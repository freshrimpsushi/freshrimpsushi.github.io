<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/tags/r/</link>
    <description>Recent content in R on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Sat, 28 Dec 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/tags/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>수리통계학에서의 첨도</title>
      <link>https://freshrimpsushi.github.io/posts/kurtosis/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kurtosis/</guid>
      <description>첨도 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{2}$ 를 $X$ 의 첨도kurtosis라고 한다. $$ \gamma_{2} := {{ E \left( X - \mu \right)^4 } \over { \sigma^4 }} $$ 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본첨도 $g_{2}$ 는 다음과 같이 구해진다. $$ g_{2} := \sum_{i=1}^{n} = {{ \left( X - \overline{X} \right)^4 } \over { n \widehat{\sigma}^4 }} - 3 $$ 설명 첨도는 4차 적률로 구해지며, 확률변수의 분포함수가 얼마</description>
    </item>
    
    <item>
      <title>수리통계학에서의 왜도</title>
      <link>https://freshrimpsushi.github.io/posts/skewness/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/skewness/</guid>
      <description>정의 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{1}$ 를 $X$ 의 왜도Skewness라고 한다. $$ \gamma_{1} := {{ E \left( X - \mu \right)^3 } \over { \sigma^3 }} $$ 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본왜도 $g_{1}$ 은 다음과 같이 구해진다. $$ g_{1} := \sum_{i=1}^{n} {{ \left( X - \overline{X} \right)^3 } \over { n \widehat{\sigma}^3 }} $$ 설명 왜도는 3차 적률로 구해지며, 확률변수의 분포함수가 어떻게 치우</description>
    </item>
    
    <item>
      <title>ROC 곡선의 AUC 를 이용해 모형 비교하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</guid>
      <description>요약 ROC 곡선은 기본적으로 사각형 $[0,1]^2$ 을 가득 채울수록 좋고, 곡선의 왼쪽 상단의 꺾이는 점이 $(0,1)$ 에 가까울 수록 좋다. 설명 위의 두 ROC 곡선이 있다고 한다면 마음 편하게 &amp;lsquo;좋다&amp;rsquo;라고 할 수 있는 쪽은 오른쪽이다. 이 &amp;lsquo;좋다&amp;rsquo;는 말이 의미하는 것은 ROC 곡선을 그려내는 모형이 더 낫다는 뜻이다. 당연히 비교되는</description>
    </item>
    
    <item>
      <title>ROC 곡선을 이용해 최적의 컷오프 찾는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</link>
      <pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</guid>
      <description>개요 ROC 곡선을 그리면 트레이닝 데이터로 얻은 모형이 테스트 데이터를 어느정도로 잘 설명하는지 한 눈에 보여서 유용하다. 하지만 이 곡선은 모든 컷오프에 대한 분류율을 계산하고 이은 것이므로 결국 &amp;lsquo;어떤 컷오프로 0과 1을 분류할 것인가&amp;rsquo;는 알 수 없다. 이것을 알아내기 위해 교차검증의 방법론을 응용해보자. 검증 데이터 트레이</description>
    </item>
    
    <item>
      <title>R 에서 ROC 곡선 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</guid>
      <description>정의 오류행렬의 False Positive Rate와 True Positive Rate를 각각 축으로 두고 그린 그림을 ROC 곡선Receiver Operating Characteristic Curve 이라고 한다. 설명 ROC 곡선은 모델의 퍼포먼스를 한 눈에 보여줄 뿐만 아니라 최적의 컷오프를 찾고 모델 간의 비교에도 쓰이는 등 요긴하게 쓸 데가 많다. 예제를 통해 R 에서 ROC 곡선을 그려보고 그 의미를 이해해보자. 핵심적인 패키지로 ROCR이 쓰인</description>
    </item>
    
    <item>
      <title>통계적 분석에서의 변수 선택 절차</title>
      <link>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistical-analysis/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistical-analysis/</guid>
      <description>빌드업 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 독립변수는 $p$ 개로, 회귀분석의 여러가지 가정들을 잘 만족하고 다중공선성이 없으며 설명력이 높다면 좋을 것이다. 물론 정보라는 것은 많으면 많을수록 좋지만, 지나치게 많은 데이터로 얻은 회귀모형은 사용하는데에도 많은 데이터를 요구한다. 그래서 가능하다면 사용하는 독립변수를 줄여</description>
    </item>
    
    <item>
      <title>R 에서 주성분회귀분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</guid>
      <description>개요 주성분회귀분석PCR 이란 주성분분석과 다중회귀분석을 합친 것으로, 주성분분석을 통해 얻은 주성분을 새로운 독립변수로 둔 회귀분석을 말한다. 사실 통계학의 관점에서 주성분분석 그 자체는 별 필요가 없고, 보통 회귀분석에 쓰일 때나 의미가 있다. 실습 (다중공선성을 찾아내는 법에 이어서) 주성분을 만들어내는 과정은 행렬분해를 포함한 복잡한</description>
    </item>
    
    <item>
      <title>분산팽창인자 VIF</title>
      <link>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</guid>
      <description>정의 1 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 할 때 $i$ 번째 독립변수에 대한 다중회귀분석 $$X_{i} \leftarrow X_{1} , \cdots, X_{i-1} , X_{i+1} , \cdots, X_{p}$$ 의 중회귀계수를 $R_{i}^2$ 라고 두자. 다음을 $X_{i}$ 의 분산팽창인자Variance Inflation Factor라고 한다. $$\displaystyle \text{VIF}_{i}: = {{1} \over {1 - R_{i}^{2} }}$$ 설명 우선 다중공선성에 대해 읽어보는 것을 추천한다. VIF는 분산확대지수 로 번역되는 경우도 있는 것 같지만, 보통은 너</description>
    </item>
    
    <item>
      <title>다중공선성</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</guid>
      <description>정의 1 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.이 때 독립변수 $ X_{1} , \cdots, X_{p}$ 중에서 독립변수끼리 강한 상관관계를 가지면 다중공선성Multicollinearity이 있다고 한다 실습 애초에 독립변수끼리 종속적이라는 것 자체가 회귀분석의 가정에 위배되는 말이며, 실제로 수치적인 문제를 야기해 분석 결과를 신뢰할 수 없게 만든다. 데이</description>
    </item>
    
    <item>
      <title>비선형회귀분석: 회귀분석에서의 변수 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation-of-variables/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation-of-variables/</guid>
      <description>개요 1 회귀분석은 기본적으로 변수들간의 선형관계를 밝히는 방법이지만, 필요하다면 데이터를 선형으로 &amp;lsquo;펴서&amp;rsquo; 분석할 수 있다. 이는 본질적으로 종속변수를 독립변수의 비선형결합으로 설명하는 것이다. 실습 내장데이터 Pressure 데이터를 불러와보자. Pressure 데이터는 사실 통계적으로 분석할 필요는 없다. 이는 어디까지나 자연현상</description>
    </item>
    
    <item>
      <title>회귀분석에서의 교호작용</title>
      <link>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</guid>
      <description>빌드업 우선 질적변수를 포함한 회귀분석에 대해 읽어보는 것을 추천한다. 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 우선 질적변수가 있으므로 성별을 $$ S = \begin{cases} 1 &amp;amp; ,\text{여성} \\ 0 &amp;amp; ,\text{남성} \end{cases} $$ 그리고 학력을 $$ E_{1} = \begin{cases} 1 &amp;amp; ,\text{대졸} \\ 0 &amp;amp; ,\text{고졸</description>
    </item>
    
    <item>
      <title>질적변수를 포함한 회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/regression-analysis-including-qualitative-factor/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regression-analysis-including-qualitative-factor/</guid>
      <description>개요 회귀분석을 하면서 독립변수로 언제나 양적변수가 들어온다는 보장은 없다. 성별이 무엇인지, 어떤 기업 소속인지, 무슨 색상인지, 금속인지 등등 범주형 자료 역시 분석에 반영시킬 필요가 있다. 빌드업 1 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 다중회귀분석을 사용하면 $Y \leftarrow X_{1} + X_{2}$ 와 같이 연봉 $Y$</description>
    </item>
    
    <item>
      <title>R 에서 다중회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</link>
      <pubDate>Wed, 05 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</guid>
      <description>데이터 탐색 tail(attitude) R에서 내장데이터 attitude를 불러와 tail() 함수를 통해 확인해보자. 우리는 rating을 종속변수로 두고 다른 독립변수들이 rating에 어떤 영향을 얼마나 미치는지에 관심이 있다. 데이터만 봐서는 rating과 다른 변수들 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph() plot(attitude) 그냥 plot() 함수에 데이터</description>
    </item>
    
    <item>
      <title>R 에서 단순회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</guid>
      <description>실습 회귀분석하는 법 head(faithful) R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 데이터만 봐서는 두 변수 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph(6,3) par(mfrow=c(1,2)) plot(faithful, main =&amp;quot;faithful&amp;quot;,asp=T) plot(faithful, main =&amp;quot;faithful&amp;quot;) points(head(faithful),col=&#39;red&#39;,pch=19) 왼쪽은 가로세로의 비율이 일정하도록 맞춰놓은 것인데, 정확한 그래프지만 보기가 어렵다. 오른쪽은 보기 편하도록 비율을 조정한 그래프</description>
    </item>
    
  </channel>
</rss>
