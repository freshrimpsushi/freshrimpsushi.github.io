<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/tags/r/</link>
    <description>Recent content in R on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Sat, 28 Dec 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/tags/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>수리통계학에서의 첨도</title>
      <link>https://freshrimpsushi.github.io/posts/kurtosis/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kurtosis/</guid>
      <description>첨도 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{2}$ 를 $X$ 의 첨도kurtosis라고 한다. $$ \gamma_{2} := {{ E \left( X - \mu \right)^4 } \over { \sigma^4 }} $$2. 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본첨도 $g_{2}$ 는 다음과 같이 구해진다. $$ g_{2} := \sum_{i=1}^{n} = {{ \left( X - \overline{X} \right)^4 } \over { n \widehat{\sigma}^4 }} - 3 $$ 설명 첨도는 4차 적률로 구해지며, 확률변수의 분포함수가 얼마</description>
    </item>
    
    <item>
      <title>수리통계학에서의 왜도</title>
      <link>https://freshrimpsushi.github.io/posts/skewness/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/skewness/</guid>
      <description>정의 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{1}$ 를 $X$ 의 왜도Skewness라고 한다. $$ \gamma_{1} := {{ E \left( X - \mu \right)^3 } \over { \sigma^3 }} $$2. 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본왜도 $g_{1}$ 은 다음과 같이 구해진다. $$ g_{1} := \sum_{i=1}^{n} {{ \left( X - \overline{X} \right)^3 } \over { n \widehat{\sigma}^3 }} $$ 설명 왜도는 3차 적률로 구해지며, 확률변수의 분포함수가 어떻게 치우</description>
    </item>
    
    <item>
      <title>R 에서 가치 모형으로 시계열 분석 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-garch-model-in-r/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-garch-model-in-r/</guid>
      <description>실습 가치 모델은 아치 이펙트를 설명하는 유용한 수단으로써 분석 절차 자체는 아르마 모델과 흡사하다. 위의 그래프는 내장데이터 EuStockMarkets에서 DAX만 뽑아내서 그린 것으로, 1991년부터 1999년까지 독일 DAX지수를 나타낸다. 리턴의 제곱을 보면 거의 확실하게 아치 이펙트가 있는 것으로 보인다. 리턴의 제곱이 아르마 모</description>
    </item>
    
    <item>
      <title>아치 이펙트</title>
      <link>https://freshrimpsushi.github.io/posts/arch-effect-autoregressive-conditional-heteroscedasticity-effect/</link>
      <pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arch-effect-autoregressive-conditional-heteroscedasticity-effect/</guid>
      <description>정의 1 아치 이펙트란 그 AutoRegressive Conditional Heteroscedasticity라는 말 그대로 &amp;lsquo;자기회귀 조건부 이분산 효과&amp;rsquo;로 순화되기 때문에 순화하지 않는다. 설명 쉽게 말해서 데이터의 변동성이 변하면서, 그 자체가 이전의 데이터로 설명될 수 있는 경우 데이터에 아치 이펙트가 있다고 말한다. 이러한 아치 이펙트를 통계적으로 설명</description>
    </item>
    
    <item>
      <title>시계열분석에서의 이분산성과 변동성 군집현상</title>
      <link>https://freshrimpsushi.github.io/posts/heteroscedasticity-and-volatility-clustering/</link>
      <pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heteroscedasticity-and-volatility-clustering/</guid>
      <description>정의 1 시계열 데이터 $\left\{ p_{t} \right\}$ 가 주어져 있다고 하자. $\left\{ p_{t} \right\}$ 의 분산이 $t$ 에 종속되어있을 때, $\left\{ p_{t} \right\}$ 는 이분산성Heteroscedasticity을 가진다고 한다. 이분산성을 가지는 $\left\{ p_{t} \right\}$ 의 분산이 커졌다 작아졌다를 반복하는 현상을 변동성 군집현상Volatility Clustering이라고 한다. 다음과 같이 정의된 $r_{t}$ 를 $t$ 에서의</description>
    </item>
    
    <item>
      <title>시계열분석의 이노베이티브 아웃라이어</title>
      <link>https://freshrimpsushi.github.io/posts/innovative-outlier/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/innovative-outlier/</guid>
      <description>빌드업 위의 그래프에서 2001년 9월에 굉장히 큰 아웃라이어를 찾을 수 있다. 그러나 애디티브 아웃라이어와 달리 그 후에도 계속해서 영향을 미치고 있다. 여객기의 이용자 수는 계절성을 가지고 꾸준히 증가하고 있었는데, 911테러의 공포가 이용자 수 자체를 팍 줄여버린 것으로 해석할 수 있다. 정의 1 이렇게 분석의 판도 자체를 바꾸는 아웃라이어를 이노</description>
    </item>
    
    <item>
      <title>시계열분석의 애디티브 아웃라이어</title>
      <link>https://freshrimpsushi.github.io/posts/additive-outlier/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/additive-outlier/</guid>
      <description>빌드업 위의 그래프에서 가장 먼저 눈에 띄는 지점은 바로 2015년 2월 근처에 있는 엄청난 아웃라이어다. 이렇듯 극심하게 다른 값을 가지면 분석에 악영향이 있을 수밖에 없다. 다행스러운 건 아주 잠깐, 말 그대로 한 순간의 아웃라이어로 그쳤다는 것이다. 정의 1 이렇듯 데이터의 등락 자체를 바꾸지는 않는 아웃라이어를 애디티브 아웃라이어Additiv</description>
    </item>
    
    <item>
      <title>사전백화</title>
      <link>https://freshrimpsushi.github.io/posts/prewhitening/</link>
      <pubDate>Sat, 17 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prewhitening/</guid>
      <description>정의 사전백화Prewhitening 란 CCF를 계산할 때 시계열을 백색잡음으로 만들어 두 데이터 간의 상관관계를 더욱 정확하게 파악하는 방법이다. 실습 1 가능하다면 이것이 어떻게 가능한지 수식적으로도 완전히 이해하는 것을 추천하는데, 우선은 예로써 다음의 데이터를 살펴보자. bluebird는 뉴질랜드에서 감자칩을 제조하는 회사인 블</description>
    </item>
    
    <item>
      <title>시계열 회귀 분석</title>
      <link>https://freshrimpsushi.github.io/posts/time-series-regression-analysis/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-series-regression-analysis/</guid>
      <description>정의 시계열 회귀 분석이란 말 그대로 시계열 데이터로 회귀분석하는 기법을 말한다. 원래 회귀분석 자체가 시계열 데이터를 다루는데 있어서 적합하지 않은 것은 사실이지만, 그럼에도 불구하고 복수의 시계열 데이터를 다룰 때는 회귀분석의 아이디어와 툴을 빌리는 것이 좋을 때가 있다. 실습 가령 위와 같이 두 종류의 데이터 x와 y가 주어져있다고 하자. 물론 두 데</description>
    </item>
    
    <item>
      <title>아리마 모형에 대한 잔차분석</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-tsdiag-plots-in-r/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-tsdiag-plots-in-r/</guid>
      <description>설명 회귀분석과 마찬가지로 시계열 분석 역시 잔차분석을 한다. 아리마 모형의 가정에 따르면 잔차는 모두 백색잡음이므로 선형성, 등분산성, 독립성, 정규성을 따르는지 확인은 할 것이다. 회귀분석과 비교하자면 전반적으로 그렇게까지 엄격하지는 않으나, 독립성 하나만큼은 철저하게 체크한다. 애초에 시계열분석 자체가 자기상관성을 파악하기 위한 것</description>
    </item>
    
    <item>
      <title>R 에서 EACF를 사용한 ARMA 모형 선택법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-determine-arma-model-using-eacf-in-r/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-determine-arma-model-using-eacf-in-r/</guid>
      <description>실습 1 PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다.직접 그 예를 살펴보자. ma1.2.s 데이터는 $MA(1)$ 모델에서, ar1.s 데이터는 $AR(1)$ 모델에서 나온 TSA 패키지의 샘플 데이터다. TSA 패키지의 acf() 함수와 pacf() 함수를 사용하면 다음과 같이 여러 시차 $k$ 에 대해 코릴로그램Correlogram을 그려준다. 그림만 봤을 때 파란 선을 넘어가는</description>
    </item>
    
    <item>
      <title>자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/acf-autocorrelation-function/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/acf-autocorrelation-function/</guid>
      <description>정의 1 $\left\{ Y_{t} \right\}_{t=1}^{n} $ 이 확률과정이라고 하자. $\mu_{t} := E ( Y_{t} ) $ 를 평균함수라고 한다. 다음과 같이 정의된 $\gamma_{ t , s }$ 를 자기공분산함수라고 한다. $$ \gamma_{t , s} : = \text{cov} ( Y_{t} , Y_{s} ) = E ( Y_{t} - \mu_{t} ) E ( Y_{s} - \mu_{s} ) $$ 다음과 같이 정의된 $\rho_{ t , s }$ 를 자기상관함수라고 한다. $$ \displaystyle \rho_{ t , s } := \text{cor} ( Y_{t} , Y_{s} ) = {{ \gamma_{t , s} } \over { \sqrt{ \gamma_{t , t} \gamma_{s , s} } }} $$ 다음과 같이 정</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 예측하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-predict-with-arima-model-in-r/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-predict-with-arima-model-in-r/</guid>
      <description>실습 R 내장데이터 UKDriverDeaths는 1969년부터 1984년까지 영국 월별 운전자 사상자에 대한 데이터다. 언뜻 보아도 계절형 아리마 모형을 따르고, 실제로 모형을 찾아내는것은 별로 어렵지 않다. 그러나 최종적으로 얻은 모형으로 식을 직접 써서 계산하는 것은 무척 손이 많이 가고 복잡한 일이다. 따라서 predict() 함수를 사용한다. n.ahead 옵션을</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 얻은 시계열 분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-arima-model-summary-in-r/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-arima-model-summary-in-r/</guid>
      <description>실습 R 내장데이터 AirPassenger는 1949년부터 1960년까지 월별 항공기의 승객 수에 대한 데이터다. (1) 모형: 사실 계수만 제대로 파악할 수 있다면 중요한 것은 아니다. 계절형 아리마 모형 $ARIMA(p,d,q)\times(P,D,Q)_{s}$ 을 나타낸다. 예로써 위 분석의 결과인 ARIMA(0,1,1)(0,1,1)[12]는 $ARIMA(0,1,1)\times(0,1,1)_{12}$ 를 의미한다. (2) 계수: 모형에 맞는 계수를 나타</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 시계열 분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-arima-model-in-r/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-arima-model-in-r/</guid>
      <description>실습 R에서 내장데이터 WWWusage 를 불러와 그래프를 그려 확인해보자. WWWusage는 먼 옛날 인터넷에 접속하는 이용자수를 나타내는 시계열 데이터로써, 그 추이를 파악하기 위해서는 시계열 분석을 해야한다. 시계열 분석에서 가장 대표적인 모형은 아리마 모형이나, 같은 아리마 모형이라고 해도 실제로 적절한 모형을 찾아내는 방법은 여러가지가 있다. 다행</description>
    </item>
    
    <item>
      <title>아리마 모형에서의 드리프트</title>
      <link>https://freshrimpsushi.github.io/posts/drift-in-arima-model/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/drift-in-arima-model/</guid>
      <description>설명 계열 분석을 하다보면 종종 다음과 같이 드리프트 라는 계수를 보게 된다. 물론 위의 경우 표준오차에 비해서 계수의 크기가 너무 작기 때문에 무시해도 상관 없다. 그러나 실제로 유의한 계수인 동시에 수식으로도 써야할 일이 있다면 드리프트가 무엇인지 알아야한다. 아쉽게도 국내에는 드리프트가 도대체 무엇인지에 대한 좋은 설명이 없으며, 수식을 동원하지</description>
    </item>
    
    <item>
      <title>시계열분석에서의 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation/</guid>
      <description>빌드업 시계열에서 변환이 필요한 이유는 시간이 흐를수록 분산이 커지는 경우 그에 따른 &amp;lsquo;패널티&amp;rsquo;를 줘서 분산을 일정하게 하고 정상성을 얻기 위함이다. 루트 $\sqrt{}$ 나 로그 $\log$ 는 값이 클수록 줄어드는 양이 많기 때문에 자주 사용된다. 당연하지만 분산이 줄어드는 경우에는 데이터의 추이가 어떤 점으로 수렴한다는 의미가 되므로 변환 이전</description>
    </item>
    
    <item>
      <title>시계열분석에서의 차분</title>
      <link>https://freshrimpsushi.github.io/posts/difference/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference/</guid>
      <description>정의 1 오퍼레이터 $B$ 를 $B Y_{t} = Y_{t-1}$ 과 같이 정의하고, 백쉬프트Backshift라 한다. 오퍼레이터 $\nabla$ 를 $\nabla := 1 - B$ 그리고 $\nabla^{r+1} = \nabla \left( \nabla^{r} Y_{t} \right)$ 와 같이 정의하고 차분 이라한다. 설명 차분의 정의에 따르면 $1$차 차분은 $$ \nabla Y_{t} = Y_{t} - Y_{t-1} $$ 와 같이 계산되며, $2$차 차분은 $$ \begin{eqnarray*} \nabla^2 Y_{t} &amp;amp;=&amp;amp; \nabla \left( \nabla Y_{t} \right) \\ &amp;amp;=&amp;amp; \nabla \left( Y_{t} - Y_{t-1} \right) \\ &amp;amp;=&amp;amp; \nabla Y_{t} - \nabla Y_{t-1} \\ &amp;amp;=&amp;amp; ( Y_{t} - Y_{t-1} ) - (</description>
    </item>
    
    <item>
      <title>시계열분석에서의 정상성</title>
      <link>https://freshrimpsushi.github.io/posts/stationarity-in-time-series-analysis/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stationarity-in-time-series-analysis/</guid>
      <description>정의 1 시계열 데이터의 평균과 분산이 일정할 때 정상성Stationarity을 갖는다고 한다. 설명 정상正常Normal이 아니라 정상定常Stational이다. 데이터가 정상성을 가진다는 것은 평균과 분산이 안정되어 있어서 분석하기 쉽다는 의미가 된다. 데이터가 정상성을 가지지 않으면 분석이 어렵기 때문에 정상성을 갖도록 만드는 전처</description>
    </item>
    
    <item>
      <title>ROC 곡선의 AUC 를 이용해 모형 비교하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</guid>
      <description>요약 ROC 곡선은 기본적으로 사각형 $[0,1]^2$ 을 가득 채울수록 좋고, 곡선의 왼쪽 상단의 꺾이는 점이 $(0,1)$ 에 가까울 수록 좋다. 설명 위의 두 ROC 곡선이 있다고 한다면 마음 편하게 &amp;lsquo;좋다&amp;rsquo;라고 할 수 있는 쪽은 오른쪽이다. 이 &amp;lsquo;좋다&amp;rsquo;는 말이 의미하는 것은 ROC 곡선을 그려내는 모형이 더 낫다는 뜻이다. 당연히 비교되는</description>
    </item>
    
    <item>
      <title>ROC 곡선을 이용해 최적의 컷오프 찾는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</link>
      <pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</guid>
      <description>개요 ROC 곡선을 그리면 트레이닝 데이터로 얻은 모형이 테스트 데이터를 어느정도로 잘 설명하는지 한 눈에 보여서 유용하다. 하지만 이 곡선은 모든 컷오프에 대한 분류율을 계산하고 이은 것이므로 결국 &amp;lsquo;어떤 컷오프로 0과 1을 분류할 것인가&amp;rsquo;는 알 수 없다. 이것을 알아내기 위해 교차검증의 방법론을 응용해보자. 검증 데이터 트레이</description>
    </item>
    
    <item>
      <title>R 에서 ROC 곡선 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</guid>
      <description>정의 오류행렬의 False Positive Rate와 True Positive Rate를 각각 축으로 두고 그린 그림을 ROC 곡선Receiver Operating Characteristic Curve 이라고 한다. 설명 ROC 곡선은 모델의 퍼포먼스를 한 눈에 보여줄 뿐만 아니라 최적의 컷오프를 찾고 모델 간의 비교에도 쓰이는 등 요긴하게 쓸 데가 많다. 예제를 통해 R 에서 ROC 곡선을 그려보고 그 의미를 이해해보자. 핵심적인 패키지로 ROCR이 쓰인</description>
    </item>
    
    <item>
      <title>확률과정이란?</title>
      <link>https://freshrimpsushi.github.io/posts/stochastic-process/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stochastic-process/</guid>
      <description>정의 확률변수 $X: \Omega \to E$ 의 공역을 상태공간이라 한다. 확률변수의 집합 $ \left\{ X_{t} \mid t \in [ 0 , \infty ) \right\} $ 을 연속적 확률과정이라 한다. 확률변수의 수열 $\left\{ X_{n} \mid n = 0, 1, 2, \cdots \right\} $ 을 이산적 확률과정이라 한다. 설명 확률과정은 과정Process이라는 단어 때문에 이해하기 어려운, 전형적으로 말이 어려워서 어려운 개념이다. &amp;lsquo;프로세스&amp;</description>
    </item>
    
    <item>
      <title>통계적 분석에서의 변수 선택 절차</title>
      <link>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistical-analysis/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistical-analysis/</guid>
      <description>빌드업 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 독립변수는 $p$ 개로, 회귀분석의 여러가지 가정들을 잘 만족하고 다중공선성이 없으며 설명력이 높다면 좋을 것이다. 물론 정보라는 것은 많으면 많을수록 좋지만, 지나치게 많은 데이터로 얻은 회귀모형은 사용하는데에도 많은 데이터를 요구한다. 그래서 가능하다면 사용하는 독립변수를 줄여</description>
    </item>
    
    <item>
      <title>R 에서 주성분회귀분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</guid>
      <description>개요 주성분회귀분석PCR 이란 주성분분석과 다중회귀분석을 합친 것으로, 주성분분석을 통해 얻은 주성분을 새로운 독립변수로 둔 회귀분석을 말한다. 사실 통계학의 관점에서 주성분분석 그 자체는 별 필요가 없고, 보통 회귀분석에 쓰일 때나 의미가 있다. 실습 (다중공선성을 찾아내는 법에 이어서) 주성분을 만들어내는 과정은 행렬분해를 포함한 복잡한</description>
    </item>
    
    <item>
      <title>분산팽창인자 VIF</title>
      <link>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</guid>
      <description>정의 1 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 할 때 $i$ 번째 독립변수에 대한 다중회귀분석 $$X_{i} \leftarrow X_{1} , \cdots, X_{i-1} , X_{i+1} , \cdots, X_{p}$$ 의 중회귀계수를 $R_{i}^2$ 라고 두자. 다음을 $X_{i}$ 의 분산팽창인자Variance Inflation Factor라고 한다. $$\displaystyle \text{VIF}_{i}: = {{1} \over {1 - R_{i}^{2} }}$$ 설명 우선 다중공선성에 대해 읽어보는 것을 추천한다. VIF는 분산확대지수 로 번역되는 경우도 있는 것 같지만, 보통은 너</description>
    </item>
    
    <item>
      <title>다중공선성</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</guid>
      <description>정의 1 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.이 때 독립변수 $ X_{1} , \cdots, X_{p}$ 중에서 독립변수끼리 강한 상관관계를 가지면 다중공선성Multicollinearity이 있다고 한다 실습 애초에 독립변수끼리 종속적이라는 것 자체가 회귀분석의 가정에 위배되는 말이며, 실제로 수치적인 문제를 야기해 분석 결과를 신뢰할 수 없게 만든다. 데이</description>
    </item>
    
    <item>
      <title>비선형회귀분석: 회귀분석에서의 변수 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation-of-variables/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation-of-variables/</guid>
      <description>개요 1 회귀분석은 기본적으로 변수들간의 선형관계를 밝히는 방법이지만, 필요하다면 데이터를 선형으로 &amp;lsquo;펴서&amp;rsquo; 분석할 수 있다. 이는 본질적으로 종속변수를 독립변수의 비선형결합으로 설명하는 것이다. 실습 내장데이터 Pressure 데이터를 불러와보자. Pressure 데이터는 사실 통계적으로 분석할 필요는 없다. 이는 어디까지나 자연현상</description>
    </item>
    
    <item>
      <title>회귀분석에서의 교호작용</title>
      <link>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</guid>
      <description>빌드업 우선 질적변수를 포함한 회귀분석에 대해 읽어보는 것을 추천한다. 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 우선 질적변수가 있으므로 성별을 $$ S = \begin{cases} 1 &amp;amp; ,\text{여성} \\ 0 &amp;amp; ,\text{남성} \end{cases} $$ 그리고 학력을 $$ E_{1} = \begin{cases} 1 &amp;amp; ,\text{대졸} \\ 0 &amp;amp; ,\text{고졸</description>
    </item>
    
    <item>
      <title>질적변수를 포함한 회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/regression-analysis-including-qualitative-factor/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regression-analysis-including-qualitative-factor/</guid>
      <description>개요 회귀분석을 하면서 독립변수로 언제나 양적변수가 들어온다는 보장은 없다. 성별이 무엇인지, 어떤 기업 소속인지, 무슨 색상인지, 금속인지 등등 범주형 자료 역시 분석에 반영시킬 필요가 있다. 빌드업 1 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 다중회귀분석을 사용하면 $Y \leftarrow X_{1} + X_{2}$ 와 같이 연봉 $Y$</description>
    </item>
    
    <item>
      <title>R 에서 다중회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</link>
      <pubDate>Wed, 05 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</guid>
      <description>데이터 탐색 tail(attitude) R에서 내장데이터 attitude를 불러와 tail() 함수를 통해 확인해보자. 우리는 rating을 종속변수로 두고 다른 독립변수들이 rating에 어떤 영향을 얼마나 미치는지에 관심이 있다. 데이터만 봐서는 rating과 다른 변수들 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph() plot(attitude) 그냥 plot() 함수에 데이터</description>
    </item>
    
    <item>
      <title>R 에서 단순회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</guid>
      <description>실습 회귀분석하는 법 head(faithful) R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 데이터만 봐서는 두 변수 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph(6,3) par(mfrow=c(1,2)) plot(faithful, main =&amp;quot;faithful&amp;quot;,asp=T) plot(faithful, main =&amp;quot;faithful&amp;quot;) points(head(faithful),col=&#39;red&#39;,pch=19) 왼쪽은 가로세로의 비율이 일정하도록 맞춰놓은 것인데, 정확한 그래프지만 보기가 어렵다. 오른쪽은 보기 편하도록 비율을 조정한 그래프</description>
    </item>
    
  </channel>
</rss>
