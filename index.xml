<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/</link>
    <description>Recent content on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Fri, 15 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>정사각 행렬의 정의와 성질</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-properties-of-square-matrix/</link>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-properties-of-square-matrix/</guid>
      <description>정의 임의의 행렬 $A$의 행과 열의 수가 같으면 행렬 $A$를 정사각 행렬(square matrix) 이라고 한다. 정사각 행렬은 다루기 쉽고 여러가지 좋은 성질들이 있지만 우리가 항상 정사각 행렬만을 다루게 되는 것은 아니다.</description>
    </item>
    
    <item>
      <title>행렬의 연산 상수배 덧셈 곱셈</title>
      <link>https://freshrimpsushi.github.io/posts/operations-of-matrix-scalar-multiplication-sum-multiplication/</link>
      <pubDate>Wed, 13 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operations-of-matrix-scalar-multiplication-sum-multiplication/</guid>
      <description>상수배 크기가 $m \times n$인 임의의 행렬 $A$와 상수 $k$의 곱은 $A$의 각 성분에 $k$를 곱하는 것으로 정의하고 다음과 같이 표기한다. $$ kA=k\begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn} \end{bmatrix} := \begin{bmatrix} ka_{11} &amp;amp; ka_{12} &amp;amp; \cdots &amp;amp; ka_{1n} \\ ka_{21} &amp;amp; ka_{22} &amp;amp; \cdots &amp;amp; ka_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{m1} &amp;amp; ka_{m2} &amp;amp; \cdots &amp;amp; ka_{mn} \end{bmatrix} $$ 정의에 의해 상수와 행렬의 곱은 교환 관계가 성립한</description>
    </item>
    
    <item>
      <title>에이전트 기반 모델 시뮬레이션에서의 번식</title>
      <link>https://freshrimpsushi.github.io/posts/1880/</link>
      <pubDate>Tue, 12 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1880/</guid>
      <description>본 시뮬레이션은 속도와 시각화 양면으로 유리하고 코딩도 쉬운 줄리아로 구현되어 있다. 가장 좋은 공부는 깃허브에서 줄리아 코드를 받아 직접 실행해보는 것이지만, 줄리아가 낯설다면 그냥 시뮬레이션을 어떻게 하는건지 읽고 이해만 해도 충분할 수 있다. 구현 자체에 있어 어떤 언어를 사용하느냐는 본질적으로 중요하지 않다. 소스 코드 이 포스트에서는 생성된</description>
    </item>
    
    <item>
      <title>매트랩에서 2차원 배열을 히트맵 이미지로 출력하고 저장하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-and-save-arrays-as-heatmap-images-in-matlab/</link>
      <pubDate>Mon, 11 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-and-save-arrays-as-heatmap-images-in-matlab/</guid>
      <description>줄리아에서 Imagesc imagesc 함수를 쓰면 2차원 배열을 히트맵으로 출력할 수 있다. colorbar는 스케일을 보여주는 컬러바를 같이 출력하는 설정이다. N=2^8; p=phantom(&amp;lsquo;Modified Shepp-Logan&amp;rsquo;,N); figure() imagesc(p) colorbar &amp;lt;img filemime=&amp;quot;image/png&amp;quot; filename=&amp;quot;화면 캡처 2020-12-31 164537.png&amp;quot; height=&amp;quot;507&amp;quot; src=&amp;quot;https://t1.daumcdn.net/cfile/tistory/9961F83E5FED830222&amp;quot; style=&amp;quot;max-width:100%;height:auto&amp;quot; width=&amp;quot;562&amp;quot;/&amp;gt; ## 저장 1 `saveas` 함수를 써서 위에서 띄운 figure를 저장할 수 있다. 이때 설정 `gcf`는 현재 figure를 의미한다. 그러</description>
    </item>
    
    <item>
      <title>블로그 이관 작업 안내</title>
      <link>https://freshrimpsushi.github.io/posts/1054/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1054/</guid>
      <description>새로운 생새우초밥집 링크생새우초밥집에 방문해주시는 모든 손님 여러분께 항상 감사드립니다.저희는 수학, 물리학, 통계학, 컴퓨터공학등의 형식과학 위주로 많은 컨텐츠를 업로드해왔으며, 앞으로도 더욱 넓고 깊은 분야를 탐구해나갈 예정입니다. 특히 수학자에게 친화적인 프로그래밍 언어, 줄리아의 국내 보급에 힘쓸 것이며 21년에는 다음과 같은</description>
    </item>
    
    <item>
      <title>서열정렬 점수와 갭 페널티</title>
      <link>https://freshrimpsushi.github.io/posts/sequence-alignment-score-and-gap-penalty/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sequence-alignment-score-and-gap-penalty/</guid>
      <description>레퍼런스 서열과 쿼리 서열이 주어져 있다고 하자. 서열정렬 점수 란 두 서열을 비교했을 때 얼마나 일치하는지를 수치화하는 것과 그 방법을 말한다. 점수화는 다음과 같은 사항들에 가중치를 주어 계산된다.1. Match : 두 서열이 일치하는 횟수다.2. Mismatch : 두 서열이 일치하지 않는 횟수다.예로써 위와 같은 두 염기서열이 있다고 하자. 이때 서열정렬을 하는 방법은</description>
    </item>
    
    <item>
      <title>서열정렬에서의 치환행렬</title>
      <link>https://freshrimpsushi.github.io/posts/substitution-matrix/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/substitution-matrix/</guid>
      <description>서열정렬 점수를 매길 때 매치와 미스매치의 기준이 되는 행렬을 치환행렬 이라 한다. using BioAlignments EDNAFULL BLOSUM45 PAM30 거두절미하고 예시부터 보자. 줄리아에서는 BioAlignments라는 패키지가 나와있고 손쉽게 원하는 치환행렬을 불러들일 수 있다. DNA 분석에 자주 사용되는 EDNAFULL나 단백질 서열에 쓰이는 BLOSUM(BLOcks SUbstitution Matrix), PAM (Point Accepted Mutation) 행렬을 불러보면 다음과 같다.매</description>
    </item>
    
    <item>
      <title>이상적인 집단 성장 맬서스 성장 모델</title>
      <link>https://freshrimpsushi.github.io/posts/malthusian-growth-model/</link>
      <pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/malthusian-growth-model/</guid>
      <description>멜서스 성장 모델의 시각적 이해 모델 **멜서스 성장 모델** [^1] $$ N &#39; = rN $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 파라메터 $r \in \mathbb{R}$ : 고유 성장률(Intrinsic Rate of Increase) 로써, $0$ 보다 크면 성장하고 $0$ 보다 작으면 쇠퇴한다. 번식률(Birth Rate) $b$ 와 사망률(Death Rate) $d$ 의 차 $r:=b-d$ 로 정의되기도 한다. 인구 동역학(Populat</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 유전체와 유전자</title>
      <link>https://freshrimpsushi.github.io/posts/genome-and-gene-in-bioinformatics/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/genome-and-gene-in-bioinformatics/</guid>
      <description>&amp;lt;p&amp;lt; b=&amp;quot;&amp;quot;&amp;gt; * 실제 화학, 생물학적인 의미에 대해서는 깊게 다루지 않고 생명정보공학에 필요할 내용만을 간추린 포스트입니다. 생명공학에 대해서는 잘 모르니 많은 지적 부탁드립니다. 마찬가지의 이유로 질문에는 대답해드리기 어렵습니다.1. 한 개체의 염기서열을 모두 모은 것을 유전체 라고 한다.2. 유전체의 일부를 차지하는 구간으로, 유전 형질의 단위가</description>
    </item>
    
    <item>
      <title>줄리아에서 움짤 찌는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-gif-animation-in-julia/</link>
      <pubDate>Sun, 27 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-gif-animation-in-julia/</guid>
      <description>원래 생새우초밥집에서는 이보다는 훨씬 자세한 설명을 추가하는 편이지만, 줄리아에서 움짤을 찌는 게 얼마나 쉬운지를 강조하기 위해 가능한한 짧게 설명하도록 하겠다.위와 같은 랜덤 워크를 시뮬레이션하는 건 둘째치더라도, 위와 같이 움짤로 만드는 것은 언어에 따라 아주 어렵고 힘들 수 있다. 그러나 줄리아에서는 @animate 매크로와 gif() 함수를 통해 어마어마하게 쉽</description>
    </item>
    
    <item>
      <title>머신 러닝에서 벡터 행렬의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-for-vector-and-matrix-in-machine-learning/</link>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-for-vector-and-matrix-in-machine-learning/</guid>
      <description>**스칼라 함수의 그래디언트: $$ \frac{ \partial f(\mathbf{w})}{ \partial \mathbf{w} } :=\nabla_{\mathbf{w}}f(\mathbf{w})=\begin{bmatrix} \frac{ \partial f(\mathbf{w})}{ \partial w_{1} },\frac{ \partial f(\mathbf{w})}{ \partial w_{2} },\cdots,\frac{ \partial f(\mathbf{w})}{ \partial w_{n} } \end{bmatrix}^{T} $$ **내적의 그래디언트Gradient of the inner product: $f(\mathbf{w})=\mathbf{w}^{T}\mathbf{x}$라고 하면 $$ \begin{align*} \frac{ \partial f(\mathbf{w})}{ \partial \mathbf{w} } =\frac{ \partial (\mathbf{w}^{T}\mathbf{x})}{ \partial \mathbf{w} } &amp;amp;=\begin{bmatrix} \frac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{1} },\frac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{2} },\cdots,\frac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{n} } \end{bmatrix}^{T}</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 인트론과 엑손</title>
      <link>https://freshrimpsushi.github.io/posts/intron-and-exon-in-bioinformatics/</link>
      <pubDate>Fri, 25 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/intron-and-exon-in-bioinformatics/</guid>
      <description>&amp;lt;p&amp;lt; b=&amp;quot;&amp;quot;&amp;gt; * 실제 화학, 생물학적인 의미에 대해서는 깊게 다루지 않고 생명정보공학에 필요할 내용만을 간추린 포스트입니다. 생명공학에 대해서는 잘 모르니 많은 지적 부탁드립니다. 마찬가지의 이유로 질문에는 대답해드리기 어렵습니다.진핵 생물의 DNA에서 실제로 단백질의 합성에 관여하는 부분을 엑손 , 그렇지 않은 부분을 인트론 이라고 한다.원핵 생물</description>
    </item>
    
    <item>
      <title>수반 작용소의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-adjoint-operator/</link>
      <pubDate>Thu, 24 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-adjoint-operator/</guid>
      <description>$H,K$가 힐베르트 공간이라고 하자. 유계 선형 작용소 $T : K \to H$ 에 대해 다음을 만족하는 $T^{ * } : H \to K$ 를 $T$ 의 수반 작용소라고 한다. $$ \left&amp;lt; T \textbf{v} , \textbf{w} \right&amp;gt;{H} = \left&amp;lt; \textbf{v} , T^{ * } \textbf{w} \right&amp;gt;{K},\quad \forall \textbf{v} \in K $$ 이때 수반 작용소는 다음의 성질을 갖는다.(a) $T^{ * }$ 는 선형이고 유계다.(b) $\left( T^{ * } \right)^{ * } = T$(c) $\left| T^{ * } \right| = \left| T \right| $ 증명 (a) Part 1. $T^{ * }$는 선형이다</description>
    </item>
    
    <item>
      <title>행렬 대각합의 정의와 성질</title>
      <link>https://freshrimpsushi.github.io/posts/defenition-and-properties-of-trace/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/defenition-and-properties-of-trace/</guid>
      <description>$n\times n$행렬 $A$가 다음과 같이 주어졌다고 하자. $$ A= \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{n1} &amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \end{bmatrix} $$ $A$의 대각 성분들의 합을 $A$의 **대각합**trace 이라 정의하고 다음과 같이 표기한다. $$ \text{tr}(A)=\text{Tr}(A)=a_{11}+a_{22}+\cdots + a_{nn}=\sum \limits_{i=1}^{n} a_{ii} $$ 다음과 같이 대각합을 함수로 생각할 수도 있다.$M_{n\times n}(\mathbb</description>
    </item>
    
    <item>
      <title>염기서열의 상류와 하류</title>
      <link>https://freshrimpsushi.github.io/posts/upstream-and-downstream-of-nucleic-sequence/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/upstream-and-downstream-of-nucleic-sequence/</guid>
      <description>1염기서열의 방향은 위의 그림처럼 오탄당의 탄소 원자 위치에 따라 번호를 부여함으로써 나타낼 수 있다. RNA와 DNA는 구체적으로 3번 탄소 3&amp;rsquo;와 5번 탄소 5&amp;rsquo;가 인산에스터 결합(Phosphodiester Bond) 을 형성함으로써 사슬 구조를 이룬다. 가령 네 개의 염기가 다음과 같이 탄소 위치와 함께 주어져 있다고 하자</description>
    </item>
    
    <item>
      <title>놈 공간에서 무한 급수 스팬 토탈 시퀀스</title>
      <link>https://freshrimpsushi.github.io/posts/infinite-series-span-total-sequence-in-normed-space/</link>
      <pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/infinite-series-span-total-sequence-in-normed-space/</guid>
      <description>놈 공간 $\left( V, \left| \cdot \right| \right)$가 주어졌다고 하자. $V$의 수열 $\left\{ \mathbf{v}{k}\right\}{k\in \mathbb{N}}$에 대해서 부분합을 다음과 같이 정의하자. $$ \mathbf{S}{N} := \sum \limits{k=1}^{N}\mathbf{v}{k} $$ 부분합 $\mathbf{S}{N}$의 극한이 $\mathbf{v} \in V$로 놈 수렴하면, 즉 아래의 식 $$ \lim \limits_{N\to \infty}\left| \mathbf{v}-\sum \limits_{k=1}^{N}\mathbf{v}_{k} \right|=0 $$ 을 만족하면 무한 급수 $\sum_{k=1}^{\infty}\mathb</description>
    </item>
    
    <item>
      <title>딥러닝의 수학적 근거  시벤코 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cybenko-theorem/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cybenko-theorem/</guid>
      <description>$\sigma$ 가 연속 시그모이달 함수라고 하면 $$ \displaystyle S := \left\{ G(x) = \sum_{k=1}^{N} \alpha_{k} \sigma \left( y_{k}^{T} x+ \theta_{k} \right) : y_{k} \in \mathbb{R}^{n} \land \alpha_{k} , \theta_{k} \in \mathbb{R} \land N \in \mathbb{N} \right\} $$ 는 $C\left( I_{n} \right)$ 에서 균등 조밀하다. 달리 말하자면, 모든 $f \in C \left( I_{n} \right)$ 과 $\varepsilon &amp;gt; 0$ 에 대해 다음을 만족하는 $G \in S$ 가 존재한다. $$ \left| G - f \right| &amp;lt; \varepsilon $$ * 다음을 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 을 시그모이달 함수라 한다. $$ \sigma (t) \to \begin{cases} 1 &amp;amp; \text{as } t \to + \infty \\ 0 &amp;amp; \text{as</description>
    </item>
    
    <item>
      <title>내적 공간에서 0의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-zero-in-inner-product-space/</link>
      <pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-zero-in-inner-product-space/</guid>
      <description>$\left( H, \left\langle \cdot,\cdot \right\rangle \right)$을 내적 공간이라고 하자.(a) 모든 $x\in H$에 대해서 다음이 성립한다. $$ \left\langle 0,x \right\rangle =0 $$ (b) 모든 $x\in H$에 대해서 위의 식을 만족하는 $H$의 원소는 오직 $0$뿐이다. $$ \forall x\in H,\ \left\langle x,y \right\rangle =0 \implies y=0 $$ (c) $y,z \in H$라고 하자. 그리고 $$ \begin{equation} \left\langle x,y \right\rangle =\left\langle x,z \right\rangle\quad \forall x\in H \label{eqc}\end{equation} $$ 라고 가정하자. 그러면 다음이 성립한다. $$ y=z $$ 증명 (a) 내적의 정의</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 코돈과 아미노산 유전 부호</title>
      <link>https://freshrimpsushi.github.io/posts/codon-amino-acid-genetic-code/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/codon-amino-acid-genetic-code/</guid>
      <description>&amp;lt;p&amp;lt; b=&amp;quot;&amp;quot;&amp;gt; * 실제 화학, 생물학적인 의미에 대해서는 깊게 다루지 않고 생명정보공학에 필요할 내용만을 간추린 포스트입니다. 생명공학에 대해서는 잘 모르니 많은 지적 부탁드립니다. 마찬가지의 이유로 질문에는 대답해드리기 어렵습니다.1. DNA의 염기 3개를 순서쌍으로 묶은 단위를 트리플렛 코드Triplet Code 라 한다.2. 센트럴 도그마에 따라 전</description>
    </item>
    
    <item>
      <title>B-스플라인 스케일링 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/b-spline-scaling-equation/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/b-spline-scaling-equation/</guid>
      <description>**B-스플라인 스케일링 방정식 (a) 오더가 $m\in N$인 B-스플라인 $N_{m}$에 대해서 다음의 식이 성립한다. $$ \widehat{N_{m}}(2\gamma)=H_{0}(\gamma)\widehat{N_{m}}(\gamma),\quad \forall \gamma \in \mathbb{R} $$ 이때 $H_{0}$는 주기가 $1$인 함수이며 다음과 같다. $$ H_{0}(\gamma)=\left( \frac{1+e^{-2\pi i \gamma}}{2} \right)^{m} $$ 또한 $f$의 푸리에 변환 $\widehat{f}$의 정의는 다음과 같다. $$ \widehat{f}(\gamma):=\int _{-\infty} ^{\infty} f(x)e^{-2\pi i x \gamma}dx $$ **(b)** 비슷하게 오더가 $m$인 중심 B-</description>
    </item>
    
    <item>
      <title>시그모이달 함수란</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-sigmoidal-function/</link>
      <pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-sigmoidal-function/</guid>
      <description>다음을 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 을 시그모이달 함수 라 한다. $$ \sigma (t) \to \begin{cases} 1 &amp;amp; \text{as } t \to + \infty \\ 0 &amp;amp; \text{as } t \to - \infty \end{cases} $$ 시그모이달 함수의 정의에서 $0$ 이나 $1$ 이냐는 것은 사실 별로 중요하지 않고, 양이든 음이든 무한대로 갈 때 상수로 수렴한다는 것이 중요하다. 무한대가 아닌 곳에서 어떤 값을 가지지는지도 별로 중요하지는 않다. 이러한 센스에서 로지스틱 함</description>
    </item>
    
    <item>
      <title>중심 B-스플라인의 정의와 성질  Definition and Properties of Centered B-Splines</title>
      <link>https://freshrimpsushi.github.io/posts/1909/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1909/</guid>
      <description>$m\in \mathbb{N}$에 대해서, 중심 B-스플라인 $B_{m}$을 다음과 같이 정의한다. $$ B_{m}(x):= T_{-\frac{m}{2}}N_{m}(x)=N_{m}(x+{\textstyle \frac{1}{2}}) $$ 이때 $T$는 $L^{2}$ 함수의 트랜슬레이션이다. 혹은 다음과 같이 정의할 수도 있다. $$ B_{1}:= \chi_{[-1/2,1/2]},\quad B_{m+1}:=B_{m}*B_{1},\ m\in\mathbb{N} $$ 두 정의는 실제로 같은 함수를 의미한다. 여기서 핵심은 $B_{m}$을 우함수가 되게끔 정의했다는 것이다. B-스플라인에서와 같이 다음의 식</description>
    </item>
    
    <item>
      <title>내적은 연속 사상임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-inner-product-is-continuous-mapping/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-inner-product-is-continuous-mapping/</guid>
      <description>$\left( H, \left\langle \cdot,\cdot \right\rangle \right)$가 내적 공간이고 $\left\{ x_{n} \right\}$, $\left\{ y_{n} \right\}$는 각각 $x$, $y$로 수렴하는 $H$의 수열이라고 하자. 그러면 다음이 성립한다. $$ \left\langle x_{n},y_{n} \right\rangle \to \left\langle x,y \right\rangle $$ 다시말해 내적은 연속 사상이다.극한 기호가 내적 안밖을 자유롭게 드나들 수 있으므로 매우 유용한 성질이다. $$ \lim \limits_{n\to \infty} \left\langle x_{n}, y_{n} \right\rangle =\left\langle x,y \right\rangle $$ 증명 내적의 정의와 코시-슈바르</description>
    </item>
    
    <item>
      <title>분자생물학의 중심원리</title>
      <link>https://freshrimpsushi.github.io/posts/central-dogma-of-molecular-biology/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/central-dogma-of-molecular-biology/</guid>
      <description>실제 화학, 생물학적인 의미에 대해서는 깊게 다루지 않고 생명정보공학에 필요할 내용만을 간추린 포스트입니다. 생명공학에 대해서는 잘 모르니 많은 지적 부탁드립니다. 마찬가지의 이유로 질문에는 대답해드리기 어렵습니다.&amp;lt;p&amp;lt; b=&amp;quot;&amp;quot;&amp;gt;분자생물학의 중심원리 혹은 센트럴 도그마 란 유전 정보는 DNA</description>
    </item>
    
    <item>
      <title>B-스플라인의 정칙성</title>
      <link>https://freshrimpsushi.github.io/posts/regularity-of-b-splines/</link>
      <pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regularity-of-b-splines/</guid>
      <description>$m=2,3,\dots$에 대해서, B-스플라인 $N_{m}$은 다음의 성질을 가진다.**(a)** $N_{m}\in C^{m-2}(\mathbb{R})$**(b)** $k\in \mathbb{Z}$에 대해, 각각의 구간 $[k,k+1]$에서 $N_{m}$은 차수가 아무리 커봐야 $m-1$인 다항식이다.**B-스플라인의 익스플리시트 공식 $$ N_{m}(x) = \frac{1}{(m-1)!}\sum \limits_{j=0}^{m} \left( -1 \right)^{j}\binom{m}{j}\left( x-j \right)_{+}^{m-1},\quad x\in \mathbb{R} $$ 이때 $$ f(x)_{+}:=\max \left( 0,f(x) \right) \quad</description>
    </item>
    
    <item>
      <title>벡터 공간에서 볼록 집합 컨벡스 셋</title>
      <link>https://freshrimpsushi.github.io/posts/convex-set-in-vector-space/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convex-set-in-vector-space/</guid>
      <description>위상공간에서 일반적으로 정의된 컨벡스벡터 공간 $V$의 부분 집합 $M$에 대해서 다음의 식이 성립하면 $M$을 볼록 집합convex set 이라고 한다. $$ \lambda x +(1-\lambda)y \in M,\quad \forall \lambda\in[0,1],\ \forall x,y \in M $$ 위 수식을 말로 풀면 &#39;$M$이 컨벡스 셋이라는 말은 $M$에 포함된 어떤 두 벡터 사이에 있는 모든 벡터들도 다 $M$에 속한다&#39; 는 의미이다. 또한 $M$이 부분 공간이</description>
    </item>
    
    <item>
      <title>차별 함수란</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-discriminatory-function/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-discriminatory-function/</guid>
      <description>모든 $y \in \mathbb{R}^{n}$ 과 $\theta \in \mathbb{R}$ 와 어떤 $\mu \in M \left( I_{n} \right) $ 에 대해 $$ \int_{I_{n}} \sigma \left( y^{T} x + \theta \right) d \mu (x) = 0 \implies \mu =0 $$ 를 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 를 **차별적 함수** 라 한다. * $I_{n} := [0,1]^{n}$ 는 $n$차원 유닛 큐브로써, $n$ 개의 단위폐구간 $[0,1]$ 에 데카르트 곱을 취한 것이다. * $M \left( I_{n} \right)$ 는 $I_{n} := [0,1]^{n}$ 에서 정의되는 부호 유한 정칙 보렐 측도의 집합이다. * $y^{T}$ 는 $y$ 의 전치 행렬로써, $y^{T} x$</description>
    </item>
    
    <item>
      <title>B-스플라인의 익스플리시트 공식</title>
      <link>https://freshrimpsushi.github.io/posts/explicit-formula-for-the-b-splines/</link>
      <pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/explicit-formula-for-the-b-splines/</guid>
      <description>함수 $f: \mathbb{R}\to \mathbb{R}$에 대해서 $$ f(x){+}:=\max \left( 0,f(x) \right) $$ 이라고 하자. 즉, $f{+}$는 $f$의 함숫값이 $0$보다 작은 부분을 모두 $0$으로 바꾼 함수이다. 또한 $$ f(x){+}^{n}:=\left( f(x){+} \right)^{n} $$ 라고 정의하자. 그러면 각각의 $m=2,3,\dots$에 대해서 B-스플라인 $N_{m}$은 다음과 같이 표현될 수 있다. $$ N_{m}(x) = \frac{1}{(m-1)!}\sum \limits_{j=0}^{m} \left( -1 \right)^{j}\binom{m}{j}\left( x-j \right)_{+}^{m-1},\quad x\in \mathbb{R} $$ 증명</description>
    </item>
    
    <item>
      <title>플랜체렐 정리</title>
      <link>https://freshrimpsushi.github.io/posts/the-plancherel-theorem/</link>
      <pubDate>Mon, 30 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-plancherel-theorem/</guid>
      <description>모든 $f,g \in L^{2}$에 대해서 다음의 식이 성립한다. $$ \begin{align*} \langle \hat{f},\hat{g} \rangle &amp;amp;=2 \pi \left\langle f,g \right\rangle \tag{1} \\ | \hat{f} |^{2} &amp;amp;= 2\pi | f| ^{2} \tag{2} \end{align*} $$ $f$의 푸리에 변환을 정의하는 과정을 보면 $f$가 $L^{1}$함수여야하고, $L^{1}$함수이기만 하면 된다. 하지만 우리는 $L^{1}$공간 뿐 아니라 $L^{2}$공간에서도 푸리에 변환을 자유자재로 쓸 수 있기를 원한</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 DNA RNA 염색체 DNA RNA Chromosome in Bioinformatics</title>
      <link>https://freshrimpsushi.github.io/posts/1827/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1827/</guid>
      <description>&amp;lt;p&amp;lt; b=&amp;quot;&amp;quot;&amp;gt; * 실제 화학, 생물학적인 의미에 대해서는 깊게 다루지 않고 생명정보공학에 필요할 내용만을 간추린 포스트입니다. 생명공학에 대해서는 잘 모르니 많은 지적 부탁드립니다. 마찬가지의 이유로 질문에는 대답해드리기 어렵습니다.**빌드업 1. 화학적 합성에 의해 단위체가 반복되어 연결된 고분자를 중합체Polymer 라고 한다.2. 인산Pho</description>
    </item>
    
    <item>
      <title>슈바르츠 공간에서의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-schwartz-space/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-schwartz-space/</guid>
      <description>$\left\{ \phi_{n} \right\}$을 슈바르츠 공간에서의 수열이라고 하자. 만약 모든 멀티 인덱스 $\alpha$, $\beta$에 대해서 수열 $\left\{ \mathbf{x}^{\beta}D^{\alpha}\phi_{n}(\mathbf{x}) \right\}$이 $0$으로 균등 수렴하면 $\left\{ \phi_{n} \right\}$이 $0$으로 수렴한다고 정의하고 다음과 같이 표기한다. $$ \phi_{n} \overset{\mathcal{S}}{\to} \phi $$ 위 정의에 따라 $\left\{ \phi_{n}-\phi \right\}$가 $0$으로 수렴하면 $\left\{ \phi_{n} \righ</description>
    </item>
    
    <item>
      <title>테스트 함수 공간은 슈바르츠 공간의 진 부분집합임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-test-functions-space-is-proper-subset-of-schwartz-space/</link>
      <pubDate>Sat, 28 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-test-functions-space-is-proper-subset-of-schwartz-space/</guid>
      <description>$\mathcal{D}$가 테스트 함수 공간, $\mathcal{S}$가 슈바르츠 공간이라고 하자. 그러면 다음의 식이 성립한다. $$ \mathcal{D} \subsetneq \mathcal{S} $$ 우선 모든 테스트 함수가 슈바르츠 공간에 속함을 보인 뒤, 슈바르츠 함수 중에서 테스트 함수가 아닌 예를 보임으로써 증명한다.**슈바르츠 함수의 조건 $(a)$ $\phi \in C^{\infty} $$ (b)$ 모든 멀티 인덱스 $\alpha$, $\beta</description>
    </item>
    
    <item>
      <title>자율 시스템의 오메가 리미트 셋</title>
      <link>https://freshrimpsushi.github.io/posts/omega-limit-set-of-autonomous-system/</link>
      <pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/omega-limit-set-of-autonomous-system/</guid>
      <description>거리 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 이 벡터 필드의 플로우 $\phi ( t, x )$ 와 한 점 $x_{0} \in X$ 에 대해, $t_{i} \to \infty$ 일 때 $$ \phi \left( t_{i} , x_{0} \right) \to x $$ 을 만족하는 시간의 시퀀스 $\left\{ t_{i} \right\} \subset \mathbb{R}$ 이 존재하면 $ x \in X$ 를 $x_{0}$ 의 **오메가 리미트 포인트** 라고 한다. $x_{0}$ 의 오메가 리미트 포인트의 집합을 $x_{0}$ 의 오</description>
    </item>
    
    <item>
      <title>초함수 컨볼루션 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/distribution-convolution-convergence-theorem/</link>
      <pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distribution-convolution-convergence-theorem/</guid>
      <description>$\phi$가 $\int_{\mathbb{R}^{n}}\phi(\mathbf{x})d\mathbf{x}=1$을 만족하는 테스트 함수라고 하자. 그리고 $\phi_{\epsilon}(\mathbf{x})=\epsilon^{-n}\phi(\epsilon^{-1}\mathbf{x})$라</description>
    </item>
    
    <item>
      <title>초함수 컨볼루션 보조정리</title>
      <link>https://freshrimpsushi.github.io/posts/distributional-convolution-lemma/</link>
      <pubDate>Thu, 26 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distributional-convolution-lemma/</guid>
      <description>$F$가 초함수, $\phi,\psi$가 테스트 함수라고 하자. 그러면 $F*\phi$는 실수 공간에서 정의된 함수이며 국소 적분 가능하다. 따라서 $F*\phi$에 대응되는 정칙 초함수 $T$가 존재한다. 이 때 다음의 식이 성립한다. $$ T_{F*\phi}(\psi)=F(\tilde{\phi}*\psi) $$ 여기서 $\tilde{\phi}(x)=\phi(-x)$이다.&amp;lsquo;초함</description>
    </item>
    
    <item>
      <title>균등 수렴과 연속성</title>
      <link>https://freshrimpsushi.github.io/posts/uniform-convegence-and-continuity/</link>
      <pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniform-convegence-and-continuity/</guid>
      <description>거리 공간 $E$위에서 함수열 $\left\{ f_{n} \right\}$이 $f$로 균등 수렴한다고 하자. $$ f_{n} \rightrightarrows f $$ 만약 각각의 $f_{n}$이 $x \in E$에서 연속이면 $f$도 $x$에서 연속이다. 즉 $$ \lim \limits_{t \to x }f_{n}(t)=f_{n}(x) \implies \lim \limits_{t \to x }f(t)=f(x) $$ 가 성립한다. 위 식의 우변을 다음과 같이 표현할 수도 있다. $$ \lim \limits_{t\to x}\lim \limits_{n\to \infty}f_{n}(t)=\lim \limits_{n\to \infty}\lim \limits_{t\to x}f_{n}(t) $$ 위 정리를 한마디로 표현하면 **&amp;lsqu</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 원핵 생물과 진핵 생물</title>
      <link>https://freshrimpsushi.github.io/posts/prokaryotes-and-eukaryotes/</link>
      <pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prokaryotes-and-eukaryotes/</guid>
      <description>&amp;lt;p&amp;lt; b=&amp;quot;&amp;quot;&amp;gt; * 실제 화학, 생물학적인 의미에 대해서는 깊게 다루지 않고 생명정보공학에 필요할 내용만을 간추린 포스트입니다. 생명공학에 대해서는 잘 모르니 많은 지적 부탁드립니다. 마찬가지의 이유로 질문에는 대답해드리기 어렵습니다. 1. 핵막이 없는 생물을 원핵 생물Prokaryotes 이라 한다.2. 핵막이 있는 핵으로 이루어진 생물을 진핵 생물E</description>
    </item>
    
    <item>
      <title>초함수의 컨볼루션과 실수에서 정의된 함수로서의 초함수</title>
      <link>https://freshrimpsushi.github.io/posts/1892/</link>
      <pubDate>Tue, 24 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1892/</guid>
      <description>초함수론의 목적은 나이브하게 정의된 디랙 델타 함수같은 것들을 수학적으로 엄밀하게 정의하는 것이다. 따라서 함수공간에서 정의된 초함수를 실수공간에서 정의되는 함수로 다룰 수 있게 해야 한다. 먼저 초함수의 미분, 평행이동 등이 어떻게 정의됐는지 생각해보자. 초함수는 정의역이 함수공간이라 미분 등을 기존의 개념대로 정의할 수 없기 때문에 해당 작용</description>
    </item>
    
    <item>
      <title>균등수렴할 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-uniform-convergence/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-uniform-convergence/</guid>
      <description>**정리 1 $E\subset \mathbb{R}$에서 정의된 함수열 $\left\{ f_{n} \right\}$이 주어졌다고 하자. 아래의 두 조건은 동치이다.$(a)$ $\left\{ f_{n} \right\}$이 $E$위에서 균등수렴한다.$(b)$ 모든 $\varepsilon&amp;gt;0$에 대해서 아래의 식을 만족시키는 자연수 $N$이 존재한다. $$ \quad m,n\ge N,\ x\in E \implies \left| f_{n}(x)-f_{m}(x) \right| \le \varepsilon</description>
    </item>
    
    <item>
      <title>줄리아에서 거리 행렬 계산하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-calculate-a-distance-matrix-in-julia/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-calculate-a-distance-matrix-in-julia/</guid>
      <description>using Distances coordinate = [2 3 4; 5 1 3; 1 7 5; 1 7 6; 2 4 3] pairwise(Euclidean(), coordinate; dims=1) pairwise(Euclidean(), coordinate; dims=2) 거리 행렬Distance Matrix 은 파티클 다이나믹스Particle Dynamics 및 무빙 에이전트Moving Agent 기반 시뮬레이션 등에 흔히 사용되나, 막상 찾아보면 딱 정리된 함수로는 없고 직접 계산하는 코드를 짜려면 막막한 게 보통이다.줄리아에서는 pairwise() 와 Distances 패키지의 Euclidean() 함수를 사용해서 위와 같이 손쉽</description>
    </item>
    
    <item>
      <title>초함수의 미분은 약한 수렴에 대해서 연속임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-differentiation-is-continuous-wrt-weak-convergence/</link>
      <pubDate>Sun, 22 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-differentiation-is-continuous-wrt-weak-convergence/</guid>
      <description>초함수의 미분은 약한 수렴에 대해서 연속이다. 다시 말해서 다음의 식이 성립한다. $$ T_{k} \to T \quad \text{weakly} \implies \partial ^{\alpha} T_{k}\to \partial ^{\alpha}T \quad \text{weakly} $$ 이때 $\alpha$는 임의의 멀티 인덱스이다.초함수의 미분이라는 오퍼레이터가 약한 수렴에 대해서 연속일 동치 조건 $$ \lim \limits_{n\to \infty} f(p_{n})=f(p),\quad \forall \left\{ p_{n} \right\} \text{s.t.} \lim_{n \to \infty}p_{n}=p $$ 을 만족한다는 말이다. 이 정리가 큰 의미를 가지는 이유는 함수의 점별 수렴, 균등</description>
    </item>
    
    <item>
      <title>디랙 델타 초함수로 수렴하는 초함수</title>
      <link>https://freshrimpsushi.github.io/posts/distribution-converging-to-dirac-delta/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distribution-converging-to-dirac-delta/</guid>
      <description>$f$가 $\int_{\mathbb{R}^{n}} f(\mathbf{x})d\mathbf{x}=1$를 만족하는 함수라고 하자. 그리고 $f_{\epsilon}(\mathbf{x})=\dfrac{ 1 }{ \epsilon^{n} }f\left( \dfrac{\mathbf{x}}{\epsilon} \right)$라고 하자. 그러면 $f$에 대응되는 정칙 초함수 $T_{\epsilon}=T_{f_{\epsilon}}$은 디랙 델타 초함수로 약한 수렴한다. 즉 $$ \lim \limits_{\epsilon \to 0} T_{\epsilon}=\delta $$ 증명 $\tilde{f}(</description>
    </item>
    
    <item>
      <title>푸앙카레 재귀 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-poincare-recurrence-theorem/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-poincare-recurrence-theorem/</guid>
      <description>푸앙카레 재귀 정리 1유클리드 공간에서 정의된 다차원 맵 $g : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 이 단사면서 연속이고 $D \subset \mathbb{R}^{n}$ 이 컴팩트 불변 집합, 다시 말해 $g(D) = D$ 라고 하자. 임의의 $\overline{x} \in D$ 의 임의의 근방을 $U$ 라고 하면 어떤 $n \in $ 에 대해 $g^{n} (x) \in U$ 가 되게끔 하는 $x \in U$ 가 존재한다.스테이트먼트는 단순한데, $D$ 가 컴팩트 불변 집합이면 그 안에서 $U$ 를 잡았을 때 $U$ 에서 잠깐은 벗어날 수</description>
    </item>
    
    <item>
      <title>머신 러닝에서 선형 회귀</title>
      <link>https://freshrimpsushi.github.io/posts/linear-regression-in-machine-learning/</link>
      <pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-regression-in-machine-learning/</guid>
      <description>머신 러닝에서 선형 회귀 란 주어진 작업에 대한 실제 함수를 가장 잘 근사하는 선형 함수를 찾는 알고리즘이다.어떤 트레이닝 샘플 $D=\left\{ (\mathbf{x}{1},y{1}),\dots,(\mathbf{x}{n},y{n }) \right\}$가 있다고 하자. 이때 인풋 $x_{i}$에 대해서 아웃풋 $y_{i}$를 주는 함수를 $f$라고 하자. $$ f(\mathbf{x}_{i})=y_{i}\quad (i=1,\dots,n) $$ 즉 $f$는 모든 데이터 $\mathbf{x}_{i}$에 대한 정답을 맞추는</description>
    </item>
    
    <item>
      <title>머신 러닝에서 벡터 행렬 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/vector-and-matrix-notation-in-machine-learning/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vector-and-matrix-notation-in-machine-learning/</guid>
      <description>선형대수를 잘 알지 못하거나, 잘 알아도 실제로 행렬 계산을 많이 해보지 않은 경우에 머신 러닝을 공부하면서 벡터와 행렬 표기법 때문에 힘들 수 있다. 해당 값이 스칼라인지, 벡터인지, 행렬인지 잘 구분해야하는데 실제로 손 계산을 해보면 익숙해지는데에 도움이 된다. 본 글의 표기법은 비숍의 &amp;lsquo;패턴 인식과 기계 학습1&amp;lsquo;을 참고했</description>
    </item>
    
    <item>
      <title>줄리아에서 빈 배열 만드는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-empty-array-in-julia/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-empty-array-in-julia/</guid>
      <description>empty = Array{Float64, 2}(undef, 3, 4) 위의 코드를 실행시키면 다음과 같이 빈 배열이 만들어진다. 간혹 1.76297e-315처럼 이상한 값이 들어가는 것처럼 보이기도 하지만 이는 0에 아주 가까운 값으로써 초기화엔 큰 문제가 없다.Array{X, Y}(undef, &amp;hellip;)는 자료형 X으로 Y차원 배열을 자료형에 해당하는 미정값으로 사이즈 &amp;hellip;만큼 채운 배</description>
    </item>
    
    <item>
      <title>스무스 함수에 대한 푸리에 역변환 정리</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-inversion-theorem-for-smooth-function/</link>
      <pubDate>Wed, 18 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-inversion-theorem-for-smooth-function/</guid>
      <description>$f$가 $\mathbb{R} $위에서 적분 가능하고 조각마다 스무스하다고 하자. 그러면 아래의 식이 성립한다. $$ \lim \limits_{r\to \infty} \frac{1}{2\pi} \int_{-r}^{r}e^{i\xi x} \hat{f}(\xi)d\xi= \frac{1}{2}\big[f(x-)+f(x+) \big],\quad \forall x\in \mathbb{R} $$ 이때 $f(x+)$, $f(x-)$는 각각 $f$의 $x$에서의 우극한, 좌극한이다.푸리에 역변환 정리는 컷오프 펑션을 사용하는 대신에 $f$에 대한 조건이 비교적 약했다. 위 정리는 푸리에 역변환 정리의 또 다른 형태이다. 결과로</description>
    </item>
    
    <item>
      <title>동역학에서의 리우빌 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-dynamics/</link>
      <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-dynamics/</guid>
      <description>복소해석에서의 리우빌 정리유클리드 공간 $\mathbb{R}^{n}$ 과 함수 $f : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 이 벡터 필드의 플로우 $\phi_t ( \cdot )$ 과 영역 $D_{0} \subset \mathbb{R}^{n}$ 에 대해 $D_{t} := \phi_{t} \left( D_{0} \right)$ 를 플로우에 따라 시간 $t$가 지나 옮겨진 영역, 그 볼륨을 $V(t) \equiv V \left( D_{t} \right)$ 와 같이 나타내자. 만약 $\nabla \cdot f = 0$ 면 모든 $D_{0} \subset \mathbb{R}^{n}$ 와 $t \in \mathbb{R}$ 에 대해 다음</description>
    </item>
    
    <item>
      <title>컨볼루션 놈 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/convolution-norm-converge-theorem/</link>
      <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convolution-norm-converge-theorem/</guid>
      <description>함수 $g \in L^{1}$가 유계이고 $\int_{\mathbb{R}}g(y)dy=1$을 만족한다고 하자. 만약 $f\in L^{2}$이고, $f$와 $g$의 컨볼루션 $f*g$가 모든 $x\in \mathbb{R}$에 대해서 잘 정의되면 $f*g_{\epsilon}$은 $f$로 놈 수렴한다. $$ \lim \limits_{\epsilon \to 0} \left| f*g_{\epsilon} -f \right| =0 \tag{1} $$ 이때 $g_{\epsilon}(y)=\frac{1}{\epsilon}g \left( \frac{y}{\epsilon} \r</description>
    </item>
    
    <item>
      <title>곡선 좌표계에서 스칼라 함수의 라플라시안</title>
      <link>https://freshrimpsushi.github.io/posts/laplacian-of-a-scalar-function-in-a-cuvilinear-coordinate-system/</link>
      <pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplacian-of-a-scalar-function-in-a-cuvilinear-coordinate-system/</guid>
      <description>곡선 좌표계에서 스칼라 함수 $f=f(q_{1},q_{2},q_{3})$의 라플라시안은 다음과 같다. $$ \nabla ^{2}f= \frac{1}{h_{1}h_{2}h_{3}}\left[\frac{ \partial }{ \partial q_{1} } \left( \frac{h_{2}h_{3}}{h_{1}} \frac{ \partial f}{ \partial q_{1}}\right)+\frac{ \partial }{ \partial q_{2} } \left( \frac{h_{1}h_{3}}{h_{2}} \frac{ \partial f}{ \partial q_{2}}\right)+\frac{ \partial }{ \partial q_{3} } \left( \frac{h_{1}h_{2}}{h_{3}} \frac{ \partial f}{ \partial q_{3}}\right) \right] $$ 각 좌표계별로 구체적인 식은 다음과 같다.**직교 좌표계:** $h_{1}=h_{2}=h_{3}=1 $$ $ \nabla ^2 f= \frac{ \partial^2 f}{ \partial x^2 }+\frac{ \partial^2 f}{ \partial y^2}+\frac{ \partial^2 f}{ \partial z^2} $$ **원통 좌표계:**</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 스칼라 함수의 라플라시안</title>
      <link>https://freshrimpsushi.github.io/posts/laplacian-of-scalar-function-in-cartesian-coordinate-system/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplacian-of-scalar-function-in-cartesian-coordinate-system/</guid>
      <description>3변수 스칼라 함수 $f=f(x,y,z)$의 라플라시안을 아래와 같이 $f$의 그래디언트의 다이버전스로 정의하고 $\nabla ^2$로 표기한다. $$ \nabla ^2 f:= \nabla \cdot(\nabla f)= \frac{ \partial^2 f}{ \partial x^2 }+\frac{ \partial^2 f}{ \partial y^2}+\frac{ \partial^2 f}{ \partial z^2} $$ 라플라시안이라는 이름은 프랑스 수학자 라플라스 에서 따온 것이다. $\nabla^{2}$라는 표현은 편의를 위해서 사용하는 것이다. 수학에서는 $</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability/</guid>
      <description>측도론으로 정의되는 확률 수렴**확률 수렴의 쉬운 정의1 확률변수 $X$ 와 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $X_{n}$ 이 $X$ 로 **확률 수렴** 한다고 말하고, $X_{n} \overset{P}{\to} X$ 와 같이 나타낸다. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left| X_{n} - X \right| &amp;lt; \varepsilon \right] = 1 $$ 확률 수렴의 조건은 수식 그대로 확률의 센스에서 수렴을 정의한 것으로, 쉽게 말해 $n$ 이 커지면 두 확률 변</description>
    </item>
    
    <item>
      <title>컨볼루션 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/convolution-converge-theorem/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convolution-converge-theorem/</guid>
      <description>함수 $g \in L^{1}$가 $\int_{\mathbb{R}}g(y)dy=1$를 만족하고 $\int_{-\infty}^{0}g(y)dy=\alpha$, $\int_{0}^{\infty}g(y)dy=\beta$, $\alpha+\beta=1$이라고 하자. 그리고 $f$가 $\mathbb{R}$위에서 조각마다 연속이라고 하자. 만약 $f$가 유계이거나 $g$가 임의의 구간 $[-a,a]$ 밖에서 $g=0$라고 하자. 즉, 합성곱 $f*g(x)$가 모</description>
    </item>
    
    <item>
      <title>자율 시스템의 보존량</title>
      <link>https://freshrimpsushi.github.io/posts/conservation-in-autonomous-system/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conservation-in-autonomous-system/</guid>
      <description>시스템의 보존량 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 주어진 시스템에 종속된 상수함수 $h : X \to \mathbb{R}$ 가 존재하면 이를 보존량 이라 한다.물리학적, 즉 역학적인(mechanical) 센스에 익숙하다면 보존량이라는 개념은 전혀 낯설지 않을 것이다. 가령 이상적인 상황에서 연직 방향</description>
    </item>
    
    <item>
      <title>줄리아로 감쇠 진동자 그래프 움짤 만드는 코드</title>
      <link>https://freshrimpsushi.github.io/posts/1876/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1876/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/gif&amp;rdquo; filename=&amp;ldquo;Damping_fps30.gif&amp;rdquo; height=&amp;ldquo;400&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99DBA3485FACCF792B&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;600&amp;rdquo;/&amp;gt;감쇠 조화 진동자의 경우 진동수와 감쇠 인자의 차이에 따라 과다감쇠, 임계감쇠, 미급감쇠로 나뉘어진다. 각각의 상황에서 진동자가 어떻게 움직이는지 시각적으로 볼 수 있다면 이를 이해하는데 큰 도움이 된다. 줄리아에서는 이런 그래프를 그리는 것을 넘어서 굉장히 쉽게 gi</description>
    </item>
    
    <item>
      <title>곡선의 도함수가 연속이면 길이를 잴 수 있는 곡선임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1870/</link>
      <pubDate>Thu, 12 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1870/</guid>
      <description>만약 $\gamma &amp;lsquo;$이 구간 $[a,b]$에서 연속이면, $\gamma$는 길이를 잴 수 있는 곡선이고 다음의 식이 성립한다. $$ \Lambda (\gamma) = \int _{a} ^{b} \left| \gamma&amp;rsquo;(t) \right| dt $$ 증명 **Part 1. $P=\left\{ a=x_{0},\dots,x_{n}=b \right\}$를 구간 $[a,b]$의 임의의 분할이라고 하자. $a\le x_{i-1}&amp;lt;x_{i}\le b$라고 하면 $$ \begin{align*} \left| \gamma(x_{i})-\gamma(x_{i-1}) \right| &amp;amp;= \left| \int_{x_{i-1}}^{x_{i}}\gamma &#39; (t)dt \right| \\ &amp;amp;\le \int_{x_{i-1}}^{x_{i}} \left| \gamma &#39; (t) \right|dt \end{align*} $$ 가 성립한다. 첫번째 줄은 미분적</description>
    </item>
    
    <item>
      <title>길이를 잴 수 있는 곡선</title>
      <link>https://freshrimpsushi.github.io/posts/rectifiable-curves/</link>
      <pubDate>Wed, 11 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rectifiable-curves/</guid>
      <description>연속 사상 $\gamma : [a,b] \to \mathbb{R}^{k}$를 $\mathbb{R}^{k}$에서의 곡선 $(\mathrm{curve})$라고 한다. 간단히 $\gamma$는 $[a,b]$위의 곡선이라고 말하기도 한다. 만약 $\gamma$가 일대일 함수이면, $\gamma$를 호$(\text{arc})$ 라고 한다. 만</description>
    </item>
    
    <item>
      <title>연속 사상 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-continuous-mapping-theorem/</link>
      <pubDate>Wed, 11 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-continuous-mapping-theorem/</guid>
      <description>연속 사상 정리의 측도론적 서술 1거리 공간 $\left( S , d \right)$ 와 $\left( S&#39; , d&#39; \right)$ 에 대해 $g : S \to S&#39;$ 가 $C_{g} \subset S$ 에서 연속이라고 하자. $S$ 의 확률 원소 $X$ 에 대해 $P \left( X \in C_{g} \right) = 1$ 이면 $X$ 로 수렴하는 확률 원소의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 에 대해 다음이 성립한다. $$ X_{n} \overset{D}{\to} X \implies g \left( X_{n} \right) \overset{D}{\to} g(X) \\ X_{n} \overset{P}{\to} X \implies g \left( X_{n} \right) \overset{P}{\to} g(X) \\ X_{n} \overset{\text{a.s.}}{\to} X \implies g \left( X_{n} \right) \overset{\text{a.s.}}{\to} g(X) $$ &amp;lt;p&amp;lt; b=&amp;quot;&amp;quot;&amp;gt; * $C_{g} \subset S$ 는 함수 $g$ 가 연속인 점</description>
    </item>
    
    <item>
      <title>벡터값함수의 적분</title>
      <link>https://freshrimpsushi.github.io/posts/integration-of-vector-valued-function/</link>
      <pubDate>Tue, 10 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integration-of-vector-valued-function/</guid>
      <description>$f_{1}$, $f_{2}$, $\dots$, $f_{k}$가 구간 $[a,b]$위에서 실수값을 갖는 함수라고 하자. 그리고 $\mathbf{f} : [a,b] \to \mathbb{R}^{k}$가 다음과 같다고 하자. $$ \mathbf{f}(x)=\left( f_{1}(x),\dots,f_{k}(x) \right),\quad x\in [a,b] $$ 만약 $\alpha$가 $[a,b]$에서 단조 증가 함수일때, $\mathbf{f} \in$$\mathscr{R}(\alpha)$라는 것은 각각의 $i=1,\dots, k$에 대해서 $f_{i}\in \math</description>
    </item>
    
    <item>
      <title>컨볼루션의 일반적인 정의</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-definition-of-convolution/</link>
      <pubDate>Sat, 31 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-definition-of-convolution/</guid>
      <description>어떤 적분 변환 $J$와 두 함수 $f$, $g$가 주어졌다고 하자. 아래의 조건을 만족하는 함수 $fg$를 $J$에 대한 $f$와 $g$의 컨볼루션이라 한다. $$ J(fg)=(Jf)(Jg) $$ 흔히 컨볼루션을 아래와 같은 꼴로 알고 있을 텐데 이는 푸리에 변환에 대한 컨볼루션이다. $$ (fg)(x) =\int _{-\infty} ^{\infty}f(y)g(x-y)dy $$ 라플라스 변환에 대한 컨볼루션은 아래와 같다. $$ (fg)(x) = \int_{0}^{x}f(x-y)g(y)dy $$ 멜린 변환에 대한 컨볼루션은 아</description>
    </item>
    
    <item>
      <title>2차원 자율 시스템에서 피리어딕 오빗의 부재성</title>
      <link>https://freshrimpsushi.github.io/posts/nonexistence-of-periodic-orbit-of-2-dimensional-autonomous-system/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/nonexistence-of-periodic-orbit-of-2-dimensional-autonomous-system/</guid>
      <description>보통 자율 시스템에서 피리어딕 오빗이 존재하는지에 대한 질문은 상당히 까다로운데, $1,2$차원 공간이라면 비교적 간단하게 그 부재성에 대해서 논할 수 있다. 공간 $X = \mathbb{R}$ 혹은 $X = \mathbb{R}^{2}$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ (1) $1$차원 자율 시스템에서는 피리어딕 오빗이 존재하지 않는다.</description>
    </item>
    
    <item>
      <title>적분 변환이란</title>
      <link>https://freshrimpsushi.github.io/posts/integral-transform/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integral-transform/</guid>
      <description>함수 $J$가 아래와 같이 임의의 함수를 적분을 통해 다른 함수로 매핑할 때 $J$를 적분 변환 이라 부른다. $$ (Jf) (s) = \int_{a}^{b} K(x,t)f(t)dt $$ 여기서 $K$를 $J$의 **커널** $(\mathrm{kernel})$이라 부른다. $Jf$를 다시 $f$로 매핑하는 함수가 존재하면 이를 $J^{-1}$로 표기하고 **역변환$(\mathrm{inve</description>
    </item>
    
    <item>
      <title>로젠블렛의 단층 퍼셉트론</title>
      <link>https://freshrimpsushi.github.io/posts/rosenblatts-perceptron/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rosenblatts-perceptron/</guid>
      <description>퍼셉트론이란? 퍼셉트론 은 1957년 로젠블렛에 의해 고안됐으며 최초의 지도 학습 모델이다. 위 그림1과 같이 단일 층으로 구성돼있고 활성화 함수 $\varphi$는 입력 데이터와 가중치의 곱을 $+1$ 혹은 $-1$로 반환한다. $-1$대신 $0$이라 두기도 하는데 본질적으로 차이는 없다. 간단한 예로 아래 그림과 같은 $m=2$인 2차원 데이터</description>
    </item>
    
    <item>
      <title>놈은 연속 사상임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-norm-is-continuous-mapping/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-norm-is-continuous-mapping/</guid>
      <description>$(X, | \cdot |)$가 놈 공간이라고 하자. 그러면 $\lim \limits_{k\to\infty} \mathbf{x}_{k}=\mathbf{x}$인 $X$의 수열 $\left\{ \mathbf{x}_{k} \right\}$에 대해서 아래의 식이 성립한다. $$ \lim \limits_{k \to\infty} | \mathbf{x}_{k}|= | \mathbf{x}| $$ 다시 말해 놈 $| \cdot |$는 연속 함수라는 뜻이다. 극한 기호는 연속 함수에 대해서 안밖을 자유롭게 드나들 수 있으므로 매우 좋다. 사실 놈으로부터 거리</description>
    </item>
    
    <item>
      <title>순서통계량</title>
      <link>https://freshrimpsushi.github.io/posts/order-statistics/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order-statistics/</guid>
      <description>**순서통계량의 확률밀도함수1 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 가 서포트 $\mathcal{S} =(a,b)$ 인 확률밀도함수 $f(x)$ 를 가지는 연속확률분포를 따른다고 하자. 이들을 크기 순으로 나열한 확률 변수들을 $Y_{1} &amp;lt; \cdots &amp;lt; Y_{n}$ 와 같이 나타내도록 하면 그 조인트, 마지널 확률밀도함수들은 다음과 같다.**[1] 조인트** : $$ g \left( y_{1} , \cdots , y_{n} \right) = \begin{cases} n! f (y_{1}) \cdots f (y_{n}) &amp;amp; a &amp;lt; y_{1} &amp;lt; \cdots &amp;lt; y_{n} &amp;lt; b \\ 0</description>
    </item>
    
    <item>
      <title>내적 공간에서 정의된 내적과 놈의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-inner-product-and-associated-norm/</link>
      <pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-inner-product-and-associated-norm/</guid>
      <description>내적 공간 $\left( H, \langle \cdot,\cdot \rangle \right)$가 주어졌다고 하자.그러면 자연스럽게 $\left| \cdot \right|:=\sqrt{\left\langle \cdot,\cdot \right\rangle }$와 같이 놈을 정의할 수 있고, $x,y \in H$에 대해서 아래의 성질들이 성립한다.(a) **코시-슈바르츠 부등식: $$ \left| \langle x,y \rangle \right| \le | x| |y| $$ **(b) 평행사변형 법칙: $$ | x+y | ^{2} + | x-y| ^{2} = 2 \left( | x| ^{2}+ | y | ^{2} \right) $$ **(c) The polarization identity in a complex vector space: $$ \langle x,y\rangle = \frac{1}{4} \Big( | x+y|^{2} - | x-y|</description>
    </item>
    
    <item>
      <title>내적 공간에서 코시-슈바르츠 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-schwarz-inequality/</link>
      <pubDate>Mon, 26 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-schwarz-inequality/</guid>
      <description>$(H, \langle \cdot ,\cdot \rangle)$가 내적 공간이라고 하자. 그러면 아래의 부등식이 성립하고 이를 코시-슈바르츠 부등식 이라 부른다. $$ \left| \langle x,y \rangle \right| \le \langle x,x \rangle^{1/2} \langle y,y \rangle ^{1/2},\quad \forall x,y \in H $$ 내적으로부터 놈을 정의할 수 있으므로 다음의 식으로 표현할 수도 있다. $$ \left| \left\langle x, y \right\rangle \right| \le \left| x \right| \left| y \right|,\quad \forall x,y\in H $$ 증명 Case 1. $x=0$ 혹은 $y=0$ 일반성을 잃지 않고 $x=0$이라고 하자.</description>
    </item>
    
    <item>
      <title>벤딕슨 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/bendixsons-criterion/</link>
      <pubDate>Mon, 26 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bendixsons-criterion/</guid>
      <description>*벤딕슨 판정법 공간 $\mathbb{R}^{2}$ 와 함수 $f,g \in C^{1} \left( \mathbb{R}^{2} \right)$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x,y) \\ y&#39; = g(x,y) $$ 단순 연결 영역 $D \subset \mathbb{R}^{2}$ 에서 $$ {{ \partial f } \over { \partial x }} + {{ \partial g } \over { \partial y }} \ne 0 $$ 의 부호가 바뀌지 않는다면, 주어진 $2$차 벡터 필드는 $D$ 내부에서 닫힌 오빗을 갖지 않는다. $D \subset \mathbb{R}^{2}$ 이 단순 연결 영역이라는 것은 $D$ 의 테두</description>
    </item>
    
    <item>
      <title>내적 공간이란</title>
      <link>https://freshrimpsushi.github.io/posts/inner-product-space/</link>
      <pubDate>Sun, 25 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inner-product-space/</guid>
      <description>$H$를 벡터 공간이라고 하자. $x,y,z \in H$ 와 $\alpha, \beta \in \mathbb{C}$에 대해서 다음의 조건을 만족하는 함수 $$ \langle \cdot , \cdot \rangle \ : \ H \times H \to \mathbb{C} $$ 를 내적 이라고 정의하고 $\left( H, \langle \cdot ,\cdot \rangle \right)$를 내적공간 이라 한다. $$ \leqalignno{ &amp;amp;\langle \alpha x + \beta y ,z \rangle =\alpha \langle x,z\rangle + \beta \langle y,z\rangle &amp;amp; (1) \\ &amp;amp;\langle x,y \rangle = \overline{ \langle y,x \rangle} &amp;amp; (2) \\ &amp;amp;\langle x,x \rangle \ge 0 &amp;amp; (3) \\ &amp;amp; \langle x,x \rangle = 0\iff x=0 &amp;amp; (4) } $$ $(1</description>
    </item>
    
    <item>
      <title>안티리니어 컨쥬게이트 리니어</title>
      <link>https://freshrimpsushi.github.io/posts/antilinear-conjugate-linear/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/antilinear-conjugate-linear/</guid>
      <description>집합 $X$와 그 위에서 정의된 함수 $ f \ : X \to \mathbb{C}$가 주어졌다고 하자. $x,y\in X$, $a,b \in \mathbb{C}$에 대해서 $f$가 아래의 식을 만족하면 $f$를 안티리니어$(\mathrm{antilinear})$ 혹은 컨쥬게이트 리니어$(\mathrm{conjugate-linear})$ 라고 한다. $$</description>
    </item>
    
    <item>
      <title>표본 분산을 n-1으로 나누는 이유 Why Sample Variance is Divided by n-1</title>
      <link>https://freshrimpsushi.github.io/posts/1747/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1747/</guid>
      <description>$X_{i} \sim \left( \mu , \sigma^{2} \right)$ 이라고 하면 표본 분산 $S^{2}$ 는 다음과 같다. $$ S^{2} := {{1} \over {n-1}} \sum_{i=1}^{n} \left( X_{i} - \overline{X} \right)^{2} $$ 알다시피 표본 평균과 달리 표본 분산은 편차의 제곱을 모두 더한 후 표본 크기인 $n$ 이 아니라 $n-1$ 로 나눈다. 당연히 이를 이상하게 느껴야한다고는 말하지 않겠지만, 수식에 대한 보편적인 감성이 있다면 $n$ 개를 더하고 $n-1$ 로 나누는 것에서 강렬한 띠꺼움을 느끼는 것 역시 정상이다</description>
    </item>
    
    <item>
      <title>내적 공간 놈 공간 거리 공간의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/1840/</link>
      <pubDate>Fri, 23 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1840/</guid>
      <description>내적 공간 $\left( H, \langle\cdot, \cdot\rangle \right)$가 주어졌다고 하자. 그러면 내적으로부터 아래와 같이 자연스럽게 놈을 정의할 수 있다. $$ |x| := \sqrt{ \langle x, x\rangle},\quad x\in H \tag{1} $$ 따라서 내적 공간이면 놈 공간이다. 계속해서 이렇게 정의된 놈으로부터 거리를 정의할 수 있다. $$ d(x,y):=|x -y | =\sqrt{ \langle x-y, x-y \rangle},\quad x,y\in H \tag{2} $$ 따라서 내적 공간이면 놈 공간이고 거리 공간이다. 몇몇의 교재에서 거리 공간이</description>
    </item>
    
    <item>
      <title>불변 매니폴드의 안정성</title>
      <link>https://freshrimpsushi.github.io/posts/stability-of-manifold/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stability-of-manifold/</guid>
      <description>**벡터 필드의 매니폴드1 공간 $\mathbb{R}^{n}$ 와 함수 $f : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 고정점 $\overline{x}$ 이 주어져 있다고 할 때, 선형화 행렬 $A := D f \left( \overline{x} \right)$ 의 각 고유값 $\lambda$ 들에 대응되는 고유벡터 $e$ 들을 실수부 $\Re (\lambda)$ 에 따라 다음과 분류하고, 그 생성 $\text{span}$ 을 다음과 같이 나타내자. $$ E^{s} := \text{span} \left\{ e :</description>
    </item>
    
    <item>
      <title>컴퓨터 비전이란</title>
      <link>https://freshrimpsushi.github.io/posts/computer-vision/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/computer-vision/</guid>
      <description>컴퓨터 비전 이란 주로 사람의 시각에 해당하는 기능을 컴퓨터가 수행할 수 있도록 하는 연구 분야이며 이미지나 영상을 다룬다. 컴퓨터 비전을 전문적으로 다루는 컨퍼런스로는 ICCV(International Conference on Computer Vision), ECCV(European Conference on Computer Vision), CVPR(Conference on Computer Vision and Pattern Recognition)등이 있다. 컴퓨터 비전에서 주로 다루는 문제는 아래의 사진과 같이 크게 3가지로 분류할 수 있다.&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/png&amp;rdquo;</description>
    </item>
    
    <item>
      <title>딥러닝에서 연속 학습이란</title>
      <link>https://freshrimpsushi.github.io/posts/continual-learning-lifelong-learning-incremental-learning/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continual-learning-lifelong-learning-incremental-learning/</guid>
      <description>딥러닝에서 연속 학습이란 평생 학습, 점진적 학습과 같은 말로서 인공 신경망이 순차적으로 여러 작업을 학습하는 것을 말한다. 인간의 경우 새로운 지식을 학습한다고 해서 기존의 지식을 잊어버리지 않는다. 물론 시간이 지나면 기존의 지식을 잊기도 하지만 이 원인이 새로운 지식을 학습했기 때문은 아니다. 하지만 인공 신경망의 경우 하나의 작업을 충분히 학습한</description>
    </item>
    
    <item>
      <title>멜린 변환의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-mellin-transform/</link>
      <pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-mellin-transform/</guid>
      <description>멜린 변환과 멀티플리케이티브 컨볼루션은 다음과 같은 식을 만족한다. $$ \mathcal{M}(f\times g) = \left( \mathcal{M}f \right) \left( \mathcal{M}g \right) $$ 정의를 따라서 변수를 잘 분리해주면 어렵지 않게 보일 수 있다. 증명 $$ \begin{align*} \mathcal{M}(f\times g)(s) &amp;amp;= \int _{0} ^{\infty} x^{s-1} (f\times g)(x)dx \\ &amp;amp;= \int _{0} ^{\infty} x^{s-1} (f\times g)(x)dx \\ &amp;amp;= \int _{0} ^{\infty} x^{s-1} \left( \int _{0}^{\infty}f(y)g \left( \frac{x}{y} \right)\frac{dy}{y} \right)dx \\ &amp;amp;= \int _{0} ^{\infty} \int _{0}^{\infty}x^{s-1}f(y)g \left( \frac{x}{y} \right)\frac{dy}{y} dx \\ &amp;amp;= \int _{0} ^{\infty} \int _{0}^{\infty}y^{s-1}z^{s-1}f(y)g (z)dydz \\ &amp;amp;= \int _{0} ^{\infty} y^{s-1}f(y)dy \int_{0}^{\infty} z^{s-1}g (z)dz \\ &amp;amp;= \mathcal{M}f(s) \mathcal{M}g(s) \end{align*} $$ ■</description>
    </item>
    
    <item>
      <title>불편추정량</title>
      <link>https://freshrimpsushi.github.io/posts/unbiased-estimator/</link>
      <pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unbiased-estimator/</guid>
      <description>**불편성1 $\theta$ 의 추정량 $T$ 가 다음을 만족하면 $T$ 를 $\mu$ 의 불편추정량 이라고 한다. $$ E T = \theta $$ 불편성이란 편의를 가지지 않는 성질을 말한다. 가령 $X_{i} \sim \left( \mu , \sigma^{2} \right)$ 라고 할 때 $\mu$ 의 추정량으로써 표본평균 $\displaystyle \overline{X} = {{ 1 } \over { n }} \sum_{i} X_{i} $ 를 사용한다면 $\displaystyle E \overline{X} = \mu$ 이므로 $\overline{X}$ 는 $\mu$ 의 불편추정량이 된다. 이는 언뜻 당연해보이지만 추정량이 모수를 정확하게 찍어</description>
    </item>
    
    <item>
      <title>곱셈적 합성곱</title>
      <link>https://freshrimpsushi.github.io/posts/multiplicative-convolution/</link>
      <pubDate>Mon, 19 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplicative-convolution/</guid>
      <description>$\mathbb{R}$에서 정의된 두 함수 $f$, $g$에 대해서 $f \times g$를 아래와 같이 정의하고 이를 곱셈적 합성곱이라 부른다. $$ (f \times g) (y) := \int _{0}^{\infty} f(x)g \left(\frac{y}{x} \right)\frac{dx}{x} $$ 컨볼루션에 비하면 메이저한 정의는 아니다. 이를 컨볼루션이라 이름 붙인 까닭은 컨볼루션과 푸리에 변환의 관계와 연관이 있을 것이라 예상할 수 있다. 아래의 식은 푸리에 변환의 성질 중 하나이다.</description>
    </item>
    
    <item>
      <title>동역학에서의 불변 집합</title>
      <link>https://freshrimpsushi.github.io/posts/invariant-set-in-dynamics/</link>
      <pubDate>Sun, 18 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/invariant-set-in-dynamics/</guid>
      <description>**불변 집합1 공간 $X$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $S \subset X$ 라고 하자.V. $\forall x_{0} \in S$ 가 모든 $t \in \mathbb{R}$ 에 대해 다음을 만족하면 벡터 필드 $x&#39;=f(x)$ 하에서의 **불변 집합** 이라 한다. $$ x(t,x_{0}) \in S $$ **M.** $\forall x_{0} \in S$ 가 모든 $n \in \mathbb{Z}$ 에 대해 다음을 만족하면 맵 $x \mapsto g(x)$ 하에서의 **불변 집합** 이라 한다. $$</description>
    </item>
    
    <item>
      <title>불연속성의 분류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-discontinuities/</link>
      <pubDate>Sun, 18 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-discontinuities/</guid>
      <description>**Discontinuous 거리 공간 $X$에서 정의된 함수 $f :X \to \mathbb{R}$이 주어졌다고 하자. 만약 $f$가 $x\in X$에서 연속이 아니면, $f$는 $x$에서 불연속하다 고 하거나 $x$에서 불연속성을 갖는다 고 한다. **Discontinuity of the First Kind, Simple Continuity $(a,b)$에서 정의된 함수 $f$가 주어졌다고 하자. 만약 $f$가 $x\in (a,b)$에서 불연속하고, $x$에서</description>
    </item>
    
    <item>
      <title>해석학에서 엄밀하게 정의되는 좌극한과 우극한</title>
      <link>https://freshrimpsushi.github.io/posts/left-hand-limits-right-hands-limits/</link>
      <pubDate>Sat, 17 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/left-hand-limits-right-hands-limits/</guid>
      <description>거리 공간 $X$에서 정의된 함수 $f :X \to \mathbb{R}$이 주어졌다고 하자. 만약 $f$가 $x\in X$에서 연속이 아니면, $f$는 $x$에서 불연속하다 고 하거나 $x$에서 불연속성을 갖는다 고 한다. 불연속성에 대해 자세히 말하기 위해 아래와 같이 좌극한, 우극한이라는 개념을 정의한다. 주의해야할 점은 좌극한, 우극한은 불연속점에서 정</description>
    </item>
    
    <item>
      <title>도함수와 함수의 증가감소의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-derivative-and-increasingdecreasing-of-function/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-derivative-and-increasingdecreasing-of-function/</guid>
      <description>함수 $f$가 $(a,b)$에거 미분 가능하다고 하자.$(a)$ 만약 모든 $x\in (a,b)$에 대해서 $f&#39;(x) \ge 0$이면, $f$는 단조롭게 증가한다.$(b)$ 만약 모든 $x\in (a,b)$에 대해서 $f&#39;(x)=0$이면, $f$는 상수함수이다.$(c)$ 만약 모든 $x\in (a,b)$에 대해서 $f&#39;(x) \le 0$이면, $f$는 단조롭게 감소한다. 증명</description>
    </item>
    
    <item>
      <title>편의-분산 트레이드 오프</title>
      <link>https://freshrimpsushi.github.io/posts/bias-variance-trade-off/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bias-variance-trade-off/</guid>
      <description>$$ \text{MSE} \left( \widehat{\theta} \right) = \text{Var} \widehat{\theta} + \left( \text{Bias} \widehat{\theta} \right)^{2} $$ 평균제곱오차 $\text{MSE}$ 는 통계 모형의 평가나 머신 러닝에서의 손실 함수로써 즐겨쓰이는 척도로써, 특히 편의와 분산에 대한 트레이드 오프로 나타난다.통계학도에게 있어서 편의를 다루는 것은 다소 어색할지 모르겠다. 적절한 확률 분포를 가정하고 그에 따른 수학적 이론을 토대로 데이터를 다루는 입장에서 분산은 손에 잡힐듯이 친숙</description>
    </item>
    
    <item>
      <title>단조함수 증가함수 감소함수</title>
      <link>https://freshrimpsushi.github.io/posts/monotone-function/</link>
      <pubDate>Thu, 15 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monotone-function/</guid>
      <description>함수 $f:[a,b] \rightarrow \mathbb{R}$가 주어졌다고 하자. $x_1$, $x_2$ $\in [a,b]$에 대해서 $x_1&amp;lt;x_2 \ \Rightarrow f(x_1) \le f(x_2)$이면 $f$는** 단조롭게 증가** 한다고 말한다. 반대로 $x_1 &amp;lt;x_2 \ \Rightarrow f(x_1) \ge f(x_2)$이면 $f$는 **단조롭게 감소** 한다고 말한다.다시 말하자면 단조롭게 증가한다는 말은 좌표평면에서 오른쪽으로 갈 수록 함숫값이 같을지언</description>
    </item>
    
    <item>
      <title>해석학에서 평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem-in-analysis/</link>
      <pubDate>Thu, 15 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem-in-analysis/</guid>
      <description>**일반화된 평균값 정리Generalized Mean Value Theorem 두 함수 $f$, $g$가 구간 $[a,b]$에서 연속이고, $(a,b)$에서 미분 가능한 실수 함수라고 하자. 그러면 아래의 식을 만족하는 $x \in (a,b)$가 존재한다. $$ [f(b)-f(a)]g&#39;(x)=[g(b)-g(a)]f&#39;(x) $$ 양 끝점 $a$, $b$에서는 미분가능성이 필요하지 않음에 주의하라.$g(x)=x$라고 두면 위 정리의 따름 정리로</description>
    </item>
    
    <item>
      <title>극대의 정의와 미분 계수</title>
      <link>https://freshrimpsushi.github.io/posts/local-maximumminimum/</link>
      <pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/local-maximumminimum/</guid>
      <description>**정의 거리 공간에서 정의된 함수 $f : X \rightarrow \mathbb{R}$가 있다고 하자. 아래의 조건을 만족하는 양수 $\delta &amp;gt;0$가 존재하면 $f$는 점 $p \in X$에서 극대를 가진다 고 한다. $$ \forall q\in X,\quad f(q)\le f(p)\ \mathrm{with}\ d(p,q)&amp;lt;\delta $$ 말로 풀어서 설명하면 아래와 같다:$p$를 기준으로 거리 $\delta$만큼 떨어진 곳 안에서만큼은 $f(p)$가 제일 크다면, $</description>
    </item>
    
    <item>
      <title>랴푸노프 함수</title>
      <link>https://freshrimpsushi.github.io/posts/liapunov-function/</link>
      <pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/liapunov-function/</guid>
      <description>**랴푸노프 함수의 정의1 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 한 점 $x_{0} \in X$ 이 주어져 있다고 할 때, $x_{0}$ 의 네이버후드 $\mathcal{N} \left( x_{0} \right)$ 에서 정의된 스칼라 함수 $V \in C^{1} \left( \mathcal{N} (x_{0}) , \mathbb{R} \right)$ 가 다음의 조건을 만족하면 **랴푸노프 함수** 라고 한다.**(i)** $V(x_{0}) = 0$ 이고</description>
    </item>
    
    <item>
      <title>미분의 연쇄 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-chain-rule-for-differentiation/</link>
      <pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-chain-rule-for-differentiation/</guid>
      <description>$f :[a,b] \to \mathbb{R}$가 $x\in [a,b]$에서 미분가능하다고 하자. $g : f([a,b])\to \mathbb{R}$가 $f (x)\in f([a,b])$에서 미분가능하다고 하자. 그러면 $$ h(t)=g\left( f(t) \right)\quad (a\le t \le b) $$ 일 때 $h$는 $x$에서 미분 가능하고 그 값은 아래와 같다. $$ h&#39;(x)=g&#39;(f(x))f&#39;(x) $$ 합성 함수기호를 사용하면 다음과 같다. $$ ( g \circ f)&#39;(x)=g&#39;(f(x))f&#39;(x) $$ 이때 $f&#39;(x)$를 속미분이</description>
    </item>
    
    <item>
      <title>미분가능한 함수의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-differentiable-funtion/</link>
      <pubDate>Tue, 13 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-differentiable-funtion/</guid>
      <description>구간 $[a,b]$에서 정의된 두 함수 $f$, $g$가 $x\in [a,b]$에서 미분가능하다고 하자. 그러면 $f+g$, $fg$, $f/g$도 $x$에서 미분가능하고 아래의 식이 성립한다. $$ \leqalignno{ (f+g)&#39;(x) &amp;amp;=f&#39;(x)+g&#39;(x) &amp;amp;(a) \\ (fg)&#39;(x) &amp;amp;=f&#39;(x)g(x)+f(x)g&#39;(x) &amp;amp; (b) \\ \left( \frac{f}{g} \right)&#39;(x)&amp;amp;=\frac{f&#39;(x)g(x)-f(x)g&#39;(x)}{g^{2}(x)} &amp;amp;(c) } $$ 단 $(c)$는 $g(x)\ne 0$일 때 성립한다. 증명 $(a)$ 미분의 정의와 거리 공간에서 함수의 극한의 성질에 의해서 자명하다. $$ \begin{align*} (f+g)&#39;(x) &amp;amp;=\lim \limits_{t \to x} \frac{(f(x)+g(x))-(f(t)+g(t))}{x-t} \\ &amp;amp;=\lim \limits_{t</description>
    </item>
    
    <item>
      <title>미분가능하면 연속임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-differentiable-function-is-continuous/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-differentiable-function-is-continuous/</guid>
      <description>$[a,b]$에서 정의된 함수 $f$가 주어졌다고 하자. 만약 $f$가 $p\in [a,b]$에서 미분가능하면, $f$는 $p$에서 연속이다.※ 역인 &amp;lsquo;연속이면 미분가능하다&amp;rsquo;는 성립하지 않음을 주의하자.라떼는 이 결과를 간미연 (간 단히 말해서 미 분가능하면 연 속이다)으로 줄이는 드립이 있었지만 요즘 학생들은 간미</description>
    </item>
    
    <item>
      <title>수리통계학에서의 편의</title>
      <link>https://freshrimpsushi.github.io/posts/bias-in-mathematical-statistics/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bias-in-mathematical-statistics/</guid>
      <description>모수 $\theta$ 에 대한 추정량 $\widehat{\theta}$ 에 대해 다음과 같이 정의된 $\text{Bias}$ 를 편의 라고 한다. $$ \text{Bias} ( \theta ) = E(\widehat{\theta}) - \theta $$ Bias는 편의 또는 편향으로 순화되지만, 역시 가장 많이 쓰이는 말은 발음 그대로 읽은 [바이어스]다. 한국어에서 편의는 Convenience인 경우가 압도적으로 많고 수식적으로나 실제 쓰임새로나 &amp;lsquo;편향&amp;rsquo;으로 순화하는</description>
    </item>
    
    <item>
      <title>조절 초함수</title>
      <link>https://freshrimpsushi.github.io/posts/tempered-distribution/</link>
      <pubDate>Sun, 11 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tempered-distribution/</guid>
      <description>슈바르츠 공간의 연속인 선형 범함수 $T:\mathcal{S}(\mathbb{R}^{n}) \to \mathbb{C}$를 조절 초함수 라고 한다. 다시 말해 조절 초함수는 슈바르츠 공간의 듀얼 스페이스의 원소이다. 따라서 $$ T \in \mathcal{S}^{ * } $$ 와 같이 표기하고 $\mathcal{S}^{ * }$를 조절 초함수 공간 $(\mathrm{space\ of\ tempered\ distribution})$이라 부른다.조절 초함수 $T$는 선형 이므로 $$ T(a\phi + b \psi) = aT(\phi) + bT(\psi)\quad \left( \phi,\psi \in \mathcal{S}(\mathbb{R}^{n}),\ a,b\in\mathbb{C} \right)</description>
    </item>
    
    <item>
      <title>자율 시스템에서 고정점의 분류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-fixed-point/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-fixed-point/</guid>
      <description>**하이퍼볼릭 고정점1과 일립틱 고정점2 공간 $X$ 와 함수 $f \in C^{1}(X,X)$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ $\overline{x}$ 가 이 자율 시스템의 한 고정점이라 하고 $D f \left( \overline{x} \right)$ 의 아이겐 밸류들을 $\lambda_{1} , \cdots , \lambda_{m}$ 이라 하자.**1. Hyperbolic** : $D f \left( \overline{x} \right)$ 의 모든 아이겐 밸류들의 실수부가 $0$ 이 아니면 $\overline{x}$ 가 하이퍼볼릭하다고 말한다. $$ \Re \left( \lambda_{1}</description>
    </item>
    
    <item>
      <title>푸리에 급수의 복소 표현</title>
      <link>https://freshrimpsushi.github.io/posts/complex-representation-of-fourier-series/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complex-representation-of-fourier-series/</guid>
      <description>구간 $[-L,\ L)$에서 정의된 함수 $f$를 푸리에 급수 꼴로 나타내면 다음과 같다. $$ \begin{align*} f(t)&amp;amp;=\dfrac{a_0}{2}+\sum \limits_{n=1}^{\infty} \left( a_n \cos \dfrac{n\pi t}{L} + b_n\sin\dfrac{n\pi t }{L} \right) \tag{1} \\ \text{where}\quad a_0 &amp;amp;=\dfrac{1}{L}\int_{-L}^{L}f(t)dt \\ a_n &amp;amp;= \dfrac{1}{L}\int_{-L}^{L} f(t)\cos\dfrac{n\pi t}{L} dt \\ b_n&amp;amp;=\dfrac{1}{L}\int_{-L}^{L}f(t)\sin\dfrac{n\pi t}{L}dt \end{align*} $$ 위 식은 삼각함수로 표현된 푸리에 급수이다. 이를 복소 지수 함수로 표현하면 다음과 같다. $$ \begin{align*} f(t) &amp;amp;=\sum \limits_{n=-\infty}^{\infty} c_n e^{i\frac{n\pi t}{L}} \\ \text{where} \quad c_n &amp;amp;= \dfrac{1}{2L}\int_{-L}^{L}f(t)e^{-i\frac{n \pi t}{L} }dt \end{align*} $$ 위와 같은 꼴의 푸리에 급수를 **복소 푸리에 급수$(\math</description>
    </item>
    
    <item>
      <title>머신러닝에서 많이 쓰이는 데이터 셋</title>
      <link>https://freshrimpsushi.github.io/posts/popular-datasets-in-machine-learning/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/popular-datasets-in-machine-learning/</guid>
      <description>**1. MNIST 머신 러닝을 공부할 때 가장 먼저 접할 데이터 셋이다. [엠니스트]라고 읽으며 $28\times 28$ 크기의 손글씨 사진 데이터이다. 학습 데이터 60,000개, 테스트 데이터 10,000개가 포함되어 있다1**2. CIFAR-10, CIFAR-100 CIFAR-10은 [싸이파-텐]이라고 읽으며, 10가지 카테고리 대한 $32\times 32$ 크기의 컬러 이미지 60,000장을 포함하는 데이터 셋</description>
    </item>
    
    <item>
      <title>수리통계학에서의 랜덤 샘플</title>
      <link>https://freshrimpsushi.github.io/posts/random-sample/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-sample/</guid>
      <description>**랜덤 샘플1 1. 확률 변수 $X$ 가 실제로 뽑힌 것을 실현Realization 이라 하고 보통 소문자 $x$ 로 나타낸다.2. 확률 변수 $X$ 와 같은 확률 분포에서 샘플 사이즈Sample Size $n$ 만큼 얻어낸 확률 변수들을 샘플Sample 이라 하고 다음과 같이 나타낸다. $$ X_{1} , X_{2} , \cdots , X_{n} $$ **3.** 확률 변수 $X_{1} , \cdots , X_{n}$ 이 iid면 사이즈 $n$ 의 **랜덤 샘플** 이</description>
    </item>
    
    <item>
      <title>머신러닝에서 레귤라이제이션이란</title>
      <link>https://freshrimpsushi.github.io/posts/regularization-in-machine-learning/</link>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regularization-in-machine-learning/</guid>
      <description>트레이닝 로스가 아닌 테스트 로스를 줄이기 위해 알고리즘을 수정하는 모든 방법을 레귤라이제이션 이라 한다1Goodfellow defines regularization as &amp;ldquo;any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.&amp;ldquo;즉, 오버피팅을 막기 위한 모든 방법을 묶어서 레귤라이제이션이라 한다. 따라서 딥러닝 교재에서 많이 소개되는 드롭아웃도 레귤라이제이</description>
    </item>
    
    <item>
      <title>곡선 좌표계에서 좌표 변환과 야코비안</title>
      <link>https://freshrimpsushi.github.io/posts/the-coordinate-transform-and-jacobian/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-coordinate-transform-and-jacobian/</guid>
      <description>3차원 데카르트 좌표계에서의 부피는 임의의 곡선 좌표계에 대해서 다음과 같이 나타난다. $$ dxdydz =\begin{vmatrix} \frac{ \partial x}{ \partial q_{1}} &amp;amp; \frac{ \partial y}{ \partial q_{1}} &amp;amp; \frac{ \partial z}{ \partial q_{1} } \\ \frac{ \partial x}{ \partial q_{2}} &amp;amp; \frac{ \partial y}{ \partial q_{2}} &amp;amp; \frac{ \partial z}{ \partial q_{2} } \\ \frac{ \partial x}{ \partial q_{3}} &amp;amp; \frac{ \partial y}{ \partial q_{3}} &amp;amp; \frac{ \partial z}{ \partial q_{3} } \end{vmatrix} dq_{1}dq_{2}dq_{3} = \begin{vmatrix}\frac{ \partial x}{ \partial q_{1}} &amp;amp; \frac{ \partial x}{ \partial q_{2}} &amp;amp; \frac{ \partial x}{ \partial q_{3}} \\ \frac{ \partial y}{ \partial q_{1}} &amp;amp; \frac{ \partial y}{ \partial q_{2}} &amp;amp; \frac{ \partial y}{ \partial q_{3}} \\ \frac{ \partial z}{ \partial q_{1}} &amp;amp; \frac{ \partial z}{ \partial q_{2}} &amp;amp; \frac{ \partial</description>
    </item>
    
    <item>
      <title>비선형 시스템의 선형화</title>
      <link>https://freshrimpsushi.github.io/posts/linearization-of-nonlinear-system/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearization-of-nonlinear-system/</guid>
      <description>공간 $\left( X, \left| \cdot \right| \right)$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 고정점 $\overline{x}$ 이 주어져 있다고 할 때, 그 근방의 안정성을 파악하기 위해서는 선형화라는 방법이 필수적으로 동원된다. 시스템을 전체적으로 보았을 땐 고정점 근처에서는 선형으로 보고 분석하겠다는 것이다. 이는 다차원</description>
    </item>
    
    <item>
      <title>슈바르츠 공간과 슈바르츠 함수</title>
      <link>https://freshrimpsushi.github.io/posts/schwartz-space-and-schwartz-fuction/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schwartz-space-and-schwartz-fuction/</guid>
      <description>아래의 두 조건을 만족하는 함수 $\phi : \mathbb{R}^{n} \to \mathbb{C}$들의 집합을 슈바르츠 공간 이라 하고 $\mathcal{S}(\mathbb{R}^{n})$로 표기한다. 슈바르츠 공간의 원소 $\phi$를 슈바르츠 함수 라 한다.$(a)$ $\phi \in $ $C^{\infty}$$(b)$ 모든 멀티 인덱스 $\alpha$, $\beta$에 대해서 $\left| \mathbf{x}^{\beta}D^{\alpha}\phi(\mathbf{x}) \right| &amp;lt;\infty $이때 $\beta=(\beta_{1}, \beta_{2},</description>
    </item>
    
    <item>
      <title>3차원 공간의 곡선 좌표계</title>
      <link>https://freshrimpsushi.github.io/posts/cuvilinear-coordinates-system-for-3-dimensional-euclidiean-space/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cuvilinear-coordinates-system-for-3-dimensional-euclidiean-space/</guid>
      <description>3차원 공간에서 위치를 표현하는 가장 일반적인 방법은 데카르트 좌표계이다. 데카르트에 의해서 고안되었기 때문에 붙은 이름이며 직교 좌표계라고도 많이 부른다. 하지만 특정한 상황에서는 데카르트 좌표계로 위치를 표현하기 어려울 수 있다. 예를 들어 2차원 평면에서 회전운동 하는 물체가 있다고 하자. 그러면 이 물체의 위치는 $(x,y)$로 표현하는</description>
    </item>
    
    <item>
      <title>곡선 좌표계에서 스케일 팩터</title>
      <link>https://freshrimpsushi.github.io/posts/scale-factor-in-cuvilinear-coordinates-system/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scale-factor-in-cuvilinear-coordinates-system/</guid>
      <description>곡선 좌표계에서 스케일 팩터는 각 성분이 길이 차원을 갖도록 곱해주는 요소이다. 예를 들어 극 좌표계는 $(r,\theta)$로 표현되는데 $\theta$가 변할 때 마다 좌표가 움직이는 거리는 호의 길이인 $l=r\theta$이다. 여기서 $r$과 같은 것들을 스케일 팩터라고 부른다. 임의의 좌표계의 변수가 $(q_{1},q_{2}</description>
    </item>
    
    <item>
      <title>약한 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/weak-derivatives/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weak-derivatives/</guid>
      <description>**약한 도함수$(\mathrm{weak\ derivatives})$, ** **초함수적 도함수$(\mathrm{distributional\ derivatives})$ $u \in {L}{\mathrm{loc}}^1(\Omega)$라고 가정하자. 그러면 다음과 같은 식을 만족하는 $v{\alpha} \in {L}{\mathrm{loc}}^1(\Omega)$가 존재할 수도, 존재하</description>
    </item>
    
    <item>
      <title>초함수의 곱의 미분법</title>
      <link>https://freshrimpsushi.github.io/posts/product-rule-for-derivatives-of-distribution/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/product-rule-for-derivatives-of-distribution/</guid>
      <description>$T\in D^{ * }$를 초함수, $f \in C^{\infty}$를 스무스 함수라고 하자. 그러면 아래의 식이 성립한다. $$ (fT)&#39;= f&amp;rsquo;T+fT&#39; $$ 기존의 두 함수의 곱의 미분법과 찰떡같이 잘 맞으니 초함수의 미분과 초함수의 곱이 그럴듯하게 정의됐음을 느낄 수 있다. 증명 초함수 미분과 곱의 정의에 의해 $$ \begin{align*} (fT)&#39;(\phi) &amp;amp;= T&#39;(f\phi) \\ &amp;amp;= T\left( (f\phi)&#39; \right) \\ &amp;amp;= T(f&#39;\phi+f\phi&#39;) \\ &amp;amp;= T(f&#39;\phi)+T(f\phi&#39;) \\ &amp;amp;=f&amp;rsquo;T(\phi)+fT(\phi&#39;) \\ &amp;amp;= f&amp;rsquo;T(\phi)+fT&#39;(\phi) \end{align*} $$ 따라서 $$ (fT)&#39;=f&amp;rsquo;T+fT&#39; $$ ■</description>
    </item>
    
    <item>
      <title>초함수의 스무스 함수와의 곱셈</title>
      <link>https://freshrimpsushi.github.io/posts/multiplication-of-regular-distribution-by-smooth-function/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplication-of-regular-distribution-by-smooth-function/</guid>
      <description>초함수는 정의역이 함수공간이기 때문에 실수 공간에서 정의된 함수와 곱셈을 할 수 없다. 하지만 정칙 초함수의 경우 대응되는 국소 적분 가능한 함수 $u\in L_{\mathrm{loc}}^{1}$가 있어서 아래와 같이 표현된다. $$ T_{u}(\phi)=\int u(x)\phi (x) dx,\quad \phi \in \mathcal{D} $$ 따라서 $u$에 가해지는 어떤 작용 $S$에 의해 $Su=u&#39;$을 얻을 수 있을텐데 여전히 $u&#39;$이</description>
    </item>
    
    <item>
      <title>놈 공간에서의 수열의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-normed-space/</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-normed-space/</guid>
      <description>**$x_{n} \text{ converges in norm to } x $ $(X,| \cdot | )$를 놈 공간, $\left\{ x_{n} \right\}$을 $X$에서의 수열이라고 하자. $$ | x-x_{n}|\to 0 \text{ as } n \to \infty ,\quad x\in X $$ 를 만족하면 수열 $\left\{ x_{n} \right\}$이 $x$로 **놈 수렴한다** 고 하고 아래와 같이 나타낸다. $$ x_{n} \to x \text { as } n \to \infty,\quad x=\lim \limits_{n\to\infty}x_{n} $$ 놈 공간에서의 수렴임이 약속된 상황에서는 간단하게 **수렴한다** 고 말</description>
    </item>
    
    <item>
      <title>초함수의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-of-distribution/</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-of-distribution/</guid>
      <description>$D^{ * }$가 초함수 공간, $\left\{ T_{n} \right\}$가 $D^{ * }$에서의 초함수열이라고 하자. 그러면 모든 테스트 함수 $\phi$에 대해서 $$ T_{n}(\phi) \to T(\phi) ,\quad \forall \phi \in \mathcal{D} $$ 를 만족하면 $\left\{ T_{n} \right\}$이 $T$로 **수렴한다** 고 한다.힐베르트 공간의 센스에서 생각해보면 이는 약한 수렴과 같기 때문에 ${T_{n} }$이 $T$로 약하게 수렴한다고 말하기</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서 약한 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/weak-convergence-in-hilbert-space/</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weak-convergence-in-hilbert-space/</guid>
      <description>$(H,\langle \cdot \rangle ) $가 힐베르트 공간, $\left\{ x_{n} \right\}$이 $H$에서의 수열이라고 하자. 모든 $y\in H$에 대해서 아래의 식이 성립할 때 $\left\{ x_{n} \right\}$이 $x$로 **약하게 수렴** $(\text{converge weakly})$한다고 말하고 $x_{n} \rightharpoonup x$라고 나타낸다. $$ \langle x_{n}, y \rangle \to \langle x , y \rangle ,\quad \forall y\in H $$ weak의 w를 따서 다음과 같이 표기하기도 한다. $$ x_{n} \overset{\text{w}}{\to}</description>
    </item>
    
    <item>
      <title>전미분</title>
      <link>https://freshrimpsushi.github.io/posts/total-derivative/</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/total-derivative/</guid>
      <description>3차원 공간에서 정의된 함수 $f=f(x,y,z)$가 주어졌다고 하자. 각 변수 $x$, $y$, $z$의 변화에 따른 $f$의 함숫값의 변화를 전미분 이라 하고 $df$로 표기한다. 그러면 아래의 식이 성립한다. $$ df=\frac{ \partial f}{ \partial x }dx + \frac{ \partial f}{ \partial y}dy+\frac{ \partial f}{ \partial z}dz $$ 2변수 함수$z=f(x,y)$에 대해서 나타내면 $$ dz=\frac{ \partial f}{ \partial x}dx+\frac{ \partial f}{ \partial y}dy $$ 와 같고 변수가 $n$개</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 벡터 함수의 다이버전스발산</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-of-fector-function-in-cartesian-cooridenates-system/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-of-fector-function-in-cartesian-cooridenates-system/</guid>
      <description>벡터 함수 $\mathbf{F}(x,y,z)=F_{x}\hat{\mathbf{x}}+F_{y}\hat{\mathbf{y}} + F_{z}\hat{\mathbf{z}}$의 **다이버전스** 를 아래와 같이 정의하고 $\nabla \cdot \mathbf{F}$라고 표기한다. $$ \nabla \cdot \mathbf{F} := \frac{ \partial F_{x}}{ \partial x} + \frac{ \partial F_{y}}{ \partial y }+ \frac{ \partial F_{z}}{ \partial z} $$ 기하학적으로 $\nabla \cdot \mathbf{F}&amp;gt;0$이면 $\mathbf{F}$가 퍼져나가는, 밖으로 나가는 모양을 하고 있음을</description>
    </item>
    
    <item>
      <title>모평균이 존재하지 않는 분포  코시분포</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-distribution/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-distribution/</guid>
      <description>다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $C$ 를 코시 분포 라고 한다. $$ f(x) = {1 \over \pi} {1 \over {x^2 + 1}} \qquad , x \in \mathbb{R} $$ [1] 코시 분포의 적률생성함수는 존재하지 않는다.모든 확률 분포가 평균과 분산을 가질 것 같지만 실제로는 그렇지 않다. 그 대표적인 예시가 코시 분포로, 언뜻 정규 분포와 닮았지만 양쪽 꼬리가 두꺼운 모양을 하고 있다. 모수에 무관하게 적률생</description>
    </item>
    
    <item>
      <title>원통 좌표계의 변수로 r theta를 쓰면 안되는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/1795/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1795/</guid>
      <description>원통 좌표계는 아래와 같이 3차원 공간의 점을 $(\rho,\phi,z)$로 표현하는 좌표계를 말한다.그런데 원통 좌표계를 $(r,\theta, z)$와 같이 표기한 것을 볼 수 있다. 극좌표계 $(r,\theta)$에서 높이 $z$가 추가되었으니 아무 생각 없이 $(r,\theta, z)$와 같이 표기한 것으로 보이는데 이는 각 기호의 의미를 생각해봤을 때 명백하게 잘못 되었다</description>
    </item>
    
    <item>
      <title>초함수의 미분</title>
      <link>https://freshrimpsushi.github.io/posts/differentiation-of-a-distribution/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/differentiation-of-a-distribution/</guid>
      <description>초함수는 정의역이 함수공간이기 때문에 실수 공간에서 정의된 함수와 같은 식으로 미분을 할 수 있는 건 아니다. 하지만 정칙 초함수의 경우 대응되는 국소 적분 가능한 함수 $u\in L_{\mathrm{loc}}^{1}$가 있어서 아래와 같이 표현된다. $$ T_{u}(\phi) =\int u(x)\phi(x) dx,\quad \phi \in \mathcal{D} $$ 따라서 $u$에 가해지는 어떤 작용 $S$에 의해 $Su=u&#39;$을 얻을 수 있을텐</description>
    </item>
    
    <item>
      <title>디랙 델타 함수는 정칙 초함수가 아님을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-dirac-delta-function-is-not-regular-distribution/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-dirac-delta-function-is-not-regular-distribution/</guid>
      <description>$$ \delta (\phi) := \phi (0), \quad \phi \in \mathcal{D} $$ 위와 같이 정의된 디랙 델타 함수는 정칙 초함수가 아니다. 정칙 초함수가 아닌 초함수를 특이 초함수$(\mathrm{singular\ distribution})$ 라고 한다.정칙 초함수란 대응되는 국소 적분 가능한 함수 $u$가 있어서 아래와 같이 정의되는 초함수를 말한다. $$ T_{u}(\phi) := \int u(x) \phi (x) dx,\quad \phi \in \mathcal{D} $$ 디랙 델타 함수가 정칙 초함수가 아니라는 말</description>
    </item>
    
    <item>
      <title>디랙 델타 함수의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transform-of-dirac-delta-function/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transform-of-dirac-delta-function/</guid>
      <description>디랙 델타 함수 $\delta (x)$의 푸리에 변환은 다음과 같다. $$ \mathcal{F}\delta = 1 $$ 증명 $$ \begin{align*} \mathcal{F}\delta &amp;amp;= \int_{-\infty}^{\infty} \delta(x)e^{-i\xi x}dx \\ &amp;amp;= \int _{-\infty} ^{\infty} \delta(x) e^{0}dx \\ &amp;amp;= \int _{-\infty} ^{\infty} \delta(x) dx \\ &amp;amp;=1 \end{align*} $$ ■</description>
    </item>
    
    <item>
      <title>자율 시스템의 오빗</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-of-autonomous-system/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-of-autonomous-system/</guid>
      <description>**오빗의 정의1와 피리어딕 오빗의 정의2 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 플로우를 $x(t,t_{0},x_{0})$ 와 같이 나타낸다고 하자.**1.** 그러면 $x_{0} \in X$ 를 지나는 **오빗** $O(x_{0})$ 을 다음과 같이 나타낸다. $$ O(x_{0}) := \left\{ x \in X : x = x(t, t_{0} , x_{0}) \right\} $$ **2.** 오빗이 모든 $t \in \mathbb{R}$ 에</description>
    </item>
    
    <item>
      <title>초함수의 다일레이션</title>
      <link>https://freshrimpsushi.github.io/posts/dilation-of-a-distribution/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dilation-of-a-distribution/</guid>
      <description>초함수는 정의역이 함수공간이기 때문에 실수 공간에서 정의된 함수와 같은 식으로 다일레이션을 할 수 있는 건 아니다. 하지만 정칙 초함수의 경우 대응되는 국소 적분 가능한 함수 $u\in L_{\mathrm{loc}}^{1}$가 있어서 아래와 같이 표현된다. $$ T_{u}(\phi) =\int u(x)\phi(x) dx,\quad \phi \in \mathcal{D} $$ 따라서 $u$에 가해지는 어떤 작용 $S$에 의해 $Su=u&#39;$을 얻을 수</description>
    </item>
    
    <item>
      <title>특성 함수</title>
      <link>https://freshrimpsushi.github.io/posts/characteristic-function/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/characteristic-function/</guid>
      <description>$A\subset X$에 대해서 아래와 같이 정의되는 함수 $\chi_{A} : X \to Y$를 **특성함수** 라 한다. $$ \chi _{A}(x) := \begin{cases} 1, &amp;amp; x\in A \\ 0 ,&amp;amp; x \notin A \end{cases} $$ $\chi$는 그리스 문자 **카이** 이다. 학창시절 수학 선생님이 엑스를 $\chi$로 쓰면 안되고 $x$로 써야한다고 말씀하신 이유는 말 그대로 $\chi$는 엑스가 아니기 때문이다. 특히 위와 같이 강력한 의미를</description>
    </item>
    
    <item>
      <title>t-분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-t-distribution/</link>
      <pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-t-distribution/</guid>
      <description>$X \sim t (\nu)$ 이면 $$ E(X) = 0 \qquad , \nu &amp;gt;1 \\ \text{Var}(X) = {{ \nu } \over { \nu - 2 }} \qquad , \nu &amp;gt; 2 $$ Strategy : t-분포 역시 카이제곱분포와 비슷하게 적률 공식이 알려져 있어, 이 공식들을 이용한다.t-분포의 적률두 확률 변수 $W,V$ 가 독립이고 $W \sim N(0,1)$, $V \sim \chi^{2} (r)$ 이라 하자. $k &amp;lt; r$ 이면 $\displaystyle T := { {W} \over {\sqrt{V/r} } }$ 는 $k$차 적률이 존재하고 $$ E T^{k} = E W^{k} {{ 2^{-k/2} \Gamma \left( {{ r } \over { 2 }} - {{ k } \over</description>
    </item>
    
    <item>
      <title>리만 함수 방정식과 리만 제타 함수의 자명근</title>
      <link>https://freshrimpsushi.github.io/posts/trivial-root-of-riemann-zeta-function/</link>
      <pubDate>Fri, 18 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trivial-root-of-riemann-zeta-function/</guid>
      <description>**리만 함수 방정식 $$ \zeta(s) = 2^{s} \pi^{s - 1} \sin \left( {{ \pi s } \over { 2 }} \right) \Gamma (1-s) \zeta (1-s) $$ * $\Gamma$ 는 감마 함수다. * $\zeta$ 는 리만 제타 함수다.리만 함수 방정식 에서 $s \in 2 \mathbb{Z}$ 이면 $\displaystyle \sin \left( {{ \pi s } \over { 2 }} \right) = 0$ 이므로 당연히 $\zeta (s) = 0$ 일 것 같다. 그러나 $s = 0$ 일 때는 우변에 $\zeta (1 - 0)$ 이 나오기 때문에 근이고 뭐고 아예 정의가 되지 않으며, $s &amp;gt; 0$ 일 때는 바이어슈트라스의 무</description>
    </item>
    
    <item>
      <title>초함수로 엄밀하게 정의되는 디랙 델타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/dirac-delta-function-strictly-dfined-as-distributiona/</link>
      <pubDate>Thu, 17 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirac-delta-function-strictly-dfined-as-distributiona/</guid>
      <description>테스트 함수 공간 $\mathcal{D}(\mathbb{R}^{n})$의 범함수 $\delta_{a} : \mathcal{D} \to \mathbb{C}$를 아래와 같이 정의하고 디랙 델타 함수라 부르자. $$ \delta_{a}(\phi):=\phi(a) $$ 그러면 디랙 델타 함수는 초함수가 된다. 간단히 $\delta=\delta_{0}$위의 정의에 의해 발산하는 값을 가지고 있어 함수가 아니지만 대충 함수라고 두</description>
    </item>
    
    <item>
      <title>t-분포</title>
      <link>https://freshrimpsushi.github.io/posts/t-distribution/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/t-distribution/</guid>
      <description>자유도 $\nu &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $t \left( \nu \right)$ 를 t-분포라고 한다. $$ f(x) = {{ \Gamma \left( {{ \nu + 1 } \over { 2 }} \right) } \over { \sqrt{\nu \pi} \Gamma \left( {{ \nu } \over { 2 }} \right) }} \left( 1 + {{ x^{2} } \over { \nu }} \right)^{- {{ \nu + 1 } \over { 2 }}} \qquad ,x \in \mathbb{R} $$ * $\Gamma (\nu)$ 는 감마 함수다.t-분포 는 지금도 맥주로 유명한 기네스 양조 공장에서 일하던 윌리엄 고셋William S.</description>
    </item>
    
    <item>
      <title>국소 적분가능</title>
      <link>https://freshrimpsushi.github.io/posts/locally-integrable/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/locally-integrable/</guid>
      <description>국소 적분가능한 함수에 대해서 여러가지 말로 정의를 할 수 있지만 그 본질은 전부 같다.함수 $u$가 열린집합 $\Omega \subset \mathbb{R}^n$상의 거의 어디에서나 정의된 함수라고 하자. 모든 열린 집합 $U \Subset \Omega$에 대해서 $u \in L^1(U)$일 때 $u$를 $\Omega$위에서 국소 적분 가능 다고 말하며 다음과 같이 표기한다. $$ u \in L_{\mathrm{loc}</description>
    </item>
    
    <item>
      <title>모든 국소 적분 가능한 함수는 초함수로 확장 가능함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-every-locally-integrable-function-can-be-treated-as-a-distribution/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-every-locally-integrable-function-can-be-treated-as-a-distribution/</guid>
      <description>모든 $u \in L_{\mathrm{loc} }^1(\Omega) $에 대응하여 다음과 같이 정의되는 초함수 $T_u \in D^{ * }(\Omega)$가 존재한다. $$ T_u (\phi) := \int_{\Omega} u(x)\phi(x)dx, \quad \phi \in D(\Omega) $$ $\mathcal{D}(\Omega)$는 테스트 함수 공간이다. 위와 같이 정의되는 초함수를 **정칙 초함수$(\mathrm{regular\ distribution})$** 라 한다. 또한 위 식은 내적 공간의 관점에서 봤을 때 $u$와</description>
    </item>
    
    <item>
      <title>초함수 일반화된 함수</title>
      <link>https://freshrimpsushi.github.io/posts/distribution-generalized-function/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distribution-generalized-function/</guid>
      <description>$\Omega \subset \mathbb{R}^{n}$가 열린 집합이라고 하자. 테스트 함수 공간의 연속인 선형 범함수 $T : \mathcal{D}(\Omega) \to \mathbb{C}$를 **초함수** 라고 정의한다. 즉 초함수는 테스트 함수 공간의 듀얼 스페이스의 원소이다. 따라서 $$ T \in \mathcal{D}^{ * } $$ 와 같이 표기하고 $D^{ * }$를 *(슈바르츠) 초함수 공간(**Schwartz) distribution space 이라 부</description>
    </item>
    
    <item>
      <title>초함수의 트랜슬레이션</title>
      <link>https://freshrimpsushi.github.io/posts/translation-of-a-distribution/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/translation-of-a-distribution/</guid>
      <description>초함수는 정의역이 함수공간이기 때문에 실수 공간에서 정의된 함수와 같은 식으로 트랜슬레이션을 할 수 있는 건 아니다. 하지만 정칙 초함수의 경우 대응되는 국소 적분 가능한 함수 $u\in L_{\mathrm{loc}}^{1}$가 있어서 아래와 같이 표현된다. $$ T_{u}(\phi) =\int u(x)\phi(x) dx,\quad \phi \in \mathcal{D}(\mathbb{R}^{n}) $$ 따라서 $u$에 가해지는 어떤 작용 $S$에 의해 $Su=u&#39;$을 얻을</description>
    </item>
    
    <item>
      <title>테스트 함수 공간에서의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-test-function-space/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-test-function-space/</guid>
      <description>테스트 함수 공간에서는 &amp;lsquo;수렴&amp;rsquo;을 특별하게 정의한다. 어떤 공간 $X$가 주어졌을 때 $X$에서 정의된 놈이나 거리를 이용해서 수렴을 정의하는것이 보통이다. 하지만 테스트 함수 공간에서는 초함수를 잘 정의하고 다룰 수 있도록 일반적이지 않은 조건으로 수렴을 정의한다.**$\mathcal{D}(\Omega)</description>
    </item>
    
    <item>
      <title>테스트 함수와 테스트 함수 공간</title>
      <link>https://freshrimpsushi.github.io/posts/test-function-space/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/test-function-space/</guid>
      <description>열린 집합 $\Omega \subset \mathbb{R}^{n}$와 함수 $\phi : \Omega \to \mathbb{C}$가 주어졌다고 하자. $\phi$가 무한히 미분 가능하고, 그 도함수들이 전부 연속이며, 컴팩트 서포트를 가지면 테스트 함수 라 한다. 테스트 함수들의 벡터 공간을 $C_{c}^{\infty}(\Omega)$ 혹은 간단하게 $\mathcal{D}(\Omega)$라고 표기한다.test function 혹</description>
    </item>
    
    <item>
      <title>델타 함수의 역사와 디랙이 델타 함수를 사용한 이유</title>
      <link>https://freshrimpsushi.github.io/posts/1781/</link>
      <pubDate>Tue, 15 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1781/</guid>
      <description>**델타 함수의 역사123 델타 함수는 19세기 초반 푸아송(1815), 푸리에(1822), 코시(1823, 1827) 등 수학, 물리학에 지대한 업적을 남긴 학자들의 작업물에서부터 나타나기 시작했다. 다만 이 당시에는 델타 함수를 현재와 같이 수학적으로 엄밀하게 정의하는데 집중한 것은 아니었다. 그 후에 키르히호프(1882, 1891)와 헤</description>
    </item>
    
    <item>
      <title>functional이 functional로 이름지어진 이유 Generalized function</title>
      <link>https://freshrimpsushi.github.io/posts/1780/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1780/</guid>
      <description>**왜 functional일까? 함수 해석학은 영어로 functional analysis이다. function analysis도 아니고 functional이 대체 뭘까? 우선 단어를 살펴보면 function+al으로 구성된 것으로 보인다. 즉 함수의 형용사형처럼 보이고 이런 느낌으로 해석해보면 functional은 &amp;lsquo;함수적인 (것)&amp;rs</description>
    </item>
    
    <item>
      <title>리만 자이 함수</title>
      <link>https://freshrimpsushi.github.io/posts/riemann-xi-function/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riemann-xi-function/</guid>
      <description>다음과 같이 정의된 함수 $\xi$ 를 리만 자이 함수 라고 한다. $$ \xi (s) := {{ 1 } \over { 2 }} s ( s-1) \pi^{-s/2} \zeta (s) \Gamma \left( {{ s } \over { 2 }} \right) $$ * $\zeta$ 는 리만 제타 함수다. * $\Gamma$ 는 감마 함수다.리만 자이 함수는 원래 이와 다른 조금 형태로 정의되어있었으나, 에드문트 란다우Edmund Landau 에 의해 소문자 자이 $\xi$ 로 다시 정의되고 원래 리만 자이 함수는 대문자 $\Xi$ 를 써서 $\Xi (z) := \xi \left( {{</description>
    </item>
    
    <item>
      <title>독립인 정규 분포와 카이제곱 분포에서 스튜던트 t-분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/204/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/204/</guid>
      <description>두 확률 변수 $W,V$ 가 독립이고 $W \sim N(0,1)$, $V \sim \chi^{2} (r)$ 이라 하면 $$ \displaystyle T = { {W} \over {\sqrt{V/r} } } \sim t(r) $$ * $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. * $\chi^{2} \left( r \right)$ 은 자유도 $r$ 인 카이제곱 분포다. * $t(r)$ 은 자유도 $r$ 인 t-분포다.어떤 분포에서 다른 분포를 유도하는 것은 공부만 열심히 하면 직관적인 추측이 가능하다. 하지만 둘 이상의 분포에서 다른 분포를 유도해낸다</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 스칼라 함수의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-of-scalar-function-in-cartesian-coordinate-system/</link>
      <pubDate>Sat, 12 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-of-scalar-function-in-cartesian-coordinate-system/</guid>
      <description>3변수 스칼라 함수 $f=f(x,y,z)$의 그래프의 각 점에서 기울기와 증가하는 방향을 나타내는 벡터를 $\nabla f$라고 표기하며 그래디언트 라고 부른다. $$ \mathrm{grad}f=\nabla f = \frac{ \partial f}{ \partial x }\hat{\mathbf{x}}+\frac{ \partial f}{ \partial y}\hat{\mathbf{y}}+\frac{ \partial f}{ \partial z}\hat{\mathbf{z}} $$ ※ 그래디언트는 방향도함수, 기울기, 구배 등으로 번역된다. 구배는 기울기의 한자어이기 때문에 기울기와 같은 말이며 최근에는 잘 쓰이지 않는다. 기</description>
    </item>
    
    <item>
      <title>완벽 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/perfect-graph/</link>
      <pubDate>Sat, 12 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/perfect-graph/</guid>
      <description>그래프 $G$ 의 모든 유도서브그래프 $H$ 가 다음을 만족하면 완벽 그래프 라고 한다. $$ \chi (H) = \omega (H) $$ $\chi (H)$ 는 그래프 $H$ 의 크로마틱 수다.* $\omega (H)$ 는 그래프 $H$ 의 클리크 수다.그래프 이론의 세계는 수학의 많은 분과가 그러하듯 어마어마하게 넓은데, 솔직히 조금은 더 넓다고 말하고 싶다. 그래프에서 버텍스와 에지를 정의하는 방법이 너무 다양하기 때문이다. 영인자</description>
    </item>
    
    <item>
      <title>표준정규분포의 제곱은 자유도가 1인 카이제곱분포를 따름을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/148/</link>
      <pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/148/</guid>
      <description>$X \sim N(\mu,\sigma ^2)$면 $$ \displaystyle V=\left( { X - \mu \over \sigma} \right) ^2 \sim \chi ^2 (1) $$ * $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. * $\chi^{2} \left( 1 \right)$ 은 자유도 $1$ 인 카이제곱 분포다.정리로는 이를 일반화시킨 스튜던트의 정리가 많이 쓰인다.통계학을 공부하는 사람이라면 표준정규분포의 제곱이 카이제곱분포를 따른다는 것은 팩트로써 항상 당연하게 알고 있어야한다. 어떤 데이</description>
    </item>
    
    <item>
      <title>정규 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-normal-distribution/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-normal-distribution/</guid>
      <description>$X \sim N\left( \mu , \sigma^{2} \right)$ 면 $$ E(X) = \mu \\ \text{Var} (X) = \sigma^{2} $$ Strategy : 정규 분포는 적률생성함수가 미분하기 쉬우니 그냥 바로 직접연역한다.**정규 분포의 적률생성함수 $$ m(t) = \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) \qquad , t \in \mathbb{R} $$ 증명 $$ m&#39;(t) = \left( \mu + \sigma^{2} t \right) \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) $$ 이므로 $E(X) = m&#39;(0) = \mu$ 이고 $$ m&#39;&#39;(t) = \left( 0 + \sigma^{2} \right) \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) + \left( \mu + \sigma^{2} t</description>
    </item>
    
    <item>
      <title>비파괴검사 토모그래피 팬텀이란</title>
      <link>https://freshrimpsushi.github.io/posts/nondestructive-testing-tomography-phantom/</link>
      <pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/nondestructive-testing-tomography-phantom/</guid>
      <description>비파괴검사 비파괴검사란 어떤 물체를 손상시키지 않으면서 그 물체 내부에서 알고 싶은 정보를 얻어내는 검사 방법을 말한다. 비파괴검사라는 말 자체는 처음 들어봤어도 개념 자체는 굉장히 일상적인 것이다. 사람의 뼈에 금이 갔는지, 간암이 있는지, 뇌경색이 있는지 알 수 있는 확실한 방법은 절개해서 확인해보는 것이지만 이는 현실적으로 불가능하다. 이때 쓰</description>
    </item>
    
    <item>
      <title>컴프턴 카메라의 원리</title>
      <link>https://freshrimpsushi.github.io/posts/principle-of-the-compton-camera/</link>
      <pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/principle-of-the-compton-camera/</guid>
      <description>컴프턴 카메라는 컴프턴 산란을 이용하여 감마선을 내뿜는 물질의 위치를 찾아내는 장치이다. Compton telescope 혹은 Compton imager라고도 한다. 그림의 오른쪽에는 컴프턴 카메라가 간단하게 두 디텍터로 표현돼있다. 디텍터는 감마선의 에너지를 측정하며, 첫번째 디텍터에서는 감마선의 산란이 일어난다. 그림 왼쪽의 검은 사각형은 파괴하지 않고 내부 구조를 파악하고</description>
    </item>
    
    <item>
      <title>푸아송 합 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-poisson-summation-formula/</link>
      <pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-poisson-summation-formula/</guid>
      <description>$f : \mathbb{R} \to \mathbb{C}$ 가 슈바르츠 함수라고 하자. 그러면 $$ \sum_{n \in \mathbb{Z}} f(n) = \sum_{k \in \mathbb{Z}} \widehat{f}(k) $$ * 슈바르츠 함수 $f \in C^{\infty}(\mathbb{R})$ 란 $x \to \pm \infty$ 일 때 함숫값의 크기 $\left| f (x) \right| $ 가 빠르게 $0$ 으로 수렴하는 함수를 말한다. * $f$ 와 $\gamma \in \mathbb{R}$ 에 대해 $\widehat{f}(\gamma)$ 는 다음과 같은 푸리에 변환을 나타낸다. $$ \widehat{f} ( \gamma ) = \int_{\mathbb{R}} f(x) e^{2 \pi i \gamma x} dx $$ 증명1 $$ F(x) := \sum_{n \in \mathbb{Z}} f ( x + n ) $$ 이라고 하면 $F$ 는 $1$-피리어딕</description>
    </item>
    
    <item>
      <title>감마함수와 리만 제타 함수 디리클레 에타 함수와의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/1641/</link>
      <pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1641/</guid>
      <description>$\Re (s) &amp;gt; 1$ 이면 $$ \zeta (s) \Gamma (s) = \mathcal{M} \left[ {{ 1 } \over { e^{x} - 1 }} \right] (s) = \int_{0}^{\infty} {{ x^{s-1} } \over { e^{x} - 1 }} dx \\ \eta (s) \Gamma (s) = \mathcal{M} \left[ {{ 1 } \over { e^{x} + 1 }} \right] (s) = \int_{0}^{\infty} {{ x^{s-1} } \over { e^{x} + 1 }} dx $$ $\mathcal{M}$ 은 멜린 변환이다.* $\Re (s)$ 는 복소수 $s$ 의 실수부를 나타낸다.디리클레 에타 함수 $\eta(s)$ 는 리만 제타 함수 $\zeta(s)$ 의 교대 급수인만큼 서로 수학적으로 흥미로운 관계를 가질 뿐만 아니라 감마 함수 $\Gamma (S)$ 와 멜</description>
    </item>
    
    <item>
      <title>감쇠 조화 진동</title>
      <link>https://freshrimpsushi.github.io/posts/damped-harmonic-oscillation/</link>
      <pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/damped-harmonic-oscillation/</guid>
      <description>단순 조화 진동강제 진동다중 스프링 진동결합 진동&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/gif&amp;rdquo; filename=&amp;ldquo;Damping_fps30.gif&amp;rdquo; height=&amp;ldquo;400&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/9994234E5FACCFA829&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;600&amp;rdquo;/&amp;gt;줄리아로 위 움짤 찌는 코드용수철 상수를 $k$라 할 때, 단순 조화 진동자의 운동 방정식은 다음과 같다. $$ m \ddot {x}+kx=0 $$ 단순 조화 진동에서는 오로지 용수철에 의한 복원력만을 고려한다. 하지만 실제로는 마찰력 등</description>
    </item>
    
    <item>
      <title>매트랩에서 감쇠 진동 강제 진동 그래프 그리는 코드</title>
      <link>https://freshrimpsushi.github.io/posts/1737/</link>
      <pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1737/</guid>
      <description>감쇠 조화 진동강제 조화 진동위와 같은 감쇠 조화 진동자의 그래프를 매트랩에서 그리는 코드는 아래와 같다. t=linspace(0,10,200); gamma1=3; omega1=1; x1=0.5*exp((-gamma1+sqrt(gamma1^2-omega1^2))*t)+0.5*exp((-gamma1-sqrt(gamma1^2-omega1^2))*t); gamma2=1; omega2=1; x2=exp(-gamma2*t)+t.*exp(-gamma2*t); gamma3=1; omega3=5; x3=real(0.5*exp((-gamma3+sqrt(gamma3^2-omega3^2))*t)+0.5*exp((-gamma3+sqrt(gamma3^2-omega3^2))*t)); figure() plot(t,x1,t,x2,t,x3); title(&#39;감쇠 조화 진동 Damped Harmonic Oscillator&#39;,&#39;FontSize&#39;,20,&#39;FontWeight&#39;,&#39;bold&#39;); xlabel(&#39;시간 t&#39;,&#39;FontSize&#39;,20,&#39;FontWeight&#39;,&#39;bold&#39;); ylabel(&#39;평형점으로부터 거리 x&#39;,&#39;FontSize&#39;,20,&#39;FontWeight&#39;,&#39;bold&#39;); lgd=legend({&#39;과다감쇠overdamping&#39;,&#39;임계감쇠critical dampi</description>
    </item>
    
    <item>
      <title>작용소로써의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transform-as-operator/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transform-as-operator/</guid>
      <description>함수 $f$ 의 푸리에 변환 $$ \widehat{f} (\gamma ) := \int_{\mathbb{R}} f(x) e^{-2 \pi i x \gamma} dx \qquad , \gamma \in \mathbb{R} $$ 을 다음과 같은 작용소 $\mathcal{F}$와 같이 표현하기도 한다. $$ (\mathcal{F} f) (\gamma ) := \widehat{f} ( \gamma ) $$ 푸리에 변환은 해석학 전반에서 널리 쓰이고 있으며 두가지 표현 $\widehat{f}$ 과 $\mathcal{F} f$ 는 본질적으로 다른 점이 없지만, 기호를 사용할 때 뉘앙스의 차이는 살짝 있다. 실질적인 계산과 공식, 빠른 표기가</description>
    </item>
    
    <item>
      <title>유클리드 공간에서 일차 형식과 이차 형식</title>
      <link>https://freshrimpsushi.github.io/posts/linear-form-and-quadratic-form-in-euclidean-space/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-form-and-quadratic-form-in-euclidean-space/</guid>
      <description>**정의 $(a)$ 일차형식linear form : 유클리드 공간 $\mathbb{R}^{n}$의 두 벡터 $\mathbf{x}=\left[ x_{1}\ \cdots\ x_{n} \right]^{T}$, $\mathbf{b}=\left[ b_{1}\ \cdots\ b_{n} \right]^{T}$에 대해서, 아래와 같은 $n$개의 변수 $x_{1},\cdots,x_{n}$의 1차 다항식을 $\mathbb{R}^{n}$ 위에서의 **일차 형식** 이라고 한다. $$ \mathbf{b}^{T}\mathbf{x}=\begin{bmatrix} b_{1}&amp;amp; \cdots &amp;amp; b_{n} \end{bmatrix} \begin{bmatrix} x_{1} \\ \vdots \\ x_{n} \end{bmatrix}=b_{1}x_{1} +\cdots + b_{n}x_{n}=\sum \limits _{i=1}^{n}b_{i}x_{i} $$ $(b)$ **</description>
    </item>
    
    <item>
      <title>트랜슬레이션 모듈레이션 다일레이션의 교환관계</title>
      <link>https://freshrimpsushi.github.io/posts/commutation-relations-of-translation-modulation-dilation/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/commutation-relations-of-translation-modulation-dilation/</guid>
      <description>모든 $a, b \in \mathbb{R}$ 과 $c &amp;gt; 0$ 에 대해 $T_{a}, E_{b}, D_{c}$ 는 다음과 같은 관계를 가진다.**[1] $$ (T_{a} E_{b} f ) (x) = e^{- 2 \pi i b a} (E_{b} T_{a} f ) (x) $$ **[2] $$ (T_{a} D_{c} f ) (x) = (D_{c} T_{a/c} f ) (x) $$ **[3] $$ (D_{c} E_{b} f ) (x) = (E_{b/c} D_{c} f ) (x) $$ $T_{a}, E_{b}, D_{c}$ 는 각각 $L^{2} $ 에서 정의된 트랜슬레이션, 모듈레이션, 다일레이션이다. 증명[1] $$ \begin{eqnarray*} (T_{a} E_{b} f ) (x) &amp;amp;=&amp;amp; T_{a} \left( e^{2 \pi i b x} f(x) \right) \\ &amp;amp;=&amp;amp; e^{2 \pi i b (x-a)} f(x-a) \\ &amp;amp;=&amp;amp; e^{2 \pi i</description>
    </item>
    
    <item>
      <title>거리공간에서 연결 집합</title>
      <link>https://freshrimpsushi.github.io/posts/connected-sets-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/connected-sets-in-metric-space/</guid>
      <description>**정의 거리공간 $X$의 두 부분 집합 $A$, $B$가 $$ A \cap \overline{B}= \varnothing\quad &amp;amp; \quad \overline{A}\cap B= \varnothing $$ 을 만족시키면, $A$와 $B$는 분리되었다$(\mathrm{separated})$ 고 한다. 다시 말해 $B$의 폐포에 포함되는 $A$의 점이 없고, $A$의 폐포에 포함되는 $B$의 점이 없다는 뜻이다. 부분 집합 $E \subset X$가 공집합이 아닌 분리된 두 집합의 합</description>
    </item>
    
    <item>
      <title>거리공간에서 연속 함수의 합성은 연속성을 보존함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-composition-of-continuous-functions-preserve-continuity/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-composition-of-continuous-functions-preserve-continuity/</guid>
      <description>**정리 세 거리공간 $(X,d_{X})$, $(Y,d_{Y})$, $(Z,d_{Z})$가 있다고 하자. $E\subset X$이고 두 함수 $f:E\to Y$, $g:f(E) \to Z$가 주어졌다고 하자. 그리고 $E$에서 정의되는 $h : E \to Z$가 아래와 같다고 하자. $$ h(x) = g(f(x))\quad \forall x \in E $$ 이때 $f$가 $p\in E$에서 연속이고 $g$가 $f(p)\in f(E)$에서 연속이면, $h$도 $p$에서 연속이다.이때 $h$를 $f$와 $g$의 합</description>
    </item>
    
    <item>
      <title>거리공간에서 연속과 균등연속</title>
      <link>https://freshrimpsushi.github.io/posts/continuous-functions-and-uniformly-continuous-functions-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuous-functions-and-uniformly-continuous-functions-in-metric-space/</guid>
      <description>두 거리 공간 $\left( X , d_{X} \right)$, $\left( Y , d_{Y} \right)$와 부분집합 $E\subset X$에 대해 함수 $f : E \to Y$ 를 정의하자.**1.** $p \in E$라고 하자. 임의의 $ \varepsilon &amp;gt; 0$ 에 대해 $$ x \in E\ &amp;amp;\ d_{X}(p, x ) &amp;lt; \delta \implies d_{Y}(f(p) , f(x) ) &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $f$ 는 $p \in E$ 에서 **연속** 이라고 한다. $f$가 $E$의 모든 점에서 연속이면 $f$를 $E$ 위에서의 **연속함</description>
    </item>
    
    <item>
      <title>거리공간에서 연속성과 컴팩트</title>
      <link>https://freshrimpsushi.github.io/posts/continuity-and-compactness-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuity-and-compactness-in-metric-space/</guid>
      <description>**정의 실수값 함수 $\mathbf{f}: E \to \mathbb{R}^{k}$가 주어졌다고 하자. 모든 $x \in E$에 대해서 $$ \left|\mathbf{f}(x) \right| \le M $$ 을 만족시키는 실수 $M$이 존재하면 $\mathbf{f}$를 유계라고 한다.**정리 $X$를 컴팩트 거리공간, $Y$를 거리공간, $f:X\to Y$가 연속이라고 하자. 그러면 $f(X)$는 컴팩트이다.*컴팩트라는 조건은</description>
    </item>
    
    <item>
      <title>거리공간에서 연속함수의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-continuous-functions-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-continuous-functions-in-metric-space/</guid>
      <description>**정리 1 두 함수 $f$, $g$가 거리 공간 $X$에서 복소수 값을 갖는 함수라고 하자. $$ f:X \to \mathbb{C},\quad g:X \to \mathbb{C} $$ 두 함수가 연속이면 $f+g$, $fg$, $f/g$도 연속이다. 단, 마지막 경우에서는 $g(x)\ne 0$인 $x\in X$에 대해서만 성립한다.**정리 2 $f_{1}$, $f_{2}$, $\cdots$, $f_{k}$가 각각 거리공간 $X$에서 실수값을 갖는 함수라고 하자. 그리고 $\mathbf{f}$를 아래</description>
    </item>
    
    <item>
      <title>거리공간에서 연속함수일 동치 조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-continuous-function-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-continuous-function-in-metric-space/</guid>
      <description>**정리 1 두 거리공간 $(X,d_{X})$, $(Y,d_{Y})$에 대해서, $E\subset X$이고 $p \in E$, $f : E \to Y$라고 하자. 그러면 아래의 세 조건은 동치이다.$(a1)$ $f$가 $p$에서 연속이다.$(b1)$ $ \lim \limits_{x \to p} f(x)=f(p)$이다.$(c1)$ $\lim \limits_{n\to\infty} p_{n}=p$인 $\left\{ p_{n} \right\}$에 대해서, $\lim \limits_{n\to\infty} f(p_{n})=f</description>
    </item>
    
    <item>
      <title>거리공간에서 최대최소 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-extreme-value-theorem-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-extreme-value-theorem-in-metric-space/</guid>
      <description>위상 공간에서 최대최소 정리**최대최소 정리 $X$를 컴팩트 거리공간, $f : X \to \mathbb{R}$을 연속이라고 하자. 그리고 $$ M = \sup \limits_{x\in X} f(x),\quad m=\inf \limits_{x \in X}f(x) $$ 라고 하자. 그러면 $$ M=f(p),\quad m=f(q) $$ 를 만족하는 $q,p\in X$가 존재한다. 다르게 표현하면: 모든 $x$에 대해서 $$ f(q)\le f(x) \le f(p) $$ 를 만족하는 $q,p \in X$가 존재한다.*컴팩트라는 조건은 빠지면 안된다</description>
    </item>
    
    <item>
      <title>거리공간에서 컴팩트인 조건의 중요성</title>
      <link>https://freshrimpsushi.github.io/posts/1728/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1728/</guid>
      <description>해석학의 많은 정리에서 컴팩트를 필요조건으로 요구한다 (참고1, 참고2, 참고3, 참고4). 증명 과정에서 컴팩트하다는 가정을 쓰기 때문에 &amp;lsquo;컴팩트하면 된다&amp;rsquo;는 것은 당연히 받아들이겠지만, &amp;lsquo;컴팩트가 아니면 안된다&amp;rsquo;는 것에 의문이 생길 수 있다. 만약 컴팩트하다는 조건이 없으면 아래와</description>
    </item>
    
    <item>
      <title>거리공간에서 함수의 극한</title>
      <link>https://freshrimpsushi.github.io/posts/limits-of-functions-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limits-of-functions-in-metric-space/</guid>
      <description>**정의 $(X,d_{X})$, $(Y,d_{Y})$를 거리 공간이라고 하자. $E\subset X$이고 $f: E\rightarrow Y$이고 $p$가 $E$의 집적점이라고 하자. 그러면 모든 양수 $\varepsilon$에 대해서 $$ x \in E \ &amp;amp; \ d_{X}(x,p)&amp;lt;\delta \implies d_{Y}(f(x),q) &amp;lt;\varepsilon $$ 를 만족시키는 $\delta&amp;gt;0$가 존재할 때, $$ f(x)\rightarrow q\ \mathrm{as}\ x\to p $$ 혹은 $$ \lim \limits_{x\to p}f(x)=q $$ 라고 표현하고 $f$는 $p$에서 **극한*</description>
    </item>
    
    <item>
      <title>거리공간에서 함수의 극한의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-limits-of-functions-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-limits-of-functions-in-metric-space/</guid>
      <description>**정리 1 $(X,d)$는 거리공간, $E\subset X$는 부분집합, $p$는 $E$의 집적점이라고 하자. 그리고 $E$에서 정의된 두 복소수값 함수 $f:E\to \mathbb{C}$, $g: E\to \mathbb{C}$가 주어졌다고 하자. 그리고 두 함수가 각각 $p$에서 아래와 같은 극한을 갖는다고 하자. $$ \lim \limits_{x \to p}f(x)=A\quad &amp;amp; \quad \lim \limits_{x \to p}g(x)=B \tag{1} $$ 그러면$ (a)$ $\lim \limits_{x \to p}(f+g)(x)=A+B $$ (b)$ $\lim \limits_{x \to p}(fg)(x)=AB $$ (c)$ $\lim \limits_{x \to p}\left( \frac{f}{g}</description>
    </item>
    
    <item>
      <title>보렐-르벡 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-borel-lebesgue-theorem/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-borel-lebesgue-theorem/</guid>
      <description>거리 공간 $(X, \rho)$ 에 대해 다음은 모두 동치다.(1) $X$ 는 컴팩트 공간이다.(2) $X$ 는 시퀀셜리 컴팩트 공간이다.(3) $X$ 는 완비 공간이고 완전 유계 공간이다.* 거리 공간 $X$ 가 **시퀀셜리 컴팩트**Sequentially Compact 공간이라는 것은 $X$ 의 모든 시퀀스가 $X$ 의 한 점으로 수렴하는 서브 시퀀스를 갖는 공간이라는 뜻이다.보렐-르벡 정리는 거</description>
    </item>
    
    <item>
      <title>완비 거리 공간의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-complete-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-complete-metric-space/</guid>
      <description>$(X,d)$ 가 거리 공간이고 $K \subset X$ 라 하자.[1] $K$ 는 완비 부분 공간 $\iff$ $X$ 에서 $K$ 가 닫힌 집합**[2]** $K$ 는 완전 유계 공간 $\iff$ $X$ 에서 닫힌 집합 $K$ 는 컴팩트 완비 거리 공간은 완비성을 가지는 거리 공간이라는 점에서 어지간한 상식적 성질을 다 갖추었다고 볼 수 있는 공간이다. 여기서 놈드 벡터 스페이스가 되면 바나흐 공간, 거기에 내적까지 정의되면 힐베르트 공간</description>
    </item>
    
    <item>
      <title>컴팩트 거리 공간에서 연속인 전단사 함수의 역함수는 연속임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-inverse-function-of-continuous-bijection-in-compact-metric-space-is-continuous/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-inverse-function-of-continuous-bijection-in-compact-metric-space-is-continuous/</guid>
      <description>**정리 $X$를 컴팩트 거리공간, $Y$를 거리공간이라고 하자. $f : X \to Y$가 전단사인 연속함수라고 하자. 그러면 아래와 같이 정의되는 $f$의 역함수 $f^{-1}$는 전단사이고 연속이다. $$ f^{-1} (f(x))=x, \quad x\in X $$ *컴팩트라는 조건은 빠지면 안된다거리공간에서 연속일 동치 조건두 거리공간 $(X,d_{X})$, $(Y,d_{Y})$에 대해서, $f : X \to Y</description>
    </item>
    
    <item>
      <title>컴팩트 거리공간에서 연속 함수는 균등 연속임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/continuous-function-is-uniformly-continuous-in-compact-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuous-function-is-uniformly-continuous-in-compact-metric-space/</guid>
      <description>**정리 $(X,d_{X})$가 컴팩트 거리공간, $(Y,d_{Y})$가 거리공간, $f:X\to Y$가 연속이라고 하자. 그러면 $f$는 $X$에서 균등연속이다.*컴팩트라는 조건은 빠지면 안된다. 증명 임의의 양수 $\varepsilon &amp;gt;0$가 주어졌다고 하자. 그러면 $f$가 연속이라고 가정했으므로 정의에 의해, 각각의 점 $p\in X$에 대해서 아래의 식</description>
    </item>
    
    <item>
      <title>디리클레 에타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/dirichlet-eta-function/</link>
      <pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichlet-eta-function/</guid>
      <description>다음과 같이 정의된 함수 $\eta : \mathbb{C} \to \mathbb{C}$ 를 디리클레 에타 함수 라고 한다. $$ \eta (s) := \sum_{n \in \mathbb{N}} (-1)^{n-1} n^{-s} $$ 디리클레 에타 함수는 교대 리만 제타 함수로 정의된다.**[1] 리만 제타 함수와의 관계** : $$ \eta(s) = \left( 1 - 2^{1-s} \right) \zeta(s) $$ [2] 감마 함수와의 관계 : $\Re (s) &amp;gt; 1$ 이면 $$ \eta (s) \Gamma (s) = \mathcal{M} \left[ {{ 1 } \over { e^{x} + 1 }} \right] (s) = \int_{0}^{\infty} {{ x^{s-1} } \over { e^{x} + 1 }} dx $$ * $\Re(z)$ 는 복소수 $z \in \mathbb{C}$ 의 실수</description>
    </item>
    
    <item>
      <title>트랜슬레이션 모듈레이션 다일레이션의 역작용소</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-of-translation-modulation-dilation/</link>
      <pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-of-translation-modulation-dilation/</guid>
      <description>$T_{a}, E_{b}, D_{c}$ 는 유니터리며, 역작용소는 다음과 같다.**[1] $$ T_{a}^{-1} = T_{-a} = \left( T_{a} \right)^{ * } $$ **[2] $$ E_{b}^{-1} = E_{-b} = \left( E_{b} \right)^{ * } $$ **[3] $$ D_{c}^{-1} = D_{1/c} = \left( D_{c} \right)^{ * } $$ $T_{a}, E_{b}, D_{c}$ 는 각각 $L^{2} $ 에서 정의된 트랜슬레이션, 모듈레이션, 다일레이션이다. 증명[1] $t := x - a$ 와 같이 치환하면 $$ \begin{eqnarray*} \left&amp;lt; T_{a} f , g \right&amp;gt; &amp;amp;=&amp;amp; \int_{-\infty}^{\infty} f \left( x - a \right) \overline{g \left( x \right)} dx \\ &amp;amp;=&amp;amp; \int_{-\infty}^{\infty} f \left( t \right) \overline{g \left( t + a \right)} dt \\ &amp;amp;=&amp;amp; \left&amp;lt;</description>
    </item>
    
    <item>
      <title>거리공간에서 수열의 수렴과 성질</title>
      <link>https://freshrimpsushi.github.io/posts/convergent-sequences-in-metric-space/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergent-sequences-in-metric-space/</guid>
      <description>$\left\{ p_{n} \right\}$이 거리 공간 $(X,d)$의 점들의 수열이라고 하자. 아래의 조건을 만족하는 점 $p \in X$가 존재하면 수열 $\left\{ p_{n} \right\}$이 $p$로 **수렴한다** 고 말하고 $p_{n} \rightarrow p$ 혹은 $\lim \limits_{n\to \infty}p_{n}=p$로 나타낸다. $$ \forall \varepsilon &amp;gt;0,\ \exists N\in \mathbb{N}\ \mathrm{s.t}\ n\ge N \implies d(p_{n},p)&amp;lt;\varepsilon $$ $\left\{ p_{n} \right\}$이 수렴하지 않으면 **발산한</description>
    </item>
    
    <item>
      <title>거리공간에서 집합의 지름</title>
      <link>https://freshrimpsushi.github.io/posts/diameter-of-set-in-metric-space/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diameter-of-set-in-metric-space/</guid>
      <description>**정의 $E$를 거리 공간 $(X,d)$의 부분집합이라고 하자. 그리고 $S$를 다음과 같다고 하자. $$ S=\left\{ d(p,q) : \forall p, q \in E\right\} $$ 그러면 $S$의 최소 상계 $\sup S$를 $E$의 지름이라고 부르고 $\mathrm{diam\ } E$로 표기한다.$\left\{ p_{n} \right\}$이 거리공간 $X$에서의 수열, $E_{N}=\left\{ p_{N},p_{N+1},p_{N+2},\cdots \right\}$라고 하자. 그러면 코시 수열과 지</description>
    </item>
    
    <item>
      <title>거리공간에서 코시수열과 완비</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-sequence-and-complete-in-metric-space/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-sequence-and-complete-in-metric-space/</guid>
      <description>**정의 $\left\{ p_{n} \right\}$을 거리 공간 $(X,d)$의 점들의 수열이라고 하자. 모든 양수 $\varepsilon$에 대해서 $$ n\ge N,\ m\ge N \implies d(p_{n},p_{m})&amp;lt;\varepsilon $$ 이 성립하는 양수 $N$이 존재하면 $\left\{ p_{n} \right\}$을 코시 수열이라고 부른다.**정** **의 거리 공간 $X$의 모든 코시 수열이 $X$의 점으로 수렴하면 $X$를 완비 공간이라</description>
    </item>
    
    <item>
      <title>하이네-보렐 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-heine-borel-theorem/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-heine-borel-theorem/</guid>
      <description>실수의 부분집합 $E \subset \mathbb{R}$ 에 대해 $\displaystyle E \subset \bigcup_{\alpha \in \forall} ( x_{\alpha} , y_{\alpha}) $ 을 만족하는 개구간의 집합 $\mathcal{O} = \left\{ ( x , y ) , | , x &amp;lt; y \right\} $ 을 $E$ 의 **오픈 커버링**Open Covering 이라고 한다. 이러한 $E$ 가 **컴팩트**Compact 라는 것은 $E$ 의 모든 오픈 커버링 $\mathcal{O}$ 에 대해 $\displaystyle E \subset \bigcup_{i =1}^{m} O_{i}$ 를 만족하는 $\mathcal{O}$ 의 유한부분집합 $\left\{ O_{1} , O_{2} , \cdots , O_{m} \right\} $ 가 존재한다는 것과 동치다</description>
    </item>
    
    <item>
      <title>리만 제타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/riemann-zeta-function/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riemann-zeta-function/</guid>
      <description>다음과 같이 정의된 함수 $\zeta : \mathbb{C} \setminus \left\{ 1 \right\} \to \mathbb{C} $ 를 리만 제타 함수 라고 한다. $$ \zeta (s) := \sum_{n \in \mathbb{N}} n^{-s} = \prod_{p : \text{prime}} \left( 1- {p^{-s}} \right)^{-1} $$ **[0] 라마누잔 합** : $\displaystyle \sum_{n \in \mathbb{N}} x^{n-1} = {{ 1 } \over { 1-x }}$ 이 $|x| = 1$ 에서도 성립한다는 주장을 받아들인다면 $$ \zeta (0) = 1 + 1 + 1 + 1 + \cdots = - {{ 1 } \over { 2 }} $$ [1] 오렘의 증명 : $\zeta (1)$ 이 정의되지 않는 이유는 다음과 같다. $$ \zeta (1) = \sum_{n \in \mathbb{N}} {{ 1 }</description>
    </item>
    
    <item>
      <title>수렴하는 실수열의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-convergent-realcomplex-sequences/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-convergent-realcomplex-sequences/</guid>
      <description>정의$\left\{ p_{n} \right\}$이 거리 공간 $(X,d)$의 점들의 수열이라고 하자. 아래의 조건을 만족하는 점 $p \in X$가 존재하면 수열 $\left\{ p_{n} \right\}$이 $p$로 **수렴한다** 고 말하고 $p_{n} \rightarrow p$ 혹은 $\lim \limits_{n\to \infty}p_{n}=p$로 나타낸다. $$ \forall \varepsilon &amp;gt;0,\ \exists N\in \mathbb{N}\ \mathrm{s.t}\ n\ge N \implies d(p_{n},p)&amp;lt;\varepsilon $$ **정리 1 $\left\{ s_{n} \right\}$, $\left\{ t_{n} \righ</description>
    </item>
    
    <item>
      <title>유클리드 공간에서 공집합이 아닌 완벽 집합은 비가산임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1712/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1712/</guid>
      <description>정의$(X,d)$가 거리 공간이라고 하자. $p \in X$이고 $E \subset X$라고 하자.$(a)$** 근방 **Neighborhood : $d(q,p)&amp;lt;r$을 만족하는 모든 $q$들을 포함하는 집합을 점 $p$의 근방이라고 정의하고 $N_{r}(p)$라고 표기한다. 이때 $r$을 $N_{r}(p)$의 반경이라고 부른다.$(b)$ **집적점 **Limit Point : $p</description>
    </item>
    
    <item>
      <title>거리공간에서 일반화된 칸토어의 축소 구간 정리</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-cantors-nested-intervals-theorem-in-metric-space/</link>
      <pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-cantors-nested-intervals-theorem-in-metric-space/</guid>
      <description>$\mathbb{R}$에서 칸토어의 축소 구간 정리**거리공간으로 일반화된 칸토어의 축소 구간 정리 $(X,d)$가 거리공간이라고 하자. $K_{n}\subset X (n=1,2,\cdots)$는 공집합이 아닌 컴팩트 부분집합이다. 이때 $\left\{ K_{n} \right\}$이 $$ K_{n}\supset K_{n+1}\ (n=1,2,\cdots) $$ 를 만족하면 $\bigcap _{i=1}^{\infty} K_{n} \ne \varnothing$이다$\left\{ K_{n} \</description>
    </item>
    
    <item>
      <title>모든 k-cell은 컴팩트임을 증명  유클리드 공간에서 컴팩트일 동치 조건</title>
      <link>https://freshrimpsushi.github.io/posts/1711/</link>
      <pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1711/</guid>
      <description>**$k-\mathrm{cell}$ $a_i,b_i \in \mathbb{R} (1\le i \le k)$에 대해서 집합 $I=[a_{1},b_{1}] \times [a_{2},b_{2}]\times \cdots \times [a_{k},b_{k}]$를 $k-$셀이라 한다. 여기서 $\times$는 집합의 데카르트 곱이다.**정리 1 $\mathbb{R}$상의 폐구간들의 수열 $\left\{ I_{n} \right\}$이 $I_{n}\supset I_{n+1}\ (n=1,2,\cdots)$를 만족한다고 하자. 그러면 $\bigcap_{i=1}^{\infty}I_{n}\ne \varnothing$이</description>
    </item>
    
    <item>
      <title>L2 공간의 트랜슬레이션 모듈레이션 다일레이션</title>
      <link>https://freshrimpsushi.github.io/posts/translation-modulation-dilation-on-l2/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/translation-modulation-dilation-on-l2/</guid>
      <description>1. $a \in \mathbb{R}$ 에 대해 다음과 같이 정의된 $T_{a} : L^{2} \to L^{2}$ 를 **트랜슬레이션** 이라 한다. $$ \left( T_{a} f \right) (x) := f(x-a) $$ **2.** $b \in \mathbb{R}$ 에 대해 다음과 같이 정의된 $E_{b} : L^{2} \to L^{2}$ 을 **모듈레이션** 이라 한다. $$ \left( E_{b} f \right) (x) := e^{2 \pi i b x} f(x) $$ **3.** $c &amp;gt; 0$ 에 대해 다음과 같이 정의된 $D_{c} : L^{2} \to L^{2}$ 을 **다일레이션** 이라 한다. $$ \left( D_{c} f \right) (x) := {{ 1 } \over { \sqrt{c} }} f \left( {{ x } \over {</description>
    </item>
    
    <item>
      <title>수론에서의 p-진수 p-adic Number</title>
      <link>https://freshrimpsushi.github.io/posts/1707/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1707/</guid>
      <description>**$p$-진수12 소수 $p$ 와 정수 $a \in \mathbb{Z}$ 에 대해 다음과 같이 정의된 $v_{p} $ 를 $a$ 의 **$**p$-진수 부치$p$-adic Valuation 라고 한다. $$ v_{p} (a) := \sup \left\{ e \in \mathbb{Z} : p^{e} \mid a \right\} $$ **[0]** 모든 소수 $p$ 에 대해 $$ v_{p} (0) = \infty $$ **[1] $$ v_{p} (xy) = v_{p}(x) + v_{p}(y) $$ **[2] $$ v_{p} (x+y) \ge \min \left\{ v_{p} (x) , v_{p} (y) \right\} $$ **[3]** $n \in \mathbb{N}$, $x , y \in \mathbb{Z}$, 소수 $p$ 가 $$ \gcd (n,p) = 1 \\ p \mid (x \mp y) \\ p \nmid x \\ p \nmid y $$ 를 만족</description>
    </item>
    
    <item>
      <title>지수승강 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lifting-the-exponent-lemma-lte-lemma/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lifting-the-exponent-lemma-lte-lemma/</guid>
      <description>$n \in \mathbb{N}$, $x , y \in \mathbb{Z}$, 소수 $p \ne 2$ 가 $$ \gcd (n,p) = 1 \\ p \mid (x - y) \\ p \nmid x \\ p \nmid y $$ 를 만족하면 $$ v_{p} \left( x^{n} - y^{n} \right) = v_{p} \left( x - y \right) + v_{p} (n) $$ $v_{p} (a)$ 는 $a$ 의 $p$-진수 부치를 의미한다.* 본 포스트는 &amp;lsquo;깁gip&amp;rsquo;님의 요청으로 작성되었다.**Strategy** : $p$-진수 부치의 성질들에서 자연스럽게 연역된다. 그</description>
    </item>
    
    <item>
      <title>거리공간에서 컴팩트</title>
      <link>https://freshrimpsushi.github.io/posts/compactness-in-metric-space/</link>
      <pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compactness-in-metric-space/</guid>
      <description>위상공간에서 컴팩트**오픈 커버 open cover 거리공간 $(X,d)$와 부분 집합 $E\subset X$가 주어졌다고 하자. 아래의 식을 만족하는 $X$의 열린 집합들의 집합 $\left\{ O_{\alpha} \right\}$를 $E$의 **오픈 커버** 라고 한다. $$ E\subset \bigcup _{\alpha} O_{\alpha} $$ 오픈 커버의 부분 집합을 부분 커버라 부른다. 특히 원소가 유한개인 부분 커버를 유한 부분 커버라 부른다.**컴팩트</description>
    </item>
    
    <item>
      <title>거리공간에서 컴팩트 집합과 닫힌 집합의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-between-compact-set-and-closed-set-in-metric-space/</link>
      <pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-between-compact-set-and-closed-set-in-metric-space/</guid>
      <description>**정리 1 거리공간 $(X,d)$의 컴팩트 부분 집합 $K$는 닫힌 집합이다.보조정리집합 $E$가 열린 집합인 것은 $E^{c}$가 닫힌 집합인 것과 동치이다. 증명 $K$를 거리공간 $X$의 컴팩트 부분 집합이라고 하자. 이제 $K^{c}$가 오픈임을 보이고자 한다. 그러면 보조정리에 의해 $K$는 닫힌 집합이다. $K^{c}$가 오</description>
    </item>
    
    <item>
      <title>F-분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-f-distribution/</link>
      <pubDate>Sat, 15 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-f-distribution/</guid>
      <description>$X \sim F ( r_{1} , r_{2})$ 면 $$ E(X) = {{ r_{2} } \over { r_{2} - 2 }} \qquad , r_{2} &amp;gt; 2 \\ \text{Var}(X) = {{ 2 d_{2}^{2} (d_{1} + d_{2} - 2) } \over { d_{1} (d_{2} -2)^{2} (d_{2} - 4) }} \qquad , r_{2} &amp;gt; 4 $$ **Strategy** : F-분포 역시 카이제곱분포와 비슷하게 적률 공식이 알려져 있어, 이 공식들을 이용한다.F-분포의 적률$X \sim F(r_{1} , r_{2})$ 이고 $\displaystyle X = {{ X_{1} } \over { X_{2} }}$ 와 같이 나타낼 수 있다고 하자. $X_{1}$ 과 $X_{2}$ 가 각각 자유도 $d_{1}, d_{2}$ 인 카이제곱 분포를 따</description>
    </item>
    
    <item>
      <title>거리공간에서 상대적으로 열린 집합</title>
      <link>https://freshrimpsushi.github.io/posts/relatively-open-set/</link>
      <pubDate>Sat, 15 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relatively-open-set/</guid>
      <description>*대한수학회에서는 $E\ \mathrm{is} \mathit{open\ relative\ to}\ Y$를 $E$는 $Y$에 대해서 상대적으로 열려있다고 번역하는데 아래에서 설명할 내용의 생각해봤을 때 $\mathit{open\ relative\ to}$는 &amp;lsquo;~에 대해서 상대적으로 열려있다&amp;rsquo;가 아니라 &amp;lsquo;~에 관련되어서/연관되어서 열려있다&amp;rsquo;고 번역하는 것이 맞는 듯 하다. $(X,d)$가</description>
    </item>
    
    <item>
      <title>거리공간에서 열린 집합과 닫힌 집합의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/1702/</link>
      <pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1702/</guid>
      <description>정의$(X,d)$가 거리 공간이라고 하자. $p \in X$이고 $E \subset X$라고 하자.$(a)$ **근방 **Neighborhood : $d(q,p)&amp;lt;r$을 만족하는 모든 $q$들을 포함하는 집합을 점 $p$의 근방이라고 정의하고 $N_{r}(p)$라고 표기한다. 이때 $r$을 $N_{r}(p)$의 반경이라고 부른다.$(b)$ **집적점 **Limit Point : $p</description>
    </item>
    
    <item>
      <title>앤더슨-리빙스톤 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-anderson-livingston-theorem/</link>
      <pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-anderson-livingston-theorem/</guid>
      <description>$R$ 이 유니티 $1$ 을 가지는 가환 링이고 그 영인자들의 집합을 $Z(R)$ 라 하면 그 영인자 그래프 $\Gamma (R)$ 는 연결 그래프고 $\text{diam}(\Gamma(R)) \le 3$ * $\text{diam}$ 은 그래프의 지름을 의미한다.앤더슨 과 리빙스톤 은 영인자 그래프의 연구에서 중요한 업적을 남겼으며, 특히 그래프의 연결성과 지름의 상한값을 특정하는 이 정리를 앤더슨-리빙스톤 정리 라 부르기도 한다. 증명 $x,y \in Z(R) (x \ne y)$ 이라 하자.C</description>
    </item>
    
    <item>
      <title>거리공간에서 정의되는 여러가지 개념과 관련된 정리</title>
      <link>https://freshrimpsushi.github.io/posts/1700/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1700/</guid>
      <description>**정의 $(X,d)$가 거리 공간이라고 하자. $p \in X$이고 $E \subset X$라고 하자.$(a)$ **근방 **Neighborhood : $d(q,p)&amp;lt;r$을 만족하는 모든 $q$들을 포함하는 집합을 점 $p$의 근방이라고 정의하고 $N_{r}(p)$라고 표기한다. 이때 $r$을 $N_{r}(p)$의 반경이라고 부른다. 거리를 나타내는게 중요하지 않</description>
    </item>
    
    <item>
      <title>거리공간에서 폐포와 도집합에 대한 성질</title>
      <link>https://freshrimpsushi.github.io/posts/1701/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1701/</guid>
      <description>정의$(X,d)$가 거리 공간이라고 하자. $p \in X$이고 $E \subset X$라고 하자.$(a)$ **근방 **Neighborhood : $d(q,p)&amp;lt;r$을 만족하는 모든 $q$들을 포함하는 집합을 점 $p$의 근방이라고 정의하고 $N_{r}(p)$라고 표기한다. 이때 $r$을 $N_{r}(p)$의 반경이라고 부른다.$(b)$ **집적점 **Limit Point : $p</description>
    </item>
    
    <item>
      <title>산술 함수의 부분합에 대한 일반화된 디리클레 곱 표현</title>
      <link>https://freshrimpsushi.github.io/posts/1607/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1607/</guid>
      <description>$h = f*g$ 인 산술 함수 $f,g,h$ 에 대해 $F, G, H$ 를 다음과 같이 정의하자. $$ F (x) := \sum_{n \le x} f(x) \\ G (x) := \sum_{n \le x} g(x) \\ H (x) := \sum_{n \le x} h(x) $$ 그러면 $$ H = f \circ G = g \circ F $$ * 연산 $\circ$ 는 일반화된 컨볼루션을 의미한다. 다시 말해, $$ H(x) = \sum_{n \le x} f(n) G \left( {{ x } \over { n }} \right) = \sum_{n \le x} g(n) F \left( {{ x } \over { n }} \right) $$ 증명 $$ U(x) := \begin{cases} 0 &amp;amp;, 0 &amp;lt; x &amp;lt; 1 \\ 1 &amp;amp;, 1 \le x\end{cases} $$ 위와 같이 $x \in (0,1)$ 에</description>
    </item>
    
    <item>
      <title>F-분포</title>
      <link>https://freshrimpsushi.github.io/posts/f-distribution/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/f-distribution/</guid>
      <description>자유도 $r_{1}, r_{2} &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $F \left( r_{1} , r_{2} \right)$ 를 **F-분포** 라고 한다. $$ f(x) = {{ 1 } \over { B \left( r_{1}/2 , r_{2} / 2 \right) }} \left( {{ r_{1} } \over { r_{2} }} \right)^{r_{1} / 2} x^{r_{1} / 2 - 1} \left( 1 + {{ r_{1} } \over { r_{2} }} x \right)^{-(r_{1} + r_{2}) / 2} \qquad , x \in (0, \infty) $$ * $B(r_{1} / 2, r_{2}/2)$ 는 베타 함수를 의미한다.**[1] 적률 생성 함수** : F-분포는 적률 생성 함수가 존</description>
    </item>
    
    <item>
      <title>리만-스틸체스 적분 가능한 함수는 적분 구간을 나누어도 적분 가능함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1695/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1695/</guid>
      <description>리만 적분은 리만-스틸체스 적분에서 $\alpha(x)=x$인 경우이므로 리만 적분에 대한 증명도 아래와 같다.**정리 함수 $f$가 $[a,b]$에서 리만(-스틸체스)적분 가능하다고 하자. 그리고 $a&amp;lt;c&amp;lt;b$라고 하자. 그러면 $f$는 $[a,c]$와 $[c,b]$에서도 적분이 가능하며 그 적분값의 합은 $</description>
    </item>
    
    <item>
      <title>적분 가능한 함수와 절댓값</title>
      <link>https://freshrimpsushi.github.io/posts/1697/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1697/</guid>
      <description>리만 적분은 리만-스틸체스 적분에서 $\alpha(x)=x$인 경우이므로 리만 적분에 대한 증명도 아래와 같다..**정리 함수 $f$가 구간 $[a,b]$에서 리만(-스틸체스) 적분 가능하다고 하자. 그러면$(a)$ $\left|f\right|$도 $[a,b]$에서 적분 가능하다. 또한 아래의 부등식이 성립한다. $$ \left|\int_{a}^{b}fd\alpha \right|</description>
    </item>
    
    <item>
      <title>함수의 대소 관계에 따른 적분의 대소 관계</title>
      <link>https://freshrimpsushi.github.io/posts/1696/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1696/</guid>
      <description>리만 적분은 리만-스틸체스 적분에서 $\alpha(x)=x$인 경우이므로 리만 적분에 대한 증명도 아래와 같다..**정리 두 함수 $f_{1}$, $f_{2}$가 구간 $[a,b]$에서 리만(-스틸체스) 적분 가능하다고 하자. 또한 $[a,b]$에서 $f_{1} \le f_{2}$라고 하자. 그러면 아래의 부등식이 성립한다. $$ \int_{a}^{b}f_{1}d\alpha \le \int_{a}^{b}f_{2}d\alpha $$ **보조정리1 리</description>
    </item>
    
    <item>
      <title>해석학에서의 미분적분학의 기본정리 1 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1698/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1698/</guid>
      <description>미적분학에서의 증명 (Calculus ver.)$f$가 구간 $[a,b]$에서 리만 적분 가능한 함수라고 하자. 그리고 $a\le x \le b$에 대해서 $F$를 아래와 같이 두자. $$ F(x) = \int {a} ^{x} f(t)dt $$ $(a)$ 그러면 $F$는 $[a,b]$에서 연속이다.$(b)$ 만약 $f$가 $x{0}\in [a,b]$에서 연속이면, $F$는 $x_{0}$에서 미분 가능하고 $F&#39;(x_{0</description>
    </item>
    
    <item>
      <title>케플러 제1 법칙 타원 궤도의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/keplers-first-law-the-law-of-ellipses/</link>
      <pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/keplers-first-law-the-law-of-ellipses/</guid>
      <description>**케플러 제1 법칙: 타원 궤도의 법칙 행성의 공전 궤도는 태양을 초첨으로하는 타원이다.케플러의 행성 운동 법칙 중 첫번째 법칙이다. 증명 중심력 $F$에 의해 운동하는 입자의 궤도 방정식은 아래와 같다.$$ \frac{ d ^{2}u}{ d \theta^{2} } + u=-\frac{1}{ml^{2}u^{2}}F(u^{-1}) $$ 이때 $u={\textstyle \frac{1}{r}}$이다. 우리는 중력에 대해서 위 문제를 풀고 싶으므로 $F=-\frac{GMm</description>
    </item>
    
    <item>
      <title>케플러 제3 법칙 조화 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/keplers-third-law-the-harmonic-law/</link>
      <pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/keplers-third-law-the-harmonic-law/</guid>
      <description>**케플러 제3 법칙: 조화 법칙 행성의 공전 주기의 제곱은 공전 궤도의 장반경의 세제곱에 비례한다.케플러의 행성 운동 법칙 중 세번째 법칙이다. 행성의 공전 궤도를 원으로 근사할 경우 &amp;lsquo;공전 주기의 제곱은 태양과의 거리의 세제곱에 비례한다&amp;rsquo;가 된다. 증명 행성의 공전 궤도의 넓이를 $A$, 면적 속도를 $\dot {A}$라고 하자. 케플</description>
    </item>
    
    <item>
      <title>제2 종 타원 적분</title>
      <link>https://freshrimpsushi.github.io/posts/completeincomplete-elliptic-integral-of-the-second-kind/</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/completeincomplete-elliptic-integral-of-the-second-kind/</guid>
      <description>아래의 적분을 제2 종 완전 타원 적분 이라고 한다. $$ E(k)=\int_{0}^{{\textstyle \frac{\pi}{2}}}\sqrt{1-k^{2} \sin ^{2} \theta} d\theta $$ 아래의 적분을 **제2 종 불완전 타원적분** 이라고 한다. $$ E(\phi, k)=\int_{0}^{\phi}\sqrt{1-k^{2} \sin ^{2} \theta}d\theta $$ 위 두 적분의 이름이 타원 적분인 것은 타원의 둘레를 구하는 과정에서 나왔기 때문이다. 타원 $$ \frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}=1,\quad (0&amp;lt;a&amp;lt;b) $$ 가 주어지면 타원의 둘레는 $$ 4bE(k),\quad k^{2}=\frac{b^{2}-a^{2} }{b^{2}} $$ 와 같이 구할 수 있다. $k$ 값에 따른 제2 종 완전 타원 적분의 그래프는 아래</description>
    </item>
    
    <item>
      <title>타원의 둘레</title>
      <link>https://freshrimpsushi.github.io/posts/circumference-of-ellipse/</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/circumference-of-ellipse/</guid>
      <description>대부분의 자료에서 제2 종 타원적분이 어떻게 유도되는지 그 과정이 자세하게 나와있지 않다. 있더라도 틀린 경우가 많아1 &amp;lsquo;정확하고&amp;rsquo; &amp;lsquo;자세한&amp;rsquo; 내용을 직접 작성했다. 참고로 보아스 수리물리학 3판의 내용도 틀렸다.우선 타원위의 점 $P=(x,y)$를 각도를 통해 표현해보자. 다만 이 때의</description>
    </item>
    
    <item>
      <title>독립인 두 감마 분포에서 베타 분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/1596/</link>
      <pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1596/</guid>
      <description>두 확률 변수 $X_{1},X_{2}$ 가 독립이고 $X_{1} \sim \Gamma ( \alpha_{1} , 1)$, $X_{2} \sim \Gamma ( \alpha_{2} , 1)$ 이라 하면 $$ {{ X_{1} } \over { X_{1} + X_{2} }} \sim \text{beta} \left( \alpha_{1} , \alpha_{2} \right) $$ 두 데이터가 감마 분포를 따르고 독립이라면, 그 합계를 계산했을 때의 비율을 분포이론으로 설명하는데 쓰일 수 있을지도 모른다. 특히 감마분포는 여러가지 확률분포를 비교적 자유롭게 넘나들 수 있으므로 팩트로써는 알아두는 게 좋다.**Str</description>
    </item>
    
    <item>
      <title>극 좌표계에서 초점이 원점인 타원의 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/equations-of-ellipses-in-polar-coordinates/</link>
      <pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equations-of-ellipses-in-polar-coordinates/</guid>
      <description>극 좌표계에서 타원의 방정식은 아래와 같다. $$ r=\frac{\alpha}{1+\epsilon \cos \theta}\tag{a} $$ 혹은 $$ r=\frac{b^{2}/a}{1+\frac{\sqrt{a^{2}-b^{2}}}{a}\cos\theta} \tag{b} $$ 이때 $\alpha$는 통경, $\epsilon$은 이심률, $a$는 장반경, $b$는 단반경이다.두 식과 증명은 본질적으로 같으나 $(b)$의 식과 증명은 고등학교에서 배우는 지식을 벗어나지 않는다는 특징이 있다. 증명 $(a)$ 타원의 정의는 두 초점까지의 거리의 합이 일정</description>
    </item>
    
    <item>
      <title>타원</title>
      <link>https://freshrimpsushi.github.io/posts/ellipse/</link>
      <pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ellipse/</guid>
      <description>**타원 두 초점까지의 거리의 합이 일정한 점들의 집합을 타원이라고 한다.$\cdot$ $F$, $F&#39;$ 초점$(\mathrm{focus}) $$ \cdot$ $a$, $b$ 장반경과 단반경$(\mathrm{semimajor\ axis,\ semiminor\ axis})$: $b=\sqrt{1-\epsilon^{2}}a$가 성립한다.$\cdot$ $\epsilon$ 이심률$(\mathrm{ecc</description>
    </item>
    
    <item>
      <title>힐베르트 공간의 프레임</title>
      <link>https://freshrimpsushi.github.io/posts/frame-in-hilbert-space/</link>
      <pubDate>Sun, 26 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/frame-in-hilbert-space/</guid>
      <description>힐베르트 공간 $H$ 의 시퀀스 $\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}}$ 에 대해 다음을 만족하는 $A,B &amp;gt; 0$ 이 존재하면 $\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}}$ 을 프레임이라 부르고, 특히 $A = B$ 일 때 이 프레임이 타이트Tight하다고 말한다. $$ A \left| \textbf{v} \right|^{2} \le \sum_{k \in \mathbb{N}} \left| \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt; \right|^{2} \le B \left| \textbf{v} \right|^{2} \qquad , \textbf{v} \in H $$ 프레임은 베셀 시퀀스와 달리 $A$ 가 존재해서 $\textbf{v}$ 를 위아래로 가두어준다. 특히 $\left\{ \textbf{e}_{k} \right\}_{k \in \mathbb{N}}$ 이 $H$ 의 정규직교 기저면</description>
    </item>
    
    <item>
      <title>함수의 서포트와 연속함수 공간의 클래스</title>
      <link>https://freshrimpsushi.github.io/posts/support-and-classes-of-continuous-functions/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/support-and-classes-of-continuous-functions/</guid>
      <description>함수공간 $\mathbb{C}^{\mathbb{R}}$ 의 함수 $f : \mathbb{R} \to \mathbb{C}$ 를 생각해보자.**1.** 함수 $f$ 의 서포트란 다음과 같이 함수값이 $0$ 이 아닌 점들의 집합에 클로져를 취한 클로즈 셋이다. $$ \text{supp} f = \overline{\left\{ x \in \mathbb{R} : f(x) \ne 0 \right\}} $$ **2. ** $\text{supp} f$ 가 유계면 $f$ 가 컴팩트 서포트를 갖는다고 말한다.**3. ** $U\Subset V$는 $\overline{U} \subset V$이고 $\overline{U}$가 컴팩트임을 뜻한다. 즉, $\mathrm{supp}(f) \Subset U$</description>
    </item>
    
    <item>
      <title>중심력을 받는 입자의 궤도 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-equation-of-a-particle-in-central-force/</link>
      <pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-equation-of-a-particle-in-central-force/</guid>
      <description>중심력을 받는 질량이 $m$인 입자의 운동 방정식을 극좌표계로 표현하면 아래와 같다. $$ m\ddot{\mathbf{r}}=F(r)\hat{\mathbf{r}} \tag{1} $$ $F(r)$은 입자에 작용하는 중심력이다. 극좌표계에서 가속도는 아래와 같다. $$ \ddot{\mathbf{r}}=\mathbf{a}=\left( \ddot{r}-r\dot{\theta}{}^{2} \right)\hat{\mathbf{r}} +\left(2\dot{r}\dot{\theta}+r\ddot{\theta} \right)\hat{\boldsymbol{\theta}} $$ 따라서 운동 방정식 $(1)$을 성분별로 나눠서 쓰면 아래와 같다. $$ \begin{align*} m\left( \ddot{r}-r\dot{\theta}{}^{2} \right) &amp;amp;= F(r) \tag{2} \\ m\left( 2\dot{r} \dot{\theta} +r\ddot{\theta}\right) &amp;amp;= 0 \end{align*} $$ 이 때 $\frac{1}{r}\frac{ d }{ dt }(r^{2}\dot{\theta})=2\dot{r} \dot{\theta} +r\ddot{\theta}$ 이므로 위의 두번째 식을 아</description>
    </item>
    
    <item>
      <title>두 벡터의 외적의 크기는 두 벡터가 만드는 평행사변형의 넓이와 같다</title>
      <link>https://freshrimpsushi.github.io/posts/1681/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1681/</guid>
      <description>두 벡터 $\mathbf{A}$, $\mathbf{B}$ 사이의 각도가 $\theta$일 때 두 벡터의 외적의 크기는 다음과 같다. $$ \left| \mathbf{A}\times \mathbf{B}\right| =\left|\mathbf{A}\right|\left| \mathbf{B} \right|\sin \theta $$ 그리고 이는 두 벡터가 만드는 평행사변형의 넓이와 같다.**** 증명 두 벡터 $\mathbf{A}=(A_{x},A_{y},A_{z})$, $\mathbf{B}=(B_{x},B_{y},B_{z})$가 위 그림과 같다고 하자. 그러면**Part 1. 평행사변형의 넓이 평행사변형의 넓이는</description>
    </item>
    
    <item>
      <title>케플러 제2 법칙 면적 속도 일정의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/keplers-second-law-equal-areas/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/keplers-second-law-equal-areas/</guid>
      <description>케플러 제2법칙: 면적 속도 일정의 법칙 태양과 행성을 연결하는 선분은 같은 시간동안 같은 면적을 지나간다.면적 속도 일정의 법칙은 케플러의 행성 운동 법칙 중 두번째 법칙이다. 다만 이는 태양과 행성간에서만 일어나는 특별한 법칙이 아니라 중심력에 의해 운동하는 어떤 물체(입자)에 대해서도 성립하는 일반적인 법칙이다.** 증명 중심력장에에서 움직</description>
    </item>
    
    <item>
      <title>타원의 방정식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/1683/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1683/</guid>
      <description>중점이 $(x_{0},y_{0})$이고 장반경이 $a$, 단반경이 $b$인 타원의 방정식은 아래와 같다. $$ \frac{(x-x_{0})^{2}}{a^{2}}+\frac{(y-y_{0})^{2}}{b^{2}}=1 $$ 타원은 두 초점까지의 거리의 합이 일정한 점들의 집합이다. 유도** 위 그림과 같은 타원이 있다고 하자. 타원의 정의에 의해 아래와 같은 방정식을 세울 수 있다. $$ \begin{align*} \overline{F&amp;rsquo;P} +\overline{PF}=&amp;amp;\mathrm{constant} \\ \sqrt{(x+c)^{2}+y^{2}}+\sqrt{(x-c)^{2}+y^{2}}=&amp;amp; \end{align*} $$ 이때 점 $P$가 $A$에 있는 경우를 생각해보면 그 일정한 거</description>
    </item>
    
    <item>
      <title>힐베르트 공간의 정규직교 기저와 유니터리 작용소</title>
      <link>https://freshrimpsushi.github.io/posts/orthonormal-bases-of-hilbert-space-and-unitary-operator/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthonormal-bases-of-hilbert-space-and-unitary-operator/</guid>
      <description>$\left\{ \textbf{e}{k} \right\}{k \in \mathbb{N}}$ 을 $H$ 의 정규직교 기저라고 하자. 그러면 $H$ 의 정규직교 기저는 유니터리 작용소 $U : H \to H$ 에 대해 정확하게 $\left\{ U \textbf{e}{k} \right\}{k \in \mathbb{N}}$ 과 같이 나타난다.이러한 결과를 두고 $H$ 의 모든 정규직교 기저가 유니터리 작용소 $U$ 에 의해 캐릭터라이제이션Characterization 된다고 말한다. 증명 $\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}}$ 도 $H$ 의 정규직교 기저라고 하자. 작용소 $U</description>
    </item>
    
    <item>
      <title>균일한 구 껍질과 떨어진 입자 사이의 중력</title>
      <link>https://freshrimpsushi.github.io/posts/gravitational-force-between-a-uniform-sphere-and-a-particle/</link>
      <pubDate>Tue, 21 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gravitational-force-between-a-uniform-sphere-and-a-particle/</guid>
      <description>전체 질량이 $M$이고 반지름이 $R$인 균일한 구 껍질이 있다고 하자. 그리고 구 껍질의 중심 $O$로부터 $r$만큼 떨어진 곳에 질량이 $m$인 입자가 있다고 하자. 이 때 $R&amp;lt;r$이다. 우선 구껍질 일부분이 입자에 미치는 힘을 구해보자. 위 그림과 같은 구 껍질 띠를 생각해보자. 그러면 껍질 띠의 반지름은 $R\sin \theta$이다. 따라서 껍</description>
    </item>
    
    <item>
      <title>케플러의 행성 운동 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/keplers-laws-of-planetary-motion/</link>
      <pubDate>Tue, 21 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/keplers-laws-of-planetary-motion/</guid>
      <description>제1 법칙: 타원 궤도의 법칙 행성의 공전 궤도는 태양을 초점으로 하는 타원이다.제2 법칙: 면적 속도 일정의 법칙 태양과 행성을 연결하는 선분은 같은 시간동안 같은 면적을 지나간다.**제3 법칙: 조화 법칙 행성의 공전 주기의 제곱은 공전 궤도의 장반경의 세제곱에 비례한다.케플러 법칙은 티코 브라헤, 히파르코스 등의 천문학자들의 관측 기록을 모아 정</description>
    </item>
    
    <item>
      <title>4색 지도 문제</title>
      <link>https://freshrimpsushi.github.io/posts/four-color-map-problem/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/four-color-map-problem/</guid>
      <description>4색 지도 문제 란 어떤 지도든 이웃된 구역이 서로 구별되도록 채색하는데 4가지 색이면 충분한지 묻는 문제다. 지도가 복잡할수록 색은 많아져야할 것 같지만, 바로 옆이랑만 다르면 되기 때문에 생각보다 많은 색이 필요하지는 않다. 예를 들어 다음은 세계지도를 단 $4$가지 색으로 칠한 것이다.역사적으로 4색 지도 문제는 1852년 영국의 식물학자 프랜시</description>
    </item>
    
    <item>
      <title>만유인력의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/law-of-universal-gravity/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/law-of-universal-gravity/</guid>
      <description>만유인력의 법칙은 뉴턴이 1687년에 프린키피아를 통해 발표한 물리 법칙이다. 내용을 간단히 말하자면 &amp;lsquo;모든 물체는 서로 끌어당긴다&amp;rsquo;이다. 이를 자세하게 기술하면 아래와 같다.질량을 가지는 모든 입자는 다른 입자에게 끌어당기는 힘을 작용한다. 이 힘의 크기는 서로 상호작용하는 두 입자의 질량의 곱에 비례하고, 두 입자</description>
    </item>
    
    <item>
      <title>입자계의 운동 에너지</title>
      <link>https://freshrimpsushi.github.io/posts/kinetic-energy-of-a-system/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kinetic-energy-of-a-system/</guid>
      <description>입자계의 선운동량과 각운동량을 정의했던 것처럼 입자계의 운동 에너지 역시 각 입자의 운동에너지의 합으로 자연스럽게 정의할 수 있다. $$ T=\sum \limits {i=1} ^{n} \frac{ 1}{ 2 }m{i}v_{i}^{2} \tag{1} $$ 이제 입자계의 선운동량, 각운동량을 질량중심에 대해서 나타냈던 것과 같은 작업을 할 것이다. 우선 각 입자의 위치 벡터를 아래 그림과 같이 질량 중심에 대한 표현으로 나타내자. $$ \mathbf{r}_{i}=\mathbf{r}_{cm}+\overline{\mathbf{r}}_{i} $$ 이를 시간에</description>
    </item>
    
    <item>
      <title>중심력</title>
      <link>https://freshrimpsushi.github.io/posts/central-force/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/central-force/</guid>
      <description>물체의 위치에 상관없이 물체에 작용하는 힘의 방향이 항상 같은 점을 향할 때 이 힘을 중심력이라 한다. 대표적인 예로 중력이 있다. 지구 그 어디에 있든 간에 우리에게 작용하는 중력은 지구 중심을 향한다. 중심력에 의해 운동하는 입자의 각운동량은 보존되고, 면적 속도가 일정하다는 사실을 수식적으로 보일 수 있다.</description>
    </item>
    
    <item>
      <title>입자계의 각운동량</title>
      <link>https://freshrimpsushi.github.io/posts/angluar-momentum-of-a-system/</link>
      <pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/angluar-momentum-of-a-system/</guid>
      <description>입자계의 선운동량을 각 입자의 선운동량의 합으로 정의했다. 이와 마찬가지로 입자계의 각운동량은 각 입자의 각운동량의 합으로 정의된다. $$ \mathbf{L}=\sum \limits {i=1} ^{n} (\mathbf{r}{i}\times \mathbf{p}_{i}) $$ 토크는 각운동량의 변화율이므로 입자계의 토크는 아래와 같다. $$ \begin{align*} \mathbf{N} &amp;amp;= \frac{d \mathbf{L}}{dt} \\ &amp;amp;= \sum \limits _{i=1} ^{n}(\mathbf{v}_{i}\times \mathbf{p}_{i}) + \sum \limits _{i=1} ^{n}(\mathbf{r}_{i}\times m_{i}\mathbf{a}_{i}) \end{align*} $$ 이때 $\mathbf{p}_{i}=m_{i}\mathbf{v}_{</description>
    </item>
    
    <item>
      <title>가분 힐베르트 공간은 l2 공간과 등거리동형임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1591/</link>
      <pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1591/</guid>
      <description>모든 무한차원 가분 힐베르트 공간 $H$ 는 $l^{2}$ 와 등거리 동형이다.가분성을 가지는 힐베르트 공간이 $l^{2}$ 와 등거리 동형이라는 말은 사실상 힐베르트 공간을 연구할 때 $l^{2}$ 만 연구하면 된다는 말이나 진배 없다. 증명 가분 힐베르트 공간의 그램-슈미트 정규직교화모든 가분 힐베르트 공간은 정규직교기저를 가진다.베셀 부등식의 보조정리$\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}}$ 이</description>
    </item>
    
    <item>
      <title>각운동량과 토크</title>
      <link>https://freshrimpsushi.github.io/posts/angular-momentum-and-torque/</link>
      <pubDate>Fri, 17 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/angular-momentum-and-torque/</guid>
      <description>운동량은 병진 운동하는 물체의 운동 상태를 나태는 물리량이다. 질량이 클수록, 속도가 빠를수록 운동량이 크다. 물리학에서는 물체의 운동이 어떻게 변화하는지에 대해서 관심이 있다. 그래서 물체의 운동상태를 바꾸는 원인인 힘을 운동량의 변화로 표현하는 것이다. $$ \mathbf{F}=\frac{d \mathbf{p}}{dt} $$ 이제 회전 운동에 대해서도 이와 비슷한 물리량을 정의하려고 한다. 회전 운동에서</description>
    </item>
    
    <item>
      <title>5색 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-five-color-theorem/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-five-color-theorem/</guid>
      <description>모든 심플 평면 그래프는 $5$-채색가능하다.이 정리는 4색 문제와 구분하는 의미에서 5색 정리 라는 이름이 붙었다. 역사적으로는 4색 정리를 증명하려고 했지만 증명에 번번히 실패했고, 대신 조금 완화된 팩트로써 증명되었다.Strategy : 수학적 귀납법을 사용한다. $n-1$ 개의 버텍스를 가진 심플 평면 그래프가 모두 $5$-채색가능하다고 가</description>
    </item>
    
    <item>
      <title>뉴턴의 운동 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/newtons-laws-of-motion/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newtons-laws-of-motion/</guid>
      <description>영국의 수학자이자 물리학자인 아이작 뉴턴 $(\mathrm{Issac\ Newton})$은 1687년 프린키피아 $(\mathrm{Principia}$,자연철학의 수학적 원리$)$에서 아래와 같은 운동에 관한 세 가지 법칙을 제시했다.1. 외부의 힘을 받지 않는 물체는 운동 상태를 바꾸지 않는다.2. 운동의 변화는 물체에 작용하는 힘과 비례한다.3. 물체 1</description>
    </item>
    
    <item>
      <title>물리학에서 질량 힘 운동량의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-mass-force-and-momentum-in-physics/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-mass-force-and-momentum-in-physics/</guid>
      <description>**질량 뉴턴의 운동 법칙에서 관성이란 운동의 변화에 저항하는 성질이라고 설명했다. 즉 관성이 크면 운동하기 어렵고 관성이 작으면 운동하기 쉽다는 말이다. 이는 가벼운 물체를 밀어 옮기는 것보다 무거울 물체를 밀어 옮기는 것이 더 힘들다는 경험과 딱 맞아 떨어진다. 즉, 관성의 크고 작음은 질량의 크고 작음으로 말할 수 있다. 질량이란 물체가 무겁고 가벼운</description>
    </item>
    
    <item>
      <title>운동량의 기호가 p인 이유</title>
      <link>https://freshrimpsushi.github.io/posts/1672/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1672/</guid>
      <description>물리학에서 쓰이는 많은 기호들은 깊게 생각하지 않아도 왜 그렇게 채택되었는지 알 수 있다. 예를 들어 힘을 뜻하는 기호인 $\mathbf{F}$나 질량, 속도, 가속도를 뜻하는 기호인 $m$, $\mathbf{v}$, $\mathbf{a}$는 각각 영단어 force, mass, velocity, acceleration의 앞글자에서 따왔음을 쉽게 추측할 수 있다. 하지만 운동량은 영어로 momentu</description>
    </item>
    
    <item>
      <title>가분 힐베르트 공간의 그램-슈미트 정규직교화</title>
      <link>https://freshrimpsushi.github.io/posts/gram-schmidt-orthonormalization-of-separable-hilbert-space/</link>
      <pubDate>Tue, 14 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gram-schmidt-orthonormalization-of-separable-hilbert-space/</guid>
      <description>모든 가분 힐베르트 공간은 정규직교기저를 가진다.Strategy : 유한차원 벡터 공간에서의 그램-슈미트 정규직교화와 본질적으로 같다. 일반적인 힐베르트 공간은 유한차원 벡터 공간과 달리 기저의 존재성이 보장되지 않으므로 가분성에 따라 정규직교화를 거치기 전의 직교 기저인 $\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}}$ 를 잡아주어야한다. 증명 $$ \overline{\text{span}} \left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}} = H $$ 힐베르</description>
    </item>
    
    <item>
      <title>입자계의 질량중심과 선운동량</title>
      <link>https://freshrimpsushi.github.io/posts/center-of-mass-and-linear-momentum-of-a-system/</link>
      <pubDate>Mon, 13 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/center-of-mass-and-linear-momentum-of-a-system/</guid>
      <description>질량이 $m_1$, $m_2$, $\cdots$, $m_n$인 입자들의 위치 벡터가 각각 $\mathbf{r}{1}$, $\mathbf{r}{2}$, $\cdots$, $\mathbf{r}{n}$일 때 이 입자계의 질량 중심을 아래와 같이 정의한다. $$ \mathbf{r}{cm}=\frac{m_{1}\mathbf{r}_{1}+m_{2}\mathbf{r}_{2}+\cdots + m_{n}\mathbf{r}_{n}}{m_{1}+ m_{2}+ \cdots+ m_{n}}=\frac{\sum m_{i}\mathbf{r}_{i}}{m} $$ 이때 $m=\sum \limits_{i}m_{i}$는 입자계의 전체 질량이다. 아래첨자 $cm$은 center of mass의 약자이다. 그러면 질량중심의 속도는 자연스럽게 아래와 같이 정의된다</description>
    </item>
    
    <item>
      <title>그래프 이론에서의 지도</title>
      <link>https://freshrimpsushi.github.io/posts/map-of-graph-theory/</link>
      <pubDate>Sun, 12 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/map-of-graph-theory/</guid>
      <description>1. $3$-연결 평면 그래프를 지도 라 정의한다.2. 같은 에지를 사이에 두고 이웃한 페이스끼리 다른 색이 되도록 $k$ 개의 색을 칠할 수 있는 지도를 $k$-페이스 채색가능 지도 라고 한다.3. 기존의 $k$-채색가능 그래프를 $k$-버텍스 채색가능 그래프 라고 한다. * 평면 그래프가 그려지면서 평면 상에서 구분되는 영역들을 페이스 라고 부른다.1</description>
    </item>
    
    <item>
      <title>벡터 공간의 리오더링</title>
      <link>https://freshrimpsushi.github.io/posts/reordering-of-vector-space/</link>
      <pubDate>Fri, 10 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reordering-of-vector-space/</guid>
      <description>벡터 공간 $V$ 의 시퀀스 $\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}}$ 이 주어져 있다고 하자. 주어진 전단사 $\sigma : \mathbb{N} \to \mathbb{N}$ 에 대해 다음을 $\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}}$ 의 리오더링 이라고 한다. $$ \left\{ \textbf{v}{\sigma (k) } \right\}{k \in \mathbb{N}} = \left\{ \textbf{v}{\sigma(1)} , \textbf{v}{\sigma(2)} , \cdots \right\} $$ 리오더링 은 순열Permutation 이라 불리기도 하는데, 보다시피 어려운 개념이 아니라 그냥 순서만 바꿔놓은 것에 불과하다. 벡터 공간에서 덧셈은 원래 교환법칙을 만족하</description>
    </item>
    
    <item>
      <title>기하적 듀얼 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/geometric-dual-graph/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/geometric-dual-graph/</guid>
      <description>주어진 평면 그래프 $G$ 에 대해 기하적 듀얼 그래프 $G^{ * }$ 는 다음과 같이 만들어진다.Step 1. $G$ 의 각 페이스 $f$ 에 대응되는 버텍스 $v^{ * }$ 를 찍는다.Step 2. $G$ 의 각 에지 $e$ 와 겹치도록 대응되는 에지 $e^{ * }$ 를 긋는다.Step 3. 원래의 그래프는 지우고 $v^{ * }$ 와 $e^{ * }$ 로 이루어진 그래프를 $G^{ * }$ 로 둔다. * 평면 그래프가 그려지면서 평면 상에서 구분</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서의 베셀 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bessels-inequality-of-hilbert-space/</link>
      <pubDate>Sun, 28 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bessels-inequality-of-hilbert-space/</guid>
      <description>푸리에 해석에서의 베셀 부등식$\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}}$ 이 힐베르트 공간 $H$ 의 정규직교 집합이라고 하면 다음이 성립한다.[1] 모든 $\left\{ c_{k} \right\}_{k \in \mathbb{N}} \in l^{2}$ 에 대해 무한 급수 $\sum_{k \in \mathbb{N}} c_{k} \textbf{v}_{k}$ 는 수렴한다.**[2]** 모든 $\textbf{v} \in H$ 에 대해 $$ \sum_{k \in \mathbb{N}} \left| \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt; \right|^{2} \le \left| \textbf{v} \right|^{2} $$ * $l^{2}$ 공간이란 제곱의 합이 수렴하는 복소수 시퀀스의 집합으로 이루어진 함수공간이다</description>
    </item>
    
    <item>
      <title>그래프의 k-연결성과 멩거 정리 k-connected and Menger Theorem</title>
      <link>https://freshrimpsushi.github.io/posts/1576/</link>
      <pubDate>Fri, 26 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1576/</guid>
      <description>주어진 그래프 $G$ 에 대해 컴포넌트의 수를 $\text{comp} (G)$ 라고 나타내자.1-1. 다음을 만족하는 에지의 집합 $D \subset E(G)$ 를 $G$ 의 단절 집합Disconnecting Set 이라 한다. $$ \text{comp} \left( G \setminus D \right) &amp;gt; \text{comp}(G) $$ 1-2. $G$ 단절 집합 중 단절 집합이 아닌 진부분집합을 갖지 않는 단절 집합을 $G$ 의 컷셋Cutset 이라고 부른다.1-3. $G$ 가 연결 그래프라고 할 때, (에지) 컷셋의</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서의 베셀 시퀀스</title>
      <link>https://freshrimpsushi.github.io/posts/bessel-sequence-of-hilbert-space/</link>
      <pubDate>Wed, 24 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bessel-sequence-of-hilbert-space/</guid>
      <description>힐베르트 공간 $H$ 의 시퀀스 $\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}} \subset H$ 에 대해 다음을 만족하는 $B &amp;gt; 0$ 가 존재하면 $\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}}$ 를 베셀 시퀀스 라 하고 $B$ 를 베셀 바운드 라 한다. $$ \sum_{k=1}^{\infty} \left| \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt; \right|^{2 } \le B \left| \textbf{v} \right|^{2} \qquad , \forall \textbf{v} \in H $$ **베셀 시퀀스** 는 직관적으로 봤을 때 무한차원 벡터 $\textbf{v}$ 의 뒷부분이 작아지도록 휘어주는 시퀀스로 볼 수 있다. 거의 대부분의 수학이 그러하듯 바운드 될 수 없</description>
    </item>
    
    <item>
      <title>오일러의 다면체 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-polyhedron-formula/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-polyhedron-formula/</guid>
      <description>연결 평면 그래프 $G$ 에 대해, $n:=|V(G)|$, $m:=|E(G)|$, $f$ 를 페이스의 수라고 하면 $$ n-m+f=2 $$ * 평면 그래프가 그려지면서 평면 상에서 구분되는 영역들을 페이스 라고 부른다.오일러의 다면체 정리 는 오일러의 표수 , 그래프 이론에서는 그냥 오일러 공식 으로도 불린다. 기하학적으로는 공간도형의 점, 선, 면이 #점-#선+#면=2 의 관계를 따른다는 의미를 갖는다. 예로써 정육면</description>
    </item>
    
    <item>
      <title>리즈 기저</title>
      <link>https://freshrimpsushi.github.io/posts/riesz-basis/</link>
      <pubDate>Mon, 22 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riesz-basis/</guid>
      <description>힐베르트 공간 $H$ 의 정규 직교 기저 $\left\{ \textbf{e}{k} \right\}{k \in \mathbb{N}}$ 이 주어져 있다고 하자. 전단사 $U : H \to H$ 가 선형이고 유계인 작용소 모든 $k \in \mathbb{N}$ 에 대해 $\textbf{v}{k} := U \textbf{e}{k}$ 라고 하면 $\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}}$ 는 $H$ 의 기저가 되며 다음이 성립한다. $$ \textbf{v} = \sum_{k \in \mathbb{N}} \left&amp;lt; \textbf{v} , \left( U^{-1} \right)^{ * } \textbf{e}_{k} \right&amp;gt; \textbf{v}_{k} $$ $U$ 가 주어졌을 때 위와 같이 기저를 구체적으로 잡을 수 있다는 것은 분명 좋은 일이지만 $U$ 의 조건도 그만큼 좋아야함</description>
    </item>
    
    <item>
      <title>웨이블릿이란</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-wavelet/</link>
      <pubDate>Mon, 22 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-wavelet/</guid>
      <description>$\psi \in L^{2}(\mathbb{R})$이라고 하자. $\psi$가 아래의 두 조건을 만족시킬 때 함수 $\psi$를 웨이블릿 이라 부른다.(a) 정수 $j,k \in \mathbb{Z}$에 대해서, $\psi_{j,k}$를 아래와 같이 정의한다. $$ \psi_{j,k} (x):=2^{\frac{j}{2}}\psi(2^{j}x-k),\quad x\in \mathbb{R} $$ **(b)** $\left\{ \psi _{j,k}\right\}_{j,k\in \mathbb{Z}}$가 $L^{2}(\mathbb{R}</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서 l2 공간으로의 수반 작용소</title>
      <link>https://freshrimpsushi.github.io/posts/1566/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1566/</guid>
      <description>$\left\{ \textbf{v}k \right\}{k \in \mathbb{N}}$ 이 힐베르트 공간 $H$ 에서 정의된 시퀀스라 하자.유계 선형 작용소 $T : l^{2} \to H$ 가 다음과 같이 정의되어있다고 하자. $$ T \left\{ c_{k} \right\}_{k \in \mathbb{N}} := \sum_{k=1}^{\infty} c_{k} \textbf{v}_{k} $$ 그러면 $T$ 의 수반 작용소 $T^{ * } : H \to l^{2}$ 는 다음과 같이 나타난다. $$ T^{ * } \textbf{v} = \left\{ \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt;_{H} \right\}_{k \in \mathbb{N}} $$ 그 뿐만 아니라, 모든 $\textbf{v} \in H$ 에 대해 $$ \sum_{k=1}^{\infty} \left| \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt;_{H} \right|^{2} \le \left| T \right|^{2} \left| \textbf{v} \right|_{H}^{2} $$ 그리고 마찬가지로 모</description>
    </item>
    
    <item>
      <title>평면 그래프와 쿠라토프스키 정리</title>
      <link>https://freshrimpsushi.github.io/posts/planar-graph-and-kuratowski-theorem/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/planar-graph-and-kuratowski-theorem/</guid>
      <description>그래프를 평면에 그렸을 때 에지가 겹치지 않게 그릴 수 있으면 그 그래프를 평면 그래프 라고 한다.평면 그래프가 그려지면서 평면 상에서 구분되는 영역들을 페이스Face 라고 부른다. 다음과 같은 평면 그래프 $K_{4}$ 는 네 개의 페이스 $f_{1}, f_{2}, f_{3}, f_{4}$ 를 가지며, 그 중에서도 특히 바운드 되지 않은 $f_{4}$ 를 **무한 페이스**Infinite Face 라 부른다.**평면 그래프</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서의 직교 사영</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-projection/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-projection/</guid>
      <description>선형대수학에서의 정사영힐베르트 공간 $H$ 의 폐부분공간 $V$ 이 주어져있다고 하자. $\textbf{v} \in H$ 이 $\textbf{v}{1} \in V$ 와 $\textbf{v}{2} \in V^{\perp}$ 에 대해 $\textbf{v} = \textbf{v}{1} + \textbf{v}{2}$ 와 같이 나타난다고 할 때, 다음을 만족시키는 전사 $P :H \to V$ 를 직교 사영이라고 한다. $$ P \textbf{v} = \textbf{v}{1} $$ 직교 사영은 다음과 같은 성질들을 가진다.[1] $P$ 는 선형이고 유계이며, $| P | = 1$[2] $P$ 는 자기 수반 작용소, 즉 $P^{ * } = P$[3] $P$</description>
    </item>
    
    <item>
      <title>그래프의 호메오멀피즘</title>
      <link>https://freshrimpsushi.github.io/posts/homeomorphism-of-graphs/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homeomorphism-of-graphs/</guid>
      <description>위상수학에서의 호메오멀피즘그래프 아이소멀피즘두 그래프 $G_{1}$ 와 $G_{2}$ 가 주어져 있다고 하자. $G_{1}$ 의 어떤 세분 $G_{1}&#39;$ 과 $G_{2}$ 의 어떤 세분 $G_{2}&#39;$ 에 대해 그래프 아이소멀피즘이 존재하면 $G_{1}$ 와 $G_{2}$ 가 **호메오멀픽** 하다고 한다. * 그래프 $G$ 에 다음과 같은 조건을 만족하는 버텍스 $w$ 들을 차례로 추가한 그래프를 $G$ 의 **세분**Subdivision $G&#39;$ 이라 한다. $$</description>
    </item>
    
    <item>
      <title>상수 계수를 갖는 1계 선형 동차 미분 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/first-order-linear-homogeneous-differential-equation-with-constant-coefficients/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/first-order-linear-homogeneous-differential-equation-with-constant-coefficients/</guid>
      <description>상수 계수를 갖는 1계 선형 동차 미분 방정식 $$ \frac{ d y}{ d x}=\alpha y $$ 의 일반해는 $$ y=Ae^{\alpha x} $$ 이다. 이때 $A$는 상수이다.한 번 미분했을 때 자기 자신과 같은 함수가 무엇인지 생각해보면 왜 지수 함수가 답인지 알 수 있을 것이다.**풀이 $$ \frac{ d y}{ d x}=\alpha y $$ 에서 변수 분리를 해주면 $$ \frac{ 1 }{ y }dy=\alpha dx $$ 양 변을 적분하면 $$ \ln y=ax+C $$ 이때 $C$는 적분 상수이다. $y$의</description>
    </item>
    
    <item>
      <title>1계 선형 미분 방정식 시스템</title>
      <link>https://freshrimpsushi.github.io/posts/system-of-first-order-linear-differential-equation/</link>
      <pubDate>Thu, 11 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/system-of-first-order-linear-differential-equation/</guid>
      <description>$x_1$, $x_2$, $\cdots$, $x_n$을 $t$에 대한 함수라고 하자. $F_1$, $F_2$, $\cdots$, $F_n$을 $x_1$, $x_2$, $\cdots$, $x_n$에 대한 함수라고 하자. 그러면 $x_i(t),$ $1\le i \le n$에 대한 1계 미분 방정식 시스템은 아래와 같다.1계 미분 방정식 시스템 $$ \begin{align*} x_{1}&#39;(t) &amp;amp;= F_{1}(t,x_{1},x_{2},\cdots,x_{n}) \\ x_{2}&#39;(t) &amp;amp;= F_{2}(t,x_{1},x_{2},\cdots,x_{n}) \\ \vdots &amp;amp; \\ x_{n}&#39;(t) &amp;amp;= F_{n}(t,x_{1},x_{2},\cdots,x_{n}) \end{align*} $$ 이 때 각각의 $F_{i}$가 선형이면 선형 시스템이라 부르고 그렇지 않으면 비선형 시스템이라 부른다</description>
    </item>
    
    <item>
      <title>라게르 다항식의 로드리게스 공식</title>
      <link>https://freshrimpsushi.github.io/posts/rodrigues-formula-of-laguerre-polynomial/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rodrigues-formula-of-laguerre-polynomial/</guid>
      <description>라게르 다항식은 라게르 미분 방정식 $$ xy&#39;&#39;+(1-x)y&#39;+ny=0,\quad n=0,1,2,\cdots $$ 의 해를 말하며 $L_{n}(x)$로 표기하고 각 $n$에 대해서 아래와 같다. $$ \begin{align*} L_{0}(x) &amp;amp;= 1 \\ L_{1}(x) &amp;amp;= -x+1 \\ L_{2}(x) &amp;amp;= \frac{1}{2}\left( x^{2}-4x+2 \right) \\ L_{3} (x) &amp;amp;=\frac{1}{6}\left( -x^{3}+9x^{2}-18x+6 \right) \\ &amp;amp; \vdots \end{align*} $$ 위 식들은 미분 방정식을 풀어서 직접 각각의 $n$에 대해서 얻은 것이다. 각각의 $n$에 대해서 라게르 다항식을 얻는 공식은 아래와 같다.**라게르 다항식의 로드</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서의 수반 작용소</title>
      <link>https://freshrimpsushi.github.io/posts/adjoint-operator-on-hilbert-space/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adjoint-operator-on-hilbert-space/</guid>
      <description>힐베르트 공간 $\left( H, \left&amp;lt; \cdot , \cdot \right&amp;gt;{H} \right)$ 과 $\left( K, \left&amp;lt; \cdot , \cdot \right&amp;gt;{K} \right)$ 에 대해 유계 선형 작용소 $T : K \to H$ 가 주어져있다고 하자. 그러면 임의의 픽스된 원소 $\textbf{w} \in H$ 에 대해 다음과 같이 정의된 $\Phi : K \to \mathbb{C} $ 는 선형 범함수 $\Phi \in K^{ * }$ 가 된다. $$ \Phi \textbf{v} := \left&amp;lt; T \textbf{v} , \textbf{w} \right&amp;gt;{H} $$ 리즈 표현 정리에 따르면 힐베르트 공간 $K$ 는 $\Phi \in K^{ * }$ 와 모든 $\textbf{v} \in K$ 에 대해 다음을 만족하는 원소 $T^{ * } \textbf{w}</description>
    </item>
    
    <item>
      <title>미분 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/differential-operator/</link>
      <pubDate>Sun, 31 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/differential-operator/</guid>
      <description>미분 방정식을 푸는 여러 방법 중 하나는 미분 연산자를 이용하여 푸는 것이다. 미분 연산자 $D$를 아래와 같이 정의하자. $$ D:= \frac{d}{dx} $$ 미분하는 변수를 확실히 표현할 때는 $D_{x}$와 같이 표기하기도 한다. 편미분에 대해서는 아래와 같이 나타낸다. $$ \partial _{x}:=\frac{ \partial }{ \partial x},\quad \partial_{y}=\frac{ \partial }{ \partial y} $$ 미분 연산자를 사용하면 미분 방정식은 아래와 같이 표현된다. $$ \begin{align*} y&#39;&#39;+4y&#39;-y=0 &amp;amp;&amp;amp; \Rightarrow&amp;amp;&amp;amp;</description>
    </item>
    
    <item>
      <title>물리학에서 고유값 문제란</title>
      <link>https://freshrimpsushi.github.io/posts/eigenvalue-problem/</link>
      <pubDate>Sat, 30 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eigenvalue-problem/</guid>
      <description>고유값 문제를 푸는 방법$n\times n$ 행렬 $A$가 주어졌다고 하자. $$ A\mathbf{x}=\lambda \mathbf{x} $$ 행렬 $A$에 대해서 위의 식을 만족하는 $n\times 1$ 행렬 $\mathbf{x}$와 상수 $\lambda$를 찾는 것을 고유값 문제라고 한다. 이러한 행렬 $\mathbf{x}$를 $A$의 고유함수라하고 $\lambda$를 $\mathbf{x}$의 고</description>
    </item>
    
    <item>
      <title>에르되시-갈라이 정리</title>
      <link>https://freshrimpsushi.github.io/posts/erd%C3%B6s-gallai-theorem/</link>
      <pubDate>Sat, 30 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/erd%C3%B6s-gallai-theorem/</guid>
      <description>1. 그래프 $G$ 의 차수를 중복을 포함해 모아놓은 집합을 그래프 스코어Graph Score 라 하고, $G$ 의 그래프 스코어를 내림차순으로 정렬한 시퀀스를 $G$ 의 디그리 시퀀스Degree Sequence 라 한다.2. 증가하지 않는 자연수들의 시퀀스 $D = (d_{1} , \cdots , d_{n})$ 에 대해 $n$ 개의 버텍스 $v_{1} , \cdots , v_{n}$ 가 다음을 만족 시키게끔 하는 그래프 $G$ 가 존재하면 $D$ 가 **그래픽**Grap</description>
    </item>
    
    <item>
      <title>각운동량과 위치 운동량의 교환자</title>
      <link>https://freshrimpsushi.github.io/posts/commutator/</link>
      <pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/commutator/</guid>
      <description>각운동량과 위치의 교환자는 다음과 같다. $$ \begin{align*} [L_{z},x]&amp;amp;=i\hbar y \\ [L_{z},y]&amp;amp;=-i\hbar x \\ [L_{z},z]&amp;amp;=0 \end{align*} $$ 위치와 운동량의 교환자$$ \begin{align*} [x,p_{x}]&amp;amp;=i\hbar \end{align*} $$ 증명 $$ \begin{align*} [L_{z},x] &amp;amp;= [xp_{y}-yp_{x},x] \\ &amp;amp;= xp_{y}x-xxp_{y}-(yp_{x}x-xyp_{x}) \end{align*} $$ 서로 다른 성분의 위치와 운동량은 교환 가능하므로 $$ xp_{y}x-xxp_{y} = xxp_{y}-xxp_{y}=0 $$ 따라서 $$ \begin{align*} [L_{z},x] &amp;amp;= -yp_{x}x+xyp_{x} \\ &amp;amp;= -yp_{x}x+yxp_{x} \\ &amp;amp;= y(xp_{x}-p_{x}x) \\ &amp;amp;= y[x,p_{x}] \\ &amp;amp;= y(i\hbar) \\ &amp;amp;= i\hbar y \end{align*} $$ 같은 방식으로 $$ \begin{align*} [L_{z},y] &amp;amp;= [xp_{y}-yp_{x},y] \\ &amp;amp;= xp_{y}y-yxp_{y}-yp_{x}y+yyp_{x} \\ &amp;amp;= xp_{y}y-yxp_{y} \\ &amp;amp;= xp_{y}y-xyp_{y} \\ &amp;amp;= x(p_{y}y-yp_{y}) \\ &amp;amp;= x[p_{y},y] \\ &amp;amp;= x(-i\hbar) \\ &amp;amp;= -i\hbar x \end{align*} $$ 또한 $z$는</description>
    </item>
    
    <item>
      <title>구면좌표계에서 각운동량의 사다리 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/the-ladder-operator-of-angular-momentum-in-spherical-coordinates/</link>
      <pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-ladder-operator-of-angular-momentum-in-spherical-coordinates/</guid>
      <description>구면좌표계에서 두 사다리 연산자의 곱 $L_{+} L_{-}$의 곱은 다음과 같다. $$ L_{+}L_{-}=-\hbar ^{2} \left( \frac{ \partial ^{2}}{ \partial \theta ^{2} } + \cot \theta \frac{ \partial }{ \partial \theta }+\cot ^{2}\theta \frac{ \partial ^{2}}{ \partial \phi^{2} } +i\frac{ \partial }{ \partial \phi}\right) $$ 단순 계산이라 풀이가 어려운 것은 아니나 식이 복잡하고 길어 실수하기 쉬우므로 꼼꼼하게 풀 필요가 있다. 또한 $L_{\pm}$는 미분연산자이므로 푸는 과정에서 주의해야 한다. 증명 깔끔함을 위해</description>
    </item>
    
    <item>
      <title>산술 함수의 벨 급수</title>
      <link>https://freshrimpsushi.github.io/posts/bell-series-of-arithmetical-function/</link>
      <pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bell-series-of-arithmetical-function/</guid>
      <description>주어진 산술 함수 $f$ 와 소수 $p$ 에 대해 다음과 같이 정의된 $f_{p}(x)$ 를 **모듈로 $p$ 에서 $f$ 의 벨 급수** 라한다. $$ f_{p}(x) := \sum_{n=0}^{\infty} f \left( p^{n} \right) x^{n} $$ 전통적인 의미에서의 무한 급수가 등장한다는 것은 본격적으로 해석적 정수론이 해석학을 도입한 것으로 보아도 좋다. 벨 급수는 특히 승법적 함수에 대해 연구할 때 유용한 개념으로써 다음과 같은 예를 생각해볼 수 있다. $$ I_{p} (x) = \sum_{n=0}^{\infty} I</description>
    </item>
    
    <item>
      <title>각운동량 연산자의 고유함수는 구면조화함수이다</title>
      <link>https://freshrimpsushi.github.io/posts/the-eigenfunction-of-angular-momentum-operator-is-spherical-harmonics/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-eigenfunction-of-angular-momentum-operator-is-spherical-harmonics/</guid>
      <description>각운동량 연산자 $L^{2}$와 $L_{z}$는 상수 $l$, $m$에 의해 결정되는 고유함수를 공통으로 가진다. 이를 $f_{l}^{m}$이나 디락 노테이션을 고려하여 $|l,m&amp;gt;$으로 표기한다. $$ \begin{align*} L^{2}|l,m&amp;gt;&amp;amp;=\hbar^{2}l(l+1)|l,m&amp;gt;\tag {1} \\ L_z|l,m&amp;gt;&amp;amp;=m\hbar|l,m&amp;gt; \end{align*} $$ 이때 각운동량 연산자의 고유함수 $|l,m&amp;gt;$은 실제로 구면조화함수 $Y_{l}^{m}$과 같다. $$</description>
    </item>
    
    <item>
      <title>레이블 트리와 케일리 정리</title>
      <link>https://freshrimpsushi.github.io/posts/labeled-tree-and-cayley-theorem/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/labeled-tree-and-cayley-theorem/</guid>
      <description>각 버텍스에 서로 다른 수가 부여된 트리를 레이블 트리 라고 한다.레이블은 버텍스의 집합과 같이 실제로 원소가 같은지 다른지 구분하는 것과는 다른 개념이다. 가령 다음의 두 그래프는 쓰여있기는 달라도 본질적으로 같은 레이블 트리로 볼 수 있다. $$ 1-2-3 \\ a-b-c $$ 물론 그래프기 때문에 다음의 두 경우는 서로 같다. $$ 1-2-3 \\ 3-2-1 $$ 그러나 다음 두 그래프는 레이블이 부여된</description>
    </item>
    
    <item>
      <title>쌍선형 형식 이차 형식 에르메트 형식</title>
      <link>https://freshrimpsushi.github.io/posts/bilinear-quadratic-and-hermitian-forms/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bilinear-quadratic-and-hermitian-forms/</guid>
      <description>**1. 쌍선형 형식$(\mathrm{bilinear\ form})$ 행렬 $\quad A=\begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp;\cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp;\cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{n1} &amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \end{pmatrix}\in \mathbb{R}^{n\times n}$와 $\mathbf{x}=\begin{pmatrix} x_{1} \\ x_{2} \\ \vdots \\ x_{n} \end{pmatrix},\mathbf{u}=\begin{pmatrix} u_{1} &amp;amp; u_{2} &amp;amp; \cdots &amp;amp; x_{n} \end{pmatrix}\in \mathbb{R}^{n}$에 대해서, **행렬 $A$에 대응하는 쌍선형 형식** 을 다음과 같이 정의한다. $$ A(\mathbf{u},\mathbf{x}):=\sum \limits_{i,k=1}^{n} a_{ik}u_{i}x_{k} $$ 행렬의 곱으로 표현하면 아래와</description>
    </item>
    
    <item>
      <title>리우빌 함수</title>
      <link>https://freshrimpsushi.github.io/posts/liouvilles-function/</link>
      <pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/liouvilles-function/</guid>
      <description>소수 $p_{1} , \cdots , p_{k}$ 에 대해 자연수 $n$ 을 $n = p_{1}^{a_{1}} \cdots p_{k}^{a_{k}}$ 과 같이 나타낸다고 하자. 다음과 같이 정의된 산술 함수 $\lambda $ 를 **리우빌 함수** 라고 한다. $$ \lambda (n) = (-1)^{a_{1} + \cdots a_{k}} $$ **[1] 리우빌 급수** : $n$ 이 제곱수일 때만 $1$ 이고 그 외엔 $0$ 이다. 다시 말해, $$ \sum_{d \mid n} \lambda (d) = \begin{cases} 1 &amp;amp;, n \text{ is a square} \\ 0 &amp;amp; , \text{otherwise}\end{cases} $$ **[2] 완전 승법성** : 모든 $m,n \in \mathbb{N}$ 에 대해 $\lambda(mn) = \lambda(m) \lambda(n) $$ $\begin{matrix} n &amp;amp; 1 &amp;amp; 2</description>
    </item>
    
    <item>
      <title>에어리 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-airy-function/</link>
      <pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-airy-function/</guid>
      <description>에어리 미분 방정식 $$ y&#39;&#39;-xy=0 $$ 의 해를 베셀 함수로 나타내면 아래와 같다. $$ \begin{align*} \mathrm{Ai}(x) &amp;amp;= \frac{1}{\pi}\sqrt{\frac{x}{3}}K_{1/3}\left( \frac{2}{3}x^{2/3} \right) \\ \mathrm{Bi}(x) &amp;amp;= \sqrt{\frac{x}{3}}\left[ I_{-1/3}\left( \frac{2}{3}x^{3/2} \right) + I_{1/3} \left( \frac{2}{3}x^{2/3} \right) \right] \end{align*} $$ 이때 $I_{\nu}$, $K_{\nu}$는 변형 베셀 함수이다.에어리 함수를 표현하는 방법은 여러가지인데 아래와 같이 이상적분 꼴로 표현할 수 도 있다. $$ \begin{align*} \mathrm{Ai}(x) &amp;amp;= \frac{1}{\pi} \int_{0}^{\infty} \cos (t^{3}/3 + xt) dt \\ \mathrm{Bi}(x) &amp;amp;= \frac{1}{\pi}\int_{0}^{\infty} \left[ \exp \left( -\frac{1}{3}t^{3}+xt \right)+\sin\left( \frac{1}{3}t^{3}+xt \right) \right]dt \end{align*} $$</description>
    </item>
    
    <item>
      <title>트리 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/tree-graph/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tree-graph/</guid>
      <description>사이클이 존재하지 않는 연결 그래프를 트리 라고 한다.트리는 컴퓨터 공학의 자료 구조 등에서 흔히 볼 수 있는 개념으로써, 컴퓨터를 조금이라도 다루는 이공계 전공이라면 아마 힙 소팅이라는 말을 들어봤을 것이다. 여기서 말하는 그 힙이 바로 트리의 일종이다.트리의 유니언은 직관적이게도 포레스트Forest 라 부른다. 유향 그래프일 경우 입력 차수가 $0$</description>
    </item>
    
    <item>
      <title>에어리 미분 방정식과 급수해</title>
      <link>https://freshrimpsushi.github.io/posts/the-airys-differential-equation-and-power-series-solution/</link>
      <pubDate>Thu, 21 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-airys-differential-equation-and-power-series-solution/</guid>
      <description>아래의 미분 방정식을 에어리 미분 방정식이라 한다. $$ y&#39;&#39;-xy=0,\quad -\infty&amp;lt;x&amp;lt;\infty $$ 스토크스 방정식$(\mathrm{Stokes\ equation})$이라고도 불린다. 이름의 유래는 영국의 천문학자 조지 비델 에어리$(\mathrm{George\ Biddell\ Airy})$이다. **풀이 $y&#39;&#39;$항의 계수가 $1$이므로 모든 점이 보통점이다. 그 중에</description>
    </item>
    
    <item>
      <title>망골트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/mangoldt-function/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mangoldt-function/</guid>
      <description>다음과 같이 정의된 산술 함수 $\Lambda$ 를 망골트 함수 라고 한다. $$ \Lambda(n) := \begin{cases} \log p &amp;amp; n = p^{m} , p \text{ is prime}, m \in \mathbb{N} \\ 0 &amp;amp; \text{otherwise} \end{cases} $$ [1] 망골트 급수 : 로그 함수 $\log$ 다. 다시 말해, $$ \sum_{d \mid n} \Lambda ( d ) = \log n $$ $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ \Lambda(n) &amp;amp; 0 &amp;amp; \log 2 &amp;amp; \log 3 &amp;amp; \log 2 &amp;amp; \log 5 &amp;amp; 0 &amp;amp; \log 7 &amp;amp; \log 2 &amp;amp; \log 3 &amp;amp; 0 \\ \sum_{d \mid n} \Lambda(d) &amp;amp; 0 &amp;amp; \log 2 &amp;amp; \log 3 &amp;amp; \log 4 &amp;amp; \log 5</description>
    </item>
    
    <item>
      <title>변형 베셀 방정식과 변형 베셀 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-modified-bessel-equation-and-the-modified-bessel-functions/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-modified-bessel-equation-and-the-modified-bessel-functions/</guid>
      <description>아래의 미분 방정식을 변형 베셀 방정식 이라 한다. $$ x^2 y&#39;&#39; + xy&#39;-(x^2-\nu^2)y=0 $$ 베셀 방정식에서 $y$항의 부호가 $+ \rightarrow -$로 바뀐 형태이다. 이 미분 방정식의 해는 베셀 방정식이 해인 미분 방정식의 공식에 의해 $$ y=Z_{\nu}(ix)=AJ_{\nu}(ix)+BN_{\nu}(ix) $$ 이다. 일반적으로 사용하는 두 해의 꼴은 다음과 같으며 **변형 베셀 함수** $(\mathrm{modified\ Bessel\ function})$라 부른다. 특히 $I_{\nu}$를 제1</description>
    </item>
    
    <item>
      <title>베셀 함수의 여러 성질</title>
      <link>https://freshrimpsushi.github.io/posts/some-properties-of-the-bessel-function/</link>
      <pubDate>Tue, 19 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/some-properties-of-the-bessel-function/</guid>
      <description>베셀 방정식 아래의 미분 방정식을 $\nu$차 베셀 방정식이라 한다. $$ \begin{align*} x^2 y&#39;&#39; +xy&#39; +(x^2-\nu^2)y&amp;amp;=0 \\ x(xy&#39;)&#39;+(x^2- \nu ^2) y&amp;amp;=0 \\ y&#39;&#39;+\frac{1}{x} y&#39; + \left( 1-\frac{\nu^{2}}{x^{2}} \right)y&amp;amp;=0 \end{align*} $$ 제1 종 베셀 함수 베셀 방정식의 첫번째 해를 $J_{\nu}(x)$라 쓰고 제1 종 베셀 함수라 부른다. $$ J_{\nu}(x)=\sum \limits_{n=0}^{\infty} \frac{(-1)^{n} }{\Gamma(n+1) \Gamma(n+\nu+1)} \left(\frac{x}{2} \right)^{2n+\nu} $$ $$ J_{-\nu}(x)=\sum \limits_{n=0}^{\infty}\frac{(-1)^{n}}{\Gamma(n+1)\Gamma(n-\nu+1)} \left( \frac{x}{2} \right)^{2n-\nu} $$ 제 2종 베셀 함수 베셀 방정식의 두번째 해를 $N_{\nu}(x)=Y_{\nu}(x</description>
    </item>
    
    <item>
      <title>제3 종 베셀 함수 한켈 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-third-kind-hankel-function/</link>
      <pubDate>Tue, 19 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-third-kind-hankel-function/</guid>
      <description>제1 종 베셀 함수와 제2 종 베셀함수의 아래와 같은 선형 결합을 제3 종 베셀함수 또는 한켈 함수라 부른다. $$ H_{p}^{(1)}(x)=J_{p}(x)+iN_{p}(x) \\ H_{p}^{(2)}(x)=J_{p}(x)-iN_{p}(x) $$ 미분 방정식 $y&#39;&#39;+y=0$의 해는 $\cos x$와 $\sin x$이다. 일반해는 이들의 선형 결합으로 나타낸다. 그 중 가장 흔하게 사용되는 꼴은 $\cos x + \pm i \sin x=e^{\pm ix}$이다. 이와 비슷하게 베셀 방정식의 해를 $J_{\nu}(x)$, $N_{\nu}(x)$의 선</description>
    </item>
    
    <item>
      <title>그래프 이론에서의 디락 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-diracs-theorem/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-diracs-theorem/</guid>
      <description>$G$ 가 $n ( \ge 3)$ 개의 버텍스를 가진 심플 그래프라고 하자.[1] 디락 정리 : $G$ 의 모든 버텍스 $v$ 에 대해 $\deg (v) \ge n / 2$ 면 $G$ 는 해밀톤 그래프다.[2] 오레 정리 : $G$ 의 모든 인접하지 않은 두 버텍스의 쌍 $(v ,w)$ 에 대해 $\deg (v) + \deg(w) \ge n$ 면 $G$ 는 해밀톤 그래프다.디락 정리 는 해밀톤 그래프의 동치조건까지는 아니지만 어떤 경우에 충분히 해밀톤 그래프인지를 판별해내</description>
    </item>
    
    <item>
      <title>베셀 함수의 직교성</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-of-the-bessel-function/</link>
      <pubDate>Sun, 17 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-of-the-bessel-function/</guid>
      <description>$\alpha, \beta$를 제1 종 베셀 함수 $J_{\nu}(x)$의 근이라고 하자. 그러면 구간 $[0,1]$에서 $\sqrt{x}J_{\nu}(x)$는 직교 집합을 이룬다. $$ \int_{0}^{1} x J_{\nu}(\alpha x) J_{\nu}(\beta x)dx=\begin{cases} 0 &amp;amp;\alpha\ne \beta \\ \frac{1}{2}J^{2}_{\nu+1}(\alpha)=\frac{1}{2}J_{\nu-1}^{2}(\alpha)=\frac{1}{2}J_{\nu}&#39;^{2}(\alpha) &amp;amp;\alpha=\beta\end{cases} $$ 위 내용을 다르게 표하면 다음과 같다. &amp;lsquo;베셀 함수 $J_{\nu}(x)$는 구간 $[0,1]$에서 가중 함수$(</description>
    </item>
    
    <item>
      <title>뫼비우스 역 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-m%C3%B6bius-inversion-formula/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-m%C3%B6bius-inversion-formula/</guid>
      <description>$f$ 와 $g$ 가 산술 함수고 $\mu$ 는 뫼비우스 함수다. $$ f(n) = \sum_{d \mid n} g(d) \iff g(n) = \sum_{d \mid n} f(d) \mu \left( {{ n } \over { d }} \right) $$ 뫼비우스 함수는 그 정의만 보았을 땐 부자연스러운 함수로 보이지만, 사실 산술 함수 전체를 관통하는 핵심 공식에 등장하게 된다. 임의의 산술 함수 $g$ 의 급수는 유닛 함수 $u$ 와 컨볼루션 $*$ 을 써서 $g*u$ 와 같이 표현할 수 있는데, 마침 $u$ 의 인버스가 $\mu$, 다시 말해 $I</description>
    </item>
    
    <item>
      <title>베셀 함수가 해인 미분 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/differential-equations-with-bessel-function-solutions/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/differential-equations-with-bessel-function-solutions/</guid>
      <description>정리 1 베셀 방정식과 조금 다른 아래와 같은 미분 방정식이 주어졌다고 하자. $$ \begin{align} y&#39;&#39;+\frac{1-2a}{x}y&#39;+\left[ (bcx^{c-1})^{2}+\frac{a^{2}-\nu^{2}c^{2}}{x^{2}} \right]y &amp;amp;=0 \\ x^{2}y&#39;&#39;+(1-2a)xy&#39;+\left[ b^{2}c^{2}x^{2c}+(a^{2}-\nu^{2}c^{2}) \right]y &amp;amp;=0\tag{1} \end{align} $$ 그리고 $Z_{\nu}(x)$를 $J_{\nu}(x)$와 $N_{\nu}(x)$의 임의의 선형결합이라고 하자. 그러면 주어진 미분 방정식의 해는 아래와 같다. $$ y=x^{a}Z_{\nu}(bx^{c})=x^{a}[AJ_{\nu}(bx^{c})+BN_{\nu}(bx^{c})] $$ $\nu$, $a$, $b$, $c$, $A$, $B$는 상수이다.**정리 2 미분 방정식 $$ x^{2}y&#39;&#39; +</description>
    </item>
    
    <item>
      <title>베셀 함수의 재귀 관계</title>
      <link>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-the-bessel-function/</link>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-the-bessel-function/</guid>
      <description>제1 종 베셀 함수 $J_{\nu}(x)$는 아래의 식을 만족한다. $$ \leqalignno{&amp;amp; \frac{ d }{ dx }[x^{\nu} J_{\nu}(x)] =x^{\nu}J_{\nu-1}(x) &amp;amp; (a) \\ &amp;amp; \frac{ d }{ dx }[x^{-\nu}J_{\nu}(x)]=-x^{-\nu}J_{\nu+1}(x) &amp;amp; (b) \\ &amp;amp; J_{\nu-1}(x)+J_{\nu+1}(x)=\frac{2\nu}{x}J_{\nu}(x) &amp;amp; (c) \\ &amp;amp; J_{\nu-1}(x)-J_{\nu+1}(x)=2J&#39;_{\nu}(x) &amp;amp; (d) \\ &amp;amp; J_{\nu}&#39;(x)=-\frac{\nu}{x}J_{\nu}(x)+J_{\nu-1}(x)=\frac{\nu}{x}J_{\nu}(x)-J_{\nu+1}(x) &amp;amp; (e) } $$ 상수 $\nu$에 대한 제1 종베셀 함수는 다음과 같다. $$ J_{\nu}(x)=\sum \limits_{n=0}^{\infty} \frac{(-1)^{n} }{\Gamma(n+1) \Gamma(n+\nu+1)} \left(\frac{x}{2} \right)^{2n+\nu}\tag{1} $$ 증명 $(a)$ $(1)$에 $x^{\nu}$를 곱한 뒤 미분하면 쉽게 얻을 수 있다. $$ \begin{align*} \frac{ d }{ dx }[x^{\nu} J_{\nu}(x)] &amp;amp;= \frac{ d }{ dx } \left[ x^{\nu}</description>
    </item>
    
    <item>
      <title>제2 종 베셀 함수 노이만 함수 베버 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-second-kind-neumann-function-weber-function/</link>
      <pubDate>Thu, 14 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-second-kind-neumann-function-weber-function/</guid>
      <description>**노이만 함수, 베버 함수, 제2 종 베셀 함수 베셀 방정식의 $\mathrm{second\ solution}$을 노이만 함수라 부르고 $N_{\nu}(x)$ 혹은 $Y_{\nu}(x)$로 표기한다. 정수가 아닌 $\nu$에 대해서 $$ N_{\nu}(x)=Y_{\nu}(x)=\frac{\cos (\nu \pi)J_{\nu}(x)-J_{-\nu}(x)}{\sin (\nu\pi)} $$ $\nu$가 정수일 경우 극한으로 정의한다. $n\in \mathbb{Z}$, $\nu \in \mathbb{R}\setminus\mathbb{Z}$에 대해서 $$ N_{n}(x)=\lim \limits_{\nu \rightarrow</description>
    </item>
    
    <item>
      <title>해밀톤 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/hamiltonian-graph/</link>
      <pubDate>Thu, 14 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hamiltonian-graph/</guid>
      <description>모든 에지를 포함하는 닫힌 트레일이 존재하는 그래프 : 오일러 그래프$G$ 가 연결 그래프라고 하자.$G$ 의 모든 버텍스를 포함하는 닫힌 패스가 존재하면 $G$ 를 해밀톤 그래프 라 하고 그 사이클을 해밀턴 사이클 이라 한다. 모든 버텍스를 포함하지만 닫혀있지 않은 패스가 존재하면 $G$ 를 세미 해밀톤 그래프 라 한다.오일러 그래프가 모든 에지를 지나는 트레일에</description>
    </item>
    
    <item>
      <title>구면 좌표계에서의 슈뢰딩거 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/the-schrodinger-equation-in-spherical-coordinates/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-schrodinger-equation-in-spherical-coordinates/</guid>
      <description>3차원에서 시간에 무관한 슈뢰딩거 방정식은 다음과 같다. $$ -\frac{\hbar^{2}}{2M}\nabla^{2}\psi+V\psi=E\psi $$ 후에 나올 분리상수 $m$과 헷갈릴 염려가 있어 슈뢰딩거 방정식에서 입자의 질량을 나타내는 $m$은 대문자로 나타내겠다. 보통 포텐셜 함수는 원점과의 거리에만 의존하므로 $V=V(r)$이고 구면좌표계로 방정식을 푸는 것이 좋다. 구면 좌표계에서 라플라스 방정식은 $$ \nabla ^2 f = \frac{1}{r^2}\frac{\partial}{\partial</description>
    </item>
    
    <item>
      <title>연관 르장드르 다항식의 여러 성질</title>
      <link>https://freshrimpsushi.github.io/posts/some-properties-of-the-associated-legendre-polynomial/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/some-properties-of-the-associated-legendre-polynomial/</guid>
      <description>연관 르장드르 미분 방정식과 연관 드장드르 다항식 아래의 미분 방정식을 르장드르 미분 방정식이라고 한다. 각각의 $l$, $m$에 따른 방정식의 해를 $P_{l}^{m}(x)$라고 표기하고연관 르장드르 다항식이라 부른다. $$ \begin{align*} &amp;amp;&amp;amp;(1-x^{2})\frac{ d^{2}y }{ dx^{2} }-2x \frac{dy}{dx}+\left[ +l(l+1)-\frac{m^{2}}{1-x^{2}} \right]y=0 \\ \mathrm{or} &amp;amp;&amp;amp; \frac{ d }{ dx } \left[ (1-x^{2})y&#39; \right] +\left[ l(l+1)-\frac{m^{2}}{1-x^{2}} \right]y=0 \end{align*} $$ $$ \begin{align*} P_{l}^{m}(x)&amp;amp;= (1-x ^{2})^{\frac{|m|}{2}} \frac{ d^{|m|} }{ dx^{|m|} } P_{l}(x) \\ &amp;amp;=(1-x ^{2})^{\frac{|m|}{2}} \frac{ d^{|m|} }{ dx^{|m|} }\left[ \dfrac{1}{2^l l!} \dfrac{d^l}{dx^l}(x^2-1)^l\right] \end{align*} $$ $P_{</description>
    </item>
    
    <item>
      <title>유닛 함수</title>
      <link>https://freshrimpsushi.github.io/posts/unit-function/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unit-function/</guid>
      <description>다음과 같이 정의된 산술 함수 $u$ 를 유닛 함수 라고 한다. $$ u(n) := 1 $$ [1] 유닛 급수 : 약수의 갯수 $\sigma_{0}$ 다. 다시 말해, $$ \sum_{d \mid n} u(d) = \sigma_{0} (n) $$ **[2] 완전 승법성** : 모든 $m,n \in \mathbb{N}$ 에 대해 $u(mn) = u(m) u(n) $$ $\begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ u (n) &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 \\ \sum_{d \mid n} u(d) &amp;amp; 1 &amp;amp; 2 &amp;amp; 2 &amp;amp; 3 &amp;amp; 2 &amp;amp; 4 &amp;amp; 2 &amp;amp; 4 &amp;amp; 3 &amp;amp; 4 \end{matrix} $$</description>
    </item>
    
    <item>
      <title>구면조화함수의 규격화</title>
      <link>https://freshrimpsushi.github.io/posts/normalization-of-spherical-harmonics/</link>
      <pubDate>Mon, 11 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normalization-of-spherical-harmonics/</guid>
      <description>규격화된 구면조화함수는 아래와 같다. $$ Y_{l}^{m}(\theta,\phi)=\sqrt{\frac{2l+1}{4\pi}\frac{(l-m)!}{(l+m)!}}P_{l}^{m}(\cos\theta)e^{im\phi} $$ $$ \nabla ^2 f = \frac{1}{r^2}\frac{\partial}{\partial r} \left( r^2\frac{\partial f}{\partial r} \right) + \frac{1}{r^2\sin\theta}\frac{\partial}{\partial\theta}\left( \sin\theta \frac{\partial f}{\partial \theta} \right) + \frac{1}{r^2\sin^2\theta}\frac{\partial^2 f}{\partial^2 \phi}=0 $$ $$ f(r,\theta,\phi)=R(r)\Theta(\theta)\Phi(\phi) $$ 구면좌표계에 대한 라플라스 방정식에서 극각 $\theta$, 방위각 $\phi$에 대한 해를 구면조화함수라 한다. $$ \Theta(\theta)\Phi(\phi)=Y_{l}^{m}(\theta,\phi)=e^{im\phi}P_{l}^{m}(\cos \theta) $$ 양자역학에서 구면조화함수를 파동함수로서 다루려면 규격화를 해야한다. $$ \iiint |R(r)\Theta (\theta) \Phi(\phi)|^{2}r^{2}\sin \theta dr d \theta d\phi=\int_{0}^{\infty}|R(r)|^{2}r^{2}dr\int_{0}^{2\pi}\int_{0}^{\pi}|Y_{l}^{m}(\theta,\phi)|^{2}\sin\theta d\theta d\phi=1 $$ 여기서 구면조화함수인</description>
    </item>
    
    <item>
      <title>연관 르장드르 다항식의 직교성</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-of-associated-legendre-polynomials/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-of-associated-legendre-polynomials/</guid>
      <description>구간 $[-1,1]$에서 고정된 $m$에 대한 연관 르장드르 다항식은 직교 집합을 이룬다. $$ \int_{-1}^{1} P_{l}^{m}(x)P_{k}^{m}(x)dx =\frac{ 2}{ 2l+1 }\frac{(l+m)!}{(l-m)!}\delta_{lk} $$ $x=\cos \theta$일 경우에는 $$ \int_{0}^{\pi} P_{l}^{m}(\cos \theta)P_ {k}^{m}(\cos\theta)\sin \theta d\theta =\frac{ 2}{ 2l+1 }\frac{(l+m)!}{(l-m)!}\delta_{lk} $$ 연관 르장드르 다항식 $$ P_{l}^{m}(x) = (1-x ^{2})^{\frac{m}{2}} \dfrac{1}{2^l l!} \dfrac{d^{l+m}}{dx^{l+m}}(x^2-1)^l $$ 로드리게스 공식 $$ P_l(x)=\dfrac{1}{2^l l!} \dfrac{d^l}{dx^l}(x^2-1)^l $$ 증명 우선 편의를 위해 $P_{l}^{m}(x)=P_{lm}$으로 간단히 표기한다. 연관 르장드르 다</description>
    </item>
    
    <item>
      <title>플뢰리 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fleurys-algorithm/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fleurys-algorithm/</guid>
      <description>$G$ 가 오일러 그래프라고 하자. 그러면 다음과 같은 방법으로 오일러 트레일을 만들 수 있다.임의의 버텍스 $u$ 에서 시작해서 다음의 두 규칙을 따라 트레일을 만든다 :(i) 이미 지나온 에지는 지운다. 만약 에지가 지워지면서 고립 버텍스가 되면 그 버텍스도 지운다.(ii) 각 단계에서 브릿지는 다른 대안이 없을때만 지나간다.* 에지 $b \in G$ 가 지워짐으로써 그래프</description>
    </item>
    
    <item>
      <title>연관 르장드르 미분 방정식과 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/associated-lengendre-differential-equation-and-polynomial/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/associated-lengendre-differential-equation-and-polynomial/</guid>
      <description>아래의 미분 방정식을 연관 르장드르 미분 방정식이라 한다. $$ \begin{align*} &amp;amp;&amp;amp;(1-x^{2})\frac{ d^{2}y }{ dx^{2} }-2x \frac{dy}{dx}+\left[ +l(l+1)-\frac{m^{2}}{1-x^{2}} \right]y=0 \tag{1} \\ \mathrm{or} &amp;amp;&amp;amp; \frac{ d }{ dx } \left[ (1-x^{2})y&#39; \right] +\left[ l(l+1)-\frac{m^{2}}{1-x^{2}} \right]y=0 \end{align*} $$ 연관 르장드르 미분 방정식의 해를 $P_{l}^{m}(x)$와 같이 표기하고 이를 연관 르장드르 다항식 혹은 일반화된 르장드르 다항식이라 한다. $$ \begin{align*} P_{l}^{m}(x)&amp;amp;= (1-x ^{2})^{\frac{|m|}{2}} \frac{ d^{|m|} }{ dx^{|m|} } P_{l}(x) \\ &amp;amp;=(1-x ^{2})^{\frac{|m|}{2}} \frac{ d^{|m|} }{ dx^{|m|} }\left[ \dfrac{1}{2^l l!} \dfrac{d^l}{dx^l}(x^2-1)^l\right] \end{align*} $$ $P_{l}(x)$</description>
    </item>
    
    <item>
      <title>쾨닉의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-k%C3%B6nigs-theorem/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-k%C3%B6nigs-theorem/</guid>
      <description>$G$ 가 국소적으로 유한인 연결 그래프라고 하자. 그러면 모든 $v \in V(G)$ 에 대해 $v$ 가 시점인 원웨이 무한 패스가 존재한다. 증명 $G$ 는 연결 그래프이므로 $v$ 가 아닌 모든 $z \in V(G)$ 에 대해 $v$ 에서 $z$ 로 가는 패스가 무한히 많이 존재한다. 그리고 $G$ 는 국소적으로 유한하므로 무한히 많은 패스들 중 무한히 많은 일부는 하나의 같은 에지로 시작해야만한다. 그 에지를 $vv_{1}$ 이라고 하</description>
    </item>
    
    <item>
      <title>슈뢰딩거 방정식의 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-schrodinger-equation/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-schrodinger-equation/</guid>
      <description>시간에 무관한 슈뢰딩거 방정식 $$ H\psi=\left(-\frac{\hbar^{2}}{2m}\frac{ d ^{2} }{ d x^{2} }+V\right)\psi=E\psi \\ H\psi=\left(-\frac{\hbar^{2}}{2m}\nabla^{2}+V\right)\psi=E\psi $$ 시간에 의존하는 슈뢰딩거 방정식 $$ i\hbar\frac{ \partial \psi}{ \partial t}=\left(-\frac{\hbar^{2}}{2m}\frac{ \partial ^{2} }{\partial x^{2} }+V\right)\psi \\ i\hbar\frac{ \partial \psi}{ \partial t}=\left(-\frac{\hbar^{2}}{2m}\nabla^{2}+V\right)\psi $$ 슈뢰딩거 방정식이란 복소 파동함수의 에너지, 위치, 시간에 관련된 편미분 방정식을 말한다. 쉽게 말하자면 고전 역학에서 $$ F=ma $$ 와 같은 것이다. 이를 이용해서 여러 포텐셜 상황에서의 파동함수와 파동함수의 에너지를 계산</description>
    </item>
    
    <item>
      <title>오일러 미분 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-euler-differential-equation/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-euler-differential-equation/</guid>
      <description>다음과 같은 꼴의 미분 방정식을 오일러 미분 방정식 혹은 오일러-코시 방정식이라 한다. $$ a_{2}x^{2}\frac{ d ^{2 }y}{ dx^{2} }+a_{1}x\frac{ d y}{ d x }+a_{0}y=0 $$ 우변이 $0$이 아닌 동차 방정일 경우 에는 $x=e^{z}$로 치환해서 풀면 된다. 계산의 편의를 위해 $(1)$의 양 변을 $a_{2}$로 나누고 나머지 두 항의 계수를 다시 $a_{1}$, $a_{0}$라고 하자. 그러면 $$ \color{green}{x^{2}\frac{ d ^{2 }y}{ dx^{2} }}+\color{blue}{a_{1}x\frac{ d</description>
    </item>
    
    <item>
      <title>오일러 토션트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/totient-fuction/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/totient-fuction/</guid>
      <description>초등적 정수론에서의 토션트 함수다음과 같이 정의된 산술 함수 $\varphi$ 을 토션트 함수 라고 한다. $$ \varphi (n) := \sum_{\gcd ( k , n ) = 1} 1 $$ **[1] 토션트 급수** : 놈 $N$ 이다. 다시 말해, $$ \sum_{d \mid n } \varphi (d) = N(n) $$ **[2] 승법성** : $\gcd (m,n) = 1$ 을 만족하는 모든 $m, n \in \mathbb{N}$ 에 대해 $\varphi (mn) = \varphi (m) \varphi (n) $$ $\begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ \varphi(n) &amp;amp; 1 &amp;amp; 1 &amp;amp; 2 &amp;amp; 2 &amp;amp; 4 &amp;amp; 2</description>
    </item>
    
    <item>
      <title>구면 좌표계 라플라스 방정식의 일반해</title>
      <link>https://freshrimpsushi.github.io/posts/general-solution-of-laplaces-equation-in-spherical-coordinates/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-solution-of-laplaces-equation-in-spherical-coordinates/</guid>
      <description>구면좌표계에서 라플라스 방정식은 아래와 같다. $$ \nabla ^2 f = \frac{1}{r^2}\frac{\partial}{\partial r} \left( r^2\frac{\partial f}{\partial r} \right) + \frac{1}{r^2\sin\theta}\frac{\partial}{\partial\theta}\left( \sin\theta \frac{\partial f}{\partial \theta} \right) + \frac{1}{r^2\sin^2\theta}\frac{\partial^2 f}{\partial^2 \phi}=0 $$ $f$가 $f(r,\theta,\phi)=R(r)\Theta(\theta)\Phi(\phi)$로 변수분리가능하다고 가정하자. 지름 성분에 대한 일반해는 오일러 미분 방정식을 풀어서 아래와 같이 구할 수 있다. $$ R(r)=\sum \limits_{l=0}^{\infty}R_{l}(r)=\sum \limits_{l=0}^{\infty}\left( A_{l}r^{l}+\frac{</description>
    </item>
    
    <item>
      <title>그래프의 오리엔테이션</title>
      <link>https://freshrimpsushi.github.io/posts/orientation-of-graph/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orientation-of-graph/</guid>
      <description>유향 그래프 $D$ 가 주어져 있다고 하자.1. 아크의 유한 시퀀스를 유향 워크Directed Walk 라고 하고 다음과 같이 나타낸다. $$ v_{0} v_{1} , v_{1} v_{2} , \cdots , v_{m-1} v_{m} \\ v_{0} \rightarrow v_{1} \rightarrow v_{2} \rightarrow \cdots \rightarrow v_{m-1} \rightarrow v_{m} $$ 이 때 $v_{0}$ 을 **시점**Initial Vertex , $v_{m}$ 을 **종점**Final Vertex 이라 하고 $m$ 을 **길이**Length 라 부른다.**2.** 유향 워크의 아크가 모두</description>
    </item>
    
    <item>
      <title>구면좌표계 라플라스 방정식에서 지름 성분 방정식의 일반해</title>
      <link>https://freshrimpsushi.github.io/posts/general-solution-of-radial-equation-for-spherical-coordinates-laplaces-equation/</link>
      <pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-solution-of-radial-equation-for-spherical-coordinates-laplaces-equation/</guid>
      <description>구면좌표계 라플라스 방정식에서 지름성분 방정식의 일반해는 아래와 같다. $$ R(r)=\sum \limits_{l=0}^{\infty}R_{l}(r)=\sum \limits_{l=0}^{\infty}\left( A_{l}r^{l}+\frac{ B_{l}}{r^{l+1}} \right) $$ 이때 $l$은 음이 아닌 정수이다. $A_{l}$, $B_{l}$은 임의의 상수.극각, 방위각에 대한 해보다는 구하는 과정이 비교적 간단하다.**풀이 구면좌표계 라플라스 방정식에서 극각 $\theta$와 방위각 $\phi$ 성분에 대한 해를 구면조화함수라고 한다. 구면</description>
    </item>
    
    <item>
      <title>구면 조화함수</title>
      <link>https://freshrimpsushi.github.io/posts/spherical-harmonics/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spherical-harmonics/</guid>
      <description>구면 조화함수는 다음과 같다. $$ Y_{l}^{m}(\theta,\phi)=e^{im\phi}P_{l}^{m}(\cos \theta) $$ 이때 $l$은 $l=0,1,2\cdots$이고 $m$은 $ -l \le m \le l$를 만족하는 정수이다. 또한 $P_{l}^{m}(\cos\theta)$는 다음과 같다. $$ \begin{align*} P_{l}^{m}(\cos \theta)&amp;amp;= (1-\cos ^{2}\theta)^{\frac{|m|}{2}} \frac{ d^{|m|} }{ dx^{|m|} } P_{l}(x) \\ &amp;amp; =(1-\cos ^{2}\theta)^{\frac{|m|}{2}} \frac{ d^{|m|} }{ dx^{|m|} }\left[ \dfrac{1}{2^l l!} \dfrac{d^l}{dx^l}(x^2-1)^l \right] \end{align*} $$ 라플라스 방정식을 만족하는 함수를 조화함수라고 한다. 구면 조화함수</description>
    </item>
    
    <item>
      <title>뫼비우스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/m%C3%B6bius-function/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/m%C3%B6bius-function/</guid>
      <description>소수 $p_{1} , \cdots , p_{k}$ 에 대해 자연수 $n$ 을 $n = p_{1}^{a_{1}} \cdots p_{k}^{a_{k}}$ 과 같이 나타낸다고 하자. 다음과 같이 정의된 산술 함수 $\mu$ 을 **뫼비우스 함수** 라고 한다. $$ \mu(n) := \begin{cases} 1 &amp;amp;, n=1 \\ (-1)^{k} &amp;amp;, a_{1} = \cdots = a_{k} = 1 \\ 0 &amp;amp; , \text{otherwise} \end{cases} $$ **[1] 뫼비우스 급수** : 아이덴터티 $I$ 다. 다시 말해, $$ \sum_{d \mid n } \mu (d) = I(n) $$ **[2] 승법성** : $\gcd (m,n) = 1$ 을 만족하는 모든 $m, n \in \mathbb{N}$ 에 대해 $\mu (mn) = \mu (m) \mu (n) $$</description>
    </item>
    
    <item>
      <title>씨티 촬영의 원리 라돈 변환</title>
      <link>https://freshrimpsushi.github.io/posts/principle-of-ct-radon-transform/</link>
      <pubDate>Thu, 23 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/principle-of-ct-radon-transform/</guid>
      <description>**1. Computer Tomography CT는 Computer Tomography의 약자로 컴퓨터 단층촬영이라는 뜻이다. 몸의 단면 사진을 얻는 기술인데 컴퓨터 계산이 필요하기 때문에 이러한 이름이 붙었다. CT는 각각의 물질마다 X-선1을 흡수하는 정도가 다르다는 점을 이용한다. 아래의 그림을 보자.그림 가운데 원을 신체 어딘가의 단면이라고 하자. 잘라서 보지 않는 한 내부는 어떻게 생긴</description>
    </item>
    
    <item>
      <title>그래프에서의 거리 네이버후드 지름 둘레</title>
      <link>https://freshrimpsushi.github.io/posts/distance-neighborhood-diameter-girth-in-graph/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distance-neighborhood-diameter-girth-in-graph/</guid>
      <description>그래프 $G$ 에서 시점이 $v \in V(G)$ 고 종점이 $w \in V(G)$ 인 패스의 집합을 $P(v,w)$ 이라 하고 $v \in V(G) $ 를 포함하는 사이클의 집합을 $C(v)$ 라 하자. 그리고 워크 $x$ 의 길이를 $l(x)$ 과 같이 나타내자.1. 두 버텍스 $v,w \in V(G)$ 사이의 거리 $d$ 는 $v$ 가 시점이고 $w$ 가 종점인 패스의 길이 중 가장 작은 값으로 정의된다. 다시 말해, $$ d(v,w) := \min_{v,w \in V(G)} \left\{ l(x) : x \in P(v,w) \right\} $$ **2.** 버텍스 $v \in V(G)$ 에 대해 $v$ 와의 거리</description>
    </item>
    
    <item>
      <title>움직이는 점전하가 만드는 자기장</title>
      <link>https://freshrimpsushi.github.io/posts/the-magnetic-field-of-a-moving-point-charge/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-magnetic-field-of-a-moving-point-charge/</guid>
      <description>움직이는 점전하가 만드는 자기장은 다음과 같다. $$ \mathbf{B}=-\frac{1}{c}\frac{1}{4\pi \epsilon_0} \frac{q}{ (\mathbf{u}\cdot \boldsymbol{\eta})^{3}} \boldsymbol{\eta} \times \left[ (c^{2}-v^{2})\mathbf{v}+(\boldsymbol{\eta} \cdot \mathbf{a})\mathbf{v}+(\boldsymbol{\eta} \cdot \mathbf{u})\mathbf{a} \right] $$ 또한 움직이는 점전하가 만드는 전기장과 아래의 관계식이 성립한다. $$ \mathbf{B}(\mathbf{r},t)=\mathbf{E}(\mathbf{r},t) $$ 움직이는 점전하가 만드는 전위는 리에나르-비케르트 전위이다. $$ V(\mathbf{r}, t)= \frac{1}{4\pi \epsilon_0} \frac{qc}{ (\eta c -\boldsymbol{\eta}\cdot \mathbf{v})} ,\quad \mathbf{A}(\mathbf{r}, t) = \frac{ \mathbf{v} } {c^2} V(\mathbf{r}, t) $$ 자기장은$$ \quad \mathbf{B}=\nabla \times \mathbf{A} $$ 로 표현된다. 그러므로 $$ \begin{align*} \nabla \times \mathbf{A} &amp;amp;= \nabla \times \left( \frac{\mathbf{v}}{c^{2}}V(\mathbf{r},t) \right)</description>
    </item>
    
    <item>
      <title>물리학에서 델 연산자란</title>
      <link>https://freshrimpsushi.github.io/posts/del-operator-in-physics/</link>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/del-operator-in-physics/</guid>
      <description>델 연산자란 간단히 말해서 3차원 공간 좌표에 대한 미분 연산자이다. 연산자라는 말이 생소하다면 그냥 대상을 계산하는 규칙이라고 이해하면 된다. 예를 들어 $\dfrac{d}{dx}$는 함수를 $x$에 대해서 미분하라는 미분 연산자이다. 델 연산자는 보통 아래와 같이 소개된다. $$ \nabla = \frac{ d }{ d x }\hat{\mathbf{x}}+\frac{ d }{ d y }\hat{\mathbf{y}}+\frac{ d }{ d z }\hat{\mathbf{z}} $$ 마치 벡터인 것처럼</description>
    </item>
    
    <item>
      <title>양자역학에서 교환자란</title>
      <link>https://freshrimpsushi.github.io/posts/commutator-in-quantum-mechanics/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/commutator-in-quantum-mechanics/</guid>
      <description>양자역학에서 두 연산자 $A$, $B$에 대한 교환자는 아래와 같다. $$ [A,B]=AB-BA $$ 이건 $0$이 아니냐는 의문이 들 수도 있다. 연산자는 행렬로 표현되고, 두 행렬의 곱은 교환법칙이 성립하지 않으므로 곱하는 순서에 따라 다른 결과를 가질 수도 있다. 수학과 전공과목으로 선형대수학을 배우면 알겠지만 행렬, 벡터, 함수 등은 모두 같은 것으로 이해할 수 있다. 연산자 또</description>
    </item>
    
    <item>
      <title>해석적 정수론에서의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-in-analytic-number-theory/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-in-analytic-number-theory/</guid>
      <description>다음과 같이 정의된 산술 함수 $N$ 을 놈 이라고 한다. $$ N(n) := n $$ [1] 놈 급수 : 시그마 함수 $\sigma = \sigma_{1}$ 다. 다시 말해, $$ \sum_{d \mid n } N(d) = \sigma_{1}(n) $$ **[2] 완전 승법성** : 모든 $m,n \in \mathbb{N}$ 에 대해 $N(mn) = N(m) N (n) $$ $\begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ N(n) &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ \sum_{d \mid n} N(d) &amp;amp; 1 &amp;amp; 3 &amp;amp; 4 &amp;amp; 7 &amp;amp; 6 &amp;amp; 6 &amp;amp; 8 &amp;amp; 15 &amp;amp; 13 &amp;amp; 18 \end{matrix} $$ 특</description>
    </item>
    
    <item>
      <title>드브로이 관계식과 물질파</title>
      <link>https://freshrimpsushi.github.io/posts/de-broglie-relation-matter-wave/</link>
      <pubDate>Sun, 19 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/de-broglie-relation-matter-wave/</guid>
      <description>빛이 파동인지 입자인지에 대한 문제는 물리학 역사에서 큰 관심사였다. 20세기 초 여러 실험들을 통해 빛은 입자의 성질과 파동의 성질을 동시에 지닌다는 것을 알게 됐다. $$ \begin{align} E=\sqrt{p^2c^2+m_{0}^{2}c^{4}} \\ E=h\nu= \frac{hc}{\lambda} \end{align} $$ 입자의 상대론적 에너지를 표현하는 식인 $(1)$과 광전 효과로부터 얻은 식 $(2)$에 의해 질량이 $0$인 광자의 파장은 아래와 같이 운동량과 플랑크 상수로 표현</description>
    </item>
    
    <item>
      <title>그래프 이론에서의 워크 트레일 패스 사이클</title>
      <link>https://freshrimpsushi.github.io/posts/walk-trail-path-cycle/</link>
      <pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/walk-trail-path-cycle/</guid>
      <description>그래프 $G$ 가 주어져 있다고 하자.1. 에지의 유한 시퀀스를 워크 라고 하고 다음과 같이 나타낸다. $$ v_{0} v_{1} , v_{1} v_{2} , \cdots , v_{m-1} v_{m} \\ v_{0} \rightarrow v_{1} \rightarrow v_{2} \rightarrow \cdots \rightarrow v_{m-1} \rightarrow v_{m} $$ 이 때 $v_{0}$ 을 **시점**Initial Vertex , $v_{m}$ 을 **종점**Final Vertex 이라 하고 $m$ 을 **길이**Length 라 부른다.**2.** 워크의 에지가 모두 다르면 **트레일** 이라고 한다</description>
    </item>
    
    <item>
      <title>양자역학에서 기댓값이란</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-value-in-quantum-mechanics/</link>
      <pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-value-in-quantum-mechanics/</guid>
      <description>결론부터 말하자면 고등학교 수학 통계 부분에서 배운 그 기댓값이 맞다. 양자역학을 공부하면서 기댓값을 이해하기 어렵다면 그 어려움에 대한 종류는 크게 두가지가 있다. 첫째는 정의 그 자체를 이해하는 것에 대한 어려움이고 둘째는 수식이 왜 그렇게 표현되는지에 대한 의문이다.**1. 기댓값이란? 여러분도 알다시피 주사위를 던질 때 주사위 눈에 대한 기댓</description>
    </item>
    
    <item>
      <title>움직이는 점전하가 만드는 전기장</title>
      <link>https://freshrimpsushi.github.io/posts/the-field-of-a-moving-point-charge/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-field-of-a-moving-point-charge/</guid>
      <description>움직이는 점전하가 만드는 전자기장 $$ \mathbf{E}(\mathbf{r}, t) = \frac{q}{4\pi\epsilon_0} \frac{\eta} {( \boldsymbol{\eta}\cdot \mathbf{u} )^3 } \left[(c^2-v^2)\mathbf{u} +\boldsymbol{\eta}\times (\mathbf{u} \times \mathbf{a} ) \right] $$ $$ \mathbf{B} (\mathbf{ r}, t) =\frac{1}{c} \hat{\boldsymbol{\eta}}\times \mathbf{ E } (\mathbf{ r}, t) $$ 움직이는 점전하가 만드는 전기장, 자기장은 리에나르-비케르트 전위를 사용하여 구할 수 있다. $$ V(\mathbf{r}, t)= \frac{1}{4\pi \epsilon_0} \frac{qc}{ (\eta c -\boldsymbol{\eta}\cdot \mathbf{v})} ,\quad \mathbf{A}(\mathbf{r}, t) = \frac{ \mathbf{v} } {c^2} V(\mathbf{r}, t) $$ 또한 전자기장은 아래의 식으로 구할 수 있다.$$ \mathbf{ E} = -\nabla V -\frac{\partial \mathbf{ A} }{\partial t},\quad \mathbf{B}=\nabla \times \mathbf{A} $$ 움직이는 점</description>
    </item>
    
    <item>
      <title>디바이저 함수</title>
      <link>https://freshrimpsushi.github.io/posts/divisor-function/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divisor-function/</guid>
      <description>$\alpha \in \mathbb{C}$ 에 대해 다음과 같이 정의된 $\sigma_{\alpha} : \mathbb{N} \to \mathbb{C}$ 을 **디바이저 함수** 라고 부른다. $$ \sigma_{\alpha} (n) := \sum_{d \mid n} d^{\alpha} $$ **[1] 승법성** : $\gcd (m,n) = 1$ 을 만족하는 모든 $m, n \in \mathbb{N}$ 에 대해 $\sigma_{\alpha} (mn) = \sigma_{\alpha} (m) \sigma_{\alpha} (n)$**[2]** 소수 $p$ 와 자연수 $a$ 에 대해 $$ \sigma_{\alpha} \left( p^{a} \right) = \begin{cases} a +1 &amp;amp; , \alpha = 0 \\ {{ p^{\alpha (a+1)} - 1 } \over { p^{\alpha} - 1 }} &amp;amp;,\alpha \ne 0 \end{cases} $$ 특히 $\alpha = 0$ 이면 약수의 수를 나타내는 함수 $d := \sigma_{0}$ 로 나타내기도 한다.</description>
    </item>
    
    <item>
      <title>패러티 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/parity-operator/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/parity-operator/</guid>
      <description>패러티 연산자 $P$는 양자역학에서 축퇴된 두 고유함수를 구별하는데 쓰이는 연산자로 정의는 아래와 같다. $$ P\psi (x) = \psi(-x) $$ 축퇴 문서에서 두 파동함수 $$ \psi_{1}(x)=e^{ikx},\quad \psi_{2}(x)=e^{-ikx} $$ 를 예로 들었다. 이 때 $$ u_{+}(x)=\psi_{1}(x) +\psi_{2}(x) \\ u_{-}(x)=\psi_{1}(x)-\psi_{2}(x) $$ 라고 하자. 그러면 패러티 연산자의 적용 결과가 달라 나와 두 함수를 구별할 수 있게 된다. $$ Pu_{+}=e^{-ikx}+e^{ikx}=u_{+} \\ Pu_{-}=e^{-ikx}-e^{ikx}=-u_{-} $$ **패러티 연산자의 성질 한편 패러티 연산자의 정의에 의해 파</description>
    </item>
    
    <item>
      <title>무한 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/infinite-graph/</link>
      <pubDate>Tue, 14 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/infinite-graph/</guid>
      <description>1. 그래프 $G$ 의 버텍스 집합 $V(G)$ 나 에지 집합 $E(G)$ 가 무한 집합이면 $G$ 를 무한 그래프 라고 한다.2. $V(G)$ 와 $E(G)$ 가 모두 가산 집합인 무한 그래프 $G$ 를 가산 그래프Countable Graph 라고 한다.3. 무한 그래프 $G$ 의 버텍스 $v \in V(G)$ 에 대해 $A(v)$ 를 다음과 같이 정의하자. $$ A(v) := \left\{ w : vw \in E(G) \right\} $$ 무한 그래프 $G$ 의 버텍스의 차수는 다음과 같이 $A(v)$ 의 기수로 정의한다. $$ \deg (v)</description>
    </item>
    
    <item>
      <title>승법적 함수의 아벨리안 그룹</title>
      <link>https://freshrimpsushi.github.io/posts/abelian-group-of-multiplicative-functions/</link>
      <pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abelian-group-of-multiplicative-functions/</guid>
      <description>승법적 함수 들의 집합 $M$ 과 이항 연산 $$ 에 대해 $(M,)$ 는 아벨리안 그룹이다.산술 함수의 집합 $A$ 가 컨볼루션 $*$과 더불어 아벨리안 그룹 $(A,*)$ 가 되듯, 승법적 함수 역시 아벨리안 그룹이 된다. 물론 $M \le A$, 즉 $M$ 이 $A$ 의 서브 그룹이 된다. 증명 Part (ii)., (v). 결합 법칙컨볼루션의 성질결합 법칙 : $(fg) k = f(gk)$교환 법칙 : $f * g = g * f$승법적 함수는 산술 함수고</description>
    </item>
    
    <item>
      <title>이분 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/bipartite-graph/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bipartite-graph/</guid>
      <description>그래프 $G$ 의 버텍스 $V(G)$ 에 대해 파티션 $\left\{ A,B \right\}$ 가 존재하고 모든 $xy \in E(G)$ 에 대해 $x \in A, y \in B$ 혹은 $x \in B , y \in A$ 이면 $G$ 를 이분 그래프 라 부르고 $G = G(A,B)$ 와 같이 나타내기도 한다.이분 그래프는 그 이름 그대로 버텍스가 두 부류로 나뉘며, 같은 부류끼리는 인접하지 않은 그래프다. 가령 다음의 그림을 보면 주황색 버텍스 끼리는 인접하지 않고, 파란색 버텍스끼리는</description>
    </item>
    
    <item>
      <title>감마 분포</title>
      <link>https://freshrimpsushi.github.io/posts/gamma-distribution/</link>
      <pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gamma-distribution/</guid>
      <description>$k, \theta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\Gamma ( k , \theta )$ 를 감마 분포 라고 한다. $$ f(x) = {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x^{k - 1} e^{ - x / \theta} \qquad , x &amp;gt; 0 $$ * $\Gamma$ 는 감마 함수를 나타낸다. * 감마 분포의 확률 밀도 함수는 $\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같이 정의되기도 한다. 본질적으로는 $\theta = {{ 1 } \over { \beta }}$ 냐의 차이 뿐이다. $$ f(x) = {{ \beta^{\alpha } } \over</description>
    </item>
    
    <item>
      <title>그래프 컴플리먼트</title>
      <link>https://freshrimpsushi.github.io/posts/complement-of-graph/</link>
      <pubDate>Sun, 29 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complement-of-graph/</guid>
      <description>심플 그래프 $G$ 에 대해 다음을 만족하는 그래프 $\overline{G}$ 를 $G$ 의 컴플리먼트 라고 한다. $$ V \left( \overline{G} \right) = V(G) \\ vw \in E \left( \overline{G} \right) \iff vw \notin E(G) $$ 보통의 수학에서 컴플리먼트Complement 가 그러하듯 그래프의 컴플리먼트는 補(도울 보)의 개념을 의미한다. 한국어 순화로는 여그래프Complement Graph 가 될텐데, 다 마음에 들지 않아서 그냥 컴플리먼트라 쓴다</description>
    </item>
    
    <item>
      <title>산술 함수의 아벨리안 그룹</title>
      <link>https://freshrimpsushi.github.io/posts/abelian-group-of-arithmetic-functions/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abelian-group-of-arithmetic-functions/</guid>
      <description>$f(1) \ne 0$ 이 아닌 산술 함수 들의 집합 $A = \left\{ f : \mathbb{N} \to \mathbb{C} \mid f(1) \ne 0 \right\}$ 과 이항 연산 $$ 에 대해 $(A,)$ 는 아벨리안 그룹이다.엄밀히 말하면 모든 산술 함수의 집합이 아벨리안 그룹이 될 수 있는 것은 아니다. 대수적 구조가 그룹이 되기 위한 마지막 조건인 역원의 존재성 때문인데, 다행스럽게도 그렇게 어려운 조건은 아니고 $f(1) \ne 0$ 이면 충분하다. 증명 Part (ii)., (v). 결합 법칙컨볼루</description>
    </item>
    
    <item>
      <title>기하 분포의 무기억성</title>
      <link>https://freshrimpsushi.github.io/posts/memoryless-property-of-geometric-distribution/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/memoryless-property-of-geometric-distribution/</guid>
      <description>지수 분포의 무기억성$X \sim \text{Geo} ( m )$ 이면 $P(X \ge s+ t ,|, X \ge s) = P(X \ge t)$기하 분포는 어떤 사건이 일어나는 횟수에 관심을 두는 이산확률분포다. 지수 분포의 이산화라는 센스에서 생각해보면 이러한 기하분포의 무기억성은 당연하다고 할 수 있겠다.여기서 무기억성 이란 지나온 시간에 의해 앞으로 일어날 일이 영향을 받지 않는 성질이다. 예를 들어 30대의</description>
    </item>
    
    <item>
      <title>서브 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/subgraph/</link>
      <pubDate>Wed, 25 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subgraph/</guid>
      <description>그래프 $G$ 에 대해서 그래프 $H$ 가 $V(H) \subset V(G) $ 와 $ E(H) \subset E(G)$ 를 만족하면 $H$ 가 $G$ 의 서브 그래프 라고 한다.주의해야하는 것은 $H$ 가 $G$ 의 서브 그래프라고 $H \subset G$ 와 같이 나타내면 안 된다는 것이다. 서브 그래프는 직접적으로 그래프 이론에서 어떤 관심의 대상이 된다기보단 당연하고 상식적인 용어로써 의미가 있다. 서브 그래프를 정의함으로써 생각할 수 있는 것들의 예시</description>
    </item>
    
    <item>
      <title>지수 분포의 무기억성</title>
      <link>https://freshrimpsushi.github.io/posts/memoryless-property-of-exponential-distribution/</link>
      <pubDate>Tue, 24 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/memoryless-property-of-exponential-distribution/</guid>
      <description>기하 분포의 무기억성$X \sim \exp{ ( \lambda ) }$ 이면 $P(X \ge s+ t ,|, X \ge s) = P(X \ge t)$지수 분포는 어떤 사건이 일어나는 기간에 관심을 두는 연속확률분포다. 깊게 생각하지 않아도 수명예측이나 보험 등에 응용될 수 있음을 짐작할 수 있다.여기서 무기억성 이란 지나온 시간에 의해 앞으로 일어날 일이 영향을 받지 않는 성질이다. 예를 들어 30대의 남성이나 50대의 남</description>
    </item>
    
    <item>
      <title>그래프의 집합 표현</title>
      <link>https://freshrimpsushi.github.io/posts/set-representation-of-graph/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/set-representation-of-graph/</guid>
      <description>두 그래프 $G_{1}$ 과 $G_{2}$ 에 대해 $V(G_{1}) \cap V(G_{2}) = \emptyset$ 이라고 하자. 그러면 두 그래프의 **유니언**Union $G = G_{1} \cup G_{2}$ 은 버텍스 셋 $V(G_{1}) \cup V(G_{2})$ 과 에지 셋 $E (G_{1}) \cup E ( G_{2} )$ 을 가지는 그래프다. 그래프 $H$ 가 그래프들의 유니언으로 표현될 수 없으면 $H$ 를 **연결되었다**Connected 고 하고, 그 외에는 **단절되었다**Disconnected 고 한다. 단</description>
    </item>
    
    <item>
      <title>지수 분포와 푸아송 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-exponential-and-poisson/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-exponential-and-poisson/</guid>
      <description>푸아송 프로세스사건이 일어날 때 걸리는 시간 $X_{k}$ 에 대해 $X_{k} \sim \exp (\lambda) $ 이면 단위시간 당 발생하는 사건의 횟수 $N$ 에 대해 $\displaystyle N \sim \text{Poi} (\lambda)$ 지수 분포와 푸아송 분포의 직관적인 정의를 생각해보자. 지수분포는 어떤 사건이 발생하기까지 걸리는 시간에 관심이 있고, 푸아송분포는 단위 시간 내에 어떤 사건이 몇 번 발생하는지 관심이 있다. 어떤 사건이 일어나는 시간과 사건이</description>
    </item>
    
    <item>
      <title>지수 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-exponential-distribution/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-exponential-distribution/</guid>
      <description>$X \sim \exp ( \lambda)$ 면 $$ E(X) = {{ 1 } \over { \lambda }} \\ \text{Var} (X) = {{ 1 } \over { \lambda^{2} }} $$ Strategy : 지수 분포의 정의에서 직접 연역한다. 지수 분포의 정의$\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\exp ( \lambda)$ 를 지수 분포 라고 한다. $$ f(x) = \lambda e^{-\lambda x} \qquad , x \ge 0 $$ 증명(평균) $$ \displaystyle E(X)=\int _{ 0 }^{ \infty }{ x\cdot \lambda { e } ^{ -\lambda x } }dx $$ $\lambda x=t$ 이라고 두면 $\lambda dx=dt$ 이므로 $$</description>
    </item>
    
    <item>
      <title>지수 분포</title>
      <link>https://freshrimpsushi.github.io/posts/exponential-distribution/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/exponential-distribution/</guid>
      <description>$\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\exp ( \lambda)$ 를 지수 분포 라고 한다. $$ f(x) = \lambda e^{-\lambda x} \qquad , x \ge 0 $$ * 모수는 책에 따라서 그 역수인 $\displaystyle \theta = {{ 1 } \over { \lambda }}$ 을 쓰기도 한다.[1] 적률 생성 함수 : $$ m(t) = {{ \lambda } \over { \lambda - t }} \qquad , t &amp;lt; \lambda $$ [2] 평균과 분산 : $X \sim \exp ( \lambda)$ 면 $$ E(X) = {{ 1 } \over { \lambda }} \\ \text{Var} (X) = {{ 1 } \over { \lambda^{2} }} $$ [a] 무기억성</description>
    </item>
    
    <item>
      <title>다르부의 중간값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-darbouxs-intermediate-value-theorem/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-darbouxs-intermediate-value-theorem/</guid>
      <description>중간값 정리함수 $f : [a,b] \to \mathbb{R}$ 이 $[a,b]$ 에서 미분가능하면 $f&#39;(a) $ 와 $f&#39;(b)$ 사이의 $y_{0}$ 에 대해 $y_{0} = f(c)$ 를 만족하는 $c \in (a,b)$ 가 존재한다.* 본 포스트는 &amp;lsquo;짱지&amp;rsquo;님의 요청으로 작성되었다. 증명 일반성을 잃지 않고, $f&amp;rsquo;(a) &amp;lt; y_{0} &amp;lt; f&#39;(b)$ 라 가정하자. 이에 대해 다음과 같은 함수 $g$ 를 정의하자. $$ g(x) := y_{0} x - f(x) $$ $g$ 는 $[a,b]$ 에서 미분가능하므로 연속이고, 최</description>
    </item>
    
    <item>
      <title>그래프의 행렬 표현</title>
      <link>https://freshrimpsushi.github.io/posts/matrix-representation-of-graph/</link>
      <pubDate>Tue, 17 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/matrix-representation-of-graph/</guid>
      <description>주어진 그래프 $G$ 에 대해 다음과 같이 구해지는 정방행렬 $A$ 를 인접 행렬Adjacent Matrix 이라고 한다. $$ A:= (a_{ij}) = \begin{cases} 1 &amp;amp;, ij \in E(G) \\ 0 &amp;amp;,ij \notin E(G) \end{cases} $$ 인접 행렬은 이산적으로도 풍부한 성질을 가지면서 행렬의 꼴을 하고 있기 때문에 선형 대수의 여러가지 이론을 접목시킬 수 있다. 특히 그 고유값은 네트워크를 응용하는 여러 모델에서 자주 언급된다.가령 위와 같은 그</description>
    </item>
    
    <item>
      <title>자율 시스템의 플로우와 타임-T 맵 Flow and Time-</title>
      <link>https://freshrimpsushi.github.io/posts/t-map-of-autonomous-system/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/t-map-of-autonomous-system/</guid>
      <description>공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 시간 변수 $t$ 와 초기값 $x_{0}$ 에 대한 자율 미분 방정식의 해를 **플로우** 라고 하고 $F(t, x_{0})$ 와 같이 나타낸다. 픽스된 단위 시간 $t = T$ 에 대해 $F_{T}(x) := F(T,x)$ 를 **타임-$T$ 맵** 이라고 한다.**플로우**Flow 는 **궤적**Trajector</description>
    </item>
    
    <item>
      <title>악수 딜레마 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-handshaking-dilemma/</link>
      <pubDate>Fri, 13 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-handshaking-dilemma/</guid>
      <description>임의의 유향 그래프에서, 입력 차수의 합과 출력 차수의 합은 같다.악수 딜레마는 유향 그래프에서의 악수 렘마라고 할 수 있다. 증명 유향 그래프에서 출력 차수의 합은 아크의 수와 같다. 아크는 하나의 버텍스에서 나오고 하나의 버텍스로 들어가므로, 출력 차수와 입력 차수의 합은 같다.■</description>
    </item>
    
    <item>
      <title>동역학에서 자율 시스템과 평형점</title>
      <link>https://freshrimpsushi.github.io/posts/autonomous-system-and-equilibrium-in-dynamics/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/autonomous-system-and-equilibrium-in-dynamics/</guid>
      <description>공간 $V$ 와 함수 $f : V \to V$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ v&#39; = f(v) $$ 1. 변수 $t$ 를 포함하는 미분 방정식에서 $t$ 가 명시적으로Explicitly 드러나지 않으면 자율 미분 방정식Automonous Differential Equation 이라고 한다.2. 상수 함수 $f_{0} (v)$ 가 자율 미분 방정식 $v &#39; = f(v)$ 의 솔루션이면 $f_{0}$ 를 **평형점**Equil</description>
    </item>
    
    <item>
      <title>그래프의 아이소멀피즘</title>
      <link>https://freshrimpsushi.github.io/posts/isomorphism-of-graphs/</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isomorphism-of-graphs/</guid>
      <description>추상대수학에서의 아이소멀피즘그래프 호메오멀피즘두 그래프 $G_{1}$ 와 $G_{2}$ 가 주어져 있다고 하자. $V(G_{1})$ 과 $V(G_{2})$ 사이에 전단사가 존재하고 $G_{1}$ 의 버텍스끼리의 에지의 수와 그에 대응하는 $G_{2}$ 의 버텍스끼리의 에지의 수가 같으면 그 전단사를 **아이소멀피즘** 이라 하고 두 그래프가 **아이소멀픽** 하다고 한다. 다시 말해, 다음을 만족하는 전단사 $\phi : G_{1} \to G_{2}$ 를 아</description>
    </item>
    
    <item>
      <title>푸아송 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-poisson-distribution/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-poisson-distribution/</guid>
      <description>$X \sim \text{Poi}(\lambda)$ 면 $$ E(X) = \lambda \\ \text{Var}(X) = \lambda $$ Strategy : 푸아송 분포의 정의에서 직접 연역한다. 팩토리얼과 급수를 쪼개는 트릭이 중요하다.푸아송 분포의 정의$\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Poi} ( \lambda )$ 를 푸아송 분포라고 한다. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over { x! }} \qquad , x = 0 , 1 , 2, \cdots $$ 증명(평균) $$ \displaystyle \begin{eqnarray*} E(X) &amp;amp;=&amp;amp; \sum _{ x=0 }^{ \infty }{ x\frac { {</description>
    </item>
    
    <item>
      <title>리에나르-비케르트 전위의 시간 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/time-derivative-of-lienard-wiechert-potentials/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-derivative-of-lienard-wiechert-potentials/</guid>
      <description>리에나르-비케르트 전위의 시간에 대한 미분은 다음과 같다.$(a) $$ $\frac{ \partial V}{ \partial t}=\frac{qc}{4\pi \epsilon_{0}} \frac{1}{(\eta c -\boldsymbol{\eta} \cdot \mathbf{v})^{2}} \left( c^{2} -c^{2}\frac{ \partial t}{ \partial t_{r}}-v^{2}+\boldsymbol{\eta}\cdot \mathbf{a} \right)\frac{ \partial t_{r}}{ \partial t } $$ $(b) $$ $\frac{ \partial \mathbf{A}}{ \partial t }=\frac{qc}{4\pi \epsilon_{0}} \frac{1}{(\eta c -\boldsymbol{\eta} \cdot \mathbf{v})^{3}}\left[ (\eta c +\boldsymbol{\eta}\cdot \mathbf{v})(\eta\mathbf{a}/c-\mathbf{v})+ \frac{\eta}{c}\mathbf{v}\left( c^{2} -v^{2}+\boldsymbol{\eta}\cdot \mathbf{a}\right) \right] $$ **보조정리 지연 시각의 시간 미분은 아래와 같다. $$ \frac{ \partial t_{r}}{ \partial t}=\frac{\eta c}{\eta c-\boldsymbol{\eta}\cdot \mathbf{v}}=\frac{ \eta c}{\boldsymbol{\eta} \cdot \mathbf{u}} $$ 이 때 $\mathbf{u}=c\hat{\boldsymbol{\</description>
    </item>
    
    <item>
      <title>푸아송 분포</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-distribution/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-distribution/</guid>
      <description>$\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Poi} ( \lambda )$ 를 푸아송 분포 라고 한다. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over { x! }} \qquad , x = 0 , 1 , 2, \cdots $$ [1] 적률 생성 함수 : $$ m(t) = \exp \left[ \lambda \left( e^{t} - 1 \right) \right] \qquad , t \in \mathbb{R} $$ [2] 평균과 분산 : $X \sim \text{Poi}(\lambda)$ 면 $$ E(X) = \lambda \\ \text{Var}(X) = \lambda $$ [a] 이항분포의 극한분포로써 푸아송분포 유도: $X_{n} \sim B(n,p)$이라고 하자. $\mu \approx np$ 이면</description>
    </item>
    
    <item>
      <title>디리클레 곱에 대한 아이덴터티</title>
      <link>https://freshrimpsushi.github.io/posts/identity-function-under-drichlet-convolution/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/identity-function-under-drichlet-convolution/</guid>
      <description>다음과 같이 정의된 산술 함수 $I$ 를 아이덴터티 함수 라고 한다. $$ I(n) := \left[ {{ 1 } \over { n }} \right] $$ [1] 아이덴터티 급수 : 유닛 함수 $u$ 다. 다시 말해, $$ \sum_{d \mid n}I(d) = u(n) = 1 $$ **[2] 완전 승법성** : 모든 $n , m \in \mathbb{N}$ 에 대해 $I (mn) = I(m) I(n)$**[a] 컨볼루션에 대한 항등원** : 모든 산술 함수 $f$ 에 대해 $$ I * f = f * I = f $$ $\left[ x \right] = \lceil x \rceil$ 는 바닥 함수Floor function 로 불리며 $x$</description>
    </item>
    
    <item>
      <title>물리학을 위한 미분방정식 기초 자주 나오는 미분방정식</title>
      <link>https://freshrimpsushi.github.io/posts/1538/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1538/</guid>
      <description>학부 물리학을 공부하기 위해서라면 미분 방정식 풀이를 수학적으로 접근할 필요가 없을 것 같다. 따라서 최대한 덜 수학적이고 간단하게 설명했다.**미분 방정식이란? 간단히 말해서 미분이 포함된 방정식이다. 어려울 것 없이 가속도는 위치를 두 번 미분한 것이므로 가장 유명한 물리 공식인 $F=ma$도 미분 방정식이다. $x^{3}+3x+1=0$</description>
    </item>
    
    <item>
      <title>음이항 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-negative-binomial-distribution/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-negative-binomial-distribution/</guid>
      <description>$X \sim \text{NB}(r, p)$ 면 $$ E(X) = {{ r (1-p) } \over { p }} \\ \text{Var}(X) = {{ r (1-p) } \over { p^{2} }} $$ Strategy : 음이항 분포가 기하 분포의 일반화라는 점을 이용한다.[b] 기하분포의 일반화 : $Y = X_{1} + \cdots + X_{r}$ 이고 $X_{i} \overset{\text{iid}}{\sim} \text{Geo}(p)$ 면 $Y \sim \text{NB}(r,p)$이 때 기하 분포의 정의는 음이항 분포와 마찬가지로 그 서포트가 $\mathcal{S} = \left\{ 0 , 1 , 2, \cdots \right\}$ 와 같이 되도록 둔다.기하 분포의 평균과 분산</description>
    </item>
    
    <item>
      <title>음이항 분포</title>
      <link>https://freshrimpsushi.github.io/posts/negative-binomial-distribution/</link>
      <pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/negative-binomial-distribution/</guid>
      <description>$r \in \mathbb{N}$ 와 $p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{NB}(r,p)$ 를 음이항 분포 라고 한다. $$ p(x) = \binom{r+x-1}{x-1} p^{r}(1-p)^{x} \qquad, x = 0,1,2,\cdots $$ [1] 적률 생성 함수 : $$ m(t) = \left[ {{ p } \over { 1 - (1-p) e^{t} }} \right]^{r} \qquad , t &amp;lt; -\log (1-P) $$ [2] 평균과 분산 : $X \sim \text{NB}(r, p)$ 면 $$ E(X) = {{ r (1-p) } \over { p }} \\ \text{Var}(X) = {{ r (1-p) } \over { p^{2} }} $$ 음이항 분포는 일어날 확률이 $p$ 인 어떤 사건이 $r$ 번 일어날 때까지의 횟수에 관</description>
    </item>
    
    <item>
      <title>르장드르 미분 방정식의 삼각함수 꼴</title>
      <link>https://freshrimpsushi.github.io/posts/trigonometry-function-form-of-associated-lengendre-differential-equation/</link>
      <pubDate>Fri, 21 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trigonometry-function-form-of-associated-lengendre-differential-equation/</guid>
      <description>삼각함수 꼴의 연관 르장드르 미분 방정식은 아래와 같다. $$ \begin{align} \frac{ d^{2} y}{ d \theta^{2} }+\cot \theta \frac{ d y}{ d \theta}+ \left( l(l+1) -\frac{m^{2}}{\sin ^{2 }\theta} \right)y=0 \\ \mathrm{or} \quad\frac{1}{\sin \theta}\left(\sin \theta \frac{dy}{d\theta} \right)+ \left(l(l+1) -\frac{ m^{2}}{\sin ^{2} \theta} \right)y=0 \end{align} $$ 전자기학, 양자역학 등에서 구면 좌표계 라플라스 방정식을 풀 때 유용하다. 참고로 해는 다음과 같다. $$ \begin{align*} y &amp;amp;= P_{l}^{m}(\cos \theta) \\ &amp;amp;= (1-\cos ^{2}\theta)^{\frac{|m|}{2}} \frac{ d^{|m|} }{ dx^{|m|} } P_{l}(\cos\theta) \end{align*} $$ $P_{l}^{m}(x)$를 연관르장드르 다항식, $P_{l</description>
    </item>
    
    <item>
      <title>산술 함수의 디리클레 곱</title>
      <link>https://freshrimpsushi.github.io/posts/dirichlet-product-of-arithmetical-function/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichlet-product-of-arithmetical-function/</guid>
      <description>두 산술 함수 $f$, $g$ 에 대해 다음을 만족시키는 산술 함수 $h$ 를 $f$, $g$ 의 디리클레 곱 이라고 부른다. $$ h(n) = \sum_{d \mid n} f(d) g \left( {{ n } \over { d }} \right) $$ 디리클레 곱은 $h (n) = (f * g) (n) $ 혹은 $h = f * g$ 와 같이 나타낼 수 있다.디리클레 곱은 그 모양에서 짐작할 수 있듯 **합성곱[컨볼루션]Convolution** 이라고도 불린다. 이러한 정의에서 산술 함수를 단</description>
    </item>
    
    <item>
      <title>기하 분포의 두가지 정의가 가지는 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/295/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/295/</guid>
      <description>기하 분포에 대해 공부하면서 가장 당황스럽고 헷갈리는 것이 교재, 블로그, 위키마다 설명이 다르다는 것이다. 어떤 곳에서는 평균이 $\displaystyle {{1} \over {p}} $ 인데 다른 곳은 $\displaystyle {{1-p} \over {p}} $ 로 쓰기도 한다.이러한 차이는 기하분포를 정의하는 방법이 두가지가 있기 때문이다. 기하분포 $\text{Geo}(p)$ 의 확률질량함수는 $$ p_{1}(x) = p(1-p)^{x-1} , x= 1,2,3,\cdots $$ 혹은 $$ p_{2}(x) = p(1-p)^{x} , x= 0,1,2,\cdots $$ 으로 정의된다. 기댓값은</description>
    </item>
    
    <item>
      <title>산술 함수</title>
      <link>https://freshrimpsushi.github.io/posts/arithmetical-function/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arithmetical-function/</guid>
      <description>정의역이 자연수의 집합 $\mathbb{N}$ 이고 공역이 실수 집합 $\mathbb{R}$ 혹은 복소수 집합 $\mathbb{C}$ 인 함수를 산술 함수 라고 한다.해석적 정수론에서는 다양한 산술 함수의 성질과 관계에 관심을 가지며, 다음과 같은 예들이 있다 :1. 아이덴티티 함수 $I$2. 디바이저 함수 $\sigma_{\alpha}$3. 놈 $N$4. 디바이저 함수 $\sigma_{\alpha}$5. 뫼비우스 함수 $\mu$6. 오일러 토션트 함수 $\varphi$7. 유닛 함수 $u$8. 망골트 함수 $\Lambda$9. 리우빌 함수 $\lambda$산술</description>
    </item>
    
    <item>
      <title>기하 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-geometric-distribution/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-geometric-distribution/</guid>
      <description>$X \sim \text{Geo} (p)$ 면 $$ E(X) = {{ 1 } \over { p }} \\ \text{Var}(X) = {{ 1-p } \over { p^{2} }} $$ 기하 분포의 평균과 분산은 생각보다 쉽게 구해지지 않는다. 본 포스트에서는 유익하면서도 재미있는 두가지 증명을 소개한다.Strategy1 : 등비 급수의 공식과 미분을 사용한다.기하 분포의 정의$p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Geo}(p)$ 를 기하 분포 라고 한다</description>
    </item>
    
    <item>
      <title>리눅스에서 줄리아 최신 버전 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-the-latest-version-julia-in-linux/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-the-latest-version-julia-in-linux/</guid>
      <description>본 포스트에서 줄리아 최신 버전은 v1.3.1이다.Step 1. 줄리아 다운로드Generic Linux Binaries for x86에서 자기 CPU의 비트에 맞는 파일을 다운로드 받는다.Step 2. 압축 해제 후 이동압축을 해제한다.줄리아가 저장되어 있을 위치로 폴더를 옮긴다. 본인이 원하는 곳 어디라도 상관 없는데, 해당 포스트에서는 다음의 위치로 옮겨두었다 :/</description>
    </item>
    
    <item>
      <title>기하 분포</title>
      <link>https://freshrimpsushi.github.io/posts/geometric-distribution/</link>
      <pubDate>Sun, 16 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/geometric-distribution/</guid>
      <description>$p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Geo}(p)$ 를 기하 분포라고 한다. $$ p(x) = p (1 - p)^{x-1} \qquad , x = 1 , 2, 3, \cdots $$ 두가지 정의가 쓰이고 있으니 수식과 정의역에 특히 주의해야한다.[1] 적률 생성 함수 : $$ m(t) = {{ p e^{t} } \over { 1 - (1-p) e^{t} }} \qquad , t &amp;lt; -\log (1-p) $$ [2] 평균과 분산 : $X \sim \text{Geo} (p)$ 면 $$ E(X) = {{ 1 } \over { p }} \\ \text{Var}(X) = {{ 1-p } \over { p^{2} }} $$ [a] 무기</description>
    </item>
    
    <item>
      <title>다차원 맵의 카오스</title>
      <link>https://freshrimpsushi.github.io/posts/chaos-of-multi-dimensional-map/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaos-of-multi-dimensional-map/</guid>
      <description>1차원 맵의 카오스맵 $f : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 의 바운디드 오빗 $\left\{ \mathbb{v}{0}, \mathbb{v}{1}, \cdots \right\}$ 이 다음을 만족하면 이 오빗을 카오틱 하다고 한다.(i) 어심토티컬리 피리어딕이 아니다.(ii) 모든 $i = 1,\cdots , m$ 에 대해 $h_{i} ( \mathbb{v}_{0} ) \ne 0 $**(iii)** $h_{1} ( \mathbb{v}_{0}) &amp;gt; 0$* 오빗이 바운디드라는 말은 모든 $n \in \mathbb{N}_{0}$ 에 대해 $ \left| \mathbb{v}_{n} \right| &amp;lt; M$ 을 만족하는 $M \in \mathbb{R}$ 이 존재한다는 뜻이다.* $h_{i}(\mathbb{v}_{0})$ 은 랴푸노프 지수를 의미한다.$</description>
    </item>
    
    <item>
      <title>이항 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-binomial-distribution/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-binomial-distribution/</guid>
      <description>$ \displaystyle X \sim \text{Bin} (n,p) $ 면 $$ E(X)=np \\ \text{Var}(X)=npq $$ 여기서 $q : = 1-p$ 다.전략 : 조합을 직접 풀어헤친다. 식이 다소 더럽긴 하지만 고등학교 과정에서 충분히 소화할 수 있다. 한번쯤은 직접 해보도록 하자. 수리통계학을 접하면 조금 더 짧고 간단한 방법으로 증명할 수 있게 된다. 평균이든 분산이든 다음과 같은 이항 분포의 확률 질량 함수에서 시작한다.이항 분포의 정의$n \in \mathbb{N}$ 과</description>
    </item>
    
    <item>
      <title>이항 분포</title>
      <link>https://freshrimpsushi.github.io/posts/binomial-distribution/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/binomial-distribution/</guid>
      <description>$n \in \mathbb{N}$ 과 $p \in [0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Bin}(n,p)$ 를 이항 분포 라고 한다. $$ p(x) = \binom{n}{x} p^{x} (1-p)^{n-x} \qquad , x = 0 , 1, \cdots n $$ [1] 적률 생성 함수 : $$ m(t) = \left[ (1-p) + pe^{t} \right]^{n} \qquad , t \in \mathbb{R} $$ [2] 평균과 분산 : $X \sim \text{Bin}(n,p)$ 면 $$ E(X) = np \\ \text{Var}(X) = np(1-p) $$ [a] 이항분포의 극한분포로써 푸아송분포 유도: $X_{n} \sim B(n,p)$이라고 하자. $\mu \approx np$ 이면 $$ X_{n} \overset{D}{\to} \text{Poi} (\mu) $$ [b] 이항분</description>
    </item>
    
    <item>
      <title>회전하는 좌표계에서 운동하는 물체의 속도와 가속도</title>
      <link>https://freshrimpsushi.github.io/posts/906/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/906/</guid>
      <description>달리는 기차가 있고 그 안에서 날아다니는 파리가 있다고 하자. 기차 안의 사람은 파리의 움직임만을 고려하면 되므로 파리의 운동을 설명하기 쉽다. 하지만 기차 밖의 사람은 기차의 운동도 같이 고려해야하기 때문에 훨씬 어렵다. 이때 파리의 운동을 두 부분으로 나누어서 생각해보자. 지면에 대해서 달리는 기차와 기차에 대해서 움직이는 파리로 나눠보자. 기차에</description>
    </item>
    
    <item>
      <title>확률 변수들의 선형 결합</title>
      <link>https://freshrimpsushi.github.io/posts/linear-combinations-of-random-variable/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-combinations-of-random-variable/</guid>
      <description>특정한 분포를 따르는 확률변수들의 덧셈확률 변수 $X_{1} , \cdots , X_{n}$ 가 어떤 $(a_{1}, \cdots , a_{n}) \in \mathbb{R}^{n}$ 에 대해 $\displaystyle T := \sum_{i=1}^{n} a_{i} X_{i}$ 를 **선형 결합** 이라고 한다.특히 $X_{1} , \cdots , X_{n}$ 이 iid면 사이즈 $n$ 의 **랜덤 샘플Random Sample** 이라고도 부른다. 통계학의 맥락이라면 모든 관측값에 같은 가중치가 곱해진 $a_{1} = \cdots = a_{n} $ 을 생각할 것이다. 해석학과 선형대수, 분포 이론을 넘</description>
    </item>
    
    <item>
      <title>물리학에서의 감마함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-gamma-function-in-physics/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-gamma-function-in-physics/</guid>
      <description>수학에서의 감마함수감마함수 $\Gamma(p)$는 아래와 같이 정의된다. $$ \Gamma(p)=\int_{0}^{\infty} t^{p-1}e^{-t}dt $$ 딱 봐도 이상하고 어렵게 생겨먹은 이 함수는 팩토리얼을 일반화하기 위해 고안되었다. 알다시피 팩토리얼은 $0$을 포함한 자연수 $n$에 대해서 성립하는 연산이다. 오일러는 이 팩토리얼이라는 연산을 자연수를 넘어 실수까지 확장하고 싶었다. 그래서 찾아낸 함</description>
    </item>
    
    <item>
      <title>확률적 경사 하강법</title>
      <link>https://freshrimpsushi.github.io/posts/stochastic-gradient-descent-method/</link>
      <pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stochastic-gradient-descent-method/</guid>
      <description>대상 함수 $Q$ 와 러닝 레이트 $\alpha &amp;gt; 0$, 배치사이즈 $m$ 과 $i$ 번째 데이터에 대해 $$ \omega_{n+1} := \omega_{n} - \alpha {{ 1 } \over { n }} \sum_{i=1}^{m} \nabla Q_{i} ( \omega_{n} ) $$ 를 **확률적 경사 하강법** 이라고 한다.확률적 경사 하강법은 데이터를 다루는만큼 필연적으로 머신러닝과 깊은 관계를 가지고 있을 수밖에 없다. 몇몇 단어가 익숙하지 않더라도 일단 예시를 통해 이해해보는 게 좋다 :$x_{1}$ 와 $x_{2}$ 가 주어졌을 때</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 변수의 독립</title>
      <link>https://freshrimpsushi.github.io/posts/independence-of-random-variable/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independence-of-random-variable/</guid>
      <description>측도론으로 정의되는 확률 변수의 독립두 확률 변수 $X_{1}, X_{2}$ 의 조인트 확률 밀도 함수 $f$ 혹은 확률 질량 함수 $p$ 에 대해 $X_{1}, X_{2}$ 의 확률 밀도 함수들 $f_{1}, f_{2}$ 혹은 확률 질량 함수 $p_{1}, p_{2}$ 가 다음을 만족하면 $X_{1}, X_{2}$ 가 **독립** 이라고 하고, $X_{1} \perp X_{2}$ 와 같이 나타낸다. $$ f(x_{1} , x_{2} ) \equiv f_{1}(x_{1})f_{2}(x_{2}) \\ p(x_{1} , x_{2} ) \equiv p_{1}(x_{1})p_{2}(x_{2}) $$ 아래의 정리는 이산 확률 변수에 대해서도 같지만, 편의상 연속 확률 변수인 경우</description>
    </item>
    
    <item>
      <title>수학에서의 최적화 기법</title>
      <link>https://freshrimpsushi.github.io/posts/optimization-method/</link>
      <pubDate>Sat, 25 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/optimization-method/</guid>
      <description>1. 함수 $f : \mathbb{R}^{n} \to \mathbb{R}$ 의 함수값이 최소가 되도록 하는 $x^{ * } = \text{argmin}_{x} f(x)$ 를 구하는 문제를 최적화 문제Optimization Problem 라고 하고, 그 문제를 푸는 알고리즘을 최적화 기법 이라고 부른다. 최적화 문제에서 주어진 함수 $f$ 를 특히 대상 함수Objective Function 라고 한다.2. 정의역의 모든 $x$ 에 대해 $f(x^{ * }) \le f(x)$ 를 만족하는 $x^{ * }$ 를 최적해Global</description>
    </item>
    
    <item>
      <title>수리통계학에서의 조건부 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-probability/</link>
      <pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-probability/</guid>
      <description>측도론으로 정의되는 조건부 확률 분포측도론으로 정의되는 조건부 기대값1. 이산 확률 변수 $X_{1}, X_{2}, \cdots , X_{n}$ 에 대해 다음의 $p_{2, \cdots , n \mid 1}$ 를 $X_{1} = x_{1}$ 이 주어졌을 때의 $ X_{2}, \cdots , X_{n}$ 의 **조인트 조건부 확률 질량 함수** 라고 한다. $$ p_{2, \cdots , n \mid 1} ( x_{2} , \cdots ,x_{n} \mid X_{1} = x_{1} ) = {{ p_{1, \cdots , n}(x_{1} , x_{2} , \cdots , x_{n}) } \over { p_{1}( X_{1} = x_{1} ) }} $$ **2.** 연속 확률 변수 $X_{1}, X_{2}, \cdots , X_{n}$ 에 대해 다음</description>
    </item>
    
    <item>
      <title>오일러 적분  베타 함수와 감마 함수</title>
      <link>https://freshrimpsushi.github.io/posts/euler-integral-beta-function-and-gamma-function/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euler-integral-beta-function-and-gamma-function/</guid>
      <description>**오일러 적분$(\mathrm{Euler\ integral})$ 아래의 두 적분을 오일러 적분이라 부른다.$(a)$ 제1종 오일러 적분$(\mathrm{Euler\ integral\ of\ the\ first\ kind})$ : 베타 함수 $$ B(p,q)=\int_0^1 t^{p-1}(1-t)^{q-1}dt,\quad p&amp;gt;0,\quad q&amp;gt;0 $$ $(b)$ 제2종 오일러 적분$(\mathrm{Euler\ integral\ of\ the\ second\ kind})$ : 감마 함수 $$ \Gamma (p) = \int_0^\infty t^{p-1}e^{-t}dt,\quad p&amp;gt;0 $$ **1-1. 베타함수 감마 함수를 팩토리얼의 일반화로 본</description>
    </item>
    
    <item>
      <title>메타 프로그래밍</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-meta-programming/</link>
      <pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-meta-programming/</guid>
      <description>메타 프로그래밍 이란 간단히 말해 프로그램이 코드를 수정하도록 하는 프로그래밍이라고 볼 수 있다. 정확하게 어떤 기법이라기보다는 그러한 개념 전반을 메타 프로그래밍이라고 부르는데, 어떤 프로그램이 다른 언어로 작성된 코드를 열어 &amp;lsquo;문자열&amp;rsquo;을 고치듯이 코드를 수정하거나 같은 언어끼리, 심지어는 스스로가 수정해도 모두</description>
    </item>
    
    <item>
      <title>베타 함수의 이상적분꼴 표현</title>
      <link>https://freshrimpsushi.github.io/posts/improper-integral-representation-of-beta-function/</link>
      <pubDate>Mon, 20 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/improper-integral-representation-of-beta-function/</guid>
      <description>**베타함수 $$ B(p,q)=\int_{0}^{1}t^{p-1}(1-t)^{q-1}dt\quad \cdots (1) $$ 베타함수를 아래와 같은 이상적분으로 표현할 수 있다. $$ B(p,q)=\int_{0}^{\infty}\frac{ t^{p-1} }{ (1+t)^{p+q}}dt\quad \cdots (2) $$ 위 식을 이용하면 계산하기 어려운 적분값을 쉽게 얻을 수 있다. 증명은 어렵지 않다. 증명 $(1)$에서 $t=\frac{x}{1+x}$라고 치환하자. 그러면 $1-t=\frac{1}{1+x}$이고, 적분 범위는 $\int_{0}^{1}\rightarrow \int_{0}^</description>
    </item>
    
    <item>
      <title>scp로 서버에 파일 업로드하고 서버에서 다운로드 받는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-scp-command/</link>
      <pubDate>Sun, 19 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-scp-command/</guid>
      <description>scp는 아마도 s erver c &amp;lt;sup&amp;gt;op y의 줄임말로, ssh 서버를 사용할 때 업로드와 다운로드를 하는 커맨드다. 띄어쓰기와 @, :의 위치에 주의하도록 하자.서버의 계정을 serverACC, 서버의 주소를 serverADD, 서버 내에서 파일을 업로드 하거나 다운로드 받을 디렉터리를 serverDIR, 내가 전송하고자 하는 파일 혹은 디렉터리를 Object, 다운로드 받을 때 내가 다운로드 받고자 하는 디렉터리를 localDI</description>
    </item>
    
    <item>
      <title>베타함수와 감마함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-between-beta-function-and-gamma-function/</link>
      <pubDate>Sat, 18 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-between-beta-function-and-gamma-function/</guid>
      <description>**베타함수와 감마함수의 관계 $$ B(p,q) = {{\Gamma (p) \Gamma (q)} \over {\Gamma (p+q) }} $$ 베타함수는 $\displaystyle B(p,q) := \int_{0}^{1} t^{p-1} (1-t)^{q-1} dt $ 로 정의되며, 감마함수와 마찬가지로 많은 분야에서 응용이 되고 있는 중요한 함수다. 감마함수는 재귀관계를 이용해서 쉽게 계산할 수 있기 때문에 위의 관계식으로 베타함수도 쉽게 계산할 수 있다.직관적으로 보자면 이항계수의 일반화고, 팩토리얼이 등장하므로 당</description>
    </item>
    
    <item>
      <title>확률 변수의 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transform-of-random-variable/</link>
      <pubDate>Fri, 17 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transform-of-random-variable/</guid>
      <description>다변량 확률 변수 $X = ( X_{1} , \cdots , X_{n} )$ 의 조인트 확률밀도함수 $f$ 가 $f(x_{1} , \cdots , x_{n})$ 와 같이 주어져있다고 하고 다음과 같은 변환을 생각해보자. $$ y_{1} = u_{1} (x_{1} , \cdots , x_{n}) \\ \vdots \\ y_{n} = u_{n} (x_{1} , \cdots , x_{n}) $$ 이러한 변환 $u_{1} , \cdots , u_{n}$ 는 단사가 아닐 수 있다. 따라서 $X$ 의 서포트 $S_{X}$ 는 $k$ 개의 파티션 $A_{1} , \cdots , A_{i} , \cdots , A_{k}$ 으로 나누어지고, 다음과 같은 역변환 $w_{ji} \mid_{i=1,\cdots,k \\ j=1,\cdots,n}$ 들을 생각할 수</description>
    </item>
    
    <item>
      <title>감마함수와 팩토리얼이 포함된 여러가지 중요한 공식</title>
      <link>https://freshrimpsushi.github.io/posts/1478/</link>
      <pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1478/</guid>
      <description>감마함수 $$ \Gamma(p)=\begin{cases} \displaystyle \int_0^\infty x^{p-1}e^{-x}dx &amp;amp; p&amp;gt;0 \\ \frac{1}{p}\Gamma(p+1)&amp;amp; p&amp;lt;0 \end{cases} $$ **감마함수의 재귀 공식 $$ \Gamma(p+1)=p\Gamma(p) $$ **감마함수와 팩토리얼이 포함된 여러가지 중요한 공식 $(a)$ $\Gamma(\frac{1}{2})=\sqrt{\pi} $$ (b)$ 오일러 반사 공식 $$ \Gamma(p)\Gamma(1-p)=\dfrac{\pi}{\sin(\pi p)} $$ $(c)$ $\Gamma(n+\frac{1}{2})=\frac{1\cdot 3\cdot \cdot5 \cdots (2n-1)}{2^{n}}\sqrt{\pi}=\frac{(2n-1)!!}{2^n}\sqrt{\pi}=\frac{(2n)!}{4^{n}n!}\sqrt{\pi},\quad n\in \mathbb{N}$이때 $!!$는 더블 팩토리얼이다.$(d)$ 이항계수 $$ \begin{pmatrix} n \\ k \end{pmatrix}=\frac{\Gamma(n+1)}{k! \Gamma(n-k+1)} $$ $(e)$ 오일러-마스케로니상수 $$ \gamma=-\Gamma &#39; (1) $$ $(f)$ 베타 함수 $$ B(p,q)=\frac{\Gamma (p) \Gamma(q)}{\Gamma(p+q)} $$ $(b</description>
    </item>
    
    <item>
      <title>줄리아의 강력한 편의 기능 매크로</title>
      <link>https://freshrimpsushi.github.io/posts/macro-in-julia/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/macro-in-julia/</guid>
      <description>위 코드의 #1, #2, #3은 기능상으로 모두 같다.코드를 실행하면 위와 같이 소요시간을 알려주는데, 이 시간 차이에 큰 의미는 없으므로 당장은 매크로에 대해서만 살펴보도록 하자 :@time : 뒤에 이어지는 함수나 스코프의 실행 시간을 측정해준다. 어떤 상황에서 어떻게 최적화를 해야할지 막막할 때 일단 시간을 재보고 좋은 쪽을 고르기가 편해진다. 언어에 따라서는 시간</description>
    </item>
    
    <item>
      <title>팩토리얼 더블 팩토리얼 멀티 팩토리얼</title>
      <link>https://freshrimpsushi.github.io/posts/factorial-double-factorial-multifactorial/</link>
      <pubDate>Tue, 14 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factorial-double-factorial-multifactorial/</guid>
      <description>**팩토리얼$(\mathrm{factorial}$, 계승, 차례곱$)$ 자연수 $n$에 대해서 $n!$을 $n$팩토리얼이라 읽고 아래와 같이 정의한다. $$ n!=n\cdot(n-1)\cdot(n-2)\cdots 2\cdot 1 =\prod\limits_{k=1}^n k $$ 많은 곳에서 식을 깔끔하게 표현하기 위해 사용된다. $0$팩토리얼은 $0!:=1$으로 정의한다. 팩토리얼을 일반화해서 감마함수라는 것을 정의할 수도 있다.</description>
    </item>
    
    <item>
      <title>R에서 폴더 내부 파일 목록 가져오는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-list-of-folder-in-r/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-list-of-folder-in-r/</guid>
      <description>setwd(&amp;#34;F: \\\ dsr \\\ project&amp;#34;) getwd() list.files(getwd()) list.files(getwd(),pattern=&amp;#34;*.csv&amp;#34;) list.files() : 여러개의 파일로 나눠진 데이터를 취합하거나 메타 프로그래밍 등에 유용하게 쓰이는 함수다 :path : 첫번째 인자로써 디렉터리를 지정해주면 해당 폴더에 있는 파일들의 목록을 반환한다.pattern : 두번째 인자로써 정규표현식으로 규칙을 받아 조건에 만족하는 파일들의 목록만을 반환한다. 예제에서는 와일드카드 를 사용해 pat</description>
    </item>
    
    <item>
      <title>감마함수 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-gamma-function/</link>
      <pubDate>Sun, 12 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-gamma-function/</guid>
      <description>오일러 적분감마함수에 대해 더 쉽게 알고 싶다면 : 팩토리얼의 일반화, 감마함수물리학에서의 감마함수**1. 음이아닌 정수에 대한 감마함수 $\alpha &amp;gt;0$에 대해서 $$ \int_{0}^{\infty} e^{-\alpha x} dx=\left[-\frac{1}{\alpha}e^{-\alpha x}\right]_{0}^{\infty}=\frac{1}{\alpha} $$ 위 식의 양변을 $\alpha$에 대해서 미분하자. 그러면 라이프니츠 적분 규칙에 의해 좌변의 미분이 적분기호 안으로 들어갈 수 있으므로 $$ \begin{align*} &amp;amp;&amp;amp;\int_0^\infty -xe^{-\alpha x}dx&amp;amp;=-\frac{1}{\alpha^2} \\ \implies &amp;amp;&amp;amp; \int_0^\infty xe^{-\alpha x}dx &amp;amp;=</description>
    </item>
    
    <item>
      <title>라이프니츠 적분 규칙</title>
      <link>https://freshrimpsushi.github.io/posts/leibniz-integral-rule/</link>
      <pubDate>Sun, 12 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/leibniz-integral-rule/</guid>
      <description>**라이프니츠 적분 규칙 $f(x,t)$와 $\dfrac{\partial f}{\partial x}(x,t)$가 연속이라고 하자. 그러면 아래의 식이 성립한다. $$ \frac{d}{dx} \int_a^b f(x,t)dt = \int_a^b\frac{\partial f}{\partial x}(x,t)dt $$ 미적분 순서를 바꿀 수 있으므로 매우 유용한 정리이다. 증명 연속이면 적분가능하므로 $$ u(x):=\int_a^b f(x,t)dt $$ 라고 하자. 그러면 $$ \begin{eqnarray*} \frac{ u(x+h)-u(x)}{h} &amp;amp;=&amp;amp; \frac{\int_{a}^{b} f(x+h,t)dt -\int_{a}^{b}f(x,t)dt}{h} \\ &amp;amp;=&amp;amp; \frac{ \int_{a}^{b} \big[f(x+h,t)-f(x,t) \big] dt}{h} \\ &amp;amp;=&amp;amp; \int_{a}^{b} \frac{f(x+h,t)-f(x,t)}{h}dt \end{eqnarray*} \tag{1} $$ 또한 고정된 $y$에 대하여 $f(x,y)</description>
    </item>
    
    <item>
      <title>줄리아에서 파이프 오퍼레이터 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/pipe-operator-in-julia/</link>
      <pubDate>Sat, 11 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pipe-operator-in-julia/</guid>
      <description>R 에서 파이프 오퍼레이터 (1:5) .|&amp;gt; (x -&amp;gt; sqrt(x+2)) .|&amp;gt; sin |&amp;gt; minimum minimum(sin.((x -&amp;gt; sqrt(x+2)).(1:5))) 줄리아는 데이터를 다루는데에서 강점을 내세우는만큼 파이프라인 연산자를 지원한다. 위의 예제 코드는배열 $[1,2,3,4,5]$ 를$\sqrt{x + 2}$ 에 넣어서 얻은 결과를$\sin$ 에 넣은 후그 중 작은 값을 얻는 코드로,위와 아래 코드는 완전히 같은 결과를 낸다. 파이프라인이 복잡한 코드를 작성하는 중에 얼마</description>
    </item>
    
    <item>
      <title>마코프 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-markovs-inequality/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-markovs-inequality/</guid>
      <description>확률변수 $X$ 에 대해 함수 $u(X) \ge 0$ 를 정의하자. $E(u(X))$ 가 존재하면 $c &amp;gt; 0$ 에 대해 $$ \displaystyle P(u(X) \ge c) \le {E(u(X)) \over c} $$ 수많은 증명에 사용되는 보조정리로써 이를 좀 더 편리하게 만든 체비셰프 부등식이 있다.조건에서 $1$차 적률이 존재해야하는 것을 보고 너무 쉽고 당연한 조건으로 여길지 모르겠다. 뭐 어느정도는 맞는 말이지만, 학부생 정도 됐다면 그 존재성이라는 게 아주 당</description>
    </item>
    
    <item>
      <title>파이썬에서 is와 ==의 차이점 How Different is and == in Python</title>
      <link>https://freshrimpsushi.github.io/posts/1444/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1444/</guid>
      <description>if type(150421) is int : print(&amp;quot;!&amp;quot;) else : print(&amp;quot;?&amp;quot;) x = [1,2] y = [1,2] x == y x is y 깃허브에서 파이썬 코드를 보다보면 간혹 is라는 게 보이기도 한다. 코드가 문장처럼 편안하게 읽히는 것은 둘째치더라도 ==와는 분명한 차이가 있어 적재적소에 사용하면 좋다 : ==는 단순하게 값을 비교한다. 우리에게 실제로 보이는 모습을 비교하기 때문에 직관적이다. is는 포인터가 가리키는 객체를</description>
    </item>
    
    <item>
      <title>n차 적률이 존재하면 차수가 n보다 작은 적률도 존재한다</title>
      <link>https://freshrimpsushi.github.io/posts/247/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/247/</guid>
      <description>확률변수 $X$와 자연수 $n$에 대해 $E( X^n )$ 이 존재하면 $E( X^m ), m=1,2,3,\cdots, n$ 도 존재한다.어떤 차수의 적률이든 존재하기만 한다면 그보다 작은 차수의 적률은 항상 존재하지만, 당연히 역은 성립하지 않는다. 물론 실제로 문제를 접해보면 높은 차수의 적률이 먼저 주어지는 경우는 거의 없으나, 어떤 정리의 조건을 나열할 때 지면을 상당히 절약할 수 있게 해주는 정리긴</description>
    </item>
    
    <item>
      <title>타이트 확률 과정</title>
      <link>https://freshrimpsushi.github.io/posts/tight-probability-process/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tight-probability-process/</guid>
      <description>수리통계학에서 정의됐던 확률유계타이트 확률 측도확률 공간 $( \Omega , \mathcal{F} , P)$ 에서 확률 과정 $\left\{ X_n \right\}{n \in \mathbb{N}}$ 이 정의되어 있다고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $\displaystyle \inf{n \in \mathbb{N}} P\left( X_{n} \in K \right) &amp;gt; 1 - \varepsilon$ 를 만족시키는 컴팩트 셋 $K \subset \Omega$ 가 존재하면 $\left\{ X_{n} \right\}$ 이 **타이트** 하다고 한다.수리통계학에서는 확률 유계에 해당하는 개념이다. 타이트는 분포 수렴과 관련해서 다음과 같이</description>
    </item>
    
    <item>
      <title>적률생성함수란</title>
      <link>https://freshrimpsushi.github.io/posts/moment-generating-function/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-generating-function/</guid>
      <description>확률변수 $X$ 와 어떤 양수 $h&amp;gt;0$ 대해 $E(e^{tX})$ 이 $-h&amp;lt; t &amp;lt; h$ 에서 존재하면 $M(t) = E( e^{tX} )$ 를 $X$ 의 적률생성함수 라고 정의한다.적률생성함수는 흔히 mgf 라는 약어로 많이 쓰인다. 수리통계학에서는 비교적 초반에 배우는데, 생소한 정의와 맥락 없는 등장 때문에 수리통계학을 싫어지게 만드는 주범 중 하나다. 적률생성함수를 이해하는게 어려운 것은 보통 교재의 구성 상 대뜸 정의</description>
    </item>
    
    <item>
      <title>줄리아에서 집합 자료형과 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/set-type-and-operator-in-julia/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/set-type-and-operator-in-julia/</guid>
      <description>X = Set([1,2,3,1]); print(X) X[1] for i in X print(i) end if 1∈X print(&amp;#34;!&amp;#34;) else print(&amp;#34;?&amp;#34;) end if 0∈X print(&amp;#34;!&amp;#34;) else print(&amp;#34;?&amp;#34;) end if 0∉X print(&amp;#34;!&amp;#34;) else print(&amp;#34;?&amp;#34;) end if [1,2] ⊆ X print(&amp;#34;!&amp;#34;) else print(&amp;#34;?&amp;#34;) end if [0,1,2] ⊆ X print(&amp;#34;!&amp;#34;) else print(&amp;#34;?&amp;#34;) end Y = [&amp;#34;1&amp;#34;,&amp;#34;2&amp;#34;,3] ∪(X,Y) ∩(X,Y) ∩(Y,X) setdiff(X,Y); X setdiff!(X,Y); X 줄리아에서는 파이썬과 마찬가지로 집합 자료형을 지원한다. 원래 집합 자료형이 그렇듯 쓰는 사람은 요긴하게 쓰고 안 쓰는 사람은 일절 사용하지 않는데, 줄리아는 언어 설계 자체</description>
    </item>
    
    <item>
      <title>수리통계학에서의 첨도</title>
      <link>https://freshrimpsushi.github.io/posts/kurtosis/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kurtosis/</guid>
      <description>1. 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{2}$ 를 $X$ 의 첨도라고 한다. $$ \gamma_{2} := {{ E \left( X - \mu \right)^4 } \over { \sigma^4 }} $$ **2.** 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본첨도 $g_{2}$ 는 다음과 같이 구해진다. $$ g_{2} := \sum_{i=1}^{n} = {{ \left( X - \overline{X} \right)^4 } \over { n \widehat{\sigma}^4 }} - 3 $$ 첨도는 4차 적률로 구해지며, 확률변수의 분포함수가 얼마나 뾰족하게 생겼는지에</description>
    </item>
    
    <item>
      <title>파이썬에서 두 변수값 서로 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-swap-two-variables-in-python/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-swap-two-variables-in-python/</guid>
      <description>변수끼리의 스왑은 흔히 아는 것처럼 임시 변수를 만들어서 옮기는 방식으로 쉽게 구현이 가능하지만, 여러가지 프로그래밍 언어를 다루는 입장에서 포인터를 주고받으면서 변수를 바인딩하는 파이썬의 특성상 이러한 방법이 잘 되는지 확신하기도 어렵고 일일이 변수를 스왑하는 함수를 작성하는 것 귀찮은 일이다. 다음과 같이 파이썬 문법 그 자체로 쉽게 해결해보자</description>
    </item>
    
    <item>
      <title>수리통계학에서의 왜도</title>
      <link>https://freshrimpsushi.github.io/posts/skewness/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/skewness/</guid>
      <description>1. 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{1}$ 를 $X$ 의 왜도라고 한다. $$ \gamma_{1} := {{ E \left( X - \mu \right)^3 } \over { \sigma^3 }} $$ **2.** 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본왜도 $g_{1}$ 은 다음과 같이 구해진다. $$ g_{1} := \sum_{i=1}^{n} {{ \left( X - \overline{X} \right)^3 } \over { n \widehat{\sigma}^3 }} $$ 왜도는 3차 적률로 구해지며, 확률변수의 분포함수가 어떻게 치우쳐져 있는지에 대한 척도</description>
    </item>
    
    <item>
      <title>공분산의 여러가지 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-covariance/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-covariance/</guid>
      <description>평균이 각각 $\mu_{X}$, $\mu_{Y}$ 인 확률 변수 $X$, $Y$ 에 대해 $\text{Cov} (X ,Y) : = E \left[ ( X - \mu_{X} ) ( Y - \mu_{Y} ) \right] $ 을 $X$ 와 $Y$ 의 **공분산** 이라고 정의한다. 공분산은 아래의 성질들을 가진다.**[1]** $\text{Var} (X) = \text{Cov} (X,X)$**[2]** $\text{Cov} (X,Y) = \text{Cov} (Y, X) $**[3]** $\text{Var} (X + Y) = \text{Var} (X) + \text{Var} (Y) + 2 \text{Cov} (X,Y) $**[4]** $\text{Cov} (X + Y , Z ) = \text{Cov}(X,Z) + \text{Cov}(Y,Z) $**[5]** $\text{Cov} (aX + b , cY + d ) = ac \text{Cov}(X,Y) $공분산은 두 변수의 선형상관관계를 나타내며,</description>
    </item>
    
    <item>
      <title>줄리아에서 배열의 슬라이싱과 인덱싱</title>
      <link>https://freshrimpsushi.github.io/posts/slicing-and-indexing-in-julia/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/slicing-and-indexing-in-julia/</guid>
      <description>M = [1. 2. ; 3. 4.] size(M) length(M) x = [[1,2,3,4] for _ in 1:4]; x y = [3,2,5,1,4] y[[4,2,1,5,3]] y[3:end] y[3:4] .= -1; y x = [1 2; 3 4] x[1,:] x[[1],:] x[1,1] = -1; x 줄리아는 R, 파이썬, 매트랩의 장점이 모두 섞여있는 언어다. 배열은 프로그래밍의 근간이 되는만큼 그 활용에서 여러 언어들의 흔적을 찾아볼 수 있다.행렬의 경우 매트랩의 문법과 거의 똑같이 정의하고 거의 똑같이 사용할 수 있다. size() 함수는 매트랩과 똑같이 쓰이고, 파</description>
    </item>
    
    <item>
      <title>피어슨 상관계수</title>
      <link>https://freshrimpsushi.github.io/posts/pearson-correlation-coefficient/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pearson-correlation-coefficient/</guid>
      <description>다음과 같이 정의된 $\rho = \rho(X,Y)$ 를 피어스 상관계수라고 한다. $$ \displaystyle \rho = { {\text{Cov} (X,Y)} \over {\sigma_X \sigma_Y} } $$ (피어슨) 상관 계수 는 두 변수가 서로 (선형) 상관 관계 를 가지고 있는지를 확인하는 척도가 된다. $1$ 이나 $–1$ 에 가까우면 상관관계가 있다고 보고 $0$ 이면 없다고 본다. $[-1, 1]$ 를 벗어나지는 않는다. $$ –1 \le \rho \le 1 $$ 주의할 것은 상관관계와 독립이 같은 개념이 아니라</description>
    </item>
    
    <item>
      <title>평균과 분산의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-mean-and-variance/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-mean-and-variance/</guid>
      <description>평균 $E ( X ) = \mu_{X} $ 과 분산 $\text{Var} (X) = E [ ( X - \mu_{X} )^2 ] $ 은 아래의 성질들을 가진다.**[1]** $E(X + Y) = E(X) + E(Y)$**[2]** $E(aX + b) = a E(X) + b $**[3]** $\text{Var} (X) \ge 0$**[4]** $ \text{Var} ( X ) = E(X^2) - \mu_{X}^2 $**[5]** $ \text{Var} (aX + b) = a^2 \text{Var} (X)$평균과 분산에 관한 것이니만큼 아주 중요한 성질들이다. 특히 **[2]** 는 이른바 **선형성**Linearity 이라 불리우는 성질로써, 수식을 다룰 때 무</description>
    </item>
    
    <item>
      <title>프리컴팩트 확률 과정</title>
      <link>https://freshrimpsushi.github.io/posts/precompact-stochastic-process/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/precompact-stochastic-process/</guid>
      <description>가측 공간 $(S, \mathcal{S})$ 에서 $(S&#39;, \mathcal{S}&#39;)$ 로 가는 연속함수들을 모아놓은 함수공간을 $\mathscr{H} := C \left( S,S&#39; \right)$와 같이 두고 $\left\{ h^{-1}(A&#39;) : h \in \mathscr{H} , A&#39; \in \mathcal{S}&#39; \right\}$ 가 $(S , \mathcal{S})$ 의 세퍼레이팅 클래스라고 하자. $X$ 는 $S$ 에서 정의된 확률 원소, $\left\{ X_n \right\}{n \in \mathbb{N}}$ 은 $S$ 에서 정의된 확률 과정이다.If (1) and (2) :(1) $\left\{ X{n} \right\}$ 은 프리 컴팩트다.(2) 모든 $h \in \mathscr{H}$ 에 대해 $h \left( X_{n} \right) \overset{D}{\to} h(X)$Then :$X_{n} \overset{D}{\to} X$연속 사상 정</description>
    </item>
    
    <item>
      <title>대표값의 수리적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mathematical-property-of-representative-value/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mathematical-property-of-representative-value/</guid>
      <description>통계학의 세가지 대표값 : 최빈값, 중앙값, 평균데이터 $X = \left\{ x_{1} , \cdots , x_{n} \right\} $ 가 주어져 있다고 하자.**[0]** $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{0}$ 가 최소가 되도록 하는 $\theta$ 는 $\text{mode}(X)$**[1]** $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{1}$ 가 최소가 되도록 하는 $\theta$ 는 $\text{median}(X)$**[2]** $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{2}$ 가 최소가 되도록 하는 $\theta$ 는 $\text{mean}(X)$선형대수의 용어로 어렵게 말해보자면 다음과 같다 :**(0)** $l^{0}$-놈을 최</description>
    </item>
    
    <item>
      <title>그리디 알고리즘</title>
      <link>https://freshrimpsushi.github.io/posts/greedy-algorithm/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/greedy-algorithm/</guid>
      <description>그리디 알고리즘 이란 어떤 선택을 할 때 그 순간만을 고려해서 가장 좋은 경우를 고르는 방법이다.그리드 알고리즘은 탐욕Greed 이라는 이름대로 길게 보지 않고 그 순간만을 생각한다. 좋게 말하면 항상 최선을 다하는 것이지만, 크게 보았을 때 이는 현명하지 못할 수도 있다. 다음의 예시를 보자 : 왼쪽 0에서 시작해 오른쪽 1에 도착하는 경로를 찾는 문제가 있</description>
    </item>
    
    <item>
      <title>수리통계학에서의 기대값 평균 분산 적률의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-mean-variance-moment/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-mean-variance-moment/</guid>
      <description>대표값으로써의 평균측도론으로 정의되는 기대값확률 변수 $X$ 가 주어져 있다고 하자.1. 연속 확률 변수 $X$ 의 확률 밀도 함수 $f(x)$ 가 $\displaystyle \int_{-\infty}^{\infty} |x| f(x) dx &amp;lt; \infty$ 를 만족하면 다음과 같이 정의된 $E(X)$ 를 $X$ 의 **기대값** 이라고 한다. $$ E(X) := \int_{-\infty}^{\infty} x f(x) dx $$ **2.** 이산 확률 변수 $X$ 의 확률 질량 함수 $p(x)$ 가 $\displaystyle \sum_{x} |x| p(x) &amp;lt; \infty$ 를 만족하면 다음과 같이 정의된 $E(X)$ 를 $X$ 의 **기대값** 이라고 한</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 변수와 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/1433/</link>
      <pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1433/</guid>
      <description>측도론으로 정의되는 확률 변수와 확률 분포측도론으로 정의되는 누적분포함수표본 공간 $\Omega$ 에서 확률 $P$ 가 정의되어 있다고 하자.1. 정의역이 표본 공간인 함수 $X : \Omega \to \mathbb{R}$ 을 확률 변수 라고 한다. 확률 변수의 치역 $X(\Omega)$ 을 공간Space 이라고도 부른다.2. 다음을 만족하는 함수 $F_{X} : \mathbb{R} \to [0,1]$ 을 $X$ 의 **누적분포함수(Cummulative Distribution Function, cdf)** 라고</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution/</link>
      <pubDate>Sat, 21 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution/</guid>
      <description>수리통계학에서 정의됐던 분포 수렴거의 확실히 수렴 $\implies$ 확률 수렴 $\implies$ 분포 수렴(약한 수렴)거리 공간 $S$ 의 보렐 시그마 필드 $\mathcal{S}:= \mathcal{B}(S)$ 에 대해 가측 공간 $(S,\mathcal{S})$ 을 정의하자.확률 공간 $(\Omega, \mathcal{F}, P)$ 에서 정의된 확률 변수 $X$ 와 확률 과정 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 $n \to \infty$ 일 때 모든 $f \in C_{b}(S)$ 에 대해 다음을 만족하면 $\left\{ X_{n} \right\}$ 이 $X$ 로 **분포 수렴한다**Converge in Distribution 고 말하고 $X_{n} \overset{D}{\to} X$ 와 같</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률과 확률의 덧셈법칙</title>
      <link>https://freshrimpsushi.github.io/posts/1431/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1431/</guid>
      <description>측도론으로 엄밀하게 정의되는 확률1. 같은 조건 하에서 반복할 수 있는 시행을 임의 시행Random Experiment 이라고 한다. 임의 시행에서 얻을 수 있는 모든 결과Outcome 를 모아놓은 집합 $\Omega$ 를 표본 공간Sample Space 이라고 한다. 표본 공간에서 우리가 관심을 가지는 결과들의 집합, 즉 $B \subset \Omega$ 를 사건Event 이라 하고 이들의 집합을 $\mathcal{B}$ 와 같이 나타낸다</description>
    </item>
    
    <item>
      <title>확률론의 혼성 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-portmanteau-theorem-in-probability-theory/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-portmanteau-theorem-in-probability-theory/</guid>
      <description>공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자.다음은 모두 동치다.(1) $P_{n} \overset{W}{\to} P$**(2)** 모든 바운디드, 균등연속함수 $f$ 에 대해 $\displaystyle \int_{S} f dP_{n} \to \int_{S}f d P$**(3)** 모든 클로즈드 셋 $F$ 에 대해 $\displaystyle \limsup_{n\to\infty} P_{n}(F) \le P(F)$**(4)** 모든 오픈 셋 $G$ 에 대해 $\displaystyle P(G) \le \liminf_{n\to\infty} P_{n}(G)$**(5)** $P(\partial A) = 0$ 인 모든 $A$ 에 대해 $\displaystyle \lim_{n\to\infty} P_{n}(A) = P(A)$ * Portmanteau는 &amp;lsquo;여러가지로 이루어진&amp;rsquo; 혹은</description>
    </item>
    
    <item>
      <title>확률과정론에서의 프로젝션 매핑</title>
      <link>https://freshrimpsushi.github.io/posts/projection-mapping/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/projection-mapping/</guid>
      <description>공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이고 $k \in \mathbb{N}$ 이라 하자.1. 이산형 프로젝션 매핑 : (이산 시간) $N = \left\{ n \in \mathbb{N} : n \le \xi, \xi \in [0,\infty] \right\}\subset \mathbb{N}$ 과 $S$ 의 $\displaystyle S^{\sup N} := \prod_{n \in N} S$ 의 원소 $x := (x_{1} , x_{2} , \cdots )$ 에 대해 다음과 같이 정의된 $\pi_{k} : S^{\sup N} \to S^{k}$ 를 **(이산형) 프로젝션 매핑** 이라고 한다. $$ \pi_{k} (x) = (x_{1} , x_{2} , \cdots , x_{k}) $$ **2. 연속형 프로젝션 매핑** : (</description>
    </item>
    
    <item>
      <title>폴란드 공간에서 정의되는 확률 측도는 타이트함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1428/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1428/</guid>
      <description>거리 공간 $(S,\rho)$ 가 폴란드 공간이라고 하자. $S$ 에서 정의되는 모든 확률 측도는 타이트하다.폴란드 공간이란 가분 완비인 거리 공간을 말한다. 확률 측도의 타이트함이라는 것을 논할 때 어지간한 확률이 죄다 타이트한 것이 바로 이 때문이다. 물론 이는 거꾸로 말해 더 나아가 폴란드 공간이 아닌 곳에서 정의된 확률들을 연구해야함을 의미하기도 한다.Strateg</description>
    </item>
    
    <item>
      <title>줄리아에서 배열을 열 방향으로 평행이동시키는 코드</title>
      <link>https://freshrimpsushi.github.io/posts/translation-transform-code-in-julia/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/translation-transform-code-in-julia/</guid>
      <description>function translation(X:: Array{Float64,2},s:: Int64) pixels=length(X[:,1]); X_translation = zeros(pixels, pixels); if s&amp;gt;0 for j=s:pixels-1 X_translation[:,j+1]=X[:,j+1-s]; end elseif s&amp;lt;0 for j=1:pixels+s X_translation[:,j]=X[:,j-s] end else X_translation=X; end return X_translation end 실수 성분을 갖는 $n\times n$ 배열 $X$와 평행이동시킬 칸 $s$를 입력하면 오른쪽으로 $s$만큼 평행이동한 $n\times n$배열 $X_{\mathrm{translation}}$을 반환한다. $s&amp;gt;0$이면 오른쪽으로 $s$칸 만큼 이동하고, $s&amp;lt;0$이면 왼쪽으로 $</description>
    </item>
    
    <item>
      <title>줄리아에서 벡터를 생성하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-generate-vector-in-julia/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-generate-vector-in-julia/</guid>
      <description>매트랩에서 등간격의 행벡터를 생성하는 방법 x1=[1 2 3] x2=[1, 2, 3] x3=[i for i in 1:3] x4=[i for i in 1:3:10] x5=[i for i in 1:3:11] $\mathsf{x1}$은 2차원 배열이다. 생겨먹은건 행벡터와 같기 때문에 성분 좌표를 1개만 입력하면 행벡터인 것 처럼 인식한다.$\mathsf{x2}$, $\mathsf{x3}$, $\mathsf{x4}$, $\mathsf{x5}$는 1차원 배열이다. x=[i for i in n:m]과 같이 입</description>
    </item>
    
    <item>
      <title>폴란드 공간</title>
      <link>https://freshrimpsushi.github.io/posts/polish-space/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/polish-space/</guid>
      <description>다음의 조건들을 만족시키는 위상 공간 $X$ 를 폴란드 공간 이라고 한다.(i) $X$ 는 거리화 가능 공간이다.(ii) $X$ 는 가분 공간이다.(iii) $X$ 는 완비 공간이다.원어가 Polish Space 인데 순화된 표현이 폴란드 공간 인 것에서 짐작할 수 있듯, 우리가 아는 &amp;lsquo;폴란드&amp;rsquo;에서 따온 말이 맞다. 이 공간이 처음 활발하게 연구한 것이 폴란드 출</description>
    </item>
    
    <item>
      <title>연속체 가설</title>
      <link>https://freshrimpsushi.github.io/posts/continuum-hypothesis/</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuum-hypothesis/</guid>
      <description>1. 연속체 가설 : $\aleph_{0} = |\mathbb{N}|$ 에 대해 $\aleph_{0} &amp;lt; x &amp;lt; 2^{\aleph_{0}}$ 를 만족하는 기수 $x$ 는 존재하지 않는다.**2. 일반 연속체 가설** : 초한기수 $a = |A|$ 에 대해 $a &amp;lt; x &amp;lt; 2^{a}$ 를 만족하는 기수 $x$ 는 존재하지 않는다.칸토어는 대각선 논법과 같은 방법으로 무한이라고 다 같은 무한이 아니라는 것을 증명해보였다. 무한집합이라고 해도 그 기수는 크기가 비교할 수 있으며, 자연수 집합</description>
    </item>
    
    <item>
      <title>러셀의 역설</title>
      <link>https://freshrimpsushi.github.io/posts/russell-paradox/</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/russell-paradox/</guid>
      <description>모든 집합의 집합 $\mathscr{U}$ 가 존재한다면 어떤 집합 $R$ 은 $\mathscr{U}$ 에 속하면서도 속하지 않는다.기원 전 6세기, 크레타 출신의 철학자 에피메니데스 는 이렇게 말했다 :&amp;ldquo;모든 크레타 사람은 거짓말쟁이다!&amp;ldquo;에피메니데스의 주장이 참이라면, 에피메니데스 또한 크레타 사람이므로 이 주장은 거짓이다. 그러나, 이 주장이 거짓이라면 에피메니</description>
    </item>
    
    <item>
      <title>부분순서 집합</title>
      <link>https://freshrimpsushi.github.io/posts/partially-ordered-set/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partially-ordered-set/</guid>
      <description>1. 집합 $A$ 에서의 관계 $\le$ 가 반사적, 추이적, 반대칭적이면 부분순서Partial Order 이라 하고 $(A,\le)$ 를 반순서 집합이라고 부른다. $A$ 가 반순서 집합이라는 것은 모든 원소 $a,b \in A$ 에 대해 다음을 만족하는 것이다. $$ a \le b \land b \le a \implies a = b $$ 2. 부분순서집합 $(A, \le)$ 가 주어져 있을 때 모든 $a,b \in A$ 에 대해 $a \le b$ 혹은 $b \le a$ 면 $\le$ 를 $A$ 에서의 전순서Total Order ,</description>
    </item>
    
    <item>
      <title>완전 유계 공간</title>
      <link>https://freshrimpsushi.github.io/posts/totally-bounded-space/</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/totally-bounded-space/</guid>
      <description>거리 공간 $(X,d)$ 과 $\varepsilon&amp;gt;0$ 가 주어져 있다고 하자.1. 모든 $x \in X$ 에 대해 $B_{d}(x,\varepsilon) \cap A_{\varepsilon} \ne \emptyset$ 을 만족하는 유한 집합 $A_{\varepsilon} \subset X$ 를 $X$ 에 대한 **$**varepsilon$-그물$\varepsilon$-net 이라고 한다.**2.** 모든 $\varepsilon &amp;gt; 0$ 에 대해 $X$ 에 대한 $\varepsilon$-넷 $A_{\varepsilon}$ 가 존재하면 $X$ 가 **완전 유계** 라고 한다.완전 유계 공</description>
    </item>
    
    <item>
      <title>딘킨의 파이-람다 정리</title>
      <link>https://freshrimpsushi.github.io/posts/dynkins-pi-lambda-theorem/</link>
      <pubDate>Sat, 30 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynkins-pi-lambda-theorem/</guid>
      <description>파이 시스템 $\mathcal{P}$ 가 람다 시스템 $\mathcal{L}$ 의 부분집합이면 $\mathcal{P} \subset \sigma ( \mathcal{P} ) \subset \mathcal{L}$ 을 만족하는 시그마 필드 $\sigma ( \mathcal{P} )$ 가 존재한다. * $\sigma ( \mathcal{P} )$ 는 $\mathcal{P}$ 의 모든 원소를 포함하는 가장 작은 시그마 필드를 나타낸다.스테이트먼트만 보면 아주 간단해보이지만 이러한 정리들이 그러하듯 그 증명은 상당히 길고 복잡하다. 여기서 파이 시스템 $\mathcal{P}$ 와 람다 시스템 $\mathcal{L}$ 의 역할이 무엇일지 생각해</description>
    </item>
    
    <item>
      <title>파이썬에서 큰 csv 파일 한번에 읽는 법 How to Read Big Data csv File in python</title>
      <link>https://freshrimpsushi.github.io/posts/1403/</link>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1403/</guid>
      <description>``` y_test=[] y_csv = open(&amp;lsquo;y_test.csv&amp;rsquo;, &amp;lsquo;r&amp;rsquo;, encoding=&amp;lsquo;utf-8&amp;rsquo;) rdr = csv.reader(y_csv) for line in rdr: y_test.append(line[0]) y_csv.close() 보통 csv 파일을 읽어들일 때는 위와 같이 파이썬 내장함수 open으로 열어서 한줄한줄 처리하지만, 반복문을 사용하는 시점에서 빅데이터의 처리에는 적합하지 않음을 짐작할 수 있다. 가령 700MB가 넘는 파일이라면 사실 별로 크지도 않은 편이지만 한줄한줄 읽어서는 끝이 없다.이런 데이터를 다룰 때는 pandas 패키지를 사</description>
    </item>
    
    <item>
      <title>파이 시스템과 람다 시스템 π-System and λ-</title>
      <link>https://freshrimpsushi.github.io/posts/system/</link>
      <pubDate>Thu, 28 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/system/</guid>
      <description>1. 다음을 만족하는 $\mathcal{P}$ 을 $\pi$-시스템 이라고 한다. $$ A, B \in \mathcal{P} \implies A \cap B \in \mathcal{P} $$ 2. 다음의 조건들을 만족하는 $\mathcal{L}$ 을 $\lambda$-시스템 이라고 한다.(i) $\emptyset \in \mathcal{L}$(ii) $A \in \mathcal{L} \implies A^{c} \in \mathcal{L}$(iii) 모든 $i \ne j$ 에 대해 $\displaystyle A_{i} \cap A_{j} = \emptyset$ 일 때, $\displaystyle \left\{ A_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{L} \implies \bigcup_{n \in \mathbb{N}} A_{n} \in \mathcal{L}$측도론에서의 **시스템**System 이란 컬렉션</description>
    </item>
    
    <item>
      <title>L1 수렴 마틴게일이면 클로저블 마틴게일임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1401/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1401/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 과 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자.확률 과정 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 확률 변수 $Y$ 로 $\mathcal{L}_{1}$하면 $\left\{ ( X_{n} , \mathcal{F}_{n} ) : n = 1 , \cdots , \infty \right\}$ 은 클로저블 마틴게일이다.원래 $X_{n}$ 이 $Y$ 로 $\mathcal{L}_{1}$ 수렴하고 $X_{n}$ 이 $X_{\infty}$ 로 거의 확실히 수렴한다고 해도 $Y $ 와 $X_{\infty}$ 이 어떤 관계가 있다고 장담할 수는 없다. $$ X_{n} \overset{\mathcal{L}_{1}}{\to} Y \land X_{n}</description>
    </item>
    
    <item>
      <title>파이썬에서 pip로 cv2 PIL 패키지 설치하는 법 How to Install cv2 PIL Package in python using pip</title>
      <link>https://freshrimpsushi.github.io/posts/1400/</link>
      <pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1400/</guid>
      <description>openCV 패키지와 PIL 패키지는 이미지 처리에 유용한 패키지다. 문제는 보통 예제 코드에서 두 패키지를 불러들일 때 cv2, PIL라고 하는데 막상 파이썬에서 pip를 이용해서 설치하려고하면 에러를 낸다는 것이다. 이는 파이썬에서 불러들일때의 이름과 설치할 때의 이름이 다르기 때문이다.스크린샷에서 보이는 것과 같이 openCV를 설치하기 위해서는 cv2도</description>
    </item>
    
    <item>
      <title>균등적분가능 마틴게일이면 L1 수렴 마틴게일임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1399/</link>
      <pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1399/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져 있다고 하자.확률 과정 $\left\{ X_{n} \right\}$ 이 어떤 확률 변수 $X_{\infty}$ 에 대해 다음을 만족하면 $\left\{ X_{n} \right\}$ 이 $X_{\infty}$ 로 $\mathcal{L}_{p}$ 수렴한다고 말한다. $$ \lim_{n \to \infty} | X_{n} - X_{\infty} |_{p} = 0 $$ 확률 과정 $\left\{ X_{n} \right\}$ 가 $\mathcal{L}_{p}$ 수렴하면 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 **$\mathcal{L}_{p}$ 수렴한다** 고 말한다.마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 균등적분가능이면 $\mathcal{L}_{1}$ 수렴한다.측도론의 센스로 보았을 때 $p=1$ 에서</description>
    </item>
    
    <item>
      <title>비탈리 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/vitali-convergence-theorem/</link>
      <pubDate>Sun, 24 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vitali-convergence-theorem/</guid>
      <description>측도 공간 $( X , \mathcal{E} , \mu)$ 가 주어져 있다고 하자.$1 \le p &amp;lt; \infty$ 라고 할 때 함수의 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{L}^{p}$ 가 $f$ 로 $\mathcal{L}_{p}$ 수렴하는 것은 다음 세 가지를 모두 만족하는 것과 필요충분조건이다.**(i)** $\left\{ f_{n} \right\}$ 은 $f$ 로 측도 수렴한다.**(ii)** $\left\{ | f_{n} |^{p} \right\}$ 은 균등적분가능하다.**(iii)** 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ F \in \mathcal{E} \land F \cap E = \emptyset \implies \int_{F} | f_{n}</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability/</link>
      <pubDate>Sat, 23 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability/</guid>
      <description>수리통계학에서 정의됐던 확률 수렴거의 확실히 수렴 $\implies$ 확률 수렴 $\implies$ 분포 수렴$\mathcal{L}_{p}$ 수렴 $\implies$ 확률 수렴**확률 수렴의 어려운 정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져 있다고 하자.확률 변수의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 확률 변수 $X$ 로 측도 수렴하면 확률 수렴한다고 말하고 $X_{n} \overset{P}{\to} X$ 와 같이 나타낸다. * 아직 측도론을 접하지 못했다면 확</description>
    </item>
    
    <item>
      <title>측도 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-measure/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-measure/</guid>
      <description>거의 어디서나 수렴 $\implies$ 측도 수렴$\mathcal{L}_{p}$ 수렴 $\implies$ 측도 수렴측도 공간 $( X , \mathcal{E} , \mu)$ 가 주어져 있다고 하자.가측 함수의 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 어떤 가측 함수 $f$ 와 모든 $M &amp;gt;0$ 에 대해 다음을 만족하면 $f$ 로 **측도 수렴** 한다고 말한다. $$ \lim_{n \to \infty} \mu \left( \left\{ x \in X : | f_{n}(x) - f(x) | \ge M \right\} \right) = 0 $$ 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 모든 $M &amp;gt;0$ 에 대해 다</description>
    </item>
    
    <item>
      <title>집합의 기수</title>
      <link>https://freshrimpsushi.github.io/posts/cardinality/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cardinality/</guid>
      <description>임의의 집합 $X$ 에 대해 다음의 성질들을 갖는 $\text{card} X$ 를 $X$ 의 기수 라고 정의한다.(i) $X = \emptyset \iff \text{card} X = 0$(ii) $A \sim B \iff \text{card} A = \text{card} B $(iii) 어떤 자연수 $k$ 에 대해 $X \sim \left\{ 1 , 2, \cdots , k \right\}$ 면 $\text{card} X = k$특히, 유한집합의 기수를 유한기수 라 하고 무한집합의 기수를 초한기수 라고 한다.1. 두 집합 $A$, $B$ 에 대해 $A$ 가 $B$ 의 어떤 부분집합과는 대등하지만 $B$ 는 $A$ 의 어떤 부분집합</description>
    </item>
    
    <item>
      <title>레귤러 마틴게일이면 균등적분가능 마틴게일임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1393/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1393/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져 있다고 하자.확률 변수의 집합 $\Phi$ 가 주어져있다고 할 때, 모든 $\varepsilon&amp;gt;0$ 에 대해 $$ \displaystyle \sup_{ X \in \Phi } \int_{ \left( \left| X \right| \ge k \right) } \left| X \right| dP &amp;lt; \varepsilon $$ 를 만족하는 $k \in \mathbb{N}$ 가 존재하면 $\Phi$ 가 균등적분가능하다고 말한다. 확률 과정 $\left\{ X_{n} \right\}$ 가 균등적분가능하면 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 균등적분가능하다고 말한다.마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 레귤</description>
    </item>
    
    <item>
      <title>위상공간에서의 내부에 대한 여러 동치 조건들</title>
      <link>https://freshrimpsushi.github.io/posts/1424/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1424/</guid>
      <description>**내부$(\mathrm{interior})$, 내부점$(\mathrm{interior point} )$ 위상공간 $(X,\mathcal{T})$와 부분공간 $A$가 주어졌다고 하자. $A$에 포함되는 모든 열린집합들의 합집합을 $A$의 내부 라고 하고 $A^{\circ}$ 혹은 $\mathrm{int}(A)$로 나타낸다. $$ A^{\circ} = \cup \left\{ U \in</description>
    </item>
    
    <item>
      <title>균등적분가능성</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-integrablility/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-integrablility/</guid>
      <description>측도 공간 $( X , \mathcal{E} , \mu)$ 가 주어져 있다고 하자.르벡 적분 가능한 함수의 집합 $\Phi \subset \mathcal{L}^{1}$ 이 주어져있다고 할 때, 모든 $\varepsilon&amp;gt;0$ 에 대해 $$ \displaystyle \mu (E) &amp;lt; \delta \implies \sup_{f \in \Phi} \int_{ E } \left| f \right| d \mu &amp;lt; \varepsilon $$ 를 만족하는 $\delta &amp;gt; 0$ 가 존재하면 $\Phi$ 가 **균등적분가능** 하다고 한다.균등적분가능성은 균등Uniformly이라는 말이 붙은만큼 셋 개념으로 접근하며, $\Phi$ 에 속한다면 어떤 함</description>
    </item>
    
    <item>
      <title>레귤러 마틴게일과 클로저블 마틴게일</title>
      <link>https://freshrimpsushi.github.io/posts/regular-martingale-and-closable/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regular-martingale-and-closable/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 와 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자.**1.** 만약 어떤 적분가능한 확률 변수 $\eta$ 에 대해 $X_{n} = E ( \eta | \mathcal{F}_{n} )$ 이면 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 을 **레귤러 마틴게일** 이라고 한다.**2.** 만약 $\left\{ ( X_{n} , \mathcal{F}_{n} ) : n = 1 , \cdots , \infty \right\}$ 이 마틴게일이 되도록 하는 어떤 적분가능한 확률 변수 $X_{\infty}$ 이 존재하고 $\mathcal</description>
    </item>
    
    <item>
      <title>칸토어의 대각선 논법</title>
      <link>https://freshrimpsushi.github.io/posts/cantors-diagonal-argument/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cantors-diagonal-argument/</guid>
      <description>열린 구간 $(0,1)$ 은 비가산집합이다.실수 집합 $\mathbb{R}$ 은 가산 집합이 아닌데, 이것은 실수 집합과 어떤 가산 집합 사이에 &amp;lsquo;일대일 대응&amp;rsquo;이 존재하지 않음을 통해서 보인다. 이는 자연수 집합과 열린 구간 $(0,1)$ 사이에 일대일 대응이 존재하지 않는 것을 보이고, 그 따름정리로써 얻을 수 있다.칸토어는 이것을 놀라운 방법으로 증명해냈고, 이 방법</description>
    </item>
    
    <item>
      <title>가산집합과 비가산집합</title>
      <link>https://freshrimpsushi.github.io/posts/countable-set-and-uncountable-set/</link>
      <pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/countable-set-and-uncountable-set/</guid>
      <description>1. 집합 $X$ 가 유한 집합이거나 $X \sim \mathbb{N}$ 면 가산 집합 이라고 한다.2. 가산 집합이 아닌 집합을 비가산 집합 이라고 한다.가산 집합이라는 개념은 동양인, 물론 한국인에게 받아들이기 쉽지만은 않다. 이는 영어를 비롯한 인도유럽어족의 사고방식과 우리의 마인드가 판이하게 다른 점에서 온다. 알다시피 유럽어는 명사에도 성이 있고 수, 격에 따라 동사와 형용사가</description>
    </item>
    
    <item>
      <title>서브 마틴게일 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-sub-martingale-convergence-theorem/</link>
      <pubDate>Sat, 16 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-sub-martingale-convergence-theorem/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자.$\displaystyle \sup_{n \in \mathbb{N}} E X_{n}^{+} &amp;lt; \infty$ 이라고 하면 $X_{n}$ 은 어떤 확률 변수 $X_{\infty} : \Omega \to \mathbb{R}$ 로 거의 확실히 수렴하고 $E X_{\infty} &amp;lt; E X_{\infty}^{+} &amp;lt; \infty $**Strategy** : 리미트 슈프리멈과 리미트 인피멈의 성질을 사용한다. $$ X^{ * } := \limsup_{n \in \mathbb{N}} X_{n} \\ X_{*} := \liminf_{n \in \mathbb{N}} X_{n} $$ 이라고 하면 $$ \left( X^{ * } &amp;gt; X_{*} \right) = \bigcup_{a &amp;lt; b \\</description>
    </item>
    
    <item>
      <title>집합론으로 엄밀하게 정의되는 유한 집합과 무한 집합</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-infinite-set/</link>
      <pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-infinite-set/</guid>
      <description>1. 두 집합 $X$ 에 대해 전단사 $f : X \to Y$ 가 존재하면 $X$ 와 $Y$ 가 서로 대등하다Equipotent 고 하고 $X \sim Y$ 와 같이 나타낸다.2. 공집합이 아닌 $X$ 의 어떤 진부분집합 $Y \subsetneq X$ 에 대해 $X \sim Y$ 면 $X$ 를 무한 집합 이라고 한다.3. 무한 집합이 아닌 집합을 유한 집합 이라고 한다.1. 흔히 집합론을 동원하지 않고 무한을 설명하려고 할 때 대등하다는 표현을 울타</description>
    </item>
    
    <item>
      <title>공진리란</title>
      <link>https://freshrimpsushi.github.io/posts/vacuous-truth/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vacuous-truth/</guid>
      <description>임의의 명제 $p$ 와 모순 $c$ 그리고 $A_{\alpha} \subset X$ 에 대해 다음이 성립한다.**[1] 공진리** : $c \implies p$**[2] 합집합** : $\displaystyle \bigcup_{\alpha \in \emptyset} A_{\alpha} = \emptyset$**[3] 교집합** : $\displaystyle \bigcap_{\alpha \in \emptyset} A_{\alpha} = X$예를 들어 &amp;ldquo;신은 죽었다.&amp;rdquo; 라는 말에서 신이 존재하지 않는다면, 가정부터 틀려먹었다면 어떻게 되는 걸까? 신이 존재하지 않는다면 $0$ 명의 신이 죽은 것이므로 누가 진</description>
    </item>
    
    <item>
      <title>확률과정론에서의 업크로싱</title>
      <link>https://freshrimpsushi.github.io/posts/upcrossing/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/upcrossing/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자.폐구간 $[a,b]$ 에 대해 $X_{t_{1}} \le a $ 이었다가 $X_{t_{2}} \ge b $ 가 되는 것을 **업크로싱** 이라고 한다. $N \in \mathbb{N}$ 번까지 관찰할 때 업크로싱의 횟수를 다음과 같이 나타낸다. $$ \beta_{N} (a,b) : = \text{A number of upcrossing of } \left\{ X_{n} \right\} \text{ of interval } [a,b] $$ 업크로싱은 쉽게 말해 $X_{n}$ 이 하한 $a$ 에서 상한 $b$ 를 넘어가는 것을 말한다.</description>
    </item>
    
    <item>
      <title>전사 단사 공역 치역을 쉽게 외우는 방법 뜻풀이</title>
      <link>https://freshrimpsushi.github.io/posts/690/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/690/</guid>
      <description>전사와 단사공역과 치역나는 이 친구들을 처음 만났을 때 이름을 외우기가 너무 힘들었다. &amp;lsquo;이게 단사인가? 전사인가?&amp;rsquo; &amp;lsquo;공역이 더 큰거였나? 뭐지?&amp;rsquo;. 이름을 비슷하게 지어놔서 써먹어야할 때 마다 헷갈렸다. 나 같은 사람이 얼마나 많을지 모르겠다만 몇 없더라도 암기가 안되서 나와 같은 고통을 받</description>
    </item>
    
    <item>
      <title>줄리아의 타입과 애노테이션</title>
      <link>https://freshrimpsushi.github.io/posts/type-and-annotation-in-julia/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/type-and-annotation-in-julia/</guid>
      <description>줄리아에는 온갖 타입들이 구현되어있다. $0$ 과 $0.0$ 은 같은 $0$ 이지만 다른 타입을 가지며, 보다시피 타입인 Bool조차 DataType이라는 타입을 갖는다. C 언어처럼 String은 Char의 배열이며, 위와 같이 큰 따옴표인가 작은 따옴표인가로 구분된다.위와 같이 supertype() 함수를 사용하면 타입의 상위 타입을 확인할 수 있다. 모든 타입은 Any 타입의 하</description>
    </item>
    
    <item>
      <title>단사 전사 전단사 역함수</title>
      <link>https://freshrimpsushi.github.io/posts/injection-surjection-bijection-inverse-function/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/injection-surjection-bijection-inverse-function/</guid>
      <description>$x \in X$ 이고 $y \in Y$ 그리고 $f: X \to Y$ 가 함수라고 하자.1. 모든 $x_{1}, x_{2} \in X$ 에 대해 $x_{1} \ne x_{2} \implies f(x_{1}) \ne f(x_{2})$ 면 $f$ 를 **단사** 라고 한다.**2.** $f(X) = Y$ 면 $f$ 를 **전사** 라고 한다.**3.** $f$ 가 단사면서 전사면 **전단사** 라고 한다.**4.** $I(x) = x$ 를 만족하는 $I : X \to X$ 를 **항등함수**Identity Function 라고 한다.**5</description>
    </item>
    
    <item>
      <title>둡의 최대 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-doobs-maximal-inequality/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-doobs-maximal-inequality/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 마틴 게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자.어떤 $N \in \mathbb{N}$ 과 $p&amp;gt;1$ 에 대해 $X_{n} \ge 0 (n \le N)$, $E X_{N}^{p} &amp;lt; \infty$ 이면 $$ E \left( \max_{n \le N} X_{n}^{p} \right) \le \left( {{ p } \over { p-1 }} \right)^{p} E X_{N}^{p} \text{ a.s.} $$ 수식의 모양은 $\displaystyle \max_{n \le N} \cdot_{n} ^{p}$ 으로 말미암아 생기는 $\displaystyle \left( {{ p } \over { p-1 }} \right)^{p}$ 을 밖으로 빼내고 그 상한을 계산하는 것으로 볼 수 있다. $\displaystyle \left( {{ p } \over { p-1 }} \right)&amp;gt;1$ 이기 때문에 $p$ 가</description>
    </item>
    
    <item>
      <title>줄리아 프로그래밍 언어</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-julia-language/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-julia-language/</guid>
      <description>줄리아 는 MIT에서 개발되어 2012년 공개된 프로그래밍 언어로써, 생산성이 높으면서도 속도가 높은 언어를 지향한다. C나 포트란에 준하는 속도를 내면서도 파이썬이나 R처럼 고수준의 문법을 갖추었으며, 그 외에도 여러 언어들의 장점을 취하고 있다. 2019년 11월 현재는 GPU가 급속도로 발전하면서 딥러닝이 유행을 선도하고 있어 조금 뒤쳐</description>
    </item>
    
    <item>
      <title>함수의 원상</title>
      <link>https://freshrimpsushi.github.io/posts/preimage-of-function/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/preimage-of-function/</guid>
      <description>함수 $f: X \to Y$ 와 $B \subset Y$ 에 대해 $f^{-1}(B) : = \left\{ x \in X \ | \ f(x) \in B \right\}$ 를 $f$ 에 따른 $B$ 의 원상 혹은 역상 이라고 한다.표기는 비슷하지만 정의 자체만으로 역상과 역함수가 어떤 관계에 있다고 말할 수는 없으며, 이들을 혼동하지 않아야한다.한국어로 말하기엔 역상이 자연스러운 반면 영어로는 [프리이미지]가 자연스럽게 느껴지는 사람이 있을 것이다. 이는 거스를</description>
    </item>
    
    <item>
      <title>마틴게일의 부등식들</title>
      <link>https://freshrimpsushi.github.io/posts/inequalities-of-martingale/</link>
      <pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inequalities-of-martingale/</guid>
      <description>$\left\{ (X_{n} , \mathcal{F}_{n}) \right\}$ 이 슈퍼 마틴게일이라고 하자.**[1]** 모든 $\lambda &amp;gt; 0$ 에 대해 $$ \begin{eqnarray*} \lambda P \left( \max_{n \le N} X_{n} \ge \lambda \right) &amp;amp;\le&amp;amp; E X_{1} - \int_{(\max_{n \le N} X_{n} &amp;lt; \lambda)} X_{N} dP \\ &amp;amp;\le&amp;amp; E X_{1} + E X_{N}^{-} \text{ a.s.} \end{eqnarray*} $$ **[2]** 모든 $\lambda &amp;gt; 0$ 에 대해 $$ \begin{eqnarray*} \lambda P \left( \min_{n \le N} X_{n} \le - \lambda \right) &amp;amp;\le&amp;amp; - \int_{(\min_{n \le N} X_{n} \le - \lambda)} X_{N} dP \\ &amp;amp;\le&amp;amp; E X_{N}^{-} \text{ a.s.} \end{eqnarray*} $$ $\left\{ (X_{n} , \mathcal{F}_{n}) \right\}$ 이 서브 마틴게일이라고 하자.**[3]** 모든 $\lambda &amp;gt; 0$ 에 대해 $$ \begin{eqnarray*} \lambda P \left( \max_{n \le N}</description>
    </item>
    
    <item>
      <title>집합론으로 엄밀하게 정의되는 함수와 상 수열</title>
      <link>https://freshrimpsushi.github.io/posts/function-image-and-sequence/</link>
      <pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/function-image-and-sequence/</guid>
      <description>공집합이 아닌 두 집합 $X$, $Y$ 이 주어져 있다고 하자.1. 이항 관계 $f \subset (X,Y)$ 가 다음을 만족하면 함수 라 하고 $f : X \to Y$ 와 같이 나타낸다. $$ (x ,y_{1}) \in f \land (x,y_{2}) \in f \implies y_{1} = y_{2} $$ **2.** 함수 $f : X \to Y$ 에 대해 $\text{Dom} (f) = X$ 를 $f$ 의 **정의역**Domain , $Y$ 를 $f$ 의 **공역**Codomain 이라고 한다. 정의역의 부분집합 $A \subset X$ 이 주어져 있을 때, $f(A) := \left\{ f(a) \in</description>
    </item>
    
    <item>
      <title>선택 공리가 추가된 체르멜로-프렝켈 집합론</title>
      <link>https://freshrimpsushi.github.io/posts/zermelo-fraenkel-set-theory-with-the-axiom-of-choice-included/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zermelo-fraenkel-set-theory-with-the-axiom-of-choice-included/</guid>
      <description>[1] 외연 공리 : $$ \forall A \forall B ( \forall x ( x \in A \iff x \in B) ) $$ 임의의 두 집합 $A$, $B$ 에 속한 원소가 같으면 두 집합이 같다고 하고 $A = B$ 와 같이 나타낸다.[2] 공집합 공리 : $$ \exists X \forall x \left( \lnot \left( x \in X \right) \right) $$ 어떤 원소도 가지지 않는 집합 $X$ 가 존재하고, 이 집합 $X$ 를 공집합이라고 정의한다.[3] 짝 공리 : $$ \forall A \forall B \exists U ( a \in A \land b \in B ) $$ 임의의 두 집합 $A$,</description>
    </item>
    
    <item>
      <title>위상수학에서 좌표계란</title>
      <link>https://freshrimpsushi.github.io/posts/coordinate-chart/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coordinate-chart/</guid>
      <description>**좌표계 $M$을 $n$차원 다양체라고 하자. 두 열린 집합 $U\subset M$, $\tilde{U} \subset \mathbb{R}^n$와 위상동형사상 $\phi\ :\ U \rightarrow \tilde{U}$가 주어졌다고 하자. 그러면 순서쌍 $(U, \phi)$를 $M$ 위의 좌표계 혹은 간단하게 좌표$(\mathrm{Chart})$ 라고 한다.만약 $p \in U$, $\phi (p)=0$이면, $(U,\phi)$</description>
    </item>
    
    <item>
      <title>선택적 샘플링 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-optional-sampling-theorem/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-optional-sampling-theorem/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 와 슈퍼 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자.$\tau$ 와 $\sigma$ 가 $\sigma \le \tau$ 면서 $\mathcal{F}_{n}$ 에 대해 바운디드 정지 시간이라고하면 $$ E \left( X_{\tau} | \mathcal{F}_{\sigma} \right) \le X_{\sigma} \text{ a.s.} $$ * $\tau$ 가 $\mathcal{F}_{n}$ 에 대해 바운디드라는 것은 말 그대로 모든 $E \in \mathcal{F}_{n}$ 에 대해 $\tau(E) \le N$ 를 만족하는 $N \in \mathbb{N}$ 이 존재한다는 것이다.수식 자체가 말해주는 것은 $\sigma \le \tau \le N$ 이라는 조건이 있을 때</description>
    </item>
    
    <item>
      <title>선택 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-choice/</link>
      <pubDate>Tue, 29 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-choice/</guid>
      <description>$$ \forall U \left( \emptyset \notin U \implies \exists f : U \to \bigcup_{X \in U \\ f(X) \in X } U \right) $$ 모든 공집합이 아닌 집합들의 집합 $U$ 에 대해 $U$ 의 모든 원소로부터 원소 하나씩을 선택하는 선택 함수 $f$ 가 존재한다.선택 공리는 가령 다음과 같은 집합의 집합 $U$ 가 있을 때, 그 원소인 집합에서 원소 하나을 뽑는 함수 $f$ 가 존재함을 보장해준다. 가령 다음의 예를 생각해보자 : $$ U = \left\{ \left\{ \pi , 1/2 \right\} , \left\{ e ,</description>
    </item>
    
    <item>
      <title>정지 시간의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-stopping-time/</link>
      <pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-stopping-time/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 와 마틴 게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자.정지 시간 $\tau$ 에 대해 $\mathcal{F}_{\tau} := \left\{ A \in \mathcal{F} : A \cap ( \tau = n ) \in \mathcal{F}_{n} \right\}$ 을 **$\tau$ 에 의해 유도된 시그마 필드** 라고 한다.**[1]** $\mathcal{F}_{\tau}$ 는 시그마 필드다.**[2]** $\tau$ 는 $\mathcal{F}_{\tau}$-가측 함수다.**[3]** 마틴 게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 에 대해</description>
    </item>
    
    <item>
      <title>치환 공리꼴</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-schema-of-replacement/</link>
      <pubDate>Sun, 27 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-schema-of-replacement/</guid>
      <description>$$ \forall X \left( \forall x \in X \exists ! y \left( p(x,y) \right) \implies \exists Y \forall x \in X \exists y \in Y \left( p(x,y) \right) \right) $$ 모든 함수에 대한 치역이 존재한다. * 기호 $\exists !$ 는 유일하게 존재함을 의미한다. * 여기서 $p(x,y)$ 는 $X \times Y$ 에서의 명제함수다.명제함수 $p(x,y)$ 는 물론 함수지만 엄밀하게 말해 함수로써 정의된 것은 아니며, 설령 함수로 정의되었다고 할지라도 위 공리에서 말하는 함수 그 자체는 아니다. 논리식 $p(x,y)$</description>
    </item>
    
    <item>
      <title>확률과정론에서의 정지 시간</title>
      <link>https://freshrimpsushi.github.io/posts/stopping-time/</link>
      <pubDate>Sat, 26 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stopping-time/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.필트레이션 $\left\{ \mathcal{F}{n} \right\}$ 에 대해 $0$ 보다 크거나 같은 정수 값을 갖는 확률 변수 $\tau$ 가 모든 $n \in \mathbb{N}{0}$ 에 대해 $(\tau = n) \in \mathcal{F}{n}$ 을 만족하면 $\tau$ 를 정지 시간이라고 한다. * 보렐 셋 $B \in \mathcal{B}(\mathbb{R})$ 에 대해 $(\tau \in B) = \tau^{-1} (B)$ 로써, $(\tau = n)$ 은 $\tau^{-1} ( \left\{ n \right\} )$ 과 같다.정지 시간의 직관적인 개념은 관심 있는 사건이 일어나는―관찰되는 순간을 말한다. 가</description>
    </item>
    
    <item>
      <title>정칙성 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-regularity/</link>
      <pubDate>Fri, 25 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-regularity/</guid>
      <description>$$ \forall X \left( \exists x_{0} ( x_{0} \in X ) \implies \exists y ( y \in X \land \lnot \exists x ( x \in y \land x \in X )) \right) $$ 모든 집합 $X \ne \emptyset$ 은 자기 자신과 서로소인 원소를 가진다.정칙성 공리에 따라 스스로를 원소로 포함하는 재귀 집합, 예컨대 $X = \left\{ X \right\}$ 와 같은 집합은 존재할 수 없다. 자기 자신과 서로소가 되기 위해서는 적어도 자기 자신은 아니어야하기 때문이다.정칙성 공리는 공집합이 아닌 집합</description>
    </item>
    
    <item>
      <title>Lp 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-lp/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-lp/</guid>
      <description>$\mathcal{L}{p}$ 수렴 $\implies$ 측도 수렴함수의 시퀀스 $\left\{ f{n} \right\}{n \in \mathbb{N}}$ 이 어떤 함수 $f$ 에 대해 다음을 만족하면 $\left\{ f{n} \right\}$ 이 $f$ 로 $\mathcal{L}_{p}$ 수렴한다 고 말한다. $$ \lim_{n \to \infty} | f_{n} - f |_{p} = 0 $$ 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 다음을 만족하면 **$\mathcal{L}_{p}$ 에서 코시Cauchy in $\mathcal{L}_{p}$** 라고 한다. $$ \lim_{n, m \to \infty} | f_{n} - f_{m} |_{p} = 0 $$ 물론 $| \cdot |_{p}$ 는 $p$-놈으로써 다음과 같이 정의된다. $$ \displaystyle | f |_{p} := \left( \int_{E} | f |^{p} dm \right) ^{{{1} \over {p}}}</description>
    </item>
    
    <item>
      <title>마틴게일의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-martingales/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-martingales/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.1. $\mathcal{F}$ 의 서브 시그마 필드의 시퀀스 $\left\{ \mathcal{F}{n} \right\}{n \in \mathbb{N}}$ 이 다음을 만족하면 필트레이션Filtration 이라고 부른다. $$ \forall n \in \mathbb{N}, \mathcal{F}{n} \subset \mathcal{F}{n+1} $$ 2. 필트레이션 $\left\{ \mathcal{F}{n} \right\}{n \in \mathbb{N}}$ 이 주어져 있을 때 르벡 적분 가능한 $\mathcal{F}{n}$-가측 확률 변수 $X{n}$ 의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 가 이루는 순서쌍의 시퀀스 $\left\{ (X_{n},</description>
    </item>
    
    <item>
      <title>무한 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-infinity/</link>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-infinity/</guid>
      <description>$$ \exists U \left( \emptyset \in U \land \forall X ( X \in U \implies S(X) \in U) \right) $$ 공집합과 $X$ 를 원소로 가지면 $S(X)$ 도 원소로 가지는 집합 $U$ 가 존재한다. * 집합 $X$ 에 대해 $S(X)$ 는 $S(X) := X \cup \left\{ X \right\}$ 와 같이 정의되는 집합이다.이것이 왜 무한 공리인지를 구구절절 설명하는 것보다 자연수 집합 $\mathbb{N}$ 의 존재성 증명을 한 번 보는 게 낫다.$\mathbb{N}$ 이 존재한다.Strategy : 폰 노이</description>
    </item>
    
    <item>
      <title>국소 적분가능한 함수의 평균값은 중심의 함숫값으로 수렴함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1391/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1391/</guid>
      <description>$f \in L^1_{\mathrm{loc}}$이라고 하자. 그러면 $$ \lim \limits_{r \rightarrow 0} A_r f(x)=f(x) \ \mathrm{a.e.}\ x\in \mathbb{R}^n $$ 국소 적분가능한 함수의 볼 $B(r,x)$위에서의 평균값의 반지름이 $0$으로 가는 극한은 볼 중심의 함숫값과 같다는 말이다.**보조정리 $f \in L^1(m)$이고 $\epsilon&amp;gt;0$이라고 하자. 그러면 아래의 조건을 만족하는 심</description>
    </item>
    
    <item>
      <title>맥시멀 정리</title>
      <link>https://freshrimpsushi.github.io/posts/the-maximal-theorem/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-maximal-theorem/</guid>
      <description>맥시멀 정리 모든 $f \in L^1_{\mathrm{loc}}$와 모든 $\alpha &amp;gt;0$에 대해서 아래의 조건을 만족하는 상수 $C&amp;gt;0$가 존재한다. $$ \mu \big( \left\{ x\ :\ Hf(x)&amp;gt;\alpha \right\}\big) \le \frac{C}{\alpha} \int |f(y)| dy $$ 위 부등식을 하디-리틀우드 맥시멀 부등식$(\mathrm{The\ Hardy-Littlewood\ maximal\ inequality})$이라 부른다.하디-리틀우드 맥시멀 함수 $$ Hf (x)</description>
    </item>
    
    <item>
      <title>조건부 옌센 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conditional-jensens-inequality/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conditional-jensens-inequality/</guid>
      <description>옌센 부등식의 기대값 폼확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G} \subset \mathcal{F}$ 가 주어져있다고 하고 $X$, 가 확률 변수라고 하자.컨벡스 함수 $\phi : \mathbb{R} \to \mathbb{R}$ 와 $\phi (X) \in \mathcal{L}^{1} ( \Omega ) $에 대해 $$ \phi \left( E \left( X | \mathcal{G} \right) \right) \le E \left( \phi (X) | \mathcal{G} \right) $$ * $\phi$ 가 컨벡스라는 것은 모든 $x,y \in \mathbb{R}$ 와 $\alpha \in [0,1]$ 에 대해 다음을 만족하는 함수라는 것이다. $$ \phi( \alpha x + (1 - \alpha ) y ) \le \alpha \phi (x) + (1 - \alpha ) \phi</description>
    </item>
    
    <item>
      <title>맥시멀 보조정리</title>
      <link>https://freshrimpsushi.github.io/posts/the-maximal-lemma/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-maximal-lemma/</guid>
      <description>**맥시멀 보조정리 $\mathcal{B}$를 $\mathbb{R}^n$에서의 오픈 볼들의 컬렉션이라고 하자. $U=\bigcup \limits_ { B\in \mathcal{B}} B$라고 하자. 그러면 어떤 상수 $c &amp;lt;m (U)$에 대해서, 아래의 조건을 만족하는 유한개의 서로소인 $B_j \in \mathcal{B}$가 존재한다. $$ \sum \limits_ {j=1}^k \mu (B_j) &amp;gt;3^{-n} c $$ 이때 $m$은 $n$차원 르벡 측도이다. 증</description>
    </item>
    
    <item>
      <title>멱집합 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-power-set/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-power-set/</guid>
      <description>$$ \forall X \exists P \forall A ( A \subset X \implies A \in P) $$ 임의의 집합 $X$ 에 대해 $X$ 의 모든 부분집합을 원소로 갖는 집합 $P$ 가 존재한다.$X$ 의 멱집합은 일반적으로 $\mathcal{P} (X)$ 와 같이 표기하거나 $2^{X}$ 와 같이 쓰는데, 그 이유는 유한 집합 $X$ 의 원소의 개수를 $|X|$ 이라고 하면 $P(X)=2^{|X|}$ 이기 때문이다. 꼭 개수가 중요한 것은 아니기 때문에 집합론을 많이 쓰면 많이 쓰는 분과일수록 $2^{X}$ 와 같은 표현을 선호</description>
    </item>
    
    <item>
      <title>하디-리틀우드 맥시멀 함수</title>
      <link>https://freshrimpsushi.github.io/posts/hardy-littlewood-maximal-function/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hardy-littlewood-maximal-function/</guid>
      <description>**하디-리틀우드 맥시멀 함수 $ f \in L^1_{\mathrm{loc}}$라고 하자. 그러면 하디-리틀우드 맥시멀 함수 $Hf$를 아래와 같이 정의한다. $$ Hf (x) = \sup \limits_{r&amp;gt;0} A_r |f|(x) = \sup \limits_{r&amp;gt;0} \frac{1}{\mu \big( B(r,x) \big)}\int_{B(r,x)}|f(y)|dy $$ $A_rf(x)$는 $B(r,x)$위에서 $f$의 함숫값의 평균을 의미한다. $H$를 맥시멀 오퍼레이터$(\mathrm{ maximal\ ope</description>
    </item>
    
    <item>
      <title>합집합 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-union/</link>
      <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-union/</guid>
      <description>$$ \forall X \left( \exists U \left( \forall a \left( a \in x \land x \in X \implies a \in U \right) \right) \right) $$ 임의의 집합 $X$ 에 대해 $X$ 모든 원소들의 원소들을 포함하는 집합 $U$ 가 존재한다.합집합 공리는 다음과 같이 정의되는 합집합의 존재성을 보장한다. $$ x \in A \lor x \in B \iff x \in A \cup B $$ 임의의 두 집합 $A$, $B$ 에 대해 적어도 둘 중 하나에 속하는 원소들의 집합을 $A$ 와 $B$ 의 합집합이라고 하고, $A \cup B$ 와 같이 나</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 조건부 분산</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-variance/</link>
      <pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-variance/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G} \subset \mathcal{F}$ 가 주어져있다고 하고 $X$, $Y$ 가 확률 변수라고 하자.다음과 같이 정의된 $\text{Var}$ 를 $\mathcal{G}$ 가 주어졌을 때 $X$ 의 분산 이라고 한다. $$ \text{Var} ( X | \mathcal{G}) := E \left[ (X - E(X | \mathcal{G}))^2 | \mathcal{G} \right] $$ * $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드라는 것은 둘 다 $\Omega$ 의 시그마 필드이되, $\mathcal{G} \subset \mathcal{F}$ 임을 의미한다.원래 평균보단 분산이 더 어렵고 조건부는 헷갈리게 마련인데</description>
    </item>
    
    <item>
      <title>분류 공리꼴</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-schema-of-specification/</link>
      <pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-schema-of-specification/</guid>
      <description>$$ \forall X \exists A \forall a \left( a \in A \iff ( a \in X \land p(a)) \right) $$ 임의의 집합 $X$ 에 대해 성질 $p$ 를 가지는 원소들로 이루어진 부분집합 $A$ 가 존재한다. * 여기서 $p(x)$ 는 $X$ 에서의 명제함수다.$A$ 를 $X$ 의 부분집합으로 한정하는 이유는 러셀의 역설과 같은 문제가 일어나는 것을 방지하기 위함이다.공리가 아니라 공리꼴인 이유는 이 공리가 무수히 많은 $p(x)$ 에 따라 무수히 많이 존재하</description>
    </item>
    
    <item>
      <title>수학에서의 포화 파이버</title>
      <link>https://freshrimpsushi.github.io/posts/saturation-fiber/</link>
      <pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/saturation-fiber/</guid>
      <description>**포화$(\mathrm{saturation})$ 두 집합 $X$, $Y$와 함수 $\pi\ :\ X\rightarrow Y$가 주어졌다고 하자. 만약 $\pi^{-1}\big( \pi(u) \big)=u$가 성립하면, $u\subset X$를 포화 라고 한다.$\pi^{-1}$는 프리이미지이다. 글로만 보면 어떤 의미인지 감을 잡기 어려울 수 있다. $u$는 항상 $\pi^{-1} \big( \pi(u) \big)$보다 작거나 같다. 따라서 $u$</description>
    </item>
    
    <item>
      <title>분리합집합 위상 공간</title>
      <link>https://freshrimpsushi.github.io/posts/disjoint-union-topological-space/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/disjoint-union-topological-space/</guid>
      <description>**분리합집합 위상 공간 $\left\{ X_\alpha \right\}_{\alpha \in A}$를 임의의 위상 공간 인덱스 패밀리라고 하자. $u \subset \bigsqcup \limits_{\alpha \in A} X_\alpha$라고 하자. 그러면 모든$\alpha \in A$에 대해서 $u \cap X_\alpha$가 $ X_\alpha$에서 열린 집합일 때, $u$가 $\bigsqcup \limits_{\alpha \in A} X_\alpha$에서 열린 집합$^{ * }$이라고 한다.이때 마지막에서 말</description>
    </item>
    
    <item>
      <title>서로소인 합집합 분리합집합</title>
      <link>https://freshrimpsushi.github.io/posts/disjoint-union/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/disjoint-union/</guid>
      <description>**서로소인 합집합, 분리합집합 $\left\{ X_\alpha \right\} _{\alpha\in A}$를 임의의 인덱스 패밀리라고 하자. 그러면 $\left\{ X_\alpha\right\}$의 분리합집합을 아래와 같이 정의한다. $$ \bigsqcup \limits_{\alpha \in A} X_\alpha := \left\{ (x,\alpha)\ |\ x\in X_\alpha,\ \alpha \in A \right\} $$ $\bigsqcup$대신에 $\amalg$, $\biguplus$등을 쓰기도 한다. $\amalg$는 대문자 파이 $\Pi$가 아님에 주</description>
    </item>
    
    <item>
      <title>조건부 기대값의 스무딩 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/smoothing-properties-of-conditional-expectation/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/smoothing-properties-of-conditional-expectation/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G}, \mathcal{G}&#39; \subset \mathcal{F}$ 가 주어져있다고 하고 $X$, $Y$ 가 확률 변수라고 하자.[1] $X$ 가 $\mathcal{G}$-가측이면 $$ E(XY | \mathcal{G}) = X E (Y | \mathcal{G}) \text{ a.s.} $$ [2] $\mathcal{G}&#39; \subset \mathcal{G}$ 이면 $$ \begin{eqnarray*} E (X | \mathcal{G}&#39;) &amp;amp;=&amp;amp; E \left( E ( X | \mathcal{G}) | \mathcal{G}&#39; \right) \\ &amp;amp;=&amp;amp; E \left( E ( X | \mathcal{G}&#39;) | \mathcal{G} \right) \end{eqnarray*} $$ * $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드라는 것은 둘 다 $\Omega$ 의 시그마 필드이되, $\mathcal{G} \subset \mathcal{F}$ 임을 의</description>
    </item>
    
    <item>
      <title>짝 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-union/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-union/</guid>
      <description>$$ \forall A \forall B \exists U ( a \in A \land b \in B ) $$ 임의의 두 집합 $A$, $B$ 에 대해 $A$ 와 $B$ 를 원소로 가지는 집합 $U$ 가 존재한다.처음으로 짝 공리를 접하면 (사실 대부분의 공리를 접할 때는 거의 다 비슷하지만) 도대체 이런 공리가 왜 필요한지 의문이 들 수가 있다. 그런데 사실 짝 공리란 진정으로 집합이라는 개념을 수학의 영역으로 끌어올리는 역할을 한다고 말할 수 있다.집합</description>
    </item>
    
    <item>
      <title>조건부 확률의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-conditional-probability/</link>
      <pubDate>Mon, 14 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-conditional-probability/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G} \subset \mathcal{F}$ 가 주어져있다고 하자.[1] 모든 $B \in \mathcal{G}$ 에 대해 $0 \le P(B | \mathcal{G}) \le 1$[2] 네스티드 시퀀스 $\left\{ B_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{G}$ 에 대해 $$ \lim_{n \to \infty} B_{n} = B \implies P ( B_{n} | \mathcal{G} ) \to P ( B | \mathcal{G} ) \text{ a.s.} $$ **[3]** $\left\{ B_{n} \right\}_{n \in \mathbb{N}}$ 가 $\Omega$ 의 파티션이면 $$ P \left( \bigsqcup_{n \in \mathbb{N}} B_{n} | \mathcal{G} \right)= \sum_{n \in \mathbb{N}} P \left( B_{n} | \mathcal{G} \right) $$ * 사건의 시퀀스 $\left\{ B_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{G}$ 가 네스티드라는 것은 다음 두</description>
    </item>
    
    <item>
      <title>공집합 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-empty-set/</link>
      <pubDate>Sun, 13 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-empty-set/</guid>
      <description>$$ \exists X \forall x \left( \lnot \left( x \in X \right) \right) $$ 어떤 원소도 가지지 않는 집합 $X$ 가 존재하고, 이 집합 $X$ 를 공집합 이라고 정의한다.공집합은 일반적으로 $\emptyset$ 과 같이 표기한다. 한편 공집합은 공집합은 원소의 개수가 $0$ 개인 집합으로도 볼 수 있는데, 이와 같이 원소의 개수로 정의할 수 있는 집합에는 다음과 같은 것들이 있다 :1. Singletone Set : 원소의 개수가 단 하나인 집합을 홑원소 집합 이</description>
    </item>
    
    <item>
      <title>조건부 지배 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conditional-dominated-convergence-theorem/</link>
      <pubDate>Sat, 12 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conditional-dominated-convergence-theorem/</guid>
      <description>지배 수렴 정리확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.확률 변수의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 모든 $n \in \mathbb{N}$ 과 어떤 $Y \in \mathcal{L}^{1} (\Omega)$ 에 대해 $ | X_{n} | \le Y$ 라고 하면 $$ X_{n} \to X \text{ a.s.} \implies E( X_{n} | \mathcal{G} ) \to \mathcal{G} ) \text{ a.s.} $$ 조건부 지배 수렴 정리는 단지 DCT가 조건부 기대값에 대해서도 똑같이 적용된다는 것을 말해준다. 물론 확률론에서의 역할도 DCT와 같다. 증명 조건부 기대</description>
    </item>
    
    <item>
      <title>복소 측도 벡터 측도</title>
      <link>https://freshrimpsushi.github.io/posts/complex-measure-vector-measure/</link>
      <pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complex-measure-vector-measure/</guid>
      <description>측도부호 측도**** **복소 측도 $(X,\mathcal{E})$를 가측공간이라고 하자. 아래의 조건을 만족하는 함수 $\nu\ :\ \mathcal{E} \rightarrow \mathbb{C}$를 $(X,\mathcal{E})$ 위의 **복소 측도** 혹은 **벡터 측도** 라고 한다.$(a)$ $\nu (\varnothing) = 0 $$ (b)$ 서로소인 $E_j \in \mathcal{E}$에 대해서, $$ \nu \left( \bigcup \limits_{j=1}^\infty E_j \right) = \sum \limits_1 ^\infty \nu(E_j) $$ $(b)$</description>
    </item>
    
    <item>
      <title>외연 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-extensionality/</link>
      <pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-extensionality/</guid>
      <description>$$ \forall A \forall B ( \forall x ( x \in A \iff x \in B) ) $$ 임의의 두 집합 $A$, $B$ 에 속한 원소가 같으면 두 집합이 같다 고 하고 $A = B$ 와 같이 나타낸다.한편 $A$ 와 $B$ 가 같지 않으면 $A \ne B$ 와 같이 나타낸다.두 집합의 같음은 그 자체로 공리이자 정의다. Extensionality는 확장이 아니라 외연外延을 의미하는 것으로, 집합은 &amp;lsquo;어떠한 집합&amp;rsqu</description>
    </item>
    
    <item>
      <title>조건부 단조 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conditional-monotone-convergence-theorem/</link>
      <pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conditional-monotone-convergence-theorem/</guid>
      <description>단조 수렴 정리확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.확률 변수의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 과 $X \in \mathcal{L}^{1} (\Omega)$에 대해 $$ X_{1} \le X_{2} \le \cdots \le X \\ X_{n} \to X \text{ a.s.} $$ 이면 $$ \lim_{n \to \infty} E( X_{n} | \mathcal{G} ) = E( \lim_{n \to \infty} X_{n} | \mathcal{G} ) \text{ a.s.} $$ 조건부 단조 수렴 정리는 단지 MCT가 조건부 기대값에 대해서도 똑같이 적용된다는 것을 말해준다. 물론 확률론에서의 역할도 MCT와</description>
    </item>
    
    <item>
      <title>매트랩에서 행렬의 특정한 행 열을 선택하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1362/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1362/</guid>
      <description>$m \times n$ 행렬로된 데이터가 있고 이를 $A$라고 하자. 행렬 $A$의 특정한 부분만을 이용하고 싶다면 아래와 같은 방법을 사용하면 된다. B=A(a:b,c:d) 위와 같은 코드를 실행시키면 $B$는 행렬 $A$의 $a$행~$b$행, $c$열~$d$열의 데이터를 가진 $(b-a) \times (d-c)$행렬이 된다. 아래는 예제 코드와 실행 결과이다. for k=1:9 for l=1:9 A(k,l)=10*k+l; end end A a1=A(3:7,4:9); a1 a2=A(2:5,1:6); a2 : :</description>
    </item>
    
    <item>
      <title>시그마 유한 측도</title>
      <link>https://freshrimpsushi.github.io/posts/sigma-finite-measure/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sigma-finite-measure/</guid>
      <description>가측 공간 $( X , \mathcal{E} )$가 주어져있다고 하자.1. $\mu (X) &amp;lt; \infty$ 이면 $\mu$ 를 유한 측도라고 한다.2. $\displaystyle X = \bigcup_{i=1}^{\infty} E_{i}$, $E_{i} \in \mathcal{E}$ 라고 할 때 모든 $i \in \mathbb{N}$ 에 대해 $\mu ( E_{i} ) &amp;lt; \infty$ 면 **시그마 유한** 측도라고 한다. 또한 순서쌍 $(X, \mathcal{E}, \mu)$를 **시그마 유한 측도 공간** 이라고 한다.**3.** $\mu ( E ) = \infty$ 인 모든 $E \in \mathcal{E}$ 에 대해 $0 &amp;lt; \mu (F) &amp;lt; \infty$ 를 만족하는 $E$ 의</description>
    </item>
    
    <item>
      <title>삼단논법의 수리논리적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-syllogism/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-syllogism/</guid>
      <description>$$ ( p \to q ) \land ( q \to r ) \implies p \to r $$ 삼단논법을 모르는 사람은 없고 굳이 설명해줄 것도 없다고 본다. 고대의 철학적 논쟁이 아닌 이상에야 굳이 &amp;lsquo;삼단논법에 의해&amp;rsquo;라는 말을 쓰는 경우는 흔치 않다. 그만큼 우리들에게는 익숙한 논법이자 보편타당한 원리기 때문이다.하지만 삼단논법이 증명이 되는 것이고 증명을 해야하는 것이</description>
    </item>
    
    <item>
      <title>수학적 귀납법</title>
      <link>https://freshrimpsushi.github.io/posts/mathmatical-induction/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mathmatical-induction/</guid>
      <description>명제 $p(n) (n=1,2,3, \cdots )$ 에 대해 $p(1)$ 이 참이고 $p(n)$ 을 가정했을 때 $p(n+1)$ 이 성립하면 $p(n)$ 은 참이다.어떤 식이 자연수에 대해 성립할 때 특히 큰 위력을 발휘하는 증명법으로, 페아노 제5공리 라고도 불리며 혹은 &amp;lsquo;수학적&amp;rsquo;이라는 말을 떼고 그냥 귀납법이라고도 한다. 본래 귀납법이란 현상이나 실체를 경험적으로 모아 어떤 결론을 내리는 것인데, 수학에</description>
    </item>
    
    <item>
      <title>행렬의 연속 미분 적분 지수행렬</title>
      <link>https://freshrimpsushi.github.io/posts/1342/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1342/</guid>
      <description>미분 방정식에서는 실변수 $t$에 대한 함수들로 이루어진 벡터 혹은 행렬을 다뤄야할 때가 있다. 예를 들어 $$ \mathbf{x}(t) = \begin{pmatrix} x_1(t) \\ \vdots \\ x_n(t) \end{pmatrix},\quad \mathbf{A}(t) \begin{pmatrix} a_{11}(t) &amp;amp; \cdots &amp;amp; a_{1m}(t) \\ \vdots &amp;amp; &amp;amp; \vdots \\ a_{n1}(t) &amp;amp; \cdots &amp;amp; a_{nm}(t) \end{pmatrix} $$ 이를 $\mathrm{matrix\ function}$이라 한다. 읽는대로 번역하면 행렬 함수이지만 함수를 성분으로 가지는 행렬이라는 의미가 잘 드러나게 하려면 함수 행렬이라는 표현이 더 맞는 것 같다</description>
    </item>
    
    <item>
      <title>귀류법의 수리논리적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-reductio-ad-absurdum/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-reductio-ad-absurdum/</guid>
      <description>$$ (p \land \lnot q) \to c \iff p \to q $$ * 여기서 $c$ 는 모순을 의미한다.배리법 혹은 귀류법 은 수학 전반에서 정말 많이 사용되는 증명법이다. 하지만 처음 귀류법을 접하는 사람은 이게 단어부터 생소해서 거부감이 들 수 있다. 혹은 그냥 익숙해졌을 뿐, 왜 귀류법이 작동하는지 이해하지 못한 사람도 있을 것이다.아래의 글을 읽어보면서 귀류법을 이해해보자:(1) 결론</description>
    </item>
    
    <item>
      <title>측도의 절대 연속</title>
      <link>https://freshrimpsushi.github.io/posts/absolutely-continuous/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/absolutely-continuous/</guid>
      <description>부호 측도의 절대 연속가측 공간 $( \Omega , \mathcal{F} )$ 가 주어져 있다고 하자. 측도 $\nu$, $\mu$ 가 모든 $A \in \mathcal{F}$ 에 대해 $$ \mu (A) = 0 \implies \nu (A) = 0 $$ 를 만족시키면 $\nu$ 가 $\mu$ 에 대해 절대 연속 이라 하고 $\nu \ll \mu$ 와 같이 나타낸다.$\nu \ll \mu$ 이라는 표기에서 단번에 알 수 있듯 $\mu$ 는 $\nu$ 를 &amp;lsquo;제압&amp;rsquo;하는 느낌이 강하다. 문제는 이걸 왜 &amp;lsquo;절대 연속&amp;</description>
    </item>
    
    <item>
      <title>프레셰 도함수에 대한 연쇄 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/chain-rule-for-frechet-derivative/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chain-rule-for-frechet-derivative/</guid>
      <description>**프레셰 도함수에 대한 연쇄 법칙$(\mathrm{Chain\ rule\ for\ Frechet\ derivative})$ $X$, $Y$, $Z$가 바나흐 공간이라고 하자. $\Omega \subset X$, $U \subset Y$가 열린 집합이라고 하자. 그리고 함수 $F\ :\ \Omega \rightarrow Y$, $G\ :\ U \rightarrow Z$가 주어졌다고 하자. 이 때 $F(\Omega) \subset U$를 만족한다.이제 $F$가 $x\in\Omega$에서 (프레셰) 미분가능하고, $G$가 $z=F(x)\in U$에서 미분</description>
    </item>
    
    <item>
      <title>가측 공간의 파티션과 리파인먼트</title>
      <link>https://freshrimpsushi.github.io/posts/partition-and-refinement/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-and-refinement/</guid>
      <description>가측 공간 $( \Omega , \mathcal{F} )$ 가 주어져 있다고 하자.$( \Omega , \mathcal )$ 에 대해 $\displaystyle \bigsqcup_{i=1}^{k} A_{i} = \Omega$ 를 만족하는 $\mathcal{P} : = \left\{ A_{i} \in \mathcal{F} : i_{1} \ne i_{2} \implies A_{i_{1}} \cap A_{i_{2}} = \emptyset \right\}_{i=1}^{k}$ 를 가측 공간 $\Omega$ 의 **유한 (가측) 파티션** 이라고 한다. 모든 $A_{i} \in \mathcal{P}$ 에 대해 $\displaystyle A_{i} = \bigsqcup_{j \in J} B_{j} $ 를 만족시키는 $B_{j} \in \mathcal{P}&#39;$ 들이 존재하면 $\mathcal{P}&#39;$ 를 $\mathcal{P}$ 의 **리파인먼트** 라고 한다. * 여기서 $\displaystyle \bigsqcup$ 은 서로소인 집합들의 합집합을</description>
    </item>
    
    <item>
      <title>대우법의 수리논리적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-contrapositive-law/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-contrapositive-law/</guid>
      <description>$$ p \to q \iff \lnot q \to \lnot p $$ 어떤 명제가 참이면 그 대우도 참, 어떤 명제가 거짓이면 그 대우도 거짓이다. 물론 역Converse 이 성립한다면 대우법에 의해서 원래 명제의 이Reverse 도 성립한다.이러한 표현들은 수학에 익숙하지 않은 사람들에겐 너무 어렵다. 예를 들어서 이해해보자 :$p$ : 날씨가 덥다$q$ : 땀이 난다$p \to q$ : 날씨가 더우면 땀</description>
    </item>
    
    <item>
      <title>유계 선형 사상</title>
      <link>https://freshrimpsushi.github.io/posts/bounded-linear-map/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bounded-linear-map/</guid>
      <description>**** **유계 선형 사상$(\mathrm{bounded\ linear\ map})$ $(X,\ |\cdot|_X)$, $(Y,\ |\cdot |Y)$가 놈 공간이라고 하자. 아래의 조건을 만족하는 선형 사상 $L\ :\ X \rightarrow Y$를 유계라 한다. $$ | L |:=\sup \limits{ | x | \le 1 \\ x\in X} |Lx| &amp;lt; \infty $$ 유계 선형 사상 $L$에 대해서 아래의 부등식이 성립한다. $$ |Lx|_Y\le |L| |x|_X,\quad \forall x \in X $$ 모든 $x\in X$에 대해서 성립한다는 것이 핵심이다. 증명 놈의</description>
    </item>
    
    <item>
      <title>드 모르간의 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-de-morgans-laws/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-de-morgans-laws/</guid>
      <description>[1] 드 모르간의 법칙 : $$ \lnot (p \land q) \iff \lnot p \lor \lnot q \\ \lnot(p \lor q) \iff \lnot p \land \lnot q $$ [2] 드 모르간의 정리 : $$ (A \cup B)^{c} = A^{c} \cap B^{c} \\ (A \cap B)^{c} = A^{c} \cup B^{c} $$ 드 모르간의 법칙와 드 모르간의 정리는 각각 명제, 집합에 대한 정리지만 실제로 말을 하면서는 별로 구분하지 않는다. 법칙이든 정리든 드 모르간- 만 붙으면 부정이나 여집합을 취하면 괄호 안의 명제, 집합과 기호가 &amp;lsq</description>
    </item>
    
    <item>
      <title>매트랩에서 그래프 색 선 종류 마커 종류 지정하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1330/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1330/</guid>
      <description>사용하는 방법은 예제 코드를 보면 쉽게 알 수 있을 것이다. 모르겠으면 덧글 달아라. 그래프 색 마커 종류 선의 형태 빨강 r .(점) . 실선 - 초록 g *(별표) * 점선 : 파랑 b x x 점단선 -. 검정 k ○(원) o (알파벳 오) 단선 &amp;ndash; 노랑 y + + 선 없음 자홍 m □ s 하양 w ◇ d 청록 c ☆(오각별) p ▽ v △ ^ ◁ &amp;lt; ▷ (육각별) h 마커 없음 x=1:20; y=x.^3+3.*x.^2+3.*x+1; figure() plot(x,y,&amp;#39;ro&amp;#39;) title(&amp;#39;ro&amp;#39;) figure() plot(x,y,&amp;#39;g-&amp;#39;) title(&amp;#39;g-&amp;#39;) figure()</description>
    </item>
    
    <item>
      <title>프레셰 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/frechet-derivative/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/frechet-derivative/</guid>
      <description>**프레셰 미분 가능$(\mathrm{ Frechet\ differentiable})$, 프레셰 도함수$(\mathrm{ Frechet\ derivative})$ 두 바나흐 공간 $X$, $Y$와 열린 집합 $\Omega \subset X$가 주어졌다고 하자. 그러면 함수 $F\ :\ \Omega \rightarrow Y$에 대해서 아래의 조건을 만족하는 유계 선형 사상 $L\ :\ X \rightarrow Y$가 존재하면 $F$가 $x\in \Omega$에서 프레셰 미분가능 하다고 한다. $$ \lim \limits_{ | y| \rightarrow 0} \frac{| F(x+y) -F(x)-Ly |}{|y|}=0 $$ 이때</description>
    </item>
    
    <item>
      <title>매트랩에서 이미지를 회전시키는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1328/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1328/</guid>
      <description>줄리아에서 이미지 회전하는방법imrotate(I,angle,method,bbox)I : 회전할 영상, 이미지이다. angle : 회전할 각도이며 단위는 도이다.method : 보간 방법이다. &amp;lsquo;nearest&amp;rsquo;, &amp;lsquo;bilinear&amp;rsquo;, &amp;lsquo;bicubic&amp;rsquo;이 있다. 아무것도 입력하지 않으면 &amp;lsquo;nearet&amp;rsquo;가 적용된다</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 조인트 분포와 마지널 분포</title>
      <link>https://freshrimpsushi.github.io/posts/joint-distribution-and-marginal-distribution/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/joint-distribution-and-marginal-distribution/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.1. 조인트 분포 : $( \Omega , \mathcal{F} , P)$ 에서 정의된 두 확률 변수 $X$, $Y$ 가 있다고 할 때, 랜덤 벡터 $(X,Y) : \Omega \to \mathbb{R}^2$ 의 분포는 보렐 셋 $B \subset \mathcal{B} \left( \mathbb{R}^2 \right)$ 에 대해 $$ \begin{eqnarray*} P_{(X,Y)} (B) &amp;amp;:=&amp;amp; P \left( (X,Y) \in B \right) \\ &amp;amp;=&amp;amp; \int_{B} f_{(X,Y)} (x,y) d m_{2} (x,y) \end{eqnarray*} $$ 와 같이 정의되며, 이를 만족시키는 $f_{(X,Y)}$ 가 존재한다면 $X$, $Y$ 가 **조인트 밀도** 를 가진다고 한다.**2. 마지널 분포</description>
    </item>
    
    <item>
      <title>매트랩에서 특수한 행렬을 만드는 함수</title>
      <link>https://freshrimpsushi.github.io/posts/1327/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1327/</guid>
      <description>zeros() : 영행렬을 반환한다. zeros(n) : $n\times n$ 영행렬을 반환한다. zeros(m,n) : $n\times m$ 영행렬을 반환한다. zeros(size(A)) : 행렬 A와 같은 크기의 영행렬을 반화한다. ones() : 모든 원소가 1인 행렬을 반환한다. 다만 두 행렬 사이의 연산을 위해서는 그냥 1을 쓰는게 편하다. 누가 봐도 예제 코드 중에서 아래의 코드가 훨씬 간단하다. ones(n) : 모든 원소가 1인 $n\times n$ 행렬을 반환한다. ones(m,n) : 모든 원소가</description>
    </item>
    
    <item>
      <title>항진 명제와 항위 명제</title>
      <link>https://freshrimpsushi.github.io/posts/tautology-and-contradiction/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tautology-and-contradiction/</guid>
      <description>모든 논리적 가능성에 대해 참인 명제를 항진 명제 라고 한다. 모든 논리적 가능성에 대해 거짓인 명제를 항위 명제 라고 한다.실제로 항위 명제라는 단어는 거의 쓰이지 않으며, 그 대신 모순이라는 말을 많이 사용한다. 기호로는 항진 Tautology과 모순 Contradiction의 앞글자를 따서 항진 $t$, 모순 $c$ 와 같이 나타낸다.위의 진리표에 따르면</description>
    </item>
    
    <item>
      <title>매트랩에서 두 행렬을 성분별로 연산하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1326/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1326/</guid>
      <description>times() , .* : 두 행렬의 각 성분을 곱해서 그 결과를 반환한다. 두 행렬의 크기가 완전히 같거나, 한 쪽이 스칼라이거나, 행의 크기가 같은 행벡터, 열의 크기가 같은 열벡터일 경우에만 연산이 가능하다. 크기가 다른 경우에 작은 행렬이 큰 행렬과 같은 크기의 행렬인 것 처럼 계산되는데 이 때 빈 자리는 똑같은 값으로 채워진다. 예를 들어 스칼라는 모든 성분이 같은 값을 가</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 특성 함수와 적률생성함수</title>
      <link>https://freshrimpsushi.github.io/posts/characteristic-function-and-moment-generating-function/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/characteristic-function-and-moment-generating-function/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.확률 변수 $X$ 과 $t \in \mathbb{R}$ 에 대해 다음과 같이 정의된 $\varphi_{X} (t)$ 를 $X$ 의 **특성 함수** 라고 한다. $$ \varphi_{X} (t) := E \left( e^{i t X} \right) = \int_{\mathbb{R}} e^{it x} f_{X} (x) dx $$ * 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다.확률 변수 $Z : = X + i Y$ 는 두 확률 변수 $X, Y : \Omega \to \mathbb{R}$ 에 대해 다음과 같은 성질을 갖도록 정의된다. $$ \int</description>
    </item>
    
    <item>
      <title>균등 C^m-정칙성 조건 The uniform C^m-regularity condition</title>
      <link>https://freshrimpsushi.github.io/posts/1324/</link>
      <pubDate>Sun, 22 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1324/</guid>
      <description>**균등 $C^m$-정칙성 조건$(\mathrm{ The\ uniform}$ $C^m$-$\mathrm{regularity\ condition})$ 만약 $\mathrm{bdry}\Omega$의 국소 유한 오픈 커버 $\left\{ U_j \right\}$가 존재하고, 그에 대응되는 $U_j$를 볼 $B=\left\{ y\in \mathbb{R}^n\ :\ |y|&amp;lt;1 \right\}$로 보내는 $m$-스무스 변환의 수열 $\left\{ \Phi_j \right\}$와 역변환 $\Psi j=\Phi_j^{-1}</description>
    </item>
    
    <item>
      <title>명제와 결합자 진리표</title>
      <link>https://freshrimpsushi.github.io/posts/statement-connective-truth-table/</link>
      <pubDate>Sun, 22 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statement-connective-truth-table/</guid>
      <description>참이거나 거짓이거나 둘 중 하나인 서술을 명제 라고 한다. 명제는 참이거나 거짓 둘 중 하나의 진리값Truth Value 을 가진다. 두 명제 $p$, $q$ 의 진리값이 같으면 $p$ 와 $q$ 가 (논리적) 동치(Logically) Equivalent 라고 하고, $p \equiv q$ 와 같이 나타낸다. 다음을 결합자 라고 한다.1. 부정 : $\lnot$2. 논리곱 : $\land$3. 논리합 : $\lor$4. 조건부 : $\to$5. 쌍조건부 : $\leftrig</description>
    </item>
    
    <item>
      <title>매트랩에서 행렬의 길이 크기와 관련된 함수</title>
      <link>https://freshrimpsushi.github.io/posts/1323/</link>
      <pubDate>Sat, 21 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1323/</guid>
      <description>size() : 행렬의 행, 열의 길이를 성분으로 갖는 행 벡터를 반환한다. 다루고 있는 행렬과 크기가 같은 영행렬을 만들 때 유용하다. zeros(size(A))는 A와 크기가 같은 영행렬을 반환한다. length() : 행과 열 중에서 더 큰 숫자를 반환한다. 행벡터, 열벡터의 경우에는 성분의 개수와 같으므로 numel() 과 같다. 또한 size()는 행과 열의 크기를 반환하므로 l</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 기대값</title>
      <link>https://freshrimpsushi.github.io/posts/expectation/</link>
      <pubDate>Sat, 21 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation/</guid>
      <description>수리통계학에서 정의됐던 기대값확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.확률 변수 $X$ 에 대해서 다음과 같이 정의된 $E(X)$ 를 $X$ 의 (수리적) 기대값 이라고 한다. $$ E(X) := \int_{\Omega} X d P $$ * 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다.기대값의 정의는 아무리 측도론이 쓰였다지만 너무 난해하다. 무슨 뜻인지 대강은 알겠지만 한 줄 찍 써놓</description>
    </item>
    
    <item>
      <title>강한 국소 립시츠 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-strong-local-lipschitz-condition/</link>
      <pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-strong-local-lipschitz-condition/</guid>
      <description>**강한 국소 립시츠 조건$(\mathrm{The\ strong\ local\ Lipschitz\ condition})$ 만약 양수 $\delta$, $M$과 $\mathrm{bdry}\Omega$의 국소 유한 오픈 커버 $\left\{ U_j \right\}$가 존재해서, 각각의 $j$에 대해서 $n-1$개의 변수를 가지는 실수값을 갖는 함수 $f_j$가 $(a)$~$(d)$를 만족하면, 오픈 셋 $\Omega \subset \mathb</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 디락 측도와 이산 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/dirac-measure-and-discrete-probability-distribution/</link>
      <pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirac-measure-and-discrete-probability-distribution/</guid>
      <description>수리통계학에서 정의됐던 이산 확률 분포 기초적인 확률론에서 확률 분포란 이산과 연속 둘 중 하나였고, 그 설명도 다소 직관을 동원할 수밖에 없었다. 그러나 측도론을 도입하면 수학적인 모호함 없이 깔끔하게 이산 확률 분포 를 정의할 수 있다. 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. Step 1. 확률 변수 $X$ 가 단 하나의 값을 가지는 경우 $X = a$ 인 경우만 있다고 생</description>
    </item>
    
    <item>
      <title>균등 콘 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-uniform-cone-condition/</link>
      <pubDate>Thu, 19 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-uniform-cone-condition/</guid>
      <description>**균등 콘 조건$(\mathrm{The\ uniform\ cone\ conditionz})$ 만약, $\Omega$의 경계의 국소 유한 오픈 커버 $\left\{ U_j \right\}$가 존재하고, 그에 대응하는 유한 콘 $\left\{ C_j \right\}$가 $(a)$~$(d)$를 만족하며 존재하면 열린 집합 $\Omega \subset \mathbb{R}^n$가 균등 콘 조건을 만족한다고 한다.$(a)$ 모든 $U_j</description>
    </item>
    
    <item>
      <title>아이젠슈타인 소수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eisenstein-prime-theorem/</link>
      <pubDate>Thu, 19 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eisenstein-prime-theorem/</guid>
      <description>아이젠슈타인 링의 이리듀서블 엘리먼트를 아이젠슈타인 소수 라고 한다. 아이젠슈타인 정수 $\pi \in \mathbb{Z}[ \omega ]$ 가 다음의 조건들 중 하나를 만족하면 아이젠슈타인 소수다.(i) $\pi = 1 + \omega 2$(ii) 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 2 \pmod{3}$ 인 $\pi = p$(iii) 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 1 \pmod{3}$ 이라고 할 때, $p = u^2 - uv+ v^2$ 를 만족시키는 $\pi = u + \omega v$(iv) 위의 (i)~(iii) 에 해당되는 $\pi$ 에 $\mathbb{Z} [\omega ] $ 의 유닛 $\pm 1 ,</description>
    </item>
    
    <item>
      <title>주어진 도메인에 대한 두 가지 유용한 표현</title>
      <link>https://freshrimpsushi.github.io/posts/1317/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1317/</guid>
      <description>열린 집합 $\Omega \subset \mathbb{R}^n$가 주어져있다고 하자. 그러면 $\Omega_{&amp;lt;\delta}$와 $\Omega_{&amp;gt;\delta}$는 아래와 같이 정의된다. $$ \Omega_{&amp;lt;\delta} := \left\{ x\in\Omega\ :\ \mathrm{dist}(x,\ \mathrm{bdry}\Omega)&amp;lt;\delta \right\} $$ $$ \Omega_{&amp;gt;\delta} := \left\{ x\in\Omega\ :\ \mathrm{dist}(x,\ \mathrm{bdry}\Omega)&amp;gt;\delta \right\} $$ 보다시피 정의는 매우 간단하다. 그렇지만 여러 증명이나 정의에서 쓰이는 등 해석적인 내용을 다룰 때 유용</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 밀도와 누적 분포 함수</title>
      <link>https://freshrimpsushi.github.io/posts/density-and-cumulative-distribution-function/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/density-and-cumulative-distribution-function/</guid>
      <description>수리통계학에서 정의됐던 확률 변수의 밀도와 누적 분포 함수확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있고 $m$ 이 측도라고 하자.1. 측도 $P : \mathcal{F} \to \mathbb{R}$ 가 적분가능한 $f \ge 0$ 에 대해 $$ A \mapsto P(A) = \int_{A} f dm $$ 의 폼을 갖추고 있으면 $P$ 가 **절대 연속**Absolutely Continuous 이라고 한다. 특히 이러한 $f$ 를 측도 $m$ 에 대한 $P$ 의 **밀도** 라고 부른다.**2.** 다</description>
    </item>
    
    <item>
      <title>아이젠슈타인 링의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-of-gaussian-ring/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-of-gaussian-ring/</guid>
      <description>아이젠슈타인 링 $\mathbb{Z}[ \omega ]$ 에 대해 함수 $N : \mathbb{Z}[\omega] \to \mathbb{Z}$ 를 생각해보자.[1] $N(x + \omega y) := x^2 - xy + y^2$ 이라고 정의하면 $N$ 은 $\mathbb{Z}[ \omega ]$ 의 승법적 놈이 된다.[2] $\mathbb{Z}[ \omega ]$ 은 유클리디안 도메인이다.[3] $\mathbb{Z}[ \omega ]$ 의 유닛은 $\pm 1, \pm \omega, \pm \omega^2 $ 뿐이다.아이젠슈타인 정수는 추상대수의 도움을 받으면 훨씬 편하게 연구할 수 있다. 인티그럴 도메인에서 정의되는 놈 $N$ 으로 [2]</description>
    </item>
    
    <item>
      <title>조던 분해 정리</title>
      <link>https://freshrimpsushi.github.io/posts/jodan-decomposition-theorem/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jodan-decomposition-theorem/</guid>
      <description>**조던 분해 정리$(\mathrm{Jodan\ decomposition\ theorem})$ 가측공간 $(X,\mathcal{E})$와 그 위에서 정의된 부호측도 $\nu$가 주어졌다고 하자. 그러면 아래의 조건을 만족하는 두 양측도 $\nu^+$, $\nu^-$가 유일하게 존재하고 $\nu=\nu^+-\nu^-$를 $\nu$의 조던 분해 라고 부른다. $$ \nu=\nu^+-\nu^- $$ $$ \nu^+ \perp \nu^- $$ 이</description>
    </item>
    
    <item>
      <title>뮤츄얼리 싱귤러</title>
      <link>https://freshrimpsushi.github.io/posts/mutually-singular/</link>
      <pubDate>Mon, 16 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mutually-singular/</guid>
      <description>**** 뮤츄얼리 싱귤러 **$(\mathrm{mutually\ singular})$ 두 부호 측도 $\nu$, $\mu$가 주어졌다고 하자. $\nu$, $\mu$에 대해서 아래의 세 조건을 만족시키는 $E,F\ \in \mathcal{E}$가 존재하면 두 부호측도 $\nu$, $\mu$는 mutually singular라고 말하고 $\nu \perp \mu$혹은 $\mu \perp \nu$라고 나타낸다.$(a)$ $E \cup F=X $$ (b)$ $E \cap F=\varnothing $$ (c)$ $E$는 $\nu$에 대해서 영집합이</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 독립</title>
      <link>https://freshrimpsushi.github.io/posts/independence-of-random-variables/</link>
      <pubDate>Mon, 16 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independence-of-random-variables/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.모든 보렐 셋 $B_{1} , B_{2} \in \mathcal{B} ( \mathbb{R} )$ 에 대해 다음이 성립하면 확률 변수 $X$, $Y$ 가 독립이라고 한다. $$ P \left( X^{-1} (B_{1} ) \cap Y^{-1} (B_{2} ) \right) = P \left( X^{-1} (B_{1}) \right) P \left( Y^{-1} (B_{2}) \right) $$ * 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다.사실 확률론을 공부함에 있어서 기초적인 분포이론을 지나고나면 사건의 독립이라는 것은 그다</description>
    </item>
    
    <item>
      <title>아이젠슈타인 정수</title>
      <link>https://freshrimpsushi.github.io/posts/eisenstein-integer/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eisenstein-integer/</guid>
      <description>$\mathbb{Z} [ \omega ] := \left\{ a + \omega b : a, b \in \mathbb{Z} \right\} $ 를 아이젠슈타인 링Eisenstein Ring 이라고 하고, 그 원소를 아이젠슈타인 인티저 라고 한다.$\omega$ 는 삼차방정식 $x^3 +1 = 0$ 의 복소근 $\displaystyle \omega := {{-1 + \sqrt{-3}} \over {2}} = e^{2 \pi i/3 }$ 으로써, $\mathbb{Z} [\omega]$ 은 인티저 링 $\mathbb{Z}$ 의 심플 익스텐젼이 된다. 가우스 정수만큼이나 흥미로운 성질을 가진 수 체계로써, 계산이 좀 더 복잡하</description>
    </item>
    
    <item>
      <title>한 분해 정리</title>
      <link>https://freshrimpsushi.github.io/posts/hahn-decomposition-theorem/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hahn-decomposition-theorem/</guid>
      <description>**한 분해 정리 $(a)$ $\nu$를 가측공간 $(X, \mathcal{E})$위에서 정의된 부호측도라고 하자. 그러면 $P \cup N=X$이고 $P \cap N =\varnothing$을 만족하는 $\nu$에 대한 양의 집합 $P$와 음의 집합 $N$이 존재한다.$(b)$ $P’$, $N’$이 $(a)$를 만족하는 다른 집합이라고 하자. 그러면 아래의 집</description>
    </item>
    
    <item>
      <title>양의 집합 음의 집합 영집합</title>
      <link>https://freshrimpsushi.github.io/posts/positive-set-negativ-set-null-set/</link>
      <pubDate>Sat, 14 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/positive-set-negativ-set-null-set/</guid>
      <description>**양의 집합, 음의 집합, 영집합$(\mathrm{positive\ set,\ negative\ set,\ null\ set})$ $\nu$를 $(X,\mathcal{E})$위에서의 부호 측도라고 하자. 그리고 $E,F \in \mathcal{E}$라고 하자. 그러면$\nu(F) \ge 0,\ \forall F\subset E$일 때 $E$를 $\nu$에 대해서 양의 집합 , 혹은 간단히 양$(\mathrm{p</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수와 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution/</link>
      <pubDate>Sat, 14 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution/</guid>
      <description>수리통계학에서 정의됐던 확률 변수와 확률 분포확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.1. 모든 보렐 셋 $B \in \mathcal{B} (\mathbb{R})$ 에 대해 $X^{-1} (B) \in \mathcal{F}$ 를 만족하는 함수 $X : \Omega \to \mathbb{R}$ 을 확률변수 라고 한다.2. 다음과 같이 정의된 $\mathcal{F}{X}$ 를 $X$ 에 의해 생성된 시그마 필드 라고 한다. $$ \mathcal{F}{X} := X^{-1} ( \mathcal{B} ) = \sigma (X) = \left\{ X^{-1} (B) \in \Omega : B \in \mathcal{B}( \Omega ) \right\} $$ 3. 다음과 같이 정의된 가측 함수 $P_{X}$ 를 $X$ 의</description>
    </item>
    
    <item>
      <title>가우스 소수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gaussian-prime-theorem/</link>
      <pubDate>Fri, 13 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gaussian-prime-theorem/</guid>
      <description>가우시안 링의 이리듀서블 엘리먼트를 가우스 소수 라고 한다. 가우스 정수 $\pi \in \mathbb{Z}[i]$ 가 다음의 조건들 중 하나를 만족하면 가우스 소수다.(i) $\pi = 1 + i$(ii) 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 3 \pmod{4}$ 인 $\pi = p$(iii) 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 1 \pmod{4}$ 이라고 할 때, $p = u^2 + v^2$ 를 만족시키는 $\pi = u + iv$(iv) 위의 (i)~(iii) 에 해당되는 $\pi$ 에 $\mathbb{Z}[i]$ 의 유닛 $1,-1,i,-i$ 을 곱해서 구해지는 $ i^{k} \pi$(iv) 위의 (i)~(iii) 에 해당되는 $\pi$ 에</description>
    </item>
    
    <item>
      <title>부호가 붙은 측도</title>
      <link>https://freshrimpsushi.github.io/posts/signed-measure/</link>
      <pubDate>Fri, 13 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/signed-measure/</guid>
      <description>측도복소 측도**부호 측도$(\mathrm{signed\ measure})$ $(X, \mathcal{E})$를 가측공간이라고 하자. 아래의 조건을 만족하는 확장된 실수값 함수 $\nu\ :\ \mathcal{E} \rightarrow \overline{\mathbb{R}}$를 부호가 붙은 측도 , 부호 측도 라고 한다.$(a)$ $\nu ( \varnothing ) =0 $$ (b)$ $\pm \infty$ 중에서 많아야 1개까지만 $\nu$의 함숫</description>
    </item>
    
    <item>
      <title>슈트라센 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-strassen-algorithm/</link>
      <pubDate>Thu, 12 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-strassen-algorithm/</guid>
      <description>$k \in \mathbb{N}$ 에 대해 $n=2^{k}$ 이라고 하자. $A, B \in \mathbb{R}^{n \times n}$ 에 대해 조던 블록 행렬 표현을 사용해 다음과 같은 8개의 ${{n} \over {2}} \times {{n} \over {2}}$ 행렬 $A_{i}$, $B_{i}$ 들을 생각해보자. $$ AB= \begin{bmatrix} A_{1} &amp;amp; A_{2} \\ A_{3} &amp;amp; A_{4} \end{bmatrix} \begin{bmatrix} B_{1} &amp;amp; B_{2} \\ B_{3} &amp;amp; B_{4} \end{bmatrix} = \begin{bmatrix} C_{1} &amp;amp; C_{2} \\ C_{3} &amp;amp; C_{4} \end{bmatrix} = C $$ $C = AB$ 를 구하기 위해 다음을 계산한다. $$ P_{1} = A_{1} ( B_{2} - B_{4} ) \\ P_{2} = ( A_{1} + A_{2} ) B_{4} \\ P_{3} = ( A_{3} + A_{4} ) B_{1} \\ P_{4} = A_{4} ( B_{3} - B_{1} ) \\ P_{5} =</description>
    </item>
    
    <item>
      <title>측도의 일반적인 정의</title>
      <link>https://freshrimpsushi.github.io/posts/measure/</link>
      <pubDate>Thu, 12 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/measure/</guid>
      <description>르벡 측도보렐 측도부호 측도복소 측도측도$(\mathrm{measure})$ 가측 공간 $(X,\mathcal{E})$가 주어졌다고 하자. 아래의 세 조건을 만족하는 확장된 실수값을 갖는 함수 $\mu\ :\ \mathcal{E} \rightarrow\overline{\mathbb{R}}$를 측도라고 한다.$(a)$ $\mu ( \varnothing ) =0 $$ (b)$ $\mu(E) \ge 0,\quad \forall</description>
    </item>
    
    <item>
      <title>선분 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-segment-condition/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-segment-condition/</guid>
      <description>**선분 조건$(\mathrm{The\ segment\ condition})$ 열린 집합 $\Omega \subset \mathbb{R}^n$이 주어졌다고 하자. 모든 $x \in \mathrm{bdry}\Omega$에 대해서 아래의 조건을 만족하는 $x$의 근방 $U_x$와 영벡터가 아닌 $y_x$가 존재하면 $\Omega$가 선분 조건을 만족한다 고 한다. $$ z\in \overline{\Omega}\cap U_x \quad \Rightarrow \quad z+ty_x \in \Omega,\ 0&amp;lt;t&amp;lt;1 $$</description>
    </item>
    
    <item>
      <title>시간복잡도와 공간복잡도</title>
      <link>https://freshrimpsushi.github.io/posts/time-complexity-and-space-complexity/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-complexity-and-space-complexity/</guid>
      <description>주어진 문제를 풀 때의 걸리는 시간을 시간복잡도 , 메모리 소요를 공간복잡도 라고 한다.점근적 표기법은 이들을 표현하는데에 굉장히 유용한 수단이 된다. 시간복잡도에 대한 예시를 살펴보자.(0) 상수 시간 : $O(1) $$ n$ 에 관계없이 끝낼 수 있는 알고리즘으로, 사실상 시간이 걸리지 않는 것이다. 가령 $\mathbb{x} = [4,3,8,-1,-9,0,5,7,2,6]$ 에서 세번째 원소를 찾는 알고리즘은 $\mathbb{x}$ 가 어떻게 생</description>
    </item>
    
    <item>
      <title>R 에서 가치 모형으로 시계열 분석 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-garch-model-in-r/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-garch-model-in-r/</guid>
      <description>가치 모형 보러가기 * 하단에 예제코드 전체가 있다.가치 모델은 아치 이펙트를 설명하는 유용한 수단으로써 분석 절차 자체는 아르마 모델과 흡사하다.위의 그래프는 내장데이터 EuStockMarkets에서 DAX만 뽑아내서 그린 것으로, 1991년부터 1999년까지 독일 DAX지수를 나타낸다.리턴의 제곱을 보면 거의 확실하게 아치 이펙트</description>
    </item>
    
    <item>
      <title>약한 콘 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-weak-con-condition/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-weak-con-condition/</guid>
      <description>약한 콘 조건$(\mathrm{The\ weak\ cone\ condition})$ 열린 집합 $\Omega \subset \mathbb{R}^n$와 임의의 점 $x \in \Omega$가 주어졌다고 하자. $R(x)$를 $x$에서부터 $y \in \Omega$까지의 선분이 다시 $\Omega$안에 포함되도록 하는 $y$들의 집합이라고 하자. 즉 $R(x)$는 $x$에서부터 시작되는 $\Omeg</description>
    </item>
    
    <item>
      <title>가우스 정수</title>
      <link>https://freshrimpsushi.github.io/posts/gaussian-integer/</link>
      <pubDate>Sat, 31 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gaussian-integer/</guid>
      <description>$\mathbb{Z} [i] := \left\{ a + i b : a, b \in \mathbb{Z} \right\} $ 를 가우시안 링Gaussian Ring 이라고 하고, 그 원소를 가우시안 인티저 라고 한다.$i$ 는 이차방정식 $x^2 +1 = 0$ 의 복소근으로써, $\mathbb{Z} [i]$ 은 인티저 링 $\mathbb{Z}$ 의 심플 익스텐젼이 된다. 마치 실수체 $\mathbb{R}$ 이 복소수체 $\mathbb{C} = \mathbb{R} [i]$ 로 확장되는 것과 비슷한데, 그 이치 역시 크게 다르지 않다. 정수를 논함에 있어서는 무리수조차도 금기</description>
    </item>
    
    <item>
      <title>R 에서 병렬처리하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-r/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-r/</guid>
      <description>R 이 속도 때문에 쓰는 언어는 아니지만, 빠른 속도가 필요할 때도 분명히 있을 것이다. 코드를 깔끔하게 잘 짜더라도 너무 오래 걸린다면 보통 병렬처리나 GPU를 동원하게 된다. 언뜻 생각했을 때 R 에서 병렬처리를 할 일이 뭐 있나 싶겠지만, 빅데이터를 다루게 되거나 규모가 큰 시뮬레이션을 하게 된다면 병렬처리가 특히 유용한 수단이 된다. 오히려 R 이야말로</description>
    </item>
    
    <item>
      <title>동적 회귀 모형</title>
      <link>https://freshrimpsushi.github.io/posts/dynamic-regression-model/</link>
      <pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamic-regression-model/</guid>
      <description>동적 회귀 모형 이란 쉽게 말해 아리마 모형에 회귀 모형을 합친 모형이다. 사실 이쯤되면 말보다는 수식이 편한데, 종속변수로 분석할 시계열 데이터가 $\left\{ y_{t} \right\}$ 이라고 하고 이 데이터를 설명할 독립변수로써 또 다른 시계열 데이터 $\left\{ x_{t} \right\}$ 가 있다고 해보자. $x_{t}$ 가 $y_{t}$ 를 잘 설명한다면 그것 자체로도 시계열 회귀분석이 가능하고, 그것으로도 설명되지 않는 부분 역시 시계</description>
    </item>
    
    <item>
      <title>제피멩코 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/jefimenko-equation/</link>
      <pubDate>Wed, 28 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jefimenko-equation/</guid>
      <description>제피멩코 방정식$(\mathrm{ Jefimenko\ equation})$ 연속전하분포가 시간에 따라 변할 때의 전기장은 $$ \mathbf{E} (\mathbf{r},t)=\frac{1}{4\pi \epsilon_0} \int \left[ \frac{ \rho(\mathbf{r}&#39;, t_r) }{\eta ^2} \hat{\boldsymbol{\eta}} + \frac{ \dot{\rho}(\mathbf{r}&#39;, t_r)}{c\eta}\hat{\boldsymbol{\eta}}-\frac{\dot{\mathbf{J}}(\mathbf{r}&#39;,t_r) }{c^2 \eta} \right]d\tau&#39; $$ 연속전류분포가 시간에 따라 변할 때의 자기장은 $$ \mathbf{B}( \mathbf{r}, t) = \dfrac{\mu_0}{4\pi} \int \left[ \frac{\mathbf{J}(\mathbf{r}&#39;,t_r)}{\eta^2} + \dfrac{ \dot{\mathbf{J}}(\mathbf{r}&#39;, t_r) } {c\eta} \right]\times \hat{\boldsymbol{\eta}}d\tau&#39; $$ 이때 $t_r$은 지연시각, $\boldsymbol{\eta}$는 분리벡터이다.전기장과 자기장은 아래의 식으</description>
    </item>
    
    <item>
      <title>시계열분석의 이노베이티브 아웃라이어</title>
      <link>https://freshrimpsushi.github.io/posts/innovative-outlier/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/innovative-outlier/</guid>
      <description>하단에 예제코드 전체가 있다.위의 그래프에서 2001년 9월에 굉장히 큰 아웃라이어를 찾을 수 있다. 그러나 애디티브 아웃라이어와 달리 그 후에도 계속해서 영향을 미치고 있다. 여객기의 이용자 수는 계절성을 가지고 꾸준히 증가하고 있었는데, 911테러의 공포가 이용자 수 자체를 팍 줄여버린 것으로 해석할 수 있다. 이렇게 분석의 판도 자체를 바꾸는 아</description>
    </item>
    
    <item>
      <title>전위와 전자기장</title>
      <link>https://freshrimpsushi.github.io/posts/potential-and-electromagnetic-field/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/potential-and-electromagnetic-field/</guid>
      <description>**맥스웰 방정식$(\mathrm{Maxwell&amp;rsquo;s\ equations})$ $(a) \quad \nabla \cdot \mathbf{E}=\dfrac{1}{\epsilon_0}\rho $ **가우스 법칙 $(b) \quad \nabla \cdot \mathbf{B}=0$ (자기장에 대한 가우스 법칙)$(c) \quad \nabla \times \mathbf{E} = -\dfrac{\partial \mathbf{B}}{\partial t}$ **패러데이 법칙 $(d) \quad \nabla \times \mathbf{B} = \mu_0 \mathbf{J}+\mu_0\epsilon_0\dfrac{\partial \mathbf{E}}{\partial t} $ 앙페르 법칙 전위 형식 시간에 따라 전하, 전류분포가 변할 때의 전기장 및 자기장은 $$ \mathbf{E}= -\nabla V-\frac{\partial \mathbf{A}}{\partial t} $$ $$ \mathbf{B} = \nabla \times \mathbf{A} $$ 전하밀도 $\rho(\mathbf{r},</description>
    </item>
    
    <item>
      <title>인티그럴 도메인의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-in-integral-domain/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-in-integral-domain/</guid>
      <description>인티그럴 도메인 $D$ 와 모든 $\alpha , \beta \in D$ 에 대해 다음의 조건을 만족하는 함수 $N : D \to \mathbb{Z}$ 를 승법적 놈Multiplicative Norm 이라고 정의한다.(i) $N (\alpha) = 0 \iff \alpha = 0 $(ii) $N ( \alpha \beta ) = N ( \alpha ) N ( \beta )$물론 놈이라고 하면 보통 $N (\alpha) \ge 0$ 이 가정되며, $\alpha \ne 0$ 에 대해서 $\nu ( \alpha) = N ( \alpha)$ 와 같은 조건이 추가되면서 승법적 놈인 동시에 유클리드 놈이</description>
    </item>
    
    <item>
      <title>물리학 부록</title>
      <link>https://freshrimpsushi.github.io/posts/1257/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1257/</guid>
      <description>**부록 1 $$ \mathbb{A} = \begin{pmatrix} e^{-ika} &amp;amp; e^{ika} \\ ike^{-ika} &amp;amp; -ike^{ika} \end{pmatrix},\quad \mathbb{B} = \begin{pmatrix} e^{\kappa a} &amp;amp; e^{-\kappa a} \\ \kappa e^{\kappa a} &amp;amp; -\kappa e^{-\kappa a} \end{pmatrix} $$ 여인수 전개로 위 두 행렬의 역행렬을 구하면 $$ \begin{eqnarray*} \mathbb{A}^{-1} &amp;amp;=&amp;amp; \frac{1}{|\mathbb{A}|} \mathrm{adj}(A) \\ &amp;amp;=&amp;amp; \frac{1}{-ik -ik} \begin{pmatrix} -ike^{ika} &amp;amp; -ike^{-ika} \\ -e^{ika} &amp;amp; e^{-ika} \end{pmatrix}^T \\ &amp;amp;=&amp;amp; \frac{1}{-2ik} \begin{pmatrix} -ike^{ika} &amp;amp; -e^{ika} \\ -ike^{-ika} &amp;amp; e^{-ika} \end{pmatrix} \\ &amp;amp;=&amp;amp; \frac{1}{2} \begin{pmatrix} e^{ika} &amp;amp; \frac{1}{ik}e^{ika} \\ e^{-ika} &amp;amp; \frac{-1}{ik} e^{-ika} \end{pmatrix} \end{eqnarray*} $$ $$ \begin{eqnarray*} \mathbb{B}^{-1} &amp;amp;=&amp;amp; \frac{1}{|\mathbb{B}|} \mathrm{adj}(B) \\ &amp;amp;=&amp;amp; \frac{1}{-\kappa -\kappa } \begin{pmatrix} -\kappa e^{-\kappa a} &amp;amp; -\kappa e^{\kappa a} \\ -e^{-\kappa a} &amp;amp; e^{\kappa a} \end{pmatrix}^T \\ &amp;amp;=&amp;amp; \frac{1}{-2\kappa } \begin{pmatrix} -\kappa e^{-\kappa a} &amp;amp; -e^{-\kappa a} \\ -\kappa e^{\kappa a} &amp;amp; e^{\kappa a} \end{pmatrix} \\ &amp;amp;=&amp;amp; \frac{1}{2} \begin{pmatrix} e^{-\kappa a}</description>
    </item>
    
    <item>
      <title>시계열분석의 애디티브 아웃라이어</title>
      <link>https://freshrimpsushi.github.io/posts/additive-outlier/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/additive-outlier/</guid>
      <description>하단에 예제코드 전체가 있다.위의 그래프에서 가장 먼저 눈에 띄는 지점은 바로 2015년 2월 근처에 있는 엄청난 아웃라이어다. 이렇듯 극심하게 다른 값을 가지면 분석에 악영향이 있을 수밖에 없다. 다행스러운 건 아주 잠깐, 말 그대로 한 순간의 아웃라이어로 그쳤다는 것이다. 이렇듯 데이터의 등락 자체를 바꾸지는 않는 아웃라이어를 애디티브 아웃라이어</description>
    </item>
    
    <item>
      <title>장벽 퍼텐셜에 대한 슈뢰딩거 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-schr%C3%B6dinger-equation-for-barrier-potential/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-schr%C3%B6dinger-equation-for-barrier-potential/</guid>
      <description>위 그림과 같이 입자의 퍼텐셜이 벽 모양으로 생겼을 때 어떻게 운동하는지 알아보자. 퍼텐셜 $U$는 $$ U(x) = \begin{cases} 0 &amp;amp; x&amp;lt;-a \\ U_0 &amp;amp; -a &amp;lt; x &amp;lt;a \\ 0 &amp;amp;a&amp;lt;x \end{cases} $$ 퍼텐셜이 $U(x)$일 때의 시간에 무관한 슈뢰딩거 방정식은 $$ \dfrac{d^2 u(x)}{dx^2}+\frac{2m}{\hbar ^2} \Big[ E-U(x) \Big]u(x)=0 $$ **1. $E&amp;lt;0$ 에너지가 퍼텐셜보다 작으면 해가 존재하지 않으므로 고려할 필요 없다.■ **2. $0 &amp;lt; E &amp;lt; U_0$ Part 2-1. $x&amp;lt;-a$ 이 영역에서 시간에 무관한 슈</description>
    </item>
    
    <item>
      <title>확장된 실수값을 갖는 함수가 가측함수가 될 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/1255/</link>
      <pubDate>Sat, 24 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1255/</guid>
      <description>가층공간 $(X,\mathcal{E})$과 확장된 실수값을 갖는 $f\ :\ X\rightarrow \overline{\mathbb{R}}$에 대하여 아래의 식이 성립한다. $$ f \ \mathrm{\ is\ measurable} \iff \begin{cases} (a)\ \left\{ x \in X \ :\ f(x)=-\infty \right\} \in \mathcal{E} \\ (b)\ \left\{ x \in X\ :\ \alpha &amp;lt; f(x) &amp;lt; +\infty \right\} \in \mathcal{E}\quad (\forall \alpha \in \mathbb{R}) \end{cases} $$ 위의 정리는 확장된 실수값을 갖는 함수가 가측인지를 판별할 때, 확장된 실수값을 갖는 가측함수</description>
    </item>
    
    <item>
      <title>스텝 함수와 펄스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/step-function-and-pulse-function/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/step-function-and-pulse-function/</guid>
      <description>1. 다음과 같이 정의된 $S_{t}^{(T)}$ 를 **스텝 함수** 라고 한다. $$ S_{t}^{(T)} := \begin{cases} 1 &amp;amp; , t \le T \\ 0 &amp;amp; , \text{otherwise} \end{cases} $$ **2.** 다음과 같이 정의된 $P_{t}^{(T)}$ 를 **펄스 함수** 라고 한다. $$ \begin{eqnarray*} P_{t}^{(T)} &amp;amp;:=&amp;amp; \nabla S_{t}^{(T)} \\ &amp;amp;=&amp;amp; S_{t}^{(T)} - S_{t-1}^{(T)} \end{eqnarray*} $$ 스텝 함수와 펄스 함수는 개입 분석에 쓰이는 수식을 나타내기에 유용한 함수들로써, 그 자체의 성질은 크게 의미가 없다. 스텝 함수는 말 그대로 그래프의 개형이 계단처럼 생겨</description>
    </item>
    
    <item>
      <title>R 에서 코드 실행 시간 재는 법 벤치마크하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/1246/</link>
      <pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1246/</guid>
      <description>매트랩R 은 분명 통계 분석에 특화되어 있는 프로그래밍 언어지만, 모든 언어가 그러하듯 속도에 관심이 없는 것은 아니다. 속도가 강점이 아니라고 해도 벤치마킹은 할 수 있어야한다. R 에서는 간단하게도 코드 전문을 system.time({})에 넣어서 시간을 잴 수 있다.다음은 에라토스테네스의 체를 R 로 구현하고 $2*10^{5}$ 이하의 홀수를 30개 뽑아 소수</description>
    </item>
    
    <item>
      <title>확장된 실수 체계</title>
      <link>https://freshrimpsushi.github.io/posts/extended-real-number-system/</link>
      <pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/extended-real-number-system/</guid>
      <description>**확장된 실수 체계$(\mathrm{extended\ real\ nubmer\ system})$ 실해석학, 측도론에서는 종종 편의를 위해 **실수 ** $\mathbb{R}$ 대신 확장된 실수 체계 를 사용한다. 확장된 실수 체계는 다음과 같이 정의한다. $$ \overline{ \mathbb{R} } := \mathbb{R} \cup \left\{ -\infty, +\infty\right\} $$ 간단히 말해 양의 무한대와 음의 무한대를 하나의 숫자로 취급해 실수 집합에 포함한 것이다. 확장된 실수 체계 안에서의 대소</description>
    </item>
    
    <item>
      <title>개입 분석</title>
      <link>https://freshrimpsushi.github.io/posts/intervention-analysis/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/intervention-analysis/</guid>
      <description>위 그래프는 실제 2015년 서울의 미세먼지 농도를 나타낸 시계열 데이터다. 누가 보더라도 가장 먼저 눈에 띄는 것은 50번째쯤, 그러니까 2월 말에 미세먼지 농도가 500을 넘긴 날이 있다는 점일 것이다. 데이터를 다루는데에 어느정도 익숙한 사람이라면 가장 먼저 잘못 관측된 것이 아닐까 의심하겠지만, 놀랍게도 실제로 일어난 일이었다. 아예 이 날에 대</description>
    </item>
    
    <item>
      <title>보렐 시그마-대수 보렐 가측 공간</title>
      <link>https://freshrimpsushi.github.io/posts/borel-sigma-algebra-borel-measurable-space/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/borel-sigma-algebra-borel-measurable-space/</guid>
      <description>실수 공간에서의 보렐 집합**$\sigma$-대수$(\mathrm{sigma} $$ \mathrm{-algebra}$, 시그마-알지브라, 시그마-필드$)$ 집합 $X$가 주어졌다고 하자. $\mathcal{P}(X)$는 $X$의 멱집합이다. 아래의 세 조건을 만족하는 $X$의 부분집합들의 집합 $\mathcal{E} \subset \mathcal{P}(X)$를 $\sigma$</description>
    </item>
    
    <item>
      <title>R 에서 Ts 함수의 start end 옵션과 window 함수에서 startend 옵션의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/1242/</link>
      <pubDate>Tue, 20 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1242/</guid>
      <description>R 로 [[시계열 데이터]]를 다루다보면 ts() 함수와 window() 함수를 자주 사용하게 된다. ts()는 R 이 받아들일 수 있도록 시계열 데이터를 만들 때 쓰고, window()는 시계열 데이터의 일부를 추출하는데 쓰인다.두 함수 모두 start, end를 옵션으로 갖는데, 그 차이는 다음과 같다.&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20190807_135454.png&amp;rdquo; height=&amp;ldquo;196&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/994F68425D4A5A8E0B&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;458&amp;rdquo;/&amp;gt;ts() : 내가 인덱스를 주기 위한 옵션이다.s</description>
    </item>
    
    <item>
      <title>시계열에서의 허위 상관관계</title>
      <link>https://freshrimpsushi.github.io/posts/spurious-correlation/</link>
      <pubDate>Mon, 19 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spurious-correlation/</guid>
      <description>허위 상관관계 는 두 데이터가 그럴싸한 상관관계를 가지는 것 같아 보이지만 실제로는 그렇지 않은 관계를 말한다. 다음의 예시를 통해 알아보자. 위와 같이 두 가지 시계열 데이터가 주어져 있다고 하자. 언뜻 보기에 두 시계열은 강력한 상관관계를 가질 것만 같이 보인다. 시간에 따라 조금씩 증가하는 트렌드을 포함해서 계절성을 포함한 등락 패턴이 매우 흡사하기 때</description>
    </item>
    
    <item>
      <title>R 에서 색 테두리 있는 점 찍는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-colorize-scatter-plot/</link>
      <pubDate>Sun, 18 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-colorize-scatter-plot/</guid>
      <description>점 도표에서 테두리의 색을 바꾸거나 내부를 칠하기 위해서는 다음의 옵션들을 바꿔주면 된다 :pch : 심볼을 바꿔서 색을 칠한다. 21번부터 25번까지를 사용하면 된다.bg : 백그라운드 컬러로써, 내부에 칠해지는 색을 결정한다. 위 그림에선 연두색이다.col : 심볼 그 자체의 컬러로써, 실제로는 테두리에 해당한다. 위 그림에선 빨간색이다. set.seed(150421) win.graph(4,4) plot(rnorm(10),</description>
    </item>
    
    <item>
      <title>매트랩에서 여러 그림 한 페이지에 출력하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1247/</link>
      <pubDate>Sat, 17 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1247/</guid>
      <description>subplot()함수를 사용하면 여러 그림을 한 페이지에 출력할 수 있다. 첫번째, 두번째 변수는 각각 이미지를 출력할 바둑판의 행과 열을 나타내며 그림을 어떤 모양으로 배치할지를 결정한다. 세번째 변수는 해당그림을 몇 번에 배치할지 결정한다.아래는 코드와 실제로 출력된 결과이다. X1=Phantom(); X2=radon(X1); X3=fft(X2); X4=iradon(X2,0:179); subplot(2,2,1) imagesc(X1) title(&amp;#34;Phantom&amp;#34;); subplot(2,2,2) imagesc(X2) title(&amp;#34;radon&amp;#34;); subplot(2,2,3) imagesc(abs(X3)) title(&amp;#34;fft&amp;#34;); subplot(2,2,4) imagesc(X4) title(&amp;#34;iradon&amp;#34;);</description>
    </item>
    
    <item>
      <title>사전백화</title>
      <link>https://freshrimpsushi.github.io/posts/prewhitening/</link>
      <pubDate>Sat, 17 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prewhitening/</guid>
      <description>하단에 예제코드 전체가 있다.* 수학, 통계적인 기초가 부족한 비전공자는 밑줄 그어진 부분만 읽어도 상관 없다.**사전백화**Prewhitening 란 CCF를 계산할 때 시계열을 백색잡음으로 만들어 두 데이터 간의 상관관계를 더욱 정확하게 파악하는 방법이다. 가능하다면 이것이 어떻게 가능한지 수식적으로도 완전히 이해하는 것을 추천하는</description>
    </item>
    
    <item>
      <title>R 에서 파이프 오퍼레이터 %gt;% 사용하는 법 %gt;%</title>
      <link>https://freshrimpsushi.github.io/posts/in-r/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/in-r/</guid>
      <description>R 에서 %&amp;gt;%은 파이프 연산자Pipe Operater 로써, 다른 연산자가 모두 그러하듯 이항연산을 한다. 파이프 연산자는 이름 그대로 어떤 값들이 파이프를 통과하는 것처럼 함수와 함수들을 타고다닐 수 있게 해준다. 백마디 말보다 다음의 예시가 더 도움이 될 것이다.위의 예시는 $1$ 부터 $10$ 까지의 제곱근을 구하고 거기에 로그를 취한 뒤 그 중에서 중위수를 구하는</description>
    </item>
    
    <item>
      <title>디리클레 경계 조건이 주어진 열방정식에 대한 초기값 문제의 수치해석적 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/790/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/790/</guid>
      <description>대수적 풀이 보러가기$\begin{cases} u_{t} = \gamma u_{xx} \\ u(t,0) = u(t,l) = 0 \\ u(0,x) = f(x) \end{cases}$주어진 문제는 대수적 풀이가 있을 정도로 쉽고 간단하지만, 미분방정식을 푸는 방법으로써의 수치해석을 왜 배우는지 명쾌하게 알려주는 예시가 되기도 한다. 단순히 $y&#39; = f(x,y)$ 꼴의 미분방정식을 푸는 게 편미분방정식의 풀이로도 이어지는 것이다</description>
    </item>
    
    <item>
      <title>룽게-쿠타 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/runge-kutta-method/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/runge-kutta-method/</guid>
      <description>$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b $ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} = Y_{0}$ 에 대해 $$ \displaystyle y_{n+1} = y_{n-1} + h \sum_{j=1}^{p} \gamma_{j} V_{j} $$ **룽게-쿠타 메소드** 는 아담스 메소드처럼 여러가지 형태를 가지며</description>
    </item>
    
    <item>
      <title>A-스테이블</title>
      <link>https://freshrimpsushi.github.io/posts/a-stable/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/a-stable/</guid>
      <description>미드포인트 메소드를 비롯한 멀티스텝 메소드는 $h$ 가 충분히 작지 않을 때 패러사이틱 솔루션이 있을 수 있다. 충분히 작지 않다는 건 $ y&#39; = \lambda y$ 와 같은 문제가 있을 때 $| 1 + h \lambda| &amp;lt;1$ 과 같은 조건을 만족하지 못하는 등의 경우를 말한다.$z : = h \lambda \in \mathbb{C}$ 라고 할 때 위의 조건을 복소평면 상에 나타내보면 아래의 그림과 같다.$z$ 이 이 영역에 속하지 못하면 메소드</description>
    </item>
    
    <item>
      <title>계단 함수 퍼텐셜에 대한 슈뢰딩거 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-schr%C3%B6dinger-equation-for-step-function-potential/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-schr%C3%B6dinger-equation-for-step-function-potential/</guid>
      <description>위 그림과 같이 입자의 퍼텐셜이 계단 함수 모양으로 생겼을 때 어떻게 운동하는지 알아보자. 퍼텐셜 $U$는 $$ U(x) = \begin{cases} 0 &amp;amp; x&amp;lt;0 \\ U_0 &amp;amp; x&amp;gt;0 \end{cases} $$ 퍼텐셜이 $U(x)$일 때의 시간에 무관한 슈뢰딩거 방정식은 $$ \dfrac{d^2 u(x)}{dx^2}+\frac{2m}{\hbar ^2} \Big[ E-U(x) \Big]u(x)=0 $$ **1. $E&amp;lt;0$ 에너지가 퍼텐셜보다 작으면 해가 존재하지 않으므로 고려할 필요 없다.■ 2. $0 &amp;lt; E &amp;lt; U_0$ Part 2-1. $x&amp;lt;0$ 이 영역에서 시간에 무관한 슈뢰딩거</description>
    </item>
    
    <item>
      <title>교차상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/ccf-cross-correlation-functon/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ccf-cross-correlation-functon/</guid>
      <description>ACF : 자기상관함수PACF : 편자기상관함수EACF : 확장자기상관함수$\left\{ X_{t} \right\}_{t=1}^{n} $, $\left\{ Y_{t} \right\}_{t=1}^{n} $ 이 확률과정이라고 하자.1. 다음과 같이 정의된 $\rho_{k}$ 를 시차 $k$ 의 교차상관함수라고 한다. $$ \rho_{k} (X,Y) := \text{cor} \left( X_{t} , Y_{t-k} \right) = \text{cor} \left( X_{t+k} , Y_{t} \right) $$ 2. 다음과 같이 정의된 $r_{k}$ 를 시차 $k$ 의 표본교차상관함수라고 한다. $$ r_{k} := {{ \sum \left( X_{t} - \overline{X} \right) \left( Y_{t-k} - \overline{Y} \right) } \over {</description>
    </item>
    
    <item>
      <title>Lp 공간이 균등하게 볼록하고 반사적임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-lp-space-is-uniformly-convex-and-reflexive/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-lp-space-is-uniformly-convex-and-reflexive/</guid>
      <description>$1&amp;lt;p &amp;lt;\infty$라고 하자. 그러면 ${L}^ p$ 공간은 균등하게 볼록하고 반사적이다.균등 볼록의 정의와 클락슨 부등식을 이용해서 증명할 수 있다. 클락슨 부등식 덕분에 쉽고 짧게 증명이 끝난다. 필살기 같은 느낌임.**균등하게 볼록$(\mathrm{uniformly\ convex})$ 놈 공간 $X$상의 놈 $| \cdot |$이 아래의 조건을 만족하면 놈과 놈</description>
    </item>
    
    <item>
      <title>R 에서 오퍼레이터 %% 정의하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-define-binary-operator-in-r/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-define-binary-operator-in-r/</guid>
      <description>R 에서는 함수를 정의할 때 아예 이항연산자로 정의할 수가 있다. 이미 R 에서 기본적으로 정의된 나눗셈의 나머지 %%, 몫 %/%, 내적 %*%, %o%나 포함관계 %in%, 그리고 파이프 연산자 %&amp;gt;% 등도 이러한 이항연산자에 속한다.가령 파이썬과 같은 언어에서는 문자열끼리 덧셈을 하면 문자열이 연결되기 때문에 아주 편한데, R 은 이에 비해서는 다소 불편한 감이 있다. 이를 해결하</description>
    </item>
    
    <item>
      <title>일관성을 가지는 멀티스텝 메소드의 수렴성과 루트 컨디션</title>
      <link>https://freshrimpsushi.github.io/posts/754/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/754/</guid>
      <description>멀티스텝 메소드가 일관성을 가진다고 하자.메소드는 수렴성을 가진다 $\iff$ 메소드는 루트 컨디션을 만족 시킨다폐구간 $[x_{0} , b]$ 에 대해 $h$ 를 단위로 잘라서 노드 포인트를 만들 때, $x_{0} \le x_{1} \le \cdots \le x_{N(h) -1} \le x_{N(h) } \le b$ 라고 하자. 여기서 $N(h)$ 는 $h$ 에 따라 변하는 마지막 노드 포인트의 인덱스를 나타낸다.메소드가 수렴성을 가진다는 것은 $h \to 0$ 일 때 $\displaystyle \eta (h) : = \max_{0 \le n \le p}</description>
    </item>
    
    <item>
      <title>시계열 회귀 분석</title>
      <link>https://freshrimpsushi.github.io/posts/time-series-regression-analysis/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-series-regression-analysis/</guid>
      <description>시계열 회귀 분석 이란 말 그대로 시계열 데이터로 회귀분석하는 기법을 말한다. 원래 회귀분석 자체가 시계열 데이터를 다루는데 있어서 적합하지 않은 것은 사실이지만, 그럼에도 불구하고 복수의 시계열 데이터를 다룰 때는 회귀분석의 아이디어와 툴을 빌리는 것이 좋을 때가 있다.가령 위와 같이 두 종류의 데이터 x와 y가 주어져있다고 하자. 물론 두 데이터의 개</description>
    </item>
    
    <item>
      <title>파동함수의 반사와 투과</title>
      <link>https://freshrimpsushi.github.io/posts/reflection-and-transmission-of-wave-function/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reflection-and-transmission-of-wave-function/</guid>
      <description>**반사계수와 투과계수$(\mathrm{Reflection\ coefficient})$ 파동 함수의 반사계수(반사율)와 투과계수(투과율)는 다음과 같이 나타낼 수 있다. $$ R=\left| \frac{j_{ref}}{j_{inc}} \right|,\quad T=\left| \frac{j_{trans}}{j_{inc}}\right| $$ 이때 $j$는 확률 흐름이다. $inc$는 입사$(\mathrm{incident})$를 의미한다. $R$, $ref$는 반사$(\mathrm{reflec</description>
    </item>
    
    <item>
      <title>륭-박스 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/ljung-box-test/</link>
      <pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ljung-box-test/</guid>
      <description>R 에서 륭-박스 테스트 하는 법시계열 분석으로 얻은 아르마 모형 $ARMA(p,q)$ 을 $M$ 이라고 하자.$H_{0}$ : $M$ 은 적합하다.$H_{1}$ : $M$ 은 적합하지 않다.**륭-박스 테스트** 는 **LBQ** 라고도 줄여부르기도 하며, 아리마 모형의 적합성을 판별하는 검정이다.1970년 박스Box와 피어스Pierce는 아리마 모형으로 얻은 잔차들의 sACF $\hat{r}_{1} , \cdots</description>
    </item>
    
    <item>
      <title>확률 흐름 밀도</title>
      <link>https://freshrimpsushi.github.io/posts/probability-current-dsnsity/</link>
      <pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-current-dsnsity/</guid>
      <description>**확률 흐름 밀도$(\mathrm{probability\ current\ dsnsity})$ 파동함수 $\psi (x, t)$의 확률 흐름 밀도는 아래와 같이 정의된다. $$ j(x,t):=\frac{\hbar}{2mi}\left( \psi^{ * }\dfrac{\partial \psi}{\partial x} - \psi\frac{\partial \psi^{ * }}{\partial x}\right) $$ 확률 흐름이라고도 한다. 유도 확률 흐름 밀도는 자유 입자의 슈뢰딩거 방정식으로부터 이끌어낼 수 있다. $$ i \hbar \frac{\partial \psi(x,t)}{\partial t} = -\frac{\hbar^2}{2m}\frac{\partial ^2 \psi(x,t)}{\partial x^2} \quad \cdots (1) $$ $(1)$의 양변에 $\psi^{ * }$를 곱하면 $$</description>
    </item>
    
    <item>
      <title>아리마 모형에 대한 잔차분석</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-tsdiag-plots-in-r/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-tsdiag-plots-in-r/</guid>
      <description>회귀분석과 마찬가지로 시계열 분석 역시 잔차분석을 한다. 아리마 모형의 가정에 따르면 잔차는 모두 백색잡음이므로 선형성, 등분산성, 독립성, 정규성을 따르는지 확인은 할 것이다. 회귀분석과 비교하자면 전반적으로 그렇게까지 엄격하지는 않으나, 독립성 하나만큼은 철저하게 체크한다. 애초에 시계열분석 자체가 자기상관성을 파악하기 위한 것인데</description>
    </item>
    
    <item>
      <title>양자역학에서의 그람-슈미트 직교화 과정</title>
      <link>https://freshrimpsushi.github.io/posts/gram-schmidt-orthogonalization-procedure/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gram-schmidt-orthogonalization-procedure/</guid>
      <description>수학에서의 그람-슈미트 직교화**그람-슈미트 직교화 과정$(\mathrm{Gram-schmidt\ orthogonalization\ procedure})$ $A$를 임의의 에르미트 연산자라 하자. 그리고 규격화된 시간에 무관한 두 1차원 파동함수 $u_1$, $u_2$가 축퇴돼있다고 하자. $$ Au_1=au_1 $$ $$ Au_2=au_2 $$ 이 때 $u_1$과 직교하는 새로운 고유함수를 구하는 방법을 그람-슈미트 직교화 과정</description>
    </item>
    
    <item>
      <title>더빈-왓슨 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/durbin-watson-test/</link>
      <pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/durbin-watson-test/</guid>
      <description>개요 회귀분석을 한 이후의 잔차 $\left\{ e_{t} \right\}_{t=1}^{n} $ 가 주어져있다고 하고 $e_{t} := \rho e_{t-1} + \nu_{t}$ 이라 하자. $H_{0}$ : $\rho = 0$ 즉, 잔차끼리 자기상관성을 가지지 않는다. $H_{1}$ : $\rho \ne 0$ 즉, 잔차끼리 자기상관성을 가진다. 더빈-왓슨 테스트 는 회귀분석 후 잔차의 독립성을 확인할 때 쓰이는 테스트로써, 잔차끼리 자기상관성이 있는지 없는지를 판단한다. 검정통계량은 $$ d := {{ \sum_{t=2}^{n} \left(</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 예측하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-predict-with-arima-model-in-r/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-predict-with-arima-model-in-r/</guid>
      <description>하단에 예제코드 전체가 있다.R 내장데이터 UKDriverDeaths는 1969년부터 1984년까지 영국 월별 운전자 사상자에 대한 데이터다. 언뜻 보아도 계절형 아리마 모형을 따르고, 실제로 모형을 찾아내는것은 별로 어렵지 않다.그러나 최종적으로 얻은 모형으로 식을 직접 써서 계산하는 것은 무척 손이 많이 가고 복잡한 일이다. 따라서 predict() 함</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드의 수렴성과 오차</title>
      <link>https://freshrimpsushi.github.io/posts/698/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/698/</guid>
      <description>초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) )= ( Y_{0} , \cdots , Y_{p} ) \end{cases}$ 에 대해 멀티스텝 메소드 $\displaystyle y_{n+1} = \sum_{j=0}^{p} a_{j} y_{n-j} + h \sum_{j = -1}^{p} b_{j} f (x_{n-j} , y_{n-j} ) $ 가 일관성을 가지고, **초기 오차** $\displaystyle \eta (h) : = \max_{ 0 \le i \le p} | Y (x_{i} ) - y_{h} (x_{i} ) | $ 가 $\displaystyle \lim_{ h \to 0} \eta (h) = 0$ 를 만족하고, $j = 0, 1, \cdots , p$ 에 대해 $a_{j} \ge 0$ 이고 $f$ 가 립시츠 조건을 만족하면 메소드는 수렴하고 적절한 상수 $c_{1}</description>
    </item>
    
    <item>
      <title>소볼레프 공간은 바나흐 공간임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-sobolev-space-is-banach-space/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-sobolev-space-is-banach-space/</guid>
      <description>소볼레프 공간 $W^{m,\ p}$는 바나흐 공간이다.놈이 정의되고 완비 인 공간을 바나흐 공간이라 한다. 소볼레프 공간을 정의할 때 놈도 같이 정의했으므로 완비인 것만 확인하면 된다. 따라서 $W^{m,\ p}$안의 코시 수열이 $W^{m,\ p}$안에서 수렴함을 보이면 된다. 증명은 어렵지 않은 편이다. $W^{m,\ p}(\Omega):=\left\{ u \in L^p(\Omega)\ :\ D^\alpha u \in L^p(\Omega),\ 0\le |\alpha | \le m \right\}$. 이때 $D^\alpha u$는 $u$의 약한 도함수이다</description>
    </item>
    
    <item>
      <title>소볼레프 놈과 소볼레프 공간</title>
      <link>https://freshrimpsushi.github.io/posts/sobolev-norms-and-sobolev-spaces/</link>
      <pubDate>Tue, 30 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sobolev-norms-and-sobolev-spaces/</guid>
      <description>$L^p$ 공간은 유용한 성질을 가지는 중요한 공간이지만 미분 방정식을 풀기에는 조금 부족하다. $u \in L^p$라는 사실을 알아도 $D^{\alpha}u$가 $L^p$ 공간에 속하는지 아닌지에 대해서는 여전히 알 수 없기 때문이다. 따라서 $L^p$ 공간 보다 더 좋은 공간에 대해서 생각할 필요가 있고 그것이 바로 소볼레프 공간 이다. **소볼레프 놈$(\mathrm{</description>
    </item>
    
    <item>
      <title>입실론-델타 논법</title>
      <link>https://freshrimpsushi.github.io/posts/epsilon-delta-argument/</link>
      <pubDate>Tue, 30 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/epsilon-delta-argument/</guid>
      <description>정의 $I$ 가 $a \in \mathbb{R}$ 를 포함하는 구간이고, $f$ 는 $I \setminus \left\{ a \right\}$ 에서는 정의된 함수라고 하자. 모든 $\epsilon &amp;gt; 0$ 에 대해 $$ 0 &amp;lt; | x - a | &amp;lt; \delta \implies | f(x) - L | &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $x \to a$ 일 때 $f(x)$ 가 $L \in \mathbb{R}$ 로 수렴한다 고 한다. 입실론-델타 논법의 이름은 보다시피 정의에 등장하는 입실론 $\varepsilon$ 과 델타 $\delta$ 에서 따온 것이다. 이는 &amp;lsquo;해석학의 아버지&amp;</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 얻은 시계열 분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-arima-model-summary-in-r/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-arima-model-summary-in-r/</guid>
      <description>하단에 예제코드 전체가 있다.* 수학, 통계적인 기초가 부족한 비전공자는 밑줄 그어진 부분만 읽어도 상관 없다.R 내장데이터 AirPassenger는 1949년부터 1960년까지 월별 항공기의 승객 수에 대한 데이터다.**(1) 모형** : 사실 계수만 제대로 파악할 수 있다면 중요한 것은 아니다. 계절형 아리마 모형 $ARIMA(p,d,q)\times(P,D,Q)_{s}$ 을 나타낸다. 예로써</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드의 일관성과 수렴차수</title>
      <link>https://freshrimpsushi.github.io/posts/consistency-and-convergence-order-of-multistep-method/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/consistency-and-convergence-order-of-multistep-method/</guid>
      <description>초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) )= ( Y_{0} , \cdots , Y_{p} ) \end{cases}$ 에 대해 멀티스텝 메소드 $\displaystyle y_{n+1} = \sum_{j=0}^{p} a_{j} y_{n-j} + h \sum_{j = -1}^{p} b_{j} f (x_{n-j} , y_{n-j} ) $ 가 일관성을 가지는 필요충분조건은 **(i)** 이고, 수렴차수 $m \in \mathbb{N}$ 을 갖는 필요충분조건은 **(ii)** 다.**(i)** $\begin{cases} \displaystyle \sum_{j = 0}^{p} a_{j} = 1 \\ \displaystyle - \sum_{j = 0}^{p} j a_{j} + \sum_{j = -1}^{p} b_{j} = 1 \end{cases} $**(ii)** $\displaystyle \sum_{j=0}^{p} (-j)^{i} a_{j} + i \sum_{j=-1}^{p} (- j )^{i-1} b_{j} = 1$ 단, $ (i = 0, 1 , \cdots , m)</description>
    </item>
    
    <item>
      <title>리미트 슈프리멈과 리미트 인피멈</title>
      <link>https://freshrimpsushi.github.io/posts/limit-supremum-and-limit-infimum/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-supremum-and-limit-infimum/</guid>
      <description>$\left\{ x_{n} \right\}_{n \in \mathbb{N}}$, $\left\{ y_{n} \right\}_{n \in \mathbb{N}}$ 이 실수열이라고 하자.**1.** $\displaystyle \limsup_{n \to \infty} x_{n} := \lim_{n \to \infty} \left( \sup_{k \ge n} x_{k} \right)$ 을 $\left\{ x_{n} \right\}$ 의 **리미트 슈프리멈** 이라고 한다.**2.** $\displaystyle \liminf_{n \to \infty} y_{n} := \lim_{n \to \infty} \left( \inf_{k \ge n} y_{k} \right)$ 을 $\left\{ y_{n} \right\}$ 의 **리미트 인피멈** 이라고 한다.* 여기서 $\displaystyle \sup_{k \ge n} x_{k} := \sup \left\{ x_{k} : k \ge n \right\}$ 그리고 $\displaystyle \inf_{k \ge n} x_{k} := \inf \left\{ x_{k} : k \ge n \right\}$ 이다.**[1] $$ \displaystyle</description>
    </item>
    
    <item>
      <title>임베딩 넣기사상</title>
      <link>https://freshrimpsushi.github.io/posts/imbedding-embedding/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/imbedding-embedding/</guid>
      <description>※ imbedding과 embedding은 같은 말이다.※ 임베딩은 매장, 매입, 넣기, 묻기 등으로 번역한다.$X$, $Y$가 놈드 스페이스라고 하자. 아래의 두 조건을 만족할 때 연속사상 $f\ :\ X \rightarrow Y$를 임베딩$(\mathrm{imbedding\ or\ embedding}$, 넣기 사상$)$ 이라 한다. 또한 $X$는 $Y$ 안으로 임베드돼었다$(\ma</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 시계열 분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-arima-model-in-r/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-arima-model-in-r/</guid>
      <description>하단에 예제코드 전체가 있다.* 수학, 통계적인 기초가 부족한 비전공자인데 당장 분석을 해야하는 사람들을 위해서 쓰인 글이다. 가능하다면 이론적인 배경을 충분히 숙지한 후 제대로 된 방법으로 하는 게 좋다.R에서 내장데이터 WWWusage를 불러와 그래프를 그려 확인해보자.WWWusage는 먼 옛날 인터넷에 접속하는 이용자수를 나타내는 시</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/multistep-method/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multistep-method/</guid>
      <description>$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) ) = (Y_{0}, \cdots , Y_{p} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b $ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값과 $0 \le p \le m$ 에 대해 $a_{p} \ne 0$ 혹은 $b_{p} \ne 0 $ 이면 다음을 $(p+1)$-스텝 메소드라고</description>
    </item>
    
    <item>
      <title>역 민코프스키 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/reverse-minkowski-inequality/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reverse-minkowski-inequality/</guid>
      <description>**민코프스키 부등식$(\mathrm{Minkowski&amp;rsquo;s\ inequality})$ $u, v \in L^p(\Omega)$라고 하자. $ 1 \le p &amp;lt; \infty$이면 $u+v \in L^p(\Omega)$이고 다음의 부등식이 성립한다. $$ | u+v |_p \le |u|_p + |v|_p $$ $\Omega$는 $\mathbb{R}^n$의 공집합이 아닌 열린 부분집합이다. 편</description>
    </item>
    
    <item>
      <title>역 횔더 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/reverse-hoelder-inequality/</link>
      <pubDate>Thu, 25 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reverse-hoelder-inequality/</guid>
      <description>**역 횔더 부등식$(\mathrm{ reverse\ Hoelder\ inequality})$ $0 &amp;lt; p &amp;lt;1 $이라고 하자. 그러면 $p&#39;=p/(p-1)&amp;lt;0$이다. 그리고 $u \in L^p(\Omega)$, $uv\in L^1(\Omega)$이고 아래의 식이 성립한다고 가정하자. $$ 0 &amp;lt; \int_\Omega |v(x)|^{p&#39;}dx &amp;lt;\infty \quad \cdots (1) $$ 그러면 아래의 부등식이 성립한다. $$ \int_\Omega |u(x)v(x)|dx \ge \left( \int_\Omega |u(x)|^p dx \right)^{\frac{1}{p}} \left( \int_\Omega |v(x)|^{p&#39;} dx \right) ^{\frac{1}{p&#39;}}=|u|_p\ |v|_{p&#39;} $$ $\Omega$는 $\mathbb</description>
    </item>
    
    <item>
      <title>초기값이 조금 달라졌을 때 오일러 메소드의 오차</title>
      <link>https://freshrimpsushi.github.io/posts/692/</link>
      <pubDate>Thu, 25 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/692/</guid>
      <description>$[x_{0} , b] \times \mathbb{R}$ 에서 정의된 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 의 해 $Y(x)$ 가 $Y \in C^{3} [ x_{0} , b ]$ 이고 $\displaystyle f_{y} (x,y) = {{ \partial f (x,y) } \over { \partial y }} $ 와 $\displaystyle f_{yy} (x,y) = {{ \partial^{2} f (x,y) } \over { \partial y^{2} }} $ 가 연속이면서 바운디드라고 하자. 초기값 $y_{h} (x_{0} ) $ 가 $Y_{0} - y_{h} (x_{0} ) = \delta_{0} h + O ( h^2 ) $ 을 만족시킨다고 하자. 그러면 오일러 메소드로 생기는 오차는 선형 초기값 문제 $\begin{cases} \displaystyle D&#39; (x) =</description>
    </item>
    
    <item>
      <title>코시 수열</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-sequence/</link>
      <pubDate>Thu, 25 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-sequence/</guid>
      <description>모든 $\varepsilon &amp;gt; 0 $ 에 대해서 $n , m \ge N \implies | x_{n} - x_{m} | &amp;lt; \varepsilon $ 를 만족하는 $N \in \mathbb{N}$ 이 존재하면 수열 $\left\{ x_{n} \right\}_{n \in \mathbb{N}}$ 이 **코시** 라고 한다.$\mathbb{R}$ 에서 코시 수열과 수렴하는 수열은 동치다.세상에 발산하면서도 중요한 수열은 별로 없다는 점을 생각해보면 여기에 이름을 붙인 &amp;lsquo;코시&amp;rsquo;가 대단한 학자였음을 짐작할 수</description>
    </item>
    
    <item>
      <title>강한 립시츠 조건과 오일러 메소드의 오차</title>
      <link>https://freshrimpsushi.github.io/posts/stronger-lipschitz/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stronger-lipschitz/</guid>
      <description>강한 립시츠 조건 $\implies$ 립시츠 조건 $\implies$ 국소 립시츠 조건$[x_{0} , b] \times \mathbb{R}$ 에서 정의된 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 의 해 $Y(x)$ 가 $[x_{0} , b]$ 에서 두 번 미분가능하다고 하자. $f$ 가 모든 $x_{0} \le x \le b$ 와 $ y_{1} , y_{2} \in \mathbb{R}$, 그리고 $K \ge 0$ 에 대해 **강한 립시츠 조건 $$ |f(x,y_{1} ) - f(x,y_{2}) | \le K | y_{1} - y_{2} | $$ 을 만족하면 오일러 메소드로 얻은 해 $ \left\{ y_{n} ( x_{ n } ) ,</description>
    </item>
    
    <item>
      <title>준소수의 소인수분해 문제가 쉽게 풀리는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/1189/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1189/</guid>
      <description>소인수분해 문제의 어려움을 이용한 보안 알고리즘RSA 공개 키 암호체계골드바서-미칼리 확률 키 암호체계소인수분해 문제에 대한 공격 알고리즘폴라드 p-1 소인수분해 알고리즘준소수의 소인수분해 문제가 쉽게 풀리는 조건준소수의 소인수분해문제 $N = pq$ 는 다음의 조건 하에서 비교적 쉽게 풀리게 된다.(i) $p$ 가 스무스한 소수다.(ii) $p \approx q$(ii) 의 의</description>
    </item>
    
    <item>
      <title>클락슨 부등식의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-clarksons-inequalities/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-clarksons-inequalities/</guid>
      <description>**클락슨 부등식$(\mathrm{Clarkson&amp;rsquo;s\ inequalities})$ $u,v\in {L}^{ p}(\Omega)$라고 하자. 또한 $\frac{1}{p}+\frac{1}{p&#39;}=1$을 만족한다고 하자. 만약 $2\le p &amp;lt;\infty$라면 다음의 두 부등식이 성립한다. $$ \left| \frac{u+v}{2}\right|{p}^{p}+ \left| \frac{u-v}{2} \right|{p}^{p} \le \frac{1}{2}| u|{p}^{p} + \frac{1}{2}|v|{p}^{p} \quad \cdots (1) $$ $$ \left| \frac{u+v}{2}\right|{p}^{p&#39;}+ \left| \frac{u-v}{2} \right|{p}^{p&#39;} \ge \left( \frac{1}{2}| u|{p}^{p} + \frac{1}{2}|v|{p}^{p}\right)^{p&#39;-1}</description>
    </item>
    
    <item>
      <title>볼자노-바이어슈트라스 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bolzano-weierstrass-theorem/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bolzano-weierstrass-theorem/</guid>
      <description>다른 증명무한집합 $E \subset \mathbb{R}$ 가 유계이면 $E$의 집적점 $p \in \mathbb{R}$이 존재한다.혹은 &amp;lsquo;유계 수열은 수렴하는 부분수열을 갖는다.&amp;lsquo;라고 해도 좋다. 조건에서 $E$ 가 꼭 닫혀있을 필요는 없다는 점을 알아두도록 하자. 증명 Part 1. $\displaystyle \bigcap_{n=1}^{\infty} I_{n} = \left\{ x \right\}$가정에서 $E$ 가 유계이므로 $E \subset I_{1}$ 를 만족하는 폐구</description>
    </item>
    
    <item>
      <title>오일러 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/euler-method/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euler-method/</guid>
      <description>$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b $ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} \simeq Y_{0}$ 에 대해 $$ y_{n+1} = y_{n} + h f ( x_{n} , y_{n} ) $$ 오일러 메소드는 개념적으로 아주 간단한 방법이지만 수치해석의 핵심</description>
    </item>
    
    <item>
      <title>인터폴레이션 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/interpolation-inequality/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interpolation-inequality/</guid>
      <description>**인터폴레이션 부등식$(\mathrm{interpolation\ inequality})$ $1\le p &amp;lt; q&amp;lt; r$이라고 하자. 그리고 $0&amp;lt;\theta &amp;lt;1$인 어떤 $\theta$에 대해서 아래의 식이 성립한다고 하자. $$ \dfrac{1}{q}=\frac{\theta}{p}+\frac{1-\theta}{r} \quad \cdots (1) $$ $u \in L^p(\Omega) \cap L^r(\Omega)$라고 가정하자. 그러면 $u\in L^{q}(\Omega)$이고 아래의 부등식이 성립한다. $$ | u</description>
    </item>
    
    <item>
      <title>폴라드 p-1 소인수분해 알고리즘 증명 Proof of Pollards p-1 Factorization Algorithm</title>
      <link>https://freshrimpsushi.github.io/posts/1187/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1187/</guid>
      <description>소인수분해 문제의 어려움을 이용한 보안 알고리즘RSA 공개 키 암호체계골드바서-미칼리 확률 키 암호체계소인수분해 문제에 대한 공격 알고리즘폴라드 p-1 소인수분해 알고리즘준소수의 소인수분해 문제가 쉽게 풀리는 조건준소수 $N$ 이 주어져있다고 하자. $p$ 가 스무스 소수라면 $N$ 의 소인수분해 $N = pq$ 는 다음과 같이 구할 수 있다.**Step 1. $a := 2 $</description>
    </item>
    
    <item>
      <title>Lp공간의 선형 범함수</title>
      <link>https://freshrimpsushi.github.io/posts/linear-functional-on-lp-space/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-functional-on-lp-space/</guid>
      <description>$1 \le p \le \infty$이고 $p&#39;=\frac{p}{p-1}$이라고 하자. 각각의 $v \in L^{p&#39;}(\Omega)$에 대해서 $L^p(\Omega)$공간상의 선형 범함수 $L_v\ :\ L^p(\Omega) \rightarrow \mathbb{C}$를 아래와 같이 정의한다. $$ L_v(u) = \int_{\Omega} u(x)v(x)dx, \quad u\in L^p(\Omega) $$ $\Omega$는 $\mathbb{R}^n$의 공집합이 아닌 열린</description>
    </item>
    
    <item>
      <title>칸토어의 축소구간 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cantors-nested-intervals-theorem/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cantors-nested-intervals-theorem/</guid>
      <description>거리공간으로 일반화된 칸토어의 축소 구간 정리집합의 수열 $\left\{ S_{n} \right\}_{n=1}^{\infty} $ 이 모든 자연수 $n$ 에 대해 $S_{n+1} \subset S_{n}$ 이면 **내포**Nested 되었다고 한다. 내포된 구간 $[a_{n}, b_{n}]$ 에 대해 다음이 성립한다.**[a]** $\displaystyle \bigcap_{n=1}^{\infty} [a_{n}, b_{n}] \ne \emptyset $**[b]** 특히 $\displaystyle \lim_{n \to \infty} (b_{n} - a_{n}) = 0$ 이면 $\displaystyle \bigcap_{n=1}^{\infty} [a_{n}, b_{n}] $ 은 홑원소 집합이다.**홑원소 집합** 이란 원소가 단 하나밖에 존재하지 않는 집합을</description>
    </item>
    
    <item>
      <title>골드바서-미칼리 확률 키 암호체계 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-goldwasser-micali-probabilistic-key-cryptosystem/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-goldwasser-micali-probabilistic-key-cryptosystem/</guid>
      <description>소인수분해 문제의 어려움을 이용한 보안 알고리즘RSA 공개 키 암호체계골드바서-미칼리 확률 키 암호체계소인수분해 문제에 대한 공격 알고리즘폴라드 p-1 소인수분해 알고리즘준소수의 소인수분해 문제가 쉽게 풀리는 조건왼쪽부터 순서대로 앨리스 , 밥 , 이브** 라고 하자. 앨리스와 밥은 메세지를 주고받을 당사자고, 이브는 메세지에 관심이 있는 소극</description>
    </item>
    
    <item>
      <title>균등 볼록성</title>
      <link>https://freshrimpsushi.github.io/posts/uniform-convexity/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniform-convexity/</guid>
      <description>**균등하게 볼록$(\mathrm{uniformly\ convex})$ 집합 $X$상의 놈 $| \cdot |$이 아래의 조건을 만족하면 균등하게 볼록하다고 말한다.$0&amp;lt;\epsilon \le 2$인 모든 $\epsilon$에 대해서 양수 $\delta(\epsilon)&amp;gt;0$이 존재해서 $x,y \in X$이고 $| x |=|y|=1$, $| x-y| \ge \epsilon$</description>
    </item>
    
    <item>
      <title>대학교 수학에서 수열의 수렴을 복잡하게 정의하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/1186/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1186/</guid>
      <description>수열의 극한을 새롭게 정의하는 이유$\left\{ x_{n } \right\}_{n = 1}^{\infty}$ 이 실수의 수열이라고 하자. 모든 $\varepsilon &amp;gt; 0 $ 에 대해 $n \ge N \implies | x_{n} - a | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하면 $\left\{ x_{n } \right\}$ 이 $a \in \mathbb{R}$ 로 수렴한다고 한다. $$ \displaystyle \lim_{n \to \infty} x_{n} = a \iff \forall \varepsilon &amp;gt; 0 , \exists N \in \mathbb{N} : n \ge N \implies | x_{n} - a | &amp;lt; \varepsilon $$ 이러한 정의를 사용한 전개를 흔히 **입실론-델타 논법** 이라고</description>
    </item>
    
    <item>
      <title>대학교 수학에서 수열의 극한을 새롭게 정의하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/1184/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1184/</guid>
      <description>수열의 수렴을 복잡하게 정의하는 이유1. 정의역이 $\mathbb{N}$ 인 함수를 수열이라고 한다.2. 자연수의 수열 $\left\{ n_{k} \right\}_{ k \in \mathbb{N}}$ 에 대해 $\left\{ x_{n_{k}} \right\}_{ k \in \mathbb{N}}$ 를 $\left\{ x_{n} \right\}_{ n \in \mathbb{N}}$ 의 **부분수열**Subsequence 이라고 한다.**3.** 모든 $x \in \left\{ x_{n} \right\}_{ n \in \mathbb{N}}$ 에 대해 $x \le M$ 을 만족하는 $M \in \mathbb{R}$ 이 존재하면 $\left\{ x_{n} \right\}_{ n \in \mathbb{N}}$ 가 **위로 유계** , $m \le x$ 를 만족하는</description>
    </item>
    
    <item>
      <title>베셀 방정식의 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-bessels-equations/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-bessels-equations/</guid>
      <description>$\nu$차 베셀 방정식은 아래와 같다. $$ \begin{align*} x^2 y&#39;&#39; +xy&#39; +(x^2-\nu^2)y&amp;amp;=0 \\ x(xy&#39;)&#39;+(x^2- \nu ^2) y&amp;amp;=0 \\ y&#39;&#39;+\frac{1}{x} y&#39; + \left( 1-\frac{\nu^{2}}{x^{2}} \right)y&amp;amp;=0 \end{align*} $$ **유도 2차원 극좌표에서 파동 방정식은 다음과 같이 주어진다. $$ \dfrac{\partial ^2 u}{\partial t^2} = c^2 \left( \dfrac{\partial ^2 u}{\partial r^2}+\frac{1}{r}\dfrac{\partial u}{\partial r}+\frac{1}{r^2} \dfrac{\partial ^2 u}{\partial \theta ^2}\right) \tag{1} $$ $c$는 상수이다. 위 방정식의 해 $u$를 변수 분리 가능한 함수라고 가정하자. $$ u(t, r, \theta)=T(t)R(r)\Theta(\theta) $$ $(1)$에 대입하면 $$ T&#39;&amp;lsquo;R\Theta=c^2\left( TR&amp;rsquo;&#39;\Theta + \dfrac{1}{r}TR&#39;\Theta + \frac{1}{r^2}TR\Theta&#39;&#39; \right) $$ 양변을 $</description>
    </item>
    
    <item>
      <title>RSA 공개 키 암호체계 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rsa-public-key-cryptosystem/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rsa-public-key-cryptosystem/</guid>
      <description>소인수분해 문제의 어려움을 이용한 보안 알고리즘RSA 공개 키 암호체계골드바서-미칼리 확률 키 암호체계소인수분해 문제에 대한 공격 알고리즘폴라드 p-1 소인수분해 알고리즘준소수의 소인수분해 문제가 쉽게 풀리는 조건왼쪽부터 순서대로 앨리스 , 밥 , 이브** 라고 하자. 앨리스와 밥은 메세지를 주고받을 당사자고, 이브는 메세지에 관심이 있는 소극</description>
    </item>
    
    <item>
      <title>물리학을 위한 푸리에 급수와 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-series-and-fourier-transform-for-physics/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-series-and-fourier-transform-for-physics/</guid>
      <description>예전부터 물리학과 수리물리 정도만 공부하는 물리학과 전공자에게 푸리에 급수와 푸리에 변환에 대한 좋은 설명이 없다고 생각했다. 푸리에 급수, 푸리에 변환에 대한 내용은 많은 교재에서 다루고 있지만 핵심을 적절한 난이도로, 적절한 분량으로 다룬 교재는 없는 것 같아서 직접 작성했다. 특히나 난이도에 대한 부분을 신경써서 글이 어렵지 않도록 했다. 전공 수</description>
    </item>
    
    <item>
      <title>매트랩에서 그래프에 사용 가능한 특수기호 일람</title>
      <link>https://freshrimpsushi.github.io/posts/1191/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1191/</guid>
      <description>매트랩에서 각각의 축이 무엇을 의미하는지 나타내기 위해서 그래프에 라벨을 붙일 경우 xlabel , ylabel 을 사용하면 된다. 특수기호를 사용할 수도 있고 볼드체, 이탤릭체 등도 사용할 수 있다.예시 1 x=-3*pi:0.2:3* pi; y=sin(x-pi/6); plot(x,y); xlabel(&amp;#39;\beta&amp;#39;), ylabel(&amp;#39;\nabla f(x)&amp;#39;),; 예시 2 x=-3*pi:0.2:3* pi; y=sin(x-pi/6); plot(x,y); xlabel(&amp;#39;진폭{\bf Volt}&amp;#39;), ylabel(&amp;#39;시간{\it sec}{\sl sec}{\rm sec}&amp;#39;); 코드에 따른 결과가 위와 같이 나타난다는</description>
    </item>
    
    <item>
      <title>소인수분해</title>
      <link>https://freshrimpsushi.github.io/posts/factorization/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factorization/</guid>
      <description>자연수 $N$ 에 대해 $N = p_{1}^{r_{1}} \cdots p_{n}^{r_{n}} $ 을 만족하는 소수 $p_{1} , \cdots , p_{n}$ 와 자연수 $r_{1} , \cdots , r_{n}$ 를 찾는 것을 **소인수분해** 라고 한다.역사적으로 소수는 늘 탐구의 대상이었으나 그럼에도 불구하고 아직 모르는 것이 많다.페르마 판정법, 코셀트 판정법, 밀러-라빈 판정법과 같은 초등적 도구는 물론, 소수 정리를 비롯한 해석적 접근은 인간 지성의 위대한 산물이다.</description>
    </item>
    
    <item>
      <title>립시츠 조건</title>
      <link>https://freshrimpsushi.github.io/posts/lipschitz-condition/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lipschitz-condition/</guid>
      <description>강한 립시츠 조건 $\implies$ 립시츠 조건 $\implies$ 국소 립시츠 조건1계 미분방정식에 대한 존재성-유일성 정리$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. $f$ 가 모든 $(x,y_{1}) , (x , y_{2} ) \in D$ 와 $K &amp;gt; 0$ 에 대해 **립시츠 조건** $|f(x,y_{1} ) - f(x,y_{2}) | \le K | y_{1} - y_{2} |$ 을 만족하면 $(x_{0} , Y_{0}) \in D^{\circ}$ 에 대해 적절한 구간 $I := [ x_{0} - \alpha , x_{0} + \alpha ]$ 에</description>
    </item>
    
    <item>
      <title>연속이지만 미분할 수 없는 함수  바이어슈트라스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/weierstrass-function/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weierstrass-function/</guid>
      <description>정리 어디에서도 미분할 수 없는 연속함수가 존재한다. Strategy : 연속함수 $g_{1} (x) := | x - 1 |$ 과 $g_{2} (x) := | x - 2 |$ 을 생각해보자. $g_{1}$ 은 $x=1$ 에서, $g_{2}$ 는 $x=2$ 에서 미분가능하지 않다. $(g_{1} + g_{2})$ 는 $x = 1$ 와 $x = 2$ 두 점 모두에서 미분가능하지 않다. 이러한 방식으로 $\displaystyle G: = \sum_{k=1}^{\infty} g_{k}$ 을 구성해보면 $G$ 는 $x \in \mathbb{N}$ 에서 미분가능하지 않을 것이다. 물론 이는 바이어슈트라스 함수라</description>
    </item>
    
    <item>
      <title>물리학에서의 오일러-라그랑주 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/euler-lagrange-equation/</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euler-lagrange-equation/</guid>
      <description>수학에서의 오일러-라그랑주 방정식 먼저 읽어야할 글 : 라그랑주 역학과 해밀턴의 변분 원리 위의 글을 읽었다는 가정에서 글을 쓰겠다. 가능하면 중복되는 표기법이라도 본 글에서 다시 설명하겠지만 설명없이 쓰는 표기법이 있다면 상단 링크를 참고하자.운동 경로에 대한 라그랑지안을 적분한 것을 작용$(\mathrm{action})$이라 하고 $</description>
    </item>
    
    <item>
      <title>수치적으로 이상적분을 계산하기 위한 가우스 구적법</title>
      <link>https://freshrimpsushi.github.io/posts/1161/</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1161/</guid>
      <description>가우스 구적법은 그 자체로 아주 탁월할뿐 아니라, 노드를 잘 고름으로써 적분범위가 무한하게 주어져도 계산을 수행해낼 수 있다.가우스-체비셰프 구적법 $$ \int_{-1}^{1} {{ 1 } \over { \sqrt{1 - x^2 } }} f(x) dx \approx \sum_{i=1}^{n} w_{i} f( x_{i} ) $$ $$ w_{i} = {{ \pi } \over { n }} $$ 여기서 $x_{i}$ 들은 $T_{n}(x) = 0$ 를 만족하는 체비셰프 노드다.가우스-라게르 구적법 $$ \int_{0}^{\infty} e^{-x} f(x) dx \approx \sum_{i=1}^{n} w_{i} f( x_{i} ) $$ $$ w_{i} = {{ x_{i} } \over { (n+1)^2</description>
    </item>
    
    <item>
      <title>라그랑주 역학과 해밀턴의 변분 원리</title>
      <link>https://freshrimpsushi.github.io/posts/lagrangian-mechanics-and-hamiltons-variational-principle/</link>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lagrangian-mechanics-and-hamiltons-variational-principle/</guid>
      <description>**※ 해밀턴의 원리, 범함수, 작용, 변분 등에 대해서 가능한 쉽게 설명해놓았으니 다른 곳에서 만족할만한 설명을 찾지 못했다면 끝까지 읽어보자. 오일러-라그랑주 방정식**해밀턴의 변분 원리$(\mathrm{Hamilton&amp;rsquo;s\ variational\ principle})$ 물체가 시간 $t_1$에서 $t_2$까지 운동할 때 운동 경로에 대한 라그랑지안을 적</description>
    </item>
    
    <item>
      <title>함수의 급수</title>
      <link>https://freshrimpsushi.github.io/posts/series-of-function/</link>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-of-function/</guid>
      <description>함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 을 정의하자.**(1)** $\displaystyle \sum_{k=1}^{n} f_{k} (x) $ 이 $n \to \infty$ 일 때 $E$ 에서 점별수렴하면 급수 $\displaystyle \sum_{k=1}^{ \infty } f_{k}$ 가 $E$ 에서 점별수렴한다고 한다.**(2)** $\displaystyle \sum_{k=1}^{n} f_{k} (x) $ 이 $n \to \infty$ 일 때 $E$ 에서 균등수렴하면 급수 $\displaystyle \sum_{k=1}^{ \infty } f_{k}$ 가 $E$ 에서 균등수렴한다고 한다.**(3)** $\displaystyle \sum_{k=1}^{n} | f_{k} (x) | $ 이 $n \to \infty$ 일 때 $E$ 에서 점별수렴하면 급수 $\displaystyle \sum_{k=1}^{ \infty } f_{k}$ 가 $E$</description>
    </item>
    
    <item>
      <title>에르미트 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-polynomial/</link>
      <pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-polynomial/</guid>
      <description>1. 확률론자의 에르미트 다항함수 : $H_{e_{n}} = (-1)^{n} e^{{x^2} \over {2}} {{d^{n}} \over {dx^{n}}} e^{- {{x^2} \over {2}}}$**2. 물리학자의 에르미트 다항함수** : $H_{n} = (-1)^{n} e^{x^2} {{d^{n}} \over {dx^{n}}} e^{-x^2}$**에르미트 다항함수** 는 두가지 꼴이 쓰이며, $H_{n} (x) = 2^{{n} \over {2}} H_{e_{n}} \left( \sqrt{2} x \right)$ 와 같은 관계를 갖는다.**[0]** $\displaystyle H_{n+1} (x) = 2x H_{n} (x) - H_{n}&#39; (x) $**[1]** 함수의 내적 $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx $ 에 대해 웨이트 $w$ 를 $\displaystyle w(x) := e^{-x^2}$ 와 같이 주</description>
    </item>
    
    <item>
      <title>함수의 점별수렴과 균등수렴의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/1158/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1158/</guid>
      <description>$\mathbb{R}$ 의 부분집합 $E \ne \emptyset$ 에 대해 함수 $f : E \to \mathbb{R}$ 와 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 을 정의하자.함수의 점별수렴모든 $\varepsilon &amp;gt; 0$ 과 $x \in E$ 에 대해 $n \ge N \implies | f_{n} (x) - f(x) | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하면 $E$ 에서 $f_{n}$ 이 $f$ 로 점별수렴한다고 하고 아래와 같이 표기한다. $$ f_n \rightarrow f $$ 함수의 균등수렴모든 $\varepsilon &amp;gt; 0$ 에 대해 $n \ge N \implies | f_{n} (x) - f(x) | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하</description>
    </item>
    
    <item>
      <title>호프-락스 공식이 해밀턴-야코비 방정식을 만족함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-hopf-lax-formula-satisfies-hamilton-jacobi-equation/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-hopf-lax-formula-satisfies-hamilton-jacobi-equation/</guid>
      <description>$x \in \mathbb{R}^n$, $t&amp;gt;0$이라고 하자. 그리고 호프-락스 공식에 의해 정의된 $u$가 점 $(x,t)$에서 미분가능하다고 하자. 그러면 $u$는 해밀턴-야코비 방정식 을 만족한다. $$ u_t(x, t) + H\big( Du(x, t) \big) =0 $$ 호프-락스 공식에 의해 정의된 $u$가 실제로 해밀턴-야코비 방정식의 해가 됨을 보일 수 있다.**호프-락스 공식$(\mathrm{</description>
    </item>
    
    <item>
      <title>거리공간에서의 내부 폐포 경계</title>
      <link>https://freshrimpsushi.github.io/posts/interior-closure-boundary/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interior-closure-boundary/</guid>
      <description>거리공간 $\left( X, d \right)$ 에 대해 $A \subset X$ 라고 하자.1. $x \in O \subset A$ 를 만족하는 열린 집합 $O$ 가 존재할 때, $x$ 를 $A$ 의 내점Interior Point 이라고 한다.2. $A$ 의 내점의 집합 $A^{\circ} $ 를 $A$ 의 내부Interior 라고 한다.3. $A$ 와 그 도집합의 합집합 $\overline{A} : = A \cup A&#39;$ 를 $A$ 의 폐포Closure 라고 한다.4. $x \in \overline{A}$ 이면서 $x \in \overline{X \setminus A}$ 일 때, $x$ 를 $A$ 의 경계점</description>
    </item>
    
    <item>
      <title>라게르 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/laguerre-polynomial/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laguerre-polynomial/</guid>
      <description>$\displaystyle L_{n} := {{ e^{x} } \over { n! }} {{ d^{n} } \over { dx^{n} }} \left( e^{-x} x^{n} \right)$ 을 **라게르 다항함수** 라고 한다.**[0]** $\displaystyle L_{n+1} (x) = {{ 1 } \over { n+1 }} \left[ \left( 2n + 1 - x \right) L_{n} (x) - n L_{n-1} (x) \right]$**[1]** 함수의 내적 $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx $ 에 대해 웨이트 $w$ 를 $\displaystyle w(x) := e^{-x}$ 와 같이 주면 $\left\{ L_{0} , L_{1}, L_{2}, \cdots \right\} $ 은 직교 집합이 된다.$n = 0, \cdots , 3$ 에 대한 라게르 다항함수는 다음과 같이 나타난다.$L_{</description>
    </item>
    
    <item>
      <title>실수 집합과 공집합은 열려있으면서도 닫혀있음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/378/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/378/</guid>
      <description>$\mathbb{R}$ 과 $\emptyset$ 은 열려있으면서 닫혀있다.실수 $\mathbb{R}$ 상에서 여러 개구간의 합집합을 열린 집합 이라고 한다. 예로써 $(-1,0) \cup (2,3)$ 은 당연히 열린 집합이고, $(0,1)$ 이나 $\mathbb{R}$ 역시 열린 집합이다. 한편 닫혀있음은 열려있음을 통해 정의된다. 어떤 실수의 부분집합 $C$ 에 대해 $R \setminus C$ 가 열려 있으면 $C$ 를 닫힌 집합 이라고 한다.제시된 정리에서도 이미 나와있지만 열리고 닫히고는 서로 배타</description>
    </item>
    
    <item>
      <title>실수 집합에서 집적점이란</title>
      <link>https://freshrimpsushi.github.io/posts/limit-point/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-point/</guid>
      <description>정의 정의 증명 거리공간에서의 집적점 정의 실수상에서의 한 점 $x \in \mathbb{R}$ 과 부분집합 $A \subset \mathbb{R} $ 에 대해 $x$ 를 포함한 임의의 열린 집합 $O$ 에 대해 $ O \cap ( A \setminus \left\{ x \right\} ) \ne \emptyset $ 이면 $x$ 를 집적점Limit Point 이라고 정의한다. $A$ 의 집적점의 집합을 $A$ 의 도집합Derived set 이라고 부르며, $A&#39;$ 로 표기한다. 위 정의에서 조건은 $( O \setminus \left\{ x \right\} ) \cap A \ne \emptyset $ 이어도</description>
    </item>
    
    <item>
      <title>영의 정리</title>
      <link>https://freshrimpsushi.github.io/posts/youngs-theorem/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/youngs-theorem/</guid>
      <description>**영의 정리$(\mathrm{Young&amp;rsquo;s\ theorem})$ $p,\ q,\ r \ge 1$이고 $ \dfrac{1}{p} +\dfrac{1}{q}+\dfrac{1}{r}=2$라고 가정하자. 그러면 모든 $u \in L^p(\mathbb{R}^n)$, $v\in L^q(\mathbb{R}^n)$, $w\in L^r(\mathbb{R}^n)$에 대해서 다음의 식이 성립한다. $$ \left| \int_{\mathbb{R}^n} ( u*v)(x)w(x)dx \right| \le | u|_p\ |v|_q\ |w|_r \quad \cdots (1) $$ 증명 $p$의 횔더 켤레$(\ma</description>
    </item>
    
    <item>
      <title>백 프로젝션 변환</title>
      <link>https://freshrimpsushi.github.io/posts/back-projection-transform/</link>
      <pubDate>Sun, 30 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/back-projection-transform/</guid>
      <description>**평면 위의 직선은 원점과 직선사이의 거리와 각도로 나타낼 수 있다. 위의 내용을 이해했다면 평면위의 한 점 $(x_0,\ y_0)$와 $\theta$가 주어졌을 때 $s$값은 유일하게 결정된다는 것을 알 수 있다. 그 값은 $x_0\cos\theta+y_0\sin\theta$인데 이는 아래의 그림에 따라 어렵지 않게 구할 수 있다.&amp;lt;img</description>
    </item>
    
    <item>
      <title>원주율은 무리수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-pi/</link>
      <pubDate>Sun, 30 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-pi/</guid>
      <description>$e$ 의 경우$\pi \notin \mathbb{Q}$* $\mathbb{Q}$ 는 유리수의 집합을 나타낸다.**Strategy** : 정수가 조밀성을 갖지 않는다는 점을 이용한다. 함수 $f$, $F$ 를 아주 교묘하게 정의해서 갖가지 트릭을 사용한다. 이 방법은 이반 니븐Ivan Niven에 의해 고안된 것으로 $\pi$ 가 무리수라는 것을 보이는 증명 중에서는 가장 쉽지만, 아쉽게도 입실론-델타 논법이 쓰이기 때</description>
    </item>
    
    <item>
      <title>푸리에 슬라이스 정리</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-slice-theorem/</link>
      <pubDate>Sun, 30 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-slice-theorem/</guid>
      <description>**푸리에 슬라이스 정리$(\mathrm{Fourier\ slice\ theorem})$ 2차원 평면에서 정의된 적절한 함수 $f$에 대해서 아래의 식이 성립한다. $$ \mathcal{F}_2 f(\xi \cos\theta,\ \xi \sin\theta)=\mathcal{F}(\mathcal{R}f)(\xi ,\ \theta) $$ $\mathcal{F}_2$는 2차원 푸리에 변환 , 우변의 $\mathcal{F}$는 1차원 푸리에 변환, $\mathcal{R}$은 라돈 변환 을 의미한다.프로젝</description>
    </item>
    
    <item>
      <title>뉴턴-코테스 적분 공식</title>
      <link>https://freshrimpsushi.github.io/posts/newton-cotes-integration-formulas/</link>
      <pubDate>Sat, 29 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newton-cotes-integration-formulas/</guid>
      <description>$f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 간격이 $\displaystyle h:= {{b-a} \over {n}}$ 로 일정한 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 다음과 같이 정의된 $I_{n}^{p}$ 을 **뉴턴-코테스 공식** 이라고 한다. $$ \displaystyle I_{n}^{p} (f) := \sum_{i=0}^{n} w_{i} f ( x_{i} ) $$ $i=0,1,\cdots , n$ 에 대해 $x_{i} := a + i h $ 이고, $l_{i}$ 는 라그랑주 공식에서 쓰이는 다항함수 $\displaystyle l_{i} (x) := \prod_{i \ne j} \left( {{ x - x_{j} } \over { x_{i} - x_{j} }} \right)$ 를 의</description>
    </item>
    
    <item>
      <title>루트 2 는 무리수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-root-2/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-root-2/</guid>
      <description>$\pi$ 는 무리수$e$ 는 무리수$\sqrt{2}$ 는 무리수다.전략 : $\sqrt{2}$ 를 기약분수꼴로 나타내서 모순을 유도한다. 이 방법은 제곱수가 아닌 모든 $n$ 에 대해 $\sqrt{n}$ 이 무리수임을 보이는데에 사용할 수 있다. 증명 $\sqrt{2}$ 가 유리수라고 가정하면 $\sqrt{2}$ 서로소인 어떤 두 자연수 $a,b$ 에 대해 $\displaystyle \sqrt{2} = {{ a } \over {b}}$ 와 같이 나타날 수 있어야한다. 양변에 $b$ 를 곱하면 $$ \sqrt{2} b= a $$ 양변</description>
    </item>
    
    <item>
      <title>매트랩에서 엑셀의 데이터를 불러오는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1163/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1163/</guid>
      <description>매트랩에서 계산한 데이터를 엑셀파일로 저장하는 방법 매트랩에는 엑셀의 데이터를 불러올 수 있는 기능이 있다. 우선 홈 메뉴에서 데이터 가져오기를 클릭한다.가져올 데이터가 저장된 엑셀 파일을 선택한다.그러면 가져올 데이터를 선택할 수 있는데 처음에 알아서 선택이돼있다. 확인하고 &amp;lsquo;선택 항목 가져오기&amp;rsquo;를 누르면 된다.</description>
    </item>
    
    <item>
      <title>해밀턴-야코비 방정식과 해밀턴 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/hamilton-jacobi-equation-and-hamiltons-equations/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hamilton-jacobi-equation-and-hamiltons-equations/</guid>
      <description>아래의 방법은 해밀턴 방정식을 얻는 두 가지 방법 중 하나이다. 다른 하나는 변분법으로 얻은 오일러-라그랑주 방정식 으로부터 해밀턴 방정식을 얻는 것 이다.다음과 같은 식을 일반적인 해밀턴-야코비 방정식$(\mathrm{the\ general\ Hamilton-Jacobi\ equation})$ 이라 한다. $$ G(Du,\ u_t,\ u,\ x,\ t)=u_t+H(Du, x)=0 $$ 이때 미분 연산자 $D$는 공간에 대한 것으로 생각한다. 즉 $Du=D_xu=(u_{x_1},\ \cdots,\ u_{x_n})$. 그리고 $H</description>
    </item>
    
    <item>
      <title>편미분방정식에서의 라그랑지안과 오일러-라그랑주 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/lagrangian-and-euler-lagrange-equation-in-pde/</link>
      <pubDate>Thu, 27 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lagrangian-and-euler-lagrange-equation-in-pde/</guid>
      <description>물리학으로 이해하는 최소 작용의 원리 라그랑지안$(\mathrm{Lagrangian})$ $L\ :\ \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R} $과 같이 정의된 함수 $L$을 (편의상) 매끄러운$(\mathrm{smooth})$ 함수라 하고, 라그랑지안 이라 이름 붙이자. 그러면 $$ L=L(v,x)=L(v_1,\ \cdots,\ v_n,\ x_1,\ \cdots ,\ x_n) \quad v,x\in \mathbb{R}^n $$ $$ D_vL=(L_{v_{1}},\ \cdots,\ L_{v_{n}}), \quad D_xL=(L_{x_1},\ \cdots,\ L_{x_n}) $$ **작용$(\mathrm{a</description>
    </item>
    
    <item>
      <title>심슨 룰</title>
      <link>https://freshrimpsushi.github.io/posts/simpson-rule/</link>
      <pubDate>Wed, 26 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simpson-rule/</guid>
      <description>$f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 간격이 $\displaystyle h:= {{b-a} \over {n}}$ 로 일정한 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 다음과 같이 정의된 $I_{n}^{2}$ 을 **심슨 룰** 이라고 한다. $$ \displaystyle I_{n}^{2} (f) := \sum_{k=1}^{n/2} {{h} \over {3}} \left[ f(x_{2k-2}) + 4 f( x_{2k-1} ) + f(x_{2k} ) \right] $$ $f \in C^4 [a,b]$ 이라고 하자.**[1]** $\displaystyle E_{1}^{2} (f) = - {{h^5} \over {90}} f^{(4)} ( \xi )$**[2]** $\displaystyle \tilde{E}_{n}^{2} (f) = - {{ h^4 } \over {180}} [ f^{(3)} (b) - f^{(3)} (a) ] $$ I_{n}^{2} (f) $ 을</description>
    </item>
    
    <item>
      <title>R 에서 로그로그 스케일 그림 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-loglog-scale-graph/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-loglog-scale-graph/</guid>
      <description>하단에 예제코드 전체가 있다. win.graph(7,4); par(mfrow=c(1,2)) plot(pressure,main=&amp;#39;Pressure&amp;#39;) y&amp;lt;-pressure[-1,]$pressure; logtemp&amp;lt;-log(y) x&amp;lt;-pressure[-1,]$temperature; logpress&amp;lt;-log(x) plot(logpress,logtemp,main=&amp;#39;log scale&amp;#39;) 로그로그 스케일로 그림을 그리는 가장 쉬운 방법은 데이터 자체에 로그를 취하는 것이다. 만약 로그로그 플랏을 처음 그려본다면 이 방법은 반드시 숙지하는 편이 좋다. 이 방법은 R 이든 어떤 언어든 먹히기 때문에 급한대로 써먹을 수 있기 때문이다. 물론 이 방법은 머리가 편한만큼 손이 다소 수고스럽다. win.graph(5,5) plot(pressure,main=&amp;#39;Pressure&amp;#39;,log=&amp;#34;xy&amp;#34;) R</description>
    </item>
    
    <item>
      <title>1차원 달랑베르 공식 1-</title>
      <link>https://freshrimpsushi.github.io/posts/dim-dalemberts-formula/</link>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dim-dalemberts-formula/</guid>
      <description>1차원이라는 말은 공간에 대한 차원을 말한다. 실제 문제는 공간+시간이므로 2차원이다.아래와 같은 파동 방정식$(\mathrm{wave\ equation})$에 대한 코시 문제가 주어졌다고 하자. $$ \begin{cases} u_{tt}-u_{xx}=0 &amp;amp; \mathrm{in}\ \mathbb{R}^2=\mathbb{R}_x \times \mathbb{R}_t \\ u=g,\quad u_t=h &amp;amp; \mathrm{on}\ \mathbb{R}\times\left\{t=0\right\} \end{cases} $$ 이때, $g \in C^2(\mathbb{R})$, $h\in C^1(\mathbb{R})$이다. 그리고 $u(x,t)$를 다음과 같이</description>
    </item>
    
    <item>
      <title>사다리꼴 룰</title>
      <link>https://freshrimpsushi.github.io/posts/trapezoidal-rule/</link>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trapezoidal-rule/</guid>
      <description>$f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 간격이 $\displaystyle h:= {{b-a} \over {n}}$ 로 일정한 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 다음과 같이 정의된 $I_{n}^{1}$ 을 **사다리꼴 룰** 이라고 한다. $$ I_{n}^{1} (f) := \displaystyle \sum_{k=1}^{n} {{h} \over {2}} \left( f(x_{k-1}) + f(x_{k} ) \right) $$ $f \in C^2 [a,b]$ 이라고 하자.**[1]** $\displaystyle E_{1}^{1} (f) = - {{1} \over {12}} h^{3} f&#39;&#39; ( \xi )$**[2]** $\displaystyle \tilde{E}_{n}^{1} (f) = - {{ h^2 } \over {12}} [ f&#39;(b) - f&#39;(a) ] $$ I_{n}^{1} (f) $ 을 풀어서 써</description>
    </item>
    
    <item>
      <title>R 에서 범례 넣는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-legend-in-r/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-legend-in-r/</guid>
      <description>데이터는 분석하는 것만큼이나 표현하는 것이 중요하다. 그림이 복잡할 수록 꼼꼼한 주석과 깔끔한 범례가 데이터를 이해하는데에 큰 도움을 준다. legend() 함수는 굉장히 많은 옵션을 가지고 있으나, 아래 코드와 같이 아주 필수적인 요소만 사용해도 좋다. 위치를 나타내는 첫번째 옵션은 &amp;ldquo;top&amp;rdquo;, &amp;ldquo;bottom&amp;rdquo; + &amp;ldquo;left&amp;rdquo;, &amp;ldquo;right&amp;rdquo; 의 조합과 &amp;ldquo;center&amp;quot;로 편하게 넣어</description>
    </item>
    
    <item>
      <title>매트랩에서 계산한 데이터를 엑셀파일로 저장하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1150/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1150/</guid>
      <description>매트랩에서 엑셀의 데이터를 불러오는 방법 MATLAB에서 계산한 데이터를 엑셀로 정리하고 싶을 때 데이터양이 얼마되지 않는 다면 직접 복사+붙여넣기를 하는 것이 가능하다. 그런데 위의 사진처럼 128128 행렬의 데이터는 그런식으로 할 수 없다. 이 때 데이터를 엑셀파일로 저장해주는 xlswrite를 사용하면 된다.위 사진과 비교했을 때 마지막줄에xl</description>
    </item>
    
    <item>
      <title>매트랩에서 한꺼번에 여러줄 주석처리주석해제 하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1149/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1149/</guid>
      <description>코드를 짤 때 어느 특정한 부분이 실행되지 않았으면 할 때가 있다. 그럴 때 주석으로 처리하면 실행되지 않는데 주석처리를 하고자 모든 줄 앞에 일일이 %를 입력하면 너무 비효율적이다.이때 주석처리하고 싶은 부분을 드래그한 뒤 Ctrl+R를 입력하면 드래그한 부분 전체를 주석처리할 수 있다. 반대로 되돌릴 때는 똑같이 드래그하고 Ctrl+T를 입력하면</description>
    </item>
    
    <item>
      <title>수치적 적분</title>
      <link>https://freshrimpsushi.github.io/posts/numerical-intergration/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/numerical-intergration/</guid>
      <description>$f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자.**(1)** 적분 오퍼레이터 $I$ 를 $\displaystyle I(f) := \int_{a}^{b} f(x) dx$ 와 같이 정의한다.**(2)** 적분 오퍼레이터 $I_{n}$ 을 $\displaystyle I_{n} (f) := \sum_{k=1}^{n} \int_{x_{k-1}}^{x_{k}} f(x) dx $ 와 같이 정의한다.**(3)** 에러 $E_{n}$ 을 $E_{n} (f) := I (f) - I_{n} ( f )$ 와 같이 정의한다.**(4)** $\displaystyle \lim_{n \to \infty} {{\tilde{E}_{n} (f) } \over</description>
    </item>
    
    <item>
      <title>R 에서 attr 참조하는 법 How to Refer attr in R</title>
      <link>https://freshrimpsushi.github.io/posts/1127/</link>
      <pubDate>Fri, 21 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1127/</guid>
      <description>R 에서 함수들을 사용하다보면 간혹 attr(,&amp;ldquo;something&amp;rdquo;)과 같은 데이터를 접할 때가 있다. Attribute 는 말 그대로 속성 을 의미하는데, 파이썬과 같은 언어와 달리 R 에서는 메타 데이터로써 데이터에 들어있는 일종의 주석으로 받아들여도 좋다. 그런데 R 을 쓰다보면 가끔 이 데이터를 참조하고 싶을 때가 있다.예를 들어</description>
    </item>
    
    <item>
      <title>베르누이 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bernoullis-inequality/</link>
      <pubDate>Wed, 19 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bernoullis-inequality/</guid>
      <description>$ \alpha &amp;gt; 0$ 이라고 하면 모든 $x \in [ - 1, \infty )$ 에 대해 다음 두 부등식이 성립한다.[1] $\alpha \in (0, 1] \implies (1 + x )^{\alpha } \le 1 + \alpha x $[2] $\alpha \in (1, \infty] \implies (1 + x )^{\alpha } \ge 1 + \alpha x $부등식의 모양을 잘 보면 $\alpha$ 의 크기에 달려 있긴 하지만 둘 중 한 쪽은 곱이고, 나머지 한 쪽은 거듭제곱이다. 물론 조건 나름이지만 곱이든 거듭제곱이든 거슬리는 계산 하나를 내가 원하는 쪽으로 바꿀 수</description>
    </item>
    
    <item>
      <title>임의의 함수를 두개의 음이 아닌 함수로 표현하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1145/</link>
      <pubDate>Wed, 19 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1145/</guid>
      <description>임의의 함수의 절대값을 두 개의 음이 아닌 함수로 표현하는 방법**양의 부분$(\mathrm{positive\ part})$, ** **음의 부분$(\mathrm{negative\ part})$ 함수 $f\ :\ X \rightarrow \mathbb{R}$에 대해서 $f^+$와 $f^-$를 다음과 같이 정의하자. $$ f^+(x) := \max \left\{ f(x),\ 0 \right\} $$ $$ f^-(x) := \max \left\{ -f(x),\ 0 \right\} $$ $f^+$를 $f$의</description>
    </item>
    
    <item>
      <title>R 에서 문자열의 벡터를 하나의 문자열로 합치는 법</title>
      <link>https://freshrimpsushi.github.io/posts/1125/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1125/</guid>
      <description>R 은 데이터를 다루기에 무척 편리한 언어지만, 다른 프로그래밍 언어에도 익숙한 사람이라면 R 의 문자열이 다소 낯설 수 있다. C 혹은 파이썬과 달리 R 자체에서 지원하는 기능이 많고, 반대로 그 기능들을 써야만 수월하게 다룰 수 있다. 그래서 내장 함수들이 생각하는대로 작동하지 않으면 답답한 면이 있다.&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20190605_115748.png&amp;rdquo; height=&amp;ldquo;33&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/9919A4335CF72FF427&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ld</description>
    </item>
    
    <item>
      <title>실수값을 갖는 가측함수의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/property-of-real-valued-measurable-function/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/property-of-real-valued-measurable-function/</guid>
      <description>$f, g\ :\ X\rightarrow \mathbb{R}$가 가측공간 $(X,\mathcal{E})$에서 정의된 실수값을 갖는 가측함수 라고 하자. 그리고 $c\in \mathbb{R}$이라 하자. 그러면 아래의 함수들도 가측이다. $$ cf,\quad f^2,\quad f+g,\quad fg,\quad |f| $$ 실수값을 갖는 가측함수의 스칼라곱, 제곱, 절댓값 역시 가측이다. 그리고 실수값을 갖는 가측함수끼리의 합과 곱 모두 가</description>
    </item>
    
    <item>
      <title>체비셰프 노드</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-node/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-node/</guid>
      <description>$[-1,1]$ 에서 $\displaystyle x_{k} = \cos \left( {{2k-1} \over {2n}} \pi \right)$, $k=1, \cdots , n$ 을 **체비셰프 노드** 라고 한다.체비셰프 노드는 일반적으로 사용하듯 일정한 간격의 노드 포인트와 달리 반원의 호를 일정한 크기로 자르고 그 점들을 $x$ 축으로 사영시킨 노드 포인트를 말한다. 점들의 분포는 가운데보다 양 끝에 조금 몰리는 모양새를 이룬다. 밑에서 다시 설명하겠지만, 이 점이 바로 체비셰프 노드의</description>
    </item>
    
    <item>
      <title>R 에서 리스트를 참조하는 여러가지 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1123/</link>
      <pubDate>Sun, 16 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1123/</guid>
      <description>R 은 데이터를 다루기 위해 정말 좋은 기능들을 많이 제공하는데, 그 중에서도 리스트는 R 을 사용하게 만드는 가장 큰 이유 중 하나다. 파이썬을 위시한 다른 언어에도 리스트 자료형 자체는 많이 구현되어 있으나 R 만큼 데이터를 다루기 편하고 직관적으로 구현되어 있지는 않다. 리스트를 잘 다룰 수 있게 되면 다른 프로그래밍 언어로는 다소 복잡하고 귀찮은 코딩도 아</description>
    </item>
    
    <item>
      <title>체비셰프 전개</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-expansion/</link>
      <pubDate>Sat, 15 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-expansion/</guid>
      <description>체비셰프 전개를 이해하기 위해서는 어떻게 체비셰프 전개가 나오는지를 먼저 알아야한다. 우선 최소극대화 문제를 푸는 대신 최소제곱 문제를 푼다고 생각해보자. $$ \displaystyle M_{n} (f) := \inf_{\deg(r) \le n } \left| f - r \right|_{2} $$ $f : [a,b] \to \mathbb{R}$ 에 대해 위와 같이 최소제곱 문제가 주어져있다고 하자. 목표는 $M_{n} (f)$ 를 최소화하는 $n$ 차 이하의 다항함수 $r_{n}^{ * }$ 를 찾는 것이다. 다행스럽게도 다항함</description>
    </item>
    
    <item>
      <title>R 에서 최대값과 최소값의 위치 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/1120/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1120/</guid>
      <description>set.seed(150421) x&amp;lt;-sample(100,10); x which.max(x) which.min(x) 통계를 목적으로 데이터를 보다보면 최대값과 최소값이 무엇인지 아는것만 중요한게 아니라 그 게 몇번째 값인지를 파악하는 것도 필요한 경우가 많다. 특히 시계열 데이터는 더더욱 그러하다.물론 R 은 이런 함수가 없어도 조작이 쉽지만, 가능하다면 복잡한 코드는 지양하는 게 좋다. 데이터 x 의 최대값이 어디인지 궁금해서 which(max(x</description>
    </item>
    
    <item>
      <title>가측 함수</title>
      <link>https://freshrimpsushi.github.io/posts/measurable-function/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/measurable-function/</guid>
      <description>**$\sigma$-대수$(\mathrm{sigma} $$ \mathrm{-algebra}$, 시그마-알제브라, 시그마-필드$)$ 집합 $X$가 주어졌다고 하자. $\mathcal{P}(X)$는 $X$의 멱집합이다. 아래의 세 조건을 만족하는 $X$의 부분집합들의 집합 $\mathcal{E} \subset \mathcal{P}(X)$를 $\sigma$-대수 라 한다.$(a)</description>
    </item>
    
    <item>
      <title>스톤-바이어슈트라스 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-stone-weierstrass-theorem/</link>
      <pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-stone-weierstrass-theorem/</guid>
      <description>$X$ 에 대해 $A \subset C(X)$ 이라고 하자.(1) 서로 다른 $x_{1}, x_{2} \in X$ 에 대해 $f(x_{1}) \ne f(x_{2})$ 를 만족하는 $f \in A$ 가 항상 존재하면 $A$ 가 $X$ 의 점들을 **분리한다**Separate 고 말한다.**(2)** $X$ 가 메트릭 스페이스이고 모든 $\varepsilon &amp;gt; 0$ 과 $f \in C(X)$ 에 대해 $| g - f | &amp;lt; \varepsilon$ 을 만족하는 $g \in A$ 가 존재하면 $A$ 가 $C(X)$ 에서 **유니폼리 덴스**Uniformly Dense 라고</description>
    </item>
    
    <item>
      <title>수치해석학에서의 최소극대화 근사와 최소제곱 근사</title>
      <link>https://freshrimpsushi.github.io/posts/minimax-approximation-and-least-squares-approximation/</link>
      <pubDate>Wed, 12 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/minimax-approximation-and-least-squares-approximation/</guid>
      <description>주어진 함수 $f : [a,b] \to \mathbb{R}$ 를 근사하는 문제가 주어져 있다고 하자. 계산은 컴퓨터의 몫이므로 다항함수로 $f$ 를 근사하는 것이 목표다. 함수를 근사시킨다는 것은 한 점에서의 계산이 아니라 정의역 $[a,b]$ 전체에서 $f$ 와 비슷한 함수를 사용하고 싶은 것이므로 가장 크게 틀리는 부분을 줄이는 것이 목표다. 이러한 상황을 최소극대화Minimax 문제라고 한다. [ NOTE :</description>
    </item>
    
    <item>
      <title>연속함수공간의 알지브라</title>
      <link>https://freshrimpsushi.github.io/posts/algebra-of-continuous-function-space/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebra-of-continuous-function-space/</guid>
      <description>다음 세 가지 조건을 만족하는 집합 $A$ 를 $C(X)$ 의 알지브라 라고 한다.(i) $\emptyset \ne A \subset C(X)$(ii) $f,g \in A \implies (f+g) , fg \in A$(iii) $f \in A , c \in \mathbb{R} \implies cf \in A$메트릭 스페이스 $X$ 에 대해 $A \subset C(X)$ 이라고 하자. $A$ 의 모든 시퀀스 $\left\{ f_{n} \in A : n \in \mathbb{N} \right\} $ 가 어떤 $f \in A$ 에 대해 $n \to \infty$ 일 때 $\displaystyle | f - f_{n} | \to 0$ 면 $A$ 가 **유니폼리 클로즈드**Uniformly Closed 라고 한다.이에 대한 다</description>
    </item>
    
    <item>
      <title>함수 근사</title>
      <link>https://freshrimpsushi.github.io/posts/approximation-of-functions/</link>
      <pubDate>Mon, 10 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/approximation-of-functions/</guid>
      <description>수치적인 계산을 할 때 컴퓨터가 인간보다 압도적으로 빠른 것은 사실이지만, 딱히 컴퓨터가 초월함수와 무리수를 이해했기 때문은 아니다. 가령 $\displaystyle \sin {{ \pi } \over {6}} = {{1} \over { 2 }}$ 을 계산시킨다면 삼각함수의 기하학적인 정의를 이용해서 직각삼각형을 그려보고 빗변과 높이의 비를 구하는 게 아니라, 다항함수로 급수전개해서 사칙연산으로 구하는 것이다. 컴퓨터</description>
    </item>
    
    <item>
      <title>L^1공간과 L^2공간의 관계 Relationship between L^2 space and L^1 space</title>
      <link>https://freshrimpsushi.github.io/posts/1114/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1114/</guid>
      <description>우선 $L^1$ 공간과 $L^2$ 공간의 정의는 다음과 같다.**$L^1$ 공간 아래의 식을 만족하는 함수를 구간 $[a,\ b]$에서 (절대)적분가능$(\mathrm{absolutely\ integrable})$ 하다고 한다. $$ \int_a^b |f(x)| dx &amp;lt; \infty $$ 구간 $[a,b]$에서 적분가능한 함수들의 집합을 $L^1(a,b)$이라 한다. $$ L^1(a,b)= \left\{ f\ \Bigg|\ \int_{-a}^{b} |f(x)| dx &amp;lt; \infty \right\} $$ 구간을 따로 언급하지</description>
    </item>
    
    <item>
      <title>아리마 모형에서의 드리프트</title>
      <link>https://freshrimpsushi.github.io/posts/drift-in-arima-model/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/drift-in-arima-model/</guid>
      <description>*하단에 예제코드 전체가 있다.*수학, 통계적인 기초가 부족한 비전공자는 밑줄 그어진 부분만 읽어도 상관 없다.시계열 분석을 하다보면 종종 다음과 같이 드리프트 라는 계수를 보게 된다.물론 위의 경우 표준오차에 비해서 계수의 크기가 너무 작기 때문에 무시해도 상관 없다. 그러나 실제로 유의한 계수인 동시에 수식으로도 써야할 일이 있다면 드리프트가 무</description>
    </item>
    
    <item>
      <title>윈도에서 명령 프롬프트로 파일 목록 얻는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-file-list-using-cmd-in-windows/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-file-list-using-cmd-in-windows/</guid>
      <description>복수의 데이터를 취합하는 프로그램을 짤 때 파일이 너무 많아서 문제가 될 수 있다. 물론 어느 프로그래밍 언어이든 이를 해결하는 방법은 각자 있겠지만, 반복할 필요가 없거나 너무 다양한 언어를 사용하는 경우 임시적인 해결법이 큰 도움이 된다. 윈도의 명령 프롬프트를 통해 쉽고 빠르게 해보자.Step 1. 주소 복사파일 목록이 필요한 폴더로 들어가 주소를 복사</description>
    </item>
    
    <item>
      <title>푸리에 역변환 정리</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-inversion-theorem/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-inversion-theorem/</guid>
      <description>여기 에서 푸리에 변환$(\mathrm{Fourier\ transform})$과 역변환 공식을 간단히 소개했다. 하지만 이는 이해를 돕기 위해 단순히 설명한 것으로 변환 식을 정확하게 유도한 것은 아니다. 우선 푸리에 역변환$(\mathrm{Fourier\ inverse\ transform})$은 아래와 같다. $$ f(x) =\dfrac{1}{2\pi} \int \hat{f}(\xi) e^{i\xi x}d\xi \quad \cdots (1) $$ 앞</description>
    </item>
    
    <item>
      <title>계절형 아리마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/seasonal-arima-model/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/seasonal-arima-model/</guid>
      <description>1. $\nabla_{s} Y_{t} := Y_{t} - Y_{t-s}$ 와 같이 정의된 오퍼레이터 $\nabla_{s}$ 를 **계절형 차분**Seasonal Difference 이라 한다.**2.** $W_{t} := \nabla^{d} \nabla_{s}^{D} Y_{t}$ 와 같이 정의된 $\left\{ W_{t} \right\}_{t \in \mathbb{N}}$ 가 $ARMA(P,Q)$ 고 $\left\{ Y_{t} \right\}_{t \in \mathbb{N}}$ 이 $ARMA(p,q)$ 면 $\left\{ Y_{t} \right\}_{t \in \mathbb{N}}$ 는 **계절형 아리마 과정** $ARIMA(p,d,q)\times(P,D,Q)_{s}$ 라고 한다. 이와 같은 꼴을 한 시계열 분석 모형을 **계절형 아리마 모형** 이라고 한다.오늘의 기온은 물론 어제의 기온에 가장 큰</description>
    </item>
    
    <item>
      <title>불연속점과 연속점에서 몰리피케이션의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-of-mollification-at-discontinuous-point-and-continuous-point/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-of-mollification-at-discontinuous-point-and-continuous-point/</guid>
      <description>$\eta_\epsilon(x)$를 $\mathbb{R}$ 위에서의 **몰리파이어,** $\alpha= \int_{-\infty}^0 \eta_\epsilon(x) dx$, $\beta=\int_0^\infty \eta_\epsilon (x) dx$, $\alpha+\beta=1$라고 하자. 그리고 $f$가 **조각마다 연속** 이고 유계라고 하자. 그러면 $f$의 몰리피케이션은 아래와 같이 수렴한다. $$ \lim \limits_{\epsilon \rightarrow 0} f * \eta_\epsilon(x) = \alpha f(x+) + \beta f(x-) $$ $\eta_\epsilon(x)$가 짝함수</description>
    </item>
    
    <item>
      <title>지수함수와 삼각함수의 집합이 정규직교기저임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1108/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1108/</guid>
      <description>두 집합 $\left\{ e^{inx} \right\}{n=-\infty}^\infty$와 $\left\{ \cos nx\ \right\}{n=0}^\infty \cup \left\{ \sin nx \right\}{n=1}^\infty$는 $L^2(-\pi,\ \pi)$의 정규직교기저 이다. 또한 $\left\{ \cos nx \right\}{n=0}^{\infty}$와 $\left\{ \sin nx \right\}_{n=1}^{\infty}$는 $L^2(0,\ \pi)$의 정규직교기저이</description>
    </item>
    
    <item>
      <title>평면 위의 직선을 극 좌표로 표현하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-represent-a-line-on-a-plan-in-polar-coordinates/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-represent-a-line-on-a-plan-in-polar-coordinates/</guid>
      <description>평면위의 직선을 특정 짓는 방법은 여러가지가 있을테지만 직선의 기울기와 $y$절편을 이용하는 방법이 보편적이다. 중고등학생에게도 익숙할 만큼 쉬운 방법이기도 하다. 그림$(1)$과 같은 직선이 있다고 하자. 그러면 기울기$a$와 $y$절편 $b$ 이 두 정보만 알면 평면위의 직선을 나타낼 수 있다. $y=ax+b$라고 표현하거나 그림으로 그려</description>
    </item>
    
    <item>
      <title>박스-칵스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/box-cox-transformation/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/box-cox-transformation/</guid>
      <description>$x &amp;gt; 0$ 에 대해 $g(x) := \begin{cases} \displaystyle {{ x^{\lambda} - 1 } \over { \lambda }} &amp;amp; , \lambda \ne 0 \\ \log x &amp;amp; , \lambda = 0 \end{cases}$ 를 박스-칵스 변환 이라고 한다.$g$ 는 원래 멱변환Power Transformation 이라고 불리나, 박스와 칵스에 의해 소개되어 박스-칵스 변환이라고 부르기도 한다. 박스-칵스 변환의 주된 용도는 데이터를 정규분포에 가깝게 만들거나 데이터의 분산을 안정화하는 것으로, 정규성을 가정하</description>
    </item>
    
    <item>
      <title>리만-르벡 보조 정리</title>
      <link>https://freshrimpsushi.github.io/posts/the-riemann-lebesgue-lemma/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-riemann-lebesgue-lemma/</guid>
      <description>리만-르벡 보조 정리$(\mathrm{The\ Riemann-Lebesgue\ lemma})$ $f \in L^1$이라고 가정하자. 그러면 $\xi \rightarrow \pm \infty$일 때 마다 $\hat{f}(\xi) \rightarrow 0$이다.우선 $f$가 계단 함수라 가정하고 정리가 성립함을 보인 다음 이를 이용하여 $f$가 일반적인 경우에 대해서도 보이겠다. Step 1과 Step 2의 $f$가 같지 않음에 주의하라.** 증명 **Step 1 $f$를 아래와 같은</description>
    </item>
    
    <item>
      <title>특성 함수의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transform-of-characteristic-function-and-step-functino/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transform-of-characteristic-function-and-step-functino/</guid>
      <description>특성 함수의 푸리에 변환은 다음과 같다. $$ \mathcal{F} \left[ \chi_{[-a,a]}(x) \right] = \dfrac{2 \sin(a\xi) }{\xi} $$ 증명 $$ \begin{eqnarray*} \mathcal{F} \left[ \chi_{[-a,a]}(x) \right] &amp;amp;=&amp;amp; \int_{-\infty}^{\infty} \chi_{[-a,a]}(x)e^{-i \xi x } dx \\ &amp;amp;=&amp;amp; \int_{-a}^{a}e^{-i \xi x} dx \\ &amp;amp;=&amp;amp; \dfrac{1}{-i\xi} \left. e^{-i\xi x}\right]_{-a}^{a} \\ &amp;amp;=&amp;amp; \dfrac{1}{-i\xi} \left( e^{-i a \xi} - e^{i a \xi} \right) \\ &amp;amp;=&amp;amp; \dfrac{2}{\xi} \dfrac{e^{ia\xi} -e^{-ia\xi}}{2i} \\ &amp;amp;=&amp;amp; \dfrac{2}{\xi} \sin (a\xi) \end{eqnarray*} $$ ■</description>
    </item>
    
    <item>
      <title>가우스 함수의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transgorm-of-gaussian-function/</link>
      <pubDate>Fri, 24 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transgorm-of-gaussian-function/</guid>
      <description>가우스 함수 $f(x)=e^{-Ax^2}$의 푸리에 변환 은 다음과 같다. $$ \mathcal{F}f = \mathcal{F} \lefte^{-Ax^2} \right=\sqrt{\frac{\pi}{A}}e^{-\frac{\xi ^2}{4A}} $$ **보조정리 : 가우스 적분 $$ \int_{-\infty}^{\infty} e^{-Ax^2} dx= \sqrt{\dfrac{\pi}{A}} $$ $\sqrt{A}x=y$로 치환하고 링크의 가우스 적분 결과를 쓰면 바로 보조정리의 결과를 얻을 수 있다.한편 만약 푸리에 변환 $\mathcal{F}$ 가 $$ \displaystyle \left( \mathcal{F} f \right) ( \xi ) := \int_{\mathbb{R}} f(x) e^{ - i \xi x } dx $$ 가 아닌 $$ \displaystyle \left( \mathcal{F} f \right) ( \gamma )</description>
    </item>
    
    <item>
      <title>다차원 비선형 맵</title>
      <link>https://freshrimpsushi.github.io/posts/multi-dimensional-nonlinear-map/</link>
      <pubDate>Fri, 24 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multi-dimensional-nonlinear-map/</guid>
      <description>1. 맵 $\mathbb{f} : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 이 선형이 아니면 비선형 이라고 한다.어떤 맵이 선형인지 보이는 것은 어렵지만 비선형임을 보이는 것은 쉽고, 선형 문제는 쉽지만 비선형 문제는 어렵다. 이 우주의 거의 모든 것은 비선형이며 비선형은 어렵기 때문에 인간들은 비선형을 선형으로 바꿀 궁리부터 한다.위 그림에서 주어진 곡선은 분명 휘어있긴 하지만, 아주 작은 범위에서 보면 거의</description>
    </item>
    
    <item>
      <title>푸리에 변환의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-fourier-transform/</link>
      <pubDate>Thu, 23 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-fourier-transform/</guid>
      <description>푸리에 변환 의 두 기호 $\mathcal{F}$와 $\hat{\color{white}{a} } $을 편의에 따라 적절하게 사용하겠다. 헷갈릴 여지가 없을 땐 햇$(\hat{})$ 기호를 사용할 것이며 나머지의 경우 확실하게 나타내기 위해 $\mathcal{F}$를 사용할 것이다. 같은 의미를 가지는 기호이므로 헷갈리지 않도록 주의하라. $f \in L^1$이라 가정하자. 그러면 (a)</description>
    </item>
    
    <item>
      <title>준가법성 가법성 가산준가법성 가산가법성 준승법성 승법성</title>
      <link>https://freshrimpsushi.github.io/posts/1096/</link>
      <pubDate>Wed, 22 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1096/</guid>
      <description>**준가법성$(\mathrm{subadditivity})$ 함수 $f\ :\ X \rightarrow Y$가 주어졌다고 하자. $a,\ b \in X$라고 하자. 그러면 아래와 같은 식이 성립할 때 함수 $f$는 준가법성 을 가진다고 한다. $$ f(a+b) \le f(a)+f(b) $$ 절댓값을 예로 들 수 있다. $$ |3+(-4)| \le |3|+|-4| $$ 다른 예로 $f(x)=2x+3$이라 하면 $$ 13=f(2+3) \le f(2)+f(3)=7+9=16 $$ **가법성$(\mathrm</description>
    </item>
    
    <item>
      <title>카라테오도리 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-caratheodory-theorem/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-caratheodory-theorem/</guid>
      <description>모든 $A \subset X$에 대해서 아래의 식이 성립하면 $E \subset X $가 카라테오도리 조건$(\mathrm{Caratheodory\ condition})$ 을 만족시킨다고 한다. $$ \mu^{ * }(A) = \mu^{ * }(A\cap E) + \mu^{ * }(A \cap E^c)\quad \cdots (P) $$ $\mu^{ * }$은 외측도 이다.**카라테오도리 정리$(\mathrm{Caratheodory\ theorem})$ $\mathcal{L}$을 카라테오도리 조</description>
    </item>
    
    <item>
      <title>다차원 선형 맵</title>
      <link>https://freshrimpsushi.github.io/posts/multi-dimensional-linear-map/</link>
      <pubDate>Mon, 20 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multi-dimensional-linear-map/</guid>
      <description>1. 맵 $T_{A} : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 가 모든 $a,b \in \mathbb{R}$ 과 $\mathbb{x}, \mathbb{y} \in \mathbb{R}^{m}$ 에 대해 $T_{A} ( a \mathbb{x} + b \mathbb{y} ) = a T_{A} ( \mathbb{x} ) + b T_{A} ( \mathbb{y} )$ 를 만족하면 $T_{A}$ 가 **선형** 라고 한다.실제로 맵 $T_{A}$ 에 대응하는 $m \times m$ 사이즈 행렬 $A$ 는 $\displaystyle A ( a \mathbb{x} + b \mathbb{y} ) = a A \mathbb{x} + b A \mathbb{y} $ 을 만족한다. 본질적으로 $T_{A}$ 와 $A$ 는 같은 것이므로 따로 구분할 이유는 없고 $A$ 자체를 맵이라고 불러도 무방하다.한편 이러한 선</description>
    </item>
    
    <item>
      <title>비선형 1계 미분방정식의 경계의 직선화</title>
      <link>https://freshrimpsushi.github.io/posts/straightening-the-boundary-of-nonlinear-first-order-pde/</link>
      <pubDate>Mon, 20 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/straightening-the-boundary-of-nonlinear-first-order-pde/</guid>
      <description>비선형 1계 미분 방정식 의 특성 방정식 을 쉽게 풀기 위한 방법 중 하나는 정의역 $\Omega)$의 경계 $\partial \Omega$ 어떤 작은 부분인 $\Gamma$를 곧게 펴주는 것이다. 이는 항상 가능한 일이므로 앞으로 경계 위의 점 $x^0$의 근방에서는 경계가 곧은 직선이라고 처음부터 가정하고 문제를 접근할 수 있다. 이를 $\mathrm{straightening\ the\ boundary}$라고 한다.$\</description>
    </item>
    
    <item>
      <title>일반화된 횔더 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-hoelder-inequality/</link>
      <pubDate>Sun, 19 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-hoelder-inequality/</guid>
      <description>유클리드 공간에서의 횔더 부등식실해석학에서의 횔더 부등식**횔더 부등식$(\mathrm{Hoelder\ inequality})$ $ \dfrac{1}{p}+\dfrac{1}{p&#39;}=1$을 만족시키는 두 상수 $1&amp;lt;p&amp;lt;\infty$, $1&amp;lt;p&#39; &amp;lt;\infty$가 주어졌다고 하자. $u \in L^p(\Omega)$, $v\in L^{p&#39;}(\Omega)$라고 가정하자. 그러면 $uv \in L^1(\O</description>
    </item>
    
    <item>
      <title>수치해석학에서의 B-스플라인 B-Spline in Numerical Analysis</title>
      <link>https://freshrimpsushi.github.io/posts/1045/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1045/</guid>
      <description>함수해석학에서의 B-스플라인* 글과 수식이 읽기 싫으면 그냥 그림으로 보고 이해해도 무방하다.구간 $[a,b]$ 를 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b $ 와 같은 노드 포인트들로 쪼갰다고 하자. 주어진 자유도 $K$ 에 대해서 $x_{-K} &amp;lt; x_{-K + 1} &amp;lt; \cdots &amp;lt; x_{-1} &amp;lt; x_{0}$ 과 $x_{N} &amp;lt; x_{N + 1} &amp;lt; \cdots &amp;lt; x_{N+K-1} &amp;lt; x_{N+K}$ 의 추가적인 노드를 생각한다. $i$번째 노드 포인트와 자유도 $1 \le k \le K$ 에 디펜드하는</description>
    </item>
    
    <item>
      <title>횔더 연속 함수 공간</title>
      <link>https://freshrimpsushi.github.io/posts/spaces-of-hoelder-continuous-functions/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spaces-of-hoelder-continuous-functions/</guid>
      <description>**연속 함수 공간$(\mathrm{spaces\ of\ continuous\ functions})$ 열린 집합 $\Omega \subset \mathbb{R}^n$가 있다고 하자. 음이 아닌 정수 $m$에 대해서 $C^m(\Omega)$를 아래와 같은 조건을 만족시키는 모든 함수 $\phi$들의 집합이라고 정의한다.$|\alpha| \le m$인 모든 멀티 인덱스 $\alpha$에 대해 $D^</description>
    </item>
    
    <item>
      <title>R 에서 데이터 프레임 열기준으로 정렬하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-sort-data-frame-by-a-column/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-sort-data-frame-by-a-column/</guid>
      <description>R 에서 데이터를 정렬하는 것 자체는 sort() 함수를 사용하면 간단하게 할 수 있으나, 기본적으로 sort() 함수는 벡터만을 소팅한다. 그러나 실제로는 데이터 프레임의 수많은 카테고리를 다루기 때문에 열 단위로도 정렬할 수 있는 방법이 필요한 경우가 많다. x&amp;lt;-c(pi,3,99,0,-1) order(x) x[order(x)] head(iris) head(iris[order(iris$Petal.Length),]) order() 함수는 주어진 벡터가 오름차순이 되도록 하는 데이터의 넘버를 반환해준다.&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20190415_132452.png&amp;rdquo;</description>
    </item>
    
    <item>
      <title>푸리에 변환 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-fourier-transform/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-fourier-transform/</guid>
      <description>유한한 구간을 주기로 갖는(=유한한 구간에서 정의된) 함수는 푸리에 급수를 이용해서 근사할 수 있었다. 이는 유용하지만 항상 주기 함수에 대해서만 다루는게 아니므로 비주기 함수에 대해서도 비슷한 역할을 하는 도구가 필요하다. 다시 말해 전체 구간을 주기로 생각하여 주기가 $(-\infty, \infty)$인 함수의 근사를 구하는 과정에서 푸리에 변환$(\mat</description>
    </item>
    
    <item>
      <title>수치해석에서의 스플라인</title>
      <link>https://freshrimpsushi.github.io/posts/spline/</link>
      <pubDate>Thu, 16 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spline/</guid>
      <description>인터폴레이션이란 정확한 함수를 복원하는 게 아니라 그와 유사하면서도 다루기 편한 함수를 구하는 것이 목적이다. 물론 익스플릭시트Explicit하고 계산이 쉬워지도록 구할 수 있다면야 제일 좋겠지만, 이 우주는 그렇게 만만한 곳이 아니다.문제에 따라서는 간단한 부분을 빨리 풀고 복잡한 부분을 정교하게 풀어야할 수도 있고, 연속성조차 보장되지 않</description>
    </item>
    
    <item>
      <title>R 에서 히스토그램 더 세밀하게 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-histogram-class-range/</link>
      <pubDate>Wed, 15 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-histogram-class-range/</guid>
      <description>R 에서는 hist() 함수를 통해 히스토그램을 쉽게 그려볼 수 있다. 이 때 계급의 크기는 R 이 알아서 판단하고 결정하는데, 좀 더 세밀하게 보기 위해서는 nclalss 옵션을 사용하면 된다. set.seed(150421) x&amp;lt;-runif(50) win.graph(7,4); par(mfrow=c(1,2)) hist(x) hist(x,nclass=20) 위 코드를 실행시킨 결과는 다음과 같다.&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;12.png&amp;rdquo; height=&amp;ldquo;376&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/9943FF395CB03EB809&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;664&amp;rdquo;/&amp;gt;</description>
    </item>
    
    <item>
      <title>에르미트 인터폴레이션</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-interpolation/</link>
      <pubDate>Tue, 14 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-interpolation/</guid>
      <description>서로 다른 $x_{1} , \cdots , x_{n}$ 의 데이터 $(x_{1}, y_{1} , y&#39;_{1}) , \cdots , (x_{n} , y_{n}, y&#39;_{n})$ 에 대해 $\begin{cases} p (x_{i} ) = y_{i} \\ p&#39;(x_{i} ) = y&#39;_{i} \end{cases}$ 와 $\deg H \le 2n-1$ 을 만족하는 폴리노미얼 $H$ 를 에르미트 인터폴레이션이라고 한다.**[1]** 존재성과 유일성 : 주어진 데이터에 대해서 $H$ 는 유일하게 존재한다.**[2]** 라그랑주 폼 : $\displaystyle H_{n} (x) = \sum_{i=1}^{n} y_{i} h_{i} (x) + \sum_{i=1}^{n} y&#39;_{i} \tilde{h}_{i} (x)$**[3]** 뉴턴 계차상 폼 : $\displaystyle H_{n} (x) = f(x_{1}) + (x - x_{1})</description>
    </item>
    
    <item>
      <title>정규직교기저 완비 정규직교집합</title>
      <link>https://freshrimpsushi.github.io/posts/orthonormal-basis-complete-orthonormal-set/</link>
      <pubDate>Tue, 14 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthonormal-basis-complete-orthonormal-set/</guid>
      <description>**정규직교집합이 가지는 동치조건 $\left\{ \phi_n \right\}1^\infty$가 $L^2(a,b)$의 정규직교집합 이고 $f \in L^2(a,b)$라고 하자. 그러면 아래의 조건은 모두 동치이다.$(a)$ 모든 $n$에 대해서 $\left&amp;lt; f, \phi_n \right&amp;gt;=0$이면, $f=0$이다.$(b)$ 모든 $f\in L^2(a,b)$에 대해서,</description>
    </item>
    
    <item>
      <title>베셀 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/bessels-inequality/</link>
      <pubDate>Mon, 13 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bessels-inequality/</guid>
      <description>**베셀 부등식$(\mathrm{Bessel&amp;rsquo;s\ inequality})$ $ \left\{ \phi_n \right\}1^\infty $가 $L^2(a,b)$에서의 정규직교집합 $(\mathrm{orthonormal\ set})$이라고 하자. 그리고 $f\in L^2(a,b)$라고 하자. 그러면 아래의 부등식이 성립하고 이를 베셀 부등식이라 한다. $$ \sum \limits{n=1}^\infty | \left&amp;lt;f, \phi_n \right&amp;gt;|^2 \le | f | ^2 $$ **$L^2$ 공간 아래의 식을 만족하는 함수를 제곱적분가능$</description>
    </item>
    
    <item>
      <title>에르미트-제노키 공식</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-genocchi-formula/</link>
      <pubDate>Sun, 12 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-genocchi-formula/</guid>
      <description>서로 다른 $x_{0}, \cdots , x_{n}$ 에 대해 $f \in C^{n} \left( \mathscr{H} \left\{ x_{0}, \cdots , x_{n} \right\} \right) $ 이라고 하자. 그러면 $\displaystyle \tau_{n} := \left\{ ( t_{1} , \cdots , t_{n} ) : t_{i} \ge 0 \land \sum_{i=1}^{t} t_{i} \le 1 \right\}$ 과 $\displaystyle t_{0} = 1 - \sum_{i=1}^{n} t_{i}$ 에 대해 $\displaystyle f [ x_{0}, \cdots , x_{n} ] = \int \cdots \int_{\tau_{n}} f^{(n)} ( t_{0} x_{0} + \cdots + t_{n} x_{n} ) dt_{1} \cdots dt_{n}$* $\mathscr{H} \left\{ a,b,c, \cdots \right\} $ 는 $a,b,c, \cdots$ 를 포함하는 가장 작은 구간을 나타낸다.에르미트-제노키 공식은 그 자체가 복잡한 수식으로 서술되는 것과 달리 계차상을</description>
    </item>
    
    <item>
      <title>함수열의 수렴과 놈</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-norm-of-a-sequence-of-function/</link>
      <pubDate>Sun, 12 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-norm-of-a-sequence-of-function/</guid>
      <description>$\left\{ f_n \right\}$를 구간 $[a,b]$에서 조각마다 매끄러운 함수들의 수열이라고 하자. 그러면 다음과 같은 조건을 만족할 때 $f_n$이 $f$로 놈 센스에서 수렴$(\mathrm{converge\ in\ norm})$한다 고 한다. $$ | f_n - f| \rightarrow 0 $$ $$ \mathrm{or} \quad \lim \limits_{n\rightarrow 0} | f_{n}-f|=0 $$ 함숫값의 수렴은 엡실론-델타 논법을 통해 정의하고 이때,</description>
    </item>
    
    <item>
      <title>R 에서 데이터 표준화하기 표준화된 잔차 보기</title>
      <link>https://freshrimpsushi.github.io/posts/1026/</link>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1026/</guid>
      <description>R 은 통계에 특화된 언어인만큼 Z-score $\displaystyle z:= {{x - \mu} \over {\sigma}}$ 를 구해야할 일이 많다. 이 때 내장된 scale() 함수를 사용하면 편리하다.예제로써 $\mathbb{x} = ( 1, \cdots , 10 )$ 이라는 벡터를 표준화해보자.center(평균)나 scale(표준편차)과 같이 지저분하게 뜨는 게 보기 싫다면 그냥 벡터를 취하면 된다.한편 표준화를 가장 많이 하게 되는 일 중 하나가 회귀분석 후 잔차 그</description>
    </item>
    
    <item>
      <title>뉴턴 계차상 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-newton-divided-difference-formula/</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-newton-divided-difference-formula/</guid>
      <description>서로 다른 $x_{0} , \cdots , x_{n}$ 의 데이터 $(x_{0}, f(x_{0} )) , \cdots , (x_{n} , f( x_{n} ) )$ 에 대해 $\displaystyle p_{n} (x) =\sum_{i=0}^{n} f [ x_{0} , \cdots , x_{i} ] \prod_{j=0}^{i-1} (x - x_{j} ) $복잡해보이지만 $n=1,2,3$ 에 대해서 실제로 전개를 해보면 다음과 같이 단순하게 나타난다. $$ p_{0} (x) = f(x_{0}) $$ $$ p_{2} (1) = f( x_{0} ) + (x - x_{0} ) f [ x_{0} , x_{1} ] $$ $$ p_{2} (x) = f( x_{0} ) + (x - x_{0} ) f [ x_{0} , x_{1} ] + ( x - x_{0} ) ( x - x_{1} ) f [ x_{0} , x_{1} , x_{2} ] $$ 뉴턴 계차상 공</description>
    </item>
    
    <item>
      <title>1차원 파동 방정식 1</title>
      <link>https://freshrimpsushi.github.io/posts/dimension-wave-equation/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dimension-wave-equation/</guid>
      <description>1차원에서의 파동 방정식은 아래와 같다. $$ \dfrac{\partial ^2 f }{\partial x^2} = \dfrac{1}{v^2}\dfrac{\partial ^2 f}{\partial t^2} $$ $v$는 파동의 전파 속력이다.** **0. 위 그림 1과 같이 속력이 $v$로 일정한 파동이 있다고 하자. 시각 $t$에서 $x$점의 파동의 변위를 $f(x,t)$라고 하자. 처음 실의 변위를 $g(x)=f(x,0)$라고 할 때 그로부터 $t$초 후의 실의 변위가 어떻게 되는지 알</description>
    </item>
    
    <item>
      <title>수치해석에서의 경사하강법</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-descent-method/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-descent-method/</guid>
      <description>머신러닝에서의 경사하강법스칼라 함수 $\varphi : \mathbb{R}^{n} \to \mathbb{R}$ 을 비용 함수Cost Function 이라고 한다. 비용 함수 $ \varphi ( \mathbb{x} ) $ 의 극소값을 구하기 위해 $\mathbb{x} = \mathbb{x}{n}$ 에서 $\varphi ( \mathbb{x}{n+1} ) &amp;lt; \varphi ( \mathbb{x}{n} ) $ 를 만족시키는 $\mathbb{x}{n+1}$ 를 찾는 알고리즘을 하강법Descent Method 이라고 한다.$\varphi$ 를 비용 함수라고 부를만한 예로써 집을 한 채 짓는다고 하자. 집 한 채에 들어가는 자원은</description>
    </item>
    
    <item>
      <title>네츄럴 인베리언트 메져</title>
      <link>https://freshrimpsushi.github.io/posts/natural-invariant-measure/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/natural-invariant-measure/</guid>
      <description>카오틱한 동역학계에서 충분히 시간이 지난 뒤의 스테이트를 확률적으로 나타낸 분포함수를 네츄럴 (인베리언트) 메져 라고 한다.예로써 로지스틱 맵 $g_{4} (x) = 4 x (1 -x)$ 를 생각해보면 카오틱한 시스템이기 때문에 초기값 $x_{0} \in [0,1]$ 만 가지고는 충분히 큰 $N$ 에 대해 $x_{N} = g_{4}^{N} (x_{0})$ 을 전혀 예측할 수 없다. 하지만 이렇게 카오틱한 오빗이 반드시 $[0,1]$ 의 모든 지점에서 고른 분포를</description>
    </item>
    
    <item>
      <title>전기역학에서의 운동량 보존</title>
      <link>https://freshrimpsushi.github.io/posts/law-of-conservation-of-momentum-in-electromagnetics/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/law-of-conservation-of-momentum-in-electromagnetics/</guid>
      <description>**전자기학에서의 운동량 보존 법칙 $$ \dfrac{d \mathbf{p}}{dt} =-\epsilon_0\mu_0\dfrac{d}{dt}\int_{\mathcal{V}} \mathbf{S} d\tau + \oint_{\mathcal{S}} \mathbf{T} \cdot d\mathbf{a} $$ 뉴턴의 제 2법칙에 의하면 물체가 받는 힘과 그 물체의 운동량의 변화량은 같다. $$ \mathbf{F} = \dfrac{d \mathbf{p}}{dt} $$ $\mathbf{p}$는 부피 $\mathcal{V}$속의 입자의 총 역학적 운동량이다. 전자기장에 저장된 운동량과 구분하기 위해 굳이 &amp;lsquo;역학적&amp;rsquo; 운동량</description>
    </item>
    
    <item>
      <title>전자기장의 각운동량</title>
      <link>https://freshrimpsushi.github.io/posts/angular-momentum-of-electromagnetic-field/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/angular-momentum-of-electromagnetic-field/</guid>
      <description>전자기장에 저장된 각운동량은 다음과 같다. $$ \mathbf{\ell} = \mathbf{r} \times \mathbf{g}=\epsilon_0\big( \mathbf{r} \times (\mathbf{E} \times \mathbf{B} )\big) $$ $\mathbf{g}$는 전자기장에 저장된 운동량 밀도 이다.전자기장은 단순히 전하들 사이에 작용하는 전자기력의 매개체일 뿐 아니라 스스로 에너지 도 가지고 있다. $$ u =\dfrac{1}{2} \left( \epsilon_0 E^2 + \dfrac{1}{\mu_0} B^2 \right) $$ 그리고 운동량도 가지고 있어서 물질의 운동량과 전자기장의 운동량의 합이 보존되</description>
    </item>
    
    <item>
      <title>스칼라 필드의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-in-scalar-field/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-in-scalar-field/</guid>
      <description>벡터장의 미분계수 :야코비 행렬스칼라 필드 $f : \mathbb{R}^{n} \to \mathbb{R}$ 에 대해 한 점 $\mathbb{x}{0} \in \mathbb{R}^{n}$ 에서 함수의 증가율이 가장 큰 방향을 나타낸 벡터를 $\mathbb{x}{0}$ 에서 $f$ 의 그래디언트 라고 한다.스칼라장의 예시로써 위의 그림을 생각해보자. 위 그림은 $z(x,y) = x^2 - y^2$ 와 같이 정의된 함수 $z : \mathbb{R}^{2} \to \mathbb{R}$ 을 시각적으로 나타낸 것이다. $y= f(x)$ 와 같은 곡선에서는 변화율을 구할만할 방향이 $x$ 축 뿐이었기</description>
    </item>
    
    <item>
      <title>바이퍼케이션 다이어그램</title>
      <link>https://freshrimpsushi.github.io/posts/bifurcation-diagram/</link>
      <pubDate>Sat, 27 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bifurcation-diagram/</guid>
      <description>동역학계에서 파라매터의 변화에 따라 나타나는 오빗을 표현한 그림을 바이퍼케이션 다이어그램 이라고 한다.예로써 로지스틱 패밀리를 생각해보면 파라매터 $a$ 의 변화에 따라 충분히 큰 $N$ 에 대해 $x_{N}$ 의 값은 다음 바이퍼케이션 다이어그램의 검은색 범위 안에 포함된다고 예상할 수 있다. $1&amp;lt;a&amp;lt;3$ 일 때는 하나의 선인 것을 보아 $x_N$ 은 하나의 고정점에서 머무르고, $3 &amp;lt; a &amp;lt;</description>
    </item>
    
    <item>
      <title>넌리니어 시스템을 풀기 위한 뉴턴 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/newton-method-for-nonlinear-system/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newton-method-for-nonlinear-system/</guid>
      <description>1차원에서의 뉴턴-랩슨 메소드$\mathbb{f} ( \mathbb{x} ) := \begin{bmatrix} f_{1}( \mathbb{x} ) \\ \vdots \\ f_{N} ( \mathbb{x} ) \end{bmatrix} $ 와 같은 다변수 함수 $\mathbb{f} : \mathbb{R}^{N} \to \mathbb{R}^{N}$ 가 $\mathbb{f} \in C^{2} \left( N ( \alpha ) \right)$ 이고 $\mathbb{f} ( \alpha ) = \mathbb{0}$, $\left[ D \mathbb{f} ( \alpha ) \right]^{-1}$ 이 존재한다고 하자. $\alpha$ 와 충분히 가까운 초기값 $\mathbb{x}_{0}$ 에 대해 $\displaystyle \mathbb{x}_{n+1} := \mathbb{x}_{n} - \left[ D \mathbb{f} ( \mathbb{x}_{n} ) \right]^{-1} f ( \mathbb{x}_{n} ) $ 과 같이 정의된 수열 $\left\{ \mathbb{x}_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 쿼드러틱하게 수렴한다</description>
    </item>
    
    <item>
      <title>딥러닝에서의 드롭아웃</title>
      <link>https://freshrimpsushi.github.io/posts/dropout/</link>
      <pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dropout/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20190328_143431.png&amp;rdquo; height=&amp;ldquo;505&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/994D443B5C9C5CFF12&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;450&amp;rdquo;/&amp;gt;** **드롭아웃** 이란 인공 신경망의 뉴런을 확률적으로 사용하지 않음으로써 과적합을 방지하는 기법이다.언뜻 생각하면 그냥 학습을 덜 하는 것이고 실제로도 어느정도는 맞는 말이다. 일정 확률로 뉴런을 사용하지 않다보면 &amp;lsquo;영향력이 지나치게 강한&amp;rsquo; 뉴런이 무시될 수도 있다. 영향력이 지나치게 강하다는 것</description>
    </item>
    
    <item>
      <title>R 에서 야코비 행렬 헤세 행렬 구하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-jacobian-matrix-hessian-matrix-in-r/</link>
      <pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-jacobian-matrix-hessian-matrix-in-r/</guid>
      <description>R 에서 야코비 행렬과 헤세 행렬을 구하기 위해서는 numDeriv 패키지의 jacobian() 함수와 hessian() 함수를 사용한다. install.packages(&amp;#34;numDeriv&amp;#34;) library(numDeriv) f &amp;lt;- function(v) {c(v[1]^2 + v[2]^2 - 1, sin(pi*v[1]/2) + v[2]^3)} g &amp;lt;- function(v) {(v[1])^3+(v[2])^2} jacobian(f, c(1,1)) hessian(g, c(1,1)) 위 코드를 실행시킨 결과는 다음과 같다. 위는 $f(x,y) := \begin{bmatrix} x^2 + y^2 -1 \\ \displaystyle \sin {{ \pi } \over {2} } x + y^3 \end{bmatrix}$ 의 야코비 행렬에 $x=y=1$ 을 대입한 결과, 아래는 $g(x,y) := x^3 + y^2$ 의 헤세 행렬에 $x=y=1$ 을 대입한 결과다.실제로 $f$ 의 야코비 행렬은 $J =</description>
    </item>
    
    <item>
      <title>푸아송 방정식에 대한 디리클레 문제의 해의 유일성</title>
      <link>https://freshrimpsushi.github.io/posts/uniqueness-of-solution-of-the-dirichlet-problem-of-poissons-equation/</link>
      <pubDate>Sun, 21 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniqueness-of-solution-of-the-dirichlet-problem-of-poissons-equation/</guid>
      <description>**디리클레 문제$(\mathrm{Dirichlet\ Problem})$ 주어진 영역의 경계값$(\mathrm{boundart\ value})$이 주어졌을 때 그 내부의 편미분방정식$(\mathrm{PDE})$을 푸는 해를 찾는 문제이다.푸아송 방정식에 대한 디리클레 문제의 해는 존재하면 유일하다. $\Omega \subset \mathbb{R}^n</description>
    </item>
    
    <item>
      <title>딥러닝에서의 소프트맥스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/softmax-function/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/softmax-function/</guid>
      <description>본 포스트는 컴퓨터보다는 통계와 수학에 더 익숙한 사람들을 위해 작성되었다.$\mathbb{x} := x_{1} , \cdots , x_{n} \in \mathbb{R}^{n}$ 이라고 하자. $\displaystyle \sigma ( \mathbb{x} ) = {{ e^{x_{j}} } \over {\sum_{i=1}^{n} e^{x_{i}} }} $ 에 대해 $\sigma( \mathbb{x} ) := \left( \sigma_{1} (\mathbb{x}) , \cdots , \sigma_{n} (\mathbb{x} ) \right) $ 와 같이 정의된 $\sigma : \mathbb{R}^{n} \to (0,1)^{n}$ 을 **소프트맥스 함수** 라고 한다.소프트맥스 함수는 활성화 함수의 일종으로써, 정의역이 $\mathbb{R}^{n}$ 이라는 특징이 있</description>
    </item>
    
    <item>
      <title>조화함수의 최대원리</title>
      <link>https://freshrimpsushi.github.io/posts/maximum-principle-of-harmonic-functions/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maximum-principle-of-harmonic-functions/</guid>
      <description>최대원리$(\mathrm{Maximum\ principle})$ $\Omega \subset \mathbb{R}^n$가 열려있고 유계라고 하자. 그리고 함수 $u : \Omega \rightarrow \mathbb{R}$가 $u \in C^2(\Omega) \cap C(\bar \Omega)$이고 라플라스 방정식을 만족한다(=** 조화함수**** )고 하자. 그러면$\mathrm{(i)}$ 최대 원리 $$ \max \limits_{\bar \Omega} u = \max \limits_{\partial \Omega} u \quad \left( \mathrm{or} \</description>
    </item>
    
    <item>
      <title>헤세 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/hessian-matrix/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hessian-matrix/</guid>
      <description>$D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 스칼라 함수 $f : D \to \mathbb{R}$ 에 대해 다음과 같은 행렬 $H \in \mathbb{R}^{n \times n}$ 을 $f $ 의 헤세 행렬 이라고 한다. $$ H := \begin{bmatrix} {{\partial^2 f } \over {\partial x_{1}^2 }} &amp;amp; \cdots &amp;amp; {{\partial^2 f } \over { \partial x_{1} \partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial^2 f } \over {\partial x_{n} \partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial^2 f_{m} } \over {\partial x_{n}^2 }} \end{bmatrix} $$ 야코비 행렬이 함수의 고차원적인 도함수에 해당한다면, 헤세 행렬은 고차원적인 이계도함수라고 볼 수 있다. 물론</description>
    </item>
    
    <item>
      <title>딥러닝에서의 활성화 함수</title>
      <link>https://freshrimpsushi.github.io/posts/activation-function/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/activation-function/</guid>
      <description>본 포스트는 컴퓨터보다는 통계와 수학에 더 익숙한 사람들을 위해 작성되었다.실제 생물의 역치를 모방한 비선형 함수를 활성화 함수 라고 한다.역치란 생물이 자극에 대해 어떤 반응을 일으키는 데 필요한 최소한의 자극의 세기로써, 딥러닝은 이를 모방하기 위해 각 노드의 계산 결과에 활성화 함수를 취해 다음 레이어로 넘긴다. 이러한 비선형적 보정이 없다면 딥러</description>
    </item>
    
    <item>
      <title>부피 속의 전하가 받는 전자기력</title>
      <link>https://freshrimpsushi.github.io/posts/total-electromagnetic-force-on-charge-in-volume-v/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/total-electromagnetic-force-on-charge-in-volume-v/</guid>
      <description>부피 $\mathcal{V}$속의 모든 전하가 받는 전자기력은 $$ \mathbf{F} =\oint_{\mathcal{S}} \mathbf{T} \cdot d\mathbf{a} -\epsilon_0\mu_0\dfrac{d}{dt}\int_{\mathcal{V}} \mathbf{S} d\tau $$ $\mathcal{S}$는 부피 $\mathcal{V}$의 경계면, $\mathbf{T}$는 **맥스웰 변형력 텐서** , $\mathbf{S}$는 **포인팅 벡터** 이다.**Part 1. **로런츠 힘 법칙** 에 의해 전하가 받는 힘</description>
    </item>
    
    <item>
      <title>딥러닝이란</title>
      <link>https://freshrimpsushi.github.io/posts/deep-learning/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/deep-learning/</guid>
      <description>딥러닝 은 인공 신경망을 이용한 머신러닝의 일종으로, 특히 인공 신경망을 구성할 때 복수의 레이어를 사용하는 기법을 말한다.인간의 두뇌가 뉴런들의 복잡한 연결관계로 구성된 것처럼 딥러닝 역시 인공 신경망을 보다 복잡하게 연결해서 퍼포먼스를 올린다. 감각세포에서 받은 자극이 척수를 통해 뇌로 전달되는 것처럼, 인공 신경망은 여러 레이어를 거쳐가며 계</description>
    </item>
    
    <item>
      <title>맥스웰 변형력 텐서</title>
      <link>https://freshrimpsushi.github.io/posts/maxwell-stress-tensor/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maxwell-stress-tensor/</guid>
      <description>**맥스웰 변형력 텐서$(\mathrm{Maxwell\ tress\ tensor})$ $$ \mathbf{T}=\overleftrightarrow{\mathbf{T}}=\begin{pmatrix} T_{xx} &amp;amp; T_{xy} &amp;amp; T_{xz} \\ T_{yx} &amp;amp; T_{yy} &amp;amp; T_{yz} \\ T_{zx} &amp;amp; T_{zy} &amp;amp; T_{zz} \end{pmatrix} $$ $$ T_{ij}=\epsilon_0 \left( E_iE_j-\dfrac{1}{2}\delta_{ij}E^2 \right) + \dfrac{1}{\mu_0}\left(B_iB_j-\dfrac{1}{2}\delta_{ij}B^2 \right) $$ $\delta_{ij}$는 **크로네커 델타** .** **0. $2$차 **텐서** 의 한 종류로 위와 같이 정의된다. 어느 부피 $\mathcal{V}$속의 전하가 받는 힘을 간단히 나타내기 위해서 쓰인다.</description>
    </item>
    
    <item>
      <title>야코비 행렬 혹은 자코비 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/jacobian-matrix/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jacobian-matrix/</guid>
      <description>스칼라장의 미분계수 : 델 연산자$D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 벡터 함수 $\mathbb{f} : D \to \mathbb{R}^{m}$ 가 각각의 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ 과 같이 정의되었다고 하자. $$ J := \begin{bmatrix} {{\partial f_{1} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{1} } \over {\partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial f_{m} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{m} } \over {\partial x_{n} }} \end{bmatrix} $$ 을 $\mathbb{f}$</description>
    </item>
    
    <item>
      <title>머신러닝에서의 경사하강법</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-descent-algorithm/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-descent-algorithm/</guid>
      <description>수치해석학에서의 경사하강법* 본 포스트는 컴퓨터보다는 통계와 수학에 더 익숙한 사람들을 위해 작성되었다.손실 함수의 기울기를 이용해 손실 함수의 극소값을 찾는 알고리즘을 **경사하강법** 이라고 한다.단, 이 때의 손실 함수 $L$ 은 데이터 셋 $X$ 가 픽스 된 상태에서 가중치와 바이어스에 대한 함수로 본다. 만약 인풋 데이터가 $\mathbb{x} \in \mathbb{R}^{m}$ 처럼 생겼다면 $L$ 은</description>
    </item>
    
    <item>
      <title>물리학에서 텐서란</title>
      <link>https://freshrimpsushi.github.io/posts/tensor/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tensor/</guid>
      <description>단언컨대 텐서에 대한 가장 쉬운 설명글이니 도대체 텐서가 뭔지 몰라서 찾아 들어온 물리학과 학부생이라면 꼭 읽기를 권한다. 정말 쉽게 써놨으니 꼭 읽어라. 두 번 읽어라. 수학적으로 틀린 부분에 대한 지적은 받지 않습니다. 음수를 배우지 않은 사람에게 &amp;lsquo;작은 수에서 큰 수를 뺄 수는 없다&amp;rsquo;, 허수를 배우지 않은 사람에게 &amp;lsqu</description>
    </item>
    
    <item>
      <title>슈발치언 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/schwarzian-derivative/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schwarzian-derivative/</guid>
      <description>$p$ 가 스무스한 맵 $f$ 의 고정점 혹은 피리어딕 포인트라고 하자.1. $f&#39;(c) = 0$ 인 $c$ 를 $f$ 의 크리티컬 포인트Critical Point 라고 한다.2. $p$ 의 베이신이 길이가 무한한 인터벌을 포함하면 인피닛 베이신Infinite Basin 이라고 한다.3. $\displaystyle S(f)(x) := {{f&#39;&#39;&#39;(x) } \over { f&#39;(x) }} - {{3} \over {2}} \left( {{f&#39;&#39;&#39;(x) } \over { f&#39;(x) }} \right)^2$ 를 $f$ 의 슈발치언 도함수 라고 한다.4. $f&#39;(x) \ne 0$ 인 모든 $x$ 에 대해</description>
    </item>
    
    <item>
      <title>R 에서 복소수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-complex-number-in-r/</link>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-complex-number-in-r/</guid>
      <description>R 에는 복소수 자료형이 구현되어있다. 굳이 스스로 구현할 필요 없이 가져다 쓰기만 하면 된다. 사칙연산은 물론 복소수를 다룰 때 빠질 수 없는 여러가지 함수 역시 만들어져 있다.$z_{1} : = 1- i$, $z_{2} := 1+ i$ 이라고 하자. z_1 = 1-1i z_2 = 1+1i z_1 + z_2 z_1 - z_2 z_1 * z_2 z_1 / z_2 Re(z_1) Im(z_1) Mod(z_1) Arg(z_1) Conj(z_1) 위의 코드를 실행시키면 다음과 같은 결과를 얻을 수 있다.$z_{1} + z_{2} =</description>
    </item>
    
    <item>
      <title>포인팅 정리와 포인팅 벡터</title>
      <link>https://freshrimpsushi.github.io/posts/poyntings-theorem-and-poynting-vecrtor/</link>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poyntings-theorem-and-poynting-vecrtor/</guid>
      <description>*포인팅 정리$(\mathrm{Poynting&amp;rsquo;s\ theorem})$ 전자기력이 전하에 해준 일은 전자기장에 저장된 에너지의 감소량과 경계면을 통해 밖으로 새어나간 에너지를 더한 것과 같다. $$ \begin{eqnarray} \dfrac{dW}{dt} &amp;amp;=&amp;amp; -\dfrac{d}{dt} \int_{\mathcal{V}} \dfrac{1}{2} \left( \epsilon_0 E^2 + \dfrac{1}{\mu_0} B^2 \right) d\tau - \dfrac{1}{\mu_0} \oint_{\mathcal{S}} (\mathbf{E} \times \mathbf{B}) \cdot d \mathbf{a} \\ &amp;amp;=&amp;amp; -\dfrac{d}{dt} \int_{\mathcal{V}} u d\tau - \oint_{\mathcal{S}}\mathbf{S} \cdot d\mathbf{a} \end{eqnarray*} $$ $\mathcal{S}$는 $\mathcal{V}$의</description>
    </item>
    
    <item>
      <title>맥스웰 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/maxwells-equations/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maxwells-equations/</guid>
      <description>**** 맥스웰 방정식$(\mathrm{Maxwell&amp;rsquo;s\ equations})$ $(\mathrm{i}) \quad \nabla \cdot \mathbf{E}=\dfrac{1}{\epsilon_0}\rho $ 가우스 법칙 $(\mathrm{ii}) \quad \nabla \cdot \mathbf{B}=0$ (자기장에 대한 가우스 법칙)$(\mathrm{iii}) \quad \nabla \times \mathbf{E} = -\dfrac{\partial \mathbf{B}}{\partial t}$ 패러데이 법칙 $(\mathrm{iv}) \quad \nabla \times \mathbf{B} = \mu_0 \mathbf{J}+\mu_0\epsilon_0\dfrac{\partial \mathbf{E}}{\partial t} $ 앙페르 법칙 맥스웰이 맥스웰 방정식을 완성시키기 전에 전기장과 자기장에 관한 4개의 방정식은 다음과 같았다.</description>
    </item>
    
    <item>
      <title>R 에서 정적분 구하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-integrate-in-r/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-integrate-in-r/</guid>
      <description>R 에서 미분계수 구하는 법 R 에서 정적분을 구하기 위해선 integrate() 함수를 사용할 수 있다. 예를 들어 $$ \displaystyle \int_{0}^{3} \left( x^2 + 4x + 1 \right) dx$ 과 $\displaystyle \int_{0}^{\infty} e^{-x} dx $$ 은 다음과 같이 구할 수 있다. 특히 적분구간에는 inf를 넣음으로써 이상적분까지 할 수 있다. f&amp;lt;-function(x) {x^2 + 4*x + 1} g&amp;lt;-function(x) {exp(-x)} integrate(f,0,3) integrate(g,0,Inf)``` &amp;lt;img filemime=&amp;#34;image/jpeg&amp;#34; filename=&amp;#34;20190322_140807.png&amp;#34; height=&amp;#34;63&amp;#34; src=&amp;#34;https://t1.daumcdn.net/cfile/tistory/998FDB405C946DC61D&amp;#34; style=&amp;#34;text-align: justify;&amp;#34; width=&amp;#34;260&amp;#34;/&amp;gt; 실제로 계산해보면 $$ \int_{0}^{3} \left( x^2 + 4x + 1 \right) dx = \left[ {{1} \over {3}} x^{3} + 2 x^2 + x \right]_{x=0}^{3} = 9 + 18 + 3</description>
    </item>
    
    <item>
      <title>라플라스 방정식에 대한 평균값 공식</title>
      <link>https://freshrimpsushi.github.io/posts/mean-value-formulas-for-laplaces-equation/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-value-formulas-for-laplaces-equation/</guid>
      <description>*라플라스 방정식의 평균값 성질$(\mathrm{mean-value\ property\ for\ Laplace&amp;rsquo;s\ equation})$ $\Omega \subset \mathbb{R}^n $가 열려있다고 하자. 그리고 $u \in C^2(\Omega)$가 라플라스 방정식 $\Delta u=0$를 만족한다고 하자. 그러면 각각의 열린 볼$(\mathrm{open\ ball})$ $B(x,r)\subset \subset \Omega$에 대해서 다음이 성립한다. $$ \begin{eqnarray} u(x) &amp;amp;=&amp;amp; \dfrac{1}{n \alpha(n)r^{n-1}} \int {\partial B(x,r)} udS \left( = -!!!!!!\int{\partial</description>
    </item>
    
    <item>
      <title>뮬러 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/muller-method/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/muller-method/</guid>
      <description>$f (\alpha) = 0$ 이라고 하자. 초기값 $x_{0} , x_{1} , x_{2}$ 과 $w_{n} := f [x_{n} , x_{n-1} ] + f [ x_{n} , x_{n-2} ] - f [ x_{n-2} , x_{n-1} ]$ 에 대해 $\displaystyle x_{n+1} : = x_{n} - {{ 2 f ( x_{n} ) } \over { w_{n} \pm \sqrt{ w_{n}^{2} - 4 f (x_{n} ) f [ x_{n} , x_{n-1} , x_{n-2} ] } }}$ 과 같이 정의된 수열 $\left\{ x_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 $\displaystyle p \approx 1.84 $ 차 수렴한다.단, $ \left( w_{n} \pm \sqrt{ w_{n}^{2} - 4 f (x_{n} ) f [ x_{n} , x_{n-1} , x_{n-2} ] } \right) \in \mathbb{C}$ 는 $+$ 와 $-$ 둘 중 $\left| w_{n} \pm \sqrt{ w_{n}^{2} - 4 f (x_{n} ) f [</description>
    </item>
    
    <item>
      <title>전자기학에서의 연속방정식</title>
      <link>https://freshrimpsushi.github.io/posts/continuity-equation-of-electromagnetics/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuity-equation-of-electromagnetics/</guid>
      <description>**연속방정식 $$ \dfrac{\partial \rho}{\partial t}=-\nabla \cdot \mathbf{J} $$ 전하량보존법칙은 원래 있던 전하가 갑자기 사라지거나 새로운 전하가 생기는 일이 없이 처음의 전하량이 그대로 유지된다는 법칙이다. 이는 우주 전체에 대해서도 그러하겠지만 우리의 눈 앞에 보이는 작은 영역에서도 마찬가지이다. 어떤 공간 안의 총 전하량에 변화가 생겼다면 반드시 그 공간의 표면을 통해 그만큼의 전하가 들어오</description>
    </item>
    
    <item>
      <title>f의 푸리에 급수가 f로 절대수렴 균등수렴할 충분 조건 Sufficient condition that Fourier series of f converges to f absolutely and uniformly</title>
      <link>https://freshrimpsushi.github.io/posts/1030/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1030/</guid>
      <description>**$f$의 푸리에 급수가 $f$로 절대수렴, 균등수렴할 충분조건 $[L, -L)$에서 정의된 함수 $f$가 연속이고, 조각마다 매끄럽다 고 하자. 그러면 $f$의 푸리에 급수는 $f$로 절대수렴, 균등수렴한다.$f$가 조각마다 매끄러울 때 $f$의 푸리에 급수가 $f$에 점마다 수렴한다. 여기에 조건이 강화되어 $f$의 불연속점이 사라진다</description>
    </item>
    
    <item>
      <title>R 에서 미분계수 구하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-differentiate-in-r/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-differentiate-in-r/</guid>
      <description>R 에서 정적분 구하는 법R 에서 미분계수를 구하기 위해선 numDeriv 패키지의 grad() 함수를 사용할 수 있다.예를 들어 $f(x) = x^2 + 4x + 1$ 과 $g(x) = e^{-x}$ 의 미분계수는 다음과 같이 구할 수 있다. install.packages(&amp;#34;numDeriv&amp;#34;) library(numDeriv) f&amp;lt;-function(x) {x^2 + 4*x + 1} g&amp;lt;-function(x) {exp(-x)} grad(f,2) grad(g,0) 실제로 계산해보면 $f&#39;(2) = 2 \cdot 2 + 4 = 8$ 이고 $g&#39;(0) = - e^{0} = -1$ 인 것을 확인할 수 있다.참고로 스칼라 함수의 경우에도 x 옵션에 벡터를 넣어주면 그래디언트를 잘</description>
    </item>
    
    <item>
      <title>스칼라 함수와 벡터 함수</title>
      <link>https://freshrimpsushi.github.io/posts/scalar-function-and-vector-function/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scalar-function-and-vector-function/</guid>
      <description>$D \subset \mathbb{R}^{n}$ 이라고 하자.1. $D$ 를 정의역으로 갖는 함수를 다변수 함수 라고 한다.2. $f : D \to \mathbb{R}$ 을 스칼라 함수 라고 한다.3. 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 $\mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix}$ 과 같이 정의된 $\mathbb{f} : D \to \mathbb{R}^{m}$ 를 **벡터 함수** 라고 한다.**1.** 다변수 함수라는 표현은 특히 미적분학을 위</description>
    </item>
    
    <item>
      <title>자기장 속의 에너지</title>
      <link>https://freshrimpsushi.github.io/posts/energy-of-magnetic-field/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/energy-of-magnetic-field/</guid>
      <description>전하 분포가 만드는 전기장의 에너지 를 생각 했듯이 전류 분포가 만드는 자기장의 에너지를 생각할 수 있다. 회로에 전류를 흐르게 하면 에너지가 들어간다. 이 에너지의 정체는 바로 역기전력 을 거슬러 하는 일이다. 역기전력 때문에 회로에 흐르는 전류에 변화를 주기 어렵다. 따라서 단위 전하가 회로를 한 바퀴 돌려면 역기전력 $-\mathcal{E}$ 만큼의 일을 해주어야 한다. 전류 의</description>
    </item>
    
    <item>
      <title>자체 인덕턴스</title>
      <link>https://freshrimpsushi.github.io/posts/self-inductance/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/self-inductance/</guid>
      <description>위 그림과 같은 상황에서 고리 1에 전류 $I_1$이 흐르면 자기장 $\mathbf{B}1$이 흐르고 $\mathbf{B}1$이 고리 2를 지나는 선속을 다음과 같이 계산할 수 있다. $$ \Phi_2 = M{21}I_1 $$ 이때 $M{21}$을 상호 인덕턴스 라고 한다. 이제 고리 1에 흐르는 전류 $I_1$이 시간에 따라 변화한다고 하자. 그러면 고리 2를 지나는 선속도</description>
    </item>
    
    <item>
      <title>바나흐 고정점 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-banach-fixed-point-theorem/</link>
      <pubDate>Sun, 31 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-banach-fixed-point-theorem/</guid>
      <description>$(X , | \cdot | ) $ 가 바나흐 공간이라고 하자. 모든 $x, \tilde{x} \in X$ 와 $0 \le r &amp;lt; 1$ 에 대해 $| T(x) - T ( \tilde{x} ) | \le r | x - \tilde{x} | $ 를 만족하는 $T : X \to X$ 를 축소 사상Contraction Mapping 이라고 정의한다. $T$ 의 고정점은 유일하게 존재한다.* 고정점이란 $T ( \alpha ) = \alpha$ 를 만족하는 $\alpha \in X$ 를 말한다.바나흐 고정점 정리는 **축소 사상 정리**Contra</description>
    </item>
    
    <item>
      <title>푸리에 코사인 급수와 사인 급수 우함수와 기함수의 푸리에 계수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-cosine-series-and-sine-series-fourier-coefficient-of-odd-function-and-even-function/</link>
      <pubDate>Sun, 31 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-cosine-series-and-sine-series-fourier-coefficient-of-odd-function-and-even-function/</guid>
      <description>** **0. $f$를 구간 $[0,L)$에서 조각마다 매끄러운 함수라고 하자.그리고 구간 $[-L, L)$로 $f$의 $\mathrm{even\ extension}$ $f_e$를 다음과 같이 정의한다. $$ f_{e}(t)=\begin{cases} f(t) &amp;amp; -L \le t &amp;lt;0 \\ f(-t) &amp;amp; 0 \le t &amp;lt;L\end{cases} $$ 즉, $f$가 우함수$(\mathrm{even\ function}$, 짝함수)가 되도록 확장한 것이다.마찬가지로 구간 $[-L, L)$로 $f$의 $\mathrm{odd\ extension}$ $f_o$를 다음과 같이 정</description>
    </item>
    
    <item>
      <title>R 에서 현재 OS 정보 확인하는 법 How to Check Operating System in R</title>
      <link>https://freshrimpsushi.github.io/posts/947/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/947/</guid>
      <description>R 은 이래저래 리눅스에서도 사용할 일이 있이 많다. 대표적으로 빅데이터를 다루기 위해 하둡을 쓰는 경우가 있다.물론 윈도우나 리눅스나 R 자체는 크게 다른 게 없지만, 작업환경이 다르기 때문에 작업경로가 달라져서 파일의 입출력이 다소 귀찮아지는 경우가 있다. 작업환경에 관계 없이 작업경로를 편하게 설정하기 위해선 현재의 OS가 어떤 것인지 확인할 필</description>
    </item>
    
    <item>
      <title>반파대칭</title>
      <link>https://freshrimpsushi.github.io/posts/half-wave-symmetry/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/half-wave-symmetry/</guid>
      <description>정의 주기가 $2L$인 주기함수 $f$가 모든 $t$에 대해서 아래의 식을 만족할 때 $f$를 반파대칭 이라 한다. $$ f(t)=-f(t+L) $$ 위의 정의를 풀어쓰면 &amp;lsquo;파동이 $xy$ 평면에 있다고 했을 때, 주기의 절반을 기준으로 파동이 진행하는 모양이 $y$축 대칭으로 번갈아 가면서 나타나는 것을 말한다.&amp;lsquo;이다. 예시 이름 그대로 반틈만큼 대칭이</description>
    </item>
    
    <item>
      <title>임의의 함수는 항상 기함수와 우함수의 합으로 표현할 수 있음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1002/</link>
      <pubDate>Fri, 29 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1002/</guid>
      <description>$(-\infty, \infty)$에서 정의되는 임의의 함수 $f$를 항상 기함수와 우함수의 합으로 표현할 수 있다.기함수와 우함수의 정의 증명 $f_e(t)$와 $f_o(t)$를 다음과 같다고 하자. $$ f_e(t)=\dfrac{ f(t)+f(-t)}{2},\ \ \ f_o(t)=\dfrac{ f(t)-f(-t)}{2} $$ 그러면 $f_e(t)$는 우함수이고, $f_o(t)$는 기함수이면서 $$ f_e(x)+f_o(x)=f(x) $$ 가 성립한다.■</description>
    </item>
    
    <item>
      <title>로그의 밑변환 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/944/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/944/</guid>
      <description>임의의 양수 $c&amp;gt;0$ 에 대해, $\displaystyle \log_{a} b = {{ \log_{c} b } \over { \log_{c} a }}$현대에 와서 공식 자체만으로는 의미가 없어졌지만 입시에서는 여전히 중요한 공식이다.간단한 성질이라고 해서 깔보지 말고 &amp;lsquo;공식&amp;rsquo;이라는 이름에 걸맞는 수준의 연습문제를 많이 풀어보는 것을 추천한다. 유도 $x := \log_{a} b$ 라고 하면 로그의 정의에 따라 $a^x = b$양변에 $\log_{c}$ 를</description>
    </item>
    
    <item>
      <title>열 방정식의 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-heat-equation/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-heat-equation/</guid>
      <description>열 방정식$(\mathrm{heat\ equation})$ 아래의 방정식을 열 방정식이라 부른다. $$ u_t=\Delta u $$ 비동차$(\mathrm{nonhomogeneous})$인 경우에는 $$ u_t-\Delta u=f $$ $t&amp;gt;0$, $x \in U$, $U \subset \mathbb{R}^n$는 열려있다.$u : \overline{U}\times [0, \infty) \rightarrow \mathbb{R}$, $u=u(x, t)=u(x_1,\ \cdots,\ x_n,\ t)$, $f:U \times [0, \infty) \rightarrow \mathbb{R}$라플라스 방정식** 에서 시간에 대항</description>
    </item>
    
    <item>
      <title>합성곱 컨볼루션의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-convolution/</link>
      <pubDate>Wed, 27 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-convolution/</guid>
      <description>$\mathbb{R}$에서 정의된 두 함수 $f$, $g$가 주어졌다고 하자. 아래의 적분이 존재하면 이를 두 함수 $f$, $g$의 합성곱이라 하고 $fg$로 표기한다. $$ fg(x):=\int {-\infty} ^{\infty} f(y)g(x-y)dy $$ 합성곱이라는 번역이 있지만 주로 컨볼루션이라고 읽는다. 대개 위의 정의를 컨볼루션이라고 배우지만, 조금 더 일반적으로 말하자면 이는 적분 변환인 푸리에 변환에 대한 컨볼루</description>
    </item>
    
    <item>
      <title>확률과정론의 인크리먼트</title>
      <link>https://freshrimpsushi.github.io/posts/increment-of-stochastic-process/</link>
      <pubDate>Wed, 27 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/increment-of-stochastic-process/</guid>
      <description>확률과정 $\xi(t)$ 이 시간 $T$ 에서 정의되었고 $t_{0} &amp;lt; t_{1} &amp;lt; \cdots &amp;lt; t_{n} \in T$ 이라고 하자.**1.** $\xi ( t ) - \xi ( s ) $ 를 **인크리먼트** 라고 한다.**2.** 모든 $i=1, \cdots , n$ 에 대해 $\xi ( t_{i} ) - \xi ( t_{i-1} )$ 들이 서로 독립이면 $\xi(t)$ 이 **독립 인크리먼트**Independent Increment 를 갖는다고 한다.**3.** 모든 $h&amp;gt;0$ 와 $t,s,t+h,s+h \in T$ 에 대해 $\xi (t+h) - \xi ( s +</description>
    </item>
    
    <item>
      <title>라플라스 방정식과 푸아송 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/laplaces-equation-and-poissons-equation/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplaces-equation-and-poissons-equation/</guid>
      <description>**** *라플라시안$(\mathrm{Laplacian})$ $n$차원 실공간에서의 미분연산자 $\Delta$를 다음과 같이 정의하고 라플라시안이라 부른다. $$ \begin{eqnarray} \Delta u(x) &amp;amp;:=&amp;amp; u_{x_1x_1}+u_{x_2x_2}+\cdots + u_{x_nx_n}=\sum \limits_{i=1}^{n}u_{x_ix_i} \\ &amp;amp;=&amp;amp; \dfrac{\partial^2 u}{\partial x_1 ^2}+\dfrac{\partial^2 u}{\partial x_2 ^2}+\cdots +\dfrac{\partial^2 u}{\partial x_n ^2}=\sum \limits_{i=1}^{n}\dfrac{\partial^2 u}{\partial x_i ^2} \end{eqnarray*} $$ $x=x(x_1,\ x_2,\ \cdots ,x_n)\in \mathbb{R}^n$, $u:\overline{U} \rightarrow \mathbb{R},\ \ U\subset\mathbb{R}^n$물리학에서는 $\Delta$ 대신 $\nabla ^2$를 쓴다. $$</description>
    </item>
    
    <item>
      <title>라플라스 방정식이 회전에 대해서 불변함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-laplaces-equation-is-invariant-under-rotations/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-laplaces-equation-is-invariant-under-rotations/</guid>
      <description>**라플라스 방정식은 회전에 대해서 불변하다. $u$가 라플라스 방정식 을 만족한다고 하자.그리고 $v(x)$를 아래와 같이 정의하자. $$ v(x) :=u(Rx) $$ 이때, $R$은 회전 변환그러면 $v(x)$도 라플라스 방정식을 만족한다. $$ \Delta v=0 $$ 증명 회전변환은 직교행렬$(\mathrm{orthogonal\ matrix})$이므로 임의의</description>
    </item>
    
    <item>
      <title>이산로그 문제가 쉽게 풀리는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/942/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/942/</guid>
      <description>이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건그룹 $G = F_{p}$ 의 원소 $g$ 가 오더 $N$ 이라고 하자. 그러면 이산로그 문제 $g^{x} = h$ 는 다음의 조건 하에서 비교적 쉽게 풀리게 된다.**(i)** $p$ 가 스무</description>
    </item>
    
    <item>
      <title>그린-가우스 정리 부분 적분 그린의 공식</title>
      <link>https://freshrimpsushi.github.io/posts/green-gauss-theorem-integration-by-parts-formula-greens-formulas/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/green-gauss-theorem-integration-by-parts-formula-greens-formulas/</guid>
      <description>**그린-가우스 정리$(\mathrm{Green-Gauss\ theorem})$ $(\mathrm{i})$ $ u \in C^1(\overline{ U})$라고 하자.그러면 아래의 식이 성립한다. $$ \int_U u_{x_i}dx=\int _{\partial U} u\nu^i dS\ \ \ (i=1,\cdots, n) $$ $(\mathrm{ii})$ $(\mathrm{i})$에서 얻은 식을 모든 $i$에 대해서 합하면 아래의 식을 얻는다. $$ \int_U \nabla \cdot \mathbf{u} dx = \int_{\partial U} \mathbf{u} \cdot \nu dS $$ 위 식을 특히 **발산 정리$(\mathrm{d</description>
    </item>
    
    <item>
      <title>수송 방정식의 초기값 문제와 비동차 문제 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problems-and-nonhomogeneous-problems-of-transport-equations/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problems-and-nonhomogeneous-problems-of-transport-equations/</guid>
      <description>아래의 편미분 방정식을 수송방정식$(\mathrm{transport\ equation})$이라 한다. $$ u_t + b\cdot Du=0\ \ \ \mathrm{in}\ \mathbb{R}^n \times (0,\ \infty) \ \ \cdots (1) $$ 이때, $b=(b_1, b_2, \cdot, b_n) \in \mathbb{R}^n$은 고정된 벡터, $u=u(x,t)$는 $u:\mathbb{R}^n \times [0,\infty) \rightarrow \mathbb{R}$, $x=(x_1, \cdots , x_n)\in \mathbb{R}^n$는 공간의 한 점, $t \ge 0$는 시간을 나타낸다.$</description>
    </item>
    
    <item>
      <title>시컨트 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/secant-method/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/secant-method/</guid>
      <description>$f,f&#39;,f&#39;&#39;$ 가 $\alpha$ 의 근방에서 연속이고 $f(\alpha) = 0, f&#39;(\alpha) \ne 0$ 이라고 하자. $\alpha$ 와 충분히 가까운 초기값 $x_{0} , x_{1}$ 에 대해 $\displaystyle x_{n+1} := x_{n} - f ( x_{n} ) {{ x_{n} - x_{n-1} } \over { f ( x_{n} ) - f ( x_{n-1} ) }}$ 과 같이 정의된 수열 $\left\{ x_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 $\displaystyle {{1 + \sqrt{5} } \over {2}} $ 차 수렴한다.수렴차수가 상당히 낯이 익을 것이다. 바로 황금비인 $\displaystyle {{1 + \sqrt{5} } \over {2}} = 1.618 \cdots $ 인데, 수열의 정의에서 세 개의 연속된 항</description>
    </item>
    
    <item>
      <title>아리마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/arima-model-intergrated-autoregressive-moving-average-model/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arima-model-intergrated-autoregressive-moving-average-model/</guid>
      <description>백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}} $ 에 대해 $$ \displaystyle \nabla^{d} Y_{t} := \sum_{i = 1}^{p} \phi_{i} \nabla^{d} Y_{t-i} + e_{t} - \sum_{i = 1}^{q} \theta_{i} e_{t-i} $$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} } $ 을 **$(p,d,q)$차 아리마 과정** $ARIMA (p,d,q)$ 라고 한다. 이와 같은 꼴을 한 시계열 분석 모형을 **아리마 모형** 이라고 한다.$ARI(p,d) \iff ARIMA(p,d,0)$ 을 **아리 모형** , $IMA(d,q) \iff ARIMA(0,d,q)$ 을 **이마 모형** 이라고 하긴 하는데 자주 쓰진 않</description>
    </item>
    
    <item>
      <title>외향 단위 법선 벡터</title>
      <link>https://freshrimpsushi.github.io/posts/the-outward-pointing-unit-normal-vector/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-outward-pointing-unit-normal-vector/</guid>
      <description>※얼핏 보면 $\nu$와 $\nu$의 볼드체인 $\boldsymbol{\nu}$가 구분이 잘 되지 않는다. 그래도 자세히 보면 구분 되니까 찰떡같이 알아보자.**1. $U$의 경계 $\partial U$가 $\partial U \in C^1$이라고 하자.그러면 다음과 같은 외향 단위 법선 벡터를 정의할 수 있다. $$ \boldsymbol{\nu}=(\nu ^1, \cdots, \nu^n) $$ 경계의 한 점에서 접하고 크기가 1이며 바깥쪽을 향</description>
    </item>
    
    <item>
      <title>도함수의 푸리에 계수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-coefficient-of-derivative/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-coefficient-of-derivative/</guid>
      <description>구간 $[-L,\ L)$에서 정의된 함수 $f$가 연속이고, 조각마다 매끄럽다 고 하자.그러면 $f&#39;$의 푸리에 계수는 다음과 같다. $$ a&#39;_n=\dfrac{n\pi}{L}b_n $$ $$ b&#39;_n=-\dfrac{n\pi}{L}a_n $$ $$ c&#39;_n=\dfrac{in\pi}{L}c_n $$ 이 때, $a_n,\ b_n$은 $f$의 푸리에 계수 , $c_n$은 $f$의 복소 푸리에 계수 이다. 증명 $\begin{eqnarray*} c&#39;_n &amp;amp;=&amp;amp;\dfrac{1}{2L}\int _{-L}^{L} f&#39;(t)e^{-i\frac{n\pi}{L}t}dt \\ &amp;amp;=&amp;amp; \dfrac{1}{2L}\left[ f(t)e^{-i\frac{n\pi}{L}t} \right]_{-L}^{L} +\dfrac{in \pi}{L}\dfrac{1}{2L}\int_{-L}^{L} f(t)e^{-i\frac{n \pi}{L}t} dt \\ &amp;amp;=&amp;amp; \dfrac{1}{2L}f(t)\left[ e^{-in\pi} -e^{in\pi}\right] +\dfrac{in \pi}{L}c_n \\ &amp;amp; =&amp;amp; \dfrac{1}{2L}f(t)\left[ (-1)^{-n} -(-1)^{n}\right] +\dfrac{in \pi}{L}c_n \\ &amp;amp;=&amp;amp; \dfrac{1}{2L}f(t)(-1)^{n}\left[ (-1)^{-2n} -1 \right] +\dfrac{in \pi}{L}c_n \\ &amp;amp;=&amp;amp; \dfrac{in \pi}{L}c_n \end{eqnarray*}$ 두번째</description>
    </item>
    
    <item>
      <title>수치해석학에서의 계차상</title>
      <link>https://freshrimpsushi.github.io/posts/divided-difference/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divided-difference/</guid>
      <description>함수 $f : \mathbb{R} \to \mathbb{R}$ 와 서로 다른 $x_{1} , \cdots , x_{n}$ 에 대해 다음을 $f$ 의 계차상이라고 한다.$f[x_{0}] := f( x_{0} ) $$ \displaystyle f [ x_{0} , x_{1} ] : = {{ f ( x_{1} ) - f ( x_{0} ) } \over { x_{1} - x_{0} }} $$ \displaystyle f [ x_{0} , x_{1} , x_{2} ] : = {{ f [ x_{1} , x_{2} ] - f [ x_{0} , x_{1} ] } \over { x_{2} - x_{0} }} $$ \displaystyle f [ x_{0} , \cdots , x_{n} ] : = {{ f [ x_{1} , \cdots , x_{n} ] - f [ x_{0} , x_{n-1} ] } \over { x_{n} - x_{0} }}$**[1]** $f [ x_{0} , \cdots , x_{n} ]</description>
    </item>
    
    <item>
      <title>정적분과 푸리에 급수</title>
      <link>https://freshrimpsushi.github.io/posts/definite-and-fourier-series/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definite-and-fourier-series/</guid>
      <description>주기가 $2L$인 주기함수 $f$가 구간 $[-L,\ L)$에서 조각마다 연속 이라고 하자.그러면 $f$의 정적분은 아래와 같이 나타낼 수 있다. $$ \int_{t_1}^{t_2} f(t) dt= c_0(t_2-t_1) +\sum \limits_{n \ne 0} \dfrac{L}{in\pi}c_n\left( e^{i\frac{n\pi}{L}t_2}-e^{i\frac{n\pi}{L}t_1} \right) $$ 이 때, $c_0,\ c_n$은 **복소 푸리에 계수** .즉, **$f(t)$의 정적분은 $f(t)$의 푸리에 급수의 각 항을 정적분하여 더한 것과 같다. 주의해야 할 점은 우변이 좌변의 푸</description>
    </item>
    
    <item>
      <title>주기함수의 한 주기 적분은 적분 구간에 상관없이 항상 같은 값을 가짐을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/982/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/982/</guid>
      <description>$f$가 주기가 $2L$인 주기함수라고 하자.그러면 $\displaystyle \int_a^{a+2L}f(t)dt$의 값은 $a$의 값에 상관없이 일정하다.주기함수를 한 주기(혹은 주기의 정수배)에 대해서 적분한 값은 적분 구관과 상관이 없다.예를 들어 $\cos x$를 $0$부터 $2\pi$까지 적분한 값이나 $-\pi$부터 $\pi$까지 적분한 값이나 같</description>
    </item>
    
    <item>
      <title>폴리그-헬맨 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pohlig-hellman-algorithm/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pohlig-hellman-algorithm/</guid>
      <description>이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건그룹 $G$ 의 원소 $g$ 가 오더 $N = q_{1}^{r_{1}} q_{2}^{r_{2}} \cdots q_{t}^{r_{t}} $ 이라고 하자. 그러면 이산로그 문제 $g^{x} = h$ 는 다음의 알고리즘에 따라 많아도 $\displaystyle O \left( \sum_{i=1}^{t} S_{q_{i}^{r_{i}}} + \log N \right)$ 스텝 안에</description>
    </item>
    
    <item>
      <title>푸리에 계수의 극한이 0으로 수렴함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-fourier-coefficients-tend-to-zero-as-n-tend-to-infinite/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-fourier-coefficients-tend-to-zero-as-n-tend-to-infinite/</guid>
      <description>푸리에 계수 $a_n,\ b_n,\ c_n,\ c_{-n}$은 $n \rightarrow \infty$인 극한을 취하면 모두 $0$으로 수렴한다. $$ \lim \limits_{n \rightarrow \infty} a_n=0 $$ $$ \lim \limits_{n \rightarrow \infty} b_n=0 $$ $$ \lim \limits_{n \rightarrow \infty} c_{\pm n}=0 $$ 증명 베셀 부등식 에 의해 푸리에 계수의 합이 수렴함을 알고 있다. $$ \dfrac{1}{4}|a_0|^2 +\dfrac{1}{2}\sum\limits_{n=1}^{\infty} \left(|a_n|^2 + |b_n|^2 \right) =\sum \limits_{-\infty}^{\infty} | c_n |^2 \le \dfrac{1}{2L}\int_{-L}^{L} | f(t)|^2 dt $$ 따라서 $|a_n|^2,\ |b_n|^2,\ |c_{\pm n}|^2$은 수렴하는 급수의 $n$번째 항이다.**급수가 수렴하면 수</description>
    </item>
    
    <item>
      <title>푸리에 급수의 상수항은 함수의 한 주기 평균과 같다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-the-constant-term-in-fourier-series-of-f-is-the-mean-value-of-f/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-the-constant-term-in-fourier-series-of-f-is-the-mean-value-of-f/</guid>
      <description>주기가 $2L$인 함수 $f$의 푸리에 급수의 상수항은 함수 $f$의 한 주기 평균 과 같다. 증명 $f(t)$의 한 주기 적분은 $$ \displaystyle \dfrac{1}{2L}\int_{-L}^{L} f(t)dt $$ 이는 **푸리에 계수** 의 정의에 따라 $\dfrac{1}{2}a_0$과 같다.따라서 $f(t)$의 한 주기 적분은 $f(t)$의 푸리에 급수의 상수항과 같다. ■ 직접 계산을 통해 위 사실을 보일수도 있</description>
    </item>
    
    <item>
      <title>함수의 평균값</title>
      <link>https://freshrimpsushi.github.io/posts/mean-value-of-function/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-value-of-function/</guid>
      <description>적분의 평균값 정리구간 $[a,\ b]$에서 $f(x)$의 평균값은 구간에 대해서 적분한 다음 구간의 길이로 나눠준 것과 같다. $$ \dfrac{1}{b-a}\int_a^bf(x)dx $$ 증명 구간 $[a,\ b]$의 분할 을 $P$라고 하자. $$ P=\left\{ x_1,\ x_2,\ \cdots ,\ x_n \right\} $$ 이때, $a=x_1 &amp;lt; x_2 &amp;lt; \cdots &amp;lt; x_n=b$이고 각 점의 사이의 거리는 같다. 그리고 $\Delta x=x_{i+1}-x_i$. $f(x_i)$의 합을 $n$으로 나눠서 $f(x)$의 평균값을 어림</description>
    </item>
    
    <item>
      <title>뉴턴-랩슨 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/newton-raphson-method/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newton-raphson-method/</guid>
      <description>고차원에 대해 일반화된 뉴턴-랩슨 메소드$f,f&#39;,f&#39;&#39;$ 가 $\alpha$ 의 근방에서 연속이고 $f(\alpha) = 0, f&#39;(\alpha) \ne 0$ 이라고 하자. $\alpha$ 와 충분히 가까운 초기값 $x_{0}$ 에 대해 $\displaystyle x_{n+1} := x_{n} - {{ f ( x_{n} ) } \over { f&#39; ( x_{n} ) }}$ 과 같이 정의된 수열 $\left\{ x_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 쿼드러틱하게 수렴한다.뉴턴-랩슨 메소드는 그냥 뉴턴 메소드라고 불리기도 한다. 미분가능성이나 연속성과</description>
    </item>
    
    <item>
      <title>샤피로-윌크 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/shapiro-wilk-test/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shapiro-wilk-test/</guid>
      <description>하르케-베라 테스트데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 가 주어져 있다고 하자.$H_{0}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따른다.$H_{1}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따르지 않는다.샤피로-윌크 테스트는 정규성을 검정하기 위해 사용하는 테스트로써, 보통은 정규성이 있음을 보이기 위해서 사용한다. 귀무가설이 채택되는 것이 &amp;lsquo</description>
    </item>
    
    <item>
      <title>바이섹션 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/bisection-method/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bisection-method/</guid>
      <description>연속함수 $f$ 가 폐구간 $[a,b]$ 에서 $f(a) f(b) &amp;lt; 0$ 이라고 하자. 허용오차는 $\varepsilon$ 이다.$f(c) = 0$ 를 만족하는 $c \in [a,b]$ 는 다음과 같이 구할 수 있다.**Step 1. $\displaystyle c:= {{a+b} \over {2}} $**Step 2. $b-c \le \varepsilon$ 이면 $c$ 를 반환한다.**Step 3. $f(b) f(c) &amp;lt; 0 $ 이면 $a:=c$, 아니면 $b:=c$그리고 Step 1. 으로 돌아간다.중간값정리의 대표적인 응용으로써, 해가 존재하는 구간을 계속 절반으</description>
    </item>
    
    <item>
      <title>시계열분석에서의 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation/</guid>
      <description>회귀분석에서의 변환시계열에서 변환이 필요한 이유는 시간이 흐를수록 분산이 커지는 경우 그에 따른 &amp;lsquo;패널티&amp;rsquo;를 줘서 분산을 일정하게 하고 정상성을 얻기 위함이다. 루트 $\sqrt{}$ 나 로그 $\log$ 는 값이 클수록 줄어드는 양이 많기 때문에 자주 사용된다. 당연하지만 분산이 줄어드는 경우에는 데이터의 추이가 어떤 점으로 수렴한다는 의미가 되</description>
    </item>
    
    <item>
      <title>수렴률</title>
      <link>https://freshrimpsushi.github.io/posts/rate-of-convergence/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rate-of-convergence/</guid>
      <description>$\alpha$ 로 수렴하는 수열 $\left\{ x_{n} \right\} $ 이 $p \ge 1$ 과 $c \ge 0$ 에 대해 $| \alpha - x_{n+1} | \le c | \alpha - x_{n} | ^{p}$ 이면 차수 $p$ 을 만족하면 $\left\{ x_{n} \right\} $ 이 **수렴률 $c$ 로 $\alpha$ 에 $p$ 차 수렴한다** 고 한다.특히 $c &amp;lt; 1$ 이라는 조건과 함께 $p=1$ 이면 **선형 수렴**Linear Convergence 이라고 부른다. 비슷하게 $p=2$ 일 때는 **Quadratic Convergence** , $p=3$ 일 때는 **Cubic Convergence** 라고 한다.해석학에서 주로 수렴하는지만 신경을 썼다</description>
    </item>
    
    <item>
      <title>스무스 소수</title>
      <link>https://freshrimpsushi.github.io/posts/smooth-prime/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/smooth-prime/</guid>
      <description>1. 소수 $p$ 에 대해 $(p-1)$ 가 많은 약수를 가지면 $p$ 가 스무스 소수라고 한다.2. $B$ 보다 작거나 같은 소수들의 곱으로 나타나는 수를 $B$-스무스 수라고 한다.3. $\psi ( X , B ) $ 는 $X$ 보다 작거나 같은 $B$-스무스 수의 갯수를 나타낸다.** **1.** 스무스한 소수의 예로써 $p=37$ 를 생각해보면 $(p-1)$ 는 $p-1 = 36 = 2^2 3^2 $ 와 같이 자잘한 소수들의 곱들로 표현된다. 스무스</description>
    </item>
    
    <item>
      <title>디리클레 조건과 푸리에 급수의 수렴성</title>
      <link>https://freshrimpsushi.github.io/posts/dirichlet-condition-and-convergence-of-fourier-series/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichlet-condition-and-convergence-of-fourier-series/</guid>
      <description>함수 $f$와 그 도함수 $f&#39;$가 구간 $I=[a,\ b]$에서 조각마다 연속 일 때, 함수 $f$를 $I$에서 조각마다 매끄럽다$(\mathrm{piecewise\ smooth})$ 고 한다. 그리고 다음과 같이 표기한다. $$ f \in PS(a,\ b) $$ 주기가 $2L$인 함수 $f$가 조각마다 매끄러울 때 즉, $\mathrm{Dirichlet}$조건을 만족할 때, 전구</description>
    </item>
    
    <item>
      <title>불연속점에서 푸리에 급수의 수렴성</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-of-fourier-series-at-point-of-discontinuity/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-of-fourier-series-at-point-of-discontinuity/</guid>
      <description>구간 $[-L,\ L)$에서 정의된 함수 $f(t)$가 조각마다 연속 이라고 하자. 불연속점을 $t_i\ (i=1,\ \cdots m )$라고 하고 각 불연속점에서 좌미분계수, 우미분계수를 가진다고 하자. 그러면 $f(t)$의 푸리에 급수는 불연속점 $t_i$에서 좌극한와 우극한의 중간값으로 수렴한다. $$ \dfrac{a_0}{2}+\sum \limits_{n=1}^{\infty}\left( a_n \cos \dfrac{n \pi }{L}t_i +b_n\sin\dfrac{n\pi }{L}t_i \right) = \dfrac{1}{2}\big(f(t_i+)+f(t_i-)\big) $$ 이때, $\lim \limits_{x \rightarrow a^+} f(x)=f(a+) $$ \lim \limits_{x \rightarrow a^-}f(x) = f(a-</description>
    </item>
    
    <item>
      <title>조각마다 연속 조각마다 스무스</title>
      <link>https://freshrimpsushi.github.io/posts/piecewise-continuous-piecewise-smooth/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/piecewise-continuous-piecewise-smooth/</guid>
      <description>※조각마다 연속, 조각별 연속, 구분적으로 연속 등 여러 번역이 있다. 보통 실제로 말 할때는 $\mathrm{piecewise\ continuous}$라고 말한다. 본 글에서는 조각마다 연속이라 하겠다.함수 $f(x)$가 구간 $I$에서 아래의 조건을 만족할 때 $f(x)$는 구간 $I$에서 조각마다 연속이라고 한다.$1.$ 유한 개의 불연속점들 $x_1,\ x_2,\ \cdots ,\ x_n \in I$을 가</description>
    </item>
    
    <item>
      <title>샹크스 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-shankss-babystep-giantstep-algorithm/</link>
      <pubDate>Tue, 19 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-shankss-babystep-giantstep-algorithm/</guid>
      <description>이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건항등원이 $e$ 인 그룹 $G$ 의 원소 $g$ 가 오더 $N$ 이라고 하자. 그러면 이산로그 문제 $g^{x} = h$ 는 다음의 알고리즘에 따라 많아도 $O \left( \sqrt{N} \log N \right)$ 스텝 안에 풀린다</description>
    </item>
    
    <item>
      <title>2계 선형 미분 방정식의 두 해의 론스키안은 항상 0이거나 항상 0이 아니다</title>
      <link>https://freshrimpsushi.github.io/posts/wronskian-of-two-solution-of-second-order-linear-differential-equation-either-is-zero-or-else-is-never-zero/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/wronskian-of-two-solution-of-second-order-linear-differential-equation-either-is-zero-or-else-is-never-zero/</guid>
      <description>아벨의 정리$(\mathrm{Abel&amp;rsquo;s\ theorem}) $$ y_1$과 $y_2$가 2계 선형 미분 방정식 $y&#39;&#39;+p(t)y&#39;+q(t)y=0$의 해라고 하자.그러면 $y_1$과 $y_2$의 론스키안 은 지수함수 꼴로 나타난다. $$ Wy_1,y_2=c e^{-\int p(t) dt} $$ 이 때 $c$는 $y_1,\ y_2$에 의존하는 상수.또한 $Wy_1,y_2$는 모든 점에</description>
    </item>
    
    <item>
      <title>시계열분석에서의 차분</title>
      <link>https://freshrimpsushi.github.io/posts/difference/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference/</guid>
      <description>수치해석에서의 차분1. 오퍼레이터 $B$ 를 $B Y_{t} = Y_{t-1}$ 과 같이 정의하고, **백쉬프트**Backshift 라고 한다.**2.** 오퍼레이터 $\nabla$ 를 $\nabla := 1 - B$ 그리고 $\nabla^{r+1} = \nabla \left( \nabla^{r} Y_{t} \right)$ 와 같이 정의하고 **차분** 이라한다.차분의 정의에 따르면 $1$차 차분은 $$ \nabla Y_{t} = Y_{t} - Y_{t-1} $$ 와 같이 계산되며, $2$차 차분은 $$ \begin{eqnarray*} \nabla^2 Y_{t} &amp;amp;=&amp;amp; \nabla \left( \nabla Y_{t} \right) \\ &amp;amp;=&amp;amp; \nabla</description>
    </item>
    
    <item>
      <title>기전력과 운동 기전력</title>
      <link>https://freshrimpsushi.github.io/posts/electromotive-force-and-motional-emf/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/electromotive-force-and-motional-emf/</guid>
      <description>1. 기전력 $(\mathrm{electromotive\ force,\ emf})$ 회로에서 전하를 움직여 전류를 만들어내는 힘을 $\mathbf{f}$라고 하자. 이 $\mathbf{f}$는 두 가지로 나눌 수 있다. 하나는 회로 전원의 힘 $\mathbf{f}_s$이고 다른 하나는 회로 어느 부분에 쌓인 전하에 의해 만들어진 전기력 $\mathbf{E}$이다. 여기서 아래첨자 $s$는 $\mat</description>
    </item>
    
    <item>
      <title>델 연산자가 포함된 식의 부분적분</title>
      <link>https://freshrimpsushi.github.io/posts/integral-by-part-with-del-operator/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integral-by-part-with-del-operator/</guid>
      <description>부분적분의 원리를 그대로 사용해서 델 연산자가 포함된 식의 모습을 유용하게 바꿀 수 있다.**부분적분 $\dfrac{d}{dx}\left( fg \right) = f\dfrac{dg}{dx}+g\dfrac{df}{dx}$양 변을 정적분하면$\displaystyle \int_a^b \dfrac{d}{dx} \left(fg\right) = (fg)\Big|_a^b=\int_a^b f\left(\dfrac{dg}{dx}\right)dx+\int_a^bg\left(\dfrac{df}{dx}\right)dx $$ \displaystyle \Rightarrow \int_a^b f\left(\dfrac{dg}{dx}\right)dx = (fg)\Big|_a^b-\int_a^bg\left(\dfrac{</description>
    </item>
    
    <item>
      <title>엘가말 공개 키 암호체계 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-elgamal-public-key-cryptosystem/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-elgamal-public-key-cryptosystem/</guid>
      <description>이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건왼쪽부터 순서대로 앨리스 , 밥 , 이브** 라고 하자. 앨리스와 밥은 메세지를 주고받을 당사자고, 이브는 메세지에 관심이 있는 소극적 공격자다.</description>
    </item>
    
    <item>
      <title>전하 분포의 일과 에너지 전기장 속의 에너지</title>
      <link>https://freshrimpsushi.github.io/posts/work-and-energy-of-charge-distribution-energy-of-electric-field/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/work-and-energy-of-charge-distribution-energy-of-electric-field/</guid>
      <description>**0. 고정된 원천 전하 분포가 있고 시험전하 $Q$를 점 $\mathbf{a}$에서 점 $\mathbf{b}$까지 옮길 때 드는 일을 계산하는 과정은 아래와 같다. $$ W=\int_{\mathbf{a}}^\mathbf{b} \mathbf{F} \cdot d\mathbf{l}$=-Q\int_\mathbf{a}^\mathbf{b} \mathbf{E} \cdot d\mathbf{l} =Q[V(\mathbf{b})-V(\mathbf{a})] $$ 위 식을 $Q$로 나누면 아래와 같고 이는 $\mathbf{a}$와 $\mathbf{b}$의 전위차는 전하 $Q$를 $\mathbf{a}$에서 $\</description>
    </item>
    
    <item>
      <title>아르마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/arma-model/</link>
      <pubDate>Sat, 16 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arma-model/</guid>
      <description>백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}} $ 에 대해 $$ Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} +e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q} $$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} } $ 을 **$(p,q)$차 자기회귀이동평균과정 $ARMA(p,q)$** 라고 한다.아르마 모형은 단순히 이동평균과정과 자기회귀과정을 이어붙인 모양을 갖고 있다. 예로써 $(1,1)$차라면 $$ ARMA(1,1) : Y_{t} = \phi Y_{t-1} + e_{t} - \theta e_{t-1} $$ 이 되는 식이다. 다만</description>
    </item>
    
    <item>
      <title>디피-헬만 키 교환 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-diffie-hellman-key-exchange-algorithm/</link>
      <pubDate>Fri, 15 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-diffie-hellman-key-exchange-algorithm/</guid>
      <description>이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건왼쪽부터 순서대로 앨리스 , 밥 , 이브 라고 하자. 앨리스와 밥은 메세지를 주고받을 당사자고, 이브는 메세지에 관심이 있는 소극적 공격자다. 주황</description>
    </item>
    
    <item>
      <title>우분투 1804 에서 R 설치하는 법 How to Install R in Ubuntu 1804</title>
      <link>https://freshrimpsushi.github.io/posts/946/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/946/</guid>
      <description>Step 1. Ctrl+Alt+T 를 눌러 콘솔창을 띄운다.Step 2. 콘솔창에 다음과 같이 입력한다.sudo apt-key adv &amp;ndash;keyserver keyserver.ubuntu.com &amp;ndash;recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9관리자 권한이 필요하므로 사용자 계정의 암호를 입력해야한다.Step 3. 콘솔창에 다음과 같이 입력한다.sudo add-apt-repository &amp;lsquo;deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/&#39;Step 4. 콘솔창에 다음과 같이 입력한다</description>
    </item>
    
    <item>
      <title>자기회귀과정</title>
      <link>https://freshrimpsushi.github.io/posts/ar-autoregressive-process/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ar-autoregressive-process/</guid>
      <description>백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}} $ 에 대해 $Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} + e_{t}$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} } $ 을 **$p$차 자기회귀과정 $AR(p)$** 라고 한다.**1.** $AR(1) : Y_{t} = \phi Y_{t-1} + e_{t}$**2.** $AR(2) : Y_{t} = \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + e_{t}$**p.** $AR(p) : Y_{t} = \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} + e_{t}$**∞.** $AR( \infty ) : Y_{t} = e_{t} + \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots $* $\mathbb{N}$ 은 자연수의 집합 $\left\{ 1, 2, 3 , \cdots \right\}$ 을 의미한다.$</description>
    </item>
    
    <item>
      <title>이산로그</title>
      <link>https://freshrimpsushi.github.io/posts/discrete-logarithm/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/discrete-logarithm/</guid>
      <description>이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건소수 $p$ 에 대해 갈루아 필드 $\mathbb{F}{p} := \mathbb{Z} / p \mathbb{Z}$ 의 항등원이 $0$ 이라고 하자. $\mathbb{F}{p} $ 의 원시근 $g \ne 0$ 에 대해 시클릭 그룹 $\mathbb{F}{p} ^{ * } := \mathbb{F}{p} \setminus \left\{ 0 \right\} = \left&amp;lt; g \right&amp;gt;$ 상에</description>
    </item>
    
    <item>
      <title>이동평균과정</title>
      <link>https://freshrimpsushi.github.io/posts/ma-moving-average-process/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ma-moving-average-process/</guid>
      <description>백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}} $ 에 대해 $Y_{t} := e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q}$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} } $ 을 **$q$차 이동평균과정 $MA(q)$** 라고 한다.**1.** $MA(1) : Y_{t} = e_{t} - \theta e_{t-1}$**2.** $MA(2) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2}$**q.** $MA(q) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q}$**∞.** $MA( \infty ) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots $* $\mathbb{N}$ 은 자연수의 집합 $\left\{ 1, 2, 3 , \cdots \right\}$ 을 의미한다</description>
    </item>
    
    <item>
      <title>암호론에서의 암호화와 복호화</title>
      <link>https://freshrimpsushi.github.io/posts/encryption-and-decryption-in-cryptography/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/encryption-and-decryption-in-cryptography/</guid>
      <description>앨리스Alice 가 밥Bob 에게 전하고 싶은 메세지가 있다고 생각해보자. 세상에 사람이 둘 뿐이라면 이 메세지는 오직 둘만이 공유하며, 감출 이유가 없다. [ NOTE : 암호론에서 앨리스는 $A$ 를 대신하는 이름이고, 밥은 $B$ 를 대신하는 이름이다. ]하지만 이들 외의 제3자로 이브Eve 가 있다고 하자. 이브는 딱히 나쁜 의도는 없지만, 앨리스가 밥에게 전하</description>
    </item>
    
    <item>
      <title>체비셰프 미분 방정식의 급수해 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/series-solution-of-chebyshev-differential-equation/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-solution-of-chebyshev-differential-equation/</guid>
      <description>**체비셰프 미분방정식 $$ (1-x^2)\dfrac{d^2 y}{dx^2} -x\dfrac{dy}{dx}+n^2 y=0 $$ 의 해를 체비셰프 다항식 이라 하고 $T_n(x)$로 표기한다. 각 $n$에 따른 처음 몇 개의 체비셰프 다항식은$T_0(x)=1 $$ T_1(x)=x $$ T_2(x)=2x^2-1 $$ T_3(x)=4x^3-3x $$ T_4(x)=8x^4-8x^2+1 $$ T_5(x)=16x^5-20x^3+5x $$ \vdots $$ $(1-x^2)\dfrac{d^2 y}{dx^2} -x\dfrac{dy}{dx}+n^2 y=0 $$ 위 식을 체비셰프 미분 방정식$(\mathrm{Chebyshev\ differential\ equation})$ 이라고 한다. 그리고 이 미분 방정식의 해를 체비셰프 다항</description>
    </item>
    
    <item>
      <title>체비셰프 미분방정식의 일반해 체비셰프 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/general-solution-of-chebyshev-differential-equation-chebyshev-polynomial/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-solution-of-chebyshev-differential-equation-chebyshev-polynomial/</guid>
      <description>삼각함수를 통한 체비셰프 다항함수의 정의체비셰프 미분방정식 $$ (1-x^2)\dfrac{d^2 y}{dx^2} -x\dfrac{dy}{dx}+n^2 y=0 $$ 체비셰프 미분방정식의 해를 체비셰프 다항식 이라 하고 이를 $T_n(x)$으로 표기한다. $T_n(x)$의 일반항은 아래와 같다. $n$이 짝수일 때 $$ 1-\dfrac{\lambda^2}{2!}x^2+\dfrac{\lambda^2(\lambda^2-2^2)}{4!}x^4+\sum \limits_{m=3}^\infty (-1)^m \dfrac{\lambda^2(\lambda^2-2^2)\cdots(\lambda^2-(2m-2)^2)}{(2m)!} x^{2m} $$ $n$이 홀수일 때 $$ x-\dfrac{\lambda^2-1^2}{3!}x^3+\dfrac{(\lambda^2-1^2)(\lambda^2-3^2)}{5!}x^5+\sum \limits_{m=3}^\infty (-1)^m\dfrac{(\lambda^2-1^2)(\lambda^2-3^2) \cdots (\lambda^2-(2m-1)^2)}{(2m+1)!} x^{2m+1} $$ 그리고 처음 몇 개의 다항식은 아래와 같다.$T_0(x)=1</description>
    </item>
    
    <item>
      <title>속박전류밀도와 자화된 물체가 만드는 벡터 전위 자기장</title>
      <link>https://freshrimpsushi.github.io/posts/vector-potential-and-magneticfield-by-magnetized-object-bound-current/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vector-potential-and-magneticfield-by-magnetized-object-bound-current/</guid>
      <description>외부 자기장에 의해 자화된 물체가 있다고 하자. 이 물체는 자화밀도 $\mathbf{M}$을 가질 것이고 이 자화밀도에 의해 새로운 자기장이 생길 것이다.하나의 자기 쌍극자가 만드는 벡터 전위는 $$ \mathbf{A} (\mathbf{r}) = \dfrac{\mu_0}{4\pi}\dfrac{\mathbf{m} \times \hat{\boldsymbol{\eta}} }{\eta ^2} $$ 자화밀도는 단위부피당 쌍극자 모멘트이므로 $\mathbf{M}=\dfrac{\mathbf{m}}{d\tau}</description>
    </item>
    
    <item>
      <title>시계열분석에서의 정상성</title>
      <link>https://freshrimpsushi.github.io/posts/stationarity-in-time-series-analysis/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stationarity-in-time-series-analysis/</guid>
      <description>시계열 데이터의 평균과 분산이 일정할 때 정상성Stationarity 을 갖는다고 한다.* 정상正常Normal이 아니라 정상定常Stational이다.데이터가 정상성을 가진다는 것은 평균과 분산이 안정되어 있어서 분석하기 쉽다는 의미가 된다. 데이터가 정상성을 가지지 않으면 분석이 어렵기 때문에 정상성을 갖도록 만드는 전처리를 하게</description>
    </item>
    
    <item>
      <title>외부 자기장에 의한 전자 궤도의 변화와 반자성</title>
      <link>https://freshrimpsushi.github.io/posts/diamagnetism-and-changes-of-electron-orbits-by-magneticfield/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diamagnetism-and-changes-of-electron-orbits-by-magneticfield/</guid>
      <description>핵 주위를 반지름 $R$로 공전하고 있는 전자가 있다고 하자. 움직이는 점전하는 정상전류가 되지 않지만 그 속도가 너무 빠르기 때문에 정상전류처럼 보인다 . 주기는 이동거리를 속도로 나눈 것이므로 $$ T=\dfrac{2\pi R}{v} $$ 전류는 단위시간당 지나가는 전하량이고 전자는 궤도 위의 어느 한 점을 한 주기에 한 번 지나가므로 $$ I=\dfrac{-e}{T}=-\dfrac{ev}{2 \pi R} $$ 따라서 이 전자 궤도의 자기 쌍극자 모멘트는</description>
    </item>
    
    <item>
      <title>자기 쌍극자가 외부 자기장에 의해 받는 토크와 상자성</title>
      <link>https://freshrimpsushi.github.io/posts/paramagnetism-and-torque-experienced-by-magnetic-dipole-by-magneticfield/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/paramagnetism-and-torque-experienced-by-magnetic-dipole-by-magneticfield/</guid>
      <description>전기 쌍극자가 외부 전기장에 의해 토크를 얻는 것 처럼 자기 쌍극자도 그러하다. 아래 그림과 같이 일정한 외부 자기장 $\mathbf{B}=B\hat{\mathbf{z}}$하에 전류 고리가 있다고 하자. 작은 사각형의 전류고리를 겹쳐서 임의의 모양으로 생긴 전류고리를 근사할 수 있으므로 사각형의 전류 고리에 대해서만 생각하도록 하자.각 변</description>
    </item>
    
    <item>
      <title>자화밀도와 자성체</title>
      <link>https://freshrimpsushi.github.io/posts/magnetization-and-magnetic-substance/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/magnetization-and-magnetic-substance/</guid>
      <description>겉으로 봤을 때 자성이 없는 물체가 있다고 하자.이 물체를 원자수준까지 자세히 들여다보자.핵 주위를 도는 전자에 의해 미세한 전류가 생성되고 이는 자기 현상을 만들어낸다.각각의 원자 마다 아주 작은 자기 쌍극자 가 생기는 것이다.하지만 원자들의 방향이 전부 제각각이기 때문에 이 쌍극자 모멘트들을 전부 더하면 $0$이다. $$ \mathbf{m}_{net}=0 $$ 그래서 거시적으로 보면</description>
    </item>
    
    <item>
      <title>도박꾼의 파산 문제</title>
      <link>https://freshrimpsushi.github.io/posts/gamblers-ruin-problem/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gamblers-ruin-problem/</guid>
      <description>도박꾼의 파산 문제 는 랜덤워크의 일종으로 두 명의 플레이어가 한정된 돈을 걸고 둘 중 하나가 파산할 때까지 반복하는 게임을 상정한다.당신이 플레이어 중 하나라고 한다면, 위 도식과 같이 당신이 이길 확률이 $p$ 고 질 확률이 $(1-p)$ 라고 할 수 있다. 상태 $0$ 은 당신이 파산한 경우고, 상태 $N$ 은 당신이 상대의 돈을 모두 딴 경우로 더 이상 게임을 반복하지 않는다. 이는 $0$ 과</description>
    </item>
    
    <item>
      <title>갈루아 이론</title>
      <link>https://freshrimpsushi.github.io/posts/galois-theory/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/galois-theory/</guid>
      <description>$K$ 가 $F$ 의 유한정규확대체고 $F \le E \le K$ 라 하자. 고정된 $E$ 를 남기는 $G ( K / F )$ 의 부분군을 $\lambda (E) $ 와 같이 나타내자. 그러면 사상 $\lambda $ 은 $F$ 와 $K$ 사이의 모든 $E$ 를 $G ( K / F )$ 의 모든 부분군으로 대응시키는 동형사상이 된다. $\lambda$ 는 다음의 성질들을 가진다.(1) $\lambda ( E ) = G ( K / E )$(2) $ E = K_{ G ( K / E ) } = K_{ \lambda (E) }$**(3)** $H \le G ( K / F ) $ 에 대</description>
    </item>
    
    <item>
      <title>ROC 곡선의 AUC 를 이용해 모형 비교하는 법 AUC Area Under Curve</title>
      <link>https://freshrimpsushi.github.io/posts/887/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/887/</guid>
      <description>*하단에 예제코드 전체가 있다.ROC 곡선은 기본적으로 사각형 $[0,1]^2$ 을 가득 채울수록 좋고, 곡선의 왼쪽 상단의 꺾이는 점이 $(0,1)$ 에 가까울 수록 좋다.위의 두 ROC 곡선이 있다고 한다면 마음 편하게 &amp;lsquo;좋다&amp;rsquo;라고 할 수 있는 쪽은 오른쪽이다. 이 &amp;lsquo;좋다&amp;rsquo;는 말이 의미하는 것은 ROC 곡선을 그려내는 모형이 더 낫다</description>
    </item>
    
    <item>
      <title>분리벡터 1r^2의 회전 Curl of separation vector 1</title>
      <link>https://freshrimpsushi.github.io/posts/r2/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/r2/</guid>
      <description>$\nabla \times \dfrac{\hat{\boldsymbol{\eta}} }{\eta ^2} =0$이 식이 특별한 의미를 가지는 것은 아니다.자기장의 발산을 구하는 과정에서 나오는데 계산이 간단하지 않아 따로 설명한다.$\boldsymbol{\eta}=(x-x&#39;)\mathbf{x} + (y-y&#39;)\mathbf{y} + (z-z&#39;)\mathbf{z}$는 분리벡터 $$ | \boldsymbol{\eta} |=\eta=\sqrt{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2} $$ $$ \hat{ \boldsymbol{\eta}}=\dfrac{ \boldsymbol{\eta} } { \eta}=\dfrac{(x-x&#39;)\mathbf{x} + (y-y&#39;)\mathbf{y} + (z-z&#39;)\mathbf{z}}{\sqrt{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2}} $$ $$ \dfrac{\hat{\boldsymbol{\eta}}}{\eta^2}=\dfrac{1}{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2}\dfrac{(x-x&#39;)\mathbf{x} + (y-y&#39;)\mathbf{y} + (z-z&#39;)\mathbf{z}}{\sqrt{(x-x&#39;)^2+(y-y&#39;)^2 +</description>
    </item>
    
    <item>
      <title>펠 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/pells-equation/</link>
      <pubDate>Mon, 25 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pells-equation/</guid>
      <description>$a_{n} : = n^2$ 를 **사각수**Square Number 라고 한다.$\displaystyle b_{m} : = {{ m ( m + 1 ) } \over {2}}$ 를 **삼각수**Triangular Number 라고 한다.이들 중에서 사각수면서도 삼각수인 수가 있는지 한번 생각해보면, 당장 $a_{1} =b_{1} = 1$ 과 $\displaystyle a_{6} = 6 ^2 = 36 = {{ 8 \cdot 9 } \over {2}} = b_{8}$ 이 있다. 이제 일반적으로 사각수이면서도 삼각수인 경</description>
    </item>
    
    <item>
      <title>ROC 곡선을 이용해 최적의 컷오프 찾는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</link>
      <pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</guid>
      <description>*하단에 예제코드 전체가 있다.ROC 곡선을 그리면 트레이닝 데이터로 얻은 모형이 테스트 데이터를 어느정도로 잘 설명하는지 한 눈에 보여서 유용하다. 하지만 이 곡선은 모든 컷오프에 대한 분류율을 계산하고 이은 것이므로 결국 &amp;lsquo;어떤 컷오프로 0과 1을 분류할 것인가&amp;rsquo;는 알 수 없다. 이것을 알아내기 위해 교차검증의 방법론을</description>
    </item>
    
    <item>
      <title>루트가 포함된 분수 유리화 빠르게 하기</title>
      <link>https://freshrimpsushi.github.io/posts/874/</link>
      <pubDate>Fri, 22 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/874/</guid>
      <description>$\displaystyle {{ x } \over { \sqrt{a} \pm \sqrt{b} }} = {{ x \left( \sqrt{a} \mp \sqrt{b} \right) } \over { a - b }}$분수의 유리화는 개념적으로는 쉽지만 분자 분모에 복잡한 항을 곱하고 정리하는 부분에서 계산이 많아져서 어렵다.그러나 위의 공식을 활용하면 빠르고 간단하게, 계산실수를 최소한으로 줄이면서 유리화를 해낼 수 있다.핵심은 이러나 저러나 분모의 루트를 벗겨내기 위해 $( \alpha^2 - \beta^2 ) $ 꼴을 만든</description>
    </item>
    
    <item>
      <title>일반화된 랜덤워크</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-random-walk/</link>
      <pubDate>Thu, 21 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-random-walk/</guid>
      <description>시계열에서의 랜덤워크확률과정 $\left\{ X_{n} \right\} $ 의 상태공간이 정수의 집합 $\left\{ \cdots , -2 , -1, 0 , 1 , 2 , \cdots \right\} $ 이고, 상태 $0$ 에서 이라고 하자. 다음 스텝에서 $1$ 만큼 작아질 확률을 $p$, $1$ 만큼 커질 확률이 $(1-p)$ 일 때 $\left\{ X_{n} \right\}$ 을 **일반화된 랜덤워크** 라고 한다.$\displaystyle p = {{1} \over {2}}$ 이면 상태 $0$ 은 리커런트하고, $\displaystyle p \ne {{1} \over {2}}$ 이면 상태 $0$ 은</description>
    </item>
    
    <item>
      <title>R 에서 ROC 곡선 그리는 법 How to Plot ROC Curve</title>
      <link>https://freshrimpsushi.github.io/posts/868/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/868/</guid>
      <description>*하단에 예제코드 전체가 있다.오류행렬의 False Positive Rate와 True Positive Rate를 각각 축으로 두고 그린 그림을 ROC 곡선Receiver Operating Characteristic Curve 이라고 한다. ROC 곡선은 모델의 퍼포먼스를 한 눈에 보여줄 뿐만 아니라 최적의 컷오프를 찾고 모델 간의 비교에도 쓰이는 등 요긴하게 쓸 데가 많다. 예제를 통해 R 에서 ROC 곡선을 그려보고 그 의미를 이해해보자. 핵심적인 패</description>
    </item>
    
    <item>
      <title>중심각이 작을 때 호의 길이와 현의 길이는 근사함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/913/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/913/</guid>
      <description>중심각 $\theta$가 충분히 작을 때 현의 길이와 호의 길이는 근사하다.$\theta \rightarrow 0$일 때 $\overline{AB} \approx \stackrel\frown{AB}$현의 길이 $\overline{AB} =2\overline{AM}=2r\sin \frac{\theta}{2}$제2코사인법칙과 삼각함수의 반각공식을 이용해도 같은 결과를 얻지만 위 방법이 훨씬 짧고 쉽다.호의 길이 중심각이 $\theta$이고 반</description>
    </item>
    
    <item>
      <title>로렌츠 끌개</title>
      <link>https://freshrimpsushi.github.io/posts/lorenz-attractor/</link>
      <pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lorenz-attractor/</guid>
      <description>$\begin{cases} \displaystyle {{dx} \over {dt}} = - \sigma x + \sigma y \\ \displaystyle {{dy} \over {dt}} = - xz + \rho x - y \\ \displaystyle {{dz} \over {dt}} = xy - \beta z \end{cases}$로렌츠 어트랙터 란 대기의 대류를 위와 같은 연립 상미분방정식으로써 표현할 수 있는 수학적 모델을 말한다.$\sigma$ 는 점성과 열전도율에 관한 파라매터인 프란틀 수Prandtl Number , $\rho$ 는 유체의 열 전달방법에 관한 파라매터인 레일리</description>
    </item>
    
    <item>
      <title>교차검증</title>
      <link>https://freshrimpsushi.github.io/posts/cross-validation/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cross-validation/</guid>
      <description>데이터 분석을 해서 얻은 모델은 그 퍼포먼스가 적절한지 확인하는 과정이 필요하다. 주어진 데이터만 잘 설명하고 실전에서 전혀 힘을 쓰지 못하면 분석을 하는 의미가 없기 때문이다. 이를 위해서 전체 데이터를 모델을 얻는데 사용할 데이터셋과 그 모형의 퍼포먼스를 평가할 데이터셋으로 쪼갠다.모델을 얻겠다는 것은 주어진 데이터를 이용해 다른 데이터도 설명해</description>
    </item>
    
    <item>
      <title>갈루아체</title>
      <link>https://freshrimpsushi.github.io/posts/galois-field/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/galois-field/</guid>
      <description>소수 $p$ 와 자연수 $n$ 에 대해 기수가 $p^{n}$ 인 유한체를 $p^{n}$ 차 갈루아체 라 정의하고 $\text{GF} \left( p^{n} \right) $ 와 같이 나타낸다. 유한체는 갈루아체 뿐이고, 주어진 $p$ 와 $n$ 에 대해 갈루아체는 유일하게 존재한다.*여기서 유일하다는 말은 서로 다른 체라고 해도 동형사상이 존재해서 사실상 같은 체라는 뜻이다.가우스가 처음 유한체의 개념을 떠올렸을 때만해도 그 실체를 믿는 사람은</description>
    </item>
    
    <item>
      <title>확률과정의 극한</title>
      <link>https://freshrimpsushi.github.io/posts/limit-of-probability-process/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-of-probability-process/</guid>
      <description>현재의 상태가 $i$ 일 때, 무한한 스탭을 거쳐 $j$ 로 갈 확률을 $\displaystyle \pi_{j} := \lim_{n \to \infty} p_{ij}^{ ( n ) }$ 과 같이 나타낸다.통계학이든 응용수학이든 하는 일이 대개 그렇지만 주된 관심사는 미래의 예측이다. 확률과정론에서 관심을 갖는 부분 역시 한 치 앞은 물론 먼 미래에 어떻게 될지가 궁금하다. 그리고 주로 이런 표현은 무한을 이용한다.정의에서 $\displaystyle \pi_{j} = \sum_{i} \pi_{i} p_{ij}$ 과 같이 표현할 수</description>
    </item>
    
    <item>
      <title>가분확대체</title>
      <link>https://freshrimpsushi.github.io/posts/separable-extension/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separable-extension/</guid>
      <description>$E$ 가 $F$ 의 확대체라고 하자.1. $E$ 에서 $\overline{F}$ 의 부분체로 가는 동형사상 중 고정된 $F$ 를 남기는 동형사상의 갯수를 $F$ 상에서 $E$ 의 인덱스Index 라 하고 $\left\{ E : F \right\}$ 와 같이 나타낸다.2. $E$ 가 유한체라고 할 때, $\left\{ E : F \right\} = [ E : F ]$ 면 $E$ 를 $F$ 의 가분확대체 라고 한다.3. $ F ( \alpha ) $ 가 $F$ 의 가분확대체면 $\alpha \in \overline{F}$ 가 $F$ 상에서 가분 이라고 한다.4. $f(x)$</description>
    </item>
    
    <item>
      <title>확률과정론에서 상태의 유형</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-state-in-stochastic-process/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-state-in-stochastic-process/</guid>
      <description>$i,j$ 를 스테이트라고 하자.1. $p_{ij}^{ ( n ) } &amp;gt; 0$ 를 만족하는 $n \ge 0$ 이 존재하면 $j$ 는 $i$ 로부터 **억세서블**Accessible 하다고 한다.**2.** $i$ 와 $j$ 가 서로 억세서블하면 **커뮤니케이트**Cummunicate 하다고 한다.**3.** 커뮤니케이트한 스테이트들의 집합 중 가장 큰 것을 **클래스**Class 라고 한</description>
    </item>
    
    <item>
      <title>1계 미분방정식에 대한 존재성-유일성 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-existence-uniqueness-theorem-for-1st-order-ode/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-existence-uniqueness-theorem-for-1st-order-ode/</guid>
      <description>$E$ 가 $\mathbb{R}^{n}$ 에서 오픈이고 $ \mathbb{f} \in C^{1} (E)$ 와 $\phi_{0} \in E$ 에 대해 초기값 문제 $\begin{cases} \dot{ \phi } = \mathbb{f} ( \phi ) \\ \phi (0) = \phi_{0} \end{cases}$ 가 있다고 하자. 그러면 어떤 $[ - h , h ]$ 에서 주어진 초기값 문제의 솔루션 $\phi( t )$ 은 유일하게 존재한다.* 유클리드 공간 $\mathbb{R}^{n}$ 의 볼을 $B \left( \mathbb{x}_{0} ; d \right) := \left\{ \mathbb{x} \in \mathbb{R}^{n} \mid | \mathbb{x}_{0} - \mathbb{x} | &amp;lt; d \right\} $, $B \left[ \mathbb{x}_{0} ; d \right] = \left\{ \mathbb{x} \in \mathbb{R}^{n} \mid | \mathbb{x}_{0} - \mathbb{x} | \le d \right\} $ 과 같이 표현한다.당연히</description>
    </item>
    
    <item>
      <title>로드리게스 공식</title>
      <link>https://freshrimpsushi.github.io/posts/rodrigues-formula/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rodrigues-formula/</guid>
      <description>**로드리게스 공식$(\mathrm{Rodrigues\ formula})$ $$ P_l(x)=\dfrac{1}{2^l l!} \dfrac{d^l}{dx^l}(x^2-1)^l $$ 이 글 에서 르장드르 미분 방정식의 해가 멱급수 꼴이라고 가정하고 풀어서 구한 해를 르장드르 다항식이라 했다. 각 $l$에 대한 정확한 드장드르 다항식을 얻는 방법이 있는데 그게 로드리게스 공식이다. 로드리게스 공식이 르장드르 방정식의 해가 됨을 보이는 과정은 아래와 같다</description>
    </item>
    
    <item>
      <title>채프만-콜모고로프 방정식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-chapman-kolmogorov-equation/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-chapman-kolmogorov-equation/</guid>
      <description>$$ \displaystyle { p }_{ ij }^{ (n+m) } =\sum _{ k } { { p } _{ ik }^{ (n) } { p } _{ kj }^{ (m) } } $$ 스테이트 $i$ 에서 $j$ 로 갈 때까지 걸리는 $n+m$ 의 스텝을 $n$ 과 $m$ 으로 쪼개어 표현할 수 있다는 뜻이다.굳이 증명하지 않고 직관적으로 생각해봐도 $i$ 부터 $k$ 까지 $n$ 번 걸리는 확률과 $k$ 에서 $j$ 까지 $m$ 번 걸리는 확률을 생각해보면 $i$ 에서 $k$ 를 거쳐 $j$ 까지 갈 확률일테고, 모든 상태 $k$ 에 대해서 이</description>
    </item>
    
    <item>
      <title>국소 립시츠 조건</title>
      <link>https://freshrimpsushi.github.io/posts/local-lipschitz-condition/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/local-lipschitz-condition/</guid>
      <description>강한 립시츠 조건 $\implies$ 립시츠 조건 $\implies$ 국소 립시츠 조건$E$ 가 $\mathbb{R}^{n}$ 에서 오픈이고 $\mathbb{f} : E \to \mathbb{R}^{n}$ 이라고 하자. 모든 $\mathbb{x} _{0} \in E$ 에 대해 $B \left( \mathbb{x} _{0} ; \varepsilon \right) \subset E $ 를 만족하는 $\varepsilon &amp;gt; 0 $ 과 모든 $\mathbb{x} , \mathbb{y} \in B \left( \mathbb{x} _{0} ; \varepsilon \right)$ 에 대해 $ | \mathbb{f} ( \mathbb{x} ) - \mathbb{f} ( \mathbb{y} ) | \le K | \mathbb{x} - \mathbb{y} | $ 를 만족하는 $K &amp;gt;0$ 가 존재하면 $\mathbb{f}$ 가 $E$ 에서 로컬리 립시츠Locally Lipshitz 라고 한다.$\math</description>
    </item>
    
    <item>
      <title>마코프 체인</title>
      <link>https://freshrimpsushi.github.io/posts/mc-markov-chain/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mc-markov-chain/</guid>
      <description>1. 확률과정 $ \left\{ X_{n} \right\} $ 이 $p \left( X_{n+1} = j \mid X_{n} = i , X_{n-1} = k , \cdots , X_{0} = l \right) = p \left( X_{n+1} = j \mid X_{n} = i \right) $ 을 만족하면 **마코프 체인** 이라고 한다.**2.** $p_{ij} := p \left( X_{n+1} = j \mid X_{n} = i \right) $ 을 **전이 확률**Transition Probability 이라고 하며 현재 상태를 의미하는 $i$ 를 **소스 스테이트**Source State , 목표 상태를 의미하는 $j$ 를 **타</description>
    </item>
    
    <item>
      <title>피카드 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/picards-method/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/picards-method/</guid>
      <description>$E$ 가 $\mathbb{R}^{n}$ 에서 오픈이고 $ \mathbb{f} \in C^{1} (E)$ 에 대해 초기값 문제 $\begin{cases} \dot{ \phi } = \mathbb{f} ( \phi ) \\ \phi (0) = \phi_{0} \end{cases}$ 가 있다고 하자. 함수의 시퀀스 $\left\{ \mathbb{u}_{k} (t) \right\} _{ k =0}^{ \infty }$ 을 $\begin{cases} \mathbb{u}_{0} (t) = \phi_{0} \\ \displaystyle \mathbb{u}_{k+1} (t) = \phi_{0} + \int_{0}^{t} \mathbb{f} \left( \mathbb{u}_{k} (s) \right) ds \end{cases}$ 과 같이 정의하면 연속함수 $\displaystyle \mathbb{u} (t) := \lim_{k \to \infty} \mathbb{u}_{k} (t) $ 는 주어진 초기값 문제의 솔루션이다.당연히 $\mathbb{u}$ 는 존재하는 것으로 가정하며, 존재하지 않는다면 의미 없는 정리다.</description>
    </item>
    
    <item>
      <title>르장드르 미분 방정식의 풀이와 르장드르 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-legendre-differential-equation-and-legendre-polynomial/</link>
      <pubDate>Mon, 11 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-legendre-differential-equation-and-legendre-polynomial/</guid>
      <description>르장드르 미분방정식 $(1-x^2)\dfrac{d^2 y}{dx^2} -2x\dfrac{dy}{dx}+l(l+1) y=0$의 해를 르장드르 다항식이라 하고 $P_l(x)$로 표시한다. 각 $l$에 따른 르장드르 다항식은 $$ \begin{array}{l} P_0(x)=1 \\ P_1(x)=x \\ P_2(x)=\dfrac{1}{2}(3x^2-1) \\ P_3(x)=\dfrac{1}{2}(5x^3-3x) \\ P_4(x)=\dfrac{1}{8}(35x^4-30x^2+3) \\ P_5(x)=\dfrac{1}{8}(63x^5-70x^3+15x)\end{array} $$ $$ \vdots $$ $$ (1-x^2)\dfrac{d^2 y}{dx^2} -2x\dfrac{dy}{dx}+l(l+1) y=0 $$ 위 식을 르장드르 미분 방정식 혹은 르장드르 방정식 이라고 한다. 그리고 이 방정식의 해를 르장드르 다항식$(\mathrm{Legendre\ polynomial})$ 이라 한다</description>
    </item>
    
    <item>
      <title>라이프니츠 규칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-leibnizs-rule/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-leibnizs-rule/</guid>
      <description>**라이프니츠 규칙($\mathrm{Leibniz&amp;rsquo;s\ rule}$, 라이프니츠 정리) $$ \dfrac{d}{dx} (fg)=\dfrac{df}{dx}g+f\dfrac{dg}{dx} $$ $$ \begin{align*} \dfrac{d^n}{dx^n}(fg)&amp;amp;=\sum \limits_{k=0}^{n}\frac{n!}{(n-k)!k!}\dfrac{d^{n-k}f}{dx^{n-k}}\dfrac{d^k g}{dx^k} \\ &amp;amp;=\sum \limits_{k=0}^{n}{}_{n}\mathrm{C}_k \dfrac{d^{n-k}f}{dx^{n-k}}\dfrac{d^k g}{dx^k} \\ &amp;amp;=\sum \limits_{k=0}^{n} \binom{n}{k} \dfrac{d^{n-k}f}{dx^{n-k}}\dfrac{d^k g}{dx^k} \end{align*} $$ 첫번째 식은 미분의 곱의 법칙 혹은 곱의 규칙이라고 잘 알려진 식이다. 두 함수의 곱을 한 번 미분했을 때의 결과를 쉽게 표현한 것이다. 여기서 좀 더 일반화하여 $n$번 미분했을 때의 결과를 나타내는 것이</description>
    </item>
    
    <item>
      <title>멱급수와 그 특징</title>
      <link>https://freshrimpsushi.github.io/posts/power-series/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/power-series/</guid>
      <description>** **** **급수$(\mathrm{Series})$ 수열 $\left\{a_n\right\}$이 주어졌을 때 첫 항부터 각 항을 더하여 아래와 같이 나타낸 것을 말한다. $$ a_1+a_2+a_3+ \cdots + a_n +\cdots $$ $$ \sum \limits_{n=1}^\infty a_n $$ 무한급수라고도 한다.특정한 항까지만 더한 것을 부분합이라 하고 흔히 $S_n$으로 표기한다. $$ S_n=a_1+a_2+ \cdots +a_n = \sum \limits_{k=1}^n a_k $$ 이때 수열 $\left</description>
    </item>
    
    <item>
      <title>확률과정이란</title>
      <link>https://freshrimpsushi.github.io/posts/stochastic-process/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stochastic-process/</guid>
      <description>1. 확률변수 $X : \Omega \to E$ 의 공역을 상태공간 이라고 한다.2. 확률변수의 집합 $ \left\{ X_{t} \mid t \in [ 0 , \infty ) \right\} $ 을 **연속적 확률과정** 이라고 한다.**3.** 확률변수의 수열 $\left\{ X_{n} \mid n = 0, 1, 2, \cdots \right\} $ 을 **이산적 확률과정** 이라고 한다.확률과정은 과정Process이라는 단어 때문에 이해하기 어려운, 전형적으로 말이 어려워서 어려운</description>
    </item>
    
    <item>
      <title>로지스틱 회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/logistic-regression/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logistic-regression/</guid>
      <description>R 에서 로티스틱 회귀분석 결과 보러가기호스머-렘소 적합도 검정 보러가기다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 $Y$ 가 질적변수, 그 중에서도 계급이 두개뿐인 경우가 있을 수 있다. 예를 들어 남자와 여자, 성공과 실패, 양성과 음성, $0$ 과 $1$ 등이 있고, 편의상 그냥 $Y=0$ 혹은 $Y=1$ 이라고 하자. 이렇게 종속변수가 이항적인 경우 관심사는 &amp;l</description>
    </item>
    
    <item>
      <title>유일 인수분해 정역</title>
      <link>https://freshrimpsushi.github.io/posts/ufd-unique-factorization-domain/</link>
      <pubDate>Wed, 30 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ufd-unique-factorization-domain/</guid>
      <description>유클리드 정역 $\implies$ 주 아이디얼 정역 $\implies$ 유일 인수분해 정역 $\implies$ 정역1. 정역 $D$ 의 $0$ 도 아니고 단원도 아닌 모든 원소에 대한 유한 인수분해가 유일하게 존재하면 $D$ 를 유일 인수분해 정역 이라고 한다.2. 유일 인수분해 정역 $D$ 의 $a_{1} , \cdots , a_{n}$ 에 대해 $d \mid a_{i}$ 이고 $a_{i}$ 의 모든 약수가 $d$ 를 나누면 $d$ 를 $a_{1} , \cdots , a_{n}$ 의 **최대공약소**Greatest Common Divisor 라 하고 gcd</description>
    </item>
    
    <item>
      <title>치환을 이용한 비동차 오일러 미분 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-nonhomogenuous-euler-differential-equations-using-substitutions/</link>
      <pubDate>Wed, 30 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-nonhomogenuous-euler-differential-equations-using-substitutions/</guid>
      <description>**오일러 방정식 $$ a_2 x^2 \dfrac{d^2 y}{d x^2} + a_1 x \dfrac{dy}{dx} + a_0 y =f(x) \tag{1} $$ 혹은 $$ a_2 x^2 y&#39;&#39; + a_1 x y&#39; +a_0 y = f(x) $$ 혹은 $$ x^2 y&#39;&#39; + \alpha x y&#39; + \beta y = f(x) $$ 오일러-코시 방정식$(\mathrm{Euler-Cauchy\ equation})$ 이라고도 부른다. $f(x)=0$인 동차방정식 꼴이라면 비교적 쉽게 풀 수 있다. 위와 같은 비동차 방정식 꼴이라면 계수에 독립변수가 있는 꼴이라</description>
    </item>
    
    <item>
      <title>통계적 분석에서의 변수 선택 기준</title>
      <link>https://freshrimpsushi.github.io/posts/variable-selection-criterion-in-statistical-analysis/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/variable-selection-criterion-in-statistical-analysis/</guid>
      <description>변수를 선택하는 문제는 필연적으로 분석자의 주관이 개입할 수 밖에 없지만, 가능한 한 객관적인 결론을 내릴 수 있게 도와주는 수치적인 지표가 필요했다. 그런 값들을 계산해낼 수 있다면 변수 선택 절차를 언제 멈추느냐에 대한 명쾌한 해답이 된다. 다만 이 기준에도 여러가지 종류가 있으며, 기준을 다르게 적용하면 결과 역시 달라질 수 있다.1. 설명력R-sq</description>
    </item>
    
    <item>
      <title>주 아이디얼 정역</title>
      <link>https://freshrimpsushi.github.io/posts/pid-principal-ideal-domain/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pid-principal-ideal-domain/</guid>
      <description>유클리드 정역 $\implies$ 주 아이디얼 정역 $\implies$ 유일 인수분해 정역 $\implies$ 정역주 아이디얼 정역 $\implies$ 뇌터 환정역 $D$ 의 $p \ne 0 $ 가 단원이 아니라고 하자.1. $a \mid b$ 이고 $b \mid a$ 면 $a,b$ 가 연합Associates 이라고 한다.2. $\forall a,b \in D$ 와 $p=ab$ 에 대해 $a$ 나 $b$ 중 하나가 단원이면 $p$ 를 기약원 Irreducible Element 이라고 한다.3. $\forall a,b \in D$ 에 대해 $p \mid ab $$ \implies $$ p \mid a$ 혹은 $p \mid b$ 면 $p$ 를 소원</description>
    </item>
    
    <item>
      <title>소수를 3으로 나눈 나머지가 1이 되는 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/824/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/824/</guid>
      <description>소수를 4로 나눈 나머지가 1이 되는 필요충분조건 $p \ne 3$ 이 소수라고 하자. $p \equiv 1 \pmod{3} $$ \iff$ 어떤 $a,b \in \mathbb{Z}$ 에 대해 $p = a^2 - ab + b^2$ $p=3$ 은 제외했지만, 사실 $ 3= 2^2 - 2 \cdot 1 + 1^2$ 이므로 정리에 포함되어도 큰 상관은 없다. 예를들어 $13 \equiv 1 \pmod{4}$ 는 $13 = 1 - 4 + 16 = 1^2 - 1 \cdot 4 + 4^2$ $37 \equiv 1 \pmod{4}$ 는 $37 = 9 -21 + 49 = 3^2 - 3 \cdot 7+ 7^2$ $61 \equiv 1 \pmod{4}$ 는 $61 = 16 - 36 + 81 = 4^2 - 4 \cdot 9</description>
    </item>
    
    <item>
      <title>뇌터 환</title>
      <link>https://freshrimpsushi.github.io/posts/noetherian-ring/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/noetherian-ring/</guid>
      <description>주 아이디얼 정역 $\implies$ 뇌터 환$N$ 을 환이라고 하자.1. $N$ 의 아이디얼들이 $S_{1} \le S_{2} \le \cdots$ 을 만족할 때 이를 **오름사슬**Ascending Chain 이라고 한다.**2.** 오름사슬 $\left\{ S_{i} \right\}_{i \in \mathbb{N} }$ 에 대해 $S_{n} = S_{n+1} = \cdots $ 을 만족하는 $n \in \mathbb{N} $ 이 존재하면 **정상적**Stationary 이라고 한다. 다시 말해 정상적 오름사슬에선 아이디얼이 어느</description>
    </item>
    
    <item>
      <title>소수를 4로 나눈 나머지가 1이 되는 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/822/</link>
      <pubDate>Fri, 25 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/822/</guid>
      <description>소수를 3으로 나눈 나머지가 1이 되는 필요충분조건$p \ne 2$ 가 소수라고 하자.$p \equiv 1 \pmod{4} $$ \iff$ 어떤 $a,b \in \mathbb{Z}$ 에 대해 $p = a^2 + b^2 $$ p=2$ 는 제외했지만, 사실 $ 2= 1^2 + 1^2$ 이므로 정리에 포함되어도 큰 상관은 없다.예를들어$13 \equiv 1 \pmod{4}$ 는 $13 = 4 + 9 = 2^2 + 3^2 $$ 37 \equiv 1 \pmod{4}$ 는 $37 = 1 + 36 = 1^2 + 6^2 $$ 61 \equiv 1 \pmod{4}$ 는 $61 = 25 + 36 = 5^2 + 6^2$이러한 팩트는 그 자체</description>
    </item>
    
    <item>
      <title>통계적 분석에서의 변수 선택 절차</title>
      <link>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistical-analysis/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistical-analysis/</guid>
      <description>*하단에 예제코드 전체가 있다.다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 독립변수는 $p$ 개로, 회귀분석의 여러가지 가정들을 잘 만족하고 다중공선성이 없으며 설명력이 높다면 좋을 것이다.물론 정보라는 것은 많으면 많을수록 좋지만, 지나치게 많은 데이터로 얻은 회귀모형은 사용하는데에도 많은 데이터를 요구한다. 그래서 가능하다면</description>
    </item>
    
    <item>
      <title>리눅스 포트란 컴파일 후 aout 실행법 How to execute aout file after fortran complie</title>
      <link>https://freshrimpsushi.github.io/posts/865/</link>
      <pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/865/</guid>
      <description>확장자가 .f90인 파일 exameple.f90 을 컴파일하려면 콘솔창에서gfortran example.f90을 입력하면 된다. 실행하고 나면 같은 디렉터리에 a.out 라는 파일이 생긴다. 콘솔창에서./a.out을 입력하면 콘솔창에서 프로그램이 실행되는 것을 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>리만-스틸체스 적분 가능한 두 함수의 곱도 적분 가능함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-multiplication-of-two-riemann-stieltjes-integrable-functions-is-riemann-stieltjes-integrable/</link>
      <pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-multiplication-of-two-riemann-stieltjes-integrable-functions-is-riemann-stieltjes-integrable/</guid>
      <description>리만 적분은 리만-스틸체스 적분에서 $\alpha(x)=x$인 경우이므로 리만 적분에 대한 증명도 아래와 같다.**** **정리 함수의 곱셈은 적분 가능성을 보존한다. 두 함수 $f$, $g$가 구간 $[a,b]$에서 리만-스틸체스 적분가능하면 $fg$도 적분가능하다.**보조정리 1 함수 $f$, $g$가 리만-스틸체스 적분가능하면 $cf$, $f</description>
    </item>
    
    <item>
      <title>R 에서 주성분회귀분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</guid>
      <description>다중공선성 보러가기주성분분석 보러가기*하단에 예제코드 전체가 있다.*수학, 통계적인 기초가 부족한 비전공자는 밑줄 그어진 부분만 읽어도 상관 없다.주성분회귀분석PCR 이란 주성분분석과 다중회귀분석을 합친 것으로, 주성분분석을 통해 얻은 주성분을 새로운 독립변수로 둔 회귀분석을 말한다. 사실 통계학의 관점에서 주성분분석 그 자체는 별</description>
    </item>
    
    <item>
      <title>리만-스틸체스 적분 가능성은 연속함수와의 합성에서 보존됨을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-riemann-stieltjes-integrability-is-preserved-under-composition-by-continuous-function/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-riemann-stieltjes-integrability-is-preserved-under-composition-by-continuous-function/</guid>
      <description>리만 적분은 리만-스틸체스 적분에서 $\alpha(x)=x$인 경우이므로 리만 적분에 대한 증명도 아래와 같다.**함수의 합성은 적분 가능성을 보존한다. 함수 $f$가 구간 $[a,b]$에서 리만-스틸체스 적분가능하고 $m \le f \le M$라고 하자. $\phi$를 구간 $[m,M]$에서 연속인 함수라고 하자. 함수 $h$를 $h=\phi \circ f$라</description>
    </item>
    
    <item>
      <title>소체</title>
      <link>https://freshrimpsushi.github.io/posts/prime-field/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prime-field/</guid>
      <description>환 $R$ 의 모든 원소 $r$ 에 대해 $n \cdot r = 0$ 을 만족하는 가장 큰 자연수 $n$ 을 $R$ 의 표수 Characteristic 라고 정의한다. 만약 그런 자연수가 존재하지 많으면 $0$ 을 $R$ 의 표수로 정의한다.(1) 단위원을 갖는 $R$ 의 표수가 $n&amp;gt;1$ 이면 $R$ 은 $\mathbb{Z}{n}$ 과 동형인 부분환을 가진다.(2) 단위원을 갖는 $R$ 의 표수가 $0$ 이면 $R$ 은 $\mathbb{Z}$ 과 동형인 부분환을 가진다.$F$ 를 체라고 하자.(1)&#39; $F$ 의 표수</description>
    </item>
    
    <item>
      <title>3대 작도 불능 문제 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-impossibility-of-construction/</link>
      <pubDate>Mon, 21 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-impossibility-of-construction/</guid>
      <description>다음 세 가지 작도는 불가능하다.[1] Squaring the circle : 주어진 사각형과 같은 넓이의 원을 작도하라.[2] Doubling the cube : 주어진 정육면체의 부피가 두 배가 되는 정육면체를 작도하라.[3] Trisecting the angle : 주어진 각을 삼등분하라.특히 &amp;ldquo;Squre the circle&amp;quot;는 영미권에서 &amp;ldquo;불가능한 일을 하다&amp;rdquo; 내지 &amp;ldquo;말이 되는 소리</description>
    </item>
    
    <item>
      <title>단조함수는 리만-스틸체스 적분가능함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-monotone-function-is-riemann-stieltjes-integrable/</link>
      <pubDate>Mon, 21 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-monotone-function-is-riemann-stieltjes-integrable/</guid>
      <description>리만 적분은 리만-스틸체스 적분에서 $\alpha(x)=x$인 경우이므로 리만 적분에 대한 증명도 아래와 같다.정리 함수 $f$가 $[a,b]$에서 단조이고, 함수 $\alpha$가 $[a,b]$에서 단조이고 연속이면 $f$는 리만-스틸체스 적분가능하다.보조정리 함수 $f$가 $[a,b]$에서 리만-스틸체스 적분가능할</description>
    </item>
    
    <item>
      <title>통계학에서의 주성분분석</title>
      <link>https://freshrimpsushi.github.io/posts/pca-principal-components-analysis-in-statistics/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pca-principal-components-analysis-in-statistics/</guid>
      <description>다중공선성 보러가기 R 에서 주성분회귀분석 하는 법 보러가기 개요 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.**주성분분석** , 영어 약어로 **PCA** 는 쉽게 말해 양적변수들이 제대로 독립이 되도록 &amp;lsquo;재구성&amp;rsquo;해서 분석하는 방법이다. 다변량 데이터의 분석이라는 관점으로 보자면 보다 적은 변수로 현상을 설명하기 위한 &amp;</description>
    </item>
    
    <item>
      <title>연속함수는 리만-스틸체스 적분가능함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-continuous-function-is-riemann-stieltjes-integrable/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-continuous-function-is-riemann-stieltjes-integrable/</guid>
      <description>리만 적분은 리만-스틸체스 적분에서 $\alpha(x)=x$인 경우이므로 리만 적분에 대한 증명도 아래와 같다..**정리 함수 $f$가 $[a,b]$에서 연속이면 $[a,b]$에서 리만(-스틸체스) 적분가능하다.보조정리1 $X$, $,Y$가 거리공간이고, $f : X \rightarrow Y$가 연속라고 하자. 이때, $X$가 컴팩트거리공간이면 $f</description>
    </item>
    
    <item>
      <title>작도가능수</title>
      <link>https://freshrimpsushi.github.io/posts/construct-number/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/construct-number/</guid>
      <description>$1$ 을 포함해 유한번의 사칙연산과 제곱근을 취함으로써 얻을 수 있는 수를 작도가능 하다고 한다.작도가능이라는 것은 원래 고대 그리스의 논증 기하에서 논의되던 개념이었으나, 현대대수학을 동원하면 캠퍼스로 원을 그리고 자로 선을 그리는 과정이 딱히 필요 없어진다. 어떻게 이 연산들이 작도를 대신하는지 살펴보자.덧셈과 뺄셈은 선분의 끝에 더하거나 빼고</description>
    </item>
    
    <item>
      <title>분산팽창인자</title>
      <link>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</guid>
      <description>*하단에 예제코드 전체가 있다.*우선 다중공선성에 대해 읽어보는 것을 추천한다.다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 할 때 $i$ 번째 독립변수에 대한 다중회귀분석 $X_{i} \leftarrow X_{1} , \cdots, X_{i-1} , X_{i+1} , \cdots, X_{p}$ 의 중회귀계수를 $R_{i}^2$ 라고 두자. $\displaystyle \text{VIF}_{i} : = {{1} \over {1 - R_{i}^{2} }}$ 를 **분산팽창인자**Variance Inflation Factor 라고 한다.VIF는 **분산확대지수** 로 번역되는 경우도 있</description>
    </item>
    
    <item>
      <title>전위의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/property-of-electric-potential/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/property-of-electric-potential/</guid>
      <description>1. 전위의 정의는 다음과 같다. $$ \displaystyle V(\mathbf{r} ) \equiv - \int _\mathcal{O} ^{\mathbf{r}} \mathbf{E} \cdot d \mathbf{l} $$ 잘 살펴보면 기준점 $\mathcal{O}$에 따라 그 값이 달라질 수 있다.예를 들어 새로운 기준점 $\mathcal{O}&#39;$을 잡으면$ \begin{eqnarray} V&#39; (\mathbf{r} )&amp;amp; =&amp;amp; -\int _{\mathcal{O}&#39;}^\mathbf{r} \mathbf{E} \cdot d\mathbf{l} \\ &amp;amp;=&amp;amp; -\int {\mathcal{O}&#39;} ^\mathcal{O} \mathbf{E} \cdot d\mathbf{l} -\int\mathcal{O} ^\mathbf{r} \mathbf{E} \cdot d \mathbf{l} \\ &amp;amp;=&amp;amp; K + V( \mathbf{r} ) \end{eqnarray}$상수 $K$만큼 차이가 날 수 있다</description>
    </item>
    
    <item>
      <title>전위</title>
      <link>https://freshrimpsushi.github.io/posts/electric-potential/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/electric-potential/</guid>
      <description>이 글 을 보면 알 수 있듯이 전기장은 항상 회전이 $0$인 특별한 벡터함수다. 이러한 성질을 이용하여 쉽게 다룰 수 있는 방법이 있다. 바로 전위$(\mathrm{Potential})$ 라는 스칼라함수를 전기장이라는 벡터함수 대신 사용하는 것이다.$\nabla \times \mathbf{E}=0$임을 증명 하는 과정에서 전기장의 폐경로에 대한</description>
    </item>
    
    <item>
      <title>추상대수의 용어로 표현된 대수학의 기본정리</title>
      <link>https://freshrimpsushi.github.io/posts/809/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/809/</guid>
      <description>대수학의 기본정리 증명체 $F$ 의 확대체를 $E$ 라고 하자.(1) $F[x]$ 의 모든 다항함수가 $F$ 에서 영을 가지면 $F$ 를 대수적으로 닫혀있다Algebraically Closed 고 한다.(2) $\overline{ F_{E}} : = \left\{ \alpha \in E \mid \alpha \text{ is algebraic over } F \right\} $ 를 $E$ 에서 $F$ 의 **대수적 폐포**Algebraic Closure 라고 한다.**[1]** $F$ 가 대수적으로 닫혀있다 $\iff$ 모든 $f(x) \in F[x]$ 는 $F[x]$ 의</description>
    </item>
    
    <item>
      <title>가우스의 이차상호 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gausss-law-of-quadratic-reciprocity/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gausss-law-of-quadratic-reciprocity/</guid>
      <description>서로 다른 두 홀수 소수 $p , q $ 에 대해**(1) $$ \displaystyle \left( {{ q } \over { p }} \right) = \begin{cases} \left( {{ p } \over { q }} \right) &amp;amp; p \equiv 1 \pmod{4} \lor q \equiv 1 \pmod{4} \\ - \left( {{ p } \over { q }} \right) &amp;amp; p \equiv 3 \pmod{4} \land q \equiv 3 \pmod{4} \end{cases} $$ **(2) $$ \displaystyle \left( {{ p } \over { q }} \right) \left( {{ q } \over { p }} \right) = (-1)^{ { {p-1} \over {2} }{ {q-1} \over {2} } } $$ (1) 과 (2) 는 표현만 다를 뿐 같은 말이다.이차잉여에 대해 너무나 깔끔하게 정리되어 있어서 그 효용</description>
    </item>
    
    <item>
      <title>다중공선성을 찾아내는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</guid>
      <description>*하단에 예제코드 전체가 있다.다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.이 때 독립변수 $ X_{1} , \cdots, X_{p}$ 중에서 독립변수끼리 강한 상관관계를 가지면 **다중공선성**Multicollinearity 이 있다고 한다. 애초에 독립변수끼리 종속적이라는 것 자체가 회귀분석의 가정에 위배되는 말이며, 실제로 수치적인 문제를 야기해 분석 결</description>
    </item>
    
    <item>
      <title>전기장의 회전</title>
      <link>https://freshrimpsushi.github.io/posts/the-curl-of-electric-field/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-curl-of-electric-field/</guid>
      <description>전기장의 회전은 항상 $0$이다. $$ \nabla \times \mathbf{E} = 0 $$ 증명 점전하가 원점에 있는 특별한 경우의 결과로부터 일반적인 결과를 이끌어낼 것이다. 원점으로부터 거리가 $r$인 곳에서 점점하에 의한 전기장은 아래와 같다. $$ \mathbf{E}=\dfrac{1}{4 \pi \epsilon_0 } \dfrac{q}{r^2} \hat{\mathbf{r}} $$ 전기장을 점 $\mathbf{a}$에서부터 점 $\mathbf{b}$까지 구좌표계에 대해서 선적분하면 $$ \begin{eqnarray*}</description>
    </item>
    
    <item>
      <title>가우스 법칙의 적분꼴과 미분꼴</title>
      <link>https://freshrimpsushi.github.io/posts/gausss-law-in-integral-and-differential-form/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gausss-law-in-integral-and-differential-form/</guid>
      <description>**가우스 법칙의 적분꼴 $$ \displaystyle \oint \mathbf{E} \cdot d\mathbf{a} =\frac{1}{\epsilon_0}Q_\mathrm{in} $$ **가우스 법칙의 미분꼴 $$ \displaystyle \nabla \cdot \mathbf{E} = \frac{1}{\epsilon_0}\rho $$ **가우스 법칙 닫힌 곡면을 지나는 전기선속은 그 곡면 내부의 총 전하량과 같다.가우스 법칙을 처음 접할 때 적분꼴로 접했을거다. 발산 정리를 이용해서 똑같은 식이지만 다르게 표현할 수 있다. 유도 과정은 어렵지 않다. 이를 가우스 법칙의 미분꼴이라고 한다. 또한 맥</description>
    </item>
    
    <item>
      <title>대수적 확대체</title>
      <link>https://freshrimpsushi.github.io/posts/algebraic-extension-field/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebraic-extension-field/</guid>
      <description>$E$ 가 $F$ 의 확대체고 $n \in \mathbb{N}$ 이라 하자.(1) $E$ 의 모든 원소가 $F$ 상에서 대수적 수면 $E$ 를 $F$ 의 대수적 확대체 라고 한다.(2) $E$ 가 $F$ 상에서의 $n$ 차원 벡터 공간이면 $E$ 를 $F$ 상에서의 $n$ 차 유한확대체 라고 한다. (3) $F$ 상에서의 유한확대체 $E$ 의 차수 를 $[ E : F ]$ 와 같이 나타낸다.$E$ 가 $F$ 의 유한확대체, $K$ 가 $E$ 의 유한확대체라고 하자.[1] 유한확대</description>
    </item>
    
    <item>
      <title>오일러 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/eulers-criterion/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eulers-criterion/</guid>
      <description>소수 $p \ne 2$에 대해, $\displaystyle a^{{p-1} \over {2}} \equiv \left( {a \over p} \right) \pmod{p} $$ a$ 하나만 QR인지 NR인지 보고싶을 땐 무작정 계산해보면 그만이라는 말이다.물론 거듭제곱이 그렇게 만만한 작업은 아니지만 모든 수를 계산해보는 것보단 나을 것이다.증명 자체는 별로 어렵지 않지만 보조정리가 많이 쓰이기 때문에 어느정도 공부를 해둬야 이해하기 쉽다.증명 $a$ 가 QR인 경우와 NR인</description>
    </item>
    
    <item>
      <title>적분꼴 가우스 법칙의 응용</title>
      <link>https://freshrimpsushi.github.io/posts/application-of-gauss-law-in-integral-form/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/application-of-gauss-law-in-integral-form/</guid>
      <description>그리피스 전자기학 교재에 따르면 가우스 법칙은 늘 성립하지만, 늘 쓸모가 있는 것은 아니다. ** 조건이 잘 갖춰져 있지 않으면 가우스 법칙의 적분을 직접 계산해서 전기장을 구하는 일은 매우 어렵다. 반대로 말하면 특정한 조건 아래에서는 놀라울 정도로 쉬워진다. 그리피스는 이 조건을 대칭성 이라고 말한다. 구체적으로 말하자면 등전기장면 이 있어야 한다. 여</description>
    </item>
    
    <item>
      <title>전기장의 발산</title>
      <link>https://freshrimpsushi.github.io/posts/the-divergence-of-electric-field/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-divergence-of-electric-field/</guid>
      <description>$$ \nabla \cdot \mathbf{E} = \dfrac{1}{\epsilon_0} \rho ( \mathbf{r} ) $$ 전기장 $\mathbf{E}$의 발산을 직접 계산하면 아래와 같다. $\boldsymbol{\eta}$는 분리벡터 다. $$ \displaystyle \mathbf{E} (\mathbf{r}) = \dfrac{1}{4\pi \epsilon_0} \int \left( \dfrac{ \hat {\boldsymbol {\eta}} } { \eta ^2} \right) \rho ( \mathbf{r}&#39; ) d\tau &#39; $$ $$ \begin{eqnarray*} \Rightarrow \nabla \cdot \mathbf{E} &amp;amp;=&amp;amp; \dfrac{1}{4\pi \epsilon_0} \int \nabla \cdot \left( \dfrac{ \hat {\boldsymbol {\eta}} } { \eta ^2} \right) \rho ( \mathbf{r}&#39; ) d\tau &#39; \\ &amp;amp;=&amp;amp; \dfrac{1}{4\pi \epsilon_0} \int 4\pi \delta ^3 (\boldsymbol{\eta} ) \rho ( \mathbf{r}&#39; ) d\tau &#39; \\ &amp;amp;=&amp;amp; \dfrac{1}{4\pi \epsilon_0} 4\pi \int\delta ^3 (\boldsymbol{\mathbf{r} - \mathbf{r}&#39;} ) \rho (</description>
    </item>
    
    <item>
      <title>전기장의 선속과 가우스 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/electric-flux-and-gausss-law/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/electric-flux-and-gausss-law/</guid>
      <description>면 $\mathcal S$를 지나는 $\mathbf{E}$의 선속$(\mathrm{flux})$ $$ \displaystyle \Phi_E \equiv \int_{\mathcal S} \mathbf{E} \cdot d\mathbf{ a} $$ ** **가우스 법칙** $$ \displaystyle \oint_\mathcal{S} \mathbf{E} \cdot d\mathbf{a} = \frac{1}{\epsilon_o}Q $$ **선속, 플럭스 선속, 플럭스란 일반적으로 어떤 물리량이 특정한 면에 대해 수직으로 지나가는 양을 말한다. 예를 들어 관에 흐르는 물이나 기체는 그 관의 수직 면에 대해서 평행하게 흐르기 때</description>
    </item>
    
    <item>
      <title>1r^2의 발산 The divergence of 1</title>
      <link>https://freshrimpsushi.github.io/posts/r2/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/r2/</guid>
      <description>$\nabla \cdot \left( \dfrac{1}{r^2}\hat{ \mathbf{r} } \right) = 4\pi \delta^3(\mathbf{r}) $$ \nabla \cdot \left( \dfrac{1}{\eta^2}\hat{ \boldsymbol{\eta} } \right) = 4\pi \delta^3(\boldsymbol{\eta}) $$ \nabla^2 \left(\dfrac{1}{\eta} \right) =-4\pi \delta^3 ( \mathbf{r} ) $벡터함수 $\mathbf{v} = \dfrac{1}{r^2}\hat{\mathbf{r}}$이 있다고 하자.크기는 거리 제곱에 반비례하고 방향은 반지름 방향이다.이제부터 이 함수의 발산을 계산해보자.구좌표계에서의 기울기 공식 을 사용하면$\nabla \cdot \mathbf{v} = \dfrac{1}{r^2}\dfrac{\partial}{\partial r}\left( r^2\dfrac{1}{r^2} \right) = \dfrac{1}{r^2}\dfrac{\partial}{\partial r</description>
    </item>
    
    <item>
      <title>르장드르 기호의 곱셈적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-legendre-symbols-multiplicativity/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-legendre-symbols-multiplicativity/</guid>
      <description>$2$ 보다 큰 소수 $p$ 에 대해, $\displaystyle \left( { ab \over p } \right) = \left( { a \over p } \right) \left( { b \over p } \right) $정수론에서 $\displaystyle \left( {{x} \over {y}} \right)$ 는 분수가 아니라 르장드르 기호Legendre Symbol 라고 하며, 소수가 아닌 자연수에 대해 일반화하면 표기는 똑같이 쓰되 야코비 기호Jacobi Symbol 라고 한다.르장드르 기호 는 $p$ 보다 작은 자연수 $a$에 대해 $\displaystyle \left( { a \over p } \right) = \cases{ 1 &amp;amp; \text{ a :</description>
    </item>
    
    <item>
      <title>추상대수학에서의 벡터 공간</title>
      <link>https://freshrimpsushi.github.io/posts/vector-space/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vector-space/</guid>
      <description>선형대수학에서의 벡터 공간체 $F$ 와 아벨군 $V$ 의 모든 $\alpha , \beta \in F$ 와 $x, y \in V$ 가 다음의 조건을 만족하면 $V$ 를 $F$ 상의 벡터 공간 이라고 한다. $F$ 의 원소를 스칼라 , $V$ 의 원소를 벡터 라고 한다.(i) $\alpha x \in V$(ii) $ \alpha ( \beta x) = ( \alpha \beta ) x $(iii) $ \alpha (x + y) = \alpha x + \alpha y $(iv) $1 x = x$첨수집합 $I$ 에 대해 $ \left\{ x_{i} \right\}_{i \in I} \subset V$ 이라고 하자.**(1)** 어떤 $ \left\{ \alpha_{i} \right\}_{</description>
    </item>
    
    <item>
      <title>이차잉여와 비이차잉여</title>
      <link>https://freshrimpsushi.github.io/posts/quadratic-residue-and-quadratic-nonresidue/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quadratic-residue-and-quadratic-nonresidue/</guid>
      <description>소수 $p \ne 2$ 와 $a &amp;lt; p$ 에 대해 합동방정식 $x^{2} \equiv a \pmod{p}$ 의 해가 존재하면 $a$ 를 모듈로 $p$ 에 대한 이차잉여(QR) 라고 한다. $a$ 가 이차잉여가 아니면 비이차잉여(NR) 라고 한다.쉽게 말해 이차잉여란 $\pmod{p}$에서 제곱근이 존재하는 수를 의미한다.예를 들어 소수 $7$ 을 생각해보면 $$ 1^2 \equiv 1 \pmod{7} \\ 2^2 \equiv 4 \pmod{7} \\ 3^2 \equiv 2 \pmod{7} \\ 4^2 \equiv 2 \pmod{7} \\ 5^2 \equiv 4 \pmod{7} \\ 6^2</description>
    </item>
    
    <item>
      <title>쿨롱 법칙과 전기장</title>
      <link>https://freshrimpsushi.github.io/posts/coulombs-law-and-electric-field/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coulombs-law-and-electric-field/</guid>
      <description>**** 쿨롱 법칙$(\mathrm{Coulomb&amp;rsquo;s\ law})$ 고정된 점전하 $q$로부터 거리가 $\eta$만큼 떨어진 시험전하 $Q$가 받는 힘을 쿨롱 힘이라 하고 수식은 다음과 같다.$\mathbf{F} = \dfrac{1}{4\pi \epsilon_0} \dfrac{qQ}{\eta ^2} \hat{\boldsymbol{\eta}}$쿨롱 법칙은 반복된 실험을 통해 얻어낸 실험 법칙이다. 따</description>
    </item>
    
    <item>
      <title>회귀분석에서의 변수 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation-of-variables/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation-of-variables/</guid>
      <description>시계열에서의 변환회귀분석은 기본적으로 변수들간의 선형관계를 밝히는 방법이지만, 필요하다면 데이터를 선형으로 &amp;lsquo;펴서&amp;rsquo; 분석할 수 있다.내장데이터 Pressure 데이터를 불러와보자.Pressure 데이터는 사실 통계적으로 분석할 필요는 없다.이는 어디까지나 자연현상이기 때문에 실험만큼이나 수학적인 증명이 필요하고</description>
    </item>
    
    <item>
      <title>기울기의 기본 정리</title>
      <link>https://freshrimpsushi.github.io/posts/fundamental-theorem-for-gradient/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fundamental-theorem-for-gradient/</guid>
      <description>**기울기의 기본 정리 임의의 경로를 따라 점 $a$에서 점 $b$로 갈 때 $T$의 총 변화량은 아래와 같다.$T(b)-T(a) = \displaystyle \int _a^b (\nabla T) \cdot d\mathbf{l}$ $\cdots (1)$이에 관련된 개념들을 수학적으로 엄밀하게 정의하고 해당 내용을 증명하는 것은 물리학을 공부하는 이에게 중요한 내용이 아니므로 간단하게 서술하겠다.기울기의 기본 정리가 어떤 내용인지? 어</description>
    </item>
    
    <item>
      <title>밀러-라빈 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/miller-rabin-test/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/miller-rabin-test/</guid>
      <description>홀수 $n,q$ 를 $n-1 = 2^{k} q$ 와 같이 나타내자. $$ a \not\mid n \\ a^{q} \not\equiv 1 \pmod{n} $$ 이면서 모든 $i = 0, 1, \cdots , (k-1)$ 에 대해 $$ a^{2^{i} q} \not\equiv -1 \pmod{n} $$ 를 만족하는 $ a$ 가 존재하면 $n$ 은 합성수다.계산량이 늘어난만큼 페르마 판정법을 통과하는 합성수도 걸러낼 가능성이 있다.예로써 카마이클 수인 $561$ 은 $n-1 = 560 = 2^4 \cdot 35$ 이 $2^{35} \equiv 263 \pmod{561}$ 이므로 $561$ 이 소수가 아님을 빠르게 확인할 수 있다. 이때 판정에</description>
    </item>
    
    <item>
      <title>3차원 스칼라 함수의 기울기</title>
      <link>https://freshrimpsushi.github.io/posts/the-gradient-of-3-dimention-scalar-function/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-gradient-of-3-dimention-scalar-function/</guid>
      <description>3변수 함수 $T(x,y,z)$의 기울기를 $\nabla T$라 하고 다음과 같이 정의한다.$\nabla T \equiv \dfrac{\partial T}{\partial x}\hat x + \dfrac{\partial T}{\partial y}\hat y + \dfrac{\partial T}{\partial z}\hat z$1.먼저 1변수 함수를 예로 들어보자.함수 $f(x)$가 있다고 하자.$f$의 미소 변화량을 $df$, $x$의 미소변화량을 $dx$라고 하자.그럼 $x$가 미소량 만큼 바뀔 때 마다 $f$에도 변화가 생길 것이</description>
    </item>
    
    <item>
      <title>실수체로 복소수체를 만들어내는 대수적인 방법</title>
      <link>https://freshrimpsushi.github.io/posts/803/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/803/</guid>
      <description>$\mathbb{R} [x ] / \left&amp;lt; x^2 + 1 \right&amp;gt; \simeq \mathbb{C} $팩트로만 보면 당연하고 실수체에서 복소수체를 만들어내는 과정이 상당히 아름답다.$\mathbb{R} [x ]$ 를 $\left&amp;lt; x^2 \right&amp;gt;$ 로 자르든 $\left&amp;lt; x^2 + x \right&amp;gt;$ 로 자르든 원소의 모양새는 $ax + b$ 꼴로 나오겠지만 하필 $\left&amp;lt; x^2 + 1 \right&amp;gt;$ 로 자르는 이유가 있다. 적어도 한 번은 직접 증명해보면서 이 아름다움을 만끽하도록 하자. 증명 $\left( x^2 + 1 \right)$ 은 $F$ 상</description>
    </item>
    
    <item>
      <title>리만스틸체스 적분 가능할 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/833/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/833/</guid>
      <description>리만 적분은 리만-스틸체스 적분에서 $\alpha(x)=x$인 경우이므로 리만 적분에 대한 증명도 아래와 같다.함수 $f$가 $[a,b]$에서 리만(-스틸체스) 적분가능할 필요충분조건은 모든 $\epsilon &amp;gt;0$에 대하여 $U(P,f,\alpha) - L(P,f,\alpha) &amp;lt; \epsilon$을 만족시키는 $[a,b]$의 분할 $P$가 존재하는 것이다. $$ f \in \mathscr{R} (\alpha)\ \mathrm{on\ } [a,b] \Leftrightarrow</description>
    </item>
    
    <item>
      <title>코셀트 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/korselt-criterion/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/korselt-criterion/</guid>
      <description>홀수 $n$ 이 합성수라고 하자.$n$ 은 카마이클 수 $\iff$ $p \mid n$ 을 만족하는 모든 소수 $p$ 에 대해 $p^2 \not\mid n $ 이면서 $(p-1) \mid (n-1)$카마이클 수임을 판정하는 방법으로써 필요충분조건이라는 점이 또 유용하게 쓰일 수 있는 정리다. 증명 $( \Rightarrow )$카마이클 수는 $2$ 를 제외한 서로 다른 소수 $p_{1} , \cdots , p_{m}$ 에 대해 $n = p_{1} \cdots p_{m}$ 로 나타낼 수 있고, 따라서 $p_{i}^2 \not\mid n$ 이어야한다.</description>
    </item>
    
    <item>
      <title>합동방정식의 거듭제곱근</title>
      <link>https://freshrimpsushi.github.io/posts/k-th-roots-modulo-m/</link>
      <pubDate>Mon, 31 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k-th-roots-modulo-m/</guid>
      <description>자연수 $b,k,m$ 가 $\gcd (b , m) = \gcd ( k , \phi (m) ) = 1$ 을 만족하면 합동방정식 $x^{k} \equiv b \pmod{ m } $ 의 해 $x$ 는 다음과 같이 계산할 수 있다.**Step 1. $\phi (m) $ 을 계산한다.**Step 2. $ku - \phi(m) v =1$ 을 만족하는 $u, v$ 을 찾고 양변에 $u$ 승을 취해 $x^{ku} \equiv b^{u} \pmod{m} $ 를 얻는다.**Step 3. $b^{u} \pmod{ m } $ 을 연속제곱법으로 계산한다.$\phi$ 는 토션트 함수로, 곱셈적</description>
    </item>
    
    <item>
      <title>소 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/prime-ideal/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prime-ideal/</guid>
      <description>가환환 $R$ 의 아이디얼 $P \ne R$ 가 $a, b \in R$ 에 대해 $ab \in P$ 이면 $a \in P$ 또는 $b \in P$ 일 때, $P$ 가 $R$ 에서 소 아이디얼Prime Ideal 이라고 한다.소Prime라는 명칭에서 알 수 있듯 곱해진 원소를 쪼개는 것에서 출발한다.예로써 정수환 $\mathbb{Z}$ 을 생각해보면 $2 \mathbb{Z}$ 의 모든 원소들은 $2k$ 와 같은 형태로 나타나고, $2 \in 2 \mathbb{Z}$ 이므로 소 아이디얼이 된다. 같은 논리로 임의의 소</description>
    </item>
    
    <item>
      <title>디락 델타 함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-dirac-delta-function/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-dirac-delta-function/</guid>
      <description>디락 델타 함수의 라플라스 변환은 다음과 같다.$\mathcal{L} \left\{ \delta(t-t_0) \right\} = e^{-st_0}$디락 델타 함수란?위그림과 같이 $d_\tau (t) = \dfrac{1}{2\tau}$ $-\tau \le t \le \tau$라고 정의하자.그러면 아래의 극한은 **델타 함수** 와 같다.$\lim \limits_{\tau \to 0^+}d_\tau (t)=\delta(t) $$ \lim \limits_{\tau \to 0^+}d_\tau (t-t_0)=\delta(t-t_0)$그러면 $\mathcal{L} \left\{ \delta(t-t_0) \right\}=\mathcal{L} \left\{ \lim \limits_{ \tau \to 0^+}d_\tau</description>
    </item>
    
    <item>
      <title>주기 함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transfotm-of-periodic-function-ft-tft/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transfotm-of-periodic-function-ft-tft/</guid>
      <description>$f$가 주기가 $T$인 주기함수라고 하자. 그러면 $f(t+T)=f(t)$이고 $f(t)$의 라플라스 변환은 아래와 같다. $$ \displaystyle \mathcal{L} \left\{ f(t) \right\} = \int_0^\infty e^{-st}f(t)dt = \frac{\displaystyle \int_0^T e^{-st}f(t)dt}{1-e^{-st}}$ $ 증명 함수 $f$가 주기 $T$를 갖는 주기함수라고 하자. $$ f(t+T)=f(t) $$ $f(t)$의 라플라스 변환은 아래와 같이 나타낼 수 있다. $$ \begin{array}{l} \displaystyle \int_0^\infty e^{-st}f(t)dt \\ = \displaystyle \int_0^T e^{-st}f(t)dt + \int_T^{2T} e^{-st}f(t)dt + \int_{2T}^{3T}e^{-st}f(t)dt + \cdots \end{array} $$ 이 때 두번째</description>
    </item>
    
    <item>
      <title>극대 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/maximal-ideal/</link>
      <pubDate>Fri, 28 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maximal-ideal/</guid>
      <description>환 $R$ 의 아이디얼 중 $R$ 이외의 아이디얼에는 포함되지 않는 아이디얼 $M$ 을 $R$ 의 극대 아이디얼Maximal Ideal 이라고 한다.대수학에서 말하는 &amp;lsquo;맥시멀&amp;rsquo;는 집합론에서의 &amp;lsquo;맥시멀&amp;rsquo;과 거의 똑같다.당연히 정의만으론 유일성을 보장할 수 없는데, 예로써 정수환 $\mathbb{Z}$ 에 대해 $2 \mathbb{Z}$**, ** $3 \mathbb{Z}$ 은 둘 모두 $\mathbb{Z}$ 외의</description>
    </item>
    
    <item>
      <title>힐베르트 공간은 리플렉시브임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/788/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/788/</guid>
      <description>$H^{**} \approx H$짧고 간단하지만 힐베르트 공간을 연구함에 있어서 듀얼 스페이스보다 커지는 것을 생각할 필요가 없다는 것은 굉장히 좋은 일이다. 증명 Part 1. $(H^{ * } , | \cdot | )$ 은 힐베르트 공간이다.리즈 표현 정리$H$ 가 힐베르트 공간이라고 하자. $f \in H^{ * }$ 와 $z \in H$ 에 대해 $f ( z ) = \left&amp;lt; z , x_{f} \right&amp;gt; $ 와 $| f | = | x_{f} | $ 을 만족하는 $x_{f} \in H$ 가 유일하게 존재한</description>
    </item>
    
    <item>
      <title>삼중대각행렬의 행렬식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-tridiagonal-matrixs-determinant/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-tridiagonal-matrixs-determinant/</guid>
      <description>삼중대각행렬 $X_{n} := \begin{bmatrix} x &amp;amp; 1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\ 1 &amp;amp; x &amp;amp; 1 &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; x &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; x &amp;amp; 1 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 1 &amp;amp; x \end{bmatrix}$ 에 대해 $\displaystyle | x_{n}| = U_{n} \left( {{x} \over {2}} \right) $$ U_{n}$ 은 $n$ 차 제2종 체비셰프 다항함수를 의미한다.물론 $X_{n}$ 은 일반적인 삼중대각행렬이 아니고 **삼중대각 퇴플리츠Toepli</description>
    </item>
    
    <item>
      <title>리즈 표현 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-riesz-representation-theorem/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-riesz-representation-theorem/</guid>
      <description>$H$ 가 힐베르트 공간이라고 하자. $f \in H^{ * }$ 와 $z \in H$ 에 대해 $f ( z ) = \left&amp;lt; z , x_{f} \right&amp;gt; $ 와 $| f | = | x_{f} | $ 을 만족하는 $x_{f} \in H$ 가 유일하게 존재한다.쉽게 말해 힐베르트 공간의 듀얼스페이스 $H^{ * }$ 의 모든 원소가 어떻게 생겼는지 규명한 셈인데, 이게 말은 간단해도 함수라는 게 정의하는 사람 마음대로라는 걸 생각해보면 이런 정리를 증명할 생각을 한 것부터</description>
    </item>
    
    <item>
      <title>단원을 가지는 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/785/</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/785/</guid>
      <description>(1) 단위원 $1$ 을 갖는 환 $R$ 의 아이디얼 $I$ 가 단원을 가지면 $I = R$(2) 체 $F$ 는 $\left\{ 0 \right\}$, $F$ 외의 아이디얼을 가지지 않는다.(1) 은 아이디얼에 단원이 있다는것만으로 전체가 되어버린다는 정리로 귀류법을 사용한 증명에 빈번하게 쓰이는 보조정리다.또한 단위원은 단원이라는 점에서, 멀쩡한 아이디얼이라면 $1$ 을 갖지 않는다는 것을 보장해주기도 한다.예로써 $\mathbb{Z}$ 의</description>
    </item>
    
    <item>
      <title>직교 분해 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-orthogonal-decomposition-theorem/</link>
      <pubDate>Sun, 23 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-orthogonal-decomposition-theorem/</guid>
      <description>힐베르트 공간 $H$ 의 닫힌 부분공간 $M$ 에 대해 $H = M \oplus M^{\perp} $$ M^{\perp } := \left\{ x \in H \mid \left&amp;lt; x , m \right&amp;gt; = 0 , m \in M \right\}$ 을 $M$ 의 직교여집합이라고 한다.직교성만큼이나 유용한 성질도 흔치 않다.힐베르트 공간이 이를 보장한다는 것은 곧 힐베르트 공간이 좋은 공간이라는 말이 된다.Strategy : 증명과정은 단순히 직합으로 나타날 조건을 보일 뿐이다. 증명 $x \in H$</description>
    </item>
    
    <item>
      <title>베이즈 인자를 통한 가설검정</title>
      <link>https://freshrimpsushi.github.io/posts/782/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/782/</guid>
      <description>고전적인 가설검정을 쓸 수 있게 되려면 기각역, 유의확률과 같은 개념에 대한 수학적인 이해를 포함해서 이를 직관적으로 받아들일 수 있을 정도의 통계학적 센스까지 갖추어야한다. 학부 1학년 교양 수준에서도 몇 시간이나 할애해가며 가르치고, 그래도 가설검정을 제대로 받아들이지 못하는 학생이 수두룩한 것도 당연한 일이다. 고등학교에서 배우는 통계가 문</description>
    </item>
    
    <item>
      <title>방데르몽드 행렬의 행렬식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-vandermonde-matrixs-determinant/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-vandermonde-matrixs-determinant/</guid>
      <description>서로 다른 $1, x_{1} , x_{2 } , \cdots , x_{n}$ 에 대해 $V_{n} := \begin{bmatrix} 1 &amp;amp; x_{1} &amp;amp; x_{1}^{2} &amp;amp; \cdots &amp;amp; x_{1}^{n-1} \\ 1 &amp;amp; x_{2} &amp;amp; x_{2}^{2} &amp;amp; \cdots &amp;amp; x_{2}^{n-1} \\ \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 1 &amp;amp; x_{n} &amp;amp; x_{n}^{2} &amp;amp; \cdots &amp;amp; x_{n}^{n-1} \end{bmatrix}$ 를 **방데르몽드 행렬** 이라고 한다. $V_{n}$ 의 행렬식은 $\displaystyle \det V_{n} = \prod_{1 \le i &amp;lt; j \le n } (x_{j} - x_{i})$방데르몽드 행렬은 특이하게 생겼지만 미분방정식의 수치적 풀이에서 등장하는 등 의외로 볼 일이 많다.$1,</description>
    </item>
    
    <item>
      <title>제1종 제2종 체비셰프 다항함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relations-between-chebyshev-polynomials/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relations-between-chebyshev-polynomials/</guid>
      <description>제1종 체비셰프 다항함수제2종 체비셰프 다항함수체비셰프 미분방정식의 해로써의 체비셰프 다항함수$T_{n} (x) = \cos \left( n \cos^{-1} x \right)$ 과 $\displaystyle U_{n} (x) = {{1} \over {n+1} } T_{n+1} &#39; (x) $ 은 다음의 관계를 가진다.**[1]** $U_{n} (x) - U_{n-2} (x) = 2 T_{n} (x) $**[2]** $T_{n} (x) - T_{n-2} (x) = 2( x^2 - 1 ) U_{n-2} (x) $*보통 $0 \le \theta \le \pi$ 에 대해 $\theta := \cos^{-1} x $ 라고 둔다.위 등식들을 증명하는 데에는 아래의 팩</description>
    </item>
    
    <item>
      <title>크레이머 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cramer-rule/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cramer-rule/</guid>
      <description>연립방정식 $A \mathbb{x} = \mathbb{b} $ 은 가역행렬 $A = \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{n1} &amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \end{bmatrix}$ 과 두 벡터 $\mathbb{x} = \begin{bmatrix} x_{1} \\ x_{2} \\ \vdots \\ x_{n} \end{bmatrix}$, $\mathbb{b} = \begin{bmatrix} b_{1} \\ b_{2} \\ \vdots \\ b_{n} \end{bmatrix}$ 로 세워져있다. $A$ 의 $j$ 번째 열을 $\mathbb{b}$ 로 대체한 행렬을 $A_{j}$ 라고 하면 $\displaystyle x_{j} = {{ \det A_{j} } \over { \det A }} $크레이머 공식은 연립방정식을 제대로 풀어내는데에 효율적이라곤 할 수 없지만 $A_{j}$</description>
    </item>
    
    <item>
      <title>제2종 체비셰프 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-second-kind/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-second-kind/</guid>
      <description>제1종 체비셰프 다항함수제1종, 제2종 체비셰프 다항함수의 관계체비셰프 미분방정식의 해로써의 체비셰프 다항함수$\displaystyle U_{n} (x) := {{1} \over {n+1} } T_{n+1} &#39; (x) = {{\sin \left( ( n +1 ) \theta \right)} \over { \sin \theta }} $ 을 **제2종 체비셰프 다항함수** 라고 한다.**[0]** $U_{n+1} (x) = 2x U_{n} (x) - U_{n-1} (x) $**[1]** 함수의 내적 $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx $ 에 대해 웨이트 $w$ 를 $\displaystyle</description>
    </item>
    
    <item>
      <title>최단 벡터 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-minimizing-vector-theorem/</link>
      <pubDate>Mon, 17 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-minimizing-vector-theorem/</guid>
      <description>힐베르트 공간 $H$ 에 대해 닫힌 컨벡스 부분공간 $M \lneq H$ 을 정의하자. $x \in ( H \setminus M)$ 에 대해 $$ \displaystyle \delta := | x - m_{0} | = \inf_{m \in M} | x - m | &amp;gt; 0 $$ 을 만족하는 $m_{0}$ 이 유일하게 존재한다. * 부분공간 $M$ 이 컨벡스하다는 것은 모든 $x,y \in M$ 과 $\lambda \in [0,1]$ 에 대해 다음이 성립한다는 것이다. $$ \lambda x + (1-\lambda) y \in M $$ 별 거 없어보이지만 가만 생각해보면 당연한 것만도 아닌 게, 그냥 일</description>
    </item>
    
    <item>
      <title>제1종 체비셰프 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-first-kind/</link>
      <pubDate>Sun, 16 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-first-kind/</guid>
      <description>제2종 체비셰프 다항함수제1종, 제2종 체비셰프 다항함수의 관계체비셰프 미분방정식의 해로써의 체비셰프 다항함수$T_{n} (x) = \cos \left( n \cos^{-1} x \right)$ 을 **제1종 체비셰프 다항함수** 라고 한다.**[0]** $T_{n+1} (x) = 2x T_{n} (x) - T_{n-1} (x) $**[1]** 함수의 내적 $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx $ 에 대해 웨이트 $w$ 를 $\displaystyle w(x) := {{1} \over { \sqrt{1 - x^2} }}$ 와 같이 주면 $\left\{ T_{0} , T_{1}, T_{2}, \cdots \right\} $ 은 직교</description>
    </item>
    
    <item>
      <title>함수해석학에서의 힐베르트 공간</title>
      <link>https://freshrimpsushi.github.io/posts/hilbert-space/</link>
      <pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hilbert-space/</guid>
      <description>실해석학에서의 힐베르트 공간$H$를 벡터 공간이라고 하자. $x,y,z \in H$ 와 $\lambda \in \mathbb{C}$ 에 대해 다음의 조건을 만족하는 함수 $\left&amp;lt; \cdot , \cdot \right&amp;gt; : H \times H \to \mathbb{C}$ 을 내적Inner Product 이라고 정의한다. 내적이 정의된 공간 $(H , \left&amp;lt; \cdot , \cdot \right&amp;gt; )$ 을 내적 공간 이라고 한다.(i) $\left&amp;lt; \lambda x + y, z \right&amp;gt; = \lambda \left&amp;lt; x, z \right&amp;gt; + \lambda \left&amp;lt; y, z \right&amp;gt;$(ii) $\left&amp;lt; x , y \right&amp;gt; = \overline{ \left&amp;lt; y , x \right&amp;gt; }$(iii) $\left&amp;lt; x , x \right&amp;gt; \ge 0$ 그리고 $\left&amp;lt;</description>
    </item>
    
    <item>
      <title>벡터 공간의 리플렉시브</title>
      <link>https://freshrimpsushi.github.io/posts/reflexive/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reflexive/</guid>
      <description>$X^{} \approx X$ 면 $X$ 가 리플렉시브 하다고 한다.일반적으로 스페이스는 듀얼을 취할때마다 점점 그 크기가 더 커진다.그런데 리플렉시브라는 말은 사실상 듀얼 스페이스가 계속해서 커지지 않는 공간이라고 보아도 좋다.리플렉시브한 공간에는 다음의 예시가 있다.[1]** $1 &amp;lt; p &amp;lt; \infty$ 에 대해 ${\mathcal{l}^{p}}^{**} \approx \mathcal{l}^{p}$**[2]** $\dim X = n$ 이면 $X^{**} \approx X$**[3]** $H$ 가 힐베르트 공간이면 $H^{**} \approx H$ 증명[1]</description>
    </item>
    
    <item>
      <title>최고사후밀도 신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</guid>
      <description>모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $C : = \left\{ \theta \in \Theta , | , p ( \theta | y ) \ge k (\alpha) \right\} $ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 최고사후밀도 신용구간 이라고 한다.여기서 $k(\alpha)$ 는 $p(\theta \in C | y ) \ge 1 - \alpha$ 를 만족하는 가장 큰 상수다.수식과 말보다는 그림을 통해 보는게 훨씬 이해하기 좋다.실제 계산에서도 위와 같이 $k$ 를 계속 바꿔가며 적분</description>
    </item>
    
    <item>
      <title>등거리 사상</title>
      <link>https://freshrimpsushi.github.io/posts/isometric-map/</link>
      <pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isometric-map/</guid>
      <description>등거리 사상$(\mathrm{isomertic\ map,\ isometry})$ 두 거리공간1 $(X,\ d_X)$, $(Y,\ d_Y)$에 대해서 아래의 조건을 만족하는 사상 $f\ :\ X\rightarrow Y$가 존재하면 $X$와 $Y$가 아이소메트릭$(\mathrm{isometric})$ 이라 하고 $X \approx Y$라고 표기한다. 또한 사상 $f$를 등거리 사상이라 한다. $$ d_X(x_1,\ x_2) =d_Y\big( f(x_1),\ f(x_2) \big),\quad \forall\ x_1,x_2\in X $$ 등거리</description>
    </item>
    
    <item>
      <title>복소수의 부호</title>
      <link>https://freshrimpsushi.github.io/posts/sign-of-complex-number/</link>
      <pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sign-of-complex-number/</guid>
      <description>$\lambda \in \mathbb{C}$ 에 대해 부호Sign 를 $\text{sign} ( \lambda ) = \begin{cases} \displaystyle {{| \lambda | } \over { \lambda }} &amp;amp;, \lambda \ne 0 \\ 1 &amp;amp;, \lambda = 0 \end{cases}$ 와 같이 정의한다.쉽게 체크할 수 있는 예로써 실수의 부호 $\text{sign} ( +2 ) = 1 $, $\text{sign} ( -3 ) = -1 $ 를 확인할 수 있다.따라서 실수의 일반화라는 점에서는 충분히 좋은 정의다.그런데 $\displaystyle \text{sign} ( i ) = {{| i | } \over {i}} = - i $ 으로 계산된다는 점이 좀 이상하게 느껴질 것이다.이</description>
    </item>
    
    <item>
      <title>유계 선형작용소의 제곱의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/738/</link>
      <pubDate>Fri, 30 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/738/</guid>
      <description>$T, T^2 \in B(X,X)$ 에 대해 $T(Tx) = T^{2} x$ 면 $| T^{2} | = | T |^{2}$단순하게 보이지만 자그마치 3개의 성질이 합쳐진 컴비네이션이다. 자연수에 대해 일반화하면 $| T^{m} | = | T |^{m}$ 으로, 거듭제곱을 자유자재로 넣고 뺄 수 있음을 보장하기 때문에 아주 유용하다.Strategy : 양쪽 방향으로 똑같이 성립하는 부등식을 세워서 등식임을 보인다. 증명 $T \in B(X,X)$ 이므로</description>
    </item>
    
    <item>
      <title>아이젠슈타인 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/eisenstein-criterion/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eisenstein-criterion/</guid>
      <description>$f(x) = a_{n} x^{n} + \cdots + a_{0 } \in \mathbb{Z} [x]$ 가 소수 $p \in \mathbb{Z}$ 와 $k = 1,2, \cdots , n-1$ 에 대해 다음 조건들을 만족하면 $f(x)$ 는 $\mathbb{Q}$ 상에서 기약함수다.**(i)** $a_{n} \not\equiv 0 \pmod{p} $**(ii)** $a_{k} \equiv 0 \pmod{p} $**(iii)** $a_{0} \not\equiv 0 \pmod{p^2} $$ f(x) = ax^{n} + b$ 꼴의 정수다항식에 대해 아주 쉬운 판정법으로써 의미가 있다.$\mathbb{Q}$ 에 대한 판정법이라는 점에서 대수적 수와 관련된 논의에서 유용하게 쓰일 수 있다. 증</description>
    </item>
    
    <item>
      <title>라플라스 전개</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-expansion/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-expansion/</guid>
      <description>정사각행렬 $A_{n \times n} = (a_{ij})$ 의 $i$ 번째 행과 $j$ 번째 행을 제거한 행렬의 행렬식 $M_{ij}$ 을 **소행렬식**Minor 이라고 한다. 이에 대해 $C_{ij} := (-1)^{i + j} M_{ij} $ 를 **여인자**Cofactor 라고 한다.**(1)** 선택된 $i$행 에 대해, $\displaystyle \det A = \sum_{j=1}^{n} a_{ij} C_{ij} $**(2)** 선택된 $j$열 에 대해, $\displaystyle \det A = \sum_{i=1}^{n} a_{ij} C_{ij} $라플라스 전개는 **여인자 전개** 로도 불리는 정</description>
    </item>
    
    <item>
      <title>다항함수의 기약원</title>
      <link>https://freshrimpsushi.github.io/posts/irreducible-element/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/irreducible-element/</guid>
      <description>상수함수가 아닌 $f(x) \in F[x]$ 가 $f(x)$ 보다 차수가 낮은 어떤 $g(x) , h(x) \in F[x]$ 의 곱 $f(x) = g(x) h(x) $ 으로 나타낼 수 없을 때 $f(x)$ 를 $F$ 상에서의 기약원Irreducible Element 이라고 한다.예로써 $\mathbb{Q} [x ]$ 를 생각해보면 $x^2 - 2$ 은 $\mathbb{Q}$ 상에서 기약원이지만, $\mathbb{R} [x]$ 에서의 $x^2 - 2$ 은 $\mathbb{R}$ 상에서 $(x + \sqrt{2} ) ( x - \sqrt{2} )$ 로 인수분해가 가능하다. 또 $x^2 + 1$ 은 $\mathbb{R}$ 상에서는 기약원이지만 $\mathbb{C}$ 에서는</description>
    </item>
    
    <item>
      <title>인수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-factor-theorem/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-factor-theorem/</guid>
      <description>$f(x) \in F[x]$ 라고 하자.$f(a) = 0 $$ \iff $$ f(x) = (x-a) q(x)$중학교부터 지겹도록 해온 인수분해의 존재성을 보장하는 정리다.주의할 것은 나눗셈 정리나 인수 정리와 같은 팩트들은 다항함수의 차수가 유한할 때 의미가 있다는 것이다. 증명 $( \Rightarrow )$나눗셈 정리$a_{n} \ne 0$ 과 $b_{m} \ne 0$, 그리고 $n &amp;gt; m &amp;gt; 0$ 에 대해 $F[x]$ 의 두 원소를 $f(x) = a_{n} x^{n} + \cdots + a_{1} x + a_{0}$ 와</description>
    </item>
    
    <item>
      <title>나눗셈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-division-algorithm/</link>
      <pubDate>Fri, 23 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-division-algorithm/</guid>
      <description>$a_{n} \ne 0$ 과 $b_{m} \ne 0$, 그리고 $n &amp;gt; m &amp;gt; 0$ 에 대해 $F[x]$ 의 두 원소를 $$ f(x) = a_{n} x^{n} + \cdots + a_{1} x + a_{0} \\ g(x) = b_{m} x^{m} + \cdots + b_{1} x + b_{0} $$ 이라고 하자. 그러면 $f(x) = g(x) q(x) + r(x) $ 를 만족하는 $q(x), r(x) \in F[x]$ 이 유일하게 존재한다. $r$ 의 차수는 $m$ 보다 작다.꼭 정리가 있어야 알 수 있는 사실은 아니지만 대수적으로 엄밀한 증명이라는 의의가 있다. 증명 $S : = \left\{ f(x) - g(x) s(x) , : , s(x) \in F[x] \right\} $</description>
    </item>
    
    <item>
      <title>선형작용소의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-linear-operator/</link>
      <pubDate>Thu, 22 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-linear-operator/</guid>
      <description>$T : (X , | \cdot |{X}) \to ( Y , | \cdot |{Y} ) $ 가 선형작용소라고 하자.[1] $T$ 가 유계면 모든 $x \in X$ 에 대해 $| T(x) |{Y} \le | T | | x |{X} $[2] $T$ 는 연속 $\iff$ $T$ 는 유계**[3]** $X$ 가 유한 차원 공간이면 $T$ 는 연속이다.**[4]** $Y$ 가 바나흐 공간이면 $( B(X,Y) , | \cdot | ) $ 는 바나흐 공간이다.$B(X,Y)$ 는 유계 선형작용소들의 공간이므로 **[2]** 에 의해 이 공간</description>
    </item>
    
    <item>
      <title>다항함수의 영</title>
      <link>https://freshrimpsushi.github.io/posts/zero-of-polynomial/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zero-of-polynomial/</guid>
      <description>체 $F \le E$ 와 $\alpha \in E$ 에 대해 $\phi_{\alpha} : F [x] \to E$ 를 $\phi_{\alpha} ( a_{0} + a_{1} x + \cdots + a_{n} x^n ) : = a_{0} + a_{1} \alpha + \cdots + a_{n} \alpha^n $ 와 같이 정의하자.팩트로써, $\phi_{\alpha}$ 는 준동형사상이 된다.정의가 너무 두리뭉술하게 느껴질 수 있는데, 간단한 예시로써 $\phi_{i} : \mathbb{R} [x] \to \mathbb{C}$ 를 생각해보자.$\phi_{i} ( x^2 - 3 x + 2) $ 이라고 하면, 단순히 $f(x) = x^2 - 3 x + 2$ 에 $i$ 를 대입한 $i^2 - 3 i +</description>
    </item>
    
    <item>
      <title>함수해석학에서 작용소란</title>
      <link>https://freshrimpsushi.github.io/posts/operator/</link>
      <pubDate>Tue, 20 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operator/</guid>
      <description>양자역학에서의 연산자$(X, | \cdot |{X})$와 $(Y, | \cdot |{Y})$가 [[놈 공간]]이라고 하자.1. 놈 공간에서 놈 공간으로의 사상을 작용소 라고 한다.2. $x,x_{1},x_{2}\in X$에 대해서, $T : X \to Y$가 $T( x_{1} + x_{2} ) = T( x_{1} ) + T( x_{2} ) $ 와 $T( a x ) = a T( x ) $을 만족하면 **선형작용소**Linear Operator 라고 한다.**3.** 모든 $x \in X$</description>
    </item>
    
    <item>
      <title>빅오 노테이션이 분모에 있을 때 분자로 올리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/727/</link>
      <pubDate>Mon, 19 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/727/</guid>
      <description>$a \ne 0$ 와 $p&amp;gt;0$, $n \in \mathbb{N}$ 에 대해 $\displaystyle {{1} \over { \sqrt[p]{a + O ( h^n ) } }} = {{1} \over { \sqrt[p]{a } }}+ O(h^n) $복잡하게 생긴 분모를 깔끔한 형태로 바꿔주는 렘마로써 요긴하게 쓰일 수 있다.상수항 $a$ 이 없다면 렘마 없이도 $\displaystyle {{1} \over { \sqrt[p]{ O ( h^n ) } }} = O \left( h^{ - {{n} \over {p}} } \right) $ 으로 깔끔하게 올라오지만 보통 쓸모가 없다. 증명 $\displaystyle {{1} \over { \sqrt[p]{a + O ( h^n ) } }} = {{1} \over { \sqrt[p]{a + b h^n } }} = (a + b h^n )^{-{{1} \over</description>
    </item>
    
    <item>
      <title>리즈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rieszs-theorem/</link>
      <pubDate>Sat, 17 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rieszs-theorem/</guid>
      <description>놈드 스페이스 $(X , | \cdot |)$ 의 스칼라 필드를 $\mathbb{C}$ 라고 하자.$X$ 는 유한차원 $\iff$ $\overline{ B ( 0 ; 1 ) } $ 은 컴팩트* $\overline{ B ( 0 ; 1 ) } := \left\{ x \in X , : , | x | \le 1 \right\} $ 는 **클로즈드 유닛 볼**Closed Unit Ball 을 나타낸다.리즈 정리에 따르면 전체 공간이 유한차원인지 판단하기 위해 아주 작은 영역만 체크하면 된다. 보통 유한 차원 놈드 스페이스의 예시</description>
    </item>
    
    <item>
      <title>t^{n}ft의 라플라스 변환 Laplace Transform of t^{</title>
      <link>https://freshrimpsushi.github.io/posts/nft/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/nft/</guid>
      <description>$t^{n}f(t)$의 라플라스 변환은 $\mathcal{L} \left\{ t^n f(t) \right\} = (-1)^nF^{(n)}(s)$이다. 유도 우선 $t^nf(t)$의 라플라스 변환을 정의에 따라 적분 꼴로 나타내면 다음과 같다.$\displaystyle \int _0 ^\infty e^{-st}tf(t) dt$적분 안을 잘 살펴보면 $e^{-st}f(t)$를 $s$에 대해 미분한 결과라는 것을 알 수 있다.(</description>
    </item>
    
    <item>
      <title>다항식의 환</title>
      <link>https://freshrimpsushi.github.io/posts/ring-of-polynomial/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ring-of-polynomial/</guid>
      <description>환 $R$ 의 다항함수Polynomial $f(x)$ 를 다음과 같이 정의한다.$\displaystyle f(x) : = \sum_{i=0}^{n} a_{i} x^{i} = a_{0} + a_{1} x + \cdots + a_{k} x^{k} $**(1)** $a_{i} \in R$ 들을 $f(x)$ 의 **계수**Coefficient 라고 한다.**(2)** $n &amp;lt; \infty$ 면 $n$ 을 $f(x)$ 의 **차수**Degree 라고 한다.**(3)** $R[x] := \left\{ a_{0} + a_{1} x + \cdots + a_{n} x^{n} , | , a_{0}, \cdots , a_{n} \in R \right\}</description>
    </item>
    
    <item>
      <title>수치해석에서의 차분</title>
      <link>https://freshrimpsushi.github.io/posts/difference/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference/</guid>
      <description>시계열분석에서의 차분**1. ** **전방차분 : ** $\Delta f(x) = f(x+h) - f(x)$ 그리고 $\Delta^{r+1} f(x) =\Delta^{r} f(x+h) - \Delta^{r} f(x)$2. 후방차분 : $\nabla f(x) = f(x) - f(x- h)$ 그리고 $\nabla^{r+1} f(x) = \nabla^{r} f(x) - \nabla^{r} f(x- h)$일반적으로 계차Difference 란 수열 전반에서 사용하는 말이지만 수치해석에선 특히 두 노드포인트의 함숫값의 차를 말한다. 사실 고등학교때부터 계속 봐왔기 때문에 익숙하다면 익숙한 연산자</description>
    </item>
    
    <item>
      <title>환의 영인자가 멱등원이면 직합으로 나타낼 수 있음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/731/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/731/</guid>
      <description>선형대수학에서의 직합 보러가기선형대수학에서의 사영 보러가기추상대수학에서의 직합 보러가기추상대수학에서의 멱등원 보러가기환 $R$ 의 영인자 $a$ 가 $a^2 = a$ 를 만족하면 $R = a R \times (1-a)R$따로 환에 대한 직합을 정의하지 않아도 알 수 있을 정도로 수학다운 매력이 있는 정리다. 증명 (i) 존재성 $r \in R$ 에 대해 $ar \in aR$ 이고 $(1-a) r \in (1-a) R$ 인데 $r = ar + (1-a)r</description>
    </item>
    
    <item>
      <title>R 에서 자료구조 뜯어보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/720/</link>
      <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/720/</guid>
      <description>R에서 여러가지 함수를 사용하다보면 아래와 같이 친절하게 결과가 출력하는 경우를 자주 볼 수 있게 된다.문제는 이 결과를 그냥 보는 게 아니라 아웃풋으로써 받아서 써먹고 싶을 때다.가령 위 스크린샷에서 잔차의 최댓값이 필요하면 그냥 15.9719을 베껴써도 되긴 한다.하지만 수십 수백번을 반복하면서 각 분석에서 잔차의 최댓값이 궁금하다면 이런식으</description>
    </item>
    
    <item>
      <title>영인자와 정역</title>
      <link>https://freshrimpsushi.github.io/posts/zero-divisior-and-integral-domain/</link>
      <pubDate>Sun, 11 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zero-divisior-and-integral-domain/</guid>
      <description>유클리드 정역 $\implies$ 주 아이디얼 정역 $\implies$ 유일 인수분해 정역 $\implies$ 정역**(1)** 환 $R$ 에 대해 $ab = 0$ 을 만족시키는 $0$ 이 아닌 $a,b \in R$ 을 **영인자**Zero Divisor 라고 한다.**(2)** 단위원 $1 \ne 0$ 을 가진 $D$ 가 영인자를 가지지 않으면 **정역**Integral Domain 이라고 한다.정역은 그 약어인 ID로도 많이 줄여쓴다.$0$ 이 아닌 것끼리 곱해</description>
    </item>
    
    <item>
      <title>1계 도함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-first-order-derivative/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-first-order-derivative/</guid>
      <description>**1계 도함수의 라플라스 변환 아래의 두 조건을 가정하자.① 임의의 구간 $0 \le t \le A$에서 함수 $f(t)$가 연속이고, 1계 도함수 $f&#39;(t)$가 부분적으로 연속(Piecewise Continuous) 이라고 하자.② $t \ge M$일 때 $|f(t)| \le Ke^{at}$를 만족하는 실수 $a$와 양수 $K$, $M$이 존재한다.그러면 1계 도함수의 라플라스 변환 $\mathcal{L} \left\{ f&#39;(t) \</description>
    </item>
    
    <item>
      <title>Fas&#43;b의 라플라스 역변환 Inverse Laplace Transform of Fas&#43;</title>
      <link>https://freshrimpsushi.github.io/posts/b/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/b/</guid>
      <description>함수 $f(t)$의 라플라스 변환 $\mathcal{L} \left\{ f(t) \right\} =F(s)$가 $s&amp;gt;\alpha \ge 0$일 때 존재한다고 가정하자.그러면 $a&amp;gt;0$인 상수 $a$, $b$에 대해서 $F(as+b)$의 라플라스 역변환은 다음과 같다.$\mathcal{L^{-1}} \left\{ F(as+b) \right\} =\frac{1}{a}e^{-\frac{b}{a}t}f\left(\frac{t}{a}\right)$ 증명1 ① $F(ks)$의 라플라스 역변환 $\mathcal{L^{-1}} \left\{ F(ks) \right\} =\dfrac{1}{k}f\lef</description>
    </item>
    
    <item>
      <title>fct의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-fct/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-fct/</guid>
      <description>함수 $f(t)$의 라플라스 변환 $\mathcal{L} \left\{ f(t) \right\} =F(s)$가 $s&amp;gt;a \ge 0$일 때 존재한다고 가정하자.그러면 양수 $c$에 대해서 $f(ct)$의 라플라스 변환은 다음과 같다.$\mathcal{L} \left\{ f(ct) \right\} =\dfrac{1}{c}F\left(\dfrac{s}{c}\right)$, $s&amp;gt;ca$변수가 상수배 일 때의 라플라스 변환이다. 증명 $ \displaystyle \mathcal{L} \left\{ f(ct) \right\} = \int _0 ^\infty e^{-st}f(ct)dt $$ ct=\tau$라고 치환하자.그러면</description>
    </item>
    
    <item>
      <title>Fks의 라플라스 역변환</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-laplace-transform-of-fks/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-laplace-transform-of-fks/</guid>
      <description>함수 $f(t)$의 라플라스 변환 $\mathcal{L} \left\{ f(t) \right\} =F(s)$가 $s&amp;gt;a \ge 0$일 때 존재한다고 가정하자.그러면 양수 $k$에 대해서 $F(ks)$의 라플라스 역변환은 다음과 같다.$\mathcal{L^{-1}} \left\{ F(ks) \right\} =\dfrac{1}{k}f\left(\frac{t}{k}\right)$, $s&amp;gt;\frac{a}{k}$ 증명1 $f(ct)$의 라플라스 변환 결과를 사용하자.$\mathcal{L} \left\{ f(ct) \right\} =\dfrac{1}{c</description>
    </item>
    
    <item>
      <title>n계 도함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-n-th-order-derivative/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-n-th-order-derivative/</guid>
      <description>**n계 도함수의 라플라스 변환 아래의 두 조건을 가정하자.① 임의의 구간 $0 \le t \le A$에서 함수 $f$, $f&#39;$, $\cdots$, $f^{(n-1)}$가 연속이고 n계 도함수 $f^{(n)}(t)$가 부분적으로 연속(Piecewise Continuous) 이라고 하자.② $t \ge M$일 때 $|f(t)| \le Ke^{at}$, $|f&#39;(t)| \le Ke^{at}$, $\cdots$, $|f^{(n-1)}(t)| \le Ke^{at}$를 만족하는 실수 $a$와 양수 $K$, $M$이 존재한다.</description>
    </item>
    
    <item>
      <title>라플라스 변환을 이용한 2계 선형 비동차 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solving-second-order-linear-inhomogeneous-differential-equations-using-laplace-transform/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solving-second-order-linear-inhomogeneous-differential-equations-using-laplace-transform/</guid>
      <description>주어진 2계 선형 비동차 미분방정식이 아래와 같다고 하자. $$ ay&#39;&#39; + by&#39; + cy = g(t) $$ 그리고 $\mathcal{L} \left\{ y \right\} =Y(s)$, $\mathcal{L} \left\{ g(t) \right\}=G(s)$라고 하자. 그러면 $$ Y(s) = \dfrac{ (as + b)y(0) + ay&#39;(0) } {as^2+bs+c} + \dfrac{G(s) }{as^2+bs+c} $$ 위 공식은 규칙만 잘 기억하면 외우기 쉽다. 규칙대로 외우면 3계, 4계의 경우를 포함하는 일반적인 공식까지도 쉽게 외울 수 있다. 위 결과는 n계 도함수의 라플라</description>
    </item>
    
    <item>
      <title>라플라스 변환의 평행이동</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-ectft/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-ectft/</guid>
      <description>함수 $f(t)$의 라플라스 변환 $F(s)=\mathcal{L} \left\{ f(t) \right\}$가 $s&amp;gt;a$일 때 존재한다고 하자.그러면 상수 $c$에 대해서 $\mathcal{L} \left\{ e^{ct}f(t) \right\}=F(s-c)$, $s&amp;gt;a+c$그리고 $\mathcal{L^{-1}} \left\{ F(s-c) \right\}=e^{ct}f(t)$함수 $f$와 $e^{ct}$의 곱의 라플라스 변환 결과는 단순히 $F(s)$가 평행이동한 것과 같다는 말이다. 증명</description>
    </item>
    
    <item>
      <title>유한 차원 놈드 스페이스는 베이시스를 가짐을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/707/</link>
      <pubDate>Mon, 29 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/707/</guid>
      <description>모든 유한 차원 놈드 스페이스는 베이시스를 가진다.특정 조건을 만족하는 베이시스도 아니고 베이시스의 존재성을 밝힌다는 것이 생소하겠지만, 실제로 베이시스의 정의만을 보아서는 모든 벡터 스페이스가 베이시스가 존재한다고 한 적이 없다. 유한 차원을 정의하기에 따라서는 별도로 증명이 필요없을 정도로 자명한 팩트기도 하다.Strategy : 유한</description>
    </item>
    
    <item>
      <title>유한 차원 벡터 공간의 하멜 베이시스</title>
      <link>https://freshrimpsushi.github.io/posts/hamel-basis-of-finite-dimensional-vector-space/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hamel-basis-of-finite-dimensional-vector-space/</guid>
      <description>선형대수학에서 벡터의 선형독립과 기저, 차원무한 차원 벡터 공간의 기저 : 샤우더 베이시스벡터 공간 $X$ 가 주어져 있다고 하자.1. $X$ 의 벡터 $x_{1} , \cdots , x_{n} $ 와 스칼라 $\alpha_{1} , \cdots , \alpha_{n}$ 에 대해 $\alpha_{1} x_{1} + \cdots + \alpha_{n} x_{n}$ 를 벡터 $x_{1} , \cdots , x_{n} $ 들의 선형 결합이라 한다.**2.** $M = \left\{ x_{1} , \cdots , x_{n} \right\} $ 이라 할 때 $M$ 의 모든 벡터의 선형 결합들의 집합을 $\text{span} M$ 이라 하고, $M$ 에</description>
    </item>
    
    <item>
      <title>바나흐 공간</title>
      <link>https://freshrimpsushi.github.io/posts/banach-space/</link>
      <pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/banach-space/</guid>
      <description>선형대수학에서의 벡터공간선형대수학에서의 놈거리공간의 완비성컴플리트 놈드 스페이스를 바나흐 스페이스 라고 정의한다.바나흐 스페이스는 아래의 각 호를 모두 만족시킨 공간으로써 거리 함수가 정의되는데다 완비성을 갖춰 아주 유용한 공간이다. 강하다면 강한 조건들을 만족시켜야 하는 것은 사실이나, 무한차원 벡터스페이스에서도 문제 없이 정의되</description>
    </item>
    
    <item>
      <title>베이지안 패러다임</title>
      <link>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</guid>
      <description>통계학이란 &amp;lsquo;모수를 파악하는 방법을 연구하는 학문&amp;rsquo;이라고 할 수 있다. 어떤 물리량을 측정하는 것처럼 공식이나 법칙을 통해 정확하게 모수를 추정할 수 있다면 더할나위 없지만, 현실적으로 그게 불가능하기 때문에 가정과 표본을 이용해 &amp;lsquo;모수로 예상되는 것&amp;rsquo;을 찾아낼 뿐이다. 우리나라 남성의 신장</description>
    </item>
    
    <item>
      <title>p=∞ 일 때 p-놈이 맥시멈 놈이 됨을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/699/</link>
      <pubDate>Sun, 21 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/699/</guid>
      <description>$1 &amp;lt; p_{0} &amp;lt; \infty $ 에 대해 $\left\{ x_{n} \right\}_{n \in \mathbb{N} } \in \mathcal{l}^{p_{0}} $ 라고 하면 $\displaystyle \lim_{p \to \infty} \left( \sum_{n \in \mathbb{N} } | x_{n} |^{p} \right)^{ {{1} \over {p}} } = \sup_{n \in \mathbb{N}} | x_{ n } | $맥시멈 놈은 해석학이나 선형대수학 등에서 꽤 일찍 접함에도 불구하고 왜 하필 $\infty$ 와 관계가 있는지 그 설명을 찾기가 어렵다. 다행스러운 점은 그냥 증명이 가능하는 것이다. 증명 $\displaystyle M := \sup_{n \in \mathbb{N}} | x_{ n } | $ 이라고 하자.만약 $M=0$ 이면 $\displaystyle 0 = \lim_{p \to</description>
    </item>
    
    <item>
      <title>R 에서 리스트 해체하기 중복 성분 제거하기</title>
      <link>https://freshrimpsushi.github.io/posts/unlist-unique/</link>
      <pubDate>Sun, 23 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unlist-unique/</guid>
      <description>온갖가지 정제되지 않은 데이터를 상대할 일이 많은 R 에서 리스트 자료형은 데이터를 정리하는데에 특히 유용하다.그러나 반대급부로 데이터에 접근하는 것이 조금 번거롭고 원하는 내용을 찾는데에 불리한 점이 있다.이때 unlist() 함수를 통해 리스트 자료형을 깨주면 이러한 조작이 한결 편해진다.unique() 함수는 받은 배열에서 중복되는 원소를 모두 제거하</description>
    </item>
    
    <item>
      <title>잉여류의 성질과 그 증명</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-cosets-and-its-proof/</link>
      <pubDate>Fri, 21 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-cosets-and-its-proof/</guid>
      <description>정규부분군 보러가기$H$를 군 $G$의 부분군이라고 하자.그러면 군 $G$의 원소 $a$에 대해서 집합 $aH= \left\{ ah | h\in H \right\}$를** 좌잉여류$\mathrm{left\ coset}$** 이라 한다.$Ha = \left\{ ha | h\in H \right\}$를 **우잉여류$\mathrm{right\ coset}$** 라 한다.$H$가 부분군이 아닌 집합이라도 집합</description>
    </item>
    
    <item>
      <title>다양체란</title>
      <link>https://freshrimpsushi.github.io/posts/manifold/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/manifold/</guid>
      <description>위상공간 $X$가 아래의 세 조건을 만족시킬 때 $X$를 $n$ 차원 매니폴드Manifold 라고 한다.$(a)$ 제 2가산이다.$(b)$ 하우스도르프이다.$(c)$ $X$의 모든 점이 $\mathbb{R}^{n}$ 의 열린집합과 위상동형인 네이버후드를 가진다.조건 $(c)$와 국소적으로 유클리드공간이다는 말은 서로 같다. 즉, 매니폴드는 국소적으로 유클리드</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 등분산성</title>
      <link>https://freshrimpsushi.github.io/posts/homoscedasticity-of-standard-residuals/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homoscedasticity-of-standard-residuals/</guid>
      <description>선형성 보러가기독립성 보러가기정규성 보러가기표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 등분산성을 확인하려면 잔차들의 흩어진 모양이 전체적으로 고른지 확인하면 된다. 흔히 볼 수 있는 등분산성 결여의 예로써 다음의 두가지 경우가 대표적이다.&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20180901_151944.png&amp;rdquo; height=&amp;ldquo;247&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99C30E4F5B8A347206&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;373&amp;rdq</description>
    </item>
    
    <item>
      <title>피보나치 수열의 일반항 유도</title>
      <link>https://freshrimpsushi.github.io/posts/the-general-term-of-fibonacci-sequence/</link>
      <pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-general-term-of-fibonacci-sequence/</guid>
      <description>수열 $\left\{ F_{n} \right\} $ 이 $F_{n+1} := F_{n} + F_{n-1}$ 과 같이 정의되어있다고 하자. $F_{0} = F_{1} = 1$ 이면 $\displaystyle r_{0} : = {{1 + \sqrt{5} } \over {2}} $ 와 $\displaystyle r_{1} : = {{1 - \sqrt{5} } \over {2}} $ 에 대해 $\displaystyle F_{n} = {{ {r_{0}}^{n+1} - {r_{1}}^{n+1} } \over { r_{0} - r_{1} }} $피보나치 수열의 일반항은 **비네 공식**Binet Formula 이라 부르기도 한다.피보나치 수열은 워낙 많은 성질을 가지고 있고 생각지도 못한 부분에서 응용이 되기도 한다.아예 피보나</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 선형성</title>
      <link>https://freshrimpsushi.github.io/posts/linearity-of-standard-residuals/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearity-of-standard-residuals/</guid>
      <description>독립성 보러가기등분산성 보러가기정규성 보러가기표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다.선형성이 있는지 확인하려면 $0$ 을 중심으로 잔차들이 대칭적으로 나타나는지 확인하면 된다.오른쪽 그림을 보면 누가봐도 선형성이 결여되어있음을 확인할 수 있다.만약 단순회귀분석이었다면 위와 같이 데이터의 경향을 전혀 설명할 수</description>
    </item>
    
    <item>
      <title>회귀분석의 모형진단</title>
      <link>https://freshrimpsushi.github.io/posts/model-diagnostic-of-regression-analysis/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/model-diagnostic-of-regression-analysis/</guid>
      <description>* 수학, 통계적인 기초가 부족한 비전공자는 밑줄 그어진 부분만 읽어도 상관 없다.단순회귀분석의 경우엔 독립변수와 종속변수를 고려해봤자 $2$ 차원이기 때문에 분석이 제대로 되었는지 한 눈에 확인할 수 있다. 하지만 다중회귀분석의 경우 $3$ 차원을 넘어가면 그림으로 그리기 어려워 때문에 분석이 정말 잘 맞는지 확인하기 어렵다. 회귀분석의 가정을 제대로 만</description>
    </item>
    
    <item>
      <title>몫 공간</title>
      <link>https://freshrimpsushi.github.io/posts/quotient-space/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quotient-space/</guid>
      <description>위상공간 $(X, \mathscr{T} )$ 와 동치 관계 $\sim$ 에 대해 동치류를 $[x] = \left\{ y \in X , | , x \sim y \right\} $ 이라 하자.(1) $X / \sim$ 을 몫 집합 이라고 정의한다.(2) $q : X \to X / \sim$ 을 $q(x) = [x]$ 로 정의하면 몫 함수 라고 부른다.(3) $U \in \mathscr{T}$ 에 대해 $\displaystyle q^{-1} (U) = \bigcup_{[x] \in U} [x] $$ \iff $$ U \in \mathscr{T_{\sim}}$ 이라고 하자. $\mathscr{T_{\sim}}$ 을 몫 위상이라 하고, $( X/ \sim , \mathscr{T_{\sim}} )$ 을 모듈러 $\sim$ 에서 $X$ 의 **몫 공간** 이라고 정</description>
    </item>
    
    <item>
      <title>R 에서 수평선 수직선 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/664/</link>
      <pubDate>Thu, 30 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/664/</guid>
      <description>1. abline(h=0) 수평선을 긋는다.2. abline(v=0) 수직선을 긋는다.**3. abline(0,3/4) $y$ 절편이 $0$ 이고 기울기가 $3/4$ 인 직선을 긋는다.애초에 abline() 함수 자체가 $y=a+bx$ 의 계수인 $a,b$ 에서 이름을 따온 것이다.통계를 목적으로 R 을 쓰고 있다면 막상 회귀직선을 그릴 때 빼곤 쓸 일이 없다.**4. segments(4,0,4,3) $(4,0)$ 에서 $(4,3)$ 으로 이어지는 선분을 그린다.깔끔하게 필요한 부분만 그리고 싶을때 필요하다. win.graph(6,5) plot(x=0,y=0,xlim=c(-1,5),ylim=c(-1,4),xlab=&amp;#34;x&amp;#34;,ylab=&amp;#34;y&amp;#34;) points(4,3,col=&amp;#34;red&amp;#34;,pch=19)</description>
    </item>
    
    <item>
      <title>군론에서의 코시 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/cauchys-theorem/</link>
      <pubDate>Wed, 29 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchys-theorem/</guid>
      <description>복소해석에서의 코시 정리 보러가기유한군 $G$ 에 대해 소수 $p$ 가 $|G|$ 의 약수면 $|H| = p$ 를 만족하는 부분군 $H \leqslant G$ 가 존재한다.보통 코시 정리라고 할 때 이 정리를 떠올리지는 않는다.또다른 &amp;lsquo;코시 정리&amp;rsquo;는 복소해석의 근간을 이룰만큼 중요한 정리인데, 이 정리는 별로 언급 될 일이 없다.무엇보다도 제1쉴로브 정리로 일반화되기 때문</description>
    </item>
    
    <item>
      <title>R 에서 그래프 그리기</title>
      <link>https://freshrimpsushi.github.io/posts/662/</link>
      <pubDate>Tue, 28 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/662/</guid>
      <description>R 은 다른 언어와 비교했을때 그래프의 표현이 아주 쉽다는 장점이 있다.여타 통계 패키지와 비교하자면 쉬운 그림은 패키지가 빨라도 세세한 표현이 많아지면 R 이 편해지는 경향이 있다.물론 R이 꼭 그래픽만을 위한 언어는 아니지만, 매우 큰 장점이니만큼 자유자재로 다룰 수 있게 연습하는 게 좋다. set.seed(150421)x&amp;lt;-1:10y&amp;lt;-rnorm(10,5)z&amp;lt;-rexp(10) win.graph(4,4)plot(x,y,ma</description>
    </item>
    
    <item>
      <title>p-군</title>
      <link>https://freshrimpsushi.github.io/posts/p-group/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/p-group/</guid>
      <description>유한군 $G$ 의 항등원이 $e$ 라고 할 때, $g \in G$ 가 $g^{n} = e$ 를 만족하는 가장 작은 $n \in \mathbb{N}$ 에 대해 $|g| = n$ 이라 나타낸다. 모든 $g \in G$ 와 주어진 소수 $p$ 에 대해 $|g| = p^{m}$ 을 만족하는 정수 $m \ge 0$ 이 존재할 때, $G$ 를 $p$-군 이라고 한다.$X_{G} : = \left\{ x \in X , | , gx = x , g \in G \right\} $ 는 작용에 무관한 집합으로, $\displaystyle X_{G} = \bigcap_{ g \in G} X_{g}$ 이라고 나타낼 수도 있다.한</description>
    </item>
    
    <item>
      <title>R 에서 조건부로 데이터 필터링하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/659/</link>
      <pubDate>Sun, 26 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/659/</guid>
      <description>R 이 주로 통계학에서 쓰이기 때문인지, 필요한 데이터를 골라내고 편집하는 기능은 타의 추종을 불허한다. 이러한 데이터의 핸들링에 익숙해지는 것은 조금 어렵지만, 완벽하게 터득하고 나면 다른 언어가 너무나 불편할 것이다.사실 이러한 팁들은 읽는 것만으로는 크게 도움이 되지 않는다. (실제로 정확성을 기하려다보니 설명도 간결할 수밖에 없다.) 많은</description>
    </item>
    
    <item>
      <title>우리손 보조정리 티체 확장 정리</title>
      <link>https://freshrimpsushi.github.io/posts/urysohns-lemma-tietze-extension-theorem/</link>
      <pubDate>Sat, 25 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/urysohns-lemma-tietze-extension-theorem/</guid>
      <description>우리손 보조정리 $X$ 가 정규 공간이면 $A \cap B = \emptyset$ 인 모든 닫힌 집합 $A, B \subset X$ 에 대해 $f(A) = \left\{ 0 \right\}$ 와 $f(B) = \left\{ 1 \right\} $ 를 만족하는 연속 함수 $f:X \to [0,1]$ 가 존재한다.티체 확장 정리 정규 공간 $X$ 에서 닫힌 집합 $C$ 에 대해 $f : C \to \mathbb{R}$ 가 연속이면 $F |_{C} = f$ 를 만족하는 연속함수 $F : X \to \mathbb{R}$ 가 존재한다.우리손 보조정리 는 위상수학을 사용하는 온갖 분야에 동원되는만큼 적혀있</description>
    </item>
    
    <item>
      <title>엔탈피 헬름홀츠 함수 깁스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/enthalpy-helmholtz-function-gibbs-function/</link>
      <pubDate>Fri, 24 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/enthalpy-helmholtz-function-gibbs-function/</guid>
      <description>1. 엔탈피 ** : $H := U + PV$2. 헬름홀츠 함수 : $F := U - TS$3. 깁스 함수 : $G := H - TS$엔탈피는 엔트로피에 거의 준할정도로 이름이 알려진 함수지만 중요하게 다루는 분야는 주로 화학이다. 물리를 위해선 아득바득 물리적인 의미를 이해하기보단 저 셋을 셋트로 묶어 대수적인 조작 정도로만 봐도 무방하다. 열역학 제1법칙에서 유도되는 내부 에너지의 표현까지 생</description>
    </item>
    
    <item>
      <title>R 에서 조건부 합 조건부 평균 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/656/</link>
      <pubDate>Thu, 23 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/656/</guid>
      <description>엑셀이라고 치면 sumif() 혹은 averageif() 함수가 필요한 상황이 가끔 있다.R 에선 그처럼 단순한 함수는 없지만, 압도적인 상위호환으로 apply 계열 함수가 있다.이 함수를 꼼꼼하게 익혀놓으면 좋긴한데, 당장은 급한대로 조건부 합과 조건부 평균만 구해보자.iris 데이터셋을 불러보자.임의로 10, 50, 90, 130번째 데이터를 살펴보면 범주형 변수로써 종을 분류해놓은 것을</description>
    </item>
    
    <item>
      <title>깁스의 엔트로피 표현</title>
      <link>https://freshrimpsushi.github.io/posts/gibbs-expression-for-the-entropy/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gibbs-expression-for-the-entropy/</guid>
      <description>거시상태가 $i$ 번째 상태일 확률을 $P_{i}$ 라고 하면 $\displaystyle S = - k_{B} \sum_{i} P_{i} \ln P_{i}$이젠 열에 대한 공부라고 말하기도 어려울 정도까지 왔다.하지만 반대로 생각해보면, 엔트로피 자체가 열역학을 뛰어넘어 이런 것까지 생각하기 위해 도입되었다고 볼 수도 있다. 유도 **Part 1. 열역학 제1법칙$d U = \delta Q + \delta W$엔트로피의 정의에서 $\delta Q = T dS$ 이고, $\delta w= - p dV$</description>
    </item>
    
    <item>
      <title>회귀계수의 t검정 t-test for Regression Coefficient</title>
      <link>https://freshrimpsushi.github.io/posts/654/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/654/</guid>
      <description>단순회귀분석 보러가기다중회귀분석 보러가기R 에서 단순회귀분석 결과 보러가기$n$ 개의 관측치와 $p$ 개의 독립변수에 대한 다중회귀분석에 대해 $i=0,1,\cdots,p$ 라고 하자.$H_{0}$ : $\beta_{i} = 0$ 즉, $i$ 번째 독립변수는 종속변수과 관계 없다.$H_{1}$ : $\beta_{i} \ne 0$ 즉, $i$ 번째 독립변수에 대한 회귀계수가 유의하다.회귀계수의 추정치 $\hat{ \beta_{i} }$ 와 표준오차 $</description>
    </item>
    
    <item>
      <title>우주의 엔트로피는 감소하지 않음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/653/</link>
      <pubDate>Mon, 20 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/653/</guid>
      <description>우주의 엔트로피는 감소하지 않는다.위 명제를 보고 가장 먼저 알 수 있는 사실은 &amp;lsquo;뭔가 멋있다&amp;rsquo;는 점이다.하지만 정말로 멋있는 건 이것을 수식적으로 이해한 사람이고, 그런 사람이 될 수 있도록 노력하자. 증명 이 우주는 유일하며, 따라서 이 우주의 &amp;lsquo;외부&amp;rsquo;같은 건 존재하지 않는다는 가정이 필요하다</description>
    </item>
    
    <item>
      <title>R 에서 단순회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</guid>
      <description>단순회귀분석 보러가기회귀계수의 t검정 보러가기*하단에 예제코드 전체가 있다.*수학, 통계적인 기초가 부족한 비전공자는 밑줄 그어진 부분만 읽어도 상관 없다. head(faithful) R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자.데이터만 봐서는 두 변수 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph(6,3) par(mfrow=c(1,2)) plot(faithful, main =&amp;#34;faithful&amp;#34;,asp=T)</description>
    </item>
    
    <item>
      <title>열역학에서 엔트로피란</title>
      <link>https://freshrimpsushi.github.io/posts/entropy/</link>
      <pubDate>Sat, 18 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/entropy/</guid>
      <description>$\displaystyle dS = {{ \delta Q_{\text{rev} } } \over { T }}$ 를 만족하는 $S$ 를 **엔트로피** 라 정의한다.엔트로피는 &amp;lsquo;무질서도&amp;rsquo;를 나타내는 물리량으로써, 수식적인 정의만 보고는 이게 왜 무질서도인지 이해하기 어렵다. &amp;lsquo;방 어지르기&amp;rsquo;나 &amp;lsquo;물잔에 잉크 떨어뜨리기&amp;rsquo; 등 비전공자를 위한 설명은</description>
    </item>
    
    <item>
      <title>단순회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/simple-linear-regression/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simple-linear-regression/</guid>
      <description>R 에서 단순회귀분석 결과 보러가기회귀계수의 t검정 보러가기*수학적인 기초가 부족한 비전공자는 수식적인 설명보다는 밑줄 그어진 설명만 읽고 대략 어떤 느낌인지만 알아도 충분하다.회귀분석이란 변수 사이의 관계를 알아내는 방법으로써, 특히 선형 관계를 밝히는 데 유용하다.단순회귀분석은 그 중에서도 가장 쉬운 것으로, 종속변수(반응변수) 하</description>
    </item>
    
    <item>
      <title>클라우지우스 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/clausius-inequality/</link>
      <pubDate>Thu, 16 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/clausius-inequality/</guid>
      <description>순환 과정에서 $\displaystyle \oint {{\delta Q} \over {T}} \le 0 $ 이다. 특히 가역 과정이면 $\displaystyle \oint {{\delta Q_{\text{rev}}} \over {T}} = 0 $ 이다.&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20180731_182816.png&amp;rdquo; height=&amp;ldquo;235&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99126E3C5B602BC724&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;309&amp;rdquo;/&amp;gt;순환 과정이란 위와 같이 과정을 시작할 때와 끝낼 때 계의 상태가 같은 과정을 말한다.만약 이 과정 전체가 가역과정이라면 그 폐적분은 항상 $0$ 이고, 그때 $Q := Q_{\text{rev}}$ 와 같은 표현</description>
    </item>
    
    <item>
      <title>적합치 예측치 잔차 오차</title>
      <link>https://freshrimpsushi.github.io/posts/fitted-value-predict-value-residual-error/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fitted-value-predict-value-residual-error/</guid>
      <description>회귀분석 $Y \leftarrow X_{1} + X_{2} + \cdots + X_{n}$ 으로 얻은 회귀식을 $y = \beta_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} + \cdots + \beta_{n} x_{n} $ 이라고 하고 $i$ 번째 데이터를 $(y_{i} , x_{i1} , x_{i2} , \cdots , x_{in})$ 와 같이 나타내도록 하자.**1. 평균Mean** : $$ \displaystyle \overline{y} := {{1} \over {n}} \sum_{i=1}^{n} y_{i} $$ **2. 적합치Fitted Value** : $i$ 번째 데이터 $y_{i}$ 에 대해 $$ \hat{y}_{i} := \beta_{0} + \beta_{1} x_{i1} + \beta_{2} x_{i2} + \cdots + \beta_{n} x_{in} $$ **3. 예측치Predicted Value** : 새로운 데이터</description>
    </item>
    
    <item>
      <title>일의 자리가 5인 두자리수의 거듭제곱 쉽게하기</title>
      <link>https://freshrimpsushi.github.io/posts/661/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/661/</guid>
      <description>중고등학생부터 대학생까지 간단한 계산은 빠를수록 좋다. 모든 곱셈을 빠르게 할 수 있는 방법 같은건 없다.비상한 두뇌를 가지고 암산 천재로 태어나는 딱 하나의 방법이 있다. 그렇지만 특별한 상황에서는 누구나 빠르게 계산할 수 있다.일의 자리가 5인 두자리수의 거듭제곱은 위의 사진에 보이는 대로 빠르고 쉽게 계산할 수 있다.결과만 알고 사용해도 상관없지</description>
    </item>
    
    <item>
      <title>카르노 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-carnot-theorem/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-carnot-theorem/</guid>
      <description>정리 카르노 기관보다 효율이 높은 기관은 존재하지 않는다. 어차피 카르노 기관을 실제로 구현할 순 없지만 이론적인 한계가 된다는 점에서 대단히 의미있는 정리다. 증명 카르노 기관 $C$ 보다 효율이 높은 기관 $E$ 가 존재한다고 가정해보자.$E$ 는 열 $Q_{h}&#39;$ 를 받아서 $W$ 만큼의 일을 하고, $C$ 는 열 $Q_{l}$ 과 일 $W$ 를 받아서 열 $Q_{h}$ 를 내놓는다.두 기관을 하나의 기관으로 보면 $E</description>
    </item>
    
    <item>
      <title>위상수학에서의 함수공간</title>
      <link>https://freshrimpsushi.github.io/posts/function-space/</link>
      <pubDate>Mon, 13 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/function-space/</guid>
      <description>위상공간 $X$ 와 $Y$ 에 대해 $\displaystyle Y^{X} : = \prod_{x \in X} Y = \left\{ f , | , f : X \to Y \text{ is a function} \right\} $ 를 함수 공간 이라고 한다. 함수공간의 위상이 되는 것으로 다음이 있다 :(1) $x \in X$ 와 $Y$ 에서 열린 집합 $U$ 에 대해 $S (x , U) = \left\{ f \in Y^{X} , | , f(x) \in U \right\} $ 라 하자. 부분기저 $\left\{ S(x,U) , | , x \in X , U \subset Y \right\} $ 로 생성되는 $Y^{X}$ 의 위상을 포인트-오픈 위상Point-Open Topology 이라</description>
    </item>
    
    <item>
      <title>카르노 기관</title>
      <link>https://freshrimpsushi.github.io/posts/carnot-engine/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/carnot-engine/</guid>
      <description>다음 네 가지 과정을 순서대로 수행하는 기관을 카르노 기관Carnot Engine 이라고 한다.Step 1. 등온 팽창 과정 $ A \to B$온도가 $T_{h}$ 로 유지된 상태에서 열에너지 $Q_{h}$ 를 받아 부피가 $V_{A}$ 에서 $V_{B}$ 로 증가한다.**Step 2.** 단열 팽창 과정 $B \to C$열이 유지된 상태에서 부피가 $V_{B}$ 에서 $V_{C}$ 로 증가해서 온도가 $T_{h}$ 에서 $T_{l}$ 로 감소한다.**Step 3.** 등온 수축 과정</description>
    </item>
    
    <item>
      <title>제3동형 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-third-isomorphism-thoerem/</link>
      <pubDate>Sat, 11 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-third-isomorphism-thoerem/</guid>
      <description>$G,G&#39;$ 가 군이라고 하자.제1동형 정리 : 준동형사상 $\phi : G \to G&#39;$ 이 존재하면 $G / \ker ( \phi ) \simeq \phi (G)$제2동형 정리 : $H \le G$ 이고 $N \triangleleft G$ 면 $(HN) / N \simeq (H \cap N)$제3동형 정리 : $H , K \triangleleft G$ , $K \le H$ 면 $G/H \simeq (G/K) / (H/K)$동형 정리는 대수학자 에미 뇌터에 의해 증명된 정리로 독립적인 위의 세 가지 정리를 일컫는다.제3동형 정리에서 몫군의 표현을 조금</description>
    </item>
    
    <item>
      <title>열역학 제2법칙</title>
      <link>https://freshrimpsushi.github.io/posts/the-second-law-of-thermodynamics/</link>
      <pubDate>Fri, 10 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-second-law-of-thermodynamics/</guid>
      <description>열역학 제0법칙 보러가기열역학 제1법칙 보러가기클라우지우스 : 스스로 차가운 쪽에서 뜨거운 쪽으로 열을 보내는 과정은 존재하지 않는다.켈빈 : 열을 완전히 일로 바꾸는 과정은 존재하지 않는다.열역학 제2법칙 에 대한 독일의 물리학자 클라우지우스Clausius와 영국의 물리학자 켈빈Kelvin의 진술은 서로 동치다.가장 유명한 것은 그리</description>
    </item>
    
    <item>
      <title>열역학 제1법칙</title>
      <link>https://freshrimpsushi.github.io/posts/the-first-law-of-thermodynamics/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-first-law-of-thermodynamics/</guid>
      <description>열역학 제0법칙 보러가기열역학 제2법칙 보러가기열에너지가 $Q$ 인 계에 가해진 일이 $W$ 일 때, 내부에너지 $U$ 에 대해 $d U = \delta Q + \delta W $$ \delta$ 는 불완전 미분Inexact Differential 임을 나타낸다.이들은 깔끔한 폼으로 원시함수가 존재하지 않기 때문에 선적분을 통해 계산해야한다.내부에너지의 변화만 가지고는 구체적으로 열에너지가 어느정도로 변했는지, 일</description>
    </item>
    
    <item>
      <title>추상대수학에서의 몫군</title>
      <link>https://freshrimpsushi.github.io/posts/factor-group/</link>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factor-group/</guid>
      <description>$H \subset G$ 의 모든 잉여류의 집합을 $G / H$ 라고 하자. $(aH) * (bH) = (ab) H$ 와 같이 잘 정의된 이항연산 $$ 이 존재하면 $\left&amp;lt; G / H , * \right&amp;gt;$ 를 몫군Factor Group 이라 한다. $H \leqslant G$ 이면 다음이 성립한다.$H \triangleleft G $$ \iff $$ G / H$ 는 군이다.이항연산 $$ 는 잉여류의 대푯값끼리만 계산하는 이항연산으로써 집합 $G / H$ 가 몫군을 이루도록 한다.$G / H$ 이 왜 군이 되는지 직관</description>
    </item>
    
    <item>
      <title>열용량</title>
      <link>https://freshrimpsushi.github.io/posts/heat-capacity/</link>
      <pubDate>Sun, 29 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heat-capacity/</guid>
      <description>열 $Q$ , 온도 $T$ 인 계에 대해 $\displaystyle C : = {{dQ} \over {dT}}$ 를 열용량Heat Capacity라 정의한다.단위질량 당 열용량을 비열Specific Heat Capacity이라고 하는데, 다른 분야에선 모르겠지만 물리에선 별로 중요치 않다.열역학에서는 어떤 특정한 물질의 특성보다는 일반적으로 계에서 일어나는 현상에 관심이 있기 때문이다.사실 열용량은 그 역</description>
    </item>
    
    <item>
      <title>티호노프 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-tychonoff-theorem/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-tychonoff-theorem/</guid>
      <description>$\left\{ X_{\alpha} , | , \alpha \in \mathscr{A} \right\} $ 가 컴팩트 공간들의 집합이면 $\displaystyle X : = \prod_{\alpha \in \mathscr{A}} X_{ \alpha} $ 는 컴팩트다.이름까지 붙은 정리치고는 일개 성질 나부랭이처럼 보이지만 사실 그 반대로 보는 게 맞다. 일개 성질 나부랭이처럼 보이지만 의외로 증명하기가 너무 어려워서 정리에 이름까지 붙어버린 것이다. 유용하기론 둘째가라면 서러운 컴팩트가 위상공간들의 데카르트 곱에 대해서</description>
    </item>
    
    <item>
      <title>기체분자의 평균 운동에너지</title>
      <link>https://freshrimpsushi.github.io/posts/mean-kinetic-energy-of-a-gas-molecule/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-kinetic-energy-of-a-gas-molecule/</guid>
      <description>온도가 $T$ 인 계에서 기체분자들의 평균 운동에너지는 $\displaystyle \left&amp;lt; E_{K} \right&amp;gt; = {{3} \over {2}} k_{B} T $기체분자 하나하나에 대해 운동에너지를 구해서 평균을 구하는 것은 비효율적일뿐만 아니라 현실적으로 불가능하다.하지만 통계적으로 유도한 이 공식에 따르면 운동에너지는 오로지 온도에만 의존하며 구하기도 쉬워진다.상수배가 하필 $\displaystyle {{ 3 } \over {2}}$ 와 같이 기괴하게 나타나는 이</description>
    </item>
    
    <item>
      <title>알렉산더 부분기저 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-alexander-subbasis-theorem/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-alexander-subbasis-theorem/</guid>
      <description>$X$ 가 위상공간이라고 하자.$X$ 는 컴팩트다. $\iff$ $\mathscr{S}$ 의 멤버들로 이루어진 $X$ 의 모든 열린 커버가 유한 부분커버를 갖게끔 하는 $X$ 의 어떤 부분기저 $\mathscr{S}$ 가 존재한다.컴팩트가 나왔으니 중요성은 말할 필요 없을 것이다.본 정리는 원래 알렉산더의 스승이 기저에 대해 증명하려고 했던 정리였다. 하지만 기저에 대해서는 증명할 수 없었고, 스승의 유지를 이어받은 알</description>
    </item>
    
    <item>
      <title>맥스웰 분포</title>
      <link>https://freshrimpsushi.github.io/posts/maxwell-distribution/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maxwell-distribution/</guid>
      <description>기체분자의 속력을 나타내는 확률변수 $V$ 는 확률밀도함수가 $\displaystyle f(v) = {{4} \over {\sqrt{ \pi } } } \left( {{m} \over {2 k_{B} T}} \right)^{{3} \over {2}} v^2 e^{- {{mv^2} \over {2k_{B} T }}} $ 인 **맥스웰 분포**Maxwell Distribution 를 따른다.맥스웰 분포는 볼츠만 분포에서 유도되어 **맥스웰-볼츠만 속력 분포** 라고도 불린다.통계역학이라는 이름이 무색해질만큼 통계학에서 볼 수 없는 분포로, 굳이 엮자면 정규</description>
    </item>
    
    <item>
      <title>유사벡터란</title>
      <link>https://freshrimpsushi.github.io/posts/pseudovector/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pseudovector/</guid>
      <description>물리학 공부를 하다 보면 유사벡터 혹은 수도벡터라는 말을 접할 수 있다. 중요한 점은 유사벡터를 접하기만 할 뿐 어떤 녀석인지 알기는 힘들다는 거다. 유사벡터가 뭔지 몰라도 학부 물리학을 공부하는데 아무 지장은 없다지만 제대로 설명해놓은 교재를 본 적이 없다. 나는 유사벡터의 특징을 배울 수 있도록 한 그리피스 전자기학의 연습문제에서 준벡터(Pseud</description>
    </item>
    
    <item>
      <title>추상대수학에서의 핵</title>
      <link>https://freshrimpsushi.github.io/posts/kernel/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kernel/</guid>
      <description>선형대수학에서의 영공간 보러가기$G, G&#39;$ 의 항등원 $e, e&#39;$ 과 준동형사상 $\phi : G \to G&#39;$ 에 대해 $\left\{ e&#39; \right\} $ 의 원상 $ \phi^{-1} [ \left\{ e&#39; \right\} ]$ 을 $\phi$ 의 핵Kernel 이라고 하고 $\ker \phi $ 라고 쓴다.(1) $g \in G$ 에 대해 $g ( \ker \phi ) = ( \ker \phi ) g$(2) $\ker \phi \triangleleft G$(3) $\ker \phi = \left\{ e \right\} $$ \iff $$ \phi$ 는 단사다.(4) $\phi$ 가 전사고 $\ker \phi = \left\{ e \right\}$ 면 $\phi$ 는 동형사상이다.(3) 는 필요충분조건이</description>
    </item>
    
    <item>
      <title>연속제곱법 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-successive-squaring-method/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-successive-squaring-method/</guid>
      <description>자연수 $a,k,m$ 에 대해 $b \equiv a^{k} \pmod{m}$ 를 다음과 같이 계산할 수 있다.Step 1. $k$ 의 이진법 전개$u_{i} = 0$ 혹은 $u_{i} = 1$ 에 대해 $\displaystyle k = \sum_{i=0}^{r} u_{i} 2^{i} = u_{0} + 2 u_{1} + \cdots + 2^r u_{r}$ 로 나타낸다.**Step 2. $a \equiv A_{0} \pmod{m} $$ a^{2} \equiv ( a^1 )^2 \equiv A_{0}^2 \equiv A_{1} \pmod{m} $$ a^{4} \equiv ( a^2 )^2 \equiv A_{1}^2 \equiv A_{2} \pmod{m} $$ a^{8} \equiv ( a^4 )^2 \equiv A_{2}^2 \equiv A_{3} \pmod{m}$&amp;hellip;위와 같이 $a^{2^{r}} \equiv ( a^{2^{r-1}} )^2 \equiv A_{r-1}^2 \equiv A_{r} \pmod{m}$ 를 계</description>
    </item>
    
    <item>
      <title>위상공간의 데카르트 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cartesian-product-of-topology-space/</link>
      <pubDate>Sun, 22 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cartesian-product-of-topology-space/</guid>
      <description>군의 데카르트 곱 보러가기인덱스 집합 $\mathscr{A}$ 에 대해 $\left\{ X_{\alpha} , | , \alpha \in \mathscr{A} \right\} $ 가 위상공간들의 집합이고 $O_{\alpha} $ 을 $X_{\alpha}$ 에서 열린 집합이라고 하자. 데카르트 곱 $\displaystyle X := \prod_{\alpha \in \mathscr{A}} X_{ \alpha} $ 에 대해 $p_{\alpha} : X \to X_{\alpha}$ 를 **사영**Projection 이라고 한다. 부분기저 $\mathscr{S} : = \left\{ p_{\alpha}^{-1} ( O_{\alpha} ) , | , O_{\alpha} \subset X_{\alpha} , \alpha \in \mathscr{A} \right\} $ 에 의해 생성되는 $X$ 의 위상을 **곱위상**Produ</description>
    </item>
    
    <item>
      <title>군의 데카르트 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cartesian-product-of-groups/</link>
      <pubDate>Sat, 21 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cartesian-product-of-groups/</guid>
      <description>선형대수학에서의 직합 보러가기위상공간의 데카르트 곱 보러가기군 $G_{1} , \cdots , G_{n}$ 들의 데카르트 곱과 그 원소 $\displaystyle (a_{1},\cdots , a_{n}), (b_{1} , \cdots , b_{n} ) \in \prod_{i=1}^{n} G_{i} $ 에 대해 $(a_{1},\cdots , a_{n}) (b_{1} , \cdots , b_{n} ) = (a_{1} b_{1},\cdots , a_{n} b_{n})$ 이면 $\displaystyle \in \prod_{i=1}^{n} G_{i} $ 를 $G_{1} , \cdots , G_{n}$ 들의 **직곱**Direct Product 이라고 한다. 특히 $G_{1}, \cdots , G_{n}$ 이 가환군이면 $\displaystyle \bigoplus_{i=1}^{n} G_{i}$ 로 쓰고 **직합**Direct Sum 이라고도 부른다.</description>
    </item>
    
    <item>
      <title>등온 대기에서 높이에 따른 기체 분자 수 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/618/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/618/</guid>
      <description>기온 $T$ 가 일정하다고 할 때 높이 $h$ 에서 단위 부피 $V=1$ 당 기체분자의 수를 $N(h)$ 라고 하자. 기체분자의 질량이 $m$ 이고 중력가속도가 $g$ 면, $\displaystyle N(h) = N(0) e^{- {{mgh} \over {k_{B} T}} }$이 공식은 원래 열역학에선 별볼일 없지만, 유도하는 두 가지 방법이 판이하게 다른 점이 재미있다. 유도1 미분방정식을 통해 유도한다.높이 $h$ 에서 $h + dh$ 까지의 공기층을 생각해보자.단위넓이 안에</description>
    </item>
    
    <item>
      <title>스털링 근사 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-stirling-approximation/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-stirling-approximation/</guid>
      <description>덜 엄밀한 증명 보러가기 $$ \displaystyle \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ 스털링 근사 혹은 스털링 공식Stirling Formula 은 통계학이나 물리학 등 여러 곳에서 유용하게 쓰인다. 또 다른 표현으로는 감마 함수를 사용해 다음과 같이 적을 수 있다. $$ \Gamma ( n ) \approx {e^{n \ln n - n} \sqrt{ 2 \pi n}} $$ 본 증명은 &amp;lsquo;제타함수의 비밀&amp;rsquo;이라는 책의 부록에</description>
    </item>
    
    <item>
      <title>볼츠만 분포</title>
      <link>https://freshrimpsushi.github.io/posts/boltzmann-distribution/</link>
      <pubDate>Tue, 17 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/boltzmann-distribution/</guid>
      <description>온도가 $T$ 인 계의 에너지가 $\epsilon$ 일 확률은 $P(\epsilon) \propto e^{ - {{\epsilon } \over {k_{B} T}} } $**앙상블**ensemble 이란 쉽게 말해 &amp;lsquo;계들이 이루는 상황&amp;rsquo;이다.그 중에서 정준 앙상블Canonical Ensemble** 이란 위와 같이 **열저장소**Reservoir 와 아주 작은 **계**&amp;lt;**sup&amp;gt;System 가 있는 상황이</description>
    </item>
    
    <item>
      <title>실해석학에서의 민코프스키 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-minkowskis-inequality/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-minkowskis-inequality/</guid>
      <description>유클리드 공간에서의 민코프스키 부등식 보러가기$p \ge 1$ 이고 $f,g \in \mathcal{L}^{p}$ 면 $| f + g |{p} \le | f |{p} + | g |_{p} $$ \mathcal{L}^p$ 가 놈 벡터공간임을 보이는데에 필요하다. 증명 $p=1$ 는 코시-슈바르츠 부등식에 의해 바로 유도되므로 $p&amp;gt;1$ 에 대해서만 보이면 충분하다.$| f + g |^{p} = | (f + g) (f+ g)^{p-1} | \le |f| |f + g |^{p-1} + |g| | f+ g |^{p-1}$ 이므로$\displaystyle \int | f + g</description>
    </item>
    
    <item>
      <title>열역학에서 온도의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-temperature/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-temperature/</guid>
      <description>에너지가 $E$ 인 계가 있다고 하자. $E$ 에 대한 미시상태의 갯수를 $\Omega(E) = \Omega$ 라고 할 때 $$ \displaystyle {{1 } \over {k_{B} T}} : = {{ d \ln ( \Omega ) } \over {d E }} $$ 를 만족하는 $T$ 를 계의 **온도** 라고 정의한다. (단, $k_{B}$ 는 볼츠만 상수)통계 역학에서 어떤 계의 **거시상태**Macrostate 와 **미시상태**Microstate 란 예를 들어 다음과 비슷한 개념이다.</description>
    </item>
    
    <item>
      <title>열역학 제0법칙</title>
      <link>https://freshrimpsushi.github.io/posts/the-zeroth-law-of-thermodynamics/</link>
      <pubDate>Sat, 14 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-zeroth-law-of-thermodynamics/</guid>
      <description>열역학 제1법칙 보러가기열역학 제2법칙 보러가기계 $A,B,C$ 에 대해 $A$ 와 $B$ 가 열역학적 평형을 이루고 $B$ 와 $C$ 열역학적 평형을 이루면 $A$ 와 $C$ 도 열역학적 평형 을 이룬다.열역학 제0법칙을 수학적으로 표현하자면 &amp;lsquo;열역학적 평형의 추이성&amp;lsquo;이 된다. 유클리드 기하학 제1공리$A = B \land B=C \implies A = C$ 와 같이 각 분야의 근간을 이루는 중</description>
    </item>
    
    <item>
      <title>실해석학에서의 횔더 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-hoelders-inequality/</link>
      <pubDate>Thu, 12 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-hoelders-inequality/</guid>
      <description>유클리드 공간에서의 횔더 부등식 보러가기일반화된 횔더 부등식$p&amp;gt;1$ 에 대해 $\displaystyle {{1} \over {p}} + {{1} \over {q}} = 1$ 이고 $f \in \mathcal{L}^{p} (E) $ , $g \in \mathcal{L}^{q} (E)$ 면 $fg \in \mathcal{L}^{1} (E)$ 그리고 $| fg |{1} \le | f |{p} | g |_{q}$ 본질적으로 선형대수학에서의 횔더 부등식과 같으며, $p=q=2$ 일 때 코시-슈발츠 부등식이 되는 것 또한 마찬가지다.증명 자체는 코시-슈발츠 부등식의 증명에서 영의 부등식이</description>
    </item>
    
    <item>
      <title>스털링 근사 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-stirling-approximation/</link>
      <pubDate>Wed, 11 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-stirling-approximation/</guid>
      <description>더 엄밀한 증명 보러가기 $$ \displaystyle \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ 흔히 **스털링 공식**Stirling&amp;rsquo;s Formula 으로 많이 불리는 이 근사는 큰 수에 대한 팩토리얼의 계산이라는 측면에서 유용하다. 열열학, 통계역학과 같은 분야에선 많은 수의 분자를 가정하기 때문에 필수적이며, $\ln n! \approx n \ln n - n$ 와 같이 더 간략화된 표현도 사용된</description>
    </item>
    
    <item>
      <title>수학 물리학 전공 교재에서 더블유와 오메가 구별하기</title>
      <link>https://freshrimpsushi.github.io/posts/611/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/611/</guid>
      <description>물리학, 수학 전공책을 읽다보면 오메가인지 더블유인지 헷갈리는 문자가 있다. 이제 갓 전공과목을 공부하기 시작한 2학년의 경우 오메가의 존재를 모르고 더블유인 줄 아는 경우도 있다. 사실 물리학에서는 십중팔구 오메가이다. 더블유는 잘 쓰이지 않는다. 수학에서는 더블유가 더 많이 쓰이는 것 같다. 솔직히 오메가라 고 읽으나 더블유라고 읽으나 크게 상관</description>
    </item>
    
    <item>
      <title>칸토어 집합</title>
      <link>https://freshrimpsushi.github.io/posts/cantor-set/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cantor-set/</guid>
      <description>$\displaystyle I = \left[ 0, 1 \right] $$ \displaystyle C_{1} := \left[ 0, {{1} \over {3}} \right] \cup \left[ {{2} \over {3}} , 1 \right] $$ \displaystyle C_{2} := \left[ 0, {{1} \over {3^2}} \right] \cup \left[ {{2} \over {3^2}}, {{3} \over {3^2}} \right] \cup \left[ {{6} \over {3^2}}, {{7} \over {3^2}} \right] \cup \left[ {{8} \over {3^2}} , 1 \right] $$ \displaystyle C_{n} := \left[ 0, {{1} \over {3^n}} \right] \cup \left[ {{2} \over {3^n}}, {{3} \over {3^n}} \right] \cup \cdots \cup \left[ {{3^n-3} \over {3^n}}, {{3^n-2} \over {3^n}} \right] \cup \left[ {{3^n - 1} \over {3^n}} , 1 \right] $$ \displaystyle C := \bigcap_{n=1}^{\infty} C_{n}$ 을 **칸토어 집합**Cantor Set 이라고 한다.**(1)** $C = \left\{ x \in I , | , x= 0.x_{1} x_{2} \cdots</description>
    </item>
    
    <item>
      <title>라그랑주의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lagranges-theorem/</link>
      <pubDate>Sat, 30 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lagranges-theorem/</guid>
      <description>$H$ 가 유한군 $G$ 의 부분군이면 $|H|$ 는 $|G| $ 의 약수다.조금 생각해보면 상식적으로 성립할 수밖에 없고 증명도 그에 걸맞게 간단하다. 증명 모든 잉여류들은 모두 같은 수만큼의 원소를 갖는다.$H$ 역시 $G$ 의 잉여류 중 하나이므로, $H$ 의 잉여류들의 기수Cardinality는 $|H|$ 이다.잉여류들은 $G$ 의 분할을 이루므로 모든 잉여류들의 기수를 더하면 $|G|$ 이다</description>
    </item>
    
    <item>
      <title>실해석학에서의 코시-슈바르츠 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-schwarz-inequality/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-schwarz-inequality/</guid>
      <description>입시 수학에서의 코시-슈바르츠 부등식유클리드 공간에서의 코시-슈바르츠 부등식$f,g \in \mathcal{L}^{2} (E)$ 면 $fg \in L^{1}(E)$ 이고 $$ \displaystyle \left| \int_{E} f \overline{g} dm \right| \le | f g |_{1} \le | f |_{2} | g |_{2} $$ 함수해석학 정도를 배우고 있다면 이 부등식에 왜 코시-슈바르츠라는 이름이 붙었는지 바로 감이 와야한다.사실 내적이 정의된다면 코시-슈바르츠 부등식은 어디서나 찾을 수 있다. 증명 $\displaystyle \int_{E}</description>
    </item>
    
    <item>
      <title>실해석학에서의 힐베르트 공간</title>
      <link>https://freshrimpsushi.github.io/posts/hilbert-space/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hilbert-space/</guid>
      <description>함수해석학에서의 힐베르트 공간함수공간 $\displaystyle \mathcal{L} ^{2} (E) : = \left\{ f , \left| , \left( \int_{E} | f |^2 dm \right)^{{1} \over {2}} &amp;lt; \infty \right. \right\} $ 을 $\mathcal{L} ^{2}$ 와 같이 나타내고 **힐베르트 공간**Hilbert Space 라고 부른다.**(1)** $\mathcal{L}^{2} $ 는 벡터공간이다.**(2)** $\mathcal{L}^{2} $ 는 놈 벡터공간이다.**(3)** $\mathcal{L}^{2} $ 는 내적 벡터공간이다.**(4)** $\mathcal{L}^{2} $ 는 완비공간이다.힐베</description>
    </item>
    
    <item>
      <title>유클리드의 완전수 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-euclids-perfect-number-formula/</link>
      <pubDate>Tue, 26 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-euclids-perfect-number-formula/</guid>
      <description>$2^{p}-1$ 이 소수면 $2^{p-1}(2^{p} - 1)$ 은 완전수다.모든 완전수가 저런 형태일지는 확실하지 않지만, 저런 형태는 반드시 완전수다.예를 들면 소수 $(2^2 -1) = 3$ 에 대해 $2^{2-1}(2^2 -1) = 6$ 은 완전수다.완전수와 메르센 소수가 이러한 관계를 가지고 있음은 메르센 소수의 등비급수전개에서 어느정도 짐작을 할 수가 있었다. 유도 $2^{p}-1$ 이 소수이므로, $2^{p-1}(2^{p} - 1)$ 의 약수는 $1,2, \cdots , 2^{p-1}$ 와 $(2^{p}-1), 2 (2^{p}-1), \cdots , 2^{p-2} (2^{p}-1)$</description>
    </item>
    
    <item>
      <title>L1 공간</title>
      <link>https://freshrimpsushi.github.io/posts/l1-space/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/l1-space/</guid>
      <description>함수공간 $\displaystyle \mathcal{L} ^{1} (E) : = \left\{ f , \left| , \int_{E} | f | dm &amp;lt; \infty \right. \right\} $ 을 $\mathcal{L} ^{1}$ 과 같이 나타내자.**(1)** $\mathcal{L}^{1} $ 는 벡터공간이다.**(2)** $\mathcal{L}^{1} $ 는 놈 벡터공간이다.**(3)** $\mathcal{L}^{1} $ 는 완비공간이다.$\mathcal{L}^{1}$ 은 르벡 적분가능에 대해 이야기할 때 적분가능한 함수들의 집합으로써 정의된 바 있다. 증명(2) 놈의 정의</description>
    </item>
    
    <item>
      <title>부분군의 정의와 부분군 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-subgroup-and-subgroup-test/</link>
      <pubDate>Sat, 23 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-subgroup-and-subgroup-test/</guid>
      <description>**부분군 군 $G$의 부분 집합 $H$가 군 $G$의 연산에 대해서 군의 조건을 만족할 때, $H$를 군 $G$의 부분군($\mathrm{Subgroup}$)이라고 한다.**부분군 판정법 군 $G$의 공집합이 아닌 부분집합 $H$에 대해서 $a,\ b$가 $H$의 원소일 때 $ab^{-1}$도 $H$의 원소이면 $H$는 $G$의 부분군이</description>
    </item>
    
    <item>
      <title>페아노 공간 충전 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-peano-space-filling-curve/</link>
      <pubDate>Sat, 23 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-peano-space-filling-curve/</guid>
      <description>$I = [0,1]$ 에 대해 전사 연속함수 $ f : I \to I \times I$ 가 존재한다.짧지만 몹시 충격적인 정리다. 이 정리가 사실이라면 선만으로 평면을 구성할 수 있다는 뜻인데, 증명을 보고도 납득하기가 어려울 정도다.&amp;lsquo;공간 충전 정리&amp;rsquo;라는 명칭은 일본에서 번역한 것을 임의로 쓴 것이다.증명을 위해선 다음의 보조정리가 필요하다.완비 거리 공</description>
    </item>
    
    <item>
      <title>르벡 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lebesgue-theorem/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lebesgue-theorem/</guid>
      <description>$\mathscr{O} $ 를 거리공간 $(X,d) $ 의 열린 커버라고 하자.(1) 르벡 수 : $\sup \left\{ d(a,b) , | , a,b \in A \right\} &amp;lt; \varepsilon $ 를 만족시키는 모든 부분집합 $A \subset X$ 이 어떤 $O \in \mathscr{O}$ 에 대해 $A \subset O$ 를 만족하면 $\varepsilon &amp;gt; 0$ 를 $\mathscr{O}$ 에 대한 르벡 수Lebesgue Number 라고 한다.(2) 르벡 보조정리 : $X$ 가 집적점 컴팩트면 $X$ 의 모든 열린 커버 $\mathscr{O}$ 에 대해 르벡 수가 존재한다.(3) 르벡 정리 : $X$ 가 컴팩트면</description>
    </item>
    
    <item>
      <title>디리클레 경계 조건이 주어진 파동방정식에 대한 초기값 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-wave-equation-for-given-dirichlet-boundary-condition/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-wave-equation-for-given-dirichlet-boundary-condition/</guid>
      <description>$\begin{cases} u_{tt} = c^2 u_{xx} \\ u(0,x) = f(x) \\ u_{t}(0,x) = g(x) \\ \end{cases}$주어진 방정식은 파동방정식이 길이가 $l$ 인 $1$차원 공간 상의 디리클레 경계 조건 $\begin{cases} u(t,0) = \alpha(t) \\ u(t,l) = \beta (t) \end{cases}$ 이 $\alpha = \beta = 0$ 으로 주어지고 파형에 대한 초기 조건이 있는 경우다. 이러한 문제 유형 중에는 가장 쉽고 단순한 형태다.여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때의 파형을 나타낸다.$</description>
    </item>
    
    <item>
      <title>파동방정식에 대한 코시 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-cauchy-problem-for-wave-equation/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-cauchy-problem-for-wave-equation/</guid>
      <description>$\begin{cases} u_{tt} = c^2 u_{xx} \\ u(0,x) = f(x) \\ u_{t}(0,x) = g(x) \end{cases}$주어진 방정식은 파동방정식 $\displaystyle \rho (x) {{\partial^2 u} \over {\partial t^2}} = {{ \partial } \over {\partial x}} \left( \kappa (x) {{ \partial u } \over { \partial x }} \right) $ 에서 **밀도Density ** $\rho (x) &amp;gt; 0$ 와 **강도**Stiffness $\kappa (x) &amp;gt; 0$ 이 모두 상수인 경우로써 $\displaystyle c : = {{\kappa} \over {\rho}}$ 를 **파속**Wave Speed 이라 한다.여기서 $t$ 는 시간, $x$ 는 위치</description>
    </item>
    
    <item>
      <title>디리클레 경계 조건이 주어진 열방정식에 대한 초기값 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-heat-equation-for-given-dirichlet-boundary-condition/</link>
      <pubDate>Mon, 18 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-heat-equation-for-given-dirichlet-boundary-condition/</guid>
      <description>수치해석적 풀이 보러가기 $$ \begin{cases} u_{t} = \gamma u_{xx} \\ u(t,0) = u(t,l) = 0 \\ u(0,x) = f(x) \end{cases} $$ 주어진 방정식은 열방정식이 길이가 $l$ 인 $1$차원 공간 상의 디리클레 경계 조건 $\begin{cases} u(t,0) = \alpha(t) \\ u(t,l) = \beta (t) \end{cases}$ 이 $\alpha = \beta = 0$ 으로 주어지고 열분포에 대한 초기 조건이 있는 경우다. 이러한 문제 유형 중에는 가장 쉽고 단순한 형태다.여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때 열의 분포를 나타</description>
    </item>
    
    <item>
      <title>열방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-heat-equation/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-heat-equation/</guid>
      <description>$$ u_{t} = \gamma u_{xx} $$ 주어진 방정식은 열방정식 $\displaystyle {{\partial} \over {\partial t}} \left( \sigma (x) u \right) = {{\partial} \over {\partial x }} \left( \kappa (x) {{\partial u} \over {\partial x}} \right) $ 에서 **열전도율**Thermal Conductivity $\kappa (x) &amp;gt; 0$ 와 **열용량**Heat Capacity $\sigma(x) &amp;gt; 0$ 이 모두 상수인 경우로써 $\displaystyle \gamma : = {{\kappa} \over {\sigma}}$ 을 **열확산율**Thermal Diffusivity 이라 한다.여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때 열의 분포를 나타낸다.</description>
    </item>
    
    <item>
      <title>푸리에 급수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-series/</link>
      <pubDate>Sat, 16 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-series/</guid>
      <description>힐베르트 공간의 함수 $f \in \mathcal{L}^{2} [- \pi , \pi] $ 에 대해 $\displaystyle a_{k} = {{1} \over {\pi}} \int_{- \pi}^{\pi} f(x) \cos kx dx$ 그리고 $\displaystyle b_{k} = {{1} \over {\pi}} \int_{- \pi}^{\pi} f(x) \sin kx dx$ 에 대해 $\displaystyle f(x) \sim {{a_{0}} \over {2}} + \sum_{k=1}^{\infty} \left( a_{k} \cos kx + b_{x} \sin kx \right) $ 를 $f$ 의 **푸리에 급수**Fourier Series 라고 한다.테일러 급수가 어떤 함수를 다항식으로 근사시키는 것과 달리 푸리에 급수는 삼각다항식으로 근사시킨다.이렇듯 복잡한 모양을 가진 푸리</description>
    </item>
    
    <item>
      <title>가산 컴팩트와 린델뢰프</title>
      <link>https://freshrimpsushi.github.io/posts/countably-compact-and-lindeloef/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/countably-compact-and-lindeloef/</guid>
      <description>$X$ 의 모든 가산 열린 커버가 유한 부분 커버를 가지면 $X$ 를 가산 컴팩트Countably Compact 라고 한다.(1) 모든 컴팩트 공간은 가산 컴팩트 공간이다.(2) 가산 컴팩트성는 위상적 성질이다.$X$ 의 모든 열린 커버가 가산 부분 커버를 가지면 $X$ 를 린델뢰프Lindelöf 라고 한다.[1] 제2가산 공간은 린델뢰프 공간이다.[2] $X$ 가 린델뢰프</description>
    </item>
    
    <item>
      <title>리만적분의 일반화로써의 르벡적분</title>
      <link>https://freshrimpsushi.github.io/posts/573/</link>
      <pubDate>Wed, 30 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/573/</guid>
      <description>유계 함수 $f : [a,b] \to \mathbb{R}$ 와 $g : \mathbb{R} \to [0,\infty)$ 이라고 하자.[1] $f$ 가 $[a,b]$ 에서 리만 적분가능한 것은 $f$ 가 르벡 측도에 대해 $[a,b]$ 의 거의 어디에서나 연속인 것과 동치다.[2] $\displaystyle \int_{a}^{b} f(x) dx$ 가 존재하면 $\displaystyle \int_{a}^{b} f(x) dx = \int_{[a,b]} f dm$**[3]** $\displaystyle \int_{-\infty}^{\infty} g(x) dx$ 가 존재하면 $\displaystyle \int_{-\infty}^{\infty} g(x) dx = \int_{\mathbb{R}} g dm$측도에 대한 그 수많은 논의는 모두 이 &amp;lsquo;적분의 일반화&amp;rsquo;를 위한 것이었다. 르벡 적</description>
    </item>
    
    <item>
      <title>파이썬으로 웹 문서 크롤링하고 태그 제거하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-crawl-web-site-and-remove-html-tag-using-python/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-crawl-web-site-and-remove-html-tag-using-python/</guid>
      <description>파이썬은 크롤링을 위한 패키지가 잘 갖춰져있어 쉽게 따라할 수 있다. import requests from bs4 import BeautifulSoup import re rq = requests.get(&amp;quot;https://ko.wikipedia.org/wiki/%EC%98%A4%EB%A7%88%EC%9D%B4%EA%B1%B8&amp;quot;) rqctnt = rq.content soup = BeautifulSoup(rqctnt,&amp;quot;html.parser&amp;quot;) OMG = str(soup.find_all(&amp;quot;p&amp;quot;)) OMG = re.sub(&#39;&amp;lt;.+?&amp;gt;&#39;, &#39;&#39;, OMG, 0).strip()[Colored by Color Scripter](http://colorscripter.com/info#e) 예제로 위키피디아에서 오마이걸 항목을 읽어와보도록 하자.필요한 패키지는 보이는대로 requests 와 bs4 가 있다.읽어들이기만 하고 출력해보면 위와 같이 html 태그가 덕지덕지 붙어있다.제거하기 위해서는 예제 코드에 나온 것처</description>
    </item>
    
    <item>
      <title>오류행렬과 민감도 특이도</title>
      <link>https://freshrimpsushi.github.io/posts/sensitivity-specipicity-and-confusion-matrix/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sensitivity-specipicity-and-confusion-matrix/</guid>
      <description>분류 문제에서 모형을 평가하는 지표로써 위와 같은 오류행렬Confusion Matrix 을 참고할 수 있다 :정분류율Accuracy $$ \displaystyle \text{Accuracy} = {{TP + TN} \over { P + N }} $$ 위 표에서 P는 양성, N은 음성을 나타낸다. TP는 양성으로 예측되었고 실제로 양성인 경우, TN은 음성으로 예측되었고 실제로 음성인 경우다. 이 TP와 TN이 상대적으로 높은 모형을 좋은</description>
    </item>
    
    <item>
      <title>위상수학에서 균등연속이란</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-continuous/</link>
      <pubDate>Sun, 27 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-continuous/</guid>
      <description>거리 공간 $(X, d)$ 와 $(Y, d&#39;)$ 에 대해 $f : X \to Y$ 라고 하자. 모든 $\varepsilon &amp;gt; 0$ 와 $x_{1}, x_{2} \in X$ 에 대해 $$ d(x_{1}, x_{2}) &amp;lt; \delta \implies d&#39;( f( x_{1} ) , f( x_{2} ) ) &amp;lt; \varepsilon $$ 을 만족하는 $\delta &amp;gt; 0$ 가 존재하면 $f$ 를 **균등연속** 이라고 한다.해석학에서 배운 연속의 개념이 위상수학에서 일반화되었듯 균등연속 역시 위상수학에서 일반화가 가능하다. 단 여기서 주의해야할 점은 연속처럼 모든 위상공간에</description>
    </item>
    
    <item>
      <title>랜킨-위고니오 조건과 엔트로피 조건</title>
      <link>https://freshrimpsushi.github.io/posts/rankine-hugoniot-condition-and-entropy-condition/</link>
      <pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rankine-hugoniot-condition-and-entropy-condition/</guid>
      <description>비점성 버거스 방정식 $\displaystyle \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases}$ 해가 $u$ 고 그 파열 시간이 $t^{ * }$ 라고 하자.비점성 버거스 방정식의 해가 파열할 때, 위와 같이 왼쪽과 오른쪽의 넓이가 같아지도록 하는 선분으로 이어준다.이렇게 물리적으로 해석할 수 있도록 해를 조정하는 것을 **등적률等積律**Equal Area Rule 이라고 한다.이렇게 생기는 불연속점의</description>
    </item>
    
    <item>
      <title>R 에서 문자열 다루기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-handle-strings-in-r/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-handle-strings-in-r/</guid>
      <description>개발자들이 많이 사용하는 언어들에 비교하면 그 정도가 덜하지만, R 에서도 문자열을 다룰 일이 생각보다 많다.데이터가 방대하고 제멋대로일수록 이런 사소한 테크닉들이 엄청나게 중요해진다.nchar() 함수는 단순히 문자열의 길이를 반환한다.다른 언어를 먼저 접한 사람은 아마 십중팔구 length를 먼저 쳐봤을 것이다.substring</description>
    </item>
    
    <item>
      <title>시그마 함수</title>
      <link>https://freshrimpsushi.github.io/posts/sigma-function/</link>
      <pubDate>Thu, 24 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sigma-function/</guid>
      <description>$\displaystyle \sigma (n) : = \sum_{d \mid n} d$ 에 대해 다음이 성립한다.**(1)** 소수 $p$ 에 대해, $\displaystyle \sigma( p^k ) = {{p^{k+1} - 1} \over {p-1}} $**(2)** $\gcd (n , m ) = 1$ 이면 $\sigma(nm) = \sigma(n) \sigma(m) $시그마 함수는 쉽게 말해 약수의 합으로, $6$ 을 예로 들자면 $\sigma(6) = 1 + 2 + 3 + 6 = 12 $ 이다. 해석적 정수론에서는 디바이저 함수로 일반화된다.한편 시그마 함수를 언급함으로써 **완전수**Perfect Number 를</description>
    </item>
    
    <item>
      <title>비점성 버거스 방정식에서의 질량 보존 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/law-of-conservation-of-mass-in-inviscid-burgers-equation/</link>
      <pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/law-of-conservation-of-mass-in-inviscid-burgers-equation/</guid>
      <description>비점성 버거스 방정식 $\displaystyle \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases}$ 의 해 $u$ 에 대해 구간 $[a,b]$ 까지의 선질량을 $\displaystyle M_{a,b}(t) := \int_{a}^{b} u(t,x) dx$ 그리고 파열시간을 $t^{ * }$ 이라고 하면 $t \in ( 0 , t^{ * })$ 에 대해 $$ \displaystyle {{d} \over {dt}} M_{a,b}(t) = - \left( {{1} \over {2}} u^2 (t,b) - {{1} \over {2}} u^2 (t,a) \right) $$ * 파열 시간은 수학적으로는 함수가 아니게 되고 물리적으로는 동시에 여러 상태가 중첩된는 시점을 의미한다.수식을 쉽게</description>
    </item>
    
    <item>
      <title>측도론에서의 레비의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-levis-theorem-in-measure-theory/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-levis-theorem-in-measure-theory/</guid>
      <description>확률론에서의 레비 정리$\displaystyle \sum_{k=1}^{\infty} \int |f_{k}| dm &amp;lt; \infty$ 면 $\displaystyle \sum_{k=1}^{\infty} f_{k} (x)$ 는 거의 어디에서나 수렴하고 $$ \displaystyle \int \sum_{k=1}^{\infty} f_{k} dm = \sum_{k=1}^{\infty} \int f_{k} dm $$ 이탈리아의 수학자 **베포 레비**Beppo Levi 에 의해 증명된 이 정리는 함수열의 적분을 놀랍도록 쉽게 풀어준다. 증명 $\displaystyle \phi (x) := \sum_{k=1}^{\infty} | f_{k} (x) |$ 이라고 정의하면 $\phi$ 는 음이 아닌 가측 함수다.단조 수렴 정리의 따름 정리</description>
    </item>
    
    <item>
      <title>위상공간에서 최대최소값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-maximum-and-minimum-value-theorem-in-topological-space/</link>
      <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-maximum-and-minimum-value-theorem-in-topological-space/</guid>
      <description>거리공간에서 최대최소 정리컴팩트 공간 $X$ 에 대해 함수 $f : X \to \mathbb{R}$ 가 연속이면 모든 $x \in X$ 에 대해 $f(c) \le f(x) \le f(d)$ 을 만족하는 $c,d \in X$ 가 존재한다.$\mathbb{R}$ 에서 컴팩트란 폐구간 $[a,b]$ 인 것과 동치이므로 결국 우리가 고등학교, 해석학 때 배운 정리의 일반화가 된다.위상수학의 어려운 이론들을 사용하는만큼 증명은 오히려 간단하고 쉽다. 증명 컴</description>
    </item>
    
    <item>
      <title>컴팩트 공간과 연속함수에 대한 유용한 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/561/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/561/</guid>
      <description>$f : X \to Y$ 에 대해 $X$ 가 컴팩트, $f$ 가 연속이라고 하자.[1] $f$ 가 전사면 $Y$ 는 컴팩트다. $f$ 가 전사가 아니더라도 $f(X)$ 는 컴팩트다.[2] $Y$ 가 하우스도르프면 $f$ 는 닫힌 함수다. 닫힌 집합 $C \subset X$ 에 대해 $f(C) \subset Y$ 는 닫힌 집합이다.[3] $f$ 가 전단사고 $Y$ 가 하우스도르프면 $f$ 는 위상동형사상이다.[4] $X$ 가 거리공간이면 $f$ 는 균등연속이다.별 시덥잖</description>
    </item>
    
    <item>
      <title>지프의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/zipfs-law/</link>
      <pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zipfs-law/</guid>
      <description>코퍼스에서 $k$ 번째로 자주 나타나는 단어의 상대빈도를 $f_{k}$ 라고 하면 $\displaystyle f_{k} = {{C} \over {k}}$여기서 $C$ 는 $\displaystyle \sum_{k} f_{k} = 1$ 이 되도록하는 정규화계수다.히스토그램으로 나타내보면 대략 위와 같은 모양이되 넓이의 합이 정확하게 $1$ 이 되도록 스케일을 조정해준 것이다.오른쪽에 생기는 두꺼운 꼬리 모양을 롱테일이라고 부른다.힙스의 법칙과 마찬가지로 경험적으로</description>
    </item>
    
    <item>
      <title>힙스의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/heaps-law/</link>
      <pubDate>Fri, 18 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heaps-law/</guid>
      <description>코퍼스에서 어휘의 갯수를 $M$, 토큰의 갯수를 $T$ 라고 하면 $M = kT^{b}$코퍼스가 영어일 경우 보통 상수 $k,b$ 는 $10 \le k \le 100$, 그리고 $b = 0.5$ 정도로 나타난다고 한다.힙스의 법칙은 수학적인 근거를 두고 유도된 것이 아니라 경험적으로 얻어진 법칙이다.언뜻 굉장히 복잡해 보이지만 양변에 로그를 취하면 $\log M = \log k + b \log T$ 가 되고, 선형적인 관계를 갖는다.</description>
    </item>
    
    <item>
      <title>R 에서 부트스트랩 함수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-boot-in-r/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-boot-in-r/</guid>
      <description>R 에서 부트스트랩을 시행하는 코드를 직접 짜볼 수도 있지만, 기본적으로 제공되는 함수를 이용할 수도 있다.그 과정은 아래와 같이 단순하지만 다른 함수들과 사용법에 다른 점이 많아서 처음엔 많이 낯설 것이다.Step 1. 구하고 싶은 통계량을 반환하는 함수 boot.fn()을 정의한다.당연히 여기서 함수의 이름은 어찌되든 상관 없다.이때 인수 중엔</description>
    </item>
    
    <item>
      <title>지배 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-dominated-convergence-theorem/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-dominated-convergence-theorem/</guid>
      <description>가측집합 $E \in \mathcal{M}$ 와 $g \in \mathcal{L}^{1} (E)$ 에 대해 가측함수열 $\left\{ f_{n} \right\}$ 이 $E$ 의 거의 어디서나 $|f_{n}| \le g $ 를 만족한다고 하자. 만약 $E$ 의 거의 어디서나 $\displaystyle f = \lim_{n \to \infty} f_{n} $ 이면, $f \in \mathcal{L}^{1}(E)$ 그리고 $$ \displaystyle \lim_{ n \to \infty} \int_{E} f_{n} (x) dm = \int_{E} f dm $$ $f,g \in \mathcal{L}^{1} (E)$ 는 $f$ 와 $g$ 가 르벡 적분가능 함수임을 의미한다.단조 수렴 정리와 비교해보자면 $f_{n} \nearrow f$ 라는 조건이 빠졌고 심지어 $f_{n} \ge 0$ 일 필요도 없어졌다.</description>
    </item>
    
    <item>
      <title>메르센 소수</title>
      <link>https://freshrimpsushi.github.io/posts/mersenne-prime/</link>
      <pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mersenne-prime/</guid>
      <description>$M_{n} = 2^{n} - 1 $ 가 소수면 $M_{n}$ 를 **메르센 소수**Mersenne Prime 라고 한다.메르센 소수의 발견은 $p=x^{n}-1$ 꼴이 소수인지에 대한 탐구로부터 시작된다.수식을 보자마자 단박에 알아챌 수 있는 것은 $x$ 가 홀수인 경우 $p=2$ 를 제외하면 소수가 될 수 없다는 것이다.또한 $x^{n}-1 = (x-1) ( x^{n-1} + x^{n-2} + \cdots + x^2 + x + 1 )$ 이므로, $( x^{n-1} + x^{n-2} + \cdots + x^2 + x + 1 )$ 이 무슨 수가 되든 적</description>
    </item>
    
    <item>
      <title>몬테카를로 방법과 부트스트랩의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/difference-between-monte-carlo-method-and-bootstrap/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-between-monte-carlo-method-and-bootstrap/</guid>
      <description>요약 : 몬테카를로 방법은 작위적인 데이터로 시뮬레이션을 반복해 새로운 기법을 확인하는 방법이고 부트스트랩은 실제 데이터에서 재표본 추출을 통해 비용을 절감하며 문제를 해결하려는 방법이다.몬테카를로 방법Monte Carlo Method 이란 난수 추출을 통해 관심 있는 대상에 대해 점추정량을 찾는 방법이다. 부트스트랩Bootstrap 이란 표본에서 재표본</description>
    </item>
    
    <item>
      <title>계획행렬</title>
      <link>https://freshrimpsushi.github.io/posts/design-matrix/</link>
      <pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/design-matrix/</guid>
      <description>R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자.고작 여섯개지만, 척 봐도 eruptions와 waiting은 양의 상관관계를 가지고 있는 것으로 보인다.만약 이들의 관계를 어떤 두 상수 $\beta_{0}, \beta_{1}$ 에 대해 $\text{(eruptions)} = \beta_{0} + \beta_{1} \cdot \text{( waiting) }$ 으로 나타낼 수 있다면 좋을 것이다.위 식은 두 변수의 선형관계를 직선의 방정식으로써 나타낸 것으로 $\beta_{0}$</description>
    </item>
    
    <item>
      <title>르벡 적분가능</title>
      <link>https://freshrimpsushi.github.io/posts/lesbegue-integrable/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lesbegue-integrable/</guid>
      <description>가측함수 $f$ 에 대해 $f^{+} := \max \left\{ f , 0 \right\}$ 그리고 $E \in \mathcal{M}$ 그리고 $f^{-} := \max \left\{ -f , 0 \right\} E \in \mathcal{M}$ 라고 하자. 그러면 $f = f^{+} - f^{-}$ 이고 $ | f | = f^{+} + f^{-}$ 으로 나타낼 수 있다. 만약 $\displaystyle \int_{E} | f | dm &amp;lt; \infty$, 즉 $\displaystyle \int_{E} f^{+} dm &amp;lt; \infty$ 그리고 $\displaystyle \int_{E} f^{-} dm &amp;lt; \infty$ 이면 $f$ 를 **르벡 적분가능**Lesbegue Integrable 이라고 한다. $E$ 에서 적분가능한 함수들의 집합을 $\displaystyle \mathcal{L}^{1}(E) : = \left\{ f \ \left| \ \int_{E} | f</description>
    </item>
    
    <item>
      <title>발산 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-divergence-theorem/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-divergence-theorem/</guid>
      <description>발산 정리$(\mathrm{divergence\ theorem})$, 가우스 정리$(\mathrm{Gauss\ theorem})$ $$ \displaystyle \int_\mathcal{V} \nabla \cdot \mathbf{ F} dV = \oint _\mathcal{S} \mathbf{F} \cdot d \mathbf{S} $$ 발산 정리는** 가우스 정리** 혹은 **그린 정리$(\mathrm{Green&amp;rsquo;s\ theorem})$** 라고도 부르며 물리에서는 주로 전자기학에서 많이 사용된다. 간단한 모양이면서도 정말 중요</description>
    </item>
    
    <item>
      <title>회귀분석이란</title>
      <link>https://freshrimpsushi.github.io/posts/regression-analysis/</link>
      <pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regression-analysis/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20190905_104344.png&amp;rdquo; height=&amp;ldquo;238&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99BA673C5D706A6A37&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;678&amp;rdquo;/&amp;gt;회귀분석은 거의 모든 통계적 기법의 근간이 되는만큼 너무 일반적이거나 너무 특수하게 설명된 경우가 많다. 그냥 회귀분석이 어떤건지 궁금한 사람에게 한마디로 설명한다면 변수 사이의 관계를 알아내는 방법이라고 할 수 있겠다.이 유용하고도 놀라운 분석법은 우생학을 만들어</description>
    </item>
    
    <item>
      <title>클레로 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-clairaut-differential-equation/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-clairaut-differential-equation/</guid>
      <description>$y=xy^\prime+f(y^\prime )$꼴의 미분방정식을 클레로 방정식 이라 한다. 클레로 미분방정식은 같은 비선형 미분방정식인 베르누이 미분방정식이나 리카티 미분방정식 보다는 풀기 쉬운 편이다.풀이 주어진 미분방정식 $y=xy^\prime+f(y^\prime )$의 양변을 미분한 뒤 정리한다. $$ \begin{align} &amp;amp;&amp;amp;y^\prime = y^\prime+xy^{\prime \prime} + y^{\prime \prime}f^\prime(y^\prime ) \\ \Rightarrow &amp;amp;&amp;amp; xy^{\prime \prime} + y^{\prime \prime}f^\prime(y^\prime )=0 \\ \Rightarrow &amp;amp;&amp;amp; y^{\prime \prime} \left[ x + f^\prime ( y^\prime) \right]=0 \end{align} $$ Case 1. $y^{\prime \prime}=0$인 경우$y=</description>
    </item>
    
    <item>
      <title>포물선의 초점을 지나는 직선이 가지는 성질</title>
      <link>https://freshrimpsushi.github.io/posts/562/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/562/</guid>
      <description>포물선 $y^2 = 4px$ 에 대해 초점 $P(p,0)$ 을 지나는 직선이 포물선과 만나는 두 점을 각각 $A, B$ 라고 하면 $\displaystyle {{1} \over {\overline{PA}} } + {{1} \over {\overline{PB}} } = {{1} \over {p}} $*본 포스트는 &amp;lsquo;수학짱&amp;rsquo;님의 요청으로 작성되었다. 증명 경우 1. $a=b$초점을 지나는 직선이 $x = p$ 인 경우다.$\overline{PA} = \overline{PB} = 2p$ 이므로, $\displaystyle {{1} \over {\overline{PA}} } + {{1} \over {\overline{PB}} } = {{1} \over {2p}}</description>
    </item>
    
    <item>
      <title>표본표준편차와 표준오차의 구분</title>
      <link>https://freshrimpsushi.github.io/posts/541/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/541/</guid>
      <description>$X$ 로부터 얻은 데이터를 $\mathbb{x} = ( x_{1}, x_{2}, \cdots , x_{n} )$ 라고 하자.**(1) 표본평균 :** $\displaystyle \overline{x} = {{1} \over {n}} \sum_{i=1}^{n} x_{i} $**(2) 표본표준편차 :** $\displaystyle s_{x} = \sqrt { {{1} \over {n-1}} \sum_{i=1}^{n} ( x_{i} - \overline{x} )^2 } $**(3) 표준오차 :** $\displaystyle \text{s.e.}( \hat{x} ) = {{ s_{x} } \over { \sqrt{n} }} $말이 비슷해서인지 의외로 많은 사람들이 표본표준편차와 표준오차를 구분하지 못한다. 사실상 통계를 글로만 배우는 고등학생들은 물론이고 심하게는 통계학</description>
    </item>
    
    <item>
      <title>르벡 적분</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-integral/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-integral/</guid>
      <description>리만 적분의 일반화를 생각하기 이전에 단순 함수Simple Function 라는 것을 정의할 필요가 있다.함숫값이 음이 아닌 $\phi : \mathbb{R} \to \mathbb{R}$ 의 치역이 유한 집합 $\left\{ a_{1} , a_{2}, \cdots , a_{n} \right\} $ 이라고 하자. $A_{i} = \phi^{-1} \left( \left\{ a_{i} \right\} \right) \in \mathcal{M}$ 을 만족하면 $\phi$ 를 **단순 함수** 라고 한다. 단순 함수는 다음 성질들을 가진다.**(i)** $i \ne j$ 면 $A_{i } \cap A_{j} = \emptyset$**(ii)** $\displaystyle \bigsqcup_{k=1}^{n} A_{k} = \mathbb{R}$**(iii)** $\displaystyle \phi(x) = \sum_{k=1}^{n} a_{k} \mathbb{1}_{A_{k}}(x) $</description>
    </item>
    
    <item>
      <title>복원력과 1차원 단순 조화 진동자</title>
      <link>https://freshrimpsushi.github.io/posts/restoring-force-and-simple-harmonic-oscillator/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/restoring-force-and-simple-harmonic-oscillator/</guid>
      <description>감쇠 진동강제 진동다중 스프링 진동결합 진동용수철에 매달린 물체의 운동을 생각해보자. 용수철의 복원력에 의해서 왔다갔다하면서 진동한다. 이러한 운동을 조화 진동 이라고 부른다. 조화 진동을 표현하는 함수인 $\sin$과 $\cos$을 아주 예전에는 조화 함수라고 불렀기 때문이다. 조화 진동 중에서도 마찰력이나 다른 외부의 힘은 전혀 없고 오직</description>
    </item>
    
    <item>
      <title>R 에서 NA 제거하기 How to Delete NA in R</title>
      <link>https://freshrimpsushi.github.io/posts/526/</link>
      <pubDate>Sun, 29 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/526/</guid>
      <description>NA는 Not Available의 약자로, R 프로그래밍에선 주로 &amp;lsquo;결측값&amp;rsquo;을 의미한다.일반적인 프로그래밍 언어에서의 null과는 그 의미도 쓰임새도 전혀 다름에 주의하도록 하자.교과서에서 다루는 예제들은 보통 분석하기에 알맞도록 잘 정리되어 있지만, 실제로 분석에 임할 땐 전혀 그렇지가 않다.그런 데이터를 핸들</description>
    </item>
    
    <item>
      <title>n-그램과 자카드 계수</title>
      <link>https://freshrimpsushi.github.io/posts/n-gram-and-jaccard-coefficient/</link>
      <pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/n-gram-and-jaccard-coefficient/</guid>
      <description>n-그램n-gram 이란 어떠한 문자열을 n개씩 끊어서 자른 것을 말한다.예를 들어 &amp;lsquo;오마이갓&amp;rsquo;이라는 문자열의 바이그램bi-gram이라면 &amp;lsquo;오마&amp;rsquo;, &amp;lsquo;마이&amp;rsquo;, &amp;lsquo;이갓&amp;rsquo; 이 된다.자카드 계수Jaccard Coefficient 란 두 집합이 얼마</description>
    </item>
    
    <item>
      <title>상수 계수의 2계 선형 동차 미분방정식과 특성방정식</title>
      <link>https://freshrimpsushi.github.io/posts/second-order-linear-homogeneous-differential-equation-with-constant-coefficients-and-characteristic-equation/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/second-order-linear-homogeneous-differential-equation-with-constant-coefficients-and-characteristic-equation/</guid>
      <description>상수 계수의 2계 선형 동차 미분방정식 $a y^{\prime \prime} + by^\prime +cy=0$의 일반해는 $$ y(x)=A e^{r_1 x}+Be^{r_2 x} $$ 이다. 이 때, $r_{1,2}=\dfrac{-b \pm \sqrt{b^2-4ac}} {2a}$**풀이 주어진 미분방정식이 $a y^{\prime \prime} + by^\prime cy=0$의 꼴일 때 일반해를 구해보자. $$ a\dfrac{d^2}{dx^2}y+b\dfrac{d}{dx}y+cy-0 \tag{1} $$ 우선 미분연산자 $D$를 정의하자. $$ D:=\dfrac{d}{dx} $$ 그러면 $D$는 $D(ay+z)=aDy+Dz$를 만족하기 때문에 선형 연산자이다.</description>
    </item>
    
    <item>
      <title>실해석에서의 거의 어디서나</title>
      <link>https://freshrimpsushi.github.io/posts/almost-everywhere/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/almost-everywhere/</guid>
      <description>거의 어디서나 수렴 $\implies$ 측도 수렴거의 확실히 수렴 $\implies$ 확률 수렴함수 $f : E \to \overline{\mathbb{R}}$ 가 $m(E_{0}) = 0$ 인 $E_{0} \subset E$ 을 제외하고 어떤 성질 $P$ 를 가질 때, $f$ 는 $E$ 의 **거의 어디서나** $P$ 를 가진다고 한다.쉽게 말하면 영집합을 제외한 모든 점을 &amp;lsquo;거의 모든 곳&amp;rsquo;으로 보는 것이다. 이러한 개념은 새삼 정의해서 생소할 뿐 고등학교에서 정적분을 배울 때</description>
    </item>
    
    <item>
      <title>선형 동차 미분방정식의 해의 선형 결합도 해임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-a-linear-combination-of-solutions-of-a-linear-homogeneous-differential-equation-also-to-be-solution/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-a-linear-combination-of-solutions-of-a-linear-homogeneous-differential-equation-also-to-be-solution/</guid>
      <description>$y_1$, $y_2$가 $ay^{\prime \prime}+by^\prime +cy=0$의 해이면 $y_1+y_2$도 해이다.증명을 보면 알겠지만 임의의 $n$계 선형 동차 미분 방정식에 대해서도 성립한다. 증명 $y_1$, $y_2$가 $ay^{\prime \prime}+by^\prime +cy=0$라고 하자. 그러면 아래의 두 식이 성립한다. $$ \begin{align*} ay_1^{\prime \prime}+by_1^\prime + cy_1&amp;amp;=0 \\ ay_2^{\prime \prime}+by_2^\prime + cy_2&amp;amp;=0 \end{align*} $$ $y_1+y_2$를 주어진 미분방정식에 대입하여 $0$이 나오면 증명 끝</description>
    </item>
    
    <item>
      <title>정수와 실수의 포맷 코드에 d f를 쓰는 이유 Why Format Codes uses d f for Integer and Real Number</title>
      <link>https://freshrimpsushi.github.io/posts/523/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/523/</guid>
      <description>점프 투 파이썬C 나 파이썬 등에서 문자열의 입출력에 사용하는 포맷 코드로 %s, %c, %d, %f 등이 있다. 알다시피 %s 은 문자열String을 나타내고 %c 는 문자Character를 나타낸다. 그런데 이렇게 머릿글자에서 따온 것과 달리 정수, 실수를 쓸 땐 %i 와 %r 이 아닌 %d 와 %f 를 사용한다.그 이유는 %d 가 그냥 정수가 아니라 10진법D ecimal을, %f 가 부</description>
    </item>
    
    <item>
      <title>삼각함수의 합차공식과 곱셈공식</title>
      <link>https://freshrimpsushi.github.io/posts/sum-to-product-identities-amp-product-to-sum-identities/</link>
      <pubDate>Wed, 25 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-to-product-identities-amp-product-to-sum-identities/</guid>
      <description>합차 공식이나 곱셈 공식은 삼각 함수의 배각 공식, 반각 공식 등 다른 공식들 보다 중요하지는 않다. 자주 쓰이지 않기 때문이다. 하지만 그렇다고 해서 아예 필요 없는 것도 아니다. 유도과정이 정말 쉬우므로 익혀두고 후에 필요할 때 찾아보지 않고 바로 유도해서 쓰는 게 좋다.삼각함수의 합차 공식 $(\mathrm{sum-to-product\ identities})$ 두 삼각함수의 합이나 차를 곱으로 표현하는 공식 $$ \begin{align} \sin A + \sin</description>
    </item>
    
    <item>
      <title>왜 음함수는 잘못된 번역인가</title>
      <link>https://freshrimpsushi.github.io/posts/why-korean-translation-of-implicit-function-is-inappropriate/</link>
      <pubDate>Wed, 25 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-korean-translation-of-implicit-function-is-inappropriate/</guid>
      <description>양함수냐 음함수냐의 차이는 그저 각각을 어떻게 표현했느냐에 지나지 않는다. 수학에서는 다소 생소한 표현이지만, 그 구분은 &amp;lsquo;독립변수&amp;rsquo;와 &amp;lsquo;종속변수&amp;rsquo;를 어떻게 나타내느냐에 달려있다. 간단히 말하자면 독립변수를 $x$, 종속변수를 그에 따라 달라지는 $y$ 로 두고 그 모양을 보는 것이다.예를 들어 $y</description>
    </item>
    
    <item>
      <title>르벡 가측 함수</title>
      <link>https://freshrimpsushi.github.io/posts/lesbegue-measurable-function/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lesbegue-measurable-function/</guid>
      <description>가측함수의 일반적인 정의함수 $f: E \in \overline{ \mathbb{R} } $ 가 모든 구간 $I \subset \overline{ \mathbb{R} }$ 에 대해 $ f^{-1} (I) = \left\{ x \in \mathbb{R} \ | \ f(x) \in I \right\} \in \mathcal{M}$ 이면 $f$ 를 르벡 가측Lesbegue Measurable 이라고 한다. 아래의 명제들은 서로 동치다.(1) $f$ 가 르벡 가측 함수다.(2) $f^{-1} ( \emptyset ), f^{-1} ( \overline{\mathbb{R}} ) \in \mathcal{M}$(3) $f^{-1} \left\{ \infty \right\} , f^{-1} \left\{ -\infty \right\} \in \mathcal{M}$(4) 모든 $r \in \mathbb{R}$ 에 대해 $f^{-1} ( - \infty , r ], f^{-1} (r, \infty ), f^{-1} ( - \infty , r ), f^{-1}</description>
    </item>
    
    <item>
      <title>유체 위에 물체가 올려져 있을 때 깊이에 따른 유체의 압력</title>
      <link>https://freshrimpsushi.github.io/posts/533/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/533/</guid>
      <description>간단히 말하자면 유체 위에 물체가 있을 때 깊이에 따른 압력은 깊이에 따른 유체의 압력을 구하는 경우에서 $P_0$ 대신 ${P_0 }^\prime$를 대입하면 된다. 원래의 공식에서 대기압 $P_0$는 유체의 위에서 누르는 압력을 의미했다. 즉. 유체 위에 물체가 올려져 있다면 대기압에 물체로 인한 압력까지 더하면 유체 위에서 누르는 압력을 얻을 수 있다. 물체를 생각</description>
    </item>
    
    <item>
      <title>깊이에 따른 유체의 압력을 구하는 공식</title>
      <link>https://freshrimpsushi.github.io/posts/fluid-pressure-to-depth/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fluid-pressure-to-depth/</guid>
      <description>유체의 표면으로부터 수직 거리 $h$만큼 아래인 곳의 압력, 쉽게 말해서 깊이가 $h$인 곳의 유체의 압력은 다음과 같다. $$ P_h=P_0+\rho g h $$ 이 때, $P_0$는 대기압, $\rho$는 물체의 밀도, $g$는 중력 가속도이다.유도 깊이가 $h$인 곳에 어떤 물체가 평형 상태로 잠겨있다고 하자. 이 물체의 각 면에서 받는 압력을 통해 깊이에 따른 유체의 압력을</description>
    </item>
    
    <item>
      <title>사건의 독립과 조건부 확률</title>
      <link>https://freshrimpsushi.github.io/posts/independent-conditional-probability-of-event/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independent-conditional-probability-of-event/</guid>
      <description>확률 공간 $(\Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.1. $P(B)&amp;gt;0$ 에 대해 $\displaystyle P (A | B) = {{P(A \cap B)} \over {P(B)}}$ 를 $B$ 에 대한 $A$ 의 조건부 확률 이라고 한다.2. 만약 $P(A | B) = P(A)$, 즉 $P( A \cap B) = P(A) \cdot P(B)$ 면 $A, B$ 가 서로 독립 이라고 한다. * 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다.확률 공간이 잘 정의된만큼 조건부 확률이나 사건의 독립은 고등학교 수준의 정의를</description>
    </item>
    
    <item>
      <title>컴팩트 하우스도르프 공간은 정규 공간임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/514/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/514/</guid>
      <description>[1] 컴팩트 공간의 닫힌 부분 집합은 컴팩트다.[2] 하우스도르프 공간의 컴팩트 부분 집합은 닫힌 집합이다.[3] 하우스도르프 공간 $X$ 의 두 컴팩트 부분 집합 $A,B \subset X$ 가 $A \cap B = \emptyset$ 이면 $A \subset U$, $B \subset V$, 그리고 $U \cap V = \emptyset$ 을 만족하는 열린 부분 집합 $U, V \subset X$ 가 존재한다.[4] 컴팩트 하우스도르프 공간은 정규 공간이다.정리 [1] 과 정리 [2] 에서 하우스도르프</description>
    </item>
    
    <item>
      <title>론스키안의 정의와 독립종속 판별</title>
      <link>https://freshrimpsushi.github.io/posts/501/</link>
      <pubDate>Sat, 31 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/501/</guid>
      <description>선형대수학에서 벡터의 정의를 생각해보면 미분 가능한 함수 역시 벡터공간을 만드는 벡터이다. 적어도 $(n-1)$번 미분 가능한 함수 $n$개가 있을 때 이 함수들의 론스키안을 아래와 같이 정의한다.$(f_1 (x),\ f_2 (x),\ \cdots ,\ f_n (x) )$의 론스키안 $W(x)$는 $$ W(x) \ \ \mathrm{or}\ \ W(f_1,\ f_2,\ \cdots,\ f_n) := \begin{vmatrix} f_1 &amp;amp; f_2 &amp;amp; \cdots &amp;amp; f_n \\ f_1’ &amp;amp; f_2’ &amp;amp; \cdots &amp;amp; f_n’ \\ \vdots</description>
    </item>
    
    <item>
      <title>분리 가능한 1계 미분방정식</title>
      <link>https://freshrimpsushi.github.io/posts/separable-first-order-differential-equation/</link>
      <pubDate>Sat, 31 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separable-first-order-differential-equation/</guid>
      <description>1계 미분 방정식이 다음과 아래의 조건을 만족할 때 분리가능 하다고 한다. $$ f(x)+g(y)\dfrac{dy}{dx}=0 \\ \mathrm{or} \ f(x)dx-=g(y)dy $$ 여러 가지 모양으로 표현할 수 있지만 중요한 점은 양변으로 각 변수가 분리돼야 한다는 것이다. 이렇게 두 변수를 분리해서 해를 구하는 방법을 변수분리법이라고 한다. 주어진 미분 방정식이 분리가능하다면 해를 쉽게 구할 수 있다. 반면에 변수분리가 되지 않으면 여러 가지</description>
    </item>
    
    <item>
      <title>보렐 집합</title>
      <link>https://freshrimpsushi.github.io/posts/borel-set/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/borel-set/</guid>
      <description>일반적인 보렐 집합$\mathcal{F}$ 를 $\mathbb{R}$ 의 σ-필드라고 하자. $\displaystyle \mathcal{B} : = \bigcap \left\{ \mathcal{F} \ | \ \mathcal{I} \subset \mathcal{F} \right\} $ 을 모든 구간의 집합 $\mathcal{I}$ 에 의해 생성되었다고 하고 $B \in \mathcal{B}$ 을 보렐 집합 이라고 하고, $\mathcal{B}$ 를 보렐 시그마 필드 라고 부른다. 이에 대해 다음이 성립한다.[1] σ-필드끼리의 교집합은 σ-필드고, 따라서 $\mathcal{B}$ 역시 σ-필드다.[2] $\mathcal{B}$ 는 모든 구간</description>
    </item>
    
    <item>
      <title>르벡 측도</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-measure/</link>
      <pubDate>Thu, 29 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-measure/</guid>
      <description>측도의 일반화$E \in \mathcal{M}$ 에 대해 함수 $m : \mathcal{M} \to [0,\infty]$ 을 $m(E) := m^{ * } (E)$ 과 같이 정의하자. $m$ 을 (르벡) 측도 라고 한다. 측도는 아래의 성질들을 가진다.[1] $A, B \in \mathcal{M}$, $A \subset B \implies m(A) \le m(B)$[2] $A, B \in \mathcal{M}$, $A \subset B$, $m(A) &amp;lt; \infty \implies m(B \setminus A) = m(B) - m(A)$[3] $t \in \mathbb{R} \implies m(E) = m(E + t)$[4] $A \in \mathcal{M}$, $m(A \triangle B) = 0 \implies B \in \mathcal{M}$, $m(A) = m(B)$[5] 모든 $\varepsilon &amp;gt; 0, A \subset \mathbb{R}$ 에 대해 $A \subset O$, $m(O) \le m^{ * }(A) + \varepsilon$ 을 만족하는 열린 $O$ 가 존재</description>
    </item>
    
    <item>
      <title>중국인의 나머지 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-chinese-remainder-theorem/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-chinese-remainder-theorem/</guid>
      <description>$\gcd(n,m) = 1 $ 면 $\begin{cases} x \equiv b \pmod{n} \\ x \equiv c \pmod{m} \end{cases}$ 는 $1 \le x \le nm$ 에서 단 하나의 해를 갖는다.중국에서 서기 3세기에서 5세기에 쓰여졌다고 전해지는 한 수학서에는 이런 문제가 있었다고 한다.어떤 수를 셋 씩 짝 지으면 둘이 남고,다섯 씩 짝 지으면 셋이 남고,일곱 씩 짝 지으면 둘이 남는다.이 수는 무엇인가? - 손자산경 하권, 연습문제 26번이를 현대적인 수학의 표현</description>
    </item>
    
    <item>
      <title>오일러의 토션트 합 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-eulers-totient-summation-formula/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-eulers-totient-summation-formula/</guid>
      <description>$n$ 의 약수를 $d_{1}, d_{2} , \cdots , d_{r}$ 이라고 하면 $\displaystyle n = \sum_{ i = 1 }^{r} \phi(d_{i}) = \phi(d_{1}) + \phi(d_{2}) + \cdots + \phi(d_{r})$토션트 함수는 정의할 때부터 다소 부자연스러운 개념이라고 느낄 수 있다. 하지만 토션트 정리도 그렇고 이런 공식도 있는 걸 보면 수학의 진리 어딘가에 분명히 필요한 함수임을 인정할수밖에 없다.예를 들어 $15$ 를 보면 $15$ 는 약수 $1,3,5,15$ 를 가진다. 실제로 계산해보</description>
    </item>
    
    <item>
      <title>오일러의 토션트 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-totient-theorem/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-totient-theorem/</guid>
      <description>$$ \gcd(a,m) = 1 \implies a^{ \phi (m) } \equiv 1 \pmod{m} $$ 보자마자 페르마의 소정리를 일반화한 정리임을 알 수 있고, 실제로 증명법도 사실 상 거의 똑같다. 증명 토션트 함수의 정의에 의해, $1 \le b_{i} \le m$ 중 $\gcd( b_{i} , m) =1 $ 을 만족하는 $b_{i}$ 는 정확히 $\phi (m)$ 개 존재한다. 이들의 집합을 $$ B:= \left\{ b_{1}, b_{2}, \cdots , b_{\phi (m)} \right\} $$ 라고 하자. 그러면 $\gcd(a,m) = 1$ 이므로 $$ aB = \left\{ ab_{1}, ab_{2}, \cdots , ab_{\phi (m)} \right\} $$ 와 정확히 같은 집합이</description>
    </item>
    
    <item>
      <title>시그마 대수와 가측 공간</title>
      <link>https://freshrimpsushi.github.io/posts/sigma-algebra-and-measurable-space/</link>
      <pubDate>Sun, 25 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sigma-algebra-and-measurable-space/</guid>
      <description>집합 $X \ne \emptyset$ 에 대해 아래의 조건들을 만족하는 $\mathcal{E} \subset \mathscr{P} (X)$ 를 $X$ 상의 시그마 대수 혹은 시그마 필드 라고 하고 어떤 공간 $X$ 에 대해 시그마 필드 $\mathcal{E}$ 가 주어진다면 $(X , \mathcal{E})$ 를 가측 공간 이라고 한다.(i) $\emptyset \in \mathcal{E}$(ii) $E \in \mathcal{E} \implies E^{c} \in \mathcal{E} $(iii) $\displaystyle \left\{ E_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{E} \implies \bigcup_{n=1}^{\infty} E_{n} \in \mathcal{E}$**(iv)** $\displaystyle \left\{ E_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{E} \implies \bigcap_{n=1}^{\infty} E_{n} \in \mathcal{E}$어떤 공간 $X$ 에 대해 시그마 필드 $\mathcal{E}$ 가 주어진다면 $(X ,</description>
    </item>
    
    <item>
      <title>위상공간에서 컴팩트 프리컴팩트란</title>
      <link>https://freshrimpsushi.github.io/posts/compactness-precompact-in-topology-space/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compactness-precompact-in-topology-space/</guid>
      <description>거리공간에서 컴팩트**컴팩트 위상공간 $X$ 에 대해 $A \subset X$ 라고 하자.1. $X$ 의 열린 집합으로 이루어진 집합 $\mathscr{O}$ 가 $A \subset \mathscr{O}$ 를 만족하면 $\mathscr{O}$ 를 $A$ 의 열린 커버Open Cove r라고 한다.2. $A \subset \mathscr{O}&#39; \subset \mathscr{O}$ 를 만족하는 $\mathscr{O} &amp;lsquo;$ 를 $\mathscr{O}$ 의 부분 커버Subcover 라고 한다.3. $X$ 의 모든 열린 커버가 유한 부분 커버를 가지면 $X$ 를 컴팩트 하다고 한다. 다시 말해, 모든 열린</description>
    </item>
    
    <item>
      <title>위상수학자의 사인 곡선과 빗 공간</title>
      <link>https://freshrimpsushi.github.io/posts/topologists-sine-curve-and-comb-space/</link>
      <pubDate>Fri, 23 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/topologists-sine-curve-and-comb-space/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20180323_143814.png&amp;rdquo; height=&amp;ldquo;259&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99F2FA345AB492E430&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;610&amp;rdquo;/&amp;gt;(1) $\displaystyle S : = \left\{ (0,y) \ | \ y \in [-1,1] \right\} \cup \left\{ \left. \left( x, \sin {{1} \over {x}} \right) \ \right| \ x \in (0,1] \right\}$ 를 위상수학자의 사인 곡선Topologist&amp;rsquo;s Sine Curve 이라고 한다.(2) $\displaystyle C := \left\{ (0,y) \ | \ y \in [0,1] \right\} \cup \left\{ (x,0) \ | \ x \in [0,1] \right\} \cup \left\{ \left( {{1} \over {n}} , y \right) \ | \ y \in [0,1] , n \in \mathbb{N} \right\} $ 를 위상수학자의 빗 공간Comb Space 이라고 한다.수식으로 나타낸 표</description>
    </item>
    
    <item>
      <title>e^x^2 꼴의 부정적분 Indefinite Integral of e^x^</title>
      <link>https://freshrimpsushi.github.io/posts/2-form/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/2-form/</guid>
      <description>$$ \displaystyle \int e^{x^2}dx = \sum\limits_{n=0}^\infty \dfrac{x^{2n+1}}{(2n+1)n!}+C $$ $e^{-x^2}$꼴과 마찬가지로 일반적인 방법으로 적분하기는 어렵다. $\mathrm{error \ function(imaginary\ error\ function,\ erfi)}$이라는 함수를 정의해서 적분하는 방법도 있지만 이 글에서는 테일러 급수 전개를 이용한 풀이를 소개한다. 증명 테일러 급수 전개 방법에 의해 $$ \displaystyle e^x=\sum\limits_{n=0}^\infty \dfrac{x^n}{n!}=1+x+\dfrac{x^2}{2!}+\cdots +\dfrac{x^n}{n!}+\cdots $$ $x$ 대신에 $x^2$을 대입하면 $$ \displaystyle e^{x^2}=\sum\limits_{n=0}^\infty \dfrac{x^{2n}}{n!}=1+x^2+\dfrac{x^4}{2!}+\cdots +\dfrac{x^{2n}}{n!}+\cdots $$ 양변을 부정적분 하면 $$ \begin{eqnarray*} \int</description>
    </item>
    
    <item>
      <title>국소연결과 국소경로연결</title>
      <link>https://freshrimpsushi.github.io/posts/locally-connected-and-locally-path-connected/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/locally-connected-and-locally-path-connected/</guid>
      <description>$X$ 를 위상공간이라고 하자.1. $x \in X$ 를 포함하는 모든 $U$ 에 대해 $x \in C \subset U$ 를 만족하는 열린 연결 집합 $C$ 가 존재하면 $X$ 가 $x$ 에서 국소연결 이라고 한다. 모든 $x \in X$ 에 대해 국소연결이면 $X$ 를 국소연결 공간 이라고 한다.2. $x \in X$ 를 포함하는 모든 $U$ 에 대해 $x \in P \subset U$ 를 만족하는 열린 경로연결 집합 $P$ 가 존재하면 $X$ 가 $x$ 에서 국소경로연결 이라고 한다.</description>
    </item>
    
    <item>
      <title>경로연결 성분</title>
      <link>https://freshrimpsushi.github.io/posts/path-connected-component/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/path-connected-component/</guid>
      <description>위상 공간 $X$ 의 경로연결 부분공간들 중 자기 자신만을 연결 초집합Superset으로 갖는 경로연결 집합을 $X$ 의 경로연결 성분Path Connected Component 이라고 한다. 특히 $x \in X$ 를 포함하는 경로연결 성분을 $P_{x}$ 라 쓴다.**(1)** $x \in X$ 은 단 하나의 $P_{x}$ 에만 속한다.**(2)** $a,b \in X$ 에 대해 $P_{a} = P_{b}$ 이거나 $P_{a} \cap P_{b} = \emptyset$ 둘 중 하나다.**(3)** 모든 경</description>
    </item>
    
    <item>
      <title>sin^2&#43;cos^2=1임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/482/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/482/</guid>
      <description>$\sin^2\theta+\cos^2\theta=1$사인제곱과 코사인제곱의 합이 1임은 삼각함수가 맨 처음 나올 때부터 알던 사실이다. 간단한 만큼이나 굉장히 중요한 식이다. 어떻게 증명하는지 알아보자. 증명1(코사인의 덧셈 공식) 코사인의 덧셈 정리를 이용하면 아주 간단하게 알 수 있다. $$ \cos(\theta_1-\theta_2)=\cos\theta_1\cos\theta_2 + \sin\theta_1\sin\theta_2 $$ 여기에 $\theta_1$, $\theta_2$ 대신 $\thet</description>
    </item>
    
    <item>
      <title>미분 방정식의 분류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-differential-equation/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-differential-equation/</guid>
      <description>미분방정식을 분류하는 기준은 여러 가지다. 크게 상미분 방정식인지 편미분 방정식인지로 구분한다. 그 다음 계수와 차수, 선형/비선형으로 더 세세하게 분류할 수 있다. 미분방정식을 분류하는 이유는 당연히 미분방정식을 풀기 위해서이다. 미분방정식의 분류에 따라 풀이 방법도 다르다. 1. 상미분 방정식과 편미분 방정식 상미분 방정식은 한 개 또는 그 이상</description>
    </item>
    
    <item>
      <title>삼각함수의 덧셈 정리로 부터 배각 공식 반각 공식 3배각 공식 유도하기</title>
      <link>https://freshrimpsushi.github.io/posts/481/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/481/</guid>
      <description>**삼각 함수의 덧셈 공식(덧셈 정리) $$ \begin{align*} \sin ( \theta_1 \pm \theta_2) &amp;amp;= \sin \theta_1 \cos \theta_2 \pm \sin \theta_2 \cos \theta_2$ \\ \cos ( \theta_1 \pm \theta_2) &amp;amp;= \cos \theta_1 \cos\theta_2 \mp \sin\theta_1 \sin\theta_2 \\ \tan ( \theta_1 \pm \theta_2) &amp;amp;= \dfrac{\tan\theta_1 \pm \tan\theta_2}{1 \mp \tan\theta_1\tan\theta_2} \end{align*} $$ 내가 고등학생이었을 때는 배각, 반각 공식에 합차 공식까지 교육과정에 있었는데 요즘은 아닌 걸로 알고 있다. 덧셈 공식은 물론이고 배각, 반각 공식 또한 유용하게 쓰이니 잘 알아두자.덧셈 공식은 다른 삼각함수 공</description>
    </item>
    
    <item>
      <title>접착 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pasting-lemma/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pasting-lemma/</guid>
      <description>위상공간 $X,Y$ 에 대해 두 닫힌 집합 $A,B \subset X$ 이 $A \cup B = X$ 를 만족하고 두 연속함수 $f : A \to Y$ 와 $g : B \to Y$ 가 모든 $x \in A \cap B$ 에 대해 $f(x) = g(x)$ 라고 하자. 그러면 $h : = \begin{cases} f(x), &amp;amp; x \in A \\ g(x), &amp;amp; x \in B \end{cases}$ 는 연속함수다.풀 보조정리Gluing Lemma 라고도 불리는 이 보조정리는 문장을 읽는 것만으로도 이해할 수 있을 정도로 당연하다.굳이 보조정리라는 이름이 남고 증</description>
    </item>
    
    <item>
      <title>외측도</title>
      <link>https://freshrimpsushi.github.io/posts/outer-measure/</link>
      <pubDate>Mon, 19 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/outer-measure/</guid>
      <description>$E \subset \mathbb{R}$, $\left\{ I_{n} \in \mathcal{I} \ | \ n \in \mathbb{N} \right\} $, $\left\{ E_{n} \in \mathscr{P} ( \mathbb{R} ) \ | \ n \in \mathbb{N} \right\}$ 에 대해 $$ \displaystyle Z_{E} : = \left\{ \left. \sum_{n=1}^{\infty} l (I_{n}) \ \right| \ E \subset \bigcup_{n=1}^{\infty} I_{n} \right\} $$ 라고 할 때 함수 $m^{ * } (E) : = \inf Z_{E} $ 를 **외측도** 라고 한다. 외측도는 아래의 성질들을 가진다.**(i) 길이의 일반화** : $I \in \mathcal{I} \implies m^{ * } (I) = l(I)$**(ii) 정부호** : $N \in \mathcal{N} \iff m^{ * }(N) = 0$**(iii) 단조성** : $E_{1} \subset E_{2} \implies m^{ * }(E_{1}) \le m^{ * }(E_{2})$**(iv)</description>
    </item>
    
    <item>
      <title>위상수학에서 경로연결성이란</title>
      <link>https://freshrimpsushi.github.io/posts/path-connectedness/</link>
      <pubDate>Sun, 18 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/path-connectedness/</guid>
      <description>$X$ 를 위상 공간이라고 하고 $C \subset \mathbb{R}^{n}$ 이라고 하자.1. 연속함수 $p : [0,1] \to X$ 를 시점Initial Point $p(0)$ 에서 종점Terminal Point $p(1)$ 까지의 경로Path 라고 한다. $\overline{p}(t) = p(1-t) $ 를 $p$ 의 역경로Reverse Path 라고 한다.2. 모든 $a,b \in X$ 에 대해 $p(0) = a$ 와 $p(1) = b$ 를 만족하는 경로 $p$ 가 존재하면 $X$ 를 경로연결Path Connected 공간이라고 한다.3. 모든 $a,b \in C$</description>
    </item>
    
    <item>
      <title>미분 방정식의 정의와 예</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-example-of-differential-equation/</link>
      <pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-example-of-differential-equation/</guid>
      <description>**** **** **** 미분방정식이란? 한 개 또는 그 이상의 종속변수를 한 개 또는 그 이상의 독립변수에 대해 미분한 도함수들을 포함하는 방정식을 말한다. 예) $$ \dfrac{dy}{dx}=y $$ $$ \dfrac{d^2y}{dx^2} = y $$ 대부분의 물리적인 상황은 1계$(\bf \text{first order})$ 혹은 2계$(\bf \text{second order})$ 미분 방정식으로 표현할 수 있다. 예) 1. **낙하하는 물체 ** $(\mathrm{Falling \ body}) $$ $F=ma=mg $$ $$ v=\dfrac{dy}{dt} $$ $$ a=\dfrac{dv}{dt}=\dfrac{d}{dt} \left( \dfrac{dy}{dx} \right)=\dfrac{d^2y}{dt^2} $$ $$ \therefore \dfrac{d^2y}{dt^2}=g $$ **2. 스프링 질</description>
    </item>
    
    <item>
      <title>위상수학에서 고정점 성질이란</title>
      <link>https://freshrimpsushi.github.io/posts/fixed-point-property/</link>
      <pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fixed-point-property/</guid>
      <description>함수 $ f : X \to X$ 에 대해 $f(x_{0}) = x_{0}$ 를 만족하는 $x_{0}$ 을 $f$ 의 **고정점**Fixed Point 이라고 한다. 모든 연속함수 $f$ 가 고정점을 가지면 $X$ 가 **고정점 성질**Fixed Point Property 을 가진다고 한다. 고정점 성질은 위상적 성질이다.주로 완비 공간과 관계가 깊다.적어도 $\mathbb{R}$ 에서는 중간값 정리를 이용하면 $f : [a,b] \to [a,b]$ 에 대해 $f(c) = c$ 를 만족하는 $c$ 가 항상 존재함</description>
    </item>
    
    <item>
      <title>중간값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-intermediate-value-theorem/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-intermediate-value-theorem/</guid>
      <description>$f : [a,b] \to \mathbb{R}$ 가 연속이면 $f(a)$ 와 $f(b)$ 사이의 $y_{0}$ 에 대해 $y_{0} = f(c)$ 를 만족하는 $c \in (a,b)$ 가 존재한다.정말 중요한 정리지만 고등학교엔 증명 없이 받아들이고 해석학 때는 너무나 어렵게 증명하는 정리다. 상위의 이론을 쓰지 않는 증명도 나름 의미는 있지만 중간값 정리의 위상적 증명은 너무나 쉬워서 그 유혹을 떨치기 쉽지 않다.한편 대우 명제를 이용하면 $\mathbb{R}^2$ 상에서 특정한 조건</description>
    </item>
    
    <item>
      <title>영집합</title>
      <link>https://freshrimpsushi.github.io/posts/null-set/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/null-set/</guid>
      <description>정의 실수의 구간들의 집합 $\mathcal{I}$ 에 대해 함수 $l : \mathcal{I} \to [ 0 , \infty )$ 을 $l( I ) := \sup{I} - \inf{I}$ 와 같이 정의하고 길이Length 라고 하자. 임의의 $\varepsilon &amp;gt; 0$ 에 대해 $\displaystyle A \subset \bigcup_{n = 1}^{\infty} I_{n}$ 과 $\displaystyle \sum_{n=1}^{\infty} l (I_{n}) &amp;lt; \varepsilon$ 을 만족하는 구간의 수열 $\left\{ I_{n} \ | \ n \in \mathbb{N} \right\}$ 이 존재하면 $A \subset \mathbb{R}$ 를 **영집합** 이라고 한다. 정리 [1] 공집합은 영집합이다. [2] 홑원소 집합은 영집합이다. [3] 가산 집합은</description>
    </item>
    
    <item>
      <title>연결 성분과 완전 분리 공간</title>
      <link>https://freshrimpsushi.github.io/posts/component-and-totally-disconnected-space/</link>
      <pubDate>Wed, 14 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/component-and-totally-disconnected-space/</guid>
      <description>위상 공간 $X$ 의 연결 부분공간들 중 자기 자신만을 연결 초집합Superset으로 갖는 연결 집합을 $X$ 의 연결 성분Connected Component 이라고 한다. 특히 $x \in X$ 를 포함하는 연결 성분을 $C_{x}$ 라 쓴다. $X$ 의 모든 연결 성분이 홑원소 집합이면 $X$ 를 **완전 분리 공간**Totally Disconnected Space 이라고 한다.정의만 보면 말이 빙빙 도는 것처럼 보이지만 의외로 별 것</description>
    </item>
    
    <item>
      <title>연결 공간의 부분 공간의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-subspace-of-connected-space/</link>
      <pubDate>Tue, 13 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-subspace-of-connected-space/</guid>
      <description>위상공간 $X$ 에 대해 $Y \subset X$ 라고 하자.[1] $Y$ 가 연결 공간이면 $\overline{Y}$ 도 연결 공간이다.[2] $Y$ 가 비연결 공간인 것과 $U \cap Y \ne \emptyset$, $V \cap Y \ne \emptyset$, $U \cap V \cap Y = \emptyset$, 그리고 $Y \subset U \cup V$ 를 만족하는 $X$ 의 열린 집합 $U$ 와 $V$ 가 존재하는 것은 서로 동치다.[3] $X$ 의 연결 부분공간의 집합 $\left\{ A_{\alpha} \ | \ \alpha \in \forall \right\}$ 에 대해 $\displaystyle \bigcap_{\alpha \in \forall} A_{\alpha} \ne \emptyset$ 이면 $\displaystyle \bigcup_{\alpha \in \forall} A_{\alpha}$ 는 연결 공간이다.*</description>
    </item>
    
    <item>
      <title>T1-공간인 것과 모든 유한부분집합이 닫혀있는 것은 동치임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/455/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/455/</guid>
      <description>$X$ 가 $T_{1}$-공간인 것과 필요충분조건은 $X$ 의 모든 홑원소집합 $\left\{ x \right\}$ 가 $X$ 에서 닫힌 집합인 것이다.닫힌 집합의 합집합은 여전히 닫힌 집합이므로, 모든 유한부분집합은 닫혀있는 것과 동치라고 해도 좋다. 증명 $(\Rightarrow) $$ T_{1}$-공간 $X$ 에 대해 $x \in X$, $x&#39; \in X \setminus \left\{ x \right\} $ 라고 하면 $x \ne x&#39;$ 일 것이다.$X$ 는 $T_{1}$-공간이므로, $x&#39;</description>
    </item>
    
    <item>
      <title>케일리의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cayleys-theorem/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cayleys-theorem/</guid>
      <description>모든 군은 대칭군의 어떤 부분군과 동형이다.짧고도 굵직한 이 정리는 대칭군을 연구하면 모든 군을 파악할 수 있다는 메세지를 담고 있다.언뜻 지루한 증명처럼 보이지만 읽어보면 그 테크닉이 상당히 흥미로움을 알 수 있다. 증명 우선 군 $G$ 와 $G&#39;$ 에 대해 준동형사상 $f : G \to G&#39;$ 가 단사면 $ G \simeq f (G)$ 임을 보이자.$f(G) = f(G)$ 이므로 $f : G \to f(G)$ 는 전사고, $f(G)$ 가</description>
    </item>
    
    <item>
      <title>베타함수의 삼각함수 표현</title>
      <link>https://freshrimpsushi.github.io/posts/trigonometric-function-representation-of-beta-function/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trigonometric-function-representation-of-beta-function/</guid>
      <description>베타함수 $$ \displaystyle B(p,q) = 2 \int_{0}^{{\pi} \over {2}} \left( \sin \theta \right) ^{2p-1} \left( \cos \theta \right) ^{2q-1} d \theta $$ 그것이 어떤 종류의 수학이라고 하더라도 어떤 함수를 다른 방식으로 표현할 수 있다는 건 좋은 일이다. 증명 $\displaystyle B(p,q) = \int_{0}^{1} t^{p-1} (1-t)^{q-1} dt$ 에서 $t = \sin^2 \theta$ 로 치환하면 $$ \displaystyle B(p,q) = \int_{0}^{{\pi} \over {2}} \left( \sin^2 \theta \right)^{p-1} \left( 1 - \sin^2 \theta \right) ^{q-1} 2 \sin \theta \cos \theta d \theta $$ $1 - \sin^2 \theta = \cos ^2 \theta$ 이므로 $$ \displaystyle B(p,q) = 2 \int_{0}^{{\pi} \over {2}} \left( \sin \theta \right)^{2p-1} \left( \cos \theta \right) ^{2q-1} d \theta $$ ■ 특히 $\sin \theta =</description>
    </item>
    
    <item>
      <title>위상수학에서의 분리성질</title>
      <link>https://freshrimpsushi.github.io/posts/separation-properties/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separation-properties/</guid>
      <description>$X$ 를 위상공간이라고 하자. $a,b \in X $ 에 대해 $a \ne b$ 고 $U, V \subset X$ 는 $X$ 에서 열린 집합이다.**0. $T_{0}$** : 임의의 $a$ 와 $b$ 중 하나만 포함하는 $U$ 가 존재하면, $X$ 를 **콜모고로프**Kolmogorov 공간이라고 한다.**1. $T_{1}$** : 임의의 $a,b$ 에 대해 $a \in U$, $b \notin U$, $a \notin V$, $b \in V$ 를 만족하는 $U,V$ 가 존재하면, $X$ 를 **프레셰**Frechet 공간이</description>
    </item>
    
    <item>
      <title>클라인 사원군</title>
      <link>https://freshrimpsushi.github.io/posts/klein-4-group/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/klein-4-group/</guid>
      <description>$V = \left\{ e, a, b, c \right\} $ 과 이항연산 $\cdot$ 에 대해, $\left&amp;lt; V , \ \cdot \ \right&amp;gt; $ 을 클라인 사원군 이라고 한다.보다시피 원소의 갯수가 항등원을 포함해서도 $4$ 개밖에 안 되기 때문에 굉장히 풍부한 성질을 갖지는 않는다. 하지만 계산이 별로 없고 독자적인 연산을 가진만큼 군의 개념을 체득하기엔 상당히 좋은 예시가 된다. $x \cdot x = e $ 즉, 모든 원소가 스스로를 역원으로 갖는</description>
    </item>
    
    <item>
      <title>토션트 함수의 곱셈적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-totient-functions-multiplicativity/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-totient-functions-multiplicativity/</guid>
      <description>$\gcd (n , m) =1 \implies \phi ( n m ) = \phi (n) \phi (m)$토션트 함수에서 유도되는 여러가지 중요한 결과를 얻기 위해선 반드시 필요한 성질이다.$\gcd (n , m) =1$ 라는 조건이 있으니 만능이라고 착각하진 말자. 증명 $nm = p_{1}^{{k}_{1}} p_{2}^{{k}_{2}} \cdots p_{r}^{{k}_{r}}$ 그리고 편의상 $p_{1} &amp;lt; p_{2} &amp;lt; \cdots &amp;lt; p_{r}$ 라고 하자.가정에서 $\gcd (n , m ) = 1$ 이므로 $p_{i} \mid n$ 이면서 $p_{i} \mid m$ 둘 중 하나여야만한다.$p_{i}</description>
    </item>
    
    <item>
      <title>이항계수의 일반화 베타함수</title>
      <link>https://freshrimpsushi.github.io/posts/beta-function/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/beta-function/</guid>
      <description>**** 오일러 적분**베타함수로 표현되는 이항계수 $0 \le k\le n$을 만족하는 두 자연수 $k,n$에 대해서 아래의 식이 성립한다. $$ \binom{n}{k}={}{n}C{k}=C(n,k)=\frac{1}{(n+1)B(n-k+1,k+1)} $$ 두 자연수 $m,n$에 대해서 아래의 식이 성립한다. $$ B(m,n)=\left[ \frac{mn}{m+n} \begin{pmatrix} m+n \\ n \end{pmatrix}\right]^{-1} $$ $B(p,q):=\displaystyle \int_{0}^{1}t^{p-1}(1-t)^{q-1}dt$로 정의되는 베타함수는 위와 같이 이항계수의 일반화로 볼 수도 있</description>
    </item>
    
    <item>
      <title>일양 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-uniform-distribution/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-uniform-distribution/</guid>
      <description>공식 $X \sim U[a,b]$ 면 $$ E(X) = {{ a+b } \over { 2 }} \\ \text{Var}(X) = {{ (b-a)^{2} } \over { 12 }} $$ Strategy : 일양 분포의 정의에서 직접 연역한다. 일양 분포의 정의 $[a,b] \subset \mathbb{R}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포]] $U[a,b]$ 를 일양 분포 라 한다. $$ f(x) = {{ 1 } \over { b - a }} \qquad , x \in [a,b] $$ 증명(평균) $$ \begin{eqnarray*} E(X) &amp;amp;=&amp;amp; \int_{a}^{b} x {{ 1 } \over { b-a }} dx \\ &amp;amp;=&amp;amp; {{ 1 } \over { b-a }} \left[ {{ x^{2} } \over { 2 }} \right]_{a}^{b} \\ &amp;amp;=&amp;amp; {{</description>
    </item>
    
    <item>
      <title>슈발츠-크리스토플 사상</title>
      <link>https://freshrimpsushi.github.io/posts/schwarz-christoffel-mapping/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schwarz-christoffel-mapping/</guid>
      <description>복소평면 상에서 $n$ 개의 각을 가진 꺾인 선을 $\mathscr{P}$ 라고 하고 그 각들을 $w_{r}$, 그 내각의 크기를 $\psi_{r}$ 라 하자. 그러면 $K, C, z_{0} \in \mathbb{C}$ 와 $x_{r} \in \mathbb{R}$ 에 대해 $f(x_{r}) = w_{r}$ 를 만족시키는 등각사상 $\displaystyle w = f(z) = K \int_{z_{0}}^{z} \prod_{r = 1}^{n} ( \zeta - x_{r})^{ \psi_{r} / \pi - 1 } d \zeta + C $ 은 실수축을 꺾인 선 $\mathscr{P}$ 로 대응시킨다. 만약 $z_{0} = 0$ 이라고 하면 단위원 $|z|=1$ 상의 $z_{1} , \cdots , z_{n}$ 에 대한 사상으로 나타내어진다.증명은 너무 길</description>
    </item>
    
    <item>
      <title>일양 분포</title>
      <link>https://freshrimpsushi.github.io/posts/uniform-distribution/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniform-distribution/</guid>
      <description>정의 $[a,b] \subset \mathbb{R}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $U(a,b)$ 를 일양 분포 라 한다. $$ f(x) = {{ 1 } \over { b - a }} \qquad , x \in [a,b] $$ 흔히 일양 분포는 균등 분포 로 불리기도 한다. 위의 정의는 연속인 경우고, 이산 일양 분포 역시 모든 케이스에 대해 같은 확률을 줌으로써 정의할 수 있다. 일양 분포가 중요한 이유는 따로 있다기보단 우리가 생각할 수 있는 가장 단</description>
    </item>
    
    <item>
      <title>쥬코프스키 변환</title>
      <link>https://freshrimpsushi.github.io/posts/joukowski-transform/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/joukowski-transform/</guid>
      <description>등각사상 $\displaystyle w = f(z) = a z + {{b} \over {z}} $ 라고 하자. $a=b$ 면 $f$ 를 쥬코프스키 변환Joukowski Transform 이라고 하고, 중심이 $0$ 이 아닌 원을 비행기 날개의 단면 모양으로 대응시킨다.(1) $f$ 는 중심이 $0$ 인 원을 타원으로 대응시킨다.(2) $f$ 는 $0$ 에서 시작되는 반직선을 쌍곡선으로 대응시킨다.쥬코프스키Zhukovsky 는 항공역학 등의 분야에 업적</description>
    </item>
    
    <item>
      <title>등각사상으로써의 삼각함수</title>
      <link>https://freshrimpsushi.github.io/posts/447/</link>
      <pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/447/</guid>
      <description>등각사상 $w = f(z) = \sin z$은 수직선 $y=k$를 타원으로, 수평선 $x = k $를 쌍곡선으로 대응시킨다. 증명 $z = x + iy$ 그리고 $w = u + i v$ 라고 하면 $u = \sin x \cosh y$ 이고 $v = \cos x \sinh y$ 이다.$y = k $ 라고 하면 $\displaystyle {{ u^2 } \over { \cosh^{2} k}} = \sin^{2} x $ 이고 $\displaystyle {{ v^2 } \over { \sinh^{2} k}} = \cos^{2} x $양변끼리 더하면 $\displaystyle {{ u^2 } \over { \cosh^{2} k}} + {{ v^2 } \over { \sinh^{2} k}} = 1 $ 즉 타원의 방정식</description>
    </item>
    
    <item>
      <title>등각사상으로써의 지수함수</title>
      <link>https://freshrimpsushi.github.io/posts/446/</link>
      <pubDate>Wed, 21 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/446/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20180212_183304.png&amp;rdquo; height=&amp;ldquo;322&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99493B3E5A815FA811&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;618&amp;rdquo;/&amp;gt;&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20180212_183315.png&amp;rdquo; height=&amp;ldquo;323&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/999A353E5A815FA81E&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;611&amp;rdquo;/&amp;gt;&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20180212_183636.png&amp;rdquo; height=&amp;ldquo;206&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99FD0A345A81603113&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;611&amp;rdquo;/&amp;gt;등각사상 $w = f(z) = e^{z} = e^{x} e^{i y}$ 은 직사각형을 부채꼴 혹은 고리로 대응시킨다.$f(z) = e^{z}$ 는 분명 등각사상이지만 단사는 아니므로 역사상을 생각할 땐 여러가지 제한이 필요하다.</description>
    </item>
    
    <item>
      <title>위상수학에서 계승적 성질이란</title>
      <link>https://freshrimpsushi.github.io/posts/hereditary/</link>
      <pubDate>Wed, 21 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hereditary/</guid>
      <description>위상공간 $(X, \mathscr{T})$ 에 대해 $Y \subset X$ 라고 하자. $\mathscr{T}&#39; := \left\{ U \cap Y \ | \ U \in \mathscr{T} \right\} $ 라고 하면 $(Y , \mathscr{T}&#39; )$ 는 $X$ 의 부분공간Subspace 이 되고 $\mathscr{T}&#39;$ 를 $\mathscr{T}$ 에 의한 $Y$ 의 부분위상Subspace Topology 이라 한다.[1] $A \subset Y$ 가 $Y$ 에서 닫힌 부분집합인 필요충분조건은 $A = C \cap Y$ 를 만족하는 닫힌 부분집합 $C \subset X$ 가 존재하는 것이다.[2] $y \in Y$ 에 대해 $N \subset Y$ 가 $y$ 의</description>
    </item>
    
    <item>
      <title>위상적 성질</title>
      <link>https://freshrimpsushi.github.io/posts/topological-property/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/topological-property/</guid>
      <description>위상동형인 두 공간 $X,Y$ 에 대해 $X$ 의 성질 $P$ 를 $Y$ 도 갖고 있으면 $P$ 를 위상적 성질Topological Property 이라고 한다. 위상적 성질의 예시로는 아래와 같은 것들이 있다.(1) 가분성**Separability(2)** 제1가산성First Countability**(3)** 제2가산성Second Countability**(4)** 거리화가능성**Metrizability(5)** 하우스도르</description>
    </item>
    
    <item>
      <title>토션트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/totient-fuction-phi-function/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/totient-fuction-phi-function/</guid>
      <description>해석적 정수론에서의 토션트 함수 $$ \displaystyle \phi( m ) = \left| \left\{ a \ | \ 1 \le a \le m \land \gcd (a,m) = 1 \right\} \right| = m \prod_{p \mid m} \left( 1 - {{1} \over {p}} \right) $$ **토션트**Totient 는 전체를 의미하는 Tot-al의 Tot-과 몫을 의미하는 Quo-tient에서 -tient가 붙어서 생긴 단어로 이해해도 무방하다. 수학, 그것도 정수론 외에는 전혀 쓰이지 않을뿐만 아니라</description>
    </item>
    
    <item>
      <title>추상대수학에서의 여러 사상들 -</title>
      <link>https://freshrimpsushi.github.io/posts/morphisms/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/morphisms/</guid>
      <description>군 $\left&amp;lt; G , * \right&amp;gt; , \left&amp;lt; G&#39; , *&#39; \right&amp;gt; $ 에 대해 $\phi : G \to G&#39;$ 이라고 하자.1. $\forall x ,y \in G $, $\phi (x * y) = \phi (x ) *&#39; \phi ( y) $ 이면 $\phi$ 를 준동형사상Homomorphism 이라고 한다.**2. ** 준동형사상 $\phi$ 가 단사면 $\phi$ 를 단형사상Monomorphism 이라 하고 $G \hookrightarrow G&#39;$ 라 쓴다.3. 준동형사상 $\phi$ 가 전사면 $\phi$ 를 전형사상Epimorphism 이라</description>
    </item>
    
    <item>
      <title>포물선을 반평면으로 대응시키는 등각사상</title>
      <link>https://freshrimpsushi.github.io/posts/437/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/437/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20180209_190640.png&amp;rdquo; height=&amp;ldquo;339&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99B9B7365A7D72C11D&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;648&amp;rdquo;/&amp;gt;등각사상 $\displaystyle w = f(z) = z^{1/2} $ 은 포물선을 반평면으로 대응시킨다.$\mathbb{R}^2$ 에서 배운 것을 생각해보면야 당연하긴하지만 복소평면에서도 성립하는지는 체크가 필요하다.깔끔하게 세로축을 기준으로 가르고 싶다면 $\xi = w - a$ 만 한번 더 취해주면 된다.</description>
    </item>
    
    <item>
      <title>부채꼴을 원으로 대응시키는 등각사상</title>
      <link>https://freshrimpsushi.github.io/posts/436/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/436/</guid>
      <description>등각사상 $\displaystyle w = f(z) = z^{n} $ 은 부채꼴을 반원으로 대응시킨다.부채꼴의 반지름이 무한대라고 생각해보면 $f$ 는 각을 평각으로 보내고 그 내부를 반평면으로 대응시킨다고 할 수 있다.한편 반원 역시 부채꼴이고 반평면 역시 각이므로, $\xi = w^{2}$ 를 한 번 더 취함으로써 완전한 원이나 평면에 대응시킬 수 있다.</description>
    </item>
    
    <item>
      <title>위상공간에서 위상동형이란</title>
      <link>https://freshrimpsushi.github.io/posts/homeomorphic/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homeomorphic/</guid>
      <description>그래프 이론에서의 위상동형두 위상공간 $X,Y$ 에 대해 전단사 $f : X \to Y$ 가 존재해서 $f$ 와 그 역함수 $f^{-1}$ 모두 연속함수면 $f$ 를 위상동형사상Homeomorphism 라 부르고 두 위상공간이 위상동형Homeomorphic 이라 한다.거리공간에서 정의했던 것과 마찬가지로 위상동형의 개념도 간단하게 확장될 수 있다.연속함수를 공부하는 이유 그 자체</description>
    </item>
    
    <item>
      <title>반원을 사분면으로 대응시키는 등각사상</title>
      <link>https://freshrimpsushi.github.io/posts/434/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/434/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20180209_185638.png&amp;rdquo; height=&amp;ldquo;218&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99A52A465A7D706A0E&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;682&amp;rdquo;/&amp;gt;등각사상 $\displaystyle w = f(z) = {{z - a} \over {z + a}} $ 는 반원을 사분면으로 대응시킨다.$\displaystyle w = {{z - a} \over {z + a}} $ 는 별다른 이름은 없지만 매우 중요하고 빈번하게 쓰이는 함수다.특히 $f(a) = 0$, $f(ai) = i$, $f(-a) = \infty$ 임을 직접 계산해서 확인해보도록 하자.</description>
    </item>
    
    <item>
      <title>열린 함수와 닫힌 함수</title>
      <link>https://freshrimpsushi.github.io/posts/open-function-and-closed-function/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/open-function-and-closed-function/</guid>
      <description>위상공간 $X,Y$ 에 대해 $f : X \to Y$ 라고 하자.1. 모든 열린 집합 $O \subset X$ 에 대해, $f (O) $ 가 $Y$ 에서 열린 집합이면 $f$ 를 열린 함수 라고 한다.2. 모든 닫힌 집합 $C \subset X$ 에 대해, $f (C) $ 가 $Y$ 에서 닫힌 집합이면 $f$ 를 닫힌 함수 라고 한다.주의해야할 것은 집합에서의 정의와 마찬가지로 열림과 닫힘이 서로 배타적이지 않다는 것이다.특히 연속함수는 아래의 성질을 가</description>
    </item>
    
    <item>
      <title>윌슨의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-wilsons-theorem/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-wilsons-theorem/</guid>
      <description>2보다 큰 소수 $p$에 대해, $(p-1)! \equiv -1 \pmod{p}$페르마의 소정리만큼은 아니더라도, 윌슨의 정리 역시 여기저기서 유용하게 쓰인다.생긴 모양새부터가 연속되는 수들의 곱을 계산할 때 편리하게 생겼다.$\pmod{p}$ 에서 곱셈에 대한 역원의 존재성, 유일성을 이용한 증명1과 원시근Primitive root 의 성질, 페르마의 소정리를</description>
    </item>
    
    <item>
      <title>복소해석학에서의 역점</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-point/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-point/</guid>
      <description>직선 $ L : 2px + 2qy + c = 0$ 과 원 $\mathscr{C} : |z - A | = r $ 의 점이 아닌 $P : z = x + iy$ 를 생각하자.(1) $\displaystyle {{y - y^{ * }} \over {x - x^{ * }}} = {{q} \over {p}}$ 와 $p(x + x^{ * }) + q(y + i y^{ * }) + c = 0$ 를 만족시키는 $Q : z^{ * } = x^{ * } + i y^{ * }$ 를 $P$ 의 직선 $L$ 에 대한 역점 이라고 정의한다.(2) $\overline{AP} \cdot \overline{AQ} = r^2$ 를 만족하는 $Q : z^{ * } = x^{ * } + i y^{ * }$ 를 $P$ 의 원 $\mathscr{C}$ 에 대</description>
    </item>
    
    <item>
      <title>위상수학에서 연속이란</title>
      <link>https://freshrimpsushi.github.io/posts/432/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/432/</guid>
      <description>위상공간 $(X, \mathscr{T}{X} )$ 와 $(Y, \mathscr{T}{Y} )$ 에 대해, $f: X \to Y$ 라고 하자. $f(a)$ 를 포함하는 모든 $V \in \mathscr{T}{Y}$ 에 대해 $f(U) \subset V$ 를 만족하면서 $a$ 를 포함하는 $ U \in \mathscr{T}{X}$ 가 존재하면 $f$ 를 $a$ 에서 연속Continuous 라고 한다. $f$ 가 $X$ 의 모든 점에서 연속이면 연속함수 라 하고 $f \in C(X,Y)$ 로 나타낼 수 있다.$f$ is continuous at $a$ $\iff$ For all neighborhood $V \in \mathscr{T}{Y}$ of $f(a)$, there exists a neighborhood $ U \in \mathscr{T}{X}$ of $a$ such that $a \in U \implies f(a) \in f(U)</description>
    </item>
    
    <item>
      <title>페르마의 소정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fermats-little-theorem/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fermats-little-theorem/</guid>
      <description>소수 $p$ 와 서로소인 정수 $a$ 에 대해, $a^{p-1} \equiv 1 \pmod{p}$페르마의 소정리는 단순하지만 아주 많은 곳에 쓰이는 정리 중 하나다. 오일러에 의해 일반화된 정리도 있지만 페르마의 소정리로도 충분한 경우가 많기 때문이다.특히 유한체에서의 거듭제곱을 많이 다루는 암호론 등에서는 필수적인 정리다. Strategy : 증명은 단순무식하지만 그만큼 간단하지는 않다.</description>
    </item>
    
    <item>
      <title>원시 피타고라스 수끼리는 서로소임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/429/</link>
      <pubDate>Sun, 11 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/429/</guid>
      <description>$a^2 + b^2 = c^2$ 를 만족하는 세 자연수 $a,b,c$ 에 대해 $\gcd (a,b,c) = 1$ 면**(1)** $\gcd (a,b) = 1$**(2)** $\gcd (b,c) = 1$**(3)** $\gcd (c,a) = 1$언뜻 피타고라스 수든 뭐든 당연해보이지만 공약수라는 걸 잘 생각해보면 그렇지만도 않다. 예로써 피타고라스 수라는 조건이 없으면 $\gcd (6,10,15) = 1$ 이지만 각 두 수끼리는 각자 공약수를 갖는다.**Strategy** : 증명에는 아래의 두 보조정리가 기본적</description>
    </item>
    
    <item>
      <title>추상대수학에서의 정이면체군</title>
      <link>https://freshrimpsushi.github.io/posts/dihedral-group/</link>
      <pubDate>Sun, 11 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dihedral-group/</guid>
      <description>대칭군의 부분군 $D_{n} \leqslant S_{n}$ 을 $n$각형에 대해 회전, 반전하는 순열만을 가지는 군으로 정의하고 **정이면체군**Dihedral Group 이라고 부른다.도형에서 유도되기 때문에 말만으로는 설명하기 어렵다.가장 작은 정이면체군의 예시로써 대칭군 $D_{3} = S_{3}$ 이 있다.&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20180204_125857.png&amp;rdquo; height=&amp;ldquo;202&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/993B67435A79B8B631&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;537&amp;rdquo;/&amp;gt;&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20180204_125905.png&amp;rdquo; height=&amp;ldquo;188&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99BA07435A79B8B613&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;536&amp;rdquo;/&amp;gt;$ | D_{n} | =2n$이러한 순열은 $n$</description>
    </item>
    
    <item>
      <title>원시 피타고라스 트리플은 두 홀수만으로 표현할 수 있음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/428/</link>
      <pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/428/</guid>
      <description>$a^2 + b^2 = c^2$ 를 만족하는 세 자연수 $a,b,c$ 에 대해 $$ a = st \\ b = {{s^2 - t^2 } \over {2}} \\ c = {{s^2 + t^2 } \over {2}} $$ 를 만족하는 서로소인 두 홀수 $s&amp;gt;t$ 가 존재한다.이는 사실상 피타고라스 트리플라고 부를 이유가 없어진다는 것이다. 변수를 줄일 수 있다는 건 학문을 가리지 않고 무조건 좋은 일이라는 걸 명심하자. 증명1 $(a,b,c)$ 는 피타고라스 트리플이므로 $a$ 혹은 $ b $ 가 짝수인데,</description>
    </item>
    
    <item>
      <title>위상수학에서 기저의 동치 조건</title>
      <link>https://freshrimpsushi.github.io/posts/430/</link>
      <pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/430/</guid>
      <description>집합 $X$ 에서 $\mathscr{B}$ 가 위상 $\mathscr{T}$ 에 대한 기저, $\mathscr{B}&#39;$ 가 위상 $\mathscr{T}&#39;$ 에 대한 기저라고 할 때, $\mathscr{T} = \mathscr{T} &#39; $ 이면 $\mathscr{B}$ 와 $\mathscr{B}&#39;$ 를 서로 동치Equivalent 라고 하고, 아래의 두 가지를 만족시키는 것과 필요충분조건이다.(1) 모든 $B \in \mathscr{B}$ 와 $x \in B$ 에 대해, $x \in B&#39; \subset B$ 를 만족시키는 $B&#39; \in \mathscr{B}&#39;$ 가 존재한다.(2) 모든 $B&#39; \in \mathscr{B}&#39;$ 와 $x&#39; \in B&#39;$ 에 대해, $x&#39; \in B \subset B&#39;$ 를 만족시키는 $B \in \mathscr{B}$</description>
    </item>
    
    <item>
      <title>복소해석에서 등각사상이란</title>
      <link>https://freshrimpsushi.github.io/posts/conformal-mapping/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conformal-mapping/</guid>
      <description>함수 $f : A \subset \mathbb{C} \to \mathbb{C}$ 가 $\mathscr{R} \subset A$ 에서 해석적이고 모든 $z \in \mathscr{R}$ 에 대해 $f&#39;(z) \ne 0$ 이면 $f$ 를 등각사상Conformal Mapping 혹은 등각변환Conformal Transform 이라고 한다. 한편 $f&#39;(\alpha) = 0$ 를 만족하는 점 $\alpha$ 가 존재하면 $\alpha$ 를 $f$ 의 임계점Critical Point 이라고 한다.등각等角이라는 한자 그대로 등각변환을 취하면 도형들이 이루는 각이 보존된다.그 이름답게 등</description>
    </item>
    
    <item>
      <title>역함수 정리 An Inverse Function Theorem 증명</title>
      <link>https://freshrimpsushi.github.io/posts/408/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/408/</guid>
      <description>$f$ 가 $\alpha$ 에서 해석적이고 $f&#39;(\alpha) \ne 0$ 이면 $\mathcal{N} (\alpha) $ 에서 $f^{-1}$ 가 존재한다.$f&#39;(\alpha) \ne 0$ 이라는 조건을 잘 생각해보자.실수함수로 생각해보면 증가함수거나 감소함수라는 것이고, 이는 역함수가 존재하는 조건이 된다.기하적인 표현을 빌리자면 매끄러운Smooth 함수를 말하는 것이고, 이는 갑자기 방향을 트는 등의 꺾인 점이 없다는 뜻이다.역</description>
    </item>
    
    <item>
      <title>여유한위상과 여가산위상</title>
      <link>https://freshrimpsushi.github.io/posts/cofinite-topology-and-cocountable-topology/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cofinite-topology-and-cocountable-topology/</guid>
      <description>$X$ 가 무한집합이라고 하자.1. $ \mathscr{T}{f} : = \left\{ \emptyset , X \right\} \cup \left\{ U \subset X , : | X \setminus U | &amp;lt; \infty \right\} $ 를 여유한위상 이라고 한다.2. $ \mathscr{T}{c} : = \left\{ \emptyset , X \right\} \cup \left\{ U \subset X , : | X \setminus U | = \aleph_{0} \right\} $ 를 **여가산위상** 이라고 한다.단어와 표현은 어렵지만 의미하는 바는 결국 여집합이 유한인 위상, 여집합이 가산인 위상이라는 말이다.여유한위상은 $X$ 가 무한집합</description>
    </item>
    
    <item>
      <title>위상공간에서 수열의 극한은 유일하지 않음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/407/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/407/</guid>
      <description>일반적으로, 위상공간에서 수열의 극한은 유일하지 않다.도대체 이게 무슨 소린가 싶겠지만 유감스럽게도 사실이다. 우리는 이제껏 해석학 등에서 수열을 포함하는 구간이 점점 좁아지면서 한 점으로 수렴하는 이미지를 떠올려왔다. 하지만 위상수학에서 정의하는 수렴의 개념에 따르면 위상공간에 따라선 한 점으로 수렴할 이유가 전혀 없다.극한의 유일성을 보</description>
    </item>
    
    <item>
      <title>시어핀스키 공간</title>
      <link>https://freshrimpsushi.github.io/posts/sierpinski-space/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sierpinski-space/</guid>
      <description>$S : = \left\{ 0, 1 \right\}$ 의 위상이 $\mathscr{T} : = \left\{ \emptyset , \left\{ 1 \right\} , \left\{ 0, 1 \right\} \right\}$ 이면 $S$ 를 시어핀스키 공간 이라고 한다.어떤 집합 $X$ 가 주어져 있을 때 자명 위상Trivial Topology $\left\{ \emptyset , X \right\} $ 를 주면 그 공간은 가장 작은 공간이며 자명 공간 이라고 한다. 반대로 이산 위상Discrete Topology $\mathscr{P}(X)$ 를 주면 그 공간은 가장 큰 공간이며 이산 공간 이라고 한다.한편 시어핀스키 공간이란</description>
    </item>
    
    <item>
      <title>위상공간에서의 가분</title>
      <link>https://freshrimpsushi.github.io/posts/separable/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separable/</guid>
      <description>위상 공간 $X$ 에 대해 $A \subset X$ 라고 하자.(1) $x \in O \subset A$ 를 만족하는 열린 집합 $O$ 가 존재할 때, $x$ 를 $A$ 의 내점Interior Point 이라고 한다.(2) $A$ 의 내점의 집합 $A^{\circ} $ 를 $A$ 의 내부Interior 라고 한다.(3) $A$ 와 그 도집합의 합집합 $\overline{A} : = A \cup A&#39;$ 를 $A$ 의 폐포Closure 라고 한다.(4) $x \in \overline{A}$ 이면서 $x \in \overline{X \setminus A}$ 일 때, $x$ 를 $A$ 의 경계</description>
    </item>
    
    <item>
      <title>순환군의 부분군은 순환군임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/402/</link>
      <pubDate>Sun, 28 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/402/</guid>
      <description>순환군 $G$ 의 부분군 $ H \leqslant G $ 은 순환군이다.생각을 조금만 해보면 당연한 사실이지만 상당히 중요한 정리일뿐만 아니라 증명 역시 간단하지만은 않다. 증명 $H = \left\{ e \right\} $ 일 경우 $H = \left&amp;lt; e \right&amp;gt; $ 이므로 순환군이다.$H \ne \left\{ e \right\} $ 일 경우 어떤 자연수 $n$ 에 대해 $a^{n} \in H$ 일 것이고, 이를 만족하는 가장 작은 자연수를 $m$ 이라고 하자.$c := a^m$ 일 때 $H = \left&amp;lt; a^m \right&amp;gt; =</description>
    </item>
    
    <item>
      <title>추상대수학에서의 동형</title>
      <link>https://freshrimpsushi.github.io/posts/isomorphism/</link>
      <pubDate>Sun, 28 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isomorphism/</guid>
      <description>그래프 이론에서의 동형두 이항연산구조 $\left&amp;lt; S , * \right&amp;gt; $ 와 $\left&amp;lt; S&#39; , *&#39; \right&amp;gt; $ 에 대해 전단사 함수 $\phi : S \to S&#39;$ 가 존재해서 모든 $x , y \in S$ 에 대해 $\phi(x * y) = \phi( x ) *&#39; \phi( y ) $ 를 만족하면 $\phi$ 를 동형사상 이라 부르고 $S$ 와 $S&#39;$ 가 동형Isomorphic 이라고 하고 $S \simeq S&#39;$ 라 쓴다.만약 $\phi$ 가 전단사가 아닐 경우 이를 준동형사상Homomorphism 이라고 한다</description>
    </item>
    
    <item>
      <title>모든 순환군은 가환군임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/401/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/401/</guid>
      <description>모든 순환군은 가환군이다.굳이 따로 증명하지 않더라도 순환군이 정수군과 동형이라는 것을 보이면 자연스럽게 따라오는 사실이기도 하다. 증명 순환군 $G := \left&amp;lt; a \right&amp;gt;$ 에 대해, $g_{1} = a^{r}$ 그리고 $g_{2} = a^{s}$ 라고 하자.$g_{1} g_{2} = a^{r} a^{s} = a^{r+s} = a^{s+r} = a^{s} a^{r} = g_{2} g_{1}$ 이므로 $G$ 는 가환군이다. ■</description>
    </item>
    
    <item>
      <title>위상공간에서의 집적점과 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/limit-point-and-convergence/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-point-and-convergence/</guid>
      <description>위상 공간 $\left( X , \mathscr{T} \right)$ 와 $A \subset X$ 에 대해 $x$ 를 포함하는 임의의 열린 집합 $O$ 가 $O \cap ( A \setminus \left\{ x \right\} ) \ne \emptyset$ 를 만족하면 $x$ 를 $A$ 의 집적점Limit Point , $A$ 의 모든 집적점의 집합 $A&#39;$ 를 $A$ 의 도집합Derived Set 이라고 한다. $X$ 의 수열 $\left\{ x_{n} \right\} $ 이 $x$ 에 **수렴한다**Converge 는 것은 $x$ 를 포함하는 임의의 열린 집합 $O$ 에 대해 $n \ge n_{0} \implies x_{n} \in O$ 를 만족하</description>
    </item>
    
    <item>
      <title>위상공간이란</title>
      <link>https://freshrimpsushi.github.io/posts/topology-space/</link>
      <pubDate>Fri, 26 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/topology-space/</guid>
      <description>집합 $X$ 가 주어졌을 때 $\mathscr{T} \subset \mathscr{P} (X)$ 가 $T \in \mathscr{T} $ 에 대해 다음 세가지 조건을 만족하면 $\mathscr{T} $ 를 $X$ 의 위상Topology 이라고 부르고, $\left( X , \mathscr{T} \right) $ 를 위상공간Topology Space 라고 부른다.(i) $\emptyset , X \in \mathscr{T}$(ii) $\displaystyle \bigcup_{ \alpha \in \forall } T_{\alpha} \in \mathscr{T} $**(iii)** $\displaystyle \bigcap_{ i= 1}^{n} T_{i} \in \mathscr{T} $조건 **(i)-(iii)** 을 다시 말로 풀어써보면 아래와 같다 :**(i)** $\mathscr{T}$ 는 공집합 $\emptyset$ 와 전체집합 $X$ 를 포함한다.**(ii)</description>
    </item>
    
    <item>
      <title>거리공간에서 완비성과 조밀성이란</title>
      <link>https://freshrimpsushi.github.io/posts/completeness-density/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/completeness-density/</guid>
      <description>거리 공간 $\left( X , d \right)$ 에 대해 $A \subset X$ 라고 하자.1. $X$ 의 수열 $\left\{ x_{n} \right\} $ 이 모든 $\varepsilon &amp;gt; 0$ 에 대해 $n,m &amp;gt; n_{0}$ 일때마다 $d(x_{n} , x_{m}) &amp;lt; \varepsilon$ 을 만족하는 자연수 $n_{0}$ 가 존재하면 **코시 수열**Cauchy Sequence 이라고 한다.**2.** $\left( X , d \right)$ 상의 코시 수열의 수렴하는 점들이 $X$ 에 속하면 $\left( X , d \right)$ 를 **완비하다**Complete 고 하고 그렇지 않을 경우 **</description>
    </item>
    
    <item>
      <title>그램-슈미트 직교화</title>
      <link>https://freshrimpsushi.github.io/posts/gram-schmidt-orthogonalization/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gram-schmidt-orthogonalization/</guid>
      <description>양자역학에서의 그람-슈미트 직교화 과정모든 유한차원 내적공간은 정규직교기저를 갖는다.존재성 증명이라는 게 대개 그렇듯 길지도 않고 별것도 아닌것 같아보이지만 엄청나게 중요한 정리다.선형대수학을 지탱하는 수많은 논리가 바로 이 정규직교기저가 존재한다는데에 의존하고 있기 때문이다. 증명 내적공간 $\left&amp;lt; V , \cdot \right&amp;gt; $ 을 생성하는 기저 중 하나를 $\left\{</description>
    </item>
    
    <item>
      <title>추상대수학에서의 순환군</title>
      <link>https://freshrimpsushi.github.io/posts/cyclic-group/</link>
      <pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cyclic-group/</guid>
      <description>군 $G$ 의 어떤 원소 $a$ 과 임의의 $x \in G$ 에 대해 $x = a^{n}$ 을 만족하는 정수 $n$ 이 존재하면 $G$ 를 순환군Cyclic Group 이라고 하고 $a$ 를 생성원Generator 이라고 한다.쉽게 말해 군의 모든 원소를 생성원의 거듭제곱으로 나타낼 수 있으면 순환군이다.계속해서 거듭제곱하는 형태로 모든 원소를 나타내게 되므로 &amp;lsquo;순환&amp;rsquo;이라는 표</description>
    </item>
    
    <item>
      <title>복소해석을 이용한 제곱수의 역수의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/390/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/390/</guid>
      <description>오일러의 풀이 보러가기$\displaystyle \sum_{n =1 }^{\infty} {{1} \over {n^2}} = {{ \pi ^2 } \over { 6 }} $오일러의 풀이가 깔끔하고 멋지긴 한데 아이디어가 너무 기발해서 막상 써먹을데는 별로 없다.복소해석을 공부하면서 가장 즐거운 점은 이러한 결과를 내는 숏컷이 바로바로 나온다는 것이다.예제로도 좋으니 직접 한번 풀어보도록 하자. 증명 $\displaystyle f(z) : = {{1} \over {z^2}} $ 이라</description>
    </item>
    
    <item>
      <title>싱크함수를 이용한 제곱수의 역수의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/391/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/391/</guid>
      <description>복소해석을 이용한 풀이 보러가기$\displaystyle \sum_{n =1 }^{\infty} {{1} \over {n^2}} = {{ \pi ^2 } \over { 6 }} $이는 오일러가 남긴 풀이로써, 다름아닌 싱크함수의 오일러 표현을 사용해서 증명한다.아이디어가 상당히 신선하고 재미있어서 한번 보면 잊어버리는 게 더 어려울 것이다. 증명** **싱크함수의 오일러 표현** $\displaystyle {{\sin x} \over {x}} = \prod_{n=1}^{\infty} \left( 1 - {{x^2} \over { \pi^2 n^2}} \</description>
    </item>
    
    <item>
      <title>유수정리를 이용한 모든 정수에 대한 급수의 합 공식</title>
      <link>https://freshrimpsushi.github.io/posts/388/</link>
      <pubDate>Sun, 21 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/388/</guid>
      <description>분수함수 $f$ 에 대해 $\displaystyle \lim_{n \to \infty} z f(z) = 0$ 이고 $n \in \mathbb{Z}$ 에서 $f(n) \ne 0$ 이라고 하자. $f$ 가 유한한 특이점 $z_{1}, \cdots , z_{m}$ 을 가질 때, $\displaystyle \sum_{n=-\infty}^{\infty} f(n) = - \sum_{n = 1}^{m} \text{Res}_{z_{n}} (\pi f(z) \cot \pi z)$단순히 자연수만을 모두 더하는 것이 아니라 모든 정수에 대한 합을 유한한 합계로 나타내는 데 의의가 있다.물론 주어진 $f$ 가 우함수일 경우 그 절반을 취하면 자연수에 대한 합을 구하는데에도 응용이 가능하다</description>
    </item>
    
    <item>
      <title>코탄젠트와 코시컨트의 로랑 전개</title>
      <link>https://freshrimpsushi.github.io/posts/laurnet-expansion-of-cotangent-and-cosecant/</link>
      <pubDate>Sun, 21 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laurnet-expansion-of-cotangent-and-cosecant/</guid>
      <description>$\displaystyle \cot z = {{1} \over {z}} - {{z} \over {3}} - {{z^{3}} \over {45}} - {{2 z^{5}} \over {945}} - \cdots $$ \displaystyle \csc z = {{1} \over {z}} + {{z} \over {6}} + {{7 z^{3}} \over {360}} + {{31 z^{5}} \over {15120}} + \cdots $복소해석에서 급수의 합 공식을 쓰기 위해선 코탄젠트와 코시컨트가 곱해진 함수의 유수를 구할 수 있어야한다.물론 이보다 우아하고 차수가 큰 항에도 쓸 수 있는 급수꼴이 있지만 대개는 이정도면 충분하다.적어도 세번째 항까지는 시험공부를 위해서</description>
    </item>
    
    <item>
      <title>거리공간에서 볼과 열린 집합 닫힌 집합</title>
      <link>https://freshrimpsushi.github.io/posts/ball-open-closed/</link>
      <pubDate>Thu, 18 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ball-open-closed/</guid>
      <description>거리 공간 $\left( X, d \right)$ 에 대해 $a \in X$ 이고 $r &amp;gt; 0$ 이라고 하자.1. $B_{d} (a,r) = \left\{ x \in X , | , d(a,x) &amp;lt; r \right\}$ 을 중심이 $a$ 고 반경이 $r$ 인 **열린 볼**Open Ball 이라고 한다.**2.** $B_{d} [a,r] = \left\{ x \in X , | , d(a,x) \le r \right\}$ 을 중심이 $a$ 고 반경이 $r$ 인 **닫힌 볼**Closed Ball 이라고 한다.**3.** $O \subset X$ 가 열린 볼의 합집합이면 $O$ 를 $X$ 에서 **열린 집</description>
    </item>
    
    <item>
      <title>거리공간이란</title>
      <link>https://freshrimpsushi.github.io/posts/metric-space/</link>
      <pubDate>Wed, 17 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/metric-space/</guid>
      <description>집합 $X$ 에 대해 함수 $d : X \times X \to [0, \infty)$ 가 $x,y,z \in X$ 에 대해 아래의 조건들을 만족시킬 때, $d$ 를 거리Metric 라고 부르고 $\left( X, d\right)$ 를 거리공간 이라고 한다.(i) $d(x,y)=0 \iff x = y$(ii) $d(x,y) = d(y,x)$(iii) $d(x,y) + d(y,z) \ge d(x,z)$선형대수학에서 놈의 개념을 체득했다면 알겠지만 크기 혹은 거리가 꼭 직관적으로만 정의될 필요는 없다.아래의 세가지 예시들은 특히 $\mathbb{R}^{n}$ 상에서 정의되</description>
    </item>
    
    <item>
      <title>다가함수의 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/375/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/375/</guid>
      <description>다가함수를 적분할 때의 가장 큰 문제점은 경로를 지나면서 분기선을 만나면 함수값이 원치 않게 바뀐다는 것이다.이러한 함수를 적분할 땐 이제까지 해왔던 것과 마찬가지로 경로 자체가 분기선을 우회하도록 하는 트릭을 사용한다.대표적인 다가함수인 로그 $\log$ 를 생각해보면, 음의 실수축이 분기선이고 원점이 분기점이므로 위와 같은 경로를 생각해볼 수 있다.그</description>
    </item>
    
    <item>
      <title>복소해석학에서의 다가함수와 분기선 분기점</title>
      <link>https://freshrimpsushi.github.io/posts/multifunction-branch-cut-branch-point/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multifunction-branch-cut-branch-point/</guid>
      <description>다가함수Multifunction 란 복수의 값을 갖는 함수로써, 통상적으로 일컫는 &amp;lsquo;함수&amp;rsquo;는 아니다. 예로써 복소해석학에서는 로그함수를 $\log z := \text{Log} |z| + i \text{arg} z$ 로 두고 원점 $O$ 를 제외한 모든 점에서 정의한다. 여기서 $\text{Log}$ 는 우리가 원래 알던 로그함수고, 어규먼트Argument $\text{arg}$ 는 양의 실수축을 기준으로 양의 방향</description>
    </item>
    
    <item>
      <title>양의 정부호 행렬의 콜레스키 분해</title>
      <link>https://freshrimpsushi.github.io/posts/cholesky-decomposition/</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cholesky-decomposition/</guid>
      <description>$m \times m$ 양의 정부호 행렬 $A : = \begin{bmatrix} a_{11} &amp;amp; \mathbb{w}^{T} \\ \mathbb{w} &amp;amp; K \end{bmatrix} &amp;gt; 0$ 을 생각해보면 $a_{11}$ 은 양수, $\mathbb{w} \in \mathbb{R}^{m-1}$ 이고 $ K \in \mathbb{R}^{(m-1) \times (m-1)}$ 이다.만약 $a_{11} \le 0$ 이면 $\mathbb{e}_{1} = (1, 0, \cdots , 0)$ 에 대해 $\mathbb{e}_{1}^{T} A \mathbb{e}_{1} = a_{11} \le 0$ 이므로 $A$ 는 양의 정부호가 될 수 없다.한편 임의의 벡터 $ \mathbb{0 } \ne \mathbb{x} \in \mathbb{R}^{m-1} $ 에 대해서 $ \mathbb{x}^{T} K \mathbb{x} = \begin{bmatrix} 0 &amp;amp; \mathbb{x}^{T} \end{bmatrix} \begin{bmatrix} a_{11} &amp;amp; \mathbb{w}^{T} \\ \mathbb{w} &amp;amp; K \end{bmatrix} \begin{bmatrix} 0 \\ \mathbb{x} \end{bmatrix} &amp;gt; 0$ 이므로 $K &amp;gt; 0$ 다.편의상 $a_{11} = 1$ 이라</description>
    </item>
    
    <item>
      <title>대칭행렬의 LDU 분해와 R 코드 LDU Decomposition</title>
      <link>https://freshrimpsushi.github.io/posts/349/</link>
      <pubDate>Fri, 29 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/349/</guid>
      <description>가역대칭행렬 $A$ 에 대해 $A = LDL^{T}$ 를 만족하는 하삼각행렬 $L$ 과 대각행렬 $D$ 가 존재한다.$L^{T}$ 는 상삼각행렬이므로 $A = LU$ 에서의 $U$ 를 $U:= DL^{T}$ 으로 바꾼다고 보면 된다.일반적인 LU 분해보다 조건이 까다로워진만큼 계산량은 많이 줄어든다. 증명 $A$ 는 가역행렬이므로 $A = L U$ 를 만족하는 하삼각행렬 $L$ 과 상삼각행렬 $U$ 가 존재한다.한편 $A = A^{T}$ 이므로</description>
    </item>
    
    <item>
      <title>정칙행렬의 LU 분해와 R 코드 LU Decomposition</title>
      <link>https://freshrimpsushi.github.io/posts/345/</link>
      <pubDate>Thu, 28 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/345/</guid>
      <description>행렬 $A \in \mathbb{R}^{m \times m}$ 의 왼쪽에 곱해졌을 때 $(i, j)$ 성분을 $0$이 되도록 하는 행렬 $E_{ij}$ 를 **$A$ 에 대한 $ij$-소거연산자** 라고 정의해보자.구체적으로 정방행렬 $(a_{ij}) \in \mathbb{R}^{m \times m}$ 에 대한 $E_{ij}$ 는 대각성분이 $1$ 이고 $(i,j)$ 성분이 $\displaystyle -m_{ij} = -{{a_{ij}} \over {a_{jj}}}$, 나머지 성분이 $0$으로 구해진다.이는 연립 방정식의 풀이에서 같은 변수끼리 계수를 맞춰서 소거하는 연산을 행렬로 나타낸 것이</description>
    </item>
    
    <item>
      <title>스펙트럴 이론 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-spectral-theory/</link>
      <pubDate>Wed, 27 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-spectral-theory/</guid>
      <description>정칙행렬 $A \in \mathbb{C}^{m \times m}$ 의 고유값 $\lambda_{i}$ 들로 구성된 대각행렬을 $\Lambda : = \text{diag} ( \lambda_{1} , \lambda_{2} , \cdots , \lambda_{m} ) $, 그 고유값들에 해당하는 정규직교 고유벡터 $\mathbb{q}_{i}$ 들로 구성된 정규직교행렬을 $Q$ 라고 하면 $$ A = A^{ * } \iff A = Q \Lambda Q^{ * } $$ * $A^{ * } = \left( \overline{A} \right)^{T}$ 는 $A$ 에 복소켤레를 취한 행렬의 전치 행렬로, 에르미트 행렬이라 부른다.**스펙트럴 이론** 은 다음과 같이 기술되기도 한</description>
    </item>
    
    <item>
      <title>선형종속인 집합을 부분집합으로 가지는 집합은 선형종속임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/370/</link>
      <pubDate>Tue, 26 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/370/</guid>
      <description>선형종속인 집합을 부분집합으로 가지는 집합은 선형종속이다즉, 선형종속인 집합에 원소를 추가해 더 큰 집합을 만들면 무조건 선형종속이라는 말이다. 증명 두 집합 $T$, $S$를 아래와 같이 정의하자.$T=\left\{ v_1,\ v_2,\cdots , v_r \right } $$ S=\left\{ v_1,\ v_2,\cdots ,v_r,\ v_{r+1},\cdots ,v_n \right\} $$ T$는 $S$의 부분집합이고 $T$는 선형종속이다.$T$가 선형종속이므로 $c_1v_1 + c_2v_2 + \cdots +c_r</description>
    </item>
    
    <item>
      <title>정칙행렬의 슈어 분해</title>
      <link>https://freshrimpsushi.github.io/posts/schur-factorization/</link>
      <pubDate>Tue, 26 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schur-factorization/</guid>
      <description>모든 정칙행렬 $A \in \mathbb{C}^{ m \times m}$ 는 슈어 분해를 갖는다.어떤 유니터리 행렬 $Q$ 와 상삼각행렬 $T$ 에 대해, $A = Q T Q^{ * }$ 이면 $A$ 는 슈어 분해를 갖는다 고 한다.고유값 대각화의 단점은 $A = S \Lambda S^{-1}$ 로 분해되었을 때 어쨌든 $S^{-1}$ 을 구하는 수고가 필요하다는 것이다. 거듭제곱을 구하는 시간이 획기적으로 줄어드는 것은 사실이지만, 선형대수학의 모든 문제가 역행렬을</description>
    </item>
    
    <item>
      <title>0이 아닌 임의의 한 벡터는 선형독립이다</title>
      <link>https://freshrimpsushi.github.io/posts/369/</link>
      <pubDate>Sun, 24 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/369/</guid>
      <description>영벡터가 아닌 벡터 $\mathbf{v}$가 벡터공간 $V$의 원소라고 하자. 이 때 $\left\{ v \right\}$는 선형독립이다. 증명 선형독립의 정의에 의해 $\mathbf{0}$이 아닌 임의의 한 벡터 $\mathbf{v}$에 대해서$c\mathbf{v} =\mathbf{0} $을 만족하는 $c$가 오직 $0$뿐이라면 선형독립이다.이 때 벡터공</description>
    </item>
    
    <item>
      <title>전체 특이값 분해의 존재성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-existence-of-fsvd/</link>
      <pubDate>Sun, 24 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-existence-of-fsvd/</guid>
      <description>세 자연수 $m \ge n \ge r = \text{rank} A$ 에 대해 행렬 $A \in \mathbb{R}^{m \times n}$ 는 $\mathrm{fSVD}$ 을 갖는다.고유값 대각화는 적용에 있어서 정방행렬이라는 제한이 있었지만 특이값 분해는 그러한 제약이 없었다.이렇게 쓸만한 분해법이 모든 행렬에 통하는지, 즉 분해의 존재성을 밝히는 것은 상당히 중요한 문제라고 할 수 있다. 증명 임의의 벡터 $\mathbb{x} \ne \mathbb{0}$ 에 대해 $\mathbb{x}^{T} A^{T} A \mathbb{x} = || A \mathbb{x} || ^2 &amp;gt; 0 $ 이므로 $A^{T}</description>
    </item>
    
    <item>
      <title>선형 독립인 집합의 부분 집합도 선형 독립임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/368/</link>
      <pubDate>Sat, 23 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/368/</guid>
      <description>어떤 선형독립인 집합의 부분집합도 선형독립이다.증명 두 집합 $T$, $S$를 아래와 같이 정의하자.$T=\left\{ v_1,\ v_2,\cdots , v_r \right } $$ S=\left\{ v_1,\ v_2,\cdots ,v_r,\ v_{r+1}, \cdots ,v_n \right\} $$ T$는 $S$의 부분집합이고 $S$는 선형독립이다.$S$가 선형독립이므로$c_1v_1 + c_2v_2 + \cdots +c_r v_r + c_{r+1} v_{r+1} + \cdots + c_n v_n=0$을 만족하는 단 하나의 조건은$c_1=c_2=</description>
    </item>
    
    <item>
      <title>행렬의 특이값 분해</title>
      <link>https://freshrimpsushi.github.io/posts/singular-value-decomposition-svd/</link>
      <pubDate>Sat, 23 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/singular-value-decomposition-svd/</guid>
      <description>유클리드 공간에 대한 타원의 확장, 일립소이드늘 고유값 대각화를 통해 행렬을 쪼갤 수 있다면 좋겠지만, 이 방법엔 아쉽게도 주어지는 행렬이 정방행렬이어야한다는 제한이 있다. 대각화할 행렬을 확장해서 두 자연수 $m &amp;gt; n$ 에 대해 행렬 $A \in \mathbb{C}^{ m \times n}$ 의 계수가 $\text{rank} A = n $ 으로 주어진다고 하자. 그러면 $\dim C(A) = \dim C(A^{T}) = n $ 으로, 이들의 정규직교벡터 $\mathbb{v}{1} , \cdots ,</description>
    </item>
    
    <item>
      <title>정칙행렬의 고유값 대각화</title>
      <link>https://freshrimpsushi.github.io/posts/diagonalization/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diagonalization/</guid>
      <description>행렬 $A \in \mathbb{R}^{m \times m}$ 의 일차독립인 고유벡터 $\mathbb{x}{1}, \mathbb{x}{2}, \cdots , \mathbb{x}{m}$ 에 대해, $S = \begin{bmatrix} \mathbb{x}{1}, \mathbb{x}{2}, \cdots , \mathbb{x}{m} \end{bmatrix}$ 라 하면 $S^{-1} A S = \begin{bmatrix} \lambda_{1} &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; \lambda_2 &amp;amp; \ddots &amp;amp; \vdots \\ \vdots &amp;amp; \ddots &amp;amp; \ddots &amp;amp; 0 \\ 0 &amp;amp; \cdots &amp;amp; 0 &amp;amp; \lambda_{m} \end{bmatrix} $$ A \in \mathbb{C}^{ m \times m }$ 에 대해 $A = Q^{ * } \Lambda Q$ 를 만족하는 유니타리 행렬 $Q$ 와 대각행렬 $\lambda$ 가 존재하면, 행렬 $A$ 는 **유니터리 대각화 가능하다** 고 말한다.가정에서 고유벡터를</description>
    </item>
    
    <item>
      <title>조화진동자의 연산자를 행렬로 표현하기</title>
      <link>https://freshrimpsushi.github.io/posts/367/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/367/</guid>
      <description>슈뢰딩거 방정식은 선형방정식이므로 방정식을 만족하는 여러 파동함수의 선형결합 역시 방정식을 만족한다.조화 진동자의 각 상태의 고유함수를 $|\psi_0&amp;gt;$, $|\psi_1&amp;gt;$, $\cdots$, $|\psi_n&amp;gt;$라 하면이 고유함수들의 선형결합인 $|\psi&amp;gt;=c_0|\psi_0&amp;gt; + c_1|\psi_1&amp;gt; + \cdots + c_n|\psi_n&amp;gt;$역시 슈뢰딩거 방정식의 해이다.(고유함수라는 것이 아니다. 일반적으로 고유함수의</description>
    </item>
    
    <item>
      <title>양자역학의 여러 연산자의 행렬표현</title>
      <link>https://freshrimpsushi.github.io/posts/366/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/366/</guid>
      <description>선형대수학을 배운 사람은 알겠지만 행렬도 벡터의 한 종류이다. 심지어 모든 벡터는 행렬로 표현할 수가 있다. 파동함수(고유함수)에 작용하는 연산자들 역시 행렬로 표현이 가능하다. (선형대수의 설명을 덧붙이자면 선형 연산자이기 때문에 행렬 변환이고 따라서 행렬로 표현이 가능하다) 따라서 양자역학의 이론은 모두 행렬로 표현이 가능하다. 잘 알려진</description>
    </item>
    
    <item>
      <title>연산자 방법으로 조화진동자 문제 풀기  일반화된 고유함수</title>
      <link>https://freshrimpsushi.github.io/posts/harmonic-oscillator-eigenfunction/</link>
      <pubDate>Sat, 16 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/harmonic-oscillator-eigenfunction/</guid>
      <description>이전 글 : 연산자 방법으로 조화진동자 문제 풀기 : 에너지 준위와 바닥상태의 고유함수 이제 조화진동자의 사다리 연산자와 바닥상태의 고유함수로부터 일반화된 고유함수를 구해보자.사다리 연산자 $a_\pm$는 고유함수 $\psi_n$의 상태를 한 단계 올려주거나 내려준다.따라서 다음과 같은 식을 세울 수 있다.$a_+|\psi_n&amp;gt</description>
    </item>
    
    <item>
      <title>연산자 방법으로 조화진동자 문제 풀기  에너지 준위와 바닥상태의 고유함수</title>
      <link>https://freshrimpsushi.github.io/posts/harmonic-oscillator-energy-level-ground-state/</link>
      <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/harmonic-oscillator-energy-level-ground-state/</guid>
      <description>이전 글 : 연산자 방법으로 조화진동자 문제 풀기 : 사다리 연산자 적용계속해서 조화진동자의 에너지와 바닥상태의 고유함수를 구해보자.$E=&amp;lt;\psi|H|\psi&amp;gt;=&amp;lt;\psi|(a_+a_-+\dfrac{1}{2})\hbar w|\psi&amp;gt;$이 때 고유함수에 한 없이 $a_-$를 적용시킬 순 없다</description>
    </item>
    
    <item>
      <title>발산하는 반원 상의 복소경로적분을 통한 유리함수의 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/338/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/338/</guid>
      <description>두 다항함수 $p(z) , q(z) $ 에 대해 $\displaystyle f(z) = {{q(z)} \over {p(z)}} $ 이라고 하자.$q(z) = 0$ 을 만족하는 실수해가 존재하지 않으면 $f$ 는 실수 특이점을 갖지 않을 것이다.이러한 유리함수의 이상적분 $\displaystyle \int_{-\infty}^{\infty} f(z) dz$ 이 존재하는 조건은 $\displaystyle f(z) \sim {{1} \over {z^{p}}} $ 에서 $p &amp;gt; 1$ 이다.무한급수의 개념으로 생각해보자면 $\displaystyle \sum_{n=0}^{\infty} {{{1} \over {n^{p}}} }$ 가 수렴하는 필요충분조건이 $p&amp;gt;1$ 인 것과 관련지어볼 수 있겠다.</description>
    </item>
    
    <item>
      <title>연산자 방법으로 조화진동자 문제 풀기  사다리 연산자 적용</title>
      <link>https://freshrimpsushi.github.io/posts/harmonic-oscillator-ladder-operator/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/harmonic-oscillator-ladder-operator/</guid>
      <description>이전 글 : 연산자 방법으로 조화진동자 문제 풀기 : 사다리 연산자의 정의이제 사다리 연산자가 조화진동자의 고유함수에 어떻게 작용하는지 알아보자.참고로 임의의 상수와 임의의 연산자간의 교환자는 항상 $0$이다.아래의 수식 전개에서 사용한 관계식 $( [AB,C]=A[B,C]+[A,C]B,\ \ [a_-,a_+]=1 ) $$ H=(a_+a_-+\dfrac{1}{2})\hbar w$이므로, $ \begin{eqnarray*} [H,a_+] &amp;amp;=&amp;amp; [(a_+a_-+\dfrac{1}{2})\hbar w,a_+] \\ &amp;amp;=&amp;amp; [a_+a_-\hbar w,a_+]+[\dfrac{1}{2}\hbar w, a_+] \\ &amp;amp;=&amp;amp; \hbar w[a_+a_-,a_+] \\ &amp;amp;=&amp;amp; \hbar w(a_+[a_-,a_+] + [a_+,a_+]a_-) \\ &amp;amp;=&amp;amp; \hbar w a_+ \\ &amp;amp;=&amp;amp; Ha_+</description>
    </item>
    
    <item>
      <title>양의 정부호 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/positive-definite-matrix/</link>
      <pubDate>Wed, 13 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/positive-definite-matrix/</guid>
      <description>행렬 $A \in \mathbb{C}^{m \times m}$ 가 $A = A^{ * }$ 즉, 에르미트 행렬일 때 임의의 벡터 $\mathbb{x} \ne \mathbb{0}$ 에 대해 $\mathbb{x}^{ * } A \mathbb{x} &amp;gt; 0$ 면 $A$ 는 양의 정부호 라고 부르고 $A&amp;gt;0$ 로 쓴다. 행렬 $A \in \mathbb{R}^{m \times m}$ 에 대해서는 $A = A^{T}$ 즉, 대칭행렬이고 $\mathbb{x} \ne \mathbb{0}$ 에 대해 $\mathbb{x}^{T} A \mathbb{x} &amp;gt; 0$ 일 때 $A&amp;gt;0$ 로 정의한다.이러한 정의는 깔끔하지만 많은 것이 생략되어 있어 머리로 따라가기가 어렵다. 차근차근 수식과 설명을 봐가면서 개</description>
    </item>
    
    <item>
      <title>연산자 방법으로 조화진동자 문제 풀기  사다리 연산자의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/harmonic-oscillator-ladder-operator/</link>
      <pubDate>Wed, 13 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/harmonic-oscillator-ladder-operator/</guid>
      <description>조화진동자 문제를 연산자 방법으로 풀 때 아주 유용한 연산자가 있다.바로 조화진동자의 사다리연산자$\mathrm{Ladder\ Operator}$이다.에너지 연산자인 해밀토니안$H$과도 치환이 가능하고,사다리 연산자의 특징을 이용해 바닥상태부터의 고유함수도 구할 수 있다.조화 진동자의 고전적인 해밀토니안$H$을 인수분</description>
    </item>
    
    <item>
      <title>무한 포텐셜 우물에서의 에너지 준위</title>
      <link>https://freshrimpsushi.github.io/posts/361/</link>
      <pubDate>Tue, 12 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/361/</guid>
      <description>무한 포텐셜 우물에서의 파동함수(고유함수)와 에너지(고유값)을 구하는 것은 여기를 참고하자.자 이제 결과만 가져와서 이게 어떤 의미를 가지는지 살펴보자.고유함수 $\displaystyle \psi_{(x)} =\sqrt{\frac{2}{a}}\sin \frac{n\pi}{a}x$고유값 $\displaystyle E_n=\frac{n^2\pi^2\hbar^2}{2ma^2}$ 무한 포텐셜 우물의 파동함수에 대해서운동량의 기댓값은 $0$이지만, 운동량의 제곱의 기댓값에 대해서는 $0$이 아니다</description>
    </item>
    
    <item>
      <title>양자역학에서 축퇴란</title>
      <link>https://freshrimpsushi.github.io/posts/degeneracy/</link>
      <pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/degeneracy/</guid>
      <description>**** 축퇴$(\mathrm{Degeneracy})$ 축퇴란 서로 다른1 두 파동함수가 같은 고유값을 가지는 것을 말한다. 다시 말하자면 두 파동함수가 축퇴되어 있다는 것은 두 파동함수의 에너지가 같다는 것이다. 그리피스 교재에서는 겹침, 겹친 상태라고 한다. 역자에 따르면 1995년 한국물리학회 발간 용어집에서 &amp;lsquo;겹침&amp;rs</description>
    </item>
    
    <item>
      <title>각운동량에서 고유함수와 사다리 연산자의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/348/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/348/</guid>
      <description>$\mathbf{L}^2$과 $L_z$의 동시 고유함수 $|l,m&amp;gt;$은 아래의 고유값 방정식을 만족한다.$\mathbf{L}^2 |l,m&amp;gt; = l(l+1)\hbar ^2 |l,m&amp;gt; $$ L_z |l,m&amp;gt; = m\hbar |l,m&amp;gt;$동시고유함수에 대한 표기는 책마다 다를 수 있다.가시오로비츠$\mathrm{gasiorowicz}$의 교재에서는 디락 표기법을 주로 쓰고</description>
    </item>
    
    <item>
      <title>임의의 두 연산자 A B가 허미션 연산자일 때 AB가 허미션 연산자일 조건</title>
      <link>https://freshrimpsushi.github.io/posts/347/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/347/</guid>
      <description>두 허미션 연산자 $A,B$가 교환 관계$\mathrm{Commute}$이면 $AB$도 허미션 연산자$\mathrm{Hermitian\ Operator}$이다.참고로 역도 성립한다. 증명 $AB$가 허미션 연산자임을 보이려면 $(AB)^\dagger=AB$임을 보이면 된다.$[A,B]=AB-BA $$ \Rightarrow AB=BA+[A,B] $$</description>
    </item>
    
    <item>
      <title>L^2과 L_z의 동시 고유함수에 대한 고유값 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/343/</link>
      <pubDate>Sun, 26 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/343/</guid>
      <description>$\mathbf L^2$과 $L_z$의 동시 고유함수 $|l,m&amp;gt;$에 대해여 고유값 방정식은 다음과 같다.$\mathbf L ^2 |l,m&amp;gt; = l(l+1)\hbar^2|l,m&amp;gt; $$ L_z|l,m&amp;gt;=m\hbar|l,m&amp;gt;$이 때, $l=0, \frac{1}{2}, 1, \frac{3}{2}, 2, \cdots $$ m= -l, -l+1, -l+2, \cdots , l-2, l-1, l$※글이 길지만 최대한 자세히 설명했으니 천천히 따라와보길 바란다.각운동량의 각 성분끼리의 교환 관계</description>
    </item>
    
    <item>
      <title>각운동량의 사다리연산자올림연산자 내림연산자</title>
      <link>https://freshrimpsushi.github.io/posts/angular-momentum-ladder-operator-raising-operator-lowering-operator/</link>
      <pubDate>Sun, 26 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/angular-momentum-ladder-operator-raising-operator-lowering-operator/</guid>
      <description>각운동량을 다룰 때 유용하게 쓰이는 두 연산자를 소개한다.$1.$ 올림 연산자$\mathrm{Raising\ Operator}$ $L_+ \equiv L_x + iL_y $$ 2.$ 내림 연산자$\mathrm{lowering\ Operator}$ $L_- \equiv L_x - iL_y$즉, $(L_-)^{ * }=L_+$이 두 연산자의 이름이 &amp;lsquo;올림&amp;rsquo;, &amp;lsquo;내림&amp;rsquo;인 이유는?각</description>
    </item>
    
    <item>
      <title>복소평면 상에서의 삼각함수 치환을 통한 정적분</title>
      <link>https://freshrimpsushi.github.io/posts/333/</link>
      <pubDate>Sun, 26 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/333/</guid>
      <description>$\displaystyle \int_{0}^{2 \pi} f( \cos \theta , \sin \theta ) d \theta = \int_{\mathscr{C}} f(z) dz = 2 \pi i \sum \text{Res} f(z) $정적분을 구하기 힘든 실함수는 복소해석으로의 우회를 통해 비교적 쉽게 풀어낼 수 있다.그 중에서도 삼각함수들로 이루어진 피적분함수에 대한 적분 테크닉을 알아보자.기본적인 전략은 적분 범위를 $z(\theta) = e^{ i \theta} , 0 &amp;lt; \theta &amp;lt; 2 \pi$ 로 바꿔 필요한 부분을 취하는 것이다.물론 필요하다면 약간의 조작을 취해</description>
    </item>
    
    <item>
      <title>R 에서 데이터 프레임의 행과 열의 위치 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-swap-row-and-column-in-r/</link>
      <pubDate>Sat, 25 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-swap-row-and-column-in-r/</guid>
      <description>R 의 강점 중 하나는 프로그래밍 언어가 익숙한 사람의 입장에서 상당히 어려운 조작들을 손쉽게 구현시켜준다는 것이다.예컨대 배열을 사용할 때 미리 메모리를 할당 시키지 않아도 스스로 확장이 되는가하면, 변수의 값을 바꾸는 등의 조작이 아주 쉽다.아이리스 데이터셋에서 Sepal.Width 열과 Species 열을 바꿔보자.방법은 너무나 간단하다.2번째 열에 5번째 열을 할당하고</description>
    </item>
    
    <item>
      <title>R 에서 내장 데이터셋 불러오기</title>
      <link>https://freshrimpsushi.github.io/posts/331/</link>
      <pubDate>Fri, 24 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/331/</guid>
      <description>R 은 대표적인 통계 프로그래밍 언어로써 유용한 메소드 뿐만 아니라 예제로 쓰기 좋은 데이터셋도 제공한다. 만약 이런 데이터셋이 없다면 강의를 할 때마다 새로운 데이터를 다운로드하고 불러들어들이는 짓을 해야할 것이다.데이터셋을 불러오는 방법은 아주 간단하다. 불러올 데이터셋의 이름을 우리가 사용할 변수에 할당하기만 하면 된다. 통계학을 공부하다</description>
    </item>
    
    <item>
      <title>에르미트 행렬의 서로 다른 두 고유값에 대한 고유벡터는 서로 수직임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/330/</link>
      <pubDate>Thu, 23 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/330/</guid>
      <description>수리물리학에서의 증명행렬 $A \in \mathbb{C}^{m \times m}$ 에 대해 $A = A^{ * }$ 이라고 하자. $A$ 의 서로 다른 두 고유값 $\lambda , \mu$ 에 대해 $A \mathbb{x} = \lambda \mathbb{x}$, $A \mathbb{y} = \mu \mathbb{y} $ 면 $ \mathbb{x} \perp \mathbb{y}$에르미트 행렬의 고유값은 모두 실수일뿐만 아니라 그들에 대응하는 고유벡터가 서로 직교한다는 성질을 가지고 있다. 이러한 성질들이 있으면 분명 어딘가의 증명에서 유용하게 쓰일 수 있</description>
    </item>
    
    <item>
      <title>에르미트 행렬의 고유값은 모두 실수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/310/</link>
      <pubDate>Wed, 22 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/310/</guid>
      <description>수리물리학에서의 증명 보기행렬 $A \in \mathbb{C}^{m \times m}$ 에 대해 $A = A^{ * }$ 면 $A$ 의 고유값은 모두 실수다.일반적인 행렬에서 고유값이 실수라는 보장은 없고, 에르미트 행렬에 대해서는 증명을 통해 실수임을 확인할 수 있다.직관적으로는 떠올리기 쉽지 않지만 증명 자체는 간단한 편이고, 팩트로써도 상당히 유용하다.후에 이어지는 양의 정부호 등의 개념과 결합해 여러</description>
    </item>
    
    <item>
      <title>고유값의 대수적 중복도는 기하적 중복도보다 크거나 같음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/328/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/328/</guid>
      <description>행렬 $A \in \mathbb{C}^{ m \times m}$ 의 고유값 $\lambda$ 가 대수적 중복도 $a$ 를 갖고 기하적 중복도 $g$ 를 갖는다고 하면 $a \ge g$고유값의 대수적 중복도와 기하적 중복도는 서로 같다는 보장이 없다. (만약 같았다면 애초에 다르게 정의하지도 않았을 것이다.) 다만 한가지 확신할 수 있는 것은 대수적 중복도가 아무리 작아도 기하적 중복도보다는 크거나 같다는 사실이다. 증명 가정에 따라</description>
    </item>
    
    <item>
      <title>두 행렬이 서로 닮음이면 고유값이 같음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/329/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/329/</guid>
      <description>$A$ 와 $B$ 가 닮음이면 $\det (A - \lambda) = \det (B - \lambda) $두 가역행렬 $A$ 와 $B$ 에 대해, $A = P^{-1} B P$ 를 만족하는 가역행렬 $P$ 가 존재하면 $A$ 와 $B$ 는 서로 닮음 이라고 정의한다.위에서 주어진 식을 $B$ 에 대해서 나타내면 $B = P^{-1} A P$ 이므로 닮음 관계가 대칭적임을 쉽게 알 수 있다.대수적으로는 $A$ 와 $B$ 가 $P$ 에 대한 켤레conjugate라고 말할 수 있겠다. 증명 고유값이 같음</description>
    </item>
    
    <item>
      <title>고유값의 대수적 중복도와 기하적 중복도</title>
      <link>https://freshrimpsushi.github.io/posts/multiplicity-of-eigen-value/</link>
      <pubDate>Sun, 19 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplicity-of-eigen-value/</guid>
      <description>행렬 $A \in \mathbb{R}^{m \times m}$ 에 대해 고유값은 $\det (A - \lambda I ) =0$ 을 만족하는 $\lambda$ 로 정의된다. 특성방정식은 $\lambda$ 에 대한 $m$ 차 방정식, 즉 $$ \det (A - \lambda I ) = (-1)^m \lambda ^m + c_{m-1} \lambda ^{m-1} + \cdots + c_{1} \lambda + c_{0} = 0 $$ 으로 나타낼 수 있다. 대수학의 기본정리에 의해, 특성방정식은 복소수를 포함하여 정확히 $m$ 개의 근을 갖는다. 여기서 근은 중근을 포함하는데, 중근을 갖는다는 것은 곧 고유값이</description>
    </item>
    
    <item>
      <title>임의의 연산자에 대해서 항상 허미션 연산자인 모양</title>
      <link>https://freshrimpsushi.github.io/posts/327/</link>
      <pubDate>Sun, 19 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/327/</guid>
      <description>임의의 연산자 $A$에 대해서 아래의 꼴은 항상 허미션 연산자이다.$(1)\ A+A^\dagger $$ (2)\ i(A-A^\dagger) $$ (3)\ AA^\dagger$원래의 식에 대거$^\dagger$를 취해도 원래의 모양임을 보이면 증명 끝. 증명$(1)$ $(A+A^\dagger)^\dagger=A^\dagger+{(A^\dagger)}^\dagger=A^\dagger+A=A+A^\dagger$ ■ 증명$(2)$ $[i(A-A^\dagger) ]^\dagger=-i\left[ A^\dagger-{(A^\dagger)}^\dagger \right]=-i(A^\dagger-A)=i(A-A^\dagger)$ ■ 증명$(3)$ $(AA^\dagger)^\dagger={(A^\dagger)}^\dagger A^\dagger=AA^\dagger$ ■</description>
    </item>
    
    <item>
      <title>단순극에서의 유수</title>
      <link>https://freshrimpsushi.github.io/posts/the-residue-at-a-simple-pole/</link>
      <pubDate>Sat, 18 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-residue-at-a-simple-pole/</guid>
      <description>함수 $f$ 를 $\displaystyle f(z) = {{g(z)} \over {h(z)}} $ 으로 나타낼 수 있다고 하자. 여기서 $g$ 와 $h$ 는 $\alpha$ 에서 해석적이고, $g(\alpha) \ne 0 , h(\alpha) = 0, h&#39;(\alpha) \ne 0$ 라고 하면 $\alpha$ 는 $f$ 의 simple pole이고 $\displaystyle \text{Res}_{\alpha} f(z) = {{g(\alpha)} \over {h&#39;(\alpha)}} $딱히 $\displaystyle f(z) = {{g(z)} \over {h(z)}} $ 꼴에서 $h$ 가 다항함수여야하는 건 아니기 때문에 그저 극에서의 유수를 $m=1$ 에 한정시킨 정리라곤 할 수 없다.조건만 잘 만족한다면 오히려 더 많은 종류의 함수 $h$ 를 커버할</description>
    </item>
    
    <item>
      <title>두 에르미트 연산자의 곱이 에르미트 연산자일 조건</title>
      <link>https://freshrimpsushi.github.io/posts/hermitian-operator-commute/</link>
      <pubDate>Sat, 18 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermitian-operator-commute/</guid>
      <description>임의의 두 연산자 $A,B$가 에르미트(허미션) 연산자일 때 두 연산자의 곱 $AB$가 에르미트 연산자일 조건은 $[A,B]=0$이다.즉, 두 연산자가 에르미트 연산자일 때 교환 관계이면 두 연산자의 곱도 에르미트 연산자이다. 증명 $\begin{eqnarray*} (AB)^\dagger &amp;amp;=&amp;amp; B^\dagger A^\dagger \\ &amp;amp;=&amp;amp; BA \ \ (A, B\text{가 에르미트 연산자 이므로}) \end{eqnarray*}$이</description>
    </item>
    
    <item>
      <title>i의 거듭 제곱을 e의 거듭 제곱으로 표현하기 i^l</title>
      <link>https://freshrimpsushi.github.io/posts/325/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/325/</guid>
      <description>자연상수 $e$와 허수 $i$의 거듭제곱은 다음과 같은 관계를 만족한다. $$ e^{ i \frac{l \pi}{2}}=i^l $$ 증명 $e^{ i \frac{l \pi}{2}}=\cos\frac{l \pi}{2}+i\sin \frac{l \pi}{2}$이므로$l=0$일 때, $$ e^{ 0}= 1 =i^{0} $$ $l=1$일 때, $$ e^{ i \frac{\pi}{2}}=\cos\frac{\pi}{2}+i\sin \frac{\pi}{2}=i=i^{1} $$ $l=2$일 때, $$ e^{ i \pi}=\cos \pi+i\sin \pi=-1=i^{2} $$ $l=3$일 때, $$ e^{ i \frac{3\pi}{2}}=\cos\frac{3\pi}{2}+i\sin \frac{3\pi}{2}=-i=i^{3} $$ 이후 반복되므로 $$ e^{ i \frac{l \pi}{2}}=i^l $$ ■</description>
    </item>
    
    <item>
      <title>극에서의 유수</title>
      <link>https://freshrimpsushi.github.io/posts/the-residue-at-a-pole/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-residue-at-a-pole/</guid>
      <description>$\alpha$ 가 함수 $f : A \subset \mathbb{C} \to \mathbb{C}$ 의 pole of order $m$, 즉 $\displaystyle f(z) = {{g(z)} \over { (z - \alpha)^m }} $ 으로 나타낼 수 있다고 하자. 여기서 $g$ 는 $\alpha$ 에서 해석적이며 $g(\alpha) \ne 0$ 이라고 하면 $\displaystyle \text{Res}_{\alpha} f(z) = {{g^{(m-1)} (\alpha)} \over {(m-1)!} } $유수정리를 통해 적분 문제를 유수를 구하는 문제로 바꿀 수 있는 것까진 좋은데, 유수를 구하는 게 적분만큼 어렵다면 소용 없는 일이다.유수정리를 쓸 때마다 정의에 따라서 로랑 전개를 하고 유</description>
    </item>
    
    <item>
      <title>기하학적으로 이해하는 고유값의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/eigen-value/</link>
      <pubDate>Thu, 16 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eigen-value/</guid>
      <description>대칭행렬 $A \in \mathbb{R}^{ m \times m }$ 과 벡터 $\mathbb{x} \in \mathbb{R}^{m}$ 을 생각해보자.벡터 $\mathbb{x}$ 를 $A$ 로 변환한 $A \mathbb{x}$ 와 $\mathbb{x}$ 의 방향이 같다고 하면 어떤 실수 $\lambda$ 에 대해 $\lambda \mathbb{x} = A \mathbb{x} $ 이 성립할 것이다. 행렬 $A$ 는 본래 어떤 방향의 개념도 갖지 않지만, 이러한 벡터가 존재한다면 $A$ 가 어떤 고유한 방향을 가리킨다고 할 수 있을 것이다. 이러한 벡터 $\mathbb{x}$ 를 $A$ 의 고유 벡터eigen vector 라 부르고, 상수 $\lambda$ 를</description>
    </item>
    
    <item>
      <title>R 에서 행렬의 곱 역행렬 전치행렬 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/317/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/317/</guid>
      <description>R 의 강점은 행렬을 위시한 각종 데이터셋의 조작이 간편하다는 점과 풍부한 통계 패키지를 무료로 제공한다는 것이다.당연한 이야기지만 통계적 분석에서 행렬의 계산은 매우 중요하고, R 은 이러한 니즈를 훌륭하게 충족시켜준다.매트랩이 아닌 이상 다른 언어에선 행렬의 연산부터 귀찮게 따로 정의를 해줘야 할 것이다. 예로써 행렬 $ A = \begin{bmatrix} 2 &amp;amp; 1 &amp;amp; 0 \\ 1 &amp;amp;</description>
    </item>
    
    <item>
      <title>여러가지 행렬들</title>
      <link>https://freshrimpsushi.github.io/posts/special-matrices/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/special-matrices/</guid>
      <description>특별한 모양을 가져서 혹은 특별한 성질을 가져서 이름이 붙은 행렬들을 소개하겠다.정사각행렬(정방행렬)$\mathrm{Square\ Matrix}$ 행와 열의 수가 같은 행렬. 임의의 자연수 $n$에 대하여 크기가 $n \times n$인 행렬. $A_{n \times n}$. 크기가 $n \times n$인 정사각행렬을 $n$차 정사각행렬이라고 한다.**단위행렬(항등행렬)$\mathrm</description>
    </item>
    
    <item>
      <title>R 에서 몫과 나머지 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/316/</link>
      <pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/316/</guid>
      <description>프로그래밍 언어의 문법에서 정말 통일이 안 되는 게 바로 몫과 나머지 연산자다.기본적으론 다 비슷비슷하게 생긴 것 같지만 오히려 그래서 헷갈리는데 한 몫한다.C는 몫을 /, 나머지를 %으로 쓰고 파이썬은 몫을 //, 나머지를 % 으로 쓰며, 이렇게 헷갈리는 예는 얼마든지 더 들 수 있다.도대체 통계와 행렬 계산에 초점을 맞춘 R 에서 몫과 나머지를 구할 일이 어디 있겠</description>
    </item>
    
    <item>
      <title>임의의 두 연산자가 교환 관계일 조건</title>
      <link>https://freshrimpsushi.github.io/posts/operator-commute/</link>
      <pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operator-commute/</guid>
      <description>임의의 서로 다른 두 연산자의 공통의 고유함수가 존재하면 두 연산자는 교환 가능하다.즉, $\begin{cases} A\psi=a\psi \\ B\psi=b\psi \end{cases}$ 이면 $[A,B]=0$이 때 고유함수는 규격화된 고유함수이다. 증명 $\begin{eqnarray*} AB\psi=Ab\psi=bA\psi=ba\psi &amp;amp;=&amp;amp; ab\psi \\ &amp;amp;=&amp;amp; aB\psi \\ &amp;amp;=&amp;amp; Ba\psi \\ &amp;amp;=&amp;amp; BA\psi \end{eqnarray*} $$ \Rightarrow AB\psi-BA\psi=(AB-BA)\psi=0$ 이므로 $[A,B]=0$</description>
    </item>
    
    <item>
      <title>R 에서 모든 변수 제거하기 콘솔창 초기화</title>
      <link>https://freshrimpsushi.github.io/posts/315/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/315/</guid>
      <description>매트랩에서 작업공간 초기화, 모든 변수 제거하는 방법 R 은 인터프리터 언어기 때문에 콘솔을 계속 보며 작업을 하게 된다. 이때 디버그 등을 하기 위해서는 이런 저런 테스트도 같은 작업환경에서 할 수밖에 없는데, 테스트 중간에 생성된 특정 변수가 아주 중요한데 프로그래머가 알아채지 못하고 완성본엔 포함시키지 않는 등의 일이 있을 수 있다. 어제 집에서 할 땐 분</description>
    </item>
    
    <item>
      <title>허미션 연산자의 여러가지 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-hermitian-operator/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-hermitian-operator/</guid>
      <description>허미션 연산자의 여러가지 성질을 한데 모아 정리했다.증명은 각 링크를 참고하길 바람.**$0.$ 허미션 연산자란? $1.$ 허미션 연산자의 기댓값(고유값)은 항상 실수이다. ** $2.$ 허미션 연산자의 서로 다른 두 고유함수(고유벡터)는 직교한다. ** $3.$ 허미션 연산자 $A$에 대해서 다음의 식이 성립한다. $&amp;lt;A\psi|\phi&amp;gt;=</description>
    </item>
    
    <item>
      <title>R 에서 else if문 사용하기 Error unexpected else in else 해결</title>
      <link>https://freshrimpsushi.github.io/posts/314/</link>
      <pubDate>Sun, 12 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/314/</guid>
      <description>R 에는 switch문과 같은 분기문이 없기 때문에 if문을 여러개 이어서 분기를 나누어야만 한다.여기서 이 조건문이라는 게 if 와 else는 다 똑같은데 유독 else if 만 다를 수가 있다.elseif로 붙여쓰거나 아예 elif 처럼 줄여쓰는 경우가 그 예고, R은 제대로 띄어쓰기가 들어간 else if 를 사용한다.여러가지 프로그래밍 언어를 다룰 수 있게 되고 프로그래</description>
    </item>
    
    <item>
      <title>허미션 연산자의 서로 다른 두 고유함수는 직교함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/318/</link>
      <pubDate>Sun, 12 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/318/</guid>
      <description>선형대수학에서의 증명임의의 허미션 연산자$(\mathrm{Hermitian\ Operator})$ $A$의 서로 다른 두 고유함수(고유벡터)는 서로 수직이다.$\begin{cases} A\psi_n=a_n\psi_n \\ A\psi_m=a_m\psi_m \end{cases} $ 일 때, $&amp;lt;\psi_n|\psi_m&amp;gt;=0$ 혹은 $\psi_n \perp \psi_m$ 증명 $&amp;lt;\psi_n|A\psi_m&amp;gt;=a_m&amp;lt;\psi_n|\psi_m&amp;gt; $$ &amp;lt;A\psi_n|\psi_m&amp;gt;={a_n}^{ * }&amp;lt;\psi_n|\psi_m&amp;gt;=a_n&amp;lt;\psi_n|\psi_m&amp;gt;$ (허미션 연산자의 고유값은 항상 실수)또한 $A$는 허미션 연산자이므로$&amp;lt;A\psi_n|\ps</description>
    </item>
    
    <item>
      <title>고유값 방정식을 푸는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/306/</link>
      <pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/306/</guid>
      <description>물리학에서 고유값 문제를 배우는 이유$n\times n$ 행렬 $A$가 주어졌다고 하자. $$ A\mathbf{x}=\lambda \mathbf{x} \tag{1} $$ 행렬 $A$에 대해서 위의 식을 만족하는 $n\times 1$ 행렬 $\mathbf{x}$와 상수 $\lambda$를 찾는 것을 고유값 문제라고 한다. 이러한 행렬 $\mathbf{x}$를 $A$의 고유함수라하고 $\lambda$를 $\mathb</description>
    </item>
    
    <item>
      <title>추상대수학에서의 가환군</title>
      <link>https://freshrimpsushi.github.io/posts/abelian-group/</link>
      <pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abelian-group/</guid>
      <description>군 $\left&amp;lt; G, * \right&amp;gt;$ 의 두 원소 $a, b$ 에 대해 $a * b = b * a$ 면 $\left&amp;lt; G, * \right&amp;gt;$를 가환군 이라고 정의한다.가환은 &amp;lsquo;교환법칙이 성립하는&amp;rsquo; 정도의 의미로 받아들이면 좋다. 영칭의 경우 Commutative 대신 Abelian 이라는 말이 붙는데, 이는 천재수학자 아벨에서 따온 말이다. 물론 한칭으로 아벨군이라고 불러도 의미전달 상 전혀 문제는 없다</description>
    </item>
    
    <item>
      <title>유수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-residue-theorem/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-residue-theorem/</guid>
      <description>해석적인 함수 $ f : A \subset \mathbb{C} \to \mathbb{C}$ 가 단순폐경로 $\mathscr{C}$ 내부의 유한한 특이점 $z_{1} , z_{2} , \cdots , z_{m}$ 들을 가진다고 하자. 그러면 $\displaystyle \int_{\mathscr{C}} f(z) dz = 2 \pi i \sum_{k=1}^{m} \text{Res}_{z_{k}} f(z) $처음 읽어보면 아리송하기짝이 없는 정리다.적분 값을 구해야하는데 미적분학스러운 계산은 없고 웬 특이점과 유수 이야기를 하고 있으니 그럴만도 하다.정리만 보자면 유수를 구해서 더하는 것만으로 적분값을 찾을</description>
    </item>
    
    <item>
      <title>허미션 연산자의 기댓값고유값은 항상 실수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/hermitian-operator-expectation-value/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermitian-operator-expectation-value/</guid>
      <description>선형대수학에서의 증명 보기허미션 연산자$\mathrm{Hermitian\ Operator}$의 기댓값(고유값$\mathrm{Eigenvlaue}$)은 항상 실수$(\mathrm{real\ number})$이다. 증명 $A$를 허미션 행렬이라고 하자.$A$의 기댓값은$\langle A \rangle = \int \psi^{ * }A\psi d</description>
    </item>
    
    <item>
      <title>추상대수학에서의 모노이드</title>
      <link>https://freshrimpsushi.github.io/posts/monoid/</link>
      <pubDate>Tue, 31 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monoid/</guid>
      <description>반군 $\left&amp;lt; M , * \right&amp;gt;$ 의 모든 원소 $ a $ 에 대해, $a * e = e * a = a$ 를 만족하는 $e$ 가 존재하면 $\left&amp;lt; M , * \right&amp;gt;$ 를 모노이드 라고 정의한다.모노이드는 항등원이 존재하는 반군이다.항등원 정도 되는 개념을 도입하면 할 수 있는 이야기는 상당히 많아진다.반군이 되면서 모노이드가 되지 않는 대표적인 예를 보도록 하자.반군 $\left&amp;lt; \mathbb{N} , +\right&amp;gt; $ 는 모노이드가 아니다.**</description>
    </item>
    
    <item>
      <title>무한 포텐셜 우물에서 파동함수고유함수 에너지고유값 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/infinite-potential-well-wave-function-eigen-function-eigenvalue/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/infinite-potential-well-wave-function-eigen-function-eigenvalue/</guid>
      <description>무한 포텐셜 우물에서의 파동함수(고유함수)는$\displaystyle \psi_n{(x)} =\sqrt{\frac{2}{a}}\sin \frac{n\pi}{a}x$각 고유함수 $\psi_n$에 대한 에너지(고유값)은$\displaystyle E_n=\frac{n^2\pi^2\hbar^2}{2ma^2}$무한 포텐셜 우물에서의 시간에 무관한 슈뢰딩거 방정식$</description>
    </item>
    
    <item>
      <title>추상대수학에서의 반군</title>
      <link>https://freshrimpsushi.github.io/posts/semigroup/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/semigroup/</guid>
      <description>마그마 $\left&amp;lt; S, *\right&amp;gt;$ 의 원소 $a,b,c$ 에 대해, $(a * b) * c = a * (b * c)$ 면 $\left&amp;lt; S, *\right&amp;gt;$ 를 반군 이라고 정의한다.반군이란 연산이 결합법칙을 만족하는 마그마다.항등원이나 역원은 존재할 필요가 없고, 오직 결합법칙만 성립하면 된다.결합법칙을 만족하는지 증명하기 쉬운가 하는 문제와는 별개로, 폐쇄성 다음으로 결합법칙이 논의되는 것은 상당히 당연하다고 할 수 있다.</description>
    </item>
    
    <item>
      <title>벡터공간의 부분공간 끼리의 교집합도 부분공간임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/subspace-intersection/</link>
      <pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subspace-intersection/</guid>
      <description>$W_1$, $W_2$를 벡터공간 $V$내의 부분공간이라고 하자. 그러면$W_1 \cap W_2$ 도 $V$의 부분공간이다.**** 증명 $V$내의 부분집합이 $V$에서 정의된 덧셈과 스칼라곱에서 닫혀있는지만 확인하면 된다. 그러므로 $W_1 \cap W_2$가 덧셈과 스칼라곱에 대해서 닫혀있다면 $V$의 부분공간이다. 우선 $W_1 \cap W_2=W$라고 하자.**Pa</description>
    </item>
    
    <item>
      <title>추상대수학에서의 마그마</title>
      <link>https://freshrimpsushi.github.io/posts/magma/</link>
      <pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/magma/</guid>
      <description>수학을 크게 세 부류로 나누자면 기하학, 해석학, 대수학이라고 할 수 있을 것이다. 그 중에서 대수학은 교과과정 상에서 배우는 이항, 약분 등을 다루는 수학의 한 분과였다. 대수학이란 기본적으로 &amp;lsquo;수&amp;rsquo;를 대신해 문자를 써서 어떤 방정식이든 풀어내는 것을 목표로 하는 학문이었다. 특정한 수에 대해서만 통하는 게 아니라 일반적이</description>
    </item>
    
    <item>
      <title>노름 놈의 동치관계</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-relation-of-norm/</link>
      <pubDate>Sat, 28 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-relation-of-norm/</guid>
      <description>벡터공간 $V$ 상에서 정의된 두 놈 $| \cdot | {\alpha}$ 와 $| \cdot | {\beta}$ 과 임의의 벡터 $v \in V$ 에 대해, $c | v | {\alpha} \le | v | {\beta} \le C | v | {\alpha} $ 를 만족하는 $c , C &amp;gt;0 $ 이 존재하면 두 놈은 서로 동치 라고 정의한다.두 놈이 서로 동치라는 것은 놈을 이용한 부등식을 다룰 때 서로 다른 놈을 사용해도 문제가 없다는 말이다. 당연히 사용하기 어려운 놈을 사용하기 쉬운 놈으로 바꿔 쓰는 식</description>
    </item>
    
    <item>
      <title>벡터공간의 부분집합이 부분공간이 될 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/286/</link>
      <pubDate>Sat, 28 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/286/</guid>
      <description>벡터공간 $V$의 공집합이 아닌 부분집합 $W$가 $V$의 부분공간이 될 필요충분 조건은 아래의 두 조건을 동시에 만족하는 것이다.$(1)$ 부분집합 $W$가 $V$에서 정의된 덧셈에 대하여 닫혀있다.$(2)$ 부분집합 $W$가 $V$에서 정의된 스칼라곱에 대하여 닫혀있다.**** 증명 $(\Rightarrow) $$ W$가 부분공간이면 $(1)$, $(2)$를 만족하</description>
    </item>
    
    <item>
      <title>벡터공간의 부분공간</title>
      <link>https://freshrimpsushi.github.io/posts/subspace/</link>
      <pubDate>Fri, 27 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subspace/</guid>
      <description>**부분공간 벡터공간 $V$의 부분 집합 $W$가 있다고 하자. 이 때 $W$가 공집합이 아니고, $V$ 상에서 정의된 덧셈과 스칼라곱에 대하여 벡터공간이 될 때($=$벡터공간의 정의 10가지를 만족할 때) $W$를 벡터공간 $V$의 부분공간 이라고 한다. $W$가 $V$의 부분 공간임은 다음과 같이 표기한다. $$ W \le V $$ 벡터공간 $V$의 한 부분</description>
    </item>
    
    <item>
      <title>직교여공간과 그 성질</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-complement/</link>
      <pubDate>Fri, 27 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-complement/</guid>
      <description>벡터공간 $\mathbb{R}^{n}$의 부분공간 $S$ 에 대해, $S^{\perp} = \left\{ v \in V , | , \mathbb{s}^{T} \mathbb{v} = \left&amp;lt; \mathbb{v} , \mathbb{s} \right&amp;gt; = \mathbb{0} , \forall \mathbb{s} \in S \right\} $ 를 $S$ 의 직교여공간 으로 정의한다.* 기호 $^{\perp}$ 는 perpendicular 를 줄여서 [perp] [펍] 으로 읽는다.단어 그대로의 정의기 때문에 특히 유클리드 공간에선 쉽게 받아들일 수 있는 정의다. 간단한 예시로 $\mathbb{R}^{3}$ 에서 $S := \text{sp} \left\{ (1,0,0) , (0,1,0) \right\} $ 이라고 하면 $S^{\perp}</description>
    </item>
    
    <item>
      <title>벡터공간의 네 가지 성질과 그 증명</title>
      <link>https://freshrimpsushi.github.io/posts/vector-space/</link>
      <pubDate>Thu, 26 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vector-space/</guid>
      <description>벡터공간 $V$내의 임의의 벡터$\mathbf u$와 임의의 스칼라$k$에 대하여 아래를 만족한다.$(a) \quad 0\mathbf u=\mathbf 0 $$ (b) \quad k\mathbf 0=\mathbf 0 $$ (c) \quad (-1)\mathbf u=-\mathbf u $$ (d) \quad k\mathbf u=\mathbf 0 \Rightarrow k=0 \ \ or \ \ \mathbf u=\mathbf 0$벡터공간의 공리에 의해 증명은 아래와 같다. 혹시라도 이해가 안된다면 공리를 다시 살펴보자.$\color{red}{※}$스칼라 0과 영벡터$\c</description>
    </item>
    
    <item>
      <title>영벡터zero vector와 벡터의 음negative의 유일성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/283/</link>
      <pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/283/</guid>
      <description>벡터공간의 정의에 의해서 임의의 벡터공간 $V$내에 덧셈에 대한 항등원(영벡터zero vector)과 역원(음negative)이 존재한다.이 때 이들은 단 하나로 유일하다. 증명 1. 벡터공간 $V$내에 존재하는 영벡터는 유일하다. 벡터공간 $V$내에 영벡터 $\mathbf 0$, $\mathbf 0&#39;$이 있다고 하자.이 때 $\mathbf 0$, $\mathbf 0&#39;$은 벡터공간의 공리에 의해 $</description>
    </item>
    
    <item>
      <title>횔더 부등식의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-hoelders-inequality/</link>
      <pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-hoelders-inequality/</guid>
      <description>실해석학에서의 횔더 부등식 보러가기 일반화된 횔더 부등식 $\displaystyle {{1 } \over {p}} + {{1} \over {q}} = 1$ 을 만족하고 1보다 큰 두 상수 $p, q$ 와 $\mathbb{u}, \mathbb{v} \in \mathbb{C}^n$에 대해 $| \left&amp;lt; \mathbb{u}, \mathbb{v} \right&amp;gt; | = |\mathbb{v} ^{ * } \mathbb{u}| \le ||\mathbb{u}||{p} ||\mathbb{v}||{q}$원래는 Hölder&amp;rsquo;s inequality로 써야하지만 움라우트가 있어 대체표기를 했다.</description>
    </item>
    
    <item>
      <title>벡터공간의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-vector-space/</link>
      <pubDate>Tue, 24 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-vector-space/</guid>
      <description>추상대수학에서의 벡터 공간벡터의 쉬운 정의 정의 공집합이 아닌 집합 $V$의 원소들이 두 연산 덧셈 과 상수배 에 대해서 아래와 같은 10가지의 규칙을 만족할 때 $V$를 체 $\mathbb{F}$에 대한 벡터공간 ** 혹은 $\mathbb{F}$-벡터공간이라고 하고 $V$의 원소를 벡터 라고 한다. $\mathbf u , \mathbf v, \mathbf w$가 $V$의 원소이고 $k, l \in</description>
    </item>
    
    <item>
      <title>영의 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-youngs-inequality/</link>
      <pubDate>Tue, 24 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-youngs-inequality/</guid>
      <description>$\displaystyle {{1} \over {p}} + {{1} \over {q}} = 1$ 을 만족하고 1보다 큰 두 상수 $p,q$와 두 양수 $a,b$에 대해 $\displaystyle ab \le { {a^{p}} \over {p} } + {{b^{q}} \over {q}} $대수적으로 모양이 아름다운 점을 빼면 횔더 부등식을 증명하는 것 외엔 크게 언급되지 않는 부등식이다. 증명 $a$와 $b$ 모두 양수이므로 $a = e^A, b = e^B$ 를 만족하는 실수 $A,B$ 가 존재한다.볼록함수의 이계도함수 $f$ 가 $I$ 에서 두 번 미분가능</description>
    </item>
    
    <item>
      <title>로렌츠 변환 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-lorentz-transformation/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-lorentz-transformation/</guid>
      <description>**※글이 좀 길기는 하지만 유도과정과 설명을 어렵지 않게 적었으니 천천히 따라해보자. **※이 글보다 쉬운 글을 없을테니 괜히 다른 글 찾느라 시간 낭비하지말고 종이와 펜을 들고 같이 해보자. $A$관성계(좌표계)의 $xy$평면에서 움직이는 빛(광자)을 생각해보자. $t=0$일 때 원점에서 출발해 $x$축과 $\theta$를 이루며 나</description>
    </item>
    
    <item>
      <title>빛과 상대성이론Theory of relativity 로렌츠 변환Lorentz transformation의 등장</title>
      <link>https://freshrimpsushi.github.io/posts/249/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/249/</guid>
      <description>상대성이론은 전자기학의 완성에서부터 출발한다.전자기학을 완성했다는 말은 맥스웰이 전기장$\vec E$과 자기장$\vec B$에 관한 방정식(맥스웰 방정식)을 완성시켰다는 말과 같다고 할 수 있겠다.맥스웰 방정식으로 부터 계산한 전자기파의 속도는 우리가 알고있던 광속과 같았다.이로부터 두 가지 새로운 사실이 등장한다.$(1)$ 빛</description>
    </item>
    
    <item>
      <title>세계선World line과 갈릴레이 변환Galilei transformation</title>
      <link>https://freshrimpsushi.github.io/posts/250/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/250/</guid>
      <description>world line(세계선)입자의 자취를 시간과 공간에 대해서 나타낸 선을 말한다.우선 한 방향으로 등속운동하는 좌표계에 대해서만 생각해보기로하자.$A$좌표계에서 원점에 정지한 입자가 있다.이 입자의 world line은 아래와 같다.** 그리고 $A$좌표계를 기준으로 $+x$방향으로 $v_0$의 속도로 이동하는 $A&#39;$좌표계가 있다.같은</description>
    </item>
    
    <item>
      <title>켤레 복소수의 정의와 성질</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-properties-of-complex-conjugate/</link>
      <pubDate>Sat, 23 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-properties-of-complex-conjugate/</guid>
      <description>정의 $z$를 $z=a+ib(a,b\in \mathbb{R})$인 복소수라고 하자. $\overline{z}$를 다음과 같이 정의하고 $z$의 켤레 복소수(complex conjugatre) 라고 한다. $$ \overline{z}:=\overline{a+ib}=a-ib $$ 원래 복소수에 $i$ 대신 $-i$를 대입한 것, 복소 평면에서 실수 축으로 대칭이동한 것 등으로 설명할 수 있다. &amp;lsquo;켤레&amp;rsquo; 라는 말은 더해서 실수를</description>
    </item>
    
    <item>
      <title>회전의 발산이 항상 0임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-divergence-of-curl-is-always-0/</link>
      <pubDate>Fri, 22 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-divergence-of-curl-is-always-0/</guid>
      <description>회전의 발산은 항상 $0$이다 $$ \nabla \cdot (\nabla \times \mathbf{A})=0 $$ 증명(직교좌표계) $$ \begin{eqnarray*} \nabla \times \mathbf{A} &amp;amp;=&amp;amp; \begin{vmatrix} \hat x &amp;amp; \hat y &amp;amp; \hat z \\ \displaystyle \frac{\partial}{\partial x} &amp;amp; \displaystyle \frac{\partial}{\partial y} &amp;amp; \displaystyle \frac{\partial}{\partial z} \\ A_x &amp;amp; A_y &amp;amp; A_z \end{vmatrix} \\ &amp;amp;=&amp;amp; \hat x \left( \frac{\partial V_z}{\partial y} - \frac{\partial V_y}{\partial z} \right) + \hat y \left( \frac{\partial V_x}{\partial z} - \frac{ \partial V_z}{\partial x} \right) + \hat z \left( \frac{\partial V_y}{\partial x}-\frac{\partial V_x}{\partial y} \right) \end{eqnarray*} $$ 이고 $$ \displaystyle \nabla = \hat x \frac{\partial}{\partial x} + \hat y \frac{\partial }{\partial y} + \hat z \frac{\partial }{\partial z} $$ 이므로 $$ \begin{eqnarray*} \nabla \cdot (\nabla \times \mathbf{A}) &amp;amp;=&amp;amp; \frac{\partial}{\partial x} \left( \frac{\partial V_z}{\partial y} - \frac{\partial V_y}{\partial z} \right) + \frac{\partial}{\partial y} \left(</description>
    </item>
    
    <item>
      <title>직교행렬과 유니터리행렬은 내적과 길이를 보존함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/233/</link>
      <pubDate>Tue, 19 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/233/</guid>
      <description>$A \in \mathbb{R}^{n \times n}$ 가 직교행렬이면 $(A \mathbf{x} )^{T} (A \mathbf{y} ) = \mathbf{x}^{T} \mathbf{y}$ , $ || A\mathbf{x} || = || \mathbf{x} || $ 이 성립한다. $A \in \mathbb{C}^{n \times n}$ 가 유니터리행렬이면 $(A \mathbf{x} )^{ * } (A \mathbf{y} ) = \mathbf{x}^{ * } \mathbf{y}$, $ || A\mathbf{x} || = || \mathbf{x} || $ 이 성립한다.직교행렬Orthogonal Matrix과 유니터리행렬Unitary Matrix을 일차변환의 행렬로 봤을 때,내적의 결과나 놈은 이러한 일차변환에 의해</description>
    </item>
    
    <item>
      <title>구의 관성모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-sphere/</link>
      <pubDate>Sun, 10 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-sphere/</guid>
      <description>반지름이 $a$, 질량이 $m$인 구의 관성모멘트는 다음과 같다. $$ \displaystyle I=\frac{2}{5}ma^2 $$ 반지름이 $a$이고 질량이 $m$인 균일한 구의 관성모멘트를 구해보자. 이전에 구했던 도형들만큼 쉽지는 않지만 천천히 읽으면 따라올 수 있을 것이다. 구의 관성모멘트를 구할 때 가장 중요한 아이디어는 구를 무수히 많은 원판의 합이라고 생각하는 것이다. 구분구적법을 떠올려보라.</description>
    </item>
    
    <item>
      <title>생성 함수란</title>
      <link>https://freshrimpsushi.github.io/posts/generating-function/</link>
      <pubDate>Wed, 30 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generating-function/</guid>
      <description>수열 $\left\{ a_{n} \right\} $ 에 대해 $$ g(x) =\sum \limits _{n=0}^{\infty}a_{n}x^{n}= a_{0} + a_{1} x + a_{2} x^2 + \cdots $$ 와 같은 꼴로 나타나는 함수 $g$를 **수열 $\left\{ a_{n}\right\}$의 생성함수** 또는 간단히 **생성함수** 라고 한다. 수열이 $a_{n}=a_{n}(x)$인 경우 아래와 같이 표기하기도 한다. $$ G(x,t)=\sum \limits _{n=0}^{\infty}a_{n}(x)t^{n} $$ 예리한 독자라면 눈치챘겠지만 테일러 급수 역시 저 비슷한 꼴을 하</description>
    </item>
    
    <item>
      <title>바이어슈트라스 M 판정법 Weierstrasss M Test</title>
      <link>https://freshrimpsushi.github.io/posts/230/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/230/</guid>
      <description>함수 $f_{n}$ 와 $z \in A$ 에 대해 $|f_{n}(z)| \le M_{n}$ 을 만족하는 양수의 수열 $M_{n}$ 이 존재하고 $\displaystyle \sum_{n=1}^{\infty} M_{n}$ 이 수렴하면 $\displaystyle \sum_{n=1}^{\infty} f_{n} $ 은 $A$ 에서 절대수렴하고 균등수렴한다.M 판정법이라는 이름은 수열 $M_{n}$ 에서 따온 것이다.이미 수렴한다는 사실을 아는 $M_{n}$ 을 잘 가져와 함수의 절댓값과 부등식을 세울 수 있으면 그냥 수렴도 아니고 절대수렴과 균등수렴을 동시에 보일 수 있어 유용한 정리다.무엇보</description>
    </item>
    
    <item>
      <title>복소해석을 사용한 테일러 급수 유도</title>
      <link>https://freshrimpsushi.github.io/posts/231/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/231/</guid>
      <description>함수 $f : A \subseteq \mathbb{C} \to \mathbb{C}$ 가 원 $|z - \alpha| &amp;lt; r$ 에서 해석적이면 $$ \displaystyle f(z) = \sum_{n = 0} ^{\infty} {{f^{(n)} (\alpha)} \over {n!}} (z - \alpha)^n $$ 수학의 즐거움 중 하나가 바로 일반화다. 테일러 정리부터가 평균값의 정리를 일반화했다고 할 수 있는데, 이번엔 실수를 복소수로 확장해보자. 재미있는 사실은 꾸역꾸역 확장하는 게 아니라 사실상 처음부터 쌓아올림에도 불구하고 증명은 더 간단해졌다는 것이다. 신</description>
    </item>
    
    <item>
      <title>로체의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-roches-theorem/</link>
      <pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-roches-theorem/</guid>
      <description>$f$ 와 $g$ 가 단순폐경로 $\mathscr{C}$ 에서 해석적이고 $\mathscr{C}$ 상에서 $|g(z)| \le |f(z)|$ 을 만족하면 $f$ 와 $f + g$ 는 $\mathscr{C}$ 내부에서 같은 수의 영점을 갖는다.원래 주어진 함수를 $h = f + g$ 로 생각하고 $f$ 와 $g$ 로 잘 분리해서 쓰는 정리다. 특히 다항함수의 경우엔 이러한 조작이 아주 쉽기 때문에 유용하게 써먹을 수 있다. 또한 수치해석적인 방법과 함께라면 방정식 $h(z) = 0$ 의 해가 구체적으로 어디에</description>
    </item>
    
    <item>
      <title>유리형함수의 영점과 극점</title>
      <link>https://freshrimpsushi.github.io/posts/poles-and-zeros-of-meromorphic-function/</link>
      <pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poles-and-zeros-of-meromorphic-function/</guid>
      <description>단순폐경로 $\mathscr{C}$ 에서 해석적인 함수 $f$ 가 $\mathscr{C}$ 내부에서 $Z$개의 영점과 $P$개의 극점을 갖고 $\mathscr{C}$ 상에서 $f(z) \ne 0$ 이라고 하자. 그러면 $\displaystyle {{1} \over {2 \pi i }} \int_{\mathscr{C}} {{f&#39;(z)} \over {f(z)}} dz = Z - P$참고로 $Z$와 $P$는 중복되는 수를 모두 더한 수다.$f$ 가 극점을 갖지 않는다면 방정식 $f(z) = 0$ 의 해의 갯수를 구하는 공식이 될 것이다.눈여겨봐야할 점은 정수가 등장했다는 것이</description>
    </item>
    
    <item>
      <title>슈발츠 보조정리Schwarzs Lemma 증명</title>
      <link>https://freshrimpsushi.github.io/posts/227/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/227/</guid>
      <description>단위원 $|z| \le 1$ 에서 해석적인 함수 $f$ 에 대해 $f(0) = 0$이고 $ 0 &amp;lt; |z| &amp;lt; 1$ 에서 $|f(z)| \le 1 $ 이라고 하자. 그러면 $|f&#39;(0)| \le 1 $ 이고 $ 0 &amp;lt; |z| &amp;lt; 1$ 에서 $|f(z)| \le |z|$물론 일반성을 잃지 않고 $|z| \le r$ 로 확장할 수 있지만 증명의 편의를 위해 단위원을 잡았다. 증명 새로운 함수 $g$ 를 $\displaystyle g(z) = \cases{ {{f(z)} / {z}} &amp;amp; 0&amp;lt;|z|&amp;lt;1 \\ f&#39;(0) &amp;amp; z=0}$ 로 정의하자.$\displaystyle \lim_{z \to 0} {{f(z)} \over {z}}</description>
    </item>
    
    <item>
      <title>푸아송 적분 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-poissons-integral-formula/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-poissons-integral-formula/</guid>
      <description>$f$ 가 원 $ \mathscr{C} : |z| = r$ 을 포함하는 단순연결영역에서 해석적이라고 하자. 그러면 $ 0 &amp;lt; \rho &amp;lt; r$에 대해 $\displaystyle f( \rho e ^{i \phi} ) = {{1} \over { 2 \pi }} \int_{0}^{2 \pi} {{r^2 - \rho^2 } \over {r^2 - 2 r \rho \cos (\theta - \phi) + \rho ^2 }} f(r e^{i \theta}) d \theta $본질적으로 코시 적분 공식의 변형이다.무수한 잔계산을 거칠 뿐이기 때문에 과정은 한 번 읽어보는 것 외에 큰 가치가 없다. 유도 먼저 $\mathscr{C}$ 내부의 $f(\alpha) \ne 0$ 를 만족하</description>
    </item>
    
    <item>
      <title>가우스의 평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gausss-mean-value-theorem/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gausss-mean-value-theorem/</guid>
      <description>평균값 정리코시의 평균값 정리적분의 평균값 정리함수 $f$ 가 닫힌 원 $| z - z_{0} | \le r $ 에서 해석적이라고 하자. 그러면 $\displaystyle f(z_{0}) = {{1} \over {2 \pi}} \int_{0}^{2 \pi} f(z_{0} + r e ^{i \theta } ) d \theta$미분의 평균값 정리가 일반화를 거치며 여러 수학자의 이름이 붙은 변형 정리를 낳았듯, 적분의 평균값 정리도 무려 가우스의 이름이 붙은 변형이 있다. 그 형태는 의심할나위 없는 적분</description>
    </item>
    
    <item>
      <title>최대절댓값 정리Maximum Modulus Theorem 증명</title>
      <link>https://freshrimpsushi.github.io/posts/225/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/225/</guid>
      <description>함수 $f$ 가 단순폐경로 $\mathscr{C}$ 상에서 연속이고 내부에서 해석적이면서 어떤 점에서도 상수함수가 아니라고 하자. 그러면 $\mathscr{C}$ 에서 $|f(z)|$ 를 가장 크게 하는 $z = z_{0}$ 는 $\mathscr{C}$ 상에 존재한다.쉽게 말해 복소해석에서는 폐경로 내에서 $|f|$의 최댓값은 그 테두리에 존재한다는 것이다.이쯤되면 직관적으로는 따라잡을 수가 없는 수준으로, 왜인지는 모르겠으나 참 신기하다는</description>
    </item>
    
    <item>
      <title>대수학의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-algebra/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-algebra/</guid>
      <description>추상대수의 용어로 표현된 대수학의 기본정리$n$차 다항식 $P(z) = a_{0} + a_{1} x + a_{2} x^2 + \cdots + a_{n} x^{n} = 0$ 은 중근을 포함해서 정확히 $n$개의 해를 갖는다.사실 우리는 다항식을 풀 때 당연히 해가 존재하는마냥 풀고있지만 그게 꼭 그렇다는 보장은 없다.예로써 2차 다항식 $x^2+1 = 0$은 실근이 존재하지 않는다.하지만 여기서 복소수를 허용하면 $\pm i$ 라는 두 해가 존</description>
    </item>
    
    <item>
      <title>복소해석에서의 리우빌의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-complex-analysis/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-complex-analysis/</guid>
      <description>동역학에서의 리우빌 정리$f$ 가 전해석함수고 모든 $z \in \mathbb{C}$ 에 대해 $|f(z)| \le M$을 만족하는 양수 $M$ 이 존재하면 $f$ 는 상수함수다.$f$ 가 전해석함수이라는 말은 복소평면 전체에서 해석적이라는 뜻이다.대우명제로 말하자면 상수함수가 아니면 그 절댓값이 유계bounded가 되지 않는다는 뜻이다.예로써 $\sin$ 은 정의역이 실수집합일 땐 자명하게도 $-1$ 과</description>
    </item>
    
    <item>
      <title>프레넬 사인 적분의 매클로린 전개</title>
      <link>https://freshrimpsushi.github.io/posts/maclaurin-expansion-of-fresnel-sine-integral/</link>
      <pubDate>Sat, 12 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maclaurin-expansion-of-fresnel-sine-integral/</guid>
      <description>$\displaystyle S(x) = \sqrt{{2} \over {\pi}} \int_{0}^{x} \sin (w^2) dw = \sqrt{{2} \over {\pi}} \sum_{n=0}^{\infty} {{(-1)^{n}} \over {(2n+1)! (4n+3)}} x^{4n+3} $프레넬은 광학을 연구했던 물리학자로써 그의 이름이 붙은 결과들을 보면 대개는 삼각함수가 연관되어있다.아무래도 삼각함수가 파동함수와 깊은 연관이 있기 때문에 없는 공식은 만들어내서라도 공부를 해야했을 것이다.이러한 연구들이 광학에 어찌 기여했는지는 몰라도 당장 삼각함수에 대한 미적분에 상당한</description>
    </item>
    
    <item>
      <title>프레넬 적분 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fresnels-integral/</link>
      <pubDate>Sat, 12 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fresnels-integral/</guid>
      <description>$$ \displaystyle \int_{0}^{\infty} \cos x^2 dx = \int_{0}^{\infty} \sin x^2 dx = {{1}\over{2}} \sqrt{{\pi}\over{2}} $$ 프레넬 적분은 언뜻 쉬워 보이지만 보이는것만큼 간단한 결과가 아니다. 단순히 삼각함수의 제곱이라면 쉽겠지만 그 안의 $x$ 에 제곱을 취한 것이기 때문이다. 막상 건드려보면 이 $x$ 가 얼마나 사라지지 않는지 알 수 있을 것이다.함수 안의 변수가 핵심 문제기 때문에 그래프의 개형부터 잘 떠오르지 않는다. 일단 이상적분이 존재하</description>
    </item>
    
    <item>
      <title>e^-x^2꼴의 정적분  가우스 적분오일러-푸아송 적분 Gaussian IntegralEuler-</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-integral/</link>
      <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-integral/</guid>
      <description>정리 가우스 함수 $f(x)=e^{-x^2}$의 전체 영역에 대한 적분은 다음과 같다. $$ \int_{-\infty}^{\infty} e^{-x^2} dx= \sqrt{\pi} $$ 위 적분을 가우스 적분$(\mathrm{Gaussian\ integral})$, 혹은 오일러-푸아송 적분$(\mathrm{Euler-Poisson\ integral})$이라고 부른다. 고등학생에겐 충격적인 적분이자 특히 통계학에선 어마</description>
    </item>
    
    <item>
      <title>이항정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/218/</link>
      <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/218/</guid>
      <description>$$ \displaystyle (x+y)^{n} = \sum_{r=0}^{n} {_n C _r} x^{n} y^{n-r} $$ 고등학교에서 배우는 것 치고는 놀랍게도 배우자마자 여러군데 쓸데가 보이는 정리다. 생김새가 자유롭기 때문에 많은 공식을 단번에 유도해낼 수 있으며 분야를 가리지 않고 많이 쓰인다. 증명 $(x+y)^{n}$ 을 전개할 때 $x^{n} y^{n-r}$ 의 계수는 $(x+y)^{n} = (x+y)(x+y)(x+y) \cdots (x+y)$ 의 각 $(x+y)$ 중에서 $x$를 $n$개, $y$를 $n-r$개 선택하는 것과 같다. 따라서 조합 $_n C r$ 이</description>
    </item>
    
    <item>
      <title>제곱수의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/189/</link>
      <pubDate>Fri, 28 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/189/</guid>
      <description>$\displaystyle \sum_{k=1}^{n} { k^2} = {{n(n+1)(2n+1)} \over {6}}$자연수의 합 공식과 마찬가지로 입시를 준비하면서 굉장히 많이 쓰는 공식 중 하나다.물론 고등학교를 졸업하고나면 자연수의 합만큼 많이 쓰이진 않지만 증명방법이 상당히 재미있다.**증명** 한 차수 더 높은 $k^3$와 $(k-1)^3$의 차를 생각해보자.$1^3 - 0^3 = 3 \cdot 1^2 - 3 \cdot 1 + 1 $$ 2^3 - 1^3 = 3 \cdot 2^2 - 3</description>
    </item>
    
    <item>
      <title>감마함수에 대한 바이어슈트라스의 무한곱</title>
      <link>https://freshrimpsushi.github.io/posts/weierstrasss-infinite-product-for-gamma/</link>
      <pubDate>Wed, 26 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weierstrasss-infinite-product-for-gamma/</guid>
      <description>팩토리얼의 일반화로써의 감마함수 보기감마함수에 대한 오일러의 극한 공식 보기**바이어슈트라스의 무한곱 $$ \displaystyle {1 \over \Gamma(x)} = x e^{\gamma x } \lim_{n \to \infty} \prod_{k=1}^{n} \left( 1 + {x \over k} \right) e^{- {x \over k} } $$ * $\gamma$는 오일러-마스케로니 상수다. $$ \displaystyle \Gamma(x) = \int_{0}^{\infty} t^{x-1} e^{-t} dt $$ 감마 함수는 위와 같이 정의되고, 오일러의 극한 공식에 의해 $$ \displaystyle \Gamma(x) = \lim_{n \to \infty} {{n^x n!} \over {x(x+1)(x+2) \cdots (x+n) }} $$ 이기도 하</description>
    </item>
    
    <item>
      <title>실수의 조밀성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-density-of-real-numbers/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-density-of-real-numbers/</guid>
      <description>두 실수 $a&amp;lt;b$ 에 대해 $a&amp;lt;r&amp;lt;b$ 를 만족하는 $r \in \mathbb{R}$ 이 존재한다실수상에선 그 어떤 구간을 생각하든 그 사이엔 반드시 또 다른 실수가 존재한다. 아무리 작게 쪼개더라도 그곳엔 또 쪼갤 수 있는 점이 있다는 말이다. 당연해보이지만 이는 당연하지 않을 뿐만 아니라 몹시 추상적인 성질이라는 것도 명심하자. 예로써 물리학에서 다루는 물질과 에너지조차도 작게 작게 쪼개다보면 그</description>
    </item>
    
    <item>
      <title>해석학의 여러가지 급수판정법 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/186/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/186/</guid>
      <description>급수판정법들은 별도의 증명 없이 소개만 하고자 한다.증명하는 법 자체보단 팩트로써 잘 활용하는 것이 중요하기도 하고, 대개는 증명 과정도 지루하기 때문이다.발산 판정법 $\displaystyle \lim { n\to \infty }{ { a }{ n }} \ne 0 $ 이면 $\displaystyle \sum { n=1 }^{ \infty }{ { a }{ n }}$ 은 발산한다. 고등학교 때 접할 수 있는 유일한 판정법이다.쉬운만큼 수렴하는 것 자체를 판정할 수는 없는 것이 아쉽지</description>
    </item>
    
    <item>
      <title>해석학에서의 아르키메데스의 원리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-archimedean-principle/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-archimedean-principle/</guid>
      <description>양수 $a$ 와 실수 $b$ 에 대해, $an&amp;gt;b$ 를 만족하는 자연수 $n$이 존재한다.어떤 $b$를 가져오더라도 항상 그보다는 큰 $a$ 의 $n$ 배수를 생각할 수 있다는 뜻이다. 쉽게 말하면 아무리 &amp;lsquo;작은 수라도 계속 더하면 계속 커진다&amp;rsquo;는 아주 상식적이고 당연한 원리다.부력의 원리, 유레카와는 상관이 전혀 없고 이름만 같을 뿐이다.Strate</description>
    </item>
    
    <item>
      <title>해석학의 세 가지 공리 3 완비성 공리</title>
      <link>https://freshrimpsushi.github.io/posts/completeness-axioms/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/completeness-axioms/</guid>
      <description>집합 $E \subset \mathbb{R}$ 이 공집합이 아니고 $E$ 가 위로 유계면 상한 $\sup(E) &amp;lt; \infty$ 가 존재한다.체 공리와 순서 공리는 이미 알던 걸 어렵게 다시 썼지만 완비성 공리는 언뜻 보기에 그렇지가 않다. 우선 여기 등장하는 단어들에 대해서 정의가 필요할 것 같다.**위로 유계$(\mathrm{bounded\ above})$, 상계$(\mathrm{upper\ bound})$, 최소상계$(\mat</description>
    </item>
    
    <item>
      <title>운동량 연산자 유도하기</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-momentum-operator/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-momentum-operator/</guid>
      <description>양자역학에서의 운동량 연산자는 아래와 같다. $$ p_{op}=\frac{\hbar}{i}\frac{\partial}{\partial x} $$ 바로 구해보자$ \displaystyle{ \begin{eqnarray*} \left\langle p \right\rangle &amp;amp;=&amp;amp; \left\langle m\frac{dx}{dt} \right\rangle = m\frac{d}{dt} \left\langle x \right\rangle \\ &amp;amp;=&amp;amp; m\frac{d}{dt} \int_{-\infty}^{+\infty}\psi^\ast x \psi \ dx \\ &amp;amp;=&amp;amp; m\int_{-\infty}^{+\infty} \left( \frac{\partial{\psi}^\ast}{\partial t}x\psi + \psi ^{ * } x \frac{\partial \psi}{\partial t} \right)dx \end{eqnarray*} }$1차원에서 슈뢰딩거 방정식과 그 복소 켤레는 아래와 같다.$\displaystyle{ \begin{eqnarray*} \Rightarrow i\hbar \frac{\partial \psi}{\partial t} &amp;amp;=&amp;amp; -\frac{{\hbar}^2}{2m}\frac{\partial ^2 \psi}{\partial x^2}+U\psi \\ \frac{\partial \psi}{\partial t}&amp;amp;=&amp;amp;-\frac{\hbar}{2mi}\frac{\partial ^2 \psi}{\partial x^2}+\frac{U\psi}{i\hbar} \end{eqnarray*} } $ $\displaystyle{ \begin{eqnarray*} \Rightarrow -i\hbar \frac{\partial \psi ^{ * }}{\partial t} &amp;amp;=&amp;amp;-\frac{{\hbar}^2}{2m}\frac{\partial ^2 \psi ^{ * }}{\partial x^2}+U^{</description>
    </item>
    
    <item>
      <title>전자가 핵의 성분이 될 수 없음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/184/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/184/</guid>
      <description>$10^{-14}m$ 정도의 크기를 가지는 핵은 $1MeV \sim10MeV$범위의 에너지를 가지는 전자를 방출한다.핵물리의 초기 시절에는 전자가 핵 안에 존재한다고 믿었다.불확정성 원리를 이용하여 그런 에너지를 가지는 전자는 핵 내부에 얽매일 수 없음을 보여라.(가시오로비츠 양자역학 2장 연습문제 21번)전자가 원자핵 안에 있다고 가정하면 불확정성 원리에 의해$</description>
    </item>
    
    <item>
      <title>해석학의 세 가지 공리 1 체 공리</title>
      <link>https://freshrimpsushi.github.io/posts/field-axioms/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/field-axioms/</guid>
      <description>추상대수학에서의 체 보러가기실수 $ a,b,c \in \mathbb{R}$ 와 연산 $+,\cdot$ 에 대해 다음의 성질들이 성립한다고 받아들이자.(A1) 덧셈에 대한 폐쇄성 : $a+b \in \mathbb{R}$(A2) 덧셈에 대한 결합법칙 : $(a+b) + c = a + (b+c)$(A3) 덧셈에 대한 교환법칙 : $ a+ b= b + a$(A4) 덧셈에 대한 항등원 : 모든 실수 $a$에 대해, $a+0=0+a=a$를 만족하는 $0$이 유일하게 존재한다.(A5) 덧셈에 대</description>
    </item>
    
    <item>
      <title>해석학의 세 가지 공리 2 순서 공리</title>
      <link>https://freshrimpsushi.github.io/posts/order-axioms/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order-axioms/</guid>
      <description>실수 $ a,b,c \in \mathbb{R}$ 에 대해, 다음의 성질들이 성립한다고 받아들이자.삼분성 : 주어진 $a,b$ 에 대해서, $a&amp;lt;b$ 혹은 $a&amp;gt;b$ 혹은 $a=b$ 이어야한다추이성 : $a&amp;lt;b$ 이고 $b&amp;lt;c$이면 $a&amp;lt;c$가산성 : $a&amp;lt;b$ 이고 $c\in \mathbb{R}$ 이면 $ a+ c&amp;lt; b + c$승산성 : $a&amp;lt;b$ 이고 $c&amp;gt;0$ 이면 $ ac&amp;lt; bc$, 혹은 $c&amp;lt;0$ 이면 $ ac&amp;gt; bc$단어들은 상당히 옛날것이지만 너무 당연한 사실들이라 이해하는데는 문제</description>
    </item>
    
    <item>
      <title>광자의 속도가 c일 때 정지 질량이 0임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/183/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/183/</guid>
      <description>1. 상대론적 에너지, 운동량과 속도의 관계 $p=\gamma m_0 v $$ E=\gamma m_0 c^2 $$ \Rightarrow \gamma m_0=\dfrac{E}{c^2}$두 식을 연립하면$p=\dfrac{E}{c^2}v $$ \Rightarrow v=\dfrac{pc^2}{E}$2. 입자의 에너지와 운동량의 상대론적 관계 $E=\sqrt{{m_0}^2c^4+p^2c^2}$3. 1과 2에 의해서 $ \displaystyle v=\frac{pc^2}{\sqrt{{m_0}^2c^4+p^2c^2}}$이 때 광자의 속도는</description>
    </item>
    
    <item>
      <title>컴프턴 산란</title>
      <link>https://freshrimpsushi.github.io/posts/compton-scattering/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compton-scattering/</guid>
      <description>컴프턴 산란 $\lambda$를 입사하는 빛의 파장, $\lambda&#39;$을 산란된 광자의 파장이라고 하자. 그러면 아래의 식이 성립한다. $$ \lambda&#39; -\lambda = \frac{h}{m_{e}c}(1-\cos\theta) $$ 이때 $h$는 플랑크 상수, $m_{e}$는 전자의 질량, $c$는 빛의 속도, $\theta$는 산란각이다. 에너지에 대해서 나타내면 $$ \cos \theta=1-\frac{m_{e}c^{2}(E-E&#39;)}{E&amp;rsquo;E} $$ 컴프턴 산란1은 X선이 전자와 만났을 때</description>
    </item>
    
    <item>
      <title>등비수열의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/170/</link>
      <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/170/</guid>
      <description>초항이 $a$고 공비가 $r$인 등비수열 $a_{n} = a r^{n-1}$에 대해, $\displaystyle \sum_{k=1}^{n} a_{k}= {{a (1- r^{n} ) } \over {1-r}}$등차수열의 합과는 달리 이 자체만으로도 굉장히 많이 쓰이는 공식이다. 증명법도 조금 다를 뿐이라서 따로 더 공부해야할만큼 어렵지는 않다.**증명** $\displaystyle S= \sum_{k=1}^{n} a_{k}$ 라고 하자. 그러면 $$ S= a + ar + \cdots + ar^{n-2} + ar^{n-1} $$ 양변에 $r$을 곱하면 $$ rS=</description>
    </item>
    
    <item>
      <title>등차수열의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/169/</link>
      <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/169/</guid>
      <description>초항이 $a$ 고 공차가 $d$ 인 등차수열 $a_{n} = a+(n-1)d $ 에 대해 $$ \displaystyle \sum_{k=1}^{n} a_{k}= {{n \left\{ 2a + (n-1)d \right\} } \over {2}} $$ 처음에 한 번 보고는 다시 이 형태로 쓸 일이 없긴 한 급수지만 이 모양을 잊되 증명을 잊어서는 안 된다. 증명이 쉽고 간단하다고 해도 한번정도는 반드시 손으로 직접 쓰면서 익혀보도록 하자. 증명 $$ \begin{eqnarray*} S:= \sum_{k=1}^{n} a_{k} \end{eqnarray*} $$ 라고 두면 $$ S= a + (a+d) + \cdots + (a + (n-2)d) + (a + (n-1)d) $$ 인데, 이 순서를 거꾸</description>
    </item>
    
    <item>
      <title>직교좌표계에서의 속도와 가속도</title>
      <link>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-cartesian-coordinate-system/</link>
      <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-cartesian-coordinate-system/</guid>
      <description>극좌표계에서 속도와 가속도원통좌표계에서 속도와 가속도구좌표계에서 속도와 가속도직교좌표계에서의 속도와 가속도 $$ \begin{align*} \mathbf{v}&amp;amp;=\dot x \hat{\mathbf{x}} + \dot y \hat{\mathbf{y}} +\dot z \hat{\mathbf{z}} \\ \mathbf{a} &amp;amp;= \ddot x \hat{\mathbf{x}} + \ddot y \hat{\mathbf{y}} +\ddot z \hat{\mathbf{z}} \end{align*} $$ 너무 당연한 사실 같아서 안썼지만 그래도 하는 마음에 추가했다. 직교좌표계에서 속도와 가속도를 구하는건 아주 간단하다.**속도** $$ \mathbf{v}=\frac{d}{dt}(x\hat x +y\hat y+z\hat z)=\dot x \hat{\mathbf{x}}+\dot y \hat{\mathbf{y}}+\dot z \hat{\mathbf{z}} $$ 직</description>
    </item>
    
    <item>
      <title>기울기가 m인 원의 접선의 방정식 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/172/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/172/</guid>
      <description>원 $x^{2}+y^{2}=r^{2}$의 기울기가 $m$인 접선의 방정식은 다음과 같다. $$ y=mx \pm r\sqrt{m^{2}+1} $$ 증명** 기울기가 $m$인 직선의 방정식을 $y=mx+n$이라고 하자. 원의 방정식에 대입하고 x에 대해서 정리하면 $$ \begin{align*} x^2+(mx+n)^2&amp;amp;=r^2 \\ x^2+m^2x^2+2mnx+n^2-r^2&amp;amp;=0 \\ (1+m^2)x^2+2mnx+n^2-r^2&amp;amp;=0 \end{align*} $$ 원과 직선이 접하므로 판별식$D=0$이다. $$ \begin{align*} D&amp;amp;=(2mn)^2-4(1+m^2)(n^2-r^2) \\ &amp;amp;= 4m^2n^2-4(n^2-r^2+m^2n^2-m^2r^2) \\ &amp;amp;= 4m^2n^2-4n^2+4r^2-4m^2n^2+4m^2r^2 \\ &amp;amp;= -4(n^2-r^2-m^2r^2)=0 \end{align*} $$ 따라서 $$ \begin{align*} &amp;amp;&amp;amp;n^2 &amp;amp;=r^2m^2+r^2=r^2(m^2+1) \\</description>
    </item>
    
    <item>
      <title>쌍곡함수의 미분법</title>
      <link>https://freshrimpsushi.github.io/posts/derivatives-of-hyperbolic-function/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivatives-of-hyperbolic-function/</guid>
      <description>$$ \displaystyle \left( \sinh x \right)&#39; = \cosh x $$ $$ \displaystyle \left( \cosh x \right)&#39; = \sinh x $$ $$ \displaystyle \left( \tanh x \right)&#39; = \text{sech}^{2} x $$ Strategy : 쌍곡함수의 미분법은 사실 증명할 것도 외울 것도 별로 없다. 증명은 그냥 단순히 정의를 이용할 뿐이고 모양새도 삼각함수에서 부호만 뗀 정도기 때문이다. 하이퍼보릭 사인에 대한 증명법으로 하이퍼볼릭 코사인의 도함수도 쉽게 구할 수 있다. 하이퍼볼릭 탄젠트의 도함수는 분수의 미분</description>
    </item>
    
    <item>
      <title>역삼각함수의 미분법</title>
      <link>https://freshrimpsushi.github.io/posts/derivatives-of-inverse-trigonometric-function/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivatives-of-inverse-trigonometric-function/</guid>
      <description>$$ \leqalignno{ \left( \sin^{-1}x \right)&#39; &amp;amp;= {{1} \over {\sqrt{1-x^2}}} &amp;amp;(a) \\ \left( \cos^{-1}x \right)&#39; &amp;amp;= -{{1} \over {\sqrt{1-x^2}}} &amp;amp; (b) \\ \left( \tan^{-1}x \right)&#39; &amp;amp;= {{1} \over {1+x^2}} &amp;amp; (c)} $$ 각각 아크사인, 아크코사인, 아크탄젠트 로 읽는다. 세상에 이런 것도 미분이 되나 싶지만 알고보면 생각보다 꽤 단순하다. 우변을 보면 알겠지만 도함수들의 모양이 그닥 생소하거나 복잡하지가 않다. 삼각함수와는 전혀 상관 없을지라도 여기저기서 쓰일데가 많으니 증명은 외워두도록</description>
    </item>
    
    <item>
      <title>원 위의 한 점에서의 접선의 방정식 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/173/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/173/</guid>
      <description>원$x^2+y^2=r^2$위의 한 점$(x_1,y_1)$에서의 접선의 방정식을 구해보자.$y_1\neq 0$인 경우와 $y_1=0$인 경우로 나눌 수 있다.1. $y_1\neq 0$인 경우 원의 중심에서 점까지의 기울기가 $\displaystyle \frac{y_1}{x_1}$이고 접선과 수직이므로 접선의 기울기는 $\displaystyle -\frac{x_1}{y_1}$(</description>
    </item>
    
    <item>
      <title>곱셈공식 표</title>
      <link>https://freshrimpsushi.github.io/posts/171/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/171/</guid>
      <description>자주쓰이는 곱셈공식들을 소개한다. $1. $ $\begin{eqnarray*} (a+b)^2=a^2+2ab+b^2 \\ (a-b)^2=a^2-2ab+b^2 \end{eqnarray*} $$ 2. $ $(a+b)(a-b)=a^2-b^2 $$ 3. $ $\begin{eqnarray*} (a+b)^3=a^3+3a^2b+3ab^2+b^3 \\ (a-b)^3=a^3-3a^2b+3ab^2-b^3 \end{eqnarray*} $$ 4. $ $(a+b+c)^2=a^2+b^2+c^2+2ab+2bc+2ca $$ 5. $ $\begin{eqnarray*} (a+b)(a^2-ab+b^2)=a^3+b^3 \\ (a-b)(a^2+ab+b^2)=a^3-b^3 \end{eqnarray*}$</description>
    </item>
    
    <item>
      <title>구좌표계에서의 속도와 가속도</title>
      <link>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-sperical-coordinate-system/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-sperical-coordinate-system/</guid>
      <description>**** 직교좌표계에서 속도와 가속도극좌표계에서 속도와 가속도원통좌표계에서 속도와 가속도구좌표계에서의 속도와 가속도 $$ \begin{align*} \mathbf{v} &amp;amp;=\dot r \hat {\mathbf{r}} +r \dot \theta \hat{ \boldsymbol{\theta}}+ r \dot \phi \sin{\theta} \hat{ \boldsymbol{\phi}} \\ \mathbf{a} &amp;amp;= (\ddot{r}-r\dot\theta^2-r\dot\phi^2\sin^2\theta)\hat{\mathbf{r}}+(r\ddot\theta+2\dot{r}\dot\theta-r\dot\phi^2\sin\theta\cos\theta)\hat{\boldsymbol{\theta}} \\ &amp;amp;\quad+(r\ddot\phi\sin\theta+2\dot{r}\dot\phi\sin\theta+2r\dot\theta\dot\phi\cos\theta)\hat{\boldsymbol{\phi}} \end{align*} $$ 구면좌표계에서 단위 벡터는 아래와 같다. $$ \begin{align*} \hat{\mathbf{r}} &amp;amp;= \cos \phi \sin \theta \hat{\mathbf{x}} + \sin \phi \sin \theta \hat{\mathbf{y}} + \cos\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\theta}} &amp;amp;= \cos\phi \cos\theta \hat{\mathbf{x}} + \sin\phi \cos\theta \hat{\mathbf{y}} - \sin\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\phi}} &amp;amp;= -\sin\phi \hat{\mathbf{x}} + \cos\phi \hat{\mathbf{y}} \end{align*} $$ 이제 구면좌표계에서 속도와 가속도</description>
    </item>
    
    <item>
      <title>그린의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-greens-theorem/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-greens-theorem/</guid>
      <description>곡선 $\mathcal{C}$ 가 평면 상의 영역 $S = [a,b] \times [c,d]$ 안에서 양의 방향을 가지고 piecewise smooth인 simple closed contour 이라고 하자. 함수 $P,Q : \mathbb{R}^2 \to \mathbb{R}$이 $\mathcal{C}$ 에서 연속이고 그 도함수도 연속이면 $$ \displaystyle \int_{\mathcal{C}} (Pdx + Qdy) = \iint_{S} (Q_{x} - P_{y}) dx dy $$ 경로적분을 면적분으로 바꿔주는 정리로 생각하면 될 것 같다. 케빈-스톡스 정리에서 평면에 국한시킨 따름정리로도 많이 알려져있다. 더 일</description>
    </item>
    
    <item>
      <title>푸비니의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fubinis-theorme/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fubinis-theorme/</guid>
      <description>2차원 영역 $R : [a,b] \times [c,d]$ 에 대해 함수 $f : R \to \mathbb{R}$ 을 정의하자. $f(x,\cdot)$ 가 $[c,d]$ 에서 적분가능하고 $f(\cdot,y)$ 가 $[a,b]$ 에서 적분가능하며 $f$ 가 $R$ 에서 적분가능하면 $$ \displaystyle \iint {R} f dA = \int{a}^{b} \int_{c}^{d} f(x,y) dy dx = \int_{c}^{d} \int_{a}^{b} f(x,y) dx dy $$ 적분영역인 $R$ 은 당연히 Rectangle에서 나온 것이다.해석학이 늘 그렇듯 말이 너무 길어서 읽기 싫은 여러분들을 위해 요약하자면, 직교하는 두 방향으로 각각 적분</description>
    </item>
    
    <item>
      <title>ML 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-ml-lemma/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-ml-lemma/</guid>
      <description>함수 $f$ 가 contour $\mathscr{C} : z = z(t), t \in [a,b]$ 에서 부분적 연속라고 하자. 양수$\displaystyle L = \int_{a}^{b} |z&#39;(t)| dt$ 는 $\mathscr{C}$ 의 길이고, $\mathscr{C}$ 상의 모든 점에 대해 $|f(z)| \le M$ 을 만족하는 양수 $M$ 이 존재한다면, $$ \displaystyle \left| \int_{\mathscr{C}} f(z) dz \right| \le ML $$ &amp;lsquo;부분적 연속&amp;rsquo;이란 piecewise continuous를 임의로 번역한 말로, 유한개의 점을 제외하곤 연속이라는 의미다</description>
    </item>
    
    <item>
      <title>원통좌표계에서의 속도와 가속도</title>
      <link>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-cylinderical-coordinate-system/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-cylinderical-coordinate-system/</guid>
      <description>직교좌표계에서 속도와 가속도극좌표계에서 속도와 가속도구좌표계에서 속도와 가속도원통좌표계에서 속도와 가속도 $$ \begin{align*} \mathbf{v}&amp;amp;=\dot r \hat{\mathbf{r}} + r \dot \phi \hat{\boldsymbol{\phi}}+\dot z \hat{\mathbf{z}} \\ \mathbf{a} &amp;amp;= (\ddot r -r\dot \phi ^2)\hat{\mathbf{r}} + (2\dot r \dot \phi + r\ddot \phi)\hat{\boldsymbol{\phi}} + \ddot z \hat{\mathbf{z}} \end{align*} $$ 원통좌표계에서 단위 벡터는 아래와 같다. $$ \begin{align*} \boldsymbol{\rho}&amp;amp;=x\hat{\mathbf{x}}+y \hat{\mathbf{y}} +z\hat{\mathbf{z}}=r\hat{\mathbf{r}} +z\hat{\mathbf{z}} \\ \hat{\mathbf{r}} &amp;amp;= \frac{x}{r}\hat{\mathbf{x}} +\frac{y}{r} \hat{\mathbf{y}}=\cos\phi \hat{\mathbf{x}} + \sin\phi \hat{\mathbf{y}} \\ \hat{\boldsymbol{\phi}} &amp;amp;= -\sin\phi \hat{\mathbf{x}} + \cos\phi \hat{\mathbf{y}} \\ \hat{\mathbf{z}} &amp;amp;= \hat{\mathbf{z}} \end{align*} $$ 속도는 위치를 시간에 대해 미분해서, 가속</description>
    </item>
    
    <item>
      <title>코시-리만 방정식의 역이 성립하는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/160/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/160/</guid>
      <description>함수 $ f : A \subseteq \mathbb{C} \to \mathbb{C}$ 가 실수값을 가지는 함수 $u,v$에 대해 $f(z) = f(x+iy) = u(x,y) + iv(x,y)$로 나타날 수 있고 $u,v$는 $x,y$에 대한 연속일차편도함수가 존재하는 동시에 연립미분방정식 $\begin{cases} u_{x} (x,y) = v_{y} (x,y) \\ u_{y} (x,y) = -v_{x} (x,y) \end{cases}$을 만족한다면, $f$는 $A$에서 해석적이다.해석학은 항상 이렇게 말이 길어서 읽기도 싫</description>
    </item>
    
    <item>
      <title>피타고라스의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pythagorean-theorem/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pythagorean-theorem/</guid>
      <description>직각삼각형의 빗변의 길이를 $c$, 나머지 두 변의 길이를 $a,b$라고 하면 아래의 식이 성립한다. $$ a^2 + b^2 = c^2 $$ 여기저기서 쓰이는 건 둘째치고 그 자체만으로도 매우 실용적인 정리다. 가장 오래된 &amp;lsquo;증명&amp;rsquo;을 남긴 것이 피타고라스기 때문에 그 이름이 붙었지만, 실제로 문명을 이루었다고 할 수 있는 고대인들 대부분 팩트 자체는 알</description>
    </item>
    
    <item>
      <title>극좌표계에서 속도와 가속도</title>
      <link>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-polar-coordinate-system/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-polar-coordinate-system/</guid>
      <description>직교좌표계에서 속도와 가속도원통좌표계에서 속도와 가속도구좌표계에서 속도와 가속도**극좌표계에서 속도와 가속도 $$ \begin{align*} \mathbf{v}&amp;amp;=\dot r \hat{\mathbf{r}} + r \dot \theta \hat{\boldsymbol{\theta}} \\ \mathbf{a}&amp;amp;= (\ddot r -r\dot \theta ^2)\hat{\mathbf{r}} + (2\dot r \dot \theta + r\ddot \theta)\hat{\boldsymbol{\theta}} \end{align*} $$ 극좌표계에서 단위 벡터는 아래와 같다. $$ \begin{align*} &amp;amp;&amp;amp; \mathbf{r}&amp;amp;=r\hat{\mathbf{r}}=x\hat{\mathbf{x}} + y \hat{\mathbf{y}} \\ \Rightarrow &amp;amp;&amp;amp; \hat{\mathbf{r}} &amp;amp;= \frac{x}{r}\hat{\mathbf{x}} +\frac{y}{r} \hat{\mathbf{y}}=\cos\theta \hat{\mathbf{x}} + \sin\theta \hat{\mathbf{y}} \end{align*} $$ $$ \hat \theta =\hat{\mathbf{r}}(\theta+\pi/2)= -\sin\theta \hat{\mathbf{x}} + \cos\theta \hat{\mathbf{y}} $$ 속도는 위치를 시간에 대해 미분해서, 가속도는 속도를</description>
    </item>
    
    <item>
      <title>드 무아브르의 정리를 이용한 삼각함수의 삼배각 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/154/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/154/</guid>
      <description>$\sin 3\theta = 3 \sin \theta - 4 \sin^{3} {\theta} $$ \cos 3\theta = 4 \cos^{3} {\theta} - 3 \cos \theta $기존의 변형 공식들은 보통 삼각함수의 덧셈정리를 여러번 써서 얻을 수 있었다.예를 들어 배각 공식은 $\sin(a + b ) = \sin {a} \cos {b} + \sin {b} \cos {a}$에서$b=a$를 대입해 $\sin(a+a) = \sin{2a} = 2 \sin{a} \cos{a}$ 을 얻는 식이다.물론 이런 방식으로 삼배각, 사배각 공식을 유도하는 것에는 아무런 문제가 없다.하지만 복소해석을 이용</description>
    </item>
    
    <item>
      <title>삼각함수와 쌍곡함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/157/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/157/</guid>
      <description>쌍곡함수 $\sinh$와 $\cosh$를 아래와 같이 정의하자. $$ \displaystyle \sinh z = { {e^{z} - e^{-z}} \over 2 } $$ $$ \displaystyle \cosh z = { {e^{z} + e^{-z}} \over 2 } $$ 그러면 아래 등식들이 성립한다. $$ \sinh (iz) = i \sin z $$ $$ \sin (iz) = i \sinh z $$ $$ \cosh (iz) = \cos z $$ $$ \cos (iz) = \cosh z $$ 쌍곡함수를 처음 접할때 가장 이해가 되지 않는 것이 바로 &amp;lsquo;왜 이런 정의를 쓰는가&amp;rsquo; 하는 점이</description>
    </item>
    
    <item>
      <title>삼각함수와 지수함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/155/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/155/</guid>
      <description>$$ \displaystyle \sin z = { {e^{iz} - e^{-iz}} \over 2 i } $$ $$ \displaystyle \cos z = { {e^{iz} + e^{-iz}} \over 2 } $$ 사실 정리라기보단 그냥 정의라고 생각해도 좋다. 이렇게 정의를 했을 때 기존에 밝혀진 정리들과 충돌이 없다 것을 보이기 위함이다. 증명 또한 이미 오일러 공식으로 알고 있던 것을 삼각함수에 맞게 정리한 것 뿐이다.증명 오일러 공식 $\displaystyle { e }^{ ix }= \cos x + i \sin x $오일러 공식에 의해 $$ \displaystyle \begin{cases} { e }^{</description>
    </item>
    
    <item>
      <title>코시-리만 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/the-cauchy-riemann-equations/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-cauchy-riemann-equations/</guid>
      <description>함수 $ f : A \subseteq \mathbb{C} \to \mathbb{C}$가 $\mathscr{R}$에서 해석적이라고 하자. 만약 실수값을 가지는 함수 $u,v$에 대해 $f(z) = f(x+iy) = u(x,y) + iv(x,y)$이라면 $u,v$는 $x,y$에 대한 일차편도함수가 존재하며 $\mathscr{R}$ 상의 모든 점에서 아래의 연립미분방정식을 만족시킨다.$\begin{cases} u_{x} (x,y) = v_{y} (x,y)</description>
    </item>
    
    <item>
      <title>오일러-마스케로니 상수의 수렴성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-convergence-of-euler-mascheroni-constant/</link>
      <pubDate>Sun, 16 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-convergence-of-euler-mascheroni-constant/</guid>
      <description>$$ \displaystyle \gamma = \lim_{n \to \infty} \left( \sum_{k=1}^{n} \left( { 1 \over k } \right) - \ln{n} \right) = 0.577215664 \cdots $$ 리만-제타 함수와 연관짓자면 $\gamma$ $0$번째 스틸체스 상수 $\gamma_{0}$ 기도 하다. $\gamma$ 는 짧게는 그냥 **오일러 상수** 라고도 불리는 수로써, 감마 함수와 깊은 관계가 있다. 정확한 값은 둘째치고, 일단 수렴을 하기는 하는걸까? $\ln{n}$ 와 조화급수 $\displaystyle \sum_{k=1}^{n} \left( { 1 \over k } \right) $ 가 발산하므로 $$ \displaystyle \lim_{n \to \infty} \left( \sum_{k=1}^{n} \left( { 1 \over k</description>
    </item>
    
    <item>
      <title>직교좌표계의 단위벡터로 표현한 구면좌표계의 단위벡터</title>
      <link>https://freshrimpsushi.github.io/posts/152/</link>
      <pubDate>Sun, 16 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/152/</guid>
      <description>구면좌표계의 단위벡터를 직교좌표계의 단위벡터로 표현하면 아래와 같다. $$ \begin{align*} \hat{\mathbf{r}} &amp;amp;= \cos\phi \sin\theta\hat{\mathbf{x}} + \sin\phi \sin\theta\hat{\mathbf{y}} + \cos\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\theta}} &amp;amp;= \cos\phi \cos\theta \hat{\mathbf{x}} + \sin\phi \cos\theta \hat{\mathbf{y}} - \sin\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\phi}} &amp;amp;= -\sin\phi \hat{\mathbf{x}} + \cos\phi \hat{\mathbf{y}} \end{align*} $$ $\hat{\mathbf{r}}$을 먼저 구한 뒤 이를 이용해서 나머지 둘을 구한다.**증명** $$ \hat{\mathbf{r}}=r\hat{\mathbf{r}}=x\hat{\mathbf{x}}+y\hat{\mathbf{y}}+z\hat{\mathbf{z}} $$ 이므로 양변을 $r$로 나누면 $$ \begin{eqnarray*} \hat{\mathbf{r}}&amp;amp;=&amp;amp;\frac{x}{r}\hat{\mathbf{x}}+\frac{y}{r}\hat{\mathbf{y}}+\frac{z}{r}\hat{\mathbf{z}} \\ &amp;amp;=&amp;amp; \frac{x}{r \sin\theta}\sin\theta\hat{\mathbf{x}}+\frac{y}{r \sin\theta}\sin\theta\hat{\mathbf{y}}+\cos\theta\hat{\mathbf{z}} \\ &amp;amp;=&amp;amp; \cos\phi \sin\theta \hat{\mathbf{x}} + \sin\phi \sin\theta\hat{\mathbf{y}} + \cos\theta\hat{\mathbf{z}} \end{eqnarray*} $$ $\ha</description>
    </item>
    
    <item>
      <title>감마함수에 대한 오일러의 극한 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-eulers-limit-formula-for-gamma/</link>
      <pubDate>Sat, 15 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-eulers-limit-formula-for-gamma/</guid>
      <description>팩토리얼의 일반화로써의 감마함수 보기감마함수에 대한 바이어슈트라스 무한곱 보기 $$ \displaystyle \Gamma(x) = \lim_{n \to \infty} {{n^x n!} \over {x(x+1)(x+2) \cdots (x+n) }} $$ 기존에 알고 있던 감마함수는 $\displaystyle \Gamma(x) = \int_{0}^{\infty} t^{x-1} e^{-t} dt$ 의 모양이다. 전혀 닮지 않았지만 두 표현이 완전히 같음을 1729년에 오일러가 증명해냈다.이 글에서 소개하려는 것은 원래보다는 조금 약식이지만 이해하는데에 본질적인 문제는 없을 것이</description>
    </item>
    
    <item>
      <title>백캡BAC-CAB공식을 이용한 간단한 수식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/146/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/146/</guid>
      <description>BAC-CAB(백캡) 공식 $ \vec{A} \times (\vec{B} \times \vec{C} )= \vec{B}(\vec{A} \cdot \vec{C} )-\vec{C}(\vec{A} \cdot \vec{B}) $백캡 공식을 이용하여 아래의 수식을 증명해보자.(그리피스 전자기학 문제 1.6)정말 간단하다.$[\vec{A} \times (\vec{B} \times \vec{C})] +[\vec{B} \times (\vec{C} \times \vec{A})] +[\vec{C} \times (\vec{A} \times \vec{B})] = 0$**증명 BAC-CAB 공식에 의해$ \vec{A} \times (\vec{B} \times \vec{C})=\vec{B}(\vec{A} \cdot \vec{C}) -\vec{C} (\vec{A} \cdot \vec{B}) $$ \vec{B} \times (\vec{C} \times \vec{B})=\vec{C}(\vec{B} \cdot \vec{A}) -\vec{A} (\vec{B} \cdot \vec{C}) $$ \vec{C} \times (\vec{A} \times \vec{B})=\vec{A}(\vec{C} \cdot \vec{B}) -\vec{B} (\vec{C} \cdot \vec{A})$</description>
    </item>
    
    <item>
      <title>스칼라 삼중곱의 특징</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-scalar-triple-product/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-scalar-triple-product/</guid>
      <description>스칼라 삼중곱은 벡터 3개를 곱하는 연산 중에서 결과가 스칼라인 것을 말한다. 결과가 벡터인 것은 벡터 삼중곱이라 한다. 결과가 스칼라로 나오기 위해서는 우선 두 벡터를 외적해서 나온 벡터와 다른 벡터를 내적해야한다. 즉, 수식은 아래와 같은 모양이다. $$ \mathbf{A}\cdot (\mathbf{B} \times \mathbf{C} ) $$ 스칼라 삼중곱의 특징을 하나씩 살펴보자.1. 스칼라 삼중곱의 크기는 세 벡터가 만드</description>
    </item>
    
    <item>
      <title>적분을 이용한 타원의 넓이 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/145/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/145/</guid>
      <description>타원의 둘레타원 ${x^2 \over a^2} + {y^2 \over b^2} = 1$ 의 넓이는 $ab \pi$특히 $a=b=r$, 즉 반지름이 $r$ 인 원 $x^2 + y^2=r^2$ 의 넓이는 익히 아는대로 $r^2 \pi$ 다. 증명** 타원의 넓이를 구하기 위해선 색칠된 영역의 넓이만 구하면 충분하다. 영역의 넓이는 $$ \displaystyle \int _{0} ^{a} \sqrt{b^2-{b^2 \over a^2} x^2} dx $$ 로 주어진다. $x = a \sin \theta $ 로 치환을 하면 $$ \begin{eqnarray*} \int _{0} ^{ \pi \over 2 } b \sqrt{1 - \sin ^ 2 \theta } a \cos \theta d \theta &amp;amp;=&amp;amp; ab \int _{0} ^{ \pi \over</description>
    </item>
    
    <item>
      <title>분리벡터</title>
      <link>https://freshrimpsushi.github.io/posts/separation-vector/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separation-vector/</guid>
      <description>원천점에서 관찰점까지의 벡터를 분리 벡터라 한다. $$ \boldsymbol{\eta} = \mathbf{r} - \mathbf{r}&#39; $$ ** **분리벡터$(\mathrm{separation\ vector})$ ** $\boldsymbol{\eta}$ : 위치벡터와 근원벡터(원천벡터)의 차.근원벡터$(\mathrm{source\ vector})$ $\mathbf{r}&#39;$ : 전하나 전류가 있는 곳. 즉, 전자기장을 만드는 근원지.위치벡터$(\mathrm{position\</description>
    </item>
    
    <item>
      <title>분리벡터의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-of-separation-vector/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-of-separation-vector/</guid>
      <description>분리 벡터 $\boldsymbol{\eta}$의 크기의 $n-$제곱인 $\eta ^{n}$의 그래디언트는 다음과 같다. $$ \nabla (\eta^n)=n\eta^{n-1}\hat{\boldsymbol{\eta}} $$ 분리 벡터는 $\boldsymbol{\eta}=\mathbf{r}-\mathbf{r&#39;}$이므로 $(x,y,z)$와 $(x&#39;,y&#39;,z&#39;)$를 변수로 가진다. 따라서 미분할 때 이에 주의해야</description>
    </item>
    
    <item>
      <title>수직선위의 내분점과 외분점 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/138/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/138/</guid>
      <description>수직선위의 점$A(x_1)$와 점$B(x_2)$를 $m:n$으로 내분하는 점$P(x)$의 좌표는 $\displaystyle x=\frac{mx_2+nx_1}{m+x}$이고, $m:n$으로 외분하는 점$Q(x)$의 좌표는 $ \displaystyle x=\frac{mx_2-nx_1}{m-n}$이다.내분점 ** $\overline{AP}:\overline{PB} = m:n $$ x-x_1:x_2-x=m:n $$ mx_2-mx=nx-nx_1 $$ mx+nx=mx_2+nx_1 $$ (m+n)x=mx_2+nx_1 $$ \displaystyle x=\frac</description>
    </item>
    
    <item>
      <title>실수의 허수승의 크기는 항상 1임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/126/</link>
      <pubDate>Thu, 29 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/126/</guid>
      <description>0이 아닌 실수 $r, \theta$에 대해 $$ |r^{i \theta}| = 1 $$ 흔히 $\left| e^{i \theta} \right| = 1$ 는 잘 숙지하고 있지만 밑이 딱히 $e$ 가 아닌 어떤 실수라도 상관없다는 건 떠올리기 어렵다. 생각해보면 당연히 성립이야하겠지만 이렇게는 잘 쓸 일이 없어서다. 증명 $\theta = 0 $ 이면 $r^0=1$ 이므로 당연히 $\left| r^{i \theta} \right| = \left| r^{i \cdot 0} \right| = 1$ 이 성립한다.$\theta \ne 0 $ 이면 $$ \left| r^{i \theta} \right| = \left| e^{i</description>
    </item>
    
    <item>
      <title>테일러 전개를 통한 오일러 공식 유도와 오일러 등식 그리고</title>
      <link>https://freshrimpsushi.github.io/posts/ii/</link>
      <pubDate>Tue, 23 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ii/</guid>
      <description>**1. 오일러 공식: $$ { e }^{ ix }= \cos x + i \sin x $$ **2. 오일러 등식: $$ { e }^{ i\pi }+1=0 $$ 오일러 공식Euler&amp;rsquo;s Formula 은 그 형태 자체가 워낙 기이해서 오일러 본인조차 어디다 쓰일지는 몰랐다고 하는데, 현대에는 너무나 많은 분야에서 활용되고 있어 요약을 하기가 어려울 정도로 유용한 공식이 되었다. 허수라는 것이 학계에서 아직 잘 받아들여지지 않았</description>
    </item>
    
    <item>
      <title>수직인 두 직선의 기울기의 곱이 -1임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/111/</link>
      <pubDate>Sat, 20 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/111/</guid>
      <description>정리 서로 수직인 두 직선의 기울기의 곱은 항상 $-1$이다. 여러 문제에서 매우 유용하게 쓰이는 사실이다. 2가지 증명 방법을 소개한다. 증명1 피타고라스의 정리를 사용한다. 아래 그림을 보자.수직인 두 직선의 기울기가 $a$, $a&#39;$라고 하자. 그러면 위의 그림과 같이 직각 삼각형$\triangle OAA&#39;$을 생각할 수 있고 피타고라스의 정리</description>
    </item>
    
    <item>
      <title>정수론에서의 합동</title>
      <link>https://freshrimpsushi.github.io/posts/congruence-in-number-theory/</link>
      <pubDate>Thu, 11 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/congruence-in-number-theory/</guid>
      <description>$a \equiv b \pmod{m} $ $\iff$ 정수 $a$, $b$, $m$ 에 대해 $a = b + mk$ 를 만족하는 정수 $k$ 가 존재한다.수식 $a \equiv b \pmod{m} $ 을 합동식 이라고 부르고, 법Modulo $m$ 에서 $a$ 가 $b$ 에 합동Congruent 이라고 한다. 다만 법은 수식에서부터 $\pmod{}$ 가 그대로 쓰인만큼 그냥 모듈로 $m$ 이라고 발음하는 편이다.$a_{1} \equiv b_{1} \pmod{m}$ 과 $a_{2} \equiv b_{2} \pmod{m}$ 이 성립한다고 하자.**[1] 덧셈**</description>
    </item>
    
    <item>
      <title>팩토리얼의 일반화 감마함수</title>
      <link>https://freshrimpsushi.github.io/posts/gamma-function/</link>
      <pubDate>Sun, 30 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gamma-function/</guid>
      <description>감마함수에 대한 오일러의 극한 공식 보기감마함수에 대한 바이어슈트라스 무한곱 보기물리학에서의 감마함수다항함수의 라플라스 변환의 결과로서의 감마함수 보기감마함수에 대해 더 자세하게 알고싶다면 : 감마함수 유도**감마 함수의 정의 다음과 같이 정의된 함수 $\Gamma$ 를 감마 함수 라고 한다. $$ \displaystyle \Gamma(x) := \int_{0}^{\infty} t^{x-1} e^{-t} dt $$ 위 수식에서 적분에 초점을 두면 오일러 적분</description>
    </item>
    
    <item>
      <title>두 레비-치비타 심볼의 곱</title>
      <link>https://freshrimpsushi.github.io/posts/multiplication-of-two-levi-civita-symbol/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplication-of-two-levi-civita-symbol/</guid>
      <description>두 레비-치비타 심볼의 곱 $(a)$ 한 개의 인덱스가 같은 경우 $\epsilon_{ijk}\epsilon_{lmk}=\delta_{il}\delta_{jm}-\delta_{im}\delta_{jl} $$ (b)$ 두 개의 인덱스가 같은 경우 $\epsilon_{ijk}\epsilon_{ljk}=2\delta_{il} $$ (c)$ 세 개의 인덱스가 같은 경우 $\epsilon_{ijk}\epsilon_{ijk}=6$포스트 전반에서 아인슈타인 표기법을 사용하고 있으니 헷갈리지 말자.**증명 $** (a)$ $$ \epsilon_{ijk}\epsilon_{lmk}=\delta_{il}\delta_{jm}-\delta_{im}\delta_{jl} $$ ■ **증명 $(b)$** $(a)$ $\epsilon_{ijk}\epsil</description>
    </item>
    
    <item>
      <title>레비-치비타 심볼과 크로네커 델타의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-of-levi-civita-symbol-and-kronecker-delta/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-of-levi-civita-symbol-and-kronecker-delta/</guid>
      <description>레비-치비타 기호와 크로네커 델타의 관계 두 레비-시비타 심볼의 곱에서 하나의 인덱스가 같으면 아래의 식이 성립한다.$\epsilon_{ij\color{red}{k}}\epsilon_{\color{red}{k}lm}=\delta_{il}\delta_{jm}-\delta_{im}\delta_{j</description>
    </item>
    
    <item>
      <title>아인슈타인 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/einstein-notation/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/einstein-notation/</guid>
      <description>정의 **아인슈타인 표기법 두 번 이상 반복되는 첨자에 대해서는 합기호$\sum$를 생략한다. 아인슈타인 합 규약(Einstein summation convention)이라 부르기도 한다. 어려운 공식 같은 것은 아니고 말 그대로 일종의 규칙이다. 벡터 계산을 하다 보면 한 수식에 $\sum$을 몇 겹씩이나 써야 하는 경우 흔히 생기는데 이러면 수식이 지저분</description>
    </item>
    
    <item>
      <title>양자역학에서 단순 조화 진동자simple harmornic motion의 바닥상태 에너지</title>
      <link>https://freshrimpsushi.github.io/posts/91/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/91/</guid>
      <description>불확정성 원리the uncertainty principle를 사용하여 단조화 진동자의 바닥상태 에너지를 구해보자.단조화 진동자의 에너지는$\begin{eqnarray*} E &amp;amp;=&amp;amp; \frac{p^2}{2m}+\frac{1}{2}kx^2 \\ &amp;amp;=&amp;amp; \frac{1}{2m}\left(\frac{{\hbar}^2}{4x^2}\right)+\frac{1}{2}kx^2 \end{eqnarray*}$불확정성 원리에 의해 $\displaystyle xp \simeq \frac{\hbar}{2} $$ E$가 최소일 때를 구하려면$ \displaystyle \left. \frac{\partial E}{\partial x}\right|_{x=x_0} =0 $$ \displaystyle { -\frac{{\hbar}^2}{4m{x_0}^3}+kx_0=0 \\ k{x_0}^4=\frac{{\hbar}^2}{4m} \\ {x_0}^4=\frac{{\hbar}^2}{4m^2w^2} (k=mw^2) \\ {x_0}^2=\frac{\hbar}{2mw} } $$ \begin{eqnarray*} \Rightarrow E_{min} &amp;amp;=&amp;amp; \frac{1}{2m}\frac{{\hbar}^2}{4}\frac{2mw}{\hbar}+\frac{1}{2}k\frac{\hbar}{2mw} \\ &amp;amp;=&amp;amp; \frac{\hbar w}{4}+\frac{\hbar</description>
    </item>
    
    <item>
      <title>양자역학에서 수소원자의 최소 에너지</title>
      <link>https://freshrimpsushi.github.io/posts/92/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/92/</guid>
      <description>불확정성 원리the uncertainty principle를 이용하여 수소원자의 최소 에너지를 구해보자.수소 원자의 에너지 $E$는$ \begin{eqnarray*} E &amp;amp;=&amp;amp; \frac{p^2}{2m}-\frac{e^2}{r} \\ &amp;amp;=&amp;amp; \frac{1}{2m}\frac{{\hbar}^2}{r^2}-\frac{e^2}{r} \end{eqnarray*}$불확정성 원리에 의해 $pr \simeq \hbar $$ E$가 최소일 때를 구하려면$ \displaystyle { \left. \frac{\partial E}{\partial r} \right|_{r=r_0}=0 \\ -\frac{{\hbar}^2}{m{r_0}^3}+\frac{e^2}{{r_0}^2}=0 \\ -\frac{{\hbar}^2}{m}+e^2r_0=0 \\ r_0=\frac{{\hbar}^2}{me^2} } $$ \begin{eqnarray*} \Rightarrow E_{min} &amp;amp;=&amp;amp; \frac{{\hbar}^2}{2m}\frac{m^2e^4}{{\hbar}^4}-\frac{me^4}{{\hbar}^2} \\ &amp;amp;=&amp;amp; \frac{me^4}{2{\hbar}^2}-\frac{me^4}{{\hbar}^2} \\ &amp;amp;=&amp;amp; -\frac{1}{2}\frac{me^4}{{\hbar}^2} \\ &amp;amp;=&amp;amp; -\frac{1}{2}\frac{me^4{\color{blue}{c^2}}}{{\hbar}^2{\color{blue}{c^2}}} \\ &amp;amp;=&amp;amp; -\frac{1}{2}mc^2\alpha ^2 \end{eqnarray*} $(여기서 $\displaystyle \alpha = \frac{e^2}{\hbar c}$으로</description>
    </item>
    
    <item>
      <title>포물선 운동 수평도달거리와 높이가 최대일 때의 각도 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/89/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/89/</guid>
      <description>**포물선 운동 물체를 던질 때 어느 각도로 던져야 가장 멀리(최대 거리) 날아갈까?2. 어느 각도로 던져야 가장 높이(최대 높이) 올라갈까?$x$성분은 중력가속도와 무관 $y$성분은 중력가속도에 영향을 받는다 $ \begin{eqnarray*} \Rightarrow a_x &amp;amp;=&amp;amp;0 \\ v_x&amp;amp;=&amp;amp;v_0\cos\alpha \\ x&amp;amp;=&amp;amp;(v_o\cos\alpha)t \\ \\ \\ F_x &amp;amp;=&amp;amp; 0 \end{eqnarray*}$ $\begin{eqnarray*} \Rightarrow a_y &amp;amp;=&amp;amp; -g \\ v_y &amp;amp;=&amp;amp; -gt+v_0\sin\alpha \\ y &amp;amp;=&amp;amp; -\frac{1}{2}gt^2+(v_0\sin\alpha)t \\ \\ F_y &amp;amp;=&amp;amp; -mg \end{eqnarray*}$위에서 $x$와</description>
    </item>
    
    <item>
      <title>아크탄젠트 함수의 급수전개</title>
      <link>https://freshrimpsushi.github.io/posts/86/</link>
      <pubDate>Thu, 27 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/86/</guid>
      <description>공식 $$ \displaystyle \tan ^{ -1 } x = \sum _{ n=0 }^{ \infty }{ \frac { (-1) ^{ n } { x } ^ { 2n+1 } } { 2n+1 } } $$ $\arctan$으로 쓰든 $\tan ^{-1}$로 쓰든 상관없다. 여러 삼각함수의 역함수 중에서도 아크탄젠트가 특히 흥미로운 이유는 바로 $\pi$ 로 수렴하는 급수를 제공해주기 때문이다. $x=1$ 을 대입하면 $$ \displaystyle { \pi \over 4 } = \tan ^{-1} 1 = 1 - {1 \over 3} + {1 \over 5} - {1 \over 7} + \cdots $$ 양변에</description>
    </item>
    
    <item>
      <title>크로네커 델타</title>
      <link>https://freshrimpsushi.github.io/posts/kronecker-delta/</link>
      <pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kronecker-delta/</guid>
      <description>정의 다음과 같이 정의되는 $\delta_{ij}$를 **크로네커 델타** 라고 한다. $$ \delta_{ij}=\begin{cases} 1,&amp;amp;i=j \\ 0, &amp;amp; i\ne j \end{cases} $$ 크로네커 델타는 여러 곳에서 쓰이는데 특히 두 벡터의 내적을 간단히 표기할 수 있게 해주므로 물리학에서도 자주 등장한다. 물리학과 학부생이라면 레비-치비타 심볼과 함께 졸업할 때까지 계속 보게 된다. 예시 크로네커 델타를 이용하면 두 벡</description>
    </item>
    
    <item>
      <title>레비-치비타 심볼</title>
      <link>https://freshrimpsushi.github.io/posts/levi-civita-symbol/</link>
      <pubDate>Tue, 25 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/levi-civita-symbol/</guid>
      <description>정의 다음과 같이 정의되는 $\epsilon_{ijk}$를 **레비-치비타 심볼** 이라고 한다. $$ \epsilon_{ijk} = \begin{cases} +1 &amp;amp; \text{if} \ \epsilon_{123}, \epsilon_{231}, \epsilon_{312} \\ -1 &amp;amp; \text{if} \ \epsilon_{132}, \epsilon_{213}, \epsilon_{321} \\ 0 &amp;amp; \text{if} \ i=j \ \text{or} \ j=k \ \text{or} \ k=i \end{cases} $$ 크로네커 델타가 인덱스끼리 값이 같은지만 따졌다고 한다면 레비-치비타 심볼은 정의에서 나타나듯이 인덱스의 순서도 값에 영향을 미친다. $\epsilon_</description>
    </item>
    
    <item>
      <title>등가속도 직선 운동과 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/72/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/72/</guid>
      <description>정의 어떤 물체의 가속도가 시간 $t$에 따라 변하지 않을 때 물체가 등가속도 운동을 한다고 말한다. $$ a(t)=a $$ 등가속도 직선 운동은 가속도가 변하지 않고 일정하게 유지되면서 직선으로 운동하는 것을 말한다. 이 때 가속도 $a$​가 양수인지 음수인지가 중요한데 $a&amp;gt;0$이라면 처음 움직이던 방향으로 점점 빠르게 움직일 것이고, $a&amp;lt;0$</description>
    </item>
    
    <item>
      <title>등속도 운동과 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/74/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/74/</guid>
      <description>등속도라는 이름을 풀어보면 &amp;lsquo;등(같다)+속도&amp;rsquo;이다.즉 속도가 같은, 일정하게 유지되는 운동이라는 것이다.속도는 벡터이므로 크기(속력)도 있고 방향도 있다.크기와 방향 둘 다 일정해야 등속도 운동이 된다.한마디로 등속도 운동은 속력과 방향이 일정한 운동을 말한다. 등속도 운동의 그래프는 아래의 그림과 같다. 이</description>
    </item>
    
    <item>
      <title>벡터 삼중곱백캡 공식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-vector-triple-productbac-cab-rule/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-vector-triple-productbac-cab-rule/</guid>
      <description>In EnglishBAC-CAB(백캡) 공식 $$ \mathbf{A} \times (\mathbf{B} \times \mathbf{C} )= \mathbf{B}(\mathbf{A} \cdot \mathbf{C} )-\mathbf{C}(\mathbf{A} \cdot \mathbf{B}) $$ 벡터 삼중곱$(\mathrm{vector\ triple\ product})$ 의 결과를 간단하게 BAC-CAB(백캡)이라고 외운다.벡터 삼중곱은 벡터를 3번 곱하는 연산 중에서 그 결과가 벡터인 것이다. 결과가 스칼라인 것은 스칼라 삼중곱이라 부른다. 결과가 벡터로 나오기 위해서 식에</description>
    </item>
    
    <item>
      <title>운동량과 충격량의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/73/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/73/</guid>
      <description>1. 운동량 물체의 질량과 속도의 곱을 운동량이라 하고 $p$로 나타낸다. 고등물리에서는 물체의 운동 상태를 나타낼 때 속도$v$를 많이 쓰지만 대학물리에서는 운동량$p$이 많이 쓰인다. $$ \vec{p}=m\vec{v}[kg\cdot m/s] $$ 속도$v$가 벡터이므로 운동량 역시 벡터이다. 질량 $m$이 항상 양수이므로 속도와 운동량의 방향은 항상 같다. 질량이 클 수록, 속도의 크기가 클 수록</description>
    </item>
    
    <item>
      <title>특수상대성이론 시간지연</title>
      <link>https://freshrimpsushi.github.io/posts/time-dilation/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-dilation/</guid>
      <description>특수상대성이론이 탄생하게된 배경이자 이 글을 읽기 위해 알아야할 사실이 있다. 바로 빛의 속도는 항상 일정하다는 것이다. 관찰자가 가만히 있을 때, 빛과 같은 방향으로 움직일 때, 빛과 반대 방향으로 움직일 때 모두 빛의 속도는 일정하다. 신기하지 않은가? 받아들이기 어려울테지만 그렇게 알고 시작해보자. 시간 지연$(\mathrm{time\ dilation})$</description>
    </item>
    
    <item>
      <title>이차행렬의 곱의 성분의 합을 쉽게 구하는 공식</title>
      <link>https://freshrimpsushi.github.io/posts/70/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/70/</guid>
      <description>이차행렬 $\pmatrix { { a }&amp;amp;{ b } \\ { c }&amp;amp;{ d } } \pmatrix { { p }&amp;amp;{ q } \\ { r }&amp;amp;{ s } }$ 의 성분의 합은 ${(a+c)(p+q)}+{(b+d)(r+s)} $두 이차행렬을 주고 그 곱의 성분의 합을 구하라는 문제를 많이 접해보았을 것이다.다들 알겠지만 이 행렬을 곱한다는게 어렵지는 않지만 시간도 걸리고 여간 귀찮은게 아니다.해서, 연산을 획기적으로 줄이는 공식을 소개한다.유도 $ \pmatrix { { a }&amp;amp;{ b } \\ { c }&amp;amp;{ d }</description>
    </item>
    
    <item>
      <title>두 행렬의 곱의 역행렬과 전치행렬</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-matrix-and-transpose-matrix-of-product-of-two-matrices/</link>
      <pubDate>Thu, 20 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-matrix-and-transpose-matrix-of-product-of-two-matrices/</guid>
      <description>크기가 같고 역행렬이 존재하는 두 행렬 $A$와 $B$에 대해 다음이 성립한다. $$ \leqalignno{ { \left( AB \right) }^{ -1 } &amp;amp;= { B }^{ -1 } { A }^{ -1 } &amp;amp; (a) \\ { \left( AB \right) }^{ T } &amp;amp;= { B }^{ T } { A }^{ T } &amp;amp;(b) \\ { \left( { A }^{ T } \right) }^{ -1 } &amp;amp;= { \left( { A }^{ -1 } \right) }^{ T } &amp;amp;(c)} $$ 정말 많이 쓰이는 성질이다. 증명 $(a)$ 두 행렬의 곱의 역행렬 $$ \begin{align*} AB\left( { B }^{ -1 } { A }^{ -1 } \right) &amp;amp;= A\left( B { B }^{ -1 } \right) {</description>
    </item>
    
    <item>
      <title>유클리드 호제법 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-euclidean-algorithm/</link>
      <pubDate>Thu, 20 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-euclidean-algorithm/</guid>
      <description>정리 $ r_i&amp;lt;r_{i+1}$ 에 대해 점화식 $r_{i-1} = q_{i+1} \cdot r_{i} + r_{i+1}$ 을 만족시키는 $a: = r_{-1}$ 와 $b:=r_{0}$ 를 정의하자. $r_{n+1} = 0$ 을 만족시키는 $n$ 에 대해 $$ r_{n} = \gcd (a,b) $$ 이른바 유클리드 호제법 으로 알려진 이 알고리즘은 최대공약수를 매우 효율적으로 구할 수 있게 해준다. 일일이 소인수분해를 하지 않고도 답을 내기 때문에 숫자가 커질수록 더욱 빛을 발한다. 알고리즘 두 정수 $a \ge b$ 에 대해 $\text{gcd}(a,b)$ 는 다음과</description>
    </item>
    
    <item>
      <title>합동방정식에 대한 대수학의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/66/</link>
      <pubDate>Thu, 20 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/66/</guid>
      <description>대수학의 기본정리어떤 소수 $p$ 에 대해 $p\nmid a_{ 0 }$ 라 하면 모든 계수가 정수인 다항식 $$ f(x)=a_{ 0 }x^{ d }+a_{ 1 }x^{ d-1 }+ \cdots +a_{ d-1 }x+a_{ d } $$ 에 대해 방정식 $f(x)\equiv 0 \pmod{p}$ 는 많아도 $d$ 개의 합동이 아닌 해를 가진다.그냥 흔히들 아는 것처럼 실계수를 갖는 다항식에 대해서 말하자면, $n$차 방정식은 중근을 포함해 $n$개의 해를 갖는다는 정리다. 이를 정수론에서 생각해보면 $\pmod{p}$ 에서</description>
    </item>
    
    <item>
      <title>소수는 무한히 존재한다  유클리드의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/64/</link>
      <pubDate>Sat, 15 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/64/</guid>
      <description>오일러의 증명 보러가기소수는 무한히 존재한다.소수가 무한하다는 것을 증명하는 방법은 여러가지가 있다.그 중에서도 가장 간단한 유클리드의 방법을 소개하도록 하겠다.이 증명은 단순할 뿐만 아니라 매우 아름답기로도 유명하다.증명 소수가 유한히 존재한다고 가정하자.$n$개의 소수들을 각각 $p_1, p_2, \cdots , p_n$ 이라고 하고 $p_{n+1}=p_1 p_2 \cdots p_n + 1$에 대해 생각해</description>
    </item>
    
    <item>
      <title>ln1-x 의 급수꼴 유도와 교대조화급수의 수렴성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/58/</link>
      <pubDate>Tue, 11 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/58/</guid>
      <description>조화급수의 발산성 $$ \displaystyle \ln(1-x)=\sum { n=0 }^{ \infty }{ \frac { -{ x }^{ n+1 } }{ n+1 } } $$ $\ln(1-x)$ 의 급수꼴은 비교적 쉽게 구할 수 있다.증명 $-1&amp;lt;x&amp;lt;1$ 에 대해 등비수열의 합 $\displaystyle \sum{n=0}^{\infty} x^{n}$ 은 다음과 같다. $$ \displaystyle {{ 1 } \over { 1-x }}=1+x+{ x }^{ 2 }+{ x }^{ 3 }+ \cdots $$ 양변에 적분을 취하면 $$ \displaystyle -\ln(1-x)=c+x+\frac { { x }^{ 2 } }{ 2 }+\frac { { x }^{ 3 } }{ 3 }+\frac { { x }^{ 4 } }{ 4 }+ \cdots $$ $ x=0 $ 일 때 $-\ln(1-0)=0=c+0$ 이므로 $c=0 $$ $ \displaystyle \therefore \ln(1-x)=\sum _{ n=0 }^{ \infty }{ \frac { -{</description>
    </item>
    
    <item>
      <title>지수 함수 사인 함수 코사인 함수의 테일러 전개</title>
      <link>https://freshrimpsushi.github.io/posts/59/</link>
      <pubDate>Tue, 11 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/59/</guid>
      <description>정리 [1] 지수 함수의 매클로린 급수 : $$ { { e ^ x } }=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ n } }{ n! } } $$ [2] 사인 함수의 매클로린 급수 : $$ \sin x=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ 2n+1 } }{ (2n+1)! }{ { (-1) }^{ n } } } $$ [3] 코사인 함수의 매클로린 급수 : $$ \cos x=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ 2n } }{ (2n)! }{ { (-1) }^{ n } } } $$ 지수 함수, 사인 함수, 코사인 함수의 매클로린 급수는 어려운 테크</description>
    </item>
    
    <item>
      <title>포커 족보별 경우의 수 확률 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/probability-of-each-poker-hand-ranking/</link>
      <pubDate>Wed, 29 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-of-each-poker-hand-ranking/</guid>
      <description>확률 이전에 포커 자체를 잘 모른다면 족보를 찾아서 알아보는 걸 추천한다. 확률을 구하기에 앞서 두 가지 정의를 내리자:문양 : 집합 {♠,◇,♤,♣}의 원소끗수 : 집합 {A,2,3,4,5,6,7,8,9,10,J,Q,K}의 원소만약 두 가지 이상의 족보를 동시에 만족하면 높은 걸 따른다. 아래의 확률들은 5장을 뽑고 그때의 족보가 가장 높은</description>
    </item>
    
    <item>
      <title>1만번째 소수까지의 소수표</title>
      <link>https://freshrimpsushi.github.io/posts/46/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/46/</guid>
      <description>prime numbers.txt2 3 5 7 11 13 17 19 23 2931 37 41 43 47 53 59 61 67 7173 79 83 89 97 101 103 107 109 113127 131 137 139 149 151 157 163 167 173179 181 191 193 197 199 211 223 227 229233 239 241 251 257 263 269 271 277 281283 293 307 311 313 317 331 337 347 349353 359 367 373 379 383 389 397 401 409419 421 431 433 439 443 449 457 461 463467 479 487 491 499 503 509 521 523 541547 557 563 569 571 577 587 593 599 601607 613 617 619 631 641 643 647 653 659661 673 677 683 691 701 709 719 727 733739 743 751 757 761 769 773 787 797 809811 821 823 827 829 839 853 857 859 863877 881 883 887 907 911 919 929 937 941947 953 967 971 977</description>
    </item>
    
    <item>
      <title>밑을 e로 가지는 로그함수lnx의 거듭제곱의 적분법</title>
      <link>https://freshrimpsushi.github.io/posts/45/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/45/</guid>
      <description>공식 $$ \int {{(\ln x)}^{ n }} dx=x{{(\ln x)}^{ n }}-\int n{{(\ln x)}^{ n-1 }}dx $$ 적분 문제를 풀다보면 심심치 않게 보게 되는 유형이다. 이런 문제들을 풀 때 정직하게 부분적분으로 풀면 시간을 너무 많이 빼앗긴다. 우선은 규칙부터 찾아보도록 하자. $f(n)=\int {{(\ln x)}^{ n }} dx$ (단, $n=1,2,3&amp;hellip;$)이라 할 때 $$ \begin{eqnarray*} f(1) &amp;amp;=&amp;amp; x(\ln|x|-1)+C \\ f(2) &amp;amp;=&amp;amp; x{(\ln|x|)^{ 2 }-2\ln|x|+2}+C \\ f(3) &amp;amp;=&amp;amp; x{(\ln|x|)^{ 3 }-3(\ln|x|)^{ 2 }+6\ln|x|-6}+C \\ f(4) &amp;amp;=&amp;amp; x{(\ln|x|)^{ 4 }-4(\ln|x|)^{ 3 }+12(\ln|x|)^{ 2 }-24\ln|x|+24}+C \end{eqnarray*} $$ 네</description>
    </item>
    
    <item>
      <title>삼각함수의 덧셈정리 여러가지 증명</title>
      <link>https://freshrimpsushi.github.io/posts/44/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/44/</guid>
      <description>$$ \sin\left( \alpha +\beta \right) =\sin\alpha \cos\beta +\cos\alpha \sin\beta \\ \sin\left( \alpha -\beta \right) =\sin\alpha \cos\beta -\cos\alpha \sin\beta \\ \cos\left( \alpha +\beta \right) =\cos\alpha \cos\beta -\sin\alpha \sin\beta \\ \cos\left( \alpha -\beta \right) =\cos\alpha \cos\beta +\sin\alpha \sin\beta \\ \tan\left( \alpha +\beta \right) =\frac { \tan\alpha +\tan\beta }{ 1-\tan\alpha \tan\beta } \\ \tan\left( \alpha -\beta \right) =\frac { \tan\alpha -\tan\beta }{ 1+\tan\alpha \tan\beta } $$ 1. 코사인 법칙을 이용한 증명 피타고라스의 정리에 의해 $$ \begin{eqnarray*} {\overline { AB } } ^{ 2 } &amp;amp;=&amp;amp; {( \cos \alpha -\cos \beta )}^{ 2 }+{(\sin\alpha -\sin\beta )}^{ 2 } \\ &amp;amp;=&amp;amp; 2-2 \cos \alpha \cos \beta –2 \sin \alpha \sin \beta \end{eqnarray*} $$ 제2코사인 법칙에 의해 $$ \begin{eqnarray*} { \overline { AB } } ^{ 2 } &amp;amp;=&amp;amp; 1^{ 2 }+1^{ 2</description>
    </item>
    
    <item>
      <title>로피탈의 정리lHospitals Theorem 증명</title>
      <link>https://freshrimpsushi.github.io/posts/39/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/39/</guid>
      <description>정리 $f(x)$ 와 $g(x)$ 가 $x=a$ 의 근방에서 미분가능하고 $g&#39;(x) \ne 0$ 이며 $\displaystyle \lim _{x \to a} f(x) = \lim _{x \to a} g(x) = 0$ 이면 $$ \lim _{x \to a} {{f(x)} \over {g(x)}} = \lim _{x \to a} {{f&#39;(x)} \over {g&#39;(x)}} $$ 수험생들에게는 마검같은 정리로 이미 수 많은 고등학생들이 배워서 써먹고 있으나, 개인적으로 수능을 몇 달 앞두기 전엔 알아도 봉인해두고 가능한 정석대로 푸는 게 좋다고 생각한다. 사실 이 정리를 처음으로 증명한 것은 로피탈</description>
    </item>
    
    <item>
      <title>롤의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rolles-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rolles-theorem/</guid>
      <description>함수 $f(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 미분가능하며 $f(a)=f(b)$ 면 $f&#39;(c)=0$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다.고등학교 과정에선 평균값의 정리만을 증명하기 위한 보조정리 정도로 소개되고 실제로 그 외엔 전혀 쓰이지 않지만, 고등학교 수준을 벗어나서는 종종 보조정리로써 사용될 때가 있다. 평균값의 정리가 더욱 일반적인 것은 사실이지만, $\displaystyle f&#39;(c) = {{f(b) - f(a)} \over {b - a}}$ 와</description>
    </item>
    
    <item>
      <title>우함수와 기함수 그리고 그 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/40/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/40/</guid>
      <description>$f(-x) = f(x)$ 를 만족하는 함수 $f(x)$ 를 우함수 라고 한다. $f(-x) = -f(x)$ 를 만족하는 함수 $f(x)$ 를 기함수 라고 한다. $f$ 가 실수 전체에서 미분가능하면 다음이 성립한다.[1] 우함수의 도함수는 기함수다.[2] 기함수의 도함수는 우함수다.우함수는 좌표평면에서 $y$ 축에 대칭인 함수, 기함수는 원점 $O$ 에 대칭인 함수를 말한다.예시로 삼각함수 중 기함수인 $\sin$과</description>
    </item>
    
    <item>
      <title>코시의 평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cauchys-mean-value-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cauchys-mean-value-theorem/</guid>
      <description>평균값 정리 적분의 평균값 정리 가우스의 평균값 정리 정리 함수 $f(x), g(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 미분가능하며 $g&#39;(x) \ne 0$이면 $$ {{f&#39;(c)}\over{g&#39;(c)}}={{f(b)-f(a)}\over{g(b)-g(a)}} $$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 보통 평균값 정리와 달라진 게 있다면 그냥 함수가 하나 더 늘어난 것이다. $g(x) = x$ 로 본다면 이 $g$ 가 더 자유로워졌다는 의미에서 평균값 정리의 일반화라고 할 수 있다. 증명 롤의 정리의 대우</description>
    </item>
    
    <item>
      <title>테일러 급수와 매클로린 급수</title>
      <link>https://freshrimpsushi.github.io/posts/taylor-series-and-maclaurin-series/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/taylor-series-and-maclaurin-series/</guid>
      <description>정리 함수 $f$ 가 점 $a$ 근방에서 무한히 미분가능하고, $\displaystyle f(x) = \sum_{n=0}^{\infty} {{f^{(n)} (a)}\over{n!}} {(x-a)}^n$ 일 필요충분조건은 어떤 $\xi \in \mathscr{H} \left\{ x , a \right\} $ 에 대해 $$ \lim_{n \to \infty} {{f^{(n)} (\xi)}\over{n!}} {(x-a)}^n = 0 $$ $\xi \in \mathscr{H} \left\{ x , a \right\} $ 라 함은 $\xi$ 가 $(x,a)$ 혹은 $(a,x)$ 에 있다는 표현이다. 테일러 정리는 함수가 한 없이 미분가능할 때 흔히 무한급수의 꼴로 표현된다. 이를 테일러 급수 라고 하며, 특히 $a=0$인 경우 매클로린 급수 라고</description>
    </item>
    
    <item>
      <title>테일러 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-taylors-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-taylors-theorem/</guid>
      <description>정리 함수 $f(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 $n$ 번 미분가능하면 $$ \displaystyle \begin{eqnarray*} f(b) &amp;amp;=&amp;amp; \sum_{k=0}^{n-1} {{(b-a)^{k}\over{k!}}{f^{(k)}( a )}} + {(b-a)^{n}\over{n!}}{f^{(n)}(\xi)} \\ &amp;amp;=&amp;amp; {f(a)} + {(b-a)f&#39;(a)} + \cdots + {(b-a)^{n-1}\over{(n-1)!}}{f^{(n-1)}(a)} + {(b-a)^{n}\over{(n)!}}{f^{(n)}(\xi)} \end{eqnarray*} $$ 를 만족하는 $\xi \in (a,b)$ 가 존재한다. 수학 전반에서 너무나 중요하게 쓰이고 있는 정리로, 이 이름을 딴 테일러 급수가 있다. 미분을 $n$ 번 한다는 의미에서는 평균값의 정리를 일반화한 정리라고 볼 수 있다. 관례적으로, 테일러 정리를 사용할 땐 $c$ 가 아</description>
    </item>
    
    <item>
      <title>페르마의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fermats-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fermats-theorem/</guid>
      <description>함수 $f(x)$ 가 $x=c$ 에서 극대 혹은 극소면서 $f&#39;(c)$ 가 존재하면 $f&#39;(c) = 0$보통 고등학교 교과서엔 롤의 정리까지만 소개되어 있으나 롤의 정리를 엄밀하게 증명하기 위해서는 극점에서의 미분계수가 왜 $0$ 인지를 보일 수 있어야하고, 페르마의 정리가 그것을 보장한다.Strategy : 극대와 극소 두가지 경우로 나누어서 증명한다.증명 Case 1.** $f(x)$ 가 $x=c$ 에서 극대충분히 작은</description>
    </item>
    
    <item>
      <title>평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem/</guid>
      <description>코시의 평균값 정리 적분의 평균값 정리 가우스의 평균값 정리 함수 $f(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 미분가능하면 $\displaystyle f&#39;(c)={{f(b)-f(a)}\over{b-a}}$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 그냥 자주 쓰는 정도가 아니라 MVT라는 약어도 사용할 정도로 유명한 정리다. 평균값이라는 말은 미분계수가 전구간의 평균변화율과 같아지는 점이 있다는 센스에서 따온 것이다. 평균이라는 개념이 유</description>
    </item>
    
    <item>
      <title>다양한 삼각함수의 적분법</title>
      <link>https://freshrimpsushi.github.io/posts/31/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/31/</guid>
      <description>적분 문제를 풀다보면 삼각함수의 적분을 상당히 많이 하게 된다. 그리고 이 적분법들에 익숙해지면 삼각함수도 다항함수처럼 빠르게 적분할 수 있다. 1. 시컨트 함수의 적분법, 코시컨트 함수의 적분법 $$ \begin{eqnarray*} \int \sec x dx &amp;amp;=&amp;amp;\int \frac { \sec x (\sec x +\tan x ) }{ (\sec x +\tan x ) }dx \\ &amp;amp;=&amp;amp;\int \frac { \sec^{ 2 }x+\sec x \tan x }{ \tan x +\sec x }dx \end{eqnarray*} $$ $ (\tan x )\prime =\sec^{ 2 }x $ 이고 $(\sec x )\prime =\sec x \tan x $ 이므로 $$ \int \sec x dx=\ln|\tan</description>
    </item>
    
    <item>
      <title>두 사건이 독립이면 여사건끼리도 독립임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/28/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/28/</guid>
      <description>다음은 서로 동치다. $$ P(A \cap B) = P(A)P(B) \\ P(A \cap B^c)=P(A)P(B^c) \\ P(A^c \cap B)=P(A^c)P(B) \\ P(A^c \cap B^c)=P(A^c)P(B^c) $$ 알아두면 큰 도움이 되는 팩트일 뿐만이 아니라 공식으로써도 유용하다. 증명 $P(A \cap B) = P(A)P(B) $ 이라고 가정하자. 다시 말해, 사건 $A$, $B$ 는 독립이다. 여사건의 성질에 따라 $$ P(A)=1-P(A^{ c }) \\ P(B)=1-P(B^{ c }) $$ 이므로 $P(A \cap B) = P(A)P(B) $ 의 우변은 $$ \begin{eqnarray*} P(A)P(B)&amp;amp;=&amp;amp;(1-P(A^{ c }))(1-P(B^{ c })) \\ &amp;amp;=&amp;amp; 1-P(A^{ c })-P(B^{ c })+P(A^{ c })P(B^{ c }) \end{eqnarray*} $$ 이고, 좌변은 드 모르간</description>
    </item>
    
    <item>
      <title>두 사건이 서로 배반이면 서로 종속임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/27/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/27/</guid>
      <description>두 사건 $A,B$에 대해 $B=A^c$ 면 $P(A\cap B) \neq P(A)P(B)$굳이 수식을 통한 증명이 없더라도 상식적으로 배반이면 독립일 리가 없다.한 사건이 일어났을 때 다른 사건이 일어나지 않는다는 것은 이미 영향을 미치다는 말이기 때문이다.다만 이것을 알고 모르고는 참 거짓을 판별하는 문제를 풀 때 아주 큰 차이가 있다.증명 두 사건 $A,B$에 대해 $P(A)&amp;gt;0, P(B)&amp;gt;0$ 라 하자.이</description>
    </item>
    
    <item>
      <title>베이즈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</guid>
      <description>표본공간 $S$ 와 사건 $A$ 에 대해서 ${S_1,S_2,&amp;hellip;,S_n}$ 가 $S$ 의 분할이면 $$ \displaystyle P(S_k|A)=\frac { P(S_k)P(A|S_k) }{ \sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$ 혹은 베이즈 법칙으로도 불리는 이 정리는 두개의 법칙만 쓰면 될 정도로 쉽게 증명할 수 있으나 그 응용은 어마어마하다. 이른바 베이지안 패러다임은 통계학 자체를 양분하는 사고방식으로써, 그 중요도는 몇 번을 강조해도 부족함이 없다.우리가 알고 싶은 것은 위 식에서의 좌</description>
    </item>
    
    <item>
      <title>이차함수의 극점 빠르게 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/30/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/30/</guid>
      <description>이차함수 $f(x)=c(x-a)(x-b)$ 의 극점은 $\frac { a+b }{ 2 } $ (단, $c\neq 0$)인수분해가 가능한 이차함수의 경우에는 굳이 이런 저런 계산할 것 없이 극점을 알 수 있다.생각해보면 당연하지만, 이 사실을 아느냐 모르느냐에 따라 계산 과정을 하나 줄일 수 있고 없고가 달라진다.증명 $\begin{eqnarray*} f(x)&amp;amp;=&amp;amp;c(x-a)(x-b) \\ &amp;amp;=&amp;amp;c x^2 -c(a+b)x+cab \end{eqnarray*} $$ \Rightarrow f&#39;(x)=2cx-c(a+b) $$ \Rightarrow 2cx-c(a+b)=0 $$ \Rightarrow x=\frac { c(a+b) }{ 2c } $$ \Rightarrow x=\frac { a+b }{ 2 } $ ■</description>
    </item>
    
    <item>
      <title>11의 배수판정법 더 간단한 증명</title>
      <link>https://freshrimpsushi.github.io/posts/23/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/23/</guid>
      <description>11의 배수 판정법 $ a_{n} - a_{n-1} + &amp;hellip; + a_{1} - a_{0} $ 이 11의 배수면 $[a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}]$ 도 11의 배수다* 편의를 위해 $[a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}] := a_{n} \cdot 10^{n} + a_{n-1} \cdot 10^{n-1} +&amp;hellip;+ a_{1} \cdot 10^{1} + a_{0} \cdot 10^{0} $ 와 같이 쓴다.예를 들어, $[5714]=5000+700+10+4=5\cdot 10^{3} +7\cdot 10^{2} +1\cdot 10^{1} +4\cdot 10^{0} $물론 $7$ 의 배수 판정법 $13$ 의 배수 판정법에서 주어진 수가 $7$, $11$, $13$ 의 배수인지를 판정하는 방법을 얻을 수 있지만, $11$ 의 경우에는 특히 훨씬 쉬운 결과와 간단한</description>
    </item>
    
    <item>
      <title>3의 배수판정법과 9의 배수판정법의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/21/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/21/</guid>
      <description>각 자리 숫자를 모두 더해 3의 배수면 3의 배수, 9의 배수면 9의 배수예를 들어 8142는 8142=32714로 3의 배수고, 실제로 8+1+4+2=15는 3의 배수다.1945125는 1945125=9216125로 9의 배수고, 실제로 1+9+4+5+1+2+5=27은 9의 배수다.배수 판정법은 현대에 와선 사실 별 의미가 없어</description>
    </item>
    
    <item>
      <title>7의 배수판정법과 13의 배수판정법의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/22/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/22/</guid>
      <description>이 포스트에서는 진법에 대한 편의를 위해 $$ [a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}] := a_{n} \cdot 10^{n} + a_{n-1} \cdot 10^{n-1} +&amp;hellip;+ a_{1} \cdot 10^{1} + a_{0} \cdot 10^{0} $$ 와 같이 쓴다. 예를 들어, $$ \begin{eqnarray*} [5714] &amp;amp;=&amp;amp; 5000+700+10+4 \\ &amp;amp;=&amp;amp; 5\cdot 10^{3} +7\cdot 10^{2} +1\cdot 10^{1} +4\cdot 10^{0} \end{eqnarray*} $$ 정리 $$ a_{n} a_{n-1} a_{n-2} - a_{n-3} a_{n-4} a_{n-5} +&amp;hellip;+ a_{5} a_{4} a_{3} - a_{2} a_{1} a_{0} $$ 이 $7$ 의 배수면 $[a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}]$ 도 $7$ 의 배수고, $$ a_{n} a_{n-1} a_{n-2} - a_{n-3} a_{n-4} a_{n-5} +&amp;hellip;+ a_{5} a_{4} a_{3} - a_{2} a_{1} a_{0} $$ 이 $13$ 의 배수면 $[a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}]$ 도 $13$ 의 배수다. 이게 무슨 말인가 하면,</description>
    </item>
    
    <item>
      <title>fx&#43;y=fx&#43;fy 꼴로 주어지는 함수가 있을 때의 문제 풀이법</title>
      <link>https://freshrimpsushi.github.io/posts/24/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/24/</guid>
      <description>$f(x+y)=f(x)+f(y)+xy$일 때, $f&#39;(0)=2$ 이다. $f&#39;(2)$를 구하라.함수 $f$ 가 $f(x+y)=f(x)+f(y)$ 를 만족할 때, 이를 $f$ 에 대한 코시 함수 방정식 이라고 부른다.풀이 대체로 이런 문제는 $f&#39;(a)$를 주고 $f&#39;(b)$를 구하라는 문제가 많다.일단 이런 문제를 풀 때 가장 먼저 생각해야할 것은 저 식에서 $f&#39;(0)$을 끄집어내는 것이다.</description>
    </item>
    
    <item>
      <title>원소가 n개인 유한 집합의 부분 집합의 갯수</title>
      <link>https://freshrimpsushi.github.io/posts/25/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/25/</guid>
      <description>유한집합 $X$에 대해 $n(X)=n$ 이면 $n(P(X))=2^{ n }$유도 $n$개의 원소 중에서 $k$개의 원소를 선택하는 부분집합의 갯수는 ${ n }{ C }{ k }$ 이다. 이항 정리를 써서 모든 경우의 수를 더하면 $\displaystyle \sum { k=0 }^{ n }{{ n }{ C }_{ k } }=2^{ n }$ 이므로 $n(P(A))=2^{ n }$■</description>
    </item>
    
    <item>
      <title>가비의 리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/16/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/16/</guid>
      <description>$bdf(b+d)\neq 0$ 이면 $$ \frac { a }{ b }=\frac { c }{ d }=\frac { e }{ f } \implies \frac { a+c }{ b+d }=\frac { e }{ f } $$ &amp;lsquo;가비&amp;rsquo;는 다른 게 아니라 두 한자 더할 가加 견줄 비比로 만들어진 단어다 여기서 견줄 비는 &amp;lsquo;비율&amp;rsquo;할때의 그 비로, 이름에 모든 게 함축된 정리다. 증명 $$ \frac { a }{ b }=\frac { c }{ d }=\frac { e }{ f } $$ 이므로 $\frac { a }{ b }=\frac { e</description>
    </item>
    
    <item>
      <title>구분구적법으로 구한 면적과 정적분의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/12/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/12/</guid>
      <description>$$ \displaystyle \lim _{ n\to \infty }{ \sum _{ k=1 }^{ n }{ f\left( a+\frac { p }{ n }k \right) \frac { p }{ n } } } =\int _{ a }^{ a+p }{ f(x)dx }=\int _{ 0 }^{ p }{ f(a+x)dx } =\int _{ 0 }^{ 1 }{ pf(a+px)dx } $$ 이따금 보면 극한을 빙자한 적분 문제가 있다. 물론 대개는 극한을 구하는 그 자체로도 풀 수 있게 해놓기 때문에 몰라도 크게 상관은 없다.하지만 가끔, 아주 가끔 저 관계 자체를 아는지 모르는지 묻는 경우가 있다. 자주 사용하지 않는만큼</description>
    </item>
    
    <item>
      <title>낙하한 물체의 속도를 구하는 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/13/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/13/</guid>
      <description>$ v=\sqrt { 2gh } $어떤 물체가 중력 $g$에 의해 높은 곳에서 낮은 곳으로 떨어졌을때,이 물체의 속도를 낙하한 거리 $h$에 대한 공식으로 나타낼 수 있다.우리가 구하고자 하는 것과 상관 없는 조건들은 모두 무시하기로 하자.유도 정지해있던 물체가 $h$ 만큼 낙하했을 때의 속도를 $v$라 하자.이때 역학적 에너지가 보존되므로 $\displaystyle \frac { 1 }{ 2 }mv^{ 2 }=mgh$</description>
    </item>
    
    <item>
      <title>드 무아브르의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/9/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/9/</guid>
      <description>in English$z = r \text{cis} \theta$ 이면 모든 자연수 $n$에 대해 $z^n = r^n \text{cis} n\theta$ 이 성립한다.* $\text{cis} \theta : = \cos \theta + i \sin \theta$**증명 수학적 귀납법을 사용하자.$n=1$ 에 대해서는 자명하고, $n=k$ 에 대해서도 성립한다고 가정하자.가정에 의해 $z^{k+1} = z z^k = (r \text{cis} \theta)(r^k \text{cis} k\theta)$한편 $z_1 z_2 = r_1 r_2 \text{cis} (\theta_1 + \theta_2)$이므로, $z^{k+1} = r^{k+1} \text{cis} (k+1)\theta $$ n=k$ 일 때</description>
    </item>
    
    <item>
      <title>삼각함수의  평행이동과  도함수의  관계</title>
      <link>https://freshrimpsushi.github.io/posts/11/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/11/</guid>
      <description>(1) $\displaystyle \sin{(\theta +\frac { n }{ 2 }\pi )}={ \sin }^{ (n) }\theta $(2) $\displaystyle \cos{(\theta +\frac { n }{ 2 }\pi )}={ \cos }^{ (n) }\theta $$ (n)$ 은 $n$ 번만큼 미분을 했다는 뜻이다.쉽게 말해서, 90˚만큼 움직일 때마다 미분을 한번씩 하면 된다.실제로 $n=3$ 에 대해서 계산을 해보자.덧셈정리를 사용한 방법 $\cos(\theta +{3 \over 2}\pi )=\cos\theta \cos\frac { 3 }{ 2 }\pi -\sin\theta \sin\frac { 3 }{ 2 }\pi =\cos\theta \cdot 0-\sin\theta \cdot (-1)=\sin\theta $공식을 사용한 방법 ${ \cos }^{ (3) }\theta =(\cos\theta )&#39;&#39;&#39;=(-\sin\theta )&#39;&#39;=(-\cos\theta )&#39;=\sin\theta $당연히 덧셈정리를 써서</description>
    </item>
    
    <item>
      <title>에네스트롬-카케야 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-enestrom-kakeya-theorem/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-enestrom-kakeya-theorem/</guid>
      <description>$\left\{ a_{i} \right\}_{i=0}^{n} \subset \mathbb{R} $ 이 $a_0 &amp;gt; a_1 &amp;gt; \cdots &amp;gt; a_n &amp;gt; 0$ 라고 하자. 다항함수 $$ P(z) := a_0 + a_1 z + \cdots + a_{n-1} z^{n-1} + a_n z^n $$ 의 모든 근 $z \in \mathbb{C}$ 는 $|z| \ge 1$ 를 만족한다. 증명1 만약 $P(z) = 0$ 의 해가 $z=1$ 이면 $\displaystyle 0 = P(1) = \sum_{i=0}^{n} a_{i} &amp;gt; 0$ 이므로 일단 해는 $z \ne 1$ 이어야한다.식 $P(z) = 0$ 의 양변에 $z$ 를 곱해 원래의 식에서 빼고 $a_0$에 대해 정리하면 $$ a_0 = (1-z)P(z) + (a_0 - a_1) z + \cdots + (a_{n-1} - a_n) z^n + a_n z^{n+1} $$ 이</description>
    </item>
    
    <item>
      <title>자주 쓰는 이차함수의 정적분</title>
      <link>https://freshrimpsushi.github.io/posts/15/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/15/</guid>
      <description>$\displaystyle \int _{ \alpha }^{ \beta }{ (x-\alpha )(x-\beta )dx }=-\frac { { (\beta -\alpha ) } ^ { 3 } }{ 6 } $문제를 풀다보면 생각보다 이런 꼴의 정적분을 할 일이 많다.풀이를 빠르게 해주는데 외엔 전혀 쓸모가 없는 공식이고 유도도 그냥 계산밖에 없다.모양만 딱 외워서 쓸 수 있도록 하자.유도 $\begin{eqnarray*} \int _{ \alpha }^{ \beta }{ (x-\alpha )(x-\beta )dx }&amp;amp;=&amp;amp;\int _{ \alpha }^{ \beta }{ { {x }^2-(\alpha +\beta )x+\alpha \beta }dx } \\ &amp;amp;=&amp;amp;\frac { \beta^3-{ \alpha^3 } }{ 3 }-(\alpha +\beta )\frac { \beta^2-\alpha^2}{ 2 }+\alpha \beta (\beta -\alpha ) \\ &amp;amp;=&amp;amp;\frac { 2\beta^3-2\alpha^3-3\beta^3-3\alpha \beta^2+3\alpha^2\beta</description>
    </item>
    
    <item>
      <title>조화급수의 발산성에 대한 오렘의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/oresmes-proof-of-divergence-of-harmonic-series/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/oresmes-proof-of-divergence-of-harmonic-series/</guid>
      <description>교대조화급수의 수렴성$\displaystyle \sum { n=1 }^{ \infty }{ \frac { 1 }{ n } }=\infty $조화급수는 언뜻 보기에 그 값이 계속 작아지므로 수렴할 것도 같지만 오렘은 이것이 발산한다는 것을 매우 간단하고 아름답게 증명했다.이러한 팩트는 주로 절대수렴의 개념을 설명하기 위한 예시로써 잘 쓰이는데, 교대조화급수는 $\displaystyle \sum{n=1}^{\infty} {{(-1)^{n-1}} \over {n}} = 1- {1 \over 2} + { 1 \over 3} - {</description>
    </item>
    
    <item>
      <title>조화평균을  활용해  평균속력  구하기</title>
      <link>https://freshrimpsushi.github.io/posts/14/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/14/</guid>
      <description>거리 $S$만큼 갈 때 속력 $a$로 이동하고 올 때 속력 $b$로 이동했다면 평균속력은 $\displaystyle \frac { 2ab }{ a+b }$시속 60km로 한 시간 이동한 후 시속 80km로 한 시간 더 이동했을 때 두 시간동안의 평균 속력은 70km/h다.이처럼 시간이 단위일 경우 쉽게 산술평균으로 답을 내놓을 수 있지만,단위가 거리일 경우 쉽게 답을 내기가 어렵다.가령 목적지까지 갈</description>
    </item>
    
    <item>
      <title>평행한 두 직선 사이의 거리를 구하는 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/4/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/4/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;20170206_182952.png&amp;rdquo; height=&amp;ldquo;299&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/2154184858C9FE680E&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;320&amp;rdquo;/&amp;gt; $$ \displaystyle d=\frac { |2k| }{ \sqrt { m^{ 2 }+1 } } $$ 이차곡선의 접선을 구하는 문제를 풀다보면 두 접선 사이의 거리를 구하라는 경우가 종종 있다. 물론 적당한 한 점과 다른 직선의 거리를 구하는 공식이 있기 때문에 구하는 것 자체가 어려운 것은 아니다. 하지만 아주 쉽고 빠르게 그 거리를 구할 수 있는 공식을 알고 있다면 조금이라도 계산량을 줄일 수 있을 것이다. 유</description>
    </item>
    
    <item>
      <title>산술평균과 기하평균 조화평균의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/3/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/3/</guid>
      <description>정의 n개의 양수 ${x}{1},{x}{2},\cdots,{x}_{n}$에 대해 산술, 기하, 조화평균은 다음과 같다. 산술평균 : $$ \displaystyle \sum { k=1 }^{ n }{ \frac { {x}{k} }{ n } }=\frac { {x}{1}+{x}{2}+\cdots+{x}_{n} }{ n } $$ 기하평균 : $$ \displaystyle \prod { k=1 }^{ n }{ { {x}{k} }^{ \frac { 1 }{ n } } }=\sqrt [ n ]{ {x}{1}{x}{2}\cdots{x}_{n} } $$ 조화평균 : $$ \displaystyle \left( \frac { \sum { k=1 }^{ n }{ \frac { 1 }{ {x}{k} } } }{ n } \right)^{-1}=\frac { n }{ \frac { 1 }{ {x}{1} }+\frac {</description>
    </item>
    
    <item>
      <title>1차원 맵의 랴푸노프 수</title>
      <link>https://freshrimpsushi.github.io/posts/lyapunov-number-of-one-dimensional-map/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lyapunov-number-of-one-dimensional-map/</guid>
      <description>스무스한 맵 $f : \mathbb{R} \to \mathbb{R}$ 의 한 오빗 $\left\{ x_{1} , x_{2} , x_{3} , \cdots \right\} $ 에 대해 $\displaystyle L ( x_{1} ) : = \lim_{ n \to \infty } \left( \prod_{i = 1}^{n} | f&#39; (x_{i} ) | \right)^{1/n}$ 을 **랴푸노프 수**Lyapunov Number 라고 하고 $\displaystyle h ( x_{1} ) := \lim_{n \to \infty } {{1} \over {n}} \sum_{i=1}^{n} \ln | f&#39; (x_{i} ) |$ 을 **랴푸노프 지수**Lyapunov Exponent 라고 한다.싱크와 소스의 개념을 다시금 생각해보면 싱크란 가까운 곳의 점이 모여드는 일종</description>
    </item>
    
    <item>
      <title>1차원 맵의 싱크와 소스</title>
      <link>https://freshrimpsushi.github.io/posts/sink-and-source-of-one-dimensional-map/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sink-and-source-of-one-dimensional-map/</guid>
      <description>스무스한 맵 $f : \mathbb{R} \to \mathbb{R}$ 에 대해 어떤 $p \in \mathbb{R} $ 가 고정점이라고 하자.(1) $| f&#39; (p) | &amp;lt; 1$ 이면 $p$ 는 싱크다.(2) $| f&#39; (p) | &amp;gt; 1$ 이면 $p$ 는 소스다.$1$차원 맵의 예로써 $f(x) = x^3$ 을 생각해보면 $f&#39;(x) = 3x^{2}$ 이므로 고정점 $f(0) = 0$ 은 싱크, $f(1) = 1$ 은 소스임을 쉽게 확인할 수 있다. 증명(1) $a \in \left( | f&#39;(p) | , 1 \right) $ 이라고 하자.$\displaystyle</description>
    </item>
    
    <item>
      <title>1차원 맵의 카오스</title>
      <link>https://freshrimpsushi.github.io/posts/chaos-of-one-dimensional-map/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaos-of-one-dimensional-map/</guid>
      <description>다차원 맵의 카오스맵 $f : \mathbb{R} \to \mathbb{R}$ 의 바운디드 오빗 $\left\{ x_{1} , x_{2} , \cdots \right\} $ 이 다음을 만족하면 이 오빗을 **카오틱**Chaotic 하다고 한다.**(i)** 어심토티컬리 피리어딕이 아니다.**(ii)** $h (x_{1} ) &amp;gt; 0$* 오빗이 바운디드라는 말은 모든 $n \in \mathbb{N}$ 에 대해 $|x_{n} | &amp;lt; M$ 을 만족하는 $M \in \mathbb{R}$ 이 존재한다는 뜻이다.* $h(x_{1} )$ 은 랴푸노프 지수를 말한</description>
    </item>
    
    <item>
      <title>2계 미분방정식의 두 번째 해를 구하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-second-solution-of-second-order-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-second-solution-of-second-order-differential-equation/</guid>
      <description>주어진 미분방정식이 $y^{\prime \prime }+p(t)y^\prime + q(t)y=0$ $\cdots \ \ (1)$이고, 하나의 해를 알고 있다고 하자.그 해를 $y_1$이라고 하면 두 번째 해를 찾는 방법은 아래와 같다. 일반해를 $y(t)=\nu(t) y_1(t)$라고 가정하자.$y$의 1계, 2계 미분을 구해보면$y^\prime = \nu ^\prime y_1 + \nu y_1^\prime $$ y^{\prime \prime} = \nu ^{\prime \prime}y_1 + \nu ^\prime y_1^\prime + \nu^ \prime y_1^\prime + \nu y_1^{\prime \prime} = \nu ^{\prime \prime}y_1 + 2\nu ^\prime y_1^\prime + \nu y_1^{\prime \prime}$ 구한</description>
    </item>
    
    <item>
      <title>2계 선형 동차 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-second-order-linear-homogeneous-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-second-order-linear-homogeneous-differential-equation/</guid>
      <description>주어진 미분방정식이 $ay^{\prime \prime} + by^\prime + cy=0$이고 특성 방정식 $ar^2+br+c=0$의 해를 $r_1$, $r_2$라고 할 때$1.$ $r_1$, $r_2$가 서로 다른 두 실수인 경우$(b^2-4ac&amp;gt;0)$ 일반해는 $$ y(t)=c_1e^{r_1t}+c_2e^{r_2t} $$ $2.$ $r_1$, $r_2$가 켤레 복소수 $\lambda \pm i \mu$인 경우$(b^2-4ac&amp;lt;0)$ 일반해는 $$ \begin{eqnarray*} y(t) &amp;amp;=&amp;amp; c_1e^{(\lambda + i\mu)t} + c_2e^{(\lambda – i\mu)t}</description>
    </item>
    
    <item>
      <title>2계 선형 동차 미분방정식의 해의 기본집합과 론스키안</title>
      <link>https://freshrimpsushi.github.io/posts/wronskian-and-fundamental-set-of-solution-of-second-order-linear-homogeneous-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/wronskian-and-fundamental-set-of-solution-of-second-order-linear-homogeneous-differential-equation/</guid>
      <description>주어진 2계 선형 동차 미분방정식이 다음과 같을 때 $W (y_1, y_2) \ne 0$이면 $y_1, y_2$는 주어진 미분방정식의 해의 기본집합이다.$ay^{\prime \prime}+ by^\prime +cy=0$주어진 2계 선형 동차 미분방정식이 아래와 같다고 하자.$ay^{\prime \prime}+ by^\prime +cy=0$미분 연산자를 $D := \dfrac{d}{dx}$라고 정의하면 $\dfrac</description>
    </item>
    
    <item>
      <title>2계 선형 비동차 미분방정식의 일반해</title>
      <link>https://freshrimpsushi.github.io/posts/general-solution-of-nonhomogeneous-second-order-linear-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-solution-of-nonhomogeneous-second-order-linear-differential-equation/</guid>
      <description>아래와 같은 비동차/동차 2계 선형 미분방정식을 생각해보자.$y^{\prime \prime}+p(t)y^\prime + q(t)y=g(t)$ $\cdots \ \ (1) $$ y^{\prime \prime}+p(t)y^\prime + q(t)y=0$ $\cdots \ \ (2)$이 때 $Y_1 (t)$와 $Y_2 (t)$가 비동차 미분방정식 $(1)$의 해이고, $y_1(t)$, $y_2(t)$가 동차 미분방정식 $(2)$의 기본 해집합이라고 하자. 그러면 아래의 식이 성립한다.$Y_1 (t) – Y_2 (t)= c_1y_1 (t)+c_2y_2(t)$ 증명 미분연</description>
    </item>
    
    <item>
      <title>2차·3차·n차 방정식의 근과 계수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/1691/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1691/</guid>
      <description>**2차 방정식의 근과 계수의 관계 2차 방정식 $ax^{2}+bx+c=0$의 두 근을 $\alpha$, $\beta$라고 하자. 그러면 아래의 식이 성립한다. $$ \alpha+\beta=-\frac{b}{a}\quad &amp;amp; \quad \alpha\beta= \frac{ c}{a} \tag{a} $$ **3차 방정식의 근과 계수의 관계 3차 방정식 $ax^{3}+bx^{2}+cx+d=0$의 세 근을 $\alpha$, $\beta$, $\gamma$라고 하자. 그러면 아래의 식이 성립한다. $$ \alpha</description>
    </item>
    
    <item>
      <title>2차원 자율 시스템에선 혼돈이 일어나지 않는다  푸앙카레-벤딕슨 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-poincare-bendixson-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-poincare-bendixson-theorem/</guid>
      <description>푸앙카레-벤딕슨 정리 $2$ 차원 매니폴드 $\mathcal{P}$ 와 함수 $f,g \in C^{r} \left( \mathcal{P} \right)$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x,y) \\ y&#39; = g(x,y) $$ $\mathcal{M}$ 이 벡터 필드의 유한한 수의 고정점을 가지는 양불변집합이라고 하면, $p \in \mathcal{M}$ 의 오메가 리미트 셋 $\omega (p)$ 은 다음 세가지 중 하나를 만족한다:(1)** $\omega (p) $ 는 홑원소 집합이다. 즉, 단 하나의 고정점만</description>
    </item>
    
    <item>
      <title>3차 방정식의 근의 공식</title>
      <link>https://freshrimpsushi.github.io/posts/1692/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1692/</guid>
      <description>증명 카르다노 방식 3차 방정식 $ax^{3}+bx^{2}+cx+d=0(a\ne0)$가 주어졌다고 하자. 풀이를 간단하게 하기 위해, 일반성을 잃지 않고 아래와 같이 나타내자. $$ x^{3}+ax^{2} +bx+c=0 \tag{1} $$ 2차항을 없애주기 위해 $x=t-{\textstyle \frac{a}{3}}$으로 치환하자. 그러면 $$ \begin{align*} &amp;amp;&amp;amp;\left( t- \frac{a}{3}\right)^{3}+a\left( t-\frac{a}{3} \right)^{2}+b\left( t-\frac{a}{3} \right) + c &amp;amp;=0 \\ \Rightarrow &amp;amp;&amp;amp; \left( t^{3}-\cancel{at^{2}}+\frac{a^{2}}{3}t-\frac{a^{3}}{27} \right)+\left(\cancel{at^{2}}-\frac{2a^{2}}{3}t + \frac{a^{3}}{9}\right) + \left( bt-\frac{ab}{3} \right) +c &amp;amp;= 0 \\ \Rightarrow &amp;amp;&amp;amp;</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 벡터 함수의 컬</title>
      <link>https://freshrimpsushi.github.io/posts/curl-of-vector-function-in-cartesian-coordinate-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/curl-of-vector-function-in-cartesian-coordinate-system/</guid>
      <description>한 줄 요약 : $\nabla \times \mathbf{F}$를 축으로 두고 오른손 법칙을 적용하면 실제 $\mathbf{F}$가 회전하는 방향과 같다.3차원 벡터 $\mathbf{F}=(F_{x},F_{y},F_{z})$에 대해서 아래의 연산을 $\mathbf{F}$의 **컬 혹은 회전** 이라고 한다. $$ \begin{align*} \nabla \times \mathbf{F} &amp;amp;=\begin{vmatrix} \hat{\mathbf{x}} &amp;amp; \hat{\mathbf{y}} &amp;amp; \hat{\mathbf{z}} \\ \frac{ \partial }{ \partial</description>
    </item>
    
    <item>
      <title>ab의 역원은 b의 역원과 a의 역원의 곱과 같음을 증명 socks-shoes property</title>
      <link>https://freshrimpsushi.github.io/posts/513/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/513/</guid>
      <description>socks shoes property 임의의 군 $G$의 원소 $a,b$에 대하여 $(ab)^{-1}=b^{-1}a^{-1}$이다. 증명 $(ab)^{-1}$는 $ab$의 역원이므로$ab(ab)^{-1}=e$양 변에 차례로 $a^{-1}$, $b^{-1}$를 곱해주면$b(ab)^{-1}=a^{-1}e=a^{-1} $$ \Rightarrow (ab)^{-1}=b^{-1}a^{-1}$ ■ 굉장히 간단하다.이름이 좀</description>
    </item>
    
    <item>
      <title>B-스플라인의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-b-splines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-b-splines/</guid>
      <description>오더가 $m\in \mathbb{N}$인 B-스플라인은 다음과 같은 성질을 만족한다.(a) $\mathrm{supp}N_{m}=[0,m]$ $\text{and}$ $N_{m}(x)&amp;gt;0 \text{ for } x\in(0,m) $**(b)** $\displaystyle \int _{-\infty} ^{\infty} N_{m}(x)dx=1$**(c)** $m\ge 2$에 대해서 아래의 식이 성립한다. $$ \begin{equation} \sum \limits_{k \in \mathbb{Z}} N_{m}(x-k)=1,\quad \forall x\in \mathbb{R} \label{eqc} \end{equation} $$ **(c&#39;)** $m=1$일 때, 위 식은 $x\in \mathbb{R}\setminus \mathbb{Z}$에 대해서 성립한다.** **(c)** 는 다시 말해 $\left\{ N_{m}(x-k) \right\}_{k}$가 단위 분할이라는 뜻이다</description>
    </item>
    
    <item>
      <title>B-스플라인의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transform-of-b-splines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transform-of-b-splines/</guid>
      <description>오더가 $m \in \mathbb{N}$인 B-스플라인 $N_{m}$의 푸리에 변환은 다음과 같다. $$ \widehat{N_{m}}(\gamma)=\left( \frac{1-e^{-2\pi i\gamma}}{2\pi i \gamma} \right)^{m} $$ 이때 $f$의 푸리에 변환 $\widehat{f}$의 정의는 다음과 같다. $$ \widehat{f}(\gamma):=\int _{-\infty} ^{\infty} f(x)e^{-2\pi i x\gamma}dx $$ B-스플라인, 푸리에 변환, 컨볼루션의 성질을 이용하여 어렵지 않게 계산할 수 있다. 증명 우선 $N_{1}$의 푸리에 변환을 계산</description>
    </item>
    
    <item>
      <title>k-평균 군집화</title>
      <link>https://freshrimpsushi.github.io/posts/k-means-clustering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k-means-clustering/</guid>
      <description>$p$ 차원의 데이터 $N$ 개와 자연수 $k$ 가 주어져있다고 하자.**Step 1. $k$ 개의 점 $\mu_{1} , \cdots , \mu_{k} $ 을 랜덤하게 정한다. 각각의 $\mu_{j}$ 는 군집 $M_{j}$ 의 평균이 될 것이다.**Step 2.** $i$ 번째 데이터 $x_{i}$ 와 $j = 1 , \cdots , k$ 에 대해서 $| x_{i} - \mu_{j} | $ 를 계산한다. 그 중 가장 작은 것을 골라 $x_{i} \in M_{j}$ 이 되도록 한다. 이를 각각의 $i = 1 , \cdots , N $ 에 대해 반복한다.**St</description>
    </item>
    
    <item>
      <title>lp 공간</title>
      <link>https://freshrimpsushi.github.io/posts/lp-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lp-space/</guid>
      <description>$1 \le p &amp;lt; \infty$ 에 대해 거리공간 $( \mathcal{l}^{p} , d^{p} ) $ 는 다음과 같이 정의된다.(i) 수렴하는 수열의 집합 : $\displaystyle \mathcal{l}^{p} := \left\{ \left\{ x_{n} \right\}_{n \in \mathbb{N}} \subset \mathbb{C} , \left| , \left( \sum_{i=1}^{\infty} | x_{i} |^{p} \right)^{{1} \over {p}} &amp;lt; \infty \right. \right\}$**(ii) 거리 함수** : $\displaystyle d^{p} ( x_{n} , y_{n} ) := \left( \sum_{i = 1}^{\infty} | x_{i} - y_{i} |^{p} \right)^{ {{1} \over {p}} } $ 단, $ \left\{ x_{n} \right\} , \left\{ y_{n} \right\} \in \mathcal{l}^{p} $$ p = \infty$ 에 대해 거리공간 $( \mathcal{l}^{\infty} , d^{\infty} ) $ 는 다음과 같이 정의된다.**(i)&#39; 유계 수열의 집</description>
    </item>
    
    <item>
      <title>Lp 공간에 대한 리즈 표현 정리</title>
      <link>https://freshrimpsushi.github.io/posts/riesz-representation-theorem-for-lp-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riesz-representation-theorem-for-lp-space/</guid>
      <description>리즈 표현 정리$(\mathrm{Riesz\ representation\ theorem}) $$ X$를 힐베르트 공간이라 하자. 그러면 아래의 두 문장은 서로 동치이다.$(a)$ $x^{ * }$는 $X$ 위에서 정의된 선형 범함수이다.$(b)$ 모든 $y\in X$에 대해서 $x^{ * }(y)=\langle x,\ y\rangle_X$를 만족하는 유일한 $x\in X$가 존재한다. 또한 $| x^{ * }\ ; X^{ * }|=|x\ ;X|$이다.$\lang</description>
    </item>
    
    <item>
      <title>m이 음수인 경우의 연관 르장드르 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/the-associated-legendre-polynomial-for-negative-m/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-associated-legendre-polynomial-for-negative-m/</guid>
      <description>연관 르장드르 다항식은 $m$의 부호에 따라 아래의 비례식이 성립한다. $$ P_{l}^{-m}(x)=(-1)^{m}\frac{(l-m)!}{(l+m)!}P_{l}^{m}(x) $$ $$ (1-x^{2})\frac{ d^{2}y }{ dx^{2} }-2x \frac{dy}{dx}+\left( \frac{-m^{2}}{1-x^{2}}+l(l+1) \right)y=0 $$ 연관 르장드르 미분 방정식을 보면 $m$에 대한 부분이 $m^2$으로 나타나있으므로 $m$이 음수인지 양수인지에 대해서는 해에 영향을 주지 않는다. 그래서 연관 르장드르 다항식도 아래와 같이 이끌어냈다. $$ \begin{align*} P_{l}^{m}(x)&amp;amp;= (1-x ^{2})^{\frac{|m|}{2}} \frac{ d^{|m|} }{ dx^{|m|} } P_{l}(x) \\ &amp;amp;=(1-x ^{2})^{\frac{|m|}{2}} \frac{ d^{|m|} }{</description>
    </item>
    
    <item>
      <title>p값 혹은 유의확률에 대한 흔한 오개념들</title>
      <link>https://freshrimpsushi.github.io/posts/significance-probability-p-value/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/significance-probability-p-value/</guid>
      <description>요약 : p-value가 아주 작다는 것은 그만큼 드문 일이라는 뜻으로, 단순한 우연으론 보기 어려우며 대립가설을 기각하기 어려움을 의미한다.가설검정에서 검정통계량이 귀무가설을 기각하도록 나타날 확률로써 귀무가설을 기각하게 되는 최소의 유의수준을 유의확률Significance Probability 혹은 p값p-value 이라고 한다.[1] p값은</description>
    </item>
    
    <item>
      <title>QR 분해를 통한 최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/least-squares-using-qr-decomposition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/least-squares-using-qr-decomposition/</guid>
      <description>$A \in \mathbb{C}^{m \times n}$ 과 벡터 $\mathbb{b} \in \mathbb{C}^{m}$ 에 대해 $\text{rank} A = n$ 이고 $A \mathbb{x} = \mathbb{b}$ 의 최소제곱해를 $\mathbb{x}{*}$ 이라고 하자.Step 1. QR 분해$A = \widehat{Q} \widehat{R}$ 을 만족하는 정규직교행렬 $\widehat{Q}$ 과 상삼각행렬 $\widehat{R}$ 을 구한다.**Step 2. QR 분해에서 얻은 $\widehat{Q}$ 를 통해 정사영 $P : = \widehat{Q} \widehat{Q}^{ * }$ 을 구한다.$A \mathbb{x}{} = P \mathbb{b}$ 이므로 $\widehat{Q} \widehat{R} \mathbb{x}_{} = \widehat{Q} \widehat{Q}^{ * } \mathbb{b}$ 이고 양변의 왼쪽에 $\widehat{Q}^{ * }$ 을 곱해 $ \widehat{R} \mathbb{x}{*} = \widehat{Q}^{ * } \mathbb{b}$ 를 얻</description>
    </item>
    
    <item>
      <title>R 에서 EACF를 사용한 ARMA 모형 선택법 How to Determine ARMA Model using EACF in R</title>
      <link>https://freshrimpsushi.github.io/posts/1216/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1216/</guid>
      <description>확장자기상관함수에 대한 이론적 설명PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다.직접 그 예를 살펴보자. ma1.2.s 데이터는 $MA(1)$ 모델에서, ar1.s 데이터는 $AR(1)$ 모델에서 나온 TSA 패키지의 샘플 데이터다. TSA 패키지의 acf() 함수와 pacf() 함수를 사용하면 다음과 같이 여러 시차 $k$ 에 대해 코릴로그램Correlogram 을 그려준다.그</description>
    </item>
    
    <item>
      <title>R 에서 그래프 그릴 때 사용하는 심볼들</title>
      <link>https://freshrimpsushi.github.io/posts/669/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/669/</guid>
      <description>각종 그래프 관련 함수에서 찍히는 점의 모양을 바꿀 때 pch 옵션을 사용한다. 위 그림은 특히 자주 쓰는 심볼들을 한 눈에 볼 수 있게 나타낸 것이다.쓸만한 게 많지만 특히 16번이 자주 쓰이며, 25번 이후에도 일단 마크 자체는 정해져 있으나 쓸만한 게 없다. 아래 예제 코드에서 sym을 26부터 50으로 고치고 확인해볼 수 있다. 한편 21번부터 25번은 bg 옵션</description>
    </item>
    
    <item>
      <title>R 에서 그래프 그릴 때 축 이름에 아래첨자 넣기</title>
      <link>https://freshrimpsushi.github.io/posts/905/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/905/</guid>
      <description>R 에서도 변수의 이름에 언더바_를 넣는 것은 허용되지만, 그래프에서도 그렇게 나타낸다면 심하게 가독성이 떨어진다.expression() 함수를 아래와 같이 사용하면 축 이름에도 보기 좋게 아래첨자를 넣을 수 있다. data&amp;lt;-as.numeric(lynx) win.graph(4,4) plot(data[-1],data[-length(data)],type=&amp;#39;p&amp;#39;,ma</description>
    </item>
    
    <item>
      <title>R 에서 그래프에 문자열 찍기</title>
      <link>https://freshrimpsushi.github.io/posts/667/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/667/</guid>
      <description>text() 함수를 통해 그래프에 문자열이 찍히도록 할 수 있다.첫번째 옵션은 $x$ 축 좌표의 벡터, 두번째 옵션은 $y$ 축 좌표의 벡터, 세번째 옵션은 입력될 문자열의 벡터를 받는다.아래의 예제코드에서 t만 바꿔가면서 실행시켜보면 바로 이해가 될 것이다. win.graph(6,5) plot(x=0,y=0,xlim=c(-1,5),ylim=c(-1,4),xlab=&amp;#34;x&amp;#34;,ylab=&amp;#34;y&amp;#34;) points(4,3,col=&amp;#34;red&amp;#34;,pch=19) #1 abline(h=0) #2 abline(v=0) #3 abline(0,3/4) #4 segments(4,0,4,3) x=c(2,-0.2,2,4.2) y=c(-0.2,2,2,2) t=c(&amp;#34;(1)&amp;#34;,&amp;#34;(2)&amp;#34;,&amp;#34;(3)&amp;#34;,&amp;#34;(4)&amp;#34;) t=c(&amp;#34;(하나)&amp;#34;,&amp;#34;(둘)&amp;#34;,</description>
    </item>
    
    <item>
      <title>R 에서 다중회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</guid>
      <description>다중회귀분석 보러가기 회귀계수의 F검정 보러가기 하단에 예제코드 전체가 있다. 수학, 통계적인 기초가 부족한 비전공자는 밑줄 그어진 부분만 읽어도 상관 없다. 단순회귀분석이 뭔지 잘 모르겠다면 단순회귀분석을 먼저 공부해야한다. tail(attitude)``` R에서 [내장데이터 attitude를 불러와](http://freshrimpsushi.tist</description>
    </item>
    
    <item>
      <title>R 에서 데이터 파일 빠르게 읽기</title>
      <link>https://freshrimpsushi.github.io/posts/1270/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1270/</guid>
      <description>R 은 기본적으로 csv 데이터를 읽는 함수로써 read.csv()를 제공하지만, 그냥 간편하게 쓰는 정도가 아니라 실전적인 분석을 하고 있다면 성능이 너무 떨어져서 써먹을 것이 못 된다. 그 대안으로써, readr 패키지에서 제공하는 read_csv()를 사용할 것을 강력하게 권장한다. read_csv()는 c++로 작성되었으며, 매우 빠른 속도로</description>
    </item>
    
    <item>
      <title>R 에서 데이터 프레임의 열과 행 이름 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/840/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/840/</guid>
      <description>R 에서 데이터 프레임을 이용해 복잡한 코드를 짜다보면 디폴트로 정해주는 열 이름들이 헷갈려서 바꿔줘야 할 상황이 있다.예제로써 위 데이터 프레임을 보면 별 다른 언급이 없으면 V1, V2, V3처럼 무성의하고 구분하기 힘든 열 이름이 주어진다.여기에 names() 함수를 씌우면 열 이름을 반환하며, 반대로 거기에 바로 문자열을 넣어 열 이름을 바꿀 수 있다.그냥 단순히 대입</description>
    </item>
    
    <item>
      <title>R 에서 두 배열의 성분 비교하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-compare-array-in-r/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-compare-array-in-r/</guid>
      <description>R 은 데이터의 형태, 구조보단 그 내용에 관심이 많은 분야에서 많이 쓰이므로 그 비교 역시 유용하다.1. 포함관계 (전혀 중요하지는 않지만, 예제에서 A는 삼각수 $\displaystyle {{n(n+1)} \over {2}}$ 이고 B는 사각수 $m^2$ 를 나타낸다.)이항연산자 %in% 을 사용해 두 배열을 비교해보면 A의 성분 중 B에도 속하는 성분에 대해 참, 그렇지 않으면 거짓으로 반환해준다. 다음과 같이 문자열을</description>
    </item>
    
    <item>
      <title>R 에서 로지스틱 회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/850/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/850/</guid>
      <description>로지스틱 회귀분석 보러가기 호스머-렘소 적합도 검정 보러가기 하단에 예제코드 전체가 있다. 내장데이터 turnout 데이터를 불러와보자. turnout는 1992년 미국 총선에 대한 데이터로써, race(인종), 연령(age), 교육수준(educate), income(수입)에 따른 vote(투표여부)를 파악할 수 있다. 이 데이터는 투</description>
    </item>
    
    <item>
      <title>R 에서 멱함수 그래프 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-power-function-in-r/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-power-function-in-r/</guid>
      <description>귀무가설 $H_{0} : \theta \in \omega_{0}$ 과 대립가설 $H_{1} : \theta \in \omega_{1}$ 에 대해 유의수준 $\alpha$ 의 기각역을 $C_{\alpha}$ 라고 하자. 참값 $\theta$ 에 대한 함수 $\gamma_{C_{\alpha}}(\theta) : = P_{\theta} [ \mathbb{x} \in C_{\alpha} ]$ 를 **멱함수**Power Function 라고 한다.다른 표현으로는 $\gamma_{C_{\alpha}}(\theta) : = 1 - P_{\theta}[\text{Type 2 Error}]$ 이다.유의확률과 마찬가지로 정의만 읽어서 멱함수를 이해하는 것은 정말 쉽지 않으니 그림으로 된 예시부터 보자.위 그래프에서 양쪽꼬리검정은</description>
    </item>
    
    <item>
      <title>R 에서 범주형 데이터의 숫자를 숫자형 데이터로 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/factor-to-numeric-in-r/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factor-to-numeric-in-r/</guid>
      <description>숫자임에도 불구하고 범주형 자료로 읽혀서 연속형 데이터로 바꾸고 싶은데 생각대로 되지 않는 이들을 위한 팁이다. 이 포스트는 지면 대부분을 그 원리를 설명하기 위해 할애하고 있으므로 결론만 필요하면 밑에서부터 읽기를 추천한다. 보통 자료형을 바꿀 때는 Cast라는 표현을 사용한다. R 을 이용해서 통계분석을 할 때 가장 중요한것은 테크닉 이전에 데이터</description>
    </item>
    
    <item>
      <title>R 에서 벡터끼리 내적 계산하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-inner-product-in-r/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-inner-product-in-r/</guid>
      <description>x&amp;lt;-1:10; x y&amp;lt;-(-1)^(1:10); y sum(x*y) x %*% y x %o% y R 에서 분석 혹은 시뮬레이션을 하다보면 가중치가 적용된 기댓값을 구할 일이 종종 있다. 물론 수식적으로 $\displaystyle \left&amp;lt; \mathbb{x}, \mathbb{y} \right&amp;gt; = \sum_{i=1}^{n} x_{i} y_{i}$ 는 아주 간단하고 R 자체의 벡터 계산이 아주 편리하기 때문에 sum() 함수만 있다면 쉽게 내적을 할 수 있다. 그러나 이는 길게 보았을 때 코드의 가독성을 떨어뜨리는 요인이 된다.한편 $n$ 차원 벡터는 $1 \times n$ 차원 행렬</description>
    </item>
    
    <item>
      <title>R 에서 여러가지 분포함수</title>
      <link>https://freshrimpsushi.github.io/posts/578/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/578/</guid>
      <description>R 에서 특정 분포에 대한 함수들은 다음과 같은 접두어와 접미어의 조합으로 만들어진다.**접두 확률분포 $X$ 의 확률분포함수를 $f(x)$ 라고 하자.r- : 랜덤 추출, 확률분포 $X$ 에서 나온 $x_{1}, \cdots , x_{n}$ 을 생각하면 좋다.**d-** : 분포함수, $f(x)$**p-** : 누적분포함수,\ $F(x) = \displaystyle \int_{\infty}^{x} f(t) dt$**q-** : 분위수함수 $F^{-1}(\alpha)$**접미 이름이 알려진 분</description>
    </item>
    
    <item>
      <title>R 에서 올림 내림 반올림 자릿수 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-round-numbers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-round-numbers/</guid>
      <description>ceiling() 함수는 올림 처리를, floor() 함수는 내림 처리를 해준다. 이런 함수들은 주로 통계를 다루는 R 에서는 필요 없어 보이지만 의외로 데이터 핸들링을 할 때 써먹기가 편하다.trunc() 함수는 소수점 아래를 모두 버려주는 건 똑같지만 $0$ 에 더 가까운 쪽으로 값을 반환해준다.round() 함수와 signif() 함수 모두 자리수를 남기지만 round()는 소수점 아래를</description>
    </item>
    
    <item>
      <title>R 에서 외부 데이터 불러오기 EOF within quoted string 해결</title>
      <link>https://freshrimpsushi.github.io/posts/496/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/496/</guid>
      <description>R 은 기본적으로 통계학을 위해 태어난 언어기 때문에 데이터의 입력 역시 편리하게 되어있다. read.table(file, header = FALSE, sep = &amp;#34;&amp;#34;, na.strings = &amp;#34;NA&amp;#34;, fileEncoding = &amp;#34;&amp;#34;) read.table()은 데이터 테이블을 불러들이는 함수로써 위와 같이 여러가지 유용한 옵션을 제공한다. 옵션자체는 더 많이 있지만, 자주 쓰이고 반드시 알아두어야할 것을 추린 것이다. 다음의 설명들을 참고하자 :(1) header : 첫줄</description>
    </item>
    
    <item>
      <title>R 에서 자리수 출력 제한 없애기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-unlimit-digits-and-print-in-r/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-unlimit-digits-and-print-in-r/</guid>
      <description>R 이 통계학을 위한 언어긴하지만 막상 R 콘솔은 데이터를 보는데 적합하지 않다.그럼에도 불구하고 관측치가 수십만개에 달하는 빅데이터를 다룰 때나 핸들링이 잘 되었나 확인할 땐 단순 출력이 편하다.관측치가 조금 많을 때 콘솔로 출력해보면 위와 같이 아랫부분이 뭉텅 잘려나온다.이럴 땐 콘솔창에 options(max.print = .Machine$integer.max)를 입</description>
    </item>
    
    <item>
      <title>R 에서 현재 날짜 시간 확인하기</title>
      <link>https://freshrimpsushi.github.io/posts/1020/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1020/</guid>
      <description>R 뿐만이 아니라 프로그래밍 언어를 사용해야하는 많은 작업에서 로그를 작성하고 해당 시각에 대한 정보가 필요하다. R 에서는 Sys.Date() 함수를 통해 날짜를 확인할 수 있으며, Sys.time() 함수를 통해 초 단위까지의 정확한 시각을 알 수 있다. 대소문자에 주의해야하며, 만약 날짜가 필요 없다면 문자열을 쪼개서 시각에 대한 정보만 취하면 될 것이다.</description>
    </item>
    
    <item>
      <title>R 패키지 설치 시 Warning in installpackages  lib = CProgram FilesRR-361library is not writable 해결</title>
      <link>https://freshrimpsushi.github.io/posts/1414/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1414/</guid>
      <description>R 을 처음 접하는, 그 중에서 프로그래밍은 고사하고 컴퓨터에 익숙하지조차 않지만 당장 R을 사용해야하는 사용자의 눈높이에 맞췄으므로 지나치게 설명이 자세할 수 있다.WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding: https://cran.rstudio.com/bin/windows/Rtools/빨리 R</description>
    </item>
    
    <item>
      <title>S-L 문제에서 고유값과 고유함수 Eigenvalue and Eigenfunctions for S-</title>
      <link>https://freshrimpsushi.github.io/posts/l-problem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/l-problem/</guid>
      <description>만약 스튀름-리우빌 미분 방정식 $$ \left[ p(x)u&#39;(x) \right]&#39;+\left[ q(x) +\lambda w(x) \right]u(x)=0 \tag{1} $$ 이 $0$이 아닌 솔루션 $u \in L_{r}^{2}(a,b)$를 가지면, $\lambda$를 고유값이라 하고 이에 대응하는 $u$를 고유함수라고 한다.여기에서 말하는 고유값이란 선형 대수학에서 말하는 그 고유값과 같다. 고유값이라 부르는 이유는 아래의 과정을 보면 이해할 수 있다. 우선</description>
    </item>
    
    <item>
      <title>가법성을 가진 연속함수의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/1102/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1102/</guid>
      <description>[1] 연속함수 $f : \mathbb{R} \to \mathbb{R}$ 가 모든 $x, y \in \mathbb{R}$ 에 대해 $f(x + y) = f(x) + f(y)$ 을 만족하면 $f(x) = f(1) x$[2] 연속함수 $g : \mathbb{R} \to ( 0 , \infty )$ 가 모든 $x, y \in \mathbb{R}$ 에 대해 $g(x + y) = g(x) g(y)$ 을 만족하면 $g(x) = \left( g(1) \right)^x $$ f(x + y) = f(x) + f(y)$ 와 같이 덧셈이 함수를 넘나들면서 보존되는 성질을 가법성이라 하고 곱셈이 보존되는 성질을 승법성이라고 한다. $g$ 는 가법성과 승법성이 반반 섞인 느낌의 호모몰</description>
    </item>
    
    <item>
      <title>가우스 구적법</title>
      <link>https://freshrimpsushi.github.io/posts/gaussian-quadrature/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gaussian-quadrature/</guid>
      <description>$f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 $a = x_{1} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. $$ \displaystyle I_{n} (f) := \sum_{j=1}^{n} w_{j} f ( x_{j} ) \approx \int_{a}^{b} w(x) f(x) dx = I ( f ) $$ 위와 같이 정의된 $I_{n}$ 의 가중치 $w_{j}$ 들을 구해서 수치적 적분을 계산하는 것을 **가우스 구적법** 이라고 한다. $f$ 를 잘 근사하는 다항함수 $p_{n-1}$ 이 존재하는 것은 보장되어있기 때문에, $f$ 대신 $p_{n-1}$ 을 생각해보려</description>
    </item>
    
    <item>
      <title>가우시안 링의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-of-gaussian-ring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-of-gaussian-ring/</guid>
      <description>가우시안 링 $\mathbb{Z}[i]$ 에 대해 함수 $N : \mathbb{Z}[i] \to \mathbb{Z}$ 를 생각해보자.[1] $N(x + iy) := x^2 + y^2$ 이라고 정의하면 $N$ 은 $\mathbb{Z}[i]$ 의 승법적 놈이 된다.[2] $\mathbb{Z}[i]$ 은 유클리디안 도메인이다.[3] $\mathbb{Z}[i]$ 의 유닛은 $1,-1,i,-i$ 뿐이다.가우스 정수는 추상대수의 도움을 받으면 훨씬 편하게 연구할 수 있다. 인티그럴 도메인에서 정의되는 놈 $N$ 으로 [2] 를 증명하면 ED가 UFD 이므로 가우스 소수로 확장된 산</description>
    </item>
    
    <item>
      <title>가중 Lp 공간 Weighted Lp Space</title>
      <link>https://freshrimpsushi.github.io/posts/1856/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1856/</guid>
      <description>다음과 같이 정의되는 함수 공간을 가중 $L^{p}$ 공간 혹은 구체적으로 $w$-가중 $L^{p}$ 공간 이라고 한다. $$ L_{w}^{p}(a,b):= \left\{ f : \mathbb{R}\to \mathbb{C}\ \big|\ \int_{a}^{b} \left| f(x) \right|^{p}w(x)dx &amp;lt;\infty \right\} $$ 이때 $w:\mathbb{R}\to[0,\infty)$를 가중 함수$(\mathrm{weight\ function})$라 한다.$L^{p}$ 공간을 일반화한 공간 중 하나이다. $w(x)=</description>
    </item>
    
    <item>
      <title>각운동량 연산자를 행렬로 표현하기기</title>
      <link>https://freshrimpsushi.github.io/posts/463/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/463/</guid>
      <description>$L_z$와 $L^2$의 동시 고유함수는 $|lm&amp;gt;$고유값 방정식은$L_z|l,m&amp;gt;=m\hbar |l,m&amp;gt; $$ L^2|l,m&amp;gt;=l(l+1)\hbar ^2|l,m&amp;gt;$ 이므로$&amp;lt;l,m&#39; |L_z|l,m&amp;gt;=m\hbar &amp;lt;l,m&#39;|l,m&amp;gt;=m\hbar \delta_{mm&#39;}$ 이다.$l=1$일 때 $L_z$를 행렬로 표현하면 가능한 $m$은 $1, 0, -1$이고$m&#39;=m$일 때만 행렬성분의 값이 0이 아니므로$L_z=\hbar \begin{pmatrix} 1 &amp;amp; 0 &amp;amp; 0 \\ 0</description>
    </item>
    
    <item>
      <title>각운동량 연산자의 각 성분끼리의 교환 관계 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/298/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/298/</guid>
      <description>각운동량 연산자의 교환 관계$\mathrm{commutation\ relation}$ $\left[L_j,\ L_k \right]=i\hbar \epsilon_{jkm}L_m$각운동량은 물체(입자)의 위치와 운동량의 외적으로 정의한다.$\vec L = \vec r \times \vec p$각운동량 연산자의 교환자 관계를 구하는 것은 각운동량의 정의로부터 시작된다.$\vec L = \vec r \times \vec p = (yp_z-zp_y)\mathbf{\hat x}+(zp_x-xp_z)\mathbf{\hat y} + (xp_y-yp_x)\mathbf{\hat z} $$</description>
    </item>
    
    <item>
      <title>각운동량 연산자의 제곱과 각운동량 연산자의 각 성분의 교환 관계가 0임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/300/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/300/</guid>
      <description>$L^2$과 $L_z$는 서로 교환 가능하다 $(\mathrm{commutativity}) $$ [L^2, L_z]=0$※ $[A,B]=0$이면 $A$와 $B$는 교환 관계$\mathrm{commutation\ relation}$가 $0$이다, $\mathrm{commute}$하다고 표현한다. 증명 ** (각운동량 연산자의 성분 끼리의 교환 관계)$\begin{eq</description>
    </item>
    
    <item>
      <title>감마 분포와 지수 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-exponential/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-exponential/</guid>
      <description>$$ \displaystyle \Gamma \left(1, { 1 \over \lambda } \right) \iff \text{exp} (\lambda) $$ 지수 분포의 직관적인 정의를 생각해보면 어떤 사건이 일어날때까지 걸리는 시간에 관심이 있는 것이다. 이산 확률 분포로 따지자면 기하 분포가 이에 해당한다.이때 기하 분포를 사건의 &amp;lsquo;발생 횟수&amp;rsquo;에 대해 일반화한 것이 음이항 분포다. 이런 센스에서, 지수 분포를 일반화한 것은 감마 분포라고 할 수</description>
    </item>
    
    <item>
      <title>감마 분포와 카이제곱 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-chi-squared/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-chi-squared/</guid>
      <description>$$ \displaystyle \Gamma \left( { r \over 2 } , 2 \right) \iff \chi ^2 (r) $$ 감마 분포와 카이제곱 분포는 위와 같은 성질을 가진다.Strategy : 두 분포의 적률생성함수가 같은 형태로 나타날 수 있음을 보인다. 증명 카이제곱분포 $\chi ^2 (r)$ 의 적률생성함수는 $ \displaystyle m_{1}(t) = (1- 2t)^{- {r \over 2} }$ 이고 감마분포 $\Gamma(k, \theta)$ 의 적률생성함수는 $m_{2}(t) = (1-\theta t)^{-k}$ 이다. 감마분포의 적률생성함수에 $\displaystyle k = {r \over 2}$ 과 $\theta = 2</description>
    </item>
    
    <item>
      <title>감마 분포와 푸아송 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-poisson/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-poisson/</guid>
      <description>모든 자연수 $k$ 에 대해 $$ \displaystyle \int_{\mu}^{\infty} { { z^{k-1} e^{-z} } \over { \Gamma (k) } } dz = \sum_{x=0}^{k-1} { { {\mu}^{x} e^{-\mu} } \over {x!} } $$ 이 등식은 감마 분포와 푸아송 분포의 누적 확률 분포 함수가 서로 관련이 있음을 보여준다. 이는 감마 분포가 지수 분포와의 관계를 가진다는 점에서 충분히 그럴법하다고 말할 수 있다. 증명 $k=1$ 일 때 $$ \displaystyle \int_{\mu}^{\infty} { { z^{0} e^{-z} } \over { \Gamma (0) } } dz = e^{-\mu} = \sum_{x=0}^{0} { { {\mu}^{x} e^{-\mu} } \over {x!} } $$ $k=N$일 때</description>
    </item>
    
    <item>
      <title>감마 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-gamma-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-gamma-distribution/</guid>
      <description>$X \sim \Gamma ( \alpha , \beta )$ 면 $$ E(X) = k \theta \\ \text{Var} (X) = k \theta^{2} $$ Strategy : 감마 분포의 정의와 감마 함수의 기본적인 성질로 직접 연역한다. $x$ 의 차수가 변하는만큼 계수의 분자 분모를 맞춰주는 트릭을 쓴다.감마 분포의 정의$k, \theta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\Gamma ( k , \theta )$ 를 감마 분포 라고 한다. $$ f(x) = {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x^{k - 1} e^{ -</description>
    </item>
    
    <item>
      <title>강제 조화 진동과 공명 진동수</title>
      <link>https://freshrimpsushi.github.io/posts/forced-harmonic-oscillation-and-resonance-frequency/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/forced-harmonic-oscillation-and-resonance-frequency/</guid>
      <description>단순 조화 진동감쇠 진동다중 스프링 진동결합 진동**강제 조화 진동 물체가 용수철에 매달려 진동하는 것과 같은 운동을 조화 운동이라 한다. 이때 공기저항 등의 마찰력을 포함하는 다른 외력은 존재하지 않고 오로지 용수철 상수 $k$로 인한 복원력만 작용하는 경우를 단순 조화 진동 이라 부른다. 마찰력과 같이 속도에 비례하는 외력이 존재하면 감쇠 조화 진동 이</description>
    </item>
    
    <item>
      <title>거리공간에서 위상동형이란</title>
      <link>https://freshrimpsushi.github.io/posts/homeomorphism/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homeomorphism/</guid>
      <description>두 거리공간 $\left( X, d_{1} \right)$ 과 $\left( Y, d_{2} \right)$ 에 대해 전단사 $f : X \to Y$ 가 존재해서 $f$ 와 그 역함수 $f^{-1}$ 모두 연속함수면 $f$ 를 **위상동형사상** 이라 부르고 두 거리공간이 **위상동형**Homeomorphic 이라 한다.거리공간에 대한 위상동형의 정의는 언뜻 공허해보인다. 물론 그도 그럴게, 거리공간 자체가 충분히 좋은 공간인데다가 두 거리공간이 위상</description>
    </item>
    
    <item>
      <title>게이지 변환</title>
      <link>https://freshrimpsushi.github.io/posts/gauge-transformation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gauge-transformation/</guid>
      <description>쿨롱 게이지와 로렌츠 게이지 스칼라전위 $V$와 벡터전위 $\mathbf{A}$는 전기장 $\mathbf{E}$와 자기장 $\mathbf{B}$를 유일하게 결정하지만 역은 성립하지 않는다. 하나의 전자기장 $\mathbf{E}$, $\mathbf{B}$를 표현하는 전위 $V$, $\mathbf{A}$는 여러개가 존재한다는 말이다. 따라서 $\ma</description>
    </item>
    
    <item>
      <title>결합 진동</title>
      <link>https://freshrimpsushi.github.io/posts/coupled-oscillation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coupled-oscillation/</guid>
      <description>단순 조화 진동감쇠 진동강제 진동다중 스프링 진동1. 단순 결합 진동 ** 두 물체 $m_{1}$, $m_{2}$가 위 그림과 같이 2개의 스프링으로 연결되어 있다고 하자. 그리고 물체 $m_{1}$이 평형점으로부터 떨어진 거리를 $x_{1}$, 물체 $m_{2}$가 평형점으로부터 떨어진 거리를 $x_{2}$라고 하자. 스프링이 물체에 작용하는 복원력은 용수철 상수와 용</description>
    </item>
    
    <item>
      <title>계단 함수</title>
      <link>https://freshrimpsushi.github.io/posts/step-functionheaviside-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/step-functionheaviside-function/</guid>
      <description>**** **계단 함수 정의역이 여러 개의 부분구간으로 나뉘어 질 때, 각 부분구간 내에서는 상수함수이며 부분구간의 경계에서 불연속인 함수를 계단 함수 라 한다. 아래의 그림을 보면 알겠지만 계단처럼 생겨서 계단 함수이다. Heaviside function 이라고도 하는데 헤비사이드는 사람 이름이다. 전기회로의 미분방정식을 푸는 방법을 만든 사람이라고 한다. 그 방법이 바로 라플라스</description>
    </item>
    
    <item>
      <title>계단 함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-step-functionheaviside-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-step-functionheaviside-function/</guid>
      <description>$u_c(t)=\begin{cases} 0 &amp;amp; t&amp;lt;c \\ 1 &amp;amp; t \ge c \end{cases}$일 때$\mathcal{L} \left\{ u_c(t) \right\} = \dfrac{e^{-cs}}{s}$ $s&amp;gt;0 $$ u_c(t)$는 특정한 값(여기서는 $c$) 미만에서는 함숫값이 $0$이고 그 이상으로는 함숫값이 $1$인 계단 함수 를 말한다. 특별히 단위 계단 함수(Unit Step Function) 라 한다.우리가 다루는 변수 $t$는 시간이므로 $t&amp;gt;0$이고 이는 따로 언</description>
    </item>
    
    <item>
      <title>고리 원통 껍질의 관성모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-hoop-cylinderical-shell/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-hoop-cylinderical-shell/</guid>
      <description>반지름이 $a$, 질량이 $m$인 고리의 관성모멘트는 다음과 같다. $$ \displaystyle I=ma^2 \ \ or \ \ I=\frac{1}{2}ma^2 $$ 반지름이 $a$이고 질량이 $m$인 얇고 균일한 원형 고리(혹은 원통형 껍질)의 관성모멘트를 구해보자. 회전축이 고리가 만드는 평면에 수직하는 경우와 고리가 만드는 평면과 나란한 경우가 있다.1. 회전축이 고리의 중심을 지나고, 고리가 만드는 평면에 수직하는</description>
    </item>
    
    <item>
      <title>곡선 좌표계에서 벡터 함수의 다이버전스발산</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-of-a-vector-function-in-a-cuvilinear-coordinate-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-of-a-vector-function-in-a-cuvilinear-coordinate-system/</guid>
      <description>곡선 좌표계에서 벡터 함수 $\mathbf{F}=\mathbf{F}(q_{1},q_{2},q_{3})=F_{1}\hat{\mathbf{q}}_{1}+F_{2}\hat{\mathbf{q}}_{2}+F_{3}\hat{\mathbf{q}}_{3}$의 다이버전스는 다음과 같다. $$ \nabla \cdot \mathbf{F}=\frac{1}{h_{1}h_{2}h_{3}}\left[ \frac{ \partial</description>
    </item>
    
    <item>
      <title>곡선 좌표계에서 스칼라 함수의 그래디언트기울기</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-of-a-scalar-function-in-a-cuvilinear-coordinate-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-of-a-scalar-function-in-a-cuvilinear-coordinate-system/</guid>
      <description>곡선 좌표계에서 스칼라 함수 $f=f(q_{1},q_{2},q_{3})$의 그래디언트를 다음과 같다. $$ \nabla f= \frac{1}{h_{1}}\frac{ \partial f }{ \partial q_{1} } \hat{\mathbf{q}}_{1} + \frac{1}{h_{2}}\frac{ \partial f }{ \partial q _{2}}\hat{\mathbf{q}}_{2}+\frac{1}{h_{3}}\frac{ \partial f }{ \partial q_{3} } \hat{\mathbf{q}}_{3}=\sum \limits _{i=1} ^{3}\frac{1}{h_{i}}\frac{ \partial f}{ \partial q_{i}}\hat{\mathbf{q}}_{i} $$ $h_{i}$는 스케일 팩터이다. 각 좌표계별로 구체적인 식은 다음과 같다.**직교 좌표계: ** **$h_{1}=h_{2}=h_{3}=1$ $$ \nabla f= \frac{\partial f}{\partial x}\mathbf{\hat x }+ \frac{\partial f}{\partial y}\mathbf{\hat y} + \frac{\partial f}{\partial z}\mathbf{\hat z} $$ **원통 좌</description>
    </item>
    
    <item>
      <title>곡선좌표계에서의 기울기 발산 회전 라플라스 연산</title>
      <link>https://freshrimpsushi.github.io/posts/299/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/299/</guid>
      <description>물리학에서 델 연산자$\nabla$가 포함된 4가지 연산 기울기$\mathrm{Gradient}$, 발산$\mathrm{Divergence}$, 회전$\mathrm{Curl}$, 라플라스 연산$\mathrm{Laplasian}$은 매우 중요하다. 따라서 3가지 좌표계에 대한 위 연산을 반드시 알아야한다.</description>
    </item>
    
    <item>
      <title>관성모멘트와 선회반경</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-inertia-and-radius-of-gyration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-inertia-and-radius-of-gyration/</guid>
      <description>**관성모멘트 $$ I=\sum_i m_i {r_i}^2 $$ $$ I=\int r^2 dm $$ 관성모멘트는 (입자의 질량)$\times$(회전축에서 입자까지의 거리)로 정의되며 물체가 계속 회전운동하려는 성질을 나타내는 물리량이다. 기호는 $I$이며 영칭인 Inertia의 앞글자를 딴것으로 보인다. 단위는 $[kg \cdot m^2]$이다. 병진운동에서의 질량과 같은 역할을 한다고 볼 수 있다. 즉</description>
    </item>
    
    <item>
      <title>교환자의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-commutator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-commutator/</guid>
      <description>**** 교환자 $A,\ B$는 아래와 같이 정의한다.$[A,B]=AB-BA$교환자의 중요 성질 $$ \leqalignno{ [A, A]&amp;amp;=0 &amp;amp;(a) \\ [A, B]&amp;amp;=-[B, A] &amp;amp;(b) \\ [A+B, C]&amp;amp;=[A, C] + [B, C] &amp;amp;(c) \\ [AB, C]&amp;amp;=A[B, C]+[A, C]B &amp;amp;(d) \\ [A,BC] &amp;amp;=B[A,C]+ [A,B]C &amp;amp;(e) } $$ 양자역학을 기술하는 주된 방법이 행렬이다. 그런데 행렬은 곱셈에 대해서 교환법칙이 성립하지 않는다. 그래서 $A,\ B$라는 연산자(행렬)가 있을 때 아래처럼 전개하면 일반적으로 맞지 않다</description>
    </item>
    
    <item>
      <title>구 껍질의 관성모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-spherical-shell/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-spherical-shell/</guid>
      <description>반지름이 $a$, 질량이 $m$인 구 껍질의 관성모멘트는 $$ I=\frac{2}{3}ma^2 $$ 반지름이 $a$이고 질량이 $m$인 균일한 구 껍질의 관성모멘트를 구해보자. 구의 관성모멘트를 구하는 것과 같은 아이디어를 사용한다. 다만, 조금의 차이가 있다.구의 관성모멘트를 구할 때 처럼 구 껍질을 수 많은 원통 껍질의 합이라고 생각하자.근데 여기서 구의 경우와 똑같이 계산하면 문제가</description>
    </item>
    
    <item>
      <title>구좌표계에서의 미소부피</title>
      <link>https://freshrimpsushi.github.io/posts/1753/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1753/</guid>
      <description>극 좌표계에서 미소 면적, 원통 좌표계에서 미소 부피구좌표계에서 미소 부피는 아래와 같다. $$ dV=r^{2}\sin\theta dr d\theta d\phi $$ 구 표면 위의 미소 면적은 $dr$을 곱하지 않음으로써 얻을 수 있다. $$ da=\color{blue}{rd\theta} \cdot \color{red}{r\sin\theta d \phi}=r^{2}\sin\theta d\theta d\phi $$ 1. 그림을 통한 이해(아래 그림을 매트랩에서 그리는 코드) 구좌표계에서 미소부피는 위 그림에서 보이는 바와 같이 (초록선의 길이)$\times$(파란</description>
    </item>
    
    <item>
      <title>국소 유한</title>
      <link>https://freshrimpsushi.github.io/posts/locally-finite/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/locally-finite/</guid>
      <description>**국소 유한 커버$(\mathrm{locally\ finite\ cover})$ 집합 $S \subset \mathbb{R}^n$의 열린 커버 $\mathcal{O}$가 있다고 하자. $\mathbb{R}^n$에서 임의의 컴팩트 집합이 열린 커버 $\mathcal{O}$의 원소와 기껏해야 유한하게 겹칠 때 열린 커버 $\mathcal{O}$는 국소 유한이</description>
    </item>
    
    <item>
      <title>군에서의 항등원과 역원의 유일성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/130/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/130/</guid>
      <description>군 $\left&amp;lt;G,\right&amp;gt;$에 대해, $G$의 모든 원소 $x$에 대해 $ex = xe = x$ 를 만족하는 항등원 $e$는 유일하다. $G$의 어떤 원소 $a$에 대해 $a{a&#39;} = {a&#39;}a = e$ 를 만족시키는 역원 $a&#39;$는 $a$에 대해 유일하다.다들 당연하게 생각하고 넘어가지만 사실 군의 정의에서는 이들의 존재성만 언급될 뿐이다.이러한 원소</description>
    </item>
    
    <item>
      <title>군의 작용</title>
      <link>https://freshrimpsushi.github.io/posts/group-action/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/group-action/</guid>
      <description>항등원이 $e$ 인 군 $G$ 와 집합 $X$ 에 대해 다음의 두 조건을 만족하는 $* : G \times X \to X$ 를 $X$ 상에서 $G$ 의 **작용** 이라 하고 $X$ 를 **$G$-집합** 이라고 부른다.**(i)** 모든 $x \in X$ 에 대해 $ex = x$**(ii)** 모든 $x \in X$ 와 $g_{1} , g_{2} \in G$ 에 대해 $( g_{1} g_{2} ) (x) = g_{1} (g_{2} x) $군의 작용은 한마디로 &amp;lsquo;$x \in X$ 에다 $g \in G$ 를 가한다&amp;rsquo;는 말이다. 직관적으로 이</description>
    </item>
    
    <item>
      <title>귀무가설과 대립가설을 정하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-choose-null-hypothesis-vs-alternative-hypothesis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-choose-null-hypothesis-vs-alternative-hypothesis/</guid>
      <description>귀무가설 $H_{0}$ vs 대립가설 $H_{1}$귀무가설은 영가설이라는 이름으로도 불린다.2018년 4월 기준으로 일부 교과서나 위키백과에서는 귀무가설을 &amp;lsquo;통계학에서 처음부터 버릴것을 예상하는 가설&amp;rsquo;로, 대립가설을 &amp;lsquo;연구를 통해 입증되기를 기대하거나 예상하는 가설&amp;rsquo;로 설명하고 있으나 이</description>
    </item>
    
    <item>
      <title>규격화된 파동함수normalized wavefunction는 시간의 변화에 무관함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/101/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/101/</guid>
      <description>한 번 규격화된 파동함수는 시간에 따라서 변하지 않고 일정하다.시간에 변해도 규격화된 상태를 유지한다.시간$t=0$일 때 파동함수를 규격화했다고 가정하자.그렇다면 그 이후에 시간이 변함에 따라 파동함수가 규격화된 상태를 유지한다고 확신할 수 있는가?다행히도 그렇다.시간이 변해도 일정하다는 것을 보이려면 $\displaystyle{ \int_{-\infty}^{+\infty}\psi ^{ * }_{(x,t)} \psi ^\ _{(x,t)} dx }$를 시간</description>
    </item>
    
    <item>
      <title>균일 진행파 편미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-uniform-traveling-wave-partial-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-uniform-traveling-wave-partial-differential-equation/</guid>
      <description>$$ \displaystyle \begin{cases} u_{t} + c u_{x} + a u = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ **균일 진행파** 는 시간이 흐름에 따라 일정한 속도로 이동하는 파동이다.만약 상수 $a$ 가 양수면 시간이 흐름에 따라 위와 같이 진폭이 작아진다.여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때 $x$ 에서의 파형을 나타낸다.$f$ 는 초기 조건으로써 특히 $t=0$ 일 때의 파형을 나타낸다.상수 $c$ 는 파동의</description>
    </item>
    
    <item>
      <title>그래프 이론에서의 차수</title>
      <link>https://freshrimpsushi.github.io/posts/degree-in-graph-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/degree-in-graph-theory/</guid>
      <description>그래프 $G$ 가 주어져있다고 하자.1. $G$ 가 유향 그래프라 하자. 에지 $vw$ 가 존재하면 에지가 $v$ 에서 나가고 $w$ 로 들어간다 고 말한다.1-1. 버텍스 $v$ 로 들어오는 에지의 수를 입력 차수Indegree 라 하고 $\deg^{-} (v)$ 와 같이 나타낸다.1-2. 버텍스 $v$ 에서 나가는 에지의 수를 출력 차수Outdegree 라 하고 $\deg^{+}(v)$ 와 같이 나타낸다.1-3. $\deg^{-} (v) = 0$ 인</description>
    </item>
    
    <item>
      <title>그래프 컬러링과 브룩스 정리</title>
      <link>https://freshrimpsushi.github.io/posts/graph-coloring-and-brooks-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/graph-coloring-and-brooks-theorem/</guid>
      <description>루프가 없는 그래프 $G$ 에 대해 다음과 같은 함수 $f : V(G) \to [k]$ 를 $G$ 의 $k$-컬러링 이라고 한다. $$ u \sim v \implies f(u) \ne f(v) $$ 그래프 $G$ 가 $k$-컬러링을 가지면 $k$-채색가능 이라고도 한다. 만약 $k$-채색가능인데 $(k-1)$-채색가능하지 않으면 그 $k$ 를 $G$ 의 크로마틱 수Chromatic Number 라 부르고 $\chi(G) = k$ 와 같이 나타낸다. 크로마틱 수가</description>
    </item>
    
    <item>
      <title>극 좌표계에서 미소 면적 원통 좌표계에서 미소 부피</title>
      <link>https://freshrimpsushi.github.io/posts/1755/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1755/</guid>
      <description>구 좌표계에서 미소 부피극 좌표계에서 미소 면적은 다음과 같다. $$ dA=rdrd\theta $$ 원통 좌표계에서 미소 부피와 원통 표면의 미소 면적은 다음과 같다. $$ dV=\rho d\rho d\phi dz \\ dA=\rho d\phi dz $$ 매트랩에서 극 좌표계 그림 그리는 코드, 원통좌표계 그림 그리는 코드**극 좌표계 $\mathbf{r}=\mathbf{r}(r,\theta)$ 미소 면적은 그림에서와 같이 (초록선의 길이)$\times$(파란선의 길이)이다. 초록색 선은 지름</description>
    </item>
    
    <item>
      <title>근의 공식 유도 무작정 따라하기</title>
      <link>https://freshrimpsushi.github.io/posts/56/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/56/</guid>
      <description>이차방정식 $a{x^2}+bx+c=0$ (단, $a\neq 0$)에 대해 $$ \displaystyle x=\frac { -b\pm \sqrt { {b^2}-4ac } }{ 2a } $$ 이차방정식이 주어졌을 때 그 근은 공식을 통해 쉽게 구할 수 있다.전략 : 공식 유도의 핵심은 바로 &amp;lsquo;완전제곱꼴로 만드는 것&amp;rsquo;이다. 수학이 낯선 어린이 친구들을 위해 가능한 세세하게 풀어서 썼다. 말 그대로 무작정 따라하면 되니까 베껴 적는다고 생각하고 여러번</description>
    </item>
    
    <item>
      <title>급수 해를 이용한 미분 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-differential-equation-using-power-series/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-differential-equation-using-power-series/</guid>
      <description>개요계수가 상수인 미분 방정식은 변수 분리법을 쓰거나 적분인자 를 사용하거나 하는 등 비교적 쉽게 풀어낼 수 있다. 그런데 계수에 독립변수가 포함된 미분 방정식은 간단하게 풀 수가 없다. $$ \begin{equation} P(x)\dfrac{d^2 y}{dx^2} + Q(x)\dfrac{dy}{dx}+R(x)y=0 \label{eq1}\end{equation} $$ 이때 $P$, $Q$, $R$은 다항식이고 공통 인수가 없다고 가정한다. 위의 꼴을 가진 방정식으로는 베셀 방정식(Bessel equation) , $$ x^2 y&#39;&#39; +xy&#39;+(x^2-\nu ^2)y=0,\quad \nu \mathrm{\ is \ constant} $$ 르</description>
    </item>
    
    <item>
      <title>기각역과 유의수준</title>
      <link>https://freshrimpsushi.github.io/posts/rejection-region-and-significance-probability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rejection-region-and-significance-probability/</guid>
      <description>아무리 데이터가 산더미같이 쌓여있고 정교한 수학적 기법을 적용시켰다고 한들 써먹지 못하면 의미가 없다. 여기서 &amp;lsquo;쓴다&amp;rsquo;는 것은 어떤 데이터에 대해 통계를 내고 그 통계를 근거로 어떠한 &amp;lsquo;주장을 한다&amp;rsquo;는 것이다. 이를 위해선 당연히 그 통계가 믿을만해야하고, 그걸 누가 무슨 잣대로 판단할 것이냐는</description>
    </item>
    
    <item>
      <title>기수 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/radix-sort/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/radix-sort/</guid>
      <description>**기수 정렬 자리수가 $k$ 로 제한된 $n$ 개의 자연수로 이루어진 데이터가 주어져있다고 하자. 그러면 데이터는 다음의 알고리즘에 따라 정렬되며 그 시간 복잡도는 $O (n)$ 이다.$i = 1 , \cdots , k$ 번째 자리수들끼리 비교해서 정렬한다.기수 정렬은 자리수의 제한이 있기 때문에 부동소수점이 있는 데이터에 적용할 수는 없으나, 정렬할 때 데이터간의 비교를 하지 않</description>
    </item>
    
    <item>
      <title>기울기의 회전이 항상 0임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-the-curl-of-a-gradient-is-always-0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-the-curl-of-a-gradient-is-always-0/</guid>
      <description>기울기의 회전은 항상 $0$이다 $$ \nabla \times (\nabla T)=0 $$ 증명 직교 좌표계에서 $T$의 기울기는 $$ \displaystyle \nabla T= \frac{\partial T}{\partial x}\hat{\mathbf{ x}} +\frac{\partial T}{\partial y}\hat{\mathbf{y}} +\frac{\partial T}{\partial z}\hat{\mathbf{z}} $$ 위의 식에 회전 연산자를 취하면 $$ \begin{eqnarray} \nabla \times (\nabla T) &amp;amp;=&amp;amp; \begin{vmatrix} \displaystyle \hat{\mathbf{x}} &amp;amp;\hat{\mathbf{y}} &amp;amp; \hat{\mathbf{z}} \\ \displaystyle \frac{\partial }{\partial x} &amp;amp; \displaystyle \frac{\partial }{\partial y} &amp;amp; \displaystyle \frac{\partial }{\partial z} \\ \displaystyle \frac{\partial T}{\partial x} &amp;amp; \displaystyle \frac{\partial T}{\partial y} &amp;amp; \displaystyle\frac{\partial T}{\partial z} \end{vmatrix} \\ &amp;amp;=&amp;amp; \left( \frac{\partial^2 T}{\partial y \partial z}-\frac{\partial^2 T}{\partial z \partial y} \right) \hat {\mathbf{x}} + \left( \frac{\partial ^2 T}{\partial x \partial z}-\frac{\partial ^2 T}{\partial z \partial x} \right) \hat {\mathbf{y}} + \left( \frac{\partial^2 T}{\partial x \partial y} -\frac{\partial^2 T}{\partial y \partial</description>
    </item>
    
    <item>
      <title>기저로부터 생성되는 위상</title>
      <link>https://freshrimpsushi.github.io/posts/a-topology-generated-by-a-basis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/a-topology-generated-by-a-basis/</guid>
      <description>**위상$(\mathrm{topology})$ 집합 $X$에 대해서 아래의 세 조건을 만족하는 $X$의 부분집합의 컬렉션 $\mathscr{T}$를 집합 $X$상의 위상 이라고 말한다.$(T1)$ $\varnothing, X \in \mathscr{T} $$ (T2)$ $U_{\alpha} \in \mathscr{T} (\alpha \in \Lambda)$이면 $\bigcup_{\alpha \in \Lambda} U_{\alpha} \in \mathscr{T}$이다.$(T3)$ $U_{1},\cdots,U_{n} \in \mathsc</description>
    </item>
    
    <item>
      <title>기저보다 원소의 개수가 많은 집합은 선형 종속임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/511/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/511/</guid>
      <description>집합 $S$에 대해서 $|S|$를 집합 $S$의 원소의 개수라고 하자. 그리고 $S$, $W$가 벡터공간 $V$의 부분집합이고 $|S| &amp;lt; |W|$라고 하자. 그러면 집합 $S=\left\{ v_1,\ v_2,\ \cdots ,\ v_n \right\}$가 벡터 공간 $V$의 기저일 때, $W$는 선형 종속이다. 쉽게 말하면 기저보다 원소의 개수가 많은 집합은 항상 선형 종속이다. 이는 기저가 최대로 선형 독립</description>
    </item>
    
    <item>
      <title>널 그래프와 컴플리트 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/null-graph-and-complete-graph/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/null-graph-and-complete-graph/</guid>
      <description>심플 그래프 $G$ 가 주어져 있다고 하자.1. $E(G) = \emptyset$ 이면 $G$ 를 널 그래프 라고 한다.2. $E \left( \overline{G} \right) = \emptyset$ 이면 $G$ 를 컴플리트 그래프 라고 한다.1. 널 그래프 는 말 그대로 비어있는 그래프를 의미한다. 여기서 Empty(빌 공, 空)이 아니라 Null(영 영, 零)이라는 표현을 쓴 이유는 실제로 $G \ne \emptyset$ 일지라도 그래프로써 아무런 의미가 없기 때문이다. 예컨</description>
    </item>
    
    <item>
      <title>놈 공간이란</title>
      <link>https://freshrimpsushi.github.io/posts/normed-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normed-space/</guid>
      <description>**놈 공간 $X$를 벡터 공간이라고 하자. 아래의 세 조건을 만족하는 함수 $| \cdot | \ :\ X \rightarrow \mathbb{R}$가 존재하면 $| \cdot |$를 $X$의 놈 이라하고 $(X,| \cdot | )$를 놈 공간 이라 한다.$(a)$ $| \mathbf{x}| \ge 0,\quad \forall\ \mathbf{x} \in X$이고 $| \mathbf{x} |=0 \iff \mathbf{x}=\mathbf{0} $$ (b)$ $|c\mathbf{x}|=|c||\mathbf{x}|,\quad \forall\ \mathbf{x}\in X,\ \forall\ c \in\mathbb{C} $$ (c)$ $| \mathbf{x}+\mathbf{y}| \le |\mathbf{x}| + |\mathbf{y}|,\quad \forall\ \mathbf{x},\mathbf{y}\in X$놈 공간 $X$의 놈은 주로 아래와 같이 표기한다. $$ {| \mathbf{x} |}{X},\quad</description>
    </item>
    
    <item>
      <title>다변수 함수의 적분</title>
      <link>https://freshrimpsushi.github.io/posts/1902/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1902/</guid>
      <description>$f:\mathbb{R}^{n} \to \mathbb{C}$이고 $\mathbf{x}=(x_{1},\dots,x_{n})\in \mathbb{R}^{n}$이라고 하자. 그러면 다변수 함수의 적분은 아래와 같이 정의된다. $$ \int f(\mathbf{x})d\mathbf{x} = \int _{x_{n}=-\infty} ^{\infty} \cdots \int _{x_{1}=-\infty} ^{\infty}f(x_{1},\dots, x_{n})dx_{1}\cdots dx_{n} $$ 이때 $r\mathbf{x}=(rx_{1},\dots, rx_{n})$이므로 $$ d(r\mathbf{x})=(drx_{1})\cdots(drx_{n})=r^{n}d\mathbf{x} $$ 가 성립한다. 따라서 $f$의 다일레이션을 다음과 같이 정의한다. $$ f_{\epsilon}(\mathbf{x})=\epsilon^{-n}f(\epsilon^{-1} \mathbf{x}) $$ 아래의 적분 결과를 통해 위의 정의가 잘 들어맞음을 알 수 있다. $$</description>
    </item>
    
    <item>
      <title>다변수 함수의 컨볼루션</title>
      <link>https://freshrimpsushi.github.io/posts/convolution-of-multi-variable-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convolution-of-multi-variable-function/</guid>
      <description>$f,g:\mathbb{R}^{n}\to \mathbb{C}$이고 $\mathbf{x},\mathbf{y} \in \mathbb{R}^{n}$이라고 하자. 그러면 두 다변수 함수의 컨볼루션은 다음과 같다. $$ f*g(\mathbf{x})=\int f(\mathbf{y})g(\mathbf{x}-\mathbf{y})d\mathbf{y} $$ 이때 위의 적분은 다변수 함수의 적분이다.다변수 함수의 컨볼루션도 일변수 함수의 컨볼루션이 만족하는 좋은 성질들을 그대로 만족한다.**(a) 교환법칙 $$ fg=gf $$ **(b) 분배법칙 $$ f*(g+h)=f*g+f*h $$ **(c) 결합법칙 $$ f*(g*h)=(f*g)*h $$ **(d) 스</description>
    </item>
    
    <item>
      <title>다중 스프링 진동</title>
      <link>https://freshrimpsushi.github.io/posts/multiple-springs-oscillation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiple-springs-oscillation/</guid>
      <description>단순 조화 진동감쇠 진동강제 진동결합 진동**1. 스프링이 물체의 양쪽에 연결된 경우 $x$를 물체가 이동한 거리라고 하자. 스프링의 복원력은 $-kx$이므로 물체는 왼쪽 스프링으로부터 $-k_{1}x$, 오른쪽 스프링으로부터 $-k_{2}x$의 힘을 받는다. 따라서 운동 방정식은 $$ \begin{align*} &amp;amp;&amp;amp; m\ddot{x}&amp;amp;=-k_{1}x-k_{2}x \\ \implies &amp;amp;&amp;amp;m\ddot{x}+(k_{1}+k_{2})x&amp;amp;=0 \\ \implies &amp;amp;&amp;amp; \ddot{x}+\frac{k_{1}+k_{2}}{m}x &amp;amp;=0 \end{align*} $$ 이는 단순 조화 진동의 방정식과 같으므로 해</description>
    </item>
    
    <item>
      <title>다중회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/multiple-linear-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiple-linear-regression/</guid>
      <description>R 에서 다중회귀분석 결과 보러가기회귀계수의 F검정 보러가기회귀분석이란 변수 사이의 관계를 알아내는 방법으로써, 특히 선형 관계를 밝히는 데 유용하다.다중회귀분석은 하나의 종속변수(반응변수) 에 복수의 독립변수(설명변수) 가 미치는 영향을 파악하는 회귀분석을 말한다.우리는 변수들이 선형관계 $Y = \beta_{0} + \beta_{1} X_{1} + \cdots + \beta_{p} X_{p} + \varepsilon $ 를 가지는</description>
    </item>
    
    <item>
      <title>다차원 맵의 랴푸노프 수와 그 수치적 계산법</title>
      <link>https://freshrimpsushi.github.io/posts/lyapunov-number-of-multi-dimensional-map/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lyapunov-number-of-multi-dimensional-map/</guid>
      <description>스무스 맵 $\mathbb{f} : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 과 초기값 $\mathbb{v}{0} \in \mathbb{R}^{m}$ 에 대해 $J{n} := D \mathbb{f}^{n} ( \mathbb{v}{0}) \in \mathbb{R}^{m \times m}$ 이라고 하자. $k = 1 , \cdots , m$ 에 대해 $m$차원 단위구 $N := \left\{ \mathbb{x} \in \mathbb{R}^{m} : \left| \mathbb{x} \right|{2} = 1 \right\}$ 의 일립소이드 $J_{n} N$ 의 축의 길이 중 $k$ 번째로 긴 축의 길이를 $r_{k}^{(n)}$ 이라고 두자. 이제 $\mathbb{v}_{0}$ 의 $k$ 번째 **랴푸노프 수** $L_{k}$ 를 다음과 같이 정의한다. $$ L_{k} := \lim_{n\to\infty} \left( r_{k}^{(n)} \right)^{1/n} $$ $\mathbb{v}_{0}$ 의 $k$ 번째 **랴푸노프 지수** 는 $h_{k}</description>
    </item>
    
    <item>
      <title>다항함수의 라플라스 변환과 감마함수</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-polynomial-and-gamma-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-polynomial-and-gamma-function/</guid>
      <description>$\mathcal{L} \left\{ t^p \right\} = \dfrac{ \Gamma (p+1) } {s^{p+1}}$ $s&amp;gt;0$다항식의 라플라스 변환은 감마함수로 나타난다.$t^p$라고 적어 헷갈리는 사람이 있을까봐 알아보기 쉽게 말하자면 $x^p$랑 같다.보통 미분방정식에서 함수가 시간에 대해서 나타나므로 $x$대신 $t$를 썼다. 유도 $\displaystyle \mathcal{L} \left\{ t^p \right\} = \int_0^\infty e^{-st}t^p dt $$ \displaystyle = \lim \limits_{A \to \infty} \left[ -\dfrac{1}{s} \left[ e^{-st}t^p \right] _0^A +\dfrac{p}{s} \int_0^A e^{-st}t^{p-1}dt \right]$ $\displaystyle = \dfrac{p}{s} \mathcal{L} \left\{ t^{p-1} \right\} $$ \displaystyle</description>
    </item>
    
    <item>
      <title>단순확대체</title>
      <link>https://freshrimpsushi.github.io/posts/simple-extension/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simple-extension/</guid>
      <description>$F$ 의 확대체 $E$ 가 어떤 $\alpha \in E$ 에 대해 $E = F( \alpha )$ 이면 $E$ 를 $F$ 의 단순확대체 라고 한다.$F ( \alpha )$ 은 쉽게 말해 $F$ 에 없던 $\alpha$ 를 하나Simple만 넣어서 확장한 것으로 볼 수 있다. 실수체 $\mathbb{R}$ 으로 말할 것 같으면 그 확대체 $\mathbb{C}$ 의 $i \in \mathbb{C}$ 를 넣으면 $\mathbb{R} ( i ) = \mathbb{C}$ 가 된다.중요한 팩트로써 $\alpha \in E$ 에 대해 $E = F ( \alpha )$ 면 모든 $ \beta \in E$ 는 $\beta = b_{0} + b_{1} \alpha + \cdots + b_{n} \alpha^n$ 와 같</description>
    </item>
    
    <item>
      <title>단열감률의 열역학적 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-adiabatic-lapse-rate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-adiabatic-lapse-rate/</guid>
      <description>질량이 $m$ 인 기체 분자의 높이 $h$ 와 온도 $T$ 에 대해 $\displaystyle {{dT} \over {dh}} = - {{ \gamma -1} \over { \gamma }} {{ mg } \over {k_{B}}} $감마는 등압 열용량과 등적 열용량의 비 $\displaystyle \gamma = {{C_{p}} \over {C_{V}}}$ 를 나타낸다.알다시피 고도가 올라갈수록 기온은 떨어지는데, 그 비율을 수식적으로 나타낸 것이다.물론 이는 습도와 같은 여러가지 변수들을 전혀 고려하지 않고 열역학만을 이용해 유도한 결과다.이 때 기체 분자</description>
    </item>
    
    <item>
      <title>단진자 운동의 주기는 진자의 질량과 무관함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/102/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/102/</guid>
      <description>단진자 운동의 주기 $T$는 진자의 질량 $m$과 무관하다.증명 진자의 복원력은 $$ F=-mg\sin\theta $$ $x=l\theta$ 이므로, $\theta$가 충분히 작을 때 $$ \sin\theta \simeq \theta $$ 이 때 복원력은 $$ \begin{eqnarray*} F &amp;amp;=&amp;amp;-mg \sin\theta \\ &amp;amp;=&amp;amp; -mg\theta \\ &amp;amp;=&amp;amp; -mg\frac{x}{l} \\ &amp;amp;=&amp;amp; -\frac{mg}{l} x \end{eqnarray*} $$ 진자의 복원력은 $F=-kx$로도 표현할 수 있다. 따라서 $$ k=\dfrac{mg}{l} \quad \Rightarrow \quad \dfrac{m}{k}=\dfrac{l}{g} $$ 주기는$T=\frac{2\pi}{w}=2\pi \sqrt{\frac{m}{k}} $ 이므로 $$</description>
    </item>
    
    <item>
      <title>대수와 준측도</title>
      <link>https://freshrimpsushi.github.io/posts/algebra-and-premeasure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebra-and-premeasure/</guid>
      <description>**대수$(\mathrm{algebra\ of\ sets\ on\ }X)$ 집합 $X \ne \varnothing$의 부분 집합들의 컬렉션 $\mathcal{A}$가 아래의 세 조건을 만족할 때 집합 $\mathcal{A}$를 $X$ 위의 집합들의 대수 라고 한다.$(a)$ $E_1$, $\cdots$, $E_n\in \mathcal{A}$이면, $\bigcup \nolimits_1^n E_n \in \mathcal{A}$이다.$</description>
    </item>
    
    <item>
      <title>대수적 수와 초월수</title>
      <link>https://freshrimpsushi.github.io/posts/algebraic-number-and-transcendental-number/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebraic-number-and-transcendental-number/</guid>
      <description>체 $F$ 의 확대체를 $E$ 라고 하자. 상수함수가 아닌 $f(x) \in F[x]$ 에 대해 $f( \alpha ) = 0$ 을 만족시키는 $\alpha \in E$ 를 $F$ 상에서 대수적Algebraic 이라고 하고, 대수적이지 않으면 초월적Transcendental 이라고 한다. $F = \mathbb{Q}$, $E = \mathbb{C}$ 이라고 할 때 $\alpha \in \mathbb{C}$ 가 대수적이면 대수적 수 , 초월적이면 초월수 라고 한다.예를 들어 $ f(x) = x^2 - 2 $ 라는 다항함수가</description>
    </item>
    
    <item>
      <title>대학교 수학에서 새롭게 정의되는 함수의 연속</title>
      <link>https://freshrimpsushi.github.io/posts/1206/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1206/</guid>
      <description>공집합이 아닌 $E \subset \mathbb{R}$ 에 대해 $f : E \to \mathbb{R}$ 이라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ | x - a | &amp;lt; \delta \implies | f(x) - f(a) | &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $f$ 가 $a \in E$ 에서 연속 이라고 하고, $E$ 의 모든 점에서 연속이면 $f$ 를 연속함수 라고 한다.고등학교에서 연속을 정의할 때 역시 (i) 함수값 $f(a)$ 가 존재하며, (ii) 극한 $\displaystyle \lim_{x \to a}$ 가 존재하며, **(iii)** $f(a) = \displaystyle \lim_{x \to a}$ 가 성립할 때 $x = a$</description>
    </item>
    
    <item>
      <title>더핑 오실레이터</title>
      <link>https://freshrimpsushi.github.io/posts/duffing-oscillator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/duffing-oscillator/</guid>
      <description>**더핑 방정식1 $$ x&#39;&#39; + \delta x&#39; + \alpha x + \beta x^{3} = \gamma \cos \left( \omega t \right) $$ 변수 $t$ : 시간 을 나타낸다.$x$ : $1$ 차원 상에서 (이를 테면 입자의) 위치 를 나타낸다.$x&#39;$ : (입자의) 속도 를 나타낸다.$x&#39;&#39;$ : (입자의) 가속도 를 나타낸다.파라메터 $\delta$ : 감쇠(Damping) 를 제어하며, 마찰(Friction)과 비슷한 역할을 한다.$</description>
    </item>
    
    <item>
      <title>델 연산자가 두 번 들어간 수식 2계 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/second-derivative-with-del-operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/second-derivative-with-del-operator/</guid>
      <description>$T$는 스칼라 함수, $\mathbf{A}$는 벡터 함수라고하자.$(1)$ 기울기의 발산 $\nabla \cdot (\nabla T) =\nabla ^2 T $$ (2)$ 기울기의 회전 $\nabla \times (\nabla T)=0 $$ (3)$ 발산의 기울기 $\nabla (\nabla \cdot \mathbf{A} ) $$ (4)$ 회전의 발산 $\nabla \cdot (\nabla \times \mathbf{A})=0 $$ (5)$ 회전의 회전 $\nabla \times (\nabla \times \mathbf{A})=\nabla ( \nabla \cdot \mathbf{A}) - \nabla ^2 \mathbf{A}$기울기와 회전의 결과가 벡터이고 발산의 결과가 스칼라이므로 2계 도함수는 총</description>
    </item>
    
    <item>
      <title>델 연산자가 포함된 곱셈 규칙</title>
      <link>https://freshrimpsushi.github.io/posts/product-rule-with-del-operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/product-rule-with-del-operator/</guid>
      <description>이전에 나뉘어 있던 두 문서의 내용을 합쳤습니다. 다른 문서에 있는 덧글도 모두 본 글로 옮겼습니다. 공식 델 연산자가 포함된 곱셈규칙 그래디언트(gradient, 기울기) (a) $\nabla{(fg)}=f\nabla{g}+g\nabla{f}$(b) $\nabla(\mathbf{A} \cdot \mathbf{B}) = \mathbf{A} \times (\nabla \times \mathbf{B}) + \mathbf{B} \times (\nabla \times \mathbf{A})+(\mathbf{A} \cdot \nabla)\mathbf{B}+(\mathbf{B} \cdot \nabla) \mathbf{A}$다이버전스(divergence, 발산) (c) $\nabla \cdot (f\mathbf{A}) = f(\nabla \cdot \mathbf{A}) + \mathbf{A} \cdot (\nabla f)$(d)** $\nabla \cdot (\mathbf{A} \times \mathbf{B}) = \mathbf{B} \cdot (\nabla \times</description>
    </item>
    
    <item>
      <title>독립인 두 카이제곱 분포에서 F-분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/1643/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1643/</guid>
      <description>두 확률 변수 $U,V$ 가 독립이고 $U \sim \chi^{2} ( r_{1})$, $V \sim \chi^{2} ( r_{2})$ 이라 하면 $$ {{ U / r_{1} } \over { V / r_{2} }} \sim F \left( r_{1} , r_{2} \right) $$ 두 데이터가 카이제곱 분포를 따르고 독립이라면, 그 비를 분포이론으로 설명할 수 있을지도 모른다.통계학 전반에서는 표준화된 잔차의 제곱이 카이제곱 분포를 따르는 것으로 가정하기 때문에 이 점에 따라 F-검정등을 즐겨쓴다. 증명 자체가 중요한 것</description>
    </item>
    
    <item>
      <title>돈스커의 정리</title>
      <link>https://freshrimpsushi.github.io/posts/donskers-theorem-invariance-priciple-functional-clt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/donskers-theorem-invariance-priciple-functional-clt/</guid>
      <description>$\left\{ \xi_i \right\}{i \in \mathbb{N}}$ 이 $(0,1)$ 에서 정의된 확률 과정이라고 하자. 함수 공간 $C[0,1]$ 에서 확률 함수 $X{n}$ 가 다음과 같이 정의되어 있다고 하자. $$ X_{n} := {{ 1 } \over { \sqrt{n} }} \sum_{i=1}^{\lfloor nt \rfloor} \xi_{i} + \left( nt - \lfloor nt \rfloor \right) {{ 1 } \over { \sqrt{n} }} \xi_{\lfloor nt \rfloor + 1} $$ $X_{n}$ 은 $n \to \infty$ 일 때 위너 프로세스 $W$ 로 분포 수렴한다. * $C[0,1]$ 은 정의역이 $[0,1]$ 이고 공역이 $\mathbb{R}$ 인 연속함수들의 공간이다. * $\lfloor \cdot \rfloor$ 은 바닥 함수Floor Fun</description>
    </item>
    
    <item>
      <title>동역학계와 맵과 고정점</title>
      <link>https://freshrimpsushi.github.io/posts/dynamic-system-map-fixed-point/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamic-system-map-fixed-point/</guid>
      <description>1. 어떤 시점의 스테이트가 그 과거의 스테이트로 표현되는 계를 동역학계 이라고 한다.2. 정의역과 공역이 같은 함수 $f : X \to X$ 를 맵 이라고 한다. $f$ 를 $k$ 번 합성한 맵을 $f^{k}$ 와 같이 나타낸다. 3. $f(p) = p$ 를 만족하는 $p \in X$ 를 고정점Fixed Point 이라고 한다.4. 모든 $x \in N_{ \epsilon } ( p ) $ 에 대해 $\displaystyle \lim_{k \to \infty} f^{k} (x) = p$ 를 만족하는 $\epsilon &amp;gt; 0$ 이 존재하면 고정점 $p$ 를</description>
    </item>
    
    <item>
      <title>동역학에서의 어트랙터</title>
      <link>https://freshrimpsushi.github.io/posts/attractor-in-dynamics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/attractor-in-dynamics/</guid>
      <description>공간 $X$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $\phi(t, \cdot)$ 은 벡터 필드 $x&#39; = f(x)$ 의 플로우, $g^{n}$ 는 맵 $g$ 를 $n$ 번 취한 맵을 나타내도록 하자.넌원더링 1한 점 $x_{0} \in X$ 이 다음의 조건을 만족하면 **넌원더링 포인트** 라 하고, 그 집합을 **넌원더링 셋**Nonwandering Set 이라고 한다.**V.*</description>
    </item>
    
    <item>
      <title>동역학적 모델 시뮬레이션</title>
      <link>https://freshrimpsushi.github.io/posts/dynamical-model-simulation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamical-model-simulation/</guid>
      <description>([멜서스 성장 모델](https://freshrimpsushi.github.io/posts/1871)에 대한 에이전트 기반 시뮬레이션) **시뮬레이션** 이란 현상을 설명하는 모델을 가상으로 구현해 실험하는 것을 말하며, **동역학적 모델** 이라는 맥락에서 시뮬레이션은 흔히 다음과 같은 방법들을 말한다: **1. Agent based Model:</description>
    </item>
    
    <item>
      <title>동적 프로그래밍</title>
      <link>https://freshrimpsushi.github.io/posts/dynamic-programing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamic-programing/</guid>
      <description>문제를 풀 때, 큰 문제의 해답에 그보다 작은 문제의 해답이 포함되어 있으면 최적 부분 구조Optimal Substructure 를 가진다고 한다. 최적 부분 구조를 갖춘 문제의 예로써 가장 쉬운 것이 바로 피보나치 수를 구하는 것이다. $n$ 번째 피보나치 수는 $a_{n} = a_{n-1} + a_{n-2}$ 와 같이 구해지므로, 큰 문제 $a_{n}$ 에 작은 문제 $a_{n-1}$, $a_{n-2}$ 가 포함되어 있기 때문이다.이를 간단하게 푸는 방법은 바로 재귀</description>
    </item>
    
    <item>
      <title>동차 미분방정식에서 동차의 의미</title>
      <link>https://freshrimpsushi.github.io/posts/meaning-of-homogeneous-in-homogeneous-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/meaning-of-homogeneous-in-homogeneous-differential-equation/</guid>
      <description>※정확한 내용이 아니라 개인적인 생각이므로 사실과 다를 수 있습니다. 미분방정식을 분류하는 기준 중에서 동차/비동차 (제차/비제차)가 있다. 선형이니, 1차니 2차니 하는 기준은 그 말과 내용을 받아들이기 쉬울 것이다. 허나 동차 라고 하는 것은 말과 그 내용을 쉽게 연결짓기가 힘들다. 우선 어떨 때 미분방정식을 동차라고 하는지 보자.미분방정식이</description>
    </item>
    
    <item>
      <title>동차함수와 1계 미분방정식</title>
      <link>https://freshrimpsushi.github.io/posts/homogeneous-function-and-first-order-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homogeneous-function-and-first-order-differential-equation/</guid>
      <description>분리 가능한 1계 미분방정식에서 1계 미분방정식 풀이의 핵심은 분리 가능한 형태로 만들어주는 것 이라고 했다.주어진 식에서 바로 분리가능하지 않더라도 여러 방법을 통해 식을 변형하여 분리 가능한 형태로 만들어줄 수 있다.동차함수가 포함된 미분 방정식이 바로 그 예이다.겉으로 보기엔 분리가능하지 않아도 치환을 통해 분리 가능한 형태로 만들어 줄 수 있다</description>
    </item>
    
    <item>
      <title>동치관계에 의한 집합의 분할</title>
      <link>https://freshrimpsushi.github.io/posts/partition-by-equivalent-relation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-by-equivalent-relation/</guid>
      <description>집합 $X$ 상의 동치관계 $R$ 에 대해 $X / R$ 은 $X$ 의 분할이다.이 정리는 별 것 아닌 것 같아 보이지만 위상수학, 추상대수학 등 수학 전반에서 널리 쓰이고 있다.동치관계란 쉽게 말해서 이거나 저거나 &amp;lsquo;같다&amp;rsquo;고 보자는건데, 아이러니하게도 동치관계가 주어짐으로써 ‘같지 않음’이라는 개념이 동반된다. 전체집합은 동치관계라는 법</description>
    </item>
    
    <item>
      <title>동치류</title>
      <link>https://freshrimpsushi.github.io/posts/equivalence-class/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalence-class/</guid>
      <description>집합 $X$ 상에서 동치관계 $R$ 이 정의되어있다고 하자. $x \in X$ 에 대해 $x / R := \left\{ y \in X : y R x \right\}$ 를 $x$ 의 동치류 라고 한다. 주어진 $X$ 의 모든 동치류를 모은 집합을 $X / R := \left\{ x / R : x \in X \right\}$ 과 같이 나타낸다.표현이 조금 더러워 보이지만 예시를 생각해보면 전혀 어려운 개념이 아니다.자연수집합 $\mathbb{N}$ 상에서 $3$ 으로 나눈 나머지가 같으면 동치라하고 $x,y \in \mathbb{Z}$</description>
    </item>
    
    <item>
      <title>두 멱급수의 곱  코시 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-product-of-series/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-product-of-series/</guid>
      <description>$\displaystyle f(x) : = \sum_{k=0}^{\infty} a_{k} x^{k}$ 와 $\displaystyle g(x) : = \sum_{k=0}^{\infty} b_{k} x^{k}$ 의 수렴구간이 $(-r,r)$ 이고 $\displaystyle c_{k} := \sum_{j=0}^{k} a_{j} b_{k-j}$ 이라고 하면 $\displaystyle \sum_{k=0}^{\infty} c_{k} x^{k}$ 는 수렴구간 $(-r,r)$ 상에서 $f(x)g(x)$ 로 수렴한다.계수들의 곱들이 알아서 두 함수의 곱의 계수로 수렴해준다는 점은 사실 꽤 신기한 일이다. 그냥 유한다항함수였다면 증명조차 필요 없을 정도로 당연하지만, 멱급수는 무한히 많은 항을 가지기 때문이다. 증명 $x \in (-r,r)$ 와 $n \in \mathbb{N}$ 을 하</description>
    </item>
    
    <item>
      <title>두 물체의 충돌과 반발계수</title>
      <link>https://freshrimpsushi.github.io/posts/465/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/465/</guid>
      <description>두 물체가 충돌할 때 그 유형을 3가지로 분류할 수 있다.$1$ 완전 탄성 충돌(탄성 충돌)$2$ 비탄성 충돌$3$ 완전 비탄성 충돌어떻게 구분하느냐?기준은 바로 반발계수$e$이다.반발계수 반발계수는 두 물체의 충돌 전 상대속도와 충돌 후 상대속도의 비다.다시 말하자면 두 물체가 가까워지는 속력과 두 물체가 멀어지는 속력의 비다.$e= \dfrac{ {v_2}&#39; -</description>
    </item>
    
    <item>
      <title>두 확률 측도가 서로 같아지는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/1415/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1415/</guid>
      <description>공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자.$\mathcal{O}$ 는 모든 열린 집합들의 집합, $\mathcal{C}$ 는 모든 닫힌 집합들의 집합이고 $P$ 와 $Q$ 는 $(S,\mathcal{B}(S))$ 에서 정의된 확률 측도다.[1] 모든 열린 집합 $O \in \mathcal{O} \subset S$ 에 대해 $P(O) = Q(O)$ 면 $P=Q$ 다. 다른 표현으로, $\mathcal{O}$ 는 세퍼레이팅 클래스다.[2] 모든 닫힌 집합 $C \in \mathcal{C} \subset S$ 에 대해 $P(C) = Q(C)$ 면 $P=Q$ 다. 다른</description>
    </item>
    
    <item>
      <title>듀얼 스페이스</title>
      <link>https://freshrimpsushi.github.io/posts/dual-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dual-space/</guid>
      <description>벡터공간 $X$의 모든 연속인 선형 범함수들의 집합을 $X^{ * }$로 표기하고 이를 $X$의 듀얼 스페이스, 간단히 $X$의 듀얼이라 한다. $$ X^{ * }:=\left\{ x^{ * }:X\to \mathbb{C}\ |\ x^{ * } \text{ is continuous and linear} \right\} $$ $$ X^{ * }:=B(X,\mathbb{C}) $$ 선형 작용소의 성질에 의해 연속이라는 조건은 유계라는 조건과 동치이다.* $B \left( X, \mathbb{C} \right)$ 는 정의역이 $X$ 고 공역이 $\mathbb{C}$ 인 유계 선형작용소의 집합을 나타낸다.* 듀</description>
    </item>
    
    <item>
      <title>등각사상은 내각의 크기를 보존함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/410/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/410/</guid>
      <description>영역 $\mathscr{R}$ 에서 함수 $f$ 가 등각사상이고 곡선 $\mathscr{C}{1}$ 과 $\mathscr{C}{2}$ 가 한 점 $\alpha$ 에서 만나며 그 내각을 $\psi$ 라고 하자. $\mathscr{C}{1}&#39;$ 과 $\mathscr{C}{2}&#39;$ 가 $\mathscr{C}{1}$ 과 $\mathscr{C}{2}$ 를 $f$ 로 보낸 상이라고 하면 두 곡선은 $\beta = f ( \alpha ) $ 에서 만나며 그 내각 역시 $\psi$ 다.해석학답게 말은 어렵지만 요는 도형들이 이루는 내각을 등각사상이 보존한다는 것이다.애초에 등각사상이라는 이름 자체가 이러한 성질에서 나온 것이다. 증명 $f$ 는</description>
    </item>
    
    <item>
      <title>등방부분군</title>
      <link>https://freshrimpsushi.github.io/posts/isotropy-subgroup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isotropy-subgroup/</guid>
      <description>군 $G$ 에 대해 $X$ 를 $G$-집합이라고 하자. $x \in X$ 와 $g \in G$ 에 대해 $ X_{g} := \left\{ x \in X , | , gx = x \right\} $ 그리고 $G_{x} := \left\{ g \in G , | , gx = x \right\}$ 라 두자. $G_{x}$ 를 $x$ 에 대한 $G$ 의 **등방부분군**Isotropy Subgroup 이라고 정의한다.등방부분군이 뭔지 감을 잡으려면 군의 작용에 대한 이해가 있어야한다.위 그림 좌측의 점들과 선들의 집합 $$ X : = \left\{ 1,2,3,4 , C,</description>
    </item>
    
    <item>
      <title>등비수열의 부분합들도 등비수열임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/194/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/194/</guid>
      <description>등비수열 $a_n = a r^{n-1}$과 그 부분합 $\displaystyle S_n = \sum_{k=1}^{n} a_k $ 그리고 어떤 자연수 $m$에 대해 $A_n = S_{mn} - S_{m(n-1)} $은 등비수열이다.모르면 정말 고생한다.예를 들어, 2의 거듭제곱을 세개씩 끊어 더한 수열을 생각해보면$(1 + 2+ 4)= 7 $, $(8 + 16 + 32)=56$, $(64+128+256)=448 \cdots$ 는 초항이 7이고 공비가 8인 등비수열이다.이러한 성질은 등차수열도 가지고 있다.원리야 사실 단순하</description>
    </item>
    
    <item>
      <title>등적 열용량과 등압 열용량</title>
      <link>https://freshrimpsushi.github.io/posts/631/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/631/</guid>
      <description>몰 수가 $1$ 인 이상기체의 계에서 등적 열용량 $C_{V}$ 와 등압 열용량 $C_{p}$ 에 대해 $$ \displaystyle C_{p} = C_{V} + R = {{5} \over {2}} R $$ 등적 과정이냐 등압 과정이냐에 따른 열용량은 다를 뿐만이 아니라 수식적으로도 착착 맞아떨어지는 관계가 있다.특히 $\displaystyle \gamma := {{C_{p}} \over {C_{V}}} $ 자체는 물리적으로 큰 의미가 없지만, 수식적으로 여기저기서 중요하게 쓰인다. 증명 Part 1. $\displaystyle C_{V} = {{\partial U} \over {\partial T}}$ 임을 보인다.</description>
    </item>
    
    <item>
      <title>등차수열의 부분합들도 등차수열임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/193/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/193/</guid>
      <description>등차수열 $a_n = a + (n-1)d$과 그 부분합 $\displaystyle S_n = \sum_{k=1}^{n} a_k $ 그리고 어떤 자연수 $m$에 대해 $A_n = S_{mn} - S_{m(n-1)} $은 등차수열이다.모르면 정말 고생한다.예를 들어, 자연수를 세 개씩 끊어 더한 수열을 생각해보면$(1 + 2+ 3)= 6 $, $(4+5+6)=15$, $(7+8+9)=24 \cdots$ 는 초항이 6이고 공차가 9인 등차수열이다.이러한 성질은 등비수열도 가지고 있다.원리야 사실 단순하니까 한번 꼼꼼하</description>
    </item>
    
    <item>
      <title>디락 델타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/dirac-delta-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirac-delta-function/</guid>
      <description>아래의 두 조건을 만족하는 함수를 디락델타함수라 한다. $$ \delta (x) = \begin{cases} 0, &amp;amp; x\neq 0 \\ \infty , &amp;amp; x=0 \end{cases} $$ $$ \int_{-\infty}^{\infty}{\delta (x) dx}=1 $$ ※크로네커 델타와 헷갈리지 않게 주의가 필요하다.공학에서는 단위 임펄스 함수$(\mathrm{unit\ impulse\ function})$이라 부른다. 정확하게 말하자면 수학적으로 디락 델타 함수는 함수가 아니다. 0에서 무한대로 발산하기</description>
    </item>
    
    <item>
      <title>디락 델타 함수Dirac delta function의 중요한 성질과 증명</title>
      <link>https://freshrimpsushi.github.io/posts/104/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/104/</guid>
      <description>$ \displaystyle 1.\ \delta (-x) =\delta (x) \\ \displaystyle 2.\ \delta (kx)= \frac{1}{|k|} \delta (x) $증명(1번) $ \displaystyle \int_{-\infty }^ { \infty } f(x) \delta (-x) dx $이 때, $-x \equiv y$라고 치환하면$x=-y$, $dx=-dy$ 이고 위의 식에 대입하면$ \displaystyle \int_{-\infty }^ { \infty } f(x) \delta (-x) dx $$ \displaystyle =-\int_ { \infty }^{-\infty} f(-y) \delta (y) dy \\ \displaystyle = \int_{-\infty } ^{\infty } f(-y) \delta(y) dy \\ = f(0) \\ \displaystyle = \int_{-\infty } ^{\infty } f(x) \delta (x) dx $$ \displaystyle \int_{-\infty }^ { \infty } f(x) \color{blue}{\delta (-x)} dx = \int_{-\infty } ^{\infty } f(x) \color{blue}{\delta (x)} dx $$ \therefore \delta (-x) = \delta (x) $ ■ **증명(2번)** $</description>
    </item>
    
    <item>
      <title>디락 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/dirac-notaion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirac-notaion/</guid>
      <description>**** **이 글을 이해하려면 양자역학을 위해 새로 배우는 벡터와 내적을 알아야한다. **디락 표기법$(\mathrm{Dirac\ notation})$ 양자역학에서 연산자와 파동함수(고유함수)를 편리하게 연산하기 위해서 사용하는 하나의 표기법이다. 벡터를 꺾쇠괄호를 사용하여 나타낸다. 열벡터$(\mathrm{column\ vector})$</description>
    </item>
    
    <item>
      <title>디리클레 곱과 승법적 성질</title>
      <link>https://freshrimpsushi.github.io/posts/drichlet-convolution-and-multiplicativity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/drichlet-convolution-and-multiplicativity/</guid>
      <description>[1] $f$ 와 $g$ 가 승법적 함수면 $f * g$ 도 승법적 함수다.[2] $g$ 와 $fg$ 가 승법적 함수면 $f$ 도 승법적 함수다.이 성질들은 승법적 함수들의 대수적인 성질을 논할 때 바로 쓰일 수 있다 :정리 [1] 은 다시 말해 승법적 함수가 컨볼루션 $*$에 대해 닫혀있음을 의미한다.정리 [2] 는 $g$ 와 $I = gg^{-1}$ 와 같이 둠으로써 승법적 함수의 인버스가 승법적 함수임을 보일 수 있다. 증명[</description>
    </item>
    
    <item>
      <title>디리클레 곱에 대한 인버스</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-function-under-drichlet-convolution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-function-under-drichlet-convolution/</guid>
      <description>산술 함수 $f$ 에 대해 다음을 만족하는 산술 함수 $f^{-1}$ 가 유일하게 존재하면 $f^{-1}$ 를 $f$ 의 (디리클레) 인버스 라고 한다. $$ f * f^{-1} = f^{-1} * f = I $$ 여기서 $I$ 는 컨볼루션에 대한 아이덴터티 함수다.대부분의 수학에서 다루는 역함수와 달리 디리클레 인버스는 사상에 대한 역사상이 아닌 대수적인 센스에서의 인버스를 말한다. 그렇다면 대수적 구조가 자연스럽게 떠오를</description>
    </item>
    
    <item>
      <title>디리클레 커널</title>
      <link>https://freshrimpsushi.github.io/posts/dirichlet-kernel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichlet-kernel/</guid>
      <description>디리클레 커널 $D_n$을 아래와 같이 정의한다. $$ D_n(t) := \dfrac{1}{2}+\sum \limits_{k=1}^{n} \cos kt $$ 디리클레 커널과 관련된 몇 가지의 정리와 그 증명을 소개한다.**정리 1 디리클레 커널 $D_n(t)$는 $n \rightarrow \infty$일 때 **디락 델타 함수** $\delta(t)$로 수렴한다.자세한 증명 대신 그림으로 대체한다. 그림을 보면 $n$이 커질수록 $x=0$에서</description>
    </item>
    
    <item>
      <title>디키-풀러 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/dickey-fuller-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dickey-fuller-test/</guid>
      <description>시계열 데이터 $\left\{ y_{t} \right\}$ 가 주어져 있다고 하자.$H_{0}$ : 데이터 $\left\{ y_{t} \right\}$ 는 정상성을 가지지 않는다.$H_{1}$ : 데이터 $\left\{ y_{t} \right\}$ 는 정상성을 갖는다. 디키-풀러 테스트는 시계열 데이터가 정상성을 가지는지 가지지 않는지를 확인할 때 사용한다. 정상성을 가지지 않으면 차분을 통해 평균을 일정하게 만들어주어야 한다. 주의해야할 것은 이러한 진</description>
    </item>
    
    <item>
      <title>라게르 미분 방정식의 급수해 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/series-solution-of-laguerre-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-solution-of-laguerre-differential-equation/</guid>
      <description>**라게르 미분 방정식 $$ xy&#39;&#39;+(1-x)y&#39;+ny=0,\quad n=0,1,2,\cdots $$ 의 해를 라게르 다항식 이라 부르고 $L_{n}(x)$으로 표기한다. $$ \begin{align*} L_{0}(x) &amp;amp;= 1 \\ L_{1}(x) &amp;amp;= -x+1 \\ L_{2}(x) &amp;amp;= \frac{1}{2}\left( x^{2}-4x+2 \right) \\ L_{3} (x) &amp;amp;=\frac{1}{6}\left( -x^{3}+9x^{2}-18x+6 \right) \\ &amp;amp; \vdots \end{align*} $$ 라게르 미분 방정식의 급수해 풀이를 소개한다.**풀이 아래와 같은 미분 방정식이 주어졌다고 하자. $\lambda$는 임의의 상수이다. $$ xy&#39;&#39; +(1-x)y&#39;+\lambda y=0 $$ $x=0$일 때 $y&#39;&#39;$의</description>
    </item>
    
    <item>
      <title>라그랑주 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-lagrange-formula/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-lagrange-formula/</guid>
      <description>서로 다른 $x_{0} , \cdots , x_{n}$ 의 데이터 $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$ 에 대해 $\displaystyle l_{i} (x) := \prod_{i \ne j} \left( {{ x - x_{j} } \over { x_{i} - x_{j} }} \right)$ 이라고 하면 $\displaystyle p_{n} (x) = \sum_{i=0}^{n} y_{i} l_{i} (x) $라그랑주 공식은 폴리노미얼 인터폴레이션을 찾는 방법 중 가장 심플한 공식이다. **Strategy** : $l_{i}$ 이 인덱스에 대해 크로데커 델타 함수임을 보인다.**유도** $$ \displaystyle l_{i} (x_{i}) = \prod_{i \ne j} \left( {{ x_{i} - x_{j} } \over { x_{i} - x_{j} }} \right) = 1 $$ $$ \displaystyle l_{i} (x_{j})</description>
    </item>
    
    <item>
      <title>라돈 변환의 유도와 성질</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-and-properties-of-radon-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-and-properties-of-radon-transform/</guid>
      <description>라돈변환의 시각적 이해 개요 라돈 변환 은 적분 변환의 일종으로 오스트리아의 수학자 라돈(Johann Radon, 1887-1956)에서 이름을 따왔다. 방사성 원소 라돈은 수학자 라돈의 이름에서 따온 것이 아니라 방사성(radiactive)이라는 단어에 비활성기체접미사(-on)를 붙여 이름 지어졌다. CT 촬영의 핵심 원리중 하나이며 베르-람</description>
    </item>
    
    <item>
      <title>라돈 변환의 정의와 성질</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-property-of-radon-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-property-of-radon-transform/</guid>
      <description>*라돈 변환$(\mathrm{Radon\ transform})$ $f$를 $\mathbb{R}^2$ 위에서 정의된 함수라고 하자. 그러면 $f$를 평면 위의 어떤 직선 $l_{s,\theta}$를 따라서 적분한 것을 $f$의 라돈 변환이라고 하고 아래와 같이 나타낸다. $$ \begin{eqnarray} \mathcal{R}f(s,\theta) &amp;amp;:=&amp;amp;\int_{l_{s,\theta}}fdt \\ &amp;amp;=&amp;amp; \int_{t =-\infty}^{\infty} f\big( s\cos\theta-t\sin\theta,\ s\sin\theta + t\cos\theta \big) dt \end{eqnarray*} $$ 물리적으로 쉽게 설명하자면 $l_{s,\theta}$은 전자기파(</description>
    </item>
    
    <item>
      <title>라돈 역변환</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-radon-transform-filtered-back-projection-formular/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-radon-transform-filtered-back-projection-formular/</guid>
      <description>**필터드 백 프로젝션 공식$(\mathrm{The\ filtered\ back\ projection\ formular})$ 2차원 평면에서 정의된 적절한 함수 $f$에 대해서 다음의 식이 성립한다. $$ f(x,y)=\dfrac{1}{2} \mathcal{B} \left\{ \mathcal{F}^{-1} \Big[ |S|\mathcal{F} (\mathcal{R}f) (S,\ \theta) \Big]\right\} (x,y) $$ 복잡해보이지만 쉽게 말해서 푸리에 변환 과 백 프로젝션 을 사용하여 $f$의 라돈 변환 $\mathcal{R}f$로부터 $f$를 구할 수 있다는 뜻이다. 즉 푸리에 변환, $</description>
    </item>
    
    <item>
      <title>라돈-니코딤 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/radon-nikodym-derivative/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/radon-nikodym-derivative/</guid>
      <description>가측 공간 $( \Omega , \mathcal{F} )$ 가 주어져 있다고 하자.측도 $\mu$, $\nu$ 가 $\mu ( \Omega ) = 1$ 과 모든 $F \in \mathcal{F}$ 에 대해 $0 \le \nu (F) \le \mu (F)$ 를 만족하면 모든 $F \in \mathcal{F}$ 에 대해 $$ \nu(F) = \int_{F} h d \mu $$ 를 만족하면서 $h \ge 0 $ 인 $\mathcal{F}$-가측 함수 $h : \Omega \to \mathbb{R}$ 가 존재한다. 이 $h$ 를 $\displaystyle h := {{d \nu } \over {d \mu }}$ 와 같이 나타내고 **$\mu$ 에 대한 $\nu$ 의 라돈-니코딤 도함수** 라고 한다. *</description>
    </item>
    
    <item>
      <title>라돈-니코딤 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-radon-nikodym-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-radon-nikodym-theorem/</guid>
      <description>가측 공간 $( \Omega , \mathcal{F} )$ 의 두 시그마 유한 측도 $\nu$, $\mu$ 가 $\nu \ll \mu$ 를 만족하면 모든 $A \in \mathcal{F}$ 에 대해 $\mu$-거의 어디서나 $h \ge 0$ 이고 $$ \nu (A) = \int_{A} h d \mu $$ 을 만족하는 $\mathcal{F}$-가측 함수 $h$ 가 주어진 $\mu$ 에 따라 유일하게 존재한다. * $h$ 가 $\mu$-거의 어디서나라는 것은 거의 어디서나와 비슷하게 $\mu \left( h^{-1} ( -\infty , 0 ) \right) = 0$ 이라는 뜻이</description>
    </item>
    
    <item>
      <title>라살 불변 원리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lasalle-invariance-principle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lasalle-invariance-principle/</guid>
      <description>라살 불변 원리 1공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 플로우 $\phi_t \left( \cdot \right)$ 하에서의 컴팩트 양불변집합을 $\mathcal{M} \subset \mathbb{R}^{n}$ 이라 하자. $\mathcal{M}$ 에서 랴푸노프 함수 $V : \mathcal{M} \to \mathbb{R}$ 가 정의되어 있다고 할 때, 다음의 두 집합을 생각해보자. $$ E := \left\{ x \in \mathcal{M} : V&#39;(x) = 0 \right\} $$ 이 $E$ 에 대해 다음과 같이 정의된 집합 $M$ 을 양불</description>
    </item>
    
    <item>
      <title>라플라스 계승 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</guid>
      <description>정리 이항모형 $\displaystyle p(y | \theta) = \pmatrix{ n \\ y} \theta^{y} (1- \theta)^{n-y}$ 의 사전분포가 균일분포 $U (0,1)$ 를 따르고 사후분포가 베타분포 $\beta (y+1 , n-y+1)$ 을 따라 $p( \theta | y ) \sim \theta^{y} (1- \theta)^{n-y} $ 이라고 하자. 그러면 이제까지 얻은 데이터 $y$ 에 대해 새로운 $\tilde{y}$ 가 $1$ 일 확률은 $$ p(\tilde{y} = 1| y) = {{y+1} \over {n+2}} $$ 프리퀀티스트의 관점으로 보았을 때 $\tilde{y} = 1$ 일 확률은 그 표본비율 $\displaystyle {{y} \over {n}}$ 에 가까울 것이다. 그런데 기본적으로 $n$</description>
    </item>
    
    <item>
      <title>라플라스 방정식의 스무싱 이펙트</title>
      <link>https://freshrimpsushi.github.io/posts/smoothing-effect-in-laplaces-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/smoothing-effect-in-laplaces-equation/</guid>
      <description>**스무싱 이펙트$(\mathrm{Smoothing\ effect})$ $u \in C(\Omega)$가 **** 각 열린 볼 $B(x,r)\subset \Omega$에서 평균값 성질$ \mathrm{(mean-value\ property})$를 만족한다고 하자. 그러면 $$ u \in C^{\infty}(\Omega) $$ 쉽게 말해서 하모닉 이면 매끄럽다는 말이다. 이 정리에서 주의해야 할 점은 $\Omega$의 경계인 $\partial \Omega$에서는 매끄럽지</description>
    </item>
    
    <item>
      <title>라플라스 변환 표</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-table/</guid>
      <description>라플라스 변환 표이다. 각각의 증명에 대한 링크는 표 하단에 있으니 참고하라. $ \begin{matrix} \hline \\ f(t)=\mathcal{L^{-1}} \left\{ F(s) \right\} &amp;amp; F(s)=\mathcal{L} \left\{ f(t) \right\} &amp;amp; \mathrm{condition} \\ &amp;amp; &amp;amp; \\ \hdashline &amp;amp; &amp;amp; \\ 1 &amp;amp; \dfrac{1}{s} &amp;amp; s&amp;gt;0 \\ &amp;amp; &amp;amp; \\ e^{at} &amp;amp; \dfrac{1}{s-a} &amp;amp; s&amp;gt;a \\ t^n\ &amp;amp; \dfrac{n!}{t^{n+1}}&amp;amp; n \in \mathbb{N},\quad s&amp;gt;0 \\ &amp;amp; &amp;amp; \\ t^{p} &amp;amp; \dfrac{ \Gamma (p+1) }{ s^{p+1}} &amp;amp; p&amp;gt;-1,\quad s&amp;gt;0 \\ &amp;amp; &amp;amp; \\ t^{p}e^{at} &amp;amp; \dfrac{ \Gamma (p+1) }{ (s-a)^{p+1}}&amp;amp; p&amp;gt;-1,\quad s&amp;gt;0 \\ &amp;amp; &amp;amp; \\ \sin (at) &amp;amp;\dfrac{a}{s^2+a^2} &amp;amp; s&amp;gt;0 \\ &amp;amp; &amp;amp; \\ \cos (at) &amp;amp;\dfrac{s}{s^2+a^2} &amp;amp; s&amp;gt;0 \\ &amp;amp; &amp;amp; \\ e^{at}\sin(bt)&amp;amp;\dfrac{b}{(s-a)^2 +b^2} &amp;amp; s&amp;gt;a&amp;amp; \\ &amp;amp; &amp;amp; \\ e^{at}\cos(bt)&amp;amp;\dfrac{s-a}{(s-a)^2+b^2} &amp;amp; s&amp;gt;0 \\ &amp;amp; &amp;amp; \\ \sinh (at) &amp;amp; \dfrac{a}{s^2-a^2} &amp;amp; s&amp;gt;|a| \\ &amp;amp;</description>
    </item>
    
    <item>
      <title>라플라스 변환에서 단위 계단 함수의 응용</title>
      <link>https://freshrimpsushi.github.io/posts/application-of-unit-step-function-in-laplace-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/application-of-unit-step-function-in-laplace-transform/</guid>
      <description>$\mathcal {L} \left\{ u_c(t) f(t-c) \right\} = e^{-cs} F(s) $ $F(s)=\mathcal {L} \left\{ f(t) \right\}$단위 계단 함수 를 이용하면 특정 시간이후부터 갑자기 값이 생기는(혹은 사라지는) 함수를 잘 표현할 수 있다.즉, 전기 회로 등의 물리적인 상황을 잘 표현할 수 있다.아래 그림을 보면 이해가 쉬울 것이다.유도 우선 $c$는 임의의 상수이고, $s &amp;gt; a \ge 0$일 때 $f(t)$의 라플라스 변환 $F(s)</description>
    </item>
    
    <item>
      <title>라플라스 변환의 선형성</title>
      <link>https://freshrimpsushi.github.io/posts/linearity-of-laplace-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearity-of-laplace-transform/</guid>
      <description>$f_1$과 $f_2$를 라플라스 변환이 존재하는 함수라고 하자.그리고 $c_1$, $c_2$를 임의의 상수라고 하자.그러면 $\mathcal{L} \left\{ c_1f_1 + c_2f_2 \right\} = c_1\mathcal{L} \left\{f_1 \right\} + c_2\mathcal{L} \left\{f_2 \right\}$라플라스 변환은 선형 연산자$\mathrm{Linear\ Operator}$라는 뜻이다.이는 라플라스 변환이 아래와 같이 곱의 꼴로 정의됐기 때문이다.$\di</description>
    </item>
    
    <item>
      <title>라플라스 변환의 정의와 존재성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-laplace-transform-and-proof-of-existence-of-laplace-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-laplace-transform-and-proof-of-existence-of-laplace-transform/</guid>
      <description>라플라스 변환은 적분 변환 으로 함수 $f(t)$의 라플라스 변환은 아래와 같이 정의한다. $$ \displaystyle \mathcal{L} \left\{ f(t) \right\} := \int _0^\infty e^{-st}f(t) dt =F(s) $$ 라플라스 변환을 이상 적분으로 정의했기 때문에 수렴해야 라플라스 변환이 존재한다.결론부터 말하자면 우리가 흔히 다루는 함수들은 전부 라플라스 변환이 가능하다.상수함수, 다항함수, 지수함수, 삼각함수, 쌍곡함수 등은 라플</description>
    </item>
    
    <item>
      <title>라플라스 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-prior/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-prior/</guid>
      <description>모수에 대한 정보가 거의 없다면 구태여 복잡한 사전분포를 생각할 이유는 없다. 내년 모 대학의 통계학과 신입생의 성비를 추측해보라고 했을 때, 통계학과를 어느정도 아는 사람이라면 예년의 성비를 보고 어느정도 짐작을 하겠지만 전혀 관계도 없고 관심도 없는 사람이 이 질문을 들었을 땐 특별한 이유가 없는 한 50:50이라고 추측할 것이다. 어떤 주머니 안에 빨</description>
    </item>
    
    <item>
      <title>랴푸노프 안정성과 오빗 안정성</title>
      <link>https://freshrimpsushi.github.io/posts/liapunov-stability-and-orbit-stability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/liapunov-stability-and-orbit-stability/</guid>
      <description>**랴푸노프 안정성1 거리 공간 $\left( X , \left| \cdot \right| \right)$ 과 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 1. $t_{0} \in \mathbb{R}$ 이라 하자. 주어진 미분 방정식의 솔루션 $\overline{x}(t)$ 가 $\varepsilon &amp;gt; 0$ 이 주어질 때마다 $$ \left| \overline{x} \left( t_{0} \right) - y \left( t_{0} \right) \right| &amp;lt; \delta \implies \left| \overline{x}(t) - y(t) \right| &amp;lt; \varepsilon \qquad , t &amp;gt; t_{0} $$ 를 만족시키는 다른 모든 솔루션 $y(t)$ 에 대해 $\delta ( \varepsilon ) &amp;gt; 0$ 가 존재</description>
    </item>
    
    <item>
      <title>레귤러 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/regular-graph/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regular-graph/</guid>
      <description>1. 모든 버텍스의 차수가 같은 그래프를 레귤러 그래프 라고 한다. 특히 모든 버텍스의 차수가 $r$ 이면 $r$-레귤러 그래프 라고 한다. 다시 말해, 다음을 만족시키는 그래프 $G$ 를 $r$-레귤러 그래프라고 한다. $$ \deg (v) = r \qquad , \forall v \in V(G) $$ 2. $2$-레귤러 연결 그래프를 사이클Cycle 이라고 한다.1. 레귤러 그래프 의 예로써 다음과 같은 것들을 생</description>
    </item>
    
    <item>
      <title>레벤슈타인 알고리즘</title>
      <link>https://freshrimpsushi.github.io/posts/levensteins-algorithm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/levensteins-algorithm/</guid>
      <description>문자열 $A,B$ 를 $A=[a_{i}]=(a_{1}, a_{2} , \cdots, a_{n})$ 과 $B=[b_{j}]=(b_{1}, b_{2} , \cdots, b_{m})$ 로 표현하자.**Step 1. 행렬 $M_{(n+1) \times (m+1)} = [m_{x y }]$ 를 만들고 $M_{11} = 0$ 을 대입한다.**Step 2. $m_{(i+1) 1} = i$ 그리고 $m_{ 1 (j+1)} = j$ 을 대입한다.**Step 3.** $i = 1, 2, \cdots , n$ 그리고 $j=1,2, \cdots , m$if $a_{i}==b_{j} $$ M_{i,j} = M_{(i-1)(j-1)}$ 을 대입한다.else$M_{i,j} = \min \left\{ M_{(i-1)(j)}, M_{(i)(j-1)}, M_{(i-1)(j-1)}\right\} + 1 $ 을 대입한다.**Step 4. $A$,$B$ 의 최소 수정 거리</description>
    </item>
    
    <item>
      <title>로랑 급수란</title>
      <link>https://freshrimpsushi.github.io/posts/laurent-series/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laurent-series/</guid>
      <description>테일러 정리는 평균값의 정리를 미분 횟수에 대해 일반화한 정리다.원래 $1$번 미분한 것만을 다루던 것에서 $n \in \mathbb{N}$ 으로 확장한 것이다.그런데 자연수로 일반화가 가능했다면, 정수 전체로 일반화할 수는 없는껄까?물론 미분을 $-n$ 번 할 수는 없지만, 미분과 역연산 관계에 있는 적분을 생각해면 어떨까?아래의 정리를 증명 없이 소개한다.로랑 정리 $f : A \subset</description>
    </item>
    
    <item>
      <title>로랑 급수의 principal part와 특이점의 분류</title>
      <link>https://freshrimpsushi.github.io/posts/293/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/293/</guid>
      <description>로랑 전개의 principal part를 잘 살펴보면 특이점의 종류를 파악할 수 있다.$\alpha$ 를 함수 $f:A\subset \mathbb{C} \to \mathbb{C} $ 의 isolated singular point 라 하자. 이의 로랑 전개 $\displaystyle f(z) = \sum_{n = 0 }^{\infty} a_{n} (z-\alpha) ^{n} + \sum_{n = 1 }^{\infty} { {b_{n} } \over{ (z-\alpha) ^{n} } } $ 에 대해, 수열 $b_{n}$ 은 아래의 성질들을 가진다.**(1)** 모든 $n$ 에 대해 $b_{n}=0$ $ \iff$ $ \alpha$ 는 removable singular point 이다.**(2)** 어떤 $m$ 에 대해 $b_{m} \ne 0$ 이고 $b_{m+1} = b_{m+2} =</description>
    </item>
    
    <item>
      <title>로렌츠 변환으로 알아보는 특수상대성이론의 특징 1 - 동시성 상실</title>
      <link>https://freshrimpsushi.github.io/posts/lorentz-transformation-theory-of-relativity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lorentz-transformation-theory-of-relativity/</guid>
      <description>특수상대성이론에서 두 좌표계 사이의 변환은 고전적인 변환과 다르다.&amp;lsquo;빛의 속도는 어느 관찰자에게나 $c$이다&amp;rsquo;라는 점 때문이다.위의 조건을 잘 만족하는 새로운 변환이 바로 로렌츠 변환이다.이 로렌츠 변환으로 인해서 고전물리에서는 나타나지 않는 새로운 현상이 세가지 있다.$1$ 동시성 상실$2$ 시간 팽창(시간</description>
    </item>
    
    <item>
      <title>로렌츠 변환으로 알아보는 특수상대성이론의 특징 2 - 시간 팽창</title>
      <link>https://freshrimpsushi.github.io/posts/lorentz-transformation-theory-of-relativity-time-dilation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lorentz-transformation-theory-of-relativity-time-dilation/</guid>
      <description>특수상대성이론에서 두 좌표계 사이의 변환은 고전적인 변환과 다르다.&amp;lsquo;빛의 속도는 어느 관찰자에게나 $c$이다&amp;rsquo;라는 점 때문이다.위의 조건을 잘 만족하는 새로운 변환이 바로 로렌츠 변환이다.이 로렌츠 변환으로 인해서 고전물리에서는 나타나지 않는 새로운 현상이 세가지 있다.$1$ 동시성 상실$2$ 시간 지연(Ti</description>
    </item>
    
    <item>
      <title>로렌츠 변환으로 알아보는 특수상대성이론의 특징 3 - 길이 수축</title>
      <link>https://freshrimpsushi.github.io/posts/lorentz-transformation-theory-of-relativity-length-contraction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lorentz-transformation-theory-of-relativity-length-contraction/</guid>
      <description>특수상대성이론에서 두 좌표계 사이의 변환은 고전적인 변환과 다르다.&amp;lsquo;빛의 속도는 어느 관찰자에게나 $c$이다&amp;rsquo;라는 점 때문이다.위의 조건을 잘 만족하는 새로운 변환이 바로 로렌츠 변환이다.이 로렌츠 변환으로 인해서 고전물리에서는 나타나지 않는 새로운 현상이 세가지 있다.$1$ 동시성 상실$2$ 시간 지연(Ti</description>
    </item>
    
    <item>
      <title>로렌츠 변환으로부터 알 수 있는 사실들</title>
      <link>https://freshrimpsushi.github.io/posts/lorentz-transformation-lorentz-facor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lorentz-transformation-lorentz-facor/</guid>
      <description>로렌츠 변환 유도하기로렌츠 변환으로부터 알 수 있는 사실을 몇 가지 정리해보자.$(1)$ 위의 링크에서 언급했지만 $A&#39;$계의 속도인 $v_0$가 빛의 속도인 $c$에 비해 굉장히 작다면로렌츠 변환은 갈릴레이 변환에 근사한다.우리가 겪는 현실에서 대부분의 경우이다.이것이 아직도 뉴턴역학을 배우는 이유이다.$(2)$ 로렌츠 인자인 $\</description>
    </item>
    
    <item>
      <title>로지스틱 패밀리</title>
      <link>https://freshrimpsushi.github.io/posts/logistic-family/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logistic-family/</guid>
      <description>$a \ge 0$ 에 대해 $g_{a} (x) = a x ( 1 - x )$ 를 **로지스틱 맵** 이라고 하고 $\left\{ g_{a} \mid a &amp;gt; 0 \right\} $ 을 **로지스틱 패밀리** 라고 한다.**(1)** $x \in [0,1] $$ \iff $$ g_{a} (x) \ge 0$**(2)** $g&#39;_{a} (x) = a ( 1 - 2x) $로지스틱 모형은 인구의 증감 등의 여러가지 현상을 모델링하는데 유용하게 쓰일 수 있다. 인구라면 한 세대가 지날 때마다 로티스틱 맵 $g_{a}$ 를 한 번 취하는 것으로 볼 수 있</description>
    </item>
    
    <item>
      <title>로지스틱 함수란</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-a-logistic-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-a-logistic-function/</guid>
      <description>로지스틱 함수 1로지스틱 함수란 미분 방정식의 해 $y&#39; = y(1-y)$ 로써, 다음과 같이 구해진다. $$ y(t) = {{ 1 } \over { 1 + e^{-t} }} $$ 조금 더 일반적인 형태로써 $ \displaystyle f(x) := {{ L } \over { 1 + e^{-k(x-x_{0})} }}$ 와 같은 꼴을 사용하기도 한다. 로지스틱 함수는 시그모이드 함수며, 쓰임새가 많아 동역학, 통계학, 딥러닝, 생물학 등 여러 분야에서 언급되기도 하는 함수다.문제는 도대체 이게</description>
    </item>
    
    <item>
      <title>르벡 공간 Lp 공간</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-space-lp-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-space-lp-space/</guid>
      <description>$1&amp;lt; p &amp;lt;\infty $ 에 대해 함수공간 $\displaystyle \mathcal{L} ^{p} (E) : = \left\{ f , \left| , \int_{E} | f |^{p} dm &amp;lt; \infty \right. \right\} $ 을 $\mathcal{L} ^{p}$ 과 같이 나타내자.**[1]** $\mathcal{L}^{p} $ 는 벡터공간이다.**[2]** $\mathcal{L}^{p} $ 는 놈 벡터공간이다.**[3]** $\mathcal{L}^{p} $ 는 완비공간이다.**[4]** $1 \le p \le q \le \infty$ 이고 $m(E) &amp;lt; \infty \implies \mathcal{L} ^{q} (E) \subset \mathcal{L} ^{p} (E)$완비 공간인 놈 벡터공간을 특별히 **바나흐 공간Bana</description>
    </item>
    
    <item>
      <title>르벡-라돈-니코딤 보조 정리</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-radon-nikodym-lemma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-radon-nikodym-lemma/</guid>
      <description>**** **르벡-라돈-니코딤 보조 정리 가측 공간 $(X, \mathcal{E})$위의 유한 측도 $\mu$, $\nu$가 주어졌다고 하자. 그러면 $\mu \perp \nu$이거나, 아래의 조건을 만족하는 $\epsilon&amp;gt;0$, $E \in \mathcal{E}$가 존재한다. $$ \mu(E) &amp;gt;0 \quad &amp;amp; \quad \nu(E) \ge \epsilon \mu (E) $$ 실제로 이 정리에 따로 정해진 이름은 없으나 르벡-라돈-니코딤 정리를 증명할 때 유용한 보조</description>
    </item>
    
    <item>
      <title>르장드르 다항식은 자신보다 차수가 낮은 임의의 다항식과 직교함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/933/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/933/</guid>
      <description>$P_l(x)$을 르장드르 다항식 , $f(x)$를 차수가 $l$보다 낮은 임의의 다항식이라 할 때 $P_l(x)$와 $f(x)$는 서로 직교 한다. $$ \int_{-1}^{1}P_l(x)f(x)dx $$ **보조정리 $f(x)$를 임의의 $n$차 다항식이라 하자.$f(x)$는 $l \le n$인 르장드르 다항식$(\mathrm{Legendre\ polynomial})$의</description>
    </item>
    
    <item>
      <title>르장드르 다항식의 생성 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-generating-function-of-lengendre-polynomial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-generating-function-of-lengendre-polynomial/</guid>
      <description>르장드르 다항식의 생성 함수는 아래와 같다. $$ \Phi (x,t)= \sum \limits_{l=0}^{\infty}P_{l}(x)t^{l}=\frac{1}{\sqrt{1-2xt+t^{2}}},\quad |t|&amp;lt;1 $$ 르장드르 다항식의 생성 함수란 쉽게 말해서 르장드르 다항식 $P_{l}(x)$를 계수로 갖는 다항식이다.**보조정리 생성함수 $\Phi (x,t)$는 아래의 미분 방정식을 만족한다. $$ (1-x^{2})\frac{ \partial ^{2} \Phi}{ \partial x^{2} }-2x\frac{ \partial \Phi}{ \partial x }+t\frac{ \partial ^{2}}{ \partial t^{2} }(t\Phi)=0\tag{1} $$ **생성함수로부터 유도된 르장드르 다항식의 재귀 관계 $$ lP_l(x)=(2l-1)xP_{l-1}(x)-(l-1)P_{l-2}(x)</description>
    </item>
    
    <item>
      <title>르장드르 다항식의 여러 성질</title>
      <link>https://freshrimpsushi.github.io/posts/some-properties-of-legendre-polynomial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/some-properties-of-legendre-polynomial/</guid>
      <description>르장드르 미분 방정식과 르장드르 다항식아래의 미분 방정식을 르장드르 미분 방정식이라 하고 이 방정식의 해를 르장드르 다항식이라 한다. $$ (1-x^2)\dfrac{d^2 y}{dx^2} -2x\dfrac{dy}{dx}+l(l+1) y=0 $$ 각 $l$에 따른 르장드르 다항식은 다음과 같다. $$ \begin{align*} P_0(x) &amp;amp;=1 \\ P_1(x) &amp;amp;=x \\ P_2(x) &amp;amp;=\dfrac{1}{2}(3x^2-1) \\ P_3(x)&amp;amp;=\dfrac{1}{2}(5x^3-3x) \\ P_4(x)&amp;amp;=\dfrac{1}{8}(35x^4-30x^2+3) \\ \vdots \end{align*} $$ 로드리게스 공식각 $l$에 대한 르장드르 다항식을 얻는 공식이다. $$ P_l(x)=\dfrac{1}{2^l l!} \dfrac{d^l}{dx^l}(x^2-1)^l $$ 르장드르 미분 방정식의 삼각함</description>
    </item>
    
    <item>
      <title>르장드르 다항식의 재귀 관계</title>
      <link>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-legendre-polynomial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-legendre-polynomial/</guid>
      <description>르장드르 다항식의 재귀 관계식 $$ P&#39;{l+1}(x)-P&#39;{l-1}(x)=(2l+1)P_{l}(x)\tag{a} $$ $$ lP_l(x)=(2l-1)xP_{l-1}(x)-(l-1)P_{l-2}(x) \tag{b} $$ $$ xP&#39;{l}(x)-P&#39;{l-1}(x)=lP_{l}(x)\tag{c} $$ 로드리게스 공식 $$ P_l(x)=\dfrac{1}{2^l l!} \dfrac{d^l}{dx^l}(x^2-1)^l $$ 르장드르 다항식의 생성함수아래의 함수 $\Phi (x,h)$를 르장드르 다항식의 생성함수라 한다. $$ \Phi (x,h)=\frac{1}{\sqrt{1-2xh+h^{2}}},\quad |h|&amp;lt;1 $$ 생성함수는 아래의 식을 만족한다. $$ \Phi(x,h)=P_{0}(x)+hP_{1}(x)+h^{2}P_{2}(x)+\cdots =\sum \limits_{l=0}^{\infty}h^{l}P_{l}(x) $$ 증명 $(a)$ 우선 $P_{l}(x)$를 계산해보자. 로드리게스 공식에 의해 $$ \begin{align*} \frac{ d }{ dx }P_{l}(x) &amp;amp;=\dfrac{1}{2^l l!}\frac{ d }{ dx } \dfrac{d^l}{dx^l}(x^2-1)^l \\ &amp;amp;= \frac{</description>
    </item>
    
    <item>
      <title>르장드르 다항식의 직교성</title>
      <link>https://freshrimpsushi.github.io/posts/the-orthogonality-of-legendre-polynomials/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-orthogonality-of-legendre-polynomials/</guid>
      <description>함수의 내적 과 직교성 구간 $[-1,\ 1]$에서 르장드르 다항식은 직교 집합을 이룬다. $$ \int_{-1}^{1} P_l(x)P_m(x) dx =\frac{2}{2l+1}\delta_{lm} $$ 증명 **Case 1. $l\ne m$ 르장드르 다항식은 드장드르 미분방정식의 해이므로 위의 미분방정식의 $y$ 자리에 대입하면 식이 성립한다.즉, $$ \dfrac{d}{dx} \left[ (1-x^2)P&#39;_l(x) \right] + l(l+1)P_l (x)=0 $$ $$ \dfrac{d}{dx} \left[ (1-x^2)P&#39;_m(x) \right] + m(m+1)P_m(x)=0 $$ 두 식에 각각 $P_m(x)$, $P_l(x)$를 곱하고 빼서 정리하면 $$ P_m\dfrac{d}{dx}\left[ (1-x^2)P&#39;_l \right] - P_l\dfrac{d}{dx}[(1-x^2)P&#39;_m]+ [l(l+1)-m(m+1)]P_lP_m=0 \tag{1} $$ 이때 $$ \begin{align*} &amp;amp;\dfrac{d}{dx}[(1-x^2)(P_mP&#39;_l-P_lP&#39;_m)] \\ =&amp;amp;\dfrac{d}{dx}[\color{blue}{(1-x^2)P&#39;_l}P_m]</description>
    </item>
    
    <item>
      <title>르장드르 변환</title>
      <link>https://freshrimpsushi.github.io/posts/legendre-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/legendre-transform/</guid>
      <description>우선 단순함을 위해 라그랑지안을 변수 $v$만을 가지는 함수라고 하자. $$ L=L(v)\ :\ \mathbb{R}^n \rightarrow \mathbb{R} $$ 그러면 $L$의 르장드르 변환을 다음과 같이 정의할 수 있다.**르장드르 변환$(\mathrm{Legendre\ transform,\ or\ Fenchel\ transform})$ 주어진 라그랑지안 $L\ :\ \mathbb{R}^n \rightarrow \mathbb{R}$이 아래의 조건을 만족한다고 하자.$(a)$ $L$은 볼록한$(\ma</description>
    </item>
    
    <item>
      <title>르장드르의 배 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-legendres-duplication-formula/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-legendres-duplication-formula/</guid>
      <description>$$ \displaystyle \Gamma (2r) = {{2^{ 2r - 1} } \over { \sqrt{ \pi } } } \Gamma \left( r \right) \Gamma \left( {{1} \over {2}} + r \right) $$ 쪼개지는 모양이 그렇게 예쁘지는 않지만 인수를 작게 나눌 수 있다는 것은 분명 유용한 사실이다.유도 자체는 베타함수에서 파생된 보조정리를 사용하면 별로 어렵지 않다. 유도 $$ \displaystyle B(p,q) = {{\Gamma (p) \Gamma (q)} \over {\Gamma (p+q) }} = \int_{0}^{1} t^{p-1} (1-t)^{q-1} dt $$ 에 대해 $r:= p=q$ 이라고 하면 $$ \displaystyle {{\Gamma (r) \Gamma (r)} \over {\Gamma (2r) }} = \int_{0}^{1} t^{r-1} (1-t)^{r-1} dt $$ $\displaystyle t =</description>
    </item>
    
    <item>
      <title>리-요크 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-li-yorke-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-li-yorke-theorem/</guid>
      <description>연속 맵 $f: [a,b] \to [a,b]$ 의 피리어딕-$3$ 오빗이 존재하면 $f$ 는 카오틱하다.리-요크 정리는 삼주기 정리Period-$3$ Theorem 라고도 불리며, 피리어딕-$3$ 가 혼돈을 야기한다는 스테이트먼트 자체로도 많이 언급된다.물론 이 정리만 보면 $1$차원 맵에 한정되어 있지만 고작 피리어딕-$3$ 오빗의 존재성이 모든 피리어딕 오빗의 존재성을 보장하</description>
    </item>
    
    <item>
      <title>리눅스에서 gcc 컴파일러로 c 코드 컴파일 하는 법 How to Compile c Code using gcc in linux</title>
      <link>https://freshrimpsushi.github.io/posts/1653/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1653/</guid>
      <description>보통 C/C++을 이용한 프로그램 개발은 윈도우에서 비주얼 스튜디오를 쓰는 것이 권장되나, 간단한 테스트나 수치계산, 시뮬레이션 등을 리눅스로 진행할 때는 리눅스 특유의 가벼움이 큰 장점으로 다가올 때가 있다.가령 infection_modified_200428.c 이라는 c 소스코드가 있다면, 터미널에서 해당 경로로 이동한 뒤 다음과 같이 입력해보자.gcc -o infection infection_modified_200428.c -lm그러면 같은 경로에 i</description>
    </item>
    
    <item>
      <title>리만-스틸체스 적분</title>
      <link>https://freshrimpsushi.github.io/posts/riemann-stieltjes-integral/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riemann-stieltjes-integral/</guid>
      <description>리만-스틸체스 적분은 리만 적분을 일반화한 것으로 간단히 스틸체스 적분이라고도 한다. $\alpha(x)=x$라고 두면 리만-스틸체스 적분은 리만 적분과 같다. 즉, 리만 적분은 리만-스틸체스 적분의 특수한 경우에 해당한다. 따라서 리만-스틸체스 적분에 관한 정리나 사실들이 리만 적분에도 그대로 적용된다.**** **단조증가함수 함</description>
    </item>
    
    <item>
      <title>리만-스틸체스 적분 가능한 함수의 상수배도 적분가능함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1665/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1665/</guid>
      <description>**정리 $f$가 $[a,b]$에서 리만(-스틸체스) 적분 가능하다고 하자. 그러면 상수 $c\in \mathbb{R}$에 대해서 $cf$도 $[a,b]$에서 적분 가능하고 그 값은 아래와 같다. $$ \int_{a}^{b}cf d\alpha = c\int_{a}^{b}f d\alpha $$ $f$가 적분가능할 때 $cf$도 적분 가능하다고 해서 그 값이 $c\displaystyle \int fd\alpha$와 값이 같으리라는 보장은 없지만 실제로는 같</description>
    </item>
    
    <item>
      <title>리만-스틸체스 적분 가능한 함수의 합도 적분가능함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1666/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1666/</guid>
      <description>리만 적분은 리만-스틸체스 적분에서 $\alpha(x)=x$인 경우이므로 리만 적분에 대한 증명도 아래와 같다.**정리 두 함수 $f_{1}$, $f_{2}$가 $[a,b]$에서 리만(-스틸체스)적분 가능하다고 하자. 그러면 $f_{1}+f_{2}$도 적분 가능하고 그 값은 아래와 같다. $$ \int _{a} ^{b}(f_{1}+f_{2})d\alpha = \int _{a} ^{b} f_{1}d\alpha + \int_{a}^{b} f_{2} d\alpha $$ $f_{1}$ 와 $f_{2}$</description>
    </item>
    
    <item>
      <title>리만-스틸체스 적분 가능할 필요충분조건에 대한 따름 정리</title>
      <link>https://freshrimpsushi.github.io/posts/1865/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1865/</guid>
      <description>**리만(-스틸체스) 적분 가능할 필요충분조건 함수 $f$가 $[a,b]$에서 리만(-스틸체스) 적분가능할 필요충분조건은 모든 $\varepsilon &amp;gt;0$에 대하여 $U(P,f,\alpha) - L(P,f,\alpha) &amp;lt; \varepsilon$을 만족시키는 $[a,b]$의 분할 $P$가 존재하는 것이다. $$ f \in \mathscr{R} (\alpha)\ \mathrm{on\ } [a,b] \\ \iff \forall\ \epsilon &amp;gt;0, \ \exists\ P \mathrm{\ s.t\ } U(P,f,\alpha) - L(P,f,\alpha) &amp;lt; \varepsilon \tag{1} $$ **따름 정리 $(a)$ 만약</description>
    </item>
    
    <item>
      <title>리에나르-비케르트 전위 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-lienard-wiechert-potentials/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-lienard-wiechert-potentials/</guid>
      <description>**리에나르-비케르트 전위$(\mathrm{Liénard-Wiechert\ potentials}$, 리에나르-비헤르트 전위$)$ 지연시각 $t_r$에서 속도 $\mathbf{v}$로 움직이는 점전하 $q$에 대한 전위는 다음과 같다. $$ V(\mathbf{r}, t)= \frac{1}{4\pi \epsilon_0} \frac{qc}{ (\eta c -\boldsymbol{\eta}\cdot \mathbf{v})} $$ $$ \mathbf{A}(\mathbf{r}, t) = \frac{\mu_0}{4 \pi}\frac{qc \mathbf{v} }{(\eta c - \boldsymbol{\eta}\cdot \mathbf{v} )}=\frac{\mathbf{v}}{c^2}V(\mathbf{r}, t) $$ 이때 $\boldsymbol{\eta}=\mathbf{r} -\mathbf{w}(t_r)$는</description>
    </item>
    
    <item>
      <title>리즈 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-riesz-lemma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-riesz-lemma/</guid>
      <description>놈드 스페이스 $(X , | \cdot | )$ 의 부분 공간 $Y \subsetneq X$ 에 대해 $Y$ 는 닫힌 집합이라고 하자. 모든 $\theta \in (0,1)$ 와 $y \in Y$ 에 대해 $| x_{ \theta } | = 1$ 와 $| x_{ \theta } - y | &amp;gt; \theta $ 를 만족하는 $x_{\theta} \in X$ 가 존재한다.**Strategy** : 구체적인 $x_{\theta}$ 가 존재함을 보인 후 $| x_{ \theta } - y | &amp;gt; \theta $ 가 성립함을 보인다. 증명 $ x_{0 } \notin Y$ 면서 $ x_{0 } \in X$ 인 $x_{0}$ 에 대해서 $d:= \inf \left\{ | x_{0} -</description>
    </item>
    
    <item>
      <title>리차드슨 오차 추정</title>
      <link>https://freshrimpsushi.github.io/posts/richardson-error-estimation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/richardson-error-estimation/</guid>
      <description>미분방정식을 푸는 메소드의 퍼포먼스를 확인하는 방법으로 참값과 비교할 수 있다면 가장 좋겠지만, 당장 참값을 구하기 귀찮은 경우부터 시작해서 아예 트루 솔루션을 구하기 곤란한 경우도 많다. 이땐 $y_{h} (x_{n} )$ 과 스탭사이즈 $h$ 를 두배로 늘렸을 때의 $y_{2h} (x_{n} )$ 을 비교함으로써 오차를 추정할 수 있다.예를 들어 사다리꼴 메소드라면 $h$ 를 고침으로써 아래의 두 식을 얻는</description>
    </item>
    
    <item>
      <title>리카티 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-ricatti-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-ricatti-differential-equation/</guid>
      <description>$y^\prime = P(x)y+Q(x)y^2+R(x)$꼴의 미분방정식을 리카티 방정식이라 한다.$y_1$을 이미 알고있는 특별해$\mathrm{Particular\ Solution}$라고 하면일반해는 $y=y_1+u(x)$꼴로 나타내진다.이 때 $u(x)$는 임의의 상수이며 $n=2$일 때의 베르누이 미분방정식을 풀어서</description>
    </item>
    
    <item>
      <title>매트랩에서 3차원 구 좌표계 미소 부피 그리는 코드</title>
      <link>https://freshrimpsushi.github.io/posts/1756/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1756/</guid>
      <description>3차원 구 좌표계에서 미소 부피위와 같은 3차원 구 좌표계의 미소 부피의 그래프를 매트랩에서 그리는 코드는 아래와 같다. r=1; dr=0.7; phi=deg2rad(39); dphi=2*phi; theta=pi/6; dtheta=theta+theta/2; n=50; m=22; pi2=pi/2; R=zeros(n,m); Phi=zeros(n,m); Theta=zeros(n,m); X=zeros(n,m); Y=zeros(n,m); Z=zeros(n,m); Rv=linspace(0,r,n); dRv=linspace(dr,r,n); Pv=linspace(phi,dphi,n); Tv1=linspace(0,pi2,n); Tv2=linspace(0,theta,n); dTv=linspace(theta,dtheta,n); %검은 점선 R(:,1)=Rv; Phi(:,1)=phi; Theta(:,1)=pi2; R(:,2)=Rv; Phi(:,2)=dphi; Theta(:,2)=pi2; R(:,3)=r; Phi(:,3)=Pv; Theta(:,3)=pi2; R(:,4)=r; Phi(:,4)=phi; Theta(:,4)=Tv1; R(:,5)=r; Phi(:,5)=dphi; Theta(:,5)=Tv1; R(:,6)=Rv; Phi(:,6)=phi; Theta(:,6)=theta; R(:,7)=Rv; Phi(:,7)=dphi; Theta(:,7)=theta; R(:,8)=Rv; Phi(:,8)=phi; Theta(:,8)=dtheta; R(:,9)=Rv; Phi(:,9)=dphi; Theta(:,9)=dtheta; R(:,10)=dr; Phi(:,10)=dphi; Theta(:,10)=dTv; R(:,11)=dr; Phi(:,11)=Pv; Theta(:,11)=theta; R(:,12)=r; Phi(:,12)=dphi; Theta(:,12)=Tv2; %검은 실선 R(:,13)=dr; Phi(:,13)=phi; Theta(:,13)=dTv; R(:,14)=dRv; Phi(:,14)=phi; Theta(:,14)=dtheta; R(:,15)=dRv; Phi(:,15)=dphi; Theta(:,15)=dtheta; R(:,16)=dr; Phi(:,16)=Pv; Theta(:,16)=dtheta; R(:,17)=r; Phi(:,17)=Pv; Theta(:,17)=dtheta; R(:,18)=r; Phi(:,18)=dphi; Theta(:,18)=dTv; %초록선 R(:,19)=dRv; Phi(:,19)=phi; Theta(:,19)=theta; %파란선 R(:,20)=r; Phi(:,20)=phi; Theta(:,20)=dTv;</description>
    </item>
    
    <item>
      <title>매트랩에서 3차원 원통 좌표계 미소 부피 그리는 코드</title>
      <link>https://freshrimpsushi.github.io/posts/1760/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1760/</guid>
      <description>원통 좌표계에서 미소 부피매트랩에서 위와 같은 그래프는 그리는 코드는 아래와 같다. r=1; dr=0.7; theta=pi/6; dtheta=2*theta; z=2; dz=1.3; n=50; m=22; pi2=pi/2; R=zeros(n,m); Theta=zeros(n,m); Z=zeros(n,m); X=zeros(n,m); Y=zeros(n,m); Rv=linspace(0,r,n); dRv=linspace(dr,r,n); Tv=linspace(0,pi2,n); dTv=linspace(theta,dtheta,n); Zv=linspace(0,z,n); dZv=linspace(dz,z,n); %검은 점선 R(:,1)=Rv ;Theta(:,1)=theta ;Z(:,1)=0; R(:,2)=Rv ;Theta(:,2)=dtheta ;Z(:,2)=0 ; R(:,3)=dr ;Theta(:,3)=dTv ;Z(:,3)=0 ; R(:,4)=dr ;Theta(:,4)=theta ;Z(:,4)=Zv ; R(:,5)=r ;Theta(:,5)=theta ;Z(:,5)=Zv ; R(:,6)=r ;Theta(:,6)=dtheta ;Z(:,6)=Zv ; R(:,7)=dr ;Theta(:,7)=dtheta ;Z(:,7)=Zv ; R(:,8)=dr ;Theta(:,8)=dTv ;Z(:,8)=dz ; R(:,9)=dRv ;Theta(:,9)=dtheta ;Z(:,9)=dz ; R(:,10)=Rv ;Theta(:,10)=theta ;Z(:,10)=z ; R(:,11)=Rv ;Theta(:,11)=dtheta ;Z(:,11)=z ; %검은 실선 R(:,12)=dr ;Theta(:,12)=theta ;Z(:,12)=dZv ; R(:,13)=dr ;Theta(:,13)=dTv ;Z(:,13)=z ; R(:,14)=dRv ;Theta(:,14)=dtheta ;Z(:,14)=z ; R(:,15)=r ;Theta(:,15)=dTv ;Z(:,15)=z ; R(:,16)=dRv ;Theta(:,16)=theta ;Z(:,16)=z ; R(:,17)=r ;Theta(:,17)=dtheta ;Z(:,17)=dZv ; %초록선 R(:,18)=dRv ;Theta(:,18)=theta ;Z(:,18)=dz ; R(:,19)=dRv ;Theta(:,19)=theta ;Z(:,19)=0 ; %파란선 R(:,20)=r</description>
    </item>
    
    <item>
      <title>매트랩에서 극 좌표계의 미소 면적 그래프 그리는 코드</title>
      <link>https://freshrimpsushi.github.io/posts/1759/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1759/</guid>
      <description>극 좌표에서 미소 면적매트랩에서 위와 같은 그래프를 그리는 코드는 아래와 같다. r=1; dr=0.77; theta=deg2rad(36); dtheta=deg2rad(56); n=50; m=8; pi2=pi/2; R=zeros(n,m); Theta=zeros(n,m); Rv=linspace(0,r,n); dRv=linspace(dr,r,n); Tv=linspace(0,pi2,n); dTv=linspace(theta,dtheta,n); %검은 점선 R(:,1)=dr; Theta(:,1)=Tv; R(:,2)=r; Theta(:,2)=Tv; R(:,3)=Rv; Theta(:,3)=dtheta; R(:,4)=Rv; Theta(:,4)=theta; %검은 실선 R(:,5)=dr; Theta(:,5)=dTv; R(:,6)=dRv; Theta(:,6)=dtheta; %초록선 R(:,7)=dRv; Theta(:,7)=theta; %파란선 R(:,8)=r; Theta(:,8)=dTv; X=zeros(n,m); Y=zeros(n,m); for i=1:n for j=1:m X(i,j)=R(i,j)*cos(Theta(i,j)); Y(i,j)=R(i,j)*sin(Theta(i,j)); end end X1=X(:,1:4); Y1=Y(:,1:4); X2=X(:,5:6); Y2=Y(:,5:6); figure() plot(X1,Y1,&amp;#39;k--&amp;#39;,&amp;#39;Linewidth&amp;#39;,2); %점선 hold on plot(X2,Y2,&amp;#39;k&amp;#39;,&amp;#39;Linewidth&amp;#39;,4); %실선 plot(X(:,7),Y(:,7),&amp;#39;Linewidth&amp;#39;,4,&amp;#39;Color&amp;#39;,&amp;#39;#70AD47&amp;#39;); %초록선 plot(X(:,8),Y(:,8),&amp;#39;Linewidth&amp;#39;,4,&amp;#39;Color&amp;#39;,&amp;#39;#4472C4&amp;#39;); %파란선 axis([0 1.2 0 1.2]);</description>
    </item>
    
    <item>
      <title>매트랩에서 등간격의 행벡터를 생성하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1376/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1376/</guid>
      <description>줄리아에서 벡터를 생성하는 방법linspace(a,b,n) : 구간 $[a,b]$를 $n$개의 등간격으로 나눈 행벡터를 반환한다. 성분개수를 입력하지 않으면 $1\times 100$ 벡터를 반환한다. 간격의 길이가 아닌 간격의 개수가 중요할 때 쓰인다. aⓜ️b : 구간 $[a,b]$를 등간격 $m$으로 나눈 행벡터를 반환한다. 간격을 입력하지 않으면 간</description>
    </item>
    
    <item>
      <title>매트랩에서 이미지 크기 조절하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-resize-a-image-in-a-matlab/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-resize-a-image-in-a-matlab/</guid>
      <description>줄리아에서 이미지 크기 조절하는 방법imresize(A,scale) : A의 크기를 scale배만큼 조정하여 새로운 이미지를 반환한다. A가 10x10이미지일 때 scale에 0.5를 입력하면 5x5 이미지를 반환한다. 아래와 같이 직접 크기를 조절할 수도 있다.imresize(A,[m n]) : m개의 행과 n개의 열을 가진 이미지를 반환</description>
    </item>
    
    <item>
      <title>매트랩에서 작업공간 초기화 모든 변수 제거하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1758/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1758/</guid>
      <description>R에서 작업공간 초기화, 모든 변수 제거하는 방법1. clear 명령어 명령창에 clear를 입력하면 작업 공간이 초기화 된다.2. 작업 공간 지우기(Alt+T+O) 작업 공간 창을 마우스 우클릭하면 &amp;lsquo;작업 공간 지우기(O)&amp;lsquo;를 선택할 수 있다. 누르면 작업 공간이 초기화된다. 이는 단축키 Alt+T+O로도 실행할 수 있으</description>
    </item>
    
    <item>
      <title>매트랩에서 코드 실행 시간 재는 법 벤치마크하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/1467/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1467/</guid>
      <description>R tic X1=rand(2^7); X2=rand(2^8); X3=rand(2^9); X4=rand(2^10); X5=rand(2^11); toc Y1=imrotate(X1,45,&amp;#39;bicubic&amp;#39;,&amp;#39;crop&amp;#39;); toc Y2=imrotate(X2,45,&amp;#39;bicubic&amp;#39;,&amp;#39;crop&amp;#39;); toc Y3=imrotate(X3,45,&amp;#39;bicubic&amp;#39;,&amp;#39;crop&amp;#39;); toc Y4=imrotate(X4,45,&amp;#39;bicubic&amp;#39;,&amp;#39;crop&amp;#39;); toc Y5=imrotate(X5,45,&amp;#39;bicubic&amp;#39;,&amp;#39;crop&amp;#39;); toc tic : 실행 시간을 측정하기 위한 스톱워치를 실행한다.toc : 스톱워치의 현재 시간을 반환한다. toc과 toc사이의 시간을 재는 것이 아님에 주의하자. 위의 예제코드에서 Y1~Y6을 계산하는 시간을 각각 재고싶다면 아래와 같이 코드를 입력해야한다. tic X1=rand(2^7); X2=rand(2^8); X3=rand(2^9); X4=rand(2^10); X5=rand(2^11); toc tic Y1=imrotate(X1,45,&amp;#39;bicubic&amp;#39;,&amp;#39;crop&amp;#39;); toc tic Y2=imrotate(X2,45,&amp;#39;bicubic&amp;#39;,&amp;#39;crop&amp;#39;); toc tic Y3=imrotate(X3,45,&amp;#39;bicubic&amp;#39;,&amp;#39;crop&amp;#39;); toc tic Y4=imrotate(X4,45,&amp;#39;bicubic&amp;#39;,&amp;#39;crop&amp;#39;); toc tic Y5=imrotate(X5,45,&amp;#39;bicubic&amp;#39;,&amp;#39;crop&amp;#39;); toc</description>
    </item>
    
    <item>
      <title>맥리어드-리 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/mcleod-li-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mcleod-li-test/</guid>
      <description>시계열 데이터의 리턴 $\left\{ r_{t} \right\}$ 이 주어져있다고 하자.$H_{0}$ : 데이터는 시차 $k$ 의 아치 이펙트를 가지지 않는다.$H_{1}$ : 데이터는 시차 $k$ 의 아치 이펙트를 가진다.**맥리어드-리 테스트** 는 주어진 리턴을 이용해 데이터에 아치 이펙트가 있는지 확인한다.다행스럽게도 R 에서는 TSA 패키지의 McLeod.Li.test() 함수를 통해 쉽게 테스트를 해볼 수 있다</description>
    </item>
    
    <item>
      <title>맥스웰 방정식으로부터 전자기파빛의 속도 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/207/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/207/</guid>
      <description>진공에서의 맥스웰 방정식 $ \displaystyle (\mathrm{i})\ \nabla \cdot \mathbf{E} = 0 $$ \displaystyle (\mathrm{ii})\ \nabla \cdot \mathbf{B} = 0 $$ \displaystyle (\mathrm{iii})\ \nabla \times \mathbf{E} = -\frac{\partial \mathbf{B}}{\partial t} $$ \displaystyle (\mathrm{iv})\ \nabla \times \mathbf{B} = \mu_0\epsilon_0\frac{\partial \mathbf{E}}{\partial t} $1차원 파동방정식** $ \displaystyle \frac{\partial^2 f}{\partial x^2}=\frac{1}{v^2}\frac{\partial^2 f}{\partial t^2}$**** **3차원 파동방정식** $ \displaystyle \nabla ^2 f = \frac{1}{v^2}\frac{\partial ^2 f}{\partial t^2}$맥스웰 방정식으로부터 $\mathbf{E}$와 $\mathbf{B}$에 관한 파동 방정식 꼴을 이끌어내는 것이 목적이다. $(</description>
    </item>
    
    <item>
      <title>맵 시스템의 오빗</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-of-map-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-of-map-system/</guid>
      <description>맵 $ f : X \to X$ 와 $p \in X$ 에 대해 $f^{k} (p) = p$ 를 만족하는 가장 작은 자연수가 $k \in \mathbb{N}$ 라고 하자.1. 맵 $f : X \to X$ 와 점 $x \in X$ 에 대해 집합 $\left\{ x , f(x) , f^{2} , \cdots \right\} $ 를 $f$ 하에서 $x$ 의 오빗Orbit 이라고 한다. 이 때 $x$ 를 오빗의 초기값Initial Value 이라고 한다.2. 초기값 $p$ 를 가지는 오빗 $\left\{ p , f (p) , f^{2} (p) , \cdots \right\}$ 을 피리어딕-$k$ 오빗 이라 하고,</description>
    </item>
    
    <item>
      <title>머신러닝에서 플루딩이란</title>
      <link>https://freshrimpsushi.github.io/posts/flooding-do-we-need-zero-training-loss-after-achieving-zero-training-error-review/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/flooding-do-we-need-zero-training-loss-after-achieving-zero-training-error-review/</guid>
      <description>플루딩 은 ICML 2020에서 발표된 &amp;lsquo;Do We Need Zero Training Loss After Achieving Zero Training Error?&amp;lsquo;에서 소개한 레귤라이제이션의 한 종류이다. 이 논문의 저자는 오버 피팅이 일어나는 이유가 아래 그림과 같이 지나치게 작은 트레이닝 로스라고 말한다.따라서 아래 그림과 같이 학습 과정에서 트레이닝 로스가 특정한 값 이하로 내려가지 않게 조절하면 테스트 로스를 줄일 수 있</description>
    </item>
    
    <item>
      <title>머신러닝에서의 손실 함수</title>
      <link>https://freshrimpsushi.github.io/posts/loss-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/loss-function/</guid>
      <description>수치해석에서의 손실 함수* 본 포스트는 컴퓨터보다는 통계와 수학에 더 익숙한 사람들을 위해 작성되었다.데이터 $Y = \begin{bmatrix} y_{1} \\ \vdots \\ y_{n} \end{bmatrix}$ 에 대한 추정치가 $\widehat{Y} = \begin{bmatrix} \widehat{ y_{1} } \\ \vdots \\ \widehat{y_{n}} \end{bmatrix}$ 와 같이 주어져 있을 때 데이터와 추정치의 괴리도를 나태는 스칼라 함수 $L : \mathbb{R}^{n} \to [ 0 , \infty ) $ 를 **손실 함수** 라 한다.손실 함수는 학습을 통해 얻은 데이터의 추정치가 실제 데</description>
    </item>
    
    <item>
      <title>멀티 인덱스 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/multiindex-notation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiindex-notation/</guid>
      <description>*멀티 인덱스$(\mathrm{Multiindex})$ 각 성분이 음이 아닌 정수인 순서쌍 $\alpha=(a_1,\ a_2,\ \cdots,\ \alpha_n)$을 오더가 $|\alpha|$인 멀티 인덱스라고 한다. 이때 $|\alpha|=\alpha_1+\cdots+\alpha_n$멀티 인덱스를 사용하여 편미분을 다음과 같이 정의하여 간소하게 표현한 수 있</description>
    </item>
    
    <item>
      <title>멀티레졸루션 아날리시스</title>
      <link>https://freshrimpsushi.github.io/posts/multiresolution-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiresolution-analysis/</guid>
      <description>$L^{2}(\mathbb{R})$공간의 닫힌 부분공간들의 수열 $\left\{V_{j}\right\}_{j \in \mathbb{Z}}$와 함수 $\phi \in V_{0}$가 아래의 조건을 만족하면 $\left( \left\{ V_{j} \right\}, \phi \right)$를 멀티레졸루션 아날리시스라 한다.$(\mathrm{i})$ 각 $V_{j}$에 대해서 $\cdots V_{-1} \subset V_{0} \subset V_{1}\cdots$가 성립한다.$(\m</description>
    </item>
    
    <item>
      <title>멀티레졸루션 아날리시스에서 스케일링 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/scaling-equation-in-multiresolution-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scaling-equation-in-multiresolution-analysis/</guid>
      <description>함수 $\phi \in L^{2}(\mathbb{R})$가 멀티레졸루션 아날리시스를 생성한다고 하자. 그러면 아래의 식을 만족하는 주기가 $1$인 함수 $H_{0}\in L^{2}(0,1)$가 존재한다. $$ \hat{\phi}(2\gamma) = H_{0}(\gamma)\hat{\phi}(\gamma),\quad \gamma \in \mathbb{R} \tag{1} $$ 이때 $\hat{\phi}(\gamma)$는 $\phi$의 푸리에 변환이다.식 $(1)$은 $\mathrm{refinement\ equation}$이라고</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드의 루트 컨디션</title>
      <link>https://freshrimpsushi.github.io/posts/root-conditions-of-multistep-method/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/root-conditions-of-multistep-method/</guid>
      <description>멀티스텝 메소드$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) ) = (Y_{0}, \cdots , Y_{p} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b $ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값과 $0 \le p \le m$ 에 대해 $a_{p} \ne 0$ 혹은 $b_{p} \ne 0 $ 이면 다음을 $(p+1)$</description>
    </item>
    
    <item>
      <title>멜린 변환</title>
      <link>https://freshrimpsushi.github.io/posts/mellin-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mellin-transform/</guid>
      <description>**멜린 변환$(\mathrm{Mellin\ transform})$ 함수 $f$의 멜린 변환을 아래와 같이 정의한다. $$ \mathcal{M}f(x)=\mathcal{M}f(s) = \phi(s) =\int_0^\infty x^{s-1}f(x)dx $$ 이 때 $s \in \mathbb{C}$. 그리고 멜린 역변환$(\mathrm{Mellin\ inverse\ transform})$ 은 다음과 같이 정의한다. $$ \mathcal{M}^{-1}\phi (x) =f(x)=\dfrac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty} x^{-s}\phi(s) ds $$ 정의를 보면 알 수 있듯이 적분 변환의 일종이다. 멜린 역변환은 상수 $c$의 값에 무관하다. 멜린 변환은 컴퓨</description>
    </item>
    
    <item>
      <title>멱급수</title>
      <link>https://freshrimpsushi.github.io/posts/power-series/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/power-series/</guid>
      <description>1. $\displaystyle g(x) \sum_{k=0}^{\infty} a_{k} x^{k} $ 를 **생성함수**Generating Function 라고 한다.**2.** $\displaystyle S(x) : = \sum_{k=0}^{\infty} a_{k} ( x - x_{0} )^{k} $ 를 **멱급수** 라 하고, $x_{0}$ 를 $S(x)$ 의 **중심**Center 이라고 한다.**3.** $S(x)$ 가 $|x - x_{0}| &amp;lt; R$ 에 대해 절대수렴하고 $|x - x_{0}| &amp;gt; R$ 에 대해 발산할 때 $R$ 을 $S(x)$ 의 **수렴반경**Radius of Convergence 이라고 한다.**4.**</description>
    </item>
    
    <item>
      <title>명제함수의 한정규칙</title>
      <link>https://freshrimpsushi.github.io/posts/quantification-rules/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quantification-rules/</guid>
      <description>전체집합 $U$ 의 명제함수 $P(x)$ 가 주어져있다고 하자.1. Universal Quantifier : &amp;lsquo;모든 $x \in U$ 에 대하여&amp;rsquo;를 $\forall x$ 와 같이 쓰고 전칭기호 라고 한다.2. Existential Quantifier : &amp;lsquo;적어도 하나의 $x \in U$ 가 존재해서&amp;rsquo;를 $\exists x$ 와 같이 쓰고 존재기호 라고 한다.가령 자연수 집합 $\mathbb{N}$ 에 대해 논리식 $p(x)$ 가 &amp;lsquo;$x$ 는 $3$ 의 배수다&amp;rsquo;라면, 위</description>
    </item>
    
    <item>
      <title>모든 등거리 사상은 임베딩이 됨을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-isometic-map-is-imbedding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-isometic-map-is-imbedding/</guid>
      <description>두 놈 공간 $X$, $Y$가 있다고 하자. 그리고 $f\ :\ X \rightarrow Y$를 등거리 사상이라고 하자. 그러면 $f$는 임베딩이다. 다시 말해 아래의 두 조건을 만족한다$(a)$ $f(X) \subset Y $$ (b)$ $f\ :\ X \rightarrow f(X)$가 위상동형사상$(\mathrm{homeomorphsim})$이다.$(b)$를 먼저 증명하고 $(a)$를 증명하겠다. 각 증명과정에서</description>
    </item>
    
    <item>
      <title>모든 순환군은 정수군과 동형임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/411/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/411/</guid>
      <description>순환군 $\left&amp;lt; a \right&amp;gt; $ 가 유한군이면 $\left&amp;lt; a \right&amp;gt; \simeq \mathbb{Z}_{n}$ 이고 무한군이면 $\left&amp;lt; a \right&amp;gt; \simeq \mathbb{Z}$ 이다.이 증명으로써 순환군에 대한 연구는 사실상 끝난다.추상적이기만 했던 군이 단숨에 정수론의 영역으로 떨어지기 때문에 할 수 있는 게 상당히 많아진다.반대로 군론의 이론들을 이용해서 정수론의 문제를 풀어내는 것 역시 가능할 것이다. 증명 어떤 $m \in \mathbb{N} $ 에 대해 $a^m = e$ 을 만족하는</description>
    </item>
    
    <item>
      <title>모레라의 정리Moreras Theorem 증명</title>
      <link>https://freshrimpsushi.github.io/posts/214/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/214/</guid>
      <description>함수 $f$가 단순연결영역 $\mathscr{R}$에서 연속이고 $\mathscr{R}$ 내부의 모든 폐경로 $\mathscr{C}$에 대해 $\displaystyle \int_{\mathscr{C}} f(z) dz = 0$을 만족하면 $f$는 $\mathscr{R}$에서 해석적이다.코시 정리의 역 정도로 생각할 수 있겠다.재미있는 점은 원래 &amp;lsquo;미분가능하면 연속, 연속이면 적분가능&amp;rsquo;이</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 독립성</title>
      <link>https://freshrimpsushi.github.io/posts/independency-of-standard-residuals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independency-of-standard-residuals/</guid>
      <description>선형성 보러가기등분산성 보러가기정규성 보러가기표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다.독립성을 확인하려면 잔차 그림에 어떤 뚜렷한 경향이 나타나지 않으면 된다.안타깝게도 독립성의 진단은 다른 회귀분석의 가정에 비해 매우 주관적일 수밖에 없다.독립성이 결여된 예로 가장 자주볼 수 있는 경우는 위와 같이 정체를 알 수 없</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 정규성</title>
      <link>https://freshrimpsushi.github.io/posts/normality-of-standard-residuals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normality-of-standard-residuals/</guid>
      <description>선형성 보러가기독립성 보러가기등분산성 보러가기표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다.정규성은 잔차들의 흩어진 모양보다는 히스토그램으로 확인하거나 정규성 검정을 하는 게 낫다.왼쪽은 가운데에서 위 아래로 갈수록 그 밀도가 작아지는 것에 비해 오른쪽은 위아래 할 것 없이 고르게 퍼져있다.하지만 이렇게 정말 잔차들이</description>
    </item>
    
    <item>
      <title>몰리파이어</title>
      <link>https://freshrimpsushi.github.io/posts/mollifier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mollifier/</guid>
      <description>**** 몰리파이어$(\mathrm{mollifier})$ $\mathrm{(i)}$ ** 함수 $\eta : \mathbb{R^n} \rightarrow [0,\ \infty)$를 다음과 같이 정의하자. $$ \eta (x) := \begin{cases} C \exp \left( \dfrac{1}{|x|^2-1} \right) &amp;amp; |x|&amp;lt;1 \\ 0 &amp;amp; |x| \ge 1\end{cases} $$ 위와 같은 $\eta$를 몰리파이어 라 한다. 특히 $C&amp;gt;0$가 $\int_{\mathbb{R^n}} \eta dx=1$을 만족시키는 상수일 때 $\eta$를 **스탠다드 몰리파이어$(\mathrm</description>
    </item>
    
    <item>
      <title>몰리피케이션이 매끄러움을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-smoothness-of-mollification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-smoothness-of-mollification/</guid>
      <description>**** **몰리피케이션 $(\mathrm{mollification})$ $f \in L^1_{\mathrm{Loc}}( \Omega)$인 함수 $f$와 $\epsilon&amp;gt;0$에 대해서 $f$의 $\epsilon -\mathrm{mollification}$을 다음과 같이 정의한다. $$ f^{\epsilon} := \eta_\epsilon * f=\int_{\mathbb{R^n}} \eta_{\epsilon}(x-y)f(y)dy \quad \mathrm{in}\ \Omega_\epsilon $$ 이때 $f$는 $\Omega$ 밖에서는 $0$로 정의된 함수이다. $\eta_\epsilon$은 **몰리파이어** , *는 ****</description>
    </item>
    
    <item>
      <title>무한 차원 벡터 공간의 샤우더 베이시스</title>
      <link>https://freshrimpsushi.github.io/posts/schauder-basis-of-infinite-dimensional-vector-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schauder-basis-of-infinite-dimensional-vector-space/</guid>
      <description>유한 차원 벡터 공간의 기저 : 하멜 베이시스벡터 공간 $X$ 의 모든 원소 $x \in X$ 에 대해 다음을 만족하는 스칼라의 시퀀스 $\left\{ a_{k} \right\}_{k \in \mathbb{N}}$ 가 유일하게 존재하면 $\left\{ \textbf{e}_{k} \right\}_{k \in \mathbb{N}} \subset X$ 를 $X$ 의 **샤우더 기저** 라고 한다. $$ x = \sum_{k \in \mathbb{N}} a_{k} \textbf{e}_{k} $$ 벡터 공간의 기저는 특히 &amp;lsquo;무한&amp;rsquo; 선형 결합에 대해 논할 때 샤우더 베이시스라고 불리운다.$H$ 가 힐</description>
    </item>
    
    <item>
      <title>무한급수가 수렴하면 무한수열은 0으로 수렴함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/54/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/54/</guid>
      <description>정리 $\displaystyle \sum { n=1 }^{ \infty }{ { a }{ n }}$ 이 수렴하면 $\displaystyle \lim { n\to \infty }{ { a }{ n }}=0 $ 처음 접하면 직관과 달라 조금 당황스러울 수 있는 정리로, 왜 역이 성리하지 않는지 궁금할 수 있다. 그 대표적인 반례로는 다음과 같은 수열을 생각해볼 수 있다. $$ \begin{eqnarray*} { a }_{ n }&amp;amp;=&amp;amp;\frac { 1 }{ n } \\ { b }_{ n }&amp;amp;=&amp;amp;\sqrt { n }-\sqrt { n-1 } \end{eqnarray*} $$ 두 수열 모두 0으로 수렴하지만 그 합은 무한대로 발산한다. 첫번</description>
    </item>
    
    <item>
      <title>문자열의 편집 거리</title>
      <link>https://freshrimpsushi.github.io/posts/edit-distance-of-strings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/edit-distance-of-strings/</guid>
      <description>편집 방법 1문자열에는 다음과 같이 네가지 작용이 있다.1. 삽입 : 문자열에 새로운 문자를 끼워넣는다.2. 제거 : 문자열에서 문자 하나를 없앤다.3. 교체 : 문자열에서 문자 하나를 다른 문자로 바꾼다.4. 전치 : 두 문자의 위치를 서로 바꾼다.편집 거리는 문자열간의 거리 함수로써 편집 방법을 허용하거나 금지함으로써 다음과 같은 타입들로 구분된</description>
    </item>
    
    <item>
      <title>물리 진자</title>
      <link>https://freshrimpsushi.github.io/posts/physical-pendulum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/physical-pendulum/</guid>
      <description>물리 진자 강체가 고정된 수평축을 중심으로 중력에 의해서 흔들릴 때 이를 물리 진자 라고 한다.&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/png&amp;rdquo; filename=&amp;ldquo;그림자료3.png&amp;rdquo; height=&amp;ldquo;409&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/99A13F435F583CBE1E&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;728&amp;rdquo;/&amp;gt;진자 운동은 조화 진동의 한 종류이다. 질량 중심에 작용하는 토크의 크기는 $$ \begin{align} N &amp;amp;=\left| \mathbf{r} \times \mathbf{F} \right|</description>
    </item>
    
    <item>
      <title>물리학에서 구배 물매란</title>
      <link>https://freshrimpsushi.github.io/posts/292/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/292/</guid>
      <description>물리학 교재에서 구배, 물매라는 단어를 본 적이 있을 것이다. 바로 그래디언트$\mathrm {Gradient}$이다.구배, 물매는 $\mathrm {Gradient}$의 옛날식 번역이다. 요즘은 gradient는 기울기로 번역한다. 혹은 경사라고도 하지만 대부분 기울기라고 쓰는 것 같다.그러니 $f$의 구배를 구하라는 문제를 봤다면 당황하</description>
    </item>
    
    <item>
      <title>물리학에서 운동 에너지 퍼텐셜 에너지의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-kinetic-energy-and-potential-energy-in-physics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-kinetic-energy-and-potential-energy-in-physics/</guid>
      <description>** 입자의 운동 에너지 $(\mathrm{kinetic\ energy})$ 힘이 위치에만 의존할 때 즉, 속도나 시간에 대해 독립일 때, 입자의 직선운동의 운동방정식(미분방정식)은 아래와 같다. $$ F(x)=m\ddot x \tag{1} $$ 이 때 가속도 $\ddot{x}$를 아래와 같이 속도에 대해서 표현할 수 있다. $$ \begin{align} \ddot x &amp;amp;= \dfrac{d \dot x}{dt} \\ &amp;amp;=\dfrac{dv}{dt} \\ &amp;amp;=\dfrac{dv}{dx} \dfrac{dx}{dt} \\ &amp;amp;=v\dfrac{dv}{dx} \\ &amp;amp;= \frac{1}{2}\frac{ d (v^{2})}{ dx } \end{align} $$ 이를 $(1)$에 대입하면 $$ F(x)=m\ddot x= m\frac{1}{2}\frac{d(v^{2})}{dx}=\frac{ d }{ dx }\left( \frac{1}{2}mv^{2} \right) $$ 위</description>
    </item>
    
    <item>
      <title>물리학을 위한 스토크스 정리</title>
      <link>https://freshrimpsushi.github.io/posts/stokes-theorem-for-physics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stokes-theorem-for-physics/</guid>
      <description>**스토크스 정리(회전의 기본 정리) $$ \int_{\mathcal{S}} (\nabla \times \mathbf{v} )\cdot d\mathbf{a} = \oint_{\mathcal{P}}v\cdot d\mathbf{l} $$ 어떤 영역 안에서의 벡터 $\mathbf{v}$가 회전하는 양(좌변)은 그 영역의 테두리에서 벡터 $\mathbf{v}$의 값(우변)과 같다.사실 물리학을 공부하는 사람이라면 위 수식의 증명이 크게 중요한 것은 아니다. 그보다 더 중요한 것은 수식이 어떤 의미를 가지고 있느냐</description>
    </item>
    
    <item>
      <title>미드포인트 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/midpoint-method/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/midpoint-method/</guid>
      <description>$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ), y (x_{1}) ) = ( Y_{0} , Y_{1} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 를 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b $ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} = Y_{0}$ 에 대해 $$ y_{n+1} := y_{n-1} + 2 h f ( x_{n} , y_{n} ) $$ 유도 $Y&#39;(t)$ 를 $x_{n}$ 에 대해 테일러 전개하면 $$ \displaystyle Y&#39;(t) = Y&#39;</description>
    </item>
    
    <item>
      <title>미적분학의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-calculus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-calculus/</guid>
      <description>해석학에서의 증명 (1)해석학에서의 증명 (2)함수 $f$ 가 폐구간 $[a,b]$ 에서 연속이라고 하자.(1) 함수 $\displaystyle F(x) = \int_{a}^{x} f(t) dt$ 는 $[a,b]$ 에서 연속, $(a,b)$ 에서 미분가능하며 $\displaystyle {{dF(x)} \over {dx}} = f(x)$ 를 만족한다.**(2)** $f$ 의 임의의 부정적분 $F$ 에 대해 $\displaystyle \int_{a}^{b} f(x) dx = F(b) - F(a) $물론 우리야 미분, 적분이라는 단어를 사용하기 때문에 이들 사이의 관계를 쉽게 짐작할 수 있다.하지</description>
    </item>
    
    <item>
      <title>민코프스키 부등식 Minkowskis Inequality 증명</title>
      <link>https://freshrimpsushi.github.io/posts/288/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/288/</guid>
      <description>실해석학에서의 민코프스키 부등식 보러가기두 벡터 $\mathbb{x} = (x_{1} , x_{2} , \cdots , x_{n} )$ , $\mathbb{y} = (y_{1} , y_{2} , \cdots , y_{n} )$ 와 $1$보다 큰 실수 $p$ 에 대해, $\displaystyle \left( \sum_{k=1}^{n} | x_{k} + y_{k} |^{p} \right)^{{1} \over {p}} \le \left( \sum_{k=1}^{n} |x_{k}|^{p} \right)^{{1} \over {p}} + \left( \sum_{k=1}^{n} |y_{k}|^{p} \right)^{{1} \over {p}}$민코프스키 부등식은 $p$-놈의 정의에서 삼각부등식에 해당한다.어떤 다른 증명방법이 또 있는지는 모르겠지만, 보통 하듯 횔더 부등식을 사용하면</description>
    </item>
    
    <item>
      <title>밑이 e인 지수함수의 라플라스 변환 Laplace Transform of Exponential Function</title>
      <link>https://freshrimpsushi.github.io/posts/750/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/750/</guid>
      <description>$\mathcal {L} \left\{ e^{at} \right\} = \dfrac{1}{s-a}$ $s&amp;gt;a$상수함수의 라플라스 변환 결과와 비교해보자.$\mathcal{L} \left\{ 1 \right\} =\dfrac{1}{s} $$ e^{at}$의 라플라스 변환 결과는 $f(t)=1$일 때 $F(s)$가 $a$만큼 평행이동한 것과 같다.당연할 수 밖에 없는 것이 원래 함수에 $e^{at}$가 곱해지면$\displaystyle \int e^{-st}f(t) dt$가$</description>
    </item>
    
    <item>
      <title>반파대칭함수의 푸리에 계수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-coefficient-of-half-symmetry-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-coefficient-of-half-symmetry-function/</guid>
      <description>주기가 $2L$인 함수 $f$가 반파대칭 이면 $f$의 푸리에 계수 는 아래와 같다.$a_0=0 $$ a_n=\begin{cases} \dfrac{2}{L} {\displaystyle \int_{0}^{L}} f(t) \cos \frac{n \pi t}{L} dt &amp;amp; (n=1,\ 2,\ \cdots ) \\ 0 &amp;amp; (n=0,\ 2,\ \cdots )\end{cases} $$ b_n=\begin{cases} \dfrac{2}{L} {\displaystyle \int_{0}^{L}} f(t) \sin \frac{n \pi t}{L} dt &amp;amp; (n=1,\ 2,\ \cdots ) \\ 0 &amp;amp; (n=0,\ 2,\ \cdots )\end{cases} $$ c_n=\begin{cases} \dfrac{1}{L} {\displaystyle \int_{0}^{L} } f(t)e^{-i\frac{n \pi t}{L} } dt &amp;amp; (n=\pm 1,\ \pm 3,\ \cdots) \\ 0 &amp;amp;( n=\pm 2,\ \pm 4,\ \cdots )\ \end{cases} $$ c_n$은 **복소 푸리에 계수** 증명은 길기만 할 뿐 어려운 구석이 하나도 없</description>
    </item>
    
    <item>
      <title>버거스 방정식에 대한 리만 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-riemann-problem-for-burgers-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-riemann-problem-for-burgers-equation/</guid>
      <description>$\displaystyle \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = \begin{cases} a &amp;amp; ,x&amp;lt;0 \\ b &amp;amp; ,x&amp;gt;0 \end{cases} &amp;amp; , t=0 \end{cases}$리만 문제란 초기값이 주어진 버거스 방정식 중에서도 그 해를 **계단 함수**Step Function 으로 갖는 경우를 말한다.이 때 $a \ne b$ 면 그냥 구한 해의 함숫값이 특정 구간에서 여러개 존재하거나 아예 존재하지 않거나 하게 된다.따라서 등적률을 적용시키거나 **평활화*</description>
    </item>
    
    <item>
      <title>번사이드 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-burnside-formula/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-burnside-formula/</guid>
      <description>유한군 $G$ 에 대해 유한집합 $X$ 가 $G$-집합이라고 하자. $r$ 이 $G$ 하의 $X$ 의 궤도의 갯수라고 하면 $\displaystyle r |G| = \sum_{g \in G} | X_{g} | $번사이드 공식은 군의 작용과 등방부분군에 대한 대표적인 응용으로써 조합론을 비롯한 분야에서 즉시 쓰일 수 있다. 유도 집합 $\left\{ (g,x) \in G \times X | gx = x \right\} $ 의 기수를 $N$ 이라고 하자.그러면 $ X_{g} = \left\{ x \in X , | , gx = x \right\} $ 그리고 $G_{x} =</description>
    </item>
    
    <item>
      <title>범함수</title>
      <link>https://freshrimpsushi.github.io/posts/functional/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/functional/</guid>
      <description>$X$를 벡터공간이라고 하자. 아래와 같은 $X$에서 $\mathbb{C}$로의 사상 $f$를 범함수 라고 한다. $$ f : X \to \mathbb{C} $$ $f$가 선형작용소이면 선형 범함수 라고 한다.한국어로 순화하면 &amp;lsquo;범함수&amp;rsquo;라서 별 느낌이 없지만 영어로 볼땐 Functional이 형용사가 아니라 명사라는 것에 주의해야한다.</description>
    </item>
    
    <item>
      <title>베르누이 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-bernoulli-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-bernoulli-differential-equation/</guid>
      <description>$y^\prime + p(x)y = q(x)y^n$꼴의 비선형 미분방정식을 베르누이 미분방정식이라 한다. (이 때 $n$은 $2$이상의 정수, $n=0,\ 1$ 일 때는 선형 방정식이다.)$u \equiv y^{1-n}$라고 치환하면 미분방정식은 아래의 선형 방정식으로 바뀐다. $$ u^\prime + (1-n)pu=q(1-n) $$ 참고로 베르누이 미분방정식의 베르누이와 널리 알려진 유체역학의 베르누이 방정식의 베르누이는</description>
    </item>
    
    <item>
      <title>베르의 범주 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-baire-category-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-baire-category-theorem/</guid>
      <description>모든 완비거리공간은 베르 공간이다.베르 공간Baire Space 이란 위상공간 $X$ 의 모든 조밀한 열린 집합의 수열 $\left\{ O_{n} \right\}_{n=1}^{\infty}$ 에 대해 $\displaystyle \bigcap_{n=1}^{\infty} O_{n}$ 이 조밀한 공간이다.베르 범주 정리는 어떤 집합의 기수를 알아내거나 함수해석 등에서 보조정리로써 유용하게 쓰인다. 증명 **Claim : ** 모든 열린 집합 $U \subset X$ 에 대해 $\displaystyle U \cap \left( \bigcap_{n=1}^{\infty} O_{n} \right) \ne \emptyset $$ X$ 는 거리공간이므로, 열린 집합은 어떤 $x^{</description>
    </item>
    
    <item>
      <title>베이즈 정리로 보는 몬티홀 딜레마</title>
      <link>https://freshrimpsushi.github.io/posts/697/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/697/</guid>
      <description>*베이즈 정리를 아는 정도라면 몬티홀 게임도 알 것이라 상정하고 몬티홀 게임에 자체는 다른 지면을 빌어 설명하겠다.알다시피 몬티홀 게임은 실제로 경품이 어디있든 관계 없이 선택을 바꾸는 것이 유리하다. 이것을 팩트로써 받아들이냐와 별개로 몬티홀 게임을 직관적으로 이해하지 못했거나 수식적인 표현이 서툰 사람들이 있다.편의상 본인이 플레이어고, 1</description>
    </item>
    
    <item>
      <title>베타 분포</title>
      <link>https://freshrimpsushi.github.io/posts/beta-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/beta-distribution/</guid>
      <description>$\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\text{Beta}(\alpha,\beta)$ 를 베타 분포 라고 한다. $$ f(x) = {{ 1 } \over { B(\alpha,\beta) }} x^{\alpha - 1} (1-x)^{\beta - 1} \qquad , x \in [0,1] $$ * $B$ 는 베타 함수를 나타낸다.[1] 적률 생성 함수 : $$ m(t) = 1 + \sum_{k=1}^{\infty} \left( \prod_{r=0}^{k-1} {{ \alpha + r } \over { \alpha + \beta + r }} {{ t^{k} } \over { k! }} \right) \qquad , t \in \mathbb{R} $$ [2] 평균과 분산 : $X \sim \text{Beta}(\alpha,\beta)$ 면 $$ E(X)={\alpha \over {\alpha + \beta} } \\ \text{Var} (X)={ { \alpha \beta } \over {(\alpha + \beta +</description>
    </item>
    
    <item>
      <title>베타 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-beta-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-beta-distribution/</guid>
      <description>$X \sim \text{Beta}(\alpha,\beta)$ 면 $$ E(X)={\alpha \over {\alpha + \beta} } \\ \text{Var} (X)={ { \alpha \beta } \over {(\alpha + \beta + 1) { ( \alpha + \beta ) }^2 } } $$ Strategy : 베타 분포의 정의와 감마 함수의 기본적인 성질로 직접 연역한다.베타 분포의 정의$\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\text{Beta}(\alpha,\beta)$ 를 베타 분포라고 한다. $$ f(x) = { \Gamma(\alpha + \beta) \over { \Gamma(\alpha) \Gamma(\beta) } } x^{\alpha - 1} (1-x)^{\beta - 1} \qquad , x \in [0,1] $$ 감마 함수의 재귀 공식</description>
    </item>
    
    <item>
      <title>벡터 전위의 다중극 전개와 자기 쌍극자 모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/multipole-expansion-of-vector-potential-and-magnetic-dipole-moment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multipole-expansion-of-vector-potential-and-magnetic-dipole-moment/</guid>
      <description>다중극 전개 가 뭔지 모른다면 링크를 따라가서 먼저 읽고오자.**1. 벡터 전위의 다중극 전개 전하가 한 곳에 모여있을 때 다중극 전개를 통해 멀리 떨어진 곳에서의 전위의 근사식을 얻었다마찬가지로 전류가 모여있을 때 충분히 먼 곳에서의 벡터 전위의 근사식을 얻을 수 있다.선 전류에 대한 벡터 전위는 $$ \mathbf{A}(\mathbf{r})=\dfrac{\mu_0 I}{4\pi}\int \dfrac{1}{\eta}d\mathbf{I}&#39; $$ 아래의 식을 유도하는 방법은 여기 에서 다뤘다.</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 다이버전스</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-in-vector-field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-in-vector-field/</guid>
      <description>**다이버전스의 정의 유클리드 공간에서 정의된 벡터 필드 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 을 $\textbf{f} = (f_{1} , \cdots , f_{n})$ 과 같이 나타내고 축의 방향을 $u_{1} , \cdots , u_{n}$ 이라고 할 때, $\textbf{f}$ 의 **다이버전스** 를 다음과 같이 정의한다. $$ \text{div} \textbf{f} := \nabla \cdot \textbf{f} = \sum_{k=1}^{n} {{ \partial f_{k} } \over { \partial u_{k} }} $$ 벡터 필드의 다이버전스는 다음과 다음과 같이 한 점 $\textbf{v} \in \mathbb{R}^{n}$ 가 주어져 있을 때 그 점에서 벡터들이 모이는지, 퍼지는지</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 볼륨</title>
      <link>https://freshrimpsushi.github.io/posts/volume-in-vector-field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/volume-in-vector-field/</guid>
      <description>**볼륨의 정의 유클리드 공간의 부분공간 $D \subset \mathbb{R}^{n} $ 의 볼륨 $V$ 는 직교좌표 $\textbf{u} = (u_{1}, u_{2}, \cdots , u_{n})$ 으로 나타낼 때 다음과 같이 정의된다. $$ V(D) = \int_{D} du_{1} du_{2} \cdots d u_{n} $$ $\textbf{u} \in \mathbb{R}^{n}$ 가 벡터 함수 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 의해 $\textbf{f} \left( \textbf{u} \right) = \left( f_{1} (\textbf{u}) , \cdots , f_{n} (\textbf{u}) \right) $ 와 같이 변환될 때, $D$ 의 **볼륨** 은 다음과 같다.$$ V(D) = \int_{D} \left| {{ \partial \textbf{f} (\textbf{u}) } \over { \partial \textbf{u} }} \right| d u_{1} d u_{2} \cdots d u_{n} $$ * $\displaystyle \left| {{ \partial \textbf{f} (\textbf{u})</description>
    </item>
    
    <item>
      <title>벡터의 선형독립과 기저 차원</title>
      <link>https://freshrimpsushi.github.io/posts/iinearly-independent-basis-dimension-of-vector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/iinearly-independent-basis-dimension-of-vector/</guid>
      <description>벡터공간 $V$와 벡터 $\mathbb{x_{i}} \in V$에 대해 벡터 방정식 $c_{1} \mathbb{x_{1}} + c_{2} \mathbb{x_{2}} + \cdots + c_{n}\mathbb{x_{n}} = \mathbb{0}$ 이 오직 자명한 해 $c_{1} = c_{2 } = \cdots = c_{n} = 0$ 만을 가질 때, 집합 $\left\{ \mathbb{x_{1}}, \mathbb{x_{2}}, \cdots , \mathbb{x_{n}} \right\}$ 을 **선형독립** 이라고 정의한다.선형대수학에선 서로 다른 벡터가 늘리거나 줄인다고 같은 벡터가 될 수 없을 때 독립이라고 한다. 상당히 깔끔한 정의지만 그만큼 익숙하지 않은 사람에겐 직관적으로</description>
    </item>
    
    <item>
      <title>벡터의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-vector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-vector/</guid>
      <description>벡터의 어려운 정의 수의 나열을 벡터 라고 한다. 보통 교과과정에서 벡터는 &amp;lsquo;크기와 방향을 가진 기하학적 객체&amp;rsquo;로 배우게 된다. 아무래도 물리학에서 가장 먼저 접하게 되는 개념이다보니 다음과 같은 $3$차원 이하의 벡터에 친숙할수밖에 없다. $$ (3,4) = \begin{bmatrix} 3 \\ 4 \end{bmatrix} \\ (x,y,z) = \begin{bmatrix} x \\ y \\ z \end{bmatrix} $$ 그런데 사실 벡터는 그보다 더 많은 좌표</description>
    </item>
    
    <item>
      <title>벡터의 회전의 회전</title>
      <link>https://freshrimpsushi.github.io/posts/the-curl-of-curl-of-vector-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-curl-of-curl-of-vector-function/</guid>
      <description>$\nabla \times (\nabla \times \mathbf{A}) = \nabla (\nabla \cdot \mathbf{A}) - \nabla^2 \mathbf{A}$증명에는 레비-치비타 심볼 $(\mathrm{Levi-Civita\ symbol})$이 사용된다.**증명 $$ \begin{eqnarray*} \nabla \times ( \nabla \times \mathbf{A}) &amp;amp;=&amp;amp; \epsilon_{ijk} e_i \nabla_j (\nabla \times \mathbf{A})_k \\ &amp;amp;=&amp;amp; \epsilon_{ijk} \hat e_i \nabla_j (\epsilon_{klm} \nabla_l A_m) \\ &amp;amp;=&amp;amp; \color{blue}{\epsilon_{ijk}\epsilon_{klm}}\hat e_i \nabla_j \nabla_l A_m \\ &amp;amp;=&amp;amp; \color{blue}{(\delta_{il}\delta_{jm} - \delta_{im} \delta_{jl}) }\hat e_i \nabla _j \nabla _l A_m \\ &amp;amp;=&amp;amp; \hat e_i\nabla_i \nabla_j A_j - \nabla_j \nabla_j \hat e_i A_i \\ &amp;amp;=&amp;amp; \nabla(\nabla \cdot \mathbf{A}) - \nabla \cdot \nabla \mathbf{A} \end{eqnarray*} $$ 파란 부분의 증명은 여기 참고 첫번째 항인 $\nabla(\nabla \cdot \mathbf{</description>
    </item>
    
    <item>
      <title>변분법과 오일러-라그랑주 방정식으로부터 유도되는 해밀턴 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/1168/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1168/</guid>
      <description>해밀턴 방정식을 이끌어내는 방법에는 두 가지가 있다. 하나는 해밀턴-야코비 방정식의 특성 방정식을 구해서 얻는 방법 이고, 다른 하나는 이 글에서 소개할 변분법의 방법으로 얻은 오일러-라그랑주 방정식 으로부터 얻는 방법이다.우선 $\mathbf{x}(\cdot)\in \mathcal{A}$가 작용$(\mathrm{action\ functional})$ $I$의 극점 이라고 하자. 그러면 극점</description>
    </item>
    
    <item>
      <title>변수분리법을 사용하여 원통 좌표계에서 z축에 무관한 라플라스 방정식의 풀이 How to solve Laplace equation with cylindrical symmetry in cylindrical coordinates using separation of variables</title>
      <link>https://freshrimpsushi.github.io/posts/873/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/873/</guid>
      <description>원기둥 좌표계에서 원통 대칭$(\mathrm{ cylindrical\ symmetry})$이 있을 때의 라플라스 방정식의 일반해는$V(s,\phi) = A_0 \ln s +B_0 +\sum \limits _{k=1} ^\infty ( A_k s^k ++ B_k s^{-k} )( C_k\cos k\phi + D_k\sin k\phi)$**0. 전위를 구할 때 경계조건$(\mathrm{boundary\ condition})$이 원통 좌표계로 표현하기 쉬운 경우라면 원통 좌표계에 대한 라플</description>
    </item>
    
    <item>
      <title>변수분리법을 사용한 구좌표계에서의 방위각에 무관한 라플라스 방정식 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-laplace-equation-with-azimuthal-symmetry-in-spherical-coordinates-using-separation-of-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-laplace-equation-with-azimuthal-symmetry-in-spherical-coordinates-using-separation-of-variables/</guid>
      <description>구면 좌표계에서 방위각 대칭$(\mathrm{ azimuthal\ symmetry})$이 있을 때의 라플라스 방정식의 일반해는$V(r,\theta) = \sum \limits_{l=0} ^\infty \left( A_l r^l + \dfrac{B_l}{r^{l+1} } \right) P_l(\cos \theta)$** ** **0. 전위를 구할 때 경계 조건($\mathrm{boundary\ condition}$)이 구면좌표계로 표현하기 쉬운 경우라면 구좌표계에 대한 라플라스 방정식</description>
    </item>
    
    <item>
      <title>병렬회로의 합성저항 쉽게 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/603/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/603/</guid>
      <description>위와 같은 회로의 합성저항을 구한다고 생각해보자. 물론 아래와 같이 병렬회로로 바꾸면 답 자체는 공식을 통해 구할 수 있다. 저항이 $n$ 개 있을 때 병렬의 저항 공식은 $\displaystyle {{1} \over {R}} = {{1} \over {R_{1}}} + {{1} \over {R_{2}}} + \cdots + {{1} \over {R_{n}}}$ 이다. 공식에 저항을 대입해보면 $$ \begin{eqnarray*} {{1} \over {R}} &amp;amp;=&amp;amp; {{1} \over {2}} + {{1} \over {5}} + {{1} \over {5}} \\ &amp;amp;=&amp;amp; {{1} \over {2}} + {{2} \over {5}} \\ &amp;amp;=&amp;amp; {{5} \over {10}} + {{4} \over {10}} \\ &amp;amp;=&amp;amp; {{9} \over {10}} \end{eqnarray*} $$ 이고, 따라서 합성</description>
    </item>
    
    <item>
      <title>복소경로적분의 수축 보조정리</title>
      <link>https://freshrimpsushi.github.io/posts/211/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/211/</guid>
      <description>단순폐경로 $\mathscr{C}$를 포함하는 단순연결영역에서 $f : A \subseteq \mathbb{C} \to \mathbb{C}$가 $\mathscr{C}$ 내부의 점 $\alpha$를 제외한 모든 점에서 해석적이라고 하자. 그러면 $\mathscr{C}$ 내부에서 $\alpha$를 중심으로 하는 원 $\mathscr{C&#39;}$에 대해, $\displaystyle \int_{\mathscr{C}} f(z) dz = \int_{\mathscr{C&#39;}} f(z) dz$말은 긴데 결국 말하자면 폐경로에서 복소적</description>
    </item>
    
    <item>
      <title>복소수에 대해 일반화된 이항 계수</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-binomial-coefficient/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-binomial-coefficient/</guid>
      <description>$\alpha \in \mathbb{C}$ 에 대해 $\displaystyle \binom{\alpha}{k} := \begin{cases} \displaystyle {{ \alpha ( \alpha - 1 ) \cdots ( \alpha - k + 1 ) } \over { k! }} &amp;amp; , k \in \mathbb{N} \\ 1 &amp;amp; ,k=0 \end{cases}$ 를 이항 계수 라고 한다.원래 이항 계수는 $\alpha \in \mathbb{N}$ 일 때만 직관적인 의미를 가지지만, 그 계산 과정만 생각해보면 딱히 자연수일 필요가 없다. 당장 생각할 수 있는 음의 정수는 물론 실수, 심지어는 복소수로 확장 가능하다.$\displaystyle \sum_{j=0}^{k} \binom{\alpha}{k-j} \binom{\beta}{j} =</description>
    </item>
    
    <item>
      <title>복소해석에서의 코시 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cauchys-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cauchys-theorem/</guid>
      <description>군론에서의 코시 정리 보러가기단순폐경로 $\mathscr{C}$와 그 내부에서 $f : A \subseteq \mathbb{C} \to \mathbb{C}$가 해석적이고 $f&#39;$가 연속이라고 하자. 그러면 $\displaystyle \int_{\mathscr{C}} f(z) dz = 0$말하자면 특정 조건을 만족시켰을 때 아예 정적분을 계산할 필요가 없다는 것이다.&amp;lsquo;해석학의 아버지&amp;rsquo;라는 코시지만 그의 이름만 단</description>
    </item>
    
    <item>
      <title>복소해석학에서 특이점Singular Point의 종류</title>
      <link>https://freshrimpsushi.github.io/posts/281/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/281/</guid>
      <description>함수 $f$ 가 $\alpha \in \mathbb{C}$ 에 대해 해석적이지 않되 $\mathcal{N}(\alpha)$ 에서 해석적이면 $\alpha$ 를 $f$ 의 특이점Singular Point 이라고 부른다.사실 아주 변태적인 경우가 아닌 이상은 보통 $f$ 가 정의되지 않는 점이 곧 특이점이 된다.예를 들어, $\displaystyle f(z) = {{z - i} \over {(z^2+1)(z+i)}} $ 이라고 한다면 특이점은 $z= \pm i$ 이 될 것이다.딱히 유한할 필요도 없는데, $\csc z$ 의 경우 $z = n \pi ( n \in \mathbb{Z} )$ 모두가 특이점이</description>
    </item>
    
    <item>
      <title>복소해석학에서의 교차비</title>
      <link>https://freshrimpsushi.github.io/posts/cross-ratio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cross-ratio/</guid>
      <description>확장복소평면상에서 네 개의 서로 다른 점 $ z_{1} , z_{2} , z_{3} , z_{4} \in \overline{ \mathbb{C} } $ 에 대해 $\displaystyle (z_{1} , z_{2} , z_{3} , z_{4} ) = {{( z_{1} - z_{4})( z_{3} - z_{2})} \over {(z_{1} - z_{2}) ( z_{3} - z_{4}) } } $ 를 **교차비**Cross Ratio 라고 정의한다.조금 모양을 바꿔서 $\displaystyle (z_{1} , z_{2} , z_{3} , z ) = {{( z_{3} - z_{2}) } \over {(z_{1} - z_{2})} } \cdot {{ ( z - z_{1}) } \over { ( z - z_{3}) } } $ 라고 해보면$ (z_{1} , z_{2} , z_{3} , z_{1} ) = 0 $$ (z_{1} , z_{2} , z_{3} , z_{2}</description>
    </item>
    
    <item>
      <title>볼록 함수 오목 함수란</title>
      <link>https://freshrimpsushi.github.io/posts/convex-function-concave-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convex-function-concave-function/</guid>
      <description>구간 $I \subset \mathbb{R}$ 의 두 원소 $x_{1} , x_{2}$ 와 함수 $f : I \to \mathbb{R}$ 와 $0 \le t \le 1$ 에 대해,**1.** $f( t x_{1} + (1-t) x_{2}) \le t f(x_{1}) + (1-t) f(x_{2})$ 일 때, $f$ 는 **$I$ 에서의 볼록Convex함수** 로 정의한다.**2.** $f( t x_{1} + (1-t) x_{2}) \ge t f(x_{1}) + (1-t) f(x_{2})$ 일 때, $f$ 는 **$I$ 에서의 오목Concave함수** 로 정의한다.* 볼록이나 오목은 위로 볼록이냐, 아래로 오목이냐 식의 헷갈리는 말</description>
    </item>
    
    <item>
      <title>볼자노-바이어슈트라스 성질와 집적점 컴팩트</title>
      <link>https://freshrimpsushi.github.io/posts/bolzano-weierstrass-property-and-limit-point-compact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bolzano-weierstrass-property-and-limit-point-compact/</guid>
      <description>위상공간 $X$ 의 모든 무한 부분집합의 집적점이 $X$ 에 속하면 $X$ 가 볼자노-바이어슈트라스 성질 을 가진다고 하거나 집적점 컴팩트 라고 한다.[1] 모든 컴팩트 공간은 집적점 컴팩트 공간이다.[2] $X$ 가 거리 공간이면 $X$ 가 컴팩트인 것과 집적점 컴팩트인 것은 서로 동치다.예를 들어 $[a,b]$ 는 집적점 컴팩트지만 $(a,b)$ 는 집적점 컴팩트가 아니다. 또한 $\mathbb{Q}$ 는 $$ P = \left\{ 3</description>
    </item>
    
    <item>
      <title>부분공간위상 상대위상</title>
      <link>https://freshrimpsushi.github.io/posts/subspace-topology-relative-topology/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subspace-topology-relative-topology/</guid>
      <description>부분공간$(\mathrm{subspace})$, 부분공간위상$(\mathrm{subspace\ topology})$ 위상공간 $(X,\mathscr{T})$와 부분집합 $A \subset X$가 주어졌다고 하자. 그러면 아래의 집합 $$ \mathscr{T}_A =\left\{ A\cap U\ :\ U\in \mathscr{T} \right\} $$ 는 $A$상의 위상이다. 이때 $\mathscr{T}_A$를 부분공간위상** 혹은 **</description>
    </item>
    
    <item>
      <title>부분적분법</title>
      <link>https://freshrimpsushi.github.io/posts/integration-by-parts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integration-by-parts/</guid>
      <description>$F$, $G$가 구간 $[a,b]$에서 미분가능하고, $F&#39;=f$, $G&#39;=g$가 적분가능하다고 하자. 그러면 다음의 식이 성립한다. $$ \int _{a} ^{b} F(x)g(x)dx= F(b)G(b)-F(a)G(a)-\int _{a} ^{b}f(x)G(x)dx $$ 증명 미분가능하면 연속이고 연속이면 적분가능하므로 $F$, $G$도 적분 가능하다. 이제 $H(x)=F(x)G(x)$라고 하자. 그러면 $H&#39;(x)=F(x)g(x)+f(x)G(x)$이고</description>
    </item>
    
    <item>
      <title>부분환의 정의와 부분환 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-subring-and-subring-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-subring-and-subring-test/</guid>
      <description>**부분환 환 $R$의 부분 집합 $S$가 환 $R$의 연산에 대해서 환의 조건을 만족할 때, $S$를 $R$의 부분환$\mathrm{Subring}$이라고 한다.$\left\{ 0 \right\}$과 $R$은 환 $R$의 부분환임이 자명하다.따라서 $\left\{ 0 \right\}$과 $R$ 자명한 부분환($\mathrm{trivia</description>
    </item>
    
    <item>
      <title>부호 측도의 절대 연속</title>
      <link>https://freshrimpsushi.github.io/posts/absolutely-continuous-of-signed-measure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/absolutely-continuous-of-signed-measure/</guid>
      <description>부호측도에 대한 절대 연속의 정의는 아래와 같다.가측공간 $(X, \mathcal{E})$ 위의 부호 측도 $\nu$와 양측도 $\mu$가 주어졌다고 하자. 모든 $E \in \mathcal{E}$에 대해서 $$ \mu (E) = 0 \implies \nu (E) = 0 $$ 이면 $\nu$ 가 $\mu$ 에 대해 절대 연속 이라 하고 $\nu \ll \mu$ 와 같이 나타낸다.이는 측도에 대한 절대 연속의 일반화다. 측도의 절대연속에서와 마찬가지로 아래의 동</description>
    </item>
    
    <item>
      <title>분광학이란</title>
      <link>https://freshrimpsushi.github.io/posts/spectrosophy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spectrosophy/</guid>
      <description>위 사진과 같이 빛을 여러 색으로 분해한 것을 스펙트럼Spectrum , 한국말로 분광 이라 한다. 분광학Spectroscopy 이란 광학의 일종으로 파장에 따라 분해된 가시광선을 관찰하고 연구하는 학문이다. 다만 최근에는 그 의미가 확대되어 파장이나 주파수에 따른 어떤 물리량을 측정하고 연구하는 것을 말하게 되었다. 스펙트럼의 의미도 확장되</description>
    </item>
    
    <item>
      <title>분수 함수의 역함수와 이차정사각 행렬의 역행렬의 모양</title>
      <link>https://freshrimpsushi.github.io/posts/53/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/53/</guid>
      <description>분수함수 $\displaystyle f(x)=\frac { ax+b }{ cx+d }$의 역함수는 $\displaystyle f^{ -1 }(x)=\frac { dx-b }{ -cx+a }$ 2차 정사각행렬 $\pmatrix { { a }&amp;amp;{ b } \\ { c }&amp;amp;{ d } }$의 역행렬은 $\displaystyle \frac { 1 }{ ad-bc } \pmatrix { { d }&amp;amp;{ -b } \\ { -c }&amp;amp;{ a } } $단순한 우연의 일치일지도 모르겠지만, 이런 우연을 찾는 것 또한 수학의 즐거움이다.행렬이 교과 과정에서 없어졌다고는 하지만 얼마든지 유용하게 쓸 수 있는 사실이다.증명 $\displaystyle y=\frac</description>
    </item>
    
    <item>
      <title>분할 리만 합 리만 적분</title>
      <link>https://freshrimpsushi.github.io/posts/partition-riemann-sum-and-riemann-integral/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-riemann-sum-and-riemann-integral/</guid>
      <description>**분할$(\mathrm{partition})$ 구간 $[a,b]$가 주어져있다고 하자. $[a,b]$의 분할 $P$를 아래와 같이 정의한다. $$ P := \left\{ x_0,\ x_1,\ \cdots, x_n\right\},\quad a=x_0 &amp;lt;x_1&amp;lt;\cdots &amp;lt; x_n =b $$ 그리고 $\Delta x_i$를 다음과 같이 정의한다. $$ \Delta x_i :=x_i-x_{i-1},\quad i=1,2,\cdots,n $$ 쉽게 말해서 분할이란 어떤 구간을 쪼갰을 때 구간의 양 끝과 구간 내 경계의 모든 점을 원소로 가지는 집합</description>
    </item>
    
    <item>
      <title>불리언 링</title>
      <link>https://freshrimpsushi.github.io/posts/boolean-ring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/boolean-ring/</guid>
      <description>선형대수학에서의 사영 보러가기$R$ 을 환이라고 하자.1. $r \in R$ 이 $r^2 = r$ 을 만족하면 $r$ 을 멱등원Idempotent Element 이라고 한다.2. $R$ 의 모든 원소가 멱원소면 $R$ 을 불리언 링Boolean Ring 이라고 한다.*불리언 링을 순화하면 &amp;lsquo;불환&amp;rsquo;이지만 어감이 매우 좋지 못해 영어 발음을 그대로 썼다.선형대수학에서</description>
    </item>
    
    <item>
      <title>비교 정렬 알고리즘 시간 복잡도의 하한 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1359/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1359/</guid>
      <description>비교 정렬 알고리즘의 시간복잡도는 아무리 좋아도 $\Omega ( n \log n )$알고리즘이 원래 신기한 것이지만, 삽입 정렬과 같은 효율적인 알고리즘도 퀵 정렬에 밀리는 것을 보면 그 이상의 알고리즘도 있지 않을까 궁금할 수밖에 없다. 다행인지 아닌지는 모르겠으나, 이 증명에 따라 그보다 효율적인 알고리즘을 생각할 필요는 없다.물론 일반적인 비교 알고리즘이 아니라</description>
    </item>
    
    <item>
      <title>비교 정렬 알고리즘들의 시간 복잡도</title>
      <link>https://freshrimpsushi.github.io/posts/1357/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1357/</guid>
      <description>$n$ 개의 데이터가 주어져 있을 때, 비교 정렬 알고리즘들의 시간 복잡도는 다음과 같다.[1] 버블 정렬 :$$ \Theta ( n^2 ) \\ O ( n^2 ) $$ [2] 선택 정렬 :$$ \Theta ( n^2 ) \\ O ( n^2 ) $$ [3] 삽입 정렬 :$$ \Theta ( n^2 ) \\ O ( n^2 ) $$ [4] 힙 정렬 :$$ \Theta ( n \log n ) \\ O ( n \log n ) $$ [5] 합병 정렬 :$$ \Theta ( n \log n ) \\ O ( n \log n ) $$ [6] 퀵 정렬 :$$ \Theta ( n \log n ) \\ O ( n^2 ) $$ 여기서 소개되는 알</description>
    </item>
    
    <item>
      <title>비균일 진행파 편미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-nonuniform-traveling-wave-partial-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-nonuniform-traveling-wave-partial-differential-equation/</guid>
      <description>$\displaystyle \begin{cases} u_{t} + c(x) u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases}$**비균일 진행파**nNonuiform Traveling Wave 는 시간이 흐름에 따라 속도가 변하는 파동이다.위 그림의 경우 갈수록 속도가 줄어들어서 한 점에서만 우뚝 서버리는 파형이 되어간다.여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때 $x$ 에서의 파형을 나타낸다.$f$ 는 초기 조건으로</description>
    </item>
    
    <item>
      <title>비선형 1계 편미분 방정식의 특성 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/characteristic-equations-of-nonlinear-first-order-pde/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/characteristic-equations-of-nonlinear-first-order-pde/</guid>
      <description>$u\in C^2(\Omega)$가 아래의 비선형 1계 편미분 방정식 의 해라고 하자. $$ F(Du,\ u,\ x)=0 \quad \cdots (1) $$ 그리고 $\mathbf{p}(s)=Du(\mathbf{x}(s))$, $z(s)=u(\mathbf{x}(s))\ s\in I$일 때 $\mathbf{x}(s)\in C^1(I;\Omega)$가 다음의 방정식 $(10)(c)$를 푼다고 가정하자. $$ \dot{\mathbf{x}}(s) = D_pF\big(\mathbf{p}(s),\ z(s),\ \mathbf{x}(s) \big) $$ 그러면 $\mathbf{p}(s)$와 $z(s)$는 각각 $(10)(a)$와 $(10)(b)$를 푸</description>
    </item>
    
    <item>
      <title>비선형 1계 편미분 방정식의 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/notation-of-nonlinear-first-order-pde/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/notation-of-nonlinear-first-order-pde/</guid>
      <description>비선형 1계 편미분 방정식은 다음과 같은 형식으로 쓸 수 있다. $$ F(Du,\ u,\ x) = 0 \quad \cdots (1) $$ 이때 $x\in \Omega$, $\Omega \subset \mathbb{R}^n$은 열린집합이다. 여기서 $F\ :\ \mathbb{R}^n \times \mathbb{R}^n \times \bar{ \Omega } \rightarrow \mathbb{R}$가 주어진 함수이고 $u\ :\ \bar{ \Omega } \rightarrow \mathbb{R}$이 변수이다. 주어진 함수에 대해서 $F=0$을 만족하는 변수 $u$를 찾는 것이 바로 비</description>
    </item>
    
    <item>
      <title>비점성 버거스 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-inviscid-burgers-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-inviscid-burgers-equation/</guid>
      <description>$\displaystyle \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases}$주어진 방정식은 **버거스 방정식**Burgers&#39; Equation $\displaystyle u_{t} + u u_{x} = \nu u_{xx}$ 에서 확산 계수 $\nu$ 가 $0$ 인 경우를 나타낸다.여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때 $x$ 에서의 파형이자 파동의 진행 속도를 나타낸다.$f$ 는 초기 조건으로써 특히 $t=0$ 일 때의 파형을 나타낸다.만약</description>
    </item>
    
    <item>
      <title>사다리꼴 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/trapezoidal-method/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trapezoidal-method/</guid>
      <description>$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b $ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} = Y_{0}$ 에 대해 $$ \displaystyle y_{n+1} = y_{n-1} + {{h} \over {2}} [ f ( x_{n} , y_{n} ) + f ( x_{n+1} , y_{n+1} ) ] $$ 오일러 메소드보다 데이터를 많이 쓴 미드</description>
    </item>
    
    <item>
      <title>사인파와 복소 파동함수</title>
      <link>https://freshrimpsushi.github.io/posts/sinusoidal-wave-and-complex-wave-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sinusoidal-wave-and-complex-wave-function/</guid>
      <description>** **1. 사인파$(\mathrm{sinusoidal\ wave})$ 1차원 파동방정식 을 살펴보면 파동함수 $f(x,t)$는 $x-vt$만의 함수로 나타난다는 것을 알 수 있다. 이때 파동 함수를 일반적으로 삼각함수꼴로 나타낸다. 주기함수(파동함수)를 삼각함수의 선형결합으로 나타내는 푸리에 급수 를 이용하기 때문이다. 무슨 말인지 모르겠으면</description>
    </item>
    
    <item>
      <title>산술 함수의 미분</title>
      <link>https://freshrimpsushi.github.io/posts/derivative-of-arithmetical-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivative-of-arithmetical-function/</guid>
      <description>산술 함수 $f$ 의 미분 혹은 도함수 $f&#39;$ 를 다음과 같이 정의한다. $$ f&#39;(n) := f(n) \log n \qquad , n \in \mathbb{N} $$ [1] 합의 미분법 : $(f+g)&#39; = f&#39;+g&#39;$[2] 곱의 미분법 : $(f*g)&#39; = f&#39;g + fg&#39;$[3] 몫의 미분법 : $f(1) \ne 0$ 이면 $\left( f^{-1} \right)&#39; = - f&#39; * (f * f)^{-1}$산술 함수는 개념적으로는 그냥 수열에 지나지 않기 때문에 흔히 변화율로 설명되곤 하는 미분을 정의할 수 없다. 하지만 단지 원래 함수에 로그를 곱함으로써</description>
    </item>
    
    <item>
      <title>산술 함수의 승법적 성질</title>
      <link>https://freshrimpsushi.github.io/posts/multiplicativity-of-arithmetical-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplicativity-of-arithmetical-function/</guid>
      <description>1. $\forall n \in \mathbb{N}$ 에 대해 $f(n) = 0$ 은 아닌 산술 함수 $f$ 가 다음을 만족시키면 승법적 함수 라고 한다. $$ f(mn) = f(m) f(n) \qquad,\gcd(m,n)=1 $$ 2. 승법적 함수가 다음 조건을 만족시키면 완전 승법적 함수 라고 한다. $$ f(mn) = f(m) f(n) \qquad,m,n \in \mathbb{N} $$ [1] $f$ 가 승법적이면 $f(1) = 1$ 이다.[2] $f$ 가 승법적 함수인 것과 모든 소수 $p_{1} , \cdots , p_{r}$ 와 모든 $a_{1} , \cdots, a_{r} \in \mathbb{N}$ 에 대해 $f \left( p_{1}^{a_{1}} \cdots p_{r}^{a_{r}} \right) = f \left( p_{1}^{a_{1}} \right) \cdots f \left( p_{r}^{a_{r}} \right)$ 은 동치</description>
    </item>
    
    <item>
      <title>산술의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-arithmetic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-arithmetic/</guid>
      <description>산술의 기본정리의 대수적 증명자연수 $n &amp;gt;2$ 은 유일한 소인수분해 $n = p_{1} p_{2} \cdots p_{r}$ 를 가진다.이때 소수 $p_{1} , p_{2} , \cdots , p_{r}$ 의 순서는 무시한다.초등학교부터 자연스럽게 써오던 성질이니만큼 증명이 필요하다는 사실이 낯설겠지만 굉장히 중요하다.어쩌면 이렇게나 쉽다는 것 자체가 기본정리라는 이름을 달만한 자격이 있다는 반증이 될 것이다. 증명 $2=2$ 이고 $3= 3$ ,</description>
    </item>
    
    <item>
      <title>삼각함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-trigonometric-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-trigonometric-function/</guid>
      <description>사인과 코사인의 라플라스 변환은 다음과 같다. $$ \mathcal{L} \left\{ \sin (at) \right\} = \dfrac{a}{s^2+a^2},\quad s&amp;gt;0 $$ $$ \mathcal{L} \left\{ \cos (at) \right\} = \dfrac{s}{s^2+a^2},\quad s&amp;gt;0 $$ 라플라스 변환표는 여기를 참고 증명 $\sin (at)$ $$ \begin{align*} \mathcal{L} \left\{ \sin (at) \right\}&amp;amp; =\displaystyle \int_0^\infty e^{-st}\sin(at)dt \\ &amp;amp;= \lim \limits_{A \to \infty} \left[-\dfrac{1}{a}e^{-st}\cos (at) \right]_0^A+ \lim \limits_{A \to \infty} \int _0^\infty -\dfrac{s}{a}e^{-st} \cos (at)dt \\ &amp;amp;= \dfrac{1}{a} - \lim \limits_{A \to \infty} \dfrac{s}{a} \left[ \dfrac{1}{a} \left[ e^{-st}\sin (at) \right]_0^A + \dfrac{s}{a}\int _0^A e^{-st} \sin (at) dt \right] \\ &amp;amp;=\dfrac{1}{a} - \dfrac{s^2}{a^2} \int_0^\infty e^{-st} \sin (at) dt \end{align*} $$ $$ \begin{align*} \Rightarrow&amp;amp; &amp;amp;\dfrac{a^2+s^2}{a^2} \int _0^\infty e^{-st} \sin (at) dt &amp;amp;= \dfrac{1}{a} \\ \Rightarrow&amp;amp; &amp;amp;\int_0^\infty e^{-st} \sin (at)dt &amp;amp;=\dfrac{a}{s^2+a^2} \end{align*} $$ 단, $\lim \limits_{A \to \infty} e^{-sA}\sin (aA</description>
    </item>
    
    <item>
      <title>삼각함수의 정의를 이용한 제2코사인 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-second-law-of-cosines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-second-law-of-cosines/</guid>
      <description>제2코사인법칙 $$ a^2=b^2+c^2-2bc\cos\alpha $$ $$ b^2=a^2+c^2-2ac\cos\beta $$ $$ c^2=a^2+b^2-2ab\cos\gamma $$ 증명** 그림에서 보는 바와 같이 $$ \begin{eqnarray*} a &amp;amp;=&amp;amp; \overline{BH_{a}}+\overline{H_{a}C} \\ &amp;amp;=&amp;amp; c\cos\beta + b\cos\gamma \end{eqnarray*} $$ 양변에 $a$를 곱하면 $$ a^2=ac\cos\beta + ab\cos \gamma $$ $b$와 $c$에 대해서도 마찬가지로 $$ \begin{align*} &amp;amp;&amp;amp;b &amp;amp;= \overline{AH_{b}}+\overline{H_{b}C} \\ &amp;amp;&amp;amp; &amp;amp;= c\cos\alpha + a\cos\gamma \\ \\ \Rightarrow &amp;amp;&amp;amp; b^2&amp;amp;=bc\cos\alpha + ab\cos\gamma \end{align*} $$ $$ \begin{align*} &amp;amp;&amp;amp;c &amp;amp;= \overline{AH_{c}}+\overline{H_{c}B} \\ &amp;amp;&amp;amp; &amp;amp;= b\cos\alpha + a\cos\beta \\ \\ \Rightarrow &amp;amp;&amp;amp;c^2&amp;amp;=bc\cos\alpha + ac\cos\beta \end{align*} $$ 따라서 $$ \begin{eqnarray*} b^2+c^2 &amp;amp;=&amp;amp; (bc\cos\alpha + ab\cos\gamma) + (bc\cos\alpha + ac\cos\beta) \\ &amp;amp;=&amp;amp; (ab\cos\gamma+ ac\cos\beta)+2bc\cos\alpha \\ &amp;amp;=&amp;amp; a^2+2bc\cos\alpha \end{eqnarray*} $$ $a^2$에 대해서 정리하면</description>
    </item>
    
    <item>
      <title>삼각함수의 집합이 직교성을 가짐을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-set-of-trigonometric-functions-has-orthogonality/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-set-of-trigonometric-functions-has-orthogonality/</guid>
      <description>주기가 $2L$인 함수들의 집합$ \left\{ 1,\ \cos \dfrac{\pi x}{L},\ \cos \dfrac{2\pi x}{L}, \cdots ,\ \sin\dfrac{\pi x}{L},\ \sin\dfrac{2\pi x}{L},\ \cdots \right\}$은 구간 $[-L,\ L)$에서 직교집합이다. $(m,n=1,\ 2,\ 3,\ \cdots ) $$ $ \begin{align*} \dfrac{1}{L} \int _{-L}^{L} \cos\dfrac{m\pi x}{L} \cos\dfrac{n\pi x}{L} dx &amp;amp;= \delta_{mn} \\ \dfrac{1}{L} \int _{-L}^{L} \sin \dfrac{m\pi x}{L}\sin \dfrac{n\pi x}{L} dx &amp;amp;= \delta_{mn} \\ \dfrac{1}{L} \int_{-L}^{L} \cos \dfrac{n\pi}{L}x dx&amp;amp;=0 \\ \dfrac{1}{L} \int_{-L}^{L} \sin \dfrac{n\pi}{L}x dx&amp;amp;=0 \end{align*} $$ 이때 $\delta$는 크로네커 델타이다.$f(t)=f(t+T)$를 만족하는 함수 $f$를 주기함수라 한다</description>
    </item>
    
    <item>
      <title>삼차원 유클리드 공간에서 외적이란</title>
      <link>https://freshrimpsushi.github.io/posts/outer-product-in-three-dimension/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/outer-product-in-three-dimension/</guid>
      <description>$\mathbb{x}, \mathbb{y} \in \mathbb{R}^3$ 에 대해 다음을 $\mathbb{x}$와 $\mathbb{y} $의 외적 으로 정의한다. $$ \begin{eqnarray*} \mathbb{x} \times \mathbb{y} &amp;amp;=&amp;amp; (x_{2}y_{3} - x_{3}y_{2}, x_{3}y_{1} - x_{1}y_{3}, x_{1}y_{2} - x_{2}y_{1}) \\ &amp;amp;=&amp;amp; \det \begin{bmatrix} \mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} \\ x_{1} &amp;amp; x_{2} &amp;amp; x_{3} \\ y_{1} &amp;amp; y_{2} &amp;amp; y_{3} \end{bmatrix} \\ &amp;amp;=&amp;amp; \begin{bmatrix} 0 &amp;amp; -x_{3} &amp;amp; x_{2} \\ x_{3} &amp;amp; 0 &amp;amp; -x_{1} \\ -x_{2} &amp;amp; x_{1} &amp;amp; 0 \end{bmatrix} \begin{bmatrix} y_{1} \\ y_{2} \\ y_{3} \end{bmatrix} \end{eqnarray*} $$ 참고로 $\mathbf{i} = (1,0,0)$ , $ \mathbf{j} = (0,1,0)$ , $ \mathbf{k} = (0,0,1)$ 이다.내적과 마찬가지로 외적 역시 더욱 일반적인 정의는 가능하지만 실용적</description>
    </item>
    
    <item>
      <title>상관관계가 없다고 독립인 것은 아니다</title>
      <link>https://freshrimpsushi.github.io/posts/536/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/536/</guid>
      <description>독립이면 상관관계가 없지만, 상관관계가 없다고 독립인 것은 아니다.상관관계가 없을 때 독립인 경우, 즉 필요충분조건이 되는 경우는 확률변수가 정규분포를 따를 때다.왼쪽의 경우에 양의 상관관계, 오른쪽의 경우에 음의 상관관계가 있다고 한다. 그림의 cor는 상관계수로써, 두 변수가 얼마나 선형적인 관계를 가지는지를 나타내는 지표다. 독립일 경</description>
    </item>
    
    <item>
      <title>상수함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-constant-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-constant-function/</guid>
      <description>$$ \mathcal{L} \left\{ 1 \right\} = \dfrac{1}{s},\quad s&amp;gt;0 $$ 라플라스 변환 표 유도 $$ \begin{eqnarray*} \mathcal{L}\left\{ 1 \right\} &amp;amp;=&amp;amp; \int _0^\infty e^{-st} \cdot 1 dt \\ &amp;amp;=&amp;amp;\lim \limits_{A \to \infty} \left[ -\dfrac{e^{-st}}{s} \right]_0^A \\ &amp;amp;=&amp;amp; \lim \limits_{A \to \infty} \left[ -\dfrac{e^{-sA}}{s} +\dfrac{e^{-0t}}{s} \right] \\ &amp;amp;=&amp;amp; \dfrac{1}{s} \end{eqnarray*} $$ ■ 여기서 $\lim \limits_{A \to \infty}\dfrac{e^{-sA}}{s}=0$ 이어야 하기 때문에1 $s&amp;gt;0$이라는 조건이 추가된다.각주 셋째줄 첫째항이 발산하는 것을 막기 위한 조건. &amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>상적분은 하적분보다 크거나 같다</title>
      <link>https://freshrimpsushi.github.io/posts/831/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/831/</guid>
      <description>정리 임의의 분할에 대하여 리만-스틸체스 상합은 리만-스틸체스 하합보다 반드시 크거나 같다. $$ \underline { \int _a ^b} f d\alpha \le \overline {\int _a^b} f d\alpha $$ 리만 적분은 리만-스틸체스 적분에서 $\alpha (x)=x$인 경우이므로 리만 적분에 대해서도 당연히 성립한다. 보조정리 $P^{ * }$를 $P$의 세분이라고 하자. 그러면 아래의 두 식이 성립한다. $$ \leqalignno{ L(P,f,\alpha) &amp;amp;\le L(P^{ * },f,\alpha) &amp;amp; (a) \\ U(P^{ * },f,\alpha)</description>
    </item>
    
    <item>
      <title>상호 인턱덕스</title>
      <link>https://freshrimpsushi.github.io/posts/mutual-inductance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mutual-inductance/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;슬라이드38.JPG&amp;rdquo; height=&amp;ldquo;409&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/998611405CABDF4928&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;728&amp;rdquo;/&amp;gt;위 그림처럼 고정된 두 도선 고리가 있다고 하자. 고리 1에 정상전류 $I_1$을 흐르게 하면 자기장 $\mathbf{B}_1$이 생긴다.(앙페르 법칙 ) $\mathbf{B}_1$의</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 염기서열</title>
      <link>https://freshrimpsushi.github.io/posts/nucleic-sequence-in-bioinformatics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/nucleic-sequence-in-bioinformatics/</guid>
      <description>&amp;lt;p&amp;lt; b=&amp;quot;&amp;quot;&amp;gt; * 실제 화학, 생물학적인 의미에 대해서는 깊게 다루지 않고 생명정보공학에 필요할 내용만을 간추린 포스트입니다. 생명공학에 대해서는 잘 모르니 많은 지적 부탁드립니다. 마찬가지의 이유로 질문에는 대답해드리기 어렵습니다.**빌드업 1. 화학적 합성에 의해 단위체가 반복되어 연결된 고분자를 중합체Polymer 라고 한다.2. 인산Pho</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 주요 염기와 염기쌍</title>
      <link>https://freshrimpsushi.github.io/posts/1832/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1832/</guid>
      <description>&amp;lt;p&amp;lt; b=&amp;quot;&amp;quot;&amp;gt; * 실제 화학, 생물학적인 의미에 대해서는 깊게 다루지 않고 생명정보공학에 필요할 내용만을 간추린 포스트입니다. 생명공학에 대해서는 잘 모르니 많은 지적 부탁드립니다. 마찬가지의 이유로 질문에는 대답해드리기 어렵습니다.다음의 다섯가지 염기를 주요 염기 라고 한다.1. 퓨린 염기 : 아데닌Adenin $A$, 구아닌Guanine $G$2. 피리미딘</description>
    </item>
    
    <item>
      <title>샤르코우스키 정리</title>
      <link>https://freshrimpsushi.github.io/posts/sharkovskiis-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sharkovskiis-theorem/</guid>
      <description>$$ 3 \prec 5 \prec 7 \prec 9 \prec \cdots \prec \\ 2\cdot 3 \prec 2 \cdot 5 \prec \cdots \prec \\ 2^2 3 \prec 2^2 5 \prec \cdots \prec \\ 2^3 3 \prec 2^3 5^2 \prec \cdots \prec \\ 2^3 \prec 2^2 \prec 2^1 \prec 2^0 $$ 추이적 관계 $\prec$ 에 대해 위와 같은 순서를 샤르코우스키 오더링 이라고 한다. 연속 맵 $f : \mathbb{R} \to \mathbb{R}$ 이 피리어딕-$p$ 오빗을 갖는다고 하자. $p \prec q$ 면 $f$ 는 피리어딕-$q$ 오빗을 갖는다.샤르코우스키 정리는 리-요크 정리를 일반화한 정리로</description>
    </item>
    
    <item>
      <title>서로 수직한 삼각함수들의 합</title>
      <link>https://freshrimpsushi.github.io/posts/930/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/930/</guid>
      <description>$C_n$, $S_n$을 아래와 같이 정의하자. $$ C_n:=1+\cos x + \cos 2x + \cdots +\cos nx $$ $$ S_n:=\sin x +\sin 2x + \cdots + \sin nx $$ 그러면 아래의 식이 성립한다. $$ C_n=\dfrac{\sin \dfrac{n+1}{2}x}{\sin \dfrac{1}{2}x} \cos \dfrac{n}{2}x $$ $$ S_n=\dfrac{\sin \dfrac{n+1}{2}x}{\sin \dfrac{1}{2}x}\sin \dfrac{n}{2}x $$ 삼각함수의 지수표현 $$ \cos x = \dfrac{ e^{ix}+e^{-ix}}{2} $$ $$ \sin x = \dfrac{e^{ix}-e^{-ix}}{2} $$ 오일러 공식을 사용하면 쉽게 보일 수 있다. 증명 오일러 공식 을 사용한다.$C_n+ i S_n $$ =(1+\cos x + \cos 2x + \cdots + \cos nx) + i(\sin x + \sin 2x + \cdots + \sin nx) $$ =1+(\cos x</description>
    </item>
    
    <item>
      <title>서열정렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-sequence-alignment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-sequence-alignment/</guid>
      <description>염기서열 간의 유사도를 근거로 나열하는 것을 서열정렬 이라 한다.1생명정보공학에서 유전체의 길이는 무척 길기 때문에 이를 데이터화하는 것부터가 엄청난 일이다. 상상하기에는 우리도 중합효소처럼 DNA의 상류부터 하류까지 순서대로 읽으면서 저장하면 좋을 것 같지만, 현실적으로는 그렇게 할 수가 없기 때문에 조각으로 나눠진 짧은 염기서열인 리드(</description>
    </item>
    
    <item>
      <title>선팽창계수와 부피팽창계수</title>
      <link>https://freshrimpsushi.github.io/posts/504/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/504/</guid>
      <description>**** 선팽창계수 고체가 열을 받아 팽창할 때 고체의 단위길이당 길이의 변화를 말한다. 예를 들어 길이가 $L$인 고체에 열을 가하고 난 뒤 길이가 $L+\Delta L$로 변했다면 해당 고체의 선팽창계수 $\alpha$를 구하는 과정은 다음과 같다. $$ \Delta L \propto L \Delta T $$ $$ \Delta L = \alpha L \Delta T $$ $$ \therefore \alpha=\dfrac{\Delta L}{L} \dfrac{1}{\Delta T} \left[ ^\circ \mathrm{C} ^{-1} \right] $$ 부피팽창계수 고체가 열을 받아 팽창할 때 고체의 단위 부</description>
    </item>
    
    <item>
      <title>선형 결합과 생성 기저</title>
      <link>https://freshrimpsushi.github.io/posts/linear-combination-span-basis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-combination-span-basis/</guid>
      <description>선형 결합$(\mathrm{ linear\ combination}$, 일차결합$)$ $v_1,v_2,\cdots ,v_n$을 벡터 공간 $V$의 벡터라고 하자. 임의의 스칼라 $k_1,k_2,\cdots , k_n$에 대해 $w=k_1v_1 + k_2v_2 + \cdots + k_nv_n = \sum\limits_{i=1}^n k_iv_i$를 만족하는 $w$를 $v_1,v_2,\cdots ,v_n$의 선형 결합이라고 한다.선형 결합이란 쉽게 말해서 주어진 원소들 각각에 임의의 상수를 곱해서 더한 것이다. 우리가 잘 아는 2차원 직교 좌표</description>
    </item>
    
    <item>
      <title>선형대수학에서 노름 혹은 놈이란</title>
      <link>https://freshrimpsushi.github.io/posts/norm-in-linear-algebra/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-in-linear-algebra/</guid>
      <description>$V$를 $\mathbb{F}$ 상에서의 벡터공간이라고 하자. $| \cdot | : V \to \mathbb{F}$ 가 $\mathbb{u}, \mathbb{v} \in V$와 $k \in \mathbb{F}$ 에 대해서 다음 세 조건을 만족시키면 $| \cdot |$ 을 $V$ 상에서의 놈 이라고 정의한다.(i) 정부호 : $| \mathbb{u} | \ge 0 $ 이고 $\mathbb{u} = \mathbb{0} \iff | \mathbb{u} | = 0$(ii) 동질성 : $| k \mathbb{u} | = | k | | \mathbb{u} | $(iii) 삼각부등식 : $| \mathbb{u} + \mathbb{v}| \le |\mathbb{v} | + | \mathbb{u} |$Norm은 절댓값에서 출발해 추상화된 개념으로, 한</description>
    </item>
    
    <item>
      <title>선형대수학에서 사영이란</title>
      <link>https://freshrimpsushi.github.io/posts/projection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/projection/</guid>
      <description>추상대수학에서의 멱등원 보러가기정방행렬 $P \in \mathbb{C}^{m \times m}$ 가 $P^2 = P$ 면 사영작용소Projector 라고 한다.대수학적인 용어로는 멱등원Idempotent 이라는 표현을 사용하고, 마찬가지로 $a^2 = a$ 와 같은 원소를 일컫는다.한편 $P$ 가 사영이면 $(I-P)^2 = I - 2P + P^2 = I - 2P + P = (I-P)$ 이므로 $(I-P)$ 역시 사영임을 알 수 있다.이러한 사영작용소 $(I - P)</description>
    </item>
    
    <item>
      <title>선형대수학에서 정사영이란</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-projection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-projection/</guid>
      <description>사영 $P \in \mathbb{C}^{m \times m}$ 가 $\mathcal{C} (P) ^{\perp} = \mathcal{N} (P)$ 를 만족하면 $P$ 를 정사영 이라고 한다.사영의 성질 $\mathbb{C}^{m } = \mathcal{C} (P) \oplus \mathcal{N} (P)$ 에 따라 $P$ 는 $\mathbb{C}^{m}$ 을 정확히 두 개의 부분공간 $\mathcal{C} (P)$ 과 $\mathcal{N} (P)$ 으로 분할함을 알 수 있다.이 분할에서 조건 $\mathcal{N} (P) = \mathcal{C} (P) ^{\perp} $ 을 만족한다는 것은 일차변환 $P$ 의 영공간 $\mathcal{N} (P)$ 가 열공간 $\mathcal{C} (P)$ 의 직교여공간이라는 뜻이므로 그냥 분할이 아니라 수직성이 포함되는 분할임을 알 수</description>
    </item>
    
    <item>
      <title>선형대수학에서 직합이란</title>
      <link>https://freshrimpsushi.github.io/posts/direct-sum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/direct-sum/</guid>
      <description>추상대수학에서의 직합 보러가기벡터공간 $S$ 의 두 부분공간 $S_{1}$ 과 $S_{2}$ 에 대해 다음을 만족하면 $S$ 를 $S_{1}$ 과 $S_{2}$ 의 직합 $S = S_{1} \oplus S_{2}$ 으로 나타낼 수 있다.**(i) 존재성** : 임의의 $\mathbb{s} \in S$ 에 대해 $\mathbb{s} = \mathbb{s}_{1} + \mathbb{s}_{2}$ 을 만족하는 $\mathbb{s}_{1} \in S_{1}$ 과 $\mathbb{s}_{2} \in S_{2}$ 가 존재한다.**(ii) 배타성** : $S_{1} \cap S_{2} = \left\{ 0 \right\}$**(iii) 유일성** : 주어진 $\mathbb{s}$ 에 대해 $\mathbb{s} = \mathbb{s}_{1} + \mathbb{s}_{2}$ 을 만족하는 $\mathbb{s}_{1} \in S_{1}$ 과 $\mathbb{s}_{2}</description>
    </item>
    
    <item>
      <title>선형범함수가 선형독립결합으로 나타나는 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/748/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/748/</guid>
      <description>$f, f_{1} , \cdots , f_{n}$ 가 정의역이 $X$ 인 선형범함수라고 하자.**[1]** $c_{1} , \cdots , c_{n} \in \mathbb{C}$ 에 대해 $\displaystyle f = \sum_{i=1}^{n} c_{i} f_{i} $ $\iff$ $\displaystyle \bigcap_{i=1}^{n} \ker ( f_{i} ) \subset \ker (f)$**[2]** $f_{1} , \cdots , f_{n}$ 이 선형독립 $\iff$ $f_{j} (x_{i} ) = \delta_{ij}$ 을 만족하는 $x_{1} , \cdots , x_{n}$ 이 존재* $\delta_{ij}$ 는 크로네커 델타함수다.커널이 동차Homogeneous의 개념과 관계가 있다는 걸 생각해보면 선형 동차 미분방정식에 대한 유용한 팩트임을</description>
    </item>
    
    <item>
      <title>세미 놈 서브 리니어</title>
      <link>https://freshrimpsushi.github.io/posts/seminorm-sublinear/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/seminorm-sublinear/</guid>
      <description>**** 세미 놈$(\mathrm{ semi\ norm}$, 반놈$)$ $X$를 벡터 공간이라고 하자. 아래의 세 조건을 만족하는 함수 $| \cdot | \ :\ X \rightarrow \mathbb{R}$가 존재하면 $| \cdot |$를 $X$의 놈이라 한다.$(a)$ $| x| \ge 0,\quad \forall\ x \in X $$ (b)$ $|cx|=|c||x|,\quad \forall\ x\in X,\ \forall\ c \in\mathbb{C} $$ (c)$ $| x+y| \le |x| + |y|,\quad \forall\ x,y\in X$놈의 정의에서 $|x |=0 \iff x=\mathbf{0 }$이 빠진 것이다.서브 리니어$(\mat</description>
    </item>
    
    <item>
      <title>세분</title>
      <link>https://freshrimpsushi.github.io/posts/refinement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/refinement/</guid>
      <description>** **** **세분 $P^{ * }$, $P$가 $[a,b]$의 분할이고 $P \subseteq P^{ * }$을 만족하면 $P^{ * }$를 $P$의 세분 이라고 한다. 따라서 $P$의 모든 점은 $P^{ * }$의 점이다. 또한 임의의 두 분할 $P_1$, $P_2$에 대해 $P_{3}=P_1 \cup P_2$를 를 $P_1$과 $P_2$의 **공통 세분** 이라 한다.고등학교에서 적분을 정의할 때 주어진 그래프를 $n$등분하고</description>
    </item>
    
    <item>
      <title>셀버그 항등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-selberg-identity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-selberg-identity/</guid>
      <description>$$ \Lambda (n) \log n + \sum_{d \mid n } \Lambda (d) \Lambda \left( {{ n } \over { d }} \right) = \sum_{d \mid n} \mu (d) \log^{2} {{ n } \over { d }} $$ **Strategy** : 보이는 것만큼 어렵지 않다. 산술함수의 미분만 있다면 아주 간단하게 유도할 수 있다. 증명 망골트 급수 $$ \sum_{d \mid n} \Lambda ( d ) = \log n $$ 산술 함수의 미분의 정의에 따라 망골트 급수는 컨볼루션을 써서 다음과 같이 나타낼 수 있다. $$ \Lambda * u = 1 \cdot \log n = u \log n = u&#39; $$ 양변</description>
    </item>
    
    <item>
      <title>소볼레프 공간은 분리가능하고 균등 볼록이고 반사적임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-sobolev-space-is-separable-uniformly-convex-and-reflexive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-sobolev-space-is-separable-uniformly-convex-and-reflexive/</guid>
      <description>$1\le p &amp;lt;\infty$일 때, 소볼레프 공간 $W^{m,\ p}$는 분리가능 하다. 또한 $1&amp;lt; p &amp;lt; \infty$일 때, 소볼레프 공간은 반사적 이고 균등 볼록하다.증명에 사용할 보조 정리를 소개한다.**보조정리 1 $(X, d)$를 거리공간이라고 하자. $(Y,d&#39;)$를 완비거리공간$(\mathrm{complete\ metric\ space})$이</description>
    </item>
    
    <item>
      <title>소수는 무한히 존재한다  오일러의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/420/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/420/</guid>
      <description>유클리드의 증명 보러가기소수는 무한히 존재한다.Strategy : 어떤 방법을 사용하든 같은 결과에만 도달한다면야 상관은 없지만, 정말 특이하게 풀어냈다면 그 자체로 공부할 가치가 있다. 유클리드의 증명처럼 단순 명료 깔끔한 맛은 없지만 정수론의 문제를 해석적인 툴로 해결했다는 점이 매우 흥미롭다. 오일러가 남긴 많은 증명들이 그렇듯 한 번 보면</description>
    </item>
    
    <item>
      <title>속박전하와 편극된 물체가 만드는 전기장</title>
      <link>https://freshrimpsushi.github.io/posts/bound-charge-and-electric-field-of-polarized-object/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bound-charge-and-electric-field-of-polarized-object/</guid>
      <description>외부 전기장에 의해서 물체의 쌍극자들이 한 방향으로 정렬하고 이로 인해 물체는 편극밀도 $\mathbf{P}$를 가진다.이렇게 생겨난 편극밀도가 만들어내는 전기장은 속박전하가 만들어내는 전위를 쓰면 쉽게 계산할 수 있다.쌍극자 모멘트 $\mathbf{p}$가 만드는 전위는 다음과 같다. $$ V(\mathbf{r}) = \dfrac{1}{4 \pi \epsilon_0} \dfrac{ \mathbf{p} \cdot \hat{ \boldsymbol{\eta}} } {\eta ^2}\tag{1} $$ $\math</description>
    </item>
    
    <item>
      <title>수리통계학에서의 다변량 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/multivariate-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multivariate-distribution/</guid>
      <description>1. 표본 공간 $\Omega$ 에서 정의된 $n$ 개의 확률 변수 $X_{i}$ 에 대해 $X = (X_{1} , \cdots , X_{n})$ 를 **$**n$차원 랜덤 벡터Random Vector 라고 한다. $X$ 의 치역 $X(\Omega)$ 를 **공간** 이라고도 부른다.**2.** 다음을 만족하는 함수 $F_{X} : \mathbb{R}^{n} \to [0,1]$ 을 $X$ 의 **조인트 누적 분포 함수** 라고 한다. $$ F_{X}\left( x_{1}, \cdots , x_{n} \right) := P \left[ X_{1} \le x_{1} , \cdots , X_{n} \le x_{n} \right] $$ **3.** 어떤 $h_{1} , \cdots , h_{n} &amp;gt;0$ 들에 대해</description>
    </item>
    
    <item>
      <title>수리통계학에서의 신뢰 구간</title>
      <link>https://freshrimpsushi.github.io/posts/confidence-interval/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/confidence-interval/</guid>
      <description>**신뢰 구간1 확률 밀도 함수 $f (x; \theta)$ 를 가지는 확률 변수 $X$ 의 샘플 $X_{1} , \cdots , X_{n}$ 와 신용 계수Confidence Coefficient $\alpha \in (0,1)$ 가 주어져 있다고 하자. $$ L := L \left( X_{1} , \cdots , X_{n} \right) \\ U := U \left( X_{1} , \cdots , X_{n} \right) $$ 통계량 $L,U$ 가 위와 같이 정의되어있다고 할 때, 다음을 만족하는 구간 $(L,U) \subset \mathbb{R}$ 을 모수 $\theta$ 에 대한 $( 1 - \alpha)100%$ 신뢰구간이라 한다. $$ 1-\alpha = P \left[ \theta \in \left( L,U \right) \right] $$ 사실</description>
    </item>
    
    <item>
      <title>수리통계학에서의 통계량과 추정량</title>
      <link>https://freshrimpsushi.github.io/posts/statistic-and-estimator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statistic-and-estimator/</guid>
      <description>**통계량1 1. 확률 변수 $X$ 의 샘플 $X_{1} , \cdots , X_{n}$ 의 함수 $T$ 를 **통계량** 이라 한다. $$ T := T \left( X_{1} , \cdots , X_{n} \right) $$ **2.** $X$ 의 분포 함수가 $f(x; \theta)$ 혹은 $p(x; \theta)$ 와 같이 나타날 때, $T$ 가 $\theta$ 를 파악하기 위한 통계량이면 $T$ 를 $\theta$ 의 **추정량** 이라고 한다.**3.** 통계량과 모수에 대한 함수를 **피벗**Pivot 이라고 한다.**2.** 추정량(Es</description>
    </item>
    
    <item>
      <title>수직선의 부분 집합이 연결 집합일 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-that-subset-of-the-real-line-is-connected-set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-that-subset-of-the-real-line-is-connected-set/</guid>
      <description>$E \subset \mathbb{R}$이고 $x,y\in E$, $x&amp;lt;z&amp;lt;y$라고 하자. 그러면 아래의 두 명제는 동치이다.$(a)$ $E$는 연결 집합이다.$(b)$ $z\in E$이다. 증명 $(a) \implies (b)$ 대우법으로 증명한다. 즉 $z\notin E$이면 $E$는 비연결집합임을 보일 것이다.$z\notin E$라고 가정하자. 두 집합 $A_{z}$, $B_{z}$를 다음과 같다고</description>
    </item>
    
    <item>
      <title>수직축 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-perpendicular-axis-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-perpendicular-axis-theorem/</guid>
      <description>**** 평행축 정리 **** 수직축 정리 임의의 평면에 수직한 회전축에 대한 관성모멘트는 그 수직축을 지나면서 평면판 위에 있는 서로 수직한 임의의 두 축에 대한 관성모멘트의 합과 같다. $$ \color{red}{I_z}=\color{blue}{I_x+I_y} $$ ** 증명은 매우 간단하다.증명 $$ I_z=\sum\limits_i m_i{r_i}^2 $$ 피타고라스의 정리에 의해서 ${r_i}^2={x_i}^2+{y_i}^2$이므로 대입하면 $$ I_z=\sum\limits_i m_i({x_i}^2+{y_i}^2)=\sum\limits_i m_i{x_i}^2+\sum\limits_i m_i{y_i}^2 $$ $x$는 $y$</description>
    </item>
    
    <item>
      <title>수직파 평행파 선편광</title>
      <link>https://freshrimpsushi.github.io/posts/transverse-wave-longitudinal-wave-linear-polarization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transverse-wave-longitudinal-wave-linear-polarization/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/jpeg&amp;rdquo; filename=&amp;ldquo;슬라이드5.JPG&amp;rdquo; height=&amp;ldquo;409&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/995B9C375CC951181B&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;728&amp;rdquo;/&amp;gt;위 그림과 같이 진행방향과 진동방향이 서로 수직인 파동을 수직파$(\mathrm{transverse\ wave})$ 또는 횡파라고 한다. 반대로 진행방향과 진동방향이 서로 평행한 파동을 평행파$(</description>
    </item>
    
    <item>
      <title>수치적으로 이상적분을 계산하기 위한 변수 치환 트릭</title>
      <link>https://freshrimpsushi.github.io/posts/1147/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1147/</guid>
      <description>$0 &amp;lt; a &amp;lt; b &amp;lt; \infty$ 라고 하자.[1] $ 0 &amp;lt; p &amp;lt; 1$ 면 $\displaystyle \int_{0}^{b} {{ f(x) } \over {x^{p} }} dx = \int_{0}^{{{ 1 } \over { 1-p }} b^{1-p} } f \left( \left[ ( 1- p ) m \right]^{{{ 1 } \over { 1-p }}} \right) dm$**[2]** $ 1 &amp;lt; p$ 면 $\displaystyle \int_{a}^{ \infty } {{ f(x) } \over {x^{p} }} dx = \int_{0}^{{{ 1 } \over { p-1 }} a^{1-p}}f \left( \left[ ( p-1 ) m \right]^{{{ 1 } \over { 1-p }}} \right) dm$이상적분은 언제나 골칫덩이지만 풀이를 포기할 수는 없다. 보통 적분이 어려운 이유는 어지간한 트릭을 써봐도 정작 그 트</description>
    </item>
    
    <item>
      <title>수치해석에서의 인터폴레이션</title>
      <link>https://freshrimpsushi.github.io/posts/interpolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interpolation/</guid>
      <description>주어진 $(n+1)$쌍의 데이터 $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$ 에 대해 $f (x_{i} ) = y_{i}$ 를 만족하면서 어떤 특정한 성질을 가지는 $f$ 를 찾는 방법을 **보간법** 혹은 **내삽법** 이라고 한다.예를 들어 위와 같이 데이터가 있긴한데 가운데 데이터가 비어있는 상황을 생각해보자. 물론 실제 데이터가 있는게 가장 좋지만, 없으면 예측이라도 해서 써야할 상황이 있을 수 있</description>
    </item>
    
    <item>
      <title>수학에서 단위 분할이란</title>
      <link>https://freshrimpsushi.github.io/posts/partition-of-unity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-of-unity/</guid>
      <description>아래의 조건을 만족하는 연속 함수 $u_{\alpha} : X \to [0,1], \alpha \in \Lambda$들의 집합 $\left\{ u_{\alpha} \right\}_{\alpha \in \Lambda}$를 **단위 분할** 이라고 한다. $$ \sum _{\alpha \in \Lambda}u_{\alpha}(x)=1 $$ 조금 더 일반적으로 정의할 수도 있지만 이 정도만 해도 충분하다. 다 더해서 1이 되는 함수들의 집합, 혹은 반대로 1을 쪼개어 놓은 함수들의 집합으로 이해할 수 있다. 미분기하학이나 수치해석학 등에</description>
    </item>
    
    <item>
      <title>수학에서 자주 쓰이는 기호와 줄임말</title>
      <link>https://freshrimpsushi.github.io/posts/1764/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1764/</guid>
      <description>예문 1-3: 거리공간에서 수열의 수렴 $$ \forall \varepsilon&amp;gt;0,\ \exists N \in \mathbb{N}\quad \mathrm{s.t}\ n\ge N \implies d(p_{n},p) &amp;lt; \varepsilon $$ For every $\varepsilon&amp;gt;0$, there is an natural number N such that $n\ge N$ implies that $d(p_{n},p)&amp;lt;\varepsilon$.모든 양의 실수 $\varepsilon$에 대해서, $n$이 어떤 자연수수 $N$보다 크기만 하면 $d(p_{n},p)&amp;lt;\varepsilon$가 성립하는 정수</description>
    </item>
    
    <item>
      <title>수학에서의 그래프와 네트워크</title>
      <link>https://freshrimpsushi.github.io/posts/graph-and-network-in-mathematics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/graph-and-network-in-mathematics/</guid>
      <description>1. 정점과 정점들을 연결한 선들로 이루어진 집합을 그래프 혹은 네트워크 라고 한다. 정점들의 집합을 $V$, 선들의 집합을 $E$ 라고 하자.2. $V(G) := V$ 의 원소를 $G$ 의 버텍스Vertex 혹은 노드Node 라고 한다.3. $E(G) := E$ 의 원소를 $G$ 의 에지Edge 라고 혹은 링크Link 라고 한다.4. 자기 자신으로 이어진 에지를 루프Loop 라고 한다.5. 두 버텍</description>
    </item>
    
    <item>
      <title>수학에서의 동치관계</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-relation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-relation/</guid>
      <description>반사적이면서 대칭적이면서 추이적인 이항관계를 동치관계 라고 한다.동치관계를 수학적이지 않게 말한다면 &amp;lsquo;그게 그거&amp;rsquo;라는 말이다.수학을 연구할 때 그 이유가 반드시 필요한 건 아니지만, 만약 수학을 연구하는 실용적인 이유가 반드시 있어야 한다면 그것은 &amp;lsquo;원래 어렵고 복잡한 개념을 쉽고 간단한 영역으로 끌어</description>
    </item>
    
    <item>
      <title>수학에서의 이항관계</title>
      <link>https://freshrimpsushi.github.io/posts/binary-relation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/binary-relation/</guid>
      <description>1. 두 집합 $X,Y$ 에 대해 $$ R := \left\{ (x,y) : x \in X , y \in Y \right\} \subset X \times Y $$ 를 (이항) 관계 라고 정의하고 다음과 같이 나타낸다. $$ (x,y) \in \sim \iff x R y $$ 2. $x R y \iff y R^{-1} x$ 를 만족하는 $$ R^{-1} : \left\{ (y,x) : (a,b) \in R \right\} $$ 을 $R$ 의 역관계Inverse 라고 한다.3. 모든 $x \in X$ 에 대해 $$ x R x $$ 를 만족하는 $ R \subset X^{2}$ 를 반사적Reflexive 이라고 한다.4. 모든 $x,y \in</description>
    </item>
    
    <item>
      <title>쉴로브 정리</title>
      <link>https://freshrimpsushi.github.io/posts/sylow-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sylow-theorem/</guid>
      <description>소수 $p$ 와 $\gcd (p, m) = 1$ 을 만족하는 어떤 자연수 $m$ 에 대해 $G$ 가 $|G| = p^{n} m$ 인 유한군이라고 하자. $G$ 의 $p$-부분군 중 다른 $p$-부분군에 포함되지 않는 $p$-부분군을 쉴로브 $p$-부분군 이라고 한다.(1) 제1쉴로브 정리 : $G$ 는 $i=1, \cdots , n$ 에 대해 $|P| = p^{i}$ 를 만족하는 $p$-부분군이 존재한다.(2) 제2쉴로브 정리 : $G$ 의 쉴로브 $p$-</description>
    </item>
    
    <item>
      <title>스튀름-리우빌 미분 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/sturm-liouville-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sturm-liouville-differential-equation/</guid>
      <description>$p\in$$C^{1}(\mathbb{R})$이고 $q,r\in C(\mathbb{R})$, $\lambda \in \mathbb{R}$이라고 하자. 아래와 같은 꼴의 미분 방정식을 스튀름-리우빌 미분 방정식 이라 한다. $$ \left[ p(x)u&#39;(x) \right]&#39;+\left[ q(x) +\lambda w(x) \right]u(x)=0 \tag{1} $$ 혹은 $$ p(x)u&#39;&#39;(x)+p&#39;(x)u&#39;(x)+\left[ q(x)+\lambda w(x) \right]u(x)=0 $$ 짧게 줄여서 &amp;lsquo;S-L 문제 &amp;lsquo;라고 부르기도 한다. 여기서 $w$는 가중 함수$(\mathrm{weight\ fu</description>
    </item>
    
    <item>
      <title>스튜던트의 정리Students Theorem 증명</title>
      <link>https://freshrimpsushi.github.io/posts/203/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/203/</guid>
      <description>$X_{i} \sim N(\mu,\sigma)$이라고 하자.**(a)** $\displaystyle \overline{X} \sim N\left( \mu , { {\sigma^2} \over {n} } \right) $**(b)** $\overline{X} \perp S^2$**(c)** $\displaystyle (n-1) { {S^2} \over {\sigma^2} } \sim \chi^2 (n-1) $**(d)** $\displaystyle T = { {\overline{X} - \mu } \over {S / \sqrt{n}} } \sim t(n-1)$통계학을 하는 사람들은 당연한듯 쓰고 있지만 사실 여기에도 이름이 있다.네 개의 파트로 나뉘어져 있어 구체적으로 인용하기도 어려운 것도 한몫을 한 것 같다.**증명(a)</description>
    </item>
    
    <item>
      <title>스펙트럼과 프라운호퍼 선</title>
      <link>https://freshrimpsushi.github.io/posts/spectrum-and-fraunhofer-line/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spectrum-and-fraunhofer-line/</guid>
      <description>스펙트럼이란 분광학의 연구 대상으 빛을 여러 색으로 분해한 것을 말한다. 흔히 제일 처음 보게되는 스펙트럼의 그림은 위와 같이 가로, 혹은 세로로 긴 형태의 선 스펙트럼 이다. 하지만 스펙트럼이 처음부터 이러한 형태를 띄었던 것은 아니다. 프리즘을 통해서 빛을 여러 색으로 분해시킬 수 있음을 처음 발견한 사람은 뉴턴이다. 뉴턴은 빛을 조그만 구멍을 통과시킨</description>
    </item>
    
    <item>
      <title>시계열 분석에서의 가치 모형</title>
      <link>https://freshrimpsushi.github.io/posts/garch-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/garch-model/</guid>
      <description>R 에서 가치 모델로 분석하는 법가치 모델 은 아치 모델을 일반화한 것으로, 이분산성을 파악하기 위한 시계열 분석법이다. $$ (1 - \beta{1} B - \cdots - \beta_{p} B^p) \sigma_{t | t-1}^2 = \omega + (\alpha_{1} B + \cdots + \alpha_{q} B^q) r_{t}^{2} $$ 유도는 가장 간단한 $ARCH(1)$ 모델부터 시작해보자.1 시계열 데이터 $\left\{ p_{t} \right\}$ 의 리턴 $\left\{ r_{t} \right\}$ 이 주어져 있다고 할 때 데이터가 시차 $1$ 의 아치 이펙트, 즉 자기 회귀 조건부 이분산성을 가진다</description>
    </item>
    
    <item>
      <title>시계열 분석에서의 이분산성과 변동성 군집현상</title>
      <link>https://freshrimpsushi.github.io/posts/heteroscedasticity-and-volatility-clustering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heteroscedasticity-and-volatility-clustering/</guid>
      <description>시계열 데이터 $\left\{ p_{t} \right\}$ 가 주어져 있다고 하자.**1.** $\left\{ p_{t} \right\}$ 의 분산이 $t$ 에 종속되어있을 때, $\left\{ p_{t} \right\}$ 는 **이분산성** 을 가진다고 한다.**2.** 이분산성을 가지는 $\left\{ p_{t} \right\}$ 의 분산이 커졌다 작아졌다를 반복하는 현상을 **변동성 군집현상** 이라고 한다.**3.** 다음과 같이 정의된 $r_{t}$ 를 $t$ 에서의 **(로그) 리턴**Retur</description>
    </item>
    
    <item>
      <title>시계열분석에서의 백색잡음</title>
      <link>https://freshrimpsushi.github.io/posts/white-noise-in-time-series-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/white-noise-in-time-series-analysis/</guid>
      <description>확률과정으로 본 랜덤워크iid한 확률변수 $e_{t}$ 들의 수열 $\left\{ e_{t} \right\}_{t = 1}^{\infty} $ 를 **백색잡음** 이라고 한다.* iid란 independent identically distributed의 줄임말로써, 서로 독립이고 같은 분포를 가짐을 의미한다.확률변수의 수열이라는 정의에 따르면 당연히 확률과정이다.특히 $E ( e_{t} ) = 0$ 이면 $Y_{t} : = \begin{cases} e_{1} &amp;amp; , t=1 \\ Y_{t-1} + e_{t} &amp;amp; , t \ne 1 \\ \end{cases}$ 과 같이 정의된</description>
    </item>
    
    <item>
      <title>시계열분석이란</title>
      <link>https://freshrimpsushi.github.io/posts/time-series-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-series-analysis/</guid>
      <description>시계열Time Series 이란 쉽게 말해 실제 데이터로 얻어지는 확률과정이라고 볼 수 있다. 주가지수는 시간이 흐름에 따라 불확실성을 가지고 그 값이 변하므로 시계열의 좋은 예시가 될 수 있다. 시계열분석 이란 이렇듯 시간 변수의 흐름에 따른 종속변수의 움직임을 이해하고 예측하는 것을 목표로 하는 분석법이다.회귀분석과의 가장 큰 차이점은 회귀분석이 독립변수</description>
    </item>
    
    <item>
      <title>시그모이드 함수란</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-a-sigmoid-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-a-sigmoid-function/</guid>
      <description>시그모이드 함수1 유계 미분가능 스칼라 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 이 모든 $x \in \mathbb{R}$ 에서 $\sigma &#39; (x) \ge 0$ 이고 단 하나의 변곡점을 가지면 시그모이드 함수 라고 한다. * 시그모이달 함수와는 그 정의가 다르다.시그모이드 함수의 예시로써 다음과 같은 함수들이 알려져있다:(1) 로지스틱 함수 $\displaystyle f(x) := {{ 1 } \over { 1 + e^{-x} }}$(2) 하이퍼볼릭 탄젠트 $\tanh x$(3) 아크 탄젠트 $\arctan x$시그모이</description>
    </item>
    
    <item>
      <title>신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval/</guid>
      <description>모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $P ( \theta \in C | y ) \ge 1 - \alpha$ 를 만족할 때, $C$ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 신용구간 이라고 한다.베이지안에서의 구간추정이란 모수 $\theta$ 를 포함하는 확률이 높은 구간을 찾는 것이다.이로써 찾아지는 &amp;lsquo;신용구간&amp;rsquo;이란 프리퀀티스트에게는 &amp;lsquo;신뢰</description>
    </item>
    
    <item>
      <title>신용구간과 신뢰구간의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</guid>
      <description>신용구간과 신뢰구간의 차이는 실로 베이지안과 프리퀀티스트의 차이라고 볼 수 있다.**요약 - 신뢰구간(프리퀀티스트) : 모수는 고정된 상수고, 신뢰구간이 랜덤으로 구해진다. - 신용구간(베이지안) : 모수도 분포를 가진 변수고, 신용구간도 사후분포로 구해진다.**신뢰구간 고전통계에서 모수 $\mu$ 에 대한 $95 %$ 신뢰구간 $[a , b]$ 이 의미하는 것</description>
    </item>
    
    <item>
      <title>실수 공간에서 정의된 함수의 미분</title>
      <link>https://freshrimpsushi.github.io/posts/differential-in-real-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/differential-in-real-space/</guid>
      <description>$a$ 를 포함하는 어떤 $E$ 에서 $f$ 가 정의되어있고 극한 $$ f&#39;(a) := \lim_{h \to 0} {{ f (a + h ) - f(a) } \over { h }}=\lim \limits_{x\rightarrow a}\frac{f(x)-f(a)}{x-a} $$ 이 존재하면 $f$ 가 $a$ 에서 **미분가능** 하다고 하고, $f&#39;(a)$ 를 $a$ 에서 $f$ 의 **미분계수** 라고 한다.$f&#39;$를 $f$의 **도함수$(\mathrm{derivative})$** 라 부른다.**[1] 연속성** : $f$ 가 $a \in E$ 에서 미</description>
    </item>
    
    <item>
      <title>실수 복소수 세미 놈에 대한 한-바나흐 정리</title>
      <link>https://freshrimpsushi.github.io/posts/hahn-banach-theorem-for-real-complex-semi-norm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hahn-banach-theorem-for-real-complex-semi-norm/</guid>
      <description>※ 놈 공간 $X$의 놈을 $| \cdot |_X$ 또는 $| \cdot\ ;X|$로 표기한다. 헷갈릴 여지가 없을 경우에는 $| \cdot |$로 표기할 수도 있다.실수에 대한 한-바나흐 정리$(\mathrm{ Hahn-Banach\ theorem\ real\ version})$ $X$는 $\mathbb{R}$-벡터 공간이고 $Y \subset X$라고 하자. $p\ :\ X \rightarrow \mathbb{ R}$를 준선형 범함수라고 하자. 이제 $\ y^{ * } \ :\ Y \rightarrow \mathbb{ R}$가 아래의 조건</description>
    </item>
    
    <item>
      <title>실수의 기수와 유리수의 기수의 크기 비교</title>
      <link>https://freshrimpsushi.github.io/posts/comparing-the-cardinality-of-real-and-rational/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/comparing-the-cardinality-of-real-and-rational/</guid>
      <description>$\text{card}(\mathbb{Q})={{ \aleph }{ 0 }}, \text{card}(\mathbb{R})=c$ 에 대해 $ { 2 }^{ {{ \aleph }{ 0 }} } =c$ , $ {{ \aleph }_{ 0 }}&amp;lt;c $ 칸토어의 대각선 논법을 보면 짐작할 수 있듯, 유리수의 집합보다 실수의 집합이 훨씬 많은 원소를 갖는다. 그 기수는 구체적으로 부등식을 세워서 보일 수 있다. 증명 Part 1. $c \le 2^{\aleph_{0}}$함수 $f : \mathbb{R} \to \wp (\mathbb{Q})$ 를 $f(a):={x\in \mathbb{Q}|x&amp;lt;a, a\in \mathbb{R}}$ 와 같이 정의하자.실수의 조밀성 의해 두 실수 $a&amp;lt;b$ 에 대</description>
    </item>
    
    <item>
      <title>실수축의 특이점을 포함했을 때 조르당 보조정리를 통한 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/373/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/373/</guid>
      <description>전체적인 흐름은 조르당 보조정리를 통한 이상적분과 비슷하다.두 다항함수 $p(z) , q(z) $ 에 대해 $\displaystyle f(z) = {{q(z)} \over {p(z)}} $ 이라고 하자.$q(z) = 0$ 을 만족하는 실수해 $a$ 가 존재한다면 $f$ 는 실수 특이점 $a$ 을 갖는 것이다.이제까지 이러한 경우를 다루지 않았던 이유는 유수 정리를 쓰기 위함이었다.물론 실수축에 특이점이 추가되었다는 이유만으로 딱히 유수정리를 포</description>
    </item>
    
    <item>
      <title>실해석에서의 단조 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-monotone-convergence-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-monotone-convergence-theorem/</guid>
      <description>함숫값이 음이 아닌 가측 함수의 수열 $\left\{ f_{n} \right\}$ 이 $f_{n} \nearrow f$ 을 만족한다고 하자. 그러면 $$ \displaystyle \lim_{n \to \infty} \int_{E} f_{n} dm = \int_{E} f dm $$ $f_{n} \nearrow f$ 이란 모든 $x$ 에 대해 $f_{n}(x) \le f_{n+1} (x)$ 이면서 $\displaystyle \lim_{n \to \infty} f_{n} = f$ 인 것이다.수식은 너무 쉽기 때문에 이 정리를 안다는 것은 &amp;lsquo;조건&amp;rsquo;을 정확하게 안다는 말이다.유용성으로 따질 것 같으면 극한이 적분을 마음대로 드나들 수 있</description>
    </item>
    
    <item>
      <title>심플 평면 그래프의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-simple-planar-graphs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-simple-planar-graphs/</guid>
      <description>$G$ 가 심플 평면 그래프라고 하자.[1] $G$ 가 연결 그래프고 $n \ge 3$ 개의 버텍스, $m$ 개의 에지를 가지면 $m \le 3n - 6$[2] 모든 심플 평면 그래프 $G$ 는 $\deg v \le 5$ 인 버텍스 $v \in V(G)$ 를 가진다. 증명[1] 평면 그래프의 각 페이스는 적어도 세 개의 에지로 둘러싸여있다고 하자.가장 간단한 케이스로 컴플리트 그래프 $K_{3}$ 만 달랑 있다면 에지 $m=3$ 에 페이스 $f=2$ 고, 여기서 페이스가</description>
    </item>
    
    <item>
      <title>싱크함수의 오일러 표현 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-representation-of-sinc-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-representation-of-sinc-function/</guid>
      <description>$$ \displaystyle \text{sinc} x = {{\sin x} \over {x}} = \prod_{n=1}^{\infty} \left( 1 - {{x^2} \over { \pi^2 n^2}} \right) $$ 싱크함수란 $\sin x$을 $x$로 나눈 함수로써, 별도의 이름이 붙은만큼 유용한 구석이 많은 함수다. 교과 과정부터 그 이름만 모를 뿐 극한이나 연속 파트에 종종 등장하기도 한다.물론 싱크함수는 $x=0$ 에서 정의되지 않지만 다들 잘 알듯 $\displaystyle \lim_{x \to 0} {{\sin x} \over {x}} = 1$ 이므로, 정말 엄밀하게 따지고 들 게 아니라면 별 말이 없</description>
    </item>
    
    <item>
      <title>쌍곡함수</title>
      <link>https://freshrimpsushi.github.io/posts/hyperbolic-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hyperbolic-functions/</guid>
      <description>쌍곡함수의 정의$z \in \mathbb{C}$에 대해서, $$ \begin{align*} \sinh z &amp;amp;:= \frac{e^{z}-e^{-z}}{2} \\ \cosh z &amp;amp;:= \frac{e^{z}+e^{-z}}{2} \\ \tanh z &amp;amp;:= \frac{\sinh z}{\cosh z} \end{align*} $$ $$ \begin{align*} \mathrm{csch}x&amp;amp;=\frac{1}{\sinh x} \\ \mathrm{sech} x&amp;amp;=\frac{1}{\cosh x} \\ \coth x &amp;amp;=\frac{1}{\tanh x} \end{align*} $$ 삼각함수와의 관계 $$ \begin{align*} \sinh (iz) &amp;amp;= i\sin z \\ \sin (iz) &amp;amp;= i\sinh z \\ \cosh (iz) &amp;amp;= \cos z \\ \cos (iz) &amp;amp;= \cosh z \end{align*} $$ 미분 $$ \begin{align*} (\sinh x)&#39; &amp;amp;= \cosh x \\ (\cosh x )&#39; &amp;amp;= \sinh x \\ (\tanh x)&#39; &amp;amp;= \frac{1}{\cosh^{2} x}=\mathrm{sech}^{2}x \end{align*} $$ 항등식 $$ \begin{align*} \sinh(-x) &amp;amp;= -\sinh x \\ \cosh(-x) &amp;amp;= \cosh x \\ \tanh(-x)&amp;amp;=- \tanh x \\ \cosh x + \sinh x &amp;amp;=e^{x} \\ \cosh x - \sinh</description>
    </item>
    
    <item>
      <title>쌍곡함수의 덧셈정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-sum-of-arguments-of-hyperbolic-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-sum-of-arguments-of-hyperbolic-function/</guid>
      <description>$$ \begin{align} \sinh (x\pm y) &amp;amp;=\sinh x \cosh y \pm \sinh y \cosh x \\ \cosh (x \pm y) &amp;amp;= \cosh x \cosh y \pm \sinh x \sinh y \\ \tanh{x \pm y}&amp;amp;=\frac{\tanh x \pm \tanh y}{1 \pm \tanh x \tanh y} \end{align} $$ 쌍곡함수와 삼각함수의 관계를 생각해보면 삼각함수의 덧셈정리와 모양이 비슷한 것은 당연하다. 증명 $(1)$ $$ \begin{align*} \sinh (x+y) &amp;amp;= \frac{e^{x+y}-e^{-x-y}}{2} \\ &amp;amp;=\frac{2e^{x+y}-2e^{-x-y}}{4} \\ &amp;amp; =\frac{e^{x+y} \color{red}{-e^{-x+y}} \color{blue}{+e^{x-y}}-e^{-x-y}}{4} +\frac{e^{x+y} \color{red}{+e^{-x+y}} \color{blue}{-e^{x-y}}-e^{-x-y}}{4} \\ &amp;amp; =\frac{(e^{x} -e^{-x})e^{y}+(e^{x}-e^{-x})e^{-y}}{4} +\frac{e^{y}(e^{x}+e^{-x})-e^{-y}(e^{x}+e^{-x})}{4} \\ &amp;amp; = \frac{(e^{x} -e^{-x})(e^{y}+e^{-y})}{4} +\frac{(e^{y}-e^{-y})(e^{x}+e^{-x})}{4} \\ &amp;amp; = \left( \frac{e^{x} -e^{-x}}{2} \right)\left( \frac{e^{y} +e^{-y}}{2} \right) + \left( \frac{e^{y} -e^{-y}}{2} \right)\left( \frac{e^{x} +e^{-x}}{2} \right) \\ &amp;amp;= \sinh x \cosh y +\sinh y \cosh x \end{align*} $$ $\sinh (-x)=-\sinh x$이</description>
    </item>
    
    <item>
      <title>쌍곡함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-hyperbolic-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-hyperbolic-function/</guid>
      <description>쌍곡사인함수와 쌍곡코사인함수의 라플라스 변환은 다음과 같다.$\mathcal{L} \left\{ \sinh (at) \right\} = \dfrac{a}{s^2-a^2}$ $s&amp;gt;|a| $$ \mathcal{L} \left\{ \cosh (at) \right\} = \dfrac{s}{s^2-a^2}$ $s&amp;gt;|a|$쌍곡함수의 정의를 한 번 짚고 넘어가자.$\sinh (ax) = \dfrac{ e^{ax} - e^{-ax} }{ 2 } $$ \cosh (ax) = \dfrac{ e^{ax} + e^{-ax} }{ 2 } $그리고 혹시 지수함수의 라플라스 변환 결과를 모른다면 이 글을 한 번 읽고 오자. 유도1 $\displaystyle \mathcal{ L } \left\{</description>
    </item>
    
    <item>
      <title>쌍곡함수의 배각 공식 반각 공식</title>
      <link>https://freshrimpsushi.github.io/posts/square-formulas-and-half-arguments-formulas-for-hyperbolic-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/square-formulas-and-half-arguments-formulas-for-hyperbolic-functions/</guid>
      <description>**쌍곡함수의 배각공식 $$ \begin{align} \sinh (2x) &amp;amp;= 2\sinh x \cosh x \\ \cosh (2x) &amp;amp;= \cosh^{2} x + \sinh^{2} x \\ &amp;amp;=2\cosh ^{2 } x -1 = 2\sinh ^{2} x +1 \nonumber \\ \tanh (2x) &amp;amp;= \frac{2\tanh x}{1+\tanh^{2}x} \end{align} $$ **쌍곡함수의 반각 공식 $$ \begin{align} \sinh^{2} \frac{x}{2} &amp;amp;=\frac{\cosh x -1 }{2} \\ \cosh^{2} \frac{x}{2} &amp;amp;=\frac{\cosh x +1 }{2} \\ \tanh ^{2} \frac{x}{2} &amp;amp;= \frac{\cosh x -1}{\cosh x +1} \end{align} $$ $$ \begin{align} \sinh \frac{x}{2}&amp;amp;=\frac{\sinh x}{\sqrt{2(\cosh x +1)}} \\ \cosh \frac{x}{2}&amp;amp;=\frac{\sinh x}{\mathrm{sgn}(x)\sqrt{2(\cosh x -1)}} \end{align} $$ $\mathrm{sgn}(x)$는 부호 함수이며 아래와 같이 정의한다. $$ \mathrm{sgn}(x)=\begin{cases} 1 &amp;amp; x&amp;gt;0 \\ 0 &amp;amp; x=0 \\ -1 &amp;amp; x&amp;lt;0 \end{cases}</description>
    </item>
    
    <item>
      <title>쌍곡함수의 합차 공식과 곱셈 공식</title>
      <link>https://freshrimpsushi.github.io/posts/sum-to-product-identities-and-product-to-sum-identities-for-hyperbolic-funtions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-to-product-identities-and-product-to-sum-identities-for-hyperbolic-funtions/</guid>
      <description>**쌍곡함수의 합차 공식 $$ \begin{align} \sinh x +\sinh y &amp;amp;=2\sinh \frac{x+y}{2} \cosh \frac{x-y}{2} \\ \sinh x -\sinh y &amp;amp;=2\sinh \frac{x-y}{2} \cosh \frac{x+y}{2} \\ \cosh x + \cosh y &amp;amp;= 2 \cosh \frac{x+y}{2} \cosh \frac{x-y}{2} \\ \cosh x -\cosh y &amp;amp;= 2 \sinh \frac{x+y}{2}\sinh \frac{x-y}{2} \end{align} $$ **쌍곡함수의 곱셈공식 $$ \begin{align} \sinh x \sinh y &amp;amp;= \frac{\cosh (x+y)-\cosh (x-y)}{2} \\ \sinh x \cosh y &amp;amp;= \frac{\sinh (x+y)+\sinh (x-y)}{2} \\ \cosh x \sinh y &amp;amp;= \frac{\sinh (x+y)-\sinh (x-y)}{2} \\ \cosh x \cosh y &amp;amp;= \frac{\cosh (x+y)+\cosh (x-y)}{2} \end{align} $$ 증명 과정은 삼각함수의 합차 공식을 유도한 것과 같으므로 구체적으로 소개하지는 않겠다. 증명 $(1)-(4)$ 덧셈 정리에</description>
    </item>
    
    <item>
      <title>쌍곡함수의 항등식</title>
      <link>https://freshrimpsushi.github.io/posts/identities-of-hyperbolic-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/identities-of-hyperbolic-functions/</guid>
      <description>$$ \begin{align} \sinh(-x) &amp;amp;= -\sinh x \\ \cosh(-x) &amp;amp;= \cosh x \\ \tanh(-x)&amp;amp;=- \tanh x \\ \cosh x + \sinh x &amp;amp;=e^{x} \\ \cosh x - \sinh x &amp;amp;= e^{-x} \\ \cosh^{2}x -\sinh^{2}x &amp;amp;=1 \end{align} $$ 딱히 증명이랄 것도 없다. 정의로부터 바로 알 수 있는 사실이다. 증명 $(1)$ $$ \begin{align*} \sinh(-x) &amp;amp;= \frac{e^{-x}-e^{x}}{2} \\ &amp;amp;=-\frac{e^{x}-e^{-x}}{2} \\ &amp;amp;=-\sinh x \end{align*} $$ ■ 증명 $(2)$ $$ \begin{align*} \cosh(-x) &amp;amp;= \frac{e^{-x}+e^{x}}{2} \\ &amp;amp;=\frac{e^{x}+e^{-x}}{2} \\ &amp;amp;=\cosh x \end{align*} $$ ■ 증명 $(3)$ $$ \tanh (-x)=\frac{\sinh (-x)}{\cosh (-x)}=\frac{-\sinh x }{\cosh x}=-\tanh x $$ ■ 증명 $(4)$ $$ \begin{align*} \cosh x + \sinh x &amp;amp;= \frac{e^{x}+e^{-x}}{2}+\frac{e^{x}-e^{-x}}{2} \\ &amp;amp;=e^{x} \end{align*} $$ ■ 증명 $(5)$ $$ \begin{align*} \cosh x - \sinh x &amp;amp;= \frac{e^{x}+e^{-x}}{2}-\frac{e^{x}-e^{-x}}{2} \\ &amp;amp;=e^{-x} \end{align*} $$ ■ 증명 $(6)$ $$ \begin{align*} \cosh^{2} x</description>
    </item>
    
    <item>
      <title>쌍극자가 만드는 전기장</title>
      <link>https://freshrimpsushi.github.io/posts/electric-field-of-a-diploe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/electric-field-of-a-diploe/</guid>
      <description>점 전기 쌍극자가 만드는 전기장은 다음과 같다.$ \displaystyle \vec{E}_{dip}(r,\theta)=\frac{1}{4 \pi \epsilon_0}\frac{p}{r^3}(2\cos\theta \hat r + \sin\theta \hat \theta)$단, 이는 전기 쌍극자 모멘트 electirc diploe moment $\vec{p}$가 원점에 있고 방향이 $\hat z$일 때의 식이다.(그림 참고)좌표계와 무관하게 사용할 수 있는 공식을 유도하겠다.$\hat{r}= \cos\phi \sin\theta \hat{x} + \sin\phi \sin\theta\hat{y} + \cos\theta\hat z $$ \hat{\theta} = \cos\phi \cos\theta \hat{x} + \sin\phi \cos\theta\hat{y} - \sin\theta\hat z $(참고 : 구면좌표계</description>
    </item>
    
    <item>
      <title>쌍선형변환</title>
      <link>https://freshrimpsushi.github.io/posts/bilinear-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bilinear-transform/</guid>
      <description>정의역에서 등각사상인 $f$ 를 다음과 같이 부른다.(1) 이동Translation : $f(z) = z + \alpha $(2) 확대Magnification : $f(z) = \rho z $(3) 회전Rotation ** : $f(z) = e^{i \theta} z$(4)** **반전**Inversion : $f(z) = {{1} \over {z}} $**(5)** **쌍선형변환**Bilinear Trasform : $\displaystyle f(z) = {{ \alpha z + \beta } \over { \gamma z + \delta }} $이동에서 $\alpha \in \mathbb{C}$ 이고,</description>
    </item>
    
    <item>
      <title>아담스 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/adams-method/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adams-method/</guid>
      <description>멀티스텝 메소드$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) ) = (Y_{0}, \cdots , Y_{p} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b $ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값과 $0 \le p \le m$ 에 대해 $a_{p} \ne 0$ 혹은 $b_{p} \ne 0 $ 이면 다음을 $(p+1)$</description>
    </item>
    
    <item>
      <title>아르마 모형의 가역성</title>
      <link>https://freshrimpsushi.github.io/posts/invertivility-of-arma-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/invertivility-of-arma-model/</guid>
      <description>아르마 모형에 있어서 가역성 을 가졌다 함은 $AR(p)$ 와 $MA(q)$ 가 서로를 표현할 수 있음을 말한다. 일반적인 $ARMA ( p , q)$ 에 대한 수식전개는 아니지만, $AR(1)$ 과 $MA(1)$ 의 예를 살펴보자.(1) $AR(1) \implies MA( \infty ) $$ | \phi | &amp;lt; 1$ 에 대해서 다음의 자기회귀모형 $AR(1)$ 을 생각해보자. $$ Y_{t} = \phi Y_{t-1} + e_{t} $$ $Y_{t-1}$ 역시 $Y_{t-1} = \phi Y_{t-2} + e_{t-1}$ 와 같이 나타낼 수 있으므로 $$ \begin{eqnarray*} Y_{t} &amp;amp;=&amp;amp; \phi ( \phi Y_{t-2} + e_{t-1} ) + e_{t} \\ &amp;amp;=&amp;amp; \phi^2 Y_{t-2} +</description>
    </item>
    
    <item>
      <title>아치 이펙트</title>
      <link>https://freshrimpsushi.github.io/posts/arch-effect-autoregressive-conditional-heteroscedasticity-effect/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arch-effect-autoregressive-conditional-heteroscedasticity-effect/</guid>
      <description>아치 이펙트 란 그 AutoRegressive Conditional Heteroscedasticity라는 말 그대로 &amp;lsquo;자기회귀 조건부 이분산 효과&amp;rsquo;로 순화되기 때문에 순화하지 않는다. 쉽게 말해서 데이터의 변동성이 변하면서, 그 자체가 이전의 데이터로 설명될 수 있는 경우 데이터에 아치 이펙트가 있다고 말한다. 이러한 아치 이펙트를 통계적으로 설명하는 모델을</description>
    </item>
    
    <item>
      <title>악수 렘마 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-handshaking-lemma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-handshaking-lemma/</guid>
      <description>임의의 그래프에서, 모든 버텍스의 차수의 합은 짝수다.이름의 &amp;lsquo;악수&amp;rsquo;는 보다시피 각각의 버텍스가 인접한 버텍스와 악수를 한다고 했을 때, 그 횟수가 바로 차수의 합이기 때문에 붙은 것이다. 증명 그래프 $G$ 에 대해 모든 차수의 합은 정확하게 모든 에지의 수의 두 배여야하므로 $$ \sum_{v \in V(G)} \deg (v) = 2 \left| E(G) \right| $$ ■ 위의 증명에서 곧바로 다</description>
    </item>
    
    <item>
      <title>알고리즘의 비용에 대한 점근적 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/asymptotic-notation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/asymptotic-notation/</guid>
      <description>크기가 $n$ 인 데이터에 대해 알고리즘의 비용을 다음과 같이 나타낸다.1. $O$ 표기법 : $O(g(n)) := \left\{ f(n) , | , \exists c &amp;gt; 0, n_{0} \in \mathbb{N} : \forall n \ge n_{0} \implies f(n) \le c g(n) \right\}$**2. $\Omega$ 표기법** : $\Omega (g(n)) := \left\{ f(n) , | , \exists c &amp;gt; 0, n_{0} \in \mathbb{N} : \forall n \ge n_{0} \implies f(n) \ge c g(n) \right\}$**3. $\Theta$ 표기법** : $\Theta (g(n)) := O (g(n)) \cap \Omega (g(n))$점근적 표기법은 알고리즘의 비용을 수리적으로 나타내는 것으로, 엡실론-델타 논</description>
    </item>
    
    <item>
      <title>앙페르 법칙과 응용</title>
      <link>https://freshrimpsushi.github.io/posts/amperes-law-and-application/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/amperes-law-and-application/</guid>
      <description>앙페르 법칙은 도선에 흐르는 전류와 자기장 사이에 특별한 관계가 있음을 말해주는 법칙이다. 도선에 전류가 흐르면 그 주위로 자기장이 생긴다 . 이 때 자기장의 방향은 &amp;lsquo;오른손 법칙&amp;rsquo;을 따른다. 오른손의 엄지를 전류가 흐르는 방향으로 뒀을 때 손을 말아쥐는 방향이 바로 자기장의 방향이다.앙페르 법칙은 정전기학에서 가우스 법칙</description>
    </item>
    
    <item>
      <title>야코비 세타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/jacobi-theta-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jacobi-theta-function/</guid>
      <description>다음과 같이 정의된 함수 $\vartheta$ 를 야코비 세타 함수 라고 한다. $$ \vartheta (\tau) := \sum_{n \in \mathbb{Z}} e^{-\pi n^{2} \tau } $$ 야코비 함수는 원래 더 일반적으로 정의될 수 있지만, 보통은 필요한 곳에 따라 그냥 특수한 형태를 쓰는 일이 잦다. 여기서 소개된 야코비 세타 함수 역시 정확한 의미에서 모든 맥락을 커버하지는 못한다는 것에 주의하자. $$ \vartheta ( \tau ) = \sqrt{ {{ 1 } \over { \tau }}} \vartheta \left( {{ 1 } \over { \tau }} \right)</description>
    </item>
    
    <item>
      <title>얇은 막대의 관성모멘트 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-interia-of-thin-rod/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-interia-of-thin-rod/</guid>
      <description>길이가 $a$, 질량이 $m$인 막대의 관성모멘트는 회전축이 막대의 끝에 있을 경우 $ I=\frac{1}{3}ma^2 $이고, 회전축이 막대의 중앙에 있을 경우 $I=\frac{1}{12}ma^2$이다.길이가 $a$이고 질량이 $m$인 얇고 균일한 막대의 관성모멘트를 구해보자. 회전축이 막대의 끝에 있는 경우와 막대의 중간에 있는 경우 두가지가 있다.1. 회전축이 막대의</description>
    </item>
    
    <item>
      <title>양자역학에서 내적이란</title>
      <link>https://freshrimpsushi.github.io/posts/1509/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1509/</guid>
      <description>**벡터와 내적 이과생이라면 고등학생 때 벡터와 내적을 아래와 같이 배웠을 것이다.벡터는 크기와 방향을 가지며 좌표 공간위에 점이나 화살표로 나타낼 수 있는 것이다. 내적이란 두 벡터 사이에서 정의되는 연산이다.두 벡터 $\mathbf{a}=(a_1,\ a_2,\ a_3)$, $\mathbf{b} = (b_1,\ b_2,\ b_3)$가 있다고 하자. $\mathbf{a}$와 $\mathbf{b}$의 내적을 $\mathbf{a}\cdot \mathbf</description>
    </item>
    
    <item>
      <title>양자역학에서 연산자란</title>
      <link>https://freshrimpsushi.github.io/posts/operator-in-quantum-mechanics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operator-in-quantum-mechanics/</guid>
      <description>함수해석학에서의 작용소양자역학에서 연산자란 쉽게 말해서 파동 함수에 대해서 원하는 값을 얻기 위해 파동 함수에 어떠한 계산을 하는 것을 말한다. 예를 들어 파동 함수의 에너지를 구하는 계산을 에너지 연산자라고 부른다. 마찬가지로 파동 함수의 운동량을 구하는 계산을 에너지 연산자라고 부른다.주어진 함수의 도함수를 구하는 계산인 $\displaystyle \frac{d}</description>
    </item>
    
    <item>
      <title>어떤 수를 나누는 소수는 그 약수 중 적어도 하나를 나누어야함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/418/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/418/</guid>
      <description>자연수 $ n : = d_{1} d_{2} \cdots d_{r}$ 에 대해 $p \mid n$ 면 $p$ 는 $d_{1} , d_{2} , \cdots , d_{r}$ 중 하나를 나누어야한다.$p \mid n$ 은 $n$ 이 $p$ 의 배수, 즉 $p$ 가 $n$ 을 나눈다는 말이다.언뜻 보면 당연한 소리 같지만 엄연히 증명이 필요한 소수만의 성질이다.소수가 아니라도 위의 정리가 항상 성립하는지 생각해보자. 증명 일단은 $n$ 이 두 자연수의 곱, 즉 $n = ab$ 라 두고 $p$ 가 $a$ 와 $b$ 둘 다를 나누지</description>
    </item>
    
    <item>
      <title>어트랙팅 셋의 베이신</title>
      <link>https://freshrimpsushi.github.io/posts/basin-of-attracting-set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/basin-of-attracting-set/</guid>
      <description>베이신 1공간 $X$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $\phi(t, \cdot)$ 은 벡터 필드 $x&#39; = f(x)$ 의 플로우, $g^{n}$ 는 맵 $g$ 를 $n$ 번 취한 맵을 나타내도록 하자.다음과 같이 정의된 집합들을 어트랙팅 셋 $A$ 의 베이신 이라고 한다.V. $\displaystyle \bigcup_{t \le 0} \phi ( t, U )$**M.** $\displaystyle \bigcup_{n \le 0} g^{n} ( U )$베이신은 우리에게 익숙한 단어가 아닌데, 정의 그</description>
    </item>
    
    <item>
      <title>에너지가 포텐셜보다 작을 때 시간에 무관한 슈뢰딩거 방정식의 해가 없음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/360/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/360/</guid>
      <description>시간에 무관한 슈뢰딩거 방정식의 해를 찾을 때 에너지가 포텐셜보다 작은 구간에서는 해가 없다.즉, 파동함수가 존재하지 않는다.이는 파동함수라면 규격화가능해야 한다는 조건으로 증명할 수 있다.규격화 가능하다는 말은 제곱적분가능$\mathrm{Square\ Integrable}$하다는 말이고 이는 파동함수를 구간 전체에서 제곱적</description>
    </item>
    
    <item>
      <title>에르미트 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/herimite-polynomial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/herimite-polynomial/</guid>
      <description>에르미트 다항식은 아래의 두 방법으로 얻을 수 있다. 첫번째 방법은 에르미트 함수로부터 얻는 것이다.아래의 에르미트 함수 $$ y_n=e^{\frac{x^{2}}{2}}\frac{ d ^{n} }{ dx^{n} }e^{-x^{2}} $$ 에 $(-1)^{n}e^{\frac{x^{2}}{2}}$를 곱한 것을 에르미트 다항식 이라 한다. $$ H_{n}(x)=(-1)^{n}e^{x^{2}}\frac{ d ^{n}}{ dx^{n} }e^{-x^{2}} \tag{1} $$ 위 식은 에르미트 다항식의 **로드리게스 공식** 이라고도 불린다.두번째 방법</description>
    </item>
    
    <item>
      <title>에르미트 다항식의 생성 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-generating-function-of-hermite-polynomial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-generating-function-of-hermite-polynomial/</guid>
      <description>에르미트 다항식의 생성 함수는 아래와 같다. $$ \Phi (x,t)=\sum \limits {n=0}^{\infty} \frac{H{n}(x)}{n!}t^{n}= e^{2xt-t^{2}} $$ $H_{n}(x)$는 에르미트 다항식이며 에르미트 함수 $y_{n}=e^{\frac{x^{2}}{2}}\frac{ d ^{n} }{ d x^{n} }e^{-x^{2}}$에 $(-1)^{n}e^{\frac{x^{2}}{2}}$를 곱해서 얻거나 에르미트 미분 방정식을 풀어서 얻을 수 있다. $$ H_{n}(x)=(-1)^{n}e^{x^{2}}\frac{ d ^{n}}{ dx^{n} }e^{-x^{2}} $$ 에르미트 다항식의 생성함수란 쉽게 말</description>
    </item>
    
    <item>
      <title>에르미트 다항식의 재귀 관계</title>
      <link>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-hermite-polynomial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-hermite-polynomial/</guid>
      <description>에르미트 다항식은 아래와 같은 재귀 관계를 만족한다. $$ \leqalignno{ H_{n}&#39;(x) &amp;amp;=2nH_{n-1}(x) &amp;amp; (a) \\ H_{n+1}(x) &amp;amp;= 2xH_{n}(x)-2nH_{n-1}(x)&amp;amp; (b) \\ &amp;amp;=2xH_{n}(x)-H_{n}&#39;(x) } $$ 에르미트 다항식 $$ H_{n}(x)=(-1)^{n}e^{x^{2}}\frac{ d ^{n}}{ dx^{n} }e^{-x^{2}} $$ 에르미트 다항식의 생성함수 $$ \Phi (x,t) = e^{2xt-t^{2}}=\sum \limits _{n=0}^{\infty} H_n(x)\frac{t^{n}}{n!} \tag{1} $$ 증명 $(a)$ 생성함수를 이용한 풀이 $(1)$의 가운데, 오른쪽 식을 $x$에 대해서 미분하면 $$ 2te^{2xt-t^{2}}=\sum \limits {n=0}^{\infty}H{n}&#39;(x)\frac{t^{n}}{n!} $$ 그러면 좌변은 다시 $(1)$에 의해서 $$ 2t\sum \limits _{n=0}^{\infty} H_n(x)\frac{t^{n}}{n!}=2te^{2xt-t^{2}}=\sum \limits {n=0}^{\infty}H{n}&#39;(x)\frac{t^{n}}{n!} $$ 이를 정리하면 $$</description>
    </item>
    
    <item>
      <title>에르미트 다항식의 직교성</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-of-hermite-polynomials/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-of-hermite-polynomials/</guid>
      <description>에르미트 다항식 $H_{0}(x),H_{1}(x),H_{2}(x),\cdots $은 구간 $[-\infty, \infty]$에서 가중 함수 $w(x)=e^{-x^{2}}$에 대해서 서로 직교한다. 즉, 다시 말해서 $$ &amp;lt;H_{n}|H_{m}&amp;gt; =\int_{-\infty}^{\infty}e^{-x^{2}}H_{n}(x)H_{m}(x)dx=\sqrt{\pi}2^{n}n!\delta_{nm} $$ $&amp;lt;|&amp;gt;$는 디락 노테이션, $\delta_{nm}$은 크로네커 델타이다.에르미트 다항식의 재귀 관계 $$ H_{n}&#39;(x) =2nH_{n-1}(x) $$ 증명 $n=m$인 경우 가독성을 위해서 미분 연산자 $D=\frac{ d }{ d</description>
    </item>
    
    <item>
      <title>에르미트 미분 방정식의 급수해 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/series-solution-of-hermite-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-solution-of-hermite-differential-equation/</guid>
      <description>**에르미트 미분 방정식 $$ y&#39;&#39;-2xy&#39;+2ny=0,\quad n=0,1,2,\cdots $$ 의 해를 에르미트 다항식 이라 부르고 $H_{n}(x)$으로 표기한다. $$ \begin{align*} H_{0}(x)&amp;amp;=1 \\ H_{1}(x) &amp;amp;=2x \\ H_{2}(x) &amp;amp;=4x^{2}-2 \\ H_{3}(x)&amp;amp;=8x^{3}-12x \\ H_{4}(x) &amp;amp;= 16x^{4}-48x^{2}+12 \\ H_{5}(x) &amp;amp;= 32x^{5}-160x^{3}+120x \\ &amp;amp;\vdots \end{align*} $$ 에르미트 함수를 살짝 바꾸어 에르미트 다항식을 얻는 등 에르미트 미분 방정식을 푸는 방법은 여러가지가 있지만 본 글에서는 급수해 풀이를 소개한다. **풀이 아래와 같은 미분 방정식이 주어졌</description>
    </item>
    
    <item>
      <title>에르미트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-function/</guid>
      <description>에르미트 함수는 다음과 같다. $$ \begin{align} y_{n} &amp;amp;= \left( D-x \right)^{n} e^{-\frac{x^{2}}{2}} \\ &amp;amp;=e^{\frac{x^{2}}{2}} D^{n} e^{-x^{2}} \end{align} $$ 이때 $D=\frac{d}{dx}$는 미분 연산자이다. 에르미트 함수는 미분 방정식 $$ y_{n}&#39;&#39;-x^{2}y_{n}=-(2n+1)y_{n},\quad n=0,1,2,\cdots $$ 의 해이며 물리학에서 1차원 조화진동자 슈뢰딩거 방정식의 해이다. 즉 1차원 조화 진동자의 파동함수이다. $(1)$은 미분 방정식을 풀어서 직접 얻을 수 있다. $(2)$가 $(1)$</description>
    </item>
    
    <item>
      <title>에르미트 함수가 만족하는 미분 방정식의 연산자 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/operator-solution-of-differential-equation-satisfied-by-hermite-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operator-solution-of-differential-equation-satisfied-by-hermite-function/</guid>
      <description>주어진 미분 방정식 $$ y_{n}&#39;&#39;-x^{2}y_{n}=-(2n+1)y_{n},\quad n=0,1,2,\cdots $$ 의 해는 아래와 같으며 에르미트 함수라 부른다. $$ \begin{align*} y_{n} &amp;amp;= \left( D-x \right)^{n} e^{-\frac{x^{2}}{2}} \\ &amp;amp;=e^{\frac{x^{2}}{2}} D^{n} x^{-x^{2}} \end{align*} $$ 이때 $D$는 미분 연산자 $D=\frac{ d }{ dx }$이다.$y_{n}$의 첫번째 식은 미분 방정식을 풀어서 직접 얻을 수 있다. 두번째 식이 첫번째 식과 같음은 수학적 귀납법을 통해 증명할 수 있다.**풀이 미분 연산자의 성질 $(e)$, $(f)$에 의해 주어진 미</description>
    </item>
    
    <item>
      <title>에이전트 기반 시뮬레이션 첫걸음 산점도로 나타내기</title>
      <link>https://freshrimpsushi.github.io/posts/tutorial-on-agent-based-simulation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tutorial-on-agent-based-simulation/</guid>
      <description>본 시뮬레이션은 속도와 시각화 양면으로 유리하고 코딩도 쉬운 줄리아로 구현되어 있다. 가장 좋은 공부는 깃허브에서 줄리아 코드를 받아 직접 실행해보는 것이지만, 줄리아가 낯설다면 그냥 시뮬레이션을 어떻게 하는건지 읽고 이해만 해도 충분할 수 있다. 구현 자체에 있어 어떤 언어를 사용하느냐는 본질적으로 중요하지 않다. 소스 코드 Step 1. 패키지 로드, 초기</description>
    </item>
    
    <item>
      <title>연결 공간에 대한 전사 연속함수의 상은 연결 공간임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/462/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/462/</guid>
      <description>연결 공간 $X$ 에 대해 $f : X \to Y$ 가 전사 연속함수면 $Y$ 는 연결 공간이다.연결과 연속처럼 비슷한 말이 섞여있어서 조금 헷갈릴 수도 있다. 대개는 영어로 외우면 해결되지만 이 정리에 쓰이는 영단어는 Connected 와 Continuous기 때문에 큰 도움은 되지 않는다. 증명 $Y$ 가 연결 공간이 아니라고 가정하면 $$ A \cap B = \emptyset \\ A \cup B = Y $$ 를 만족하는 열린 진부분집합</description>
    </item>
    
    <item>
      <title>연결 공간의 여러가지 동치조건</title>
      <link>https://freshrimpsushi.github.io/posts/461/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/461/</guid>
      <description>위상공간 $X$ 에 대해 부분집합 $A \subset X$ 가 $A \ne \emptyset$ 이고 $A \ne X$ 면 $A$ 를 $X$ 의 진부분집합Proper Subset 이라고 한다. 한편 두 진부분집합 $A,B$ 에 대해 $\overline{A} \cap B = \emptyset$ 이고 $A \cap \overline{B} = \emptyset$ 이면 $A$ 와 $B$ 를 분리 집합Separated Set 이라고 한다.분리 집합은 그냥 분리Separation 로 불리기도 한다.위의 정의를 포함해서 연결 공간의 여러가지 동치조건을 찾을 수</description>
    </item>
    
    <item>
      <title>연립방정식으로 이해하는 계수rank와 퇴화차수</title>
      <link>https://freshrimpsushi.github.io/posts/nullity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/nullity/</guid>
      <description>역사적으로는 행렬이 고안된 배경 자체가 연립방정식을 보다 쉽고 편하게 표기하기 위함이었다. 예를 들어 연립방정식 $\begin{cases} 2x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; + &amp;amp; x_{3} &amp;amp; = &amp;amp; 0 \\ &amp;amp; &amp;amp; x_{2} &amp;amp; &amp;amp; &amp;amp; = &amp;amp; 0 \end{cases}$ 을 잘 보면, 같은 변수를 여러번 써야한다는 불편함이 있다. 이를 행렬로 나타내면 $\begin{bmatrix} 2 &amp;amp; 1 &amp;amp; 1 \\ 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} x_{1} \\ x_{2} \\ x_{3} \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix} $ 와 같이 각 잡힌 모양으로 깔끔하게 나</description>
    </item>
    
    <item>
      <title>영인자 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/zero-divisor-graph/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zero-divisor-graph/</guid>
      <description>가환 링 $R$ 이 주어져 있다고 하자. $R$ 의 영인자 집합을 $Z(R)$ 이라고 할 때, 다음과 같이 정의된 그래프 $\Gamma (R)$ 을 $R$ 에 대한 영인자 그래프라고 한다. $$ V \left( \Gamma(R) \right) = Z(R) \\ E( \Gamma(R)) = \left\{ ab : ab=0 \right\} $$ 알다시피 영인자끼리 곱한다고해서 반드시 $0$ 이 되는 것은 아니다. 예로써, $ 2, 4 \in Z \left( \mathbb{Z}{10} \right)$ 는 $\mathbb{Z}{10}$ 의 영인자가 맞지만 그 곱은 $8 \ne 0$ 이다. 따라서 주어지는 가환 링 $R$ 에 따른 영인</description>
    </item>
    
    <item>
      <title>옌센 부등식의 기댓값 폼 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-expectation-form-of-jensens-inequality/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-expectation-form-of-jensens-inequality/</guid>
      <description>옌센 부등식의 유한 폼 보기옌센 부등식의 적분 폼 보기조건부 옌센 부등식개구간 $I$ 에서 함수 $\phi$ 가 컨벡스하고 두 번 미분가능, 확률변수 $X$의 기댓값 $\mu$ 가 존재하며 $X \subset I $ 면 $$ \phi [ E(X) ] \le E [ \phi(X)] $$ 적분 폼과는 상당히 유사한 형태를 가지고 있다. 잘 생각해보면 유한 폼 역시 항이 무한하지는 않지만 가중평균의 부등식이라는 센스에서 기댓값이라고 볼 수 있겠</description>
    </item>
    
    <item>
      <title>옌센 부등식의 유한 폼 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-finite-form-of-jensens-inequality/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-finite-form-of-jensens-inequality/</guid>
      <description>옌센 부등식의 적분 폼 보기옌센 부등식의 기댓값 폼 보기$I \subset \mathbb{R}$ 에서 컨벡스 함수 $f : I \to \mathbb{R}$ 와 $\displaystyle \sum_{k=1}^{n} \lambda_{k} = 1, \lambda_{k}&amp;gt;0$ 에 대해 $f( \lambda_{1} x_{1} + \lambda_{2} x_{2} + \cdots + \lambda_{n} x_{n} ) \le \lambda_{1} f( x_{1}) + \lambda_{2} f( x_{2}) + \cdots + \lambda_{n} f( x_{n} ) $옌센의 부등식은 컨벡스 함수의 대표적인 응용으로써 여러 분야에서 폭넓게 사용되고 있다.유한 폼은 원래 컨벡스의 정의에서 점의 갯수와 가중치에 대해 일반화가 이루어진 모양</description>
    </item>
    
    <item>
      <title>옌센 부등식의 적분 폼 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-integral-form-of-jensens-inequality/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-integral-form-of-jensens-inequality/</guid>
      <description>옌센 부등식의 유한 폼 보기옌센 부등식의 기댓값 폼 보기Convex 함수 $ \phi : [a,b] \to \mathbb{R}$ 와 $f: [0,1] \to [a,b]$ 에 대해, $\phi \circ f$ 이 $[0,1]$ 에서 적분가능하면 $ \displaystyle \phi \left( \int_{0}^{1} f(x) dx \right) \le \int_{0}^{1} (\phi \circ f ) (x) dx $당연하지만 주어진 조건만 만족한다면 치환 등을 통해서 적분 구간 역시 바꿀 수 있다.유한 폼이 정의를 이용해 항의 갯수를 일반화 한 것과 달리 적분 폼은 함수가 적분 기호를 넘나드는</description>
    </item>
    
    <item>
      <title>오일러 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/eulerian-graph/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eulerian-graph/</guid>
      <description>모든 버텍스를 포함하는 닫힌 패스가 존재하는 그래프 : 헤밀톤 그래프$G$ 가 연결 그래프라고 하자.$G$ 의 모든 에지를 포함하는 닫힌 트레일이 존재하면 $G$ 를 오일러 그래프 라 하고 그 트레일을 오일러 트레일 이라 한다. 모든 에지를 포함하지만 닫혀있지 않은 트레일이 존재하면 $G$ 를 세미 오일러 그래프 라한다.우리에게는 한 붓 그리기 문제로도 익숙한 개념</description>
    </item>
    
    <item>
      <title>오일러 상수는 무리수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-e/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-e/</guid>
      <description>$\pi$ 의 경우$e \notin \mathbb{Q}$* $\mathbb{Q}$ 는 유리수의 집합을 나타낸다.**Strategy** : 매클로린 전개를 통해 $e^{-1}$ 를 두 파트로 찢고 모순을 이끌어낸다. 매클로린 전개를 사용해야하기 때문에 고등학교 교과과정 내에서는 증명할 수 없다. 증명 $\mathbb{N}$ 는 자연수의 집합, $\mathbb{Z}$ 는 정수의 집합을 나타낸다.Part 1. $x_{1} = x_{2} $$ e \in \mathbb{Q}$ 이라고 가정하면 오일러 상수 $e$ 는 어떤 $a,b \in</description>
    </item>
    
    <item>
      <title>오일러의 반사 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-eulers-reflection-formula/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-eulers-reflection-formula/</guid>
      <description>**오일러 반사 공식 정수가 아닌 $p$ 에 대해 $$ \displaystyle {\Gamma (1-p) \Gamma ( p )} = { {\pi} \over {\sin \pi p } } $$ 감마함수를 이용한 공식 중 가장 유명한 공식이다.반사 공식으로 얻을 수 있는 유용한 결과로는 $ \Gamma ( { 1 \over 2} ) = \sqrt{\pi}$ 이 있다. 그래서일까? 반사 공식이라는 이름 또한 $\frac{1}{2}$ 에 대해 반사 시킨다는 의미에서 붙었다고 한다. 유도 바이어슈트라스의 무한곱 $$ \displaystyle {1 \over \Gamma(p)} = p e^{\gamma p }</description>
    </item>
    
    <item>
      <title>오일러의 완전수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-perfect-number-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-perfect-number-theorem/</guid>
      <description>짝수 $n = 2^{p-1} (2^p - 1)$ 가 완전수면 $2^{p}-1$ 는 메르센 소수다.언뜻 보면 유클리드완전수 공식의 역이 되는 것 같지만 짝수에 대해서만 언급되었다는 점이 다르다.그러나 이 정리는 완전수의 거의 모든 것을 말해주고 있는데, 실제로 홀수 완전수는 아직 발견된 적이 없기 때문이다.현재까지 홀수 완전수에 대해 밝혀진 사실이라고는 &amp;lsquo;존재한다면 아주 클 것이다</description>
    </item>
    
    <item>
      <title>완전 미분방정식의 정의와 판별법</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-method-of-determination-of-exact-differential-equations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-method-of-determination-of-exact-differential-equations/</guid>
      <description>완전 미분방정식의 풀이완전 미분방정식 주어진 미분방정식 $$ M(x,y)+N(x,y)y^\prime=0 $$ 에서 $$ \dfrac{\partial \psi }{\partial x}=M(x,y) \quad \And \quad \dfrac{\partial \psi }{\partial y}=N(x,y) $$ 를 만족하는 $\psi=\psi(x,y)$가 존재하면 이 미분방정식을 완전하다고 말하며, 이 미분방정식을 완전 미분방정식이라고 한다.주어진 미분방정식이 완전 미분방정식이면 미분방정식을 $\psi(x,y)$에 대한 전미분$(\m</description>
    </item>
    
    <item>
      <title>완전 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-exact-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-exact-differential-equation/</guid>
      <description>주어진 미분방정식이 $M(x,y)+N(x,y)\dfrac{dy}{dx}=0$이 판별법에 의해 완전하다면 풀이는 아래와 같다.Step 0. 주어진 미분방정식이 완전하므로 $\psi_x=M,\ \ \psi_y=N, \ \ \psi=c$인 $\psi$가 존재한다.Step 1. $\psi_x$를 적분한다. 그 후 얻은 $\psi$를 다시 $y$로 미분하여 $h^\p</description>
    </item>
    
    <item>
      <title>완전 탄성 충돌과 운동에너지 보존</title>
      <link>https://freshrimpsushi.github.io/posts/466/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/466/</guid>
      <description>반발계수$e$가 $1$일 때 완전 탄성 충돌이라 한다.완전 탄성 충돌에는 중요한 특징이 두가지 있다.$1.$ 충돌 전 후의 각 물체의 운동에너지 합이 보존된다.$2.$ 두 물체의 질량이 같으면 충돌 후 속도가 서로 교환된다.$1.$증명 운동량 보존 법칙과 반발계수 식을 이용해서 증명한다.운동량 보존 법칙$m_1v_1+m_2v_2 = m_1{v_1}&#39;+m_2{v_2}&#39; $$ \Rightarrow</description>
    </item>
    
    <item>
      <title>운동량 보존 법칙 쉬운 증명고등학교 수준</title>
      <link>https://freshrimpsushi.github.io/posts/464/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/464/</guid>
      <description>외력이 작용하지 않으면 힘(내력)의 작용 전후의 운동량 총합은 일정하다. 쉽게 말해 두 물체가 충돌할 때 충돌 전 각 물체의 운동량 합과 충돌 후 각 물체의 운동량 합은 같다. $$ m_1v_1+m_2v_2=m_1{v_1}&#39;+m_2{v_2}&#39; $$ 증명** (고등학교 수준)$(1)$ 두 물체 $A, B$가 충돌할 때 작용반작용의 법칙에 의해 서로가 서로에게 주는 힘은 크기는 같고 방향은 반대이다. $F=F_{AB}$ $A$가 $ B$에게 주는 힘</description>
    </item>
    
    <item>
      <title>운동량 연산자와 위치의 교환자</title>
      <link>https://freshrimpsushi.github.io/posts/commutator-of-momentum-operator-and-position/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/commutator-of-momentum-operator-and-position/</guid>
      <description>위치와 운동량 연산자의 교환자는 다음과 같다.**표준교환관계식$(\mathrm{canonical\ commutation\ relation})$ $$ [p,x]=-i\hbar $$ $$ [x,p]=i\hbar $$ 정규교환관계식, 정준교환관계식 등으로 부르기도 한다. 이름이 중요한 건 아니다.미분 표기를 아래와 같이 간단히 나타내겠다. $$ \frac{ d }{ d x}=D_{x},\quad \frac{ d f}{ d x}=f_{x}, \quad D_{x}f=f_{x} $$ 증명 운동량 연산자는 $p=-i\hbar \dfrac{ d }{ d x }=-i\hbar D_{x}$이므</description>
    </item>
    
    <item>
      <title>운동량Momentum의 기댓값Expectation value이 항상 실수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/199/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/199/</guid>
      <description>운동량 연산자의 기댓값$ \langle p \rangle $은 항상 실수이다증명 운동량의 기댓값은 아래와 같다.$ \displaystyle \langle p \rangle = \int \psi^{ * } \left( \frac{\hbar}{i}\frac{\partial}{\partial x} \right) \psi dx$또한 운동량의 기댓값의 복소 켤레는 다음과 같다.$ \displaystyle \langle p \rangle ^{ * }= \int \psi \left( \frac{\hbar}{-i}\frac{\partial}{\partial x} \right) \psi^{ * } dx$두 값을 빼서 0이라면 증명 끝$ \begin{eqnarray*} \langle p \rangle -\langle p \rangle ^{ * } &amp;amp;=&amp;amp; \frac{\hbar}{i} \int \left( \psi^{ * } \frac{\partial \psi}{\partial x}+\psi\frac{\partial \psi^{ * }}{\partial x} \right) dx \\ &amp;amp;=&amp;amp;\frac{\hbar}{i} \int \frac{\partial}{\partial x} \left( \psi^{ * } \psi \right) dx \\ &amp;amp;=&amp;amp;\frac{\hbar}{i}</description>
    </item>
    
    <item>
      <title>원시근 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-primitive-root-thoerem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-primitive-root-thoerem/</guid>
      <description>$1 \le a \le p$ 가 $\text{ord}_{p} (a) = p-1$ 를 만족하면 법 $p$ 의 원시근 이라고 정의한다. 모든 소수 $p$ 는 $\phi ( p - 1)$ 개의 원시근을 갖는다.* $\text{ord}_{p} (a) $ 는 $a^{e} \equiv 1 \pmod{p} $ 를 만족하는 가장 작은 자연수 $e$ 를 의미한다.$\text{ord}_{p} (a) = p-1$ 를 만족하는 $a$ 를 원시근이라고 부르는 이유는 페르마의 소정리에 의해 $a^{p-1} \equiv 1 \pmod{ p } $ 이므로 $\text{ord}_{p} (a) \le p-1$ 임은 보장되어 있는데,</description>
    </item>
    
    <item>
      <title>원판 원통의 관성모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-circular-disc-cylinder/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-circular-disc-cylinder/</guid>
      <description>공식 반지름이 $a$, 질량이 $m$인 원판의 관성모멘트는 다음과 같다. 회전축이 원판에 수직한 경우 $$ I=\frac{1}{2}ma^2 $$ 회전축이 원판과 수평인 경우 $$ I=\frac{1}{4}ma^2 $$ 회전축이 원판의 중심을 지나고, 원판에 수직하는 경우 $\rho$를 단위면적당 질량이라고 하자. 그러면 원판의 질량은 $m=\rho \pi r^2$. 따라서 $$ dm=\rho \pi 2r dr $$ 관성모멘트를 구하는 식은 $ \displaystyle I=\int r^2dm$이므로 $$ I=\int_0^a\rho \pi 2</description>
    </item>
    
    <item>
      <title>월리스 곱</title>
      <link>https://freshrimpsushi.github.io/posts/wallis-product/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/wallis-product/</guid>
      <description>$$ \displaystyle \prod_{n=1}^{\infty} {{4n^2} \over {4n^2 - 1}} = \lim_{n \to \infty} {{2 \cdot 2 } \over { 1 \cdot 3 } } \cdot {{4 \cdot 4 } \over { 3 \cdot 5 } } \cdot \cdots \cdot {{2n \cdot 2n } \over { (2n-1) \cdot (2n+1) } } = {{ \pi } \over {2}} $$ 급수뿐만이 아니라 곱으로도 원주율을 구할 수 있다는 건 두말할 것도 없이 신기하고 유용한 사실이다.본디 증명은 이보다 어렵고 사실상 싱크함수의 오일러 표현을 증명하는 과정에 포함되어 있다고 볼 수 있다. 증명 싱크함수의 오</description>
    </item>
    
    <item>
      <title>위너 프로세스</title>
      <link>https://freshrimpsushi.github.io/posts/wiener-process/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/wiener-process/</guid>
      <description>$s&amp;lt; t &amp;lt; t+u$ 라고 할 때, 다음의 조건들을 만족하는 확률과정 $\left\{ W_{t} \right\}$ 를 **위너 프로세스** 라고 한다. **(i)** $W_{0} = 0$ **(ii)** $\left( W_{t+u} - W_{t} \right) \perp W_{s}$ **(iii)** $\left( W_{t+u} - W_{t} \right) \sim N ( 0, u )$ **(iv)** $W_{t}$ 의 샘플 패스는 거의 어디서나 연속이다. 위너 프로세스는 **브라운 운동**Brownian Motion 이라고도 불린다. (ii) $\left( W_{t+u} - W_{t} \right) \perp W_{s}$ 이고 **(iii)** 인크리먼트가 정규분포 $N(0,t)$ 를 따른다는 것은 위너</description>
    </item>
    
    <item>
      <title>위상 동형 사상은 기저를 보존함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-homeomorphism-perserve-basis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-homeomorphism-perserve-basis/</guid>
      <description>**위상 동형 사상은 기저를 보존한다. 두 위상공간 $X$, $Y$와 둘 사이의 위상동형사상 $f$가 주어졌다고 하자. $$ f\ :\ X \rightarrow Y $$ $\mathcal{B}_X$를 $X$의 기저라고 하면 $f(\mathcal{B}X)$는 $Y$의 기저가 된다.집합 $X$에 대해서 아래의 두 조건을 만족하는 $X$의 부분집합의 컬렉션 $\mathca</description>
    </item>
    
    <item>
      <title>위상공간과 부분공간에서 내부에 대한 여러 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-for-interior-in-topological-space-and-subspace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-for-interior-in-topological-space-and-subspace/</guid>
      <description>위상공간 $(X,\mathcal{T})$와 부분집합 $A,B,A_{\alpha}\subset X\ (\alpha \in \Lambda)$가 주어졌다고 하자. 그러면$(a1)$ $A\subset B$이면 $A^{\circ} \subset B^{\circ}$이다.$(b1)$ $A^{\circ}\cup B^{\circ} \subset (A\cup B)^{\circ} $$ (c1)$ $A^{\circ} \cap B^{\circ} = (A\cap B)^{\circ} $$ (d1)$ $(\cap_{\alpha\in\Lambda}A_{\alpha})^{\circ} \subset \cap _{\alpha \in \Lambda} A_{\alpha}^{\circ} $$ A^{\circ}$은 집합 $A$의 내부이다. 증명 ** **$(a1)$ $x \in A^{\circ}$이라고 하자.</description>
    </item>
    
    <item>
      <title>위상수학에서 연결성이란</title>
      <link>https://freshrimpsushi.github.io/posts/connectedness/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/connectedness/</guid>
      <description>위상공간 $X$ 에서 $A \cap B = \emptyset$ 과 $A \cup B = X$ 을 만족하는 열린 집합 $A \ne \emptyset$, $B \ne \emptyset$ 이 존재하면 $X$ 를 비연결Disconnected 공간이라고 한다. 비연결공간이 아니면 연결Connected 공간이라고 한다.[1] 연결성은 위상적 성질이다.[2] 모든 자명공간은 연결 공간이다.[3] 모든 이산공간은 비연결 공간이다.[4] 모든 홑원소집</description>
    </item>
    
    <item>
      <title>위상수학에서의 기저와 국소기저</title>
      <link>https://freshrimpsushi.github.io/posts/basis-and-local-basis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/basis-and-local-basis/</guid>
      <description>위상공간 $\left( X , \mathscr{T} \right) $ 에 대해 $\mathscr{B} , \mathscr{B}{x} \subset \mathscr{P}(X)$ 라고 하자.1. $B{\lambda} \in \mathscr{B}$ 이라고 할 때, 모든 $ U \in \mathscr{T}$ 에 대해 $\displaystyle U = \bigcup_{\lambda \in \Lambda} B_{ \lambda } $ 를 만족하는 $\Lambda$ 가 존재하면 $\mathscr{B}$ 를 $\mathscr{T}$ 에 대한 **기저**Basis 라고 한다. 이 때 위상 $\mathscr{T}$ 는 $\mathscr{B}$ 에 의해 **생성된다** 고 한다.**2.** $x \in X$ 라고 할 때, 모든 $B \in \mathscr{B}_{x}$ 에 대해 $x \in B$ 이고 $x$ 를 포함하는 모든 $U \in \mathscr{T}$ 에 대해 $x</description>
    </item>
    
    <item>
      <title>위상수학에서의 부분기저</title>
      <link>https://freshrimpsushi.github.io/posts/subbasis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subbasis/</guid>
      <description>위상공간 $\left( X , \mathscr{T} \right)$ 에 대해 $\mathscr{S} \subset \mathscr{T} $ 이라고 하자. $\displaystyle \mathscr{B} = \left\{ \left. B = \bigcap_{ i = 1}^{n} S_{i} , \right| , S_{i} \in \mathscr{S} \right\} $ 가 $\mathscr{T}$ 의 기저가 될 때, $\mathscr{S}$ 를 $\mathscr{T}$ 의 **부분기저**Subbasis 라고 한다.부분기저를 받아들이기 어려운 이유는 보통 수학에서 &amp;lsquo;부분&amp;rsquo;을 붙일 때는 부분집합이면서 원래의 성질을 유지하기 때문이다.부분군이라면 부분집</description>
    </item>
    
    <item>
      <title>윈도에서 파이썬 텐서플로우 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-tensorflow-in-windows/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-tensorflow-in-windows/</guid>
      <description>텐서플로우를 설치할 때 문제가 생기는 경우는 보통 파이썬을 잘못 설치했기 때문이다.시작하기 전에 파이썬을 삭제하고 처음부터 다시 시작하거나, 가능하다면 컴퓨터를 한 번 밀어두는 것을 추천한다.Step 1. 파이썬Step 1-1. 비트 확인제어판/모든 제어판 항목/시스템 혹은 내 PC(우클릭)-속성을 통해 시스템 정보를 확인하자.요즘은 대개 64</description>
    </item>
    
    <item>
      <title>윈도우에서 ssh 서버 구축하는 법 How to construct ssh server in windows</title>
      <link>https://freshrimpsushi.github.io/posts/1445/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1445/</guid>
      <description>윈도우는 10 버전에 들어 파워쉘PowerShell을 비롯하여 리눅스 특유의 편의 기능을 많이 제공하게 되었다. ssh 서버의 경우 GUI를 통해 아주 간단하게 설치할 수 있다.Step 1. 앱 및 기능Win+S 를 눌러 프로그램 추가/제거 나 앱 및 기능 을 찾아 선택적 기능 을 클릭한다.Step 2. OpenSSH 서버 설치기능 추가를 클릭하고 OpenSSH 서버 를 설치한다.Ste</description>
    </item>
    
    <item>
      <title>유전체와 편극밀도</title>
      <link>https://freshrimpsushi.github.io/posts/dielectrics-and-polarization-density/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dielectrics-and-polarization-density/</guid>
      <description>도체 속에는 자유전하가 아주 많다. 수 많은 전자들이 특정한 원자핵에 구속되지 않고 자유롭게 물질 내부를 돌아다닌 다는 뜻이다.이에 반해 유전체($\mathrm{dielectrics}$, 혹은 절연체$\mathrm{insulator}$) 는 모든 전자가 특정 원자(분자)에 구속돼있다. 분자 속에서 조금 움직이는 것은 가능하나 자</description>
    </item>
    
    <item>
      <title>유체와 압력</title>
      <link>https://freshrimpsushi.github.io/posts/fluid-and-pressure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fluid-and-pressure/</guid>
      <description>흔히 물질의력 상태를 고체, 액체, 기체 3가지로 분류한다. 이 때, 액체와 기체를 유체라고 한다. 유체라는 한자어를 직역하면 ‘흐르는 것’이고 제 모양을 가지고 있지 않은 상태라고 생각하면 되겠다. 초등학생 때 배웠던 말로 설명하면 모양이 일정하지 않고 담는 그릇에 따라 모양 바뀌는 게 유체이다. 유체의 압력 이란? 유체가 단위면적당 작용하는 힘을 압력</description>
    </item>
    
    <item>
      <title>유체와 유체역학의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-fluid-and-fluid-mechanics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-fluid-and-fluid-mechanics/</guid>
      <description>유체 란?$(a)$ 액체와 기체를 합쳐서 부르는 말$(b)$ 정지상태에서는 수직 응력이 작용하고, 유동 상태에서는 전단력이 미치면 연속적으로 변형이 일어나서 흐르는 물질1정의라고는 하나 그렇게 엄밀한 것은 아니다. 하지만 엄밀한 정의를 들이밀지 않아도 우리는 유체가 무엇인지 안다. 그거면 충분하다. 유체가 가지는 일반적인 성질로 유동성과 점</description>
    </item>
    
    <item>
      <title>유클리드 공간에서 내적이란</title>
      <link>https://freshrimpsushi.github.io/posts/inner-product-in-euclidean-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inner-product-in-euclidean-space/</guid>
      <description>벡터공간 $V = \mathbb{R}^n$ 에 대해 $\mathbb{x}, \mathbb{y}, \mathbb{z} \in V$ 그리고 $k \in \mathbb{R}$ 이라고 하자. $\left&amp;lt; , , \right&amp;gt; : V^2 \to \mathbb{R} $ 가 아래 네 조건들을 만족시킬 때 $\left&amp;lt; , , \right&amp;gt;$ 를 $V$ 상에서의 내적 으로 정의한다.(1) 대칭성 : $\left&amp;lt; \mathbb{x} , \mathbb{y} \right&amp;gt; = \left&amp;lt; \mathbb{y}, \mathbb{x} \right&amp;gt;$(2) 가산성 : $\left&amp;lt; \mathbb{x} + \mathbb{y} , \mathbb{z} \right&amp;gt; = \left&amp;lt; \mathbb{x}, \mathbb{z} \right&amp;gt; + \left&amp;lt; \mathbb{y}, \mathbb{z} \right&amp;gt;$(3) 동질성 : $ \left&amp;lt; k \mathbb{x} , \mathbb{y} \right&amp;gt; = k \left&amp;lt; \mathbb{x}, \mathbb{y} \right&amp;gt;$(4) 정부호 : $\left&amp;lt; \mathbb{x} , \mathbb{x} \right&amp;gt; \ge 0$ 그리고 $\left&amp;lt; \mathbb{x} , \mathbb{x} \right&amp;gt; =0 \iff \mathb</description>
    </item>
    
    <item>
      <title>유클리드 공간이란</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-an-euclidean-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-an-euclidean-space/</guid>
      <description>정의 유클리드 공간 $$ \mathbb{R}^{n} = \mathbb{R} \times \cdots \times \mathbb{R} $$ 자연수 $n \in \mathbb{N}$ 에 대해 실수 집합 $\mathbb{R}$ 의 데카르트 곱 $\mathbb{R}^{n}$ 을 유클리드 공간 이라고 한다. 1. $\mathbb{R}^{1}$ 을 실수 공간 혹은 수직선 이라고 한다. 2. $\mathbb{R}^{2}$ 을 평면 이라고 한다. 3. $\mathbb{R}^{3}$ 을 $3$차원 공간 이라고 한다. $\mathbb{N} := \left\{ 1, 2, 3, \cdots \right\}$ 은 자연수를 모두 모아놓은 집합을 의미한다. $\mathbb{R}$ 은 실수를 모두 모아놓은 집합을 의미한다. 유클리드 공간은 기</description>
    </item>
    
    <item>
      <title>유클리드 정역</title>
      <link>https://freshrimpsushi.github.io/posts/ed-euclidean-domain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ed-euclidean-domain/</guid>
      <description>유클리드 정역 $\implies$ 주 아이디얼 정역 $\implies$ 유일 인수분해 정역 $\implies$ 정역정역 $D$ 에서 다음의 두 조건을 만족하는 유클리드 놈Euclidean Norm $\nu : D \setminus \left\{ 0 \right\} \to \mathbb{N}{0}$ 이 존재하면 $D$ 를 유클리드 정역 이라고 한다.(i) 모든 $a,b \in D (b \ne 0 )$ 에 대해 $a = bq + r$ 을 만족하는 $q$ 와 $r$ 이 존재한다. 이 때 $r = 0$ 이거나 $\nu (r) &amp;lt; \nu (b)$ 둘 중 하나여야한다.(ii) 모든 $a,b \in D</description>
    </item>
    
    <item>
      <title>유한 교집합 성질</title>
      <link>https://freshrimpsushi.github.io/posts/finite-intersection-property-fip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finite-intersection-property-fip/</guid>
      <description>위상공간 $X$ 에 대해 $\mathscr{A} \subset \mathscr{P} (X) $ 라고 하자. 모든 유한 부분집합 $A \subset \mathscr{A}$ 에 대해 $\displaystyle \bigcap A \ne \emptyset$ 이면 $A$ 가 유한 교집합 성질Finite Intersection Property 을 가진다고 한다.$A$ 가 f.i.p.를 가진다는 것은 열린 집합 $U_{\alpha} \subset A$ 에 대해 항상 $\displaystyle \bigcap_{i=1}^{n} \left( X \setminus U_{i} \right) \ne \emptyset $ 이면 $\displaystyle \bigcap_{\alpha \in \forall } \left( X \setminus U_{\alpha} \right) \ne \emptyset $ 인 것과 같다.이 성질은 위상공간이 아니라 그냥 집합에 대한 성질이라는 것에</description>
    </item>
    
    <item>
      <title>유한 차원 놈드 스페이스는 완비성을 가짐을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/711/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/711/</guid>
      <description>유한 차원 놈드 스페이스는 완비성을 가진다.이에 따라 유한 차원 벡터 스페이스는 놈이 정의되는 것만으로 바나흐 공간이 된다.대표적으로 많이 쓰이는 $\mathbb{R}^{n}$ 혹은 $\mathbb{C}^{n}$ 이 있기 때문에 특히 유용한 팩트다.Strategy : 유한차원 벡터 스페이스라는 점을 이용해 모든 벡터를 베이시스 단위로 찢은 후 다루기 편한 놈을 정의한다. 놈의 동치관계를 타서 추상적인 계산</description>
    </item>
    
    <item>
      <title>유한 차원 벡터 스페이스 상에서 정의된 모든 놈은 동치임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/709/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/709/</guid>
      <description>유한 차원 벡터 스페이스 상에서 정의된 모든 놈은 동치다.유클리드 공간 상에서 정의된 모든 놈은 동치라는 사실은 본 정리의 따름 정리에 해당한다.Strategy : $c | v | _{\alpha} \le | v | {\beta} \le C | v | {\alpha} $ 를 만족하는 $c , C &amp;gt;0 $ 가 존재함을 보이면 두 놈 $| \cdot |{\alpha} $ 와 $| \cdot |{\beta} $ 는 동치다. 최대최소값 정리를 통해 $\displaystyle { { | v | _{\beta} } \over {| v | _{\alpha} } } $ 의 최대</description>
    </item>
    
    <item>
      <title>유한 콘</title>
      <link>https://freshrimpsushi.github.io/posts/finite-cone/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finite-cone/</guid>
      <description>**유한 콘$(\mathrm{finite\ cone})$ $v$를 $\mathbb{R}^n$에서의 단위벡터라고 하자.1 그리고 영벡터가 아닌 각각의 $x\in \mathbb{R}^n$에 대해서 $\angle(x,v)$를 두 벡터 $v,x$사이의 각도라고 하자. 그러면 주어진 $v$, $\rho &amp;gt;0$ $0&amp;lt; \kappa \le \pi$에 대해서 아래의 집합 $C$를 높이가 $\rho$, 축</description>
    </item>
    
    <item>
      <title>음이항계수</title>
      <link>https://freshrimpsushi.github.io/posts/negative-binomial-coefficient/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/negative-binomial-coefficient/</guid>
      <description>$r,k \in \mathbb{N}$ 에 대해 $\displaystyle \binom{-r}{k}$ 를 음이항계수 라 한다.음이항계수라는 이름에서 짐작할 수 있듯 이항계수가 음수에 대해 확장된 것이다. 수식적으로만 생각해보면 $\alpha \in \mathbb{Z}$ 에 대해 $\displaystyle \binom{\alpha}{k} = {{ \alpha ( \alpha - 1 ) \cdots ( \alpha - k + 1 ) } \over { k! }} $ 와 같이 계산하지 못할 이유가 없다. 더 나아가서 복소수에 대해서도 일반화 할 수 있는데, 특히 음의 정수 $-r$ 에 대한 논의는 또 다른 쓰임새가</description>
    </item>
    
    <item>
      <title>이산 푸리에 변환과 고속 푸리에 변환 매트랩</title>
      <link>https://freshrimpsushi.github.io/posts/discrete-fourier-transform-and-fast-foutier-transform-in-matlab/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/discrete-fourier-transform-and-fast-foutier-transform-in-matlab/</guid>
      <description>푸리에 변환 은 물리학, 의학, 공학, 전자공학 등에서 매우 유용하게 쓰인다. 허나 이는 적분 변환이기 때문에 컴퓨터로 다룰 때 그대로 사용할 수 없다. 사람이야 적분을 손으로 계산할 수 있지만 컴퓨터는 그런거 못 한다. 컴퓨터가 다루는 모든 신호는 0과 1의 조합으로 표현되는 이산 신호이다. 그래서 이산 푸리에 변환$(\mathrm{discrete</description>
    </item>
    
    <item>
      <title>이상기체 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/pv-nrt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pv-nrt/</guid>
      <description>분자의 갯수가 $N$ 개면서 부피가 $V$ 인 이상기체의 절대온도가 $T$ 고 압력이 $p$ 라고 하자.[1] 보일의 법칙 : ** $\displaystyle p \propto {{1} \over {V}}$[2] 샤를의 법칙 : ** $ V \propto T$[3] 게이뤼삭의 법칙 : ** $ p \propto T$[4] 이상기체 방정식 : $pV = N k_{B} T$이상기체 방정식의 $k_{B} = 1.3807 \times 10^{-23} J / K$ 를 **볼츠만 상수** 라고 한다. 기체를 분자의 갯수 $N$ 이 아니라 몰수 $n$ 에 대해 나타내면 $pV = nRT$ 의 꼴로</description>
    </item>
    
    <item>
      <title>이상기체의 단열 팽창</title>
      <link>https://freshrimpsushi.github.io/posts/adiabatic-expansion-of-an-ideal-gas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adiabatic-expansion-of-an-ideal-gas/</guid>
      <description>몰 수가 $1$ 이고 단열 팽창을 하는 이상기체의 계에서 압력이 $p$, 부피가 $V$ 라고 하면 $p V^{\gamma}$ 은 상수다.단열 팽창이란 열에너지가 변하지 않는 조건에서의 팽창을 말한다.등압 열용량과 등적 열용량의 비 $\displaystyle \gamma = {{C_{p}} \over {C_{V}}}$ 는 물리적으로 딱히 의미가 없다. 증명 열역학 제1법칙$d U = \delta Q + \delta W$열역학 제1법칙에 의해 $dU(T,V)$ 는 완전미분이고 $\displaystyle dU = {{\partial U} \over {\partial T}} dT + {{\partial U}</description>
    </item>
    
    <item>
      <title>이상기체의 등온 팽창</title>
      <link>https://freshrimpsushi.github.io/posts/isothermal-expansion-of-an-ideal-gas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isothermal-expansion-of-an-ideal-gas/</guid>
      <description>몰 수가 $1$ 이고 등온 팽창을 하는 이상기체의 계에서 열에너지가 $Q$, 온도가 $T$, 팽창 전의 부피를 $V_{1}$ , 팽창 후의 부피를 $V_{2}$ 라고 하면 $\displaystyle \Delta Q = RT \ln {{V_{2}} \over {V_{1}}} $등온 팽창이란 온도가 변하지 않는 조건에서의 팽창을 말한다.이때 열에너지의 변화는 편리하게도 부피의 변화만을 이용해 구해낼 수 있다.일단은 팽창이므로 $V_{2} &amp;gt; V_{1}$ 일테고, $\Delta Q &amp;gt; 0$ 에서 열에너지는 증가해서</description>
    </item>
    
    <item>
      <title>이항 급수 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-binomial-series/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-binomial-series/</guid>
      <description>$|x| &amp;lt; 1$ 이면 $\alpha \in \mathbb{C}$ 에 대해 $\displaystyle (1 + x )^{\alpha} = \sum_{k=0}^{\infty} \binom{\alpha}{k} x^{k}$이른바 **뉴턴의 이항 정리** 로써, 이항 전개가 무한대와 복소수에 대해서 일반화된 것으로 볼 수 있다.한편 우리에게 익숙한 꼴은 다음과 같은 방법으로 간단하게 유도할 수 있다. $$ \begin{eqnarray*} &amp;amp;&amp;amp; \left( 1 + {{ y } \over { x }} \right)^{\alpha} = \sum_{k=0}^{\infty} \binom{\alpha}{k} \left( {{ y } \over { x }} \right)^{k} \\ &amp;amp;\implies&amp;amp; x^{-\alpha} \left( x + y \right)^{\alpha} = \sum_{k=0}^{\infty} \binom{\alpha}{k} y^{k} x^{-k} \\ &amp;amp;\implies&amp;amp; \left( x + y \right)^{\alpha} = \sum_{k=0}^{\infty} \binom{\alpha}{k}</description>
    </item>
    
    <item>
      <title>인공 신경망이란</title>
      <link>https://freshrimpsushi.github.io/posts/ann-artificial-neural-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ann-artificial-neural-network/</guid>
      <description>본 포스트는 컴퓨터보다는 통계와 수학에 더 익숙한 사람들을 위해 작성되었다.실제 생물의 신경계를 모방한 네트워크를 인공 신경망 이라고 한다.신경계는 뉴런들의 결합으로 구성되어있다. 신경세포체는 가지돌기를 통해 자극을 받아들이며, 축삭돌기를 통해 전기자극을 전달한다. 인간을 포함한 많은 생물들은 이렇듯 단순한 뉴런들의 결합을 환경에 적합하</description>
    </item>
    
    <item>
      <title>일 일-운동 에너지 정리</title>
      <link>https://freshrimpsushi.github.io/posts/work-work-kinetic-energy-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/work-work-kinetic-energy-theorem/</guid>
      <description>힘 $\mathbf{F}$가 물체에 작용하여 물체가 힘과 같은 방향으로 $s$만큼 이동했을 때, 힘의 크기와 이동거리의 곱 $W=Fs$를 힘 $\mathbf{F}$가 물체에 해준 일이라고 한다. 이동거리-힘 그래프에서 그래프 아래의 면적이 일의 양과 같다. 이동방향과 힘의 방향이 같아야 힘이 물체에 일을 해준 것으로 정의하기에 아래와 같이 두</description>
    </item>
    
    <item>
      <title>일관성을 가지는 멀티스텝 메소드의 안정성과 루트 컨디션</title>
      <link>https://freshrimpsushi.github.io/posts/734/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/734/</guid>
      <description>멀티스텝 메소드가 일관성을 가진다고 하자.메소드는 안정성을 가진다 $\iff$ 메소드는 루트 컨디션을 만족 시킨다폐구간 $[x_{0} , b]$ 에 대해 $h$ 를 단위로 잘라서 노드 포인트를 만들 때, $x_{0} \le x_{1} \le \cdots \le x_{N(h) -1} \le x_{N(h) } \le b$ 라고 하자. 여기서 $N(h)$ 는 $h$ 에 따라 변하는 마지막 노드 포인트의 인덱스를 나타낸다.원래 주어진 초기값 $y_{0} , \cdots , y_{p}$ 에 대해 아주 조금 변화를 준 $z_{0} , \cdots , z_{p}$</description>
    </item>
    
    <item>
      <title>일반화된 디리클레 곱</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-convolution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-convolution/</guid>
      <description>산술 함수의 디리클레 곱$F : \mathbb{R}^{+} \to \mathbb{C}$ 는 $x \in (0,1)$ 에서 $F(x) = 0$ 인 함수라고 하자. 임의의 산술 함수 $\alpha$ 에 대해 다음과 같은 연산 $\circ$ 을 일반화된 디리클레 곱 이라 정의한다. $$ (\alpha \circ F)(x) := \sum_{n \le x} \alpha(n) F \left( {{ x } \over { n }} \right) $$ $\alpha$ 와 $\beta$ 는 산술 함수고 $F , G : \mathbb{R}^{+} \to \mathbb{C}$ 는 $x \in (0,1)$ 에서 함숫값이 $0$ 인 함수이라 하자.**[1]** $\alpha \circ \left( \beta \circ F \right) = \left( \alpha * \beta \right) \circ F$**[2] 좌항등원</description>
    </item>
    
    <item>
      <title>일정하지 않은 전기장에 의한 극성분자의 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/alignment-of-polar-molecules-by-nonuniform-electric-field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/alignment-of-polar-molecules-by-nonuniform-electric-field/</guid>
      <description>외부 전기장이 일정할 때 극성분자가 받는 영향은 이 글에서 다루었다.만약 전기장이 고르지 않다면 $\mathbf{F}+$와 $\mathbf{F}-$가 같지 않기 때문에 돌림힘과 더불어 알짜힘도 받는다.알짜힘을 계산하는 방법은 아래와 같다.$\mathbf{E}\pm$를 $\pm q$에서의 전기장이라고 하면$\mathbf{F}=</description>
    </item>
    
    <item>
      <title>일정한 외부 전기장에 의한 극성분자의 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/alignment-of-polar-molecules-by-uniform-electric-field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/alignment-of-polar-molecules-by-uniform-electric-field/</guid>
      <description>개요 전기적으로 중성인 원자가 외부 전기장 속에 놓여져 있을 경우 편극되어 쌍극자 모멘트 $\mathbf{p}$를 가지게 된다. 그런데 어떤 분자는 외부 전기장의 영향을 받지 않아도 쌍극자 모멘트를 가지고 있다. 이런 분자를 가리켜 극성분자(polar molecule) 라고 한다. 극성 분자 극성분자의 대표적인 예로 물 분자가 있다. 물 분자는 105도로 꺽여있기</description>
    </item>
    
    <item>
      <title>임의의 함수의 절대값을 두 개의 음이 아닌 함수로 표현하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/1325/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1325/</guid>
      <description>임의의 함수를 두 개의 음이 아닌 함수로 표현하는 방법함수 $f : X \to \mathbb{R}$ 의 절대값 $|f|$ 는 $f$ 의 양의 부분 $f^{+}$ 와 음의 부분 $f^{-}$ 에 대해 다음과 같이 나타난다. $$ |f| = f^{+} + f^{-} $$ 함수의 절대값 표현은 양의 부분과 음의 부분의 정의에 따라 곧바로 유도되며, 특히 실해석에서 쓰일 일이 많다. 다음의 유용한 성질들을 자유자재로 사용할 수 있게 되도록 하자.함수 $g : X \to \mathbb{R}$ 은 [</description>
    </item>
    
    <item>
      <title>자기 쌍극자가 만드는 자기장</title>
      <link>https://freshrimpsushi.github.io/posts/156/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/156/</guid>
      <description>원점에 놓인, 방향이 $\hat z$인 자기 쌍극자가 만드는 자기장은 다음과 같다.$ \displaystyle \vec{B}_{dip}(r,\theta)=\frac{\mu_0 }{4 \pi }\frac{m}{r^3}(2\cos\theta \hat r + \sin\theta \hat \theta)$놀랍게도 전기 쌍극자가 만드는 전기장과 같은 모양이다.(쌍극자가 만드는 전기장)마찬가지로 좌표계와 무관하게 사용할 수 있는 공식을 유도해보자.$\hat{r}= \cos\phi \sin\theta \hat{x} + \sin\phi \sin\theta\hat{y} + \cos\theta\hat z $$ \hat{\theta} = \cos\phi \cos\theta \hat{x} + \sin\phi \cos\theta\hat{y} - \sin\theta\hat z $(참고 :</description>
    </item>
    
    <item>
      <title>자기력과 로런츠 힘 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/magnetic-force-and-lorentz-force-law/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/magnetic-force-and-lorentz-force-law/</guid>
      <description>움직이는 전하(전류)는 주위에 자기장 $\mathbf{B}$를 만든다.자기장 $\mathbf{B}$속에서 $\mathbf{v}$의 속도로 움직이는 전하 $Q$가 받는 힘은 다음과 같다. $$ \mathbf{F}_m=Q(\mathbf{v} \times \mathbf{B}) $$ 이 힘을 자기력 이라 하고 위의 공식을 로런츠 힘 법칙$(\mathrm{Lorentz\ force\ law})$ 이라 한다.실제로는 헤비사이드$\</description>
    </item>
    
    <item>
      <title>자기력은 일을 하지 않음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-magnetic-forces-do-not-work/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-magnetic-forces-do-not-work/</guid>
      <description>자기력을 다룰 때 주의해야 할 점이 있다.헷갈리기 쉬운 사실인데 바로 자기력은 일을 하지 않는다 는 것이다.자기력에 의해 입자 등이 움직이면 겉으로 보기엔 마치 자기력이 일을 해준 것 처럼 보인다.허나 사실은 전혀 그렇지 않다. 증명 $$ W=\int \mathbf{F} \cdot d\mathbf{l} $$ 일은 힘과 변위의 곱이다.자기력이 해준 일은 $$ W_{mag}=\int \mathbf{F}_{mag} \cdot d\mathbf{l} = \int Q(\mathbf{v}\times \mathbf{B})\cdot d\mathbf{l} $$ 이때 $d\mathbf{l}=\d</description>
    </item>
    
    <item>
      <title>자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/acf-autocorrelation-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/acf-autocorrelation-function/</guid>
      <description>PACF : 편자기상관함수EACF : 확장자기상관함수CCF : 교차상관함수$\left\{ Y_{t} \right\}_{t=1}^{n} $ 이 확률과정이라고 하자.**1.** $\mu_{t} := E ( Y_{t} ) $ 를 **평균함수** 라고 한다.**2.** 다음과 같이 정의된 $\gamma_{ t , s }$ 를 **자기공분산함수** 라고 한다. $$ \gamma_{t , s} : = \text{cov} ( Y_{t} , Y_{s} ) = E ( Y_{t} - \mu_{t} ) E ( Y_{s} - \mu_{s} ) $$ **3.** 다음과 같이 정</description>
    </item>
    
    <item>
      <title>자기장의 발산과 회전</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-and-curl-of-magnetic-field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-and-curl-of-magnetic-field/</guid>
      <description>$$ \nabla \cdot \mathbf{B}=0 $$ $$ \nabla \times \mathbf{B} = \mu_0 \mathbf{J} $$ **0. 전기장은 항상 회전이 0인 특별한 벡터 함수였듯이 자기장 또한 그러하다. 부피전류에 대한 비오-사바르 법칙으로 발산과 회전을 구해보자. $$ \displaystyle \mathbf{B} (\mathbf{r}) = \dfrac{\mu_0}{4 \pi} \int \dfrac{\mathbf{J} (\mathbf{r}&#39;) \times \hat{\boldsymbol{\eta}} }{\eta^2} d \tau $$ 이 때 중요하게 알고 넘어가야 할 점이 있다. 각 함수가 어느 좌표에 대해서 영향을 받는지를 확실하게 구분해야한다.$\mathbf{B}$는</description>
    </item>
    
    <item>
      <title>자기장의 벡터 전위</title>
      <link>https://freshrimpsushi.github.io/posts/magnetic-vector-potential/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/magnetic-vector-potential/</guid>
      <description>1. 정전기학에서 전기장을 쉽게 다루기 위해 $\nabla \times \mathbf{E} =0$이라는 성질을 이용해서 스칼라 전위 $V$를 정의한다. 마찬가지로 정자기학에서 $\nabla \cdot \mathbf{B}$라는 성질을 이용해 벡터 전위 $A$를 정의해 사용한다.자기장 $\mathbf{B}$를 어떤 벡터 $\mathbf{A}$의 회전이라고 하자. $$ \mathbf{B}=\nabla \times \mathbf{A} $$ 그러면 회전의 발산</description>
    </item>
    
    <item>
      <title>자연스러운 임베딩과 반사적인 공간</title>
      <link>https://freshrimpsushi.github.io/posts/natural-embedding-and-reflexive-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/natural-embedding-and-reflexive-space/</guid>
      <description>※ 놈 공간 $X$의 놈을 $| \cdot |_X$ 또는 $| x\ ;X|$로 표기한다. 헷갈릴 여지가 없을 경우에는 $| \cdot |$로 표기할 수도 있다.자연스러운 임베딩$(\mathrm{natural\ embedding})$ $X$를 놈 공간이라고 하자. 그리고 $X^{}$를 $X$의 바이듀얼이라고 하자. 그리고 $X$에서부터 $X^{}$로 대응되는 함수 $J\ :\ X \rightarrow X^{}$를 다</description>
    </item>
    
    <item>
      <title>재귀함수를 쓸 때 주의해야하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/1254/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1254/</guid>
      <description>프로그래밍을 처음 배우면 그것이 어떤 언어든지 &amp;lsquo;재귀함수는 조심해서 써야한다&amp;rsquo;는 경고가 함께한다. 사실 재귀함수라는 게 그렇게 빈번하게 사용되는 테크닉이 아니기 때문에 그 이유는 설명하지 않는 경우가 많은데, 배우는 입장에선 이 좋은 걸 왜 꺼리는지 이해가 잘 되지 않을 수 있다. 예시를 통해 알아보자. def fibo1(n) : if n==1 or n==2 : return</description>
    </item>
    
    <item>
      <title>적분의 평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem-for-integral/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem-for-integral/</guid>
      <description>평균값 정리 코시의 평균값 정리 가우스의 평균값 정리 정리 폐구간 $[a,b]$ 에서 함수 $f$ 가 연속이라고 하면 $\displaystyle f(c) = {{1}\over {b-a} } \int_{a}^{b} f(x) dx $ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 평균값의 정리와 유사하지만 말 그대로 적분에 사용되기 때문에 이런 이름이 붙었다. 사용법 역시 매우 유사하고 활용도도 결코 평균값의 정리에 뒤지지 않는다. 한편 함수의 평균값을 우변과 같이</description>
    </item>
    
    <item>
      <title>적분인자를 이용한 1계 선형 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-solution-of-first-order-linear-differential-equation-by-using-integrating-factor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-solution-of-first-order-linear-differential-equation-by-using-integrating-factor/</guid>
      <description>1계 선형 미분방정식 $\dfrac{dy}{dx}+p(x)y=q(x)$의 해는 $$ \begin{align*} y(x)&amp;amp;=\dfrac{1}{e^{\int p(x) dx}} \left[ \int e^{\int p(x) dx} q(x) dx +C \right] \\ &amp;amp;=e^{-\int p(x) dx}\int e^{\int p(x) dx} q(x) dx + e^{-\int p(x) dx}C \end{align*} $$ $y^\prime+p(x)y=q(x)$ 꼴의 미분 방정식을 1계 선형 미분방정식이라고 한다. 여기서 $q(x)=0$이면 바로 변수분리가 가능하고 분리 가능한 미분방정식의 풀이대로 해를 구하면 된다. 하지만 $q(x) \ne 0 $인 경우엔</description>
    </item>
    
    <item>
      <title>전류와 전류밀도</title>
      <link>https://freshrimpsushi.github.io/posts/current-and-current-density/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/current-and-current-density/</guid>
      <description>1. 전류 는 도선의 어느 지점을 단위시간동안 지나가는 전하량 으로 정의된다. 따라서 왼쪽으로 움직이는 음전하와 오른쪽으로 움직이는 양전하는 부호가 같은 전류이다.전류를 재는 단위는 암페어 $\mathrm{Ampere}$이며 1암페어는 1초 동안 1쿨롱이 흐르는 것을 뜻한다. $$ 1 A=1 C/s $$ 참고로 $\mathrm{Ampere}$는 프랑</description>
    </item>
    
    <item>
      <title>전위의 다중극 전개와 쌍극자 모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/multipole-expansion-and-dipole-moment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multipole-expansion-and-dipole-moment/</guid>
      <description>** 1. 전위의 다중극 전개 **** 모여있는 전하분포를 충분히 멀리서 바라보면 마치 점전하 처럼 보일 것이다.전하분포의 총 전하량이 $Q$라면 전하량이 $Q$인 점전하처럼 보일거라는 말이다.그럴 때 전위를 $\dfrac{1}{4\pi\epsilon_0} \dfrac{Q}{r}$이라고 해도 거의 비슷하다.이때 총 전하량이 $0$이라면 전위를 $0$에 근사시켜야할까?다중극 전개는 총 전하량</description>
    </item>
    
    <item>
      <title>절대 연속과 적분 가능한 함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/1373/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1373/</guid>
      <description>가측 공간 $(X,\mathcal{E})$위의 측도 $\mu$와 $\mu-$적분가능한 함수 $f$가 주어졌다고 하자. 그러면 $f$에 디펜드하는 $\nu \ll\mu$인 $\nu$가 존재한다.이를 보이는 것은 증명이랄 것도 없다. $\nu$를 아래와 같이 정의하면 $\nu \ll\mu$이기 때문에 위 조건을 만족하는 $\nu$가 존재한다</description>
    </item>
    
    <item>
      <title>정규분포</title>
      <link>https://freshrimpsushi.github.io/posts/normal-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normal-distribution/</guid>
      <description>$\mu \in \mathbb{R}$ 과 $\sigma &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $N \left( \mu,\sigma^{2} \right)$ 를 정규 분포 라고 한다. $$ f(x) = {{ 1 } \over { \sqrt{2 \pi} \sigma }} \exp \left[ - {{ 1 } \over { 2 }} \left( {{ x - \mu } \over { \sigma }} \right)^{2} \right] \qquad, x \in \mathbb{R} $$ 특히 다음과 같은 확률 밀도를 함수를 가지는 정규분포 $N \left( 0,1^{2} \right)$ 를 표준정규분포 라고 한다. $$ f(z) = {{ 1 } \over { \sqrt{2 \pi} }} \exp \left[ - {{ z^{2} } \over { 2 }} \right] $$ 정규분포의</description>
    </item>
    
    <item>
      <title>정규분포를 따르는 두 분포가 독립인 것과 공분산이 0인 것이 동치임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/591/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/591/</guid>
      <description>$X_{1} \sim N ( \mu_{1} , \sigma_{1} ) , X_{2} \sim N ( \mu_{2} , \sigma_{2} ) $ 면 $X_{1} \perp X_{2} \iff \text{cov} (X_{1} , X_{2} ) = 0$일반적으로 상관관계가 없다고 독립인 것은 아니다. 하지만 분포들이 정규분포를 따른다는 가정이 있다면 공분산이 $0$ 인 것이 독립임을 보장해준다. 증명 $$ \displaystyle M_{X_{1}} (t_{1} ) = \exp \left[ \mu_{1} t_{1} + {{1} \over {2}} \sigma_{1} t_{1}^{2} \right] M_{X_{2}} (t_{2} ) = \exp \left[ \mu_{2} t_{2} + {{1} \over {2}} \sigma_{2} t_{2}^{2} \right] $$ $\sigma_{12} : = \text{cov} (X_{1} , X_{2} )$ 그리고 $\sigma_{21} : = \text{cov} (X_{2} , X_{1} ) $ 이라</description>
    </item>
    
    <item>
      <title>정상전류와 비오-사바르 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/steady-current-and-biot-savart-law/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/steady-current-and-biot-savart-law/</guid>
      <description>0. 정상전류 정상전류 란 양과 진행 방향이 바뀌지 않고 끊임없이 계속되는 전하의 흐름을 말한다. 시간에 따라 전류가 변하지 않으므로 정상전류가 만든 자기장 또 한 시간에 따라 변하지 않는다. 여기서 말한 &amp;lsquo;진행 방향&amp;rsquo;이랑 여러분이 흔히 아는 벡터의 방향과는 무관하다. 반드시 직선으로 흘러야 한다는 얘기가 아니다. 꺽인 도서을 흐</description>
    </item>
    
    <item>
      <title>정상파 편미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-stationary-wave-partial-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-stationary-wave-partial-differential-equation/</guid>
      <description>$$ \displaystyle \begin{cases} u_{t} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ **정상파**Stationary Wave 는 시간이 흘러도 그 자리 그대로 움직이지 않는 파동이다.여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때 $x$ 에서의 파형을 나타낸다.$f$ 는 초기 조건으로써 특히 $t=0$ 일 때의 파형을 나타낸다.정상파 편미분방정식의 해가 존재한다면 풀이는 다음과 같다.**풀이 **Step 1.** 양</description>
    </item>
    
    <item>
      <title>정수론에서의 위수</title>
      <link>https://freshrimpsushi.github.io/posts/order/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order/</guid>
      <description>$\gcd (a, p) = 1$ 이라고 하자. $a^{e} \equiv 1 \pmod{p} $ 를 만족하는 가장 작은 자연수 $e$ 를 $\text{ord}{p} (a)$ 라 쓰고 법 $p$ 에서 $a$ 의 위수Order 라고 정의한다. $a^{n} \equiv 1 \pmod{p}$ 이라고 하면 $\text{ord}{p} (a) \mid n$예를 들어 $p=7$ 을 생각해보면$1^{1} \equiv 1 \pmod{ 7 }$ $2^{3} \equiv 1 \pmod{ 7 }$ $3^{6} \equiv 1 \pmod{ 7 } $$ 4^{3} \equiv 1 \pmod{ 7 }$ $5^{6} \equiv 1 \pmod{ 7 }$ $6^{2} \equiv 1 \pmod{ 7 }$여기서 $6$ 의 위수는 $2$ 고 $2, 4$ 의 위수는 $3$ 이고 $3,5$ 의 위수는 $6$ 이다</description>
    </item>
    
    <item>
      <title>정칙 스튀름-리우빌 문제의 솔루션의 직교성</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-of-solutions-of-regular-sturm-liouville-problem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-of-solutions-of-regular-sturm-liouville-problem/</guid>
      <description>서로 다른 $\lambda_{n}$, $\lambda_{m}$이 정칙 S-L 문제의 고유값이고 $u_{n}$, $u_{m}$이 각각의 고유값에 대응되는 실수값을 갖는 고유함수라고 하자. 그러면 $u_{n}$, $u_{m}$은 $L_{w}^{2}(a,b)$ 공간에서 서로 수직한다. 즉, $$ \int _{a} ^{b} u_{n}(x)u_{m}(x)r(x)dx=0 $$ **정칙 스튀름-리우빌 문제** $(\mathrm{Regular\ Sturm-Liouville\ problem})$미분 방정식 $(1)$이 구간 $[a,b]$에서 정의되어</description>
    </item>
    
    <item>
      <title>정칙 측도</title>
      <link>https://freshrimpsushi.github.io/posts/regular-measure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regular-measure/</guid>
      <description>측도의 정칙성 1$\mu$ 가 가측 공간 $(X, \Sigma)$ 에서 정의된 측도라고 하자.1. $\mu$ 에 대해 가측 집합 $A \in \Sigma$ 가 다음을 만족하면 내적 정칙Inner Regular 이라고 한다. $$ \mu (A) = \sup \left\{ \mu (F) : F \subset A, F \in \Sigma \text{ is compact} \right\} $$ 2. $\mu$ 에 대해 가측 집합 $A \in \Sigma$ 가 다음을 만족하면 외적 정칙Outer Regular 이라고 한다. $$ \mu (A) = \inf \left\{ \mu (G) : G \supset A, G \in \Sigma \text{ is open} \right\} $$ 3. 모든 가측 집합 $A \in \Sigma$ 가</description>
    </item>
    
    <item>
      <title>제1가산과 제2가산</title>
      <link>https://freshrimpsushi.github.io/posts/first-countable-and-second-countable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/first-countable-and-second-countable/</guid>
      <description>위상공간 $X$ 의 모든 점 $x$ 에 대해 가산 국소기저가 존재하면 제1가산 공간 이라고 한다. $X$ 가 가산 기저를 가지면 제2가산 공간 이라고 한다.기저와 국소기저라는 개념을 통해 가산의 새로운 갈래를 만들어냈다고 보면 된다.정확한 설명은 아니지만 제1가산은 모든 점에서 열린 집합이 셀수 있는 만큼 존재하는 느낌으로 받아들일 수 있다. 반면 제2가산은 가산 집합</description>
    </item>
    
    <item>
      <title>제1가산이고 가분 거리공간은 제2가산임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/414/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/414/</guid>
      <description>(1) 모든 거리공간은 제1가산이다.(2) 모든 가분 거리공간은 제2가산이다.위상수학에서 온갖 추상적인 공간들을 보고나면 거리공간이 얼마나 편리하고 좋은 공간인지 깨닫게 된다. 증명(1) 거리공간 $\left( X , d \right) $ 에 대해 $x \in X$ 라고 하자.$\displaystyle \left\{ \left. B_{d} \left(x , {{1} \over {n}} \right) , \right| , n \in \mathbb{N} \right\} $ 은 $x$ 에 대한 가산 국소기저이므로,</description>
    </item>
    
    <item>
      <title>제1동형 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-first-isomorphism-thoerem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-first-isomorphism-thoerem/</guid>
      <description>$G,G&#39;$ 가 군이라고 하자.제1동형 정리 : 준동형사상 $\phi : G \to G&#39;$ 이 존재하면 $G / \ker ( \phi ) \simeq \phi (G)$제2동형 정리 : $H \le G$ 이고 $N \triangleleft G$ 면 $(HN) / N \simeq (H \cap N)$제3동형 정리 : $H , K \triangleleft G$ , $K \leq H$ 면 $G/H \simeq (G/K) / (H/K)$동형 정리는 대수학자 에미 뇌터에 의해 증명된 정리로 독립적인 위의 세 가지 정리를 일컫는다.제1동형 정리는 위의 도식에서 빨간색</description>
    </item>
    
    <item>
      <title>제1종 베셀 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-first-kind/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-first-kind/</guid>
      <description>$\nu$차 제1 종 베셀 함수$(\mathrm{The\ Bessel\ function\ of\ the\ first\ kind\ of\ order\ \nu}) $$ $J_{\nu}(x)=\sum \limits_{n=0}^{\infty} \frac{(-1)^{n} }{\Gamma(n+1) \Gamma(n+\nu+1)} \left(\frac{x}{2} \right)^{2n+\nu} $$ $$ J_{-\nu}(x)=\sum \limits_{n=0}^{\infty}\frac{(-1)^{n}}{\Gamma(n+1)\Gamma(n-\nu+1)} \left( \frac{x}{2} \right)^{2n-\nu} $$ $\Gamma(x)$는 감마함수이다. 제1 종 베셀 함수란 베셀 방정식을 풀어서 얻는 두 가지 급수해 중 첫번째 해를 말한다. 베셀 방정식은 다음과 같다. $$ \begin{align*} x^{2} y&#39;&#39; +xy&#39;+(x^{2}-\nu^{2})y&amp;amp;=0 \\ y&#39;&#39;+\frac{1}{x} y&#39; + \left( 1-\frac{\nu^{2}}{x^{2}} \right)y&amp;amp;=0 \end{align*} $$ 독립 변수 $x$가 계수에 붙어있어서 풀기</description>
    </item>
    
    <item>
      <title>제1종 오류와 제2종 오류의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/difference-between-type-1-error-and-type-2-error/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-between-type-1-error-and-type-2-error/</guid>
      <description>귀무가설 $H_{0}$ 에 대해 $H_{0}$ 이 참인데 채택하지 않은 경우의 오류를 **제1종 오류Type 1 Error** , $H_{0}$ 이 거짓인데 채택한 경우의 오류를 **제2종 오류Type 2 Error** 라고 한다.귀무가설에는 &amp;lsquo;채택&amp;rsquo;이라는 말을 쓰고 대립가설에는 &amp;lsquo;기각&amp;rsquo;이라는 말을 쓴다. 귀무가설을 지지하는 증거가 충분하다면 &amp;l</description>
    </item>
    
    <item>
      <title>제2동형 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-second-isomorphism-thoerem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-second-isomorphism-thoerem/</guid>
      <description>$G,G&#39;$ 가 군이라고 하자.제1동형 정리 : 준동형사상 $\phi : G \to G&#39;$ 이 존재하면 $G / \ker ( \phi ) \simeq \phi (G)$제2동형 정리 : $H \le G$ 이고 $N \triangleleft G$ 면 $(HN) / N \simeq (H \cap N)$제3동형 정리 : $H , K \le G$ , $K \leq H$ 면 $G/H \simeq (G/K) / (H/K)$동형 정리는 대수학자 에미 뇌터에 의해 증명된 정리로 독립적인 위의 세 가지 정리를 일컫는다.$HN := \left\{ hn , | , h \in H , n \in N</description>
    </item>
    
    <item>
      <title>제이만 효과</title>
      <link>https://freshrimpsushi.github.io/posts/zeeman-effect/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zeeman-effect/</guid>
      <description>1897년 네덜란드 물리학자 **피테르 제이만Pieter Zeeman ** 이 발견한 현상으로 원자가 자기장 내에 있을 때 방출 스펙트럼 선이 갈라지는 것을 말한다.패러데이가 1860년에 나트륨의 스펙트럼과 자기장에 대한 연구를 진행했지만 별다른 소득을 얻지 못했다. 이후 제이만도 같은 연구를 하였으나 마찬가지로 새로운 결과를 얻지 못하고 한동안 잊고 살았</description>
    </item>
    
    <item>
      <title>제프리 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/jeffreys-prior/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jeffreys-prior/</guid>
      <description>자료의 분포 $p( y | \theta) $ 에 대해 $\pi ( \theta ) \propto I^{1/2} ( \theta )$ 를 제프리 사전분포Jeffreys Prior 라고 한다.* $I$ 는 피셔정보Fishser Information $\displaystyle I ( \theta ) = E \left[ \left( \left. {{\partial \ln p (y | \theta) } \over {\partial \theta}} \right)^2 \right| \theta \right] = E \left[ \left. - {{\partial^2 \ln p (y | \theta) } \over { (\partial \theta )^2 }} \right| \theta \right] $ 를 의미한다.라플라스 사전분포 $\pi (\theta) \propto 1$ 는 모수 $\theta$ 의 사전분포로써는 충분했으나, $\phi = \theta^2$ 와 같이 모수의</description>
    </item>
    
    <item>
      <title>조건부 기대값의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-conditional-expectation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-conditional-expectation/</guid>
      <description>확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.[1] 측도론에서의 정리 : 가측 함수 $f$, $g$ 가 $\mathcal{F}$-가측이면 $g = h (f)$ 를 만족하는 보렐 함수 $h : \mathbb{R} \to \mathbb{R}$ 가 존재한다.[2] 확률론에서의 응용 : 확률 변수 $X$, $Y$ 이 $\sigma(X)$-가측이면 $E(Y | X) = h(X)$ 를 만족하는 보렐 함수 $h : \mathbb{R} \to \mathbb{R}$ 가 존재한다. * $\sigma (X) = \left\{ X^{-1} (B) : B</description>
    </item>
    
    <item>
      <title>조르당 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-jordan-lemma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-jordan-lemma/</guid>
      <description>반원호 $\Gamma$ 를 $z(\theta) = R e^{i \theta} , 0 \le \theta \le \pi$ 와 같이 나타냈을 때, 함수 $f : \mathbb{C} \to \mathbb{C}$ 가 $\Gamma$ 에서 연속이고 $\displaystyle \lim_{z \to \infty} f(z) = 0 $ 이면 양수 $m \in \mathbb{R}^{+}$ 에 대해 $$ \displaystyle \lim_{R \to \infty} \int_{\Gamma} e^{m i z } f(z) dz = 0 $$ 조르당이라는 발음법은 콩글리쉬가 아니라 프랑스어에서 온 것이다.보조정리이니만큼 바로 그 의미를 깨닫긴 어렵고, 여러가지 적분 테크닉에 쓰인다는 정도만 알아두면 충분하다.증</description>
    </item>
    
    <item>
      <title>조르당 보조정리를 통한 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/372/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/372/</guid>
      <description>우선은 발산하는 반원 상의 복소경로적분을 통한 유리함수의 이상적분과 비슷하게 시작해보자.두 다항함수 $p(z) , q(z) $ 에 대해 $\displaystyle f(z) = {{q(z)} \over {p(z)}} $ 이라고 하자.$q(z) = 0$ 을 만족하는 실수해가 존재하지 않으면 $f$ 는 실수 특이점을 갖지 않을 것이다.양수 $m \in \mathbb{R}^{+}$ 에 대해 $\displaystyle \int_{- \infty}^{\infty} \sin{mx}f(x) dx$ 혹은 $\displaystyle \int_{- \infty}^{\infty} \cos{mx}f(x) dx$ 꼴의 적분을 한다고 생각해보자.이때 이상적분이 존재하는 조</description>
    </item>
    
    <item>
      <title>조밀한 부분공간을 갖는 힐베르트 공간의 베셀 시퀀스</title>
      <link>https://freshrimpsushi.github.io/posts/1581/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1581/</guid>
      <description>힐베르트 공간 $H$ 가 주어져 있을 때 $\left\{ \textbf{v}{k} \right\}{k \in \mathbb{N}} \subset H$ 와 $\overline{V} = H$ 인 $V \subset H$ 가 다음을 만족한다고 하자. $$ \sum_{k \in \mathbb{N}} \left| \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt; \right|^{2} \le B \left| \textbf{v} \right|^{2} \qquad , \textbf{v} \in V $$ 그러면 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 은 베셀 바운드 $B$ 인 베셀 시퀀스다.원래 베셀 시퀀스는 모든 $\textbf{v} \in H$ 에서 부등식을 만족해야했지만, $\overline{V} = H$ 에 따라 그러한 조건이 약화되어 $\textbf{v} \in V$ 에서만 만족해도 충분해진다. 특히 $H$ 가 폴</description>
    </item>
    
    <item>
      <title>좌우간약율 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-left-and-right-cancellation-law/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-left-and-right-cancellation-law/</guid>
      <description>군 $\left&amp;lt;G,\right&amp;gt;$ 의 원소 $a,b,c$에 대해, $$ ab = ac \implies b = c \\ ba = c*a \implies b=c $$ 추상대수학을 접하면 이제까지 배워왔던 걸 새로운 언어로 배우게 된다. 아마 좌우간약율은 그 중에서도 가장 먼저 접하게되는 정리일 것이다. 우리는 보통 그냥 양변에서 같은 걸 나눈다(역원을 곱한다)는 식으로만 말한다. 간약율은 일본에서 쓰는 표현으로, 굳이 어떤 명칭으로 기억하</description>
    </item>
    
    <item>
      <title>주 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/principal-ideal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/principal-ideal/</guid>
      <description>단위원을 가지는 가환환 $R$ 의 원소 $a$ 로 생성되는 $\left&amp;lt; a \right&amp;gt;$ 를 $a$ 에 의해 생성되는 주 아이디얼 이라고 한다.$\left&amp;lt; a \right&amp;gt; := \left\{ r a \mid r\ \in R \right\}$ 의 표기는 순환군과 같지만 실제 순환군보다는 조금 더 큰 구조를 이룬다.예로써 $\mathbb{Z}$ 의 모든 아이디얼 $n \mathbb{Z} = \left&amp;lt; n \right&amp;gt; = \left\{ \cdots , -2n , -n , 0 , n , 2n , \cdots \right\}$ 은 주 아이디얼이다.또한 주 아이디얼은 다음과 같은 성</description>
    </item>
    
    <item>
      <title>준소수</title>
      <link>https://freshrimpsushi.github.io/posts/semiprime/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/semiprime/</guid>
      <description>두 소수의 곱을 준소수 라고 한다.준소수의 예로써 $4 = 2 \cdot 2$ 이나 $21 = 3 \cdot 7$, $673703 = 719 \cdot 937$ 등이 있다.일본어 번역으로는 반소수半素數 라고도 하는데, 한국어 문서로는 준소수나 반소수나 둘 다 찾아보기 어렵다.본질적으로 준소수는 준소수 자체가 아니라 소수의 성질을 어느정도 이어받아서 응용된다. 예를들어 제법 큰 두 개의 소수를 곱해서 준소수를 만들면</description>
    </item>
    
    <item>
      <title>줄리아에서 2차원 배열 연산에 관한 함수들</title>
      <link>https://freshrimpsushi.github.io/posts/1460/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1460/</guid>
      <description>$A=\begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 1 \\ 0 &amp;amp; 3 &amp;amp; 0 \\ 2 &amp;amp; 3 &amp;amp; 4 \end{pmatrix}$라고 하자.**전치행렬 A=[1 2 1; 0 3 0; 2 3 4] transpose(A) A&amp;#34; 행렬의 원소가 실수라면 transpose()와 &amp;lsquo;는 같은 행렬을 반환하지만 자료형이 미묘하게 다르다. 그 이유는 &amp;lsquo;가 정확하게는 transpose가 아니라 conjugate transpose이기 때문</description>
    </item>
    
    <item>
      <title>줄리아에서 배열을 히트맵 이미지로 출력 저장하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-and-save-arrays-as-heatmap-images-in-julia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-and-save-arrays-as-heatmap-images-in-julia/</guid>
      <description>매트랩에서 Heatmap Plots 패키지의 heatmap 함수를 쓰면 2차원 배열을 히트맵 이미지로 출력할 수 있고, savefig 함수로 해당 이미지를 저장할 수 있다. @__DIR__은 줄리아 코드 파일의 위치를 알려주는 매크로이다. julia&amp;gt; cd(@__DIR__) julia&amp;gt; using Plots julia&amp;gt; A=[i for i=1:25] 25-element Array{Int64,1}: 1 2 3 4 ⋮ 23 24 25 julia&amp;gt; A=transpose(reshape(A, 5,5)) 5×5 LinearAlgebra.Transpose{Int64,Array{Int64,2}}: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 julia&amp;gt; h1=heatmap(A) julia&amp;gt; savefig(h1, &amp;#34;heatmap1.png&amp;#34;) 그런데 배열 A와 히트맵</description>
    </item>
    
    <item>
      <title>줄리아에서 병렬처리 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-julia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-julia/</guid>
      <description>using Base.Threads for i in 1:10 println(i^2) end @threads for i in 1:10 println(i^2) end 원래 생새우초밥집에는 상세한 설명을 포함하는데, 줄리아가 병렬처리를 얼마나 편하게 할 수 있는지 강조하기 위해 굳이 설명을 생략하려 한다.위의 반복문을 병렬처리하고 싶다면 단지 포문 앞에 @threads만 붙이면 된다.그래도 당부의 말을 한마디만 적는다면, 병렬처리라고 해서 모든 게 빨라지지는 않는다는 것이</description>
    </item>
    
    <item>
      <title>줄리아에서 이미지 불러오고 행렬로 변환 저장하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-and-save-an-image-convert-to-matrix-in-julia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-and-save-an-image-convert-to-matrix-in-julia/</guid>
      <description>using Images cd(&amp;#34;C: \\\ Users \\\ rmsms \\\ OneDrive \\\ examples&amp;#34;) pwd() example = load(&amp;#34;example.jpg&amp;#34;) typeof(example) size(example) gray1 = Gray.(example) typeof(gray1) size(gray1) M = convert(Array{Float64},gray1) typeof(M) size(M) colorview(Gray, M.^(1/2)) save(&amp;#34;rgb.png&amp;#34;, colorview(RGB, example)) save(&amp;#34;gray1.png&amp;#34;, colorview(Gray, gray1)) save(&amp;#34;gray2.png&amp;#34;, colorview(Gray, transpose(gray1))) save(&amp;#34;gray3.png&amp;#34;, colorview(Gray, M.^(1/2))) 예제 코드를 위에서부터 간략하게 이해해보자 :cd() : Change Directory, 작업 경로를 원하는 곳으로 바꿔준다.pwd() : Print Working Directory, 작업 경로를 출력해준다. 예제를 그대로 따라해보고싶다면 위의 파일을 작업 경로에 다운로드 받고 파일 이름을 example.jpg로 수정하</description>
    </item>
    
    <item>
      <title>줄리아에서 이미지 크기 변경하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-resize-a-image-in-a-julia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-resize-a-image-in-a-julia/</guid>
      <description>매트랩에서 이미지 크기 조정하는 방법Images 패키지의 imresize를 사용하면 된다. 함수 이름이 매트랩과 같다. imresize(X,ratio=a) : 배열 X를 a배만큼 조정한 이미지를 반환한다. 매트랩에서와는 다르게 냅다 비율만 적으면 안되고 반드시 ratio=a와 같이 적어야한다.imresize(X,m,n) : 배열 X를 m행,n열로 확대/축소한 이미</description>
    </item>
    
    <item>
      <title>줄리아에서 이미지배열을 회전하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-rotate-imagearraymatrix-in-julia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-rotate-imagearraymatrix-in-julia/</guid>
      <description>매트랩에서 이미지 회전시키는 방법imrotate(X,$\theta$) : 배열 X를 $\theta$라디안 만큼 회전시킨다. 여기서 주의해야할 점은 각도의 단위가 도($^{\circ})$인 매트랩과 달리 각도의 단위가 라디안 이라는 것이다. 또한 매트랩과는 다르게 시계방향으로 회전 한다. 다른 변수를 입력하지 않을 경우 보간법은 b</description>
    </item>
    
    <item>
      <title>줄리아에서 패키지 설치하고 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-and-use-packages-in-julia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-and-use-packages-in-julia/</guid>
      <description>방법 1 using LinearAlgebra using Pkg Pkg.add(&amp;ldquo;Plots&amp;rdquo;) Pkg.add(&amp;ldquo;Distributions&amp;rdquo;) using Plots 위의 코드는 `LinearAlgebra` 패키지와 `Pkg` 패키지를 불러오며, `.add()` 함수를 통해 `Plots`, `Distribution` 패키지를 설치하는 코드를 나타낸다. 패키지를 불러오는 키워드 **using** 은 마치 수학에서 어떤 정리나 논법을 사용할 때 쓰는 말과 닮았다. 패키지를 설치하는 것 자체는 [파이썬보다](https://freshrimpsushi.github.io/pos</description>
    </item>
    
    <item>
      <title>줄리아의 람다식</title>
      <link>https://freshrimpsushi.github.io/posts/lambda-expression-in-julia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lambda-expression-in-julia/</guid>
      <description>(x -&amp;gt; 3x^2 - 2x + 3)(1) # Example 1 example = rand(-20:20,10) sort(example, by=(x -&amp;gt; abs(x))) # Example 2 example = rand(1:3,10); println(example) uexample = sort(unique(example)) counts = map(x-&amp;gt;count(y-&amp;gt;x==y,example),uexample) 줄리아에서 람다식은 위와 같이 정의된다. 이는 익명함수 $\lambda : \mathbb{Z} \to \mathbb{Z}$ 를 다음과 같이 정의하고, 거기에 $1$ 을 대입해서 $4$ 라는 함수값을 얻은 것에 해당한다. $$ \lambda : x \mapsto ( 3 x^{2} - 2 x + 3 ) \\ \lambda(1) = 4 $$ 사실 람다식 자체는 줄리아의 특징이 아니라 매트랩과 파이썬을 비롯해 함수형 언어에 영</description>
    </item>
    
    <item>
      <title>지도학습과 비지도학습</title>
      <link>https://freshrimpsushi.github.io/posts/supervised-learning-vs-unsupervised-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/supervised-learning-vs-unsupervised-learning/</guid>
      <description>본 포스트는 컴퓨터보다는 통계와 수학에 더 익숙한 사람들을 위해 작성되었다.머신러닝에서 종속변수가 정해진 경우를 지도학습 , 그렇지 않은 경우를 비지도학습 이라고 한다.지도학습과 비지도학습의 차이는 쉽게 비유하자면 객관식과 주관식의 차이다. 예를 들어 위와 같이 6개의 타일을 주고 색을 답하는 문제가 있다고 해보자.그런데 여기서 녹색이냐 적색</description>
    </item>
    
    <item>
      <title>지연 시각 연속 분포에 대한 지연 전위</title>
      <link>https://freshrimpsushi.github.io/posts/retarded-potential-of-continuous-distributions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/retarded-potential-of-continuous-distributions/</guid>
      <description>**지연 시각$(\mathrm{retarded\ time})$ 전하와 전류분포가 시간에 따라 변하지 않으면 스칼라 전위와 벡터 전위는 다음의 푸아송 방정식을 만족한다. $$ \nabla^2 V=-\dfrac{1}{\epsilon_0} \rho,\quad \nabla^2 \mathbf{A}=-\mu_0\mathbf{J} $$ 이를 풀면 다음과 같다. $$ V(\mathbf{r})=\dfrac{1}{4\pi\epsilon_0} \int \dfrac{ \rho(\mathbf{r}&#39;) }{ \eta } d\tau&#39;,\quad \mathbf{A}( \mathbf{r} ) = \dfrac{\mu_0}{4\pi} \int \dfrac{\mathbf{J}(\mathbf{r}&#39;)}{\eta}d\tau&#39; \quad \cdots (1) $$ $\boldsymbol{\eta}$는 분리 벡터이다.그런데 전자기파는 광속으로 진행하</description>
    </item>
    
    <item>
      <title>지연시각의 기울기</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-of-retarded-time/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-of-retarded-time/</guid>
      <description>&amp;lt;img &amp;ldquo;&amp;quot;=&amp;rdquo;&amp;quot; filemime=&amp;ldquo;image/png&amp;rdquo; filename=&amp;ldquo;수리물리학2.png&amp;rdquo; height=&amp;ldquo;409&amp;rdquo; src=&amp;ldquo;https://t1.daumcdn.net/cfile/tistory/991735475E4CD78718&amp;quot; style=&amp;rdquo;&amp;quot; width=&amp;ldquo;728&amp;rdquo;/&amp;gt;$\eta = c(t -t_r)$이고 $t$는 공간 변수와는 무관하므로 $$ \nabla \eta =\nabla(-c t_r)=-c \nabla t_{r} $$ 따라서 지연시각의 기울기는 $\nabla \eta$를 계산해서 구할 수 있다. $$ \begin{eqnarray*} \nabla \eta &amp;amp;=&amp;amp; \nabla \sqrt{\boldsymbol{\eta} \cdot \boldsymbol{\eta} } \\ &amp;amp;=&amp;amp; \frac{1}{2\sqrt{\boldsymbol{\eta}\cdot \boldsymbol{\eta}}} \nabla (\boldsymbol{\eta} \cdot \boldsymbol{\eta} ) \\ &amp;amp;=&amp;amp; \frac{1}{2\eta} \nabla (\boldsymbol{\eta} \cdot \boldsymbol{\eta} ) \\ &amp;amp;=&amp;amp; \frac{1}{2\eta} \Big[ \boldsymbol{\eta} \times (\nabla \times \boldsymbol{\eta} ) + \boldsymbol{\eta} \times (\nabla \times \boldsymbol{\eta}) + (\boldsymbol{\eta} \cdot \nabla)\boldsymbol{\eta} +(\boldsymbol{\eta}</description>
    </item>
    
    <item>
      <title>직교 원통 구면 좌표계에 대한 기울기 발산 회전 라플라스 연산</title>
      <link>https://freshrimpsushi.github.io/posts/294/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/294/</guid>
      <description>직교좌표계, 원통좌표계, 구면좌표계에서의 기울기$\mathrm{Gradient}$, 발산$\mathrm{Divergence}$, 회전$\mathrm{Curl}$, 라플라스 연산$\mathrm{Laplasian}$을 정리했다. 이렇게 정리한 이유는 보고 달달달 외우라는게 아니다. 절대 외울 필요 없다. 외</description>
    </item>
    
    <item>
      <title>직교좌표계 단위벡터를 구면좌표계의 단위벡터로 나타내기</title>
      <link>https://freshrimpsushi.github.io/posts/291/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/291/</guid>
      <description>직교좌표계의 단위벡터를 구면좌표계의 단위벡터로 나타낸 식은 아래와 같다. $$ \begin{eqnarray*} \hat{ \mathbf{x} }&amp;amp;=&amp;amp; \cos \phi \sin \theta \hat{ \mathbf{r} } + \cos \phi \cos \theta \hat{ \boldsymbol{\theta} } - \sin\phi\hat{ \boldsymbol{\phi} } \\ \hat{ \mathbf{y} } &amp;amp;=&amp;amp; \sin\phi\sin\theta \hat{ \mathbf{r} } + \sin\phi\cos\theta\hat{ \boldsymbol{\theta} } + \cos\phi\hat{ \boldsymbol{\phi} } \\ \hat{ \mathbf{z} } &amp;amp;=&amp;amp; \cos\theta\hat{ \mathbf{r} } - \sin\theta\hat{ \boldsymbol{\theta} } \end{eqnarray*} $$ 구면좌표계의 단위벡터를 직교좌표계의 단위벡터로 나타내면 아래와 같다. (구면좌표계와 직교좌표계의 관계) $$ \begin{eqnarray*} \hat{ \mathbf{r} } &amp;amp;=&amp;amp; \cos\phi \sin\theta \hat{ \mathbf{x} } + \sin\phi \sin\theta\hat{</description>
    </item>
    
    <item>
      <title>직교좌표계에서의 벡터 미분</title>
      <link>https://freshrimpsushi.github.io/posts/derivative-of-a-vector-in-cartesian-coordinate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivative-of-a-vector-in-cartesian-coordinate/</guid>
      <description>3차원 직교좌표계에서 두 벡터 $\mathbf{A}$, $\mathbf{B}$에 대한 미분은 다음과 같다.$\mathbf{A},\ \mathbf{B}$를 각각$\mathbf{A}(u)=A_x(u)\hat x + A_y(u)\hat y + A_z(u)\hat z$,$\mathbf{B}(u)=B_x(u)\hat x + B_y(u)\hat y + B_z(u)\hat z$라고 하면$1 \ \ \dfrac{ d \left( n \mathbf{A} \right) }{du} = \dfrac{ dn }{du} \mathbf{A} + n\dfrac{ d\mathbf{A}}{du} $$ 2 \ \ \dfrac{ d ( \mathbf{A} \cdot \mathbf{B} )} {du} = \dfrac{ \mathbf{A} }{du} \cdot \mathbf{B} + \mathbf{A} \cdot \dfrac{</description>
    </item>
    
    <item>
      <title>직교함수 직교집합 정규직교집합 함수의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-function-orthogonal-set-orthonomal-set-norm-of-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-function-orthogonal-set-orthonomal-set-norm-of-function/</guid>
      <description>** **** 내적$(\mathrm{inner\ product})$ 구간 $[a,b]$에서 정의된 두 복소 함수 $f$, $g$의 내적을 다음과 같이 정의한다. $$ \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) \overline{g(x)} dx $$ 따라서 같은 두 함수끼리의 내적은 $$ \left&amp;lt; f,f \right&amp;gt;=\int_a^b f(x) \overline{f(x)} dx = \int_a^b \left| f(x) \right| ^2 dx $$ 함수의 내적을 정적분으로 정의하는 이유직교 $(\mathrm{orthogonal})$ 두 복소 함수 $f$, $g$가 아래의 식을 만족하면 &amp;lsquo;$f$, $g$는 구간 $[a,b]$에서 직</description>
    </item>
    
    <item>
      <title>질적변수를 포함한 회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/686/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/686/</guid>
      <description>회귀분석을 하면서 독립변수로 언제나 양적변수가 들어온다는 보장은 없다.성별이 무엇인지, 어떤 기업 소속인지, 무슨 색상인지, 금속인지 등등 범주형 자료 역시 분석에 반영시킬 필요가 있다.올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자.다중회귀분석을 사용하면 $Y \leftarrow X_{1} + X_{2}$ 와 같이 연봉 $Y$ 에 성적 $X_{1}$ 과 연</description>
    </item>
    
    <item>
      <title>집합과 명제함수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-set-and-propositional-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-set-and-propositional-function/</guid>
      <description>1. Set : 우리의 직관 또는 사고의 대상으로써 서로 뚜렷이 구분되는 객체의 모임을 집합 이라 한다.2. Element : 집합에 속한 객체를 원소 라고 한다.**3. ** Propositional Function : 집합 $U$ 의 원소 $x$ 에 대해 참이거나 거짓 둘 중 하나인 명제 $p(x)$ 를 $U$ 에서의 명제함수 라고 한다.1. 수학에서 집합은 거의 모국어 하나에 필적할만큼 중요한 개념이다. 어쩌면 자연어보다 나을 수도 있는 게</description>
    </item>
    
    <item>
      <title>집합의 데카르트 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cartesian-product/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cartesian-product/</guid>
      <description>1. 임의의 두 대상 $a$, $b$ 에 대해 $(a,b)$ 를 순서쌍Ordered Pair 이라고 한다. 2. 임의의 두 집합 $A$, $B$ 에 대해 $a \in A$, $b \in B$ 의 순서쌍 $(a,b)$ 의 집합을 $A$, $B$ 의 데카르트 곱 이라 하고 다음과 같이 나타낸다. $$ A \times B := \left\{ (a,b) : a \in A \land b \in B \right\} $$ 데카르트 곱에서 &amp;lsquo;곱&amp;rsquo;이라는 표현을 쓰는 이유는 집합이 가지는 원소의 개수를 생각했을 때 $| A \times</description>
    </item>
    
    <item>
      <title>집합의 분할</title>
      <link>https://freshrimpsushi.github.io/posts/partition-of-set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-of-set/</guid>
      <description>집합 $X$ 의 모든 부분집합 $A,B,C$ 에 대해 다음의 조건을 만족하는 $\mathscr{P}$ 를 $X$ 의 분할 이라고 한다.(i) $A,B \subset \mathscr{P} \land A \ne B \implies A \cap B = \emptyset$(ii) $\displaystyle \bigcup_{C \in \mathscr{P} } C = X$수식으로 나타내니까 복잡해 보이지만 간단히 말하자면 그냥 전체집합을 빠짐 없이 여러 조각으로 나누는 것에 불과하다. 수식적인 정의에 매달릴 여유가 있다면 차라리 $X$ 의 분할 $\mathscr{P}$ 가 $X$ 의 멱집합 $2^{X} = \mathscr{P} (X)$ 의 부분집합</description>
    </item>
    
    <item>
      <title>집합의 포함관계</title>
      <link>https://freshrimpsushi.github.io/posts/subset-relation-of-sets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subset-relation-of-sets/</guid>
      <description>$$ A \subset B \iff \forall x (x\in A \implies x \in B) $$ 임의의 집합 $A$, $B$ 에 대하여 $A$ 의 모든 원소가 $B$ 의 원소일 때 $A$ 는 $B$ 의 부분집합Subset , $B$ 는 $A$ 의 초집합Superset 이라고 하고 $A \subset B$ 와 같이 나타낸다.한편 $A \subset B$ 인데 $B \not\subset A$ 이면 $A$ 를 $B$ 의 진부분집합Proper Subset 이라고하고 $A \subsetneq B$ 와 같이 나타낸다.사소한 주의사항으로, $A \subset B$ 은 $A$ 가 $B$ 에 포함된다</description>
    </item>
    
    <item>
      <title>집합족과 첨수</title>
      <link>https://freshrimpsushi.github.io/posts/family-and-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/family-and-index/</guid>
      <description>1. 원소가 집합인 집합을 패밀리Family 라고 한다.2. 패밀리의 원소를 멤버Member 라고 한다.3. 하나의 집합 $\Gamma$ 의 각 $\gamma \in \Gamma$ 에 집합 $A_{\gamma}$ 가 대응할 때 $\gamma$ 를 **인덱스** , $\Gamma$ 를 **인덱스 집합** , $\left\{ A_{\gamma} : \gamma \in \Gamma \right\}$ 를 **인덱스 패밀리** 라고 한다.**1., 2.** 패밀리는 본디 &amp;lsquo;집합족&amp;rsquo;으로 순화하도록 되</description>
    </item>
    
    <item>
      <title>짝으로 독립이라고 상호 독립은 아니다  번스타인 분포</title>
      <link>https://freshrimpsushi.github.io/posts/sbernstein-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sbernstein-distribution/</guid>
      <description>$\displaystyle p(x,y,z) = {{1} \over {4} }$ 여기서 $(x,y,z) \in \left\{ (1,0,0), (0,1,0), (0,0,1), (1,1,1) \right\}$ 다.번스타인 분포는 분포의 조건을 모두 만족시키고는 있지만 자연계에 실재하는 분포라고 보기는 어렵다. &amp;lsquo;짝으로 독립이면 상호 독립이다&amp;rsquo;라는 명제의 반례로 제시된 것으로, 그 외엔 아무런 의미가 없다. 다만 그 반례로써는 상당히 직관적이라 팩트를 숙지하는데 큰 도움이 된다.**</description>
    </item>
    
    <item>
      <title>짝이면서 홀인 순열은 존재하지 않음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/467/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/467/</guid>
      <description>유한대칭군의 순열이 짝수 만큼의 전위의 곱으로 나타날 수 있으면 짝Even 이라고 하고 홀수 만큼의 전위의 곱으로 나타날 수 있으면 홀Odd 라고 한다. 짝이면서 홀인 순열은 존재하지 않는다.짝과 홀의 정의 자체는 상당히 자연스럽지만 추상적인 학문이니만큼 그 두가지 개념이 배타적인가에 대해선 확신할 수 없다. 이에 대해서는 증명이 필요하다. 증명 유한</description>
    </item>
    
    <item>
      <title>체비셰프 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-chebyshevs-inequality/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-chebyshevs-inequality/</guid>
      <description>확률변수 $X$ 의 분산 $\sigma^2 &amp;lt; \infty$ 가 존재하면 $\mu := E(X)$ 와 어떤 양수 $k&amp;gt;0$ 에 대해 $$ \displaystyle P(|X-\mu| \ge k\sigma) \le {1 \over k^2} $$ 비교적 형태가 간단하고 식의 조작이 쉬운데다 결과도 한 눈에 들어오기 때문에 보조정리로써 많이 쓰인다. 다만 마코프 부등식과 비교하자면 분산이 존재해야한다는 조건이 하나 더 있다.조건에서 $2$차 적률이 존재해야하는 것을 보고 너무 쉽고 당연한 조건으로 여길지</description>
    </item>
    
    <item>
      <title>체의 자기동형사상</title>
      <link>https://freshrimpsushi.github.io/posts/automorphism-of-field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/automorphism-of-field/</guid>
      <description>$E$ 가 $F$ 의 확대체라고 하자.1. 체 $E$ 에 대해 동형사상 $\sigma : E \to E$ 을 자기동형사상Automorphism 이라고 하고, $E$ 의 자기동형사상의 집합을 $\text{Auto} (E)$ 와 같이 나타낸다.2. $\sigma \in \text{Auto} (E)$ 에 대해 $\sigma ( a ) = a$ 면 $\sigma$ 가 고정된 $a$ 를 남긴다 고 한다.3. $S \subset \text{Auto} (E)$ 라고 하자. 모든 $a \in F$ 에 대해 모든 $\sigma \in S$ 가 고정된 $a$ 를 남기면 $S$ 가 고정된 부분체 $F$ 를 남긴</description>
    </item>
    
    <item>
      <title>최소분열체</title>
      <link>https://freshrimpsushi.github.io/posts/splitting-field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/splitting-field/</guid>
      <description>$F \le E$ 라고 하자.1. $f(x) \in F[x]$ 가 $E[x]$ 의 일차항들로 인수분해되면 $f(x)$ 가 $E$ 에서 분열된다 고 한다.2. $\left\{ f_{i} (x) \mid i \in I \right\} \subset F[x]$ 에 대해 모든 $f_{i} (x)$ 들의 영을 포함하고 $E$ 가 $\overline{F}$ 의 가장 작은 부분체가 될 때 $E$ 를 **$F$ 상에서 $\left\{ f_{i} (x) \mid i \in I \right\} $ 의 최소분열체** 라고 한다.말이 어려우므로 예시를 통해 개념적으로 이해해보자.유리수체 $\mathbb{Q}$ 에 대해 $( x^4 - 5 x^2 + 6 ) \in \mathbb{Q}</description>
    </item>
    
    <item>
      <title>최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/the-method-of-least-square/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-method-of-least-square/</guid>
      <description>행렬 $A \in \mathbb{C}^{m \times n}$ 와 벡터 $\mathbb{b} \in \mathbb{C}^{m}$ 에 대해 $\mathbb{b} \notin \mathcal{C} (A)$ 이면 방정식 $A\mathbb{x} = \mathbb{b}$ 는 해를 갖지 않고 $\mathbb{x}{*} = \text{argmin} | \mathbb{b} - A \mathbb{x} |{2} $ 를 최소제곱해 라고 정의한다.방정식의 해가 존재하지 않는 것은 안타깝지만 그렇다고 풀이 자체를 포기할 수는 없다. 사실 이 세상에 잘 풀리지 않는, 학계의 최전선에서 수학자들의 해법을 기다리고 있는 방정식들은 대개 그런 문제들이다. 이런 문제를 비</description>
    </item>
    
    <item>
      <title>추상대수학에서의 교대군</title>
      <link>https://freshrimpsushi.github.io/posts/alternating-group/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/alternating-group/</guid>
      <description>$S_{n}$ 의 짝순열들로 이루어진 군을 **대칭군**Alternating Group 이라고 하고 $A_{n}$ 으로 쓴다. $n\le 2$ 에 대해 $\displaystyle \left| A_{n} \right| = {{\left| S_{n} \right|} \over {2}} = {{ n! } \over {2}} $$ A_{n}$ 의 위수가 정확히 $\left| S_{n} \right|$ 의 절반이 된다는 것은 상당히 흥미로운 성질이 아닐 수 없다.교대군은 후에 $5$ 차 이상의 방정식이 근의 공식을 갖지 않음을 보일 때 쓰이므로 매우 중요한 군이라 할 수 있다. 증명 우선</description>
    </item>
    
    <item>
      <title>추상대수학에서의 군</title>
      <link>https://freshrimpsushi.github.io/posts/group/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/group/</guid>
      <description>모노이드 $\left&amp;lt; G, * \right&amp;gt;$ 의 원소 $a$ 와 항등원 $e$ 대해 $a * a&#39; = a&#39; * a = e $ 를 만족하는 $a&#39;$ 가 존재하면 $\left&amp;lt; G, * \right&amp;gt;$를 군 이라고 정의한다. 즉, 군은 아래의 성질들을 만족하는 이항연산구조다.(i) 연산에 대해 결합법칙이 성립한다.(ii) 모든 원소에 대해 항등원이 존재한다.(iii) 모든 원소에 대해 역원이 존재한다.마그마부터</description>
    </item>
    
    <item>
      <title>추상대수학에서의 궤도 순환 전위</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-cycle-transposition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-cycle-transposition/</guid>
      <description>$\sigma$ 를 군 $G$ 에 대한 순열이라고 하면 $a, b \in G$ 에 대한 동치관계 $\sim$ 는 $b=\sigma^n (a)$ 를 만족하는 정수 $n$ 이 존재할 때 $a \sim b$ 로 정의된다.1. $\sim$ 의 동치류들을 $\sigma$ 의 궤도 라고 한다.2. 원소가 둘 이상인 궤도를 많아도 하나만 가지는 순열을 순환 이라고 한다.3. 순환이 가지는 궤도들 중 가장 기수가 큰 궤도의 기수를 순환의 길이Length 라고 한다.4. 길이가 $2$ 인 순환</description>
    </item>
    
    <item>
      <title>추상대수학에서의 대칭군</title>
      <link>https://freshrimpsushi.github.io/posts/symmetric-group/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/symmetric-group/</guid>
      <description>집합 $A$ 에 대해 전단사 $\phi : A \to A$ 를 순열Permutation 이라고 한다. $S_{A}$ 는 모든 순열을 모아놓은 집합으로써 함수의 합성 $\circ$ 에 대해 군 $\left&amp;lt; S_{A} , \circ \right&amp;gt; $ 를 이루고 **대칭군** 이라 부른다.대칭군이 정말 군의 조건을 만족하는지는 순열이 전단사로 정의되었다는 점에서 쉽게 확인할 수 있다. 주로 관심의 대상이 되는 것은 $A$ 가 유한집합인 경우 즉 $|A| = n$</description>
    </item>
    
    <item>
      <title>추상대수학에서의 래디컬과 닐래디컬</title>
      <link>https://freshrimpsushi.github.io/posts/radical-and-nilradical/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/radical-and-nilradical/</guid>
      <description>$N$ 이 환 $R$ 의 아이디얼이라고 하자.(1) $\text{rad} N := \left\{ a \in R , | , a^n \in N \right\} $ 을 $N$ 의 래디컬Radical 이라고 한다.(2) $a^{n} = 0$ 을 만족하는 $n \in \mathbb{N}$ 이 존재하면 $a$ 가 닐포텐트Nilpotent 라고 한다. 닐포텐트 엘러먼트들의 집합 $\text{nil} R := \left\{ a \in R , | , a^n = 0 \right\} $ 을 $R$ 의 닐래디컬Nilradical 이라고 한다.$N$ 의 래디컬을 $\sqrt{N}$,</description>
    </item>
    
    <item>
      <title>추상대수학에서의 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/ideal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ideal/</guid>
      <description>환 $(R , + , \cdot )$ 의 모든 $a,b \in R$ 에 대해 $a I \subset I$ 와 $I b \subset I$ 을 만족하는 부분군 $(I, +)$ 을 아이디얼Ideal 이라고 한다.간단한 예시로써 $n \mathbb{Z}$ 는 $\mathbb{Z}$ 의 아이디얼이 된다. 아이디얼 이라는 명명은 말 그대로 이상적인Ideal 에서 왔다. 추상대수에서 다루기에 이상적인 부분군이기 때문에 실제로 그렇게 부르는 것이다.특히 $R$ 이 가환환이라면 $I$ 가 $R$ 의 정규</description>
    </item>
    
    <item>
      <title>추상대수학에서의 정규부분군</title>
      <link>https://freshrimpsushi.github.io/posts/normal-subgroup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normal-subgroup/</guid>
      <description>잉여류의 성질 보러가기군 $G$ 과 그 부분군 $H$ 에 대해 $aH = \left\{ ah \ | \ h \in H \right\} $ 를 좌잉여류Left Coset , $Ha = \left\{ ha \ | \ h \in H \right\} $ 를 우잉여류Right Coset 이라고 한다. $H$ 가 $G$ 의 부분군이고 모든 $g \in G$ 에 대해 $gH = Hg$ 면 $H$ 를 $G$ 의 정규부분군Normal Subgroup 이라고 하고 $H \triangleleft G$ 로 쓴다.$H = \left\{ e \right\}$ 혹은 $H = G$ 인 $H \leqslant G$ 가 존재하지 않는 $G \ne \left\{ e \right\} $</description>
    </item>
    
    <item>
      <title>추상대수학에서의 체</title>
      <link>https://freshrimpsushi.github.io/posts/field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/field/</guid>
      <description>해석학에서의 체 보러가기(1) 환 $(R , + , \cdot)$ 이 곱셉 $\cdot$ 에 대한 항등원 $1 \in R$ 을 가질 때, $1$ 을 단위원Unity 이라고 한다.(2) 단위원을 가진 환 $R$ 에서 곱셈에 대한 역원이 존재하는 원소 $r \ne 0$ 를 단원Unit 이라고 한다.(3) 단위원을 가진 환 $R$ 에서 $0$ 이 아닌 모든 원소가 단원이면 상환Division Ring 이라고 한다.(4) 곱셈에 대해 교환</description>
    </item>
    
    <item>
      <title>추상대수학에서의 환</title>
      <link>https://freshrimpsushi.github.io/posts/ring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ring/</guid>
      <description>두 이항연산 덧셈$+$과 곱셈$\cdot$에 대해서 아래와 같은 규칙을 만족하는 집합 $R$을 환 이라고 정의한다.$a$, $b$, $c$가 $R$의 원소일 때,$1.$ $a+b=b+a$ 덧셈에 대하여 교환법칙이 성립한다.$2.$ $(a+b)+c=a+(b+c)$ 덧셈에 대하여 결합법칙이 성립한다.$3.$ $\forall a \ \exists 0\ \ \mathrm{s.t} \ a+0=a$ 덧셈에 대한 항등원이 존재한다. $4.$ $\forall a \ \exists -a\ \ \mathrm{s.t}\ a+(-a)=0$ 모든 원</description>
    </item>
    
    <item>
      <title>추상적 듀얼 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/abstract-dual-graph/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abstract-dual-graph/</guid>
      <description>기하적 듀얼 그래프의 성질[3] 평면 그래프 $G$ 와 그 기하적 듀얼 그래프 $G^{ * }$ 에 대해,$C \subset E(G)$ 가 사이클 $\iff$ $C^{ * } \subset E \left( G^{ * } \right)$ 는 컷셋추상적 듀얼 그래프 는 직관적으로 평면 그래프에 대해 기하적 듀얼 그래프와 달리 일반적인 그래프에 대해서 추상적으로 정의된다. 듀얼 그래프가 어떠한 방법으로 만들어지는 것이 아니라, 듀얼의 성질을 가지면 듀얼 그래</description>
    </item>
    
    <item>
      <title>충분히 작은 각도란</title>
      <link>https://freshrimpsushi.github.io/posts/sufficiently-small-angle-small-angle-approximation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficiently-small-angle-small-angle-approximation/</guid>
      <description>물리학의 많은 곳에서 $\sin x\approx x$ 근사를 사용한다. 이게 되는 이유는 아래의 식이 성립하기 때문이다. $$ \lim \limits_{x\rightarrow 0}\frac{\sin x}{x}=1 $$ 이는 고등학교에서 처음 배우기 때문에 대학생이라면 당연한 것처럼 느껴질 정도이다. 그래서 근사할 수 있다는 것에 의문을 가지는 사람은 거의 없을 것이다. 그런데 여기서 어느정도로 작아야 비슷하다고 할 수 있는지가 궁금한 사람들이 있을 것이다.</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률</title>
      <link>https://freshrimpsushi.github.io/posts/probability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability/</guid>
      <description>수리통계학에서 정의됐던 확률$\mathcal{F}$ 가 집합 $\Omega$ 의 시그마 필드라고 하자.1. 가측 집합 $E \in \mathcal{F}$ 를 사건Event 라고 한다.2. $\mathcal{F}$ 상의 측도 $P : \mathcal{F} \to \mathbb{R}$ 가 $P(\Omega) = 1$ 를 만족하면 $P$ 를 확률 이라고 한다.3. $( \Omega, \mathcal{F} , P )$ 를 확률 공간Probability Space 라고 한다.측도론의 힘을 빌리면 확률론의 여러가지 개념들에 대해 수리적</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 조건부 기대값</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-expectation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-expectation/</guid>
      <description>수리통계학에서의 조건부 기대값확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.$\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드고 확률 변수 $X \in \mathcal{L}^{1} ( \Omega )$ 는 적분 가능하다. 모든 $A \in \mathcal{G}$ 에 대해 $$ \int_{A} Y d P = \int_{A} X d P $$ 를 만족하는 $\mathcal{G}$-가측 확률 변수 $Y$ 가 유일하게 존재하면 $Y := E ( X | \mathcal{G} )$ 를 **$\mathcal{G}$ 에 대한 $X$ 의 조건부 기대</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 조건부 확률</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-probability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-probability/</guid>
      <description>수리통계학에서의 조건부 확률확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.1. $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드라고 할 때, 사건 $F \in \mathcal{F}$ 에 대해 $$ P(F | \mathcal{G}) := E ( \mathbb{1}{F} | \mathcal{G}) $$ 를 $\mathcal{G}$ 에 대한 $F$ 의 조건부 확률 이라고 한다.2. 다음과 같이 정의된 $f{Y | X =x}$ 를 $X=x$ 일 때 $Y$ 의 조건부 밀도라고 한다. $$ f_{Y | X = x} (y | X = x) := {{\partial } \over {\partial y }} P( Y \le y | X = x) $$ * 아직 측도</description>
    </item>
    
    <item>
      <title>측도의 약한 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/weak-convergence-of-probability-measure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weak-convergence-of-probability-measure/</guid>
      <description>거의 확실히 수렴 $\implies$ 확률 수렴 $\implies$ 분포 수렴(약한 수렴)힐베르트 공간에서 약한 수렴공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자.$S$ 에서 정의되는 측도 $\mu$ 와 측도의 시퀀스 $\left\{ \mu_n \right\}{n \in \mathbb{N}}$ 이 $n \to \infty$ 일 때 모든 $f \in C{b}(S)$ 에 대해 다음을 만족하면 $\left\{ \mu_{n} \right\}$ 이 측도 $\mu$ 로 **약하게 수렴한다**Converge Weakly 고 말하고 $\mu_{n}\overset{W}{\to}\mu$ 와 같이 나타낸다. $$ \int_{S} f</description>
    </item>
    
    <item>
      <title>카마이클 수</title>
      <link>https://freshrimpsushi.github.io/posts/carmichael-number/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/carmichael-number/</guid>
      <description>자연수 $n$ 이 모든 $1 \le a \le n$ 에 대해 $a^{n} \equiv a \pmod{n} $ 를 만족하면 카마이클 수 라고 한다. 모든 카마이클 수는 $2$ 를 제외한 서로 다른 소수의 곱으로만 나타난다.카마이클 수는 합성수임에도 불구하고 페르마 판정법을 통과하는, 말하자면 소수처럼 보이는 수다. 예로써 $561=3 \cdot 11 \cdot 17$ 은 합성수지만 $a^{561} \equiv a \pmod{561}$ 이 항상 성립한다.한편 이러한 카마이클 수를 잡아내기 위해 밀</description>
    </item>
    
    <item>
      <title>카오스 이론에서 맵들의 컨쥬게이트</title>
      <link>https://freshrimpsushi.github.io/posts/conjugate-of-maps-in-chaos-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conjugate-of-maps-in-chaos-theory/</guid>
      <description>$X$ 에서 정의된 두 맵 $f, g : X \to X$ 에 대해 $C \circ f = g \circ C$ 를 만족하는 연속 단사 $C$ 가 존재하면 $f$ 와 $g$ 가 컨쥬게이트 라고 한다.카오스 이론에서 맵의 컨쥬게이트는 일종의 아이소메트리, 아이소멀피즘, 호메오몰피즘과 비슷한 개념이며, 완전히 같지는 않더라도 용도는 정확히 같다. 수학에서 하는 일이 다 그렇듯, 계산이 쉬운 곳에서 어떤 성질이 있음을 확인</description>
    </item>
    
    <item>
      <title>카오틱 어트랙터</title>
      <link>https://freshrimpsushi.github.io/posts/chaotic-attractor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaotic-attractor/</guid>
      <description>$\left\{ f^{n} (x_{0}) \right\}_{n \in \mathbb{N}_{0}}$ 을 카오틱 오빗이라고 하자. 만약 $x_{0} \in \omega(x_{0})$ 이면 $\omega ( x_{0})$ 을 **카오틱 셋**Chaotic Set 이라고 한다. 만약 카오틱 셋이 어트랙터면 **카오틱 어트랙터** 라고 한다. * $\omega$ 는 오메가-리미트 셋을 의미한다.카오스 이론에서 카오틱 어트랙터란 그 분과의 이름이 될만큼 중요하고 관심을 가지는 개념이다. 다만 수학적, 이론적으로 너무 멀</description>
    </item>
    
    <item>
      <title>카오틱 트랜지션</title>
      <link>https://freshrimpsushi.github.io/posts/chaotic-transition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaotic-transition/</guid>
      <description>시스템이 파라매터의 변화에 따라 카오틱해지거나 카오틱해지지 않는 등의 현상을 카오틱 트랜지션 이라고 한다.예로써 로지스틱 패밀리를 생각해보면 $g_{a} = ax (1-x)$ 로 만들어지는 시스템은 파라매터 $a$ 에 따라 달라지는 모습을 보이다가 $a=4$ 일 때 카오틱 오빗을 가짐을 확인할 수 있다. 그러면 그 다음 질문은 바로 &amp;lsquo;$a&amp;gt;4$ 일 때는 어떻게 될 것인가&amp;rsquo;다.우선 $a&amp;gt;4$ 면</description>
    </item>
    
    <item>
      <title>카이제곱 분포</title>
      <link>https://freshrimpsushi.github.io/posts/chi-square-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chi-square-distribution/</guid>
      <description>자유도 $r &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\chi^{2} (r)$ 를 카이제곱 분포 라고 한다. $$ f(x) = {{ 1 } \over { \Gamma(r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} \qquad , x \in (0, \infty) $$ [1] 적률 생성 함수 : $$ m(t) = (1-2t)^{-r/2} \qquad , t &amp;lt; {{ 1 } \over { 2 }} $$ [2] 평균과 분산 : $X \sim \chi^{2} (r)$ 이면 $$ E(X) = r \\ \text{Var} (X) = 2r $$ [a] $k$차 적률 : $X \sim \chi^{2} (r)$ 이라고 하자. $k &amp;gt; - r/ 2$ 이면 $k$차 적률이 존재하고 $$ E X^{k}</description>
    </item>
    
    <item>
      <title>카이제곱 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-chi-square-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-chi-square-distribution/</guid>
      <description>$X \sim \chi^{2} (r)$ 이면 $$ E(X) = r \\ \text{Var} (X) = 2r $$ Strategy : 카이제곱분포는 고맙게도 적률 공식이 알려져있다.카이제곱 분포의 적률$X \sim \chi^{2} (r)$ 이라고 하자. $k &amp;gt; - r/ 2$ 이면 $k$차 적률이 존재하고 $$ E X^{k} = {{ 2^{k} \Gamma (r/2 + k) } \over { \Gamma (r/2) }} $$ 증명(평균) $$ EX^{1} = {{ 2^{1} \Gamma (r/2 + 1) } \over { \Gamma (r/2) }} = 2 \cdot {{ r } \over { 2 }} = r $$ ■ 증명(분산) $$ EX^{2} = {{ 2^{2} \Gamma (r/2 + 2) } \over { \Gamma (r/2)</description>
    </item>
    
    <item>
      <title>칸토어-베른슈타인 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cantor-bernstein-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cantor-bernstein-theorem/</guid>
      <description>집합 $A$, $B$ 에 대해 $A$ 가 $B$ 의 부분집합과 대등하고 $B$ 가 $A$ 의 부분집합과 대등하면 $A$ 와 $B$ 는 대등하다. * 두 집합이 대등하다는 것은 두 집합 사이에 전단사가 존재한다는 것이다.Strategy : $x$ 에 함수 $f$ 를 $k$ 번 취하는 것을 $f^{k}(x)$ 와 같이 나타내려고 한다. 그러면 모든 $k \in \mathbb{N}$ 에 대해 $f^{k}(x) = f \left( f^{k-1}(x) \right)$ 처럼 나타낼 수 있을 것이다. 이러한 관점에서 $f^{0}$ 는 함수 $f$ 를 한</description>
    </item>
    
    <item>
      <title>칸토어의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cantors-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cantors-theorem/</guid>
      <description>임의의 집합 $X$ 와 그 멱집합 $\mathscr{P} (X)$ 에 대해 $\text{card}(X)&amp;lt;\text{card}(\mathscr{P} (X)) $어떤 집합이든 그 기수는 그 멱집합의 기수보다 작다는 말이다. 이미 집합론에서 말하는 무한이라는 개념에 익숙해졌다면 이것은 조금 의외일지도 모르겠다. 자연수의 집합 $\mathbb{N}$ 이 유리수의 집합 $\mathbb{Q}$ 과 일대일 대응이 존재했고, 안타깝게도 $\mathbb{R}$ 과의 일대일 대응은 존재하지 않았다. 이러한 논의들을 생각해볼 때 집합의 포함</description>
    </item>
    
    <item>
      <title>켤레 동형사상 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conjugation-isomorphism-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conjugation-isomorphism-theorem/</guid>
      <description>체 $F$ 에 대해 $\alpha$ 가 $F$ 상에서 대수적이라고 하자.1. 최대차항의 계수가 $1$ 이고 $p( \alpha ) = 0$ 를 만족하는 $p(x) \in F[x]$ 를 $\alpha$ 에 대한 $F$ 상에서의 기약 다항함수 라 하고 $\text{irr} ( \alpha , F) = p(x)$ 와 같이 나타낸다.2. $\text{irr} ( \alpha , F)$ 의 최대차항의 차수를 $F$ 상에서 $\alpha$ 의 차수 라 하고 $\deg ( \alpha , F )$ 와 같이 나타낸다.3. $F$ 의 대수적 확대체 $E$ 에 대해 $\text{irr} ( \alpha , F) = \text{irr} ( \beta , F)$ 라고 하면</description>
    </item>
    
    <item>
      <title>켤레사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/conjugate-prior/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conjugate-prior/</guid>
      <description>사전분포와 사후분포가 동일한 분포족에 속하면 사전분포를 켤레사전분포 라고 한다.베이지안이란 본래 사전분포가 어떻게 되든 업데이트를 통해 모수를 찾아가는 것이긴 하지만, 모형에 대해 어느정도 아는 바가 있다면 적절한 사전분포를 사용함으로써 수학적 계산을 간단하게 하고 결과를 이해하기 쉽게 할 수 있다.(1) $\text{Bin} (n , \theta) $ 의 켤레사전분포는 $\theta \sim \text{Beta}</description>
    </item>
    
    <item>
      <title>코시 적분 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-cauchys-integral-formula/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-cauchys-integral-formula/</guid>
      <description>함수 $f : A \subseteq \mathbb{C} \to \mathbb{C}$가 단순연결영역 $\mathscr{R}$에서 해석적이라고 하자. $\mathscr{R}$ 내부의 단순폐경로 $\mathscr{C}$가 어떤 점 $\alpha$를 둘러싸고 있다면, $\displaystyle f(\alpha) = {{1} \over {2 \pi i }} \int_{\mathscr{C}} {{f(z)} \over { z - \alpha }} dz$장님이 눈을 뜨고 앉은뱅이가 벌떡 일어설 공식이다.수학적인 아름다움은 말할 것도 없고</description>
    </item>
    
    <item>
      <title>코시-슈바르츠 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cauchy-schwarz-inequality/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cauchy-schwarz-inequality/</guid>
      <description>일반화된 증명 보기$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\ge { (ax+by) }^{ 2 } $빠르게는 고등학교 과정부터 접하게 되는 부등식으로, 분야를 가리지 않고 여러 곳에서 쓰이고 있다.대수적인 증명은 매우 간단하다.**증명 $({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})-{ (ax+by) }^{ 2 } $$ ={a}^{2}{x}^{2}+{b}^{2}{x}^{2}+{a}^{2}{y}^{2}+{b}^{2}{y}^{2}-{ (ax+by) }^{ 2 } $$ ={b}^{2}{x}^{2}+{a}^{2}{y}^{2}-2axby $$ ={ (ay-bx) }^{ 2 } $$ \ge 0 $$ \Rightarrow ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\ge { (ax+by) }^{ 2 } $ ■ 증명과정에서 알 수 있듯 등호가 성립하는 경우는 $ay-bx=0$인 경우 뿐이다.코시-슈바르</description>
    </item>
    
    <item>
      <title>콘 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-cone-condition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-cone-condition/</guid>
      <description>**콘 조건$(\mathrm{The\ cone\ condition})$ $\Omega \subset \mathbb{R}^n$이 열린 집합이라고 하자. 만약에 어떤 유한 콘이 존재해서 각각의 $x \in \Omega$에 대해서 $x$를 꼭짓점으로 가지는 유한 콘 $C_x \subset \Omega$가 존재하면 $\Omega$가 콘 조건을 만족한다 고 한다.모든 $x\in \Omega$에 대해서 위 그림과 같이 $C_x \in \O</description>
    </item>
    
    <item>
      <title>콜레스키 분해를 통한 최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/least-squares-using-cholesky-decomposition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/least-squares-using-cholesky-decomposition/</guid>
      <description>$A \in \mathbb{C}^{m \times n}$ 과 벡터 $\mathbb{b} \in \mathbb{C}^{m}$ 에 대해 $\text{rank} A = n$ 이고 $A \mathbb{x} = \mathbb{b}$ 의 최소제곱해를 $\mathbb{x}_{*}$ 이라고 하자.Step 1. 주어진 방정식의 양변에 $A^{ * }$ 을 곱해 표준방정식 $A^{ * } A \mathbb{x} = A^{ * } \mathbb{b}$ 을 세운다.표준방정식의 해는 원래 방정식의 최소제곱해가 되므로, 표준방정식의 해 $\mathbb{x}$ 를 구하면 된다.Step 2. $\mathbb{y} := A^{ * } \mathbb{b}$ 을 계산해 $A^{ * } A \mathbb{x} = \mathbb{y}$ 을 얻는다.Step 3.</description>
    </item>
    
    <item>
      <title>콜레스키 분해의 유일성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-uniqueness-of-cholesky-decomposition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-uniqueness-of-cholesky-decomposition/</guid>
      <description>$A&amp;gt;0$ 은 오직 하나의 콜레스키 분해를 가진다.고유값 대각화, 특이값 분해, 슈어 분해, LU 분해, LDU 분해 모두 유일성을 가지지 않는다는 공통점이 있다.이 방법들은 모두 고유값과 고유벡터의 관계를 이용하거나 $\displaystyle 1 = a {{1} \over {a}} $ 이므로 $L$ 이나 $U$ 에 나눠줄 수 있기 때문이다.하지만 콜레스키 분해는 고유값의 개념을 사용하지 않고 $A=LL^{T}$ 로 나타나므로 $1$을 둘로</description>
    </item>
    
    <item>
      <title>쾨니히스베르크의 다리 문제와 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/k%C3%B6nigsberg-bridge-problem-and-solution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k%C3%B6nigsberg-bridge-problem-and-solution/</guid>
      <description>쾨니히스베르크의 다리 문제 는 다음과 같이 도시에 놓인 7개의 다리를 한 번씩만 건너면서 처음 있는 위치로 돌아올 수 있는지에 관한 것이었다. 해법을 모른다면 언뜻 경우의 수를 다 따져봐야하는 막막한 문제로 보인다. 일단 수학 문제처럼 보이지도 않고, 모든 경우를 다 따져보면 풀릴 것 같은데 막상 따져보기가 쉽지는 않다.위대한 수학자 오일러는 이것을 그래프</description>
    </item>
    
    <item>
      <title>쿨롱 게이지와 로렌츠 게이지</title>
      <link>https://freshrimpsushi.github.io/posts/coulomb-gauge-and-lorenz-gauge/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coulomb-gauge-and-lorenz-gauge/</guid>
      <description>**** 게이지 변환 **** 1. 쿨롱 게이지 **$(\mathrm{Coulomb\ gauge})$ 정자기학에서와 같이 벡터 전위의 발산Divergence을 $0$으로 한다. $$ \nabla \cdot \mathbf{A}=0 $$ 이렇게 하면 전하밀도에 관한 식을 스칼라전위에 대해서만 나타낼 수 있다. 즉, 푸아송 방정식$(\mathrm{Poisson\ equation})$이 된다. $$ \nabla ^2 V = -\frac{1}{\epsilon_0}\rho $$ 장점은 스칼라 전위$V$를 계산하기</description>
    </item>
    
    <item>
      <title>크로네커 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-kronecker-thoerem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-kronecker-thoerem/</guid>
      <description>정의 체 $F$ 에 대해 $F \le E$ 인 $E$ 를 $F$ 의 확대체Extension Field 라고 한다. 정리 $f(x) \in F[x]$ 가 상수가 아니라고 하면 $F$ 의 확대체 $E$ 와 $f ( \alpha ) = 0$ 인 $ \alpha \in E$ 가 존재한다. 확대체의 예로써 $\mathbb{C}$ 는 $\mathbb{R}$ 의 확대체다. 크로네커의 정리 는 당장 $F$ 에서는 다항함수의 근이 존재하지 않을지라도 정의역을 $E$ 로 키울 수 있고, 키우면 근이 존재함을 함의한다. $F$ 가 어떻게 생</description>
    </item>
    
    <item>
      <title>타원의 일반화 일립소이드</title>
      <link>https://freshrimpsushi.github.io/posts/ellipsoid/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ellipsoid/</guid>
      <description>행렬의 특이값 분해선형 변환 $A \in \mathbb{R}^{m \times m}$ 에 대해 $m$차원 단위구 $N := \left\{ \mathbb{x} \in \mathbb{R}^{m} : \left| \mathbb{x} \right|{2} = 1 \right\}$ 의 이미지 $AN$ 을 일립소이드 라고 한다. $A$ 의 아이겐 밸류 $\sigma{1}^{2} &amp;gt; \cdots \ge \sigma_{m}^{2} \ge 0$ 와 그에 따른 단위 아이겐 벡터 $u_{1} , \cdots , u_{m}$ 에 대해 $\sigma_{i} u_{i}$ 를 일립소이드의 **축**Axis 라고 한다.* $m$차원 단위구는 중심이 $\mathbb{0} \in \mathbb{R}^{m}$ 이고 반지름이 $1$ 인 점들을 모아놓은 집합으로,</description>
    </item>
    
    <item>
      <title>타이트 확률 측도</title>
      <link>https://freshrimpsushi.github.io/posts/tight-probability-measure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tight-probability-measure/</guid>
      <description>타이트 확률 과정공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자.$P$ 가 $S$ 에서 정의된 확률 측도라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $P(K) &amp;gt; 1 - \varepsilon$ 가 되도록하는 컴팩트 셋 $K$ 가 존재하면 $P$ 가 타이트 하다고 한다.일반적으로 학부 수준 이하의 확률에서는 타이트하지 않은 확률은 접하기가 어렵다. 가령 정규분포를 따르는 확률 변수 $X$ 에서 유도된 확률 측</description>
    </item>
    
    <item>
      <title>토탈 배리에이션</title>
      <link>https://freshrimpsushi.github.io/posts/total-variation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/total-variation/</guid>
      <description>가측공간 $(X, \mathcal{E})$위의 부호 측도 $\nu$의 토탈 배리에이션 $| \nu |$를 다음과 같이 정의한다. $$ |\nu |=\nu^+ +\nu^- $$ 이때 $\nu=\nu^+-\nu^-$는 $\nu$의 조던 분해이다.$\nu^+$와 $\nu^-$를 각각 $\nu$의 포지티브 배리에이션$(\mathrm{positive}$ $\mathrm{variation})$, 네거티브 배리</description>
    </item>
    
    <item>
      <title>통계학의 세가지 대표값  최빈값 중앙값 평균</title>
      <link>https://freshrimpsushi.github.io/posts/mode-median-mean/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mode-median-mean/</guid>
      <description>수리통계학에서의 평균 대표값들의 수리적 성질 대표값 은 데이터를 설명하는 대표적인 값을 말한다. 수천 수만에 달하는 데이터가 있어도 일일이 다 살펴볼 게 아니라면 결국 중요한 것은 데이터가 무엇을 의미하느냐고, 대표값은 이를 효과적으로 요약한다. 그 중 가장 자주 쓰이는 세가지 대표값으로써 최빈값 , 중앙값 , 평균 이 있다. 0. 최빈값 : 표본에서 가장 자</description>
    </item>
    
    <item>
      <title>특성 방정식을 이용한 비선형 1계 편미분 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-nonlinear-first-order-pde-using-characteristic-equations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-nonlinear-first-order-pde-using-characteristic-equations/</guid>
      <description>특성 방정식 을 이용한 비선형 1계 편미분 방정식 의 풀이는 미분 방정식이 어떻게 주어지느냐에 따라서 조금씩 다르다. 이는 문제에 선형성이 어느정도로 있는지에 따라 구분한다. 완전히 선형 인경우, 가장 높은 미분항이 선형 인경우, 아예 비선형 인 경우로 구분한다. 당연히 언급한 순서대로 어렵다. **특성 방정식 $$ \begin{cases}(a)\ \ \dot{\mathbf{p}} (s) = -D_xF\big(\mathbf{p}(s),\ z(s),\ \mathbf{x}(s) \big)-D_zF\big(\mathbf{p}(s),\ z(s),\ \mathbf{x}(s) \big)\mathbf{p}(s) \\ (b)\ \ \dot{z}(s) =</description>
    </item>
    
    <item>
      <title>특이값 분해를 통한 최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/least-squares-using-sigular-value-decomposition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/least-squares-using-sigular-value-decomposition/</guid>
      <description>$A \in \mathbb{C}^{m \times n}$ 과 벡터 $\mathbb{b} \in \mathbb{C}^{m}$ 에 대해 $\text{rank} A = n$ 이고 $A \mathbb{x} = \mathbb{b}$ 의 최소제곱해를 $\mathbb{x}{*}$ 이라고 하자.Step 1. 특이값 분해$A = \widehat{U} \widehat{\Sigma} V^{ * }$ 를 만족하는 정규직교행렬 $\widehat{U}$ 과 대각행렬 $\widehat{\Sigma}$ 과 유니터리 행렬 $V$ 를 구한다.**Step 2. 특이값 분해에서 얻은 $\widehat{U}$ 를 통해 정사영 $P : = \widehat{U} \widehat{U}^{ * }$ 을 구한다.$A \mathbb{x}{} = P \mathbb{b}$ 이므로 $\widehat{U} \widehat{\Sigma} V^{ * } \mathbb{x}_{} = \widehat{U} \widehat{U}^{ * } \mathbb{b}$ 이고 양변의 왼쪽</description>
    </item>
    
    <item>
      <title>특정한 분포를 따르는 확률변수들의 덧셈 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/202/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/202/</guid>
      <description>확률 변수 $X_{1} , \cdots , X_{n}$ 들이 상호 독립이라고 하자.**[1] 이항 분포** : $X_i \sim \text{Bin} ( n_{i}, p)$ 이면 $$ \displaystyle \sum_{i=1}^{m} X_{i} \sim \text{Bin} \left( \sum_{i=1}^{m} n_{i} , p \right) $$ **[2] 푸아송 분포** : $X_i \sim \text{Poi}( m_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \text{Poi} \left( \sum_{i=1}^{n} m_{i} \right) $$ **[3] 감마 분포** : $X_i \sim \Gamma( k_{i}, \theta)$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \Gamma \left( \sum_{i=1}^{n} k_{i} , \theta \right) $$ **[4] 카이제곱 분포** : $X_i \sim \chi^2 ( r_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \chi ^2 \left( \sum_{i=1}^{n} r_{i} \right) $$ **[5] 정규 분포** : $X_i \sim N(</description>
    </item>
    
    <item>
      <title>파동의 경계조건 반사 투과</title>
      <link>https://freshrimpsushi.github.io/posts/boundary-conditoion-of-wave-reflection-transmission/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/boundary-conditoion-of-wave-reflection-transmission/</guid>
      <description>위 그림과 같이 서로 다른 줄 2개가 묶여있다고 하자. 파동이 줄 1을 따라서 왼쪽에서 오른쪽으로 전파되는 상황이라고 하자. 파동의 전파 속도는 질량과 관계가 있으므로 줄이 묶인 곳을 지나면서 파동의 속도가 달라진다. 편의상 매듭의 위치를 $x=0$라고 하고 파동이 왼쪽에서 들어온다고 하자. 그러면 입사파$(\mathrm{incident\ w</description>
    </item>
    
    <item>
      <title>파동함수의 규격화와 제곱적분 가능</title>
      <link>https://freshrimpsushi.github.io/posts/normalize-of-wave-function-and-square-integrable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normalize-of-wave-function-and-square-integrable/</guid>
      <description>**1. 파동함수$(\mathrm{wave\ function})$와 확률 밀도$(\mathrm{probability\ density})$ 파동함수는 양자역학에서 시간, 위치에 따른 입자의 운동 상태를 나타내는 함수이다. 보통 $u$, $\psi$, $\Psi$로 표기한다. 본 블로그에서 위치와 시간에 대한 파동함수는 $\psi(x,t)$로 나타내고 시간에 무</description>
    </item>
    
    <item>
      <title>파동함수의 상대적 위상의 중요성</title>
      <link>https://freshrimpsushi.github.io/posts/201/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/201/</guid>
      <description>파동함수는 코사인으로 표현할 수 있는 것은 물론 복소수 꼴로 표현할 수도 있다.$\psi=Re^{i\theta}$이 때 물리적으로 의미를 가지는 것은 $\psi$가 아니라 $ | \psi | ^2$이기 때문에 위상은 중요하지 않다.계산하면 어차피 결과에는 반영되지 않는 부분이다.즉, 아무렇게나 바꿔도 상관 없다는 말이다.다만 파동함수를 다른 두</description>
    </item>
    
    <item>
      <title>파이썬에서 numpy array로 행병합 열병합하는 법 How to Bind in Row or Column numpy array</title>
      <link>https://freshrimpsushi.github.io/posts/1409/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1409/</guid>
      <description>import numpy as np a = np.array([[1,2,3]]) b = np.array([[4,5,6]]) print(a) print(b) print(np.c_[a,b]) print(np.r_[a,b]) 파이썬의 numpy 패키지는 무척 편리한 기능을 많이 제공한다. 다음의 스크린샷에서 보이다시피 객체 numpy.c_와 numpy.r_는 대괄호 [] 안에 들어간 배열들을 각각 열(column)병합, 행(row)병합한 배열이다. 여기서 이들이 메서드가 아님을 분명히 하고 넘어가자. 마치 메서드처럼 쓰고 있지만 어디</description>
    </item>
    
    <item>
      <title>파이썬에서 리스트의 요소를 찾아서 위치를 반환하는 함수</title>
      <link>https://freshrimpsushi.github.io/posts/which-function-in-python/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/which-function-in-python/</guid>
      <description>R 에서는 이와 비슷한 역할을 하는 which 함수가 기본적으로 구현되어있다. 파이썬의 리스트에도 모듈로써 .index()가 있긴하지만, 가장 앞 요소의 위치만 가르쳐준다는 점에서 which()처럼 사용하기에 부족함이 있었다. 두번째 팩터인 item은 본래 리스트로 주는 것이 맞으나, 리스트가 아니더라도 어느정도는 대응하도록 구현되었다. 검색</description>
    </item>
    
    <item>
      <title>파투의 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fatous-lemma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fatous-lemma/</guid>
      <description>함숫값이 음이 아닌 가측 함수의 수열 $\left\{ f_{n} \right\}$ 에 대해 $$ \displaystyle \int_{E} \left( \liminf_{n \to \infty} f_{n} \right) dm \le \liminf_{n \to \infty} \int_{E} f_{n} dm $$ 실해석에서의 단조 수렴 정리와 지배 수렴 정리를 증명하기 위해 필요한 보조정리다. 가측 함수라는 조건이 빠진 급수에 대한 파투 보조정리는 다음과 같다.함숫값이 음이 아닌 함수의 수열 $\left\{ f_{k} : \mathbb{N} \to [0, \infty) \right\}_{k \in \mathbb{N}}$ 에 대해 $$ \sum_{j=1}^{\infty} \liminf_{k \to \infty} f_{k} (j) \le \liminf_{k \to \infty} \sum_{j=1}^{\infty} f_{k} (j) \qquad , \forall j \in \mathbb{N} $$</description>
    </item>
    
    <item>
      <title>파푸스-굴딘 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pappus-guldinus-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pappus-guldinus-theorem/</guid>
      <description>$yz$-평면 상의 도형 $F$ 의 넓이를 $A$ 라고 하고 $F$ 를 $z$-축으로 회전시켜서 얻은 회전체 $W$ 의 부피를 $V$ 라고 하자. $z$-축과 $F$ 의 무게중심 사이의 거리를 $r$ 이라고 하면 $V = 2 \pi r A$*본 포스트는 &amp;lsquo;학수짱&amp;rsquo;님의 요청으로 작성되었다.파푸스-굴딘 정리는 고등학교 수준으로는 증명할 수 없지만 회전체에 대해 배울</description>
    </item>
    
    <item>
      <title>패러데이 법칙과 렌츠의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/faradays-law-and-lenzs-law/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/faradays-law-and-lenzs-law/</guid>
      <description>패러데이 법칙 패러데이 법칙 변화하는 자기장은 전기장을 만들어 낸다. $$ \nabla \times \mathbf{E} = -\dfrac{\partial \mathbf{B}}{\partial t} $$ 패러데이가 1831년에 발표한 실험결과의 내용은 다음과 같다. 실험 1. 자기장 속에 놓여진 도선 고리를 오른쪽 으로 당겼다. 고리에 전류가 흘렀다. 실험 2. 자기장 속에 도선 고리를 고정하고 자석을 왼쪽 으로 밀었다. 고리에 전류가 흘렀다.실험 3. 도선 고리와 자석</description>
    </item>
    
    <item>
      <title>패러사이틱 솔루션</title>
      <link>https://freshrimpsushi.github.io/posts/parasitic-solution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/parasitic-solution/</guid>
      <description>패러사이틱 솔루션Parasitic Solution 이란 직역했을 때 &amp;lsquo;기생하는 해&amp;rsquo;라는 뜻으로 메소드가 진행될수록 크기가 커지며 부호가 바뀌는 등의 항을 말한다. $a_{n} = 2^{-n} + (-2)^{n}$ 이라는 수열이 $ (-2)^{n}$ 때문에 수렴하지 않는 걸 상상하면 좋다. 이런 항에다 &amp;lsquo;패러사이틱&amp;rsquo;이라는 표현을 쓰는것은 수렴을 방해한다는</description>
    </item>
    
    <item>
      <title>편극과 유도된 쌍극자 쌍극자 모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/polarization-dipole-and-dipole-moment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/polarization-dipole-and-dipole-moment/</guid>
      <description>전기적으로 중성인 원자가 전기장 $ \mathbf{E}$속에 놓여져 있다면 어떤 일이 일어날까? 간단히 생각해보면 아무 일도 일어나지 않을 것 같다. &amp;ldquo;원자가 전기적으로 중성이기 때문에 전기장으로부터 아무 영향도 받지 않는다&amp;quot;가 정답처럼 들린다. 하지만 사실은 그렇지 않다. 전기적으로 중성인 원자가 겉으로 보기엔 아무</description>
    </item>
    
    <item>
      <title>편미분 방정식이란</title>
      <link>https://freshrimpsushi.github.io/posts/partial-differential-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partial-differential-equation/</guid>
      <description>편미분 방정식 이란 둘 이상의 변수와 그 편도함수들이 일부가 포함된 임의의 함수를 말한다.정수 $k \ge 1$, 열린 집합 $U \subset \mathbb{R}^{n}$, 주어진 $F : {\mathbb{R}}^{n^{k}}\times{\mathbb{R}}^{n^{k-1}}\times \cdots \times \mathbb{R}^{n}\times \mathbb{R}\times U \to \mathbb{R}$와 미지수 $u : U \to \mathbb{R}$에 대해서 아래의 표현 $$ F(D^{k}u(x), D^{k-1}u(x),\cdots,Du(x),u(x),x)=0,\quad x\in U \tag {1} $$ 을 $k$-오더 편미분 방정식 이라 한다. 이때 $D^{k}u$는 멀티인덱스 표기법이다. 편</description>
    </item>
    
    <item>
      <title>편자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/pacf-partial-autocorrelation-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pacf-partial-autocorrelation-function/</guid>
      <description>ACF : 자기상관함수EACF : 확장자기상관함수CCF : 교차상관함수$\left\{ Y_{t} \right\}_{t=1}^{n} $ 이 확률과정이고 시차 $k$ 에 대해서 $Y_{t-1}, \cdots , Y_{t-(k-1)}$ 로 $Y_{t}$ 를 회귀분석한 잔차를 $\widehat{e_{t}}$, $Y_{t-k}$ 를 회귀분석한 잔차를 $\widehat{e_{t-k}}$ 이라고 하자.**1.** 다음과 같이 정의된 $\phi_{kk}$ 를 시차 $k$ 의 **편자기공분산함수** 라고 한다. $$ \phi_{kk} := \text{cor} ( \widehat{e_{t}} , \widehat{e_{t-k}} ) $$ **2.** 다음과 같이 정의된 $\phi_{kk}$ 를 시차 $k$</description>
    </item>
    
    <item>
      <title>평행육면체</title>
      <link>https://freshrimpsushi.github.io/posts/parallelepiped/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/parallelepiped/</guid>
      <description>**패러럴러파이프$(\mathrm{parallelepiped})$ $n$개의 선형 독립인 벡터 $y_1,\ \cdots,\ y_n \in \mathbb{R}^n$가 주어졌다고 하자. 그러면 아래와 같은 집합 $P$를 패러럴러파이드라고 한다. $$ P = \left\{ \sum \limits_{j=1}^{n} \lambda_j y_j \ \ \Big| \quad 0\le \lambda_j \le 1 \right\} $$ 더 자세히는 원점을 꼭짓점$(\mathrm{vertex})$ 중의</description>
    </item>
    
    <item>
      <title>평행축 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-parallel-axis-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-parallel-axis-theorem/</guid>
      <description>수직축 정리평행축 정리 강체의 임의의 회전축에 대한 관성모멘트는 그 축과 평행 하고 질량중심을 지나는 회전축에 대한 관성모멘트와 강체의 질량과 두 축 사이의 거리제곱의 곱을 더한 것과 같다. $$ \color{red}I=\color{blue}{I_{cm}}+\color{green}{md^2} $$ **증명** 임의로 좌표축을 설정하고 z축에 대한 관성모멘트를 $I_z$라 하자. $$ I_z=\sum\limits_i m_i {r_i}^2=\sum\limits_i m_i ({x_i}^2+{y_i}^2) $$ 원점에서 강체의 임의의 점까지의 거리를 원점에서 질량</description>
    </item>
    
    <item>
      <title>폐구간에서 적분할 수 없는 함수  디리클레 함수</title>
      <link>https://freshrimpsushi.github.io/posts/dirichelt-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichelt-function/</guid>
      <description>$f(x) := \begin{cases} 1 &amp;amp;, x \in \mathbb{Q} \\ 0 &amp;amp;, x \notin \mathbb{Q} \end{cases}$ 을 디리클레 함수라고 한다. 디리클레 함수는 $[0,1]$ 에서 적분할 수 없다.디리클레 함수는 리만적분을 할 수 없는 대표적인 함수로, 아마 해석학 이상의 공부를 하지 않는다면 평생 상상도 해볼 일 없는 변태적인 예시다. 콕 찝어서 리만적분 할 수 없다고 말하는 이유는 리만적분이 아니면 적분가능할 수도 있기 때문이다. 증명 실수의 조</description>
    </item>
    
    <item>
      <title>포물선의 접선의 방정식 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/52/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/52/</guid>
      <description>우선은 기울기가 주어진 경우를 먼저 보도록 하자.포물선 $y^{ 2 }=4px$에 접하는 직선의 방정식이 $y=mx+n$일 때,두 도형은 한 점에서만 만나야 하므로$ (mx+n)^{ 2 }=4px $$ \Rightarrow m^{ 2 }x^{ 2 }+2(mn-2p)x+n^{ 2 }=0 $근의 공식에 따라, $ \frac { D }{ 4 }=m^{ 2 }n^{ 2 }-4mnp+4p^{ 2 }-m^{ 2 }n^{ 2 }=0$위 식을 정리하면 $n=\frac { p }{ m }$이고, 이를 직선의 방정식에 대입하면포물선에 접하는 직선</description>
    </item>
    
    <item>
      <title>포흐하머 기호</title>
      <link>https://freshrimpsushi.github.io/posts/pochhammer-symbol/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pochhammer-symbol/</guid>
      <description>포흐하머 기호는 아래와 같이 두 종류의 표현이 있다. **하강 계승$(\mathrm{falling\ factorial})$ $$ \begin{align*} x^{\underline{n}}=(x)_{n}&amp;amp;=x(x-1)(x-2)\cdots(x-n+1) \\ &amp;amp;=\frac{x!}{(x-n)!}=\frac{\Gamma (x+1) }{ \Gamma(x-n+1)} \\ &amp;amp;=\prod \limits_{k=0}^{n-1}(x-k) \end{align*} $$ **상승 계승$(\mathrm{rasing\ factorial})$ $$ \begin{align*} x^{\overline{n}}=x^{(n)}&amp;amp;=x(x+1)(x+2)\cdots(x+n-1) \\ &amp;amp;=\frac{(x+n-1)!}{(x-1)!}=\frac{\Gamma (x+n) }{ \Gamma(x)} \\ &amp;amp;=\prod \limits_{k=0}^{n-1}(x+k) \end{align*} $$ $x^{\overline{0}}$과 $x^{\underline{0}}$은 $1$로 정의한다. $$ x^{\overline{0}}=x^{\underline{n}}=1 $$ 조합</description>
    </item>
    
    <item>
      <title>폴리노미얼 인터폴레이션</title>
      <link>https://freshrimpsushi.github.io/posts/polynomial-interpolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/polynomial-interpolation/</guid>
      <description>서로 다른 $x_{0} , \cdots , x_{n}$ 의 데이터 $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$ 에 대해 $p (x_{i} ) = y_{i}$ 와 $\deg p \le n$ 을 만족하는 폴리노미얼 $p$ 를 **폴리노미얼 인터폴레이션** 이라고 한다.**[1] 존재성과 유일성** : 주어진 데이터에 대해서 $p$ 는 유일하게 존재한다.**[2] 라그랑주 공식** : $\displaystyle p_{n} (x) = \sum_{i=0}^{n} y_{i} l_{i} (x) $**[3] 뉴턴 계차상 공식** : $\displaystyle p_{n} (x) = f(x_{0}) + \sum_{i=1}^{n} f [ x_{0} , \cdots , x_{i}</description>
    </item>
    
    <item>
      <title>푸리에 급수 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-fourier-series/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-fourier-series/</guid>
      <description>주어진 함수 $f$에 대해서 아래의 급수를 $f$의 푸리에 급수 라고 한다. $$ \begin{align*} \lim \limits_{N \rightarrow \infty} S^{f}_{N}(t)&amp;amp;=\lim \limits_{N \to \infty}\left( \dfrac{a_0}{2}+\sum \limits_{n=1}^{N} \left( a_n \cos \dfrac{n\pi t}{L} + b_n\sin\dfrac{n\pi t}{L} \right) \right) \\ &amp;amp;= \dfrac{a_0}{2}+\sum \limits_{n=1}^{\infty} \left( a_n \cos \dfrac{n\pi t}{L} + b_n\sin\dfrac{n\pi t}{L} \right) \\ \text{where} \quad a_0 &amp;amp;=\dfrac{1}{L}\int_{-L}^{L}f(t)dt \\ a_n &amp;amp;= \dfrac{1}{L}\int_{-L}^{L} f(t)\cos\dfrac{n\pi t}{L} dt \\ b_n&amp;amp;=\dfrac{1}{L}\int_{-L}^{L}f(t)\sin\dfrac{n\pi t}{L}dt \end{align*} $$ 푸리에 급수는 주기함수를 주기함수의 합으로 표현한 것이다. 좀 더 구체적으로 말하자면 **삼각함수들의 직교성** 을 이용해 주기 함수 $f$를 삼각함수</description>
    </item>
    
    <item>
      <title>푸리에 변환을 이용한 미분 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-heat-equation-using-fourier-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-heat-equation-using-fourier-analysis/</guid>
      <description>푸리에 급수$(\mathrm{Fourier\ series})$ 와 푸리에 변환$(\mathrm{Fourier\ transform})$ 은 열 방정식$(\mathrm{heat\ equation})$ 을 풀기 위해 등장한 개념이다. 물론 열 방정식 뿐만 아니라 조건을 만족한다면 다른 미분 방정식을 풀 때도 사용할 수 있다. 특히 푸리에 급수는 양자 물리학에서 입자의 에너지를 슈뢰딩거 방정식을</description>
    </item>
    
    <item>
      <title>푸리에 변환의 여러 정의와 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/various-definitions-and-notation-of-fourier-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/various-definitions-and-notation-of-fourier-transform/</guid>
      <description>푸리에 변환의 정의와 표기법은 저자의 필요와 취향에 따라 다양하게 나타난다. 따라서 교재, 강의, 논문 등에서 푸리에 변환을 다루기 전에 정의와 표기법을 확실하게 못 박아두니 그 부분을 잘 읽어봐야한다. 제일 중요한 것은 본질적으로 다 같다는 것 이므로 노테이션에 크게 집중하지 말자. 본 문서에서는 각각의 정의에 어떤 장단점과 차이가 있는지 소개한다.푸</description>
    </item>
    
    <item>
      <title>푸아송 방정식의 기본해</title>
      <link>https://freshrimpsushi.github.io/posts/fundamental-solution-of-poissons-equation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fundamental-solution-of-poissons-equation/</guid>
      <description>**푸아송 방정식의 기본해$(\mathrm{Fundamental\ solution\ of\ Poisson&amp;rsquo;s\ equation})$ $f \in C_{c}^2(\mathbb{R}^n)$이라고 하자.즉, $f$는 두 번 연속적으로 미분가능하고 컴팩트 서포트를 가진다.그리고 $u$를 다음과 같이 정의하자.$\begin{eqnarray*} u(x) = \Phi * f &amp;amp;=&amp;amp; \int_{\mathbb{R}^n} \Phi (x-y) f(y)dy \\ &amp;amp;=&amp;amp; \begin{cases} \displaystyle -\dfrac{1}{2\pi} \int_{\mathbb{R}^2} \log</description>
    </item>
    
    <item>
      <title>푸아송 프로세스</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-process/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-process/</guid>
      <description>지수분포와 푸아송분포의 관계1. $\tau_{1} , \tau_{2} , \cdots \sim \text{exp} ( \lambda )$ 이라고 하자. $\lambda$ 를 **강도**Intensity 라고 한다.**2.** $\displaystyle s_{n} := \sum_{k=1}^{n} \tau_{k}$ 를 **도달 시간**Arrival Time 이라고 한다.**3.** $N_{t} := \begin{cases} 0 , &amp;amp; 0 \le t &amp;lt; s_{1} \\ k , &amp;amp; s_{k} \le t &amp;lt; s_{k+1} \end{cases}$ 와 같이 정의된 확률과정 $\left\{ N_{t} \right\}_{t = 0}^{\infty}$ 를 **푸아송 프로세스** 라고 한다.**(1</description>
    </item>
    
    <item>
      <title>프로그래밍 패러다임</title>
      <link>https://freshrimpsushi.github.io/posts/programming-paradigm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/programming-paradigm/</guid>
      <description>프로그래밍 패러다임 이란 주어진 문제를 해결하는 프로그램을 작성할 때의 관점 내지 방법론을 말한다. 어떠한 패러다임에 알맞는 프로그래밍 언어는 그러한 프로그래밍 패러다임을 갖는다 고 말하며, 대개의 언어는 하나의 패러다임을 갖는다. 여러 패러다임을 갖는 언어를 멀티 패러다임 언어 라고 한다.언어가 하나의 패러다임을 갖는다는 것은 다른 패러다임의</description>
    </item>
    
    <item>
      <title>프로그래밍에서의 일급 객체</title>
      <link>https://freshrimpsushi.github.io/posts/first-class-object-in-programming/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/first-class-object-in-programming/</guid>
      <description>프로그래밍에서 일급 객체는 다음의 조건을 만족하는 요소를 말한다.(i) 함수의 실제 매개변수가 될 수 있다.(ii) 함수의 반환 값이 될 수 있다.(iii) 할당 명령문의 대상이 될 수 있다.(iv) 동일 비교의 대상이 될 수 있다.쉽게 말해 보통 수처럼 다룰 수 있는 것을 일급 객체라고 하는데, 이는 자명하게도 &amp;lsquo;보통 수&amp;rsquo;라</description>
    </item>
    
    <item>
      <title>프로그래밍에서의 타입</title>
      <link>https://freshrimpsushi.github.io/posts/type-in-programming/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/type-in-programming/</guid>
      <description>(1) 타입의 탄생 : 변수를 선언할 때 타입을 지정해야하는 언어를 써본 적이 있다면 거의 확실히 띠꺼움도 함께 느껴봤을 것이다. 어떤 언어들은 굳이 타입이 뭔지 정해주지 않더라도 알아서 계산을 해주는데, 굳이 지저분하고 의미 없어 보이는 코드를 쓰는 것이 시간과 에너지의 낭비처럼 느껴지는 것이다.타입이 없던 시기의 프로그래밍 환경을 상상해보자. 컴퓨터가</description>
    </item>
    
    <item>
      <title>프로베니우스 방법</title>
      <link>https://freshrimpsushi.github.io/posts/frobenius-method/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/frobenius-method/</guid>
      <description>복잡한 미분 방정식을 푸는 방법 중 하나로 해를 다음과 같은 급수라고 가정하는 것이 있다. $$ y=\sum \limits_{n=0}^{\infty} a_{n}x^{n} $$ 그런데 어떤 급수들은 위의 꼴로 나타낼 수 없다. 예를 들면 $$ \frac{\cos x}{x^{2}}=\frac{1}{x^{2}}-\frac{1}{2!}+\frac{ x^{2}}{4!}-\cdots $$ $$ \sqrt{x} \sin x = x^{\frac{1}{2}}\left( x - \frac{x^{3}}{3!}+\cdots \right) $$ 이런 경우에는 해를 아래와 같은 꼴이라고 가정하면 풀 수 있다. $$ y=\sum \limits {n=0}^{\infty} a{n} x^{n+r}=x^r\sum \limits {n=0}^{\infty} a{n}x^{n} \tag{1} $$ 이때 $r$은 양수, 음수는 물론 유리수도 가능하다. 또한 $a_{0}</description>
    </item>
    
    <item>
      <title>피타고라스 트리플</title>
      <link>https://freshrimpsushi.github.io/posts/pythagoras-triple/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pythagoras-triple/</guid>
      <description>$a^2 + b^2 = c^2$ 를 만족하는 세 자연수의 순서쌍 $(a,b,c)$ 을 피타고라스 트리플 이라고 한다. 만약 세 자연수가 공약수를 가지지 않으면 원시 피타고라스 트리플Primitive Pytahgoras Triple 라고 한다.편의상 피타고라스 트리플에 포함된 수를 피타고라스 수라고 부르도록 하자.피타고라스 트리플의 예로는 다들 잘 아는 것과 같이 $(3, 4, 5)$ 그리고 $(5, 12, 13)$ 등이 있다. 주로 관심의 대</description>
    </item>
    
    <item>
      <title>피타고리스 수 중 하나는 반드시 3의 배수여야함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/96/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/96/</guid>
      <description>자연수 $a,b,c$ 가 $a^2 + b^2 = c^2$ 를 만족할 때, $a$ 혹은 $b$ 는 $3$ 의 배수다.피타고라스 수 중 하나는 반드시 짝수일 뿐만이 아니라 적어도 하나는 $3$ 의 배수라는 이야기를 할 수 있다. 증명 어떤 자연수 $n$ 에 대해 자연수를 $3$ 으로 나눈 나머지 $1, 2, 0$ 에 따라 세가지로 나눠 생각해보자.Case 1. 나머지가 $1$ 인 경우 $$ \begin{eqnarray*} (3n+1)^2 &amp;amp;=&amp;amp; 9 n^2 + 6n + 1 \\ &amp;amp;=&amp;amp; 3( 3 n^2 + 2n) + 1 \end{eqnarray*} $$ 이므로 제곱</description>
    </item>
    
    <item>
      <title>피타고리스 수 중 하나는 반드시 짝수여야함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/416/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/416/</guid>
      <description>자연수 $a,b,c$가 $a^2 + b^2 = c^2$ 를 만족할 때, $a$ 혹은 $b$ 는 짝수다.흥미롭게도 피타고라스 수 중 하나는 반드시 짝수여야한다. 증명1 짝수의 제곱은 짝수고 홀수의 제곱은 홀수이므로, $c^2$ 이 홀수면 $a^2$ 이 짝수거나 $b^2$ 여야만 한다. $c^2$ 이 짝수라고 가정하면 $a^2$ 과 $b^2$ 이 모두 홀수거나 짝수인데, 모두 홀수인 경우만 살펴보면 충분하다.어떤 자연수 $x,y,z \in \mathbb{N}$ 에 대</description>
    </item>
    
    <item>
      <title>하르케-베라 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/jarque-bera-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jarque-bera-test/</guid>
      <description>샤피로-윌크 테스트데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 가 주어져 있다고 하자.$H_{0}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따른다.$H_{1}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따르지 않는다.하르케-베라 테스트는 정규성을 검정하기 위해 사용하는 테스트로써, 보통은 정규성이 있음을 보이기 위해서 사용한다. 귀무가설이 채택되는 것이 &amp;lsquo</description>
    </item>
    
    <item>
      <title>하벨-하키미 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-havel-hakimi-algorithm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-havel-hakimi-algorithm/</guid>
      <description>증가하지 않는 시퀀스 $D = (d_{1} , \cdots , d_{n})$ 가 주어져있다고 하자. $D$ 가 그래픽하다면 다음과 같은 방법으로 $D$ 의 실현 $G$ 를 찾을 수 있다.**Step 1. $n$ 개의 버텍스 $v_{1} , \cdots , v_{n}$ 를 가지는 널 그래프를 만든다.**Step 2.** $k = 1, \cdots , n$**Step 2-1.** $v_{k}$ 과 $v_{k+1} , \cdots , v_{d_{k} + 1}$ 를 잇는다.**Step 2-2.** $d_{k+1} , \cdots , d_{d_{k}+1}$ 를 $1$ 씩 감소시킨다.**Step 2-3.** $d_{k} \leftarrow 0$ 와 같이 대입</description>
    </item>
    
    <item>
      <title>하우스도르프 공간 상의 수열은 둘 이상의 점으로 수렴하지 않음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/456/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/456/</guid>
      <description>$T_{2}$-공간 $X$ 상의 수열 $\left\{ x_{n} \right\} $ 은 둘 이상의 점으로 수렴하지 않는다.극한의 유일성에 대해서 그 중요함을 굳이 역설할 필요가 있을까 싶다. 이런 성질이 있다는 것부터가 하우스도르프 공간이 쓸만하다는 증거가 된다.주의해야하는 것은 표현상 &amp;lsquo;단 하나의 점으로 수렴한다&amp;rsquo;와는 조금 차이가 있다는 것이다. 만약 그러</description>
    </item>
    
    <item>
      <title>한 점 컴팩트화</title>
      <link>https://freshrimpsushi.github.io/posts/one-point-compactification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/one-point-compactification/</guid>
      <description>위상공간 $(X , \mathscr{T})$ 에 대해 $\infty \notin X$ 이라고 하자. $X_{\infty} := X \cup \left\{ \infty \right\} $ 에 대해 아래의 **(i)** 와 **(ii)** 를 만족하는 위상 $\mathscr{T}_{\infty}$ 을 정의한 $(X_{\infty } , \mathscr{T}_{\infty} )$ 를 $(X, \mathscr{T})$ 의 **한 점 컴팩트화**One-Point Compactification 이라고 한다.**(i)** $\infty \notin U \implies U \in \mathscr{T}_{\infty}$ 와 $U \in \mathscr{T}$ 은 동치다.**(ii)** $\infty \in U \implies U \in \mathscr{T}_{\infty}$ 와 $X_{\infty} \setminus U $ 가 닫혀있고 컴팩트인 것은 동치다.$(X_{\inf</description>
    </item>
    
    <item>
      <title>한 직선과 x축 y축으로 둘러싸인 삼각형의 넓이</title>
      <link>https://freshrimpsushi.github.io/posts/50/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/50/</guid>
      <description>최댓값 혹은 최솟값, 접선을 구할 수 있는가를 묻는 문제 등에서 꽤 자주 나오는 것이 이런 삼각형의 넓이 $S$다.물론 삼각형의 넓이를 구하는 건 어렵지 않지만 간단한 공식의 형태로 기억해 바로바로 풀 수 있다면 더 좋을 것이다.직선 $y=mx+n$ 의 $y$절편은 $n$, $x$절편은 $-\frac { n }{ m }$이다.이 직선과 $x$축, $y$축으로 둘러싸인 삼각형의 넓이는 $ \displaystyle \left|</description>
    </item>
    
    <item>
      <title>한-바나흐 확장 정리</title>
      <link>https://freshrimpsushi.github.io/posts/hahn-banach-extension-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hahn-banach-extension-theorem/</guid>
      <description>※ 놈 공간 $X$의 놈을 $| \cdot |_X$ 또는 $| x ;X|$로 표기한다. 헷갈릴 여지가 없을 경우에는 $| \cdot |$로 표기할 수도 있다.**한-바나흐 확장 정리$(\mathrm{ Hahn-Banach\ extension\ theorem})$ $X$는 놈 공간이고 $Y \subset X$라고 하자. 그리고 $Y$의 선형 범함수 $y^{ * } \in Y^{ * }$가 주어졌다고 하자. 그러면 아래의 식을 만족하는 $X$의 선형 범함수 $x^{ * } \in X^{ *</description>
    </item>
    
    <item>
      <title>함수 f의 푸리에 급수는 f로 수렴함을 증명 Proof of That Fourier Series of f converges f</title>
      <link>https://freshrimpsushi.github.io/posts/934/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/934/</guid>
      <description>**푸리에 급수의 수렴 조건 주어진 함수 $f$가 구간 $[-L,\ L)$에서 리만적분가능하다고 하자. 그러면 연속인 점 $t$에 대해서 $f$의 푸리에 급수 $\lim \limits_{N \to \infty }S^{f}_{N}(t)$는 $f(t)$로 수렴한다. $$ \lim \limits_{N \rightarrow \infty} S^{f}_{N}(t)=f(t) $$ 이때 $$ \begin{align*} S^{f}_{N}(t)&amp;amp;=\dfrac{a_0}{2}+\sum \limits_{n=1}^{N} \left( a_n \cos \dfrac{n\pi t}{L} + b_n\sin\dfrac{n\pi t} {L} \right) \\ a_0 &amp;amp;=\dfrac{1}{L}\int_{-L}^{L}f(t)dt \\ a_n &amp;amp;= \dfrac{1}{L}\int_{-L}^{L} f(t)\cos\dfrac{n\pi t}{L} dt \\ b_n&amp;amp;=\dfrac{1}{L}\int_{-L}^{L}f(t)\sin\dfrac{n\pi t}{L}dt \end{align*} $$ **보조정리 1 $$ S^{f}{N}(t)=\dfrac{1}{L}\int{-L}^{L}f(x)D_N\left(\dfrac{\pi(x-t)}{L}\right)dx $$ **보조정리 2</description>
    </item>
    
    <item>
      <title>함수의 균등수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-uniformly-of-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-uniformly-of-function/</guid>
      <description>함수의 점별수렴과 균등수렴의 차이$\mathbb{R}$ 의 부분집합 $E \ne \emptyset$ 에 대해 함수 $f : E \to \mathbb{R}$ 와 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 을 정의하자. 모든 $\varepsilon &amp;gt; 0$에 대해 $n \ge N \implies | f_{n} (x) - f(x) | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하면 $E$ 에서 $f_{n}$ 이 $f$ 로 **균등수렴** 한다고 하고 다음과 같이 표기한다. $$ f_n \rightrightarrows f $$ 혹은 $$ f_{n} \overset{\text{unif}}{\to} f $$ 혹은 $$ f_{n} \to f \quad \text{uniformly} $$ 균등수</description>
    </item>
    
    <item>
      <title>함수의 균등연속</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-continuous/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-continuous/</guid>
      <description>공집합이 아닌 $E \subset \mathbb{R}$ 에 대해 $f : E \to \mathbb{R}$ 이라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ | x_{1} - x_{2} | &amp;lt; \delta \land x_{1} , x_{2} \in E \implies | f(x_{1}) - f(x_{2}) | &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $f$ 가 $E$ 상에서 **균등연속** 이라고 한다.* $\land$ 는 논리적으로 &amp;lsquo;그리고&amp;rsquo;를 나타내는 기호다.공집합이 아닌 $E \subset \mathbb{R}$ 에 대해 $f : E \to \mathbb{R}$ 라고 하자.**[1] 컴팩트 거</description>
    </item>
    
    <item>
      <title>함수의 내적을 정적분으로 정의하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/599/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/599/</guid>
      <description>내적의 정의벡터공간 $V $ 에 대해 $x,y,z \in V$ 그리고 $c \in \mathbb{C}$ 이라고 하자. $\left&amp;lt; , , \right&amp;gt; : V^2 \to \mathbb{C} $ 가 아래 네 조건들을 만족시킬 때 $\left&amp;lt; , , \right&amp;gt;$ 를 $V$ 상에서의 내적 으로 정의한다.(i) 켤레대칭성 : $\left&amp;lt; x , y \right&amp;gt; = \overline{ \left&amp;lt; y, x \right&amp;gt; } $(ii) 가산성 : $\left&amp;lt; x + y , z \right&amp;gt; = \left&amp;lt; x, z \right&amp;gt; + \left&amp;lt; y, z \right&amp;gt;$(iii) 동질성 : $ \left&amp;lt; c x , y \right&amp;gt; = c \left&amp;lt; x, y \right&amp;gt;$(iv) 정부호 : $\left&amp;lt; x , x \right&amp;gt; \ge 0$ 그리고 $\left&amp;lt; x , x \right&amp;gt; =0</description>
    </item>
    
    <item>
      <title>함수의 점별수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-pointwise-of-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-pointwise-of-function/</guid>
      <description>함수의 점별수렴과 균등수렴의 차이$\mathbb{R}$ 의 부분집합 $E \ne \emptyset$ 에 대해 함수 $f : E \to \mathbb{R}$ 를 정의하자. 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 이 각각의 $x \in E$ 에 대해 $\displaystyle f(x) = \lim_{n \to \infty} f_{n} (x) $ 을 만족하면 $E$ 에서 $f_{n}$ 이 $f$ 로 점별수렴한다고 한다.위 정의를 입실론-델타 논법으로 다시 써보면 다음과 필요충분조건이다.모든 $\varepsilon &amp;gt; 0$ 과 $x \in E$ 에 대해 $n \ge N \implies |</description>
    </item>
    
    <item>
      <title>함수해석학에서 스플라인 B-스플라인</title>
      <link>https://freshrimpsushi.github.io/posts/spline-and-b-spline-in-functional-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spline-and-b-spline-in-functional-analysis/</guid>
      <description>수치해석학에서의 B-스플라인$\mathbb{R}$에서 정의된 함수 $f:\mathbb{R} \to \mathbb{R}$이 piecewise polynomial이면 $f$를 $\mathbb{R}$위에서의 스플라인 이라고 한다. 다항식이 바뀌는 점을 놋knot 이라 한다.정의를 보면 알 수 있듯이 스플라인이 연속함수여야하는 것은 아니다. 아래와 같은 함수 $f$는 스</description>
    </item>
    
    <item>
      <title>합성곱 컨볼루션의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-convolution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-convolution/</guid>
      <description>컨볼루션은 다음과 같은 성질을 만족한다.(a) 교환법칙 $$ fg=gf $$ **(b) 분배법칙 $$ f*(g+h)=f*g+f*h $$ **(c) 결합법칙 $$ f*(g*h)=(f*g)*h $$ **(d) 스칼라곱의 결합 법칙 $$ a(fg)=(afg)=(f*ag) $$ **(e) 미분 $$ (f*g)&#39;=f&#39;g=fg&#39; $$ **(f) 켤레 복소수 $$ \overline{f*g}=\overline{f} * \overline{g} $$ **(g) 디랙 델타 함수 $$ f*\delta =f $$ 증명 (a) $$ \begin{align*} f*g(x)&amp;amp;=\int _{-\infty} ^{\infty} f(y)g(x-y)dy \\ &amp;amp;=\int_{\infty} ^{-\infty} f(x-z)g(z)(-dz) \\ &amp;amp;=\int_{-\infty} ^{\infty} f(x-z)g(z)dz \\ &amp;amp;=\int_{-\infty} ^{\infty} g(z)f(x-z)dz \\ &amp;amp;=g*f(x) \end{align*} $$ 두번째 등호에서 $x-y=z$로 치환하였다.■ 증명 (b) $$ \begin{align*} f*(g+h)(x) &amp;amp;= \int f(y) (g+h)(x-y)dy \\ &amp;amp;= \int f(y)\left( g(x-y) + h(x-y) \right)</description>
    </item>
    
    <item>
      <title>합성곱과 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/convolution-and-laplace-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convolution-and-laplace-transform/</guid>
      <description>$F(s)=\mathcal{L} \left\{ f(t) \right\}$이고 $G(s)=\mathcal{L} \left\{ g(t) \right\}$라고 하자. 그리고 $F(s)G(s)=H(s)=\mathcal{L} \left\{ h(t) \right\}$라고 하자. 그러면 $h(t)$는 $f(t)$와 $g(t)$의 합성곱 이다. $$ h(t)=\int_0^t f(t-\tau)g(\tau)d\tau = \int_0^t f(\tau) g(t-\tau)d\tau $$ $F(s)G(s)=H(s)=\mathcal{L} \left\{ h(t) \right\}$라고 했을 때 $h(t)=f(t)g(t)$라면 정말 편하고 좋겠지만 그렇지 않다. 대신 $h(t)$는 $f(</description>
    </item>
    
    <item>
      <title>해밀토니안과 라그랑지안의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/convex-duality-of-hamiltonian-and-lagrangian/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convex-duality-of-hamiltonian-and-lagrangian/</guid>
      <description>**르장드르 변환$(\mathrm{Legendre\ transform,\ or\ Fenchel\ transform})$ 주어진 라그랑지안 $L\ :\ \mathbb{R}^n \rightarrow \mathbb{R}$이 아래의 조건을 만족한다고 하자.$(a)$ $L$은 볼록한$(\mathrm{convex})$ 함수이다. $$ \lambda L(v_1) + (1-\lambda)L(v_2) \le L\big( \lambda v_1 +(1-\lambda)v_2 \big) \quad \forall\ v_1,v_2\in \mathbb{R}^n,\quad \forall\ 0\le \lambda \le 1 $$ $(b)$ $\lim \limits_{ |v|\rightarrow \infty} \dfrac{ L(v) }{ |v| }=+\infty$그러면 $L</description>
    </item>
    
    <item>
      <title>해석학에서의 미분적분학의 기본정리 2 증명</title>
      <link>https://freshrimpsushi.github.io/posts/1866/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1866/</guid>
      <description>미분적분학에서의 증명 (Calculus ver.)함수 $f$가 구간 $[a,b]$에서 리만 적분 가능하고 $F&#39;=f$을 만족하는 $[a,b]$에서 미분 가능한 함수 $F$가 존재한다고 하자. 그러면 $$ \int_{a}^{b} f(x) dx= F(b)-F(a) $$ 가 성립한다.$f$의 부정적분 $F$가존재하면, $f$의 정적분 값은 간단하게 구간 양 끝에서의 $F$의 값의 차로 나타난다는 정리이다.</description>
    </item>
    
    <item>
      <title>행공간 열공간 영공간 계수 퇴화차수</title>
      <link>https://freshrimpsushi.github.io/posts/row-space-column-space-null-space-rank-nullity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/row-space-column-space-null-space-rank-nullity/</guid>
      <description>추상대수학에서의 핵 보러가기행렬 $A \in \mathbb{R}^{m \times n}$이 아래와 같이 나타난다고 하자.$ \begin{eqnarray*} A &amp;amp;=&amp;amp; \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; &amp;amp; \vdots \\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn} \end{bmatrix} = \begin{bmatrix} \mathbb{r_{1}} \\ \mathbb{r_{2}} \\ \vdots \\ \mathbb{r_{m}} \end{bmatrix} \\ &amp;amp;=&amp;amp; \begin{bmatrix} \mathbb{c_{1}} &amp;amp; \mathbb{c_{2}} &amp;amp; \cdots \mathbb{c_{n}} \end{bmatrix} \end{eqnarray*}$**(1)** $\left\{ \mathbb{r_{1}} , \mathbb{r_{2}} , \cdots , \mathbb{r_{m}} \right\}$ 에 의해 생성되는 $\mathbb{R}^n$ 의 부분벡터공간을 $A$의 **행공간 $\mathcal{R}(A)$** 라고 정의한다.**(2)** $\left\{ \mathbb{c_{1}} , \mathbb{c_{2}} , \cdots , \mathbb{c_{n}}</description>
    </item>
    
    <item>
      <title>행렬식이란</title>
      <link>https://freshrimpsushi.github.io/posts/determinant/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/determinant/</guid>
      <description>행렬식 이야기를 하기 위해선 선형대수학의 목적 자체를 이야기하지 않을 수 없다. 대부분의 수학에서 말하는 문제는 기본적으로 &amp;lsquo;방정식을 풀 수 있는가&amp;rsquo;로 요약될 수 있다고 해도 과언이 아니다.간단한 방정식인 $ax = b$를 생각해보면, $ a = 0$이 아닌 이상 이 방정식은 해를 가진다는 것을 쉽게 알 수 있다. 이차방정식 $a x^2 + b</description>
    </item>
    
    <item>
      <title>행렬의 QR 분해 QR Decomposition of Matrix</title>
      <link>https://freshrimpsushi.github.io/posts/355/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/355/</guid>
      <description>계수가 $n$ 인 행렬 $A := \begin{bmatrix} \mathbb{a}{1} &amp;amp; \cdots &amp;amp; \mathbb{a}{n} \end{bmatrix} \in \mathbb{C}^{m \times n}{n}$ 에 대해 $i$ 번째까지의 열벡터로 생성된 부분공간 $S{i} (A) := \text{sp} \left\{ \mathbb{a}{1}, \cdots , \mathbb{a}{i} \right\}$ 을 정의하자.벡터공간을 생성할 땐 $i$ 가 클수록 많은 열벡터를 사용할 수 있으므로 $S_{1} (A) \subset S_{2} (A) \subset \cdots S_{n} (A)$ 가 성립할 것이다.물론 정규직교벡터로 이루어진 행렬 $\widehat{Q} : = \begin{bmatrix} \mathbb{q}_{1} &amp;amp; \cdots &amp;amp; \mathbb{q}_{n} \end{bmatrix} \in \mathbb{C}^{m \times n}_{n} $ 에 대해서도 $S_{1} (\widehat{Q}) \subset S_{2} (\widehat{Q}) \subset \cdots S_{n} (\widehat{Q})$ 는 성립한다</description>
    </item>
    
    <item>
      <title>행렬의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-matrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-matrix/</guid>
      <description>정의1 수를 다음과 같이 직사각형의 모양으로 나열해놓은 것을 행렬(matrix) 이라고 한다. $$ A=\begin{bmatrix} 10 &amp;amp; 0 &amp;amp; 3 \\ 0 &amp;amp; 8 &amp;amp; 22 \end{bmatrix} $$ 나열해놓은 각각의 수를 엔트리(entry) 혹은 성분(element) 이라고 한다. 가로 줄을 행(row) 이라고 하며, 세로 줄을 열(column) 이라고 한다. 또한 임의의 행렬이 $m$개의 행과 $n$개</description>
    </item>
    
    <item>
      <title>허미션 허미션 행렬 허미션 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/hermitian-matrix-operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermitian-matrix-operator/</guid>
      <description>임의의 행렬 $A$가 있을 때 $A ^\dagger$를 $A$의 $\mathrm{Hermitian}$(허미션)이라고 한다.$\dagger$는 대거라고 읽고 $A ^\dagger$는 &amp;ldquo;에이 대거&amp;quot;라고 읽는다.단검모양처럼 생겼다해서 대거dagger라는 이름이 붙여졌다.연필로 쓸 땐 그냥 십자가모양처</description>
    </item>
    
    <item>
      <title>헤비사이드 계단 함수를 미분하면 디락 델타 함수가 됨을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/878/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/878/</guid>
      <description>헤비사이드 계단 함수의 미분은 디락 델타 함수이다. $$ \dfrac{dH}{dx}=\delta (x) $$ $H=H(x)$는 헤비사이드 계단 함수($\mathrm{Heaviside}$ $\mathrm{step}$ $\mathrm{function}$, $\mathrm{or}$ $\mathrm{unit}$ $\mathrm{step}$ $\mathrm{function}$ 단위 계단 함수)$H(x)=\begin{cases} 1 &amp;amp; x&amp;gt;0 \\ 0 &amp;amp; x \le 0 \end{cases} $$ \delta=\delta (x)$는 **디락 델타 함수 $1.\ \ \delta (x) = \begin{cases} 0, &amp;amp; x\neq 0 \\ \infty , &amp;amp; x=0 \end{cases} $$ 2.\ \ \displaystyle{ \int_{-\infty}^{\infty}{\delta (x) dx}=1 } $ 증명 $</description>
    </item>
    
    <item>
      <title>호스머-렘쇼 적합도 검정</title>
      <link>https://freshrimpsushi.github.io/posts/hosmer-lemeshow-gof-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hosmer-lemeshow-gof-test/</guid>
      <description>로지스틱 회귀분석 보러가기R 에서 호스머-렘쇼 적합도 검정 하는 법 보러가기로지스틱 회귀분석으로 얻은 모형을 $M$ 이라고 하자.$H_{0}$ : $M$ 은 적합하다.$H_{1}$ : $M$ 은 적합하지 않다.호스머-렘쇼 적합도 검정은 로지스틱 회귀모형의 적합성을 판별하는 대표적인 방법이다.아주 단순한 테스트지만 귀무가설과 대립가설이 헷갈릴 수 있</description>
    </item>
    
    <item>
      <title>호프-락스 공식의 유도와 증명</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-and-proof-of-hopf-lax-formula/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-and-proof-of-hopf-lax-formula/</guid>
      <description>해밀토니안 $H$가 $Du$에만 의존하는 해밀턴-야코비 방정식 의 초기값 문제를 보자. $$ (1) \cdots \quad \begin{cases} u_t + H(Du)=0 &amp;amp; \mathrm{in}\ \mathbb{R}^n \times (0,\infty) \\ u=g &amp;amp; \mathrm{on}\ \mathbb{R}^n \times \left\{ t=0 \right\} \end{cases} $$ 일반적으로는 공간 변수까지 더해 $H(Du,\ x)$이나 $x$에 대해서는 영향을 받지 않는다고 하자. 그리고 해밀토니안 $H\in C^\infty$에 대해서 다음과 같은 가정을 하자. $$ \begin{cases} H \mathrm{\ is\ convex} \\ \lim \limits_{|p|\rightarrow \infty} \dfrac{H(p)}{|p|}=\infty \end{cases} $$ 그</description>
    </item>
    
    <item>
      <title>확률 변수들의 상호 독립과</title>
      <link>https://freshrimpsushi.github.io/posts/iid-mutual-independence-and-iidindependent-and-identically-distributed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/iid-mutual-independence-and-iidindependent-and-identically-distributed/</guid>
      <description>1. 확률 변수 $X_{1} , \cdots , X_{n}$ 가 $i \ne j \implies X_{i} \perp X_{j}$ 를 만족하면 $X_{1} , \cdots , X_{n}$ 이 **짝으로 독립**Pairwise Independent 이라고 한다.**2.** 연속 확률 변수 $X_{1} , \cdots , X_{n}$ 의 조인트 확률 밀도 함수 $f$ 가 각각의 확률 밀도 함수 $f_{1} , \cdots , f_{n}$ 에 대해 다음을 만족하면 $X_{1} , \cdots , X_{n}$ 가 **상호 독립** 이라고 한다. $$ f(x_{1} , \cdots , x_{n} ) \equiv f_{1} (x_{1}) \cdots f_{n} (x_{n}) $$ **3.** 이산 확률 변수 $X_{1} , \cdots</description>
    </item>
    
    <item>
      <title>확률론에서의 레비 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-levys-theorem-in-probability-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-levys-theorem-in-probability-theory/</guid>
      <description>측도론에서의 레비 정리확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져있다고 하자.$\eta$ 가 적분 가능한 확률 변수고 $\left\{ \mathcal{F}{n} \right\}{n \in \mathbb{N}}$ 가 $\mathcal{F}{n} \subset \mathcal{F}{n+1}$ 인 시그마 필드의 시퀀스면 $n \to \infty$ 일 때 $$ E \left( \eta | \mathcal{F}{n} \right) \to E \left( \eta | \mathcal{F}{\infty} \right) $$ * $\displaystyle \mathcal{F}{\infty} = \bigotimes{n=1}^{\infty} \mathcal{F}{n}$ 는 텐서 곱이 아니라 $\mathcal{F}{n}$ 들의 모든 원소들을 포함하면서 가장 작은 시그마 필드를 의미한다. 그다지 새로울 것은 없는 게, 사실 위상 공간 $\Omega$ 의</description>
    </item>
    
    <item>
      <title>확률론에서의 세퍼레이팅 클래스</title>
      <link>https://freshrimpsushi.github.io/posts/separating-class/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separating-class/</guid>
      <description>가측 공간 $(S, \mathcal{B}(S))$ 에서 정의된 두 확률 $P$, $Q$ 에 대해 다음을 만족하는 $\mathcal{C}$ 를 세퍼레이팅 클래스 라고 한다. $$ P(A) = Q(A), \forall A \in \mathcal{C} \implies P(A) = Q(A), \forall A \in \mathcal{B}(S) $$ 세퍼레이팅 클래스가 존재한다는 것은 두 측도가 서로 같은지 확인하기 위해서 가측 공간 전체가 아니라 일부만 확인하면 된다는 의미가 된다. 상식적으로 이렇게 좋은 클래스가 그냥 존재해 줄 리는 없을 것 같지만, 다음의 정리</description>
    </item>
    
    <item>
      <title>확장된 유클리드 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-extended-euclid-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-extended-euclid-theorem/</guid>
      <description>두 정수 $a,b$ 에 대해 $ax + by = \gcd (a,b)$ 는 반드시 정수해를 가진다.이 정리는 선형 합동 정리Linear Congruence Theorem 이라고도 불린다.다소 복잡한 모양새고 존재성만 논하기 때문에 직접적으로 쓰이긴 어려울 것 같지만 의외로 굉장히 많이 사용한다. 구체적인 해 $(x,y)$ 를 찾아주는 건 아니지만 $a$, $b$ 에 대한 관계식에서 출발할 수 있다는 것만 해도 굉장한 수확이기 때문이다. 실제 $x$,</description>
    </item>
    
    <item>
      <title>확장복소평면에서 원은 쌍선형변환을 취해도 원임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/423/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/423/</guid>
      <description>모든 쌍선형변환은 $\overline { \mathbb{C} } $ 의 원을 $\overline { \mathbb{C} } $ 의 원으로 대응시킨다.확장복소평면이란 단순히 복소평면 $\mathbb{C}$ 에서 무한대 $\infty$ 를 더해서 확장한 개념이다.야매지만 수식으로 나타내보면 $\overline { \mathbb{C} } = \mathbb{C} \cup \left\{ \infty \right\} $ 이고, $\infty$ 를 &amp;lsquo;평면의 끝&amp;rsquo; 처럼 생각해도 무관하다.이러한 센스에서 $\infty$ 는 원점에서 무한히 먼 곳이라면 방향에 관계 없</description>
    </item>
    
    <item>
      <title>확장자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/eacf-extended-autocorrelation-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eacf-extended-autocorrelation-function/</guid>
      <description>ACF : 자기상관함수PACF : 편자기상관함수CCF : 교차상관함수R 에서 EACF로 ARMA 모형 선택법PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다. 하지만 $ARMA(p,q)$ 모형에 적용시킬 땐 아르마 모형의 가역성 때문에 $AR(p)$ 라도 $MA(\infty)$ 처럼 보일 수 있고, $MA(q)$ 라도 $AR(\infty)$ 처럼 보일 수 있다. 따라서 이러한 문제를 회피하고 아르마 모형을 찾기위</description>
    </item>
    
    <item>
      <title>환에서 곱셈에 대한 규칙</title>
      <link>https://freshrimpsushi.github.io/posts/rules-of-multiplication-of-ring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rules-of-multiplication-of-ring/</guid>
      <description>$a,\ b,\ c$가 환 $R$의 원소이고 $0$이 덧셈에 대한 항등원이라고 하자.그러면 아래의 성질이 성립한다.$1.$ $a0=0a=0 $$ 2.$ $a(-b)=(-a)b=-(ab) $$ 3.$ $(-a)(-b)=ab $$ 4.$ $a(b-c)=ac-ac \ \ \And\ \ (b-c)a=ba-ca$곱셈에 대한 항등원인 단위원 $1$이 존재하면 아래의 성질 또한 성립한다.$5.$ $(-1)a=-a $$ 6.$ $(-1)(-1)$=1$ 증명 1 ** 덧셈에 대한 항등원과 어떤 원소를 곱해도 다시 덧셈에 대한 항등원이 된</description>
    </item>
    
    <item>
      <title>회귀계수의 F검정 F-test for Regression Coefficient</title>
      <link>https://freshrimpsushi.github.io/posts/672/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/672/</guid>
      <description>다중회귀분석 보러가기R 에서 다중회귀분석 결과 보러가기$n$ 개의 관측치와 $p$ 개의 독립변수에 대한 다중회귀분석에 대해 $i=0,1,\cdots,p$ 라고 하자.$H_{0}$ : $\beta_{1} = \beta_{2} = \cdots = \beta_{p} = 0$ 즉, 모든 독립변수가 종속변수과 관계 없다.$H_{1}$ : $\beta_{1} , \beta_{2} , \cdots , \beta_{p}$ 중 적어도 하나는 $ 0$ 이 아니다. 즉, 종속변수와 관계 있는 독립변수가 존재한다.$\dis</description>
    </item>
    
    <item>
      <title>회귀분석에서의 교호작용</title>
      <link>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</guid>
      <description>우선 질적변수를 포함한 회귀분석에 대해 읽어보는 것을 추천한다. 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 우선 질적변수가 있으므로 성별을 $$ S = \begin{cases} 1 &amp;amp; ,\text{여성} \\ 0 &amp;amp; ,\text{남성} \end{cases} $$ 그리고 학력을 $$ E_{1} = \begin{cases} 1 &amp;amp; ,\text{대졸} \\ 0 &amp;amp; ,\text{고졸} \end{cases} \\</description>
    </item>
    
    <item>
      <title>회전변환 행렬의 거듭제곱 공식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/55/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/55/</guid>
      <description>$$ { \pmatrix {{ \cos \theta }&amp;amp;{ -\sin \theta } \\ { \sin \theta }&amp;amp;{ \cos \theta }} }^{n}=\pmatrix {{ \cos n\theta }&amp;amp;{ -\sin n\theta } \\ { \sin n\theta }&amp;amp;{ \cos n\theta }} (n=1,2,3,&amp;hellip;) $$ 원점을 중심으로 $\theta$만큼 회전하는 일차변환의 행렬을 $n$제곱하면 $n\theta$만큼 회전하는 일차변환이 된다.전략 : 상식적으로도 당연하고, 수학적 귀납법을 이용해 쉽게 증명할 수 있다. 증명 $$ (ㄱ) : { \pmatrix {{ \cos \theta }&amp;amp;{ -\sin \theta } \\ { \sin \theta }&amp;amp;{ \cos</description>
    </item>
    
    <item>
      <title>히든 마코프 체인</title>
      <link>https://freshrimpsushi.github.io/posts/hidden-markov-chain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hidden-markov-chain/</guid>
      <description>위의 그림과 같이 어떤 기계에서 일정한 시간마다 어떤 물건을 생산한다고 생각해보자. 녹색이 정상적인 양품 $1$ 이고 적색이 폐기해야하는 불량품 $0$ 이라면, 지금까지의 기록은 $\left( 1, 0 , 1 \right) $ 이 될 것이다. 이렇게 실제로 눈에 보이는 결과를 시그널Signal 이라고 한다.단, 불량품이 나올 확률은 기계가 정상인지 고장인지에 따라 다르다고 하자. 정상 $+$</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서 직교성 정규 직교 시스템</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-and-orthonormal-system-in-hilbert-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-and-orthonormal-system-in-hilbert-space/</guid>
      <description>$H$를 힐베르트 공간이라고 하자.(a) 두 원소 $x,y\in H$가 $ \left\langle x,y \right\rangle =0$을 만족하면 $x$와 $y$는 서로 직교orthogonal 한다고 하고 다음과 같이 표기한다. $$ x \perp y $$ (b) $H$의 원소들의 집합 $\left\{ x_{k} \right\}_{k\in \mathbb{N}}$이 다음의 식을 만족하면 **직교 시스템**orthogonal system , 혹은 **직교 집합** 이라 한</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서 푸리에 계수 푸리에 급수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-coefficient-fourier-series-in-hilbert-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-coefficient-fourier-series-in-hilbert-space/</guid>
      <description>$H$를 힐베르트 공간, $\left\{ u_{\alpha} \right\}_{\alpha\in A}$를 $H$의 정규직교 시스템이라고 하자. 그러면 고정된 $x\in H$에 대해서 복소 함수 $\hat{x} :A\to \mathbb{C}$를 다음과 같이 정의하자. $$ \hat{x}(\alpha)=\left\langle x,u_{\alpha} \right\rangle $$ 이때 위의 값들을 가리켜 $x$의 $\left\{ u_{\alpha} \right\}$에 대한 **푸리에 계수**Fourier coefficients 라고 한다.$x=f$, $\left\{ u_{\alpha} \right\}=\left\{ e^{-i n x} \right\</description>
    </item>
    
    <item>
      <title>힐베르트 변환</title>
      <link>https://freshrimpsushi.github.io/posts/hilbert-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hilbert-transform/</guid>
      <description>**** **역 라돈 변환 The filterd back projection formular 2차원 평면에서 정의된 적절한 함수 $f$에 대해서 다음의 식이 성립한다. $$ f(x,y)=\dfrac{1}{2} \mathcal{B} \left\{ \mathcal{F}^{-1} \Big[ |S|\mathcal{F} (\mathcal{R}f) (S,\ \theta) \Big]\right\} (x,y) $$ The filtered back-projection formula로 주어진 $\mathcal{R}f$로부터 $f$를 구한 것까지는 좋으나 공식이 너무 길고 알아보기도 힘들다. 여기서 힐베르트 변환을 사용하면 좀 더 간결하게 나타낼 수 있다.우선 다음과</description>
    </item>
    
  </channel>
</rss>
