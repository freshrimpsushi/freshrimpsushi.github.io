<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/</link>
    <description>Recent content on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Fri, 23 Jul 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>바틀렛 항등식</title>
      <link>https://freshrimpsushi.github.io/posts/bartlett-identity/</link>
      <pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bartlett-identity/</guid>
      <description>정리 정칙조건: (R0): 확률밀도함수 $f$ 는 $\theta$ 에 대해 단사다. 수식으로는 다음을 만족시킨다. $$ \theta \ne \theta&#39; \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta&#39; \right) $$ (R1): 확률밀도함수 $f$ 는 모든 $\theta$ 에 대해 같은 서포트를 가진다. (R2): 참값 $\theta_{0}$ 는 $\Omega$ 의 내점Interior Point이다. (R3): 확률밀도함수 $f$ 는 $\theta$ 에 대해 두 번 미분가능하다. (R4): 적분 $\int f (x; \theta) dx$ 은 적분 기호를 넘나들며 $\theta$ 에 대</description>
    </item>
    
    <item>
      <title>라플라스 방정식의 기본해</title>
      <link>https://freshrimpsushi.github.io/posts/fundamental-solution-of-laplaces-equation/</link>
      <pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fundamental-solution-of-laplaces-equation/</guid>
      <description>빌드업1 라플라스 방정식은 회전변환에 대해서 불변하므로 $u(x)$의 변수를 반지름으로 바꿔서 생각할 것이다. 그러면 아래와 같은 과정을 거쳐 미분방정식을 더 쉬운 꼴로 만들어 줄 수 있다. $u=u(x)$를 라플라스 방정식의 해라고 하자. $$ \Delta u = 0 $$ 그리고 $r=|x|=(x_{1}^{2} + \cdots + x_{n}^{2})^{1/2}$라고 두고, $v\in C^2$이고 $u(x) = v(|x|)</description>
    </item>
    
    <item>
      <title>수학에서의 질량 작용 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/law-of-mass-action/</link>
      <pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/law-of-mass-action/</guid>
      <description>법칙 1 화학반응의 정도는 반응에 관여하는 각종 분자수에 같은 힘을 야기하는 물질의 농도에 비례한다. 설명 2 수리적 모델링에서 질량 작용 법칙Law of Mass Action은 법칙이라는 이름이 무색하지 않을만큼 일상적으로 사용된다. 가령 두가지 물질 $A$, $B$ 가 만나 $k$ 만큼의 반응속도로 작용해 $C$ 가 생겨난다고 생각해보자. $$ A + B \overset{k}{\to} C $$ 질량 작용 법칙에 따</description>
    </item>
    
    <item>
      <title>생존 함수</title>
      <link>https://freshrimpsushi.github.io/posts/survival-function/</link>
      <pubDate>Mon, 19 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/survival-function/</guid>
      <description>정의 1 $S(0)=1$ 이면서 증가하지 않는 함수 $S : [0,\infty) \to [0,1]$ 를 생존 함수Survival Function라 정의한다. 설명 생존 함수란 쉽게 말해 시간 $t$ 에 생존해있을 확률 $S(t) \in [0,1]$ 을 매핑하는 함수다. 수학에서 생존이란 딱히 &amp;lsquo;살아있다&amp;rsquo;는 의미에 집착할 필요 없이 어떠한 사건이 일어날 때까지의 기간으로 추상화되며, 확률에 대한 맵핑</description>
    </item>
    
    <item>
      <title>회전변환</title>
      <link>https://freshrimpsushi.github.io/posts/rotation-transformations/</link>
      <pubDate>Sun, 18 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rotation-transformations/</guid>
      <description>2차원 2차원 평면 $\mathbb{R}^{2}$에서 벡터를 반시계반향으로 $\theta$만큼 회전시키는 변환은 다음과 같다. $$ \begin{pmatrix} x^{\prime} \\ y^{\prime} \end{pmatrix} = \begin{pmatrix} \cos \theta &amp;amp; -\sin \theta \\ \sin \theta &amp;amp; \cos \theta \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} $$ 유도 삼각함수의 덧셈정리에 의해 $x^{\prime}, y^{\prime}$은 각각 다음과 같다. $$ \begin{align*} x^{\prime} =&amp;amp; \dfrac{1}{r} \cos(\phi + \theta) \\ =&amp;amp; \dfrac{\cos \phi}{r} \cos \theta - \dfrac{\sin \phi}{r} \sin \theta \\ =&amp;amp; x \cos \theta - y \sin \theta \end{align*}</description>
    </item>
    
    <item>
      <title>에이즈 전염 모델</title>
      <link>https://freshrimpsushi.github.io/posts/aids-infection-model/</link>
      <pubDate>Sat, 17 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/aids-infection-model/</guid>
      <description>개요 에이즈AIDS, 후천면역결핍증후군은 바이러스인 HIV에 의해 발병하며 수십년간 인류를 괴롭혀오고 있는 전염병이다. 에이즈의 전파 경로는 동성애, 이성애, 약물 사용 등으로 다양하며 그에 대한 수학적 모델링은 전체 인구의 구조를 포함하지 않을 수가 없다. 그러나 우선은 가장 단순하게 카스티요Castillo, 카베즈Chavez 등에 의</description>
    </item>
    
    <item>
      <title>절댓값 함수</title>
      <link>https://freshrimpsushi.github.io/posts/absolute-value-function/</link>
      <pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/absolute-value-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $f$를 절댓값 함수absolute value function라고 하고, 함숫값을 $|x|$와 같이 표기한다. $$ |x| := f(x) = \begin{cases} x &amp;amp;\text{if } x&amp;gt;0 \\ 0 &amp;amp;\text{if } x=0 \\ -x &amp;amp;\text{if } x&amp;lt;0 \end{cases},\quad x\in \mathbb{R} $$ 설명 절댓값이란 실수의 크기를 의미하며, 이를 일반화한 것이 놈이다. 삼각부등식이 성립한다. $$ |x + y| \le |x| + |y|,\quad x \in \mathbb{R} $$</description>
    </item>
    
    <item>
      <title>복소수의 극좌표 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/polar-representation-of-complex-number/</link>
      <pubDate>Thu, 15 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/polar-representation-of-complex-number/</guid>
      <description>정의 1 복소수 $z \ne 0$ 는 복소평면 상의 점 $P(x,y)$ 에 대응되며, 선분 $\overline{OP}$ 의 길이 $r := |z|$ 와 $x$ 축과 $\overline{OP}$ 가 만드는 시계반대방향의 각 $\theta$ 을 통해 다음과 같이 극좌표 표기Polar Representation를 할 수 있다. $$ z = r \left( \cos \theta + i \sin \theta \right) $$ 이 때 $\theta$ 를 편각Argument이라 부르며 $\theta = \arg z$ 와 같이 나타낸다. 하나의 복소수에는 무수히 많은 편각 $\theta +</description>
    </item>
    
    <item>
      <title>전도함수: 다변수 벡터함수의 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/total-derivative-of-multivariable-vector-function/</link>
      <pubDate>Wed, 14 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/total-derivative-of-multivariable-vector-function/</guid>
      <description>빌드업1 일변수함수의 도함수의 정의를 떠올려보자. $$ \lim \limits_{h\to 0} \dfrac{f(x+h) - f(x)}{h} = f&#39;(x) $$ 여기서 좌변의 분자를 아래와 같이 $h$에 대한 선형함수로 근사하면 다음과 같다. $$ \begin{equation} f(x+h) - f(x) = a h + r(h) \label{1} \end{equation} $$ 여기서 $r(h)$는 다음과 같은 조건을 만족하는 나머지remainder, 잔차라고 하자. $$ \lim \limits_{h \to 0} \dfrac{r(h)}{h}=0 $$ 그러면 $\eqref{1}$의 양변을 $h</description>
    </item>
    
    <item>
      <title>주기 함수</title>
      <link>https://freshrimpsushi.github.io/posts/periodic-function/</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/periodic-function/</guid>
      <description>정의 함수 $f : \mathbb{R} \to \mathbb{R}$ 이 어떤 상수 $T \ne 0$ 와 모든 $t \in \mathbb{R}$ 에 대해 다음을 만족하면 $T$-주기 함수$T$-periodic function라 한다. $$ f(t + T) = f(t) $$ 예시 사인 $\sin$ 과 코사인 $\cos$ 은 대표적인 주기 함수로써, 위 정의에 따라 $2\pi$-주기 함수다.</description>
    </item>
    
    <item>
      <title>스칼라필드의 라플라시안</title>
      <link>https://freshrimpsushi.github.io/posts/laplacian-of-scalar-field/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplacian-of-scalar-field/</guid>
      <description>정의 스칼라 함수 $u : \mathbb{R}^{n} \to \mathbb{R}$의 그래디언트의 다이벌전스를 라플라시안Laplacian이라 하고 다음과 같이 표기한다. $$ \begin{align*} \Delta u :&amp;amp;= \mathrm{div}(\nabla (u)) \\ &amp;amp;= \mathrm{div} \left( \left( u_{x_{1}}, u_{x_{2}}, \dots, u_{x_{n}} \right) \right) \\ &amp;amp;= u_{x_{1}x_{1}} + u_{x_{2}x_{2}} + \cdots + u_{x_{n}x_{n}} \\ &amp;amp;= \sum _{i=1}^{n} u_{x_{i}x_{i}} \end{align*} $$ 여기서 $u_{x_{i}}=\dfrac{\partial u}{\partial x_{i}}$이다. 설명 수학에서는 다이벌전스를 $\mathrm{div}$로 표기하는 일이 잦고, 라</description>
    </item>
    
    <item>
      <title>깁스 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/gibbs-inequality/</link>
      <pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gibbs-inequality/</guid>
      <description>개요 깁스 부등식Gibbs Inequality은 샤넌 엔트로피와 크로스 엔트로피 사이의 관계를 말해주며, 쿨백-라이블러 발산의 하한을 보장해주는 부등식이다. 정리 $$ H(P) \le H(P,Q) $$ 증명 1 이산형에 대한 경우만 증명하고, 모든 $k$ 에 대해 $p_{k} &amp;gt; 0$ 이라 가정한다. 곡선 $y = \ln x$ 의 $x=1$ 에서의 접선의 방정식은 $y = x - 1$ 이다. 로그함수는 위로 볼록한 함수</description>
    </item>
    
    <item>
      <title>수송 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/transport-equation/</link>
      <pubDate>Sat, 10 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transport-equation/</guid>
      <description>정의1 아래의 편미분방정식을 수송방정식transport equation이라 한다. $$ \begin{equation} u_{t} + b \cdot Du=0\quad \text{in }\mathbb{R}^n \times (0,\ \infty) \label{TPE} \end{equation} $$ $b=(b_1, b_2, \cdot, b_n) \in \mathbb{R}^n$은 고정된 벡터 $u=u(x,t)$는 $u:\mathbb{R}^n \times [0,\infty) \rightarrow \mathbb{R}$ $x=(x_1, \cdots , x_n)\in \mathbb{R}^n$ $t \ge 0$는 시간 $Du=D_{x}u=(u_{x_1}, \cdots ,u_{x_n})$는 공간변수 $x$에 대한 $u$의 그래디언트 설명 $u \in C^1$가 $\</description>
    </item>
    
    <item>
      <title>함수로써의 대각행렬, 대각성분</title>
      <link>https://freshrimpsushi.github.io/posts/diagonal-as-function/</link>
      <pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diagonal-as-function/</guid>
      <description>정의 대각성분 행렬에 대한 $\text{diag} : \mathbb{R}^{n \times n} \to \mathbb{R}^{n}$ 는 다음과 같이 행렬의 대각 성분으로 이루어진 벡터를 의미한다. $$ \text{diag} A = \begin{bmatrix} A_{11} \\ A_{22} \\ \vdots \\ A_{nn} \end{bmatrix} $$ 대각행렬 벡터에 대한 $\text{diag} : \mathbb{R}^{n} \to \mathbb{R}^{n \times n}$ 는 다음과 같이 벡터를 대각성분으로 갖는 행렬을 의미한다. $$ \text{diag} \begin{bmatrix} x_{1} \\ x_{2} \\ \vdots \\ x_{n} \end{bmatrix} = \begin{bmatrix} x_{1} &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; x_{2} &amp;amp; \cdots &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; x_{n} \end{bmatrix} $$ 설명 대각</description>
    </item>
    
    <item>
      <title>동형사상, 모든 n차원 실벡터공간은 Rn과 동형이다</title>
      <link>https://freshrimpsushi.github.io/posts/isomorphism/</link>
      <pubDate>Thu, 08 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isomorphism/</guid>
      <description>정의1 선형변환 $T : V \to W$가 일대일이고 전사이면 $T$를 동형사상isomorphism이라 한다. 혹은 $W$가 $V$와 동형isomorphic이라고 한다. 설명 $T : V \to W$가 동형사상이라는 말은 $V$나 $W$나 사실상 다른게 없다는 말이다. 정리 모든 $n$차원 실벡터공간은 $\mathbb{R}^{n}$과 동형이다</description>
    </item>
    
    <item>
      <title>상대적 엔트로피, 쿨백-라이블러 발산</title>
      <link>https://freshrimpsushi.github.io/posts/relative-entropy-kullback-leibler-divergence/</link>
      <pubDate>Wed, 07 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relative-entropy-kullback-leibler-divergence/</guid>
      <description>빌드업 두 확률분포 $P$ 와 $Q$ 가 있을 때, 이 둘이 얼마나 다른지 궁금할 상황은 얼마든지 쉽게 상상해볼 수 있다. 가령 카메라에 찍힌 숫자가 정확히 어떤 숫자인지에 대해 맞추는 상황을 생각해보자. 숫자 6과 9는 위아래를 정확히 표시하지 않으면 사람도 충분히 헷갈릴만한데, 9에서 아래로 획을 긋는 사람이 있고 아닌 사람이 있으니 수많은 사람들의 필체 데이터를 모</description>
    </item>
    
    <item>
      <title>복소수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-complex-number/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-complex-number/</guid>
      <description>정의 1 이차방정식 $x^{2} +1 = 0$ 의 해 $x = \sqrt{-1}$ 을 허수Imaginary Number라 한다. 두 실수 $x,y \in \mathbb{R}$ 에 대해 $z = x + iy$ 꼴의 수를 복소수Complex Number라 하고 $(x,y)$ 와 같이 나타내기도 한다. 이 때 $\Re (z) = x$ 와 $\Im (z) = y$ 를 각각 $z$ 의 실수부Real Part와 허수부Imaginary Part라 한다. 모든 복소수의 집합을 $\mathbb{C}$ 로 표기한</description>
    </item>
    
    <item>
      <title>크로스 엔트로피</title>
      <link>https://freshrimpsushi.github.io/posts/cross-entropy/</link>
      <pubDate>Sat, 03 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cross-entropy/</guid>
      <description>개요 크로스 엔트로피Cross Entropy는 두 확률분포를 구분하기 위해 필요한 평균 비트수로써, 보통 참으로 가정되는 (레퍼런스) 확률분포 $p$ 와 이를 추정하기 위한 (예상) 확률분포 $q$ 사이에서 정의된다. 정의 1 이산 두 이산확률분포의 확률질량함수 $p,q$ 가 주어져있다고 하자. 두 확률분포의 크로스 엔트로피 $H (p,q)$ 는 다음과 같이 정의된다. $$ H</description>
    </item>
    
    <item>
      <title>푸앙카레 맵</title>
      <link>https://freshrimpsushi.github.io/posts/poincare-map/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poincare-map/</guid>
      <description>정의 1 유클리드 공간 $\mathbb{R}^{n}$ 와 오픈 셋 $U \subset \mathbb{R}^{n}$ 에서 $r$번 미분가능한 함수 $f : U \to \mathbb{R}^{n}$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 그 플로우를 $\phi_t \left( \cdot \right)$ 와 같이 나타내고 벡터 필드를 가로지르는 $n-1$차원 곡면 $\Sigma$ 를 생각해보자. 오픈 셋 $V \subset \Sigma$ 에 대해 다음과 같은 맵 $P$ 를 푸앙카레 맵Poincaré Map이라 한다.</description>
    </item>
    
    <item>
      <title>가역선형변환 공간의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-space-of-invertible-linear-transformations/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-space-of-invertible-linear-transformations/</guid>
      <description>정리1 $\Omega$를 모든 $\mathbb{R}^{n}$ 위의 가역 선형변환들의 집합이라고 하자. $$ \Omega = \left\{ \text{all invertible linear operator on } \mathbb{R}^{n} \right\} $$ (a) $T_{1} \in \Omega$와 $T_{2} \in L(\mathbb{R}^{n})$에 대해서 다음이 성립하면, $B \in \Omega$이다. $$ \| T_{2} - T_{1} \| \| T_{1}^{-1} \| &amp;lt; 1 $$ (b) $\Omega$는 열린 집합이다. (c) 다음과 같이 주어진 $f : \Omega \to \Omega$</description>
    </item>
    
    <item>
      <title>조건부 엔트로피</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-entropy/</link>
      <pubDate>Tue, 29 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-entropy/</guid>
      <description>정의 1 확률변수 $X_{1}, \cdots , X_{n}$ 의 결합확률질량함수 $p$ 혹은 결합확률밀도함수 $f$ 가 주어져 있다고 하자. $H \left( X_{1}, \cdots , X_{n} | X_{k} \right)$ 을 $X_{k}$ 가 주어져 있을 때 $X_{1}, \cdots , X_{n}$ 의 조건부 엔트로피Conditional Entropy라 한다. 이산 $$ H \left( X_{1}, \cdots , X_{n} | X_{k} \right) := - \sum_{x_{1}} \cdots \sum_{x_{n}} p \left( x_{1} , \cdots , x_{n} \right) \log_{2} {{ p \left( x_{1} , \cdots , x_{n} \right) } \over { p(x_{k}) }} $$ 연속 $$ H \left( X_{1}, \cdots , X_{n} | X_{k} \right) := - \int_{\mathbb{R}}</description>
    </item>
    
    <item>
      <title>선형변환의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/the-norm-of-linear-transformations/</link>
      <pubDate>Mon, 28 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-norm-of-linear-transformations/</guid>
      <description>정의1 선형변환 $T \in L(\mathbb{R}^{n}, \mathbb{R}^{m})$의 놈을 다음과 같이 정의한다. $$ \| T \| := \sup \limits_{| \mathbf{x} | \le 1} | T ( \mathbf{x} ) | $$ 설명 (a) 를 보면 다음의 식이 성립하므로, $\| T \|$는 $T$가 $\mathbb{R}^{n}$의 원소를 $\mathbb{R}^{m}$으로 매핑할 때 크기가 변하는 비율이라는 것을 알 수 있다. 그러니까 크기</description>
    </item>
    
    <item>
      <title>일반적인 직선, 평면, 구의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/general-definition-of-line-plane-sphere/</link>
      <pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-definition-of-line-plane-sphere/</guid>
      <description>정의 1 벡터공간 $X$ 가 주어져 있다고 하자. 다음의 방정식을 만족시키는 점들의 집합 $L \subset X$ 혹은 $\alpha (t)$ 그 자체를 점 $\mathbf{x}_{0} \in X$ 를 지나고 벡터 $\mathbf{v} \ne 0$ 와 평행한 직선Line이라 정의한다. $$ \alpha(t) = \mathbf{x}_{0} + t \mathbf{v} \qquad , t \in \mathbb{R} $$ 다음의 방정식을 만족시키는 점들의 집합 $P \subset X$ 를 점 $\mathbf{x}_{0} \in X$ 를 지나고 벡터 $\mathbf{n} \ne 0$ 에 수직인 평면Plane이라 정의한다. $$ \left&amp;lt; \mathbf{x} - \mathbf{x}_{0} , \mathbf{n} \right&amp;gt; =</description>
    </item>
    
    <item>
      <title>선형변환의 합성과 역변환</title>
      <link>https://freshrimpsushi.github.io/posts/composition-and-inverse-of-linear-transformations/</link>
      <pubDate>Sat, 26 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/composition-and-inverse-of-linear-transformations/</guid>
      <description>정의1 선형변환 $T_{1} : X \to Y$과 $T_{2} : Y \to Z$가 주어졌다고 하자. 그러면 다음과 같이 정의되는 변환 $T_{2} \circ T_{1}$을 $T_{1}$과 $T_{2}$의 합성composition of $T_{2}$ with $T_{1}$이라 한다. $$ (T_{2} \circ T_{1})(\mathbf{x}) = T_{2}\left( T_{1}(\mathbf{x}) \right) \quad \mathbf{x} \in X $$ $T :X \to Y$가 선형변환이면 $T$의 치역 $R(T)$는 $Y$의 부분공간이다. $T$가 일</description>
    </item>
    
    <item>
      <title>줄리아에서 변수의 값을 편리하게 출력하는 법, 보간법</title>
      <link>https://freshrimpsushi.github.io/posts/interpolation-in-julia/</link>
      <pubDate>Fri, 25 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interpolation-in-julia/</guid>
      <description>개요 줄리아의 편의 기능인 보간법Interpolation에 대해 설명한다. 인터폴레이션을 잘 이용하면 출력문을 쉽고 깔끔하게 쓸 수 있어 아주 편리하다. 수치해석학의 보간법과 관계는 없으나 단어의 의미는 상통한다. 코드 사용법은 아주 간단하다. 다음과 같이 문자열 안에서 변수 앞에 달러 기호 $를 붙이면 변수가 알아서 문자열처럼 읽힌다. 변수 그</description>
    </item>
    
    <item>
      <title>선형변환의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-linear-transformations/</link>
      <pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-linear-transformations/</guid>
      <description>정리11 선형변환 $T: V \to W$에 대해서 다음의 두 명제는 동치이다. $T$가 일대일이다. $\mathrm{ker}(T) = \left\{ \mathbf{0} \right\}$ 설명 이는 $T$의 커널을 파악하는 것이 $T$가 일대일인지 아닌지를 판별하는 방법이라는 말이다. 위 정리에 의해서 선형변환이 일대일이라는 것은 다음의 조건과 동치이다. $$ \mathbf{x} \ne \mathbf{0} \implies T(\mathbf{x}) \ne \mathbf{0} $$ 증명 $(\implies)$ $T$가 일대일이라고 가정하자. $T$가 선</description>
    </item>
    
    <item>
      <title>벡터공간에서 정의되는 기저의 방향</title>
      <link>https://freshrimpsushi.github.io/posts/orientation-of-bases-of-vector-space/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orientation-of-bases-of-vector-space/</guid>
      <description>정의 1 $$ U = \left\{ \mathbf{u}_{1}, \cdots, \mathbf{u}_{n} \right\} \\ V = \left\{ \mathbf{v}_{1}, \cdots, \mathbf{v}_{n} \right\} $$ 위의 두 순서 있는 집합 $U,V$ 가 벡터공간 $X$ 의 기저라고 하고 행렬 $\left( a_{ij} \right) \in \mathbb{C}^{n \times n}$ 을 다음 식이 만족되도록 정의하자. $$ \mathbf{v}_{j} = \sum_{i=1}^{n} a_{ij} \mathbf{u}_{i} $$ 이때 $\det \left( a_{ij} \right) &amp;gt; 0$ 이면 $U,V$ 가 같은 방향Orientation이라하고 $\det \left( a_{ij} \right) &amp;lt; 0$ 이면 다른 방향이라 한다. 특히 유클리드 공간 $X = \mathbb{R}^{n}$ 에서는 방향의 이름이 있다. $\mathbb{R}^{2}$ 에서 기저</description>
    </item>
    
    <item>
      <title>선형변환의 랭크, 무효차수, 차원정리</title>
      <link>https://freshrimpsushi.github.io/posts/rank-nullity-dimension-theorem-for-linear-transformaions/</link>
      <pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rank-nullity-dimension-theorem-for-linear-transformaions/</guid>
      <description>정의1 $T : V \to W$를 선형변환이라 하자. $T$ 치역 $W$가 유한차원이면, $W$의 차원을 $T$의 랭크rank라고 하고 다음과 같이 표기한다. $$ \mathrm{rank}(T) := \dim (W) $$ $T$의 커널이 유한차원이면, $\mathrm{ker}(T)$의 차원을 $T$의 무효차수nullity라고 하고 다음과 같이 표기한다. $$ \mathrm{nullity}(T) := \dim\left( \mathrm{ker}(T) \right) $$ 설명 행렬의 랭크, 무</description>
    </item>
    
    <item>
      <title>천장 함수와 바닥 함수</title>
      <link>https://freshrimpsushi.github.io/posts/ceil-and-floor-function/</link>
      <pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ceil-and-floor-function/</guid>
      <description>정의 1 천장 함수Ceil $\lceil \cdot \rceil : \mathbb{R} \to \mathbb{Z}$ 와 바닥 함수Floor $\lfloor \cdot \rfloor : \mathbb{R} \to \mathbb{Z}$ 는 다음과 같이 정의된다. $$ \lceil x \rceil := \min \left\{ n \in \mathbb{Z} : x \le n \right\} \\ \lfloor x \rfloor := \max \left\{ n \in \mathbb{Z} : n \le x \right\} $$ 설명 국내에서는 바닥 함수 $\lfloor \cdot \rfloor$ 가 이른바 가우스 함수 $[ \cdot ]$ 로도 많이 알려져있다. 10진법으로 보았을 때 자릿수 버림에 해당하기 때문에 직관적이고, 그래서 쓴다고 하면</description>
    </item>
    
    <item>
      <title>선형변환의 커널, 치역</title>
      <link>https://freshrimpsushi.github.io/posts/kernel-range-for-linear-transformations/</link>
      <pubDate>Sun, 20 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kernel-range-for-linear-transformations/</guid>
      <description>정의1 $T : V \to W$를 선형변환이라 하자. $T$가 $\mathbf{0}$으로 매핑하는 $V$의 원소들의 집합을 커널kernel이라 하고 다음과 같이 표기한다. $$ \mathrm{ker}(T) := \left\{ \mathbf{v} \in V : T( \mathbf{v} ) = \mathbf{0} \right\} $$ 모든 $\mathbf{v} \in V$의 $T$에 의한 상의 집합을 $T$의 치역range라 하고 다음과 같이 표기한다. $$ R(T) := \left\{ T(\mathbf{v}) : \forall \mathbf{v} \in V \right\} $$ 설명 $T : V \to W</description>
    </item>
    
    <item>
      <title>일반적인 각도와 수직의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/general-definition-of-angle/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-definition-of-angle/</guid>
      <description>정의 1 $V$ 가 벡터공간이라고 하자. 두 벡터 $\mathbb{u}, \mathbb{v} \in V$ 에 대해 다음을 만족하는 $\theta$ 를 두 벡터 사이의 각도Angle라 정의한다. $$ \cos \theta = {{ \left&amp;lt; \mathbb{u}, \mathbb{v} \right&amp;gt; } \over { \left| \mathbb{u} \right| \left| \mathbb{v} \right| }} $$ 만약 두 벡터 $\mathbb{u}, \mathbb{v}$ 가 $\left&amp;lt; \mathbb{u}, \mathbb{v} \right&amp;gt; = 0$ 을 만족하면 $\mathbb{u}$ 가 $\mathbb{v}$ 에 직교Orthogonal 혹은 수직Perpendicular하다고 말하고 $\mathbb{u} \perp \mathbb{v}$ 와 같이 나타낸다. $\left&amp;lt; \cdot, \cdot \right&amp;gt;$ 는 내적이</description>
    </item>
    
    <item>
      <title>기저벡터의 상으로부터 선형변환 찾기</title>
      <link>https://freshrimpsushi.github.io/posts/finding-linear-transformations-from-images-of-basis-vector/</link>
      <pubDate>Fri, 18 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finding-linear-transformations-from-images-of-basis-vector/</guid>
      <description>정리1 선형변환 $T : V \to W$가 주어졌다고 하자. $V$가 유한차원이고, $S = \left\{ \mathbf{v}_{1}, \mathbf{v}_{2}, \dots, \mathbf{v}_{n} \right\}$를 $V$의 기저라고 하자. 그러면 임의의 $\mathbf{v} \in V$의 상은 다음가 같이 표현된다. $$ T(\mathbf{v}) = c_{1}T(\mathbf{v}_{1}) + c_{2}T(\mathbf{v}_{2}) + \cdots c_{n}T(\mathbf{v}_{n}) $$ 이때 $c_{i}$는 $\mathbf{v} = \sum c_{i}\mathbf{v}_{i}$를 만족하는 계수이다. 설명 선형변환 $T$에 대해서</description>
    </item>
    
    <item>
      <title>조인트 엔트로피</title>
      <link>https://freshrimpsushi.github.io/posts/joint-entropy/</link>
      <pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/joint-entropy/</guid>
      <description>정의 확률변수 $X_{1}, \cdots , X_{n}$ 의 결합확률질량함수 $p$ 혹은 결합확률밀도함수 $f$ 가 주어져 있다고 하자. 이산 $$ H \left( X_{1}, \cdots , X_{n} \right) := - \sum_{x_{1}} \cdots \sum_{x_{n}} p \left( x_{1} , \cdots , x_{n} \right) \log_{2} p \left( x_{1} , \cdots , x_{n} \right) $$ 연속 $$ H \left( X_{1}, \cdots , X_{n} \right) := - \int_{\mathbb{R}} \cdots \int_{\mathbb{R}} f \left( x_{1} , \cdots , x_{n} \right) \log_{2} f \left( x_{1} , \cdots , x_{n} \right) d x_{1} \cdots d x_{n} $$ 정리 조인트 엔트로피는 다음과 같은 성질들을 가진다. [1] 부등식: $$ 0 \le \max_{k=1 \cdots n} \left\{ H \left( {X_{k}}</description>
    </item>
    
    <item>
      <title>윈도 cmd, powershell에서 줄리아 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-julia-in-windows-cmd-or-powershell/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-julia-in-windows-cmd-or-powershell/</guid>
      <description>가이드 Step 0. julia 1.6 이상 버전 설치 1.6 버전 이상부터는 인스톨 과정에서 환경변수에 넣을 수 있다. 표시된 옵션을 체크하고 설치하면 된다. 구버전을 사용하고 있다면 1.6 이상 버전을 설치하거나 아래의 지시를 따르면 된다. Step 1. 줄리아 설치 경로 확인 줄리아의 설치 경로를 확인한다. 별달리 건드린 게 없다면 다음 경로에 저장되어 있을 것이다. C:\Users\사</description>
    </item>
    
    <item>
      <title>샤넌 엔트로피: 확률변수로 정의되는 엔트로피</title>
      <link>https://freshrimpsushi.github.io/posts/shannon-entropy/</link>
      <pubDate>Sun, 13 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shannon-entropy/</guid>
      <description>개요 샤넌 엔트로피Shannon Entropy 혹은 정보 엔트로피는 확률변수로 정의되는 무질서에 대한 척도로써, 확률분포 상 얼마나 불확실한지에 대한 계량화로 볼 수 있다. 쉽고 복잡한 정의 이산형 엔트로피 1 이산확률변수 $X$ 의 확률질량함수가 $p(x)$ 일 때, $X$ 의 엔트로피를 다음과 같이 나타낸다. $$ H(X) := - \sum p(x) \log_{2} p(x) $$ 연속형 엔트로피 2 연속확률변수 $X$ 의 값이 확률</description>
    </item>
    
    <item>
      <title>피셔 정보</title>
      <link>https://freshrimpsushi.github.io/posts/fisher-information/</link>
      <pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fisher-information/</guid>
      <description>빌드업 스코어 함수 모수 $\theta \in \Omega$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. 로그우도함수가 가장 커지는 추정량인 최대우도추정량은 다음과 같은 편미분방정식을 만족하는 $\widehat{\theta}$ 으로 구할 수 있었다. $$ \sum_{k=1}^{n} {{ \partial \log f \left( x_{k} ; \theta \right) } \over { \partial \theta }} $$ 여기서 $\displaystyle {{ \partial \log f ( x ; \theta ) } \over { \partial \theta }}$ 를 스코어 함수Score Function이라</description>
    </item>
    
    <item>
      <title>샤넌 정보: 확률론으로 정의되는 정보</title>
      <link>https://freshrimpsushi.github.io/posts/information-contents-in-probability-theory/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/information-contents-in-probability-theory/</guid>
      <description>빌드업 카드 맞추기 게임 앨리스와 밥이 조커 없는 트럼프 카드 덱 52장 중 하나를 뒷면으로 뽑고 어떤 카드인지 맞추는 내기를 한다고 상상해보자. 앨리스: 뽑은 카드는 조커가 아니다. 듣자마자 밥이 표정을 찌푸린다. 말이야 맞는 말인데, 너무 당연히 맞는 말이라서 아무런 의미가 없기 때문이다. 내기에 앞서 배당에 대한 합의가 필요해보인다. 두 사람은 우선 막</description>
    </item>
    
    <item>
      <title>종간 전염 모델: 3개 집단 간의 질병 전파</title>
      <link>https://freshrimpsushi.github.io/posts/host-vector-host-model/</link>
      <pubDate>Mon, 07 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/host-vector-host-model/</guid>
      <description>개요 종간 장벽Species Barrier이란 감염원이 종래의 숙주에서 다른 종에 전염되기 어려운 현상을 말한다. 이러한 종간 장벽을 뛰어넘어 병이 전염되는 것을 종간 전염Cross-species Transmission이라 부르는데, 이를 수학적으로 모델링한 호스트-벡터-호스트 모델Host-vector-host mode</description>
    </item>
    
    <item>
      <title>최적해: 최대인수와 최소인수</title>
      <link>https://freshrimpsushi.github.io/posts/optimizer-argmax-and-argmin/</link>
      <pubDate>Sat, 05 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/optimizer-argmax-and-argmin/</guid>
      <description>어려운 정의 임의의 집합 $X$ 과 전순서집합 $\left( Y, \le \right)$ 가 주어져 있다고 하자. $X$ 의 부분집합 $S \subset X$ 에 대해 함수 $f : X \to Y$ 의 최대인수Argument of Maxima $\argmax_{S} : Y^{X} \to 2^{X}$ 와 최소인수Argument of Minima $\argmin_{S} : Y^{X} \to 2^{X}$ 는 다음과 같이 정의된다. $$ \argmax_{S} f := \left\{ x_{\ast} \in S : f \left( x_{\ast} \right) \ge f(x) , \forall x \in X \right\} \\ \argmin_{S} f := \left\{ x_{\ast} \in S : f \left( x_{\ast} \right) \le f(x) , \forall x \in X \right\} $$ $2^{X}$ 은 $X$ 의 멱집</description>
    </item>
    
    <item>
      <title>성병 모델: 2개 집단 간의 질병 전파</title>
      <link>https://freshrimpsushi.github.io/posts/venereal-disease-model/</link>
      <pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/venereal-disease-model/</guid>
      <description>개요 쿡Cooke과 요크Yorke에 의해 제안된 성병 전파의 수학적 모델에 대해 알아본다. 레퍼런스에서는 성병의 구체적인 예로써 임질Gonorrhea을 고려했다. 모델 1 $$ \begin{align*} {{d S_{1}} \over {d t}} =&amp;amp; - \beta_{12} S_{1} I_{2} + \gamma_{1} I_{1} \\ {{d I_{1}} \over {d t}} =&amp;amp; \beta_{12} S_{1} I_{2} - \gamma_{1} I_{1} \\ {{d S_{2}} \over {d t}} =&amp;amp; - \beta_{21} S_{2} I_{1} + \gamma_{2} I_{2} \\ {{d I_{2}} \over {d t}} =&amp;amp; \beta_{21} S_{2} I_{1} - \gamma_{2} I_{2} \end{align*} $$ 변수 $S_{k}(t)$: $t$ 시점에서 병에 걸릴 수 있는S</description>
    </item>
    
    <item>
      <title>돌턴법칙</title>
      <link>https://freshrimpsushi.github.io/posts/daltons-law/</link>
      <pubDate>Wed, 02 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/daltons-law/</guid>
      <description>법칙 $n$ 종류의 분자가 섞인 기체 혼합물이 있다고 하자. 이 기체의 총 압력은 각 기체의 압력을 더한 것과 같다. $$ p = \sum \limits_{i=1}^{n}N_{i} k_{B} T = \sum \limits_{i=1}^{n}p_{i} $$ 설명 영국의 화학자 돌턴(Dalton, 1766~1844)의 이름을 따서 명명되었다.</description>
    </item>
    
    <item>
      <title>수리통계학에서의 정칙성 조건</title>
      <link>https://freshrimpsushi.github.io/posts/regularity-conditions-in-mathematical-statistics/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regularity-conditions-in-mathematical-statistics/</guid>
      <description>개요 수학을 사용하는 과목에서 대개 정칙성Regularity Conditions이란 대개 응용될 구석이 많으면서 이론적인 전개가 편해지는 조건들을 말하며, 수리통계학에서는 다음과 같다. 가정 1 모수 $\theta \in \Omega$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. $X$ 와 같은 분포로 iid하게 뽑은 랜덤샘플 $X_{1} , \cdots , X_{n}$ 는 같은 확률</description>
    </item>
    
    <item>
      <title>구의 입체각</title>
      <link>https://freshrimpsushi.github.io/posts/solid-angle-of-sphere/</link>
      <pubDate>Mon, 31 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solid-angle-of-sphere/</guid>
      <description>정의1 반지름이 $r$, 겉넓이가 $A$인 3차원 부채꼴의 입체각 solid angle $\Omega$를 다음과 같이 정의하고 $$ \Omega := \dfrac{A}{r^{2}} $$ 단위는 스테라디안steradian이라 하고 $\mathrm{sr}$이라 표기한다. 설명 원에서의 라디안 각도가 다음과 같이 반지름에 대한 호의 비율로 정의되는 것을 생각해보면 자연스러운 정의이다. $$ \theta := \dfrac{s}{r} $$ 다만 분모</description>
    </item>
    
    <item>
      <title>SIS 모델: 재감염과 고질병</title>
      <link>https://freshrimpsushi.github.io/posts/sis-model-reinfection-and-endemic/</link>
      <pubDate>Sun, 30 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sis-model-reinfection-and-endemic/</guid>
      <description>개요 SIS 모델은 전염이나 정보의 확산에서 면역, 무관심 등을 고려하지 않는 모델이다. 주로 유행병Epidemic이 아닌 풍토병Endemic, 예를 들어 감기, 독감, 성병, 말라리아 등이 SIS 로 모델링될 수 있다. 모델 1 $$ \begin{align*} {{d S} \over {d t}} =&amp;amp; - {{ \beta } \over { N }} I S + \gamma I \\ {{d I} \over {d t}} =&amp;amp; {{ \beta } \over { N }} S I - \gamma I \end{align*} $$ 변수 $S(t)$: $t$ 시점에서 병에 걸릴 수</description>
    </item>
    
    <item>
      <title>기체운동론으로 유도되는 이상기체방정식</title>
      <link>https://freshrimpsushi.github.io/posts/ideal-gas-equation-derived-by-kinetic-theory-of-gass/</link>
      <pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ideal-gas-equation-derived-by-kinetic-theory-of-gass/</guid>
      <description>정의1 면적 $M$에 작용하는 유체의 압력 $p$를 유체가 면적 $M$에 수직으로 작용하는 힘 $F$와 면적 $M$의 비율로 정의한다. $$ p:=\frac{F}{M} \left[ \mathrm{N/m^{2}} \right] $$ 공식 기체의 부피를 $V$, 온도를 $T$, 분자 수를 $N$이라고 하자. 그러면 기체의 압력 $p$는 다음과 같은 식을 만족한다. $$ p V = N k_{B}T $$ 이때 $k_{B} = 1.3807 \times 10^{-23} J / K$를 볼츠만 상수Boltzmann con</description>
    </item>
    
    <item>
      <title>최적값: 최대값과 최소값</title>
      <link>https://freshrimpsushi.github.io/posts/optimum-maximum-minimum/</link>
      <pubDate>Fri, 28 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/optimum-maximum-minimum/</guid>
      <description>쉬운 정의 최대값Maximum과 최소값Minimum을 통틀어 최적값Optimum이라 한다. 집합 $X$ 에서 가장 큰 원소를 최대값 $\max X$, 가장 작은 원소를 최소값 $\min X$ 과 같이 나타낸다. 함수 $f : X \to \mathbb{R}$ 의 가장 큰 함수값을 $\max_{X} f$, 가장 작은 함수값을 $\min_{X} f$ 와 같이 나타낸다. $\mathbb{R}$ 은 실수 전체의 집합을 나타낸다. 최대, 최소는 한자어고 값은 순우리말이므로 사</description>
    </item>
    
    <item>
      <title>기체분자의 속도/속력의 기대값</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-of-velocity-and-speed-for-molecules-in-a-gas/</link>
      <pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-of-velocity-and-speed-for-molecules-in-a-gas/</guid>
      <description>공식 기체분자의 속도를 $\mathbf{v} = (v_{X}, v_{y}, v_{z}$, 속력을 $v = | \mathbf{v} |$라고 하자. 기체분자의 속도의 기댓값은 다음과 같다. $$ \begin{align*} \left&amp;lt; v_{x} \right&amp;gt; &amp;amp;= 0 \\ \left&amp;lt; |v_{x}| \right&amp;gt; &amp;amp;= \sqrt{\dfrac{2 k_{B} T}{\pi m}} \\ \left&amp;lt; v_{x} ^{2} \right&amp;gt; &amp;amp;= \dfrac{k_{B} T}{\pi m} \end{align*} $$ 기체분자의 속력의 기댓값은 다음과 같다. $$ \begin{align*} \left&amp;lt; v \right&amp;gt; &amp;amp;= 0 \\ \left&amp;lt; |v_{x}| \right&amp;gt; &amp;amp;= \sqrt{\dfrac{2 k_{B} T}{\pi m}} \\ \left&amp;lt; v_{x} ^{2} \right&amp;gt; &amp;amp;= \dfrac{k_{B} T}{\pi m} \end{align*} $$ 기댓값 변수가 $x$, $x$의 확률밀도함수가 $f(x)$일 때 $x$의 기</description>
    </item>
    
    <item>
      <title>최대우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/maximum-likelihood-estimator/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maximum-likelihood-estimator/</guid>
      <description>빌드업 모수 $\theta \in \Omega$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. $X$ 와 같은 분포로 iid하게 뽑은 랜덤샘플 $X_{1} , \cdots , X_{n}$ 는 같은 확률밀도함수 $f(x ; \theta)$ 와 실현 $\mathbf{x} := \left( x_{1} , \cdots , x_{n} \right)$ 을 가진다. 이에 대해 다음과 같은 함수 $L$ 을 우도함수Likelihood Function라 한다. $$ L ( \theta ; \mathbf{x} ) := \prod_{k=1}^{n} f \left( x_{k} ; \theta \right) $$ 아래에서 나오</description>
    </item>
    
    <item>
      <title>SIR 모델: 가장 기본적인 확산 모델</title>
      <link>https://freshrimpsushi.github.io/posts/sir-model-most-basic-epdemic-spreading-model/</link>
      <pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sir-model-most-basic-epdemic-spreading-model/</guid>
      <description>개요 SIR 모델은 가장 간단하고 수많은 변형이 있는 역학 구획 모델로써, 질병이나 정보 등의 확산 자체를 간단하면서도 직관적으로 잘 설명한다. 모델 1 $$ \begin{align*} {{d S} \over {d t}} =&amp;amp; - {{ \beta } \over { N }} I S \\ {{d I} \over {d t}} =&amp;amp; {{ \beta } \over { N }} S I - \mu I \\ {{d R} \over {d t}} =&amp;amp; \mu I \end{align*} $$ 변수 $S(t)$: $t$ 시점에서 병에 걸릴 수 있는Susceptible 집단의 개체수를 나타낸다. $I(t)$: $t$</description>
    </item>
    
    <item>
      <title>줄리아에서의 메타 프로그래밍</title>
      <link>https://freshrimpsushi.github.io/posts/meta-programming-in-julia/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/meta-programming-in-julia/</guid>
      <description>코드 1 줄리아에서는 메타 프로그래밍을 언어 차원에서 지원한다. 다음은 문자열을 코드 그 자체로 읽고 실행한 결과다. julia&amp;gt; text = &amp;quot;f(x) = 2x + 1; f(2)&amp;quot; &amp;quot;f(x) = 2x + 1; f(2)&amp;quot; julia&amp;gt; code = Meta.parse(text) :($(Expr(:toplevel, :(f(x) = begin #= none:1 =# 2x + 1 end), :(f(2))))) julia&amp;gt; eval(code) 5 Meta.Parse(): 이 함수를 통해 입력된 문자열을 표현식Expression으로 바꿔 반환한다. eval(): 표현식을 평가Evaluate한다. 위 예제코드에서는 $f(2)$ 가 실제</description>
    </item>
    
    <item>
      <title>전염병 확산 모델에서 기초감염재생산수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-basic-reproduction-number-in-epidemic-spreading-model/</link>
      <pubDate>Thu, 20 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-basic-reproduction-number-in-epidemic-spreading-model/</guid>
      <description>정의 기초감염재생산수Basic Reproduction Number $\mathcal{R}_{0}$ 는 전염병이 확산되는 속도를 나타낸 값으로써, 기본적으로 한 명의 감염자가 얼마나 감염시킬지에 대한 기대값로 표현된다. 역학 구획 모델 1 미분방정식으로 표현된 동역학계에서는 자코비안 행렬의 실수부가 가장 큰 고유값을 $\mathcal{R}_{0}$ 이라 한다. 설명 정의만 읽어보면 무슨 소린지 이해하기 어렵지만 구체적인 값으로 생각해</description>
    </item>
    
    <item>
      <title>줄리아에서 배열 Flatten 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-flatten-array-in-julia/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-flatten-array-in-julia/</guid>
      <description>코드 vec() 함수를 쓰면 된다. julia&amp;gt; A = rand(0:9, 3,4) 3×4 Array{Int64,2}: 6 8 7 3 2 9 3 2 5 0 6 7 julia&amp;gt; vec(A) 12-element Array{Int64,1}: 6 2 5 8 9 0 7 3 6 3 2 7 사람이 생각하기로, 사람에게 보이기로는 똑같이 1차원 배열인데 타입상 2차원 배열이라 에러를 내는 경우도 이 방법으로 해결하면 된다. 다음 두 명령은 정확히 같은 배열로 보이지만 $\mathbb{N}^{10 \times 1}$ 행렬이냐 $\mathbb{N}^{10 }$ 벡터냐의 차이가 있다. julia&amp;gt; b = rand(0:9, 10,1) 10</description>
    </item>
    
    <item>
      <title>하이젠베르크 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/heisenbergs-inequality/</link>
      <pubDate>Mon, 17 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heisenbergs-inequality/</guid>
      <description>빌드업 $f$와 $f$의 푸리에 변환 $\hat{f}$ 사이에는 특별한 관계가 있다. 만약 어떤 상수 $\Omega$에 대해서 $\hat{f} (\omega) = 0\ for\ | \omega | \ge \Omega$가 성립할 때 $f$도 이와 같은 성질을 갖는 것이 불가능하다. 다시 말해 $f$와 $\hat{f}$이 둘 다 좁은 곳에 모여있는 모양을 가질 수 없다는 말이고, 수학적으로 말하자면 $f$와 $\hat{</description>
    </item>
    
    <item>
      <title>일치추정량</title>
      <link>https://freshrimpsushi.github.io/posts/consistent-estimator/</link>
      <pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/consistent-estimator/</guid>
      <description>정의 1 확률변수 $X$ 가 누적분포함수 $F ( x ; \theta), \theta \in \Omega$ 를 가진다고 하자. $X_{1} , \cdots , X_{n}$ 을 $X$ 에서 뽑은 샘플이라고 할 때, 통계량 $T_{n}$ 이 다음을 만족하면 모수 $\theta$ 에 대한 일치추정량Consistent Estimator이라 한다. $$ T_{n} \overset{P}{\to} \theta $$ $\overset{P}{\to}$ 는 확률수렴이다. 예시 $X_{1} , \cdots , X_{n}$ 가 확률분포 $\left( \mu, \sigma^{2} \right)$ 를 따르는 랜덤 샘플, 즉 $X_{1} , \cdots , X_{n} \sim \left( \mu, \sigma^{2} \right)$ 이고 첨</description>
    </item>
    
    <item>
      <title>발산하는 실수열의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-divergent-real-sequence/</link>
      <pubDate>Sat, 15 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-divergent-real-sequence/</guid>
      <description>정리1 $\left\{ x_{n} \right\}$, $\left\{ y_{n} \right\}$이 실수열이고 $\lim \limits_{n\to\infty} x_{n}=\infty(-\infty)$라고 하자. 그러면 다음이 성립한다. (a) $\left\{ y_{n} \right\}$이 아래로 유계(위로 유계)이면, $\lim \limits_{n\to\infty}(x_{n}+y_{n}) = \infty(-\infty)$ (b) $\forall \alpha &amp;gt; 0,\quad \lim \limits_{n\to\infty} \alpha x_{n} = \infty (-\infty)$ (c) 모든 $n\in \mathbb{N}$에 대해서 $y_{n} &amp;gt; M_{0}$인 $M_{0} &amp;gt;0$가 존재하면, $\lim \limits_{n\to\infty} x_{n}y_{n}</description>
    </item>
    
    <item>
      <title>줄리아에서 거리 행렬 계산 최적화하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-optimize-calculating-distance-matrix/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-optimize-calculating-distance-matrix/</guid>
      <description>결론 $n$ 개의 좌표끼리 거리를 계산한다고 하자. 모든 좌표끼리 계산할 필요가 없다면 그룹을 나누어 직사각 거리 행렬을 만들면 된다. 직사각 거리행렬은 pairwise() 함수로 쉽고 빠르게 계산할 수 있다. 속도 비교 가령 SIR 모델에 대해 무빙 에이전트 기반 시뮬레이션을 한다고 생각해보자. 원래의 시간복잡도는 $O \left( n^{2} \right)$ 이지만, $S$ 와 $I$ 그룹으로 나누어 계산하면 시간 복잡도</description>
    </item>
    
    <item>
      <title>샘플링 정리</title>
      <link>https://freshrimpsushi.github.io/posts/the-sampling-theorem/</link>
      <pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-sampling-theorem/</guid>
      <description>빌드업1 어떤 물리적 신호 $f$가 시간 $t_{1} &amp;lt; t_{2} &amp;lt; t_{3} &amp;lt; \cdots$에 따라서 측정되고 있다고 생각해보자. 일반적으로 $f(t_{1}), f(t_{2}), \dots$를 알고 있다고 해도 임의의 $f(t)$를 알 수는 없다. 하지만 여기서 신호 $f$가 특정한 범위 내의 주파수의 신호만 포함한다고 가정해보자. 즉 어떤 상수 $\Omega$보다 작은 주파수만 포함하는 신호 $f</description>
    </item>
    
    <item>
      <title>역학 구획 모델</title>
      <link>https://freshrimpsushi.github.io/posts/compartmental-model-in-epidemiology/</link>
      <pubDate>Wed, 12 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compartmental-model-in-epidemiology/</guid>
      <description>개요 1 역학 구획 모델은 전염병의 창궐에 대한 모델로써, 인구 동역학에 전염병을 가미하고 &amp;lsquo;인구&amp;rsquo;을 몇가지 구획Compartmental으로 나눈다. 역학疫學, Epidemiology이란 전염병을 다루는 학문으로써, 생새우초밥집에서 다루는 역학力學, Mechanics과는 관계가 없다. 설명 커맥Ke</description>
    </item>
    
    <item>
      <title>지수함수와 로그함수의 극한</title>
      <link>https://freshrimpsushi.github.io/posts/limit-of-exponential-and-logarithm/</link>
      <pubDate>Tue, 11 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-of-exponential-and-logarithm/</guid>
      <description>공식 지수함수와 로그함수에 대해서 다음의 식이 성립한다. $$ \begin{equation} \lim \limits_{x \to 0} \dfrac{\log (x + 1) }{x} = 1 \label{fml1} \end{equation} $$ $$ \begin{equation} \lim \limits_{x \to 0} \dfrac{ e^{x} - 1}{x} = 1 \label{fml2} \end{equation} $$ 증명 $\eqref{fml1}$ $$ \begin{align*} \lim \limits_{x \to 0} \dfrac{\log (x + 1) }{x} &amp;amp;= \lim \limits_{x \to 0} \dfrac{1}{x} \log ( x + 1) \\ &amp;amp;= \lim \limits_{x \to 0} \log (x + 1)^{\frac{1}{x}} \\ &amp;amp;= \log\left( \lim \limits_{x \to 0} (x + 1)^{\frac{1}{x}}\right) \\ &amp;amp;= \log\left( e \right) \\ &amp;amp;= \log\left( e \right) \end{align*} $$ 세번째 등호는 로그함수가 연속이므로 성립한다. 마지막 등호는 $e$의 정의 ■ $\eqref{fml2}$ $e^{x}-1 =</description>
    </item>
    
    <item>
      <title>줄리아에서 가중치를 주고 랜덤 샘플링 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-random-sampling-with-weight-in-julia/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-random-sampling-with-weight-in-julia/</guid>
      <description>개요 줄리아에서 R에서의 sample()이나 파이썬 패키지 numpy의 random.choice()와 같은 역할을 하는 함수인 sample()과 Weights 함수의 사용법이다. 코드 1 using StatsBase items = 0:5 weights = 0:5 sample(items, Weights(weights)) # With replacement my_samps = sample(items, Weights(weights), 10) # Without replacement my_samps = sample(items, Weights(weights), 2, replace=false) 실행 결과 julia&amp;gt; using StatsBase julia&amp;gt; items = 0:5 0:5 julia&amp;gt; weights = 0:5 0:5 julia&amp;gt; sample(items, Weights(weights)) 5 julia&amp;gt; # With replacement julia&amp;gt; my_samps = sample(items, Weights(weights), 10) 10-element Array{Int64,1}: 4 3 2 1 3 3 5 5 2</description>
    </item>
    
    <item>
      <title>단조 수열, 단조수렴정리</title>
      <link>https://freshrimpsushi.github.io/posts/monotonic-convergence-theorem/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monotonic-convergence-theorem/</guid>
      <description>정의1 실수들의 수열 $\left\{ s_{n} \right\}$에 대해서 $s_{n} \le s_{n+1}$가 성립하면 단조증가수열이라고 한다. $s_{n} \ge s_{n+1}$가 성립하면 단조감소수열이라고 한다. 단조증가하거나 단조감소하는 수열을 단조롭다고 한다. 설명 수열은 자연수를 정의역으로 갖는 함수로 정의되므로 단조증가수열이라는 말은 정의역이 자연수인 단조증가함</description>
    </item>
    
    <item>
      <title>스미스-워터맨 정렬: 국소 서열 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/smith-waterman-alignment/</link>
      <pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/smith-waterman-alignment/</guid>
      <description>개요 두 염기서열에서 가장 비슷한 부분의 정렬을 찾는 것을 국소 정렬Local Alignment이라 하는데, 그 방법으로 가장 널리 쓰이는 스미스-워터맨 알고리즘Smith-Waterman Algorithm을 소개한다. 서열정렬에는 너무나 많은 경우의 수가 있기 때문에 다이내믹 프로그래밍 을 통해 효율적이고 빠르게 계산할 필요가 있다.</description>
    </item>
    
    <item>
      <title>줄리아에서 문자와 정수의 이퀄 오퍼레이터 == 속도 비교</title>
      <link>https://freshrimpsushi.github.io/posts/speed-of-equal-operator-for-character-or-integer-in-julia/</link>
      <pubDate>Thu, 06 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/speed-of-equal-operator-for-character-or-integer-in-julia/</guid>
      <description>결론 배열의 각 원소를 Equal Operator ==를 통해 비교하면 정수보다 Char가 빠르다. 속도 비교 julia&amp;gt; integer = rand(1:5, N); print(typeof(integer)) Array{Int64,1} julia&amp;gt; character = rand([&#39;S&#39;,&#39;E&#39;,&#39;I&#39;,&#39;R&#39;,&#39;D&#39;], N); print(typeof(character)) Array{Char,1} julia&amp;gt; @time integer .== 1; 0.009222 seconds (6 allocations: 1.196 MiB) julia&amp;gt; @time character .== &#39;S&#39;; 0.005266 seconds (7 allocations: 1.196 MiB) 위의 코드는 정수와 문자로 이루어진 배열에서 각각 1과 S가 어디에 있는지 파악하는 프로그램이다. 정수냐 문자열이냐의 차이 빼고는 정확히 같으나, 시간 소요는 두배에 육박할만큼 큰</description>
    </item>
    
    <item>
      <title>이항분포에서 근사시킨 정규분포의 분산 안정화</title>
      <link>https://freshrimpsushi.github.io/posts/parameter-free-transform-of-binomial-distribution/</link>
      <pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/parameter-free-transform-of-binomial-distribution/</guid>
      <description>예시 1 $Y = Y_{n}$ 가 이항분포 $\text{Bin} (n,p)$ 를 따른다고 하면 $$ \arcsin \sqrt{ {{ Y } \over { n }} } \overset{D}{\to} N \left( \arcsin \sqrt{p} , n/4 \right) $$ $N \left( \mu , \sigma^{2} \right)$ 는 정규분포를 의미한다. $\overset{D}{\to}$ 는 분포수렴을 의미한다. 설명 이항분포 $\text{Bin} (n, p )$ 는 $n \to \infty$ 일 때 정규분포 $N \left( np, np(1-p) \right)$ 로 수렴하므로 정규분포 자체는 신기할 게 없지만, 위와 같은 변환을 취함으로써 분산이 모수 $p$ 에 관계 없이 일정한 극한 분포를 얻을 수도</description>
    </item>
    
    <item>
      <title>2차원 배열의 행우선과 열우선</title>
      <link>https://freshrimpsushi.github.io/posts/row-major-and-column-major/</link>
      <pubDate>Sun, 02 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/row-major-and-column-major/</guid>
      <description>개요 1 행렬 혹은 2차원 배열의 행우선row-major, 열우선column-major에 대해 설명한다. 행우선이냐 열우선이냐는 쉽게 말해 배열을 참조하면서 어떤 반향으로 읽느냐를 선호하는지를 말한다. 차이점 위키피디아에 따르면 어떤 프로그래밍 언어와 라이브러리들은 다음과 같이 네이티브Native한 행/렬우선이 정해져있다고 한</description>
    </item>
    
    <item>
      <title>오일러 상수, 자연 상수 e의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-euler-constant/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-euler-constant/</guid>
      <description>정의1 아래의 급수의 극한을 상수 $e$라고 정의한다. $$ e: = \sum \limits_{n=0}^{\infty} \dfrac{1}{n!} $$ 설명 저 값이 당장에 뭔지는 몰라도 위의 급수가 수렴하여 어떤 극한이 존재한다는 사실은 쉽게 보일 수 있다. 부분합 $s_{n}$은 아래와 같이 유계이면서 증가수열이므로 수렴한다. $$ \begin{align*} s_{n} &amp;amp;= 1 + 1 + \dfrac{1}{2} + \dfrac{1}{2 \cdot 3} + \dfrac{1}{2 \cdot 3 \cdot 4} + \cdots + \dfrac{1}{1 \cdot 2 \cdot \cdots \cdot n} \\ &amp;amp;&amp;lt; 1 + 1 + \dfrac{1}{2} + \dfrac{1}{2 \cdot 2} + \dfrac{1}{2</description>
    </item>
    
    <item>
      <title>스튜던트의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-students-theorem/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-students-theorem/</guid>
      <description>정리 1 확률 변수 $X_{1} , \cdots , X_{n}$ 들이 iid로 정규분포 $N\left( \mu,\sigma^{2} \right)$ 를 따른다고 하면 (a): $$ \overline{X} \sim N\left( \mu , { {\sigma^2} \over {n} } \right) $$ (b): $$ \overline{X} \perp S^2 $$ (c): $$ (n-1) { {S^2} \over {\sigma^2} } \sim \chi^2 (n-1) $$ (d): $$ T = { {\overline{X} - \mu } \over {S / \sqrt{n}} } \sim t(n-1) $$ 표뵨 평균 $\overline{X}$ 과 표본 분산 $S^{2}$ 는 다음과 같이 정의된 확률 변수다. $$ \overline{X} := {{ 1 } \over { n }} \sum_{k=1}^{n} X_{k} \\ S^{2} := {{ 1 } \over { n-1 }} \sum_{k=1}^{n} \left( X_{k} - \overline{X} \right)^{2} $$ 설명 통계학을 하는 사람들은 당연</description>
    </item>
    
    <item>
      <title>직교기저들에 상대적인 좌표</title>
      <link>https://freshrimpsushi.github.io/posts/coordinate/</link>
      <pubDate>Thu, 29 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coordinate/</guid>
      <description>정의1 내적공간 $V$의 기저 $S$가 직교집합이면 $S$를 직교기저orthogonal basis라 한다. $S$가 정규직교집합이면 정규직교기저orthonormal basis라 한다. 정리 $S = \left\{ \mathbf{v}_{1}, \mathbf{v}_{2}, \dots, \mathbf{v}_{n} \right\}$가 내적공간 $V$의 직교기저이고, $\mathbf{u} \in V$라고 하자. 그러면 다음의 식이 성립한다. $$ \begin{equation} \begin{aligned} \mathbf{u} &amp;amp;= \dfrac{\langle</description>
    </item>
    
    <item>
      <title>RGB 색상 치트 시트</title>
      <link>https://freshrimpsushi.github.io/posts/rgb-color-cheat-sheet/</link>
      <pubDate>Wed, 28 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rgb-color-cheat-sheet/</guid>
      <description>개요 자주 사용되는 RGB색상표다. 코드 000000 R - 000 G - 000 B - 000 333333 R - 051 G - 051 B - 051 666666 R - 102 G - 102 B - 102 999999 R - 153 G - 153 B - 153 CCCCCC R - 204 G - 204 B - 204 FFFFFF R - 255 G - 255 B - 255 000033 R - 000 G - 000 B - 051 333300 R - 051 G - 051 B - 000 666600 R - 102 G - 102 B - 000 999900 R - 153 G - 153 B - 000 CCCC00 R - 204 G - 204 B - 000 FFFF00 R - 255 G - 255 B - 000 000066 R - 000 G - 000 B - 102 333366 R</description>
    </item>
    
    <item>
      <title>기저의 더하기/빼기 정리</title>
      <link>https://freshrimpsushi.github.io/posts/plus-minus-theorem-for-basis/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/plus-minus-theorem-for-basis/</guid>
      <description>정리1 $S$를 벡터공간 $V$의 공집합이 아닌 부분집합이라고 하자. (a) 만약 $S$가 선형독립이고 $\mathbf{v} \in V$가 $\mathbf{v} \notin \text{span}(S)$이면, $S \cup \left\{ \mathbf{v} \right\}$는 여전히 선형독립니다. (b) 만약 $\mathbf{v} \in S$가 $S$의 다른 벡터들의 선형결합으로 나타나면, $S$와 $S \setminus \left\{ \mathbf{v} \right\}$는 같은 공간을 생성한다.</description>
    </item>
    
    <item>
      <title>역 전파 알고리즘</title>
      <link>https://freshrimpsushi.github.io/posts/back-propagation-algorithm/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/back-propagation-algorithm/</guid>
      <description>이 글은 역전파 알고리즘의 원리를 수학 전공자가 이해하기 쉽도록 작성되었다. 표기법 위 그림과 같은 인공 신경망이 주어졌다고 하자. $\mathbf{x} = (x_{1}, x_{2}, \dots, x_{n_{0}})$는 입력input, $y_{j}^{l}$는 $l$번째 층의 $j$번째 노드, $\hat{\mathbf{y}} = (\hat{y}_{1}, \hat{y}_{2}, \dots, \hat{y}_{\hat{n}})$는 출력output이다. $L \in \mat</description>
    </item>
    
    <item>
      <title>니들맨-분쉬 알고리즘: 전역 서열 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/needleman-wunsch-algorithm/</link>
      <pubDate>Mon, 26 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/needleman-wunsch-algorithm/</guid>
      <description>개요 두 염기서열의 공통 부분이 가장 많아지는 정렬을 찾는 것을 전역 정렬Global Alignment이라 하는데, 그 방법으로 가장 널리 쓰이는 니들맨-분쉬 알고리즘Needleman-Wunsch Algorithm을 소개한다. 서열정렬에는 너무나 많은 경우의 수가 있기 때문에 다이내믹 프로그래밍 을 통해 효율적이고 빠르게 계산할 필요</description>
    </item>
    
    <item>
      <title>지수함수의 미분법</title>
      <link>https://freshrimpsushi.github.io/posts/derivative-of-exponential-function/</link>
      <pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivative-of-exponential-function/</guid>
      <description>공식 지수함수의 도함수는 다음과 같다. $$ \begin{equation} \dfrac{d e^{x}}{dx} = e^{x} \label{fml1} \end{equation} $$ 지수합성함수의 도함수는 다음과 같다. $$ \begin{equation} \dfrac{d \left( e^{f(x)} \right)}{dx} = f&#39;(x)e^{f(x)} \label{fml2} \end{equation} $$ 설명 지수함수는 도함수와 자기 자신이 같은 유일한 함수이다. 유도 (1) 도함수의 정의를 이용하여 계산하면 다음과 같다. $$ \begin{align*} \dfrac{d e^{x}}{d x} &amp;amp;= \lim \limits_{h \to 0} \dfrac{e^{x+h}-e^{x}}{h} \\ &amp;amp;= e^{x}\lim \limits_{h \to 0} \dfrac{e^{h}-1}{h} \\ &amp;amp;= e^{x} \end{align*} $$ 마지막 등호는 $\lim \limits_{x \to 0} \dfrac{ e^{x} - 1}{x} = 1$이므로 성립한</description>
    </item>
    
    <item>
      <title>유사 역행렬</title>
      <link>https://freshrimpsushi.github.io/posts/pseudoinvers-matrix/</link>
      <pubDate>Sat, 24 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pseudoinvers-matrix/</guid>
      <description>개요 유사역행렬Pseudoinvers Matrix은 역행렬의 일반화로써, 행과 열의 크기가 같지 않아서 정방행렬이 아닌 행렬 $A \in \mathbb{R}^{m \times n}$ 에 대해 &amp;lsquo;사실상&amp;rsquo; 역행렬이 되는 행렬을 말한다. 행렬변환 $T_{A} : \mathcal{N} (A) \to \mathcal{C} (A)$ 이 모든 $\mathbf{x} \in \mathcal{N} (A)^{\perp}$ 에 대해 $$ T_{A} \mathbf{x} = A \mathbf{x} $$ 을 만족한다면 $T_{A}$ 는 전단사가 된다. 이는 $T_{A}$ 의 공역을 좁혀서 강제</description>
    </item>
    
    <item>
      <title>직교성과 선형독립의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-orthogonality-and-linear-independence/</link>
      <pubDate>Fri, 23 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-orthogonality-and-linear-independence/</guid>
      <description>정의1 내적공간 $V$의 두 벡터 $\mathbf{u}, \mathbf{v}$가 $\langle \mathbf{u}, \mathbf{v} \rangle$을 만족하면 서로 직교orthogonal한다고 한다. $V$의 원소들로 이루어진 집합에서 각각의 원소들이 다른 모든 원소와 서로 직교하면 그 집합을 직교집합orthogonal set이라 한다. 직교집합의 모든 원소의 놈이 $1$이면 정규직교집합or</description>
    </item>
    
    <item>
      <title>일제사격 전투 모델</title>
      <link>https://freshrimpsushi.github.io/posts/salvo-combat-model/</link>
      <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/salvo-combat-model/</guid>
      <description>개요 란체스터 법칙이 근대전과 현대전의 양상을 묘사하는 모델이라면, 일제사격 전투 모델은 현대전 중에서도 특히 스케일이 큰 함대전을 묘사한다. 함대전에서 공격의 수단은 미사일과 같이 크고 강력한 것들이 많으며, 반대로 이런 미사일을 요격하는 미사일도 있다는 점이 다르다. 모델1 $$ \begin{align*} \Delta A =&amp;amp; - { { 1 } \over { H_{A} } } \left( O_{B} B - D_{A} A \right) \\ \Delta B =&amp;amp; - { { 1</description>
    </item>
    
    <item>
      <title>행공간, 열공간, 영공간에 대한 기저</title>
      <link>https://freshrimpsushi.github.io/posts/bases-for-row-spaces-column-spaces-null-spaces/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bases-for-row-spaces-column-spaces-null-spaces/</guid>
      <description>개요1 행공간, 열공간, 영공간과 같은 개념은 선형 시스템 $A \mathbf{x} = \mathbf{b}$을 풀기 위해서 만들어졌다. 선형 시스템은 기본 행 연산을 통해 풀 수 있는데, 실제로 행공간과 영공간은 기본 행 연산에 대해서 불변이기 때문에 선형 시스템과 관계가 있음을 알 수 있다. 여기에서 유념해야할 것은 열공간은 기본 행 연산에 대해서 불변이 아니라는 것이다.</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution-of-random-vector/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution-of-random-vector/</guid>
      <description>정의1 $p$차원 랜덤 벡터 $\mathbf{X}$ 와 랜덤 벡터의 시퀀스 $\left\{ \mathbf{X}_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $\mathbf{X}_{n}$ 이 $\mathbf{X}$ 로 분포 수렴한다고 말하고, $\mathbf{X}_{n} \overset{D}{\to} \mathbf{X}$ 와 같이 나타낸다. $$\lim_{n \to \infty} F_{\mathbf{X}_{n}} (x) = F_{\mathbf{X}} (x) \qquad, \forall x \in C_{F_{\mathbf{X}}}$$ $F_{X}$ 는 확률변수 $X$ 의 누적분포함수다. $C_{F_{\mathbf{X}}}$ 는 함수 $F_{\mathbf{X}}$ 가 연속인 점들의 집합을 나타낸다. 다변량 중심 극한 정리 $\left\{ \mathbf{X}_{n} \right\}$ 가 평균 벡터 $\mathbf{\mu} \in \mathbb{R}^{p}$ 와 공분산 행렬 $\Sigma \in \mathbb{R}^{p \times p}$ 를 가지고 ii</description>
    </item>
    
    <item>
      <title>함수의 합성</title>
      <link>https://freshrimpsushi.github.io/posts/function-composition/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/function-composition/</guid>
      <description>정의 함수 $f: X \to Y$, $g: f(X) \to Z$에 대해서 다음과 같이 정의되는 $h: X \to Z$를 $f$와 $g$의 합성composition of $g$ with $f$이라고 하고 $h=g \circ f$라고 표기한다. $$ h(x) = (g\circ f) (x) := g\left( f(x) \right) $$</description>
    </item>
    
    <item>
      <title>란체스터 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/lanchester-laws/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lanchester-laws/</guid>
      <description>법칙 제1법칙 근대전 혹은 근접전투에서 전투력은 부대 규모에 비례한다. 제2법칙 현대전 혹은 원거리전투에서는 전투력은 부대 규모의 제곱에 비례한다. 설명 란체스터 법칙Lanchester&amp;rsquo;s Laws은 두 집단의 전투에서 사상자의 수에 대한 법칙으로, 제1법칙(선형 법칙)과 제2법칙(제곱 법칙)으로 서술된다. 선형 법칙:</description>
    </item>
    
    <item>
      <title>실벡터공간에서 내적이란?</title>
      <link>https://freshrimpsushi.github.io/posts/inner-product-in-real-vector-space/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inner-product-in-real-vector-space/</guid>
      <description>정의1 $V$를 실벡터공간이라고 하자. $V$ 위의 내적inner product이란, 아래의 조건을 만족하면서, $V$ 내의 두 벡터를 하나의 실수 $\langle \mathbf{u}, \mathbf{v} \rangle$에 대응시키는 함수를 말한다. $\mathbf{u}, \mathbf{v}, \mathbf{w} \in V$이고 $k \in \mathbb{R}$일 때, $\langle \mathbf{u}, \mathbf{v} \rangle = \langle \mathbf{v}, \mathbf{u} \rangle$ $\langle \mathbf{u} + \mathbf{v}, \mathbf{w} \rangle = \langle \mathbf{u}, \mathbf{w} \rangle + \langle \mathbf{v}, \mathbf{w} \rangle$ $\langle k \mathbf{u}, \mathbf{v} \rangle = k \langle \mathbf{u}, \mathbf{v} \rangle$ $\langle \mathbf{v}, \mathbf{v} \rangle</description>
    </item>
    
    <item>
      <title>git warning: LF will be replaced by LF in … 해결법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-fix-warning-lf-will-be-replaced-by-lf-in/</link>
      <pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-fix-warning-lf-will-be-replaced-by-lf-in/</guid>
      <description>명령 git config --global core.safecrlf false 리눅스랑 윈도우 차이 때문에 나오는 경고인데 무시하면 된다. 위와 같이 입력하면 된다.</description>
    </item>
    
    <item>
      <title>선형변환</title>
      <link>https://freshrimpsushi.github.io/posts/linear-transformations/</link>
      <pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-transformations/</guid>
      <description>정의1 함수 $T : V \to W$가 벡터공간에서 벡터공간으로의 사상일 때, 즉 $V$, $W$가 벡터공간일 때 $T$를 변환transformation이라고 한다. 변환 $T$가 선형 함수이면, 즉 모든 $\mathbf{v},\mathbf{u} \in V$와 상수 $k$에 대해서 다음의 두 조건을 만족하면 선형변환linear transformation이라고 한다. $T(k \mathbf{u}) = k T(\mathbf{u})$ $T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) +</description>
    </item>
    
    <item>
      <title>로그함수의 미분법</title>
      <link>https://freshrimpsushi.github.io/posts/derivative-of-logarithm/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivative-of-logarithm/</guid>
      <description>공식 로그함수의 도함수는 다음과 같다. $$ \begin{equation} \dfrac{d \log x}{dx}=\dfrac{1}{x} \label{fml1} \end{equation} $$ 로그합성함수의 도함수는 다음과 같다. $$ \begin{equation} \dfrac{d \left( \log f(x) \right)}{dx} = \dfrac{f&#39;(x)}{f(x)} \label{fml2} \end{equation} $$ 설명 특히 $\eqref{fml2}$는 자주 쓰이는 치환트릭이다. 유도 (1) 로그함수의 정의에 의해서 다음의 식이 성립한다. $$ x = e^{\log x} $$ 양변을 미분하면 지수함수의 미분법과 연쇄법칙에 의해 다음과 같다. $$ \begin{align*} 1 &amp;amp;= \dfrac{ d</description>
    </item>
    
    <item>
      <title>메이-레너드 경쟁 모델</title>
      <link>https://freshrimpsushi.github.io/posts/may-leonard-competition-model/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/may-leonard-competition-model/</guid>
      <description>개요 메이-레너드 경쟁 모델은 세 가지 집단이 포함된 경쟁 상태에서의 인구 동역학 모델로, 세 집단이 서로 먹고 먹히는 삼각 관계를 묘사한다. 세 개의 당이나 기업, 혹은 실제로 상성이 있는 경쟁이 될 수도 있다. 모델1 $$ \begin{align*} x_{1}&#39; =&amp;amp; x_{1} \left( 1 - x_{1} - b x_{2} - a x_{3} \right) \\ x_{2}&#39; =&amp;amp; x_{2} \left( 1 - a x_{1} - x_{2} - b x_{3} \right) \\ x_{3}&#39; =&amp;amp; x_{3} \left( 1 - b x_{1} - a x_{2} - x_{3} \right) \end{align*} $$ 변수 $x_{1}(t)$: $t$ 시점에서 집단 $x_{1}$ 의</description>
    </item>
    
    <item>
      <title>유한차원 벡터공간에서 기저일 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-basis/</link>
      <pubDate>Sun, 11 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-basis/</guid>
      <description>정리1 $V$를 $n$차원 벡터공간이라고 하자. 부분집합 $S\subset V$가 $n$개의 원소를 갖는다고 하자. $S$가 $V$의 기저일 필요충분조건은 $V = \text{span}(S)$이거나 $S$가 선형독립인 것이다. 설명 벡터공간, 차원, 기저, 생성, 독립 등 선형대수에서 중요한 기초 개념이 모두 등장한다. 임의의 집합이 벡터공간의 기저가</description>
    </item>
    
    <item>
      <title>1&#43;2&#43;3&#43;4&#43;5&#43;⋯=-1/12 의 해석적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/analytic-proof-of-zeta-1/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/analytic-proof-of-zeta-1/</guid>
      <description>정리 $$ \begin{align*} &amp;amp; 1 + 2 + 3 + 4 + 5 + \cdots \\ =&amp;amp; \sum_{n \in \mathbb{N}} {{ 1 } \over { n^{-1} }} \\ =&amp;amp; \zeta(-1) \\ =&amp;amp; -{{ 1 } \over { 12 }} \end{align*} $$ 설명 양수를 계속 더했는데 어떻게 음수가 나오는가에만 집중한다면 이 포스트를 절대 이해할 수 없을 것이다. 핵심은 $\sum_{n \in \mathbb{N}} n$ 이 디리클레 급수 $\displaystyle \sum_{n \in \mathbb{N}} {{ 1 } \over { n^{-1} }}$ 으로 표현된다는 것이고, 그 해석적 연속인 리만 제타 함수 $\zeta$ 의 함숫값 $\zeta(-1)$ 으로써 계산한다는</description>
    </item>
    
    <item>
      <title>역행렬과 연립 일차 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-matrix-and-linear-system/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-matrix-and-linear-system/</guid>
      <description>정리: 가역행렬일 동치 조건1 $A$를 크기가 $n\times n$인 정사각행렬이라고 하자. 그러면 아래의 명제는 모두 동치이다. (a) $A$는 가역행렬이다. (e) $A\mathbf{x}=\mathbf{b}$는 모든 $n\times 1$ 행렬 $\mathbf{b}$에 대해서 해를 갖는다. (f) $A\mathbf{x}=\mathbf{b}$는 모든 $n\times 1$ 행렬 $</description>
    </item>
    
    <item>
      <title>선형대수에서 사영정리</title>
      <link>https://freshrimpsushi.github.io/posts/projection-theorem-in-linear-algebra/</link>
      <pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/projection-theorem-in-linear-algebra/</guid>
      <description>정리1 $W$가 유한차원 내적공간 $V$의 부분공간이면 모든 $\mathbf{u} \in V$는 다음과 같은 식으로 유일하게 표현된다. $$ \begin{equation} \mathbf{u} = \mathbf{w}_{1} + \mathbf{w}_{2} \label{thm1} \end{equation} $$ 이때 $\mathbf{w}_{1} \in W$이고 $\mathbf{w}_{2} \in W^{\perp}$ 이다. 설명 정리의 $\mathbf{w}_{1}$와 $\mathbf{w}_{2}$는 각각 다음과 같이 표기하기도 한다. $$ \mathbf{w}_{1} = \mathrm{proj}_{W} \mathbf{u} \quad \text{and} \quad \mathbf{w}_{2} = \mathrm{proj}_{W^{\perp}} \mathbf{u} $$ 또한 이러한 $\mathbf{w}_{1}$, $\ma</description>
    </item>
    
    <item>
      <title>퍼셉트론 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/perceptron-convergence-theorem/</link>
      <pubDate>Mon, 05 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/perceptron-convergence-theorem/</guid>
      <description>$X^{+}$, $X^{-}$가 선형 분리 가능한 트레이닝 셋이라고 하자. $y$를 다음과 같은 레이블이라고 하자. $$ y_{i} = \pm 1\ (\mathbf{x}_{i} \in X^{\pm}) $$ 전체 트레이닝 셋 $X = X^{+} \cup X^{-}$에 $N$개의 데이터가 있다고 할 때 다음과 같은 순서로 입력값을 대입한다고 하자. $$ \mathbf{x}(1), \mathbf{x}(2), \cdots \mathbf{x}(N), \mathbf{x}(1), \mathbf{x}(2), \cdots \mathbf{x}(N),\mathbf{x}(1), \mathbf{x}(2), \cdots $$ 즉 마지막 데이터까지 학습 과정이 끝나면 처음으로 돌아가 다시 시작하는 것이</description>
    </item>
    
    <item>
      <title>롯카-볼테라 경쟁 모델</title>
      <link>https://freshrimpsushi.github.io/posts/competitive-lotka-volterra-equations/</link>
      <pubDate>Sun, 04 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/competitive-lotka-volterra-equations/</guid>
      <description>개요 롯카-볼테라 경쟁 모델은 두 집단 사이의 경쟁적 배제 원리Principle of Competitive Exclusion을 설명할 수 있는 모델로써, 특히 두 집단이 서로를 견제하는 상황을 묘사한다. 이를테면 같은 목초지를 공유하는 토끼와 양의 관계나 두 라이벌 부족의 살육전 등에 대해 적용될 수 있다. 모델1 $$ \begin{align*} x_{1}&#39; =&amp;amp; r_{1} x_{1} {{ K_{1} - x_{1} - \beta_{12} x_{2} } \over { K_{1} }} \\ x_{2}&#39; =&amp;amp; r_{2} x_{2} {{ K_{2}</description>
    </item>
    
    <item>
      <title>기본행렬</title>
      <link>https://freshrimpsushi.github.io/posts/elementary-matrix/</link>
      <pubDate>Sat, 03 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/elementary-matrix/</guid>
      <description>정의1 두 행렬 $A$와 $B$가 기본 행 연산을 통해서 서로를 얻을 수 있으면 두 행렬을 행동등row equivalent이라고 한다. 단위행렬에 기본 행 연산을 한 번만 수행하여 얻을 수 있는 행렬을 기본행렬elementary matrix이라고 한다. 기본행렬은 주로 $E$라고 표기한다. 성질 단위행렬 $I_{m}$에 어떤 기본 행 연산을 통</description>
    </item>
    
    <item>
      <title>다변량 t-분포</title>
      <link>https://freshrimpsushi.github.io/posts/multivariate-t-distribution/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multivariate-t-distribution/</guid>
      <description>정의 로케이션 벡터 $\mathbf{\mu} \in \mathbb{R}^{p}$ 와 양의 정부호인 스케일 행렬 $\Sigma \in \mathbb{R}^{p \times p}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 다변량 분포 $t_{p} \left(\nu; \mu , \Sigma \right)$ 를 다변량 t-분포Multivariate t-distribution라고 한다. $$ f (\textbf{x}) = {{ \Gamma \left[ (\nu + p) / 2 \right] } \over { \Gamma ( \nu / 2) \sqrt{ \nu^{p} \pi^{p} \det \Sigma } }} \left[ 1 + {{ 1 } \over { \nu }} \left( \textbf{x} - \mathbf{\mu} \right)^{T} \Sigma^{-1} \left( \textbf{x} - \mathbf{\mu} \right) \right] \qquad , \textbf{x} \in</description>
    </item>
    
    <item>
      <title>푸리에 변환의 여러가지 의미</title>
      <link>https://freshrimpsushi.github.io/posts/various-meanings-of-fourier-transforms/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/various-meanings-of-fourier-transforms/</guid>
      <description>푸리에 변환은 수학, 물리학, 공학 등 광범위한 분야에서 다루는 만큼 어떻게 바라보느냐에 따라서 서로 다른 의미를 지니게 된다. 크게 수학, 양자역학, 신호처리에서의 의미를 소개한다. 우선 푸리에 변환과 역변환은 여러 꼴로 정의되므로 이 글에서 말하는 푸리에 변환이란 다음과 같다고 하자. $$ \hat{f}(\xi) := \int_{-\infty}^{\infty} f(t) e^{-i\xi x}dx $$ 수학에서 기본적으로 수학에서 말하는 푸리에</description>
    </item>
    
    <item>
      <title>롯카-볼테라 포식자-피식자 모델</title>
      <link>https://freshrimpsushi.github.io/posts/lotka-volterra-predator-prey-model/</link>
      <pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lotka-volterra-predator-prey-model/</guid>
      <description>개요 롯카-볼테라 포식자-식식자 모델은 종간의 상호작용을 시스템으로써 모델링하며, 특히 포식자-피식자 모델은 두 종의 포식관계를 나타낸다. 두 종에 대해서만 다루면 그 확장은 끝이 없기 때문에 먹이사슬을 표현하기엔 충분하다. 모델1 $$ \begin{align*} x&#39; =&amp;amp; a x - b y \cdot x \\ y&#39; =&amp;amp; c x \cdot y - d y \end{align*} $$ 변수 $x(t)$: $t$ 시점에서 피식자 집단 $x$ 의 개체수를 나타낸다. $y(t)$:</description>
    </item>
    
    <item>
      <title>물리학에서 열의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-heat-in-physics/</link>
      <pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-heat-in-physics/</guid>
      <description>정의1 상호작용하는 두 계 사이에서 이동하는 에너지를 열heat이라고 정의한다. 설명 열의 정의를 이해하기 위해서는 일의 개념을 떠올리면 좋다. 어떤 사람이 힘을 줘서 정지한 물체를 움직이는 상황을 생각해보자. 이때 물체가 움직이면 힘이 물체에 일을 했다고 한다. 물체의 입장에서 보면 운동에너지를 얻은 것인데, 이를 운동에너지가 힘에서부터 물체로</description>
    </item>
    
    <item>
      <title>git 비밀번호 저장하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-save-git-password/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-save-git-password/</guid>
      <description>명령 git config credential.helper store 위와 같이 입력하면 된다.</description>
    </item>
    
    <item>
      <title>동차 연립 일차 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/homogeneous-linear-system/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homogeneous-linear-system/</guid>
      <description>정의1 선형 시스템에서 다음과 같이 상수항이 전부 $0$이면 동차homogeneous라고 한다. $$ \begin{align*} a_{11}x_{1} + a_{12}x_{2} + \cdots + a_{1n}x_{n} &amp;amp;= 0 \\ a_{21}x_{1} + a_{22}x_{2} + \cdots + a_{2n}x_{n} &amp;amp;= 0 \\ &amp;amp;\vdots \\ a_{m1}x_{1} + a_{m2}x_{2} + \cdots + a_{mn}x_{n} &amp;amp;= 0 \end{align*} $$ 일반적인 선형 시스템과 달리 모든 동차 선형 시스템은 항상 해를 가진다. 왜냐하면 상수항이 $0$이면 너무도 당연하게 $x_{1}=0, x_{2}=0, \dots, x_{n}=0$을 해로 가지기 때문이다</description>
    </item>
    
    <item>
      <title>가우스-요르단 소거법</title>
      <link>https://freshrimpsushi.github.io/posts/gauss-jordan-elimination/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gauss-jordan-elimination/</guid>
      <description>기약 행사다리꼴1 첨가행렬이 다음의 조건을 만족하면 행사다리꼴echelon form이라 한다. $0$이 아닌 성분이 있는 행에서 가장 처음 나오는 $0$이 아닌 수가 $1$이다. 이를 선도 1leading 1 모든 성분가 $0$인 행은 가장 아래에 적는다. $0$이 아닌 원소가 있는 행이 연속될 때 윗행의 선도 1이 아랫행의 선도 1보다 왼쪽에 있어야 한다. 행사다</description>
    </item>
    
    <item>
      <title>줄리아 패키지 설치 시 \General\Registry.toml: No such file or directory 해결</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-fix-registry.toml-no-such-file-or-directory/</link>
      <pubDate>Sat, 20 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-fix-registry.toml-no-such-file-or-directory/</guid>
      <description>에러 ERROR: SystemError: opening file &amp;quot;C:\\Users\\rmsms\\.julia\\registries\\General\\Registry.toml&amp;quot;: No such file or directory 원인 사람 정말 열 받게 하는 에러인데, 말 그대로 해당 경로에 Registry.toml 파일이 없어서 일어나는 에러다. 해결법 C:\Users\사용자이름\.julia\registries\General 폴더를 삭제하고 다시 시도해본다. 그러면 위와 같이 Registry.toml 파일도 생기고 설치도 정상적으로 진행되는 것을 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>벡터공간의 기저</title>
      <link>https://freshrimpsushi.github.io/posts/basis-of-vector-space/</link>
      <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/basis-of-vector-space/</guid>
      <description>정의1 $S = \left\{ \mathbf{v}_{1}, \mathbf{v}_{2}, \dots, \mathbf{v}_{r} \right\}$를 벡터공간 $V$의 부분집합이라고 하자. $S$가 아래의 두 조건을 만족시키면 $S$를 $V$의 기저basis라 한다. $S$가 $V$를 생성한다. $$ V = \text{span}(S) $$ $S$가 선형독립이다. 설명 기저는 그 이름에서 짐작할 수 있듯 &amp;lsquo;벡터공간을 만들어낼 수 있는 가장 작은 것&amp;rsquo;의</description>
    </item>
    
    <item>
      <title>윈도에서 줄리아 최신 버전 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-julia-in-windows/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-julia-in-windows/</guid>
      <description>가이드 Step 1. 줄리아 설치 줄리아 다운로드 페이지에서 설치 파일을 받고 실행한다. Step 2. vs code 설치 비주얼 스튜디오 코드 다운로드 페이지에서 설치파일을 받고 실행한다. Step 3. 줄리아 확장 설치 좌측 다섯번째 아이콘 혹은 Ctrl + Shift + X으로 Extensions을 연다. &amp;lsquo;julia&amp;rsquo;를 검색하면 최상단에 Julia Language Support가 뜬</description>
    </item>
    
    <item>
      <title>행렬변환</title>
      <link>https://freshrimpsushi.github.io/posts/matrix-transformation/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/matrix-transformation/</guid>
      <description>정의 $\mathbb{R}^{n}$에서 $\mathbb{R}^{m}$으로의 함수가 $m \times n$ 행렬 $A$에 대해서 다음과 같이 매핑될 때 이를 행렬변환matrix transformation이라 하고 $T_{A} : \mathbb{R}^{n} \to \mathbb{R}^{m}$와 같이 표기한다. $$ \mathbf{w} = T_{A} (\mathbf{x}) = A\mathbf{x}\quad \left( \mathbf{x} \in \mathbb{R}^{n}, \mathbf{w} \in \mathbb{R}^{m} \right) $$ $\mathbf{x} \overset{T_{A}}{\to} \mathbf{w}$와</description>
    </item>
    
    <item>
      <title>행렬의 닮음</title>
      <link>https://freshrimpsushi.github.io/posts/similarity-of-matrix/</link>
      <pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/similarity-of-matrix/</guid>
      <description>정의1 정사각행렬 $A$, $B$와 어떤 가역행렬 $P$에 대해서 다음의 식이 성립하면 $B$가 $A$와 닮았다$B$ is similar to $A$고 한다. $$ B = P^{-1} A P $$ 설명 정의에 의해 $B$가 $A$와 닮았으면 $A$도 $B$와 닮았다. 닮았다고 명명한 이유는 닮은 행렬끼리 공유하는 중요한 성질이 많기 때문이다. 이를 닮음 불변similarity invariant 혹은 닮</description>
    </item>
    
    <item>
      <title>여러가지 함수공간</title>
      <link>https://freshrimpsushi.github.io/posts/various-function-space/</link>
      <pubDate>Fri, 12 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/various-function-space/</guid>
      <description>정의 함수들의 집합 $X$가 벡터공간이면 $X$를 함수공간function space이라 한다. 설명 함수공간 $X$에서 내적은 다음과 같이 적분으로 정의된다. $$ \langle f, g \rangle = \int f(x) g(x) dx,\quad f,g\in X $$ 주요하게 다루는 함수 공간으로는 다음의 것들이 있다. 연속함수공간 $C^{m}$ $$ C^{m}(\mathbb{R}) : =\left\{ f \in C(\mathbb{R}) : f^{(n)} \text{ is continuous } \forall n \le m \right\} $$ 테스트함수공간 $C_{c}^{\infty} = \mathcal{D}$ 슈바르츠공간</description>
    </item>
    
    <item>
      <title>고유값과 고유벡터</title>
      <link>https://freshrimpsushi.github.io/posts/eigenvalue-and-eigenvector/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eigenvalue-and-eigenvector/</guid>
      <description>정의1 $n\times n$ 행렬 $A$가 주어졌다고 하자. $\mathbf{0}$이 아닌 $n\times 1$ 열벡터 $\mathbf{x}$, 그리고 상수 $\lambda$에 대해서 다음의 식을 고유값 방정식eigenvalue equation 혹은 고유값 문제eigenvalue problem이라고 한다. $$ \begin{equation} A \mathbf{x} = \lambda \mathbf{x} \label{eigenvalue} \end{equation} $$ 주어진 $A$에 대해서 위와 같이 고유값 방정식을 만족하는 $\lam</description>
    </item>
    
    <item>
      <title>편도함수</title>
      <link>https://freshrimpsushi.github.io/posts/partial-derivative/</link>
      <pubDate>Mon, 08 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partial-derivative/</guid>
      <description>정의1 $E\subset \mathbb{R}^{n}$를 열린집합, $\mathbf{x}\in E$, 그리고 $\mathbf{f} : E \to \mathbb{R}^{m}$라고 하자. $\left\{ \mathbf{e}_{1}, \mathbf{e}_{2}, \dots, \mathbf{e}_{n} \right\}$, $\left\{ \mathbf{u}_{1}, \mathbf{u}_{2}, \dots, \mathbf{u}_{m} \right\}$을 각각 $\mathbb{R}^{n}$, $\mathbb{R}^{m}$의 표준기저라고 하자. 그러면 $\mathbf{f}$의 성분components $f_{i} : \mathbb{R}^{n} \to \mathbb{R}$은 다음</description>
    </item>
    
    <item>
      <title>정부호 행렬</title>
      <link>https://freshrimpsushi.github.io/posts/definite-matrix/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definite-matrix/</guid>
      <description>정의: 정부호 행렬1 이차 형식 $\mathbf{x}^{\ast} A \mathbf{x}$가 모든 $\mathbf{x} \ne \mathbf{0}$ 에 대해서 $\mathbf{x}^{\ast} A \mathbf{x} &amp;gt; 0$ 을 만족하면 이차 형식 혹은 행렬 $A$를 양의 정부호positive definite라고 한다. 모든 $\mathbf{x} \ne \mathbf{0}$ 에 대해서 $\mathbf{x}^{\ast} A \mathbf{x} &amp;lt; 0$ 을 만족하면 이차 형식 혹은 행렬 $A$를 음의 정부호negative definite라고 한다. $\mathbf{x}$ 에 따라서 양수이기</description>
    </item>
    
    <item>
      <title>일차 형식과 이차 형식</title>
      <link>https://freshrimpsushi.github.io/posts/linear-form-and-quadratic-form/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-form-and-quadratic-form/</guid>
      <description>정의1 상수 $a_{1}, a_{2}, \dots, a_{n}$과 변수 $x_{1}, x_{2}, \dots, x_{n}$들에 대해서 다음과 같은 일차 다항식을 일차형식linear form이라 한다. $$ a_{1}x_{1} + a_{2}x_{2} + \cdots + a_{n}x_{n} = \sum \limits _{i=1}^{n} a_{i}x_{i} $$ 설명 $a_{i}$, $x_{i}$들이 실수이면 $\mathbb{R}^{n}$ 상의 일차 형식이라 한다. 또한 상수와 변수를 $\mathbf{a}=\begin{bmatrix} a_{1} &amp;amp; \cdots &amp;amp; a_{n} \end{bmatrix}^{T}$, $\mathbf{x}=\begin{bmatrix} x_{1} &amp;amp; \cdots &amp;amp; x_{n} \end{bmatrix}^{T}$와 같이 열벡터로 나</description>
    </item>
    
    <item>
      <title>행렬식의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-determinant/</link>
      <pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-determinant/</guid>
      <description>성질 $A,B$를 $n\times n$행렬, $k$를 상수라고 하자. 행렬식은 다음과 같은 성질을 만족한다. (a) $\det(kA) = k^{n}\det(A)$ (b) $\det(AB) = \det(A)\det(B)$ (c) $\det(AB)=\det(BA)$ (d) $A$가 가역행렬이면, $\det(A^{-1}) = \dfrac{1}{\det(A)}$ (e) $\det(A^{T}) = \det(A)$. 이때 $A^{T}$는 $A$의 전치이다.</description>
    </item>
    
    <item>
      <title>행렬식</title>
      <link>https://freshrimpsushi.github.io/posts/determinant/</link>
      <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/determinant/</guid>
      <description>정의 $A$를 다음과 같은 $2 \times 2$ 행렬이라고 하자. $$ A = \begin{bmatrix} a &amp;amp; b \\ c &amp;amp; d \end{bmatrix} $$ $A$의 행렬식determinant을 다음과 같이 정의하고 $\det(A)$로 나타낸다. $$ \det(A) := ad - bc $$ 설명 행렬식 이야기를 하기 위해선 선형 대수학의 목적 자체를 이야기하지 않을 수 없다. 대부분의 수학에서 말하는 문제는 기본적으로 &amp;lsquo;방정식</description>
    </item>
    
    <item>
      <title>첨가행렬과 기본 행 연산</title>
      <link>https://freshrimpsushi.github.io/posts/augmented-matrix-and-elementary-row-operations/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/augmented-matrix-and-elementary-row-operations/</guid>
      <description>정의1 아래와 같은 선형 시스템이 주어졌다고 하자. $$ \begin{equation} \begin{aligned} a_{11}x_{1} + a_{12}x_{2} + \cdots + a_{1n}x_{n} &amp;amp;= b_{1}\\ a_{21}x_{1} + a_{22}x_{2} + \cdots + a_{2n}x_{n} &amp;amp;= b_{2}\\ &amp;amp;\vdots\\ a_{m1}x_{1} + a_{m2}x_{2} + \cdots + a_{mn}x_{n} &amp;amp;= b_{m} \end{aligned} \label{linsys2} \end{equation} $$ 선형 시스템의 상수들을 행렬로 표현한 것을 첨가행렬augmented matrix라고 한다. $$ \begin{equation} \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} &amp;amp; b_{1} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} &amp;amp; b_{2} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \vdots \\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn} &amp;amp; b_{m} \end{bmatrix} \label{augmented} \end{equation} $$ 설명 행렬은</description>
    </item>
    
    <item>
      <title>연립 일차 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/linear-system/</link>
      <pubDate>Mon, 22 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-system/</guid>
      <description>정의1 상수 $a_{1}$, $a_{2}$, $\dots$, $a_{n}$, $b$에 대해서 변수 $x_{1}$, $x_{2}$, $\dots$, $x_{n}$의 일차 방정식linear equation을 다음과 같이 정의한다. $$ \begin{equation} a_{1}x_{1} + a_{2}x_{2} + \cdots + a_{n}x_{n} = b \label{lineq} \end{equation} $$ 이때 적어도 하나의 $a$는 $0$이 아니다. 다시 말해 &#39;모든 $a$가 $0$&#39;인 것은 아니다. 일차 방정식들의 유한 집합을 연립 일차 방정식system of linear equations 혹은 간단히 선형</description>
    </item>
    
    <item>
      <title>선형함수</title>
      <link>https://freshrimpsushi.github.io/posts/linear-function/</link>
      <pubDate>Sat, 20 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-function/</guid>
      <description>정의 함수 $f : X \to Y$가 다음의 두 조건을 만족하면 선형linear이라고 한다. $x,x_{1},x_{2}\in X$, $a \in \mathbb{R}$에 대해서, $f(ax) = af(x)$ $f(x_{1} + x_{2}) = f(x_{1}) + f(x_{2})$ 두 조건을 한데 묶어 다음과 같이 표현하기도 한다 $$ f(ax_{1} + x_{2}) = af(x_{1}) + f(x_{2}) $$</description>
    </item>
    
    <item>
      <title>줄리아, 매트랩, 파이썬, R에서 동등한 코드들</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-codes-in-julia-python-matlab-r/</link>
      <pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-codes-in-julia-python-matlab-r/</guid>
      <description>파이썬에 대해서 다음과 같은 환경이라고 하자. import numpy as np 일반 줄리아 매트랩 파이썬 R 주석 #comment %comment #comment #comment 2차원 그리드 [X,Y] = meshgrid(x,y) X,Y = np.meshgrid(x,y) 플래튼 y = vec(x) y = x(:) y = np.ravel(x) y = c(x) 영행렬 y = zeros(4,2) y = zeros(4,2) y = np.zeros([4,2]) y = matrix(0,4,2) 푸리에 변환 줄리아에 대해서 다음과 같은 환경이라고 하자. using FFTW 줄리아 매트랩 파이썬 R 푸리에 변환 y = fft(x) y = fft(x) y = np.fft.fft(x) y = fft(x) 역변환 변환 x = ifft(y) x = ifft(y) x</description>
    </item>
    
    <item>
      <title>에르미트 행렬의 서로 다른 고유값의 고유벡터는 서로 수직이다</title>
      <link>https://freshrimpsushi.github.io/posts/the-eigenvectors-for-two-different-eigenvalues-of-the-hermitian-matrix-are-perpendicular-to-each-other/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-eigenvectors-for-two-different-eigenvalues-of-the-hermitian-matrix-are-perpendicular-to-each-other/</guid>
      <description>정리 $A$를 크기가 $n \times n$인 에르미트 행렬이라고 하자. $A$ 의 서로 다른 두 고유값 $\lambda , \mu$ 에 대한 고유 벡터를 $\mathbf{x}$, $\mathbf{y}$라고 하자. 즉 $$ \begin{align*} A \mathbf{x} =&amp;amp; \lambda \mathbf{x} \quad \\ A \mathbf{y} =&amp;amp; \mu \mathbf{y} \end{align*} $$ 그러면 두 고유 벡터는 서로 직교한다. $$ \mathbf{x} \perp \mathbf{y} $$ 설명 에르미트 행렬은 고유값이 모두 실수라는 성질뿐만 아니라 그들에 대응하는 고유벡터가 서로 직교한다는 성질</description>
    </item>
    
    <item>
      <title>유니타리 행렬</title>
      <link>https://freshrimpsushi.github.io/posts/unitary-matrix/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unitary-matrix/</guid>
      <description>정의 $A$를 정사각 복소수 행렬이라고 하자. $A$가 아래의 식을 만족하면 유니타리 행렬unitary이라 한다. $$ A^{-1}=A^{\ast} $$ 이때 $A^{-1}$는 $A$의 역행렬, $A^{\ast}$는 $A$의 켤레전치이다. 설명 유니타리 행렬은 간단히 말해서 직교행렬을 복소수 행렬에 대해서 확장한 것이다. 따라서 직교행렬의 성질을 그대로 가진다. 아</description>
    </item>
    
    <item>
      <title>에르미트 행렬의 고유값은 항상 실수이다</title>
      <link>https://freshrimpsushi.github.io/posts/eigenvalue-of-hermitian-is-real-number/</link>
      <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eigenvalue-of-hermitian-is-real-number/</guid>
      <description>정리 $A$를 크기가 $n \times n$인 에르미트 행렬이라고 하자. 그러면 $A$ 의 고유값은 모두 실수다. 설명 일반적인 행렬에서 고유값이 실수라는 보장은 없고, 에르미트 행렬에 대해서는 증명을 통해 실수임을 확인할 수 있다.직관적으로는 떠올리기 쉽지 않지만 증명 자체는 간단한 편이고, 팩트로써도 상당히 유용하다.후에 이어지는 양의 정부호 등의 개념과 결합</description>
    </item>
    
    <item>
      <title>마코프 결정 과정</title>
      <link>https://freshrimpsushi.github.io/posts/markov-decision-process/</link>
      <pubDate>Sun, 14 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/markov-decision-process/</guid>
      <description>정의 쉬운 정의1 강화학습에서 환경은 에이전트가 선택한 행동에 따라 다음 상태와 보상을 결정한다. 이 때 바로 직전 시점의 정보만 참고하여 상태와 보상을 결정하는 것을 마코프 결정 과정Markov decision procsee이라 한다. 이를 수식으로 나타내면 다음과 같다. $$ P(S_{t+1}, R_{t+1} | S_{t}, A_{t}) = P\left( S_{t+1}, R_{t+1} | S_{t}, A_{t}, S_{t-1}, A_{t-1}, \dots, S_{1}, A_{1}, S_{0}, A_{0} \right) $$ 어려운 정의 환경을 묘사하는 상태, 행</description>
    </item>
    
    <item>
      <title>에르미트 행렬</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-properties-hermite-matrix/</link>
      <pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-properties-hermite-matrix/</guid>
      <description>정의 $A$를 정사각 복소수 행렬이라고 하자. $A$가 아래의 식을 만족하면 에르미트 행렬Hermitian 혹은 자가 수반 행렬self-adjoint matrix이라 한다. $$ A^{\ast}=A $$ 이때 $A^{\ast}$는 $A$의 켤레 전치이다. $A$가 아래의 식을 만족하면 반 에르미트 행렬skew-Hermitian, anti-Herm</description>
    </item>
    
    <item>
      <title>직교행렬일 동치 조건</title>
      <link>https://freshrimpsushi.github.io/posts/equivalents-statements-for-orthogonal-matrix/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalents-statements-for-orthogonal-matrix/</guid>
      <description>정리 $n \times n$ 실수 행렬 $A$에 대해서 아래의 명제는 모두 동치이다. (a) $A$가 직교행렬이다. (b) $A$의 행 벡터들의 집합은 $\mathbb{R}^n$의 정규직교집합이다. (c) $A$의 열 벡터들의 집합은 $\mathbb{R}^n$의 정규직교집합이다. (d) $A$가 내적을 보존한다. 즉 모든 $\mathbf{x},\mathbf{y}\in \mathbb{R}^{n}$에 대해</description>
    </item>
    
    <item>
      <title>다변량 정규 분포</title>
      <link>https://freshrimpsushi.github.io/posts/multivariate-normal-distribution/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multivariate-normal-distribution/</guid>
      <description>정의 모평균 벡터 $\mathbf{\mu} \in \mathbb{R}^{p}$ 와 공분산 행렬 $\Sigma \in \mathbb{R}^{p \times p}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 다변량 분포 $N_{p} \left( \mu , \Sigma \right)$ 를 다변량 정규 분포Multivariate Normal Distribution라고 한다. $$ f (\textbf{x}) = \left( (2\pi)^{p} \det \Sigma \right)^{-1/2} \exp \left[ - {{ 1 } \over { 2 }} \left( \textbf{x} - \mathbf{\mu} \right)^{T} \Sigma^{-1} \left( \textbf{x} - \mathbf{\mu} \right) \right] \qquad , \textbf{x} \in \mathbb{R}^{p} $$ 같이보기 일변량 정규 분포: $p = 1$ 이어서 $\mu \in \mathbb{R}^{1}$ 이고 $\Sigma \in</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability-of-random-vector/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability-of-random-vector/</guid>
      <description>정의 1 $p$차원 랜덤 벡터 $\mathbf{X}$ 와 랜덤 벡터의 시퀀스 $\left\{ \mathbf{X}_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $\mathbf{X}_{n}$ 이 $\mathbf{X}$ 로 확률 수렴Convergence in Probability한다고 말하고, $\mathbf{X} _ {n} \overset{P}{\to} \mathbf{X}$ 와 같이 나타낸다. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left\| \mathbf{X}_{n} - \mathbf{X} \right\| &amp;lt; \varepsilon \right] = 1 $$ $\| \cdot \|$ 는 유클리드 놈으로써, $\left\| \left( x_{1} , \cdots , x_{n} \right) \right\| = \sqrt{ x_{1}^{2} + \cdots + x_{n}^{2}}$ 와 같이 정의된다. 정리</description>
    </item>
    
    <item>
      <title>1&#43;1&#43;1&#43;1&#43;1&#43;⋯=-12 의 해석적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/analytic-proof-of-zeta-zero/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/analytic-proof-of-zeta-zero/</guid>
      <description>정리 $$ \begin{align*} &amp;amp;&amp;amp; 1 + 1 + 1 + 1 + 1 + \cdots \\ =&amp;amp; \sum_{n \in \mathbb{N}} {{ 1 } \over { n^{0} }} \\ =&amp;amp; \zeta(0) \\ =&amp;amp; -{{ 1 } \over { 2 }} \end{align*} $$ 설명 양수를 계속 더했는데 어떻게 음수가 나오는가에만 집중한다면 이 포스트를 절대 이해할 수 없을 것이다. 핵심은 $\sum_{n \in \mathbb{N}} 1$ 이 디리클레 급수 $\displaystyle \sum_{n \in \mathbb{N}} {{ 1 } \over { n^{0} }}$ 으로 표현된다는 것이고, 그 해석적 연속인 리만 제타 함수 $\zeta$ 의 함숫값 $\zeta(0)$ 으로써 계산한다는</description>
    </item>
    
    <item>
      <title>공분산 행렬</title>
      <link>https://freshrimpsushi.github.io/posts/covariance-matrix/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/covariance-matrix/</guid>
      <description>정의1 $p$차원 랜덤 벡터 $\mathbf{X} = \left( X_{1}, \cdots , X_{p} \right)$ 에 대해 다음과 같이 정의된 $\text{Cov} (\mathbf{X})$ 를 공분산 행렬Covariance Matrix이라 한다. $$ \left( \text{Cov} \left( \mathbf{X} \right) \right)_{ij} := \text{Cov} \left( X_{i} , X_{j} \right) $$ $\text{Cov}$ 는 공분산이다. 설명 정의를 더 쉽게 풀어 적어보면 다음과 같다. $$ \text{Cov} \left( \mathbf{X} \right) := \begin{pmatrix} \text{Var} \left( X_{1} \right) &amp;amp; \text{Cov} \left( X_{1} , X_{2} \right) &amp;amp; \cdots &amp;amp; \text{Cov} \left( X_{1} , X_{p} \right) \\ \text{Cov} \left( X_{2} , X_{1} \right) &amp;amp; \text{Var} \left( X_{2} \right) &amp;amp; \cdots &amp;amp; \text{Cov} \left( X_{2} , X_{p}</description>
    </item>
    
    <item>
      <title>바스 확산 모델: 혁신과 모방</title>
      <link>https://freshrimpsushi.github.io/posts/bass-diffusion-model/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bass-diffusion-model/</guid>
      <description>모델 12 $$ N&#39; = \left( p + q {{ N } \over { K }} \right) \left( 1 - {{ N } \over { K }} \right) $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 파라메터 $K$: 환경 용량Carrying Capacity으로, 집단을 수용할 수 있는 환경의 크기를 묘사한다. 개체수는 환경 용량을 넘어서 성장할 수 없다. $p$: 혁신 계수Coefficient of Innovation 혹은 전역 성장률Global Growth R</description>
    </item>
    
    <item>
      <title>직교행렬의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-orthogonal-matrix/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-orthogonal-matrix/</guid>
      <description>성질1 직교행렬은 다음과 같은 성질을 갖는다. (a) 직교행렬의 전치도 직교행렬이다. (b) 직교행렬의 역행렬은 직교행렬이다. (c) 두 직교행렬의 곱은 직교행렬이다. (d) 직교행렬의 행렬식은 $1$이거나 $-1$이다. $$ \det(A)=\pm 1 $$ 증명 (a) $A$를 직교행렬이라고 하자. $B$를 $A$의 전치라고 하자. $$ B=A^{T} $$ 그러면 다음의 식이 성립한다. $$ B^{-1} = (A^{T})^{-1} = (A^{-1})^{-1}</description>
    </item>
    
    <item>
      <title>곰페르츠 성장 모델: 시간에 따른 성장 지연</title>
      <link>https://freshrimpsushi.github.io/posts/gompertz-growth-mode/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gompertz-growth-mode/</guid>
      <description>모델 1 $$ {{ d N } \over { dt }} = r e^{ - \alpha t} N \qquad, \alpha 0 $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 파라메터 $r \in \mathbb{R}$ : 고유 성장률Intrinsic Rate of Increase로써, $0$ 보다 크면 성장하고 $0$ 보다 작으면 쇠퇴한다. 번식률Birth Rate $b$ 와 사망률Death Rate $d$ 의 차 $r:=b-d$ 로 정의되기도 한다. $\alpha&amp;gt;0$: 일종의 감쇠율 을 나타내는 상수로, 클수록</description>
    </item>
    
    <item>
      <title>머신러닝에서 강화학습이란</title>
      <link>https://freshrimpsushi.github.io/posts/reinforcement-learning-in-machine-learning/</link>
      <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reinforcement-learning-in-machine-learning/</guid>
      <description>정의 강화학습이란, 에이전트가 환경과 상호작용하여 누적 보상을 최대화하는 정책을 찾을 수 있도록 하는 것이다. 설명1 강화학습을 이루고 있는 요소들은 다음과 같다. 에이전트agent: 주어진 상태에 대해서, 정책에 따라 행동을 결정한다. 상태state: 에이전트가 처한 상황을 말한다. 행동action: 에이전트가 주어진 상태에서 취할 수</description>
    </item>
    
    <item>
      <title>수리생물학에서의 알리 효과</title>
      <link>https://freshrimpsushi.github.io/posts/allee-efect-in-mathematical-biology/</link>
      <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/allee-efect-in-mathematical-biology/</guid>
      <description>알리 효과란? 1 개체군의 밀도가 낮을 때 인구수가 감소하는 효과를 알리 효과Allee Efect라 한다. 수식적으로는 다음과 같이 모델에서 $N$ 에 대한 함수 $a: \mathbb{R} \to \mathbb{R}$ 를 위로 볼록한 컨벡스 함수로 두어 표현한다. $$ N&#39; = a(N) N $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 예시 알리 이펙트는 예로써 함수 $a$ 를 다음과 같은 이차함수로 두어서 가정할 수 있다</description>
    </item>
    
    <item>
      <title>격자 모델 시뮬레이션에서의 확산</title>
      <link>https://freshrimpsushi.github.io/posts/diffusion-in-lattice-model-simulation/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diffusion-in-lattice-model-simulation/</guid>
      <description>시뮬레이션 이 포스트에서는 격자 공간에서 어떤 성분(Ingredient)의 확산 현상을 모방하려고 한다. 이는 그 동시에 SI 질병 확산 모델의 시뮬레이션이기도 하며, 공간이 제한되어 있다는 점에서 SIR 모델로도 볼 수 있다. 변수 $t$: 현재 턴을 의미한다. $I(t) \in \mathbb{N}$: $t$ 턴에서 확산되고 있는 성분(Ingredient)의 양을 나타낸다. $S(t) \in \mathbb{N}$: $t$ 턴에서</description>
    </item>
    
    <item>
      <title>라마누잔 합</title>
      <link>https://freshrimpsushi.github.io/posts/ramanujan-summation/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ramanujan-summation/</guid>
      <description>정의 발산하는 급수에 값을 매기는 것을 라마누잔 합이라 하고, 심볼 $\Re$ 을 통해 나타낸다. 정리 [1] 그란디 급수Grandi Series** 1: $$ 1-1+1-1+ \cdots = {{ 1 } \over { 2 }} \qquad ( \Re ) $$ [2] $$ 1-2+3-4+ \cdots = {{ 1 } \over { 4 }} \qquad ( \Re ) $$ [2]&#39; $$ 1+2+3+4+ \cdots = - {{ 1 } \over { 12 }} \qquad ( \Re ) $$ 설명 값이 존재하지 않으니 발산하지 거기다 값을 매긴다는 게 무슨 말인가 싶을 것이다. 우선은 수렴하지 않지만</description>
    </item>
    
    <item>
      <title>중심극한 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-central-limit-theorem/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-central-limit-theorem/</guid>
      <description>정리 1 ${X_n}$가 iid 확률 변수들이고 확률분포 $\left( \mu, \sigma^2 \right) $를 따른다고 하면 $n \to \infty$ 일 때 $$ \displaystyle \sqrt{n} {{ \overline{X}_n - \mu } \over {\sigma}} \overset{D}{\to} \text{N} (0,1) $$ $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 통계학에선 대수의 법칙과 더불어 정말 그 명성이 자자한 정리로 꼽힌다. 수없이 듣고 쓰는 정리지만 막상 증명은 수리통계학을 배우면서 한번 해볼까말까다. 하지만 실제로는 활용도를 떠나 증명 자체</description>
    </item>
    
    <item>
      <title>직교행렬</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-matrix/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-matrix/</guid>
      <description>정의 $A$를 정사각 실수 행렬이라고 하자. $A$가 아래의 식을 만족하면 직교행렬orthogonal matrix이라 한다. $$ A^{-1} = A^{T} $$ 위 조건을 다르게 표현다음 아래와 같다. $$ AA^{T} = A^{T}A =I $$ 설명 정의를 말로 풀어서 쓰면, 직교행렬이란 각각의 행벡터 혹은 열벡터들이 서로 직교하는 단위 벡터인 행렬이다. 복소수 행렬으로 확장한 경우에는 유니타</description>
    </item>
    
    <item>
      <title>격자 모델 시뮬레이션 첫걸음: 히트맵으로 나타내기</title>
      <link>https://freshrimpsushi.github.io/posts/tutorial-on-lattice-model-simulation/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tutorial-on-lattice-model-simulation/</guid>
      <description>시뮬레이션 코드 리뷰 Step 1. 격자 공간 생성 julia&amp;gt; colormap\_SI = [colorant&amp;quot;#EEEEEE&amp;quot;, colorant&amp;quot;#111111&amp;quot;] julia&amp;gt; row\_size = 5 5 julia&amp;gt; column\_size = 5 5 julia&amp;gt; Random.seed!(3); julia&amp;gt; stage\_lattice = rand([&#39;S&#39;], row\_size, column\_size) 5×5 Array{Char,2}: &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; &#39;S&#39; 위의 코드는 $5 \times 5$ 크기의 빈 격자 공간을 만들고 랜덤한 위치 두 곳을 채운 것이다. 빈 공간은 문자 &#39;S&#39;, 채운 공간은 &#39;I&#39;로 표시되어있다. Step 2. 히트맵으로 플로팅 stage\_lattice[rand(1:row\_size), rand(1:column\_size)] = &#39;I&#39;; stage\_lattice figure = heatmap(reverse(stage\_lattice,dims=1), color=colormap\_SI, xaxis=false,yaxis=false,axis=nothing, size = [400,400], legend</description>
    </item>
    
    <item>
      <title>리만 제타 함수의 로랑 전개 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-laurent-expansion-of-riemann-zeta-function/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-laurent-expansion-of-riemann-zeta-function/</guid>
      <description>정리 리만 제타 함수 $\zeta$ 의 로랑 전개는 다음과 같다. $$ \zeta (s) = {{ 1 } \over { s-1 }} + \sum_{n=0}^{\infty} \gamma_{n} {{ (1-s)^{n} } \over { n! }} \qquad , s &amp;gt; 1 $$ 여기서 $\gamma_{n}$ 은 $n$번째 스틸체스 상수Stieltjes constants 로, 다음과 같이 정의된다. $$ \gamma_{n} := \lim_{m \to \infty} \sum_{k=1}^{m} \left( {{ \left( \log k \right)^{n} } \over { k }} - {{ \left( \log m \right)^{n} } \over { n+1 }} \right) $$ 설명 스틸체스 상수는 특히 $n=0$ 일 때 $\gamma_{0} = \gamma$ 로써 오일러-마스케로니 상수다. 이</description>
    </item>
    
    <item>
      <title>약한 대수의 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-weak-law-of-large-numbers/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-weak-law-of-large-numbers/</guid>
      <description>법칙 ${X_n}$가 iid 확률 변수들이고 확률분포 $\left( \mu, \sigma^2 \right) $를 따른다고 하면 $n \to \infty$ 일 때 $$ \overline{X}_n \overset{P}{\to} \mu $$ $\overset{P}{\to}$ 는확률 수렴을 의미한다. 설명 이 정리는 그 어떤 분포든 &amp;lsquo;표본평균은 모평균으로 수렴한다&amp;rsquo;는 팩트를 함의한다. 생각해보면 당연할 수도 있지만, 자연과학에서 &amp;lsquo;당연하다&amp;rsquo;는 말만큼 중요한</description>
    </item>
    
    <item>
      <title>해석적 연속</title>
      <link>https://freshrimpsushi.github.io/posts/analytic-continuation/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/analytic-continuation/</guid>
      <description>정의 1 해석적 함수 $f_{1}: \mathscr{R}_{1} \to \mathbb{C}$ 에 대해 $$ \mathscr{S} := \mathscr{R}_{1} \cap \mathscr{R}_{2} \ne \emptyset \\ f_{1} (z) = f_{2} (z) \qquad , z \in \mathscr{S} $$ 를 만족하면서 $\mathscr{R}_{2} \subset \mathbb{C}$ 에서 해석적 함수 $f_{2}: \mathscr{R}_{2} \to \mathbb{C}$ 가 존재하면 $f_{2}$ 가 $\mathscr{R}_{2}$ 에서 $f_{1}$ 의 해석적 연속Analytic Continuation이라고 부른다. 설명 글은 굉장히 어렵게 적혀있지만 정의를 잘 읽어보면 결국 특정 영역 $\mathscr{S}$ 에서 $f_{2}$ 가 $f_{1}$ 을 완벽하게 대신할 수 있는 해석적 함수</description>
    </item>
    
    <item>
      <title>행렬의 내적</title>
      <link>https://freshrimpsushi.github.io/posts/inner-product-of-matrices/</link>
      <pubDate>Sun, 31 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inner-product-of-matrices/</guid>
      <description>정의: 두 열벡터의 내적1 크기가 $n \times 1$인 두 열벡터 $\mathbf{u}$, $\mathbf{v}$ $\in \mathbb{R}^{n}$의 내적inner product을 다음과 같이 정의한다. $$ \begin{equation} \mathbf{u} \cdot \mathbf{v} := \mathbf{u}^{T}\mathbf{v}=u_{1}v_{1} + u_{2}v_{2} + \cdots + u_{n}v_{n} \label{EuclideanIP} \end{equation} $$ $\mathbf{u}$, $\mathbf{v}$ $\in \mathbb{C}^{n}$인 경우에는 다음과 같다. $$ \mathbf{u} \cdot \mathbf{v} := \mathbf{u}^{\ast}\mathbf{v}=u^{\ast}_{1}v_{1}^{\ } + u_{2}^{\ast}v_{2}^{\ } + \cdots + u_{n}^{\ast}v_{n}^{\ } $$ 이때 $\mathbf{u}$는 $\mathb</description>
    </item>
    
    <item>
      <title>분포수렴하면 확률유계다</title>
      <link>https://freshrimpsushi.github.io/posts/if-convergence-in-distribution-then-bounded-in-probability/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-convergence-in-distribution-then-bounded-in-probability/</guid>
      <description>정리 확률변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 분포수렴하면 확률유계다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 앞서 확률수렴하면 분포수렴함을 보였으므로, 이 대우 명제를 생각해보면 &amp;lsquo;확률유계가 아니면 확률수렴하지 않는다&amp;rsquo;는 상식적인 따름정리도 얻을 수 있다. 증명 $\epsilon&amp;gt;0$ 가 주어져 있고 $X_{n}$ 이 확률변수 $X$ 로 분포수렴하며 그 누적분포함수가 $F_{X}$</description>
    </item>
    
    <item>
      <title>켤레전치행렬</title>
      <link>https://freshrimpsushi.github.io/posts/conjugate-transpose/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conjugate-transpose/</guid>
      <description>정의 $A$를 크기가 $m \times n $인 복소수 행렬이라고 하자. $\overline{A}$를 다음과 같이 정의하고 $A$의 켤레 행렬conjugate matrix이라고 한다. $$ \overline{A} :=\begin{bmatrix} \overline{a_{11}} &amp;amp; \overline{a_{12}} &amp;amp; \cdots &amp;amp; \overline{a_{1n}} \\ \overline{a_{21}} &amp;amp; \overline{a_{22}} &amp;amp; \cdots &amp;amp; \overline{a_{2n}} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ \overline{a_{m1}} &amp;amp; \overline{a_{m2}} &amp;amp; \cdots &amp;amp; \overline{a_{mn}} \end{bmatrix} = \left[ \overline{a_{ij}} \right] $$ 이때 $\overline{a}$는 $a$의 켤레 복소수이다. 다시 말</description>
    </item>
    
    <item>
      <title>해석적 함수</title>
      <link>https://freshrimpsushi.github.io/posts/analytic-funcion-regular-function-holomorphic-function/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/analytic-funcion-regular-function-holomorphic-function/</guid>
      <description>정의 열린 집합 $A \subset \mathbb{C}$ 과 $f: A \to \mathbb{C}$ 가 정의되어있고 $\alpha \in A$ 라고 하자. $\displaystyle \lim_{z \to \alpha } f(z) = f (\alpha)$ 면 $f$ 가 $\alpha$ 에서 연속이라고 하고 영역 $\mathscr{R}$ 의 모든 점에서 연속이면 $f$ 가 $\mathscr{R}$ 상에서 연속이라고 한다. 특히 $f$ 가 정의역 상에서 연속이면 연속함수라 부른다. 12. $\alpha$ 에서 $f$ 의 미분계수를 다음과 같이 정의하고, $\alpha$ 에서 미분계수가 존재하면 $f$ 가 $\alpha$ 에서 미분가능 하다고 한다. 2</description>
    </item>
    
    <item>
      <title>확률수렴하면 분포수렴한다</title>
      <link>https://freshrimpsushi.github.io/posts/if-convergence-in-probability-then-convergence-in-distribution/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-convergence-in-probability-then-convergence-in-distribution/</guid>
      <description>정리1 확률변수 $X$ 와 확률변수의 시퀀스 $\left\{ X_{n} \right\}$ 에 대해 $$ X_{n} \overset{P}{\to} X \implies X_{n} \overset{D}{\to} X $$ $\overset{P}{\to}$ 는 확률 수렴을 의미한다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 직관적인 단어로 다시 말하자면, 분포만 수렴하는 것이 정확히 수렴하는 것보다는 훨씬 쉽다는 말이다. 확률변수라는 것 자체를 함수로써 정확하게 이해하고 있다면 받아들이기 어렵지 않을 것이다. 증명 전략: 사건을 둘로</description>
    </item>
    
    <item>
      <title>대칭행렬, 반대칭행렬</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-properties-of-symmetric-matrix-antisymmetric-matrix/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-properties-of-symmetric-matrix-antisymmetric-matrix/</guid>
      <description>정의1 임의의 정사각행렬 $A$가 다음의 식을 만족하면 $A$를 대칭행렬symmetric matrix 이라고 한다. $$ A=A^{T} $$ 이때 $A^{T}$는 $A$의 전치행렬이다. $A$가 다음의 식을 만족하면 $A$를 반대칭행렬anti-symmetric matrix이라고 한다. $$ A =-A^{T} $$ 설명 전치행렬의 정의에 의해 정사각행렬이 아닌 행렬은 대칭행</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 유계</title>
      <link>https://freshrimpsushi.github.io/posts/bounded-in-probability/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bounded-in-probability/</guid>
      <description>정의 1 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 주어져 있다고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 다음을 만족시키는 $N_{\varepsilon} \in \mathbb{N}$ 과 상수 $B_{\varepsilon} &amp;gt; 0$ 가 존재하면 $\left\{ X_{n} \right\}$ 가 확률 유계Bounded in Probability라고 한다. $$ n \ge N_{\varepsilon} \implies P \left[ \left| X_{n} \right| \le B_{\varepsilon} \right] \ge 1 - \varepsilon $$ 설명 생각해보면 일상생활에서 실제로 접하는 많은 확률 분포 함수들의 정의역이 무한히 넓다. 표준정규분포 $N(0,1)$</description>
    </item>
    
    <item>
      <title>스튜던트 t-분포의 극한분포로써 표준정규분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-t-distribution/</link>
      <pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-t-distribution/</guid>
      <description>정리 $T_n \sim t(n)$ 이면 $$ T_n \ \overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. $t(r)$ 은 자유도 $r$ 인 t-분포다. $\overset{D}{\to}$ 는 각각 분포 수렴을 의미한다. 애초에 스튜던트 t분포는 표본이 작을 때 통계적 분석을 하기 위해 태어났다. 표본의 크기가 커지면 표준정규분포와 비슷해지는데, 통계학적인 용어로는 분포수렴한다고 말한다. 따라서 별다른 과정이 없더라</description>
    </item>
    
    <item>
      <title>줄리아에서 16진법 RGB 코드 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-hex-rgb-code-in-julia/</link>
      <pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-hex-rgb-code-in-julia/</guid>
      <description>코드 줄리아에서는 rgb() 함수를 사용해서 0부터 1까지의 숫자로 색상을 만드는 법도 있지만 보통 색은 16진법으로 쓰게 편하기 때문에 함수보다 문자열로 바로 넣는 게 낫다. 대개의 언어는 문자열로 &amp;quot;#000000&amp;quot;를 쓰면 바로 검은색이 표현되지만, 줄리아의 경우엔 앞에 colorant를 붙여 명시해주어야한다. using Plots histogram(randn(100), color = colorant&amp;quot;#6666FF&amp;quot;)</description>
    </item>
    
    <item>
      <title>가역행렬일 동치 조건</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-statements-for-invertible-matrix/</link>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-statements-for-invertible-matrix/</guid>
      <description>정리1 $A$를 크기가 $n\times n$인 정사각행렬이라고 하자. 그러면 아래의 명제는 모두 동치이다. (a) $A$는 가역행렬이다. (b) 동차 선형 시스템 $A\mathbf{x}=\mathbf{0}$는 오직 자명해만을 갖는다. (c) $A$의 기약 행사다리꼴 이 $I_{n}$이다. (d) $A$는 기본행렬의 곱으로 표현가능하다. (e) $A\mathbf</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터프레임과 2차원배열 간 변환 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-convert-between-dataframe-and-2-dimensional-array/</link>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-convert-between-dataframe-and-2-dimensional-array/</guid>
      <description>코드 줄리아에서는 다음과 같이 convert() 함수를 통해 간단하게 데이터프레임과 2차원배열 사이를 오갈 수 있다. 이 함수는 물론 다른 자료형에 대해서도 유용하게 사용된다. data1 = rand(4,3) data2 = convert(DataFrame, data1) data3 = convert(Array, data2) 실행결과는 다음과 같다.</description>
    </item>
    
    <item>
      <title>푸아송분포의 극한분포로써 표준정규분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-poisson-distribution/</link>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-poisson-distribution/</guid>
      <description>정리 $X_{n} \sim \text{Poi} \left( n \right)$ 이고 $\displaystyle Y_{n} := {{ X_{n} - n } \over { \sqrt{n} }}$ 이면 $$ Y_{n} \overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. $\text{Poi} (\lambda)$ 는 평균과 분산이 $\lambda$ 인 푸아송 분포다. 이항분포의 푸아송분포 근사를 생각해보면 당연하겠지만, 푸아송분포에서 역시 표준정규분포를 유도될 수 있다. 유도1 $Y_{n}$ 의 적률생성함수 $M_{Y_{n}} (t)$ 를 통해 분포수렴함을 보인다. 푸아송 분포의</description>
    </item>
    
    <item>
      <title>리만 가설</title>
      <link>https://freshrimpsushi.github.io/posts/riemman-hypothesis/</link>
      <pubDate>Sun, 24 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riemman-hypothesis/</guid>
      <description>추측 $\zeta (s) = 0$ 을 만족하는 모든 비자명 해 $s$ 는 $\displaystyle \Re (s) = {{ 1 } \over { 2 }}$ 를 만족할 것이다. $\zeta$ 는 리만 제타 함수다. $\Re(z)$ 는 복소수 $z \in \mathbb{C}$ 의 실수부를 의미한다. 설명 리만 가설은 아직까지 풀리지 않은 밀레니엄 문제로써, 수학에 익숙하지 않은 비전공자라면 그 의미는 물론 말 자체를 이해하기 어려울 것이다. 이 가설은 참인 것으로 증명될 경우 덩달아 참인걸로 밝혀</description>
    </item>
    
    <item>
      <title>줄리아에서 *.csv 파일 읽어들이는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-csv-files-in-julia/</link>
      <pubDate>Sun, 24 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-csv-files-in-julia/</guid>
      <description>가이드 사실 줄리아는 아직 데이터 입력 면에서 특출나게 편리한 언어는 아니다. 그래도 빠른 속도를 원한다면 파이썬이나 R, matlab보다 줄리아를 선택해야하는 순간이 올 수도 있을 것이다. 가령 위와 같이 E 드라이브 바로 밑에 있는 *.csv파일을 불러들인다고 하면 다음과 같이 입력하면 된다. using CSV data = CSV.read(&amp;quot;E:/example.csv&amp;quot;) 실행 결과를 보면 *.csv파일이 데이터프</description>
    </item>
    
    <item>
      <title>로지스틱 성장 모델: 집단 성장의 한계</title>
      <link>https://freshrimpsushi.github.io/posts/logistic-growth-model/</link>
      <pubDate>Sat, 23 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logistic-growth-model/</guid>
      <description>모델 $$ N&#39; = {{ r } \over { K }} N ( K - N) $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 파라메터 $r \in \mathbb{R}$ : 고유 성장률Intrinsic Rate of Increase로써, $0$ 보다 크면 성장하고 $0$ 보다 작으면 쇠퇴한다. 번식률Birth Rate $b$ 와 사망률Death Rate $d$ 의 차 $r:=b-d$ 로 정의되기도 한다. $K$: 환경 용량Carrying Capacity으로,</description>
    </item>
    
    <item>
      <title>역행렬, 가역행렬</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-properties-of-inverse-matrix-invertible-matrix/</link>
      <pubDate>Sat, 23 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-properties-of-inverse-matrix-invertible-matrix/</guid>
      <description>정의 $A$를 크기가 $n\times n$인 임의의 정사각행렬이라고 하자. $A$와 행렬 곱이 가능한 행렬 $L$이 다음의 식을 만족하면 $L$을 $A$의 좌 역행렬left inverse matrix라고 한다. $$ LA=I_{n} $$ 이때 $I_{n}$은 크기가 $n\times n$인 항등행렬이다. $A$와 행렬 곱이 가능한 행렬 $R$이 다음의 식을 만족하면 $R$을 $A$의 우 역행렬righ</description>
    </item>
    
    <item>
      <title>윈도우에서 줄리아 병렬연산 시 사용하는 쓰레드 수 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-the-number-of-thread-in-windows/</link>
      <pubDate>Sat, 23 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-the-number-of-thread-in-windows/</guid>
      <description>가이드 줄리아에서는 병렬 연산을 일상적으로 사용하기 때문에 경우에 따라서는 컴퓨터의 모든 소스를 계산에 집중할 필요가 있다. 이때 쓰레드 수를 바꾸는 방법은 여러가지가 있겠지만 가장 스태틱하고 편한 방법은 환경 변수를 편집하는 것이다. Step 1. 시스템 환경 변수 편집 윈도키 혹은 윈도+S를 눌러 &amp;lsquo;시스템 환경 변수 편집&amp;rsquo;을 찾는</description>
    </item>
    
    <item>
      <title>이항분포의 극한분포로써 표준정규분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-binomial-distribution/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-binomial-distribution/</guid>
      <description>정리 $X_i \sim B(1,p)$ 이고 $Y_n = X_1 + X_2 + \cdots + X_n$ 이라고 하면 $Y_n \sim B(n,p)$ 이고 $$ \displaystyle { { Y_n - np } \over {\sqrt{ np(1-p) } } }\overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. $B(n,p)$ 은 시행 $n$ 번에 확률 $p$ 인 이항 분포다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 통계를 처음 접할때부터 이항분포의 표본이 커지면 정규분포에 근사함을 배워왔다. 경험적으로도 당연하고 증명 과정이 큰 의미를</description>
    </item>
    
    <item>
      <title>줄리아에서 실행되는 코드 파일의 위치 확인하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-the-directory-of-julia-code-file/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-the-directory-of-julia-code-file/</guid>
      <description>가이드 줄리아를 사용하는 사람이라면 서버를 포함해서 여러 운영 체제나 여러 컴퓨터를 사용하는 것에 익숙할 가능성이 높다. 만약 파일 입출력이 있다면 개발환경이 달라질때마다 그 경로를 잡아주는 것이 무척 번거로울 수 있다. 이를 해결해주는 것이 바로 @__DIR__ 매크로다. 가령 다음과 같은 줄리아 코드 파일이 있다고 하자. 기본적으로 터미널에서 실행하면 pwd(</description>
    </item>
    
    <item>
      <title>리눅스에서 줄리아 병렬연산 시 사용하는 쓰레드 수 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-the-number-of-thread-in-linux/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-the-number-of-thread-in-linux/</guid>
      <description>가이드 줄리아에서는 병렬 연산을 일상적으로 사용하기 때문에 경우에 따라서는 컴퓨터의 모든 소스를 계산에 집중할 필요가 있다. 이때 쓰레드 수를 바꾸는 방법은 여러가지가 있겠지만 가장 스태틱하고 편한 방법은 환경 변수를 편집하는 것이다. Step 1. 시스템 환경 변수 편집 Ctrl + Alt + T 를 눌러 터미널을 열고 gedit ~/.bashrc를 입력한다. 그러면 다음과 같이</description>
    </item>
    
    <item>
      <title>이항분포의 극한분포로써 푸아송분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-distribution-as-limiting-distribution-of-binomial-distribution/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-distribution-as-limiting-distribution-of-binomial-distribution/</guid>
      <description>정리 $X_{n} \sim B(n,p)$이라고 하자. $\mu \approx np$ 이면 $$ X_{n} \overset{D}{\to} \text{Poi} (\mu) $$ $B(n,p)$ 은 시행 $n$ 번에 확률 $p$ 인 이항 분포다. $\text{Poi} (\lambda)$ 는 평균과 분산이 $\lambda$ 인 푸아송 분포다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 여기엔 $\mu \approx np$ 이라는 조건이 필요한 것에 주목하자. $ np \approx npq$ 이므로 $q = (1-p) \approx 1$ 즉, $p \approx 0$ 이다. 이는 $p$가 아주 작은 것을 뜻한다. 한편 $\displaystyle p \approx { {\mu} \over {n} }$ 이므로 $n</description>
    </item>
    
    <item>
      <title>전치행렬</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-properties-of-transpose-matrix/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-properties-of-transpose-matrix/</guid>
      <description>정의1 $A$를 크기가 $m\times n$인 행렬이라고 하자. $A$의 행과 열을 서로 바꾼 행렬을 $A$의 전치행렬transpose, 전치이라고 하고 $A^{T}$ 혹은 $A^{t}$라고 표기한다. 설명 정의에 따라 $A$가 $m \times n$ 행렬이면 $A^{T}$는 $n \times m$ 행렬이 된다. 또한 $A$의 $i$번째 행은 $A^{T}$의 $i$번째 열과 같고 그 반대도 마찬</description>
    </item>
    
    <item>
      <title>줄리아에서 합성함수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-function-composition-in-julia/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-function-composition-in-julia/</guid>
      <description>코드 julia&amp;gt; f(x) = 2x + 1 f (generic function with 1 method) julia&amp;gt; g(x) = x^2 g (generic function with 1 method) julia&amp;gt; (g ∘ f)(3) 49 설명 줄리아에서 함수의 합성은 프로그래밍적으로는 파이프 오퍼레이터와 흡사하다. 이러한 합성이 가능함으로써 가장 큰 이점은 수학자의 입장에서 수식을 코드로 표현하기가 쉬워진다는 것이다. 위 예시는 단지 다음의 수식을 코드로 옮긴 것에 불과하다. $$ f(x) := 2x + 1 \\ g(x) := x^2 \\ (g \circ f) (3)</description>
    </item>
    
    <item>
      <title>항등행렬, 영행렬</title>
      <link>https://freshrimpsushi.github.io/posts/identity-matrix-and-zero-matrix/</link>
      <pubDate>Tue, 19 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/identity-matrix-and-zero-matrix/</guid>
      <description>정의: 항등행렬 크기가 $n\times n$이고 대각 성분 모두 $1$인 대각행렬을 항등행렬identity matrix 혹은 단위 행렬unit matrix이라 하고 $I_{n}$혹은 $I_{n\times n}$이라 표기한다. $$ I_{n\times n}= \begin{bmatrix} 1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 1 \end{bmatrix} $$ 항등행렬은 행렬 곱에 대한 항등원이다. 즉 임의의 $n\times n$ 행렬 $A$에 대</description>
    </item>
    
    <item>
      <title>대각합</title>
      <link>https://freshrimpsushi.github.io/posts/defenition-and-properties-of-trace/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/defenition-and-properties-of-trace/</guid>
      <description>정의 $n\times n$ 행렬 $A$가 다음과 같이 주어졌다고 하자. $$ A= \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{n1} &amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \end{bmatrix} $$ $A$의 대각 성분들의 합을 $A$의 대각합trace 이라 정의하고 다음과 같이 표기한다. $$ \text{tr}(A)=\text{Tr}(A)=a_{11}+a_{22}+\cdots + a_{nn}=\sum \limits_{i=1}^{n} a_{ii} $$ 설명 다음과 같이 대각합을 함수로 생각할 수도 있다. $M_{n\times n}(\mathbb{R})$을 실수를 성분</description>
    </item>
    
    <item>
      <title>수리통계학에서의 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution/</guid>
      <description>정의 1 확률변수 $X$ 와 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $X_{n}$ 이 $X$ 로 분포 수렴Convergence in Distribution한다고 말하고, $X_{n} \overset{D}{\to} X$ 와 같이 나타낸다. $$ \lim_{n \to \infty} F_{X_{n}} (x) = F_{X} (x) \qquad, \forall x \in C_{F_{X}} $$ $F_{X}$ 는 확률변수 $X$ 의 누적분포함수다. $C_{F_{X}}$ 는 함수 $F_{X}$ 가 연속인 점들의 집합을 나타낸다. 설명 분포 수렴은 확률 수렴과 마찬가지</description>
    </item>
    
    <item>
      <title>대각행렬, 삼각 행렬</title>
      <link>https://freshrimpsushi.github.io/posts/diagonal-matrix-and-triangular-matrix/</link>
      <pubDate>Sun, 17 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diagonal-matrix-and-triangular-matrix/</guid>
      <description>대각행렬1 $A$를 크기가 $n\times n$인 정사각행렬이라고 하자. 행과 열의 번호가 같은 성분, 즉 $a_{11}$, $a_{22}$, $\dots$, $a_{nn}$들을 주대각성분main diagonal elements이라 한다. 주 대각 성분들을 이은 가상의 선을 주대각선main diagonal, principal diagonal 이라 한다. 주 대각 성분 $a_{11}$, $a_{22}$, $\dots$, $a_{nn}$을 제외한 모든 성분이 $0$이면 행렬 $A$를 대각행렬diag</description>
    </item>
    
    <item>
      <title>에이전트 기반 모델 시뮬레이션에서의 사망</title>
      <link>https://freshrimpsushi.github.io/posts/death-in-agent-based-simulation-model/</link>
      <pubDate>Sat, 16 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/death-in-agent-based-simulation-model/</guid>
      <description>시뮬레이션 이 포스트에서는 생성된 에이전트가 사망하는 액션을 주어 거시적인 관점에서 집단의 역성장을 모방하려고 한다. 이 시뮬레이션에서 공간이나 이동에 관련된 모든 것들은 단지 시각화를 위한 것이며, 실제 목적과는 아무런 관계가 없다. 변수 $t$: 현재 턴을 의미한다. $N(t)$: $t$ 턴에서 에이전트의 수를 나타낸다. 파라메터 $N_{0} \in \mathbb{N}$: 시뮬레이션이 시작할 때 에이</description>
    </item>
    
    <item>
      <title>정사각행렬</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-properties-of-square-matrix/</link>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-properties-of-square-matrix/</guid>
      <description>정의 임의의 행렬 $A$의 행과 열의 수가 같으면 행렬 $A$를 정사각행렬square matrix이라고 한다. 설명 정방 행렬이라고도 한다. 정사각행렬은 다루기 쉽고 여러가지 좋은 성질들이 있지만 우리가 항상 정사각행렬만을 다루게 되는 것은 아니다. 예 항등행렬 가역행렬 기본행렬 대칭행렬 직교행렬 에르미트 행렬 유니타리 행렬</description>
    </item>
    
    <item>
      <title>행렬의 연산: 상수배, 덧셈, 곱셈</title>
      <link>https://freshrimpsushi.github.io/posts/operations-of-matrix-scalar-multiplication-sum-multiplication/</link>
      <pubDate>Wed, 13 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operations-of-matrix-scalar-multiplication-sum-multiplication/</guid>
      <description>상수배 크기가 $m \times n$인 임의의 행렬 $A$와 상수 $k$의 곱은 $A$의 각 성분에 $k$를 곱하는 것으로 정의하고 다음과 같이 표기한다. $$ kA=k\begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn} \end{bmatrix} := \begin{bmatrix} ka_{11} &amp;amp; ka_{12} &amp;amp; \cdots &amp;amp; ka_{1n} \\ ka_{21} &amp;amp; ka_{22} &amp;amp; \cdots &amp;amp; ka_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{m1} &amp;amp; ka_{m2} &amp;amp; \cdots &amp;amp; ka_{mn} \end{bmatrix} $$ 정의에 의해 상수와 행렬의 곱은 교환 관계가 성립한</description>
    </item>
    
    <item>
      <title>에이전트 기반 모델 시뮬레이션에서의 번식</title>
      <link>https://freshrimpsushi.github.io/posts/reproduction-in-agent-based-simulation-model/</link>
      <pubDate>Tue, 12 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reproduction-in-agent-based-simulation-model/</guid>
      <description>시뮬레이션 이 포스트에서는 생성된 에이전트에게 스스로 복제하는 액션을 주어 거시적인 관점에서 집단의 성장을 모방하려고 한다. 이 시뮬레이션에서 공간이나 이동에 관련된 모든 것들은 단지 시각화를 위한 것이며, 실제 목적과는 아무런 관계가 없다. 변수 $t$: 현재 턴을 의미한다. $N(t)$: $t$ 턴에서 에이전트의 수를 나타낸다. 파라메터 $N_{0} \in \mathbb{N}$: 시뮬레이션이 시작할</description>
    </item>
    
    <item>
      <title>매트랩에서 2차원 배열을 히트맵 이미지로 출력하고 저장하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-and-save-arrays-as-heatmap-images-in-matlab/</link>
      <pubDate>Mon, 11 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-and-save-arrays-as-heatmap-images-in-matlab/</guid>
      <description>Imagesc imagesc 함수를 쓰면 2차원 배열을 히트맵으로 출력할 수 있다. colorbar는 스케일을 보여주는 컬러바를 같이 출력하는 설정이다. N=2^8; p=phantom(&#39;Modified Shepp-Logan&#39;,N); figure() imagesc(p) colorbar 저장 방법1 saveas 함수를 써서 위에서 띄운 figure를 저장할 수 있다. 이때 설정 gcf는 현재 figure를 의미한다. 그러면 아래의 그림이 저장된다. N=2^8; p=phantom(&#39;Modified Shepp-Logan&#39;,N); figure() imagesc(p) colorbar saveas(gcf,&#39;phantom.png&#39;) 방법2 아래 사진과 같이 figu</description>
    </item>
    
    <item>
      <title>서열정렬 점수와 갭 페널티</title>
      <link>https://freshrimpsushi.github.io/posts/sequence-alignment-score-and-gap-penalty/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sequence-alignment-score-and-gap-penalty/</guid>
      <description>정의 레퍼런스 서열과 쿼리 서열이 주어져 있다고 하자. 서열정렬 점수Sequence Alignment Score란 두 서열을 비교했을 때 얼마나 일치하는지를 수치화하는 것과 그 방법을 말한다. 점수화는 다음과 같은 사항들에 가중치를 주어 계산된다. Match: 두 서열이 일치하는 횟수다. Mismatch: 두 서열이 일치하지 않는 횟수다. 예시 예로써 위와 같은 두 염기서열이 있다고 하자.</description>
    </item>
    
    <item>
      <title>서열정렬에서의 치환행렬</title>
      <link>https://freshrimpsushi.github.io/posts/substitution-matrix/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/substitution-matrix/</guid>
      <description>정의 서열정렬 점수를 매길 때 매치와 미스매치의 기준이 되는 행렬을 치환행렬Substitution Matrix이라 한다. 예시 using BioAlignments EDNAFULL BLOSUM45 PAM30 거두절미하고 예시부터 보자. 줄리아에서는 BioAlignments라는 패키지가 나와있고 손쉽게 원하는 치환행렬을 불러들일 수 있다. DNA 분석에 자주 사용되는 EDNAFULL나 단백질 서열에 쓰이</description>
    </item>
    
    <item>
      <title>행렬의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-matrix/</link>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-matrix/</guid>
      <description>정의1 수를 다음과 같이 직사각형의 모양으로 나열해놓은 것을 행렬matrix이라고 한다. $$ A=\begin{bmatrix} 10 &amp;amp; 0 &amp;amp; 3 \\ 0 &amp;amp; 8 &amp;amp; 22 \end{bmatrix} $$ 나열해놓은 각각의 수를 엔트리entry 혹은 성분element이라고 한다. 가로 줄을 행row이라고 하며, 세로 줄을 열column이라고 한다. 또한 임의의 행렬이 $m$개의 행과 $n$개의 열을 가지면 그 행렬의</description>
    </item>
    
    <item>
      <title>벡터의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-vector/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-vector/</guid>
      <description>정의 수의 나열을 벡터라 한다. 설명 보통 교과과정에서 벡터는 &amp;lsquo;크기와 방향을 가진 기하학적 객체&amp;rsquo;로 배우게 된다. 아무래도 물리학에서 가장 먼저 접하게 되는 개념이다보니 다음과 같은 $3$차원 이하의 벡터에 친숙할수밖에 없다. $$ (3,4) = \begin{bmatrix} 3 \\ 4 \end{bmatrix} \\ (x,y,z) = \begin{bmatrix} x \\ y \\ z \end{bmatrix} $$ 그런데 사실 벡터는 그보다 더 많은 좌표에 대해 일반</description>
    </item>
    
    <item>
      <title>에이전트 기반 시뮬레이션 첫걸음: 산점도로 나타내기</title>
      <link>https://freshrimpsushi.github.io/posts/tutorial-on-agent-based-simulation/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tutorial-on-agent-based-simulation/</guid>
      <description>시뮬레이션 코드 리뷰 Step 1. 패키지 로드, 초기값 설정 julia&amp;gt; cd(@\_\_DIR\_\_) # 파일 저장 경로cd(@\_\_DIR\_\_) # 파일 저장 경로 julia&amp;gt; @time using Plots 19.989912 seconds (31.16 M allocations: 1.628 GiB, 4.49% gc Time) julia&amp;gt; @time using Random 0.034412 seconds (33.81 k allocations: 1.722 MiB) julia&amp;gt; @time using Distributions 3.436091 seconds (2.74 M allocations: 156.074 MiB, 0.90% gc Time) julia&amp;gt; @time using LinearAlgebra 0.009646 seconds (1.23 k allocations: 77.531 KiB) julia&amp;gt; N0 = 10 # 초기 인구수 10 julia&amp;gt; gaussian2 = MvNormal([0.0; 0.0], 0.02I) # 2차원 정규분포 IsoNormal( dim: 2 μ: [0.0, 0.0] Σ: [0.02 0.0; 0.0 0.02] ) 위의 코드는 패키</description>
    </item>
    
    <item>
      <title>델 연산자가 포함된 곱셈 규칙</title>
      <link>https://freshrimpsushi.github.io/posts/product-rule-with-del-operator/</link>
      <pubDate>Thu, 07 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/product-rule-with-del-operator/</guid>
      <description>공식 $f=f(x,y,z)$를 스칼라 함수라고 하자. $\mathbf{A} = A_{x}\hat{\mathbf{x}} + A_{y}\hat{\mathbf{y}} + A_{z}\hat{\mathbf{z}}, \mathbf{B} = B_{x}\hat{\mathbf{x}} + B_{y}\hat{\mathbf{y}} + B_{z}\hat{\mathbf{z}}$를 벡터 함수라고 하자. 그러면 다음의 식들이 성립한다. 그래디언트(기울기) (a) $\nabla{(fg)}=f\nabla{g}+g\nabla{f}$ (b) $\nabla(\mathbf{A} \cdot \mathbf{B}) = \mathbf{A} \times (\nabla \times \mathbf{B}) + \mathbf{B} \times (\nabla \times \mathbf{A})+(\mathbf{A} \cdot \nabla)\mathbf{B}+(\mathbf{B} \cdot \nabla) \mathbf{A}$ 다이벌전스(발산) (c) $\nabla \cdot (f\mathbf{A}) = f(\nabla \cdot \mathbf{A}) + \mathbf{A} \cdot (\nabla f)$ (d) $\nabla \cdot (\mathbf{A} \times \mathbf{B}) = \mathbf{B} \cdot (\nabla \times</description>
    </item>
    
    <item>
      <title>서열정렬이란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-sequence-alignment/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-sequence-alignment/</guid>
      <description>정의 염기서열 간의 유사도를 근거로 나열하는 것을 서열정렬Sequence Alignment이라 한다. 1 설명 생명정보공학에서 유전체의 길이는 무척 길기 때문에 이를 데이터화하는 것부터가 엄청난 일이다. 상상하기에는 우리도 중합효소처럼 DNA의 상류부터 하류까지 순서대로 읽으면서 저장하면 좋을 것 같지만, 현실적으로는 그렇게 할 수가 없</description>
    </item>
    
    <item>
      <title>라돈 변환의 유도와 성질</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-and-properties-of-radon-transform/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-and-properties-of-radon-transform/</guid>
      <description>설명 라돈 변환 은 적분 변환의 일종으로 오스트리아의 수학자 라돈(Johann Radon, 1887-1956)에서 이름을 따왔다. 방사성 원소 라돈은 수학자 라돈의 이름에서 따온 것이 아니라 방사성(radiactive)이라는 단어에 비활성기체접미사(-on)를 붙여 이름 지어졌다. CT 촬영의 핵심 원리중 하나이며 베르-람베르트 법칙이라는 물리</description>
    </item>
    
    <item>
      <title>동역학적 모델 시뮬레이션</title>
      <link>https://freshrimpsushi.github.io/posts/dynamical-model-simulation/</link>
      <pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamical-model-simulation/</guid>
      <description>설명 위의 움짤은 멜서스 성장 모델을 에이전트 기반 시뮬레이션으로 시각화한 것이다. 시뮬레이션Simulation이란 현상을 설명하는 모델을 가상으로 구현해 실험하는 것을 말하며, 동역학적 모델이라는 맥락에서 시뮬레이션은 흔히 다음과 같은 방법들을 말한다: Agent based Model: 에이전트 기반 모델은 거시세계를 모방하는 모델을 각 행위자(에이전트)의 미</description>
    </item>
    
    <item>
      <title>급수 해를 이용한 미분 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-differential-equation-using-power-series/</link>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-differential-equation-using-power-series/</guid>
      <description>설명 계수가 상수인 미분 방정식은 변수 분리법을 쓰거나 적분인자법을 사용하거나 하는 등 비교적 쉽게 풀어낼 수 있다. 그런데 아래와 같이 계수에 독립변수가 포함된 미분 방정식은 간단하게 풀 수가 없다. $$ \begin{equation} P(x)\dfrac{d^2 y}{dx^2} + Q(x)\dfrac{dy}{dx}+R(x)y=0 \label{1}\end{equation} $$ 이때 $P$, $Q$, $R$은 다항식이고 공통 인수가 없다고 가정한다. 위의 꼴을 가진 방정식으로는 베셀 방정식Bessel equation $$ x^2 y&#39;&#39; +xy&#39;+(x^2-\nu ^2)y=0,\quad \nu \text{ is</description>
    </item>
    
    <item>
      <title>문자열의 편집 거리</title>
      <link>https://freshrimpsushi.github.io/posts/edit-distance-of-strings/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/edit-distance-of-strings/</guid>
      <description>빌드업 1 문자열에는 다음과 같이 네가지 작용이 있다: 삽입: 문자열에 새로운 문자를 끼워넣는다. 제거: 문자열에서 문자 하나를 없앤다. 교체: 문자열에서 문자 하나를 다른 문자로 바꾼다. 전치: 두 문자의 위치를 서로 바꾼다. 정의 편집 거리는 문자열간의 거리 함수로써 편집 방법을 허용하거나 금지함으로써 다음과 같은 타입들로 구분된다: (1) Hamming distance: 해밍</description>
    </item>
    
    <item>
      <title>세미나</title>
      <link>https://freshrimpsushi.github.io/posts/seminar/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/seminar/</guid>
      <description>Google Drive ERPS Chaos: 2.643 🟡 Persistent coexistence of cyclically competing species in spatially extended ecosystems 🟢 Robust coexistence with alternative competition strategy in the spatial cyclic game of five species Scientific reports: 3.998 🟡 Heterogeneous network promotes species coexistence: metapopulation model for rock-paper-scissors game 🔴 Emergence of unusual coexistence states in cyclic game systems 🔴 Mesoscopic Interactions and Species Coexistence in Evolutionary Game Dynamics of Cyclic Competitions Eurosurveillance: 6.454 🔴 Incubation period of 2019 novel coronavirus (2019-nCoV) infections among travellers from Wuhan, China, 20–28 January 2020 Metapopulation Chinese Science Bulletin: 6.227 🔴🔥 Spatial epidemiology of networked metapopulation: an overview JSTOR 🔴 Entropy and Diversity: 인용수 3553 Ecology Letters: 8.66 🔴 Network theory and metapopulation persistence: incorporating node self‐connections Journal of Theoretical Biology: 2.327 🔴 Epidemic modeling in</description>
    </item>
    
    <item>
      <title>맬서스 성장 모델: 이상적인 집단 성장</title>
      <link>https://freshrimpsushi.github.io/posts/malthusian-growth-model/</link>
      <pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/malthusian-growth-model/</guid>
      <description>모델 $$ N &#39; = rN $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 파라메터 $r \in \mathbb{R}$ : 고유 성장률Intrinsic Rate of Increase로써, $0$ 보다 크면 성장하고 $0$ 보다 작으면 쇠퇴한다. 번식률Birth Rate $b$ 와 사망률Death Rate $d$ 의 차 $r:=b-d$ 로 정의되기도 한다. 설명 인구 동역학Population Dynamics은 동역학이 수리생물</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 유전체와 유전자</title>
      <link>https://freshrimpsushi.github.io/posts/genome-and-gene-in-bioinformatics/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/genome-and-gene-in-bioinformatics/</guid>
      <description>정의 한 개체의 염기서열을 모두 모은 것을 유전체Genome라고 한다. 유전체의 일부를 차지하는 구간으로, 유전 형질의 단위가 되는 것을 유전자Gene라고 한다. 특히 진핵생물에서는 인트론과 엑손으로 이루어져있다. 설명 사실 genome에 대해 유전체라는 순화는 거의 쓰이지 않고, 게놈 혹은 지놈으로 부르는게 보통이다. 지놈과 유전자는, 특</description>
    </item>
    
    <item>
      <title>줄리아에서 움짤 찌는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-gif-animation-in-julia/</link>
      <pubDate>Sun, 27 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-gif-animation-in-julia/</guid>
      <description>코드 원래 생새우초밥집에서는 이보다는 훨씬 자세한 설명을 추가하는 편이지만, 줄리아에서 움짤을 찌는 게 얼마나 쉬운지를 강조하기 위해 가능한한 짧게 설명하도록 하겠다. 위와 같은 랜덤 워크를 시뮬레이션하는 건 둘째치더라도, 위와 같이 움짤로 만드는 것은 언어에 따라 아주 어렵고 힘들 수 있다. 그러나 줄리아에서는 @animate 매크로와 gif() 함수를 통해 어마어마하</description>
    </item>
    
    <item>
      <title>머신 러닝에서 벡터 행렬의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-for-vector-and-matrix-in-machine-learning/</link>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-for-vector-and-matrix-in-machine-learning/</guid>
      <description>스칼라 함수의 그래디언트: $$ \frac{ \partial f(\mathbf{w})}{ \partial \mathbf{w} } :=\nabla_{\mathbf{w}}f(\mathbf{w})=\begin{bmatrix} \frac{ \partial f(\mathbf{w})}{ \partial w_{1} },\frac{ \partial f(\mathbf{w})}{ \partial w_{2} },\cdots,\frac{ \partial f(\mathbf{w})}{ \partial w_{n} } \end{bmatrix}^{T} $$ 내적의 그래디언트 $f(\mathbf{w})=\mathbf{w}^{T}\mathbf{x}$라고 하면 $$ \begin{align*} \frac{ \partial f(\mathbf{w})}{ \partial \mathbf{w} } =\frac{ \partial (\mathbf{w}^{T}\mathbf{x})}{ \partial \mathbf{w} } &amp;amp;=\begin{bmatrix} \frac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{1} },\frac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{2} },\cdots,\frac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{n} } \end{bmatrix}^{T} \\ &amp;amp;= \begin{bmatrix} x_{1} &amp;amp; x_{2} &amp;amp; \cdots &amp;amp; x_{n} \end{bmatrix}^{T} \\ &amp;amp;= \mathbf{x} \end{align*} $$</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 인트론과 엑손</title>
      <link>https://freshrimpsushi.github.io/posts/intron-and-exon-in-bioinformatics/</link>
      <pubDate>Fri, 25 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/intron-and-exon-in-bioinformatics/</guid>
      <description>정의 진핵 생물의 DNA에서 실제로 단백질의 합성에 관여하는 부분을 엑손Exon, 그렇지 않은 부분을 인트론Intron이라고 한다. 설명 원핵 생물과 진핵 생물은 세포핵에 핵막이 있냐 없느냐로 구분되지만, 생명정보공학의 관점에서 중요한 차이점은 센트럴 도그마에 의해 mRNA가 전사되고 난 뒤의 스플라이싱Splicing이라는 과정이 있느</description>
    </item>
    
    <item>
      <title>수반 작용소의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-adjoint-operator/</link>
      <pubDate>Thu, 24 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-adjoint-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $H,K$가 힐베르트 공간이라고 하자. 유계 선형 작용소 $T : K \to H$ 에 대해 다음을 만족하는 $T^{\ast} : H \to K$ 를 $T$ 의 수반 작용소라고 한다. $$ \left&amp;lt; T \textbf{v} , \textbf{w} \right&amp;gt;_{H} = \left&amp;lt; \textbf{v} , T^{\ast} \textbf{w} \right&amp;gt;_{K},\quad \forall \textbf{v} \in K $$ 이때 수반 작용소는 다음의 성질을 갖는다. (a)** $T^{\ast}$ 는 선형이고 유계다. (b)** $\left( T^{\ast} \right)^{\ast} = T$ (c)** $\left\| T^{\ast} \right\| = \left\| T \right\| $ 증명 (a) Part 1. $</description>
    </item>
    
    <item>
      <title>R 파일 읽기나 경로 변경 시 Error: &#39;C:\U&#39; used without hex digits in character string starting &#39;C:\U&#39; 해결</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-fix-error-used-without-hex-digits-in-character-string-starting/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-fix-error-used-without-hex-digits-in-character-string-starting/</guid>
      <description>해결만을 위한다면 어떻게 수정하는지만 봐도 되는데, 원리를 알고 다시는 같은 에러를 겪고 싶지 않다면 모두 읽는 것을 추천한다. 에러 진단 가령 바탕화면에 위와 같이 exampe.csv 파일을 읽고싶다고 할 때, 다음과 같은 에러가 뜨는 경우가 있다. Error: &#39;\U&#39; used without hex digits in character string starting &amp;quot;&amp;quot;C:\U&amp;quot; 아무리 봐도 모든 경로에 문제가 없기 때문에 이런 저런 시도를 하다가 &amp;lsquo;바탕 화면&amp;rs</description>
    </item>
    
    <item>
      <title>염기서열의 상류와 하류</title>
      <link>https://freshrimpsushi.github.io/posts/upstream-and-downstream-of-nucleic-sequence/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/upstream-and-downstream-of-nucleic-sequence/</guid>
      <description>빌드업 1 염기서열의 방향은 위의 그림처럼 오탄당의 탄소 원자 위치에 따라 번호를 부여함으로써 나타낼 수 있다. RNA와 DNA는 구체적으로 3번 탄소 $3&#39;$와 5번 탄소 $5&#39;$가 인산에스터 결합Phosphodiester Bond을 형성함으로써 사슬 구조를 이룬다. 가령 네 개의 염기가 다음과 같이 탄소 위치와 함께 주어져 있다고 하자. $$ 3&amp;rsquo;C5&#39;</description>
    </item>
    
    <item>
      <title>놈 공간에서 무한 급수 스팬 토탈 시퀀스</title>
      <link>https://freshrimpsushi.github.io/posts/infinite-series-span-total-sequence-in-normed-space/</link>
      <pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/infinite-series-span-total-sequence-in-normed-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 놈 공간 $\left( V, \left\| \cdot \right\| \right)$가 주어졌다고 하자. $V$의 수열 $\left\{ \mathbf{v}_{k}\right\}_{k\in \mathbb{N}}$에 대해서 부분합을 다음과 같이 정의하자. $$ \mathbf{S}_{N} := \sum \limits_{k=1}^{N}\mathbf{v}_{k} $$ 부분합 $\mathbf{S}_{N}$의 극한이 $\mathbf{v} \in V$로 놈 수렴하면, 즉 아래의 식 $$ \lim \limits_{N\to \infty}\left\| \mathbf{v}-\sum \limits_{k=1}^{N}\mathbf{v}_{k} \right\|=0 $$ 을 만족하면 무한 급수 $\</description>
    </item>
    
    <item>
      <title>딥러닝의 수학적 근거, 시벤코 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cybenko-theorem/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cybenko-theorem/</guid>
      <description>정리 $\sigma$ 가 연속 시그모이달 함수라고 하면 $$ \displaystyle S := \left\{ G(x) = \sum_{k=1}^{N} \alpha_{k} \sigma \left( y_{k}^{T} x+ \theta_{k} \right) : y_{k} \in \mathbb{R}^{n} \land \alpha_{k} , \theta_{k} \in \mathbb{R} \land N \in \mathbb{N} \right\} $$ 는 $C\left( I_{n} \right)$ 에서 균등 조밀하다. 달리 말하자면, 모든 $f \in C \left( I_{n} \right)$ 과 $\varepsilon &amp;gt; 0$ 에 대해 다음을 만족하는 $G \in S$ 가 존재한다. $$ \left\| G - f \right\| &amp;lt; \varepsilon $$ 다음을 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 을 시그모이달 함수라 한다. $$ \sigma (t) \to \begin{cases} 1 &amp;amp; \text{as } t \to + \infty \\ 0 &amp;amp;</description>
    </item>
    
    <item>
      <title>내적 공간에서 0의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-zero-in-inner-product-space/</link>
      <pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-zero-in-inner-product-space/</guid>
      <description>정리 $\left( H, \left\langle \cdot,\cdot \right\rangle \right)$을 내적 공간이라고 하자. (a) 모든 $x\in H$에 대해서 다음이 성립한다. $$ \left\langle 0,x \right\rangle =0 $$ (b) 모든 $x\in H$에 대해서 아래의 식을 만족하는 $H$의 원소는 오직 $0$뿐이다. $$ \forall x\in H,\ \left\langle x,y \right\rangle =0 \implies y=0 $$ (c) $y,z \in H$라고 하자. 그리고 $$ \begin{equation} \left\langle x,y \right\rangle =\left\langle x,z \right\rangle, \quad \forall x\in H \end{equation} $$ 라고 가정하자. 그러면 다음이 성립한다. $$ y=z $$ 설명 이 글에서</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 코돈과 아미노산 유전 부호</title>
      <link>https://freshrimpsushi.github.io/posts/codon-amino-acid-genetic-code/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/codon-amino-acid-genetic-code/</guid>
      <description>정의 DNA의 염기 3개를 순서쌍으로 묶은 단위를 트리플렛 코드Triplet Code라 한다. 센트럴 도그마에 따라 전사된 mRNA의 트리플렛 코드를 코돈Codon이라 한다. 화학적으로 아미노기와 카복시기를 포함한 분자로, 단백질의 구성 단위를 아미노산Amino Acid이라 부른다. 코돈의 순열에 따라 아미노산의 대응관계를 유전 부호</description>
    </item>
    
    <item>
      <title>B-스플라인 스케일링 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/b-spline-scaling-equation/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/b-spline-scaling-equation/</guid>
      <description>공식 (a) B-스플라인 스케일링 방정식: 오더가 $m\in N$인 B-스플라인 $N_{m}$에 대해서 다음의 식이 성립한다. $$ \widehat{N_{m}}(2\gamma)=H_{0}(\gamma)\widehat{N_{m}}(\gamma),\quad \forall \gamma \in \mathbb{R} $$ 이때 $H_{0}$는 주기가 $1$인 함수이며 다음과 같다. $$ H_{0}(\gamma)=\left( \frac{1+e^{-2\pi i \gamma}}{2} \right)^{m} $$ 또한 $f$의 푸리에 변환 $\widehat{f}$의 정의는 다음과 같다. $$ \widehat{f}(\gamma):=\int _{-\infty} ^{\infty} f(x)e^{-2\pi i x \gamma}dx $$ (b) 중심 B-스플라인 스케일링 방정</description>
    </item>
    
    <item>
      <title>시그모이달 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-sigmoidal-function/</link>
      <pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-sigmoidal-function/</guid>
      <description>정의 다음을 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 을 시그모이달 함수Sigmoidal Function라 한다. $$ \sigma (t) \to \begin{cases} 1 &amp;amp; \text{as } t \to + \infty \\ 0 &amp;amp; \text{as } t \to - \infty \end{cases} $$ 정의에 대한 설명 시그모이달 함수의 정의에서 $0$ 이나 $1$ 이냐는 것은 사실 별로 중요하지 않고, 양이든 음이든 무한대로 갈 때 상수로 수렴한다는 것이 중요하다. 무한대가 아닌 곳에서 어떤 값을 가지</description>
    </item>
    
    <item>
      <title>중심 B-스플라인</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-properties-of-centered-b-splines/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-properties-of-centered-b-splines/</guid>
      <description>정의 $m\in \mathbb{N}$에 대해서, 중심 B-스플라인 $B_{m}$을 다음과 같이 정의한다. $$ B_{m}(x):= T_{-\frac{m}{2}}N_{m}(x)=N_{m}(x+{\textstyle \frac{1}{2}}) $$ 이때 $T$는 $L^{2}$ 함수의 트랜슬레이션이다. 다음과 같이 정의할 수도 있다. $$ B_{1}:= \chi_{[-1/2,1/2]},\quad B_{m+1}:=B_{m}*B_{1},\ m\in\mathbb{N} $$ 두 정의는 실제로 같은 함수를 의미한다. 여기서 핵심은 $B_{m}$을 우함수가 되게끔 정의했다는 것이다. B-스플라인에서와 같이 다음의 식</description>
    </item>
    
    <item>
      <title>내적은 연속 사상임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-inner-product-is-continuous-mapping/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-inner-product-is-continuous-mapping/</guid>
      <description>정리1 $\left( H, \left\langle \cdot,\cdot \right\rangle \right)$가 내적 공간이고 $\left\{ x_{n} \right\}$, $\left\{ y_{n} \right\}$는 각각 $x$, $y$로 수렴하는 $H$의 수열이라고 하자. 그러면 다음이 성립한다. $$ \left\langle x_{n},y_{n} \right\rangle \to \left\langle x,y \right\rangle \text{ as } n \to \infty $$ 극한이 내적 안팎을 드나들 수 있으므로 다음의 따름정리를 얻는다. 따름정리 $H$가 힐베르트 공간, $\left\{ \mathbf{v}_{k} \right\}_{k\in \N}$가 $H$의 수열, $\left\{ c_{k} \right\}_{k\in\mathbb{N}} \in \ell^{2}</description>
    </item>
    
    <item>
      <title>분자생물학의 중심원리</title>
      <link>https://freshrimpsushi.github.io/posts/central-dogma-of-molecular-biology/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/central-dogma-of-molecular-biology/</guid>
      <description>원리 분자생물학의 중심원리 혹은 센트럴 도그마Central Dogma란 유전 정보는 DNA에서 RNA로, RNA에서 단백질로 전달된다는 가설로써 다음과 같은 세 가지 현상으로 이루어져있다. 복제: DNA는 스스로 복제된다. 전사: DNA와 같은 정보를 담은 RNA가 만들어진다. 번역: RNA의 정보에 따라 단백질이 합성된다. 설명 센트럴</description>
    </item>
    
    <item>
      <title>B-스플라인의 정칙성</title>
      <link>https://freshrimpsushi.github.io/posts/regularity-of-b-splines/</link>
      <pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regularity-of-b-splines/</guid>
      <description>성질 $m=2,3,\dots$에 대해서, B-스플라인 $N_{m}$은 다음의 성질을 가진다. (a) $N_{m}\in C^{m-2}(\mathbb{R})$ (b) $k\in \mathbb{Z}$에 대해, 각각의 구간 $[k,k+1]$에서 $N_{m}$은 차수가 아무리 커봐야 $m-1$인 다항식이다. B-스플라인의 익스플리시트 공식 $$ N_{m}(x) = \frac{1}{(m-1)!}\sum \limits_{j=0}^{m} \left( -1 \right)^{j}\binom{m}{j}\left( x-j \right)_{+}^{m-1},\quad x\in \mathbb{R} $$ 이때 $$ f(x)_{+}:=\max \left( 0,f(x) \right) \quad \&amp;amp; \quad f(x)_{+}^{n}:=\left( f(x)_{+} \right)^{n}</description>
    </item>
    
    <item>
      <title>벡터 공간에서 볼록 집합 컨벡스 셋</title>
      <link>https://freshrimpsushi.github.io/posts/convex-set-in-vector-space/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convex-set-in-vector-space/</guid>
      <description>정의 벡터 공간 $V$의 부분 집합 $M$에 대해서 다음의 식이 성립하면 $M$을 볼록 집합convex set 이라고 한다. $$ \lambda x +(1-\lambda)y \in M,\quad \forall \lambda\in[0,1],\ \forall x,y \in M $$ 설명 위 수식을 말로 풀면 &#39;$M$이 컨벡스 셋이라는 말은 $M$에 포함된 어떤 두 벡터 사이에 있는 모든 벡터들도 다 $M$에 속한다&#39; 이다. 또한 $M$이 부분 공간이라면 덧셈과 스칼라곱에 대해서 닫혀있</description>
    </item>
    
    <item>
      <title>차별 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-discriminatory-function/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-discriminatory-function/</guid>
      <description>정의 모든 $y \in \mathbb{R}^{n}$ 과 $\theta \in \mathbb{R}$ 와 어떤 $\mu \in M \left( I_{n} \right)$ 에 대해 $$ \int_{I_{n}} \sigma \left( y^{T} x + \theta \right) d \mu (x) = 0 \implies \mu =0 $$ 를 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 를 차별적 함수Discriminatory Function라 한다. $I_{n} := [0,1]^{n}$ 는 $n$차원 유닛 큐브로써, $n$ 개의 단위폐구간 $[0,1]$ 에 데카르트 곱을 취한 것이다. $M \left( I_{n} \right)$ 는 $I_{n} := [0,1]^{n}$ 에서 정의되는 부호 유한 정칙 보렐 측도의 집합</description>
    </item>
    
    <item>
      <title>B-스플라인의 익스플리시트 공식</title>
      <link>https://freshrimpsushi.github.io/posts/explicit-formula-for-the-b-splines/</link>
      <pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/explicit-formula-for-the-b-splines/</guid>
      <description>공식 함수 $f: \mathbb{R}\to \mathbb{R}$에 대해서 $$ f(x)_{+}:=\max \left( 0,f(x) \right) $$ 이라고 하자. 즉, $f_{+}$는 $f$의 함숫값이 $0$보다 작은 부분을 모두 $0$으로 바꾼 함수이다. 또한 $$ f(x)_{+}^{n}:=\left( f(x)_{+} \right)^{n} $$ 라고 정의하자. 그러면 각각의 $m=2,3,\dots$에 대해서 B-스플라인 $N_{m}$은 다음과 같이 표현될 수 있다. $$ N_{m}(x) = \frac{1}{(m-1)!}\sum \limits_{j=0}^{m} \left( -1 \right)^{j}\binom{m}{j}\left( x-j \right)_{+}^{m-1},\quad x\in \mathbb{R}</description>
    </item>
    
    <item>
      <title>정칙 측도</title>
      <link>https://freshrimpsushi.github.io/posts/regular-measure/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regular-measure/</guid>
      <description>정의: 측도의 정칙성 1 $\mu$ 가 가측 공간 $(X, \Sigma)$ 에서 정의된 측도라고 하자. $\mu$ 에 대해 가측 집합 $A \in \Sigma$ 가 다음을 만족하면 내적 정칙Inner Regular이라 한다. $$ \mu (A) = \sup \left\{ \mu (F) : F \subset A, F \in \Sigma \text{ is compact} \right\} $$ $\mu$ 에 대해 가측 집합 $A \in \Sigma$ 가 다음을 만족하면 외적 정칙Outer Regular이라 한다. $$ \mu (A) = \inf \left\{ \mu (G) : G \supset A, G \in \Sigma \text{ is open} \right\} $$</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서 푸리에 계수 푸리에 급수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-coefficient-fourier-series-in-hilbert-space/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-coefficient-fourier-series-in-hilbert-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $H$를 힐베르트 공간, $\left\{ u_{\alpha} \right\}_{\alpha\in A}$를 $H$의 정규직교 시스템이라고 하자. 그러면 고정된 $x\in H$에 대해서 복소 함수 $\hat{x} :A\to \mathbb{C}$를 다음과 같이 정의하자. $$ \hat{x}(\alpha)=\left\langle x,u_{\alpha} \right\rangle $$ 이때 위의 값들을 가리켜 $x$의 $\left\{ u_{\alpha} \right\}$에 대한 푸리에 계수Fourier coefficients 라고 한다.</description>
    </item>
    
    <item>
      <title>B-스플라인의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transform-of-b-splines/</link>
      <pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transform-of-b-splines/</guid>
      <description>공식 오더가 $m \in \mathbb{N}$인 B-스플라인 $N_{m}$의 푸리에 변환은 다음과 같다. $$ \widehat{N_{m}}(\gamma)=\left( \frac{1-e^{-2\pi i\gamma}}{2\pi i \gamma} \right)^{m} $$ 이때 $f$의 푸리에 변환 $\widehat{f}$의 정의는 다음과 같다. $$ \widehat{f}(\gamma):=\int _{-\infty} ^{\infty} f(x)e^{-2\pi i x\gamma}dx $$ 설명 B-스플라인, 푸리에 변환, 컨볼루션의 성질을 이용하여 어렵지 않게 계산할 수 있다. 증명 우선 $N_{1}$의 푸리에 변</description>
    </item>
    
    <item>
      <title>내적 공간에서 직교성, 직교 집합, 정규 직교 집합</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-and-orthonormal-system-in-hilbert-space/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-and-orthonormal-system-in-hilbert-space/</guid>
      <description>정의 $\left( V, \left\langle \cdot, \cdot \right\rangle \right)$를 내적 공간이라고 하자. 두 원소 $\mathbf{u}, \mathbf{v}\in V$가 $\left\langle \mathbf{u}, \mathbf{v} \right\rangle =0$을 만족하면 $\mathbf{u}$와 $\mathbf{v}$는 서로 직교orthogonal 한다고 하고 다음과 같이 표기한다. $$ \mathbf{u} \perp \mathbf{v} $$ $V$의 원소들의 집합 $\left\{ \mathbf{v}_{k} \right\}_{k\in \mathbb{N}}$이 다음의 식을 만족하면 직교 시스템ort</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 주요 염기와 염기쌍</title>
      <link>https://freshrimpsushi.github.io/posts/canonical-base-and-pair/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/canonical-base-and-pair/</guid>
      <description>정의 다음의 다섯가지 염기를 주요 염기Canonical Base라고 한다. 퓨린 염기: 아데닌Adenin $A$, 구아닌Guanine $G$ 피리미딘 염기: 사이토신Cytosine $C$, 티민Thymine $T$, 유라실Uracil $U$ 설명 티민은 DNA에서만 사용되며, 유라실은 RNA에서만 사용된다. 따라서 데이터에서 $T$ 와 $U$ 중 어느 것이 쓰이는</description>
    </item>
    
    <item>
      <title>B-스플라인의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-b-splines/</link>
      <pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-b-splines/</guid>
      <description>성질 오더가 $m\in \mathbb{N}$인 B-스플라인은 다음과 같은 성질을 만족한다. (a) $\mathrm{supp}N_{m}=[0,m]$ $\text{and}$ $N_{m}(x)&amp;gt;0 \text{ for } x\in(0,m) $ (b) $\displaystyle \int _{-\infty} ^{\infty} N_{m}(x)dx=1$ (c) $m\ge 2$에 대해서 아래의 식이 성립한다. $$ \begin{equation} \sum \limits_{k \in \mathbb{Z}} N_{m}(x-k)=1,\quad \forall x\in \mathbb{R} \label{eqc} \end{equation} $$ (c&#39;) $m=1$일 때, 위 식은 $x\in \mathbb{R}\setminus \mathbb{Z}$에 대해서 성립한다. 설명 (c) 는 다시 말해 $\left\{ N_{m}(x-k) \right\}_{k}$가 단위 분할이라는 뜻</description>
    </item>
    
    <item>
      <title>다변수 함수의 컨볼루션</title>
      <link>https://freshrimpsushi.github.io/posts/convolution-of-multi-variable-function/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convolution-of-multi-variable-function/</guid>
      <description>정의 $f,g:\mathbb{R}^{n}\to \mathbb{C}$이고 $\mathbf{x},\mathbf{y} \in \mathbb{R}^{n}$이라고 하자. 그러면 두 다변수 함수의 컨볼루션은 다음과 같다. $$ f \ast g(\mathbf{x})=\int f(\mathbf{y})g(\mathbf{x}-\mathbf{y})d\mathbf{y} $$ 이때 위의 적분은 다변수 함수의 적분이다. 성질 다변수 함수의 컨볼루션도 일변수 함수의 컨볼루션이 만족하는 좋은 성질들을 그대로 만족한다. (a) 교환법칙 $$ f \ast g = g \ast f $$ (b) 분배법칙 $$ f \ast (g+h)=f \ast</description>
    </item>
    
    <item>
      <title>라살 불변 원리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lasalle-invariance-principle/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lasalle-invariance-principle/</guid>
      <description>원리 빌드업 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 플로우 $\phi_t \left( \cdot \right)$ 하에서의 컴팩트 양불변집합을 $\mathcal{M} \subset \mathbb{R}^{n}$ 이라 하자. $\mathcal{M}$ 에서 랴푸노프 함수 $V : \mathcal{M} \to \mathbb{R}$ 가 정의되어 있다고 할 때, 다음의 두 집합을 생각해보자. $$ E := \left\{ x \in \mathcal{M} : V&#39;(x) = 0 \right\} $$ 이 $E$ 에 대해 다음과 같이 정의된 집합 $M$ 을 양불변부</description>
    </item>
    
    <item>
      <title>다변수 함수의 적분</title>
      <link>https://freshrimpsushi.github.io/posts/integral-of-multi-variable-function/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integral-of-multi-variable-function/</guid>
      <description>정의1 $I^{k}$가 k-cell이고, $\mathbf{x} \in I^{k}$라고 하자. $$ \mathbf{x} = (x_{1},\dots,x_{k}),\quad a_{i} \le x_{i} \le b_{i} (i=1,\dots,k) $$ $f: I^{k} \to \mathbb{R}$가 연속이라고 하자. 그러면 적분가능하므로 $f=f_{k}$로 두고, $f_{k-1} : I^{k-1} \to \mathbb{R}$을 다음과 같이 정의하자. $$ f_{k-1} (x_{1}, \dots, x_{k-1}) = \int_{a_{k}}^{b_{k}} f_{k}(x_{1}, \dots, x_{k}) dx_{k} $$ 그러면 라이프니츠 룰에 의해서 $f_{k-1}$</description>
    </item>
    
    <item>
      <title>어트랙팅 셋의 베이신</title>
      <link>https://freshrimpsushi.github.io/posts/basin-of-attracting-set/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/basin-of-attracting-set/</guid>
      <description>정의 1 공간 $X$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $\phi(t, \cdot)$ 은 벡터 필드 $x&#39; = f(x)$ 의 플로우, $g^{n}$ 는 맵 $g$ 를 $n$ 번 취한 맵을 나타내도록 하자.다음과 같이 정의된 집합들을 어트랙팅 셋 $A$ 의 베이신Basin이라고 한다. Vector Field $$\displaystyle \bigcup_{t \le 0} \phi ( t, U )$$ Map $$\displaystyle \bigcup_{n \le 0} g^{n} ( U )$$ 설명 베이신은 우리에게 익숙한 단어가 아</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 염기서열</title>
      <link>https://freshrimpsushi.github.io/posts/nucleic-sequence-in-bioinformatics/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/nucleic-sequence-in-bioinformatics/</guid>
      <description>빌드업 화학적 합성에 의해 단위체가 반복되어 연결된 고분자를 중합체Polymer라고 한다. 인산Phosphoric Acid은 무기 산소산의 일종으로, 화학식은 $H_{3}PO_{4}$이다. 5개의 탄소 원자를 갖는 단당류를 오탄당Pentose이라 한다. 유전 정보의 기본단위로써 기능하는 분자를 질소 염기Nitrogenou</description>
    </item>
    
    <item>
      <title>컨볼루션의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-convolution/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-convolution/</guid>
      <description>정리 컨볼루션은 다음과 같은 성질을 만족한다. (a) 교환법칙 $$ f \ast g = g \ast f $$ (b) 분배법칙 $$ f \ast (g+h) = f \ast g + f \ast h $$ (c) 결합법칙 $$ f \ast (g \ast h) = (f \ast g) \ast h $$ (d) 스칼라곱의 결합 법칙 $$ a(f \ast g)=(af\ast g)=(f\ast ag) $$ (e) 미분 $$ (f\ast g)&#39;=f&#39;\ast g=f\ast g&#39; $$ (f) 켤레 복소수 $$ \overline{f\ast g}=\overline{f} \ast \overline{g} $$ (g) 디랙 델타 함수 $$ f \ast \delta =f $$ 증명 (a) $$ \begin{align*} f\ast g(x)&amp;amp;=\int _{-\infty} ^{\infty} f(y)g(x-y)dy \\ &amp;amp;=\int_{\infty} ^{-\infty} f(x-z)g(z)(-dz) \\ &amp;amp;=\int_{-\infty} ^{\infty} f(x-z)g(z)dz \\ &amp;amp;=\int_{-\infty} ^{\infty} g(z)f(x-z)dz \\ &amp;amp;=g\ast f(x) \end{align*} $$ 두번</description>
    </item>
    
    <item>
      <title>동역학에서의 어트랙터</title>
      <link>https://freshrimpsushi.github.io/posts/attractor-in-dynamics/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/attractor-in-dynamics/</guid>
      <description>빌드업 공간 $X$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $\phi(t, \cdot)$ 은 벡터 필드 $x&#39; = f(x)$ 의 플로우, $g^{n}$ 는 맵 $g$ 를 $n$ 번 취한 맵을 나타내도록 하자. 넌원더링의 정의1 넌원더링Nonwandering한 점 $x_{0} \in X$ 이 다음의 조건을 만족하면 넌원더링 포인트라 하고, 그 집합을 넌원더링 셋이라 한다. (V): $x_{0}$ 의 모든</description>
    </item>
    
    <item>
      <title>푸리에 변환의 여러 정의와 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/various-definitions-and-notation-of-fourier-transform/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/various-definitions-and-notation-of-fourier-transform/</guid>
      <description>설명1 푸리에 변환의 정의와 표기법은 저자의 필요와 취향에 따라 다양하게 나타난다. 따라서 교재, 강의, 논문 등에서 푸리에 변환을 다루기 전에 정의와 표기법을 확실하게 못 박아두니 그 부분을 잘 읽어봐야한다. 제일 중요한 것은 본질적으로 다 같다는 것 이므로 노테이션에 크게 집중하지 말자. 본 문서에서는 각각의 정의에 어떤 장단점과 차이가 있는지 소개한</description>
    </item>
    
    <item>
      <title>플랜체렐 정리</title>
      <link>https://freshrimpsushi.github.io/posts/the-plancherel-theorem/</link>
      <pubDate>Mon, 30 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-plancherel-theorem/</guid>
      <description>정리 모든 $f,g \in L^{2}$에 대해서 다음의 식이 성립한다. $$ \begin{align} \langle \hat{f},\hat{g} \rangle &amp;amp;=2 \pi \left\langle f,g \right\rangle \label{eq1} \\ \| \hat{f} \|^{2} &amp;amp;= 2\pi \| f \| ^{2} \label{eq2} \end{align} $$ 설명 $f$의 푸리에 변환을 정의하는 과정을 보면 $f$가 $L^{1}$함수여야하고, $L^{1}$함수이기만 하면 된다. 하지만 우리는 $L^{1}$공간 뿐 아니라 $L^{2}$공간에서도 푸리에 변환을 자유자재로 쓸 수</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 DNA, RNA, 염색체</title>
      <link>https://freshrimpsushi.github.io/posts/dna-rna-chromosome-in-bioinformatics/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dna-rna-chromosome-in-bioinformatics/</guid>
      <description>빌드업 화학적 합성에 의해 단위체가 반복되어 연결된 고분자를 중합체Polymer라고 한다. 인산Phosphoric Acid은 무기 산소산의 일종으로, 화학식은 $H_{3}PO_{4}$이다. 5개의 탄소 원자를 갖는 단당류를 오탄당Pentose이라 한다. 유전 정보의 기본단위로써 기능하는 분자를 질소 염기Nitrogenou</description>
    </item>
    
    <item>
      <title>슈바르츠 공간에서의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-schwartz-space/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-schwartz-space/</guid>
      <description>정의 $\left\{ \phi_{n} \right\}$을 슈바르츠 공간에서의 수열이라고 하자. 만약 모든 멀티 인덱스 $\alpha$, $\beta$에 대해서 수열 $\left\{ \mathbf{x}^{\beta}D^{\alpha}\phi_{n}(\mathbf{x}) \right\}$이 $0$으로 균등 수렴하면 $\left\{ \phi_{n} \right\}$이 $0$으로 수렴한다고 정의하고 다음과 같이 표기한다. $$ \phi_{n} \overset{\mathcal{S}}{\to} 0 $$ 설명 위 정의를 일반화하여 $\left\{ \phi_{n}-\phi \right\}$가 $0$으로 수렴하면</description>
    </item>
    
    <item>
      <title>테스트 함수 공간은 슈바르츠 공간의 진 부분집합임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-test-functions-space-is-proper-subset-of-schwartz-space/</link>
      <pubDate>Sat, 28 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-test-functions-space-is-proper-subset-of-schwartz-space/</guid>
      <description>정리1 $\mathcal{D}$가 테스트 함수 공간, $\mathcal{S}$가 슈바르츠 공간이라고 하자. 그러면 다음의 식이 성립한다. $$ \mathcal{D} \subsetneq \mathcal{S} $$ 증명 우선 모든 테스트 함수가 슈바르츠 공간에 속함을 보인 뒤, 슈바르츠 함수 중에서 테스트 함수가 아닌 예를 보임으로써 증명한다. 증명 슈바르츠 함수 다음의 두 조건을 만족하는 $\phi$를</description>
    </item>
    
    <item>
      <title>자율 시스템의 오메가 리미트 셋</title>
      <link>https://freshrimpsushi.github.io/posts/omega-limit-set-of-autonomous-system/</link>
      <pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/omega-limit-set-of-autonomous-system/</guid>
      <description>정의 거리 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 이 벡터 필드의 플로우 $\phi ( t, x )$ 와 한 점 $x_{0} \in X$ 에 대해, $t_{i} \to \infty$ 일 때 $$ \phi \left( t_{i} , x_{0} \right) \to x $$ 을 만족하는 시간의 시퀀스 $\left\{ t_{i} \right\} \subset \mathbb{R}$ 이 존재하면 $ x \in X$ 를 $x_{0}$ 의 오메가 리미트 포인트라 한다. $x_{0}$ 의 오메가 리미트 포인트의 집합을 $x_{0}$ 의 오메가 리</description>
    </item>
    
    <item>
      <title>초함수 컨볼루션 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/distribution-convolution-convergence-theorem/</link>
      <pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distribution-convolution-convergence-theorem/</guid>
      <description>정리1 $\phi$가 $\int_{\mathbb{R}^{n}}\phi(\mathbf{x})d\mathbf{x}=1$을 만족하는 테스트 함수라고 하자. 그리고 $\phi_{\epsilon}(\mathbf{x})=\epsilon^{-n}\phi(\epsilon^{-1}\mathbf{x}</description>
    </item>
    
    <item>
      <title>초함수 컨볼루션 보조정리</title>
      <link>https://freshrimpsushi.github.io/posts/distributional-convolution-lemma/</link>
      <pubDate>Thu, 26 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distributional-convolution-lemma/</guid>
      <description>정리1 $F$가 초함수, $\phi,\psi$가 테스트 함수라고 하자. 그러면 $F \ast \phi$는 실수 공간에서 정의된 함수이며 국소 적분 가능하다. 따라서 $F \ast \phi$에 대응되는 정칙 초함수 $T$가 다음과 같이 존재한다. $$ T_{F \ast \phi}(\psi)=F(\tilde{\phi} \ast \psi) $$ 여기서 $\tilde{\phi}(x)=\phi(-x)$이다. 설명 &amp;lsquo;초함</description>
    </item>
    
    <item>
      <title>균등 수렴은 연속성을 보존한다</title>
      <link>https://freshrimpsushi.github.io/posts/uniform-convegence-and-continuity/</link>
      <pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniform-convegence-and-continuity/</guid>
      <description>정리1 거리공간 $E$위에서 함수열 $\left\{ f_{n} \right\}$이 $f$로 균등 수렴한다고 하자. $$ f_{n} \rightrightarrows f $$ 만약 각각의 $f_{n}$이 $x \in E$에서 연속이면 $f$도 $x$에서 연속이다. 즉 다음이 성립한다. $$ \lim \limits_{t \to x }f_{n}(t)=f_{n}(x) \implies \lim \limits_{t \to x }f(t)=f(x) $$ 혹은 $$ \lim \limits_{t\to x}\lim \limits_{n\to \infty}f_{n}(t)=\lim \limits_{n\to \infty}\lim \limits_{t\to x}f_{n}(t) $$ 증명 $\varepsilon &amp;gt;0$이 주어졌다고 하자. $\left\{ f_{n} \right\}$이 $</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 원핵 생물과 진핵 생물</title>
      <link>https://freshrimpsushi.github.io/posts/prokaryotes-and-eukaryotes/</link>
      <pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prokaryotes-and-eukaryotes/</guid>
      <description>정의 핵막이 없는 생물을 원핵 생물Prokaryotes이라 한다. 핵막이 있는 핵으로 이루어진 생물을 진핵 생물Eukaryotes이라 한다. 설명 진핵 생물에서는 유전 물질을 지니는 부분인 세포핵Nucleus과 각종 대사가 일어나는 세포질Cytoplasm이 핵막Nuclear Envelope에 의해 구분되지만 원핵 세포는 핵양체</description>
    </item>
    
    <item>
      <title>초함수의 컨볼루션, 실수에서 정의된 함수로서의 초함수</title>
      <link>https://freshrimpsushi.github.io/posts/colvolution-of-distribution/</link>
      <pubDate>Tue, 24 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/colvolution-of-distribution/</guid>
      <description>빌드업1 초함수론의 목적은 나이브하게 정의된 디랙 델타 함수같은 것들을 수학적으로 엄밀하게 정의하는 것이다. 따라서 함수공간에서 정의된 초함수를 실수공간에서 정의되는 함수로 다룰 수 있게 해야 한다. 먼저 초함수의 미분, 트렌슬레이션 등이 어떻게 정의됐는지 생각해보자. 초함수는 정의역이 함수공간이라 미분 등을 기존의 개념대로 정의할 수 없기 때</description>
    </item>
    
    <item>
      <title>균등수렴할 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-uniform-convergence/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-uniform-convergence/</guid>
      <description>정리1 $E\subset \mathbb{R}$에서 정의된 함수열 $\left\{ f_{n} \right\}$이 주어졌다고 하자. 아래의 두 조건은 동치이다. $\left\{ f_{n} \right\}$이 $E$위에서 균등수렴한다. 모든 $\varepsilon&amp;gt;0$에 대해서 아래의 식을 만족시키는 자연수 $N$이 존재한다. $$ \begin{equation} \quad m,n\ge N,\ x\in E \implies \left| f_{n}(x)-f_{m}(x) \right| \le \varepsilon \label{eq1} \end{equation} $$ 다시 말해 모든 $x \in</description>
    </item>
    
    <item>
      <title>줄리아에서 거리 행렬 계산하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-calculate-a-distance-matrix-in-julia/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-calculate-a-distance-matrix-in-julia/</guid>
      <description>개요 거리 행렬Distance Matrix은 파티클 다이나믹스Particle Dynamics 및 무빙 에이전트Moving Agent 기반 시뮬레이션 등에 흔히 사용되나, 막상 찾아보면 딱 정리된 함수로는 없고 직접 계산하는 코드를 짜려면 막막한 게 보통이다. 줄리아에서는 pairwise() 와 Distances 패키지의 Euclidean() 함수를 사용해서 위와 같이 손쉽게 거리 행렬을 계산할 수 있다. 1 dims 옵션을</description>
    </item>
    
    <item>
      <title>초함수의 미분은 약 수렴에 대해서 연속이다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-differentiation-is-continuous-wrt-weak-convergence/</link>
      <pubDate>Sun, 22 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-differentiation-is-continuous-wrt-weak-convergence/</guid>
      <description>정리1 초함수의 미분은 약 수렴에 대해서 연속이다. 다시말해 $T_{k}$가 $T$로 약 수렴하면 $\partial ^{\alpha} T_{k}$가 $\partial ^{\alpha}T$로 약 수렴한다. $$ T_{k} \to T \quad \text{weakly} \implies \partial ^{\alpha} T_{k}\to \partial ^{\alpha}T \quad \text{weakly} $$ 이때 $\alpha$는 임의의 멀티 인덱스이다. 설명 초함수의 미분이라는 오퍼레이터가 약 수렴에 대해서 연속일 동치 조건을 만족한다는 의미이다.</description>
    </item>
    
    <item>
      <title>디랙 델타 초함수로 수렴하는 초함수</title>
      <link>https://freshrimpsushi.github.io/posts/distribution-converging-to-dirac-delta/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distribution-converging-to-dirac-delta/</guid>
      <description>정리1 $f$가 $\int_{\mathbb{R}^{n}} f(\mathbf{x})d\mathbf{x}=1$를 만족하는 함수라고 하자. 그리고 $f_{\epsilon}(\mathbf{x})=\dfrac{ 1 }{ \epsilon^{n} }f\left( \dfrac{\mathbf{x}}{\epsilon} \right)$라고 하자. 그러면 $f$에 대응되는 정칙 초함수 $T_{\epsilon}=T_{f_{\epsilon}}$은 디랙 델타 초함수로 약 수렴한다. 즉 다음이 성립한다. $$ \lim \limits_{\epsilon \to 0} T_{\epsilon}=\delta $$ 증명 $</description>
    </item>
    
    <item>
      <title>푸앙카레 재귀 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-poincare-recurrence-theorem/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-poincare-recurrence-theorem/</guid>
      <description>정리 유클리드 공간에서 정의된 다차원 맵 $g : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 이 단사면서 연속이고 $D \subset \mathbb{R}^{n}$ 이 컴팩트 불변 집합, 다시 말해 $g(D) = D$ 라고 하자. 임의의 $\overline{x} \in D$ 의 임의의 근방을 $U$ 라고 하면 어떤 $n \in $ 에 대해 $g^{n} (x) \in U$ 가 되게끔 하는 $x \in U$ 가 존재한다. 설명 스테이트먼트는 단순한데, $D$ 가 컴팩트 불변 집합이면 그 안에서 $U$ 를 잡았을 때 $U$ 에서 잠깐은 벗어날 수 없어도 결국</description>
    </item>
    
    <item>
      <title>머신 러닝에서 선형 회귀</title>
      <link>https://freshrimpsushi.github.io/posts/linear-regression-in-machine-learning/</link>
      <pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-regression-in-machine-learning/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 머신 러닝에서 선형 회귀 란 주어진 작업에 대한 실제 함수를 가장 잘 근사하는 선형 함수를 찾는 알고리즘이다. 어떤 트레이닝 샘플 $D=\left\{ (\mathbf{x}_{1},y_{1}),\dots,(\mathbf{x}_{n},y_{n }) \right\}$가 있다고 하자. 이때 인풋 $x_{i}$에 대해서 아웃풋 $y_{i}$를 주는 함수를 $f$라고 하자. $$ f(\mathbf{x}_{i})=y_{i}\quad (i=1,\dots,n) $$ 즉 $f$는 모든 데이터 $\</description>
    </item>
    
    <item>
      <title>머신 러닝에서 벡터 행렬 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/vector-and-matrix-notation-in-machine-learning/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vector-and-matrix-notation-in-machine-learning/</guid>
      <description>선형대수를 잘 알지 못하거나, 잘 알아도 실제로 행렬 계산을 많이 해보지 않은 경우에 머신 러닝을 공부하면서 벡터와 행렬 표기법 때문에 힘들 수 있다. 해당 값이 스칼라인지, 벡터인지, 행렬인지 잘 구분해야하는데 실제로 손 계산을 해보면 익숙해지는데에 도움이 된다. 본 글의 표기법은 비숍의 &#39; 패턴 인식과 기계 학습1 &amp;lsquo;을 참고했다. 벡터 주로</description>
    </item>
    
    <item>
      <title>줄리아에서 빈 배열 만드는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-empty-array-in-julia/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-empty-array-in-julia/</guid>
      <description>코드 크기 지정 julia&amp;gt; empty = Array{Float64, 2}(undef, 3, 4) 3×4 Array{Float64,2}: 3.39519e-313 3.18299e-313 4.66839e-313 1.061e-313 4.03179e-313 5.51719e-313 1.6976e-313 4.24399e-314 2.97079e-313 4.66839e-313 7.00259e-313 5.0e-324 위의 코드를 실행시키면 빈 배열이 만들어진다. 간혹 1.76297e-315처럼 이상한 값이 들어가는 것처럼 보이기도 하지만 이는 0에 아주 가까운 값으로써 초기화엔 큰 문제가 없다. Array{X, Y}(undef, ...)는 자료형 X로 Y차원 배열을 자료형에 해당하는 미정값으로 사이즈 ...만큼 채운 배</description>
    </item>
    
    <item>
      <title>스무스 함수에 대한 푸리에 역변환 정리</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-inversion-theorem-for-smooth-function/</link>
      <pubDate>Wed, 18 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-inversion-theorem-for-smooth-function/</guid>
      <description>정리 $f$가 $\mathbb{R} $위에서 적분 가능하고 조각마다 스무스하다고 하자. 그러면 아래의 식이 성립한다. $$ \lim \limits_{r\to \infty} \frac{1}{2\pi} \int_{-r}^{r}e^{i\xi x} \hat{f}(\xi)d\xi= \frac{1}{2}\big[f(x-)+f(x+) \big],\quad \forall x\in \mathbb{R} $$ 이때 $f(x+)$, $f(x-)$는 각각 $f$의 $x$에서의 우극한, 좌극한이다. 설명 푸리에 역변환 정리는 컷오프 펑션을 사용하는 대신에 $f$에 대한 조건이 비교적 약했다. 위 정리는 푸리에 역변환 정리의 또 다른 형태이다</description>
    </item>
    
    <item>
      <title>동역학에서의 리우빌 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-dynamics/</link>
      <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-dynamics/</guid>
      <description>정리 유클리드 공간 $\mathbb{R}^{n}$ 과 함수 $f : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 이 벡터 필드의 플로우 $\phi_t ( \cdot )$ 과 영역 $D_{0} \subset \mathbb{R}^{n}$ 에 대해 $D_{t} := \phi_{t} \left( D_{0} \right)$ 를 플로우에 따라 시간 $t$가 지나 옮겨진 영역, 그 볼륨을 $V(t) \equiv V \left( D_{t} \right)$ 와 같이 나타내자. 만약 $\nabla \cdot f = 0$ 면 모든 $D_{0} \subset \mathbb{R}^{n}$ 와 $t \in \mathbb{R}$ 에 대해 다음이 성립한다. $$ V \left( D_{t}</description>
    </item>
    
    <item>
      <title>컨볼루션 놈 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/convolution-norm-converge-theorem/</link>
      <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convolution-norm-converge-theorem/</guid>
      <description>정리 함수 $g \in L^{1}$가 유계이고 $\int_{\mathbb{R}}g(y)dy=1$을 만족한다고 하자. 만약 $f\in L^{2}$이고, $f$와 $g$의 컨볼루션 $f \ast g$가 모든 $x\in \mathbb{R}$에 대해서 잘 정의되면 $f \ast g_{\epsilon}$은 $f$로 놈 수렴한다. $$ \begin{equation} \lim \limits_{\epsilon \to 0} \left\| f \ast g_{\epsilon} -f \right\| = 0 \label{eq1} \end{equation} $$ 이때</description>
    </item>
    
    <item>
      <title>곡선 좌표계에서 스칼라 함수의 라플라시안</title>
      <link>https://freshrimpsushi.github.io/posts/laplacian-of-a-scalar-function-in-a-cuvilinear-coordinate-system/</link>
      <pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplacian-of-a-scalar-function-in-a-cuvilinear-coordinate-system/</guid>
      <description>정리 곡선 좌표계에서 스칼라 함수 $f=f(q_{1},q_{2},q_{3})$의 라플라시안은 다음과 같다. $$ \nabla ^{2}f= \frac{1}{h_{1}h_{2}h_{3}}\left[\frac{ \partial }{ \partial q_{1} } \left( \frac{h_{2}h_{3}}{h_{1}} \frac{ \partial f}{ \partial q_{1}}\right)+\frac{ \partial }{ \partial q_{2} } \left( \frac{h_{1}h_{3}}{h_{2}} \frac{ \partial f}{ \partial q_{2}}\right)+\frac{ \partial }{ \partial q_{3} } \left( \frac{h_{1}h_{2}}{h_{3}} \frac{ \partial f}{ \partial q_{3}}\right) \right] $$ 공식 직교 좌표계: $$ h_{1}=h_{2}=h_{3}=1 $$ $$ \nabla ^2 f= \frac{ \partial^2 f}{ \partial x^2 }+\frac{ \partial^2 f}{ \partial y^2}+\frac{ \partial^2 f}{ \partial z^2} $$ 원통 좌표계: $$ h_{1}=1,\quad h_{2}=\rho,\quad h_{3}=1 $$ $$ \nabla ^{2}f= \frac{1}{\rho} \frac{ \partial }{ \partial \rho }\left( \rho\frac{ \partial f}{ \partial \rho} \right)</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 스칼라 함수의 라플라시안</title>
      <link>https://freshrimpsushi.github.io/posts/laplacian-of-scalar-function-in-cartesian-coordinate-system/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplacian-of-scalar-function-in-cartesian-coordinate-system/</guid>
      <description>정의 3차원 스칼라 함수 $f=f(x,y,z)$의 그래디언트의 다이벌전스를 $f$의 라플라시안Laplacian이라 하고 $\nabla^{2}$로 표기한다. $$ \nabla ^{2} f := \nabla \cdot(\nabla f)= \frac{ \partial^{2} f}{ \partial x^{2} }+\frac{ \partial^{2} f}{ \partial y^{2}}+\frac{ \partial^{2} f}{ \partial z^{2}} $$ 설명 라플라시안이라는 이름은 프랑스 수학자 라플라스 에서 따온 것이다. $\nabla^{2}$라는 표현은 편의를 위</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability/</guid>
      <description>정의 1 확률변수 $X$ 와 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $X_{n}$ 이 $X$ 로 확률 수렴Convergence in Probability한다고 말하고, $X_{n} \overset{P}{\to} X$ 와 같이 나타낸다. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left| X_{n} - X \right| &amp;lt; \varepsilon \right] = 1 $$ 설명 확률 수렴의 조건은 수식 그대로 확률의 센스에서 수렴을 정의한 것으로, 쉽게 말해 $n$ 이 커지면 두 확률 변수</description>
    </item>
    
    <item>
      <title>컨볼루션 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/convolution-converge-theorem/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convolution-converge-theorem/</guid>
      <description>정리 함수 $g \in L^{1}$가 다음의 조건을 만족한다고 하자. $$ \begin{align*} \int_{\mathbb{R}}g(y)dy &amp;amp;= 1 \\ \int_{-\infty}^{0}g(y)dy &amp;amp;= \alpha \\ \int_{0}^{\infty}g(y)dy &amp;amp;=\beta \\ \alpha+\beta &amp;amp;= 1 \end{align*} $$ 그리고 $f$가 $\mathbb{R}$위에서 조각마다 연속이라고 하자. 그리고 $f$가 유계이거나 $g$가 임의의 구간 $[-a,a]$ 밖에서 $g=0$라고 하자. 즉, 합성곱 $f \ast g(x)$가 모든 $x\in \mathbb{R}$에 대해서 잘 정의된다</description>
    </item>
    
    <item>
      <title>자율 시스템의 보존량</title>
      <link>https://freshrimpsushi.github.io/posts/conservation-in-autonomous-system/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conservation-in-autonomous-system/</guid>
      <description>정의 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 주어진 시스템에 종속된 상수함수 $h : X \to \mathbb{R}$ 가 존재하면 이를 보존량이라 한다. 설명 물리학적, 즉 역학적인(mechanical) 센스에 익숙하다면 보존량이라는 개념은 전혀 낯설지 않을 것이다. 가령 이상적인 상황에서 연직 방향 반대로</description>
    </item>
    
    <item>
      <title>곡선의 도함수가 연속이면 길이를 잴 수 있는 곡선이다</title>
      <link>https://freshrimpsushi.github.io/posts/if-derivative-of-curve-is-continuous-then-curve-is-rectifiable/</link>
      <pubDate>Thu, 12 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-derivative-of-curve-is-continuous-then-curve-is-rectifiable/</guid>
      <description>정리1 만약 $\gamma ^{\prime}$이 구간 $[a,b]$에서 연속이면, $\gamma$는 길이를 잴 수 있는 곡선이고 다음의 식이 성립한다. $$ \Lambda (\gamma) = \int _{a} ^{b} \left| \gamma&#39;(t) \right| dt $$ 증명 Part 1. $P=\left\{ a=x_{0},\dots,x_{n}=b \right\}$를 구간 $[a,b]$의 임의의 분할이라고 하자. $a\le x_{i-1}&amp;lt;x_{i}\le b$라고 하면 다음이 성립한다. $$ \begin{align*} \left| \gamma(x_{i})-\gamma(x_{i-1}) \right| &amp;amp;= \left| \int_{x_{i-1}}^{x_{i}}\gamma &#39; (t)dt \right| \\ &amp;amp;\le \int_{x_{i-1}}^{x_{i}} \left| \gamma &#39; (t) \right|dt \end{align*} $$ 첫</description>
    </item>
    
    <item>
      <title>길이를 잴 수 있는 곡선</title>
      <link>https://freshrimpsushi.github.io/posts/rectifiable-curves/</link>
      <pubDate>Wed, 11 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rectifiable-curves/</guid>
      <description>정의1 연속 함수 $\gamma : [a,b] \to \mathbb{R}^{k}$를 $\mathbb{R}^{k}$에서의 곡선curve 혹은 간단히 $[a,b]$위의 곡선이라고 한다. 만약 곡선 $\gamma$가 일대일 함수이면 호arc라고 한다 만약 $\gamma(a)=\gamma(b)$이면 $\gamma$를 닫힌 곡선closed cur</description>
    </item>
    
    <item>
      <title>연속 사상 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-continuous-mapping-theorem/</link>
      <pubDate>Wed, 11 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-continuous-mapping-theorem/</guid>
      <description>정리 1 다음은 연속 사상 정리의 측도론적 서술이다. 거리 공간 $\left( S , d \right)$ 와 $\left( S&#39; , d&#39; \right)$ 에 대해 $g : S \to S&#39;$ 가 $C_{g} \subset S$ 에서 연속이라고 하자. $S$ 의 확률 원소 $X$ 에 대해 $P \left( X \in C_{g} \right) = 1$ 이면 $X$ 로 수렴하는 확률 원소의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 에 대해 다음이 성립한다. $$ X_{n} \overset{D}{\to} X \implies g \left( X_{n} \right) \overset{D}{\to} g(X) \\ X_{n} \overset{P}{\to} X \implies g \left( X_{n} \right) \overset{P}{\to} g(X) \\ X_{n} \overset{\text{a.s.}}{\to} X \implies g \left( X_{n} \right) \overset{\text{a.s.}}{\to} g(X) $$ $C_{g} \subset S$ 는 함수 $g$</description>
    </item>
    
    <item>
      <title>벡터값 함수의 적분</title>
      <link>https://freshrimpsushi.github.io/posts/integration-of-vector-valued-function/</link>
      <pubDate>Tue, 10 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integration-of-vector-valued-function/</guid>
      <description>정의1 $f_{1}$, $f_{2}$, $\dots$, $f_{k}$가 구간 $[a,b]$위에서 실수값을 갖는 함수라고 하자. 그리고 $\mathbf{f} : [a,b] \to \mathbb{R}^{k}$가 다음과 같다고 하자. $$ \mathbf{f}(x)=\left( f_{1}(x),\dots,f_{k}(x) \right),\quad x\in [a,b] $$ 이때 각각의 $f_{k}$가 구간 $[a,b]$에서 적분가능하면, $\mathbf{f}$의 적분을 다음과 같이 정의한다. $$ \int _{a} ^{b} \mathbf{f}dx = \left( \int _{a} ^{b}f_{1} dx, \dots, \int _{a} ^{b}f_{k}</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 다이벌전스</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-in-vector-field/</link>
      <pubDate>Mon, 09 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-in-vector-field/</guid>
      <description>정의 유클리드 공간에서 정의된 벡터 필드 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 을 $\textbf{f} = (f_{1} , \cdots , f_{n})$ 과 같이 나타내고 축의 방향을 $u_{1} , \cdots , u_{n}$ 이라고 할 때, $\textbf{f}$ 의 다이벌전스 를 다음과 같이 정의한다. $$ \text{div} \textbf{f} := \nabla \cdot \textbf{f} = \sum_{k=1}^{n} {{ \partial f_{k} } \over { \partial u_{k} }} $$ 설명 벡터 필드의 다이벌전스는 다음과 다음과 같이 한 점 $\textbf{v} \in \mathbb{R}^{n}$ 가 주어져 있을 때 그 점에서 벡터들이 모이는지, 퍼지는지에 대한 하나의 척도가 된</description>
    </item>
    
    <item>
      <title>부분적분법</title>
      <link>https://freshrimpsushi.github.io/posts/integration-by-parts/</link>
      <pubDate>Mon, 09 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integration-by-parts/</guid>
      <description>정리 1 $F$, $G$가 구간 $[a,b]$에서 미분가능하고, $F&#39;=f$, $G&#39;=g$가 적분가능하다고 하자. 그러면 다음의 식이 성립한다. $$ \begin{align*} \int _{a} ^{b} F(x)g(x)dx &amp;amp;= F(b)G(b)-F(a)G(a)-\int _{a} ^{b}f(x)G(x)dx \\ &amp;amp;= \left[ F(x)G(x) \right]_{a}^{b} -\int _{a} ^{b}f(x)G(x)dx \end{align*} $$ 설명 이 결과를 부분적분법이라 부른다. 그적미적[그냥 적분]- $\int$ 미분 적분으로 외우면 쉽다. 적분할 것은 양쪽에 그대로 적고, 미분할 것은 앞쪽에는 그냥 적고 뒷쪽에는 미</description>
    </item>
    
    <item>
      <title>해석학에서 미분적분학의 기본정리2</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-2-of-calculus-in-analysis/</link>
      <pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-2-of-calculus-in-analysis/</guid>
      <description>정리1 함수 $f$가 구간 $[a,b]$에서 리만 적분 가능하고, $F&#39;=f$을 만족하는 $[a,b]$에서 미분 가능한 함수 $F$가 존재한다고 하자. 그러면 다음이 성립한다. $$ \int_{a}^{b} f(x) dx= F(b)-F(a) $$ 설명 미분적분학의 기본정리2라는 이름으로 유명한 정리이다. 흔히 FTC2Funcamental Theorem of Calculus1라고 줄여 부른다. $f$의 정적분은 부정적분인 $F$</description>
    </item>
    
    <item>
      <title>로지스틱 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-a-logistic-function/</link>
      <pubDate>Sat, 07 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-a-logistic-function/</guid>
      <description>정의 1 로지스틱 함수란 미분 방정식의 해 $y&#39; = y(1-y)$ 로써, 다음과 같이 구해진다. $$ y(t) = {{ 1 } \over { 1 + e^{-t} }} $$ 설명 조금 더 일반적인 형태로써 $\displaystyle f(x) := {{ L } \over { 1 + e^{-k(x-x_{0})} }}$ 와 같은 꼴을 사용하기도 한다. 로지스틱 함수는 시그모이드 함수며, 쓰임새가 많아 동역학, 통계학, 딥러닝, 생물학 등 여러 분야에서 언급되기도 하는 함수다. 로지스틱? 문제는 도대체</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 볼륨</title>
      <link>https://freshrimpsushi.github.io/posts/volume-in-vector-field/</link>
      <pubDate>Thu, 05 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/volume-in-vector-field/</guid>
      <description>정의 유클리드 공간의 부분공간 $D \subset \mathbb{R}^{n}$ 의 볼륨 $V$ 는 직교좌표 $\textbf{u} = (u_{1}, u_{2}, \cdots , u_{n})$ 으로 나타낼 때 다음과 같이 정의된다. $$ V(D) = \int_{D} du_{1} du_{2} \cdots d u_{n} $$ $\textbf{u} \in \mathbb{R}^{n}$ 가 벡터 함수 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 의해 $\textbf{f} \left( \textbf{u} \right) = \left( f_{1} (\textbf{u}) , \cdots , f_{n} (\textbf{u}) \right)$ 와 같이 변환될 때, $D$ 의 볼륨 은 다음과 같다. $$ V(D) = \int_{D} \left| {{ \partial \textbf{f} (\textbf{u}) } \over { \partial \textbf{u} }} \right| d u_{1} d u_{2} \cdots d u_{n} $$ $\displaystyle \left| {{ \partial \textbf{f} (\textbf{u}) } \over { \partial \textbf{u} }} \right|$ 는 다음과 같이</description>
    </item>
    
    <item>
      <title>정칙 스튀름-리우빌 문제의 솔루션의 직교성</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-of-solutions-of-regular-sturm-liouville-problem/</link>
      <pubDate>Thu, 05 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-of-solutions-of-regular-sturm-liouville-problem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 서로 다른 $\lambda_{n}$, $\lambda_{m}$이 정칙 S-L 문제의 고유값이고 $u_{n}$, $u_{m}$이 각각의 고유값에 대응되는 실수값을 갖는 고유함수라고 하자. 그러면 $u_{n}$, $u_{m}$은 $L_{w}^{2}(a,b)$ 공간에서 서로 수직한다. 즉, $$ \int _{a} ^{b} u_{n}(x)u_{m}(x)r(x)dx=0 $$ 정칙 스튀름-리우빌 문제 $(\mathrm{Regular\ Sturm-Liouville\ problem})$미분 방정식 $(</description>
    </item>
    
    <item>
      <title>S-L 문제에서 고유값과 고유함수</title>
      <link>https://freshrimpsushi.github.io/posts/eigenvalue-and-eigenfunctions-for-s-l-problem/</link>
      <pubDate>Wed, 04 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eigenvalue-and-eigenfunctions-for-s-l-problem/</guid>
      <description>정의 만약 스튀름-리우빌 미분 방정식 $$ \begin{equation} \left[ p(x)u&#39;(x) \right]&#39;+\left[ q(x) +\lambda w(x) \right]u(x)=0 \label{SLeq} \end{equation} $$ 이 $0$이 아닌 솔루션 $u \in L_{r}^{2}(a,b)$를 가지면, $\lambda$를 고유값이라 하고 이에 대응하는 $u$를 고유함수라고 한다. 설명 여기에서 말하는 고유값이란 선형 대수학에서 말하는 그 고유값과 같다. 고유값이라 부르는 이유는 아래의 과정을 보면 이해할</description>
    </item>
    
    <item>
      <title>2차원 자율 시스템에선 혼돈이 일어나지 않는다  푸앙카레-벤딕슨 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-poincare-bendixson-theorem/</link>
      <pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-poincare-bendixson-theorem/</guid>
      <description>정리 $2$차원 매니폴드 $\mathcal{P}$ 와 함수 $f,g \in C^{r} \left( \mathcal{P} \right)$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x,y) \\ y&#39; = g(x,y) $$ $\mathcal{M}$ 이 벡터 필드의 유한한 수의 고정점을 가지는 양불변집합이라고 하면, $p \in \mathcal{M}$ 의 오메가 리미트 셋 $\omega (p)$ 은 다음 세가지 중 하나를 만족한다: (1): $\omega (p)$ 는 홑원소 집합이다. 즉, 단 하나의 고정점만을 포함한다. (2): $\omega (p)$ 는 닫</description>
    </item>
    
    <item>
      <title>가중 Lp 공간</title>
      <link>https://freshrimpsushi.github.io/posts/weighted-lp-space/</link>
      <pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weighted-lp-space/</guid>
      <description>정의1 다음과 같이 정의되는 함수 공간을 가중 $L^{p}$ 공간weighted $L^{p}$ space 혹은 구체적으로 $w$-가중 $L^{p}$ 공간 이라고 한다. $$ L_{w}^{p}(a,b):= \left\{ f : \mathbb{R}\to \mathbb{C}\ \big|\ \int_{a}^{b} \left| f(x) \right|^{p}w(x)dx &amp;lt;\infty \right\} $$ 이때 $w:\mathbb{R}\to[0,\infty)$를 가중 함수weight function라 한다. 설명 $L^{p}$ 공간을 일반화한 공간 중 하나이다. $w(x)=1$인 경우</description>
    </item>
    
    <item>
      <title>스튀름-리우빌 미분 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/sturm-liouville-differential-equation/</link>
      <pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sturm-liouville-differential-equation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $p\in$$C^{1}(\mathbb{R})$이고 $q,r\in C(\mathbb{R})$, $\lambda \in \mathbb{R}$이라고 하자. 아래와 같은 꼴의 미분 방정식을 스튀름-리우빌 미분 방정식 이라 한다. $$ \left[ p(x)u&#39;(x) \right]&#39;+\left[ q(x) +\lambda w(x) \right]u(x)=0 \tag{1} $$ 혹은 $$ p(x)u&#39;&#39;(x)+p&#39;(x)u&#39;(x)+\left[ q(x)+\lambda w(x) \right]u(x)=0 $$ 짧게 줄여서 &amp;lsquo;S-L 문제 &amp;lsquo;라고 부르기도 한다. 여기서 $w$는</description>
    </item>
    
    <item>
      <title>시그모이드 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-a-sigmoid-function/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-a-sigmoid-function/</guid>
      <description>정의 1 유계 미분가능 스칼라 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 이 모든 $x \in \mathbb{R}$ 에서 $\sigma &#39; (x) \ge 0$ 이고 단 하나의 변곡점을 가지면 시그모이드 함수Sigmoid Function라고 한다. - 시그모이달 함수와는 그 정의가 다르다. 종류 시그모이드 함수의 예시로써 다음과 같은 함수들이 알려져있다: 로지스틱 함수: $\displaystyle f(x) := {{ 1 } \over { 1 + e^{-x} }}$ 하이퍼볼릭 탄젠트: $\tanh x$ 아</description>
    </item>
    
    <item>
      <title>컨볼루션의 일반적인 정의</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-definition-of-convolution/</link>
      <pubDate>Sat, 31 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-definition-of-convolution/</guid>
      <description>정의 적분 변환 $J$와 두 함수 $f$, $g$가 주어졌다고 하자. 아래의 조건을 만족하는 함수 $f \ast g$를 $J$에 대한 $f$와 $g$의 컨볼루션이라 정의 한다. $$ J(f \ast g)=(Jf)(Jg) $$ 종류 푸리에 변환 $$ (f \ast g)(x) =\int _{-\infty} ^{\infty}f(y)g(x-y)dy $$ 보통 아무 설명없이 컨볼루션이라 함은 위의 정의를 말한다. 라플라스 변환 $$ (f \ast g)(x) = \int_{0}^{x}f(x-y)g(y)dy $$ 멜린 변환 $$ ( f\times g)(x)=\int _{0} ^{\infty} f(y)g \left( \frac{x}{y} \right)\frac{dy}{y} $$</description>
    </item>
    
    <item>
      <title>2차원 자율 시스템에서 피리어딕 오빗의 부재성</title>
      <link>https://freshrimpsushi.github.io/posts/nonexistence-of-periodic-orbit-of-2-dimensional-autonomous-system/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/nonexistence-of-periodic-orbit-of-2-dimensional-autonomous-system/</guid>
      <description>피리어딕 오빗에 대한 고찰 보통 자율 시스템에서 피리어딕 오빗이 존재하는지에 대한 질문은 상당히 까다로운데, $1,2$차원 공간이라면 비교적 간단하게 그 부재성에 대해서 논할 수 있다. 공간 $X = \mathbb{R}$ 혹은 $X = \mathbb{R}^{2}$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 1차원 $1$차원 자율 시스템에서는 피리</description>
    </item>
    
    <item>
      <title>적분 변환이란</title>
      <link>https://freshrimpsushi.github.io/posts/integral-transform/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integral-transform/</guid>
      <description>정의 함수공간에서 함수공간으로의 매핑 $J$가 아래와 같이 적분으로 정의되면 $J$를 적분변환integral transform이라 한다. $$ (Jf) (s) = \int_{a}^{b} K(x,t)f(t)dt $$ 이때 $K$를 $J$의 커널kernel이라 한다. $Jf$를 다시 $f$로 매핑하는 함수가 존재하면 이를 $J^{-1}$로 표기하고 역변환inverse transform</description>
    </item>
    
    <item>
      <title>로젠블렛의 단층 퍼셉트론</title>
      <link>https://freshrimpsushi.github.io/posts/rosenblatts-perceptron/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rosenblatts-perceptron/</guid>
      <description>설명 퍼셉트론 은 1957년 로젠블렛에 의해 고안됐으며 최초의 지도 학습 모델이다. 위 그림1과 같이 단일 층으로 구성돼있고 활성화 함수 $\varphi$는 입력 데이터와 가중치의 곱을 $+1$ 혹은 $-1$로 반환한다. $-1$대신 $0$이라 두기도 하는데 본질적으로 차이는 없다. 간단한 예로 아래 그림과 같은 $m=2$인 2차원 데이터를 생각해보</description>
    </item>
    
    <item>
      <title>놈은 연속 사상임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-norm-is-continuous-mapping/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-norm-is-continuous-mapping/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $(X, | \cdot |)$가 놈 공간이라고 하자. 그러면 $\lim \limits_{k\to\infty} \mathbf{x}_{k}=\mathbf{x}$인 $X$의 수열 $\left\{ \mathbf{x}_{k} \right\}$에 대해서 아래의 식이 성립한다. $$ \lim \limits_{k \to\infty} | \mathbf{x}_{k}|= | \mathbf{x}| $$ 다시 말해 놈 $| \cdot |$는 연속 함수라는 뜻이다. 극한 기호는 연속 함수에 대해서 안밖을 자유롭</description>
    </item>
    
    <item>
      <title>순서통계량</title>
      <link>https://freshrimpsushi.github.io/posts/order-statistics/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order-statistics/</guid>
      <description>정리1 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 가 서포트 $\mathcal{S} =(a,b)$ 인 확률밀도함수 $f(x)$ 를 가지는 연속확률분포를 따른다고 하자. 이들을 크기 순으로 나열한 확률 변수들을 $Y_{1} &amp;lt; \cdots &amp;lt; Y_{n}$ 와 같이 나타내도록 하면 그 조인트, 마지널 확률밀도함수들은 다음과 같다. [1] 조인트: $$ g \left( y_{1} , \cdots , y_{n} \right) = \begin{cases} n! f (y_{1}) \cdots f (y_{n}) &amp;amp;, a &amp;lt; y_{1} &amp;lt; \cdots &amp;lt; y_{n} &amp;lt; b \\ 0 &amp;amp; , \text{elsewhere} \end{cases} $$ [2] 마지널: $Y_{k}$ 의 누적밀도함수</description>
    </item>
    
    <item>
      <title>내적 공간에서 정의된 내적과 연관된 놈의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-inner-product-and-associated-norm/</link>
      <pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-inner-product-and-associated-norm/</guid>
      <description>정리1 내적 공간 $\left( H, \langle \cdot,\cdot \rangle \right)$가 주어졌다고 하자. 그러면 자연스럽게 $\left\| \cdot \right\|:=\sqrt{\left\langle \cdot,\cdot \right\rangle }$와 같이 놈을 정의할 수 있고 아래의 성질들이 성립한다. (a) 코시-슈바르츠 부등식: 임의의 $x,y\in H$에 대해서, $$ \left| \langle x,y \rangle \right| \le \left\| x \right\| \left\| y \right\| $$ (b) 평행사변형 법칙: 임의의 $x,y\in H$에 대해서, $$ \left\| x + y \right\|^{2} + \left\| x - y \right\|^{2} = 2 \left( \left\| x \right\| ^{2}+ \left\| y \right\| ^{2} \right) $$ (c)</description>
    </item>
    
    <item>
      <title>내적 공간에서 코시-슈바르츠 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-schwarz-inequality-in-inner-product-space/</link>
      <pubDate>Mon, 26 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-schwarz-inequality-in-inner-product-space/</guid>
      <description>정리1 $(H, \langle \cdot ,\cdot \rangle)$가 내적 공간이라고 하자. 그러면 아래의 부등식이 성립하고 이를 코시-슈바르츠 부등식Cauchy-Schwarz inequality 이라 한다. $$ \left| \langle x,y \rangle \right| \le \langle x,x \rangle^{1/2} \langle y,y \rangle ^{1/2},\quad \forall x,y \in H $$ 설명 내적으로부터 놈을 정의할 수 있으므로 다음의 식으로 표현할 수도 있다. $$ \left| \left\langle x, y \right\rangle \right| \le \left\| x \right\| \left\| y \right\|,\quad \forall x,y\in H $$ 증명 Case 1. $x=0$ 혹은 $y=0$</description>
    </item>
    
    <item>
      <title>벤딕슨 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/bendixsons-criterion/</link>
      <pubDate>Mon, 26 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bendixsons-criterion/</guid>
      <description>벤딕슨 판정법 공간 $\mathbb{R}^{2}$ 와 함수 $f,g \in C^{1} \left( \mathbb{R}^{2} \right)$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x,y) \\ y&#39; = g(x,y) $$ 단순 연결 영역 $D \subset \mathbb{R}^{2}$ 에서 $$ {{ \partial f } \over { \partial x }} + {{ \partial g } \over { \partial y }} \ne 0 $$ 의 부호가 바뀌지 않는다면, 주어진 $2$차 벡터 필드는 $D$ 내부에서 닫힌 오빗을 갖지 않는다. $D \subset \mathbb{R}^{2}$ 이 단순 연결 영역이라는 것은 $D$ 의 테두리</description>
    </item>
    
    <item>
      <title>내적 공간이란</title>
      <link>https://freshrimpsushi.github.io/posts/inner-product-space/</link>
      <pubDate>Sun, 25 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inner-product-space/</guid>
      <description>정의1 $H$를 벡터 공간이라고 하자. $x,y,z \in H$ 와 $\alpha, \beta \in \mathbb{C}$에 대해서 다음의 조건을 만족하는 함수 $$ \langle \cdot , \cdot \rangle : H \times H \to \mathbb{C} $$ 를 내적inner product이라고 정의하고 $\left( H, \langle \cdot ,\cdot \rangle \right)$를 내적공간inner product space이라 한다. 선형성: $$\langle \alpha x + \beta y ,z \rangle =\alpha \langle x,z\rangle + \beta \langle y,z\rangle$$ 켤레대칭성: $$\langle x,y \rangle =</description>
    </item>
    
    <item>
      <title>안티 리니어, 컨쥬게이트 리니어</title>
      <link>https://freshrimpsushi.github.io/posts/antilinear-conjugate-linear/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/antilinear-conjugate-linear/</guid>
      <description>정의 함수 $f : X \to \mathbb{C}$가 주어졌다고 하자. $x,y\in X$, $a,b \in \mathbb{C}$에 대해서 아래의 식이 성립하면 $f$를 안티리니어antilinear 혹은 컨쥬게이트 리니어conjugate linear라고 한다. $$ f(ax + by)=\overline{a}f(x)+\overline{b}f(y) $$ 설명 곱해진 상수가 함수 안팎에서 같은 선형 함수와 달리 함수 안팎에서 켤레 복소수인 함수이다.</description>
    </item>
    
    <item>
      <title>표본 분산을 n-1으로 나누는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-sample-variance-is-divided-by-n-1/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-sample-variance-is-divided-by-n-1/</guid>
      <description>왜 n-1로 나누지? $X_{i} \sim \left( \mu , \sigma^{2} \right)$ 이라고 하면 표본 분산 $S^{2}$ 는 다음과 같다. $$ S^{2} := {{1} \over {n-1}} \sum_{i=1}^{n} \left( X_{i} - \overline{X} \right)^{2} $$ 알다시피 표본 평균과 달리 표본 분산은 편차의 제곱을 모두 더한 후 표본 크기인 $n$ 이 아니라 $n-1$ 로 나눈다. 당연히 이를 이상하게 느껴야한다고는 말하지 않겠지만, 수식에 대한 보편적인 감성이 있다면 $n$ 개를 더하고 $n-1$ 로 나누는 것에서 강렬한 띠꺼움을 느</description>
    </item>
    
    <item>
      <title>내적 공간, 놈 공간, 거리공간의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-inner-space-inner-space-and-street-space/</link>
      <pubDate>Fri, 23 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-inner-space-inner-space-and-street-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 내적 공간 $\left( H, \langle\cdot, \cdot\rangle \right)$가 주어졌다고 하자. 그러면 내적으로부터 아래와 같이 자연스럽게 놈을 정의할 수 있다. $$ |x| := \sqrt{ \langle x, x\rangle},\quad x\in H \tag{1} $$ 따라서 내적 공간이면 놈 공간이다. 계속해서 이렇게 정의된 놈으로부터 거리를 정의할 수 있다. $$ d(x,y):=|x -y | =\sqrt{ \langle x-y, x-y \rangle},\quad x,y\in H \tag{2} $$ 따라서 내적 공간이면 놈</description>
    </item>
    
    <item>
      <title>불변 매니폴드의 안정성</title>
      <link>https://freshrimpsushi.github.io/posts/stability-of-manifold/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stability-of-manifold/</guid>
      <description>정의 벡터 필드의 매니폴드1 공간 $\mathbb{R}^{n}$ 와 함수 $f : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 고정점 $\overline{x}$ 이 주어져 있다고 할 때, 선형화 행렬 $A := D f \left( \overline{x} \right)$ 의 각 고유값 $\lambda$ 들에 대응되는 고유벡터 $e$ 들을 실수부 $\Re (\lambda)$ 에 따라 다음과 분류하고, 그 생성 $\text{span}$ 을 다음과 같이 나타내자. $$ E^{s} := \text{span} \left\{ e :</description>
    </item>
    
    <item>
      <title>컴퓨터 비전이란</title>
      <link>https://freshrimpsushi.github.io/posts/computer-vision/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/computer-vision/</guid>
      <description>설명 컴퓨터 비전 이란 주로 사람의 시각에 해당하는 기능을 컴퓨터가 수행할 수 있도록 하는 연구 분야이며 이미지나 영상을 다룬다. 컴퓨터 비전을 전문적으로 다루는 컨퍼런스로는 ICCV(International Conference on Computer Vision), ECCV(European Conference on Computer Vision), CVPR(Conference on Computer Vision and Pattern Recognition)등이 있다. 컴퓨터 비전에서 주로 다루는 문제는 아래의 사진과 같이 크게 3가지로 분류할 수 있다. 분류class</description>
    </item>
    
    <item>
      <title>딥러닝에서 연속 학습이란</title>
      <link>https://freshrimpsushi.github.io/posts/continual-learning-lifelong-learning-incremental-learning/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continual-learning-lifelong-learning-incremental-learning/</guid>
      <description>설명 딥러닝에서 연속 학습이란 평생 학습, 점진적 학습과 같은 말로서 인공 신경망이 순차적으로 여러 작업을 학습하는 것을 말한다. 인간의 경우 새로운 지식을 학습한다고 해서 기존의 지식을 잊어버리지 않는다. 물론 시간이 지나면 기존의 지식을 잊기도 하지만 이 원인이 새로운 지식을 학습했기 때문은 아니다. 하지만 인공 신경망의 경우 하나의 작업을 충분히 학</description>
    </item>
    
    <item>
      <title>불편추정량</title>
      <link>https://freshrimpsushi.github.io/posts/unbiased-estimator/</link>
      <pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unbiased-estimator/</guid>
      <description>정의 1 $\theta$ 의 추정량 $T$ 가 다음을 만족하면 $T$ 를 $\mu$ 의 불편추정량Unbiased Estimator이라고 한다. $$ E T = \theta $$ 설명 특히 $\theta$ 에 대한 불편추정량 중 가장 분산이 작은 경우 최소분산불편추정량Mimimum Variance Unbiased Estimator, MVUE이라고 한다. 불편성이란 편의를 가지지 않는 성질을 말한다. 가령 $X_{i} \sim \left( \mu , \sigma^{2} \right)$ 라고 할 때 $\mu$ 의 추정량으로써 표본</description>
    </item>
    
    <item>
      <title>멜린변환의 컨볼루션</title>
      <link>https://freshrimpsushi.github.io/posts/multiplicative-convolution/</link>
      <pubDate>Mon, 19 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplicative-convolution/</guid>
      <description>정의 멜린변환의 컨볼루션은 다음과 같다. $$ (f \times g) (y) = \int _{0}^{\infty} f(x)g \left(\frac{y}{x} \right)\frac{dx}{x} $$ 설명 곱셈적 합성곱multiplicative convolution1이라 부르기도 한다. 증명 $$ \mathcal{M}(f \times g)=(\mathcal{M}f)(\mathcal{M}g) $$ 위 등식이 성립함을 보이면 된다. $$ \begin{align*} \mathcal{M}(f\times g)(s) &amp;amp;= \int _{0} ^{\infty} x^{s-1} (f\times g)(x)dx \\ &amp;amp;= \int _{0} ^{\infty} x^{s-1} (f\times g)(x)dx \\ &amp;amp;= \int _{0} ^{\infty} x^{s-1} \left( \int _{0}^{\infty}f(y)g \left( \frac{x}{y} \right)\frac{dy}{y} \right)dx \\ &amp;amp;= \int _{0} ^{\infty} \int _{0}^{\infty}x^{s-1}f(y)g \left( \frac{x}{y} \right)\frac{dy}{y} dx \\ &amp;amp;= \int _{0} ^{\infty} \int _{0}^{\infty}y^{s-1}z^{s-1}f(y)g (z)dydz \\ &amp;amp;= \int _{0} ^{\infty}</description>
    </item>
    
    <item>
      <title>동역학에서의 불변 집합</title>
      <link>https://freshrimpsushi.github.io/posts/invariant-set-in-dynamics/</link>
      <pubDate>Sun, 18 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/invariant-set-in-dynamics/</guid>
      <description>정의1 공간 $X$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $S \subset X$ 라고 하자. (V): $\forall x_{0} \in S$ 가 모든 $t \in \mathbb{R}$ 에 대해 다음을 만족하면 벡터 필드 $x&#39;=f(x)$ 하에서의 불변 집합이라 한다. $$ x(t,x_{0}) \in S $$ (M): $\forall x_{0} \in S$ 가 모든 $n \in \mathbb{Z}$ 에 대해 다음을 만족하면 맵 $x \mapsto g(x)$ 하에서의 불변 집합이라 한다. $$ g^{n} (x_{0}) \in S $$ 불변 집합Inva</description>
    </item>
    
    <item>
      <title>불연속성의 분류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-discontinuities/</link>
      <pubDate>Sun, 18 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-discontinuities/</guid>
      <description>정의1 거리공간 $X$에서 정의된 함수 $f :X \to \mathbb{R}$이 주어졌다고 하자. 만약 $f$가 $x\in X$에서 연속이 아니면, $f$는 $x$에서 불연속하다discontinuous 고 하거나 $x$에서 불연속성discontinuity 을 갖는다고 한다. $f: (a,b) \to \mathbb{R}$이라고 하자. $f$가 $x\in (a,b)$</description>
    </item>
    
    <item>
      <title>해석학에서 엄밀하게 정의되는 좌극한과 우극한</title>
      <link>https://freshrimpsushi.github.io/posts/left-hand-limits-right-hands-limits/</link>
      <pubDate>Sat, 17 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/left-hand-limits-right-hands-limits/</guid>
      <description>정의[^1] 거리공간 $X$에서 정의된 함수 $f :X \to \mathbb{R}$이 주어졌다고 하자. 만약 $f$가 $x\in X$에서 연속이 아니면, $f$는 $x$에서 불연속하다 고 하거나 $x$에서 불연속성을 갖는다 고 한다. $f: (a,b) \to \mathbb{R}$이라고 하자. 임의의 점 $x$에 대해서 $a \le x &amp;lt;b$라고 하자. $\left\{ t_{n} \right\</description>
    </item>
    
    <item>
      <title>도함수와 함수의 증가감소의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-derivative-and-increasingdecreasing-of-function/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-derivative-and-increasingdecreasing-of-function/</guid>
      <description>정리 함수 $f$가 $(a,b)$에거 미분 가능하다고 하자. 만약 모든 $x\in (a,b)$에 대해서 $f&#39;(x) \ge 0$이면, $f$는 단조롭게 증가한다. 만약 모든 $x\in (a,b)$에 대해서 $f&#39;(x)=0$이면, $f$는 상수함수이다. 만약 모든 $x\in (a,b)$에 대해서 $f&#39;(x) \le 0$이면, $f$는 단조롭게 감소한다. 증명 평균값 정리로부터 모든 $x_{1},x_{2}\in (a</description>
    </item>
    
    <item>
      <title>편의-분산 트레이드 오프</title>
      <link>https://freshrimpsushi.github.io/posts/bias-variance-trade-off/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bias-variance-trade-off/</guid>
      <description>정의 $$ \text{MSE} \left( \widehat{\theta} \right) = \text{Var} \widehat{\theta} + \left( \text{Bias} \widehat{\theta} \right)^{2} $$ 평균 평균제곱오차 $\text{MSE}$ 는 통계 모형의 평가나 머신 러닝에서의 손실 함수로써 즐겨쓰이는 척도로써, 특히 편의와 분산에 대한 트레이드 오프로 나타난다.통계학도에게 있어서 편의를 다루는 것은 다소 어색할지 모르겠다. 적절한 확률 분포를 가정하고 그에 따른 수학적 이론을 토대로 데이터를 다루는 입장에서 분산은 손에 잡힐</description>
    </item>
    
    <item>
      <title>단조함수, 증가함수, 감소함수</title>
      <link>https://freshrimpsushi.github.io/posts/monotone-function/</link>
      <pubDate>Thu, 15 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monotone-function/</guid>
      <description>정의 함수 $f:[a,b] \rightarrow \mathbb{R}$가 주어졌다고 하자. $x_1$, $x_2$ $\in [a,b]$에 대해서 $$ x_1&amp;lt;x_2 \ \implies f(x_1) \le f(x_2) $$ 를 만족하면 $f$가 단조롭게 증가monotonically increasing한다고 말하거나, $f$를 단조증가함수monotone increasing function라 부른다. 반대로 $$ x_1 &amp;lt;x_2 \ \implies f(x_1) \ge f(x_2) $$ 를 만족하면 $f$가 단조롭게</description>
    </item>
    
    <item>
      <title>해석학에서 평균값 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem-in-analysis/</link>
      <pubDate>Thu, 15 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem-in-analysis/</guid>
      <description>정리 두 함수 $f$, $g$가 구간 $[a,b]$에서 연속이고, $(a,b)$에서 미분 가능한 함수라고 하자. 그러면 아래의 식을 만족하는 $x \in (a,b)$가 존재한다. $$ [f(b)-f(a)]g&#39;(x)=[g(b)-g(a)]f&#39;(x) $$ 양 끝점 $a$, $b$에서는 미분가능성이 필요하지 않음에 주의하라. 설명 이는 고등학교와 미분적분학에서 배운 평균값 정리를 일반화 한 것이다. $g(x)=x$라고 두면 흔히</description>
    </item>
    
    <item>
      <title>랴푸노프 함수</title>
      <link>https://freshrimpsushi.github.io/posts/liapunov-function/</link>
      <pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/liapunov-function/</guid>
      <description>정의1 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 한 점 $x_{0} \in X$ 이 주어져 있다고 할 때, $x_{0}$ 의 네이버후드 $\mathcal{N} \left( x_{0} \right)$ 에서 정의된 스칼라 함수 $V \in C^{1} \left( \mathcal{N} (x_{0}) , \mathbb{R} \right)$ 가 다음의 조건을 만족하면 랴푸노프 함수Liapunov Function라고 한다. (i): $V(x_{0}) = 0$ 이고, $x \ne</description>
    </item>
    
    <item>
      <title>해석학에서 극대의 정의와 미분 계수와의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/local-maximumminimum/</link>
      <pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/local-maximumminimum/</guid>
      <description>정의 $(X,d)$를 거리공간이라고 하자. 함수 $f : X \rightarrow \mathbb{R}$에 대해서 아래의 조건을 만족하는 양수 $\delta &amp;gt;0$가 존재하면, $f$는 점 $p \in X$에서 극대local maximum를 가진다 고 한다. $$ \forall q\in X,\quad f(q)\le f(p)\ \mathrm{with}\ d(p,q)&amp;lt;\delta $$ 설명 말로 풀어서 설명하면 다음과 같다: $p$를 기준으로 거리 $\delta$만큼 떨어진 곳 안</description>
    </item>
    
    <item>
      <title>해석학에서 미분의 연쇄 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-chain-rule-for-differentiation/</link>
      <pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-chain-rule-for-differentiation/</guid>
      <description>정리1 $f :[a,b] \to \mathbb{R}$가 연속함수이고, $x\in [a,b]$에서 미분가능하다고 하자. $g : f([a,b])\to \mathbb{R}$가 $f (x)\in f([a,b])$에서 미분가능하다고 하자. 그리고 $h : [a,b] \to \mathbb{R}$을 다음과 같다고 하자. $$ h(t)=g\left( f(t) \right)\quad (a\le t \le b) $$ 그러면 $h$는 $x$에서 미분 가능하고 그 값은 아래와 같다. $$ h&#39;(x)=g&#39;(f(x))f&#39;(x) $$ 합</description>
    </item>
    
    <item>
      <title>미분가능한 함수의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-differentiable-funtion/</link>
      <pubDate>Tue, 13 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-differentiable-funtion/</guid>
      <description>정리1 $f, g : [a,b] \to \mathbb{R}$이라고 하자. 만약 $f,g$가 $x\in [a,b]$에서 미분가능면, $f+g$, $fg$, $f/g$도 $x$에서 미분가능하고 아래의 식이 성립한다. $$ \begin{align} (f+g)&#39;(x) &amp;amp;=f&#39;(x)+g&#39;(x) \label{eq1} \\ (fg)&#39;(x) &amp;amp;= f&#39;(x)g(x)+f(x)g&#39;(x) \label{eq2} \\ \left( \frac{f}{g} \right)&#39;(x) &amp;amp;= \frac{f&#39;(x)g(x)-f(x)g&#39;(x)}{g^{2}(x)} \label{eq3} \end{align} $$ 단 $\eqref{eq3}$은 $g(x)\ne 0$일 때 성립한다. 설명 $\eqref{eq2}$는 흔히 곱의 미분법이라고 불린다</description>
    </item>
    
    <item>
      <title>미분가능하면 연속이다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-differentiable-function-is-continuous/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-differentiable-function-is-continuous/</guid>
      <description>정리1 $f : [a,b] \to \mathbb{R}$이라고 하자. 만약 $f$가 $p \in [a,b]$에서 미분가능하면, $f$는 $p$에서 연속이다. 설명 역인 &amp;lsquo;연속이면 미분가능하다&amp;rsquo;는 성립하지 않음을 주의하자. 라떼는 이 결과를 간미연 (간 단히 말해서 미 분가능하면 연 속이다)으로 줄이는 드립이 있었지만 요즘 학생들은 간미</description>
    </item>
    
    <item>
      <title>수리통계학에서의 편의</title>
      <link>https://freshrimpsushi.github.io/posts/bias-in-mathematical-statistics/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bias-in-mathematical-statistics/</guid>
      <description>정의 모수 $\theta$ 에 대한 추정량 $\widehat{\theta}$ 에 대해 다음과 같이 정의된 $\text{Bias}$ 를 편의라 한다. $$ \text{Bias} ( \theta ) = E(\widehat{\theta}) - \theta $$ 설명 Bias는 편의 또는 편향으로 순화되지만, 역시 가장 많이 쓰이는 말은 발음 그대로 읽은 [바이어스]다. 한국어에서 편의는 Convenience인 경우가 압도적으로 많고 수식적으로나 실제 쓰임새로나 &amp;lsquo;편향&amp;rsquo;으로 순</description>
    </item>
    
    <item>
      <title>조절 초함수</title>
      <link>https://freshrimpsushi.github.io/posts/tempered-distribution/</link>
      <pubDate>Sun, 11 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tempered-distribution/</guid>
      <description>정의1 슈바르츠 공간의 연속인 선형 범함수 $T:\mathcal{S}(\mathbb{R}^{n}) \to \mathbb{C}$를 조절 초함수tempered distribution라고 한다. 다시 말해 조절 초함수는 슈바르츠 공간의 듀얼 스페이스의 원소이다. 따라서 $$ T \in \mathcal{S}^{ \ast } $$ 와 같이 표기하고 $\mathcal{S}^{ \ast }$를 조절 초함수 공간space of tempered distribution이라 부른다. 설명 조절 초</description>
    </item>
    
    <item>
      <title>자율 시스템에서 고정점의 분류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-fixed-point/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-fixed-point/</guid>
      <description>정의 공간 $X$ 와 함수 $f \in C^{1}(X,X)$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ $\overline{x}$ 가 이 자율 시스템의 한 고정점이라 하고 $D f \left( \overline{x} \right)$ 의 아이겐 밸류들을 $\lambda_{1} , \cdots , \lambda_{m}$ 이라 하자. 하이퍼볼릭: 쌍곡 고정점1 Hyperbolic: $D f \left( \overline{x} \right)$ 의 모든 아이겐 밸류들의 실수부가 $0$ 이 아니면 $\overline{x}$ 가 하이퍼볼릭하다고 말한다. $$ \Re \left( \lambda_{1} \right) \ne 0 , \cdots , \Re \left( \lambda_{m} \right)</description>
    </item>
    
    <item>
      <title>푸리에 급수의 복소 표현</title>
      <link>https://freshrimpsushi.github.io/posts/complex-representation-of-fourier-series/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complex-representation-of-fourier-series/</guid>
      <description>공식 구간 $[-L,\ L)$에서 정의된 함수 $f$의 복소 푸리에 급수complex Fourier series는 다음과 같다. $$ f(t) = \sum \limits_{n=-\infty}^{\infty} c_{n} e^{i\frac{n\pi t}{L}} $$ 이때 복소 푸리에 계수는 다음과 같다. $$ c_{n} = \dfrac{1}{2L}\int_{-L}^{L}f(t)e^{-i\frac{n \pi t}{L} }dt $$ 푸리에 계수에 대해 다음의 식을 만족한다. $$ \begin{align*} a_{0} &amp;amp; = 2 c_{0} \\ a_{n} &amp;amp;= c_{n}+c_{-n} \\ b_{n} &amp;amp;= i(c_{n}-c_{-n}) \\ c_{n} &amp;amp;= \frac{1}{2} (a_{n}-ib_{n}) \\ c_{-n} &amp;amp;= \frac{1}{2} (a_{n}+ib_{n}) \end{align*} $$ 삼각함수 꼴보다 간단하여 더 자주 쓰이는 폼이다. 증명 푸리</description>
    </item>
    
    <item>
      <title>편미분 방정식이란</title>
      <link>https://freshrimpsushi.github.io/posts/partial-differential-equation/</link>
      <pubDate>Fri, 09 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partial-differential-equation/</guid>
      <description>정의1 자연수 $k \in \mathbb{N}$, 열린 집합 $U \subset \mathbb{R}^{n}$에 대해서 다음의 표현을 을 $k$계 편미분 방정식kth-order partial differential equation이라 한다. $$ \begin{equation} F(D^{k}u(x), D^{k-1}u(x),\cdots,Du(x),u(x),x)=0\quad (x\in U) \label{PDE} \end{equation} $$ 여기서 $D^{k}u$는 멀티인덱스 표기법이다. $F$는 다음과 같이 주어지고, 미지수 $u$는 다음과 같다. $$ F : {\mathbb{R}}^{n^{k}}\times{\mathbb{R}}^{n^{k-1}}\times \cdots \times \mathbb{R}^{n}\times \mathbb{R}\times U \to \mathbb{R} \\ u : U \to</description>
    </item>
    
    <item>
      <title>곡선 좌표계에서 벡터 함수의 다이벌전스발산</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-of-a-vector-function-in-a-cuvilinear-coordinate-system/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-of-a-vector-function-in-a-cuvilinear-coordinate-system/</guid>
      <description>정리 곡선 좌표계에서 벡터 함수 $\mathbf{F}=\mathbf{F}(q_{1},q_{2},q_{3})=F_{1}\hat{\mathbf{q}}_{1}+F_{2}\hat{\mathbf{q}}_{2}+F_{3}\hat{\mathbf{q}}_{3}$의 다이벌전스는 다음과 같다. $$ \nabla \cdot \mathbf{F}=\frac{1}{h_{1}h_{2}h_{3}}\left[</description>
    </item>
    
    <item>
      <title>수리통계학에서의 신뢰 구간</title>
      <link>https://freshrimpsushi.github.io/posts/confidence-interval/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/confidence-interval/</guid>
      <description>정의 1 확률 밀도 함수 $f (x; \theta)$ 를 가지는 확률 변수 $X$ 의 샘플 $X_{1} , \cdots , X_{n}$ 와 신뢰 계수Confidence Coefficient $\alpha \in (0,1)$ 가 주어져 있다고 하자. $$ L := L \left( X_{1} , \cdots , X_{n} \right) \\ U := U \left( X_{1} , \cdots , X_{n} \right) $$ 통계량 $L,U$ 가 위와 같이 정의되어있다고 할 때, 다음을 만족하는 구간 $(L,U) \subset \mathbb{R}$ 을 모수 $\theta$ 에 대한 $( 1 - \alpha)100 \%$ 신뢰구간이라 한다. $$ 1-\alpha = P \left[ \theta \in \left( L,U \right) \right] $$ 설명 사실 신</description>
    </item>
    
    <item>
      <title>곡선 좌표계에서 스칼라 함수의 그래디언트기울기</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-of-a-scalar-function-in-a-cuvilinear-coordinate-system/</link>
      <pubDate>Wed, 07 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-of-a-scalar-function-in-a-cuvilinear-coordinate-system/</guid>
      <description>정리 곡선 좌표계에서 스칼라 함수 $f=f(q_{1},q_{2},q_{3})$의 그래디언트를 다음과 같다. $$ \nabla f= \frac{1}{h_{1}}\frac{ \partial f }{ \partial q_{1} } \hat{\mathbf{q}}_{1} + \frac{1}{h_{2}}\frac{ \partial f }{ \partial q _{2}}\hat{\mathbf{q}}_{2}+\frac{1}{h_{3}}\frac{ \partial f }{ \partial q_{3} } \hat{\mathbf{q}}_{3}=\sum \limits _{i=1} ^{3}\frac{1}{h_{i}}\frac{ \partial f}{ \partial q_{i}}\hat{\mathbf{q}}_{i} $$ $h_{i}$는 스케일 팩터이다. 공식 직교 좌표계: $$ h_{1}=h_{2}=h_{3}=1 $$ $$ \nabla f= \frac{\partial f}{\partial x}\mathbf{\hat{\mathbf{x}} }+ \frac{\partial f}{\partial y}\mathbf{\hat{\mathbf{y}}} + \frac{\partial f}{\partial z}\mathbf{\hat{\mathbf{z}}} $$ 원통 좌표계: $$ h_{1}=1,\quad h_{2}=\rho,\quad h_{3}=1 $$ $$ \nabla f = \frac{\partial f}{\partial \rho}\boldsymbol{\hat \rho} + \frac{1}{\rho}\frac{\partial f}{\partial \phi}\boldsymbol{\hat</description>
    </item>
    
    <item>
      <title>더핑 오실레이터</title>
      <link>https://freshrimpsushi.github.io/posts/duffing-oscillator/</link>
      <pubDate>Tue, 06 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/duffing-oscillator/</guid>
      <description>더핑 방정식1 $$ x&#39;&#39; + \delta x&#39; + \alpha x + \beta x^{3} = \gamma \cos \left( \omega t \right) $$ 변수 $t$: 시간을 나타낸다. $x$: $1$차원 상에서 (이를 테면 입자의) 위치를 나타낸다. $x&#39;$: (입자의) 속도 를 나타낸다 $x&#39;&#39;$: (입자의) 가속도 를 나타낸다. 파라메터 $\delta$: 감쇠(Damping) 를 제어하며, 마찰(Friction)과 비슷한 역할을 한다. $\alpha$: 강성(Stiffness) 를 제</description>
    </item>
    
    <item>
      <title>함수해석학에서 스플라인, B-스플라인</title>
      <link>https://freshrimpsushi.github.io/posts/spline-and-b-spline-in-functional-analysis/</link>
      <pubDate>Tue, 06 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spline-and-b-spline-in-functional-analysis/</guid>
      <description>정의 $\mathbb{R}$에서 정의된 함수 $f:\mathbb{R} \to \mathbb{R}$이 piecewise polynomial이면 $f$를 $\mathbb{R}$위에서의 스플라인spline이라고 한다. 다항식이 바뀌는 점을 놋knot 이라 한다. 설명 정의를 보면 알 수 있듯이 스플라인이 연속함수여야하는 것은 아니다. 아래와 같은 함수 $f$는 스플라인의</description>
    </item>
    
    <item>
      <title>수학에서 단위 분할이란</title>
      <link>https://freshrimpsushi.github.io/posts/partition-of-unity/</link>
      <pubDate>Mon, 05 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-of-unity/</guid>
      <description>정의 아래의 조건을 만족하는 연속 함수 $u_{\alpha} : X \to [0,1], \alpha \in \Lambda$들의 집합 $\left\{ u_{\alpha} \right\}_{\alpha \in \Lambda}$를 단위 분할Partition of Unity이라고 한다. $$ \sum _{\alpha \in \Lambda}u_{\alpha}(x)=1 $$ 설명 조금 더 일반적으로 정의할 수도 있지만 이 정도만 해도 충분하다. 다 더해서 1이 되는 함수들의 집합, 혹은 반대로 1을 쪼개어 놓은 함수들의 집합으로 이해할 수 있다</description>
    </item>
    
    <item>
      <title>수리통계학에서의 통계량과 추정량</title>
      <link>https://freshrimpsushi.github.io/posts/statistic-and-estimator/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statistic-and-estimator/</guid>
      <description>정의 1 확률 변수 $X$ 의 샘플 $X_{1} , \cdots , X_{n}$ 의 함수 $T$ 를 통계량Statistic이라 한다. $$ T := T \left( X_{1} , \cdots , X_{n} \right) $$ $X$ 의 분포 함수가 $f(x; \theta)$ 혹은 $p(x; \theta)$ 와 같이 나타날 때, $T$ 가 $\theta$ 를 파악하기 위한 통계량이면 $T$ 를 $\theta$ 의 추정량Estimator이라고 한다. 통계량과 모수에 대한 함수를 피벗Pivot이라고 한다. 설명 2: 추정량(Estimator)</description>
    </item>
    
    <item>
      <title>제이만 효과</title>
      <link>https://freshrimpsushi.github.io/posts/zeeman-effect/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zeeman-effect/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 1897년 네덜란드 물리학자 **피테르 제이만Pieter Zeeman ** 이 발견한 현상으로 원자가 자기장 내에 있을 때 방출 스펙트럼 선이 갈라지는 것을 말한다. 패러데이가 1860년에 나트륨의 스펙트럼과 자기장에 대한 연구를 진행했지만 별다른 소득을 얻지 못했다. 이후 제이만도 같은 연구를 하였으나</description>
    </item>
    
    <item>
      <title>스펙트럼과 프라운호퍼 선</title>
      <link>https://freshrimpsushi.github.io/posts/spectrum-and-fraunhofer-line/</link>
      <pubDate>Sat, 03 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spectrum-and-fraunhofer-line/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 스펙트럼이란 분광학의 연구 대상으 빛을 여러 색으로 분해한 것을 말한다. 흔히 제일 처음 보게되는 스펙트럼의 그림은 위와 같이 가로, 혹은 세로로 긴 형태의 선 스펙트럼 이다. 하지만 스펙트럼이 처음부터 이러한 형태를 띄었던 것은 아니다. 프리즘을 통해서 빛을 여러 색으로 분해시킬 수 있음을 처음 발견한</description>
    </item>
    
    <item>
      <title>랴푸노프 안정성과 오빗 안정성</title>
      <link>https://freshrimpsushi.github.io/posts/liapunov-stability-and-orbit-stability/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/liapunov-stability-and-orbit-stability/</guid>
      <description>정의 랴푸노프 안정성 1 거리 공간 $\left( X , \left\| \cdot \right\| \right)$ 과 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ $t_{0} \in \mathbb{R}$ 이라 하자. 주어진 미분 방정식의 솔루션 $\overline{x}(t)$ 가 $\varepsilon &amp;gt; 0$ 이 주어질 때마다 $$ \left\| \overline{x} \left( t_{0} \right) - y \left( t_{0} \right) \right\| &amp;lt; \delta \implies \left\| \overline{x}(t) - y(t) \right\| &amp;lt; \varepsilon \qquad , t &amp;gt; t_{0} $$ 를 만족시키는 다른 모든 솔루션 $y(t)$ 에 대해 $\delta ( \varepsilon ) &amp;gt; 0$ 가 존재하</description>
    </item>
    
    <item>
      <title>분광학이란</title>
      <link>https://freshrimpsushi.github.io/posts/spectrosophy/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spectrosophy/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 위 사진과 같이 빛을 여러 색으로 분해한 것을 스펙트럼Spectrum , 한국말로 분광 이라 한다. 분광학Spectroscopy 이란 광학의 일종으로 파장에 따라 분해된 가시광선을 관찰하고 연구하는 학문이다. 다만 최근에는 그 의미가 확대되어 파장이나 주파수에 따른 어떤 물리량을 측정하고 연</description>
    </item>
    
    <item>
      <title>논문 리뷰: Do We Need Zero Training Loss After Achieving Zero Training Error?</title>
      <link>https://freshrimpsushi.github.io/posts/flooding-do-we-need-zero-training-loss-after-achieving-zero-training-error-review/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/flooding-do-we-need-zero-training-loss-after-achieving-zero-training-error-review/</guid>
      <description>논문 리뷰 플루딩은 ICML 2020에서 발표된 Do We Need Zero Training Loss After Achieving Zero Training Error?에서 소개한 레귤라이제이션 기법을 말한다. 이 논문의 저자는 오버 피팅이 일어나는 이유가 아래 그림과 같이 지나치게 작은 트레이닝 로스라고 말한다. 따라서 아래 그림과 같이 학습 과정에서 트레이닝 로스가 특정한 값 이하로 내려가지 않게 조절하면 테스트 로스를 줄일 수 있을 것이</description>
    </item>
    
    <item>
      <title>머신러닝에서 많이 쓰이는 데이터 셋</title>
      <link>https://freshrimpsushi.github.io/posts/popular-datasets-in-machine-learning/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/popular-datasets-in-machine-learning/</guid>
      <description>이미지 처리 MNIST 머신 러닝을 공부할 때 가장 먼저 접할 데이터 셋이다. [엠니스트]라고 읽으며 $28\times 28$ 크기의 손글씨 사진 데이터이다. 학습 데이터 60,000개, 테스트 데이터 10,000개가 포함되어 있다[^1] CIFAR-10, CIFAR-100 CIFAR-10은 [싸이파-텐]이라고 읽으며, 10가지 카테고리 대한 $32\times 32$ 크기의 컬러 이미지 60,000장을 포함하는 데</description>
    </item>
    
    <item>
      <title>수리통계학에서의 랜덤 샘플</title>
      <link>https://freshrimpsushi.github.io/posts/random-sample/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-sample/</guid>
      <description>정의 1 확률 변수 $X$ 가 실제로 뽑힌 것을 실현Realization이라 하고 보통 소문자 $x$ 로 나타낸다. 확률 변수 $X$ 와 같은 확률 분포에서 샘플 사이즈Sample Size $n$ 만큼 얻어낸 확률 변수들을 샘플Sample이라 하고 다음과 같이 나타낸다. $$ X_{1} , X_{2} , \cdots , X_{n} $$ 확률 변수 $X_{1} , \cdots , X_{n}$ 이 iid면 사이즈 $n$ 의 랜덤 샘플이라 부른다. 설명 이러한 정의</description>
    </item>
    
    <item>
      <title>머신러닝에서 레귤라이제이션이란</title>
      <link>https://freshrimpsushi.github.io/posts/regularization-in-machine-learning/</link>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regularization-in-machine-learning/</guid>
      <description>정의 트레이닝 로스가 아닌 테스트 로스를 줄이기 위해 알고리즘을 수정하는 모든 방법을 레귤라이제이션 이라 한다.1 Goodfellow defines regularization as &amp;ldquo;any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.&amp;rdquo; 즉, 오버피팅을 막기 위한 모든 방법을 묶어서 레귤라이제이션이라 한다. 머신러닝, 딥러닝 교재에서 흔히 소개되는 기법으로는 드롭 아웃이 있다. 종류 $l_{2}$ regularization $l_{1}$ regularization Weight decay Early stopping 드롭 아웃</description>
    </item>
    
    <item>
      <title>곡선 좌표계에서 좌표 변환과 야코비안</title>
      <link>https://freshrimpsushi.github.io/posts/the-coordinate-transform-and-jacobian/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-coordinate-transform-and-jacobian/</guid>
      <description>공식 3차원 데카르트 좌표계에서의 부피는 임의의 곡선 좌표계에 대해서 다음과 같이 나타난다. $$ dxdydz =\begin{vmatrix} \frac{ \partial x}{ \partial q_{1}} &amp;amp; \frac{ \partial y}{ \partial q_{1}} &amp;amp; \frac{ \partial z}{ \partial q_{1} } \\ \frac{ \partial x}{ \partial q_{2}} &amp;amp; \frac{ \partial y}{ \partial q_{2}} &amp;amp; \frac{ \partial z}{ \partial q_{2} } \\ \frac{ \partial x}{ \partial q_{3}} &amp;amp; \frac{ \partial y}{ \partial q_{3}} &amp;amp; \frac{ \partial z}{ \partial q_{3} } \end{vmatrix} dq_{1}dq_{2}dq_{3} = \begin{vmatrix}\frac{ \partial x}{ \partial q_{1}} &amp;amp; \frac{ \partial x}{ \partial q_{2}} &amp;amp; \frac{ \partial x}{ \partial q_{3}} \\ \frac{ \partial y}{ \partial q_{1}} &amp;amp; \frac{ \partial y}{ \partial q_{2}} &amp;amp; \frac{ \partial y}{ \partial q_{3}} \\ \frac{ \partial z}{ \partial q_{1}} &amp;amp; \frac{ \partial z}{ \partial q_{2}} &amp;amp;</description>
    </item>
    
    <item>
      <title>비선형 시스템의 선형화</title>
      <link>https://freshrimpsushi.github.io/posts/linearization-of-nonlinear-system/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearization-of-nonlinear-system/</guid>
      <description>비선형 시스템의 선형화란? 공간 $\left( X, \left\| \cdot \right\| \right)$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 고정점 $\overline{x}$ 이 주어져 있다고 할 때, 그 근방의 안정성을 파악하기 위해서는 선형화라는 방법이 필수적으로 동원된다. 시스템을 전체적으로 보았을 땐 고정점 근처에서는 선형으로 보고 분석하</description>
    </item>
    
    <item>
      <title>슈바르츠 공간과 슈바르츠 함수</title>
      <link>https://freshrimpsushi.github.io/posts/schwartz-space-and-schwartz-fuction/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schwartz-space-and-schwartz-fuction/</guid>
      <description>정의 아래의 두 조건을 만족하는 함수 $\phi : \mathbb{R}^{n} \to \mathbb{C}$들의 집합을 슈바르츠 공간Schwartz space이라 하고 $\mathcal{S}(\mathbb{R}^{n})$로 표기한다. 슈바르츠 공간의 원소 $\phi$를 슈바르츠 함수Schwartz function라 한다. (a) $\phi \in $ $C^{\infty}$ (b) 모든 멀티 인덱스 $\alpha$, $</description>
    </item>
    
    <item>
      <title>3차원 공간의 곡선 좌표계</title>
      <link>https://freshrimpsushi.github.io/posts/cuvilinear-coordinates-system-for-3-dimensional-euclidiean-space/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cuvilinear-coordinates-system-for-3-dimensional-euclidiean-space/</guid>
      <description>빌드업 3차원 공간에서 위치를 표현하는 가장 일반적인 방법은 데카르트 좌표계이다. 데카르트에 의해서 고안되었기 때문에 붙은 이름이며 직교 좌표계라고도 많이 부른다. 하지만 특정한 상황에서는 데카르트 좌표계로 위치를 표현하기 어려울 수 있다. 예를 들어 2차원 평면에서 회전운동 하는 물체가 있다고 하자. 그러면 이 물체의 위치는 $(x,y)$로 표</description>
    </item>
    
    <item>
      <title>곡선 좌표계의 스케일 팩터</title>
      <link>https://freshrimpsushi.github.io/posts/scale-factor-in-cuvilinear-coordinates-system/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scale-factor-in-cuvilinear-coordinates-system/</guid>
      <description>빌드업 곡선 좌표계에서 스케일 팩터는 각 성분이 길이 차원을 갖도록 곱해주는 요소이다. 예를 들어 극 좌표계는 $(r,\theta)$로 표현되는데 $\theta$가 변할 때 마다 좌표가 움직이는 거리는 호의 길이인 $l=r\theta$이다. 여기서 $r$과 같은 것들을 스케일 팩터라고 부른다. 임의의 좌표계의 변수가 $(q_{1},q_</description>
    </item>
    
    <item>
      <title>약 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/weak-derivatives/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weak-derivatives/</guid>
      <description>빌드업 초함수의 미분을 정의하는 아이디어를 떠올려보자. $u \in {L}_{\mathrm{loc}}^1(\Omega)$에 대해서 정칙 초함수 $T_{u}$가 존재한다. $u$가 미분 가능하다면 부분적분법에 의해 다음의 식이 성립하여, $T_{u}$의 도함수를 $u$의 도함수인 $u&#39;$에 대응되는 $T_{u&#39;}$으로 정의했다</description>
    </item>
    
    <item>
      <title>초함수의 곱의 미분법</title>
      <link>https://freshrimpsushi.github.io/posts/product-rule-for-derivatives-of-distribution/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/product-rule-for-derivatives-of-distribution/</guid>
      <description>정리1 $T\in D^{\ast}$를 초함수, $f \in C^{\infty}$를 스무스 함수라고 하자. 그러면 아래의 식이 성립한다. $$ (fT)&#39;= f&amp;rsquo;T+fT&#39; $$ 설명 기존의 곱의 미분법과 찰떡같이 잘 맞으니 초함수의 미분과 초함수의 곱이 그럴듯하게 정의됐음을 느낄 수 있다. 증명 초함수 미분과 곱의 정의에 의해 다음이 성립한다. $$ \begin{align*} D( fT (\phi) ) &amp;amp;= D( T(f\phi) ) \\ &amp;amp;= T\left( (f\phi)&#39; \right) \\ &amp;amp;= T(f&#39;\phi+f\phi&#39;) \\ &amp;amp;=</description>
    </item>
    
    <item>
      <title>초함수의 스무스 함수와의 곱셈</title>
      <link>https://freshrimpsushi.github.io/posts/multiplication-of-regular-distribution-by-smooth-function/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplication-of-regular-distribution-by-smooth-function/</guid>
      <description>빌드업 초함수는 정의역이 함수공간이기 때문에 실수 공간에서 정의된 함수와 곱셈을 할 수 없다. 하지만 정칙 초함수의 경우 대응되는 국소 적분 가능한 함수 $u\in L_{\mathrm{loc}}^{1}$가 있어서 아래와 같이 표현된다. $$ T_{u}(\phi)=\int u(x)\phi (x) dx,\quad \phi \in \mathcal{D} $$ 따라서 $u$에 가해지는 어떤 작용 $S$에 의해 $Su=u&#39;$을 얻을 수 있을텐데 여전히 $u</description>
    </item>
    
    <item>
      <title>놈 공간에서의 수열의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-normed-space/</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-normed-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **$x_{n} \text{ converges in norm to } x $ $(X,| \cdot | )$를 놈 공간, $\left\{ x_{n} \right\}$을 $X$에서의 수열이라고 하자. $$ | x-x_{n}|\to 0 \text{ as } n \to \infty ,\quad x\in X $$ 를 만족하면 수열 $\left\{ x_{n} \right\}$이 $x$로 놈 수렴한다 고 하고 아래와 같이 나타낸다. $$ x_{n} \to x \text { as } n \to \infty,\quad x=\lim \limits_{n\to\infty}x_{n} $$ 놈 공간에서의 수렴임이 약속된</description>
    </item>
    
    <item>
      <title>초함수의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-of-distribution/</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-of-distribution/</guid>
      <description>정의1 $D^{\ast}$를 초함수 공간, $\left\{ T_{n} \right\}$를 $D^{\ast}$에서의 초함수열이라고 하자. 모든 테스트 함수 $\phi$에 대해서 아래의 식이 성립하면 $\left\{ T_{n} \right\}$이 $T$로 약 수렴weak convergence한다고 한다. $$ T_{n}(\phi) \to T(\phi) ,\quad \forall \phi \in \mathcal{D} $$ 설명 초함수의 수렴을 약수렴이라고 명명하는</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서 약 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/weak-convergence-in-hilbert-space/</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weak-convergence-in-hilbert-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $(H,\langle \cdot \rangle ) $가 힐베르트 공간, $\left\{ x_{n} \right\}$이 $H$에서의 수열이라고 하자. 모든 $y\in H$에 대해서 아래의 식이 성립할 때 $\left\{ x_{n} \right\}$이 $x$로 약하게 수렴 $(\text{converge weakly})$한다고 말하고 $x_{n} \rightharpoonup x$라고 나타낸다. $$ \langle x_{n}, y \rangle \to \langle x , y \rangle ,\quad \forall y\in H $$ weak의 w</description>
    </item>
    
    <item>
      <title>전미분, 완전미분</title>
      <link>https://freshrimpsushi.github.io/posts/total-differential/</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/total-differential/</guid>
      <description>정의 다변수 함수 $f : \mathbb{R}^{n} \to \mathbb{R}$가 주어졌다고 하자. 변수 $\mathbf{x} = (x_{1}, x_{2}, \dots, x_{n})$의 변화에 따른 $f(\mathbf{x})$의 변화를 다음과 같이 $df$로 표기하고 이를 $f$의 전미분total differential 혹은 완전미분exact differential이라 한다. $$ \begin{equation} df = \frac{ \partial f}{ \partial x_{1} }dx_{1} + \frac{ \partial f}{ \partial x_{2} }dx_{2} + \cdots + \frac{ \partial f}{</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 벡터 함수의 다이벌전스(발산)</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-of-fector-function-in-cartesian-cooridenates-system/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-of-fector-function-in-cartesian-cooridenates-system/</guid>
      <description>정의 벡터 함수 $\mathbf{F}(x,y,z)=F_{x}\hat{\mathbf{x}}+F_{y}\hat{\mathbf{y}} + F_{z}\hat{\mathbf{z}}$에 대해서 다음과 같은 스칼라값을 $\mathbf{F}$ 다이벌전스divergence라고 정의하고 $\nabla \cdot \mathbf{F}$라고 표기한다. $$ \begin{equation} \nabla \cdot \mathbf{F} := \frac{ \partial F_{x}}{ \partial x} + \frac{ \partial F_{y}}{ \partial y }+ \frac{ \partial F_{z}}{ \partial z} \label{divergence} \end{equation} $$ 기하학적으로 $\nabla \cdot \mathbf{F}&amp;gt;0$이면 $\mathbf{F}$</description>
    </item>
    
    <item>
      <title>원통 좌표계의 변수로 r, 세타를 쓰면 안되는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/reason-not-to-use-rtheta-as-a-variable-in-the-cylindrical-coordinate-system/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reason-not-to-use-rtheta-as-a-variable-in-the-cylindrical-coordinate-system/</guid>
      <description>극좌표계와 원통좌표계의 차이 원통 좌표계는 아래와 같이 3차원 공간의 점을 $(\rho,\phi,z)$로 표현하는 좌표계를 말한다. 그런데 원통 좌표계를 $(r,\theta, z)$와 같이 표기한 것을 볼 수 있다. 극좌표계 $(r,\theta)$에서 높이 $z$가 추가되었으니 아무 생각 없이 $(r,\theta, z)$와 같이 표기한 것으로 보이는데 이는 각 기호의 의미를 생각</description>
    </item>
    
    <item>
      <title>초함수의 미분</title>
      <link>https://freshrimpsushi.github.io/posts/differentiation-of-a-distribution/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/differentiation-of-a-distribution/</guid>
      <description>빌드업 초함수는 정의역이 함수공간이기 때문에 실수 공간에서 정의된 함수와 같은 식으로 미분을 할 수 있는 건 아니다. 하지만 정칙 초함수의 경우 대응되는 국소 적분 가능한 함수 $u\in L_{\mathrm{loc}}^{1}$가 있어서 아래와 같이 표현된다. $$ T_{u}(\phi) =\int u(x)\phi(x) dx,\quad \phi \in \mathcal{D} $$ 따라서 $u$에 가해지는 어떤 작용 $S$에 의해 $Su=u^{\pri</description>
    </item>
    
    <item>
      <title>코시 분포: 모평균이 존재하지 않는 분포</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-distribution/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-distribution/</guid>
      <description>정의 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $C$ 를 코시 분포라고 한다. $$ f(x) = {1 \over \pi} {1 \over {x^2 + 1}} \qquad , x \in \mathbb{R} $$ 설명 모든 확률 분포가 평균과 분산을 가질 것 같지만 실제로는 그렇지 않다. 그 대표적인 예시가 코시 분포로, 언뜻 정규 분포와 닮았지만 양쪽 꼬리가 두꺼운 모양을 하고 있다. 모수에 무관하게 적률생성함수가 존재하지 않으니 모평균이든 모</description>
    </item>
    
    <item>
      <title>디랙 델타 함수는 정칙 초함수가 아님을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-dirac-delta-function-is-not-regular-distribution/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-dirac-delta-function-is-not-regular-distribution/</guid>
      <description>정리1 $$ \delta (\phi) := \phi (0), \quad \phi \in \mathcal{D} $$ 위와 같이 정의된 디랙 델타 함수는 정칙 초함수가 아니다. 정칙 초함수가 아닌 초함수를 특이 초함수singular distribution라고 한다. 설명 정칙 초함수란 대응되는 국소 적분 가능한 함수 $u$가 있어서 아래와 같이 정의되는 초함수를 말한다. $$ T_{u}(\phi) := \int u(x) \phi (x) dx,\quad \phi \in \mathcal{D} $$ 디랙 델타 함수가 정칙 초함수가</description>
    </item>
    
    <item>
      <title>디랙 델타 함수의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transform-of-dirac-delta-function/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transform-of-dirac-delta-function/</guid>
      <description>공식 디랙 델타 함수 $\delta (x)$의 푸리에 변환은 다음과 같다. $$ \mathcal{F}[\delta] (\xi) = 1 $$ 증명 $$ \begin{align*} \mathcal{F}[\delta] (\xi) &amp;amp;= \int_{-\infty}^{\infty} \delta(x)e^{-i\xi x}dx \\ &amp;amp;= \int _{-\infty} ^{\infty} \delta(x) e^{0}dx \\ &amp;amp;= \int _{-\infty} ^{\infty} \delta(x) dx \\ &amp;amp;=1 \end{align*} $$ ■</description>
    </item>
    
    <item>
      <title>자율 시스템의 오빗</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-of-autonomous-system/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-of-autonomous-system/</guid>
      <description>정의 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 플로우를 $x(t,t_{0},x_{0})$ 와 같이 나타낸다고 하자. 그러면 $x_{0} \in X$ 를 지나는 오빗Orbit$O(x_{0})$ 을 다음과 같이 나타낸다. 1 $$ O(x_{0}) := \left\{ x \in X : x = x(t, t_{0} , x_{0}) \right\} $$ 2. 오빗이 모든 $t \in \mathbb{R}$ 에 대해 다음을 만족시키는 $T &amp;gt;</description>
    </item>
    
    <item>
      <title>초함수의 다일레이션</title>
      <link>https://freshrimpsushi.github.io/posts/dilation-of-a-distribution/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dilation-of-a-distribution/</guid>
      <description>빌드업 초함수는 정의역이 함수공간이기 때문에 실수 공간에서 정의된 함수와 같은 식으로 다일레이션을 할 수 있는 건 아니다. 하지만 정칙 초함수의 경우 대응되는 국소 적분 가능한 함수 $u\in L_{\mathrm{loc}}^{1}$가 있어서 아래와 같이 표현된다. $$ T_{u}(\phi) =\int u(x)\phi(x) dx,\quad \phi \in \mathcal{D} $$ 따라서 $u$에 가해지는 어떤 작용 $S$에 의해 $Su=u&#39;$을</description>
    </item>
    
    <item>
      <title>특성 함수</title>
      <link>https://freshrimpsushi.github.io/posts/characteristic-function/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/characteristic-function/</guid>
      <description>정의 $A \subset X$에 대해서 아래와 같이 정의되는 함수 $\chi_{A} : X \to Y$를 특성함수 라 한다. $$ \chi _{A}(x) := \begin{cases} 1, &amp;amp; x\in A \\ 0 ,&amp;amp; x \notin A \end{cases} $$ 설명 $\chi$는 그리스 문자 카이이다. 학창시절 수학 선생님이 엑스를 $\chi$로 쓰면 안되고 $x$로 써야한다고 말씀하신 이유는 말 그대로 $\chi$는 엑스가 아니기 때문이다. 특히 위와 같이 강력한 의미를 갖고 있</description>
    </item>
    
    <item>
      <title>t-분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-t-distribution/</link>
      <pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-t-distribution/</guid>
      <description>공식 $X \sim t (\nu)$ 이면 $$ E(X) = 0 \qquad , \nu &amp;gt;1 \\ \text{Var}(X) = {{ \nu } \over { \nu - 2 }} \qquad , \nu &amp;gt; 2 $$ 유도 전략: t-분포 역시 카이제곱분포와 비슷하게 적률 공식이 알려져 있어, 이 공식들을 이용한다. t-분포의 적률: 두 확률 변수 $W,V$ 가 독립이고 $W \sim N(0,1)$, $V \sim \chi^{2} (r)$ 이라 하자. $k &amp;lt; r$ 이면 $\displaystyle T := { {W} \over {\sqrt{V/r} } }$ 는 $k$차 적률이 존재하고 $$ E T^{k} = E W^{k} {{ 2^{-k/2} \Gamma \left( {{ r } \over { 2</description>
    </item>
    
    <item>
      <title>리만 함수 방정식과 리만 제타 함수의 자명근</title>
      <link>https://freshrimpsushi.github.io/posts/trivial-root-of-riemann-zeta-function/</link>
      <pubDate>Fri, 18 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trivial-root-of-riemann-zeta-function/</guid>
      <description>공식 다음을 리만 함수 방정식이라 한다. $$ \zeta(s) = 2^{s} \pi^{s - 1} \sin \left( {{ \pi s } \over { 2 }} \right) \Gamma (1-s) \zeta (1-s) $$ $\Gamma$ 는 감마 함수다. $\zeta$ 는 리만 제타 함수다. 설명 리만 함수 방정식에서 $s \in 2 \mathbb{Z}$ 이면 $\displaystyle \sin \left( {{ \pi s } \over { 2 }} \right) = 0$ 이므로 당연히 $\zeta (s) = 0$ 일 것 같다. 그러나 $s = 0$ 일 때는 우변에 $\zeta (1 - 0)$ 이 나오기 때문에 근이고 뭐고 아예 정의가 되지 않으며, $s &amp;gt; 0$ 일 때는 바</description>
    </item>
    
    <item>
      <title>초함수로 엄밀하게 정의되는 디랙 델타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/dirac-delta-function-strictly-dfined-as-distributiona/</link>
      <pubDate>Thu, 17 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirac-delta-function-strictly-dfined-as-distributiona/</guid>
      <description>정의1 테스트 함수 공간 $\mathcal{D}(\mathbb{R}^{n})$의 범함수 $\delta_{a} : \mathcal{D} \to \mathbb{C}$를 아래와 같이 정의하고 디랙 델타 함수라 부르자. $$ \delta_{a}(\phi):=\phi(a) $$ 그러면 디랙 델타 함수는 초함수가 된다. $a=0$이면 다음과 같이 간단히 나타낸다. $$ \delta=\delta_{0} $$ 설명 발산하는 값을 가지고 있어 함수가 아니지만 대충 함수라고 두고</description>
    </item>
    
    <item>
      <title>t-분포</title>
      <link>https://freshrimpsushi.github.io/posts/t-distribution/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/t-distribution/</guid>
      <description>정의 자유도 $\nu &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $t \left( \nu \right)$ 를 t-분포라고 한다. $$ f(x) = {{ \Gamma \left( {{ \nu + 1 } \over { 2 }} \right) } \over { \sqrt{\nu \pi} \Gamma \left( {{ \nu } \over { 2 }} \right) }} \left( 1 + {{ x^{2} } \over { \nu }} \right)^{- {{ \nu + 1 } \over { 2 }}} \qquad ,x \in \mathbb{R} $$ $\Gamma (\nu)$ 는 감마 함수다. 설명 t-분포는 지금도 맥주로 유명한 기네스 양조 공장에서 일하던 윌리엄 고셋Willi</description>
    </item>
    
    <item>
      <title>국소 적분가능</title>
      <link>https://freshrimpsushi.github.io/posts/locally-integrable/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/locally-integrable/</guid>
      <description>국소 적분가능함은 다음과 같이 여러 스테이트로 표현할 수 있다. 다 같은 말이다. 정의1 함수 $u$가 열린집합 $\Omega \subset \mathbb{R}^n$상의 거의 어디에서나 정의된 함수라고 하자. 모든 열린 집합 $U \Subset \Omega$에 대해서 $u \in L^1(U)$일 때 $u$를 $\Omega$위에서 국소 적분 가능 다고 말하며 다음과 같이 표기한다. $$ u \in</description>
    </item>
    
    <item>
      <title>모든 국소 적분 가능한 함수는 초함수로 확장 가능함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-every-locally-integrable-function-can-be-treated-as-a-distribution/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-every-locally-integrable-function-can-be-treated-as-a-distribution/</guid>
      <description>정리1 모든 $u \in L_{\mathrm{loc} }^1(\Omega) $에 대응하여 다음과 같이 정의되는 초함수 $T_u \in D^{\ast}(\Omega)$가 존재한다. $$ T_u (\phi) := \int_{\Omega} u(x)\phi(x)dx, \quad \phi \in D(\Omega) $$ 설명 $\mathcal{D}(\Omega)$는 테스트 함수 공간이다. 위와 같이 정의되는 초함수를 정칙 초함수regular distribution라 한다. 또한 위 식은 내적 공간의 관점에</description>
    </item>
    
    <item>
      <title>초함수, 일반화된 함수</title>
      <link>https://freshrimpsushi.github.io/posts/distribution-generalized-function/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distribution-generalized-function/</guid>
      <description>정의1 2 $\Omega \subset \mathbb{R}^{n}$가 열린 집합이라고 하자. 테스트 함수 공간의 연속인 선형 범함수 $T : \mathcal{D}(\Omega) \to \mathbb{C}$를 초함수distribution라고 정의한다. 즉 초함수는 테스트 함수 공간의 듀얼 스페이스의 원소이다. 따라서 $$ T \in \mathcal{D}^{\ast} $$ 와 같이 표기하고 $D^{\ast}$를 (슈바르츠) 초함수 공간(S</description>
    </item>
    
    <item>
      <title>초함수의 트랜슬레이션</title>
      <link>https://freshrimpsushi.github.io/posts/translation-of-a-distribution/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/translation-of-a-distribution/</guid>
      <description>빌드업 초함수는 정의역이 함수공간이기 때문에 실수 공간에서 정의된 함수와 같은 식으로 트랜슬레이션을 할 수 있는 건 아니다. 하지만 정칙 초함수의 경우 대응되는 국소 적분 가능한 함수 $u\in L_{\mathrm{loc}}^{1}$가 있어서 아래와 같이 표현된다. $$ T_{u}(\phi) =\int u(x)\phi(x) dx,\quad \phi \in \mathcal{D}(\mathbb{R}^{n}) $$ 따라서 $u$에 가해지는 어떤 작용 $S$에 의해 $Su=u&#39;$</description>
    </item>
    
    <item>
      <title>테스트 함수 공간에서의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-test-function-space/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-test-function-space/</guid>
      <description>테스트 함수 공간에서는 &amp;lsquo;수렴&amp;rsquo;을 특별하게 정의한다. 어떤 공간 $X$가 주어졌을 때 $X$에서 정의된 놈이나 거리를 이용해서 수렴을 정의하는것이 보통이다. 하지만 테스트 함수 공간에서는 초함수를 잘 정의하고 다룰 수 있도록 더 강력한 조건으로 수렴을 정의한다. 정의 $\Omega \subset \mathbb{R}^n$가 열린 집합, $\left\{ \phi</description>
    </item>
    
    <item>
      <title>테스트 함수와 테스트 함수 공간</title>
      <link>https://freshrimpsushi.github.io/posts/test-function-space/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/test-function-space/</guid>
      <description>정의1 열린 집합 $\Omega \subset \mathbb{R}^{n}$와 함수 $\phi : \Omega \to \mathbb{C}$가 주어졌다고 하자. $\phi$가 무한히 미분 가능하고, 그 도함수들이 전부 연속이며, 컴팩트 서포트를 가지면 테스트 함수test function라 한다. 테스트 함수들의 함수 공간을 $C_{c}^{\infty}(\Omega)$ 혹은 간단하게 $\mathcal{D}(\Omega</description>
    </item>
    
    <item>
      <title>델타 함수의 역사와 디랙이 델타 함수를 사용한 이유</title>
      <link>https://freshrimpsushi.github.io/posts/history-of-dirac-delta-function/</link>
      <pubDate>Tue, 15 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/history-of-dirac-delta-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **델타 함수의 역사123 델타 함수는 19세기 초반 푸아송(1815), 푸리에(1822), 코시(1823, 1827) 등 수학, 물리학에 지대한 업적을 남긴 학자들의 작업물에서부터 나타나기 시작했다. 다만 이 당시에는 델타 함수를 현재와 같이 수학적으로 엄밀하게 정의하는데 집중한 것은 아니었</description>
    </item>
    
    <item>
      <title>functional이 functional로 이름지어진 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-functional-is-named-functional/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-functional-is-named-functional/</guid>
      <description>functional의 어원 함수 해석학은 영어로 functional analysis이다. function analysis도 아니고 functional이 대체 뭘까? 우선 단어를 살펴보면 function+al으로 구성된 것으로 보인다. 즉 함수의 형용사형처럼 보이고 이런 느낌으로 해석해보면 functional은 &amp;lsquo;함수적인 (것)&amp;rsquo</description>
    </item>
    
    <item>
      <title>리만 자이 함수</title>
      <link>https://freshrimpsushi.github.io/posts/riemann-xi-function/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riemann-xi-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $\xi$ 를 리만 자이 함수Riemann xi Function라고 한다. $$ \xi (s) := {{ 1 } \over { 2 }} s ( s-1) \pi^{-s/2} \zeta (s) \Gamma \left( {{ s } \over { 2 }} \right) $$ $\zeta$ 는 리만 제타 함수다. $\Gamma$ 는 감마 함수다. 설명 리만 자이 함수는 원래 이와 다른 조금 형태로 정의되어있었으나, 에드문트 란다우Edmund Landau 에 의해 소문자 자이 $\xi$ 로 다시 정의되고 원래 리만</description>
    </item>
    
    <item>
      <title>독립인 정규 분포와 카이제곱 분포에서 스튜던트 t-분포 유도 </title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-t-distribution-from-independent-chi-squared-and-normal-distribution/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-t-distribution-from-independent-chi-squared-and-normal-distribution/</guid>
      <description>정리 두 확률 변수 $W,V$ 가 독립이고 $W \sim N(0,1)$, $V \sim \chi^{2} (r)$ 이라 하면 $$ \displaystyle T = { {W} \over {\sqrt{V/r} } } \sim t(r) $$ $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. $\chi^{2} \left( r \right)$ 은 자유도 $r$ 인 카이제곱 분포다. $t(r)$ 은 자유도 $r$ 인 t-분포다. 설명 어떤 분포에서 다른 분포를 유도하는 것은 공부만 열심히 하면 직관적인 추측이 가능하다. 하지만 둘 이상의 분포에서 다른 분포를 유도해낸</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 스칼라 함수의 그래디언트(기울기)</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-of-scalar-function-in-cartesian-coordinate-system/</link>
      <pubDate>Sat, 12 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-of-scalar-function-in-cartesian-coordinate-system/</guid>
      <description>정의 3변수 스칼라 함수 $f=f(x,y,z)$의 그래프의 각 점에서 기울기와 증가하는 방향을 나타내는 벡터를 $\nabla f$라고 표기하며 그래디언트gradient라고 부른다. $$ \mathrm{grad}f=\nabla f = \frac{ \partial f}{ \partial x }\hat{\mathbf{x}}+\frac{ \partial f}{ \partial y}\hat{\mathbf{y}}+\frac{ \partial f}{ \partial z}\hat{\mathbf{z}} $$ 설명 그래디언트는 기울기, 구배, 물매 등으로 번역된다. 구매, 물매는 그래디언트의 옛날식 번역이고 최근에는 잘 쓰이지 않는</description>
    </item>
    
    <item>
      <title>완벽 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/perfect-graph/</link>
      <pubDate>Sat, 12 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/perfect-graph/</guid>
      <description>정의 그래프 $G$ 의 모든 유도서브그래프 $H$ 가 다음을 만족하면 완벽 그래프라 한다. $$ \chi (H) = \omega (H) $$ $\chi (H)$ 는 그래프 $H$ 의 크로마틱 수다. $\omega (H)$ 는 그래프 $H$ 의 클리크 수다. 설명 그래프 이론의 세계는 수학의 많은 분과가 그러하듯 어마어마하게 넓은데, 솔직히 조금은 더 넓다고 말하고 싶다. 그래프에서 버텍스와 에지를 정의하는 방법이 너무 다양하기 때문이다. 영</description>
    </item>
    
    <item>
      <title>표준정규분포의 제곱은 자유도가 1인 카이제곱분포를 따름을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/squared-standard-normal-distribution-is-chi-squared-distribution/</link>
      <pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/squared-standard-normal-distribution-is-chi-squared-distribution/</guid>
      <description>정리 $X \sim N(\mu,\sigma ^2)$면 $$ \displaystyle V=\left( { X - \mu \over \sigma} \right) ^2 \sim \chi ^2 (1) $$ $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. $\chi^{2} \left( 1 \right)$ 은 자유도 $1$ 인 카이제곱 분포다. 설명 정리로는 이를 일반화시킨 스튜던트의 정리가 많이 쓰인다. 통계학을 공부하는 사람이라면 표준정규분포의 제곱이 카이제곱분포를 따른다는 것은 팩트로써 항상 당연하게 알고 있어야한다. 어떤</description>
    </item>
    
    <item>
      <title>정규 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-normal-distribution/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-normal-distribution/</guid>
      <description>공식 $X \sim N\left( \mu , \sigma^{2} \right)$ 면 $$ E(X) = \mu \\ \text{Var} (X) = \sigma^{2} $$ 유도 전략: 정규 분포는 적률생성함수가 미분하기 쉬우니 그냥 바로 직접연역한다. 정규 분포의 적률생성함수: $$ m(t) = \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) \qquad , t \in \mathbb{R} $$ $$ m&#39;(t) = \left( \mu + \sigma^{2} t \right) \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) $$ 이므로 $E(X) = m&#39;(0) = \mu$ 이고 $$ m&#39;&#39;(t) = \left( 0 + \sigma^{2} \right) \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) + \left( \mu +</description>
    </item>
    
    <item>
      <title>결합 진동</title>
      <link>https://freshrimpsushi.github.io/posts/coupled-oscillation/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coupled-oscillation/</guid>
      <description>단순 결합 진동 두 물체 $m_{1}$, $m_{2}$가 위 그림과 같이 2개의 스프링으로 연결되어 있다고 하자. 그리고 물체 $m_{1}$이 평형점으로부터 떨어진 거리를 $x_{1}$, 물체 $m_{2}$가 평형점으로부터 떨어진 거리를 $x_{2}$라고 하자. 스프링이 물체에 작용하는 복원력은 용수철 상수와 용수철이 늘어난(줄어든)길이의 곱이므로 용수철1이 물</description>
    </item>
    
    <item>
      <title>다중 스프링 진동</title>
      <link>https://freshrimpsushi.github.io/posts/multiple-springs-oscillation/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiple-springs-oscillation/</guid>
      <description>스프링이 물체의 양쪽에 연결된 경우 $x$를 물체가 이동한 거리라고 하자. 스프링의 복원력은 $-kx$이므로 물체는 왼쪽 스프링으로부터 $-k_{1}x$, 오른쪽 스프링으로부터 $-k_{2}x$의 힘을 받는다. 따라서 운동 방정식은 다음과 같다. $$ \begin{align*} &amp;amp;&amp;amp; m\ddot{x}&amp;amp;=-k_{1}x-k_{2}x \\ \implies &amp;amp;&amp;amp;m\ddot{x}+(k_{1}+k_{2})x&amp;amp;=0 \\ \implies &amp;amp;&amp;amp; \ddot{x}+\frac{k_{1}+k_{2}}{m}x &amp;amp;=0 \end{align*} $$ 이는 단순 조화 진동의 방정식과 같으므로 해는 아래와 같다. $$ \begin{align*} x(t) &amp;amp;= A\cos(\omega_{p} t + \phi) \end{align*}</description>
    </item>
    
    <item>
      <title>유체와 유체역학의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-fluid-and-fluid-mechanics/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-fluid-and-fluid-mechanics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 유체 란?$(a)$ 액체와 기체를 합쳐서 부르는 말$(b)$ 정지상태에서는 수직 응력이 작용하고, 유동 상태에서는 전단력이 미치면 연속적으로 변형이 일어나서 흐르는 물질1 정의라고는 하나 그렇게 엄밀한 것은 아니다. 하지만 엄밀한 정의를 들이밀지 않아도 우리는 유체가 무엇인지 안다. 그거면</description>
    </item>
    
    <item>
      <title>리눅스에서 gcc 컴파일러로 c 코드 컴파일 하는 법 </title>
      <link>https://freshrimpsushi.github.io/posts/how-to-compile-c-code-using-gcc-in-linux/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-compile-c-code-using-gcc-in-linux/</guid>
      <description>가이드 보통 C/C++을 이용한 프로그램 개발은 윈도우에서 비주얼 스튜디오를 쓰는 것이 권장되나, 간단한 테스트나 수치계산, 시뮬레이션 등을 리눅스로 진행할 때는 리눅스 특유의 가벼움이 큰 장점으로 다가올 때가 있다. 가령 infection\_modified\_200428.c이라는 c 소스코드가 있다면, 터미널에서 해당 경로로 이동</description>
    </item>
    
    <item>
      <title>물리진자</title>
      <link>https://freshrimpsushi.github.io/posts/physical-pendulum/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/physical-pendulum/</guid>
      <description>정의1 강체가 고정된 수평축을 중심으로 중력에 의해서 흔들릴 때 이를 물리진자physical pendulum라고 한다. 물리진자 진자 운동은 조화 진동의 한 종류이다. 질량 중심에 작용하는 토크의 크기는 다음과 같다. $$ \begin{align*} N &amp;amp;=\left| \mathbf{r} \times \mathbf{F} \right| \\ &amp;amp;= rF\sin\theta \\ &amp;amp;=lmg \sin\theta \end{align*} $$ 토크를 관성 모멘트로 표현하면 $N=I \dot{\omega}=I\ddot{\theta}$ 이므로 아래와 같은 운동 방정식을 얻는다. $$ \begin{align*} &amp;amp;&amp;amp; I\ddot{\theta} &amp;amp;= mgl\sin</description>
    </item>
    
    <item>
      <title>수학에서 자주 쓰이는 기호와 줄임말</title>
      <link>https://freshrimpsushi.github.io/posts/symbols-and-abbreviations-frequently-used-in-mathematics/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/symbols-and-abbreviations-frequently-used-in-mathematics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 예문 1-3: 거리공간에서 수열의 수렴 $$ \forall \varepsilon&amp;gt;0,\ \exists N \in \mathbb{N}\quad \mathrm{s.t}\ n\ge N \implies d(p_{n},p) &amp;lt; \varepsilon $$ For every $\varepsilon&amp;gt;0$, there is an natural number N such that $n\ge N$ implies that $d(p_{n},p)&amp;lt;\varepsilon$.모든 양의 실수 $\varepsilon$에 대해서, $n$이 어떤 자연수수 $N$보다 크기만 하면 $d(p_{n},p)</description>
    </item>
    
    <item>
      <title>멀티레졸루션 아날리시스</title>
      <link>https://freshrimpsushi.github.io/posts/multiresolution-analysis/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiresolution-analysis/</guid>
      <description>정의 $L^{2}(\mathbb{R})$의 닫힌 부분공간들의 수열 $\left\{V_{j}\right\}_{j \in \mathbb{Z}}$와 함수 $\phi \in V_{0}$가 아래의 조건을 만족하면 $\left( \left\{ V_{j} \right\}, \phi \right)$를 멀티레졸루션 아날리시스multiresolution analysis 라 한다. (a) 각 $V_{j}$에 대해서 $\cdots V_{-1} \subset V_{0} \subset V_{1}\cdots$가 성립한다. (b)</description>
    </item>
    
    <item>
      <title>멀티레졸루션 아날리시스 스케일링 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/scaling-equation-in-multiresolution-analysis/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scaling-equation-in-multiresolution-analysis/</guid>
      <description>정리 함수 $\phi \in L^{2}(\mathbb{R})$가 멀티레졸루션 아날리시스를 생성한다고 하자. 그러면 아래의 식을 만족하는 주기가 $1$인 함수 $H_{0}\in L^{2}(0,1)$가 존재한다. $$ \begin{equation} \hat{\phi}(2\gamma) = H_{0}(\gamma)\hat{\phi}(\gamma),\quad \gamma \in \mathbb{R} \label{eq1} \end{equation} $$ 이를 스케일링 방정식scaling- equation이라 한다. 여기서 $\hat{\phi}(\gamma)$는 $</description>
    </item>
    
    <item>
      <title>매트랩에서 작업공간 초기화, 모든 변수 제거하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/work-space-clear-in-matlab/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/work-space-clear-in-matlab/</guid>
      <description>방법 clear 명령어 명령창에 clear를 입력하면 작업 공간이 초기화 된다. 작업 공간 지우기(Alt+T+O) 작업 공간 창을 마우스 우클릭하면 &amp;lsquo;작업 공간 지우기(O)&amp;rsquo; 를 선택할 수 있다. 누르면 작업 공간이 초기화된다. 이는 단축키 Alt+T+O로도 실행할 수 있으며 편집기를 띄워놓은 상태에서는 안된다. 직접 선택해</description>
    </item>
    
    <item>
      <title>정규분포</title>
      <link>https://freshrimpsushi.github.io/posts/normal-distribution/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normal-distribution/</guid>
      <description>정의 평균 $\mu \in \mathbb{R}$ 과 분산 $\sigma^{2} &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $N \left( \mu,\sigma^{2} \right)$ 를 정규 분포Normal Distribution라고 한다. $$ f(x) = {{ 1 } \over { \sqrt{2 \pi} \sigma }} \exp \left[ - {{ 1 } \over { 2 }} \left( {{ x - \mu } \over { \sigma }} \right)^{2} \right] \qquad, x \in \mathbb{R} $$ 특히 다음과 같은 확률 밀도를 함수를 가지는 정규분포 $N \left( 0,1^{2} \right)$ 를 표준정규분포라고 한다. $$ f(z) = {{</description>
    </item>
    
    <item>
      <title>구좌표계에서의 미소부피</title>
      <link>https://freshrimpsushi.github.io/posts/volume-in-polar-coordinates/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/volume-in-polar-coordinates/</guid>
      <description>공식 구좌표계에서 미소 부피는 아래와 같다. $$ dV=r^{2}\sin\theta dr d\theta d\phi $$ 구 표면 위의 미소 면적은 $dr$을 곱하지 않음으로써 얻을 수 있다. $$ da=\color{blue}{rd\theta} \cdot \color{red}{r\sin\theta d \phi}=r^{2}\sin\theta d\theta d\phi $$ 설명 그림을 통한 이해 구좌표계에서 미소부피는 위 그림에서 보이는 바와 같이 (초록선의 길이)$\times$(파란선의 길이)$\times$(빨간선의 길이)로 나타남을 알 수 있다. 원점에서 세</description>
    </item>
    
    <item>
      <title>극 좌표계에서 미소 면적 원통 좌표계에서 미소 부피</title>
      <link>https://freshrimpsushi.github.io/posts/volume-in-cylindrical-coordinates/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/volume-in-cylindrical-coordinates/</guid>
      <description>공식 극 좌표계에서 미소 면적은 다음과 같다. $$ dA=rdrd\theta $$ 원통 좌표계에서 미소 부피와 원통 표면의 미소 면적은 다음과 같다. $$ dV=\rho d\rho d\phi dz \\ dA=\rho d\phi dz $$ 설명 극 좌표계 $\mathbf{r}=\mathbf{r}(r,\theta)$ 미소 면적은 그림에서와 같이 (초록선의 길이)$\times$(파란선의 길이)이다. 초록색 선은 지름 방향의 미소 변화량이므로 $\color{green}{dr}$이다. 파란색 선</description>
    </item>
    
    <item>
      <title>야코비 세타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/jacobi-theta-function/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jacobi-theta-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $\vartheta$ 를 야코비 세타 함수Jacobi theta Function라고 한다. $$ \vartheta (\tau) := \sum_{n \in \mathbb{Z}} e^{-\pi n^{2} \tau } $$ 설명 야코비 함수는 원래 더 일반적으로 정의될 수 있지만, 보통은 필요한 곳에 따라 그냥 특수한 형태를 쓰는 일이 잦다. 여기서 소개된 야코비 세타 함수 역시 정확한 의미에서 모든 맥락을 커버하지는 못한다는 것에 주의하자. 다음의 성질</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 벡터 함수의 컬(회전)</title>
      <link>https://freshrimpsushi.github.io/posts/curl-of-vector-function-in-cartesian-coordinate-system/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/curl-of-vector-function-in-cartesian-coordinate-system/</guid>
      <description>정의 3차원 벡터 $\mathbf{F}(x,y,z)=(F_{x},F_{y},F_{z})=F_{x}\hat{\mathbf{x}} + F_{y}\hat{\mathbf{y}} + F_{z}\hat{\mathbf{z}}$에 대해서 다음과 같은 벡터를 $\mathbf{F}$의 컬curl이라 정의하고 $\nabla \times \mathbf{F}$라고 표기한다. $$ \begin{align} \nabla \times \mathbf{F} &amp;amp;= \left( \dfrac{ \partial F_{z}}{ \partial y }-\dfrac{ \partial F_{y}}{ \partial z} \right)\hat{\mathbf{x}}+ \left( \dfrac{ \partial F_{x}}{ \partial z }-\dfrac{ \partial F_{z}}{ \partial x} \right)\hat{\mathbf{y}}+ \left( \dfrac{ \partial F_{y}}{ \partial x }-\dfrac{ \partial F_{x}}{ \partial y} \right)\hat{\mathbf{z}} \label{def1} \\ &amp;amp;=\begin{vmatrix} \hat{\mathbf{x}} &amp;amp; \hat{\mathbf{y}} &amp;amp; \hat{\mathbf{z}} \\ \dfrac{ \partial }{ \partial x} &amp;amp; \dfrac{ \partial }{ \partial</description>
    </item>
    
    <item>
      <title>쌍곡함수</title>
      <link>https://freshrimpsushi.github.io/posts/hyperbolic-functions/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hyperbolic-functions/</guid>
      <description>정의 $z \in \mathbb{C}$에 대해서, $$ \begin{align*} \sinh z &amp;amp;:= \frac{e^{z}-e^{-z}}{2} \\ \cosh z &amp;amp;:= \frac{e^{z}+e^{-z}}{2} \\ \tanh z &amp;amp;:= \frac{\sinh z}{\cosh z} \end{align*} $$ $$ \begin{align*} \mathrm{csch}x&amp;amp;=\frac{1}{\sinh x} \\ \mathrm{sech} x&amp;amp;=\frac{1}{\cosh x} \\ \coth x &amp;amp;=\frac{1}{\tanh x} \end{align*} $$ 삼각함수와의 관계 $$ \begin{align*} \sinh (iz) &amp;amp;= i\sin z \\ \sin (iz) &amp;amp;= i\sinh z \\ \cosh (iz) &amp;amp;= \cos z \\ \cos (iz) &amp;amp;= \cosh z \end{align*} $$ 미분 $$ \begin{align*} (\sinh x)&#39; &amp;amp;= \cosh x \\ (\cosh x )&#39; &amp;amp;= \sinh x \\ (\tanh x)&#39; &amp;amp;= \frac{1}{\cosh^{2} x}=\mathrm{sech}^{2}x \end{align*} $$ 항등식 $$ \begin{align*} \sinh(-x) &amp;amp;= -\sinh x \\ \cosh(-x) &amp;amp;= \cosh x \\ \tanh(-x)&amp;amp;=- \tanh x \\ \cosh x + \sinh x &amp;amp;=e^{x} \\ \cosh x - \sinh x &amp;amp;= e^{-x} \\ \cosh^{2}x -\sinh^{2}x</description>
    </item>
    
    <item>
      <title>쌍곡함수의 배각 공식 반각 공식</title>
      <link>https://freshrimpsushi.github.io/posts/square-formulas-and-half-arguments-formulas-for-hyperbolic-functions/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/square-formulas-and-half-arguments-formulas-for-hyperbolic-functions/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **쌍곡함수의 배각공식 $$ \begin{align} \sinh (2x) &amp;amp;= 2\sinh x \cosh x \\ \cosh (2x) &amp;amp;= \cosh^{2} x + \sinh^{2} x \\ &amp;amp;=2\cosh ^{2 } x -1 = 2\sinh ^{2} x +1 \nonumber \\ \tanh (2x) &amp;amp;= \frac{2\tanh x}{1+\tanh^{2}x} \end{align} $$ **쌍곡함수의 반각 공식 $$ \begin{align} \sinh^{2} \frac{x}{2} &amp;amp;=\frac{\cosh x -1 }{2} \\ \cosh^{2} \frac{x}{2} &amp;amp;=\frac{\cosh x +1 }{2} \\ \tanh ^{2} \frac{x}{2} &amp;amp;= \frac{\cosh x -1}{\cosh x +1} \end{align} $$ $$ \begin{align} \sinh \frac{x}{2}&amp;amp;=\frac{\sinh x}{\sqrt{2(\cosh x +1)}} \\ \cosh \frac{x}{2}&amp;amp;=\frac{\sinh x}{\mathrm{sgn}(x)\sqrt{2(\cosh x -1)}} \end{align} $$ $\mathrm{sgn}(x)$는 부호 함수이며 아</description>
    </item>
    
    <item>
      <title>쌍곡함수의 합차 공식과 곱셈 공식</title>
      <link>https://freshrimpsushi.github.io/posts/sum-to-product-identities-and-product-to-sum-identities-for-hyperbolic-funtions/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-to-product-identities-and-product-to-sum-identities-for-hyperbolic-funtions/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **쌍곡함수의 합차 공식 $$ \begin{align} \sinh x +\sinh y &amp;amp;=2\sinh \frac{x+y}{2} \cosh \frac{x-y}{2} \\ \sinh x -\sinh y &amp;amp;=2\sinh \frac{x-y}{2} \cosh \frac{x+y}{2} \\ \cosh x + \cosh y &amp;amp;= 2 \cosh \frac{x+y}{2} \cosh \frac{x-y}{2} \\ \cosh x -\cosh y &amp;amp;= 2 \sinh \frac{x+y}{2}\sinh \frac{x-y}{2} \end{align} $$ **쌍곡함수의 곱셈공식 $$ \begin{align} \sinh x \sinh y &amp;amp;= \frac{\cosh (x+y)-\cosh (x-y)}{2} \\ \sinh x \cosh y &amp;amp;= \frac{\sinh (x+y)+\sinh (x-y)}{2} \\ \cosh x \sinh y &amp;amp;= \frac{\sinh (x+y)-\sinh (x-y)}{2} \\ \cosh x \cosh y &amp;amp;= \frac{\cosh (x+y)+\cosh (x-y)}{2} \end{align} $$ 증명 과정은 삼각함수의 합차 공식을 유도한 것과 같으므</description>
    </item>
    
    <item>
      <title>강제 조화 진동과 공명 진동수</title>
      <link>https://freshrimpsushi.github.io/posts/forced-harmonic-oscillation-and-resonance-frequency/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/forced-harmonic-oscillation-and-resonance-frequency/</guid>
      <description>강제 조화 진동1 물체가 용수철에 매달려 진동하는 것과 같은 운동을 조화 운동이라 한다. 이때 공기저항 등의 마찰력을 포함하는 다른 외력은 존재하지 않고 오로지 용수철 상수 $k$로 인한 복원력만 작용하는 경우를 단순 조화 진동이라 부른다. 마찰력과 같이 속도에 비례하는 외력이 존재하면 감쇠 조화 진동이라 부른다. 여기에 외부에서 주기적인 힘, 구동력d</description>
    </item>
    
    <item>
      <title>독립인 두 카이제곱 분포에서 F-분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-f-distribution-from-two-independent-chi-squared-distribution/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-f-distribution-from-two-independent-chi-squared-distribution/</guid>
      <description>정리 두 확률 변수 $U,V$ 가 독립이고 $U \sim \chi^{2} ( r_{1})$, $V \sim \chi^{2} ( r_{2})$ 이라 하면 $$ {{ U / r_{1} } \over { V / r_{2} }} \sim F \left( r_{1} , r_{2} \right) $$ 설명 두 데이터가 카이제곱 분포를 따르고 독립이라면, 그 비를 분포이론으로 설명할 수 있을지도 모른다.통계학 전반에서는 표준화된 잔차의 제곱이 카이제곱 분포를 따르는 것으로 가정하기 때문에 이 점에 따라 F-검정등을 즐겨쓴다. 증명 자체가</description>
    </item>
    
    <item>
      <title>쌍곡함수의 덧셈정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-sum-of-arguments-of-hyperbolic-function/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-sum-of-arguments-of-hyperbolic-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $$ \begin{align} \sinh (x\pm y) &amp;amp;=\sinh x \cosh y \pm \sinh y \cosh x \\ \cosh (x \pm y) &amp;amp;= \cosh x \cosh y \pm \sinh x \sinh y \\ \tanh{x \pm y}&amp;amp;=\frac{\tanh x \pm \tanh y}{1 \pm \tanh x \tanh y} \end{align} $$ 쌍곡함수와 삼각함수의 관계를 생각해보면 삼각함수의 덧셈정리와 모양이 비슷한 것은 당연하다. 증명 $(1)$ $$ \begin{align*} \sinh (x+y) &amp;amp;= \frac{e^{x+y}-e^{-x-y}}{2} \\ &amp;amp;=\frac{2e^{x+y}-2e^{-x-y}}{4} \\ &amp;amp; =\frac{e^{x+y} \color{red}{-e^{-x+y}} \color{blue}{+e^{x-y}}-e^{-x-y}}{4} +\frac{e^{x+y} \color{red}{+e^{-x+y}} \color{blue}{-e^{x-y}}-e^{-x-y}}{4} \\ &amp;amp; =\frac{(e^{x} -e^{-x})e^{y}+(e^{x}-e^{-x})e^{-y}}{4} +\frac{e^{y}(e^{x}+e^{-x})-e^{-y}(e^{x}+e^{-x})}{4} \\ &amp;amp; = \frac{(e^{x} -e^{-x})(e^{y}+e^{-y})}{4} +\frac{(e^{y}-e^{-y})(e^{x}+e^{-x})}{4} \\ &amp;amp; = \left( \frac{e^{x} -e^{-x}}{2} \right)\left( \frac{e^{y} +e^{-y}}{2} \right) + \left(</description>
    </item>
    
    <item>
      <title>쌍곡함수의 항등식</title>
      <link>https://freshrimpsushi.github.io/posts/identities-of-hyperbolic-functions/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/identities-of-hyperbolic-functions/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $$ \begin{align} \sinh(-x) &amp;amp;= -\sinh x \\ \cosh(-x) &amp;amp;= \cosh x \\ \tanh(-x)&amp;amp;=- \tanh x \\ \cosh x + \sinh x &amp;amp;=e^{x} \\ \cosh x - \sinh x &amp;amp;= e^{-x} \\ \cosh^{2}x -\sinh^{2}x &amp;amp;=1 \end{align} $$ 딱히 증명이랄 것도 없다. 정의로부터 바로 알 수 있는 사실이다. 증명 $(1)$ $$ \begin{align*} \sinh(-x) &amp;amp;= \frac{e^{-x}-e^{x}}{2} \\ &amp;amp;=-\frac{e^{x}-e^{-x}}{2} \\ &amp;amp;=-\sinh x \end{align*} $$ ■ 증명 $(2)$ $$ \begin{align*} \cosh(-x) &amp;amp;= \frac{e^{-x}+e^{x}}{2} \\ &amp;amp;=\frac{e^{x}+e^{-x}}{2} \\ &amp;amp;=\cosh x \end{align*} $$ ■ 증명 $(3)$ $$ \tanh (-x)=\frac{\sinh (-x)}{\cosh (-x)}=\frac{-\sinh x }{\cosh x}=-\tanh x $$ ■ 증명 $(4)$ $$ \begin{align*} \cosh x + \sinh x &amp;amp;= \frac{e^{x}+e^{-x}}{2}+\frac{e^{x}-e^{-x}}{2} \\ &amp;amp;=e^{x} \end{align*} $$ ■ 증</description>
    </item>
    
    <item>
      <title>비파괴검사, 토모그래피, 팬텀</title>
      <link>https://freshrimpsushi.github.io/posts/nondestructive-testing-tomography-phantom/</link>
      <pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/nondestructive-testing-tomography-phantom/</guid>
      <description>비파괴검사 비파괴검사란 어떤 물체를 손상시키지 않으면서 그 물체 내부에서 알고 싶은 정보를 얻어내는 검사 방법을 말한다. 비파괴검사라는 말 자체는 처음 들어봤어도 개념 자체는 굉장히 일상적인 것이다. 사람의 뼈에 금이 갔는지, 간암이 있는지, 뇌경색이 있는지 알 수 있는 확실한 방법은 절개해서 확인해보는 것이지만 이는 현실적으로 불가능하다. 이때 쓰</description>
    </item>
    
    <item>
      <title>컴프턴 카메라의 원리</title>
      <link>https://freshrimpsushi.github.io/posts/principle-of-the-compton-camera/</link>
      <pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/principle-of-the-compton-camera/</guid>
      <description>원리 컴프턴 카메라는 컴프턴 산란을 이용하여 감마선을 내뿜는 물질의 위치를 찾아내는 장치이다. Compton telescope 혹은 Compton imager라고도 한다. 그림의 오른쪽에는 컴프턴 카메라가 간단하게 두 디텍터로 표현돼있다. 디텍터는 감마선의 에너지를 측정하며, 첫번째 디텍터에서는 감마선의 산란이 일어난다. 그림 왼쪽의 검은 사각형은 파괴하지 않고 내부 구조를 파악</description>
    </item>
    
    <item>
      <title>푸아송 합 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-poisson-summation-formula/</link>
      <pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-poisson-summation-formula/</guid>
      <description>공식 $f : \mathbb{R} \to \mathbb{C}$ 가 슈바르츠 함수라고 하자. 그러면 $$ \sum_{n \in \mathbb{Z}} f(n) = \sum_{k \in \mathbb{Z}} \widehat{f}(k) $$ 슈바르츠 함수 $f \in C^{\infty}(\mathbb{R})$ 란 $x \to \pm \infty$ 일 때 함숫값의 크기 $\left| f (x) \right|$ 가 빠르게 $0$ 으로 수렴하는 함수를 말한다. $f$ 와 $\gamma \in \mathbb{R}$ 에 대해 $\widehat{f}(\gamma)$ 는 다음과 같은 푸리에 변환을 나타낸다. $$ \widehat{f} ( \gamma ) = \int_{\mathbb{R}} f(x) e^{2 \pi i \gamma x} dx $$ 증명1 $$ F(x) := \sum_{n \in \mathbb{Z}} f ( x + n ) $$ 이라고 하면 $F$ 는 $1$-피리어딕하</description>
    </item>
    
    <item>
      <title>감마함수와 리만 제타 함수 디리클레 에타 함수와의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-among-gamma-riemann-zeta-dirichlet-eta-functions/</link>
      <pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-among-gamma-riemann-zeta-dirichlet-eta-functions/</guid>
      <description>정리 $\Re (s) &amp;gt; 1$ 이면 $$ \zeta (s) \Gamma (s) = \mathcal{M} \left[ {{ 1 } \over { e^{x} - 1 }} \right] (s) = \int_{0}^{\infty} {{ x^{s-1} } \over { e^{x} - 1 }} dx \\ \eta (s) \Gamma (s) = \mathcal{M} \left[ {{ 1 } \over { e^{x} + 1 }} \right] (s) = \int_{0}^{\infty} {{ x^{s-1} } \over { e^{x} + 1 }} dx $$ $\mathcal{M}$ 은 멜린 변환이다. $\Re (s)$ 는 복소수 $s$ 의 실수부를 나타낸다. 설명 디리클레 에타 함수 $\eta(s)$ 는 리만 제타 함수 $\zeta(s)$ 의 교대 급수인만큼 서로 수학적으로 흥미로운 관계를 가질 뿐만 아니라 감마 함수 $\Gamma</description>
    </item>
    
    <item>
      <title>감쇠 조화 진동</title>
      <link>https://freshrimpsushi.github.io/posts/damped-harmonic-oscillation/</link>
      <pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/damped-harmonic-oscillation/</guid>
      <description>감쇠 조화 진동1 용수철 상수를 $k$라 할 때, 단순 조화 진동자의 운동 방정식은 다음과 같다. $$ m \ddot {x}+kx=0 $$ 단순 조화 진동에서는 오로지 용수철에 의한 복원력만을 고려한다. 하지만 실제로는 마찰력 등의 다른 외력이 물체의 운동에 영향을 미치기 때문에 이를 무시할 수는 없다. 따라서 속도에 비례해서 작용하는 마찰력이 있다고 가정해보자. 이러한 힘을 제동력</description>
    </item>
    
    <item>
      <title>작용소로써의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transform-as-operator/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transform-as-operator/</guid>
      <description>정의1 함수 $f$ 의 푸리에 변환 $$ \widehat{f} (\gamma ) := \int_{\mathbb{R}} f(x) e^{-2 \pi i x \gamma} dx, \quad \gamma \in \mathbb{R} $$ 을 다음과 같은 작용소 $\mathcal{F}$와 같이 표현하기도 한다. $$ (\mathcal{F} f) (\gamma ) := \widehat{f} ( \gamma ) $$ 설명 푸리에 변환은 해석학 전반에서 널리 쓰이고 있으며 두가지 표현 $\widehat{f}$ 과 $\mathcal{F} f$ 는 본질적으로 다른 점이 없지만, 기호를 사용할 때 뉘앙스의 차이는 살짝 있다. 실질적인 계산과 공식, 빠</description>
    </item>
    
    <item>
      <title>L2 공간에서 트랜슬레이션, 모듈레이션, 다일레이션의 교환관계</title>
      <link>https://freshrimpsushi.github.io/posts/commutation-relations-of-translation-modulation-dilation/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/commutation-relations-of-translation-modulation-dilation/</guid>
      <description>정리1 모든 $a, b \in \mathbb{R}$ 과 $c &amp;gt; 0$ 에 대해 $T_{a}, E_{b}, D_{c}$ 는 다음과 같은 관계를 가진다. $$ \begin{equation} (T_{a} E_{b} f ) (x) = e^{- 2 \pi i b a} (E_{b} T_{a} f ) (x) \end{equation} $$ $$ \begin{equation} (T_{a} D_{c} f ) (x) = (D_{c} T_{a/c} f ) (x) \end{equation} $$ $$ \begin{equation} (D_{c} E_{b} f ) (x) = (E_{b/c} D_{c} f ) (x) \end{equation} $$ 이때 $T_{a}, E_{b}, D_{c}$ 는 각각 $L^{2}$ 에서 정의된 트랜슬레이션, 모듈레이션, 다일레이션이다. 증명 (1) $$ \begin{align*} (T_{a} E_{b} f ) (x) =&amp;amp; T_{a} \left( e^{2 \pi i b x} f(x) \right) \\ =&amp;amp; e^{2 \pi i b (x-a)} f(x-a) \\ =&amp;amp; e^{2 \pi</description>
    </item>
    
    <item>
      <title>거리공간에서 연결 집합</title>
      <link>https://freshrimpsushi.github.io/posts/connected-sets-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/connected-sets-in-metric-space/</guid>
      <description>정의 거리공간 $X$의 두 부분 집합 $A$, $B$가 $$ A \cap \overline{B}= \varnothing \quad \text{and} \quad \overline{A}\cap B= \varnothing $$ 을 만족시키면, $A$와 $B$는 분리되었다separated고 한다. 다시 말해 $B$의 폐포에 포함되는 $A$의 점이 없고, $A$의 폐포에 포함되는 $B$의 점이 없다는 뜻이다. 부분 집합 $E \subset X$가 공집합이 아닌 분리된 두 집합의 합집합으로 표현되지 않으면 $E$</description>
    </item>
    
    <item>
      <title>거리공간에서 연속 함수의 합성은 연속성을 보존한다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-composition-of-continuous-functions-preserve-continuity/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-composition-of-continuous-functions-preserve-continuity/</guid>
      <description>정리 세 거리공간 $(X,d_{X})$, $(Y,d_{Y})$, $(Z,d_{Z})$가 있다고 하자. $E\subset X$이고 두 함수 $f:E\to Y$, $g:f(E) \to Z$가 주어졌다고 하자. 그리고 $E$에서 정의되는 $h : E \to Z$가 아래와 같다고 하자. $$ h(x) = g(f(x))\quad \forall x \in E $$ 이때 $f$가 $p\in E$에서 연속이고 $g$가 $f(p)\in f(E)$에서 연속이면, $h$도 $p$에서 연속이다. 여기서 $h$를 $f$와 $g$의 합성</description>
    </item>
    
    <item>
      <title>거리공간에서 연속과 균등연속</title>
      <link>https://freshrimpsushi.github.io/posts/continuous-functions-and-uniformly-continuous-functions-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuous-functions-and-uniformly-continuous-functions-in-metric-space/</guid>
      <description>정의 두 거리 공간 $\left( X , d_{X} \right)$, $\left( Y , d_{Y} \right)$와 부분집합 $E\subset X$ 에 대해 함수 $f : E \to Y$ 를 정의하자. $p \in E$라고 하자. 임의의 $\varepsilon &amp;gt; 0$ 에 대해 $$ x \in E \quad \text{and} \quad d_{X}(p, x ) &amp;lt; \delta \implies d_{Y}(f(p) , f(x) ) &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $f$ 는 $p \in E$ 에서 연속이라 한다. $f$가 $E$ 의 모든 점에서 연속이면 $f$를 $E$ 위에서의 연속함수continuous fu</description>
    </item>
    
    <item>
      <title>거리공간에서 연속성과 컴팩트</title>
      <link>https://freshrimpsushi.github.io/posts/continuity-and-compactness-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuity-and-compactness-in-metric-space/</guid>
      <description>정리 $X$를 컴팩트 거리공간, $Y$를 거리공간, $f:X\to Y$가 연속이라고 하자. 그러면 $f(X)$는 컴팩트이다. 이때 컴팩트라는 조건은 빠지면 안된다. 증명 $\left\{ O_\alpha \right\}$를 $f(X)$의 오픈 커버라고 하자. 그러면 $f$가 연속이므로, 동치조건에 의해 각각의 프리이미지 $f^{-1}(O_{\alpha})$도 $X$</description>
    </item>
    
    <item>
      <title>거리공간에서 연속함수의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-continuous-functions-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-continuous-functions-in-metric-space/</guid>
      <description>정리1 두 함수 $f$, $g$가 거리공간 $X$에서 복소수 값을 갖는 함수라고 하자. $$ f:X \to \mathbb{C},\quad g:X \to \mathbb{C} $$ 두 함수가 연속이면 $f+g$, $fg$, $f/g$도 연속이다. 단, 마지막 경우에서는 $g(x)\ne 0$인 $x\in X$에 대해서만 성립한다. 증명 보조정리1 $(X,d)$는 거리공간, $E\subset X$는 부분집합, $p$는 $E$의 집적점이라고 하자. 그리고 $E$에서 정의된 두 복소</description>
    </item>
    
    <item>
      <title>거리공간에서 연속함수일 동치 조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-continuous-function-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-continuous-function-in-metric-space/</guid>
      <description>정리1 두 거리공간 $(X,d_{X})$, $(Y,d_{Y})$에 대해서, $E\subset X$이고 $p \in E$, $f : E \to Y$라고 하자. 그러면 아래의 세 명제는 동치이다. (1a) $f$가 $p$에서 연속이다. (1b) $ \lim \limits_{x \to p} f(x)=f(p)$이다. (1c) $\lim \limits_{n\to\infty} p_{n}=p$인 $\left\{ p_{n} \right\}$에 대해서, $\lim \limits_{n\to\infty} f(p_{n})=f(p)$이다. 증명 (1a) $\iff$ (1b) 극한과 연속</description>
    </item>
    
    <item>
      <title>거리공간에서 최대최소 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-extreme-value-theorem-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-extreme-value-theorem-in-metric-space/</guid>
      <description>정리 $X$를 컴팩트 거리공간, $f : X \to \mathbb{R}$을 연속이라고 하자. 그리고 다음과 같다고 하자. $$ M = \sup \limits_{x\in X} f(x),\quad m=\inf \limits_{x \in X}f(x) $$ 그러면 $$ M=f(p),\quad m=f(q) $$ 를 만족하는 $q,p\in X$가 존재한다. 다르게 표현하면: 모든 $x$에 대해서 $$ f(q)\le f(x) \le f(p) $$ 를 만족하는 $q,p \in X$가 존재한다. 이를 최대최소정리extreme value theorem라 한다. 설명</description>
    </item>
    
    <item>
      <title>거리공간에서 컴팩트인 조건의 중요성</title>
      <link>https://freshrimpsushi.github.io/posts/importance-of-compact-condition-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/importance-of-compact-condition-in-metric-space/</guid>
      <description>해석학의 많은 정리에서 컴팩트를 필요조건으로 요구한다 (참고1, 참고2, 참고3, 참고4). 증명 과정에서 컴팩트하다는 가정을 쓰기 때문에 &amp;lsquo;컴팩트하면 된다&amp;rsquo;는 것은 당연히 받아들이겠지만, &amp;lsquo;컴팩트가 아니면 안된다&amp;rsquo;는 것에 의문이 생길 수 있다. 만약 컴팩트하다는 조건이 없으면 아래와</description>
    </item>
    
    <item>
      <title>거리공간에서 함수의 극한</title>
      <link>https://freshrimpsushi.github.io/posts/limits-of-functions-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limits-of-functions-in-metric-space/</guid>
      <description>정의 $(X,d_{X})$, $(Y,d_{Y})$를 거리공간이라고 하자. $E\subset X$이고 $f: E\rightarrow Y$이고 $p$가 $E$의 집적점이라고 하자. 그러면 모든 양수 $\varepsilon$에 대해서 $$ x \in E \ \text{and} \ d_{X}(x,p)&amp;lt;\delta \implies d_{Y}(f(x),q) &amp;lt;\varepsilon $$ 를 만족시키는 $\delta&amp;gt;0$가 존재할 때, $$ f(x)\rightarrow q\ \mathrm{as}\ x\to p $$ 혹은 $$ \lim \limits_{x\to p}f(x)=q $$ 라고 표현하고 $f$는 $p$에서 극한 $q$를 가</description>
    </item>
    
    <item>
      <title>거리공간에서 함수의 극한의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-limits-of-functions-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-limits-of-functions-in-metric-space/</guid>
      <description>정리1 $(X,d)$는 거리공간, $E\subset X$는 부분집합, $p$는 $E$의 집적점이라고 하자. 그리고 $E$에서 정의된 두 복소수값 함수 $f:E\to \mathbb{C}$, $g: E\to \mathbb{C}$가 주어졌다고 하자. 그리고 두 함수가 각각 $p$에서 아래와 같은 극한을 갖는다고 하자. $$ \begin{equation} \lim \limits_{x \to p}f(x)=A \quad \text{and} \quad \lim \limits_{x \to p}g(x)=B \tag{1} \label{thm1} \end{equation} $$ 그러면 다음이 성립한다. (a) $\lim \limits_{x \to p}(f+g)(x)=A+B$ (b) $\lim \limits_{x \to</description>
    </item>
    
    <item>
      <title>보렐-르벡 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-borel-lebesgue-theorem/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-borel-lebesgue-theorem/</guid>
      <description>정리 거리 공간 $(X, \rho)$ 에 대해 다음은 모두 동치다. (a) $X$ 는 컴팩트 공간이다. (b) $X$ 는 시퀀셜리 컴팩트 공간이다. (c) $X$ 는 완비 공간이고 완전 유계 공간이다. 설명 거리 공간 $X$ 가 시퀀셜리 컴팩트Sequentially Compact 공간이라는 것은 $X$ 의 모든 시퀀스가 $X$ 의 한 점으로 수렴하는 서브 시퀀스를 갖는 공간이라는 뜻이다.보렐-르벡 정리는 거리 공간에서 컴팩</description>
    </item>
    
    <item>
      <title>완비 거리 공간의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-complete-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-complete-metric-space/</guid>
      <description>성질 $(X,d)$ 가 거리 공간이고 $K \subset X$ 라 하자. [1]: $K$ 는 완비 부분 공간이다. $\iff$ $X$ 에서 $K$가 닫힌 집합이다. [2]: $K$ 는 완전 유계 공간 $\iff$ $X$에서 닫힌 집합 $K$ 는 컴팩트이다. 설명 완비 거리 공간은 완비성을 가지는 거리 공간이라는 점에서 어지간한 상식적 성질을 다 갖추었다고 볼 수 있는 공간이다. 여기서 놈드 벡터 스페이스가 되면 바나흐 공간, 거기에 내적까지 정</description>
    </item>
    
    <item>
      <title>컴팩트 거리공간에서 연속 함수는 균등 연속임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/continuous-function-is-uniformly-continuous-in-compact-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuous-function-is-uniformly-continuous-in-compact-metric-space/</guid>
      <description>정리 $(X,d_{X})$가 컴팩트 거리공간, $(Y,d_{Y})$가 거리공간, $f:X\to Y$가 연속이라고 하자. 그러면 $f$는 $X$에서 균등연속이다. 컴팩트라는 조건은 빠지면 안된다. 증명 임의의 양수 $\varepsilon &amp;gt;0$가 주어졌다고 하자. 그러면 $f$가 연속이라고 가정했으므로 정의에 의해, 각각의 점 $p\in X$에 대해서 아래의 식을 만족</description>
    </item>
    
    <item>
      <title>컴팩트 거리공간에서 연속인 전단사 함수의 역함수는 연속이다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-inverse-function-of-continuous-bijection-in-compact-metric-space-is-continuous/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-inverse-function-of-continuous-bijection-in-compact-metric-space-is-continuous/</guid>
      <description>정리 $X$를 컴팩트 거리공간, $Y$를 거리공간이라고 하자. $f : X \to Y$가 전단사인 연속함수라고 하자. 그러면 아래와 같이 정의되는 $f$의 역함수 $f^{-1}$는 전단사이고 연속이다. $$ f^{-1} (f(x))=x, \quad x\in X $$ 컴팩트라는 조건은 빠지면 안된다 증명 거리공간에서 연속일 동치 조건 두 거리공간 $(X,d_{X})$, $(Y,d_{Y})$에 대해서, $f : X \to Y$</description>
    </item>
    
    <item>
      <title>디리클레 에타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/dirichlet-eta-function/</link>
      <pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichlet-eta-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $\eta : \mathbb{C} \to \mathbb{C}$ 를 디리클레 에타 함수Dirichlet eta Function라고 한다. $$ \eta (s) := \sum_{n \in \mathbb{N}} (-1)^{n-1} n^{-s} $$ 디리클레 에타 함수는 교대 리만 제타 함수로 정의된다. 정리 [1] 리만 제타 함수와의 관계: $$ \eta(s) = \left( 1 - 2^{1-s} \right) \zeta(s) $$ [2] 감마 함수와의 관계: $\Re (s) &amp;gt; 1$ 이면 $$ \eta (s) \Gamma (s) = \mathcal{M} \left[ {{ 1 } \over { e^{x} + 1 }} \right] (s) = \int_{0}^{\infty} {{ x^{s-1} } \over { e^{x} +</description>
    </item>
    
    <item>
      <title>L2 공간에서 트랜슬레이션, 모듈레이션, 다일레이션의 역작용소</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-of-translation-modulation-dilation/</link>
      <pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-of-translation-modulation-dilation/</guid>
      <description>정리1 $T_{a}, E_{b}, D_{c}$ 는 유니터리며, 역작용소는 다음과 같다. $$ T_{a}^{-1} = T_{-a} = \left( T_{a} \right)^{ \ast } $$ $$ E_{b}^{-1} = E_{-b} = \left( E_{b} \right)^{ \ast } $$ $$ D_{c}^{-1} = D_{1/c} = \left( D_{c} \right)^{ \ast } $$ 이때 $T_{a}, E_{b}, D_{c}$ 는 각각 $L^{2}$ 에서 정의된 트랜슬레이션, 모듈레이션, 다일레이션이다. 증명 트랜슬레이션 $t := x - a$ 와 같이 치환하면 $$ \begin{align*} \langle T_{a} f , g \rangle =&amp;amp; \int_{-\infty}^{\infty} f \left( x - a \right) \overline{g \left( x \right)} dx \\ =&amp;amp; \int_{-\infty}^{\infty} f \left( t \right) \overline{g \left( t + a \right)} dt \\ =&amp;amp; \langle</description>
    </item>
    
    <item>
      <title>거리공간에서 수열의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergent-sequences-in-metric-space/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergent-sequences-in-metric-space/</guid>
      <description>정의 $\left\{ p_{n} \right\}$이 거리공간 $(X,d)$의 점들의 수열이라고 하자. 아래의 조건을 만족하는 점 $p \in X$가 존재하면 수열 $\left\{ p_{n} \right\}$이 $p$로 수렴한다converge고 말하고 $p_{n} \rightarrow p$ 혹은 $\lim \limits_{n\to \infty}p_{n}=p$로 나타낸다. $$ \forall \varepsilon &amp;gt;0,\ \exists N\in \mathbb{N}\ \mathrm{s.t}\ n\ge N \implies d(p_{n},p)&amp;lt;\varepsilon $$ $\left\{ p_{n} \right\}$이 수렴하지 않으</description>
    </item>
    
    <item>
      <title>거리공간에서 집합의 지름</title>
      <link>https://freshrimpsushi.github.io/posts/diameter-of-set-in-metric-space/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diameter-of-set-in-metric-space/</guid>
      <description>정의 $E$를 거리공간 $(X,d)$의 부분집합이라고 하자. 그리고 $S$를 다음과 같다고 하자. $$ S=\left\{ d(p,q) : \forall p, q \in E\right\} $$ 그러면 $S$의 최소 상계 $\sup S$를 $E$의 지름이라고 부르고 $\text{diam } E$로 표기한다. 설명 $\left\{ p_{n} \right\}$이 거리공간 $X$에서의 수열, $E_{N}=\left\{ p_{N},p_{N+1},p_{N+2},\cdots \right\}$라고 하자. 그러면 코시 수열과 지름의 정의에 의해</description>
    </item>
    
    <item>
      <title>거리공간에서 코시수열과 완비</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-sequence-and-complete-in-metric-space/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-sequence-and-complete-in-metric-space/</guid>
      <description>정의 $\left\{ p_{n} \right\}$을 거리공간 $(X,d)$의 점들의 수열이라고 하자. 모든 양수 $\varepsilon$에 대해서 $$ n\ge N,\ m\ge N \implies d(p_{n},p_{m})&amp;lt;\varepsilon $$ 이 성립하는 양수 $N$이 존재하면 $\left\{ p_{n} \right\}$을 코시 수열Cauchy sequence이라 한다. 거리공간 $X$의 모든 코시 수열이 $X$의 점으로 수렴하면 $X$를 완비 공간</description>
    </item>
    
    <item>
      <title>하이네-보렐 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-heine-borel-theorem/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-heine-borel-theorem/</guid>
      <description>정의 실수의 부분집합 $E \subset \mathbb{R}$ 에 대해 $\displaystyle E \subset \bigcup_{\alpha \in \forall} ( x_{\alpha} , y_{\alpha})$ 을 만족하는 개구간의 집합 $\mathcal{O} = \left\{ ( x , y ) \ | \ x &amp;lt; y \right\}$ 을 $E$ 의 오픈 커버링open covering이라 한다. 이러한 $E$ 가 컴팩트compact라는 것은 $E$ 의 모든 오픈 커버링 $\mathcal{O}$ 에 대해 $\displaystyle E \subset \bigcup_{i =1}^{m} O_{i}$ 를 만족하는 $\mathcal{O}$ 의 유한부분집합 $\left\{ O_{1} , O_{2} , \cdots , O_{m} \right\}$ 가 존재한다는 것과 동치다. 이 정</description>
    </item>
    
    <item>
      <title>리만 제타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/riemann-zeta-function/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riemann-zeta-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $\zeta : \mathbb{C} \setminus \left\{ 1 \right\} \to \mathbb{C}$ 를 리만 제타 함수Riemann zeta Function&amp;lt;/sup라고 한다. $$ \zeta (s) := \sum_{n \in \mathbb{N}} n^{-s} = \prod_{p : \text{prime}} \left( 1- {p^{-s}} \right)^{-1} $$ 관련 정리 [0] 라마누잔 합: $\displaystyle \sum_{n \in \mathbb{N}} x^{n-1} = {{ 1 } \over { 1-x }}$ 이 $|x| = 1$ 에서도 성립한다는 주장을 받아들인다면 $$ \zeta (0) = 1 + 1 + 1 + 1 + \cdots = - {{ 1 } \over { 2 }} $$ [1] 오렘의 증명 : $\zeta</description>
    </item>
    
    <item>
      <title>수렴하는 실수열의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-convergent-realcomplex-sequences/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-convergent-realcomplex-sequences/</guid>
      <description>정리11 $\left\{ s_{n} \right\}$, $\left\{ t_{n} \right\}$이 실수(혹은 복소수) 수열이고 $\lim \limits_{n\to\infty} s_{n}=s$, $\lim\limits_{n\to\infty}t_{n}=t$라고 하자. 그러면 (a) $\lim \limits_{n\to\infty}(s_{n}+t_{n})=s+t$ (b) $\forall c \in \mathbb{C},\quad\lim \limits_{n\to\infty} cs_{n}=cs \quad \text{and} \quad \lim \limits_{n\to\infty} (c+s_{n})=c+s$ (c) $\lim \limits_{n\to\infty} s_{n}t_{n}=st$ (d) $\forall s_{n}\ne 0,s\ne0,\quad \lim \limits_{n\to\infty}\frac{1}{s_{n}}=\frac{1}{s}$ 물론 $\mathbb{R}^{k}$에 대해서도 확장할 수 있다. 정리2에서 확인하자. 증명 (a) 임의의 양수</description>
    </item>
    
    <item>
      <title>유클리드 공간에서 공집합이 아닌 완벽 집합은 비가산이다</title>
      <link>https://freshrimpsushi.github.io/posts/in-euclidean-space-non-empty-perfect-set-is-uncountable-set/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/in-euclidean-space-non-empty-perfect-set-is-uncountable-set/</guid>
      <description>정의 $(X,d)$가 거리공간이라고 하자. $p \in X$이고 $E \subset X$라고 하자. $d(q,p)&amp;lt;r$을 만족하는 모든 $q$들을 포함하는 집합을 점 $p$의 근방neighborhood이라고 정의하고 $N_{r}(p)$라고 표기한다. 이때 $r$을 $N_{r}(p)$의 반경이라고 부른다. 거리를 생략해도 될 경우 $N_{</description>
    </item>
    
    <item>
      <title>거리공간에서 일반화된 칸토어의 축소 구간 정리</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-cantors-nested-intervals-theorem-in-metric-space/</link>
      <pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-cantors-nested-intervals-theorem-in-metric-space/</guid>
      <description>정리1 $(X,d)$가 거리공간이라고 하자. $K_{n}\subset X (n=1,2,\cdots)$는 공집합이 아닌 컴팩트 부분집합이다. 이때 $\left\{ K_{n} \right\}$이 $$ K_{n}\supset K_{n+1}\ (n=1,2,\cdots) $$ 를 만족하면 $\bigcap _{i=1}^{\infty} K_{n} \ne \varnothing$이다. $\left\{ K_{n} \right\}$을 위와 같이 두면 유한 교집합 성질을 가지므로 아래에서 보일 정리의 따름정리로서 바로 성립한다.</description>
    </item>
    
    <item>
      <title>모든 k-cell은 컴팩트이다: 유클리드 공간에서 컴팩트일 동치 조건</title>
      <link>https://freshrimpsushi.github.io/posts/every-k-cell-is-compact/</link>
      <pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/every-k-cell-is-compact/</guid>
      <description>정의 $a_i,b_i \in \mathbb{R} (1\le i \le k)$에 대해서 집합 $I=[a_{1},b_{1}] \times [a_{2},b_{2}]\times \cdots \times [a_{k},b_{k}]$를 $k$-셀k-cell이라 한다. 여기서 $\times$는 집합의 데카르트 곱이다. 정리1 $\mathbb{R}$상의 폐구간들의 수열 $\left\{ I_{n} \right\}$이 $I_{n}\supset I_{n+1}\ (n=1,2,\cdots)$를 만족한다고 하자. 그러면 다음이 성립한다. $$</description>
    </item>
    
    <item>
      <title>L2 공간의 트랜슬레이션, 모듈레이션, 다일레이션</title>
      <link>https://freshrimpsushi.github.io/posts/translation-modulation-dilation-on-l2/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/translation-modulation-dilation-on-l2/</guid>
      <description>정의1 $a \in \mathbb{R}$ 에 대해 다음과 같이 정의된 $T_{a} : L^{2} \to L^{2}$ 를 트랜슬레이션translation, 평행이동이라 한다. $$ \left( T_{a} f \right) (x) := f(x-a) $$ $b \in \mathbb{R}$ 에 대해 다음과 같이 정의된 $E_{b} : L^{2} \to L^{2}$ 을 모듈레이션modulation, 변조 이라 한다. $$ \left( E_{b} f \right) (x) := e^{2 \pi i b x} f(x) $$ $c &amp;gt; 0$ 에 대해 다음과 같이 정의된 $D_{c} : L^{2} \to L^{2}$ 을 다일레이션dilation,</description>
    </item>
    
    <item>
      <title>수론에서의 p-진수 p-adic Number</title>
      <link>https://freshrimpsushi.github.io/posts/1707/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1707/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **$p$-진수12 소수 $p$ 와 정수 $a \in \mathbb{Z}$ 에 대해 다음과 같이 정의된 $v_{p}$ 를 $a$ 의 $p$-진수 부치$p$-adic Valuation라 한다. $$ v_{p} (a) := \sup \left\{ e \in \mathbb{Z} : p^{e} \mid a \right\} $$ [0]** 모든 소수 $p$ 에 대해 $$ v_{p} (0) = \infty $$ [1] $$ v_{p} (xy) = v_{p}(x) + v_{p}(y) $$ [2] $$ v_{p} (x+y) \ge \min \left\{ v_{p} (x) , v_{p} (y) \right\} $$ [3]: $n \in \mathbb{N}$, $x , y \in \mathbb{Z}$, 소수</description>
    </item>
    
    <item>
      <title>지수승강 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lifting-the-exponent-lemma-lte-lemma/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lifting-the-exponent-lemma-lte-lemma/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $n \in \mathbb{N}$, $x , y \in \mathbb{Z}$, 소수 $p \ne 2$ 가 $$ \gcd (n,p) = 1 \\ p \mid (x - y) \\ p \nmid x \\ p \nmid y $$ 를 만족하면 $$ v_{p} \left( x^{n} - y^{n} \right) = v_{p} \left( x - y \right) + v_{p} (n) $$ $v_{p} (a)$ 는 $a$ 의 $p$-진수 부치를 의미한다.* 본 포스트는 &amp;lsquo;깁gip&amp;rsquo;님의 요청으로 작성되었다. 전략: $p$-진수 부치의 성질들</description>
    </item>
    
    <item>
      <title>거리공간에서 컴팩트</title>
      <link>https://freshrimpsushi.github.io/posts/compactness-in-metric-space/</link>
      <pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compactness-in-metric-space/</guid>
      <description>정의 거리공간 $(X,d)$와 부분 집합 $E\subset X$가 주어졌다고 하자. 아래의 식을 만족하는 $X$의 열린 집합들의 집합 $\left\{ O_{\alpha} \right\}$를 $E$의 오픈 커버open cover 라고 한다. $$ E\subset \bigcup _{\alpha} O_{\alpha} $$ 오픈 커버의 부분 집합을 부분 커버라 부른다. 특히 원소가 유한개인 부분 커버를 유한 부분 커버라 부른다. 거리공간 $X$의 부분집합 $K$가 주어졌</description>
    </item>
    
    <item>
      <title>거리공간에서 컴팩트 집합과 닫힌 집합의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-between-compact-set-and-closed-set-in-metric-space/</link>
      <pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-between-compact-set-and-closed-set-in-metric-space/</guid>
      <description>정리1 거리공간 $(X,d)$의 컴팩트 부분 집합 $K$는 닫힌 집합이다. 증명 $K$를 거리공간 $X$의 컴팩트 부분 집합이라고 하자. 여기서 $K^{c}$가 열려있음을 보이면, 열린 집합의 여집합은 닫힌 집합이므로, $K$는 닫힌 집합이다. $K^{c}$가 오픈인 것은 보이려면 $K^{c}$의 모든 점이 내점임을 보이면 된다. 이제 $p</description>
    </item>
    
    <item>
      <title>F-분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-f-distribution/</link>
      <pubDate>Sat, 15 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-f-distribution/</guid>
      <description>공식 $X \sim F ( r_{1} , r_{2})$ 면 $$ E(X) = {{ r_{2} } \over { r_{2} - 2 }} \qquad , r_{2} &amp;gt; 2 \\ \text{Var}(X) = {{ 2 d_{2}^{2} (d_{1} + d_{2} - 2) } \over { d_{1} (d_{2} -2)^{2} (d_{2} - 4) }} \qquad , r_{2} &amp;gt; 4 $$ 유도 전략: F-분포 역시 카이제곱분포와 비슷하게 적률 공식이 알려져 있어, 이 공식들을 이용한다. F-분포의 적률: $X \sim F(r_{1} , r_{2})$ 이고 $\displaystyle X = {{ X_{1} } \over { X_{2} }}$ 와 같이 나타낼 수 있다고 하자. $X_{1}$ 과 $X_{2}$ 가 각각 자유도 $d_{1}, d_{2}$ 인 카이제</description>
    </item>
    
    <item>
      <title>거리공간에서 상대적으로 열린 집합</title>
      <link>https://freshrimpsushi.github.io/posts/relatively-open-set/</link>
      <pubDate>Sat, 15 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relatively-open-set/</guid>
      <description>대한수학회에서는 E is open relative to Y를 $E$는 $Y$에 대해서 상대적으로 열려있다고 번역하는데 아래에서 설명할 내용의 생각해봤을 때 open relative to는 &amp;lsquo;~에 대해서 상대적으로 열려있다&amp;rsquo;가 아니라 &amp;lsquo;~에 관련되어서/연관되어서 열려있다&amp;rsquo;고 번역하는 것이 맞는 듯 하다. $(X,d)$가 거리공간</description>
    </item>
    
    <item>
      <title>거리공간에서 열린 집합, 닫힌 집합의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-open-set-and-closed-set-in-metric-space/</link>
      <pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-open-set-and-closed-set-in-metric-space/</guid>
      <description>$(X,d)$가 거리공간이라고 하자. $p \in X$이고 $E \subset X$라고 하자. $d(q,p)&amp;lt;r$을 만족하는 모든 $q$들을 포함하는 집합을 점 $p$의 근방neighborhood이라고 정의하고 $N_{r}(p)$라고 표기한다. 이때 $r$을 $N_{r}(p)$의 반경이라고 부른다. 거리를 생략해도 될 경우 $N_{p}</description>
    </item>
    
    <item>
      <title>앤더슨-리빙스톤 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-anderson-livingston-theorem/</link>
      <pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-anderson-livingston-theorem/</guid>
      <description>정리 1 $R$ 이 유니티 $1$ 을 가지는 가환 링이고 그 영인자들의 집합을 $Z(R)$ 라 하면 그 영인자 그래프 $\Gamma (R)$ 는 연결 그래프고 $\text{diam}(\Gamma(R)) \le 3$ $\text{diam}$ 은 그래프의 지름을 의미한다. 설명 앤더슨과 리빙스톤은 영인자 그래프의 연구에서 중요한 업적을 남겼으며, 특히 그래프의 연결성과 지름의 상한값을 특정하는 이 정리를 앤더슨-리빙스톤 정리라 부르기도 한다. 증명 $x,y \in Z(R) (x \ne y)$ 이라</description>
    </item>
    
    <item>
      <title>거리공간에서 근방, 집적점, 열림, 닫힘</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-open-in-metric-space-at-pma/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-open-in-metric-space-at-pma/</guid>
      <description>정의 $(X,d)$가 거리공간이라고 하자. $p \in X$이고 $E \subset X$라고 하자. $d(q,p)&amp;lt;r$을 만족하는 모든 $q$들을 포함하는 집합을 점 $p$의 근방neighborhood이라고 정의하고 $N_{r}(p)$라고 표기한다. 이때 $r$을 $N_{r}(p)$의 반경이라고 부른다. 거리를 생략해도 될 경우 $N_{</description>
    </item>
    
    <item>
      <title>거리공간에서 폐포, 도집합</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-closure-and-derived-set-in-metric-space/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-closure-and-derived-set-in-metric-space/</guid>
      <description>$(X,d)$가 거리공간이라고 하자. $p \in X$이고 $E \subset X$라고 하자. $d(q,p)&amp;lt;r$을 만족하는 모든 $q$들을 포함하는 집합을 점 $p$의 근방neighborhood이라고 정의하고 $N_{r}(p)$라고 표기한다. 이때 $r$을 $N_{r}(p)$의 반경이라고 부른다. 거리를 생략해도 될 경우 $N_{p}</description>
    </item>
    
    <item>
      <title>산술 함수의 부분합에 대한 일반화된 디리클레 곱 표현</title>
      <link>https://freshrimpsushi.github.io/posts/1607/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1607/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $h = f*g$ 인 산술 함수 $f,g,h$ 에 대해 $F, G, H$ 를 다음과 같이 정의하자. $$ F (x) := \sum_{n \le x} f(x) \\ G (x) := \sum_{n \le x} g(x) \\ H (x) := \sum_{n \le x} h(x) $$ 그러면 $$ H = f \circ G = g \circ F $$ 연산 $\circ$ 는 일반화된 컨볼루션을 의미한다. 다시 말해, $$ H(x) = \sum_{n \le x} f(n) G \left( {{ x } \over { n }} \right) = \sum_{n \le x} g(n) F \left( {{ x } \over { n }} \right) $$ 증명 $$ U(x) := \begin{cases}</description>
    </item>
    
    <item>
      <title>F-분포</title>
      <link>https://freshrimpsushi.github.io/posts/f-distribution/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/f-distribution/</guid>
      <description>정의 1 자유도 $r_{1}, r_{2} &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $F \left( r_{1} , r_{2} \right)$ 를 F-분포라고 한다. $$ f(x) = {{ 1 } \over { B \left( r_{1}/2 , r_{2} / 2 \right) }} \left( {{ r_{1} } \over { r_{2} }} \right)^{r_{1} / 2} x^{r_{1} / 2 - 1} \left( 1 + {{ r_{1} } \over { r_{2} }} x \right)^{-(r_{1} + r_{2}) / 2} \qquad , x \in (0, \infty) $$ $B(r_{1} / 2, r_{2}/2)$ 는 베타 함수를 의미한다. 기초 성질 [1] 적률 생성 함수: F-분포는 적률 생성 함수가 존재하지 않</description>
    </item>
    
    <item>
      <title>리만(-스틸체스) 적분가능성은 구간 내에서 보존된다</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-riemann-stieltjes-integral/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-riemann-stieltjes-integral/</guid>
      <description>해당 글은 리만-스틸체스 적분을 기준으로 작성되었다. $\alpha=\alpha(x)=x$로 두면 리만 적분과 같다. 정리 1 함수 $f$가 $[a,b]$에서 리만(-스틸체스)적분 가능하다고 하자. 그리고 $a&amp;lt;c&amp;lt;b$라고 하자. 그러면 $f$는 $[a,c]$와 $[c,b]$에서도 적분이 가능하며 그 적분값의</description>
    </item>
    
    <item>
      <title>적분 가능한 함수와 절댓값</title>
      <link>https://freshrimpsushi.github.io/posts/integrable-functions-and-absolute-values/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integrable-functions-and-absolute-values/</guid>
      <description>해당 글은 리만-스틸체스 적분을 기준으로 작성되었다. $\alpha=\alpha(x)=x$로 두면 리만 적분과 같다. 정리1 함수 $f$가 구간 $[a,b]$에서 리만(-스틸체스) 적분가능하다고 하자. 그러면 (a) $\left|f\right|$도 $[a,b]$에서 적분 가능하다. (b) 또한 아래의 부등식이 성립한다. $$ \left|\int_{a}^{b}fd\alpha \right| \le</description>
    </item>
    
    <item>
      <title>함수의 대소 관계에 따른 적분의 대소 관계</title>
      <link>https://freshrimpsushi.github.io/posts/large-small-relationship-of-function-and-integration/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/large-small-relationship-of-function-and-integration/</guid>
      <description>해당 글은 리만-스틸체스 적분을 기준으로 작성되었다. $\alpha=\alpha(x)=x$로 두면 리만 적분과 같다. 정리1 두 함수 $f_{1}, f_{2}$가 구간 $[a,b]$에서 리만(-스틸체스) 적분 가능하다고 하자. 또한 $[a,b]$에서 $f_{1} \le f_{2}$라고 하자. 그러면 아래의 부등식이 성립한다. $$ \int_{a}^{b}f_{1}d\alpha \le \int_{a}^{b}f_{2}d\alpha $$ 증명 양수 $\varepsilon &amp;g</description>
    </item>
    
    <item>
      <title>해석학에서 미분적분학의 기본정리1</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-1-of-calculus-in-analysis/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-1-of-calculus-in-analysis/</guid>
      <description>정리1 $f$가 구간 $[a,b]$에서 리만 적분 가능한 함수라고 하자. 그리고 $a\le x \le b$에 대해서 $F$를 아래와 같이 두자. $$ F(x) = \int _{a} ^{x} f(t)dt $$ (a) 그러면 $F$는 $[a,b]$에서 연속이다. (b) 만약 $f$가 $x_{0}\in [a,b]$에서 연속이면, $F$는 $x_{0}$에서 미분 가능하고 $F&#39;(x_{0})=f(x_{0})$를 만족한</description>
    </item>
    
    <item>
      <title>영인자 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/zero-divisor-graph/</link>
      <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zero-divisor-graph/</guid>
      <description>정의 가환 링 $R$ 이 주어져 있다고 하자. $R$ 의 영인자 집합을 $Z(R)$ 이라고 할 때, 다음과 같이 정의된 그래프 $\Gamma (R)$ 을 $R$ 에 대한 영인자 그래프Zero Divisor Graph라고 한다. $$ V \left( \Gamma(R) \right) = Z(R) \\ E( \Gamma(R)) = \left\{ ab : ab=0 \right\} $$ 설명 알다시피 영인자끼리 곱한다고해서 반드시 $0$ 이 되는 것은 아니다. 예로써, $ 2, 4 \in Z \left( \mathbb{Z}_{10} \right)$ 는 $\mathbb{Z}_{10}$ 의 영인자가 맞지만 그 곱은 $8 \ne 0$ 이다. 따라</description>
    </item>
    
    <item>
      <title>일반화된 디리클레 곱</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-convolution/</link>
      <pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-convolution/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 산술 함수의 디리클레 곱 $F : \mathbb{R}^{+} \to \mathbb{C}$ 는 $x \in (0,1)$ 에서 $F(x) = 0$ 인 함수라고 하자. 임의의 산술 함수 $\alpha$ 에 대해 다음과 같은 연산 $\circ$ 을 일반화된 디리클레 곱이라 정의한다. $$ (\alpha \circ F)(x) := \sum_{n \le x} \alpha(n) F \left( {{ x } \over { n }} \right) $$ $\alpha$ 와 $\beta$ 는 산술 함수고 $F , G : \mathbb{R}^{+} \to \mathbb{C}$ 는 $x \in (0,1)$ 에서 함숫값이 $0$ 인 함수이라 하자. [1]: $\alpha \circ \left(</description>
    </item>
    
    <item>
      <title>일, 일-운동 에너지 정리</title>
      <link>https://freshrimpsushi.github.io/posts/work-work-kinetic-energy-theorem/</link>
      <pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/work-work-kinetic-energy-theorem/</guid>
      <description>정의 힘 $\mathbf{F}$가 물체에 작용하여 물체가 힘과 같은 방향으로 $s$만큼 이동했을 때, 힘의 크기와 이동거리의 곱 $W=Fs$를 힘 $\mathbf{F}$가 물체에 해준 일work이라고 한다. 설명 이동거리-힘 그래프에서 그래프 아래의 면적이 일의 양과 같다. 이동방향과 힘의 방향이 같아야 힘이 물체에 일을 해준 것으로 정의하</description>
    </item>
    
    <item>
      <title>카이제곱 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-chi-square-distribution/</link>
      <pubDate>Wed, 05 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-chi-square-distribution/</guid>
      <description>공식 $X \sim \chi^{2} (r)$ 이면 $$ E(X) = r \\ \text{Var} (X) = 2r $$ 유도 전략: 카이제곱분포는 고맙게도 적률 공식이 알려져있다. 카이제곱 분포의 적률: $X \sim \chi^{2} (r)$ 이라고 하자. $k &amp;gt; - r/ 2$ 이면 $k$차 적률이 존재하고 $$ E X^{k} = {{ 2^{k} \Gamma (r/2 + k) } \over { \Gamma (r/2) }} $$ 평균 $$ EX^{1} = {{ 2^{1} \Gamma (r/2 + 1) } \over { \Gamma (r/2) }} = 2 \cdot {{ r } \over { 2 }} = r $$ ■ 분산 $$ EX^{2} = {{ 2^{2} \Gamma (r/2 + 2) } \over { \Gamma (r/2) }} = 4</description>
    </item>
    
    <item>
      <title>2차/3차/n차 방정식의 근과 계수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/the-relationship-between-root-and-coefficient/</link>
      <pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-relationship-between-root-and-coefficient/</guid>
      <description>공식 2차 방정식의 근과 계수의 관계 2차 방정식 $ax^{2}+bx+c=0$의 두 근을 $\alpha$, $\beta$라고 하자. 그러면 아래의 식이 성립한다. $$ \alpha+\beta=-\frac{b}{a}\quad \&amp;amp; \quad \alpha\beta= \frac{ c}{a} $$ 3차 방정식의 근과 계수의 관계 3차 방정식 $ax^{3}+bx^{2}+cx+d=0$의 세 근을 $\alpha$, $\beta$, $\gamma$라고 하자. 그러면 아래의 식이 성립한다. $$ \alpha + \beta +</description>
    </item>
    
    <item>
      <title>3차 방정식의 근의 공식</title>
      <link>https://freshrimpsushi.github.io/posts/the-cubic-formula/</link>
      <pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-cubic-formula/</guid>
      <description>공식 3차 방정식 $t^{3}+pt+q = 0$의 해는 다음과 같다. $$ \begin{cases} t_{1}=u_{1}+v_{1}=\sqrt[3]{\frac{q}{2}+\sqrt{\frac{q^{2}}{4}+\frac{p^{3}}{27}}}+\sqrt[3]{\frac{q}{2}-\sqrt{\frac{q^{2}}{4}+\frac{p^{3}}{27}}} \\ t_{2}=u_{2}+v_{3}=\sqrt[3]{\frac{q}{2}+\sqrt{\frac{q^{2}}{4}+\frac{p^{3}}{27}}}\omega+\sqrt[3]{\frac{q}{2}-\sqrt{\frac{q^{2}}{4}+\frac{p^{3}}{27}}}\omega^{2} \\ t_{3}=u_{3}+v_{2}=\sqrt[3]{\frac{q}{2}+\sqrt{\frac{q^{2}}{4}+\frac{p^{3}}{27}}}\omega^{2}+\sqrt[3]{\frac{q}{2}-\sqrt{\frac{q^{2}}{4}+\frac{p^{3}}{27}}}\omega\end{cases} $$ 증명 카르다노 방식 3차 방정식 $ax^{3}+bx^{2}+cx+d=0(a\ne0)$가 주어졌다고 하자. 풀이를 간단하게 하기 위해, 일반성을 잃지 않고 아래와 같이 나타내자. $$ \begin{equation} x^{3}+ax^{2} +bx+c=0 \label{eq1} \end{equation} $$ 2차항을 없애주기 위해 $x=t-{\textstyle \frac{a}{3}}$으로 치환하자. 그러면</description>
    </item>
    
    <item>
      <title>카이제곱 분포</title>
      <link>https://freshrimpsushi.github.io/posts/chi-square-distribution/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chi-square-distribution/</guid>
      <description>정의 1 자유도 $r &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\chi^{2} (r)$ 를 카이제곱 분포chi-square Distribution라고 한다. $$ f(x) = {{ 1 } \over { \Gamma(r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} \qquad , x \in (0, \infty) $$ $\Gamma$ 는 감마 함수를 나타낸다. 기초 성질 [1] 적률 생성 함수: $$ m(t) = (1-2t)^{-r/2} \qquad , t &amp;lt; {{ 1 } \over { 2 }} $$ [2] 평균과 분산: $X \sim \chi^{2} (r)$ 이면 $$ E(X) = r \\ \text{Var} (X) =</description>
    </item>
    
    <item>
      <title>케플러 제1 법칙 타원 궤도의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/keplers-first-law-the-law-of-ellipses/</link>
      <pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/keplers-first-law-the-law-of-ellipses/</guid>
      <description>케플러 제1 법칙: 타원 궤도의 법칙 행성의 공전 궤도는 태양을 초첨으로하는 타원이다. 케플러의 행성 운동 법칙 중 첫번째 법칙이다. 증명1 중심력 $F$에 의해 운동하는 입자의 궤도 방정식은 아래와 같다. $$ \frac{ d ^{2}u}{ d \theta^{2} } + u=-\frac{1}{ml^{2}u^{2}}F(u^{-1}) $$ 이때 $u={\textstyle \frac{1}{r}}$이다. 우리는 중력에 대해서 위 문제를 풀고 싶으므로 $F=-\frac{GMm}{</description>
    </item>
    
    <item>
      <title>케플러 제3 법칙 조화 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/keplers-third-law-the-harmonic-law/</link>
      <pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/keplers-third-law-the-harmonic-law/</guid>
      <description>케플러 제3 법칙: 조화 법칙 행성의 공전 주기의 제곱은 공전 궤도의 장반경의 세제곱에 비례한다. 케플러의 행성 운동 법칙 중 세번째 법칙이다. 행성의 공전 궤도를 원으로 근사할 경우 &amp;lsquo;공전 주기의 제곱은 태양과의 거리의 세제곱에 비례한다&amp;rsquo;가 된다. 증명1 행성의 공전 궤도의 넓이를 $A$, 면적 속도를 $\dot {A}$라고 하자. 케플러</description>
    </item>
    
    <item>
      <title>제2 종 타원 적분</title>
      <link>https://freshrimpsushi.github.io/posts/completeincomplete-elliptic-integral-of-the-second-kind/</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/completeincomplete-elliptic-integral-of-the-second-kind/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 아래의 적분을 제2 종 완전 타원 적분 이라고 한다. $$ E(k)=\int_{0}^{{\textstyle \frac{\pi}{2}}}\sqrt{1-k^{2} \sin ^{2} \theta} d\theta $$ 아래의 적분을 제2 종 불완전 타원적분 이라고 한다. $$ E(\phi, k)=\int_{0}^{\phi}\sqrt{1-k^{2} \sin ^{2} \theta}d\theta $$ 위 두 적분의 이름이 타원 적분인 것은 타원의 둘레를 구하는 과정에서 나왔기 때문이다. 타원 $$ \frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}=1,\quad (0&amp;lt;a&amp;lt;b) $$ 가 주어지면 타원의 둘레는 $$ 4bE(k),\quad k^{2}=\frac{b^{2}-a^{2} }{b^{2}} $$ 와 같이 구할 수 있다. $k$ 값</description>
    </item>
    
    <item>
      <title>타원의 둘레</title>
      <link>https://freshrimpsushi.github.io/posts/circumference-of-ellipse/</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/circumference-of-ellipse/</guid>
      <description>대부분의 자료에서 제2 종 타원적분이 어떻게 유도되는지 그 과정이 자세하게 나와있지 않다. 있더라도 틀린 경우가 많아1 &amp;lsquo;정확하고&amp;rsquo; &amp;lsquo;자세한&amp;rsquo; 내용을 직접 작성했다. 참고로 보아스 수리물리학 3판의 내용도 틀렸다. 공식 장반경이 $a$, 단반경이 $b$, 이심률이 $k^{2}$인 타원의 둘레는 다음과</description>
    </item>
    
    <item>
      <title>독립인 두 감마 분포에서 베타 분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-beta-distribution-from-two-independent-gamma-distributions/</link>
      <pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-beta-distribution-from-two-independent-gamma-distributions/</guid>
      <description>정리 두 확률 변수 $X_{1},X_{2}$ 가 독립이고 $X_{1} \sim \Gamma ( \alpha_{1} , 1)$, $X_{2} \sim \Gamma ( \alpha_{2} , 1)$ 이라 하면 $$ {{ X_{1} } \over { X_{1} + X_{2} }} \sim \text{beta} \left( \alpha_{1} , \alpha_{2} \right) $$ 설명 두 데이터가 감마 분포를 따르고 독립이라면, 그 합계를 계산했을 때의 비율을 분포이론으로 설명하는데 쓰일 수 있을지도 모른다. 특히 감마분포는 여러가지 확률분포를 비교적 자유롭게 넘나들 수 있으므로 팩트로써는 알아두는 게 좋다. 유</description>
    </item>
    
    <item>
      <title>극 좌표계에서 초점이 원점인 타원의 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/equations-of-ellipses-in-polar-coordinates/</link>
      <pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equations-of-ellipses-in-polar-coordinates/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 극 좌표계에서 타원의 방정식은 아래와 같다. $$ r=\frac{\alpha}{1+\epsilon \cos \theta}\tag{a} $$ 혹은 $$ r=\frac{b^{2}/a}{1+\frac{\sqrt{a^{2}-b^{2}}}{a}\cos\theta} \tag{b} $$ 이때 $\alpha$는 통경, $\epsilon$은 이심률, $a$는 장반경, $b$는 단반경이다. 두 식과 증명은 본질적으로 같으나 $(b)$의 식과 증명은 고등학교에서 배우는 지식을 벗어나지 않는다는 특징이 있다</description>
    </item>
    
    <item>
      <title>타원</title>
      <link>https://freshrimpsushi.github.io/posts/ellipse/</link>
      <pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ellipse/</guid>
      <description>정의 두 초점까지의 거리의 합이 일정한 점들의 집합을 타원ellipse이라고 한다. 타원의 구성요소는 다음과 같다. $F$, $F&#39;$를 초점focus이라 한다. $a$를 장반경semimajor axis, $b$를 단반경semiminor axis이라 한다. $b=\sqrt{1-\epsilon^{2}}a$가 성립한다. $\epsil</description>
    </item>
    
    <item>
      <title>힐베르트 공간의 프레임</title>
      <link>https://freshrimpsushi.github.io/posts/frame-in-hilbert-space/</link>
      <pubDate>Sun, 26 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/frame-in-hilbert-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 힐베르트 공간 $H$ 의 시퀀스 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 에 대해 다음을 만족하는 $A,B &amp;gt; 0$ 이 존재하면 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 을 프레임이라 부르고, 특히 $A = B$ 일 때 이 프레임이 타이트Tight하다고 말한다. $$ A \left\| \textbf{v} \right\|^{2} \le \sum_{k \in \mathbb{N}} \left| \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt; \right|^{2} \le B \left\| \textbf{v} \right\|^{2} \qquad , \textbf{v} \in H $$ 프레임은 베셀 시퀀스와 달리 $A$ 가 존재해서 $\textbf{v}$ 를 위아래로</description>
    </item>
    
    <item>
      <title>함수의 서포트와 연속함수 공간의 클래스</title>
      <link>https://freshrimpsushi.github.io/posts/support-and-classes-of-continuous-functions/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/support-and-classes-of-continuous-functions/</guid>
      <description>정의 함수공간 $\mathbb{C}^{\mathbb{R}}$ 의 함수 $f : \mathbb{R} \to \mathbb{C}$ 를 생각해보자. 함수 $f$ 의 서포트support란 다음과 같이 함수값이 $0$ 이 아닌 점들의 집합에 클로져를 취한 클로즈 셋이다. $$ \text{supp} f = \overline{\left\{ x \in \mathbb{R} : f(x) \ne 0 \right\}} $$ $\text{supp} f$ 가 유계면 $f$ 가 컴팩트 서포트를 갖는다고 한다. 클로져는 닫힌 집합이고, 실수 공간에서 닫혀있고 유계인 집합은 컴팩트이기 때문이다. $U\Subset V$ 는 $\overline{U} \subset V$이</description>
    </item>
    
    <item>
      <title>중심력을 받는 입자의 궤도 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-equation-of-a-particle-in-central-force/</link>
      <pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-equation-of-a-particle-in-central-force/</guid>
      <description>중심력을 받는 입자의 궤도 방정식1 중심력을 받는 질량이 $m$인 입자의 운동 방정식을 극좌표계로 표현하면 아래와 같다. $$ \begin{equation} m\ddot{\mathbf{r}}=F(r)\hat{\mathbf{r}} \label{eq1} \end{equation} $$ $F(r)$은 입자에 작용하는 중심력이다. 극좌표계에서 가속도는 아래와 같다. $$ \ddot{\mathbf{r}}=\mathbf{a}=\left( \ddot{r}-r\dot{\theta}{}^{2} \right)\hat{\mathbf{r}} +\left(2\dot{r}\dot{\theta}+r\ddot{\theta} \right)\hat{\boldsymbol{\theta}} $$ 따라서 운동 방정식 $\eqref{eq1}$을 성분별로 나눠서 쓰면 아래와 같다. $$ \begin{align} m\left( \ddot{r}-r\dot{\theta}{}^{2} \right) &amp;amp;= F(r) \label{eq2} \\ m\left( 2\dot{r} \dot{\theta}</description>
    </item>
    
    <item>
      <title>두 벡터의 외적의 크기는 두 벡터가 만드는 평행사변형의 넓이와 같다</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-outer-product/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-outer-product/</guid>
      <description>정리 두 벡터 $\mathbf{A}$, $\mathbf{B}$ 사이의 각도가 $\theta$일 때 두 벡터의 외적의 크기는 다음과 같다. $$ \left| \mathbf{A}\times \mathbf{B}\right| =\left|\mathbf{A}\right|\left| \mathbf{B} \right|\sin \theta $$ 그리고 이는 두 벡터가 만드는 평행사변형의 넓이와 같다. 증명 두 벡터 $\mathbf{A}=(A_{x},A_{y},A_{z})$, $\mathbf{B}=(B_{x},B_{y},B_{z})$가 위 그림과 같다고 하자. 그러면 part 1. 평행사변형의 넓이 평행사변형의 넓이는 밑변과 높이의 곱</description>
    </item>
    
    <item>
      <title>케플러 제2 법칙 면적 속도 일정의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/keplers-second-law-equal-areas/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/keplers-second-law-equal-areas/</guid>
      <description>케플러 제2 법칙: 면적 속도 일정의 법칙1 태양과 행성을 연결하는 선분은 같은 시간동안 같은 면적을 지나간다. 면적 속도 일정의 법칙은 케플러의 행성 운동 법칙 중 두번째 법칙이다. 다만 이는 태양과 행성간에서만 일어나는 특별한 법칙이 아니라 중심력에 의해 운동하는 어떤 물체(입자)에 대해서도 성립하는 일반적인 법칙이다. 증명 중심력장에에서 움직이</description>
    </item>
    
    <item>
      <title>타원의 방정식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-an-elliptical-equation/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-an-elliptical-equation/</guid>
      <description>공식 🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 중점이 $(x_{0},y_{0})$이고 장반경이 $a$, 단반경이 $b$인 타원의 방정식은 아래와 같다. $$ \frac{(x-x_{0})^{2}}{a^{2}}+\frac{(y-y_{0})^{2}}{b^{2}}=1 $$ 타원은 두 초점까지의 거리의 합이 일정한 점들의 집합이다. 유도** 위 그림과 같은 타원이 있다고 하자. 타원의 정의에 의해 아래와 같은 방정식을 세울 수 있다. $$ \begin{align*} \overline{F&amp;rsquo;P} +\overline{PF}=&amp;amp;\mathrm{constant} \\ \sqrt{(x+c)^{2}+y^{2}}+\sqrt{(x-c)^{2}+y^{2}}=&amp;amp; \end{align*} $$ 이</description>
    </item>
    
    <item>
      <title>힐베르트 공간의 정규직교 기저와 유니터리 작용소</title>
      <link>https://freshrimpsushi.github.io/posts/orthonormal-bases-of-hilbert-space-and-unitary-operator/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthonormal-bases-of-hilbert-space-and-unitary-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\left\{ \textbf{e}_{k} \right\}_{k \in \mathbb{N}}$ 을 $H$ 의 정규직교 기저라고 하자. 그러면 $H$ 의 정규직교 기저는 유니터리 작용소 $U : H \to H$ 에 대해 정확하게 $\left\{ U \textbf{e}_{k} \right\}_{k \in \mathbb{N}}$ 과 같이 나타난다. 이러한 결과를 두고 $H$ 의 모든 정규직교 기저가 유니터리 작용소 $U$ 에 의해 캐릭터라이제이션Characterization 된다고 말한다. 증명</description>
    </item>
    
    <item>
      <title>균일한 구 껍질과 떨어진 입자 사이의 중력</title>
      <link>https://freshrimpsushi.github.io/posts/gravitational-force-between-a-uniform-sphere-and-a-particle/</link>
      <pubDate>Tue, 21 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gravitational-force-between-a-uniform-sphere-and-a-particle/</guid>
      <description>균일한 구 껍질과 떨어진 입자 사이의 중력1 전체 질량이 $M$이고 반지름이 $R$인 균일한 구 껍질이 있다고 하자. 그리고 구 껍질의 중심 $O$로부터 $r$만큼 떨어진 곳에 질량이 $m$인 입자가 있다고 하자. 이 때 $R&amp;lt;r$이다. 우선 구껍질 일부분이 입자에 미치는 힘을 구해보자. 위 그림과 같은 구 껍질 띠를 생각해보자. 그러면 껍질 띠의 반</description>
    </item>
    
    <item>
      <title>케플러의 행성 운동 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/keplers-laws-of-planetary-motion/</link>
      <pubDate>Tue, 21 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/keplers-laws-of-planetary-motion/</guid>
      <description>케플러의 행성 운동 법칙1 케플러 법칙은 티코 브라헤, 히파르코스 등의 천문학자들의 관측 기록을 모아 정리한 경험 법칙이다. 이는 뉴턴의 만유인력 법칙 유도에 큰 기여를 했다. 또한 반대로 만유인력 법칙과 뉴턴의 운동 법칙을 통해 케플러 법칙을 수식적으로 설명할 수 있게 됐다. 제1 법칙: 타원 궤도의 법칙 행성의 공전 궤도는 태양을 초점으로 하는 타원이다.</description>
    </item>
    
    <item>
      <title>4색 지도 문제</title>
      <link>https://freshrimpsushi.github.io/posts/four-color-map-problem/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/four-color-map-problem/</guid>
      <description>빌드업 4색 지도 문제란 어떤 지도든 이웃된 구역이 서로 구별되도록 채색하는데 4가지 색이면 충분한지 묻는 문제다. 지도가 복잡할수록 색은 많아져야할 것 같지만, 바로 옆이랑만 다르면 되기 때문에 생각보다 많은 색이 필요하지는 않다. 예를 들어 다음은 세계지도를 단 $4$가지 색으로 칠한 것이다. 역사적으로 4색 지도 문제는 1852년 영국의 식물학자</description>
    </item>
    
    <item>
      <title>만유인력의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/law-of-universal-gravity/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/law-of-universal-gravity/</guid>
      <description>만유인력의 법칙1 만유인력의 법칙law of universal gravity은 뉴턴이 1687년에 프린키피아를 통해 발표한 물리 법칙이다. 내용을 간단히 말하자면 &amp;lsquo;모든 물체는 서로 끌어당긴다&amp;rsquo;이다. 이를 자세하게 기술하면 아래와 같다. 질량을 가지는 모든 입자는 다른 입자에게 끌어당기는 힘을 작용한다. 이 힘의 크기는 서로 상호작</description>
    </item>
    
    <item>
      <title>입자계의 운동 에너지</title>
      <link>https://freshrimpsushi.github.io/posts/kinetic-energy-of-a-system/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kinetic-energy-of-a-system/</guid>
      <description>입자계의 운동 에너지1 입자계의 선운동량과 각운동량을 정의했던 것처럼 입자계의 운동 에너지 역시 각 입자의 운동에너지의 합으로 자연스럽게 정의할 수 있다. $$ \begin{equation} T=\sum \limits _{i=1} ^{n} \frac{ 1}{ 2 }m_{i}v_{i}^{2} \label{kinetic} \end{equation} $$ 이제 입자계의 선운동량, 각운동량을 질량중심에 대해서 나타냈던 것과 같은 작업을 할 것이다. 우선 각 입자의 위치 벡터를 아래 그림과 같이 질량 중심에 대한 표현으로 나</description>
    </item>
    
    <item>
      <title>중심력</title>
      <link>https://freshrimpsushi.github.io/posts/central-force/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/central-force/</guid>
      <description>정의 물체의 위치에 상관없이 물체에 작용하는 힘의 방향이 항상 같은 점을 향할 때 이 힘을 중심력이라 한다. 대표적인 예로 중력이 있다. 지구 그 어디에 있든 간에 우리에게 작용하는 중력은 지구 중심을 향한다. 중심력에 의해 운동하는 입자의 각운동량은 보존되고, 면적 속도가 일정하다는 사실을 수식적으로 보일 수 있다.</description>
    </item>
    
    <item>
      <title>입자계의 각운동량</title>
      <link>https://freshrimpsushi.github.io/posts/angluar-momentum-of-a-system/</link>
      <pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/angluar-momentum-of-a-system/</guid>
      <description>입자계의 각운동량1 입자계의 선운동량을 각 입자의 선운동량의 합으로 정의했다. 이와 마찬가지로 입자계의 각운동량은 각 입자의 각운동량의 합으로 정의된다. $$ \mathbf{L}=\sum \limits _{i=1} ^{n} (\mathbf{r}_{i}\times \mathbf{p}_{i}) $$ 토크는 각운동량의 변화율이므로 입자계의 토크는 아래와 같다. $$ \begin{align*} \mathbf{N} &amp;amp;= \frac{d \mathbf{L}}{dt} \\ &amp;amp;= \sum \limits _{i=1} ^{n}(\mathbf{v}_{i}\times \mathbf{p}_{i}) + \sum \limits _{i=1} ^{n}(\mathbf{r}_{i}\times m_{i}\mathbf{a}_{i}) \end{align*} $$ 이때 $\mathbf{p}_{i}=m_{i}\ma</description>
    </item>
    
    <item>
      <title>가분 힐베르트 공간은 스몰엘2 공간과 등거리동형임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/separable-hilbert-space-and-l2-space-are-isometrically-isomorphic/</link>
      <pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separable-hilbert-space-and-l2-space-are-isometrically-isomorphic/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 모든 무한차원 가분 힐베르트 공간 $H$ 는 $l^{2}$ 와 등거리 동형이다. 가분성을 가지는 힐베르트 공간이 $l^{2}$ 와 등거리 동형이라는 말은 사실상 힐베르트 공간을 연구할 때 $l^{2}$ 만 연구하면 된다는 말이나 진배 없다. 증명 가분 힐베르트 공간의 그램-슈미트 정규직교화모든 가분 힐베르트 공간은 정규직교기저를 가진다.</description>
    </item>
    
    <item>
      <title>각운동량과 토크</title>
      <link>https://freshrimpsushi.github.io/posts/angular-momentum-and-torque/</link>
      <pubDate>Fri, 17 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/angular-momentum-and-torque/</guid>
      <description>각운동량1 운동량은 병진 운동하는 물체의 운동 상태를 나태는 물리량이다. 질량이 클수록, 속도가 빠를수록 운동량이 크다. 물리학에서는 물체의 운동이 어떻게 변화하는지에 대해서 관심이 있다. 그래서 물체의 운동상태를 바꾸는 원인인 힘을 운동량의 변화로 표현하는 것이다. $$ \mathbf{F}=\frac{d \mathbf{p}}{dt} $$ 이제 회전 운동에 대해서도 이와 비슷한 물리량을 정의하려고 한다. 회</description>
    </item>
    
    <item>
      <title>5색 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-five-color-theorem/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-five-color-theorem/</guid>
      <description>정리 1 모든 심플 평면 그래프는 $5$-채색가능하다. 설명 이 정리는 4색 문제와 구분하는 의미에서 5색 정리라는 이름이 붙었다. 역사적으로는 4색 정리를 증명하려고 했지만 증명에 번번히 실패했고, 대신 조금 완화된 팩트로써 증명되었다. 증명 전략: 수학적 귀납법을 사용한다. $n-1$ 개의 버텍스를 가진 심플 평면 그래프가 모두 $5$-채색가능하다고</description>
    </item>
    
    <item>
      <title>뉴턴의 운동 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/newtons-laws-of-motion/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newtons-laws-of-motion/</guid>
      <description>뉴턴의 운동법칙 1 영국의 수학자이자 물리학자인 아이작 뉴턴Issac Newton은 1687년 프린키피아Principia, 자연철학의 수학적 원리에서 아래와 같은 운동에 관한 세 가지 법칙을 제시했다. 외부의 힘을 받지 않는 물체는 운동 상태를 바꾸지 않는다. 운동의 변화는 물체에 작용하는 힘과 비례한다. 물체1이 물체2에 힘을 가하면, 물</description>
    </item>
    
    <item>
      <title>물리학에서 질량 힘 운동량의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-mass-force-and-momentum-in-physics/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-mass-force-and-momentum-in-physics/</guid>
      <description>질량1 뉴턴의 운동 법칙에서 관성이란 운동의 변화에 저항하는 성질이라고 설명했다. 즉 관성이 크면 운동하기 어렵고 관성이 작으면 운동하기 쉽다는 말이다. 이는 가벼운 물체를 밀어 옮기는 것보다 무거울 물체를 밀어 옮기는 것이 더 힘들다는 경험과 딱 맞아 떨어진다. 즉, 관성의 크고 작음은 질량의 크고 작음으로 말할 수 있다. 질량이란 물체가 무겁고 가벼운 정</description>
    </item>
    
    <item>
      <title>운동량의 기호가 피인 이유</title>
      <link>https://freshrimpsushi.github.io/posts/the-reason-why-the-symbol-for-momentum-is-p/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-reason-why-the-symbol-for-momentum-is-p/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 물리학에서 쓰이는 많은 기호들은 깊게 생각하지 않아도 왜 그렇게 채택되었는지 알 수 있다. 예를 들어 힘을 뜻하는 기호인 $\mathbf{F}$나 질량, 속도, 가속도를 뜻하는 기호인 $m$, $\mathbf{v}$, $\mathbf{a}$는 각각 영단어 force, mass, velocity, acceleration의 앞글자에서 따왔음을 쉽게 추</description>
    </item>
    
    <item>
      <title>가분 힐베르트 공간의 그램-슈미트 정규직교화</title>
      <link>https://freshrimpsushi.github.io/posts/gram-schmidt-orthonormalization-of-separable-hilbert-space/</link>
      <pubDate>Tue, 14 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gram-schmidt-orthonormalization-of-separable-hilbert-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 모든 가분 힐베르트 공간은 정규직교기저를 가진다. 전략: 유한차원 벡터 공간에서의 그램-슈미트 정규직교화와 본질적으로 같다. 일반적인 힐베르트 공간은 유한차원 벡터 공간과 달리 기저의 존재성이 보장되지 않으므로 가분성에 따라 정규직교화를 거치기 전의 직교 기저인 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 를 잡아주어야한</description>
    </item>
    
    <item>
      <title>입자계의 질량중심과 선운동량</title>
      <link>https://freshrimpsushi.github.io/posts/center-of-mass-and-linear-momentum-of-a-system/</link>
      <pubDate>Mon, 13 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/center-of-mass-and-linear-momentum-of-a-system/</guid>
      <description>입자계와 질량중심1 질량이 $m_1$, $m_2$, $\cdots$, $m_n$인 입자들의 위치 벡터가 각각 $\mathbf{r}_{1}$, $\mathbf{r}_{2}$, $\cdots$, $\mathbf{r}_{n}$일 때 이 입자계system of particles의 질량중심center of mass을 아래와 같이 정의한다. $$ \mathbf{r}_{cm}=\frac{m_{1}\mathbf{r}_{1}+m_{2}\mathbf{r}_{2}+\cdots + m_{n}\mathbf{r}_{n}}{m_{1}+ m_{2}+ \cdots+ m_{n}}=\frac{\sum m_{i}\mathbf{r}_{i}}{m} $$ 이때 $m=\sum \limits_{i}m_{i}$는 입자계의 전체 질량이다. 아래첨자 $cm$은</description>
    </item>
    
    <item>
      <title>그래프 이론에서 지도의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/map-of-graph-theory/</link>
      <pubDate>Sun, 12 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/map-of-graph-theory/</guid>
      <description>정의 1 $3$-연결 평면 그래프를 지도라 정의한다. 같은 에지를 사이에 두고 이웃한 페이스끼리 다른 색이 되도록 $k$ 개의 색을 칠할 수 있는 지도를 $k$-페이스 채색가능 지도라 한다. 기존의 $k$-채색가능 그래프를 $k$-버텍스 채색가능 그래프라 한다. 평면 그래프가 그려지면서 평면 상에서 구분되는 영역들을 페이스라 부른다. 설명 $3$-그</description>
    </item>
    
    <item>
      <title>벡터 공간의 리오더링</title>
      <link>https://freshrimpsushi.github.io/posts/reordering-of-vector-space/</link>
      <pubDate>Fri, 10 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reordering-of-vector-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 벡터 공간 $V$ 의 시퀀스 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 이 주어져 있다고 하자. 주어진 전단사 $\sigma : \mathbb{N} \to \mathbb{N}$ 에 대해 다음을 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 의 리오더링이라 한다. $$ \left\{ \textbf{v}_{\sigma (k) } \right\}_{k \in \mathbb{N}} = \left\{ \textbf{v}_{\sigma(1)} , \textbf{v}_{\sigma(2)} , \cdots \right\} $$ 리오더링은 순열Permutation이라 불리기도 하는데, 보다시피 어려운 개념이 아니라 그냥 순서만 바꿔놓은 것에 불과</description>
    </item>
    
    <item>
      <title>심플 평면 그래프의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-simple-planar-graphs/</link>
      <pubDate>Wed, 08 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-simple-planar-graphs/</guid>
      <description>정리 1 $G$ 가 심플 평면 그래프라고 하자. [1]: $G$ 가 연결 그래프고 $n \ge 3$ 개의 버텍스, $m$ 개의 에지를 가지면 $m \le 3n - 6$ [2]: 모든 심플 평면 그래프 $G$ 는 $\deg v \le 5$ 인 버텍스 $v \in V(G)$ 를 가진다. 증명 [1] 평면 그래프의 각 페이스는 적어도 세 개의 에지로 둘러싸여있다고 하자.가장 간단한 케이스로 컴플리트 그래프 $K_{3}$ 만 달랑 있다면 에지 $m=3$ 에 페이스 $f=2$ 고, 여기서 페이스가</description>
    </item>
    
    <item>
      <title>무한 차원 벡터 공간의 샤우더 베이시스</title>
      <link>https://freshrimpsushi.github.io/posts/schauder-basis-of-infinite-dimensional-vector-space/</link>
      <pubDate>Mon, 06 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schauder-basis-of-infinite-dimensional-vector-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 유한 차원 벡터 공간의 기저 : 하멜 베이시스 벡터 공간 $X$ 의 모든 원소 $x \in X$ 에 대해 다음을 만족하는 스칼라의 시퀀스 $\left\{ a_{k} \right\}_{k \in \mathbb{N}}$ 가 유일하게 존재하면 $\left\{ \textbf{e}_{k} \right\}_{k \in \mathbb{N}} \subset X$ 를 $X$ 의 샤우더 기저라 한다. $$ x = \sum_{k \in \mathbb{N}} a_{k} \textbf{e}_{k} $$ 벡터 공간의 기저는 특히 &amp;lsquo;무한&amp;rsquo; 선형 결합에 대해 논할 때 샤</description>
    </item>
    
    <item>
      <title>추상적 듀얼 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/abstract-dual-graph/</link>
      <pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abstract-dual-graph/</guid>
      <description>빌드업 기하적 듀얼 그래프의 성질 [3]: 평면 그래프 $G$ 와 그 기하적 듀얼 그래프 $G^{ \ast }$ 에 대해,$C \subset E(G)$ 가 사이클 $\iff$ $C^{ \ast } \subset E \left( G^{ \ast } \right)$ 는 컷셋 추상적 듀얼 그래프는 직관적으로 평면 그래프에 대해 기하적 듀얼 그래프와 달리 일반적인 그래프에 대해서 추상적으로 정의된다. 듀얼 그래프가 어떠한 방법으로 만들어지는 것이 아니라, 듀얼의 성질을 가지면 듀얼 그</description>
    </item>
    
    <item>
      <title>리만(-스틸체스) 적분은 선형이다</title>
      <link>https://freshrimpsushi.github.io/posts/linearity-of-riemann-stieltjes-integral/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearity-of-riemann-stieltjes-integral/</guid>
      <description>해당 글은 리만-스틸체스 적분을 기준으로 작성되었다. $\alpha=\alpha(x)=x$로 두면 리만 적분과 같다. 정리1 $f$가 $[a,b]$에서 리만(-스틸체스) 적분 가능하다고 하자. 그러면 상수 $c\in \mathbb{R}$에 대해서 $cf$도 $[a,b]$에서 적분 가능하고 그 값은 아래와 같다. $$ \int_{a}^{b}cf d\alpha = c\int_{a}^{b}f d\alpha $$ 두 함수</description>
    </item>
    
    <item>
      <title>조밀한 부분공간을 갖는 힐베르트 공간의 베셀 시퀀스</title>
      <link>https://freshrimpsushi.github.io/posts/bessel-sequence-in-hilbert-space-having-dense-subspace/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bessel-sequence-in-hilbert-space-having-dense-subspace/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 힐베르트 공간 $H$ 가 주어져 있을 때 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}} \subset H$ 와 $\overline{V} = H$ 인 $V \subset H$ 가 다음을 만족한다고 하자. $$ \sum_{k \in \mathbb{N}} \left| \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt; \right|^{2} \le B \left\| \textbf{v} \right\|^{2} \qquad , \textbf{v} \in V $$ 그러면 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 은 베셀 바운드 $B$ 인 베셀 시퀀스다. 원래 베셀 시퀀스는 모든 $\textbf{v} \in H$ 에서 부등식을 만족해야했지만, $\overline{V} = H$ 에 따라 그러한 조건이 약화</description>
    </item>
    
    <item>
      <title>기하적 듀얼 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/geometric-dual-graph/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/geometric-dual-graph/</guid>
      <description>정의 1 주어진 평면 그래프 $G$ 에 대해 기하적 듀얼 그래프 $G^{ \ast }$ 는 다음과 같이 만들어진다. **Step 1. $G$ 의 각 페이스 $f$ 에 대응되는 버텍스 $v^{ \ast }$ 를 찍는다. Step 2. $G$ 의 각 에지 $e$ 와 겹치도록 대응되는 에지 $e^{ \ast }$ 를 긋는다. Step 3. 원래의 그래프는 지우고 $v^{ \ast }$ 와 $e^{ \ast }$ 로 이루어진 그래프를 $G^{ \ast }$ 로 둔다. 평면 그래프가 그려지면서 평면 상에서 구분되는 영역들을 페</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서의 베셀 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bessels-inequality-of-hilbert-space/</link>
      <pubDate>Sun, 28 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bessels-inequality-of-hilbert-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 푸리에 해석에서의 베셀 부등식 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 이 힐베르트 공간 $H$ 의 정규직교 집합이라고 하면 다음이 성립한다. [1]** 모든 $\left\{ c_{k} \right\}_{k \in \mathbb{N}} \in l^{2}$ 에 대해 무한 급수 $\sum_{k \in \mathbb{N}} c_{k} \textbf{v}_{k}$ 는 수렴한다. [2]: 모든 $\textbf{v} \in H$ 에 대해 $$ \sum_{k \in \mathbb{N}} \left| \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt; \right|^{2} \le \left\| \textbf{v} \right\|^{2} $$ $l^{2}$ 공간이란 제곱의 합이 수렴하는 복소수 시퀀스의 집합으로 이루어</description>
    </item>
    
    <item>
      <title>그래프의 k-연결성과 멩거 정리</title>
      <link>https://freshrimpsushi.github.io/posts/k-connected-and-menger-theorem/</link>
      <pubDate>Fri, 26 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k-connected-and-menger-theorem/</guid>
      <description>정의 주어진 그래프 $G$ 에 대해 컴포넌트의 수를 $\text{comp} (G)$ 라고 나타내자. 1-1. 다음을 만족하는 에지의 집합 $D \subset E(G)$ 를 $G$ 의 단절 집합Disconnecting Set이라 한다. $$ \text{comp} \left( G \setminus D \right) &amp;gt; \text{comp}(G) $$ 1-2. $G$ 단절 집합 중 단절 집합이 아닌 진부분집합을 갖지 않는 단절 집합을 $G$ 의 컷셋Cutset이라 부른다. 1-3. $G$ 가 연결 그래프라고 할 때, (에지) 컷셋의 기수 중</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서의 베셀 시퀀스</title>
      <link>https://freshrimpsushi.github.io/posts/bessel-sequence-of-hilbert-space/</link>
      <pubDate>Wed, 24 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bessel-sequence-of-hilbert-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 힐베르트 공간 $H$ 의 시퀀스 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}} \subset H$ 에 대해 다음을 만족하는 $B &amp;gt; 0$ 가 존재하면 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 를 베셀 시퀀스라 하고 $B$ 를 베셀 바운드라 한다. $$ \sum_{k=1}^{\infty} \left| \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt; \right|^{2 } \le B \left\| \textbf{v} \right\|^{2} \qquad , \forall \textbf{v} \in H $$ 베셀 시퀀스 는 직관적으로 봤을 때 무한차원 벡터 $\textbf{v}$ 의 뒷부분이 작아지도록 휘어주는 시퀀스로 볼 수 있다.</description>
    </item>
    
    <item>
      <title>오일러의 다면체 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-polyhedron-formula/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-polyhedron-formula/</guid>
      <description>정리 1 연결 평면 그래프 $G$ 에 대해, $n:=|V(G)|$, $m:=|E(G)|$, $f$ 를 페이스의 수라고 하면 $$ n-m+f=2 $$ 평면 그래프가 그려지면서 평면 상에서 구분되는 영역들을 페이스라 부른다. 설명 오일러의 다면체 정리 는 오일러의 표수 , 그래프 이론에서는 그냥 오일러 공식 으로도 불린다. 기하학적으로는 공간도형의 점, 선, 면이 #점-#선+#면=2 의 관계를 따른다는 의미를 갖는다. 예로써</description>
    </item>
    
    <item>
      <title>리즈 기저</title>
      <link>https://freshrimpsushi.github.io/posts/riesz-basis/</link>
      <pubDate>Mon, 22 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riesz-basis/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 힐베르트 공간 $H$ 의 정규 직교 기저 $\left\{ \textbf{e}_{k} \right\}_{k \in \mathbb{N}}$ 이 주어져 있다고 하자. 전단사 $U : H \to H$ 가 선형이고 유계인 작용소 모든 $k \in \mathbb{N}$ 에 대해 $\textbf{v}_{k} := U \textbf{e}_{k}$ 라고 하면 $\left\{ \textbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 는 $H$ 의 기저가 되며 다음이 성립한다. $$ \textbf{v} = \sum_{k \in \mathbb{N}} \left&amp;lt; \textbf{v} , \left( U^{-1} \right)^{ \ast } \textbf{e}_{k} \right&amp;gt; \textbf{v}_{k} $$ $U$ 가 주어졌을 때 위와 같이 기저를 구체적으로 잡을 수 있다</description>
    </item>
    
    <item>
      <title>웨이블릿이의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-wavelet/</link>
      <pubDate>Mon, 22 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-wavelet/</guid>
      <description>정의 $\psi \in L^{2}(\mathbb{R})$이라고 하자. $\psi$가 아래의 두 조건을 만족시킬 때 함수 $\psi$를 웨이블릿wavelet이라 한다. (a) 정수 $j,k \in \mathbb{Z}$에 대해서, $\psi_{j,k}$를 아래와 같이 정의한다. $$ \psi_{j,k} (x):=2^{\frac{j}{2}}\psi(2^{j}x-k),\quad x\in \mathbb{R} $$ (b) $\left\{ \psi _{j,k}\right\}_{j,k\in \mathbb{Z}}$가 $L^{2}(\mat</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서 스몰엘2 공간으로의 수반 작용소</title>
      <link>https://freshrimpsushi.github.io/posts/adjoint-operator-form-hilbert-space-to-l2-space/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adjoint-operator-form-hilbert-space-to-l2-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\left\{ \textbf{v}_k \right\}_{k \in \mathbb{N}}$ 이 힐베르트 공간 $H$ 에서 정의된 시퀀스라 하자.유계 선형 작용소 $T : l^{2} \to H$ 가 다음과 같이 정의되어있다고 하자. $$ T \left\{ c_{k} \right\}_{k \in \mathbb{N}} := \sum_{k=1}^{\infty} c_{k} \textbf{v}_{k} $$ 그러면 $T$ 의 수반 작용소 $T^{ \ast } : H \to l^{2}$ 는 다음과 같이 나타난다. $$ T^{ \ast } \textbf{v} = \left\{ \left&amp;lt; \textbf{v} , \textbf{v}_{k} \right&amp;gt;_{H} \right\}_{k \in \mathbb{N}} $$ 그 뿐만 아니라, 모든 $\textbf{v} \in H$ 에 대해 $$ \sum_{k=1}^{\infty} \left|</description>
    </item>
    
    <item>
      <title>평면 그래프와 쿠라토프스키 정리</title>
      <link>https://freshrimpsushi.github.io/posts/planar-graph-and-kuratowski-theorem/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/planar-graph-and-kuratowski-theorem/</guid>
      <description>정리 그래프를 평면에 그렸을 때 에지가 겹치지 않게 그릴 수 있으면 그 그래프를 평면 그래프라 한다. 설명 평면 그래프가 그려지면서 평면 상에서 구분되는 영역들을 페이스Face라 부른다. 다음과 같은 평면 그래프 $K_{4}$ 는 네 개의 페이스 $f_{1}, f_{2}, f_{3}, f_{4}$ 를 가지며, 그 중에서도 특히 바운드 되지 않은 $f_{4}$ 를 무한 페이스Infinite Face라 부른다. 평면 그래프는</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서의 직교 사영</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-projection/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-projection/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 선형대수학에서의 정사영 힐베르트 공간 $H$ 의 폐부분공간 $V$ 이 주어져있다고 하자. $\textbf{v} \in H$ 이 $\textbf{v}_{1} \in V$ 와 $\textbf{v}_{2} \in V^{\perp}$ 에 대해 $\textbf{v} = \textbf{v}_{1} + \textbf{v}_{2}$ 와 같이 나타난다고 할 때, 다음을 만족시키는 전사 $P :H \to V$ 를 직교 사영이라고 한다. $$ P \textbf{v} = \textbf{v}_{1} $$ 직교 사영은 다음과 같은 성질들을 가진다. [1]: $P$ 는 선형이고 유계이며, $|</description>
    </item>
    
    <item>
      <title>그래프의 호메오멀피즘</title>
      <link>https://freshrimpsushi.github.io/posts/homeomorphism-of-graphs/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homeomorphism-of-graphs/</guid>
      <description>정의 1 두 그래프 $G_{1}$ 와 $G_{2}$ 가 주어져 있다고 하자. $G_{1}$ 의 어떤 세분 $G_{1}&#39;$ 과 $G_{2}$ 의 어떤 세분 $G_{2}&#39;$ 에 대해 그래프 아이소멀피즘이 존재하면 $G_{1}$ 와 $G_{2}$ 가 호메오멀픽Homeomorphic하다고 한다. 그래프 $G$ 에 다음과 같은 조건을 만족하는 버텍스 $w$ 들을 차례로 추가한 그래프를 $G$ 의 세분Subdivision $G&#39;$ 이라 한다. $$ \begin{align*} u \sim_{G} v &amp;amp; \implies \begin{cases} u \nsim_{G&#39;} v \\ u \sim_{G&#39;} w \\ w</description>
    </item>
    
    <item>
      <title>상수 계수를 갖는 1계 선형 동차 미분 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/first-order-linear-homogeneous-differential-equation-with-constant-coefficients/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/first-order-linear-homogeneous-differential-equation-with-constant-coefficients/</guid>
      <description>정리 상수 계수를 갖는 1계 선형 동차 미분 방정식 $$ \frac{ d y}{ d x}=\alpha y $$ 의 일반해는 $$ y=Ae^{\alpha x} $$ 이다. 이때 $A$는 상수이다. 설명 한 번 미분했을 때 자기 자신과 같은 함수가 무엇인지 생각해보면 왜 지수 함수가 답인지 알 수 있을 것이다. 증명 $$ \frac{ d y}{ d x}=\alpha y $$ 에서 변수 분리를 해주면 $$ \frac{ 1 }{ y }dy=\alpha dx $$ 양 변을 적분하면 $$ \ln y=ax+C $$ 이때 $C$는 적분 상수이다. $y</description>
    </item>
    
    <item>
      <title>1계 선형 미분 방정식 시스템</title>
      <link>https://freshrimpsushi.github.io/posts/system-of-first-order-linear-differential-equation/</link>
      <pubDate>Thu, 11 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/system-of-first-order-linear-differential-equation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $x_1$, $x_2$, $\cdots$, $x_n$을 $t$에 대한 함수라고 하자. $F_1$, $F_2$, $\cdots$, $F_n$을 $x_1$, $x_2$, $\cdots$, $x_n$에 대한 함수라고 하자. 그러면 $x_i(t),$ $1\le i \le n$에 대한 1계 미분 방정식 시스템은 아래와 같다. 1계 미분 방정식 시스템 $$ \begin{align*} x_{1}&#39;(t) &amp;amp;= F_{1}(t,x_{1},x_{2},\cdots,x_{n}) \\ x_{2}&#39;(t) &amp;amp;= F_{2}(t,x_{1},x_{2},\cdots,x_{n}) \\ \vdots &amp;amp; \\ x_{n}&#39;(t) &amp;amp;= F_{n}(t,x_{1},x_{2},\cdots,x_{n}) \end{align*} $$ 이 때 각각의 $F_{i}$가 선형이면 선형 시스</description>
    </item>
    
    <item>
      <title>라게르 다항식의 로드리게스 공식</title>
      <link>https://freshrimpsushi.github.io/posts/rodrigues-formula-of-laguerre-polynomial/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rodrigues-formula-of-laguerre-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 라게르 다항식은 라게르 미분 방정식 $$ xy&#39;&#39;+(1-x)y&#39;+ny=0,\quad n=0,1,2,\cdots $$ 의 해를 말하며 $L_{n}(x)$로 표기하고 각 $n$에 대해서 아래와 같다. $$ \begin{align*} L_{0}(x) &amp;amp;= 1 \\ L_{1}(x) &amp;amp;= -x+1 \\ L_{2}(x) &amp;amp;= \frac{1}{2}\left( x^{2}-4x+2 \right) \\ L_{3} (x) &amp;amp;=\frac{1}{6}\left( -x^{3}+9x^{2}-18x+6 \right) \\ &amp;amp; \vdots \end{align*} $$ 위 식들은 미분 방정식을 풀어서 직접 각각의 $n$에 대해서 얻은 것이다. 각각의 $n$에 대해서 라게르 다항식</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서의 수반 작용소</title>
      <link>https://freshrimpsushi.github.io/posts/adjoint-operator-on-hilbert-space/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adjoint-operator-on-hilbert-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 힐베르트 공간 $\left( H, \left&amp;lt; \cdot , \cdot \right&amp;gt;_{H} \right)$ 과 $\left( K, \left&amp;lt; \cdot , \cdot \right&amp;gt;_{K} \right)$ 에 대해 유계 선형 작용소 $T : K \to H$ 가 주어져있다고 하자. 그러면 임의의 픽스된 원소 $\textbf{w} \in H$ 에 대해 다음과 같이 정의된 $\Phi : K \to \mathbb{C}$ 는 선형 범함수 $\Phi \in K^{ \ast }$ 가 된다. $$ \Phi \textbf{v} := \left&amp;lt; T \textbf{v} , \textbf{w} \right&amp;gt;_{H} $$ 리즈 표현 정리에 따르면 힐베르트 공간 $K$ 는 $\Phi \in K^{ \ast }$</description>
    </item>
    
    <item>
      <title>에르미트 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/herimite-polynomial/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/herimite-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 에르미트 다항식은 아래의 두 방법으로 얻을 수 있다. 첫번째 방법은 에르미트 함수로부터 얻는 것이다. 아래의 에르미트 함수 $$ y_n=e^{\frac{x^{2}}{2}}\frac{ d ^{n} }{ dx^{n} }e^{-x^{2}} $$ 에 $(-1)^{n}e^{\frac{x^{2}}{2}}$를 곱한 것을 에르미트 다항식 이라 한다. $$ H_{n}(x)=(-1)^{n}e^{x^{2}}\frac{ d ^{n}}{ dx^{n} }e^{-x^{2}} \tag{1} $$ 위 식은 에르미트 다항식의 로</description>
    </item>
    
    <item>
      <title>에르미트 다항식의 생성 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-generating-function-of-hermite-polynomial/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-generating-function-of-hermite-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 에르미트 다항식의 생성 함수는 아래와 같다. $$ \Phi (x,t)=\sum \limits _{n=0}^{\infty} \frac{H_{n}(x)}{n!}t^{n}= e^{2xt-t^{2}} $$ $H_{n}(x)$는 에르미트 다항식이며 에르미트 함수 $y_{n}=e^{\frac{x^{2}}{2}}\frac{ d ^{n} }{ d x^{n} }e^{-x^{2}}$에 $(-1)^{n}e^{\frac{x^{2}}{2}}$를 곱해서 얻거나 에르미트 미분 방정식을 풀어서 얻을 수 있다.</description>
    </item>
    
    <item>
      <title>에르미트 다항식의 재귀 관계</title>
      <link>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-hermite-polynomial/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-hermite-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 에르미트 다항식은 아래와 같은 재귀 관계를 만족한다. $$ \leqalignno{ H_{n}&#39;(x) &amp;amp;=2nH_{n-1}(x) &amp;amp; (a) \\ H_{n+1}(x) &amp;amp;= 2xH_{n}(x)-2nH_{n-1}(x)&amp;amp; (b) \\ &amp;amp;=2xH_{n}(x)-H_{n}&#39;(x) } $$ 에르미트 다항식 $$ H_{n}(x)=(-1)^{n}e^{x^{2}}\frac{ d ^{n}}{ dx^{n} }e^{-x^{2}} $$ 에르미트 다항식의 생성함수 $$ \Phi (x,t) = e^{2xt-t^{2}}=\sum \limits _{n=0}^{\infty} H_n(x)\frac{t^{n}}{n!} \tag{1} $$ 증명 $(a)$ 생성함수를 이용한 풀이 $(1)$의 가운데, 오른쪽 식을 $x$에 대해서 미분하면 $$ 2te^{2xt-t^{2}}=\sum \limits _{n=0}^{\infty}H_{n}&#39;(x)\frac{t^{n}}{n!} $$ 그러면 좌변은 다시 $</description>
    </item>
    
    <item>
      <title>에르미트 다항식의 직교성</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-of-hermite-polynomials/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-of-hermite-polynomials/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 에르미트 다항식 $H_{0}(x),H_{1}(x),H_{2}(x),\cdots $은 구간 $[-\infty, \infty]$에서 가중 함수 $w(x)=e^{-x^{2}}$에 대해서 서로 직교한다. 즉, 다시 말해서 $$ &amp;lt;H_{n}|H_{m}&amp;gt; =\int_{-\infty}^{\infty}e^{-x^{2}}H_{n}(x)H_{m}(x)dx=\sqrt{\pi}2^{n}n!\delta_{nm} $$ $&amp;lt;|&amp;gt;$는 디랙 노테이션, $\delta_{nm}$은 크로네커 델타이다. 에르미트 다항식의 재귀 관계 $$ H_{n}&#39;(x) =2nH_{n-1}(x) $$ 증명 $</description>
    </item>
    
    <item>
      <title>그래프 컬러링과 브룩스 정리</title>
      <link>https://freshrimpsushi.github.io/posts/graph-coloring-and-brooks-theorem/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/graph-coloring-and-brooks-theorem/</guid>
      <description>정의 루프가 없는 그래프 $G$ 에 대해 다음과 같은 함수 $f : V(G) \to [k]$ 를 $G$ 의 $k$-컬러링이라 한다. $$ u \sim v \implies f(u) \ne f(v) $$ 그래프 $G$ 가 $k$-컬러링을 가지면 $k$-채색가능이라도 한다. 만약 $k$-채색가능인데 $(k-1)$-채색가능하지 않으면 그 $k$ 를 $G$ 의 크로마틱 수Chromatic Number라 부르고 $\chi(G) = k$ 와 같이 나타낸다. 크</description>
    </item>
    
    <item>
      <title>셀버그 항등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-selberg-identity/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-selberg-identity/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $$ \Lambda (n) \log n + \sum_{d \mid n } \Lambda (d) \Lambda \left( {{ n } \over { d }} \right) = \sum_{d \mid n} \mu (d) \log^{2} {{ n } \over { d }} $$ 전략: 보이는 것만큼 어렵지 않다. 산술함수의 미분만 있다면 아주 간단하게 유도할 수 있다. 증명 망골트 급수 $$ \sum_{d \mid n} \Lambda ( d ) = \log n $$ 산술 함수의 미분의 정의에 따라 망골트 급수는 컨볼루션을 써서 다음과 같이 나</description>
    </item>
    
    <item>
      <title>포흐하머 기호</title>
      <link>https://freshrimpsushi.github.io/posts/pochhammer-symbol/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pochhammer-symbol/</guid>
      <description>정의 포흐하머 기호는 아래와 같이 두 종류의 표현이 있다. 아래의 식을 하강 계승falling factorial이라 정의한다. $$ \begin{align*} x^{\underline{n}} := (x)_{n}&amp;amp;=x(x-1)(x-2)\cdots(x-n+1) \\ &amp;amp;=\frac{x!}{(x-n)!}=\frac{\Gamma (x+1) }{ \Gamma(x-n+1)} \\ &amp;amp;=\prod \limits_{k=0}^{n-1}(x-k) \end{align*} $$ 아래의 식을 상승 계승rasing factorial이라 정의한다. $$ \begin{align*} x^{\overline{n}} := x^{(n)}&amp;amp;=x(x+1)(x+2)\cdots(x+n-1) \\ &amp;amp;=\frac{(x+n-1)!}{(x-1)!}=\frac{\Gamma (x+n) }{ \Gamma(x)} \\ &amp;amp;=\prod \limits_{k=0}^{n-1}(x+k) \end{align*} $$ $x^{\overline{0}}$과 $x^{\underline</description>
    </item>
    
    <item>
      <title>라게르 미분 방정식의 급수해</title>
      <link>https://freshrimpsushi.github.io/posts/series-solution-of-laguerre-differential-equation/</link>
      <pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-solution-of-laguerre-differential-equation/</guid>
      <description>정의 다음의 미분방정식을 라게르Laguerre 미분방정식이라 한다. $$ xy&#39;&#39;+(1-x)y&#39;+ny=0,\quad n=0,1,2,\cdots $$ 라게르 미분방정식의 해를 라게르 다항식이라 하고 흔히 $L_{n}(x)$으로 표기한다. 처음 몇 개의 라게르 다항식은 다음과 같다. $$ \begin{align*} L_{0}(x) =&amp;amp; 1 \\ L_{1}(x) =&amp;amp; -x+1 \\ L_{2}(x) =&amp;amp; \frac{1}{2}\left( x^{2}-4x+2 \right) \\ L_{3}(x) =&amp;amp; \frac{1}{6}\left( -x^{3}+9x^{2}-18x+6 \right) \\ \vdots &amp;amp; \end{align*} $$ 설명 $x=0$일 때 $y&#39;&#39;$의 계수인 $P(x)=x$가 $0$</description>
    </item>
    
    <item>
      <title>하벨-하키미 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-havel-hakimi-algorithm/</link>
      <pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-havel-hakimi-algorithm/</guid>
      <description>정리 증가하지 않는 시퀀스 $D = (d_{1} , \cdots , d_{n})$ 가 주어져있다고 하자. $D$ 가 그래픽하다면 다음과 같은 방법으로 $D$ 의 실현 $G$ 를 찾을 수 있다. **Step 1. $n$ 개의 버텍스 $v_{1} , \cdots , v_{n}$ 를 가지는 널 그래프를 만든다. Step 2. $k = 1, \cdots , n$ **Step 2-1. $v_{k}$ 과 $v_{k+1} , \cdots , v_{d_{k} + 1}$ 를 잇는다. Step 2-2. $d_{k+1} , \cdots , d_{d_{k}+1}$ 를 $1$ 씩 감소시킨다. Step 2-3. $d_{k} \leftarrow 0$ 와 같이 대입한다. $D = (0,\cdots , 0)$ 이 될때까지 Step 2.를</description>
    </item>
    
    <item>
      <title>에르미트 미분방정식의 급수해: 에르미트 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/series-solution-of-hermite-differential-equation/</link>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-solution-of-hermite-differential-equation/</guid>
      <description>정의 다음의 미분방정식을 에르미트Hermite 미분방정식이라 한다. $$ y&#39;&#39;-2xy&#39;+2ny=0,\quad n=0,1,2,\cdots $$ 에르미트 미분방정식의 해를 에르미트 다항식이라 하고 흔히 $H_{n}(x)$으로 표기한다. 처음 몇 개의 에르미트 다항식은 다음과 같다. $$ \begin{align*} H_{0}(x) =&amp;amp; 1 \\ H_{1}(x) =&amp;amp; 2x \\ H_{2}(x) =&amp;amp; 4x^{2}-2 \\ H_{3}(x) =&amp;amp; 8x^{3}-12x \\ H_{4}(x) =&amp;amp; 16x^{4}-48x^{2}+12 \\ H_{5}(x) =&amp;amp; 32x^{5}-160x^{3}+120x \\ \vdots&amp;amp; \end{align*} $$ 설명 Hermite는 프랑스 사람이므로 [에르미트]</description>
    </item>
    
    <item>
      <title>산술 함수의 미분</title>
      <link>https://freshrimpsushi.github.io/posts/derivative-of-arithmetical-function/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivative-of-arithmetical-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 산술 함수 $f$ 의 미분 혹은 도함수 $f&#39;$ 를 다음과 같이 정의한다. $$ f&#39;(n) := f(n) \log n \qquad , n \in \mathbb{N} $$ [1] 합의 미분법: $(f+g)&#39; = f&#39;+g&#39;$ [2] 곱의 미분법**: $(f*g)&#39; = f&#39;*g + f*g&#39;$ [3] 몫의 미분법**: $f(1) \ne 0$ 이면 $\left( f^{-1} \right)&#39; = - f&#39; \ast\ (f \ast\ f)^{-1}$ 산술 함수는 개념적으로는 그냥 수열에 지나지 않기 때문에 흔히 변화율로 설명되곤 하는 미분을 정의할</description>
    </item>
    
    <item>
      <title>에르미트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-function/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 에르미트 함수는 다음과 같다. $$ \begin{align} y_{n} &amp;amp;= \left( D-x \right)^{n} e^{-\frac{x^{2}}{2}} \\ &amp;amp;=e^{\frac{x^{2}}{2}} D^{n} e^{-x^{2}} \end{align} $$ 이때 $D=\frac{d}{dx}$는 미분 연산자이다. 에르미트 함수는 미분 방정식 $$ y_{n}&#39;&#39;-x^{2}y_{n}=-(2n+1)y_{n},\quad n=0,1,2,\cdots $$ 의 해이며 물리학에서 1차원 조화진동자 슈뢰딩거 방정식의 해이다. 즉 1차원 조화 진동자의 파동함수이다. $(1)$은 미분 방정식</description>
    </item>
    
    <item>
      <title>에르미트 함수가 만족하는 미분 방정식의 연산자 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/operator-solution-of-differential-equation-satisfied-by-hermite-function/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operator-solution-of-differential-equation-satisfied-by-hermite-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 주어진 미분 방정식 $$ y_{n}&#39;&#39;-x^{2}y_{n}=-(2n+1)y_{n},\quad n=0,1,2,\cdots \tag{1} \label{eq1} $$ $\eqref{eq1}$ 의 해는 아래와 같으며 에르미트 함수라 부른다. $$ \begin{align*} y_{n} &amp;amp;= \left( D-x \right)^{n} e^{-\frac{x^{2}}{2}} \\ &amp;amp;=e^{\frac{x^{2}}{2}} D^{n} x^{-x^{2}} \end{align*} $$ 이때 $D$는 미분 연산자 $D=\frac{ d }{ dx }$이다. $y_{n}$의 첫번째 식은 미분 방정식을 풀어서 직접 얻을 수 있다. 두번째 식이 첫번째 식과 같음은 수학적 귀납법을 통해 증명할 수 있다</description>
    </item>
    
    <item>
      <title>미분 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/differential-operator/</link>
      <pubDate>Sun, 31 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/differential-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 미분 방정식을 푸는 여러 방법 중 하나는 미분 연산자를 이용하여 푸는 것이다. 미분 연산자 $D$를 아래와 같이 정의하자. $$ D:= \frac{d}{dx} $$ 미분하는 변수를 확실히 표현할 때는 $D_{x}$와 같이 표기하기도 한다. 편미분에 대해서는 아래와 같이 나타낸다. $$ \partial _{x}:=\frac{ \partial }{ \partial x},\quad \partial_{y}=\frac{ \partial }{ \partial y} $$ 미분 연산자를 사용</description>
    </item>
    
    <item>
      <title>물리학에서 고유값 문제란</title>
      <link>https://freshrimpsushi.github.io/posts/eigenvalue-problem/</link>
      <pubDate>Sat, 30 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eigenvalue-problem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 고유값 문제를 푸는 방법 $n\times n$ 행렬 $A$가 주어졌다고 하자. $$ A\mathbf{x}=\lambda \mathbf{x} $$ 행렬 $A$에 대해서 위의 식을 만족하는 $n\times 1$ 행렬 $\mathbf{x}$와 상수 $\lambda$를 찾는 것을 고유값 문제라고 한다. 이러한 행렬 $\mathbf{x}$를 $A$의 고유함수라하고 $\lambda</description>
    </item>
    
    <item>
      <title>에르되시-갈라이 정리</title>
      <link>https://freshrimpsushi.github.io/posts/erdoes-gallai-theorem/</link>
      <pubDate>Sat, 30 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/erdoes-gallai-theorem/</guid>
      <description>빌드업 그래프 $G$ 의 차수를 중복을 포함해 모아놓은 집합을 그래프 스코어Graph Score라 하고, $G$ 의 그래프 스코어를 내림차순으로 정렬한 시퀀스를 $G$ 의 디그리 시퀀스Degree Sequence라 한다. 증가하지 않는 자연수들의 시퀀스 $D = (d_{1} , \cdots , d_{n})$ 에 대해 $n$ 개의 버텍스 $v_{1} , \cdots , v_{n}$ 가 다음을 만족 시키게끔 하는 그래프 $G$ 가 존재하면 $D$ 가</description>
    </item>
    
    <item>
      <title>각운동량과 위치 운동량의 교환자</title>
      <link>https://freshrimpsushi.github.io/posts/commutator/</link>
      <pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/commutator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 각운동량과 위치의 교환자는 다음과 같다. $$ \begin{align*} [L_{z},x]&amp;amp;=i\hbar y \\ [L_{z},y]&amp;amp;=-i\hbar x \\ [L_{z},z]&amp;amp;=0 \end{align*} $$ 위치와 운동량의 교환자$$ \begin{align*} [x,p_{x}]&amp;amp;=i\hbar \end{align*} $$ 증명 $$ \begin{align*} [L_{z},x] &amp;amp;= [xp_{y}-yp_{x},x] \\ &amp;amp;= xp_{y}x-xxp_{y}-(yp_{x}x-xyp_{x}) \end{align*} $$ 서로 다른 성분의 위치와 운동량은 교환 가능하므로 $$ xp_{y}x-xxp_{y} = xxp_{y}-xxp_{y}=0 $$ 따라서 $$ \begin{align*} [L_{z},x] &amp;amp;= -yp_{x}x+xyp_{x} \\ &amp;amp;= -yp_{x}x+yxp_{x} \\ &amp;amp;= y(xp_{x}-p_{x}x) \\ &amp;amp;= y[x,p_{x}] \\ &amp;amp;= y(i\hbar) \\ &amp;amp;= i\hbar y \end{align*} $$ 같은 방식으로 $$ \begin{align*} [L_{z},y] &amp;amp;= [xp_{y}-yp_{x},y] \\ &amp;amp;= xp_{y}y-yxp_{y}-yp_{x}y+yyp_{x} \\ &amp;amp;= xp_{y}y-yxp_{y} \\</description>
    </item>
    
    <item>
      <title>구면좌표계에서 각운동량의 사다리 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/the-ladder-operator-of-angular-momentum-in-spherical-coordinates/</link>
      <pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-ladder-operator-of-angular-momentum-in-spherical-coordinates/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 구면좌표계에서 두 사다리 연산자의 곱 $L_{+} L_{-}$의 곱은 다음과 같다. $$ L_{+}L_{-}=-\hbar ^{2} \left( \frac{ \partial ^{2}}{ \partial \theta ^{2} } + \cot \theta \frac{ \partial }{ \partial \theta }+\cot ^{2}\theta \frac{ \partial ^{2}}{ \partial \phi^{2} } +i\frac{ \partial }{ \partial \phi}\right) $$ 단순 계산이라 풀이가 어려운 것은 아니나 식이 복잡하고 길어 실수하기 쉬우므로 꼼꼼하게 풀 필요가 있다. 또한 $L_{\pm}$는 미분연산자이</description>
    </item>
    
    <item>
      <title>산술 함수의 벨 급수</title>
      <link>https://freshrimpsushi.github.io/posts/bell-series-of-arithmetical-function/</link>
      <pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bell-series-of-arithmetical-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 주어진 산술 함수 $f$ 와 소수 $p$ 에 대해 다음과 같이 정의된 $f_{p}(x)$ 를 모듈로 $p$ 에서 $f$ 의 벨 급수 라한다. $$ f_{p}(x) := \sum_{n=0}^{\infty} f \left( p^{n} \right) x^{n} $$ 전통적인 의미에서의 무한 급수가 등장한다는 것은 본격적으로 해석적 정수론이 해석학을 도입한 것으로 보아도 좋다. 벨 급수는 특히 승법적 함수에 대해 연구할 때 유용한 개념으로써 다음</description>
    </item>
    
    <item>
      <title>각운동량 연산자의 고유함수는 구면조화함수이다</title>
      <link>https://freshrimpsushi.github.io/posts/the-eigenfunction-of-angular-momentum-operator-is-spherical-harmonics/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-eigenfunction-of-angular-momentum-operator-is-spherical-harmonics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 각운동량 연산자 $L^{2}$와 $L_{z}$는 상수 $l$, $m$에 의해 결정되는 고유함수를 공통으로 가진다. 이를 $f_{l}^{m}$이나 디랙 노테이션을 고려하여 $|l,m&amp;gt;$으로 표기한다. $$ \begin{align*} L^{2}|l,m&amp;gt;&amp;amp;=\hbar^{2}l(l+1)|l,m&amp;gt;\tag {1} \\ L_{z}|l,m&amp;gt;&amp;amp;=m\hbar|l,m&amp;gt; \end{align*} $$ 이때 각운동량 연산자의 고유함수 $|l,m&amp;gt;$은 실제</description>
    </item>
    
    <item>
      <title>레이블 트리와 케일리 정리</title>
      <link>https://freshrimpsushi.github.io/posts/labeled-tree-and-cayley-theorem/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/labeled-tree-and-cayley-theorem/</guid>
      <description>정의 각 버텍스에 서로 다른 수가 부여된 트리를 레이블 트리라 한다. 설명 레이블은 버텍스의 집합과 같이 실제로 원소가 같은지 다른지 구분하는 것과는 다른 개념이다. 가령 다음의 두 그래프는 쓰여있기는 달라도 본질적으로 같은 레이블 트리로 볼 수 있다. $$ 1-2-3 \\ a-b-c $$ 물론 그래프기 때문에 다음의 두 경우는 서로 같다. $$ 1-2-3 \\ 3-2-1 $$ 그러나 다음 두 그래프는 레이블이</description>
    </item>
    
    <item>
      <title>쌍선형 형식 이차 형식 에르메트 형식</title>
      <link>https://freshrimpsushi.github.io/posts/bilinear-quadratic-and-hermitian-forms/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bilinear-quadratic-and-hermitian-forms/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 쌍선형 형식$(\mathrm{bilinear\ form})$ 행렬 $\quad A=\begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp;\cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp;\cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{n1} &amp;amp; a_{n2} &amp;amp; \cdots &amp;amp; a_{nn} \end{pmatrix}\in \mathbb{R}^{n\times n}$와 $\mathbf{x}=\begin{pmatrix} x_{1} \\ x_{2} \\ \vdots \\ x_{n} \end{pmatrix},\mathbf{u}=\begin{pmatrix} u_{1} &amp;amp; u_{2} &amp;amp; \cdots &amp;amp; x_{n} \end{pmatrix}\in \mathbb{R}^{n}$에 대해서, 행렬 $A$에 대응하는 쌍선형 형식 을 다음과 같이 정의한다.</description>
    </item>
    
    <item>
      <title>에어리 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-airy-function/</link>
      <pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-airy-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 에어리 미분 방정식 $$ y&#39;&#39;-xy=0 $$ 의 해를 베셀 함수로 나타내면 아래와 같다. $$ \begin{align*} \mathrm{Ai}(x) &amp;amp;= \frac{1}{\pi}\sqrt{\frac{x}{3}}K_{1/3}\left( \frac{2}{3}x^{2/3} \right) \\ \mathrm{Bi}(x) &amp;amp;= \sqrt{\frac{x}{3}}\left[ I_{-1/3}\left( \frac{2}{3}x^{3/2} \right) + I_{1/3} \left( \frac{2}{3}x^{2/3} \right) \right] \end{align*} $$ 이때 $I_{\nu}$, $K_{\nu}$는 변형 베셀 함수이다. 에어리 함수를 표현하는 방법은 여러가지인데 아래와 같이 이상적분 꼴로 표현할 수 도 있다. $$ \begin{align*} \mathrm{Ai}(x) &amp;amp;= \frac{1}{\pi} \int_{0}^{\infty} \cos (t^{3}/3 + xt) dt \\ \mathrm{Bi}(x) &amp;amp;= \frac{1}{\pi}\int_{0}^{\infty} \left[</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 리우빌 함수</title>
      <link>https://freshrimpsushi.github.io/posts/liouvilles-function-in-analytic-number-theory/</link>
      <pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/liouvilles-function-in-analytic-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소수 $p_{1} , \cdots , p_{k}$ 에 대해 자연수 $n$ 을 $n = p_{1}^{a_{1}} \cdots p_{k}^{a_{k}}$ 과 같이 나타낸다고 하자. 다음과 같이 정의된 산술 함수 $\lambda$ 를 리우빌 함수라 한다. $$ \lambda (n) = (-1)^{a_{1} + \cdots a_{k}} $$ [1] 리우빌 급수: $n$ 이 제곱수일 때만 $1$ 이고 그 외엔 $0$ 이다. 다시 말해, $$ \sum_{d \mid n} \lambda (d) = \begin{cases} 1 &amp;amp;, n \text{ is a square} \\ 0 &amp;amp; , \text{otherwise}\end{cases} $$ [2] 완전 승법성**: 모든 $m,n \in</description>
    </item>
    
    <item>
      <title>트리 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/tree-graph/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tree-graph/</guid>
      <description>정의 1 사이클이 존재하지 않는 연결 그래프를 트리라 한다. 설명 트리는 컴퓨터 공학의 자료 구조 등에서 흔히 볼 수 있는 개념으로써, 컴퓨터를 조금이라도 다루는 이공계 전공이라면 아마 힙 소팅이라는 말을 들어봤을 것이다. 여기서 말하는 그 힙이 바로 트리의 일종이다.트리의 유니언은 직관적이게도 포레스트Forest라 부른다. 유향 그래프일 경우 입력</description>
    </item>
    
    <item>
      <title>에어리 미분 방정식의 급수해</title>
      <link>https://freshrimpsushi.github.io/posts/the-airys-differential-equation-and-power-series-solution/</link>
      <pubDate>Thu, 21 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-airys-differential-equation-and-power-series-solution/</guid>
      <description>정의 다음의 미분방정식을 에어리Airy 미분방정식이라 한다. $$ y&#39;&#39;-xy=0,\quad -\infty&amp;lt;x&amp;lt;\infty $$ 설명 이름의 유래는 영국의 천문학자 조지 비델 에어리George Biddell Airy이다. 스토크스 방정식Stokes equation이라고도 불린다. 풀이 $y&#39;&#39;$항의 계수가 $1$이므로 모든 점이 보통점이다. 그 중에서 $x=0$ 근방에서의 급수해를 구해보자. 에어리 방정식</description>
    </item>
    
    <item>
      <title>변형 베셀 방정식과 변형 베셀 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-modified-bessel-equation-and-the-modified-bessel-functions/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-modified-bessel-equation-and-the-modified-bessel-functions/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 아래의 미분 방정식을 변형 베셀 방정식 이라 한다. $$ x^2 y&#39;&#39; + xy&#39;-(x^2-\nu^2)y=0 $$ 베셀 방정식에서 $y$항의 부호가 $+ \rightarrow -$로 바뀐 형태이다. 이 미분 방정식의 해는 베셀 방정식이 해인 미분 방정식의 공식에 의해 $$ y=Z_{\nu}(ix)=AJ_{\nu}(ix)+BN_{\nu}(ix) $$ 이다. 일반적으로 사용하는 두 해의 꼴은 다음과 같으며 변형 베셀 함수 $(\mathrm{modified\ Bessel\ function})$</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 망골트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/mangoldt-function-in-analytic-number-theory/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mangoldt-function-in-analytic-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 다음과 같이 정의된 산술 함수 $\Lambda$ 를 망골트 함수라 한다. $$ \Lambda(n) := \begin{cases} \log p &amp;amp; n = p^{m} , p \text{ is prime}, m \in \mathbb{N} \\ 0 &amp;amp; \text{otherwise} \end{cases} $$ [1] 망골트 급수: 로그 함수 $\log$ 다. 다시 말해, $$ \sum_{d \mid n} \Lambda ( d ) = \log n $$ $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ \Lambda(n) &amp;amp; 0 &amp;amp; \log 2 &amp;amp; \log 3 &amp;amp; \log 2 &amp;amp; \log 5 &amp;amp; 0 &amp;amp; \log 7 &amp;amp; \log 2 &amp;amp; \log</description>
    </item>
    
    <item>
      <title>베셀 함수의 여러 성질</title>
      <link>https://freshrimpsushi.github.io/posts/some-properties-of-the-bessel-function/</link>
      <pubDate>Tue, 19 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/some-properties-of-the-bessel-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 베셀 방정식 아래의 미분 방정식을 $\nu$차 베셀 방정식이라 한다. $$ \begin{align*} x^2 y&#39;&#39; +xy&#39; +(x^2-\nu^2)y&amp;amp;=0 \\ x(xy&#39;)&#39;+(x^2- \nu ^2) y&amp;amp;=0 \\ y&#39;&#39;+\frac{1}{x} y&#39; + \left( 1-\frac{\nu^{2}}{x^{2}} \right)y&amp;amp;=0 \end{align*} $$ 제1 종 베셀 함수 베셀 방정식의 첫번째 해를 $J_{\nu}(x)$라 쓰고 제1 종 베셀 함수라 부른다. $$ J_{\nu}(x)=\sum \limits_{n=0}^{\infty} \frac{(-1)^{n} }{\Gamma(n+1) \Gamma(n+\nu+1)} \left(\frac{x}{2} \right)^{2n+\nu} $$ $$ J_{-\nu}(x)=\sum \limits_{n=0}^{\infty}\frac{(-1)^{n}}{\Gamma(n+1)\Gamma(n-\nu+1)} \left( \frac{x}{2} \right)^{2n-\nu} $$ 제 2종 베셀 함수 베셀 방정식의 두번째</description>
    </item>
    
    <item>
      <title>제3 종 베셀 함수 한켈 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-third-kind-hankel-function/</link>
      <pubDate>Tue, 19 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-third-kind-hankel-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 제1 종 베셀 함수와 제2 종 베셀함수의 아래와 같은 선형 결합을 제3 종 베셀함수 또는 한켈 함수라 부른다. $$ H_{p}^{(1)}(x)=J_{p}(x)+iN_{p}(x) \\ H_{p}^{(2)}(x)=J_{p}(x)-iN_{p}(x) $$ 미분 방정식 $y&#39;&#39;+y=0$의 해는 $\cos x$와 $\sin x$이다. 일반해는 이들의 선형 결합으로 나타낸다. 그 중 가장 흔하게 사용되는 꼴은 $\cos x + \pm i \sin x=e^{\pm ix}$이다. 이와 비슷하게</description>
    </item>
    
    <item>
      <title>그래프 이론에서의 디락 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-diracs-theorem/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-diracs-theorem/</guid>
      <description>정리 1 $G$ 가 $n ( \ge 3)$ 개의 버텍스를 가진 심플 그래프라고 하자. [1] 디락 정리: $G$ 의 모든 버텍스 $v$ 에 대해 $\deg (v) \ge n / 2$ 면 $G$ 는 해밀톤 그래프다. [2] 오레 정리: $G$ 의 모든 인접하지 않은 두 버텍스의 쌍 $(v ,w)$ 에 대해 $\deg (v) + \deg(w) \ge n$ 면 $G$ 는 해밀톤 그래프다. 설명 디락 정리 는 해밀톤 그래프의 동치조건까지는 아니지만 어떤 경우에 충분히 해밀톤 그래프인지를 판별해</description>
    </item>
    
    <item>
      <title>베셀 함수의 직교성</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-of-the-bessel-function/</link>
      <pubDate>Sun, 17 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-of-the-bessel-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\alpha, \beta$를 제1 종 베셀 함수 $J_{\nu}(x)$의 근이라고 하자. 그러면 구간 $[0,1]$에서 $\sqrt{x}J_{\nu}(x)$는 직교 집합을 이룬다. $$ \int_{0}^{1} x J_{\nu}(\alpha x) J_{\nu}(\beta x)dx=\begin{cases} 0 &amp;amp;\alpha\ne \beta \\ \frac{1}{2}J^{2}_{\nu+1}(\alpha)=\frac{1}{2}J_{\nu-1}^{2}(\alpha)=\frac{1}{2}J_{\nu}&#39;^{2}(\alpha) &amp;amp;\alpha=\beta\end{cases} $$ 위 내용을 다르게 표하면 다음과 같다. &amp;lsquo;베셀 함수 $J_{\nu</description>
    </item>
    
    <item>
      <title>뫼비우스 역 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-m%C3%B6bius-inversion-formula/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-m%C3%B6bius-inversion-formula/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $f$ 와 $g$ 가 산술 함수고 $\mu$ 는 뫼비우스 함수다. $$ f(n) = \sum_{d \mid n} g(d) \iff g(n) = \sum_{d \mid n} f(d) \mu \left( {{ n } \over { d }} \right) $$ 뫼비우스 함수는 그 정의만 보았을 땐 부자연스러운 함수로 보이지만, 사실 산술 함수 전체를 관통하는 핵심 공식에 등장하게 된다. 임의의 산술 함수 $g$ 의 급수는 유닛 함수 $u$ 와 컨볼루션 $\ast$ 을 써서 $g*u$ 와 같</description>
    </item>
    
    <item>
      <title>베셀 함수가 해인 미분 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/differential-equations-with-bessel-function-solutions/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/differential-equations-with-bessel-function-solutions/</guid>
      <description>정리1 정리1 베셀 방정식과 조금 다른 아래와 같은 미분 방정식이 주어졌다고 하자. $$ \begin{equation} \begin{aligned} &amp;amp;&amp;amp; y&#39;&#39;+\frac{1-2a}{x}y&#39;+\left[ (bcx^{c-1})^{2}+\frac{a^{2}-\nu^{2}c^{2}}{x^{2}} \right]y =&amp;amp; 0 \\ \text{or} &amp;amp;&amp;amp; x^{2}y&#39;&#39;+(1-2a)xy&#39;+\left[ b^{2}c^{2}x^{2c}+(a^{2}-\nu^{2}c^{2}) \right]y =&amp;amp; 0 \end{aligned} \label{1} \end{equation} $$ 그리고 $Z_{\nu}(x)$를 $J_{\nu}(x)$와 $N_{\nu}(x)$의 임의의 선형결합이라고 하자. 그러면 주어진 미분 방정식의 해는 아래와 같다. $$ y=x^{a}Z_{\nu}(bx^{c})=x^{a}[AJ_{\nu}(bx^{c})+BN_{\nu}(bx^{c})] $$ $\nu$, $a$, $b$, $c$, $A$, $B$는 상수이다. 정리</description>
    </item>
    
    <item>
      <title>베셀 함수의 재귀 관계</title>
      <link>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-the-bessel-function/</link>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-the-bessel-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 제1 종 베셀 함수 $J_{\nu}(x)$는 아래의 식을 만족한다. $$ \leqalignno{&amp;amp; \frac{ d }{ dx }[x^{\nu} J_{\nu}(x)] =x^{\nu}J_{\nu-1}(x) &amp;amp; (a) \\ &amp;amp; \frac{ d }{ dx }[x^{-\nu}J_{\nu}(x)]=-x^{-\nu}J_{\nu+1}(x) &amp;amp; (b) \\ &amp;amp; J_{\nu-1}(x)+J_{\nu+1}(x)=\frac{2\nu}{x}J_{\nu}(x) &amp;amp; (c) \\ &amp;amp; J_{\nu-1}(x)-J_{\nu+1}(x)=2J&#39;_{\nu}(x) &amp;amp; (d) \\ &amp;amp; J_{\nu}&#39;(x)=-\frac{\nu}{x}J_{\nu}(x)+J_{\nu-1}(x)=\frac{\nu}{x}J_{\nu}(x)-J_{\nu+1}(x) &amp;amp; (e) } $$ 상수 $\nu$에 대한 제1 종베셀 함수는 다음과 같다. $$ J_{\nu}(x)=\sum \limits_{n=0}^{\infty} \frac{(-1)^{n} }{\Gamma(n+1) \Gamma(n+\nu+1)} \left(\frac{x}{2} \right)^{2n+\nu}\tag{1} $$ 증명 $(a)$ $(1)$에 $x^{\nu}$를 곱한 뒤 미분하면 쉽</description>
    </item>
    
    <item>
      <title>베셀 방정식의 두번째 급수해: 제2 종 베셀 함수, 노이만 함수, 베버 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-second-kind-neumann-function-weber-function/</link>
      <pubDate>Thu, 14 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-second-kind-neumann-function-weber-function/</guid>
      <description>정의1 베셀 방정식의 두번째 해second solution를 노이만 함수라 부르고 $N_{\nu}(x)$ 혹은 $Y_{\nu}(x)$로 표기한다. 정수가 아닌 $\nu$에 대해서 $$ N_{\nu}(x)=Y_{\nu}(x)=\frac{\cos (\nu \pi)J_{\nu}(x)-J_{-\nu}(x)}{\sin (\nu\pi)} $$ $\nu$가 정수일 경우 극한으로 정의한다. $n\in \mathbb{Z}$, $\nu \in \mathbb{R}\setminus\mathbb{Z}$에 대해서 $$ N_{n}(x)=\lim \limits_{\nu \rightarrow n}N_{\nu}(x) $$ 이때 $J_{\pm \nu}(</description>
    </item>
    
    <item>
      <title>해밀톤 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/hamiltonian-graph/</link>
      <pubDate>Thu, 14 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hamiltonian-graph/</guid>
      <description>정의 1 $G$ 가 연결 그래프라고 하자. $G$ 의 모든 버텍스를 포함하는 닫힌 패스가 존재하면 $G$ 를 해밀톤 그래프라 하고 그 사이클을 해밀턴 사이클이라 한다. 모든 버텍스를 포함하지만 닫혀있지 않은 패스가 존재하면 $G$ 를 세미 해밀톤 그래프라 한다. 설명 오일러 그래프가 모든 에지를 지나는 트레일에 관심이 있듯 해밀톤 그래프는 모든 버텍스를 지나는 패스에 관심이 있</description>
    </item>
    
    <item>
      <title>구면 좌표계에서의 슈뢰딩거 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/the-schrodinger-equation-in-spherical-coordinates/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-schrodinger-equation-in-spherical-coordinates/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 3차원에서 시간에 무관한 슈뢰딩거 방정식은 다음과 같다. $$ -\frac{\hbar^{2}}{2M}\nabla^{2}\psi+V\psi=E\psi $$ 후에 나올 분리상수 $m$과 헷갈릴 염려가 있어 슈뢰딩거 방정식에서 입자의 질량을 나타내는 $m$은 대문자로 나타내겠다. 보통 포텐셜 함수는 원점과의 거리에만 의존하므로 $V=V(r)$이고 구면좌표계로 방정식을 푸는 것이 좋</description>
    </item>
    
    <item>
      <title>연관 르장드르 다항식의 여러 성질</title>
      <link>https://freshrimpsushi.github.io/posts/some-properties-of-the-associated-legendre-polynomial/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/some-properties-of-the-associated-legendre-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 연관 르장드르 미분 방정식과 연관 드장드르 다항식 아래의 미분 방정식을 르장드르 미분 방정식이라고 한다. 각각의 $l$, $m$에 따른 방정식의 해를 $P_{l}^{m}(x)$라고 표기하고연관 르장드르 다항식이라 부른다. $$ \begin{align*} &amp;amp;&amp;amp;(1-x^{2})\frac{ d^{2}y }{ dx^{2} }-2x \frac{dy}{dx}+\left[ +l(l+1)-\frac{m^{2}}{1-x^{2}} \right]y=0 \\ \mathrm{or} &amp;amp;&amp;amp; \frac{ d }{ dx } \left[ (1-x^{2})y&#39; \right] +\left[ l(l+1)-\frac{m^{2}}{1-x^{2}} \right]y=0 \end{align*} $$ $$ \begin{align*} P_{l}^{m}(x)&amp;amp;= (1-x ^{2})^{\frac{|m|}{2}}</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 유닛 함수</title>
      <link>https://freshrimpsushi.github.io/posts/unit-function-in-analytic-number-theory/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unit-function-in-analytic-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 다음과 같이 정의된 산술 함수 $u$ 를 유닛 함수라 한다. $$ u(n) := 1 $$ [1] 유닛 급수: 약수의 갯수 $\sigma_{0}$ 다. 다시 말해, $$ \sum_{d \mid n} u(d) = \sigma_{0} (n) $$ [2] 완전 승법성**: 모든 $m,n \in \mathbb{N}$ 에 대해 $u(mn) = u(m) u(n)$ $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ u (n) &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 \\ \sum_{d \mid n} u(d)</description>
    </item>
    
    <item>
      <title>구면조화함수의 규격화</title>
      <link>https://freshrimpsushi.github.io/posts/normalization-of-spherical-harmonics/</link>
      <pubDate>Mon, 11 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normalization-of-spherical-harmonics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 규격화된 구면조화함수는 아래와 같다. $$ Y_{l}^{m}(\theta,\phi)=\sqrt{\frac{2l+1}{4\pi}\frac{(l-m)!}{(l+m)!}}P_{l}^{m}(\cos\theta)e^{im\phi} $$ $$ \nabla ^2 f = \frac{1}{r^2}\frac{\partial}{\partial r} \left( r^2\frac{\partial f}{\partial r} \right) + \frac{1}{r^2\sin\theta}\frac{\partial}{\partial\theta}\left( \sin\theta \frac{\partial f}{\partial \theta} \right) + \frac{1}{r^2\sin^2\theta}\frac{\partial^2 f}{\partial^2 \phi}=0 $$ $$ f(r,\theta,\phi)=R(r)\Theta(\theta)\Phi(\phi) $$ 구면좌표계에 대한 라플라스 방정식에서 극각 $\theta$, 방위각 $\phi$에 대한 해를 구면조화함수라 한다. $$ \Theta(\theta)\Phi(\phi)=Y_{l}^{m}(\theta,\phi)=e^{im\phi}P_{l}^{m}(\cos \theta) $$ 양자역학에서 구면조화함수를 파동함수로서 다루려면 규격화를 해야한다.</description>
    </item>
    
    <item>
      <title>연관 르장드르 다항식의 직교성</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-of-associated-legendre-polynomials/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-of-associated-legendre-polynomials/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 구간 $[-1,1]$에서 고정된 $m$에 대한 연관 르장드르 다항식은 직교 집합을 이룬다. $$ \int_{-1}^{1} P_{l}^{m}(x)P_{k}^{m}(x)dx =\frac{ 2}{ 2l+1 }\frac{(l+m)!}{(l-m)!}\delta_{lk} $$ $x=\cos \theta$일 경우에는 $$ \int_{0}^{\pi} P_{l}^{m}(\cos \theta)P_ {k}^{m}(\cos\theta)\sin \theta d\theta =\frac{ 2}{ 2l+1 }\frac{(l+m)!}{(l-m)!}\delta_{lk} $$ 연관 르장드르 다항식 $$ P_{l}^{m}(x) = (1-x ^{2})^{\frac{m}{2}} \dfrac{1}{2^l l!} \dfrac{d^{l+m}}{dx^{l+m}}(x^2-1)^l $$ 로드리게스 공식 $$ P_l(x)=\dfrac{1}{2^l l!} \dfrac{d^l}{dx^l}(x^2-1)^l $$ 증명 우선 편의를 위해 $P_{l}^{m}(x)=P</description>
    </item>
    
    <item>
      <title>플뢰리 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fleurys-algorithm/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fleurys-algorithm/</guid>
      <description>정의 1 $G$ 가 오일러 그래프라고 하자. 그러면 다음과 같은 방법으로 오일러 트레일을 만들 수 있다. 임의의 버텍스 $u$ 에서 시작해서 다음의 두 규칙을 따라 트레일을 만든다: (i): 이미 지나온 에지는 지운다. 만약 에지가 지워지면서 고립 버텍스가 되면 그 버텍스도 지운다. (ii): 각 단계에서 브릿지는 다른 대안이 없을때만 지나간다. 에지 $b \in G$ 가 지워짐으로써 그래프</description>
    </item>
    
    <item>
      <title>엠이 음수인 경우의 연관 르장드르 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/the-associated-legendre-polynomial-for-negative-m/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-associated-legendre-polynomial-for-negative-m/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 연관 르장드르 다항식은 $m$의 부호에 따라 아래의 비례식이 성립한다. $$ P_{l}^{-m}(x)=(-1)^{m}\frac{(l-m)!}{(l+m)!}P_{l}^{m}(x) $$ $$ (1-x^{2})\frac{ d^{2}y }{ dx^{2} }-2x \frac{dy}{dx}+\left( \frac{-m^{2}}{1-x^{2}}+l(l+1) \right)y=0 $$ 연관 르장드르 미분 방정식을 보면 $m$에 대한 부분이 $m^2$으로 나타나있으므로 $m$이 음수인지 양수인지에 대해서는 해에 영향을 주지 않는다. 그래서 연관 르장드르 다항식도 아래와 같이</description>
    </item>
    
    <item>
      <title>르장드르 다항식의 여러 성질</title>
      <link>https://freshrimpsushi.github.io/posts/some-properties-of-legendre-polynomial/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/some-properties-of-legendre-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 르장드르 미분 방정식과 르장드르 다항식아래의 미분 방정식을 르장드르 미분 방정식이라 하고 이 방정식의 해를 르장드르 다항식이라 한다. $$ (1-x^2)\dfrac{d^2 y}{dx^2} -2x\dfrac{dy}{dx}+l(l+1) y=0 $$ 각 $l$에 따른 르장드르 다항식은 다음과 같다. $$ \begin{align*} P_0(x) &amp;amp;=1 \\ P_1(x) &amp;amp;=x \\ P_2(x) &amp;amp;=\dfrac{1}{2}(3x^2-1) \\ P_3(x)&amp;amp;=\dfrac{1}{2}(5x^3-3x) \\ P_4(x)&amp;amp;=\dfrac{1}{8}(35x^4-30x^2+3) \\ \vdots \end{align*} $$ 로드리게스 공식각 $l$에 대한 르장드르 다항식을 얻는</description>
    </item>
    
    <item>
      <title>르장드르 다항식의 생성 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-generating-function-of-lengendre-polynomial/</link>
      <pubDate>Thu, 07 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-generating-function-of-lengendre-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 르장드르 다항식의 생성 함수는 아래와 같다. $$ \Phi (x,t)= \sum \limits_{l=0}^{\infty}P_{l}(x)t^{l}=\frac{1}{\sqrt{1-2xt+t^{2}}},\quad |t|&amp;lt;1 $$ 르장드르 다항식의 생성 함수란 쉽게 말해서 르장드르 다항식 $P_{l}(x)$를 계수로 갖는 다항식이다. **보조정리 생성함수 $\Phi (x,t)$는 아래의 미분 방정식을 만족한다. $$ (1-x^{2})\frac{ \partial ^{2} \Phi}{ \partial x^{2} }-2x\frac{ \partial \Phi}{ \partial x }+t\frac{ \partial ^{2}}{ \partial t^{2} }(t\Phi)=0\tag{1} $$ **생</description>
    </item>
    
    <item>
      <title>르장드르 다항식의 재귀 관계</title>
      <link>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-legendre-polynomial/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-recurrence-relation-of-legendre-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 르장드르 다항식의 재귀 관계식 $$ P&#39;_{l+1}(x)-P&#39;_{l-1}(x)=(2l+1)P_{l}(x)\tag{a} $$ $$ lP_l(x)=(2l-1)xP_{l-1}(x)-(l-1)P_{l-2}(x) \tag{b} $$ $$ xP&#39;_{l}(x)-P&#39;_{l-1}(x)=lP_{l}(x)\tag{c} $$ 로드리게스 공식 $$ P_l(x)=\dfrac{1}{2^l l!} \dfrac{d^l}{dx^l}(x^2-1)^l $$ 르장드르 다항식의 생성함수아래의 함수 $\Phi (x,h)$를 르장드르 다항식의 생성함수라 한다. $$ \Phi (x,h)=\frac{1}{\sqrt{1-2xh+h^{2}}},\quad |h|&amp;lt;1 $$ 생성함수는 아래의 식을 만족한다. $$ \Phi(x,h)=P_{0}(x)+hP_{1}(x)+h^{2}P_{2}(x)+\cdots =\sum \limits_{l=0}^{\infty}h^{l}P_{l}(x) $$ 증명 $(a)$ 우선 $P_{l}(x)$를 계산해보자. 로드리게</description>
    </item>
    
    <item>
      <title>쾨니히스베르크의 다리 문제와 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/koenigsberg-bridge-problem-and-solution/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/koenigsberg-bridge-problem-and-solution/</guid>
      <description>문제 1 쾨니히스베르크의 다리 문제는 다음과 같이 도시에 놓인 7개의 다리를 한 번씩만 건너면서 처음 있는 위치로 돌아올 수 있는지에 관한 것이었다. 해법을 모른다면 언뜻 경우의 수를 다 따져봐야하는 막막한 문제로 보인다. 일단 수학 문제처럼 보이지도 않고, 모든 경우를 다 따져보면 풀릴 것 같은데 막상 따져보기가 쉽지는 않다. 위대한 수학자 오일러는 이것을</description>
    </item>
    
    <item>
      <title>베타 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-beta-distribution/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-beta-distribution/</guid>
      <description>공식 $X \sim \text{Beta}(\alpha,\beta)$ 면 $$ E(X)={\alpha \over {\alpha + \beta} } \\ \text{Var} (X)={ { \alpha \beta } \over {(\alpha + \beta + 1) { ( \alpha + \beta ) }^2 } } $$ 유도 전략: 베타 분포의 정의와 감마 함수의 기본적인 성질로 직접 연역한다. 베타 분포의 정의: $\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\text{Beta}(\alpha,\beta)$ 를 베타 분포라고 한다. $$ f(x) = { \Gamma(\alpha + \beta) \over { \Gamma(\alpha) \Gamma(\beta) } } x^{\alpha - 1} (1-x)^{\beta - 1} \qquad , x \in [0,1] $$ 감마 함수의 재귀 공식</description>
    </item>
    
    <item>
      <title>오일러 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/eulerian-graph/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eulerian-graph/</guid>
      <description>정의 $G$ 가 연결 그래프라고 하자. $G$ 의 모든 에지를 포함하는 닫힌 트레일이 존재하면 $G$ 를 오일러 그래프라 하고 그 트레일을 오일러 트레일이라 한다. 모든 에지를 포함하지만 닫혀있지 않은 트레일이 존재하면 $G$ 를 세미 오일러 그래프라 한다. 설명 우리에게는 한 붓 그리기 문제로도 익숙한 개념이다. 오일러 그래프에 대한 논의는 그 유명한 쾨니히스베르크의 다리</description>
    </item>
    
    <item>
      <title>베타 분포</title>
      <link>https://freshrimpsushi.github.io/posts/beta-distribution/</link>
      <pubDate>Sat, 02 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/beta-distribution/</guid>
      <description>정의 1 $\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\text{Beta}(\alpha,\beta)$ 를 베타 분포beta Distribution라고 한다. $$ f(x) = {{ 1 } \over { B(\alpha,\beta) }} x^{\alpha - 1} (1-x)^{\beta - 1} \qquad , x \in [0,1] $$ $B$ 는 베타 함수를 나타낸다. 기초 성질 [1] 적률 생성 함수: $$ m(t) = 1 + \sum_{k=1}^{\infty} \left( \prod_{r=0}^{k-1} {{ \alpha + r } \over { \alpha + \beta + r }} {{ t^{k} } \over { k! }} \right) \qquad , t \in \mathbb{R} $$ [2] 평균과 분산: $X \sim \text{Beta}(\alpha,\beta)$</description>
    </item>
    
    <item>
      <title>연관 르장드르 미분 방정식과 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/associated-lengendre-differential-equationpolynomial/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/associated-lengendre-differential-equationpolynomial/</guid>
      <description>정의1 아래의 미분 방정식을 연관 르장드르 미분 방정식이라 한다. $$ \begin{equation} \begin{aligned} &amp;amp;&amp;amp;(1-x^{2})\frac{ d^{2}y }{ dx^{2} }-2x \frac{dy}{dx}+\left[ +l(l+1)-\frac{m^{2}}{1-x^{2}} \right]y =&amp;amp; 0 \\ \mathrm{or} &amp;amp;&amp;amp; \frac{ d }{ dx } \left[ (1-x^{2})y&#39; \right] +\left[ l(l+1)-\frac{m^{2}}{1-x^{2}} \right]y =&amp;amp; 0 \end{aligned} \label{1} \end{equation} $$ 연관 르장드르 미분 방정식의 해를 $P_{l}^{m}(x)$와 같이 표기하고 이를 연관 르장드르 다항식associated Legendre polynomial 혹은 일반화된 르장드르 다항식generalized Legendre polyno</description>
    </item>
    
    <item>
      <title>쾨닉의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-koenigs-theorem/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-koenigs-theorem/</guid>
      <description>정리 1 $G$ 가 국소적으로 유한인 연결 그래프라고 하자. 그러면 모든 $v \in V(G)$ 에 대해 $v$ 가 시점인 원웨이 무한 패스가 존재한다. 증명 $G$ 는 연결 그래프이므로 $v$ 가 아닌 모든 $z \in V(G)$ 에 대해 $v$ 에서 $z$ 로 가는 패스가 무한히 많이 존재한다. 그리고 $G$ 는 국소적으로 유한하므로 무한히 많은 패스들 중 무한히 많은 일부는 하나의 같은 에지로 시작해야만한다. 그 에지를 $vv_{1}$ 이</description>
    </item>
    
    <item>
      <title>슈뢰딩거 방정식의 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-schrodinger-equation/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-schrodinger-equation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 시간에 무관한 슈뢰딩거 방정식 $$ H\psi=\left(-\frac{\hbar^{2}}{2m}\frac{ d ^{2} }{ d x^{2} }+V\right)\psi=E\psi \\ H\psi=\left(-\frac{\hbar^{2}}{2m}\nabla^{2}+V\right)\psi=E\psi $$ 시간에 의존하는 슈뢰딩거 방정식 $$ i\hbar\frac{ \partial \psi}{ \partial t}=\left(-\frac{\hbar^{2}}{2m}\frac{ \partial ^{2} }{\partial x^{2} }+V\right)\psi \\ i\hbar\frac{ \partial \psi}{ \partial t}=\left(-\frac{\hbar^{2}}{2m}\nabla^{2}+V\right)\psi $$ 슈뢰딩거 방정식이란 복소 파동함수의 에너지, 위치, 시간에 관련된 편미분 방정식을 말한다. 쉽게 말하자면 고전 역학에서 $$ F=ma $$ 와 같은 것이다. 이를 이용해서 여러 포</description>
    </item>
    
    <item>
      <title>오일러 미분 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-euler-differential-equation/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-euler-differential-equation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 다음과 같은 꼴의 미분 방정식을 오일러 미분 방정식 혹은 오일러-코시 방정식이라 한다. $$ a_{2}x^{2}\frac{ d ^{2 }y}{ dx^{2} }+a_{1}x\frac{ d y}{ d x }+a_{0}y=0 $$ 우변이 $0$이 아닌 동차 방정일 경우 에는 $x=e^{z}$로 치환해서 풀면 된다. 계산의 편의를 위해 $(1)$의 양 변을 $a_{2}$로 나누고 나머지 두 항의 계수를 다시 $a_{1}$,</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 오일러 토션트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/totient-fuction-in-analytic-number-theory/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/totient-fuction-in-analytic-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 초등적 정수론에서의 토션트 함수 다음과 같이 정의된 산술 함수 $\varphi$ 을 토션트 함수라 한다. $$ \varphi (n) := \sum_{\gcd ( k , n ) = 1} 1 $$ [1] 토션트 급수: 놈 $N$ 이다. 다시 말해, $$ \sum_{d \mid n } \varphi (d) = N(n) $$ [2] 승법성**: $\gcd (m,n) = 1$ 을 만족하는 모든 $m, n \in \mathbb{N}$ 에 대해 $\varphi (mn) = \varphi (m) \varphi (n)$ $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7</description>
    </item>
    
    <item>
      <title>구면 좌표계 라플라스 방정식의 일반해</title>
      <link>https://freshrimpsushi.github.io/posts/general-solution-of-laplaces-equation-in-spherical-coordinates/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-solution-of-laplaces-equation-in-spherical-coordinates/</guid>
      <description>정리 구면좌표계에서 라플라스 방정식은 아래와 같다. $$ \nabla ^2 f = \frac{1}{r^2}\frac{\partial}{\partial r} \left( r^2\frac{\partial f}{\partial r} \right) + \frac{1}{r^2\sin\theta}\frac{\partial}{\partial\theta}\left( \sin\theta \frac{\partial f}{\partial \theta} \right) + \frac{1}{r^2\sin^2\theta}\frac{\partial^2 f}{\partial^2 \phi}=0 $$ 설명 $f$가 $f(r,\theta,\phi)=R(r)\Theta(\theta)\Phi(\phi)$로 변수분리가능하다고 가정하자. 지름 성분에 대한 일반해는 오일러 미분 방정식을 풀어서 아래와 같이 구할 수 있다. $$</description>
    </item>
    
    <item>
      <title>그래프의 오리엔테이션</title>
      <link>https://freshrimpsushi.github.io/posts/orientation-of-graph/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orientation-of-graph/</guid>
      <description>빌드업 유향 그래프 $D$ 가 주어져 있다고 하자. 아크의 유한 시퀀스를 유향 워크Directed Walk라 하고 다음과 같이 나타낸다. $$ v_{0} v_{1} , v_{1} v_{2} , \cdots , v_{m-1} v_{m} \\ v_{0} \rightarrow v_{1} \rightarrow v_{2} \rightarrow \cdots \rightarrow v_{m-1} \rightarrow v_{m} $$ 이 때 $v_{0}$ 을 시점Initial Vertex , $v_{m}$ 을 종점Final Vertex이라 하고 $m$ 을 길이Length라 부른다. 유향 워크의 아크가 모두 다르면 유향 트레일Di</description>
    </item>
    
    <item>
      <title>구면좌표계 라플라스 방정식에서 지름 성분 방정식의 일반해</title>
      <link>https://freshrimpsushi.github.io/posts/general-solution-of-radial-equation-for-spherical-coordinates-laplaces-equation/</link>
      <pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-solution-of-radial-equation-for-spherical-coordinates-laplaces-equation/</guid>
      <description>정리 구면좌표계 라플라스 방정식에서 지름성분 방정식의 일반해는 아래와 같다. $$ R(r)=\sum \limits_{l=0}^{\infty}R_{l}(r)=\sum \limits_{l=0}^{\infty}\left( A_{l}r^{l}+\frac{ B_{l}}{r^{l+1}} \right) $$ 이때 $l$은 음이 아닌 정수, $A_{l}$, $B_{l}$은 상수이다. 설명 극각, 방위각에 대한 해보다는 구하는 과정이 비교적 간단하다. 증명 구면좌표계 라플라스 방정식에서 극각 $\theta$와 방위각 $\phi$ 성분에 대한 해를 구면조화함수라고 한다. 구면 조</description>
    </item>
    
    <item>
      <title>구면 조화함수: 구면좌표 라플라스 방정식의 극각, 방위각에 대한 일반해</title>
      <link>https://freshrimpsushi.github.io/posts/spherical-harmonics/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spherical-harmonics/</guid>
      <description>정의 구면좌표계에서 라플라스 방정식의 극각, 방위각에 대한 일반해는 다음과 같으며, 이를 구면 조화함수Spherical harmonics라고 한다. $$ Y_{l}^{m}(\theta,\phi)=e^{im\phi}P_{l}^{m}(\cos \theta) $$ 이때 $l$은 $l=0,1,2\cdots$이고 $m$은 $ -l \le m \le l$를 만족하는 정수이다. 또한 $P_{l}^{m}(\cos\theta)$는 다음과 같다. $$ \begin{align*}</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 뫼비우스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/m%C3%B6bius-function-in-analytic-number-theory/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/m%C3%B6bius-function-in-analytic-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소수 $p_{1} , \cdots , p_{k}$ 에 대해 자연수 $n$ 을 $n = p_{1}^{a_{1}} \cdots p_{k}^{a_{k}}$ 과 같이 나타낸다고 하자. 다음과 같이 정의된 산술 함수 $\mu$ 을 뫼비우스 함수라 한다. $$ \mu(n) := \begin{cases} 1 &amp;amp;, n=1 \\ (-1)^{k} &amp;amp;, a_{1} = \cdots = a_{k} = 1 \\ 0 &amp;amp; , \text{otherwise} \end{cases} $$ [1] 뫼비우스 급수: 아이덴터티 $I$ 다. 다시 말해, $$ \sum_{d \mid n } \mu (d) = I(n) $$ [2] 승법성** : $\gcd (m,n) = 1$ 을 만족하는 모</description>
    </item>
    
    <item>
      <title>CT 촬영의 원리</title>
      <link>https://freshrimpsushi.github.io/posts/principle-of-ct-radon-transform/</link>
      <pubDate>Thu, 23 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/principle-of-ct-radon-transform/</guid>
      <description>Computer Tomography CT는 Computer Tomography의 약자로 컴퓨터 단층촬영이라는 뜻이다. 몸의 단면 사진을 얻는 기술인데 컴퓨터 계산이 필요하기 때문에 이러한 이름이 붙었다. CT는 각각의 물질마다 X-선1을 흡수하는 정도가 다르다는 점을 이용한다. 아래의 그림을 보자. 그림 가운데 원을 신체 어딘가의 단면이라고 하자. 잘라서 보지 않는 한 내부는 어떻게 생긴지</description>
    </item>
    
    <item>
      <title>그래프에서의 거리, 네이버후드, 지름, 둘레</title>
      <link>https://freshrimpsushi.github.io/posts/distance-neighborhood-diameter-girth-in-graph/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distance-neighborhood-diameter-girth-in-graph/</guid>
      <description>정의 그래프 $G$ 에서 시점이 $v \in V(G)$ 고 종점이 $w \in V(G)$ 인 패스의 집합을 $P(v,w)$ 이라 하고 $v \in V(G)$ 를 포함하는 사이클의 집합을 $C(v)$ 라 하자. 그리고 워크 $x$ 의 길이를 $l(x)$ 과 같이 나타내자. 두 버텍스 $v,w \in V(G)$ 사이의 거리 $d$ 는 $v$ 가 시점이고 $w$ 가 종점인 패스의 길이 중 가장 작은 값으로 정의된다. 다시 말해, $$ d(v,w) := \min_{v,w \in V(G)} \left\{ l(x) : x \in P(v,w) \right\} $$ 버텍스 $v \in V(G)$ 에 대해 $v$ 와의 거리가 정</description>
    </item>
    
    <item>
      <title>움직이는 점전하가 만드는 자기장</title>
      <link>https://freshrimpsushi.github.io/posts/the-magnetic-field-of-a-moving-point-charge/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-magnetic-field-of-a-moving-point-charge/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 움직이는 점전하가 만드는 자기장은 다음과 같다. $$ \mathbf{B}=-\frac{1}{c}\frac{1}{4\pi \epsilon_0} \frac{q}{ (\mathbf{u}\cdot \boldsymbol{\eta})^{3}} \boldsymbol{\eta} \times \left[ (c^{2}-v^{2})\mathbf{v}+(\boldsymbol{\eta} \cdot \mathbf{a})\mathbf{v}+(\boldsymbol{\eta} \cdot \mathbf{u})\mathbf{a} \right] $$ 또한 움직이는 점전하가 만드는 전기장과 아래의 관계식이 성립한다. $$ \mathbf{B}(\mathbf{r},t)=\mathbf{E}(\mathbf{r},t) $$ 움직이는 점전하가 만드는 전위는 리에나르-비케르트 전위이다. $$ V(\mathbf{r}, t)= \frac{1}{4\pi \epsilon_0} \frac{qc}{ (\eta c -\boldsymbol{\eta}\cdot \mathbf{v})} ,\quad \mathbf{A}(\mathbf{r}, t) = \frac{ \mathbf{v} } {c^2} V(\mathbf{r}, t) $$ 자기장은$$ \quad \mathbf{B}=\nabla \times</description>
    </item>
    
    <item>
      <title>물리학에서 델 연산자란</title>
      <link>https://freshrimpsushi.github.io/posts/del-operator-in-physics/</link>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/del-operator-in-physics/</guid>
      <description>설명 델 연산자란 간단히 말해서 3차원 공간 좌표에 대한 미분 연산자이다. 연산자라는 말이 생소하다면 그냥 대상을 계산하는 규칙이라고 이해하면 된다. 예를 들어 $\dfrac{d}{dx}$는 함수를 $x$에 대해서 미분하라는 미분 연산자이다. 델 연산자는 보통 아래와 같이 소개된다. $$ \nabla = \frac{ \partial }{ \partial x }\hat{\mathbf{x}}+\frac{ \partial }{ \partial y }\hat{\mathbf{y}}+\frac{ \partial }{ \partial z }\hat{\mathbf{z}} $$ 마치 벡터인 것</description>
    </item>
    
    <item>
      <title>양자역학에서 교환자란</title>
      <link>https://freshrimpsushi.github.io/posts/commutator-in-quantum-mechanics/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/commutator-in-quantum-mechanics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 양자역학에서 두 연산자 $A$, $B$에 대한 교환자는 아래와 같다. $$ [A,B]=AB-BA $$ 이건 $0$이 아니냐는 의문이 들 수도 있다. 연산자는 행렬로 표현되고, 두 행렬의 곱은 교환법칙이 성립하지 않으므로 곱하는 순서에 따라 다른 결과를 가질 수도 있다. 수학과 전공과목으로 선형대수학을 배우면 알겠지만 행렬, 벡터</description>
    </item>
    
    <item>
      <title>해석적 정수론에서의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-in-analytic-number-theory/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-in-analytic-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 다음과 같이 정의된 산술 함수 $N$ 을 놈이라 한다. $$ N(n) := n $$ [1] 놈 급수: 시그마 함수 $\sigma = \sigma_{1}$ 다. 다시 말해, $$ \sum_{d \mid n } N(d) = \sigma_{1}(n) $$ [2] 완전 승법성**: 모든 $m,n \in \mathbb{N}$ 에 대해 $N(mn) = N(m) N (n)$ $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ N(n) &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ \sum_{d \mid n} N(d) &amp;amp;</description>
    </item>
    
    <item>
      <title>드브로이 관계식과 물질파</title>
      <link>https://freshrimpsushi.github.io/posts/de-broglie-relation-matter-wave/</link>
      <pubDate>Sun, 19 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/de-broglie-relation-matter-wave/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 빛이 파동인지 입자인지에 대한 문제는 물리학 역사에서 큰 관심사였다. 20세기 초 여러 실험들을 통해 빛은 입자의 성질과 파동의 성질을 동시에 지닌다는 것을 알게 됐다. $$ \begin{align} E=\sqrt{p^2c^2+m_{0}^{2}c^{4}} \\ E=h\nu= \frac{hc}{\lambda} \end{align} $$ 입자의 상대론적 에너지를 표현하는 식인 $(1)$과 광전 효과로부터 얻은 식 $(2)$에 의해 질량이 $0$인</description>
    </item>
    
    <item>
      <title>그래프 이론에서의 워크, 트레일, 패스, 사이클</title>
      <link>https://freshrimpsushi.github.io/posts/walk-trail-path-cycle/</link>
      <pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/walk-trail-path-cycle/</guid>
      <description>정의 1 그래프 $G$ 가 주어져 있다고 하자. 에지의 유한 시퀀스를 워크라 하고 다음과 같이 나타낸다. $$ v_{0} v_{1} , v_{1} v_{2} , \cdots , v_{m-1} v_{m} \\ v_{0} \rightarrow v_{1} \rightarrow v_{2} \rightarrow \cdots \rightarrow v_{m-1} \rightarrow v_{m} $$ 이 때 $v_{0}$ 을 시점Initial Vertex , $v_{m}$ 을 종점Final Vertex이라 하고 $m$ 을 길이Length라 부른다. 워크의 에지가 모두 다르면 트레일이라 한다. 워크의 버텍스가 모두 다르면 패스라 한다</description>
    </item>
    
    <item>
      <title>양자역학에서 기댓값이란</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-value-in-quantum-mechanics/</link>
      <pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-value-in-quantum-mechanics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 결론부터 말하자면 고등학교 수학 통계 부분에서 배운 그 기댓값이 맞다. 양자역학을 공부하면서 기댓값을 이해하기 어렵다면 그 어려움에 대한 종류는 크게 두가지가 있다. 첫째는 정의 그 자체를 이해하는 것에 대한 어려움이고 둘째는 수식이 왜 그렇게 표현되는지에 대한 의문이다. 기댓값이란? 여러분도 알</description>
    </item>
    
    <item>
      <title>움직이는 점전하가 만드는 전기장</title>
      <link>https://freshrimpsushi.github.io/posts/the-field-of-a-moving-point-charge/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-field-of-a-moving-point-charge/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 움직이는 점전하가 만드는 전자기장 $$ \mathbf{E}(\mathbf{r}, t) = \frac{q}{4\pi\epsilon_0} \frac{\eta} {( \boldsymbol{\eta}\cdot \mathbf{u} )^3 } \left[(c^2-v^2)\mathbf{u} +\boldsymbol{\eta}\times (\mathbf{u} \times \mathbf{a} ) \right] $$ $$ \mathbf{B} (\mathbf{ r}, t) =\frac{1}{c} \hat{\boldsymbol{\eta}}\times \mathbf{ E } (\mathbf{ r}, t) $$ 움직이는 점전하가 만드는 전기장, 자기장은 리에나르-비케르트 전위를 사용하여 구할 수 있다. $$ V(\mathbf{r}, t)= \frac{1}{4\pi \epsilon_0} \frac{qc}{ (\eta c -\boldsymbol{\eta}\cdot \mathbf{v})} ,\quad \mathbf{A}(\mathbf{r}, t) = \frac{ \mathbf{v} } {c^2} V(\mathbf{r}, t) $$ 또한 전자기장은 아래의 식으로 구할 수 있</description>
    </item>
    
    <item>
      <title>패러티 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/parity-operator/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/parity-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 패러티 연산자 $P$는 양자역학에서 축퇴된 두 고유함수를 구별하는데 쓰이는 연산자로 정의는 아래와 같다. $$ P\psi (x) = \psi(-x) $$ 축퇴 문서에서 두 파동함수 $$ \psi_{1}(x)=e^{ikx},\quad \psi_{2}(x)=e^{-ikx} $$ 를 예로 들었다. 이 때 $$ u_{+}(x)=\psi_{1}(x) +\psi_{2}(x) \\ u_{-}(x)=\psi_{1}(x)-\psi_{2}(x) $$ 라고 하자. 그러면 패러티 연산자의 적용 결과가 달라 나와 두 함수를 구별할 수 있게 된다. $$ Pu_{+}=e^{-ikx}+e^{ikx}=u_{+} \\ Pu_{-}=e^{-ikx}-e^{ikx}=-u_{-} $$ **패</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 디바이저 함수</title>
      <link>https://freshrimpsushi.github.io/posts/divisor-function-in-analytic-number-theory/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divisor-function-in-analytic-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\alpha \in \mathbb{C}$ 에 대해 다음과 같이 정의된 $\sigma_{\alpha} : \mathbb{N} \to \mathbb{C}$ 을 디바이저 함수라 부른다. $$ \sigma_{\alpha} (n) := \sum_{d \mid n} d^{\alpha} $$ [1] 승법성 : $\gcd (m,n) = 1$ 을 만족하는 모든 $m, n \in \mathbb{N}$ 에 대해 $\sigma_{\alpha} (mn) = \sigma_{\alpha} (m) \sigma_{\alpha} (n)$ [2]: 소수 $p$ 와 자연수 $a$ 에 대해 $$ \sigma_{\alpha} \left( p^{a} \right) = \begin{cases} a +1 &amp;amp; , \alpha = 0 \\ {{ p^{\alpha (a+1)} - 1 } \over { p^{\alpha} - 1 }} &amp;amp;,\alpha \ne 0 \end{cases} $$ 특히 $\alpha = 0$ 이면 약수의 수를 나</description>
    </item>
    
    <item>
      <title>무한 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/infinite-graph/</link>
      <pubDate>Tue, 14 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/infinite-graph/</guid>
      <description>정의 1 그래프 $G$ 의 버텍스 집합 $V(G)$ 나 에지 집합 $E(G)$ 가 무한 집합이면 $G$ 를 무한 그래프라고 한다. $V(G)$ 와 $E(G)$ 가 모두 가산 집합인 무한 그래프 $G$ 를 가산 그래프Countable Graph라 한다. 무한 그래프 $G$ 의 버텍스 $v \in V(G)$ 에 대해 $A(v)$ 를 다음과 같이 정의하자. $$ A(v) := \left\{ w : vw \in E(G) \right\} $$ 무한 그래프 $G$ 의 버텍스의 차수는 다음과 같이 $A(v)$ 의 기수로 정의한다. $$ \deg</description>
    </item>
    
    <item>
      <title>승법적 함수의 아벨리안 그룹</title>
      <link>https://freshrimpsushi.github.io/posts/abelian-group-of-multiplicative-functions/</link>
      <pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abelian-group-of-multiplicative-functions/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 승법적 함수 들의 집합 $M$ 과 이항 연산 $\ast$ 에 대해 $(M,*)$ 는 아벨리안 그룹이다. 산술 함수의 집합 $A$ 가 컨볼루션 $\ast$과 더불어 아벨리안 그룹 $(A,*)$ 가 되듯, 승법적 함수 역시 아벨리안 그룹이 된다. 물론 $M \le A$, 즉 $M$ 이 $A$ 의 서브 그룹이 된다. 증명 Part (ii)., (v). 결합 법칙 컨볼루션의 성질결합 법칙: $(fg) k = f(gk</description>
    </item>
    
    <item>
      <title>이분 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/bipartite-graph/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bipartite-graph/</guid>
      <description>정의 1 그래프 $G$ 의 버텍스 $V(G)$ 에 대해 파티션 $\left\{ A,B \right\}$ 가 존재하고 모든 $xy \in E(G)$ 에 대해 $x \in A, y \in B$ 혹은 $x \in B , y \in A$ 이면 $G$ 를 이분 그래프라 부르고 $G = G(A,B)$ 와 같이 나타내기도 한다. 설명 이분 그래프는 그 이름 그대로 버텍스가 두 부류로 나뉘며, 같은 부류끼리는 인접하지 않은 그래프다. 가령 다음의 그림을 보면 주황색 버텍스 끼리는 인접하지 않고, 파란색 버</description>
    </item>
    
    <item>
      <title>디리클레 곱과 승법적 성질</title>
      <link>https://freshrimpsushi.github.io/posts/drichlet-convolution-and-multiplicativity/</link>
      <pubDate>Wed, 08 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/drichlet-convolution-and-multiplicativity/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 [1]: $f$ 와 $g$ 가 승법적 함수면 $f \ast\ g$ 도 승법적 함수다. [2]: $g$ 와 $f*g$ 가 승법적 함수면 $f$ 도 승법적 함수다. 이 성질들은 승법적 함수들의 대수적인 성질을 논할 때 바로 쓰일 수 있다:**정리 [1]**은 다시 말해 승법적 함수가 컨볼루션 $\ast$에 대해 닫혀있음을 의미한다.정리 [2] 는 $g$ 와 $I = g*g^{-1}$ 와 같이</description>
    </item>
    
    <item>
      <title>감마 분포와 카이제곱 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-chi-squared/</link>
      <pubDate>Tue, 07 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-chi-squared/</guid>
      <description>정리 $$ \displaystyle \Gamma \left( { r \over 2 } , 2 \right) \iff \chi ^2 (r) $$ 설명 감마 분포와 카이제곱 분포는 위와 같은 성질을 가진다. 증명 전략: 두 분포의 적률생성함수가 같은 형태로 나타날 수 있음을 보인다. 카이제곱분포 $\chi ^2 (r)$ 의 적률생성함수는 $\displaystyle m_{1}(t) = (1- 2t)^{- {r \over 2} }$ 이고 감마분포 $\Gamma(k, \theta)$ 의 적률생성함수는 $m_{2}(t) = (1-\theta t)^{-k}$ 이다. 감마분포의 적률생성함수에 $\displaystyle k = {r \over 2}$ 과 $\theta = 2$ 을 대입</description>
    </item>
    
    <item>
      <title>레귤러 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/regular-graph/</link>
      <pubDate>Mon, 06 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regular-graph/</guid>
      <description>정의 1 모든 버텍스의 차수가 같은 그래프를 레귤러 그래프Regular Graph라고 한다. 특히 모든 버텍스의 차수가 $r$ 이면 $r$-레귤러 그래프라고 한다. 다시 말해, 다음을 만족시키는 그래프 $G$ 를 $r$-레귤러 그래프라고 한다. $$ \deg (v) = r \qquad , \forall v \in V(G) $$ $2$-레귤러 연결 그래프를 사이클Cycle이라고 한다. 예시 레귤러 그래프</description>
    </item>
    
    <item>
      <title>감마 분포와 지수 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-exponential/</link>
      <pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-exponential/</guid>
      <description>정리 $$ \displaystyle \Gamma \left(1, { 1 \over \lambda } \right) \iff \text{exp} (\lambda) $$ 설명 지수 분포의 직관적인 정의를 생각해보면 어떤 사건이 일어날때까지 걸리는 시간에 관심이 있는 것이다. 이산 확률 분포로 따지자면 기하 분포가 이에 해당한다. 이때 기하 분포를 사건의 &amp;lsquo;발생 횟수&amp;rsquo;에 대해 일반화한 것이 음이항 분포다. 이런 센스에서, 지수 분포를 일반화한 것은 감마 분포</description>
    </item>
    
    <item>
      <title>산술 함수의 승법적 성질</title>
      <link>https://freshrimpsushi.github.io/posts/multiplicativity-of-arithmetical-function/</link>
      <pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplicativity-of-arithmetical-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **1. $\forall n \in \mathbb{N}$ 에 대해 $f(n) = 0$ 은 아닌 산술 함수 $f$ 가 다음을 만족시키면 승법적 함수라 한다. $$ f(mn) = f(m) f(n) \qquad,\gcd(m,n)=1 $$ 승법적 함수가 다음 조건을 만족시키면 완전 승법적 함수라 한다. $$ f(mn) = f(m) f(n) \qquad,m,n \in \mathbb{N} $$ [1]: $f$ 가 승법적이면 $f(1) = 1$ 이다. [2]: $f$ 가 승법적 함수인 것과 모든 소수 $p_{1} , \cdots , p_{r}$ 와 모든 $a_{1} , \cdots, a_{r} \in \mathbb{N}$ 에 대해 $f</description>
    </item>
    
    <item>
      <title>감마 분포와 푸아송 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-poisson/</link>
      <pubDate>Fri, 03 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-poisson/</guid>
      <description>정리 모든 자연수 $k$ 에 대해 $$ \displaystyle \int_{\mu}^{\infty} { { z^{k-1} e^{-z} } \over { \Gamma (k) } } dz = \sum_{x=0}^{k-1} { { {\mu}^{x} e^{-\mu} } \over {x!} } $$ 이 등식은 감마 분포와 푸아송 분포의 누적 확률 분포 함수가 서로 관련이 있음을 보여준다. 이는 감마 분포가 지수 분포와의 관계를 가진다는 점에서 충분히 그럴법하다고 말할 수 있다. 증명 $k=1$ 일 때 $$ \displaystyle \int_{\mu}^{\infty} { { z^{0} e^{-z} } \over { \Gamma (0) } } dz = e^{-\mu} = \sum_{x=0}^{0} { { {\mu}^{x} e^{-\mu} } \over {x!} } $$ $k=N$</description>
    </item>
    
    <item>
      <title>널 그래프와 컴플리트 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/null-graph-and-complete-graph/</link>
      <pubDate>Thu, 02 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/null-graph-and-complete-graph/</guid>
      <description>정의 1 심플 그래프 $G$ 가 주어져 있다고 하자. $E(G) = \emptyset$ 이면 $G$ 를 널 그래프라고 한다. $E \left( \overline{G} \right) = \emptyset$ 이면 $G$ 를 컴플리트 그래프라고 한다. 설명 널 그래프는 말 그대로 비어있는 그래프를 의미한다. 여기서 Empty(빌 공, 空)이 아니라 Null(영 영, 零)이라는 표현을 쓴 이유는 실제로 $G \ne \emptyset$ 일지라도 그래프로써 아무런 의미가 없기 때문이다. 예컨대</description>
    </item>
    
    <item>
      <title>감마 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-gamma-distribution/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-gamma-distribution/</guid>
      <description>공식 $X \sim \Gamma ( \alpha , \beta )$ 면 $$ E(X) = k \theta \\ \text{Var} (X) = k \theta^{2} $$ 유도 전략: 감마 분포의 정의와 감마 함수의 기본적인 성질로 직접 연역한다. $x$ 의 차수가 변하는만큼 계수의 분자 분모를 맞춰주는 트릭을 쓴다. 감마 분포의 정의: $k, \theta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\Gamma ( k , \theta )$ 를 감마 분포라고 한다. $$ f(x) = {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x^{k</description>
    </item>
    
    <item>
      <title>감마 분포</title>
      <link>https://freshrimpsushi.github.io/posts/gamma-distribution/</link>
      <pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gamma-distribution/</guid>
      <description>정의 1 $k, \theta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\Gamma ( k , \theta )$ 를 감마 분포Gamma Distribution라고 한다. $$ f(x) = {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x^{k - 1} e^{ - x / \theta} \qquad , x &amp;gt; 0 $$ $\Gamma$ 는 감마 함수를 나타낸다. 감마 분포의 확률 밀도 함수는 $\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같이 정의되기도 한다. 본질적으로는 $\theta = {{ 1 } \over {</description>
    </item>
    
    <item>
      <title>그래프 컴플리먼트</title>
      <link>https://freshrimpsushi.github.io/posts/complement-of-graph/</link>
      <pubDate>Sun, 29 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complement-of-graph/</guid>
      <description>정의 1 심플 그래프 $G$ 에 대해 다음을 만족하는 그래프 $\overline{G}$ 를 $G$ 의 컴플리먼트라 한다. $$ V \left( \overline{G} \right) = V(G) \\ vw \in E \left( \overline{G} \right) \iff vw \notin E(G) $$ 설명 보통의 수학에서 컴플리먼트Complement가 그러하듯 그래프의 컴플리먼트는 補(도울 보)의 개념을 의미한다. 한국어 순화로는 여그래프Complement Graph가 될텐데, 다 마음에 들지 않아서 그냥</description>
    </item>
    
    <item>
      <title>산술 함수의 아벨리안 그룹</title>
      <link>https://freshrimpsushi.github.io/posts/abelian-group-of-arithmetic-functions/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abelian-group-of-arithmetic-functions/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $f(1) \ne 0$ 이 아닌 산술 함수 들의 집합 $A = \left\{ f : \mathbb{N} \to \mathbb{C} \mid f(1) \ne 0 \right\}$ 과 이항 연산 $\ast$ 에 대해 $(A,*)$ 는 아벨리안 그룹이다. 엄밀히 말하면 모든 산술 함수의 집합이 아벨리안 그룹이 될 수 있는 것은 아니다. 대수적 구조가 그룹이 되기 위한 마지막 조건인 역원의 존재성 때문인데, 다행스럽게도 그렇게 어려운 조건은 아니</description>
    </item>
    
    <item>
      <title>기하 분포의 무기억성</title>
      <link>https://freshrimpsushi.github.io/posts/memoryless-property-of-geometric-distribution/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/memoryless-property-of-geometric-distribution/</guid>
      <description>정리 $X \sim \text{Geo} ( m )$ 이면 $P(X \ge s+ t ,|, X \ge s) = P(X \ge t)$ 설명 기하 분포는 어떤 사건이 일어나는 횟수에 관심을 두는 이산확률분포다. 지수 분포의 이산화라는 센스에서 생각해보면 이러한 기하분포의 무기억성은 당연하다고 할 수 있겠다. 여기서 무기억성Memoryless Property이란 지나온 시간에 의해 앞으로 일어날 일이 영향을 받지 않는 성질이</description>
    </item>
    
    <item>
      <title>서브 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/subgraph/</link>
      <pubDate>Wed, 25 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subgraph/</guid>
      <description>1 그래프 $G$ 에 대해서 그래프 $H$ 가 $V(H) \subset V(G)$ 와 $ E(H) \subset E(G)$ 를 만족하면 $H$ 가 $G$ 의 서브 그래프라 한다. 설명 주의해야하는 것은 $H$ 가 $G$ 의 서브 그래프라고 $H \subset G$ 와 같이 나타내면 안 된다는 것이다. 서브 그래프는 직접적으로 그래프 이론에서 어떤 관심의 대상이 된다기보단 당연하고 상식적인 용어로써 의미가 있다. 예시 서브 그래프를 정의함으로써 생각할 수 있는 것들</description>
    </item>
    
    <item>
      <title>지수 분포의 무기억성</title>
      <link>https://freshrimpsushi.github.io/posts/memoryless-property-of-exponential-distribution/</link>
      <pubDate>Tue, 24 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/memoryless-property-of-exponential-distribution/</guid>
      <description>성질 $X \sim \exp{ ( \lambda ) }$ 이면 $P(X \ge s+ t ,|, X \ge s) = P(X \ge t)$ 설명 지수 분포는 어떤 사건이 일어나는 기간에 관심을 두는 연속확률분포다. 깊게 생각하지 않아도 수명예측이나 보험 등에 응용될 수 있음을 짐작할 수 있다. 여기서 무기억성Memoryless Property이란 지나온 시간에 의해 앞으로 일어날 일이 영향을 받지 않는 성질이다. 예를 들어 30대</description>
    </item>
    
    <item>
      <title>그래프의 집합 표현</title>
      <link>https://freshrimpsushi.github.io/posts/set-representation-of-graph/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/set-representation-of-graph/</guid>
      <description>정의 1 두 그래프 $G_{1}$ 과 $G_{2}$ 에 대해 $V(G_{1}) \cap V(G_{2}) = \emptyset$ 이라고 하자. 두 그래프의 유니언Union $G = G_{1} \cup G_{2}$ 은 버텍스 셋 $V(G_{1}) \cup V(G_{2})$ 과 에지 셋 $E (G_{1}) \cup E ( G_{2} )$ 을 가지는 그래프다. 그래프 $H$ 가 그래프들의 유니언으로 표현될 수 없으면 $H$ 를 연결되었다Connected고 하고, 그 외에는 단절되었다Disconnected고 한다. 단절된 그래프를 이루는 각 연결</description>
    </item>
    
    <item>
      <title>지수 분포와 푸아송 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-exponential-and-poisson/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-exponential-and-poisson/</guid>
      <description>정리 사건이 일어날 때 걸리는 시간 $X_{k}$ 에 대해 $X_{k} \sim \exp (\lambda)$ 이면 단위시간 당 발생하는 사건의 횟수 $N$ 에 대해 $\displaystyle N \sim \text{Poi} (\lambda)$ 설명 지수 분포와 푸아송 분포의 직관적인 정의를 생각해보자. 지수분포는 어떤 사건이 발생하기까지 걸리는 시간에 관심이 있고, 푸아송분포는 단위 시간 내에 어떤 사건이 몇 번 발생하는지 관심이 있다. 어떤 사건이 일어나는 시간과 사건이 일어나는</description>
    </item>
    
    <item>
      <title>지수 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-exponential-distribution/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-exponential-distribution/</guid>
      <description>공식 $X \sim \exp ( \lambda)$ 면 $$ E(X) = {{ 1 } \over { \lambda }} \\ \text{Var} (X) = {{ 1 } \over { \lambda^{2} }} $$ 증명 전략: 지수 분포의 정의에서 직접 연역한다. 지수 분포의 정의: $\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\exp ( \lambda)$ 를 지수 분포라고 한다. $$ f(x) = \lambda e^{-\lambda x} \qquad , x \ge 0 $$ 평균 $$ \displaystyle E(X)=\int _{ 0 }^{ \infty }{ x\cdot \lambda { e } ^{ -\lambda x } }dx $$ $\lambda x=t$ 이라고 두면 $\lambda dx=dt$ 이므로 $$ \begin{align*} \int _{ 0 }^{</description>
    </item>
    
    <item>
      <title>지수 분포</title>
      <link>https://freshrimpsushi.github.io/posts/exponential-distribution/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/exponential-distribution/</guid>
      <description>정의 1 $\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\exp ( \lambda)$ 를 지수 분포Exponential Distribution라고 한다. $$ f(x) = \lambda e^{-\lambda x} \qquad , x \ge 0 $$ 모수는 책에 따라서 그 역수인 $\displaystyle \theta = {{ 1 } \over { \lambda }}$ 을 쓰기도 한다. 기초 성질 [1] 적률 생성 함수: $$ m(t) = {{ \lambda } \over { \lambda - t }} \qquad , t &amp;lt; \lambda $$ [2] 평균과 분산: $X \sim \exp ( \lambda)$ 면</description>
    </item>
    
    <item>
      <title>다르부의 중간값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-darbouxs-intermediate-value-theorem/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-darbouxs-intermediate-value-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 중간값 정리 함수 $f : [a,b] \to \mathbb{R}$ 이 $[a,b]$ 에서 미분가능하면 $f&#39;(a)$ 와 $f&#39;(b)$ 사이의 $y_{0}$ 에 대해 $y_{0} = f(c)$ 를 만족하는 $c \in (a,b)$ 가 존재한다. 본 포스트는 &amp;lsquo;짱지&amp;rsquo;님의 요청으로 작성되었다. 증명 일반성을 잃지 않고, $f&amp;rsquo;(a) &amp;lt; y_{0} &amp;lt; f&#39;(b)$ 라 가정하자. 이에 대해 다음과 같은 함수 $g$ 를 정의하자. $$ g(x) := y_{0} x</description>
    </item>
    
    <item>
      <title>그래프의 행렬 표현</title>
      <link>https://freshrimpsushi.github.io/posts/matrix-representation-of-graph/</link>
      <pubDate>Tue, 17 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/matrix-representation-of-graph/</guid>
      <description>정의 1 그래프 $G(V,E)$가 주어졌다고 하자. 차수 행렬 각 버텍스 $v_{i}\in V$ 의 차수 $d(v_{i})$를 간단히 $d_{i}$라고 표기하자. 다음과 같은 행렬을 $G$ 의 차수 행렬degree matrix이라고 하고 $D(G)$ 혹은 간단하게 $D$라고 표기한다. $$ D(G) = \mathrm{diag} (d_{1}, \dots, d_{n}) = \begin{bmatrix} d_{1} &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; d_{2} &amp;amp; \cdots &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; \cdots</description>
    </item>
    
    <item>
      <title>자율 시스템의 플로우와 타임-T 맵</title>
      <link>https://freshrimpsushi.github.io/posts/t-map-of-autonomous-system/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/t-map-of-autonomous-system/</guid>
      <description>정의 1 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 시간 변수 $t$ 와 초기값 $x_{0}$ 에 대한 자율 미분 방정식의 해를 플로우라 하고 $F(t, x_{0})$ 와 같이 나타낸다. 픽스된 단위 시간 $t = T$ 에 대해 $F_{T}(x) := F(T,x)$ 를 타임-$T$ 맵이라 한다. 설명 플로우Flow는 궤적Trajectory 혹은 위상 공간Phase S</description>
    </item>
    
    <item>
      <title>악수 딜레마 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-handshaking-dilemma/</link>
      <pubDate>Fri, 13 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-handshaking-dilemma/</guid>
      <description>정리 1 임의의 유향 그래프에서, 입력 차수의 합과 출력 차수의 합은 같다. 설명 악수 딜레마는 유향 그래프에서의 악수 렘마라고 할 수 있다. 증명 유향 그래프에서 출력 차수의 합은 아크의 수와 같다. 아크는 하나의 버텍스에서 나오고 하나의 버텍스로 들어가므로, 출력 차수와 입력 차수의 합은 같다. ■ Wilson. (1970). Introduction to Graph Theory: p105. &amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>미분방정식으로 표현되는 동역학계와 평형점</title>
      <link>https://freshrimpsushi.github.io/posts/autonomous-system-and-equilibrium-in-dynamics/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/autonomous-system-and-equilibrium-in-dynamics/</guid>
      <description>정의 1 공간 $V$ 와 함수 $f : V \to V$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ v&#39; = f(v) $$ 변수 $t$ 를 포함하는 미분 방정식에서 $t$ 가 명시적으로Explicitly 드러나지 않으면 자율 미분 방정식Automonous Differential Equation이라 한다. 상수 함수 $f_{0} (v)$ 가 자율 미분 방정식 $v &#39; = f(v)$ 의 솔루션이면 $f_{0}$ 를 평형점Equ</description>
    </item>
    
    <item>
      <title>악수 렘마 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-handshaking-lemma/</link>
      <pubDate>Mon, 09 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-handshaking-lemma/</guid>
      <description>정리 1 임의의 그래프에서, 모든 버텍스의 차수의 합은 짝수다. 설명 이름의 &amp;lsquo;악수&amp;rsquo;는 보다시피 각각의 버텍스가 인접한 버텍스와 악수를 한다고 했을 때, 그 횟수가 바로 차수의 합이기 때문에 붙은 것이다. 증명 그래프 $G$ 에 대해 모든 차수의 합은 정확하게 모든 에지의 수의 두 배여야하므로 $$ \sum_{v \in V(G)} \deg (v) = 2 \left| E(G) \right| $$ ■ 위의 증명에</description>
    </item>
    
    <item>
      <title>어트랙터의 카오스</title>
      <link>https://freshrimpsushi.github.io/posts/chaotic-attractor/</link>
      <pubDate>Sat, 07 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaotic-attractor/</guid>
      <description>빌드업 공간 $X = \left( \mathbb{R}^{n} , \left\| \cdot \right\| \right)$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $\phi(t, \cdot)$ 은 벡터 필드 $x&#39; = f(x)$ 의 플로우, $g^{n}$ 는 맵 $g$ 를 $n$ 번 취한 맵을 나타내고, $\Lambda \subset X$ 가 $\phi(t, \cdot)$ 혹은 $g(\cdot)$ 하에서 불변 컴팩트 집합이라고 하자. $\phi(t,x)$ 혹은 $g(x)$ 가 $\Lambda$ 에서 초기값에 민감하다Sensitive Dependence on Initial Conditions는 것</description>
    </item>
    
    <item>
      <title>그래프 이론에서의 차수</title>
      <link>https://freshrimpsushi.github.io/posts/degree-in-graph-theory/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/degree-in-graph-theory/</guid>
      <description>정의 1 유향 그래프 $G$ 가 주어져있다고 하자. 에지 $vw$ 가 존재하면 에지가 $v$ 에서 나가고 $w$ 로 들어간다고 말한다. 버텍스 $v$ 로 들어오는 에지의 수를 입력 차수Indegree라 하고 $\deg^{-} (v)$ 와 같이 나타낸다. 버텍스 $v$ 에서 나가는 에지의 수를 출력 차수Outdegree라 하고 $\deg^{+}(v)$ 와 같이 나타낸다. $\deg^{-} (v) = 0$ 인 버텍스를 소스Source , $\deg^{+} (v) = 0$ 인 버텍</description>
    </item>
    
    <item>
      <title>디리클레 곱에 대한 인버스</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-function-under-drichlet-convolution/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-function-under-drichlet-convolution/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 산술 함수 $f$ 에 대해 다음을 만족하는 산술 함수 $f^{-1}$ 가 유일하게 존재하면 $f^{-1}$ 를 $f$ 의 (디리클레) 인버스라 한다. $$ f \ast\ f^{-1} = f^{-1} \ast\ f = I $$ 여기서 $I$ 는 컨볼루션에 대한 아이덴터티 함수다. 대부분의 수학에서 다루는 역함수와 달리 디리클레 인버스는 사상에 대한 역사상이 아닌 대수적인 센스에서의 인버스를</description>
    </item>
    
    <item>
      <title>그래프의 아이소멀피즘</title>
      <link>https://freshrimpsushi.github.io/posts/isomorphism-of-graphs/</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isomorphism-of-graphs/</guid>
      <description>정의 1 두 그래프 $G_{1}$ 와 $G_{2}$ 가 주어져 있다고 하자. $V(G_{1})$ 과 $V(G_{2})$ 사이에 전단사가 존재하고 $G_{1}$ 의 버텍스끼리의 에지의 수와 그에 대응하는 $G_{2}$ 의 버텍스끼리의 에지의 수가 같으면 그 전단사를 아이소멀피즘이라 하고 두 그래프가 아이소멀픽Isomorphic하다고 한다. 다시 말해, 다음을 만족하는 전단사 $\phi : G_{1} \to G_{2}$ 를 아이소멀피즘이라 부른다. $$ u \sim_{1} v \iff \phi (u)</description>
    </item>
    
    <item>
      <title>푸아송 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-poisson-distribution/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-poisson-distribution/</guid>
      <description>공식 $X \sim \text{Poi}(\lambda)$ 면 $$ E(X) = \lambda \\ \text{Var}(X) = \lambda $$ 유도 전략: 푸아송 분포의 정의에서 직접 연역한다. 팩토리얼과 급수를 쪼개는 트릭이 중요하다. 푸아송 분포의 정의: $\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Poi} ( \lambda )$ 를 푸아송 분포라고 한다. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over { x! }} \qquad , x = 0 , 1 , 2, \cdots $$ 평균 $$ \displaystyle \begin{align*} E(X) =&amp;amp; \sum _{ x=0 }^{ \infty }{ x\frac { { \lambda ^ x }{ e</description>
    </item>
    
    <item>
      <title>리에나르-비케르트 전위의 시간 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/time-derivative-of-lienard-wiechert-potentials/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-derivative-of-lienard-wiechert-potentials/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 리에나르-비케르트 전위의 시간에 대한 미분은 다음과 같다.$(a) $$ $\frac{ \partial V}{ \partial t}=\frac{qc}{4\pi \epsilon_{0}} \frac{1}{(\eta c -\boldsymbol{\eta} \cdot \mathbf{v})^{2}} \left( c^{2} -c^{2}\frac{ \partial t}{ \partial t_{r}}-v^{2}+\boldsymbol{\eta}\cdot \mathbf{a} \right)\frac{ \partial t_{r}}{ \partial t } $$ $(b) $$ $\frac{ \partial \mathbf{A}}{ \partial t }=\frac{qc}{4\pi \epsilon_{0}} \frac{1}{(\eta c -\boldsymbol{\eta} \cdot \mathbf{v})^{3}}\left[ (\eta c +\boldsymbol{\eta}\cdot \mathbf{v})(\eta\mathbf{a}/c-\mathbf{v})+ \frac{\eta}{c}\mathbf{v}\left( c^{2} -v^{2}+\boldsymbol{\eta}\cdot \mathbf{a}\right) \right] $$ **보조정리 지연 시각의 시간 미분은 아래와 같다. $$ \frac{ \partial t_{r}}{ \partial t}=\frac{\eta c}{\eta c-\boldsymbol{\eta}\cdot \mathbf{v}}=\frac{ \eta c}{\boldsymbol{\eta} \cdot \mathbf{u}} $$ 이 때 $\mathbf</description>
    </item>
    
    <item>
      <title>푸아송 분포</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-distribution/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-distribution/</guid>
      <description>정의 1 $\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Poi} ( \lambda )$ 를 푸아송 분포Poisson Distribution라고 한다. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over { x! }} \qquad , x = 0 , 1 , 2, \cdots $$ 기초 성질 [1] 적률 생성 함수: $$ m(t) = \exp \left[ \lambda \left( e^{t} - 1 \right) \right] \qquad , t \in \mathbb{R} $$ [2] 평균과 분산: $X \sim \text{Poi}(\lambda)$ 면 $$ E(X) = \lambda \\ \text{Var}(X) = \lambda $$ 정리 [a] 이항분포의 극한분포로써</description>
    </item>
    
    <item>
      <title>디리클레 곱에 대한 아이덴터티</title>
      <link>https://freshrimpsushi.github.io/posts/identity-function-under-drichlet-convolution/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/identity-function-under-drichlet-convolution/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 다음과 같이 정의된 산술 함수 $I$ 를 아이덴터티 함수라 한다. $$ I(n) := \left[ {{ 1 } \over { n }} \right] $$ [1] 아이덴터티 급수: 유닛 함수 $u$ 다. 다시 말해, $$ \sum_{d \mid n}I(d) = u(n) = 1 $$ [2] 완전 승법성**: 모든 $n , m \in \mathbb{N}$ 에 대해 $I (mn) = I(m) I(n)$ [a] 컨볼루션에 대한 항등원: 모든 산술 함수 $f$ 에 대해 $$ I \ast\ f = f \ast\ I = f $$ $\left[ x</description>
    </item>
    
    <item>
      <title>물리학을 위한 미분방정식 기초 자주 나오는 미분방정식</title>
      <link>https://freshrimpsushi.github.io/posts/differential-equation-for-physics/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/differential-equation-for-physics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 학부 물리학을 공부하기 위해서라면 미분 방정식 풀이를 수학적으로 접근할 필요가 없을 것 같다. 따라서 최대한 덜 수학적이고 간단하게 설명했다.**미분 방정식이란? 간단히 말해서 미분이 포함된 방정식이다. 어려울 것 없이 가속도는 위치를 두 번 미분한 것이므로 가장 유명한 물리 공식인 $F=ma$</description>
    </item>
    
    <item>
      <title>음이항 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-negative-binomial-distribution/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-negative-binomial-distribution/</guid>
      <description>공식 $X \sim \text{NB}(r, p)$ 면 $$ E(X) = {{ r (1-p) } \over { p }} \\ \text{Var}(X) = {{ r (1-p) } \over { p^{2} }} $$ 증명 전략: 음이항 분포가 기하 분포의 일반화라는 점을 이용한다. [b] 기하분포의 일반화: $Y = X_{1} + \cdots + X_{r}$ 이고 $X_{i} \overset{\text{iid}}{\sim} \text{Geo}(p)$ 면 $Y \sim \text{NB}(r,p)$ 이 때 기하 분포의 정의는 음이항 분포와 마찬가지로 그 서포트가 $\mathcal{S} = \left\{ 0 , 1 , 2, \cdots \right\}$ 와 같이 되도록 둔다. 기하 분포의 평균과 분산: $X \sim \text{Geo} (p)$ 면 $$ E(X) = {{ 1-p</description>
    </item>
    
    <item>
      <title>음이항 분포</title>
      <link>https://freshrimpsushi.github.io/posts/negative-binomial-distribution/</link>
      <pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/negative-binomial-distribution/</guid>
      <description>정의 1 $r \in \mathbb{N}$ 와 $p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{NB}(r,p)$ 를 음이항 분포Negative Binomial Distribution라고 한다. $$ p(x) = \binom{r+x-1}{x-1} p^{r}(1-p)^{x} \qquad, x = 0,1,2,\cdots $$ 기초 성질 [1] 적률 생성 함수: $$ m(t) = \left[ {{ p } \over { 1 - (1-p) e^{t} }} \right]^{r} \qquad , t &amp;lt; -\log (1-P) $$ [2] 평균과 분산: $X \sim \text{NB}(r, p)$ 면 $$ E(X) = {{ r (1-p) } \over { p }} \\ \text{Var}(X) = {{ r (1-p) } \over { p^{2} }} $$ 설명 음이</description>
    </item>
    
    <item>
      <title>르장드르 미분 방정식의 삼각함수 꼴</title>
      <link>https://freshrimpsushi.github.io/posts/trigonometry-function-form-of-associated-lengendre-differential-equation/</link>
      <pubDate>Fri, 21 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trigonometry-function-form-of-associated-lengendre-differential-equation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 삼각함수 꼴의 연관 르장드르 미분 방정식은 아래와 같다. $$ \begin{align} \frac{ d^{2} y}{ d \theta^{2} }+\cot \theta \frac{ d y}{ d \theta}+ \left( l(l+1) -\frac{m^{2}}{\sin ^{2 }\theta} \right)y=0 \\ \mathrm{or} \quad\frac{1}{\sin \theta}\left(\sin \theta \frac{dy}{d\theta} \right)+ \left(l(l+1) -\frac{ m^{2}}{\sin ^{2} \theta} \right)y=0 \end{align} $$ 전자기학, 양자역학 등에서 구면 좌표계 라플라스 방정식을 풀 때 유용하다. 참고로 해는 다음과 같다. $$ \begin{align*} y &amp;amp;= P_{l}^{m}(\cos \theta) \\ &amp;amp;= (1-\cos ^{2}\theta)^{\frac{|m|}{2}} \frac{ d^{|m|} }{ dx^{|m|} } P_{l}(\cos\theta) \end{align*} $$ $P_{l}^</description>
    </item>
    
    <item>
      <title>산술 함수의 디리클레 곱</title>
      <link>https://freshrimpsushi.github.io/posts/dirichlet-product-of-arithmetical-function/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichlet-product-of-arithmetical-function/</guid>
      <description>정의 1 두 산술 함수 $f$, $g$ 에 대해 다음을 만족시키는 산술 함수 $h$ 를 $f$, $g$ 의 디리클레 곱Dirichlet Product이라고 부른다. $$ h(n) = \sum_{d \mid n} f(d) g \left( {{ n } \over { d }} \right) $$ 디리클레 곱은 $h (n) = (f \ast g) (n) $ 혹은 $h = f \ast g$ 와 같이 나타낼 수 있다. 설명 디리클레 곱은 그 모양에서 짐작할 수 있듯 합성곱[컨볼루션]Convolution이라고도</description>
    </item>
    
    <item>
      <title>기하 분포의 두가지 정의가 가지는 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/two-different-definitions-of-geometric-distribution/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/two-different-definitions-of-geometric-distribution/</guid>
      <description>설명 기하 분포에 대해 공부하면서 가장 당황스럽고 헷갈리는 것이 교재, 블로그, 위키마다 설명이 다르다는 것이다. 어떤 곳에서는 평균이 $\displaystyle {{1} \over {p}} $ 인데 다른 곳은 $\displaystyle {{1-p} \over {p}}$ 로 쓰기도 한다. 이러한 차이는 기하분포를 정의하는 방법이 두가지가 있기 때문이다. 기하분포 $\text{Geo}(p)$ 의 확률질량함수는 $$ p_{1}(x) = p(1-p)^{x-1} , x= 1,2,3,\cdots $$ 혹은 $$ p_{2}(x) = p(1-p)^{x} , x= 0,1,2,\cdots $$ 으로 정의된다. 기댓값</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 산술 함수</title>
      <link>https://freshrimpsushi.github.io/posts/arithmetical-function-in-analytic-number-theory/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arithmetical-function-in-analytic-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정의역이 자연수의 집합 $\mathbb{N}$ 이고 공역이 실수 집합 $\mathbb{R}$ 혹은 복소수 집합 $\mathbb{C}$ 인 함수를 산술 함수라 한다. 해석적 정수론에서는 다양한 산술 함수의 성질과 관계에 관심을 가지며, 다음과 같은 예들이 있다:1. 아이덴티티 함수 $I$2. 디바이저 함수 $\sigma_{\alpha}$3. 놈 $N$4. 디바이저 함수 $\sigma_{\alpha}$5. 뫼비우스 함수 $\mu$6. 오일러 토션트 함수 $\varphi$7. 유닛 함</description>
    </item>
    
    <item>
      <title>기하 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-geometric-distribution/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-geometric-distribution/</guid>
      <description>공식 $X \sim \text{Geo} (p)$ 면 $$ E(X) = {{ 1 } \over { p }} \\ \text{Var}(X) = {{ 1-p } \over { p^{2} }} $$ 유도 기하 분포의 평균과 분산은 생각보다 쉽게 구해지지 않는다. 본 포스트에서는 유익하면서도 재미있는 두가지 증명을 소개한다. 기하 분포의 정의$p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Geo}(p)$ 를 기하 분포라고 한다. $$ p(x) = p (1 - p)^{x-1} \qquad , x = 1 , 2, 3, \cdots $$ 첫번째 방</description>
    </item>
    
    <item>
      <title>리눅스에서 줄리아 최신 버전 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-the-latest-version-julia-in-linux/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-the-latest-version-julia-in-linux/</guid>
      <description>본 포스트에서 줄리아 최신 버전은 v1.3.1이다. 가이드 Step 1. 줄리아 다운로드 Generic Linux Binaries for x86에서 자기 CPU의 비트에 맞는 파일을 다운로드 받는다. Step 2. 압축 해제 후 이동 압축을 해제한다. 줄리아가 저장되어 있을 위치로 폴더를 옮긴다. 본인이 원하는 곳 어디라도 상관 없는데, 해당 포스트에서는 /home/[유저이름]/julia-1.3</description>
    </item>
    
    <item>
      <title>기하 분포</title>
      <link>https://freshrimpsushi.github.io/posts/geometric-distribution/</link>
      <pubDate>Sun, 16 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/geometric-distribution/</guid>
      <description>정의 $p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Geo}(p)$ 를 기하 분포Geometric Distribution라고 한다. $$ p(x) = p (1 - p)^{x-1} \qquad , x = 1 , 2, 3, \cdots $$ 두가지 정의가 쓰이고 있으니 수식과 정의역에 특히 주의해야한다. 기초 성질 [1] 적률 생성 함수: $$ m(t) = {{ p e^{t} } \over { 1 - (1-p) e^{t} }} \qquad , t &amp;lt; -\log (1-p) $$ [2] 평균과 분산: $X \sim \text{Geo} (p)$</description>
    </item>
    
    <item>
      <title>다차원 맵의 카오스</title>
      <link>https://freshrimpsushi.github.io/posts/chaos-of-multi-dimensional-map/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaos-of-multi-dimensional-map/</guid>
      <description>정의1 맵 $f : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 의 바운디드 오빗 $\left\{ \mathbb{v}_{0}, \mathbb{v}_{1}, \cdots \right\}$ 이 다음을 만족하면 이 오빗을 캐어릭Chaotic하다고 한다. (i): 어심토티컬리 피리어딕이 아니다. (ii): 모든 $i = 1,\cdots , m$ 에 대해 $h_{i} ( \mathbb{v}_{0} ) \ne 0$ (iii): $h_{1} ( \mathbb{v}_{0}) &amp;gt; 0$ 오빗이 바운디드라는 말은 모든 $n \in \mathbb{N}_{0}$ 에 대해 $\left\| \mathbb{v}_{n} \right\| &amp;lt; M$ 을 만족하는 $M \in \mathbb{R}$ 이 존재한다는 뜻이다. $h_{i}(\mathbb{v}_{0})$ 은 랴푸노프 지수를 의미한다. 설명 $1$차</description>
    </item>
    
    <item>
      <title>이항 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-binomial-distribution/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-binomial-distribution/</guid>
      <description>공식 $\displaystyle X \sim \text{Bin} (n,p)$ 면 $$ E(X)=np \\ \text{Var}(X)=npq $$ 여기서 $q : = 1-p$ 다. 유도 전략: 조합을 직접 풀어헤친다. 식이 다소 더럽긴 하지만 고등학교 과정에서 충분히 소화할 수 있다. 한번쯤은 직접 해보도록 하자. 수리통계학을 접하면 조금 더 짧고 간단한 방법으로 증명할 수 있게 된다. 평균이든 분산이든 다음과 같은 이항 분포의 확률 질량 함수에서 시작한다. 이항 분포의 정의: $n \in</description>
    </item>
    
    <item>
      <title>이항 분포</title>
      <link>https://freshrimpsushi.github.io/posts/binomial-distribution/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/binomial-distribution/</guid>
      <description>정의 1 $n \in \mathbb{N}$ 과 $p \in [0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Bin}(n,p)$ 를 이항 분포Binomial Distribution라고 한다. $$ p(x) = \binom{n}{x} p^{x} (1-p)^{n-x} \qquad , x = 0 , 1, \cdots n $$ 기초 성질 [1] 적률 생성 함수: $$ m(t) = \left[ (1-p) + pe^{t} \right]^{n} \qquad , t \in \mathbb{R} $$ [2] 평균과 분산: $X \sim \text{Bin}(n,p)$ 면 $$ E(X) = np \\ \text{Var}(X) = np(1-p) $$ 정리 [a] 이항분포의 극한분포로써 푸아송분포 유도: $X_{n}</description>
    </item>
    
    <item>
      <title>회전하는 좌표계에서 운동하는 물체의 속도와 가속도</title>
      <link>https://freshrimpsushi.github.io/posts/dynamics-of-a-particle-in-a-rotating-coordinate-system/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamics-of-a-particle-in-a-rotating-coordinate-system/</guid>
      <description>공식 회전하는 좌표계에서 물체의 속도와 가속도는 다음과 같다. $$ \mathbf{v} = \mathbf{v}&#39; + \boldsymbol{\omega} \times \mathbf{r}&#39; +\mathbf{V}_0 $$ $$ \mathbf{a} = \mathbf{a}&#39; + \dot{\boldsymbol{\omega}} \times \mathbf{r}&#39;+ 2\boldsymbol{\omega} \times \mathbf{v}&#39;+\boldsymbol{\omega} \times ( \boldsymbol{\omega} \times \mathbf{r}&#39;) + \mathbf{A}_0 $$ 회전하는 좌표계1 달리는 기차가 있고 그 안에서 날아다니는 파리가 있다고 하자. 기차 안의 사람은 파리의 움직임만을 고려하면 되므로 파리의 운동을 설명하기 쉽다. 하지만 기차 밖의 사람은 기차의 운동도 같이 고려해야하기 때</description>
    </item>
    
    <item>
      <title>확률 변수들의 선형 결합</title>
      <link>https://freshrimpsushi.github.io/posts/linear-combinations-of-random-variable/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-combinations-of-random-variable/</guid>
      <description>정의 1 확률 변수 $X_{1} , \cdots , X_{n}$ 가 어떤 $(a_{1}, \cdots , a_{n}) \in \mathbb{R}^{n}$ 에 대해 $\displaystyle T := \sum_{i=1}^{n} a_{i} X_{i}$ 를 선형 결합Linear Combinations이라고 한다. 설명 특히 $X_{1} , \cdots , X_{n}$ 이 iid면 사이즈 $n$ 의 **랜덤 샘플Random Sample**이라도 부른다. 통계학의 맥락이라면 모든 관측값에 같은 가중치가 곱해진 $a_{1} = \cdots = a_{n} = {{ 1 } \over { n } }$ 을 생각할 것이다</description>
    </item>
    
    <item>
      <title>충분히 작은 각도란</title>
      <link>https://freshrimpsushi.github.io/posts/sufficiently-small-angle-small-angle-approximation/</link>
      <pubDate>Sun, 09 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficiently-small-angle-small-angle-approximation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 물리학의 많은 곳에서 $\sin x\approx x$ 근사를 사용한다. 이게 되는 이유는 아래의 식이 성립하기 때문이다. $$ \lim \limits_{x\rightarrow 0}\frac{\sin x}{x}=1 $$ 이는 고등학교에서 처음 배우기 때문에 대학생이라면 당연한 것처럼 느껴질 정도이다. 그래서 근사할 수 있다는 것에 의문을 가지는 사람은 거의 없을 것이다. 그런데 여기서 어느정도로 작아야 비</description>
    </item>
    
    <item>
      <title>줄리아에서 병렬처리 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-julia/</link>
      <pubDate>Sat, 08 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-julia/</guid>
      <description>코드 원래 생새우초밥집에는 상세한 설명을 포함하는데, 줄리아가 병렬처리를 얼마나 편하게 할 수 있는지 강조하기 위해 굳이 설명을 생략하려 한다. using Base.Threads for i in 1:10 println(i^2) end 위의 반복문을 병렬처리하고 싶다면 단지 포문 앞에 @threads만 붙이면 된다. @threads for i in 1:10 println(i^2) end 그래도 당부의 말을 한마디만 적는다면, 병렬처리라고 해서 모든 게 빨라지지는 않는다는</description>
    </item>
    
    <item>
      <title>양자역학에서 내적이란</title>
      <link>https://freshrimpsushi.github.io/posts/inner-product-in-quantum-physics/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inner-product-in-quantum-physics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **벡터와 내적 이과생이라면 고등학생 때 벡터와 내적을 아래와 같이 배웠을 것이다. 벡터는 크기와 방향을 가지며 좌표 공간위에 점이나 화살표로 나타낼 수 있는 것이다. 내적이란 두 벡터 사이에서 정의되는 연산이다.두 벡터 $\mathbf{a}=(a_1,\ a_2,\ a_3)$, $\mathbf{b} = (b_1,\ b_2,\ b_3)$가 있다고 하자. $\mathbf{a}$와 $</description>
    </item>
    
    <item>
      <title>다차원 맵의 랴푸노프 수와 그 수치적 계산법</title>
      <link>https://freshrimpsushi.github.io/posts/lyapunov-number-of-multi-dimensional-map/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lyapunov-number-of-multi-dimensional-map/</guid>
      <description>정의 1 스무스 맵 $\mathbb{f} : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 과 초기값 $\mathbb{v}_{0} \in \mathbb{R}^{m}$ 에 대해 $J_{n} := D \mathbb{f}^{n} ( \mathbb{v}_{0}) \in \mathbb{R}^{m \times m}$ 이라고 하자. $k = 1 , \cdots , m$ 에 대해 $m$차원 단위구 $N := \left\{ \mathbb{x} \in \mathbb{R}^{m} : \left\| \mathbb{x} \right\|_{2} = 1 \right\}$ 의 일립소이드 $J_{n} N$ 의 축의 길이 중 $k$ 번째로 긴 축의 길이를 $r_{k}^{(n)}$ 이라고 두자. 이제 $\mathbb{v}_{0}$ 의 $k$ 번째 랴푸노프 수 $L_{k}$ 를 다음과 같이 정의한다. $$ L_{k} := \lim_{n\to\infty} \left( r_{k}^{(n)} \right)^{1/n} $$ $\mathbb{v}_{0}$ 의 $k$ 번째 랴푸노프 지수 는 $h_{k} := \ln L_{k}$ 와 같</description>
    </item>
    
    <item>
      <title>정규분포를 따르는 두 확률 변수가 독립인 것과 공분산이 0인 것은 동치다</title>
      <link>https://freshrimpsushi.github.io/posts/two-normal-distributions-are-independent-iff-their-covariance-is-equal-to-zero/</link>
      <pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/two-normal-distributions-are-independent-iff-their-covariance-is-equal-to-zero/</guid>
      <description>정리 $$ X_{1} \sim N ( \mu_{1} , \sigma_{1} ) \\ X_{2} \sim N ( \mu_{2} , \sigma_{2} ) $$ 면 $$ X_{1} \perp X_{2} \iff \text{cov} (X_{1} , X_{2} ) = 0 $$ 설명 일반적으로 상관관계가 없다고 독립인 것은 아니다. 하지만 분포들이 정규분포를 따른다는 가정이 있다면 공분산이 $0$ 인 것이 독립임을 보장해준다. 증명 $( \Leftarrow ) $ $$ \displaystyle M_{X_{1}} (t_{1} ) = \exp \left[ \mu_{1} t_{1} + {{1} \over {2}} \sigma_{1} t_{1}^{2} \right] M_{X_{2}} (t_{2} ) = \exp \left[ \mu_{2} t_{2} + {{1} \over {2}} \sigma_{2} t_{2}^{2} \right] $$ $\sigma_{12} : = \text{cov} (X_{1} , X_{2} )$ 그리고 $\sigma_{21}</description>
    </item>
    
    <item>
      <title>프로베니우스 방법</title>
      <link>https://freshrimpsushi.github.io/posts/frobenius-method/</link>
      <pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/frobenius-method/</guid>
      <description>설명1 미분방정식을 푸는 다양한 방법들이 있다. 그 중 하나로 해를 다음과 같이 멱급수라고 가정하는 것이 있다. $$ y=\sum \limits_{n=0}^{\infty} a_{n}x^{n} $$ 그런데 어떤 급수들은 위의 꼴로 나타낼 수 없다. 예를 들면 다음과 같다. $$ \frac{\cos x}{x^{2}}=\frac{1}{x^{2}}-\frac{1}{2!}+\frac{ x^{2}}{4!}-\cdots $$ $$ \sqrt{x} \sin x = x^{\frac{1}{2}}\left( x - \frac{x^{3}}{3!}+\cdots \right) $$ 이런 경우에는 해를 아래와 같은 꼴이라고 가정한다. $$ \begin{equation} y=\sum \limits_{n=0}^{\infty} a_{n} x^{n+r}=x^{r}\sum \limits_{n=0}^{\infty} a_{n}x^{n} \label{eq1} \end{equation} $$ 이때 $r$은 양수, 음수는 물론 유리수도 가</description>
    </item>
    
    <item>
      <title>타원의 일반화: 일립소이드</title>
      <link>https://freshrimpsushi.github.io/posts/ellipsoid-of-linear-transform/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ellipsoid-of-linear-transform/</guid>
      <description>정의 선형 변환 $A \in \mathbb{R}^{m \times m}$ 에 대해 $m$차원 단위구 $N := \left\{ \mathbb{x} \in \mathbb{R}^{m} : \left\| \mathbb{x} \right\|_{2} = 1 \right\}$ 의 이미지 $AN$ 을 일립소이드라 한다. $A$ 의 아이겐 밸류 $\sigma_{1}^{2} &amp;gt; \cdots \ge \sigma_{m}^{2} \ge 0$ 와 그에 따른 단위 아이겐 벡터 $u_{1} , \cdots , u_{m}$ 에 대해 $\sigma_{i} u_{i}$ 를 일립소이드의 축Axis라 한다. 설명 $m$차원 단위구는 중심이 $\mathbb{0} \in \mathbb{R}^{m}$ 이고 반지름이 $1$ 인 점들을 모아놓은 집합으로, $m=2$ 일 때 우리가 흔히 알고 있</description>
    </item>
    
    <item>
      <title>번스타인 분포: 짝으로 독립이라고 상호 독립은 아니다</title>
      <link>https://freshrimpsushi.github.io/posts/bernstein-distribution/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bernstein-distribution/</guid>
      <description>정의 $(x,y,z) \in \left\{ (1,0,0), (0,1,0), (0,0,1), (1,1,1) \right\}$ 에 대해 다음과 같은 확률질량함수를 가지는 분포를 번스타인 분포Bernstein Distribution라고 한다. $$ p(x,y,z) = {{1} \over {4} } $$ 설명 번스타인 분포는 분포의 조건을 모두 만족시키고는 있지만 자연계에 실재하는 분포라고 보기는 어렵다. &amp;lsquo;짝으로 독립이면 상호 독립이다&amp;rsquo;라는 명제의 반례</description>
    </item>
    
    <item>
      <title>베셀 방정식의 급수해: 제1종 베셀 함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-first-kind/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-bessel-function-of-the-first-kind/</guid>
      <description>정의1 $\nu \in \mathbb{R}$에 대해서, 아래와 같은 꼴의 미분방정식을 $\nu$차 베셀 방정식이라 한다. $$ \begin{align*} &amp;amp;&amp;amp; x^{2} y&#39;&#39; +xy&#39;+(x^{2}-\nu^{2})y &amp;amp;= 0 \\ \text{or} &amp;amp;&amp;amp; y&#39;&#39;+\frac{1}{x} y&#39; + \left( 1-\frac{\nu^{2}}{x^{2}} \right)y &amp;amp;= 0 \end{align*} $$ 설명 베셀 방정식은 파동방정식을 구면좌표계에서 풀 때 등장하는 미분방정식이다. 계수는 상수가 아니고 독립 변수 $x$에 의존한다. $x=0$일 때 아래의 식을 만족하므로 $x=0$</description>
    </item>
    
    <item>
      <title>확률 변수들의 상호 독립과 iid</title>
      <link>https://freshrimpsushi.github.io/posts/mutual-independence-and-iid-independent-and-identically-distributed/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mutual-independence-and-iid-independent-and-identically-distributed/</guid>
      <description>정의 1 확률 변수 $X_{1} , \cdots , X_{n}$ 가 다음을 만족하면 $X_{1} , \cdots , X_{n}$ 이 짝으로 독립Pairwise Independent이라 한다. $$ i \ne j \implies X_{i} \perp X_{j} $$ 연속 확률 변수 $X_{1} , \cdots , X_{n}$ 의 조인트 확률 밀도 함수 $f$ 가 각각의 확률 밀도 함수 $f_{1} , \cdots , f_{n}$ 에 대해 다음을 만족하면 $X_{1} , \cdots , X_{n}$ 가 상호 독립이라 한다. $$ f(x_{1} , \cdots , x_{n} ) \equiv f_{1} (x_{1}) \cdots f_{n} (x_{n}) $$ 이산 확률 변수 $X_{1} , \cdots ,</description>
    </item>
    
    <item>
      <title>물리학에서의 감마함수</title>
      <link>https://freshrimpsushi.github.io/posts/the-gamma-function-in-physics/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-gamma-function-in-physics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 수학에서의 감마함수 감마함수 $\Gamma(p)$는 아래와 같이 정의된다. $$ \Gamma(p)=\int_{0}^{\infty} t^{p-1}e^{-t}dt $$ 딱 봐도 이상하고 어렵게 생겨먹은 이 함수는 팩토리얼을 일반화하기 위해 고안되었다. 알다시피 팩토리얼은 $0$을 포함한 자연수 $n$에 대해서 성립하는 연산이다. 오일러는 이 팩토리얼이라는 연산을 자연</description>
    </item>
    
    <item>
      <title>확률적 경사 하강법</title>
      <link>https://freshrimpsushi.github.io/posts/stochastic-gradient-descent-method/</link>
      <pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stochastic-gradient-descent-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 대상 함수 $Q$ 와 러닝 레이트 $\alpha &amp;gt; 0$, 배치사이즈 $m$ 과 $i$ 번째 데이터에 대해 $$ \omega_{n+1} := \omega_{n} - \alpha {{ 1 } \over { n }} \sum_{i=1}^{m} \nabla Q_{i} ( \omega_{n} ) $$ 를 확률적 경사 하강법이라 한다. 확률적 경사 하강법은 데이터를 다루는만큼 필연적으로 머신러닝과 깊은 관계를 가지고 있을 수밖에 없다. 몇몇 단어가 익숙하지 않더라도 일단 예시를 통</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 변수의 독립</title>
      <link>https://freshrimpsushi.github.io/posts/independence-of-random-variable/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independence-of-random-variable/</guid>
      <description>정의 1 두 확률 변수 $X_{1}, X_{2}$ 의 조인트 확률 밀도 함수 $f$ 혹은 확률 질량 함수 $p$ 에 대해 $X_{1}, X_{2}$ 의 확률 밀도 함수들 $f_{1}, f_{2}$ 혹은 확률 질량 함수 $p_{1}, p_{2}$ 가 다음을 만족하면 $X_{1}, X_{2}$ 가 독립이라 하고, $X_{1} \perp X_{2}$ 와 같이 나타낸다. $$ f(x_{1} , x_{2} ) \equiv f_{1}(x_{1})f_{2}(x_{2}) \\ p(x_{1} , x_{2} ) \equiv p_{1}(x_{1})p_{2}(x_{2}) $$ 정리 아래의 정리는 이산 확률 변수에 대해서도 같지만, 편의상 연속 확률 변수인 경우만 언급한다. 다음은 모두 동치다. [1]:</description>
    </item>
    
    <item>
      <title>수학에서의 최적화 기법</title>
      <link>https://freshrimpsushi.github.io/posts/optimization-method/</link>
      <pubDate>Sat, 25 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/optimization-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **1. 함수 $f : \mathbb{R}^{n} \to \mathbb{R}$ 의 함수값이 최소가 되도록 하는 $x^{ \ast } = \argmin_{x} f(x)$ 를 구하는 문제를 최적화 문제Optimization Problem라 하고, 그 문제를 푸는 알고리즘을 최적화 기법이라 부른다. 최적화 문제에서 주어진 함수 $f$ 를 특히 대상 함수Objective Function라 한다. 2. 정</description>
    </item>
    
    <item>
      <title>수리통계학에서의 조건부 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-probability/</link>
      <pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-probability/</guid>
      <description>정의 이산 확률 변수 $X_{1}, X_{2}, \cdots , X_{n}$ 에 대해 다음의 $p_{2, \cdots , n \mid 1}$ 를 $X_{1} = x_{1}$ 이 주어졌을 때의 $ X_{2}, \cdots , X_{n}$ 의 조인트 조건부 확률 질량 함수라고 한다. $$ p_{2, \cdots , n \mid 1} ( x_{2} , \cdots ,x_{n} \mid X_{1} = x_{1} ) = {{ p_{1, \cdots , n}(x_{1} , x_{2} , \cdots , x_{n}) } \over { p_{1}( X_{1} = x_{1} ) }} $$ 연속 확률 변수 $X_{1}, X_{2}, \cdots , X_{n}$ 에 대해 다음의 $f_{2, \cdots , n \mid 1}$ 를 $X_{1} = x_{1}$ 이 주어졌을 때의 $ X_{2}, \cdots , X_{n}$ 의 조인트 조건부 확률 밀도 함수</description>
    </item>
    
    <item>
      <title>오일러 적분: 베타 함수와 감마 함수</title>
      <link>https://freshrimpsushi.github.io/posts/euler-integral-beta-function-and-gamma-function/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euler-integral-beta-function-and-gamma-function/</guid>
      <description>정의 오일러 적분$(\mathrm{Euler\ integral})$ 아래의 두 적분을 오일러 적분이라 부른다. $(a)$ 제1종 오일러 적분$(\mathrm{Euler\ integral\ of\ the\ first\ kind})$ : 베타 함수 $$ B(p,q)=\int_0^1 t^{p-1}(1-t)^{q-1}dt,\quad p&amp;gt;0,\quad q&amp;gt;0 $$ $(b)$ 제2종 오일러 적분$(\mathrm{Euler\ integral\ of\ the\ second\ kind})$ : 감마 함수 $$ \Gamma (p) = \int_0^\infty t^{p-1}e^{-t}dt,\quad p&amp;gt;0 $$ 설명 제1종 오일러 적분 1-1. 베타함수: 감마 함수를 팩토리</description>
    </item>
    
    <item>
      <title>메타 프로그래밍</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-meta-programming/</link>
      <pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-meta-programming/</guid>
      <description>메타프로그래밍이란? 간단히 말해 프로그램이 코드를 수정하도록 하는 프로그래밍이라고 볼 수 있다. 정확하게 어떤 기법이라기보다는 그러한 개념 전반을 메타 프로그래밍이라고 부르는데, 어떤 프로그램이 다른 언어로 작성된 코드를 열어 &amp;lsquo;문자열&amp;rsquo;을 고치듯이 코드를 수정하거나 같은 언어끼리, 심지어는 스스로가 수정해도 모</description>
    </item>
    
    <item>
      <title>베타 함수의 이상적분꼴 표현</title>
      <link>https://freshrimpsushi.github.io/posts/improper-integral-representation-of-beta-function/</link>
      <pubDate>Mon, 20 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/improper-integral-representation-of-beta-function/</guid>
      <description>정리 베타함수: $$ B(p,q)=\int_{0}^{1}t^{p-1}(1-t)^{q-1}dt\quad \cdots (1) $$ 베타함수를 아래와 같은 이상적분으로 표현할 수 있다. $$ B(p,q)=\int_{0}^{\infty}\frac{ t^{p-1} }{ (1+t)^{p+q}}dt\quad \cdots (2) $$ 설명 위 식을 이용하면 계산하기 어려운 적분값을 쉽게 얻을 수 있다. 증명은 어렵지 않다. 증명 $(1)$에서 $t=\frac{x}{1+x}$라고 치환하자. 그러면 $1-t=\frac{1}{1+x}$이고, 적분 범위는 $\int_{0}^{1}\rightarrow \int_{</description>
    </item>
    
    <item>
      <title>scp로 서버에 파일 업로드하고 서버에서 다운로드 받는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-scp-command/</link>
      <pubDate>Sun, 19 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-scp-command/</guid>
      <description>명령어 scp는 아마도 server copy의 줄임말로, ssh 서버를 사용할 때 업로드와 다운로드를 하는 커맨드다. 띄어쓰기와 @, :의 위치에 주의하도록 하자. 서버의 계정을 serverACC, 서버의 주소를 serverADD, 서버 내에서 파일을 업로드 하거나 다운로드 받을 디렉터리를 serverDIR, 내가 전송하고자 하는 파일 혹은 디렉터리를 Object, 다운로드 받을 때 내가 다운로드 받고자 하는 디렉터리를 loca</description>
    </item>
    
    <item>
      <title>베타함수와 감마함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-between-beta-function-and-gamma-function/</link>
      <pubDate>Sat, 18 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-between-beta-function-and-gamma-function/</guid>
      <description>정리 $$ B(p,q) = {{\Gamma (p) \Gamma (q)} \over {\Gamma (p+q) }} $$ 설명 베타함수는 $\displaystyle B(p,q) := \int_{0}^{1} t^{p-1} (1-t)^{q-1} dt $ 로 정의되며, 감마함수와 마찬가지로 많은 분야에서 응용이 되고 있는 중요한 함수다. 감마함수는 재귀관계를 이용해서 쉽게 계산할 수 있기 때문에 위의 관계식으로 베타함수도 쉽게 계산할 수 있다.직관적으로 보자면 이항계수의 일반화고, 팩토리얼이 등장하므로 당연히 감마함수와 관련이</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transform-of-random-variable/</link>
      <pubDate>Fri, 17 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transform-of-random-variable/</guid>
      <description>공식 다변량 확률 변수 $X = ( X_{1} , \cdots , X_{n} )$ 의 조인트 확률밀도함수 $f$ 가 $f(x_{1} , \cdots , x_{n})$ 와 같이 주어져있다고 하고 다음과 같은 변환을 생각해보자. $$ y_{1} = u_{1} (x_{1} , \cdots , x_{n}) \\ \vdots \\ y_{n} = u_{n} (x_{1} , \cdots , x_{n}) $$ 이러한 변환 $u_{1} , \cdots , u_{n}$ 는 단사가 아닐 수 있다. 따라서 $X$ 의 서포트 $S_{X}$ 는 $k$ 개의 파티션 $A_{1} , \cdots , A_{i} , \cdots , A_{k}$ 으로 나누어지고, 다음과 같은 역변환 $w_{ji} \mid_{i=1,\cdots,k \\ j=1,\cdots,n}$ 들을 생각</description>
    </item>
    
    <item>
      <title>감마함수와 팩토리얼이 포함된 여러가지 중요한 공식</title>
      <link>https://freshrimpsushi.github.io/posts/some-important-formula-including-gamma-function-and-factorial/</link>
      <pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/some-important-formula-including-gamma-function-and-factorial/</guid>
      <description>공식 $(a)$ $\Gamma(\frac{1}{2})=\sqrt{\pi}$ $(b)$ 오일러 반사 공식: $$ \Gamma(p)\Gamma(1-p)=\dfrac{\pi}{\sin(\pi p)} $$ $(c)$ $$\Gamma(n+\frac{1}{2})=\frac{1\cdot 3\cdot \cdot5 \cdots (2n-1)}{2^{n}}\sqrt{\pi}=\frac{(2n-1)!!}{2^n}\sqrt{\pi}=\frac{(2n)!}{4^{n}n!}\sqrt{\pi},\quad n\in \mathbb{N}$$ $(d)$ 이항계수 $$ \begin{pmatrix} n \\ k \end{pmatrix}=\frac{\Gamma(n+1)}{k! \Gamma(n-k+1)} $$ $(e)$ 오일러-마스케로니상수: $$ \gamma=-\Gamma &#39; (1) $$ $(f)$ 베타 함수: $$ B(p,q)=\frac{\Gamma (p) \Gamma(q)}{\Gamma(p+q)} $$ $!!$는 더블 팩토리얼이다. 증명 감마함수: $$ \Gamma(p)=\begin{cases} \displaystyle \int_0^\infty x^{p-1}e^{-x}dx &amp;amp; p&amp;gt;0 \\ \frac{1}{p}\Gamma(p+1)&amp;amp; p&amp;lt;0 \end{cases} $$ 감마함수의 재귀 공식: $$ \Gamma(p+1)=p\Gamma(p) $$ $(a)$ $(b)$에서 $p=\frac{1}{2}$로 두면 $(a)$를 얻을 수 있지</description>
    </item>
    
    <item>
      <title>줄리아의 강력한 편의 기능, 매크로</title>
      <link>https://freshrimpsushi.github.io/posts/macro-in-julia/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/macro-in-julia/</guid>
      <description>개요 매크로는 줄리아로 코딩할 때 편의를 주는 기능들로써, 스코프 앞에 두어 실행한다. 예를 들어 자신의 프로그램이 얼마나 많은 시간을 소비하는지 알고 싶다면 다음과 같이 작성하면 된다. @time for t in 1:10 foo() bar() end 예시 많은 종류가 있지만 다음의 매크로들이 특히 널리 쓰인다: @time : 뒤에 이어지는 함수나 스코프의 실행 시간을 측정해준다. 어떤 상황에서 어떻게 최적</description>
    </item>
    
    <item>
      <title>팩토리얼, 더블 팩토리얼, 멀티 팩토리얼</title>
      <link>https://freshrimpsushi.github.io/posts/factorial-double-factorial-multifactorial/</link>
      <pubDate>Tue, 14 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factorial-double-factorial-multifactorial/</guid>
      <description>정의 팩토리얼$(\mathrm{factorial}$, 계승, 차례곱$)$ 자연수 $n$에 대해서 $n!$을 $n$팩토리얼이라 읽고 아래와 같이 정의한다. $$ n!=n\cdot(n-1)\cdot(n-2)\cdots 2\cdot 1 =\prod\limits_{k=1}^n k $$ 많은 곳에서 식을 깔끔하게 표현하기 위해 사용된다. $0$팩토리얼은 $0!:=1$으로 정의한다. 팩토리얼을 일반화해서 감마함수라는 것을 정의할 수도 있다.</description>
    </item>
    
    <item>
      <title>R에서 폴더 내부 파일 목록 가져오는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-list-of-folder-in-r/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-list-of-folder-in-r/</guid>
      <description>코드 setwd(&amp;quot;F:\\dsr\\project&amp;quot;) getwd() list.files(getwd()) list.files(getwd(),pattern=&amp;quot;*.csv&amp;quot;) list.files()는 여러개의 파일로 나눠진 데이터를 취합하거나 메타 프로그래밍 등에 유용하게 쓰이는 함수다: path: 첫번째 인자로써 디렉터리를 지정해주면 해당 폴더에 있는 파일들의 목록을 반환한다. pattern: 두번째 인자로써 정규표현식으로 규칙을 받아 조건에 만족하는 파일들의 목록만을 반환한다. 예제에서는 와일드카드 를 사용해 p</description>
    </item>
    
    <item>
      <title>감마함수 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-gamma-function/</link>
      <pubDate>Sun, 12 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-gamma-function/</guid>
      <description>음이 아닌 정수에 대한 감마함수 $\alpha &amp;gt;0$에 대해서 $$ \int_{0}^{\infty} e^{-\alpha x} dx=\left[-\frac{1}{\alpha}e^{-\alpha x}\right]_{0}^{\infty}=\frac{1}{\alpha} $$ 위 식의 양변을 $\alpha$에 대해서 미분하자. 그러면 라이프니츠 적분 규칙에 의해 좌변의 미분이 적분기호 안으로 들어갈 수 있으므로 $$ \begin{align*} &amp;amp;&amp;amp;\int_0^\infty -xe^{-\alpha x}dx&amp;amp;=-\frac{1}{\alpha^2} \\ \implies &amp;amp;&amp;amp; \int_0^\infty xe^{-\alpha x}dx &amp;amp;= \frac{1}{\alpha ^2} \end{align*} $$ 계속 미분해보면 $$ \begin{align*} \int_0^\infty x^2e^{-\alpha x}dx&amp;amp;=\frac{2}{\alpha^3} \\ \int_0^\infty x^3e^{-\alpha x}dx&amp;amp;=\frac{3\cdot 2}{\alpha^4} \\ \int_0^\infty x^4e^{-\alpha x}dx &amp;amp;=\frac{4\cdot 3\cdot 2}{\alpha^5} \\ &amp;amp;\vdots \\ \int_0^\infty x^ne^{-\alpha x}dx&amp;amp;=\frac{n!}{\alpha^{n+1}} \end{align*} $$ 여기서 $\alpha =1$이라고 두면</description>
    </item>
    
    <item>
      <title>라이프니츠 적분 규칙</title>
      <link>https://freshrimpsushi.github.io/posts/leibniz-integral-rule/</link>
      <pubDate>Sun, 12 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/leibniz-integral-rule/</guid>
      <description>정리 $f(x,t)$와 $\dfrac{\partial f}{\partial x}(x,t)$가 연속이라고 하자. 그러면 아래의 식이 성립한다. $$ \frac{d}{dx} \int_a^b f(x,t)dt = \int_a^b\frac{\partial f}{\partial x}(x,t)dt $$ 설명 미분과 적분의 순서를 바꿀 수 있으므로 유용함은 말할 것도 없다. 증명 연속이면 적분가능하므로 $u$를 다음과 같이 두자. $$ u(x):=\int_a^b f(x,t)dt $$ 그러면 다음이 성립한다. $$ \begin{equation} \begin{aligned} \frac{ u(x+h)-u(x)}{h} &amp;amp;= \frac{\int_{a}^{b} f(x+h,t)dt -\int_{a}^{b}f(x,t)dt}{h} \\ &amp;amp;= \frac{ \int_{a}^{b} \big[f(x+h,t)-f(x,t) \big] dt}{h} \\ &amp;amp;= \int_{a}^{b} \frac{f(x+h,t)-f(x,t)}{h}dt \end{aligned} \label{eq1} \end{equation} $$ 또한 고정된</description>
    </item>
    
    <item>
      <title>줄리아에서 파이프 오퍼레이터 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/pipe-operator-in-julia/</link>
      <pubDate>Sat, 11 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pipe-operator-in-julia/</guid>
      <description>개요 줄리아는 데이터를 다루는데에서 강점을 내세우는만큼 파이프라인 연산자를 지원한다. 코드 julia&amp;gt; (1:5) .|&amp;gt; (x -&amp;gt; sqrt(x+2)) .|&amp;gt; sin |&amp;gt; minimum 0.4757718381527513 julia&amp;gt; minimum(sin.((x -&amp;gt; sqrt(x+2)).(1:5))) 0.4757718381527513 위의 예제 코드는 배열 $[1,2,3,4,5]$ 를 $\sqrt{x + 2}$ 에 넣어서 얻은 결과를 $\sin$ 에 넣은 후 그 중 작은 값을 얻는 코드로,위와 아래 코드는 완전히 같은 결과를 낸다. 파이프라인이 복잡한 코드를 작성하는 중에 얼마나 유용한지는 굳이 설명할 필요가 없</description>
    </item>
    
    <item>
      <title>수리통계학에서의 다변량 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/multivariate-distribution/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multivariate-distribution/</guid>
      <description>정의 1 표본 공간 $\Omega$ 에서 정의된 $n$ 개의 확률 변수 $X_{i}$ 에 대해 $X = (X_{1} , \cdots , X_{n})$ 를 $n$차원 랜덤 벡터Random Vector라고 한다. $X$ 의 치역 $X(\Omega)$ 를 공간이라고도 부른다. 다음을 만족하는 함수 $F_{X} : \mathbb{R}^{n} \to [0,1]$ 을 $X$ 의 조인트Joint 누적 분포 함수라고 한다. $$ F_{X}\left( x_{1}, \cdots , x_{n} \right) := P \left[ X_{1} \le x_{1} , \cdots , X_{n} \le x_{n} \right] $$ 어떤 $h_{1} , \cdots , h_{n} &amp;gt;0$ 들에 대해 다음을 만족하는</description>
    </item>
    
    <item>
      <title>위상공간과 부분공간에서 내부에 대한 여러 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-for-interior-in-topological-space-and-subspace/</link>
      <pubDate>Wed, 08 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-for-interior-in-topological-space-and-subspace/</guid>
      <description>정리 위상공간 $(X,\mathcal{T})$와 부분집합 $A,B,A_{\alpha}\subset X\ (\alpha \in \Lambda)$가 주어졌다고 하자. 그러면 $(a1)$: $A\subset B$이면 $A^{\circ} \subset B^{\circ}$이다. $(b1)$: $A^{\circ}\cup B^{\circ} \subset (A\cup B)^{\circ}$ $(c1)$: $A^{\circ} \cap B^{\circ} = (A\cap B)^{\circ}$ $(d1)$: $(\cap_{\alpha\in\Lambda}A_{\alpha})^{\circ} \subset \cap _{\alpha \in \Lambda} A_{\alpha}^{\circ}$ 부분공간에 대한 내부 똑같은 집합이라도 전체공간이 어떻게 주어지는가에 따라서 열린집합이 될 수도 있고 안 될 수도 있다. 따라서 그</description>
    </item>
    
    <item>
      <title>줄리아에서의 람다식</title>
      <link>https://freshrimpsushi.github.io/posts/lambda-expression-in-julia/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lambda-expression-in-julia/</guid>
      <description>개요 줄리아에서 람다식은 다음과 같이 정의된다. (x -&amp;gt; 3x^2 - 2x + 3)(1) 이는 익명함수 $\lambda : \mathbb{Z} \to \mathbb{Z}$ 를 다음과 같이 정의하고, 거기에 $1$ 을 대입해서 $4$ 라는 함수값을 얻은 것에 해당한다. $$ \lambda : x \mapsto ( 3 x^{2} - 2 x + 3 ) \\ \lambda(1) = 4 $$ 사실 람다식 자체는 줄리아의 특징이 아니라 매트랩과 파이썬을 비롯해 함수형 언어에 영향을 받았다면 거의 당연하게 지원하고, 줄리아</description>
    </item>
    
    <item>
      <title>기저로부터 생성되는 위상</title>
      <link>https://freshrimpsushi.github.io/posts/a-topology-generated-by-a-basis/</link>
      <pubDate>Mon, 06 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/a-topology-generated-by-a-basis/</guid>
      <description>빌드업 위상 집합 $X$에 대해서 아래의 세 조건을 만족하는 $X$의 부분집합의 컬렉션 $\mathscr{T}$를 집합 $X$상의 위상 이라고 말한다. $(T1)$ $\varnothing, X \in \mathscr{T}$ $(T2)$ $U_{\alpha} \in \mathscr{T} (\alpha \in \Lambda)$이면 $\bigcup_{\alpha \in \Lambda} U_{\alpha} \in \mathscr{T}$이다. $(T3)$ $U_{1},\cdots,U_{n} \in \mathscr{T}$이면 $\bigcap_{i=1}^{n}U_{i} \in \mathscr{T}$이다. 간단히 말하자면</description>
    </item>
    
    <item>
      <title>돈스커의 정리</title>
      <link>https://freshrimpsushi.github.io/posts/donskers-theorem-invariance-priciple-functional-clt/</link>
      <pubDate>Sun, 05 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/donskers-theorem-invariance-priciple-functional-clt/</guid>
      <description>정리 $\left\{ \xi_i \right\}_{i \in \mathbb{N}}$ 이 $(0,1)$ 에서 정의된 확률 과정이라고 하자. 함수 공간 $C[0,1]$ 에서 확률 함수 $X_{n}$ 가 다음과 같이 정의되어 있다고 하자. $$ X_{n}:= {{ 1 } \over { \sqrt{n} }} \sum_{i=1}^{\lfloor nt \rfloor} \xi_{i} + \left( nt - \lfloor nt \rfloor \right) {{ 1 } \over { \sqrt{n} }} \xi_{\lfloor nt \rfloor + 1} $$ $X_{n}$ 은 $n \to \infty$ 일 때 위너 프로세스 $W$ 로 분포 수렴한다. $C[0,1]$ 은 정의역이 $[0,1]$ 이고 공역이 $\mathbb{R}$ 인 연속함수들의 공간이다. $\lfloor \cdot \rfloor$ 은 바닥 함수Floor Func</description>
    </item>
    
    <item>
      <title>옌센 부등식의 기댓값 폼 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-expectation-form-of-jensens-inequality/</link>
      <pubDate>Sat, 04 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-expectation-form-of-jensens-inequality/</guid>
      <description>정리 1 개구간 $I$ 에서 함수 $\phi$ 가 컨벡스하고 두 번 미분가능, 확률변수 $X$ 의 기댓값 $\mu$ 가 존재하며 $X \subset I $ 면 $$ \phi [ E(X) ] \le E [ \phi(X)] $$ 다른 형태 옌센 부등식의 유한 폼 옌센 부등식의 적분 폼 조건부 옌센 부등식 적분 폼과는 상당히 유사한 형태를 가지고 있다. 잘 생각해보면 유한 폼 역시 항이 무한하지는 않지만 가중평균의 부등식이라는 센스에서 기댓값이라고 볼 수 있</description>
    </item>
    
    <item>
      <title>매트랩에서 코드 실행 시간 재는 법</title>
      <link>https://freshrimpsushi.github.io/posts/calculating-running-time-of-code-in-matlab/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/calculating-running-time-of-code-in-matlab/</guid>
      <description>방법 tic X1=rand(2^7); X2=rand(2^8); X3=rand(2^9); X4=rand(2^10); X5=rand(2^11); toc Y1=imrotate(X1,45,&#39;bicubic&#39;,&#39;crop&#39;); toc Y2=imrotate(X2,45,&#39;bicubic&#39;,&#39;crop&#39;); toc Y3=imrotate(X3,45,&#39;bicubic&#39;,&#39;crop&#39;); toc Y4=imrotate(X4,45,&#39;bicubic&#39;,&#39;crop&#39;); toc Y5=imrotate(X5,45,&#39;bicubic&#39;,&#39;crop&#39;); toc tic: 실행 시간을 측정하기 위한 스톱워치를 실행한다. toc: 스톱워치의 현재 시간을 반환한다. toc과 toc사이의 시간을 재는 것이 아님에 주의하자. 위의 예제코드에서 Y1~Y6을 계산하는 시간을 각각 재고싶다면 아래와 같이 코드를 입력해야한다. tic X1=rand(2^7); X2=rand(2^8); X3=rand(2^9); X4=rand(2^10); X5=rand(2^11); toc tic Y1=imrotate(X1,45,&#39;bicubic&#39;,&#39;crop&#39;); toc tic Y2=imrotate(X2,45,&#39;bicubic&#39;,&#39;crop&#39;); toc tic Y3=imrotate(X3,45,&#39;bicubic&#39;,&#39;crop&#39;); toc tic Y4=imrotate(X4,45,&#39;bicubic&#39;,&#39;crop&#39;); toc tic Y5=imrotate(X5,45,&#39;bicubic&#39;,&#39;crop&#39;); toc 타언어</description>
    </item>
    
    <item>
      <title>줄리아에서 이미지 불러오고 행렬로 변환 저장하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-and-save-an-image-convert-to-matrix-in-julia/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-and-save-an-image-convert-to-matrix-in-julia/</guid>
      <description>코드 using Images cd(&amp;quot;C:/Users/rmsms/OneDrive/examples&amp;quot;) pwd() example = load(&amp;quot;example.jpg&amp;quot;) typeof(example) size(example) gray1 = Gray.(example) typeof(gray1) size(gray1) M = convert(Array{Float64},gray1) typeof(M) size(M) colorview(Gray, M.^(1/2)) save(&amp;quot;rgb.png&amp;quot;, colorview(RGB, example)) save(&amp;quot;gray1.png&amp;quot;, colorview(Gray, gray1)) save(&amp;quot;gray2.png&amp;quot;, colorview(Gray, transpose(gray1))) save(&amp;quot;gray3.png&amp;quot;, colorview(Gray, M.^(1/2))) 예제 코드를 위에서부터 간략하게 이해해보자: cd() : Change Directory, 작업 경로를 원하는 곳으로 바꿔준다. pwd() : Print Working Directory, 작업 경로를 출력해준다. 예제를 그대로 따라해보고싶다면 위의 파일을 작업 경로에 다운로드 받고 파일 이름을 example.jpg로 수정하자. load() : 작업 경로 내</description>
    </item>
    
    <item>
      <title>줄리아에서 이미지 크기 변경하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-resize-a-image-in-a-julia/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-resize-a-image-in-a-julia/</guid>
      <description>이미지 크기 변경 Images 패키지의 imresize를 사용하면 된다. 함수 이름이 매트랩과 같다. imresize(X, ratio=a): 배열 X를 a배만큼 조정한 이미지를 반환한다. 매트랩에서와는 다르게 냅다 비율만 적으면 안되고 반드시 ratio=a와 같이 적어야한다. imresize(X, m, n): 배열 X를 m행,n열로 확대/축소한 이미지를 반환한다. 아래는 예제 코드와 그 결과이다. using Images X=load(&amp;quot;example\_image2.jpg&amp;quot;) Y1=imresize(X, ratio=0.5) Y2=imresize(X,500,500)</description>
    </item>
    
    <item>
      <title>매트랩에서 이미지 크기 조절하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-resize-a-image-in-a-matlab/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-resize-a-image-in-a-matlab/</guid>
      <description>방법 imresize(A,scale): A의 크기를 scale배만큼 조정하여 새로운 이미지를 반환한다. A가 10x10이미지일 때 scale에 0.5를 입력하면 5x5 이미지를 반환한다. 아래와 같이 직접 크기를 조절할 수도 있다. imresize(A,[m n]): m개의 행과 n개의 열을 가진 이미지를 반환한다. 아래는 예제 코드와 그 결과이다. X=imread(&#39;test\_image.jpg&#39;); figure() imshow(X) saveas(gcf,&#39;X.png&#39;) title(&#39;X&#39;) Y1=imresize(X,0.5); Y2=imresize(X,[500 500]); Y3=imresize(X,[700 500]); Y4=imresize(X,[500,700]); figure() imshow(Y1) saveas(gcf,&#39;Y1.png&#39;) title(&#39;Y1=imresize(X,0.5)&#39;) figure() imshow(Y2) saveas(gcf,&#39;Y2.png&#39;) title(&#39;Y2=imresize(X,[500 500])&#39;) figure() imshow(Y3) saveas(gcf,&#39;Y3.png&#39;) title(&#39;Y3=imresize(X,[700 500])&#39;) figure() imshow(Y4)</description>
    </item>
    
    <item>
      <title>줄리아에서 이미지 배열을 회전하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-rotate-imagearraymatrix-in-julia/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-rotate-imagearraymatrix-in-julia/</guid>
      <description>이미지 회전 imrotate(X, theta) : 배열 X를 theta라디안만큼 회전시킨다. 여기서 주의해야할 점은 각도의 단위가 도($^{\circ})$인 매트랩과 달리 각도의 단위가 라디안이라는 것이다. 또한 매트랩과는 다르게 시계방향으로 회전한다. 다른 변수를 입력하지 않을 경우 보간법은 bilinear이고 회전된 이미지는 자르지 않는다. 원본 이미지 X와 이</description>
    </item>
    
    <item>
      <title>체비셰프 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-chebyshevs-inequality/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-chebyshevs-inequality/</guid>
      <description>정리 1 확률변수 $X$ 의 분산 $\sigma^2 &amp;lt; \infty$ 가 존재하면 $\mu := E(X)$ 와 어떤 양수 $k&amp;gt;0$ 에 대해 $$ \displaystyle P(|X-\mu| \ge k\sigma) \le {1 \over k^2} $$ 설명 비교적 형태가 간단하고 식의 조작이 쉬운데다 결과도 한 눈에 들어오기 때문에 보조정리로써 많이 쓰인다. 다만 마코프 부등식과 비교하자면 분산이 존재해야한다는 조건이 하나 더 있다. 조건에서 $2$차 적률이 존재해야하는 것을 보고 너무 쉽고 당연한 조건</description>
    </item>
    
    <item>
      <title>윈도우에서 ssh 서버 구축하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-construct-ssh-server-in-windows/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-construct-ssh-server-in-windows/</guid>
      <description>개요 윈도우는 10 버전에 들어 파워쉘PowerShell을 비롯하여 리눅스 특유의 편의 기능을 많이 제공하게 되었다. ssh 서버의 경우 GUI를 통해 아주 간단하게 설치할 수 있다. 가이드 **Step 1. 앱 및 기능 Win+S 를 눌러 프로그램 추가/제거 나 앱 및 기능 을 찾아 선택적 기능 을 클릭한다. Step 2. OpenSSH 서버 설치 기능 추가를 클릭하고 OpenSSH 서버 를 설치한다. Step 3. PowerShell Power</description>
    </item>
    
    <item>
      <title>줄리아에서 2차원 배열 연산에 관한 함수들</title>
      <link>https://freshrimpsushi.github.io/posts/1460/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1460/</guid>
      <description>$A = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 1 \\ 0 &amp;amp; 3 &amp;amp; 0 \\ 2 &amp;amp; 3 &amp;amp; 4\end{pmatrix}$라고 하자. 전치행렬 julia&amp;gt; A =[1 2 1; 0 3 0; 2 3 4] 3×3 Array{Int64,2}: 1 2 1 0 3 0 2 3 4 julia&amp;gt; transpose(A) 3×3 LinearAlgebra.Transpose{Int64,Array{Int64,2}}: 1 0 2 2 3 3 1 0 4 julia&amp;gt; A&#39; 3×3 LinearAlgebra.Adjoint{Int64,Array{Int64,2}}: 1 0 2 2 3 3 1 0 4 행렬의 원소가 실수라면 transpose()와 &#39;는 같은 행렬을 반환하지만 자료형이 미묘하게 다르다. 그 이유는 &#39;가 정</description>
    </item>
    
    <item>
      <title>줄리아에서 배열을 히트맵 이미지로 출력 저장하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-and-save-arrays-as-heatmap-images-in-julia/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-and-save-arrays-as-heatmap-images-in-julia/</guid>
      <description>Heatmap Plots 패키지의 heatmap 함수를 쓰면 2차원 배열을 히트맵 이미지로 출력할 수 있고, savefig 함수로 해당 이미지를 저장할 수 있다. @__DIR__은 줄리아 코드 파일의 위치를 알려주는 매크로이다. julia&amp;gt; cd(@__DIR__) julia&amp;gt; using Plots julia&amp;gt; A=[i for i=1:25] 25-element Array{Int64,1}: 1 2 3 4 ⋮ 23 24 25 julia&amp;gt; A=transpose(reshape(A, 5,5)) 5×5 LinearAlgebra.Transpose{Int64,Array{Int64,2}}: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 julia&amp;gt; h1=heatmap(A) julia&amp;gt; savefig(h1, &amp;quot;heatmap1.png&amp;quot;) 그런데 배열 A와 히트맵 이미지를 비</description>
    </item>
    
    <item>
      <title>마코프 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-markovs-inequality/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-markovs-inequality/</guid>
      <description>정리 1 확률변수 $X$ 에 대해 함수 $u(X) \ge 0$ 를 정의하자. $E \left( u(X) \right)$ 가 존재하면 $c &amp;gt; 0$ 에 대해 $$ \displaystyle P(u(X) \ge c) \le {E \left( u(X) \right) \over c} $$ 설명 수많은 증명에 사용되는 보조정리로써 이를 좀 더 편리하게 만든 체비셰프 부등식이 있다. 조건에서 $1$차 적률이 존재해야하는 것을 보고 너무 쉽고 당연한 조건으로 여길지 모르겠다. 뭐 어느정도는 맞는 말이지만, 학부생 정도 됐다면</description>
    </item>
    
    <item>
      <title>파이썬에서 is와 ==의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/how-different-is-and-in-python/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-different-is-and-in-python/</guid>
      <description>코드 if type(150421) is int : print(&amp;quot;!&amp;quot;) else : print(&amp;quot;?&amp;quot;) x = [1,2] y = [1,2] x == y x is y 설명 깃허브에서 파이썬 코드를 보다보면 간혹 is라는 게 보이기도 한다. 코드가 문장처럼 편안하게 읽히는 것은 둘째치더라도 ==와는 분명한 차이가 있어 적재적소에 사용하면 좋다: ==는 단순하게 값을 비교한다. 우리에게 실제로 보이는 모습을 비교하기 때문에 직관적이다. is는 포인터가 가리키</description>
    </item>
    
    <item>
      <title>n차 적률이 존재하면 차수가 n보다 작은 적률도 존재한다</title>
      <link>https://freshrimpsushi.github.io/posts/if-nth-moment-exists-then-moments-with-less-degree-are-exist/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-nth-moment-exists-then-moments-with-less-degree-are-exist/</guid>
      <description>정리 확률변수 $X$와 자연수 $n$ 에 대해 $E( X^n )$ 이 존재하면 $E( X^m ), m=1,2,3,\cdots, n$ 도 존재한다. 설명 어떤 차수의 적률이든 존재하기만 한다면 그보다 작은 차수의 적률은 항상 존재하지만, 당연히 역은 성립하지 않는다. 물론 실제로 문제를 접해보면 높은 차수의 적률이 먼저 주어지는 경우는 거의 없으나, 어떤 정리의 조건을 나열할 때 지면을 상당히 절약할 수 있게 해주는 정</description>
    </item>
    
    <item>
      <title>타이트 확률 과정</title>
      <link>https://freshrimpsushi.github.io/posts/tight-probability-process/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tight-probability-process/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 에서 확률 과정 $\left\{ X_n \right\}_{n \in \mathbb{N}}$ 이 정의되어 있다고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$\displaystyle \inf_{n \in \mathbb{N}} P\left( X_{n} \in K \right) &amp;gt; 1 - \varepsilon$$ 를 만족시키는 컴팩트 셋 $K \subset \Omega$ 가 존재하면 $\left\{ X_{n} \right\}$ 이 타이트Tight하다고 한다. 설명 수리통계학에서는 확률 유계에 해당하는 개념이다. 타이트는 분포 수렴과 관련해서 다음과 같이 중요한 성질들을 여럿 가진다. 기초 성질</description>
    </item>
    
    <item>
      <title>적률생성함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/moment-generating-function/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-generating-function/</guid>
      <description>정의 1 확률변수 $X$ 와 어떤 양수 $h&amp;gt;0$ 대해 $E(e^{tX})$ 이 $-h&amp;lt; t &amp;lt; h$ 에서 존재하면 $M(t) = E( e^{tX} )$ 를 $X$ 의 적률생성함수Moment Generating Function라고 정의한다. 설명 적률생성함수는 흔히 mgf라는 약어로 많이 쓰인다. 수리통계학에서는 비교적 초반에 배우는데, 생소한 정의와 맥락 없는 등장 때문에 수리통계학을 싫어지게 만드는 주범 중 하나다. 적률생성함수를</description>
    </item>
    
    <item>
      <title>줄리아에서 집합 자료형과 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/set-type-and-operator-in-julia/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/set-type-and-operator-in-julia/</guid>
      <description>개요 줄리아에서는 파이썬과 마찬가지로 집합 자료형을 지원한다. 원래 집합 자료형이 그렇듯 쓰는 사람은 요긴하게 쓰고 안 쓰는 사람은 일절 사용하지 않는데, 줄리아는 언어 설계 자체가 수학과 가까운만큼 집합의 개념과 연산이 잘 구현되어 있어 반드시 알아두는 게 좋다. 기존의 언어, 특히 파이썬과 가장 다른 점은 유니코드 기호들도 코드의 일부로 사용할 수 있다</description>
    </item>
    
    <item>
      <title>수리통계학에서의 첨도</title>
      <link>https://freshrimpsushi.github.io/posts/kurtosis/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kurtosis/</guid>
      <description>첨도 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{2}$ 를 $X$ 의 첨도kurtosis라고 한다. $$ \gamma_{2} := {{ E \left( X - \mu \right)^4 } \over { \sigma^4 }} $$ 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본첨도 $g_{2}$ 는 다음과 같이 구해진다. $$ g_{2} := \sum_{i=1}^{n} = {{ \left( X - \overline{X} \right)^4 } \over { n \widehat{\sigma}^4 }} - 3 $$ 설명 첨도는 4차 적률로 구해지며, 확률변수의 분포함수가 얼마</description>
    </item>
    
    <item>
      <title>파이썬에서 두 변수값 서로 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-swap-two-variables-in-python/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-swap-two-variables-in-python/</guid>
      <description>코드 변수끼리의 스왑은 흔히 아는 것처럼 임시 변수를 만들어서 옮기는 방식으로 쉽게 구현이 가능하지만, 여러가지 프로그래밍 언어를 다루는 입장에서 포인터를 주고받으면서 변수를 바인딩하는 파이썬의 특성상 이러한 방법이 잘 되는지 확신하기도 어렵고 일일이 변수를 스왑하는 함수를 작성하는 것 귀찮은 일이다. 다음과 같이 파이썬 문법 그 자체로 쉽게 해결해</description>
    </item>
    
    <item>
      <title>수리통계학에서의 왜도</title>
      <link>https://freshrimpsushi.github.io/posts/skewness/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/skewness/</guid>
      <description>정의 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{1}$ 를 $X$ 의 왜도Skewness라고 한다. $$ \gamma_{1} := {{ E \left( X - \mu \right)^3 } \over { \sigma^3 }} $$ 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본왜도 $g_{1}$ 은 다음과 같이 구해진다. $$ g_{1} := \sum_{i=1}^{n} {{ \left( X - \overline{X} \right)^3 } \over { n \widehat{\sigma}^3 }} $$ 설명 왜도는 3차 적률로 구해지며, 확률변수의 분포함수가 어떻게 치우</description>
    </item>
    
    <item>
      <title>공분산의 여러가지 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-covariance/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-covariance/</guid>
      <description>정의와 성질 평균이 각각 $\mu_{X}$, $\mu_{Y}$ 인 확률 변수 $X$, $Y$ 에 대해 $\text{Cov} (X ,Y) : = E \left[ ( X - \mu_{X} ) ( Y - \mu_{Y} ) \right] $ 을 $X$ 와 $Y$ 의 공분산Covariance이라고 정의한다. 공분산은 아래의 성질들을 가진다. [1]: $\text{Var} (X) = \text{Cov} (X,X)$ [2]: $\text{Cov} (X,Y) = \text{Cov} (Y, X)$ [3]: $\text{Var} (X + Y) = \text{Var} (X) + \text{Var} (Y) + 2 \text{Cov} (X,Y) $ [4]: $\text{Cov} (X + Y , Z ) = \text{Cov}(X,Z) + \text{Cov}(Y,Z) $ [5]: $\text{Cov} (aX + b , cY + d ) = ac \text{Cov}(X,Y) $ 설명 공분산은 두 변수의 선형</description>
    </item>
    
    <item>
      <title>줄리아에서 배열의 슬라이싱과 인덱싱</title>
      <link>https://freshrimpsushi.github.io/posts/slicing-and-indexing-in-julia/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/slicing-and-indexing-in-julia/</guid>
      <description>코드 줄리아는 R, 파이썬, 매트랩의 장점이 모두 섞여있는 언어다. 배열은 프로그래밍의 근간이 되는만큼 그 활용에서 여러 언어들의 흔적을 찾아볼 수 있다. 행렬 julia&amp;gt; M = [1. 2. ; 3. 4.] 2×2 Array{Float64,2}: 1.0 2.0 3.0 4.0 julia&amp;gt; size(M) (2, 2) julia&amp;gt; length(M) 4 행렬의 경우 매트랩의 문법과 거의 똑같이 정의하고 거의 똑같이 사용할 수 있다. size() 함수는 매트랩과 똑같이 쓰이고, 파이썬에서 numpy 패키지의 프로</description>
    </item>
    
    <item>
      <title>피어슨 상관계수</title>
      <link>https://freshrimpsushi.github.io/posts/pearson-correlation-coefficient/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pearson-correlation-coefficient/</guid>
      <description>정의 1 다음과 같이 정의된 $\rho = \rho(X,Y)$ 를 피어스 상관계수라고 한다. $$ \rho = { {\text{Cov} (X,Y)} \over {\sigma_X \sigma_Y} } $$ 설명 (피어슨) 상관 계수(Pearson) Correlation Coefficient는 두 변수가 서로 (선형) 상관 관계 를 가지고 있는지를 확인하는 척도가 된다. $1$ 이나 $–1$ 에 가까우면 상관관계가 있다고 보고 $0$ 이면 없다고 본다. 주의할 것은 상관관계와 독립이 같은 개</description>
    </item>
    
    <item>
      <title>평균과 분산의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-mean-and-variance/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-mean-and-variance/</guid>
      <description>정리 평균 $E ( X ) = \mu_{X}$ 과 분산 $\text{Var} (X) = E [ ( X - \mu_{X} )^2 ]$ 은 아래의 성질들을 가진다. [1]: $E(X + Y) = E(X) + E(Y)$ [2]: $E(aX + b) = a E(X) + b$ [3]: $\text{Var} (X) \ge 0$ [4]: $\text{Var} ( X ) = E(X^2) - \mu_{X}^2$ [5]: $\text{Var} (aX + b) = a^2 \text{Var} (X)$ 설명 평균과 분산에 관한 것이니만큼 아주 중요한 성질들이다. 특히 [1]과 [2]는 이른바 선형성Linearity이라 불리우는 성질로써, 수식을 다룰 때 무척 편리하게</description>
    </item>
    
    <item>
      <title>프리컴팩트 확률 과정</title>
      <link>https://freshrimpsushi.github.io/posts/precompact-stochastic-process/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/precompact-stochastic-process/</guid>
      <description>정리 가측 공간 $(S, \mathcal{S})$ 에서 $(S&#39;, \mathcal{S}&#39;)$ 로 가는 연속함수들을 모아놓은 함수공간을 $\mathscr{H}:= C \left( S,S&#39; \right)$와 같이 두고 $\left\{ h^{-1}(A&#39;): h \in \mathscr{H} , A&#39; \in \mathcal{S}&#39; \right\}$ 가 $(S , \mathcal{S})$ 의 세퍼레이팅 클래스라고 하자. $X$ 는 $S$ 에서 정의된 확률 원소, $\left\{ X_n \right\}_{n \in \mathbb{N}}$ 은 $S$ 에서 정의된 확률 과정이다. 만약 (i) $\left\{ X_{n} \right\}$ 은 프리 컴팩트다. (ii) 모든 $h \in \mathscr{H}$ 에 대해 $h \left( X_{n} \right) \overset{D}{\to} h(X)$ 면, $X_{n} \overset{D}{\to} X$ 이다. 설명 연속 사상</description>
    </item>
    
    <item>
      <title>대표값의 수리적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mathematical-property-of-representative-value/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mathematical-property-of-representative-value/</guid>
      <description>정리 데이터 $X = \left\{ x_{1} , \cdots , x_{n} \right\}$ 가 주어져 있다고 하자. [0]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{0}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{mode}(X) $$ [1]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{1}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{median}(X) $$ [2]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{2}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{mean}(X) $$ 설명 선형대수의 용어로 어렵게 말해보자면 다음과 같다: [0]: $l^{0}$-놈을 최소화하는 것은 최빈값이다.</description>
    </item>
    
    <item>
      <title>그리디 알고리즘</title>
      <link>https://freshrimpsushi.github.io/posts/greedy-algorithm/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/greedy-algorithm/</guid>
      <description>정의 그리디 알고리즘 이란 어떤 선택을 할 때 그 순간만을 고려해서 가장 좋은 경우를 고르는 방법이다. 설명 그리드 알고리즘은 탐욕Greed이라는 이름대로 길게 보지 않고 그 순간만을 생각한다. 좋게 말하면 항상 최선을 다하는 것이지만, 크게 보았을 때 이는 현명하지 못할 수도 있다. 다음의 예시를 보자: 왼쪽 0에서 시작해 오른쪽 1에 도착하는 경로를 찾는</description>
    </item>
    
    <item>
      <title>수리통계학에서의 기대값, 평균, 분산, 적률의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-mean-variance-moment/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-mean-variance-moment/</guid>
      <description>정의: 기대값, 평균, 분산 확률 변수 $X$ 가 주어져 있다고 하자. 연속 확률 변수 $X$ 의 확률 밀도 함수 $f(x)$ 가 $\displaystyle \int_{-\infty}^{\infty} |x| f(x) dx &amp;lt; \infty$ 를 만족하면 다음과 같이 정의된 $E(X)$ 를 $X$ 의 기대값Expectation이라고 한다. $$ E(X) := \int_{-\infty}^{\infty} x f(x) dx $$ 이산 확률 변수 $X$ 의 확률 질량 함수 $p(x)$ 가 $\displaystyle \sum_{x} |x| p(x) &amp;lt; \infty$ 를 만족하면 다음과 같이 정의된 $E(X)$ 를 $X$ 의 기대값Expectation이라</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 변수와 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution/</link>
      <pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution/</guid>
      <description>정의 1 표본 공간 $\Omega$ 에서 확률 $P$ 가 정의되어 있다고 하자. 정의역이 표본 공간인 함수 $X : \Omega \to \mathbb{R}$ 을 확률 변수Random Variable라고 한다. 확률 변수의 치역 $X(\Omega)$ 을 공간Space이라고도 부른다. 다음을 만족하는 함수 $F_{X} : \mathbb{R} \to [0,1]$ 을 $X$ 의 **누적분포함수(Cummulative Distribution Function, cdf)**라 한다. $$ F_{X}(x) = P_{X}\left( (-\infty,x] \right) = P \left( \left\{ \omega \in \Omega</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution-in-terms-of-measure-theory/</link>
      <pubDate>Sat, 21 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution-in-terms-of-measure-theory/</guid>
      <description>정의 거리 공간 $S$ 의 보렐 시그마 필드 $\mathcal{S}:= \mathcal{B}(S)$ 에 대해 가측 공간 $(S,\mathcal{S})$ 을 정의하자. 확률 공간 $(\Omega, \mathcal{F}, P)$ 에서 정의된 확률 변수 $X$ 와 확률 과정 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 $n \to \infty$ 일 때 모든 $f \in C_{b}(S)$ 에 대해 다음을 만족하면 $\left\{ X_{n} \right\}$ 이 $X$ 로 분포 수렴한다Converge in Distribution고 말하고 $X_{n} \overset{D}{\to} X$ 와 같이 나타낸다. $$ \int_{\Omega} f(X_{n}) dP \to \int_{\Omega} f(X) dP $$ $C_{b}(S)$ 는 다음과 같이 $S$ 에서 정의되는</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률과 확률의 덧셈법칙</title>
      <link>https://freshrimpsushi.github.io/posts/probability-and-additive-law-of-probability/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-and-additive-law-of-probability/</guid>
      <description>정의 1 같은 조건 하에서 반복할 수 있는 시행을 임의 시행Random Experiment이라고 한다. 임의 시행에서 얻을 수 있는 모든 결과Outcome를 모아놓은 집합 $\Omega$ 를 표본 공간Sample Space이라고 한다. 표본 공간에서 우리가 관심을 가지는 결과들의 집합, 즉 $B \subset \Omega$ 를 사건Event이라 하고 이들의 집합을 $\mathcal{B}$ 와 같이 나타낸다.</description>
    </item>
    
    <item>
      <title>확률론의 혼성 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-portmanteau-theorem-in-probability-theory/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-portmanteau-theorem-in-probability-theory/</guid>
      <description>정리 공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자. 다음은 모두 동치다. (1): $P_{n} \overset{W}{\to} P$ (2): 모든 바운디드, 균등연속함수 $f$ 에 대해 $\displaystyle \int_{S} f dP_{n} \to \int_{S}f d P$ (3): 모든 클로즈드 셋 $F$ 에 대해 $\displaystyle \limsup_{n\to\infty} P_{n}(F) \le P(F)$ (4): 모든 오픈 셋 $G$ 에 대해 $\displaystyle P(G) \le \liminf_{n\to\infty} P_{n}(G)$ (5): $P(\partial A) = 0$ 인 모든 $A$ 에 대해 $\displaystyle \lim_{n\to\infty} P_{n}(A) = P(A)$ 설명 Portmanteau는 &amp;lsquo;여러가지로 이루어진&amp;rsq</description>
    </item>
    
    <item>
      <title>확률과정론에서의 프로젝션 매핑</title>
      <link>https://freshrimpsushi.github.io/posts/projection-mapping/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/projection-mapping/</guid>
      <description>정의 공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이고 $k \in \mathbb{N}$ 이라 하자. 이산형 프로젝션 매핑: (이산 시간) $N = \left\{ n \in \mathbb{N}: n \le \xi, \xi \in [0,\infty] \right\}\subset \mathbb{N}$ 과 $S$ 의 $\displaystyle S^{\sup N}:= \prod_{n \in N} S$ 의 원소 $x:= (x_{1} , x_{2} , \cdots )$ 에 대해 다음과 같이 정의된 $\pi_{k}: S^{\sup N} \to S^{k}$ 를 (이산형) 프로젝션 매핑이라 한다. $$ \pi_{k} (x) = (x_{1} , x_{2} , \cdots , x_{k}) $$ 연속형 프로젝션 매핑: (연속 시간) $T \subset [0,\infty]$ 에 대해 $\displaystyle</description>
    </item>
    
    <item>
      <title>폴란드 공간에서 정의되는 확률 측도는 타이트하다</title>
      <link>https://freshrimpsushi.github.io/posts/1428/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1428/</guid>
      <description>정리 거리 공간 $(S,\rho)$ 가 폴란드 공간이라고 하자. $S$ 에서 정의되는 모든 확률 측도는 타이트하다. 설명 폴란드 공간이란 가분 완비인 거리 공간을 말한다. 확률 측도의 타이트함이라는 것을 논할 때 어지간한 확률이 죄다 타이트한 것이 바로 이 때문이다. 물론 이는 거꾸로 말해 더 나아가 폴란드 공간이 아닌 곳에서 정의된 확률들을 연구해야함을 의미하기도 한다. 증명 전</description>
    </item>
    
    <item>
      <title>줄리아에서 벡터를 생성하는 여러가지 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-generate-vector-in-julia/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-generate-vector-in-julia/</guid>
      <description>코드 julia&amp;gt; x1=[1 2 3] 1×3 Array{Int64,2}: 1 2 3 julia&amp;gt; x2=[1, 2, 3] 3-element Array{Int64,1}: 1 2 3 julia&amp;gt; x3=[i for i in 1:3] 3-element Array{Int64,1}: 1 2 3 julia&amp;gt; x4=[i for i in 1:3:10] 4-element Array{Int64,1}: 1 4 7 10 julia&amp;gt; x5=[i for i in 1:3:11] 4-element Array{Int64,1}: 1 4 7 10 x1은 2차원 배열이다. 생겨먹은건 행벡터와 같기 때문에 성분 좌표를 1개만 입력하면 행벡터인 것 처럼 인식한다. x2, x3, x4, x5 는 1차원 배열이다. x=[i for i in n:m]과 같이 입력하면 $n$부터 $m$까지 간격이 $1$</description>
    </item>
    
    <item>
      <title>폴란드 공간</title>
      <link>https://freshrimpsushi.github.io/posts/polish-space/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/polish-space/</guid>
      <description>정의 다음의 조건들을 만족시키는 위상 공간 $X$ 를 폴란드 공간이라 한다. **(i): $X$ 는 거리화 가능 공간이다. **(ii): $X$ 는 가분 공간이다. **(iii): $X$ 는 완비 공간이다. 설명 원어가 Polish Space 인데 순화된 표현이 폴란드 공간 인 것에서 짐작할 수 있듯, 우리가 아는 &amp;lsquo;폴란드&amp;rsquo;에서 따온 말이 맞다. 이 공간이 처음 활발하게 연구한 것이 폴란드 출신의 위상수학</description>
    </item>
    
    <item>
      <title>연속체 가설</title>
      <link>https://freshrimpsushi.github.io/posts/continuum-hypothesis/</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuum-hypothesis/</guid>
      <description>추측 연속체 가설: $\aleph_{0} = |\mathbb{N}|$ 에 대해 $\aleph_{0} &amp;lt; x &amp;lt; 2^{\aleph_{0}}$ 를 만족하는 기수 $x$ 는 존재하지 않는다. 일반 연속체 가설: 초한기수 $a = |A|$ 에 대해 $a &amp;lt; x &amp;lt; 2^{a}$ 를 만족하는 기수 $x$ 는 존재하지 않는다. 설명 칸토어는 대각선 논법과 같은 방법으로 무한이라고 다 같은 무한이 아니라는 것을 증명해보였다. 무한집합이라고 해도 그 기수는 크기가 비교할 수 있으며, 자연수 집합 $\mathbb{N}$ 과 정</description>
    </item>
    
    <item>
      <title>러셀의 역설</title>
      <link>https://freshrimpsushi.github.io/posts/russell-paradox/</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/russell-paradox/</guid>
      <description>역설 1 모든 집합의 집합 $\mathscr{U}$ 가 존재한다면 어떤 집합 $R$ 은 $\mathscr{U}$ 에 속하면서도 속하지 않는다. 설명 기원 전 6세기, 크레타 출신의 철학자 에피메니데스는 이렇게 말했다: &amp;ldquo;모든 크레타 사람은 거짓말쟁이다!&amp;rdquo; 에피메니데스의 주장이 참이라면, 에피메니데스 또한 크레타 사람이므로 이 주장은 거짓이다. 그러나, 이 주장이 거짓이라</description>
    </item>
    
    <item>
      <title>부분순서 집합</title>
      <link>https://freshrimpsushi.github.io/posts/partially-ordered-set/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partially-ordered-set/</guid>
      <description>정의 1 집합 $A$ 에서의 관계 $\le$ 가 반사적, 추이적, 반대칭적이면 부분순서Partial Order이라 하고 $(A,\le)$ 를 반순서 집합이라고 부른다. $A$ 가 반순서 집합이라는 것은 모든 원소 $a,b \in A$ 에 대해 다음을 만족하는 것이다. $$ a \le b \land b \le a \implies a = b $$ 부분순서집합 $(A, \le)$ 가 주어져 있을 때 모든 $a,b \in A$ 에 대해 $a \le b$ 혹은 $b \le a$ 면 $\le$ 를 $A$ 에서의 전순서To</description>
    </item>
    
    <item>
      <title>완전 유계 공간</title>
      <link>https://freshrimpsushi.github.io/posts/totally-bounded-space/</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/totally-bounded-space/</guid>
      <description>정의 1 거리 공간 $(X,d)$ 과 $\varepsilon&amp;gt;0$ 가 주어져 있다고 하자. 모든 $x \in X$ 에 대해 $B_{d}(x,\varepsilon) \cap A_{\varepsilon} \ne \emptyset$ 을 만족하는 유한 집합 $A_{\varepsilon} \subset X$ 를 $X$ 에 대한 $\varepsilon$-그물$\varepsilon$-net이라 한다. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $X$ 에 대한 $\varepsilon$-넷 $A_{\varepsilon}$ 가 존재하면 $X$ 가 완전 유계Totally Bounded라 한다. 설명 완전 유</description>
    </item>
    
    <item>
      <title>타이트 확률 측도</title>
      <link>https://freshrimpsushi.github.io/posts/tight-probability-measure/</link>
      <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tight-probability-measure/</guid>
      <description>정의 공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자. $P$ 가 $S$ 에서 정의된 확률 측도라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $P(K) &amp;gt; 1 - \varepsilon$ 가 되도록하는 컴팩트 셋 $K$ 가 존재하면 $P$ 가 타이트Tight하다고 한다. 설명 일반적으로 학부 수준 이하의 확률에서는 타이트하지 않은 확률은 접하기가 어렵다. 가령 정규분포를 따르는 확률 변수 $X$ 에서 유도된 확률 측</description>
    </item>
    
    <item>
      <title>실수의 기수와 유리수의 기수의 크기 비교</title>
      <link>https://freshrimpsushi.github.io/posts/comparing-the-cardinality-of-real-and-rational/</link>
      <pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/comparing-the-cardinality-of-real-and-rational/</guid>
      <description>정리 1 $\text{card}(\mathbb{Q})={{ \aleph }_{ 0 }}, \text{card}(\mathbb{R})=c$ 에 대해 $$ { 2 }^{ {{ \aleph }_{ 0 }} } =c \\ {{ \aleph }_{ 0 }}&amp;lt;c $$ 설명 칸토어의 대각선 논법을 보면 짐작할 수 있듯, 유리수의 집합보다 실수의 집합이 훨씬 많은 원소를 갖는다. 그 기수는 구체적으로 부등식을 세워서 보일 수 있다. 증명 Part 1. $c \le 2^{\aleph_{0}}$ 함수 $f : \mathbb{R} \to \wp (\mathbb{Q})$ 를 $f(a):={x\in \mathbb{Q}|x&amp;lt;a, a\in \mathbb{R}}$ 와 같이 정의하자.실수의 조밀성 의해 두 실수 $a&amp;lt;b$ 에 대해 $a&amp;lt;r&amp;l</description>
    </item>
    
    <item>
      <title>줄리아에서 패키지 설치하고 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-and-use-packages-in-julia/</link>
      <pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-and-use-packages-in-julia/</guid>
      <description>방법 1 using LinearAlgebra using Pkg Pkg.add(&amp;quot;Plots&amp;quot;) Pkg.add(&amp;quot;Distributions&amp;quot;) using Plots 위의 코드는 LinearAlgebra 패키지와 Pkg 패키지를 불러오며, .add() 함수를 통해 Plots, Distribution 패키지를 설치하는 코드를 나타낸다. 패키지를 불러오는 키워드 using은 마치 수학에서 어떤 정리나 논법을 사용할 때 쓰는 말과 닮았다. 패키지를 설치하는 것 자체는 파이썬보다는 R에 더 가깝고, 사용법은 파이썬과 더 비슷하다. R과 마찬가지로 패키지 이름을</description>
    </item>
    
    <item>
      <title>두 확률 측도가 서로 같아지는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/1415/</link>
      <pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1415/</guid>
      <description>정리 공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자. $\mathcal{O}$ 는 모든 열린 집합들의 집합, $\mathcal{C}$ 는 모든 닫힌 집합들의 집합이고 $P$ 와 $Q$ 는 $(S,\mathcal{B}(S))$ 에서 정의된 확률 측도다. [1]: 모든 열린 집합 $O \in \mathcal{O} \subset S$ 에 대해 $P(O) = Q(O)$ 면 $P=Q$ 다. 다른 표현으로, $\mathcal{O}$ 는 세퍼레이팅 클래스다. [2]: 모든 닫힌 집합 $C \in \mathcal{C} \subset S$ 에 대해 $P(C) = Q(C)$ 면 $P=Q$ 다. 다른 표현으로, $\mathcal{C}$ 는 세퍼레이팅 클래</description>
    </item>
    
    <item>
      <title>R 패키지 설치 시 Warning in installpackages  lib = CProgram FilesRR-361library is not writable 해결</title>
      <link>https://freshrimpsushi.github.io/posts/1414/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1414/</guid>
      <description>개요 R 을 처음 접하는, 그 중에서 프로그래밍은 고사하고 컴퓨터에 익숙하지조차 않지만 당장 R을 사용해야하는 사용자의 눈높이에 맞췄으므로 지나치게 설명이 자세할 수 있다. WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding: https://cran.rstudio.com/bin/windows/Rtools/ 빨리 R 을 써서 뭔가를 해야하는데 위와 같은 경고가 뜨면서 패키지가 설치되지 않는 경우가 종종 있다. 주로 R을 처음 쓰거나</description>
    </item>
    
    <item>
      <title>부분공간위상 상대위상</title>
      <link>https://freshrimpsushi.github.io/posts/subspace-topology-relative-topology/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subspace-topology-relative-topology/</guid>
      <description>정의 1 위상공간 $(X,\mathscr{T})$와 부분집합 $A \subset X$가 주어졌다고 하자. 그러면 아래의 집합 $$ \mathscr{T}_A =\left\{ A\cap U\ :\ U\in \mathscr{T} \right\} $$ 는 $A$상의 위상이다. 이때 $\mathscr{T}_A$를 부분공간위상Subspace Topology혹은 상대위상이라 부른다. 또한 위상공간 $(A, \mathscr{T}_A)$를 $(X,</description>
    </item>
    
    <item>
      <title>칸토어의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cantors-theorem/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cantors-theorem/</guid>
      <description>정리 1 임의의 집합 $X$ 와 그 멱집합 $\mathscr{P} (X)$ 에 대해 $$ \text{card}(X)&amp;lt;\text{card}(\mathscr{P} (X)) $$ 설명 어떤 집합이든 그 기수는 그 멱집합의 기수보다 작다는 말이다. 이미 집합론에서 말하는 무한이라는 개념에 익숙해졌다면 이것은 조금 의외일지도 모르겠다. 자연수의 집합 $\mathbb{N}$ 이 유리수의 집합 $\mathbb{Q}$ 과 일대일 대응이 존재했고, 안타깝게도 $\mathbb{R}$ 과의 일대일 대응은 존재하지 않았다. 이러한 논의들을 생각해볼</description>
    </item>
    
    <item>
      <title>확률론에서의 세퍼레이팅 클래스</title>
      <link>https://freshrimpsushi.github.io/posts/separating-class/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separating-class/</guid>
      <description>정리 가측 공간 $(S, \mathcal{B}(S))$ 에서 정의된 두 확률 $P$, $Q$ 에 대해 다음을 만족하는 $\mathcal{C}$ 를 세퍼레이팅 클래스Separating Class라고 한다. $$ P(A) = Q(A), \forall A \in \mathcal{C} \implies P(A) = Q(A), \forall A \in \mathcal{B}(S) $$ 설명 세퍼레이팅 클래스가 존재한다는 것은 두 측도가 서로 같은지 확인하기 위해서 가측 공간 전체가 아니라 일부만 확인하면 된다는 의미가 된다. 상식적으로 이렇게 좋은 클래스가 그</description>
    </item>
    
    <item>
      <title>칸토어-베른슈타인 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cantor-bernstein-theorem/</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cantor-bernstein-theorem/</guid>
      <description>정리 1 집합 $A$, $B$ 에 대해 $A$ 가 $B$ 의 부분집합과 대등하고 $B$ 가 $A$ 의 부분집합과 대등하면 $A$ 와 $B$ 는 대등하다. 두 집합이 대등하다는 것은 두 집합 사이에 전단사가 존재한다는 것이다. 증명 전략: $x$ 에 함수 $f$ 를 $k$ 번 취하는 것을 $f^{k}(x)$ 와 같이 나타내려고 한다. 그러면 모든 $k \in \mathbb{N}$ 에 대해 $f^{k}(x) = f \left( f^{k-1}(x) \right)$ 처럼 나타낼 수 있을 것이다. 이러한 관점에서 $f^{0}$ 는 함수 $f$ 를 한 번도</description>
    </item>
    
    <item>
      <title>측도의 약한 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/weak-convergence-of-probability-measure/</link>
      <pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weak-convergence-of-probability-measure/</guid>
      <description>정의 공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자. 측도론 $S$ 에서 정의되는 측도 $\mu$ 와 측도의 시퀀스 $\left\{ \mu_n \right\}_{n \in \mathbb{N}}$ 이 $n \to \infty$ 일 때 모든 $f \in C_{b}(S)$ 에 대해 다음을 만족하면 $\left\{ \mu_{n} \right\}$ 이 측도 $\mu$ 로 약하게 수렴한다Converge Weakly고 말하고 $\mu_{n}\overset{W}{\to}\mu$ 와 같이 나타낸다. $$ \int_{S} f d\mu_{n} \to \int_{S} f d\mu $$ 확률론 $S$ 에서 정의되는 확률 $P$ 와 확률의 시퀀스 $\left\{ P_n \right\}_{n \in \mathbb{N}}$</description>
    </item>
    
    <item>
      <title>파이썬에서 numpy array로 행병합 열병합하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-bind-in-row-or-column-numpy-array/</link>
      <pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-bind-in-row-or-column-numpy-array/</guid>
      <description>코드 import numpy as np a = np.array([[1,2,3]]) b = np.array([[4,5,6]]) print(a) print(b) print(np.c_[a,b]) print(np.r_[a,b]) 파이썬의 numpy 패키지는 무척 편리한 기능을 많이 제공한다. 다음의 스크린샷에서 보이다시피 객체 numpy.c_와 numpy.r_는 대괄호 [] 안에 들어간 배열들을 각각 열(column)병합, 행(row)병합한 배열이다. 여기서 이들이 메서드가 아님을 분명히 하고 넘어가자. 마치 메서드처럼 쓰고 있지만</description>
    </item>
    
    <item>
      <title>확률론에서의 레비 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-levys-theorem-in-probability-theory/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-levys-theorem-in-probability-theory/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져있다고 하자. $\eta$ 가 적분 가능한 확률 변수고 $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$ 가 $\mathcal{F}_{n} \subset \mathcal{F}_{n+1}$ 인 시그마 필드의 시퀀스면 $n \to \infty$ 일 때 $$ E \left( \eta | \mathcal{F}_{n} \right) \to E \left( \eta | \mathcal{F}_{\infty} \right) $$ $\displaystyle \mathcal{F}_{\infty} = \bigotimes_{n=1}^{\infty} \mathcal{F}_{n}$ 는 텐서 곱이 아니라 $\mathcal{F}_{n}$ 들의 모든 원소들을 포함하면서 가장 작은 시그마 필드를 의미한다. 그다지 새로울 것은 없는 게, 사실 위상 공간 $\Omega$ 의 모든 열린 집합을 포함하면서 가장</description>
    </item>
    
    <item>
      <title>딘킨의 파이-람다 정리</title>
      <link>https://freshrimpsushi.github.io/posts/dynkins-pi-lambda-theorem/</link>
      <pubDate>Sat, 30 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynkins-pi-lambda-theorem/</guid>
      <description>정리 파이 시스템 $\mathcal{P}$ 가 람다 시스템 $\mathcal{L}$ 의 부분집합이면 $\mathcal{P} \subset \sigma ( \mathcal{P} ) \subset \mathcal{L}$ 을 만족하는 시그마 필드 $\sigma ( \mathcal{P} )$ 가 존재한다. $\sigma ( \mathcal{P} )$ 는 $\mathcal{P}$ 의 모든 원소를 포함하는 가장 작은 시그마 필드를 나타낸다. 설명 스테이트먼트만 보면 아주 간단해보이지만 이러한 정리들이 그러하듯 그 증명은 상당히 길고 복잡하다. 여기서 파이 시스템 $\mathcal{P}$ 와 람다 시스템 $\mathcal{L}$ 의 역할이 무엇일지</description>
    </item>
    
    <item>
      <title>파이썬에서 큰 csv 파일 한번에 읽는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-big-data-csv-file-in-python/</link>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-big-data-csv-file-in-python/</guid>
      <description>코드 y_test=[] y_csv = open(&#39;y_test.csv&#39;, &#39;r&#39;, encoding=&#39;utf-8&#39;) rdr = csv.reader(y_csv) for line in rdr: y_test.append(line[0]) y_csv.close() 보통 csv 파일을 읽어들일 때는 위와 같이 파이썬 내장함수 open으로 열어서 한줄한줄 처리하지만, 반복문을 사용하는 시점에서 빅데이터의 처리에는 적합하지 않음을 짐작할 수 있다. 가령 700MB가 넘는 파일이라면 사실 별로 크지도 않은 편이지만 한줄한줄 읽어서는 끝이 없다. pandas 패키지 이런 데이터를 다룰 때는 pandas</description>
    </item>
    
    <item>
      <title>파이 시스템과 람다 시스템</title>
      <link>https://freshrimpsushi.github.io/posts/pi-system-and-lambda-system/</link>
      <pubDate>Thu, 28 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pi-system-and-lambda-system/</guid>
      <description>정의 다음을 만족하는 $\mathcal{P}$ 을 $\pi$-시스템이라 한다. $$ A, B \in \mathcal{P} \implies A \cap B \in \mathcal{P} $$ 다음의 조건들을 만족하는 $\mathcal{L}$ 을 $\lambda$-시스템이라 한다. (i): $\emptyset \in \mathcal{L}$ (ii): $A \in \mathcal{L} \implies A^{c} \in \mathcal{L}$ (iii): 모든 $i \ne j$ 에 대해 $\displaystyle A_{i} \cap A_{j} = \emptyset$ 일 때, $\displaystyle \left\{ A_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{L} \implies \bigcup_{n \in \mathbb{N}} A_{n} \in \mathcal{L}$ 설명 측도론에서의 시스템System이란 컬렉션 상에서 정의된 일종의 대수구조로 볼</description>
    </item>
    
    <item>
      <title>L1 수렴 마틴게일이면 클로저블 마틴게일이다</title>
      <link>https://freshrimpsushi.github.io/posts/if-convergence-in-l1-martingale-then-closable/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-convergence-in-l1-martingale-then-closable/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 과 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자.확률 과정 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 확률 변수 $Y$ 로 $\mathcal{L}_{1}$하면 $\left\{ ( X_{n} , \mathcal{F}_{n} ): n = 1 , \cdots , \infty \right\}$ 은 클로저블 마틴게일이다. 설명 원래 $X_{n}$ 이 $Y$ 로 $\mathcal{L}_{1}$ 수렴하고 $X_{n}$ 이 $X_{\infty}$ 로 거의 확실히 수렴한다고 해도 $Y$ 와 $X_{\infty}$ 이 어떤 관계가 있다고 장담할 수는 없다. $$ X_{n} \overset{\mathcal{L}_{1}}{\to} Y</description>
    </item>
    
    <item>
      <title>파이썬에서 pip로 cv2 PIL 패키지 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-cv2-pil-package-in-python-using-pip/</link>
      <pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-cv2-pil-package-in-python-using-pip/</guid>
      <description>가이드 openCV 패키지와 PIL 패키지는 이미지 처리에 유용한 패키지다. 문제는 보통 예제 코드에서 두 패키지를 불러들일 때 cv2, PIL라고 하는데 막상 파이썬에서 pip를 이용해서 설치하려고하면 에러를 낸다는 것이다. 이는 파이썬에서 불러들일때의 이름과 설치할 때의 이름이 다르기 때문이다. openCV 스크린샷에서 보이는 것과 같이 openCV를 설치하기 위해서는</description>
    </item>
    
    <item>
      <title>균등적분가능 마틴게일이면 L1 수렴 마틴게일이다</title>
      <link>https://freshrimpsushi.github.io/posts/if-uniformly-integrable-martingale-then-converge-in-l1/</link>
      <pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-uniformly-integrable-martingale-then-converge-in-l1/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져 있다고 하자.확률 과정 $\left\{ X_{n} \right\}$ 이 어떤 확률 변수 $X_{\infty}$ 에 대해 다음을 만족하면 $\left\{ X_{n} \right\}$ 이 $X_{\infty}$ 로 $\mathcal{L}_{p}$ 수렴한다고 말한다. $$ \lim_{n \to \infty} | X_{n} - X_{\infty} |_{p} = 0 $$ 확률 과정 $\left\{ X_{n} \right\}$ 가 $\mathcal{L}_{p}$ 수렴하면 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 $\mathcal{L}_{p}$ 수렴한다고 말한다. 정리 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 균등적분가능이면 $\mathcal{L}_{1}$ 수렴한다. 설명 측도론의 센스로 보았을</description>
    </item>
    
    <item>
      <title>비탈리 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/vitali-convergence-theorem/</link>
      <pubDate>Sun, 24 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vitali-convergence-theorem/</guid>
      <description>정리 1 측도 공간 $( X , \mathcal{E} , \mu)$ 가 주어져 있다고 하자. $1 \le p &amp;lt; \infty$ 라고 할 때 함수의 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{L}^{p}$ 가 $f$ 로 $\mathcal{L}_{p}$ 수렴하는 것은 다음 세 가지를 모두 만족하는 것과 필요충분조건이다. (i): $\left\{ f_{n} \right\}$ 은 $f$ 로 측도 수렴한다. (ii): $\left\{ | f_{n} |^{p} \right\}$ 은 균등적분가능하다. (iii): 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ F \in \mathcal{E} \land F \cap E = \emptyset \implies \int_{F} | f_{n} |^{p} d \mu &amp;lt; \varepsilon^{p} \qquad \forall n \in \mathbb{N} $$ 를 만족하고 $\mu (E) &amp;lt;</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability-in-terms-of-measure-theory/</link>
      <pubDate>Sat, 23 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability-in-terms-of-measure-theory/</guid>
      <description>확률 수렴의 어려운 정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져 있다고 하자. 확률 변수의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 확률 변수 $X$ 로 측도 수렴하면 확률 수렴한다고 말하고 $X_{n} \overset{P}{\to} X$ 와 같이 나타낸다. 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다. 설명 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 $X$ 로 수렴한다는 말은 곧 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ \lim_{n \to \infty} P \left( \left\{ \omega \in \Omega : | X_{n}(\omega) - X(\omega) | \ge \varepsilon</description>
    </item>
    
    <item>
      <title>측도 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-measure/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-measure/</guid>
      <description>정의 1 측도 공간 $( X , \mathcal{E} , \mu)$ 가 주어져 있다고 하자. 가측 함수의 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 어떤 가측 함수 $f$ 와 모든 $M &amp;gt;0$ 에 대해 다음을 만족하면 $f$ 로 측도 수렴한다고 말한다. $$ \lim_{n \to \infty} \mu \left( \left\{ x \in X : | f_{n}(x) - f(x) | \ge M \right\} \right) = 0 $$ 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 모든 $M &amp;gt;0$ 에 대해 다음을 만족하면 측도에서 코시Cauchy in Measure라고 한다. $$ \lim_{n,m \to \infty} \mu \left( \left\{</description>
    </item>
    
    <item>
      <title>집합의 기수</title>
      <link>https://freshrimpsushi.github.io/posts/cardinality-of-set/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cardinality-of-set/</guid>
      <description>정의 1 임의의 집합 $X$ 에 대해 다음의 성질들을 갖는 $\text{card} X$ 를 $X$ 의 기수Cardinality라고 정의한다. (i): $X = \emptyset \iff \text{card} X = 0$ (ii): $A \sim B \iff \text{card} A = \text{card} B$ (iii): 어떤 자연수 $k$ 에 대해 $X \sim \left\{ 1 , 2, \cdots , k \right\}$ 면 $\text{card} X = k$ 특히, 유한집합의 기수를 유한기수라 하고 무한집합의 기수를 초한기수라고 한다. 두 집합 $A$, $B$ 에 대해 $A$ 가 $B$ 의 어떤 부분집합과는 대등하지만</description>
    </item>
    
    <item>
      <title>레귤러 마틴게일이면 균등적분가능 마틴게일이다</title>
      <link>https://freshrimpsushi.github.io/posts/if-regular-martingale-then-uniformly-integrable/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-regular-martingale-then-uniformly-integrable/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져 있다고 하자.확률 변수의 집합 $\Phi$ 가 주어져있다고 할 때, 모든 $\varepsilon&amp;gt;0$ 에 대해 $$ \displaystyle \sup_{ X \in \Phi } \int_{ \left( \left| X \right| \ge k \right) } \left| X \right| dP &amp;lt; \varepsilon $$ 를 만족하는 $k \in \mathbb{N}$ 가 존재하면 $\Phi$ 가 균등적분가능하다고 말한다. 확률 과정 $\left\{ X_{n} \right\}$ 가 균등적분가능하면 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 균등적분가능하다고 말한다. 정리 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} )</description>
    </item>
    
    <item>
      <title>위상공간에서의 내부에 대한 여러 동치 조건들</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-interior/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-interior/</guid>
      <description>정의 1 위상공간 $(X,\mathcal{T})$와 부분공간 $A$가 주어졌다고 하자. $A$에 포함되는 모든 열린집합들의 합집합을 $A$의 내부Interior라고 하고 $A^{\circ}$ 혹은 $\mathrm{int}(A)$로 나타낸다. $$ A^{\circ} = \cup \left\{ U \in \mathcal{T} \ :\ U \subset A\right\} $$ 또한 $x \in X$에 대해서 $x \in U \subset A$를 만족하는 열린집합 $U$가 존재</description>
    </item>
    
    <item>
      <title>균등적분가능성</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-integrablility/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-integrablility/</guid>
      <description>정의 측도 공간 $( X , \mathcal{E} , \mu)$ 가 주어져 있다고 하자. 르벡 적분 가능한 함수의 집합 $\Phi \subset \mathcal{L}^{1}$ 이 주어져있다고 할 때, 모든 $\varepsilon&amp;gt;0$ 에 대해 $$ \displaystyle \mu (E) &amp;lt; \delta \implies \sup_{f \in \Phi} \int_{ E } \left| f \right| d \mu &amp;lt; \varepsilon $$ 를 만족하는 $\delta &amp;gt; 0$ 가 존재하면 $\Phi$ 가 균등적분가능하다고 한다. 설명 균등적분가능성은 균등Uniformly이라는 말이 붙은만큼 셋 개념으로 접근하며, $\Phi$ 에 속한다면 어떤 함</description>
    </item>
    
    <item>
      <title>레귤러 마틴게일과 클로저블 마틴게일</title>
      <link>https://freshrimpsushi.github.io/posts/regular-martingale-and-closable/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regular-martingale-and-closable/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. 만약 어떤 적분가능한 확률 변수 $\eta$ 에 대해 $X_{n} = E ( \eta | \mathcal{F}_{n} )$ 이면 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 을 레귤러 마틴게일이라 한다. 만약 $\left\{ ( X_{n} , \mathcal{F}_{n} ): n = 1 , \cdots , \infty \right\}$ 이 마틴게일이 되도록 하는 어떤 적분가능한 확률 변수 $X_{\infty}$ 이 존재하고 $\mathcal{F}_{\infty}$-가측</description>
    </item>
    
    <item>
      <title>칸토어의 대각선 논법</title>
      <link>https://freshrimpsushi.github.io/posts/cantors-diagonal-argument/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cantors-diagonal-argument/</guid>
      <description>정리 1 열린 구간 $(0,1)$ 은 비가산집합이다. 증명 실수 집합 $\mathbb{R}$ 은 가산 집합이 아닌데, 이것은 실수 집합과 어떤 가산 집합 사이에 &amp;lsquo;일대일 대응&amp;rsquo;이 존재하지 않음을 통해서 보인다. 이는 자연수 집합과 열린 구간 $(0,1)$ 사이에 일대일 대응이 존재하지 않는 것을 보이고, 그 따름정리로써 얻을 수 있다. 칸토어는 이것을 놀라운 방법으로 증명해냈</description>
    </item>
    
    <item>
      <title>가산집합과 비가산집합</title>
      <link>https://freshrimpsushi.github.io/posts/countable-set-and-uncountable-set/</link>
      <pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/countable-set-and-uncountable-set/</guid>
      <description>정의 1 집합 $X$ 가 유한 집합이거나 $X \sim \mathbb{N}$ 면 가산 집합이라 한다. 가산 집합이 아닌 집합을 비가산 집합이라 한다. $\mathbb{N}$ 은 자연수의 집합이다. 설명 가산 집합이라는 개념은 동양인, 물론 한국인에게 받아들이기 쉽지만은 않다. 이는 영어를 비롯한 인도유럽어족의 사고방식과 우리의 마인드가 판이하게 다른 점에서 온다. 알다시피 유럽어는 명사에도 성이 있고 수,</description>
    </item>
    
    <item>
      <title>서브 마틴게일 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-sub-martingale-convergence-theorem/</link>
      <pubDate>Sat, 16 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-sub-martingale-convergence-theorem/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. $\displaystyle \sup_{n \in \mathbb{N}} E X_{n}^{+} &amp;lt; \infty$ 이라고 하면 $X_{n}$ 은 어떤 확률 변수 $X_{\infty}: \Omega \to \mathbb{R}$ 로 거의 확실히 수렴하고 $$E X_{\infty} &amp;lt; E X_{\infty}^{+} &amp;lt; \infty$$ 증명 전략: 리미트 슈프리멈과 리미트 인피멈의 성질을 사용한다. $$ X^{\ast}:= \limsup_{n \in \mathbb{N}} X_{n} \\ X_{\ast}:= \liminf_{n \in \mathbb{N}} X_{n} $$ 이라고 하면 $$ \left( X^{\ast} &amp;gt; X_{\ast} \right) = \bigcup_{a &amp;lt; b \\ a, b \in \mathbb{Q}} \left( X^{\ast} &amp;gt; b &amp;gt; a &amp;gt; X_{\ast} \right) $$ 인</description>
    </item>
    
    <item>
      <title>집합론으로 엄밀하게 정의되는 유한 집합과 무한 집합</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-infinite-set/</link>
      <pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-infinite-set/</guid>
      <description>정의 1 두 집합 $X$ 에 대해 전단사 $f : X \to Y$ 가 존재하면 $X$ 와 $Y$ 가 서로 대등하다Equipotent고 하고 $X \sim Y$ 와 같이 나타낸다. 공집합이 아닌 $X$ 의 어떤 진부분집합 $Y \subsetneq X$ 에 대해 $X \sim Y$ 면 $X$ 를 무한 집합이라 한다. 무한 집합이 아닌 집합을 유한 집합이라 한다. 설명 흔히 집합론을 동원하지 않고 무한을 설명하려고 할 때 대등하다는 표현을 울타리에서 양</description>
    </item>
    
    <item>
      <title>공진리란?</title>
      <link>https://freshrimpsushi.github.io/posts/vacuous-truth/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vacuous-truth/</guid>
      <description>정리 임의의 명제 $p$ 와 모순 $c$ 그리고 $A_{\alpha} \subset X$ 에 대해 다음이 성립한다. [1] 공진리: $c \implies p$ [2] 합집합: $\displaystyle \bigcup_{\alpha \in \emptyset} A_{\alpha} = \emptyset$ [3] 교집합: $\displaystyle \bigcap_{\alpha \in \emptyset} A_{\alpha} = X$ 설명 예를 들어 &amp;ldquo;신은 죽었다.&amp;rdquo; 라는 말에서 신이 존재하지 않는다면, 가정부터 틀려먹었다면 어떻게 되는 걸까? 신이 존재하지 않는다면 $0$ 명의 신이 죽은 것이므로 누가 진짜 죽었나 살</description>
    </item>
    
    <item>
      <title>확률과정론에서의 업크로싱</title>
      <link>https://freshrimpsushi.github.io/posts/upcrossing-in-stochastic-process/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/upcrossing-in-stochastic-process/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자.폐구간 $[a,b]$ 에 대해 $X_{t_{1}} \le a$ 이었다가 $X_{t_{2}} \ge b$ 가 되는 것을 업크로싱이라 한다. $N \in \mathbb{N}$ 번까지 관찰할 때 업크로싱의 횟수를 다음과 같이 나타낸다. $$ \beta_{N} (a,b): = \text{A number of upcrossing of } \left\{ X_{n} \right\} \text{ of interval } [a,b] $$ 기초 성질 [1]: $\chi_{i}$ 는 $\mathcal{F}_{i-1}$-가측 함수다. [2]: $\displaystyle E</description>
    </item>
    
    <item>
      <title>전사, 단사, 공역, 치역을 쉽게 외우는 방법, 뜻풀이</title>
      <link>https://freshrimpsushi.github.io/posts/690/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/690/</guid>
      <description>설명 전사와 단사공역과 치역나는 이 친구들을 처음 만났을 때 이름을 외우기가 너무 힘들었다. &amp;lsquo;이게 단사인가? 전사인가?&amp;rsquo; &amp;lsquo;공역이 더 큰거였나? 뭐지?&amp;rsquo;. 이름을 비슷하게 지어놔서 써먹어야할 때 마다 헷갈렸다. 나 같은 사람이 얼마나 많을지 모르겠다만 몇 없더라도 암기가 안되서 나와 같은 고통</description>
    </item>
    
    <item>
      <title>줄리아의 타입과 애노테이션</title>
      <link>https://freshrimpsushi.github.io/posts/type-and-annotation-in-julia/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/type-and-annotation-in-julia/</guid>
      <description>코드 julia&amp;gt; typeof(0) Int64 julia&amp;gt; typeof(0.0) Float64 julia&amp;gt; typeof(0 == 0.0) Bool julia&amp;gt; typeof(Bool) DataType julia&amp;gt; typeof(NaN) Float64 julia&amp;gt; typeof(Inf) Float64 julia&amp;gt; typeof(&#39;O&#39;) Char julia&amp;gt; typeof(&amp;quot;Ohmygirl&amp;quot;) String julia&amp;gt; typeof(&amp;quot;O&amp;quot;) String 줄리아에는 온갖 타입들이 구현되어있다. $0$ 과 $0.0$ 은 같은 $0$ 이지만 다른 타입을 가지며, 보다시피 타입인 Bool조차 DataType이라는 타입을 갖는다. C 언어처럼 String은 Char의 배열이며, 위와 같이 큰 따옴표인가 작은 따옴표인가로 구분된다. julia&amp;gt; supertype(Int64) Signed julia&amp;gt; supertype(Signed) Integer</description>
    </item>
    
    <item>
      <title>단사, 전사, 전단사, 역함수</title>
      <link>https://freshrimpsushi.github.io/posts/injection-surjection-bijection-inverse-function/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/injection-surjection-bijection-inverse-function/</guid>
      <description>정의 1 $x \in X$ 이고 $y \in Y$ 그리고 $f: X \to Y$ 가 함수라고 하자. 모든 $x_{1}, x_{2} \in X$ 에 대해 $x_{1} \ne x_{2} \implies f(x_{1}) \ne f(x_{2})$ 면 $f$ 를 단사라고 한다. $f(X) = Y$ 면 $f$ 를 전사라고 한다. $f$ 가 단사면서 전사면 전단사라고 한다. $I(x) = x$ 를 만족하는 $I : X \to X$ 를 항등함수Identity Function라고 한다. 모든 $x, y$ 에 대해 $f(x) = y$ 고 $f^{-1} (y) = x$ 를 만족하는 $f^{-1} : Y \to X$ 를 $f$ 의 역</description>
    </item>
    
    <item>
      <title>둡의 최대 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-doobs-maximal-inequality/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-doobs-maximal-inequality/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 마틴 게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. 어떤 $N \in \mathbb{N}$ 과 $p&amp;gt;1$ 에 대해 $X_{n} \ge 0 (n \le N)$, $E X_{N}^{p} &amp;lt; \infty$ 이면 $$ E \left( \max_{n \le N} X_{n}^{p} \right) \le \left( {{ p } \over { p-1 }} \right)^{p} E X_{N}^{p} \text{ a.s.} $$ 설명 수식의 모양은 $\displaystyle \max_{n \le N} \cdot_{n} ^{p}$ 으로 말미암아 생기는 $\displaystyle \left( {{ p } \over { p-1 }} \right)^{p}$ 을 밖으로 빼내고 그 상한을 계산하는 것으로 볼 수 있다. $\displaystyle \left( {{ p } \over { p-1 }} \right)&amp;gt;1$ 이기 때</description>
    </item>
    
    <item>
      <title>줄리아 프로그래밍 언어</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-julia-language/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-julia-language/</guid>
      <description>개요 줄리아 는 MIT에서 개발되어 2012년 공개된 프로그래밍 언어로써, 생산성이 높으면서도 속도가 높은 언어를 지향한다. C나 포트란에 준하는 속도를 내면서도 파이썬이나 R처럼 고수준의 문법을 갖추었으며, 그 외에도 여러 언어들의 장점을 취하고 있다. 2019년 11월 현재는 GPU가 급속도로 발전하면서 딥러닝이 유행을 선도하고 있어 조금</description>
    </item>
    
    <item>
      <title>함수의 원상</title>
      <link>https://freshrimpsushi.github.io/posts/preimage-of-function/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/preimage-of-function/</guid>
      <description>정의 1 함수 $f: X \to Y$ 와 $B \subset Y$ 에 대해 $f^{-1}(B): = \left\{ x \in X \ | \ f(x) \in B \right\}$ 를 $f$ 에 따른 $B$ 의 원상 혹은 역상이라 한다. 설명 표기는 비슷하지만 정의 자체만으로 역상과 역함수가 어떤 관계에 있다고 말할 수는 없으며, 이들을 혼동하지 않아야한다. 한국어로 말하기엔 역상이 자연스러운 반면 영어로는 [프리이미지]가 자연스럽게 느껴지는 사람이 있을 것이다. 이는</description>
    </item>
    
    <item>
      <title>마틴게일의 부등식들</title>
      <link>https://freshrimpsushi.github.io/posts/inequalities-of-martingale/</link>
      <pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inequalities-of-martingale/</guid>
      <description>정리 $\left\{ (X_{n} , \mathcal{F}_{n}) \right\}$ 이 슈퍼 마틴게일이라고 하자. [1]: 모든 $\lambda &amp;gt; 0$ 에 대해 $$ \begin{align*} \lambda P \left( \max_{n \le N} X_{n} \ge \lambda \right) \le&amp;amp; E X_{1} - \int_{(\max_{n \le N} X_{n} &amp;lt; \lambda)} X_{N} dP \\ \le&amp;amp; E X_{1} + E X_{N}^{-} \text{ a.s.} \end{align*} $$ [2]: 모든 $\lambda &amp;gt; 0$ 에 대해 $$ \begin{align*} \lambda P \left( \min_{n \le N} X_{n} \le - \lambda \right) \le&amp;amp; - \int_{(\min_{n \le N} X_{n} \le - \lambda)} X_{N} dP \\ \le&amp;amp; E X_{N}^{-} \text{ a.s.} \end{align*} $$ $\left\{ (X_{n} , \mathcal{F}_{n}) \right\}$ 이 서브 마틴게일이라고 하자. [3]: 모든 $\lambda &amp;gt; 0$ 에 대해 $$ \begin{align*} \lambda P \left( \max_{n \le N} X_{n} \ge \lambda \right) \le&amp;amp; \int_{(\max_{n \le N} X_{n} \ge</description>
    </item>
    
    <item>
      <title>집합론으로 엄밀하게 정의되는 함수와 상, 수열</title>
      <link>https://freshrimpsushi.github.io/posts/function-image-and-sequence/</link>
      <pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/function-image-and-sequence/</guid>
      <description>정의 1 공집합이 아닌 두 집합 $X$, $Y$ 이 주어져 있다고 하자. 이항 관계 $f \subset (X,Y)$ 가 다음을 만족하면 함수라 하고 $f : X \to Y$ 와 같이 나타낸다. $$ (x ,y_{1}) \in f \land (x,y_{2}) \in f \implies y_{1} = y_{2} $$ 함수 $f : X \to Y$ 에 대해 $\text{Dom} (f) = X$ 를 $f$ 의 정의역Domain, $Y$ 를 $f$ 의 공역Codomain이라 한다. 정의역의 부분집합 $A \subset X$ 이 주어져 있을 때, $f(A):= \left\{ f(a) \in Y \ | \ x \in A \right\}$ 를 $f$</description>
    </item>
    
    <item>
      <title>동치관계에 의한 집합의 분할</title>
      <link>https://freshrimpsushi.github.io/posts/partition-by-equivalent-relation/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-by-equivalent-relation/</guid>
      <description>정리 1 집합 $X$ 상의 동치관계 $R$ 에 대해 $X / R$ 은 $X$ 의 분할이다. 설명 이 정리는 별 것 아닌 것 같아 보이지만 위상수학, 추상대수학 등 수학 전반에서 널리 쓰이고 있다.동치관계란 쉽게 말해서 이거나 저거나 &amp;lsquo;같다&amp;rsquo;고 보자는건데, 아이러니하게도 동치관계가 주어짐으로써 ‘같지 않음’이라는 개념이 동반된다. 전체집합은 동치</description>
    </item>
    
    <item>
      <title>프로그래밍에서의 일급 객체</title>
      <link>https://freshrimpsushi.github.io/posts/first-class-object-in-programming/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/first-class-object-in-programming/</guid>
      <description>정의 프로그래밍에서 일급 객체First Class Object는 다음의 조건을 만족하는 요소를 말한다. (i) 함수의 실제 매개변수가 될 수 있다. (ii) 함수의 반환 값이 될 수 있다. (iii) 할당 명령문의 대상이 될 수 있다. (iv) 동일 비교의 대상이 될 수 있다. 예시 쉽게 말해 보통 수처럼 다룰 수 있는 것을 일급 객체라고 하는데, 이는 자명하게도 &amp;lsquo;보통 수&amp;rsq</description>
    </item>
    
    <item>
      <title>k-평균 군집화</title>
      <link>https://freshrimpsushi.github.io/posts/k-means-clustering/</link>
      <pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k-means-clustering/</guid>
      <description>알고리즘 Input $p$ 차원의 데이터 $N$ 개와 자연수 $k$ 가 주어져있다고 하자. Step 1. 초기화 $k$ 개의 점 $\mu_{1} , \cdots , \mu_{k}$ 을 랜덤하게 정한다. 각각의 $\mu_{j}$ 는 군집 $M_{j}$ 의 평균이 될 것이다. Step 2. 거리 계산 $i$ 번째 데이터 $x_{i}$ 와 $j = 1 , \cdots , k$ 에 대해서 $\| x_{i} - \mu_{j} \|$ 를 계산한다. 그 중 가장 작은 것을 골라 $x_{i} \in M_{j}$ 이 되도록 한다. 이를 각각의 $i = 1 , \cdots , N $ 에 대해 반복한다. Step 3. $\mu_{j}$ 업</description>
    </item>
    
    <item>
      <title>동치류</title>
      <link>https://freshrimpsushi.github.io/posts/equivalence-class/</link>
      <pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalence-class/</guid>
      <description>정의 1 집합 $X$ 상에서 동치관계 $R$ 이 정의되어있다고 하자. $x \in X$ 에 대해 $x / R := \left\{ y \in X : y R x \right\}$ 를 $x$ 의 동치류라고 한다. 주어진 $X$ 의 모든 동치류를 모은 집합을 $X / R := \left\{ x / R : x \in X \right\}$ 과 같이 나타낸다. 설명 표현이 조금 더러워 보이지만 예시를 생각해보면 전혀 어려운 개념이 아니다.자연수집합 $\mathbb{N}$ 상에서 $3$ 으로 나눈 나머지가 같으면 동치라</description>
    </item>
    
    <item>
      <title>레벤슈타인 알고리즘</title>
      <link>https://freshrimpsushi.github.io/posts/levensteins-algorithm/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/levensteins-algorithm/</guid>
      <description>알고리즘 Input 문자열 $A,B$ 를 $A=[a_{i}]=(a_{1}, a_{2} , \cdots, a_{n})$ 과 $B=[b_{j}]=(b_{1}, b_{2} , \cdots, b_{m})$ 로 표현하자. Step 1. 초기화 행렬 $M_{(n+1) \times (m+1)} = [m_{x y }]$ 를 만들고 $M_{11} ← 0$ 을 대입한다. 그리고 $1$행과 $1$열을 다음과 같이 채운다. $$ M_{(i+1) 1} ← i \\ M_{ 1 (j+1)} ← j $$ Step 2. 동적 계획법 for $i = 1, 2, \cdots , n$ and $j=1,2, \cdots , m$ if $a_{i}==b_{j}$ $M_{i,j} ← M_{(i-1)(j-1)}$ else $M_{i,j} ← \min \left\{ M_{(i-1)(j)}, M_{(i)(j-1)}, M_{(i-1)(j-1)}\right\} + 1 $ Output $A$, $B$ 의 최소 수정 거리는 $m_{nm}$ 이다. 설명 편집 거리 란 두 문자열</description>
    </item>
    
    <item>
      <title>집합의 분할</title>
      <link>https://freshrimpsushi.github.io/posts/partition-of-set/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-of-set/</guid>
      <description>정의 1 집합 $X$ 의 모든 부분집합 $A,B,C$ 에 대해 다음의 조건을 만족하는 $\mathscr{P}$ 를 $X$ 의 분할이라 한다. (i): $$A,B \subset \mathscr{P} \land A \ne B \implies A \cap B = \emptyset$$ (ii): $$\displaystyle \bigcup_{C \in \mathscr{P} } C = X$$ 설명 수식으로 나타내니까 복잡해 보이지만 간단히 말하자면 그냥 전체집합을 빠짐 없이 여러 조각으로 나누는 것에 불과하다. 수식적인 정의에 매달릴 여유가 있다면 차라리 $X$ 의 분할 $\mathscr{P}$ 가 $X$ 의 멱집합 $2^{X} = \mathscr{P} (X)$ 의 부분</description>
    </item>
    
    <item>
      <title>프로그래밍에서의 타입</title>
      <link>https://freshrimpsushi.github.io/posts/type-in-programming/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/type-in-programming/</guid>
      <description>타입의 탄생 변수를 선언할 때 타입을 지정해야하는 언어를 써본 적이 있다면 거의 확실히 띠꺼움도 함께 느껴봤을 것이다. 어떤 언어들은 굳이 타입이 뭔지 정해주지 않더라도 알아서 계산을 해주는데, 굳이 지저분하고 의미 없어 보이는 코드를 쓰는 것이 시간과 에너지의 낭비처럼 느껴지는 것이다.타입이 없던 시기의 프로그래밍 환경을 상상해보자. 컴퓨터가 이해</description>
    </item>
    
    <item>
      <title>기수 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/radix-sort/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/radix-sort/</guid>
      <description>알고리즘 자리수가 $k$ 로 제한된 $n$ 개의 자연수로 이루어진 데이터가 주어져있다고 하자. 그러면 데이터는 다음의 알고리즘에 따라 정렬되며 그 시간 복잡도는 $O (n)$ 이다. $i = 1 , \cdots , k$ 번째 자리수들끼리 비교해서 정렬한다. 설명 기수 정렬Radix Sort은 자리수의 제한이 있기 때문에 부동소수점이 있는 데이터에 적용할 수는 없으나, 정렬할 때 데이터</description>
    </item>
    
    <item>
      <title>수학에서의 동치관계</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-relation/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-relation/</guid>
      <description>정의 1 반사적이면서 대칭적이면서 추이적인 이항관계를 동치관계라고 한다. 설명 동치관계를 수학적이지 않게 말한다면 &amp;lsquo;그게 그거&amp;rsquo;라는 말이다. 수학을 연구할 때 그 이유가 반드시 필요한 건 아니지만, 만약 수학을 연구하는 실용적인 이유가 반드시 있어야 한다면 그것은 &amp;lsquo;원래 어렵고 복잡한 개념을 쉽고 간단한 영</description>
    </item>
    
    <item>
      <title>수학에서의 이항관계</title>
      <link>https://freshrimpsushi.github.io/posts/binary-relation/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/binary-relation/</guid>
      <description>정의 1 두 집합 $X,Y$ 에 대해 $$ R := \left\{ (x,y): x \in X , y \in Y \right\} \subset X \times Y $$ 를 (이항) 관계라고 정의하고 다음과 같이 나타낸다. $$ (x,y) \in R \iff x R y $$ $x R y \iff y R^{-1} x$ 를 만족하는 $$ R^{-1} : \left\{ (y,x): (a,b) \in R \right\} $$ 을 $R$ 의 역관계Inverse라고 한다. 모든 $x \in X$ 에 대해 다음을 만족하는 $ R \subset X^{2}$ 를 반사적Reflexive이라 한다. $$ x R x $$ 모든 $x,y \in X$ 에 대해</description>
    </item>
    
    <item>
      <title>프로그래밍 패러다임</title>
      <link>https://freshrimpsushi.github.io/posts/programming-paradigm/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/programming-paradigm/</guid>
      <description>정의 프로그래밍 패러다임Programming Paradigm이란 주어진 문제를 해결하는 프로그램을 작성할 때의 관점 내지 방법론을 말한다. 어떠한 패러다임에 알맞는 프로그래밍 언어는 그러한 프로그래밍 패러다임을 갖는다고 말하며, 대개의 언어는 하나의 패러다임을 갖는다. 여러 패러다임을 갖는 언어를 멀티 패러다임 언어라고 한다. 언어가</description>
    </item>
    
    <item>
      <title>집합의 데카르트 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cartesian-product/</link>
      <pubDate>Mon, 04 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cartesian-product/</guid>
      <description>정의 1 임의의 두 대상 $a$, $b$ 에 대해 $(a,b)$ 를 순서쌍Ordered Pair이라 한다. 2. 임의의 두 집합 $A$, $B$ 에 대해 $a \in A$, $b \in B$ 의 순서쌍 $(a,b)$ 의 집합을 $A$, $B$ 의 데카르트 곱Cartesian Product이라 하고 다음과 같이 나타낸다. $$ A \times B := \left\{ (a,b): a \in A \land b \in B \right\} $$ 설명 데카르트 곱에서 &amp;lsquo;곱&amp;rsquo;이라는 표현을 쓰는 이유</description>
    </item>
    
    <item>
      <title>비교 정렬 알고리즘 시간 복잡도의 하한</title>
      <link>https://freshrimpsushi.github.io/posts/lower-bound-of-time-complexity-of-comparison-sort-algorithms/</link>
      <pubDate>Sun, 03 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lower-bound-of-time-complexity-of-comparison-sort-algorithms/</guid>
      <description>정리 비교 정렬 알고리즘의 시간복잡도는 아무리 좋아도 $\Omega ( n \log n )$ 이다. 설명 알고리즘이 원래 신기한 것이지만, 삽입 정렬과 같은 효율적인 알고리즘도 퀵 정렬에 밀리는 것을 보면 그 이상의 알고리즘도 있지 않을까 궁금할 수밖에 없다. 다행인지 아닌지는 모르겠으나, 이 증명에 따라 그보다 효율적인 알고리즘을 생각할 필요는 없다.물론 일반적인 비교 알고</description>
    </item>
    
    <item>
      <title>위상 동형 사상은 기저를 보존함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-homeomorphism-perserve-basis/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-homeomorphism-perserve-basis/</guid>
      <description>정리 두 위상공간 $X$, $Y$와 둘 사이의 위상동형사상 $f$가 주어졌다고 하자. $$ f\ :\ X \rightarrow Y $$ $\mathcal{B}_X$를 $X$의 기저라고 하면 $f(\mathcal{B}_X)$는 $Y$의 기저가 된다. 설명 쉽게 말해, 위상 동형 사상은 기저를 보존한다. 증명 집합 $X$에 대해서 아래의 두 조건을 만족하는 $X$의 부분집합의 컬</description>
    </item>
    
    <item>
      <title>집합족과 첨수</title>
      <link>https://freshrimpsushi.github.io/posts/family-and-index/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/family-and-index/</guid>
      <description>정의 원소가 집합인 집합을 패밀리Family라고 한다. 패밀리의 원소를 멤버Member라고 한다. 하나의 집합 $\Gamma$ 의 각 $\gamma \in \Gamma$ 에 집합 $A_{\gamma}$ 가 대응할 때 $\gamma$ 를 인덱스, $\Gamma$ 를 인덱스 집합, $\left\{ A_{\gamma} : \gamma \in \Gamma \right\}$ 를 인덱스 패밀리라고 한다. 설명 패밀리는 본디 &amp;lsquo;집합족&amp;rsquo;으로 순화하도록 되어있으나, 이러한 표현은 &amp;lsquo;집</description>
    </item>
    
    <item>
      <title>비교 정렬 알고리즘들의 시간 복잡도</title>
      <link>https://freshrimpsushi.github.io/posts/time-complexity-of-comparison-sort-algorithms/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-complexity-of-comparison-sort-algorithms/</guid>
      <description>정리 $n$ 개의 데이터가 주어져 있을 때, 비교 정렬 알고리즘들의 시간 복잡도는 다음과 같다. [1] 버블 정렬: $$ \Theta ( n^2 ) \\ O ( n^2 ) $$ [2] 선택 정렬: $$ \Theta ( n^2 ) \\ O ( n^2 ) $$ [3] 삽입 정렬: $$ \Theta ( n^2 ) \\ O ( n^2 ) $$ [4] 힙 정렬: $$ \Theta ( n \log n ) \\ O ( n \log n ) $$ [5] 합병 정렬: $$ \Theta ( n \log n ) \\ O ( n \log n ) $$ [6] 퀵 정렬: $$ \Theta ( n \log n ) \\ O ( n^2 ) $$ 설명</description>
    </item>
    
    <item>
      <title>선택 공리가 추가된 체르멜로-프렝켈 집합론</title>
      <link>https://freshrimpsushi.github.io/posts/zermelo-fraenkel-set-theory-with-the-axiom-of-choice-included/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zermelo-fraenkel-set-theory-with-the-axiom-of-choice-included/</guid>
      <description>체르멜로 공리계 [1] 외연 공리: $$ \forall A \forall B ( \forall x ( x \in A \iff x \in B) ) $$ 임의의 두 집합 $A$, $B$ 에 속한 원소가 같으면 두 집합이 같다고 하고 $A = B$ 와 같이 나타낸다. [2] 공집합 공리: $$ \exists X \forall x \left( \lnot \left( x \in X \right) \right) $$ 어떤 원소도 가지지 않는 집합 $X$ 가 존재하고, 이 집합 $X$ 를 공집합이라고 정의한다. [3] 짝 공리: $$ \forall A \forall B \exists U ( a \in A \land b \in B ) $$ 임의의 두</description>
    </item>
    
    <item>
      <title>위상수학에서 좌표계란</title>
      <link>https://freshrimpsushi.github.io/posts/coordinate-chart/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coordinate-chart/</guid>
      <description>정의 $M$을 $n$차원 다양체라고 하자. 두 열린 집합 $U\subset M$, $\tilde{U} \subset \mathbb{R}^n$와 위상동형사상 $\phi\ :\ U \rightarrow \tilde{U}$가 주어졌다고 하자. 그러면 순서쌍 $(U, \phi)$를 $M$ 위의 좌표계 혹은 간단하게 **좌표$(\mathrm{Chart})$**라고 한다. 설명 만약 $p \in U$, $\phi (p)=0$이면, $(U,\ph</description>
    </item>
    
    <item>
      <title>선택적 샘플링 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-optional-sampling-theorem/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-optional-sampling-theorem/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 슈퍼 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. $\tau$ 와 $\sigma$ 가 $\sigma \le \tau$ 면서 $\mathcal{F}_{n}$ 에 대해 바운디드 정지 시간이라고하면 $$ E \left( X_{\tau} | \mathcal{F}_{\sigma} \right) \le X_{\sigma} \text{ a.s.} $$ $\tau$ 가 $\mathcal{F}_{n}$ 에 대해 바운디드라는 것은 말 그대로 모든 $E \in \mathcal{F}_{n}$ 에 대해 $\tau(E) \le N$ 를 만족하는 $N \in \mathbb{N}$ 이 존재한다는 것이다. 설명 수식 자체가 말해주는 것은 $\sigma \le \tau \le N$ 이라는 조건이 있을 때 슈퍼</description>
    </item>
    
    <item>
      <title>선택 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-choice/</link>
      <pubDate>Tue, 29 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-choice/</guid>
      <description>공리 1 $$ \forall U \left( \emptyset \notin U \implies \exists f : U \to \bigcup_{X \in U \\ f(X) \in X } U \right) $$ 모든 공집합이 아닌 집합들의 집합 $U$ 에 대해 $U$ 의 모든 원소로부터 원소 하나씩을 선택하는 선택 함수 $f$ 가 존재한다. 설명 선택 공리는 가령 다음과 같은 집합의 집합 $U$ 가 있을 때, 그 원소인 집합에서 원소 하나을 뽑는 함수 $f$ 가 존재함을 보장해준다. 가령 다음의 예를 생각해보자: $$ U = \left\{ \left\{ \pi , 1/2</description>
    </item>
    
    <item>
      <title>정지 시간의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-stopping-time/</link>
      <pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-stopping-time/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 마틴 게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. 정지 시간 $\tau$ 에 대해 $\mathcal{F}_{\tau}:= \left\{ A \in \mathcal{F}: A \cap ( \tau = n ) \in \mathcal{F}_{n} \right\}$ 을 $\tau$ 에 의해 유도된 시그마 필드라 한다. [1]: $\mathcal{F}_{\tau}$ 는 시그마 필드다. [2]: $\tau$ 는 $\mathcal{F}_{\tau}$-가측 함수다. [3]: 마틴 게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 에 대해 $X_{\tau}$ 는 $\mathcal{F}_{\tau}</description>
    </item>
    
    <item>
      <title>치환 공리꼴</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-schema-of-replacement/</link>
      <pubDate>Sun, 27 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-schema-of-replacement/</guid>
      <description>공리 $$ \forall X \left( \forall x \in X \exists ! y \left( p(x,y) \right) \implies \exists Y \forall x \in X \exists y \in Y \left( p(x,y) \right) \right) $$ 모든 함수에 대한 치역이 존재한다. 기호 $\exists !$ 는 유일하게 존재함을 의미한다. 여기서 $p(x,y)$ 는 $X \times Y$ 에서의 명제함수다. 명제함수 $p(x,y)$ 는 물론 함수지만 엄밀하게 말해 아직 함수로써 정의된 것은 아니며, 설령 함수로 정의되었다고 할지라도 위 공리에서 말하는 함수 그 자체는 아니다. 논리</description>
    </item>
    
    <item>
      <title>확률과정론에서의 정지 시간</title>
      <link>https://freshrimpsushi.github.io/posts/stopping-time/</link>
      <pubDate>Sat, 26 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stopping-time/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.필트레이션 $\left\{ \mathcal{F}_{n} \right\}$ 에 대해 $0$ 보다 크거나 같은 정수 값을 갖는 확률 변수 $\tau$ 가 모든 $n \in \mathbb{N}_{0}$ 에 대해 $(\tau = n) \in \mathcal{F}_{n}$ 을 만족하면 $\tau$ 를 정지 시간Stopping Time이라고 한다. 보렐 셋 $B \in \mathcal{B}(\mathbb{R})$ 에 대해 $(\tau \in B) = \tau^{-1} (B)$ 로써, $(\tau = n)$ 은 $\tau^{-1} ( \left\{ n \right\} )$ 과 같다. 예시 정지 시간의 직관적인 개념은 관심 있는 사건이 일어</description>
    </item>
    
    <item>
      <title>정칙성 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-regularity/</link>
      <pubDate>Fri, 25 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-regularity/</guid>
      <description>공리 $$ \forall X \left( \exists x_{0} ( x_{0} \in X ) \implies \exists y ( y \in X \land \lnot \exists x ( x \in y \land x \in X )) \right) $$ 모든 집합 $X \ne \emptyset$ 은 자기 자신과 서로소인 원소를 가진다. 설명 정칙성 공리에 따라 스스로를 원소로 포함하는 재귀 집합, 예컨대 $X = \left\{ X \right\}$ 와 같은 집합은 존재할 수 없다. 자기 자신과 서로소가 되기 위해서는 적어도 자기 자신은 아니어야하기 때문이다. 정칙성 공리는 공집합이</description>
    </item>
    
    <item>
      <title>Lp 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-lp/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-lp/</guid>
      <description>정의 1 함수의 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 어떤 함수 $f$ 에 대해 다음을 만족하면 $\left\{ f_{n} \right\}$ 이 $f$ 로 $L^{p}$ 수렴한다고 말한다. $$ \lim_{n \to \infty} \left\| f_{n} - f \right\|^{p} = 0 $$ 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 다음을 만족하면 $L^{p}$ 에서 코시Cauchy in $L^{p}$라 한다. $$ \lim_{n, m \to \infty} \left\| f_{n} - f_{m} \right\|_{p} = 0 $$ 설명 물론 $\left\| \cdot \right\|_{p}$ 는 $p$-놈으로써 다음과 같이 정의된다. $$ \left\| f \right\|_{p} := \left( \int_{E} | f |^{p} dm \right) ^{{{1} \over</description>
    </item>
    
    <item>
      <title>마틴게일의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-martingales/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-martingales/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. $\mathcal{F}$ 의 서브 시그마 필드의 시퀀스 $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$ 이 다음을 만족하면 필트레이션Filtration이라 부른다. $$ \forall n \in \mathbb{N}, \mathcal{F}_{n} \subset \mathcal{F}_{n+1} $$ 필트레이션 $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$ 이 주어져 있을 때 르벡 적분 가능한 $\mathcal{F}_{n}$-가측 확률 변수 $X_{n}$ 의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 가 이루는 순서쌍의 시퀀스 $\left\{ (X_{n}, \mathcal{F}_{n})</description>
    </item>
    
    <item>
      <title>무한 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-infinity/</link>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-infinity/</guid>
      <description>공리 $$ \exists U \left( \emptyset \in U \land \forall X ( X \in U \implies S(X) \in U) \right) $$ 공집합과 $X$ 를 원소로 가지면 $S(X)$ 도 원소로 가지는 집합 $U$ 가 존재한다. 집합 $X$ 에 대해 $S(X)$ 는 $S(X):= X \cup \left\{ X \right\}$ 와 같이 정의되는 집합이다. 설명 이것이 왜 무한 공리인지를 구구절절 설명하는 것보다 자연수 집합 $\mathbb{N}$ 의 존재성 증명을 한 번 보는 게 낫다. 정리: 자연수 집합의 존재성 $\mathbb{N}$ 이 존재한다. 증명 전략: 폰 노이만</description>
    </item>
    
    <item>
      <title>국소 적분가능한 함수의 평균값은 중심의 함숫값으로 수렴한다</title>
      <link>https://freshrimpsushi.github.io/posts/the-average-of-a-locally-integrable-function-converges-to-the-value-of-the-center/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-average-of-a-locally-integrable-function-converges-to-the-value-of-the-center/</guid>
      <description>정리 $f \in L^1_{\mathrm{loc}}$이라고 하자. 그러면 다음이 성립한다. $$ \lim \limits_{r \rightarrow 0} A_r f(x)=f(x) \ \mathrm{a.e.}\ x\in \mathbb{R}^n $$ 설명 국소 적분가능한 함수의 볼 $B(r,x)$위에서의 평균값의 반지름이 $0$으로 가는 극한은 볼 중심의 함숫값과 같다는 말이다. 증명 볼의 반지름이 $0$으로 가는 극한을 취하기 때문에, 어떤 $N \in \mathbb{N}$</description>
    </item>
    
    <item>
      <title>맥시멀 정리</title>
      <link>https://freshrimpsushi.github.io/posts/the-maximal-theorem/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-maximal-theorem/</guid>
      <description>정리1 모든 $f \in L^1_{\mathrm{loc}}$와 모든 $\alpha &amp;gt;0$에 대해서 아래의 조건을 만족하는 상수 $C&amp;gt;0$가 존재한다. $$ \mu \big( \left\{ x\ :\ Hf(x)&amp;gt;\alpha \right\}\big) \le \frac{C}{\alpha} \int |f(y)| dy $$ 위 부등식을 하디-리틀우드 맥시멀 부등식the Hardy-Littlewood maximal inequality이라 한다. 하디-리틀우드 맥시멀 함수 $$ Hf (x) = \sup \limits_{r&amp;gt;0} A_r |f|(x) = \sup \limits_{r&amp;gt;0} \frac{1}{\mu \big( B(r,x) \big)}\int_{B(r,x)}|f(y)|dy $$ 증명 $E_\alpha =\left\{</description>
    </item>
    
    <item>
      <title>조건부 옌센 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conditional-jensens-inequality/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conditional-jensens-inequality/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G} \subset \mathcal{F}$ 가 주어져있다고 하고 $X$ 가 확률 변수라고 하자. 컨벡스 함수 $\phi : \mathbb{R} \to \mathbb{R}$ 와 $\phi (X) \in \mathcal{L}^{1} ( \Omega ) $에 대해 $$ \phi \left( E \left( X | \mathcal{G} \right) \right) \le E \left( \phi (X) | \mathcal{G} \right) $$ $\phi$ 가 컨벡스라는 것은 모든 $x,y \in \mathbb{R}$ 와 $\alpha \in [0,1]$ 에 대해 다음을 만족하는 함수라는 것이다. $$ \phi( \alpha x + (1 - \alpha ) y ) \le \alpha \phi (x) + (1 - \alpha ) \phi (y) $$ $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시</description>
    </item>
    
    <item>
      <title>맥시멀 보조정리</title>
      <link>https://freshrimpsushi.github.io/posts/the-maximal-lemma/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-maximal-lemma/</guid>
      <description>정리1 $\mathcal{B}$를 $\mathbb{R}^n$에서의 오픈 볼들의 컬렉션이라고 하자. $U=\bigcup \limits_ { B\in \mathcal{B}} B$라고 하자. 그러면 어떤 상수 $c &amp;lt;m (U)$에 대해서, 아래의 조건을 만족하는 유한개의 서로소인 $B_j \in \mathcal{B}$가 존재한다. $$ \sum \limits_ {j=1}^k \mu (B_j) &amp;gt;3^{-n} c $$ 이때 $m$은 $n$차원 르벡 측도이다. 증명 우선 $c&amp;lt; m (K)</description>
    </item>
    
    <item>
      <title>멱집합 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-power-set/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-power-set/</guid>
      <description>공리 1 $$ \forall X \exists P \forall A ( A \subset X \implies A \in P) $$ 임의의 집합 $X$ 에 대해 $X$ 의 모든 부분집합을 원소로 갖는 집합 $P$ 가 존재한다. 설명 $X$ 의 멱집합은 일반적으로 $\mathcal{P} (X)$ 와 같이 표기하거나 $2^{X}$ 와 같이 쓰는데, 그 이유는 유한 집합 $X$ 의 원소의 개수를 $|X|$ 이라고 하면 $P(X)=2^{|X|}$ 이기 때문이다. 꼭 개수가 중요한 것은 아니기 때문에 집합론을 많이 쓰면 많이 쓰는 분과일수록 $2^{X}$ 와 같은 표현</description>
    </item>
    
    <item>
      <title>하디-리틀우드 맥시멀 함수</title>
      <link>https://freshrimpsushi.github.io/posts/hardy-littlewood-maximal-function/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hardy-littlewood-maximal-function/</guid>
      <description>정의1 $ f \in L^1_{\mathrm{loc}}$라고 하자. 그러면 하디-리틀우드 맥시멀 함수 $Hf$를 아래와 같이 정의한다. $$ Hf (x) := \sup \limits_{r&amp;gt;0} A_r |f|(x) = \sup \limits_{r&amp;gt;0} \frac{1}{\mu \big( B(r,x) \big)}\int_{B(r,x)}|f(y)|dy $$ $A_rf(x)$는 $B_{r}(x)$위에서 $f$의 함숫값의 평균을 의미한다. $H$를 맥시멀 오퍼레이터maximal operator라고 한다. 정리 $</description>
    </item>
    
    <item>
      <title>합집합 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-union/</link>
      <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-union/</guid>
      <description>공리 $$ \forall X \left( \exists U \left( \forall a \left( a \in x \land x \in X \implies a \in U \right) \right) \right) $$ 임의의 집합 $X$ 에 대해 $X$ 모든 원소들의 원소들을 포함하는 집합 $U$ 가 존재한다. 합집합의 정의 1 합집합 공리는 다음과 같이 정의되는 합집합의 존재성을 보장한다. $$ x \in A \lor x \in B \iff x \in A \cup B $$ 임의의 두 집합 $A$, $B$ 에 대해 적어도 둘 중 하나에 속하는 원소들의 집합을 $A$ 와 $B$ 의 합집합이라 하고</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 조건부 분산</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-variance-in-terms-of-measure-theory/</link>
      <pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-variance-in-terms-of-measure-theory/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G} \subset \mathcal{F}$ 가 주어져있다고 하고 $X$, $Y$ 가 확률 변수라고 하자. 다음과 같이 정의된 $\text{Var}$ 를 $\mathcal{G}$ 가 주어졌을 때 $X$ 의 분산이라고 한다. $$ \text{Var} ( X | \mathcal{G}) := E \left[ (X - E(X | \mathcal{G}))^2 | \mathcal{G} \right] $$ $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드라는 것은 둘 다 $\Omega$ 의 시그마 필드이되, $\mathcal{G} \subset \mathcal{F}$ 임을 의미한다. 정리 [1]: $\text{Var}( X |\mathcal{G}) = E(X^2 | \mathcal{G}) - \left[ E(X | \mathcal{G}) \right]^2$ [2]: $\text{Var}(X) = E \left( \text{Var}(X | \mathcal{G})</description>
    </item>
    
    <item>
      <title>분류 공리꼴</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-schema-of-specification/</link>
      <pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-schema-of-specification/</guid>
      <description>공리 1 $$ \forall X \exists A \forall a \left( a \in A \iff ( a \in X \land p(a)) \right) $$ 임의의 집합 $X$ 에 대해 성질 $p$ 를 가지는 원소들로 이루어진 부분집합 $A$ 가 존재한다. $p(x)$ 는 $X$ 에서의 명제함수다. 설명 $A$ 를 $X$ 의 부분집합으로 한정하는 이유는 러셀의 역설과 같은 문제가 일어나는 것을 방지하기 위함이다.공리가 아니라 공리꼴인 이유는 이 공리가 무수히 많은 $p(x)$ 에 따라 무수히 많이 존재하기</description>
    </item>
    
    <item>
      <title>수학에서의 포화 파이버</title>
      <link>https://freshrimpsushi.github.io/posts/saturation-fiber/</link>
      <pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/saturation-fiber/</guid>
      <description>정의 두 집합 $X$, $Y$와 함수 $\pi\ :\ X\rightarrow Y$가 주어졌다고 하자. 만약 $\pi^{-1}\big( \pi(u) \big)=u$ 가 성립하면, $u\subset X$를 포화Saturation라고 한다. 집합 $\pi^{-1}(y) \subset X$를 점 $y\in Y$위의 $\pi$의 파이버Fiber 혹은 올이라고 한다. 설명 포화 $\pi^{-1}$는 프리이미지이다. 글로만 보면 어떤 의미인지 감을 잡기 어려울 수 있다. $u$는 항상 $\pi^{-1} \big( \pi(u) \b</description>
    </item>
    
    <item>
      <title>분리합집합 위상 공간</title>
      <link>https://freshrimpsushi.github.io/posts/disjoint-union-topological-space/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/disjoint-union-topological-space/</guid>
      <description>정의 $\left\{ X_\alpha \right\}_{\alpha \in A}$를 임의의 위상 공간 인덱스 패밀리라고 하자. $u \subset \bigsqcup \limits_{\alpha \in A} X_\alpha$라고 하자. 그러면 모든 $\alpha \in A$에 대해서 $u \cap X_\alpha$가 $ X_\alpha$에서 열린 집합일 때, $u$가 $\bigsqcup \limits_{\alpha \in A} X_\alpha$에서 열린 집합$^{\ast}$이라고 한다. 이때 마지막에서 말하는 오픈$^{\ast}</description>
    </item>
    
    <item>
      <title>분리합집합: 서로소인 합집합</title>
      <link>https://freshrimpsushi.github.io/posts/disjoint-union/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/disjoint-union/</guid>
      <description>정의 서로소인 합집합, 분리합집합 $\left\{ X_\alpha \right\} _{\alpha\in A}$를 임의의 인덱스 패밀리라고 하자. 그러면 $\left\{ X_\alpha\right\}$의 분리합집합을 아래와 같이 정의한다. $$ \bigsqcup \limits_{\alpha \in A} X_\alpha := \left\{ (x,\alpha)\ |\ x\in X_\alpha,\ \alpha \in A \right\} $$ 설명 $\bigsqcup$ 대신에 $\amalg$, $\biguplus$등을 쓰기도 한다. $\amalg$는 대문자 파이 $\Pi$가 아님에 주의하자. $\Pi</description>
    </item>
    
    <item>
      <title>조건부 기대값의 스무딩 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/smoothing-properties-of-conditional-expectation/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/smoothing-properties-of-conditional-expectation/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G}, \mathcal{G}&#39; \subset \mathcal{F}$ 가 주어져있다고 하고 $X$, $Y$ 가 확률 변수라고 하자. [1]: $X$ 가 $\mathcal{G}$-가측이면 $$ E(XY | \mathcal{G}) = X E (Y | \mathcal{G}) \text{ a.s.} $$ [2]: $\mathcal{G}&#39; \subset \mathcal{G}$ 이면 $$ \begin{align*} E (X | \mathcal{G}&#39;) =&amp;amp; E \left( E ( X | \mathcal{G}) | \mathcal{G}&#39; \right) \\ =&amp;amp; E \left( E ( X | \mathcal{G}&#39;) | \mathcal{G} \right) \end{align*} $$ $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드라는 것은 둘 다 $\Omega$ 의 시그마 필드이되, $\mathcal{G} \subset \mathcal{F}$ 임을 의미</description>
    </item>
    
    <item>
      <title>짝 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-pair/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-pair/</guid>
      <description>공리 $$ \forall A \forall B \exists U ( a \in A \land b \in B ) $$ 임의의 두 집합 $A$, $B$ 에 대해 $A$ 와 $B$ 를 원소로 가지는 집합 $U$ 가 존재한다. 설명 처음으로 짝 공리를 접하면 (사실 대부분의 공리를 접할 때는 거의 다 비슷하지만) 도대체 이런 공리가 왜 필요한지 의문이 들 수가 있다. 그런데 사실 짝 공리란 진정으로 집합이라는 개념을 수학의 영역으로 끌어올리는 역할을 한다고 말할 수 있</description>
    </item>
    
    <item>
      <title>조건부 확률의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-conditional-probability/</link>
      <pubDate>Mon, 14 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-conditional-probability/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G} \subset \mathcal{F}$ 가 주어져있다고 하자. [1] 모든 $B \in \mathcal{G}$ 에 대해 $0 \le P(B | \mathcal{G}) \le 1$ [2] 확률의 연속성: 네스티드 시퀀스 $\left\{ B_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{G}$ 에 대해 $$ \lim_{n \to \infty} B_{n} = B \implies P ( B_{n} | \mathcal{G} ) \to P ( B | \mathcal{G} ) \text{ a.s.} $$ [3] $\left\{ B_{n} \right\}_{n \in \mathbb{N}}$ 가 $\Omega$ 의 파티션이면 $$ P \left( \bigsqcup_{n \in \mathbb{N}} B_{n} | \mathcal{G} \right)= \sum_{n \in \mathbb{N}} P \left( B_{n} | \mathcal{G} \right) $$ 사건의 시퀀스 $\left\{ B_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{G}$ 가 네스티드</description>
    </item>
    
    <item>
      <title>공집합 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-empty-set/</link>
      <pubDate>Sun, 13 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-empty-set/</guid>
      <description>공리 1 $$ \exists X \forall x \left( \lnot \left( x \in X \right) \right) $$ 어떤 원소도 가지지 않는 집합 $X$ 가 존재하고, 이 집합 $X$ 를 공집합이라고 정의한다. 설명 공집합은 일반적으로 $\emptyset$ 과 같이 표기한다. 한편 공집합은 공집합은 원소의 개수가 $0$ 개인 집합으로도 볼 수 있는데, 이와 같이 원소의 개수로 정의할 수 있는 집합에는 다음과 같은 것들이 있다: Singletone Set: 원소의 개수가 단 하나인 집합을 홑원</description>
    </item>
    
    <item>
      <title>조건부 지배 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conditional-dominated-convergence-theorem/</link>
      <pubDate>Sat, 12 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conditional-dominated-convergence-theorem/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 확률 변수의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 모든 $n \in \mathbb{N}$ 과 어떤 $Y \in \mathcal{L}^{1} (\Omega)$ 에 대해 $| X_{n} | \le Y$ 라고 하면 $$ X_{n} \to X \text{ a.s.} \implies E( X_{n} | \mathcal{G} ) \to \mathcal{G} ) \text{ a.s.} $$ 설명 조건부 지배 수렴 정리는 단지 DCT가 조건부 기대값에 대해서도 똑같이 적용된다는 것을 말해준다. 물론 확률론에서의 역할도 DCT와 같다. 증명 조건부 기대값의 성</description>
    </item>
    
    <item>
      <title>복소 측도 벡터 측도</title>
      <link>https://freshrimpsushi.github.io/posts/complex-measure-vector-measure/</link>
      <pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complex-measure-vector-measure/</guid>
      <description>정의1 $(X,\mathcal{E})$를 가측공간이라고 하자. 아래의 조건을 만족하는 함수 $\nu : \mathcal{E} \to \mathbb{C}$를 $(X,\mathcal{E})$ 위의 복소 측도complex measure 혹은 벡터 측도vector measure라고 한다. (a) $\nu (\varnothing) = 0$ (b) 서로소인 $E_j \in \mathcal{E}$에 대해서, $$ \nu \left( \bigcup \limits_{j=1}^\infty E_j \right) = \sum \limits_1 ^\infty \nu(E_j) $$ 설명 (b) 는 가산가법성을</description>
    </item>
    
    <item>
      <title>외연 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-extensionality/</link>
      <pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-extensionality/</guid>
      <description>공리 1 $$ \forall A \forall B ( \forall x ( x \in A \iff x \in B) ) $$ 임의의 두 집합 $A$, $B$ 에 속한 원소가 같으면 두 집합이 같다고 하고 $A = B$ 와 같이 나타낸다. 설명 한편 $A$ 와 $B$ 가 같지 않으면 $A \ne B$ 와 같이 나타낸다. 두 집합의 같음은 그 자체로 공리이자 정의다. Extensionality는 확장이 아니라 외연外延을 의미하는 것으로, 집합은 &amp;lsquo;어떠한 집합</description>
    </item>
    
    <item>
      <title>조건부 단조 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conditional-monotone-convergence-theorem/</link>
      <pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conditional-monotone-convergence-theorem/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 확률 변수의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 과 $X \in \mathcal{L}^{1} (\Omega)$에 대해 $$ X_{1} \le X_{2} \le \cdots \le X \\ X_{n} \to X \text{ a.s.} $$ 이면 $$ \lim_{n \to \infty} E( X_{n} | \mathcal{G} ) = E( \lim_{n \to \infty} X_{n} | \mathcal{G} ) \text{ a.s.} $$ 설명 조건부 단조 수렴 정리는 단지 MCT가 조건부 기대값에 대해서도 똑같이 적용된다는 것을 말해준다. 물론 확률론에서의 역할도 MCT와 같다</description>
    </item>
    
    <item>
      <title>대수, 준측도</title>
      <link>https://freshrimpsushi.github.io/posts/algebra-and-premeasure/</link>
      <pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebra-and-premeasure/</guid>
      <description>정의 집합 $X \ne \varnothing$의 부분 집합들의 컬렉션 $\mathcal{A}$가 아래의 세 조건을 만족할 때 집합 $\mathcal{A}$를 $X$ 위의 집합들의 대수algebra of sets on X 라고 한다. (a) $E_1$, $\cdots$, $E_n\in \mathcal{A}$이면, $\bigcup \nolimits_1^n E_n \in \mathcal{A}$이다. (b) $E_1$, $\cdots$, $E_n\in \mathcal{A}$이면</description>
    </item>
    
    <item>
      <title>집합의 포함관계</title>
      <link>https://freshrimpsushi.github.io/posts/subset-relation-of-sets/</link>
      <pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subset-relation-of-sets/</guid>
      <description>정의 1 $$ A \subset B \iff \forall x (x\in A \implies x \in B) $$ 임의의 집합 $A$, $B$ 에 대하여 $A$ 의 모든 원소가 $B$ 의 원소일 때 $A$ 는 $B$ 의 부분집합Subset, $B$ 는 $A$ 의 초집합Superset이라 하고 $A \subset B$ 와 같이 나타낸다. 설명 한편 $A \subset B$ 인데 $B \not\subset A$ 이면 $A$ 를 $B$ 의 진부분집합Proper Subset이라고하고 $A \subsetneq B$ 와 같이 나타낸다.사소한 주의사항으로, $A \subset B$</description>
    </item>
    
    <item>
      <title>매트랩에서 등간격의 행벡터를 생성하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/linspace-in-matlab/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linspace-in-matlab/</guid>
      <description>방법 linspace(a,b,n): 구간 $[a,b]$를 $n$개의 등간격으로 나눈 행벡터를 반환한다. 성분개수를 입력하지 않으면 $1\times 100$ 벡터를 반환한다. 간격의 길이가 아닌 간격의 개수가 중요할 때 쓰인다. a: m :b : 구간 $[a,b]$를 등간격 $m$으로 나눈 행벡터를 반환한다. 간격을 입력하지 않으면 간격이 $1$로 설정된다. 간격의 개수가 아니라 간격의 길이가 주요</description>
    </item>
    
    <item>
      <title>임의의 함수의 절대값을 두 개의 음이 아닌 함수로 표현하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/way-to-represent-the-absolute-value-of-any-function-as-two-nonnegative-functions/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/way-to-represent-the-absolute-value-of-any-function-as-two-nonnegative-functions/</guid>
      <description>정리 기본 함수 $f : X \to \mathbb{R}$ 의 절대값 $|f|$ 는 $f$ 의 양의 부분 $f^{+}$ 와 음의 부분 $f^{-}$ 에 대해 다음과 같이 나타난다. $$ |f| = f^{+} + f^{-} $$ 고급 함수 $g : X \to \mathbb{R}$ 은 [[거의 어디서나]] $g \ge 0$ 이라고 하자. [1] 절대값 내부: $$ f^{+} = |f^{+}| \\ f^{-} = |f^{-}| \\ |f| = |f^{+}| + |f^{-}| $$ [2] 절대값 외부: $$ |f|^{-} = 0 \\ |f|^{+} = |f| \\ |f| = |f|^{+} + |f|^{-} $$ [3] 부호의 출입: $$ |f^{+}| + |f^{-}| = |f|^{+} + |f|^{-} \\ |g^{-}| = |g|^{-} = 0 \qquad \text{ a.e.} \\ |g^{+}| =</description>
    </item>
    
    <item>
      <title>조건부 기대값의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-conditional-expectation/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-conditional-expectation/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. [1] 측도론에서의 정리: 가측 함수 $f$, $g$ 가 $\mathcal{F}$-가측이면 $g = h (f)$ 를 만족하는 보렐 함수 $h : \mathbb{R} \to \mathbb{R}$ 가 존재한다. [2] 확률론에서의 응용: 확률 변수 $X$, $Y$ 이 $\sigma(X)$-가측이면 $E(Y | X) = h(X)$ 를 만족하는 보렐 함수 $h : \mathbb{R} \to \mathbb{R}$ 가 존재한다. [3]: $X$ 가 $\mathca</description>
    </item>
    
    <item>
      <title>명제함수의 한정규칙</title>
      <link>https://freshrimpsushi.github.io/posts/quantification-rules/</link>
      <pubDate>Sun, 06 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quantification-rules/</guid>
      <description>정의 1 전체집합 $U$ 의 명제함수 $P(x)$ 가 주어져있다고 하자. Universal Quantifier: &amp;lsquo;모든 $x \in U$ 에 대하여&amp;rsquo;를 $\forall x$ 와 같이 쓰고 전칭기호라고 한다. Existential Quantifier: &amp;lsquo;적어도 하나의 $x \in U$ 가 존재해서&amp;rsquo;를 $\exists x$ 와 같이 쓰고 존재기호라고 한다. 설명 가령 자연수 집합 $\mathbb{N}$ 에 대해 논리식 $p(x)$ 가 &amp;lsquo;$x$ 는 $3$ 의 배수다&amp;rsquo;라면, 위의</description>
    </item>
    
    <item>
      <title>절대 연속과 적분 가능한 함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-absolutely-continuity-and-integral-functions/</link>
      <pubDate>Sun, 06 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-absolutely-continuity-and-integral-functions/</guid>
      <description>빌드업 아래와 같은 명제를 생각해보자. 가측 공간 $(X,\mathcal{E})$위의 측도 $\mu$와 $\mu-$적분가능한 함수 $f$가 주어졌다고 하자. 그러면 $f$에 디펜드하는 $\nu \ll\mu$인 $\nu$가 존재한다. 이를 보이는 것은 증명이랄 것도 없다. $\nu$를 아래와 같이 정의하면 $\nu \ll\mu$이기 때문에 위</description>
    </item>
    
    <item>
      <title>동적 프로그래밍</title>
      <link>https://freshrimpsushi.github.io/posts/dynamic-programing/</link>
      <pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamic-programing/</guid>
      <description>빌드업 문제를 풀 때, 큰 문제의 해답에 그보다 작은 문제의 해답이 포함되어 있으면 최적 부분 구조Optimal Substructure를 가진다고 한다. 최적 부분 구조를 갖춘 문제의 예로써 가장 쉬운 것이 바로 피보나치 수를 구하는 것이다. $n$ 번째 피보나치 수는 $a_{n} = a_{n-1} + a_{n-2}$ 와 같이 구해지므로, 큰 문제 $a_{n}$ 에 작은 문제 $a_{n-1}$, $a_{n-2}$ 가 포함되어 있기 때문이다. 이</description>
    </item>
    
    <item>
      <title>르벡-라돈-니코딤 보조 정리</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-radon-nikodym-lemma/</link>
      <pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-radon-nikodym-lemma/</guid>
      <description>정리1 가측 공간 $(X, \mathcal{E})$위의 유한 측도 $\mu$, $\nu$가 주어졌다고 하자. 그러면 $\mu \perp \nu$이거나, 아래의 조건을 만족하는 $\epsilon&amp;gt;0$, $E \in \mathcal{E}$가 존재한다. $$ \mu(E) &amp;gt;0 \quad \text{and} \quad \nu(E) \ge \epsilon \mu (E) $$ 설명 이 정리에 따로 붙은 이름은 없으나 르벡-라돈-니코딤 정리를 증명할 때 유용한 보조정리로 사용한다. 이름은 없지만 두</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 조건부 확률</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-probability-in-terms-of-measure-theory/</link>
      <pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-probability-in-terms-of-measure-theory/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드라고 할 때, 사건 $F \in \mathcal{F}$ 에 대해 $$ P(F | \mathcal{G}) := E ( \mathbb{1}_{F} | \mathcal{G}) $$ 를 $\mathcal{G}$ 에 대한 $F$ 의 조건부 확률이라고 한다. 다음과 같이 정의된 $f_{Y | X =x}$ 를 $X=x$ 일 때 $Y$ 의 조건부 밀도라고 한다. $$ f_{Y | X = x} (y | X = x) := {{\partial } \over {\partial y }} P( Y \le y | X = x) $$ 아직 측도론을 접하지 못했다면 확률 공간이라는</description>
    </item>
    
    <item>
      <title>부호 측도의 절대 연속</title>
      <link>https://freshrimpsushi.github.io/posts/absolutely-continuous-of-signed-measure/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/absolutely-continuous-of-signed-measure/</guid>
      <description>정의1 가측공간 $(X, \mathcal{E})$ 위의 부호 측도 $\nu$와 양측도 $\mu$가 주어졌다고 하자. 모든 $E \in \mathcal{E}$에 대해서 $$ \mu (E) = 0 \implies \nu (E) = 0 $$ 이면 $\nu$ 가 $\mu$ 에 대해 절대 연속absolutely continuous이라 하고 $\nu \ll \mu$ 와 같이 나타낸다. 설명 절대 연속 이는 측도에 대한 절대 연속의 일반화다. 측도의 절대연속에서와 마</description>
    </item>
    
    <item>
      <title>집합과 명제함수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-set-and-propositional-function/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-set-and-propositional-function/</guid>
      <description>정의 1 Set: 우리의 직관 또는 사고의 대상으로써 서로 뚜렷이 구분되는 객체의 모임을 집합이라 한다. Element: 집합에 속한 객체를 원소라고 한다. Propositional Function: 집합 $U$ 의 원소 $x$ 에 대해 참이거나 거짓 둘 중 하나인 명제 $p(x)$ 를 $U$ 에서의 명제함수라고 한다. 설명 수학에서 집합은 거의 모국어 하나에 필적할만큼 중요한 개념이다. 어쩌면 자연어보다 나을 수도 있는 게, 필연적으로 따라</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 조건부 기대값</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-expectation-in-terms-of-measure-theory/</link>
      <pubDate>Thu, 03 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-expectation-in-terms-of-measure-theory/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드고 확률 변수 $X \in \mathcal{L}^{1} ( \Omega )$ 는 적분 가능하다. 모든 $A \in \mathcal{G}$ 에 대해 $$ \int_{A} Y d P = \int_{A} X d P $$ 를 만족하는 $\mathcal{G}$-가측 확률 변수 $Y$ 가 유일하게 존재하면 $Y := E ( X | \mathcal{G} )$ 를 $\mathcal{G}$ 에 대한 $X$ 의 조건부 기대값이라고 정의한다. 아직 측도론을 접하지 못했다면 확률</description>
    </item>
    
    <item>
      <title>라돈-니코딤 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-radon-nikodym-theorem/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-radon-nikodym-theorem/</guid>
      <description>정리 1 가측 공간 $( \Omega , \mathcal{F} )$ 의 두 시그마 유한 측도 $\nu$, $\mu$ 가 $\nu \ll \mu$ 를 만족하면 모든 $A \in \mathcal{F}$ 에 대해 $\mu$-거의 어디서나 $h \ge 0$ 이고 $$ \nu (A) = \int_{A} h d \mu $$ 을 만족하는 $\mathcal{F}$-가측 함수 $h$ 가 주어진 $\mu$ 에 따라 유일하게 존재한다. $h$ 가 $\mu$-거의 어디서나라는 것은 거의 어디서나와 비슷하게 $\mu \left( h^{-1} ( -\infty , 0 ) \right) = 0$ 이라는</description>
    </item>
    
    <item>
      <title>토탈 배리에이션</title>
      <link>https://freshrimpsushi.github.io/posts/total-variation/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/total-variation/</guid>
      <description>정의1 가측공간 $(X, \mathcal{E})$위의 부호 측도 $\nu$의 토탈 배리에이션total variation $| \nu |$를 다음과 같이 정의한다. $$ |\nu |= \nu^{+} +\nu^{-} $$ 이때 $\nu=\nu^{+}-\nu^{-}$는 $\nu$의 조던 분해이다. 설명 $\nu^{+}$와 $\nu^{-}$를 각각 $\nu$의 포지티브 배리에이션positiv</description>
    </item>
    
    <item>
      <title>라돈-니코딤 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/radon-nikodym-derivative/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/radon-nikodym-derivative/</guid>
      <description>정리 1 가측 공간 $( \Omega , \mathcal{F} )$ 가 주어져 있다고 하자.측도 $\mu$, $\nu$ 가 $\mu ( \Omega ) = 1$ 과 모든 $F \in \mathcal{F}$ 에 대해 $0 \le \nu (F) \le \mu (F)$ 를 만족하면 모든 $F \in \mathcal{F}$ 에 대해 $$ \nu(F) = \int_{F} h d \mu $$ 를 만족하면서 $h \ge 0$ 인 $\mathcal{F}$-가측 함수 $h : \Omega \to \mathbb{R}$ 가 존재한다. 이 $h$ 를 $\displaystyle h := {{d \nu } \over {d \mu }}$ 와 같이 나타내고 $\mu$ 에 대한 $\nu$ 의 라돈-니코딤 도함수라 한다. 어떤</description>
    </item>
    
    <item>
      <title>재귀함수를 쓸 때 주의해야하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-you-watch-out-when-you-using-recurrence/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-you-watch-out-when-you-using-recurrence/</guid>
      <description>주의 프로그래밍을 처음 배우면 그것이 어떤 언어든지 &amp;lsquo;재귀함수는 조심해서 써야한다&amp;rsquo;는 경고가 함께한다. 사실 재귀함수라는 게 그렇게 빈번하게 사용되는 테크닉이 아니기 때문에 그 이유는 설명하지 않는 경우가 많은데, 배우는 입장에선 이 좋은 걸 왜 꺼리는지 이해가 잘 되지 않을 수 있다. 예시를 통해 알아보자. 예시 def fibo1(n) : if n==1</description>
    </item>
    
    <item>
      <title>매트랩에서 행렬의 특정한 행, 열을 선택하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/row-vector-column-vector-in-matlab/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/row-vector-column-vector-in-matlab/</guid>
      <description>방법 $m \times n$ 행렬로된 데이터가 있고 이를 $A$라고 하자. 행렬 $A$의 특정한 부분만을 이용하고 싶다면 아래와 같은 방법을 사용하면 된다. B=A(a:b, c:d) 위와 같은 코드를 실행시키면 $B$는 행렬 $A$의 $a$행~$b$행, $c$열~$d$열의 데이터를 가진 $(b-a) \times (d-c)$행렬이 된다. 아래는 예제 코드와 실행 결과이다. for k=1:9 for l=1:9 A(k,l)=10*k+l; end end A a1=A(3:7,4:9) a2=A(2:5,1:6) ::</description>
    </item>
    
    <item>
      <title>시그마 유한 측도</title>
      <link>https://freshrimpsushi.github.io/posts/sigma-finite-measure/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sigma-finite-measure/</guid>
      <description>정의 1 가측 공간 $( X , \mathcal{E} )$가 주어져있다고 하자. $\mu (X) &amp;lt; \infty$ 이면 $\mu$ 를 유한 측도라고 한다. $$\displaystyle X = \bigcup_{i=1}^{\infty} E_{i} \qquad , E_{i} \in \mathcal{E}$$ 라고 할 때 모든 $i \in \mathbb{N}$ 에 대해 $\mu ( E_{i} ) &amp;lt; \infty$ 면 시그마 유한 측도라고 한다. 또한 순서쌍 $(X, \mathcal{E}, \mu)$를 시그마 유한 측도 공간이라 한다. $\mu ( E ) = \infty$ 인 모든 $E \in \mathcal{E}$ 에 대해 $0 &amp;lt; \mu (F) &amp;lt; \infty$ 를 만족하는 $E$ 의 부분집합 $F \in \mathcal{E}$ 이 존재하면 $\mu$ 를</description>
    </item>
    
    <item>
      <title>삼단논법의 수리논리적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-syllogism/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-syllogism/</guid>
      <description>법칙 1 $$ ( p \to q ) \land ( q \to r ) \implies p \to r $$ 설명 삼단논법을 모르는 사람은 없고 굳이 설명해줄 것도 없다고 본다. 고대의 철학적 논쟁이 아닌 이상에야 굳이 &amp;lsquo;삼단논법에 의해&amp;rsquo;라는 말을 쓰는 경우는 흔치 않다. 그만큼 우리들에게는 익숙한 논법이자 보편타당한 원리기 때문이다. 하지만 삼단논법이 증명이 되는 것이고 증명을 해</description>
    </item>
    
    <item>
      <title>수학적 귀납법</title>
      <link>https://freshrimpsushi.github.io/posts/mathmatical-induction/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mathmatical-induction/</guid>
      <description>법칙 1 명제 $p(n) (n=1,2,3, \cdots )$ 에 대해 $p(1)$ 이 참이고 $p(n)$ 을 가정했을 때 $p(n+1)$ 이 성립하면 $p(n)$ 은 참이다. 설명 어떤 식이 자연수에 대해 성립할 때 특히 큰 위력을 발휘하는 증명법으로, 페아노 제5공리라고도 불리며 혹은 &amp;lsquo;수학적&amp;rsquo;이라는 말을 떼고 그냥 귀납법이라고도 한다. 본래 귀납법이란 현상이나 실체를 경험적으로 모아 어떤 결론을 내리는 것인</description>
    </item>
    
    <item>
      <title>행렬의 연속 미분 적분 지수행렬</title>
      <link>https://freshrimpsushi.github.io/posts/continuity-and-differentiability-of-matrix/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuity-and-differentiability-of-matrix/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 미분 방정식에서는 실변수 $t$에 대한 함수들로 이루어진 벡터 혹은 행렬을 다뤄야할 때가 있다. 예를 들어 $$ \mathbf{x}(t) = \begin{pmatrix} x_1(t) \\ \vdots \\ x_n(t) \end{pmatrix},\quad \mathbf{A}(t) \begin{pmatrix} a_{11}(t) &amp;amp; \cdots &amp;amp; a_{1m}(t) \\ \vdots &amp;amp; &amp;amp; \vdots \\ a_{n1}(t) &amp;amp; \cdots &amp;amp; a_{nm}(t) \end{pmatrix} $$ 이를 $\mathrm{matrix\ function}$이라 한다. 읽는대로 번역하면 행렬 함수이지만 함수를 성분으로 가지는 행렬이라는 의미가 잘</description>
    </item>
    
    <item>
      <title>귀류법의 수리논리적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-reductio-ad-absurdum/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-reductio-ad-absurdum/</guid>
      <description>법칙 1 $$ (p \land \lnot q) \to c \iff p \to q $$ $c$ 는 모순을 의미한다. 설명 배리법 혹은 귀류법은 수학 전반에서 정말 많이 사용되는 증명법이다. 하지만 처음 귀류법을 접하는 사람은 이게 단어부터 생소해서 거부감이 들 수 있다. 혹은 그냥 익숙해졌을 뿐, 왜 귀류법이 작동하는지 이해하지 못한 사람도 있을 것이다.아래의 글을 읽어보면서 귀류법을 이해해보자: (1) 결론 $q$</description>
    </item>
    
    <item>
      <title>측도의 절대 연속</title>
      <link>https://freshrimpsushi.github.io/posts/absolutely-continuous/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/absolutely-continuous/</guid>
      <description>정의 1 가측 공간 $( \Omega , \mathcal{F} )$ 가 주어져 있다고 하자. 측도 $\nu$, $\mu$ 가 모든 $A \in \mathcal{F}$ 에 대해 $$ \mu (A) = 0 \implies \nu (A) = 0 $$ 를 만족시키면 $\nu$ 가 $\mu$ 에 대해 절대 연속이라 하고 $\nu \ll \mu$ 와 같이 나타낸다. 설명 $\nu \ll \mu$ 이라는 표기에서 단번에 알 수 있듯 $\mu$ 는 $\nu$ 를 &amp;lsquo;제압&amp;rsquo;하는 느낌이 강하다. 문제는 이걸 왜 &amp;lsquo;절대 연속&amp;lsquo;이</description>
    </item>
    
    <item>
      <title>프레셰 도함수에 대한 연쇄 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/chain-rule-for-frechet-derivative/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chain-rule-for-frechet-derivative/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **프레셰 도함수에 대한 연쇄 법칙$(\mathrm{Chain\ rule\ for\ Frechet\ derivative})$ $X$, $Y$, $Z$가 바나흐 공간이라고 하자. $\Omega \subset X$, $U \subset Y$가 열린 집합이라고 하자. 그리고 함수 $F\ :\ \Omega \rightarrow Y$, $G\ :\ U \rightarrow Z$가 주어졌다고 하자. 이 때 $F(\Omega) \subset U$를 만족한다.이제 $F$가 $x\in\Omega$에서</description>
    </item>
    
    <item>
      <title>가측 공간의 파티션과 리파인먼트</title>
      <link>https://freshrimpsushi.github.io/posts/partition-and-refinement/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-and-refinement/</guid>
      <description>정의 가측 공간 $( \Omega , \mathcal{F} )$ 가 주어져 있다고 하자. $( \Omega , \mathcal{F} )$ 에 대해 $\displaystyle \bigsqcup_{i=1}^{k} A_{i} = \Omega$ 를 만족하는 $$\mathcal{P} : = \left\{ A_{i} \in \mathcal{F} : i_{1} \ne i_{2} \implies A_{i_{1}} \cap A_{i_{2}} = \emptyset \right\}_{i=1}^{k}$$ 를 가측 공간 $\Omega$ 의 유한 (가측) 파티션이라 한다. 모든 $A_{i} \in \mathcal{P}$ 에 대해 $\displaystyle A_{i} = \bigsqcup_{j \in J} B_{j}$ 를 만족시키는 $B_{j} \in \mathcal{P}&#39;$ 들이 존재하면 $\mathcal{P}&#39;$ 를 $\mathcal{P}$ 의 리파인먼트라 한다. $\displaystyle \bigsqcup$ 은 서로소인 집합들의 합집합을 의미한다. 설명 리만 합을 정의할</description>
    </item>
    
    <item>
      <title>대우법의 수리논리적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-contrapositive-law/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-contrapositive-law/</guid>
      <description>법칙 1 $$ p \to q \iff \lnot q \to \lnot p $$ 설명 어떤 명제가 참이면 그 대우도 참, 어떤 명제가 거짓이면 그 대우도 거짓이다. 물론 역Converse이 성립한다면 대우법에 의해서 원래 명제의 이Reverse도 성립한다. 이러한 표현들은 수학에 익숙하지 않은 사람들에겐 너무 어려울 수 있다. 직관적인 예를 들어서 이해해보자: $p$ : 날씨가 덥다 $q$ : 땀이 난다 $p</description>
    </item>
    
    <item>
      <title>유계 선형 사상</title>
      <link>https://freshrimpsushi.github.io/posts/bounded-linear-map/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bounded-linear-map/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **유계 선형 사상$(\mathrm{bounded\ linear\ map})$ $(X,\ |\cdot|_X)$, $(Y,\ |\cdot |_Y)$가 놈 공간이라고 하자. 아래의 조건을 만족하는 선형 사상 $L\ :\ X \rightarrow Y$를 유계라 한다. $$ | L |:=\sup \limits_{ | x | \le 1 \\ x\in X} |Lx| &amp;lt; \infty $$ 유계 선형 사상 $L$에 대해서 아래의 부등식이 성립한다. $$ |Lx|_Y\le |L| |x|_X,\quad \forall x \in X $$ 모든</description>
    </item>
    
    <item>
      <title>드 모르간의 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-de-morgans-laws/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-de-morgans-laws/</guid>
      <description>정리 1 [1] 드 모르간의 법칙: $$ \lnot (p \land q) \iff \lnot p \lor \lnot q \\ \lnot(p \lor q) \iff \lnot p \land \lnot q $$ [2] 드 모르간의 정리: $$ (A \cup B)^{c} = A^{c} \cap B^{c} \\ (A \cap B)^{c} = A^{c} \cup B^{c} $$ 설명 드 모르간의 법칙와 드 모르간의 정리는 각각 명제, 집합에 대한 정리지만 실제로 말을 하면서는 별로 구분하지 않는다. 법칙이든 정리든 드 모르간- 만 붙으면 부정이나 여집합을 취하면 괄호 안의 명제, 집합과 기호</description>
    </item>
    
    <item>
      <title>매트랩에서 그래프 색, 선 종류, 마커 종류 지정하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/plot-option-in-matlab/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/plot-option-in-matlab/</guid>
      <description>표 그래프 색 마커 선의 형태 빨강 r 점 . 실선 - 초록 g 별표 * 점선 : 파랑 b x x 점단선 -. 검정 k 원 o(알파벳 오) 단선 -- 노랑 y + + 선 없음 자홍 m □ s 하양 w ◇ d 청록 c ☆ p ▽ v △ ^ ◁ &amp;lt; ▷ &amp;gt; 육각별 h 마커 없음 예제 x=1:20; y=x.^3+3.*x.^2+3.*x+1; figure() plot(x,y,&#39;ro&#39;) title(&#39;ro&#39;) figure() plot(x,y,&#39;g-&#39;) title(&#39;g-&#39;) figure() plot(x,y,&#39;mo&#39;) title(&#39;mo&#39;) figure() plot(x,y,&#39;c:&#39;) title(&#39;c:&#39;) figure() plot(x,y,&#39;k--&#39;) title(&#39;k--&#39;)</description>
    </item>
    
    <item>
      <title>프레셰 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/frechet-derivative/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/frechet-derivative/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **프레셰 미분 가능$(\mathrm{ Frechet\ differentiable})$, 프레셰 도함수$(\mathrm{ Frechet\ derivative})$ 두 바나흐 공간 $X$, $Y$와 열린 집합 $\Omega \subset X$가 주어졌다고 하자. 그러면 함수 $F\ :\ \Omega \rightarrow Y$에 대해서 아래의 조건을 만족하는 유계 선형 사상 $L\ :\ X \rightarrow Y$가 존재하면 $F$가 $x\in \Omega$에서 프레셰 미</description>
    </item>
    
    <item>
      <title>매트랩에서 이미지를 회전시키는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/image-rotation-in-matlab/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/image-rotation-in-matlab/</guid>
      <description>방법 imrotate(I,angle,method,bbox) I: 회전할 영상, 이미지이다. angle : 회전할 각도이며 단위는 도이다. method : 보간 방법이다. &amp;lsquo;nearest&amp;rsquo;, &amp;lsquo;bilinear&amp;rsquo;, &amp;lsquo;bicubic&amp;rsquo;이 있다. 아무것도 입력하지 않으면 &amp;lsquo;nearet&amp;rsquo;가 적용된다. X = phantom(&#39;Modified Shepp-Logan&#39;,64); figure() imagesc(X) title(&#39;X&#39;) Y1=imrotate(X,30,&#39;nearest&#39;,&#39;crop&#39;); Y2=imrotate(X,30,&#39;bilinear&#39;,&#39;crop&#39;); Y3=imrotate(X,30,&#39;bicubic&#39;,&#39;crop&#39;); figure() subplot(1,3,1) imagesc(Y1) title(&#39;Y1 - nearest&#39;) subplot(1,3,2) imagesc(Y2) title(&#39;Y2 - bilinear&#39;) subplot(1,3,3) imagesc(Y3) title(&#39;Y3 - bicubic&#39;) bbox : 출력 이미지의 크기를 지정해준다. &amp;l</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 조인트 분포와 마지널 분포</title>
      <link>https://freshrimpsushi.github.io/posts/joint-distribution-and-marginal-distribution-in-terms-of-measure-theory/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/joint-distribution-and-marginal-distribution-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 조인트 분포: $( \Omega , \mathcal{F} , P)$ 에서 정의된 두 확률 변수 $X$, $Y$ 가 있다고 할 때, 랜덤 벡터 $(X,Y) : \Omega \to \mathbb{R}^2$ 의 분포는 보렐 셋 $B \subset \mathcal{B} \left( \mathbb{R}^2 \right)$ 에 대해 $$ \begin{align*} P_{(X,Y)} (B) &amp;amp;:=&amp;amp; P \left( (X,Y) \in B \right) \\ =&amp;amp; \int_{B} f_{(X,Y)} (x,y) d m_{2} (x,y) \end{align*} $$ 와 같이 정의되며, 이를 만족시키는 $f_{(X,Y)}$ 가 존재한다면 $X$, $Y$ 가 조인트 밀도를 가진다고 한다. 마지널 분포: 보렐 셋 $A \subset \mathbb{R}$</description>
    </item>
    
    <item>
      <title>매트랩에서 특수한 행렬을 만드는 함수</title>
      <link>https://freshrimpsushi.github.io/posts/special-matrices-in-matlab/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/special-matrices-in-matlab/</guid>
      <description>영행렬 zeros(): 영행렬을 반환한다. zeros(n): $n\times n$ 영행렬을 반환한다. zeros(m,n): $n\times m$ 영행렬을 반환한다. zeros(size(A)): 행렬 A와 같은 크기의 영행렬을 반화한다. 모든 원소가 1인 행렬 ones(): 모든 원소가 1인 행렬을 반환한다. 다만 두 행렬 사이의 연산을 위해서는 그냥 1을 쓰는게 편하다. 누가 봐도 예제 코드 중에서 아래의 코드가 훨씬 간단하다. ones(n): 모든 원소가 1인 $n\times n$ 행렬을 반환한다. ones(m,n):</description>
    </item>
    
    <item>
      <title>항진 명제와 항위 명제</title>
      <link>https://freshrimpsushi.github.io/posts/tautology-and-contradiction/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tautology-and-contradiction/</guid>
      <description>정의 1 모든 논리적 가능성에 대해 참인 명제를 항진 명제TTautology라고 한다. 모든 논리적 가능성에 대해 거짓인 명제를 항위 명제Contradiction라고 한다. $p$, $q$ 에 대해 조건문 $p \to q$ 가 항진 명제면 함의 명제Implication라 하고 다음과 같이 나타낸다. $$ p \implies q $$ $p$, $q$ 에 대해 쌍조건문 $p \leftrightarrow q$ 가 항진 명제면 동치Equ</description>
    </item>
    
    <item>
      <title>매트랩에서 두 행렬을 성분별로 연산하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/elementwise-operation-of-matrix-in-matlab/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/elementwise-operation-of-matrix-in-matlab/</guid>
      <description>곱셈 times() , .*: 두 행렬의 각 성분을 곱해서 그 결과를 반환한다. 두 행렬의 크기가 완전히 같거나, 한 쪽이 스칼라이거나, 행의 크기가 같은 행벡터, 열의 크기가 같은 열벡터일 경우에만 연산이 가능하다. 크기가 다른 경우에 작은 행렬이 큰 행렬과 같은 크기의 행렬인 것 처럼 계산되는데 이 때 빈 자리는 똑같은 값으로 채워진다. 예를 들어 스칼라는 모든 성분이 같은 값을</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 특성 함수와 적률생성함수</title>
      <link>https://freshrimpsushi.github.io/posts/characteristic-function-and-moment-generating-function-in-terms-of-measure-theory/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/characteristic-function-and-moment-generating-function-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.확률 변수 $X$ 과 $t \in \mathbb{R}$ 에 대해 다음과 같이 정의된 $\varphi_{X} (t)$ 를 $X$ 의 특성 함수라고 한다. $$ \varphi_{X} (t) := E \left( e^{i t X} \right) = \int_{\mathbb{R}} e^{it x} f_{X} (x) dx $$ 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다. 설명 확률 변수 $Z : = X + i Y$ 는 두 확률 변수 $X, Y : \Omega \to \mathbb{R}$ 에 대해 다음과 같은 성질을 갖도록 정의된다. $$ \int</description>
    </item>
    
    <item>
      <title>균등 씨^엠-정칙성 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-uniform-cm-regularity-condition/</link>
      <pubDate>Sun, 22 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-uniform-cm-regularity-condition/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **균등 $C^m$-정칙성 조건$(\mathrm{ The\ uniform}$ $C^m$-$\mathrm{regularity\ condition})$ 만약 $\mathrm{bdry}\Omega$의 국소 유한 오픈 커버 $\left\{ U_j \right\}$가 존재하고, 그에 대응되는 $U_j$를 볼 $B=\left\{ y\in \mathbb{R}^n\ :\ |y|&amp;lt;1 \right\}$로 보내는 $m$-스무스 변환의 수열 $\left\{ \Phi_j \rig</description>
    </item>
    
    <item>
      <title>명제와 결합자, 진리표</title>
      <link>https://freshrimpsushi.github.io/posts/statement-connective-truth-table/</link>
      <pubDate>Sun, 22 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statement-connective-truth-table/</guid>
      <description>정의 1 참이거나 거짓이거나 둘 중 하나인 서술을 명제라고 한다. 명제는 참이거나 거짓 둘 중 하나의 진리값Truth Value을 가진다. 두 명제 $p$, $q$ 의 진리값이 같으면 $p$ 와 $q$ 가 (논리적) 동치(Logically) Equivalent라 하고, $p \equiv q$ 와 같이 나타낸다. 합성명제를 구성하는 방법으로써 다음과 같은 기호들을 결합자Conne</description>
    </item>
    
    <item>
      <title>매트랩에서 행렬의 길이 크기와 관련된 함수</title>
      <link>https://freshrimpsushi.github.io/posts/matrix-operator-in-matlab/</link>
      <pubDate>Sat, 21 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/matrix-operator-in-matlab/</guid>
      <description>함수 size(): 행렬의 행, 열의 길이를 성분으로 갖는 행 벡터를 반환한다. 다루고 있는 행렬과 크기가 같은 영행렬을 만들 때 유용하다. zeros(size(A)): A와 크기가 같은 영행렬을 반환한다. length(): 행과 열 중에서 더 큰 숫자를 반환한다. 행벡터, 열벡터의 경우에는 성분의 개수와 같으므로 numel()과 같다. 또한 size()는 행과 열의 크기를 반환하므로 length(A)</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 기대값</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-in-terms-of-measure-theory/</link>
      <pubDate>Sat, 21 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.확률 변수 $X$ 에 대해서 다음과 같이 정의된 $E(X)$ 를 $X$ 의 (수리적) 기대값이라고 한다. $$ E(X) := \int_{\Omega} X d P $$ 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다. 설명 기대값의 정의는 아무리 측도론이 쓰였다지만 너무 난해하다. 무슨 뜻인지 대강은 알겠지만 한 줄 찍 써놓은 수식만으로는 이해하</description>
    </item>
    
    <item>
      <title>강한 국소 립시츠 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-strong-local-lipschitz-condition/</link>
      <pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-strong-local-lipschitz-condition/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **강한 국소 립시츠 조건$(\mathrm{The\ strong\ local\ Lipschitz\ condition})$ 만약 양수 $\delta$, $M$과 $\mathrm{bdry}\Omega$의 국소 유한 오픈 커버 $\left\{ U_j \right\}$가 존재해서, 각각의 $j$에 대해서 $n-1$개의 변수를 가지는 실수값을 갖는 함수 $f_j$가 $(a)$</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 디락 측도와 이산 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/dirac-measure-and-discrete-probability-distribution-in-terms-of-measure-theory/</link>
      <pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirac-measure-and-discrete-probability-distribution-in-terms-of-measure-theory/</guid>
      <description>개요 기초적인 확률론에서 확률 분포란 이산과 연속 둘 중 하나였고, 그 설명도 다소 직관을 동원할 수밖에 없었다. 그러나 측도론을 도입하면 수학적인 모호함 없이 깔끔하게 이산 확률 분포를 정의할 수 있다. 이산 확률 분포 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. Step 1. 확률 변수 $X$ 가 단 하나의 값을 가지는 경우 $X = a$ 인 경우만 있다고 생각할 때, 그 확률 분</description>
    </item>
    
    <item>
      <title>균등 콘 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-uniform-cone-condition/</link>
      <pubDate>Thu, 19 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-uniform-cone-condition/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **균등 콘 조건$(\mathrm{The\ uniform\ cone\ conditionz})$ 만약, $\Omega$의 경계의 국소 유한 오픈 커버 $\left\{ U_j \right\}$가 존재하고, 그에 대응하는 유한 콘 $\left\{ C_j \right\}$가 $(a)$~$(d)$를 만족하며 존재하면 열린 집합 $\Omega \subset \mathbb{R}^n$가 균등</description>
    </item>
    
    <item>
      <title>아이젠슈타인 소수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eisenstein-prime-theorem/</link>
      <pubDate>Thu, 19 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eisenstein-prime-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 아이젠슈타인 링의 이리듀서블 엘리먼트를 아이젠슈타인 소수라 한다. 아이젠슈타인 정수 $\pi \in \mathbb{Z}[ \omega ]$ 가 다음의 조건들 중 하나를 만족하면 아이젠슈타인 소수다. (i): $\pi = 1 + \omega 2$ (ii): 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 2 \pmod{3}$ 인 $\pi = p$ (iii): 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 1 \pmod{3}$ 이라고 할 때, $p = u^2 - uv+ v^2$ 를 만족시키는 $\pi = u +</description>
    </item>
    
    <item>
      <title>집합의 경계로부터 일정한 거리밖의/안의 집합</title>
      <link>https://freshrimpsushi.github.io/posts/usefull-tool/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/usefull-tool/</guid>
      <description>정의 열린 집합 $\Omega \subset \mathbb{R}^n$가 주어져있다고 하자. 그러면 $\Omega_{&amp;lt;\delta}$와 $\Omega_{&amp;gt;\delta}$를 아래와 같이 정의한다. $$ \Omega_{&amp;lt;\delta} := \left\{ x\in\Omega : \mathrm{dist}(x, \mathrm{bdry}\Omega)&amp;lt;\delta \right\} $$ $$ \Omega_{&amp;gt;\delta} := \left\{ x\in\Omega : \mathrm{dist}(x, \mathrm{bdry}\Omega)&amp;gt;\delta \right\} $$ 설명 이러한 집합은 편미분방정식, 함수해석등에서 유용하게 쓰인다. 교재에 따라서 $\Omeg</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 밀도와 누적 분포 함수</title>
      <link>https://freshrimpsushi.github.io/posts/density-and-cumulative-distribution-function-in-terms-of-measure-theory/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/density-and-cumulative-distribution-function-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있고 $m$ 이 측도라고 하자. 측도 $P : \mathcal{F} \to \mathbb{R}$ 가 적분가능한 $f \ge 0$ 에 대해 $$ A \mapsto P(A) = \int_{A} f dm $$ 의 폼을 갖추고 있으면 $P$ 가 절대 연속Absolutely Continuous이라 한다. 특히 이러한 $f$ 를 측도 $m$ 에 대한 $P$ 의 밀도라고 부른다. 다음과 같이 정의된 $F$ 를 밀도 $f$ 에 해당하는 (누적) 분포 함수라고 한다.</description>
    </item>
    
    <item>
      <title>아이젠슈타인 링의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-of-gaussian-ring/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-of-gaussian-ring/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 아이젠슈타인 링 $\mathbb{Z}[ \omega ]$ 에 대해 함수 $N : \mathbb{Z}[\omega] \to \mathbb{Z}$ 를 생각해보자. [1]: $N(x + \omega y) := x^2 - xy + y^2$ 이라고 정의하면 $N$ 은 $\mathbb{Z}[ \omega ]$ 의 승법적 놈이 된다. [2]: $\mathbb{Z}[ \omega ]$ 은 유클리디안 도메인이다. [3]: $\mathbb{Z}[ \omega ]$ 의 유닛은 $\pm 1, \pm \omega, \pm \omega^2 $ 뿐이다. 아이젠슈타인 정수는 추상대수의 도움을 받으면 훨씬 편하게 연구할 수 있다. 인</description>
    </item>
    
    <item>
      <title>조던 분해 정리</title>
      <link>https://freshrimpsushi.github.io/posts/jodan-decomposition-theorem/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jodan-decomposition-theorem/</guid>
      <description>정리 가측공간 $(X,\mathcal{E})$와 그 위에서 정의된 부호측도 $\nu$가 주어졌다고 하자. 그러면 아래의 조건을 만족하는 두 양측도 $\nu^{+}$, $\nu^{-}$가 유일하게 존재하고 $\nu=\nu^{+}-\nu^{-}$를 $\nu$ 조던 분해Jodan decomposition라고 한다. $$ \nu=\nu^{+}-\nu^{-} $$ $$ \nu^{+} \perp \nu^{-} $$ 이때 $X=P \cup N$을</description>
    </item>
    
    <item>
      <title>뮤츄얼리 싱귤러</title>
      <link>https://freshrimpsushi.github.io/posts/mutually-singular/</link>
      <pubDate>Mon, 16 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mutually-singular/</guid>
      <description>정의1 두 부호 측도 $\nu$, $\mu$가 주어졌다고 하자. $\nu$, $\mu$에 대해서 아래의 세 조건을 만족시키는 $E,F\ \in \mathcal{E}$가 존재하면 두 부호측도 $\nu$, $\mu$가 mutually singular라고 말하고 $\nu \perp \mu$혹은 $\mu \perp \nu$라고 나타낸다. $E \cup F=X$ $E \cap F=\varnothing$ $E$는 $\nu$에 대해서 영집합이고, $F$는 $\mu$에 대해서 영</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 독립</title>
      <link>https://freshrimpsushi.github.io/posts/independence-of-random-variables-in-terms-of-measure-theory/</link>
      <pubDate>Mon, 16 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independence-of-random-variables-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 모든 보렐 셋 $B_{1} , B_{2} \in \mathcal{B} ( \mathbb{R} )$ 에 대해 다음이 성립하면 확률 변수 $X$, $Y$ 가 독립이라고 한다. $$ P \left( X^{-1} (B_{1} ) \cap Y^{-1} (B_{2} ) \right) = P \left( X^{-1} (B_{1}) \right) P \left( Y^{-1} (B_{2}) \right) $$ 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다. 사실 확률론을 공부함에 있어서 기초적인 분포이론을 지나고나면 사건의 독립이라는 것은</description>
    </item>
    
    <item>
      <title>아이젠슈타인 정수</title>
      <link>https://freshrimpsushi.github.io/posts/eisenstein-integer/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eisenstein-integer/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\mathbb{Z} [ \omega ] := \left\{ a + \omega b : a, b \in \mathbb{Z} \right\}$ 를 아이젠슈타인 링Eisenstein Ring이라 하고, 그 원소를 아이젠슈타인 인티저라 한다. $\omega$ 는 삼차방정식 $x^3 +1 = 0$ 의 복소근 $\displaystyle \omega := {{-1 + \sqrt{-3}} \over {2}} = e^{2 \pi i/3 }$ 으로써, $\mathbb{Z} [\omega]$ 은 인티저 링 $\mathbb{Z}$ 의 심플 익스텐젼이 된다. 가우스 정수만큼이나 흥미로운 성질을</description>
    </item>
    
    <item>
      <title>한 분해 정리</title>
      <link>https://freshrimpsushi.github.io/posts/hahn-decomposition-theorem/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hahn-decomposition-theorem/</guid>
      <description>정리1 (a) $\nu$를 가측공간 $(X, \mathcal{E})$위에서 정의된 부호측도라고 하자. 그러면 다음을 만족하는 $\nu$에 대한 양집합 $P$와 음집합 $N$이 존재한다. $$ P \cup N=X \quad \text{and} \quad P \cap N =\varnothing $$ 이러한 $X=P \cup N$을 $\nu$에 대한 한 분해Hahn decomposition라고 한다. (b) $P’, N’$이 (a) 를 만족하는 다른</description>
    </item>
    
    <item>
      <title>양집합, 음집합, 영집합</title>
      <link>https://freshrimpsushi.github.io/posts/positive-set-negativ-set-null-set/</link>
      <pubDate>Sat, 14 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/positive-set-negativ-set-null-set/</guid>
      <description>정의1 $\nu$를 $(X,\mathcal{E})$위에서의 부호 측도라고 하자. 그리고 $E,F \in \mathcal{E}$라고 하자. 그러면 $\nu(F) \ge 0,\ \forall F\subset E$일 때 $E$를 $\nu$에 대해서 양집합positive set 혹은 간단히 파지티브positive라고 한다. $\nu(F) \le 0,\ \forall F\subset E$일 때 $E$를 $\nu$에 대해서 음집합negat</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수와 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution-in-terms-of-measure-theory/</link>
      <pubDate>Sat, 14 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 모든 보렐 셋 $B \in \mathcal{B} (\mathbb{R})$ 에 대해 $X^{-1} (B) \in \mathcal{F}$ 를 만족하는 함수 $X : \Omega \to \mathbb{R}$ 을 확률변수Random Variable라고 한다. 다음과 같이 정의된 $\mathcal{F}_{X}$ 를 $X$ 에 의해 생성된 시그마 필드라고 한다. $$ \mathcal{F}_{X} := X^{-1} ( \mathcal{B} ) = \sigma (X) = \left\{ X^{-1} (B) \in \Omega : B \in \mathcal{B}( \Omega ) \right\} $$ 다음과 같이 정의된 가측 함수 $P_{X}$ 를 $X$ 의 확률 분포Prob</description>
    </item>
    
    <item>
      <title>가우스 소수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gaussian-prime-theorem/</link>
      <pubDate>Fri, 13 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gaussian-prime-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 가우시안 링의 이리듀서블 엘리먼트를 가우스 소수라 한다. 가우스 정수 $\pi \in \mathbb{Z}[i]$ 가 다음의 조건들 중 하나를 만족하면 가우스 소수다. (i): $\pi = 1 + i$ (ii): 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 3 \pmod{4}$ 인 $\pi = p$ (iii): 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 1 \pmod{4}$ 이라고 할 때, $p = u^2 + v^2$ 를 만족시키는 $\pi = u + iv$ (iv): 위의 (i)~(iii) 에 해당되는 $\pi$ 에 $\mathbb{Z}[i]$ 의 유</description>
    </item>
    
    <item>
      <title>부호가 붙은 측도</title>
      <link>https://freshrimpsushi.github.io/posts/signed-measure/</link>
      <pubDate>Fri, 13 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/signed-measure/</guid>
      <description>정의1 $(X, \mathcal{E})$를 가측공간이라고 하자. 아래의 조건을 만족하는 확장된 실수값 함수 $\nu : \mathcal{E} \to \overline{\mathbb{R}}$를 부호 측도signed measure 라고 한다. $\nu ( \varnothing ) = 0$ $\pm \infty$ 중에서 많아야 1개까지만 $\nu$의 함숫값이 될 수 있다. 다시 말해서 $-\infty \in \nu(\mathcal{E})$이면 $+\infty</description>
    </item>
    
    <item>
      <title>슈트라센 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-strassen-algorithm/</link>
      <pubDate>Thu, 12 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-strassen-algorithm/</guid>
      <description>알고리즘 $k \in \mathbb{N}$ 에 대해 $n=2^{k}$ 이라고 하자. $A, B \in \mathbb{R}^{n \times n}$ 에 대해 조던 블록 행렬 표현을 사용해 다음과 같은 8개의 ${{n} \over {2}} \times {{n} \over {2}}$ 행렬 $A_{i}$, $B_{i}$ 들을 생각해보자. $$ AB= \begin{bmatrix} A_{1} &amp;amp; A_{2} \\ A_{3} &amp;amp; A_{4} \end{bmatrix} \begin{bmatrix} B_{1} &amp;amp; B_{2} \\ B_{3} &amp;amp; B_{4} \end{bmatrix} = \begin{bmatrix} C_{1} &amp;amp; C_{2} \\ C_{3} &amp;amp; C_{4} \end{bmatrix} = C $$ $C = AB$ 를 구하기 위해 다음을 계산한다. $$ P_{1} = A_{1} ( B_{2} - B_{4} ) \\ P_{2} = ( A_{1} + A_{2} ) B_{4} \\ P_{3} = ( A_{3} + A_{4} ) B_{1} \\ P_{4} = A_{4} ( B_{3} - B_{1}</description>
    </item>
    
    <item>
      <title>측도의 일반적인 정의</title>
      <link>https://freshrimpsushi.github.io/posts/general-definition-of-measure/</link>
      <pubDate>Thu, 12 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-definition-of-measure/</guid>
      <description>정의 가측 공간 $(X,\mathcal{E})$가 주어졌다고 하자. 아래의 세 조건을 만족하는 확장된 실수값을 갖는 함수 $\mu : \mathcal{E} \to \overline{\mathbb{R}}$를 측도measure 라고 한다. (a) $\mu ( \varnothing ) = 0$ (b) $\mu(E) \ge 0,\quad \forall E\in \mathcal{E}$ (c) $\left\{E_j\right\}$를 $\mathcal{E}$에서 서로소인</description>
    </item>
    
    <item>
      <title>선분 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-segment-condition/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-segment-condition/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **선분 조건$(\mathrm{The\ segment\ condition})$ 열린 집합 $\Omega \subset \mathbb{R}^n$이 주어졌다고 하자. 모든 $x \in \mathrm{bdry}\Omega$에 대해서 아래의 조건을 만족하는 $x$의 근방 $U_{x}$와 영벡터가 아닌 $y_{x}$가 존재하면 $\Omega</description>
    </item>
    
    <item>
      <title>시간복잡도와 공간복잡도</title>
      <link>https://freshrimpsushi.github.io/posts/time-complexity-and-space-complexity/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-complexity-and-space-complexity/</guid>
      <description>정의 주어진 문제를 풀 때의 걸리는 시간을 시간복잡도Time Complexity, 메모리 소요를 공간복잡도Space Complexity라고 한다. 예시 점근적 표기법은 이들을 표현하는데에 굉장히 유용한 수단이 된다. 시간복잡도에 대한 예시를 살펴보자. 상수 시간 $O(1)$ $n$ 에 관계없이 끝낼 수 있는 알고리즘으로, 사실상 시간이 걸리지 않는 것이다. 가령 $\mathbb{x} = [4,3,8,-1,-9,0,5,7,2,6]$ 에서 세</description>
    </item>
    
    <item>
      <title>R 에서 가치 모형으로 시계열 분석 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-garch-model-in-r/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-garch-model-in-r/</guid>
      <description>실습 가치 모델은 아치 이펙트를 설명하는 유용한 수단으로써 분석 절차 자체는 아르마 모델과 흡사하다. 위의 그래프는 내장데이터 EuStockMarkets에서 DAX만 뽑아내서 그린 것으로, 1991년부터 1999년까지 독일 DAX지수를 나타낸다. 리턴의 제곱을 보면 거의 확실하게 아치 이펙트가 있는 것으로 보인다. 리턴의 제곱이 아르마 모</description>
    </item>
    
    <item>
      <title>약한 콘 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-weak-con-condition/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-weak-con-condition/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 약한 콘 조건$(\mathrm{The\ weak\ cone\ condition})$ 열린 집합 $\Omega \subset \mathbb{R}^n$와 임의의 점 $x \in \Omega$가 주어졌다고 하자. $R(x)$를 $x$에서부터 $y \in \Omega$까지의 선분이 다시 $\Omega$안에 포함되도록 하는 $y$들의 집합이라고 하자. 즉 $</description>
    </item>
    
    <item>
      <title>국소 유한</title>
      <link>https://freshrimpsushi.github.io/posts/locally-finite/</link>
      <pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/locally-finite/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **국소 유한 커버$(\mathrm{locally\ finite\ cover})$ 집합 $S \subset \mathbb{R}^n$의 열린 커버 $\mathcal{O}$가 있다고 하자. $\mathbb{R}^n$에서 임의의 컴팩트 집합이 열린 커버 $\mathcal{O}$의 원소와 기껏해야 유한하게 겹칠 때</description>
    </item>
    
    <item>
      <title>알고리즘의 비용에 대한 점근적 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/asymptotic-notation/</link>
      <pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/asymptotic-notation/</guid>
      <description>정의 크기가 $n$ 인 데이터에 대해 알고리즘의 비용을 다음과 같이 나타낸다. $O$ 표기법: $$ O(g(n)) := \left\{ f(n) \ | \ \exists c &amp;gt; 0, n_{0} \in \mathbb{N} : \forall n \ge n_{0} \implies f(n) \le c g(n) \right\} $$ $\Omega$ 표기법: $$ \Omega (g(n)) := \left\{ f(n) \ | \ \exists c &amp;gt; 0, n_{0} \in \mathbb{N} : \forall n \ge n_{0} \implies f(n) \ge c g(n) \right\} $$ $\Theta$ 표기법: $$ \Theta (g(n)) := O (g(n)) \cap \Omega (g(n)) $$ 설명 점근적 표기법은 알고리즘의 비용을 수리적으로 나타내는 것으로, 엡실론-델타 논법을</description>
    </item>
    
    <item>
      <title>콘 조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-cone-condition/</link>
      <pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-cone-condition/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **콘 조건$(\mathrm{The\ cone\ condition})$ $\Omega \subset \mathbb{R}^n$이 열린 집합이라고 하자. 만약에 어떤 유한 콘이 존재해서 각각의 $x \in \Omega$에 대해서 $x$를 꼭짓점으로 가지는 유한 콘 $C_{x} \subset \Omega$가 존재하면 $\Omega$가 콘 조건을 만족한다 고 한다. 모</description>
    </item>
    
    <item>
      <title>시계열 분석에서의 가치 모형</title>
      <link>https://freshrimpsushi.github.io/posts/garch-model/</link>
      <pubDate>Sun, 08 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/garch-model/</guid>
      <description>모델 1 가치 모델은 아치 모델을 일반화한 것으로, 이분산성을 파악하기 위한 시계열 분석법이다. $$ (1 - \beta{1} B - \cdots - \beta_{p} B^p) \sigma_{t | t-1}^2 = \omega + (\alpha_{1} B + \cdots + \alpha_{q} B^q) r_{t}^{2} $$ 유도 유도는 가장 간단한 $ARCH(1)$ 모델부터 시작해보자.2 시계열 데이터 $\left\{ p_{t} \right\}$ 의 리턴 $\left\{ r_{t} \right\}$ 이 주어져 있다고 할 때 데이터가 시차 $1$ 의 아치 이펙트, 즉 자기 회귀 조건부 이분산성을 가진다는 말은 다음과 같이</description>
    </item>
    
    <item>
      <title>맥리어드-리 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/mcleod-li-test/</link>
      <pubDate>Sat, 07 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mcleod-li-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 시계열 데이터의 리턴 $\left\{ r_{t} \right\}$ 이 주어져있다고 하자. $H_{0}$ : 데이터는 시차 $k$ 의 아치 이펙트를 가지지 않는다. $H_{1}$ : 데이터는 시차 $k$ 의 아치 이펙트를 가진다. 맥리어드-리 테스트 는 주어진 리턴을 이용해 데이터에 아치 이펙트가 있는지 확인한다. 다행스럽게도 R 에서는 TSA 패키지의 McLeod.Li.test() 함수를 통해 쉽게 테스</description>
    </item>
    
    <item>
      <title>유한 콘</title>
      <link>https://freshrimpsushi.github.io/posts/finite-cone/</link>
      <pubDate>Sat, 07 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finite-cone/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **유한 콘$(\mathrm{finite\ cone})$ $v$를 $\mathbb{R}^n$에서의 단위벡터라고 하자.1 그리고 영벡터가 아닌 각각의 $x\in \mathbb{R}^n$에 대해서 $\angle(x,v)$를 두 벡터 $v,x$사이의 각도라고 하자. 그러면 주어진 $v$, $\rho &amp;gt;0$ $0&amp;lt; \kappa</description>
    </item>
    
    <item>
      <title>아치 이펙트</title>
      <link>https://freshrimpsushi.github.io/posts/arch-effect-autoregressive-conditional-heteroscedasticity-effect/</link>
      <pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arch-effect-autoregressive-conditional-heteroscedasticity-effect/</guid>
      <description>정의 1 아치 이펙트란 그 AutoRegressive Conditional Heteroscedasticity라는 말 그대로 &amp;lsquo;자기회귀 조건부 이분산 효과&amp;rsquo;로 순화되기 때문에 순화하지 않는다. 설명 쉽게 말해서 데이터의 변동성이 변하면서, 그 자체가 이전의 데이터로 설명될 수 있는 경우 데이터에 아치 이펙트가 있다고 말한다. 이러한 아치 이펙트를 통계적으로 설명</description>
    </item>
    
    <item>
      <title>일반적인 평행육면체의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/parallelepiped/</link>
      <pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/parallelepiped/</guid>
      <description>정의 $n$개의 선형 독립인 벡터 $y_{1},\ \cdots,\ y_{n} \in \mathbb{R}^n$가 주어졌다고 하자. 그러면 아래와 같은 집합 $P$를 패럴렐러파입트parallelepiped라고 한다. $$ P = \left\{ \sum \limits_{j=1}^{n} \lambda_{j} y_{j} \ \ \Big| \quad 0\le \lambda_{j} \le 1 \right\} $$ 설명 위와 같이 정의하면 원점을 꼭짓점vertex으로 가지게 된다. 쉽게 말해서 계수가 1이하로 구성된 모든 선형 결합의</description>
    </item>
    
    <item>
      <title>가우시안 링의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-of-gaussian-ring/</link>
      <pubDate>Thu, 05 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-of-gaussian-ring/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 가우시안 링 $\mathbb{Z}[i]$ 에 대해 함수 $N : \mathbb{Z}[i] \to \mathbb{Z}$ 를 생각해보자. [1]: $N(x + iy) := x^2 + y^2$ 이라고 정의하면 $N$ 은 $\mathbb{Z}[i]$ 의 승법적 놈이 된다. [2]: $\mathbb{Z}[i]$ 은 유클리디안 도메인이다. [3]: $\mathbb{Z}[i]$ 의 유닛은 $1,-1,i,-i$ 뿐이다. 가우스 정수는 추상대수의 도움을 받으면 훨씬 편하게 연구할 수 있다. 인티그럴 도메인에서 정의되는 놈 $N$ 으로 [2] 를 증명하면</description>
    </item>
    
    <item>
      <title>시계열분석에서의 이분산성과 변동성 군집현상</title>
      <link>https://freshrimpsushi.github.io/posts/heteroscedasticity-and-volatility-clustering/</link>
      <pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heteroscedasticity-and-volatility-clustering/</guid>
      <description>정의 1 시계열 데이터 $\left\{ p_{t} \right\}$ 가 주어져 있다고 하자. $\left\{ p_{t} \right\}$ 의 분산이 $t$ 에 종속되어있을 때, $\left\{ p_{t} \right\}$ 는 이분산성Heteroscedasticity을 가진다고 한다. 이분산성을 가지는 $\left\{ p_{t} \right\}$ 의 분산이 커졌다 작아졌다를 반복하는 현상을 변동성 군집현상Volatility Clustering이라고 한다. 다음과 같이 정의된 $r_{t}$ 를 $t$ 에서의</description>
    </item>
    
    <item>
      <title>지연시각의 기울기</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-of-retarded-time/</link>
      <pubDate>Tue, 03 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-of-retarded-time/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\eta = c(t -t_r)$이고 $t$는 공간 변수와는 무관하므로 $$ \nabla \eta =\nabla(-c t_r)=-c \nabla t_{r} $$ 따라서 지연시각의 기울기는 $\nabla \eta$를 계산해서 구할 수 있다. $$ \begin{align*} \nabla \eta &amp;amp;= \nabla \sqrt{\boldsymbol{\eta} \cdot \boldsymbol{\eta} } \\ &amp;amp;= \frac{1}{2\sqrt{\boldsymbol{\eta}\cdot \boldsymbol{\eta}}} \nabla (\boldsymbol{\eta} \cdot \boldsymbol{\eta} ) \\ &amp;amp;= \frac{1}{2\eta} \nabla (\boldsymbol{\eta} \cdot \boldsymbol{\eta} ) \\ &amp;amp;= \frac{1}{2\eta} \Big[ \boldsymbol{\eta} \times (\nabla \times \boldsymbol{\eta} ) + \boldsymbol{\eta} \times (\nabla \times \boldsymbol{\eta}) + (\boldsymbol{\eta} \cdot \nabla)\boldsymbol{\eta} +(\boldsymbol{\eta} \cdot \nabla)\boldsymbol{\eta} \Big] \\ &amp;amp;= \frac{1}{\eta} \Big[\boldsymbol{\eta}\times (\nabla \times \boldsymbol{\eta}) + (\boldsymbol{\eta} \cdot \nabla) \boldsymbol{\eta} \Big]</description>
    </item>
    
    <item>
      <title>R 에서 데이터 파일 빠르게 읽기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-data-file-fast-in-r/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-data-file-fast-in-r/</guid>
      <description>개요 R 은 기본적으로 csv 데이터를 읽는 함수로써 read.csv()를 제공하지만, 그냥 간편하게 쓰는 정도가 아니라 실전적인 분석을 하고 있다면 성능이 너무 떨어져서 써먹을 것이 못 된다. 그 대안으로써, readr 패키지에서 제공하는 read\_csv()를 사용할 것을 강력하게 권장한다. read\_csv()는 c++로 작성되었으며, 매우 빠</description>
    </item>
    
    <item>
      <title>리에나르-비케르트 전위 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-lienard-wiechert-potentials/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-lienard-wiechert-potentials/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **리에나르-비케르트 전위$(\mathrm{Liénard-Wiechert\ potentials}$, 리에나르-비헤르트 전위$)$ 지연시각 $t_r$에서 속도 $\mathbf{v}$로 움직이는 점전하 $q$에 대한 전위는 다음과 같다. $$ V(\mathbf{r}, t)= \frac{1}{4\pi \epsilon_0} \frac{qc}{ (\eta c -\boldsymbol{\eta}\cdot \mathbf{v})} $$ $$ \mathbf{A}(\mathbf{r}, t) = \frac{\mu_0}{4 \pi}\frac{qc \mathbf{v} }{(\eta c - \boldsymbol{\eta}\cdot \mathbf{v} )}=\frac{\mathbf{v}}{c^2}V(\mathbf{r},</description>
    </item>
    
    <item>
      <title>가우스 정수</title>
      <link>https://freshrimpsushi.github.io/posts/gaussian-integer/</link>
      <pubDate>Sat, 31 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gaussian-integer/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\mathbb{Z} [i] := \left\{ a + i b : a, b \in \mathbb{Z} \right\}$ 를 가우시안 링Gaussian Ring이라 하고, 그 원소를 가우시안 인티저라 한다. $i$ 는 이차방정식 $x^2 +1 = 0$ 의 복소근으로써, $\mathbb{Z} [i]$ 은 인티저 링 $\mathbb{Z}$ 의 심플 익스텐젼이 된다. 마치 실수체 $\mathbb{R}$ 이 복소수체 $\mathbb{C} = \mathbb{R} [i]$ 로 확장되는 것과 비슷한데, 그 이치 역시 크게 다르지</description>
    </item>
    
    <item>
      <title>R 에서 병렬처리하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-r/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-r/</guid>
      <description>개요 R 이 속도 때문에 쓰는 언어는 아니지만, 빠른 속도가 필요할 때도 분명히 있을 것이다. 코드를 깔끔하게 잘 짜더라도 너무 오래 걸린다면 보통 병렬처리나 GPU를 동원하게 된다. 언뜻 생각했을 때 R 에서 병렬처리를 할 일이 뭐 있나 싶겠지만, 빅데이터를 다루게 되거나 규모가 큰 시뮬레이션을 하게 된다면 병렬처리가 특히 유용한 수단이 된다. 오히려 R 이야</description>
    </item>
    
    <item>
      <title>동적 회귀 모형</title>
      <link>https://freshrimpsushi.github.io/posts/dynamic-regression-model/</link>
      <pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamic-regression-model/</guid>
      <description>모델 동적 회귀 모형이란 쉽게 말해 아리마 모형에 회귀 모형을 합친 모형이다. 설명 사실 이쯤되면 말보다는 수식이 편한데, 종속변수로 분석할 시계열 데이터가 $\left\{ y_{t} \right\}$ 이라고 하고 이 데이터를 설명할 독립변수로써 또 다른 시계열 데이터 $\left\{ x_{t} \right\}$ 가 있다고 해보자. $x_{t}$ 가 $y_{t}$ 를 잘 설명한다면 그것 자체로도 시계열 회귀분석이 가능하고, 그것으로도 설명되지 않는 부분</description>
    </item>
    
    <item>
      <title>제피멩코 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/jefimenko-equation/</link>
      <pubDate>Wed, 28 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jefimenko-equation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **제피멩코 방정식$(\mathrm{ Jefimenko\ equation})$ 연속전하분포가 시간에 따라 변할 때의 전기장은 $$ \mathbf{E} (\mathbf{r},t)=\frac{1}{4\pi \epsilon_0} \int \left[ \frac{ \rho(\mathbf{r}^{\prime}, t_r) }{\eta ^2} \hat{\boldsymbol{\eta}} + \frac{ \dot{\rho}(\mathbf{r}^{\prime}, t_r)}{c\eta}\hat{\boldsymbol{\eta}}-\frac{\dot{\mathbf{J}}(\mathbf{r}^{\prime},t_r) }{c^2 \eta} \right]d\tau^{\prime} $$ 연속전류분포가 시간에 따라 변할 때의 자기장은 $$ \mathbf{B}( \mathbf{r}, t) = \dfrac{\mu_0}{4\pi} \int \left[ \frac{\mathbf{J}(\mathbf{r}^{\prime},t_r)}{\eta^2} + \dfrac{ \dot{\mathbf{J}}(\mathbf{r}^{\prime}, t_r) } {c\eta} \right]\times \hat{\boldsymbol{\eta}}d\tau^{\prime} $$ 이때 $t_r$은 지연시각, $\boldsymbol{\e</description>
    </item>
    
    <item>
      <title>시계열분석의 이노베이티브 아웃라이어</title>
      <link>https://freshrimpsushi.github.io/posts/innovative-outlier/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/innovative-outlier/</guid>
      <description>빌드업 위의 그래프에서 2001년 9월에 굉장히 큰 아웃라이어를 찾을 수 있다. 그러나 애디티브 아웃라이어와 달리 그 후에도 계속해서 영향을 미치고 있다. 여객기의 이용자 수는 계절성을 가지고 꾸준히 증가하고 있었는데, 911테러의 공포가 이용자 수 자체를 팍 줄여버린 것으로 해석할 수 있다. 정의 1 이렇게 분석의 판도 자체를 바꾸는 아웃라이어를 이노</description>
    </item>
    
    <item>
      <title>전위와 전자기장</title>
      <link>https://freshrimpsushi.github.io/posts/potential-and-electromagnetic-field/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/potential-and-electromagnetic-field/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **맥스웰 방정식$(\mathrm{Maxwell&amp;rsquo;s\ equations})$ $(a) \quad \nabla \cdot \mathbf{E}=\dfrac{1}{\epsilon_0}\rho $ **가우스 법칙 $(b) \quad \nabla \cdot \mathbf{B}=0$ (자기장에 대한 가우스 법칙)$(c) \quad \nabla \times \mathbf{E} = -\dfrac{\partial \mathbf{B}}{\partial t}$ **패러데이 법칙 $(d) \quad \nabla \times \mathbf{B} = \mu_0 \mathbf{J}+\mu_0\epsilon_0\dfrac{\partial \mathbf{E}}{\partial t} $ 앙페르 법칙 전위 형식 시간에 따라 전하, 전류분포가 변할 때의 전기장 및</description>
    </item>
    
    <item>
      <title>인티그럴 도메인의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-in-integral-domain/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-in-integral-domain/</guid>
      <description>정의 1 인티그럴 도메인 $D$ 와 모든 $\alpha , \beta \in D$ 에 대해 다음의 조건을 만족하는 함수 $N : D \to \mathbb{Z}$ 를 승법적 놈Multiplicative Norm이라 정의한다. (i): $N (\alpha) = 0 \iff \alpha = 0$ (ii): $N ( \alpha \beta ) = N ( \alpha ) N ( \beta )$ 정리 $p \in \mathbb{Z}$ 가 소수라고 하자. [1]: $D$ 에서 승법적 놈 $N$ 이 정의되면 $N(1) = 1$ 이고 모든 유닛 $u \in D$ 에 대해 $| N ( u ) | = 1$ [2]: $| N ( \alpha )| =1$</description>
    </item>
    
    <item>
      <title>물리학 부록</title>
      <link>https://freshrimpsushi.github.io/posts/physics-appendix/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/physics-appendix/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **부록 1 $$ \mathbb{A} = \begin{pmatrix} e^{-ika} &amp;amp; e^{ika} \\ ike^{-ika} &amp;amp; -ike^{ika} \end{pmatrix},\quad \mathbb{B} = \begin{pmatrix} e^{\kappa a} &amp;amp; e^{-\kappa a} \\ \kappa e^{\kappa a} &amp;amp; -\kappa e^{-\kappa a} \end{pmatrix} $$ 여인수 전개로 위 두 행렬의 역행렬을 구하면 $$ \begin{align*} \mathbb{A}^{-1} &amp;amp;= \frac{1}{|\mathbb{A}|} \mathrm{adj}(A) \\ &amp;amp;= \frac{1}{-ik -ik} \begin{pmatrix} -ike^{ika} &amp;amp; -ike^{-ika} \\ -e^{ika} &amp;amp; e^{-ika} \end{pmatrix}^T \\ &amp;amp;= \frac{1}{-2ik} \begin{pmatrix} -ike^{ika} &amp;amp; -e^{ika} \\ -ike^{-ika} &amp;amp; e^{-ika} \end{pmatrix} \\ &amp;amp;= \frac{1}{2} \begin{pmatrix} e^{ika} &amp;amp; \frac{1}{ik}e^{ika} \\ e^{-ika} &amp;amp; \frac{-1}{ik} e^{-ika} \end{pmatrix} \end{align*} $$ $$ \begin{align*} \mathbb{B}^{-1} &amp;amp;= \frac{1}{|\mathbb{B}|} \mathrm{adj}(B) \\ &amp;amp;= \frac{1}{-\kappa -\kappa } \begin{pmatrix} -\kappa e^{-\kappa a} &amp;amp; -\kappa e^{\kappa a} \\ -e^{-\kappa a} &amp;amp; e^{\kappa a} \end{pmatrix}^T \\ &amp;amp;=</description>
    </item>
    
    <item>
      <title>시계열분석의 애디티브 아웃라이어</title>
      <link>https://freshrimpsushi.github.io/posts/additive-outlier/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/additive-outlier/</guid>
      <description>빌드업 위의 그래프에서 가장 먼저 눈에 띄는 지점은 바로 2015년 2월 근처에 있는 엄청난 아웃라이어다. 이렇듯 극심하게 다른 값을 가지면 분석에 악영향이 있을 수밖에 없다. 다행스러운 건 아주 잠깐, 말 그대로 한 순간의 아웃라이어로 그쳤다는 것이다. 정의 1 이렇듯 데이터의 등락 자체를 바꾸지는 않는 아웃라이어를 애디티브 아웃라이어Additiv</description>
    </item>
    
    <item>
      <title>유한 우물 퍼텐셜 사각형 우물 퍼텐셜에 대한 슈뢰딩거 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/finite-potential-well-square-potential-well/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finite-potential-well-square-potential-well/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 위 그림과 같이 입자의 퍼텐셜이 벽 모양으로 생겼을 때 어떻게 운동하는지 알아보자. 퍼텐셜 $U$는 $$ U(x) = \begin{cases} 0 &amp;amp; x&amp;lt;-a \\ U_0 &amp;amp; -a &amp;lt; x &amp;lt;a \\ 0 &amp;amp;a&amp;lt;x \end{cases} $$ 퍼텐셜이 $U(x)$일 때의 시간에 무관한 슈뢰딩거 방정식은 $$ \dfrac{d^2 u(x)}{dx^2}+\frac{2m}{\hbar ^2} \Big[ E-U(x) \Big]u(x)=0 $$ $E&amp;lt;-U_0$ 에너지가 퍼텐셜보다 작으면 해가 존재하지 않으므로 고려할 필요 없다.</description>
    </item>
    
    <item>
      <title>장벽 퍼텐셜에 대한 슈뢰딩거 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-schr%C3%B6dinger-equation-for-barrier-potential/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-schr%C3%B6dinger-equation-for-barrier-potential/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 위 그림과 같이 입자의 퍼텐셜이 벽 모양으로 생겼을 때 어떻게 운동하는지 알아보자. 퍼텐셜 $U$는 $$ U(x) = \begin{cases} 0 &amp;amp; x&amp;lt;-a \\ U_0 &amp;amp; -a &amp;lt; x &amp;lt;a \\ 0 &amp;amp;a&amp;lt;x \end{cases} $$ 퍼텐셜이 $U(x)$일 때의 시간에 무관한 슈뢰딩거 방정식은 $$ \dfrac{d^2 u(x)}{dx^2}+\frac{2m}{\hbar ^2} \Big[ E-U(x) \Big]u(x)=0 $$ $E&amp;lt;0$ 에너지가 퍼텐셜보다 작으면 해가 존재하지 않으므로 고려할 필요 없다.</description>
    </item>
    
    <item>
      <title>확장된 실수값을 갖는 함수가 가측함수가 될 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-that-a-extended-real-valued-function-will-be-a-measurable-function/</link>
      <pubDate>Sat, 24 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-that-a-extended-real-valued-function-will-be-a-measurable-function/</guid>
      <description>정리1 가층공간 $(X,\mathcal{E})$과 확장된 실수값을 갖는 함수 $f\ :\ X\rightarrow \overline{\mathbb{R}}$가 가측 함수가 될 필요충분조건은 다음과 같다. $$ f\text{ is measurable} \iff \begin{align} &amp;amp; \left\{ x \in X : f(x)=-\infty \right\} \in \mathcal{E} \label{eq1} \\ &amp;amp; \left\{ x \in X : \alpha &amp;lt; f(x) &amp;lt; +\infty \right\} \in \mathcal{E}\quad (\forall \alpha \in \mathbb{R}) \label{eq2} \end{align} $$ 위의 정리는 확장된 실수값을 갖는 함수가 가측인지를 판별할 때, 확장된</description>
    </item>
    
    <item>
      <title>스텝 함수와 펄스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/step-function-and-pulse-function/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/step-function-and-pulse-function/</guid>
      <description>정의 1 다음과 같이 정의된 $S_{t}^{(T)}$ 를 스텝 함수라 한다. $$ S_{t}^{(T)} := \begin{cases} 1 &amp;amp; , t \le T \\ 0 &amp;amp; , \text{otherwise} \end{cases} $$ 다음과 같이 정의된 $P_{t}^{(T)}$ 를 펄스 함수라 한다. $$ \begin{align*} P_{t}^{(T)} &amp;amp;:=&amp;amp; \nabla S_{t}^{(T)} \\ =&amp;amp; S_{t}^{(T)} - S_{t-1}^{(T)} \end{align*} $$ 설명 스텝 함수와 펄스 함수는 개입 분석에 쓰이는 수식을 나타내기에 유용한 함수들로써, 그 자체의 성질은 크게 의미가 없다. 스텝 함수는 말 그대로 그래프의 개형이 계단처럼 생겨서 붙인 것이고,</description>
    </item>
    
    <item>
      <title>R 에서 코드 실행 시간 재는 법, 벤치마크하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-benchmark-in-r/</link>
      <pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-benchmark-in-r/</guid>
      <description>개요 매트랩R 은 분명 통계 분석에 특화되어 있는 프로그래밍 언어지만, 모든 언어가 그러하듯 속도에 관심이 없는 것은 아니다. 속도가 강점이 아니라고 해도 벤치마킹은 할 수 있어야한다. R 에서는 간단하게도 코드 전문을 system.time({})에 넣어서 시간을 잴 수 있다. 예시 다음은 에라토스테네스의 체를 R 로 구현하고 $2*10^{5}$ 이하의 홀수를 30개</description>
    </item>
    
    <item>
      <title>확장된 실수 체계</title>
      <link>https://freshrimpsushi.github.io/posts/extended-real-number-system/</link>
      <pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/extended-real-number-system/</guid>
      <description>정의 다음과 같이 정의되는 집합을 확장된 실수 체계extended real number system라 한다. $$ \overline{ \mathbb{R} } := \mathbb{R} \cup \left\{ -\infty, +\infty\right\} $$ 설명 해석학 등의 분야에서 종종 편의를 위해 실수 집합 $\mathbb{R}$ 대신 $\overline{ \mathbb{R} }$를 사용한다. $\pm \infty$는 숫자가 아니지만 숫자라도 퉁치고 $\mathbb{R}$에 추가하여 사용하면 편하다. 확장된 실수 체계 안에서 대소 비교와</description>
    </item>
    
    <item>
      <title>개입 분석</title>
      <link>https://freshrimpsushi.github.io/posts/intervention-analysis/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/intervention-analysis/</guid>
      <description>빌드업 위 그래프는 실제 2015년 서울의 미세먼지 농도를 나타낸 시계열 데이터다. 누가 보더라도 가장 먼저 눈에 띄는 것은 50번째쯤, 그러니까 2월 말에 미세먼지 농도가 500을 넘긴 날이 있다는 점일 것이다. 데이터를 다루는데에 어느정도 익숙한 사람이라면 가장 먼저 잘못 관측된 것이 아닐까 의심하겠지만, 놀랍게도 실제로 일어난 일이었다. 아예 이</description>
    </item>
    
    <item>
      <title>보렐 시그마-대수, 보렐 가측 공간</title>
      <link>https://freshrimpsushi.github.io/posts/borel-sigma-algebra-borel-measurable-space/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/borel-sigma-algebra-borel-measurable-space/</guid>
      <description>정리 $X$를 임의의 집합이라 하자. 그리고 공집합이 아닌 $A \subset \mathcal{P}(X)$가 주어졌다고 하자. 그러면 $A$를 포함하는 가장 작은 $\sigma$-대수인 $\mathcal{E}_A$가 존재한다. 증명 $\mathcal{E}_A$를 정의해서 그게 $\sigma$-대수가 되는 것을 보인 뒤 가장 작다[^2]</description>
    </item>
    
    <item>
      <title>R 에서 ts 함수의 start, end 옵션과 window 함수에서 start, end 옵션의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/1242/</link>
      <pubDate>Tue, 20 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1242/</guid>
      <description>설명 R 로 시계열 데이터를 다루다보면 ts() 함수와 window() 함수를 자주 사용하게 된다. ts()는 R 이 받아들일 수 있도록 시계열 데이터를 만들 때 쓰고, window()는 시계열 데이터의 일부를 추출하는데 쓰인다. 두 함수 모두 start, end를 옵션으로 갖는데, 그 차이는 다음과 같다. ts() 내가 인덱스를 주기 위한 옵션이다. start: 시계열 데이터로 만들어질 데이터의 첫</description>
    </item>
    
    <item>
      <title>시계열회귀분석에서의 허위 상관관계</title>
      <link>https://freshrimpsushi.github.io/posts/spurious-correlation/</link>
      <pubDate>Mon, 19 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spurious-correlation/</guid>
      <description>정의 1 허위 상관관계는 두 데이터가 그럴싸한 상관관계를 가지는 것 같아 보이지만 실제로는 그렇지 않은 관계를 말한다. 실습 1 다음의 예시를 통해 알아보자. 위와 같이 두 가지 시계열 데이터가 주어져 있다고 하자. 언뜻 보기에 두 시계열은 강력한 상관관계를 가질 것만 같이 보인다. 시간에 따라 조금씩 증가하는 트렌드을 포함해서 계절성을 포함한 등락 패턴이 매</description>
    </item>
    
    <item>
      <title>R 에서 색 테두리 있는 점 찍는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-colorize-scatter-plot/</link>
      <pubDate>Sun, 18 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-colorize-scatter-plot/</guid>
      <description>코드 점 도표에서 테두리의 색을 바꾸거나 내부를 칠하기 위해서는 다음의 옵션들을 바꿔주면 된다: pch: 심볼을 바꿔서 색을 칠한다. 21번부터 25번까지를 사용하면 된다. bg: 백그라운드 컬러로써, 내부에 칠해지는 색을 결정한다. 위 그림에선 연두색이다. col: 심볼 그 자체의 컬러로써, 실제로는 테두리에 해당한다. 위 그림에선 빨간색이다. set.seed(150421) win.graph(4,4) plot(rnorm(10), pch=21, bg=&#39;green&#39;, col=&#39;red&#39;)</description>
    </item>
    
    <item>
      <title>매트랩에서 여러 그림 한 페이지에 출력하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/subplot-in-matlab/</link>
      <pubDate>Sat, 17 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subplot-in-matlab/</guid>
      <description>방법 subplot() 함수를 사용하면 여러 그림을 한 페이지에 출력할 수 있다. 첫번째, 두번째 변수는 각각 이미지를 출력할 바둑판의 행과 열을 나타내며 그림을 어떤 모양으로 배치할지를 결정한다. 세번째 변수는 해당그림을 몇 번에 배치할지 결정한다. 아래는 코드와 실제로 출력된 결과이다. X1=Phantom(); X2=radon(X1); X3=fft(X2); X4=iradon(X2,0:179); subplot(2,2,1) imagesc(X1) title(&amp;quot;Phantom&amp;quot;); subplot(2,2,2) imagesc(X2) title(&amp;quot;radon&amp;quot;); subplot(2,2,3) imagesc(abs(X3)) title(&amp;quot;fft&amp;quot;); subplot(2,2,4) imagesc(X4) title(&amp;quot;iradon&amp;quot;);</description>
    </item>
    
    <item>
      <title>사전백화</title>
      <link>https://freshrimpsushi.github.io/posts/prewhitening/</link>
      <pubDate>Sat, 17 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prewhitening/</guid>
      <description>정의 사전백화Prewhitening 란 CCF를 계산할 때 시계열을 백색잡음으로 만들어 두 데이터 간의 상관관계를 더욱 정확하게 파악하는 방법이다. 실습 1 가능하다면 이것이 어떻게 가능한지 수식적으로도 완전히 이해하는 것을 추천하는데, 우선은 예로써 다음의 데이터를 살펴보자. bluebird는 뉴질랜드에서 감자칩을 제조하는 회사인 블</description>
    </item>
    
    <item>
      <title>R 에서 파이프 오퍼레이터 %&gt;% 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/in-r/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/in-r/</guid>
      <description>개요 R 에서 %&amp;gt;%은 파이프 연산자Pipe Operater 로써, 다른 연산자가 모두 그러하듯 이항연산을 한다. 파이프 연산자는 이름 그대로 어떤 값들이 파이프를 통과하는 것처럼 함수와 함수들을 타고다닐 수 있게 해준다. 백마디 말보다 다음의 예시가 더 도움이 될 것이다. 예시 위의 예시는 $1$ 부터 $10$ 까지의 제곱근을 구하고 거기에 로그를 취한 뒤 그 중에서 중위수</description>
    </item>
    
    <item>
      <title>디리클레 경계 조건이 주어진 열방정식에 대한 초기값 문제의 수치해석적 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/numerical-solution-for-heat-equation-with-dirichlet-boundary-condition/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/numerical-solution-for-heat-equation-with-dirichlet-boundary-condition/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 대수적 풀이 $\begin{cases} u_{t} = \gamma u_{xx} \\ u(t,0) = u(t,l) = 0 \\ u(0,x) = f(x) \end{cases}$ 주어진 문제는 대수적 풀이가 있을 정도로 쉽고 간단하지만, 미분방정식을 푸는 방법으로써의 수치해석을 왜 배우는지 명쾌하게 알려주는 예시가 되기도 한다. 단순히 $y&#39; = f(x,y)$ 꼴의 미분방정식을 푸는 게 편미분방정식의 풀이로도 이어지는 것이다.**풀이</description>
    </item>
    
    <item>
      <title>룽게-쿠타 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/runge-kutta-method/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/runge-kutta-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} = Y_{0}$ 에 대해 $$ \displaystyle y_{n+1} = y_{n-1} + h \sum_{j=1}^{p} \gamma_{j} V_{j} $$ 룽게-쿠타 메소드 는</description>
    </item>
    
    <item>
      <title>A-스테이블</title>
      <link>https://freshrimpsushi.github.io/posts/a-stable/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/a-stable/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 미드포인트 메소드를 비롯한 멀티스텝 메소드는 $h$ 가 충분히 작지 않을 때 패러사이틱 솔루션이 있을 수 있다. 충분히 작지 않다는 건 $ y&#39; = \lambda y$ 와 같은 문제가 있을 때 $| 1 + h \lambda| &amp;lt;1$ 과 같은 조건을 만족하지 못하는 등의 경우를 말한다. $z : = h \lambda \in \mathbb{C}$ 라고 할 때 위의 조건을 복소평면 상에 나타내보면 아래의 그</description>
    </item>
    
    <item>
      <title>계단 함수 퍼텐셜에 대한 슈뢰딩거 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-schr%C3%B6dinger-equation-for-step-function-potential/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-schr%C3%B6dinger-equation-for-step-function-potential/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 위 그림과 같이 입자의 퍼텐셜이 계단 함수 모양으로 생겼을 때 어떻게 운동하는지 알아보자. 퍼텐셜 $U$는 $$ U(x) = \begin{cases} 0 &amp;amp; x&amp;lt;0 \\ U_0 &amp;amp; x&amp;gt;0 \end{cases} $$ 퍼텐셜이 $U(x)$일 때의 시간에 무관한 슈뢰딩거 방정식은 $$ \dfrac{d^2 u(x)}{dx^2}+\frac{2m}{\hbar ^2} \Big[ E-U(x) \Big]u(x)=0 $$ $E&amp;lt;0$ 에너지가 퍼텐셜보다 작으면 해가 존재하지 않으므로 고려할 필요 없다.■ $0 &amp;lt;</description>
    </item>
    
    <item>
      <title>교차상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/ccf-cross-correlation-functon/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ccf-cross-correlation-functon/</guid>
      <description>정의 1 $\left\{ X_{t} \right\}_{t=1}^{n}$, $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이라고 하자. 다음과 같이 정의된 $\rho_{k}$ 를 시차 $k$ 의 교차상관함수라고 한다. $$ \rho_{k} (X,Y) := \text{cor} \left( X_{t} , Y_{t-k} \right) = \text{cor} \left( X_{t+k} , Y_{t} \right) $$ 다음과 같이 정의된 $r_{k}$ 를 시차 $k$ 의 표본교차상관함수라고 한다. $$ r_{k} := {{ \sum \left( X_{t} - \overline{X} \right) \left( Y_{t-k} - \overline{Y} \right) } \over { \sqrt{ \sum \left( X_{t} - \overline{X} \right)^2 } \sqrt{ \left( Y_{t-k} - \overline{Y} \right)^2 } }} $$ 설명 교차상관함수는 두 시계열 데이터 간의 상관관계를 파악</description>
    </item>
    
    <item>
      <title>R 에서 오퍼레이터 %% 정의하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-define-binary-operator-in-r/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-define-binary-operator-in-r/</guid>
      <description>개요 R 에서는 함수를 정의할 때 아예 이항연산자로 정의할 수가 있다. 이미 R 에서 기본적으로 정의된 나눗셈의 나머지 %%, 몫 %/%, 내적 %*%, %o%나 포함관계 %in%, 그리고 파이프 연산자 %&amp;gt;% 등도 이러한 이항연산자에 속한다. 코드 가령 파이썬과 같은 언어에서는 문자열끼리 덧셈을 하면 문자열이 연결되기 때문에 아주 편한데, R 은 이에 비해서는 다소 불편한 감이 있다. 이</description>
    </item>
    
    <item>
      <title>엘피 공간이 균등하게 볼록하고 반사적임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-lp-space-is-uniformly-convex-and-reflexive/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-lp-space-is-uniformly-convex-and-reflexive/</guid>
      <description>정리1 $1 \lt p \lt \infty$라고 하자. 그러면 $L^{p}$ 공간은 균등하게 볼록하고 반사적이다. 설명 균등하게 볼록함의 정의와 클락슨 부등식을 이용해서 증명할 수 있다. 클락슨 부등식 덕분에 쉽고 짧게 증명이 끝난다. 필살기 같은 느낌임. 균등하게 볼록 놈 공간 $X$상의 놈 $| \cdot |$이 아래의 조건을 만족하면 놈과 놈 공간 $X$를 균등하게 볼록하다고 말한</description>
    </item>
    
    <item>
      <title>일관성을 가지는 멀티스텝 메소드의 수렴성과 루트 컨디션</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-and-root-condition-of-multi-step-method-with-consistency/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-and-root-condition-of-multi-step-method-with-consistency/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 멀티스텝 메소드가 일관성을 가진다고 하자.메소드는 수렴성을 가진다 $\iff$ 메소드는 루트 컨디션을 만족 시킨다 폐구간 $[x_{0} , b]$ 에 대해 $h$ 를 단위로 잘라서 노드 포인트를 만들 때, $x_{0} \le x_{1} \le \cdots \le x_{N(h) -1} \le x_{N(h) } \le b$ 라고 하자. 여기서 $N(h)$ 는 $h$ 에 따라 변하는 마지막 노드 포인트의 인덱스를 나타낸다.메소드가 수렴</description>
    </item>
    
    <item>
      <title>시계열 회귀 분석</title>
      <link>https://freshrimpsushi.github.io/posts/time-series-regression-analysis/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-series-regression-analysis/</guid>
      <description>정의 시계열 회귀 분석이란 말 그대로 시계열 데이터로 회귀분석하는 기법을 말한다. 원래 회귀분석 자체가 시계열 데이터를 다루는데 있어서 적합하지 않은 것은 사실이지만, 그럼에도 불구하고 복수의 시계열 데이터를 다룰 때는 회귀분석의 아이디어와 툴을 빌리는 것이 좋을 때가 있다. 실습 가령 위와 같이 두 종류의 데이터 x와 y가 주어져있다고 하자. 물론 두 데</description>
    </item>
    
    <item>
      <title>파동함수의 반사와 투과</title>
      <link>https://freshrimpsushi.github.io/posts/reflection-and-transmission-of-wave-function/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reflection-and-transmission-of-wave-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **반사계수와 투과계수$(\mathrm{Reflection\ coefficient})$ 파동 함수의 반사계수(반사율)와 투과계수(투과율)는 다음과 같이 나타낼 수 있다. $$ R=\left| \frac{j_{ref}}{j_{inc}} \right|,\quad T=\left| \frac{j_{trans}}{j_{inc}}\right| $$ 이때 $j$는 확률 흐름이다. $inc$는 입사$(\mathrm{incident})$를 의미한다. $R$, $</description>
    </item>
    
    <item>
      <title>륭-박스 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/ljung-box-test/</link>
      <pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ljung-box-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 R 에서 륭-박스 테스트 하는 법 시계열 분석으로 얻은 아르마 모형 $ARMA(p,q)$ 을 $M$ 이라고 하자. $H_{0}$ : $M$ 은 적합하다. $H_{1}$ : $M$ 은 적합하지 않다. 륭-박스 테스트 는 LBQ 라고도 줄여부르기도 하며, 아리마 모형의 적합성을 판별하는 검정이다.1970년 박스Box와 피어스Pierce는 아리마 모형으로 얻은 잔</description>
    </item>
    
    <item>
      <title>확률 흐름 밀도</title>
      <link>https://freshrimpsushi.github.io/posts/probability-current-dsnsity/</link>
      <pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-current-dsnsity/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **확률 흐름 밀도$(\mathrm{probability\ current\ dsnsity})$ 파동함수 $\psi (x, t)$의 확률 흐름 밀도는 아래와 같이 정의된다. $$ j(x,t):=\frac{\hbar}{2mi}\left( \psi^{\ast}\dfrac{\partial \psi}{\partial x} - \psi\frac{\partial \psi^{\ast}}{\partial x}\right) $$ 확률 흐름이라고도 한다. 유도 확률 흐름 밀도는 자유 입자의 슈뢰딩거 방정식으로부터 이끌어낼 수 있다. $$ i \hbar \frac{\partial \psi(x,t)}{\partial t} = -\frac{\hbar^2}{2m}\frac{\partial ^2 \psi(x,t)}{\partial x^2} \quad \cdots (1)</description>
    </item>
    
    <item>
      <title>아리마 모형에 대한 잔차분석</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-tsdiag-plots-in-r/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-tsdiag-plots-in-r/</guid>
      <description>설명 회귀분석과 마찬가지로 시계열 분석 역시 잔차분석을 한다. 아리마 모형의 가정에 따르면 잔차는 모두 백색잡음이므로 선형성, 등분산성, 독립성, 정규성을 따르는지 확인은 할 것이다. 회귀분석과 비교하자면 전반적으로 그렇게까지 엄격하지는 않으나, 독립성 하나만큼은 철저하게 체크한다. 애초에 시계열분석 자체가 자기상관성을 파악하기 위한 것</description>
    </item>
    
    <item>
      <title>양자역학에서의 그람-슈미트 직교화 과정</title>
      <link>https://freshrimpsushi.github.io/posts/gram-schmidt-orthogonalization-procedure/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gram-schmidt-orthogonalization-procedure/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 수학에서의 그람-슈미트 직교화 **그람-슈미트 직교화 과정$(\mathrm{Gram-schmidt\ orthogonalization\ procedure})$ $A$를 임의의 에르미트 연산자라 하자. 그리고 규격화된 시간에 무관한 두 1차원 파동함수 $u_1$, $u_2$가 축퇴돼있다고 하자. $$ Au_1=au_1 $$ $$ Au_2=au_2 $$ 이 때 $u_1$과 직교하는 새로</description>
    </item>
    
    <item>
      <title>더빈-왓슨 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/durbin-watson-test/</link>
      <pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/durbin-watson-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 개요 회귀분석을 한 이후의 잔차 $\left\{ e_{t} \right\}_{t=1}^{n}$ 가 주어져있다고 하고 $e_{t} := \rho e_{t-1} + \nu_{t}$ 이라 하자. $H_{0}$ : $\rho = 0$ 즉, 잔차끼리 자기상관성을 가지지 않는다. $H_{1}$ : $\rho \ne 0$ 즉, 잔차끼리 자기상관성을 가진다. 더빈-왓슨 테스트 는 회귀분석 후 잔차의 독립성을 확인할 때 쓰이는 테스트로써, 잔차끼리 자기상관성이 있는</description>
    </item>
    
    <item>
      <title>R 에서 EACF를 사용한 ARMA 모형 선택법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-determine-arma-model-using-eacf-in-r/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-determine-arma-model-using-eacf-in-r/</guid>
      <description>실습 1 PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다.직접 그 예를 살펴보자. ma1.2.s 데이터는 $MA(1)$ 모델에서, ar1.s 데이터는 $AR(1)$ 모델에서 나온 TSA 패키지의 샘플 데이터다. TSA 패키지의 acf() 함수와 pacf() 함수를 사용하면 다음과 같이 여러 시차 $k$ 에 대해 코릴로그램Correlogram을 그려준다. 그림만 봤을 때 파란 선을 넘어가는</description>
    </item>
    
    <item>
      <title>자연스러운 임베딩과 반사적인 공간</title>
      <link>https://freshrimpsushi.github.io/posts/natural-embedding-and-reflexive-space/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/natural-embedding-and-reflexive-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 ※ 놈 공간 $X$의 놈을 $| \cdot |_X$ 또는 $| x\ ;X|$로 표기한다. 헷갈릴 여지가 없을 경우에는 $| \cdot |$로 표기할 수도 있다. 자연스러운 임베딩$(\mathrm{natural\ embedding})$ $X$를 놈 공간이라고 하자. 그리고 $X^{}$를 $X$의 바이듀얼이라고 하자. 그리고 $X$에서부터 $</description>
    </item>
    
    <item>
      <title>일관성을 가지는 멀티스텝 메소드의 안정성과 루트 컨디션</title>
      <link>https://freshrimpsushi.github.io/posts/stability-and-root-condition-of-multi-step-method-with-consistency/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stability-and-root-condition-of-multi-step-method-with-consistency/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 멀티스텝 메소드가 일관성을 가진다고 하자.메소드는 안정성을 가진다 $\iff$ 메소드는 루트 컨디션을 만족 시킨다 폐구간 $[x_{0} , b]$ 에 대해 $h$ 를 단위로 잘라서 노드 포인트를 만들 때, $x_{0} \le x_{1} \le \cdots \le x_{N(h) -1} \le x_{N(h) } \le b$ 라고 하자. 여기서 $N(h)$ 는 $h$ 에 따라 변하는 마지막 노드 포인트의 인덱스를 나타낸다.원래 주어진 초</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드의 루트 컨디션</title>
      <link>https://freshrimpsushi.github.io/posts/root-conditions-of-multistep-method/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/root-conditions-of-multistep-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 멀티스텝 메소드$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) ) = (Y_{0}, \cdots , Y_{p} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값과 $0 \le p \le m$ 에 대</description>
    </item>
    
    <item>
      <title>한-바나흐 확장 정리</title>
      <link>https://freshrimpsushi.github.io/posts/hahn-banach-extension-theorem/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hahn-banach-extension-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 ※ 놈 공간 $X$의 놈을 $| \cdot |_X$ 또는 $| x ;X|$로 표기한다. 헷갈릴 여지가 없을 경우에는 $| \cdot |$로 표기할 수도 있다. **한-바나흐 확장 정리$(\mathrm{ Hahn-Banach\ extension\ theorem})$ $X$는 놈 공간이고 $Y \subset X$라고 하자. 그리고 $Y$의 선형 범함수 $y^{\ast} \in Y^{\ast}$가 주어졌다고 하자. 그</description>
    </item>
    
    <item>
      <title>확장자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/eacf-extended-autocorrelation-function/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eacf-extended-autocorrelation-function/</guid>
      <description>빌드업 PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다. 하지만 $ARMA(p,q)$ 모형에 적용시킬 땐 아르마 모형의 가역성 때문에 $AR(p)$ 라도 $MA(\infty)$ 처럼 보일 수 있고, $MA(q)$ 라도 $AR(\infty)$ 처럼 보일 수 있다. 따라서 이러한 문제를 회피하고 아르마 모형을 찾기위한 여러가지 방법이 고안되었다. 정의 확장자기상관함수 는 그 중의 한 방법으로, 다음과 같이 정의</description>
    </item>
    
    <item>
      <title>실수 복소수 세미 놈에 대한 한-바나흐 정리</title>
      <link>https://freshrimpsushi.github.io/posts/hahn-banach-theorem-for-real-complex-semi-norm/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hahn-banach-theorem-for-real-complex-semi-norm/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 ※ 놈 공간 $X$의 놈을 $| \cdot |_X$ 또는 $| \cdot\ ;X|$로 표기한다. 헷갈릴 여지가 없을 경우에는 $| \cdot |$로 표기할 수도 있다. 실수에 대한 한-바나흐 정리$(\mathrm{ Hahn-Banach\ theorem\ real\ version})$ $X$는 $\mathbb{R}$-벡터 공간이고 $Y \subset X$라고 하자. $p\ :\ X \rightarrow \mathbb{ R}$를 준선형 범함수라고</description>
    </item>
    
    <item>
      <title>아담스 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/adams-method/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adams-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 멀티스텝 메소드$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) ) = (Y_{0}, \cdots , Y_{p} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값과 $0 \le p \le m$ 에 대</description>
    </item>
    
    <item>
      <title>편자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/pacf-partial-autocorrelation-function/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pacf-partial-autocorrelation-function/</guid>
      <description>정의 1 $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이고 시차 $k$ 에 대해서 $Y_{t-1}, \cdots , Y_{t-(k-1)}$ 로 $Y_{t}$ 를 회귀분석한 잔차를 $\widehat{e_{t}}$, $Y_{t-k}$ 를 회귀분석한 잔차를 $\widehat{e_{t-k}}$ 이라고 하자. 다음과 같이 정의된 $\phi_{kk}$ 를 시차 $k$ 의 편자기공분산함수라고 한다. $$ \phi_{kk} := \text{cor} ( \widehat{e_{t}} , \widehat{e_{t-k}} ) $$ 다음과 같이 정의된 $\phi_{kk}$ 를 시차 $k$ 의 표본편자기공분산함수라고 한다. $$ \widehat{ \phi_{kk} } := {{ r_{k} - \sum_{j=1}^{k-1} \phi_{(k-1),j} r_{k-j} } \over { 1 - \sum_{j=1}^{k-1} \phi_{(k-1),j} r_{j} }} \\ \phi_{k,j} := \phi_{(k-1),j} - \phi_{kk} \phi_{(k-1),(k-j)} $$ $r_{k}$ 는 시</description>
    </item>
    
    <item>
      <title>거리공간에서 위상동형이란</title>
      <link>https://freshrimpsushi.github.io/posts/homeomorphism/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homeomorphism/</guid>
      <description>정의 두 거리공간 $\left( X, d_{1} \right)$ 과 $\left( Y, d_{2} \right)$ 에 대해 전단사 $f : X \to Y$ 가 존재해서 $f$ 와 그 역함수 $f^{-1}$ 모두 연속함수면 $f$ 를 위상동형사상이라 부르고 두 거리공간이 위상동형Homeomorphic이라 한다. 설명 거리공간에 대한 위상동형의 정의는 언뜻 공허해보인다. 물론 그도 그럴게, 거리공간 자체가 충분히 좋은 공간인데다가 두 거리공간이 위상동형임을</description>
    </item>
    
    <item>
      <title>리차드슨 오차 추정</title>
      <link>https://freshrimpsushi.github.io/posts/richardson-error-estimation/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/richardson-error-estimation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 미분방정식을 푸는 메소드의 퍼포먼스를 확인하는 방법으로 참값과 비교할 수 있다면 가장 좋겠지만, 당장 참값을 구하기 귀찮은 경우부터 시작해서 아예 트루 솔루션을 구하기 곤란한 경우도 많다. 이땐 $y_{h} (x_{n} )$ 과 스탭사이즈 $h$ 를 두배로 늘렸을 때의 $y_{2h} (x_{n} )$ 을 비교함으로써 오차를 추정할 수 있다. 예를 들어 사</description>
    </item>
    
    <item>
      <title>세미 놈 서브 리니어</title>
      <link>https://freshrimpsushi.github.io/posts/seminorm-sublinear/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/seminorm-sublinear/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 세미 놈$(\mathrm{ semi\ norm}$, 반놈$)$ $X$를 벡터 공간이라고 하자. 아래의 세 조건을 만족하는 함수 $| \cdot | \ :\ X \rightarrow \mathbb{R}$가 존재하면 $| \cdot |$를 $X$의 놈이라 한다.$(a)$ $| x| \ge 0,\quad \forall\ x \in X $$ (b)$ $|cx|=|c||x|,\quad \forall\ x\in X,\ \forall\ c \in\mathbb{C} $$ (c)$ $| x+y| \le |x| + |y|,\quad \forall\ x,y\in X$ 놈의 정의에서 $|x |=0 \iff</description>
    </item>
    
    <item>
      <title>실수 공간에서 정의된 함수의 미분</title>
      <link>https://freshrimpsushi.github.io/posts/differential-in-real-space/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/differential-in-real-space/</guid>
      <description>정의1 $a$ 를 포함하는 어떤 $E$ 에서 $f$ 가 정의되어있고 극한 $$ f&#39;(a) := \lim_{h \to 0} {{ f (a + h ) - f(a) } \over { h }}=\lim \limits_{x\rightarrow a}\frac{f(x)-f(a)}{x-a} $$ 이 존재하면 $f$ 가 $a$ 에서 미분가능differentiable하다고 하고, $f&#39;(a)$ 를 $a$ 에서 $f$ 의 미분계수라 한다. $f&#39;$를 $f$ 의 도함수derivative라 부른다. 설명 해석학을 공부함에 있어 가장 반가운 것이 바로 미분이다. 왜냐하면</description>
    </item>
    
    <item>
      <title>사다리꼴 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/trapezoidal-method/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trapezoidal-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} = Y_{0}$ 에 대해 $$ \displaystyle y_{n+1} = y_{n-1} + {{h} \over {2}} [ f ( x_{n} , y_{n} ) + f ( x_{n+1}</description>
    </item>
    
    <item>
      <title>엘피 공간에 대한 리즈 표현 정리</title>
      <link>https://freshrimpsushi.github.io/posts/riesz-representation-theorem-for-lp-space/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riesz-representation-theorem-for-lp-space/</guid>
      <description>정리1 ${L}^{\ p}$공간에 대한 리즈 표현 정리 $1&amp;lt;p&amp;lt;\infty$이고 $L\in \big( {L}^{\ p} \big)^{\ast}$라고 하자. 이때 $({L}^{\ p})^{\ast}$는 ${L}^{\ p}$ 공간의 듀얼이다. 그러면 모든 $u\in {L}^{\ p}$에 대해서 아래의 식을 만족하는 $v \in {L}^{\ p^{\prime}}$가 존재한다. $$ L(u)=L_v(u)=\int_{\Omega} u(x)v(x)dx $$ 설명 $p=1$인 경우를 포함하지 않음</description>
    </item>
    
    <item>
      <title>자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/acf-autocorrelation-function/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/acf-autocorrelation-function/</guid>
      <description>정의 1 $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이라고 하자. $\mu_{t} := E ( Y_{t} )$ 를 평균함수라고 한다. 다음과 같이 정의된 $\gamma_{ t , s }$ 를 자기공분산함수라고 한다. $$ \gamma_{t , s} : = \text{cov} ( Y_{t} , Y_{s} ) = E ( Y_{t} - \mu_{t} ) E ( Y_{s} - \mu_{s} ) $$ 다음과 같이 정의된 $\rho_{ t , s }$ 를 자기상관함수라고 한다. $$ \displaystyle \rho_{ t , s } := \text{cor} ( Y_{t} , Y_{s} ) = {{ \gamma_{t , s} } \over { \sqrt{ \gamma_{t , t} \gamma_{s , s} } }} $$ 다음과 같이 정의된</description>
    </item>
    
    <item>
      <title>모든 등거리 사상은 임베딩이 됨을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-isometic-map-is-imbedding/</link>
      <pubDate>Sat, 03 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-isometic-map-is-imbedding/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 두 놈 공간 $X$, $Y$가 있다고 하자. 그리고 $f\ :\ X \rightarrow Y$를 등거리 사상이라고 하자. 그러면 $f$는 임베딩이다. 다시 말해 아래의 두 조건을 만족한다$(a)$ $f(X) \subset Y $$ (b)$ $f\ :\ X \rightarrow f(X)$가 위상동형사상$(\mathrm{homeomorphsim})$이다. $(b)$를 먼저</description>
    </item>
    
    <item>
      <title>함수의 균등연속</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-continuous/</link>
      <pubDate>Sat, 03 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-continuous/</guid>
      <description>정의1 공집합이 아닌 $E \subset \mathbb{R}$ 에 대해 $f : E \to \mathbb{R}$ 이라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ | x_{1} - x_{2} | &amp;lt; \delta \land x_{1} , x_{2} \in E \implies | f(x_{1}) - f(x_{2}) | &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $f$ 가 $E$ 상에서 균등연속uniformly continuous이라 한다. $\land$ 는 논리적으로 &amp;lsquo;그리고&amp;rsquo;를 나타내는 기호다. 설명 함수의 연속성 그 자체는 $a \in E$</description>
    </item>
    
    <item>
      <title>놈 공간이란</title>
      <link>https://freshrimpsushi.github.io/posts/normed-space/</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normed-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **놈 공간 $X$를 벡터 공간이라고 하자. 아래의 세 조건을 만족하는 함수 $| \cdot | \ :\ X \rightarrow \mathbb{R}$가 존재하면 $| \cdot |$를 $X$의 놈 이라하고 $(X,| \cdot | )$를 놈 공간 이라 한다.$(a)$ $| \mathbf{x}| \ge 0,\quad \forall\ \mathbf{x} \in X$이고 $| \mathbf{x} |=0 \iff \mathbf{x}=\mathbf{0} $$ (b)$ $|c\mathbf{x}|=|c||\mathbf{x}|,\quad \forall\ \mathbf{x}\in X,\ \forall\ c \in\mathbb{C} $$ (c)$ $| \mathbf{x}+\mathbf{y}| \le |\mathbf{x}| + |\mathbf{y}|,\quad \forall\ \mathbf{x},\mathbf{y}\in X$놈 공</description>
    </item>
    
    <item>
      <title>아르마 모형의 가역성</title>
      <link>https://freshrimpsushi.github.io/posts/invertivility-of-arma-model/</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/invertivility-of-arma-model/</guid>
      <description>정의 1 아르마 모형에 있어서 가역성을 가졌다 함은 $AR(p)$ 와 $MA(q)$ 가 서로를 표현할 수 있음을 말한다. 예시 일반적인 $ARMA ( p , q)$ 에 대한 수식전개는 아니지만, $AR(1)$ 과 $MA(1)$ 의 예를 살펴보자. 자기회귀모형 $AR(1) \implies MA( \infty )$ $| \phi | &amp;lt; 1$ 에 대해서 다음의 자기회귀모형 $AR(1)$ 을 생각해보자. $$ Y_{t} = \phi Y_{t-1} + e_{t} $$ $Y_{t-1}$ 역시 $Y_{t-1} = \phi Y_{t-2} + e_{t-1}$ 와 같이 나타낼 수 있으므로 $$ \begin{align*} Y_{t} =&amp;amp; \phi ( \phi Y_{t-2} + e_{t-1} )</description>
    </item>
    
    <item>
      <title>패러사이틱 솔루션</title>
      <link>https://freshrimpsushi.github.io/posts/parasitic-solution/</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/parasitic-solution/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 패러사이틱 솔루션Parasitic Solution 이란 직역했을 때 &amp;lsquo;기생하는 해&amp;rsquo;라는 뜻으로 메소드가 진행될수록 크기가 커지며 부호가 바뀌는 등의 항을 말한다. $a_{n} = 2^{-n} + (-2)^{n}$ 이라는 수열이 $ (-2)^{n}$ 때문에 수렴하지 않는 걸 상상하면 좋다. 이런 항에다 &amp;lsquo;패러사이틱&amp;r</description>
    </item>
    
    <item>
      <title>대학교 수학에서 새롭게 정의되는 함수의 연속</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-continuity-of-function-in-analysis/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-continuity-of-function-in-analysis/</guid>
      <description>정의 공집합이 아닌 $E \subset \mathbb{R}$ 에 대해 $f : E \to \mathbb{R}$ 이라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ | x - a | &amp;lt; \delta \implies | f(x) - f(a) | &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $f$ 가 $a \in E$ 에서 연속continuous이라 하고, $E$ 의 모든 점에서 연속이면 $f$ 를 연속함수continuous function라 한다. 설명 고등학교에서 연속을 정의할 때 함수값 $f(a)$ 가 존재한다. 극</description>
    </item>
    
    <item>
      <title>미드포인트 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/midpoint-method/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/midpoint-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ), y (x_{1}) ) = ( Y_{0} , Y_{1} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 를 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} = Y_{0}$ 에 대해 $$ y_{n+1} := y_{n-1} + 2 h f ( x_{n} , y_{n}</description>
    </item>
    
    <item>
      <title>소볼레프 공간은 분리가능하고 균등 볼록이고 반사적임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-sobolev-space-is-separable-uniformly-convex-and-reflexive/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-sobolev-space-is-separable-uniformly-convex-and-reflexive/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $1\le p &amp;lt;\infty$일 때, 소볼레프 공간 $W^{m,\ p}$는 분리가능 하다. 또한 $1&amp;lt; p &amp;lt; \infty$일 때, 소볼레프 공간은 반사적 이고 균등 볼록하다. 증명에 사용할 보조 정리를 소개한다. **보조정리 1 $(X, d)$를 거리공간이라고 하자. $(Y,d&#39;)$를 완비거리공간$(\mat</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 예측하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-predict-with-arima-model-in-r/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-predict-with-arima-model-in-r/</guid>
      <description>실습 R 내장데이터 UKDriverDeaths는 1969년부터 1984년까지 영국 월별 운전자 사상자에 대한 데이터다. 언뜻 보아도 계절형 아리마 모형을 따르고, 실제로 모형을 찾아내는것은 별로 어렵지 않다. 그러나 최종적으로 얻은 모형으로 식을 직접 써서 계산하는 것은 무척 손이 많이 가고 복잡한 일이다. 따라서 predict() 함수를 사용한다. n.ahead 옵션을</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드의 수렴성과 오차</title>
      <link>https://freshrimpsushi.github.io/posts/error-and-stability-analysis-for-multi-step-method/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/error-and-stability-analysis-for-multi-step-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) )= ( Y_{0} , \cdots , Y_{p} ) \end{cases}$ 에 대해 멀티스텝 메소드 $\displaystyle y_{n+1} = \sum_{j=0}^{p} a_{j} y_{n-j} + h \sum_{j = -1}^{p} b_{j} f (x_{n-j} , y_{n-j} )$ 가 일관성을 가지고, 초기 오차 $\displaystyle \eta (h) : = \max_{ 0 \le i \le p} | Y (x_{i} ) - y_{h} (x_{i} ) |$ 가 $\displaystyle \lim_{ h \to 0} \eta (h) = 0$ 를 만족하고, $j = 0, 1, \cdots , p$ 에 대해 $a_{j} \ge 0$ 이고 $f$ 가 립시츠 조건을 만</description>
    </item>
    
    <item>
      <title>소볼레프 공간은 바나흐 공간임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-sobolev-space-is-banach-space/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-sobolev-space-is-banach-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소볼레프 공간 $W^{m,\ p}$는 바나흐 공간이다. 놈이 정의되고 완비 인 공간을 바나흐 공간이라 한다. 소볼레프 공간을 정의할 때 놈도 같이 정의했으므로 완비인 것만 확인하면 된다. 따라서 $W^{m,\ p}$안의 코시 수열이 $W^{m,\ p}$안에서 수렴함을 보이면 된다. 증명은 어렵지 않은 편이다. $W^{m,\ p}(\Omega):=\left\{ u \in L^p(\Omega)\ :\ D^\alpha u \in L^p(\Omega),\</description>
    </item>
    
    <item>
      <title>소볼레프 놈과 소볼레프 공간</title>
      <link>https://freshrimpsushi.github.io/posts/sobolev-norms-and-sobolev-spaces/</link>
      <pubDate>Tue, 30 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sobolev-norms-and-sobolev-spaces/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $L^p$ 공간은 유용한 성질을 가지는 중요한 공간이지만 미분 방정식을 풀기에는 조금 부족하다. $u \in L^p$라는 사실을 알아도 $D^{\alpha}u$가 $L^p$ 공간에 속하는지 아닌지에 대해서는 여전히 알 수 없기 때문이다. 따라서 $L^p$ 공간 보다 더 좋은 공간에 대해서 생각할 필요가 있고 그것이 바로 소볼레</description>
    </item>
    
    <item>
      <title>입실론-델타 논법</title>
      <link>https://freshrimpsushi.github.io/posts/epsilon-delta-argument/</link>
      <pubDate>Tue, 30 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/epsilon-delta-argument/</guid>
      <description>정의1 $I$ 가 $a \in \mathbb{R}$ 를 포함하는 구간이고, $f$ 는 $I \setminus \left\{ a \right\}$ 에서는 정의된 함수라고 하자. 모든 $\epsilon &amp;gt; 0$ 에 대해 $$ 0 &amp;lt; | x - a | &amp;lt; \delta \implies | f(x) - L | &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $x \to a$ 일 때 $f(x)$ 가 $L \in \mathbb{R}$ 로 수렴한다converge고 한다. 설명 입실론-델타 논법의 이름은 보다시피 정의에 등장하는 입실론 $\varepsilon$ 과 델타 $\delta$ 에서 따온 것이다. 이는 &amp;lsq</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 얻은 시계열 분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-arima-model-summary-in-r/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-arima-model-summary-in-r/</guid>
      <description>실습 R 내장데이터 AirPassenger는 1949년부터 1960년까지 월별 항공기의 승객 수에 대한 데이터다. (1) 모형: 사실 계수만 제대로 파악할 수 있다면 중요한 것은 아니다. 계절형 아리마 모형 $ARIMA(p,d,q)\times(P,D,Q)_{s}$ 을 나타낸다. 예로써 위 분석의 결과인 ARIMA(0,1,1)(0,1,1)[12]는 $ARIMA(0,1,1)\times(0,1,1)_{12}$ 를 의미한다. (2) 계수: 모형에 맞는 계수를 나타</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드의 일관성과 수렴차수</title>
      <link>https://freshrimpsushi.github.io/posts/consistency-and-convergence-order-of-multistep-method/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/consistency-and-convergence-order-of-multistep-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) )= ( Y_{0} , \cdots , Y_{p} ) \end{cases}$ 에 대해 멀티스텝 메소드 $\displaystyle y_{n+1} = \sum_{j=0}^{p} a_{j} y_{n-j} + h \sum_{j = -1}^{p} b_{j} f (x_{n-j} , y_{n-j} )$ 가 일관성을 가지는 필요충분조건은 (i) 이고, 수렴차수 $m \in \mathbb{N}$ 을 갖는 필요충분조건은 (ii) 다. (i): $\begin{cases} \displaystyle \sum_{j = 0}^{p} a_{j} = 1 \\ \displaystyle - \sum_{j = 0}^{p} j a_{j} + \sum_{j = -1}^{p} b_{j} = 1 \end{cases}$ (ii): $\displaystyle \sum_{j=0}^{p} (-j)^{i} a_{j} + i \sum_{j=-1}^{p} (-</description>
    </item>
    
    <item>
      <title>리미트 슈프리멈과 리미트 인피멈</title>
      <link>https://freshrimpsushi.github.io/posts/limit-supremum-and-limit-infimum/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-supremum-and-limit-infimum/</guid>
      <description>정의 $\left\{ x_{n} \right\}_{n \in \mathbb{N}}$, $\left\{ y_{n} \right\}_{n \in \mathbb{N}}$ 이 실수열이라고 하자. $\displaystyle \limsup_{n \to \infty} x_{n} := \lim_{n \to \infty} \left( \sup_{k \ge n} x_{k} \right)$ 을 $\left\{ x_{n} \right\}$ 의 리미트 슈프리멈limit supremum이라 한다. $\displaystyle \liminf_{n \to \infty} y_{n} := \lim_{n \to \infty} \left( \inf_{k \ge n} y_{k} \right)$ 을 $\left\{ y_{n} \right\}$ 의 리미트 인피멈limit infimum이라 한다. 여기서 $\displaystyle \sup_{k \ge n} x_{k} := \sup \left\{ x_{k} : k \ge n \right\}$ 그리고 $\displaystyle \inf_{k \ge n} x_{k} := \inf \left\{ x_{k} : k \ge n \right\}$ 이다. 성질 (a)</description>
    </item>
    
    <item>
      <title>임베딩 넣기사상</title>
      <link>https://freshrimpsushi.github.io/posts/imbedding-embedding/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/imbedding-embedding/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 ※ imbedding과 embedding은 같은 말이다.※ 임베딩은 매장, 매입, 넣기, 묻기 등으로 번역한다. $X$, $Y$가 놈드 스페이스라고 하자. 아래의 두 조건을 만족할 때 연속사상 $f\ :\ X \rightarrow Y$를 임베딩$(\mathrm{imbedding\ or\ embedding}$, 넣기 사상$)$ 이라 한다. 또</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 시계열 분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-arima-model-in-r/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-arima-model-in-r/</guid>
      <description>실습 R에서 내장데이터 WWWusage 를 불러와 그래프를 그려 확인해보자. WWWusage는 먼 옛날 인터넷에 접속하는 이용자수를 나타내는 시계열 데이터로써, 그 추이를 파악하기 위해서는 시계열 분석을 해야한다. 시계열 분석에서 가장 대표적인 모형은 아리마 모형이나, 같은 아리마 모형이라고 해도 실제로 적절한 모형을 찾아내는 방법은 여러가지가 있다. 다행</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/multistep-method/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multistep-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) ) = (Y_{0}, \cdots , Y_{p} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값과 $0 \le p \le m$ 에 대해 $a_{p} \ne 0$ 혹은 $b_{p} \ne</description>
    </item>
    
    <item>
      <title>역방향 민코프스키 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/reverse-minkowski-inequality/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reverse-minkowski-inequality/</guid>
      <description>정리1 $\Omega \subset \mathbb{R}^{n}$를 열린 집합, $0 \lt p \lt 1$이라고 하자. 만약 $u, v \in L^p(\Omega)$이면 $u+v \in L^p(\Omega)$이고 $$ \| \left| u \right| + \left| v \right| \|_{p} \ge \| u \|_{p} + \| v \|_{p} $$ 이를 역방향 민코프스키 부등식reverse Minkowski&amp;rsquo;s inequality이라 한다. 설명 $$ \left\| u \right\|_{p} := \left( \int_{\Omega} \left| u(x) \right|^{p} dx \right)^{1/p},\quad u\in L^{p}(\Omega) $$ 민코프스키</description>
    </item>
    
    <item>
      <title>역방향 횔더 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/reverse-hoelders-inequality/</link>
      <pubDate>Thu, 25 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reverse-hoelders-inequality/</guid>
      <description>정리1 $\Omega \subset \mathbb{R}^{n}$를 열린 집합이라고 하자. $0 &amp;lt; p &amp;lt; 1$이고 $p^{\prime} = \dfrac{p}{p-1} &amp;lt; 0$라고 하자. 만약 $u \in L^{p}(\Omega)$, ${uv\in L^{1}(\Omega)}$이고 $$ \begin{equation} 0 \lt \int_{\Omega} |v(x)|^{p^{\prime}}dx \lt \infty \end{equation} $$ 이면, 아래의 부등식이 성립한다. $$ \int_{\Omega} |u(x)v(x)|dx \ge \left( \int_{\Omega} |u(x)|^{p} dx \right)^{1/p} \left( \int_{\Omega} |v(x)|^{p^{\prime}} dx \right) ^{1/p^{\prime}} $$ 이를 역방향 횔더 부등식reverse Höelder&amp;rsquo;s ineq</description>
    </item>
    
    <item>
      <title>초기값이 조금 달라졌을 때 오일러 메소드의 오차</title>
      <link>https://freshrimpsushi.github.io/posts/error-analysis-for-euler-methods-with-perturbed-initial-valued/</link>
      <pubDate>Thu, 25 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/error-analysis-for-euler-methods-with-perturbed-initial-valued/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $[x_{0} , b] \times \mathbb{R}$ 에서 정의된 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 의 해 $Y(x)$ 가 $Y \in C^{3} [ x_{0} , b ]$ 이고 $\displaystyle f_{y} (x,y) = {{ \partial f (x,y) } \over { \partial y }}$ 와 $\displaystyle f_{yy} (x,y) = {{ \partial^{2} f (x,y) } \over { \partial y^{2} }}$ 가 연속이면서 바운디드라고 하자. 초기값 $y_{h} (x_{0} )$ 가 $Y_{0} - y_{h} (x_{0} ) = \delta_{0} h + O ( h^2 )$ 을 만족시킨다고 하자. 그러면 오일러 메소드</description>
    </item>
    
    <item>
      <title>코시 수열</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-sequence/</link>
      <pubDate>Thu, 25 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-sequence/</guid>
      <description>정의 모든 $\varepsilon &amp;gt; 0$ 에 대해서 $n , m \ge N \implies | x_{n} - x_{m} | &amp;lt; \varepsilon$ 를 만족하는 $N \in \mathbb{N}$ 이 존재하면 수열 $\left\{ x_{n} \right\}_{n \in \mathbb{N}}$ 이 코시Cauchy라 한다. 정리 $\mathbb{R}$ 에서 코시 수열과 수렴하는 수열은 동치다. 설명 세상에 발산하면서도 중요한 수열은 별로 없다는 점을 생각해보면 여기에 이름을 붙인 &amp;lsquo;코시&amp;rsquo;가 대단한 학자였음을 짐작할 수 있다. 고등학</description>
    </item>
    
    <item>
      <title>강한 립시츠 조건과 오일러 메소드의 오차</title>
      <link>https://freshrimpsushi.github.io/posts/stronger-lipschitz/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stronger-lipschitz/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 강한 립시츠 조건 $\implies$ 립시츠 조건 $\implies$ 국소 립시츠 조건 $[x_{0} , b] \times \mathbb{R}$ 에서 정의된 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 의 해 $Y(x)$ 가 $[x_{0} , b]$ 에서 두 번 미분가능하다고 하자. $f$ 가 모든 $x_{0} \le x \le b$ 와 $ y_{1} , y_{2} \in \mathbb{R}$, 그리고 $K \ge 0$ 에 대해 **강한 립시츠 조건 $$ |f(x,y_{1} ) - f(x,y_{2}) | \le K | y_{1} - y_{2} | $$ 을 만족하면 오일</description>
    </item>
    
    <item>
      <title>준소수의 소인수분해 문제가 쉽게 풀리는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/condition-for-factorization-problem-be-solved-easily/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/condition-for-factorization-problem-be-solved-easily/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소인수분해 문제의 어려움을 이용한 보안 알고리즘RSA 공개 키 암호체계골드바서-미칼리 확률 키 암호체계소인수분해 문제에 대한 공격 알고리즘폴라드 p-1 소인수분해 알고리즘준소수의 소인수분해 문제가 쉽게 풀리는 조건 준소수의 소인수분해문제 $N = pq$ 는 다음의 조건 하에서 비교적 쉽게 풀리게 된다</description>
    </item>
    
    <item>
      <title>클락슨 부등식의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-clarksons-inequalities/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-clarksons-inequalities/</guid>
      <description>정리1 $\Omega \subset \mathbb{R}^{n}$를 열린 집합이라고 하자. $u,v\in {L}^{p}(\Omega)$라고 하자. 또한 $\frac{1}{p}+\frac{1}{p^{\prime}}=1$을 만족한다고 하자. 만약 $2 \le p \lt \infty$라면 다음의 두 부등식이 성립한다. $$ \begin{equation} \left\| \frac{u+v}{2}\right\|_{p}^{p}+ \left\| \frac{u-v}{2} \right\|_{p}^{p} \le \frac{1}{2}\left\| u \right\|_{p}^{p} + \frac{1}{2}\left\| v \right\|_{p}^{p} \end{equation} $$ $$ \begin{equation} \left\| \frac{u+v}{2}\right\|_{p}^{p^{\prime}}+ \left\|</description>
    </item>
    
    <item>
      <title>르벡공간에서 인터폴레이션 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/interpolation-inequality/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interpolation-inequality/</guid>
      <description>정리1 $\Omega \subset \mathbb{R}^{n}$를 열린 집합이라고 하자. $1 \le p \lt q\lt r \le \infty$가 $0 \lt \theta \lt 1$인 어떤 $\theta$에 대해서 아래의 식을 만족한다고 하자. $$ \dfrac{1}{q} = \frac{\theta}{p} + \frac{1-\theta}{r} $$ $u \in L^p(\Omega) \cap L^r(\Omega)$라고 가정하자. 그러면 $u\in L^{q}(\Omega)$이고 아래의 부등식이 성립한다. $$ \left\| u \right\|_{q} \le \left\| u \right\|_{p}^{\theta}</description>
    </item>
    
    <item>
      <title>볼자노-바이어슈트라스 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bolzano-weierstrass-theorem/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bolzano-weierstrass-theorem/</guid>
      <description>정리 무한집합 $E \subset \mathbb{R}$ 가 유계이면 $E$ 의 집적점 $p \in \mathbb{R}$이 존재한다. 설명 혹은 &amp;lsquo;유계 수열은 수렴하는 부분수열을 갖는다.&amp;lsquo;라고 해도 좋다. 조건에서 $E$ 가 꼭 닫혀있을 필요는 없다는 점을 알아두도록 하자. 증명 **Part 1. $\displaystyle \bigcap_{n=1}^{\infty} I_{n} = \left\{ x \right\}$ 가정에서 $E$ 가 유계이므로 $E \subset I_{1}$ 를 만족하는 폐구간 $I_{1} := [a,b]$ 가 존재한다.</description>
    </item>
    
    <item>
      <title>수치해석에서의 오일러 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/euler-method-in-numerical-analysis/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euler-method-in-numerical-analysis/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} \simeq Y_{0}$ 에 대해 $$ y_{n+1} = y_{n} + h f ( x_{n} , y_{n} ) $$ 오일러 메소드는</description>
    </item>
    
    <item>
      <title>폴라드 p-1 소인수분해 알고리즘 증명 Proof of Pollards p-1 Factorization Algorithm</title>
      <link>https://freshrimpsushi.github.io/posts/1187/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1187/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소인수분해 문제의 어려움을 이용한 보안 알고리즘RSA 공개 키 암호체계골드바서-미칼리 확률 키 암호체계소인수분해 문제에 대한 공격 알고리즘폴라드 p-1 소인수분해 알고리즘준소수의 소인수분해 문제가 쉽게 풀리는 조건 준소수 $N$ 이 주어져있다고 하자. $p$ 가 스무스 소수라면 $N$ 의 소인수분해 $N = pq$</description>
    </item>
    
    <item>
      <title>Lp 공간의 선형 범함수</title>
      <link>https://freshrimpsushi.github.io/posts/linear-functional-on-lp-space/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-functional-on-lp-space/</guid>
      <description>정의1 $\Omega \subset \mathbb{R}^{n}$를 열린 집합이라고 하자. $1 \le p \le \infty$이고 $p^{\prime}=\frac{p}{p-1}$이라고 하자. 각각의 $v \in L^{p^{\prime}}(\Omega)$에 대해서 $L^p(\Omega)$공간상의 선형 범함수 $L_v\ :\ L^p(\Omega) \rightarrow \mathbb{C}$를 아래와 같</description>
    </item>
    
    <item>
      <title>칸토어의 축소구간 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cantors-nested-intervals-theorem/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cantors-nested-intervals-theorem/</guid>
      <description>정의1 집합의 수열 $\left\{ S_{n} \right\}_{n=1}^{\infty}$ 이 모든 자연수 $n$ 에 대해 $S_{n+1} \subset S_{n}$ 이면 내포Nested 되었다고 한다. 설명 내포의 번역은 별로 매끄럽지 않은데, 별다른 대안이 없으므로 그냥 네스티드Nested로 외우는 걸 추천한다. 정리 내포된 구간 $[a_{n}, b_{n}]$ 에 대해 다음이 성립한다. (a) $\displaystyle \bigcap_{n=1}^{\infty} [a_{n}, b_{n}] \ne \emptyset$ (b) 특히 $\displaystyle \lim_{n \to \infty} (b_{n} - a_{n}) = 0$ 이면 $\displaystyle \bigcap_{n=1}^{\infty} [a_{n}, b_{n}]$ 은 홑원소 집합이다. 홑원소 집합</description>
    </item>
    
    <item>
      <title>골드바서-미칼리 확률 키 암호체계 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-goldwasser-micali-probabilistic-key-cryptosystem/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-goldwasser-micali-probabilistic-key-cryptosystem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소인수분해 문제의 어려움을 이용한 보안 알고리즘RSA 공개 키 암호체계골드바서-미칼리 확률 키 암호체계소인수분해 문제에 대한 공격 알고리즘폴라드 p-1 소인수분해 알고리즘준소수의 소인수분해 문제가 쉽게 풀리는 조건왼쪽부터 순서대로 앨리스 , 밥 , 이브**라 하자. 앨리스와 밥은 메세지를 주</description>
    </item>
    
    <item>
      <title>균등 볼록성</title>
      <link>https://freshrimpsushi.github.io/posts/uniform-convexity/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniform-convexity/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **균등하게 볼록$(\mathrm{uniformly\ convex})$ 집합 $X$상의 놈 $| \cdot |$이 아래의 조건을 만족하면 균등하게 볼록하다고 말한다.$0&amp;lt;\epsilon \le 2$인 모든 $\epsilon$에 대해서 양수 $\delta(\epsilon)&amp;gt;0$이 존재</description>
    </item>
    
    <item>
      <title>대학교 수학에서 수열의 수렴을 복잡하게 정의하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/1186/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1186/</guid>
      <description>정의 $\left\{ x_{n } \right\}_{n = 1}^{\infty}$ 이 실수의 수열이라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $n \ge N \implies | x_{n} - a | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하면 $\left\{ x_{n } \right\}$ 이 $a \in \mathbb{R}$ 로 수렴한다고 한다. $$ \displaystyle \lim_{n \to \infty} x_{n} = a \iff \forall \varepsilon &amp;gt; 0 , \exists N \in \mathbb{N} : n \ge N \implies | x_{n} - a | &amp;lt; \varepsilon $$ 설명 이러한 정의를 사용한 전개를 흔히 **입실론-델타 논법**이라 부른다. 직관을 버리고 수열의 극한을 엄밀하게</description>
    </item>
    
    <item>
      <title>대학교 수학에서 수열의 극한을 새롭게 정의하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/1184/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1184/</guid>
      <description>정의 $\mathbb{N}$ 은 자연수의 집합, $\mathbb{R}$ 은 실수의 집합을 의미한다. 정의역이 $\mathbb{N}$ 인 함수를 수열이라고 한다. 자연수의 수열 $\left\{ n_{k} \right\}_{ k \in \mathbb{N}}$ 에 대해 $\left\{ x_{n_{k}} \right\}_{ k \in \mathbb{N}}$ 를 $\left\{ x_{n} \right\}_{ n \in \mathbb{N}}$ 의 부분수열Subsequence이라 한다. 모든 $x \in \left\{ x_{n} \right\}_{ n \in \mathbb{N}}$ 에 대해 $x \le M$ 을 만족하는 $M \in \mathbb{R}$ 이 존재하면 $\left\{ x_{n} \right\}_{ n \in \mathbb{N}}$ 가 위로 유계 , $m \le x$ 를 만족하는 $m \in \mathbb{R}$ 이 존재하면 아래로</description>
    </item>
    
    <item>
      <title>베셀 방정식의 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-bessels-equations/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-bessels-equations/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\nu$차 베셀 방정식은 아래와 같다. $$ \begin{align*} x^2 y&#39;&#39; +xy&#39; +(x^2-\nu^2)y&amp;amp;=0 \\ x(xy&#39;)&#39;+(x^2- \nu ^2) y&amp;amp;=0 \\ y&#39;&#39;+\frac{1}{x} y&#39; + \left( 1-\frac{\nu^{2}}{x^{2}} \right)y&amp;amp;=0 \end{align*} $$ 유도 2차원 극좌표에서 파동 방정식은 다음과 같이 주어진다. $$ \dfrac{\partial ^2 u}{\partial t^2} = c^2 \left( \dfrac{\partial ^2 u}{\partial r^2}+\frac{1}{r}\dfrac{\partial u}{\partial r}+\frac{1}{r^2} \dfrac{\partial ^2 u}{\partial \theta ^2}\right) \tag{1} $$ $c$는 상수이다. 위 방정식의 해 $u$를 변수 분리 가능한 함수라고 가정하자. $$ u(t, r, \theta)=T(t)R(r)\Theta(\theta) $$ $(</description>
    </item>
    
    <item>
      <title>RSA 공개 키 암호체계 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rsa-public-key-cryptosystem/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rsa-public-key-cryptosystem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소인수분해 문제의 어려움을 이용한 보안 알고리즘RSA 공개 키 암호체계골드바서-미칼리 확률 키 암호체계소인수분해 문제에 대한 공격 알고리즘폴라드 p-1 소인수분해 알고리즘준소수의 소인수분해 문제가 쉽게 풀리는 조건왼쪽부터 순서대로 앨리스 , 밥 , 이브**라 하자. 앨리스와 밥은 메세지를 주</description>
    </item>
    
    <item>
      <title>물리학을 위한 푸리에 급수와 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-series-and-fourier-transform-for-physics/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-series-and-fourier-transform-for-physics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 예전부터 물리학과 수리물리 정도만 공부하는 물리학과 전공자에게 푸리에 급수와 푸리에 변환에 대한 좋은 설명이 없다고 생각했다. 푸리에 급수, 푸리에 변환에 대한 내용은 많은 교재에서 다루고 있지만 핵심을 적절한 난이도로, 적절한 분량으로 다룬 교재는 없는 것 같아서 직접 작성했다. 특히나 난이도에</description>
    </item>
    
    <item>
      <title>매트랩에서 그래프에 사용 가능한 특수기호 일람</title>
      <link>https://freshrimpsushi.github.io/posts/available-special-character-in-matlab/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/available-special-character-in-matlab/</guid>
      <description>방법 매트랩에서 각각의 축이 무엇을 의미하는지 나타내기 위해서 그래프에 라벨을 붙일 경우 xlabel, ylabel 을 사용하면 된다. 특수기호를 사용할 수도 있고 볼드체, 이탤릭체 등도 사용할 수 있다. x=-3*pi:0.2:3* pi; y=sin(x-pi/6); plot(x,y); xlabel(&#39;\beta&#39;), ylabel(&#39;\nabla f(x)&#39;),; x=-3*pi:0.2:3* pi; y=sin(x-pi/6); plot(x,y); xlabel(&#39;진폭{\bf Volt}&#39;), ylabel(&#39;시간{\it sec}{\sl sec}{\rm sec}&#39;); 기호 코드 이름 기호 코드 이름 기호 코드 이름 $\alpha$ \alpha 알파 $\beta$ \beta 베타 $\gamma$ \gamma 감마</description>
    </item>
    
    <item>
      <title>소인수분해</title>
      <link>https://freshrimpsushi.github.io/posts/factorization/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factorization/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 자연수 $N$ 에 대해 $N = p_{1}^{r_{1}} \cdots p_{n}^{r_{n}}$ 을 만족하는 소수 $p_{1} , \cdots , p_{n}$ 와 자연수 $r_{1} , \cdots , r_{n}$ 를 찾는 것을 소인수분해라 한다. 역사적으로 소수는 늘 탐구의 대상이었으나 그럼에도 불구하고 아직 모르는 것이 많다. 페르마 판정법, 코셀트 판정법, 밀러-라빈 판정법과 같은 초등적 도구는 물론, 소수 정리를 비롯한 해석</description>
    </item>
    
    <item>
      <title>립시츠 조건</title>
      <link>https://freshrimpsushi.github.io/posts/lipschitz-condition/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lipschitz-condition/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 강한 립시츠 조건 $\implies$ 립시츠 조건 $\implies$ 국소 립시츠 조건 1계 미분방정식에 대한 존재성-유일성 정리$D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. $f$ 가 모든 $(x,y_{1}) , (x , y_{2} ) \in D$ 와 $K &amp;gt; 0$ 에 대해 립시츠 조건 $|f(x,y_{1} ) - f(x,y_{2}) | \le K | y_{1} - y_{2} |$ 을 만족하면 $(x_{0} , Y_{0}) \in D^{\circ}$ 에</description>
    </item>
    
    <item>
      <title>연속이지만 미분할 수 없는 함수: 바이어슈트라스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/weierstrass-function/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weierstrass-function/</guid>
      <description>정리 어디에서도 미분할 수 없는 연속함수가 존재한다. 증명 Strategy: 연속함수 $g_{1} (x) := | x - 1 |$ 과 $g_{2} (x) := | x - 2 |$ 을 생각해보자. $g_{1}$ 은 $x=1$ 에서, $g_{2}$ 는 $x=2$ 에서 미분가능하지 않다. $(g_{1} + g_{2})$ 는 $x = 1$ 와 $x = 2$ 두 점 모두에서 미분가능하지 않다. 이러한 방식으로 $\displaystyle G: = \sum_{k=1}^{\infty} g_{k}$ 을 구성해보면 $G$ 는 $x \in \mathbb{N}$ 에서 미분가능하지 않을 것이다. 물론 이는 바이어슈트라스 함수</description>
    </item>
    
    <item>
      <title>물리학에서의 오일러-라그랑주 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/euler-lagrange-equation/</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euler-lagrange-equation/</guid>
      <description>본 글은 독자가 고전역학 카테고리의 라그랑주 역학과 해밀턴의 변분 원리를 읽었다는 가정하에 쓰여졌다. 가능하면 중복되는 표기법, 내용이라도 본 글에서 다시 설명하겠지만 설명없이 쓰는 표기법이 있다면 링크를 참고하자. 운동 경로에 대한 라그랑지안을 적분한 것을 작용이라 하고 $J$로 표기한다. 위치를 $y$라고 두면 $$ J =\int_{t_1} ^{t_2} Ldt=\int_{t_1}^{t_2}L\big( y&#39;(t),\ y(t),\ t \big)dt $$ 이때 실</description>
    </item>
    
    <item>
      <title>수치적으로 이상적분을 계산하기 위한 가우스 구적법</title>
      <link>https://freshrimpsushi.github.io/posts/gaussian-quadrature-to-calculate-numerically-improper-integration/</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gaussian-quadrature-to-calculate-numerically-improper-integration/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 가우스 구적법은 그 자체로 아주 탁월할뿐 아니라, 노드를 잘 고름으로써 적분범위가 무한하게 주어져도 계산을 수행해낼 수 있다. 가우스-체비셰프 구적법 $$ \int_{-1}^{1} {{ 1 } \over { \sqrt{1 - x^2 } }} f(x) dx \approx \sum_{i=1}^{n} w_{i} f( x_{i} ) $$ $$ w_{i} = {{ \pi } \over { n }} $$ 여기서 $x_{i}$ 들은 $T_{n}(x) = 0$ 를 만족하는 체비셰프 노드다. 가우스-라게르 구</description>
    </item>
    
    <item>
      <title>라그랑주 역학과 해밀턴의 변분 원리</title>
      <link>https://freshrimpsushi.github.io/posts/lagrangian-mechanics-and-hamiltons-variational-principle/</link>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lagrangian-mechanics-and-hamiltons-variational-principle/</guid>
      <description>해밀턴의 원리, 범함수, 작용, 변분 등에 대해서 가능한 쉽게 설명해놓았으니 다른 곳에서 만족할만한 설명을 찾지 못했다면 끝까지 읽어보자. 해밀턴의 변분 원리1 물체가 시간 $t_{1}$에서 $t_{2}$까지 운동할 때 운동 경로에 대한 라그랑지안을 적분한 것을 작용action이라 하고 아래와 같이 $J$로 표기한다. $$ \begin{equation} J=\int_{t_{1}}^{t_{2}} L dt \label{action} \end{equation} $$ 이때</description>
    </item>
    
    <item>
      <title>함수의 급수</title>
      <link>https://freshrimpsushi.github.io/posts/series-of-function/</link>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-of-function/</guid>
      <description>정의 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 을 정의하자. (1) $\displaystyle \sum_{k=1}^{n} f_{k} (X)$ 이 $n \to \infty$ 일 때 $E$ 에서 점별수렴하면 급수 $\displaystyle \sum_{k=1}^{ \infty } f_{k}$ 가 $E$ 에서 점별수렴한다고 한다. (2) $\displaystyle \sum_{k=1}^{n} f_{k} (X)$ 이 $n \to \infty$ 일 때 $E$ 에서 균등수렴하면 급수 $\displaystyle \sum_{k=1}^{ \infty } f_{k}$ 가 $E$ 에서 균등수렴한다고 한다. (3) $\displaystyle \sum_{k=1}^{n} | f_{k} (x) |$ 이 $n \to \infty$ 일 때 $E$ 에서 점별수렴하면 급수 $\displaystyle \sum_{k=1}^{ \infty } f_{k}$ 가 $E$ 에서 절대수렴한다고 한다. 설명 함수의 수열</description>
    </item>
    
    <item>
      <title>에르미트 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-polynomial/</link>
      <pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 1. 확률론자의 에르미트 다항함수: $H_{e_{n}} = (-1)^{n} e^{{x^2} \over {2}} {{d^{n}} \over {dx^{n}}} e^{- {{x^2} \over {2}}}$ 2. 물리학자의 에르미트 다항함수**: $H_{n} = (-1)^{n} e^{x^2} {{d^{n}} \over {dx^{n}}} e^{-x^2}$ 에르미트 다항함수 는 두가지 꼴이 쓰이며, $H_{n} (x) = 2^{{n} \over {2}} H_{e_{n}} \left( \sqrt{2} x \right)$ 와 같은 관계를 갖는다. [0] $\displaystyle H_{n+1} (x) = 2x H_{n} (x) - H_{n}&#39; (X)$ [1]** 함수의 내적 $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx $ 에 대해 웨이트 $w$ 를 $\displaystyle w(x)</description>
    </item>
    
    <item>
      <title>함수의 점별수렴과 균등수렴의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/the-difference-between-the-pointwise-convergence-and-uniformly-convergence-of-a-function/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-difference-between-the-pointwise-convergence-and-uniformly-convergence-of-a-function/</guid>
      <description>$\mathbb{R}$ 의 부분집합 $E \ne \emptyset$ 에 대해 함수 $f : E \to \mathbb{R}$ 와 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 을 정의하자. 함수의 점별수렴 모든 $\varepsilon &amp;gt; 0$ 과 $x \in E$ 에 대해 $n \ge N \implies | f_{n} (x) - f(x) | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하면 $E$ 에서 $f_{n}$ 이 $f$ 로 점별수렴한다고 하고 아래와 같이 표기한다. $$ f_n \rightarrow f $$ 함수의 균등수렴 모든 $\varepsilon &amp;gt; 0$ 에 대해 $n \ge N \implies | f_{n} (x) - f(x) | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하</description>
    </item>
    
    <item>
      <title>호프-락스 공식이 해밀턴-야코비 방정식을 만족함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-hopf-lax-formula-satisfies-hamilton-jacobi-equation/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-hopf-lax-formula-satisfies-hamilton-jacobi-equation/</guid>
      <description>정리 1 호프-락스 공식 $$ u(x,t) = \min \limits_{y \in \mathbb{R}^n} \left\{ tL\left( \dfrac{x-y}{t} \right) +g(y) \right\} $$ $x \in \mathbb{R}^n$, $t&amp;gt;0$이라고 하자. 그리고 호프-락스 공식에 의해 정의된 $u$가 점 $(x,t)$에서 미분가능하다고 하자. 그러면 $u$는 해밀턴-야코비 방정식 을 만족한다. $$ u_t(x, t) + H\big( Du(x, t) \big) =0 $$ 증명 보조정리: 호프-락스 공식의 일반화 $t&amp;gt;0$라고 하자. 그러면 각각</description>
    </item>
    
    <item>
      <title>거리공간에서의 내부 폐포 경계</title>
      <link>https://freshrimpsushi.github.io/posts/interior-closure-boundary/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interior-closure-boundary/</guid>
      <description>정의 거리공간 $\left( X, d \right)$ 에 대해 $A \subset X$ 라고 하자. $x \in O \subset A$ 를 만족하는 열린 집합 $O$ 가 존재할 때, $x$ 를 $A$ 의 내점Interior Point이라 한다. $A$ 의 내점의 집합 $A^{\circ}$ 를 $A$ 의 내부Interior라 한다. $A$ 와 그 도집합의 합집합 $\overline{A} : = A \cup A&#39;$ 를 $A$ 의 폐포Closure라 한다. $x \in \overline{A}$ 이면서 $x \in \overline{X \setminus A}$ 일 때, $x$ 를 $A$ 의 경계점Bounda</description>
    </item>
    
    <item>
      <title>라게르 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/laguerre-polynomial/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laguerre-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\displaystyle L_{n} := {{ e^{x} } \over { n! }} {{ d^{n} } \over { dx^{n} }} \left( e^{-x} x^{n} \right)$ 을 라게르 다항함수라 한다. [0]** $\displaystyle L_{n+1} (x) = {{ 1 } \over { n+1 }} \left[ \left( 2n + 1 - x \right) L_{n} (x) - n L_{n-1} (x) \right]$ [1]** 함수의 내적 $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx $ 에 대해 웨이트 $w$ 를 $\displaystyle w(x) := e^{-x}$ 와 같이 주면 $\left\{ L_{0} , L_{1}, L_{2}, \cdots \right\}$ 은 직교 집합이 된다. $n = 0, \cdots , 3$ 에 대한 라게르 다항함수는 다음과</description>
    </item>
    
    <item>
      <title>실수 집합과 공집합은 열려있으면서도 닫혀있다</title>
      <link>https://freshrimpsushi.github.io/posts/real-set-and-empty-set-is-open-and-closed/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/real-set-and-empty-set-is-open-and-closed/</guid>
      <description>정리 $\mathbb{R}$ 과 $\emptyset$ 은 열려있으면서 닫혀있다. 설명 실수 $\mathbb{R}$ 상에서 여러 개구간의 합집합을 열린 집합이라고 한다. 예로써 $(-1,0) \cup (2,3)$ 은 당연히 열린 집합이고, $(0,1)$ 이나 $\mathbb{R}$ 역시 열린 집합이다. 한편 닫혀있음은 열려있음을 통해 정의된다. 어떤 실수의 부분집합 $C$ 에 대해 $R \setminus C$ 가 열려 있으면 $C$ 를 닫힌 집합이라고 한다.제시된 정리에서도 이미 나와있지만 열리고 닫히고는</description>
    </item>
    
    <item>
      <title>실수 집합에서 집적점이란</title>
      <link>https://freshrimpsushi.github.io/posts/limit-point/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-point/</guid>
      <description>정의 실수상에서의 한 점 $x \in \mathbb{R}$ 과 부분집합 $A \subset \mathbb{R}$ 에 대해 $x$ 를 포함한 임의의 열린 집합 $O$ 에 대해 $ O \cap ( A \setminus \left\{ x \right\} ) \ne \emptyset $ 이면 $x$ 를 집적점Limit Point이라 정의한다. $A$ 의 집적점의 집합을 $A$ 의 도집합Derived set이라 부르며, $A&#39;$ 로 표기한다. 설명 위 정의에서 조건은 $( O \setminus \left\{ x \right\} ) \cap A \ne \emptyset$ 이어도 상관 없다. 직관적으로 예시</description>
    </item>
    
    <item>
      <title>영의 정리</title>
      <link>https://freshrimpsushi.github.io/posts/youngs-theorem/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/youngs-theorem/</guid>
      <description>정리1 $p, q, r \ge 1$가 $\dfrac{1}{p} + \dfrac{1}{q} + \dfrac{1}{r} = 2$를 만족한다고 하자. 그러면 모든 ${u \in L^{p}(\mathbb{R}^{n})}$, ${v \in L^{q}(\mathbb{R}^{n})}$, ${w \in L^{r}(\mathbb{R}^{n})}$에 대해서 다음의 식이 성립한다. $$ \begin{equation} \left| \int_{\mathbb{R}^{n}} (u \ast v)(x)w(x)dx \right| \le \left\| u \right\|_{p} \left\| v \right\|_{q} \left\| w \right\|_{r} \end{equation} $$ 이때 $u \ast v$는 $u$와 $v$의 컨볼루션이다. 설명 이를 영의 정리Young&amp;rsquo;s theorem라고 한</description>
    </item>
    
    <item>
      <title>함수열의 균등수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-uniformly-of-function/</link>
      <pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-uniformly-of-function/</guid>
      <description>정의 $\mathbb{R}$ 의 부분집합 $E \ne \emptyset$ 에 대해 함수 $f : E \to \mathbb{R}$ 와 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 을 정의하자. 모든 $\varepsilon &amp;gt; 0$에 대해 $n \ge N \implies | f_{n} (x) - f(x) | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하면 $E$ 에서 $f_{n}$ 이 $f$ 로 균등수렴uniformly convergence한다고 하고 다음과 같이 표기한다. $$ f_n \rightrightarrows f $$ 혹은 $$ f_{n} \overset{\text{unif}}{\to} f $$ 혹은 $$ f_{n} \to f \quad \text{uniformly} $$ 설명 균등수렴은 함수값이</description>
    </item>
    
    <item>
      <title>호프-락스 공식의 유도와 증명</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-and-proof-of-hopf-lax-formula/</link>
      <pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-and-proof-of-hopf-lax-formula/</guid>
      <description>빌드업1 해밀토니안 $H$가 $Du$에만 의존하는 해밀턴-야코비 방정식 의 초기값 문제를 보자. $$ \begin{equation} \left\{ \begin{aligned} u_{t} + H(Du)&amp;amp;=0 &amp;amp;&amp;amp; \text{in } \mathbb{R}^n \times (0,\infty) \\ u&amp;amp;=g &amp;amp;&amp;amp; \text{on } \mathbb{R}^n \times \left\{ t=0 \right\} \end{aligned} \right. \label{eq1} \end{equation} $$ 일반적으로 해밀토니안은 공간 변수에 의존하여 $H(Du, x)$와 같은 꼴이나, 여기에서는 $x$에 대해서 영향을 받지 않는다고 하자. 그리고 해밀토니안 $H\in C^\infty$에 대해서 다음</description>
    </item>
    
    <item>
      <title>멜린 변환</title>
      <link>https://freshrimpsushi.github.io/posts/mellin-transform/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mellin-transform/</guid>
      <description>정의 다음과 같이 정의되는 적분변환 $\mathcal{M}$을 멜린 변환Mellin transform이라 한다. $$ \mathcal{M}[f(x)] (s) = \mathcal{M}f(s) = \int_{0}^{\infty} x^{s-1}f(x)dx = \phi(s) $$ 이 때 $s \in \mathbb{C}$이다. 멜린 역변환Mellin inverse transform은 다음과 같다. $$ \mathcal{M}^{-1}\phi (x) = f(x) = \dfrac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty} x^{-s}\phi(s) ds $$ 설명 적분 변환의 일종이다. 멜린 역변환은 상수 $c$의 값에 무관</description>
    </item>
    
    <item>
      <title>함수열의 점별수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-pointwise-of-function/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-pointwise-of-function/</guid>
      <description>정의 $\mathbb{R}$ 의 부분집합 $E \ne \emptyset$ 에 대해 함수 $f : E \to \mathbb{R}$ 를 정의하자. 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 이 각각의 $x \in E$ 에 대해 $f(x) = \lim \limits_{n \to \infty} f_{n} (X)$ 을 만족하면 $E$ 에서 $f_{n}$ 이 $f$ 로 점별수렴pointwise convergence한다고 하고 다음과 같이 표기한다. $$ f_{n} \to f $$ 설명 위 정의를 입실론-델타 논법으로 다시 써보면 다음과 필요충분조건이다. 모든 $\varepsilon 0$ 과 $x</description>
    </item>
    
    <item>
      <title>수치적으로 이상적분을 계산하기 위한 변수 치환 트릭</title>
      <link>https://freshrimpsushi.github.io/posts/substitution-trick-to-calculate-numerically-improper-integration/</link>
      <pubDate>Sat, 06 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/substitution-trick-to-calculate-numerically-improper-integration/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $0 &amp;lt; a &amp;lt; b &amp;lt; \infty$ 라고 하자. [1]: $ 0 &amp;lt; p &amp;lt; 1$ 면 $\displaystyle \int_{0}^{b} {{ f(x) } \over {x^{p} }} dx = \int_{0}^{{{ 1 } \over { 1-p }} b^{1-p} } f \left( \left[ ( 1- p ) m \right]^{{{ 1 } \over { 1-p }}} \right) dm$ [2]: $ 1 &amp;lt; p$ 면 $\displaystyle \int_{a}^{ \infty } {{ f(x) } \over {x^{p} }} dx = \int_{0}^{{{ 1 } \over { p-1 }} a^{1-p}}f \left( \left[ ( p-1 ) m \right]^{{{ 1 } \over { 1-p }}} \right) dm$ 이상적분은 언제나 골칫덩이지만 풀이를 포기할 수는 없다. 보통 적분이</description>
    </item>
    
    <item>
      <title>해밀토니안과 라그랑지안의 컨벡스 듀얼리티</title>
      <link>https://freshrimpsushi.github.io/posts/convex-duality-of-hamiltonian-and-lagrangian/</link>
      <pubDate>Sat, 06 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convex-duality-of-hamiltonian-and-lagrangian/</guid>
      <description>정리1 르장드르 변환 $L$이 볼록함수이다. $\lim \limits_{ |v|\to \infty} \dfrac{ L(v) }{ |v| }=+\infty$ 위 조건을 만족하는 라그랑지안 $L : \mathbb{R}^{n} \to \mathbb{R}$에 대해서 $L$의 르장드르 변환 $L^{\ast} : \mathbb{R}^{n} \to \mathbb{R}$를 다음과 같이 정의한다. $$ L^{\ast} (p) := \sup \limits_{v \in \mathbb{R}^{n}} \big( p\cdot v -L(v) \big) \quad \forall \ p \in \mathbb{R}^{n} $$ 라그랑지안 $L$이 르장드르 변환이 정의될 조건을 만족한다고 하자. 해밀토</description>
    </item>
    
    <item>
      <title>르장드르 변환</title>
      <link>https://freshrimpsushi.github.io/posts/legendre-transform/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/legendre-transform/</guid>
      <description>x와 p에 대해서, 편미분방정식의 변수임을 강조할 때는 일반 글씨체 $x,p \in \mathbb{R}^{n}$으로 표기하고, $s$에 대한 함수임을 강조할 때는 굵은 글씨체 $\mathbf{x}, \mathbf{p} \in \mathbb{R}^{n}$으로 표기한다. 정의 1 우선 단순함을 위해 라그랑지안을 변수 $v\in \mathbb{R}^{n}$만을 가지는 함수라고 하자. $$ L(v) = L :</description>
    </item>
    
    <item>
      <title>폐구간에서 적분할 수 없는 함수: 디리클레 함수</title>
      <link>https://freshrimpsushi.github.io/posts/dirichelt-function/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichelt-function/</guid>
      <description>정의 다음과 같이 정의되는 $f$를 디리클레 함수라고 한다. $$ f(x) := \begin{cases} 1 &amp;amp;, x \in \mathbb{Q} \\ 0 &amp;amp;, x \notin \mathbb{Q} \end{cases} $$ 설명 디리클레 함수는 리만적분을 할 수 없는 대표적인 함수로, 아마 해석학 이상의 공부를 하지 않는다면 평생 상상도 해볼 일 없는 변태적인 예시다. 콕 찝어서 리만적분 할 수 없다고 말하는 이유는 리만적분이 아니면 적분가능할 수도 있기 때문이다. 정리 디리클</description>
    </item>
    
    <item>
      <title>가우스 구적법</title>
      <link>https://freshrimpsushi.github.io/posts/gaussian-quadrature/</link>
      <pubDate>Thu, 04 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gaussian-quadrature/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 $a = x_{1} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. $$ \displaystyle I_{n} (f) := \sum_{j=1}^{n} w_{j} f ( x_{j} ) \approx \int_{a}^{b} w(x) f(x) dx = I ( f ) $$ 위와 같이 정의된 $I_{n}$ 의 가중치 $w_{j}$ 들을 구해서 수치적 적분을 계산하는 것을 가우스 구적법이라 한다. $f$ 를 잘 근사하는 다항함수 $p_{n-1}$ 이 존재하는 것은 보장</description>
    </item>
    
    <item>
      <title>라플라스 변환의 컨볼루션(합성곱)</title>
      <link>https://freshrimpsushi.github.io/posts/convolution-and-laplace-transform/</link>
      <pubDate>Thu, 04 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convolution-and-laplace-transform/</guid>
      <description>정의1 $\mathcal{L}$을 라플라스 변환이라고 하자. 다음의 식을 만족하는 함수 $f*g$를 라플라스 변환에 대한 $f$와 $g$의 컨볼루션convolution of $f$ and $g$ with Laplace transform이라 한다. $$ \mathcal{L}(f*g) = \mathcal{L}(f) \cdot \mathcal{L}(g) $$ 정리 $f$와 $g$의 라플라스 변환에 대한 컨볼루션 $h=f*g$는 다음과 같다. $$ h(t) = f*g(t) = \int_0^t f(t-\tau)g(\tau)d\tau =</description>
    </item>
    
    <item>
      <title>변분법과 오일러-라그랑주 방정식으로부터 유도되는 해밀턴 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/hamilton-equation-derived-from-the-variational-method-and-euler-lagrange-equation/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hamilton-equation-derived-from-the-variational-method-and-euler-lagrange-equation/</guid>
      <description>x와 p에 대해서, 편미분방정식의 변수임을 강조할 때는 일반 글씨체 $x,p \in \mathbb{R}^{n}$으로 표기하고, $s$에 대한 함수임을 강조할 때는 굵은 글씨체 $\mathbf{x}, \mathbf{p} \in \mathbb{R}^{n}$으로 표기한다. 마찬가지로 v도 변수임을 강조할 때는 일반 글씨체 $v \in \mathbb{R}^{n}$로 나타내고, 함수임을 강조할 때</description>
    </item>
    
    <item>
      <title>음이항계수</title>
      <link>https://freshrimpsushi.github.io/posts/negative-binomial-coefficient/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/negative-binomial-coefficient/</guid>
      <description>정의 $r,k \in \mathbb{N}$ 에 대해 $\displaystyle \binom{-r}{k}$ 를 음이항계수Negative Binomial Coefficient라 한다. 설명 음이항계수라는 이름에서 짐작할 수 있듯 이항계수가 음수에 대해 확장된 것이다. 수식적으로만 생각해보면 $\alpha \in \mathbb{Z}$ 에 대해 $\displaystyle \binom{\alpha}{k} = {{ \alpha ( \alpha - 1 ) \cdots ( \alpha - k + 1 ) } \over { k! }}$ 와 같이 계산하지 못할 이유가 없다. 더 나아가서 복소수에 대해서도 일반화 할 수 있</description>
    </item>
    
    <item>
      <title>오일러 상수 e는 무리수이다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-e/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-e/</guid>
      <description>정리 $$ e \notin \mathbb{Q} $$ $\mathbb{Q}$ 는 유리수의 집합을 나타낸다. 증명 매클로린 전개를 이용1 Strategy: 매클로린 전개를 통해 $e^{-1}$ 를 두 파트로 찢고 모순을 이끌어낸다. 매클로린 전개를 사용해야하기 때문에 고등학교 교과과정 내에서는 증명할 수 없다. $\mathbb{N}$ 는 자연수의 집합, $\mathbb{Z}$ 는 정수의 집합을 나타낸다. Part 1. $x_{1} = x_{2}$ $e \in \mathbb{Q}$ 이라고 가정하면 오일러 상수 $e$ 는 어떤 $a,b \in \mathbb{N}$ 에 대해 $e = {{</description>
    </item>
    
    <item>
      <title>힐베르트 변환</title>
      <link>https://freshrimpsushi.github.io/posts/hilbert-transform/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hilbert-transform/</guid>
      <description>빌드업 라돈 역변환 $$ f(x,y)=\dfrac{1}{2} \mathcal{B} \left\{ \mathcal{F}^{-1} \Big[ |S|\mathcal{F} (\mathcal{R}f) (S,\ \theta) \Big]&amp;gt; \right\} (x,y) $$ 위 공식은 $f$의 라돈 변환 $\mathcal{R}f$로부터 $f$를 구하는 공식이다 우선 다음과 같은 푸리에 변환의 성질을 떠올려보자. $$ \mathcal{F} [f&#39; ] (\xi) = i\xi \mathcal{F}(\xi) $$ 여기서 $f$ 대신 $\mathcal{R}f$를 대입하면 다음을 얻는다. $$ \begin{equation} \mathcal{F} \left( \dfrac{\partial (\mathcal{R}f)(t,\ \theta) } {\partial t} \right) (S,\ \theta) = i S \mathcal{F}(\mathcal{R}f)(S,\ \theta) \label{eq1} \end{equation} $$ 그리고 $|S|=S\cdot</description>
    </item>
    
    <item>
      <title>라돈 역변환</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-radon-transform-filtered-back-projection-formular/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-radon-transform-filtered-back-projection-formular/</guid>
      <description>정리 $f : \mathbb{R}^{2} \to \mathbb{R}$에 대해서 다음의 식이 성립한다. $$ f(x,y)=\dfrac{1}{2} \mathcal{B} \left\{ \mathcal{F}^{-1} \Big[ |S|\mathcal{F} (\mathcal{R}f) (S,\ \theta) \Big]\right\} (x,y) $$ 설명 The filtered back projection formular 이라고도 한다. $f$의 라돈변환 $\mathcal{R}f$가 주어졌을 때, 푸리에 변환과 백 프로젝션을 사용하여 $f$를 얻을 수 있다는 말이다. 즉 라돈 변환에 푸리에 변환을 취하고, $|S|$를 곱한 뒤 다시 푸리에 역 변환</description>
    </item>
    
    <item>
      <title>백 프로젝션 변환</title>
      <link>https://freshrimpsushi.github.io/posts/back-projection-transform/</link>
      <pubDate>Sun, 30 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/back-projection-transform/</guid>
      <description>정의 $(x,y)$를 2차원 직교좌표, $(s,\theta)$를 2차원 극좌표라고 하자. $f: \mathbb{R}^{2]} \to \mathbb{R}$이라고 하자. 그러면 $(x, y)$에서 $f=f(s,\theta)$의 백 프로젝션 변환back projection transform, 배경투사을 다음과 같이 정의한다. $$ \mathcal{B}f(x,y) := \int_0^\pi f(x\cos\theta+y\sin\theta,\ \theta) d\theta $$ 설명 극좌표 $(s,\theta)$가 주어질 때 마다 2차원</description>
    </item>
    
    <item>
      <title>원주율은 무리수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-pi/</link>
      <pubDate>Sun, 30 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-pi/</guid>
      <description>정리 $\pi \notin \mathbb{Q}$ $\mathbb{Q}$ 는 유리수의 집합을 나타낸다. 증명 Strategy: 정수가 조밀성을 갖지 않는다는 점을 이용한다. 함수 $f$, $F$ 를 아주 교묘하게 정의해서 갖가지 트릭을 사용한다. 이 방법은 이반 니븐Ivan Niven에 의해 고안된 것으로 $\pi$ 가 무리수라는 것을 보이는 증명 중에서는 가장 쉽지만, 아쉽게도 입실론-델타 논법이 쓰이기 때문에 비약 없이는 고등학교 교과과정</description>
    </item>
    
    <item>
      <title>푸리에 슬라이스 정리</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-slice-theorem/</link>
      <pubDate>Sun, 30 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-slice-theorem/</guid>
      <description>정리 $f : \mathbb{R}^{2} \to \mathbb{R}$에 대해서 다음의 식이 성립한다. $$ \begin{equation} \mathcal{F}_2 f(\xi \cos\theta,\ \xi \sin\theta)=\mathcal{F}(\mathcal{R}f)(\xi ,\ \theta) \label{thm1} \end{equation} $$ 여기서 $\mathcal{F}$는 1차원 푸리에 변환, $\mathcal{F}_2$는 2차원 푸리에 변환, $\mathcal{R}$은 라돈 변환을 의미한다. $$ \begin{align*} \mathcal{F}f (y) &amp;amp;= \int f(x) e^{-i xy } dx \\ \mathcal{F}_{2} f (y_{1}, y_{2}) &amp;amp;= \int \int f(x_{1}, x_{2}) e^{-i (x_{1}, x_{2}) \cdot (y_{1}, y_{2})} dx_{1} dx_{2} \\ \mathcal{R}f(s,\theta) &amp;amp;=</description>
    </item>
    
    <item>
      <title>뉴턴-코테스 적분 공식</title>
      <link>https://freshrimpsushi.github.io/posts/newton-cotes-integration-formulas/</link>
      <pubDate>Sat, 29 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newton-cotes-integration-formulas/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 간격이 $\displaystyle h:= {{b-a} \over {n}}$ 로 일정한 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 다음과 같이 정의된 $I_{n}^{p}$ 을 뉴턴-코테스 공식이라 한다. $$ \displaystyle I_{n}^{p} (f) := \sum_{i=0}^{n} w_{i} f ( x_{i} ) $$ $i=0,1,\cdots , n$ 에 대해 $x_{i} := a + i h$ 이고, $l_{i}$ 는 라그랑주 공식에서 쓰이는 다항함수 $\displaystyle l_{i} (x) := \prod_{i</description>
    </item>
    
    <item>
      <title>루트 2 는 무리수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-root-2/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-root-2/</guid>
      <description>정리 $\sqrt{2}$ 는 무리수다. 증명 전략: $\sqrt{2}$ 를 기약분수꼴로 나타내서 모순을 유도한다. 이 방법은 제곱수가 아닌 모든 $n$ 에 대해 $\sqrt{n}$ 이 무리수임을 보이는데에 사용할 수 있다. $\sqrt{2}$ 가 유리수라고 가정하면 $\sqrt{2}$ 서로소인 어떤 두 자연수 $a,b$ 에 대해 $\displaystyle \sqrt{2} = {{ a } \over {b}}$ 와 같이 나타날 수 있어야한다. 양변에 $b$ 를 곱하면 $$ \sqrt{2} b= a $$ 양변을 제곱하면 $$ 2 b^2 = a^2 $$ $a^2$ 는 $2$ 와 $b^2$ 의 곱이</description>
    </item>
    
    <item>
      <title>매트랩에서 엑셀의 데이터를 불러오는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/load-excel-file-in-matlab/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/load-excel-file-in-matlab/</guid>
      <description>방법 매트랩에는 엑셀의 데이터를 불러올 수 있는 기능이 있다. 우선 홈 메뉴에서 데이터 가져오기를 클릭한다. 가져올 데이터가 저장된 엑셀 파일을 선택한다. 그러면 가져올 데이터를 선택할 수 있는데 처음에 알아서 선택이돼있다. 확인하고 &amp;lsquo;선택 항목 가져오기&amp;rsquo;를 누르면 된다. &amp;lsquo;선택 항목 가져오기&amp;rsquo</description>
    </item>
    
    <item>
      <title>해밀턴-야코비 방정식과 해밀턴 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/hamilton-jacobi-equation-and-hamiltons-equations/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hamilton-jacobi-equation-and-hamiltons-equations/</guid>
      <description>해밀턴 방정식을 얻는 방법에는 두 가지가 있다. 하나는 오일러-라그랑주 방정식으로부터 얻는 것이고, 다른 하나는 이 글에서 소개할 해밀턴-야코비 방정식의 특성 방정식으로부터 얻는 방법이다. 정의1 다음의 편미분방정식을 일반 해밀턴-야코비 방정식the general Hamilton-Jacobi equation이라 한다. $$ G(Du, u_t, u, x, t)=u_t+H(Du, x)=0 $$ $t &amp;gt;0 \in \mathbb{R}$ $x \in \mathbb{R}^{n}$ $u : \mathbb{R}^{n} \to \mathbb{R}$ 이때 미분</description>
    </item>
    
    <item>
      <title>편미분방정식에서 라그랑지안과 오일러-라그랑주 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/lagrangian-and-euler-lagrange-equation-in-pde/</link>
      <pubDate>Thu, 27 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lagrangian-and-euler-lagrange-equation-in-pde/</guid>
      <description>정의1 라그랑지안Lagrangian 스무스 함수 $L : \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}$이 주어졌다고 하자. 이를 라그랑지안 이라 부르고 다음과 같이 표기한다. $$ L = L(v,x)=L(v_{1}, \dots, v_{n}, x_{1}, \dots, x_{n}) \quad v,x\in \mathbb{R}^{n} \\ D_{v}L = (L_{v_{1}}, \dots, L_{v_{n}}), \quad D_{x}L = (L_{x_1}, \dots, L_{x_n}) $$ 여기서 변수를 $v, x$로 쓰는 이유는 실제로 물리학에서 각 변수가 속도와 위치를 의미하기 때문이다. 액션action, 어드미</description>
    </item>
    
    <item>
      <title>심슨 룰</title>
      <link>https://freshrimpsushi.github.io/posts/simpson-rule/</link>
      <pubDate>Wed, 26 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simpson-rule/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 간격이 $\displaystyle h:= {{b-a} \over {n}}$ 로 일정한 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 다음과 같이 정의된 $I_{n}^{2}$ 을 심슨 룰이라 한다. $$ \displaystyle I_{n}^{2} (f) := \sum_{k=1}^{n/2} {{h} \over {3}} \left[ f(x_{2k-2}) + 4 f( x_{2k-1} ) + f(x_{2k} ) \right] $$ $f \in C^4 [a,b]$ 이라고 하자.[1] $\displaystyle E_{1}^{2} (f) = - {{h^5} \over {90}} f^{(4)} ( \xi )$[2] $\displaystyle \tilde{E}_{n}^{2} (f) = - {{ h^4 }</description>
    </item>
    
    <item>
      <title>R 에서 로그로그 스케일 그림 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-loglog-scale-graph/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-loglog-scale-graph/</guid>
      <description>좋지 않은 방법 win.graph(7,4); par(mfrow=c(1,2)) plot(pressure,main=&#39;Pressure&#39;) y&amp;lt;-pressure[-1,]$pressure; logtemp&amp;lt;-log(y) x&amp;lt;-pressure[-1,]$temperature; logpress&amp;lt;-log(x) plot(logpress,logtemp,main=&#39;log scale&#39;) 로그로그 스케일로 그림을 그리는 가장 쉬운 방법은 데이터 자체에 로그를 취하는 것이다. 만약 로그로그 플랏을 처음 그려본다면 이 방법은 반드시 숙지하는 편이 좋다. 이 방법은 R 이든 어떤 언어든 먹히기 때문에 급한대로 써먹을 수 있기 때문이다. 물론 이 방법은 머리가 편한만큼 손이 다소 수고스럽다. win.graph(5,5) plot(pressure,main=&#39;Pressure&#39;,log=&amp;quot;xy&amp;quot;) 권장되는 방법 R 자</description>
    </item>
    
    <item>
      <title>1차원 달랑베르 공식</title>
      <link>https://freshrimpsushi.github.io/posts/one-dimentional-dalemberts-formula/</link>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/one-dimentional-dalemberts-formula/</guid>
      <description>정리1 파동 방정식의 코시 문제가 다음과 같이 주어졌다고 하자. $$ \begin{align*} u_{tt}-u_{xx}&amp;amp;=0 &amp;amp;&amp;amp; \text{in } \mathbb{R}^2=\mathbb{R}_{x} \times \mathbb{R}_{t} \\ u=g,\quad u_{t}&amp;amp;=h &amp;amp;&amp;amp; \text{on } \mathbb{R}\times\left\{t=0\right\} \end{align*} $$ 이때 $g \in C^2(\mathbb{R}), h\in C^1(\mathbb{R})$이다. 그리고 $u(x,t)$를 다음과 같이 정의하자. $$ \begin{equation} u(x,t)=\dfrac{1}{2} \left[ g(x+t)+g(x-t) \right] + \dfrac{1}{2} \int_{x-t}^{x+t}h(y)dy \quad \forall\ (x,t)\in \mathbb{R}^2 \label{thm} \end{equation} $$ 그러면 $u\in C^2(\mathbb{R}^2)$는 주어진 코시 문제의 해다. 설명 $\eqre</description>
    </item>
    
    <item>
      <title>사다리꼴 룰</title>
      <link>https://freshrimpsushi.github.io/posts/trapezoidal-rule/</link>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trapezoidal-rule/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 간격이 $\displaystyle h:= {{b-a} \over {n}}$ 로 일정한 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 다음과 같이 정의된 $I_{n}^{1}$ 을 사다리꼴 룰이라 한다. $$ I_{n}^{1} (f) := \displaystyle \sum_{k=1}^{n} {{h} \over {2}} \left( f(x_{k-1}) + f(x_{k} ) \right) $$ $f \in C^2 [a,b]$ 이라고 하자.[1] $\displaystyle E_{1}^{1} (f) = - {{1} \over {12}} h^{3} f&#39;&#39; ( \xi )$[2] $\displaystyle \tilde{E}_{n}^{1} (f) = - {{ h^2 } \over {12}}</description>
    </item>
    
    <item>
      <title>R 에서 범례 넣는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-legend-in-r/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-legend-in-r/</guid>
      <description>코드 데이터는 분석하는 것만큼이나 표현하는 것이 중요하다. 그림이 복잡할 수록 꼼꼼한 주석과 깔끔한 범례가 데이터를 이해하는데에 큰 도움을 준다. legend() 함수는 굉장히 많은 옵션을 가지고 있으나, 아래 코드와 같이 아주 필수적인 요소만 사용해도 좋다. 위치를 나타내는 첫번째 옵션은 &amp;ldquo;top&amp;rdquo;, &amp;ldquo;bottom&amp;rdquo; + &amp;ldquo;left&amp;rdquo;, &amp;ldquo;right&amp;rdquo; 의 조합과 &amp;ldquo;center&amp;quot;로 편하게</description>
    </item>
    
    <item>
      <title>매트랩에서 계산한 데이터를 엑셀파일로 저장하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/save-matlab-data-as-excel-file/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/save-matlab-data-as-excel-file/</guid>
      <description>방법 MATLAB에서 계산한 데이터를 엑셀로 정리하고 싶을 때 데이터양이 얼마되지 않는 다면 직접 복사+붙여넣기를 하는 것이 가능하다. 그런데 위의 사진처럼 128*128 행렬의 데이터는 그런식으로 할 수 없다. 이 때 데이터를 엑셀파일로 저장해주는 xlswrite를 사용하면 된다. 위 사진과 비교했을 때 마지막줄에 xlswrite(&#39;test&#39;, Y)가 추가됐다. Y의 데이터가 tes</description>
    </item>
    
    <item>
      <title>매트랩에서 한꺼번에 여러줄 주석처리, 주석해제 하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/multiline-annotation-in-matlab/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiline-annotation-in-matlab/</guid>
      <description>방법 주석처리하고 싶은 부분을 드래그한 뒤 Ctrl+R을 입력하면 드래그한 부분 전체를 주석처리할 수 있다. 반대로 되돌릴 때는 똑같이 드래그하고 Ctrl+T를 입력하면 각 줄의 %가 사라진다.</description>
    </item>
    
    <item>
      <title>수치적 적분</title>
      <link>https://freshrimpsushi.github.io/posts/numerical-intergration/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/numerical-intergration/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. (1)** 적분 오퍼레이터 $I$ 를 $\displaystyle I(f) := \int_{a}^{b} f(x) dx$ 와 같이 정의한다. (2)** 적분 오퍼레이터 $I_{n}$ 을 $\displaystyle I_{n} (f) := \sum_{k=1}^{n} \int_{x_{k-1}}^{x_{k}} f(x) dx$ 와 같이 정의한다. (3)** 에러 $E_{n}$ 을 $E_{n} (f) := I (f) - I_{n} ( f )$ 와 같이 정의한다. 4. $\displaystyle \lim_{n \to \infty} {{\tilde{E}_{n} (f) } \over { E_{n}</description>
    </item>
    
    <item>
      <title>R 에서 메타데이터, attr 참조하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-refer-attr-in-r/</link>
      <pubDate>Fri, 21 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-refer-attr-in-r/</guid>
      <description>개요 R 에서 함수들을 사용하다보면 간혹 attr(,&amp;quot;something&amp;quot;)과 같은 데이터를 접할 때가 있다. Attribute 는 말 그대로 속성 을 의미하는데, 파이썬과 같은 언어와 달리 R 에서는 메타 데이터로써 데이터에 들어있는 일종의 주석으로 받아들여도 좋다. 그런데 R 을 쓰다보면 가끔 이 데이터를 참조하고 싶을 때가 있다. 예시 예를</description>
    </item>
    
    <item>
      <title>베르누이 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bernoullis-inequality/</link>
      <pubDate>Wed, 19 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bernoullis-inequality/</guid>
      <description>정리 $\alpha &amp;gt; 0$ 이라고 하면 모든 $x \in [ - 1, \infty )$ 에 대해 다음 두 부등식이 성립한다. [1]: $\alpha \in (0, 1] \implies (1 + x )^{\alpha } \le 1 + \alpha x $ [2] $\alpha \in (1, \infty] \implies (1 + x )^{\alpha } \ge 1 + \alpha x $ 설명 부등식의 모양을 잘 보면 $\alpha$ 의 크기에 달려 있긴 하지만 둘 중 한 쪽은 곱이고, 나머지 한 쪽은 거듭제곱이다. 물론 조건 나름이지만 곱이든 거듭제곱이든 거슬리는 계산 하나를 내가 원하는 쪽으로 바</description>
    </item>
    
    <item>
      <title>임의의 함수를 두개의 음이 아닌 함수로 표현하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/to-represent-an-arbitrary-function-as-a-non-negative-function/</link>
      <pubDate>Wed, 19 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/to-represent-an-arbitrary-function-as-a-non-negative-function/</guid>
      <description>정의1 함수 $f : X \to \mathbb{R}$에 대해서 $f^{+}$와 $f^{-}$를 다음과 같이 정의하자. $$ \begin{align*} f^{+} (x) &amp;amp;:= \max \left\{ f(x),\ 0 \right\} \\ f^{-} (x) &amp;amp;:= \max \left\{ -f(x),\ 0 \right\} \end{align*} $$ $f^{+}$를 $f$의 양의 부분positive part이라 하고, $f^{-}$를 $f$의 음의 부분negative part 이라 한다. 설명 이름 때문에 헷갈릴 수도 있지만 $</description>
    </item>
    
    <item>
      <title>R 에서 문자열의 벡터를 하나의 문자열로 합치는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-join-string-vector-in-r/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-join-string-vector-in-r/</guid>
      <description>개요 R 은 데이터를 다루기에 무척 편리한 언어지만, 다른 프로그래밍 언어에도 익숙한 사람이라면 R 의 문자열이 다소 낯설 수 있다. C 혹은 파이썬과 달리 R 자체에서 지원하는 기능이 많고, 반대로 그 기능들을 써야만 수월하게 다룰 수 있다. 그래서 내장 함수들이 생각하는대로 작동하지 않으면 답답한 면이 있다. 예시 예를 들어 위와 같이 캐릭터들로 이루어진 벡</description>
    </item>
    
    <item>
      <title>실수값을 갖는 가측 함수의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/property-of-real-valued-measurable-function/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/property-of-real-valued-measurable-function/</guid>
      <description>정리1 가측공간 $(X,\mathcal{E})$에서 정의된 두 함수 $f, g : X \to \mathbb{R}$가 가측 함수이면, 다음의 함수들도 모두 가측이다. $$ cf,\quad f^2,\quad f+g,\quad fg,\quad |f| $$ 증명 가측함수 모든 $\alpha \in \mathbb{R}$에 대해서 다음의 식을 만족하는 $f : X \to \overline{\mathbb{R}}$를 가측함수라고 한다. $$ S_f(\alpha):=\left\{ x\in</description>
    </item>
    
    <item>
      <title>체비셰프 노드</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-node/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-node/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $[-1,1]$ 에서 $\displaystyle x_{k} = \cos \left( {{2k-1} \over {2n}} \pi \right)$, $k=1, \cdots , n$ 을 체비셰프 노드라 한다. 체비셰프 노드는 일반적으로 사용하듯 일정한 간격의 노드 포인트와 달리 반원의 호를 일정한 크기로 자르고 그 점들을 $x$ 축으로 사영시킨 노드 포인트를 말한다. 점들의 분포는 가운데보다 양 끝에 조금 몰리는 모양새를 이룬다. 밑에서 다시 설</description>
    </item>
    
    <item>
      <title>R 에서 리스트를 참조하는 여러가지 방법</title>
      <link>https://freshrimpsushi.github.io/posts/some-way-to-refer-list-in-r/</link>
      <pubDate>Sun, 16 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/some-way-to-refer-list-in-r/</guid>
      <description>개요 R 은 데이터를 다루기 위해 정말 좋은 기능들을 많이 제공하는데, 그 중에서도 리스트는 R 을 사용하게 만드는 가장 큰 이유 중 하나다. 파이썬을 위시한 다른 언어에도 리스트 자료형 자체는 많이 구현되어 있으나 R 만큼 데이터를 다루기 편하고 직관적으로 구현되어 있지는 않다. 리스트를 잘 다룰 수 있게 되면 다른 프로그래밍 언어로는 다소 복잡하고 귀찮은 코딩</description>
    </item>
    
    <item>
      <title>체비셰프 전개</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-expansion/</link>
      <pubDate>Sat, 15 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-expansion/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 체비셰프 전개를 이해하기 위해서는 어떻게 체비셰프 전개가 나오는지를 먼저 알아야한다. 우선 최소극대화 문제를 푸는 대신 최소제곱 문제를 푼다고 생각해보자. $$ \displaystyle M_{n} (f) := \inf_{\deg(r) \le n } \left\| f - r \right\|_{2} $$ $f : [a,b] \to \mathbb{R}$ 에 대해 위와 같이 최소제곱 문제가 주어져있다고 하자. 목표는 $M_{n} (f)$ 를 최소화하는 $n$ 차 이하의</description>
    </item>
    
    <item>
      <title>R 에서 최대값과 최소값의 위치 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-argmax-argmin-or-index-of-maximum-or-minimum-in-r/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-argmax-argmin-or-index-of-maximum-or-minimum-in-r/</guid>
      <description>코드 set.seed(150421) x&amp;lt;-sample(100,10); x which.max(x) which.min(x) 통계를 목적으로 데이터를 보다보면 최대값과 최소값이 무엇인지 아는것만 중요한게 아니라 그 게 몇번째 값인지를 파악하는 것도 필요한 경우가 많다. 특히 시계열 데이터는 더더욱 그러하다. 물론 R 은 이런 함수가 없어도 조작이 쉽지만, 가능하다면 복잡한 코드는 지양하는 게 좋다. 데이터 x 의 최대값이 어디인지 궁금해서 which(max</description>
    </item>
    
    <item>
      <title>가측 함수</title>
      <link>https://freshrimpsushi.github.io/posts/measurable-function/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/measurable-function/</guid>
      <description>정의1 $\mathcal{E}$를 집합 $X$의 $\sigma$-대수라고 하자. $\alpha$를 임의의 실수라고 하자. 그러면 아래의 조건을 만족시키는 확장된 실수값을 갖는 함수 $f : X \to \overline{\mathbb{R}}$를 $\mathcal{E}$-가측$\mathcal{E}$-measurable</description>
    </item>
    
    <item>
      <title>스톤-바이어슈트라스 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-stone-weierstrass-theorem/</link>
      <pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-stone-weierstrass-theorem/</guid>
      <description>정의1 $X$ 에 대해 $A \subset C(X)$ 이라고 하자. (1) 서로 다른 $x_{1}, x_{2} \in X$ 에 대해 $f(x_{1}) \ne f(x_{2})$ 를 만족하는 $f \in A$ 가 항상 존재하면 $A$ 가 $X$ 의 점들을 분리한다Separate고 말한다. (2) $X$ 가 메트릭 스페이스이고 모든 $\varepsilon &amp;gt; 0$ 과 $f \in C(X)$ 에 대해 $| g - f | &amp;lt; \varepsilon$ 을 만족하는 $g \in A$ 가 존재하면 $A$ 가 $C(X)$ 에서 유니폼리 덴스Uniformly Dense라 한다. 정리 $X$ 가 컴팩트</description>
    </item>
    
    <item>
      <title>수치해석학에서의 최소극대화 근사와 최소제곱 근사</title>
      <link>https://freshrimpsushi.github.io/posts/minimax-approximation-and-least-squares-approximation/</link>
      <pubDate>Wed, 12 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/minimax-approximation-and-least-squares-approximation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 주어진 함수 $f : [a,b] \to \mathbb{R}$ 를 근사하는 문제가 주어져 있다고 하자. 계산은 컴퓨터의 몫이므로 다항함수로 $f$ 를 근사하는 것이 목표다. 함수를 근사시킨다는 것은 한 점에서의 계산이 아니라 정의역 $[a,b]$ 전체에서 $f$ 와 비슷한 함수를 사용하고 싶은 것이므로 가장 크게 틀리는 부분을 줄이는 것이 목표다. 이러한 상황</description>
    </item>
    
    <item>
      <title>연속함수공간의 알지브라</title>
      <link>https://freshrimpsushi.github.io/posts/algebra-of-continuous-function-space/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebra-of-continuous-function-space/</guid>
      <description>정의1 다음 세 가지 조건을 만족하는 집합 $A$ 를 $C(X)$ 의 알지브라algebra라 한다. **(i): $\emptyset \ne A \subset C(X)$ **(ii): $f,g \in A \implies (f+g) , fg \in A$ **(iii): $f \in A , c \in \mathbb{R} \implies cf \in A$ 메트릭 스페이스 $X$ 에 대해 $A \subset C(X)$ 이라고 하자. $A$ 의 모든 시퀀스 $\left\{ f_{n} \in A : n \in \mathbb{N} \right\}$ 가 어떤 $f \in A$ 에 대해 $n \to \infty$ 일 때 $\displaystyle | f - f_{n} | \to 0$ 면 $A$ 가 유니폼리 클로즈드Uniformly Closed라 한</description>
    </item>
    
    <item>
      <title>함수 근사</title>
      <link>https://freshrimpsushi.github.io/posts/approximation-of-functions/</link>
      <pubDate>Mon, 10 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/approximation-of-functions/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 수치적인 계산을 할 때 컴퓨터가 인간보다 압도적으로 빠른 것은 사실이지만, 딱히 컴퓨터가 초월함수와 무리수를 이해했기 때문은 아니다. 가령 $\displaystyle \sin {{ \pi } \over {6}} = {{1} \over { 2 }}$ 을 계산시킨다면 삼각함수의 기하학적인 정의를 이용해서 직각삼각형을 그려보고 빗변과 높이의 비를 구하는 게 아니라, 다항함수</description>
    </item>
    
    <item>
      <title>이항 급수 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-binomial-series/</link>
      <pubDate>Sun, 09 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-binomial-series/</guid>
      <description>공식 $|x| &amp;lt; 1$ 이면 $\alpha \in \mathbb{C}$ 에 대해 $$ \begin{align*} (1 + x )^{\alpha} =&amp;amp; \sum_{k=0}^{\infty} \binom{\alpha}{k} x^{k} \\ =&amp;amp; 1 + \alpha x + \dfrac{\alpha(\alpha-1)}{2!}x^{2} + \dfrac{\alpha(\alpha-1)(\alpha-2)}{3!}x^{3} + \cdots \end{align*} $$ 설명 이른바 뉴턴의 이항 정리 로써, 이항 전개가 무한대와 복소수에 대해서 일반화된 것으로 볼 수 있다. 한편 우리에게 익숙한 꼴은 다음과 같은 방법으로 간단하게 유도할 수 있다. $$ \begin{align*} &amp;amp;&amp;amp; \left( 1 + {{y} \over {x}} \right)^{\alpha} =&amp;amp; \sum_{k=0}^{\infty} \binom{\alpha}{k} \left( \dfrac{y}{x} \right)^{k} \\ \implies &amp;amp;&amp;amp; x^{-\alpha} \left( x + y \right)^{\alpha} =&amp;amp; \sum_{k=0}^{\infty} \binom{\alpha}{k} y^{k} x^{-k} \\ \implies &amp;amp;&amp;amp; \left( x + y \right)^{\alpha} =&amp;amp;</description>
    </item>
    
    <item>
      <title>가법성을 가진 연속함수의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-continuous-function-with-additivity/</link>
      <pubDate>Sat, 08 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-continuous-function-with-additivity/</guid>
      <description>정리 [1] 연속함수 $f : \mathbb{R} \to \mathbb{R}$ 가 모든 $x, y \in \mathbb{R}$ 에 대해 $f(x + y) = f(x) + f(y)$ 을 만족하면 $$ f(x) = f(1) x $$ [2] 연속함수 $g : \mathbb{R} \to ( 0 , \infty )$ 가 모든 $x, y \in \mathbb{R}$ 에 대해 $g(x + y) = g(x) g(y)$ 을 만족하면 $$ g(x) = \left( g(1) \right)^x $$ 설명 $f(x + y) = f(x) + f(y)$ 와 같이 덧셈이 함수를 넘나들면서 보존되는 성질을 가법성이라 하고 곱셈이 보존되는 성질을 승법성이라고 한다. $g$ 는 가법성과 승법성이 반반</description>
    </item>
    
    <item>
      <title>복소수에 대해 일반화된 이항 계수</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-binomial-coefficient/</link>
      <pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-binomial-coefficient/</guid>
      <description>정의 $\alpha \in \mathbb{C}$ 에 대해 다음을 이항 계수Binomial Coefficient라고 한다. $$ \binom{\alpha}{k} := \begin{cases} \displaystyle {{ \alpha ( \alpha - 1 ) \cdots ( \alpha - k + 1 ) } \over { k! }} &amp;amp; , k \in \mathbb{N} \\ 1 &amp;amp; ,k=0 \end{cases} $$ 설명 원래 이항 계수는 $\alpha \in \mathbb{N}$ 일 때만 직관적인 의미를 가지지만, 그 계산 과정만 생각해보면 딱히 자연수일 필요가 없다. 당장 생각할 수 있는 음의 정수는 물론 실수, 심지어는 복소수</description>
    </item>
    
    <item>
      <title>코시 곱: 수렴하는 두 멱급수의 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-product-of-series/</link>
      <pubDate>Thu, 06 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-product-of-series/</guid>
      <description>정리 1 $f(x) : = \sum _{k=0}^{\infty} a_{k} x^{k}$ 와 $g(x) : = \sum_{k=0}^{\infty} b_{k} x^{k}$ 의 수렴구간이 $(-r,r)$ 이고 $c_{k} := \sum_{j=0}^{k} a_{j} b_{k-j}$ 이라고 하면 $\sum_{k=0}^{\infty} c_{k} x^{k}$ 는 수렴구간 $(-r,r)$ 상에서 $f(x)g(x)$ 로 수렴한다. 설명 계수들의 곱들이 알아서 두 함수의 곱의 계수로 수렴해준다는 점은 사실 꽤 신기한 일이다. 그냥 유한다항함수였다면 증명조차 필요 없을 정도로 당연하지만, 멱급수는 무한히 많은 항을 가지기 때문이다. 증명 $x \in (-r,r)$ 와 $n \in \mathbb{N}$</description>
    </item>
    
    <item>
      <title>멱급수</title>
      <link>https://freshrimpsushi.github.io/posts/power-series/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/power-series/</guid>
      <description>정의 $S(x) : = \sum \limits_{k=0}^{\infty} a_{k} ( x - x_{0} )^{k}$ 를 멱급수라 하고, $x_{0}$ 를 $S(x)$ 의 중심Center이라 한다. $S(x)$ 가 $|x - x_{0}| &amp;lt; R$ 에 대해 절대수렴하고 $|x - x_{0}| &amp;gt; R$ 에 대해 발산할 때 $R$ 을 $S(x)$ 의 수렴반경Radius of Convergence이라 한다. $S(x)$ 가 수렴하는 가장 큰 구간을 수렴구간Interval of Convergence이라 한다. 수렴구간 $[c,d] \subset (a,b)$ 에서 $x_{0} \in (c,d)$</description>
    </item>
    
    <item>
      <title>이산 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/discrete-fourier-transform/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/discrete-fourier-transform/</guid>
      <description>빌드업1 $f$가 특정한 간격마다 측정되는 어떤 물리적인 신호라고 하자. 그러면 현실적인 조건을 생각해봤을 때, 신호가 측정되기 시작하는 순간 $t=0$와 측정이 끝나는 순간 $t=\Omega$가 존재할테니 $f$의 함숫값은 $[0, \Omega]$를 제외한 곳에서 모두 $0$이라 가정할 수 있다. 샘플링 정리 $f\in L^{2}$이고 $\hat{</description>
    </item>
    
    <item>
      <title>R 에서 벡터끼리 내적 계산하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-inner-product-in-r/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-inner-product-in-r/</guid>
      <description>코드 x&amp;lt;-1:10; x y&amp;lt;-(-1)^(1:10); y sum(x*y) x %*% y x %o% y R 에서 분석 혹은 시뮬레이션을 하다보면 가중치가 적용된 기댓값을 구할 일이 종종 있다. 물론 수식적으로 $\displaystyle \left&amp;lt; \mathbb{x}, \mathbb{y} \right&amp;gt; = \sum_{i=1}^{n} x_{i} y_{i}$ 는 아주 간단하고 R 자체의 벡터 계산이 아주 편리하기 때문에 sum() 함수만 있다면 쉽게 내적을 할 수 있다. 그러나 이는 길게 보았을 때 코드의 가독성을 떨어뜨리는 요인이 된다. 한편 $n$ 차원 벡터는 $1 \times n$ 차원</description>
    </item>
    
    <item>
      <title>푸리에 변환을 이용한 미분 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-heat-equation-using-fourier-analysis/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-heat-equation-using-fourier-analysis/</guid>
      <description>설명 푸리에 급수와 푸리에 변환은 열 방정식을 풀기 위해 등장한 개념이다. 물론 열 방정식 뿐만 아니라 조건을 만족한다면 다른 미분 방정식을 풀 때도 사용할 수 있다. 특히 푸리에 급수는 양자 물리학에서 입자의 에너지를 슈뢰딩거 방정식을 통해서 계산할 때 사용된다. 많은 물리학과 학생들은 그것이 푸리에 급수라는 것인지는 모르고 사용하긴 하지만 말해주면 뭔지</description>
    </item>
    
    <item>
      <title>라돈 변환</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-property-of-radon-transform/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-property-of-radon-transform/</guid>
      <description>정의 함수 $f : \mathbb{R}^2 \to R$가 주어졌다고 하자. $l_{s,\theta}$를 극좌표 $(s,\theta)$에 의해 결정되는 직선이라고 하자. $f$를 $l_{s,\theta}$위에서 적분한 것을 $f$의 라돈 변환이라고 하고 아래와 같이 나타낸다. $$ \begin{align*} \mathcal{R}f(s,\theta) &amp;amp;:= \int_{l_{s,\theta}}fdt \\ &amp;amp;= \int_{t =-\infty}^{\infty} f\big( s\cos\theta-t\sin\theta,\ s\sin\theta + t\cos\theta \big) dt \end{align*} $$ 설명 커널이 $K=1$인 적분변환의 일종이</description>
    </item>
    
    <item>
      <title>L1공간과 L2공간의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-l2-space-and-l1-space/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-l2-space-and-l1-space/</guid>
      <description>정의 $L^{1}$ 공간 아래의 식을 만족하는 함수 $f$를 구간 $[a,\ b]$에서 (절대)적분가능absolutely integrable다고 한다. $$ \int_a^b |f(x)| dx &amp;lt; \infty $$ 구간 $[a,b]$에서 적분가능한 함수들의 집합을 $L^{1}(a,b)$이라 한다. $$ L^{1}(a,b)= \left\{ f : \int_{-a}^{b} |f(x)| dx &amp;lt; \infty \right\} $$ $L^{2}$ 공간 아래의 식을 만족하는 함수를 제곱적분가능square-in</description>
    </item>
    
    <item>
      <title>아리마 모형에서의 드리프트</title>
      <link>https://freshrimpsushi.github.io/posts/drift-in-arima-model/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/drift-in-arima-model/</guid>
      <description>설명 시계열 분석을 하다보면 종종 다음과 같이 드리프트Drift라는 계수를 보게 된다. 물론 위의 경우 표준오차에 비해서 계수의 크기가 너무 작기 때문에 무시해도 상관 없다. 그러나 실제로 유의한 계수인 동시에 수식으로도 써야할 일이 있다면 드리프트가 무엇인지 알아야한다. 아쉽게도 국내에는 드리프트가 도대체 무엇인지에 대한 좋은 설명이 없으며, 수</description>
    </item>
    
    <item>
      <title>윈도에서 명령 프롬프트로 파일 목록 얻는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-file-list-using-cmd-in-windows/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-file-list-using-cmd-in-windows/</guid>
      <description>개요 복수의 데이터를 취합하는 프로그램을 짤 때 파일이 너무 많아서 문제가 될 수 있다. 물론 어느 프로그래밍 언어이든 이를 해결하는 방법은 각자 있겠지만, 반복할 필요가 없거나 너무 다양한 언어를 사용하는 경우 임시적인 해결법이 큰 도움이 된다. 윈도의 명령 프롬프트를 통해 쉽고 빠르게 해보자. 가이드 **Step 1. 주소 복사 파일 목록이 필요한 폴더로 들어가 주소를</description>
    </item>
    
    <item>
      <title>푸리에 역변환 정리</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-inversion-theorem/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-inversion-theorem/</guid>
      <description>빌드업 푸리에 변환을 유도하는 과정에서 역변환의 정의도 같이 유도했다. 하지만 이는 이해를 돕기 위해 단순히 설명한 것으로 변환 식을 정확하게 유도한 것은 아니다. 우선 푸리에 역변환은 아래와 같다. $$ \begin{equation} f(x) =\dfrac{1}{2\pi} \int \hat{f}(\xi) e^{i\xi x}d\xi \label{eq1} \end{equation} $$ 위 식에는 $f$로부터 얻은 $\hat{f}$로부터 $f$를 다시 얻을 수 있다는 의미가 있다. 이게 소린지, 당연한 말이 아닌</description>
    </item>
    
    <item>
      <title>계절형 아리마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/seasonal-arima-model/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/seasonal-arima-model/</guid>
      <description>모델 1 $\nabla_{s} Y_{t} := Y_{t} - Y_{t-s}$ 와 같이 정의된 오퍼레이터 $\nabla_{s}$ 를 계절형 차분Seasonal Difference이라 한다. $W_{t} := \nabla^{d} \nabla_{s}^{D} Y_{t}$ 와 같이 정의된 $\left\{ W_{t} \right\}_{t \in \mathbb{N}}$ 가 $ARMA(P,Q)$ 고 $\left\{ Y_{t} \right\}_{t \in \mathbb{N}}$ 이 $ARMA(p,q)$ 면 $\left\{ Y_{t} \right\}_{t \in \mathbb{N}}$ 는 계절형 아리마 과정 $ARIMA(p,d,q)\times(P,D,Q)_{s}$ 라고 한다. 이와 같은 꼴을 한 시계열 분석 모형을 계절형 아리마 모형이라 한다. 설명 오늘의 기온은 물론 어제의 기온에 가장 큰 영향을 받겠지</description>
    </item>
    
    <item>
      <title>몰리피케이션의 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-of-mollification-at-discontinuous-point-and-continuous-point/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-of-mollification-at-discontinuous-point-and-continuous-point/</guid>
      <description>정리 몰리파이어 $\eta_{\epsilon}$에 대해서 다음이 성립한다고 하자. $\displaystyle \alpha= \int_{-\infty}^{0} \eta_{\epsilon}(x) dx$ $\displaystyle \beta=\int_{0}^{\infty} \eta_{\epsilon} (x) dx$ $\alpha + \beta = 1$라고 하자. 그리고 $f$가 조각마다 연속이고 유계라고 하자. 그러면 $f$의 몰리피케이션은 아래와 같이 수렴한다. $$ \lim \limits_{\epsilon \rightarrow 0} f * \eta_{\epsilon}(x) = \alpha f(x+) + \beta f(x-) $$ $\eta_{\epsilon}(x)$가 짝함수이면 $$ \lim \limits_{\epsilon</description>
    </item>
    
    <item>
      <title>지수함수집합, 삼각함수집합은 정규직교기저이다</title>
      <link>https://freshrimpsushi.github.io/posts/set-of-exponential-functions-and-trigonometric-functions-is-orthonormal-basis/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/set-of-exponential-functions-and-trigonometric-functions-is-orthonormal-basis/</guid>
      <description>정리 두 집합 $\left\{ e^{inx} \right\}_{n=-\infty}^\infty$와 $\left\{ \cos nx\ \right\}_{n=0}^\infty \cup \left\{ \sin nx \right\}_{n=1}^\infty$는 [$L^{2}(-\pi,\ \pi)$]의 정규직교기저 이다. 또한 $\left\{ \cos nx \right\}_{n=0}^{\infty}$와 $\left\{ \sin nx \right\}_{n=1}^{\infty}$는 $L^{2}(0,\ \pi)$의 정</description>
    </item>
    
    <item>
      <title>평면 위의 직선을 극 좌표로 표현하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-represent-a-line-on-a-plan-in-polar-coordinates/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-represent-a-line-on-a-plan-in-polar-coordinates/</guid>
      <description>설명 평면위의 직선을 특정 짓는 방법은 여러가지가 있을테지만 직선의 기울기와 $y$절편을 이용하는 방법이 보편적이다. 중고등학생에게도 익숙할 만큼 쉬운 방법이기도 하다. 그림$(1)$과 같은 직선이 있다고 하자. 그러면 기울기$a$와 $y$절편 $b$ 이 두 정보만 알면 평면위의 직선을 나타낼 수 있다. $y=ax+b$라고 표현하거나 그림으로</description>
    </item>
    
    <item>
      <title>박스-칵스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/box-cox-transformation/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/box-cox-transformation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $x &amp;gt; 0$ 에 대해 $g(x) := \begin{cases} \displaystyle {{ x^{\lambda} - 1 } \over { \lambda }} &amp;amp; , \lambda \ne 0 \\ \log x &amp;amp; , \lambda = 0 \end{cases}$ 를 박스-칵스 변환이라 한다. $g$ 는 원래 멱변환Power Transformation이라 불리나, 박스와 칵스에 의해 소개되어 박스-칵스 변환이라고 부르기도 한다. 박스-칵스 변환의 주된 용도는 데이터를 정규분</description>
    </item>
    
    <item>
      <title>리만-르벡 보조 정리</title>
      <link>https://freshrimpsushi.github.io/posts/the-riemann-lebesgue-lemma/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-riemann-lebesgue-lemma/</guid>
      <description>정리1 $f \in L^{1}$이라고 하자. 그러면 다음의 식이 성립한다. $$ \lim \limits_{n \to \pm \infty} \hat{f}(\xi) = 0 $$ 증명 step 1에서 계단 함수 $f$에 대해서 증명하고, step 2에서 일반화한다. step 1과 step 2의 $f$가 같지 않음에 주의하라. case 1 $f$를 아래와 같은 계단 함수라고 가정하자. $$ f(x) = \sum \limits_{j=1}^n c_{j} \chi_{j}(x) $$ $c_{j}$는 상수이고 $\chi_{j}(x)=\chi_{ [-x_{j}-a_{j} ,\ x_{j}+a_{j}] }(x)$이다. 여기서 $\mathcal{F}</description>
    </item>
    
    <item>
      <title>특성 함수의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transform-of-characteristic-function-and-step-functino/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transform-of-characteristic-function-and-step-functino/</guid>
      <description>공식 특성 함수의 푸리에 변환은 다음과 같다. $$ \mathcal{F} \left[ \chi_{[-a,a]}(x) \right] = \dfrac{2 \sin(a\xi) }{\xi} $$ 증명 $$ \begin{align*} \mathcal{F} \left[ \chi_{[-a,a]}(x) \right] &amp;amp;= \int_{-\infty}^{\infty} \chi_{[-a,a]}(x)e^{-i \xi x } dx \\ &amp;amp;= \int_{-a}^{a}e^{-i \xi x} dx \\ &amp;amp;= \dfrac{1}{-i\xi} \left. e^{-i\xi x}\right]_{-a}^{a} \\ &amp;amp;= \dfrac{1}{-i\xi} \left( e^{-i a \xi} - e^{i a \xi} \right) \\ &amp;amp;= \dfrac{2}{\xi} \dfrac{e^{ia\xi} -e^{-ia\xi}}{2i} \\ &amp;amp;= \dfrac{2}{\xi} \sin (a\xi) \end{align*} $$ ■</description>
    </item>
    
    <item>
      <title>가우스 함수의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transgorm-of-gaussian-function/</link>
      <pubDate>Fri, 24 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transgorm-of-gaussian-function/</guid>
      <description>공식 가우스 함수 $f(x)=e^{-Ax^2}$의 푸리에 변환 은 다음과 같다. $$ \mathcal{F}[f] (\xi) = \mathcal{F} \left[ e^{-Ax^2} \right] (\xi)=\sqrt{\frac{\pi}{A}}e^{-\frac{\xi ^2}{4A}} $$ 설명 보조정리: 가우스 적분 $$ \int_{-\infty}^{\infty} e^{-Ax^2} dx= \sqrt{\dfrac{\pi}{A}} $$ 만약 푸리에 변환 $\mathcal{F}$ 가 $$ \left( \mathcal{F} f \right) ( \xi ) := \int_{\mathbb{R}} f(x) e^{ - i \xi x } dx $$ 가 아닌 $$ \left( \mathcal{F} f \right) ( \gamma ) := \int_{\mathbb{R}} f(x) e^{ - 2 \pi i x \gamma } dx $$ 와 같이 정의되어 있다고 하면 가우스 함수 $f(x) = e^{-A x^{2}}$ 의 푸리에 변환은 다음과 같다</description>
    </item>
    
    <item>
      <title>다차원 비선형 맵</title>
      <link>https://freshrimpsushi.github.io/posts/multi-dimensional-nonlinear-map/</link>
      <pubDate>Fri, 24 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multi-dimensional-nonlinear-map/</guid>
      <description>비선형 맵의 정의 맵 $\mathbb{f} : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 이 선형이 아니면 비선형이라 한다. 빌드업 1 어떤 맵이 선형인지 보이는 것은 어렵지만 비선형임을 보이는 것은 쉽고, 선형 문제는 쉽지만 비선형 문제는 어렵다. 이 우주의 거의 모든 것은 비선형이며 비선형은 어렵기 때문에 인간들은 비선형을 선형으로 바꿀 궁리부터 한다. 위 그림에서 주어진 곡선은 분명 휘어있긴 하지만, 아주 작</description>
    </item>
    
    <item>
      <title>푸리에 변환의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-fourier-transform/</link>
      <pubDate>Thu, 23 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-fourier-transform/</guid>
      <description>정리1 $\cal{F}f, \hat{f}$를 $f$의 푸리에 변환이라고 하자. $f \in L^{1}$이라 하자. 그러면 푸리에 변환에 대해서 다음의 성질들이 성립한다. (a) 임의의 실수 $a$에 대해서 $$ \mathcal{F} \left[ f(x-a) \right] ( \xi ) = e^{-ia\xi}\hat{f}(\xi) \quad \mathrm{and} \quad \mathcal{F} \left[ e^{iax}f(x)\right] (\xi) = \hat{f}(\xi-a) $$ (b) $\delta &amp;gt;0$에 대해서 $f_\delta(x) := \frac{1}{\delta}f ( \frac{x}{\delta} )$라고 정의하자. 그러면 $$ \mathcal{F}\left[ f_\delta \right] (\xi ) = (\mathcal{F}f)(\delta \xi) \quad \mathrm{and} \quad \mathcal{F} \left[ f(\delta x) \right] (\xi) = ( \mathcal{F} f )</description>
    </item>
    
    <item>
      <title>가법함수와 승법함수</title>
      <link>https://freshrimpsushi.github.io/posts/additivity-multiplicativity/</link>
      <pubDate>Wed, 22 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/additivity-multiplicativity/</guid>
      <description>함수 $f : X \to Y$가 주어졌다고 하자. $a, b \in X$, $a_i \in X\ (i=1,\cdots)$라고 하자. 준가법 함수 $f$가 아래의 식을 만족할 때 준가법 함수subadditive function라고 한다. $$ f(a+b) \le f(a)+f(b) $$ 절댓값을 예로 들 수 있다. $$ |3+(-4)| \le |3|+|-4| $$ 다른 예로 $f(x)=2x+3$이라 하면 $$ 13=f(2+3) \le f(2)+f(3)=7+9=16 $$ 가법 함수 $f$가 아래의 식을 만족할</description>
    </item>
    
    <item>
      <title>카라테오도리 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-caratheodory-theorem/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-caratheodory-theorem/</guid>
      <description>정의1 모든 $A \subset X$에 대해서 아래의 식이 성립하면 $E \subset X$가 카라테오도리 조건Caratheodory condition을 만족시킨다고 하거나 $E$가 $\mu^{\ast}$-가측가능$\mu^{\ast}$-measurable이라고 한다. $$ \begin{equation} \mu^{\ast}(A) = \mu^{\ast}(A\cap E) + \mu^{\ast}(A \cap E^{c}) \label{def1} \end{equation} $$ $\mu^{\ast}$은 외측도 이다. 정리</description>
    </item>
    
    <item>
      <title>다차원 선형 맵</title>
      <link>https://freshrimpsushi.github.io/posts/multi-dimensional-linear-map/</link>
      <pubDate>Mon, 20 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multi-dimensional-linear-map/</guid>
      <description>정의 1 맵 $T_{A} : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 가 모든 $a,b \in \mathbb{R}$ 과 $\mathbb{x}, \mathbb{y} \in \mathbb{R}^{m}$ 에 대해 $$ T_{A} ( a \mathbb{x} + b \mathbb{y} ) = a T_{A} ( \mathbb{x} ) + b T_{A} ( \mathbb{y} ) $$ 를 만족하면 $T_{A}$ 가 선형Linear이라고 한다. $A$ 의 아이겐 밸류들을 $\lambda_{1} , \cdots , \lambda_{m}$ 이라고 하자. 2. $| \lambda_{1} | \ne 1, \cdots , | \lambda_{m} | \ne 1$ 이면 $A$ 가 하이퍼볼릭Hyperbolic하다고 한다. 3. 하이퍼볼릭 $A$ 에 대해 $\begin{cases} | \lambda_{i} | &amp;gt;1 \\ | \lambda_{j} | &amp;lt;1 \end{cases}$ 를 만족하는</description>
    </item>
    
    <item>
      <title>비선형 1계 미분방정식의 경계의 직선화</title>
      <link>https://freshrimpsushi.github.io/posts/straightening-the-boundary-of-nonlinear-first-order-pde/</link>
      <pubDate>Mon, 20 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/straightening-the-boundary-of-nonlinear-first-order-pde/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 빌드업 비선형 1계 미분 방정식의 특성 방정식을 쉽게 풀기 위한 방법 중 하나는 정의역 $\Omega$의 경계인 $\partial \Omega$의 어떤 작은 부분인 $\Gamma$를 곧게 펴주는 것이다. 이는 항상 가능한 일이므로 경계 위의 점 $x^0$의 근방에서는 경계가 곧은 직선이라고 처음부터 가정하고 문</description>
    </item>
    
    <item>
      <title>일반화된 횔더 부등식, 횔더 부등식의 따름정리</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-hoelder-inequality/</link>
      <pubDate>Sun, 19 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-hoelder-inequality/</guid>
      <description>설명 $\Omega \subset \mathbb{R}^{n}$를 열린 집합이라고 하자. 다음의 식을 만족시키는 두 상수 $1 \lt p \lt \infty, 1 \lt p^{\prime} \lt \infty$가 주어졌다고 하자. $$ \dfrac{1}{p} + \dfrac{1}{p^{\prime}} = 1 \left(\text{or } p^{\prime} = \frac{p}{p-1} \right) $$ 만약 $u \in L^p(\Omega)$, $v\in L^{p^{\prime}}(\Omega)$이면 $uv \in L^1(\Omega)$이고 아래의 부등식이 성립한다. $$ \| uv \|_{1} = \int_{\Omega} |u(x)v(x)| dx \le \|</description>
    </item>
    
    <item>
      <title>수치해석학에서의 B-스플라인 B-Spline in Numerical Analysis</title>
      <link>https://freshrimpsushi.github.io/posts/1045/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1045/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 함수해석학에서의 B-스플라인* 글과 수식이 읽기 싫으면 그냥 그림으로 보고 이해해도 무방하다. 구간 $[a,b]$ 를 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 주어진 자유도 $K$ 에 대해서 $x_{-K} &amp;lt; x_{-K + 1} &amp;lt; \cdots &amp;lt; x_{-1} &amp;lt; x_{0}$ 과 $x_{N} &amp;lt; x_{N + 1} &amp;lt; \cdots &amp;lt; x_{N+K-1} &amp;lt; x_{N+K}$ 의 추가적인 노드를 생각한다. $i$</description>
    </item>
    
    <item>
      <title>횔더 연속 함수 공간</title>
      <link>https://freshrimpsushi.github.io/posts/spaces-of-hoelder-continuous-functions/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spaces-of-hoelder-continuous-functions/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 연속 함수 공간$(\mathrm{spaces\ of\ continuous\ functions})$ 열린 집합 $\Omega \subset \mathbb{R}^n$가 있다고 하자. 음이 아닌 정수 $m$에 대해서 $C^m(\Omega)$를 아래와 같은 조건을 만족시키는 모든 함수 $\phi$들의 집합이라고 정의한다.$|\alpha| \le m$인</description>
    </item>
    
    <item>
      <title>R 에서 데이터 프레임 열기준으로 정렬하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-sort-data-frame-by-a-column/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-sort-data-frame-by-a-column/</guid>
      <description>개요 R 에서 데이터를 정렬하는 것 자체는 sort() 함수를 사용하면 간단하게 할 수 있으나, 기본적으로 sort() 함수는 벡터만을 소팅한다. 그러나 실제로는 데이터 프레임의 수많은 카테고리를 다루기 때문에 열 단위로도 정렬할 수 있는 방법이 필요한 경우가 많다. 코드 x&amp;lt;-c(pi,3,99,0,-1) order(x) x[order(x)] head(iris) head(iris[order(iris$Petal.Length),]) order() 함수는 주어진 벡터가 오름차순이 되도록 하는 데이터의 넘버를 반환해준다. 위의 예시를 보</description>
    </item>
    
    <item>
      <title>푸리에 변환 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-fourier-transform/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-fourier-transform/</guid>
      <description>빌드업 유한한 구간을 주기로 갖는(=유한한 구간에서 정의된) 함수는 푸리에 급수를 이용해서 근사할 수 있다. 이는 유용하지만 주기함수 에 대해서만 쓸 수 있으므로 비주기 함수에 대해서도 비슷한 역할을 하는 도구가 필요하다. 이러한 아이디어에서부터 나온 것이 푸리에 변환Fourier transform이다. 푸리에 변환을 유도하는 과정에서 핵심</description>
    </item>
    
    <item>
      <title>수치해석에서의 스플라인</title>
      <link>https://freshrimpsushi.github.io/posts/spline-in-numerical-analysis/</link>
      <pubDate>Thu, 16 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spline-in-numerical-analysis/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 인터폴레이션이란 정확한 함수를 복원하는 게 아니라 그와 유사하면서도 다루기 편한 함수를 구하는 것이 목적이다. 물론 익스플릭시트Explicit하고 계산이 쉬워지도록 구할 수 있다면야 제일 좋겠지만, 이 우주는 그렇게 만만한 곳이 아니다.문제에 따라서는 간단한 부분을 빨리 풀고 복잡한 부분을</description>
    </item>
    
    <item>
      <title>R 에서 히스토그램 더 세밀하게 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-histogram-class-range/</link>
      <pubDate>Wed, 15 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-histogram-class-range/</guid>
      <description>코드 R 에서는 hist() 함수를 통해 히스토그램을 쉽게 그려볼 수 있다. 이 때 계급의 크기는 R 이 알아서 판단하고 결정하는데, 좀 더 세밀하게 보기 위해서는 nclalss 옵션을 사용하면 된다. set.seed(150421) x&amp;lt;-runif(50) win.graph(7,4); par(mfrow=c(1,2)) hist(x) hist(x,nclass=20) 위 코드를 실행시킨 결과는 다음과 같다.</description>
    </item>
    
    <item>
      <title>에르미트 인터폴레이션</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-interpolation/</link>
      <pubDate>Tue, 14 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-interpolation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 서로 다른 $x_{1} , \cdots , x_{n}$ 의 데이터 $(x_{1}, y_{1} , y&#39;_{1}) , \cdots , (x_{n} , y_{n}, y&#39;_{n})$ 에 대해 $\begin{cases} p (x_{i} ) = y_{i} \\ p&#39;(x_{i} ) = y&#39;_{i} \end{cases}$ 와 $\deg H \le 2n-1$ 을 만족하는 폴리노미얼 $H$ 를 에르미트 인터폴레이션이라고 한다. [1]** 존재성과 유일성 : 주어진 데이터에 대해서 $H$ 는 유일하게 존재한다. [2]: 라그랑주 폼 : $\displaystyle H_{n} (x) = \sum_{i=1}^{n} y_{i} h_{i} (x) + \sum_{i=1}^{n} y&#39;_{i} \tilde{h}_{i} (x)$ [3]: 뉴턴 계차</description>
    </item>
    
    <item>
      <title>정규직교기저 완비 정규직교집합</title>
      <link>https://freshrimpsushi.github.io/posts/orthonormal-basis-complete-orthonormal-set/</link>
      <pubDate>Tue, 14 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthonormal-basis-complete-orthonormal-set/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **정규직교집합이 가지는 동치조건 $\left\{ \phi_n \right\}_1^\infty$가 $L^2(a,b)$의 정규직교집합 이고 $f \in L^2(a,b)$라고 하자. 그러면 아래의 조건은 모두 동치이다.$(a)$ 모든 $n$에 대해서 $\left&amp;lt; f, \phi_n \right&amp;gt;=0$이면, $f=0$이</description>
    </item>
    
    <item>
      <title>L2 공간에서의 베셀 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/bessels-inequality/</link>
      <pubDate>Mon, 13 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bessels-inequality/</guid>
      <description>정리 베셀 부등식$(\mathrm{Bessel&amp;rsquo;s\ inequality})$ $\left\{ \phi_n \right\}_1^\infty$가 $L^2(a,b)$에서의 정규직교집합 $(\mathrm{orthonormal\ set})$이라고 하자. 그리고 $f\in L^2(a,b)$라고 하자. 그러면 아래의 부등식이 성립하고 이를 베셀 부등식이라 한다. $$ \sum \limits_{n=1}^\infty | \left&amp;lt;f, \phi_n \right&amp;gt;|^2 \le | f | ^2 $$ 설명 $L^2$ 공간 아래</description>
    </item>
    
    <item>
      <title>에르미트-제노키 공식</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-genocchi-formula/</link>
      <pubDate>Sun, 12 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-genocchi-formula/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 서로 다른 $x_{0}, \cdots , x_{n}$ 에 대해 $f \in C^{n} \left( \mathscr{H} \left\{ x_{0}, \cdots , x_{n} \right\} \right)$ 이라 하자. 그러면 $\displaystyle \tau_{n} := \left\{ ( t_{1} , \cdots , t_{n} ) : t_{i} \ge 0 \land \sum_{i=1}^{t} t_{i} \le 1 \right\}$ 과 $\displaystyle t_{0} = 1 - \sum_{i=1}^{n} t_{i}$ 에 대해 $\displaystyle f [ x_{0}, \cdots , x_{n} ] = \int \cdots \int_{\tau_{n}} f^{(n)} ( t_{0} x_{0} + \cdots + t_{n} x_{n} ) dt_{1} \cdots dt_{n}$ $\mathscr{H} \left\{ a,b,c, \cdots \right\}$ 는 $a,b,c, \cdots$ 를 포함하는 가장 작은 구간을 나타낸다.에르미트-제노키 공식은 그 자체</description>
    </item>
    
    <item>
      <title>함수열의 놈수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-norm-of-a-sequence-of-function/</link>
      <pubDate>Sun, 12 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-norm-of-a-sequence-of-function/</guid>
      <description>정의 함수열 $\left\{ f_n \right\}$이 주어졌다고 하자. $\| f_{n} - f \|$가 $0$으로 수렴하면 $f_{n}$이 $f$로 놈수렴한다converge in norm고 하고 다음과 같이 표기한다. $$ f_n \to f \text{ in norm } $$ 혹은 $$ \| f_n - f\| \to 0 $$ 혹은 $$ \lim \limits_{n \to 0} \| f_{n}-f\|=0 $$ 설명 수열의 극한을 정의하기 위해서는 거리의 개념이 필요하다. 함수공간에서 거리는</description>
    </item>
    
    <item>
      <title>R 에서 데이터 표준화하기 표준화된 잔차 보기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-standardize-data-in-r/</link>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-standardize-data-in-r/</guid>
      <description>코드 R 은 통계에 특화된 언어인만큼 Z-score $\displaystyle z:= {{x - \mu} \over {\sigma}}$ 를 구해야할 일이 많다. 이 때 내장된 scale() 함수를 사용하면 편리하다. 예제로써 $\mathbb{x} = ( 1, \cdots , 10 )$ 이라는 벡터를 표준화해보자. center(평균)나 scale(표준편차)과 같이 지저분하게 뜨는 게 보기 싫다면 그냥 벡터를 취하면 된다. 한편 표준화를 가장 많이 하게 되는 일 중 하나가 회귀분석 후 잔</description>
    </item>
    
    <item>
      <title>뉴턴 계차상 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-newton-divided-difference-formula/</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-newton-divided-difference-formula/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 서로 다른 $x_{0} , \cdots , x_{n}$ 의 데이터 $(x_{0}, f(x_{0} )) , \cdots , (x_{n} , f( x_{n} ) )$ 에 대해 $\displaystyle p_{n} (x) =\sum_{i=0}^{n} f [ x_{0} , \cdots , x_{i} ] \prod_{j=0}^{i-1} (x - x_{j} ) $ 복잡해보이지만 $n=1,2,3$ 에 대해서 실제로 전개를 해보면 다음과 같이 단순하게 나타난다. $$ p_{0} (x) = f(x_{0}) $$ $$ p_{2} (1) = f( x_{0} ) + (x - x_{0} ) f [ x_{0} , x_{1} ] $$ $$ p_{2} (x) = f( x_{0} ) + (x - x_{0} ) f [ x_{0} , x_{1} ] + ( x</description>
    </item>
    
    <item>
      <title>지연 시각 연속 분포에 대한 지연 전위</title>
      <link>https://freshrimpsushi.github.io/posts/retarded-potential-of-continuous-distributions/</link>
      <pubDate>Thu, 09 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/retarded-potential-of-continuous-distributions/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **지연 시각$(\mathrm{retarded\ time})$ 전하와 전류분포가 시간에 따라 변하지 않으면 스칼라 전위와 벡터 전위는 다음의 푸아송 방정식을 만족한다. $$ \nabla^2 V=-\dfrac{1}{\epsilon_0} \rho,\quad \nabla^2 \mathbf{A}=-\mu_0\mathbf{J} $$ 이를 풀면 다음과 같다. $$ V(\mathbf{r})=\dfrac{1}{4\pi\epsilon_0} \int \dfrac{ \rho(\mathbf{r}^{\prime}) }{ \eta } d\tau^{\prime},\quad \mathbf{A}( \mathbf{r} ) = \dfrac{\mu_0}{4\pi} \int \dfrac{\mathbf{J}(\mathbf{r}^{\prime})}{\eta}d\tau^{\prime} \quad \cdots (1) $$ $\boldsymbol{\eta}$</description>
    </item>
    
    <item>
      <title>라그랑주 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-lagrange-formula/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-lagrange-formula/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 서로 다른 $x_{0} , \cdots , x_{n}$ 의 데이터 $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$ 에 대해 $\displaystyle l_{i} (x) := \prod_{i \ne j} \left( {{ x - x_{j} } \over { x_{i} - x_{j} }} \right)$ 이라고 하면 $\displaystyle p_{n} (x) = \sum_{i=0}^{n} y_{i} l_{i} (X)$ 라그랑주 공식은 폴리노미얼 인터폴레이션을 찾는 방법 중 가장 심플한 공식이다. Strategy: $l_{i}$ 이 인덱스에 대해 크로데커 델타 함수임을 보인다.유도 $$ \displaystyle l_{i} (x_{i}) = \prod_{i \ne j} \left( {{ x_{i}</description>
    </item>
    
    <item>
      <title>특성 방정식을 이용한 비선형 1계 편미분 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-nonlinear-first-order-pde-using-characteristic-equations/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-nonlinear-first-order-pde-using-characteristic-equations/</guid>
      <description>x와 p에 대해서, 편미분방정식의 변수임을 강조할 때는 일반 글씨체 $x,p \in \mathbb{R}^{n}$으로 표기하고, $s$에 대한 함수임을 강조할 때는 굵은 글씨체 $\mathbf{x}, \mathbf{p} \in \mathbb{R}^{n}$으로 표기한다. 설명1 특성 방정식 $$ \begin{cases} \dot{\mathbf{p}} (s) = -D_{x}F\big(\mathbf{p}(s),\ z(s),\ \mathbf{x}(s) \big)-D_{z}F\big(\mathbf{p}(s),\ z(s),\ \mathbf{x}(s) \big)\mathbf{p}(s) \\ \dot{z}(s) = D_pF\big(\mathbf{p}(s),\ z(s),\ \mathbf{x}(s) \big) \cdot \mathbf{p}(s) \\ \dot{\mathbf{x}}(s) = D_pF\big(\mathbf{p}(s),\ z(s),\ \mathbf{x}(s) \big) \end{cases} $$ 특성 방정식을 이용한 비선형 1계</description>
    </item>
    
    <item>
      <title>비선형 1계 편미분 방정식의 특성 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/characteristic-equations-of-nonlinear-first-order-pde/</link>
      <pubDate>Tue, 07 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/characteristic-equations-of-nonlinear-first-order-pde/</guid>
      <description>x와 p에 대해서, 편미분방정식의 변수임을 강조할 때는 일반 글씨체 $x,p \in \mathbb{R}^{n}$으로 표기하고, $s$에 대한 함수임을 강조할 때는 굵은 글씨체 $\mathbf{x}, \mathbf{p} \in \mathbb{R}^{n}$으로 표기한다. 특성 메소드1 열린 집합 $\Omega \subset \mathbb{R}^{n}$가 주어졌다고 하자. $u\in C^{2}(\Omega)$가</description>
    </item>
    
    <item>
      <title>비선형 1계 편미분 방정식의 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/notation-of-nonlinear-first-order-pde/</link>
      <pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/notation-of-nonlinear-first-order-pde/</guid>
      <description>표기법1 비선형 1계 편미분방정식은 다음과 같이 표기한다. $$ \begin{equation} F(Du, u, x) = F(p, z, x) = 0 \label{eq1} \end{equation} $$ $\Omega \subset \mathbb{R}^{n}$은 열린집합 $x\in \Omega$ $F : \mathbb{R}^n \times \mathbb{R}^n \times \bar{ \Omega } \to \mathbb{R}$는 주어진 함수 $u : \bar{ \Omega } \to \mathbb{R}$는 $F$의 변수 설명 비선형 1계 편미분 방정식 $F$를 푼다는 것은, 주어진 $F$에 대해서 $F</description>
    </item>
    
    <item>
      <title>폴리노미얼 인터폴레이션</title>
      <link>https://freshrimpsushi.github.io/posts/polynomial-interpolation/</link>
      <pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/polynomial-interpolation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 서로 다른 $x_{0} , \cdots , x_{n}$ 의 데이터 $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$ 에 대해 $p (x_{i} ) = y_{i}$ 와 $\deg p \le n$ 을 만족하는 폴리노미얼 $p$ 를 폴리노미얼 인터폴레이션이라 한다. [1] 존재성과 유일성**: 주어진 데이터에 대해서 $p$ 는 유일하게 존재한다. [2] 라그랑주 공식**: $\displaystyle p_{n} (x) = \sum_{i=0}^{n} y_{i} l_{i} (X)$ [3] 뉴턴 계차상 공식**: $\displaystyle p_{n} (x) =</description>
    </item>
    
    <item>
      <title>R 에서 현재 날짜 시간 확인하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-time-and-date-in-r/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-time-and-date-in-r/</guid>
      <description>코드 R 뿐만이 아니라 프로그래밍 언어를 사용해야하는 많은 작업에서 로그를 작성하고 해당 시각에 대한 정보가 필요하다. R 에서는 Sys.Date() 함수를 통해 날짜를 확인할 수 있으며, Sys.time() 함수를 통해 초 단위까지의 정확한 시각을 알 수 있다. 대소문자에 주의해야하며, 만약 날짜가 필요 없다면 문자열을 쪼개서 시각에 대한 정보만 취하면 될 것이다.</description>
    </item>
    
    <item>
      <title>수직파 평행파 선편광</title>
      <link>https://freshrimpsushi.github.io/posts/transverse-wave-longitudinal-wave-linear-polarization/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transverse-wave-longitudinal-wave-linear-polarization/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 위 그림과 같이 진행방향과 진동방향이 서로 수직인 파동을 수직파$(\mathrm{transverse\ wave})$ 또는 횡파라고 한다. 반대로 진행방향과 진동방향이 서로 평행한 파동을 평행파$(\mathrm{longitudinal\ wave})$ 또는 종파라고 한다.편광$(\mathrm{</description>
    </item>
    
    <item>
      <title>쿨롱 게이지와 로렌츠 게이지</title>
      <link>https://freshrimpsushi.github.io/posts/coulomb-gauge-and-lorenz-gauge/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coulomb-gauge-and-lorenz-gauge/</guid>
      <description>1 🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **** 게이지 변환 **** 1. 쿨롱 게이지 **$(\mathrm{Coulomb\ gauge})$ 정자기학에서와 같이 벡터 전위의 발산Divergence을 $0$으로 한다. $$ \nabla \cdot \mathbf{A}=0 $$ 이렇게 하면 전하밀도에 관한 식을 스칼라전위에 대해서만 나타낼 수 있다. 즉, 푸아송 방정식$(\mathrm{Poisson\ equation})$이 된다</description>
    </item>
    
    <item>
      <title>수치해석에서의 인터폴레이션</title>
      <link>https://freshrimpsushi.github.io/posts/interpolation-in-numerical-analysis/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interpolation-in-numerical-analysis/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 주어진 $(n+1)$쌍의 데이터 $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$ 에 대해 $f (x_{i} ) = y_{i}$ 를 만족하면서 어떤 특정한 성질을 가지는 $f$ 를 찾는 방법을 보간법 혹은 내삽법이라 한다. 예를 들어 위와 같이 데이터가 있긴한데 가운데 데이터가 비어있는 상황을 생각해보자. 물론 실제 데이터가 있는게 가장 좋지만, 없으면 예측이</description>
    </item>
    
    <item>
      <title>조화 함수의 스무싱 이펙트</title>
      <link>https://freshrimpsushi.github.io/posts/smoothing-effect-in-laplaces-equation/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/smoothing-effect-in-laplaces-equation/</guid>
      <description>정리 평균값 성질 $$ \begin{align*} u(x) = -\!\!\!\!\!\! \int_{\partial B(x,r)} udS = -\!\!\!\!\!\! \int _{B(x,r)} udy \end{align*} $$ $u \in C(\Omega)$가 각각의 열린 볼 $B(x,r)\subset \Omega$에서 평균값 성질을 만족한다고 하자. 그러면 다음이 성립한다. $$ u \in C^{\infty}(\Omega) $$ 설명 하모닉이면, 내부에서 매끄럽다는 말이다. 주의해야 할 점은 경계인 $\partial \Omega$에서는 매끄러움이나 연속성이 보장되지 않는다는 것이다. 증명 $\e</description>
    </item>
    
    <item>
      <title>멀티 인덱스 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/multiindex-notation/</link>
      <pubDate>Thu, 02 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiindex-notation/</guid>
      <description>정의1 각 성분이 음이 아닌 정수인 순서쌍 $\alpha=(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n})$을 오더가 $|\alpha|$인 멀티 인덱스multi-index 라고 한다. 이때 $| \alpha|$는 다음과 같다. $$ |\alpha| = \sum _{i}^{n} \alpha_{i} = \alpha_{1} + \cdots + \alpha_{n} $$ 표기법 $x = (x_{1}, x_{2}, \dots, x_{n}) \in \mathbb{R}^{n}$에 대해서 $x^{\alpha}$는 다음과 같다. $$ x^{\alpha} :=</description>
    </item>
    
    <item>
      <title>몰리피케이션</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-smoothness-of-mollification/</link>
      <pubDate>Thu, 02 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-smoothness-of-mollification/</guid>
      <description>정의 1 $f \in \href{https://freshrimpsushi.github.io/posts/locally-integrable/}{L^1_{\mathrm{Loc}}( \Omega)}$와 $\epsilon&amp;gt;0$에 대해서 $f$의 $\epsilon$-몰리피케이션$\epsilon$ -mollification을 다음과 같이 정의한다. $$ f^{\epsilon}(x) := \eta_{\epsilon} * f (x) =\int_{\mathbb{R}^{n}} \eta_{\epsilon}(x-y)f(y)dy, \quad x\in \Omega_{&amp;gt;\epsilon} $$ 이때 $f$는 $\Omega$ 밖에서는 $0$로 정의된 함수이다. $\eta_\epsilon$는 몰리파이어이다</description>
    </item>
    
    <item>
      <title>카오틱 트랜지션</title>
      <link>https://freshrimpsushi.github.io/posts/chaotic-transition/</link>
      <pubDate>Thu, 02 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaotic-transition/</guid>
      <description>정의 시스템이 파라매터의 변화에 따라 카오틱해지거나 카오틱해지지 않는 등의 현상을 카오틱 트랜지션이라 한다. 예시 예로써 로지스틱 패밀리를 생각해보면 $g_{a} = ax (1-x)$ 로 만들어지는 시스템은 파라매터 $a$ 에 따라 달라지는 모습을 보이다가 $a=4$ 일 때 카오틱 오빗을 가짐을 확인할 수 있다. 그러면 그 다음 질문은 바로 &amp;lsquo;$a&amp;gt;4$ 일 때는 어떻게 될 것인가&amp;rsquo;다. 우</description>
    </item>
    
    <item>
      <title>디키-풀러 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/dickey-fuller-test/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dickey-fuller-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 시계열 데이터 $\left\{ y_{t} \right\}$ 가 주어져 있다고 하자. $H_{0}$ : 데이터 $\left\{ y_{t} \right\}$ 는 정상성을 가지지 않는다. $H_{1}$ : 데이터 $\left\{ y_{t} \right\}$ 는 정상성을 갖는다. 디키-풀러 테스트는 시계열 데이터가 정상성을 가지는지 가지지 않는지를 확인할 때 사용한다. 정상성을 가지지 않으면 차분을 통해 평균을 일정하게 만들어주어야 한다.</description>
    </item>
    
    <item>
      <title>몰리파이어</title>
      <link>https://freshrimpsushi.github.io/posts/mollifier/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mollifier/</guid>
      <description>정의1 함수 $\eta \in C^{\infty}(\mathbb{R}^{n})$을 다음과 같이 정의하자. $$ \begin{equation} \eta (x) := \begin{cases} C \exp \left( \dfrac{1}{|x|^2-1} \right) &amp;amp; |x|&amp;lt;1 \\ 0 &amp;amp; |x| \ge 1\end{cases} \label{def} \end{equation} $$ 이러한 $\eta$를 몰리파이어mollifier라 한다. 특히 $C&amp;gt;0$가 $\int_{\mathbb{R}^{n}} \eta dx=1$을 만족시키는 상수일 때 $\eta$를 스탠다드 몰리파이어standard mol</description>
    </item>
    
    <item>
      <title>사인파와 복소 파동함수</title>
      <link>https://freshrimpsushi.github.io/posts/sinusoidal-wave-and-complex-wave-function/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sinusoidal-wave-and-complex-wave-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 ** **1. 사인파$(\mathrm{sinusoidal\ wave})$ 1차원 파동방정식 을 살펴보면 파동함수 $f(x,t)$는 $x-vt$만의 함수로 나타난다는 것을 알 수 있다. 이때 파동 함수를 일반적으로 삼각함수꼴로 나타낸다. 주기함수(파동함수)를 삼각함수의 선형결합으로 나타내는 푸리</description>
    </item>
    
    <item>
      <title>지도학습과 비지도학습</title>
      <link>https://freshrimpsushi.github.io/posts/supervised-learning-vs-unsupervised-learning/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/supervised-learning-vs-unsupervised-learning/</guid>
      <description>정의 머신러닝에서 종속변수가 정해진 경우를 지도학습, 그렇지 않은 경우를 비지도학습이라고 한다. 예시 지도학습과 비지도학습의 차이는 쉽게 비유하자면 객관식과 주관식의 차이다. 예를 들어 위와 같이 6개의 타일을 주고 색을 답하는 문제가 있다고 해보자. 지도학습 그런데 여기서 녹색이냐 적색이냐의 두 가지 선택지만 있다면 솔직히 반반도 있고 아예 노란</description>
    </item>
    
    <item>
      <title>파동의 경계조건 반사 투과</title>
      <link>https://freshrimpsushi.github.io/posts/boundary-conditoion-of-wave-reflection-transmission/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/boundary-conditoion-of-wave-reflection-transmission/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 위 그림과 같이 서로 다른 줄 2개가 묶여있다고 하자. 파동이 줄 1을 따라서 왼쪽에서 오른쪽으로 전파되는 상황이라고 하자. 파동의 전파 속도는 질량과 관계가 있으므로 줄이 묶인 곳을 지나면서 파동의 속도가 달라진다. 편의상 매듭의 위치를 $x=0$라고 하고 파동이 왼쪽에서 들어온다고 하자. 그러면</description>
    </item>
    
    <item>
      <title>1차원 파동 방정식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/dimension-wave-equation/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dimension-wave-equation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정의 1차원에서의 파동 방정식은 아래와 같다. $$ \dfrac{\partial ^2 f }{\partial x^2} = \dfrac{1}{v^2}\dfrac{\partial ^2 f}{\partial t^2} $$ 이때 $v$는 파동의 전파 속력이다. 0. 위 그림 1과 같이 속력이 $v$로 일정한 파동이 있다고 하자. 시각 $t$에서 $x$점의 파동의 변위를 $f(x,t)$라고 하자. 처음 실의 변위를 $g(x)=f(x,0)$라</description>
    </item>
    
    <item>
      <title>수치해석에서의 경사하강법</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-descent-method/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-descent-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 머신러닝에서의 경사하강법 스칼라 함수 $\varphi : \mathbb{R}^{n} \to \mathbb{R}$ 을 비용 함수Cost Function이라 한다. 비용 함수 $ \varphi ( \mathbb{x} )$ 의 극소값을 구하기 위해 $\mathbb{x} = \mathbb{x}_{n}$ 에서 $\varphi ( \mathbb{x}_{n+1} ) &amp;lt; \varphi ( \mathbb{x}_{n} )$ 를 만족시키는 $\mathbb{x}_{n+1}$ 를 찾는 알고리즘을 하강법Descent Method이라 한다. $\varphi$ 를 비용 함수라고 부를만한 예로</description>
    </item>
    
    <item>
      <title>네츄럴 인베리언트 메져</title>
      <link>https://freshrimpsushi.github.io/posts/natural-invariant-measure/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/natural-invariant-measure/</guid>
      <description>정의 1 카오틱한 동역학계에서 충분히 시간이 지난 뒤의 스테이트를 확률적으로 나타낸 분포함수를 네츄럴 (인베리언트) 메져라 한다. 예시 1 예로써 로지스틱 맵 $g_{4} (x) = 4 x (1 -x)$ 를 생각해보면 카오틱한 시스템이기 때문에 초기값 $x_{0} \in [0,1]$ 만 가지고는 충분히 큰 $N$ 에 대해 $x_{N} = g_{4}^{N} (x_{0})$ 을 전혀 예측할 수 없다. 하지만 이렇게 카오틱한 오빗이 반드시 $[0,1]$ 의 모든 지점에서</description>
    </item>
    
    <item>
      <title>전기역학에서의 운동량 보존</title>
      <link>https://freshrimpsushi.github.io/posts/law-of-conservation-of-momentum-in-electromagnetics/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/law-of-conservation-of-momentum-in-electromagnetics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **전자기학에서의 운동량 보존 법칙 $$ \dfrac{d \mathbf{p}}{dt} =-\epsilon_0\mu_0\dfrac{d}{dt}\int_{\mathcal{V}} \mathbf{S} d\tau + \oint_{\mathcal{S}} \mathbf{T} \cdot d\mathbf{a} $$ 뉴턴의 제 2법칙에 의하면 물체가 받는 힘과 그 물체의 운동량의 변화량은 같다. $$ \mathbf{F} = \dfrac{d \mathbf{p}}{dt} $$ $\mathbf{p}$는 부피 $\mathcal{V}$속의 입자의 총 역학적 운동량이다. 전자기장에 저장된 운동량과 구분하기 위</description>
    </item>
    
    <item>
      <title>전자기장의 각운동량</title>
      <link>https://freshrimpsushi.github.io/posts/angular-momentum-of-electromagnetic-field/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/angular-momentum-of-electromagnetic-field/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 전자기장에 저장된 각운동량은 다음과 같다. $$ \mathbf{\ell} = \mathbf{r} \times \mathbf{g}=\epsilon_0\big( \mathbf{r} \times (\mathbf{E} \times \mathbf{B} )\big) $$ $\mathbf{g}$는 전자기장에 저장된 운동량 밀도 이다. 전자기장은 단순히 전하들 사이에 작용하는 전자기력의 매개체일 뿐 아니라 스스로 에너지 도 가지고 있다. $$ u =\dfrac{1}{2} \left( \epsilon_0 E^2 + \dfrac{1}{\mu_0} B^2 \right) $$ 그리고 운동량도 가지고 있</description>
    </item>
    
    <item>
      <title>스칼라 필드의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-in-scalar-field/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-in-scalar-field/</guid>
      <description>정의 스칼라 필드 $f : \mathbb{R}^{n} \to \mathbb{R}$ 에 대해 한 점 $\mathbb{x}_{0} \in \mathbb{R}^{n}$ 에서 함수의 증가율이 가장 큰 방향을 나타낸 벡터를 $\mathbb{x}_{0}$ 에서 $f$ 의 그래디언트 라고 한다. 설명 스칼라장의 예시로써 위의 그림을 생각해보자. 위 그림은 $z(x,y) = x^2 - y^2$ 와 같이 정의된 함수 $z : \mathbb{R}^{2} \to \mathbb{R}$ 을 시각적으로 나타낸 것이다. $y= f(x)$ 와 같은 곡선에서는 변화율을 구할만할 방향이 $x$ 축 뿐이었기 때문에 접선의 기울기를</description>
    </item>
    
    <item>
      <title>바이퍼케이션 다이어그램</title>
      <link>https://freshrimpsushi.github.io/posts/bifurcation-diagram/</link>
      <pubDate>Sat, 27 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bifurcation-diagram/</guid>
      <description>정의 동역학계에서 파라매터의 변화에 따라 나타나는 오빗을 표현한 그림을 바이퍼케이션 다이어그램이라 한다. 예시1 예로써 로지스틱 패밀리를 생각해보면 파라매터 $a$ 의 변화에 따라 충분히 큰 $N$ 에 대해 $x_{N}$ 의 값은 다음 바이퍼케이션 다이어그램의 검은색 범위 안에 포함된다고 예상할 수 있다. $1&amp;lt;a&amp;lt;3$ 일 때는 하나의 선인 것을 보아 $x_N$ 은 하나의 고정점에서 머무르고,</description>
    </item>
    
    <item>
      <title>넌리니어 시스템을 풀기 위한 뉴턴 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/newton-method-for-nonlinear-system/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newton-method-for-nonlinear-system/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 1차원에서의 뉴턴-랩슨 메소드 $\mathbb{f} ( \mathbb{x} ) := \begin{bmatrix} f_{1}( \mathbb{x} ) \\ \vdots \\ f_{N} ( \mathbb{x} ) \end{bmatrix}$ 와 같은 다변수 함수 $\mathbb{f} : \mathbb{R}^{N} \to \mathbb{R}^{N}$ 가 $\mathbb{f} \in C^{2} \left( N ( \alpha ) \right)$ 이고 $\mathbb{f} ( \alpha ) = \mathbb{0}$, $\left[ D \mathbb{f} ( \alpha ) \right]^{-1}$ 이 존재한다고 하자. $\alpha$ 와 충분히 가까운 초기값 $\mathbb{x}_{0}$ 에 대해 $\displaystyle \mathbb{x}_{n+1} := \mathbb{x}_{n} - \left[ D \mathbb{f} ( \mathbb{x}_{n} ) \right]^{-1} f ( \mathbb{x}_{n} )$ 과 같이 정의된 수열 $\left\{ \mathbb{x}_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$</description>
    </item>
    
    <item>
      <title>딥러닝에서의 드롭아웃</title>
      <link>https://freshrimpsushi.github.io/posts/dropout/</link>
      <pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dropout/</guid>
      <description>정의 드롭아웃Dropout이란 인공 신경망의 뉴런을 확률적으로 사용하지 않음으로써 과적합을 방지하는 기법이다. 설명 언뜻 생각하면 그냥 학습을 덜 하는 것이고 실제로도 어느정도는 맞는 말이다. 일정 확률로 뉴런을 사용하지 않다보면 &amp;lsquo;영향력이 지나치게 강한&amp;rsquo; 뉴런이 무시될 수도 있다. 영향력이 지나치게 강하다는 것은</description>
    </item>
    
    <item>
      <title>R 에서 야코비 행렬 헤세 행렬 구하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-jacobian-matrix-hessian-matrix-in-r/</link>
      <pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-jacobian-matrix-hessian-matrix-in-r/</guid>
      <description>코드 R 에서 야코비 행렬과 헤세 행렬을 구하기 위해서는 numDeriv 패키지의 jacobian() 함수와 hessian() 함수를 사용한다. install.packages(&amp;quot;numDeriv&amp;quot;) library(numDeriv) f &amp;lt;- function(v) {c(v[1]^2 + v[2]^2 - 1, sin(pi*v[1]/2) + v[2]^3)} g &amp;lt;- function(v) {(v[1])^3+(v[2])^2} jacobian(f, c(1,1)) hessian(g, c(1,1)) 위 코드를 실행시킨 결과는 다음과 같다. 위는 $f(x,y) := \begin{bmatrix} x^2 + y^2 -1 \\ \displaystyle \sin {{ \pi } \over {2} } x + y^3 \end{bmatrix}$ 의 야코비 행렬에 $x=y=1$ 을 대입한 결과, 아래는 $g(x,y) := x^3 + y^2$ 의 헤세 행렬에 $x=y=1$ 을 대입한 결과다. 실제로 $f$ 의 야코비 행렬은</description>
    </item>
    
    <item>
      <title>푸아송 방정식에 대한 디리클레 문제의 해의 유일성</title>
      <link>https://freshrimpsushi.github.io/posts/uniqueness-of-solution-of-the-dirichlet-problem-of-poissons-equation/</link>
      <pubDate>Sun, 21 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniqueness-of-solution-of-the-dirichlet-problem-of-poissons-equation/</guid>
      <description>정리1 $\Omega \subset \mathbb{R}^n$이 열려있고 유계라고 하자. 그리고 $g \in C(\partial \Omega)$, $f \in C(\Omega)$라고 하자. 그러면 아래와 같은 푸아송방정식의 디리클레 문제에서, 솔루션 $u \in C^2(\Omega) \cap C(\bar{\Omega})$는 존재하면 유일하다(=많아봤자 1개 존재한다). $$ \begin{equation} \left\{ \begin{aligned} -\Delta u &amp;amp;= f &amp;amp;&amp;amp; \text{in } \Omega \\ u &amp;amp;= g &amp;amp;&amp;amp; \text{on }\partial \Omega \end{aligned} \right. \label{eq1} \end{equation} $$ 증</description>
    </item>
    
    <item>
      <title>딥러닝에서의 소프트맥스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/softmax-function/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/softmax-function/</guid>
      <description>정의 $\mathbb{x} := x_{1} , \cdots , x_{n} \in \mathbb{R}^{n}$ 이라고 하자. $\displaystyle \sigma ( \mathbb{x} ) = {{ e^{x_{j}} } \over {\sum_{i=1}^{n} e^{x_{i}} }}$ 에 대해 $\sigma( \mathbb{x} ) := \left( \sigma_{1} (\mathbb{x}) , \cdots , \sigma_{n} (\mathbb{x} ) \right)$ 와 같이 정의된 $\sigma : \mathbb{R}^{n} \to (0,1)^{n}$ 을 소프트맥스 함수라 한다. 설명 소프트맥스 함수는 활성화 함수의 일종으로써, 정의역이 $\mathbb{R}^{n}$ 이라는 특징이 있다. 이는 벡터로 인풋을 받아 그 값들을 정규화하는데에 쓰기 위함이다. 어떤 $\mathbb{x} \in \mathbb{R}$ 이든 $\sigma( \mathbb{x} )$ 의 모든 성분은</description>
    </item>
    
    <item>
      <title>조화함수의 최대원리</title>
      <link>https://freshrimpsushi.github.io/posts/maximum-principle-of-harmonic-functions/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maximum-principle-of-harmonic-functions/</guid>
      <description>정리1 $\Omega \subset \mathbb{R}^n$가 열려있고 유계라고 하자. 그리고$u : \Omega \to \mathbb{R}$가 $u \in C^2(\Omega) \cap C(\bar \Omega)$이고 라플라스 방정식을 만족한다고 하자. 그러면 다음이 성립한다. (i) 최대 원리maximum principle $$ \max \limits_{\bar \Omega} u = \max \limits_{\partial \Omega} u \quad \left( \mathrm{or} \ \ \min \limits_{\bar \Omega} u= \min \limits_{\partial \Omega} u \right) $$ (ii) 강한 최대원리strong maximum principle $\Ome</description>
    </item>
    
    <item>
      <title>헤세 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/hessian-matrix/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hessian-matrix/</guid>
      <description>정의 $D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 스칼라 함수 $f : D \to \mathbb{R}$ 에 대해 다음과 같은 행렬 $H \in \mathbb{R}^{n \times n}$ 을 $f$ 의 헤세 행렬이라 한다. $$ H := \begin{bmatrix} {{\partial^2 f } \over {\partial x_{1}^2 }} &amp;amp; \cdots &amp;amp; {{\partial^2 f } \over { \partial x_{1} \partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial^2 f } \over {\partial x_{n} \partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial^2 f_{m} } \over {\partial x_{n}^2 }} \end{bmatrix} $$ 설명 야코비 행렬이 함수의 고차원적인 도함수에 해당한다면, 헤세 행렬은 고차원적인 이계도함수라고 볼 수 있다.</description>
    </item>
    
    <item>
      <title>딥러닝에서의 활성화 함수</title>
      <link>https://freshrimpsushi.github.io/posts/activation-function/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/activation-function/</guid>
      <description>정의 실제 생물의 역치를 모방한 비선형 함수를 활성화 함수라 한다. 모티브 역치란 생물이 자극에 대해 어떤 반응을 일으키는 데 필요한 최소한의 자극의 세기로써, 딥러닝은 이를 모방하기 위해 각 노드의 계산 결과에 활성화 함수를 취해 다음 레이어로 넘긴다. 이러한 비선형적 보정이 없다면 딥러닝에서 히든 레이어를 두며 계산을 여러번 하는 의미가 없다.활성화 함</description>
    </item>
    
    <item>
      <title>부피 속의 전하가 받는 전자기력</title>
      <link>https://freshrimpsushi.github.io/posts/total-electromagnetic-force-on-charge-in-volume-v/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/total-electromagnetic-force-on-charge-in-volume-v/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 부피 $\mathcal{V}$속의 모든 전하가 받는 전자기력은 $$ \mathbf{F} =\oint_{\mathcal{S}} \mathbf{T} \cdot d\mathbf{a} -\epsilon_0\mu_0\dfrac{d}{dt}\int_{\mathcal{V}} \mathbf{S} d\tau $$ $\mathcal{S}$는 부피 $\mathcal{V}$의 경계면, $\mathbf{T}$는 맥스웰 변형력 텐서 , $\mathbf{S}$는 포인팅 벡터 이다. Part 1. 로런츠 힘 법칙 에 의해</description>
    </item>
    
    <item>
      <title>딥러닝이란?</title>
      <link>https://freshrimpsushi.github.io/posts/deep-learning/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/deep-learning/</guid>
      <description>정의 딥러닝은 인공 신경망을 이용한 머신러닝의 일종으로, 특히 인공 신경망을 구성할 때 복수의 레이어를 사용하는 기법을 말한다. 모티브 인간의 두뇌가 뉴런들의 복잡한 연결관계로 구성된 것처럼 딥러닝 역시 인공 신경망을 보다 복잡하게 연결해서 퍼포먼스를 올린다. 감각세포에서 받은 자극이 척수를 통해 뇌로 전달되는 것처럼, 인공 신경망은 여러 레이어를</description>
    </item>
    
    <item>
      <title>맥스웰 변형력 텐서</title>
      <link>https://freshrimpsushi.github.io/posts/maxwell-stress-tensor/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maxwell-stress-tensor/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **맥스웰 변형력 텐서$(\mathrm{Maxwell\ tress\ tensor})$ $$ \mathbf{T}=\overleftrightarrow{\mathbf{T}}=\begin{pmatrix} T_{xx} &amp;amp; T_{xy} &amp;amp; T_{xz} \\ T_{yx} &amp;amp; T_{yy} &amp;amp; T_{yz} \\ T_{zx} &amp;amp; T_{zy} &amp;amp; T_{zz} \end{pmatrix} $$ $$ T_{ij}=\epsilon_0 \left( E_iE_j-\dfrac{1}{2}\delta_{ij}E^2 \right) + \dfrac{1}{\mu_0}\left(B_iB_j-\dfrac{1}{2}\delta_{ij}B^2 \right) $$ $\delta_{ij}$는 크로네커 델타 . ** **0. $2$차 텐서 의 한 종류로 위와 같이 정의된다. 어느 부피 $\mathcal{V}$속의 전하가 받는</description>
    </item>
    
    <item>
      <title>야코비 행렬 혹은 자코비 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/jacobian-matrix/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jacobian-matrix/</guid>
      <description>정의 $D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 벡터 함수 $\mathbb{f} : D \to \mathbb{R}^{m}$ 가 각각의 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ 과 같이 정의되었다고 하자. $$ J := \begin{bmatrix} {{\partial f_{1} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{1} } \over {\partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial f_{m} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{m} } \over {\partial x_{n} }} \end{bmatrix} $$ 을 $\mathbb{f}$ 의 야코비 행렬이라 한다. 설명</description>
    </item>
    
    <item>
      <title>머신러닝에서의 경사하강법</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-descent-algorithm/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-descent-algorithm/</guid>
      <description>개요 손실 함수의 기울기를 이용해 손실 함수의 극소값을 찾는 알고리즘 중 가장 간단한 방법으로 경사하강법Gradient Descent Algorithm이 있다. 설명 단, 이 때의 손실 함수 $L$ 은 데이터 셋 $X$ 가 픽스 된 상태에서 가중치와 바이어스에 대한 함수로 본다. 만약 인풋 데이터가 $\mathbb{x} \in \mathbb{R}^{m}$ 처럼 생겼다면 $L$ 은 $(w_{1} , w_{2} , \cdots , w_{m} , b) \in \mathbb{R}^{m+1}$ 에 대한 함수가 되는 것이다</description>
    </item>
    
    <item>
      <title>물리학에서 텐서란</title>
      <link>https://freshrimpsushi.github.io/posts/tensor/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tensor/</guid>
      <description>단언컨대 텐서에 대한 가장 쉬운 설명글이니 도대체 텐서가 뭔지 몰라서 찾아 들어온 물리학과 학부생이라면 꼭 읽기를 권한다. 수학적으로 틀린 부분에 대한 지적은 받지 않는다. 음수를 배우지 않은 사람에게 &amp;lsquo;작은 수에서 큰 수를 뺄 수는 없다&amp;rsquo;, 허수를 배우지 않은 사람에게 &amp;lsquo;루트 안에 음수는 들어갈 수 없다&amp;rsqu</description>
    </item>
    
    <item>
      <title>슈발치언 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/schwarzian-derivative/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schwarzian-derivative/</guid>
      <description>정의1 $p$ 가 스무스한 맵 $f : \mathbb{R} \to \mathbb{R}$ 의 고정점 혹은 피리어딕 포인트라고 하자. $f&#39;(c) = 0$ 인 $c$ 를 $f$ 의 크리티컬 포인트Critical Point라 한다. $p$ 의 베이신이 길이가 무한한 인터벌을 포함하면 인피닛 베이신Infinite Basin이라 한다. $\displaystyle S(f)(x) := {{f&#39;&#39;&#39;(x) } \over { f&#39;(x) }} - {{3} \over {2}} \left( {{f&#39;&#39;&#39;(x) } \over { f&#39;(x) }} \right)^2$ 를 $f$ 의 슈발치언 도함수라 한다. $f&#39;(x) \ne 0$ 인 모든</description>
    </item>
    
    <item>
      <title>R 에서 복소수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-complex-number-in-r/</link>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-complex-number-in-r/</guid>
      <description>개요 R 에는 복소수 자료형이 구현되어있다. 굳이 스스로 구현할 필요 없이 가져다 쓰기만 하면 된다. 사칙연산은 물론 복소수를 다룰 때 빠질 수 없는 여러가지 함수 역시 만들어져 있다. 코드 $z_{1} : = 1- i$, $z_{2} := 1+ i$ 이라고 하자. z_1 = 1-1i z_2 = 1+1i z_1 + z_2 z_1 - z_2 z_1 * z_2 z_1 / z_2 Re(z_1) Im(z_1) Mod(z_1) Arg(z_1) Conj(z_1) 위의 코드를 실행시키면 다음과 같은 결과를 얻을 수 있다. 수식으로 확인해보자.</description>
    </item>
    
    <item>
      <title>포인팅 정리와 포인팅 벡터</title>
      <link>https://freshrimpsushi.github.io/posts/poyntings-theorem-and-poynting-vecrtor/</link>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poyntings-theorem-and-poynting-vecrtor/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 포인팅 정리$(\mathrm{Poynting&amp;rsquo;s\ theorem})$ 전자기력이 전하에 해준 일은 전자기장에 저장된 에너지의 감소량과 경계면을 통해 밖으로 새어나간 에너지를 더한 것과 같다. $$ \begin{align} \dfrac{dW}{dt} &amp;amp;= -\dfrac{d}{dt} \int_{\mathcal{V}} \dfrac{1}{2} \left( \epsilon_0 E^2 + \dfrac{1}{\mu_0} B^2 \right) d\tau - \dfrac{1}{\mu_0} \oint_{\mathcal{S}} (\mathbf{E} \times \mathbf{B}) \cdot d \mathbf{a} \\ &amp;amp;= -\dfrac{d}{dt} \int_{\mathcal{V}} u d\tau - \oint_{\mathcal{S}}\mathbf{S} \cdot d\mathbf{a} \end{align} $$ $\math</description>
    </item>
    
    <item>
      <title>맥스웰 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/maxwells-equations/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maxwells-equations/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **맥스웰 방정식$(\mathrm{Maxwell&amp;rsquo;s\ equations})$ $(\mathrm{i}) \quad \nabla \cdot \mathbf{E}=\dfrac{1}{\epsilon_0}\rho $ **가우스 법칙 $(\mathrm{ii}) \quad \nabla \cdot \mathbf{B}=0$ (자기장에 대한 가우스 법칙)$(\mathrm{iii}) \quad \nabla \times \mathbf{E} = -\dfrac{\partial \mathbf{B}}{\partial t}$ **패러데이 법칙 $(\mathrm{iv}) \quad \nabla \times \mathbf{B} = \mu_0 \mathbf{J}+\mu_0\epsilon_0\dfrac{\partial \mathbf{E}}{\partial t} $ 앙페르 법칙 맥스웰이 맥스웰 방정식을 완성시</description>
    </item>
    
    <item>
      <title>R 에서 정적분 구하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-integrate-in-r/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-integrate-in-r/</guid>
      <description>개요 R 에서 정적분을 구하기 위해선 integrate() 함수를 사용할 수 있다. 예를 들어 코드 $\displaystyle \int_{0}^{3} \left( x^2 + 4x + 1 \right) dx$ 과 $\displaystyle \int_{0}^{\infty} e^{-x} dx$ 은 다음과 같이 구할 수 있다. 특히 적분구간에는 inf를 넣음으로써 이상적분까지 할 수 있다. f&amp;lt;-function(x) {x^2 + 4*x + 1} g&amp;lt;-function(x) {exp(-x)} integrate(f,0,3) integrate(g,0,Inf) 실제로 계산해보면 $$ \int_{0}^{3} \left( x^2 + 4x + 1 \right) dx = \left[ {{1} \over {3}} x^{3} + 2 x^2 + x \right]_{x=0}^{3} = 9 + 18 + 3 = 30 $$ 이고 $$ \displaystyle \int_{0}^{\infty} e^{-x} dx = \left[ - e^{-x} \right]_{x = 0}^{\infty}</description>
    </item>
    
    <item>
      <title>라플라스 방정식에 대한 평균값 공식</title>
      <link>https://freshrimpsushi.github.io/posts/mean-value-formulas-for-laplaces-equation/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-value-formulas-for-laplaces-equation/</guid>
      <description>정리1 열린 집합 $\Omega \subset \mathbb{R}^{n}$가 주어졌다고 하자. 그리고 $u \in C^2(\Omega)$가 라플라스 방정식을 만족한다고 하자. 그러면 각각의 열린 볼 $B(x,r)\subset \subset \Omega$에 대해서 다음이 성립한다. $$ \begin{align*} u(x) &amp;amp;= \dfrac{1}{n \alpha(n)r^{n-1}} \int _{\partial B(x,r)} udS =: -\!\!\!\!\!\! \int_{\partial B(x,r)} udS \\ &amp;amp;= \dfrac{1}{\alpha(n)r^n}\int_{B(x,r)}udy =: -\!\!\!\!\!\! \int _{B(x,r)} udy \end{align*} $$ $V \subset \bar V \subset U$이고 $\bar V$가 컴팩트 일 때 $V\subset \subset U$라고 표기한다</description>
    </item>
    
    <item>
      <title>뮬러 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/muller-method/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/muller-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $f (\alpha) = 0$ 이라고 하자. 초기값 $x_{0} , x_{1} , x_{2}$ 과 $w_{n} := f [x_{n} , x_{n-1} ] + f [ x_{n} , x_{n-2} ] - f [ x_{n-2} , x_{n-1} ]$ 에 대해 $\displaystyle x_{n+1} : = x_{n} - {{ 2 f ( x_{n} ) } \over { w_{n} \pm \sqrt{ w_{n}^{2} - 4 f (x_{n} ) f [ x_{n} , x_{n-1} , x_{n-2} ] } }}$ 과 같이 정의된 수열 $\left\{ x_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 $\displaystyle p \approx 1.84 $ 차 수렴한다.단, $\left( w_{n} \pm \sqrt{ w_{n}^{2} - 4 f (x_{n} ) f [ x_{n} , x_{n-1} , x_{n-2} ]</description>
    </item>
    
    <item>
      <title>전자기학에서의 연속방정식</title>
      <link>https://freshrimpsushi.github.io/posts/continuity-equation-of-electromagnetics/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuity-equation-of-electromagnetics/</guid>
      <description>공식 다음의 식을 연속방정식continuity equation이라 한다. $$ \dfrac{\partial \rho}{\partial t}=-\nabla \cdot \mathbf{J} $$ 설명1 연속방정식은 국소적인 영역에서의 전하량보존법칙을 수식적으로 표현한 것이다. 전하량보존법칙은 원래 있던 전하가 갑자기 사라지거나 새로운 전하가 생기는 일이 없이 처음의 전하량이 그대로 유지된다는 법칙이다. 이는 우주 전체에 대해서도 그러하</description>
    </item>
    
    <item>
      <title>R 에서 미분계수 구하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-differentiate-in-r/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-differentiate-in-r/</guid>
      <description>개요 R 에서 미분계수를 구하기 위해선 numDeriv 패키지의 grad() 함수를 사용할 수 있다. 코드 예를 들어 $f(x) = x^2 + 4x + 1$ 과 $g(x) = e^{-x}$ 의 미분계수는 다음과 같이 구할 수 있다. install.packages(&amp;quot;numDeriv&amp;quot;) library(numDeriv) f&amp;lt;-function(x) {x^2 + 4*x + 1} g&amp;lt;-function(x) {exp(-x)} grad(f,2) grad(g,0) 실제로 계산해보면 $f&#39;(2) = 2 \cdot 2 + 4 = 8$ 이고 $g&#39;(0) = - e^{0} = -1$ 인 것을 확인할 수 있다. 참고로 스칼라 함수의 경우에도 x 옵션에 벡터를 넣어주면 그래디언트를 잘 계산해준다.</description>
    </item>
    
    <item>
      <title>함수의 푸리에 급수가 함수로 절대수렴 균등수렴할 충분 조건</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-condition-that-fourier-series-of-f-converges-to-f-absolutely-and-uniformly/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-condition-that-fourier-series-of-f-converges-to-f-absolutely-and-uniformly/</guid>
      <description>정리 $[L, -L)$에서 정의된 함수 $f$가 연속이고, 조각마다 매끄럽다 고 하자. 그러면 $f$의 푸리에 급수는 $f$로 절대수렴, 균등수렴한다. $f$가 조각마다 매끄러울 때 $f$의 푸리에 급수가 $f$에 점마다 수렴한다. 여기에 조건이 강화되어 $f$의 불연속점이 사라진다면, $f$가 연속이라면 $f$의 푸리에 급수는 $f$로 절대수</description>
    </item>
    
    <item>
      <title>스칼라 함수와 벡터 함수</title>
      <link>https://freshrimpsushi.github.io/posts/scalar-function-and-vector-function/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scalar-function-and-vector-function/</guid>
      <description>정의 $D\subset \mathbb{R}^{n}$ 이라고 하자. 1. $D$ 를 정의역으로 갖는 함수를 다변수 함수라 한다. 2. $f : D \to \mathbb{R}$ 을 스칼라 함수라 한다. 3. 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ 과 같이 정의된 $\mathbb{f} : D \to \mathbb{R}^{m}$ 를 벡터 함수라 한다. 설명 1. 다변수 함수라는 표현은 특히 미적분학을 위시한 해석학에서 쓰는 표</description>
    </item>
    
    <item>
      <title>자기장 속의 에너지</title>
      <link>https://freshrimpsushi.github.io/posts/energy-of-magnetic-field/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/energy-of-magnetic-field/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 전하 분포가 만드는 전기장의 에너지 를 생각 했듯이 전류 분포가 만드는 자기장의 에너지를 생각할 수 있다. 회로에 전류를 흐르게 하면 에너지가 들어간다. 이 에너지의 정체는 바로 역기전력 을 거슬러 하는 일이다. 역기전력 때문에 회로에 흐르는 전류에 변화를 주기 어렵다. 따라서 단위 전하가 회로를 한 바퀴</description>
    </item>
    
    <item>
      <title>자체 인덕턴스</title>
      <link>https://freshrimpsushi.github.io/posts/self-inductance/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/self-inductance/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 위 그림과 같은 상황에서 고리 1에 전류 $I_1$이 흐르면 자기장 $\mathbf{B}_1$이 흐르고 $\mathbf{B}_1$이 고리 2를 지나는 선속을 다음과 같이 계산할 수 있다. $$ \Phi_2 = M_{21}I_1 $$ 이때 $M_{21}$을 상호 인덕턴스 라고 한다. 이제 고리 1에 흐르는 전류 $I_1$이</description>
    </item>
    
    <item>
      <title>상호 인턱덕스</title>
      <link>https://freshrimpsushi.github.io/posts/mutual-inductance/</link>
      <pubDate>Tue, 09 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mutual-inductance/</guid>
      <description>설명1 위 그림처럼 고정된 두 도선 고리가 있다고 하자. 고리 1에 정상전류 $I_1$을 흐르게 하면 자기장 $\mathbf{B}_1$이 생긴다.(앙페르 법칙 ) $\mathbf{B}_1$의 자기장선 중 일부는 고리 2를 지나가게 된다. 그럼 고리 2를 지나가는 $\mathbf{B}_1$의 선속 $\Phi_2=\mathbf{B}_1 \cdot d\mathbf{a}_2$를 말</description>
    </item>
    
    <item>
      <title>카오스 이론에서 맵들의 컨쥬게이트</title>
      <link>https://freshrimpsushi.github.io/posts/conjugate-of-maps-in-chaos-theory/</link>
      <pubDate>Tue, 09 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conjugate-of-maps-in-chaos-theory/</guid>
      <description>개요 카오스 이론에서 맵의 컨쥬게이트는 일종의 아이소메트리, 아이소멀피즘과 비슷하며, 사실 더 일반적인 동역학의 맥락에서는 호메오멀피즘 그 자체다. 1 교재에 따라 완전히 같지는 않을 수 있지만 용도는 정확히 같다. 수학에서 하는 일이 다 그렇듯, 계산이 쉬운 곳에서 어떤 성질이 있음을 확인한 후 실제로 증명이 필요한 곳으로 그 성질을 보존 시키는 것이다</description>
    </item>
    
    <item>
      <title>머신러닝에서의 손실 함수</title>
      <link>https://freshrimpsushi.github.io/posts/loss-function/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/loss-function/</guid>
      <description>정의 데이터 $Y = \begin{bmatrix} y_{1} \\ \vdots \\ y_{n} \end{bmatrix}$ 에 대한 추정치가 $\widehat{Y} = \begin{bmatrix} \widehat{ y_{1} } \\ \vdots \\ \widehat{y_{n}} \end{bmatrix}$ 와 같이 주어져 있을 때 데이터와 추정치의 괴리도를 나태는 스칼라 함수 $L : \mathbb{R}^{n} \to [ 0 , \infty )$ 를 손실 함수라 한다. 다른 이름 손실 함수는 학습을 통해 얻은 데이터의 추정치가 실제 데이터와 얼마나 차이나는지 평가하는 지표로 쓰인다. 이 값이 크면 클수록 많이 틀렸다는 의미고, 이 값이 $0$</description>
    </item>
    
    <item>
      <title>로지스틱 패밀리</title>
      <link>https://freshrimpsushi.github.io/posts/logistic-family/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logistic-family/</guid>
      <description>정의 1 $a \ge 0$ 에 대해 $g_{a} (x) = a x ( 1 - x )$ 를 로지스틱 맵Logistic Map이라고 하고 $\left\{ g_{a} \mid a &amp;gt; 0 \right\}$ 을 로지스틱 패밀리Logistic Family라고 한다. 성질 [1]: $x \in [0,1] \iff g_{a} (x) \ge 0$ [2]: $g&#39;_{a} (x) = a ( 1 - 2x)$ [3]: $1 &amp;lt; a \le 4$ 이면 $\displaystyle x_{1} = {{ a - 1} \over { a }}$ 는 $g_{a} (x)$ 의 고정점이다. [4]: $1 &amp;lt; a &amp;lt; 3$ 이면 $$ \lim_{ k \to \infty} f^{k} (x) = x_{1} = {{a-1} \over {a}} $$ 설명 로지</description>
    </item>
    
    <item>
      <title>수학에서의 그래프와 네트워크</title>
      <link>https://freshrimpsushi.github.io/posts/graph-and-network-in-mathematics/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/graph-and-network-in-mathematics/</guid>
      <description>정의 1 정점과 정점들을 연결한 선들로 이루어진 집합을 그래프 혹은 네트워크라고 한다. 정점들의 집합을 $V$, 선들의 집합을 $E$라고 하자. $V(G) := V$ 의 원소를 $G$ 의 버텍스Vertex 혹은 노드Node라고 한다. $E(G) := E$ 의 원소를 $G$ 의 에지Edge 혹은 링크Link라고 한다. 자기 자신으로 이어진 에지를 루프Loop라고 한다. 두 버텍스가 에지로 이</description>
    </item>
    
    <item>
      <title>샤르코우스키 정리</title>
      <link>https://freshrimpsushi.github.io/posts/sharkovskiis-theorem/</link>
      <pubDate>Sat, 06 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sharkovskiis-theorem/</guid>
      <description>정리 1 $$ 3 \prec 5 \prec 7 \prec 9 \prec \cdots \prec \\ 2\cdot 3 \prec 2 \cdot 5 \prec \cdots \prec \\ 2^2 3 \prec 2^2 5 \prec \cdots \prec \\ 2^3 3 \prec 2^3 5^2 \prec \cdots \prec \\ 2^3 \prec 2^2 \prec 2^1 \prec 2^0 $$ 추이적 관계 $\prec$ 에 대해 위와 같은 순서를 샤르코우스키 오더링이라 한다. 연속 맵 $f : \mathbb{R} \to \mathbb{R}$ 이 피리어딕-$p$ 오빗을 갖는다고 하자. $p \prec q$ 면 $f$ 는 피리어딕-$q$ 오빗을 갖는다. 설명 샤르코우스키 정리Sharkovskii</description>
    </item>
    
    <item>
      <title>인공 신경망이란?</title>
      <link>https://freshrimpsushi.github.io/posts/ann-artificial-neural-network/</link>
      <pubDate>Sat, 06 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ann-artificial-neural-network/</guid>
      <description>정의 실제 생물의 신경계를 모방한 네트워크를 인공 신경망이라 한다. 모티브 신경계는 뉴런들의 결합으로 구성되어있다. 신경세포체는 가지돌기를 통해 자극을 받아들이며, 축삭돌기를 통해 전기자극을 전달한다. 인간을 포함한 많은 생물들은 이렇듯 단순한 뉴런들의 결합을 환경에 적합하도록 진화시켜왔다. 그 결과 신경계는 빛을 감지하거나, 다리를 움직</description>
    </item>
    
    <item>
      <title>리-요크 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-li-yorke-theorem/</link>
      <pubDate>Fri, 05 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-li-yorke-theorem/</guid>
      <description>정리 연속 맵 $f: [a,b] \to [a,b]$ 의 피리어딕-$3$ 오빗이 존재하면 $f$ 는 캐어릭하다. 설명 리-요크 정리Li-Yorke Theorem는 삼주기 정리Period-$3$ Theorem라도 불리며, 피리어딕-$3$ 가 혼돈을 야기한다는 스테이트먼트 자체로도 많이 언급된다. 물론 이 정리만 보면 $1$차원 맵에 한정되어 있지만 고작 피리어딕-$3</description>
    </item>
    
    <item>
      <title>1차원 맵의 혼돈, 카오스</title>
      <link>https://freshrimpsushi.github.io/posts/chaos-of-one-dimensional-map/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaos-of-one-dimensional-map/</guid>
      <description>정의 캐어릭 오빗1 맵 $f : \mathbb{R} \to \mathbb{R}$ 의 바운디드 오빗 $\left\{ x_{1} , x_{2} , \cdots \right\}$ 이 다음을 만족하면 이 오빗을 캐어릭Chaotic하다고 한다. (i) 어심토티컬리 피리어딕이 아니다. **(ii): $h (x_{1} ) &amp;gt; 0$ 바운디드 오빗이란 모든 $n \in \mathbb{N}$ 에 대해 $|x_{n} | &amp;lt; M$ 을 만족하는 $M \in \mathbb{R}$ 이 존재한다는 뜻이다. $h(x_{1} )$ 은 랴푸노프 지수를 말한다. 캐어릭 맵 모든 $n \in \mathbb{N}$ 에 대해 피리어딕-$n$</description>
    </item>
    
    <item>
      <title>윈도에서 파이썬 텐서플로우 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-tensorflow-in-windows/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-tensorflow-in-windows/</guid>
      <description>가이드 텐서플로우를 설치할 때 문제가 생기는 경우는 보통 파이썬을 잘못 설치했기 때문이다. 시작하기 전에 파이썬을 삭제하고 처음부터 다시 시작하거나, 가능하다면 컴퓨터를 한 번 밀어두는 것을 추천한다. **Step 1. 파이썬 **Step 1-1. 비트 확인 제어판/모든 제어판 항목/시스템 혹은 내 PC(우클릭)-속성을 통해 시스템 정보를 확인하자.요즘은 대개 64비트기</description>
    </item>
    
    <item>
      <title>패러데이 법칙과 렌츠의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/faradays-law-and-lenzs-law/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/faradays-law-and-lenzs-law/</guid>
      <description>패러데이 법칙 변화하는 자기장은 전기장을 유도한다. $$ \nabla \times \mathbf{E} = -\dfrac{\partial \mathbf{B}}{\partial t} $$ 설명1 패러데이가 1831년에 다음과 같은 내용의 실험 결과를 발표하였다. 발표한 실험결과의 내용은 다음과 같다. 자기장 속에 놓여진 도선 고리를 오른쪽 으로 당겼다. 고리에 전류가 흘렀다. 자기장 속에 도선 고리를 고정하고 자석을 왼쪽 으로 밀었다. 고리에 전류가 흘렀다. 도</description>
    </item>
    
    <item>
      <title>1차원 맵의 랴푸노프 수</title>
      <link>https://freshrimpsushi.github.io/posts/lyapunov-number-of-one-dimensional-map/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lyapunov-number-of-one-dimensional-map/</guid>
      <description>정의1 스무스한 $1$차원 맵 $f : \mathbb{R} \to \mathbb{R}$ 의 한 오빗 $\left\{ x_{1} , x_{2} , x_{3} , \cdots \right\}$ 에 대해 $$L ( x_{1} ) : = \lim_{ n \to \infty } \left( \prod_{i = 1}^{n} | f&#39; (x_{i} ) | \right)^{1/n}$$ 을 랴푸노프 수Lyapunov Number라 하고 $$ h ( x_{1} ) := \lim_{n \to \infty } {{1} \over {n}} \sum_{i=1}^{n} \ln | f&#39; (x_{i} ) |$$ 을 랴푸노프 지수Lyapunov Exponent라 한다. 설명 싱크와 소스의 개념을 다시금 생각해보면 싱크란 가까운</description>
    </item>
    
    <item>
      <title>위너 프로세스</title>
      <link>https://freshrimpsushi.github.io/posts/wiener-process/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/wiener-process/</guid>
      <description>정의 $s&amp;lt; t &amp;lt; t+u$ 라고 할 때, 다음의 조건들을 만족하는 확률과정 $\left\{ W_{t} \right\}$ 를 위너 프로세스라 한다. (i): $W_{0} = 0$ (ii): $\left( W_{t+u} - W_{t} \right) \perp W_{s}$ (iii): $\left( W_{t+u} - W_{t} \right) \sim N ( 0, u )$ (iv): $W_{t}$ 의 샘플 패스는 거의 어디서나 연속이다. 기초 성질 [1]: $\displaystyle W_{t} \sim N ( 0 , t ) $ [2]: $\displaystyle E ( W_{t} ) = 0$ [3]: $\displaystyle \text{Var} ( W_{t} ) = t$ [4]: $\displaystyle \text{cov} ( W_{t} , W_{s} ) = {{1} \over {2}} (|t| + |s| - |t-s|) = \min \left\{ t , s \right\}$ 설명 위너 프로세스는 브라운</description>
    </item>
    
    <item>
      <title>푸아송 방정식의 기본해</title>
      <link>https://freshrimpsushi.github.io/posts/fundamental-solution-of-poissons-equation/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fundamental-solution-of-poissons-equation/</guid>
      <description>빌드업1 라플라스 방정식의 기본해 $x \in \mathbb{R}^{n}$이고, $x \ne 0$에 대해 아래의 함수 $\Phi$를 라플라스 방정식의 기본해라고 정의한다. $$ \Phi(x) := \begin{cases} -\frac{1}{2\pi}\log |x| &amp;amp; n=2 \\ \frac{1}{n(n-2)\alpha(n)} \frac{1}{|x|^{n-2}} &amp;amp; n \ge 3 \end{cases} $$ $x \mapsto \Phi(x)$와 같이 매핑하는 함수를 생각해보자. 이는 $x \ne 0$인 곳에서 하모닉이다. 원점을 $0$에서 $y\in \mathbb{R}</description>
    </item>
    
    <item>
      <title>맵 시스템의 오빗</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-of-map-system/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-of-map-system/</guid>
      <description>정의1 맵 $f : X \to X$ 와 $p \in X$ 에 대해 $f^{k} (p) = p$ 를 만족하는 가장 작은 자연수가 $k \in \mathbb{N}$ 라고 하자. 맵 $f : X \to X$ 와 점 $x \in X$ 에 대해 집합 $\left\{ x , f(x) , f^{2} , \cdots \right\}$ 를 $f$ 하에서 $x$ 의 오빗Orbit이라 한다. 이 때 $x$ 를 오빗의 초기값Initial Value이라 한다. 초기값 $p$ 를 가지는 오빗 $\left\{ p , f (p) , f^{2} (p) , \cdots \right\}$ 을 피리어딕-$k$ 오빗이라 하고, $p$</description>
    </item>
    
    <item>
      <title>준소수</title>
      <link>https://freshrimpsushi.github.io/posts/semiprime/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/semiprime/</guid>
      <description>정의 두 소수의 곱을 준소수Semiprime라 한다. 설명 준소수의 예로써 $4 = 2 \cdot 2$ 이나 $21 = 3 \cdot 7$, $673703 = 719 \cdot 937$ 등이 있다. 일본어 번역으로는 반소수半素數라고도 하는데, 한국어 문서로는 준소수나 반소수나 둘 다 찾아보기 어렵다. 본질적으로 준소수는 준소수 자체가 아니라 소수의 성질을 어느정도 이어받아서 응용된다. 예를들어 제법 큰 두 개의 소</description>
    </item>
    
    <item>
      <title>1차원 맵의 싱크와 소스 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/sink-and-source-of-one-dimensional-map/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sink-and-source-of-one-dimensional-map/</guid>
      <description>정리1 스무스한 맵 $f : \mathbb{R} \to \mathbb{R}$ 에 대해 어떤 $p \in \mathbb{R}$ 가 고정점이라고 하자. [1] $| f&#39; (p) | &amp;lt; 1$ 이면 $p$ 는 싱크다. [2] $| f&#39; (p) | &amp;gt; 1$ 이면 $p$ 는 소스다. 예시 $1$차원 맵의 예로써 $f(x) = x^3$ 을 생각해보면 $f&#39;(x) = 3x^{2}$ 이므로 고정점 $f(0) = 0$ 은 싱크, $f(1) = 1$ 은 소스임을 쉽게 확인할 수 있다. 증명 정리 [1]의 증명 $a \in \left( | f&#39;(p) | , 1 \right)$ 이라고 하자. $$ \lim_{x \to p} {{ | f(x) - f(p) |</description>
    </item>
    
    <item>
      <title>반파대칭함수의 푸리에 계수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-coefficient-of-half-symmetry-function/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-coefficient-of-half-symmetry-function/</guid>
      <description>정리 주기가 $2L$인 함수 $f$가 반파대칭이면 $f$의 푸리에 계수는 아래와 같다. $$ \begin{align*} a_{0} &amp;amp;= 0 \\ a_{n} &amp;amp;= \begin{cases} \dfrac{2}{L} {\displaystyle \int_{0}^{L}} f(t) \cos \frac{n \pi t}{L} dt &amp;amp; (n=1, 3, \cdots ) \\ 0 &amp;amp; (n=0, 2, \cdots )\end{cases} \\ b_{n} &amp;amp;= \begin{cases} \dfrac{2}{L} {\displaystyle \int_{0}^{L}} f(t) \sin \frac{n \pi t}{L} dt &amp;amp; (n=1, 3, \cdots ) \\ 0 &amp;amp; (n=0, 2, \cdots )\end{cases} \\ c_{n} &amp;amp;= \begin{cases} \dfrac{1}{L} {\displaystyle \int_{0}^{L} } f(t)e^{-i\frac{n \pi t}{L} } dt &amp;amp; (n=\pm 1, \pm 3, \cdots) \\ 0 &amp;amp;( n=\pm 2, \pm 4, \cdots )\ \end{cases} \end{align*} $$ $c_{n}$은 복소 푸리에 계수이다. 증명 $$ \begin{align*} a_{0} &amp;amp;= \dfrac{1}{L} {\displaystyle</description>
    </item>
    
    <item>
      <title>하르케-베라 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/jarque-bera-test/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jarque-bera-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 샤피로-윌크 테스트 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 가 주어져 있다고 하자. $H_{0}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따른다. $H_{1}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따르지 않는다. 하르케-베라 테스트는 정규성을 검정하기 위해 사용하는 테스트로써, 보통은 정규성이 있음을 보이기 위해서 사용한다. 귀무가설이 채</description>
    </item>
    
    <item>
      <title>바나흐 고정점 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-banach-fixed-point-theorem/</link>
      <pubDate>Sun, 31 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-banach-fixed-point-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $(X , | \cdot | )$ 가 바나흐 공간이라고 하자. 모든 $x, \tilde{x} \in X$ 와 $0 \le r &amp;lt; 1$ 에 대해 $| T(x) - T ( \tilde{x} ) | \le r | x - \tilde{x} |$ 를 만족하는 $T : X \to X$ 를 축소 사상Contraction Mapping이라 정의한다. $T$ 의 고정점은 유일하게 존재한다. 고정점이란 $T ( \alpha ) = \alpha$ 를 만족하는 $\alpha \in X$ 를 말한다.</description>
    </item>
    
    <item>
      <title>푸리에 코사인 급수, 사인 급수, 우함수와 기함수의 푸리에 계수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-cosine-series-and-sine-series-fourier-coefficient-of-odd-function-and-even-function/</link>
      <pubDate>Sun, 31 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-cosine-series-and-sine-series-fourier-coefficient-of-odd-function-and-even-function/</guid>
      <description>정의 $f$를 구간 $[0,L)$에서 조각마다 매끄러운 함수라고 하자. 아래와 같이 정의되는 $f_{e}$를 구간 $[-L, L)$로 $f$의 even extension이라 한다. $$ f_{e}(t) := \begin{cases} f(t) &amp;amp; -L \le t &amp;lt;0 \\ f(-t) &amp;amp; 0 \le t &amp;lt;L\end{cases} $$ 비슷하게 아래와 같이 정의되는 $f_{o}$를 구간 $[-L, L)$로 $f$의 odd extension이라 한다. $$ f_{o}(t) := \begin{cases} -f(-t) &amp;amp; -L \le t &amp;lt;0</description>
    </item>
    
    <item>
      <title>R 에서 현재 OS 정보 확인하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-operating-system-in-r/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-operating-system-in-r/</guid>
      <description>개요 R 은 이래저래 리눅스에서도 사용할 일이 있이 많다. 대표적으로 빅데이터를 다루기 위해 하둡을 쓰는 경우가 있다. 물론 윈도우나 리눅스나 R 자체는 크게 다른 게 없지만, 작업환경이 다르기 때문에 작업경로가 달라져서 파일의 입출력이 다소 귀찮아지는 경우가 있다. 작업환경에 관계 없이 작업경로를 편하게 설정하기 위해선 현재의 OS가 어떤 것인지 확인</description>
    </item>
    
    <item>
      <title>반파대칭 함수</title>
      <link>https://freshrimpsushi.github.io/posts/half-wave-symmetry/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/half-wave-symmetry/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정의 주기가 $2L$인 주기함수 $f$가 모든 $t$에 대해서 아래의 식을 만족할 때 $f$를 반파대칭 이라 한다. $$ f(t)=-f(t+L) $$ 위의 정의를 풀어쓰면 &amp;lsquo;파동이 $xy$ 평면에 있다고 했을 때, 주기의 절반을 기준으로 파동이 진행하는 모양이 $y$축 대칭으로 번갈아 가면서 나타나는 것을 말한다.&amp;</description>
    </item>
    
    <item>
      <title>임의의 함수는 항상 기함수와 우함수의 합으로 표현할 수 있다</title>
      <link>https://freshrimpsushi.github.io/posts/any-function-can-always-be-expressed-as-the-sum-of-even-and-odd/</link>
      <pubDate>Fri, 29 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/any-function-can-always-be-expressed-as-the-sum-of-even-and-odd/</guid>
      <description>정리 $\mathbb{R}$에서 정의된 임의의 함수 $f$를 항상 기함수와 우함수의 합으로 표현할 수 있다. 증명 $f_e(t)$와 $f_o(t)$를 다음과 같다고 하자. $$ f_e(t)=\dfrac{ f(t)+f(-t)}{2},\ \ \ f_o(t)=\dfrac{ f(t)-f(-t)}{2} $$ 그러면 $f_e(t)$는 우함수이고, $f_o(t)$는 기함수이면서 다음의 식이 성립한다. $$ f_e(x)+f_o(x)=f(x) $$ ■</description>
    </item>
    
    <item>
      <title>로그의 밑변환 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/logarithmic-identities/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logarithmic-identities/</guid>
      <description>공식 임의의 양수 $c&amp;gt;0$ 에 대해, $$ \displaystyle \log_{a} b = {{ \log_{c} b } \over { \log_{c} a }} $$ 설명 현대에 와서 공식 자체만으로는 의미가 없어졌지만 입시에서는 여전히 중요한 공식이다. 간단한 성질이라고 해서 깔보지 말고 &amp;lsquo;공식&amp;rsquo;이라는 이름에 걸맞는 수준의 연습문제를 많이 풀어보는 것을 추천한다. 유도 $x := \log_{a} b$ 라고 하면 로그의 정의에 따라 $$ a^x = b $$</description>
    </item>
    
    <item>
      <title>열 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-heat-equation/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-heat-equation/</guid>
      <description>정의1 아래의 편미분방정식을 열 방정식heat equation이라 한다. $$ u_{t}=\Delta u $$ 비동차nonhomogeneous인 경우에는 다음과 같다. $$ u_{t}-\Delta u=f $$ $U \subset \mathbb{R}^{n}$는 열린 집합 $u : \overline{U}\times [0, \infty) \to \mathbb{R}$ $t&amp;gt;0$ $x \in U$ $u=u(x, t)=u(x_1,\ \cdots,\ x_n,\ t)$ $\Delta$는 라플라시안 $f:U \times [0, \infty) \to \mathbb{R}$ 설명 라플라스 방정식에서 시간에 대한 미분항이 추가</description>
    </item>
    
    <item>
      <title>컨볼루션(합성곱)의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-convolution/</link>
      <pubDate>Wed, 27 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-convolution/</guid>
      <description>정의 $\mathbb{R}$에서 정의된 두 함수 $f$, $g$가 주어졌다고 하자. 아래의 적분이 존재하면 이를 두 함수 $f$, $g$의 합성곱이라 하고 $f \ast g$로 표기한다. $$ f \ast g(x):=\int _{-\infty} ^{\infty} f(y)g(x-y)dy $$ $f$, $g$가 이산함수일 경우 아래와 같이 정의한다. $$ (f \ast g)(m)=\sum \limits_{n}f(n)g(m-n) $$ 설명 합성곱이라는 번역이 있지만 컨볼루션이라는 말이 더 자주 쓰인다. 대개 위의 정의를 컨볼루션이</description>
    </item>
    
    <item>
      <title>확률과정론의 인크리먼트</title>
      <link>https://freshrimpsushi.github.io/posts/increment-of-stochastic-process/</link>
      <pubDate>Wed, 27 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/increment-of-stochastic-process/</guid>
      <description>정의 확률과정 $\xi(t)$ 이 시간 $T$ 에서 정의되었고 $t_{0} &amp;lt; t_{1} &amp;lt; \cdots &amp;lt; t_{n} \in T$ 이라고 하자. $\xi ( t ) - \xi ( s )$ 를 인크리먼트라 한다. 모든 $i=1, \cdots , n$ 에 대해 $\xi ( t_{i} ) - \xi ( t_{i-1} )$ 들이 서로 독립이면 $\xi(t)$ 이 독립 인크리먼트Independent Increment를 갖는다고 한다. 모든 $h&amp;gt;0$ 와 $t,s,t+h,s+h \in T$ 에 대해 $\xi (t+h) - \xi ( s + h )$ 가 같은 확률분포를 가지면 $\xi(t)$ 이 정상적</description>
    </item>
    
    <item>
      <title>라플라스 방정식과 푸아송 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/laplaces-equation-and-poissons-equation/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplaces-equation-and-poissons-equation/</guid>
      <description>정의1 $\ U \in \mathbb{R}^n$는 열린 집합 $\ x\in U$ $u=u(x) : \overline{U} \rightarrow \mathbb{R}^n$ 라플라스 방정식 아래의 편미분방정식을 라플라스 방정식Laplace&amp;rsquo;s equation이라 한다. $$ \Delta u=0 $$ 이때 $\Delta$는 라플라시안이다. 라플라스 방정식을 만족하는 $u$를 특별히 조화함수harmonic function라고 한다</description>
    </item>
    
    <item>
      <title>라플라스 방정식은 직교변환에 대해서 불변임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-laplaces-equation-is-invariant-under-rotations/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-laplaces-equation-is-invariant-under-rotations/</guid>
      <description>정리1 $u$가 라플라스 방정식을 만족한다고 하자. 그리고 $v(x)$를 아래와 같이 정의하자. $$ v(x) :=u(Rx) $$ 이때, $R$은 회전변환이다. 그러면 $v(x)$도 라플라스 방정식을 만족한다. $$ \Delta v=0 $$ 설명 사실 위의 내용은 모든 직교변환에 대해서 성립한다. 따라서 라플라스 방정식이 회전 변환에 불변이라는 사실은 라플라스 방정식이 직교 변환에 대</description>
    </item>
    
    <item>
      <title>이산로그 문제가 쉽게 풀리는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/condition-for-discrete-log-problem-be-solved-easily/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/condition-for-discrete-log-problem-be-solved-easily/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건 그룹 $G = F_{p}$ 의 원소 $g$ 가 오더 $N$ 이라고 하자. 그러면 이산로그 문제 $g^{x} = h$ 는 다음의 조건 하에</description>
    </item>
    
    <item>
      <title>그린-가우스 정리, 부분적분 공식</title>
      <link>https://freshrimpsushi.github.io/posts/green-gauss-theorem-integration-by-parts-formula/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/green-gauss-theorem-integration-by-parts-formula/</guid>
      <description>정리 $U\subset \mathbb{R}^{n}$를 열린집합이라고 하자. $u : \bar{U} \to \mathbb{R}$이고, $u \in C^1(\bar{U})$라고 하자. $\nu$를 외향단위법선벡터라고 하자. 그러면 아래의 식이 성립한다. $$ \begin{equation} \int_{U} u_{x_{i}}dx=\int _{\partial U} u\nu^{i} dS\quad (i=1,\dots, n) \label{eq1} \end{equation} $$ 이를 모든 $i$에 대해서 합하면 아래의 식을 얻는다. 각각의 $u^{1} \in C^{1}(\bar</description>
    </item>
    
    <item>
      <title>그린의 공식</title>
      <link>https://freshrimpsushi.github.io/posts/greens-formula/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/greens-formula/</guid>
      <description>정리 $u, v \in C^2( \bar{U})$이라고 하자. 그러면 다음의 식들이 성립한다. (i) $\displaystyle \int_{U} \Delta u dx=\int_{\partial U} \dfrac{\partial u}{\partial \nu}dS$ (ii) $\displaystyle \int_{U} Dv \cdot Du dx = -\int_{U} u \Delta v dx+\int_{\partial U}\dfrac{\partial v}{\partial \nu}udS$ (iii) $\displaystyle \int_{U} (u\Delta v - v\Delta u )dx = \int_{\partial U} \left( \dfrac{\partial v}{\partial \nu}u - \dfrac{\partial u}{\partial \nu} v\right)dS$ 이를 묶어 그린의 공식Green&amp;rsquo;s formula이라 한다. $\Delta$는 라플라시안 $D$는 그래디언트 $\nu$는 외향단위법</description>
    </item>
    
    <item>
      <title>수송 방정식의 초기값 문제와 비동차 문제 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problems-and-nonhomogeneous-problems-of-transport-equations/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problems-and-nonhomogeneous-problems-of-transport-equations/</guid>
      <description>수송방정식 $$ u_{t} + b \cdot Du=0\quad \text{in }\mathbb{R}^n \times (0,\ \infty) $$ 풀이1 초기값 문제 수송방정식의 초기값 문제가 아래와 같이 주어졌다고 하자. $$ \begin{equation} \left\{ \begin{aligned} u_t+b \cdot Du &amp;amp;= 0 &amp;amp;&amp;amp; \text{in } \mathbb{R}^n \times [0,\ \infty) \\ u &amp;amp;= g &amp;amp;&amp;amp; \text{on } \mathbb{R}^n\times \left\{ t=0 \right\} \end{aligned} \right. \label{IVP} \end{equation} $$ $b \in \mathbb{R}^n$는 수송방정식에서 주어진 상수이고, $g:\mathbb{R}^n \rightarrow \mathbb{R}$는 초기값으로 주어져있다. 이를 통해 $u$를 얻는 것이</description>
    </item>
    
    <item>
      <title>시컨트 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/secant-method/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/secant-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $f,f&#39;,f&#39;&#39;$ 가 $\alpha$ 의 근방에서 연속이고 $f(\alpha) = 0, f&#39;(\alpha) \ne 0$ 이라고 하자. $\alpha$ 와 충분히 가까운 초기값 $x_{0} , x_{1}$ 에 대해 $\displaystyle x_{n+1} := x_{n} - f ( x_{n} ) {{ x_{n} - x_{n-1} } \over { f ( x_{n} ) - f ( x_{n-1} ) }}$ 과 같이 정의된 수열 $\left\{ x_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 $\displaystyle {{1 + \sqrt{5} } \over {2}}$ 차 수렴한다. 수렴차수가 상당히 낯이 익을 것이다. 바로 황금비인 $\displaystyle {{1 + \sqrt{5} } \over</description>
    </item>
    
    <item>
      <title>아리마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/arima-model-intergrated-autoregressive-moving-average-model/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arima-model-intergrated-autoregressive-moving-average-model/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $$ \displaystyle \nabla^{d} Y_{t} := \sum_{i = 1}^{p} \phi_{i} \nabla^{d} Y_{t-i} + e_{t} - \sum_{i = 1}^{q} \theta_{i} e_{t-i} $$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 $(p,d,q)$차 아리마 과정 $ARIMA (p,d,q)$ 라고 한다. 이와 같은 꼴을 한 시계열 분석 모형을 아리마 모형이라고 한다. 설명 $ARI(p,d) \iff ARIMA(p,d,0)$ 을 아리 모형 , $IMA(d,q) \iff ARIMA(0,d,q)$ 을 이마 모형이라 하긴 하는데 자주 쓰진 않는다. 차라리 $ARIMA(p,d,0)$ 이나 $ ARIMA(0,d,q)$ 와 같은 표현을 즐겨 쓰는 편</description>
    </item>
    
    <item>
      <title>외향 단위 법선 벡터</title>
      <link>https://freshrimpsushi.github.io/posts/the-outward-pointing-unit-normal-vector/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-outward-pointing-unit-normal-vector/</guid>
      <description>정의1 $U\subset \mathbb{R}^{n}$을 열린 집합이라고 하자. $U$의 경계 $\partial U$가 $\partial U \in C^1$이라고 하자.그러면 다음과 같은 외향 단위 법선 벡터를 정의할 수 있다. $$ \boldsymbol{\nu}=(\nu^{1}, \nu^{2}, \dots, \nu^{n}) \quad \text{and} \quad |\boldsymbol{\nu}|=1 $$ $\boldsymbol{\nu}$는 경계의 한 점에서 접하고 크기가 1이며 바깥쪽을 향하는 벡터이다. $u \in C^{1}(\bar{U})</description>
    </item>
    
    <item>
      <title>도함수의 푸리에 계수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-coefficient-of-derivative/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-coefficient-of-derivative/</guid>
      <description>공식 구간 $[-L,\ L)$에서 정의된 함수 $f$가 연속이고, 조각마다 매끄럽다 고 하자.그러면 $f&#39;$의 푸리에 계수는 다음과 같다. $$ a&#39;_{n}=\dfrac{n\pi}{L}b_{n} $$ $$ b&#39;_{n}=-\dfrac{n\pi}{L}a_{n} $$ $$ c&#39;_{n}=\dfrac{in\pi}{L}c_{n} $$ 이 때, $a_{n},\ b_{n}$은 $f$의 푸리에 계수 , $c_{n}$은 $f$의 복소 푸리에 계수 이다. 증명 $$ \begin{align*} c&#39;_{n} &amp;amp;=\dfrac{1}{2L}\int _{-L}^{L} f&#39;(t)e^{-i\frac{n\pi t}{L}}dt \\ &amp;amp;= \dfrac{1}{2L}\left[ f(t)e^{-i\frac{n\pi t}{L}} \right]_{-L}^{L} +\dfrac{in \pi}{L}\dfrac{1}{2L}\int_{-L}^{L} f(t)e^{-i\frac{n \pi}{L}t} dt \\ &amp;amp;= \dfrac{1}{2L}f(t)\left[ e^{-in\pi} -e^{in\pi}\right] +\dfrac{in \pi}{L}c_{n} \\ &amp;amp;= \dfrac{1}{2L}f(t)\left[ (-1)^{-n} -(-1)^{n}\right] +\dfrac{in \pi}{L}c_{n} \\ &amp;amp;= \dfrac{1}{2L}f(t)(-1)^{n}\left[ (-1)^{-2n} -1 \right] +\dfrac{in \pi}{L}c_{n}</description>
    </item>
    
    <item>
      <title>수치해석학에서의 계차상</title>
      <link>https://freshrimpsushi.github.io/posts/divided-difference/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divided-difference/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 함수 $f : \mathbb{R} \to \mathbb{R}$ 와 서로 다른 $x_{1} , \cdots , x_{n}$ 에 대해 다음을 $f$ 의 계차상이라고 한다. $f[x_{0}] := f( x_{0} ) $$ \displaystyle f [ x_{0} , x_{1} ] : = {{ f ( x_{1} ) - f ( x_{0} ) } \over { x_{1} - x_{0} }} $$ \displaystyle f [ x_{0} , x_{1} , x_{2} ] : = {{ f [ x_{1} , x_{2} ] - f [ x_{0} , x_{1} ] } \over { x_{2} - x_{0} }} $$ \displaystyle f [ x_{0} , \cdots , x_{n} ] : = {{ f [ x_{1} , \cdots , x_{n} ] - f [ x_{0} , x_{n-1} ]</description>
    </item>
    
    <item>
      <title>주기함수의 한 주기 적분은 적분 구간에 상관없이 항상 같은 값을 가진다</title>
      <link>https://freshrimpsushi.github.io/posts/periodic-integral-of-periodic-function-is-constant/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/periodic-integral-of-periodic-function-is-constant/</guid>
      <description>정리 $f$를 $2L$-주기함수라고 하자. 그러면 아래의 값은 $a$의 값에 상관없이 일정하다. $$ \int_a^{a+2L}f(t)dt $$ 설명 주기함수의 정의에 의하면 당연한 사실이다. 이러한 사실로부터 주기함수를 적분할 때 적분구간을 변경하는 등의 테크닉을 쓸 수 있다. 또한 함숫값의 평균과 연관지어서 생각하면 주기함수의 한 주기 평균은 일정하다는 뜻인데 이 역시 주기함수의 정</description>
    </item>
    
    <item>
      <title>폴리그-헬맨 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pohlig-hellman-algorithm/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pohlig-hellman-algorithm/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건 그룹 $G$ 의 원소 $g$ 가 오더 $N = q_{1}^{r_{1}} q_{2}^{r_{2}} \cdots q_{t}^{r_{t}}$ 이라고 하자. 그러면 이산로그 문제 $g^{x} = h$ 는 다음의 알</description>
    </item>
    
    <item>
      <title>푸리에 계수의 극한은 0이다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-fourier-coefficients-tend-to-zero-as-n-tend-to-infinite/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-fourier-coefficients-tend-to-zero-as-n-tend-to-infinite/</guid>
      <description>정리 푸리에 계수 $a_{n}, b_{n}$와 복소 푸리에 계수 $c_{\pm n}$은 $n \rightarrow \infty$인 극한 $$ \begin{align*} \lim \limits_{n \rightarrow \infty} a_{n} &amp;amp;= 0 \\ \lim \limits_{n \rightarrow \infty} b_{n} &amp;amp;= 0 \\ \lim \limits_{n \rightarrow \infty} c_{\pm n} &amp;amp;= 0 \end{align*} $$ 증명 베셀 부등식에 의해 푸리에 계수의 합이 수렴함을 알고 있다. $$ \dfrac{1}{4}|a_0|^2 +\dfrac{1}{2}\sum\limits_{n=1}^{\infty} \left(|a_{n}|^2 + |b_{n}|^2 \right) =\sum \limits_{-\infty}^{\infty} | c_{n} |^2 \le \dfrac{1}{2L}\int_{-L}^{L} | f(t)|^2 dt $$ 따라서 $|a_{n}|^2,\ |b_{n}|^2,\ |c_{\pm n}|^2$은 수렴하는 급수의 $n$번째 항이다.급수가 수렴하면 수열</description>
    </item>
    
    <item>
      <title>푸리에 급수의 상수항은 함수의 한 주기 평균과 같다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-the-constant-term-in-fourier-series-of-f-is-the-mean-value-of-f/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-the-constant-term-in-fourier-series-of-f-is-the-mean-value-of-f/</guid>
      <description>정리 주기가 $2L$인 함수 $f$의 푸리에 급수의 상수항은 함수 $f$의 한 주기 평균과 같다. 증명 정의에 의해 $f(t)$의 한 주기 적분은 $$ \dfrac{1}{2L}\int_{-L}^{L} f(t)dt $$ 이는 푸리에 계수의 정의에 따라 $\dfrac{1}{2}a_0$과 같다. 따라서 $f(t)$의 한 주기 적분은 $f(t)$의 푸리에 급수의 상수항과 같다. ■ 직접계산 직접 계산을 통해 위 사실</description>
    </item>
    
    <item>
      <title>푸리에 급수의 정적분</title>
      <link>https://freshrimpsushi.github.io/posts/definite-and-fourier-series/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definite-and-fourier-series/</guid>
      <description>정리 주기가 $2L$인 주기함수 $f$가 구간 $[-L,\ L)$에서 조각마다 연속 이라고 하자.그러면 $f$의 정적분은 아래와 같이 나타낼 수 있다. $$ \int_{t_{1}}^{t_{2}} f(t) dt= c_{0}(t_{2}-t_{1}) +\sum \limits_{n \ne 0} \dfrac{L}{in\pi}c_{n}\left( e^{i\frac{n\pi t_{2}}{L}}-e^{i\frac{n\pi t_{1}}{L}} \right) $$ 이 때, $c_{0},\ c_{n}$은 복소 푸리에 계수이다. 즉, $f(t)$의 정적분은 $f(t)$의 푸리에 급수의 각 항을 정적분하여 더한 것과 같다. 주의해야 할 점은 우변이 좌변</description>
    </item>
    
    <item>
      <title>함수값의 평균</title>
      <link>https://freshrimpsushi.github.io/posts/mean-value-of-function/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-value-of-function/</guid>
      <description>정리 구간 $[a,\ b]$에서 $f(x)$의 평균값은 구간에 대해서 적분한 다음 구간의 길이로 나눠준 것과 같다. $$ \dfrac{1}{b-a}\int_a^bf(x)dx $$ 증명 구간 $[a,\ b]$의 분할을 $P$라고 하자. $$ P=\left\{ x_1,\ x_2,\ \cdots ,\ x_n \right\} $$ 이때, $a=x_1 &amp;lt; x_2 &amp;lt; \cdots &amp;lt; x_n=b$이고 각 점의 사이의 거리는 같다. 그리고 $\Delta x=x_{i+1}-x_i$. $f(x_i)$의 합을 $n$으로 나눠서 $f(x)$의 평균값을 어림하려고 한다.</description>
    </item>
    
    <item>
      <title>뉴턴-랩슨 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/newton-raphson-method/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newton-raphson-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 고차원에 대해 일반화된 뉴턴-랩슨 메소드 $f,f&#39;,f&#39;&#39;$ 가 $\alpha$ 의 근방에서 연속이고 $f(\alpha) = 0, f&#39;(\alpha) \ne 0$ 이라고 하자. $\alpha$ 와 충분히 가까운 초기값 $x_{0}$ 에 대해 $\displaystyle x_{n+1} := x_{n} - {{ f ( x_{n} ) } \over { f&#39; ( x_{n} ) }}$ 과 같이 정의된 수열 $\left\{ x_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 쿼드러틱하게 수렴한다. 뉴턴-랩슨 메소드는 그냥 뉴턴 메소드라고 불리기도</description>
    </item>
    
    <item>
      <title>샤피로-윌크 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/shapiro-wilk-test/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shapiro-wilk-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 하르케-베라 테스트 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 가 주어져 있다고 하자. $H_{0}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따른다. $H_{1}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따르지 않는다. 샤피로-윌크 테스트는 정규성을 검정하기 위해 사용하는 테스트로써, 보통은 정규성이 있음을 보이기 위해서 사용한다. 귀무가설이 채</description>
    </item>
    
    <item>
      <title>바이섹션 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/bisection-method/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bisection-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 연속함수 $f$ 가 폐구간 $[a,b]$ 에서 $f(a) f(b) &amp;lt; 0$ 이라고 하자. 허용오차는 $\varepsilon$ 이다. $f(c) = 0$ 를 만족하는 $c \in [a,b]$ 는 다음과 같이 구할 수 있다.**Step 1. $\displaystyle c:= {{a+b} \over {2}}$**Step 2. $b-c \le \varepsilon$ 이면 $c$ 를 반환한다.**Step 3. $f(b) f(c) &amp;lt; 0$ 이면 $a:=c$, 아니면 $b:=c$그리고 Step 1. 으로 돌아간다. 중간값정리의 대표적인 응용으</description>
    </item>
    
    <item>
      <title>시계열분석에서의 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation/</guid>
      <description>빌드업 시계열에서 변환이 필요한 이유는 시간이 흐를수록 분산이 커지는 경우 그에 따른 &amp;lsquo;패널티&amp;rsquo;를 줘서 분산을 일정하게 하고 정상성을 얻기 위함이다. 루트 $\sqrt{}$ 나 로그 $\log$ 는 값이 클수록 줄어드는 양이 많기 때문에 자주 사용된다. 당연하지만 분산이 줄어드는 경우에는 데이터의 추이가 어떤 점으로 수렴한다는 의미가 되므로 변환 이전</description>
    </item>
    
    <item>
      <title>수치해석에서의 수렴률</title>
      <link>https://freshrimpsushi.github.io/posts/rate-of-convergence-in-numerical-analysis/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rate-of-convergence-in-numerical-analysis/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\alpha$ 로 수렴하는 수열 $\left\{ x_{n} \right\}$ 이 $p \ge 1$ 과 $c \ge 0$ 에 대해 $| \alpha - x_{n+1} | \le c | \alpha - x_{n} | ^{p}$ 이면 차수 $p$ 을 만족하면 $\left\{ x_{n} \right\}$ 이 수렴률 $c$ 로 $\alpha$ 에 $p$ 차 수렴한다고 한다. 특히 $c &amp;lt; 1$ 이라는 조건과 함께 $p=1$ 이면 선형 수렴Linear Convergence이라 부른다. 비슷하게 $p=2$ 일 때는 Quadratic Convergence , $p=3$ 일 때는 Cubic Co</description>
    </item>
    
    <item>
      <title>스무스 소수</title>
      <link>https://freshrimpsushi.github.io/posts/smooth-prime/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/smooth-prime/</guid>
      <description>정의 소수 $p$ 에 대해 $(p-1)$ 가 많은 약수를 가지면 $p$ 가 스무스 소수라고 한다. $B$ 보다 작거나 같은 소수들의 곱으로 나타나는 수를 $B$-스무스 수라고 한다. $\psi ( X , B )$ 는 $X$ 보다 작거나 같은 $B$-스무스 수의 갯수를 나타낸다. 설명 스무스한 소수의 예로써 $p=37$ 를 생각해보면 $(p-1)$ 는 $p-1 = 36 = 2^2 3^2$ 와 같이 자잘한 소수들의 곱들로 표현된다. 스무스는 개념은 암호</description>
    </item>
    
    <item>
      <title>푸리에 급수에 대한 베셀 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/bessels-inequality-for-fourier-series/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bessels-inequality-for-fourier-series/</guid>
      <description>공식 구간 $[-L,L)$에서 정의된 함수 $f$가 리만적분가능하면 아래의 부등식이 성립하고 이를 베셀 부등식이라 한다. $$ \dfrac{1}{4}|a_{0}|^{2} +\dfrac{1}{2}\sum\limits_{n=1}^{\infty} \left(|a_{n}|^{2} + |b_{n}|^{2} \right) =\sum \limits_{n=-\infty}^{\infty} | c_{n} |^{2} \le \dfrac{1}{2L}\int_{-L}^{L} | f(t)|^{2} dt $$ 이때 $a_{0},\ a_{n},\ b_{n}$은 $f$의 푸리에 계수, $c_{n}$은 $f$의 복소 푸리에 계수이다. 증명 임의의 복소수 $z$에 대해서 $|z|^{2}= z \overline{z}$이므로, $$</description>
    </item>
    
    <item>
      <title>불연속점에서 푸리에 급수의 수렴성</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-of-fourier-series-at-point-of-discontinuity/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-of-fourier-series-at-point-of-discontinuity/</guid>
      <description>정리1 구간 $[-L,\ L)$에서 정의된 함수 $f(t)$가 조각마다 연속이라고 하자. 불연속점을 $t_i\ (i=1,\ \cdots m )$라고 하고 각 불연속점에서 좌미분계수 $f(a-)$, 우미분계수 $f(a+)$ 를 가진다고 하자. 그러면 $f(t)$의 푸리에 급수는 불연속점 $t_i$에서 좌극한와 우극한의 중간값으로 수렴한다. $$ \dfrac{a_0}{2}+\sum \limits_{n=1}^{\infty}\left( a_{n} \cos \dfrac{n \pi t_{i} }{L} +b_{n}\sin\dfrac{n\pi t_{i}}{L} \right) = \dfrac{f(t_i+)+f(t_i-)}{2} $$ $f$가 리만적분가능하면 $</description>
    </item>
    
    <item>
      <title>조각마다 연속, 조각마다 매끄러움</title>
      <link>https://freshrimpsushi.github.io/posts/piecewise-continuous-piecewise-smooth/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/piecewise-continuous-piecewise-smooth/</guid>
      <description>정의 함수 $f$가 구간 $I$에서 아래의 조건을 만족할 때 $f$는 구간 $I$에서 조각마다 연속piecewise continuous이라고 한다. 유한 개의 불연속점들 $x_1,\ x_2,\ \cdots ,\ x_n \in I$을 가진다. 불연속 점에서 좌극한과 우극한을 가진다. $$ \left|\lim \limits_{x\rightarrow x_i^{+}} f(x) \right| &amp;lt; \infty \quad \text{and} \quad \left|\lim_{x \rightarrow x_i^{-}}f(x)\right|&amp;lt;\infty \quad (i=1,\ \cdots ,\ n) $$ 함수 $f$가 유한개의 불연속 점을 제외한 모든 곳에서</description>
    </item>
    
    <item>
      <title>샹크스 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-shankss-babystep-giantstep-algorithm/</link>
      <pubDate>Tue, 19 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-shankss-babystep-giantstep-algorithm/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건 항등원이 $e$ 인 그룹 $G$ 의 원소 $g$ 가 오더 $N$ 이라고 하자. 그러면 이산로그 문제 $g^{x} = h$ 는 다음의</description>
    </item>
    
    <item>
      <title>2계 선형 미분 방정식의 두 해의 론스키안</title>
      <link>https://freshrimpsushi.github.io/posts/wronskian-of-two-solution-of-second-order-linear-differential-equation/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/wronskian-of-two-solution-of-second-order-linear-differential-equation/</guid>
      <description>정리 1 $y_1$과 $y_2$가 2계 선형 미분 방정식 $y&#39;&#39;+p(t)y&#39;+q(t)y=0$의 해라고 하자. 그러면 $y_1$과 $y_2$의 론스키안 은 지수함수 꼴로 나타난다. $$ W [y_{1}, y_{2}] (t)=c e^{-\int p(t) dt} $$ 이 때 $c$는 $y_1,\ y_2$에 의존하는 상수이다. $W[y_1,y_2] (t)$는 모든 점에서 $0$이거나 모든 점에서 $0$이 아니다. 설명 아벨의 정리A</description>
    </item>
    
    <item>
      <title>시계열분석에서의 차분</title>
      <link>https://freshrimpsushi.github.io/posts/difference/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference/</guid>
      <description>정의 1 오퍼레이터 $B$ 를 $B Y_{t} = Y_{t-1}$ 과 같이 정의하고, 백쉬프트Backshift라 한다. 오퍼레이터 $\nabla$ 를 $\nabla := 1 - B$ 그리고 $\nabla^{r+1} = \nabla \left( \nabla^{r} Y_{t} \right)$ 와 같이 정의하고 차분 이라한다. 설명 차분의 정의에 따르면 $1$차 차분은 $$ \nabla Y_{t} = Y_{t} - Y_{t-1} $$ 와 같이 계산되며, $2$차 차분은 $$ \begin{align*} \nabla^2 Y_{t} =&amp;amp; \nabla \left( \nabla Y_{t} \right) \\ =&amp;amp; \nabla \left( Y_{t} - Y_{t-1} \right) \\ =&amp;amp; \nabla Y_{t} - \nabla Y_{t-1} \\ =&amp;amp; ( Y_{t} - Y_{t-1} ) - (</description>
    </item>
    
    <item>
      <title>기전력과 운동 기전력</title>
      <link>https://freshrimpsushi.github.io/posts/electromotive-force-and-motional-emf/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/electromotive-force-and-motional-emf/</guid>
      <description>정의 기전력 회로에서 전하를 움직여 전류를 만들어내는 힘을 $\mathbf{f}$라고 하자. 이 $\mathbf{f}$는 두 가지로 나눌 수 있다. 하나는 회로 전원의 힘 $\mathbf{f}_s$이고 다른 하나는 회로 어느 부분에 쌓인 전하에 의해 만들어진 전기력 $\mathbf{E}$이다. 여기서 아래첨자 $s$는 source의</description>
    </item>
    
    <item>
      <title>델 연산자가 포함된 식의 부분적분</title>
      <link>https://freshrimpsushi.github.io/posts/integral-by-part-with-del-operator/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integral-by-part-with-del-operator/</guid>
      <description>공식 델 연산자가 포함된 벡터 적분에 대해서 다음의 식이 성립한다. (a) $$ \int_{\mathcal{V}}\mathbf{A} \cdot (\nabla f)d\tau = \oint_{\mathcal{S}}f\mathbf{A} \cdot d \mathbf{a}-\int_{\mathcal{V}}f(\nabla \cdot \mathbf{A})d\tau $$ (b) $$ \int_{\mathcal{S}} f \left( \nabla \times \mathbf{A} \right)\mathbf{A} \cdot d \mathbf{a} = \int_{\mathcal{S}} \left[ \mathbf{A} \times \left( \nabla f \right) \right] \cdot d\mathbf{a} + \oint_{\mathcal{P}} f\mathbf{A} \cdot d\mathbf{l} $$ (c) $$ \int_{\mathcal{V}} \mathbf{B} \cdot \left( \nabla \times \mathbf{A} \right) d\tau = \int_{\mathcal{V}} \mathbf{A} \cdot \left( \nabla \times \mathbf{B} \right) d\tau + \oint_{\mathcal{S}} \left( \mathbf{A} \times \mathbf{B} \right) \cdot d \mathbf{a} $$ 설명 부분적분은 어떤 함수$(f\ or\ \mathbf{A}$)와 어떤 함수의 도함수$(\nabla f\</description>
    </item>
    
    <item>
      <title>엘가말 공개 키 암호체계 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-elgamal-public-key-cryptosystem/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-elgamal-public-key-cryptosystem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건왼쪽부터 순서대로 앨리스 , 밥 , 이브**라 하자. 앨리스와 밥은 메세지를 주고받을 당사자</description>
    </item>
    
    <item>
      <title>정전기학에서의 일과 에너지</title>
      <link>https://freshrimpsushi.github.io/posts/work-and-energy-in-electrostatics/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/work-and-energy-in-electrostatics/</guid>
      <description>설명1 전하를 옮기느라 한 일 전위와 전기장 사이에 아래와 같은 식이 성립한다. $$ -\int_\mathbf{a} ^\mathbf{b} \mathbf{E} \cdot d\mathbf{l} = \int_\mathbf{a} ^ \mathbf{b} \left( \nabla V \right) \cdot d\mathbf{l} = V(\mathbf{b}) - V(\mathbf{a}) $$ 따라서 고정된 원천 전하 분포가 있고 시험전하 $Q$를 점 $\mathbf{a}$에서 점 $\mathbf{b}$까지 옮길 때 드는 일은 다음과 같이 계산한다. $$ W=\int_{\mathbf{a}}^\mathbf{b} \mathbf{F} \cdot d\mathbf{l} = -Q\int_\mathbf{a}^\mathbf{b} \mathbf{E} \cdot d\mathbf{l} =Q[V(\mathbf{b})-V(\mathbf{a})] $$ 위 식을 $Q$로 나누면 아래와 같</description>
    </item>
    
    <item>
      <title>아르마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/arma-model/</link>
      <pubDate>Sat, 16 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arma-model/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $$ Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} +e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q} $$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 **$(p,q)$차 자기회귀이동평균과정 $ARMA(p,q)$**라 한다. 설명 아르마 모형은 단순히 이동평균과정과 자기회귀과정을 이어붙인 모양을 갖고 있다. 예로써 $(1,1)$차라면 $$ ARMA(1,1) : Y_{t} = \phi Y_{t-1} +</description>
    </item>
    
    <item>
      <title>디피-헬만 키 교환 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-diffie-hellman-key-exchange-algorithm/</link>
      <pubDate>Fri, 15 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-diffie-hellman-key-exchange-algorithm/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건왼쪽부터 순서대로 앨리스 , 밥 , 이브라 하자. 앨리스와 밥은 메세지를 주고받을 당사자고,</description>
    </item>
    
    <item>
      <title>우분투에서 R 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-r-in-ubuntu/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-r-in-ubuntu/</guid>
      <description>가이드 Step 1. Ctrl+Alt+T 를 눌러 콘솔창을 띄운다. Step 2. 콘솔창에 다음과 같이 입력한다. sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 관리자 권한이 필요하므로 사용자 계정의 암호를 입력해야한다. Step 3. 콘솔창에 다음과 같이 입력한다. sudo add-apt-repository &#39;deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/&#39; Step 4. 콘솔창에 다음과 같이 입력한다. sudo apt update Step 5. 콘솔창에 다음과 같이 입력한다. sudo apt install r-base *Step 6. 성공적으로 설치되었는지 확인하기 위해 콘솔창에</description>
    </item>
    
    <item>
      <title>자기회귀과정</title>
      <link>https://freshrimpsushi.github.io/posts/ar-autoregressive-process/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ar-autoregressive-process/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} + e_{t}$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 $p$차 자기회귀과정 $AR(p)$ 라고 한다. (1): $AR(1) : Y_{t} = \phi Y_{t-1} + e_{t}$ (2): $AR(2) : Y_{t} = \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + e_{t}$ (p): $AR(p) : Y_{t} = \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} + e_{t}$ (∞): $AR( \infty ) : Y_{t} = e_{t} + \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots $ $\mathbb{N}$ 은 자연수의 집합 $\left\{ 1, 2, 3 , \cdots \right\}$ 을 의미한다. 설명 $AR(p)$ 를 &amp;lsquo;자</description>
    </item>
    
    <item>
      <title>이산로그</title>
      <link>https://freshrimpsushi.github.io/posts/discrete-logarithm/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/discrete-logarithm/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 이산로그 문제의 어려움을 이용한 보안 알고리즘디피-헬만 키 교환 알고리즘엘가말 공개 키 암호체계이산로그 문제에 대한 공격 알고리즘샹크스 알고리즘폴리그-헬맨 알고리즘이산로그 문제가 쉽게 풀리는 조건 소수 $p$ 에 대해 갈루아 필드 $\mathbb{F}_{p} := \mathbb{Z} / p \mathbb{Z}$ 의 항등원이 $0$ 이라고 하자. $\mathbb{F}_{p}$ 의 원시근 $g \ne 0$ 에 대</description>
    </item>
    
    <item>
      <title>이동평균과정</title>
      <link>https://freshrimpsushi.github.io/posts/ma-moving-average-process/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ma-moving-average-process/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $Y_{t} := e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q}$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 **$q$차 이동평균과정 $MA(q)$**라고 한다. (1): $MA(1) : Y_{t} = e_{t} - \theta e_{t-1}$ (2): $MA(2) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2}$ (q): $MA(q) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q}$ (∞): $MA( \infty ) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots$ $\mathbb{N}$ 은 자연수의 집합 $\left\{ 1, 2, 3 , \cdots \right\}$ 을 의미한다. 설명 다</description>
    </item>
    
    <item>
      <title>암호론에서의 암호화와 복호화</title>
      <link>https://freshrimpsushi.github.io/posts/encryption-and-decryption-in-cryptography/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/encryption-and-decryption-in-cryptography/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 앨리스Alice가 밥Bob 에게 전하고 싶은 메세지가 있다고 생각해보자. 세상에 사람이 둘 뿐이라면 이 메세지는 오직 둘만이 공유하며, 감출 이유가 없다. [ NOTE: 암호론에서 앨리스는 $A$ 를 대신하는 이름이고, 밥은 $B$ 를 대신하는 이름이다. ]하지만 이들 외의 제3자로 이브Eve가 있다고 하자. 이</description>
    </item>
    
    <item>
      <title>체비셰프 미분방정식과 체비셰프 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-differential-equation-and-chebyshev-polynomial/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-differential-equation-and-chebyshev-polynomial/</guid>
      <description>정의 다음의 미분방정식을 체비셰프Chebyshev 미분방정식이라 한다. $$ \begin{equation} (1-x^2)\dfrac{d^2 y}{dx^2} -x\dfrac{dy}{dx}+n^2 y=0 \label{def1} \end{equation} $$ 체비셰프 미분방정식의 해를 체비셰프 다항식이라 하고 이를 흔히 $T_n(x)$으로 표기한다. $T_n(x)$의 일반항은 아래와 같다. $n$이 짝수일 때 $$ 1-\dfrac{\lambda^2}{2!}x^2+\dfrac{\lambda^2(\lambda^2-2^2)}{4!}x^4+\sum \limits_{m=3}^\infty (-1)^m \dfrac{\lambda^2(\lambda^2-2^2)\cdots(\lambda^2-(2m-2)^2)}{(2m)!} x^{2m} $$ $n$이 홀수일 때 $$ x-\dfrac{\lambda^2-1^2}{3!}x^3+\dfrac{(\lambda^2-1^2)(\lambda^2-3^2)}{5!}x^5+\sum \limits_{m=3}^\infty (-1)^m\dfrac{(\lambda^2-1^2)(\lambda^2-3^2) \cdots (\lambda^2-(2m-1)^2)}{(2m+1)!} x^{2m+1} $$ 특히 처음 몇 개의 다항식은 아래와 같</description>
    </item>
    
    <item>
      <title>체비셰프 미분방정식의 급수해: 체비셰프 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/series-solution-of-chebyshev-differential-equation/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-solution-of-chebyshev-differential-equation/</guid>
      <description>정의 다음의 미분방정식을 체비셰프Chebyshev 미분방정식이라 한다. $$ (1-x^2)\dfrac{d^2 y}{dx^2} -x\dfrac{dy}{dx}+n^2 y=0 $$ 설명 체비셰프는 러시아 사람이라 이름 표기가 제각각이다. 네이버에서는 체비쇼프라고 검색해야 해당 인물이 나오고, 대한수학회에서는 체비셰프라고 한다. 계수에 독립변수 $x$가 포함된 형태이며, 해가 멱급수 꼴이라고 가정하면 풀 수 있다. 체비셰프 방정</description>
    </item>
    
    <item>
      <title>속박전류밀도와 자화된 물체가 만드는 벡터 전위 자기장</title>
      <link>https://freshrimpsushi.github.io/posts/vector-potential-and-magneticfield-by-magnetized-object-bound-current/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vector-potential-and-magneticfield-by-magnetized-object-bound-current/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 외부 자기장에 의해 자화된 물체가 있다고 하자. 이 물체는 자화밀도 $\mathbf{M}$을 가질 것이고 이 자화밀도에 의해 새로운 자기장이 생길 것이다.하나의 자기 쌍극자가 만드는 벡터 전위는 $$ \mathbf{A} (\mathbf{r}) = \dfrac{\mu_0}{4\pi}\dfrac{\mathbf{m} \times \hat{\boldsymbol{\eta}} }{\eta ^2} $$ 자화밀도는 단위부피당 쌍극자 모멘트이므로 $\mathbf{M}=\d</description>
    </item>
    
    <item>
      <title>시계열분석에서의 정상성</title>
      <link>https://freshrimpsushi.github.io/posts/stationarity-in-time-series-analysis/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stationarity-in-time-series-analysis/</guid>
      <description>정의 1 시계열 데이터의 평균과 분산이 일정할 때 정상성Stationarity을 갖는다고 한다. 설명 정상正常Normal이 아니라 정상定常Stational이다. 데이터가 정상성을 가진다는 것은 평균과 분산이 안정되어 있어서 분석하기 쉽다는 의미가 된다. 데이터가 정상성을 가지지 않으면 분석이 어렵기 때문에 정상성을 갖도록 만드는 전처</description>
    </item>
    
    <item>
      <title>외부 자기장에 의한 전자 궤도의 변화와 반자성</title>
      <link>https://freshrimpsushi.github.io/posts/diamagnetism-and-changes-of-electron-orbits-by-magneticfield/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diamagnetism-and-changes-of-electron-orbits-by-magneticfield/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 핵 주위를 반지름 $R$로 공전하고 있는 전자가 있다고 하자. 움직이는 점전하는 정상전류가 되지 않지만 그 속도가 너무 빠르기 때문에 정상전류처럼 보인다 . 주기는 이동거리를 속도로 나눈 것이므로 $$ T=\dfrac{2\pi R}{v} $$ 전류는 단위시간당 지나가는 전하량이고 전자는 궤도 위의 어느 한 점을 한 주기에 한 번 지나가므로</description>
    </item>
    
    <item>
      <title>자기 쌍극자가 외부 자기장에 의해 받는 토크와 상자성</title>
      <link>https://freshrimpsushi.github.io/posts/paramagnetism-and-torque-experienced-by-magnetic-dipole-by-magneticfield/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/paramagnetism-and-torque-experienced-by-magnetic-dipole-by-magneticfield/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 전기 쌍극자가 외부 전기장에 의해 토크를 얻는 것 처럼 자기 쌍극자도 그러하다. 아래 그림과 같이 일정한 외부 자기장 $\mathbf{B}=B\hat{\mathbf{z}}$하에 전류 고리가 있다고 하자. 작은 사각형의 전류고리를 겹쳐서 임의의 모양으로 생긴 전류고리를 근사할 수 있으므로</description>
    </item>
    
    <item>
      <title>자화밀도와 자성체</title>
      <link>https://freshrimpsushi.github.io/posts/magnetization-and-magnetic-substance/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/magnetization-and-magnetic-substance/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 겉으로 봤을 때 자성이 없는 물체가 있다고 하자.이 물체를 원자수준까지 자세히 들여다보자.핵 주위를 도는 전자에 의해 미세한 전류가 생성되고 이는 자기 현상을 만들어낸다.각각의 원자 마다 아주 작은 자기 쌍극자 가 생기는 것이다.하지만 원자들의 방향이 전부 제각각이기 때문에 이 쌍극자 모멘트들을 전</description>
    </item>
    
    <item>
      <title>R 에서 그래프 그릴 때 축 이름에 아래첨자 넣기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-subscript-in-plot-in-r/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-subscript-in-plot-in-r/</guid>
      <description>코드 R 에서도 변수의 이름에 언더바 _를 넣는 것은 허용되지만, 그래프에서도 그렇게 나타낸다면 심하게 가독성이 떨어진다. expression() 함수를 아래와 같이 사용하면 축 이름에도 보기 좋게 아래첨자를 넣을 수 있다. data&amp;lt;-as.numeric(lynx) win.graph(4,4) plot(data[-1],data[-length(data)],type=&#39;p&#39;,main=&#39;아래첨자 사용&#39;, xlab=expression(Y[t]),ylab=expression(Y[t-1]))</description>
    </item>
    
    <item>
      <title>시계열분석에서의 백색잡음</title>
      <link>https://freshrimpsushi.github.io/posts/white-noise-in-time-series-analysis/</link>
      <pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/white-noise-in-time-series-analysis/</guid>
      <description>정의 1 iid한 확률변수 $e_{t}$ 들의 수열 $\left\{ e_{t} \right\}_{t = 1}^{\infty}$ 를 백색잡음White Noise이라고 한다. iid란 independent identically distributed의 줄임말로써, 서로 독립이고 같은 분포를 가짐을 의미한다. 설명 확률변수의 수열이라는 정의에 따르면 당연히 확률과정이다. 특히 $E ( e_{t} ) = 0$ 이면 $Y_{t} : = \begin{cases} e_{1} &amp;amp; , t=1 \\ Y_{t-1} + e_{t} &amp;amp; , t \ne 1 \\ \end{cases}$ 과 같이 정의된 확률</description>
    </item>
    
    <item>
      <title>푸아송 프로세스</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-process/</link>
      <pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-process/</guid>
      <description>정의 $\tau_{1} , \tau_{2} , \cdots \sim \text{exp} ( \lambda )$ 이라고 하자. $\lambda$ 를 강도Intensity라고 한다. $\displaystyle s_{n}:= \sum_{k=1}^{n} \tau_{k}$ 를 도달 시간Arrival Time이라 한다. $N_{t}:= \begin{cases} 0 , &amp;amp; 0 \le t &amp;lt; s_{1} \\ k , &amp;amp; s_{k} \le t &amp;lt; s_{k+1} \end{cases}$ 와 같이 정의된 확률과정 $\left\{ N_{t} \right\}_{t = 0}^{\infty}$ 를 푸아송 프로세스Poisson Process라 한다. 기초 성질 [1]: $\displaystyle p (N_{t} = k ) = {{ ( \lambda t )^{t} e^{ - \lambda t} } \over { k! }}$ [2]: $\displaystyle</description>
    </item>
    
    <item>
      <title>파동함수의 규격화와 제곱적분 가능</title>
      <link>https://freshrimpsushi.github.io/posts/normalize-of-wave-function-and-square-integrable/</link>
      <pubDate>Wed, 06 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normalize-of-wave-function-and-square-integrable/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **파동함수(wave function)와 확률 밀도(probability density) 파동함수는 양자역학에서 시간, 위치에 따른 입자의 운동 상태를 나타내는 함수이다. 보통 $u$, $\psi$, $\Psi$로 표기한다. 본 블로그에서 위치와 시간에 대한 파동함수는 $\psi(x,t)$로 나타내고 시간</description>
    </item>
    
    <item>
      <title>히든 마코프 체인</title>
      <link>https://freshrimpsushi.github.io/posts/hidden-markov-chain/</link>
      <pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hidden-markov-chain/</guid>
      <description>빌드업 위의 그림과 같이 어떤 기계에서 일정한 시간마다 어떤 물건을 생산한다고 생각해보자. 녹색이 정상적인 양품 $1$ 이고 적색이 폐기해야하는 불량품 $0$ 이라면, 지금까지의 기록은 $\left( 1, 0 , 1 \right)$ 이 될 것이다. 이렇게 실제로 눈에 보이는 결과를 시그널Signal이라고 한다. 단, 불량품이 나올 확률은 기계가 정상인지 고장인지에 따라 다르다고 하자. 정</description>
    </item>
    
    <item>
      <title>시계열분석이란</title>
      <link>https://freshrimpsushi.github.io/posts/time-series-analysis/</link>
      <pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-series-analysis/</guid>
      <description>설명 시계열Time Series 이란 쉽게 말해 실제 데이터로 얻어지는 확률과정이라고 볼 수 있다. 주가지수는 시간이 흐름에 따라 불확실성을 가지고 그 값이 변하므로 시계열의 좋은 예시가 될 수 있다. 시계열분석이란 이렇듯 시간 변수의 흐름에 따른 종속변수의 움직임을 이해하고 예측하는 것을 목표로 하는 분석법이다. 회귀분석과의 가장 큰 차이점은 회귀분석이 독립</description>
    </item>
    
    <item>
      <title>벡터 전위의 다중극 전개와 자기 쌍극자 모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/multipole-expansion-of-vector-potential-and-magnetic-dipole-moment/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multipole-expansion-of-vector-potential-and-magnetic-dipole-moment/</guid>
      <description>설명1 벡터 전위의 다중극 전개 전기장의 스칼라 전위와 마찬가지로 벡터 전위도 전류가 모여있을 때 충분히 먼 곳에서 $\dfrac{1}{r}$에 대한 급수 근사식을 얻을 수 있다. 선 전류 고리에 대한 벡터 전위 $$ \mathbf{A}(\mathbf{r})=\dfrac{\mu_0 I}{4\pi}\oint \dfrac{1}{\eta}d\mathbf{l}^{\prime} $$ 위 그림과 같은 조건에서 다음의 식이 성립한다. $$ \dfrac{1}{\eta} =\dfrac{1}{\sqrt{r^2+(r^{\prime})^2-2rr^{\prime}\cos\alpha}} = \dfrac{1}{r}\sum \limits_{n=0}^{\infty} \left( \dfrac{r^{\prime}}{r} \right)^{n} P_n(\cos \alpha ) $$ 이를 벡터 전위 식에 대입하면 아래와 같다. $$ \mathbf{A}(\mathbf{r})=\dfrac{\mu_0 I}{4\pi} \sum \limits_{n=0}^{\infty}</description>
    </item>
    
    <item>
      <title>속박전하와 편극된 물체가 만드는 전기장</title>
      <link>https://freshrimpsushi.github.io/posts/bound-charge-and-electric-field-of-polarized-object/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bound-charge-and-electric-field-of-polarized-object/</guid>
      <description>설명1 속박전하 외부 전기장에 의해서 물체의 쌍극자들이 한 방향으로 정렬하고 이로 인해 물체는 편극되고, 쌍극자 모멘트 $\mathbf{p}$를 가진다. 쌍극자 모멘트들이 만들어내는 전기장은 다음과 같이 계산한다. 쌍극자 모멘트 $\mathbf{p}$가 만드는 전위는 다음과 같다. $$ \begin{equation} V(\mathbf{r}) = \dfrac{1}{4 \pi \epsilon_0} \dfrac{ \mathbf{p} \cdot \hat{ \boldsymbol{\eta}} } {\eta ^2} \label{1} \end{equation} $$ $\math</description>
    </item>
    
    <item>
      <title>스토크스 정리</title>
      <link>https://freshrimpsushi.github.io/posts/stokes-theorem-for-physics/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stokes-theorem-for-physics/</guid>
      <description>정리1 $\mathbf{v}, \mathcal{S}$를 각각 3차원 공간에서 어떤 벡터, 면적이라고 하자. $\mathcal{S}$의 면적 벡터를 $d\mathbf{a}$, $\mathcal{S}$의 테두리를 $\mathcal{P}$, $\mathcal{P}$를 따라 움직이는 경로를 $d\mathbf{l}$이라고 하자. 그러면 다음의 식이 성립한다. $$ \int_{\mathcal{S}} (\nabla \times \mathbf{v} )\cdot d\mathbf{a} = \oint_{\mathcal{P}} \mathbf{v} \cdot d\mathbf{l} $$ 이를 스토</description>
    </item>
    
    <item>
      <title>쌍극자가 만드는 전기장</title>
      <link>https://freshrimpsushi.github.io/posts/electric-field-of-a-diploe/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/electric-field-of-a-diploe/</guid>
      <description>공식1 전기 쌍극자 $\mathbf{p}$가 원점에 있고 방향이 $\hat{\mathbf{z}}$일 때, 쌍극자가 만드는 전기장은 다음과 같다. $$ \mathbf{E}_{\text{dip}}(r,\theta)=\frac{1}{4 \pi \epsilon_0}\frac{p}{r^3}(2\cos\theta \hat{\mathbf{r}} + \sin\theta \hat{\boldsymbol{\theta}}) $$ 이를 좌표계에 무관한 식으로 바꾸면 다음과 같다. $$ \mathbf{E}_{\text{dip}}(\mathbf{r}) = \frac{1}{4 \pi \epsilon_0}\frac{1}{r^3}[3 (\mathbf{p} \cdot \hat{\mathbf{r}}) \hat{\mathbf{r}} - \mathbf{p}] $$ 유도 우선 구면좌표계의 단위벡터를 직교좌표계의 단위벡터로 나타내면 다음과 같다. $$ \begin{align*} \hat{\mathbf{r}} =&amp;amp;</description>
    </item>
    
    <item>
      <title>앙페르 법칙과 응용</title>
      <link>https://freshrimpsushi.github.io/posts/amperes-law-and-application/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/amperes-law-and-application/</guid>
      <description>공식 부피전류밀도 $\mathbf{J}$에 의해 생기는 자기장 $\mathbf{B}$가 회전하는 방향은, $\mathbf{J}$의 방향을 축으로 했을 때 오른손법칙을 만족시키는 방향이다. $$ \nabla \times \mathbf{B}=\mu_0 \mathbf{J} $$ 설명1 앙페르 법칙은 도선에 흐르는 전류와 자기장 사이에 특별한 관계가 있음을 말해주는 법칙이다. 도선에 전류가 흐르면 그 주위로 자</description>
    </item>
    
    <item>
      <title>일정하지 않은 전기장에 의한 극성분자의 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/alignment-of-polar-molecules-by-nonuniform-electric-field/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/alignment-of-polar-molecules-by-nonuniform-electric-field/</guid>
      <description>설명 1 극성분자는 외부 전기장이 없을 때에도 쌍극자 모멘트를 갖는다. 만약 일정한 외부 전기장이 있다면 쌍극자 모멘트가 전기장과 같은 방향으로 정렬한다. 그런데 외부 전기장이 일정하지 않다면 $\mathbf{F}_+$와 $\mathbf{F}_-$가 같지 않기 때문에 토크와 더불어 알짜힘도 받는다. 알짜힘은 다음과 같이 계산할 수 있다. $</description>
    </item>
    
    <item>
      <title>일정한 외부 전기장에 의한 극성분자의 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/alignment-of-polar-molecules-by-uniform-electric-field/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/alignment-of-polar-molecules-by-uniform-electric-field/</guid>
      <description>설명 1 전기적으로 중성인 원자가 외부 전기장 속에 놓여져 있을 경우 편극되어 쌍극자 모멘트 $\mathbf{p}$를 가지게 된다. 그런데 어떤 분자는 외부 전기장의 영향을 받지 않아도 쌍극자 모멘트를 가지고 있다. 이런 분자를 가리켜 극성분자polar molecule라고 한다. 극성 분자 극성분자의 예로 물 분자가 있다. 물 분자는 $105^{</description>
    </item>
    
    <item>
      <title>자기 쌍극자가 만드는 자기장</title>
      <link>https://freshrimpsushi.github.io/posts/magnetic-field-by-magnetic-dipole/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/magnetic-field-by-magnetic-dipole/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 원점에 놓인, 방향이 $\hat{\mathbf{z}}$인 자기 쌍극자가 만드는 자기장은 다음과 같다. $ \displaystyle \vec{B}_{\text{dip}}(r,\theta)=\frac{\mu_0 }{4 \pi }\frac{m}{r^3}(2\cos\theta \hat r + \sin\theta \hat \theta)$ 놀랍게도 전기 쌍극자가 만드는 전기장과 같은 모양이다.(쌍극자가 만드는 전기장)마찬가지로 좌표계와 무관하게 사용할 수 있는 공식을 유도해보자.$\ha</description>
    </item>
    
    <item>
      <title>자기력과 로런츠 힘 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/magnetic-force-and-lorentz-force-law/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/magnetic-force-and-lorentz-force-law/</guid>
      <description>정의1 움직이는 전하(전류)는 주위에 자기장magnetic field $\mathbf{B}$를 만든다. 자기장 $\mathbf{B}$속에서 $\mathbf{v}$의 속도로 움직이는 전하 $Q$가 받는 힘은 다음과 같다. $$ \begin{equation} \mathbf{F}_m=Q(\mathbf{v} \times \mathbf{B}) \end{equation} $$ 이 힘을 자기력magnetic force 이라 하고 위의 공식을 로런츠 힘 법칙Lorentz force law이라</description>
    </item>
    
    <item>
      <title>자기력은 일을 하지 않는다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-magnetic-forces-do-not-work/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-magnetic-forces-do-not-work/</guid>
      <description>정리1 자기력은 일을 하지 않는다. 설명 자기력이 있는 상황에서 입자나 물체 등이 움직이면 겉으로 보기엔 마치 자기력이 일을 해준 것 처럼 보인다. 허나 사실은 그렇지 않다. 증명 일은 힘과 변위의 곱이다. $$ W=\int \mathbf{F} \cdot d\mathbf{l} $$ 자기력이 해준 일은 $$ W_{\text{mag}}=\int \mathbf{F}_{\text{mag}} \cdot d\mathbf{l} = \int Q(\mathbf{v}\times \mathbf{B})\cdot d\mathbf{l} $$ 이때 $d\mathbf{l} = \dfrac{d\mathbf{l}}{dt}dt = \mathbf{v}dt$이므로 $$ W_{\text{mag}} = \int Q( \mathbf{v} \times \mathbf{B})\cdot \mathbf{v}dt $$ 여기서 $(\mathbf{v}\times \mat</description>
    </item>
    
    <item>
      <title>자기장의 다이벌전스(발산)와 컬(회전)</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-and-curl-of-magnetic-field/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-and-curl-of-magnetic-field/</guid>
      <description>정리 자기장의 다이벌전스와 컬은 다음과 같다. $$ \begin{align*} \nabla \cdot \mathbf{B} =&amp;amp; 0 \\ \nabla \times \mathbf{B} =&amp;amp; \mu_0 \mathbf{J} \end{align*} $$ 설명 전기장은 항상 컬이 $\mathbf{0}$인 특별한 벡터 함수였듯이 자기장 또한 그러하다. 부피전류에 대한 비오-사바르 법칙으로 발산과 회전을 구해보자. $$ \mathbf{B} (\mathbf{r}) = \dfrac{\mu_0}{4 \pi} \int \dfrac{\mathbf{J} (\mathbf{r}^{\prime}) \times \hat{\boldsymbol{\eta}} }{\eta^2} d \tau $$ 이 때 중요하게 알고 넘어가야 할 점이 있다. 각 함수가 어느 좌표에 대</description>
    </item>
    
    <item>
      <title>자기장의 벡터 전위</title>
      <link>https://freshrimpsushi.github.io/posts/magnetic-vector-potential/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/magnetic-vector-potential/</guid>
      <description>설명1 정전기학에서 전기장을 쉽게 다루기 위해 $\nabla \times \mathbf{E} = \mathbf{0}$이라는 성질을 이용해서 스칼라 전위 $V$를 정의한다. 마찬가지로 정자기학에서 $\nabla \cdot \mathbf{B} = 0$라는 성질을 이용해 벡터 전위 $A$를 정의해 사용한다. 자기장 $\mathbf{B}$를 어떤 벡터 $\mathbf{A}$의 회전이라고 하자. $$ \mathbf{B}=\nabla \times \mathbf{A} $$ 그러면 회</description>
    </item>
    
    <item>
      <title>전류와 전류밀도</title>
      <link>https://freshrimpsushi.github.io/posts/current-and-current-density/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/current-and-current-density/</guid>
      <description>정의1 도선의 어느 지점을 단위시간동안 지나가는 전하량을 전류current라고 정의한다. 따라서 왼쪽으로 움직이는 음전하와 오른쪽으로 움직이는 양전하는 부호가 같은 전류이다. 단위 시간동안 흐르는 쿨롱의 양을 암페어ampere라고 한다. $$ 1 [A] = 1 [C/s] $$ 설명 Ampere는 프랑스사람으로 실제 발음은 [앙페르]에 가깝다. 그래서 앙페</description>
    </item>
    
    <item>
      <title>정상전류와 비오-사바르 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/steady-current-and-biot-savart-law/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/steady-current-and-biot-savart-law/</guid>
      <description>정의1 정상전류steady current란 양과 진행 방향이 바뀌지 않고 끊임없이 계속되는 전하의 흐름을 말한다. 설명 시간에 따라 전류가 변하지 않으므로 정상전류가 만든 자기장 또 한 시간에 따라 변하지 않는다. 여기서 말하는 &amp;lsquo;진행 방향&amp;rsquo;이란, 흔히 생각하는 벡터의 방향과는 다른 개념이다. 반드시 직선으로 흘러야 한</description>
    </item>
    
    <item>
      <title>편극밀도와 유전체</title>
      <link>https://freshrimpsushi.github.io/posts/dielectrics-and-polarization-density/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dielectrics-and-polarization-density/</guid>
      <description>설명1 2 도체 속에는 자유전하가 굉장히 많다. 많은 전자들이 특정한 원자핵에 구속되지 않고 도체의 내부를 자유롭게 돌아다닌다는 의미이다. 반면 유전체dielectrics 혹은 절연체insulator에서는 상황이 다르다. 모든 전자가 특정 원자(분자)에 구속돼있다. 분자 속에서 조금 움직이는 것은 가능하나 자유전하처럼 움직일 수는 없다</description>
    </item>
    
    <item>
      <title>리만적분가능한 함수의 푸리에 급수는 수렴한다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-fourier-series-of-f-converges-f/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-fourier-series-of-f-converges-f/</guid>
      <description>정리1 함수 $f$가 구간 $[-L,\ L)$에서 리만적분가능하다고 하자. 그러면 연속인 점 $t$에 대해서 $f$의 푸리에 급수 $\lim \limits_{N \to \infty }S^{f}_{N}(t)$는 $f(t)$로 수렴한다. $$ \lim \limits_{N \rightarrow \infty} S^{f}_{N}(t)=f(t) $$ 이때 $$ \begin{align*} S^{f}_{N}(t)&amp;amp;=\dfrac{a_0}{2}+\sum \limits_{n=1}^{N} \left( a_n \cos \dfrac{n\pi t}{L} + b_n\sin\dfrac{n\pi t} {L} \right) \\ a_0 &amp;amp;=\dfrac{1}{L}\int_{-L}^{L}f(t)dt \\ a_n &amp;amp;= \dfrac{1}{L}\int_{-L}^{L} f(t)\cos\dfrac{n\pi t}{L} dt \\ b_n&amp;amp;=\dfrac{1}{L}\int_{-L}^{L}f(t)\sin\dfrac{n\pi t}{L}dt \end{align*} $$ 증명 $| \lim \limits_{N \rightarrow \infty} S^{f}_{N}(t)-f(t)|=0$임</description>
    </item>
    
    <item>
      <title>삼각함수의 정의를 이용한 제2코사인 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-second-law-of-cosines/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-second-law-of-cosines/</guid>
      <description>공식 위와 같이 주어진 삼각형에 대해서 다음의 식들이 성립하고, 이를 묶어 제2 코사인 법칙law of cosines이라 한다. $$ \begin{cases} a^{2} =b^{2}+c^{2}-2bc\cos\alpha \\ b^{2}=a^{2}+c^{2}-2ac\cos\beta \\ c^{2}=a^{2}+b^{2}-2ab\cos\gamma \end{cases} $$ 증명 그림의 좌상단 삼각형으로부터 아래의 식을 얻는다. $$ \begin{align} a &amp;amp;= \overline{BH_{a}}+\overline{H_{a}C} \nonumber \\ &amp;amp;= c\cos\beta + b\cos\gamma \label{eq1} \end{align} $$ 양변에 $a$를 곱하면 다음과 같다. $$ a^{2}=ac\cos\beta + ab\cos \gamma $$ $b$와 $c$에 대해서도 마찬가지로 다음과 같은 결과를 얻</description>
    </item>
    
    <item>
      <title>전위의 다중극 전개와 쌍극자 모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/multipole-expansion-and-dipole-moment/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multipole-expansion-and-dipole-moment/</guid>
      <description>설명1 다중극 전개 모여있는 전하분포를 충분히 멀리서 바라보면 마치 점전하 처럼 보일 것이다. 다시말해 전하분포의 총 전하량이 $Q$라면 이를 아주 멀리서 바라봤을 때 마치 전하량이 $Q$인 점전하 하나가 있는 것과 비슷하게 느껴질것이다. 그러면 전위를 $\dfrac{1}{4\pi\epsilon_0} \dfrac{Q}{r}$라고 해도 얼추 비슷할거라는 말이 된다. 그런데 만약 총 전하량이 $</description>
    </item>
    
    <item>
      <title>디리클레 커널</title>
      <link>https://freshrimpsushi.github.io/posts/dirichlet-kernel/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichlet-kernel/</guid>
      <description>정의 디리클레 커널Dirichlet kernel $D_{n}$을 아래와 같이 정의한다. $$ \begin{equation} D_{n}(t) := \dfrac{1}{2}+\sum \limits_{k=1}^{n} \cos kt \label{def} \end{equation} $$ 설명 디리클레 커널은 델다함수, 지수함수 등과 관련되어 있으며, 푸리에 해석에서 등장한다. 관련된 몇 가지의 정리와 증명을 소개한다. 정리1 디리클레 커널 $D_{n}(t)$는 $n \rightarrow \infty$일 때 디랙 델타 함수 $\delta(</description>
    </item>
    
    <item>
      <title>르장드르 다항식은 자신보다 차수가 낮은 임의의 다항식과 직교함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonality-of-legendre-polynomial/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonality-of-legendre-polynomial/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $P_l(x)$을 르장드르 다항식 , $f(x)$를 차수가 $l$보다 낮은 임의의 다항식이라 할 때 $P_l(x)$와 $f(x)$는 서로 직교 한다. $$ \int_{-1}^{1}P_l(x)f(x)dx $$ **보조정리 $f(x)$를 임의의 $n$차 다항식이라 하자.$f(x)$는 $l \le n$인 르장드르 다항식$(\mathrm{</description>
    </item>
    
    <item>
      <title>르장드르 다항식의 직교성</title>
      <link>https://freshrimpsushi.github.io/posts/the-orthogonality-of-legendre-polynomials/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-orthogonality-of-legendre-polynomials/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 함수의 내적 과 직교성 구간 $[-1,\ 1]$에서 르장드르 다항식은 직교 집합을 이룬다. $$ \int_{-1}^{1} P_l(x)P_m(x) dx =\frac{2}{2l+1}\delta_{lm} $$ 증명 **Case 1. $l\ne m$ 르장드르 다항식은 드장드르 미분방정식의 해이므로 위의 미분방정식의 $y$ 자리에 대입하면 식이 성립한다.즉, $$ \dfrac{d}{dx} \left[ (1-x^2)P&#39;_l(x) \right] + l(l+1)P_l (x)=0 $$ $$ \dfrac{d}{dx} \left[ (1-x^2)P&#39;_m(x) \right] + m(m+1)P_m(x)=0 $$ 두 식에 각각 $P_m(x)$, $P_l(x)$를 곱하</description>
    </item>
    
    <item>
      <title>삼각함수의 집합이 직교성을 가짐을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-set-of-trigonometric-functions-has-orthogonality/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-set-of-trigonometric-functions-has-orthogonality/</guid>
      <description>정리 $2L$-주기함수가 $2L$인 함수들의 집합 $\left\{ 1,\ \cos \dfrac{\pi x}{L},\ \cos \dfrac{2\pi x}{L}, \cdots ,\ \sin\dfrac{\pi x}{L},\ \sin\dfrac{2\pi x}{L},\ \cdots \right\}$은 구간 $[-L,\ L)$에서 직교집합이다. 다시말해 $m,n = 1, 2, 3, \dots$에 대해서 다음이 성립한다. $$ \begin{align} \dfrac{1}{L} \int _{-L}^{L} \cos\dfrac{m\pi x}{L} \cos\dfrac{n\pi x}{L} dx &amp;amp;= \delta_{mn} \label{eq1} \\ \dfrac{1}{L} \int _{-L}^{L} \sin \dfrac{m\pi x}{L}\sin \dfrac{n\pi x}{L} dx &amp;amp;= \delta_{mn} \label{eq2} \\ \int _{-L}^{L} \cos \dfrac{m\pi x}{L} \sin \dfrac{n\pi x}{L} dx \quad &amp;amp;= 0 \label{eq3} \\ \dfrac{1}{L} \int_{-L}^{L} \cos \dfrac{n\pi x}{L} dx &amp;amp;= 0 \label{eq4} \\ \dfrac{1}{L} \int_{-L}^{L} \sin \dfrac{n\pi x}{L} dx &amp;amp;= 0 \label{eq5}</description>
    </item>
    
    <item>
      <title>서로 수직한 삼각함수들의 합</title>
      <link>https://freshrimpsushi.github.io/posts/sum-of-orthogonal-trigonometric-functions/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-of-orthogonal-trigonometric-functions/</guid>
      <description>공식 $C_{n}$, $S_{n}$을 아래와 같이 정의하자. $$ \begin{align*} C_{n}: &amp;amp;= 1+\cos x + \cos 2x + \cdots +\cos nx \\ S_{n}: &amp;amp;= \sin x +\sin 2x + \cdots + \sin nx \end{align*} $$ 그러면 아래의 식이 성립한다. $$ \begin{align*} C_{n} &amp;amp;= \dfrac{\sin \dfrac{n+1}{2}x}{\sin \dfrac{1}{2}x} \cos \dfrac{n}{2}x \\ S_{n} &amp;amp;= \dfrac{\sin \dfrac{n+1}{2}x}{\sin \dfrac{1}{2}x}\sin \dfrac{n}{2}x \end{align*} $$ 증명 오일러 공식 을 사용한다. $$ \begin{align*} &amp;amp; C_{n}+ i S_{n} \\ =&amp;amp; (1+\cos x + \cos 2x + \cdots + \cos nx) + i(\sin x + \sin 2x + \cdots + \sin nx) \\ =&amp;amp; 1+(\cos x + i\sin x) + (\cos 2x + i \sin 2x) + \cdots + (\cos nx + i\sin nx) \\ =&amp;amp; e^{i0x}+e^{i1x}+e^{i2x}+\cdots +e^{inx} \\ =&amp;amp; \sum</description>
    </item>
    
    <item>
      <title>직교함수 직교집합 정규직교집합 함수의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-function-orthogonal-set-orthonomal-set-norm-of-function/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-function-orthogonal-set-orthonomal-set-norm-of-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 ** **내적$(\mathrm{inner\ product})$ 구간 $[a,b]$에서 정의된 두 복소 함수 $f$, $g$의 내적을 다음과 같이 정의한다. $$ \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) \overline{g(x)} dx $$ 따라서 같은 두 함수끼리의 내적은 $$ \left&amp;lt; f,f \right&amp;gt;=\int_a^b f(x) \overline{f(x)} dx = \int_a^b \left| f(x) \right| ^2 dx $$ 함수의 내적을 정적분으로 정의하는 이유 직교 $(\mathrm{orthogonal})$ 두 복소 함수 $f$, $g$가 아래</description>
    </item>
    
    <item>
      <title>푸리에 급수 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-fourier-series/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-fourier-series/</guid>
      <description>정의 $2L$-주기함수 $f$에 대해서 다음과 같은 급수를 $f$의 푸리에 급수Fourier series of f라고 정의한다. $$ \begin{align*} \lim \limits_{N \rightarrow \infty} S^{f}_{N}(t) &amp;amp;= \lim \limits_{N \to \infty}\left[ \dfrac{a_0}{2}+\sum \limits_{n=1}^{N} \left( a_{n} \cos \dfrac{n\pi t}{L} + b_{n}\sin\dfrac{n\pi t}{L} \right) \right] \\ &amp;amp;= \dfrac{a_0}{2}+\sum \limits_{n=1}^{\infty} \left( a_{n} \cos \dfrac{n\pi t}{L} + b_{n}\sin\dfrac{n\pi t}{L} \right) \end{align*} $$ 이때 각각의 계수 $a_{0}, a_{n}, b_{n}$을 푸리에 계수Fourier coefficient라고 하며 값은 다음과 같다. $$ \begin{align*} \\ a_0 &amp;amp;=\dfrac{1}{L}\int_{-L}^{L}f(t)dt \\ a_{n} &amp;amp;=</description>
    </item>
    
    <item>
      <title>도박꾼의 파산 문제</title>
      <link>https://freshrimpsushi.github.io/posts/gamblers-ruin-problem/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gamblers-ruin-problem/</guid>
      <description>문제 도박꾼의 파산 문제는 랜덤워크의 일종으로 두 명의 플레이어가 한정된 돈을 걸고 둘 중 하나가 파산할 때까지 반복하는 게임을 상정한다. 당신이 플레이어 중 하나라고 한다면, 위 도식과 같이 당신이 이길 확률이 $p$ 고 질 확률이 $(1-p)$ 라고 할 수 있다. 상태 $0$ 은 당신이 파산한 경우고, 상태 $N$ 은 당신이 상대의 돈을 모두 딴 경우로 더 이상 게임을 반복하지 않는다. 이는</description>
    </item>
    
    <item>
      <title>갈루아 이론</title>
      <link>https://freshrimpsushi.github.io/posts/galois-theory/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/galois-theory/</guid>
      <description>정리 1 $K$ 가 $F$ 의 유한정규확대체고 $F \le E \le K$ 라 하자. 고정된 $E$ 를 남기는 $G ( K / F )$ 의 부분군을 $\lambda (E)$ 와 같이 나타내자. 그러면 사상 $\lambda$ 은 $F$ 와 $K$ 사이의 모든 $E$ 를 $G ( K / F )$ 의 모든 부분군으로 대응시키는 동형사상이 된다. $\lambda$ 는 다음의 성질들을 가진다. $\lambda ( E ) = G ( K / E )$ $E = K_{ G ( K / E ) } = K_{ \lambda (E) }$ $H \le G ( K / F )$ 에 대해 $\lambda ( K_{H}</description>
    </item>
    
    <item>
      <title>ROC 곡선의 AUC 를 이용해 모형 비교하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</guid>
      <description>요약 ROC 곡선은 기본적으로 사각형 $[0,1]^2$ 을 가득 채울수록 좋고, 곡선의 왼쪽 상단의 꺾이는 점이 $(0,1)$ 에 가까울 수록 좋다. 설명 위의 두 ROC 곡선이 있다고 한다면 마음 편하게 &amp;lsquo;좋다&amp;rsquo;라고 할 수 있는 쪽은 오른쪽이다. 이 &amp;lsquo;좋다&amp;rsquo;는 말이 의미하는 것은 ROC 곡선을 그려내는 모형이 더 낫다는 뜻이다. 당연히 비교되는</description>
    </item>
    
    <item>
      <title>분리벡터의 회전</title>
      <link>https://freshrimpsushi.github.io/posts/curl-of-separation-vector-1r2/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/curl-of-separation-vector-1r2/</guid>
      <description>공식 $\nabla \times \dfrac{\hat{\boldsymbol{\eta}} }{\eta ^2} =0$ 설명 이 식이 특별한 의미를 가지는 것은 아니다. 자기장의 발산을 구하는 과정에서 나오는데 계산이 간단하지 않아 따로 설명한다. 증명 $\boldsymbol{\eta}=(x-x&#39;)\hat{\mathbf{x}} + (y-y&#39;)\hat{\mathbf{y}} + (z-z&#39;)\hat{\mathbf{z}}$를 분리벡터라고 하면 다음과 같다. $$ | \boldsymbol{\eta} |=\eta=\sqrt{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2} $$ $$ \hat{ \boldsymbol{\eta}}=\dfrac{ \boldsymbol{\eta} } { \eta}=\dfrac{(x-x&#39;)\hat{\mathbf{x}} + (y-y&#39;)\hat{\mathbf{y}} + (z-z&#39;)\hat{\mathbf{z}}}{\sqrt{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2}} $$ $$ \dfrac{\hat{\boldsymbol{\eta}}}{\eta^2}=\dfrac{1}{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2}\dfrac{(x-x&#39;)\hat{\mathbf{x}} + (y-y&#39;)\hat{\mathbf{y}} + (z-z&#39;)\hat{\mathbf{z}}}{\sqrt{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2}} $$ 계산의 편의를 위해 $$ \dfrac{\hat{\boldsymbol{\eta}} }{\eta ^2}</description>
    </item>
    
    <item>
      <title>펠 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/pells-equation/</link>
      <pubDate>Mon, 25 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pells-equation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $a_{n} : = n^2$ 를 사각수Square Number라 한다. $\displaystyle b_{m} : = {{ m ( m + 1 ) } \over {2}}$ 를 삼각수Triangular Number라 한다. 이들 중에서 사각수면서도 삼각수인 수가 있는지 한번 생각해보면, 당장 $a_{1} =b_{1} = 1$ 과 $\displaystyle a_{6} = 6 ^2 = 36 = {{ 8 \cdot 9 } \over {2}} = b_{8}$ 이 있다. 이제 일반적으로 사각</description>
    </item>
    
    <item>
      <title>ROC 곡선을 이용해 최적의 컷오프 찾는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</link>
      <pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</guid>
      <description>개요 ROC 곡선을 그리면 트레이닝 데이터로 얻은 모형이 테스트 데이터를 어느정도로 잘 설명하는지 한 눈에 보여서 유용하다. 하지만 이 곡선은 모든 컷오프에 대한 분류율을 계산하고 이은 것이므로 결국 &amp;lsquo;어떤 컷오프로 0과 1을 분류할 것인가&amp;rsquo;는 알 수 없다. 이것을 알아내기 위해 교차검증의 방법론을 응용해보자. 검증 데이터 트레이</description>
    </item>
    
    <item>
      <title>루트가 포함된 분수 유리화 빠르게 하기</title>
      <link>https://freshrimpsushi.github.io/posts/874/</link>
      <pubDate>Fri, 22 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/874/</guid>
      <description>공식 $$ \displaystyle {{ x } \over { \sqrt{a} \pm \sqrt{b} }} = {{ x \left( \sqrt{a} \mp \sqrt{b} \right) } \over { a - b }} $$ 설명 분수의 유리화는 개념적으로는 쉽지만 분자 분모에 복잡한 항을 곱하고 정리하는 부분에서 계산이 많아져서 어렵다. 그러나 위의 공식을 활용하면 빠르고 간단하게, 계산실수를 최소한으로 줄이면서 유리화를 해낼 수 있다.핵심은 이러나 저러나 분모의 루트를 벗겨내기 위해 $( \alpha^2 - \beta^2 )$ 꼴</description>
    </item>
    
    <item>
      <title>일반화된 랜덤워크</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-random-walk/</link>
      <pubDate>Thu, 21 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-random-walk/</guid>
      <description>정의 확률과정 $\left\{ X_{n} \right\}$ 의 상태공간이 정수의 집합 $\left\{ \cdots , -2 , -1, 0 , 1 , 2 , \cdots \right\}$ 이고, 상태 $0$ 에서 이라고 하자. 다음 스텝에서 $1$ 만큼 작아질 확률을 $p$, $1$ 만큼 커질 확률이 $(1-p)$ 일 때 $\left\{ X_{n} \right\}$ 을 일반화된 랜덤워크라 한다. 설명 랜덤워크란 확률 과정 중에서도 아주 단순한 예시로써, 보통 좌우로 갈 확률을 똑같이 둔다. 일반화된 랜덤워크란 그 확률을 다르게 두기도</description>
    </item>
    
    <item>
      <title>R 에서 ROC 곡선 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</guid>
      <description>정의 오류행렬의 False Positive Rate와 True Positive Rate를 각각 축으로 두고 그린 그림을 ROC 곡선Receiver Operating Characteristic Curve이라 한다. 설명 ROC 곡선은 모델의 퍼포먼스를 한 눈에 보여줄 뿐만 아니라 최적의 컷오프를 찾고 모델 간의 비교에도 쓰이는 등 요긴하게 쓸 데가 많다. 예제를 통해 R 에서 ROC 곡선을 그려보고 그 의미를 이해해보자. 핵심적인 패키지로 ROCR</description>
    </item>
    
    <item>
      <title>중심각이 작을 때 호의 길이와 현의 길이는 근사함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/the-arc-length-and-the-length-of-the-string-are-approximately-equal-when-the-center-angle-is-small/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-arc-length-and-the-length-of-the-string-are-approximately-equal-when-the-center-angle-is-small/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 중심각 $\theta$가 충분히 작을 때 현의 길이와 호의 길이는 근사하다.$\theta \rightarrow 0$일 때 $\overline{AB} \approx \stackrel\frown{AB}$ 현의 길이 $\overline{AB} =2\overline{AM}=2r\sin \frac{\theta}{2}$ 제2코사인법칙과 삼각함수의 반각공식을 이용해도 같은 결과를 얻지만 위 방법이 훨씬 짧고 쉽다. 호의 길이 중심각이 $\theta$이고 반지름의 길이가 $r$인 호의</description>
    </item>
    
    <item>
      <title>로렌츠 끌개</title>
      <link>https://freshrimpsushi.github.io/posts/lorenz-attractor/</link>
      <pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lorenz-attractor/</guid>
      <description>개요 로렌츠 방정식Lorenz Equation이란 대기의 대류를 연립 상미분 방정식으로써 표현하는 수학적 모델이다. 시스템 $$ \begin{align*} {{dx} \over {dt}} =&amp;amp; - \sigma x + \sigma y \\ {{dy} \over {dt}} =&amp;amp; - xz + \rho x - y \\ {{dz} \over {dt}} =&amp;amp; xy - \beta z \end{align*} $$ 변수 $x(t)$: $t$ 시점에서 입자의 $x$ 좌표를 나타낸다. $y(t)$: $t$ 시점에서 입자의 $y$ 좌표를 나타낸다. $z(t)$: $t$ 시점에서 입자의 $z$ 좌표를 나타낸다. 파라메</description>
    </item>
    
    <item>
      <title>교차검증</title>
      <link>https://freshrimpsushi.github.io/posts/cross-validation/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cross-validation/</guid>
      <description>모델 검증 데이터 분석을 해서 얻은 모델은 그 퍼포먼스가 적절한지 확인하는 과정이 필요하다. 주어진 데이터만 잘 설명하고 실전에서 전혀 힘을 쓰지 못하면 분석을 하는 의미가 없기 때문이다. 이를 위해서 전체 데이터를 모델을 얻는데 사용할 데이터셋과 그 모형의 퍼포먼스를 평가할 데이터셋으로 쪼갠다. 모델을 얻겠다는 것은 주어진 데이터를 이용해 다른 데이터</description>
    </item>
    
    <item>
      <title>갈루아체</title>
      <link>https://freshrimpsushi.github.io/posts/galois-field/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/galois-field/</guid>
      <description>정의 1 소수 $p$ 와 자연수 $n$ 에 대해 기수가 $p^{n}$ 인 유한체를 $p^{n}$ 차 갈루아체Galois Field라 정의하고 $\text{GF} \left( p^{n} \right)$ 와 같이 나타낸다. 정리 유한체는 갈루아체 뿐이고, 주어진 $p$ 와 $n$ 에 대해 갈루아체는 유일하게 존재한다. 여기서 유일하다는 말은 서로 다른 체라고 해도 동형사상이 존재해서 사실상 같은 체라는 뜻이다. 설명 가우스가 처음 유한체의 개념을 떠</description>
    </item>
    
    <item>
      <title>확률과정의 극한</title>
      <link>https://freshrimpsushi.github.io/posts/limit-of-probability-process/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-of-probability-process/</guid>
      <description>정의 현재의 상태가 $i$ 일 때, 무한한 스탭을 거쳐 $j$ 로 갈 확률을 $\displaystyle \pi_{j}:= \lim_{n \to \infty} p_{ij}^{ ( n ) }$ 과 같이 나타낸다. 설명 통계학이든 응용수학이든 하는 일이 대개 그렇지만 주된 관심사는 미래의 예측이다. 확률과정론에서 관심을 갖는 부분 역시 한 치 앞은 물론 먼 미래에 어떻게 될지가 궁금하다. 그리고 주로 이런 표현은 무한을 이용한다. 정의에서 $\displaystyle \pi_{j} = \sum_{i} \pi_{i} p_{ij}$ 과 같이 표</description>
    </item>
    
    <item>
      <title>가분확대체</title>
      <link>https://freshrimpsushi.github.io/posts/separable-extension-in-abstract-algebra/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separable-extension-in-abstract-algebra/</guid>
      <description>정의 1 $E$ 가 $F$ 의 확대체라고 하자. $E$ 에서 $\overline{F}$ 의 부분체로 가는 동형사상 중 고정된 $F$ 를 남기는 동형사상의 갯수를 $F$ 상에서 $E$ 의 인덱스Index라 하고 $\left\{ E : F \right\}$ 와 같이 나타낸다. $E$ 가 유한체라고 할 때, $\left\{ E : F \right\} = [ E : F ]$ 면 $E$ 를 $F$ 의 가분확대체라 한다. $f ( \alpha )$ 가 $F$ 의 가분확대체면 $\alpha \in \overline{F}$ 가 $F$ 상에서 가분이라 한다. $f(x)$ 의 모든 영이 $F$ 상에서</description>
    </item>
    
    <item>
      <title>확률과정론에서 상태의 유형</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-state-in-stochastic-process/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-state-in-stochastic-process/</guid>
      <description>정의 $i,j$ 를 스테이트라고 하자. $p_{ij}^{ ( n ) } &amp;gt; 0$ 를 만족하는 $n \ge 0$ 이 존재하면 $j$ 는 $i$ 로부터 억세서블Accessible하다고 한다. $i$ 와 $j$ 가 서로 억세서블하면 커뮤니케이트Cummunicate하다고 한다. 커뮤니케이트한 스테이트들의 집합 중 가장 큰 것을 클래스Class라고 한다. 두 스테이트가 커뮤니케이트하면 하나의 클래스 안에</description>
    </item>
    
    <item>
      <title>1계 상미분방정식의 초기값 문제에 대한 솔루션의 존재성과 유일성</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-existence-uniqueness-theorem-for-first-order-ordinary-differential-equation/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-existence-uniqueness-theorem-for-first-order-ordinary-differential-equation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정리 $E$가 $\mathbb{R}^{n}$에서 열린집합이고 $f \in C^{1} (E)$와 $\phi_{0} \in E$에 대해 아래와 같은 초기값 문제가 주어졌다고 하자. 그러면 어떤 $[-h,h]$ 에서 주어진 초기값 문제의 솔루션 $\phi (t)$ 은 유일하게 존재한다. 유클리드 공간 $\mathbb{R}^{n}$ 의 볼을 $B \left( \mathbb{x}_{0} ; d \right) := \left\{ \mathbb{x} \in \mathbb{R}^{n} \mid | \mathbb{x}_{0} - \mathbb{x} | &amp;lt; d \right\}$, $B</description>
    </item>
    
    <item>
      <title>로드리게스 공식</title>
      <link>https://freshrimpsushi.github.io/posts/rodrigues-formula/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rodrigues-formula/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **로드리게스 공식$(\mathrm{Rodrigues\ formula})$ $$ P_l(x)=\dfrac{1}{2^l l!} \dfrac{d^l}{dx^l}(x^2-1)^l $$ 이 글 에서 르장드르 미분 방정식의 해가 멱급수 꼴이라고 가정하고 풀어서 구한 해를 르장드르 다항식이라 했다. 각 $l$에 대한 정확한 드장드르 다항식을 얻는 방법이 있는데 그게 로드리게스 공식이다. 로드리게스 공식이</description>
    </item>
    
    <item>
      <title>채프만-콜모고로프 방정식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-chapman-kolmogorov-equation/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-chapman-kolmogorov-equation/</guid>
      <description>정리 $$ \displaystyle { p }_{ ij }^{ (n+m) } =\sum _{ k } { { p } _{ ik }^{ (n) } { p } _{ kj }^{ (m) } } $$ 설명 스테이트 $i$ 에서 $j$ 로 갈 때까지 걸리는 $n+m$ 의 스텝을 $n$ 과 $m$ 으로 쪼개어 표현할 수 있다는 뜻이다. 굳이 증명하지 않고 직관적으로 생각해봐도 $i$ 부터 $k$ 까지 $n$ 번 걸리는 확률과 $k$ 에서 $j$ 까지 $m$ 번 걸리는 확률을 생각해보면 $i$ 에서 $k$ 를 거쳐 $j$ 까지 갈 확률일테고, 모든 상태 $k$ 에</description>
    </item>
    
    <item>
      <title>국소 립시츠 조건</title>
      <link>https://freshrimpsushi.github.io/posts/local-lipschitz-condition/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/local-lipschitz-condition/</guid>
      <description>정의 $E$ 가 $\mathbb{R}^{n}$ 에서 오픈이고 $\mathbf{f} : E \to \mathbb{R}^{n}$ 이라고 하자. 모든 $\mathbf{x} _{0} \in E$ 에 대해 $B \left( \mathbf{x} _{0} ; \varepsilon \right) \subset E$ 를 만족하는 $\varepsilon &amp;gt; 0$ 과 모든 $\mathbf{x} , \mathbf{y} \in B \left( \mathbf{x} _{0} ; \varepsilon \right)$ 에 대해 $| \mathbf{f} ( \mathbf{x} ) - \mathbf{f} ( \mathbf{y} ) | \le K | \mathbf{x} - \mathbf{y} |$ 를 만족하는 $K &amp;gt;0$ 가 존재하면 $\mathbf{f}$ 가 $E$ 에서 로컬리 립시츠Locally Lipshitz라 한다. 이떄 다음과 같은 관계가 성립한다. 강한 립시츠 조건 $\implies$ 립시</description>
    </item>
    
    <item>
      <title>마코프 체인</title>
      <link>https://freshrimpsushi.github.io/posts/mc-markov-chain/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mc-markov-chain/</guid>
      <description>정의 $p_{ij}:= p \left( X_{n+1} = j \mid X_{n} = i \right)$ 을 전이 확률Transition Probability이라 하며 현재 상태를 의미하는 $i$ 를 소스 스테이트Source State , 목표 상태를 의미하는 $j$ 를 타겟 스테이트Target State라고 한다. $k$ 스텝 뒤의 전이 확률은 $p_{ij}^{(k)}: = p \left( X_{n+k} = j \mid X_{n} = i \right)$ 과 같이 나타낸다. 확률과정 $\left\{ X_{n} \right\}$ 이 다음을 만족하면 마코프 체</description>
    </item>
    
    <item>
      <title>피카드 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/picards-method/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/picards-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정리 $E$가 $\mathbb{R}^{n}$에서 오픈이고 $\mathbb{f} \in C^{1} (E)$에 대해 아래와 같은 초기값 문제가 주어졌다고 하자. $$ \begin{cases} \dot{ \phi } = \mathbb{f} ( \phi ) \\ \phi (0) = \phi_{0} \end{cases} $$ 함수열 $\left\{ \mathbb{u}_{k} (t) \right\} _{ k =0}^{ \infty }$을 아래와 같이 정의하자. $$ \begin{cases} \mathbb{u}_{0} (t) = \phi_{0} \\ \displaystyle \mathbb{u}_{k+1} (t) = \phi_{0} + \int_{0}^{t} \mathbb{f} \left( \mathbb{u}_{k} (s) \right) ds \end{cases} $$ 그러면 연속함수</description>
    </item>
    
    <item>
      <title>르장드르 미분 방정식의 급수해: 르장드르 다항식</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-legendre-differential-equation-and-legendre-polynomial/</link>
      <pubDate>Mon, 11 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-legendre-differential-equation-and-legendre-polynomial/</guid>
      <description>정의1 다음의 미분방정식을 르장드르Legendre 미분방정식이라 한다. $$ (1-x^2)\dfrac{d^2 y}{dx^2} -2x\dfrac{dy}{dx}+l(l+1) y=0 $$ 르장드르 미분방정식의 해를 르장드르 다항식이라 하고 흔히 $P_{l}(x)$로 표기한다. 처음 몇 개의 $l$에 따른 르장드르 다항식은 다음과 같다. $$ \begin{align*} P_0(x) =&amp;amp; 1 \\ P_1(x) =&amp;amp; x \\ P_2(x) =&amp;amp; \dfrac{1}{2}(3x^2-1) \\ P_3(x) =&amp;amp; \dfrac{1}{2}(5x^3-3x) \\ P_4(x) =&amp;amp; \dfrac{1}{8}(35x^4-30x^2+3) \\ P_5(x) =&amp;amp; \dfrac{1}{8}(63x^5-70x^3+15x) \\ \vdots&amp;amp; \end{align*} $$ 설명 르장드르 미분방정식은 다음과</description>
    </item>
    
    <item>
      <title>급수, 무한급수</title>
      <link>https://freshrimpsushi.github.io/posts/series/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series/</guid>
      <description>정의1 수열 $\left\{ a_{n} \right\}$이 주어졌다고 하자. 그리고 아래의 표기법을 정의하자. $$ \sum \limits_{n=p}^{q} a_{n} = a_{p} + a_{p+1} + \cdots + a_{q}\quad (p \le q) $$ $\left\{ a_{n} \right\}$의 부분합partial sum $s_{n}$을 다음과 같이 정의한다. $$ s_{n} = \sum \limits_{k=1}^{n} a_{k} $$ 그러면 $s_{n}$들의 수열 $\left\{ s_{n} \right\}$을 생각할 수 있다. 수열 $\left\{ s_{n} \right\}$</description>
    </item>
    
    <item>
      <title>라이프니츠 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-leibnizs-rule/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-leibnizs-rule/</guid>
      <description>정리 $$ \dfrac{d}{dx} (fg)=\dfrac{df}{dx}g+f\dfrac{dg}{dx} $$ $$ \begin{align*} \dfrac{d^n}{dx^n}(fg)&amp;amp;=\sum \limits_{k=0}^{n}\frac{n!}{(n-k)!k!}\dfrac{d^{n-k}f}{dx^{n-k}}\dfrac{d^k g}{dx^k} \\ &amp;amp;=\sum \limits_{k=0}^{n}{}_{n}\mathrm{C}_k \dfrac{d^{n-k}f}{dx^{n-k}}\dfrac{d^k g}{dx^k} \\ &amp;amp;=\sum \limits_{k=0}^{n} \binom{n}{k} \dfrac{d^{n-k}f}{dx^{n-k}}\dfrac{d^k g}{dx^k} \end{align*} $$ 설명 라이프니츠 규칙Leibniz&amp;rsquo;s rule이라고도 한다. 첫번째 식은 미분의 곱의 법칙 혹은 곱의 규칙이라고 잘 알려진 식이다. 두 함수의 곱을 한 번 미분했을 때의 결과를 쉽게 표현한 것이다. 여기서 좀 더 일반화하여 $n$번 미분했을 때의 결과를 나타내는 것이 아래의 식이다.</description>
    </item>
    
    <item>
      <title>확률과정이란?</title>
      <link>https://freshrimpsushi.github.io/posts/stochastic-process/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stochastic-process/</guid>
      <description>정의 확률변수 $X: \Omega \to E$ 의 공역을 상태공간이라 한다. 확률변수의 집합 $\left\{ X_{t} \mid t \in [ 0 , \infty ) \right\}$ 을 연속적 확률과정이라 한다. 확률변수의 수열 $\left\{ X_{n} \mid n = 0, 1, 2, \cdots \right\}$ 을 이산적 확률과정이라 한다. 설명 확률과정은 과정Process이라는 단어 때문에 이해하기 어려운, 전형적으로 말이 어려워서 어려운 개념이다. &amp;lsquo;프로세스&amp;rsq</description>
    </item>
    
    <item>
      <title>맵으로 표현되는 동역학계와 고정점</title>
      <link>https://freshrimpsushi.github.io/posts/dynamic-system-map-fixed-point/</link>
      <pubDate>Sat, 09 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamic-system-map-fixed-point/</guid>
      <description>정의1 정의역과 공역이 같은 함수 $f : X \to X$ 를 맵Map이라고 한다. $f$ 를 $k$ 번 합성한 맵을 $f^{k}$ 와 같이 나타낸다. 2. $f(p) = p$ 를 만족하는 $p \in X$ 를 고정점Fixed Point이라고 한다. 모든 $x \in N_{ \epsilon } ( p )$ 에 대해 $\displaystyle \lim_{k \to \infty} f^{k} (x) = p$ 를 만족하는 $\epsilon &amp;gt; 0$ 이 존재하면 고정점 $p$ 를 싱크Sink라 한다. $p$ 를 제외한 모든 $x \in N_{\epsilon } (p)$ 에 대해 $f^{ \infty } (x) \notin N_{\epsilon</description>
    </item>
    
    <item>
      <title>델 연산자가 두 번 들어간 수식, 2계 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/second-derivative-with-del-operator/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/second-derivative-with-del-operator/</guid>
      <description>$T$를 스칼라 함수, $\mathbf{A}$를 벡터 함수라고하자. 그래디언트의 다이벌전스: $\nabla \cdot (\nabla T) = \dfrac{\partial^{2} T}{\partial x^{2}} + \dfrac{\partial ^{2} T} {\partial y^{2}} + \dfrac{\partial ^{2} T}{\partial z^{2}}$ 그래디언트의 컬: $\nabla \times (\nabla T)=0$ 다이벌전스의 그래디언트: $\nabla (\nabla \cdot \mathbf{A} )$ 컬의 다이벌전스: $\nabla \cdot (\nabla \times \mathbf{A})=0$ 컬의 컬: $\nabla \times (\nabla \times \mathbf{A})=\nabla ( \nabla \cdot \mathbf{A}) - \nabla ^{2} \mathbf{A}$ 설명 그래디언트와 컬의 결과가 벡터이고, 다이벌전스의 결과가 스</description>
    </item>
    
    <item>
      <title>헤비사이드 계단 함수를 미분하면 디랙 델타 함수가 됨을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/derivative-of-heaviside-function-is-dirac-delta-function/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivative-of-heaviside-function-is-dirac-delta-function/</guid>
      <description>정리 헤비사이드 계단 함수의 도함수는 디랙 델타 함수이다. $$ \dfrac{dH}{dx}=\delta (x) $$ 이때 $H=H(x)$는 헤비사이드 계단 함수Heaviside step function 혹은 단위 계단 함수unit step function $$ H(x)=\begin{cases} 1 &amp;amp; x&amp;gt;0 \\ 0 &amp;amp; x \le 0 \end{cases} $$ 디랙 델타 함수 아래의 두 조건을 만족하는 함수를 디랙 델타 함수라고 한다. $$ \begin{equation} \delta (x) = \begin{cases} 0, &amp;amp; x\neq 0 \\ \infty , &amp;amp; x=0 \end{cases} \label{condition1} \end{equation} $$ $$ \begin{equation} \int_{-\infty}^{\infty}{\delta (x) dx}=1 \label{condition2} \end{equation} $$ 증명 $\d</description>
    </item>
    
    <item>
      <title>호스머-렘쇼 적합도 검정</title>
      <link>https://freshrimpsushi.github.io/posts/hosmer-lemeshow-gof-test/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hosmer-lemeshow-gof-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 로지스틱 회귀분석R 에서 호스머-렘쇼 적합도 검정 하는 법 로지스틱 회귀분석으로 얻은 모형을 $M$ 이라고 하자. $H_{0}$ : $M$ 은 적합하다. $H_{1}$ : $M$ 은 적합하지 않다. 호스머-렘쇼 적합도 검정은 로지스틱 회귀모형의 적합성을 판별하는 대표적인 방법이다.아주 단순한 테스트지만 귀무가설과 대립가설이 헷갈</description>
    </item>
    
    <item>
      <title>최소분열체</title>
      <link>https://freshrimpsushi.github.io/posts/splitting-field-in-abstract-algebra/</link>
      <pubDate>Thu, 07 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/splitting-field-in-abstract-algebra/</guid>
      <description>정의 1 $F \le E$ 라고 하자. $f(x) \in F [ x ]$ 가 $E [ x ]$ 의 일차항들로 인수분해되면 $f(x)$ 가 $E$ 에서 분열된다고 한다. $\left\{ f_{i} (x) \mid i \in I \right\} \subset F [ x ]$ 에 대해 모든 $f_{i} (x)$ 들의 영을 포함하고 $E$ 가 $\overline{F}$ 의 가장 작은 부분체가 될 때 $E$ 를 $F$ 상에서 $\left\{ f_{i} (x) \mid i \in I \right\}$ 의 최소분열체라 한다. 예시 말이 어려우므로 예시를 통해 개념적으로 이해해보자. 유리수체 $\mathbb{Q}$ 에 대해 $( x^4 - 5</description>
    </item>
    
    <item>
      <title>R 에서 로지스틱 회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-result-of-logistic-regression-in-r/</link>
      <pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-result-of-logistic-regression-in-r/</guid>
      <description>실습 내장데이터 turnout 데이터를 불러와보자. turnout는 1992년 미국 총선에 대한 데이터로써, race(인종), 연령(age), 교육수준(educate), income(수입)에 따른 vote(투표여부)를 파악할 수 있다. 이 데이터는 투표를 했느냐 안 했느냐하는 종속변수에 관심이 있으므로 로지스틱 회귀분석을 사용할 수 있다</description>
    </item>
    
    <item>
      <title>체의 자기동형사상</title>
      <link>https://freshrimpsushi.github.io/posts/automorphism-of-field/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/automorphism-of-field/</guid>
      <description>정의 1 $E$ 가 $F$ 의 확대체라고 하자. 체 $E$ 에 대해 동형사상 $\sigma : E \to E$ 을 자기동형사상Automorphism이라 하고, $E$ 의 자기동형사상의 집합을 $\text{Auto} (E)$ 와 같이 나타낸다. $\sigma \in \text{Auto} (E)$ 에 대해 $\sigma ( a ) = a$ 면 $\sigma$ 가 고정된 $a$ 를 남긴다고 한다. $S \subset \text{Auto} (E)$ 라고 하자. 모든 $a \in F$ 에 대해 모든 $\sigma \in S$ 가 고정된 $a$ 를 남기면 $S$ 가 고정된 부분체 $F$ 를 남긴다고 한다</description>
    </item>
    
    <item>
      <title>R 에서 두 배열의 성분 비교하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-compare-array-in-r/</link>
      <pubDate>Mon, 04 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-compare-array-in-r/</guid>
      <description>개요 R 은 데이터의 형태, 구조보단 그 내용에 관심이 많은 분야에서 많이 쓰이므로 그 비교 역시 유용하다. 포함관계 (전혀 중요하지는 않지만, 예제에서 A는 삼각수 $\displaystyle {{n(n+1)} \over {2}}$ 이고 B는 사각수 $m^2$ 를 나타낸다.) 이항연산자 %in% 을 사용해 두 배열을 비교해보면 A의 성분 중 B에도 속하는 성분에 대해 참, 그렇지 않으면 거짓으로 반환해준다. 다음과 같이 문자열을</description>
    </item>
    
    <item>
      <title>변수분리법을 사용하여 원통 좌표계에서 제트축에 무관한 라플라스 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-laplace-equation-with-cylindrical-symmetry-in-cylindrical-coordinates-using-separation-of-variables/</link>
      <pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-laplace-equation-with-cylindrical-symmetry-in-cylindrical-coordinates-using-separation-of-variables/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 원기둥 좌표계에서 원통 대칭$(\mathrm{ cylindrical\ symmetry})$이 있을 때의 라플라스 방정식의 일반해는$V(s,\phi) = A_0 \ln s +B_0 +\sum \limits _{k=1} ^\infty ( A_k s^k ++ B_k s^{-k} )( C_k\cos k\phi + D_k\sin k\phi)$ 0. 전위를 구할 때 경계조건$(\mathrm{boundary\ condition})$이 원통</description>
    </item>
    
    <item>
      <title>켤레 동형사상 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conjugation-isomorphism-theorem/</link>
      <pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conjugation-isomorphism-theorem/</guid>
      <description>정의 1 체 $F$ 에 대해 $\alpha$ 가 $F$ 상에서 대수적이라고 하자. 최대차항의 계수가 $1$ 이고 $p( \alpha ) = 0$ 를 만족하는 $p(x) \in F [ x ]$ 를 $\alpha$ 에 대한 $F$ 상에서의 기약 다항함수라 하고 $\text{irr} ( \alpha , F) = p(x)$ 와 같이 나타낸다. $\text{irr} ( \alpha , F)$ 의 최대차항의 차수를 $F$ 상에서 $\alpha$ 의 차수 라 하고 $\deg ( \alpha , F )$ 와 같이 나타낸다. $F$ 의 대수적 확대체 $E$ 에 대해 $\text{irr} ( \alpha , F) = \text{irr} ( \beta , F)$ 라고 하면</description>
    </item>
    
    <item>
      <title>R 에서 데이터 프레임의 열과 행 이름 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-row-and-column-name-of-dataframe-in-r/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-row-and-column-name-of-dataframe-in-r/</guid>
      <description>개요 R 에서 데이터 프레임을 이용해 복잡한 코드를 짜다보면 디폴트로 정해주는 열 이름들이 헷갈려서 바꿔줘야 할 상황이 있다. names() 예제로써 위 데이터 프레임을 보면 별 다른 언급이 없으면 V1, V2, V3처럼 무성의하고 구분하기 힘든 열 이름이 주어진다. 여기에 names() 함수를 씌우면 열 이름을 반환하며, 반대로 거기에 바로 문자열을 넣어 열 이름을 바꿀 수 있다. 그냥 단순</description>
    </item>
    
    <item>
      <title>변수분리법을 사용한 구좌표계에서의 방위각에 무관한 라플라스 방정식 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-laplace-equation-with-azimuthal-symmetry-in-spherical-coordinates-using-separation-of-variables/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-laplace-equation-with-azimuthal-symmetry-in-spherical-coordinates-using-separation-of-variables/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 구면 좌표계에서 방위각 대칭$(\mathrm{ azimuthal\ symmetry})$이 있을 때의 라플라스 방정식의 일반해는$V(r,\theta) = \sum \limits_{l=0} ^\infty \left( A_l r^l + \dfrac{B_l}{r^{l+1} } \right) P_l(\cos \theta)$ ** ** 0. 전위를 구할 때 경계 조건($\mathrm{boundary\ condition}$)이 구면좌표계로</description>
    </item>
    
    <item>
      <title>유클리드 정역</title>
      <link>https://freshrimpsushi.github.io/posts/ed-euclidean-domain/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ed-euclidean-domain/</guid>
      <description>정의 1 정역 $D$ 에서 다음의 두 조건을 만족하는 유클리드 놈Euclidean Norm $\nu : D \setminus \left\{ 0 \right\} \to \mathbb{N}_{0}$ 이 존재하면 $D$ 를 유클리드 정역이라 한다. (i): 모든 $a,b \in D (b \ne 0 )$ 에 대해 $$ a = bq + r $$ 을 만족하는 $q$ 와 $r$ 이 존재한다. 이 때 $r = 0$ 이거나 $\nu (r) &amp;lt; \nu (b)$ 둘 중 하나여야한다. (ii): 모든 $a,b \in D (b \ne 0 )$ 에 대해 $\nu ( a ) \le \nu ( ab )$ $\mathbb{N}_{0}$ 은 자연수의 집합에 $0$ 을</description>
    </item>
    
    <item>
      <title>로지스틱 회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/logistic-regression/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logistic-regression/</guid>
      <description>빌드업 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 $Y$ 가 질적변수, 그 중에서도 계급이 두개뿐인 경우가 있을 수 있다. 예를 들어 남자와 여자, 성공과 실패, 양성과 음성, $0$ 과 $1$ 등이 있고, 편의상 그냥 $Y=0$ 혹은 $Y=1$ 이라고 하자. 이렇게 종속변수가 이항적인 경우 관심사는 &amp;lsquo;독립변수 $ X_{1} , \cdots X_{p}$ 들을 보았을 때 $Y$ 가 무엇인지&amp;rsquo;일 것</description>
    </item>
    
    <item>
      <title>유일 인수분해 정역</title>
      <link>https://freshrimpsushi.github.io/posts/ufd-unique-factorization-domain/</link>
      <pubDate>Wed, 30 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ufd-unique-factorization-domain/</guid>
      <description>정의 1 정역 $D$ 의 $0$ 도 아니고 단원도 아닌 모든 원소에 대한 유한 인수분해가 유일하게 존재하면 $D$ 를 유일 인수분해 정역UFD이라 한다. 유일 인수분해 정역 $D$ 의 $a_{1} , \cdots , a_{n}$ 에 대해 $d \mid a_{i}$ 이고 $a_{i}$ 의 모든 약수가 $d$ 를 나누면 $d$ 를 $a_{1} , \cdots , a_{n}$ 의 최대공약소Greatest Common Divisor라 하고 $\gcd$ 로 쓴다. 유일 인수분해 정역 $D$ 의 어떤 다항함수를 $f(x) := a_{0} +</description>
    </item>
    
    <item>
      <title>치환을 이용한 비동차 오일러 미분 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-nonhomogenuous-euler-differential-equations-using-substitutions/</link>
      <pubDate>Wed, 30 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-nonhomogenuous-euler-differential-equations-using-substitutions/</guid>
      <description>정의 다음과 같이 주어진 미분 방정식을 오일러 미분 방정식Euler differential equation이라 한다. $$ \begin{align} &amp;amp;&amp;amp; a_2 x^2 \dfrac{d^2 y}{d x^2} + a_1 x \dfrac{dy}{dx} + a_0 y &amp;amp;= f(x) \label{eq1} \\ \mathrm{or}&amp;amp;&amp;amp; a_2 x^2 y&#39;&#39; + a_1 x y&#39; +a_0 y &amp;amp;= f(x) \nonumber \\ \mathrm{or}&amp;amp;&amp;amp; x^2 y&#39;&#39; + \alpha x y&#39; + \beta y &amp;amp;= f(x) \nonumber \end{align} $$ 설명 오일러-코시 방정식Euler-Cauchy equation이라고도 부른다. $f(x)=0$인 동차방정식 꼴이라면 비교</description>
    </item>
    
    <item>
      <title>통계적 분석에서의 변수 선택 기준</title>
      <link>https://freshrimpsushi.github.io/posts/variable-selection-criterion-in-statistical-analysis/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/variable-selection-criterion-in-statistical-analysis/</guid>
      <description>개요 변수를 선택하는 문제는 필연적으로 분석자의 주관이 개입할 수 밖에 없지만, 가능한 한 객관적인 결론을 내릴 수 있게 도와주는 수치적인 지표가 필요했다. 그런 값들을 계산해낼 수 있다면 변수 선택 절차를 언제 멈추느냐에 대한 명쾌한 해답이 된다. 다만 이 기준에도 여러가지 종류가 있으며, 기준을 다르게 적용하면 결과 역시 달라질 수 있다. 지표 1 설명력 R-squared</description>
    </item>
    
    <item>
      <title>주 아이디얼 정역</title>
      <link>https://freshrimpsushi.github.io/posts/pid-principal-ideal-domain/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pid-principal-ideal-domain/</guid>
      <description>정의 1 가환환 $R$ 이 단위원 $1$ 을 가진다고 하자. $a,b \in R$ 에 대해 $b=ac$ 를 만족하는 $c \in R$ 이 존재하면 $a$ 가 $b$ 를 나눈다Divide 혹은 $a$ 가 $b$ 의 인수Factor라 하고 $a \mid b$ 와 같이 나타낸다. 정역 $D$ 의 $p \ne 0$ 가 단원이 아니라고 하자. $a \mid b$ 이고 $b \mid a$ 면 $a,b$ 가 연합Associates이라 한다. $\forall a,b \in D$ 와 $p=ab$ 에 대해 $a$ 나 $b$ 중 하나가 단원이면 $p$ 를 기</description>
    </item>
    
    <item>
      <title>소수를 3으로 나눈 나머지가 1이 되는 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessity-and-sufficiency-for-prime-number-is-congruent-to-1-mod-4/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessity-and-sufficiency-for-prime-number-is-congruent-to-1-mod-4/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소수를 4로 나눈 나머지가 1이 되는 필요충분조건 $p \ne 3$ 이 소수라고 하자. $p \equiv 1 \pmod{3} $$ \iff$ 어떤 $a,b \in \mathbb{Z}$ 에 대해 $p = a^2 - ab + b^2$ $p=3$ 은 제외했지만, 사실 $ 3= 2^2 - 2 \cdot 1 + 1^2$ 이므로 정리에 포함되어도 큰 상관은 없다. 예를들어 $13 \equiv 1 \pmod{4}$ 는 $13 = 1 - 4 + 16 = 1^2 - 1 \cdot 4 + 4^2$ $37 \equiv 1 \pmod{4}$ 는 $37 = 9 -21 + 49 = 3^2</description>
    </item>
    
    <item>
      <title>뇌터 환</title>
      <link>https://freshrimpsushi.github.io/posts/noetherian-ring/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/noetherian-ring/</guid>
      <description>정의 $N$ 을 환이라고 하자. $N$ 의 아이디얼들이 $S_{1} \le S_{2} \le \cdots$ 을 만족할 때 이를 오름사슬Ascending Chain이라 한다. 오름사슬 $\left\{ S_{i} \right\}_{i \in \mathbb{N} }$ 에 대해 $S_{n} = S_{n+1} = \cdots$ 을 만족하는 $n \in \mathbb{n}$ 이 존재하면 정상적Stationary이라 한다. 다시 말해 정상적 오름사슬에선 아이디얼이 어느 순간부터 더 이상 커지지 않는다. 모든 오름사슬이 정상적인 환을</description>
    </item>
    
    <item>
      <title>소수를 4로 나눈 나머지가 1이 되는 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessity-and-sufficiency-for-prime-number-is-congruent-to-1-mod-3/</link>
      <pubDate>Fri, 25 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessity-and-sufficiency-for-prime-number-is-congruent-to-1-mod-3/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소수를 3으로 나눈 나머지가 1이 되는 필요충분조건 $p \ne 2$ 가 소수라고 하자. $p \equiv 1 \pmod{4} $$ \iff$ 어떤 $a,b \in \mathbb{Z}$ 에 대해 $p = a^2 + b^2$ $p=2$ 는 제외했지만, 사실 $ 2= 1^2 + 1^2$ 이므로 정리에 포함되어도 큰 상관은 없다. 예를들어$13 \equiv 1 \pmod{4}$ 는 $13 = 4 + 9 = 2^2 + 3^2 $$ 37 \equiv 1 \pmod{4}$ 는 $37 = 1 + 36 = 1^2 + 6^2 $$ 61 \equiv 1 \pmod{4}$ 는 $61</description>
    </item>
    
    <item>
      <title>통계적 분석에서의 변수 선택 절차</title>
      <link>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistical-analysis/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistical-analysis/</guid>
      <description>빌드업 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 독립변수는 $p$ 개로, 회귀분석의 여러가지 가정들을 잘 만족하고 다중공선성이 없으며 설명력이 높다면 좋을 것이다. 물론 정보라는 것은 많으면 많을수록 좋지만, 지나치게 많은 데이터로 얻은 회귀모형은 사용하는데에도 많은 데이터를 요구한다. 그래서 가능하다면 사용하는 독립변수를 줄여</description>
    </item>
    
    <item>
      <title>리눅스 포트란 컴파일 후 aout 실행법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-execute-aout-file-after-fortran-complie/</link>
      <pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-execute-aout-file-after-fortran-complie/</guid>
      <description>가이드 확장자가 .f90인 파일 exameple.f90 을 컴파일하려면 콘솔창에서 gfortran example.f90 을 입력하면 된다. 실행하고 나면 같은 디렉터리에 a.out 라는 파일이 생긴다. 콘솔창에서 ./a.out 을 입력하면 콘솔창에서 프로그램이 실행되는 것을 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>적분가능성은 두 함수의 곱셈에서 보존된다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-multiplication-of-two-riemann-stieltjes-integrable-functions-is-riemann-stieltjes-integrable/</link>
      <pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-multiplication-of-two-riemann-stieltjes-integrable-functions-is-riemann-stieltjes-integrable/</guid>
      <description>정리1 두 함수 $f$, $g$가 구간 $[a,b]$에서 리만(-스틸체스) 적분가능하면 $fg$도 적분가능하다. 증명 $f, g$가 적분가능하다고 하자. 적분은 선형성이 있으므로 $-g,\ f+g,\ f-g$도 적분가능하다. 함수 $\phi$를 $\phi(x)=x^2$라고 하자. 그러면 $\phi$는 전영역에서 연속이다. 적분가능성은 연속함수와의 합</description>
    </item>
    
    <item>
      <title>R 에서 주성분회귀분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</guid>
      <description>개요 주성분회귀분석PCR 이란 주성분분석과 다중회귀분석을 합친 것으로, 주성분분석을 통해 얻은 주성분을 새로운 독립변수로 둔 회귀분석을 말한다. 사실 통계학의 관점에서 주성분분석 그 자체는 별 필요가 없고, 보통 회귀분석에 쓰일 때나 의미가 있다. 실습 (다중공선성을 찾아내는 법에 이어서) 주성분을 만들어내는 과정은 행렬분해를 포함한 복잡한</description>
    </item>
    
    <item>
      <title>소체</title>
      <link>https://freshrimpsushi.github.io/posts/prime-field-in-abstract-algebra/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prime-field-in-abstract-algebra/</guid>
      <description>빌드업 환 $R$ 의 모든 원소 $r$ 에 대해 $n \cdot r = 0$ 을 만족하는 가장 큰 자연수 $n$ 을 $R$ 의 표수Characteristic라 정의한다. 만약 그런 자연수가 존재하지 많으면 $0$ 을 $R$ 의 표수로 정의한다. 곱셈에 대한 항등원, 즉 단위원을 갖는 환은 다음과 같은 성질을 가진다. [1]: 단위원을 갖는 $R$ 의 표수가 $n&amp;gt;1$ 이면 $R$ 은 $\mathbb{Z}_{n}$ 과 동형인 부분환을 가진다. [2]: 단위원을 갖는</description>
    </item>
    
    <item>
      <title>적분가능성은 연속함수와의 합성에서 보존된다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-riemann-stieltjes-integrability-is-preserved-under-composition-by-continuous-function/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-riemann-stieltjes-integrability-is-preserved-under-composition-by-continuous-function/</guid>
      <description>해당 글은 리만-스틸체스 적분을 기준으로 작성되었다. $\alpha=\alpha(x)=x$로 두면 리만 적분과 같다. 정리1 함수 $f$가 구간 $[a,b]$에서 리만(-스틸체스) 적분가능하고 $m \le f \le M$라고 하자. $\phi$를 구간 $[m,M]$에서 연속인 함수라고 하자. 함수 $h$를 $h=\phi \circ f$라고 하자. 그러면 $h$</description>
    </item>
    
    <item>
      <title>3대 작도 불능 문제 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-impossibility-of-construction/</link>
      <pubDate>Mon, 21 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-impossibility-of-construction/</guid>
      <description>정리 1 다음 세 가지 작도는 불가능하다. [1] Squaring the circle: 주어진 사각형과 같은 넓이의 원을 작도하라. [2] Doubling the cube: 주어진 정육면체의 부피가 두 배가 되는 정육면체를 작도하라. [3] Trisecting the angle: 주어진 각을 삼등분하라. 반증 오랫동안 기하학의 문제였으나 대수학으로써 풀린다는 것이 실로 경이롭다. 기본적으로 아래 보조정리의 대우명제를 사용한다. 작도가능수의 성질:</description>
    </item>
    
    <item>
      <title>단조함수는 리만(-스틸체스) 적분가능하다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-monotone-function-is-riemann-stieltjes-integrable/</link>
      <pubDate>Mon, 21 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-monotone-function-is-riemann-stieltjes-integrable/</guid>
      <description>리만적분에 대해서 함수 $f$가 $[a,b]$에서 단조라고 하자. 그러면 $f$는 리만적분가능하다. 증명 $f$가 단조증가함수1라고 가정하자. $\epsilon &amp;gt;0$이 주어졌다고 하자. 구간 $[a,b]$의 분할 $P= \left\{ x_{i} : a=x_{0} &amp;lt; x_{1} &amp;lt; x_{2} &amp;lt; \cdots &amp;lt; x_{n}=b \right\}$가 임의의 자연수 $n$에 대해서 다음을 만족하도록 주어졌다고 하자. $$ \Delta x_i =</description>
    </item>
    
    <item>
      <title>통계학에서의 주성분분석</title>
      <link>https://freshrimpsushi.github.io/posts/pca-principal-components-analysis-in-statistics/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pca-principal-components-analysis-in-statistics/</guid>
      <description>개요 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자. 주성분분석, 영어 약어로 PCA는 쉽게 말해 양적변수들이 제대로 독립이 되도록 &amp;lsquo;재구성&amp;rsquo;해서 분석하는 방법이다. 다변량 데이터의 분석이라는 관점으로 보자면 보다 적은 변수로 현상을 설명하기 위한 &amp;lsquo;차원축소&amp;rsquo;로써의 의미가 있다. 주성</description>
    </item>
    
    <item>
      <title>연속함수는 리만(-스틸체스) 적분가능하다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-continuous-function-is-riemann-stieltjes-integrable/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-continuous-function-is-riemann-stieltjes-integrable/</guid>
      <description>해당 글은 리만-스틸체스 적분을 기준으로 작성되었다. $\alpha=\alpha(x)=x$로 두면 리만 적분과 같다. 정리 함수 $f$가 $[a,b]$에서 연속이면 $[a,b]$에서 리만(-스틸체스) 적분가능하다. 증명 $\epsilon &amp;gt;0$이 주어졌다고 하자. 그리고 $\left[ \alpha (b) - \alpha (a) \right] \eta &amp;lt; \epsilon$을 만족하는 $\eta</description>
    </item>
    
    <item>
      <title>작도가능수</title>
      <link>https://freshrimpsushi.github.io/posts/construct-number-in-abstract-algebra/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/construct-number-in-abstract-algebra/</guid>
      <description>정의 $1$ 을 포함해 유한번의 사칙연산과 제곱근을 취함으로써 얻을 수 있는 수를 작도가능Constructible하다고 한다. 설명 작도가능이라는 것은 원래 고대 그리스의 논증 기하에서 논의되던 개념이었으나, 현대대수학을 동원하면 캠퍼스로 원을 그리고 자로 선을 그리는 과정이 딱히 필요 없어진다. 어떻게 이 연산들이 작도를 대신하는지 살펴보자.</description>
    </item>
    
    <item>
      <title>분산팽창인자 VIF</title>
      <link>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</guid>
      <description>정의 1 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 할 때 $i$ 번째 독립변수에 대한 다중회귀분석 $$X_{i} \leftarrow X_{1} , \cdots, X_{i-1} , X_{i+1} , \cdots, X_{p}$$ 의 중회귀계수를 $R_{i}^2$ 라고 두자. 다음을 $X_{i}$ 의 분산팽창인자Variance Inflation Factor라고 한다. $$\displaystyle \text{VIF}_{i}: = {{1} \over {1 - R_{i}^{2} }}$$ 설명 우선 다중공선성에 대해 읽어보는 것을 추천한다. VIF는 분산확대지수 로 번역되는 경우도 있는 것 같지만, 보통은 너</description>
    </item>
    
    <item>
      <title>전위의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/property-of-electric-potential/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/property-of-electric-potential/</guid>
      <description>설명1 전위의 기준점 전위의 정의는 다음과 같다. $$ V(\mathbf{r} ) \equiv - \int _\mathcal{O} ^{\mathbf{r}} \mathbf{E} \cdot d \mathbf{l} $$ 따라서 기준점 $\mathcal{O}$에 따라 그 값이 달라질 수 있다. 예를 들어 새로운 기준점 $\mathcal{O}&#39;$을 잡으면 다음과 같이 어떤 상수 $K$만큼 값의 차이가 생긴다. $$ \begin{align*} V&#39; (\mathbf{r} ) =&amp;amp; -\int _{\mathcal{O}&#39;}^\mathbf{r} \mathbf{E} \cdot d\mathbf{l} \\ =&amp;amp; -\int _{\mathcal{O}&#39;} ^\mathcal{O} \mathbf{E} \cdot d\mathbf{l} -\int_\mathcal{O} ^\mathbf{r} \mathbf{E} \cdot d \mathbf{l} \\ =&amp;amp; K + V( \mathbf{r} ) \end{align*}</description>
    </item>
    
    <item>
      <title>전위</title>
      <link>https://freshrimpsushi.github.io/posts/electric-potential/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/electric-potential/</guid>
      <description>설명1 전기장은 항상 컬(회전)이 $\mathbf{0}$인 특별한 벡터함수다. 이러한 특징으로부터 전기장 $\mathbf{E}$와 관련된 전위electric potential라는 스칼라함수를 도입한다. 전위는 $V$로 표기하며 전기장 $\mathbf{E}$와 아래의 관계가 성립한다. $$ \mathbf{E} = -\nabla V $$ 따라서 전위 $V$를</description>
    </item>
    
    <item>
      <title>추상대수의 용어로 표현된 대수학의 기본정리</title>
      <link>https://freshrimpsushi.github.io/posts/fundamental-theorem-of-algebra-in-terms-of-abstract-algebra/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fundamental-theorem-of-algebra-in-terms-of-abstract-algebra/</guid>
      <description>정의 1 체 $F$ 의 확대체를 $E$ 라고 하자. $F [ x ]$ 의 모든 다항함수가 $F$ 에서 영을 가지면 $F$ 를 대수적으로 닫혀있다Algebraically Closed고 한다. $\overline{ F_{E}} : = \left\{ \alpha \in E \mid \alpha \text{ is algebraic over } F \right\}$ 를 $E$ 에서 $F$ 의 대수적 폐포Algebraic Closure라 한다. 정리 [1]: $F$ 가 대수적으로 닫혀있다 $\iff$ 모든 $f(x) \in F [ x ]$ 는 $F [ x ]$ 의 $1$ 차항</description>
    </item>
    
    <item>
      <title>가우스의 이차상호 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gausss-law-of-quadratic-reciprocity/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gausss-law-of-quadratic-reciprocity/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 서로 다른 두 홀수 소수 $p , q $ 에 대해 (1) $$ \displaystyle \left( {{ q } \over { p }} \right) = \begin{cases} \left( {{ p } \over { q }} \right) &amp;amp; p \equiv 1 \pmod{4} \lor q \equiv 1 \pmod{4} \\ - \left( {{ p } \over { q }} \right) &amp;amp; p \equiv 3 \pmod{4} \land q \equiv 3 \pmod{4} \end{cases} $$ (2) $$ \displaystyle \left( {{ p } \over { q }} \right) \left( {{ q } \over { p }} \right) = (-1)^{ { {p-1} \over {2} }{ {q-1} \over {2} } } $$ (1)**과 (2) 는 표현만 다를 뿐 같은 말이다. 이</description>
    </item>
    
    <item>
      <title>다중공선성</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</guid>
      <description>정의 1 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.이 때 독립변수 $ X_{1} , \cdots, X_{p}$ 중에서 독립변수끼리 강한 상관관계를 가지면 다중공선성Multicollinearity이 있다고 한다 실습 애초에 독립변수끼리 종속적이라는 것 자체가 회귀분석의 가정에 위배되는 말이며, 실제로 수치적인 문제를 야기해 분석 결과를 신뢰할 수 없게 만든다. 데이</description>
    </item>
    
    <item>
      <title>전기장의 컬(회전)</title>
      <link>https://freshrimpsushi.github.io/posts/the-curl-of-electric-field/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-curl-of-electric-field/</guid>
      <description>정리 전기장의 컬(회전)은 항상 $\mathbf{0}$이다. $$ \nabla \times \mathbf{E} = \mathbf{0} $$ 증명1 점전하가 원점에 있는 특별한 경우의 결과로부터 일반적인 결과를 이끌어낼 것이다. 원점으로부터 거리가 $r$인 곳에서 점점하에 의한 전기장은 아래와 같다. $$ \mathbf{E}=\dfrac{1}{4 \pi \epsilon_0 } \dfrac{q}{r^2} \hat{\mathbf{r}} $$ 전기장을 점 $\mathbf{a}$에서부터 점 $\mathbf{b}$까지</description>
    </item>
    
    <item>
      <title>대수적 확대체</title>
      <link>https://freshrimpsushi.github.io/posts/algebraic-extension-field/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebraic-extension-field/</guid>
      <description>정의 1 $E$ 가 $F$ 의 확대체고 $n \in \mathbb{N}$ 이라 하자. $E$ 의 모든 원소가 $F$ 상에서 대수적 수면 $E$ 를 $F$ 의 대수적 확대체라 한다. $E$ 가 $F$ 상에서의 $n$ 차원 벡터 공간이면 $E$ 를 $F$ 상에서의 $n$ 차 유한확대체라 한다. $F$ 상에서의 유한확대체 $E$ 의 차수 를 $[ E : F ]$ 와 같이 나타낸다. 정리 $E$ 가 $F$ 의 유한확대체, $K$ 가 $E$ 의 유한확대체라고 하자. [1]: 유한확대체는 대수적 확대체</description>
    </item>
    
    <item>
      <title>오일러 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/eulers-criterion/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eulers-criterion/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소수 $p \ne 2$ 에 대해, $\displaystyle a^{{p-1} \over {2}} \equiv \left( {a \over p} \right) \pmod{p}$ $a$ 하나만 QR인지 NR인지 보고싶을 땐 무작정 계산해보면 그만이라는 말이다.물론 거듭제곱이 그렇게 만만한 작업은 아니지만 모든 수를 계산해보는 것보단 나을 것이다.증명 자체는 별로 어렵지 않지만 보조정리가 많이 쓰이기 때문에 어느정도 공부를 해둬</description>
    </item>
    
    <item>
      <title>적분꼴 가우스 법칙의 응용</title>
      <link>https://freshrimpsushi.github.io/posts/application-of-gauss-law-in-integral-form/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/application-of-gauss-law-in-integral-form/</guid>
      <description>설명1 가우스 법칙은 전기장을 매우 쉽게 계산할 수 있도록 해주지만 항상 그런 것은 아니다. 가우스 법칙 자체는 언제나 성립하지만, 수식적인 이점은 특정한 상황에서만 살릴 수 있다. 아래에서 설명하겠지만 가우스 법칙을 통해 전기장을 쉽게 계산하려면 특정 좌표계가 만드는 곡면에 대해서 전기장 $\mathbf{E}$의 크기가 일정하고, 방향은 수직이</description>
    </item>
    
    <item>
      <title>전기장의 다이벌전스(발산)</title>
      <link>https://freshrimpsushi.github.io/posts/the-divergence-of-electric-field/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-divergence-of-electric-field/</guid>
      <description>공식1 부피전하밀도가 $\rho$인 부피전하가 만드는 전기장 $\mathbf{E}$의 다이벌전스는 다음과 같다. $$ \nabla \cdot \mathbf{E} = \dfrac{1}{\epsilon_0} \rho ( \mathbf{r} ) $$ 설명 전기장의 다이벌전스는 가우스 법칙의 미분꼴이라 불리기도 한다. 양변을 적분하면 가우스 법칙의 적분꼴을 얻는다. 증명 부피전하가 만드는 전기장 $$ \mathbf{E}(\mathbf {r}) =\dfrac{1}{4\pi \epsilon_0} \int _\mathcal{V} \dfrac{\rho(\mathbf{r}^{\prime})}{\eta^2} \hat{\boldsymbol{\eta}} d\tau^{\prime} $$ 이때 $\boldsym</description>
    </item>
    
    <item>
      <title>전기장의 선속과 가우스 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/electric-flux-and-gausss-law/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/electric-flux-and-gausss-law/</guid>
      <description>정의1 면 $\mathcal S$를 지나는 전기장 $\mathbf{E}$의 선속flux을 다음과 같이 정의한다. $$ \Phi_E \equiv \int_{\mathcal S} \mathbf{E} \cdot d\mathbf{a} $$ 이제 $\mathcal{S}$를 어떤 닫힌 곡면이라고 하자. 닫힌 곡면 안의 총 전하량을 $Q_{\text{in}}$라고 하자. 그러면 다음의 식이 성립한다. $$ \oint_{\mathcal{S}} \mathbf{E} \cdot d\mathbf{a} = \frac{1}{\epsilon_{0}}Q_{\mathrm{in}} $$ 이를 가우스 법칙Gauss&#39; law이</description>
    </item>
    
    <item>
      <title>르장드르 기호의 곱셈적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-legendre-symbols-multiplicativity/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-legendre-symbols-multiplicativity/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $2$ 보다 큰 소수 $p$ 에 대해, $\displaystyle \left( { ab \over p } \right) = \left( { a \over p } \right) \left( { b \over p } \right) $ 정수론에서 $\displaystyle \left( {{x} \over {y}} \right)$ 는 분수가 아니라 르장드르 기호Legendre Symbol라 하며, 소수가 아닌 자연수에 대해 일반화하면 표기는 똑같이 쓰되 야코비 기호Jacobi Symbol라 한다. 르장드르 기</description>
    </item>
    
    <item>
      <title>분리벡터의 발산</title>
      <link>https://freshrimpsushi.github.io/posts/the-divergence-of-1r2/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-divergence-of-1r2/</guid>
      <description>공식 $\nabla \cdot \left( \dfrac{1}{r^2}\hat{ \mathbf{r} } \right) = 4\pi \delta^3(\mathbf{r})$ $\nabla \cdot \left( \dfrac{1}{\eta^2}\hat{ \boldsymbol{\eta} } \right) = 4\pi \delta^3(\boldsymbol{\eta})$ $\nabla^2 \left(\dfrac{1}{\eta} \right) =-4\pi \delta^3 ( \mathbf{r} )$ 설명 벡터 함수 $\mathbf{v} = \dfrac{1}{r^2}\hat{\mathbf{r}}$이 있다고 하자. 크기는 거리 제곱에 반비례하고 방향은 반지름 방향이다.이제부터 이 함수의 발산을 계산해보자. 구좌표계에서의 기울기 공식을 사용하면 $$ \nabla \cdot \mathbf{v} = \dfrac{1}{r^2}\dfrac{\partial}{\partial r}\left( r^2\dfrac{1}{r^2} \right) = \dfrac{1}{r^2}\dfrac{\partial}{\partial r}(1)=0 $$ 그런데</description>
    </item>
    
    <item>
      <title>추상대수학에서의 벡터 공간</title>
      <link>https://freshrimpsushi.github.io/posts/vector-space-in-abstract-algebra/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vector-space-in-abstract-algebra/</guid>
      <description>정의 1 체 $F$ 와 아벨군 $V$ 의 모든 $\alpha , \beta \in F$ 와 $x, y \in V$ 가 다음의 조건을 만족하면 $V$ 를 $F$ 상의 벡터 공간Vector Space이라고 한다. $F$ 의 원소를 스칼라Scalar, $V$ 의 원소를 벡터Vector라 한다. (i): $\alpha x \in V$ (ii): $\alpha ( \beta x) = ( \alpha \beta ) x$ (iii): $\alpha (x + y) = \alpha x + \alpha y$ (iv): $1 x = x$ 첨수집합 $I$ 에 대해 $\left\{ x_{i} \right\}_{i \in I} \subset V$ 이라고 하자. 어떤 $\left\{ \alpha_{i} \right\}_{</description>
    </item>
    
    <item>
      <title>비선형회귀분석: 회귀분석에서의 변수 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation-of-variables/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation-of-variables/</guid>
      <description>개요 1 회귀분석은 기본적으로 변수들간의 선형관계를 밝히는 방법이지만, 필요하다면 데이터를 선형으로 &amp;lsquo;펴서&amp;rsquo; 분석할 수 있다. 이는 본질적으로 종속변수를 독립변수의 비선형결합으로 설명하는 것이다. 실습 내장데이터 Pressure 데이터를 불러와보자. Pressure 데이터는 사실 통계적으로 분석할 필요는 없다. 이는 어디까지나 자연현상</description>
    </item>
    
    <item>
      <title>이차잉여와 비이차잉여</title>
      <link>https://freshrimpsushi.github.io/posts/quadratic-residue-and-quadratic-nonresidue/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quadratic-residue-and-quadratic-nonresidue/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소수 $p \ne 2$ 와 $a &amp;lt; p$ 에 대해 합동방정식 $x^{2} \equiv a \pmod{p}$ 의 해가 존재하면 $a$ 를 모듈로 $p$ 에 대한 **이차잉여(QR)**라 한다. $a$ 가 이차잉여가 아니면 **비이차잉여(NR)**라 한다. 쉽게 말해 이차잉여란 $\pmod{p}$에서 제곱근이 존재하는 수를 의미한다. 예를 들어 소수 $7$ 을 생각해</description>
    </item>
    
    <item>
      <title>쿨롱 법칙과 전기장</title>
      <link>https://freshrimpsushi.github.io/posts/coulombs-law-and-electric-field/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coulombs-law-and-electric-field/</guid>
      <description>쿨롱 법칙1 고정된 점전하 $q$로부터 거리가 $\eta$만큼 떨어진 시험전하 $Q$가 받는 힘을 쿨롱 힘이라 하고 수식은 다음과 같다. $$ \mathbf{F} = \dfrac{1}{4\pi \epsilon_0} \dfrac{qQ}{\eta ^2} \hat{\boldsymbol{\eta}} $$ 이를 쿨롱 법칙Coulomb&amp;rsquo;s law이라 한다. 설명 쿨롱 법칙은 반복된 실험을 통해 얻어낸 실험 법칙이다. 따라서 수학적으로 증명할 수는 없다. 마치 수학에서 공리와 같다고</description>
    </item>
    
    <item>
      <title>기울기의 기본 정리</title>
      <link>https://freshrimpsushi.github.io/posts/fundamental-theorem-for-gradient/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fundamental-theorem-for-gradient/</guid>
      <description>정리 $T$를 3차원 스칼라 함수라고 하자. $a, b$를 3차원 공간상의 임의의 점이라고 하자. $a$에서 점 $b$로 가는 임의의 경로에 따른 $T$의 총 변화량은 다음과 같다. $$ \begin{equation} T(b)-T(a) = \int _{a}^{b} (\nabla T) \cdot d\mathbf{l} \label{1} \end{equation} $$ 이를 기울기의 기본 정리fundamental theorem for gradients 혹은 기울기 정리gradients theorem라고 한다. 참고로 생새우초밥집에</description>
    </item>
    
    <item>
      <title>밀러-라빈 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/miller-rabin-test/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/miller-rabin-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 홀수 $n,q$ 를 $n-1 = 2^{k} q$ 와 같이 나타내자. $$ a \not\mid n \\ a^{q} \not\equiv 1 \pmod{n} $$ 이면서 모든 $i = 0, 1, \cdots , (k-1)$ 에 대해 $$ a^{2^{i} q} \not\equiv -1 \pmod{n} $$ 를 만족하는 $ a$ 가 존재하면 $n$ 은 합성수다. 계산량이 늘어난만큼 페르마 판정법을 통과하는 합성수도 걸러낼 가능성이 있다. 예로써 카마이클 수인 $561$ 은 $n-1 = 560 = 2^4 \cdot 35$ 이 $2^{35} \equiv 263 \pmod{561}$ 이므로</description>
    </item>
    
    <item>
      <title>실수체로 복소수체를 만들어내는 대수적인 방법</title>
      <link>https://freshrimpsushi.github.io/posts/algebraic-method-to-drive-complex-field-from-real-field/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebraic-method-to-drive-complex-field-from-real-field/</guid>
      <description>정리 1 $$ \mathbb{R} [x ] / \left&amp;lt; x^2 + 1 \right&amp;gt; \simeq \mathbb{C} $$ 설명 팩트로만 보면 당연하고 실수체에서 복소수체를 만들어내는 과정이 상당히 아름답다. $\mathbb{R} [x ]$ 를 $\left&amp;lt; x^2 \right&amp;gt;$ 로 자르든 $\left&amp;lt; x^2 + x \right&amp;gt;$ 로 자르든 원소의 모양새는 $ax + b$ 꼴로 나오겠지만 하필 $\left&amp;lt; x^2 + 1 \right&amp;gt;$ 로 자르는 이유가 있다. 적어도 한 번은 직접 증명해보면서 이 아름다움을 만끽하도록 하자. 증명 $\left( x^2 + 1 \right)$ 은 $F$ 상에서의 기</description>
    </item>
    
    <item>
      <title>리만(-스틸체스) 적분가능할 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/the-necessary-and-sufficient-condition-for-riemann-stieltjes-integrable/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-necessary-and-sufficient-condition-for-riemann-stieltjes-integrable/</guid>
      <description>해당 글은 리만-스틸체스 적분을 기준으로 작성되었다. $\alpha=\alpha(x)=x$로 두면 리만 적분과 같다. 정리1 함수 $f$가 $[a,b]$에서 리만(-스틸체스) 적분가능할 필요충분조건은 모든 $\epsilon &amp;gt;0$에 대하여 $U(P,f,\alpha) - L(P,f,\alpha) &amp;lt; \epsilon$을 만족시키는 $[a,b]$의 분할 $P$가 존재하는 것이다. $$ \begin{equation}</description>
    </item>
    
    <item>
      <title>코셀트 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/korselt-criterion/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/korselt-criterion/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 홀수 $n$ 이 합성수라고 하자. $n$ 은 카마이클 수 $\iff$ $p \mid n$ 을 만족하는 모든 소수 $p$ 에 대해 $p^2 \not\mid n$ 이면서 $(p-1) \mid (n-1)$ 카마이클 수임을 판정하는 방법으로써 필요충분조건이라는 점이 또 유용하게 쓰일 수 있는 정리다. 증명 $( \Rightarrow )$카마이클 수는 $2$ 를 제외한 서로 다른 소수 $p_{1} , \cdots , p_{m}$ 에 대해 $n = p_{1} \cdots p_{m}$ 로 나타낼 수</description>
    </item>
    
    <item>
      <title>단순확대체</title>
      <link>https://freshrimpsushi.github.io/posts/simple-extension-in-abstract-algebra/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simple-extension-in-abstract-algebra/</guid>
      <description>정의 1 $F$ 의 확대체 $E$ 가 어떤 $\alpha \in E$ 에 대해 $E = F( \alpha )$ 이면 $E$ 를 $F$ 의 단순확대체Simple Extension라 한다. 설명 $F ( \alpha )$ 은 쉽게 말해 $F$ 에 없던 $\alpha$ 를 하나Simple만 넣어서 확장한 것으로 볼 수 있다. 실수체 $\mathbb{R}$ 으로 말할 것 같으면 그 확대체 $\mathbb{C}$ 의 $i \in \mathbb{C}$ 를 넣으면 $\mathbb{R} ( i ) = \mathbb{C}$ 가 된다. 중요한 팩트로써 $\alpha \in E$ 에 대해 $E = F ( \alpha )$ 면 모든</description>
    </item>
    
    <item>
      <title>상적분은 하적분보다 크거나 같다</title>
      <link>https://freshrimpsushi.github.io/posts/the-upper-integral-is-greater-than-or-equal-to-the-lower-integral/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-upper-integral-is-greater-than-or-equal-to-the-lower-integral/</guid>
      <description>해당 글은 리만-스틸체스 적분을 기준으로 작성되었다. $\alpha=\alpha(x)=x$로 두면 리만적분과 같다. 정리1 임의의 분할에 대하여 리만(-스틸체스) 상합은 리만(-스틸체스) 하합보다 항상 크거나 같다. $$ \underline { \int _a ^b} f d\alpha \le \overline {\int _a^b} f d\alpha $$ 증명 증명에 앞서 다음과 같이 주어졌다고 하자. $f : [a,b] \to \mathbb{R}$</description>
    </item>
    
    <item>
      <title>세분</title>
      <link>https://freshrimpsushi.github.io/posts/refinement/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/refinement/</guid>
      <description>해당 글은 리만-스틸체스 적분을 기준으로 작성되었다. $\alpha=\alpha(x)=x$로 두면 리만적분과 같다. 정의 $P^{\ast}$, $P$가 $[a,b]$의 분할이고 $P \subseteq P^{\ast}$을 만족하면 $P^{\ast}$를 $P$의 세분refinement이라고 한다. 따라서 $P$의 모든 점은 $P^{\ast}$의 점이다. 임</description>
    </item>
    
    <item>
      <title>원시근 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-primitive-root-thoerem/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-primitive-root-thoerem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $1 \le a \le p$ 가 $\text{ord}_{p} (a) = p-1$ 를 만족하면 법 $p$ 의 원시근이라 정의한다. 모든 소수 $p$ 는 $\phi ( p - 1)$ 개의 원시근을 갖는다. $\text{ord}_{p} (a) $ 는 $a^{e} \equiv 1 \pmod{p}$ 를 만족하는 가장 작은 자연수 $e$ 를 의미한다. $\text{ord}_{p} (a) = p-1$ 를 만족하는 $a$ 를 원시근이라고 부르는 이유는 페르마의 소정리에 의해 $a^{p-1} \equiv 1 \pmod{ p }$ 이므로 $\text{ord}_{p} (a) \le p-1$ 임은 보장되</description>
    </item>
    
    <item>
      <title>대수적 수와 초월수</title>
      <link>https://freshrimpsushi.github.io/posts/algebraic-number-and-transcendental-number/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebraic-number-and-transcendental-number/</guid>
      <description>정의 1 체 $F$ 의 확대체를 $E$ 라고 하자. 상수함수가 아닌 $f(x) \in F [ x ]$ 에 대해 $f( \alpha ) = 0$ 을 만족시키는 $\alpha \in E$ 를 $F$ 상에서 대수적Algebraic이라 하고, 대수적이지 않으면 초월적Transcendental이라 한다. $F = \mathbb{Q}$, $E = \mathbb{C}$ 이라고 할 때 $\alpha \in \mathbb{C}$ 가 대수적이면 대수적 수, 초월적이면 초월수라 한다. 설명 예를 들어 $ f(x) = x^2 - 2 $ 라는</description>
    </item>
    
    <item>
      <title>리만-스틸체스 적분</title>
      <link>https://freshrimpsushi.github.io/posts/riemann-stieltjes-integral/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riemann-stieltjes-integral/</guid>
      <description>리만-스틸체스 적분Riemann-Stieltjes integral은 리만 적분을 일반화한 것으로 간단히 스틸체스 적분이라고도 한다. 리만 적분은 리만-스틸체스 적분에서 $\alpha(x)=x$인 특수한 경우에 해당한다. 리만-스틸체스 적분을 정의하는 과정은 리만 적분을 정의하는 과정과 같으므로 노테이션, 빌드업에 대한 구체</description>
    </item>
    
    <item>
      <title>정수론에서의 위수</title>
      <link>https://freshrimpsushi.github.io/posts/order-in-analytic-number-theory/</link>
      <pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order-in-analytic-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\gcd (a, p) = 1$ 이라고 하자. $a^{e} \equiv 1 \pmod{p}$ 를 만족하는 가장 작은 자연수 $e$ 를 $\text{ord}_{p} (a)$ 라 쓰고 법 $p$ 에서 $a$ 의 위수Order라 정의한다. $a^{n} \equiv 1 \pmod{p}$ 이라고 하면 $\text{ord}_{p} (a) \mid n$ 예를 들어 $p=7$ 을 생각해보면$1^{1} \equiv 1 \pmod{ 7 }$ $2^{3} \equiv 1 \pmod{ 7 }$ $3^{6} \equiv 1 \pmod{ 7 } $$ 4^{3} \equiv 1 \pmod{ 7 }$ $5^{6} \equiv 1 \pmod{ 7 }$ $6^{2} \equiv 1 \pmod{ 7 }$여기서 $6$ 의 위수</description>
    </item>
    
    <item>
      <title>분할, 리만 합, 리만 적분</title>
      <link>https://freshrimpsushi.github.io/posts/partition-riemann-sum-and-riemann-integral/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-riemann-sum-and-riemann-integral/</guid>
      <description>분할1 구간 $[a,b]$가 주어졌다고 하자. $[a,b]$의 분할partition $P$를 아래와 같이 정의한다. $$ P := \left\{ x_0,\ x_1,\ \cdots, x_n\right\},\quad a=x_0 &amp;lt;x_1&amp;lt;\cdots &amp;lt; x_n =b $$ 그리고 $\Delta x_i$를 다음과 같이 정의한다. $$ \Delta x_i :=x_i-x_{i-1},\quad i=1,2,\cdots,n $$ 쉽게 말해서 분할이란 어떤 구간을 쪼갰을 때 구간의 양 끝과 구간 내 경계의 모든 점을 원소로 가지는 집합이다. 중요한 점은 분할을 얘기 하려</description>
    </item>
    
    <item>
      <title>확대체의 정의와 크로네커 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-kronecker-thoerem/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-kronecker-thoerem/</guid>
      <description>확대체의 정의 1 체 $F$ 에 대해 $F \le E$ 인 $E$ 를 $F$ 의 확대체Extension Field라 한다. 크로네커 정리 $f(x) \in F [ x ]$ 가 상수가 아니라고 하면 $F$ 의 확대체 $E$ 와 $f ( \alpha ) = 0$ 인 $\alpha \in E$ 가 존재한다. 설명 확대체의 예로써 $\mathbb{C}$ 는 $\mathbb{R}$ 의 확대체다. 크로네커의 정리는 당장 $F$ 에서는 다항함수의 근이 존재하지 않을지라도 정의역을 $E$ 로 키울 수 있고, 키우면 근</description>
    </item>
    
    <item>
      <title>카마이클 수</title>
      <link>https://freshrimpsushi.github.io/posts/carmichael-number/</link>
      <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/carmichael-number/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 자연수 $n$ 이 모든 $1 \le a \le n$ 에 대해 $a^{n} \equiv a \pmod{n}$ 를 만족하면 카마이클 수라 한다. 모든 카마이클 수는 $2$ 를 제외한 서로 다른 소수의 곱으로만 나타난다. 카마이클 수는 합성수임에도 불구하고 페르마 판정법을 통과하는, 말하자면 소수처럼 보이는 수다. 예로써 $561=3 \cdot 11 \cdot 17$ 은 합성수지만 $a^{561} \equiv a \pmod{561}$ 이 항상 성립</description>
    </item>
    
    <item>
      <title>주 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/principal-ideal-in-abstract-algebra/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/principal-ideal-in-abstract-algebra/</guid>
      <description>정의 1 단위원을 가지는 가환환 $R$ 의 원소 $a$ 로 생성되는 $\left&amp;lt; a \right&amp;gt;$ 를 $a$ 에 의해 생성되는 주 아이디얼Principal Ideal이라고 한다. 곱셈에 대한 항등원 $1$ 을 단위원이라 한다. 설명 $\left&amp;lt; a \right&amp;gt; := \left\{ r a \mid r\ \in R \right\}$ 의 표기는 순환군과 같지만 실제 순환군보다는 조금 더 큰 구조를 이룬다. 예로써 $\mathbb{Z}$ 의 모든 아이디얼 $n \mathbb{Z} = \left&amp;lt; n \right&amp;gt; = \left\{ \cdots , -2n , -n , 0 , n</description>
    </item>
    
    <item>
      <title>합동방정식의 거듭제곱근</title>
      <link>https://freshrimpsushi.github.io/posts/k-th-roots-modulo-m/</link>
      <pubDate>Mon, 31 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k-th-roots-modulo-m/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 자연수 $b,k,m$ 가 $\gcd (b , m) = \gcd ( k , \phi (m) ) = 1$ 을 만족하면 합동방정식 $x^{k} \equiv b \pmod{ m }$ 의 해 $x$ 는 다음과 같이 계산할 수 있다.**Step 1. $\phi (m)$ 을 계산한다.**Step 2. $ku - \phi(m) v =1$ 을 만족하는 $u, v$ 을 찾고 양변에 $u$ 승을 취해 $x^{ku} \equiv b^{u} \pmod{m}$ 를 얻는다.**Step 3. $b^{u} \pmod{ m }$ 을 연속제곱법으로 계산한</description>
    </item>
    
    <item>
      <title>소 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/prime-ideal-in-abstract-algebra/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prime-ideal-in-abstract-algebra/</guid>
      <description>정의 1 가환환 $R$ 의 아이디얼 $P \ne R$ 가 $a, b \in R$ 에 대해 $ab \in P$ 이면 $a \in P$ 또는 $b \in P$ 일 때, $P$ 가 $R$ 에서 소 아이디얼Prime Ideal이라 한다. 설명 소Prime라는 명칭에서 알 수 있듯 곱해진 원소를 쪼개는 것에서 출발한다. 예로써 정수환 $\mathbb{Z}$ 을 생각해보면 $2 \mathbb{Z}$ 의 모든 원소들은 $2k$ 와 같은 형태로 나타나고, $2 \in 2 \mathbb{Z}$ 이므로 소 아이디얼이 된다. 같</description>
    </item>
    
    <item>
      <title>디랙 델타 함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-dirac-delta-function/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-dirac-delta-function/</guid>
      <description>정리1 디랙 델타 함수의 라플라스 변환은 다음과 같다. $$ \mathcal{L} \left\{ \delta(t-t_0) \right\} = e^{-st_0} $$ 증명 위 그림과 같이 $d_\tau (t) = \dfrac{1}{2\tau}$ $-\tau \le t \le \tau$라고 정의하자. 그러면 아래의 극한은 디랙 델타 함수와 같다. $$ \lim \limits_{\tau \to 0^+}d_\tau (t)=\delta(t) \\ \lim \limits_{\tau \to 0^+}d_\tau (t-t_0)=\delta(t-t_0) $$ 그러면 $\mathcal{L} \left\{ \delta(t-t_0) \right\}=\mathcal{L} \left\{ \lim \limits_{ \tau \to 0^+}d_\tau (t-t_0) \right\}$이다.따라서 $$ \begin{align*} \int_0^\infty e^{-st}\delta(t-t_0)dt &amp;amp;=\lim_{\tau \to 0^+} \int_0 ^\infty e^{-st}d_\tau(t-t_0)dt \\ &amp;amp;= \lim_{\tau \to 0^+} \int_0 ^\infty e^{-st}d_\tau(t-t_0)dt \\ &amp;amp;= \lim_{\tau \to 0^+} \int_{t_0-\tau}^{t_0+\tau}e^{-st}d_\tau(t-t_0)dt \\ &amp;amp;= \lim_{\tau \to 0^+} \int_{t_0-\tau}^{t_0+\tau}e^{-st}\dfrac{1}{2\tau}dt</description>
    </item>
    
    <item>
      <title>주기 함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-periodic-function/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-periodic-function/</guid>
      <description>공식 $f$를 주기가 $T$인 주기함수라고 하자. 그러면 $f(t+T)=f(t)$이고 $f(t)$의 라플라스 변환은 아래와 같다. $$ \mathcal{L} \left\{ f(t) \right\} = \int_0^\infty e^{-st}f(t)dt = \frac{\displaystyle \int_0^T e^{-st}f(t)dt}{1-e^{-st}} $$ 유도 $$ f(t+T)=f(t) $$ $f(t)$의 라플라스 변환은 아래와 같이 나타낼 수 있다. $$ \int_0^\infty e^{-st}f(t)dt = \int_0^T e^{-st}f(t)dt + \int_T^{2T} e^{-st}f(t)dt + \int_{2T}^{3T}e^{-st}f(t)dt + \cdots $$ 이 때 두번째 항의 적분 범위를 첫번째 항과 같게 해주기 위해서 $t=t&#39;+T</description>
    </item>
    
    <item>
      <title>극대 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/maximal-ideal-in-abstract-algebra/</link>
      <pubDate>Fri, 28 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maximal-ideal-in-abstract-algebra/</guid>
      <description>정의 1 환 $R$ 의 아이디얼 중 $R$ 이외의 아이디얼에는 포함되지 않는 아이디얼 $M$ 을 $R$ 의 극대 아이디얼Maximal Ideal이라 한다. 설명 대수학에서 말하는 &amp;lsquo;맥시멀&amp;rsquo;는 집합론에서의 맥시멀과 거의 똑같다. 당연히 정의만으론 유일성을 보장할 수 없는데, 예로써 정수환 $\mathbb{Z}$ 에 대해 $2 \mathbb{Z}$, $3 \mathbb{Z}$ 은 둘 모두 $\mathbb{Z}$ 외의 초아이디얼Su</description>
    </item>
    
    <item>
      <title>힐베르트 공간은 리플렉시브임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/hilbert-space-is-reflexive/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hilbert-space-is-reflexive/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $H^{**} \approx H$ 짧고 간단하지만 힐베르트 공간을 연구함에 있어서 듀얼 스페이스보다 커지는 것을 생각할 필요가 없다는 것은 굉장히 좋은 일이다. 증명 **Part 1. $(H^{ \ast } , | \cdot | )$ 은 힐베르트 공간이다. 리즈 표현 정리$H$ 가 힐베르트 공간이라고 하자. $f \in H^{ \ast }$ 와 $z \in H$ 에 대해 $f ( z ) = \left&amp;lt; z , x_{f} \right&amp;gt;$ 와 $| f |</description>
    </item>
    
    <item>
      <title>삼중대각행렬의 행렬식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-tridiagonal-matrixs-determinant/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-tridiagonal-matrixs-determinant/</guid>
      <description>공식 삼중대각행렬 $X_{n} := \begin{bmatrix} x &amp;amp; 1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\ 1 &amp;amp; x &amp;amp; 1 &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; x &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; x &amp;amp; 1 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 1 &amp;amp; x \end{bmatrix}$ 에 대해 $$ | x_{n}| = U_{n} \left( {{x} \over {2}} \right) $$ $U_{n}$ 은 $n$ 차 제2종 체비셰프 다항함수를 의미한다.물론 $X_{n}$ 은 일반적인 삼중대각행렬이 아니고 삼중대각 퇴플리츠Toepli</description>
    </item>
    
    <item>
      <title>리즈 표현 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-riesz-representation-theorem/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-riesz-representation-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $H$ 가 힐베르트 공간이라고 하자. $f \in H^{ \ast }$ 와 $z \in H$ 에 대해 $f ( z ) = \left&amp;lt; z , x_{f} \right&amp;gt;$ 와 $| f | = | x_{f} |$ 을 만족하는 $x_{f} \in H$ 가 유일하게 존재한다. 쉽게 말해 힐베르트 공간의 듀얼스페이스 $H^{ \ast }$ 의 모든 원소가 어떻게 생겼는지 규명한 셈인데, 이게 말은 간단해도 함수라는 게 정의하는 사람 마음대로라는</description>
    </item>
    
    <item>
      <title>단원을 가지는 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/ideal-with-unity/</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ideal-with-unity/</guid>
      <description>정리 1 [1]: 단위원 $1$ 을 갖는 환 $R$ 의 아이디얼 $I$ 가 단원을 가지면 $I = R$ [2]: 체 $F$ 는 $\left\{ 0 \right\}$, $F$ 외의 아이디얼을 가지지 않는다. 설명 정리 [1]은 아이디얼에 단원이 있다는것만으로 전체가 되어버린다는 정리로, 귀류법을 사용한 증명에 빈번하게 쓰이는 보조정리다. 또한 단위원은 단원이라는 점에서, 멀쩡한 아이디얼이라면 $1$ 을 갖지 않는다는 것을 보장해주기</description>
    </item>
    
    <item>
      <title>직교 분해 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-orthogonal-decomposition-theorem/</link>
      <pubDate>Sun, 23 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-orthogonal-decomposition-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 힐베르트 공간 $H$ 의 닫힌 부분공간 $M$ 에 대해 $H = M \oplus M^{\perp}$ $M^{\perp } := \left\{ x \in H \mid \left&amp;lt; x , m \right&amp;gt; = 0 , m \in M \right\}$ 을 $M$ 의 직교여집합이라고 한다.직교성만큼이나 유용한 성질도 흔치 않다. 힐베르트 공간이 이를 보장한다는 것은 곧 힐베르트 공간이 좋은 공간이라는 말이 된다. 전략: 증명과정은 단순히 직합으로 나</description>
    </item>
    
    <item>
      <title>베이즈 인자를 통한 가설검정</title>
      <link>https://freshrimpsushi.github.io/posts/statistical-hypothesis-test-by-bayes-factor/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statistical-hypothesis-test-by-bayes-factor/</guid>
      <description>빌드업 고전적인 가설검정을 쓸 수 있게 되려면 기각역, 유의확률과 같은 개념에 대한 수학적인 이해를 포함해서 이를 직관적으로 받아들일 수 있을 정도의 통계학적 센스까지 갖추어야한다. 학부 1학년 교양 수준에서도 몇 시간이나 할애해가며 가르치고, 그래도 가설검정을 제대로 받아들이지 못하는 학생이 수두룩한 것도 당연한 일이다. 고등학교에서 배우는 통</description>
    </item>
    
    <item>
      <title>방데르몽드 행렬의 행렬식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-vandermonde-matrix-determinant/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-vandermonde-matrix-determinant/</guid>
      <description>정의 서로 다른 $1, x_{1} , x_{2 } , \cdots , x_{n}$ 에 대해 다음과 같이 정의된 행렬 $V_{n}$ 을 방데르몽드 행렬Vandermonde Matrix이라고 한다. $$ V_{n} := \begin{bmatrix} 1 &amp;amp; x_{1} &amp;amp; x_{1}^{2} &amp;amp; \cdots &amp;amp; x_{1}^{n-1} \\ 1 &amp;amp; x_{2} &amp;amp; x_{2}^{2} &amp;amp; \cdots &amp;amp; x_{2}^{n-1} \\ \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 1 &amp;amp; x_{n} &amp;amp; x_{n}^{2} &amp;amp; \cdots &amp;amp; x_{n}^{n-1} \end{bmatrix} $$ 공식 $V_{n}$ 의 행렬식은 $$ \det V_{n} = \prod_{1 \le i &amp;lt; j \le n } (x_{j} - x_{i}) $$ 설명 방데르몽드 행렬은 특이하게 생겼지만 미분방</description>
    </item>
    
    <item>
      <title>제1종 제2종 체비셰프 다항함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relations-between-chebyshev-polynomials/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relations-between-chebyshev-polynomials/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 제1종 체비셰프 다항함수제2종 체비셰프 다항함수체비셰프 미분방정식의 해로써의 체비셰프 다항함수 $T_{n} (x) = \cos \left( n \cos^{-1} x \right)$ 과 $\displaystyle U_{n} (x) = {{1} \over {n+1} } T_{n+1} &#39; (X)$ 은 다음의 관계를 가진다. [1]: $U_{n} (x) - U_{n-2} (x) = 2 T_{n} (X)$ [2]: $T_{n} (x) - T_{n-2} (x) = 2( x^2 - 1 ) U_{n-2} (x) $ *보통 $0 \le \theta \le \pi$ 에 대해 $\theta := \cos^{-1} x $ 라고 둔다. 위 등식들을</description>
    </item>
    
    <item>
      <title>크레이머 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cramer-rule/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cramer-rule/</guid>
      <description>개요 크레이머 공식Cramer Rule은 연립방정식을 제대로 풀어내는데에 효율적이라곤 할 수 없지만 $A_{j}$ 가 비가역행렬이라거나 $A$ 자체가 행렬식을 구하기 편리하도록 특정한 조건이 주어져있다면 필요한 답만 바로바로 구해내는데 충분히 유용하게 쓰일 수 있다. 정리 연립방정식 $A \mathbb{x} = \mathbb{b}$ 이 가역행렬 $$ A = \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots</description>
    </item>
    
    <item>
      <title>제2종 체비셰프 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-second-kind/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-second-kind/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 제1종 체비셰프 다항함수제1종, 제2종 체비셰프 다항함수의 관계체비셰프 미분방정식의 해로써의 체비셰프 다항함수 $\displaystyle U_{n} (x) := {{1} \over {n+1} } T_{n+1} &#39; (x) = {{\sin \left( ( n +1 ) \theta \right)} \over { \sin \theta }} $ 을 제2종 체비셰프 다항함수라 한다. [0]** $U_{n+1} (x) = 2x U_{n} (x) - U_{n-1} (X)$ [1]** 함수의 내적 $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx $ 에 대해 웨이트 $w$ 를 $\displaystyle w(x)</description>
    </item>
    
    <item>
      <title>최단 벡터 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-minimizing-vector-theorem/</link>
      <pubDate>Mon, 17 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-minimizing-vector-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 힐베르트 공간 $H$ 에 대해 닫힌 컨벡스 부분공간 $M \lneq H$ 을 정의하자. $x \in ( H \setminus M)$ 에 대해 $$ \displaystyle \delta := | x - m_{0} | = \inf_{m \in M} | x - m | &amp;gt; 0 $$ 을 만족하는 $m_{0}$ 이 유일하게 존재한다. 부분공간 $M$ 이 컨벡스하다는 것은 모든 $x,y \in M$ 과 $\lambda \in [0,1]$ 에 대해 다음이 성립한다는 것이다. $$ \lambda x + (1-\lambda) y \in M $$ 별 거 없어보이</description>
    </item>
    
    <item>
      <title>제1종 체비셰프 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-first-kind/</link>
      <pubDate>Sun, 16 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-first-kind/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 제2종 체비셰프 다항함수제1종, 제2종 체비셰프 다항함수의 관계체비셰프 미분방정식의 해로써의 체비셰프 다항함수 $T_{n} (x) = \cos \left( n \cos^{-1} x \right)$ 을 제1종 체비셰프 다항함수라 한다. [0]** $T_{n+1} (x) = 2x T_{n} (x) - T_{n-1} (X)$ [1]** 함수의 내적 $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx $ 에 대해 웨이트 $w$ 를 $\displaystyle w(x) := {{1} \over { \sqrt{1 - x^2} }}$ 와 같이 주면 $\left\{ T_{0} , T_{1},</description>
    </item>
    
    <item>
      <title>함수해석학에서의 힐베르트 공간</title>
      <link>https://freshrimpsushi.github.io/posts/hilbert-space/</link>
      <pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hilbert-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 실해석학에서의 힐베르트 공간 $H$를 벡터 공간이라고 하자. $x,y,z \in H$ 와 $\lambda \in \mathbb{C}$ 에 대해 다음의 조건을 만족하는 함수 $\left&amp;lt; \cdot , \cdot \right&amp;gt; : H \times H \to \mathbb{C}$ 을 내적Inner Product이라 정의한다. 내적이 정의된 공간 $(H , \left&amp;lt; \cdot , \cdot \right&amp;gt; )$ 을 내적 공간이라 한다. (i): $\left&amp;lt; \lambda x + y, z \right&amp;gt; = \lambda \left&amp;lt; x, z \right&amp;gt; + \lambda \left&amp;lt; y, z</description>
    </item>
    
    <item>
      <title>벡터 공간의 리플렉시브</title>
      <link>https://freshrimpsushi.github.io/posts/reflexive/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reflexive/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $X^{**} \approx X$ 면 $X$ 가 리플렉시브 하다고 한다. 일반적으로 스페이스는 듀얼을 취할때마다 점점 그 크기가 더 커진다. 그런데 리플렉시브라는 말은 사실상 듀얼 스페이스가 계속해서 커지지 않는 공간이라고 보아도 좋다.리플렉시브한 공간에는 다음의 예시가 있다. [1]: $1 &amp;lt; p &amp;lt; \infty$ 에 대해 ${\mathcal{l}^{p}}^{**} \approx \mathcal{l}^{p}$ [2]: $\dim X = n$ 이면 $X^{**}</description>
    </item>
    
    <item>
      <title>최고사후밀도 신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</guid>
      <description>정의 1 모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $C : = \left\{ \theta \in \Theta \ | \ p ( \theta | y ) \ge k (\alpha) \right\}$ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 최고사후밀도 신용구간HPD이라고 한다. 여기서 $k(\alpha)$ 는 $p(\theta \in C | y ) \ge 1 - \alpha$ 를 만족하는 가장 큰 상수다. 설명 수식과 말보다는 그림을 통해 보는게 훨씬 이해하기 좋다. 실제 계산에서도 위와 같이 $k$ 를 계</description>
    </item>
    
    <item>
      <title>등거리 사상</title>
      <link>https://freshrimpsushi.github.io/posts/isometric-map/</link>
      <pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isometric-map/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **등거리 사상$(\mathrm{isomertic\ map,\ isometry})$ 두 거리공간1 $(X,\ d_X)$, $(Y,\ d_Y)$ 에 대해서 아래의 조건을 만족하는 사상 $f\ :\ X\rightarrow Y$가 존재하면 $X$와 $Y$가 **아이소메트릭$(\mathrm{isometric})$**이라 하고 $X \approx Y$라고 표기한다. 또한 사상 $f$</description>
    </item>
    
    <item>
      <title>복소수의 부호</title>
      <link>https://freshrimpsushi.github.io/posts/sign-of-complex-number/</link>
      <pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sign-of-complex-number/</guid>
      <description>정의 $\lambda \in \mathbb{C}$ 에 대해 부호Sign를 다음과 같이 정의한다. $$ \text{sign} ( \lambda ) = \begin{cases} \displaystyle {{| \lambda | } \over { \lambda }} &amp;amp;, \lambda \ne 0 \\ 1 &amp;amp;, \lambda = 0 \end{cases} $$ 설명 쉽게 체크할 수 있는 예로써 실수의 부호 $\text{sign} ( +2 ) = 1$, $\text{sign} ( -3 ) = -1$ 를 바로 확인할 수 있다. 따라서 실수의 일반화라는 점에서는 충분히 좋은 정의다. $\displaystyle \text{sign} ( i ) = {{| i | } \over {i}} = - i$ 으로 계산된다는 점이 좀 이상하게 느껴질 수</description>
    </item>
    
    <item>
      <title>듀얼 스페이스</title>
      <link>https://freshrimpsushi.github.io/posts/dual-space/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dual-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 벡터공간 $X$ 의 모든 연속인 선형 범함수들의 집합을 $X^{ \ast }$로 표기하고 이를 $X$ 의 듀얼 스페이스, 간단히 $X$ 의 듀얼이라 한다. $$ X^{ \ast }:=\left\{ x^{ \ast }:X\to \mathbb{C}\ |\ x^{ \ast } \text{ is continuous and linear} \right\} $$ $$ X^{ \ast }:=B(X,\mathbb{C}) $$ 선형 작용소의 성질에 의해 연속이라는 조건은 유계라는 조건과 동치이다.* $B \left( X, \mathbb{C} \right)$ 는 정의역이 $X$ 고 공역이 $\mathbb{C}$ 인 유</description>
    </item>
    
    <item>
      <title>신용구간과 신뢰구간의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</guid>
      <description>요약 신용구간과 신뢰구간의 차이는 실로 베이지안과 프리퀀티스트의 차이라고 볼 수 있다. 신뢰구간(프리퀀티스트): 모수는 고정된 상수고, 신뢰구간이 랜덤으로 구해진다. 신용구간(베이지안): 모수도 분포를 가진 변수고, 신용구간도 사후분포로 구해진다. 신뢰구간 고전통계에서 모수 $\mu$ 에 대한 $95 \% $ 신뢰구간 $[a , b]$ 이 의미하는 것은 같은 방법</description>
    </item>
    
    <item>
      <title>선형범함수가 선형독립결합으로 나타나는 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-of-that-linear-functional-is-linearly-independent/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-of-that-linear-functional-is-linearly-independent/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $f, f_{1} , \cdots , f_{n}$ 가 정의역이 $X$ 인 선형범함수라고 하자. [1]: $c_{1} , \cdots , c_{n} \in \mathbb{C}$ 에 대해 $\displaystyle f = \sum_{i=1}^{n} c_{i} f_{i}$ $\iff$ $\displaystyle \bigcap_{i=1}^{n} \ker ( f_{i} ) \subset \ker (f)$ [2]: $f_{1} , \cdots , f_{n}$ 이 선형독립 $\iff$ $f_{j} (x_{i} ) = \delta_{ij}$ 을 만족하는 $x_{1} , \cdots , x_{n}$ 이 존재 $\delta_{ij}$ 는 크로네커 델타함수다. 커널이 동차Homogeneous의 개념과 관계가 있다는 걸 생각해보면 선형 동</description>
    </item>
    
    <item>
      <title>추상대수학에서의 래디컬과 닐래디컬</title>
      <link>https://freshrimpsushi.github.io/posts/radical-and-nilradical-in-abstract-algebra/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/radical-and-nilradical-in-abstract-algebra/</guid>
      <description>정의 1 $N$ 이 환 $R$ 의 아이디얼이라고 하자. $\text{rad} N := \left\{ a \in R \ | \ a^n \in N \right\}$ 을 $N$ 의 래디컬Radical이라 한다. $a^{n} = 0$ 을 만족하는 $n \in \mathbb{N}$ 이 존재하면 $a$ 가 닐포텐트Nilpotent라 한다. 닐포텐트 엘러먼트들의 집합 $\text{nil} R := \left\{ a \in R \ | \ a^n = 0 \right\}$ 을 $R$ 의 닐래디컬Nilradical이라 한다. 설명 $N$ 의 래디컬을 $\sqrt{N}$, $R$ 의 닐래디컬을 $\sqrt{0}$</description>
    </item>
    
    <item>
      <title>회귀분석에서의 교호작용</title>
      <link>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</guid>
      <description>빌드업 우선 질적변수를 포함한 회귀분석에 대해 읽어보는 것을 추천한다. 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 우선 질적변수가 있으므로 성별을 $$ S = \begin{cases} 1 &amp;amp; ,\text{여성} \\ 0 &amp;amp; ,\text{남성} \end{cases} $$ 그리고 학력을 $$ E_{1} = \begin{cases} 1 &amp;amp; ,\text{대졸} \\ 0 &amp;amp; ,\text{고졸</description>
    </item>
    
    <item>
      <title>범함수</title>
      <link>https://freshrimpsushi.github.io/posts/functional/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/functional/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $X$를 벡터공간이라고 하자. 아래와 같은 $X$에서 $\mathbb{C}$로의 사상 $f$를 범함수라 한다. $$ f : X \to \mathbb{C} $$ $f$가 선형작용소이면 선형 범함수라 한다. 한국어로 순화하면 &amp;lsquo;범함수&amp;rsquo;라서 별 느낌이 없지만 영어로 볼땐 Functional</description>
    </item>
    
    <item>
      <title>질적변수를 포함한 회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/regression-analysis-including-qualitative-factor/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regression-analysis-including-qualitative-factor/</guid>
      <description>개요 회귀분석을 하면서 독립변수로 언제나 양적변수가 들어온다는 보장은 없다. 성별이 무엇인지, 어떤 기업 소속인지, 무슨 색상인지, 금속인지 등등 범주형 자료 역시 분석에 반영시킬 필요가 있다. 빌드업 1 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 다중회귀분석을 사용하면 $Y \leftarrow X_{1} + X_{2}$ 와 같이 연봉 $Y$</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 정규성</title>
      <link>https://freshrimpsushi.github.io/posts/normality-of-standard-residuals/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normality-of-standard-residuals/</guid>
      <description>진단법 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 정규성은 잔차들의 흩어진 모양보다는 히스토그램으로 확인하거나 정규성 검정을 하는 게 낫다. 왼쪽은 가운데에서 위 아래로 갈수록 그 밀도가 작아지는 것에 비해 오른쪽은 위아래 할 것 없이 고르게 퍼져있다. 하지만 이렇게 정말 잔차들이 정규분포 외의 알려진 분포를 따르는 케이스는</description>
    </item>
    
    <item>
      <title>신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval/</guid>
      <description>정의 1 모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $P ( \theta \in C | y ) \ge 1 - \alpha$ 를 만족할 때, $C$ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 신용구간Credible Interval이라고 한다. 설명 베이지안에서의 구간추정이란 모수 $\theta$ 를 포함하는 확률이 높은 구간을 찾는 것이다. 이로써 찾아지는 &amp;lsquo;신용구간&amp;rsquo</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 독립성</title>
      <link>https://freshrimpsushi.github.io/posts/independency-of-standard-residuals/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independency-of-standard-residuals/</guid>
      <description>진단법 직관적 패턴 파악 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 독립성을 확인하려면 잔차 그림에 어떤 뚜렷한 경향이 나타나지 않으면 된다. 안타깝게도 독립성의 진단은 다른 회귀분석의 가정에 비해 매우 주관적일 수밖에 없다. 독립성이 결여된 예로 가장 자주볼 수 있는 경우는 위와 같이 정체를 알 수 없는 직선이 보이는 것이다. 물</description>
    </item>
    
    <item>
      <title>통계학의 세가지 대표값: 최빈값, 중앙값, 평균</title>
      <link>https://freshrimpsushi.github.io/posts/mode-median-mean/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mode-median-mean/</guid>
      <description>개요 대표값은 데이터를 설명하는 대표적인 값을 말한다. 수천 수만에 달하는 데이터가 있어도 일일이 다 살펴볼 게 아니라면 결국 중요한 것은 데이터가 무엇을 의미하느냐고, 대표값은 이를 효과적으로 요약한다. 그 중 가장 자주 쓰이는 세가지 대표값으로써 최빈값, 중앙값, 평균이 있다. (0) 최빈값: 표본에서 가장 자주 발생한 값 (1) 중앙값: 표본에서 중앙에 위</description>
    </item>
    
    <item>
      <title>추상대수학에서의 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/ideal-in-abstract-algebra/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ideal-in-abstract-algebra/</guid>
      <description>정의 1 환 $(R , + , \cdot )$ 의 모든 $a,b \in R$ 에 대해 $a I \subset I$ 와 $I b \subset I$ 을 만족하는 부분군 $(I, +)$ 을 아이디얼Ideal이라 한다. 설명 간단한 예시로써 $n \mathbb{Z}$ 는 $\mathbb{Z}$ 의 아이디얼이 된다. 아이디얼이라는 명명은 말 그대로 이상적인Ideal에서 왔다. 추상대수에서 다루기에 이상적인 부분군이기 때문에 실제로 그렇게 부르는 것이다. 특히 $R$ 이 가환환이라면 $I$ 가</description>
    </item>
    
    <item>
      <title>유계 선형작용소의 제곱의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-of-square-of-bounded-linear-operator/</link>
      <pubDate>Fri, 30 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-of-square-of-bounded-linear-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $T, T^2 \in B(X,X)$ 에 대해 $T(Tx) = T^{2} x$ 면 $| T^{2} | = | T |^{2}$ 단순하게 보이지만 자그마치 3개의 성질이 합쳐진 컴비네이션이다. 자연수에 대해 일반화하면 $| T^{m} | = | T |^{m}$ 으로, 거듭제곱을 자유자재로 넣고 뺄 수 있음을 보장하기 때문에 아주 유용하다. 전략: 양쪽 방향으로 똑같이 성립하는 부등식을 세워서 등식임을</description>
    </item>
    
    <item>
      <title>아이젠슈타인 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/eisenstein-criterion/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eisenstein-criterion/</guid>
      <description>정리 1 $f(x) = a_{n} x^{n} + \cdots + a_{0 } \in \mathbb{Z} [ x ]$ 가 소수 $p \in \mathbb{Z}$ 와 $k = 1,2, \cdots , n-1$ 에 대해 다음 조건들을 만족하면 $f(x)$ 는 $\mathbb{Q}$ 상에서 기약함수다. (i): $a_{n} \not\equiv 0 \pmod{p}$ (ii): $a_{k} \equiv 0 \pmod{p} $ (iii): $a_{0} \not\equiv 0 \pmod{p^2}$ 설명 $f(x) = ax^{n} + b$ 꼴의 정수다항식에 대해 아주 쉬운 판정법으로써 의미가 있다. $\mathbb{Q}$ 에 대한 판정법이라는 점에서 대수적 수와 관련된 논의에서 유용하게 쓰일 수 있다. 증명 $f(x) \in \mathbb{Z} [ x ]$ 는 차수</description>
    </item>
    
    <item>
      <title>라플라스 전개</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-expansion/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-expansion/</guid>
      <description>빌드업 정사각행렬 $A_{n \times n} = (a_{ij})$ 의 $i$ 번째 행과 $j$ 번째 행을 제거한 행렬의 행렬식 $M_{ij}$ 을 소행렬식Minor이라고 한다. 이에 대해 $C_{ij} := (-1)^{i + j} M_{ij}$ 를 여인자Cofactor라고 한다. 정리 [1] 선택된 $i$행 에 대해 $$ \det A = \sum_{j=1}^{n} a_{ij} C_{ij} $$ [2] 선택된 $j$열 에 대해 $$ \det A = \sum_{i=1}^{n} a_{ij} C_{ij} $$ 설명 라플라스 전개는 여인자 전개 로도 불리는 정리로써, 그 유용함이 이루 말할</description>
    </item>
    
    <item>
      <title>다항함수의 기약원</title>
      <link>https://freshrimpsushi.github.io/posts/irreducible-element-in-abstract-algebra/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/irreducible-element-in-abstract-algebra/</guid>
      <description>정의 1 상수함수가 아닌 $f(x) \in F [ x ]$ 가 $f(x)$ 보다 차수가 낮은 어떤 $g(x) , h(x) \in F [ x ]$ 의 곱 $f(x) = g(x) h(X)$ 으로 나타낼 수 없을 때 $f(x)$ 를 $F$ 상에서의 기약원Irreducible Element이라 한다. 설명 예로써 $\mathbb{Q} [x ]$ 를 생각해보면 $x^2 - 2$ 은 $\mathbb{Q}$ 상에서 기약원이지만, $\mathbb{R} [ x ]$ 에서의 $x^2 - 2$ 은 $\mathbb{R}$ 상에서 $$ (x + \sqrt{2} ) ( x - \sqrt{2} ) $$ 로 인수분해가 가능하다. 또</description>
    </item>
    
    <item>
      <title>인수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-factor-theorem/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-factor-theorem/</guid>
      <description>정리 1 $f(x) \in F [ x ]$ 라고 하자. $$ f(a) = 0 \iff f(x) = (x-a) q(x) $$ 설명 중학교부터 지겹도록 해온 인수분해의 존재성을 보장하는 정리다. 주의할 것은 나눗셈 정리나 인수 정리와 같은 팩트들은 다항함수의 차수가 유한할 때 의미가 있다는 것이다. 증명 $( \Rightarrow )$ 나눗셈 정리: $a_{n} \ne 0$ 과 $b_{m} \ne 0$, 그리고 $n &amp;gt; m &amp;gt; 0$ 에 대해 $F [ x ]$ 의 두 원소를 $$ f(x) = a_{n} x^{n} + \cdots + a_{1} x + a_{0} \\ g(x)</description>
    </item>
    
    <item>
      <title>나눗셈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-division-algorithm/</link>
      <pubDate>Fri, 23 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-division-algorithm/</guid>
      <description>정리 1 $a_{n} \ne 0$ 과 $b_{m} \ne 0$, 그리고 $n &amp;gt; m &amp;gt; 0$ 에 대해 $F [ x ]$ 의 두 원소를 $$ f(x) = a_{n} x^{n} + \cdots + a_{1} x + a_{0} \\ g(x) = b_{m} x^{m} + \cdots + b_{1} x + b_{0} $$ 이라고 하자. 그러면 $f(x) = g(x) q(x) + r(X)$ 를 만족하는 $q(x), r(x) \in F [ x ]$ 이 유일하게 존재한다. $r$ 의 차수는 $m$ 보다 작다. 설명 꼭 정리가 있어야 알 수 있는 사실은 아니지만 대수적으로 엄밀한 증명이라는 의의가 있다. 증명 $$ S : = \left\{ f(x)</description>
    </item>
    
    <item>
      <title>선형작용소의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-linear-operator/</link>
      <pubDate>Thu, 22 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-linear-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $T : (X , | \cdot |_{X}) \to ( Y , | \cdot |_{Y} )$ 가 선형작용소라고 하자. [1]: $T$ 가 유계면 모든 $x \in X$ 에 대해 $| T(x) |_{Y} \le | T | | x |_{X}$ [2]: $T$ 는 연속 $\iff$ $T$ 는 유계 [3]: $X$ 가 유한 차원 공간이면 $T$ 는 연속이다. [4]: $Y$ 가 바나흐 공간이면 $( B(X,Y) , | \cdot | )$ 는 바나흐 공간이다. $B(X,Y)$ 는 유계 선형작용소들의 공간이므로 [2] 에 의해 이 공간</description>
    </item>
    
    <item>
      <title>다항함수의 영</title>
      <link>https://freshrimpsushi.github.io/posts/zero-of-polynomial-in-abstract-algebra/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zero-of-polynomial-in-abstract-algebra/</guid>
      <description>정의 1 $$ f(x) : = \sum_{i=0}^{n} a_{i} x^{i} = a_{0} + a_{1} x + \cdots + a_{k} x^{k} $$ 다항함수 $f \in F [x]$ 와 체 $F \le E$ 에 대해 $\alpha \in E$ 에서의 평가함수Evaluation $\phi_{\alpha} : F [ x ] \to E$ 를 다음과 같이 정의하자. $$ \phi_{\alpha} ( f(x) ) : = a_{0} + a_{1} \alpha + \cdots + a_{n} \alpha^n = f (\alpha) $$ $f( \alpha ) = 0$ 을 만족시키는 $\alpha \in E$ 를 $f(x)$ 의 영Zero이라 한다. 설명 평가함수 팩트로써, $\phi_{\alpha}$ 는 준동형사상이 된다. 정의가 너무</description>
    </item>
    
    <item>
      <title>함수해석학에서 작용소란</title>
      <link>https://freshrimpsushi.github.io/posts/operator/</link>
      <pubDate>Tue, 20 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 양자역학에서의 연산자 $(X, | \cdot |_{X})$와 $(Y, | \cdot |_{Y})$가 [[놈 공간]]이라고 하자. 1.** 놈 공간에서 놈 공간으로의 사상을 **작용소**라 한다. 2. $x,x_{1},x_{2}\in X$ 에 대해서, $T : X \to Y$가 $T( x_{1} + x_{2} ) = T( x_{1} ) + T( x_{2} )$ 와 $T( a x ) = a T( x ) $을 만족하면 **선형작용소**Lin</description>
    </item>
    
    <item>
      <title>빅오 노테이션이 분모에 있을 때 분자로 올리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/trick-for-big-o-notation-in-denominator/</link>
      <pubDate>Mon, 19 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trick-for-big-o-notation-in-denominator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $a \ne 0$ 와 $p&amp;gt;0$, $n \in \mathbb{N}$ 에 대해 $\displaystyle {{1} \over { \sqrt[p]{a + O ( h^n ) } }} = {{1} \over { \sqrt[p]{a } }}+ O(h^n)$ 복잡하게 생긴 분모를 깔끔한 형태로 바꿔주는 렘마로써 요긴하게 쓰일 수 있다.상수항 $a$ 이 없다면 렘마 없이도 $\displaystyle {{1} \over { \sqrt[p]{ O ( h^n ) } }} = O \left( h^{ - {{n} \over {p}} } \right) $ 으로 깔끔하게 올라오지만 보통 쓸모가 없다. 증명 $\displaystyle {{1} \over { \sqrt[p]{a + O</description>
    </item>
    
    <item>
      <title>리즈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rieszs-theorem/</link>
      <pubDate>Sat, 17 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rieszs-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 놈드 스페이스 $(X , | \cdot |)$ 의 스칼라 필드를 $\mathbb{C}$ 라고 하자. $X$ 는 유한차원 $\iff$ $\overline{ B ( 0 ; 1 ) }$ 은 컴팩트 $\overline{ B ( 0 ; 1 ) } := \left\{ x \in X \ : \ | x | \le 1 \right\} $ 는 클로즈드 유닛 볼&amp;lt;**sup&amp;gt;Closed Unit Ball을 나타낸다.리즈 정리에 따르면 전체 공간이 유한차원인지 판단하기</description>
    </item>
    
    <item>
      <title>t^{n}f(t)의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-tnft/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-tnft/</guid>
      <description>공식 함수 $f(t)$의 라플라스 변환이 $\mathcal{L} \left\{ f(t) \right\} = \displaystyle \int _0 ^\infty e^{-st}f(t)dt = F(s)$라고 하자. 그러면 $t^{n}f(t)$의 라플라스 변환은 다음과 같다. $$ \mathcal{L} \left\{ t^n f(t) \right\} = (-1)^nF^{(n)}(s) $$ 유도 우선 $t^nf(t)$의 라플라스 변환은 정의에 의해 다음과 같다. $$ \int _0 ^\infty e^{-st}tf(t) dt $$ 적분 안을 잘 살펴보면 $e^{-st}f(t)$를 $s$에 대해 미분한 것과 같</description>
    </item>
    
    <item>
      <title>다항식의 환</title>
      <link>https://freshrimpsushi.github.io/posts/ring-of-polynomial/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ring-of-polynomial/</guid>
      <description>정의 1 $$ f(x) : = \sum_{i=0}^{n} a_{i} x^{i} = a_{0} + a_{1} x + \cdots + a_{k} x^{k} $$ 환 $R$ 의 다항함수Polynomial $f(x)$ 를 위와 같이 정의한다. $a_{i} \in R$ 들을 $f(x)$ 의 계수Coefficient라 한다. $n &amp;lt; \infty$ 면 $n$ 을 $f(x)$ 의 차수Degree라 한다. $R[x]$ 는 $R$ 의 원소를 계수로 갖는 유한다항함수들을 모아놓은 집합이다. $$ R[x] := \left\{ a_{0} + a_{1} x + \cdots + a_{n} x^{n} \ | \ a_{0}, \cdots , a_{n} \in R \right\} $$ $R[[x]]$ 는 $R$ 의</description>
    </item>
    
    <item>
      <title>수치해석에서의 차분</title>
      <link>https://freshrimpsushi.github.io/posts/difference-in-numerical-analysis/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-in-numerical-analysis/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 시계열분석에서의 차분 **1. ** 전방차분 : ** $\Delta f(x) = f(x+h) - f(x)$ 그리고 $\Delta^{r+1} f(x) =\Delta^{r} f(x+h) - \Delta^{r} f(x)$ 2. 후방차분: $\nabla f(x) = f(x) - f(x- h)$ 그리고 $\nabla^{r+1} f(x) = \nabla^{r} f(x) - \nabla^{r} f(x- h)$ 일반적으로 계차Difference 란 수열 전반에서 사용하는 말이지만 수치해석에선 특히 두 노드포인트의 함숫값의 차를 말한다. 사실 고등학교때부터 계속</description>
    </item>
    
    <item>
      <title>환의 영인자가 멱등원이면 직합으로 나타낼 수 있다</title>
      <link>https://freshrimpsushi.github.io/posts/if-zero-divisor-of-ring-is-idempotent-then-it-can-be-represented-by-direct-sum/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-zero-divisor-of-ring-is-idempotent-then-it-can-be-represented-by-direct-sum/</guid>
      <description>정리 환 $R$ 의 영인자 $a$ 가 $a^2 = a$ 를 만족하면, 즉 멱등원이면 $$ R = a R \times (1-a)R $$ 설명 따로 환에 대한 직합을 정의하지 않아도 알 수 있을 정도로 수학다운 매력이 있는 정리다. 증명 Part (i). 존재성 $r \in R$ 에 대해 $$ ar \in aR \\ (1-a) r \in (1-a) R $$ 이며, $r = ar + (1-a)r$ 이므로 $R = a R \times (1-a)R$ 다. Part (ii). 유일성 $r_{1}, r_{2}, r_{3} , r_{4} \in R$ 에 대해 $$ \begin{align*} a r_{1} =&amp;amp; x_{1} \in aR \\ a r_{3} =&amp;amp; x_{2} \in aR \\ (1-a) r_{2} =&amp;amp; y_{1} \in</description>
    </item>
    
    <item>
      <title>R 에서 자료구조 뜯어보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/data-structure-in-r/</link>
      <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/data-structure-in-r/</guid>
      <description>개요 R에서 여러가지 함수를 사용하다보면 아래와 같이 친절하게 결과가 출력되는 경우를 자주 볼 수 있게 된다. 문제는 이 결과를 그냥 보는 게 아니라 아웃풋으로써 받아서 써먹고 싶을 때다. 예시 가령 위 스크린샷에서 잔차의 최댓값이 필요하면 그냥 15.9719을 베껴써도 되긴 한다. 하지만 수십 수백번을 반복하면서 각 분석에서 잔차의 최댓값이 궁금하다면</description>
    </item>
    
    <item>
      <title>영인자와 정역</title>
      <link>https://freshrimpsushi.github.io/posts/zero-divisior-and-integral-domain/</link>
      <pubDate>Sun, 11 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zero-divisior-and-integral-domain/</guid>
      <description>정의 1 환 $R$ 에 대해 $ab = 0$ 을 만족시키는 $0$ 이 아닌 $a,b \in R$ 을 영인자Zero Divisor라 한다. 단위원 $1 \ne 0$ 을 가진 $D$ 가 영인자를 가지지 않으면 정역Integral Domain이라 한다. 설명 영인자 $0$ 이 아닌 것끼리 곱해서 $0$ 이 되는 예시로는 $$ \begin{bmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} 0 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{bmatrix} = \begin{bmatrix} 0 &amp;amp; 0 \\ 0 &amp;amp; 0 \end{bmatrix} $$ 과 $2 \cdot 3 \equiv 0 \pmod{6}$ 등이 있다.</description>
    </item>
    
    <item>
      <title>1계 도함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-first-order-derivative/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-first-order-derivative/</guid>
      <description>정리1 아래의 두 조건을 가정하자. 임의의 구간 $0 \le t \le A$에서 함수 $f(t)$가 연속이고, 1계 도함수 $f&#39;(t)$가 부분적으로 연속이라고 하자. $t \ge M$일 때 $|f(t)| \le Ke^{at}$를 만족하는 실수 $a$와 양수 $K$, $M$이 존재한다. 그러면 $f$의 1계 도함수의 라플라스 변환 $\mathcal{L} \left\{ f&#39;(t) \right\}$가 $s&amp;gt;a$일 때 존</description>
    </item>
    
    <item>
      <title>F(as&#43;b)의 라플라스 역변환</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-laplace-transform-of-fas-b/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-laplace-transform-of-fas-b/</guid>
      <description>공식1 함수 $f(t)$의 라플라스 변환 $\mathcal{L} \left\{ f(t) \right\}= \displaystyle \int _0 ^\infty e^{-st}f(t)dt =F(s)$가 $s&amp;gt;\alpha \ge 0$일 때 존재한다고 가정하자. 그러면 상수 $a&amp;gt;0 , b$에 대해서 $F(as+b)$의 라플라스 역변환은 다음과 같다. $$ \mathcal{L^{-1}} \left\{ F(as+b) \right\} =\frac{1}{a}e^{-\frac{b}{a}t}f\left(\frac{t}{a}\right) $$ 유도 1 $F(ks)$의 라플라스 역변환: $$ \mathcal{L^{-1}} \left\{ F(ks) \right\} =\dfrac{1}{k}f\left(\frac{t}{k}\right) $$ 라플라스 변환의 평행이동: $$ \mathcal{L^{-1}} \left\{ F(s-c) \right\}=e^{ct}f(t) $$ 1. 에 의해서 다음을 얻는다.</description>
    </item>
    
    <item>
      <title>f(ct)의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-dilation/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-dilation/</guid>
      <description>공식1 함수 $f(t)$의 라플라스 변환 $\mathcal{L} \left\{ f(t) \right\} = \displaystyle \int _0 ^\infty e^{-st}f(t)dt = F(s)$가 $s&amp;gt;a \ge 0$일 때 존재한다고 가정하자. 그러면 $c &amp;gt;0$에 대해서 $f(ct)$의 라플라스 변환은 다음과 같다. $$ \mathcal{L} \left\{ f(ct) \right\} =\dfrac{1}{c}F\left(\dfrac{s}{c}\right), \quad s&amp;gt;ca $$ 유도 $$ \mathcal{L} \left\{ f(ct) \right\} = \int _0 ^\infty e^{-st}f(ct)dt $$ 여기서 $ct=\tau$라고 치환하자. 그러면 $st=\dfrac{s}{c}\tau$, $dt=\dfrac{1}{c}d\t</description>
    </item>
    
    <item>
      <title>F(ks)의 라플라스 역변환</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-laplace-transform-of-dilation/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-laplace-transform-of-dilation/</guid>
      <description>공식1 함수 $f(t)$의 라플라스 변환 $\mathcal{L} \left\{ f(t) \right\} = \displaystyle \int _0 ^\infty e^{-st}f(t)dt = F(s)$가 $s&amp;gt;a \ge 0$일 때 존재한다고 가정하자. 그러면 양수 $k&amp;gt; 0$에 대해서 $F(ks)$의 라플라스 역변환은 다음과 같다. $$ \mathcal{L^{-1}} \left\{ F(ks) \right\} =\dfrac{1}{k}f\left(\frac{t}{k}\right),\quad s&amp;gt;\frac{a}{k} $$ 유도 1 $f(ct)$의 라플라스 변환 $$ \mathcal{L} \left\{ f(ct) \right\} =\dfrac{1}{c}F\left(\dfrac{s}{c}\right), \quad s&amp;gt;ca $$ 위 식에서 $c$대신 $\dfrac{1}{k}$를 대입하면 $$ \begin{align*} \mathcal{L}</description>
    </item>
    
    <item>
      <title>n계 도함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-n-th-order-derivative/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-n-th-order-derivative/</guid>
      <description>정리1 아래의 두 조건을 가정하자. 임의의 구간 $0 \le t \le A$에서 함수 $f$, $f&#39;$, $\cdots$, $f^{(n-1)}$가 연속이고 n계 도함수 $f^{(n)}(t)$가 부분적으로 연속이라고 하자. $t \ge M$일 때 $|f(t)| \le Ke^{at}$, $|f&#39;(t)| \le Ke^{at}$, $\cdots$, $|f^{(n-1)}(t)| \le Ke^{at}$를 만족하는 실수 $a$와 양수 $K$, $M$이 존재한다. 그러면 $f$의 n계 도함수의 라플라스 변환 $\mathcal{L} \left\{ f^{(n)}(t) \r</description>
    </item>
    
    <item>
      <title>라플라스 변환을 이용한 2계 선형 비동차 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solving-second-order-linear-inhomogeneous-differential-equations-using-laplace-transform/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solving-second-order-linear-inhomogeneous-differential-equations-using-laplace-transform/</guid>
      <description>정리1 $$ ay&#39;&#39; + by&#39; + cy = g(t) $$ 위와 같은 2계 선형 비동차 미분방정식이 주어졌다고 하자. 그리고 $\mathcal{L} \left\{ y \right\} =Y(s)$, $\mathcal{L} \left\{ g(t) \right\}=G(s)$라고 하자. 그러면 $$ Y(s) = \dfrac{ (as + b)y(0) + ay&#39;(0) } {as^2+bs+c} + \dfrac{G(s) }{as^2+bs+c} $$ 설명 위 공식은 규칙만 잘 기억하면 외우기 쉽다. 규칙대로 외우면 3계, 4계의 경우를 포함하는 일반적인 공식까지도 쉽게 외울 수 있다. 위 결과는 n계 도함</description>
    </item>
    
    <item>
      <title>라플라스 변환의 평행이동</title>
      <link>https://freshrimpsushi.github.io/posts/translation-of-laplace-transform/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/translation-of-laplace-transform/</guid>
      <description>공식1 함수 $f(t)$의 라플라스 변환 $F(s)=\mathcal{L} \left\{ f(t) \right\}$가 $s&amp;gt;a$일 때 존재한다고 하자. 그러면 상수 $c$에 대해서 다음이 성립한다. $$ \begin{align*} \mathcal{L} \left\{ e^{ct}f(t) \right\}&amp;amp;=F(s-c), &amp;amp;s&amp;gt;a+c \\ \mathcal{L^{-1}} \left\{ F(s-c) \right\}&amp;amp;=e^{ct}f(t) &amp;amp; \end{align*} $$ 설명 $f$에 지수함수를 곱하는 것과 $F$를 평행이동하는 것이 같다는 의미이다. 유도 $$ \begin{align*} \mathcal{L} \left\{ e^{ct}f(t) \right\} &amp;amp;=\int_0^\infty e^{-st}e^{ct}f(t)dt \\ &amp;amp;= \int_0^\infty e^{-(s-c)t}f(t)dt \\ &amp;amp;= F(s-c) \end{align*} $$ ■ 따름정리 $$ \begin{align*} \mathcal{L} \left\{ e^{ct} t^p</description>
    </item>
    
    <item>
      <title>계단 함수</title>
      <link>https://freshrimpsushi.github.io/posts/step-functionheaviside-function/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/step-functionheaviside-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **계단 함수 정의역이 여러 개의 부분구간으로 나뉘어 질 때, 각 부분구간 내에서는 상수함수이며 부분구간의 경계에서 불연속인 함수를 계단 함수 라 한다. 아래의 그림을 보면 알겠지만 계단처럼 생겨서 계단 함수이다. Heaviside function 이라고도 하는데 헤비사이드는 사람 이름이다. 전기회로의 미분방정식을 푸는 방</description>
    </item>
    
    <item>
      <title>계단 함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-heaviside-step-function/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-heaviside-step-function/</guid>
      <description>정의1 단위 계단 함수를 $c$만큼 평행이동한 것을 다음과 같이 나타내자 $$ u_c(t)=\begin{cases} 0 &amp;amp; t&amp;lt;c \\ 1 &amp;amp; t \ge c \end{cases} $$ 공식 계단 함수 $u_{c}(t)$의 라플라스 변환은 다음과 같다. $$ \begin{equation} \mathcal{L} \left\{ u_c(t) \right\} = \dfrac{e^{-cs}}{s},\quad s&amp;gt;0 \label{eq1} \end{equation} $$ $c$를 임의의 상수, $s &amp;gt; a \ge 0$일 때 $f(t)$의 라플라스 변환 $F(s)$이 존재한다고 하자. 즉 $F(s)=\mathcal{L} \left\{ f(t) \right\}$. 그러면 $f$와 $u_{c}</description>
    </item>
    
    <item>
      <title>라플라스 변환의 정의와 존재성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-laplace-transform-and-proof-of-existence-of-laplace-transform/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-laplace-transform-and-proof-of-existence-of-laplace-transform/</guid>
      <description>정의1 함수 $f$의 라플라스 변환을 아래와 같이 정의한다. $$ \mathcal{L} \left\{ f(t) \right\} := \int _0^\infty e^{-st}f(t) dt =F(s) $$ 설명 라플라스 변환은 커널이 지수함수인 적분 변환이다 라플라스 변환을 이상적분으로 정의했기 때문에 수렴해야 라플라스 변환이 존재한다. 결론부터 말하자면 우리가 흔히 다루는 함수들은 전부 라플라스 변환이 가능하다. 상수함수, 다항함수, 지수함수, 삼각함수</description>
    </item>
    
    <item>
      <title>불리언 링</title>
      <link>https://freshrimpsushi.github.io/posts/boolean-ring/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/boolean-ring/</guid>
      <description>정의 1 $R$ 을 환이라고 하자. $r \in R$ 이 $r^2 = r$ 을 만족하면 $r$ 을 멱등원Idempotent Element이라 한다. $R$ 의 모든 원소가 멱원소면 $R$ 을 불리언 링Boolean Ring이라 한다. 설명 불리언 링을 순화하면 &amp;lsquo;불환&amp;rsquo;이지만 어감이 매우 좋지 못해 영어 발음을 그대로 썼다. 선형대수학에서의 사영이 유용한 성질</description>
    </item>
    
    <item>
      <title>제프리 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/jeffreys-prior/</link>
      <pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jeffreys-prior/</guid>
      <description>정의 1 자료의 분포 $p( y | \theta)$ 에 대해 $\pi ( \theta ) \propto I^{1/2} ( \theta )$ 를 제프리 사전분포Jeffreys Prior라 한다. $I$ 는 피셔정보Fishser Information를 의미한다. $$ I ( \theta ) = E \left[ \left( \left. {{\partial \ln p (y | \theta) } \over {\partial \theta}} \right)^2 \right| \theta \right] = E \left[ \left. - {{\partial^2 \ln p (y | \theta) } \over { (\partial \theta )^2 }} \right| \theta \right] $$ 설명 라플라스 사전분포 $\pi (\theta) \propto 1$ 는 모수 $\theta$ 의 사전분포로써</description>
    </item>
    
    <item>
      <title>추상대수학에서의 체</title>
      <link>https://freshrimpsushi.github.io/posts/field-in-abstract-algebra/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/field-in-abstract-algebra/</guid>
      <description>정의 1 환 $(R , + , \cdot)$ 이 곱셉 $\cdot$ 에 대한 항등원 $1 \in R$ 을 가질 때, $1$ 을 단위원Unity이라 한다. 단위원을 가진 환 $R$ 에서 곱셈에 대한 역원이 존재하는 원소 $r \ne 0$ 를 단원Unit이라 한다. 단위원을 가진 환 $R$ 에서 $0$ 이 아닌 모든 원소가 단원이면 상환Division Ring이라 한다. 곱셈에 대해 교환법칙이 성립하는 상환 $R$ 을 체Field라 한다</description>
    </item>
    
    <item>
      <title>라플라스 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-prior/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-prior/</guid>
      <description>빌드업 모수에 대한 정보가 거의 없다면 구태여 복잡한 사전분포를 생각할 이유는 없다. 내년 모 대학의 통계학과 신입생의 성비를 추측해보라고 했을 때, 통계학과를 어느정도 아는 사람이라면 예년의 성비를 보고 어느정도 짐작을 하겠지만 전혀 관계도 없고 관심도 없는 사람이 이 질문을 들었을 땐 특별한 이유가 없는 한 50:50이라고 추측할 것이다. 어떤 주머니</description>
    </item>
    
    <item>
      <title>리즈 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-riesz-lemma/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-riesz-lemma/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 놈드 스페이스 $(X , | \cdot | )$ 의 부분 공간 $Y \subsetneq X$ 에 대해 $Y$ 는 닫힌 집합이라고 하자. 모든 $\theta \in (0,1)$ 와 $y \in Y$ 에 대해 $| x_{ \theta } | = 1$ 와 $| x_{ \theta } - y | &amp;gt; \theta$ 를 만족하는 $x_{\theta} \in X$ 가 존재한다. 전략: 구체적인 $x_{\theta}$ 가 존재함을 보인 후 $| x_{ \theta } - y | &amp;gt; \theta$ 가 성립함을 보인다. 증명 $ x_{0 } \notin Y$ 면서 $ x_{0 } \in X$ 인</description>
    </item>
    
    <item>
      <title>민코프스키 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-minkowskis-inequality/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-minkowskis-inequality/</guid>
      <description>정리 두 벡터 $\mathbf{x}= (x_{1} , x_{2} , \dots , x_{n} )$ , $\mathbf{y} = (y_{1} , y_{2} , \dots , y_{n} )$ 와 $1$보다 큰 실수 $p$ 에 대해 다음의 식이 성립한다. $$ \left( \sum_{k=1}^{n} | x_{k} + y_{k} |^{p} \right)^{{1} \over {p}} \le \left( \sum_{k=1}^{n} |x_{k}|^{p} \right)^{{1} \over {p}} + \left( \sum_{k=1}^{n} |y_{k}|^{p} \right)^{{1} \over {p}} $$ 이를 민코프스키 부등식Minkowski&amp;rsquo;s inequality이라 한다. 설명 민코프스키 부등식은 $p$-놈의 정의에서 삼각부등식에 해당한다. 어떤</description>
    </item>
    
    <item>
      <title>다항함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-polynomial/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-polynomial/</guid>
      <description>공식1 $$ \mathcal{L} \left\{ t^p \right\} = \dfrac{ \Gamma (p+1) } {s^{p+1}},\quad s&amp;gt;0 $$ 설명 다항식의 라플라스 변환은 감마함수로 나타난다. $t^p$ 대신 익숙한 모양새인 $x^p$라고 하면 한 눈에 알아보기 쉬울 것이다. 보통 미분방정식에서 변수는 시간에 대해서 나타나므로 $x$대신 $t$를 썼다. 유도 $$ \begin{align*} \mathcal{L} \left\{ t^p \right\} &amp;amp;= \int_0^\infty e^{-st}t^p dt \\ &amp;amp;= \lim \limits_{A \to \infty} \left[ -\dfrac{1}{s} \left[ e^{-st}t^p \right] _0^A +\dfrac{p}{s} \int_0^A e^{-st}t^{p-1}dt \right] \\ &amp;amp;= \dfrac{p}{s} \mathcal{L} \left\{ t^{p-1} \right\} \\ &amp;amp;= \lim \limits_{A \to \infty} \left[ \dfrac{p}{s} \dfrac{-1}{s}\left[</description>
    </item>
    
    <item>
      <title>라플라스 변환 표</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-table/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-table/</guid>
      <description>공식1 라플라스 변환 표이다. $f(t)=\mathcal{L^{-1}}$ $F(s)=\mathcal{L} \left\{ f(t) \right\}$ 유도과정 $1$ $\dfrac{1}{s}$ 링크 $e^{at}$ $\dfrac{1}{s-a}$ 링크 $t^n$ $\dfrac{n!}{t^{n+1}}$ 링크 $t^{p}$ $\dfrac{ \Gamma (p+1) }{ s^{p+1}}$ 링크 $t^{p}e^{at}$ $\dfrac{ \Gamma (p+1) }{ (s-a)^{p+1}}$ 링크 $\sin (at)$ $\dfrac{a}{s^2+a^2}$ 링크 $\cos (at)$ $\dfrac{s}{s^2+a^2}$ 링크 $e^{at}\sin(bt)$ $\dfrac{b}{(s-a)^2 +b^2}$ 링크 $e^{at}\cos(bt)$ $\dfrac{s-a}{(s-a)^2+b^2}$ 링크 $\sinh (at)$ $\dfrac{a}{s^2-a^2}$ 링크 $\cosh (at)$ $\dfrac{s}{s^2-a^2}$ 링크 $e^{at} \sinh (bt)$ $\dfrac{b}{(s-a)^2-b^2}$ 링크 $e^{at} \cosh (bt)$ $\dfrac{s}{(s-a)^2-b^2}$ 링크 $u_c(t)= \begin{cases} 0 &amp;amp; t&amp;lt;c \\ 1 &amp;amp; t\ge c\end{cases}$ $\dfrac{e^{-cs}}{s}$ 링크 $u_c(t)f(t-c)$ $e^{-cs}F(s)$ 링크 $f&#39;(t)$ $s\mathcal{L} \left\{ f(t) \right\} -f(0)$ 링크 $f^{(n)}$ ${s^n\mathcal {L}\left\{ f(t) \right\} -s^{n-1}f(0) - \cdots -f^{(n-1)}(0) }$ 링크 $f(t)=f(t+T)$ $\dfrac{\displaystyle \int_0^T e^{-st}f(t)dt}{1-e^{-st}}$ 링크 $\delta(t-t_0)$ $e^{-st_0}$ 링크 $f(ct)$ $\frac{1}{c}F \left( \frac{s}{c} \right)$ 링크 $\frac{1}{k}f (\frac{t}{k} )$ $F(ks)$ 링</description>
    </item>
    
    <item>
      <title>라플라스 변환의 선형성</title>
      <link>https://freshrimpsushi.github.io/posts/linearity-of-laplace-transform/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearity-of-laplace-transform/</guid>
      <description>정리1 $f_1$과 $f_2$를 라플라스 변환이 존재하는 함수라고 하자. 그리고 $c_1, c_2$를 임의의 상수라고 하자.그러면 $$ \mathcal{L} \left\{ c_1f_1 + c_2f_2 \right\} = c_1\mathcal{L} \left\{f_1 \right\} + c_2\mathcal{L} \left\{f_2 \right\} $$ 설명 라플라스 변환이 적분변환이라 당연하다. 증명 $$ \begin{align*} \mathcal{L} \left\{ c_1f_1+c_2f_2 \right\} &amp;amp;= \int_0^\infty e^{-st} \left( c_1f_1+c_2f_2 \right) dt \\ &amp;amp;= \int_0^\infty e^{-st}c_1f_1 dt + \int _0^\infty e^{-st}c_2f_2 dt \\ &amp;amp;= c_1\int_0^\infty e^{-st}f_1 dt + c_2\int _0^\infty e^{-st}f_2 dt \\ &amp;amp;= c_1\mathcal{ L} \left\{ f_1 \right\} + c_2 \mathcal{ L} \left\{ f_2 \right\} \end{align*} $$ ■ William E. Boyce , Boyce&amp;rsquo;s Elementary Differential</description>
    </item>
    
    <item>
      <title>삼각함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-trigonometric-function/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-trigonometric-function/</guid>
      <description>공식1 사인과 코사인의 라플라스 변환은 다음과 같다. $$ \mathcal{L} \left\{ \sin (at) \right\} = \dfrac{a}{s^2+a^2},\quad s&amp;gt;0 $$ $$ \mathcal{L} \left\{ \cos (at) \right\} = \dfrac{s}{s^2+a^2},\quad s&amp;gt;0 $$ 유도 $\sin (at)$ $$ \begin{align*} \mathcal{L} \left\{ \sin (at) \right\}&amp;amp; =\displaystyle \int_0^\infty e^{-st}\sin(at)dt \\ &amp;amp;= \lim \limits_{A \to \infty} \left[-\dfrac{1}{a}e^{-st}\cos (at) \right]_0^A+ \lim \limits_{A \to \infty} \int _0^\infty -\dfrac{s}{a}e^{-st} \cos (at)dt \\ &amp;amp;= \dfrac{1}{a} - \lim \limits_{A \to \infty} \dfrac{s}{a} \left[ \dfrac{1}{a} \left[ e^{-st}\sin (at) \right]_0^A + \dfrac{s}{a}\int _0^A e^{-st} \sin (at) dt \right] \\ &amp;amp;=\dfrac{1}{a} - \dfrac{s^2}{a^2} \int_0^\infty e^{-st} \sin (at) dt \end{align*} $$ 여기서 $\mathcal{L} \left\{ \sin (at) \right\} = \displaystyle \int_0^\infty e^{-st} \sin (at) dt$가 성립하므로, $$ \begin{align*} \implies&amp;amp; &amp;amp;\dfrac{a^2+s^2}{a^2} \int _0^\infty e^{-st} \sin (at) dt &amp;amp;= \dfrac{1}{a} \\ \implies&amp;amp; &amp;amp;\int_0^\infty e^{-st} \sin</description>
    </item>
    
    <item>
      <title>상수함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-constant-function/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-constant-function/</guid>
      <description>공식1 $$ \mathcal{L} \left\{ 1 \right\} = \dfrac{1}{s},\quad s&amp;gt;0 $$ 유도 $$ \begin{align*} \mathcal{L}\left\{ 1 \right\} &amp;amp;= \int _0^\infty e^{-st} \cdot 1 dt \\ &amp;amp;= \lim \limits_{A \to \infty} \left[ -\dfrac{e^{-st}}{s} \right]_0^A \\ &amp;amp;= \lim \limits_{A \to \infty} \left[ -\dfrac{e^{-sA}}{s} +\dfrac{e^{-0t}}{s} \right] \\ &amp;amp;= \dfrac{1}{s} \end{align*} $$ 여기서 $\lim \limits_{A \to \infty}\dfrac{e^{-sA}}{s}=0$ 이어야 하기 때문에2 $s&amp;gt;0$이라는 조건이 추가된다. ■ 같이보기 라플라스 변환 표 William E. Boyce , Boyce&amp;rsquo;s Elementary Differential Equations and Boundary Value Problems (11th Edition, 2017), p245 &amp;#x21a9;&amp;#xfe0e; 셋째줄 첫째항이 발산하는 것을 막기 위한 조건. &amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>쌍곡함수의 라플라스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-hyperbolic-function/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-hyperbolic-function/</guid>
      <description>공식1 쌍곡사인함수와 쌍곡코사인함수의 라플라스 변환은 다음과 같다. $$ \mathcal{L} \left\{ \sinh (at) \right\} = \dfrac{a}{s^2-a^2},\quad s&amp;gt;|a| \\ \mathcal{L} \left\{ \cosh (at) \right\} = \dfrac{s}{s^2-a^2},\quad s&amp;gt;|a| $$ 설명 쌍곡함수의 정의는 다음과 같다. $$ \sinh (ax) = \dfrac{ e^{ax} - e^{-ax} }{ 2 } \\ \cosh (ax) = \dfrac{ e^{ax} + e^{-ax} }{ 2 } $$ 유도 지수함수의 라플라스 변환 결과를 이용한다. $\sinh (at)$ $$ \begin{align*} \mathcal{ L } \left\{ \sinh (at) \right\} &amp;amp;= \int_0^\infty e^{-st} \sinh (at) dt \\ &amp;amp;= \int _0 ^\infty e^{-st} \left( \dfrac{ e^{at} - e^{-at} }{ 2 } \right) dt \\ &amp;amp;= \dfrac{1}{2}\int _0^\infty e^{-st}e^{at} dt -\dfrac{1}{2}\int</description>
    </item>
    
    <item>
      <title>지수함수의 라플라스 변환 </title>
      <link>https://freshrimpsushi.github.io/posts/laplace-transform-of-exponential-function/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-transform-of-exponential-function/</guid>
      <description>공식1 $$ \mathcal {L} \left\{ e^{at} \right\} = \dfrac{1}{s-a},\quad s&amp;gt;a $$ 설명 상수함수의 라플라스 변환 결과와 비교해보자. $$ \mathcal{L} \left\{ 1 \right\} =\dfrac{1}{s} $$ $e^{at}$의 라플라스 변환 결과는 $f(t)=1$일 때 $F(s)$가 $a$만큼 평행이동한 것과 같다. 당연할 수 밖에 없는 것이 원래 함수에 $e^{at}$가 곱해지면 $\displaystyle \int e^{-st}f(t) dt$가$\displaystyle \int e^{-(s-a)t} f(t) dt$로 되기</description>
    </item>
    
    <item>
      <title>켤레사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/conjugate-prior/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conjugate-prior/</guid>
      <description>정의 1 사전분포와 사후분포가 동일한 분포족에 속하면 사전분포를 켤레사전분포Conjugate Prior 혹은 공액사전분포라고 한다. 설명 베이지안이란 본래 사전분포가 어떻게 되든 업데이트를 통해 모수를 찾아가는 것이긴 하지만, 모형에 대해 어느정도 아는 바가 있다면 적절한 사전분포를 사용함으로써 수학적 계산을 간단하게 하고 결과를 이해하기 쉽게 할</description>
    </item>
    
    <item>
      <title>유한 차원 놈드 스페이스는 완비성을 가짐을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/finite-dimentional-normed-space-is-complete/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finite-dimentional-normed-space-is-complete/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 유한 차원 놈드 스페이스는 완비성을 가진다. 이에 따라 유한 차원 벡터 스페이스는 놈이 정의되는 것만으로 바나흐 공간이 된다. 대표적으로 많이 쓰이는 $\mathbb{R}^{n}$ 혹은 $\mathbb{C}^{n}$ 이 있기 때문에 특히 유용한 팩트다. 전략: 유한차원 벡터 스페이스라는 점을 이용해 모든 벡터를 베이시스 단위로 찢은 후 다루기 편한 놈을 정의한</description>
    </item>
    
    <item>
      <title>라플라스 계승 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</guid>
      <description>정리 1 이항모형 $\displaystyle p(y | \theta) = \pmatrix{ n \\ y} \theta^{y} (1- \theta)^{n-y}$ 의 사전분포가 일양 분포 $U (0,1)$ 를 따르고 사후분포가 베타 분포 $\beta (y+1 , n-y+1)$ 을 따라 $p( \theta | y ) \sim \theta^{y} (1- \theta)^{n-y}$ 이라고 하자. 그러면 이제까지 얻은 데이터 $y$ 에 대해 새로운 $\tilde{y}$ 가 $1$ 일 확률은 $$ p(\tilde{y} = 1| y) = {{y+1} \over {n+2}} $$ 설명 프리퀀티스트의 관점으로 보았을 때 $\tilde{y} = 1$ 일 확률은 그 표본비율 $\displaystyle {{y} \over {n}}$ 에 가까울 것이다. 그런데 기본적으</description>
    </item>
    
    <item>
      <title>유한 차원 벡터 스페이스 상에서 정의된 모든 놈은 동치임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-relation-of-norm-defined-in-finite-dimentional-vector-space/</link>
      <pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-relation-of-norm-defined-in-finite-dimentional-vector-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 유한 차원 벡터 스페이스 상에서 정의된 모든 놈은 동치다. 유클리드 공간 상에서 정의된 모든 놈은 동치라는 사실은 본 정리의 따름 정리에 해당한다. 전략: $c | v | _{\alpha} \le | v | _{\beta} \le C | v | _{\alpha}$ 를 만족하는 $c , C &amp;gt;0$ 가 존재함을 보이면 두 놈 $| \cdot |_{\alpha}$ 와 $| \cdot |_{\beta}$ 는 동치다. 최대최소값 정리를 통해 $\displaystyle { { | v |</description>
    </item>
    
    <item>
      <title>유한 차원 놈드 스페이스는 베이시스를 가짐을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/finite-dimentional-normed-space-have-basis/</link>
      <pubDate>Mon, 29 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finite-dimentional-normed-space-have-basis/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 모든 유한 차원 놈드 스페이스는 베이시스를 가진다. 특정 조건을 만족하는 베이시스도 아니고 베이시스의 존재성을 밝힌다는 것이 생소하겠지만, 실제로 베이시스의 정의만을 보아서는 모든 벡터 스페이스가 베이시스가 존재한다고 한 적이 없다. 유한 차원을 정의하기에 따라서는 별도로 증명이 필요없을 정</description>
    </item>
    
    <item>
      <title>노름 놈의 동치관계</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-relation-of-norm/</link>
      <pubDate>Sun, 28 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-relation-of-norm/</guid>
      <description>정의 벡터공간 $V$ 상에서 정의된 두 놈 $\left\| \cdot \right\|_{\alpha}, \left\| \cdot \right\|_{\beta}$과 임의의 벡터 $\mathbf{v} \in V$ 에 대해 $$ c \left\| \mathbf{v} \right\|_{\alpha} \le \left\| \mathbf{v} \right\|_{\beta} \le C \left\| \mathbf{v} \right\|_{\alpha} $$ 를 만족하는 $c , C &amp;gt;0$ 이 존재하면 두 놈은 서로 동치라 정의한다. 설명 두 놈이 서로 동치라는 것은 놈을 이용한 부등식을 다룰 때 서로 다른 놈을 사용해도 문제가 없다는 말이다. 당연히 사용하기 어려운 놈을 사용</description>
    </item>
    
    <item>
      <title>유한 차원 벡터 공간의 하멜 베이시스</title>
      <link>https://freshrimpsushi.github.io/posts/hamel-basis-of-finite-dimensional-vector-space/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hamel-basis-of-finite-dimensional-vector-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 선형대수학에서 벡터의 선형독립과 기저, 차원무한 차원 벡터 공간의 기저 : 샤우더 베이시스 벡터 공간 $X$ 가 주어져 있다고 하자.**1. $X$ 의 벡터 $x_{1} , \cdots , x_{n}$ 와 스칼라 $\alpha_{1} , \cdots , \alpha_{n}$ 에 대해 $\alpha_{1} x_{1} + \cdots + \alpha_{n} x_{n}$ 를 벡터 $x_{1} , \cdots , x_{n}$ 들의 선형 결합이라 한다.**2. $M = \left\{ x_{1} , \cdots , x_{n} \right\}$ 이라 할 때 $M$ 의 모든 벡</description>
    </item>
    
    <item>
      <title>직교여공간</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-complement/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-complement/</guid>
      <description>정의1 벡터공간 $V$ 의 부분공간 $W$ 에 대해서 집합 $$ W^{\perp} = \left\{ \mathbf{v} \in V \ : \left\langle \mathbf{v} , \mathbf{w} \right\rangle = 0,\quad \forall \mathbf{w} \in W \right\} $$ 를 $W$ 의 직교여공간orthogonal complement이라한다. 이때 $\langle , \rangle$ 는 내적이다. 설명 다시말해 $W^{\perp}$은 $W$ 의 모든 원소와 수직인 벡터를 모아놓은 집합이다. 기호 $^{\perp}$ 는 perpendicular를 줄여서 per</description>
    </item>
    
    <item>
      <title>바나흐 공간</title>
      <link>https://freshrimpsushi.github.io/posts/banach-space/</link>
      <pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/banach-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 선형대수학에서의 벡터공간선형대수학에서의 놈거리공간의 완비성 컴플리트 놈드 스페이스를 바나흐 스페이스라 정의한다. 바나흐 스페이스는 아래의 각 호를 모두 만족시킨 공간으로써 거리 함수가 정의되는데다 완비성을 갖춰 아주 유용한 공간이다. 강하다면 강한 조건들을 만족시켜야 하는 것은 사실이</description>
    </item>
    
    <item>
      <title>횔더 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-hoelders-inequality/</link>
      <pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-hoelders-inequality/</guid>
      <description>정의 $\dfrac{1}{p} + \dfrac{1}{q} = 1$ 을 만족하고 1보다 큰 두 상수 $p, q$ 와 $\mathbf{u}, \mathbf{v} \in \mathbb{C}^n$에 대해 다음의 부등식이 성립한다. $$ | \left\langle \mathbf{u}, \mathbf{v} \right\rangle | = |\mathbf{u} ^{\ast} \mathbf{v}| \le ||\mathbf{u}||_{p} ||\mathbf{v}||_{q} $$ 이를 횔더 부등식Hoelder&amp;rsquo;s inequality이라 한다. 설명 원래는 Hölder&amp;rsquo;s inequality로 써야하지만 움라우트가 있어 대체표</description>
    </item>
    
    <item>
      <title>베이지안 패러다임</title>
      <link>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</guid>
      <description>빌드업 통계학이란 &amp;lsquo;모수를 파악하는 방법을 연구하는 학문&amp;rsquo;이라고 할 수 있다. 어떤 물리량을 측정하는 것처럼 공식이나 법칙을 통해 정확하게 모수를 추정할 수 있다면 더할나위 없지만, 현실적으로 그게 불가능하기 때문에 가정과 표본을 이용해 &amp;lsquo;모수로 예상되는 것&amp;rsquo;을 찾아낼 뿐이다. 우리나라 남성</description>
    </item>
    
    <item>
      <title>영의 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-youngs-inequality/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-youngs-inequality/</guid>
      <description>정리 $\displaystyle {{1} \over {p}} + {{1} \over {q}} = 1$ 을 만족하고 1보다 큰 두 상수 $p,q$와 두 양수 $a,b$ 에 대해 $$ ab \le { {a^{p}} \over {p} } + {{b^{q}} \over {q}} $$ 설명 대수적으로 모양이 아름다운 점을 빼면 횔더 부등식을 증명하는 것 외엔 크게 언급되지 않는 부등식이다. 증명 $a$와 $b$ 모두 양수이므로 $a = e^A, b = e^B$ 를 만족하는 실수 $A,B$ 가 존재한다. 볼록함수의 이계도함수 $f$ 가 $I$ 에서 두 번 미분가능</description>
    </item>
    
    <item>
      <title>피=∞ 일 때 피-놈이 맥시멈 놈이 됨을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-p-norm-is-maximum-norm-when-p-is-infinity/</link>
      <pubDate>Sun, 21 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-p-norm-is-maximum-norm-when-p-is-infinity/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $1 &amp;lt; p_{0} &amp;lt; \infty$ 에 대해 $\left\{ x_{n} \right\}_{n \in \mathbb{N} } \in \mathcal{l}^{p_{0}}$ 라고 하면 $\displaystyle \lim_{p \to \infty} \left( \sum_{n \in \mathbb{N} } | x_{n} |^{p} \right)^{ {{1} \over {p}} } = \sup_{n \in \mathbb{N}} | x_{ n } | $ 맥시멈 놈은 해석학이나 선형대수학 등에서 꽤 일찍 접함에도 불구하고 왜 하필 $\infty$ 와 관계가 있는지 그 설명을 찾기가 어렵다. 다행스러운 점은 그냥 증명이 가능하는 것이다. 증명 $\displaystyle M := \sup_{n \in \mathbb{N}} |</description>
    </item>
    
    <item>
      <title>베이즈 정리로 보는 몬티홀 딜레마</title>
      <link>https://freshrimpsushi.github.io/posts/monty-hall-dilemma/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monty-hall-dilemma/</guid>
      <description>설명 알다시피 몬티홀 게임은 실제로 경품이 어디있든 관계 없이 선택을 바꾸는 것이 유리하다. 이것을 팩트로써 받아들이냐와 별개로 몬티홀 게임을 직관적으로 이해하지 못했거나 수식적인 표현이 서툰 사람들이 있다. 편의상 본인이 플레이어고, 1번 문을 선택했다고 생각해보자. 이 때 우리는 경품에 대한 어떤 정보도 없기에, 어떤 번호든 선택할 확률은 같다고</description>
    </item>
    
    <item>
      <title>옌센 부등식의 유한 폼 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-finite-form-of-jensens-inequality/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-finite-form-of-jensens-inequality/</guid>
      <description>정리 $I \subset \mathbb{R}$ 에서 컨벡스 함수 $f : I \to \mathbb{R}$ 와 $\displaystyle \sum_{k=1}^{n} \lambda_{k} = 1, \lambda_{k}&amp;gt;0$ 에 대해 $$ f( \lambda_{1} x_{1} + \lambda_{2} x_{2} + \cdots + \lambda_{n} x_{n} ) \le \lambda_{1} f( x_{1}) + \lambda_{2} f( x_{2}) + \cdots + \lambda_{n} f( x_{n} ) $$ 설명 옌센의 부등식은 컨벡스 함수의 대표적인 응용으로써 여러 분야에서 폭넓게 사용되고 있다.유한 폼은 원래 컨벡스의 정의에서 점의 갯수와 가중치에 대해 일반화가 이루어진 모양을 하고 있다. 증명 전략: 컨벡스 함수의 정의</description>
    </item>
    
    <item>
      <title>선형대수학에서 노름 혹은 놈이란</title>
      <link>https://freshrimpsushi.github.io/posts/norm-in-linear-algebra/</link>
      <pubDate>Sat, 06 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-in-linear-algebra/</guid>
      <description>정의 $V$를 $\mathbb{F}$ 상에서의 벡터공간이라고 하자. $\left\| \cdot \right\| : V \to \mathbb{F}$ 가 $\mathbf{u}, \mathbf{v} \in V$와 $k \in \mathbb{F}$ 에 대해서 다음 세 조건을 만족시키면 $\left\| \cdot \right\|$ 을 $V$ 상에서의 놈이라고 정의한다. (i) 정부호: $\left\| \mathbf{u} \right\| \ge 0$ 이고 $\mathbf{u} = \mathbb{0} \iff \left\| \mathbf{u} \right\| = 0$ (ii) 동질성: $\left\|k \mathbf{u} \right\| = | k | \left\| \mathbf{u} \right\| $ (iii) 삼각부등식: $\left\| \mathbf{u} + \mathbf{v}\right\| \le \left\|\mathbf{v} \right\| + \left\| \mathbf{u} \right\|$ 설명 Norm은 절댓값에서 출발해 추상화된 개념으로,</description>
    </item>
    
    <item>
      <title>부분환의 정의와 부분환 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-subring-and-subring-test/</link>
      <pubDate>Wed, 03 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-subring-and-subring-test/</guid>
      <description>정의 1 환 $R$의 부분 집합 $S$가 환 $R$의 연산에 대해서 환의 조건을 만족할 때, $S$를 $R$의 부분환$\mathrm{Subring}$이라고 한다. 한편 $\left\{ 0 \right\}$과 $R$은 환 $R$의 부분환임이 자명하므로 $\left\{ 0 \right\}$과 $R$을 자명한 부분환($\mathrm{trivial\ subri</description>
    </item>
    
    <item>
      <title>추상대수학에서의 환</title>
      <link>https://freshrimpsushi.github.io/posts/ring-in-algebra/</link>
      <pubDate>Wed, 03 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ring-in-algebra/</guid>
      <description>정의 1 두 이항연산 덧셈$+$과 곱셈$\cdot$에 대해서 아래와 같은 규칙을 만족하는 집합 $R$을 환 이라고 정의한다. $a$, $b$, $c$가 $R$의 원소일 때, 덧셈에 대하여 교환법칙이 성립한다. $$a+b=b+a$$ 덧셈에 대하여 결합법칙이 성립한다. $$(a+b)+c=a+(b+c)$$ 덧셈에 대한 항등원이 존재한다. $$\forall a \ \exists 0\ \ \mathrm{s.t} \ a+0=a$$ 모든 원소의 덧셈에 대한 역원이 존재한다. $$\forall a \ \exists -a\ \</description>
    </item>
    
    <item>
      <title>환에서 곱셈에 대한 규칙</title>
      <link>https://freshrimpsushi.github.io/posts/rules-of-multiplication-of-ring/</link>
      <pubDate>Wed, 03 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rules-of-multiplication-of-ring/</guid>
      <description>정리 $a,\ b,\ c$가 환 $R$의 원소이고 $0$이 덧셈에 대한 항등원이라고 하면 아래의 성질이 성립한다. $a0=0a=0$ $a(-b)=(-a)b=-(ab)$ $(-a)(-b)=ab$ $a(b-c)=ac-ac \ \ \And\ \ (b-c)a=ba-ca$ 에 대한 항등원인 단위원 $1$이 존재하면 아래의 성질 또한 성립한다. $(-1)a=-a$ $(-1)(-1)=1$ 증명 1. 덧셈에 대한 항등원과 어떤 원소를 곱해도 다시 덧셈에 대한 항등원이 된다는 내용이다. $$ a0=a(0+0)=a0+a0 $$ 이 때 $a0$는 환 $R$의 원소이므로 덧셈에 대한 역</description>
    </item>
    
    <item>
      <title>엘피 공간</title>
      <link>https://freshrimpsushi.github.io/posts/lp-space/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lp-space/</guid>
      <description>정의 🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $1 \le p &amp;lt; \infty$ 에 대해 거리공간 $( \mathcal{l}^{p} , d^{p} )$ 는 다음과 같이 정의된다. (i) 수렴하는 수열의 집합**: $\displaystyle \mathcal{l}^{p} := \left\{ \left\{ x_{n} \right\}_{n \in \mathbb{N}} \subset \mathbb{C} \ \left| \ \left( \sum_{i=1}^{\infty} | x_{i} |^{p} \right)^{{1} \over {p}} &amp;lt; \infty \right. \right\}$ (ii) 거리 함수**: $\displaystyle d^{p} ( x_{n} , y_{n} ) := \left( \sum_{i = 1}^{\infty} | x_{i} - y_{i} |^{p} \right)^{ {{1} \over {p}} }$ 단, $\left\{ x_{n} \right\} , \left\{ y_{n} \right\} \in \mathcal{l}^{p}$ $p = \infty$ 에 대해 거리공간 $( \mathcal{l}^{\infty} , d^{\infty} )$ 는 다</description>
    </item>
    
    <item>
      <title>R 에서 리스트 해체하기, 중복 성분 제거하기</title>
      <link>https://freshrimpsushi.github.io/posts/unlist-unique/</link>
      <pubDate>Sun, 23 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unlist-unique/</guid>
      <description>개요 온갖가지 정제되지 않은 데이터를 상대할 일이 많은 R 에서 리스트 자료형은 데이터를 정리하는데에 특히 유용하다. 그러나 반대급부로 데이터에 접근하는 것이 조금 번거롭고 원하는 내용을 찾는데에 불리한 점이 있다. 이때 unlist() 함수를 통해 리스트 자료형을 깨주면 이러한 조작이 한결 편해진다. unique() 함수는 받은 배열에서 중복되는 원소를 모두 제거하고 하나씩만</description>
    </item>
    
    <item>
      <title>잉여류의 성질과 그 증명</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-cosets-and-its-proof/</link>
      <pubDate>Fri, 21 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-cosets-and-its-proof/</guid>
      <description>정리 $H$를 군 $G$의 부분군이라고 하자. 그러면 군 $G$의 원소 $a$에 대해서 집합 $aH= \left\{ ah | h\in H \right\}$를 좌잉여류$\mathrm{left\ coset}$라 한다. $Ha = \left\{ ha | h\in H \right\}$를 우잉여류$\mathrm{right\ coset}$라 한다. $H &amp;lt; G, \ \ a,b \in G, \ \ h \in H$라고 하자.</description>
    </item>
    
    <item>
      <title>다양체란</title>
      <link>https://freshrimpsushi.github.io/posts/manifold-in-topology/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/manifold-in-topology/</guid>
      <description>정의 1 위상공간 $X$가 아래의 세 조건을 만족시킬 때 $X$를 $n$차원 매니폴드Manifold라 한다. (i): 제 2가산이다. (ii): 하우스도르프이다. (iii): $X$의 모든 점이 $\mathbb{R}^{n}$ 의 열린집합과 위상동형인 네이버후드를 가진다. $n$차원 매니폴드 $X$ 가 다음 두 가지 유형의 점들을 가질 때 $X$ 는 바운더리를 가진다고 한다. (1) 인테리어 포인트: 모든 $x \in X^{\circ}$</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 등분산성</title>
      <link>https://freshrimpsushi.github.io/posts/homoscedasticity-of-standard-residuals/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homoscedasticity-of-standard-residuals/</guid>
      <description>진단법 1 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 등분산성을 확인하려면 잔차들의 흩어진 모양이 전체적으로 고른지 확인하면 된다. 흔히 볼 수 있는 등분산성 결여의 예로써 다음의 두가지 경우가 대표적이다. 뒤로 갈수록 분산이 커지는 꼴인데, 이런 경우 변환이나 가중치를 도입함으로써 해결해야한다. 정말 쉽게 해결되느냐와</description>
    </item>
    
    <item>
      <title>피보나치 수열의 일반항 유도</title>
      <link>https://freshrimpsushi.github.io/posts/the-general-term-of-fibonacci-sequence/</link>
      <pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-general-term-of-fibonacci-sequence/</guid>
      <description>정리 수열 $\left\{ F_{n} \right\}$ 이 $F_{n+1} := F_{n} + F_{n-1}$ 과 같이 정의되어있다고 하자. $F_{0} = F_{1} = 1$ 이면 $\displaystyle r_{0} : = {{1 + \sqrt{5} } \over {2}}$ 와 $\displaystyle r_{1} : = {{1 - \sqrt{5} } \over {2}}$ 에 대해 $$ \displaystyle F_{n} = {{ {r_{0}}^{n+1} - {r_{1}}^{n+1} } \over { r_{0} - r_{1} }} $$ 설명 피보나치 수열의 일반항은 비네 공식Binet Formula이라 부르기도 한다.피보나치 수열은 워낙 많은 성질을 가지고 있고 생각지도 못한 부분에서 응용이 되기도 한다. 아</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 선형성</title>
      <link>https://freshrimpsushi.github.io/posts/linearity-of-standard-residuals/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearity-of-standard-residuals/</guid>
      <description>진단법 1 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다.선형성이 있는지 확인하려면 $0$ 을 중심으로 잔차들이 대칭적으로 나타나는지 확인하면 된다. 오른쪽 그림을 보면 누가봐도 선형성이 결여되어있음을 확인할 수 있다. 만약 단순회귀분석이었다면 위와 같이 데이터의 경향을 전혀 설명할 수 없는 결과를 낳는다. 주의해야할 형태들로</description>
    </item>
    
    <item>
      <title>회귀분석의 모형진단</title>
      <link>https://freshrimpsushi.github.io/posts/model-diagnostic-of-regression-analysis/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/model-diagnostic-of-regression-analysis/</guid>
      <description>필요성 단순회귀분석의 경우엔 독립변수와 종속변수를 고려해봤자 $2$ 차원이기 때문에 분석이 제대로 되었는지 한 눈에 확인할 수 있다. 하지만 다중회귀분석의 경우 $3$ 차원을 넘어가면 그림으로 그리기 어려워 때문에 분석이 정말 잘 맞는지 확인하기 어렵다. 회귀분석의 가정을 제대로 만족시키지 못했지만 가설검정은 통과하는 경우가 있는데, 이 경우 분석은 그냥</description>
    </item>
    
    <item>
      <title>파푸스-굴딘 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pappus-guldinus-theorem/</link>
      <pubDate>Sat, 08 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pappus-guldinus-theorem/</guid>
      <description>정리 $yz$-평면 상의 도형 $F$ 의 넓이를 $A$ 라고 하고 $F$ 를 $z$-축으로 회전시켜서 얻은 회전체 $W$ 의 부피를 $V$ 라고 하자. $z$-축과 $F$ 의 무게중심 사이의 거리를 $r$ 이라고 하면 $$ V = 2 \pi r A $$ 설명 파푸스-굴딘 정리는 고등학교 수준으로는 증명할 수 없지만 회전체에 대해 배울때 선생님들이 심심찮게 언급하는 정리다. 막상 학부수준의 수학을 공부</description>
    </item>
    
    <item>
      <title>회귀계수의 F검정 F-test for Regression Coefficient</title>
      <link>https://freshrimpsushi.github.io/posts/672/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/672/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 다중회귀분석R 에서 다중회귀분석 결과 $n$ 개의 관측치와 $p$ 개의 독립변수에 대한 다중회귀분석에 대해 $i=0,1,\cdots,p$ 라고 하자. $H_{0}$ : $\beta_{1} = \beta_{2} = \cdots = \beta_{p} = 0$ 즉, 모든 독립변수가 종속변수과 관계 없다. $H_{1}$ : $\beta_{1} , \beta_{2} , \cdots , \beta_{p}$ 중 적어도 하나는 $ 0$ 이 아니다. 즉, 종속변수와 관계 있는 독립변수가 존재한다. $\displaystyle F = {{</description>
    </item>
    
    <item>
      <title>R 에서 다중회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</link>
      <pubDate>Wed, 05 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</guid>
      <description>데이터 탐색 tail(attitude) R에서 내장데이터 attitude를 불러와 tail() 함수를 통해 확인해보자. 우리는 rating을 종속변수로 두고 다른 독립변수들이 rating에 어떤 영향을 얼마나 미치는지에 관심이 있다. 데이터만 봐서는 rating과 다른 변수들 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph() plot(attitude) 그냥 plot() 함수에 데이터</description>
    </item>
    
    <item>
      <title>R 에서 그래프 그릴 때 사용하는 심볼들</title>
      <link>https://freshrimpsushi.github.io/posts/symbols-for-plots-in-r/</link>
      <pubDate>Tue, 04 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/symbols-for-plots-in-r/</guid>
      <description>코드 각종 그래프 관련 함수에서 찍히는 점의 모양을 바꿀 때 pch 옵션을 사용한다. 위 그림은 특히 자주 쓰는 심볼들을 한 눈에 볼 수 있게 나타낸 것이다.쓸만한 게 많지만 특히 16번이 자주 쓰이며, 25번 이후에도 일단 마크 자체는 정해져 있으나 쓸만한 게 없다. 아래 예제 코드에서 sym을 26부터 50으로 고치고 확인해볼 수 있다. 한편 21번부터 25번은 bg</description>
    </item>
    
    <item>
      <title>쉴로브 정리</title>
      <link>https://freshrimpsushi.github.io/posts/sylow-theorem/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sylow-theorem/</guid>
      <description>정리 1 소수 $p$ 와 $\gcd (p, m) = 1$ 을 만족하는 어떤 자연수 $m$ 에 대해 $G$ 가 $|G| = p^{n} m$ 인 유한군이라고 하자. $G$ 의 $p$-부분군 중 다른 $p$-부분군에 포함되지 않는 $p$-부분군을 쉴로브 $p$-부분군이라고 한다. 제1쉴로브 정리: $G$ 는 $i=1, \cdots , n$ 에 대해 $|P| = p^{i}$ 를 만족하는 $p$-부분군이 존재한다. 제2쉴로브 정리: $G$ 의 쉴로브 $p$-부분군</description>
    </item>
    
    <item>
      <title>R 에서 그림에 문자열 찍는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-print-text-in-plot/</link>
      <pubDate>Sun, 02 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-print-text-in-plot/</guid>
      <description>코드 text() 함수를 통해 그래프에 문자열이 찍히도록 할 수 있다. 첫번째 옵션은 $x$ 축 좌표의 벡터, 두번째 옵션은 $y$ 축 좌표의 벡터, 세번째 옵션은 입력될 문자열의 벡터를 받는다. 아래의 예제코드에서 t만 바꿔가면서 실행시켜보면 바로 이해가 될 것이다. win.graph(6,5) plot(x=0,y=0,xlim=c(-1,5),ylim=c(-1,4),xlab=&amp;quot;x&amp;quot;,ylab=&amp;quot;y&amp;quot;) points(4,3,col=&amp;quot;red&amp;quot;,pch=19) #1 abline(h=0) #2 abline(v=0) #3 abline(0,3/4) #4 segments(4,0,4,3) x=c(2,-0.2,2,4.2) y=c(-0.2,2,2,2) t=c(&amp;quot;(1)&amp;quot;,&amp;quot;(2)&amp;quot;,&amp;quot;(3)&amp;quot;,&amp;quot;(4)&amp;quot;) t=c(&amp;quot;(하나)&amp;quot;,&amp;quot;(둘)&amp;</description>
    </item>
    
    <item>
      <title>다중회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/multiple-linear-regression/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiple-linear-regression/</guid>
      <description>개요 회귀분석이란 변수 사이의 관계를 알아내는 방법으로써, 특히 선형 관계를 밝히는 데 유용하다. 다중회귀분석Multiple Linear Regression은 하나의 종속변수(반응변수) 에 복수의 독립변수(설명변수) 가 미치는 영향을 파악하는 회귀분석을 말한다. 모델 1 $$Y = \beta_{0} + \beta_{1} X_{1} + \cdots + \beta_{p} X_{p} + \varepsilon $$ 우리는 변수들이 위와 같은 선형관계를 가지</description>
    </item>
    
    <item>
      <title>몫 공간</title>
      <link>https://freshrimpsushi.github.io/posts/quotient-space/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quotient-space/</guid>
      <description>정의 1 위상공간 $(X, \mathscr{T} )$ 와 동치 관계 $\sim$ 에 대해 동치류를 $[x] = \left\{ y \in X \ | \ x \sim y \right\}$ 이라 하자. $X / \sim$ 을 몫 집합이라 정의한다. $q : X \to X / \sim$ 을 $q(x) = [ x ]$ 로 정의하면 몫 함수라 부른다. $U \in \mathscr{T}$ 에 대해 $$ \displaystyle q^{-1} (U) = \bigcup_{[ x ] \in U} [ x ] \iff U \in \mathscr{T_{\sim}} $$ 이라고 하자. $\mathscr{T_{\sim}}$ 을 몫 위상이라 하고, $( X/ \sim , \mathscr{T_{\sim}} )$ 을 모듈러 $\sim$ 에서 $X$ 의 몫 공간이라 정의한다. $A \subset X$ 에</description>
    </item>
    
    <item>
      <title>R 에서 수평선 수직선 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-draw-horizontal-or-vertical-line-in-r/</link>
      <pubDate>Thu, 30 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-draw-horizontal-or-vertical-line-in-r/</guid>
      <description>예시 1. abline(h=0) 수평선을 긋는다. 2. abline(v=0) 수직선을 긋는다. 3. abline(0,3/4) $y$ 절편이 $0$ 이고 기울기가 $3/4$ 인 직선을 긋는다. 애초에 abline() 함수 자체가 $y=a+bx$ 의 계수인 $a,b$ 에서 이름을 따온 것이다. 통계를 목적으로 R 을 쓰고 있다면 막상 회귀직선을 그릴 때 빼곤 쓸 일이 없다. segments(4,0,4,3) $(4,0)$ 에서 $(4,3)$ 으로 이어지는 선분을 그린다.깔끔하게 필요한 부분만 그리고 싶을때 필요하다. win.graph(6,5) plot(x=0,y=0,xlim=c(-1,5),ylim=c(-1,4),xlab=&amp;quot;x&amp;quot;,ylab=&amp;quot;y&amp;quot;) points(4,3,col=&amp;quot;red&amp;quot;,pch=19) #1 abline(h=0) #2 abline(v=0) #3 abline(0,3/4)</description>
    </item>
    
    <item>
      <title>군론에서의 코시 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/cauchys-theorem/</link>
      <pubDate>Wed, 29 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchys-theorem/</guid>
      <description>정리 1 유한군 $G$ 에 대해 소수 $p$ 가 $|G|$ 의 약수면 $|H| = p$ 를 만족하는 부분군 $H \leqslant G$ 가 존재한다. 설명 보통 코시 정리라고 할 때 이 정리를 떠올리지는 않는다. 또다른 또다른 코시 정리는 복소해석의 근간을 이룰만큼 중요한 정리인데, 이 정리는 별로 언급 될 일이 없다. 무엇보다도 제1 쉴로브 정리로 일반화되기 때문에 굳이 코시 정리를 써야할 경우는 극히 드물다. 알</description>
    </item>
    
    <item>
      <title>R 에서 그래프 그리기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-in-r/</link>
      <pubDate>Tue, 28 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-in-r/</guid>
      <description>개요 R 은 다른 언어와 비교했을때 그래프의 표현이 아주 쉽다는 장점이 있다. 여타 통계 패키지와 비교하자면 쉬운 그림은 패키지가 빨라도 세세한 표현이 많아지면 R 이 편해지는 경향이 있다. 물론 R이 꼭 그래픽만을 위한 언어는 아니지만, 매우 큰 장점이니만큼 자유자재로 다룰 수 있게 연습하는 게 좋다. 코드 set.seed(150421) x&amp;lt;-1:10 y&amp;lt;-rnorm(10,5) z&amp;lt;-rexp(10) win.graph(4,4) plot(x,y,main=&amp;qu</description>
    </item>
    
    <item>
      <title>추상대수학에서의 p-군</title>
      <link>https://freshrimpsushi.github.io/posts/p-group-in-abstract-algebra/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/p-group-in-abstract-algebra/</guid>
      <description>정의 1 유한군 $G$ 의 항등원이 $e$ 라고 할 때, $g \in G$ 가 $g^{n} = e$ 를 만족하는 가장 작은 $n \in \mathbb{N}$ 에 대해 $|g| = n$ 이라 나타낸다. 모든 $g \in G$ 와 주어진 소수 $p$ 에 대해 $|g| = p^{m}$ 을 만족하는 정수 $m \ge 0$ 이 존재할 때, $G$ 를 $p$-군$p$-group이라고 한다. 설명 $|G| = p^{m}$ 이면 $p$-군이고, 다음과 같은 정리가 알려져있다. 정리 $X_{G} : = \left\{ x \in X \ | \ gx = x</description>
    </item>
    
    <item>
      <title>R 에서 조건부로 데이터 필터링하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/conditionally-data-filtering-in-r/</link>
      <pubDate>Sun, 26 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditionally-data-filtering-in-r/</guid>
      <description>개요 R 이 주로 통계학에서 쓰이기 때문인지, 필요한 데이터를 골라내고 편집하는 기능은 타의 추종을 불허한다. 이러한 데이터의 핸들링에 익숙해지는 것은 조금 어렵지만, 완벽하게 터득하고 나면 다른 언어가 너무나 불편할 것이다. 사실 이러한 팁들은 읽는 것만으로는 크게 도움이 되지 않는다. (실제로 정확성을 기하려다보니 설명도 간결할 수밖에 없다.)</description>
    </item>
    
    <item>
      <title>우리손 보조정리와 티체 확장 정리</title>
      <link>https://freshrimpsushi.github.io/posts/urysohns-lemma-tietze-extension-theorem/</link>
      <pubDate>Sat, 25 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/urysohns-lemma-tietze-extension-theorem/</guid>
      <description>정리 우리손 보조정리 1 $X$ 가 정규 공간이면 $A \cap B = \emptyset$ 인 모든 닫힌 집합 $A, B \subset X$ 에 대해 $f(A) = \left\{ 0 \right\}$ 와 $f(B) = \left\{ 1 \right\}$ 를 만족하는 연속 함수 $f:X \to [0,1]$ 가 존재한다. 티체 확장 정리 2 정규 공간 $X$ 에서 닫힌 집합 $C$ 에 대해 $f : C \to \mathbb{R}$ 가 연속이면 $F |_{C} = f$ 를 만족하는 연속함수 $F : X \to \mathbb{R}$ 가 존재한다. 설명 우리손 보조정리는 위상수학을 사용하는 온갖 분야에 동원되는</description>
    </item>
    
    <item>
      <title>엔탈피 헬름홀츠 함수 깁스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/enthalpy-helmholtz-function-gibbs-function/</link>
      <pubDate>Fri, 24 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/enthalpy-helmholtz-function-gibbs-function/</guid>
      <description>정의 엔탈피enthalpy $H$ 는 다음과 같이 정의된다. $$ H := U + PV $$ 헬름홀츠 함수Helmholtz function $F$ 는 다음과 같이 정의된다. $$ F := U - TS $$ 깁스 함수Gibbs function $G$ 는 다음과 같이 정의된다. $$ G := H - TS $$ 설명 엔탈피는 엔트로피에 거의 준할정도로 이름이 알려진 함수지만 중요하게 다루는 분야는 주로 화학이다. 물리를 위해선 아득바</description>
    </item>
    
    <item>
      <title>R 에서 조건부 합 조건부 평균 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-sum-and-conditional-mean-in-r/</link>
      <pubDate>Thu, 23 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-sum-and-conditional-mean-in-r/</guid>
      <description>개요 엑셀이라고 치면 sumif() 혹은 averageif() 함수가 필요한 상황이 가끔 있다.R 에선 그처럼 단순한 함수는 없지만, 압도적인 상위호환으로 apply 계열 함수가 있다. 이 함수를 꼼꼼하게 익혀놓으면 좋긴한데, 당장은 급한대로 조건부 합과 조건부 평균만 구해보자. 예제 iris 데이터셋을 불러보자. 임의로 10, 50, 90, 130번째 데이터를 살펴보면 범주형 변수로써 종을 분류해놓은 것</description>
    </item>
    
    <item>
      <title>깁스의 엔트로피 표현</title>
      <link>https://freshrimpsushi.github.io/posts/gibbs-expression-for-the-entropy/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gibbs-expression-for-the-entropy/</guid>
      <description>공식 거시상태가 $i$번째 상태일 확률을 $P_{i}$라고 하면 다음이 성립한다. $$ S = - k_{B} \sum_{i} P_{i} \ln P_{i} $$ 설명 이젠 열에 대한 공부라고 말하기도 어려울 정도까지 왔다. 하지만 반대로 생각해보면, 엔트로피 자체가 열역학을 뛰어넘어 이런 것까지 생각하기 위해 도입되었다고 볼 수도 있다. 유도 Part 1. 열역학 제1법칙 $$ d U = \delta Q + \delta W $$ 엔트로피의 정</description>
    </item>
    
    <item>
      <title>회귀계수의 t검정 t-test for Regression Coefficient</title>
      <link>https://freshrimpsushi.github.io/posts/654/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/654/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 단순회귀분석다중회귀분석R 에서 단순회귀분석 결과 $n$ 개의 관측치와 $p$ 개의 독립변수에 대한 다중회귀분석에 대해 $i=0,1,\cdots,p$ 라고 하자. $H_{0}$ : $\beta_{i} = 0$ 즉, $i$ 번째 독립변수는 종속변수과 관계 없다. $H_{1}$ : $\beta_{i} \ne 0$ 즉, $i$ 번째 독립변수에 대한 회귀계수가 유의하다. 회귀계수의 추정치 $\hat{ \beta_{i} }$ 와 표준오차 $ \text{se} ( \hat{</description>
    </item>
    
    <item>
      <title>우주의 엔트로피는 감소하지 않는다</title>
      <link>https://freshrimpsushi.github.io/posts/653/</link>
      <pubDate>Mon, 20 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/653/</guid>
      <description>정리 우주의 엔트로피는 감소하지 않는다. 설명 위 명제를 보고 가장 먼저 알 수 있는 사실은 &amp;lsquo;뭔가 멋있다&amp;rsquo;는 점이다. 하지만 정말로 멋있는 건 이것을 수식적으로 이해한 사람이고, 그런 사람이 될 수 있도록 노력하자. 증명 이 우주는 유일하며, 따라서 이 우주의 &amp;lsquo;외부&amp;rsquo;같은 건 존재하지 않는다는 가정이</description>
    </item>
    
    <item>
      <title>R 에서 단순회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</guid>
      <description>실습 회귀분석하는 법 head(faithful) R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 데이터만 봐서는 두 변수 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph(6,3) par(mfrow=c(1,2)) plot(faithful, main =&amp;quot;faithful&amp;quot;,asp=T) plot(faithful, main =&amp;quot;faithful&amp;quot;) points(head(faithful),col=&#39;red&#39;,pch=19) 왼쪽은 가로세로의 비율이 일정하도록 맞춰놓은 것인데, 정확한 그래프지만 보기가 어렵다. 오른쪽은 보기 편하도록 비율을 조정한 그래프</description>
    </item>
    
    <item>
      <title>열역학에서 엔트로피란</title>
      <link>https://freshrimpsushi.github.io/posts/entropy-in-thermodynamics/</link>
      <pubDate>Sat, 18 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/entropy-in-thermodynamics/</guid>
      <description>정의 다음의 식을 만족하는 $S$를 엔트로피entropy라 정의한다. $$ dS = {{ \delta Q_{\text{rev} } } \over { T }} $$ 설명 엔트로피는 &amp;lsquo;무질서도&amp;rsquo;를 나타내는 물리량으로써, 수식적인 정의만 보고는 이게 왜 무질서도인지 이해하기 어렵다. &amp;lsquo;방 어지르기&amp;rsquo;나 &amp;lsquo;물잔에 잉크 떨어뜨리기&amp;rsq</description>
    </item>
    
    <item>
      <title>단순회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/simple-linear-regression/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simple-linear-regression/</guid>
      <description>개요 회귀분석이란 변수 사이의 관계를 알아내는 방법으로써, 특히 선형 관계를 밝히는 데 유용하다 단순회귀분석Simple Linear Regression은 그 중에서도 가장 쉬운 것으로, 종속변수(반응변수) 하나와 독립변수(설명변수) 하나에 대한 회귀분석을 말한다. 모델 1 독립변수 $x_{i}$ 와 종속변수 $y_{i}$ 가 선형 관계를 가진다는 말은 어떤 $a,b$ 에 대해 $y_{i} = ax_{i}</description>
    </item>
    
    <item>
      <title>클라우지우스 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/clausius-inequality/</link>
      <pubDate>Thu, 16 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/clausius-inequality/</guid>
      <description>정리 순환 과정에서 다음의 식이 성립한다. $$ \oint {{\delta Q} \over {T}} \le 0 $$ 특히 가역 과정이면 다음이 성립한다. $$ \oint {{\delta Q_{\text{rev}}} \over {T}} = 0 $$ 설명 순환 과정이란 위와 같이 과정을 시작할 때와 끝낼 때 계의 상태가 같은 과정을 말한다. 만약 이 과정 전체가 가역과정이라면 그 폐적분은 항상 $0$ 이고, 그때 $Q := Q_{\text{rev}}$ 와 같은 표현을 사용한다.</description>
    </item>
    
    <item>
      <title>적합치, 예측치, 잔차, 오차</title>
      <link>https://freshrimpsushi.github.io/posts/fitted-value-predict-value-residual-error/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fitted-value-predict-value-residual-error/</guid>
      <description>정의 1 회귀분석 $Y \leftarrow X_{1} + X_{2} + \cdots + X_{n}$ 으로 얻은 회귀식을 $y = \beta_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} + \cdots + \beta_{n} x_{n}$ 이라고 하고 $i$ 번째 데이터를 $(y_{i} , x_{i1} , x_{i2} , \cdots , x_{in})$ 와 같이 나타내도록 하자. 평균Mean: $$ \displaystyle \overline{y} := {{1} \over {n}} \sum_{i=1}^{n} y_{i} $$ 적합치Fitted Value: $i$ 번째 데이터 $y_{i}$ 에 대해 $$ \hat{y}_{i} := \beta_{0} + \beta_{1} x_{i1} + \beta_{2} x_{i2} + \cdots + \beta_{n} x_{in} $$ 예측치Predicted Value: 새로운 데이터 $y_{0}$ 에 대해 $$ \hat{y}_{0} := \beta_{0}</description>
    </item>
    
    <item>
      <title>일의 자리가 5인 두자리수의 거듭제곱 쉽게하기</title>
      <link>https://freshrimpsushi.github.io/posts/661/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/661/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 중고등학생부터 대학생까지 간단한 계산은 빠를수록 좋다. 모든 곱셈을 빠르게 할 수 있는 방법 같은건 없다.비상한 두뇌를 가지고 암산 천재로 태어나는 딱 하나의 방법이 있다. 그렇지만 특별한 상황에서는 누구나 빠르게 계산할 수 있다.일의 자리가 5인 두자리수의 거듭제곱은 위의 사진에 보이는 대로 빠르</description>
    </item>
    
    <item>
      <title>카르노 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-carnot-theorem/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-carnot-theorem/</guid>
      <description>정리 카르노 기관보다 효율이 높은 기관은 존재하지 않는다. 설명 어차피 카르노 기관을 실제로 구현할 순 없지만 이론적인 한계가 된다는 점에서 대단히 의미있는 정리다. 증명 카르노 기관 $C$보다 효율이 높은 기관 $E$가 존재한다고 가정해보자. $E$ 는 열 $Q_{h}&#39;$를 받아서 $W$만큼의 일을 하고, $C$ 는 열 $Q_{l}$과 일 $W$를 받아서 열</description>
    </item>
    
    <item>
      <title>위상수학에서의 함수공간</title>
      <link>https://freshrimpsushi.github.io/posts/function-space/</link>
      <pubDate>Mon, 13 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/function-space/</guid>
      <description>정의 1 위상공간 $X$ 와 $Y$ 에 대해 다음과 같이 정의된 곱 공간 $Y^{X}$를 함수 공간이라 한다. $$ Y^{X} : = \prod_{x \in X} Y = \left\{ f \ | \ f : X \to Y \text{ is a function} \right\} $$ 함수공간의 위상이 되는 것으로 다음이 있다: $x \in X$ 와 $Y$ 에서 열린 집합 $U$ 에 대해 $$ S (x , U) = \left\{ f \in Y^{X} \ | \ f(x) \in U \right\} $$ 라 하자. 부분기저 $\left\{ S(x,U) \ | \ x \in X , U \subset Y \right\}$ 로 생성되는 $Y^{X}$ 의 위상을 포</description>
    </item>
    
    <item>
      <title>카르노 기관</title>
      <link>https://freshrimpsushi.github.io/posts/carnot-engine/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/carnot-engine/</guid>
      <description>정의 다음 네 가지 과정을 순서대로 수행하는 기관을 카르노 기관Carnot engine이라 한다. Step 1. 등온 팽창 과정 $A \to B$: 온도가 $T_{h}$로 유지된 상태에서 열에너지 $Q_{h}$를 받아 부피가 $V_{A}$에서 $V_{B}$로 증가한다. Step 2. 단열 팽창 과정 $B \to C$: 열이 유지된 상태에서 부피가 $V_{B}$에서 $V_{C}$</description>
    </item>
    
    <item>
      <title>제3동형 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-third-isomorphism-thoerem/</link>
      <pubDate>Sat, 11 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-third-isomorphism-thoerem/</guid>
      <description>정리 1 $G,G&#39;$ 가 군이라고 하자. 제1동형 정리: 준동형사상 $\phi : G \to G&#39;$ 이 존재하면 $$ G / \ker ( \phi ) \simeq \phi (G) $$ 제2동형 정리: $H \le G$ 이고 $N \triangleleft G$ 면 $$ (HN) / N \simeq (H \cap N) $$ 제3동형 정리: $H , K \triangleleft G$ , $K \leq H$ 면 $$ G/H \simeq (G/K) / (H/K) $$ 동형 정리Isomorphism Thoerem는 대수학자 에미 뇌터에 의해 증명된 정리로 독립적인 위의 세 가지 정리를 일컫는다</description>
    </item>
    
    <item>
      <title>열역학 제2법칙</title>
      <link>https://freshrimpsushi.github.io/posts/the-second-law-of-thermodynamics/</link>
      <pubDate>Fri, 10 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-second-law-of-thermodynamics/</guid>
      <description>법칙 클라우지우스: 스스로 차가운 쪽에서 뜨거운 쪽으로 열을 보내는 과정은 존재하지 않는다. 켈빈: 열을 완전히 일로 바꾸는 과정은 존재하지 않는다. 설명 열역학 제2법칙 에 대한 독일의 물리학자 클라우지우스Clausius와 영국의 물리학자 켈빈Kelvin의 진술은 서로 동치다. 가장 유명한 것은 그리스의 수학자 카라테오도리Καραθεο</description>
    </item>
    
    <item>
      <title>제2동형 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-second-isomorphism-thoerem/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-second-isomorphism-thoerem/</guid>
      <description>정리 1 $G,G&#39;$ 가 군이라고 하자. 제1동형 정리: 준동형사상 $\phi : G \to G&#39;$ 이 존재하면 $$ G / \ker ( \phi ) \simeq \phi (G) $$ 제2동형 정리: $H \le G$ 이고 $N \triangleleft G$ 면 $$ (HN) / N \simeq (H \cap N) $$ 제3동형 정리: $H , K \triangleleft G$ , $K \leq H$ 면 $$ G/H \simeq (G/K) / (H/K) $$ 동형 정리Isomorphism Thoerem는 대수학자 에미 뇌터에 의해 증명된 정리로 독립적인 위의 세 가지 정리를 일컫는다</description>
    </item>
    
    <item>
      <title>단열감률의 열역학적 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-adiabatic-lapse-rate/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-adiabatic-lapse-rate/</guid>
      <description>공식 $m$을 기체 분자의 질량, $h$를 높이, $T$를 온도라고하면 다음의 식이 성립한다. $$ \dfrac{dT}{dh} = - {{ \gamma -1} \over { \gamma }} \dfrac{ mg }{k_{B}} $$ 이떄 $\gamma = \dfrac{C_{p}}{C_{V}}$ 는 등압 열용량과 등적 열용량의 비율이다. 설명 알다시피 고도가 올라갈수록 기온은 떨어지는데, 그 비율을 수식적으로 나타낸 것이다. 물론 이는 습도와 같은 여러가지 변수들을 전혀 고려하지 않고 열역학만을 이용</description>
    </item>
    
    <item>
      <title>제1동형 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-first-isomorphism-thoerem/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-first-isomorphism-thoerem/</guid>
      <description>정리 1 $G,G&#39;$ 가 군이라고 하자. 제1동형 정리: 준동형사상 $\phi : G \to G&#39;$ 이 존재하면 $$ G / \ker ( \phi ) \simeq \phi (G) $$ 제2동형 정리: $H \le G$ 이고 $N \triangleleft G$ 면 $$ (HN) / N \simeq (H \cap N) $$ 제3동형 정리: $H , K \triangleleft G$ , $K \leq H$ 면 $$ G/H \simeq (G/K) / (H/K) $$ 동형 정리Isomorphism Thoerem는 대수학자 에미 뇌터에 의해 증명된 정리로 독립적인 위의 세 가지 정리를 일컫는다</description>
    </item>
    
    <item>
      <title>이상기체의 단열 팽창</title>
      <link>https://freshrimpsushi.github.io/posts/adiabatic-expansion-of-an-ideal-gas/</link>
      <pubDate>Mon, 06 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adiabatic-expansion-of-an-ideal-gas/</guid>
      <description>정리 몰수가 $1$이고 단열 팽창을 하는 이상기체의 계에서 압력이 $p$, 부피가 $V$라고 하면 $p V^{\gamma}$은 상수다. 이때 $\gamma = \dfrac{C_{p}}{C_{V}}$ 는 등압 열용량과 등적 열용량의 비율이다. 설명 단열 팽창이란 열에너지가 변하지 않는 조건에서의 팽창을 말한다. $\gamma = \dfrac{C_{p}}{C_{V}}$ 는 물리적으로의 의미는 딱히 없다. 증명 열역학 제1법칙 $$ d U = \delta Q + \delta W $$ 열역학 제</description>
    </item>
    
    <item>
      <title>번사이드 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-burnside-formula/</link>
      <pubDate>Sun, 05 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-burnside-formula/</guid>
      <description>개요 번사이드 공식은 군의 작용과 등방부분군에 대한 대표적인 응용으로써 조합론을 비롯한 분야에서 즉시 쓰일 수 있다. 공식 1 유한군 $G$ 에 대해 유한집합 $X$ 가 $G$-집합이라고 하자. $r$ 이 $G$ 하의 $X$ 의 궤도의 갯수라고 하면 $$ r |G| = \sum_{g \in G} \left| X_{g} \right| $$ 유도 집합 $\left\{ (g,x) \in G \times X | gx = x \right\}$ 의 기수를 $N$ 이라고 하면 $$ X_{g} = \left\{ x \in X \ | \ gx = x \right\} $$ 이고, $G_{x} =</description>
    </item>
    
    <item>
      <title>이상기체의 등온 팽창</title>
      <link>https://freshrimpsushi.github.io/posts/isothermal-expansion-of-an-ideal-gas/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isothermal-expansion-of-an-ideal-gas/</guid>
      <description>공식 몰 수가 $1$이고 등온 팽창을 하는 이상기체의 계에서 열에너지가 $Q$, 온도가 $T$, 팽창 전의 부피를 $V_{1}$, 팽창 후의 부피를 $V_{2}$라고 할 때 다음의 식이 성립한다. $$ \Delta Q = RT \ln \dfrac{V_{2}}{V_{1}} $$ 설명 등온 팽창이란 온도가 변하지 않는 조건에서의 팽창을 말한다. 이때 열에너지의 변화는 편리하게도 부피의 변화만을 이용해 구해낼 수 있다. 일단은 팽창이므로 $V_{2} &amp;gt; V_{1}$</description>
    </item>
    
    <item>
      <title>등방부분군</title>
      <link>https://freshrimpsushi.github.io/posts/isotropy-subgroup/</link>
      <pubDate>Fri, 03 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isotropy-subgroup/</guid>
      <description>정의 1 군 $G$ 에 대해 $X$ 를 $G$-집합이라고 하자. $x \in X$ 와 $g \in G$ 에 대해 $X_{g} := \left\{ x \in X \ | \ gx = x \right\}$ 그리고 $G_{x} := \left\{ g \in G \ | \ gx = x \right\}$ 라 두자. $G_{x}$ 를 $x$ 에 대한 $G$ 의 등방부분군Isotropy Subgroup이라 정의한다. 설명 등방부분군이 뭔지 감을 잡으려면 군의 작용에 대한 이해가 있어야한다. 위 그림 좌측의 점들과 선들의 집합 $$ X :</description>
    </item>
    
    <item>
      <title>등적 열용량과 등압 열용량</title>
      <link>https://freshrimpsushi.github.io/posts/constant-volume-heat-capacity-and-constant-pressure-heat-capacity/</link>
      <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/constant-volume-heat-capacity-and-constant-pressure-heat-capacity/</guid>
      <description>공식 몰 수가 $1$인 이상기체의 계에서 등적 열용량 $C_{V}$와 등압 열용량 $C_{p}$ 에 대해 다음의 식이 성립한다. $$ C_{p} = C_{V} + R = {{5} \over {2}} R $$ 설명 등적 과정이냐 등압 과정이냐에 따른 열용량은 다를 뿐만이 아니라 수식적으로도 착착 맞아떨어지는 관계가 있다. 특히 $\gamma := \dfrac{C_{p}}{C_{V}}$ 자체는 물리적으로 큰 의미가 없지만, 수식적으로 여기저기서 중요하게 쓰인다. 증</description>
    </item>
    
    <item>
      <title>군의 작용</title>
      <link>https://freshrimpsushi.github.io/posts/group-action/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/group-action/</guid>
      <description>정의 1 항등원이 $e$ 인 군 $G$ 와 집합 $X$ 에 대해 다음의 두 조건을 만족하는 이항연산 $\ast : G \times X \to X$ 를 $X$ 상에서 $G$ 의 작용Action이라 하고 $X$ 를 $G$-집합이라고 부른다. (i): 모든 $x \in X$ 에 대해 $ex = x$ (ii): 모든 $x \in X$ 와 $g_{1} , g_{2} \in G$ 에 대해 $( g_{1} g_{2} ) (x) = g_{1} (g_{2} x)$ 설명 군의 작용은 한마디로 &amp;lsquo;$x \in X$ 에다 $g \in G$ 를 가한다&amp;rsquo;는 말이다. 직관적으로</description>
    </item>
    
    <item>
      <title>열역학 제1법칙</title>
      <link>https://freshrimpsushi.github.io/posts/the-first-law-of-thermodynamics/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-first-law-of-thermodynamics/</guid>
      <description>법칙 열에너지가 $Q$인 계에 가해진 일이 $W$일 때, 내부에너지 $U$ 에 대해서 다음의 식이 성립한다. $$ d U = \delta Q + \delta W $$ $\delta$ 는 불완전 미분inexact differential임을 나타낸다. 설명 이들은 깔끔한 폼으로 원시함수가 존재하지 않기 때문에 선적분을 통해 계산해야한다. 내부에너지의 변화만 가지고는 구체적으로 열에너지가 어느</description>
    </item>
    
    <item>
      <title>추상대수학에서의 몫군</title>
      <link>https://freshrimpsushi.github.io/posts/factor-group/</link>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factor-group/</guid>
      <description>정의 1 $H \subset G$ 의 모든 잉여류의 집합을 $G / H$ 라고 하자. $(aH) \ast\ (bH) = (ab) H$ 와 같이 잘 정의된 이항연산 $\ast$ 이 존재하면 $\left&amp;lt; G / H , * \right&amp;gt;$ 를 몫군Factor Group이라 한다. 정리 $H \leqslant G$ 이라고 하자. $H \triangleleft G$ 인 것과 $G / H$ 는 군인 것은 동치다. 설명 $H \triangleleft G$ 라는 것은 $H$ 가 $G$ 의 정규부분군이라는 것이다. 이항연산 $\ast$ 는 잉여류의 대푯값끼리만 계산하는 이항연</description>
    </item>
    
    <item>
      <title>열용량</title>
      <link>https://freshrimpsushi.github.io/posts/heat-capacity/</link>
      <pubDate>Sun, 29 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heat-capacity/</guid>
      <description>정의 물체의 온도를 $dT$만큼 올리는데 필요한 열 $dQ$ 열을 물체의 열용량heat capacity이라 하고 capacity의 C를 따서 다음과 같이 표기한다. $$ C = \dfrac{dQ}{dT} [\text{J/K}] $$ 설명 단위질량당 열용량을 특별히 비열specific heat capacity이라고 하는데, 다른 분야에선 모르겠지만 물리에선 별로 중요치 않다. 열역학에서는 어떤 특정한</description>
    </item>
    
    <item>
      <title>티호노프 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-tychonoff-theorem/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-tychonoff-theorem/</guid>
      <description>정리 $\left\{ X_{\alpha} \ | \ \alpha \in \mathscr{A} \right\}$ 가 컴팩트 공간들의 집합이면 $\displaystyle X : = \prod_{\alpha \in \mathscr{A}} X_{ \alpha}$ 는 컴팩트다. 설명 이름까지 붙은 정리치고는 일개 성질 나부랭이처럼 보이지만 사실 그 반대로 보는 게 맞다. 일개 성질 나부랭이처럼 보이지만 의외로 증명하기가 너무 어려워서 정리에 이름까지 붙어버린 것이다. 유용하기론 둘째가라면 서러운 컴팩트가 위상공간들의 데카르트 곱에 대</description>
    </item>
    
    <item>
      <title>기체분자의 평균 운동에너지</title>
      <link>https://freshrimpsushi.github.io/posts/mean-kinetic-energy-of-a-gas-molecule/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-kinetic-energy-of-a-gas-molecule/</guid>
      <description>공식 온도가 $T$인 계에서 기체분자들의 평균 운동에너지는 다음과 같다. $$ \left&amp;lt; E_{K} \right&amp;gt; = {{3} \over {2}} k_{B} T $$ 설명 기체분자 하나하나에 대해 운동에너지를 구해서 평균을 구하는 것은 비효율적일뿐만 아니라 현실적으로 불가능하다. 하지만 통계적으로 유도한 이 공식에 따르면 운동에너지는 오로지 온도에만 의존하며 구하기도 쉬워진다. 상수배가 하필 $\dfra</description>
    </item>
    
    <item>
      <title>알렉산더 부분기저 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-alexander-subbasis-theorem/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-alexander-subbasis-theorem/</guid>
      <description>정리 $X$ 가 위상공간이라고 하자. $X$ 는 컴팩트다. $\iff$ $\mathscr{S}$ 의 멤버들로 이루어진 $X$ 의 모든 열린 커버가 유한 부분커버를 갖게끔 하는 $X$ 의 어떤 부분기저 $\mathscr{S}$ 가 존재한다. 설명 컴팩트가 나왔으니 중요성은 말할 필요 없을 것이다. 본 정리는 원래 알렉산더의 스승이 기저에 대해 증명하려고 했던 정리였다. 하지만 기저에 대해서는 증명할 수 없었고, 스승의 유지를 이어받</description>
    </item>
    
    <item>
      <title>맥스웰 분포</title>
      <link>https://freshrimpsushi.github.io/posts/maxwell-distribution/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maxwell-distribution/</guid>
      <description>정리 기체분자의 속력을 나타내는 확률변수 $V$ 는 확률밀도함수가 아래와 같은 맥스웰 분포Maxwell distribution를 따른다. $$ f(v) = \dfrac{4}{\sqrt{ \pi}} \left( \dfrac{m}{2 k_{B} T} \right)^{3/2} v^{2} e^{-mv^2 / 2k_{B}T } $$ 설명 맥스웰 분포는 볼츠만 분포에서 유도되어 맥스웰-볼츠만 속력 분포라고도 불린다. 통계역학이라는 이름이 무색해질만큼 통계학에서 볼 수 없는 분포로, 굳이 엮자면 정규</description>
    </item>
    
    <item>
      <title>유사벡터란</title>
      <link>https://freshrimpsushi.github.io/posts/pseudovector/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pseudovector/</guid>
      <description>설명 물리학 공부를 하다 보면 유사벡터 혹은 수도벡터라는 말을 접할 수 있다. 중요한 점은 유사벡터를 접하기만 할 뿐 어떤 녀석인지 알기는 힘들다는 거다. 유사벡터가 뭔지 몰라도 학부 물리학을 공부하는데 아무 지장은 없다지만 제대로 설명해놓은 교재를 본 적이 없다. 나는 유사벡터의 특징을 배울 수 있도록 한 그리피스 전자기학의 연습문제에서 준벡터(Pse</description>
    </item>
    
    <item>
      <title>추상대수학에서의 핵</title>
      <link>https://freshrimpsushi.github.io/posts/kernel-in-abstract-algebra/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kernel-in-abstract-algebra/</guid>
      <description>정의 $G, G&#39;$ 의 항등원 $e, e&#39;$ 과 준동형사상 $\phi : G \to G&#39;$ 에 대해 $\left\{ e&#39; \right\}$ 의 원상 $ \phi^{-1} [ \left\{ e&#39; \right\} ]$ 을 $\phi$ 의 핵Kernel이라 하고 $\ker \phi $ 라고 쓴다. [1]: $g \in G$ 에 대해 $g ( \ker \phi ) = ( \ker \phi ) g$ [2]: $\ker \phi \triangleleft G$ [3]: $\ker \phi = \left\{ e \right\}$ $\iff$ $\phi$ 는 단사다. [4]: $\phi$ 가 전사고 $\ker \phi = \left\{ e \right\}$ 면 $\phi$ 는 동형사상이다. 설명 정리 [3]은 필요충분조건이지만 특히 준동형사상이 단사임을 보이는</description>
    </item>
    
    <item>
      <title>연속제곱법 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-successive-squaring-method/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-successive-squaring-method/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 자연수 $a,k,m$ 에 대해 $b \equiv a^{k} \pmod{m}$ 를 다음과 같이 계산할 수 있다.**Step 1. $k$ 의 이진법 전개$u_{i} = 0$ 혹은 $u_{i} = 1$ 에 대해 $\displaystyle k = \sum_{i=0}^{r} u_{i} 2^{i} = u_{0} + 2 u_{1} + \cdots + 2^r u_{r}$ 로 나타낸다.**Step 2. $a \equiv A_{0} \pmod{m} $$ a^{2} \equiv ( a^1 )^2 \equiv A_{0}^2 \equiv A_{1} \pmod{m} $$ a^{4} \equiv ( a^2 )^2 \equiv A_{1}^2 \equiv A_{2} \pmod{m} $$ a^{8} \equiv ( a^4 )^2 \equiv A_{2}^2 \equiv A_{3} \pmod{m}</description>
    </item>
    
    <item>
      <title>위상공간의 데카르트 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cartesian-product-of-topology-space/</link>
      <pubDate>Sun, 22 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cartesian-product-of-topology-space/</guid>
      <description>정의 1 인덱스 집합 $\mathscr{A}$ 에 대해 $\left\{ X_{\alpha} \ | \ \alpha \in \mathscr{A} \right\}$ 가 위상공간들의 집합이고 $O_{\alpha}$ 을 $X_{\alpha}$ 에서 열린 집합이라고 하자. 데카르트 곱 $\displaystyle X := \prod_{\alpha \in \mathscr{A}} X_{ \alpha}$ 에 대해 $p_{\alpha} : X \to X_{\alpha}$ 를 사영Projection이라 한다. 부분기저 $\mathscr{S} : = \left\{ p_{\alpha}^{-1} ( O_{\alpha} ) \ | \ O_{\alpha} \subset X_{\alpha} , \alpha \in \mathscr{A} \right\}$ 에 의해 생성되는 $X$ 의 위상을 곱위상Product Topology라 한다. 기저 $\displaystyle \mathscr{B} : = \left\{</description>
    </item>
    
    <item>
      <title>군의 데카르트 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cartesian-product-of-groups/</link>
      <pubDate>Sat, 21 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cartesian-product-of-groups/</guid>
      <description>정의 1 군 $G_{1} , \cdots , G_{n}$ 들의 데카르트 곱과 그 원소 $\displaystyle (a_{1},\cdots , a_{n}), (b_{1} , \cdots , b_{n} ) \in \prod_{i=1}^{n} G_{i}$ 에 대해 $$ (a_{1},\cdots , a_{n}) (b_{1} , \cdots , b_{n} ) = (a_{1} b_{1},\cdots , a_{n} b_{n}) $$ 이면 $\displaystyle \in \prod_{i=1}^{n} G_{i}$ 를 $G_{1} , \cdots , G_{n}$ 들의 직곱Direct Product이라 한다. 특히 $G_{1}, \cdots , G_{n}$ 이 가환군이면 $\displaystyle \bigoplus_{i=1}^{n} G_{i}$ 로 쓰고 직합Direct Sum이라고도 부른다. 설명 벡터 공간은 덧셈에 대해 군이지만 군은 벡터공간이 아니므</description>
    </item>
    
    <item>
      <title>등온 대기에서 높이에 따른 기체 분자 수 공식</title>
      <link>https://freshrimpsushi.github.io/posts/formulas-in-the-number-of-gaseous-molecules-by-height-in-an-isothermal-atmosphere/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/formulas-in-the-number-of-gaseous-molecules-by-height-in-an-isothermal-atmosphere/</guid>
      <description>공식 기온 $T$가 일정하다고 할 때 높이 $h$에서 단위 부피 $V=1$당 기체분자의 수를 $N(h)$라고 하자. 기체분자의 질량이 $m$이고 중력가속도가 $g$ 면 다음의 식이 성립한다. $$ N(h) = N(0) e^{- {{mgh} \over {k_{B} T}} } $$ 설명 이 공식은 원래 열역학에선 별볼일 없지만, 유도하는 두 가지 방법이 판이하게 다른 점이 재미있다. 유도 미분방정식을 이용하여 높이 $</description>
    </item>
    
    <item>
      <title>스털링 근사 공식의 엄밀한 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-stirling-approximation/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-stirling-approximation/</guid>
      <description>정리 $$ \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ 설명 스털링 근사 혹은 스털링 공식Stirling Formula은 통계학이나 물리학 등 여러 곳에서 유용하게 쓰인다. 또 다른 표현으로는 감마 함수를 사용해 다음과 같이 적을 수 있다. $$ \Gamma ( n ) \approx {e^{n \ln n - n} \sqrt{ 2 \pi n}} $$ 본 증명은 &amp;lsquo;제타함수의 비밀&amp;rsquo;이라는 책의 부록에 실</description>
    </item>
    
    <item>
      <title>볼츠만 분포</title>
      <link>https://freshrimpsushi.github.io/posts/boltzmann-distribution/</link>
      <pubDate>Tue, 17 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/boltzmann-distribution/</guid>
      <description>정리 온도가 $T$인 계의 에너지가 $\varepsilon$일 확률은 다음과 같다. $$ P(\varepsilon) \propto e^{ - \frac{\varepsilon}{k_{B} T} } $$ 이러한 분포를 볼츠만 분포Boltzmann distribution라고 한다. 유도 앙상블ensemble이란 쉽게 말해 &amp;lsquo;계들이 이루는 상황&amp;rsquo;이다. 그 중에서 정준 앙상블canonical ense</description>
    </item>
    
    <item>
      <title>르벡공간에서의 민코프스키 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-minkowskis-inequality-in-lebesgue-space/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-minkowskis-inequality-in-lebesgue-space/</guid>
      <description>정리1 $\Omega \subset \mathbb{R}^{n}$를 열린 집합이라고 하자. $1 \le p &amp;lt; \infty$이고 $u, v \in L^{p}(\Omega)$이면, $$ \left\| u + v \right\|_{p} \le \left\| u \right\|_{p}+\left\| v \right\|_{p} $$ 이를 민코프스키 부등식Minkowski inequality이라 한다. 설명 $\left\| \cdot \right\|_{p}$가 삼각 부등식을 만족하여 놈이 되고, $L^{p}$ 공간은 놈 공</description>
    </item>
    
    <item>
      <title>물리학에서 온도의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-temperature-in-physics/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-temperature-in-physics/</guid>
      <description>정의1 2 에너지가 $E$인 계가 있다고 하자. $E$ 에 대한 미시상태의 개수를 $\Omega(E) = \Omega$ 라고 할 때 $$ \dfrac{1}{k_{B} T} := \dfrac{d \ln ( \Omega )}{d E } $$ 를 만족하는 $T$를 계의 온도temperature라고 정의한다. (단, $k_{B}$는 볼츠만 상수) 미시상태와 거시상태 통계역학에서 어떤 계의 거시상태Macrostate와 미시상태Microstate란 예를</description>
    </item>
    
    <item>
      <title>열역학 제0법칙</title>
      <link>https://freshrimpsushi.github.io/posts/the-zeroth-law-of-thermodynamics/</link>
      <pubDate>Sat, 14 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-zeroth-law-of-thermodynamics/</guid>
      <description>법칙 계 $A,B,C$ 에 대해 $A$ 와 $B$ 가 열역학적 평형을 이루고 $B$ 와 $C$ 열역학적 평형을 이루면 $A$ 와 $C$ 도 열역학적 평형 을 이룬다. 설명 열역학 제0법칙을 수학적으로 표현하자면 &amp;lsquo;열역학적 평형의 추이성&amp;lsquo;이 된다. 유클리드 기하학 제1공리$A = B \land B=C \implies A = C$ 와 같이 각 분야의 근간을 이루는 중요한 법칙이고, 물리학의 많은 부분에서 자</description>
    </item>
    
    <item>
      <title>스털링 공식</title>
      <link>https://freshrimpsushi.github.io/posts/naive-proof-of-stirling-approximation/</link>
      <pubDate>Wed, 11 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/naive-proof-of-stirling-approximation/</guid>
      <description>공식 다음의 방정식을 스털링 공식Stirling&amp;rsquo;s formula이라 한다. $$ \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ 설명1 이 근사는 큰 수에 대한 팩토리얼의 계산이라는 측면에서 유용하다. 열열학, 통계역학과 같은 분야에선 많은 수의 분자를 가정하기 때문에 필수적이며, $$ \ln n! \approx n \ln n - n $$ 와 같이 더 간략화된 표현도 사용</description>
    </item>
    
    <item>
      <title>수학 물리학 전공 교재에서 더블유와 오메가 구별하기</title>
      <link>https://freshrimpsushi.github.io/posts/omega-and-double-u-in-text-book/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/omega-and-double-u-in-text-book/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 물리학, 수학 전공책을 읽다보면 오메가인지 더블유인지 헷갈리는 문자가 있다. 이제 갓 전공과목을 공부하기 시작한 2학년의 경우 오메가의 존재를 모르고 더블유인 줄 아는 경우도 있다. 사실 물리학에서는 십중팔구 오메가이다. 더블유는 잘 쓰이지 않는다. 수학에서는 더블유가 더 많이 쓰이는 것 같다.</description>
    </item>
    
    <item>
      <title>칸토어 집합</title>
      <link>https://freshrimpsushi.github.io/posts/cantor-set/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cantor-set/</guid>
      <description>정의 $$ \begin{align*} I =&amp;amp; \left[ 0, 1 \right] \\ C_{1} =&amp;amp; \left[ 0, {{1} \over {3}} \right] \cup \left[ {{2} \over {3}} , 1 \right] \\ C_{2} =&amp;amp; \left[ 0, {{1} \over {3^2}} \right] \cup \left[ {{2} \over {3^2}}, {{3} \over {3^2}} \right] \cup \left[ {{6} \over {3^2}}, {{7} \over {3^2}} \right] \cup \left[ {{8} \over {3^2}} , 1 \right] \\ &amp;amp;\vdots \\ C_{n} =&amp;amp; \left[ 0, {{1} \over {3^n}} \right] \cup \left[ {{2} \over {3^n}}, {{3} \over {3^n}} \right] \cup \cdots \cup \left[ {{3^n-3} \over {3^n}}, {{3^n-2} \over {3^n}} \right] \cup \left[ {{3^n - 1} \over {3^n}} , 1 \right] \end{align*} $$ 이라고 하자. $\displaystyle C := \bigcap_{n=1}^{\infty} C_{n}$ 을 **칸토어 집합**Cantor Set이라 한다. 정리 [1]: $C = \left\{ x \in I \</description>
    </item>
    
    <item>
      <title>Lp 공간, 르벡 공간</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-space-lp-space/</link>
      <pubDate>Sun, 08 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-space-lp-space/</guid>
      <description>정의1 2 3 $\Omega \subset \mathbb{R}^{n}$를 열린 집합, $p$를 양의 실수라고 하자. $\Omega$ 위에서 정의된 모든 가측함수 $f$에 대해서 집합 $L^{p}(\Omega)$를 다음과 같이 정의한다. $$ L^{p}(\Omega) := \left\{ f : \int_{\Omega} \left| f(x) \right|^{p} dx &amp;lt; \infty \right\} $$ 이를 엘피공간Lp space 혹은 르벡공간Lebesgue space이라 하고, 간단히 $L^{p}$와 같이</description>
    </item>
    
    <item>
      <title>베르의 범주 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-baire-category-theorem/</link>
      <pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-baire-category-theorem/</guid>
      <description>정의 위상공간 $X$ 의 모든 조밀한 열린 집합의 수열 $\left\{ O_{n} \right\}_{n=1}^{\infty}$ 에 대해 $\displaystyle \bigcap_{n=1}^{\infty} O_{n}$ 이 조밀한 공간을 베르 공간Baire Space이라 한다. 베르의 범주 정리 1 모든 완비거리공간은 베르 공간이다. 증명 Claim: 모든 열린 집합 $U \subset X$ 에 대해 $\displaystyle U \cap \left( \bigcap_{n=1}^{\infty} O_{n} \right) \ne \emptyset$ 이다. Part 1. $X$ 는 거리공간이므로, 열린 집합은 어떤 $x^{ \ast } \in X$ 와 $r^{ \ast } &amp;gt; 0$ 에 대해 다음과 같이 나타낼 수 있다</description>
    </item>
    
    <item>
      <title>병렬회로의 합성저항 쉽게 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/603/</link>
      <pubDate>Fri, 06 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/603/</guid>
      <description>빌드업 위와 같은 회로의 합성저항을 구한다고 생각해보자. 물론 아래와 같이 병렬회로로 바꾸면 답 자체는 공식을 통해 구할 수 있다. 저항이 $n$ 개 있을 때 병렬의 저항 공식은 $\displaystyle {{1} \over {R}} = {{1} \over {R_{1}}} + {{1} \over {R_{2}}} + \cdots + {{1} \over {R_{n}}}$ 이다. 공식에 저항을 대입해보면 $$ \begin{align*} {{1} \over {R}} =&amp;amp; {{1} \over {2}} + {{1} \over {5}} + {{1} \over {5}} \\ =&amp;amp; {{1} \over {2}} + {{2} \over {5}} \\ =&amp;amp; {{5} \over {10}} + {{4} \over {10}} \\ =&amp;amp; {{9} \over {10}} \end{align*} $$ 이고, 따라</description>
    </item>
    
    <item>
      <title>이상기체 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/pv-nrt/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pv-nrt/</guid>
      <description>공식1 기체의 분자 수를 $N$, 부피를 $V$, 압력을 $p$, 절대온도를 $T$라고 하자. 그러면 다음의 식이 성립하며 이를 이상기체 방정식ideal gas equation이라 한다. $$ pV = N k_{B} T $$ 이때 $k_{B} = 1.3807 \times 10^{-23} J / K$를 볼츠만 상수Boltzmann constant라 한다. 설명 역사적으로 보면 실험법칙으로부터 유도되었다가 후에 기체운동론에서 수</description>
    </item>
    
    <item>
      <title>월리스 곱</title>
      <link>https://freshrimpsushi.github.io/posts/wallis-product/</link>
      <pubDate>Wed, 04 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/wallis-product/</guid>
      <description>정리 $$ \displaystyle \prod_{n=1}^{\infty} {{4n^2} \over {4n^2 - 1}} = \lim_{n \to \infty} {{2 \cdot 2 } \over { 1 \cdot 3 } } \cdot {{4 \cdot 4 } \over { 3 \cdot 5 } } \cdot \cdots \cdot {{2n \cdot 2n } \over { (2n-1) \cdot (2n+1) } } = {{ \pi } \over {2}} $$ 설명 급수뿐만이 아니라 곱으로도 원주율을 구할 수 있다는 건 두말할 것도 없이 신기하고 유용한 사실이다. 본디 증명은 이보다 어렵고 사실상 싱크함수의 오일러 표현을 증명하는 과정에 포함되어 있다고 볼 수 있다. 증명 싱크</description>
    </item>
    
    <item>
      <title>오일러의 완전수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-perfect-number-theorem/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-perfect-number-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 짝수 $n = 2^{p-1} (2^p - 1)$ 가 완전수면 $2^{p}-1$ 는 메르센 소수다. 언뜻 보면 유클리드완전수 공식의 역이 되는 것 같지만 짝수에 대해서만 언급되었다는 점이 다르다. 그러나 이 정리는 완전수의 거의 모든 것을 말해주고 있는데, 실제로 홀수 완전수는 아직 발견된 적이 없기 때문이다.현재까지 홀수 완전수에 대해 밝혀진 사</description>
    </item>
    
    <item>
      <title>함수의 내적을 정적분으로 정의하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/reason-for-defining-the-inner-product-of-a-function-as-definitive-integral/</link>
      <pubDate>Mon, 02 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reason-for-defining-the-inner-product-of-a-function-as-definitive-integral/</guid>
      <description>빌드업 내적의 일반적인 정의는 다음과 같다. $H$를 벡터 공간이라고 하자. $x,y,z \in H$와 $\alpha, \beta \in \mathbb{C}$에 대해서 다음의 조건을 만족하는 함수 $$ \langle \cdot , \cdot \rangle \ : \ H \times H \to \mathbb{C} $$ 를 내적이라 정의하고 $\left( H, \langle \cdot ,\cdot \rangle \right)$를 내적공간이라 한다. 선형성: $\langle \alpha x + \beta y ,z \rangle =\alpha \langle x,z\rangle + \beta \langle y,z\rangle$ 켤레대칭성: $\langle x,y \rangle = \overline{ \langle y,x \rangle}$ 정</description>
    </item>
    
    <item>
      <title>한 점 컴팩트화</title>
      <link>https://freshrimpsushi.github.io/posts/one-point-compactification/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/one-point-compactification/</guid>
      <description>정의 1 위상공간 $(X , \mathscr{T})$ 에 대해 $\infty \notin X$ 이라고 하자. $X_{\infty} := X \cup \left\{ \infty \right\}$ 에 대해 아래의 두 조건을 만족하는 위상 $\mathscr{T}_{\infty}$ 을 정의한 $(X_{\infty } , \mathscr{T}_{\infty} )$ 를 $(X, \mathscr{T})$ 의 한 점 컴팩트화One-Point Compactification이라 한다. (i): $\infty \notin U \implies U \in \mathscr{T}_{\infty}$ 와 $U \in \mathscr{T}$ 은 동치다. (ii): $\infty \in U \implies U \in \mathscr{T}_{\infty}$ 와 $X_{\infty} \setminus U$ 가 닫혀있고 컴팩트인 것은 동치다. 정리 $(X_{\infty } , \mathscr{T}_{\infty} )$ 는 다음의</description>
    </item>
    
    <item>
      <title>라그랑주의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lagranges-theorem/</link>
      <pubDate>Sat, 30 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lagranges-theorem/</guid>
      <description>정리 1 $H$ 가 유한군 $G$ 의 부분군이면 $|H|$ 는 $|G|$ 의 약수다. 증명 모든 잉여류들은 모두 같은 수만큼의 원소를 갖는다. $H$ 역시 $G$ 의 잉여류 중 하나이므로, $H$ 의 잉여류들의 기수Cardinality는 $|H|$ 이다. 잉여류들은 $G$ 의 분할을 이루므로 모든 잉여류들의 기수를 더하면 $|G|$ 이다. $H$ 의 잉여류의 갯수 $( G : H )$ 를 $r$ 이라고 하면 $$ |G| = |H| + \cdots |H| = r |H| $$ 따</description>
    </item>
    
    <item>
      <title>르벡 공간에서의 코시-슈바르츠 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-schwarz-inequality/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-schwarz-inequality/</guid>
      <description>정리1 $f,g \in L^{2} (E)$면 $fg \in L^{1}(E)$이고 다음이 성립한다. $$ \left| \int_{E} f \overline{g} dm \right| \le \left\| f g \right\|_{1} \le \left\| f \right\|_{2} \left\| g \right\|_{2} $$ 여기서 $\| \cdot \|_{2}$은 $L^{2}$ 공간의 놈, $\| \cdot \|_{1}$은 $L^{1}$ 공간의 놈이다. 설명 함수해석학 정도를 배우고 있다면 이 부등식에 왜 코시-슈바르츠라는 이름이 붙었는지 바로 감이 와야한다. 사실 내적이 정의된다면 코시-슈</description>
    </item>
    
    <item>
      <title>L2 공간</title>
      <link>https://freshrimpsushi.github.io/posts/l2-space/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/l2-space/</guid>
      <description>정의 1 함수공간 $L^{2}$를 다음과 같이 정의한다. $$ L^{2} (E) := \left\{ f : \left( \int_{E} | f |^2 dm \right)^{{1} \over {2}} &amp;lt; \infty \right\} $$ 성질 $L^{2}$는 벡터공간이다. $L^{2}$는 놈 공간이다. $L^{2}$는 완비공간이다. $L^{2}$는 내적공간이다. 설명 $L^{2}$ 공간은 $L^{p}$ 공간의 $p=2$일 때의 특수한 경우이며, $L^{p}$ 공간 중 유일하게 내적이 정의되는 공간이</description>
    </item>
    
    <item>
      <title>유클리드의 완전수 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-euclids-perfect-number-formula/</link>
      <pubDate>Tue, 26 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-euclids-perfect-number-formula/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $2^{p}-1$ 이 소수면 $2^{p-1}(2^{p} - 1)$ 은 완전수다. 모든 완전수가 저런 형태일지는 확실하지 않지만, 저런 형태는 반드시 완전수다. 예를 들면 소수 $(2^2 -1) = 3$ 에 대해 $2^{2-1}(2^2 -1) = 6$ 은 완전수다.완전수와 메르센 소수가 이러한 관계를 가지고 있음은 메르센 소수의 등비급수전개에서 어느정도 짐작을 할 수가 있었다. 유도 $2^{p}-1$ 이 소수</description>
    </item>
    
    <item>
      <title>L1 공간</title>
      <link>https://freshrimpsushi.github.io/posts/l1-space/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/l1-space/</guid>
      <description>정의1 함수공간 $L^{1}$을 다음과 같이 정의한다. $$ L^{1} (E) := \left\{ f : \int_{E} | f | dm \lt \infty \right\} $$ 성질 $L^{1}$은 벡터공간이다. $L^{1}$은 놈 공간이다. $L^{1}$은 완비공간이다. 설명 $L^{1}$ 공간은 $L^{p}$ 공간의 $1=2$일 때의 특수한 경우이며, 르벡 적분가능에 대해 이야기할 때 적분가능한 함수들의 집합으로써 정의된 바 있다. $L</description>
    </item>
    
    <item>
      <title>부분군의 정의와 부분군 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-subgroup-and-subgroup-test/</link>
      <pubDate>Sat, 23 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-subgroup-and-subgroup-test/</guid>
      <description>정의 1 군 $G$의 부분 집합 $H$가 군 $G$의 연산에 대해서 군의 조건을 만족할 때, $H$를 군 $G$의 부분군($\mathrm{Subgroup}$)이라고 한다. 정리: 부분군 판정법 군 $G$의 공집합이 아닌 부분집합 $H$에 대해서 $a,\ b$가 $H$의 원소일 때 $ab^{-1}$도 $H$의 원소이면 $H$는 $G$의 부분군이다</description>
    </item>
    
    <item>
      <title>페아노 공간 충전 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-peano-space-filling-curve/</link>
      <pubDate>Sat, 23 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-peano-space-filling-curve/</guid>
      <description>정리 1 $I = [0,1]$ 에 대해 전사 연속함수 $f : I \to I \times I$ 가 존재한다. 설명 짧지만 몹시 충격적인 정리다. 이 정리가 사실이라면 선만으로 평면을 구성할 수 있다는 뜻인데, 증명을 보고도 납득하기가 어려울 정도다.&amp;lsquo;공간 충전 정리&amp;rsquo;라는 명칭은 일본에서 번역한 것을 임의로 쓴 것이다. 증명 Part 1. 다음 그림들과 같이 경로의 수열 $\left\{ f_{n} \</description>
    </item>
    
    <item>
      <title>르벡 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lebesgue-theorem/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lebesgue-theorem/</guid>
      <description>정의 $\mathscr{O}$ 를 거리공간 $(X,d)$ 의 열린 커버라고 하자. $\sup \left\{ d(a,b) \ | \ a,b \in A \right\} &amp;lt; \varepsilon$ 를 만족시키는 모든 부분집합 $A \subset X$ 이 어떤 $O \in \mathscr{O}$ 에 대해 $A \subset O$ 를 만족하면 $\varepsilon &amp;gt; 0$ 를 $\mathscr{O}$ 에 대한 르벡 수Lebesgue Number라 한다. 정리 1 [1] 르벡 보조정리: $X$ 가 집적점 컴팩트면 $X$ 의 모든 열린 커버 $\mathscr{O}$ 에 대해 르벡 수가 존재한다. [2] 르벡 정리: $X$ 가 컴팩트면 $X$ 의 모든 열</description>
    </item>
    
    <item>
      <title>디리클레 경계 조건이 주어진 파동방정식에 대한 초기값 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-wave-equation-for-given-dirichlet-boundary-condition/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-wave-equation-for-given-dirichlet-boundary-condition/</guid>
      <description>설명 $$ \begin{cases} u_{tt} = c^2 u_{xx} \\ u(0,x) = f(x) \\ u_{t}(0,x) = g(x) \\ \end{cases} $$ 위 방정식은 파동 방정식에서 길이가 $l$ 인 $1$차원 공간 상의 디리클레 경계조건 $$ \begin{cases} u(t,0) = \alpha(t) \\ u(t,l) = \beta (t) \end{cases} $$ 이 $\alpha = \beta = 0$ 으로 주어지고 파형에 대한 초기 조건이 있는 경우다. 이러한 문제 유형 중에는 가장 쉽고 단순한 형태다. 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간 $t$일 때 $x$</description>
    </item>
    
    <item>
      <title>파동방정식에 대한 코시 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-cauchy-problem-for-wave-equation/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-cauchy-problem-for-wave-equation/</guid>
      <description>tjfaud $$ \begin{cases} u_{tt} = c^2 u_{xx} \\ u(0,x) = f(x) \\ u_{t}(0,x) = g(x) \end{cases} $$ 위 식은 다음과 같은 파동 방정식 $$ \rho (x) {{\partial^2 u} \over {\partial t^2}} = {{ \partial } \over {\partial x}} \left( \kappa (x) {{ \partial u } \over { \partial x }} \right) $$ 에서 밀도density $\rho (x) &amp;gt; 0$ 와 강도stiffness $\kappa (x) &amp;gt; 0$ 이 모두 상수인 경우로써 $\displaystyle c : = {{\kappa} \over {\rho}}$ 를 파속wave speed이라 한다. 여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때의 파형을 나타</description>
    </item>
    
    <item>
      <title>디리클레 경계 조건이 주어진 열방정식에 대한 초기값 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-heat-equation-for-given-dirichlet-boundary-condition/</link>
      <pubDate>Mon, 18 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-heat-equation-for-given-dirichlet-boundary-condition/</guid>
      <description>설명 $$ \begin{cases} u_{t} = \gamma u_{xx} \\ u(t,0) = u(t,l) = 0 \\ u(0,x) = f(x) \end{cases} $$ 위 방정식은 열방정식에서 길이가 $l$ 인 $1$차원 공간 상의 디리클레 경계조건 $$ \begin{cases} u(t,0) = \alpha(t) \\ u(t,l) = \beta (t) \end{cases} $$ 이 $\alpha = \beta = 0$으로 주어지고 열분포에 대한 초기 조건이 있는 경우다. 이러한 문제 유형 중에는 가장 쉽고 단순한 형태다. 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간 $t$일 때 열</description>
    </item>
    
    <item>
      <title>열방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-heat-equation/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-heat-equation/</guid>
      <description>설명 $$ u_{t} = \gamma u_{xx} $$ 위 식은 다음의 일반화된 열방정식 $$ {{\partial} \over {\partial t}} \left( \sigma (x) u \right) = {{\partial} \over {\partial x }} \left( \kappa (x) {{\partial u} \over {\partial x}} \right) $$ 에서 열전도율thermal conductivity $\kappa (x) &amp;gt; 0$ 와 열용량heat capacity $\sigma(x) &amp;gt; 0$ 이 모두 상수인 경우로써 $\displaystyle \gamma : = {{\kappa} \over {\sigma}}$ 을 열확산율thermal diffusivity이라 한다. 여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때 열의 분포를 나타</description>
    </item>
    
    <item>
      <title>편미분 방정식 풀이를 위한 푸리에 급수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-series/</link>
      <pubDate>Sat, 16 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-series/</guid>
      <description>정의 힐베르트 공간의 함수 $f \in \mathcal{L}^{2} [- \pi , \pi] $ 에 대해 $\displaystyle a_{k} = {{1} \over {\pi}} \int_{- \pi}^{\pi} f(x) \cos kx dx$ 그리고 $\displaystyle b_{k} = {{1} \over {\pi}} \int_{- \pi}^{\pi} f(x) \sin kx dx$ 에 대해 $$ f(x) \sim {{a_{0}} \over {2}} + \sum_{k=1}^{\infty} \left( a_{k} \cos kx + b_{x} \sin kx \right) $$ 를 $f$ 의 푸리에 급수Fourier series라 한다. 설명 테일러 급수가 어떤 함수를 다항식으로 근사시키는 것과 달리 푸리에 급수는 삼각다항식으로 근사시킨다. 이렇듯 복잡한 모양을</description>
    </item>
    
    <item>
      <title>R 에서 여러가지 분포함수</title>
      <link>https://freshrimpsushi.github.io/posts/random-number-generate-in-r/</link>
      <pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-number-generate-in-r/</guid>
      <description>설명 R 에서 특정 분포에 대한 함수들은 다음과 같은 접두어와 접미어의 조합으로 만들어진다. 접두 확률분포 $X$ 의 확률분포함수를 $f(x)$ 라고 하자. r-:랜덤 추출, 확률분포 $X$ 에서 나온 $x_{1}, \cdots , x_{n}$ 을 생각하면 좋다. d-: 분포함수, $f(x)$ p-: 누적분포함수, $F(x) = \displaystyle \int_{\infty}^{x} f(t) dt$ q-: 분위수함수, $F^{-1}(\alpha)$ 접미 이름이 알려진 분포는 거의 다 있지만 특히 자주 쓰는 분포는 아래와 같다.</description>
    </item>
    
    <item>
      <title>버거스 방정식에 대한 리만 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-riemann-problem-for-burgers-equation/</link>
      <pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-riemann-problem-for-burgers-equation/</guid>
      <description>설명 $$ \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = \begin{cases} a &amp;amp; ,x&amp;lt;0 \\ b &amp;amp; ,x&amp;gt;0 \end{cases} &amp;amp; , t=0 \end{cases} $$ 리만 문제란 초기값이 주어진 버거스 방정식 중에서도 그 해를 계단 함수step function 로 갖는 경우를 말한다. 이 때 $a \ne b$ 면 그냥 구한 해의 함숫값이 특정 구간에서 여러개 존재하거나 아예 존재하지 않거나 하게 된다. 따라서 등적률을 적용시키거나 평활화smoothing 된 해를 구한다.</description>
    </item>
    
    <item>
      <title>R 에서 올림, 내림, 반올림, 자릿수 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-round-numbers/</link>
      <pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-round-numbers/</guid>
      <description>개요 ceiling() 함수는 올림 처리를, floor() 함수는 내림 처리를 해준다. 이런 함수들은 주로 통계를 다루는 R 에서는 필요 없어 보이지만 의외로 데이터 핸들링을 할 때 써먹기가 편하다. 설명 trunc() 함수는 소수점 아래를 모두 버려주는 건 똑같지만 $0$ 에 더 가까운 쪽으로 값을 반환해준다. round() 함수와 signif() 함수 모두 자리수를 남기지만 round()는 소수점 아래를, signif(</description>
    </item>
    
    <item>
      <title>볼자노-바이어슈트라스 성질과 집적점 컴팩트</title>
      <link>https://freshrimpsushi.github.io/posts/bolzano-weierstrass-property-and-limit-point-compact/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bolzano-weierstrass-property-and-limit-point-compact/</guid>
      <description>정의 1 위상공간 $X$ 의 모든 무한 부분집합의 집적점이 $X$ 에 속하면 $X$ 가 볼자노-바이어슈트라스 성질을 가진다고 하거나 집적점 컴팩트라 한다. 정리 [1]: 모든 컴팩트 공간은 집적점 컴팩트 공간이다. [2]: $X$ 가 거리 공간이면 $X$ 가 컴팩트인 것과 집적점 컴팩트인 것은 서로 동치다. 설명 예를 들어 $[a,b]$ 는 집적점 컴팩트지만 $(a,b)$ 는 집적점 컴팩트가 아니다. 또한 $\mathbb{Q}$ 는 $$ P =</description>
    </item>
    
    <item>
      <title>가산 컴팩트와 린델뢰프</title>
      <link>https://freshrimpsushi.github.io/posts/countably-compact-and-lindeloef/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/countably-compact-and-lindeloef/</guid>
      <description>정의 1 $X$ 의 모든 가산 열린 커버가 유한 부분 커버를 가지면 $X$ 를 가산 컴팩트Countably Compact라 한다. $X$ 의 모든 열린 커버가 가산 부분 커버를 가지면 $X$ 를 린델뢰프Lindelöf라 한다. 정리 가산 컴팩트 [1-1]: 모든 컴팩트 공간은 가산 컴팩트 공간이다. [1-2]: 가산 컴팩트성는 위상적 성질이다. 린델뢰프 [2-1]: 제2가산 공간은 린델뢰프 공간이다</description>
    </item>
    
    <item>
      <title>리만적분의 일반화로써의 르벡적분</title>
      <link>https://freshrimpsushi.github.io/posts/lbesgue-integral-generalized-riemann-integral/</link>
      <pubDate>Wed, 30 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lbesgue-integral-generalized-riemann-integral/</guid>
      <description>정리 1 유계 함수 $f : [a,b] \to \mathbb{R}$ 와 $g : \mathbb{R} \to [0,\infty)$ 이라고 하자. [1]: $f$ 가 $[a,b]$ 에서 리만 적분가능한 것은 $f$ 가 르벡 측도에 대해 $[a,b]$ 의 거의 어디에서나 연속인 것과 동치다. [2]: $\displaystyle \int_{a}^{b} f(x) dx$ 가 존재하면 $\displaystyle \int_{a}^{b} f(x) dx = \int_{[a,b]} f dm$ [3]: $\displaystyle \int_{-\infty}^{\infty} g(x) dx$ 가 존재하면 $\displaystyle \int_{-\infty}^{\infty} g(x) dx = \int_{\mathbb{R}} g dm$ 설명 측도에 대한 그 수많은 논의는 모두 이 &amp;lsquo;적분의 일반화&amp;rsquo;를 위한 것으로 보아도 무방</description>
    </item>
    
    <item>
      <title>파이썬으로 웹 문서 크롤링하고 태그 제거하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-crawl-web-site-and-remove-html-tag-using-python/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-crawl-web-site-and-remove-html-tag-using-python/</guid>
      <description>개요 파이썬은 크롤링을 위한 패키지가 잘 갖춰져있어 쉽게 따라할 수 있다. 웹 페이지를 읽어들이고 html 태그를 제거해보자. 예제 코드 import requests from bs4 import BeautifulSoup import re rq = requests.get(&amp;quot;https://ko.wikipedia.org/wiki/%EC%98%A4%EB%A7%88%EC%9D%B4%EA%B1%B8&amp;quot;) rqctnt = rq.content soup = BeautifulSoup(rqctnt,&amp;quot;html.parser&amp;quot;) OMG = str(soup.find\_all(&amp;quot;p&amp;quot;)) OMG = re.sub(&#39;&amp;lt;.+?&amp;gt;&#39;, &#39;&#39;, OMG, 0).strip() 결과 예제로 위키피디아에서 오마이걸 항목을 읽어와보도록 하자. 필요한 패키지는 보이는대로 requests와 bs4가 있다. 읽어들이기만 하고 출력해보면</description>
    </item>
    
    <item>
      <title>오류행렬과 민감도, 특이도</title>
      <link>https://freshrimpsushi.github.io/posts/sensitivity-specipicity-and-confusion-matrix/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sensitivity-specipicity-and-confusion-matrix/</guid>
      <description>오류행렬 분류 문제에서 모형을 평가하는 지표로써 위와 같은 오류행렬Confusion Matrix을 참고할 수 있다. 정분류율Accuracy $$ \displaystyle \text{Accuracy} = {{TP + TN} \over { P + N }} $$ 위 표에서 P는 양성, N은 음성을 나타낸다. TP는 양성으로 예측되었고 실제로 양성인 경우, TN은 음성으로 예측되었고 실제로 음성인 경우다. 이 TP와 TN이 상대적</description>
    </item>
    
    <item>
      <title>균등연속 정리</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-continuous-in-topology/</link>
      <pubDate>Sun, 27 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-continuous-in-topology/</guid>
      <description>정의 거리공간 $(X, d)$ 와 $(Y, d&#39;)$ 에 대해 $f : X \to Y$ 라고 하자. 모든 $\varepsilon &amp;gt; 0$ 와 $x_{1}, x_{2} \in X$ 에 대해 $$ d(x_{1}, x_{2}) &amp;lt; \delta \implies d&#39;( f( x_{1} ) , f( x_{2} ) ) &amp;lt; \varepsilon $$ 을 만족하는 $\delta &amp;gt; 0$ 가 존재하면 $f$ 를 균등연속Uniformly Continuous이라 한다. 설명 해석학에서 배운 연속의 개념이 위상수학에서 일반화되었듯 균등연속 역시 위상수학에서 일반화가 가능하다. 단 여기서</description>
    </item>
    
    <item>
      <title>랜킨-위고니오 조건과 엔트로피 조건</title>
      <link>https://freshrimpsushi.github.io/posts/rankine-hugoniot-condition-and-entropy-condition/</link>
      <pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rankine-hugoniot-condition-and-entropy-condition/</guid>
      <description>정의 $$ \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 위 비점성 버거스 방정식의 해가 $u$고 그 파열 시간이 $t_{\ast}$ 라고 하자. 비점성 버거스 방정식의 해가 파열할 때, 위와 같이 왼쪽과 오른쪽의 넓이가 같아지도록 하는 선분으로 이어준다. 이렇게 물리적으로 해석할 수 있도록 해를 조정하는 것을 등적률等積律equal area rule이라 한다. 설명 이렇게 생기는</description>
    </item>
    
    <item>
      <title>R 에서 문자열 다루기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-handle-strings-in-r/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-handle-strings-in-r/</guid>
      <description>개요 개발자들이 많이 사용하는 언어들에 비교하면 그 정도가 덜하지만, R 에서도 문자열을 다룰 일이 생각보다 많다. 데이터가 방대하고 제멋대로일수록 이런 사소한 테크닉들이 엄청나게 중요해진다. 팁 nchar() 함수는 단순히 문자열의 길이를 반환한다. 다른 언어를 먼저 접한 사람은 아마 십중팔구 length를 먼저 쳐봤을 것이다. substring() 함수는 그 이름에서 쉽게 짐</description>
    </item>
    
    <item>
      <title>정수론에서의 시그마 함수</title>
      <link>https://freshrimpsushi.github.io/posts/sigma-function-in-number-theory/</link>
      <pubDate>Thu, 24 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sigma-function-in-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\displaystyle \sigma (n) : = \sum_{d \mid n} d$ 에 대해 다음이 성립한다. (1)** 소수 $p$ 에 대해, $\displaystyle \sigma( p^k ) = {{p^{k+1} - 1} \over {p-1}} $ 2. $\gcd (n , m ) = 1$ 이면 $\sigma(nm) = \sigma(n) \sigma(m) $ 시그마 함수는 쉽게 말해 약수의 합으로, $6$ 을 예로 들자면 $\sigma(6) = 1 + 2 + 3 + 6 = 12$ 이다. 해석적 정수론에서는 디바이저 함수로 일반화된다. 한편 시그마 함수를 언급함으로</description>
    </item>
    
    <item>
      <title>비점성 버거스 방정식에서의 질량 보존 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/law-of-conservation-of-mass-in-inviscid-burgers-equation/</link>
      <pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/law-of-conservation-of-mass-in-inviscid-burgers-equation/</guid>
      <description>정리 $$ \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 위의 비점성 버거스 방정식의 해 $u$에 대해 구간 $[a,b]$까지의 선질량 $M$을 다음과 같이 정의하자. $$ M_{a,b}(t) := \int_{a}^{b} u(t,x) dx $$ 그리고 파열시간을 $t_{\ast}$이라고 하면 $t \in ( 0 , t_{\ast})$에 대해 다음이 성립한다. $$ {{d} \over {dt}} M_{a,b}(t) = - \left( {{1} \over {2}} u^2 (t,b) - {{1} \over {2}} u^2 (t,a) \right) $$ 설명 파</description>
    </item>
    
    <item>
      <title>측도론에서의 레비의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-levis-theorem-in-measure-theory/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-levis-theorem-in-measure-theory/</guid>
      <description>정리 1 $\displaystyle \sum_{k=1}^{\infty} \int |f_{k}| dm &amp;lt; \infty$ 면 $\displaystyle \sum_{k=1}^{\infty} f_{k} (x)$ 는 거의 어디에서나 수렴하고 $$ \displaystyle \int \sum_{k=1}^{\infty} f_{k} dm = \sum_{k=1}^{\infty} \int f_{k} dm $$ 증명 $\displaystyle \phi (x) := \sum_{k=1}^{\infty} | f_{k} (x) |$ 이라고 정의하면 $\phi$ 는 음이 아닌 가측 함수다. 단조 수렴 정리의 따름 정리: $$\displaystyle \int \sum_{n=1}^{\infty} f_{n} dm = \sum_{n=1}^{\infty} \int f_{n} dm$$ 단조 수렴 정리에 의해 $\displaystyle \int \phi dm = \sum_{n=1}^{\infty} \int | f_{k} | dm$ 인데 가정에서 $\displaystyle \sum_{k=1}^{\infty} \int |f_{k}| dm &amp;lt; \infty$ 이었으므로 $\phi$ 는 적분가능하다. 따라서 $\phi$ 는 거의 어디서나 유</description>
    </item>
    
    <item>
      <title>위상공간에서 최대최소값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-maximum-and-minimum-value-theorem-in-topological-space/</link>
      <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-maximum-and-minimum-value-theorem-in-topological-space/</guid>
      <description>정리 1 컴팩트 공간 $X$ 에 대해 함수 $f : X \to \mathbb{R}$ 가 연속이면 모든 $x \in X$ 에 대해 $f(c) \le f(x) \le f(d)$ 을 만족하는 $c,d \in X$ 가 존재한다. 설명 $\mathbb{R}$ 에서 컴팩트란 폐구간 $[a,b]$ 인 것과 동치이므로 결국 우리가 고등학교, 해석학 때 배운 정리의 일반화가 된다. 위상수학의 어려운 이론들을 사용하는만큼 증명은 오히려 간단하고 쉽다. 증명 컴팩트 공간에 대한 보조정리: $f : X \to Y$ 에</description>
    </item>
    
    <item>
      <title>컴팩트 공간과 연속함수에 대한 유용한 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/useful-properties-of-compact-space-and-continuous-function/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/useful-properties-of-compact-space-and-continuous-function/</guid>
      <description>정리 $f : X \to Y$ 에 대해 $X$ 가 컴팩트, $f$ 가 연속이라고 하자. [1]: $f$ 가 전사면 $Y$ 는 컴팩트다. $f$ 가 전사가 아니더라도 $f(X)$ 는 컴팩트다. [2]: $Y$ 가 하우스도르프면 $f$ 는 닫힌 함수다. 닫힌 집합 $C \subset X$ 에 대해 $f(C) \subset Y$ 는 닫힌 집합이다. [3]: $f$ 가 전단사고 $Y$ 가 하우스도르프면 $f$ 는 위상동형사상이다. [4]: $X$ 가 거리공간이면 $f$ 는 균등연속이다. 설명 별 시덥잖은 성질이</description>
    </item>
    
    <item>
      <title>지프의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/zipfs-law/</link>
      <pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zipfs-law/</guid>
      <description>법칙 코퍼스에서 $k$ 번째로 자주 나타나는 단어의 상대빈도를 $f_{k}$ 라고 하면 $$ f_{k} = {{C} \over {k}} $$ 설명 여기서 $C$ 는 $\displaystyle \sum_{k} f_{k} = 1$ 이 되도록하는 정규화계수다. 히스토그램으로 나타내보면 대략 위와 같은 모양이되 넓이의 합이 정확하게 $1$ 이 되도록 스케일을 조정해준 것이다. 오른쪽에 생기는 두꺼운 꼬리 모양을 롱테일이라고 부른다. 힙스의 법칙과 마찬가지로 경험적으</description>
    </item>
    
    <item>
      <title>힙스의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/heaps-law/</link>
      <pubDate>Fri, 18 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heaps-law/</guid>
      <description>법칙 코퍼스에서 어휘의 갯수를 $M$, 토큰의 갯수를 $T$ 라고 하면 $$ M = kT^{b} $$ 설명 코퍼스가 영어일 경우 보통 상수 $k,b$ 는 $10 \le k \le 100$, 그리고 $b = 0.5$ 정도로 나타난다고 한다. 힙스의 법칙은 수학적인 근거를 두고 유도된 것이 아니라 경험적으로 얻어진 법칙이다. 수식은 언뜻 굉장히 복잡해 보이지만 양변에 로그를 취하면 $\log M = \log k + b \log T$ 가 되고, 다음과 같이 선형적</description>
    </item>
    
    <item>
      <title>R 에서 부트스트랩 함수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-boot-in-r/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-boot-in-r/</guid>
      <description>개요 R 에서 부트스트랩을 시행하는 코드를 직접 짜볼 수도 있지만, 기본적으로 제공되는 함수를 이용할 수도 있다. 그 과정은 아래와 같이 단순하지만 다른 함수들과 사용법에 다른 점이 많아서 처음엔 많이 낯설 것이다. 가이드 Step 1. 구하고 싶은 통계량을 반환하는 함수 boot.fn()을 정의한다.당연히 여기서 함수의 이름은 어찌되든 상관 없다. 이때 인수</description>
    </item>
    
    <item>
      <title>지배 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-dominated-convergence-theorem/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-dominated-convergence-theorem/</guid>
      <description>정리 1 가측집합 $E \in \mathcal{M}$ 와 $g \in \mathcal{L}^{1} (E)$ 에 대해 가측함수열 $\left\{ f_{n} \right\}$ 이 $E$ 의 거의 어디서나 $|f_{n}| \le g$ 를 만족한다고 하자. 만약 $E$ 의 거의 어디서나 $\displaystyle f = \lim_{n \to \infty} f_{n}$ 이면, $f \in \mathcal{L}^{1}(E)$ 이고 $$ \displaystyle \lim_{ n \to \infty} \int_{E} f_{n} (x) dm = \int_{E} f dm $$ $f,g \in \mathcal{L}^{1} (E)$ 는 $f$ 와 $g$ 가 르벡 적분가능 함수임을 의미한다. 설명 단조 수렴 정리와 비교해보자면 $f_{n} \nearrow f$ 라는 조건이 빠졌고 심지어 $f_{n} \ge 0$ 일 필요도 없어졌</description>
    </item>
    
    <item>
      <title>메르센 소수</title>
      <link>https://freshrimpsushi.github.io/posts/mersenne-prime/</link>
      <pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mersenne-prime/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $M_{n} = 2^{n} - 1$ 가 소수면 $M_{n}$ 를 메르센 소수Mersenne Prime라 한다. 메르센 소수의 발견은 $p=x^{n}-1$ 꼴이 소수인지에 대한 탐구로부터 시작된다. 수식을 보자마자 단박에 알아챌 수 있는 것은 $x$ 가 홀수인 경우 $p=2$ 를 제외하면 소수가 될 수 없다는 것이다. 또한 $x^{n}-1 = (x-1) ( x^{n-1} + x^{n-2} + \cdots + x^2 + x + 1 )$ 이므로,</description>
    </item>
    
    <item>
      <title>몬테카를로 방법과 부트스트랩의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/difference-between-monte-carlo-method-and-bootstrap/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-between-monte-carlo-method-and-bootstrap/</guid>
      <description>개요 몬테카를로 방법은 작위적인 데이터로 시뮬레이션을 반복해 새로운 기법을 확인하는 방법이고 부트스트랩은 실제 데이터에서 재표본 추출을 통해 비용을 절감하며 문제를 해결하려는 방법이다. 정의 몬테카를로 방법Monte Carlo Method이란 난수 추출을 통해 관심 있는 대상에 대해 점추정량을 찾는 방법이다. 부트스트랩Bootstrap이란 표</description>
    </item>
    
    <item>
      <title>계획행렬</title>
      <link>https://freshrimpsushi.github.io/posts/design-matrix/</link>
      <pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/design-matrix/</guid>
      <description>빌드업 R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 고작 여섯개지만, 척 봐도 eruptions와 waiting은 양의 상관관계를 가지고 있는 것으로 보인다. 만약 이들의 관계를 어떤 두 상수 $\beta_{0}, \beta_{1}$ 에 대해 $$\text{(eruptions)} = \beta_{0} + \beta_{1} \cdot \text{( waiting) }$$ 으로 나타낼 수 있다면 좋을 것이다. 위 식은 두 변수의 선형관계를 직선의 방정식으로써 나타낸 것</description>
    </item>
    
    <item>
      <title>가우스 정리, 발산 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gauss-theorem-divergence-theorem/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gauss-theorem-divergence-theorem/</guid>
      <description>정리1 3차원 $$ \begin{equation} \int_\mathcal{V} \nabla \cdot \mathbf{ F} dV = \oint _\mathcal{S} \mathbf{F} \cdot d \mathbf{S} \label{1} \end{equation} $$ 이를 가우스 정리Gauss&amp;rsquo;s theorem, 그린 정리Green&amp;rsquo;s theorem, 혹은 발산 정리divergence theorem라고 한다. 설명1 발산 정리는 특히 전자기학에서 많이 사용된다. 수식적 의미 수식적으로는 면적분을 부피적분으로, 부피적분을 면적분으로 바꾸어 표</description>
    </item>
    
    <item>
      <title>르벡 적분가능</title>
      <link>https://freshrimpsushi.github.io/posts/lesbegue-integrable/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lesbegue-integrable/</guid>
      <description>정의 1 $E \in \mathcal{M}$ 이라고 할 떄 가측함수 $f$ 에 대해 $$f^{+} := \max \left\{ f , 0 \right\} \\ f^{-} := \max \left\{ -f , 0 \right\}$$ 라고 하자. 그러면 $$ f = f^{+} - f^{-} \\ | f | = f^{+} + f^{-} $$ 으로 나타낼 수 있다. 만약 $\displaystyle \int_{E} | f | dm &amp;lt; \infty$, 즉 $$ \int_{E} f^{+} dm &amp;lt; \infty \\ \int_{E} f^{-} dm &amp;lt; \infty $$ 이면 $f$ 를 르벡 적분가능Lesbegue Integrable이라 한다. $E$ 에서 적분가능한 함수들의 집합을 다음과 같이 나타낸다.</description>
    </item>
    
    <item>
      <title>회귀분석이란?</title>
      <link>https://freshrimpsushi.github.io/posts/regression-analysis/</link>
      <pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regression-analysis/</guid>
      <description>설명 회귀분석은 거의 모든 통계적 기법의 근간이 되는만큼 너무 일반적이거나 너무 특수하게 설명된 경우가 많다. 그냥 회귀분석이 어떤건지 궁금한 사람에게 한마디로 설명한다면 변수 사이의 관계를 알아내는 방법이라고 할 수 있겠다. 이 유용하고도 놀라운 분석법은 우생학을 만들어낸 프랜시스 골턴Francis Galton의 아이디어에서 태어났다. 골</description>
    </item>
    
    <item>
      <title>클레로 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-clairaut-differential-equation/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-clairaut-differential-equation/</guid>
      <description>정의 아래의 1계 비선형 미분방정식을 클레로 방정식Clairaut equation이라 한다. $$ y=xy^\prime+f(y^\prime ) $$ 설명 클레로 미분방정식은 같은 비선형 미분방정식인 베르누이 미분방정식이나 리카티 미분방정식 보다는 풀기 쉬운 편이다. 풀이 주어진 미분방정식 $y=xy^\prime+f(y^\prime )$의 양변을 미분한 뒤 정리한다. $$ \begin{align*} &amp;amp;&amp;amp; y^\prime = y^\prime+xy^{\prime \prime} + y^{\prime \prime}f^\prime(y^\prime ) \\ \implies &amp;amp;&amp;amp; xy^{\prime \prime} + y^{\prime \prime}f^\prime(y^\prime )=0 \\ \implies &amp;amp;&amp;amp; y^{\prime \prime}</description>
    </item>
    
    <item>
      <title>포물선의 초점을 지나는 직선이 가지는 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-straight-lines-passing-through-the-focus-of-parabolic-lines/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-straight-lines-passing-through-the-focus-of-parabolic-lines/</guid>
      <description>정리 포물선 $y^2 = 4px$ 에 대해 초점 $P(p,0)$ 을 지나는 직선이 포물선과 만나는 두 점을 각각 $A, B$ 라고 하면 $$ \displaystyle {{1} \over {\overline{PA}} } + {{1} \over {\overline{PB}} } = {{1} \over {p}} $$ 증명 경우 1. $a=b$ 초점을 지나는 직선이 $x = p$ 인 경우다. $\overline{PA} = \overline{PB} = 2p$ 이므로 $$ \displaystyle {{1} \over {\overline{PA}} } + {{1} \over {\overline{PB}} } = {{1} \over {2p}} + {{1} \over {2p}}= {{1} \over {p}} $$ 경우 2. $b \ne a$ 일반성을 잃지 않고, $b&amp;gt;a$ 인 경우만 증명하면 충분하다. $A,B$ 에서 준선으로 내린 선분을</description>
    </item>
    
    <item>
      <title>표본표준편차와 표준오차의 구분</title>
      <link>https://freshrimpsushi.github.io/posts/how-different-between-sample-standard-deviation-and-standard-error/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-different-between-sample-standard-deviation-and-standard-error/</guid>
      <description>정의 $X$ 로부터 얻은 데이터를 $\mathbb{x} = ( x_{1}, x_{2}, \cdots , x_{n} )$ 라고 하자. 표본평균: $$ \overline{x} = {{1} \over {n}} \sum_{i=1}^{n} x_{i} $$ 표본표준편차: $$ s_{x} = \sqrt { {{1} \over {n-1}} \sum_{i=1}^{n} ( x_{i} - \overline{x} )^2 } $$ 표준오차: $$ \text{s.e.}( \hat{x} ) = {{ s_{x} } \over { \sqrt{n} }} $$ 설명 말이 비슷해서인지 의외로 많은 사람들이 표본표준편차와 표준오차를 구분하지 못한다. 사실상 통계를 글로만 배우는 고등학생들은 물론이고 심하게는 통계학과</description>
    </item>
    
    <item>
      <title>R 에서 멱함수 그래프 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-power-function-in-r/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-power-function-in-r/</guid>
      <description>개요 간단하게 일변량 함수의 그래프를 그리는 법을 소개한다. 통계학에서 적절한 예로써 멱함수를 그려보자. 정의 귀무가설 $H_{0} : \theta \in \omega_{0}$ 과 대립가설 $H_{1} : \theta \in \omega_{1}$ 에 대해 유의수준 $\alpha$ 의 기각역을 $C_{\alpha}$ 라고 하자. 참값 $\theta$ 에 대한 함수 $\gamma_{C_{\alpha}}(\theta) : = P_{\theta} [ \mathbb{x} \in C_{\alpha} ]$ 를 멱함수Power Function라 한다. 설명 다른 표현으로는 $\gamma_{C_{\alpha}}(\theta) : = 1 - P_{\theta}[\text{Type 2 Error}]$ 이다. 유의확률과 마</description>
    </item>
    
    <item>
      <title>리카티 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-ricatti-differential-equation/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-ricatti-differential-equation/</guid>
      <description>정의 아래의 1계 비선형 미분방정식을 리카티 방정식Ricatti equation이라 한다. $$ y^\prime = P(x)y+Q(x)y^2+R(x) $$ 설명 $y_1$을 이미 알고있는 특별해particular solution라고 하면 일반해는 $y=y_1+u(x)$ 꼴로 나타내진다. 이 때 $u(x)$는 임의의 상수이며 $n=2$일 때의 베르누이 미분방정식을 풀어서 얻을 수 있다. 풀이 리카티 방정식</description>
    </item>
    
    <item>
      <title>p값 혹은 유의확률에 대한 흔한 오개념들</title>
      <link>https://freshrimpsushi.github.io/posts/significance-probability-p-value/</link>
      <pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/significance-probability-p-value/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 요약 : p-value가 아주 작다는 것은 그만큼 드문 일이라는 뜻으로, 단순한 우연으론 보기 어려우며 대립가설을 기각하기 어려움을 의미한다. 가설검정에서 검정통계량이 귀무가설을 기각하도록 나타날 확률로써 귀무가설을 기각하게 되는 최소의 유의수준을 유의확률Significance Probability</description>
    </item>
    
    <item>
      <title>베르누이 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-bernoulli-differential-equation/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-bernoulli-differential-equation/</guid>
      <description>정의 아래의 1계 비선형 미분방정식을 베르누이 방정식Bernoulli equation이라 한다. $$ y^\prime + p(x)y = q(x)y^n $$ 이 때 $n$은 $2$이상의 정수이며, $n=0,\ 1$일 때는 선형 방정식이다. 설명 참고로 베르누이 미분방정식의 베르누이와 널리 알려진 유체역학의 베르누이 방정식의 베르누이는 다른 사람이다. 베르누이 가문이 워낙 수학, 과학으로 뛰</description>
    </item>
    
    <item>
      <title>상관관계가 없다고 독립인 것은 아니다</title>
      <link>https://freshrimpsushi.github.io/posts/no-correlation-implies-no-independency/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/no-correlation-implies-no-independency/</guid>
      <description>설명 독립이면 상관관계가 없지만, 상관관계가 없다고 독립인 것은 아니다. 상관관계가 없을 때 독립인 경우, 즉 필요충분조건이 되는 경우는 확률변수가 정규분포를 따를 때다. 왼쪽의 경우에 양의 상관관계, 오른쪽의 경우에 음의 상관관계가 있다고 한다. 그림의 cor는 상관계수로써, 두 변수가 얼마나 선형적인 관계를 가지는지를 나타내는 지표다. 독립</description>
    </item>
    
    <item>
      <title>2계 미분방정식의 두 번째 해를 구하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/second-solution-of-second-order-differential-equation/</link>
      <pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/second-solution-of-second-order-differential-equation/</guid>
      <description>설명1 $$ \begin{equation} y^{\prime \prime }+p(t)y^\prime + q(t)y=0 \label{eq1} \end{equation} $$ 위와 같은 미분방정식이 주어졌고, 하나의 해 $y_{1}$을 알고 있다고 하자. 일반해를 $y(t)=\nu(t) y_1(t)$라고 가정하자. $y$의 1계, 2계 미분을 구해보면 다음과 같다. $$ \begin{align*} y^\prime &amp;amp;= \nu ^\prime y_1 + \nu y_1^\prime \\ y^{\prime \prime} &amp;amp;= \nu ^{\prime \prime}y_1 + \nu ^\prime y_1^\prime + \nu^ \prime y_1^\prime + \nu y_1^{\prime \prime} \\ &amp;amp;= \nu ^{\prime \prime}y_1 + 2\nu ^\prime y_1^\prime + \nu y_1^{\prime \prime} \end{align*} $$ $y^\prime$, $y^{\prime \prime}$을 $\eqre</description>
    </item>
    
    <item>
      <title>단조 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-monotone-convergence-theorem/</link>
      <pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-monotone-convergence-theorem/</guid>
      <description>정리 1 함숫값이 음이 아닌 가측 함수의 수열 $\left\{ f_{n} \right\}$ 이 $f_{n} \nearrow f$ 을 만족한다고 하자. 그러면 $$ \displaystyle \lim_{n \to \infty} \int_{E} f_{n} dm = \int_{E} f dm $$ 설명 $f_{n} \nearrow f$ 이란 모든 $x$ 에 대해 $f_{n}(x) \le f_{n+1} (x)$ 이면서 $\displaystyle \lim_{n \to \infty} f_{n} = f$ 인 것이다. 수식은 너무 쉽기 때문에 이 정리를 안다는 것은 &amp;lsquo;조건&amp;rsquo;을 정확하게 안다는 말이다. 유용성으로 따질 것 같으면 극한이 적분을 마음대로</description>
    </item>
    
    <item>
      <title>파투의 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fatous-lemma/</link>
      <pubDate>Sat, 05 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fatous-lemma/</guid>
      <description>정리 1 함숫값이 음이 아닌 가측 함수의 수열 $\left\{ f_{n} \right\}$ 에 대해 $$ \displaystyle \int_{E} \left( \liminf_{n \to \infty} f_{n} \right) dm \le \liminf_{n \to \infty} \int_{E} f_{n} dm $$ 설명 실해석에서의 단조 수렴 정리와 지배 수렴 정리를 증명하기 위해 필요한 보조정리다. 가측 함수라는 조건이 빠진 급수에 대한 파투 보조정리는 다음과 같다. 함숫값이 음이 아닌 함수의 수열 $\left\{ f_{k} : \mathbb{N} \to [0, \infty) \right\}_{k \in \mathbb{N}}$ 에 대해 $$ \sum_{j=1}^{\infty} \liminf_{k \to \infty} f_{k} (j) \le \liminf_{k \to \infty} \sum_{j=1}^{\infty} f_{k} (j) \qquad ,</description>
    </item>
    
    <item>
      <title>2계 선형 비동차 미분방정식의 일반해</title>
      <link>https://freshrimpsushi.github.io/posts/general-solution-of-nonhomogeneous-second-order-linear-differential-equation/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-solution-of-nonhomogeneous-second-order-linear-differential-equation/</guid>
      <description>보조정리1 아래와 같은 비동차/동차 2계 선형 미분방정식을 생각해보자. $$ \begin{align} y^{\prime \prime}+p(t)y^\prime + q(t)y &amp;amp;=g(t) \label{eq1} \\ y^{\prime \prime}+p(t)y^\prime + q(t)y &amp;amp;=0 \label{eq2} \end{align} $$ 이 때 $Y_1 (t)$와 $Y_2 (t)$가 비동차 미분방정식 $\eqref{eq1}$의 해이고, $y_1(t)$, $y_2(t)$가 동차 미분방정식 $\eqref{eq2}$의 기본 해집합이라고 하자. 그러면 아래의 식이 성립한다. $$ Y_1 (t) – Y_2 (t)=</description>
    </item>
    
    <item>
      <title>비점성 버거스 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-inviscid-burgers-equation/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-inviscid-burgers-equation/</guid>
      <description>정의 다음의 편미분방정식을 버거스 방정식Burgers&#39; equation이라 한다. $$ \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간 $t$일 때 $x$에서의 파형을 나타낸다. $f$는 초기 조건으로써 특히 $t=0$일 때의 파형을 나타낸다. 설명 버거스 방정식은 은$\dis</description>
    </item>
    
    <item>
      <title>2계 선형 동차 미분방정식의 해의 기본집합과 론스키안</title>
      <link>https://freshrimpsushi.github.io/posts/wronskian-and-fundamental-set-of-solution-of-second-order-linear-homogeneous-differential-equation/</link>
      <pubDate>Thu, 03 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/wronskian-and-fundamental-set-of-solution-of-second-order-linear-homogeneous-differential-equation/</guid>
      <description>정의1 $$ ay^{\prime \prime}+ by^\prime +cy=0 $$ 위와 같은 2계 선형 동차 미분방정식이 주어졌다고 하자. $W$를 론스키안이라고 하자. $W (y_1, y_2) \ne 0$이면 $\left\{ y_1, y_2 \right\}$를 주어진 미분방정식의 해의 기본집합fundamental set of solution이라 한다. 설명 $$ ay^{\prime \prime}+ by^\prime +cy=0 $$ 위와 같은 2계 선형 동차 미분방정식이 주어졌다고 하자. 미분 연산자를 $D := \</description>
    </item>
    
    <item>
      <title>비균일 진행파 편미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-nonuniform-traveling-wave-partial-differential-equation/</link>
      <pubDate>Thu, 03 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-nonuniform-traveling-wave-partial-differential-equation/</guid>
      <description>정의 다음의 식을 만족하는 $u$를 비균일 진행파non-uiform traveling wave라고 한다. $$ \displaystyle \begin{cases} u_{t} + c(x) u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간 $t$일 때 $x$에서의 파형을 나타낸다. $f$는 초기 조건으로써 특히 $t=0$일 때의 파형을 나타낸다. 함수 $c(x)$는 파동의</description>
    </item>
    
    <item>
      <title>균일 진행파 편미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-uniform-traveling-wave-partial-differential-equation/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-uniform-traveling-wave-partial-differential-equation/</guid>
      <description>정의 다음의 식을 만족하는 $u$를 균일 진행파uniform traveling wave라고 한다. $$ \displaystyle \begin{cases} u_{t} + c u_{x} + a u = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간 $t$일 때 $x$에서의 파형을 나타낸다. $f$는 초기 조건으로써 특히 $t=0$일 때의 파형을 나타낸다. 상수 $c$ 는 파동의 진행 속도를 나</description>
    </item>
    
    <item>
      <title>동차 미분방정식에서 동차의 의미</title>
      <link>https://freshrimpsushi.github.io/posts/meaning-of-homogeneous-in-homogeneous-differential-equation/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/meaning-of-homogeneous-in-homogeneous-differential-equation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 ※정확한 내용이 아니라 개인적인 생각이므로 사실과 다를 수 있습니다. 미분방정식을 분류하는 기준 중에서 동차/비동차 (제차/비제차)가 있다. 선형이니, 1차니 2차니 하는 기준은 그 말과 내용을 받아들이기 쉬울 것이다. 허나 동차 라고 하는 것은 말과 그 내용을 쉽게 연결짓기가 힘들다. 우선 어떨</description>
    </item>
    
    <item>
      <title>정상파 편미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-stationary-wave-partial-differential-equation/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-stationary-wave-partial-differential-equation/</guid>
      <description>정의 다음의 조건을 만족하는 $u$를 정상파stationary wave라고 한다. $$ \displaystyle \begin{cases} u_{t} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 설명 정상파는 시간이 흘러도 모양이 변하지 않는 파동이다. 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간이 $t$일 때 $x$에서의 파형을 나타낸다. $f$는 초기 조건으로써 특히 $t=0$일 때의</description>
    </item>
    
    <item>
      <title>2계 선형 동차 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-second-order-linear-homogeneous-differential-equation/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-second-order-linear-homogeneous-differential-equation/</guid>
      <description>정리1 $$ ay^{\prime \prime} + by^\prime + cy=0 $$ 위와 같이 주어진 미분방정식의 특성 방정식 $ar^2+br+c=0$의 해를 $r_1$, $r_2$라고 하자. 그러면 $r_1$, $r_2$가 서로 다른 두 실수인 경우$(b^2-4ac&amp;gt;0)$ 일반해는 다음과 같다. $$ y(t)=c_1e^{r_1t}+c_2e^{r_2t} $$ $r_1$, $r_2$가 켤레 복소수 $\lambda \pm i \mu$인 경우$(b^2-4ac&amp;lt;0)$ 일반해는 다음과</description>
    </item>
    
    <item>
      <title>R 에서 자리수 출력 제한 없애기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-unlimit-digits-and-print-in-r/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-unlimit-digits-and-print-in-r/</guid>
      <description>개요 R 이 통계학을 위한 언어긴하지만 막상 R 콘솔은 데이터를 보는데 적합하지 않다. 그럼에도 불구하고 관측치가 수십만개에 달하는 빅데이터를 다룰 때나 핸들링이 잘 되었나 확인할 땐 단순 출력이 편하다. 팁 관측치가 조금 많을 때 콘솔로 출력해보면 위와 같이 아랫부분이 뭉텅 잘려나온다. 이럴 땐 콘솔창에 options(max.print = .Machine$integer.max</description>
    </item>
    
    <item>
      <title>르벡 적분</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-integral/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-integral/</guid>
      <description>빌드업 리만 적분의 일반화를 생각하기 이전에 단순 함수Simple Function라는 것을 정의할 필요가 있다. 함숫값이 음이 아닌 $\phi : \mathbb{R} \to \mathbb{R}$ 의 치역이 유한 집합 $\left\{ a_{1} , a_{2}, \cdots , a_{n} \right\}$ 이라고 하자. $A_{i} = \phi^{-1} \left( \left\{ a_{i} \right\} \right) \in \mathcal{M}$ 을 만족하면 $\phi$ 를 단순 함수라 한다. 단순 함수는 다음 성질들을 가진다. (i): $i \ne j$ 면 $A_{i } \cap A_{j} = \emptyset$ (ii): $\displaystyle \bigsqcup_{k=1}^{n} A_{k} = \mathbb{R}$ (iii): $\displaystyle \phi(x) = \sum_{k=1}^{n} a_{k} \mathbb{1}_{A_{k}}(x)$ 는</description>
    </item>
    
    <item>
      <title>복원력과 1차원 단순 조화 진동자</title>
      <link>https://freshrimpsushi.github.io/posts/restoring-force-and-simple-harmonic-oscillator/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/restoring-force-and-simple-harmonic-oscillator/</guid>
      <description>단순 조화 운동1 용수철에 매달린 물체의 운동을 생각해보자. 용수철의 복원력에 의해서 왔다갔다하면서 진동한다. 이러한 운동을 조화 진동harmonic oscillation이라 한다. 조화 진동을 표현하는 함수인 $\sin$과 $\cos$을 아주 예전에는 조화 함수라고 불렀기 때문이다. 조화 진동 중에서도 마찰력이나 다른 외부의 힘은 전</description>
    </item>
    
    <item>
      <title>R 에서 NA 제거하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-delete-na-in-r/</link>
      <pubDate>Sun, 29 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-delete-na-in-r/</guid>
      <description>개요 NA는 Not Available의 약자로, R 프로그래밍에선 주로 &amp;lsquo;결측값&amp;rsquo;을 의미한다. 일반적인 프로그래밍 언어에서의 null과는 그 의미도 쓰임새도 전혀 다름에 주의하도록 하자. 교과서에서 다루는 예제들은 보통 분석하기에 알맞도록 잘 정리되어 있지만, 실제로 분석에 임할 땐 전혀 그렇지가 않다. 그런 데이터를</description>
    </item>
    
    <item>
      <title>n-그램과 자카드 계수</title>
      <link>https://freshrimpsushi.github.io/posts/n-gram-and-jaccard-coefficient/</link>
      <pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/n-gram-and-jaccard-coefficient/</guid>
      <description>정의 n-그램n-gram이란 어떠한 문자열을 n개씩 끊어서 자른 것을 말한다. 자카드 계수Jaccard Coefficient란 두 집합이 얼마나 비슷한지에 대한 척도로써 $0$ 부터 $1$ 사이의 값을 가진다. 수식으로 표현하면 다음과 같다. $$ JC(A,B) = {{| A \cap B|} \over {| A \cup B| }} = {{| A \cap B|} \over { |A|+ |B| -| A \cap B| }} $$ 예시 예를 들어 &amp;lsquo;오마이갓&amp;</description>
    </item>
    
    <item>
      <title>상수 계수의 2계 선형 동차 미분방정식과 특성방정식</title>
      <link>https://freshrimpsushi.github.io/posts/second-order-linear-homogeneous-differential-equation-with-constant-coefficients-and-characteristic-equation/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/second-order-linear-homogeneous-differential-equation-with-constant-coefficients-and-characteristic-equation/</guid>
      <description>정리1 상수 계수의 2계 선형 동차 미분방정식 $a y^{\prime \prime} + by^\prime +cy=0$의 일반해는 다음과 같다. $$ y(x)=A e^{r_1 x}+Be^{r_2 x} $$ 이 때, $r_{1,2}=\dfrac{-b \pm \sqrt{b^2-4ac}} {2a}$ 풀이 $$ \begin{equation} a\dfrac{d^2}{dx^2}y+b\dfrac{d}{dx}y+cy-0 \label{eq1} \end{equation} $$ 우선 미분연산자 $D$를 다음과 같이 정의하자. $$ D:=\dfrac{d}{dx} \\ Df = D(f) = \dfrac{df}{dx} $$ 그러면 $D$는 $D(ay_{1}+y_{2}) = a\dfrac{dy_{1}}{dx} + \dfrac{dy_{2}}{dx} = aDy_{1}+Dy_{2}$를 만족하기 때문에 선형 연산자이다. $D$를 이용하여 식$\eqr</description>
    </item>
    
    <item>
      <title>측도론에서의 거의 어디서나와 거의 확실히</title>
      <link>https://freshrimpsushi.github.io/posts/almost-everywhere-and-almost-surely-in-measure-theory/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/almost-everywhere-and-almost-surely-in-measure-theory/</guid>
      <description>정의 1 함수 $f : E \to \overline{\mathbb{R}}$ 가 $m(E_{0}) = 0$ 인 $E_{0} \subset E$ 을 제외하고 어떤 성질 $P$ 를 가질 때, $f$ 는 $E$ 의 거의 어디서나 $P$ 를 가진다고 한다. 표기 확률을 이야기 할 때 거의 어디서나Almost Everywhere는 거의 확실히Almost Surely 로 표현하며, 한국어만으로 표기하는 게 번거로울 때는 다음과 같이 약자를 써서 표현한다. $$ f = g \text{ a.e.} \\ P(E) = 0 \text{ a.s.} $$ 설명</description>
    </item>
    
    <item>
      <title>선형 동차 미분방정식의 해의 선형 결합도 해임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-a-linear-combination-of-solutions-of-a-linear-homogeneous-differential-equation-also-to-be-solution/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-a-linear-combination-of-solutions-of-a-linear-homogeneous-differential-equation-also-to-be-solution/</guid>
      <description>정리1 $y_{1}, y_{2}$가 $ay^{\prime \prime}+by^\prime +cy=0$의 해이면 $d_{1}y_{1} + d_{2}y_{2}$도 해이다. 이때 $d_{1}, d_{2}$는 임의의 상수이다. 설명 증명을 보면 알겠지만 임의의 $n$계 선형 동차 미분 방정식에 대해서도 성립한다. 증명 $y_{1}, y_{2}$가 $ay^{\prime \prime}+by^\prime +cy=0$의 해라고 하자. 그러면 아래의 두 식이 성립한다. $$ \begin{align*} d_{1} (ay_{1}^{\prime \prime}+by_{1}^\prime + cy_{1} ) &amp;amp;=0 \\ d_{2} (ay_{2}^{\prime \prime}+by_{2}^\prime + cy_{2})</description>
    </item>
    
    <item>
      <title>정수와 실수의 포맷 코드에 d, f를 쓰는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-format-codes-uses-d-f-for-integer-and-real-number/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-format-codes-uses-d-f-for-integer-and-real-number/</guid>
      <description>왜 하필 d와 f인가 1 C 나 파이썬 등에서 문자열의 입출력에 사용하는 포맷 코드로 %s, %c, %d, %f 등이 있다. 알다시피 %s 은 문자열String을 나타내고 %c 는 문자Character를 나타낸다. 그런데 이렇게 머릿글자에서 따온 것과 달리 정수, 실수를 쓸 땐 %i 와 %r 이 아닌 %d 와 %f 를 사용한다. 그 이유는 %d 가 그냥 정수가 아니라 10진법Decimal을,</description>
    </item>
    
    <item>
      <title>삼각함수의 합차공식과 곱셈공식</title>
      <link>https://freshrimpsushi.github.io/posts/sum-to-product-identities-amp-product-to-sum-identities/</link>
      <pubDate>Wed, 25 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-to-product-identities-amp-product-to-sum-identities/</guid>
      <description>합차/곱셈 공식은 자주 쓰이지 않아서 배각/반각 공식보다 중요하지는 않다. 하지만 그렇다고 해서 아예 필요 없는 것도 아니다. 유도과정이 정말 쉬우므로 익혀두고 후에 필요할 때 마다 바로 유도해서 쓸 수 있으면 좋다. 덧셈정리만을 이용해서 유도한다. 덧셈 정리 $$ \begin{align*} \sin ( \theta_{1} \pm \theta_{2}) &amp;amp;= \sin \theta_{1} \cos \theta_{2} \pm \sin \theta_{2} \cos \theta_{2}$ \\ \cos ( \theta_{1} \pm \theta_{2}) &amp;amp;= \cos \theta_{1} \cos\theta_{2} \mp \sin\theta_{1} \sin\theta_{2} \\ \tan ( \theta_{1} \pm \theta_{2}) &amp;amp;= \dfrac{\tan\theta_{1} \pm \tan\theta_{2}}{1</description>
    </item>
    
    <item>
      <title>왜 &#39;음함수&#39;는 잘못된 번역인가?</title>
      <link>https://freshrimpsushi.github.io/posts/why-korean-translation-of-implicit-function-is-inappropriate/</link>
      <pubDate>Wed, 25 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-korean-translation-of-implicit-function-is-inappropriate/</guid>
      <description>정의 양함수냐 음함수냐의 차이는 그저 각각을 어떻게 표현했느냐에 지나지 않는다. 수학에서는 다소 생소한 표현이지만, 그 구분은 &amp;lsquo;독립변수&amp;rsquo;와 &amp;lsquo;종속변수&amp;rsquo;를 어떻게 나타내느냐에 달려있다. 간단히 말하자면 독립변수를 $x$, 종속변수를 그에 따라 달라지는 $y$ 로 두고 그 모양을 보는 것이다. 예시 예</description>
    </item>
    
    <item>
      <title>르벡 가측 함수</title>
      <link>https://freshrimpsushi.github.io/posts/lesbegue-measurable-function/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lesbegue-measurable-function/</guid>
      <description>정의 1 함수 $f: E \in \overline{ \mathbb{R} }$ 가 모든 구간 $I \subset \overline{ \mathbb{R} }$ 에 대해 $f^{-1} (I) = \left\{ x \in \mathbb{R} \ | \ f(x) \in I \right\} \in \mathcal{M}$ 이면 $f$ 를 (르벡) 가측(Lesbegue) Measurable이라 한다. 동치조건 아래의 명제들은 서로 동치다. (1): $f$ 가 르벡 가측 함수다. (2): $f^{-1} ( \emptyset ), f^{-1} ( \overline{\mathbb{R}} ) \in \mathcal{M}$ (3): $f^{-1} \left\{ \infty \right\} , f^{-1} \left\{ -\infty \right\} \in \mathcal{M}$ (4): 모든 $r \in \mathbb{R}$ 에 대해 $f^{-1} ( - \infty , r ], f^{-1} (r, \infty ), f^{-1} ( - \infty</description>
    </item>
    
    <item>
      <title>유체 위에 물체가 올려져 있을 때 깊이에 따른 유체의 압력</title>
      <link>https://freshrimpsushi.github.io/posts/pressure-of-fluid-with-depth-when-an-object-is-placed-on-the-fluid/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pressure-of-fluid-with-depth-when-an-object-is-placed-on-the-fluid/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 간단히 말하자면 유체 위에 물체가 있을 때 깊이에 따른 압력은 깊이에 따른 유체의 압력을 구하는 경우에서 $P_0$ 대신 ${P_0 }^\prime$를 대입하면 된다. 원래의 공식에서 대기압 $P_0$는 유체의 위에서 누르는 압력을 의미했다. 즉. 유체 위에 물체가 올려져 있다면 대기압에 물체로 인한 압력까지 더하</description>
    </item>
    
    <item>
      <title>깊이에 따른 유체의 압력을 구하는 공식</title>
      <link>https://freshrimpsushi.github.io/posts/fluid-pressure-to-depth/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fluid-pressure-to-depth/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 유체의 표면으로부터 수직 거리 $h$만큼 아래인 곳의 압력, 쉽게 말해서 깊이가 $h$인 곳의 유체의 압력은 다음과 같다. $$ P_h=P_0+\rho g h $$ 이 때, $P_0$는 대기압, $\rho$는 물체의 밀도, $g$는 중력 가속도이다. 유도 깊이가 $h$인 곳에 어떤 물체가 평형 상태로 잠겨있다고 하자. 이 물체</description>
    </item>
    
    <item>
      <title>사건의 독립과 조건부 확률</title>
      <link>https://freshrimpsushi.github.io/posts/independent-conditional-probability-of-event/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independent-conditional-probability-of-event/</guid>
      <description>정의 1 확률 공간 $(\Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. $P(B)&amp;gt;0$ 에 대해 $\displaystyle P (A | B) = {{P(A \cap B)} \over {P(B)}}$ 를 $B$ 에 대한 $A$ 의 조건부 확률Conditional Probability이라고 한다. 만약 $P(A | B) = P(A)$, 즉 $P( A \cap B) = P(A) \cdot P(B)$ 면 $A, B$ 가 서로 독립Independent이라고 한다. 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다. 설명 확</description>
    </item>
    
    <item>
      <title>컴팩트 하우스도르프 공간은 정규 공간이다</title>
      <link>https://freshrimpsushi.github.io/posts/compact-hausdorff-space-is-regular-space/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compact-hausdorff-space-is-regular-space/</guid>
      <description>정리 1 [1]: 컴팩트 공간의 닫힌 부분 집합은 컴팩트다. [2]: 하우스도르프 공간의 컴팩트 부분 집합은 닫힌 집합이다. [3]: 하우스도르프 공간 $X$ 의 두 컴팩트 부분 집합 $A,B \subset X$ 가 $A \cap B = \emptyset$ 이면 다음을 만족하는 열린 부분 집합 $U, V \subset X$ 가 존재한다. $$ A \subset U \\ B \subset V \\ U \cap V = \emptyset $$ [4]: 컴팩트 하우스도르프 공간은 정규 공간이다. 설명 정리 [1]과 [2]에서 하우</description>
    </item>
    
    <item>
      <title>유체와 압력</title>
      <link>https://freshrimpsushi.github.io/posts/fluid-and-pressure/</link>
      <pubDate>Mon, 09 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fluid-and-pressure/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 흔히 물질의력 상태를 고체, 액체, 기체 3가지로 분류한다. 이 때, 액체와 기체를 유체라고 한다. 유체라는 한자어를 직역하면 ‘흐르는 것’이고 제 모양을 가지고 있지 않은 상태라고 생각하면 되겠다. 초등학생 때 배웠던 말로 설명하면 모양이 일정하지 않고 담는 그릇에 따라 모양 바뀌는 게 유체이다. 유</description>
    </item>
    
    <item>
      <title>1계 선형 미분방정식의 적분인자법</title>
      <link>https://freshrimpsushi.github.io/posts/method-of-integrating-factor-in-first-order-linear-differential-equation/</link>
      <pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/method-of-integrating-factor-in-first-order-linear-differential-equation/</guid>
      <description>정리1 1계 선형 미분방정식 $\dfrac{dy}{dx}+p(x)y=q(x)$의 해는 다음과 같이 주어진다. $$ \begin{align*} y(x)&amp;amp;=\dfrac{1}{e^{\int p(x) dx}} \left[ \int e^{\int p(x) dx} q(x) dx +C \right] \\ &amp;amp;=e^{-\int p(x) dx}\int e^{\int p(x) dx} q(x) dx + e^{-\int p(x) dx}C \end{align*} $$ 설명 $y^\prime+p(x)y=q(x)$ 꼴의 미분 방정식을 1계 선형 미분방정식이라고 한다. 여기서 $q(x)=0$이면 바로 변수분리가 가능하고 분리 가능한 미분방정식의 풀이대로 해를 구하</description>
    </item>
    
    <item>
      <title>기각역과 유의수준</title>
      <link>https://freshrimpsushi.github.io/posts/rejection-region-and-significance-probability/</link>
      <pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rejection-region-and-significance-probability/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 아무리 데이터가 산더미같이 쌓여있고 정교한 수학적 기법을 적용시켰다고 한들 써먹지 못하면 의미가 없다. 여기서 &amp;lsquo;쓴다&amp;rsquo;는 것은 어떤 데이터에 대해 통계를 내고 그 통계를 근거로 어떠한 &amp;lsquo;주장을 한다&amp;rsquo;는 것이다. 이를 위해선 당연히 그 통계가 믿</description>
    </item>
    
    <item>
      <title>완전 미분방정식의 정의와 판별법</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-method-of-determination-of-exact-differential-equations/</link>
      <pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-method-of-determination-of-exact-differential-equations/</guid>
      <description>정의 다음과 같이 주어진 미분방정식 $$ M(x,y)+N(x,y)y^\prime=0 $$ 에서 $$ \dfrac{\partial \psi }{\partial x}=M(x,y) \quad \And \quad \dfrac{\partial \psi }{\partial y}=N(x,y) $$ 를 만족하는 $\psi=\psi(x,y)$가 존재하면 완전exact 미분방정식이라고 한다. 설명 주어진 미분방정식이 완전 미분방정식이면 미분방정식을 $\psi(x,y)$에 대한 전미분으로 나타낼 수 있다. $$ \begin{align*} &amp;amp;&amp;amp;M(x,y)dx+N(x,y)dy=0 \\ \implies &amp;amp;&amp;amp; \dfrac{\partial \psi }{\partial x}dx + \dfrac{\partial \psi }{\partial y}dy=0 \end{align*} $$ 이 때 $d\psi(x,y)=\dfrac{\partial \psi</description>
    </item>
    
    <item>
      <title>완전 미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-exact-differential-equation/</link>
      <pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-exact-differential-equation/</guid>
      <description>풀이 주어진 완전 미분방정식 $M(x,y)+N(x,y)\dfrac{dy}{dx}=0$의 풀이는 다음과 같다. Step 0. 주어진 미분방정식이 완전하므로 $\psi_{x}=M,\ \ \psi_{y}=N, \ \ \psi=c$인 $\psi$가 존재한다. Step 1. $\psi_{x}$를 적분한다. 그 후 얻은 $\psi$를 다시 $y$로 미분하여 $h^\prime(y)$를 구한다</description>
    </item>
    
    <item>
      <title>구 껍질의 관성모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-spherical-shell/</link>
      <pubDate>Sat, 07 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-spherical-shell/</guid>
      <description>공식 반지름이 $a$, 질량이 $m$인 구 껍질의 관성모멘트는 다음과 같다. $$ I=\frac{2}{3}ma^{2} $$ 유도 반지름이 $a$이고 질량이 $m$인 균일한 구 껍질을 생각해보자. 구의 관성모멘트를 구하는 것과 같은 아이디어를 사용한다. 다만, 조금의 차이가 있다. 구의 관성모멘트를 구할 때 처럼 구 껍질을 수 많은 원통 껍질의 합이라고 생각하자. 근데 여기서 구의 경우와 똑같이 계산</description>
    </item>
    
    <item>
      <title>제1종 오류와 제2종 오류의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/difference-between-type-1-error-and-type-2-error/</link>
      <pubDate>Sat, 07 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-between-type-1-error-and-type-2-error/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 귀무가설 $H_{0}$ 에 대해 $H_{0}$ 이 참인데 채택하지 않은 경우의 오류를 제1종 오류Type 1 Error , $H_{0}$ 이 거짓인데 채택한 경우의 오류를 제2종 오류Type 2 Error라 한다. 귀무가설에는 &amp;lsquo;채택&amp;rsquo;이라는 말을 쓰고 대립가설에는 &amp;lsquo;기각&amp;rsquo;이라는 말을</description>
    </item>
    
    <item>
      <title>유한 교집합 성질</title>
      <link>https://freshrimpsushi.github.io/posts/finite-intersection-property-fip/</link>
      <pubDate>Fri, 06 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finite-intersection-property-fip/</guid>
      <description>정의 1 위상공간 $X$ 에 대해 $\mathscr{A} \subset \mathscr{P} (X)$ 라고 하자. 모든 유한 부분집합 $A \subset \mathscr{A}$ 에 대해 $\displaystyle \bigcap A \ne \emptyset$ 이면 $A$ 가 유한 교집합 성질Finite Intersection Property을 가진다고 한다. 설명 $A$ 가 f.i.p.를 가진다는 것은 열린 집합 $U_{\alpha} \subset A$ 에 대해 항상 다음이 성립하는 것과 같다. $$ \bigcap_{i=1}^{n} \left( X \setminus U_{i} \right) \ne \emptyset \implies \bigcap_{\alpha \in \forall } \left( X \setminus U_{\alpha} \right) \ne \emptyset $$ 이 성질은 위상공간이 아니라 그냥</description>
    </item>
    
    <item>
      <title>귀무가설과 대립가설을 정하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-choose-null-hypothesis-vs-alternative-hypothesis/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-choose-null-hypothesis-vs-alternative-hypothesis/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 귀무가설 $H_{0}$ vs 대립가설 $H_{1}$ 귀무가설은 영가설이라는 이름으로도 불린다.2018년 4월 기준으로 일부 교과서나 위키백과에서는 귀무가설을 &amp;lsquo;통계학에서 처음부터 버릴것을 예상하는 가설&amp;rsquo;로, 대립가설을 &amp;lsquo;연구를 통해 입증되기를 기대하거나 예상하는 가</description>
    </item>
    
    <item>
      <title>르장드르의 배 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-legendres-duplication-formula/</link>
      <pubDate>Wed, 04 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-legendres-duplication-formula/</guid>
      <description>공식 $$ \displaystyle \Gamma (2r) = {{2^{ 2r - 1} } \over { \sqrt{ \pi } } } \Gamma \left( r \right) \Gamma \left( {{1} \over {2}} + r \right) $$ 설명 쪼개지는 모양이 그렇게 예쁘지는 않지만 인수를 작게 나눌 수 있다는 것은 분명 유용한 사실이다. 유도 자체는 베타함수에서 파생된 보조정리를 사용하면 별로 어렵지 않다. 유도 $$ \displaystyle B(p,q) = {{\Gamma (p) \Gamma (q)} \over {\Gamma (p+q) }} = \int_{0}^{1} t^{p-1} (1-t)^{q-1} dt $$ 에 대해 $r:= p=q$ 이라고 하면 $$ \displaystyle {{\Gamma (r) \Gamma (r)} \over {\Gamma (2r) }} = \int_{0}^{1} t^{r-1} (1-t)^{r-1} dt</description>
    </item>
    
    <item>
      <title>양말-신발 성질: ab의 역원은 b의 역원과 a의 역원의 곱과 같다</title>
      <link>https://freshrimpsushi.github.io/posts/socks-shoes-property/</link>
      <pubDate>Wed, 04 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/socks-shoes-property/</guid>
      <description>정리 1 임의의 군 $G$의 원소 $a,b$에 대하여 $(ab)^{-1}=b^{-1}a^{-1}$이다. 증명 $(ab)^{-1}$는 $ab$의 역원이므로 $$ ab(ab)^{-1}=e $$ 양변에 $a^{-1}$를 곱해주면 $$ b(ab)^{-1}=a^{-1}e=a^{-1} $$ 양변에 $b^{-1}$를 곱해주면 $$ (ab)^{-1}=b^{-1}a^{-1} $$ ■ 설명 이 정리에는 양말-신발 성질Socks Shoes Property이라는 이름이 붙</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률</title>
      <link>https://freshrimpsushi.github.io/posts/probability-in-terms-of-measure-theory/</link>
      <pubDate>Tue, 03 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-in-terms-of-measure-theory/</guid>
      <description>정의 1 $\mathcal{F}$ 가 집합 $\Omega$ 의 시그마 필드라고 하자. 가측 집합 $E \in \mathcal{F}$ 를 사건Event라고 한다. $\mathcal{F}$ 상의 측도 $P : \mathcal{F} \to \mathbb{R}$ 가 $P(\Omega) = 1$ 를 만족하면 $P$ 를 확률Probability이라고 한다. $( \Omega, \mathcal{F} , P )$ 를 확률 공간Probability Space라 한다. 설명 측도론의 힘을 빌리면 확률론의 여러가지 개념들에 대해 수리적 토대가 되고 모호함을 제거할</description>
    </item>
    
    <item>
      <title>R 에서 범주형 데이터의 숫자를 숫자형 데이터로 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/factor-to-numeric-in-r/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factor-to-numeric-in-r/</guid>
      <description>개요 숫자임에도 불구하고 범주형 자료로 읽혀서 연속형 데이터로 바꾸고 싶은데 생각대로 되지 않는 이들을 위한 팁이다. 이 포스트는 지면 대부분을 그 원리를 설명하기 위해 할애하고 있으므로 결론만 필요하면 아래의 실전 예시부터 읽기를 추천한다. 참고로, 보통 자료형을 바꿀 때는 Cast라는 표현을 사용한다. 원리 R 을 이용해서 통계분석을 할 때 가장 중요</description>
    </item>
    
    <item>
      <title>물리학에서 운동 에너지, 퍼텐셜 에너지의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-kinetic-energy-and-potential-energy-in-physics/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-kinetic-energy-and-potential-energy-in-physics/</guid>
      <description>운동 에너지1 힘이 위치에만 의존할 때 즉, 속도나 시간에 대해 독립일 때, 입자의 직선운동의 운동방정식(미분방정식)은 아래와 같다. $$ \begin{equation} F(x)=m\ddot{x} \label{force1} \end{equation} $$ 이 때 가속도 $\ddot{x}$를 아래와 같이 속도에 대해서 표현할 수 있다. $$ \begin{align*} \ddot{x} &amp;amp;= \dfrac{d \dot{x}}{dt} \\ &amp;amp;=\dfrac{dv}{dt} \\ &amp;amp;=\dfrac{dv}{dx} \dfrac{dx}{dt} \\ &amp;amp;=v\dfrac{dv}{dx} \\ &amp;amp;= \frac{1}{2}\frac{ d (v^{2})}{ dx } \end{align*} $$ 이를 $\eqref{force1}$에 대입하면 $$ F(x)=m\ddot{x}= m\frac{1}{2}\frac{d(v^{2})}{dx}=\frac{ d }{ dx }\left(</description>
    </item>
    
    <item>
      <title>직교좌표계에서의 벡터, 내적, 외적의 미분</title>
      <link>https://freshrimpsushi.github.io/posts/derivative-of-a-vector-in-cartesian-coordinate/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivative-of-a-vector-in-cartesian-coordinate/</guid>
      <description>공식 $\mathbf{A} = A_{x}\hat{\mathbf{x}} + A_{y}\hat{\mathbf{y}} + A_{z}\hat{\mathbf{z}}, \mathbf{B} = B_{x}\hat{\mathbf{x}} + B_{y}\hat{\mathbf{y}} + B_{z}\hat{\mathbf{z}}$를 3차원 직교좌표계에서의 벡터라고 하자. $n$을 임의의 스칼라라고 하자. 그러면 다음의 식이 성립한다. (a) $\dfrac{ d \left( n \mathbf{A} \right) }{dt} = \dfrac{ dn }{dt} \mathbf{A} + n\dfrac{ d\mathbf{A}}{dt}$ (b) $\dfrac{ d ( \mathbf{A} \cdot \mathbf{B} )}{dt} = \dfrac{ \mathbf{A} }{dt} \cdot \mathbf{B} + \mathbf{A} \cdot \dfrac{ d\mathbf{B}}{dt}$ (c) $\dfrac{ d ( \mathbf{A} \times \mathbf{B}) }{dt} = \dfrac{ d \mathbf{A} } {dt} \times \mathbf{B} + \mathbf{A} \times \dfrac{ d \mathbf{B} } {dt}$ 설명 고등학생 때</description>
    </item>
    
    <item>
      <title>R 에서 외부 데이터 불러오기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-eof-within-quoted-string/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-eof-within-quoted-string/</guid>
      <description>개요 R 은 기본적으로 통계학을 위해 태어난 언어기 때문에 데이터의 입력 역시 편리하게 되어있다. read.table(file, header = FALSE, sep = &amp;quot;&amp;quot;, na.strings = &amp;quot;NA&amp;quot;, fileEncoding = &amp;quot;&amp;quot;) 함수 소개 read.table()은 데이터 테이블을 불러들이는 함수로써 위와 같이 여러가지 유용한 옵션을 제공한다. 옵션자체는 더 많이 있지만, 자주 쓰이고 반드시 알아두어야할 것을 추린 것이다. 다음의 설명들을 참고하</description>
    </item>
    
    <item>
      <title>동차함수와 1계 미분방정식</title>
      <link>https://freshrimpsushi.github.io/posts/homogeneous-function-and-first-order-differential-equation/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homogeneous-function-and-first-order-differential-equation/</guid>
      <description>정의 함수 $f(x,y)$가 임의의 양의 정수 $n$에 대하여 $f(tx,ty)=t^nf(x,y)$를 만족할 때, $f$를 $n$차 동차함수homogeneous function라고 한다. 설명 분리가능한 1계 미분방정식에서 1계 미분방정식 풀이의 핵심은 분리가능한 형태로 만들어주는 것이라고 했다. 주어진 식에서 바로 분리가능</description>
    </item>
    
    <item>
      <title>선팽창계수와 부피팽창계수</title>
      <link>https://freshrimpsushi.github.io/posts/coefficient-of-linear-expansion-and-volume-expansion/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coefficient-of-linear-expansion-and-volume-expansion/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **** 선팽창계수 고체가 열을 받아 팽창할 때 고체의 단위길이당 길이의 변화를 말한다. 예를 들어 길이가 $L$인 고체에 열을 가하고 난 뒤 길이가 $L+\Delta L$로 변했다면 해당 고체의 선팽창계수 $\alpha$를 구하는 과정은 다음과 같다. $$ \Delta L \propto L \Delta T $$ $$ \Delta L = \alpha L \Delta T $$ $$ \therefore \alpha=\dfrac{\Delta L}{L} \dfrac{1}{\Delta T} \left[ ^\circ \mathrm{C} ^{-1} \right] $$</description>
    </item>
    
    <item>
      <title>론스키안의 정의와 독립종속 판별</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-wronskian/</link>
      <pubDate>Sat, 31 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-wronskian/</guid>
      <description>정의1 $S=\left\{ f_{1}, f_{2}, \dots, f_{n} \right\}$가 $n-1$번까지 미분가능한 함수들의 집합이라 하자. 이의 론스키언Wronskian $W$를 다음과 같은 행렬식으로 정의한다. $$ W(x) = W(f_{1}, f_{2}, \dots, f_{n}) := \begin{vmatrix} f_{1} &amp;amp; f_{2} &amp;amp; \cdots &amp;amp; f_{n} \\ f_1’ &amp;amp; f_2’ &amp;amp; \cdots &amp;amp; f_n’ \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ f_{1}^{(n-1)} &amp;amp; f_{2}^{(n-1)} &amp;amp; \cdots &amp;amp; f_{n}^{(n-1)} \end{vmatrix} $$ 설명 미분 가능한 함수들의 집합 역시 벡터공간이 되는 함</description>
    </item>
    
    <item>
      <title>분리 가능한 1계 미분방정식</title>
      <link>https://freshrimpsushi.github.io/posts/separable-first-order-differential-equation/</link>
      <pubDate>Sat, 31 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separable-first-order-differential-equation/</guid>
      <description>정의1 1계 미분 방정식이 다음과 아래의 조건을 만족할 때 분리가능 하다고 한다. $$ f(x)+g(y)\dfrac{dy}{dx}=0 \quad \text{or} \quad f(x)dx-=g(y)dy $$ 설명 여러 가지 모양으로 표현할 수 있지만 중요한 점은 양변으로 각 변수가 분리돼야 한다는 것이다. 이렇게 두 변수를 분리해서 해를 구하는 방법을 변수분리법separation of variables이라 한다. 분리가능함은 굉장히 좋은 조건으로, 주어진</description>
    </item>
    
    <item>
      <title>보렐 집합</title>
      <link>https://freshrimpsushi.github.io/posts/borel-set/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/borel-set/</guid>
      <description>정의 1 $\mathcal{F}$ 를 $\mathbb{R}$ 의 σ-필드라고 하자. $\displaystyle \mathcal{B} : = \bigcap \left\{ \mathcal{F} \ | \ \mathcal{I} \subset \mathcal{F} \right\}$ 을 모든 구간의 집합 $\mathcal{I}$ 에 의해 생성되었다고 하고 $B \in \mathcal{B}$ 을 보렐 집합Borel Set이라 하고, $\mathcal{B}$ 를 보렐 시그마 필드라 부른다. $\mathcal{I}$ 는 모든 구간들의 집합이다. 설명 쉽게 말해 모든 구간을 가지는 시그마 대수 중에 가장 작은 시그마 대수다. 있을 건 다 있으면서 쓸모 없는 것을 쳐내고 필요한</description>
    </item>
    
    <item>
      <title>르벡 측도</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-measure/</link>
      <pubDate>Thu, 29 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-measure/</guid>
      <description>정의 1 $E \in \mathcal{M}$ 에 대해 함수 $m : \mathcal{M} \to [0,\infty]$ 을 $m(E) := m^{ \ast } (E)$ 과 같이 정의하자. $m$ 을 (르벡) 측도라 한다. $\mathcal{M}$ 는 $X = \mathbb{R}$ 의 가측 집합들의 집합인 시그마 대수다. $m^{\ast}$ 는 외측도다. 설명 외측도는 $m^{ \ast } : \mathscr{P}( \mathbb{R} ) \to [0, \infty]$ 으로 깔끔하게 정의된 대신 길이의 일반화로써는 아쉬운 점이 있었다. 대신 실수의 시그마-필드로 정의역에 제한을 주는 것으로 이상적인 &amp;lsqu</description>
    </item>
    
    <item>
      <title>중국인의 나머지 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-chinese-remainder-theorem/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-chinese-remainder-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\gcd(n,m) = 1$ 면 $\begin{cases} x \equiv b \pmod{n} \\ x \equiv c \pmod{m} \end{cases}$ 는 $1 \le x \le nm$ 에서 단 하나의 해를 갖는다. 중국에서 서기 3세기에서 5세기에 쓰여졌다고 전해지는 한 수학서에는 이런 문제가 있었다고 한다.어떤 수를 셋 씩 짝 지으면 둘이 남고,다섯 씩 짝 지으면 셋이 남고,일곱 씩 짝 지으면 둘이 남는다. 이 수는 무엇인가? - 손자산</description>
    </item>
    
    <item>
      <title>오일러의 토션트 합 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-eulers-totient-summation-formula/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-eulers-totient-summation-formula/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $n$ 의 약수를 $d_{1}, d_{2} , \cdots , d_{r}$ 이라고 하면 $\displaystyle n = \sum_{ i = 1 }^{r} \phi(d_{i}) = \phi(d_{1}) + \phi(d_{2}) + \cdots + \phi(d_{r})$ 토션트 함수는 정의할 때부터 다소 부자연스러운 개념이라고 느낄 수 있다. 하지만 토션트 정리도 그렇고 이런 공식도 있는 걸 보면 수학의 진리 어딘가에 분명히 필요한 함수임을 인정할수밖에 없다. 예를 들어 $15$ 를 보면 $15$ 는 약수 $1,3,5,15$</description>
    </item>
    
    <item>
      <title>오일러의 토션트 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-totient-theorem/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-totient-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $$ \gcd(a,m) = 1 \implies a^{ \phi (m) } \equiv 1 \pmod{m} $$ 보자마자 페르마의 소정리를 일반화한 정리임을 알 수 있고, 실제로 증명법도 사실 상 거의 똑같다. 증명 토션트 함수의 정의에 의해, $1 \le b_{i} \le m$ 중 $\gcd( b_{i} , m) =1$ 을 만족하는 $b_{i}$ 는 정확히 $\phi (m)$ 개 존재한다. 이들의 집합을 $$ B:= \left\{ b_{1}, b_{2}, \cdots , b_{\phi (m)} \right\} $$ 라고 하자. 그러면 $\gcd(a,m) = 1$ 이므</description>
    </item>
    
    <item>
      <title>시그마 대수와 가측 공간</title>
      <link>https://freshrimpsushi.github.io/posts/sigma-algebra-and-measurable-space/</link>
      <pubDate>Sun, 25 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sigma-algebra-and-measurable-space/</guid>
      <description>정의 집합 $X \ne \emptyset$ 에 대해 아래의 조건들을 만족하는 $\mathcal{E} \subset \mathscr{P} (X)$ 를 $X$ 상의 시그마 대수Sigma Algebra 혹은 시그마 필드라 하고 어떤 공간 $X$ 에 대해 시그마 필드 $\mathcal{E}$ 가 주어진다면 $(X , \mathcal{E})$ 를 가측 공간Measurable Space이라고 한다. (i): $\emptyset \in \mathcal{E}$ (ii): $E \in \mathcal{E} \implies E^{c} \in \mathcal{E}$ (iii): $\displaystyle \left\{ E_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{E} \implies \bigcup_{n=1}^{\infty} E_{n} \in \mathcal{E}$ (iv): $\displaystyle \left\{ E_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{E} \implies \bigcap_{n=1}^{\infty} E_{n} \in \mathcal{E}$ 설명 어떤 공간 $X$ 에 대해 시</description>
    </item>
    
    <item>
      <title>위상공간에서 컴팩트, 프리컴팩트란?</title>
      <link>https://freshrimpsushi.github.io/posts/compactness-precompact-in-topology-space/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compactness-precompact-in-topology-space/</guid>
      <description>정의 1 위상공간 $\left( X, \mathscr{T} \right)$ 에 대해 $A \subset X$ 라고 하자. $X$ 의 열린 집합으로 이루어진 집합 $\mathscr{O} \subset \mathscr{T}$ 가 다음을 만족하면 $\mathscr{O}$ 를 $A$ 의 오픈 커버링Open Covering라 한다. $$ A \subset \bigcup_{O \in \mathscr{O}} O $$ $\mathscr{O}&#39; \subset \mathscr{O}$ 인 $\mathscr{O}&#39;$ 를 $\mathscr{O}$ 의 부분 커버Subcover라 한다. 특히 $\mathscr{O}&#39;$ 의 기수가 자연수면 유한 부분커버Finite Subcover라 한다. $X$ 의 모든 열린 커버가 유한</description>
    </item>
    
    <item>
      <title>위상수학자의 사인 곡선과 빗 공간</title>
      <link>https://freshrimpsushi.github.io/posts/topologists-sine-curve-and-comb-space/</link>
      <pubDate>Fri, 23 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/topologists-sine-curve-and-comb-space/</guid>
      <description>정의 1 다음과 같이 정의된 $S$ 를 위상수학자의 사인 곡선Topologist&amp;rsquo;s Sine Curve이라 한다. $$ S : = \left\{ (0,y) \ | \ y \in [-1,1] \right\} \cup \left\{ \left. \left( x, \sin {{1} \over {x}} \right) \ \right| \ x \in (0,1] \right\} $$ 다음과 같이 정의된 $C$ 를 위상수학자의 빗 공간Comb Space이라 한다. $$ C := \left\{ (0,y) \ | \ y \in [0,1] \right\} \cup \left\{ (x,0) \ | \ x \in [0,1] \right\} \cup \left\{ \left( {{1} \over {n}} , y \right) \ | \</description>
    </item>
    
    <item>
      <title>국소연결과 국소경로연결</title>
      <link>https://freshrimpsushi.github.io/posts/locally-connected-and-locally-path-connected/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/locally-connected-and-locally-path-connected/</guid>
      <description>정의 $X$ 를 위상공간이라고 하자. $x \in X$ 를 포함하는 모든 $U$ 에 대해 $x \in C \subset U$ 를 만족하는 열린 연결 집합 $C$ 가 존재하면 $X$ 가 $x$ 에서 국소연결이라 한다. 모든 $x \in X$ 에 대해 국소연결이면 $X$ 를 국소연결 공간이라 한다. $x \in X$ 를 포함하는 모든 $U$ 에 대해 $x \in P \subset U$ 를 만족하는 열린 경로연결 집합 $P$ 가 존재하면 $X$ 가 $x$ 에서 국소경로연결이라 한다. 모든 $x \in X$</description>
    </item>
    
    <item>
      <title>이의엑스제곱 꼴의 부정적분</title>
      <link>https://freshrimpsushi.github.io/posts/indefinite-integral-of-ex2-form/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/indefinite-integral-of-ex2-form/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $$ \int e^{x^2}dx = \sum\limits_{n=0}^\infty \dfrac{x^{2n+1}}{(2n+1)n!}+C $$ $e^{-x^2}$꼴과 마찬가지로 일반적인 방법으로 적분하기는 어렵다. $\mathrm{error \ function(imaginary\ error\ function,\ erfi)}$이라는 함수를 정의해서 적분하는 방법도 있지만 이 글에서는 테일러 급수 전개를 이용한 풀이를 소개한다. 증명 테일러 급수 전개 방법에 의해 $$ e^x=\sum\limits_{n=0}^\infty \dfrac{x^n}{n!}=1+x+\dfrac{x^2}{2!}+\cdots +\dfrac{x^n}{n!}+\cdots $$ $x$ 대신에 $x^2$을 대</description>
    </item>
    
    <item>
      <title>경로연결 성분</title>
      <link>https://freshrimpsushi.github.io/posts/path-connected-component-in-in-topology/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/path-connected-component-in-in-topology/</guid>
      <description>정의 1 위상공간 $X$ 의 경로연결 부분공간들 중 자기 자신만을 연결 초집합Superset으로 갖는 경로연결 집합을 $X$ 의 경로연결 성분Path Connected Component이라 한다. 특히 $x \in X$ 를 포함하는 경로연결 성분을 $P_{x}$ 라 쓴다. 정리 [1]: $x \in X$ 은 단 하나의 $P_{x}$ 에만 속한다. [2]: $a,b \in X$ 에 대해 $P_{a} = P_{b}$ 이거나 $P_{a} \cap P_{b} = \emptyset$ 둘 중 하나다. [3]: 모든 경로연결 공간은</description>
    </item>
    
    <item>
      <title>미분 방정식의 분류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-differential-equation/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-differential-equation/</guid>
      <description>설명 미분방정식을 분류하는 기준은 여러 가지다. 크게 상미분 방정식인지 편미분 방정식인지로 구분한다. 그 다음 계수와 차수, 선형/비선형으로 더 세세하게 분류할 수 있다. 미분방정식을 분류하는 이유는 당연히 미분방정식을 풀기 위해서이다. 미분방정식의 분류에 따라 풀이 방법도 다르다. 상미분방정식과 편미분방정식 상미분방정식은 한 개 또는 그 이</description>
    </item>
    
    <item>
      <title>사인제곱&#43;코사인제곱=1임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-sin2-cos21/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-sin2-cos21/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\sin^2\theta+\cos^2\theta=1$ 사인제곱과 코사인제곱의 합이 1임은 삼각함수가 맨 처음 나올 때부터 알던 사실이다. 간단한 만큼이나 굉장히 중요한 식이다. 어떻게 증명하는지 알아보자. 증명1(코사인의 덧셈 공식) 코사인의 덧셈 정리를 이용하면 아주 간단하게 알 수 있다. $$ \cos(\theta_1-\theta_2)=\cos\theta_1\cos\theta_2 + \sin\theta_1\sin\theta_2 $$ 여기에 $\theta_1$, $\theta_2$ 대신 $\theta$를 대입</description>
    </item>
    
    <item>
      <title>삼각함수의 배각공식과 반각공식</title>
      <link>https://freshrimpsushi.github.io/posts/trigonometric-identity/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trigonometric-identity/</guid>
      <description>사장들이 고등학생이었을 때는 배각, 반각 공식에 합차 공식까지 교육과정에 있었는데 요즘은 아닌 걸로 알고 있다. 아래의 공식들은 모두 덧셈 공식으로부터 유도할 수 있으니 이를 모두 외우기 보다는 유도 과정을 익혀 필요할 때 마다 유도해서 쓰는게 좋다. 덧셈 정리 $$ \begin{align*} \sin ( \theta_{1} \pm \theta_{2}) &amp;amp;= \sin \theta_{1} \cos \theta_{2} \pm \sin \theta_{2} \cos \theta_{2}$ \\ \cos ( \theta_{1} \pm \theta_{2}) &amp;amp;= \cos \theta_{1} \cos\theta_{2} \mp \sin\theta_{1} \sin\theta_{2} \\ \tan ( \theta_{1} \pm \theta_{2}) &amp;amp;= \dfrac{\tan\theta_{1} \pm \tan\theta_{2}}{1 \mp</description>
    </item>
    
    <item>
      <title>접착 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pasting-lemma/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pasting-lemma/</guid>
      <description>정리 위상공간 $X,Y$ 에 대해 두 닫힌 집합 $A,B \subset X$ 이 $A \cup B = X$ 를 만족하고 두 연속함수 $f : A \to Y$ 와 $g : B \to Y$ 가 모든 $x \in A \cap B$ 에 대해 $f(x) = g(x)$ 라고 하자. 그러면 다음과 같이 정의된 $h$ 는 연속함수다. $$ h(x) : = \begin{cases} f(x), &amp;amp; x \in A \\ g(x), &amp;amp; x \in B \end{cases} $$ 설명 풀 보조정리Gluing Lemma라도 불리는 이 보조정리는 문장을 읽는 것만으로도 이해할 수 있을 정도로 당</description>
    </item>
    
    <item>
      <title>외측도</title>
      <link>https://freshrimpsushi.github.io/posts/outer-measure/</link>
      <pubDate>Mon, 19 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/outer-measure/</guid>
      <description>정의 1 $E \subset \mathbb{R}$, $\left\{ I_{n} \in \mathcal{I} \ | \ n \in \mathbb{N} \right\} $, $\left\{ E_{n} \in \mathscr{P} ( \mathbb{R} ) \ | \ n \in \mathbb{N} \right\}$ 에 대해 $$ \displaystyle Z_{E} : = \left\{ \left. \sum_{n=1}^{\infty} l (I_{n}) \ \right| \ E \subset \bigcup_{n=1}^{\infty} I_{n} \right\} $$ 라고 할 때 함수 $m^{ \ast } (E) : = \inf Z_{E}$ 를 외측도Outer Measure라 한다. 기초 성질 외측도는 아래의 성질들을 가진다. [1] 길이의 일반화: $I \in \mathcal{I} \implies m^{ \ast } (I) = l(I)$ [2] 정부호: $N \in \mathcal{N} \iff m^{ \ast }(N) = 0$ [3] 단조성: $E_{1} \subset E_{2} \implies m^{ \ast</description>
    </item>
    
    <item>
      <title>위상수학에서 경로연결성이란</title>
      <link>https://freshrimpsushi.github.io/posts/path-connectedness-in-topology/</link>
      <pubDate>Sun, 18 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/path-connectedness-in-topology/</guid>
      <description>정의 1 $X$ 를 위상공간이라고 하고 $C \subset \mathbb{R}^{n}$ 이라고 하자. 연속함수 $p : [0,1] \to X$ 를 시점Initial Point $p(0)$ 에서 종점Terminal Point $p(1)$ 까지의 경로Path라 한다. $\overline{p}(t) = p(1-t)$ 를 $p$ 의 역경로Reverse Path라 한다. 모든 $a,b \in X$ 에 대해 $p(0) = a$ 와 $p(1) = b$ 를 만족하는 경로 $p$ 가 존재하면 $X$ 를 경로연결Path Connected 공간이라고 한다. 모든 $a,b \in C$ 와 $t \in</description>
    </item>
    
    <item>
      <title>미분 방정식의 정의와 예</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-example-of-differential-equation/</link>
      <pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-example-of-differential-equation/</guid>
      <description>정의 한 개 또는 그 이상의 종속변수를 한 개 또는 그 이상의 독립변수에 대해 미분한 도함수들을 포함하는 방정식을 미분방정식differential equation이라 한다. $$ \dfrac{dy}{dx}=y $$ $$ \dfrac{d^2y}{dx^2} = y $$ 설명 대부분의 물리적인 상황은 1계 혹은 2계 미분방정식으로 표현할 수 있다. 낙하하는 물체 $$ F=ma=mg $$ $$ v=\dfrac{dy}{dt} $$ $$ a=\dfrac{dv}{dt}=\dfrac{d}{dt} \left( \dfrac{dy}{dx} \right)=\dfrac{d^2y}{dt^2} $$ $$ \dfrac{d^2y}{dt^2}=g $$ 스프링 질량계 $$ F=ma=-ky $$ $$ a= -\dfrac{k}{m}y</description>
    </item>
    
    <item>
      <title>위상수학에서 고정점 성질이란?</title>
      <link>https://freshrimpsushi.github.io/posts/fixed-point-property-in-topology/</link>
      <pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fixed-point-property-in-topology/</guid>
      <description>정의 함수 $f : X \to X$ 에 대해 $f(x_{0}) = x_{0}$ 를 만족하는 $x_{0}$ 을 $f$ 의 고정점Fixed Point이라 한다. 모든 연속함수 $f$ 가 고정점을 가지면 $X$ 가 고정점 성질Fixed Point Property을 가진다고 한다. 설명 주로 완비 공간과 관계가 깊다.적어도 $\mathbb{R}$ 에서는 중간값 정리를 이용하면 $f : [a,b] \to [a,b]$ 에 대해 $f(c) = c$ 를 만족하는 $c$ 가 항상 존재함을 보일 수 있다. 정리</description>
    </item>
    
    <item>
      <title>중간값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-intermediate-value-theorem/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-intermediate-value-theorem/</guid>
      <description>정의 1 $f : [a,b] \to \mathbb{R}$ 가 연속이면 $f(a)$ 와 $f(b)$ 사이의 $y_{0}$ 에 대해 $y_{0} = f(c)$ 를 만족하는 $c \in (a,b)$ 가 존재한다. 설명 대우 명제를 이용하면 $\mathbb{R}^2$ 상에서 특정한 조건을 만족한 두 도형을 연결하는 곡선이 없음을 보일 수 있다. 따름정리 한편 중간값 정리에는 다음과 같이 여러 유용한 따름정리가 있다. 방정식 $f(x)=0$ 의 해 존재성 판별법: 연속함수 $f:[a,b] \to \mathbb{R}$ 에 대해 $f(a) f(b) &amp;lt; 0$ 이면 $f(x) = 0$ 는 해 $x_{0}</description>
    </item>
    
    <item>
      <title>영집합</title>
      <link>https://freshrimpsushi.github.io/posts/null-set/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/null-set/</guid>
      <description>정의 1 실수의 구간들의 집합 $\mathcal{I}$ 에 대해 함수 $l : \mathcal{I} \to [ 0 , \infty )$ 을 $l( I ) := \sup{I} - \inf{I}$ 와 같이 정의하고 길이Length라 하자. 임의의 $\varepsilon &amp;gt; 0$ 에 대해 $$ A \subset \bigcup_{n = 1}^{\infty} I_{n} \\ \sum_{n=1}^{\infty} l (I_{n}) &amp;lt; \varepsilon $$ 을 만족하는 구간의 수열 $\left\{ I_{n} \ | \ n \in \mathbb{N} \right\}$ 이 존재하면 $A \subset \mathbb{R}$ 를 영집합Null Set이라고 한다. 설명 모든 구간들의 집합을 $\mathcal{I}$ 로, 모든 영집합의 집합을 $\mathcal{N}$ 으로 나타낸</description>
    </item>
    
    <item>
      <title>연결 성분과 완전 분리 공간</title>
      <link>https://freshrimpsushi.github.io/posts/component-and-totally-disconnected-space/</link>
      <pubDate>Wed, 14 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/component-and-totally-disconnected-space/</guid>
      <description>정의 위상공간 $X$ 의 연결 부분공간들 중 자기 자신만을 연결 초집합Superset으로 갖는 연결 집합을 $X$ 의 연결 성분Connected Component이라 한다. 특히 $x \in X$ 를 포함하는 연결 성분을 $C_{x}$ 라 쓴다. $X$ 의 모든 연결 성분이 홑원소 집합이면 $X$ 를 완전 분리 공간Totally Disconnected Space이라 한다. 설명 연결성분 정의만 보면 말이 빙빙</description>
    </item>
    
    <item>
      <title>연결 공간의 부분 공간의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-subspace-of-connected-space/</link>
      <pubDate>Tue, 13 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-subspace-of-connected-space/</guid>
      <description>정리 위상공간 $X$ 에 대해 $Y \subset X$ 라고 하자. [1]: $Y$ 가 연결 공간이면 $\overline{Y}$ 도 연결 공간이다. [2]: $Y$ 가 비연결 공간인 것과 $$ U \cap Y \ne \emptyset \\ V \cap Y \ne \emptyset \\ U \cap V \cap Y = \emptyset \\ Y \subset U \cup V $$ 를 만족하는 $X$ 의 열린 집합 $U$ 와 $V$ 가 존재하는 것은 서로 동치다. [3]: $X$ 의 연결 부분공간의 집합 $\left\{ A_{\alpha} \ | \ \alpha \in \forall \right\}$ 에 대해 $$ \displaystyle \bigcap_{\alpha \in \forall} A_{\alpha} \ne \emptyset $$ 이면 $\displaystyle \bigcup_{\alpha \in \forall} A_{\alpha}$ 는 연결 공간이다. [4]:</description>
    </item>
    
    <item>
      <title>추상대수학에서의 잉여류와 정규부분군</title>
      <link>https://freshrimpsushi.github.io/posts/normal-subgroup/</link>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normal-subgroup/</guid>
      <description>정의 1 군 $G$ 과 그 부분군 $H$ 에 대해 $aH = \left\{ ah \ | \ h \in H \right\}$ 를 좌잉여류Left Coset , $Ha = \left\{ ha \ | \ h \in H \right\}$ 를 우잉여류Right Coset이라 한다. $H \leqslant G$ 의 좌(우)잉여류의 갯수를 $(G : H)$ 라 쓰고 $G$ 에서 $H$ 의 인덱스Index라 한다. $H$ 가 $G$ 의 부분군이고 모든 $g \in G$ 에 대해 $gH = Hg$ 면 $H$ 를 $G$ 의 정규부분군Normal Subgroup이</description>
    </item>
    
    <item>
      <title>완전 탄성 충돌과 운동에너지 보존</title>
      <link>https://freshrimpsushi.github.io/posts/perfectly-elastic-collision/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/perfectly-elastic-collision/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 반발계수$e$가 $1$일 때 완전 탄성 충돌이라 한다.완전 탄성 충돌에는 중요한 특징이 두가지 있다. $1.$ 충돌 전 후의 각 물체의 운동에너지 합이 보존된다.$2.$ 두 물체의 질량이 같으면 충돌 후 속도가 서로 교환된다. $1.$증명 운동량 보존 법칙과 반발계수 식을 이용해서 증명한다.운동량 보존</description>
    </item>
    
    <item>
      <title>추상대수학에서의 교대군</title>
      <link>https://freshrimpsushi.github.io/posts/alternating-group/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/alternating-group/</guid>
      <description>정의 1 $S_{n}$ 의 짝순열들로 이루어진 군을 교대군Alternating Group이라 하고 $A_{n}$ 으로 쓴다. 정리 $n \le 2$ 에 대해 $$ \left| A_{n} \right| = {{\left| S_{n} \right|} \over {2}} = {{ n! } \over {2}} $$ 설명 $A_{n}$ 의 위수가 정확히 $\left| S_{n} \right|$ 의 절반이 된다는 것은 상당히 흥미로운 성질이 아닐 수 없다. 교대군은 후에 $5$ 차 이상의 방정식이 근의 공식을 갖지 않음을 보일 때 쓰이므로 매우 중요한 군이라 할 수</description>
    </item>
    
    <item>
      <title>짝이면서 홀인 순열은 존재하지 않음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/there-is-no-permutation-which-is-even-and-odd-both/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/there-is-no-permutation-which-is-even-and-odd-both/</guid>
      <description>정의 유한대칭군의 순열이 짝수 만큼의 전위의 곱으로 나타날 수 있으면 짝Even이라 하고 홀수 만큼의 전위의 곱으로 나타날 수 있으면 홀Odd라 한다. 정리 1 짝이면서 홀인 순열은 존재하지 않는다. 설명 짝과 홀의 정의 자체는 상당히 자연스럽지만 추상적인 학문이니만큼 그 두가지 개념이 배타적인가에 대해선 확신할 수 없다. 증명 유한대칭군 $S_{n}$ 의 전위 $\tau :</description>
    </item>
    
    <item>
      <title>두 물체의 충돌과 반발계수</title>
      <link>https://freshrimpsushi.github.io/posts/coefficient-of-restitution/</link>
      <pubDate>Tue, 06 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coefficient-of-restitution/</guid>
      <description>설명 🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 두 물체가 충돌할 때 그 유형을 3가지로 분류할 수 있다. $1$ 완전 탄성 충돌(탄성 충돌)$2$ 비탄성 충돌$3$ 완전 비탄성 충돌 어떻게 구분하느냐?기준은 바로 반발계수$e$이다. 반발계수 반발계수는 두 물체의 충돌 전 상대속도와 충돌 후 상대속도의 비다.다시 말하자면 두 물체가 가까워지는</description>
    </item>
    
    <item>
      <title>전사 연속함수는 연결성을 보존한다</title>
      <link>https://freshrimpsushi.github.io/posts/surjective-continuous-function-preserves-connectedness/</link>
      <pubDate>Tue, 06 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/surjective-continuous-function-preserves-connectedness/</guid>
      <description>정리 연결 공간 $X$ 에 대해 $f : X \to Y$ 가 전사 연속함수면 $Y$ 는 연결 공간이다. 설명 연결과 연속처럼 비슷한 말이 섞여있어서 조금 헷갈릴 수도 있다. 대개는 영어로 외우면 해결되지만 이 정리에 쓰이는 영단어는 Connected 와 Continuous기 때문에 큰 도움은 되지 않는다. 증명 $Y$ 가 연결 공간이 아니라고 가정하면 $$ A \cap B = \emptyset \\ A \cup B = Y $$ 를 만족하는 열린 진</description>
    </item>
    
    <item>
      <title>연결 공간의 여러가지 동치조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-of-connected-space/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-of-connected-space/</guid>
      <description>정의 1 위상공간 $X$ 에 대해 부분집합 $A \subset X$ 가 $$ A \ne \emptyset \\ A \ne X $$ 면 $A$ 를 $X$ 의 진부분집합Proper Subset이라 한다. 두 진부분집합 $A,B \subset X$ 에 대해 $$ \overline{A} \cap B = \emptyset \\ A \cap \overline{B} = \emptyset $$ 이면 $A$ 와 $B$ 를 분리 집합Separated Set 혹은 그냥 분리Separation라 부른다. 연결 공간의 동치조건 위의 정의를 포함해서 연결 공간의 여러가지 동치</description>
    </item>
    
    <item>
      <title>운동량 보존 법칙 쉬운 증명고등학교 수준</title>
      <link>https://freshrimpsushi.github.io/posts/law-of-conservation-of-momentum/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/law-of-conservation-of-momentum/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 외력이 작용하지 않으면 힘(내력)의 작용 전후의 운동량 총합은 일정하다. 쉽게 말해 두 물체가 충돌할 때 충돌 전 각 물체의 운동량 합과 충돌 후 각 물체의 운동량 합은 같다. $$ m_1v_1+m_2v_2=m_1{v_1}&#39;+m_2{v_2}&#39; $$ 증명** (고등학교 수준) $(1)$ 두 물체 $A, B$가 충돌할 때 작용반작용의 법칙에 의해 서로가 서로에게 주는 힘은 크기는 같고 방향</description>
    </item>
    
    <item>
      <title>추상대수학에서의 궤도, 순환, 전위</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-cycle-transposition-in-abstract-algebra/</link>
      <pubDate>Sun, 04 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-cycle-transposition-in-abstract-algebra/</guid>
      <description>정의 1 $\sigma$ 를 군 $G$ 에 대한 순열이라고 하면 $a, b \in G$ 에 대한 동치관계 $\sim$ 는 $b=\sigma^n (a)$ 를 만족하는 정수 $n \in \mathbb{Z}$ 이 존재할 때 $a \sim b$ 로 정의된다. $\sim$ 의 동치류들을 $\sigma$ 의 궤도Orbit라 한다. 원소가 둘 이상인 궤도를 많아도 하나만 가지는 순열을 순환Cycle이라고 한다. 순환이 가지는 궤도들 중 가장 기수가 큰 궤도의 기수를 순환의 길이Length라 한다. 길이</description>
    </item>
    
    <item>
      <title>각운동량 연산자의 행렬 표현</title>
      <link>https://freshrimpsushi.github.io/posts/angular-momentum-matrix/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/angular-momentum-matrix/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $L_{z}$와 $L^2$의 동시 고유함수는 $|lm&amp;gt;$고유값 방정식은$L_{z}|l,m&amp;gt;=m\hbar |l,m&amp;gt; $$ L^2|l,m&amp;gt;=l(l+1)\hbar ^2|l,m&amp;gt;$ 이므로$&amp;lt;l,m&#39; |L_{z}|l,m&amp;gt;=m\hbar &amp;lt;l,m&#39;|l,m&amp;gt;=m\hbar \delta_{mm&#39;}$ 이다.$l=1$일 때 $L_{z}$를 행렬로 표현하면 가능한 $m$은 $1, 0, -1$이고$m&#39;=m$일 때만 행렬</description>
    </item>
    
    <item>
      <title>위상수학에서 연결성이란</title>
      <link>https://freshrimpsushi.github.io/posts/connectedness-in-topology/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/connectedness-in-topology/</guid>
      <description>정의 1 위상공간 $X$ 에서 $A \cap B = \emptyset$ 과 $A \cup B = X$ 을 만족하는 열린 집합 $A \ne \emptyset$, $B \ne \emptyset$ 이 존재하면 $X$ 를 비연결Disconnected 공간이라고 한다. 비연결공간이 아니면 연결Connected 공간이라고 한다. 정리 [1]: 연결성은 위상적 성질이다. [2]: 모든 자명공간은 연결 공간이다. [3]: 모든 이산공간은 비연결 공간이다. [4]: 모든 홑원소집합은 연</description>
    </item>
    
    <item>
      <title>하우스도르프 공간에서는 시퀀스의 극한이 유일하다</title>
      <link>https://freshrimpsushi.github.io/posts/uniqueness-of-limit-of-sequence-in-hausdorff-space/</link>
      <pubDate>Fri, 02 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniqueness-of-limit-of-sequence-in-hausdorff-space/</guid>
      <description>정리 $T_{2}$-공간 $X$ 상의 수열 $\left\{ x_{n} \right\}$ 은 둘 이상의 점으로 수렴하지 않는다. 설명 극한의 유일성에 대해서 그 중요함을 굳이 역설할 필요가 있을까 싶다. 이런 성질이 있다는 것부터가 하우스도르프 공간이 쓸만하다는 증거가 된다. 주의해야하는 것은 표현상 &amp;lsquo;단 하나의 점으로 수렴한다&amp;rsquo;와는 조금 차이가 있다는 것이다. 만</description>
    </item>
    
    <item>
      <title>T1-공간인 것과 모든 유한부분집합이 닫혀있는 것은 동치다</title>
      <link>https://freshrimpsushi.github.io/posts/t1-space-iff-all-finite-subset-are-closed/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/t1-space-iff-all-finite-subset-are-closed/</guid>
      <description>정리 $X$ 가 $T_{1}$-공간인 것과 필요충분조건은 $X$ 의 모든 홑원소집합 $\left\{ x \right\}$ 가 $X$ 에서 닫힌 집합인 것이다. 증명 $(\Rightarrow)$ $T_{1}$-공간 $X$ 에 대해 $x \in X$, $x&#39; \in X \setminus \left\{ x \right\}$ 라고 두면 $x \ne x&#39;$ 이다. $X$ 는 $T_{1}$-공간이므로, $x&#39; \in U_{x&#39;}$ 이면서 $x \notin U_{x&#39;}$ 인 열린 집합 $U_{x&#39;} \subset X$ 이 존재한다. 정리하면 $$ x&#39; \in U_{x&#39;} \subset X \setminus \left\{ x \right\} $$ 이고, $$ \displaystyle X \setminus \left\{ x \right\}</description>
    </item>
    
    <item>
      <title>케일리의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cayleys-theorem/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cayleys-theorem/</guid>
      <description>정리 1 모든 군은 대칭군의 어떤 부분군과 동형이다. 설명 짧고도 굵직한 이 정리는 대칭군을 연구하면 모든 군을 파악할 수 있다는 메세지를 담고 있다. 증명 증명은 언뜻 지루해 보이지만 읽어보면 그 테크닉이 상당히 흥미로우니 한번정도는 직접 따라해보는 것을 추천한다. Part 1. $f : G \to G&#39;$ 가 단사면 $G \simeq f (G)$ 군 $G$ 와 $G&#39;$ 에 대해 준동형사상 $f : G \to G&#39;$ 가 단사면 $G \simeq</description>
    </item>
    
    <item>
      <title>베타함수의 삼각함수 표현</title>
      <link>https://freshrimpsushi.github.io/posts/trigonometric-function-representation-of-beta-function/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trigonometric-function-representation-of-beta-function/</guid>
      <description>정리 $$ \displaystyle B(p,q) = 2 \int_{0}^{{\pi} \over {2}} \left( \sin \theta \right) ^{2p-1} \left( \cos \theta \right) ^{2q-1} d \theta $$ 설명 그것이 어떤 종류의 수학이라고 하더라도 어떤 함수를 다른 방식으로 표현할 수 있다는 건 좋은 일이다. 증명 $\displaystyle B(p,q) = \int_{0}^{1} t^{p-1} (1-t)^{q-1} dt$ 에서 $t = \sin^2 \theta$ 로 치환하면 $$ \displaystyle B(p,q) = \int_{0}^{{\pi} \over {2}} \left( \sin^2 \theta \right)^{p-1} \left( 1 - \sin^2 \theta \right) ^{q-1} 2 \sin \theta \cos \theta d \theta $$ $1 - \sin^2 \theta = \cos ^2 \theta$ 이므로 $$ \displaystyle B(p,q) = 2 \int_{0}^{{\pi} \over {2}} \left( \sin \theta \right)^{2p-1} \left( \cos \theta \right) ^{2q-1} d \theta $$ ■ 따름정리 특</description>
    </item>
    
    <item>
      <title>위상수학에서의 분리성질</title>
      <link>https://freshrimpsushi.github.io/posts/separation-properties/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separation-properties/</guid>
      <description>정의 1 $X$ 를 위상공간이라고 하자. $a,b \in X$ 에 대해 $a \ne b$ 고 $U, V \subset X$ 는 $X$ 에서 열린 집합이다. $T_{0}$: 임의의 $a$ 와 $b$ 중 하나만 포함하는 $U$ 가 존재하면, $X$ 를 콜모고로프Kolmogorov 공간이라고 한다. $T_{1}$: 임의의 $a,b$ 에 대해 $$ a \in U, b \notin U \\ a \notin V, b \in V $$ 를 만족하는 $U,V$ 가 존재하면, $X$ 를 프레셰Frechet 공간이라고 한다. $T_{2}$: 임의의 $a,b$ 에 대해</description>
    </item>
    
    <item>
      <title>클라인 사원군</title>
      <link>https://freshrimpsushi.github.io/posts/klein-4-group/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/klein-4-group/</guid>
      <description>정의 1 $V = \left\{ e, a, b, c \right\}$ 과 이항연산 $\cdot$ 에 대해, $\left&amp;lt; V , \ \cdot \ \right&amp;gt;$ 을 클라인 사원군Klein 4-group이라고 한다. 설명 보다시피 원소의 갯수가 항등원을 포함해서도 $4$ 개밖에 안 되기 때문에 굉장히 풍부한 성질을 갖지는 않는다. 하지만 계산이 별로 없고 독자적인 연산을 가진만큼 군의 개념을 체득하기엔 상당히 좋은 예시가 된다. $x \cdot x = e$ 즉, 모</description>
    </item>
    
    <item>
      <title>토션트 함수의 곱셈적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-totient-functions-multiplicativity/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-totient-functions-multiplicativity/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\gcd (n , m) =1 \implies \phi ( n m ) = \phi (n) \phi (m)$ 토션트 함수에서 유도되는 여러가지 중요한 결과를 얻기 위해선 반드시 필요한 성질이다. $\gcd (n , m) =1$ 라는 조건이 있으니 만능이라고 착각하진 말자. 증명 $nm = p_{1}^{{k}_{1}} p_{2}^{{k}_{2}} \cdots p_{r}^{{k}_{r}}$ 그리고 편의상 $p_{1} &amp;lt; p_{2} &amp;lt; \cdots &amp;lt; p_{r}$ 라고 하자.가정에서 $\gcd (n , m ) = 1$ 이므로 $p_{i} \mid n$ 이면서 $p_{i} \mid m$</description>
    </item>
    
    <item>
      <title>이항계수의 일반화 베타함수</title>
      <link>https://freshrimpsushi.github.io/posts/beta-function/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/beta-function/</guid>
      <description>정리: 베타함수로 표현되는 이항계수 $0 \le k\le n$을 만족하는 두 자연수 $k,n$ 에 대해서 아래의 식이 성립한다. $$ \binom{n}{k}={}_{n}C_{k}=C(n,k)=\frac{1}{(n+1)B(n-k+1,k+1)} $$ 두 자연수 $m,n$ 에 대해서 아래의 식이 성립한다. $$ B(m,n)=\left[ \frac{mn}{m+n} \begin{pmatrix} m+n \\ n \end{pmatrix}\right]^{-1} $$ 설명 $B(p,q):=\displaystyle \int_{0}^{1}t^{p-1}(1-t)^{q-1}dt$로 정의되는 베타함수는 위와 같이 이항계수의 일반화로 볼 수도 있다. 증명은 어렵지 않으나</description>
    </item>
    
    <item>
      <title>일양 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-uniform-distribution/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-uniform-distribution/</guid>
      <description>공식 $X \sim U[a,b]$ 면 $$ E(X) = {{ a+b } \over { 2 }} \\ \text{Var}(X) = {{ (b-a)^{2} } \over { 12 }} $$ 유도 전략: 일양 분포의 정의에서 직접 연역한다. 일양 분포의 정의: $[a,b] \subset \mathbb{R}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포]] $U[a,b]$ 를 일양 분포라 한다. $$ f(x) = {{ 1 } \over { b - a }} \qquad , x \in [a,b] $$ 평균 $$ \begin{align*} E(X) =&amp;amp; \int_{a}^{b} x {{ 1 } \over { b-a }} dx \\ =&amp;amp; {{ 1 } \over { b-a }} \left[ {{ x^{2} } \over { 2 }} \right]_{a}^{b} \\ =&amp;amp; {{</description>
    </item>
    
    <item>
      <title>슈발츠-크리스토플 사상</title>
      <link>https://freshrimpsushi.github.io/posts/schwarz-christoffel-mapping/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schwarz-christoffel-mapping/</guid>
      <description>정리 1 복소평면 상에서 $n$ 개의 각을 가진 꺾인 선을 $\mathscr{P}$ 라고 하고 그 각들을 $w_{r}$, 그 내각의 크기를 $\psi_{r}$ 라 하자. 그러면 $K, C, z_{0} \in \mathbb{C}$ 와 $x_{r} \in \mathbb{R}$ 에 대해 $f(x_{r}) = w_{r}$ 를 만족시키는 등각사상 $$ w = f(z) = K \int_{z_{0}}^{z} \prod_{r = 1}^{n} ( \zeta - x_{r})^{ \psi_{r} / \pi - 1 } d \zeta + C $$ 은 실수축을 꺾인 선 $\mathscr{P}$ 로 대응시킨다. 이를 슈발츠-크리스토플 사상Schwarz Christoffel Mapping이라 부른다. 설명 만약</description>
    </item>
    
    <item>
      <title>일양 분포</title>
      <link>https://freshrimpsushi.github.io/posts/uniform-distribution/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniform-distribution/</guid>
      <description>정의 1 $[a,b] \subset \mathbb{R}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $U(a,b)$ 를 일양 분포Uniform Distribution라 한다. $$ f(x) = {{ 1 } \over { b - a }} \qquad , x \in [a,b] $$ 설명 흔히 일양 분포는 균등 분포로 불리기도 한다. 위의 정의는 연속인 경우고, 이산 일양 분포 역시 모든 케이스에 대해 같은 확률을 줌으로써 정의할 수 있다. 일양 분포가 중요한</description>
    </item>
    
    <item>
      <title>쥬코프스키 변환</title>
      <link>https://freshrimpsushi.github.io/posts/joukowski-transform/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/joukowski-transform/</guid>
      <description>정의 1 등각사상 $\displaystyle w = f(z) = a z + {{b} \over {z}}$ 라고 하자. $a=b$ 면 $f$ 를 쥬코프스키 변환Joukowski Transform이라고 하고, 중심이 $0$ 이 아닌 원을 비행기 날개의 단면 모양으로 대응시킨다. [1]: $f$ 는 중심이 $0$ 인 원을 타원으로 대응시킨다. [2]: $f$ 는 $0$ 에서 시작되는 반직선을 쌍곡선으로 대응시킨다. 설명 쥬코프스키Zhukovsky는 항공역</description>
    </item>
    
    <item>
      <title>등각사상으로써의 삼각함수</title>
      <link>https://freshrimpsushi.github.io/posts/trigonometric-function-as-conforming-mapping/</link>
      <pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trigonometric-function-as-conforming-mapping/</guid>
      <description>정리 1 등각사상 $w = f(z) = \sin z$은 수직선 $y=k$ 를 타원으로, 수평선 $x = k$ 를 쌍곡선으로 대응시킨다. 증명 $$ z = x + iy \\ w = u + i v $$ 라고 하면 $$ u = \sin x \cosh y \\ v = \cos x \sinh y $$ 이다. $y = k$ 라고 하면 $$ {{ u^2 } \over { \cosh^{2} k}} = \sin^{2} x \\ \displaystyle {{ v^2 } \over { \sinh^{2} k}} = \cos^{2} x $$ 양변끼리 더하면 $$ {{ u^2 } \over { \cosh^{2} k}} + {{ v^2 } \over { \sinh^{2} k}} = 1 $$ 즉 타원의 방정식이 된다. $x</description>
    </item>
    
    <item>
      <title>등각사상으로써의 지수함수</title>
      <link>https://freshrimpsushi.github.io/posts/exponential-function-as-conforming-mapping/</link>
      <pubDate>Wed, 21 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/exponential-function-as-conforming-mapping/</guid>
      <description>정리 1 등각사상 $w = f(z) = e^{z} = e^{x} e^{i y}$ 은 직사각형을 부채꼴 혹은 고리로 대응시킨다. 설명 $f(z) = e^{z}$ 는 분명 등각사상이지만 단사는 아니므로 역사상을 생각할 땐 여러가지 제한이 필요하다. Osborne (1999). Complex variables and their applications: p217. &amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>위상수학에서 계승적 성질이란?</title>
      <link>https://freshrimpsushi.github.io/posts/hereditary/</link>
      <pubDate>Wed, 21 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hereditary/</guid>
      <description>빌드업: 부분공간 위상공간 $(X, \mathscr{T})$ 에 대해 $Y \subset X$ 라고 하자. $\mathscr{T}&#39; := \left\{ U \cap Y \ | \ U \in \mathscr{T} \right\}$ 라고 하면 $(Y , \mathscr{T}&#39; )$ 는 $X$ 의 부분공간Subspace이 되고 $\mathscr{T}&#39;$ 를 $\mathscr{T}$ 에 의한 $Y$ 의 부분위상Subspace Topology이라 한다. [1]: $A \subset Y$ 가 $Y$ 에서 닫힌 부분집합인 필요충분조건은 $A = C \cap Y$ 를 만족하는 닫힌 부분집합 $C \subset X$ 가 존재하는 것이다. [2]: $y \in</description>
    </item>
    
    <item>
      <title>위상적 성질</title>
      <link>https://freshrimpsushi.github.io/posts/topological-property/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/topological-property/</guid>
      <description>정의 1 위상동형인 두 공간 $X,Y$ 에 대해 $X$ 의 성질 $P$ 를 $Y$ 도 갖고 있으면 $P$ 를 위상적 성질Topological Property이라 한다. 위상적 성질의 예시로는 아래와 같은 것들이 있다. [1]: 가분성 Separability [2]: 제1가산성 First Countability [3]: 제2가산성 Second Countability [4]: 거리화가능성 Metrizability [5]: 하우스도르프 Hausdorff [6]: 연결성 Connectedness [7]: 고정점 성질 Fixed Point Property [8]: 컴팩트성 Compactness [9]: 가산 컴팩트성 Countably Compactness 설명 대수</description>
    </item>
    
    <item>
      <title>토션트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/totient-fuction-phi-function/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/totient-fuction-phi-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 해석적 정수론에서의 토션트 함수 $$ \displaystyle \phi( m ) = \left| \left\{ a \ | \ 1 \le a \le m \land \gcd (a,m) = 1 \right\} \right| = m \prod_{p \mid m} \left( 1 - {{1} \over {p}} \right) $$ 토션트Totient는 전체를 의미하는 Tot-al의 Tot-과 몫을 의미하는 Quo-tient에서 -tient가 붙어서 생긴 단어로 이해해도 무방하다. 수학, 그것</description>
    </item>
    
    <item>
      <title>추상대수학에서의 여러 사상들</title>
      <link>https://freshrimpsushi.github.io/posts/morphisms-in-abstract-algebra/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/morphisms-in-abstract-algebra/</guid>
      <description>정의 군 $\left&amp;lt; G , \ast\ \right&amp;gt; , \left&amp;lt; G&#39; , *&#39; \right&amp;gt;$ 에 대해 $\phi : G \to G&#39;$ 이라고 하자. $\forall x ,y \in G $, $\phi (x \ast\ y) = \phi (x ) *&#39; \phi ( y)$ 이면 $\phi$ 를 준동형사상Homomorphism이라 한다. 준동형사상 $\phi$ 가 단사면 $\phi$ 를 단형사상Monomorphism이라 하고 $G \hookrightarrow G&#39;$ 라 쓴다. 준동형사상 $\phi$ 가 전사면 $\phi$ 를 전형사상Epimorphism이라 하고 $G \twoheadrightarrow G&#39;$ 라 쓴다. 준</description>
    </item>
    
    <item>
      <title>포물선을 반평면으로 대응시키는 등각사상</title>
      <link>https://freshrimpsushi.github.io/posts/conforming-mapping-parabola-to-half-plane/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conforming-mapping-parabola-to-half-plane/</guid>
      <description>정리 1 등각사상 $\displaystyle w = f(z) = z^{1/2}$ 은 포물선을 반평면으로 대응시킨다. 설명 $\mathbb{R}^2$ 에서 배운 것을 생각해보면야 당연하긴하지만 복소평면에서도 성립하는지는 체크가 필요하다. 깔끔하게 세로축을 기준으로 가르고 싶다면 $\xi = w - a$ 만 한번 더 취해주면 된다. 증명 $$ z = x + i y \\ w = u + i v $$ 라고 두면 $$ z = w^2 = (u + iv)^2 = u^2 - v^2 + i 2 uv = x + iy $$ 이므</description>
    </item>
    
    <item>
      <title>부채꼴을 원으로 대응시키는 등각사상</title>
      <link>https://freshrimpsushi.github.io/posts/conforming-mapping-circular-sector-to-circle/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conforming-mapping-circular-sector-to-circle/</guid>
      <description>정리 1 등각사상 $\displaystyle w = f(z) = z^{n}$ 은 부채꼴을 반원으로 대응시킨다. 설명 부채꼴의 반지름이 무한대라고 생각해보면 $f$ 는 각을 평각으로 보내고 그 내부를 반평면으로 대응시킨다고 할 수 있다. 한편 반원 역시 부채꼴이고 반평면 역시 각이므로, $\xi = w^{2}$ 를 한 번 더 취함으로써 완전한 원이나 평면에 대응시킬 수 있다. Osborne (1999). Complex variables and their applications: p212. &amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>위상공간에서 위상동형이란</title>
      <link>https://freshrimpsushi.github.io/posts/homeomorphic-in-topology/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homeomorphic-in-topology/</guid>
      <description>정의 1 두 위상공간 $X,Y$ 에 대해 전단사 $f : X \to Y$ 가 존재해서 $f$ 와 그 역함수 $f^{-1}$ 모두 연속함수면 $f$ 를 위상동형사상Homeomorphism라 부르고 두 위상공간이 위상동형Homeomorphic이라 한다. 정리 다음 명제들은 서로 동치다. (1): $f : X \to Y$ 가 위상동형사상이다. (2): $f^{-1} : Y \to X$ 가 위상동형사상이다. (3): $f : X \to Y$ 가 닫힌 함수면서</description>
    </item>
    
    <item>
      <title>반원을 사분면으로 대응시키는 등각사상</title>
      <link>https://freshrimpsushi.github.io/posts/conforming-mapping-half-circle-to-quadrant/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conforming-mapping-half-circle-to-quadrant/</guid>
      <description>정리 1 등각사상 $\displaystyle w = f(z) = {{z - a} \over {z + a}}$ 는 반원을 사분면으로 대응시킨다. 설명 $\displaystyle w = {{z - a} \over {z + a}}$ 는 별다른 이름은 없지만 매우 중요하고 빈번하게 쓰이는 함수다. 특히 $f(a) = 0$, $f(ai) = i$, $f(-a) = \infty$ 임을 직접 계산해서 확인해보도록 하자. Osborne (1999). Complex variables and their applications: p210. &amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>열린 함수와 닫힌 함수</title>
      <link>https://freshrimpsushi.github.io/posts/open-function-and-closed-function/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/open-function-and-closed-function/</guid>
      <description>정의 위상공간 $X,Y$ 에 대해 $f : X \to Y$ 라고 하자. 모든 열린 집합 $O \subset X$ 에 대해, $f (O)$ 가 $Y$ 에서 열린 집합이면 $f$ 를 열린 함수라 한다. 모든 닫힌 집합 $C \subset X$ 에 대해, $f (C)$ 가 $Y$ 에서 닫힌 집합이면 $f$ 를 닫힌 함수라 한다. 정리 특히 연속함수는 아래의 성질을 가진다. [1]: 연속함수 $f : \mathbb{R} \to \mathbb{R}$ 가 전단사면 열린 함수면서 닫힌 함수다. 위의 성질은 아래 정리의 아주 특수</description>
    </item>
    
    <item>
      <title>윌슨의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-wilsons-theorem/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-wilsons-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 2보다 큰 소수 $p$ 에 대해, $(p-1)! \equiv -1 \pmod{p}$ 페르마의 소정리만큼은 아니더라도, 윌슨의 정리 역시 여기저기서 유용하게 쓰인다.생긴 모양새부터가 연속되는 수들의 곱을 계산할 때 편리하게 생겼다. $\pmod{p}$ 에서 곱셈에 대한 역원의 존재성, 유일성을 이용한 증명1과 **원시근Primitive root**의</description>
    </item>
    
    <item>
      <title>복소해석학에서의 역점</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-point/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-point/</guid>
      <description>정의 1 직선 $L: 2px + 2qy + c = 0$ 과 원 $\mathscr{C}: |z - A | = r$ 의 점이 아닌 $P: z = x + iy$ 를 생각하자. 이에 대한 역점Inverse Point은 다음과 같이 정의된다. $\displaystyle {{y - y^{ \ast }} \over {x - x^{ \ast }}} = {{q} \over {p}}$ 와 $p(x + x^{ \ast }) + q(y + i y^{ \ast }) + c = 0$ 를 만족시키는 $Q: z^{ \ast } = x^{ \ast } + i y^{ \ast }$ 를 $P$ 의 직선 $L$ 에 대한 역점이라고 정의한다. 2. $\overline{AP} \cdot \overline{AQ} = r^2$ 를 만족하는</description>
    </item>
    
    <item>
      <title>위상수학에서 연속이란</title>
      <link>https://freshrimpsushi.github.io/posts/continuous-in-topology/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuous-in-topology/</guid>
      <description>정의 한국어 위상공간 $(X, \mathscr{T}_{X} )$ 와 $(Y, \mathscr{T}_{Y} )$ 에 대해, $f: X \to Y$ 라고 하자. $f(a)$ 를 포함하는 모든 $V \in \mathscr{T}_{Y}$ 에 대해 $f(U) \subset V$ 를 만족하면서 $a$ 를 포함하는 $ U \in \mathscr{T}_{X}$ 가 존재하면 $f$ 를 $a$ 에서 연속Continuous라 한다. $f$ 가 $X$ 의 모든 점에서 연속이면 연속함수라 하고 $f \in C(X,Y)$ 로 나타낼 수 있다. 영어 $f$ is continuous at $a$ $\iff$ For all neighborhood $V \in \mathscr{T}_{Y}$ of $f(a)$, there exists a neighborhood $ U \in \mathscr{T}_{X}$ of $a$ such that $a \in U</description>
    </item>
    
    <item>
      <title>페르마의 소정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fermats-little-theorem/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fermats-little-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 소수 $p$ 와 서로소인 정수 $a$ 에 대해, $a^{p-1} \equiv 1 \pmod{p}$ 페르마의 소정리는 단순하지만 아주 많은 곳에 쓰이는 정리 중 하나다. 오일러에 의해 일반화된 정리도 있지만 페르마의 소정리로도 충분한 경우가 많기 때문이다. 특히 유한체에서의 거듭제곱을 많이 다루는 암호론 등에서는 필수적인 정리다. 전략: 증명은 단순</description>
    </item>
    
    <item>
      <title>원시 피타고라스 수끼리는 서로소다</title>
      <link>https://freshrimpsushi.github.io/posts/pytagorean-triples-are-coprime/</link>
      <pubDate>Sun, 11 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pytagorean-triples-are-coprime/</guid>
      <description>정리 $a^2 + b^2 = c^2$ 를 만족하는 세 자연수 $a,b,c$ 에 대해 $\gcd (a,b,c) = 1$ 면 $$ \gcd (a,b) = 1 \\ \gcd (b,c) = 1 \\ \gcd (c,a) = 1 $$ 설명 언뜻 피타고라스 수든 뭐든 당연해보이지만 공약수라는 걸 잘 생각해보면 그렇지만도 않다. 예로써 피타고라스 수라는 조건이 없으면 $\gcd (6,10,15) = 1$ 이지만 각 두 수끼리는 각자 공약수를 갖는다. 전략: 증명에는 아래의 두 보조정리가 기본적으로 전제된다. 피타고</description>
    </item>
    
    <item>
      <title>추상대수학에서의 정이면체군</title>
      <link>https://freshrimpsushi.github.io/posts/dihedral-group/</link>
      <pubDate>Sun, 11 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dihedral-group/</guid>
      <description>정의 1 대칭군의 부분군 $D_{n} \leqslant S_{n}$ 을 $n$각형에 대해 회전, 반전하는 순열만을 가지는 군으로 정의하고 정이면체군Dihedral Group이라 부른다. 설명 도형에서 유도되기 때문에 말만으로는 설명하기 어렵다. $D_{3} = S_{3}$ 가장 작은 정이면체군의 예시로써 대칭군 $D_{3} = S_{3}$ 이 있다. $| D_{n} | =2n$ 이러한 순열은 $n$각형에 대해 $2n$ 개 존재함을 어렵지 않게 짐</description>
    </item>
    
    <item>
      <title>원시 피타고라스 트리플은 두 홀수만으로 표현할 수 있다</title>
      <link>https://freshrimpsushi.github.io/posts/primitive-pytagorean-triple-can-be-represented-by-2-odd-numbers/</link>
      <pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/primitive-pytagorean-triple-can-be-represented-by-2-odd-numbers/</guid>
      <description>정리 1 $a^2 + b^2 = c^2$ 를 만족하는 세 자연수 $a,b,c$ 에 대해 $$ \begin{align*} a =&amp;amp; st \\ b =&amp;amp; {{s^2 - t^2 } \over {2}} \\ c =&amp;amp; {{s^2 + t^2 } \over {2}} \end{align*} $$ 를 만족하는 서로소인 두 홀수 $s&amp;gt;t$ 가 존재한다. 설명 이 정리에 따르면 피타고라스 트리플은 사실상 &amp;lsquo;트리플&amp;rsquo;이라고 부를 이유가 없어진다. 변수를 줄일 수 있다는 건 그것이 어떤 과목이든 가리지 않고 무조건 좋은 일이다. 증</description>
    </item>
    
    <item>
      <title>위상수학에서 기저의 동치 조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-baisis/</link>
      <pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-baisis/</guid>
      <description>정의 1 집합 $X$ 에서 $\mathscr{B}$ 가 위상 $\mathscr{T}$ 에 대한 기저, $\mathscr{B}&#39;$ 가 위상 $\mathscr{T}&#39;$ 에 대한 기저라고 할 때, $\mathscr{T} = \mathscr{T}&#39;$ 이면 $\mathscr{B}$ 와 $\mathscr{B}&#39;$ 를 서로 동치Equivalent라 한다. 정리 기저의 동치는 아래의 두 가지를 만족시키는 것과 필요충분조건이다. (i): 모든 $B \in \mathscr{B}$ 와 $x \in B$ 에 대해, $x \in B&#39; \subset B$ 를 만족시키는 $B&#39; \in \mathscr{B}&#39;$ 가 존재한다. (ii): 모든 $B&#39; \in \mathscr{B}&#39;$ 와 $x&#39; \in B&#39;$ 에 대해, $x&#39; \in B \subset B&#39;$ 를 만족시키</description>
    </item>
    
    <item>
      <title>복소해석학에서의 교차비</title>
      <link>https://freshrimpsushi.github.io/posts/cross-ratio-in-complex-analysis/</link>
      <pubDate>Fri, 09 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cross-ratio-in-complex-analysis/</guid>
      <description>정의 1 확장복소평면상에서 네 개의 서로 다른 점 $ z_{1} , z_{2} , z_{3} , z_{4} \in \overline{ \mathbb{C} }$ 에 대해 다음을 교차비Cross Ratio라고 정의한다. $$ (z_{1} , z_{2} , z_{3} , z_{4} ) = {{( z_{1} - z_{4})( z_{3} - z_{2})} \over {(z_{1} - z_{2}) ( z_{3} - z_{4}) } } $$ 설명 조금 모양을 바꿔서 $\displaystyle (z_{1} , z_{2} , z_{3} , z ) = {{( z_{3} - z_{2}) } \over {(z_{1} - z_{2})} } \cdot {{ ( z - z_{1}) } \over { ( z - z_{3}) } }$ 라고 해보면 $$ (z_{1} , z_{2} , z_{3} , z_{1} ) = 0 \\ (z_{1} ,</description>
    </item>
    
    <item>
      <title>위상수학에서의 부분기저</title>
      <link>https://freshrimpsushi.github.io/posts/subbasis-in-topology/</link>
      <pubDate>Fri, 09 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subbasis-in-topology/</guid>
      <description>정의 1 위상공간 $\left( X , \mathscr{T} \right)$ 에 대해 $\mathscr{S} \subset \mathscr{T}$ 이라 하자. $\displaystyle \mathscr{B} = \left\{ \left. B = \bigcap_{ i = 1}^{n} S_{i} \ \right| \ S_{i} \in \mathscr{S} \right\}$ 가 $\mathscr{T}$ 의 기저가 될 때, $\mathscr{S}$ 를 $\mathscr{T}$ 의 부분기저Subbasis라 한다. 설명 부분기저를 받아들이기 어려운 이유는 보통 수학에서 &amp;lsquo;부분&amp;rsquo;을 붙일 때는 부분집합이면서 원래의 성질을 유지하기 때문이다. 예를 들어 부분군이라면 부분</description>
    </item>
    
    <item>
      <title>피타고리스 수 중 하나는 반드시 3의 배수여야한다</title>
      <link>https://freshrimpsushi.github.io/posts/one-of-pythagorean-triple-must-be-multiple-of-3/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/one-of-pythagorean-triple-must-be-multiple-of-3/</guid>
      <description>정의 1 자연수 $a,b,c$ 가 $a^2 + b^2 = c^2$ 를 만족할 때, $a$ 혹은 $b$ 는 $3$ 의 배수다. 설명 피타고라스 수 중 하나는 반드시 짝수일 뿐만이 아니라 적어도 하나는 $3$ 의 배수라는 이야기를 할 수 있다. 증명 어떤 자연수 $n$ 에 대해 자연수를 $3$ 으로 나눈 나머지 $1, 2, 0$ 에 따라 세가지로 나눠 생각해보자. Case 1. 나머지가 $1$ 인 경우 $$ \begin{align*} (3n+1)^2 &amp;amp;= 9 n^2 + 6n + 1 \\ =&amp;amp; 3( 3 n^2 + 2n) + 1 \end{align*} $$ 이므로</description>
    </item>
    
    <item>
      <title>피타고라스 트리플</title>
      <link>https://freshrimpsushi.github.io/posts/pythagorean-triple/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pythagorean-triple/</guid>
      <description>정의 1 $a^2 + b^2 = c^2$ 를 만족하는 세 자연수의 순서쌍 $(a,b,c)$ 을 피타고라스 트리플이라 한다. 만약 세 자연수가 공약수를 가지지 않으면 원시 피타고라스 트리플Primitive Pytahgoras Triple라 한다. 설명 편의상 피타고라스 트리플에 포함된 수를 피타고라스 수라고 부르도록 하자. 피타고라스 트리플의 예로는 다들 잘 아는 것과 같이 $(3, 4, 5)$ 그리고 $(5, 12, 13)$ 등이 있</description>
    </item>
    
    <item>
      <title>피타고리스 수 중 하나는 반드시 짝수여야한다</title>
      <link>https://freshrimpsushi.github.io/posts/one-of-pythagorean-triple-must-be-even/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/one-of-pythagorean-triple-must-be-even/</guid>
      <description>정리 1 자연수 $a,b,c$ 가 $a^2 + b^2 = c^2$ 를 만족할 때, $a$ 혹은 $b$ 는 짝수다. 설명 흥미롭게도 피타고라스 수 중 하나는 반드시 짝수여야한다. 증명 짝수의 제곱은 짝수고 홀수의 제곱은 홀수이므로, $c^2$ 이 홀수면 $a^2$ 이 짝수거나 $b^2$ 여야만 한다. $c^2$ 이 짝수라고 가정하면 $a^2$ 과 $b^2$ 이 모두 홀수거나 짝수인데, 모두 홀수인 경우만 살펴보면 충분하다.어떤 자연수 $x,y,z \in \mathbb{N}$ 에 대해 $a,b,c$</description>
    </item>
    
    <item>
      <title>확장복소평면에서 원은 쌍선형변환에 대해 불변이다</title>
      <link>https://freshrimpsushi.github.io/posts/circle-is-invariant-to-bilinear-transform-in-extended-complex-plane/</link>
      <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/circle-is-invariant-to-bilinear-transform-in-extended-complex-plane/</guid>
      <description>정리 1 모든 쌍선형변환은 $\overline { \mathbb{C} }$ 의 원을 $\overline { \mathbb{C} }$ 의 원으로 대응시킨다. 증명 일반적인 원의 방정식을 $$ a ( x^2 + y^2 ) + 2p x + 2q y + c = 0 $$ 로 나타내보자. 그리고 $B := p - iq$ 라 두면 복소평면 상의 $z = x + i y$ 에 대해 $$ az \overline{z} + Bz + \overline{Bz } + c = 0 $$ 을 얻을 수 있다. 이제 $az \overline{z} + Bz + \overline{Bz } + c = 0$ 에 선형변환 $\displaystyle w = {{z - \beta} \over {\alpha}}$ 와 반전 $\displaystyle w = {{1} \over {z}}$</description>
    </item>
    
    <item>
      <title>산술의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-arithmetic/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-arithmetic/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 산술의 기본정리의 대수적 증명 자연수 $n &amp;gt;2$ 은 유일한 소인수분해 $n = p_{1} p_{2} \cdots p_{r}$ 를 가진다. 이때 소수 $p_{1} , p_{2} , \cdots , p_{r}$ 의 순서는 무시한다.초등학교부터 자연스럽게 써오던 성질이니만큼 증명이 필요하다는 사실이 낯설겠지만 굉장히 중요하다.어쩌면 이렇게나 쉽다는 것 자체가 기본정리라는 이름을 달만</description>
    </item>
    
    <item>
      <title>소수는 무한히 존재한다  오일러의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/eulers-proof-of-the-infinitude-of-primes/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eulers-proof-of-the-infinitude-of-primes/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 유클리드의 증명 소수는 무한히 존재한다. 전략: 어떤 방법을 사용하든 같은 결과에만 도달한다면야 상관은 없지만, 정말 특이하게 풀어냈다면 그 자체로 공부할 가치가 있다. 유클리드의 증명처럼 단순 명료 깔끔한 맛은 없지만 정수론의 문제를 해석적인 툴로 해결했다는 점이 매우 흥미롭다. 오일러가 남긴</description>
    </item>
    
    <item>
      <title>쌍선형변환</title>
      <link>https://freshrimpsushi.github.io/posts/bilinear-transform/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bilinear-transform/</guid>
      <description>정의 1 정의역에서 등각사상인 $f$ 를 다음과 같이 부른다. 이동Translation $f(z) = z + \alpha$ 확대Magnification: $f(z) = \rho z$ 회전Rotation: $f(z) = e^{i \theta} z$ 반전Inversion: $f(z) = {{1} \over {z}}$ 쌍선형변환Bilinear Trasform: $\displaystyle f(z) = {{ \alpha z + \beta } \over { \gamma z + \delta }}$ 이동에서 $\alpha \in \mathbb{C}$ 이고, 확대에서 $\rho \in \mathbb{R}^{ \ast }$ 이다. 설명 1</description>
    </item>
    
    <item>
      <title>어떤 수를 나누는 소수는 그 약수 중 적어도 하나를 나누어야한다</title>
      <link>https://freshrimpsushi.github.io/posts/prime-divisor-must-divide-one-ot-other-divisor/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prime-divisor-must-divide-one-ot-other-divisor/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 자연수 $ n : = d_{1} d_{2} \cdots d_{r}$ 에 대해 $p \mid n$ 면 $p$ 는 $d_{1} , d_{2} , \cdots , d_{r}$ 중 하나를 나누어야한다. $p \mid n$ 은 $n$ 이 $p$ 의 배수, 즉 $p$ 가 $n$ 을 나눈다는 말이다.언뜻 보면 당연한 소리 같지만 엄연히 증명이 필요한 소수만의 성질이다.소수가 아니라도 위의 정리가 항상 성립하는지 생각해보자. 증명 일단은 $n$ 이 두 자연</description>
    </item>
    
    <item>
      <title>추상대수학에서의 대칭군</title>
      <link>https://freshrimpsushi.github.io/posts/symmetric-group/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/symmetric-group/</guid>
      <description>정의 1 집합 $A$ 에 대해 전단사 $\phi : A \to A$ 를 순열Permutation이라 한다. $S_{A}$ 는 모든 순열을 모아놓은 집합으로써 함수의 합성 $\circ$ 에 대해 군 $\left&amp;lt; S_{A} , \circ \right&amp;gt;$ 를 이루고 대칭군Symmetric Group이라 부른다. 설명 대칭군이 정말 군의 조건을 만족하는지는 순열이 전단사로 정의되었다는 점에서 쉽게 확인할 수 있다. 주로 관심의 대상이 되는 것은</description>
    </item>
    
    <item>
      <title>확장된 유클리드 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-extended-euclid-theorem/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-extended-euclid-theorem/</guid>
      <description>정리 1 두 정수 $a,b$ 에 대해 $ax + by = \gcd (a,b)$ 는 반드시 정수해를 가진다. 설명 이 정리는 $\gcd (a,b)$ 가 $a$ 와 $b$ 의 일차Linear식으로 나타날 수 있다는 의미에서 선형 합동 정리Linear Congruence Theorem이라고도 불린다. 다소 복잡한 모양새고 존재성만 논하기 때문에 직접적으로 쓰이긴 어려울 것 같지만 의외로 굉장히 많이 사용한다. 구체적인 해 $(x,y)$ 를 찾아주는 건</description>
    </item>
    
    <item>
      <title>거리공간의 제1가산성과 제2가산성</title>
      <link>https://freshrimpsushi.github.io/posts/if-first-countable-and-seperable-then-second-countable/</link>
      <pubDate>Sat, 03 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-first-countable-and-seperable-then-second-countable/</guid>
      <description>정리 [1]: 모든 거리공간은 제1가산이다. [2]: 모든 가분 거리공간은 제2가산이다. 설명 위상수학에서 온갖 추상적인 공간들을 보고나면 거리공간이 얼마나 편리하고 좋은 공간인지 깨닫게 된다. 증명 [1] 거리공간 $\left( X , d \right)$ 에 대해 $x \in X$ 라고 하면 $$ \displaystyle \left\{ \left. B_{d} \left(x , {{1} \over {n}} \right) \ \right| \ n \in \mathbb{N} \right\} $$ 은 $x$ 에 대한 가산 국소기저이므로, $X$ 는 제1가산이다. ■ [2] 거리공</description>
    </item>
    
    <item>
      <title>위상수학에서의 기저와 국소기저</title>
      <link>https://freshrimpsushi.github.io/posts/basis-and-local-basis-in-topology/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/basis-and-local-basis-in-topology/</guid>
      <description>정의 위상공간 $\left( X , \mathscr{T} \right)$ 에 대해 $\mathscr{B} , \mathscr{B}_{x} \subset \mathscr{T}$ 라고 하자. $B_{\lambda} \in \mathscr{B}$ 이라고 할 때, 모든 $U \in \mathscr{T}$ 에 대해 $$ U = \bigcup_{\lambda \in \Lambda} B_{ \lambda } $$ 를 만족하는 첨수집합 $\Lambda$ 가 존재하면 $\mathscr{B}$ 를 $\mathscr{T}$ 에 대한 기저Basis라고 한다. 이 때 위상 $\mathscr{T}$ 는 $\mathscr{B}$ 에 의해 생성된다Generated고 한다. $x \in X$ 라고 할 때, 모든 $B \in \mathscr{B}_{x}$ 에 대해 $x \in B$ 이고 $x$ 를 포함하는 모든 $U \in \mathscr{T}$ 에 대해 $$ x \in B</description>
    </item>
    
    <item>
      <title>제1가산과 제2가산</title>
      <link>https://freshrimpsushi.github.io/posts/first-countable-and-second-countable/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/first-countable-and-second-countable/</guid>
      <description>정의 1 위상공간 $X$ 이 주어져 있다고 하자. 모든 점 $x \in X$ 에 대해 가산 국소기저가 존재하면 제1가산 공간이라 한다. $X$ 가 가산 기저를 가지면 제2가산 공간이라 한다. 설명 기저와 국소기저라는 개념을 통해 가산의 새로운 갈래를 만들어냈다고 보면 된다. 제1가산이 되지 못하는 예시 여유한공간 $\left( \mathbb{R} , \mathscr{T}_{f} \right)$ 은 제1가산이 되지 못하며, 말할 것도 없이 제2가산</description>
    </item>
    
    <item>
      <title>등각사상은 내각의 크기를 보존한다</title>
      <link>https://freshrimpsushi.github.io/posts/conformal-mapping-preserves-internal-angle-scale/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conformal-mapping-preserves-internal-angle-scale/</guid>
      <description>정리 1 영역 $\mathscr{R}$ 에서 함수 $f$ 가 등각사상이고 곡선 $\mathscr{C}_{1}$ 과 $\mathscr{C}_{2}$ 가 한 점 $\alpha$ 에서 만나며 그 내각을 $\psi$ 라고 하자. $\mathscr{C}_{1}&#39;$ 과 $\mathscr{C}_{2}&#39;$ 가 $\mathscr{C}_{1}$ 과 $\mathscr{C}_{2}$ 를 $f$ 로 보낸 상이라고 하면 두 곡선은 $\beta = f ( \alpha )$ 에서 만나며 그 내각 역시 $\psi$ 다. 설명 해석학답게 말은 어렵지만 요는 도형들이 이루는 내각을 등각사상이 보존한다는 것이다. 애초에 등각사상이라는 이름 자체가 이러한 성질에서 나온 것이다.</description>
    </item>
    
    <item>
      <title>모든 순환군은 정수군과 동형임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/every-cyclic-group-is-isomorphic-to-integer-group/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/every-cyclic-group-is-isomorphic-to-integer-group/</guid>
      <description>정리 1 순환군 $\left&amp;lt; a \right&amp;gt;$ 가 유한군이면 $\left&amp;lt; a \right&amp;gt; \simeq \mathbb{Z}_{n}$ 이고 무한군이면 $\left&amp;lt; a \right&amp;gt; \simeq \mathbb{Z}$ 이다. 설명 이 정리로 순환군에 대한 탐구는 사실상 거의 끝난다. 추상적이기만 했던 군이 단숨에 정수론의 영역으로 떨어지기 때문에 할 수 있는 게 상당히 많아진다. 반대로 군론의 이론들을 이용해서 정수론의 문제를 풀어내는 것 역시 가능할 것이다. 증명 어떤 $m \in \mathbb{n}$ 에 대해 $a^m = e$ 을 만</description>
    </item>
    
    <item>
      <title>복소해석에서 등각사상이란?</title>
      <link>https://freshrimpsushi.github.io/posts/conformal-mapping/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conformal-mapping/</guid>
      <description>정의 1 함수 $f: A \subset \mathbb{C} \to \mathbb{C}$ 가 $\mathscr{R} \subset A$ 에서 해석적이고 모든 $z \in \mathscr{R}$ 에 대해 $f&#39;(z) \ne 0$ 이면 $f$ 를 등각사상Conformal Mapping 혹은 등각변환Conformal Transform이라고 한다. 한편 $f&#39;(\alpha) = 0$ 를 만족하는 점 $\alpha$ 가 존재하면 $\alpha$ 를 $f$ 의 임계점Critical Point이라고 한다. 설명 등각等角이라는 한자 그대로 등각변환을 취하면 도형들이</description>
    </item>
    
    <item>
      <title>역함수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-inverse-function-theorem/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-inverse-function-theorem/</guid>
      <description>정리 1 $f$ 가 $\alpha$ 에서 해석적이고 $f&#39;(\alpha) \ne 0$ 이면 $\mathcal{N} (\alpha)$ 에서 $f^{-1}$ 가 존재한다. 설명 $f&#39;(\alpha) \ne 0$ 이라는 조건을 잘 생각해보자. 실수함수로 생각해보면 증가함수거나 감소함수라는 것이고, 이는 역함수가 존재하는 조건이 된다. 기하적인 표현을 빌리자면 매끄러운Smooth 함수를 말하는 것이고, 이는 갑자기 방향을 트는 등의 꺾인 점이 없다는 뜻이다. 역함수 정리에서</description>
    </item>
    
    <item>
      <title>여유한위상과 여가산위상</title>
      <link>https://freshrimpsushi.github.io/posts/cofinite-topology-and-cocountable-topology/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cofinite-topology-and-cocountable-topology/</guid>
      <description>정의 $X$ 가 무한집합이라고 하자. $\mathscr{T}_{f} : = \left\{ \emptyset , X \right\} \cup \left\{ U \subset X : | X \setminus U | &amp;lt; \infty \right\}$ 를 여유한위상이라 한다. $\mathscr{T}_{c} : = \left\{ \emptyset , X \right\} \cup \left\{ U \subset X : | X \setminus U | = \aleph_{0} \right\}$ 를 여가산위상이라 한다. 알레프 제로 $\aleph_{0}$ 는 무한 가산 집합의 기수를 의미한다. 설명 단어와 표현은 어렵지만 의미하는 바는 결국 여집합이 유한인 위상, 여집합이 가산인 위상이라는 말이다. 여유</description>
    </item>
    
    <item>
      <title>일반적인 위상공간에서 수열의 극한은 유일하지 않다</title>
      <link>https://freshrimpsushi.github.io/posts/limits-of-sequence-are-not-unique-in-general-space/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limits-of-sequence-are-not-unique-in-general-space/</guid>
      <description>정리 일반적으로, 위상공간에서 수열의 극한은 유일하지 않다. 설명 도대체 이게 무슨 소린가 싶겠지만 놀랍게도 사실이다. 우리는 이제껏 해석학 등에서 수열을 포함하는 구간이 점점 좁아지면서 한 점으로 수렴하는 이미지를 떠올려왔다. 하지만 위상수학에서 정의하는 수렴의 개념에 따르면 위상공간에 따라선 한 점으로 수렴할 이유가 전혀 없다. 극한의 유일성</description>
    </item>
    
    <item>
      <title>위상공간에서의 가분과 폐포</title>
      <link>https://freshrimpsushi.github.io/posts/separable-in-topology/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separable-in-topology/</guid>
      <description>정의 1 위상공간 $X$ 에 대해 $A \subset X$ 라고 하자. $x \in O \subset A$ 를 만족하는 열린 집합 $O$ 가 존재할 때, $x$ 를 $A$ 의 내점Interior Point이라 한다. $A$ 의 내점의 집합 $A^{\circ}$ 를 $A$ 의 내부Interior라 한다. $A$ 와 그 도집합의 합집합 $\overline{A} : = A \cup A&#39;$ 를 $A$ 의 폐포Closure라 한다. $x \in \overline{A}$ 이면서 $x \in \overline{X \setminus A}$ 일 때, $x$ 를 $A$ 의 경계점Boundary</description>
    </item>
    
    <item>
      <title>자명 위상과 이산 위상</title>
      <link>https://freshrimpsushi.github.io/posts/sierpinski-space/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sierpinski-space/</guid>
      <description>정의 1 어떤 집합 $X$ 가 주어져 있을 때 자명 위상Trivial Topology $\left\{ \emptyset , X \right\}$ 를 주면 그 공간은 가장 작은 공간이며 자명 공간이라 한다. 반대로 이산 위상Discrete Topology $\mathscr{P}(X)$ 를 주면 그 공간은 가장 큰 공간이며 이산 공간이라 한다. 시어핀스키 공간 $S : = \left\{ 0, 1 \right\}$ 의 위상이 $\mathscr{T} : = \left\{ \emptyset , \left\{ 1 \right\} , \left\{ 0, 1 \right\} \right\}$ 이면 $S$ 를 시어핀스키 공간Sierpinski</description>
    </item>
    
    <item>
      <title>순환군의 부분군은 순환군임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/subgroup-of-cyclic-group-is-also-cyclic-group/</link>
      <pubDate>Sun, 28 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subgroup-of-cyclic-group-is-also-cyclic-group/</guid>
      <description>정의 1 순환군 $G$ 의 부분군 $ H \leqslant G$ 은 순환군이다. 설명 생각을 조금만 해보면 당연한 사실이지만 상당히 중요한 정리일뿐만 아니라 증명 역시 간단하지만은 않다. 증명 $H = \left\{ e \right\}$ 일 경우 $H = \left&amp;lt; e \right&amp;gt;$ 이므로 순환군이다. $H \ne \left\{ e \right\}$ 일 경우 어떤 자연수 $n$ 에 대해 $a^{n} \in H$ 일 것이고, 이를 만족하는 가장 작은 자연수를 $m$ 이라고 하자. $c := a^m$ 일 때 $H = \left&amp;lt; a^m \right&amp;gt; = \left&amp;lt;</description>
    </item>
    
    <item>
      <title>추상대수학에서의 동형</title>
      <link>https://freshrimpsushi.github.io/posts/isomorphism-in-abstract-algebra/</link>
      <pubDate>Sun, 28 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isomorphism-in-abstract-algebra/</guid>
      <description>정의 1 두 이항연산구조 $\left&amp;lt; S , * \right&amp;gt;$ 와 $\left&amp;lt; S&#39; , *&#39; \right&amp;gt;$ 에 대해 전단사 함수 $\phi : S \to S&#39;$ 가 존재해서 모든 $x , y \in S$ 에 대해 $$ \phi(x \ast\ y) = \phi( x ) *&#39; \phi( y ) $$ 를 만족하면 $\phi$ 를 동형사상이라 부르고 $S$ 와 $S&#39;$ 가 동형Isomorphic이라 하고 $S \simeq S&#39;$ 라 쓴다. 설명 정의를 요약하자면 연산를 보존하는 전단사가 존재해주면 사실상 서로 같다고 보겠다는 것이다. 꼭 추상</description>
    </item>
    
    <item>
      <title>모든 순환군은 가환군임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/evert-cyclic-group-is-abelian-group/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/evert-cyclic-group-is-abelian-group/</guid>
      <description>정리 1 모든 순환군은 가환군이다. 설명 굳이 따로 증명하지 않더라도 순환군이 정수군과 동형이라는 것을 보이면 자연스럽게 따라오는 사실이기도 하다. 증명 순환군 $G := \left&amp;lt; a \right&amp;gt;$ 에 대해, $g_{1} = a^{r}$ 그리고 $g_{2} = a^{s}$ 라고 하자. $$ g_{1} g_{2} = a^{r} a^{s} = a^{r+s} = a^{s+r} = a^{s} a^{r} = g_{2} g_{1} $$ 이므로 $G$ 는 가환군이다. ■ Fraleigh. (2003). A first course in abstract algebra(7th Edition): p59. &amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>위상공간에서의 집적점과 수렴, 도집합</title>
      <link>https://freshrimpsushi.github.io/posts/limit-point-and-convergence/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-point-and-convergence/</guid>
      <description>정의 1 위상공간 $\left( X , \mathscr{T} \right)$ 이 주어져 있다고 하자. $A \subset X$ 에 대해 $x$ 를 포함하는 임의의 열린 집합 $O$ 가 $O \cap ( A \setminus \left\{ x \right\} ) \ne \emptyset$ 를 만족하면 $x$ 를 $A$ 의 집적점Limit Point , $A$ 의 모든 집적점의 집합 $A&#39;$ 를 $A$ 의 도집합Derived Set이라 한다. $X$ 의 수열 $\left\{ x_{n} \right\}$ 이 $x$ 에 수렴한다Converge는 것은 $x$ 를 포함하는 임의의 열린 집합 $O$ 에 대해 다음을</description>
    </item>
    
    <item>
      <title>위상공간이란?</title>
      <link>https://freshrimpsushi.github.io/posts/topology-space/</link>
      <pubDate>Fri, 26 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/topology-space/</guid>
      <description>정의 위상공간 1 집합 $X$ 가 주어졌을 때 $\mathscr{T} \subset \mathscr{P} (X)$ 가 $T \in \mathscr{T}$ 에 대해 다음 세가지 조건을 만족하면 $\mathscr{T}$ 를 $X$ 의 위상Topology이라 부르고, $\left( X , \mathscr{T} \right)$ 를 위상공간Topology Space라 부른다. (i): $$\emptyset , X \in \mathscr{T}$$ (ii): $$\displaystyle \bigcup_{ \alpha \in \forall } T_{\alpha} \in \mathscr{T}$$ (iii): $$\displaystyle \bigcap_{ i= 1}^{n} T_{i} \in \mathscr{T}$$ 조건 (i)~(iii)을 다시 말로 풀어써보면 아래와 같다: (i): $\mathscr{T}$ 는 공집합 $\emptyset$ 와 전체집합</description>
    </item>
    
    <item>
      <title>거리공간에서 완비성과 조밀성</title>
      <link>https://freshrimpsushi.github.io/posts/completeness-density/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/completeness-density/</guid>
      <description>정의 거리 공간 $\left( X , d \right)$ 에 대해 $A \subset X$ 라고 하자. $X$ 의 수열 $\left\{ x_{n} \right\}$ 이 모든 $\varepsilon &amp;gt; 0$ 에 대해 $n,m &amp;gt; n_{0}$ 일때마다 $d(x_{n} , x_{m}) &amp;lt; \varepsilon$ 을 만족하는 자연수 $n_{0}$ 가 존재하면 코시 수열Cauchy sequence이라고 한다. $\left( X , d \right)$ 상의 코시 수열의 수렴하는 점들이 $X$ 에 속하면 $\left( X , d \right)$ 를 완비하다complete고 하고 그렇지 않을 경우 불완비하다incom</description>
    </item>
    
    <item>
      <title>그램-슈미트 직교화</title>
      <link>https://freshrimpsushi.github.io/posts/gram-schmidt-orthogonalization/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gram-schmidt-orthogonalization/</guid>
      <description>정리 모든 유한차원 내적공간은 정규직교기저를 갖는다. 설명 존재성 증명이라는 게 대개 그렇듯 길지도 않고 별것도 아닌것 같아보이지만 엄청나게 중요한 정리다. 선형대수학을 지탱하는 수많은 논리가 바로 이 정규직교기저가 존재한다는데에 의존하고 있기 때문이다. 증명 내적공간 $(V, \left\langle \cdot , \cdot \right\rangle)$을 생성하는 기저 중 하나를 $\left\{</description>
    </item>
    
    <item>
      <title>추상대수학에서의 순환군</title>
      <link>https://freshrimpsushi.github.io/posts/cyclic-group/</link>
      <pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cyclic-group/</guid>
      <description>정의 1 군 $G$ 의 어떤 원소 $a$ 과 임의의 $x \in G$ 에 대해 $x = a^{n}$ 을 만족하는 정수 $n \in \mathbb{Z}$ 이 존재하면 $G$ 를 순환군Cyclic Group이라 하고 $a$ 를 생성원Generator이라 한다. 설명 쉽게 말해 군의 모든 원소를 생성원의 거듭제곱으로 나타낼 수 있으면 순환군이다. 계속해서 거듭제곱하는 형태로 모든 원소를 나타내게 되므로 &amp;lsquo;순환&amp;r</description>
    </item>
    
    <item>
      <title>복소해석을 이용한 제곱수의 역수의 합 계산</title>
      <link>https://freshrimpsushi.github.io/posts/calculating-riemann-zeta-2-using-complex-analysis/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/calculating-riemann-zeta-2-using-complex-analysis/</guid>
      <description>정리 1 $$ \sum_{n =1 }^{\infty} {{1} \over {n^2}} = {{ \pi ^2 } \over { 6 }} $$ 오일러의 풀이가 깔끔하고 멋지긴 한데 아이디어가 너무 기발해서 막상 써먹을데는 별로 없다. 복소해석을 공부하면서 가장 즐거운 점은 이러한 결과를 내는 숏컷이 바로바로 나온다는 것이다. 예제로도 좋으니 직접 한번 풀어보도록 하자. 증명 $\displaystyle f(z) : = {{1} \over {z^2}}$ 이라고 정의하면 $\displaystyle \lim_{z \to \infty} z f(z) = 0$ 이다. 모든 정수에</description>
    </item>
    
    <item>
      <title>오일러의 증명: 싱크함수를 이용한 제곱수의 역수의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/finding-sum-of-reciprocal-of-square-number-using-sinc-function/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finding-sum-of-reciprocal-of-square-number-using-sinc-function/</guid>
      <description>정리 $$ \sum_{n =1 }^{\infty} {{1} \over {n^2}} = {{ \pi ^2 } \over { 6 }} $$ 증명 전략: 이는 오일러가 남긴 풀이로써, 다름아닌 싱크함수의 오일러 표현을 사용해서 증명한다. 아이디어가 상당히 신선하고 재미있어서 한번 보면 잊어버리는 게 더 어려울 것이다. 싱크함수의 오일러 표현: $$ {{\sin x} \over {x}} = \prod_{n=1}^{\infty} \left( 1 - {{x^2} \over { \pi^2 n^2}} \right) $$ 오일러 표현의 우변을 풀어서 적어보면 아래와 같다. $$ \prod_{n=1}^{\infty} \left( 1</description>
    </item>
    
    <item>
      <title>유수정리를 이용한 모든 정수에 대한 급수의 합 공식</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-series-formula-for-all-integers-using-residue-theorem/</link>
      <pubDate>Sun, 21 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-series-formula-for-all-integers-using-residue-theorem/</guid>
      <description>공식 1 분수함수 $f$ 에 대해 $\lim_{n \to \infty} z f(z) = 0, n \in \mathbb{Z}$ 에서 $f(n) \ne 0$ 이라고 하자. $f$ 가 유한한 특이점 $z_{1}, \cdots , z_{m}$ 을 가질 때, $$ \sum_{n=-\infty}^{\infty} f(n) = - \sum_{n = 1}^{m} \text{Res}_{z_{n}} (\pi f(z) \cot \pi z) $$ 설명 단순히 자연수만을 모두 더하는 것이 아니라 모든 정수에 대한 합을 유한한 합계로 나타내는 데 의의가 있다. 물론 주어진 $f$ 가 우함수일 경우 그 절반을 취하면 자연수에 대한 합을 구하는데에도 응용이 가능하</description>
    </item>
    
    <item>
      <title>코탄젠트와 코시컨트의 로랑 전개</title>
      <link>https://freshrimpsushi.github.io/posts/laurnet-expansion-of-cotangent-and-cosecant/</link>
      <pubDate>Sun, 21 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laurnet-expansion-of-cotangent-and-cosecant/</guid>
      <description>공식 $$ \cot z = {{1} \over {z}} - {{z} \over {3}} - {{z^{3}} \over {45}} - {{2 z^{5}} \over {945}} - \cdots \\ \csc z = {{1} \over {z}} + {{z} \over {6}} + {{7 z^{3}} \over {360}} + {{31 z^{5}} \over {15120}} + \cdots $$ 설명 복소해석에서 급수의 합 공식을 쓰기 위해선 코탄젠트와 코시컨트가 곱해진 함수의 유수를 구할 수 있어야한다. 물론 이보다 우아하고 차수가 큰 항에도 쓸 수 있는 급수꼴이 있지만 대개는 이정도면 충분하다. 적어도 세번째 항까지는 시험공부를</description>
    </item>
    
    <item>
      <title>거리공간에서 볼과 열린 집합 닫힌 집합</title>
      <link>https://freshrimpsushi.github.io/posts/ball-open-closed/</link>
      <pubDate>Thu, 18 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ball-open-closed/</guid>
      <description>정의 거리 공간 $\left( X, d \right)$ 에 대해 $a \in X$ 이고 $r &amp;gt; 0$ 이라고 하자. $B_{d} (a,r) = \left\{ x \in X \ | \ d(a,x) &amp;lt; r \right\}$ 을 중심이 $a$ 고 반경이 $r$ 인 열린 볼Open Ball이라 한다. $B_{d} [a,r] = \left\{ x \in X \ | \ d(a,x) \le r \right\}$ 을 중심이 $a$ 고 반경이 $r$ 인 닫힌 볼Closed Ball이라 한다. $O \subset X$ 가 열린 볼의 합집합이면 $O$ 를 $X$ 에서 열린 집합Open Set이라 한다. $C \subset X$ 에 대</description>
    </item>
    
    <item>
      <title>거리공간의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/metric-space/</link>
      <pubDate>Wed, 17 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/metric-space/</guid>
      <description>정의 집합 $X$ 에 대해 함수 $d : X \times X \to [0, \infty)$가 $x,y,z \in X$ 에 대해 아래의 조건들을 만족시킬 때, $d$를 거리metric라고 하고 $\left( X, d\right)$를 거리공간metric space이라고 한다. 거리가 자명한 경우에는 거리공간을 간단히 $X$라고 표기하기도 한다. $d(x,y)=0 \iff x = y$ $d(x,y) = d(y,x)$ $d(x,y) + d(y,z) \ge d(x,z)$ 설명 선형대수학에서 놈의 개</description>
    </item>
    
    <item>
      <title>다가함수의 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/improper-integral-of-mult-ivalued-function/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/improper-integral-of-mult-ivalued-function/</guid>
      <description>빌드업 1 다가함수를 적분할 때의 가장 큰 문제점은 경로를 지나면서 분기선을 만나면 함수값이 원치 않게 바뀐다는 것이다. 이러한 함수를 적분할 땐 이제까지 해왔던 것과 마찬가지로 경로 자체가 분기선을 우회하도록 하는 트릭을 사용한다. 대표적인 다가함수인 로그 $\log$ 를 생각해보면, 음의 실수축이 분기선이고 원점이 분기점이므로 위와 같은 경로를 생각해볼 수</description>
    </item>
    
    <item>
      <title>복소해석학에서의 다가함수와 분기</title>
      <link>https://freshrimpsushi.github.io/posts/multifunction-branch-cut-branch-point/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multifunction-branch-cut-branch-point/</guid>
      <description>정의 1 $X = \mathbb{C}$ 의 원소를 $Y$ 의 여러 값으로 대응시키는 사상을 다가함수Multifunction라 한다. 오픈셋 $A \subset \mathbb{C}$ 에서 정의된 다가함수 $g$ 에 대해 $\alpha \in \mathbb{C}$ 을 감싸고 $A$ 안에 놓이는 폐곡선 $\mathscr{C}$ 를 따라 $z-\alpha$ 가 $2\pi$ 만큼 계속해서 바뀌었을 때 값 $g(z)$ 이 원래의 값이 아니게끔 하도록하는 $\mathscr{C}$ 가 적어도 하나 존재하면 $\alpha$ 를 분기점Branch Point라 한다. $\alpha$ 의 모</description>
    </item>
    
    <item>
      <title>실수축의 특이점을 포함했을 때 조르당 보조정리를 통한 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/improper-integration-by-jordan-lemma-when-real-singular-points-are-included/</link>
      <pubDate>Sun, 07 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/improper-integration-by-jordan-lemma-when-real-singular-points-are-included/</guid>
      <description>빌드업 전체적인 흐름은 조르당 보조정리를 통한 이상적분과 비슷하다. 두 다항함수 $p(z) , q(z)$ 에 대해 $\displaystyle f(z) = {{q(z)} \over {p(z)}}$ 이라고 하자. $q(z) = 0$ 을 만족하는 실수해 $a$ 가 존재한다면 $f$ 는 실수 특이점 $a$ 을 갖는 것이다. 이제까지 이러한 경우를 다루지 않았던 이유는 유수 정리를 쓰기 위함이었다. 물론 실수축에 특이점이 추가되었다는 이유만으로 딱히 유수정리를 포기하지</description>
    </item>
    
    <item>
      <title>조르당 보조정리를 통한 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/improper-integration-by-jordan-lemma/</link>
      <pubDate>Sun, 07 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/improper-integration-by-jordan-lemma/</guid>
      <description>설명 1 우선은 발산하는 반원 상의 복소경로적분을 통한 유리함수의 이상적분과 비슷하게 시작해보자. 두 다항함수 $p(z) , q(z)$ 에 대해 $\displaystyle f(z) = {{q(z)} \over {p(z)}}$ 이라고 하자. $q(z) = 0$ 을 만족하는 실수해가 존재하지 않으면 $f$ 는 실수 특이점을 갖지 않을 것이다. 양수 $m \in \mathbb{R}^{+}$ 에 대해 $\displaystyle \int_{- \infty}^{\infty} \sin{mx}f(x) dx$ 혹은 $\displaystyle \int_{- \infty}^{\infty} \cos{mx}f(x) dx$ 꼴의 적분을 한다고 생각해보자. 이때 이상적분이 존재하는 조건은 $\displaystyle</description>
    </item>
    
    <item>
      <title>조르당 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-jordan-lemma/</link>
      <pubDate>Sat, 06 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-jordan-lemma/</guid>
      <description>정리 1 반원호 $\Gamma$ 를 $z(\theta) = R e^{i \theta} , 0 \le \theta \le \pi$ 와 같이 나타냈을 때, 함수 $f: \mathbb{C} \to \mathbb{C}$ 가 $\Gamma$ 에서 연속이고 $\displaystyle \lim_{z \to \infty} f(z) = 0$ 이면 양수 $m \in \mathbb{R}^{+}$ 에 대해 $$ \displaystyle \lim_{R \to \infty} \int_{\Gamma} e^{m i z } f(z) dz = 0 $$ 설명 조르당이라는 발음법은 콩글리쉬가 아니라 프랑스어에서 온 것이다. 보조정리이니만큼 바로 그 의미를 깨닫긴 어렵고, 여러가지 적분 테크닉에 쓰인다는 정도만 알아두면 충분하</description>
    </item>
    
    <item>
      <title>특이값 분해를 통한 최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/least-squares-using-sigular-value-decomposition/</link>
      <pubDate>Sat, 06 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/least-squares-using-sigular-value-decomposition/</guid>
      <description>알고리즘 $A \in \mathbb{C}^{m \times n}$ 과 벡터 $\mathbb{b} \in \mathbb{C}^{m}$ 에 대해 $\text{rank} A = n$ 이고 $A \mathbb{x} = \mathbb{b}$ 의 최소제곱해를 $\mathbb{x}_{\ast}$ 이라고 하자. Step 1. 특이값 분해 $A = \widehat{U} \widehat{\Sigma} V^{\ast}$ 를 만족하는 정규직교행렬 $\widehat{U}$ 과 대각행렬 $\widehat{\Sigma}$ 과 유니터리 행렬 $V$ 를 구한다. Step 2. 특이값 분해에서 얻은 $\widehat{U}$ 를 통해 정사영 $P : = \widehat{U} \widehat{U}^{\ast}$ 을 구한다. $A \mathbb{x}_{\ast} = P \mathbb{b}$ 이므로 $\widehat{U} \widehat{\Sigma} V^{\ast} \mathbb{x}_{\ast} = \widehat{U} \widehat{U}^{\ast} \mathbb{b}$ 이고 양변의 왼쪽에 $\widehat{U}^{\ast}$ 을 곱해 $\widehat{\Sigma} V^{\ast} \mathbb{x}_{\ast} = \widehat{U}^{\ast} \mathbb{b}$ 를 얻는</description>
    </item>
    
    <item>
      <title>QR 분해를 통한 최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/least-squares-using-qr-decomposition/</link>
      <pubDate>Fri, 05 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/least-squares-using-qr-decomposition/</guid>
      <description>알고리즘 $A \in \mathbb{C}^{m \times n}$ 과 벡터 $\mathbb{b} \in \mathbb{C}^{m}$ 에 대해 $\text{rank} A = n$ 이고 $A \mathbb{x} = \mathbb{b}$ 의 최소제곱해를 $\mathbb{x}_{\ast}$ 이라고 하자. Step 1. QR 분해 $A = \widehat{Q} \widehat{R}$을 만족하는 정규직교행렬 $\widehat{Q}$ 과 상삼각행렬 $\widehat{R}$ 을 구한다. Step 2. QR 분해에서 얻은 $\widehat{Q}$ 를 통해 정사영 $P : = \widehat{Q} \widehat{Q}^{\ast}$ 을 구한다. $A \mathbb{x}_{\ast} = P \mathbb{b}$ 이므로 $\widehat{Q} \widehat{R} \mathbb{x}_{\ast} = \widehat{Q} \widehat{Q}^{\ast} \mathbb{b}$ 이고 양변의 왼쪽에 $\widehat{Q}^{\ast}$ 을 곱해 $\widehat{R} \mathbb{x}_{\ast} = \widehat{Q}^{\ast} \mathbb{b}$ 를 얻는다. Step</description>
    </item>
    
    <item>
      <title>콜레스키 분해를 통한 최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/least-squares-using-cholesky-decomposition/</link>
      <pubDate>Fri, 05 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/least-squares-using-cholesky-decomposition/</guid>
      <description>알고리즘 $A \in \mathbb{C}^{m \times n}$ 과 벡터 $\mathbb{b} \in \mathbb{C}^{m}$ 에 대해 $\text{rank} A = n$ 이고 $A \mathbb{x} = \mathbb{b}$ 의 최소제곱해를 $\mathbb{x}_{\ast}$ 이라고 하자. Step 1. 주어진 방정식의 양변에 $A^{\ast}$ 을 곱해 표준방정식 $A^{\ast} A \mathbb{x} = A^{\ast} \mathbb{b}$ 을 세운다. 표준방정식의 해는 원래 방정식의 최소제곱해가 되므로, 표준방정식의 해 $\mathbb{x}$ 를 구하면 된다. Step 2. $\mathbb{y} := A^{\ast} \mathbb{b}$ 을 계산해 $A^{\ast} A \mathbb{x} = \mathbb{y}$ 을 얻는다. Step 3. 콜레스키 분해 $A^{\ast} A = L L^{\ast}$ 을 만족하</description>
    </item>
    
    <item>
      <title>최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/the-method-of-least-square/</link>
      <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-method-of-least-square/</guid>
      <description>정의 행렬 $A \in \mathbb{C}^{m \times n}$ 와 벡터 $\mathbf{b} \in \mathbb{C}^{m}$ 에 대해 $\mathbf{b} \notin \mathcal{C} (A)$ 이면 방정식 $A\mathbf{x} = \mathbf{b}$ 는 해를 갖지 않으나, 대신 $\mathbf{x}_{\ast} = \argmin \left\| \mathbf{b} - A \mathbf{x} \right\|_{2}$ 를 최소제곱해라고 정의한다. 설명 방정식의 해가 존재하지 않는 것은 안타깝지만 그렇다고 풀이 자체를 포기할 수는 없다. 사실 이 세상에 잘 풀리지 않는, 학계의 최전선에서 수학자들의 해법을 기다리고 있는 방정식들은 대개 그런 문제들이다</description>
    </item>
    
    <item>
      <title>행렬의 QR 분해</title>
      <link>https://freshrimpsushi.github.io/posts/qr-decomposition-of-matrix/</link>
      <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/qr-decomposition-of-matrix/</guid>
      <description>개요 효율적인 행렬 분해에는 여러가지 조건이 필요하지만, 효율 이전에 분해 자체를 할 수 있느냐 없느냐가 중요할 수 있다. QR 분해는 정방행렬이라는 조건이 필요 없는 행렬 분해법이다. 정의 계수가 $n$ 인 행렬 $A := \begin{bmatrix} \mathbb{a}_{1} &amp;amp; \cdots &amp;amp; \mathbb{a}_{n} \end{bmatrix} \in \mathbb{C}^{m \times n}_{n}$ 에 대해 $i$ 번째까지의 열벡터로 생성된 부분공간 $$ S_{i} (A) := \text{sp} \left\{ \mathbb{a}_{1}, \cdots , \mathbb{a}_{i} \right\} $$ 을 정의하자. 벡터공간을 생성할 땐 $i$ 가 클수</description>
    </item>
    
    <item>
      <title>선형대수학에서 정사영이란</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-projection-in-linear-algebra/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-projection-in-linear-algebra/</guid>
      <description>정의 사영 $P \in \mathbb{C}^{m \times m}$ 가 $\mathcal{C} (P) ^{\perp} = \mathcal{N} (P)$ 를 만족하면 $P$ 를 정사영이라 한다. 설명 사영의 성질 $\mathbb{C}^{m } = \mathcal{C} (P) \oplus \mathcal{N} (P)$ 에 따라 $P$ 는 $\mathbb{C}^{m}$ 을 정확히 두 개의 부분공간 $\mathcal{C} (P)$ 과 $\mathcal{N} (P)$ 으로 분할함을 알 수 있다. 이 분할에서 조건 $\mathcal{N} (P) = \mathcal{C} (P) ^{\perp}$ 을 만족한다는 것은 일차변환 $P$ 의 영공간 $\mathcal{N} (P)$ 가 열공간 $\mathcal{C} (P)$ 의 직교여공간이라는 뜻이므로 그냥 분할이 아니라 수직성이 포함되는 분할임을</description>
    </item>
    
    <item>
      <title>행렬대수에서 사영이란</title>
      <link>https://freshrimpsushi.github.io/posts/projection-in-matrix-algebra/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/projection-in-matrix-algebra/</guid>
      <description>정의 정방행렬 $P \in \mathbb{C}^{m \times m}$ 가 $P^2 = P$ 면 사영작용소Projector라 한다. 설명 대수학적인 용어로는 멱등원Idempotent이라는 표현을 사용하고, 마찬가지로 $a^2 = a$ 와 같은 원소를 일컫는다. 한편 $P$ 가 사영이면 $(I-P)^2 = I - 2P + P^2 = I - 2P + P = (I-P)$ 이므로 $(I-P)$ 역시 사영임을 알 수 있다. 이러한 사영작용소 $(I - P)$를 $P$ 의 여사영작용소Co</description>
    </item>
    
    <item>
      <title>벡터공간에서 직합이란</title>
      <link>https://freshrimpsushi.github.io/posts/direct-sum-of-vector-space/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/direct-sum-of-vector-space/</guid>
      <description>정의 벡터공간 $S$ 의 두 부분공간 $S_{1}$과 $S_{2}$ 에 대해 다음을 만족하면 $S$를 $S_{1}$과 $S_{2}$ 의 직합direct sum이라 하고, $S = S_{1} \oplus S_{2}$와 같이 표기한다. (i) 존재성: 임의의 $\mathbf{s} \in S$ 에 대해 $\mathbf{s} = \mathbf{s}_{1} + \mathbf{s}_{2}$ 을 만족하는 $\mathbf{s}_{1} \in S_{1}$ 과 $\mathbf{s}_{2} \in S_{2}$ 가 존재한다. (ii) 배타성: $S_{1} \cap S_{2} = \left\{ \mathbf{0} \right\}$ (iii) 유일성: 주어진 $\mathbf{s}$ 에 대해 $\mathbf{s} = \mathbf{s}_{1} + \mathbf{s}_{2}$ 을 만족하</description>
    </item>
    
    <item>
      <title>콜레스키 분해의 유일성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-uniqueness-of-cholesky-decomposition/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-uniqueness-of-cholesky-decomposition/</guid>
      <description>정리 $A&amp;gt;0$ 은 오직 하나의 콜레스키 분해를 가진다. 설명 고유값 대각화, 특이값 분해, 슈어 분해, LU 분해, LDU 분해 모두 유일성을 가지지 않는다는 공통점이 있다. 이 방법들은 모두 고유값과 고유벡터의 관계를 이용하거나 $1 = a \dfrac{1}{a}$ 이므로 $L$ 이나 $U$ 에 나눠줄 수 있기 때문이다. 하지만 콜레스키 분해는 고유값의 개념을 사용하지 않고 $A=LL^{T}$ 로 나타나므로 $1$을 둘로</description>
    </item>
    
    <item>
      <title>양의 정부호 행렬의 콜레스키 분해</title>
      <link>https://freshrimpsushi.github.io/posts/cholesky-decomposition/</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cholesky-decomposition/</guid>
      <description>개요 정칙행렬에서 대각행렬로 조건이 강화되면서 LDU 분해를 할 수 있었듯 양의 정부호 행렬로 조건이 강화되면 더욱 효율적인 행렬 분해인 콜레스키 분해Cholesky Decomposition를 할 수 있다. 빌드업 $m \times m$ 양의 정부호 행렬 $A : = \begin{bmatrix} a_{11} &amp;amp; \mathbb{w}^{T} \\ \mathbb{w} &amp;amp; K \end{bmatrix} &amp;gt; 0$을 생각해보면 $a_{11}$ 은 양수, $\mathbb{w} \in \mathbb{R}^{m-1}$ 이고 $K \in \mathbb{R}^{(m-1) \times (m-1)}$ 이다. 만약 $a_{11} \le 0$ 이면 $\mathbb{e}_{1} =</description>
    </item>
    
    <item>
      <title>대칭행렬의 LDU 분해</title>
      <link>https://freshrimpsushi.github.io/posts/ldu-decomposition-of-symmetric-matrix/</link>
      <pubDate>Fri, 29 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ldu-decomposition-of-symmetric-matrix/</guid>
      <description>개요 $L^{T}$ 는 상삼각행렬이므로 $A = LU$ 에서의 $U$ 를 $U:= DL^{T}$ 으로 바꾼다고 보면 된다. 일반적인 LU 분해보다 조건이 까다로워진만큼 계산량은 많이 줄어든다. 정리 가역대칭행렬 $A$ 에 대해 $A = LDL^{T}$ 를 만족하는 하삼각행렬 $L$ 과 대각행렬 $D$ 가 존재한다. 증명 $A$ 는 가역행렬이므로 $A = L U$ 를 만족하는 하삼각행렬 $L$ 과 상삼각행렬 $U$ 가 존재한다. 한편 $A = A^{T}$ 이므로 $$ L</description>
    </item>
    
    <item>
      <title>정칙행렬의 LU 분해</title>
      <link>https://freshrimpsushi.github.io/posts/lu-decomposition-of-nonsingular-matrix/</link>
      <pubDate>Thu, 28 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lu-decomposition-of-nonsingular-matrix/</guid>
      <description>빌드업 행렬 $A \in \mathbb{R}^{m \times m}$ 의 왼쪽에 곱해졌을 때 $(i, j)$ 성분을 $0$ 이 되도록 하는 행렬 $E_{ij}$ 를 $A$ 에 대한 $ij$-소거연산자라고 정의해보자. 구체적으로 정방행렬 $(a_{ij}) \in \mathbb{R}^{m \times m}$ 에 대한 $E_{ij}$ 는 대각성분이 $1$ 이고 $(i,j)$ 성분이 $\displaystyle -m_{ij} = -{{a_{ij}} \over {a_{jj}}}$, 나머지 성분이 $0$으로 구해진다. 이는 연립 방정식의 풀이에서 같은 변수끼리 계수를 맞춰서 소거하는 연산을 행렬로 나타낸 것이다</description>
    </item>
    
    <item>
      <title>스펙트럴 이론 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-spectral-theory/</link>
      <pubDate>Wed, 27 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-spectral-theory/</guid>
      <description>정리 정칙행렬 $A \in \mathbb{C}^{m \times m}$ 의 고유값 $\lambda_{i}$ 들로 구성된 대각행렬을 $\Lambda : = \text{diag} ( \lambda_{1} , \lambda_{2} , \cdots , \lambda_{m} )$, 그 고유값들에 해당하는 정규직교 고유벡터 $\mathbb{q}_{i}$ 들로 구성된 정규직교행렬을 $Q$ 라고 하면 $$ A = A^{\ast} \iff A = Q \Lambda Q^{\ast} $$ 설명 $A^{\ast} = \left( \overline{A} \right)^{T}$ 는 $A$ 에 복소켤레를 취한 행렬의 전치 행렬로, 에르미트 행렬이라 부른다. 스펙트럴 이론Spectral Theory은 다음과 같이</description>
    </item>
    
    <item>
      <title>정칙행렬의 슈어 분해</title>
      <link>https://freshrimpsushi.github.io/posts/schur-factorization-for-nonsingular-matrix/</link>
      <pubDate>Tue, 26 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schur-factorization-for-nonsingular-matrix/</guid>
      <description>정의 어떤 유니터리 행렬 $Q$ 와 상삼각행렬 $T$ 에 대해, $A = Q T Q^{\ast}$ 이면 $A$ 는 슈어 분해Schur Factorization를 갖는다고 한다. 정리 모든 정칙행렬 $A \in \mathbb{C}^{ m \times m}$ 는 슈어 분해를 갖는다. 설명 고유값 대각화의 단점은 $A = S \Lambda S^{-1}$ 로 분해되었을 때 어쨌든 $S^{-1}$ 을 구하는 수고가 필요하다는 것이다. 거듭제곱을 구하는 시간이 획기적으로 줄어드는 것</description>
    </item>
    
    <item>
      <title>전체 특이값 분해의 존재성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-existence-of-fsvd/</link>
      <pubDate>Sun, 24 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-existence-of-fsvd/</guid>
      <description>개요 고유값 대각화는 적용에 있어서 정방행렬이라는 제한이 있었지만 특이값 분해는 그러한 제약이 없었다. 이렇게 쓸만한 분해법이 모든 행렬에 통하는지, 즉 분해의 존재성을 밝히는 것은 상당히 중요한 문제라고 할 수 있다. 정리 세 자연수 $m \ge n \ge r = \text{rank} A$ 에 대해 행렬 $A \in \mathbb{R}^{m \times n}$ 는 fSVD를 갖는다. 증명 임의의 벡터 $\mathbb{x} \ne \mathbb{0}$ 에 대해 $\mathbb{x}^{T} A^{T} A \mathbb{x} = || A \mathbb{x} || ^2</description>
    </item>
    
    <item>
      <title>행렬의 특이값 분해</title>
      <link>https://freshrimpsushi.github.io/posts/singular-value-decomposition-svd/</link>
      <pubDate>Sat, 23 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/singular-value-decomposition-svd/</guid>
      <description>개요 늘 고유값 대각화를 통해 행렬을 쪼갤 수 있다면 좋겠지만, 이 방법엔 아쉽게도 주어지는 행렬이 정방행렬이어야한다는 제한이 있다. 이에 대각화할 행렬을 정방행렬이 아닌 경우로 확장해서 분해하려고 한다. 빌드업 두 자연수 $m &amp;gt; n$ 에 대해 행렬 $A \in \mathbb{C}^{ m \times n}$ 의 계수가 $\text{rank} A = n$ 으로 주어진다고 하자. 그러면 $\dim C(A) = \dim C(A^{T}) = n $ 으로, 이들의 정규직교벡터</description>
    </item>
    
    <item>
      <title>정칙행렬의 고유값 대각화</title>
      <link>https://freshrimpsushi.github.io/posts/diagonalization-of-nonsingular-matrix/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diagonalization-of-nonsingular-matrix/</guid>
      <description>정의 $A \in \mathbb{C}^{ m \times m }$ 에 대해 $A = Q^{ \ast } \Lambda Q$ 를 만족하는 유니타리 행렬 $Q$ 와 대각행렬 $\lambda$ 가 존재하면, 행렬 $A$ 는 유니터리 대각화 가능하다고 말한다. 정리 정칙행렬 $A \in \mathbb{R}^{m \times m}$ 의 일차독립인 고유벡터 $\mathbb{x}_{1}, \mathbb{x}_{2}, \cdots , \mathbb{x}_{m}$ 에 대해 $S = \begin{bmatrix} \mathbb{x}_{1}, \mathbb{x}_{2}, \cdots , \mathbb{x}_{m} \end{bmatrix}$ 라 하면 $$ S^{-1} A S = \begin{bmatrix} \lambda_{1} &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; \lambda_2 &amp;amp; \ddots &amp;amp; \vdots \\ \vdots &amp;amp; \ddots &amp;amp; \ddots &amp;amp; 0 \\ 0 &amp;amp; \cdots &amp;amp; 0 &amp;amp; \lambda_{m} \end{bmatrix} $$ 설명 가정에서 고</description>
    </item>
    
    <item>
      <title>조화진동자 연산자의 행렬 표현</title>
      <link>https://freshrimpsushi.github.io/posts/harmonic-oscillator-operator-matrix/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/harmonic-oscillator-operator-matrix/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 슈뢰딩거 방정식은 선형방정식이므로 방정식을 만족하는 여러 파동함수의 선형결합 역시 방정식을 만족한다.조화 진동자의 각 상태의 고유함수를 $|\psi_0&amp;gt;$, $|\psi_1&amp;gt;$, $\cdots$, $|\psi_n&amp;gt;$라 하면이 고유함수들의 선형결합인 $|\psi&amp;gt;=c_0|\psi_0&amp;gt; + c_1|\psi_1&amp;gt; + \cdots + c_n|\psi_n&amp;gt;$역시 슈뢰딩거 방정식의 해이다.</description>
    </item>
    
    <item>
      <title>양자역학의 여러 연산자의 행렬표현</title>
      <link>https://freshrimpsushi.github.io/posts/operator-matrices-in-quantum-physics/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operator-matrices-in-quantum-physics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 선형대수학을 배운 사람은 알겠지만 행렬도 벡터의 한 종류이다. 심지어 모든 벡터는 행렬로 표현할 수가 있다. 파동함수(고유함수)에 작용하는 연산자들 역시 행렬로 표현이 가능하다. (선형대수의 설명을 덧붙이자면 선형 연산자이기 때문에 행렬 변환이고 따라서 행렬로 표현이 가능하다) 따라서 양자</description>
    </item>
    
    <item>
      <title>연산자 방법으로 조화진동자 문제 풀기  일반화된 고유함수</title>
      <link>https://freshrimpsushi.github.io/posts/harmonic-oscillator-eigenfunction/</link>
      <pubDate>Sat, 16 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/harmonic-oscillator-eigenfunction/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 이전 글 : 연산자 방법으로 조화진동자 문제 풀기 : 에너지 준위와 바닥상태의 고유함수 이제 조화진동자의 사다리 연산자와 바닥상태의 고유함수로부터 일반화된 고유함수를 구해보자.사다리 연산자 $a_\pm$는 고유함수 $\psi_n$의 상태를 한 단계 올려주거나 내려준다.따라서 다음과 같</description>
    </item>
    
    <item>
      <title>연산자 방법으로 조화진동자 문제 풀기  에너지 준위와 바닥상태의 고유함수</title>
      <link>https://freshrimpsushi.github.io/posts/harmonic-oscillator-energy-level-ground-state/</link>
      <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/harmonic-oscillator-energy-level-ground-state/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 이전 글 : 연산자 방법으로 조화진동자 문제 풀기 : 사다리 연산자 적용계속해서 조화진동자의 에너지와 바닥상태의 고유함수를 구해보자.$E=&amp;lt;\psi|H|\psi&amp;gt;=&amp;lt;\psi|(a_+a_-+\dfrac{1}{2})\hbar w|\psi&amp;gt;$</description>
    </item>
    
    <item>
      <title>발산하는 반원 상의 복소경로적분을 통한 유리함수의 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/improper-integration-using-contour-integration-on-half-circle/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/improper-integration-using-contour-integration-on-half-circle/</guid>
      <description>빌드업 두 다항함수 $p(z) , q(z)$ 에 대해 $\displaystyle f(z) = {{q(z)} \over {p(z)}}$ 이라고 하자. $q(z) = 0$ 을 만족하는 실수해가 존재하지 않으면 $f$ 는 실수 특이점을 갖지 않을 것이다. 이러한 유리함수의 이상적분 $\displaystyle \int_{-\infty}^{\infty} f(z) dz$ 이 존재하는 조건은 $\displaystyle f(z) \sim {{1} \over {z^{p}}}$ 에서 $p &amp;gt; 1$ 이다. 무한급수의 개념으로 생각해보자면 $\displaystyle \sum_{n=0}^{\infty} {{{1} \over {n^{p}}} }$ 가 수렴하는 필요충분조건이 $p&amp;gt;1$ 인 것과 관련지어볼 수 있겠다. 이 조건을</description>
    </item>
    
    <item>
      <title>연산자 방법으로 조화진동자 문제 풀기  사다리 연산자 적용</title>
      <link>https://freshrimpsushi.github.io/posts/harmonic-oscillator-ladder-operator/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/harmonic-oscillator-ladder-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 이전 글 : 연산자 방법으로 조화진동자 문제 풀기 : 사다리 연산자의 정의이제 사다리 연산자가 조화진동자의 고유함수에 어떻게 작용하는지 알아보자.참고로 임의의 상수와 임의의 연산자간의 교환자는 항상 $0$이다.아래의 수식 전개에서 사용한 관계식 $( [AB,C]=A[B,C]+[A,C]B,\ \ [a_-,a_+]=1 ) $$ H=(a_+a_-+\dfrac{1}{2})\hbar w$이므로, $ \begin{align*} [H,a_+] &amp;amp;= [(a_+a_-+\dfrac{1}{2})\hbar w,a_+] \\</description>
    </item>
    
    <item>
      <title>연산자 방법으로 조화진동자 문제 풀기  사다리 연산자의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/harmonic-oscillator-ladder-operator/</link>
      <pubDate>Wed, 13 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/harmonic-oscillator-ladder-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 조화진동자 문제를 연산자 방법으로 풀 때 아주 유용한 연산자가 있다.바로 조화진동자의 사다리연산자$\mathrm{Ladder\ Operator}$이다.에너지 연산자인 해밀토니안$H$과도 치환이 가능하고,사다리 연산자의 특징을 이용해 바닥상태부터의 고유함수도 구할 수 있다</description>
    </item>
    
    <item>
      <title>무한 포텐셜 우물에서의 에너지 준위</title>
      <link>https://freshrimpsushi.github.io/posts/energy-level-in-infinite-potential-wells/</link>
      <pubDate>Tue, 12 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/energy-level-in-infinite-potential-wells/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 무한 포텐셜 우물에서의 파동함수(고유함수)와 에너지(고유값)을 구하는 것은 여기를 참고하자.자 이제 결과만 가져와서 이게 어떤 의미를 가지는지 살펴보자. 고유함수 $\displaystyle \psi_{(x)} =\sqrt{\frac{2}{a}}\sin \frac{n\pi}{a}x$고유값 $\displaystyle E_n=\frac{n^2\pi^2\hbar^2}{2ma^2}$ 무한 포텐셜 우물의 파동함수에 대해서운동량의 기댓값은 $0$이지만</description>
    </item>
    
    <item>
      <title>양자역학에서 축퇴란</title>
      <link>https://freshrimpsushi.github.io/posts/degeneracy/</link>
      <pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/degeneracy/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **** 축퇴$(\mathrm{Degeneracy})$ 축퇴란 서로 다른1 두 파동함수가 같은 고유값을 가지는 것을 말한다. 다시 말하자면 두 파동함수가 축퇴되어 있다는 것은 두 파동함수의 에너지가 같다는 것이다. 그리피스 교재에서는 겹침, 겹친 상태라고 한다. 역자에 따르면 1995년 한국</description>
    </item>
    
    <item>
      <title>에너지가 포텐셜보다 작을 때 시간에 무관한 슈뢰딩거 방정식의 해가 없음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/there-is-no-solution-when-the-energy-is-less-than-potential/</link>
      <pubDate>Wed, 06 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/there-is-no-solution-when-the-energy-is-less-than-potential/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 시간에 무관한 슈뢰딩거 방정식의 해를 찾을 때 에너지가 포텐셜보다 작은 구간에서는 해가 없다.즉, 파동함수가 존재하지 않는다.이는 파동함수라면 규격화가능해야 한다는 조건으로 증명할 수 있다.규격화 가능하다는 말은 제곱적분가능$\mathrm{Square\ Integrable}</description>
    </item>
    
    <item>
      <title>각운동량에서 고유함수와 사다리 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/ladder-operator-of-angular-momentum/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ladder-operator-of-angular-momentum/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\mathbf{L}^2$과 $L_{z}$의 동시 고유함수 $|l,m&amp;gt;$은 아래의 고유값 방정식을 만족한다.$\mathbf{L}^2 |l,m&amp;gt; = l(l+1)\hbar ^2 |l,m&amp;gt; $$ L_{z} |l,m&amp;gt; = m\hbar |l,m&amp;gt;$ 동시고유함수에 대한 표기는 책마다 다를 수 있다.가시오로비츠$\mathrm{gasiorowicz}</description>
    </item>
    
    <item>
      <title>임의의 두 연산자 에이 비가 허미션 연산자일 때 에이비가 허미션 연산자일 조건</title>
      <link>https://freshrimpsushi.github.io/posts/condition-which-product-of-two-hermitian-is-hermitian/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/condition-which-product-of-two-hermitian-is-hermitian/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 두 허미션 연산자 $A,B$가 교환 관계$\mathrm{Commute}$이면 $AB$도 허미션 연산자$\mathrm{Hermitian\ Operator}$이다.참고로 역도 성립한다. 증명 $AB$가 허미션 연산자임을 보이려면 $(AB)^\dagger=AB$임</description>
    </item>
    
    <item>
      <title>각운동량의 사다리연산자올림연산자 내림연산자</title>
      <link>https://freshrimpsushi.github.io/posts/angular-momentum-ladder-operator-raising-operator-lowering-operator/</link>
      <pubDate>Sun, 26 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/angular-momentum-ladder-operator-raising-operator-lowering-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 각운동량을 다룰 때 유용하게 쓰이는 두 연산자를 소개한다. $1.$ 올림 연산자$\mathrm{Raising\ Operator}$ $L_+ \equiv L_{x} + iL_{y} $$ 2.$ 내림 연산자$\mathrm{lowering\ Operator}$ $L_- \equiv L_{x} - iL_{y}$즉, $(L_-)^{\ast}=L_+$ 이 두 연산자의 이름이 &amp;lsquo;올림&amp;rsquo;, &amp;lsquo;</description>
    </item>
    
    <item>
      <title>복소평면 상에서의 삼각함수 치환을 통한 정적분</title>
      <link>https://freshrimpsushi.github.io/posts/integration-on-complex-plane-by-trigonometric-substitution/</link>
      <pubDate>Sun, 26 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integration-on-complex-plane-by-trigonometric-substitution/</guid>
      <description>정리 $$ \int_{0}^{2 \pi} f( \cos \theta , \sin \theta ) d \theta = \int_{\mathscr{C}} f(z) dz = 2 \pi i \sum \text{Res} f(z) $$ 설명 정적분을 구하기 힘든 실함수는 복소해석으로의 우회를 통해 비교적 쉽게 풀어낼 수 있다. 그 중에서도 삼각함수들로 이루어진 피적분함수에 대한 적분 테크닉을 알아보자. 기본적인 전략은 적분 범위를 $z(\theta) = e^{ i \theta} , 0 &amp;lt; \theta &amp;lt; 2 \pi$ 로 바꿔 필요한 부분을 취하는 것이다. 물론 필요하다면 약간의 조</description>
    </item>
    
    <item>
      <title>엘제곱과 엘제트의 동시 고유함수에 대한 고유값</title>
      <link>https://freshrimpsushi.github.io/posts/eigenvalue-of-l2-lz/</link>
      <pubDate>Sun, 26 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eigenvalue-of-l2-lz/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\mathbf L^2$과 $L_{z}$의 동시 고유함수 $|l,m&amp;gt;$에 대해여 고유값 방정식은 다음과 같다.$\mathbf L ^2 |l,m&amp;gt; = l(l+1)\hbar^2|l,m&amp;gt; $$ L_{z}|l,m&amp;gt;=m\hbar|l,m&amp;gt;$이 때, $l=0, \frac{1}{2}, 1, \frac{3}{2}, 2, \cdots $$ m= -l, -l+1, -l+2, \cdots , l-2, l-1, l$ ※글이 길지만 최대한 자세히 설명했으니 천</description>
    </item>
    
    <item>
      <title>R 에서 데이터 프레임의 행과 열의 위치 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-swap-row-and-column-in-r/</link>
      <pubDate>Sat, 25 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-swap-row-and-column-in-r/</guid>
      <description>개요 R 의 강점 중 하나는 프로그래밍 언어가 익숙한 사람의 입장에서 상당히 어려운 조작들을 손쉽게 구현시켜준다는 것이다. 예컨대 배열을 사용할 때 미리 메모리를 할당 시키지 않아도 스스로 확장이 되는가하면, 변수의 값을 바꾸는 등의 조작이 아주 쉽다. 예시 아이리스 데이터셋에서 Sepal.Width 열과 Species 열을 바꿔보자. 방법은 너무나 간단하다. 2번째 열에 5번째 열을</description>
    </item>
    
    <item>
      <title>R 에서 내장 데이터셋 불러오는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-load-built-in-dataset-in-r/</link>
      <pubDate>Fri, 24 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-load-built-in-dataset-in-r/</guid>
      <description>개요 R 은 대표적인 통계 프로그래밍 언어로써 유용한 메소드 뿐만 아니라 예제로 쓰기 좋은 데이터셋도 제공한다. 만약 이런 데이터셋이 없다면 강의를 할 때마다 새로운 데이터를 다운로드하고 불러들어들이는 짓을 해야할 것이다. 가이드 데이터셋을 불러오는 방법은 아주 간단하다. 불러올 데이터셋의 이름을 우리가 사용할 변수에 할당하기만 하면 된다. 통계학</description>
    </item>
    
    <item>
      <title>고유값의 대수적 중복도는 기하적 중복도보다 크거나 같다</title>
      <link>https://freshrimpsushi.github.io/posts/the-algebraic-multiplicity-of-eigenvalues-is-greater-than-or-equal-to-the-geometric-multiplicity/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-algebraic-multiplicity-of-eigenvalues-is-greater-than-or-equal-to-the-geometric-multiplicity/</guid>
      <description>정리 행렬 $A \in \mathbb{C}^{ m \times m}$ 의 고유값 $\lambda$ 가 대수적 중복도 $a$ 를 갖고 기하적 중복도 $g$ 를 갖는다고 하면 $a \ge g$ 이다. 설명 고유값의 대수적 중복도와 기하적 중복도는 서로 같다는 보장이 없다. 만약 같았다면 애초에 다르게 정의하지도 않았을 것이다. 다만 한가지 확신할 수 있는 것은 대수적 중복도가 아무리 작아도 기하적 중복도보다는 크거나 같다는 사실이다. 증명 표</description>
    </item>
    
    <item>
      <title>행렬의 닮음과 고유값</title>
      <link>https://freshrimpsushi.github.io/posts/two-similar-matrices-have-same-eigenvalue/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/two-similar-matrices-have-same-eigenvalue/</guid>
      <description>정의 두 가역행렬 $A$ 와 $B$ 에 대해 $$ A = P^{-1} B P $$ 를 만족하는 가역행렬 $P$ 가 존재하면 $A$ 와 $B$ 는 서로 닮았다고 한다. 켤레 위에서 주어진 식을 $B$ 에 대해서 나타내면 $$ B = P^{-1} A P $$ 이므로 닮음 관계가 대칭적임을 쉽게 알 수 있다. 대수적으로는 $A$ 와 $B$ 가 $P$ 에 대한 켤레conjugate라고 말할 수 있겠다. 정리 두 행렬 $A,B$ 가 닮음이면 다음이 성립한다. $$ \det (A</description>
    </item>
    
    <item>
      <title>고유값의 대수적 중복도와 기하적 중복도</title>
      <link>https://freshrimpsushi.github.io/posts/multiplicity-of-eigen-value/</link>
      <pubDate>Sun, 19 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplicity-of-eigen-value/</guid>
      <description>대수적 중복도 행렬 $A \in \mathbb{R}^{m \times m}$ 에 대해 고유값은 $\det (A - \lambda I ) =0$ 을 만족하는 $\lambda$ 로 정의된다. 특성방정식은 $\lambda$ 에 대한 $m$ 차 방정식, 즉 $$ \det (A - \lambda I ) = (-1)^m \lambda ^m + c_{m-1} \lambda ^{m-1} + \cdots + c_{1} \lambda + c_{0} = 0 $$ 으로 나타낼 수 있다. 대수학의 기본정리에 의해, 특성방정식은 복소수를 포함하여 정확히 $m$ 개의 근을 갖는다. 여기서 근은 중근을 포함하는데, 중근을 갖는다는 것</description>
    </item>
    
    <item>
      <title>임의의 연산자에 대해서 항상 허미션 연산자인 모양</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-hermitian/</link>
      <pubDate>Sun, 19 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-hermitian/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 임의의 연산자 $A$에 대해서 아래의 꼴은 항상 허미션 연산자이다.$(1)\ A+A^\dagger $$ (2)\ i(A-A^\dagger) $$ (3)\ AA^\dagger$ 원래의 식에 대거$^\dagger$를 취해도 원래의 모양임을 보이면 증명 끝. 증명$(1)$ $(A+A^\dagger)^\dagger=A^\dagger+{(A^\dagger)}^\dagger=A^\dagger+A=A+A^\dagger$ ■ 증명$(2)$ $[i(A-A^\dagger) ]^\dagger=-i\left[ A^\dagger-{(A^\dagger)}^\dagger \right]=-i(A^\dagger-A)=i(A-A^\dagger)$ ■ 증명$(3)$ $(AA^\dagger)^\dagger={(A^\dagger)}^\dagger A^\dagger=AA^\dagger$ ■</description>
    </item>
    
    <item>
      <title>단순극에서의 유수</title>
      <link>https://freshrimpsushi.github.io/posts/the-residue-at-a-simple-pole/</link>
      <pubDate>Sat, 18 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-residue-at-a-simple-pole/</guid>
      <description>정리 1 함수 $f$ 를 $\displaystyle f(z) = {{g(z)} \over {h(z)}}$ 으로 나타낼 수 있다고 하자. 여기서 $g$ 와 $h$ 는 $\alpha$ 에서 해석적이고, $g(\alpha) \ne 0 , h(\alpha) = 0, h&#39;(\alpha) \ne 0$ 라고 하면 $\alpha$ 는 $f$ 의 단순 극이고 $$ \text{Res}_{\alpha} f(z) = {{g(\alpha)} \over {h&#39;(\alpha)}} $$ 딱히 $\displaystyle f(z) = {{g(z)} \over {h(z)}}$ 꼴에서 $h$ 가 다항함수여야하는 건 아니기 때문에 그저 극에서의 유수를 $m=1$ 에 한정시킨 정리라곤 할 수 없다. 조건만 잘 만족한다면 오히려 더 많은 종류의 함수 $h$ 를 커버할 수</description>
    </item>
    
    <item>
      <title>두 에르미트 연산자의 곱이 에르미트 연산자일 조건</title>
      <link>https://freshrimpsushi.github.io/posts/hermitian-operator-commute/</link>
      <pubDate>Sat, 18 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermitian-operator-commute/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 임의의 두 연산자 $A,B$가 에르미트(허미션) 연산자일 때 두 연산자의 곱 $AB$가 에르미트 연산자일 조건은 $[A,B]=0$이다. 즉, 두 연산자가 에르미트 연산자일 때 교환 관계이면 두 연산자의 곱도 에르미트 연산자이다. 증명 $\begin{align*} (AB)^\dagger &amp;amp;= B^\dagger A^\dagger \\ &amp;amp;= BA \ \ (A, B\text{가 에르미트 연산</description>
    </item>
    
    <item>
      <title>극점에서의 유수</title>
      <link>https://freshrimpsushi.github.io/posts/the-residue-at-a-pole/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-residue-at-a-pole/</guid>
      <description>정리 1 $\alpha$ 가 함수 $f: A \subset \mathbb{C} \to \mathbb{C}$ 의 pole of order $m$, 즉 $\displaystyle f(z) = {{g(z)} \over { (z - \alpha)^m }}$ 으로 나타낼 수 있다고 하자. 여기서 $g$ 는 $\alpha$ 에서 해석적이며 $g(\alpha) \ne 0$ 이라고 하면 $$ \text{Res}_{\alpha} f(z) = {{g^{(m-1)} (\alpha)} \over {(m-1)!} } $$ 유수정리를 통해 적분 문제를 유수를 구하는 문제로 바꿀 수 있는 것까진 좋은데, 유수를 구하는 게 적분만큼 어렵다면 소용 없는 일이다. 유수정리를 쓸 때마다 정의에 따라서 로랑 전개를 하고</description>
    </item>
    
    <item>
      <title>아이의 거듭 제곱을 이의 거듭 제곱으로 표현하기</title>
      <link>https://freshrimpsushi.github.io/posts/il/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/il/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 자연상수 $e$와 허수 $i$의 거듭제곱은 다음과 같은 관계를 만족한다. $$ e^{ i \frac{l \pi}{2}}=i^l $$ 증명 $e^{ i \frac{l \pi}{2}}=\cos\frac{l \pi}{2}+i\sin \frac{l \pi}{2}$이므로$l=0$일 때, $$ e^{ 0}= 1 =i^{0} $$ $l=1$일 때, $$ e^{ i \frac{\pi}{2}}=\cos\frac{\pi}{2}+i\sin \frac{\pi}{2}=i=i^{1} $$ $l=2$일 때, $$ e^{ i \pi}=\cos \pi+i\sin \pi=-1=i^{2} $$ $l=3$일 때, $$ e^{ i \frac{3\pi}{2}}=\cos\frac{3\pi}{2}+i\sin \frac{3\pi}{2}=-i=i^{3} $$ 이후 반복되므로 $$ e^{ i \frac{l \pi}{2}}=i^l $$</description>
    </item>
    
    <item>
      <title>R 에서 행렬의 곱 역행렬 전치행렬 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/matrix-product-inverse-matrix-transpose-matrix/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/matrix-product-inverse-matrix-transpose-matrix/</guid>
      <description>개요 R 의 강점은 행렬을 위시한 각종 데이터셋의 조작이 간편하다는 점과 풍부한 통계 패키지를 무료로 제공한다는 것이다. 당연한 이야기지만 통계적 분석에서 행렬의 계산은 매우 중요하고, R 은 이러한 니즈를 훌륭하게 충족시켜준다. 매트랩이나 줄리아가 아닌 이상 다른 언어에선 행렬의 연산부터 귀찮게 따로 정의를 해줘야 할 것이다. 코드 행렬의 곱 예로써 행</description>
    </item>
    
    <item>
      <title>R 에서 몫과 나머지 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/quotient-and-remainder-in-r/</link>
      <pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quotient-and-remainder-in-r/</guid>
      <description>개요 프로그래밍 언어의 문법에서 정말 통일이 안 되는 게 바로 몫과 나머지 연산자다. 기본적으론 다 비슷비슷하게 생긴 것 같지만 오히려 그래서 헷갈리는데 한 몫한다.C는 몫을 /, 나머지를 %으로 쓰고 파이썬은 몫을 //, 나머지를 % 으로 쓰며, 이렇게 헷갈리는 예는 얼마든지 더 들 수 있다. 도대체 통계와 행렬 계산에 초점을 맞춘 R 에서 몫과 나머지를 구할 일이 어디</description>
    </item>
    
    <item>
      <title>임의의 두 연산자가 교환 관계일 조건</title>
      <link>https://freshrimpsushi.github.io/posts/operator-commute/</link>
      <pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operator-commute/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 임의의 서로 다른 두 연산자의 공통의 고유함수가 존재하면 두 연산자는 교환 가능하다.즉, $\begin{cases} A\psi=a\psi \\ B\psi=b\psi \end{cases}$ 이면 $[A,B]=0$이 때 고유함수는 규격화된 고유함수이다. 증명 $\begin{align*} AB\psi=Ab\psi=bA\psi=ba\psi &amp;amp;= ab\psi \\ &amp;amp;= aB\psi \\ &amp;amp;= Ba\psi \\ &amp;amp;= BA\psi \end{align*} $$ \implies AB\psi-BA\psi=(AB-BA)\psi=0$ 이므로 $[A,B]=0$</description>
    </item>
    
    <item>
      <title>R 에서 모든 변수 제거하기 콘솔창 초기화</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-clear-console-and-remove-all-variable-in-r/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-clear-console-and-remove-all-variable-in-r/</guid>
      <description>개요 R 은 인터프리터 언어기 때문에 콘솔을 계속 보며 작업을 하게 된다. 이때 디버그 등을 하기 위해서는 이런 저런 테스트도 같은 작업환경에서 할 수밖에 없는데, 테스트 중간에 생성된 특정 변수가 아주 중요한데 프로그래머가 알아채지 못하고 완성본엔 포함시키지 않는 등의 일이 있을 수 있다. 어제 집에서 할 땐 분명히 돌아갔는데 오늘 발표 때 갑자기 안 돌아가는 등</description>
    </item>
    
    <item>
      <title>허미션 연산자의 여러가지 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-hermitian-operator/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-hermitian-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 허미션 연산자의 여러가지 성질을 한데 모아 정리했다.증명은 각 링크를 참고하길 바람.**$0.$ 허미션 연산자란? **$1.$ 허미션 연산자의 기댓값(고유값)은 항상 실수이다. ** **$2.$ 허미션 연산자의 서로 다른 두 고유함수(고유벡터)는 직교한다. ** $3.$ 허미션 연산자 $A$에 대해서 다음의 식이 성립</description>
    </item>
    
    <item>
      <title>R 에서 else if문 사용하기 Error: unexpected else in else 해결</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-fix-error-unexpected-else-in-else-in-r/</link>
      <pubDate>Sun, 12 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-fix-error-unexpected-else-in-else-in-r/</guid>
      <description>개요 R 에는 switch문과 같은 분기문이 없기 때문에 if문을 여러개 이어서 분기를 나누어야만 한다. 여기서 이 조건문이라는 게 프로그래밍 언어마다 if 와 else는 다 똑같은데 유독 else if 만 다를 수가 있다. elseif로 붙여쓰거나 아예 elif 처럼 줄여쓰는 경우가 그 예고, R은 제대로 띄어쓰기가 들어간 else if 를 사용한다. 여러가지 프로그래밍 언어를</description>
    </item>
    
    <item>
      <title>허미션 연산자의 서로 다른 두 고유함수는 직교함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/the-two-different-eigenfunctions-of-the-mission-operator-are-orthogonal/</link>
      <pubDate>Sun, 12 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-two-different-eigenfunctions-of-the-mission-operator-are-orthogonal/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 선형대수학에서의 증명 임의의 허미션 연산자$(\mathrm{Hermitian\ Operator})$ $A$의 서로 다른 두 고유함수(고유벡터)는 서로 수직이다.$\begin{cases} A\psi_n=a_n\psi_n \\ A\psi_m=a_m\psi_m \end{cases} $ 일 때, $&amp;lt;\psi_n|\psi_m&amp;gt;=0$ 혹은 $\psi_n \perp \psi_m$ 증명 $&amp;lt;\psi_n|A\psi_m&amp;gt;=a_m&amp;lt;\psi_n|\psi_m&amp;gt; $$ &amp;lt;A\psi_n|\psi_m&amp;gt;={a_n}^{\ast}&amp;lt;\psi_n|\psi_m&amp;gt;=a_n&amp;lt;\psi_n|\psi_m&amp;gt;$ (허미션 연산자의 고유값은 항상 실수)또한 $A$는 허미션 연</description>
    </item>
    
    <item>
      <title>고유값 방정식을 푸는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/eigenvalue-problem/</link>
      <pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eigenvalue-problem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 물리학에서 고유값 문제를 배우는 이유 $n\times n$ 행렬 $A$가 주어졌다고 하자. $$ A\mathbf{x}=\lambda \mathbf{x} \tag{1} $$ 행렬 $A$에 대해서 위의 식을 만족하는 $n\times 1$ 행렬 $\mathbf{x}$와 상수 $\lambda$를 찾는 것을 고유값 문제라고 한다. 이러한 행렬 $\mathbf{x}$를 $A$의 고유함수라하고 $</description>
    </item>
    
    <item>
      <title>추상대수학에서의 가환군</title>
      <link>https://freshrimpsushi.github.io/posts/abelian-group/</link>
      <pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abelian-group/</guid>
      <description>정의 1 군 $\left&amp;lt; G, \ast\ \right&amp;gt;$ 의 두 원소 $a, b$ 에 대해 $a \ast\ b = b \ast\ a$ 면 $\left&amp;lt; G, \ast\ \right&amp;gt;$를 가환군Abelian Group이라 정의한다. 설명 가환은 &amp;lsquo;교환법칙이 성립하는&amp;rsquo; 정도의 의미로 받아들이면 좋다. 영칭의 경우 Commutative 대신 Abelian 이라는 말이 붙는데, 이는 천재수학자 아벨에서 따온 말이다. 물론 한칭으로 아벨군이라</description>
    </item>
    
    <item>
      <title>유수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-residue-theorem/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-residue-theorem/</guid>
      <description>정리 1 해석적인 함수 $f: A \subset \mathbb{C} \to \mathbb{C}$ 가 단순폐경로 $\mathscr{C}$ 내부의 유한한 특이점 $z_{1} , z_{2} , \cdots , z_{m}$ 들을 가진다고 하자. 그러면 $$ \int_{\mathscr{C}} f(z) dz = 2 \pi i \sum_{k=1}^{m} \text{Res}_{z_{k}} f(z) $$ 설명 처음 읽어보면 아리송하기짝이 없는 정리다. 적분 값을 구해야하는데 미적분학스러운 계산은 없고 웬 특이점과 유수 이야기를 하고 있으니 그럴만도 하다. 정리만 보자면 유수를 구해서 더하는 것만으로 적분값</description>
    </item>
    
    <item>
      <title>허미션 연산자의 기댓값고유값은 항상 실수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/hermitian-operator-expectation-value/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermitian-operator-expectation-value/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 선형대수학에서의 증명 보기 허미션 연산자$\mathrm{Hermitian\ Operator}$의 기댓값(고유값$\mathrm{Eigenvlaue}$)은 항상 실수$(\mathrm{real\ number})$이다. 증명 $A$를 허미션 행렬이라고 하자.$</description>
    </item>
    
    <item>
      <title>허미션 허미션 행렬 허미션 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/hermitian-matrix-operator/</link>
      <pubDate>Thu, 09 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermitian-matrix-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 임의의 행렬 $A$가 있을 때 $A ^\dagger$를 $A$의 $\mathrm{Hermitian}$(허미션)이라고 한다.$\dagger$는 대거라고 읽고 $A ^\dagger$는 &amp;ldquo;에이 대거&amp;quot;라고 읽는다.단검모양처럼 생겼다해서 대거dagger</description>
    </item>
    
    <item>
      <title>디랙 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/dirac-notaion/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirac-notaion/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **** **이 글을 이해하려면 양자역학을 위해 새로 배우는 벡터와 내적을 알아야한다. **디랙 표기법$(\mathrm{Dirac\ notation})$ 양자역학에서 연산자와 파동함수(고유함수)를 편리하게 연산하기 위해서 사용하는 하나의 표기법이다. 벡터를 꺾쇠괄호를 사용하여 나타낸다. 열벡터$(\</description>
    </item>
    
    <item>
      <title>벡터공간의 차원</title>
      <link>https://freshrimpsushi.github.io/posts/dimension-of-vector-space/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dimension-of-vector-space/</guid>
      <description>정의1 벡터공간 $V$의 기저의 벡터 개수를 $V$의 차원dimension이라고 정의하고 다음과 같이 표기한다. $$ \dim (V) $$ 설명 이러한 차원의 일반화는 단순히 벡터공간에 대한 탐구를 넘어서서 이 사회를 떠받치는 여러가지 기술에 접목되고 있다. 세상이 $3$차원이고 그림으로도 못 그리는 $4$차원이 무슨 소용인가 싶겠지만 딱히 유클리드공간만</description>
    </item>
    
    <item>
      <title>로랑 급수의 주부분과 특이점의 분류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-among-principal-part-and-singular-point-of-laurent-expansion/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-among-principal-part-and-singular-point-of-laurent-expansion/</guid>
      <description>개요 1 로랑 전개의 principal part를 잘 살펴보면 특이점의 종류를 파악할 수 있다. $\alpha$ 를 함수 $f:A\subset \mathbb{C} \to \mathbb{C}$ 의 고립된 특이점이라 하자. 이의 로랑 전개 $$ f(z) = \sum_{n = 0 }^{\infty} a_{n} (z-\alpha) ^{n} + \sum_{n = 1 }^{\infty} { {b_{n} } \over{ (z-\alpha) ^{n} } } $$ 에 대해, 수열 $b_{n}$ 은 아래의 성질들을 가진다. 정리 [1]: 모든 $n$ 에 대해 $b_{n}=0$ $ \iff$ $\alpha$ 는 제거가능한 특이점이다. [2]: 어떤 $m$ 에 대해 $b_{m} \ne 0$ 이고 $b_{m+1} = b_{m+2} = \cdots = 0$ $\iff$ $\alpha$ 는 $</description>
    </item>
    
    <item>
      <title>양자역학에서 연산자란</title>
      <link>https://freshrimpsushi.github.io/posts/operator-in-quantum-mechanics/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operator-in-quantum-mechanics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 함수해석학에서의 작용소양자역학에서 연산자란 쉽게 말해서 파동 함수에 대해서 원하는 값을 얻기 위해 파동 함수에 어떠한 계산을 하는 것을 말한다. 예를 들어 파동 함수의 에너지를 구하는 계산을 에너지 연산자라고 부른다. 마찬가지로 파동 함수의 운동량을 구하는 계산을 에너지 연산자라고 부른다.주어</description>
    </item>
    
    <item>
      <title>각운동량 연산자의 제곱과 각운동량 연산자의 각 성분의 교환 관계가 0임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-commutative-relation-between-elements-of-angular-momentum/</link>
      <pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-commutative-relation-between-elements-of-angular-momentum/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $L^2$과 $L_{z}$는 서로 교환 가능하다 $$ [L^2, L_{z}]=0 $$ ※ $[A,B]=0$이면 $A$와 $B$는 교환 관계(commutation relation) 가 $0$이다, 증명 $$ \begin{align*} [L^2, L_{z}] &amp;amp;= [{L_{x}}^2 + {L_{y}}^2 + {L_{z}}^2, L_{z}] \\ &amp;amp;= [{L_{x}}^2,L_{z}] + [{L_{y}}^2, L_{z}] +[{L_{z}^2}, L_{z}] \\ &amp;amp;= L_{x}[L_{x}, L_{z}] + [L_{x}, L_{z}]L_{x} + L_{y}[L_{y}, L_{z}] + [L_{y}, L_{z}]L_{y} \\ &amp;amp;= (-i\hbar L_{x}L_{y}) + (-i\hbar L_{y}L_{x}) + i\hbar L_{y}L_{z} + i\hbar L_{x}L_{y} \\ &amp;amp;= 0 \ \ \end{align*} $$ 비슷한</description>
    </item>
    
    <item>
      <title>로랑 급수란?</title>
      <link>https://freshrimpsushi.github.io/posts/laurent-series/</link>
      <pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laurent-series/</guid>
      <description>빌드업 테일러 정리는 평균값의 정리를 미분 횟수에 대해 일반화한 정리다. 원래 $1$번 미분한 것만을 다루던 것에서 $n \in \mathbb{N}$ 으로 확장한 것이다. 그런데 자연수로 일반화가 가능했다면, 정수 전체로 일반화할 수는 없는껄까? 물론 미분을 $-n$ 번 할 수는 없지만, 미분과 역연산 관계에 있는 적분을 생각해면 어떨까? 아래의 로랑 정리를 증명 없이 소개한다. $f: A \subset</description>
    </item>
    
    <item>
      <title>곡선좌표계에서의 그래디언트 다이벌전스 컬 라플라시안</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-divergence-curl-and-laplacian-in-a-curved-coordinates-system/</link>
      <pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-divergence-curl-and-laplacian-in-a-curved-coordinates-system/</guid>
      <description>설명 물리학에서 델 연산자 $\nabla$가 포함된 4가지 연산 그래디언트(기울기), 다이벌전스(발산), 컬(회전), 라플라시안은 매우 중요하다. 따라서 3가지 좌표계에 대한 위 연산을 반드시 알아야한다. 물론 이 말은 외워야한다는 뜻이 아니다. 물리학 공부는 이런 식을 외우는 것이 아니기 때문이다. 공부하다 보면 자연스레 외워질 것이므로</description>
    </item>
    
    <item>
      <title>각운동량 연산자의 각 성분끼리의 교환 관계 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/commutative-relation-between-elements-of-angular-momentum/</link>
      <pubDate>Sat, 04 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/commutative-relation-between-elements-of-angular-momentum/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 각운동량 연산자의 교환 관계 $\left[L_j,\ L_k \right]=i\hbar \epsilon_{jkm}L_m$ 각운동량은 물체(입자)의 위치와 운동량의 외적으로 정의한다.$\vec L = \vec r \times \vec p$각운동량 연산자의 교환자 관계를 구하는 것은 각운동량의 정의로부터 시작된다.$\vec L = \vec r \times \vec p = (yp_{z}-zp_{y})\mathbf{\hat{\mathbf{x}}}+(zp_{x}-xp_{z})\mathbf{\hat{\mathbf{y}}} + (xp_{y}-yp_{x})\mathbf{\hat{\mathbf{z}}} $$ \vec L = L_{x}\mathbf{\hat{\mathbf{x}}}+L_{y}\mathbf{\hat{\mathbf{y}}} + L_{z}\mathbf{\hat{\mathbf{z}}} $$ \therefore L_{x}=yp_{z}-zp_{y},\ L_{y}=zp_{x}-xp_{z}, \ L_{z}=xp</description>
    </item>
    
    <item>
      <title>복소해석에서 특이점의 종류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-singular-point/</link>
      <pubDate>Sat, 04 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-singular-point/</guid>
      <description>정의 특이점 1 함수 $f$ 가 $\alpha$ 에서 어떤 $\mathcal{N}(\alpha)$ 의 모든 점에서 미분가능하면 $\alpha$ 에서 해석적Analytic이라고 한다. 함수 $f$ 가 $\alpha \in \mathbb{C}$ 에서는 해석적이지는 않지만 모든 $\mathcal{N}(\alpha)$ 의 어떤 점에서는 해석적일 때 $\alpha$ 를 $f$ 의 특이점Singular Point이라고 부른다. 특이점 $\alpha$ 이 $\alpha$ 를 제외한 모든 점에서 해석적인 $\mathcal{N}(\alpha)$ 가 존재하면 $\alpha$ 가 고립Isolated되어있다</description>
    </item>
    
    <item>
      <title>교환자의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-commutator/</link>
      <pubDate>Fri, 03 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-commutator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 교환자 $A,\ B$는 아래와 같이 정의한다.$[A,B]=AB-BA$ 교환자의 중요 성질 $$ \leqalignno{ [A, A]&amp;amp;=0 &amp;amp;(a) \\ [A, B]&amp;amp;=-[B, A] &amp;amp;(b) \\ [A+B, C]&amp;amp;=[A, C] + [B, C] &amp;amp;(c) \\ [AB, C]&amp;amp;=A[B, C]+[A, C]B &amp;amp;(d) \\ [A,BC] &amp;amp;=B[A,C]+ [A,B]C &amp;amp;(e) } $$ 양자역학을 기술하는 주된 방법이 행렬이다. 그런데 행렬은 곱셈에 대해서 교환법칙이 성립하지 않는다. 그래서 $A,\ B$라는 연산자(행렬</description>
    </item>
    
    <item>
      <title>선형 독립과 선형 종속</title>
      <link>https://freshrimpsushi.github.io/posts/linearly-independent-and-linearly-dependent/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearly-independent-and-linearly-dependent/</guid>
      <description>정의1 $S = \left\{ \mathbf{v}_{1}, \mathbf{v}_{2}, \dots, \mathbf{v}_{r} \right\}$를 벡터공간 $V$ 의 공집합이 아닌 부분집합이라고 하자. 상수 $k_{1}, k_{2}, \dots, k_{r}$들에 대해서 다음의 방정식 $$ k_{1} \mathbf{v}_{1} + k_{2} \mathbf{v}_{2} + \dots + k_{r} \mathbf{v}_{r} = \mathbf{0} $$ 은 적어도 하나의 해 $$ k_{1} = 0,\ k_{2} = 0,\ \dots,\ k_{r} = 0 $$ 를 갖는다. 이를 자명해trivial solution라고 한다. 오직 자명해만이 유일한 해이면 벡터 $\mathbf{v}_{1}, \mathbf{v}_{2}, \dots, \mat</description>
    </item>
    
    <item>
      <title>연립방정식으로 이해하는 랭크와 무효차수</title>
      <link>https://freshrimpsushi.github.io/posts/rank-and-nullity/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rank-and-nullity/</guid>
      <description>역사적 배경 역사적으로는 행렬이 고안된 배경 자체가 연립방정식을 보다 쉽고 편하게 표기하기 위함이었다. 예를 들어 연립방정식 $$ \begin{cases} 2x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; + &amp;amp; x_{3} =&amp;amp; 0 \\ &amp;amp; x_{2} &amp;amp; =&amp;amp; 0 \end{cases} $$ 을 잘 보면, 같은 변수를 여러번 써야한다는 불편함이 있다. 이를 행렬로 나타내면 $$ \begin{bmatrix} 2 &amp;amp; 1 &amp;amp; 1 \\ 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} x_{1} \\ x_{2} \\ x_{3} \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix} $$ 와 같이 각 잡힌 모양으로 깔끔하</description>
    </item>
    
    <item>
      <title>직교 원통 구면 좌표계에 대한 기울기 발산 회전 라플라스 연산</title>
      <link>https://freshrimpsushi.github.io/posts/del-operator-in-several-coordinates/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/del-operator-in-several-coordinates/</guid>
      <description>설명 직교좌표계, 원통좌표계, 구면좌표계에서의 그래디언트, 다이벌전스, 컬, 라플라시안을 한데 모아 정리했다. 이렇게 정리한 이유는 보고 암기하라는 것이 아니라 갑자기 필요한데 생각이 안나거나 할 때 검색해서 보고 참고하라고 정리한 것이다. 굳이 외우려하지 않아도 어차피 공부 열심히하다보면 외워진다. $f$는 스칼라 함수, $\mathbf A$는 벡터 함</description>
    </item>
    
    <item>
      <title>군에서의 항등원과 역원의 유일성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/uniqueness-of-identity-and-inverse-in-group/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniqueness-of-identity-and-inverse-in-group/</guid>
      <description>정리 1 군 $\left&amp;lt;G, \ast \right&amp;gt;$ 에 대해, $G$ 의 모든 원소 $x$ 에 대해 $e \ast x = x \ast e = x$ 를 만족하는 항등원 $e$ 는 유일하다. $G$ 의 어떤 원소 $a$ 에 대해 $a \ast {a&#39;} = {a&#39;} \ast a = e$ 를 만족시키는 역원 $a&#39;$ 는 $a$ 에 대해 유일하다. 설명 다들 당연하게 생각하고 넘어가지만 사실 군의 정의에서는 이들의 존재성만 언급될 뿐이다. 이러한 원소들이 유일하게 존재하는 것은 증명이 필요하다. 증명</description>
    </item>
    
    <item>
      <title>좌우간약율 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-left-and-right-cancellation-law/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-left-and-right-cancellation-law/</guid>
      <description>정리 1 군 $\left&amp;lt;G, \ast \right&amp;gt;$ 의 원소 $a,b,c$ 에 대해, $$ a \ast b = a \ast c \implies b = c \\ b \ast a = c \ast a \implies b=c $$ 설명 추상대수학을 접하면 이제까지 배워왔던 걸 새로운 언어로 배우게 된다. 아마 좌우간약율은 그 중에서도 가장 먼저 접하게되는 정리일 것이다. 우리는 보통 그냥 양변에서 같은 걸 나눈다(역원을 곱한다)는 식으로만 말한다. 간약율은 일본에서 쓰는 표현으로, 굳이</description>
    </item>
    
    <item>
      <title>직교좌표계 단위벡터를 구면좌표계의 단위벡터로 나타내기</title>
      <link>https://freshrimpsushi.github.io/posts/cartesian-coordinate-system-unit-vectors-and-spherical-coordinate-system-unit-vectors/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cartesian-coordinate-system-unit-vectors-and-spherical-coordinate-system-unit-vectors/</guid>
      <description>공식 직교좌표계의 단위벡터를 구면좌표계의 단위벡터로 나타낸 식은 아래와 같다. $$ \begin{align*} \hat{ \mathbf{x} }&amp;amp;= \cos \phi \sin \theta \hat{ \mathbf{r} } + \cos \phi \cos \theta \hat{ \boldsymbol{\theta} } - \sin\phi\hat{ \boldsymbol{\phi} } \\ \hat{ \mathbf{y} } &amp;amp;= \sin\phi\sin\theta \hat{ \mathbf{r} } + \sin\phi\cos\theta\hat{ \boldsymbol{\theta} } + \cos\phi\hat{ \boldsymbol{\phi} } \\ \hat{ \mathbf{z} } &amp;amp;= \cos\theta\hat{ \mathbf{r} } - \sin\theta\hat{ \boldsymbol{\theta} } \end{align*} $$ 구면좌표계의 단위벡터를 직교좌표계의 단위벡터로 나타내면 아래와 같다. (구면좌표계와 직교좌표계의 관계) $$ \begin{align*} \hat{ \mathbf{r} } &amp;amp;= \cos\phi \sin\theta \hat{ \mathbf{x} } +</description>
    </item>
    
    <item>
      <title>추상대수학에서의 군</title>
      <link>https://freshrimpsushi.github.io/posts/group-in-abstract-algebra/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/group-in-abstract-algebra/</guid>
      <description>정의 1 모노이드 $\left&amp;lt; G, \ast\ \right&amp;gt;$ 의 원소 $a$ 와 항등원 $e$ 대해 $a \ast\ a&#39; = a&#39; \ast\ a = e$ 를 만족하는 $a&#39;$ 가 존재하면 $\left&amp;lt; G, \ast\ \right&amp;gt;$를 군Group이라고 정의한다. 즉, 군은 아래의 성질들을 만족하는 이항연산구조다. (i): 연산에 대해 결합법칙이 성립한다. (ii): 모든 원소에 대해 항등원이 존재한다. (iii): 모든 원소에 대해 역원이 존재한다. 설명 마그마부터</description>
    </item>
    
    <item>
      <title>추상대수학에서의 모노이드</title>
      <link>https://freshrimpsushi.github.io/posts/monoid-in-abstract-algebra/</link>
      <pubDate>Tue, 31 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monoid-in-abstract-algebra/</guid>
      <description>정의 1 반군 $\left&amp;lt; M , \ast\ \right&amp;gt;$ 의 모든 원소 $a $ 에 대해, $a \ast\ e = e \ast\ a = a$ 를 만족하는 $e$ 가 존재하면 $\left&amp;lt; M , \ast\ \right&amp;gt;$ 를 모노이드Monoid라 정의한다. 설명 모노이드는 항등원이 존재하는 반군이다. 항등원 정도 되는 개념을 도입하면 할 수 있는 이야기는 상당히 많아진다. 반군이 되면서 모노이드가 되지 않는 대표적인 예를 보도록 하자. 반군 $\left&amp;lt; \mathbb{N} , +\right&amp;gt;$ 는 모노이</description>
    </item>
    
    <item>
      <title>무한 포텐셜 우물에서 파동함수고유함수 에너지고유값 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/infinite-potential-well-wave-function-eigen-function-eigenvalue/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/infinite-potential-well-wave-function-eigen-function-eigenvalue/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 무한 포텐셜 우물에서의 파동함수(고유함수)는$\displaystyle \psi_n{(x)} =\sqrt{\frac{2}{a}}\sin \frac{n\pi}{a}x$각 고유함수 $\psi_n$에 대한 에너지(고유값)은$\displaystyle E_n=\frac{n^2\pi^2\hbar^2}{2ma^2}$ 무한 포텐셜 우물에서의 시간에 무관한 슈뢰딩거 방정식$ \displaystyle -\frac{\hbar ^2}{2m}\frac{d^2 \psi{(x)}}{dx^2}+U\psi{(x)}=E\psi{(x)},\ \ U=\begin{cases} \infty, &amp;amp; -\infty &amp;lt;</description>
    </item>
    
    <item>
      <title>선형 결합, 생성</title>
      <link>https://freshrimpsushi.github.io/posts/linear-combination-and-span/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-combination-and-span/</guid>
      <description>정의: 선형결합1 $\mathbf{w}$를 벡터공간 $V$의 벡터라고 하자. 만약 $w$를 $V$의 벡터 $\mathbf{v}_{1},\mathbf{v}_{2},\cdots ,\mathbf{v}_{r}$와 임의의 상수 $k_{1}, k_{2}, \cdots, k_{r}$에 대해 다음과 같이 표현할 수 있으면 $\mathbf{w}$를 $\mathbf{v}_{1},\mathbf{v}_{2},\cdots ,\mathbf{v}_{r}$들의 선형결합linear combination 혹은 일차결합이라 한다. $$</description>
    </item>
    
    <item>
      <title>추상대수학에서의 반군</title>
      <link>https://freshrimpsushi.github.io/posts/semigroup-in-abstract-algebra/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/semigroup-in-abstract-algebra/</guid>
      <description>정의 1 마그마 $\left&amp;lt; S, *\right&amp;gt;$ 의 원소 $a,b,c$ 에 대해, $(a \ast\ b) \ast\ c = a \ast\ (b \ast\ c)$ 면 $\left&amp;lt; S, *\right&amp;gt;$ 를 반군Semigroup이라고 정의한다. 설명 반군이란 연산이 결합법칙을 만족하는 마그마다. 항등원이나 역원은 존재할 필요가 없고, 오직 결합법칙만 성립하면 된다. 결합법칙을 만족하는지 증명하기 쉬운가 하는 문제와는 별개로, 폐쇄성 다음으로 결합법칙이 논의되는 것</description>
    </item>
    
    <item>
      <title>추상대수학에서의 이항연산</title>
      <link>https://freshrimpsushi.github.io/posts/magma-in-abstract-algebra/</link>
      <pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/magma-in-abstract-algebra/</guid>
      <description>빌드업 수학을 크게 세 부류로 나누자면 기하학, 해석학, 대수학이라고 할 수 있을 것이다. 그 중에서 대수학은 교과과정 상에서 배우는 이항, 약분 등을 다루는 수학의 한 분과였다. 대수학이란 기본적으로 &amp;lsquo;수&amp;rsquo;를 대신해 문자를 써서 어떤 방정식이든 풀어내는 것을 목표로 하는 학문이었다. 특정한 수에 대해서만 통하는 게 아니라 일</description>
    </item>
    
    <item>
      <title>부분공간</title>
      <link>https://freshrimpsushi.github.io/posts/subspace-of-vector-space/</link>
      <pubDate>Fri, 27 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subspace-of-vector-space/</guid>
      <description>정의1 $W$를 벡터공간 $V$의 공집합이 아닌 부분 집합이라고 하자. $W$가 $V$ 에서 정의된 덧셈과 상수배에 대하여 벡터공간의 정의를 만족 시킬 때 $W$를 벡터공간 $V$의 부분공간subspace이라고 하고 다음과 같이 표기한다. $$ W \le V $$ 벡터공간의 정의 $\mathbf{u}, \mathbf{v}, \mathbf{w} \in V$이고, $k, l \in \mathbb{R}$에 대해서 (A1) $\mathbf{u}, \mathb</description>
    </item>
    
    <item>
      <title>벡터공간의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-vector-space/</link>
      <pubDate>Tue, 24 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-vector-space/</guid>
      <description>정의1 vector space이라고 하고 $V$의 원소를 **벡터**vector 라고 한다. --- 공집합이 아닌 집합 $V$의 원소들이 두 연산 덧셈과 상수배에 대해서 아래와 같은 10가지의 규칙을 만족할 때 $V$를 체 $\mathbb{F}$2에 대한 벡터공간vector space 혹은 $\mathbb{F}$-벡터공간이라고 하고 $V$의 원소를 벡터</description>
    </item>
    
    <item>
      <title>로렌츠 변환으로 인한 특수상대성이론의 특징: 길이 수축</title>
      <link>https://freshrimpsushi.github.io/posts/lorentz-transformation-theory-of-relativity-length-contraction/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lorentz-transformation-theory-of-relativity-length-contraction/</guid>
      <description>로렌츠 변환의 특징 특수상대성이론에서 두 좌표계 사이의 변환은 고전적인 변환과 다르다. &amp;lsquo;빛의 속도는 어느 관찰자에게나 똑같다&amp;rsquo; 라는 점 때문이다. 이러한 조건을 고려하여 유도해낸 것이 로렌츠 변환이다. 로렌츠 변환으로 인해서 고전물리에서는 나타나지 않는 새로운 현상이 세가지 있다. 동시성 상실 시간 지연 길이 수축 길이</description>
    </item>
    
    <item>
      <title>로렌츠 변환으로 인한 특수상대성이론의 특징: 동시성 상실</title>
      <link>https://freshrimpsushi.github.io/posts/lorentz-transformation-theory-of-relativity/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lorentz-transformation-theory-of-relativity/</guid>
      <description>로렌츠 변환의 특징 특수상대성이론에서 두 좌표계 사이의 변환은 고전적인 변환과 다르다. &amp;lsquo;빛의 속도는 어느 관찰자에게나 똑같다&amp;rsquo; 라는 점 때문이다. 이러한 조건을 고려하여 유도해낸 것이 로렌츠 변환이다. 로렌츠 변환으로 인해서 고전물리에서는 나타나지 않는 새로운 현상이 세가지 있다. 동시성 상실 시간 지연 길이 수축 동시</description>
    </item>
    
    <item>
      <title>볼록 함수, 오목 함수</title>
      <link>https://freshrimpsushi.github.io/posts/convex-function-concave-function/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convex-function-concave-function/</guid>
      <description>정의 구간 $I \subset \mathbb{R}$ 의 두 원소 $x_{1} , x_{2}$ 와 함수 $f : I \to \mathbb{R}$ 와 $0 \le t \le 1$ 에 대해, $f( t x_{1} + (1-t) x_{2}) \le t f(x_{1}) + (1-t) f(x_{2})$ 일 때, $f$ 는 $I$ 에서의 볼록 함수로 정의한다. $f( t x_{1} + (1-t) x_{2}) \ge t f(x_{1}) + (1-t) f(x_{2})$ 일 때, $f$ 는 $I$ 에서의 오목 함수로 정의한다. 설명 볼록이나 오목은 위로 볼록이냐, 아래로 오목이냐 식의 헷갈리는 말들이 너무 많기 때문에 컨벡스와 컨케이브를 영어표현 그대로 쓰</description>
    </item>
    
    <item>
      <title>옌센 부등식의 적분 폼 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-integral-form-of-jensens-inequality/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-integral-form-of-jensens-inequality/</guid>
      <description>정리 컨벡스 함수 $ \phi : [a,b] \to \mathbb{R}$ 와 $f: [0,1] \to [a,b]$ 에 대해, $\phi \circ f$ 이 $[0,1]$ 에서 적분가능하면 $$ \phi \left( \int_{0}^{1} f(x) dx \right) \le \int_{0}^{1} (\phi \circ f ) (x) dx $$ 설명 당연하지만 주어진 조건만 만족한다면 치환 등을 통해서 적분 구간 역시 바꿀 수 있다. 유한 폼이 정의를 이용해 항의 갯수를 일반화 한 것과 달리 적분 폼은 함수가 적분 기호를 넘나드는 부등식이 된다. 증명 적분의 평균값 정리에 의해 어떤 상</description>
    </item>
    
    <item>
      <title>삼차원 유클리드 공간에서 외적이란</title>
      <link>https://freshrimpsushi.github.io/posts/outer-product-in-three-dimension/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/outer-product-in-three-dimension/</guid>
      <description>정의 $\mathbf{x}, \mathbf{y} \in \mathbb{R}^3$ 에 대해 다음을 $\mathbf{x}$와 $\mathbf{y}$ 의 외적 으로 정의한다. $$ \begin{align*} \mathbf{x} \times \mathbf{y} =&amp;amp; (x_{2}y_{3} - x_{3}y_{2}, x_{3}y_{1} - x_{1}y_{3}, x_{1}y_{2} - x_{2}y_{1}) \\ =&amp;amp; \det \begin{bmatrix} \mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} \\ x_{1} &amp;amp; x_{2} &amp;amp; x_{3} \\ y_{1} &amp;amp; y_{2} &amp;amp; y_{3} \end{bmatrix} \\ =&amp;amp; \begin{bmatrix} 0 &amp;amp; -x_{3} &amp;amp; x_{2} \\ x_{3} &amp;amp; 0 &amp;amp; -x_{1} \\ -x_{2} &amp;amp; x_{1} &amp;amp; 0 \end{bmatrix} \begin{bmatrix} y_{1} \\ y_{2} \\ y_{3} \end{bmatrix} \end{align*} $$ 설명 참고로 $\mathbf{i} = (1,0,0)$ , $ \mathbf{j} = (0,1,0)$ , $\mathbf{k} = (0,0,1)$ 이다. 내적과 마찬가지로 외적 역시 더욱 일반적인 정의는 가능하지만 실</description>
    </item>
    
    <item>
      <title>유클리드 공간에서 내적이란</title>
      <link>https://freshrimpsushi.github.io/posts/inner-product-in-euclidean-space/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inner-product-in-euclidean-space/</guid>
      <description>정의 벡터공간 $V = \mathbb{R}^n$ 에 대해 $\mathbb{x}, \mathbb{y}, \mathbb{z} \in V$ 그리고 $k \in \mathbb{R}$ 이라고 하자. $\left&amp;lt; \cdot , \cdot \right&amp;gt; : V^2 \to \mathbb{R}$ 가 아래 네 조건들을 만족시킬 때 $\left&amp;lt; \cdot , \cdot \right&amp;gt;$ 를 $V$ 상에서의 내적 으로 정의한다. (1) 대칭성: $\left&amp;lt; \mathbb{x} , \mathbb{y} \right&amp;gt; = \left&amp;lt; \mathbb{y}, \mathbb{x} \right&amp;gt;$ (2) 가산성: $\left&amp;lt; \mathbb{x} + \mathbb{y} , \mathbb{z} \right&amp;gt; = \left&amp;lt; \mathbb{x}, \mathbb{z} \right&amp;gt; + \left&amp;lt; \mathbb{y}, \mathbb{z} \right&amp;gt;$ (3) 동질성: $\left&amp;lt; k \mathbb{x} , \mathbb{y} \right&amp;gt; = k \left&amp;lt; \mathbb{x}, \mathbb{y} \right&amp;gt;$ (4) 정부호: $\left&amp;lt; \mathbb{x} , \mathbb{x} \right&amp;gt; \ge 0$ 그리고 $\left&amp;lt; \mathbb{x} , \mathbb{x} \right&amp;gt; =0 \iff \mathbb{x}=\mathbb{0}$ 특히</description>
    </item>
    
    <item>
      <title>행렬의 랭크, 무효차수</title>
      <link>https://freshrimpsushi.github.io/posts/rank-and-nullity-of-matrix/</link>
      <pubDate>Wed, 04 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rank-and-nullity-of-matrix/</guid>
      <description>정리1 행렬 $A$의 행공간과 열공간의 차원은 같다. 증명 $R$을 $A$의 행사다리꼴 행렬이라고 하자. 기본 행 연산은 $A$의 행공간의 차원과 열공간의 차원을 바꾸지 않으므로 다음의 식이 성립한다. $$ \begin{align*} \dim \big( \mathcal{R}(A) \big) &amp;amp;= \dim \big( \mathcal{R}(R) \big) \\ \dim \big( \mathcal{C}(A) \big) &amp;amp;= \dim \big( \mathcal{C}(R) \big) \end{align*} $$ 따라서 $R$의 행공간과 열공간의 차원이 같음을 보이면 충분하다. 그런데 $R$의 행공간은</description>
    </item>
    
    <item>
      <title>행공간, 열공간, 영공간</title>
      <link>https://freshrimpsushi.github.io/posts/row-space-column-space-null-space-of-matrix/</link>
      <pubDate>Tue, 03 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/row-space-column-space-null-space-of-matrix/</guid>
      <description>정의1 $m \times n$ 행렬 $A$ 에 대해서, $A$ 의 행으로 만들어지는 $\mathbb{R}^{n}$ 벡터들 $$ \begin{align*} \mathbf{r}_{1} =&amp;amp; \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \end{bmatrix} \\ \mathbf{r}_{2} =&amp;amp; \begin{bmatrix} a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \end{bmatrix} \\ &amp;amp;\vdots \\ \mathbf{r}_{m} =&amp;amp; \begin{bmatrix} a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn} \end{bmatrix} \end{align*} $$ 을 $A$ 의 행벡터row vectors라고 한다. $A$ 의 열로 만들어지는 $\mathbb{R}^{m}$ 벡터들 $$ \mathbf{c}_{1} = \begin{bmatrix} a_{11} \\ a_{21} \\ \vdots \\ a_{m1} \end{bmatrix},\quad \mathbf{c}_{2} = \begin{bmatrix} a_{12} \\ a_{22} \\ \vdots \\ a_{m2} \end{bmatrix},\quad \dots,\quad \mathbf{c}_{n} = \begin{bmatrix} a_{1n} \\ a_{2n} \\ \vdots \\ a_{mn} \end{bmatrix} $$ 을 $A$ 의 열벡터colum</description>
    </item>
    
    <item>
      <title>로렌츠 변환 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-lorentz-transformation/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-lorentz-transformation/</guid>
      <description>유도 글이 좀 길기는 하지만 굉장히 쉽게 적어놨으니 쫄지말고 해보자. $A$관성계(좌표계)의 $xy$평면에서 움직이는 빛(광자)을 생각해보자. $t=0$일 때 원점에서 출발해 $x$축과 $\theta$를 이루며 나아가고 있다. 갈릴레이 변환을 대신할 새로운 변환의 모습은 아래와 같다고 할 수 있다. $$ \begin{pmatrix} t&#39; \\ x&#39; \\ y&#39; \\ z&#39; \end{pmatrix} = \begin{pmatrix} &amp;amp; &amp;amp; &amp;amp; \\ &amp;amp;</description>
    </item>
    
    <item>
      <title>상대성이론과 로렌츠 변환</title>
      <link>https://freshrimpsushi.github.io/posts/lorentz-transformation/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lorentz-transformation/</guid>
      <description>빌드업 상대성이론은 전자기학의 완성에서부터 출발한다. 전자기학을 완성했다는 말은 맥스웰이 전기장 $\mathbf{E}$와 자기장 $\mathbf{B}$에 대한 4개의 편미분 방정식을 완성했다는 말과 같다. 맥스웰 방정식으로부터 전자기파의 속도가 광속과 같다는 점을 알게 되었다. 이로 인해 아래의 두 사실을 얻게 된다. 빛은 전자기파이</description>
    </item>
    
    <item>
      <title>세계선과 갈릴레이 변환</title>
      <link>https://freshrimpsushi.github.io/posts/world-line-and-galilei-transformation/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/world-line-and-galilei-transformation/</guid>
      <description>정의 입자의 자취를 시간과 공간에 대해서 나타낸 선을 세계선world line이라 한다. 설명 우선 한 방향으로 등속운동하는 좌표계에 대해서만 생각해보기로하자. $A$좌표계에서 원점에 정지한 입자가 있다.이 입자의 세계선은 아래와 같다. 그리고 $A$좌표계를 기준으로 $+x$방향으로 $v_0$의 속도로 이동하는 $A&#39;$좌표계가 있다</description>
    </item>
    
    <item>
      <title>켤레 복소수</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-properties-of-complex-conjugate/</link>
      <pubDate>Sat, 23 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-properties-of-complex-conjugate/</guid>
      <description>정의 $z$ 를 $z=a+ib(a,b\in \mathbb{R})$인 복소수라고 하자. $\overline{z}$ 를 다음과 같이 정의하고 $z$ 의 켤레 복소수Complex Conjugatre라고 한다. $$ \overline{z}:=\overline{a+ib}=a-ib $$ 설명 원래 복소수에 $i$ 대신 $-i$ 를 대입한 것, 복소 평면에서 실수 축으로 대칭이동한 것 등으로 설명할 수 있다. 켤레라는 말은 더해서 실수를 만들어내는 한 쌍이라는 점 때문에 붙은 이름으로 보인다.</description>
    </item>
    
    <item>
      <title>컬의 다이벌전스는 항상 0이다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-divergence-of-curl-is-always-0/</link>
      <pubDate>Fri, 22 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-divergence-of-curl-is-always-0/</guid>
      <description>공식 벡터 함수 $\mathbf{A}$의 컬의 다이벌전스는 항상 $0$이다. $$ \nabla \cdot (\nabla \times \mathbf{A}) = 0 $$ 증명 $\mathbf{A}$의 컬은 다음과 같다. $$ \begin{align*} \nabla \times \mathbf{A} &amp;amp;= \begin{vmatrix} \hat{\mathbf{x}} &amp;amp; \hat{\mathbf{y}} &amp;amp; \hat{\mathbf{z}} \\ \displaystyle \frac{\partial}{\partial x} &amp;amp; \displaystyle \frac{\partial}{\partial y} &amp;amp; \displaystyle \frac{\partial}{\partial z} \\ A_{x} &amp;amp; A_{y} &amp;amp; A_{z} \end{vmatrix} \\ &amp;amp;= \hat{\mathbf{x}} \left( \frac{\partial A_{z}}{\partial y} - \frac{\partial A_{y}}{\partial z} \right) + \hat{\mathbf{y}} \left( \frac{\partial A_{x}}{\partial z} - \frac{ \partial A_{z}}{\partial x} \right) + \hat{\mathbf{z}} \left( \frac{\partial A_{y}}{\partial x}-\frac{\partial A_{x}}{\partial y} \right) \end{align*} $$ 어떤 벡터 함수 $\mathbf{F}</description>
    </item>
    
    <item>
      <title>구의 관성모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-sphere/</link>
      <pubDate>Sun, 10 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-sphere/</guid>
      <description>공식 반지름이 $a$, 질량이 $m$인 구의 관성모멘트는 다음과 같다. $$ I=\frac{2}{5}ma^{2} $$ 유도 구의 관성모멘트를 구하는 아이디어는 다른 강체들과는 살짝 다르다. 핵심적인 아이디어는 구분구적법과 비슷하게 구를 무수히 많은 원판의 합이라고 생각하는 것이다. 저 무수히 많은 원판의 관성모멘트를 다 더하면 구의 관성모멘트가 된다. 회전축과 수직한 원판의 관성모멘트는 $I</description>
    </item>
    
    <item>
      <title>고리, 원통 껍질의 관성모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-hoop-cylinderical-shell/</link>
      <pubDate>Fri, 08 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-hoop-cylinderical-shell/</guid>
      <description>공식 반지름이 $a$, 질량이 $m$인 고리의 관성모멘트는 회전축이 고리의 중심을 지나고, 고리가 만드는 평면에 수직한 경우에는 $I=ma^{2}$이다. 고리가 만드는 평면과 나란한 경우에는 $I=\dfrac{1}{2}ma^{2}$이다. 유도 반지름이 $a$이고 질량이 $m$인 얇고 균일한 원형 고리(혹은 원통형 껍질)를 생각해보자.</description>
    </item>
    
    <item>
      <title>원판, 원통의 관성모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-circular-disc-cylinder/</link>
      <pubDate>Fri, 08 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-inertia-of-circular-disc-cylinder/</guid>
      <description>공식 반지름이 $a$, 질량이 $m$인 원판의 관성모멘트는 회전축이 원판에 수직한 경우에는 $I=\dfrac{1}{2}ma^2$이다. 회전축이 원판과 수평인 경우에는 $I=\dfrac{1}{4}ma^2$이다. 유도 회전축이 원판의 중심을 지나고, 원판에 수직하는 경우 $\rho$를 단위면적당 질량이라고 하자. 그러면 원판의 질량</description>
    </item>
    
    <item>
      <title>수직축 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-perpendicular-axis-theorem/</link>
      <pubDate>Wed, 06 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-perpendicular-axis-theorem/</guid>
      <description>수직축 정리 임의의 평면에 수직한 회전축에 대한 관성모멘트는 그 수직축을 지나면서 평면판 위에 있는 서로 수직한 임의의 두 축에 대한 관성모멘트의 합과 같다. $$ \color{red}{I_{z}}=\color{blue}{I_{x}+I_{y}} $$ 증명 $$ I_{z}=\sum\limits_{i} m_{i}{r_{i}}^{2} $$ 피타고라스의 정리에 의해서 ${r_{i}}^{2}={x_{i}}^{2}+{y_{i}}^{2}$이므로 이를 위 식에 대입하면 다음과 같다. $$ I_{z}=\sum\limits_{i} m_{i}({x_{i}}^{2}+{y_{i}}^{2})=\sum\limits_{i} m_{i}{x_{i}}^{2}+\sum\limits_{i} m_{i}{y_{i}}^{2} $$ $x</description>
    </item>
    
    <item>
      <title>평행축 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-parallel-axis-theorem/</link>
      <pubDate>Wed, 06 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-parallel-axis-theorem/</guid>
      <description>평행축 정리 강체의 임의의 회전축에 대한 관성모멘트는 그 축과 평행 하고 질량중심을 지나는 회전축에 대한 관성모멘트와 강체의 질량과 두 축 사이의 거리제곱의 곱을 더한 것과 같다. $$ \color{red}I=\color{blue}{I_{cm}}+\color{green}{md^{2}} $$ 증명 임의로 좌표축을 설정하고 $z$-축에 대한 관성모멘트를 $I_{z}$라 하자. $$ \begin{equation} I_{z}=\sum\limits_{i} m_{i} {r_{i}}^{2} = \sum\limits_{i} m_{i} ({x_{i}}^{2}+{y_{i}}^{2}) \label{eq1} \end{equation} $$ 원점에서 강체의 임의의 점까지의 거리를 원점에서 질</description>
    </item>
    
    <item>
      <title>관성모멘트와 선회반경</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-inertia-and-radius-of-gyration/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-inertia-and-radius-of-gyration/</guid>
      <description>관성모멘트 $$ \begin{align*} I &amp;amp;= \sum_i m_i {r_i}^2 \\ I &amp;amp;= \int r^2 dm \end{align*} $$ 관성모멘트moment of inertia는 (입자의 질량)$\times$(회전축에서 입자까지의 거리)로 정의되며 물체가 계속 회전운동하려는 성질을 나타내는 물리량이다. 기호는 $I$이며 영칭인 Inertia의 앞글자를 딴것으로 보인다. 단위는 $[kg \cdot m^2]$이다. 병진운동에서의</description>
    </item>
    
    <item>
      <title>얇은 막대의 관성모멘트</title>
      <link>https://freshrimpsushi.github.io/posts/moment-of-interia-of-thin-rod/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-of-interia-of-thin-rod/</guid>
      <description>공식 길이가 $a$, 질량이 $m$인 막대의 관성모멘트는 회전축이 막대의 끝에 있으면 $I=\dfrac{1}{3}ma^{2}$이다. 회전축이 막대의 중앙에 있으면 $I=\dfrac{1}{12}ma^{2}$이다. 유도 회전축이 막대의 끝에 있는 경우 $\rho$를 단위길이당 질량이라고 하면 막대의 질량은 $m=\rho x$이다. 그리고 $dm=\rho dx</description>
    </item>
    
    <item>
      <title>생성함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/generating-function/</link>
      <pubDate>Wed, 30 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generating-function/</guid>
      <description>정의 수열 $\left\{ a_{n} \right\}$ 에 대해 $$ g(x) =\sum \limits _{n=0}^{\infty}a_{n}x^{n}= a_{0} + a_{1} x + a_{2} x^2 + \cdots $$ 와 같은 꼴로 나타나는 함수 $g$를 수열 $\left\{ a_{n}\right\}$ 의 생성함수 또는 간단히 생성함수라 한다. 수열이 $a_{n}=a_{n}(x)$인 경우 아래와 같이 표기하기도 한다. $$ G(x,t)=\sum \limits _{n=0}^{\infty}a_{n}(x)t^{n} $$ 설명 예리한 독자라면 눈치챘겠지만 테일러 급수 역시 저 비슷한 꼴을 하고 있다. 예리하지 못한 독자라도 고등학교때</description>
    </item>
    
    <item>
      <title>바이어슈트라스 M 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/weierstrasss-m-test/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weierstrasss-m-test/</guid>
      <description>정리 1 함수 $f_{n}$ 와 $z \in A$ 에 대해 $|f_{n}(z)| \le M_{n}$ 을 만족하는 양수의 수열 $M_{n}$ 이 존재하고 $\displaystyle \sum_{n=1}^{\infty} M_{n}$ 이 수렴하면 $\displaystyle \sum_{n=1}^{\infty} f_{n}$ 은 $A$ 에서 절대수렴하고 균등수렴한다. 설명 M 판정법이라는 이름은 수열 $M_{n}$ 에서 따온 것이다. 이미 수렴한다는 사실을 아는 $M_{n}$ 을 잘 가져와 함수의 절댓값과 부등식을 세울 수 있으면 그냥 수렴도 아니고 절대수렴과 균등수렴을 동시에 보일 수 있어 유용한 정리다</description>
    </item>
    
    <item>
      <title>복소해석을 사용한 테일러 급수 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-taylor-expansion-by-complex-analysis/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-taylor-expansion-by-complex-analysis/</guid>
      <description>정리 1 함수 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 원 $|z - \alpha| &amp;lt; r$ 에서 해석적이면 $$ f(z) = \sum_{n = 0} ^{\infty} {{f^{(n)} (\alpha)} \over {n!}} (z - \alpha)^n $$ 설명 수학의 즐거움 중 하나가 바로 일반화다. 테일러 정리부터가 평균값의 정리를 일반화했다고 할 수 있는데, 이번엔 실수를 복소수로 확장해보자. 재미있는 사실은 꾸역꾸역 확장하는 게 아니라 사실상 처음부터 쌓아올림에도 불구하고 증명은 더 간단해졌다는 것이</description>
    </item>
    
    <item>
      <title>로체의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-roches-theorem/</link>
      <pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-roches-theorem/</guid>
      <description>정리 1 $f$ 와 $g$ 가 단순폐경로 $\mathscr{C}$ 에서 해석적이고 $\mathscr{C}$ 상에서 $|g(z)| \le |f(z)|$ 을 만족하면 $f$ 와 $f + g$ 는 $\mathscr{C}$ 내부에서 같은 수의 영점을 갖는다. 설명 원래 주어진 함수를 $h = f + g$ 로 생각하고 $f$ 와 $g$ 로 잘 분리해서 쓰는 정리다. 특히 다항함수의 경우엔 이러한 조작이 아주 쉽기 때문에 유용하게 써먹을 수 있다. 또한 수치해석적인 방법과 함께라면 방정식 $h(z) = 0$ 의 해가 구체적</description>
    </item>
    
    <item>
      <title>유리형함수의 영점과 극점</title>
      <link>https://freshrimpsushi.github.io/posts/poles-and-zeros-of-meromorphic-function/</link>
      <pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poles-and-zeros-of-meromorphic-function/</guid>
      <description>정리 1 단순폐경로 $\mathscr{C}$ 에서 해석적인 함수 $f$ 가 $\mathscr{C}$ 내부에서 $Z$개의 영점과 $P$개의 극점을 갖고 $\mathscr{C}$ 상에서 $f(z) \ne 0$ 이라고 하자. 그러면 $$ {{1} \over {2 \pi i }} \int_{\mathscr{C}} {{f&#39;(z)} \over {f(z)}} dz = Z - P $$ $Z$ 와 $P$ 는 중복되는 수를 모두 더한 수다. 설명 $f$ 가 극점을 갖지 않는다면 방정식 $f(z) = 0$ 의 해의 갯수를 구하는 공식이 될 것이다. 눈여겨봐야할 점은 정수가 등장했다는 것이다. 복소</description>
    </item>
    
    <item>
      <title>슈발츠 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-schwarzs-lemma/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-schwarzs-lemma/</guid>
      <description>정리 1 단위원 $|z| \le 1$ 에서 해석적인 함수 $f$ 에 대해 $f(0) = 0$이고 $0 &amp;lt; |z| &amp;lt; 1$ 에서 $|f(z)| \le 1$ 이라고 하자. 그러면 $0 &amp;lt; |z| &amp;lt; 1$ 에서 $$ |f&#39;(0)| \le 1 \\ |f(z)| \le |z| $$ 증명 물론 일반성을 잃지 않고 $|z| \le r$ 로 확장할 수 있지만 증명의 편의를 위해 단위원을 잡았다. 새로운 함수 $g$ 를 $\displaystyle g(z) := \cases{ {{f(z)} / {z}} &amp;amp; , 0&amp;lt;|z|&amp;lt;1 \\ f&#39;(0) &amp;amp; , z=0}$ 와 같이 정의하자. $\displaystyle \lim_{z \to 0} {{f(z)} \over {z}} = f&#39;(0)$ 이므로 $g$ 는 단위원 안에</description>
    </item>
    
    <item>
      <title>푸아송 적분 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-poissons-integral-formula/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-poissons-integral-formula/</guid>
      <description>공식 1 $f$ 가 원 $\mathscr{C}: |z| = r$ 을 포함하는 단순연결영역에서 해석적이라고 하자. 그러면 $0 &amp;lt; \rho &amp;lt; r$ 에 대해 $$ f( \rho e ^{i \phi} ) = {{1} \over { 2 \pi }} \int_{0}^{2 \pi} {{r^2 - \rho^2 } \over {r^2 - 2 r \rho \cos (\theta - \phi) + \rho ^2 }} f(r e^{i \theta}) d \theta $$ 본질적으로 코시 적분 공식의 변형이다. 무수한 잔계산을 거칠 뿐이기 때문에 과정은 한 번 읽어보는 것 외에 큰 가치는 없다. 유도 먼저 $\mathscr{C}$ 내부의 $f(\alpha) \ne 0$ 를 만족하는</description>
    </item>
    
    <item>
      <title>가우스의 평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gausss-mean-value-theorem/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gausss-mean-value-theorem/</guid>
      <description>정리 함수 $f$ 가 닫힌 원 $| z - z_{0} | \le r $ 에서 해석적이라고 하자. 그러면 $$ f(z_{0}) = {{1} \over {2 \pi}} \int_{0}^{2 \pi} f(z_{0} + r e ^{i \theta } ) d \theta $$ 설명 미분의 평균값 정리가 일반화를 거치며 여러 수학자의 이름이 붙은 변형 정리를 낳았듯, 적분의 평균값 정리도 무려 가우스의 이름이 붙은 변형이 있다. 그 형태는 의심할나위 없는 적분의 평균값 정리지만 개념을 잘 생각해보면 마냥 당연하</description>
    </item>
    
    <item>
      <title>최대절댓값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-maximum-modulus-theorem/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-maximum-modulus-theorem/</guid>
      <description>정리 1 함수 $f$ 가 단순폐경로 $\mathscr{C}$ 상에서 연속이고 내부에서 해석적이면서 어떤 점에서도 상수함수가 아니라고 하자. 그러면 $\mathscr{C}$ 에서 $|f(z)|$ 를 가장 크게 하는 $z = z_{0}$ 는 $\mathscr{C}$ 상에 존재한다. 설명 쉽게 말해 복소해석에서는 폐경로 내에서 $|f|$ 의 최댓값은 그 테두리에 존재한다는 것이다. 이쯤되면 직관적으로는 따라잡을 수가 없는 수준으로, 왜인지는 모르겠으나 참 신기하다</description>
    </item>
    
    <item>
      <title>대수학의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-algebra/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-algebra/</guid>
      <description>정리 1 $n$차 다항식 $P(z) = a_{0} + a_{1} x + a_{2} x^2 + \cdots + a_{n} x^{n} = 0$ 은 중근을 포함해서 정확히 $n$개의 해를 갖는다. 설명 사실 우리는 다항식을 풀 때 당연히 해가 존재하는마냥 풀고있지만 그게 꼭 그렇다는 보장은 없을 수 있다. 예로써 2차 다항식 $x^2+1 = 0$은 실근이 존재하지 않는다. 하지만 여기서 복소수를 허용하면 $\pm i$ 라는 두 해가 존재함을 알 수 있다. 팩트로</description>
    </item>
    
    <item>
      <title>복소해석에서의 리우빌의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-complex-analysis/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-complex-analysis/</guid>
      <description>정리 1 $f$ 가 전해석함수고 모든 $z \in \mathbb{C}$ 에 대해 $|f(z)| \le M$을 만족하는 양수 $M$ 이 존재하면 $f$ 는 상수함수다. 설명 $f$ 가 전해석함수이라는 말은 복소평면 전체에서 해석적이라는 뜻이다. 대우명제로 말하자면 상수함수가 아니면 그 절댓값이 유계Bounded가 되지 않는다는 뜻이다. 예로써 $\sin$ 은 정의역이 실수집합일 땐 자명하게도 $-1$ 과 $1$ 에 바운드되어있지만</description>
    </item>
    
    <item>
      <title>프레넬 사인 적분의 매클로린 전개</title>
      <link>https://freshrimpsushi.github.io/posts/maclaurin-expansion-of-fresnel-sine-integral/</link>
      <pubDate>Sat, 12 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maclaurin-expansion-of-fresnel-sine-integral/</guid>
      <description>공식 $$ S(x) = \sqrt{{2} \over {\pi}} \int_{0}^{x} \sin (w^2) dw = \sqrt{{2} \over {\pi}} \sum_{n=0}^{\infty} {{(-1)^{n}} \over {(2n+1)! (4n+3)}} x^{4n+3} $$ 설명 프레넬은 광학을 연구했던 물리학자로써 그의 이름이 붙은 결과들을 보면 대개는 삼각함수가 연관되어있다. 아무래도 삼각함수가 파동함수와 깊은 연관이 있기 때문에 없는 공식은 만들어내서라도 공부를 해야했을 것이다. 이러한 연구들이 광학에 어찌 기여했는지는 몰라도 당장 삼각함수에 대한 미적분</description>
    </item>
    
    <item>
      <title>프레넬 적분 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fresnels-integral/</link>
      <pubDate>Sat, 12 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fresnels-integral/</guid>
      <description>정리 1 $$ \displaystyle \int_{0}^{\infty} \cos x^2 dx = \int_{0}^{\infty} \sin x^2 dx = {{1}\over{2}} \sqrt{{\pi}\over{2}} $$ 설명 프레넬 적분은 언뜻 쉬워 보이지만 보이는것만큼 간단한 결과가 아니다. 단순히 삼각함수의 제곱이라면 쉽겠지만 그 안의 $x$ 에 제곱을 취한 것이기 때문이다. 막상 건드려보면 이 $x$ 가 얼마나 사라지지 않는지 알 수 있을 것이다.함수 안의 변수가 핵심 문제기 때문에 그래프의 개형부터 잘 떠오르지 않는다. 일단 이상적</description>
    </item>
    
    <item>
      <title>e^-x^2꼴의 정적분  가우스 적분오일러-푸아송 적분 Gaussian IntegralEuler-</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-integral/</link>
      <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-integral/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정리 가우스 함수 $f(x)=e^{-x^2}$ 의 전체 영역에 대한 적분은 다음과 같다. $$ \int_{-\infty}^{\infty} e^{-x^2} dx= \sqrt{\pi} $$ 위 적분을 가우스 적분$(\mathrm{Gaussian\ integral})$, 혹은 오일러-푸아송 적분$(\mathrm{Euler-Poisson\ integral})$이라고 부른다. 고등학생에겐 충격적인 적분이자</description>
    </item>
    
    <item>
      <title>이항정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-binomial-theorem/</link>
      <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-binomial-theorem/</guid>
      <description>정리 $$ \displaystyle (x+y)^{n} = \sum_{r=0}^{n} {_n C _r} x^{n} y^{n-r} $$ 설명 고등학교에서 배우는 것 치고는 놀랍게도 배우자마자 여러군데 쓸데가 보이는 정리다. 생김새가 자유롭기 때문에 많은 공식을 단번에 유도해낼 수 있으며 분야를 가리지 않고 많이 쓰인다. 증명 $(x+y)^{n}$ 을 전개할 때 $x^{n} y^{n-r}$ 의 계수는 $$ (x+y)^{n} = (x+y)(x+y)(x+y) \cdots (x+y) $$ 의 각 $(x+y)$ 중에서 $x$를 $n$개, $y$를 $n-r$개 선택하는 것과 같다. 따라서</description>
    </item>
    
    <item>
      <title>모레라의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-moreras-theorem/</link>
      <pubDate>Wed, 09 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-moreras-theorem/</guid>
      <description>정리 1 함수 $f$ 가 단순연결영역 $\mathscr{R}$ 에서 연속이고 $\mathscr{R}$ 내부의 모든 폐경로 $\mathscr{C}$ 에 대해 $\displaystyle \int_{\mathscr{C}} f(z) dz = 0$을 만족하면 $f$ 는 $\mathscr{R}$ 에서 해석적이다. 설명 코시 정리의 역 정도로 생각할 수 있겠다. 재미있는 점은 원래 &amp;lsquo;미분가능하면 연속, 연속이면 적분가능&amp;rsquo;이 원래 해석학의 상식이라는 사실이다. 그런데 모레라의 정리는 오히려 적분을 통해 함</description>
    </item>
    
    <item>
      <title>코시 적분 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-cauchys-integral-formula/</link>
      <pubDate>Wed, 09 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-cauchys-integral-formula/</guid>
      <description>정리 1 함수 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 단순연결영역 $\mathscr{R}$ 에서 해석적이라고 하자. $\mathscr{R}$ 내부의 단순폐경로 $\mathscr{C}$ 가 어떤 점 $\alpha$ 를 둘러싸고 있다면 $$ f(\alpha) = {{1} \over {2 \pi i }} \int_{\mathscr{C}} {{f(z)} \over { z - \alpha }} dz $$ 유도 우선 $\displaystyle 2 \pi i = \int_{\mathscr{C&#39;}} {{1} \over { z - \alpha }} dz$ 임을 보이자. 복소경로적분의 수축 보조정리: $\mathscr{C}$ 내부에서 $\alpha$ 를 중심으로 하는 원 $\mathscr{C&#39;}$ 에 대해 $$\int_{\mathscr{C}} f(z) dz = \int_{\mathscr{C&#39;}} f(z) dz$$ $\displaystyle \int_{\mathscr{C}} {{1} \over { z - \alpha }} dz$ 의 적분구간</description>
    </item>
    
    <item>
      <title>미적분학의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-calculus/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-calculus/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 해석학에서의 증명 (1)해석학에서의 증명 (2) 함수 $f$ 가 폐구간 $[a,b]$ 에서 연속이라고 하자. (1)** 함수 $\displaystyle F(x) = \int_{a}^{x} f(t) dt$ 는 $[a,b]$ 에서 연속, $(a,b)$ 에서 미분가능하며 $\displaystyle {{dF(x)} \over {dx}} = f(x)$ 를 만족한다. 2. $f$ 의 임의의 부정적분 $F$ 에 대해 $\displaystyle \int_{a}^{b} f(x) dx = F(b) - F(a)$ 물론 우리야 미분, 적분이라는 단어를 사용하기 때문에 이들 사이의 관계</description>
    </item>
    
    <item>
      <title>적분의 평균값 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem-for-integral/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem-for-integral/</guid>
      <description>정리 폐구간 $[a,b]$ 에서 함수 $f$ 가 연속이라고 하면 $\displaystyle f(c) = {{1}\over {b-a} } \int_{a}^{b} f(x) dx$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 설명 평균값의 정리와 유사하지만 말 그대로 적분에 사용되기 때문에 이런 이름이 붙었다. 사용법 역시 매우 유사하고 활용도도 결코 평균값의 정리에 뒤지지 않는다. 한편 함수의 평균값을 우변과 같이 정의하는 걸 생각해보면 오히려 이 쪽이 평균값의 정</description>
    </item>
    
    <item>
      <title>복소경로적분의 수축 보조정리</title>
      <link>https://freshrimpsushi.github.io/posts/shrinking-lemma-of-complex-contour-integral/</link>
      <pubDate>Mon, 07 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shrinking-lemma-of-complex-contour-integral/</guid>
      <description>정리 1 단순폐경로 $\mathscr{C}$ 를 포함하는 단순연결영역에서 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 $\mathscr{C}$ 내부의 점 $\alpha$ 를 제외한 모든 점에서 해석적이라고 하자. 그러면 $\mathscr{C}$ 내부에서 $\alpha$ 를 중심으로 하는 폐곡선 $\mathscr{C&#39;}$ 에 대해 $$ \int_{\mathscr{C}} f(z) dz = \int_{\mathscr{C&#39;}} f(z) dz $$ 설명 말은 긴데 결국 말하자면 폐경로에서 복소적분을 할 땐 어떤 점을 중심으로 그 폐경로를 수축시킬 수 있다는 말이다.적분구간을 이렇게나 마음대로 바꿀 수</description>
    </item>
    
    <item>
      <title>복소해석에서의 코시 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cauchys-theorem/</link>
      <pubDate>Mon, 07 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cauchys-theorem/</guid>
      <description>정리 1 단순폐경로 $\mathscr{C}$와 그 내부에서 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 해석적이고 $f&#39;$ 가 연속이라고 하자. 그러면 $$ \int_{\mathscr{C}} f(z) dz = 0 $$ 증명 $a \le t \le b$ 에 대해 $$ z(t) = x(t) + i y(t) \\ f(z) = u(x,y) + i v(x,y) $$ 라고 하면 $\displaystyle {{dz} \over {dt}} = x&#39; + i y&#39;$ 이므로 $$ \begin{align*} f(z)dz =&amp;amp; f(z) (x&#39; + i y&#39;) dt \\ =&amp;amp; (u + i v ) ( x&#39; + i y&#39; ) dt \\ =&amp;amp; (u x&#39; - v y&#39;) + i (v x&#39; + u y&#39;) dt \end{align*} $$ $\displaystyle x&#39; = {{dx} \over {dt}}$ 이고 $\displaystyle</description>
    </item>
    
    <item>
      <title>벡터 함수의 컬의 컬</title>
      <link>https://freshrimpsushi.github.io/posts/the-curl-of-curl-of-vector-function/</link>
      <pubDate>Sun, 06 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-curl-of-curl-of-vector-function/</guid>
      <description>공식 벡터 함수의 컬의 컬은 다음과 같다. $$ \nabla \times (\nabla \times \mathbf{A}) = \nabla (\nabla \cdot \mathbf{A}) - \nabla^2 \mathbf{A} $$ 설명 첫번째 항인 $\nabla(\nabla \cdot \mathbf{A})$는 다이벌전스의 그래디언트이며 따로 붙여진 이름은 없다. 두번째 항은 중요해서 이름이 있다. $\nabla \cdot \nabla$를 라플라시안이라 하는데, 정확하게는 벡터 함수의 라플라시안이다. 컬의 컬에 특별한 의미가 있는 것은 아니고,</description>
    </item>
    
    <item>
      <title>그래디언트의 컬은 항상 0이다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-the-curl-of-a-gradient-is-always-0/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-the-curl-of-a-gradient-is-always-0/</guid>
      <description>공식 스칼라 함수 $T$의 그래디언트의 컬은 항상 $\mathbf{0}$이다 $$ \nabla \times (\nabla T)=0 $$ 증명 직교 좌표계에서 $T$의 그래디언트는 다음과 같다. $$ \nabla T = \frac{\partial T}{\partial x}\hat{\mathbf{ x}} +\frac{\partial T}{\partial y}\hat{\mathbf{y}} +\frac{\partial T}{\partial z}\hat{\mathbf{z}} $$ $\nabla T$의 컬을 구하면 다음과 같다. $$ \begin{align*} \nabla \times (\nabla T) &amp;amp;= \begin{vmatrix} \displaystyle \hat{\mathbf{x}} &amp;amp;\hat{\mathbf{y}} &amp;amp; \hat{\mathbf{z}} \\ \displaystyle \frac{\partial }{\partial x} &amp;amp; \displaystyle \frac{\partial }{\partial y} &amp;amp; \displaystyle \frac{\partial }{\partial z} \\ \displaystyle \frac{\partial T}{\partial x} &amp;amp; \displaystyle \frac{\partial T}{\partial y} &amp;amp; \displaystyle\frac{\partial T}{\partial z} \end{vmatrix} \\ &amp;amp;= \left( \frac{\partial^2 T}{\partial y \partial z}-\frac{\partial^2 T}{\partial z \partial</description>
    </item>
    
    <item>
      <title>맥스웰 방정식으로부터 전자기파빛의 속도 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/light-speed-derived-from-maxwell-equations/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/light-speed-derived-from-maxwell-equations/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **진공에서의 맥스웰 방정식 $ \displaystyle (\mathrm{i})\ \nabla \cdot \mathbf{E} = 0 $$ \displaystyle (\mathrm{ii})\ \nabla \cdot \mathbf{B} = 0 $$ \displaystyle (\mathrm{iii})\ \nabla \times \mathbf{E} = -\frac{\partial \mathbf{B}}{\partial t} $$ \displaystyle (\mathrm{iv})\ \nabla \times \mathbf{B} = \mu_0\epsilon_0\frac{\partial \mathbf{E}}{\partial t} $ 1차원 파동방정식 $ \displaystyle \frac{\partial^2 f}{\partial x^2}=\frac{1}{v^2}\frac{\partial^2 f}{\partial t^2}$ 3차원 파동방정식 $ \displaystyle \nabla ^2 f = \frac{1}{v^2}\frac{\partial ^2 f}{\partial t^2}$ 맥스웰 방정식으로부터 $\mathbf{E}$와 $\mathbf{B}$에 관한 파동 방정식 꼴</description>
    </item>
    
    <item>
      <title>특정한 분포를 따르는 확률변수들의 덧셈 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/sum-of-some-probability-distribution/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-of-some-probability-distribution/</guid>
      <description>정리 확률 변수 $X_{1} , \cdots , X_{n}$ 들이 상호 독립이라고 하자. [1] 이항 분포: $X_i \sim \text{Bin} ( n_{i}, p)$ 이면 $$ \displaystyle \sum_{i=1}^{m} X_{i} \sim \text{Bin} \left( \sum_{i=1}^{m} n_{i} , p \right) $$ [2] 푸아송 분포: $X_i \sim \text{Poi}( m_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \text{Poi} \left( \sum_{i=1}^{n} m_{i} \right) $$ [3] 감마 분포: $X_i \sim \Gamma( k_{i}, \theta)$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \Gamma \left( \sum_{i=1}^{n} k_{i} , \theta \right) $$ [4] 카이제곱 분포: $X_i \sim \chi^2 ( r_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \chi ^2 \left( \sum_{i=1}^{n} r_{i} \right) $$ [5] 정규 분포: $X_i \sim N( \mu_{i}, \sigma_{i}^{2} )$ 이면 주어진 벡터 $(a_{1} ,</description>
    </item>
    
    <item>
      <title>유클리드 공간이란</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-an-euclidean-space/</link>
      <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-an-euclidean-space/</guid>
      <description>정의 자연수 $n \in \mathbb{N}$ 에 대해 실수 집합 $\mathbb{R}$ 의 데카르트 곱 $\mathbb{R}^{n}$ 을 유클리드 공간 이라고 한다. $$ \mathbb{R}^{n} = \mathbb{R} \times \cdots \times \mathbb{R} $$ $\mathbb{R}^{1}$ 을 실수 공간 혹은 수직선 이라고 한다. $\mathbb{R}^{2}$ 을 평면 이라고 한다. $\mathbb{R}^{3}$ 을 $3$차원 공간 이라고 한다. 이때 $\mathbb{N} := \left\{ 1, 2, 3, \cdots \right\}$은 자연수를 모두 모아놓은 집합을 의미한다. $\mathbb{R}$ 은 실수를 모두 모아놓은 집합을 의미한다. 설명 유클리드 공</description>
    </item>
    
    <item>
      <title>파동함수의 상대적 위상의 중요성</title>
      <link>https://freshrimpsushi.github.io/posts/importance-of-phases/</link>
      <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/importance-of-phases/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 파동함수는 코사인으로 표현할 수 있는 것은 물론 복소수 꼴로 표현할 수도 있다.$\psi=Re^{i\theta}$이 때 물리적으로 의미를 가지는 것은 $\psi$가 아니라 $ | \psi | ^2$이기 때문에 위상은 중요하지 않다.계산하면 어차피 결과에는 반영되지 않는 부분이다.즉, 아무렇게</description>
    </item>
    
    <item>
      <title>운동량 연산자와 위치의 교환자</title>
      <link>https://freshrimpsushi.github.io/posts/commutator-of-momentum-operator-and-position/</link>
      <pubDate>Thu, 03 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/commutator-of-momentum-operator-and-position/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 위치와 운동량 연산자의 교환자는 다음과 같다. **표준교환관계식$(\mathrm{canonical\ commutation\ relation})$ $$ [p,x]=-i\hbar $$ $$ [x,p]=i\hbar $$ 정규교환관계식, 정준교환관계식 등으로 부르기도 한다. 이름이 중요한 건 아니다.미분 표기를 아래와 같이 간단히 나타내겠다. $$ \frac{ d }{ d x}=D_{x},\quad \frac{ d f}{ d x}=f_{x}, \quad D_{x}f=f_{x} $$ 증</description>
    </item>
    
    <item>
      <title>운동량의 기댓값이 항상 실수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-of-momentum-is-always-real-number/</link>
      <pubDate>Thu, 03 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-of-momentum-is-always-real-number/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 운동량 연산자의 기댓값$ \langle p \rangle $은 항상 실수이다 증명 운동량의 기댓값은 아래와 같다.$ \displaystyle \langle p \rangle = \int \psi^{\ast} \left( \frac{\hbar}{i}\frac{\partial}{\partial x} \right) \psi dx$또한 운동량의 기댓값의 복소 켤레는 다음과 같다.$ \displaystyle \langle p \rangle ^{\ast}= \int \psi \left( \frac{\hbar}{-i}\frac{\partial}{\partial x} \right) \psi^{\ast} dx$두 값을 빼서 0이라면 증명 끝$ \begin{align*} \langle p \rangle -\langle p \rangle ^{\ast} &amp;amp;= \frac{\hbar}{i} \int \left( \psi^{\ast} \frac{\partial \psi}{\partial x}+\psi\frac{\partial \psi^{\ast}}{\partial x} \right) dx \\ &amp;amp;=\frac{\hbar}{i} \int</description>
    </item>
    
    <item>
      <title>등비수열의 부분합들도 등비수열임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/partial-sum-of-geometric-sequence-is-geometric-sequence/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partial-sum-of-geometric-sequence-is-geometric-sequence/</guid>
      <description>정리 등비수열 $a_n = a r^{n-1}$과 그 부분합 $\displaystyle S_n = \sum_{k=1}^{n} a_k$ 그리고 어떤 자연수 $m$ 에 대해 $A_n = S_{mn} - S_{m(n-1)}$ 은 등비수열이다. 설명 모르면 정말 고생한다. 예를 들어, 2의 거듭제곱을 세개씩 끊어 더한 수열을 생각해보면$(1 + 2+ 4)= 7 $, $(8 + 16 + 32)=56$, $(64+128+256)=448 \cdots$ 는 초항이 7이고 공비가 8인 등비수열이다. 이러한 성질은 등차수열도 가지고 있다. 원리야 사실 단순하</description>
    </item>
    
    <item>
      <title>등차수열의 부분합들도 등차수열임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/partial-sum-of-arithmetic-sequence-is-arithmetic-sequence/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partial-sum-of-arithmetic-sequence-is-arithmetic-sequence/</guid>
      <description>정리 등차수열 $a_n = a + (n-1)d$과 그 부분합 $\displaystyle S_n = \sum_{k=1}^{n} a_k $ 그리고 어떤 자연수 $m$ 에 대해 $A_n = S_{mn} - S_{m(n-1)} $은 등차수열이다. 설명 모르면 정말 고생한다. 예를 들어, 자연수를 세 개씩 끊어 더한 수열을 생각해보면$(1 + 2+ 3)= 6 $, $(4+5+6)=15$, $(7+8+9)=24 \cdots$ 는 초항이 6이고 공차가 9인 등차수열이다. 이러한 성질은 등비수열도 가지고 있다. 원리야 사실 단순하니까 한번 꼼</description>
    </item>
    
    <item>
      <title>싱크함수의 오일러 표현 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-representation-of-sinc-function/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-representation-of-sinc-function/</guid>
      <description>정의 $$ \text{sinc} x = {{\sin x} \over {x}} $$ 정리: 오일러 표현 $$ \displaystyle \text{sinc} x = \prod_{n=1}^{\infty} \left( 1 - {{x^2} \over { \pi^2 n^2}} \right) $$ 설명 싱크함수란 $\sin x$을 $x$로 나눈 함수로써, 별도의 이름이 붙은만큼 유용한 구석이 많은 함수다. 교과 과정부터 그 이름만 모를 뿐 극한이나 연속 파트에 종종 등장하기도 한다.물론 싱크함수는 $x=0$ 에서 정의되지 않지만 다들 잘 알듯 $\displaystyle \lim_{x \to 0} {{\sin x} \over {x}} = 1$ 이므로, 정말 엄</description>
    </item>
    
    <item>
      <title>오일러의 반사 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-eulers-reflection-formula/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-eulers-reflection-formula/</guid>
      <description>공식 정수가 아닌 $p$ 에 대해 $$ \displaystyle {\Gamma (1-p) \Gamma ( p )} = { {\pi} \over {\sin \pi p } } $$ 설명 감마함수를 이용한 공식 중 가장 유명한 공식이다. 반사 공식으로 얻을 수 있는 유용한 결과로는 $ \Gamma ( { 1 \over 2} ) = \sqrt{\pi}$ 이 있다. 그래서일까? 반사 공식이라는 이름 또한 $\frac{1}{2}$ 에 대해 반사 시킨다는 의미에서 붙었다고 한다. 유도 바이어슈트라스의 무한곱: $$ {1 \over \Gamma(p)} = p e^{\gamma p } \prod_{n=1}^{\infty} \left( 1 + {p</description>
    </item>
    
    <item>
      <title>제곱수의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/sum-of-square-number/</link>
      <pubDate>Fri, 28 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-of-square-number/</guid>
      <description>공식 $$\displaystyle \sum_{k=1}^{n} { k^2} = {{n(n+1)(2n+1)} \over {6}}$$ 유도 한 차수 더 높은 $k^3$와 $(k-1)^3$ 의 차를 생각해보자. $$ 1^3 - 0^3 = 3 \cdot 1^2 - 3 \cdot 1 + 1 \\ 2^3 - 1^3 = 3 \cdot 2^2 - 3 \cdot 2 + 1 \\ 3^3 - 2^3 = 3 \cdot 3^2 - 3 \cdot 3 + 1 \\ \vdots \\ n^3 - (n-1)^3 = 3n^2 - 3n + 1 $$ 양변을 각각 모두 더하면 $$ n^3 - 0^3 = 3 \sum_{k=1}^{n} { k^2} - 3 \sum_{k=1}^{n} { k} + n $$ 우리는 자연수의 합이 $\displaystyle \sum_{k=1}^{n} {k} = {{n(n+1)} \over {2}}$ 임을 알고 있다. 위의 식을 $\displaystyle \sum_{k=1}^{n} { k^2}$ 에 대해</description>
    </item>
    
    <item>
      <title>감마함수에 대한 바이어슈트라스의 무한곱</title>
      <link>https://freshrimpsushi.github.io/posts/weierstrasss-infinite-product-for-gamma/</link>
      <pubDate>Wed, 26 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weierstrasss-infinite-product-for-gamma/</guid>
      <description>정리 $$ \displaystyle {1 \over \Gamma(x)} = x e^{\gamma x } \lim_{n \to \infty} \prod_{k=1}^{n} \left( 1 + {x \over k} \right) e^{- {x \over k} } $$ $\gamma$ 는 오일러-마스케로니 상수다. 설명 $$ \displaystyle \Gamma(x) = \int_{0}^{\infty} t^{x-1} e^{-t} dt $$ 감마 함수는 위와 같이 정의되고, 오일러의 극한 공식에 의해 $$ \displaystyle \Gamma(x) = \lim_{n \to \infty} {{n^x n!} \over {x(x+1)(x+2) \cdots (x+n) }} $$ 이기도 하다. 여기서 한가지 더, 감마함수의 새로운 형태가 바로 바이어슈트라스의 무한곱이다. 이걸 배움으로써 우리는 감마함수</description>
    </item>
    
    <item>
      <title>실수의 조밀성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-density-of-real-numbers/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-density-of-real-numbers/</guid>
      <description>정리 두 실수 $a&amp;lt;b$ 에 대해 $a&amp;lt;r&amp;lt;b$ 를 만족하는 $r \in \mathbb{R}$ 이 존재한다 설명 실수상에선 그 어떤 구간을 생각하든 그 사이엔 반드시 또 다른 실수가 존재한다. 아무리 작게 쪼개더라도 그곳엔 또 쪼갤 수 있는 점이 있다는 말이다. 당연해보이지만 이는 당연하지 않을 뿐만 아니라 몹시 추상적인 성질이라는 것도 명심하자. 예로써 물리학에서 다루는 물질과 에너지조차도 작게 작게 쪼개</description>
    </item>
    
    <item>
      <title>해석학의 여러가지 급수판정법 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/series-convergence-test/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-convergence-test/</guid>
      <description>급수판정법들은 별도의 증명 없이 소개만 하고자 한다.증명하는 법 자체보단 팩트로써 잘 활용하는 것이 중요하기도 하고, 대개는 증명 과정도 지루하기 때문이다. 발산 판정법 $\displaystyle \lim _{ n\to \infty }{ { a }_{ n }} \ne 0$ 이면 $\displaystyle \sum _{ n=1 }^{ \infty }{ { a }_{ n }}$ 은 발산한다. 고등학교 때 접할 수 있는 유일한 판정법이다.쉬운만큼 수렴하는 것 자체를 판정할 수는 없는 것이 아쉽지만</description>
    </item>
    
    <item>
      <title>해석학에서 아르키메데스의 원리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-archimedean-principle/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-archimedean-principle/</guid>
      <description>정리 양수 $a$ 와 실수 $b$ 에 대해, $an&amp;gt;b$ 를 만족하는 자연수 $n$ 이 존재한다. 설명 어떤 $b$를 가져오더라도 항상 그보다는 큰 $a$ 의 $n$ 배수를 생각할 수 있다는 뜻이다. 쉽게 말하면 아무리 &amp;lsquo;작은 수라도 계속 더하면 계속 커진다&amp;rsquo;는 아주 상식적이고 당연한 원리다.부력의 원리, 유레카와는 상관이 전혀 없고 이름만 같을 뿐이다. 증명 Strategy: 증</description>
    </item>
    
    <item>
      <title>해석학의 세 가지 공리: 3 완비성 공리</title>
      <link>https://freshrimpsushi.github.io/posts/completeness-axioms/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/completeness-axioms/</guid>
      <description>공리1 집합 $E \subset \mathbb{R}$ 이 공집합이 아니고 $E$ 가 위로 유계면 상한 $\sup(E) &amp;lt; \infty$ 가 존재한다. 설명 체 공리와 순서 공리는 이미 알던 걸 어렵게 다시 썼지만 완비성 공리는 언뜻 보기에 그렇지가 않다. 우선 여기 등장하는 단어들에 대해서 정의가 필요할 것 같다. 정의 $E$ 의 모든 원소 $a$ 에 대해 $a \le M$ 이 성립하면 $E$를 위로 유계bounded above라 하한다. 이러한 조</description>
    </item>
    
    <item>
      <title>양자역학에서 운동량 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-momentum-operator/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-momentum-operator/</guid>
      <description>양자역학에서의 운동량 연산자는 아래와 같다. $$ p_{op}=\frac{\hbar}{i}\frac{\partial}{\partial x} $$ 유도 $$ \begin{align*} \left\langle p \right\rangle &amp;amp;= \left\langle m\frac{dx}{dt} \right\rangle \\ &amp;amp;= m\frac{d}{dt} \left\langle x \right\rangle \\ &amp;amp;= m\frac{d}{dt} \int_{-\infty}^{+\infty}\psi^\ast x \psi \ dx \\ &amp;amp;= m\int_{-\infty}^{+\infty} \left( \frac{\partial{\psi}^\ast}{\partial t}x\psi + \psi ^{\ast} x \frac{\partial \psi}{\partial t} \right)dx \end{align*} $$ 1차원에서 슈뢰딩거 방정식과 그 복소 켤레는 아래와 같다. $$ \begin{equation*} \begin{aligned} i\hbar \frac{\partial \psi}{\partial t} &amp;amp;= -\frac{{\hbar}^2}{2m}\frac{\partial ^2 \psi}{\partial x^2}+U\psi \\ \frac{\partial \psi}{\partial t}&amp;amp;=-\frac{\hbar}{2mi}\frac{\partial ^2 \psi}{\partial x^2}+\frac{U\psi}{i\hbar} \end{aligned} \quad \text{and} \quad \begin{aligned} -i\hbar \frac{\partial \psi ^{\ast}}{\partial t} &amp;amp;=-\frac{{\hbar}^2}{2m}\frac{\partial ^2 \psi ^{\ast}}{\partial x^2}+U^{\ast}\psi ^{\ast} \\ \frac{\partial \psi ^{\ast}}{\partial t} &amp;amp;= \frac{\hbar}{2mi}\frac{\partial ^2 \psi ^{\ast}}{\partial x^2}-\frac{U^{\ast}\psi ^{\ast}}{i\hbar} \end{aligned} \end{equation*} $$ 위의 식에 대입하면 다음</description>
    </item>
    
    <item>
      <title>전자가 핵의 성분이 될 수 없음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/the-electrons-could-not-be-contained-inside-the-nucleus/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-electrons-could-not-be-contained-inside-the-nucleus/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $10^{-14}m$ 정도의 크기를 가지는 핵은 $1MeV \sim10MeV$범위의 에너지를 가지는 전자를 방출한다.핵물리의 초기 시절에는 전자가 핵 안에 존재한다고 믿었다.불확정성 원리를 이용하여 그런 에너지를 가지는 전자는 핵 내부에 얽매일 수 없음을 보여라.(가시오로비츠 양자역학 2장 연습문제 21번)전자</description>
    </item>
    
    <item>
      <title>해석학의 세 가지 공리: 1 체 공리</title>
      <link>https://freshrimpsushi.github.io/posts/field-axioms/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/field-axioms/</guid>
      <description>공리1 실수 $a,b,c \in \mathbb{R}$ 와 연산 $+,\cdot$ 에 대해 다음의 성질들이 성립한다고 받아들이자. (A1) 덧셈에 대한 폐쇄성: $a+b \in \mathbb{R}$ (A2) 덧셈에 대한 결합법칙: $(a+b) + c = a + (b+c)$ (A3) 덧셈에 대한 교환법칙: $ a+ b= b + a$ (A4) 덧셈에 대한 항등원: 모든 실수 $a$ 에 대해, $a+0=0+a=a$를 만족하는 $0$ 이 유일하게 존재한다. (A5) 덧셈에 대한 역원: 모든 실수 $a$ 에 대해, $a + (-a) = (-a)</description>
    </item>
    
    <item>
      <title>해석학의 세 가지 공리: 2 순서 공리</title>
      <link>https://freshrimpsushi.github.io/posts/order-axioms/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order-axioms/</guid>
      <description>공리1 실수 $ a,b,c \in \mathbb{R}$ 에 대해, 다음의 성질들이 성립한다고 받아들이자. 삼분성: 주어진 $a,b$ 에 대해서, $a&amp;lt;b$ 혹은 $a&amp;gt;b$ 혹은 $a=b$ 이어야한다 추이성: $a&amp;lt;b$ 이고 $b&amp;lt;c$이면 $a&amp;lt;c$ 가산성: $a&amp;lt;b$ 이고 $c\in \mathbb{R}$ 이면 $a+ c&amp;lt; b + c$ 승산성: $a&amp;lt;b$ 이고 $c&amp;gt;0$ 이면 $ac&amp;lt; bc$, 혹은 $c&amp;lt;0$ 이면 $ac&amp;gt; bc$ 설명 단어들은 상당히 옛날것이지만 너무 당연한 사실들이라 이해하는데는 문제가 없을 것이다. 체</description>
    </item>
    
    <item>
      <title>광자의 속도가 씨일 때 정지 질량이 0임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/rest-mass-of-photon-is-zero-when-light-speed-is-c/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rest-mass-of-photon-is-zero-when-light-speed-is-c/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 1. 상대론적 에너지, 운동량과 속도의 관계 $p=\gamma m_0 v $$ E=\gamma m_0 c^2 $$ \implies \gamma m_0=\dfrac{E}{c^2}$두 식을 연립하면$p=\dfrac{E}{c^2}v $$ \implies v=\dfrac{pc^2}{E}$2. 입자의 에너지와 운동량의 상대론적 관계 $E=\sqrt{{m_0}^2c^4+p^2c^2}$3. 1과 2에 의해서 $ \displaystyle v=\frac{pc^2}{\sqrt{{m_0}</description>
    </item>
    
    <item>
      <title>컴프턴 산란</title>
      <link>https://freshrimpsushi.github.io/posts/compton-scattering/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compton-scattering/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 컴프턴 산란 $\lambda$를 입사하는 빛의 파장, $\lambda&#39;$을 산란된 광자의 파장이라고 하자. 그러면 아래의 식이 성립한다. $$ \lambda&#39; -\lambda = \frac{h}{m_{e}c}(1-\cos\theta) $$ 이때 $h$는 플랑크 상수, $m_{e}$는 전자의 질량, $c$는 빛의 속도, $\theta$는 산란각이다. 에너지에 대해서 나타</description>
    </item>
    
    <item>
      <title>등비수열의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-geometric-series-formula/</link>
      <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-geometric-series-formula/</guid>
      <description>공식 초항이 $a$ 고 공비가 $r$인 등비수열 $a_{n} = a r^{n-1}$ 에 대해, $$ \displaystyle \sum_{k=1}^{n} a_{k}= {{a (1- r^{n} ) } \over {1-r}} $$ 증명 $\displaystyle S= \sum_{k=1}^{n} a_{k}$ 라고 하자. 그러면 $$ S= a + ar + \cdots + ar^{n-2} + ar^{n-1} $$ 양변에 $r$을 곱하면 $$ rS= ar + a r^2 + \cdots + ar^{n-1} + ar^{n} $$ 여기서 위의 두 식에 대해서 양변을 빼면 $$ S - rS = (1-r)S = a- a r^n $$ 오른쪽의 두 식을 $1-r$로 나누면 $$ S=\sum_{k=1}^{n} a_{k}= {{a (1- r^{n} ) } \over {1-r}} $$ ■ 설명 등차수열의 합</description>
    </item>
    
    <item>
      <title>등차수열의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-arithmetic-series-formula/</link>
      <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-arithmetic-series-formula/</guid>
      <description>공식 🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 초항이 $a$ 고 공차가 $d$ 인 등차수열 $a_{n} = a+(n-1)d $ 에 대해 $$ \displaystyle \sum_{k=1}^{n} a_{k}= {{n \left\{ 2a + (n-1)d \right\} } \over {2}} $$ 설명 처음에 한 번 보고는 다시 이 형태로 쓸 일이 없긴 한 급수지만 이 모양을 잊되 증명을 잊어서는 안 된다. 증명이 쉽고 간단하다고 해도 한번정도는 반드시 손으로 직접 쓰면서 익혀보도록 하자. 등차수열의 합 중 가장 자주</description>
    </item>
    
    <item>
      <title>직교좌표계에서의 속도와 가속도</title>
      <link>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-cartesian-coordinate-system/</link>
      <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-cartesian-coordinate-system/</guid>
      <description>직교좌표계에서의 속도와 가속도 $$ \begin{align*} \mathbf{v}&amp;amp;=\dot{x} \hat{\mathbf{x}} + \dot{y} \hat{\mathbf{y}} +\dot{z} \hat{\mathbf{z}} \\ \mathbf{a} &amp;amp;= \ddot{x} \hat{\mathbf{x}} + \ddot{y} \hat{\mathbf{y}} +\ddot{z}\hat{\mathbf{z}} \end{align*} $$ 유도 직교좌표계에서 속도와 가속도를 구하는건 아주 간단하다. 속도 $\mathbf{r}$을 $t$로 미분하면 다음과 같다. $$ \mathbf{v}=\frac{d}{dt}(x\hat{\mathbf{x}} +y\hat{\mathbf{y}}+z\hat{\mathbf{z}})=\dot{x} \hat{\mathbf{x}} + x\dot{\hat{\mathbf{x}}}+\dot{y} \hat{\mathbf{y}} + y\dot{\hat{\mathbf{y}}} +\dot{z} \hat{\mathbf{z}} + z\dot{\hat{\mathbf{z}}} $$ 직교좌표계의 단위벡터는 시간에 무관하므로 $dot{\hat{\mathbf{x}}}=\dot{\hat{\mathbf{y}}}=\dot{\hat{\mathbf{z}}} = 0$이고, 따라서 다음과 같다. $$ \mathbf{v} = \dot{x} \hat{\mathbf{x}} + \dot{y} \hat{\mathbf{y}} + \dot{z} \hat{\mathbf{z}}</description>
    </item>
    
    <item>
      <title>기울기가 m인 원의 접선의 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/finding-the-equation-of-tangent-of-a-circle-with-a-slope-of-m/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finding-the-equation-of-tangent-of-a-circle-with-a-slope-of-m/</guid>
      <description>공식 원 $x^{2}+y^{2}=r^{2}$의 기울기가 $m$인 접선의 방정식은 다음과 같다. $$ y=mx \pm r\sqrt{m^{2}+1} $$ 증명 기울기가 $m$인 직선의 방정식을 $y=mx+n$이라고 하자. 원의 방정식에 대입하고 x에 대해서 정리하면 $$ \begin{align*} x^2+(mx+n)^2&amp;amp;=r^2 \\ x^2+m^2x^2+2mnx+n^2-r^2&amp;amp;=0 \\ (1+m^2)x^2+2mnx+n^2-r^2&amp;amp;=0 \end{align*} $$ 원과 직선이 접하므로 판별식$D=0$이다. $$ \begin{align*} D&amp;amp;=(2mn)^2-4(1+m^2)(n^2-r^2) \\ &amp;amp;= 4m^2n^2-4(n^2-r^2+m^2n^2-m^2r^2) \\ &amp;amp;= 4m^2n^2-4n^2+4r^2-4m^2n^2+4m^2r^2 \\ &amp;amp;= -4(n^2-r^2-m^2r^2)=0 \end{align*} $$ 따라서 $$ \begin{align*} &amp;amp;&amp;amp;n^2 &amp;amp;=r^2m^2+r^2=r^2(m^2+1) \\</description>
    </item>
    
    <item>
      <title>쌍곡함수의 미분법</title>
      <link>https://freshrimpsushi.github.io/posts/derivatives-of-hyperbolic-function/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivatives-of-hyperbolic-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $$ \displaystyle \left( \sinh x \right)&#39; = \cosh x $$ $$ \displaystyle \left( \cosh x \right)&#39; = \sinh x $$ $$ \displaystyle \left( \tanh x \right)&#39; = \text{sech}^{2} x $$ 전략: 쌍곡함수의 미분법은 사실 증명할 것도 외울 것도 별로 없다. 증명은 그냥 단순히 정의를 이용할 뿐이고 모양새도 삼각함수에서 부호만 뗀 정도기 때문이다. 하이퍼보릭 사인에 대한 증명법으로 하이퍼볼릭 코사인의 도함수도 쉽게</description>
    </item>
    
    <item>
      <title>역삼각함수의 미분법</title>
      <link>https://freshrimpsushi.github.io/posts/derivatives-of-inverse-trigonometric-function/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivatives-of-inverse-trigonometric-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $$ \leqalignno{ \left( \sin^{-1}x \right)&#39; =&amp;amp; {{1} \over {\sqrt{1-x^2}}} &amp;amp;(a) \\ \left( \cos^{-1}x \right)&#39; =&amp;amp; -{{1} \over {\sqrt{1-x^2}}} &amp;amp; (b) \\ \left( \tan^{-1}x \right)&#39; =&amp;amp; {{1} \over {1+x^2}} &amp;amp; (c)} $$ 각각 아크사인, 아크코사인, 아크탄젠트 로 읽는다. 세상에 이런 것도 미분이 되나 싶지만 알고보면 생각보다 꽤 단순하다. 우변을 보면 알겠지만 도함수들의 모양이 그닥 생소하거나 복잡하지가 않다. 삼각함수와는 전혀 상관 없을</description>
    </item>
    
    <item>
      <title>원 위의 한 점에서의 접선의 방정식 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/finding-the-equation-of-a-tangent-line-at-point-on-a-circle/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finding-the-equation-of-a-tangent-line-at-point-on-a-circle/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 원$x^2+y^2=r^2$위의 한 점$(x_1,y_1)$에서의 접선의 방정식을 구해보자.$y_1\neq 0$인 경우와 $y_1=0$인 경우로 나눌 수 있다.1. $y_1\neq 0$인 경우 원의 중심에서 점까지의 기울기가 $\displaystyle \frac{y_1}{x_1}$이고 접선과 수직이므로 접선의</description>
    </item>
    
    <item>
      <title>곱셈공식 표</title>
      <link>https://freshrimpsushi.github.io/posts/table-of-product-formula/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/table-of-product-formula/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 자주쓰이는 곱셈공식들을 소개한다. $1. $ $\begin{align*} (a+b)^2=a^2+2ab+b^2 \\ (a-b)^2=a^2-2ab+b^2 \end{align*} $$ 2. $ $(a+b)(a-b)=a^2-b^2 $$ 3. $ $\begin{align*} (a+b)^3=a^3+3a^2b+3ab^2+b^3 \\ (a-b)^3=a^3-3a^2b+3ab^2-b^3 \end{align*} $$ 4. $ $(a+b+c)^2=a^2+b^2+c^2+2ab+2bc+2ca $$ 5. $ $\begin{align*} (a+b)(a^2-ab+b^2)=a^3+b^3 \\ (a-b)(a^2+ab+b^2)=a^3-b^3 \end{align*}$</description>
    </item>
    
    <item>
      <title>구좌표계에서 속도와 가속도</title>
      <link>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-sperical-coordinate-system/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-sperical-coordinate-system/</guid>
      <description>구좌표계에서 속도와 가속도 $$ \begin{align*} \mathbf{v} &amp;amp;=\dot{r} \hat {\mathbf{r}} +r \dot{\theta} \hat{ \boldsymbol{\theta}}+ r \dot{\phi} \sin{\theta} \hat{ \boldsymbol{\phi}} \\ \mathbf{a} &amp;amp;= (\ddot{r}-r\dot\theta^2-r\dot\phi^2\sin^2\theta)\hat{\mathbf{r}}+(r\ddot\theta+2\dot{r}\dot\theta-r\dot\phi^2\sin\theta\cos\theta)\hat{\boldsymbol{\theta}} \\ &amp;amp;\quad+(r\ddot\phi\sin\theta+2\dot{r}\dot\phi\sin\theta+2r\dot\theta\dot\phi\cos\theta)\hat{\boldsymbol{\phi}} \end{align*} $$ 유도 구면좌표계에서 단위 벡터는 아래와 같다. $$ \begin{align*} \hat{\mathbf{r}} &amp;amp;= \cos \phi \sin \theta \hat{\mathbf{x}} + \sin \phi \sin \theta \hat{\mathbf{y}} + \cos\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\theta}} &amp;amp;= \cos\phi \cos\theta \hat{\mathbf{x}} + \sin\phi \cos\theta \hat{\mathbf{y}} - \sin\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\phi}} &amp;amp;= -\sin\phi \hat{\mathbf{x}} + \cos\phi \hat{\mathbf{y}} \end{align*} $$ 이제 구면좌표계에서 속도와 가속도를 차례로 구해보자. 속도는 위치를 시간에 대해 미분해서, 가속도는 속도를 시간에 대해 미분해서</description>
    </item>
    
    <item>
      <title>그린의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-greens-theorem/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-greens-theorem/</guid>
      <description>정리 곡선 $\mathcal{C}$ 가 평면 상의 영역 $S = [a,b] \times [c,d]$ 안에서 시계반대방향을 가지고 조각마다 스무스한 단순 폐경로라고 하자. 함수 $P,Q : \mathbb{R}^2 \to \mathbb{R}$ 이 $\mathcal{C}$ 에서 연속이고 그 도함수도 연속이면 $$ \displaystyle \int_{\mathcal{C}} (Pdx + Qdy) = \iint_{S} (Q_{x} - P_{y}) dx dy $$ 설명 경로적분을 면적분으로 바꿔주는 정리로 생각하면 될 것 같다. 케빈-스톡스 정리에서 평면에 국한시킨 따름정리로도 많이 알려져있다. 더 일반화된</description>
    </item>
    
    <item>
      <title>푸비니의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fubinis-theorme/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fubinis-theorme/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 2차원 영역 $R : [a,b] \times [c,d]$ 에 대해 함수 $f : R \to \mathbb{R}$ 을 정의하자. $f(x,\cdot)$ 가 $[c,d]$ 에서 적분가능하고 $f(\cdot,y)$ 가 $[a,b]$ 에서 적분가능하며 $f$ 가 $R$ 에서 적분가능하면 $$ \displaystyle \iint _{R} f dA = \int_{a}^{b} \int_{c}^{d} f(x,y) dy dx = \int_{c}^{d} \int_{a}^{b} f(x,y) dx dy $$ 적분영역인 $R$ 은 당연히 Rectangle에서 나온 것이다.해석학이 늘 그렇듯 말이 너무 길어서 읽기 싫은 여러분</description>
    </item>
    
    <item>
      <title>ML 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-ml-lemma/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-ml-lemma/</guid>
      <description>정리 1 함수 $f$ 가 적분경로 $\mathscr{C}: z = z(t), t \in [a,b]$ 에서 조각마다 연속라고 하자. 양수 $\displaystyle L = \int_{a}^{b} |z&#39;(t)| dt$ 는 $\mathscr{C}$ 의 길이고, $\mathscr{C}$ 상의 모든 점에 대해 $|f(z)| \le M$ 을 만족하는 양수 $M$ 이 존재한다면 $$ \left| \int_{\mathscr{C}} f(z) dz \right| \le ML $$ 증명 함수 $z&#39;: [a,b] \to \mathbb{C}$ 에 대해 $\displaystyle \left| \int_{a}^{b} z&#39;(t) dt \right| = r$ 이라 하자. $r \ne 0$ 이면 $\displaystyle \int_{a}^{b} z&#39;(t) dt = r e^{i \theta}$ 로 나타낼 수 있다. 그러면 $\theta$ 는 상수이므로 $$ \displaystyle r = \int_{a}^{b} e^{- i \theta} z&#39;(t) dt \le \int_{a}^{b} \left| e^{-</description>
    </item>
    
    <item>
      <title>원통좌표계에서 속도와 가속도</title>
      <link>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-cylinderical-coordinate-system/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-cylinderical-coordinate-system/</guid>
      <description>원통좌표계에서 속도와 가속도 $$ \begin{align*} \mathbf{v}&amp;amp;=\dot{r} \hat{\mathbf{r}} + r \dot{\phi} \hat{\boldsymbol{\phi}}+\dot{z} \hat{\mathbf{z}} \\ \mathbf{a} &amp;amp;= (\ddot r -r\dot{\phi} ^2)\hat{\mathbf{r}} + (2\dot{r} \dot{\phi} + r\ddot{\phi})\hat{\boldsymbol{\phi}} + \ddot{z}\hat{\mathbf{z}} \end{align*} $$ 유도 원통좌표계에서 단위 벡터는 아래와 같다. $$ \begin{align*} \boldsymbol{\rho}&amp;amp;=x\hat{\mathbf{x}}+y \hat{\mathbf{y}} +z\hat{\mathbf{z}}=r\hat{\mathbf{r}} +z\hat{\mathbf{z}} \\ \hat{\mathbf{r}} &amp;amp;= \hat{\mathbf{r}}(\phi) = \cos\phi \hat{\mathbf{x}} + \sin\phi \hat{\mathbf{y}} \\ \hat{\boldsymbol{\phi}} &amp;amp;= \hat{\mathbf{r}}(\phi+\pi/2) = -\sin\phi \hat{\mathbf{x}} + \cos\phi \hat{\mathbf{y}} \\ \hat{\mathbf{z}} &amp;amp;= \hat{\mathbf{z}} \end{align*} $$ 속도는 위치를 시간에 대해 미분해서, 가속도는 속도를 시간에 대해 미분해서 구할 수 있다. 참고로 $\dot{r}$은 [알 돗(도트)]이</description>
    </item>
    
    <item>
      <title>코시-리만 방정식의 역이 성립하는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/condition-for-converse-of-cauchy-riemann-equation-hold/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/condition-for-converse-of-cauchy-riemann-equation-hold/</guid>
      <description>정리 함수 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 실수값을 가지는 함수 $u,v$ 에 대해 $f(z) = f(x+iy) = u(x,y) + iv(x,y)$ 로 나타날 수 있고 $u,v$ 는 $x,y$ 에 대한 연속일차편도함수가 존재하는 동시에 연립미분방정식 $$ \begin{cases} u_{x} (x,y) = v_{y} (x,y) \\ u_{y} (x,y) = -v_{x} (x,y) \end{cases} $$ 을 만족한다면, $f$ 는 $A$ 에서 해석적이다. 설명 해석학은 항상 이렇게 말이 길어서 읽기도 싫은 게 문제다. 간단하게 요약하자면, 코시-리만 방정식의 역이 성립하</description>
    </item>
    
    <item>
      <title>피타고라스의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pythagorean-theorem/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pythagorean-theorem/</guid>
      <description>정리 직각삼각형의 빗변의 길이를 $c$, 나머지 두 변의 길이를 $a,b$라고 하면 아래의 식이 성립한다. $$ a^2 + b^2 = c^2 $$ 설명 여기저기서 쓰이는 건 둘째치고 그 자체만으로도 매우 실용적인 정리다. 가장 오래된 &amp;lsquo;증명&amp;rsquo;을 남긴 것이 피타고라스기 때문에 그 이름이 붙었지만, 실제로 문명을 이루었다고 할 수 있는 고대인들 대부분 팩트</description>
    </item>
    
    <item>
      <title>극좌표계에서 속도와 가속도</title>
      <link>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-polar-coordinate-system/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/velocity-and-acceleration-in-polar-coordinate-system/</guid>
      <description>극좌표계에서 속도와 가속도 $$ \begin{align*} \mathbf{v}&amp;amp;=\dot{r} \hat{\mathbf{r}} + r \dot{\theta} \hat{\boldsymbol{\theta}} \\ \mathbf{a}&amp;amp;= (\ddot r -r\dot{\theta} ^2)\hat{\mathbf{r}} + (2\dot{r} \dot{\theta} + r\ddot{\theta})\hat{\boldsymbol{\theta}} \end{align*} $$ 유도 극좌표계에서 단위 벡터는 아래와 같다. $$ \begin{align*} &amp;amp;&amp;amp; \mathbf{r}&amp;amp;=r\hat{\mathbf{r}}=x\hat{\mathbf{x}} + y \hat{\mathbf{y}} \\ \implies &amp;amp;&amp;amp; \hat{\mathbf{r}} &amp;amp;= \frac{x}{r}\hat{\mathbf{x}} +\frac{y}{r} \hat{\mathbf{y}}=\cos\theta \hat{\mathbf{x}} + \sin\theta \hat{\mathbf{y}} = \hat{\mathbf{r}} (\theta) \\ {} \\ &amp;amp;&amp;amp; \hat \theta &amp;amp;= \hat{\mathbf{r}}(\theta+\pi/2)= -\sin\theta \hat{\mathbf{x}} + \cos\theta \hat{\mathbf{y}} \end{align*} $$ 속도는 위치를 시간에 대해 미분해서, 가속도는 속도를 시간에 대해 미분해서 구할 수 있다. 참고로 $\dot{r}$은 [알 돗(도트)]이라</description>
    </item>
    
    <item>
      <title>드 무아브르의 정리를 이용한 삼각함수의 삼배각 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-triple-angle-formula-using-de-moivres-theorem/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-triple-angle-formula-using-de-moivres-theorem/</guid>
      <description>공식 $$ \sin 3\theta = 3 \sin \theta - 4 \sin^{3} {\theta} \\ \cos 3\theta = 4 \cos^{3} {\theta} - 3 \cos \theta $$ 설명 기존의 변형 공식들은 보통 삼각함수의 덧셈정리를 여러번 써서 얻을 수 있었다. 예를 들어 배각 공식은 $\sin(a + b ) = \sin {a} \cos {b} + \sin {b} \cos {a}$ 에서 $b=a$ 를 대입해 $\sin(a+a) = \sin{2a} = 2 \sin{a} \cos{a}$ 을 얻는 식이다. 물론 이런 방식으로 삼배각, 사배각 공식을 유도하는 것 자체는 아무런 문제가 없다. 하지만 복소해석을 이용하</description>
    </item>
    
    <item>
      <title>복소해석에서 삼각함수와 쌍곡함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-of-trigonometric-and-hyperbolic-in-complex-analysis/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-of-trigonometric-and-hyperbolic-in-complex-analysis/</guid>
      <description>정의 1 쌍곡함수 $\sinh$ 와 $\cosh$ 를 아래와 같이 정의하자. $$ \displaystyle \sinh z := { {e^{z} - e^{-z}} \over 2 } \\ \cosh z := { {e^{z} + e^{-z}} \over 2 } $$ 정리 2 $$ \begin{align*} \sinh (iz) =&amp;amp; i \sin z \\ \sin (iz) =&amp;amp; i \sinh z \\ \cosh (iz) =&amp;amp; \cos z \\ \cos (iz) =&amp;amp; \cosh z \end{align*} $$ 설명 쌍곡함수를 처음 접할때 가장 이해가 되지 않는 것이 바로 &amp;lsquo;왜 이런 정의를 쓰는가&amp;rsquo; 하는 점이다. 실수 상에서 삼각함수는 단위원의 삼각비로 정</description>
    </item>
    
    <item>
      <title>복소해석에서 삼각함수와 지수함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-of-trigonometric-and-exponential-in-complex-analysis/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-of-trigonometric-and-exponential-in-complex-analysis/</guid>
      <description>정리 1 $$ \displaystyle \sin z = { {e^{iz} - e^{-iz}} \over 2 i } \\ \cos z = { {e^{iz} + e^{-iz}} \over 2 } $$ 설명 사실 정리라기보단 그냥 정의라고 생각해도 좋다. 이렇게 정의를 했을 때 기존에 밝혀진 정리들과 충돌이 없다 것을 보이기 위함이다. 증명 또한 이미 오일러 공식으로 알고 있던 것을 삼각함수에 맞게 정리한 것 뿐이다. 증명 오일러 공식 $\displaystyle { e }^{ ix }= \cos x + i \sin x $ 에 의해 $$ \displaystyle \begin{cases} { e }^{ iz }=</description>
    </item>
    
    <item>
      <title>코시-리만 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/the-cauchy-riemann-equations/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-cauchy-riemann-equations/</guid>
      <description>정리 1 함수 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 $\mathscr{R}$ 에서 해석적이라고 하자. 만약 실함수 $u,v$ 에 대해 $$ f(z) = f(x+iy) = u(x,y) + iv(x,y) $$ 이라면 $u,v$ 는 $x,y$ 에 대한 일차편도함수가 존재하며 $\mathscr{R}$ 상의 모든 점에서 아래의 연립미분방정식을 만족시킨다. $$ \begin{cases} u_{x} (x,y) = v_{y} (x,y) \\ u_{y} (x,y) = -v_{x} (x,y) \end{cases} $$ 요약 코시-리만 방정식은 아래와 같이 요약된다. $$ \begin{align*} f&#39;(z) =&amp;amp; u_x + i v_x \\ =&amp;amp; v_y - i u_y \\ =&amp;amp; u_x -i u_y \\ =&amp;amp; v_y + i v_x \end{align*} $$</description>
    </item>
    
    <item>
      <title>오일러-마스케로니 상수의 수렴성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-convergence-of-euler-mascheroni-constant/</link>
      <pubDate>Sun, 16 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-convergence-of-euler-mascheroni-constant/</guid>
      <description>정리 $$ \gamma = \lim_{n \to \infty} \left( \sum_{k=1}^{n} \left( { 1 \over k } \right) - \ln{n} \right) = 0.577215664 \cdots $$ 설명 리만-제타 함수와 연관짓자면 $\gamma$ $0$번째 스틸체스 상수 $\gamma_{0}$ 기도 하다. $\gamma$ 는 짧게는 그냥 오일러 상수 라고도 불리는 수로써, 감마 함수와 깊은 관계가 있다. 정확한 값은 둘째치고, 일단 수렴을 하기는 하는걸까? $\ln{n}$ 와 조화급수 $\displaystyle \sum_{k=1}^{n} \left( { 1 \over k } \right)$ 가 발산하므로 $$ \lim_{n \to \infty} \left( \sum_{k=1}^{n} \left( { 1 \over k } \right) -</description>
    </item>
    
    <item>
      <title>직교좌표계의 단위벡터로 표현한 구면좌표계의 단위벡터</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-cartesian-coordinate-system-unit-vectors-and-spherical-coordinate-system-unit-vectors/</link>
      <pubDate>Sun, 16 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-cartesian-coordinate-system-unit-vectors-and-spherical-coordinate-system-unit-vectors/</guid>
      <description>구면좌표계의 단위벡터 $$ \begin{align*} \hat{\mathbf{r}} &amp;amp;= \cos\phi \sin\theta\hat{\mathbf{x}} + \sin\phi \sin\theta\hat{\mathbf{y}} + \cos\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\theta}} &amp;amp;= \cos\phi \cos\theta \hat{\mathbf{x}} + \sin\phi \cos\theta \hat{\mathbf{y}} - \sin\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\phi}} &amp;amp;= -\sin\phi \hat{\mathbf{x}} + \cos\phi \hat{\mathbf{y}} \end{align*} $$ 유도 $\hat{\mathbf{r}}$을 먼저 구한 뒤 이를 이용해서 나머지 둘을 구한다. 반지름 방향 단위벡터 $\hat{\mathbf{r}}$ $$ \hat{\mathbf{r}}=r\hat{\mathbf{r}}=x\hat{\mathbf{x}}+y\hat{\mathbf{y}}+z\hat{\mathbf{z}} $$ 이므로 양변을 $r$로 나누면 다음과 같다. $$ \begin{align*} \hat{\mathbf{r}}&amp;amp;=\frac{x}{r}\hat{\mathbf{x}}+\frac{y}{r}\hat{\mathbf{y}}+\frac{z}{r}\hat{\mathbf{z}} \\ &amp;amp;= \frac{x}{r \sin\theta}\sin\theta\hat{\mathbf{x}}+\frac{y}{r \sin\theta}\sin\theta\hat{\mathbf{y}}+\cos\theta\hat{\mathbf{z}} \\ &amp;amp;= \cos\phi \sin\theta \hat{\mathbf{x}} + \sin\phi \sin\theta\hat{\mathbf{y}} + \cos\theta\hat{\mathbf{z}} =\hat{\mathbf{r}}(\theta,\phi) \end{align*} $$ 극각 방향 단위벡터 $\hat{\boldsymbol{\theta}}$ $\ha</description>
    </item>
    
    <item>
      <title>감마함수에 대한 오일러의 극한 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-eulers-limit-formula-for-gamma/</link>
      <pubDate>Sat, 15 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-eulers-limit-formula-for-gamma/</guid>
      <description>공식 $$ \Gamma(x) = \lim_{n \to \infty} {{n^x n!} \over {x(x+1)(x+2) \cdots (x+n) }} $$ 설명 기존에 알고 있던 감마함수는 $\displaystyle \Gamma(x) = \int_{0}^{\infty} t^{x-1} e^{-t} dt$ 의 모양이다. 전혀 닮지 않았지만 두 표현이 완전히 같음을 1729년에 오일러가 증명해냈다. 이 글에서 소개하려는 유도는 원래보다는 조금 약식이지만 이해하는데에 본질적인 문제는 없을 것이다. 유도 $\displaystyle \Gamma_{n}(x) := \int_{0}^{n} t^{x-1} \left( 1 - { t \over n } \right) ^{n} dt$ 이라고 하면 $\displaystyle e^{-t} = \lim_{n \to \infty }</description>
    </item>
    
    <item>
      <title>스칼라 삼중곱</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-scalar-triple-product/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-scalar-triple-product/</guid>
      <description>스칼라 삼중곱 $$ \mathbf{A}\cdot (\mathbf{B} \times \mathbf{C} ) $$ 설명 위 식을 스칼라 삼중곱scalar triple product이라 한다. 스칼라 삼중곱은 벡터 3개를 곱하는 연산 중에서 결과가 스칼라인 것을 말한다. 결과가 벡터인 것은 벡터 삼중곱이라 한다. 결과가 스칼라로 나오기 위해서는 우선 두 벡터를 외적해서 나온 벡터와 다른 벡터를 내적해야한다. 스칼라 삼중곱의 특징을 하나씩 살펴</description>
    </item>
    
    <item>
      <title>적분을 이용한 타원의 넓이 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/finding-area-of-ellipse-using-integral/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finding-area-of-ellipse-using-integral/</guid>
      <description>공식 타원 $\displaystyle {x^2 \over a^2} + {y^2 \over b^2} = 1$ 의 넓이는 $ab \pi$ 이다. 설명 특히 $a=b=r$, 즉 반지름이 $r$ 인 원 $x^2 + y^2=r^2$ 의 넓이는 익히 아는대로 $r^2 \pi$ 다. 증명 타원의 넓이를 구하기 위해선 색칠된 영역의 넓이만 구하면 충분하다. 영역의 넓이는 $$ \displaystyle \int _{0} ^{a} \sqrt{b^2-{b^2 \over a^2} x^2} dx $$ 로 주어진다. $x = a \sin \theta$ 로 치환을 하면 $$ \begin{align*} \int _{0} ^{ \pi \over 2 } b \sqrt{1 - \sin ^ 2 \theta } a \cos \theta d \theta =&amp;amp; ab \int _{0} ^{ \pi \over 2 } \cos</description>
    </item>
    
    <item>
      <title>분리벡터</title>
      <link>https://freshrimpsushi.github.io/posts/separation-vector/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separation-vector/</guid>
      <description>정의1 원천점에서 관찰점까지의 벡터를 분리벡터separation vector라 한다. $$ \boldsymbol{\eta} = \mathbf{r} - \mathbf{r}&#39; $$ 설명 원천벡터source vector $\mathbf{r}&#39;$: 전하나 전류가 있는 곳. 즉, 전자기장을 만드는 근원지의 좌표를 나타내는 벡터이다. 위치벡터position vector $\mathbf{r}$: 전기장 $\mathbf{E}$나 자기장 $\mathbf{B}$ 등을 측정하는 곳의 좌표를 나타내는 벡터이</description>
    </item>
    
    <item>
      <title>분리벡터의 크기의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-of-separation-vector/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-of-separation-vector/</guid>
      <description>공식 분리벡터 $\boldsymbol{\eta}$의 크기의 $n$ 제곱, $\eta ^{n}$의 그래디언트는 다음과 같다. $$ \nabla (\eta^n)=n\eta^{n-1}\hat{\boldsymbol{\eta}} $$ 다항함수의 미분과 같은 방식으로 계산한 뒤에 단위벡터인 $\hat{\boldsymbol{\eta}}$만 붙여주면 된다. 설명 분리벡터는 $\boldsymbol{\eta}=\mathbf{r}-</description>
    </item>
    
    <item>
      <title>수직선위의 내분점과 외분점 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/internally-dividing-point-externally-dividing-point/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/internally-dividing-point-externally-dividing-point/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 수직선위의 점$A(x_1)$와 점$B(x_2)$를 $m:n$으로 내분하는 점$P(x)$의 좌표는 $\displaystyle x=\frac{mx_2+nx_1}{m+x}$이고, $m:n$으로 외분하는 점$Q(x)$의 좌표는 $ \displaystyle x=\frac{mx_2-nx_1}{m-n}$이다. 내</description>
    </item>
    
    <item>
      <title>실수의 허수승의 크기는 항상 1이다</title>
      <link>https://freshrimpsushi.github.io/posts/mudulus-of-imaginary-number-power-of-real-number-is-1/</link>
      <pubDate>Thu, 29 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mudulus-of-imaginary-number-power-of-real-number-is-1/</guid>
      <description>정리 $0$ 이 아닌 실수 $r, \theta$ 에 대해 $$ \left| r^{i \theta} \right| = 1 $$ 설명 흔히 $\left| e^{i \theta} \right| = 1$ 는 잘 숙지하고 있지만 밑이 딱히 $e$ 가 아닌 어떤 실수라도 상관없다는 건 떠올리기 어렵다. 생각해보면 당연히 성립이야하겠지만 이렇게는 잘 쓸 일이 없어서다. 증명 $\theta = 0$ 이면 $r^0=1$ 이므로 당연히 $\left| r^{i \theta} \right| = \left| r^{i \cdot 0} \right| = 1$ 이 성립한다. $\theta \ne 0$ 이면 $$ \left| r^{i \theta} \right| = \left| e^{i \theta \ln r} \right| = \left| e^{i \theta</description>
    </item>
    
    <item>
      <title>미적분학에서의 오일러 공식</title>
      <link>https://freshrimpsushi.github.io/posts/euler-formula-in-calculus/</link>
      <pubDate>Tue, 23 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euler-formula-in-calculus/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **1. 오일러 공식: $$ { e }^{ ix }= \cos x + i \sin x $$ 2. 오일러 등식: $$ { e }^{ i\pi }+1=0 $$ 오일러 공식Euler&amp;rsquo;s Formula은 그 형태 자체가 워낙 기이해서 오일러 본인조차 어디다 쓰일지는 몰랐다고 하는데, 현대에는 너무나 많은 분야에서 활용되고 있어 요약을 하기가 어려울 정도로 유용</description>
    </item>
    
    <item>
      <title>수직인 두 직선의 기울기의 곱이 -1임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/the-product-of-the-slope-of-two-vertical-straight-lines-is-1/</link>
      <pubDate>Sat, 20 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-product-of-the-slope-of-two-vertical-straight-lines-is-1/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정리 서로 수직인 두 직선의 기울기의 곱은 항상 $-1$이다. 여러 문제에서 매우 유용하게 쓰이는 사실이다. 2가지 증명 방법을 소개한다. 증명1 피타고라스의 정리를 사용한다. 아래 그림을 보자.수직인 두 직선의 기울기가 $a$, $a&#39;$라고 하자. 그러면 위의 그림과 같이 직각 삼각형$\trian</description>
    </item>
    
    <item>
      <title>정수론에서의 합동</title>
      <link>https://freshrimpsushi.github.io/posts/congruence-in-number-theory/</link>
      <pubDate>Thu, 11 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/congruence-in-number-theory/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $a \equiv b \pmod{m}$ $\iff$ 정수 $a$, $b$, $m$ 에 대해 $a = b + mk$ 를 만족하는 정수 $k$ 가 존재한다. 수식 $a \equiv b \pmod{m}$ 을 합동식이라 부르고, 법Modulo $m$ 에서 $a$ 가 $b$ 에 합동Congruent이라 한다. 다만 법은 수식에서부터 $\pmod{}$ 가 그대로 쓰인만큼 그냥 모듈로 $m$ 이라고 발음하는 편이다. $a_{1} \equiv b_{1} \pmod{m}$ 과 $a_{2} \equiv b_{2} \pmod{m}$ 이 성립한</description>
    </item>
    
    <item>
      <title>규격화된 파동함수는 시간의 변화에 무관함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/the-normalized-wave-function-is-time-independent/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-normalized-wave-function-is-time-independent/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 한 번 규격화된 파동함수는 시간에 따라서 변하지 않고 일정하다.시간에 변해도 규격화된 상태를 유지한다. 시간$t=0$일 때 파동함수를 규격화했다고 가정하자.그렇다면 그 이후에 시간이 변함에 따라 파동함수가 규격화된 상태를 유지한다고 확신할 수 있는가?다행히도 그렇다.시간이 변해도 일정</description>
    </item>
    
    <item>
      <title>단진자 운동의 주기는 진자의 질량과 무관함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/the-period-of-a-single-pendulum-movement-is-independent-of-the-mass-of-the-pendulum/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-period-of-a-single-pendulum-movement-is-independent-of-the-mass-of-the-pendulum/</guid>
      <description>정리 단진자 운동의 주기 $T$는 진자의 질량 $m$과 무관하다. 설명 따라서 단진자 운동의 주기 $T$는 진자의 질량, 진폭의 크기 등과 무관하고 오로지 진자의 길이와 중력가속도에만 의존한다는 것을 알 수 있다. 증명 진자의 복원력은 다음과 같다. $$ F=-mg\sin\theta $$ $x=l\theta$ 이므로, $\theta$가 충분히 작을 때 아래의 근사가 성립한다. $$ \sin\theta \simeq \theta $$ 이 때 복원력은</description>
    </item>
    
    <item>
      <title>디랙 델타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/dirac-delta-function/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirac-delta-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 아래의 두 조건을 만족하는 함수를 디랙델타함수라 한다. $$ \delta (x) = \begin{cases} 0, &amp;amp; x\neq 0 \\ \infty , &amp;amp; x=0 \end{cases} $$ $$ \int_{-\infty}^{\infty}{\delta (x) dx}=1 $$ ※크로네커 델타와 헷갈리지 않게 주의가 필요하다.공학에서는 단위 임펄스 함수$(\mathrm{unit\ impulse\ function})$이라 부른다. 정확하게 말하자면 수학적으로 디랙</description>
    </item>
    
    <item>
      <title>디랙 델타 함수의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-dirac-delta-function/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-dirac-delta-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $ \displaystyle 1.\ \delta (-x) =\delta (x) \\ \displaystyle 2.\ \delta (kx)= \frac{1}{|k|} \delta (x) $ 증명(1번) $ \displaystyle \int_{-\infty }^ { \infty } f(x) \delta (-x) dx $이 때, $-x \equiv y$라고 치환하면$x=-y$, $dx=-dy$ 이고 위의 식에 대입하면$ \displaystyle \int_{-\infty }^ { \infty } f(x) \delta (-x) dx $$ \displaystyle =-\int_ { \infty }^{-\infty} f(-y) \delta (y) dy \\ \displaystyle = \int_{-\infty } ^{\infty } f(-y) \delta(y) dy \\ = f(0) \\ \displaystyle = \int_{-\infty } ^{\infty } f(x) \delta (x) dx $$ \displaystyle \int_{-\infty }^ { \infty } f(x) \color{blue}{\delta (-x)} dx = \int_{-\infty } ^{\infty } f(x)</description>
    </item>
    
    <item>
      <title>감마함수</title>
      <link>https://freshrimpsushi.github.io/posts/gamma-function/</link>
      <pubDate>Sun, 30 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gamma-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $\Gamma$ 를 감마 함수라고 한다. $$ \displaystyle \Gamma(x) := \int_{0}^{\infty} t^{x-1} e^{-t} dt $$ 위 수식에서 적분에 초점을 두면 오일러 적분이라고도 부른다. 감마함수는 순수수학 뿐만 아니라 물리학, 통계학 등지에서 무척 중요한 함수로도 유명하다. 흥미로운 성질들을 매우 풍부하게 가지고 있으나 가장 대표적인 것은 팩토리얼을 실수에 대해 일반화하는 개념이라는 점이다. 정</description>
    </item>
    
    <item>
      <title>두 레비-치비타 심볼의 곱</title>
      <link>https://freshrimpsushi.github.io/posts/multiplication-of-two-levi-civita-symbol/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplication-of-two-levi-civita-symbol/</guid>
      <description>공식 (a) 한 개의 인덱스가 같은 경우: $\epsilon_{ijk}\epsilon_{lmk}=\delta_{il}\delta_{jm}-\delta_{im}\delta_{jl}$ (b) 두 개의 인덱스가 같은 경우: $\epsilon_{ijk}\epsilon_{ljk}=2\delta_{il}$ (c) 세 개의 인덱스가 같은 경우: $\epsilon_{ijk}\epsilon_{ijk}=6$ 설명 글 전반에서 아인슈타인 표기법을 사용하고 있으니 헷갈리지 말자. 증명 (a) 레비-치비타 심볼은 아래와 같이 나타낼 수 있다. $$ \begin{align*} \epsilon _{ ijk } &amp;amp;= \left| \begin{matrix} \delta _{ i1 } &amp;amp; \delta _{ i2 } &amp;amp; \delta _{ i3 } \\ \delta _{ j1 } &amp;amp; \delta _{ j2 } &amp;amp; \delta _{ j3 } \\ \delta _{ k1 } &amp;amp; \delta _{ k2 } &amp;amp; \delta _{ k3</description>
    </item>
    
    <item>
      <title>아인슈타인 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/einstein-notation/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/einstein-notation/</guid>
      <description>노테이션 두 번 이상 반복되는 첨자에 대해서는 합기호 $\sum$를 생략한다. 설명 아인슈타인 합 규약Einstein summation conventionend이라 부르기도 한다. 공식 같은 것은 아니고 말 그대로 일종의 규칙이다. 벡터 계산을 하다 보면 한 수식에 $\sum$을 몇 겹씩이나 써야 하는 경우가 흔히 생기는데 이러면 수식이 지저분해지고 손으로 쓸</description>
    </item>
    
    <item>
      <title>양자역학에서 단순 조화 진동자의 바닥상태 에너지</title>
      <link>https://freshrimpsushi.github.io/posts/ground-state-of-simple-harmonic-motion/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ground-state-of-simple-harmonic-motion/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 불확정성 원리the uncertainty principle를 사용하여 단조화 진동자의 바닥상태 에너지를 구해보자.단조화 진동자의 에너지는$\begin{align*} E &amp;amp;= \frac{p^2}{2m}+\frac{1}{2}kx^2 \\ &amp;amp;= \frac{1}{2m}\left(\frac{{\hbar}^2}{4x^2}\right)+\frac{1}{2}kx^2 \end{align*}$불확정성 원리에 의해 $\displaystyle xp \simeq \frac{\hbar}{2} $$ E$가 최소일 때를 구하려면$ \displaystyle \left. \frac{\partial E}{\partial x}\right|_{x=x_0} =0 $$ \displaystyle { -\frac{{\hbar}^2}{4m{x_0}^3}+kx_0=0 \\</description>
    </item>
    
    <item>
      <title>양자역학에서 수소원자의 최소 에너지</title>
      <link>https://freshrimpsushi.github.io/posts/ground-energy-of-hydrogen-atoms-in-quantum-mechanics/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ground-energy-of-hydrogen-atoms-in-quantum-mechanics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 불확정성 원리the uncertainty principle를 이용하여 수소원자의 최소 에너지를 구해보자.수소 원자의 에너지 $E$는$ \begin{align*} E &amp;amp;= \frac{p^2}{2m}-\frac{e^2}{r} \\ &amp;amp;= \frac{1}{2m}\frac{{\hbar}^2}{r^2}-\frac{e^2}{r} \end{align*}$불확정성 원리에 의해 $pr \simeq \hbar $$ E$가 최소일 때를 구하려면$ \displaystyle { \left. \frac{\partial E}{\partial r} \right|_{r=r_0}=0 \\ -\frac{{\hbar}^2}{m{r_0}^3}+\frac{e^2}{{r_0}^2}=0 \\ -\frac{{\hbar}^2}{m}+e^2r_0=0 \\ r_0=\frac{{\hbar}^2}{me^2} } $$ \begin{align*} \implies E_{min} &amp;amp;= \frac{{\hbar}^2}{2m}\frac{m^2e^4}{{\hbar}^4}-\frac{me^4}{{\hbar}^2} \\ &amp;amp;= \frac{me^4}{2{\hbar}^2}-\frac{me^4}{{\hbar}^2} \\ &amp;amp;= -\frac{1}{2}\frac{me^4}{{\hbar}^2} \\ &amp;amp;=</description>
    </item>
    
    <item>
      <title>포물선 운동의 수평도달거리와 최대 높이 각도</title>
      <link>https://freshrimpsushi.github.io/posts/horizontal-range-and-maximum-height-angle-of-parabolic-motion/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/horizontal-range-and-maximum-height-angle-of-parabolic-motion/</guid>
      <description>] 포물선 운동 포물선 운동에 대해서 우리는 아래와 같은 두가지 물음에 대해서 생각할 수 있다. 최대 거리: 물체를 던질 때 어느 각도로 던져야 가장 멀리 날아갈까? 최대 높이: 어느 각도로 던져야 가장 높이 올라갈까? $x$성분은 중력가속도와 무관하고, $y$성분은 중력가속도에 영향을 받는다 $$ \begin{align*} x &amp;amp;= (v_o\cos\alpha)t &amp;amp;&amp;amp; &amp;amp; y &amp;amp;= -\frac{1}{2}gt^2+(v_0\sin\alpha)t \\ v_{x} &amp;amp;= v_0\cos\alpha &amp;amp;&amp;amp; &amp;amp; v_{y} &amp;amp;= -gt+v_0\sin\alpha \\ a_{x} &amp;amp;= 0 &amp;amp;&amp;amp; &amp;amp; a_{y}</description>
    </item>
    
    <item>
      <title>아크탄젠트 함수의 급수전개</title>
      <link>https://freshrimpsushi.github.io/posts/series-expansion-of-arctangent-function/</link>
      <pubDate>Thu, 27 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-expansion-of-arctangent-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 공식 $$ \displaystyle \tan ^{ -1 } x = \sum _{ n=0 }^{ \infty }{ \frac { (-1) ^{ n } { x } ^ { 2n+1 } } { 2n+1 } } $$ $\arctan$으로 쓰든 $\tan ^{-1}$로 쓰든 상관없다. 여러 삼각함수의 역함수 중에서도 아크탄젠트가 특히 흥미로운 이유는 바로 $\pi$ 로 수렴하는 급수를 제공해주기 때문이다. $x=1$ 을 대입하면 $$ \displaystyle { \pi \over 4 } =</description>
    </item>
    
    <item>
      <title>크로네커 델타</title>
      <link>https://freshrimpsushi.github.io/posts/kronecker-delta/</link>
      <pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kronecker-delta/</guid>
      <description>정의 다음과 같이 정의되는 $\delta_{ij}$를 크로네커 델타 라고 한다. $$ \delta_{ij} := \begin{cases} 1,&amp;amp;i=j \\ 0, &amp;amp; i\ne j \end{cases} $$ 설명 크로네커 델타 굉장히 많은 곳에서 쓰이는데 주 역할은 모든 성분(원소, 가능성 등) 중에서 원하는 것만을 나타내주는 것이다. 물리학과 학생이라면 내적에 대한 표현으로 주로 접하게된다. 이게 무슨 말인지 감이 잘 오지 않을테니 아래의 예시</description>
    </item>
    
    <item>
      <title>레비-치비타 심볼</title>
      <link>https://freshrimpsushi.github.io/posts/levi-civita-symbol/</link>
      <pubDate>Tue, 25 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/levi-civita-symbol/</guid>
      <description>정의 다음과 같이 정의되는 $\epsilon_{ijk}$를 레비-치비타 심볼Levi-Civita-symbol 이라고 한다. $$ \epsilon_{ijk} = \begin{cases} +1 &amp;amp; \text{if} \ \epsilon_{123}, \epsilon_{231}, \epsilon_{312} \\ -1 &amp;amp; \text{if} \ \epsilon_{132}, \epsilon_{213}, \epsilon_{321} \\ 0 &amp;amp; \text{if} \ i=j \ \text{or} \ j=k \ \text{or} \ k=i \end{cases} $$ 설명 크로네커 델타가 인덱스끼리 값이 같은지만 따졌다고 한다면 레비-치비타 심볼은 정의에서 나타나듯이 인덱스의 순서도 값에 영</description>
    </item>
    
    <item>
      <title>등가속도 직선 운동과 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-acceleration-straight-motion-and-graphs/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-acceleration-straight-motion-and-graphs/</guid>
      <description>정의 어떤 물체의 가속도가 시간 $t$에 따라 변하지 않을 때 물체가 등가속도 운동을 한다고 말한다. $$ a(t)=a $$ 등가속도 직선 운동은 가속도가 변하지 않고 일정하게 유지되면서 직선으로 운동하는 것을 말한다. 이 때 가속도 $a$​가 양수인지 음수인지가 중요한데 $a&amp;gt;0$이라면 처음 움직이던 방향으로 점점 빠르게 움직일 것이고, $a&amp;lt;0$</description>
    </item>
    
    <item>
      <title>등속도 운동과 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/constant-velocity-motion-and-graph/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/constant-velocity-motion-and-graph/</guid>
      <description>설명 등속도라는 이름을 풀어보면 &amp;lsquo;등(같다)+속도&amp;rsquo;이다. 즉 속도가 같은, 일정하게 유지되는 운동이라는 것이다. 속도는 벡터이므로 크기(속력)도 있고 방향도 있다.크기와 방향 둘 다 일정해야 등속도 운동이 된다.한마디로 등속도 운동은 속력과 방향이 일정한 운동을 말한다. 그래프 등속도 운동의 그래프는 아래의 그림</description>
    </item>
    
    <item>
      <title>로렌츠 변환으로 인한 특수상대성이론의 특징: 시간 지연</title>
      <link>https://freshrimpsushi.github.io/posts/time-dilation/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-dilation/</guid>
      <description>로렌츠 변환의 특징 특수상대성이론에서 두 좌표계 사이의 변환은 고전적인 변환과 다르다. &amp;lsquo;빛의 속도는 어느 관찰자에게나 똑같다&amp;rsquo; 라는 점 때문이다. 이러한 조건을 고려하여 유도해낸 것이 로렌츠 변환이다. 로렌츠 변환으로 인해서 고전물리에서는 나타나지 않는 새로운 현상이 세가지 있다. 동시성 상실 시간 지연 길이 수축 시간</description>
    </item>
    
    <item>
      <title>벡터 삼중곱, BAC-CAB 공식</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-vector-triple-productbac-cab-rule/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-vector-triple-productbac-cab-rule/</guid>
      <description>공식 $$ \mathbf{A} \times (\mathbf{B} \times \mathbf{C} ) = \mathbf{B}(\mathbf{A} \cdot \mathbf{C} )-\mathbf{C}(\mathbf{A} \cdot \mathbf{B}) $$ 설명 위 공식의 좌변을 벡터 삼중곱vector triple product이라 한다. 우변의 결과를 간단하게 **BAC-CAB(백캡)**이라고 한다. 벡터 삼중곱은 벡터를 3번 곱하는 연산 중에서 그 결과가 벡터인 것이다. 결과가 벡터로 나오기 위해서 식에는 외적만 두 번 들어간다. 두 벡터의 외적은 여전히 벡터이므</description>
    </item>
    
    <item>
      <title>운동량과 충격량의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-momentum-and-impact/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-momentum-and-impact/</guid>
      <description>정의 운동량 물체의 질량과 속도의 곱을 운동량이라 하고 $p$로 나타낸다. 고등학교 물리에서는 물체의 운동 상태를 나타낼 때 속도 $v$를 많이 쓰지만 대학물리에서는 운동량 $p$가 많이 쓰인다. $$ \vec{p}=m\vec{v}[kg\cdot m/s] $$ 속도$v$가 벡터이므로 운동량 역시 벡터이다. 질량 $m$이 항상 양수이므로 속도와 운동량의 방향은 항상 같다. 질량이 클 수록, 속도의 크기가</description>
    </item>
    
    <item>
      <title>이차행렬의 곱의 성분의 합을 쉽게 구하는 공식</title>
      <link>https://freshrimpsushi.github.io/posts/70/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/70/</guid>
      <description>공식 이차행렬 $\pmatrix { { a }&amp;amp;{ b } \\ { c }&amp;amp;{ d } } \pmatrix { { p }&amp;amp;{ q } \\ { r }&amp;amp;{ s } }$ 의 성분의 합은 다음과 같다. $$ {(a+c)(p+q)}+{(b+d)(r+s)} $$ 설명 두 이차행렬을 주고 그 곱의 성분의 합을 구하라는 문제를 많이 접해보았을 것이다. 다들 알겠지만 이 행렬을 곱한다는게 어렵지는 않지만 시간도 걸리고 여간 귀찮은게 아니다. 해서, 연산을 획기적으로 줄이는 공식을 소개한다. 유도 $$ \pmatrix {</description>
    </item>
    
    <item>
      <title>유클리드 호제법 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-euclidean-algorithm/</link>
      <pubDate>Thu, 20 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-euclidean-algorithm/</guid>
      <description>알고리즘 두 정수 $a \ge b$ 에 대해 $\text{gcd}(a,b)$ 는 다음과 같이 구할 수 있다. Step 1. 초기화 $r_i, i=1,2,3,\cdots $ 에 대해 $a=r_0, b=r_1$ 이라고 두자. Step 2. 반복법 $$ r_{i-1} = r_i \cdot q_i + r_{i+1} \qquad , (r_i&amp;gt;r_{i+1}) $$ 이 성립하도록 $q_i$ 와 새로운 $r_{i+1}$를 계속 구한다. Step 3. $r_{i+1}=0$ 일 때까지 반복하면 $r_i=\text{gcd}(a,b)$ 이다. 설명 이른바 유클리드 호제법Euclidean Algorithm으로 알려진 이 알고리즘은 최대공약수</description>
    </item>
    
    <item>
      <title>합동방정식에 대한 대수학의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-algebra-for-congruence/</link>
      <pubDate>Thu, 20 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-algebra-for-congruence/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 대수학의 기본정리 어떤 소수 $p$ 에 대해 $p\nmid a_{ 0 }$ 라 하면 모든 계수가 정수인 다항식 $$ f(x)=a_{ 0 }x^{ d }+a_{ 1 }x^{ d-1 }+ \cdots +a_{ d-1 }x+a_{ d } $$ 에 대해 방정식 $f(x)\equiv 0 \pmod{p}$ 는 많아도 $d$ 개의 합동이 아닌 해를 가진다. 그냥 흔히들 아는 것처럼 실계수를 갖는 다항식에 대해서 말하자면, $n$차 방정식은 중근을 포함해 $n$개의 해를</description>
    </item>
    
    <item>
      <title>소수는 무한히 존재한다  유클리드의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/euclids-proof-of-the-infinitude-of-primes/</link>
      <pubDate>Sat, 15 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euclids-proof-of-the-infinitude-of-primes/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 오일러의 증명 소수는 무한히 존재한다. 소수가 무한하다는 것을 증명하는 방법은 여러가지가 있다. 그 중에서도 가장 간단한 유클리드의 방법을 소개하도록 하겠다. 이 증명은 단순할 뿐만 아니라 매우 아름답기로도 유명하다.증명 소수가 유한히 존재한다고 가정하자. $n$개의 소수들을 각각 $p_1, p_2, \cdots ,</description>
    </item>
    
    <item>
      <title>자연로그의 급수꼴 유도와 교대조화급수의 수렴성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/expansion-of-natural-log-and-convergence-of-alternating-harmonic-series/</link>
      <pubDate>Tue, 11 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expansion-of-natural-log-and-convergence-of-alternating-harmonic-series/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 조화급수의 발산성 $$ \displaystyle \ln(1-x)=\sum _{ n=0 }^{ \infty }{ \frac { -{ x }^{ n+1 } }{ n+1 } } $$ $\ln(1-x)$ 의 급수꼴은 비교적 쉽게 구할 수 있다.증명 $-1&amp;lt;x&amp;lt;1$ 에 대해 등비수열의 합 $\displaystyle \sum_{n=0}^{\infty} x^{n}$ 은 다음과 같다. $$ \displaystyle {{ 1 } \over { 1-x }}=1+x+{ x }^{ 2 }+{ x }^{ 3 }+ \cdots $$ 양변에 적분을 취하면 $$ \displaystyle -\ln(1-x)=c+x+\frac { { x }^{ 2 } }{ 2 }+\frac { { x }^{ 3 } }{ 3 }+\frac { { x }^{ 4 } }{ 4 }+ \cdots $$</description>
    </item>
    
    <item>
      <title>지수 함수 사인 함수 코사인 함수의 테일러 전개</title>
      <link>https://freshrimpsushi.github.io/posts/59/</link>
      <pubDate>Tue, 11 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/59/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정리 [1] 지수 함수의 매클로린 급수 : $$ { { e ^ x } }=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ n } }{ n! } } $$ [2] 사인 함수의 매클로린 급수 : $$ \sin x=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ 2n+1 } }{ (2n+1)! }{ { (-1) }^{ n } } } $$ [3] 코사인 함수의 매클로린 급수 : $$ \cos x=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ 2n } }{ (2n)! }{ { (-1) }^{ n } } } $$ 지수 함수,</description>
    </item>
    
    <item>
      <title>근의 공식 유도 무작정 따라하기</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-quadratic-formula/</link>
      <pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-quadratic-formula/</guid>
      <description>공식 이차방정식 $ax^{2}+bx+c=0$ (단, $a\neq 0$)에 대해 $$ x=\dfrac{ -b\pm \sqrt { b^{2}-4ac } }{2a} $$ 설명 이차방정식이 주어졌을 때 그 근은 공식을 통해 쉽게 구할 수 있다. 유도 전략: 공식 유도의 핵심은 바로 &amp;lsquo;완전제곱꼴로 만드는 것&amp;rsquo;이다. 수학이 낯선 어린이 친구들을 위해 가능한 세세하게 풀어서 썼다. 말 그대로 무작정 따라하면 되니까 베껴 적는다고 생각하고 여</description>
    </item>
    
    <item>
      <title>무한급수가 수렴하면 무한수열은 0으로 수렴함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-the-infinite-series-converges-to-zero-when-it-converges/</link>
      <pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-the-infinite-series-converges-to-zero-when-it-converges/</guid>
      <description>정리 $\displaystyle \sum _{ n=1 }^{ \infty }{ { a }_{ n }}$ 이 수렴하면 $\displaystyle \lim _{ n\to \infty }{ { a }_{ n }}=0$ 설명 처음 접하면 직관과 달라 조금 당황스러울 수 있는 정리로, 왜 역이 성리하지 않는지 궁금할 수 있다. 그 대표적인 반례로는 다음과 같은 수열을 생각해볼 수 있다. $$ \begin{align*} { a }_{ n }&amp;amp;=\frac { 1 }{ n } \\ { b }_{ n }&amp;amp;=\sqrt { n }-\sqrt { n-1 } \end{align*} $$ 두 수열 모두 0으로 수렴하지만 그 합은 무한대로 발산한다. 첫</description>
    </item>
    
    <item>
      <title>회전변환 행렬의 거듭제곱 공식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-power-square-formula-of-the-rotational-transform-matrix/</link>
      <pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-power-square-formula-of-the-rotational-transform-matrix/</guid>
      <description>정리 $$ { \pmatrix {{ \cos \theta }&amp;amp;{ -\sin \theta } \\ { \sin \theta }&amp;amp;{ \cos \theta }} }^{n}=\pmatrix {{ \cos n\theta }&amp;amp;{ -\sin n\theta } \\ { \sin n\theta }&amp;amp;{ \cos n\theta }} (n=1,2,3,&amp;hellip;) $$ 원점을 중심으로 $\theta$만큼 회전하는 일차변환의 행렬을 $n$제곱하면 $n\theta$만큼 회전하는 일차변환이 된다.전략: 상식적으로도 당연하고, 수학적 귀납법을 이용해 쉽게 증명할 수 있다. 증명 $$ (ㄱ) : { \pmatrix {{ \cos \theta }&amp;amp;{ -\sin \theta } \\ { \sin \theta</description>
    </item>
    
    <item>
      <title>분수 함수의 역함수와 이차정사각 행렬의 역행렬의 모양</title>
      <link>https://freshrimpsushi.github.io/posts/53/</link>
      <pubDate>Wed, 05 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/53/</guid>
      <description>정리 분수함수 $\displaystyle f(x)=\frac { ax+b }{ cx+d }$ 의 역함수는 $$ f^{ -1 }(x)=\frac { dx-b }{ -cx+a } $$ 2차 정사각행렬 $\pmatrix { { a }&amp;amp;{ b } \\ { c }&amp;amp;{ d } }$ 의 역행렬은 $$ \frac { 1 }{ ad-bc } \pmatrix { { d }&amp;amp;{ -b } \\ { -c }&amp;amp;{ a } } $$ 설명 단순한 우연의 일치일지도 모르겠지만, 이런 우연을 찾는 것 또한 수학의 즐거움이다. 행렬이 교과 과정에서 없어졌다고는 하지만 얼마든지 유용하게 쓸 수 있는 사실이다. 증</description>
    </item>
    
    <item>
      <title>포물선의 접선의 방정식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/finding-the-equation-of-parabolic-tangents/</link>
      <pubDate>Wed, 05 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finding-the-equation-of-parabolic-tangents/</guid>
      <description>유도 기울기가 주어진 경우 우선은 기울기가 주어진 경우를 먼저 보도록 하자. 포물선 $y^{ 2 }=4px$ 에 접하는 직선의 방정식이 $y=mx+n$일 때, 두 도형은 한 점에서만 만나야 하므로 $$ (mx+n)^{ 2 }=4px \implies m^{ 2 }x^{ 2 }+2(mn-2p)x+n^{ 2 }=0 $$ 근의 공식에 따라 $$ \frac { D }{ 4 }=m^{ 2 }n^{ 2 }-4mnp+4p^{ 2 }-m^{ 2 }n^{ 2 }=0 $$ 위 식을 정리하면 $n=\frac { p }{ m }$ 이고, 이를 직선의 방정식에 대입하면 포물선에 접하는 직</description>
    </item>
    
    <item>
      <title>코시-슈바르츠 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cauchy-schwarz-inequality/</link>
      <pubDate>Mon, 03 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cauchy-schwarz-inequality/</guid>
      <description>정리 $$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\ge { (ax+by) }^{ 2 } $$ 증명 $$ \begin{align*} &amp;amp; ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})-{ (ax+by) }^{ 2 } \\ =&amp;amp; {a}^{2}{x}^{2}+{b}^{2}{x}^{2}+{a}^{2}{y}^{2}+{b}^{2}{y}^{2}-{ (ax+by) }^{ 2 } \\ =&amp;amp; {b}^{2}{x}^{2}+{a}^{2}{y}^{2}-2axby \\ =&amp;amp; { (ay-bx) }^{ 2 } \\ \ge&amp;amp; 0 \end{align*} $$ 이므로, 정리하면 다음을 얻는다. $$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\ge { (ax+by) }^{ 2 } $$ ■ 설명 빠르게는 고등학교 과정부터 접하게 되는 부등식으로, 분야를 가리지 않고 여러 곳에서 쓰이고 있다. 대수적인 증명은 매우 간단하다. 증명과정에서 알 수 있듯 등호가 성립하는 경우는 $ay-bx</description>
    </item>
    
    <item>
      <title>한 직선과 x축 y축으로 둘러싸인 삼각형의 넓이</title>
      <link>https://freshrimpsushi.github.io/posts/50/</link>
      <pubDate>Mon, 03 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/50/</guid>
      <description>개요 최댓값 혹은 최솟값, 접선을 구할 수 있는가를 묻는 문제 등에서 꽤 자주 나오는 것이 이런 삼각형의 넓이 $S$ 다. 물론 삼각형의 넓이를 구하는 건 어렵지 않지만 간단한 공식의 형태로 기억해 바로바로 풀 수 있다면 더 좋을 것이다. 정리 직선 $y=mx+n$ 의 $y$절편은 $n$, $x$절편은 $-\frac { n }{ m }$이다. 이 직선과 $x$축, $y$축으로 둘러싸인 삼각형의 넓이는 다</description>
    </item>
    
    <item>
      <title>포커 족보별 경우의 수 확률 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/probability-of-each-poker-hand-ranking/</link>
      <pubDate>Wed, 29 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-of-each-poker-hand-ranking/</guid>
      <description>문양과 끗수의 정의 확률 이전에 포커 자체를 잘 모른다면 족보를 찾아서 알아보는 걸 추천한다. 확률을 구하기에 앞서 두 가지 정의를 내리자: 문양: 집합 {♠,◇,♤,♣}의 원소 끗수: 집합 {A,2,3,4,5,6,7,8,9,10,J,Q,K}의 원소 만약 두 가지 이상의 족보를 동시에 만족하면 높은 걸 따른다. 아래의 확률들은 5장을 뽑고 그때</description>
    </item>
    
    <item>
      <title>삼각함수의 덧셈정리 여러가지 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-angle-sum-and-difference-identities-of-trigonometric-function/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-angle-sum-and-difference-identities-of-trigonometric-function/</guid>
      <description>정리 $$ \sin\left( \alpha +\beta \right) =\sin\alpha \cos\beta +\cos\alpha \sin\beta \\ \sin\left( \alpha -\beta \right) =\sin\alpha \cos\beta -\cos\alpha \sin\beta \\ \cos\left( \alpha +\beta \right) =\cos\alpha \cos\beta -\sin\alpha \sin\beta \\ \cos\left( \alpha -\beta \right) =\cos\alpha \cos\beta +\sin\alpha \sin\beta \\ \tan\left( \alpha +\beta \right) =\frac { \tan\alpha +\tan\beta }{ 1-\tan\alpha \tan\beta } \\ \tan\left( \alpha -\beta \right) =\frac { \tan\alpha -\tan\beta }{ 1+\tan\alpha \tan\beta } $$ 증명 코사인 법칙을 이용한 증명 피타고라스의 정리에 의해 $$ \begin{align*} {\overline { AB } } ^{ 2 } =&amp;amp; {( \cos \alpha -\cos \beta )}^{ 2 }+{(\sin\alpha -\sin\beta )}^{ 2 } \\ =&amp;amp; 2-2 \cos \alpha \cos \beta –2 \sin \alpha \sin \beta \end{align*} $$ 제2코사인 법칙에 의해 $$ \begin{align*} { \overline { AB } } ^{ 2 } =&amp;amp; 1^{</description>
    </item>
    
    <item>
      <title>자연로그의 거듭제곱의 적분법</title>
      <link>https://freshrimpsushi.github.io/posts/integration-of-power-of-natural-log/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integration-of-power-of-natural-log/</guid>
      <description>공식 $$ \int {{(\ln x)}^{ n }} dx=x{{(\ln x)}^{ n }}-\int n{{(\ln x)}^{ n-1 }}dx $$ 설명 적분 문제를 풀다보면 심심치 않게 보게 되는 유형이다. 이런 문제들을 풀 때 정직하게 부분적분으로 풀면 시간을 너무 많이 빼앗긴다. 우선은 규칙부터 찾아보도록 하자. $f(n)=\int {{(\ln x)}^{ n }} dx$ (단, $n=1,2,3&amp;hellip;$)이라 할 때 $$ \begin{align*} f(1) =&amp;amp; x(\ln|x|-1)+C \\ f(2) =&amp;amp; x{(\ln|x|)^{ 2 }-2\ln|x|+2}+C \\ f(3) =&amp;amp; x{(\ln|x|)^{ 3 }-3(\ln|x|)^{ 2 }+6\ln|x|-6}+C \\ f(4) =&amp;amp; x{(\ln|x|)^{ 4 }-4(\ln|x|)^{ 3 }+12(\ln|x|)^{ 2 }-24\ln|x|+24}+C \end{align*}</description>
    </item>
    
    <item>
      <title>로피탈의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lhospitals-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lhospitals-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정리 $f(x)$ 와 $g(x)$ 가 $x=a$ 의 근방에서 미분가능하고 $g&#39;(x) \ne 0$ 이며 $\displaystyle \lim _{x \to a} f(x) = \lim _{x \to a} g(x) = 0$ 이면 $$ \lim _{x \to a} {{f(x)} \over {g(x)}} = \lim _{x \to a} {{f&#39;(x)} \over {g&#39;(x)}} $$ 수험생들에게는 마검같은 정리로 이미 수 많은 고등학생들이 배워서 써먹고 있으나, 개인적으로 수능을 몇 달 앞두기 전엔 알아도 봉인해두고 가능한 정석대로 푸는 게 좋다고</description>
    </item>
    
    <item>
      <title>롤의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rolles-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rolles-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 함수 $f(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 미분가능하며 $f(a)=f(b)$ 면 $f&#39;(c)=0$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 고등학교 과정에선 평균값의 정리만을 증명하기 위한 보조정리 정도로 소개되고 실제로 그 외엔 전혀 쓰이지 않지만, 고등학교 수준을 벗어나서는 종종 보조정리로써 사용될 때가 있다. 평균값의 정리가 더욱</description>
    </item>
    
    <item>
      <title>우함수와 기함수</title>
      <link>https://freshrimpsushi.github.io/posts/40/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/40/</guid>
      <description>정의 $f(-x) = f(x)$ 를 만족하는 함수 $f(x)$ 를 우함수Even라고 한다. $f(-x) = -f(x)$ 를 만족하는 함수 $f(x)$ 를 기함수Odd라고 한다. 설명 우함수는 좌표평면에서 $y$ 축에 대칭인 함수, 기함수는 원점 $O$ 에 대칭인 함수를 말한다. 예시로 삼각함수 중 기함수인 $\sin$과 우함수인 $\cos$을 들 수 있겠다. $\sin$을 미분하면 $\cos$이, $\cos$을</description>
    </item>
    
    <item>
      <title>코시의 평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cauchys-mean-value-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cauchys-mean-value-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 평균값 정리 적분의 평균값 정리 가우스의 평균값 정리 정리 함수 $f(x), g(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 미분가능하며 $g&#39;(x) \ne 0$이면 $$ {{f&#39;(c)}\over{g&#39;(c)}}={{f(b)-f(a)}\over{g(b)-g(a)}} $$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 보통 평균값 정리와 달라진 게 있다면 그냥 함수가 하나 더 늘어난 것이다. $g(x) = x$ 로 본다면 이 $g$ 가 더 자유로워졌다는 의미에서 평균</description>
    </item>
    
    <item>
      <title>테일러 급수와 매클로린 급수</title>
      <link>https://freshrimpsushi.github.io/posts/taylor-series-and-maclaurin-series/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/taylor-series-and-maclaurin-series/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정리 함수 $f$ 가 점 $a$ 근방에서 무한히 미분가능하고, $\displaystyle f(x) = \sum_{n=0}^{\infty} {{f^{(n)} (a)}\over{n!}} {(x-a)}^n$ 일 필요충분조건은 어떤 $\xi \in \mathscr{H} \left\{ x , a \right\}$ 에 대해 $$ \lim_{n \to \infty} {{f^{(n)} (\xi)}\over{n!}} {(x-a)}^n = 0 $$ $\xi \in \mathscr{H} \left\{ x , a \right\}$ 라 함은 $\xi$ 가 $(x,a)$ 혹은 $(a,x)$ 에 있다는 표현이다. 테일러 정리는 함수가 한 없이 미분가능할 때 흔히 무한급수의 꼴로 표현된다. 이를 테일러 급수라 하</description>
    </item>
    
    <item>
      <title>테일러 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-taylors-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-taylors-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정리 함수 $f(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 $n$ 번 미분가능하면 $$ \displaystyle \begin{align*} f(b) =&amp;amp; \sum_{k=0}^{n-1} {{(b-a)^{k}\over{k!}}{f^{(k)}( a )}} + {(b-a)^{n}\over{n!}}{f^{(n)}(\xi)} \\ =&amp;amp; {f(a)} + {(b-a)f&#39;(a)} + \cdots + {(b-a)^{n-1}\over{(n-1)!}}{f^{(n-1)}(a)} + {(b-a)^{n}\over{(n)!}}{f^{(n)}(\xi)} \end{align*} $$ 를 만족하는 $\xi \in (a,b)$ 가 존재한다. 수학 전반에서 너무나 중요하게 쓰이고 있는 정리로, 이 이름을 딴 테일러 급수가 있다. 미분을 $n$ 번 한다는 의미에서는 평균값의 정리를 일반화한 정리라고 볼</description>
    </item>
    
    <item>
      <title>페르마의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fermats-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fermats-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 함수 $f(x)$ 가 $x=c$ 에서 극대 혹은 극소면서 $f&#39;(c)$ 가 존재하면 $f&#39;(c) = 0$ 보통 고등학교 교과서엔 롤의 정리까지만 소개되어 있으나 롤의 정리를 엄밀하게 증명하기 위해서는 극점에서의 미분계수가 왜 $0$ 인지를 보일 수 있어야하고, 페르마의 정리가 그것을 보장한다. Strategy** : 극대와 극소 두가지 경우로 나누어서 증명한다.*</description>
    </item>
    
    <item>
      <title>평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 코시의 평균값 정리 적분의 평균값 정리 가우스의 평균값 정리 함수 $f(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 미분가능하면 $\displaystyle f&#39;(c)={{f(b)-f(a)}\over{b-a}}$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 그냥 자주 쓰는 정도가 아니라 MVT라는 약어도 사용할 정도로 유명한 정리다. 평균값이라는 말은 미분계수가 전구간의 평균변화율과 같아지는 점</description>
    </item>
    
    <item>
      <title>다양한 삼각함수의 적분법</title>
      <link>https://freshrimpsushi.github.io/posts/31/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/31/</guid>
      <description>개요 적분 문제를 풀다보면 삼각함수의 적분을 상당히 많이 하게 된다. 그리고 이 적분법들에 익숙해지면 삼각함수도 다항함수처럼 빠르게 적분할 수 있다. 시컨트 함수의 적분법, 코시컨트 함수의 적분법 $$ \begin{align*} \int \sec x dx &amp;amp;=\int \frac { \sec x (\sec x +\tan x ) }{ (\sec x +\tan x ) }dx \\ &amp;amp;=\int \frac { \sec^{ 2 }x+\sec x \tan x }{ \tan x +\sec x }dx \end{align*} $$ $ (\tan x )\prime =\sec^{ 2 }x$ 이고 $(\sec x )\prime =\sec x \tan x$ 이므로 $$ \int \sec x dx=\ln|\tan x</description>
    </item>
    
    <item>
      <title>두 사건이 독립이면 여사건끼리도 독립임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/28/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/28/</guid>
      <description>정리 다음은 서로 동치다. $$ P(A \cap B) = P(A)P(B) \\ P(A \cap B^c)=P(A)P(B^c) \\ P(A^c \cap B)=P(A^c)P(B) \\ P(A^c \cap B^c)=P(A^c)P(B^c) $$ 설명 알아두면 큰 도움이 되는 팩트일 뿐만이 아니라 공식으로써도 유용하다. 증명 $P(A \cap B) = P(A)P(B)$ 이라 가정하자. 다시 말해, 사건 $A$, $B$ 는 독립이다. 여사건의 성질에 따라 $$ P(A)=1-P(A^{ c }) \\ P(B)=1-P(B^{ c }) $$ 이므로 $P(A \cap B) = P(A)P(B)$ 의 우변은 $$ \begin{align*} P(A)P(B)&amp;amp;=(1-P(A^{ c }))(1-P(B^{ c })) \\ =&amp;amp; 1-P(A^{ c })-P(B^{ c })+P(A^{ c })P(B^{ c }) \end{align*} $$ 이고, 좌변은 드 모르</description>
    </item>
    
    <item>
      <title>두 사건이 서로 배반이면 서로 종속임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/27/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/27/</guid>
      <description>정리 두 사건 $A,B$ 에 대해 $B=A^c$ 면 $P(A\cap B) \neq P(A)P(B)$ 설명 굳이 수식을 통한 증명이 없더라도 상식적으로 배반이면 독립일 리가 없다. 한 사건이 일어났을 때 다른 사건이 일어나지 않는다는 것은 이미 영향을 미치다는 말이기 때문이다. 다만 이것을 알고 모르고는 참 거짓을 판별하는 문제를 풀 때 아주 큰 차이가 있다. 증명 두 사건 $A,B$ 에 대해 $P(A)&amp;gt;0, P(B)&amp;gt;0$ 라 하자.이때 두 사건은 서로 배반이므로</description>
    </item>
    
    <item>
      <title>베이즈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</guid>
      <description>정리 1 표본공간 $S$ 와 사건 $A$ 에 대해서 ${S_1,S_2,&amp;hellip;,S_n}$ 가 $S$ 의 분할이면 $$ \displaystyle P(S_k|A)=\frac { P(S_k)P(A|S_k) }{ \sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$ 설명 혹은 베이즈 법칙으로도 불리는 이 정리는 두개의 법칙만 쓰면 될 정도로 쉽게 증명할 수 있으나 그 응용은 어마어마하다. 이른바 베이지안 패러다임은 통계학 자체를 양분하는 사고방식으로써, 그 중요도는 몇 번을 강조해도 부족함이 없다. 우리가 알고 싶은 것은 위</description>
    </item>
    
    <item>
      <title>이차함수의 극점 빠르게 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/30/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/30/</guid>
      <description>공식 이차함수 $f(x)=c(x-a)(x-b)$ 의 극점은 $\frac { a+b }{ 2 }$ (단, $c\neq 0$) 인수분해가 가능한 이차함수의 경우에는 굳이 이런 저런 계산할 것 없이 극점을 알 수 있다.생각해보면 당연하지만, 이 사실을 아느냐 모르느냐에 따라 계산 과정을 하나 줄일 수 있고 없고가 달라진다. 유도 $$ \begin{align*} &amp;amp; f(x) = c(x-a)(x-b) = c x^2 -c(a+b)x+cab \\ \implies&amp;amp; f&#39;(x)=2cx-c(a+b) \\ \implies&amp;amp; 2cx-c(a+b)=0 \\ \implies&amp;amp; x=\frac { c(a+b) }{ 2c } \\ \implies&amp;amp; x=\frac { a+b }{ 2 } \end{align*} $$ ■</description>
    </item>
    
    <item>
      <title>11의 배수판정법 더 간단한 증명</title>
      <link>https://freshrimpsushi.github.io/posts/easy-proof-of-the-11-divisibility-rule/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/easy-proof-of-the-11-divisibility-rule/</guid>
      <description>빌드업 이 포스트에서는 진법에 대한 편의를 위해 다음과 같은 표기를 사용한다. $$ [a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}] := a_{n} \cdot 10^{n} + a_{n-1} \cdot 10^{n-1} +&amp;hellip;+ a_{1} \cdot 10^{1} + a_{0} \cdot 10^{0} $$ 예를 들어 $5714$ 는 다음과 같이 나타낼 수 있다. $$ \begin{align*} [5714] =&amp;amp; 5000+700+10+4 \\ =&amp;amp; 5\cdot 10^{3} +7\cdot 10^{2} +1\cdot 10^{1} +4\cdot 10^{0} \end{align*} $$ 정리 $a_{n} - a_{n-1} + &amp;hellip; + a_{1} - a_{0}$ 이 $11$ 의 배수면 $[a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}]$ 도 $11$ 의 배수다. 설명 물론 $7$ 의 배수 판정법 $13$ 의 배수 판정법에서 주어진 수가 $7$, $11$, $13$ 의 배</description>
    </item>
    
    <item>
      <title>3의 배수판정법과 9의 배수판정법의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-3-and-9-divisibility-rule/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-3-and-9-divisibility-rule/</guid>
      <description>정리 각 자리 숫자를 모두 더해 $3$ 의 배수면 $3$ 의 배수, $9$ 의 배수면 $9$ 의 배수다. 설명 예로써 $8142$ 는 $8142=3 \cdot 2714$ 로 $3$의 배수고, 실제로 $8+1+4+2=15$ 는 $3$ 의 배수다. $1945125$ 는 $1945125=9 \cdot 216125$ 로 $9$의 배수고, 실제로 $1+9+4+5+1+2+5=27$ 은 $9$ 의 배수다. 배수 판정법은 현대에 와선 사실 별 의미가 없어졌지만 여전히 흥미로운 도구다. $2,4,5,8$ 의 배수는 판정하기가 아주 쉽지만 $3, 7, 9, 11$ 등의 수에 대해서는 별도</description>
    </item>
    
    <item>
      <title>7의 배수판정법과 13의 배수판정법의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-7-11-and-13-divisibility-rule/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-7-11-and-13-divisibility-rule/</guid>
      <description>빌드업 이 포스트에서는 진법에 대한 편의를 위해 다음과 같은 표기를 사용한다. $$ [a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}] := a_{n} \cdot 10^{n} + a_{n-1} \cdot 10^{n-1} +&amp;hellip;+ a_{1} \cdot 10^{1} + a_{0} \cdot 10^{0} $$ 예를 들어 $5714$ 는 다음과 같이 나타낼 수 있다. $$ \begin{align*} [5714] =&amp;amp; 5000+700+10+4 \\ =&amp;amp; 5\cdot 10^{3} +7\cdot 10^{2} +1\cdot 10^{1} +4\cdot 10^{0} \end{align*} $$ 정리 $$ a_{n} a_{n-1} a_{n-2} - a_{n-3} a_{n-4} a_{n-5} +&amp;hellip;+ a_{5} a_{4} a_{3} - a_{2} a_{1} a_{0} $$ 이 $7$ 의 배수면 $[a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}]$ 도 $7$ 의 배수고, $$ a_{n} a_{n-1} a_{n-2} - a_{n-3} a_{n-4} a_{n-5} +&amp;hellip;+ a_{5} a_{4} a_{3} - a_{2} a_{1} a_{0} $$ 이 $13$ 의 배수</description>
    </item>
    
    <item>
      <title>원소가 n개인 유한 집합의 부분 집합의 갯수</title>
      <link>https://freshrimpsushi.github.io/posts/the-number-of-subsets-of-finite-set-with-cardinality-n/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-number-of-subsets-of-finite-set-with-cardinality-n/</guid>
      <description>공식 유한집합 $X$ 에 대해 $n(X)=n$ 이면 $n(P(X))=2^{ n }$ 이다. 유도 $n$ 개의 원소 중에서 $k$ 개의 원소를 선택하는 부분집합의 갯수는 $_{ n }{ C }_{ k }$ 이다. 이항 정리를 써서 모든 경우의 수를 더하면 $\displaystyle \sum _{ k=0 }^{ n }{_{ n }{ C }_{ k } }=2^{ n }$ 이므로 $n(P(A))=2^{ n }$ 이다. ■</description>
    </item>
    
    <item>
      <title>가비의 리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mediant/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mediant/</guid>
      <description>정리 $bdf(b+d)\neq 0$ 이면 $$ \frac { a }{ b }=\frac { c }{ d }=\frac { e }{ f } \implies \frac { a+c }{ b+d }=\frac { e }{ f } $$ 설명 &amp;lsquo;가비&amp;rsquo;는 다른 게 아니라 두 한자 더할 가加 견줄 비比로 만들어진 단어다 여기서 견줄 비는 &amp;lsquo;비율&amp;rsquo;할때의 그 비로, 이름에 모든 게 함축된 정리다. 증명 $$ \frac { a }{ b }=\frac { c }{ d }=\frac { e }{ f } $$ 이므로 $\frac { a }{</description>
    </item>
    
    <item>
      <title>구분구적법으로 구한 면적과 정적분의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-the-area-and-the-static-fraction-obtained-by-the-separation-method/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-the-area-and-the-static-fraction-obtained-by-the-separation-method/</guid>
      <description>공식 $$ \begin{align*} &amp;amp; \lim _{ n\to \infty }{ \sum _{ k=1 }^{ n }{ f\left( a+\frac { p }{ n }k \right) \frac { p }{ n } } } \\ =&amp;amp; \int _{ a }^{ a+p }{ f(x)dx } \\ =&amp;amp; \int _{ 0 }^{ p }{ f(a+x)dx } \\ =&amp;amp; \int _{ 0 }^{ 1 }{ pf(a+px)dx } \end{align*} $$ 설명 이따금 보면 극한을 빙자한 적분 문제가 있다. 물론 대개는 극한을 구하는 그 자체로도 풀 수 있게 해놓기 때문에 몰라도 크게 상관은 없다. 하지만 가끔, 아주 가끔 저 관계 자체를 아는지 모르는지 묻는 경우가</description>
    </item>
    
    <item>
      <title>낙하한 물체의 속도를 구하는 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/velocity-of-falling-body/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/velocity-of-falling-body/</guid>
      <description>공식 $g$ 가 중력가속도라고 하자. 어떤 물체가 중력에 의해 높은 곳에서 낮은 곳으로 떨어졌을때, 이 물체의 속도를 낙하한 거리 $h$ 에 대한 공식으로 나타내면 다음과 같다. $$ v=\sqrt { 2gh } $$ 유도 우리가 구하고자 하는 것과 상관 없는 조건들은 모두 무시하기로 하자. 정지해있던 물체가 $h$ 만큼 낙하했을 때의 속도를 $v$라 하자.이때 역학적 에너지가 보존되므로 $$ \frac</description>
    </item>
    
    <item>
      <title>드 무아브르의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-de-moivres-theorem/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-de-moivres-theorem/</guid>
      <description>정리 $z = r \text{cis} \theta$ 이면 모든 자연수 $n$ 에 대해 $z^n = r^n \text{cis} n\theta$ 이 성립한다. $\text{cis} \theta: = \cos \theta + i \sin \theta$ 증명 수학적 귀납법을 사용하자. $n=1$ 에 대해서는 자명하고, $n=k$ 에 대해서도 성립한다고 가정하면 $$ z^{k+1} = z z^k = (r \text{cis} \theta)(r^k \text{cis} k\theta) $$ 이다. 한편 $z_1 z_2 = r_1 r_2 \text{cis} (\theta_1 + \theta_2)$ 이므로 $$ z^{k+1} = r^{k+1} \text{cis} (k+1)\theta $$ $n=k$ 일 때 $n=k+1$ 에 대해서도 성립하므로 주어진 식은 모든 자연수에 대해 성립한다. ■</description>
    </item>
    
    <item>
      <title>삼각함수의  평행이동과  도함수의  관계</title>
      <link>https://freshrimpsushi.github.io/posts/11/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/11/</guid>
      <description>공식 [1] 사인: $$\sin{(\theta +\frac { n }{ 2 }\pi )}={ \sin }^{ (n) }\theta$$ [2] 코사인: $$\cos{(\theta +\frac { n }{ 2 }\pi )}={ \cos }^{ (n) }\theta$$ $(n)$ 은 $n$ 번만큼 미분을 했다는 뜻이다. 설명 쉽게 말해서, 90˚만큼 움직일 때마다 미분을 한번씩 하면 된다. 실제로 $n=3$ 에 대해서 계산을 해보자. 덧셈정리를 사용한 방법 $$ \begin{align*} \cos(\theta +{3 \over 2}\pi ) =&amp;amp; \cos\theta \cos\frac { 3 }{ 2 }\pi -\sin\theta \sin\frac { 3 }{ 2 }\pi \\ =&amp;amp; \cos\theta \cdot 0-\sin\theta \cdot (-1) \\ =&amp;amp; \sin\theta $ \end{align*} $$ 공식을 사용한 방법 $$</description>
    </item>
    
    <item>
      <title>에네스트롬-카케야 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-enestrom-kakeya-theorem/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-enestrom-kakeya-theorem/</guid>
      <description>정리 1 $\left\{ a_{i} \right\}_{i=0}^{n} \subset \mathbb{R}$ 이 $a_0 &amp;gt; a_1 &amp;gt; \cdots &amp;gt; a_n &amp;gt; 0$ 라고 하자. 그러면 다항 함수 $$ P(z) := a_0 + a_1 z + \cdots + a_{n-1} z^{n-1} + a_n z^n $$ 의 모든 근 $z \in \mathbb{C}$ 는 $|z| \ge 1$ 를 만족한다. 증명 만약 $P(z) = 0$ 의 해가 $z=1$ 이면 $\displaystyle 0 = P(1) = \sum_{i=0}^{n} a_{i} &amp;gt; 0$ 이므로 일단 해는 $z \ne 1$ 이어야한다.식 $P(z) = 0$ 의 양변에 $z$ 를 곱해 원래의 식에서 빼고 $a_0$ 에 대해 정리하면 $$ a_0 = (1-z)P(z) + (a_0 - a_1) z + \cdots + (a_{n-1} - a_n) z^n + a_n z^{n+1} $$ 이</description>
    </item>
    
    <item>
      <title>자주 쓰는 이차함수의 정적분</title>
      <link>https://freshrimpsushi.github.io/posts/15/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/15/</guid>
      <description>공식 $$ \int _{ \alpha }^{ \beta }{ (x-\alpha )(x-\beta )dx }=-\frac { { (\beta -\alpha ) } ^ { 3 } }{ 6 } $$ 설명 문제를 풀다보면 생각보다 이런 꼴의 정적분을 할 일이 많다. 풀이를 빠르게 해주는데 외엔 전혀 쓸모가 없는 공식이고 유도도 그냥 계산밖에 없다. 모양만 딱 외워서 쓸 수 있도록 하자. 유도 $$ \begin{align*} &amp;amp; \int _{ \alpha }^{ \beta }{ (x-\alpha )(x-\beta )dx } \\ &amp;amp;=\int _{ \alpha }^{ \beta }{ { {x }^2-(\alpha +\beta )x+\alpha \beta }dx } \\ &amp;amp;=\frac { \beta^3-{ \alpha^3 } }{ 3 }-(\alpha +\beta )\frac { \beta^2-\alpha^2}{ 2 }+\alpha \beta</description>
    </item>
    
    <item>
      <title>조화급수의 발산성에 대한 오렘의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/oresmes-proof-of-divergence-of-harmonic-series/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/oresmes-proof-of-divergence-of-harmonic-series/</guid>
      <description>정리 조화급수는 발산한다. $$ \sum _{ n=1 }^{ \infty }{ \frac { 1 }{ n } }=\infty $$ 설명 조화급수는 언뜻 보기에 그 값이 계속 작아지므로 수렴할 것도 같지만 오렘은 이것이 발산한다는 것을 매우 간단하고 아름답게 증명했다. 이러한 팩트는 주로 절대수렴의 개념을 설명하기 위한 예시로써 잘 쓰이는데, 교대조화급수는 $\displaystyle \sum_{n=1}^{\infty} {{(-1)^{n-1}} \over {n}} = 1- {1 \over 2} + { 1 \over 3} - { 1 \over 4 }+ \cdots = \ln 2 &amp;lt;</description>
    </item>
    
    <item>
      <title>조화평균을  활용해  평균속력  구하기</title>
      <link>https://freshrimpsushi.github.io/posts/using-harmonic-means-to-obtain-average-speed/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/using-harmonic-means-to-obtain-average-speed/</guid>
      <description>공식 거리 $S$ 만큼 갈 때 속력 $a$ 로 이동하고 올 때 속력 $b$ 로 이동했다면 평균속력 $v$ 는 다음과 같다. $$ v = \frac { 2ab }{ a+b } $$ 설명 시속 60km로 한 시간 이동한 후 시속 80km로 한 시간 더 이동했을 때 두 시간동안의 평균 속력은 70km/h다. 이처럼 시간이 단위일 경우 쉽게 산술평균으로 답을 내놓을 수 있지만, 단위가 거리일 경우 쉽게 답을 내기가 어렵다. 가</description>
    </item>
    
    <item>
      <title>평행한 두 직선 사이의 거리를 구하는 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-formula-for-distance-of-two-parallel-lines/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-formula-for-distance-of-two-parallel-lines/</guid>
      <description>공식 $$ d=\frac { |2k| }{ \sqrt { m^{ 2 }+1 } } $$ 설명 이차곡선의 접선을 구하는 문제를 풀다보면 두 접선 사이의 거리를 구하라는 경우가 종종 있다. 물론 적당한 한 점과 다른 직선의 거리를 구하는 공식이 있기 때문에 구하는 것 자체가 어려운 것은 아니다. 하지만 아주 쉽고 빠르게 그 거리를 구할 수 있는 공식을 알고 있다면 조금이라도 계산량을 줄일 수 있을 것이다. 유도 평행하는</description>
    </item>
    
    <item>
      <title>산술평균과 기하평균 조화평균사이의 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/inequalities-between-arithmatic-geometric-harmonic-means/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inequalities-between-arithmatic-geometric-harmonic-means/</guid>
      <description>정의 $n$ 개의 양수 ${x}_{1},{x}_{2},\cdots,{x}_{n}$ 에 대해 산술, 기하, 조화평균은 다음과 같다. 산술평균 : $$ \displaystyle \sum _{ k=1 }^{ n }{ \frac { {x}_{k} }{ n } }=\frac { {x}_{1}+{x}_{2}+\cdots+{x}_{n} }{ n } $$ 기하평균 : $$ \displaystyle \prod _{ k=1 }^{ n }{ { {x}_{k} }^{ \frac { 1 }{ n } } }=\sqrt [ n ]{ {x}_{1}{x}_{2}\cdots{x}_{n} } $$ 조화평균 : $$ \displaystyle \left( \frac { \sum _{ k=1 }^{ n }{ \frac { 1 }{ {x}_{k} } } }{ n } \right)^{-1}=\frac { n }{ \frac { 1 }{ {x}_{1} }+\frac { 1 }{ {x}_{2} }+\cdots+\frac { 1 }{ {x}_{n} } } $$ 정리 이에 대해 다음의 부등식이 성립한다.</description>
    </item>
    
    <item>
      <title>비축분</title>
      <link>https://freshrimpsushi.github.io/posts/1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1/</guid>
      <description>All 뒤에는 가산명사 복수형이나 비가산명사 단수형이 온다 문법 All 뒤에 올 명사를 N이라 하자. All 뒤에 오는 N은 가산명사 복수형이나 비가산명사 단수형이어야하고, &amp;ldquo;All N&amp;rdquo; 의 수는 N의 수와 일치해야한다. 예문 복수형 &amp;ldquo;모든 빨간 타일들은 키메라 상태가 양쪽 레이어에서 일어났음을 나타낸다.&amp;rdquo; &amp;ldquo;All red tiles indicate chimera states that emerge in both layers.&amp;rdquo; 1 til</description>
    </item>
    
    <item>
      <title>수업</title>
      <link>https://freshrimpsushi.github.io/posts/2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>르벡공간의 횔더 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/%EB%A5%B4%EB%B2%A1%EA%B3%B5%EA%B0%84%EC%9D%98-%ED%9A%94%EB%8D%94-%EB%B6%80%EB%93%B1%EC%8B%9D-%EC%A6%9D%EB%AA%85/</link>
      <pubDate>Thu, 12 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/%EB%A5%B4%EB%B2%A1%EA%B3%B5%EA%B0%84%EC%9D%98-%ED%9A%94%EB%8D%94-%EB%B6%80%EB%93%B1%EC%8B%9D-%EC%A6%9D%EB%AA%85/</guid>
      <description>정리1 $\Omega \subset \mathbb{R}^{n}$를 열린 집합이라고 하자. 다음의 식을 만족시키는 두 상수 $1 \lt p \lt \infty, 1 \lt p^{\prime} \lt \infty$가 주어졌다고 하자. $$ \dfrac{1}{p}+\dfrac{1}{p^{\prime}} = 1 \left(\text{or } p^{\prime} = \frac{p}{p-1} \right) $$ 만약 $u \in L^p(\Omega)$, $v\in L^{p^{\prime}}(\Omega)$이면 $uv \in L^1(\Omega)$이고 아래의 부등식이 성립한다. $$ \| uv \|_{1} = \int_{\Omega} |u(x)v(x)| dx \le \| u</description>
    </item>
    
    <item>
      <title></title>
      <link>https://freshrimpsushi.github.io/posts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
