<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>数理統計学 on 生エビ寿司屋</title><link>https://freshrimpsushi.github.io/jp/categories/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99/</link><description>Recent content in 数理統計学 on 生エビ寿司屋</description><generator>Hugo -- gohugo.io</generator><language>jp</language><lastBuildDate>Tue, 01 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/jp/categories/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99/index.xml" rel="self" type="application/rss+xml"/><item><title>確率ベクトル</title><link>https://freshrimpsushi.github.io/jp/posts/3665/</link><pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/3665/</guid><description>定義 次の条件を満たすベクトル$\mathbf{p} = \begin{bmatrix}p_{1} &amp;amp; \cdots &amp;amp; p_{n} \end{bmatrix}^{\mathsf{T}}$を確率ベクトルproba</description></item><item><title>コクランの定理の証明</title><link>https://freshrimpsushi.github.io/jp/posts/2655/</link><pubDate>Tue, 27 May 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2655/</guid><description>定理 サンプル $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ が $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} N \left( 0, \sigma^{2} \right)$ のように iid で 正規分布 に従うとしよう。ランク が $r_{j}$ の 対称行列 $A_{1} , \cdots , A_{k} \in \mathbb{R}^{n \times n}$ に対して 確率</description></item><item><title>ホッグ・クレイグ定理の証明</title><link>https://freshrimpsushi.github.io/jp/posts/2651/</link><pubDate>Mon, 19 May 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2651/</guid><description>定理 サンプル $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ が $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} N \left( 0, \sigma^{2} \right)$ のように iid より 正規分布 に従うとしよう。対称行列 $A_{1} , \cdots , A_{k} \in \mathbb{R}^{n \times n}$ に対して 確率変数 $Q_{1} , \cdots</description></item><item><title>クレイグの定理の証明</title><link>https://freshrimpsushi.github.io/jp/posts/2647/</link><pubDate>Sun, 11 May 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2647/</guid><description>定理 サンプル $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ は $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} N \left( 0, \sigma^{2} \right)$ と同様に iid で 正規分布 に従うと仮定する。対称行列 $A, B \in \mathbb{R}^{n \times n}$ に対して 確率変数 $Q_{1}$ と $Q_{2}$ が ラン</description></item><item><title>混合分布</title><link>https://freshrimpsushi.github.io/jp/posts/3639/</link><pubDate>Tue, 06 May 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/3639/</guid><description>ビルドアップ1 下の図のような確率密度関数を持つ確率分布を近似したいとしよう。 確率分布を近似する基本的な方法の一つは、近似したい分布と最も似た</description></item><item><title>正規分布ランダムベクトルの二次形式におけるカイ二乗性の同値条件</title><link>https://freshrimpsushi.github.io/jp/posts/2639/</link><pubDate>Fri, 25 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2639/</guid><description>定理 サンプル $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ は $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} N \left( 0, \sigma^{2} \right)$ に従って iid の 正規分布 に従うとする。ランク が $r \le n$ の 対称行列 $A \in \mathbb{R}^{n \times n}$ に対して ランダムベ</description></item><item><title>正規分布ランダムベクトルの二次形式のモーメント母関数</title><link>https://freshrimpsushi.github.io/jp/posts/2637/</link><pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2637/</guid><description>定理 サンプル $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ が $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} N \left( 0, \sigma^{2} \right)$ と同様に iidで 正規分布に従うとする。 ランクが $r \le n$ である 対称行列 $A \in \mathbb{R}^{n \times n}$ に対して、</description></item><item><title>ランダムベクトルの二次形式で表された偏差平方和</title><link>https://freshrimpsushi.github.io/jp/posts/2635/</link><pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2635/</guid><description>公式 ランダムベクトル $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ と 単位行列 $I_{n} \in \mathbb{R}^{n \times n}$ およびすべての成分が $1$ である一行列 $J_{n} \in \mathbb{R}^{n \times n}$ に対して、次が成り立つ。 $$ \mathbf{X}^{T} \left( I_{n} - {\frac{ 1</description></item><item><title>ランダムベクトルの二次形式の期待値</title><link>https://freshrimpsushi.github.io/jp/posts/2633/</link><pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2633/</guid><description>公式 母平均ベクトル $\mu \in \mathbb{R}^{n}$ と 共分散行列 $\Sigma \in \mathbb{R}^{n \times n}$ に対して、ランダムベクトル が $\mathbf{X}$ となり、$\mathbf{X} \sim \left( \mu , \Sigma \right)$ とする。対称行列 $A$ に対</description></item><item><title>ランダムベクトルの二次形式</title><link>https://freshrimpsushi.github.io/jp/posts/2631/</link><pubDate>Wed, 09 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2631/</guid><description>定義 1 ランダムベクトル $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ と 対称行列 $A \in \mathbb{R}^{n \times n}$ に関して $Q = \mathbf{X}^{T} A \mathbf{X}$ を二次形式quadratic form in $\mathbf{X}$と呼ぶ</description></item><item><title>数理統計学における主成分分析（PCA）</title><link>https://freshrimpsushi.github.io/jp/posts/2606/</link><pubDate>Fri, 02 Aug 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2606/</guid><description>概要 主成分分析は、回帰分析で多重共線性を避けることやデータを要約するなど、統計学で多くの使い道があり、機械学習でも次元削減という重要な意味を</description></item><item><title>ランダムベクトルの期待値</title><link>https://freshrimpsushi.github.io/jp/posts/2555/</link><pubDate>Thu, 18 Apr 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2555/</guid><description>定義 1 $$ E \left( X \right) := \begin{bmatrix} E \left( X_{1} \right) \\ \vdots \\ E \left( X_{n} \right) \end{bmatrix} $$ ランダムベクトル $X = \left( X_{1} , \cdots , X_{n} \right)$ の期待値expectationは、上記のように各成分の期待値</description></item><item><title>条件付き期待値は偏差の二乗和を最小化する</title><link>https://freshrimpsushi.github.io/jp/posts/3514/</link><pubDate>Wed, 29 Nov 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/3514/</guid><description>要約 次のことが成り立つ。 $$ \begin{equation} E\left[ Y | X \right] = \argmin_{f(X)} E\left[ (Y - f(X))^{2} | X \right] \end{equation} $$ $$ \begin{equation} E\left[ Y | X \right] = \argmin_{f(X)} E\left[ (Y - f(X))^{2} \right] \end{equation} $$ 証明 (1) $$ \begin{align*} &amp;amp; \argmin_{f(X)} E\left[ (Y - f(X))^{2} | X \right] \\ &amp;amp;= \argmin_{f(X)} E\left[ Y^{2} - 2Yf(X) + f(X)^{2} |</description></item><item><title>合同共分散の定義</title><link>https://freshrimpsushi.github.io/jp/posts/2472/</link><pubDate>Sat, 04 Nov 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2472/</guid><description>ビルドアップ 分布が$X \sim \left( \mu , \sigma^{2} \right)$の母集団から相互独立で引いた$n$個のサンプルが実際には$m$つの母集団$\left( \mu_{1} , \sigma_{1}^{2}</description></item><item><title>加重平均の定義</title><link>https://freshrimpsushi.github.io/jp/posts/2470/</link><pubDate>Tue, 31 Oct 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2470/</guid><description>定義 データ $\mathbf{x} = \left\{ x_{1} , \cdots , x_{n} \right\}$ と ベクトル $\mathbf{w} = \left( w_{1} , \cdots , w_{n} \right) \in \mathbb{R}^{n}$ に対して、以下を加重平均weighted meanという。 $$ {{ \sum_{k=1}^{n} w_{k} x_{k} } \over { \sum_{k=1}^{n} w_{k} }} =</description></item><item><title>標準誤差の一般的な定義</title><link>https://freshrimpsushi.github.io/jp/posts/2462/</link><pubDate>Sun, 15 Oct 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2462/</guid><description>定義 1 ある推定量estimator $T$ について、$T$ の標準偏差の推定値estimateを標準誤差standard errorと言う。 $$ \text{s.e.} \left( T \right)</description></item><item><title>ユニモーダル分布の最短信頼区間</title><link>https://freshrimpsushi.github.io/jp/posts/2337/</link><pubDate>Tue, 07 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2337/</guid><description>定理 ユニモーダル関数の定義 関数 $f : \mathbb{R} \to \mathbb{R}$ が $x \le x^{\ast}$ で減少せず、$x \ge x^{\ast}$ で増加しないようにする モード $x^{\ast}$ が存在する場合、$f$ は ユニモーダル と呼ぶ</description></item><item><title>確率的増減関数と信頼区間</title><link>https://freshrimpsushi.github.io/jp/posts/2335/</link><pubDate>Fri, 03 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2335/</guid><description>定理 1 確率的単調関数の定義 累積分布関数$F \left( t ; \theta \right)$が$\theta$に対して増加（減少）関数ならば確率的増加（減少）関数とい</description></item><item><title>最も正確な信頼集合</title><link>https://freshrimpsushi.github.io/jp/posts/2333/</link><pubDate>Mon, 30 Jan 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2333/</guid><description>定義 1 $\theta$に対する仮説検定の$1 - \alpha$信頼集合を$C \left( \mathbf{x} \right)$とし、受容域を$A \left( \theta \right) = C \left( \mathbf{x} \right)</description></item><item><title>仮説検定と信頼集合の一対一対応関係</title><link>https://freshrimpsushi.github.io/jp/posts/2332/</link><pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2332/</guid><description>定理 パラメータ空間 $\Theta$ と空間 $\mathcal{X}$ が与えられているとしよう。 各々の $\theta_{0} \in \Theta$ に対して、$A \left( \theta_{0} \right)$ を仮説検定 $H_{0} : \theta = \theta_{0}$のレベル $\alpha$ 棄却</description></item><item><title>数理統計学におけるピボットの定義</title><link>https://freshrimpsushi.github.io/jp/posts/2331/</link><pubDate>Thu, 26 Jan 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2331/</guid><description>定義 1 確率変数 $Q \left( \mathbf{X} ; \theta \right) := Q \left( X_{1} , \cdots , X_{n} ; \theta \right)$ の確率分布が全てのパラメータ $\theta$ に独立ならば、$Q$ を ピボットpivot または ピボタル量piv</description></item><item><title>数理統計的な信頼集合の定義</title><link>https://freshrimpsushi.github.io/jp/posts/2329/</link><pubDate>Sun, 22 Jan 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2329/</guid><description>定義 1 パラメータ $\theta$ の区間推定値 $\left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right]$ において、以下をカバレッジ確率coverage Probabilityと呼ぶ。 $$ P_{\theta} \left( \theta \in \left[ L</description></item><item><title>区間推定量</title><link>https://freshrimpsushi.github.io/jp/posts/2327/</link><pubDate>Wed, 18 Jan 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2327/</guid><description>定義 1 パラメーター$\theta \in \mathbb{R}$に対して、順序対$\left( L \left( x_{1} , \cdots , x_{n} \right), U \left( x_{1} , \cdots , x_{n} \right) \right)$が全て</description></item><item><title>数理統計的な有意確率の定義</title><link>https://freshrimpsushi.github.io/jp/posts/2304/</link><pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2304/</guid><description>定義 1 仮説検定 $H_{0} \text{ vs } H_{1}$が与えられているとしよう。全ての実現 $\mathbf{x} \in \Omega$に対して$0 \le p \left( \mathbf{x} \right) \le 1$を満たす検定統計量 $p \left( \mathbf{X}</description></item><item><title>十分統計量を含む最強力検定</title><link>https://freshrimpsushi.github.io/jp/posts/2301/</link><pubDate>Sun, 27 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2301/</guid><description>定理 仮説検定: $$ \begin{align*} H_{0} :&amp;amp; \theta = \theta_{0} \\ H_{1} :&amp;amp; \theta = \theta_{1} \end{align*} $$ このような仮説検定では、十分統計量 $T$ の $\theta_{0}, \theta_{1}$ に対する確率密度関数または確率質量関数を $g \left( t | \theta_{0} \right), g</description></item><item><title>カリン-ルビン定理の証明</title><link>https://freshrimpsushi.github.io/jp/posts/2299/</link><pubDate>Wed, 23 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2299/</guid><description>定理 仮説検定: $$ \begin{align*} H_{0} :&amp;amp; \theta \le \theta_{0} \\ H_{1} :&amp;amp; \theta &amp;gt; \theta_{0} \end{align*} $$ このような仮説検定では、$T$ を $\theta$ の十分統計量と言い、$t$ の確率密度関数または確率質量関数のフ</description></item><item><title>単調確率の定義</title><link>https://freshrimpsushi.github.io/jp/posts/2297/</link><pubDate>Sat, 19 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2297/</guid><description>定義 パラメーター$\theta \in \mathbb{R}$と一変量確率変数$T$に関する確率質量関数または確率密度関数のファミリーを$G := \left\{ g (</description></item><item><title>ネイマン-ピアソン補助定理の証明</title><link>https://freshrimpsushi.github.io/jp/posts/2295/</link><pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2295/</guid><description>定理 仮説検定: $$ \begin{align*} H_{0} :&amp;amp; \theta = \theta_{0} \\ H_{1} :&amp;amp; \theta = \theta_{1} \end{align*} $$ 上記の仮説検定において、$\theta_{0}, \theta_{1}$の確率密度関数または確率質</description></item><item><title>一変量確率変数のサンプリング方法</title><link>https://freshrimpsushi.github.io/jp/posts/2294/</link><pubDate>Sun, 13 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2294/</guid><description>概要 確率変数の具体的な実現を求める方法だ。 定理 単変量確率変数 $T$ の累積分布関数 $F = F_{T}$ が増加関数だとする。そうすると、一様分布に従う確率変数 $U \sim</description></item><item><title>不便検定力関数と最強力検定</title><link>https://freshrimpsushi.github.io/jp/posts/2293/</link><pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2293/</guid><description>定義 1 仮説検定: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 検定力関数 $\beta (\theta)$が全ての$\theta_{0} \in \Theta_{0}$と$\th</description></item><item><title>仮説検定の検定力関数</title><link>https://freshrimpsushi.github.io/jp/posts/2291/</link><pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2291/</guid><description>定義 1 仮説検定: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ このような仮説検定が与えられていて、$\alpha \in [0,1]$ とする。 パラメータ $\theta$ に対して、棄却域が $R$</description></item><item><title>十分統計量を含む尤度比検定</title><link>https://freshrimpsushi.github.io/jp/posts/2289/</link><pubDate>Thu, 03 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2289/</guid><description>定理 仮説検定: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 尤度比検定統計量: $$ \lambda \left( \mathbf{x} \right) := {{ \sup_{\Theta_{0}} L \left( \theta \mid \mathbf{x} \right) } \over { \sup_{\Theta} L \left( \theta \mid \mathbf{x} \right) }} $$ $T \left( \mathbf{X} \right)$がパ</description></item><item><title>数理統計学における尤度比検定の定義</title><link>https://freshrimpsushi.github.io/jp/posts/2287/</link><pubDate>Sun, 30 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2287/</guid><description>定義 1 $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 上記の仮説検定について、次の統計量 $\lambda$ を 尤度比検定統計量likelihood Ratio test statisticと言う。</description></item><item><title>ロケーションファミリーの十分統計量と最尤推定量</title><link>https://freshrimpsushi.github.io/jp/posts/2285/</link><pubDate>Wed, 26 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2285/</guid><description>定理 確率密度関数が$f_{X} \left( x ; \theta \right) = f_{X} \left( x - \theta \right)$であるロケーションファミリーから得たランダムサンプル$X_{1} , \cdots , X_{n}</description></item><item><title>数理統計的な仮説検定の定義</title><link>https://freshrimpsushi.github.io/jp/posts/2283/</link><pubDate>Sat, 22 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2283/</guid><description>定義 1 パラメーターに関する命題を仮説hypothesisという。 与えられたサンプルに基づき仮説$H_{0}$を真と受け入れるか、仮説$H_{</description></item><item><title>ランダムサンプルの標本平均の平均と分散</title><link>https://freshrimpsushi.github.io/jp/posts/2281/</link><pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2281/</guid><description>説明 簡単すぎて、実際に簡単だからって適当に考えてると、突然聞かれると意外と混乱して恥ずかしいのがまさに標本平均の平均と分散だ。少しだけ頭を使</description></item><item><title>唯一の最尤推定量は十分統計量に依存する</title><link>https://freshrimpsushi.github.io/jp/posts/2279/</link><pubDate>Fri, 14 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2279/</guid><description>定理 もしパラメータ $\theta$ に対する十分統計量 $T$ が存在し、$\theta$ の最尤推定量 $\hat{\theta}$ が一意に存在するなら、$\hat{\theta}$ は $T$ の関数</description></item><item><title>レマン-シェップの定理の証明</title><link>https://freshrimpsushi.github.io/jp/posts/2277/</link><pubDate>Mon, 10 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2277/</guid><description>定理 1 2 完備 十分 統計量に従属する不偏推定量は一意的である。つまり、$\theta$ の完備十分統計量 $T$ について、もし $E \left[ \phi (T) \right] = \tau (\theta)$ ならば $\phi (T)$</description></item><item><title>最小分散不偏推定量の一意性</title><link>https://freshrimpsushi.github.io/jp/posts/2275/</link><pubDate>Thu, 06 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2275/</guid><description>定理 1 もし$W$が$\tau (\theta)$の最良不偏推定量だったら、$W$は唯一無二である。 証明 コーシー・シュヴァルツの不等式：確率変数</description></item><item><title>最良不偏推定量、最小分散不偏推定量 UMVUE</title><link>https://freshrimpsushi.github.io/jp/posts/2273/</link><pubDate>Sun, 02 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2273/</guid><description>定義 1 パラメータ $\theta$ が与えられているとする。偏りのない推定量 $W^{\ast}$ が、他の全ての偏りのない推定量 $W$ に対して以下を満たす場合、それを 最良偏りのない推</description></item><item><title>不偏推定量とクラメール・ラオの限界</title><link>https://freshrimpsushi.github.io/jp/posts/2271/</link><pubDate>Wed, 28 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2271/</guid><description>定理 正則条件: (R0): 確率密度関数 $f$ は $\theta$ について単射である。次の式を満たす。 $$ \theta \ne \theta ' \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta ' \right) $$ (R1): 確率密度関数 $f$ は全ての $\theta$ に</description></item><item><title>最尤推定量の不変性の証明</title><link>https://freshrimpsushi.github.io/jp/posts/2269/</link><pubDate>Sat, 24 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2269/</guid><description>정리 最尤推定量は、関数を取ることに関して不変invariantだ。つまり、もし$\hat{\theta}$がパラメータ$\theta$の最尤</description></item><item><title>サタスウェイトの近似</title><link>https://freshrimpsushi.github.io/jp/posts/2267/</link><pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2267/</guid><description>ビルドアップ 自由度が$r_{k}$のカイ二乗分布に従う独立した$n$個の確率変数$Y_{k} \sim \chi_{r_{k}}^{2}$があるとしよ</description></item><item><title>ロケーション-スケール族の補助統計量</title><link>https://freshrimpsushi.github.io/jp/posts/2265/</link><pubDate>Fri, 16 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2265/</guid><description>定理 1 $X_{1} , \cdots , X_{n}$がロケーションファミリーであり、かつスケールファミリーから来るランダムサンプルであるとしよう。二つの統計量 $T_{1} \left( X_{1} ,</description></item><item><title>最小十分統計量が与えられた偏りのない推定量の分散は最小化される</title><link>https://freshrimpsushi.github.io/jp/posts/2263/</link><pubDate>Mon, 12 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2263/</guid><description>定理 1 パラメーター $\theta$ が与えられたとしよう。$U$ は不偏推定量、$T_{1}$ は十分統計量で、$T_{2}$ は最小十分統計量で以下のように $$ \begin{align*}</description></item><item><title>指数族確率分布の完全統計量</title><link>https://freshrimpsushi.github.io/jp/posts/2261/</link><pubDate>Thu, 08 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2261/</guid><description>定理 1 パラメーター$\mathbf{\theta} = \left( \theta_{1} , \cdots , \theta_{k} \right)$が与えられて、ランダムサンプル$X_{1} , \cdots , X_{n}$</description></item><item><title>モーメント法</title><link>https://freshrimpsushi.github.io/jp/posts/2259/</link><pubDate>Sun, 04 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2259/</guid><description>定義 1 与えられた分布のパラメーターを知らない場合に、モーメントを利用してパラメーターに関する連立方程式を作り、その解をパラメーターの推定値と</description></item><item><title>ベズーの定理の証明</title><link>https://freshrimpsushi.github.io/jp/posts/2257/</link><pubDate>Wed, 31 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2257/</guid><description>定理 もし$T \left( \mathbf{X} \right)$が完結統計量であり、最小十分統計量でもあるなら、$T \left( \mathbf{X} \right)$は全ての補助統計量と独立である。 説明</description></item><item><title>十分統計量</title><link>https://freshrimpsushi.github.io/jp/posts/2255/</link><pubDate>Sat, 27 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2255/</guid><description>定義 1 $\Omega$をパラメータの集合としよう。サンプル$\mathbf{X}$の統計量$T := T \left( \mathbf{X} \right)$の確率密度関数または確</description></item><item><title>スケールファミリー</title><link>https://freshrimpsushi.github.io/jp/posts/2253/</link><pubDate>Tue, 23 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2253/</guid><description>定義 累積分布関数 $F$ が全ての $x$ に対して $F_{\sigma} (x) = F \left( x / \sigma \right)$ を満たすとしよう。 $\left\{ F_{\sigma} : \sigma &amp;gt; 0 \right\}$ をスケールファミリーという。 例 1 パラメータ $\sigma$ のランダム</description></item><item><title>ロケーションファミリー</title><link>https://freshrimpsushi.github.io/jp/posts/2251/</link><pubDate>Fri, 19 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2251/</guid><description>定義 累積分布関数 $F$ について $F_{\theta}$ が全ての $x$ に対し $F_{\theta} (x) = F \left( x - \theta \right)$ を満たすとする。 $\left\{ F_{\theta} : \theta \in \mathbb{R} \right\}$ をロケーションファミリーと呼ぶ。 例 1 パラメーター</description></item><item><title>補助統計量</title><link>https://freshrimpsushi.github.io/jp/posts/2249/</link><pubDate>Mon, 15 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2249/</guid><description>定義 1 $S$がサンプルの$\mathbf{X}$の統計量だとしよう。$S \left( \mathbf{X} \right)$の分布が母数$\theta$に依存しない場合、補</description></item><item><title>最小十分統計量</title><link>https://freshrimpsushi.github.io/jp/posts/2247/</link><pubDate>Thu, 11 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2247/</guid><description>定義 1 $T \left( \mathbf{X} \right)$を十分統計量だとしよう。全ての別の十分統計量$T ' \left( \mathbf{X} \right)$に対して、$T \left( \mathbf{x} \right)$が$T '</description></item><item><title>尤度関数の定義</title><link>https://freshrimpsushi.github.io/jp/posts/2239/</link><pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2239/</guid><description>定義 1 サンプル $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right)$ のジョイント確率密度関数または確率質量関数を$f(\mathbf{x}|\theta)$ としよう。その実現が</description></item><item><title>数理統計学におけるデルタ法</title><link>https://freshrimpsushi.github.io/jp/posts/2237/</link><pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2237/</guid><description>定理 定数$\theta \in \mathbb{R}$と確率変数のシーケンス$\left\{ Y_{n} \right\}_{n \in \mathbb{N}}$について、$\sqrt{n</description></item><item><title>スターリングの公式の統計的証明</title><link>https://freshrimpsushi.github.io/jp/posts/2235/</link><pubDate>Mon, 18 Jul 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2235/</guid><description>정리 $$ \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ 설명 スターリングの近似またはスターリングの公式stirling formulaは、統計学や物理学など</description></item><item><title>指数族の確率分布</title><link>https://freshrimpsushi.github.io/jp/posts/2213/</link><pubDate>Sat, 04 Jun 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2213/</guid><description>定義 1 2 パラメーター $\theta$ を持つ確率分布の確率質量関数または確率密度関数が、いくつかの関数 $p,K,H,q,h,c,w_{i},t_{i}$ に対して以下のように表せる場合、それは 指数族expo</description></item><item><title>確率密度関数の畳み込み公式</title><link>https://freshrimpsushi.github.io/jp/posts/2211/</link><pubDate>Tue, 31 May 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2211/</guid><description>式 1 ２つの独立した連続確率変数 $X, Y$ の確率密度関数が $f_{X}, f_{Y}$ で与えられるとする。それでは、$Z := X + Y$ の確率密度関数は２つの確率密度関数の畳み込み</description></item><item><title>関数形の確率変数の和の期待値</title><link>https://freshrimpsushi.github.io/jp/posts/2209/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2209/</guid><description>定理 1 $X_{1} , \cdots , X_{n}$がランダムサンプルであり、$E g \left( X_{1} \right)$と$\Var g \left( X_{1} \right)$が存在して$g : \mathbb{R} \to \mat</description></item><item><title>ラオ・ブラックウェルの定理の証明</title><link>https://freshrimpsushi.github.io/jp/posts/2107/</link><pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2107/</guid><description>定理 1 2 パラメーター $\theta$ が与えられたとする。$T$ が $\theta$ の十分統計量で、$W$ が $\tau \left( \theta \right)$ の不偏推定量である場合、$\phi \left( T \right) := E \left( W | T \right)$ を</description></item><item><title>ノイマン因数分解定理の証明</title><link>https://freshrimpsushi.github.io/jp/posts/2084/</link><pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2084/</guid><description>定理 random sample $X_{1} , \cdots , X_{n}$ がパラメータ $\theta \in \Theta$ に対して同じ確率質量/密度関数$f \left( x ; \theta \right)$ を持つとしよう。統計量 $Y = u_{1} \left( X_{1} , \cdots , X_{n} \right)$ が $\theta$ の 十分統計量 で</description></item><item><title>十分統計量</title><link>https://freshrimpsushi.github.io/jp/posts/2061/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2061/</guid><description>定義 数式的な定義 1 パラメータ$\theta \in \Theta$に対するランダムサンプル$X_{1} , \cdots , X_{n}$の確率質量/密度関数を$f(</description></item><item><title>効率的な推定量</title><link>https://freshrimpsushi.github.io/jp/posts/2059/</link><pubDate>Sat, 31 Jul 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2059/</guid><description>定義 1 $Y$がパラメーター$\theta$に対する不偏推定量であるとしよう。 クラメール・ラオ下界 $\text{RC}$に対する推定量$Y$の</description></item><item><title>ラオ-ブラックウェル-コルモゴロフ定理</title><link>https://freshrimpsushi.github.io/jp/posts/2057/</link><pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2057/</guid><description>要旨 1 正則条件： (R0)：確率密度関数$f$は$\theta$に対して単射である。数式で表せば次を満たす。 $$ \theta \ne \theta ' \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ;</description></item><item><title>バートレットの同一性</title><link>https://freshrimpsushi.github.io/jp/posts/2055/</link><pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2055/</guid><description>定理 正則条件: (R0): 確率密度関数$f$は$\theta$に対して単射である。数式で示すと以下を満たす。 $$ \theta \ne \theta ' \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta ' \right) $$</description></item><item><title>フィッシャー情報</title><link>https://freshrimpsushi.github.io/jp/posts/2034/</link><pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2034/</guid><description>ビルドアップ スコア関数 パラメータ $\theta \in \Theta$ に対する確率密度関数が $f \left( x ; \theta \right)$ である確率変数 $X$ を考えよう。対数尤度関数が最大になる推定量である最尤</description></item><item><title>数理統計学における正則性条件</title><link>https://freshrimpsushi.github.io/jp/posts/2029/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2029/</guid><description>概要 数学を使用する科目では、正則性regularity conditionsとは、一般的に応用の範囲が広く、理論的な展開を容易にする条件を指し</description></item><item><title>最尤推定量</title><link>https://freshrimpsushi.github.io/jp/posts/2026/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2026/</guid><description>ビルドアップ パラメータ$\theta \in \Theta$に対して、確率密度関数が$f \left( x ; \theta \right)$である確率変数$X$について考えよう</description></item><item><title>一致推定量</title><link>https://freshrimpsushi.github.io/jp/posts/2021/</link><pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2021/</guid><description>定義 1 確率変数$X$が累積分布関数$F ( x ; \theta), \theta \in \Theta$を持つとする。$X_{1} , \cdots , X_{n}$を$X$から抽出されたサンプルと</description></item><item><title>スチューデントのt検定の証明</title><link>https://freshrimpsushi.github.io/jp/posts/203/</link><pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/203/</guid><description>定理 1 確率変数 $X_{1} , \cdots , X_{n}$ がiidで正規分布 $N\left( \mu,\sigma^{2} \right)$ に従うとすると (a): $$ \overline{X} \sim N\left( \mu , { {\sigma^2} \over {n} } \right) $$ (b): $$ \overline{X} \perp S^2 $$ (c): $$ (n-1) { {S^2} \over {\sigma^2} } \sim \chi^2 (n-1) $$ (d): $$ T = { {\overline{X} -</description></item><item><title>多変量確率変数の分布収束</title><link>https://freshrimpsushi.github.io/jp/posts/2009/</link><pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/2009/</guid><description>定義1 $p$次元ランダムベクトル$\mathbf{X}$とランダムベクトルのシークエンス$\left\{ \mathbf{X}_{n} \right\}$が次の条件を満た</description></item><item><title>多変量確率変数の確率収束</title><link>https://freshrimpsushi.github.io/jp/posts/1952/</link><pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1952/</guid><description>定義 1 $p$次元のランダムベクトル$\mathbf{X}$とランダムベクトルのシーケンス$\left\{ \mathbf{X}_{n} \right\}$が下記を満たす時</description></item><item><title>共分散行列</title><link>https://freshrimpsushi.github.io/jp/posts/1950/</link><pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1950/</guid><description>定義1 $p$次元ランダムベクトル$\mathbf{X} = \left( X_{1}, \cdots , X_{p} \right)$に対して、次のように定義された$\operatorname</description></item><item><title>中心極限定理の証明</title><link>https://freshrimpsushi.github.io/jp/posts/43/</link><pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/43/</guid><description>定理 1 $\left\{ X_{k} \right\}_{k=1}^{n}$がiid確率変数で、確率分布$\left( \mu, \sigma^2 \right) $に従うとき、$n \to \infty$で $$ \sqrt{n} {{ \overline{X}_n</description></item><item><title>弱い大数の法則の証明</title><link>https://freshrimpsushi.github.io/jp/posts/32/</link><pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/32/</guid><description>法則 $\left\{ X_{k} \right\}_{k=1}^{n}$がiidの確率変数であり、分布 $\left( \mu, \sigma^2 \right) $に従うとき、$n \to \infty$であるならば $$ \overline{X}_n \overset{P}{\to} \mu $$</description></item><item><title>分布の収束は確率の境界を意味する</title><link>https://freshrimpsushi.github.io/jp/posts/176/</link><pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/176/</guid><description>定理 確率変数のシーケンス $\left\{ X_{n} \right\}$ が分布収束する場合、確率的に有界である。 $\overset{D}{\to}$ は分布収束を意味する。 説明 ほぼ確実に収束するならば分布収束することを</description></item><item><title>確率収束は分布収束を意味する</title><link>https://freshrimpsushi.github.io/jp/posts/175/</link><pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/175/</guid><description>定理1 確率変数 $X$ とその シーケンス $\left\{ X_{n} \right\}$ について $$ X_{n} \overset{P}{\to} X \implies X_{n} \overset{D}{\to} X $$ $\overset{P}{\to}$ は確率収束を意味する。 $\overset{D}{\to}$ は分布収束を意味する。 説明 もっと直感的に言い換える</description></item><item><title>数理統計学における確率の境界</title><link>https://freshrimpsushi.github.io/jp/posts/1922/</link><pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1922/</guid><description>定義 1 ある確率変数のシークエンス $\left\{ X_{n} \right\}$ が与えられているとする。全ての $\varepsilon &amp;gt; 0$ に対して、次を満たす$N_{\varepsilon} \in \mathbb{N}$ および定数</description></item><item><title>数理統計学における分布収束</title><link>https://freshrimpsushi.github.io/jp/posts/1888/</link><pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1888/</guid><description>定義 1 確率変数 $X$ と確率変数のシーケンス $\left\{ X_{n} \right\}$ が次を満たす場合、$n \to \infty$ の時、$X_{n}$ へ分布収束convergence in distribu</description></item><item><title>数理統計学における確率収束</title><link>https://freshrimpsushi.github.io/jp/posts/1789/</link><pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1789/</guid><description>定義 1 確率変数 $X$ と確率変数のシーケンス $\left\{ X_{n} \right\}$ が次を満たすとき、$n \to \infty$ のとき $X$ に確率収束すると言い、$X_{n} \overset{P}{\to} X$ と示される。 $$ \forall \varepsilon &amp;gt; 0 ,</description></item><item><title>順序統計量</title><link>https://freshrimpsushi.github.io/jp/posts/1757/</link><pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1757/</guid><description>定理1 ランダムサンプル $X_{1} , \cdots , X_{n}$ がサポート $\mathcal{S} =(a,b)$ を持つ確率密度関数 $f(x)$ を有し、連続確率分布に従うとしよう。これらを大きさ順に並べた確率変数を $Y_{1} &amp;lt;</description></item><item><title>標本分散をn-1で割る理由</title><link>https://freshrimpsushi.github.io/jp/posts/1747/</link><pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1747/</guid><description>なぜ n-1で割るのか? $X_{i} \sim \left( \mu , \sigma^{2} \right)$ とすると、標本分散 $S^{2}$ は次のようになる。 $$ S^{2} := {{1} \over {n-1}} \sum_{i=1}^{n} \left( X_{i} - \overline{X} \right)^{2} $$ ご存知の通り、標本平均と異なり、標本分散</description></item><item><title>不偏推定量</title><link>https://freshrimpsushi.github.io/jp/posts/1745/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1745/</guid><description>定義 1 $\theta$ の推定量 $T$ が次を満たす場合、$T$ は $\theta$ の不偏推定量unbiased estimatorと呼ばれる。 $$ E T = \theta $$ 説明 特に、$\theta</description></item><item><title>便宜性-分散トレードオフ</title><link>https://freshrimpsushi.github.io/jp/posts/1739/</link><pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1739/</guid><description>定義 $$ \text{MSE} \left( \widehat{\theta} \right) = \Var \widehat{\theta} + \left( \text{Bias} \widehat{\theta} \right)^{2} $$ 説明 平均二乗誤差 $\text{MSE}$ は、統計モデルの評価や機械学習の損失関数としてよく使用される指標で、特にバイアスと分散のト</description></item><item><title>数理統計学における便宜</title><link>https://freshrimpsushi.github.io/jp/posts/1735/</link><pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1735/</guid><description>定義 パラメーター$\theta$に対する推定量$\widehat{\theta}$について、以下のように定義された$\text{Bias}$</description></item><item><title>信頼区間の簡単な定義</title><link>https://freshrimpsushi.github.io/jp/posts/1732/</link><pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1732/</guid><description>定義 1 確率密度関数 $f (x; \theta)$ を持つ確率変数 $X$ のサンプル $X_{1} , \cdots , X_{n}$ と信頼係数confidence Coefficient $\alpha \in (0,1)$ が与えられているとしよう。 $$ L := L \left( X_{1} , \cdots</description></item><item><title>数理統計学における統計量と推定量</title><link>https://freshrimpsushi.github.io/jp/posts/1730/</link><pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1730/</guid><description>定義 1 2 確率変数 $X$ のサンプル $X_{1} , \cdots , X_{n}$ の関数 $T$ を統計量statisticと言う。 $$ T := T \left( X_{1} , \cdots , X_{n} \right) $$ $X$ の分布関数が $f(x; \theta)$ あるいは $p(x; \theta)$ のよう</description></item><item><title>数理統計学におけるランダムサンプリング</title><link>https://freshrimpsushi.github.io/jp/posts/1715/</link><pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1715/</guid><description>定義 1 確率変数 $X$の実際に引き出された結果を実現realizationと言い、普通、小文字の$x$で表す。 確率変数$X$と同じ確率分布から</description></item><item><title>確率変数の線形結合</title><link>https://freshrimpsushi.github.io/jp/posts/1479/</link><pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1479/</guid><description>一緒に見る 特定の分布に従う確率変数の加算</description></item><item><title>二つの正規分布に従う確率変数が独立であることと共分散が0であることは等価である</title><link>https://freshrimpsushi.github.io/jp/posts/591/</link><pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/591/</guid><description>요약 $$ X_{1} \sim N ( \mu_{1} , \sigma_{1} ) \\ X_{2} \sim N ( \mu_{2} , \sigma_{2} ) $$ 面 $$ X_{1} \perp X_{2} \iff \text{cov} (X_{1} , X_{2} ) = 0 $$ 설명 일반적으로 상관관계가 없다고 독립인 것은 아니야. 하지만 분포들이 정규분포</description></item><item><title>バーンスタイン分布：対の独立は相互独立を意味しない</title><link>https://freshrimpsushi.github.io/jp/posts/206/</link><pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/206/</guid><description>定義 $(x,y,z) \in \left\{ (1,0,0), (0,1,0), (0,0,1), (1,1,1) \right\}$ に対して、以下の確率質量関数を持つ分布を バーンスタイン分布bernstein distributionという。 $$ p(x,y,z) = {{1} \over {4}</description></item><item><title>確率変数の独立性とiid</title><link>https://freshrimpsushi.github.io/jp/posts/1469/</link><pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1469/</guid><description>定義1 確率変数$X_{1} , \cdots , X_{n}$が次を満たすとき、$X_{1} , \cdots , X_{n}$はペアワイズ独立と言われる。 $$ i \ne j \implies X_{i} \perp X_{j} $$ 連</description></item><item><title>数理統計学における確率変数の独立</title><link>https://freshrimpsushi.github.io/jp/posts/1461/</link><pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1461/</guid><description>定義 1 二つの確率変数 $X_{1}, X_{2}$ の結合確率密度関数 $f$ または確率質量関数 $p$ が、$X_{1}, X_{2}$ の確率密度関数 $f_{1}, f_{2}$ または確率質量関数 $p_{1}, p_{2}$ で以下を満たす場</description></item><item><title>数理統計学における条件付き確率分布</title><link>https://freshrimpsushi.github.io/jp/posts/1458/</link><pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1458/</guid><description>定義1 離散確率ベクトル $(X, Y)$に対して、$p_{X, Y}$を$(X, Y)$の結合確率質量関数とする。$p_{X}$を$X$の周辺確率質量関数</description></item><item><title>多変量確率変数の変換</title><link>https://freshrimpsushi.github.io/jp/posts/1455/</link><pubDate>Fri, 17 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1455/</guid><description>公式 多変量確率変数 $X = ( X_{1} , \cdots , X_{n} )$ の結合確率密度関数 $f$ が次のように与えられているとする。 $$ y_{1} = u_{1} (x_{1} , \cdots , x_{n}) \\ \vdots \\ y_{n} = u_{n} (x_{1} , \cdots , x_{n}) $$ このよう</description></item><item><title>数理統計学における多変量確率分布</title><link>https://freshrimpsushi.github.io/jp/posts/1449/</link><pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1449/</guid><description>定義 1 標本空間 $\Omega$で定義された$n$個の確率変数 $X_{i}$に対し$X = (X_{1} , \cdots , X_{n})$を$n$次元ランダムベクトルra</description></item><item><title>n次のモーメントが存在する場合、nより小さい次数のモーメントも存在する</title><link>https://freshrimpsushi.github.io/jp/posts/247/</link><pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/247/</guid><description>定理 確率変数 $X$ と自然数 $n$ に対して $E( X^n )$ が存在するなら、$E( X^m ), m=1,2,3,\cdots, n$ も存在する。 説明 ある次数の積率が存在するだけで、それより小さい次数の積率</description></item><item><title>積率母関数とは何か？</title><link>https://freshrimpsushi.github.io/jp/posts/248/</link><pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/248/</guid><description>定義 1 確率変数$X$とある正の数$h&amp;gt;0$に対して、$E(e^{tX})$が$-h&amp;lt; t &amp;lt; h$で存在するならば、$M(t) = E( e^{tX} )</description></item><item><title>数理統計学における尖度</title><link>https://freshrimpsushi.github.io/jp/posts/1271/</link><pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1271/</guid><description>尖度 確率変数 $X$ の平均が $\mu$、分散が $\sigma^2$の場合、以下のように定義される $X$の尖度kurtosisは、 $$ \gamma_{2} := {{ E \left( X - \mu</description></item><item><title>数理統計学における歪度</title><link>https://freshrimpsushi.github.io/jp/posts/1268/</link><pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1268/</guid><description>定義 確率変数$X$の平均が$\mu$で、分散が$\sigma^2$だとする時、次のように定義された$\gamma_{1}$を$X$の歪度sk</description></item><item><title>共分散の様々な性質</title><link>https://freshrimpsushi.github.io/jp/posts/425/</link><pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/425/</guid><description>定義と性質 平均がそれぞれ$\mu_{X}$、$\mu_{Y}$である確率変数$X$と$Y$について、$\operatorname{Cov} (X</description></item><item><title>ピアソン相関係数</title><link>https://freshrimpsushi.github.io/jp/posts/57/</link><pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/57/</guid><description>定義 1 二つの確率変数 $X, Y$ に対して次のように定義される $\rho = \rho (X,Y)$ を ピアソン相関係数pearson Correlation と呼ぶ。 $$ \rho = { {\operatorname{Cov} (X,Y)} \over {\sigma_X \sigma_Y} } $$ $\sigma_{X}$, $\sigma_{Y}$ はそれぞれ $X$,</description></item><item><title>平均と分散の性質들</title><link>https://freshrimpsushi.github.io/jp/posts/424/</link><pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/424/</guid><description>定理 平均 $E ( X ) = \mu_{X}$ と分散 $\Var (X) = E [ ( X - \mu_{X} )^2 ]$ は以下の性質を持っている。 [1]: $E(X + Y) = E(X) + E(Y)$ [2]: $E(aX + b) = a E(X) + b$ [3]: $\Var (X) \ge 0$ [4]: $\Var ( X ) = E(X^2) - \mu_{X}^2$ [5]: $\Var</description></item><item><title>代表値の数理的性質の証明</title><link>https://freshrimpsushi.github.io/jp/posts/49/</link><pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/49/</guid><description>定理 データ $X = \left\{ x_{1} , \cdots , x_{n} \right\}$ が与えられているとしよう。 0: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{0}$ を最小にする $\theta$ は $$ \argmin_{\theta} h \left( \theta \right) = \text{mode}(X) $$ 1: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{1}$ を最小にする $\theta$ は $$ \argmin_{\theta} h \left( \theta \right)</description></item><item><title>数理統計学における期待値、平均、分散、モーメントの定義</title><link>https://freshrimpsushi.github.io/jp/posts/246/</link><pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/246/</guid><description>定義: 期待値、平均、分散 確率変数 $X$ が与えられたとする。 連続確率変数$X$ の確率密度関数$f(x)$ が $\displaystyle \int_{-\infty}^{\infty} |x| f(x) dx &amp;lt; \infty$ を満たす場合、以下のように</description></item><item><title>数理統計学における確率変数と確率分布</title><link>https://freshrimpsushi.github.io/jp/posts/1433/</link><pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1433/</guid><description>定義 1 標本空間 $\Omega$ で 確率 $P$ が定義されているとする。 定義域が標本空間の関数 $X : \Omega \to \mathbb{R}$ を 確率変数random variableと呼ぶ。確率変数の値域</description></item><item><title>数理統計学における確率と確率の加法定理</title><link>https://freshrimpsushi.github.io/jp/posts/1431/</link><pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/1431/</guid><description>定義 1 同じ条件下で繰り返しできる試行を無作為試行random experimentと呼ぶ。 無作為試行で得られる全ての結果outcomeを集めた</description></item><item><title>ベイズ因子を通じた仮説検定</title><link>https://freshrimpsushi.github.io/jp/posts/782/</link><pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/782/</guid><description>ビルドアップ 古典的な仮説検定を使うためには、棄却域、有意確率などの概念に対する数学的な理解から、それらを直観的に受け入れられるだけの統計学的</description></item><item><title>最高事後密度信頼区間</title><link>https://freshrimpsushi.github.io/jp/posts/769/</link><pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/769/</guid><description>定義 1 パラメータ空間$\Theta$の部分集合$C \subset \Theta$が、データ$y$が与えられたときの有意水準$\alpha$における$100</description></item><item><title>信用区間と信頼区間の違い</title><link>https://freshrimpsushi.github.io/jp/posts/752/</link><pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/752/</guid><description>定理 信用区間と信頼区間の違いは、本質的にベイジアンとフリークエンティストの違いとみなせる。 信頼区間(フリークエンティスト): パラメーターは固</description></item><item><title>信頼区間</title><link>https://freshrimpsushi.github.io/jp/posts/741/</link><pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/741/</guid><description>定義 1 パラメータ空間 $\Theta$ の部分集合 $C \subset \Theta$ が、有意水準 $\alpha$ に対して $P ( \theta \in C | y ) \ge 1 - \alpha$ を満たすとき、$C$ をデータ$y$が与えられた時の$\t</description></item><item><title>統計学の三つの代表値：最頻値、中央値、平均</title><link>https://freshrimpsushi.github.io/jp/posts/740/</link><pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/740/</guid><description>概要 代表値とは、データを説明する代表的な値のことだ。何千何万というデータがあっても、一つ一つ詳しく見るわけにはいかない場合、結局重要なのはデ</description></item><item><title>ジェフリーズ事前分布</title><link>https://freshrimpsushi.github.io/jp/posts/716/</link><pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/716/</guid><description>定義 1 データの分布$p( y | \theta)$について、$\pi ( \theta ) \propto I^{1/2} ( \theta )$をジェフリーズ事前分布jeffreys priorと言う。 $I</description></item><item><title>ラプラス事前分布</title><link>https://freshrimpsushi.github.io/jp/posts/714/</link><pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/714/</guid><description>ビルドアップ パラメータについてほぼ情報がなければ、わざわざ複雑な事前分布を考える必要はない： 例1：来年のある大学の統計学部の新入生の性比を推</description></item><item><title>共役事前分布</title><link>https://freshrimpsushi.github.io/jp/posts/712/</link><pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/712/</guid><description>定義 1 事前分布と事後分布が同じ分布族に属している場合、事前分布を共役事前分布conjugate priorと呼ぶ。 説明 ベイズ推定は本来、事前分</description></item><item><title>ラプラスの後継法則</title><link>https://freshrimpsushi.github.io/jp/posts/710/</link><pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/710/</guid><description>定理 1 二項モデル $\displaystyle p(y | \theta) = \binom{ n }{ y} \theta^{y} (1- \theta)^{n-y}$ の事前分布が一様分布 $U (0,1)$ に従い、事後分布がベータ分布 $\beta (y+1 , n-y+1)$ に従うとするとき、$p( \theta | y ) \sim \theta^{y} (1- \theta)^{n-y}$</description></item><item><title>ベイジアン・パラダイム</title><link>https://freshrimpsushi.github.io/jp/posts/702/</link><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/702/</guid><description>ビルドアップ 統計学とは、「母数を把握する方法を研究する学問」と言える。物理量を測定するように、公式や法則を通じて正確に母数を推定できれば言う</description></item><item><title>ベイズの定理を通して見るモンティ・ホールのジレンマ</title><link>https://freshrimpsushi.github.io/jp/posts/697/</link><pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/697/</guid><description>説明 周知の通り、モンティ・ホール問題では実際に賞品がどこにあっても選択を変える方が有利になる。これを事実として受け入れるかどうかとは別に、モ</description></item><item><title>モンテカルロ法とブートストラップの違い</title><link>https://freshrimpsushi.github.io/jp/posts/551/</link><pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/551/</guid><description>概要 モンテカルロ法は、任意のデータを使ってシミュレーションを繰り返し、新しい技術を検証する方法であり、ブートストラップは実際のデータから再サ</description></item><item><title>標本標準偏差と標準誤差の区別</title><link>https://freshrimpsushi.github.io/jp/posts/541/</link><pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/541/</guid><description>定義 $X$から得られたデータを$\mathbf{x} = ( x_{1}, x_{2}, \cdots , x_{n} )$としよう。 標本平均: $$ \overline{x} = {{1} \over {n}} \sum_{i=1}^{n} x_{i} $$ 標本標準偏差: $$ s_{x} = \sqrt { {{1} \over {n-1}} \sum_{i=1}^{n}</description></item><item><title>独立とは相関がないという意味ではない</title><link>https://freshrimpsushi.github.io/jp/posts/536/</link><pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/536/</guid><description>説明 独立である場合、相関関係はないが、相関関係がないからといって独立とは限らない。 相関関係がない時に独立であり、必要十分条件になるケースは、</description></item><item><title>特定の分布に従う確率変数の加算の総括</title><link>https://freshrimpsushi.github.io/jp/posts/202/</link><pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/202/</guid><description>定理 確率変数$X_{1} , \cdots , X_{n}$が相互に独立してるとしよう。 [1] 二項分布: $X_i \sim \text{Bin} ( n_{i}, p)$ならば $$ \sum_{i=1}^{m} X_{i} \sim \text{Bin} \left( \sum_{i=1}^{m} n_{i} , p \right) $$ [2] ポアソン分</description></item><item><title>ベイズの定理の証明と事前分布、事後分布</title><link>https://freshrimpsushi.github.io/jp/posts/29/</link><pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/jp/posts/29/</guid><description>定理 1 標本空間 $S$ と事象 $A$、確率 $P$ $\left\{ S_1, S_2, \cdots ,S_n \right\}$ が $S$ の分割だとすると、次が成り立つ。 $$ P(S_k|A)=\frac { P(S_k)P(A|S_k) }{ \sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$ 定義 ベイズ定理の右辺である</description></item></channel></rss>