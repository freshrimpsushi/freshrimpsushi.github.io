<!doctype html><html class=blog lang=jp><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link rel=preload href=https://freshrimpsushi.github.io/jp/css/style.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=preload href=https://freshrimpsushi.github.io/jp/css/comment.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=icon href=https://freshrimpsushi.github.io/ko/logo/favicon.ico><meta name=msapplication-TileColor content="#FFFFFF"><meta name=msapplication-TileImage content="logo/basic.png"><meta name=NaverBot content="All"><meta name=NaverBot content="index,follow"><meta name=Yeti content="All"><meta name=Yeti content="index,follow"><meta name=google-site-verification content="KYAokS7-6C5YuXOjatJQsiK1T0O8x4YncYFIF4tneYI"><meta name=naver-site-verification content="e5651d6f97899061897203413efc84994f04bbba"><link rel=alternate type=application/rss+xml title=生エビ寿司屋 href=https://freshrimpsushi.github.io/jp/index.xml><title>論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）</title></head><meta name=title content="論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）"><meta name=description content="국내 최대의 수학, 물리학, 통계학 블로그"><meta property="og:title" content="論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）"><meta property="og:description" content><meta property="og:image" content="https://freshrimpsushi.github.io/jp/logo/basic.png/"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"r_","name":"論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）","headline":"論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）","alternativeHeadline":"","description":"概要と要約 Kolmogorov–Arnold Networks（KAN）は、その名の通りコルモゴロフ-アルノルト表現定理Kolmogorov–","inLanguage":"jp","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/freshrimpsushi.github.io\/jp\/posts\/322\/"},"author":{"@type":"Person","name":"류대식","url":"https://math.stackexchange.com/users/459895/ryu-dae-sick"},"creator":{"@type":"Person","name":"류대식"},"accountablePerson":{"@type":"Person","name":"류대식"},"copyrightHolder":"生エビ寿司屋","copyrightYear":"2024","dateCreated":"2024-09-29T00:00:00.00Z","datePublished":"2024-09-29T00:00:00.00Z","dateModified":"2024-09-29T00:00:00.00Z","publisher":{"@type":"Organization","name":"生エビ寿司屋","url":"https://freshrimpsushi.github.io/jp/","logo":{"@type":"ImageObject","url":"https:\/\/freshrimpsushi.github.io\/jp\/logo\/basic.png","width":"32","height":"32"}},"image":"https://freshrimpsushi.github.io/jp/logo/basic.png","url":"https:\/\/freshrimpsushi.github.io\/jp\/posts\/322\/","wordCount":"7964","genre":[],"keywords":[]}</script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/mhchem.min.js integrity=sha384-F2ptQFZqNJuqfGGl28mIXyQ5kXH48spn7rcoS0Y9psqIKAcZPLd1NzwFlm/bl1mH crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>function renderKaTex(e){renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],trust:!0,trust:e=>["\\htmlId","\\href","\\includegraphics"].includes(e.command),macros:{"\\eqref":"(\\text{#1})","\\ref":"\\href{###1}{\\text{#1}}","\\label":"\\htmlId{#1}{}","\\sech":"\\operatorname{sech}","\\csch":"\\operatorname{csch}","\\sgn":"\\operatorname{sgn}","\\sign":"\\operatorname{sign}","\\sinc":"\\operatorname{sinc}","\\diag":"\\operatorname{diag}","\\diam":"\\operatorname{diam}","\\trace":"\\operatorname{trace}","\\Tr":"\\operatorname{Tr}","\\tr":"\\operatorname{tr}","\\re":"\\operatorname{Re}","\\im":"\\operatorname{Im}","\\Var":"\\operatorname{Var}","\\Poi":"\\operatorname{Poi}","\\Cov":"\\operatorname{Cov}","\\span":"\\operatorname{span}","\\supp":"\\operatorname{supp}","\\rank":"\\operatorname{rank}","\\nullity":"\\operatorname{nullity}","\\ad":"\\operatorname{ad}","\\Ric":"\\operatorname{Ric}","\\i":"\\mathrm{i}","\\d":"\\mathrm{d}","\\cR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5863.png}","\\acR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.4371.png}","\\bcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5899.png}","\\abcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.0596.png}","\\crH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\smallcrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\acrH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}","\\smallacrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}"},throwOnError:!1})}</script><body class=main><header><a href=https://freshrimpsushi.github.io/jp/ rel=home><p style=text-align:center;font-size:1rem;color:#000><img src=https://freshrimpsushi.github.io/jp/logo/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.png style=height:80px alt=logo></p></a></header><form method=get action=/jp/search style=border:1px;text-align:center><div class=field><input type=text id=searchtext placeholder=🔍︎ class=input_text name=s style=background-color:#eee;text-align:center;width:200px;font-size:1.5rem;border:1px;border-radius:5px;padding-top:5px;padding-bottom:5px;margin-bottom:1.5rem></div></form><aside style=text-align:center;margin-bottom:1rem><a href=https://freshrimpsushi.github.io/ko//posts/322/>한국어</a> |
<a href=https://freshrimpsushi.github.io/en//posts/322/>English</a> |
<a href=https://freshrimpsushi.github.io/jp//posts/322/>日本語</a></aside><div class=wrapper><div class=content><div class=content-box><title>論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）</title>
<a href=https://freshrimpsushi.github.io/jp/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/ style=background-color:rgba(0,0,0,.8);color:orange;border-radius:10px;padding:5px>📂機械学習</a><h1>論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）</h1><aside><div class=innerheader><div class=innertoc><b>目次</b><nav id=TableOfContents><ul><li><a href=#概要と要約>概要と要約</a></li><li><a href=#0-アブストラクト>0. アブストラクト</a></li><li><a href=#1-はじめに>1. はじめに</a></li><li><a href=#2-kolmogorovarnold-networkskan>2. Kolmogorov–Arnold Networks（KAN）</a><ul><li><a href=#21-コルモゴロフ-アルノルト表現定理>2.1 コルモゴロフ-アルノルト表現定理</a></li><li><a href=#22-kanのアーキテクチャ>2.2 KANのアーキテクチャ</a></li><li><a href=#23-kanの近似能力とスケーリング則>2.3 KANの近似能力とスケーリング則</a></li><li><a href=#24-精度向上のためにグリッド拡張>2.4 精度向上のために：グリッド拡張</a></li><li><a href=#25-解釈可能性のためにkanの簡素化とインタラクティブ化>2.5 解釈可能性のために：KANの簡素化とインタラクティブ化</a></li></ul></li><li><a href=#3-kanは正確である>3. KANは正確である</a><ul><li><a href=#33-ファインマンデータセット>3.3 ファインマンデータセット</a></li><li><a href=#34-偏微分方程式の解法>3.4 偏微分方程式の解法</a></li></ul></li><li><a href=#4-kanは解釈可能である>4. KANは解釈可能である</a><ul><li><a href=#43-数学への応用結び目理論>4.3 数学への応用：結び目理論</a></li><li><a href=#44-物理学への応用アンダーソン局在化>4.4 物理学への応用：アンダーソン局在化</a></li></ul></li><li><a href=#5-関連研究>5. 関連研究</a></li><li><a href=#6-議論>6. 議論</a><ul><li><a href=#最終的な結論kanとmlpのどちらを使うべきか>最終的な結論：KANとMLPのどちらを使うべきか？</a></li></ul></li><li><a href=#余談>余談</a></li></ul></nav></div></div></aside><h2 id=概要と要約>概要と要約</h2><p>Kolmogorov–Arnold Networks（KAN）は、その名の通り<strong>コルモゴロフ-アルノルト表現定理</strong><sup>Kolmogorov–Arnold representation theorem</sup>にインスパイアされて開発されたニューラルネットワークであり、関連するアイデア自体は数十年前から議論されていましたが、<strong>ジローシ</strong><sup>Girosi</sup>と<strong>ポッジョ</strong><sup>Poggio</sup>らが1989年に「Representation Properties of Networks: Kolmogorov&rsquo;s Theorem Is Irrelevant」という論文で指摘したように、当該定理と大きな関連性はありません<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>。ただし、多くの有名なニューラルネットワークが<a href=../966>ネットワーク</a>の構築方法に従って直感的なネーミングをする中、あえて数学者の名前を取ったのは、それだけ理論的な基盤がしっかりしていることを強調したかったのだと思います。2024年4月にarXivに投稿され<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>、この投稿を書いている2024年9月27日現在、すでに200回近く引用されているので、所期の目的は達成したのではないかと思います。</p><p>KANのコンセプトは確固たるものであり、現代の人工知能といえば絶対的な主流であるMLP<sup>Multi-Layer Perceptron</sup>と二大勢力を形成し、従来のMLPやディープラーニングがブラックボックス手法として持つ限界を突破しようというものです。性能自体は良いが、その原理を解明しないまま受け入れるのは困難であり、例えば金融や医療、宇宙、軍需などの分野にも進出するためには必ず研究が行われなければならない部分であり、これまでのところかなり斬新なアプローチを示しています。</p><p>ただし、モデルのパフォーマンスを含めて学習速度などに関しては、どうしても誇張がかなりあり、肝心な数式化をやや大雑把に解決した点は確かに警戒すべきです。</p><h2 id=0-アブストラクト>0. アブストラクト</h2><p><img src=image-1.png#center alt="alt text"></p><p>KANはコルモゴロフ-アルノルト表現定理にインスパイアされており、従来のMLPが既に定められた<a href=../991>活性化関数</a>を用いてノードで<a href=../2470>重み</a>を更新するのとは異なり、KANは活性化関数自体が学習を通じて形を変え、リンクで重みを更新するという戦略を取ります。KANを貫くテーマは<strong>解釈可能性</strong><sup>interpretability</sup>であり、著者らが提案するいくつかの事例では数学者や物理学者にとって有用な共同研究者となりうるとし、MLPに対する有望な代替手段になると主張しています。</p><h2 id=1-はじめに>1. はじめに</h2><p>MLPの最大の問題点である解釈可能性から指摘します。MLPが<a href=../1853>シベンコの定理</a>を理論的根拠として発展したように、KANはコルモゴロフ-アルノルト表現定理を基盤としています。MLPがデータの<a href=../512>線形結合</a>に非線形関数を適用し、脳を模倣するコンセプトを持ち、その計算がどれほど複雑で膨大であっても、GPUが実際にそのようなタスクを<a href=../1955>行列</a>演算で解き始め、大きな発展を遂げました。一方、KANは基本設定からして1次元関数、より具体的には<a href=../1036>スプライン</a>を通じてモデルが学習されることを望みます。誰もがこの説明を聞けば自然に「それでは計算に時間がかかりすぎるのではないか？」そして「GPUを使えないということではないか？」と思うでしょうが、幸いなことに通常はMLPに比べてネットワークのサイズが非常に小さくても性能を出せると述べています。</p><p>次に、従来もニューラルネットワークを構築するためにコルモゴロフ-アルノルト表現定理を試そうとする試みはありましたが、その定理で明示する条件をあまりに正確に守ろうとしたために現代的な手法を使いにくかったという説明とともに、著者らはそのような構造を任意に変えて様々な試みをしたと述べています。ある意味、コルモゴロフ-アルノルト表現定理と決別したことを告白する場面とも言えますが、実際にも次の段落でKANはスプラインとMLPの組み合わせに過ぎないと認めています。</p><p>著者らはアブストラクトから一貫してKANが<strong>次元の呪い</strong><sup>curse of dimension</sup>を克服したという主張を繰り返していますが、正直なところその部分はあまり共感できません。KANの潜在性を示すために様々な問題に挑戦し、依然として数学者や科学者に役立つとアピールしています。正直に言えば、現時点では工学界や産業界の主流を奪うのは難しく、ニューラルネットワークのネーミングから一貫して基礎科学に集中していると見ればよいと思います。研究に使用されたコードはGitHubリポジトリ <a href=https://github.com/KindXiaoming/pykan>https://github.com/KindXiaoming/pykan</a> で確認できます。</p><h2 id=2-kolmogorovarnold-networkskan>2. Kolmogorov–Arnold Networks（KAN）</h2><p>再びMLPとシベンコの定理、KANとコルモゴロフ-アルノルト表現定理の関係を強調します。</p><h3 id=21-コルモゴロフ-アルノルト表現定理>2.1 コルモゴロフ-アルノルト表現定理</h3><p>コルモゴロフ-アルノルト表現定理は、<a href=../180>有界</a>なドメインで<a href=../432>連続</a>な<a href=../970>多変数関数</a>が有限個の一変数連続関数の<a href=../3048>合成</a>と<a href=../275>加法</a>で表せるという定理です。より正確には、滑らかな $f : [0, 1]^{n} \to \mathbb{R}$ は $\phi_{q,p} : [0, 1] \to \mathbb{R}$ と $\Phi_{q} : \mathbb{R} \to \mathbb{R}$ に対して
$$
f\left( x_{1}, \cdots, x_{n} \right) = \sum_{q=1}^{2n+1} \Phi_{q}\left( \sum_{p=1}^{n} \phi_{q,p}\left( x_{p} \right) \right)
$$
と表せるというものです。問題は、コルモゴロフ-アルノルト表現定理が単に存在性のみを述べる定理であり、これらの $\phi_{q,p}$ と $\Phi_{q}$ に何の制約もないということです。したがって、実際にこのような近似が存在するとしても、現実的にその関数を見つけられない可能性があり、機械学習の分野ではほとんど相手にされなかったとまで付け加えています。</p><p>しかし、著者らはこの定理の有用性を楽観的に見ており、数式で言う構造を正確に守ることに固執しないと述べています。また、科学や日常生活では滑らかでスパースな構造が多いため、実際にはうまく機能する可能性が高いと考えているようです。</p><h3 id=22-kanのアーキテクチャ>2.2 KANのアーキテクチャ</h3><p>ここからいくつかの記法が紹介されます。まず、KANの形は次のように<a href=../587>整数</a>の配列で表されます。
$$
\left[ n_{0}, n_{1}, \cdots, n_{L} \right]
$$
$n_{l}$ は第 $l$ 層のノード数であり、このKANは入力層と出力層を含めて $\left( L+1 \right)$ 個の層を持っています。第 $l$ 層の第 $i$ 番目のノードを $\left( l, i \right)$ と表し、このノードの値を $x_{l,i}$ とします。$l$ 番目の層と $(l+1)$ 番目の層の間には正確に $n_{l} n_{l+1}$ 個のリンク（活性化関数）があり、2つのニューロン $(l,i)$ と $\left( l+1, j \right)$ をつなぐリンクの活性化関数を $\phi_{l,j,i}$ と表します。ここでインデックスの範囲は当然 $l = 0, \cdots, L-1$ と前の層の $i = 1, \cdots, n_{l}$、そして後の層の $j = 1, \cdots, n_{l+1}$ で定まります。</p><p>後の層のノードの値 $x_{l+1, j}$ は
$$
x_{l+1, j} = \sum_{i=1}^{n_{l}} \phi_{l,j,i}\left( x_{l, i} \right)
$$
と表され、これらの<a href=../1947>ベクトル</a>は $\mathbf{x}_{l} = \left( x_{l, 1}, \cdots, x_{l, n_{l}} \right)$ のようにボールド体で表記します。この過程をより理解しやすく<a href=../1955>行列</a>形式で表すと次のようになります。
$$
\begin{align*}
& \mathbf{x}_{l+1} \
=& \Phi_{l}\left( \mathbf{x}_{l+1} \right) \
=& \begin{bmatrix}
\phi_{l,1,1}(\cdot) & \phi_{l,1,2}(\cdot) & \cdots & \phi_{l,1,n_{l}}(\cdot) \
\phi_{l,2,1}(\cdot) & \phi_{l,2,2}(\cdot) & \cdots & \phi_{l,2,n_{l}}(\cdot) \
\vdots & \vdots & \ddots & \vdots \
\phi_{l,n_{l+1},1}(\cdot) & \phi_{l,n_{l+1},2}(\cdot) & \cdots & \phi_{l,n_{l+1},n_{l}}(\cdot)
\end{bmatrix} \mathbf{x}_{l} \
=& \begin{bmatrix}
\phi_{l,1,1}\left( x_{l, 1} \right) + \phi_{l,1,2}\left( x_{l, 2} \right) + \cdots + \phi_{l,1,n_{l}}\left( x_{l, n_{l}} \right) \
\phi_{l,2,1}\left( x_{l, 1} \right) + \phi_{l,2,2}\left( x_{l, 2} \right) + \cdots + \phi_{l,2,n_{l}}\left( x_{l, n_{l}} \right) \
\vdots \
\phi_{l,n_{l+1},1}\left( x_{l, 1} \right) + \phi_{l,n_{l+1},2}\left( x_{l, 2} \right) + \cdots + \phi_{l,n_{l+1},n_{l}}\left( x_{l, n_{l}} \right)
\end{bmatrix} \
=& \begin{bmatrix}
\sum_{i=1}^{n_{l}} \phi_{l,1,i}\left( x_{l, i} \right) \
\sum_{i=1}^{n_{l}} \phi_{l,2,i}\left( x_{l, i} \right) \
\vdots \
\sum_{i=1}^{n_{l}} \phi_{l,n_{l+1},i}\left( x_{l, i} \right)
\end{bmatrix}
\end{align*}
$$
これは数学的に厳密な表現ではないので注意が必要です。$\Phi_{l}$ と $\mathbf{x}_{l}$ の行列積ではなく、関数 $\phi$ たちにベクトルの各成分を入れて足し合わせる過程がまるで行列の演算と似ているため、見やすく示しただけです。</p><p>この表現に従って、KANは次のように $\Phi_{l}$ たちの合成関数で表すことができます。
$$
\operatorname{KAN}\left( \mathbf{x} \right) = \left( \Phi_{L-1} \circ \cdots \circ \Phi_{1} \circ \Phi_{0} \right)\left( \mathbf{x} \right)
$$
これはMLPが活性化関数 $\sigma$ とアフィン変換 $W_{l}$ に対して次のように表せるのと類似しています。
$$
\operatorname{MLP}\left( \mathbf{x} \right) = \left( W_{L-1} \circ \sigma \circ \cdots \circ \sigma \circ W_{1} \circ \sigma \circ W_{0} \right)\left( \mathbf{x} \right)
$$</p><h4 id=実装の詳細>実装の詳細</h4><p>$$
\phi(x) = w_{b} b(x) + w_{s} \operatorname{spline}(x)
$$
活性化関数 $\phi$ は基本的に上記の形を持ちます。$w_{b}$ と $w_{s}$ は<a href=../2594>ハイパーパラメータ</a>であり、必須ではなく、特に $w_{s}$ は学習過程で何の意味も持ちませんが、一応モデルを調整する要素として残しておくと述べています。活性化関数 $b(x)$ と<a href=../1036>スプライン</a> $\operatorname{spline}(x)$ は自由に変更できる要素ですが、この研究ではとりあえず次のようにしました。
$$
\begin{align*}
b(x) =& \operatorname{SiLU} := x \sigma(x) = \frac{x}{1 + e^{-x}} \
\operatorname{spline} =& \sum_{i} c_{i} B_{i}(x)
\end{align*}
$$
ここで $\operatorname{SiLU}$ はシグモイド加速線形ユニット、$\sigma$ は<a href=../1775>ロジスティック関数</a>、$B_{i}$ は<a href=../1045>B-スプライン</a>であり、B-スプラインの係数 $c_{i}$ たちがまさに学習の対象となる<sup>trainable</sup>変数です。B-スプラインは与えられたドメイン外では値が $0$ になってしまうので、学習過程で同じ層にあるスプラインたちは前の層から来た値に応じてグリッドを更新していく必要性があります。これが果たして効率的かは別として、著者らが主張したように「活性化関数が学習する」という言葉自体は事実です。</p><h3 id=23-kanの近似能力とスケーリング則>2.3 KANの近似能力とスケーリング則</h3><p>いよいよKANの核心となる本当の定理が登場します。</p><blockquote><p><strong>近似理論、KAT</strong>：$\mathbf{x} = \left( x_{1}, \cdots, x_{n} \right)$ とします。$(k-1)$ 回<a href=../1210>微分可能</a>な $\phi_{l,j,i}$ に対して $f$ が次のように表されると仮定します。
$$
\begin{align*}
\Phi_{l} := & \left( \sum_{i=1}^{n_{l}} \phi_{l,1,i}, \cdots, \sum_{i=1}^{n_{l}} \phi_{l,n_{l+1},i} \right) \
f =& \left( \Phi_{L-1} \circ \cdots \circ \Phi_{1} \circ \Phi_{0} \right)
\end{align*}
$$
すると、グリッドサイズが $G$ の $k$ 次B-スプラインを $\phi_{l,j,i}^{G}$ と表すとき、すべての $0 \le m \le k$ に対して次を満たす $f$ に依存した<a href=../2465>定数</a> $C$ が存在します。
$$
\left| f - \left( \Phi_{L-1}^{G} \circ \cdots \circ \Phi_{1}^{G} \circ \Phi_{0}^{G} \right) \right| \le C G^{-k-1+m}
$$
ここで<a href=../1225>ノルム</a> $\left| \cdot \right|$ は<a href=../728>微分作用素</a> $D$ に対して次のように導関数の大きさを測る方式で定義される $C^{m}$-ノルムです。
$$
\left| g \right| := \max_{| \beta | \le m} \sup_{x \in [0, 1]^{n}} \left| D^{\beta} g(x) \right|
$$</p></blockquote><p>この定理はB-スプラインの性質によって容易に証明されるように見えますが、B-スプラインに関する背景知識がかなり要求されます。これで元のコルモゴロフ-アルノルト表現定理とは距離ができましたが、無から有を生じるわけでもなく、$\phi$ にB-スプラインを導入した意図は明確に現れています。このように誤差の上限が $G^{-k-1+m}$ で抑えられるということは、B-スプラインにより大きなコストを支払うほど関数の近似が正確になることを示唆しています。
$$
\lim_{G, k \to \infty} G^{-k-1+m} = \lim_{G, k \to \infty} \frac{G^{m-1}}{G^{k}} = 0
$$
具体的には上記のようにB-スプラインで使用されるグリッドの数 $G$ を増やすほど、次数 $k$ を大きくするほど誤差の上限が減少するということです。確かにこの定理がこの論文の核心であり、新しいニューラルネットワークの理論的根拠となります。しかし、個人的に見ても非常に優れた業績だと認めますが、いずれにせよコルモゴロフ-アルノルト表現定理はモチーフだけが残り、実際の突破口はB-スプラインで見つけたことを確かめておきましょう。</p><p>一方、著者らがここでもう一度強調するのは、そのような上限が入力ベクトルのサイズ $n$ に無関係であるため、<strong>次元の呪いを克服した</strong>ということですが、実際には同意し難いです。数式的におかしいというわけではありませんが、実戦的な状況では誤差の上限が大きな意味を持たないこともあり、今後KANを基盤とした変形アーキテクチャが出てくればまた話が変わるからです。実質的にこのような主張を堂々とするなら、画像データなどに対してもベンチマークを行い、次元の呪いを克服したことを立証すべきではないかと思います。</p><h3 id=24-精度向上のためにグリッド拡張>2.4 精度向上のために：グリッド拡張</h3><p>当然といえば当然ですが、B-スプラインで近似された関数はグリッドをさらに追加し、つまりスプラインのドメインをより細かく分割したり、範囲外の点を追加することで、既存のモデルを維持しながら性能を改善する余地があります。重み一つの修正がモデル全体の構造にどう影響するかわからないMLPと比較すればもちろん良いことですが、実用的な側面で想像するに、ここまで細かなコントロールをする機会があるかはわかりません。実際本文でも「小さなKANはより一般化する」と述べており、果たしてグリッドを増やすことがいつも良いと見なせるかについては懐疑を示しているので、あまり深く考える必要はないでしょう。</p><h3 id=25-解釈可能性のためにkanの簡素化とインタラクティブ化>2.5 解釈可能性のために：KANの簡素化とインタラクティブ化</h3><p>先に証明された定理と同じくらい重要なコンセプトとして、KANの構造を<a href=../2513>スパース</a>にして解釈可能性を高めるアイデアについて紹介します。</p><h4 id=251-簡素化手法>2.5.1 簡素化手法</h4><p>MLPとは異なり、KANは行列積がないため、層と層の間の値がどのように伝達されるかすべて把握でき、もし影響力の小さいリンクの活性化関数がすべての値を $0$ にマッピングする<a href=../2465>定数関数</a> $\mathbf{0}(\cdot)$ に収束すれば、そのリンクを取り除き、人間が読める程度に明示的な公式に変える可能性も出てきます。そのために著者らは<a href=../967>損失関数</a>に2つの項を追加します。</p><p>1つ目は<a href=../2571>ラッソ回帰</a>のアイデアそのままに $L_{1}$ ノルム $\left| \cdot \right|_{1}$ を使用し、データサイエンスに馴染みのある人なら自然な流れとして感じられるほど直感的です。活性化関数 $\phi$ の $L_{1}$ ノルム $\left| \phi \right|_{1}$ は、$\phi$ を通過する $s$ 番目の入力値 $x^{(s)}$ に対して、$N$ 個のすべての出力値 $\phi\left( x^{(s)} \right)$ の平均として定義され、数式で表すと次のようになります。
$$
\left| \phi \right|_{1} := \frac{1}{N} \sum_{s=1}^{N} \left| \phi\left( x^{(s)} \right) \right|
$$
これにより、層 $\Phi$ の $L_{1}$ ノルム $\left| \Phi \right|_{1}$ も自然に次のように定義されます。
$$
\left| \Phi \right|_{1} := \sum_{i=1}^{n_{\text{in}}} \sum_{j=1}^{n_{\text{out}}} \left| \phi_{j,i} \right|_{1}
$$
しかし、著者らは層の $L_{1}$ ノルムだけでは十分でないことを発見し、次のように層 $\Phi$ の<a href=../2035>エントロピー</a> $S\left( \Phi \right)$ も定義します。
$$
S\left( \Phi \right) := - \sum_{i=1}^{n_{\text{in}}} \sum_{j=1}^{n_{\text{out}}} \frac{\left| \phi_{j,i} \right|_{1}}{\left| \Phi \right|_{1}} \log \frac{\left| \phi_{j,i} \right|_{1}}{\left| \Phi \right|_{1}}
$$
最後に、元の損失 $\mathscr{l}$ に重み $\mu_{1}$ と $\mu_{2}$ をかけて足した総損失 $\mathscr{L}$ を次のように定義します。
$$
\mathscr{L} = \mathscr{l} + \mu_{1} \sum_{l=0}^{L-1} \left| \Phi_{l} \right|_{1} + \mu_{2} \sum_{l=0}^{L-1} S\left( \Phi_{l} \right)
$$
$\phi$ の相対的な大きさで定義されるエントロピーを最小化するということは、どのような意味を持つのでしょうか。確率論に詳しい人ならば、すぐに納得できるほど巧妙な妙手であり、関数値の無秩序度を最小化するということは、それ自体で $\left| \phi \right|_{1}$ を大きくしたり $0$ に収束させる作用を追加することになります。</p><p><img src=image.png#center alt="alt text"></p><p>しかし、このように完成したモデルをシンボル化<sup>symbolification</sup>する過程からは、どうしても納得できない部分が多いです。図2.4で説明しているように、まずは可視化<sup>visualization</sup>から始まります。$\phi : \mathbb{R} \to \mathbb{R}$ は $x$ 軸と $y$ 軸を与えてグラフを描くことができ、$\tanh\left( 3 \left| \phi \right|_{1} \right)$ で透明度を与えてどのリンクが重要か大まかに把握しておきます。次に、ノードごとに<strong>入力スコア</strong><sup>incoming score</sup> $I_{l,i}$ と<strong>出力スコア</strong><sup>outgoing score</sup> $O_{l,i}$ を次のように定義します。
$$
\begin{align*}
I_{l,i} :=& \max_{k} \left| \phi_{l-1, i, k} \right| \
O_{l,i} :=& \max_{k} \left| \phi_{l+1, k, i} \right|
\end{align*}
$$
2つのスコアが<a href=../2569>しきい値</a> $\theta = 10^{-2}$ を超えない場合、そのノードを削除します。最後に、関数の概形を見て適当な候補 $f$ を見つけた後、$\phi$ のドメインにある様々な $x$ を代入した $y = \phi(x)$ をサンプリングします。これが $y \approx c f(a x + b) + d$ を最大限よく満たす $a, b, c, d$ を見つけ、$\phi$ を $f$ で置き換えます。</p><p>🤔&mldr; もちろんこのように数式を作る過程がKANの核心ではありません。数式を見つける過程を手作業で行うからといって、研究の核心価値が下がるわけでもありません。しかし、これまでの斬新な展開に比べると、その結末がやや物足りなく見えるのも事実です。続いて著者らはシンボリック回帰<sup>symbolic regression</sup>とKANを比較し、セクション2を締めくくります。シンボリック回帰は扱いにくいのに対し、KANで数式を作る過程はKANの脳を見せてユーザーが直接手術をするようなものだと述べる程度で終わります。</p><p>ここからはKANとMLPを比較したり、様々な問題に挑戦しながら実験的にKANの可能性を立証する内容が続きます。約30ページ分のすべての内容を細かく見る必要はないので、大きなポイントだけ強調してレビューを終えます。</p><h2 id=3-kanは正確である>3. KANは正確である</h2><h3 id=33-ファインマンデータセット>3.3 ファインマンデータセット</h3><p><a href=https://space.mit.edu/home/tegmark/aifeynman.html>ファインマンデータセット</a><sup>Feynman dataset</sup>は、ファインマンの著書から収集した物理方程式で作られた<a href=../2418>データセット</a>で、数十種類の方程式に対してKANがうまく機能することを示しています。</p><h3 id=34-偏微分方程式の解法>3.4 偏微分方程式の解法</h3><p><a href=../3313>PINN</a>は主に<a href=../1818>偏微分方程式</a>を解くために多く応用されており、KANとPINNが共存できることを示す例として<a href=../997>ポアソン方程式</a>を採用しました。PINNはニューラルネットワークのアーキテクチャがどうであれ、損失関数に方程式の情報を含めることが核心アイデアであり、数式的に見たときにKANと組み合わせられない理由はありません。</p><h2 id=4-kanは解釈可能である>4. KANは解釈可能である</h2><h3 id=43-数学への応用結び目理論>4.3 数学への応用：結び目理論</h3><p>純粋数学の研究に役立つ可能性がある例として<strong>結び目理論</strong><sup>knot theory</sup>を挙げました。結び目理論では、与えられた2つの結び目が互いに同じかどうかを判別できる定理やアルゴリズムなどに多くの関心を持ち、結び目が固有に持つ不変量<sup>invariants</sup>を用いて結び目と結び目を区別する方法を好んで使います。自然に浮かぶ質問は「多数の結び目と多数の不変量がどのような関係を持つのか」、つまり「関数を見つけることができるのか」です。この例で著者らは「AI for Math」という表現まで使ってKANが研究に役立つことをアピールしています。</p><h3 id=44-物理学への応用アンダーソン局在化>4.4 物理学への応用：アンダーソン局在化</h3><p>私が<strong>アンダーソン局在化</strong><sup>Anderson localization</sup>についてよく知らないので詳しく説明するのは難しいですが、要点は結局これまでと同じです。KANが物理学の研究に役立つということです。</p><h2 id=5-関連研究>5. 関連研究</h2><p>KANと関連する研究について論じます。論文に必要な内容ではないかもしれませんが、2024年時点で関連する分野がどのようなトレンドをたどり、KANに至るまでどのようなアイデアがあったのかについて説明します。</p><h2 id=6-議論>6. 議論</h2><h3 id=最終的な結論kanとmlpのどちらを使うべきか>最終的な結論：KANとMLPのどちらを使うべきか？</h3><p>それでは、KANとMLPのどちらを使うべきでしょうか？著者らは解釈可能性が重要であり、トレーニング時間がそれほど大きな問題でない場合、それほどスケールが大きくないAIや自然科学の問題でKANを試すことを勧めています。</p><h2 id=余談>余談</h2><p>これまで紹介されたKANは、学習するたびにB-スプラインのドメインを更新し、新しい関数を見つけるという、従来のMLPに比べて非常に複雑な方式で実装されています。現在、MLPを基盤として広く使われているニューラルネットワークはGPUの強力な線形代数計算を積極的に使用していますが、KANは根本的にこのような物量戦に弱いと言わざるを得ません。実際、著者らは同じ数のパラメータを持つMLPモデルに比べてKANが約10倍遅く学習すると述べていますが、私が見るには10倍の速度差でさえ非常に楽観的なのではないかと思います。<a href=../996>ディープラーニング</a>の真価は、ヒューリスティックなニューラルネットワーク構造の変化にも飛躍的な性能改善の余地があることにあります。</p><p>ただし、KANの理論的根拠は明確であり、ディープラーニングのようなブラックボックス手法が持っていた気がかりな欠点を解決できる強力な候補であることも認めます。当然ながら、KANが登場するや否や、この速度問題を解決しようとする試みが続きました。</p><ul><li><a href=https://github.com/Blealtan/efficient-kan>efficient KAN</a>：$\left| \phi \right|_{1}$ を計算する方式を変更しました。出力値の絶対値平均を計算する過程がかなり大きなコストを伴うため、わざわざそうするのではなく、パラメータ（B-スプラインの係数）の絶対値を使っても数式的な意味は大きく変わらないでしょう。リンクを切るという意図とは別に、ある観点ではより正確にラッソ回帰の方式を継承したと言えます。</li><li><a href=https://github.com/ZiyaoLi/fast-kan>FastKAN</a>：B-スプラインの代わりにガウス放射関数を使用します。ガウシアン形の関数は $k=3$ のB-スプラインと非常によく似ているため、パフォーマンスは大きく変わらないのに対して、トレーニング速度は非常に速くなることが予想されます。しかし、これは工学的に妥当な改造であるだけで、KANの理論的基盤となるB-スプラインを放棄したため、コルモゴロフ-アルノルト表現定理とはまた一段と離れたことを知っておく必要があります。</li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Federico Girosi, Tomaso Poggio; Representation Properties of Networks: Kolmogorov&rsquo;s Theorem Is Irrelevant. Neural Comput 1989; 1 (4): 465–469. doi: <a href=https://doi.org/10.1162/neco.1989.1.4.465>https://doi.org/10.1162/neco.1989.1.4.465</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Liu, Z., Wang, Y., Vaidya, S., Ruehle, F., Halverson, J., Soljačić, M., &mldr; & Tegmark, M. (2024). Kan: Kolmogorov-arnold networks. arXiv preprint arXiv:2404.19756. <a href=https://arxiv.org/abs/2404.19756>https://arxiv.org/abs/2404.19756</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div><aside style=text-align:right>2024-09-29&emsp;
류대식&emsp;
<a href=../1714>🎲 322</a></aside><script>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）",c="https://freshrimpsushi.github.io/jp/posts/322/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script></div><aside><h2>コメント</h2><div class=area-reply><div class=list-reply></div></div><div class=write-box><div class="write-author-info box-account"><input type=hidden name=cmt_idx>
<input class=ai-author type=text placeholder=Name>
<input class=ai-password type=password maxlength=20 placeholder=Password></div><div class=write-content><textarea class=ai-content value placeholder=日本語でも構いませんが、できれば英語でお願いします style=ime-mode:active></textarea></div><button class=write-button onclick=write_comment() aria-label=send><i class='fa-solid fa-paper-plane'></i></button><aside class=tex>コメントにも $\TeX$ が適用されます。</aside></div></aside><script>let commentRows=[];const listReply=document.querySelector(".list-reply");document.addEventListener("DOMContentLoaded",()=>{get_all_comment()});function get_all_comment(){fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=getAllComment";return postFetch(t,{board_idx:"322",user_ip:e})}).then(e=>e.json()).then(e=>{e.ok&&(commentRows=e.rows,render_comment(commentRows))}).catch(e=>console.error(e))}function render_comment(e){const n=["류대식","전기현","ㅇㅇ","질문"],s=["류대식","전기현"];render_blank();let t="";e.map(e=>{t+=`<div id="comment${e.cmt_idx}" class="parents">`,t+=`<div class="content-info">`;let o="";e.cmt_cnt>125?o="🥇":e.cmt_cnt>25?o="🥈":e.cmt_cnt>5&&(o="🥉"),n.includes(e.author)&&(o="");let i="";e.ip_address==null?i="(-)":(ipParts=e.ip_address.split("."),i=`(${ipParts[0]}.${ipParts[1]})`),s.includes(e.author)&&(i=""),t+=`<div class="list-author">${o} ${e.author} ${i}</div>`,t+=`<sup class="list-date">${e.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,e.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> 管理者の承認を待っています</div>`);let a=e.content;a=a.replace(/\n/g,"<br />"),t+=`<div class="content-text">${a} <span class="re-comment-button" onclick="re_comment('${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`,e.child.map(o=>{let c="child";e.ip_address&&o.ip_address===e.ip_address&&(c="parentself"),t+=`<div id="comment${o.cmt_idx}" class="${c}">`,t+=`<div class="content-info">`;let i="";o.cmt_cnt>5?i="🥉":o.cmt_cnt>25?i="🥈":o.cmt_cnt>125&&(i="🥇"),n.includes(o.author)&&(i="");let a="";o.ip_address==null?a="(-)":a=`(${o.ip_address})`,s.includes(o.author)&&(a=""),t+=`<div class="list-author">${i} ${o.author} ${a}</div>`,t+=`<sup class="list-date">${o.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,o.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> 管理者の承認を待っています</div>`);let r=o.content;r=r.replace(/\n/g,"<br />"),t+=`<div class="content-text">${r} <span class="re-comment-button" onclick="re_comment('${o.cmt_idx}', '${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`})}),listReply.innerHTML=t,renderKaTex(listReply),location.href.indexOf("#")!=-1&&(location.href=location.href.substr(location.href.indexOf("#")))}function render_blank(){listReply.innerHTML=""}function write_comment(){const e=document.querySelector(".ai-author"),t=document.querySelector(".ai-password"),n=document.querySelector(".ai-content"),s=e.value,o=t.value,i=n.value;if(s===""||o===""||i===""){alert("빈칸을 채워주세요");return}const a="322",r="",c="論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeComment";return postFetch(t,{board_idx:a,board_slug:r,board_title:c,author:s.replace(/\+/g,"%2B"),password:o,content:i.replace(/\+/g,"%2B"),user_ip:e})}).then(e=>e.json()).then(s=>{s.ok?(commentRows.push(s.row),render_comment(commentRows),e.value="",t.value="",n.value=""):s.status===606?(Swal.fire(`Warning!
지속적인 도배 시도시
IP가 차단될 수 있습니다.`),e.value="",t.value="",n.value=""):s.status===607&&(alert(`지나친 댓글 도배를 확인하여
접근을 차단합니다.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}async function update_comment(e,t){const{value:n}=await Swal.fire({title:"댓글 수정",input:"password",inputPlaceholder:"글 작성 시 입력했던 패스워드를 입력하세요",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(s=>{if(s.ok){const s=document.querySelector(`#comment${e}`),o="https://freshrimpsushi.com/blog/ajax/comment.php?action=getComment";postFetch(o,{cmt_idx:e}).then(e=>e.json()).then(o=>{if(o.ok){const a=o.row,r=a.author,c=a.content;let i="";i+=`<div class="update-author-info">`,i+=`<input class="update-author" type="text" value="${r}" placeholder="이름" />`,i+=`<input class="update-password" type="password" value="${n}" placeholder="비밀번호" disabled />`,i+="</div>",i+=`<textarea class="update-content" value="" style="IME-MODE:active;">${c}</textarea>`,i+=`<input class="update_comment-button" type="submit" value="수정" onclick="update_comment_click(${e}, '${t}')" />`,i+=`<input class="update_comment-button" type="submit" value="취소" onclick="cancel_click(${e})" />`,s.innerHTML=i}}).catch(e=>console.error(e))}else Swal.fire("패스워드 일치 오류")}).catch(e=>console.error(e))}}async function delete_comment(e,t){const{value:n}=await Swal.fire({title:"댓글 삭제",text:"삭제하면 되돌릴 수 없습니다.",input:"password",icon:"warning",showCancelButton:!0,confirmButtonColor:"#3085d6",cancelButtonColor:"#d33",inputPlaceholder:"글 작성 시 입력했던 패스워드를 입력하세요",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(n=>{if(n.ok){const n="https://freshrimpsushi.com/blog/ajax/comment.php?action=deleteComment";postFetch(n,{cmt_idx:e}).then(e=>e.json()).then(n=>{Swal.fire("삭제되었습니다."),t==="parents"?commentRows=commentRows.filter(t=>t.cmt_idx!==e):t==="child"&&commentRows.map(t=>{t.child=t.child.filter(t=>t.cmt_idx!==e),t.child_cnt=t.child.length}),render_comment(commentRows)}).catch(e=>console.error(e))}else Swal.fire("패스워드 일치 오류")}).catch(e=>console.error(e))}}function update_comment_click(e,t){const i=document.querySelector(`#comment${e} .update-author`),a=document.querySelector(`#comment${e} .update-password`),r=document.querySelector(`#comment${e} .update-content`),n=i.value,s=a.value,o=r.value;(n===""||s===""||o==="")&&alert("빈칸을 채워주세요");const c="https://freshrimpsushi.com/blog/ajax/comment.php?action=updateComment";postFetch(c,{cmt_idx:e,author:n.replace(/\+/g,"%2B"),password:s,content:o.replace(/\+/g,"%2B")}).then(e=>e.json()).then(n=>{n.ok&&(Swal.fire("수정되었습니다."),t==="parents"?commentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}):t==="child"&&commentRows.map(t=>{t.cmt_idx==n.parent_cmt_idx&&t.child.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)})}),render_comment(commentRows),recentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}),render_recent_comment(recentRows))}).catch(e=>console.error(e))}function cancel_click(){render_comment(commentRows)}function re_comment(e,t){const s=document.querySelector(`#comment${e} .re-comment`);let n="";n+='<div class="re-comment-box">',n+='<div class="re-comment-author-info">',n+='<input class="re-comment-author" type="text" value="" placeholder="이름" />',n+='<input class="re-comment-password" type="password" value="" placeholder="비밀번호" />',n+="</div>",n+='<textarea class="re-comment-content" placeholder="내용" value="" style="IME-MODE:active;"></textarea>',t===void 0?n+=`<button class="write-button" onclick="re_comment_click(${e})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`:n+=`<button class="write-button" onclick="re_comment_click(${e}, ${t})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`,n+=`<button class="write-button" onclick="cancel_click(${e})" value="close"><i class='fa-solid fa-solid fa-ban'></i></button>`,n+="</div>",s.innerHTML=n}function re_comment_click(e,t){const n=document.querySelector(`#comment${e} .re-comment-author`),s=document.querySelector(`#comment${e} .re-comment-password`),o=document.querySelector(`#comment${e} .re-comment-content`),i=n.value,a=s.value,r=o.value;if(i===""||a===""||r===""){alert("빈칸을 채워주세요");return}const c="322",l="",d="論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(n=>{const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeReComment";return postFetch(s,{board_idx:c,board_slug:l,board_title:d,cmt_idx:t===void 0?e:t,author:i.replace(/\+/g,"%2B"),password:a,content:r.replace(/\+/g,"%2B"),user_ip:n})}).then(e=>e.json()).then(i=>{i.ok?(commentRows.map(n=>{t===void 0?n.cmt_idx==e&&n.child.push(i.row):n.cmt_idx==t&&n.child.push(i.row)}),render_comment(commentRows)):i.status==606?(Swal.fire(`Warning!
지속적인 도배 시도시
IP가 차단될 수 있습니다.`),n.value="",s.value="",o.value=""):i.status===607&&(alert(`지나친 댓글 도배를 확인하여
접근을 차단합니다.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}</script></div><aside class=sidebar><aside><style>.reddot a:link{color:#67d10f;text-shadow:0 0 10px #d3d3d3;font-weight:700}.reddot a:visited{color:#f5f5f5}</style><p class=reddot style=text-align:center;margin:0><a href=https://freshrimpsushi.github.io/jp/posts/2707/>夏の特選おまかせ<br>「想像上の数」</a></p></aside><br><div class=category></div><div style=display:flex>● をクリックして、興味ある分野だけ強調。<div class=resetmute><button class="sb-btn btnReset" style=border-radius:5px;border:0>reset</button>
<button class="sb-btn btnMute" style=border-radius:5px;border:0>mute</button></div></div><script defer>const color={green:"#33cc33",yellow:"#ffcc00",red:"#ff3333",black:"#000000"},categoryRows=[[{idx:1,name:"함수",color:color.green,show:"関数",size:"146"},{idx:2,name:"보조정리",color:color.green,show:"レンマ",size:"55"},{idx:3,name:"미분적분학",color:color.green,show:"微分積分学",size:"45"},{idx:4,name:"행렬대수",color:color.green,show:"行列代数",size:"117"}],[{idx:1,name:"정수론",color:color.green,show:"整数論",size:"90"},{idx:2,name:"집합론",color:color.green,show:"集合論",size:"49"},{idx:3,name:"그래프이론",color:color.green,show:"グラフ理論",size:"65"},{idx:4,name:"선형대수",color:color.green,show:"線形代数",size:"97"},{idx:5,name:"해석개론",color:color.green,show:"解析学",size:"84"},{idx:6,name:"추상대수",color:color.green,show:"抽象代数",size:"98"},{idx:7,name:"위상수학",color:color.green,show:"位相幾何学",size:"64"},{idx:8,name:"기하학",color:color.green,show:"幾何学",size:"167"}],[{idx:1,name:"다변수벡터해석",color:color.green,show:"ベクトル分析",size:"36"},{idx:2,name:"복소해석",color:color.green,show:"複素解析",size:"71"},{idx:3,name:"측도론",color:color.green,show:"測度論",size:"53"},{idx:4,name:"푸리에해석",color:color.green,show:"フーリエ解析",size:"54"},{idx:5,name:"표현론",color:color.red,show:"表現論",size:"7"},{idx:6,name:"초함수론",color:color.green,show:"シュワルツ超函数",size:"22"},{idx:7,name:"단층촬영",color:color.green,show:"トモグラフィ",size:"20"}],[{idx:1,name:"거리공간",color:color.green,show:"距離空間",size:"38"},{idx:2,name:"바나흐공간",color:color.green,show:"バナッハ空間",size:"38"},{idx:3,name:"힐베르트공간",color:color.green,show:"ヒルベルト空間",size:"31"},{idx:4,name:"르벡공간",color:color.green,show:"ルベーグ空間",size:"33"}],[{idx:1,name:"상미분방정식",color:color.green,show:"微分方程式",size:"58"},{idx:2,name:"편미분방정식",color:color.green,show:"偏微分方程式",size:"60"},{idx:3,name:"확률미분방정식",color:color.green,show:"確率微分方程式",size:"26"}],[{idx:1,name:"줄리아",color:color.green,show:"ジュリア",size:"234"},{idx:2,name:"알고리즘",color:color.green,show:"アルゴリズム",size:"28"},{idx:3,name:"수치해석",color:color.green,show:"数値解析",size:"63"},{idx:4,name:"최적화이론",color:color.green,show:"最適化理論",size:"37"},{idx:5,name:"머신러닝",color:color.green,show:"機械学習",size:"114"},{idx:6,name:"프로그래밍",color:color.yellow,show:"プログラミング",size:"125"},{idx:7,name:"세이버메트릭스",color:color.green,show:"セイバーメトリクス",size:"234",size:"13"}],[{idx:1,name:"물리학",color:color.green,show:"物理学",size:"30"},{idx:2,name:"수리물리",color:color.green,show:"数理物理学",size:"78"},{idx:3,name:"고전역학",color:color.green,show:"古典力学",size:"48"},{idx:4,name:"전자기학",color:color.green,show:"電磁気学",size:"51"},{idx:5,name:"양자역학",color:color.green,show:"量子力学",size:"57"},{idx:6,name:"열물리학",color:color.green,show:"熱物理学",size:"29"}],[{idx:1,name:"R",color:color.green,show:"R",size:"54"},{idx:2,name:"데이터확보",color:color.green,show:"データ確保",size:"29"},{idx:3,name:"데이터과학",color:color.green,show:"データサイエンス",size:"41"},{idx:4,name:"통계적검정",color:color.green,show:"統計的検定",size:"33"},{idx:5,name:"통계적분석",color:color.green,show:"統計的分析",size:"76"},{idx:6,name:"수리통계학",color:color.green,show:"数理統計学",size:"123"},{idx:7,name:"확률분포론",color:color.green,show:"確率分布論",size:"84"},{idx:8,name:"확률론",color:color.green,show:"確率論",size:"80"},{idx:9,name:"위상데이터분석",color:color.green,show:"位相データ分析",size:"40"}],[{idx:1,name:"논문작성",color:color.red,show:"論文作成",size:"63"},{idx:2,name:"생새우초밥지",color:color.black,show:"生エビ寿司誌",size:"7"}]];document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("blindList"));(e==""||e==null||e==null||e==0||e==NaN)&&localStorage.setItem("blindList",null),render_category(categoryRows),blind_category(e);const t=document.querySelector(".btnReset");t.addEventListener("click",()=>{let e=new Array;localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)});const n=document.querySelector(".btnMute");n.addEventListener("click",()=>{let e=new Array;for(let t=0;t<categoryRows.length;t++)categoryRows[t].map(n=>{const s={mainIdx:t,subIdx:n.idx};e.push(s)});localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)})});function render_category(e){const n=document.querySelector(".category");let t="";for(let n=0;n<e.length;n++)e[n].map(e=>{t+=`<span id="cate${n}-${e.idx}" class="cate etewsert">`,t+=`<span onclick="check_blind(${n}, ${e.idx});" style="cursor: pointer; color: ${e.color}">●</span>`,t+=`<a href="https://freshrimpsushi.github.io/jp/categories/${e.name.toLowerCase()}/">`,t+=` ${e.show} (${e.size})</a>`,t+="</span>",screen.width>954?t+="<br>":t+=" "}),t+="<hr>";n.innerHTML=t}function check_blind(e,t){const o=document.querySelector(`#cate${e}-${t}`);let n=new Array;const i={mainIdx:e,subIdx:t};let s=JSON.parse(localStorage.getItem("blindList"));if(s==""||s==null||s==null||s==0||s==NaN)n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind";else{n=s;let a=null;for(let s=0;s<n.length;s++)if(n[s].mainIdx==e&&n[s].subIdx==t){a=n.filter(n=>n.mainIdx!=e||n.subIdx!=t);break}a===null?(n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind"):(localStorage.setItem("blindList",JSON.stringify(a)),o.className="cate")}}function blind_category(e){const t=document.querySelectorAll(".cate");t.forEach(e=>{e.className="cate"}),e!==null&&e.map(e=>{const t=document.querySelector(`#cate${e.mainIdx}-${e.subIdx}`);t.className+=" blind"})}</script><br><br><b>最近見たポスト</b><div class=lately-viewed-list style=padding-left:4px></div><script defer>document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("latelyViewPostList")),n=document.querySelector(".lately-viewed-list");let t="";if(e==""||e==null||e==null||e==0||e==NaN)localStorage.setItem("latelyViewPostList",null),t+='<div class="lv-list">',t+=" · 열람한 포스트가 없습니다.",t+="</div>",n.innerHTML=t;else{for(let n=e.length-1;n>=0;n--)t+='<div class="lv-list">',t+=`<a href="${e[n].link}"> · ${e[n].title}</a>`,t+="</div>";n.innerHTML=t}})</script><script defer>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="論文レビュー：コルモゴロフ・アーノルドニューラルネットワーク（KAN）",c="https://freshrimpsushi.github.io/jp/posts/322/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script><br><b>最新コメント</b><div class=current-reply></div><script defer>const url="https://freshrimpsushi.com/blog/ajax/recent_comment.php?action=getCurrentComment";let recentRows=[];fetch(url).then(e=>e.json()).then(e=>{e.ok&&(recentRows=e.rows,render_recent_comment(recentRows))}).catch(e=>console.error(e));function render_recent_comment(e){const n=document.querySelector(".current-reply");let t="";e.map(e=>{let n="https://freshrimpsushi.github.io/jp/";e.board_idx>-1?n+=`posts/${e.board_idx}#comment${e.cmt_idx}`:e.board_idx==-1?n+=`#comment${e.cmt_idx}`:n+=`categories/${e.board_title}#comment${e.cmt_idx}`,t+='<div class="current-reply-list">',t+=`<a href="${n}">`,t+=`<b> - ${e.author}</b>: `,t+=`${e.content}`,t+=`</a>`,t+=`</div>`}),n.innerHTML=t,renderKaTex(n)}</script><br></aside></div><footer><aside><div><p id=mirror-link style=text-align:center><a style=cursor:text href=http://localhost:1313//jp/posts/322/>© 生エビ寿司屋 / Powered by 류대식, 전기현</a><br>Contact:
<img src=https://freshrimpsushi.github.io/jp/logo/gmail.png width=12px alt=mail> freshrimpsushi@gmail.com
<a href=https://freshrimpsushi.github.io/jp/index.xml><img src=https://freshrimpsushi.github.io/jp/logo/RSS.png width=12px alt=RSS> RSS</a></p></div><script type=text/javascript>var goIndex=function(){var e=document.getElementsByName("idx")[0].value,t="https://freshrimpsushi.github.io/jp/posts/"+e;location.replace(t)};document.addEventListener("keydown",function(e){const n=document.getElementById("navigator");if(e.altKey&&e.ctrlKey&&e.key==="l"){e.preventDefault();var t=document.querySelector("#mirror-link a");t?t.click():console.log("거울 링크를 찾지 못했습니다.")}})</script></aside></footer></body><script async src="https://www.googletagmanager.com/gtag/js?id=G-NLV8Y9PRK1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NLV8Y9PRK1")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4751085325232621" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/sweetalert2@11></script><script src=https://freshrimpsushi.github.io/jp/js/fontawsome.min.js></script><script src=https://freshrimpsushi.github.io/jp/js/common.js></script><script>document.addEventListener("DOMContentLoaded",()=>{fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/ip_checker.php";return postFetch(t,{user_ip:e})}).then(e=>e.json()).then(e=>{e.ok||(alert(`차단된 IP입니다.
Contact:
freshrimpsushi@gmail.com`),window.location.href="https://google.com")}).catch(e=>console.error(e))})</script></html>