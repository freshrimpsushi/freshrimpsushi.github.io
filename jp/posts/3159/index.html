<!doctype html><html class=blog lang=jp><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link rel=preload href=https://freshrimpsushi.github.io/jp/css/style.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=preload href=https://freshrimpsushi.github.io/jp/css/comment.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=icon href=https://freshrimpsushi.github.io/ko/logo/favicon.ico><meta name=msapplication-TileColor content="#FFFFFF"><meta name=msapplication-TileImage content="logo/basic.png"><meta name=NaverBot content="All"><meta name=NaverBot content="index,follow"><meta name=Yeti content="All"><meta name=Yeti content="index,follow"><meta name=google-site-verification content="KYAokS7-6C5YuXOjatJQsiK1T0O8x4YncYFIF4tneYI"><meta name=naver-site-verification content="e5651d6f97899061897203413efc84994f04bbba"><link rel=alternate type=application/rss+xml title=生エビ寿司屋 href=https://freshrimpsushi.github.io/jp/index.xml><title>論文レビュー: Neural Ordinary Differential Equations</title></head><meta name=title content="論文レビュー: Neural Ordinary Differential Equations"><meta name=description content="국내 최대의 수학, 물리학, 통계학 블로그"><meta property="og:title" content="論文レビュー: Neural Ordinary Differential Equations"><meta property="og:description" content><meta property="og:image" content="https://freshrimpsushi.github.io/jp/logo/basic.png/"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"j_","name":"論文レビュー: Neural Ordinary Differential Equations","headline":"論文レビュー: Neural Ordinary Differential Equations","alternativeHeadline":"","description":"概要および要約 「Neural Ordinary Differential Equations」はRicky T. Q. Chenら3名が2018年に発表した論文であり、2018 NeurIPS Best Papers","inLanguage":"jp","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/freshrimpsushi.github.io\/jp\/posts\/3159\/"},"author":{"@type":"Person","name":"전기현","url":"https://math.stackexchange.com/users/459895/ryu-dae-sick"},"creator":{"@type":"Person","name":"전기현"},"accountablePerson":{"@type":"Person","name":"전기현"},"copyrightHolder":"生エビ寿司屋","copyrightYear":"2021","dateCreated":"2021-12-15T00:00:00.00Z","datePublished":"2021-12-15T00:00:00.00Z","dateModified":"2021-12-15T00:00:00.00Z","publisher":{"@type":"Organization","name":"生エビ寿司屋","url":"https://freshrimpsushi.github.io/jp/","logo":{"@type":"ImageObject","url":"https:\/\/freshrimpsushi.github.io\/jp\/logo\/basic.png","width":"32","height":"32"}},"image":"https://freshrimpsushi.github.io/jp/logo/basic.png","url":"https:\/\/freshrimpsushi.github.io\/jp\/posts\/3159\/","wordCount":"5975","genre":[],"keywords":[]}</script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/mhchem.min.js integrity=sha384-F2ptQFZqNJuqfGGl28mIXyQ5kXH48spn7rcoS0Y9psqIKAcZPLd1NzwFlm/bl1mH crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>function renderKaTex(e){renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],trust:!0,trust:e=>["\\htmlId","\\href","\\includegraphics"].includes(e.command),macros:{"\\eqref":"(\\text{#1})","\\ref":"\\href{###1}{\\text{#1}}","\\label":"\\htmlId{#1}{}","\\sech":"\\operatorname{sech}","\\csch":"\\operatorname{csch}","\\sgn":"\\operatorname{sgn}","\\sign":"\\operatorname{sign}","\\sinc":"\\operatorname{sinc}","\\diag":"\\operatorname{diag}","\\diam":"\\operatorname{diam}","\\trace":"\\operatorname{trace}","\\Tr":"\\operatorname{Tr}","\\tr":"\\operatorname{tr}","\\re":"\\operatorname{Re}","\\im":"\\operatorname{Im}","\\Var":"\\operatorname{Var}","\\Poi":"\\operatorname{Poi}","\\Cov":"\\operatorname{Cov}","\\span":"\\operatorname{span}","\\supp":"\\operatorname{supp}","\\rank":"\\operatorname{rank}","\\nullity":"\\operatorname{nullity}","\\ad":"\\operatorname{ad}","\\Ric":"\\operatorname{Ric}","\\i":"\\mathrm{i}","\\d":"\\mathrm{d}","\\cR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5863.png}","\\acR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.4371.png}","\\bcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5899.png}","\\abcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.0596.png}","\\crH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\smallcrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\acrH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}","\\smallacrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}"},throwOnError:!1})}</script><body class=main><header><a href=https://freshrimpsushi.github.io/jp/ rel=home><p style=text-align:center;font-size:1rem;color:#000><img src=https://freshrimpsushi.github.io/jp/logo/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.png style=height:80px alt=logo></p></a></header><form method=get action=/jp/search style=border:1px;text-align:center><div class=field><input type=text id=searchtext placeholder=🔍︎ class=input_text name=s style=background-color:#eee;text-align:center;width:200px;font-size:1.5rem;border:1px;border-radius:5px;padding-top:5px;padding-bottom:5px;margin-bottom:1.5rem></div></form><aside style=text-align:center;margin-bottom:1rem><a href=https://freshrimpsushi.github.io/ko//posts/3159/>한국어</a> |
<a href=https://freshrimpsushi.github.io/en//posts/3159/>English</a> |
<a href=https://freshrimpsushi.github.io/jp//posts/3159/>日本語</a></aside><div class=wrapper><div class=content><div class=content-box><title>論文レビュー: Neural Ordinary Differential Equations</title>
<a href=https://freshrimpsushi.github.io/jp/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/ style=background-color:rgba(0,0,0,.8);color:orange;border-radius:10px;padding:5px>📂機械学習</a><h1>論文レビュー: Neural Ordinary Differential Equations</h1><aside><div class=innerheader><div class=innertoc><b>目次</b><nav id=TableOfContents><ul><li><a href=#概要および要約>概要および要約</a></li><li><a href=#1-はじめに>1 はじめに</a></li><li><a href=#2-odeソリューションのリバースモード自動微分>2 ODEソリューションのリバースモード自動微分</a></li><li><a href=#3-監督学習のための残差ネットワークをodeに置き換える>3 監督学習のための残差ネットワークをODEに置き換える</a></li><li><a href=#4-連続ノーマライジングフロー>4 連続ノーマライジングフロー</a><ul><li><a href=#41-連続ノーマライジングフローを用いた実験>4.1 連続ノーマライジングフローを用いた実験</a></li></ul></li><li><a href=#5-ジェネレーティブ潜在関数時系列モデル>5 ジェネレーティブ潜在関数時系列モデル</a><ul><li><a href=#51-時系列潜在ode実験>5.1 時系列潜在ODE実験</a></li></ul></li></ul></nav></div></div></aside><h2 id=概要および要約>概要および要約</h2><p>「<a href=https://proceedings.neurips.cc/paper_files/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf>Neural Ordinary Differential Equations</a>」はRicky T. Q. Chenら3名が2018年に発表した論文であり、<a href=https://neurips.cc/Conferences/2018/Awards>2018 NeurIPS Best Papers</a>に選ばれた。以下のように簡単な<a href=../1660>1階常微分方程式</a>である<a href=../1505>非自律システム</a>をニューラルネットワークで近似する方法を提案している。</p><p>$$
\dfrac{\mathrm{d}y}{\mathrm{d}t} = f(y, t)
$$</p><p>注目すべきは、ニューラルネットワークが近似（予測）するのは$y$ではなく、変化率$f$であるということだ。この式の両辺を$0$から任意の$T$まで積分すると次のようになる。</p><p>$$
y(T) - y(0) = \int\limits_{0}^{T} f(y, t) \mathrm{d}t \implies y(T) = y(0) + \int\limits_{0}^{T} f(y, t) \mathrm{d}t
$$</p><p>したがって、$f$を正確に近似できさえすれば、任意の$T$に対して$y(T)$を得ることができる。</p><h2 id=1-はじめに>1 はじめに</h2><p>下の図のように、等間隔の時間である8つのデータポイントから成る<a href=../900>時系列データ</a>が与えられているとする。</p><p><img src=3159_1.png#center alt></p><p>このような状況で、通常我々がやりたいことは、$t_{9}$、$t_{10}$、$t_{11}$、$\dots$に対するデータ$\mathbf{h}_{9}$、$\mathbf{h}_{10}$、$\mathbf{h}_{11}$、$\dots$を予測することである。これを実現するための簡単に考えられる方法の一つは、残差ニューラルネットワーク、<a href=../3634>RNN</a>、<a href=../3247>ノーマライジングフロー</a>などを使用して以下のようにモデリングするものである。</p><p>$$
\mathbf{h}_{t+1} = \mathbf{h}_{t} + f(\mathbf{h}_{t}; \theta) \tag{1}
$$</p><p>ここで$f$は<a href=../962>ニューラルネットワーク</a>であり、$\theta$は$f$の学習すべき<a href=../962>パラメータ</a>（重み）である。こういった方法はシンプルで直感的であり、最初に試してみることのできる方法の一つだが、次のような欠点がある。</p><ul><li>データを<a href=../1016>補間</a>することが難しい。$(1)$のようなモデルでは$t_{3}$と$t_{4}$の間のデータを予測することが難しい。特に任意の時間$t_{3.472}$に対するデータを予測することが簡単でない。</li><li>時間間隔が均等でないデータに対しては適用が難しい。$(1)$で$\mathbf{h}_{t+1}$を更新するルールは$f$を1回、2回、整数回足していくものであるため、時間間隔が均等でなければ$(1)$の等式は成立しない。</li></ul><p>この論文で提案する方法は、離散<a href=../1660>自律システム</a>である$(1)$を次のように連続な<a href=../1660>非自律システム</a>に変えて考えるものである。</p><p>$$
\dfrac{\mathrm{d}\mathbf{h}}{\mathrm{d}t} = f(\mathbf{h}(t), t; \theta) \tag{2}
$$</p><p>「非自律システムで外力（あるいは速度）$f$をパラメータ$\theta$を持つ人工ニューラルネットワークで定義した$(2)$」をNeural Ordinary Differential Equations（Neural ODE, NODE）という。</p><p>このようなODEを解いてくれる<a href=../1093>ソルバー</a>（すなわち$f$を積分してくれるもの）はすでに多く研究されており、性能の良いさまざまな方法が提案されている。したがってニューラルネットワークを通じて$f$をうまく近似したならば、以下の式を通じて任意の時間$t$について$\mathbf{h}(t)$を予測することができる。両辺を積分すると、</p><p>$$
\mathbf{h}(t) = \mathbf{h}(0) + \int\limits_{0}^{t} f(\mathbf{h}(t), s; \theta) \mathrm{d}s \tag{3}
$$</p><p>右辺は初期値$\mathbf{h}(0)$と$f$が与えられているならばODEソルバーを通して得られる値であるため、論文では次のように表記する。</p><p>$$
\mathbf{h}(t_{1}) = \operatorname{ODESolve}(\mathbf{h}(t_{0}), f, t_{0}, t_{1}, \theta)
$$</p><p>論文ではODEソルバーによってモデルを定義し値を計算することによって得られるメリットを以下のように説明している。</p><ul><li><p><strong>Memory efficiency<sup>メモリ効率</sup>:</strong></p><p>下記の2章で、<a href=../3077>逆伝播アルゴリズム</a>を使用せずに損失関数の<a href=../1010>勾配</a>を計算する方法を紹介する。したがってモデルの関数値を計算するときに<a href=../3442>中間計算結果を保存</a>する必要がなく、これはメモリ使用量がモデルのサイズに依存せず一定に維持されることを意味する。</p></li><li><p><strong>Adaptive computation<sup>適応計算</sup>:</strong></p><p><a href=../687>オイラー法</a>以来120年が経過する間に、より正確で効率的なODEソルバーが多く開発されてきた。特に最近のODEソルバーは、誤差のモニタリングおよび高精度達成を目的として実行中に評価戦略<sup>evaluation strategy</sup>を動的に調整する機能を提供する。</p></li><li><p><strong>Scalable and invertible normalizing flows<sup>ノーマライジングフローの一般化</sup>:</strong></p><p>連続的なモデルの副次的利点の一つは、変数変換の公式を計算しやすいということであり（4章で説明する）、これは効率の良い<a href=../3247>ノーマライジングフロー</a>モデルを構築できることを意味する。</p></li><li><p><strong>Continuous time-series models<sup>連続時系列モデル</sup>:</strong></p><p>訓練および予測データが等間隔に離散化されている必要があるRNNとは異なり、連続で定義されたNeural ODEは任意の時間$t$に対して予測を行うことができる。この内容は5章で詳しく説明される。</p></li></ul><h2 id=2-odeソリューションのリバースモード自動微分>2 ODEソリューションのリバースモード自動微分</h2><p>Neural ODEに関する核心的なアイデアと原理は<a href=#1-Introduction>はじめに</a>で全て説明された。2章では学習法について扱う。著者はNeural ODEを実装する方法を開発し、<a href=https://github.com/rtqichen/torchdiffeq>GitHubで公開</a>している。直接実装するわけではないので、学習に関する内容が特に気にならなければ飛ばしても構わないと思う。3〜5章はNeural ODEがどのように応用されるかを扱っているため、自分のフィールドでNeural ODEを活用したいならば3〜5章を詳しく読むことをお勧めする。特に4章の内容はディフュージョンモデルの次に生成モデルの主流を引っ張っているフローマッチングにもつながる。</p><p>観測値（正解データ）はニューラルネットワークのパラメータ$\theta$に依存しない定数であるため、損失関数を次のように簡単に表現しよう。</p><p>$$
L(\mathbf{z}(t_{1})) = L \left( \mathbf{z}(t_{0}) + \int_{t_{0}}^{t_{1}} f(\mathbf{z}(t), t; \theta) \mathrm{d}t \right) = L \left( \operatorname{OSESolve}(\mathbf{z}(t_{0}), f_{\theta}, t_{0}, t_{1}) \right)
$$</p><p>論文で損失関数の<a href=../1010>勾配</a>を計算するための方法はadjoint sensitivity methodであり、これは別のODEを時間逆順に積分することだ。その結果だけを見ると次のようになる。</p><p>$$
\dfrac{\mathrm{d}L}{\mathrm{d}\theta} = \int\limits_{t_{1}}^{t_{0}} \left( \dfrac{\partial L}{\partial \mathbf{z}(t)} \right)^{\mathsf{T}} \dfrac{\partial f(\mathbf{z}(t), t; \theta)}{\partial \theta} \mathrm{d}t
$$</p><p>詳細はAppendix B、C、Dで確認できる。<a href=https://proceedings.neurips.cc/paper_files/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Supplemental.zip>(ダウンロードリンク)</a> また下記の例で説明したコードと学習に関連するメソッドは <code>torchdiffeq</code> パッケージに含まれており <a href=https://github.com/rtqichen/torchdiffeq/tree/master>GitHub</a>で公開されている。</p><h2 id=3-監督学習のための残差ネットワークをodeに置き換える>3 監督学習のための残差ネットワークをODEに置き換える</h2><p>Neural ODEは$(1)$を$(3)$として置き換えたものであると考えれば、残差ネットワークの一般化として見ることができる。</p><p>$$
\text{residual: } \mathbf{h}_{t+1} = \mathbf{h}_{t} + f(\mathbf{h}_{t}; \theta) \quad\overset{\text{generalization}}{\implies}\quad \dfrac{\mathrm{d}\mathbf{h}}{\mathrm{d}t} = f(\mathbf{h}(t), t; \theta)
$$</p><p>したがってResNetを利用した監督学習においてNeural ODEを活用できる。著者たちは<a href=../3444>MNISTデータセット</a>の判別問題でResNetの部分をそのままNeural ODEで置き換えて性能を比較した。</p><p>ODEの初期値問題を数値的に解くために選ばれた<a href=../1093>ソルバー</a>は<a href=../724>アダムズメソッド</a>であり、<code>scipy.integrate</code> パッケージで提供される<a href=../2671>陰的メソッド</a>を使用した。最適化手法であるadjoint sensitivity methodを <code>pytorch.autograd</code> で実装した。</p><p>実験結果としてODE-NetはResNetに比べて$1/3$程度のパラメータを持つにもかかわらず、ほぼ同じ性能を示した。$L$はResNetの層数を意味し、ResNetの計算時間と逆伝播に必要なメモリは$L$に比例する。$\tilde{L}$はODEソルバーのnumber of function evaluations (NFE)であり、積分区間をどれだけ分割して計算するかを意味する。ODEソルバーは数値積分を行うので<a href=../1128>積分区間を分割する</a>ことになり、NFEはこの区間の数を示す。例えば$[0, 1]$区間を$0.05$の間隔で積分を行うと$\text{NFE} = \dfrac{1}{0.05} = 20$である。論文ではこれをODE-Netの層数と解釈することができると述べている。NFEが大きいほど正確に計算できるが、計算に時間がかかるため、適度な数を選ぶことが重要である。Neural ODEではNFEをモデルが自動で選択する。</p><p><img src=3159_3.png alt></p><p>Figure 3a、3bではそれぞれ順方向計算におけるNFEに応じた誤差と計算時間を示し、直感に矛盾しない結果と言える。Figure 3cを見ると逆方向計算が順方向計算に比べておおよそ半分のレベルであることがわかる。これは提案する学習方法であるadjoint sensitivity methodが非常に効率的であることを示している。Figure 3dは訓練が進むにつれてNFEが増加することを示しており、これはモデルが訓練されるにつれて徐々に複雑になり、それをよく表現するために精巧になっていると説明している。</p><p><img src=3159_4.png alt></p><h2 id=4-連続ノーマライジングフロー>4 連続ノーマライジングフロー</h2><p>$(1)$のような離散的なモデリングは<a href=../3247>ノーマライジングフロー</a><sup>normalizing flow (NF)</sup>においても見受けられる。</p><p>$$
\mathbf{z}_{1} = f(\mathbf{z}_{0})
$$</p><p>$$
\log p(\mathbf{z}_{1}) = \log p(\mathbf{z}_{0}) - \log \left| \det \dfrac{\partial f}{\partial \mathbf{z}_{0}} \right| \tag{a4}
$$</p><p>簡単にplanar flowを例として挙げると、</p><p>$$
\mathbf{z}_{t+1} = \mathbf{z}_{t} + \mathbf{u} \tanh (\mathbf{w}^{\mathsf{T}}\mathbf{z}_{t} + b)
$$</p><p>$$
\log p(\mathbf{z}_{t+1}) = \log p(\mathbf{z}_{t}) - \log \left| 1 + \mathbf{u}^{\mathsf{T}} \dfrac{\partial \tanh}{\partial \mathbf{z}} \right|
$$</p><p>ノーマルフローを学習する上で最も重要な考慮点は、$(a4)$の<a href=../252>行列式</a>の計算である。これは$\mathbf{z}$の次元や重みの数に対して三乗の計算コストを持つ。興味深いことに離散的な構造$(1)$を連続的構造$(3)$に変えるとそれに関連する計算がさらに簡素化される。</p><hr><p>$\textbf{Theorem 1 }\text{(Instantaneous Change of Variables).}$</p><p>$\mathbf{z}(t)$を<a href=../1433>連続確率変数</a>、$p(\mathbf{z}(t))$をそれに対する<a href=../1433>確率密度関数</a>としよう。また<a href=../1660>非自律微分方程式</a>が次のように与えられたとしよう。</p><p>$$
\dfrac{\mathrm{d} \mathbf{z}}{\mathrm{d}t} = f(\mathbf{z}(t), t) \tag{a5}
$$</p><p>$f$が変数$\mathbf{z}$に関して<a href=../3541>リプシッツ連続</a>であり、変数$t$に関して<a href=../1206>連続</a>であるとしよう。すると、対数確率密度の導関数は次のようになる。</p><p>$$
\dfrac{\partial \log p(\mathbf{z}(t))}{\partial t} = -\Tr \left( \dfrac{\partial f}{\partial \mathbf{z}(t)} \right)
$$</p><p>ここで$\Tr$は<a href=../1924>トレース</a>である。</p><hr><p>$(a4)$の行列式計算が単純なトレース計算に変わった。また標準的な離散ノーマライジングフローでは、今回は$f$が<a href=../471>変数分離可能</a>である必要がない。上記で例として挙げたplanar flowを上記$\textbf{Theorem 1}$に合わせて連続的形態に変えれば次のようになる。</p><p>$$
\dfrac{\mathrm{d}\mathbf{z}(t)}{\mathrm{d}t} = \mathbf{u} \tanh(\mathbf{w}^{\mathsf{T}}\mathbf{z}(t) + b), \qquad \dfrac{\partial \log p (\mathbf{z}(t))}{\partial t} = -\Tr \left( \mathbf{u} \dfrac{\partial \tanh(\mathbf{w}^{\mathsf{T}}\mathbf{z}(t) + b)}{\partial \mathbf{z}(t)} \right)
$$</p><p><strong>複数の隠れユニットを線形コストで使用する</strong></p><p>行列式は線形ではないが、<a href=../1924>トレースは線形</a>であるため$\Tr \sum\limits_{n} J_{n} = \sum\limits_{n} \Tr J_{n}$が成立する。したがって$(a5)$の$f$を線形結合で表しても、対数確率密度の導関数は次のように簡単に表現できる。</p><p>$$
\dfrac{\mathrm{d} \mathbf{z}(t)}{\mathrm{d}t} = \sum\limits_{n=1}^{M} f_{n}(\mathbf{z}(t)), \qquad \dfrac{\mathrm{d}\log p(\mathbf{z}(t))}{\mathrm{d}t} = -\sum\limits_{n=1}^{M} \Tr \left( \dfrac{\partial f_{n}}{\partial \mathbf{z}(t)} \right)
$$</p><p>これは隠れ層のノード数$M$に対して計算コストが線形的に増加することを意味する。既存のノーマライジングフローは$\mathcal{O}(M^{3})$の計算コストのために多くの場合、一つのノードを多くの層で使用する構造をしている。</p><p><strong>時間依存ダイナミクス</strong></p><p>論文ではgatingと呼ばれる方法を使用してフローを以下のように定義する。</p><p>$$
\dfrac{\mathrm{d} \mathbf{z}}{\mathrm{d}t} = \sum\limits_{n} \sigma_{n}(t)f_{n}(\mathbf{z}), \qquad \sigma_{n}(t) \in (0 1)
$$</p><p>すなわち、$f(\mathbf{z}, t)$が<a href=../1985>変数分離可能</a>であると仮定する。ここで$\sigma_{n}$も$f_{n}$も全て学習する必要があるニューラルネットワークである。論文ではこれを<strong>連続ノーマライジングフロー</strong><sup>continuous normalizing flow (CNF)</sup>と呼ぶ。[フローマッチング]はこのCNFをより効率的に学習することができる一つの方法である。</p><h3 id=41-連続ノーマライジングフローを用いた実験>4.1 連続ノーマライジングフローを用いた実験</h3><p>CNFとNFを比較する。CNFは上記で説明した通りに実装され、<a href=../3529>Adam</a>オプティマイザーを用いて10,000回の反復を行い訓練された。NFは<a href=../3247>初提案された論文</a>と同様に実装され、<a href=../3529>RMSprop</a>オプティマイザーを用いて500,000回の反復で訓練された。CNF側の反復回数は顕著に少ない。結果は以下の図から確認できる。</p><p><img src=3159_5.png alt></p><p>下のFigure 5の上の2行はCNF、最後の行はNFに対する結果として見られる。CNFは滑らかに変換される一方で、NFはそうではなく、Two Moonsデータに対して正しくモデル化ができていない。</p><p><img src=3159_6.png alt></p><h2 id=5-ジェネレーティブ潜在関数時系列モデル>5 ジェネレーティブ潜在関数時系列モデル</h2><p>Neural ODEは非自律システムをニューラルネットワークで近似する方法であるため、<a href=../900>時系列データ</a>の予測、補間、欠損値生成などにも使用できる。論文が提案する訓練方法は以下の通りである。</p><ol start=0><li><p>時系列データ$\left\{ \mathbf{x}_{i}, t_{i} \right\}_{i=1}^{N}$が与えられているとする。</p></li><li><p>RNNを<a href=../3380>エンコーダー</a>として利用し、<a href=../3589>潜在変数</a>$\boldsymbol{\mu}$および$\boldsymbol{\sigma}$を抽出する。</p><p>$$
(\boldsymbol{\mu}, \log\boldsymbol{\sigma}^{2}) = \operatorname{RNNencoder}\left( \left\{ \mathbf{x}_{i}, t_{i} \right\} \right)
$$</p></li><li><p>正規分布$N(\mathbf{0}, I)$から$\boldsymbol{\epsilon}$を<a href=../2686>抽出</a>し、$\boldsymbol{\mu}$と$\boldsymbol{\sigma}$を使用して潜在変数の初期値$\mathbf{z}_{t_{0}}$を生成する。</p><p>$$
\mathbf{z}_{t_{0}} = \exp(0.5 \log\boldsymbol{\sigma}^{2}) \odot \boldsymbol{\epsilon} + \boldsymbol{\mu}
$$</p><p>こうすることで、あたかも$\operatorname{RNNencoder}$が時系列データを<a href=../3589>潜在空間</a>$N(\boldsymbol{\mu}, \diag(\boldsymbol{\sigma}^{2}))$にマッピングするように見せるが、逆伝播が可能である。</p></li><li><p>潜在変数の初期値$\mathbf{z}_{t_{0}}$とNeural ODEを通じて$\mathbf{z}_{t_{i}}$を計算する。</p><p>$$
(\mathbf{z}_{t_{1}}, \mathbf{z}_{t_{2}}, \dots, \mathbf{z}_{t_{N}})
= \operatorname{ODESolve}(\mathbf{z}_{t_{0}}, f, t_{0}, \dots, t_{N}, \theta)
$$</p></li><li><p>$\mathbf{z}_{t_{i}}$を<a href=../3447>FCN</a>として定義された<a href=../3380>デコーダー</a>に入力し、予測された時系列データ$\mathbf{x}_{i}$を得る。</p><p>$$
\mathbf{x}_{t_{i}} = \operatorname{FCNdecoder}(\mathbf{z}_{t_{i}})
$$</p></li><li><p>ELBOを最大化する。</p><p>$$
\text{ELBO} = \sum\limits_{i} \log p(\mathbf{x}_{t_{i}} | \mathbf{z}_{t_{i}}) + \log p(\mathbf{z}_{t_{0}}) - \log q(\mathbf{z}_{t_{0}} | \left\{ \mathbf{x}_{t_{i}}, t_{i} \right\})
$$</p></li></ol><h3 id=51-時系列潜在ode実験>5.1 時系列潜在ODE実験</h3><p>実験に使用したニューラルネットワークは次のとおりである。</p><ul><li>$\operatorname{RNNencoder}$: ノードが25個のRNN</li><li>潜在空間は4次元。$(\boldsymbol{\mu}), (\boldsymbol{\sigma}) \in \mathbb{R}^{2 \times 2}$</li><li>NeuralODE $f$: ノードが20個の隠れ層を1つ持つMLP</li><li>$\operatorname{FCNdecoder}$: ノードが20個の隠れ層を1つ持つ別のMLP</li></ul><p>データセットに関する条件は以下の通りである。</p><ul><li>2次元螺旋データ1000個を生成。</li><li>半分は時計回り、残りは反時計回り。</li><li>各軌道は異なる初期値から始まり等間隔な時間で100個の点をサンプリング。</li><li>観測値にガウシアンノイズを追加した。</li><li>学習時には各軌道の100個の点から重複なしで無作為に30/50/100個を抽出して使用した。</li></ul><p>以下の表を見るとNeuralODEの性能が明らかに優れていることが分かり、さらにデータが少ない時も多い時に比べて性能が大幅に落ちないということが確認できる。</p><p><img src=3159_7.png alt></p><p>以下の図はRNNとNeuralODEの予測結果である。NeuralODEの結果の方が滑らかで、学習しなかった外部領域での予測もより優れていることが示されている。</p><p><img src=3159_8.png alt></p><p>以下の図は潜在変数の軌道を最初の2次元について描いたものである。軌道は時計回りの螺旋と反時計回りの螺旋という2つのクラスタに分かれており、これは提案する方法が<a href=../3589>潜在変数</a>をうまく表現していることを意味する。</p><p><img src=3159_9.png alt></p><aside style=text-align:right>2021-12-15&emsp;
전기현&emsp;
<a href=../960>🎲 3159</a></aside><script>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="論文レビュー: Neural Ordinary Differential Equations",c="https://freshrimpsushi.github.io/jp/posts/3159/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script></div><aside><h2>コメント</h2><div class=area-reply><div class=list-reply></div></div><div class=write-box><div class="write-author-info box-account"><input type=hidden name=cmt_idx>
<input class=ai-author type=text placeholder=Name>
<input class=ai-password type=password maxlength=20 placeholder=Password></div><div class=write-content><textarea class=ai-content value placeholder=日本語でも構いませんが、できれば英語でお願いします style=ime-mode:active></textarea></div><button class=write-button onclick=write_comment() aria-label=send><i class='fa-solid fa-paper-plane'></i></button><aside class=tex>コメントにも $\TeX$ が適用されます。</aside></div></aside><script>let commentRows=[];const listReply=document.querySelector(".list-reply");document.addEventListener("DOMContentLoaded",()=>{get_all_comment()});function get_all_comment(){fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=getAllComment";return postFetch(t,{board_idx:"3159",user_ip:e})}).then(e=>e.json()).then(e=>{e.ok&&(commentRows=e.rows,render_comment(commentRows))}).catch(e=>console.error(e))}function render_comment(e){const n=["류대식","전기현","ㅇㅇ","질문"],s=["류대식","전기현"];render_blank();let t="";e.map(e=>{t+=`<div id="comment${e.cmt_idx}" class="parents">`,t+=`<div class="content-info">`;let o="";e.cmt_cnt>125?o="🥇":e.cmt_cnt>25?o="🥈":e.cmt_cnt>5&&(o="🥉"),n.includes(e.author)&&(o="");let i="";e.ip_address==null?i="(-)":(ipParts=e.ip_address.split("."),i=`(${ipParts[0]}.${ipParts[1]})`),s.includes(e.author)&&(i=""),t+=`<div class="list-author">${o} ${e.author} ${i}</div>`,t+=`<sup class="list-date">${e.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,e.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> 管理者の承認を待っています</div>`);let a=e.content;a=a.replace(/\n/g,"<br />"),t+=`<div class="content-text">${a} <span class="re-comment-button" onclick="re_comment('${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`,e.child.map(o=>{let c="child";e.ip_address&&o.ip_address===e.ip_address&&(c="parentself"),t+=`<div id="comment${o.cmt_idx}" class="${c}">`,t+=`<div class="content-info">`;let i="";o.cmt_cnt>5?i="🥉":o.cmt_cnt>25?i="🥈":o.cmt_cnt>125&&(i="🥇"),n.includes(o.author)&&(i="");let a="";o.ip_address==null?a="(-)":a=`(${o.ip_address})`,s.includes(o.author)&&(a=""),t+=`<div class="list-author">${i} ${o.author} ${a}</div>`,t+=`<sup class="list-date">${o.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,o.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> 管理者の承認を待っています</div>`);let r=o.content;r=r.replace(/\n/g,"<br />"),t+=`<div class="content-text">${r} <span class="re-comment-button" onclick="re_comment('${o.cmt_idx}', '${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`})}),listReply.innerHTML=t,renderKaTex(listReply),location.href.indexOf("#")!=-1&&(location.href=location.href.substr(location.href.indexOf("#")))}function render_blank(){listReply.innerHTML=""}function write_comment(){const e=document.querySelector(".ai-author"),t=document.querySelector(".ai-password"),n=document.querySelector(".ai-content"),s=e.value,o=t.value,i=n.value;if(s===""||o===""||i===""){alert("빈칸을 채워주세요");return}const a="3159",r="",c="論文レビュー: Neural Ordinary Differential Equations";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeComment";return postFetch(t,{board_idx:a,board_slug:r,board_title:c,author:s.replace(/\+/g,"%2B"),password:o,content:i.replace(/\+/g,"%2B"),user_ip:e})}).then(e=>e.json()).then(s=>{s.ok?(commentRows.push(s.row),render_comment(commentRows),e.value="",t.value="",n.value=""):s.status===606?(Swal.fire(`Warning!
지속적인 도배 시도시
IP가 차단될 수 있습니다.`),e.value="",t.value="",n.value=""):s.status===607&&(alert(`지나친 댓글 도배를 확인하여
접근을 차단합니다.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}async function update_comment(e,t){const{value:n}=await Swal.fire({title:"댓글 수정",input:"password",inputPlaceholder:"글 작성 시 입력했던 패스워드를 입력하세요",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(s=>{if(s.ok){const s=document.querySelector(`#comment${e}`),o="https://freshrimpsushi.com/blog/ajax/comment.php?action=getComment";postFetch(o,{cmt_idx:e}).then(e=>e.json()).then(o=>{if(o.ok){const a=o.row,r=a.author,c=a.content;let i="";i+=`<div class="update-author-info">`,i+=`<input class="update-author" type="text" value="${r}" placeholder="이름" />`,i+=`<input class="update-password" type="password" value="${n}" placeholder="비밀번호" disabled />`,i+="</div>",i+=`<textarea class="update-content" value="" style="IME-MODE:active;">${c}</textarea>`,i+=`<input class="update_comment-button" type="submit" value="수정" onclick="update_comment_click(${e}, '${t}')" />`,i+=`<input class="update_comment-button" type="submit" value="취소" onclick="cancel_click(${e})" />`,s.innerHTML=i}}).catch(e=>console.error(e))}else Swal.fire("패스워드 일치 오류")}).catch(e=>console.error(e))}}async function delete_comment(e,t){const{value:n}=await Swal.fire({title:"댓글 삭제",text:"삭제하면 되돌릴 수 없습니다.",input:"password",icon:"warning",showCancelButton:!0,confirmButtonColor:"#3085d6",cancelButtonColor:"#d33",inputPlaceholder:"글 작성 시 입력했던 패스워드를 입력하세요",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(n=>{if(n.ok){const n="https://freshrimpsushi.com/blog/ajax/comment.php?action=deleteComment";postFetch(n,{cmt_idx:e}).then(e=>e.json()).then(n=>{Swal.fire("삭제되었습니다."),t==="parents"?commentRows=commentRows.filter(t=>t.cmt_idx!==e):t==="child"&&commentRows.map(t=>{t.child=t.child.filter(t=>t.cmt_idx!==e),t.child_cnt=t.child.length}),render_comment(commentRows)}).catch(e=>console.error(e))}else Swal.fire("패스워드 일치 오류")}).catch(e=>console.error(e))}}function update_comment_click(e,t){const i=document.querySelector(`#comment${e} .update-author`),a=document.querySelector(`#comment${e} .update-password`),r=document.querySelector(`#comment${e} .update-content`),n=i.value,s=a.value,o=r.value;(n===""||s===""||o==="")&&alert("빈칸을 채워주세요");const c="https://freshrimpsushi.com/blog/ajax/comment.php?action=updateComment";postFetch(c,{cmt_idx:e,author:n.replace(/\+/g,"%2B"),password:s,content:o.replace(/\+/g,"%2B")}).then(e=>e.json()).then(n=>{n.ok&&(Swal.fire("수정되었습니다."),t==="parents"?commentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}):t==="child"&&commentRows.map(t=>{t.cmt_idx==n.parent_cmt_idx&&t.child.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)})}),render_comment(commentRows),recentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}),render_recent_comment(recentRows))}).catch(e=>console.error(e))}function cancel_click(){render_comment(commentRows)}function re_comment(e,t){const s=document.querySelector(`#comment${e} .re-comment`);let n="";n+='<div class="re-comment-box">',n+='<div class="re-comment-author-info">',n+='<input class="re-comment-author" type="text" value="" placeholder="이름" />',n+='<input class="re-comment-password" type="password" value="" placeholder="비밀번호" />',n+="</div>",n+='<textarea class="re-comment-content" placeholder="내용" value="" style="IME-MODE:active;"></textarea>',t===void 0?n+=`<button class="write-button" onclick="re_comment_click(${e})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`:n+=`<button class="write-button" onclick="re_comment_click(${e}, ${t})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`,n+=`<button class="write-button" onclick="cancel_click(${e})" value="close"><i class='fa-solid fa-solid fa-ban'></i></button>`,n+="</div>",s.innerHTML=n}function re_comment_click(e,t){const n=document.querySelector(`#comment${e} .re-comment-author`),s=document.querySelector(`#comment${e} .re-comment-password`),o=document.querySelector(`#comment${e} .re-comment-content`),i=n.value,a=s.value,r=o.value;if(i===""||a===""||r===""){alert("빈칸을 채워주세요");return}const c="3159",l="",d="論文レビュー: Neural Ordinary Differential Equations";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(n=>{const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeReComment";return postFetch(s,{board_idx:c,board_slug:l,board_title:d,cmt_idx:t===void 0?e:t,author:i.replace(/\+/g,"%2B"),password:a,content:r.replace(/\+/g,"%2B"),user_ip:n})}).then(e=>e.json()).then(i=>{i.ok?(commentRows.map(n=>{t===void 0?n.cmt_idx==e&&n.child.push(i.row):n.cmt_idx==t&&n.child.push(i.row)}),render_comment(commentRows)):i.status==606?(Swal.fire(`Warning!
지속적인 도배 시도시
IP가 차단될 수 있습니다.`),n.value="",s.value="",o.value=""):i.status===607&&(alert(`지나친 댓글 도배를 확인하여
접근을 차단합니다.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}</script></div><aside class=sidebar><aside><style>.reddot a:link{color:#67d10f;text-shadow:0 0 10px #d3d3d3;font-weight:700}.reddot a:visited{color:#f5f5f5}</style><p class=reddot style=text-align:center;margin:0><a href=https://freshrimpsushi.github.io/jp/posts/2707/>夏の特選おまかせ<br>「想像上の数」</a></p></aside><br><div class=category></div><div style=display:flex>● をクリックして、興味ある分野だけ強調。<div class=resetmute><button class="sb-btn btnReset" style=border-radius:5px;border:0>reset</button>
<button class="sb-btn btnMute" style=border-radius:5px;border:0>mute</button></div></div><script defer>const color={green:"#33cc33",yellow:"#ffcc00",red:"#ff3333",black:"#000000"},categoryRows=[[{idx:1,name:"함수",color:color.green,show:"関数",size:"146"},{idx:2,name:"보조정리",color:color.green,show:"レンマ",size:"55"},{idx:3,name:"미분적분학",color:color.green,show:"微分積分学",size:"45"},{idx:4,name:"행렬대수",color:color.green,show:"行列代数",size:"117"}],[{idx:1,name:"정수론",color:color.green,show:"整数論",size:"90"},{idx:2,name:"집합론",color:color.green,show:"集合論",size:"49"},{idx:3,name:"그래프이론",color:color.green,show:"グラフ理論",size:"65"},{idx:4,name:"선형대수",color:color.green,show:"線形代数",size:"97"},{idx:5,name:"해석개론",color:color.green,show:"解析学",size:"84"},{idx:6,name:"추상대수",color:color.green,show:"抽象代数",size:"98"},{idx:7,name:"위상수학",color:color.green,show:"位相幾何学",size:"64"},{idx:8,name:"기하학",color:color.green,show:"幾何学",size:"167"}],[{idx:1,name:"다변수벡터해석",color:color.green,show:"ベクトル分析",size:"36"},{idx:2,name:"복소해석",color:color.green,show:"複素解析",size:"71"},{idx:3,name:"측도론",color:color.green,show:"測度論",size:"53"},{idx:4,name:"푸리에해석",color:color.green,show:"フーリエ解析",size:"54"},{idx:5,name:"표현론",color:color.red,show:"表現論",size:"7"},{idx:6,name:"초함수론",color:color.green,show:"シュワルツ超函数",size:"22"},{idx:7,name:"단층촬영",color:color.green,show:"トモグラフィ",size:"20"}],[{idx:1,name:"거리공간",color:color.green,show:"距離空間",size:"38"},{idx:2,name:"바나흐공간",color:color.green,show:"バナッハ空間",size:"38"},{idx:3,name:"힐베르트공간",color:color.green,show:"ヒルベルト空間",size:"31"},{idx:4,name:"르벡공간",color:color.green,show:"ルベーグ空間",size:"33"}],[{idx:1,name:"상미분방정식",color:color.green,show:"微分方程式",size:"58"},{idx:2,name:"편미분방정식",color:color.green,show:"偏微分方程式",size:"60"},{idx:3,name:"확률미분방정식",color:color.green,show:"確率微分方程式",size:"26"}],[{idx:1,name:"줄리아",color:color.green,show:"ジュリア",size:"234"},{idx:2,name:"알고리즘",color:color.green,show:"アルゴリズム",size:"28"},{idx:3,name:"수치해석",color:color.green,show:"数値解析",size:"63"},{idx:4,name:"최적화이론",color:color.green,show:"最適化理論",size:"37"},{idx:5,name:"머신러닝",color:color.green,show:"機械学習",size:"114"},{idx:6,name:"프로그래밍",color:color.yellow,show:"プログラミング",size:"125"},{idx:7,name:"세이버메트릭스",color:color.green,show:"セイバーメトリクス",size:"234",size:"13"}],[{idx:1,name:"물리학",color:color.green,show:"物理学",size:"30"},{idx:2,name:"수리물리",color:color.green,show:"数理物理学",size:"78"},{idx:3,name:"고전역학",color:color.green,show:"古典力学",size:"48"},{idx:4,name:"전자기학",color:color.green,show:"電磁気学",size:"51"},{idx:5,name:"양자역학",color:color.green,show:"量子力学",size:"57"},{idx:6,name:"열물리학",color:color.green,show:"熱物理学",size:"29"}],[{idx:1,name:"R",color:color.green,show:"R",size:"54"},{idx:2,name:"데이터확보",color:color.green,show:"データ確保",size:"29"},{idx:3,name:"데이터과학",color:color.green,show:"データサイエンス",size:"41"},{idx:4,name:"통계적검정",color:color.green,show:"統計的検定",size:"33"},{idx:5,name:"통계적분석",color:color.green,show:"統計的分析",size:"76"},{idx:6,name:"수리통계학",color:color.green,show:"数理統計学",size:"123"},{idx:7,name:"확률분포론",color:color.green,show:"確率分布論",size:"86"},{idx:8,name:"확률론",color:color.green,show:"確率論",size:"80"},{idx:9,name:"위상데이터분석",color:color.green,show:"位相データ分析",size:"40"}],[{idx:1,name:"논문작성",color:color.red,show:"論文作成",size:"63"},{idx:2,name:"생새우초밥지",color:color.black,show:"生エビ寿司誌",size:"7"}]];document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("blindList"));(e==""||e==null||e==null||e==0||e==NaN)&&localStorage.setItem("blindList",null),render_category(categoryRows),blind_category(e);const t=document.querySelector(".btnReset");t.addEventListener("click",()=>{let e=new Array;localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)});const n=document.querySelector(".btnMute");n.addEventListener("click",()=>{let e=new Array;for(let t=0;t<categoryRows.length;t++)categoryRows[t].map(n=>{const s={mainIdx:t,subIdx:n.idx};e.push(s)});localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)})});function render_category(e){const n=document.querySelector(".category");let t="";for(let n=0;n<e.length;n++)e[n].map(e=>{t+=`<span id="cate${n}-${e.idx}" class="cate etewsert">`,t+=`<span onclick="check_blind(${n}, ${e.idx});" style="cursor: pointer; color: ${e.color}">●</span>`,t+=`<a href="https://freshrimpsushi.github.io/jp/categories/${e.name.toLowerCase()}/">`,t+=` ${e.show} (${e.size})</a>`,t+="</span>",screen.width>954?t+="<br>":t+=" "}),t+="<hr>";n.innerHTML=t}function check_blind(e,t){const o=document.querySelector(`#cate${e}-${t}`);let n=new Array;const i={mainIdx:e,subIdx:t};let s=JSON.parse(localStorage.getItem("blindList"));if(s==""||s==null||s==null||s==0||s==NaN)n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind";else{n=s;let a=null;for(let s=0;s<n.length;s++)if(n[s].mainIdx==e&&n[s].subIdx==t){a=n.filter(n=>n.mainIdx!=e||n.subIdx!=t);break}a===null?(n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind"):(localStorage.setItem("blindList",JSON.stringify(a)),o.className="cate")}}function blind_category(e){const t=document.querySelectorAll(".cate");t.forEach(e=>{e.className="cate"}),e!==null&&e.map(e=>{const t=document.querySelector(`#cate${e.mainIdx}-${e.subIdx}`);t.className+=" blind"})}</script><br><br><b>最近見たポスト</b><div class=lately-viewed-list style=padding-left:4px></div><script defer>document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("latelyViewPostList")),n=document.querySelector(".lately-viewed-list");let t="";if(e==""||e==null||e==null||e==0||e==NaN)localStorage.setItem("latelyViewPostList",null),t+='<div class="lv-list">',t+=" · 열람한 포스트가 없습니다.",t+="</div>",n.innerHTML=t;else{for(let n=e.length-1;n>=0;n--)t+='<div class="lv-list">',t+=`<a href="${e[n].link}"> · ${e[n].title}</a>`,t+="</div>";n.innerHTML=t}})</script><script defer>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="論文レビュー: Neural Ordinary Differential Equations",c="https://freshrimpsushi.github.io/jp/posts/3159/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script><br><b>最新コメント</b><div class=current-reply></div><script defer>const url="https://freshrimpsushi.com/blog/ajax/recent_comment.php?action=getCurrentComment";let recentRows=[];fetch(url).then(e=>e.json()).then(e=>{e.ok&&(recentRows=e.rows,render_recent_comment(recentRows))}).catch(e=>console.error(e));function render_recent_comment(e){const n=document.querySelector(".current-reply");let t="";e.map(e=>{let n="https://freshrimpsushi.github.io/jp/";e.board_idx>-1?n+=`posts/${e.board_idx}#comment${e.cmt_idx}`:e.board_idx==-1?n+=`#comment${e.cmt_idx}`:n+=`categories/${e.board_title}#comment${e.cmt_idx}`,t+='<div class="current-reply-list">',t+=`<a href="${n}">`,t+=`<b> - ${e.author}</b>: `,t+=`${e.content}`,t+=`</a>`,t+=`</div>`}),n.innerHTML=t,renderKaTex(n)}</script><br></aside></div><footer><aside><div><p id=mirror-link style=text-align:center><a style=cursor:text href=http://localhost:1313//jp/posts/3159/>© 生エビ寿司屋 / Powered by 류대식, 전기현</a><br>Contact:
<img src=https://freshrimpsushi.github.io/jp/logo/gmail.png width=12px alt=mail> freshrimpsushi@gmail.com
<a href=https://freshrimpsushi.github.io/jp/index.xml><img src=https://freshrimpsushi.github.io/jp/logo/RSS.png width=12px alt=RSS> RSS</a></p></div><script type=text/javascript>var goIndex=function(){var e=document.getElementsByName("idx")[0].value,t="https://freshrimpsushi.github.io/jp/posts/"+e;location.replace(t)};document.addEventListener("keydown",function(e){const n=document.getElementById("navigator");if(e.altKey&&e.ctrlKey&&e.key==="l"){e.preventDefault();var t=document.querySelector("#mirror-link a");t?t.click():console.log("거울 링크를 찾지 못했습니다.")}})</script></aside></footer></body><script async src="https://www.googletagmanager.com/gtag/js?id=G-NLV8Y9PRK1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NLV8Y9PRK1")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4751085325232621" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/sweetalert2@11></script><script src=https://freshrimpsushi.github.io/jp/js/fontawsome.min.js></script><script src=https://freshrimpsushi.github.io/jp/js/common.js></script><script>document.addEventListener("DOMContentLoaded",()=>{fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/ip_checker.php";return postFetch(t,{user_ip:e})}).then(e=>e.json()).then(e=>{e.ok||(alert(`차단된 IP입니다.
Contact:
freshrimpsushi@gmail.com`),window.location.href="https://google.com")}).catch(e=>console.error(e))})</script></html>