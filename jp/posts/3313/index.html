<!doctype html><html class=blog lang=jp><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link rel=preload href=https://freshrimpsushi.github.io/jp/css/style.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=preload href=https://freshrimpsushi.github.io/jp/css/comment.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=icon href=https://freshrimpsushi.github.io/ko/logo/favicon.ico><meta name=msapplication-TileColor content="#FFFFFF"><meta name=msapplication-TileImage content="logo/basic.png"><meta name=NaverBot content="All"><meta name=NaverBot content="index,follow"><meta name=Yeti content="All"><meta name=Yeti content="index,follow"><meta name=google-site-verification content="KYAokS7-6C5YuXOjatJQsiK1T0O8x4YncYFIF4tneYI"><meta name=naver-site-verification content="e5651d6f97899061897203413efc84994f04bbba"><link rel=alternate type=application/rss+xml title=生エビ寿司屋 href=https://freshrimpsushi.github.io/jp/index.xml><title>論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)</title></head><meta name=title content="論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)"><meta name=description content="국내 최대의 수학, 물리학, 통계학 블로그"><meta property="og:title" content="論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)"><meta property="og:description" content><meta property="og:image" content="https://freshrimpsushi.github.io/jp/logo/basic.png/"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"j_","name":"論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)","headline":"論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)","alternativeHeadline":"","description":"概要 レファレンスと数式の番号や表記法は、論文をそのまま踏襲する。 Physics-informed neural networks (PINN[ピン]と読む)は、数値的に解くために設計された微分方程式の","inLanguage":"jp","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/freshrimpsushi.github.io\/jp\/posts\/3313\/"},"author":{"@type":"Person","name":"전기현","url":"https://math.stackexchange.com/users/459895/ryu-dae-sick"},"creator":{"@type":"Person","name":"전기현"},"accountablePerson":{"@type":"Person","name":"전기현"},"copyrightHolder":"生エビ寿司屋","copyrightYear":"2022","dateCreated":"2022-10-19T00:00:00.00Z","datePublished":"2022-10-19T00:00:00.00Z","dateModified":"2022-10-19T00:00:00.00Z","publisher":{"@type":"Organization","name":"生エビ寿司屋","url":"https://freshrimpsushi.github.io/jp/","logo":{"@type":"ImageObject","url":"https:\/\/freshrimpsushi.github.io\/jp\/logo\/basic.png","width":"32","height":"32"}},"image":"https://freshrimpsushi.github.io/jp/logo/basic.png","url":"https:\/\/freshrimpsushi.github.io\/jp\/posts\/3313\/","wordCount":"9033","genre":[],"keywords":[]}</script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/mhchem.min.js integrity=sha384-F2ptQFZqNJuqfGGl28mIXyQ5kXH48spn7rcoS0Y9psqIKAcZPLd1NzwFlm/bl1mH crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>function renderKaTex(e){renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],trust:!0,trust:e=>["\\htmlId","\\href","\\includegraphics"].includes(e.command),macros:{"\\eqref":"(\\text{#1})","\\ref":"\\href{###1}{\\text{#1}}","\\label":"\\htmlId{#1}{}","\\sech":"\\operatorname{sech}","\\csch":"\\operatorname{csch}","\\sgn":"\\operatorname{sgn}","\\sign":"\\operatorname{sign}","\\sinc":"\\operatorname{sinc}","\\diag":"\\operatorname{diag}","\\diam":"\\operatorname{diam}","\\trace":"\\operatorname{trace}","\\Tr":"\\operatorname{Tr}","\\tr":"\\operatorname{tr}","\\re":"\\operatorname{Re}","\\im":"\\operatorname{Im}","\\Var":"\\operatorname{Var}","\\Poi":"\\operatorname{Poi}","\\Cov":"\\operatorname{Cov}","\\span":"\\operatorname{span}","\\supp":"\\operatorname{supp}","\\rank":"\\operatorname{rank}","\\nullity":"\\operatorname{nullity}","\\ad":"\\operatorname{ad}","\\Ric":"\\operatorname{Ric}","\\i":"\\mathrm{i}","\\d":"\\mathrm{d}","\\cR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5863.png}","\\acR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.4371.png}","\\bcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5899.png}","\\abcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.0596.png}","\\crH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\smallcrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\acrH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}","\\smallacrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}"},throwOnError:!1})}</script><body class=main><header><a href=https://freshrimpsushi.github.io/jp/ rel=home><p style=text-align:center;font-size:1rem;color:#000><img src=https://freshrimpsushi.github.io/jp/logo/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.png style=height:80px alt=logo></p></a></header><form method=get action=/jp/search style=border:1px;text-align:center><div class=field><input type=text id=searchtext placeholder=🔍︎ class=input_text name=s style=background-color:#eee;text-align:center;width:200px;font-size:1.5rem;border:1px;border-radius:5px;padding-top:5px;padding-bottom:5px;margin-bottom:1.5rem></div></form><aside style=text-align:center;margin-bottom:1rem><a href=https://freshrimpsushi.github.io/ko//posts/3313/>한국어</a> |
<a href=https://freshrimpsushi.github.io/en//posts/3313/>English</a> |
<a href=https://freshrimpsushi.github.io/jp//posts/3313/>日本語</a></aside><div class=wrapper><div class=content><div class=content-box><title>論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)</title>
<a href=https://freshrimpsushi.github.io/jp/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/ style=background-color:rgba(0,0,0,.8);color:orange;border-radius:10px;padding:5px>📂機械学習</a><h1>論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)</h1><aside><div class=innerheader><div class=innertoc><b>目次</b><nav id=TableOfContents><ul><li><a href=#概要>概要</a><ul><li><a href=#実装>実装</a></li></ul></li><li><a href=#0-抄録>0. 抄録</a></li><li><a href=#1-序論>1. 序論</a></li><li><a href=#2-問題設定>2. 問題設定</a></li><li><a href=#3-偏微分方程式のデータ駆動ソリューション>3. 偏微分方程式のデータ駆動ソリューション</a><ul><li><a href=#31-連続時間モデル>3.1. 連続時間モデル</a></li><li><a href=#32-離散時間モデル>3.2. 離散時間モデル</a></li></ul></li><li><a href=#4-偏微分方程式のデータ駆動発見>4. 偏微分方程式のデータ駆動発見</a><ul><li><a href=#41-連続時間モデル>4.1. 連続時間モデル</a></li></ul></li><li><a href=#5-結論>5. 結論</a></li></ul></nav></div></div></aside><h2 id=概要>概要</h2><ul><li>レファレンスと数式の番号や表記法は、論文をそのまま踏襲する。</li></ul><p>Physics-informed neural networks (PINN<sup>[ピン]と読む</sup>)は、<a href=../../categories/%E6%95%B0%E5%80%A4%E8%A7%A3%E6%9E%90/>数値的に解くために</a>設計された微分方程式の人工ニューラルネットワークであり、2018年Journal of Computational Physicsに発表された論文<a href=https://www.sciencedirect.com/science/article/pii/S0021999118307125>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations</a>で紹介されました。この論文の著者は、応用数学、機械工学のM. Raissi, P. Perdikaris, G.E. Karniadakisです。</p><p>この論文で述べられている<strong>物理情報</strong><sup>physics information</sup>は、壮大に見えるかもしれませんが、実際には与えられた<strong>微分方程式</strong>自体を意味すると考えても良いでしょう。つまり、&lsquo;微分方程式を人工ニューラルネットワークで解く際、与えられた微分方程式を利用します&rsquo;と言っているのと同じです。機械学習の論文を読むときは、このように<strong>見栄えの良い</strong>名前に惑わされないよう注意が必要です。</p><p>微分方程式の数値的解法においてPINNが注目される理由は、損失関数に関するアイデアがシンプルで理解しやすく、実装も簡単だからでしょう。実際に論文の例では非常にシンプルなDNNが紹介されています。</p><p>一般的に言われるPINNはSection 3.1で紹介されるモデルを指します。</p><h3 id=実装>実装</h3><ul><li><a href=../1967>PyTorchパイトチ</a></li></ul><h2 id=0-抄録>0. 抄録</h2><p>著者はPINNを&rsquo;与えられた非線形偏微分方程式を満たしながら、教師あり学習問題を解くために訓練された人工ニューラルネットワーク&rsquo;と紹介しています。この論文で主に扱う2つの問題は、&lsquo;data-driven solution and data-driven discovery of partial differential equations&rsquo;です。性能評価のために、流体力学、量子力学、拡散方程式などの問題を解いてみました。</p><h2 id=1-序論>1. 序論</h2><p>最近の機械学習とデータ分析の進歩は、画像認識<sup>image recognition</sup>、認知科学<sup>cognitive science</sup>、ゲノム学<sup>genomics</sup>などの科学分野で革新的な結果をもたらしていますが、複雑な物理的、生物学的、工学的システムに対しては（データ収集コストが高いため）少ない情報で望ましい結果を導き出す必要がある困難があります。このような*小さなデータ領域<sup>small data regime</sup>*では、DNN、CNN、RNNなどの先進技術の収束性が保証されていません。</p><p>[4-6]で、データ効率が良く（=少ないデータで）、物理情報を学習できる（=微分方程式を解くことができる）方法についての研</p><p>究が進んでいます。非線形問題への拡張は、この論文の著者であるRaissiの後続研究[8,9]で提案されました。</p><h2 id=2-問題設定>2. 問題設定</h2><p>人工ニューラルネットワークで表される関数は、入力値（偏微分方程式でのソリューション$u$の座標$x, t$を指す）とパラメータによって関数値が決定されるが、これら2種類の変数に対して微分を行うために<strong>自動微分</strong><sup>automatic differentiation</sup>を活用する。</p><blockquote><p>このようなニューラルネットワークは、観測されたデータを支配する物理法則に起因する任意の対称性、不変性、または保存原理を尊重するように制約されている。これは、一般的な時間依存かつ非線形の偏微分方程式によってモデル化される。</p></blockquote><p>この論文でこの文章が難しいと感じられるかもしれないが、私の考えでは簡単に言えば提案された人工ニューラルネットワークであるPINNが、与えられた微分方程式を満たす必要があるということだ。後述するが、微分方程式を満たす必要があるという条件を損失関数として使用するためである。</p><p>この論文の目的は、数理物理学におけるディープラーニングを進化させる新しいパラダイムのモデリングと計算パラダイムを提示することである。そのために、前述したように、この論文では主に2つの問題を扱う。一つは偏微分方程式の<strong>データ駆動ソリューション</strong><sup>data-driven solution</sup>であり、もう一つは偏微分方程式の<strong>データ駆動発見</strong><sup>data-driven discovery</sup>である。使用された全てのコードとデータセットはhttps://github.com/maziarraissi/PINNsで確認できる。この論文では、$L1$、$L2$、<a href=../1004>ドロップアウト</a>などの<a href=../1807>正則化</a>なしに、ハイパーボリックタンジェントを<a href=../991>活性化関数</a>として用いたシンプルなMLPが使用されている。各例では、ニューラルネットワークの構造、オプティマイザー、<a href=../987>学習率</a>などが具体的に紹介される。</p><p>この論文では、以下のようなパラメータ化された非線形偏微分方程式の一般的な形<sup>parameterized and nonlinear partial differential equations of the general form</sup>を扱う。</p><p>$$
\begin{equation}
u_{t} + \mathcal{N}[u; \lambda] = 0,\quad x \in \Omega,\quad t \in [0,T]
\end{equation}
$$</p><p>ここで、$u=u(t,x)$は(1)を満たす隠れた<sup>(=与えられていない=知られていない)</sup>関数、つまり(1)のソリューションであり、$\mathcal{N}[\cdot; \lambda]$は$\lambda$でパラメータ化された非線形演算子（NonlinearのNに由来する）であり、$\Omega \subset \mathbb{R}^{D}$である。多くの数理物理学の問題<sup>problems in mathematical physics</sup>は上記のような形で表される。例えば、1次</p><p>元粘性<a href=../532>バーガース方程式</a>を見てみよう。</p><p>$$
u_{t} + uu_{x} = \nu u_{xx}
$$</p><p>これは(1)で$\mathcal{N}[u; \lambda] = \lambda_{1} uu_{x} - \lambda_{2}u_{xx}$、$\lambda = (\lambda_{1}, \lambda_{2})$の場合である。与えられた方程式(1)に対して、扱うべき2つの問題はそれぞれ以下の通りである。</p><ul><li><strong>偏微分方程式のデータ駆動ソリューション:</strong> 固定された$\lambda$に対して、システムのソリューション$u(t,x)$は何か？</li><li><strong>偏微分方程式のデータ駆動発見:</strong> 観測されたデータを最もよく表現するパラメータ$\lambda$は何か？</li></ul><h2 id=3-偏微分方程式のデータ駆動ソリューション>3. 偏微分方程式のデータ駆動ソリューション</h2><p>セクション3では、以下の形式の偏微分方程式からデータに基づいたソリューションを見つける問題について扱う。</p><p>$$
\begin{equation}
u_{t} + \mathcal{N}[u] = 0,\quad x \in \Omega,\quad t \in [0,T]
\end{equation}
$$</p><p>つまり、$(1)$でパラメータ $\lambda$ が固定されている状況である。セクション3.1とセクション3.2ではそれぞれ連続時間モデルと離散時間モデルを扱う。方程式を見つける問題はセクション4で扱う。ここで言う&rsquo;データ&rsquo;の意味は以下で詳しく説明する。</p><h3 id=31-連続時間モデル>3.1. 連続時間モデル</h3><p>$(t,x) \in \mathbb{R} \times \mathbb{R}$ とすると、$u : \mathbb{R}^{2} \to \mathbb{R}$ である。これを人工ニューラルネットワークで近似するが、次のように実装されるシンプルなMLPを使用する。Juliaでは、</p><pre tabindex=0><code>using Flux

u = Chain(
    Dense(2, 10, relu),
    Dense(10, 10, relu),
    Dense(10, 1)
    )
</code></pre><p>PyTorchでは、</p><pre tabindex=0><code>import torch
import torch.nn as nn
import torch.nn.functional as F

layers = [2, 10, 10, 1]

class network(nn.Module):
    def __init__(self):
        super(network, self).__init__()
        layer_list = [nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)]
        self.linears = nn.ModuleList(layer_list)
        
    def forward(self, tx):
        u = tx

        for i in range(len(layers)-2):
            u = self.linears[i](u)
            u = F.relu(u)

        u = self.linears[-1](u)
        
        return u

u = network()
</code></pre><p>これで $u$ は入力ノードが $2$ つ、出力ノードが $1$ つの人工ニューラルネットワークとなる。$(2)$ の左辺を次のような関数 $f = f(t,x; u)$ として定義しよう。</p><p>$$
\begin{equation}
f := u_{t} + \mathcal{N}[u]
\end{equation}
$$</p><p>ここで $u$ は人工ニューラルネットワークであるため、$f$ も隠れ層のパラメータを持つ一種の人工ニューラルネットワークである。上記のような $f$ を<strong>物理情報に基づいたニューラルネットワーク</strong><sup>physics-informed neural network, PINN</sup>と呼ぶ。言い換えれば、<strong>与えられた偏微分方程式そのもの</strong>である。$f$ に含まれる微分は自動微分で実装され、$u$ と同じパラメータを共有する。人工ニューラルネットワーク $u$ が $(2)$ のソリューションを適切に近似していれば、$f$ の関数値はどこでも $0$ であるべきだ。ここから、$ f \to 0$ になるように人工ニューラルネットワークを学習させることが推測できる。</p><p>$(t_{u}^{i}, x_{u}^{i})$ を初期値、境界値が定義された領域の点とする。</p><p>$$
(t_{u}^{i}, x_{u}^{i}) \in( \Omega \times \left\{ 0 \right\}) \cup (\partial \Omega \times [0, T])
$$</p><p>$u_{\ast}$ を実際のソリューションとすると、初期条件と境界条件が与えられたということは、次のような値が与えられたということと同じである。</p><p>$$
\left\{ t_{u}^{i}, x_{u}^{i}, u^{i} \right\}_{i=1}^{N_{u}},\quad u^{i} = u_{\ast}(t_{u}^{i}, x_{u}^{i})
$$</p><p>理論上はこれらの値を無限に持つことになるが、数値的な問題では有限の点のみを扱えるので、$N_{u}$ 個を持っているとする。人工ニューラルネットワーク $u$ は $(t_{u}^{i}, x_{u}^{i})$ を入力として受け取り、$u^{i}$ を出力する必要があるので、これらがそれぞれ入力と対応するラベルとなる。</p><p>$$
\text{input} = (t_{u}^{i}, x_{u}^{i}),\qquad \text{label} = u^{i}
$$</p><p>これがPINNで学習する<b>&lsquo;データ&rsquo;</b>である。それでは、損失関数を次のように設定できる。</p><p>$$
MSE_{u} = \dfrac{1}{N_{u}} \sum\limits_{i=1}^{N_{u}} \left| u(t_{u}^{i},x_{u}^{i}) - u^{i} \right|^{2}
$$</p><p>また、$f$は適切な点集合（理論的には解 $u_{\ast}$ が定義されるすべての点で満たされるべきだが、数値的には有限の点しか扱えない）$\left\{ t_{f}^{i}, x_{f}^{i} \right\}_{i=1}^{N_{f}}$で$(2)$を満たさなければならない。これらの適切な点を論文では<strong>コロケーションポイント</strong><sup>collocation points</sup>と呼ぶ。コロケーションポイントに対して以下の損失関数を設定する。</p><p>$$
MSE_{f} = \dfrac{1}{N_{f}}\sum\limits_{i=1}^{N_{f}} \left| f(t_{f}^{i}, x_{f}^{i}) \right|^{2}
$$</p><p>つまり、$MSE_{f}$が$0$に近づくことは、物理的情報（偏微分方程式）を満たすことを意味する。したがって、人工ニューラルネットワーク $u$ を訓練するための最終的な損失関数は以下の通りである。</p><p>$$
MSE = MSE_{u} + MSE_{f}
$$</p><p>論文では、$MSE_{f}$を使用することで物理的情報を制約として設けることは、[15, 16]で初めて研究されたが、PINN論文ではこれを現代的な計算ツールで検討し、より困難なダイナミックシステムに適用したと説明されている。</p><p><strong>物理情報に基づく機械学習</strong><sup>physics-informed machine learning</sup>という用語自体は、Wangの乱流モデリング<sup>turbulence modeling</sup>に関する研究[17]で初めて使用されたとされる。しかし、PINN以前の研究では、<a href=../2402>サポートベクターマシン</a>、ランダムフォレスト、FNNなどの機械学習アルゴリズムが単に使用されていたと説明されている。PINNがこれらと区別される点は、一般的に機械学習に使用されるパラメータに対する微分だけでなく、解の座標 $x, t$ に関する微分も考慮している点である。つまり、パラメータ $w$ を持つ人工ニューラルネットワークで近似された解を $u(t,x; w)$ とするとき、以前に提案された方法は偏微分 $u_{w}$ のみを利用したが、PINNは $u_{t}$ や $u_{x}$ などを利用して解を求める。このようなアプローチにより、少量のデータでも解をうまく見つけることができると説明されている。</p><blockquote><p>この手続きがグローバル最小値に収束するという理論的な保証はないにもかかわらず、与えられた偏微分方程式が適切に定義されており、その解が一意であり、十分に表現力のあるニューラルネットワークアーキテクチャと十分な数のコロケーションポイント $N_{f}$ が与えられている場合、我々の方法は良好な</p></blockquote><p>予測精度<sup>good prediction accuracy</sup>を達成することが経験的に確認されていると論文には述べられている。</p><h4 id=311-例シュレーディンガー方程式>3.1.1. 例（シュレーディンガー方程式）</h4><p>この例では、周期的な境界条件と複素数値を取る解に対して、提案された方法がうまく機能するかを重点的に確認する。例として、以下の初期条件と境界条件が与えられる<a href=../1598>シュレーディンガー方程式</a>を扱う。</p><p>$$
\begin{align*}
ih_{t} + 0.5h_{xx} + \left| h \right|^{2}h &= 0,\quad x\in [-5, 5], t\in[0, \pi/2], \\
h(0,x) &= 2\operatorname{sech} (x), \\
h(t,-5) &= h(t,5), \\
h_{x}(t,-5) &= h_{x}(t,5)
\end{align*}
$$</p><p>問題の解 $h_{\ast}(t,x)$ は $h_{\ast} : [0, \pi/2] \times [-5, 5] \to \mathbb{C}$ として複素関数値を持つ。しかし、関数の出力が複素数になるように人工ニューラルネットワークを定義するのではなく、実部を担当する $u(t,x)$ と虚部を担当する $v(t,x)$ の2次元ベクトルが出力されるように定義する。簡単に言えば、入力と出力のノードがそれぞれ2つのMLPとして定義することである。</p><p>$$
h(t,x) = \begin{bmatrix} u(t,x) \\[0.5em] v(t,x) \end{bmatrix}
$$</p><p>この問題におけるPINN $f$ は以下の通りである。</p><p>$$
f := ih_{t} + 0.5h_{xx} + \left| h \right|^{2} h
$$</p><p>$h(t,x)$ と $f(t,x)$ のパラメータは、初期値に対する損失 $MSE_{0}$、境界値に対する損失 $MSE_{b}$、物理情報に対する損失 $MSE_{f}$ を最小化するように学習される。</p><p>$$
MSE = MSE_{0} + MSE_{b} + MSE_{f}
$$</p><p>$$
\begin{align*}
\text{where } MSE_{0} &= \dfrac{1}{N_{0}}\sum_{i=1}^{N_{0}} \left| h(0, x_{0}^{i}) - h_{0}^{i} \right|^{2} \quad (h_{0}^{i} = 2\operatorname{sech} (x_{0}^{i})) \\
MSE_{b} &= \dfrac{1}{N_{b}}\sum_{i=1}^{N_{b}} \left( \left| h(t_{b}^{i}, -5) - h(t_{b}^{i}, 5) \right|^{2} + \left| h_{x}(t_{b}^{i},-5) - h_{x}(t_{b}^{i},5) \right|^{2} \right) \\
MSE_{f} &= \dfrac{1}{N_{f}} \sum\limits_{i=1}^{N_{f}} \left| f(t_{f}^{i}, x_{f}^{i}) \right|^{2}
\end{align*}
$$</p><ul><li>論文には $MSE_{b}$ の式にタイプミスがあるので注意すること。</li></ul><p>ここで、$\left\{ x_{0}^{i}, h_{0}^{i} \right\}_{i=1}^{N_{0}}$ は初期値データ、$\left\{ t_{b}^{i} \right\}_{i=1}^{N_{b}}$ は境界でのコロケーションポイント、$\left\{ t_{f}^{i}, x_{f}^{i} \right\}_{i=1}^{N_{f}}$ は $f$ に対するコロケーションポイントである。</p><p>データセットを生成するために、従来のスペクトルメソッド<sup>spectral methods</sup>を使用した。$h(0,x)$ での初期値データの数は $N_{0} = 50$、境界値データの数は $N_{b} = 50$ とし、ランダムに選んだ。また、$f$ のコロケーションポイントの数は $N_{f} = 20,000$ である。人工ニューラルネットワークは、100個のノードを持つ線形層を5層、層間の活性化関数としてハイパーボリックタンジェント $\tanh$ を使用して構築した。</p><p><img src=figure1.png#center alt=figure1.png></p><p align=middle>Figure 1.</p><p>Figure 1では、上の図は予測された解 $\left| h(t, x) \right|$ のヒートマップを示している。下の図は、時間がそれぞれ $t = 0.59, 0.79, 0.98$ のときの予測された解と実際の解がどれだけ一致しているかを示している。相対的 $L_{2}$ ノルム<sup>relative $L_{2}$-norm</sup> は $0.00197 = 1.97 \cdot 10^{-3}$ で、予測された解が正確な解と比較して約 $0.02%$ の差異があることを意味している。したがって、PINNは少ない初期値データでシュレーディンガー方程式の非線形挙動を正確に捉えることができる。</p><p>現在扱っている連続時間モデルは、初期値が少なくてもうまく機能するが、コロケーションポイントの数 $N_{f}$ が十分に多くなければならないという潜在的な制約がある。これは空間の次元が2以下の場合はあまり問題にならないが、高次元の場合、必要なコロケーションポイントの数が指数関数的に増加する可能性があるため、問題になる可能性がある。そのため、次のセクションでは、多くのコロケーションポイントを必要としないようにするために、古典的なルンゲ・クッタ時間ステップスキームを活用した、より構造化されたニューラルネットワークを提案する。</p><h3 id=32-離散時間モデル>3.2. 離散時間モデル</h3><p>セクション3.1では、解を連続時間に対して近似した。この場合、人工ニューラルネットワークは全体の領域に対して同時に学習され、任意の点 $(x,t)$ に対して出力がある。このセクションでは、セクション3.1とは異なり、離散時間について扱う。つまり $t_{n}$ の値を知っているとき、$t_{n+1}$ の値を人工ニューラルネットワークで近似する方法について説明する。$(2)$ に $q$ ステージの<a href=../3319>ルンゲ・クッタ法</a>を適用すると、以下のようになる。</p><p>$$
u(t_{n+1}, x) = u(t_{n}, x) - \Delta t \sum_{j=1}^{q} b_{j}\mathcal{N}\left[ u(t_{n}+c_{j} \Delta t, x) \right]
$$</p><p>ここで $u^{n}(x) = u(t_{n}, x)$, $u^{n+c_{j}} = u(t_{n} + c_{j}\Delta t, x)$ と表記すると、</p><p>$$
\begin{equation}
\begin{aligned}
u^{n+1} &= u^{n} - \Delta t \sum_{j=1}^{q} b_{j}\mathcal{N}\left[ u^{n+c_{j}}\right] \\
\text{where } u^{n+c_{j}} &= u^{n} - \Delta t \sum_{i=1}^{q} a_{j,i}\mathcal{N}\left[ u^{n+c_{i}}\right] \quad j=1,\dots,q
\end{aligned}\tag{7}
\end{equation}
$$</p><p>上記の $q+1$ 個の式で、右辺の $\sum$ 項を全て左辺に移行する。そして、左辺を $u_{i}^{n}$ のように表記する。</p><p>$$
\begin{equation}
\begin{aligned}
u_{q+1}^{n} &:= u^{n+1} + \Delta t \sum_{j=1}^{q} b_{j}\mathcal{N}\left[ u^{n+c_{j}}\right] = u^{n} \\
\\
u_{1}^{n} &:= u^{n+c_{1}} + \Delta t \sum_{i=1}^{q} a_{1,i}\mathcal{N}\left[ u^{n+c_{i}}\right] = u^{n} \\
u_{2}^{n} &:= u^{n+c_{2}} + \Delta t \sum_{i=1}^{q} a_{2,i}\mathcal{N}\left[ u^{n+c_{i}}\right] = u^{n} \\
&\vdots \\
u_{q}^{n} &:= u^{n+c_{q}} + \Delta t \sum_{i=1}^{q} a_{q,i}\mathcal{N}\left[ u^{n+c_{i}}\right] = u^{n}
\end{aligned}\tag{9}
\end{equation}
$$</p><p>すると、これらの全ての値が $u^{n}$ に等しくなることがわかる。</p><p>$$
u^{n} = u_{1}^{n} = u_{2}^{n} = \cdots = u_{q+1}^{n}
\tag{8}
$$</p><p>したがって、セクション3.2で言及されている物理情報とは、与えられた初期条件・境界条件と $(8)$ を指す。今度は $u(t_{n+1}, x)$ を求めるために二つの人工ニューラルネットワークを定義する。セクション3.1で使用した人工ニューラルネットワークは、正確な解 $u_{\ast}$ に収束することを期待する $u$ と、$u$ が満たすべき微分方程式 $f$ だったが、ここでは少し異なる。まず、人工ニューラルネットワーク $U$ を次の関数として定義する。</p><p>$$
U : \mathbb{R} \to \mathbb{R}^{q+1}
$$</p><p>つまり、入力層のノードが $1$ つ、出力層のノードが $q+1$ つのニューラルネットワークである。このニューラルネットワークの出力を以下の値とする。</p><p>$$
U(x) = \begin{bmatrix}
u^{n+c_{1}}(x) \\[0.5em]
u^{n+c_{2}}(x) \\
\vdots \\[0.5em]
u^{n+c_{q}}(x) \\[0.5em]
u^{n+1}(x)
\end{bmatrix}
\tag{10}
$$</p><p>このニューラルネットワークは、添付されたコード内の <code>PhysicsInformedNN</code> クラスで定義されている <code>neural_net</code> に該当する。</p><p>つまり、以下の学習プロセスで $U$ の出力の最後の成分が $u(t_{n+1}, x)$ に収束することを期待している。二番目のニューラルネットワークは、$U$ の出力と $(7)$ の定義を利用して、次のように定義される関数である。</p><h4 id=321-例アレンカーン方程式>3.2.1. 例（アレン・カーン方程式）</h4><p>離散時間モデルにおける例として、以下の初期条件と周期的な境界条件が与えられるアレン・カーン方程式を取り上げる。</p><p>$$
\begin{equation}
\begin{aligned}
&amp;u_{t} - 0.0001u_{xx} + 5 u^{3} - 5u = 0,\qquad x\in [-1, 1], t\in[0, 1], \\
&amp;u(0,x) = x^{2} \cos (\pi x), \\
&amp;u(t,-1) = u(t,1), \\
&amp;u_{x}(t,-1) = u_{x}(t,1)
\end{aligned}\tag{12}
\end{equation}
$$</p><p>この例における $(9)$ に含まれる非線形演算子は以下の通りである。</p><p>$$
\mathcal{N}[u^{n+c_{j}}] = -0.0001u_{xx}^{n+c_{j}} + 5(u^{n+c_{j}})^{3} - 5u^{n+c_{j}}
$$</p><p>タイムステップ $t^{n}$ での $u$ の値を $u^{n,i}$ と表記する。</p><p>$$
u^{n,i} = u^{n}(x^{n,i}) = u(t^{n}, x^{n,i}),\qquad i=1,\dots,N_{n}
$$</p><p>問題は $u^{n}$ が与えられたときに $u^{n+1}$ を計算することであり、$\left\{ x^{n,i}, u^{n,i} \right\}_{i=1}^{N_{n}}$ は与えられたデータセットである。$(8)$ により、このデータセットに対して以下が成り立つ。</p><p>$$
u^{n,i} = u_{1}^{n}(x^{n,i}) = \cdots = u_{q+1}^{n}(x^{n,i})
$$</p><p>したがって、以下のような二乗誤差の合計<sup>sum of squared error (SSE)</sup>を損失関数とする。</p><ul><li>ここではなぜ $MSE$ ではなく $SSE$ を使用するのかは明確ではない。連続時間モデルでは $MSE$ を使用していたが、離散時間モデルでは $SSE$ を使用しており、何らかの実験的な理由があると思われる。</li></ul><p>$$
SSE_{n} = \sum\limits_{j=1}^{q+1} \sum\limits_{i=1}^{N_{n}} \left| u_{j}^{n} (x^{n,i}) - u^{n,i} \right|^{2}
$$</p><p>各 $u_{j}^{n}$ は $(9)$ によって計算され、この計算にはニューラルネットワーク $U$ の出力が使用される。このロスは、添付されたコード内の <code>PhysicsInformedNN</code> クラスで定義されている <code>net_U0</code> に対応する。そして $U$ の出力は $(12)$ の境界条件を満たさなければならないため、以下のような損失関数を設定する。</p><p>$$
\begin{align*}
SSE_{b}
&= \sum\limits_{i=1}^{q} \left| u^{n+c_{i}}(-1) - u^{n+c_{i}}(1) \right|^{2} + \left| u^{n+1}(-1) - u^{n+1}(1) \right|^{2} \\
&\quad+ \sum\limits_{i=1}^{q} \left| u_{x}^{n+c_{i}}(-1) - u_{x}^{n+c_{i}}(1) \right|^{2} + \left| u_{x}^{n+1}(-1) - u_{x}^{n+1}(1) \right|^{2} \
\end{align*}
$$</p><p>これらの合計が最終的なロスである。</p><p>$$
SSE = SSE_{n} + SSE_{b}
$$</p><p><img src=figure2.png#center alt=figure2.png></p><p align=middle>Figure 2.</p><p>Fig. 2では、上の図が正確な解のヒートマップを示している。下の図では、$t=0.1$ での $u$ を知っているときに $t=0.9$ での値を予測した結果を示している。下の左側の図では、青い線が正確な解であり、$\color{red}\mathsf{X}$ がデータとして使用された点を示している。下の右側の図では、青い線が正確な解であり、赤い線が予測された解である。</p><p><a href=../3319>暗黙のルンゲ・クッタ法 (IRK)</a> では $u^{n+c_{j}}$ を計算するためにすべての $j$ に対する連立方程式を解く必要があるため、$q$ が大きくなると計算コストが大幅に増加するが、この論文で提案されている方法では $q$ が大きくなってもそれに伴う追加コストは非常に少ないと説明されている。また、$q$ が小さい場合、IRK ではタイムステップ $\Delta t$ が大きいと正確な予測ができないが、PINN の場合は $\Delta t$ が大きくても正確に予測できると説明されている。</p><h2 id=4-偏微分方程式のデータ駆動発見>4. 偏微分方程式のデータ駆動発見</h2><p>この章では、観測データがある場合に、偏微分方程式 $(1)$ のパラメータ $\lambda$ を見つける問題について扱う。詳細は以下の例を通じて説明する。</p><h3 id=41-連続時間モデル>4.1. 連続時間モデル</h3><p>$f$ を以下のように $(1)$ の左辺として定義しよう。</p><p>$$
f = u_{t} + \mathcal{N}[u; \lambda]
$$</p><p>セクション3の $(3)$ と異なる点は、$\lambda$ が固定された定数ではなく、学習が必要な未知のパラメータになったことである。</p><h4 id=411-例ナヴィエストークス方程式>4.1.1. 例（ナヴィエ–ストークス方程式）</h4><p>セクション4.1.1では、非圧縮性流体の実際のデータに関する例として、ナヴィエ–ストークス方程式によって表されるケースを紹介する。以下の2次元ナヴィエ–ストークス方程式を考える。</p><p>$$
\begin{equation}
\begin{aligned}
u_{t} + \lambda_{1}(uu_{x} + vu_{y}) &= -p_{x} + \lambda_{2}(u_{xx} + u_{yy}) \\
v_{t} + \lambda_{1}(uv_{x} + vv_{y}) &= -p_{y} + \lambda_{2}(v_{xx} + v_{yy})
\end{aligned}
\tag{15}
\end{equation}
$$</p><p>ここで、$u(t,x,y)$ は流体の速度ベクトルの $x$ 成分、$v(t,x,y)$ は $y$ 成分である。また、$p(t,x,y)$ は圧力、$\lambda = (\lambda_{1}, \lambda_{2})$ は未知のパラメータである。ナヴィエ–ストークス方程式の解は<a href=../1777>発散</a>が $0$ となる条件を満たすため、以下が成立する。</p><p>$$
\begin{equation}
u_{x} + v_{y} = 0 \tag{17}
\end{equation}
$$</p><p>ある潜在関数 $\psi (t, x, y)$ に対して、以下のように仮定する。</p><p>$$
u = \psi_{y},\quad v = -\psi_{x}
$$</p><p>つまり、流体の速度ベクトルを $\begin{bmatrix} \psi_{y} & -\psi_{x}\end{bmatrix}$ とすると、$u_{x} + v_{y} = \psi_{yx} - \psi_{xy} = 0$ であるため、自然に $(17)$ を満たす。$u$ と $v$ を個別に求めるのではなく、$\psi$ を人工ニューラルネットワークで近似し、その偏微分によって $u, v$ を得る。実際の速度ベクトル場に対して、以下のように測定された情報があるとする。</p><p>$$
\left\{ t^{i}, x^{i}, y^{i}, u^{i}, v^{i} \right\}_{i=1}^{N}
$$</p><p>これに基づいて損失関数を以下のようにする。ここで、$u = \phi_{y}$, $v = -\psi_{x}$ であることを思い出す。</p><p>$$
\dfrac{1}{N} \sum\limits_{i=1}^{N} \left( \left| u(t^{i}, x^{i}, y^{i}) - u^{i} \right|^{2} + \left| v(t^{i}, x^{i}, y^{i}) - v^{i} \right|^{2} \right)
$$</p><p>そして、$(15)$ の右辺を左辺に定理し、それぞれを $f$ と $g$ として定義する。</p><p>$$
\begin{equation}
\begin{aligned}
f &:= u_{t} + \lambda_{1}(uu_{x} + vu_{y}) + p_{x} - \lambda_{2}(u_{xx} + u_{yy}) \\
g &:= v_{t} + \lambda_{1}(uv_{x} + vv_{y}) + p_{y} - \lambda_{2}(v_{xx} + v_{yy})
\end{aligned}\tag{18}
\end{equation}
$$</p><p>すると $f, g$ の値は $\psi$ によって以下のように表される。（$p$ もニューラルネットワークで近似する）</p><p>$$
\begin{align*}
f &= \phi_{yt} + \lambda_{1}(\psi_{y} \psi_{yx} - \psi_{x}\psi_{yy}) + p_{x} -\lambda_{2}(\psi_{yxx} + \psi_{yyy}) \\
g &= -\phi_{xt} + \lambda_{1}(-\psi_{y} \psi_{xx} + \psi_{x}\psi_{xy}) + p_{y} + \lambda_{2}(\psi_{xxx} + \psi_{xyy}) \\
\end{align*}
$$</p><p>損失関数に $f(t^{i}, x^{i}, y^{i}) = 0 = g(t^{i}, x^{i}, y^{i})$ という情報を加え、最終的に以下のようにする。</p><p>$$
\begin{aligned}
MSE &:= \dfrac{1}{N} \sum\limits_{i=1}^{N} \left( \left| u(t^{i}, x^{i}, y^{i}) - u^{i} \right|^{2} + \left| v(t^{i}, x^{i}, y^{i}) - v^{i} \right|^{2} \right) \\
&\qquad + \dfrac{1}{N} \sum\limits_{i=1}^{N} \left( \left| f(t^{i}, x^{i}, y^{i}) \right|^{2} + \left| g(t^{i}, x^{i}, y^{i}) \right|^{2} \right)
\end{aligned} \tag{19}
$$</p><p>次に、入力ノードが $3$ つ、出力ノードが $2$ つの人工ニューラルネットワークを定義する。この出力を $\begin{bmatrix} \psi (t, x, y) & p(t, x, y) \end{bmatrix}$ とする。すると、上記の損失関数を計算することができる。</p><p>ノイズがある場合とない場合のデータについて実験を行い、どちらの場合も高い精度で $\lambda_{1}, \lambda_{2}$ を予測できたことが示されている。また、圧力 $p$ に関するデータが与えられていない場合でも、人工ニューラルネットワークがパラメータと共に $p$ もかなり正確に近似できることが示された。具体的な実験設定、結果、参照解の求め方については、論文に詳しく記載されている。</p><h2 id=5-結論>5. 結論</h2><p>この論文では、与えられたデータが満たす物理法則をエンコードする能力があり、偏微分方程式で説明できる新しい種類のニューラルネットワーク構造である物理情報に基づいたニューラルネットワークを紹介した。この結果から、物理モデルに対してディープラーニングが学習できることがわかった。これは多くの物理的シミュレーションに応用可能である。</p><p>しかし、著者は提案された方法が偏微分方程式を解くための既存の方法、例えば有限要素法<sup>finite element method</sup>、スペクトル方法<sup>spectral methods</sup>などを置き換えるものだと考えるべきではないと述べている。実際に<a href=#32-discrete-time-models>セクション3.2.</a>では<a href=../796>ルンゲ・クッタ法</a>をPINNに適用している。</p><p>PINNを実装するために、どれくらいの深さのニューラルネットワークが必要か、どれくらいのデータが必要かなどのハイパーパラメータに関する問題についても、著者は解決策を提案しようとした。しかし、ある方程式で効果的な設定が他の方程式ではそうではないことが観察されたと述べている。</p><aside style=text-align:right>2022-10-19&emsp;
전기현&emsp;
<a href=../2126>🎲 3313</a></aside><script>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)",c="https://freshrimpsushi.github.io/jp/posts/3313/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script></div><aside><h2>コメント</h2><div class=area-reply><div class=list-reply></div></div><div class=write-box><div class="write-author-info box-account"><input type=hidden name=cmt_idx>
<input class=ai-author type=text placeholder=Name>
<input class=ai-password type=password maxlength=20 placeholder=Password></div><div class=write-content><textarea class=ai-content value placeholder=日本語でも構いませんが、できれば英語でお願いします style=ime-mode:active></textarea></div><button class=write-button onclick=write_comment() aria-label=send><i class='fa-solid fa-paper-plane'></i></button><aside class=tex>コメントにも $\TeX$ が適用されます。</aside></div></aside><script>let commentRows=[];const listReply=document.querySelector(".list-reply");document.addEventListener("DOMContentLoaded",()=>{get_all_comment()});function get_all_comment(){fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=getAllComment";return postFetch(t,{board_idx:"3313",user_ip:e})}).then(e=>e.json()).then(e=>{e.ok&&(commentRows=e.rows,render_comment(commentRows))}).catch(e=>console.error(e))}function render_comment(e){const n=["류대식","전기현","ㅇㅇ","질문"],s=["류대식","전기현"];render_blank();let t="";e.map(e=>{t+=`<div id="comment${e.cmt_idx}" class="parents">`,t+=`<div class="content-info">`;let o="";e.cmt_cnt>125?o="🥇":e.cmt_cnt>25?o="🥈":e.cmt_cnt>5&&(o="🥉"),n.includes(e.author)&&(o="");let i="";e.ip_address==null?i="(-)":(ipParts=e.ip_address.split("."),i=`(${ipParts[0]}.${ipParts[1]})`),s.includes(e.author)&&(i=""),t+=`<div class="list-author">${o} ${e.author} ${i}</div>`,t+=`<sup class="list-date">${e.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,e.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> 管理者の承認を待っています</div>`);let a=e.content;a=a.replace(/\n/g,"<br />"),t+=`<div class="content-text">${a} <span class="re-comment-button" onclick="re_comment('${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`,e.child.map(o=>{let c="child";e.ip_address&&o.ip_address===e.ip_address&&(c="parentself"),t+=`<div id="comment${o.cmt_idx}" class="${c}">`,t+=`<div class="content-info">`;let i="";o.cmt_cnt>5?i="🥉":o.cmt_cnt>25?i="🥈":o.cmt_cnt>125&&(i="🥇"),n.includes(o.author)&&(i="");let a="";o.ip_address==null?a="(-)":a=`(${o.ip_address})`,s.includes(o.author)&&(a=""),t+=`<div class="list-author">${i} ${o.author} ${a}</div>`,t+=`<sup class="list-date">${o.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,o.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> 管理者の承認を待っています</div>`);let r=o.content;r=r.replace(/\n/g,"<br />"),t+=`<div class="content-text">${r} <span class="re-comment-button" onclick="re_comment('${o.cmt_idx}', '${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`})}),listReply.innerHTML=t,renderKaTex(listReply),location.href.indexOf("#")!=-1&&(location.href=location.href.substr(location.href.indexOf("#")))}function render_blank(){listReply.innerHTML=""}function write_comment(){const e=document.querySelector(".ai-author"),t=document.querySelector(".ai-password"),n=document.querySelector(".ai-content"),s=e.value,o=t.value,i=n.value;if(s===""||o===""||i===""){alert("빈칸을 채워주세요");return}const a="3313",r="",c="論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeComment";return postFetch(t,{board_idx:a,board_slug:r,board_title:c,author:s.replace(/\+/g,"%2B"),password:o,content:i.replace(/\+/g,"%2B"),user_ip:e})}).then(e=>e.json()).then(s=>{s.ok?(commentRows.push(s.row),render_comment(commentRows),e.value="",t.value="",n.value=""):s.status===606?(Swal.fire(`Warning!
지속적인 도배 시도시
IP가 차단될 수 있습니다.`),e.value="",t.value="",n.value=""):s.status===607&&(alert(`지나친 댓글 도배를 확인하여
접근을 차단합니다.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}async function update_comment(e,t){const{value:n}=await Swal.fire({title:"댓글 수정",input:"password",inputPlaceholder:"글 작성 시 입력했던 패스워드를 입력하세요",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(s=>{if(s.ok){const s=document.querySelector(`#comment${e}`),o="https://freshrimpsushi.com/blog/ajax/comment.php?action=getComment";postFetch(o,{cmt_idx:e}).then(e=>e.json()).then(o=>{if(o.ok){const a=o.row,r=a.author,c=a.content;let i="";i+=`<div class="update-author-info">`,i+=`<input class="update-author" type="text" value="${r}" placeholder="이름" />`,i+=`<input class="update-password" type="password" value="${n}" placeholder="비밀번호" disabled />`,i+="</div>",i+=`<textarea class="update-content" value="" style="IME-MODE:active;">${c}</textarea>`,i+=`<input class="update_comment-button" type="submit" value="수정" onclick="update_comment_click(${e}, '${t}')" />`,i+=`<input class="update_comment-button" type="submit" value="취소" onclick="cancel_click(${e})" />`,s.innerHTML=i}}).catch(e=>console.error(e))}else Swal.fire("패스워드 일치 오류")}).catch(e=>console.error(e))}}async function delete_comment(e,t){const{value:n}=await Swal.fire({title:"댓글 삭제",text:"삭제하면 되돌릴 수 없습니다.",input:"password",icon:"warning",showCancelButton:!0,confirmButtonColor:"#3085d6",cancelButtonColor:"#d33",inputPlaceholder:"글 작성 시 입력했던 패스워드를 입력하세요",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(n=>{if(n.ok){const n="https://freshrimpsushi.com/blog/ajax/comment.php?action=deleteComment";postFetch(n,{cmt_idx:e}).then(e=>e.json()).then(n=>{Swal.fire("삭제되었습니다."),t==="parents"?commentRows=commentRows.filter(t=>t.cmt_idx!==e):t==="child"&&commentRows.map(t=>{t.child=t.child.filter(t=>t.cmt_idx!==e),t.child_cnt=t.child.length}),render_comment(commentRows)}).catch(e=>console.error(e))}else Swal.fire("패스워드 일치 오류")}).catch(e=>console.error(e))}}function update_comment_click(e,t){const i=document.querySelector(`#comment${e} .update-author`),a=document.querySelector(`#comment${e} .update-password`),r=document.querySelector(`#comment${e} .update-content`),n=i.value,s=a.value,o=r.value;(n===""||s===""||o==="")&&alert("빈칸을 채워주세요");const c="https://freshrimpsushi.com/blog/ajax/comment.php?action=updateComment";postFetch(c,{cmt_idx:e,author:n.replace(/\+/g,"%2B"),password:s,content:o.replace(/\+/g,"%2B")}).then(e=>e.json()).then(n=>{n.ok&&(Swal.fire("수정되었습니다."),t==="parents"?commentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}):t==="child"&&commentRows.map(t=>{t.cmt_idx==n.parent_cmt_idx&&t.child.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)})}),render_comment(commentRows),recentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}),render_recent_comment(recentRows))}).catch(e=>console.error(e))}function cancel_click(){render_comment(commentRows)}function re_comment(e,t){const s=document.querySelector(`#comment${e} .re-comment`);let n="";n+='<div class="re-comment-box">',n+='<div class="re-comment-author-info">',n+='<input class="re-comment-author" type="text" value="" placeholder="이름" />',n+='<input class="re-comment-password" type="password" value="" placeholder="비밀번호" />',n+="</div>",n+='<textarea class="re-comment-content" placeholder="내용" value="" style="IME-MODE:active;"></textarea>',t===void 0?n+=`<button class="write-button" onclick="re_comment_click(${e})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`:n+=`<button class="write-button" onclick="re_comment_click(${e}, ${t})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`,n+=`<button class="write-button" onclick="cancel_click(${e})" value="close"><i class='fa-solid fa-solid fa-ban'></i></button>`,n+="</div>",s.innerHTML=n}function re_comment_click(e,t){const n=document.querySelector(`#comment${e} .re-comment-author`),s=document.querySelector(`#comment${e} .re-comment-password`),o=document.querySelector(`#comment${e} .re-comment-content`),i=n.value,a=s.value,r=o.value;if(i===""||a===""||r===""){alert("빈칸을 채워주세요");return}const c="3313",l="",d="論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(n=>{const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeReComment";return postFetch(s,{board_idx:c,board_slug:l,board_title:d,cmt_idx:t===void 0?e:t,author:i.replace(/\+/g,"%2B"),password:a,content:r.replace(/\+/g,"%2B"),user_ip:n})}).then(e=>e.json()).then(i=>{i.ok?(commentRows.map(n=>{t===void 0?n.cmt_idx==e&&n.child.push(i.row):n.cmt_idx==t&&n.child.push(i.row)}),render_comment(commentRows)):i.status==606?(Swal.fire(`Warning!
지속적인 도배 시도시
IP가 차단될 수 있습니다.`),n.value="",s.value="",o.value=""):i.status===607&&(alert(`지나친 댓글 도배를 확인하여
접근을 차단합니다.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}</script></div><aside class=sidebar><aside><style>.reddot a:link{color:#67d10f;text-shadow:0 0 10px #d3d3d3;font-weight:700}.reddot a:visited{color:#f5f5f5}</style><p class=reddot style=text-align:center;margin:0><a href=https://freshrimpsushi.github.io/jp/posts/2707/>夏の特選おまかせ<br>「想像上の数」</a></p></aside><br><div class=category></div><div style=display:flex>● をクリックして、興味ある分野だけ強調。<div class=resetmute><button class="sb-btn btnReset" style=border-radius:5px;border:0>reset</button>
<button class="sb-btn btnMute" style=border-radius:5px;border:0>mute</button></div></div><script defer>const color={green:"#33cc33",yellow:"#ffcc00",red:"#ff3333",black:"#000000"},categoryRows=[[{idx:1,name:"함수",color:color.green,show:"関数",size:"146"},{idx:2,name:"보조정리",color:color.green,show:"レンマ",size:"55"},{idx:3,name:"미분적분학",color:color.green,show:"微分積分学",size:"45"},{idx:4,name:"행렬대수",color:color.green,show:"行列代数",size:"117"}],[{idx:1,name:"정수론",color:color.green,show:"整数論",size:"90"},{idx:2,name:"집합론",color:color.green,show:"集合論",size:"49"},{idx:3,name:"그래프이론",color:color.green,show:"グラフ理論",size:"65"},{idx:4,name:"선형대수",color:color.green,show:"線形代数",size:"97"},{idx:5,name:"해석개론",color:color.green,show:"解析学",size:"84"},{idx:6,name:"추상대수",color:color.green,show:"抽象代数",size:"98"},{idx:7,name:"위상수학",color:color.green,show:"位相幾何学",size:"64"},{idx:8,name:"기하학",color:color.green,show:"幾何学",size:"167"}],[{idx:1,name:"다변수벡터해석",color:color.green,show:"ベクトル分析",size:"36"},{idx:2,name:"복소해석",color:color.green,show:"複素解析",size:"71"},{idx:3,name:"측도론",color:color.green,show:"測度論",size:"53"},{idx:4,name:"푸리에해석",color:color.green,show:"フーリエ解析",size:"54"},{idx:5,name:"표현론",color:color.red,show:"表現論",size:"7"},{idx:6,name:"초함수론",color:color.green,show:"シュワルツ超函数",size:"22"},{idx:7,name:"단층촬영",color:color.green,show:"トモグラフィ",size:"20"}],[{idx:1,name:"거리공간",color:color.green,show:"距離空間",size:"38"},{idx:2,name:"바나흐공간",color:color.green,show:"バナッハ空間",size:"38"},{idx:3,name:"힐베르트공간",color:color.green,show:"ヒルベルト空間",size:"31"},{idx:4,name:"르벡공간",color:color.green,show:"ルベーグ空間",size:"33"}],[{idx:1,name:"상미분방정식",color:color.green,show:"微分方程式",size:"58"},{idx:2,name:"편미분방정식",color:color.green,show:"偏微分方程式",size:"60"},{idx:3,name:"확률미분방정식",color:color.green,show:"確率微分方程式",size:"26"}],[{idx:1,name:"줄리아",color:color.green,show:"ジュリア",size:"232"},{idx:2,name:"알고리즘",color:color.green,show:"アルゴリズム",size:"28"},{idx:3,name:"수치해석",color:color.green,show:"数値解析",size:"63"},{idx:4,name:"최적화이론",color:color.green,show:"最適化理論",size:"37"},{idx:5,name:"머신러닝",color:color.green,show:"機械学習",size:"114"},{idx:6,name:"프로그래밍",color:color.yellow,show:"プログラミング",size:"120"},{idx:7,name:"세이버메트릭스",color:color.green,show:"セイバーメトリクス",size:"232",size:"13"}],[{idx:1,name:"물리학",color:color.green,show:"物理学",size:"30"},{idx:2,name:"수리물리",color:color.green,show:"数理物理学",size:"78"},{idx:3,name:"고전역학",color:color.green,show:"古典力学",size:"48"},{idx:4,name:"전자기학",color:color.green,show:"電磁気学",size:"51"},{idx:5,name:"양자역학",color:color.green,show:"量子力学",size:"57"},{idx:6,name:"열물리학",color:color.green,show:"熱物理学",size:"29"}],[{idx:1,name:"R",color:color.green,show:"R",size:"54"},{idx:2,name:"데이터확보",color:color.green,show:"データ確保",size:"29"},{idx:3,name:"데이터과학",color:color.green,show:"データサイエンス",size:"41"},{idx:4,name:"통계적검정",color:color.green,show:"統計的検定",size:"33"},{idx:5,name:"통계적분석",color:color.green,show:"統計的分析",size:"76"},{idx:6,name:"수리통계학",color:color.green,show:"数理統計学",size:"123"},{idx:7,name:"확률분포론",color:color.green,show:"確率分布論",size:"84"},{idx:8,name:"확률론",color:color.green,show:"確率論",size:"80"},{idx:9,name:"위상데이터분석",color:color.green,show:"位相データ分析",size:"40"}],[{idx:1,name:"논문작성",color:color.red,show:"論文作成",size:"63"},{idx:2,name:"생새우초밥지",color:color.black,show:"生エビ寿司誌",size:"7"}]];document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("blindList"));(e==""||e==null||e==null||e==0||e==NaN)&&localStorage.setItem("blindList",null),render_category(categoryRows),blind_category(e);const t=document.querySelector(".btnReset");t.addEventListener("click",()=>{let e=new Array;localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)});const n=document.querySelector(".btnMute");n.addEventListener("click",()=>{let e=new Array;for(let t=0;t<categoryRows.length;t++)categoryRows[t].map(n=>{const s={mainIdx:t,subIdx:n.idx};e.push(s)});localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)})});function render_category(e){const n=document.querySelector(".category");let t="";for(let n=0;n<e.length;n++)e[n].map(e=>{t+=`<span id="cate${n}-${e.idx}" class="cate etewsert">`,t+=`<span onclick="check_blind(${n}, ${e.idx});" style="cursor: pointer; color: ${e.color}">●</span>`,t+=`<a href="https://freshrimpsushi.github.io/jp/categories/${e.name.toLowerCase()}/">`,t+=` ${e.show} (${e.size})</a>`,t+="</span>",screen.width>954?t+="<br>":t+=" "}),t+="<hr>";n.innerHTML=t}function check_blind(e,t){const o=document.querySelector(`#cate${e}-${t}`);let n=new Array;const i={mainIdx:e,subIdx:t};let s=JSON.parse(localStorage.getItem("blindList"));if(s==""||s==null||s==null||s==0||s==NaN)n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind";else{n=s;let a=null;for(let s=0;s<n.length;s++)if(n[s].mainIdx==e&&n[s].subIdx==t){a=n.filter(n=>n.mainIdx!=e||n.subIdx!=t);break}a===null?(n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind"):(localStorage.setItem("blindList",JSON.stringify(a)),o.className="cate")}}function blind_category(e){const t=document.querySelectorAll(".cate");t.forEach(e=>{e.className="cate"}),e!==null&&e.map(e=>{const t=document.querySelector(`#cate${e.mainIdx}-${e.subIdx}`);t.className+=" blind"})}</script><br><br><b>最近見たポスト</b><div class=lately-viewed-list style=padding-left:4px></div><script defer>document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("latelyViewPostList")),n=document.querySelector(".lately-viewed-list");let t="";if(e==""||e==null||e==null||e==0||e==NaN)localStorage.setItem("latelyViewPostList",null),t+='<div class="lv-list">',t+=" · 열람한 포스트가 없습니다.",t+="</div>",n.innerHTML=t;else{for(let n=e.length-1;n>=0;n--)t+='<div class="lv-list">',t+=`<a href="${e[n].link}"> · ${e[n].title}</a>`,t+="</div>";n.innerHTML=t}})</script><script defer>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="論文レビュー: 物理情報基盤ニューラルネットワーク(PINN)",c="https://freshrimpsushi.github.io/jp/posts/3313/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script><br><b>最新コメント</b><div class=current-reply></div><script defer>const url="https://freshrimpsushi.com/blog/ajax/recent_comment.php?action=getCurrentComment";let recentRows=[];fetch(url).then(e=>e.json()).then(e=>{e.ok&&(recentRows=e.rows,render_recent_comment(recentRows))}).catch(e=>console.error(e));function render_recent_comment(e){const n=document.querySelector(".current-reply");let t="";e.map(e=>{let n="https://freshrimpsushi.github.io/jp/";e.board_idx>-1?n+=`posts/${e.board_idx}#comment${e.cmt_idx}`:e.board_idx==-1?n+=`#comment${e.cmt_idx}`:n+=`categories/${e.board_title}#comment${e.cmt_idx}`,t+='<div class="current-reply-list">',t+=`<a href="${n}">`,t+=`<b> - ${e.author}</b>: `,t+=`${e.content}`,t+=`</a>`,t+=`</div>`}),n.innerHTML=t,renderKaTex(n)}</script><br></aside></div><footer><aside><div><p id=mirror-link style=text-align:center><a style=cursor:text href=http://localhost:1313//jp/posts/3313/>© 生エビ寿司屋 / Powered by 류대식, 전기현</a><br>Contact:
<img src=https://freshrimpsushi.github.io/jp/logo/gmail.png width=12px alt=mail> freshrimpsushi@gmail.com
<a href=https://freshrimpsushi.github.io/jp/index.xml><img src=https://freshrimpsushi.github.io/jp/logo/RSS.png width=12px alt=RSS> RSS</a></p></div><script type=text/javascript>var goIndex=function(){var e=document.getElementsByName("idx")[0].value,t="https://freshrimpsushi.github.io/jp/posts/"+e;location.replace(t)};document.addEventListener("keydown",function(e){const n=document.getElementById("navigator");if(e.altKey&&e.ctrlKey&&e.key==="l"){e.preventDefault();var t=document.querySelector("#mirror-link a");t?t.click():console.log("거울 링크를 찾지 못했습니다.")}})</script><link rel=stylesheet href=https://freshrimpsushi.github.io/jp/css/codefence.css><script src=https://freshrimpsushi.github.io/jp/js/highlight.min.js></script><script>hljs.highlightAll()</script></aside></footer></body><script async src="https://www.googletagmanager.com/gtag/js?id=G-NLV8Y9PRK1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NLV8Y9PRK1")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4751085325232621" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/sweetalert2@11></script><script src=https://freshrimpsushi.github.io/jp/js/fontawsome.min.js></script><script src=https://freshrimpsushi.github.io/jp/js/common.js></script><script>document.addEventListener("DOMContentLoaded",()=>{fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/ip_checker.php";return postFetch(t,{user_ip:e})}).then(e=>e.json()).then(e=>{e.ok||(alert(`차단된 IP입니다.
Contact:
freshrimpsushi@gmail.com`),window.location.href="https://google.com")}).catch(e=>console.error(e))})</script></html>