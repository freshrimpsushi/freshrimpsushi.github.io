<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on FreshrimpRestaurant</title>
    <link>https://freshrimpsushi.github.io/en/tags/r/</link>
    <description>Recent content in R on FreshrimpRestaurant</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 04 Sep 2019 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://freshrimpsushi.github.io/en/tags/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Heteroskedasticity and Volatility Clustering in Time Series Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/1272/</link>
      <pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1272/</guid>
      <description>Definition 1 Given a time series data $\left\{ p_{t} \right\}$. When the variance of $\left\{ p_{t} \right\}$ depends on $t$, $\left\{ p_{t} \right\}$ is said to have Heteroscedasticity. The phenomenon of the variance of $\left\{ p_{t} \right\}$, which has Heteroscedasticity, increasing and decreasing repeatedly is referred to as Volatility Clustering. The following defined $r_{t}$ is referred to as (Log) Return in $t$. $$ r_{t} := \nabla \log p_{t} = \log</description>
    </item>
    <item>
      <title>Autocorrelation Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/1209/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1209/</guid>
      <description>Definition 1 Let&amp;rsquo;s say $\left\{ Y_{t} \right\}_{t=1}^{n}$ is a stochastic process. $\mu_{t} := E ( Y_{t} )$ is called the mean function. The following defined $\gamma_{ t , s }$ is called the autocovariance function. $$ \gamma_{t , s} : = \text{cov} ( Y_{t} , Y_{s} ) = E ( Y_{t} - \mu_{t} ) E ( Y_{s} - \mu_{s} ) $$ The following defined $\rho_{ t , s }$ is</description>
    </item>
    <item>
      <title>Transformation in Time Series Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/938/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/938/</guid>
      <description>Buildup The reason why transformations are necessary in time series is to give a &amp;ldquo;penalty&amp;rdquo; for increasing variance over time, to keep the variance constant, and to achieve stationarity. The square root $\sqrt{}$ and log $\log$ are often used because the amount reduced is greater for larger values. Of course, when variance decreases, it means that the trend of data converges to some point, thus no time series analysis is</description>
    </item>
    <item>
      <title>Differencing in Time Series Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/916/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/916/</guid>
      <description>Definition 1 Define operator $B$ as $B Y_{t} = Y_{t-1}$, referred to as Backshift. Define operator $\nabla$ as $\nabla := 1 - B$ and $\nabla^{r+1} = \nabla \left( \nabla^{r} Y_{t} \right)$, referred to as Differencing. Explanation According to the definition of differencing, the $1$th difference is calculated as $$ \nabla Y_{t} = Y_{t} - Y_{t-1} $$, and the $2$th difference is calculated as $$ \begin{align*} \nabla^2 Y_{t} =&amp;amp; \nabla \left(</description>
    </item>
    <item>
      <title>Stability in Time Series Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/907/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/907/</guid>
      <description>Definition 1 Time series data is said to have stationarity when its mean and variance are constant over time. Description It&amp;rsquo;s not normal正常 as in standard, but stationarity定常. The fact that data is stationary means that its mean and variance are stabilized, making it easier to analyze. If the</description>
    </item>
    <item>
      <title>What is a Stochastic Process?</title>
      <link>https://freshrimpsushi.github.io/en/posts/857/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/857/</guid>
      <description>Definition The range of the random variable $X: \Omega \to E$ is called the state space. The set of random variables $\left\{ X_{t} \mid t \in [ 0 , \infty ) \right\}$ is called a continuous stochastic process. The sequence of random variables $\left\{ X_{n} \mid n = 0, 1, 2, \cdots \right\}$ is called a discrete stochastic process. Explanation The term &amp;lsquo;process&amp;rsquo; in stochastic process often makes the concept</description>
    </item>
    <item>
      <title>Multicollinearity</title>
      <link>https://freshrimpsushi.github.io/en/posts/808/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/808/</guid>
      <description>Definition 1 Consider performing multiple regression analysis $Y \gets X_{1} , \cdots, X_{p}$. If among the independent variables $ X_{1} , \cdots, X_{p}$ there is a strong correlation between the independent variables, then it is said that there is multicollinearity. Practice Initially, the very idea that independent variables are dependent violates the assumptions of regression analysis and indeed leads to numerical problems that make the analysis results unreliable. It can</description>
    </item>
    <item>
      <title>How to Interpret Multiple Regression Analysis Results in R</title>
      <link>https://freshrimpsushi.github.io/en/posts/670/</link>
      <pubDate>Wed, 05 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/670/</guid>
      <description>Data Exploration tail(attitude) In R, let&amp;rsquo;s load the built-in data attitude and check it using the tail() function. We are interested in performing multiple regression analysis on this data. We are interested in how the other independent variables affect the rating, which is our dependent variable. It&amp;rsquo;s difficult to see if there is a linear relationship between rating and the other variables just by looking at the data, so let&amp;rsquo;s</description>
    </item>
  </channel>
</rss>
