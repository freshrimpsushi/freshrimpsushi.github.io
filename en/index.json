[{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition 1 In a network $\\left( V, E \\right)$, the number of shortest paths connecting two nodes $s,t \\in V$ is denoted by $\\sigma_{st} = \\sigma_{ts}$, and specifically, the number of paths among those that include another node $v \\in V$ is denoted by $\\sigma_{st} (v)$. The following defined $C_{S} : V \\to \\mathbb{Z}$ is referred to as the Stress Centrality of node $v$. $$ C_{S} (v) := \\sum_{s \\ne v \\ne t \\in V} \\sigma_{st} (v) $$\nExplanation $\\sigma_{st} (v)$ If you read carefully the definition of $\\sigma_{st}$, it is not the shortest distance $d(s,t) = d(t,s)$ between $s,t$, but the number of paths that make it the shortest distance, for all $v \\in V$, $\\sigma_{vv} = 1$, and with respect to the graph\u0026rsquo;s distance function $d$, $\\sigma_{st} (v)$ is as follows. $$ \\sigma_{st} (v) = \\begin{cases} 0 \u0026amp; , \\text{if } d \\left( s , t \\right) \u0026lt; d \\left( s , v \\right) + d \\left( v , t \\right) \\\\ \\sigma_{sv} \\cdot \\sigma_{vt} \u0026amp; , \\text{otherwise} \\end{cases} $$\nIntuitive Meaning Stress Centrality is one of the oldest centralities introduced by Shimbel in 1953, and the equation $$ C_{S} (v) = \\sum_{s \\ne v \\ne t \\in V} \\sigma_{st} (v) $$ can be seen as how much a node $v \\in V$ creates the shortest paths by intermediating between all pairs of nodes $s, t \\in V$. In many phenomena in nature\u0026hellip; for example, as a water droplet minimizes surface area and the action in motion is minimized, there is often a great interest in the shortest or fastest path to connect two nodes, and points that frequently belong to the shortest path would bear a lot of Stress. From this intuitive standpoint, it makes quite sense to call $C_{S} (v)$ Stress Centrality.\nLater, Betweenness Centrality was introduced as a measure that complements Stress Centrality.\nSee Also Various Centrality in Networks üîí(24/02/08) Degree Centrality üîí(24/02/16) Betweenness Centrality üîí(24/02/12) Stress Centrality üîí(24/02/20) Closeness Centrality üîí(24/02/24) Eigenvector Centrality Brandes. (2001). A Faster Algorithm for Betweenness Centrality. https://doi.org/10.1080/0022250X.2001.9990249\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2522,"permalink":"https://freshrimpsushi.github.io/en/posts/2522/","tags":null,"title":"Stress Centrality in Network Theory"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition In natural language, sparse refers to being thin or scarce in a way that a value is considered virtually non-existent if it is $0$. Sparsity indicates the degree to which something is made up of such $0$ values.\nSparse Matrix A matrix whose elements are mostly $0$ is referred to as a Sparse Matrix.\n$S$-Sparse 1 Even if there are many values, when there are only $S \\ll d$ non-$0$ elements, $\\mathbf{x}$ is said to be $S$-sparse. Here, the integer $S \\in \\mathbb{Z}$ for the vector $\\mathbf{v}$\u0026rsquo;s support $\\operatorname{supp} \\mathbf{v} = \\left\\{ k : \\mathbf{v}_{k} \\ne 0 \\right\\}$ satisfies the following inequality: $$ \\operatorname{card} \\left( \\operatorname{supp} \\mathbf{v} \\right) \\le S $$ where $\\operatorname{card}$ represents cardinality.\nExplanation Alternative terms include thin matrix and scarce matrix, but usually, neither is used, and it\u0026rsquo;s called by its English pronunciation, [Sparse Matrix]. As the term suggests, a sparse matrix is defined as a matrix with \u0026lsquo;meaningful\u0026rsquo; information being sparse. As the word \u0026lsquo;mostly\u0026rsquo; suggests, this isn\u0026rsquo;t a mathematically strict definition. When a specific $S$ is given, making it \u0026lsquo;sufficiently sparse,\u0026rsquo; its definition becomes clear.\nOptimization Theory In [optimization theory](../../categories/optimization theory), sparse regression refers to the optimization problem of maximizing the sparsity of the solution, that is, minimizing $S$ in a regression problem.\nGraph Theory In [graph theory](../../categories/graph theory), the adjacency matrix of a random network given as data is assumed to be a sparse matrix.\nData Structures In the realm of practical computation, sparse matrices are close to data structures. For instance, consider $X,Y \\in \\mathbb{R}^{10^{6} \\times 10^{6}}$ where only the last element is $\\sqrt{2}$, and the rest are $0$. To store this matrix, a $2 \\cdot 10^{12}$-slot array filled with floating-point numbers is needed, but if it\u0026rsquo;s certain that it\u0026rsquo;s a sparse matrix, there\u0026rsquo;s no need to store all those $0$ values ‚Äì just the last slot suffices. Not only does this make storage more convenient, but it also allows for more efficient operations. Despite these two matrices being enormously large, their product can simply be calculated as $$ X Y = \\begin{bmatrix} 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 2 \\end{bmatrix} $$ It would be unwise to use Strassen\u0026rsquo;s algorithm for this multiplication. \u0026lsquo;Computing sparse matrices on a computer\u0026rsquo; means being able to read and write these matrices with less storage, and performing calculations very quickly by skipping parts that are $0$2.\nNeedell, D., Vershynin, R. Uniform Uncertainty Principle and Signal Recovery via Regularized Orthogonal Matching Pursuit. Found Comput Math 9, 317‚Äì334 (2009). https://doi.org/10.1007/s10208-008-9031-3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://ko.wikipedia.org/wiki/%ED%9D%AC%EC%86%8C%ED%96%89%EB%A0%AC\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2513,"permalink":"https://freshrimpsushi.github.io/en/posts/2513/","tags":null,"title":"Sparse Matrices"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition1 Let\u0026rsquo;s say a function $f : \\mathbb{R} \\to \\mathbb{R}( \\text{or } \\mathbb{C})$ is given. If for any finite number of mutually disjoint intervals $(a_{i}, b_{i}) \\sub [a,b]$, the following condition is satisfied, then it is said to be absolutely continuousabsolutely continuous on $[a, b]$.\n$$ \\forall \\epsilon \\gt 0 \\quad \\exist \\delta \\gt 0 \\text{ such that } \\sum\\limits_{i=1}^{N} (b_{i} - a_{i}) \\lt \\delta \\implies \\sum\\limits_{i=1}^{N} \\left| f(b_{j}) - f(a_{j}) \\right| \\lt \\epsilon $$\nExplanation According to the definition, if it is absolutely continuous, it is also uniformly continuous.\nProperties If $f$ is differentiable and its derivative $f^{\\prime}$ is bounded, then $f$ is absolutely continuous.\nSee Also Absolute Continuity of Real Functions Absolute Continuity of Measures Absolute Continuity of Signed Measures Gerald B. Folland, Real Analysis: Modern Techniques and Their Applications (2nd Edition, 1999), p105\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3542,"permalink":"https://freshrimpsushi.github.io/en/posts/3542/","tags":null,"title":"Absolutely Continuous Real Function"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview InfiniteArrays.jl is a package that enables the use of arrays of infinite size1, and is, in fact, closely related to Lazy Arrays. Lazy Evaluation refers to the method where the computer knows what needs to be computed but postpones the calculation until it is absolutely necessary. Obviously, computers cannot understand infinity, but this method allows for the implementation of infinite arrays on computers.\nCode ‚àû julia\u0026gt; using InfiniteArrays\rjulia\u0026gt; 3141592 \u0026lt; ‚àû\rtrue\rjulia\u0026gt; Inf == ‚àû\rtrue\rjulia\u0026gt; Inf === ‚àû\rfalse Loading InfiniteArrays.jl, you first become able to express infinity with the ‚àû symbol. Though you can express infinity as Inf without this package, using this symbol allows for a more intuitive use. While they hold the same magnitude of infinity in comparison, they can be differentiated as pointers.\n‚Ñµ‚ÇÄ julia\u0026gt; x = zeros(Int64, ‚àû);\rjulia\u0026gt; length(x)\r‚Ñµ‚ÇÄ Creating an infinite array filled with zeros results in a [countably infinite set], hence its size is aleph-zero $\\aleph_{0}$.\nCan be used ordinarily julia\u0026gt; x[2] = 3; x[94124843] = 7; x\r‚Ñµ‚ÇÄ-element LazyArrays.CachedArray{Int64, 1, Vector{Int64}, Zeros{Int64, 1, Tuple{InfiniteArrays.OneToInf{Int64}}}} with indices OneToInf():\r0\r3\r0\r0\r0\r0\r0\r0\r0\r‚ãÆ\rjulia\u0026gt; sum(x)\r10 Having an infinite array doesn\u0026rsquo;t mean the interface changes significantly. You can handle it just like any regular array, and it will work as expected.\nComplete code using InfiniteArrays\r3141592 \u0026lt; ‚àû\rInf == ‚àû\rInf === ‚àû\rx = zeros(Int64, ‚àû);\rlength(x)\rx[2] = 3; x[94124843] = 7; x\rsum(x) Environment OS: Windows julia: v1.7.3 https://github.com/JuliaArrays/InfiniteArrays.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2511,"permalink":"https://freshrimpsushi.github.io/en/posts/2511/","tags":null,"title":"How to Use Infinite Arrays in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview MAT.jl is a library for reading and writing *.mat files, which are the data storage format used in MATLAB1. As is typical of Julia, this package does not force users to abandon their existing programming languages and habits; instead, it aims to secure users by providing an environment that is as familiar as possible.\nWhile the speed and convenience of Julia are significant advantages, MATLAB offers unique benefits for visualization for research purposes. If you are already proficient at drawing with MATLAB, a \u0026lsquo;complete transition to Julia\u0026rsquo; may seem less appealing due to the significant sacrifices it entails. The existence of MAT.jl presents a tempting proposition: \u0026ldquo;Don\u0026rsquo;t worry about that, just perform your calculations quickly with Julia and then go back to MATLAB for drawing.\u0026rdquo; Conversely, it is also helpful in situations where \u0026lsquo;you have already done much work and built structures with MATLAB but feel some limitations and wish to switch to Julia\u0026rsquo;. To learn about Julia\u0026rsquo;s advanced native storage format, refer to the JLD2.jl package.\nCode X = rand(0:9, 8, 3)\rusing MAT\rmatwrite(\u0026#34;example.mat\u0026#34;, Dict(\u0026#34;Y\u0026#34; =\u0026gt; X))\rmatfile = matopen(\u0026#34;elpmaxe.mat\u0026#34;)\rA = read(matfile, \u0026#34;A\u0026#34;)\rclose(matfile) Julia ‚Üí MATLAB MATLAB ‚Üí Julia Environment OS: Windows julia: v1.7.3 MAT v0.10.3 MATLAB: R2022b https://github.com/JuliaIO/MAT.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2509,"permalink":"https://freshrimpsushi.github.io/en/posts/2509/","tags":null,"title":"Reading and Writing mat Files in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview UnicodePlots.jl is a library that uses Unicode characters to print graphics in the Julia REPL1, enabling lightweight yet high-quality visualization as the program runs.\nCode using UnicodePlots\rp1 = lineplot(100 |\u0026gt; randn |\u0026gt; cumsum)\rp1 = lineplot!(p1, 100 |\u0026gt; randn |\u0026gt; cumsum); p1\rUnicodePlots.heatmap(cumsum(abs.(randn(100,100)), dims=2)) The result of running the above example code is as follows.\nEnvironment OS: Windows julia: v1.7.3 UnicodePlots v3.0.4 https://github.com/JuliaPlots/UnicodePlots.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2507,"permalink":"https://freshrimpsushi.github.io/en/posts/2507/","tags":null,"title":"How to Output Simple Graphics in the Julia Console"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Method In the console, pressing Ctrl + L appears to clear the console completely, but in some environments, it does not actually reset but rather scrolls the window as if it were pushed up. To cleanly remove or not rely on keyboard input, printing ASCII character \\033c can be used12.\nprint(\u0026#34;\\033c\u0026#34;) Also, printing \\007 will play a notification sound. 3 It\u0026rsquo;s surprisingly useful when you want to hear the end of a simple simulation or similar event through sound.\nprintln(\u0026#34;\\007\u0026#34;) Environment OS: Windows julia: v1.7.3 https://stackoverflow.com/questions/26548687/julia-how-to-clear-console\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/47503734/what-does-printf-033c-mean\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://discourse.julialang.org/t/how-to-play-a-sound-or-tone-when-a-program-ends/41239/13\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2505,"permalink":"https://freshrimpsushi.github.io/en/posts/2505/","tags":null,"title":"How to Initialize the Console in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview 1 In Julia, you can easily remove missing values using the dropmissing() function.\nCode julia\u0026gt; df = DataFrame(x = [\u0026#34;i\u0026#34;, missing, \u0026#34;k\u0026#34;, \u0026#34;j\u0026#34;], y = [1, 2, 3, missing])\r4√ó2 DataFrame\rRow ‚îÇ x y ‚îÇ String? Int64? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ i 1\r2 ‚îÇ missing 2\r3 ‚îÇ k 3\r4 ‚îÇ j missing Suppose we have a dataframe with missing values missing as shown above.\njulia\u0026gt; dropmissing(df, :x)\r3√ó2 DataFrame\rRow ‚îÇ x y ‚îÇ String Int64? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ i 1\r2 ‚îÇ k 3\r3 ‚îÇ j missing julia\u0026gt; dropmissing(df, :y)\r3√ó2 DataFrame\rRow ‚îÇ x y ‚îÇ String? Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ i 1\r2 ‚îÇ missing 2\r3 ‚îÇ k 3 To remove missing values from the column you want, just put the symbol of the column as an argument.\njulia\u0026gt; dropmissing(df)\r2√ó2 DataFrame\rRow ‚îÇ x y ‚îÇ String Int64\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ i 1\r2 ‚îÇ k 3 If you want to remove all missing values from the entire dataframe, you don\u0026rsquo;t need to input any column.\nFull Code using DataFrames\rdf = DataFrame(x = [\u0026#34;i\u0026#34;, missing, \u0026#34;k\u0026#34;, \u0026#34;j\u0026#34;], y = [1, 2, 3, missing])\rdropmissing(df, :x)\rdropmissing(df, :y)\rdropmissing(df) Environment OS: Windows julia: v1.7.3 https://discourse.julialang.org/t/how-to-remove-rows-containing-missing-from-dataframe/12234/7\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2503,"permalink":"https://freshrimpsushi.github.io/en/posts/2503/","tags":null,"title":"Removing Missing Values in DataFrames in Julia"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Overview In Spatial Statistics Analysis, if a Spatial Process is Isotropic and the Semivariogram satisfies $\\gamma \\left( \\left\\| \\mathbf{h} \\right\\| \\right) = \\gamma (d)$, then $\\gamma$ can be expressed not as a complex matrix form but as a one-dimensional scalar function, that is, $\\gamma : \\mathbb{R} \\to \\mathbb{R}$. This means that the correlation between point reference data $Y(s), Y(s + d)$ can be plotted as a line graph.\nModels 1 (Following the post on Isotropy of Variograms)\nVariogram graphs can be categorized into several types depending on the characteristics of the data.\nSetting aside how these are interpreted, the method of drawing such a picture simply involves placing the distance $Y(s), Y(s+d)$ between the data $d$ on the x-axis and $\\gamma (d)$ on the y-axis. From the fact that it is represented as a picture in the first place, it can be confirmed that calling $\\gamma$ a \u0026lsquo;variogram\u0026rsquo; is a natural naming.\nIn actual data, there may not be many data pairs that exactly correspond to a certain length $d$, so it can be empirically obtained by dividing into partitions. The above figure is an example of drawing a variogram in Julia, showing not only the semivariogram but also the frequency of the respective class according to $h = d$2.\nEquations Several functions are known as models for fitting variograms.\nHere, we will briefly comment on a few important models and move on:\nLinear: A model in which influence is determined proportional to distance. At first glance, it seems plausible, but it\u0026rsquo;s actually not used due to difficult interpretation with the covariogram. Spherical: A model in which influence completely disappears beyond a certain distance. It is a reasonable choice for many data sets. Exponential: The simplest and most understandable model where influence decreases exponentially as distance increases. It\u0026rsquo;s sufficient for undergraduate level projects. Mat√©rn: Among the given models, it can be used in a wide variety of data due to its inclusion of $\\tau^{2}$ which relates to the y-intercept, $\\sigma^{2}$ that determines scale, and $\\phi$ to $\\nu$ that affect the shape itself. If Exponential is the simple go-to, then Mat√©rn is considered the strongest and most widely used model. The $K_{\\nu}$ appearing in equations refers to the Modified Bessel function of the first kind. Now let\u0026rsquo;s look at how to read a semivariogram through equations. Before that, it is good to remember the following equation, where $\\gamma$ and $C$ have a trade-off relationship, and since $C$ represents covariance, a high value of $\\gamma$ means that the relationship between the data decreases. $$ \\text{Var} Y = \\gamma ( \\mathbf{h} ) + C ( \\mathbf{h} ) $$\nGenerally, variograms often depict a shape where $t$ increases and then $\\gamma (t)$ also increases until it no longer grows after a certain point. Intuitively, this describes that as the distance increases, the relevance between the data decreases until it becomes particularly unrelated beyond a certain distance.\nNugget $$ \\text{Nugget} := \\gamma \\left( 0^{+} \\right) = \\lim_{t \\to 0+} \\gamma (t) = \\tau^{2} $$ Among the known models, $\\tau^{2}$ corresponds to the value known as Nugget,\nTheoretically, since $\\text{Var} Y = \\gamma ( \\mathbf{h} ) + C ( \\mathbf{h} )$, at $\\mathbf{h} = 0$ it should be $C ( 0 ) = \\text{Var} Y$, but When handling actual data, there is practically no meaning at exactly data $\\left| \\mathbf{h} \\right| = 0$, and even very close points show some differences. Thus, the y-intercept emerging contrary to theory is called a Nugget.\nSill $$ \\text{Sill} := \\lim_{t \\to \\infty} \\gamma (t) = \\tau^{2} + \\sigma^{2} $$ Among the known models, the value corresponding to $\\tau^{2} + \\sigma^{2}$ is called the Sill of $\\gamma (t)$. Depending on the model, it may not converge theoretically, but if we consider a suitable tolerance $0.05$ as \u0026lsquo;having reached the ceiling,\u0026rsquo; that point can be called the Sill. Especially, the height between the Sill and Nugget $\\sigma$ is referred to as the Partial Sill.\nRange The point up to which $\\gamma (t)$ first touches the Sill is referred to as the Range. Particularly, if a tolerance is given when determining the Sill, it is also called the Effective Range.\nBanerjee. (2015). Hierarchical Modeling and Analysis for Spatial Data(2nd Edition): p24~29.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://juliaearth.github.io/GeoStats.jl/stable/variography/empirical.html#Variograms\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2502,"permalink":"https://freshrimpsushi.github.io/en/posts/2502/","tags":null,"title":"Models of Semivariograms"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Overview1 2 Describe the adaptive learning rate used in gradient descent and the models that apply it: AdaGrad, RMSProp, and Adam.\nExplanation In gradient descent, the learning rate learning rate is an important parameter that determines how fast the parameter converges, how successful the method is, and so on. It is often written as $\\alpha$, $\\eta$, and determines how much of the gradient is taken into account when updating the parameter.\nOptimization Patterns with Learning Rate: Large Learning Rate (Left), Small Learning Rate (Right)\"\r$$ \\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\alpha \\nabla L (\\boldsymbol{\\theta}_{i}) $$\nIn basic gradient descent, $\\alpha$ is described as a constant, and in this case, gradient is a vector, so the same learning rate applies to all variables (parameters) as follows\n$$ \\alpha \\nabla L (\\boldsymbol{\\theta}) = \\alpha \\begin{bmatrix} \\dfrac{\\partial L}{\\partial \\theta_{1}} \u0026amp; \\dfrac{\\partial L}{\\partial \\theta_{2}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial L}{\\partial \\theta_{k}} \\end{bmatrix} = \\begin{bmatrix} \\alpha\\dfrac{\\partial L}{\\partial \\theta_{1}} \u0026amp; \\alpha\\dfrac{\\partial L}{\\partial \\theta_{2}} \u0026amp; \\cdots \u0026amp; \\alpha\\dfrac{\\partial L}{\\partial \\theta_{k}} \\end{bmatrix} $$\nSo, by thinking of the learning rate as a vector like $\\boldsymbol{\\alpha} = (\\alpha_{1}, \\alpha_{2}, \\dots, \\alpha_{k})$, we can generalize the gradient term to the expression below.\n$$ \\boldsymbol{\\alpha} \\odot \\nabla L (\\boldsymbol{\\theta}) = \\begin{bmatrix} \\alpha_{1}\\dfrac{\\partial L}{\\partial \\theta_{1}} \u0026amp; \\alpha_{2}\\dfrac{\\partial L}{\\partial \\theta_{2}} \u0026amp; \\cdots \u0026amp; \\alpha_{k}\\dfrac{\\partial L}{\\partial \\theta_{k}} \\end{bmatrix} $$\nwhere $\\odot$ is the matrix\u0026rsquo;s [Adamar product (componentwise product)] (../3436). The learning rate $\\boldsymbol{\\alpha}$, which varies from parameter to parameter in this way, is called the adaptive learning rateadaptive learning rate. Since the following techniques rely on the gradient to determine the adaptive learning rate, $\\boldsymbol{\\alpha}$ can be viewed as a function of $\\boldsymbol{\\alpha}$.\n$$ \\boldsymbol{\\alpha} (\\nabla L(\\boldsymbol{\\theta})) = \\begin{bmatrix} \\alpha_{1}(\\nabla L(\\boldsymbol{\\theta})) \u0026amp; \\alpha_{2}(\\nabla L(\\boldsymbol{\\theta})) \u0026amp; \\dots \u0026amp; \\alpha_{k}(\\nabla L(\\boldsymbol{\\theta})) \\end{bmatrix} $$\nBelow we introduce AdaGrad, RMSProp, and Adam. It is important to note that there is no absolute winner among these optimizers, including the [momentum] (../3528) technique. Different fields and different tasks require different optimizers, so it\u0026rsquo;s not a good idea to make a judgment or question about \u0026ldquo;what\u0026rsquo;s best\u0026rdquo;. It\u0026rsquo;s helpful to find out what\u0026rsquo;s commonly used in your field, and if you don\u0026rsquo;t have that or aren\u0026rsquo;t sure, you can try SGD+Momentum or Adam.\nAdaGrad AdaGrad is an adaptive learning rate technique introduced in the paper \u0026ldquo;Adaptive subgradient methods for online learning and stochastic optimization\u0026rdquo; by Duchi et al. (2011). The name is short for adaptive gradient and is pronounced as [AY-duh-grad] or [AH-duh-grad]. In AdaGrad, the learning rate for each parameter is set inversely proportional to the gradient. Consider the vector $\\mathbf{r}$ as follows.\n$$ \\mathbf{r} = (\\nabla L) \\odot (\\nabla L) = \\begin{bmatrix} \\left( \\dfrac{\\partial L}{\\partial \\theta_{1}} \\right)^{2} \u0026amp; \\left( \\dfrac{\\partial L}{\\partial \\theta_{2}} \\right)^{2} \u0026amp; \\cdots \u0026amp; \\left( \\dfrac{\\partial L}{\\partial \\theta_{k}} \\right)^{2} \\end{bmatrix} $$\nFor a global learning rate global learning rate $\\epsilon$, an arbitrary small number $\\delta$, the adaptive learning rate $\\boldsymbol{\\alpha}$ is given by\n$$ \\boldsymbol{\\alpha} = \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}}} $$\nAs you can see from the formula, we apply a smaller learning rate for variables with larger components of the gradient and a larger learning rate for variables with smaller components of the gradient. The $\\delta$, as you might guess, prevents the denominator from being $0$ or too small a number, and is often used between $10^{-5} \\sim 10^{-7}$, and is often used for values between $10^{-5} and $10^{-7}. Also, the learning rate is cumulative from iteration to iteration. The gradient at the $i$th iteration is called $\\nabla L _{i} = \\nabla L (\\boldsymbol{\\theta}_{i})$,\n$$ \\begin{align} \\mathbf{r}_{i} \u0026amp;= (\\nabla L_{i}) \\odot (\\nabla L_{i}) \\nonumber \\\\ \\boldsymbol{\\alpha}_{i} \u0026amp;= \\boldsymbol{\\alpha}_{i-1} + \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}_{i}}} = \\sum_{j=1}^{i} \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}_{j}}} \\\\ \\boldsymbol{\\theta}_{i+1} \u0026amp;= \\boldsymbol{\\theta}_{i} - \\boldsymbol{\\alpha}_{i} \\odot \\nabla L_{i} \\nonumber \\end{align} $$\nAlgorithm: AdaGrad Input Global learning rate $\\epsilon$, small positive value $\\delta$, epochs $N$ 1. Initialize parameters $\\boldsymbol{\\theta}$ with random values. 2. Initialize learning rates $\\boldsymbol{\\alpha} = \\mathbf{0}$. 3. for $i = 1, \\cdots, N$ do 4. $\\mathbf{r} \\leftarrow \\nabla L(\\boldsymbol{\\theta}) \\odot \\nabla L(\\boldsymbol{\\theta})$ # Compute gradients and square each component 5. $\\boldsymbol{\\alpha} \\leftarrow \\boldsymbol{\\alpha} + \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}}}$ # Update adaptive learning rates 6. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\boldsymbol{\\alpha} \\odot \\nabla L(\\boldsymbol{\\theta})$ # Update parameters 7. end for RMSProp RMSProp, short for Root Mean Square Propagation, is an adaptive learning rate technique proposed in Geoffrey Hinton\u0026rsquo;s lecture Neural networks for machine learning. It is basically a variant of AdaGrad, only with the addition of $(1)$ replaced by a [weighted sum] (../2470/#exponentially weighted average) so that the added term decreases exponentially. For $\\rho \\in (0,1)$,\n$$ \\boldsymbol{\\alpha}_{i} = \\rho \\boldsymbol{\\alpha}_{i-1} + (1-\\rho) \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}_{i}}} = (1-\\rho) \\sum_{j=1}^{i} \\rho^{i-j} \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}_{j}}} $$\nLarge values such as $\\rho = 0.9, 0.99$ are commonly used.\nAlgorithm: RMSProp Input Global learning rate $\\epsilon$, small positive value $\\delta$, decay rate $\\rho$, epochs $N$ 1. Initialize parameters $\\boldsymbol{\\theta}$ with random values. 2. Initialize learning rates $\\boldsymbol{\\alpha} = \\mathbf{0}$. 3. for $i = 1, \\dots, N$ do 4. $\\mathbf{r} \\leftarrow \\nabla L(\\boldsymbol{\\theta}) \\odot \\nabla L(\\boldsymbol{\\theta})$ # Compute gradients and square each component 5. $\\boldsymbol{\\alpha} \\leftarrow \\rho \\boldsymbol{\\alpha} + (1-\\rho) \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}}}$ # Update adaptive learning rates 6. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\boldsymbol{\\alpha} \\odot \\nabla L(\\boldsymbol{\\theta})$ # Update parameters 7. end for Adam Adamderives from \u0026quot;apative moments\u0026quot; is an optimizer introduced in the paper \u0026quot;Adam: A method for stochastic optimization\u0026quot; (Kingma and Ba, 2014). It combines the adaptive learning rate and the momentum technique and can be thought of as RMSProp + momentum. Once you understand RMSProp and momentum, it\u0026rsquo;s not hard to understand Adam. Here\u0026rsquo;s how RMSProp, momentum, and Adam compare to each other If $\\nabla L_{i} = \\nabla L(\\boldsymbol{\\theta}_{i})$,\nMomentum\r$\\mathbf{p}_{i} = \\beta_{1}\\mathbf{p}_{i-1} + \\nabla L_{i} \\quad (\\mathbf{p}_{0}=\\mathbf{0}) \\\\\r\\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\alpha \\mathbf{p}_{i}$\rRMSProp\r$\\mathbf{r}_{i} = \\nabla L_{i} \\odot \\nabla L_{i} \\\\\r\\boldsymbol{\\alpha}_{i} = \\beta_{2} \\boldsymbol{\\alpha}_{i-1} + (1-\\beta_{2})\\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}_{i}}} \\quad (\\boldsymbol{\\alpha}_{0}=\\mathbf{0})\\\\\r\\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\boldsymbol{\\alpha}_{i} \\odot \\nabla L_{i}$\rAdam\r$\\mathbf{p}_{i} = \\beta_{1}\\mathbf{p}_{i-1} + (1-\\beta_{1}) \\nabla L_{i-1} \\quad (\\mathbf{p}_{0}=\\mathbf{0}) \\\\\\\\[0.5em]\r\\hat{\\mathbf{p}}_{i} = \\dfrac{\\mathbf{p}_{i}}{1-(\\beta_{1})^{i}} \\\\\\\\[0.5em]\r\\mathbf{r}_{i} = \\beta_{2} \\mathbf{r}_{i-1} + (1-\\beta_{2}) \\nabla L_{i} \\odot \\nabla L_{i} \\\\\\\\[0.5em]\r\\hat{\\mathbf{r}}_{i} = \\dfrac{\\mathbf{r}}{1-(\\beta_{2})^{i}} \\\\\\\\[0.5em]\r\\hat{\\boldsymbol{\\alpha}}_{i} = \\dfrac{\\epsilon}{\\delta + \\sqrt{\\hat{\\mathbf{r}}_{i}}} \\\\\\\\[0.5em]\r\\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\hat{\\boldsymbol{\\alpha}_{i}} \\odot \\hat{\\mathbf{p}_{i}}\r$\rThe reason we divide $1 - \\beta^{i}$ when calculating $\\hat{\\mathbf{p}}_{i}$ and $\\hat{\\mathbf{r}}_{i}$ is to make them weighted averages since $\\mathbf{p}_{i}$ and $\\mathbf{r}_{i}$ are weighted sums.\nAlgorithm: Adam\rInput Global learning rate $\\epsilon$ (recommended value is $0.001$), epochs $N$ Small constant $\\delta$ (recommended value is $10^{-8}$) Decay rates $\\beta_{1}, \\beta_{2}$ (recommended values are $0.9$ and $0.999$ respectively) 1. Initialize parameters $\\boldsymbol{\\theta}$ with random values. 2. Initialize learning rates $\\boldsymbol{\\alpha} = \\mathbf{0}$. 3. Initialize momentum $\\mathbf{p} = \\mathbf{0}$. 4. for $i = 1, \\dots, N$ do 5. $\\mathbf{p} \\leftarrow \\beta_{1}\\mathbf{p} + (1-\\beta_{1}) \\nabla L$ # Update momentum using weighted sum 6. $\\hat{\\mathbf{p}} \\leftarrow \\dfrac{\\mathbf{p}}{1-(\\beta_{1})^{i}}$ # Correct with weighted average 7. $\\mathbf{r} \\leftarrow \\beta_{2} \\mathbf{r} + (1-\\beta_{2}) \\nabla L \\odot \\nabla L$ # Update gradient square vector with weighted sum 8. $\\hat{\\mathbf{r}} \\leftarrow \\dfrac{\\mathbf{r}}{1-(\\beta_{2})^{i}}$ # Correct with weighted average 9. $\\hat{\\boldsymbol{\\alpha}} \\leftarrow \\dfrac{\\epsilon}{\\delta + \\sqrt{\\hat{\\mathbf{r}}}}$ # Update adaptive learning rates 10. $\\boldsymbol{\\theta} = \\boldsymbol{\\theta} - \\hat{\\boldsymbol{\\alpha}} \\odot \\hat{\\mathbf{p}}$ # Update parameters 11. end for Ian Goodfellow, Deep Learning, 8.5 Algorithms with Adaptive Learning Rates\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nÏò§ÏùºÏÑù, Í∏∞Í≥Ñ ÌïôÏäµ(MACHINE LEARNING) (2017), ch 5.4 Ï†ÅÏùëÏ†Å ÌïôÏäµÎ•†\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3529,"permalink":"https://freshrimpsushi.github.io/en/posts/3529/","tags":null,"title":"Adaptive Learning Rates: AdaGrad, RMSProp, Adam"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview This document explains how to reference environment variables in Julia1.\nCode Base.ENV\rBase.ENV[\u0026#34;JULIA_NUM_THREADS\u0026#34;] As you can see, accessing environment variables does not require loading any separate package; you can directly access them through Base.ENV. Since they are read as a dictionary, using the name of the desired environment variable as a key will return the environment variable as a string. The results of executing the above two lines of code are as follows.\njulia\u0026gt; Base.ENV\rBase.EnvDict with 62 entries:\r\u0026#34;ALLUSERSPROFILE\u0026#34; =\u0026gt; \u0026#34;C:\\\\ProgramData\u0026#34;\r\u0026#34;APPDATA\u0026#34; =\u0026gt; \u0026#34;C:\\\\Users\\\\rmsms\\\\AppData\\\\Roaming\u0026#34;\r\u0026#34;CHROME_CRASHPAD_PIPE_NAME\u0026#34; =\u0026gt; \u0026#34;\\\\\\\\.\\\\pipe\\\\crashpad_14984_WLSYYXMTXMJWXZQG\u0026#34;\r\u0026#34;COMMONPROGRAMFILES\u0026#34; =\u0026gt; \u0026#34;C:\\\\Program Files\\\\Common Files\u0026#34;\r\u0026#34;COMMONPROGRAMFILES(X86)\u0026#34; =\u0026gt; \u0026#34;C:\\\\Program Files (x86)\\\\Common Files\u0026#34;\r\u0026#34;COMMONPROGRAMW6432\u0026#34; =\u0026gt; \u0026#34;C:\\\\Program Files\\\\Common Files\u0026#34;\r\u0026#34;COMPUTERNAME\u0026#34; =\u0026gt; \u0026#34;SICKRIGHT\u0026#34;\r\u0026#34;COMSPEC\u0026#34; =\u0026gt; \u0026#34;C:\\\\WINDOWS\\\\system32\\\\cmd.exe\u0026#34;\r\u0026#34;CUDA_PATH\u0026#34; =\u0026gt; \u0026#34;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v11.5\u0026#34;\r\u0026#34;CUDA_PATH_V11_5\u0026#34; =\u0026gt; \u0026#34;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v11.5\u0026#34;\r\u0026#34;DRIVERDATA\u0026#34; =\u0026gt; \u0026#34;C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData\u0026#34;\r\u0026#34;GOPATH\u0026#34; =\u0026gt; \u0026#34;C:\\\\Users\\\\rmsms\\\\go\u0026#34;\r\u0026#34;HOMEDRIVE\u0026#34; =\u0026gt; \u0026#34;C:\u0026#34;\r\u0026#34;HOMEPATH\u0026#34; =\u0026gt; \u0026#34;\\\\Users\\\\rmsms\u0026#34;\r\u0026#34;JULIA_NUM_THREADS\u0026#34; =\u0026gt; \u0026#34;16\u0026#34;\r\u0026#34;LOCALAPPDATA\u0026#34; =\u0026gt; \u0026#34;C:\\\\Users\\\\rmsms\\\\AppData\\\\Local\u0026#34;\r\u0026#34;LOGONSERVER\u0026#34; =\u0026gt; \u0026#34;\\\\\\\\SICKRIGHT\u0026#34;\r\u0026#34;NAVER\u0026#34; =\u0026gt; \u0026#34;e=2.718281\u0026#34;\r\u0026#34;NUMBER_OF_PROCESSORS\u0026#34; =\u0026gt; \u0026#34;16\u0026#34;\r\u0026#34;NVCUDASAMPLES11_5_ROOT\u0026#34; =\u0026gt; \u0026#34;C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v11.5\u0026#34;\r\u0026#34;NVCUDASAMPLES_ROOT\u0026#34; =\u0026gt; \u0026#34;C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v11.5\u0026#34;\r\u0026#34;NVTOOLSEXT_PATH\u0026#34; =\u0026gt; \u0026#34;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NvToolsExt\\\\\u0026#34;\r\u0026#34;ONEDRIVE\u0026#34; =\u0026gt; \u0026#34;C:\\\\Users\\\\rmsms\\\\OneDrive - knu.ac.kr\u0026#34;\r\u0026#34;ONEDRIVECOMMERCIAL\u0026#34; =\u0026gt; \u0026#34;C:\\\\Users\\\\rmsms\\\\OneDrive - knu.ac.kr\u0026#34;\r\u0026#34;ONEDRIVECONSUMER\u0026#34; =\u0026gt; \u0026#34;C:\\\\Users\\\\rmsms\\\\OneDrive\u0026#34;\r\u0026#34;OPENBLAS_MAIN_FREE\u0026#34; =\u0026gt; \u0026#34;1\u0026#34;\r\u0026#34;OPENBLAS_NUM_THREADS\u0026#34; =\u0026gt; \u0026#34;8\u0026#34;\r‚ãÆ =\u0026gt; ‚ãÆ\rjulia\u0026gt; Base.ENV[\u0026#34;JULIA_NUM_THREADS\u0026#34;]\r\u0026#34;16\u0026#34; Environment OS: Windows julia: v1.7.0 https://docs.julialang.org/en/v1/base/base/#Base.ENV\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2499,"permalink":"https://freshrimpsushi.github.io/en/posts/2499/","tags":null,"title":"How to Reference Environment Variables in Julia"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Overview1 2 In gradient descent, the momentum technique involves using all previous gradients when updating parameters. This is its essence and the end of the explanation. However, explanations involving strange update equations, the motivation from physics\u0026rsquo; momentum, setting the mass to $1$ and the initial velocity to $0$, only complicate understanding. This article explains the momentum technique as plainly as possible.\nBuild-Up Let\u0026rsquo;s denote the parameters as $\\boldsymbol{\\theta}$ and the loss function as $L$. The standard gradient descent method updates the parameters iteratively as follows:\n$$ \\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\alpha \\nabla L_{i} $$\nHere, $L_{i} = L(\\boldsymbol{\\theta}_{i})$ represents the loss function calculated in the $i$th iteration. The momentum technique simply adds $\\nabla L_{i-1}$, the gradient of the loss function calculated in the previous iteration.\n$$ \\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\alpha \\nabla L_{i} - \\alpha \\nabla L_{i-1} - \\cdots - \\alpha \\nabla L_{0} $$\nAs iterations progress, to reduce the impact of the gradient and prevent the sum of gradients from diverging, a coefficient $\\beta \\in (0,1)$ is added as follows:\n$$ \\begin{align} \\boldsymbol{\\theta}_{i+1} \u0026amp;= \\boldsymbol{\\theta}_{i} - \\alpha \\nabla L_{i} - \\beta \\alpha \\nabla L_{i-1} - \\cdots - \\beta^{i}\\alpha \\nabla L_{0} \\nonumber \\\\ \u0026amp;= \\boldsymbol{\\theta}_{i} - \\alpha\\sum_{j=0}^{i} \\beta^{j} \\nabla L_{i-j} \\end{align} $$\nDefinition Updating the parameters as in $(1)$ is called the momentum method, and the added term $\\alpha\\sum\\limits_{j=0}^{i} \\beta^{j} \\nabla L_{i-j}$ is referred to as momentum.\nExplanation According to the definition, the momentum method is a generalized form of gradient descent. In fact, gradient descent can be seen as a special case of the momentum method where $\\beta = 0$. The closer $\\beta$ is to $1$, the more it reflects previous gradients, and vice versa when it\u0026rsquo;s closer to $0$.\nGradient descent updates parameters in the direction of the steepest current gradient and is thus a greedy algorithm. The momentum method mitigates this greediness, enabling choices that may not be the best in the short term but are more beneficial in the long run. It also helps prevent sudden and excessive changes in gradient direction.\nObviously, since the magnitude of the gradient used to update parameters is larger compared to standard gradient descent, the momentum method has the advantage of faster convergence. Empirically, it is also known to escape local minima more effectively, similar to how a ball rolling down a hill can overcome small bumps if it has enough speed.\nIt is important to note that there is no absolute superiority among these optimizers, including adaptive learning rate techniques. The optimal optimizer varies by field and task, so it\u0026rsquo;s unwise to ask or judge which is the best. It\u0026rsquo;s helpful to learn what is commonly used in your field, or if unsure, to try SGD+momentum or Adam.\nNesterov Momentum To summarize the momentum method: to obtain the next parameter $\\boldsymbol{\\theta}_{i+1}$, the current gradient $\\alpha \\nabla L(\\boldsymbol{\\theta}_{i})$ is cumulatively added to the current parameter $\\boldsymbol{\\theta}_{i}$.\nNesterov momentum, or Nesterov accelerated gradient (NAG), computes the gradient at \u0026ldquo;the current parameter plus the previous gradient\u0026rdquo; and adds this to the current parameter to obtain the next one. This might sound complicated, but if you understand the momentum method, the following algorithm may make Nesterov momentum easier to grasp.\nAlgorithm Let\u0026rsquo;s denote the momentum term as $\\mathbf{p}$.\nAlgorithm: Momentum Method Input Learning rate $\\alpha$, momentum parameter $\\beta$, epochs $N$ 1. Initialize parameters $\\boldsymbol{\\theta}$ to random values. 2. Initialize momentum $\\mathbf{p} = \\mathbf{0}$. 3. for $k = 1, \\cdots, N$ do 4. $\\mathbf{p} \\leftarrow \\beta \\mathbf{p} - \\alpha \\nabla L(\\boldsymbol{\\theta})$ # Update momentum with calculated gradient 5. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\mathbf{p}$ # Update parameters 6. end for Algorithm: Nesterov Momentum Input Learning rate $\\alpha$, momentum parameter $\\beta$, epochs $N$ 1. Initialize parameters $\\boldsymbol{\\theta}$ to random values. 2. Initialize momentum $\\mathbf{p} = \\mathbf{0}$. 3. for $k = 1, \\cdots, N$ do 4. $\\mathbf{p} \\leftarrow \\beta \\mathbf{p} - \\alpha \\nabla L(\\boldsymbol{\\theta} + \\beta \\mathbf{p})$ # Update momentum with calculated gradient 5. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\mathbf{p}$ # Update parameters 6. end for Looking at the first few calculations of both methods, we can represent it as follows. If we simply denote $\\mathbf{p}_{i} = \\alpha \\nabla L_{i}$, and $\\mathbf{p}^{i} = \\alpha \\nabla L(\\boldsymbol{\\theta}_{i} - \\beta^{1}\\mathbf{p}^{i-1} - \\beta^{2}\\mathbf{p}^{i-2} - \\cdots - \\beta^{i}\\mathbf{p}^{0})$ (here $\\mathbf{p}^{0} = \\mathbf{p}_{0}$), then\nMomentum Nesterov Momentum $\\boldsymbol{\\theta}\\_{0} =$ initial\r$\\boldsymbol{\\theta}\\_{0} =$ initial\r$\\boldsymbol{\\theta}\\_{1} = \\boldsymbol{\\theta}\\_{0} - \\alpha \\nabla L\\_{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{0} - \\mathbf{p}\\_{0}$\r$\\boldsymbol{\\theta}\\_{1} = \\boldsymbol{\\theta}\\_{0} - \\alpha \\nabla L\\_{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{0} - \\mathbf{p}^{0}$\r$\\boldsymbol{\\theta}\\_{2} = \\boldsymbol{\\theta}\\_{1} - \\alpha\\nabla L\\_{1} - \\beta \\mathbf{p}\\_{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{1} - \\mathbf{p}\\_{1} - \\beta \\mathbf{p}\\_{0}$\r$\\boldsymbol{\\theta}\\_{2} = \\boldsymbol{\\theta}\\_{1} - \\alpha \\nabla L(\\boldsymbol{\\theta}\\_{1} - \\beta \\mathbf{p}^{0}) - \\beta \\mathbf{p}^{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{1} - \\mathbf{p}^{1} - \\beta \\mathbf{p}^{0}$\r$\\boldsymbol{\\theta}\\_{3} = \\boldsymbol{\\theta}\\_{2} - \\mathbf{p}\\_{2} - \\beta \\mathbf{p}\\_{1} - \\beta^{2} \\mathbf{p}\\_{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{2} - \\sum\\limits\\_{j=0}^{2}\\beta^{j}\\mathbf{p}\\_{2-j}$\r$\\boldsymbol{\\theta}\\_{3} = \\boldsymbol{\\theta}\\_{2} - \\alpha \\nabla L(\\boldsymbol{\\theta}\\_{2} - \\beta \\mathbf{p}^{1} - \\beta^{2}\\mathbf{p}^{0}) - \\beta \\mathbf{p}^{1} - \\beta^{2}\\mathbf{p}^{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{2} - \\mathbf{p}^{2} - \\beta \\mathbf{p}^{1} - \\beta^{2} \\mathbf{p}^{0}$\r$$\\vdots$$\r$$\\vdots$$\r$\\boldsymbol{\\theta}\\_{i+1} = \\boldsymbol{\\theta}\\_{i} - \\sum\\limits\\_{j=0}^{i}\\beta^{j}\\mathbf{p}\\_{i-j}$\r$\\boldsymbol{\\theta}\\_{i+1} = \\boldsymbol{\\theta}\\_{i} - \\sum\\limits\\_{j=0}^{i}\\beta^{j}\\mathbf{p}^{i-j}$\rIan Goodfellow, Deep Learning, Ch 8.3.2 Momentum, 8.3.3 Nesterov Momentum\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nO Ilseok, Machine Learning (2017), Ch 5.3 Momentum\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3528,"permalink":"https://freshrimpsushi.github.io/en/posts/3528/","tags":null,"title":"Momentum Method in Gradient Descent"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 In a fixed subset $D \\subset \\mathbb{R}^{r}$ of Euclidean space , consider a space process $\\left\\{ Y(s) \\right\\}_{s \\in D}$ which is a set of random variables $Y(s) : \\Omega \\to \\mathbb{R}^{1}$ and a direction vector $\\mathbf{h} \\in \\mathbb{R}^{r}$. Specifically, represent $n \\in \\mathbb{N}$ sites as $\\left\\{ s_{1} , \\cdots , s_{n} \\right\\} \\subset D$, and assume that $Y(s)$ has variance existing for all $s \\in D$. The following defined $2 \\gamma ( \\mathbf{h} )$ is called a Variogram. $$ 2 \\gamma ( \\mathbf{h} ) := E \\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right]^{2} $$ Especially, half of the variogram $\\gamma ( \\mathbf{h} )$ is called a Semivariogram.\nExplanation Definition of Regular Spatial Process:\nIf in all $s \\in D$, $\\mu (s)$ is a constant function $\\mu (s) := \\mu$ and both belong to $D$ for all $\\mathbf{h}$ such that the covariance is expressed as a function of $\\mathbf{h}$ only $C : \\mathbb{R}^{r} \\to \\mathbb{R}$, regardless of $s$, through some function $C$ then $\\left\\{ Y(s) \\right\\}$ is said to have Weak Stationarity. $$ \\text{Cov} \\left( Y (s) , Y \\left( s + \\mathbf{h} \\right) \\right) = C \\left( \\mathbf{h} \\right) $$ Here, $C$ is called the Covariance Function or Covariogram. If the mean of $\\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right]$ is $0$ and the variance depends only on $\\mathbf{h}$ then $\\left\\{ Y(s) \\right\\}$ is said to have Intrinsic Stationarity. $$ \\begin{align*} E \\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right] =\u0026amp; 0 \\\\ \\text{Var} \\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right] =\u0026amp; 2 \\gamma ( \\mathbf{h} ) \\end{align*} $$ Intrinsic Stationarity Just seeing from the definition, although the variogram $2 \\gamma ( \\mathbf{h} ) = E \\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right]^{2}$ is a function that depends also on $s$, it‚Äôs usually assumed that the given space process is intrinsically stationary. Conversely, because the definition of intrinsic stationarity itself doesn‚Äôt depend on $s$, these two cannot be thought of separately.\nWeak Stationarity It is natural to call $C \\left( \\mathbf{h} \\right)$ the covariance function in the definition of weak stationarity, and the reason why it is specifically called a Covariogram despite it can be defined alone without $\\gamma$ is due to the following relationship.\nTheorem For a weakly stationary spatial process $\\left\\{ Y (s) \\right\\}_{s \\in D}$, the semivariogram $\\gamma \\left( \\mathbf{h} \\right)$ and the covariogram $C \\left( \\mathbf{h} \\right)$ satisfy the following. $$ \\text{Var} Y = \\gamma \\left( \\mathbf{h} \\right) + C \\left( \\mathbf{h} \\right) $$\nProof Following the weak stationarity of the space process $\\left\\{ Y \\right\\}$, by substituting the zero vector into the direction vector $\\mathbf{h} \\in \\mathbb{R}^{r}$ in $\\text{Cov} \\left( Y (s) , Y \\left( s + \\mathbf{h} \\right) \\right) = C \\left( \\mathbf{h} \\right)$, we obtain the following. $$ C \\left( \\mathbf{0} \\right) = \\text{Cov} \\left( Y (s) , Y (s) \\right) = \\text{Var} Y (s) $$\nRelationship of Stationarity: A strongly stationary spatial process is a weakly stationary spatial process, and a weakly stationary spatial process is intrinsic. $$ \\text{Strong} \\implies \\text{Weak} \\implies \\text{Intrinsic} $$\nMeanwhile, since a weakly stationary spatial process is intrinsically stationary, for all $\\mathbf{h} \\in \\mathbb{R}^{r}$ $$ \\text{Var} \\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right] = 2 \\gamma ( \\mathbf{h} ) $$ holds. If we unravel this backwards, $$ \\begin{align*} \u0026amp; 2 \\gamma \\left( \\mathbf{h} \\right) \\\\ =\u0026amp; \\text{Var} \\left[ Y \\left( s + \\mathbf{h} \\right) - Y (s) \\right] \\\\ =\u0026amp; \\text{Var} \\left[ Y \\left( s + \\mathbf{h} \\right) \\right] + \\text{Var} \\left[ Y (s) \\right] - 2 \\text{Cov} \\left[ Y \\left( s + \\mathbf{h} \\right) , Y (s) \\right] \\\\ =\u0026amp; \\text{Cov} \\left[ Y \\left( s + \\mathbf{h} \\right) , Y \\left( s + \\mathbf{h} \\right) \\right] + \\text{Cov} \\left[ Y (s) , Y (s) \\right] - 2 \\text{Cov} \\left[ Y \\left( s + \\mathbf{h} \\right) , Y (s) \\right] \\\\ =\u0026amp; C ( \\mathbf{0} ) + C ( \\mathbf{0} ) - 2 C ( \\mathbf{h} ) \\\\ =\u0026amp; 2 \\left[ C ( \\mathbf{0} ) - C ( \\mathbf{h} ) \\right] \\\\ =\u0026amp; 2 \\left[ \\text{Var} Y - C ( \\mathbf{h} ) \\right] \\end{align*} $$ thus, we obtain the following equality. $$ \\gamma \\left( \\mathbf{h} \\right) = \\text{Var} Y - C \\left( \\mathbf{h} \\right) $$\n‚ñ†\nSee Also Isotropic Variogram: When the variogram does not depend on direction and only on distance, we say the variogram is isotropic. Semivariogram Models: When the semivariogram is isotropic, plotting the scatter diagram with x-axis as $d := \\left\\| \\mathbf{h} \\right\\|$ and y-axis as $\\gamma (h)$ and fitting it to a specific model can give a sense of how variance changes with distance. It\u0026rsquo;s from this graphical examination that $2 \\gamma$ and $C$ are called Variograms. Empirical Variogram $\\gamma^{\\ast}$: In actual data, there may not be many observations that exactly match $\\mathbf{h}$. Before analysis, it\u0026rsquo;s advisable to look into whether the data meets certain assumptions through $\\gamma^{\\ast}$. Banerjee. (2015). Hierarchical Modeling and Analysis for Spatial Data(2nd Edition): p24.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2498,"permalink":"https://freshrimpsushi.github.io/en/posts/2498/","tags":null,"title":"Definition of Variogram"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, you can easily use a progress bar to indicate the progress of a program.\nCode ProgressMeter.jl By placing the @showprogress macro from the ProgressMeter.jl package in a for loop, you can display the progress1.\nusing ProgressMeter chi2 = [] @showprogress for n in 1:20000 push!(chi2, sum(randn(n) .^ 2)) end Compared to ProgressBars.jl below, the use of a macro makes the code more concise.\nProgressBars.jl You can wrap the iterator of a for loop with the ProgressBar() function from the ProgressBars.jl package2.\nusing ProgressBars chi2 = [] for n in ProgressBar(1:20000) push!(chi2, sum(randn(n) .^ 2)) end Regardless of the actual task, the progress of the program is beautifully displayed. Naturally, since it only indicates which iteration the for loop is currently on, it can only provide the average execution time per iteration, not an accurate prediction of the total time required.\nEnvironment OS: Windows julia: v1.7.3 https://github.com/timholy/ProgressMeter.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/cloud-oak/ProgressBars.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2497,"permalink":"https://freshrimpsushi.github.io/en/posts/2497/","tags":null,"title":"How to use progress bars in Julia"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definitions 1 Consider a spatial process $\\left\\{ Y(s) \\right\\}_{s \\in D}$ and direction vector $\\mathbf{h} \\in \\mathbb{R}^{r}$, which is a set of random variables $Y(s) : \\Omega \\to \\mathbb{R}^{1}$ in a fixed subset $D \\subset \\mathbb{R}^{r}$ of Euclidean space. Specifically, represent $n \\in \\mathbb{N}$ number of sites as $\\left\\{ s_{1} , \\cdots , s_{n} \\right\\} \\subset D$, and assume that $Y(s)$ has a variance for all $s \\in D$.\n$\\left\\{ Y(s) \\right\\}$ is said to have strong stationarity if the distribution of the following two random vectors is the same for all $\\left\\{ s_{1} , \\cdots , s_{n} \\right\\}$ and all $\\mathbf{h}$. $$ \\left( Y \\left( s_{1} \\right) , \\cdots , Y \\left( s_{n} \\right) \\right) \\\\ \\left( Y \\left( s_{1} + \\mathbf{h} \\right) , \\cdots , Y \\left( s_{n} + \\mathbf{h} \\right) \\right) $$ $\\left\\{ Y(s) \\right\\}$ is considered to have weak stationarity if for all $s \\in D$, $\\mu (s)$ is a constant function $\\mu (s) := \\mu$ and both $s , s + \\mathbf{h}$ belong to $D$, and the covariance for all $\\mathbf{h}$ can be expressed as a function of $\\mathbf{h}$ only, independently from $s$, as some function $C$. $$ \\text{Cov} \\left( Y (s) , Y \\left( s + \\mathbf{h} \\right) \\right) = C \\left( \\mathbf{h} \\right) $$ Here, we call $C$ a covariance function or variogram, and especially when $\\left\\| \\mathbf{h} \\right\\| \\to \\infty$, if $C \\left( \\mathbf{h} \\right) \\to 0$ then $\\left\\{ Y(s) \\right\\}$ is said to be ergodic. If the mean of $\\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right]$ is $0$ and its variance depends only on $\\mathbf{h}$, then $\\left\\{ Y(s) \\right\\}$ is said to have intrinsic stationarity. $$ \\begin{align*} E \\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right] =\u0026amp; 0 \\\\ \\text{Var} \\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right] =\u0026amp; 2 \\gamma ( \\mathbf{h} ) \\end{align*} $$ $2 \\gamma \\left( \\mathbf{h} \\right)$ is called a variogram. Theorems Strong stationary spatial processes are weak stationary, and weak stationary processes are intrinsic. $$ \\text{Strong} \\implies \\text{Weak} \\implies \\text{Intrinsic} $$ Furthermore, if the random vector $\\left( Y \\left( s_{1} \\right) , \\cdots , Y \\left( s_{n} \\right) \\right)$ follows a multivariate normal distribution for all $\\left\\{ s_{1} , \\cdots , s_{n} \\right\\}$, then $\\left\\{ Y(s) \\right\\}$ is Gaussian. A necessary and sufficient condition for a weak stationary spatial process to be strong stationary is for the spatial process to be Gaussian. $$ \\text{Strong} \\overset{\\text{gaussian}}{\\impliedby} \\text{Weak} $$\nExplanation Why Stationarity is Necessary Just as stationarity in time series analysis became a common assumption for various models, stationarity in spatial processes refers to properties that logically must be satisfied before analyzing spatial data. If stationarity cannot be assumed, analysis becomes meaningless in many cases.\nStrong stationarity is essentially stationarity itself without doubt. The issue is, even though this might be true stationarity in theory, it might be hard to find examples in reality, thus a retreat to the compromised condition of weak stationarity might be necessary. Weak stationarity compromises that it\u0026rsquo;s alright if not all distributions at each site are known, at least the mean is constant and its covariance depends only on relative distance and direction $\\mathbf{h}$. The term intrinsic stationarity might be unfamiliar only to those who have studied statistics, but it\u0026rsquo;s called \u0026lsquo;intrinsic\u0026rsquo; as its definition is similar to the viewpoint that the observed differences between two points depend solely on $\\mathbf{h}$. Definition of an intrinsic function: In differential geometry, a function that depends only on the coefficients of the first fundamental form $g_{ij}$, not on the unit normal $\\mathbf{n}$, is called intrinsic.\nErgodicity While the pronunciation of Ergodic is closer to [ÏóòÍ∞ÄÎîï] in Korean, let\u0026rsquo;s not dwell on it.\nThat a spatial process is ergodic, i.e., $$ \\lim_{\\left\\| \\mathbf{h} \\right\\| \\to \\infty} C \\left( \\mathbf{h} \\right) = 0 $$ suggests that regardless of direction, as the distance between two sites increases, their correlation decreases. This is a fairly logical assumption. Not all data may be ergodic, but intuitively, it\u0026rsquo;s common for relationships to weaken as they become more distant, unless $C \\left( \\mathbf{h} \\right)$ has periodicity or is an exceptionally unique case. It seems plausible to expect at least up to $C \\left( \\mathbf{h} \\right) \\searrow \\varepsilon$ in a limit sense.\nErgodicity in stochastic processes, generally considered dependent on time $t$, approaches the concept in a manner similar to how, after a long time ($t \\to \\infty$), a specific state returns to its initial state. Similarly, in spatial processes, it deals with how their correlation decreases beyond a distant range ($\\left\\| \\mathbf{h} \\right\\| \\to \\infty$) instead of over time. Although many fields explain ergodicity in connection with time and initial states, it\u0026rsquo;s not an entirely forced naming.\nSee Also Stationarity in Time Series Analysis Intrinsic Functions in Differential Geometry Ergodicity in Stochastic Processes Banerjee. (2003). Hierarchical Modeling and Analysis for Spatial Data: p23~24.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2496,"permalink":"https://freshrimpsushi.github.io/en/posts/2496/","tags":null,"title":"Stationarity of Spatial Processes"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview R language has options within functions like sum() or mean() to ignore missing values directly, whereas Julia lacks such options but actively employs Functional Programming approaches instead.\nCode julia\u0026gt; data = [0,1,2,3,0]\r5-element Vector{Int64}:\r0\r1\r2\r3\r0\rjulia\u0026gt; sum(data) / length(data)\r1.2\rjulia\u0026gt; sum(data) / sum(!iszero, data)\r2.0 The top portion results in 1.2, dividing by the total number of samples including up to $0$, while the bottom portion achieves 2.0 by dividing by the number of samples counted excluding $0$ values using the !iszero function as an argument. What could be considered more powerful than R is that numerous exception handling functions like isnan(), isinf(), ismissing(), etc., can be used in the same manner without relying on the function\u0026rsquo;s own options, and customization is flexible.\nWhile there isn\u0026rsquo;t a significant performance difference, if the return of is~ series functions is strictly Boolean, then it wouldn\u0026rsquo;t matter if the denominator\u0026rsquo;s sum() is changed to count().\nEnvironment OS: Windows julia: v1.7.0 ","id":2495,"permalink":"https://freshrimpsushi.github.io/en/posts/2495/","tags":null,"title":"Calculating the Mean Excluding 0 or Missing Values in Julia"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 Especially when it is $r \u0026gt; 1$, for a fixed subset $D \\in \\mathbb{R}^{r}$ of the Euclidean space, the following set of $p$-variate random vectors $Y(s) : \\Omega \\to \\mathbb{R}^{p}$ is also referred to as a Spatial Process. $$ \\left\\{ Y(s) : s \\in D \\right\\} $$ Especially when the spatial process is a finite set and represented as a vector like the following, it is also referred to as a Random Field. $$ \\left( Y \\left( s_{1} \\right) , \\cdots , Y \\left( s_{n} \\right) \\right) $$\nDescription Especially when dealing with spatial data including point-referenced data, $Y(s)$ is assumed to be continuously sampled with respect to $s$, but the actual realization $D = \\left\\{ s_{1} , \\cdots , s_{n} \\right\\}$ would be a finite set.\nIn undergraduate courses on stochastic processes, one commonly studies only such stochastic processes concerning $r = p = 1$ and $[ 0 , \\infty ) \\subset \\mathbb{R}$. $$ \\left\\{ Y_{t} : t \\in [ 0 , \\infty ) \\right\\} $$ If one has been introduced to stochastic processes only as a backdrop to time-series data, the definition of spatial processes might be somewhat perplexing. In reality, the general definition of a stochastic process as \u0026lsquo;a set of random elements\u0026rsquo; is sufficient, so there\u0026rsquo;s no reason not to consider $\\left\\{ Y(s) \\right\\} _{s \\in D}$ a stochastic process.\nRather than strictly calling spatial processes a generalization of temporal processes, it\u0026rsquo;s more accurate to say they were never distinctly separated to begin with. If this is hard to grasp, it might help to remember that the 1-dimensional axis of time $\\mathbb{R}^{1}$ when dealing with time-series is indeed a genuine Euclidean space. Thinking it over, the term \u0026lsquo;process\u0026rsquo; following the flow of time $t \\in \\mathbb{R}$ didn\u0026rsquo;t quite align with everyday language, so there‚Äôs no need to feel uneasy about the term \u0026lsquo;spatial process\u0026rsquo;.\nBanerjee. (2003). Hierarchical Modeling and Analysis for Spatial Data: p23.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2494,"permalink":"https://freshrimpsushi.github.io/en/posts/2494/","tags":null,"title":"Spatial Processes"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Question Electromagnetism is literally the study of electric fields $\\mathbf{E}$ and magnetic fields $\\mathbf{B}$. While studying electromagnetism, one might have wondered the following at least once.\nWhy is the symbol for magnetic fields $\\mathbf{B}$ used?\nIt's understandable that the electric field is $\\mathbf{E}$, derived from the Electric field, but why is the magnetic field $\\mathbf{B}$ when it should be from Magnetic field? This notation might feel oddly placed, and it's because it was decided without any significant reason.\rAnswer Maxwell\u0026rsquo;s Notation1 2 Maxwell, often called the father of electromagnetism, completed classical electromagnetism3 with Maxwell\u0026rsquo;s equations. Like Newton, Leibniz, Euler, and other individuals who made significant achievements in mathematics/science, not only their names and accomplishments but also their notations have been passed down to future generations. This is true for Maxwell as well; the notation of using $\\mathbf{B}$ for magnetic fields and $\\mathbf{H}$ for auxiliary fields has naturally continued because Maxwell noted them this way.\nThe symbols for various vectors used by Maxwell in electromagnetism4 are as follows.5 Maxwell denoted these vectors with alphabets from A to J, and in cases where there were appropriate symbols like C, D, F, he assigned them, while the rest were seemingly chosen at his discretion.\nNotation\rMeaning\rMaxwell\rToday\r$\\frak{A}$$(A)$\r$\\mathbf{A}$\rThe electromagnetic momentum at a point\rCurrently known as vector potential.\r$\\frak{B}$$(B)$\r$\\mathbf{B}$\rThe magnetic induction\rNowadays referred to as the magnetic field.\r$\\frak{C}$$(C)$\r$I$\rThe (total) electric 'C'urrent, current\r$\\frak{D}$$(D)$\r$\\mathbf{D}$\rThe electric 'D'isplacement, displacement field\r$\\frak{E}$$(E)$\r$\\mathcal{E}$\rThe 'E'lectromotive intensity\rToday called electromotive force, emf.\r$\\frak{F}$$(F)$\r$\\mathbf{F}$\rThe mechanical 'F'orce\rCurrently known as Lorentz force.\r$\\frak{G}$$(G)$\rThe velocity of a point\r$\\frak{H}$$(H)$\r$\\mathbf{H}$\rThe magnetic force\rToday, this is referred to as the H-field, auxiliary field, magnetic field intensity, etc.\r$\\frak{I}$$(I)$\r$\\mathbf{M}$\rThe 'I'ntensity of magnetization\rSeems to be what is called magnetization density today.\r$\\frak{J}$$(J)$\r$\\mathbf{J}$\rThe current of conduction, conduction current\rMost of these notations are still used today, with the current being denoted as $I$, following the initial of the intensity of current.\nFurthermore, upon researching, one may find the argument that \u0026rsquo;the symbol for magnetic fields comes from Biot in the Biot-Savart law\u0026rsquo; but, in my opinion, that\u0026rsquo;s debatable. Firstly, the question \u0026lsquo;Why is the symbol for magnetic fields $\\mathbf{B}$?\u0026rsquo; is equivalent to asking \u0026lsquo;Why do we use $\\mathbf{B}$ as the symbol for magnetic fields today?\u0026rsquo;, so the answer \u0026lsquo;Because Maxwell used it that way\u0026rsquo; seems valid. Then that aside, one might wonder, \u0026lsquo;Did Maxwell choose $\\mathbf{B}$ for the magnetic field symbol because it was named after Biot?\u0026rsquo;. There doesn\u0026rsquo;t seem to be a concrete basis for this answer either. Even if it were, it wouldn\u0026rsquo;t be because it was named after Biot\u0026rsquo;s name but rather \u0026lsquo;Among the vectors listed above, the one that best fits the symbol $\\mathbf{B}$ is magnetic induction, related to the Biot-Savart law\u0026rsquo; might be a more fitting explanation. (Honestly, the claims that it was derived from Biot, bi-polar field, boreal, etc., seem like a stretch to me)\nBetween B and H, What is the Magnetic Field? Meanwhile, there\u0026rsquo;s also discussion on whether $\\mathbf{B}$ or $\\mathbf{H}$ should be called the magnetic field. $\\mathbf{H}$ is a value that can be adjusted in experiments regardless of the medium. Hence, in engineering-related areas (for example, electrical engineering textbooks), $\\mathbf{H}$ is commonly referred to as the magnetic field, whereas in physics-related areas, $\\mathbf{B}$ is typically called the magnetic field. However, as explained in the Wikipedia article on magnetic fields, since $\\mathbf{B}$ mediates the Lorentz force, it appears consistent and logical to call $\\mathbf{E}$ the electric field, similarly $\\mathbf{B}$ should be referred to as the magnetic field.\n$$ \\text{Lorentz force}: \\mathbf{F}=Q\\left[ \\mathbf{E} + (\\mathbf{v}\\times\\mathbf{B}) \\right] $$\nhttps://www.johndcook.com/blog/2012/02/12/why-magnetic-field-b/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.cantorsparadise.com/why-the-symbol-for-magnetic-field-is-b-e40658e17ece\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nNot considering quantum mechanical phenomena\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWritten in FrakturFraktur typeface.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMaxwell, James Clerk. A treatise on electricity and magnetism. Vol. 2. Oxford: Clarendon Press, 1873. page 257\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3523,"permalink":"https://freshrimpsushi.github.io/en/posts/3523/","tags":null,"title":"ÏûêÍ∏∞Ïû•Ïùò Í∏∞Ìò∏Î°ú BÎ•º ÏÇ¨Ïö©ÌïòÎäî Ïù¥Ïú†"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview This brief introduction presents the GLM.jl package for conducting regression analysis in Julia, emphasizing its similarity to the interface in R and thus, skipping detailed explanations1.\nCode Julia using GLM, RDatasets\rfaithful = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;faithful\u0026#34;)\rout1 = lm(@formula(Waiting ~ Eruptions), faithful) The result of running the above code is as follows:\njulia\u0026gt; out1 = lm(@formula(Waiting ~ Eruptions), faithful)\rStatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\rWaiting ~ 1 + Eruptions\rCoefficients:\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\rCoef. Std. Error t Pr(\u0026gt;|t|) Lower 95% Upper 95%\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r(Intercept) 33.4744 1.15487 28.99 \u0026lt;1e-84 31.2007 35.7481\rEruptions 10.7296 0.314753 34.09 \u0026lt;1e-99 10.11 11.3493\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Compare this with the results from regression analysis in R.\nComparison with R out1\u0026lt;-lm(waiting~eruptions,data=faithful); summary(out1) out1 = lm(@formula(Waiting ~ Eruptions), faithful) The above is the code in R, and below is the code in Julia. The @formula macro was used to input variables, almost perfectly replicating the convention in R.\nEnvironment OS: Windows julia: v1.7.0 GLM v1.8.0 See Also How to perform regression analysis in R https://juliastats.org/GLM.jl/v0.11/index.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2493,"permalink":"https://freshrimpsushi.github.io/en/posts/2493/","tags":null,"title":"How to Perform Regression Analysis in Julia"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Explanation 1 Spatial Data refers to data that includes information about space, and Spatial Statistics is a branch of statistics that analyzes Euclidean space $\\mathbb{R}^{r}$ as \u0026lsquo;space\u0026rsquo; in the true dictionary sense. While time series analysis analyses data that changes over the time axis $t$, spatial data analysis analyses data that changes depending on the given $D \\subset \\mathbb{R}^{r}$, (usually when $r = 2$) location.\nEven at first thought, the variety of data is diverse compared to time series data since the axis describing the data increases to $r \u0026gt; 1$. Spatial data can fundamentally be classified into the following three main types.\nPoint Reference Data Point-referenced Data assumes that points $s \\in Y$ at fixed $D \\subset \\mathbb{R}^{r}$ locations change continuously and represents most data given coordinates as a random vector $Y(s)$. The example above shows concentrations measured at PM2.5 monitoring stations displayed on a map according to coordinates.\nPoint reference data is also called Geostatistical Data.\nAreal Data Areal Data, like point reference data, has fixed $D \\subset \\mathbb{R}^{r}$ but differs as it is divided into finite partitions within it. Point reference data might seem universally applicable, but it expresses administrative divisions defined by human society instead of coordinates, such as city, county, ward, town, and neighborhood. The example above shows poverty levels based on irregularly shaped partitions rather than coordinates.\nAreal Data, when the $D$ partition is regular in shape, meaning cut neatly and uniformly unlike the example, is also referred to as Lattice data.\nPoint Pattern Data Point Pattern Data refers to data for which the $D \\subset \\mathbb{R}^{r}$ itself is random, unlike the previous two types. Especially for all $s \\in D$ when $Y(s) = 1$, point pattern data will only convey the fact that an event occurred at each location. The example above is a commonly referenced illustration when explaining survivorship bias, indicating which parts of American fighter planes returning from World War II were damaged.2 In this case, the locations of damage aren‚Äôt predetermined like monitoring stations or administrative divisions but change, and the \u0026lsquo;damage\u0026rsquo; is the event in point pattern data.\nBanerjee. (2003). Hierarchical Modeling and Analysis for Spatial Data: p16~18.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.andrewahn.co/silicon-valley/survivorship-bias/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2492,"permalink":"https://freshrimpsushi.github.io/en/posts/2492/","tags":null,"title":"What is Spatial Data Analysis?"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Overview Monte Carlo integration is a numerical approximation method used when calculating the integral of a given function is difficult. Consider the following scenario: For an integrable function $f$ in the given $[0, 1]$or generally $[0, 1]^{n}$, we know the formula of $f(x)$ but calculating its integral is not straightforward. However, we want to calculate the integral $I[f]$ of $f$.\n$$ \\begin{equation} I[f] = \\int_{[0,1]} f(x) dx \\end{equation} $$\nDefinition Monte Carlo integrationMonte Carlo integration is a method to estimate the integral of $f$ by drawing samples $\\left\\{ x_{i} \\right\\}$ from a distribution on $[0, 1]$ as follows:\n$$ I[f] \\approx I_{n}[f] := \\dfrac{1}{n}\\sum_{i=1}^{n} f(x_{i}) $$\nDifference from Riemann Sum The idea of Riemann Sum is to divide the interval $[0,1]$ into $n$ equal parts and get points $\\left\\{ x_{i} = \\frac{i-1}{n} \\right\\}_{i=1}^{n}$, then sum up the function values at these points.\n$$ \\text{mensuration by parts}[f] = \\dfrac{1}{n}\\sum_{i=1}^{n} f(x_{i}) $$\nAt first glance, Monte Carlo integration and Riemann Sum may seem similar, but their meanings are completely different. In Riemann Sum, $\\left\\{ x_{i} \\right\\}$ are points obtained by dividing the interval $[0, 1]$ into $n$ equal parts, whereas in Monte Carlo integration, $x$ represents $n$ samples drawn from the distribution $p(x)$. Thus, the value obtained by Riemann Sum simply represents the area under the graph drawn by $f$, while the value obtained by Monte Carlo integration represents the expectation of $f$.\nProperties The statistical meaning of equation $(1)$ is that \u0026rsquo;the $I[f]$ is equal to the expectation of $f(X)$ when $X$ follows a uniform distribution'.\n$$ X \\sim U(0,1) \\implies I[f] = \\int_{[0,1]} f(x) dx = E\\left[ f(X) \\right] $$\nExpectation Let the random variable $X$ follow a uniform distribution. $I_{n}[f]$ is an unbiased estimator of $I[f]$.\n$$ E\\left[ I_{n}[f] \\right] = I[f] $$\nProof $$ \\begin{align*} E\\left[ I_{n}[f] \\right] \u0026amp;= E\\left[ \\dfrac{1}{n} \\sum\\limits_{i=1}^{n} f(X_{i}) \\right] \\\\ \u0026amp;= \\dfrac{1}{n} \\sum\\limits_{i=1}^{n} E\\left[ f(X_{i}) \\right] \\qquad \\text{by linearity of $E$} \\\\ \u0026amp;= \\dfrac{1}{n} \\sum\\limits_{i=1}^{n} I\\left[ f \\right] \\\\ \u0026amp;= I\\left[ f \\right] \\end{align*} $$\n‚ñ†\nVariance Proof Properties of Variance\n[a] $\\Var (aX) = a^{2} \\Var (X)$\n[b] If $X, Y$ are independent, $\\Var (X + Y) = \\Var(X) + \\Var(Y)$\nLet\u0026rsquo;s denote the variance of $f(X)$ as $\\sigma^{2}$. Then, by the properties of variance:\n$$ \\begin{align*} \\Var \\left[ I_{n}[f] \\right] \u0026amp;= \\Var \\left[ \\dfrac{1}{n} \\sum\\limits_{i=1}^{n} f(X_{i}) \\right] \\\\ \u0026amp;= \\dfrac{1}{n^{2}} \\Var \\left[ \\sum\\limits_{i=1}^{n} f(X_{i}) \\right] \\\\ \u0026amp;= \\dfrac{1}{n^{2}} \\sum\\limits_{i=1}^{n} \\Var \\left[ f(X_{i}) \\right] \\\\ \u0026amp;= \\dfrac{1}{n^{2}} \\sum\\limits_{i=1}^{n} \\sigma^{2} \\\\ \u0026amp;= \\dfrac{\\sigma^{2}}{n} \\end{align*} $$\n‚ñ†\nGeneralization Now consider a function $p(x) \\ge 0$ and $\\int_{[0,1]} p = 1$. Think about the integral $I[fp]$.\n$$ I[fp] = \\int_{[0, 1]}f(x)p(x) dx $$\nThis is the same as the expectation of $f(X)$ for a random variable $X$ with a probability density function $p$. To approximate this value, we can consider the following two methods:\nDraw samples $\\left\\{ x_{i} \\right\\}_{i=1}^{n}$ uniformly and approximate $I[fp]$ as follows: $$ X_{i} \\sim U(0,1) \\qquad I[fp] \\approx \\dfrac{1}{n}\\sum\\limits_{i}f(x_{i})p(x_{i}) $$\nDraw samples $\\left\\{ x_{i} \\right\\}_{i=1}^{n}$ from $p(x)$ and approximate $I[fp]$ as follows: $$ X_{i} \\sim p(x) \\qquad I[fp] = I_{p}[f] \\approx \\dfrac{1}{n}\\sum\\limits_{i}f(x_{i}) $$\nIn other words, 1. is averaging $f(x)p(x)$ by uniform sampling, and 2. is averaging $f(x)$ by sampling from $p(x)$. Among these, the one with smaller variance is 1. Let\u0026rsquo;s simplify the notation as $I = I[fp] = I[fp]$.\nIn case of 1. $$ \\begin{align*} \\sigma_{1}^{2} = \\Var [fp] \u0026amp;= E \\left[ (fp - I)^{2} \\right] \\\\ \u0026amp;= \\int (fp - I)^{2} dx \\\\ \u0026amp;= \\int (fp)^{2} dx - 2I\\int fp dx + I^{2}\\int dx\\\\ \u0026amp;= \\int (fp)^{2} dx - 2I^{2} + I^{2}\\\\ \u0026amp;= \\int (fp)^{2} dx - I^{2}\\\\ \\end{align*} $$\nIn case of 2. $$ \\begin{align*} \\sigma_{2}^{2} = \\Var [f] \u0026amp;= E_{p} \\left[ (f - I)^{2} \\right] \\\\ \u0026amp;= \\int (f - I)^{2}p dx \\\\ \u0026amp;= \\int f^{2}p dx - 2I\\int fp dx + I^{2}\\int pdx\\\\ \u0026amp;= \\int f^{2}p dx - 2I^{2} + I^{2}\\\\ \u0026amp;= \\int f^{2}p dx - I^{2}\\\\ \\end{align*} $$\nHowever, since $0 \\le p \\le 1$, it follows that $f^{2}p \\ge f^{2}p^{2}$. Therefore,\n$$ \\sigma_{1}^{2} \\le \\sigma_{2}^{2} $$\n","id":3515,"permalink":"https://freshrimpsushi.github.io/en/posts/3515/","tags":null,"title":"Monte Carlo Integration"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let‚Äôs say we have two vectors $\\mathbf{x}, \\mathbf{u} \\in \\mathbb{R}^{n}$ as follows.\n$$ \\mathbf{x}=\\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix},\\quad \\mathbf{u}^{T} = \\begin{bmatrix} u_{1} \u0026amp; u_{2} \u0026amp; \\cdots \u0026amp; u_{n} \\end{bmatrix} $$\nFor a real constant $a_{ij} \\in \\mathbb{R} (1\\le i,j \\le n)$, the function $A : \\mathbb{R}^{n} \\times \\mathbb{R}^{n} \\to \\mathbb{R}$, defined as follows, is called the bilinear form.\n$$ A(\\mathbf{u},\\mathbf{x}):=\\sum \\limits_{i,k=1}^{n} a_{ik}u_{i}x_{k} $$\nIn the bilinear form, if the constant $a_{ij} (1\\le i,j \\le n)$ is a complex number and satisfies $a_{ij}=\\overline{a_{ji}}$, it is called the Hermite form.\n$$ A(\\mathbf{u},\\mathbf{x})=\\sum \\limits _{i,k=1} ^{n} a_{ik}u_{i}x_{k} = \\mathbf{u}^{\\ast} A \\mathbf{x} $$\nExplanation Simply put, a Hermitian matrix in the context of bilinear form is when the matrix $A$ is Hermitian.\nLet‚Äôs notate the matrix of constants as follows.\n$$ \\quad A=\\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp;\\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp;\\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{n1} \u0026amp; a_{n2} \u0026amp; \\cdots \u0026amp; a_{nn} \\end{bmatrix} $$\nThen, the bilinear form is expressed as a matrix product, which is also called the bilinear form corresponding to matrix $A$.\n$$ A(\\mathbf{u},\\mathbf{x})=\\sum \\limits_{i,k=1}^{n} a_{ik}u_{i}x_{k}= \\mathbf{u}^{T}A\\mathbf{x} $$\nIf a system of linear equations is given as\n$$ \\begin{cases} a_{11}x_{1}+a_{12}x_{2}+\\cdots +a_{1n}x_{n}\u0026amp;=y_{1} \\\\ a_{21}x_{1}+a_{22}x_{2}+\\cdots +a_{2n}x_{n}\u0026amp;=y_{2} \\\\ \u0026amp;\\vdots \\\\ a_{n1}x_{1}+a_{n2}x_{2}+\\cdots +a_{nn}x_{n}\u0026amp;=y_{n} \\end{cases} $$\nBy multiplying each equation by $u_{i}$ and adding them all together, one can obtain a bilinear form as below. $I$ is the identity matrix.\n$$ A(\\mathbf{u},\\mathbf{x})=\\sum \\limits_{i,k=1}^{n} a_{ik}u_{i}x_{k}=\\sum \\limits_{i=1}^{n}u_{i}y_{i}=I(\\mathbf{u}, \\mathbf{y}) $$\nQuadratic form is a special case in bilinear form where $\\mathbf{u} = \\mathbf{x}$.\nSee Also Linear form Quadratic form Bilinear form Hermitian form Howard Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p416-417\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3513,"permalink":"https://freshrimpsushi.github.io/en/posts/3513/","tags":null,"title":"Bilinear Forms and Hermitian Forms"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition $V$ is called a $n$dimensional vector space. For a given constant $a_{ij} \\in \\mathbb{R}(\\text{or } \\mathbb{C})$, the following second order homogeneous function $A : V \\to \\mathbb{R}(\\text{or } \\mathbb{C})$ is called a quadratic form.\n$$ A(\\mathbf{x}) := \\sum\\limits_{i,j=1}^{n} a_{ij}x_{i}x_{j},\\qquad (a_{ij} = a_{ji}) $$\nHere, $\\mathbf{x} = \\begin{bmatrix} x_{1} \u0026amp; \\cdots \u0026amp; x_{n} \\end{bmatrix}^{T}$ holds. The term $i \\ne j$ for $a_{ij}x_{i}x_{j}$ is called the cross product terms.\nExplanation According to the definition, $A(\\lambda \\mathbf{x}) = \\lambda^{2} A(\\mathbf{x})$ holds.\nMatrix Form Let $A$ be a $n\\times n$ symmetric matrix $A = \\begin{bmatrix} a_{ij} \\end{bmatrix}$. The quadratic form of matrix $A$, denoted by $Q_{A}(\\mathbf{x})$, is called quadratic form associated with A.\n$$ Q_{A}(\\mathbf{x}) = \\mathbf{x}^{T}A\\mathbf{x} =\\begin{bmatrix} x_{1} \u0026amp; \\cdots \u0026amp;x_{n} \\end{bmatrix} \\begin{bmatrix} a_{11} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{n1} \u0026amp; \\cdots \u0026amp; a_{nn} \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix}=\\sum \\limits _{i=1} ^{n}\\sum \\limits _{j=1} ^{n}a_{ij}x_{i}x_{j} $$\nFor example, the quadratic form on $\\mathbb{R}^{2}$ is as follows.\n$$ \\begin{align*} \u0026amp; a_{11}^{\\ }x_{1}^{2} + a_{22}^{\\ }x_{2}^{2} + a_{12}^{\\ }x_{1}^{\\ }x_{2}^{\\ } + a_{21}^{\\ }x_{2}^{\\ }x_{1}^{\\ } \\\\ =\u0026amp;\\ a_{11}^{\\ }x_{1}^{2} + a_{22}^{\\ }x_{2}^{2} + 2a_{12}^{\\ }x_{1}^{\\ }x_{2}^{\\ } \\end{align*} $$\nThe quadratic form on $\\mathbb{R}^{3}$ is as follows.\n$$ a_{11}^{\\ }x_{1}^{2} + a_{22}^{\\ }x_{2}^{2} + a_{33}^{\\ }x_{3}^{2} + 2a_{12}^{\\ }x_{1}^{\\ }x_{2}^{\\ } + 2a_{13}^{\\ }x_{1}^{\\ }x_{3}^{\\ } + 2a_{23}^{\\ }x_{2}^{\\ }x_{3}^{\\ } $$\nTo avoid repetition, it is common to combine cross terms as shown above. The quadratic form can be represented by the properties of matrix inner product as follows. For real and complex numbers, respectively:\n$$ \\begin{align*} Q_{A}(\\mathbf{x}) \u0026amp;= \\mathbf{x}^{T} A \\mathbf{x} = \\mathbf{x} \\cdot A\\mathbf{x} = A\\mathbf{x} \\cdot \\mathbf{x} = \\left\u0026lt; A\\mathbf{x}, \\mathbf{x}\\right\u0026gt; = \\left\u0026lt; \\mathbf{x}, A \\mathbf{x} \\right\u0026gt; \\\\ Q_{A}(\\mathbf{x}) \u0026amp;= \\mathbf{x}^{\\ast} A \\mathbf{x} = \\mathbf{x} \\cdot A\\mathbf{x} = A\\mathbf{x} \\cdot \\mathbf{x} = \\left\u0026lt; A\\mathbf{x}, \\mathbf{x}\\right\u0026gt; = \\left\u0026lt; \\mathbf{x}, A \\mathbf{x} \\right\u0026gt; \\end{align*} $$\nIf $A$ is a diagonal matrix, then since $a_{ij}=0 (i \\ne j)$ holds, the quadratic form $Q_{A}(\\mathbf{x})$ does not have cross terms.\n$$ Q_{A}(\\mathbf{x}) = \\mathbf{x}^{T}A\\mathbf{x} =\\begin{bmatrix} x_{1} \u0026amp; \\cdots \u0026amp;x_{n} \\end{bmatrix} \\begin{bmatrix} a_{11} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; a_{nn} \\end{bmatrix}\\begin{bmatrix} x_{1} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix}=\\sum \\limits _{i=1}^{n} a_{ii}x_{i}^{2} $$\nSee Also Linear form Quadratic form Bilinear form Hermitian form ","id":3512,"permalink":"https://freshrimpsushi.github.io/en/posts/3512/","tags":null,"title":"Quadratic Form"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition Let a random vector composed of $n \\in \\mathbb{N}$ and $k \\in \\mathbb{N}$ counts of random variables be denoted as $\\left( X_{1} , \\cdots , X_{k} \\right)$. $$ \\sum_{i=1}^{k} X_{i} = n \\qquad \\\u0026amp; \\qquad \\sum_{i=1}^{k} p_{i} = 1 $$ For $\\mathbf{p} = \\left( p_{1} , \\cdots , p_{k} \\right) \\in [0,1]^{k}$ that satisfies this, a multivariate probability distribution $M_{k} \\left( n, \\mathbf{p} \\right)$ with the following probability mass function is called the Multinomial Distribution. $$ p \\left( x_{1} , \\cdots , x_{k} \\right) = {{ n! } \\over { x_{1} ! \\cdots x_{k}! }} p_{1}^{x_{1}} \\cdots p_{k}^{x_{k}} \\qquad , x_{1} , \\cdots , x_{k} \\in \\mathbb{N}_{0} $$\n$[0,1]^{k} = [0,1] \\times \\cdots \\times [0,1]$ is a $k$-cell. $\\mathbb{N}_{0} = \\left\\{ 0 \\right\\} \\cup \\mathbb{N}$ is a set that includes natural numbers and $0$. Description To interpret the definition as it is, $\\left( X_{1} , \\cdots , X_{k} \\right)$ is a random vector indicating how many elements are actually in each category when $n$ elements have a probability $p_{i}$ of falling into the $i$ category among $k$ categories, having a probability mass function of $$ \\begin{align*} p \\left( x_{1} , \\cdots , x_{k} \\right) =\u0026amp; P \\left( X_{1} = x_{1} , \\cdots , X_{k} = x_{k} \\right) \\\\ =\u0026amp; {{ n! } \\over { x_{1} ! \\cdots x_{k}! }} p_{1}^{x_{1}} \\cdots p_{k}^{x_{k}} \\end{align*} $$ Especially, when $k = 2$, it becomes a generalization of the binomial distribution itself.\nBasic Properties Mean and Covariance [1]: If $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{k} \\right) \\sim M_{k} \\left( n, \\mathbf{p} \\right)$, the expected value of the $i$ component $X_{i}$ is $$ E \\left( X_{i} \\right) = n p_{i} $$ and the covariance matrix is as follows. $$ \\text{Cov} \\left( \\mathbf{X} \\right) = n \\begin{bmatrix} p_{1} \\left( 1 - p_{1} \\right) \u0026amp; - p_{1} p_{2} \u0026amp; \\cdots \u0026amp; - p_{1} p_{k} \\\\ - p_{2} p_{1} \u0026amp; p_{2} \\left( 1 - p_{2} \\right) \u0026amp; \\cdots \u0026amp; - p_{2} p_{2} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ - p_{k} p_{1} \u0026amp; - p_{k} p_{2} \u0026amp; \\cdots \u0026amp; p_{k} \\left( 1 - p_{k} \\right) \\end{bmatrix} $$ Theorem Lumping Property For $i \\ne j$, $X_{i} + X_{j}$ follows the binomial distribution $\\text{Bin} \\left( n , p_{i} + p_{j} \\right)$. $$ X_{i} + X_{j} \\sim \\text{Bin} \\left( n , p_{i} + p_{j} \\right) $$ This is called the Lumping Property.\nProof Mean Looking at each component $X_{i}$ alone, it‚Äôs essentially a binomial distribution regarding whether it falls into category $i$ with a probability $p_{i}$ or not, hence $X_{i} \\sim \\text{Bin} \\left( n , p_{i} \\right)$, and its expected value is $E \\left( X_{i} \\right) = n p_{i}$.\n‚ñ†\nCovariance It is directly deduced using the lumping property.\n‚ñ†\nLumping Property 1 In the case of $n = 1$, that is, when considering only a single trial, $X_{i} + X_{j}$ is exactly $1$ when the outcome of that trial belongs to either the $i$ or $j$ category, and follows a Bernoulli distribution $\\text{Bin} \\left( 1, p_{i} + p_{j} \\right)$ which is $0$ in all other cases.\nAddition of Binomial Distributions: Let\u0026rsquo;s assume that the probability variables $X_{1} , \\cdots , X_{n}$ are mutually independent. In the case of binomial distributions, if $X_i \\sim \\text{Bin} ( n_{i}, p)$ is true, $$ \\displaystyle \\sum_{i=1}^{m} X_{i} \\sim \\text{Bin} \\left( \\sum_{i=1}^{m} n_{i} , p \\right) $$\nSince $n$ trials are conducted independently, the following is obtained according to the addition of binomial distributions. $$ X_{i} + X_{j} \\sim \\text{Bin} \\left( \\sum_{j=1}^{n} 1 , p_{i} + p_{j} \\right) = \\text{Bin} \\left( n , p_{i} + p_{j} \\right) $$\n‚ñ†\nhttps://math.stackexchange.com/a/1678138/459895\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2480,"permalink":"https://freshrimpsushi.github.io/en/posts/2480/","tags":null,"title":"Polynomial Distribution"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Buildup Modified Bessel Functions $$ J_{\\nu}(x) = \\sum \\limits_{n=0}^{\\infty} \\frac{(-1)^{n} }{\\Gamma (n+1) \\Gamma (n+\\nu+1)} \\left(\\frac{x}{2} \\right)^{2n+\\nu} $$\nThe $I_{\\nu}$ defined as follows for the Bessel function of the first kind $J_{\\nu}$ is called the modified Bessel function of the first kind1.\n$$ \\begin{align*} I_{\\nu} (z) :=\u0026amp; i^{-\\nu} J_{\\nu} \\left( iz \\right) \\\\ =\u0026amp; \\left( {{ z } \\over { 2 }} \\right)^{\\nu} \\sum_{k=0}^{\\infty} {{ {{ z } \\over { 2 }}^{2k} } \\over { k! \\Gamma \\left( \\nu + k + 1 \\right) }} \\\\ =\u0026amp; {{ \\left( {{ z } \\over { 2 }} \\right)^{\\nu} } \\over { \\sqrt{\\pi} \\Gamma \\left( \\nu + {{ 1 } \\over { 2 }} \\right) }} \\int_{-1}^{1} e^{zt} \\left( 1 - t^{2} \\right)^{\\nu - {{ 1 } \\over { 2 }}} dt \\end{align*} $$\nDirectional Statistics On the other hand, Directional Statistics is a field that studies probability distributions and statistical inferences in manifolds, rather than in the usual Euclidean space. For example, it deals with data placed on spheres like the Earth, represented by Spheres, and on tori reflected by $2 \\pi$ modulus, like Torus, and can be applied to spatial statistics (on spheres) such as the distance between points, as well as to angles between molecules (on tori), showing a bright future for this subdivision. However, the distributions that appear here all have strange probability density functions as follows. $$ f_{p} \\left( \\mathbf{x} ; \\mu , \\kappa \\right) := \\left( {{ \\kappa } \\over { 2 }} \\right)^{p/2 - 1} {{ 1 } \\over { \\Gamma \\left( p/2 \\right) I_{p/2 - 1} \\left( \\kappa \\right) }} \\exp \\left( \\kappa \\mu^{T} \\mathbf{x} \\right) \\qquad , \\mathbf{x} \\in S^{p-1} $$ The complex factor in front is a constant that normalizes $\\int_{S^{p-1}} f d \\mathbf{x} = 1$, including the modified Bessel function of the first kind $I_{\\nu}$. This complex function is used for a simple reason.\nSolutions Derivation of the Bessel Function of the First Kind: For $\\nu \\in \\mathbb{R}$, the differential equation of the following form is called the $\\nu$ order Bessel equation. $$ \\begin{align*} \u0026amp;\u0026amp; x^{2} y^{\\prime \\prime} +xy^{\\prime}+(x^{2}-\\nu^{2})y \u0026amp;= 0 \\\\ \\text{or} \u0026amp;\u0026amp; y^{\\prime \\prime}+\\frac{1}{x} y^{\\prime} + \\left( 1-\\frac{\\nu^{2}}{x^{2}} \\right)y \u0026amp;= 0 \\end{align*} $$ Bessel\u0026rsquo;s equation is a differential equation that appears when solving the wave equation in spherical coordinates. The coefficient is not constant and depends on the independent variable $x$. Solutions can be found using the Frobenius Method, and the series solution looks as follows. $$ \\begin{align*} J_{\\nu}(x) \u0026amp;= \\sum \\limits_{n=0}^{\\infty} \\frac{(-1)^{n} }{\\Gamma (n+1) \\Gamma (n+\\nu+1)} \\left(\\frac{x}{2} \\right)^{2n+\\nu} \\\\ J_{-\\nu}(x) \u0026amp; =\\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}}{\\Gamma (n+1)\\Gamma (n-\\nu+1)} \\left( \\frac{x}{2} \\right)^{2n-\\nu} \\end{align*} $$\nBessel functions and their derivation involve complex expressions, like Bessel equation being one of the differential equations and its solutions. However, in the provided quote about directional statistics, only one sentence is of importance.\n\u0026ldquo;Bessel\u0026rsquo;s equation is a differential equation that appears when solving the wave equation in spherical coordinates.\u0026rdquo;\nIn mathematical physics, there might be discussions about wave equations and such, but what we really need is only $\\int_{S^{p-1}} f d \\mathbf{x} = 1$. The issue is, unlike in ordinary Euclidean space, the probability density function values on the sphere do not experience the phenomenon of \u0026lsquo;getting farther from the center and closer to $0$,\u0026rsquo; making integration itself not an easy task. Imagine the shape covered by the probability density function of the normal distribution wrapping around a circle $S^{1}$.\nLooking at when $\\tau = 1$ in the above figure, the infinitely long tail of the normal distribution is adding infinitely thin layers while circling around $S^{1}$ infinitely, not being $0$. 2 This repeats with $2 \\pi$, twice the pi, as its period, and this is exactly why the Bessel function can be used, as it creates a \u0026lsquo;wave on the sphere\u0026rsquo; like shape.\nSungkyu Jung. \u0026ldquo;Geodesic projection of the von Mises‚ÄìFisher distribution for projection pursuit of directional data.\u0026rdquo; Electron. J. Statist. 15 (1) 984 - 1033, 2021. https://doi.org/10.1214/21-EJS1807\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nStraub, J. (2017). Bayesian Inference with the von-Mises-Fisher Distribution in 3D. https://www.semanticscholar.org/paper/Bayesian-Inference-with-the-von-Mises-Fisher-in-3-D-Straub/26d5bb31153df418388b6eb242b2d8842c039c2d#extracted\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2478,"permalink":"https://freshrimpsushi.github.io/en/posts/2478/","tags":null,"title":"Reasons Why the Modified Bessel Function of the First Kind Appears in Directional Statistics"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Definition 1 For a non-empty subset $A,B \\subset \\mathbb{C}$ of the set of complex numbers $\\mathbb{C}$, $f : A \\to B$ is called a Complex Valued Function. On the other hand, when $A, B \\subset \\mathbb{R}$, $f : A \\to B$ is also referred to as a Real Valued Function to distinguish it from complex functions.\nExplanation The above definition actually means nothing. You might wonder what all this is about, but if you start to nitpick, there are too many details in this definition to quibble over, making it worthless as a definition.\nThe expression Real, Complex Valued Function technically distinguishes whether the \u0026lsquo;value of the function\u0026rsquo; is real or complex, so it seems reasonable to define it regardless of the domain. Just because the codomain is $\\mathbb{C}^{n}$, it‚Äôs not called a complex vector function. Naturally, the corresponding expression for $f : \\mathbb{C} \\to \\mathbb{C}$ is not called a complex scalar function either. It does not call a function both a complex function and a real function just because its domain is real numbers and its codomain is complex numbers, or vice versa. In actuality, although real functions seem to refer to most of the functions encountered from middle and high school, in mathematics departments, many courses and textbooks also call topics related to measure theory simply Real Analysis, which can cause confusion. The point is, the expressions complex function and real function are not used based on strict definitions but follow conventions depending on the context. For example, $f : \\mathbb{C} \\to \\mathbb{C}$ is just called a complex function by everyone, and $f : \\mathbb{R} \\to \\mathbb{C}$ can be called a complex function, but there is a \u0026rsquo;tendency\u0026rsquo; to distinguish it as \u0026lsquo;a function whose value is complex\u0026rsquo;. $f : \\mathbb{C}^{n} \\to \\mathbb{C}^{n}$ is universally called a complex function, but it is rare to call $f : \\mathbb{R}^{n} \\to \\mathbb{R}^{n}$ a real function, mainly because $\\mathbb{C}^{n}$ is meaningful as a generalization of some function or theorem, but $\\mathbb{R}^{n}$ tends to have a strong implication as a vector function.\nOsborne (1999). Complex variables and their applications: p22.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2473,"permalink":"https://freshrimpsushi.github.io/en/posts/2473/","tags":null,"title":"Definition of a Complex Function"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Plots.jl essentially outputs everything including grids, ticks, axes, and color bars by default, but if you want to make it clean without these, you can add the following options.\ncolorbar=:none: Removes the color bar. showaxis = false: Removes the axes and ticks. grid=false: Removes the background grid. ticks=false: Removes both background grid and ticks. framestyle=:none: Removes both background grid and axes. using Plots\rsurface(L, title=\u0026#34;default\u0026#34;)\rsurface(L, title=\u0026#34;colorbar=:none\u0026#34;, colorbar=:none)\rsurface(L, title=\u0026#34;showaxis=false\u0026#34;, showaxis=false)\rsurface(L, title=\u0026#34;grid=false\u0026#34;, grid=false)\rsurface(L, title=\u0026#34;ticks=false\u0026#34;, ticks=false)\rsurface(L, title=\u0026#34;framestyle=:none\u0026#34;, framestyle=:none)\rsurface(L, title=\u0026#34;all off\u0026#34;, ticks=false, framestyle=:none, colorbar=:none) Environment OS: Windows11 Version: Julia v1.8.3, Plots v1.38.6 ","id":3501,"permalink":"https://freshrimpsushi.github.io/en/posts/3501/","tags":null,"title":"How to Neatly Print without Axes, Scales, etc. in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Theorem There is no direct equivalent to the meshgrid() function used in Python and MATLAB. If you only want to obtain the function values on a grid, there is a simpler method that does not require creating a grid.\nCode 2D Multiplying a column vector by a row vector gives the same result as taking the Kronecker product of a column vector and a row vector.\nU(t,x) = sin(œÄ*x)*exp(- œÄ^2 * t)\rx = LinRange(-1., 1, 100)\rt = LinRange(0., 0.35, 200)\u0026#39;\r# Fig. 1\rX = x * fill!(similar(t), 1)\rT = fill!(similar(x), 1) * t\ru1 = U.(T,X)\rheatmap(t\u0026#39;, x, u1, title=\u0026#34;Fig 1\u0026#34;) When using the Kronecker product,\nusing LinearAlgebra\rX = kron(x, ones(size(t)))\rT = kron(ones(size(x)), t)\ru2 = U.(T,X)\rheatmap(t\u0026#39;, x, u2, title=\u0026#34;Fig 2\u0026#34;)\rjulia\u0026gt; u1 == u2\rtrue 3D1 U(x,y,t) = exp(-x^2) * exp(-2y^2) * exp(- œÄ^2 * t)\rx = LinRange(-1., 1, 100)\ry = LinRange(-1., 1, 100)\rt = LinRange(0.,0.35, 50)\rX = getindex.(Iterators.product(x, y, t), 1)\rY = getindex.(Iterators.product(x, y, t), 2)\rT = getindex.(Iterators.product(x, y, t), 3)\ru3 = U.(X,Y,T)\ranim = @animate for i ‚àà 1:50\rsurface(u3[:,:,i], zlims=(0,1), clim=(-1,1), title=\u0026#34;Anim. 1\u0026#34;)\rend Full Code using Plots\rcd = @__DIR__\rU(t,x) = sin(œÄ*x)*exp(- œÄ^2 * t)\rx = LinRange(-1., 1, 100)\rt = LinRange(0., 0.35, 200)\u0026#39;\r# Fig. 1\rX = x * fill!(similar(t), 1)\rT = fill!(similar(x), 1) * t\ru1 = U.(T,X)\rheatmap(t\u0026#39;, x, u1, title=\u0026#34;Fig 1\u0026#34;)\rsavefig(cd*\u0026#34;/fig1.png\u0026#34;)\r# kron\rusing LinearAlgebra\rX = kron(x, ones(size(t)))\rT = kron(ones(size(x)), t)\ru2 = U.(T,X)\rheatmap(t\u0026#39;, x, u2, title=\u0026#34;Fig 2\u0026#34;)\rsavefig(cd*\u0026#34;/fig2.png\u0026#34;)\ru1 == u2\r# 3d\rU(x,y,t) = (1/4) * exp(-x^2) * exp(-2y^2) * exp(- œÄ^2 * t)\rx = LinRange(-2., 2, 100)\ry = LinRange(-2., 2, 100)\rt = LinRange(0.,0.35, 50)\rX = getindex.(Iterators.product(x, y, t), 1)\rY = getindex.(Iterators.product(x, y, t), 2)\rT = getindex.(Iterators.product(x, y, t), 3)\ru3 = U.(X,Y,T)\ranim = @animate for i ‚àà 1:50\rsurface(u3[:,:,i], zlims=(0,0.5), clim=(0,0.3), title=\u0026#34;Anim. 1\u0026#34;)\rend\rgif(anim, cd*\u0026#34;/anim1.gif\u0026#34;, fps=10) Environment OS: Windows11 Version: Julia v1.8.3, Plots v1.38.6 https://discourse.julialang.org/t/meshgrid-function-in-julia/48679/26\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3500,"permalink":"https://freshrimpsushi.github.io/en/posts/3500/","tags":null,"title":"How to Create a Meshgrid in Julia"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition The following is called the Weighted Mean for data $\\mathbf{x} = \\left\\{ x_{1} , \\cdots , x_{n} \\right\\}$ and vector $\\mathbf{w} = \\left( w_{1} , \\cdots , w_{n} \\right) \\in \\mathbb{R}^{n}$. $$ {{ \\sum_{k=1}^{n} w_{k} x_{k} } \\over { \\sum_{k=1}^{n} w_{k} }} = {{ w_{1} x_{1} + \\cdots + w_{n} x_{n} } \\over { w_{1} + \\cdots + w_{n} }} $$ Meanwhile, $\\mathbf{w}$ is also called a weighted vector or simply a weight, and in English, it is just called Weight.\nDescription Weighted Mean is a statistic frequently mentioned in mathematical statistics and various branches of general mathematics. It can be seen as a generalization of the arithmetic mean, where all weights are equal. If $\\mathbf{w} = \\left( a , \\cdots , a \\right) \\ne \\mathbf{0}$, it becomes the widely used sample mean as follows. $$ {{ a x_{1} + \\cdots + a x_{n} } \\over { a + \\cdots + a }} = {{ x_{1} + \\cdots + x_{n} } \\over { n }} $$ If $\\mathbf{x}$ is extended to multiple dimensions, it can be geometrically considered as the centroid of multiple points allowing overlaps. In physics, the center of mass can be defined as a weighted mean where each particle\u0026rsquo;s mass is a weight, as follows. $$ \\mathbf{r}_{cm}=\\frac{m_{1}\\mathbf{r}_{1}+m_{2}\\mathbf{r}_{2}+\\cdots + m_{n}\\mathbf{r}_{n}}{m_{1}+ m_{2}+ \\cdots+ m_{n}}=\\frac{\\sum m_{i}\\mathbf{r}_{i}}{m} $$ In the home ground of statistics, it is difficult to specifically pinpoint an example because there are so many, and it appears so obvious and familiar that it suddenly comes up without any special explanation. For example, the population mean of the combined variance from several populations $s_{p}^{2}$ is as follows. $$ s_{p}^{2} = {{ \\left( n_{1} - 1 \\right) s_{1}^{2} + \\cdots + \\left( n_{m} - 1 \\right) s_{m}^{2} } \\over { \\left( n_{1} - 1 \\right) + \\cdots + \\left( n_{m} - 1 \\right) }} = {{ \\sum_{i=1}^{m} \\left( n_{i} - 1 \\right) s_{i}^{2} } \\over { \\sum_{i=1}^{m} \\left( n_{i} - 1 \\right) }} $$\nExponentially Weighted Average For time series data $\\left\\{ x_{t} \\right\\}_{t=1}^{n}$, the following value is called the exponentially weighted average of $\\left\\{ x_{t} \\right\\}_{t=1}^{n}$. Regarding $\\beta \\in (0,1)$,\n$$ \\begin{align*} \\dfrac{\\beta^{n-1}x_{1} + \\beta^{n-2}x_{2} + \\cdots + \\beta^{0}x_{n}}{\\beta^{n-1} + \\beta^{n-2} + \\cdots + \\beta^{0}} \u0026amp;= (1 - \\beta) \\dfrac{\\beta^{n-1}x_{1} + \\beta^{n-2}x_{2} + \\cdots + \\beta^{0}x_{n}}{1 - \\beta^{n}} \\\\ \u0026amp;= \\dfrac{ (1 - \\beta) \\sum\\limits_{t=1}^{n}\\beta^{n-t}x_{t} }{1 - \\beta^{n}} \\end{align*} $$\nThe first equality is due to the formula for the sum of a geometric sequence. This means adding $x_{t}$s by reducing the weight exponentially for data from further in the past. It is also defined recursively as follows.\n$$ \\begin{align*} y_{0} \u0026amp;= 0 \\\\ y_{t} \u0026amp;= \\beta y_{t-1} + (1-\\beta) x_{t} = (1-\\beta) \\sum\\limits_{j=1}^{t} \\beta^{t-j} x_{j} \\end{align*} $$\nIn this case, as it is a weighted sum, dividing by $(1 - \\beta^{t})$ results in a weighted average.\n$$ \\hat{y}_{t} = \\dfrac{y_{t}}{1 - \\beta^{t}} $$\n","id":2470,"permalink":"https://freshrimpsushi.github.io/en/posts/2470/","tags":null,"title":"Definition of Weighted Average"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Introducing how to broadcast multivariable functions in Julia. Like in Python, you can create a meshgrid, or you can easily calculate by creating vectors for each dimension.\nBivariate Functions $$ u(t,x) = \\sin(\\pi x) e^{-\\pi^{2}t} $$\nTo plot the function $(t,x) \\in [0, 0.35] \\times [-1,1]$ as above, the function values can be calculated like this:\nx = LinRange(-1., 1, 100)\rt = LinRange(0., 0.35, 200)\u0026#39;\ru1 = @. sin(œÄ*x)*exp(- œÄ^2 * t)\rheatmap(t\u0026#39;, x, u1, xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x\u0026#34;, title=\u0026#34;Fig. 1\u0026#34;) After defining the function itself, the same results can be obtained by creating a 2D grid as follows:\nU(t,x) = sin(œÄ*x)*exp(- œÄ^2 * t)\rx = LinRange(-1., 1, 100)\rt = LinRange(0., 0.35, 200)\u0026#39;\rX = x * fill!(similar(t), 1)\rT = fill!(similar(x), 1) * t\ru2 = U.(T,X)\rheatmap(t\u0026#39;, x, u2, xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x\u0026#34;, title=\u0026#34;Fig. 2\u0026#34;) Trivariate Functions $$ u(x,y,t) = e^{-x^{2} - 2y^{2}}e^{-\\pi^{2}t} $$\nIf you want to get the function values of $u$ over the space-time domain $(x,y,t) \\in [-1,1] \\times [-1,1] \\times [0, 0.35]$, you can just create vectors that have dimensions only for each variable and broadcast.\nIf you want to create a 3D mesh and broadcast, see here.\njulia\u0026gt; x = reshape(LinRange(-1., 1, 100), (100,1,1))\r100√ó1√ó1 reshape(::LinRange{Float64, Int64}, 100, 1, 1) with eltype Float64:\rjulia\u0026gt; y = reshape(LinRange(-1., 1, 100), (1,100,1))\r1√ó100√ó1 reshape(::LinRange{Float64, Int64}, 1, 100, 1) with eltype Float64:\rjulia\u0026gt; t = reshape(LinRange(0.,0.35, 200), (1,1,200))\r1√ó1√ó200 reshape(::LinRange{Float64, Int64}, 1, 1, 200) with eltype Float64:\rjulia\u0026gt; u3 = @. exp(-x^2) * exp(-2y^2) * exp(- œÄ^2 * t)\r100√ó100√ó200 Array{Float64, 3}:\ranim = @animate for i ‚àà 1:200\rsurface(u3[:,:,i], zlims=(0,1), clim=(-1,1))\rend Code Details using Plots\rcd = @__DIR__\r# Fig. 1\rx = LinRange(-1., 1, 100)\rt = LinRange(0., 0.35, 200)\u0026#39;\ru1 = @. sin(œÄ*x)*exp(- œÄ^2 * t)\rheatmap(t\u0026#39;, x, u1, xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x\u0026#34;, title=\u0026#34;Fig. 1\u0026#34;)\rsavefig(cd*\u0026#34;/fig1.png\u0026#34;)\r# Fig. 2\rU(t,x) = sin(œÄ*x)*exp(- œÄ^2 * t)\rx = LinRange(-1., 1, 100)\rt = LinRange(0., 0.35, 200)\u0026#39;\rX = x * fill!(similar(t), 1)\rT = fill!(similar(x), 1) * t\ru2 = U.(T,X)\rheatmap(t\u0026#39;, x, u2, xlabel=\u0026#34;t\u0026#34;, ylabel=\u0026#34;x\u0026#34;, title=\u0026#34;Fig. 2\u0026#34;)\rsavefig(cd*\u0026#34;/fig2.png\u0026#34;)\r# gif 1\rx = reshape(LinRange(-1., 1, 100), (100,1,1))\ry = reshape(LinRange(-1., 1, 100), (1,100,1))\rt = reshape(LinRange(0.,0.35, 200), (1,1,200))\ru3 = @. exp(-x^2) * exp(-2y^2) * exp(- œÄ^2 * t)\ranim = @animate for i ‚àà 1:200\rsurface(u3[:,:,i], zlims=(0,1), clim=(-1,1), title=\u0026#34;Anim. 1\u0026#34;)\rend\rgif(anim, cd*\u0026#34;/anim1.gif\u0026#34;, fps=30) Environment OS: Windows11 Version: Julia v1.8.3, Plots v1.38.6 ","id":3499,"permalink":"https://freshrimpsushi.github.io/en/posts/3499/","tags":null,"title":"Broadcasting of Multivariable Functions in Julia"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Overview We introduce definitions for dealing with the set of complex numbers $\\mathbb{C}$ as a topological space. Although it is referred to as a topological space, most of the definitions are specializations of the definitions in a metric space for complex sets. If you have studied introductory analysis diligently, you will be able to understand these without much difficulty.\nDefinitions 1 Let\u0026rsquo;s assume $\\alpha \\in \\mathbb{C}$, $\\delta \u0026gt; 0$ and $S \\subset \\mathbb{C}$.\nOpen and Closed Sets The following set is called the Open Neighborhood or Open Ball of $\\alpha$. $$ B \\left( \\alpha ; \\delta \\right) := \\left\\{ z \\in \\mathbb{C} : \\left| z - \\alpha \\right| \u0026lt; \\delta \\right\\} $$ When an asterisk $\\ast$ is superscripted, it means that the center $\\alpha$ is excluded. For example, $B^{\\ast} \\left( \\alpha ; \\delta \\right)$ is defined as follows and is called a Punctured Ball. $$ B^{\\ast} \\left( \\alpha ; \\delta \\right) := \\left\\{ z \\in \\mathbb{C} : 0 \u0026lt; \\left| z - \\alpha \\right| \u0026lt; \\delta \\right\\} $$ If any open ball of $\\alpha$ is included in $S$, then $\\alpha$ is called an Interior Point of $S$. $$ \\exist \\delta : B \\left( \\alpha , \\delta \\right) \\subset S $$ If every punctured open ball of $\\alpha$ is not disjoint with $S$, then $\\alpha$ is called a Limit Point of $S$. $$ \\forall \\delta : B^{\\ast} \\left( \\alpha , \\delta \\right) \\cap S \\ne \\emptyset $$ If every point of $S$ is an interior point of $S$, then $S$ is said to be Open; and if $S$ contains all its limit points, it is said to be Closed. Bounded and Compact If for every element $z \\in S$ of $S \\subset \\mathbb{C}$ there exists a positive number $M \u0026gt; 0$ that satisfies $\\left| z \\right| \\le M$, then $S$ is said to be Bounded. If it is closed and bounded, it is called Compact. Complex Domain If every two points of $S \\subset \\mathbb{C}$ can be connected by segments forming a path, then $S$ is called a (Polygonally) Connected set. A non-empty, open connected set $\\mathscr{R} \\subset \\mathbb{C}$ is called a Region, and particularly in the context of complex space, it is emphasized as a Complex Region. Further Definitions This section summarized parts universally essential in mathematics, not just in complex analysis. Of course, the following definitions and notations are also necessary when needed.\nThe following set is called the Closed Neighborhood or Closed Ball of $\\alpha$. $$ B \\left[ \\alpha ; \\delta \\right] := \\left\\{ z \\in \\mathbb{C} : \\left| z - \\alpha \\right| \\le \\delta \\right\\} $$ If every open neighborhood of $\\alpha$ contains a point of $S$ and $S^{c}$, then $\\alpha$ is called a Boundary Point. If $\\alpha$ is neither an interior point nor a boundary point, it is called an Exterior Point. The set of all limit points of $S$ is called the Closure of $S$, and it is represented as $\\overline{S}$. If $\\mathbb{C} \\setminus S$ is a connected set, then the connected set $S$ is called Simply Connected. See Also The set of complex numbers $\\mathbb{C}$ not only follows the axioms of a field but also is a $\\mathbb{C}$-vector space with the modulus of complex numbers $\\left| \\cdot \\right|$, making it a normed space as well as a metric space. Therefore, if you are already familiar with metric spaces, there is nothing new to learn specifically as a complex space.\nBalls and Open and Closed Sets in Metric Spaces Neighborhoods, Accumulation Points, Openness, and Closure in Metric Spaces Interior, Closure, and Boundary in Metric Spaces Compactness in Metric Spaces Heine-Borel Theorem Proof: Originally, defining a compact requires much more complicated discussions but in complex analysis, it\u0026rsquo;s acceptable to define compactness simply as equivalence if it is bounded and a closed set. Path Connectivity in Topology: Actually, the connectivity introduced in the definition is closer to path connectivity, because if it\u0026rsquo;s path-connected, it is connected, and to understand the general definition of connectivity in topology, a solid topological mindset is required, hence, a geometric intuition of \u0026lsquo;being connected by segments\u0026rsquo; is borrowed instead. Connected Sets in Metric Spaces Osborne (1999). Complex variables and their applications: p10~12.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2467,"permalink":"https://freshrimpsushi.github.io/en/posts/2467/","tags":null,"title":"Topology of Complex Spaces"},{"categories":"Ìï®Ïàò","contents":"Definition A function $c : X \\to Y$ is called a Constant Function if it satisfies the following for all $x_{1} , x_{2} \\in X$. $$ c \\left( x_{1} \\right) = c \\left( x_{2} \\right) $$\nExplanation Typically, the starting point where one first \u0026lsquo;recognizes\u0026rsquo; a constant function as a function is when learning about the differentiation of constant functions. $$ \\lim_{h \\to 0} {{ c \\left( x + h \\right) - c \\left( x \\right) } \\over { h }} = 0 $$ Up to that point in the curriculum, students often find it hard to understand what a function is, what numbers are, and if they are not top students, they may even absurdly categorize terms into \u0026rsquo;letters\u0026rsquo; and \u0026rsquo;numbers\u0026rsquo; (the author included). However, by differentiating both sides, one starts to ponder how to handle the part that is not a letter‚Äïnot a polynomial function. Soon after dealing with indefinite integrals, $$ \\int f(x) dx = F(x) + c $$ one becomes accustomed to the concept of constants by denoting \u0026lsquo;some constant $c$\u0026rsquo;. Interestingly, even jokingly, there comes a time when \u0026lsquo;constant functions\u0026rsquo;, which are not considered important in mathematics, universally appear in some field.\nContinuity If $X, Y$ is a topological space, one can discuss the continuity of a function. A constant function is trivially continuous in any space, and usually, continuous functions like $f : X \\to \\mathbb{Z}$ appear in arguments stating that \u0026lsquo;because the function values that are integers cannot change continuously, $f$ is none other than a constant function\u0026rsquo;.\nProof of the Monodromy Theorem ","id":2465,"permalink":"https://freshrimpsushi.github.io/en/posts/2465/","tags":null,"title":"Definition of a Constant Function"},{"categories":"Ìï®Ïàò","contents":"Definition 1 For any two polynomial functions $P_{1}(z), P_{2}(z) : \\mathbb{C} \\to \\mathbb{C}$, the following function $Q$ that maps every $z \\in \\mathbb{C}$ for which $P_{2} (z) \\ne 0$ into $\\left( P_{1} / P_{2} \\right) (z)$ is called a Rational Function or an Algebraic Fraction. $$ Q (z) := {{ P_{1} (z) } \\over { P_{2} (z) }} \\qquad \\text{where } P_{2} (z) \\ne 0 $$\nOsborne (1999). Complex variables and their applications: p24.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2463,"permalink":"https://freshrimpsushi.github.io/en/posts/2463/","tags":null,"title":"Definition of a Rational Function"},{"categories":"Ìë∏Î¶¨ÏóêÌï¥ÏÑù","contents":"Overview1 The Discrete Fourier Transform (DFT), when computed naively following its mathematical definition, has a time complexity of $\\mathcal{O}(N^{2})$. However, by using the algorithm described below, the time complexity can be reduced to $\\mathcal{O}(N\\log_{2}N)$. This efficient computation method of the Discrete Fourier Transform is known as the Fast Fourier Transform (FFT).\nBuildup Let\u0026rsquo;s define multiplying two numbers and then adding them to another number as one operation. To compute the value of $\\sum\\limits_{i=0}^{n-1}a_{n}b_{n}$, $n$ operations are needed.\n$$ \\begin{align*} \\sum\\limits_{n=0}^{0} a_{n}b_{b} \u0026amp;= a_{0}b_{0} = \\overbrace{0 {\\color{red} +} a_{0} {\\color{red} \\times} b_{0}}^{\\color{red} 1 \\text{ operation}} \\\\ \\sum\\limits_{n=0}^{1} a_{n}b_{b} \u0026amp;= a_{0}b_{0} + a_{1}b_{1} = \\overbrace{\\big( \\overbrace{0 {\\color{red} +} a_{0} {\\color{red} \\times} b_{0}}^{\\color{red} 1 \\text{ operation}} \\big) {\\color{#5882FA} + } a_{1} {\\color{#5882FA} \\times} b_{1}}^{\\color{#5882FA}2 \\text{ operations}} \\\\ \\sum\\limits_{n=0}^{2} a_{n}b_{b} \u0026amp;= a_{0}b_{0} + a_{1}b_{1} + a_{2}b_{2} = \\overbrace{\\bigg( \\overbrace{\\big( \\overbrace{0 {\\color{red} +} a_{0} {\\color{red} \\times} b_{0}}^{\\color{red} 1 \\text{ operation}} \\big) {\\color{#5882FA} + } a_{1} {\\color{#5882FA} \\times} b_{1}}^{\\color{#5882FA}2 \\text{ operations}} \\bigg) {\\color{#FE9A2E} + } a_{2} {\\color{#FE9A2E} \\times} b_{2}}^{\\color{#FE9A2E}3 \\text{ operations}} \\\\ \\end{align*} $$\nNow, recall the definition of the Discrete Fourier Transform.\nThe linear transformation $\\mathcal{F}_{N} : \\mathbb{C}^{N} \\to \\mathbb{C}^{N}$ is called the Discrete Fourier Transform.\n$$ \\mathcal{F}_{N}(\\mathbf{a}) = \\hat{\\mathbf{a}} = \\begin{bmatrix} \\hat{a}_{0} \\\\ \\hat{a}_{1} \\\\ \\dots \\\\ \\hat{a}_{N-1} \\end{bmatrix} ,\\quad \\hat{a}_{m} = \\sum_{n=0}^{N-1}e^{-i2\\pi mn /N} a_{n}\\quad (0\\le m \u0026lt; N) \\tag{1} $$\nWhere $\\mathbf{a} = \\begin{bmatrix} a_{0}\u0026amp; a_{1}\u0026amp; \\dots\u0026amp; a_{N-1} \\end{bmatrix}^{T}$.\nTo compute $\\hat{a}_{m}$, $N$ operations are needed, and to compute $\\hat{\\mathbf{a}}$, this must be performed $N$ times. Therefore, the total number of operations needed for the Discrete Fourier Transform is $N^{2}$, which means it has a time complexity of $\\mathcal{O}(N^{2})$. This implies a significant computational cost for Fourier Transforms from a computer calculation perspective.\nAlgorithm Let\u0026rsquo;s assume the length of the data, $N$, is a composite number $N = N_{1}N_{2}$. Now, define the indices $m, n$ as follows.\n$$ m = m^{\\prime}N_{1} + m^{\\prime \\prime},\\quad n = n^{\\prime}N_{2} + n^{\\prime \\prime} $$\nThen, $0 \\le m^{\\prime}, n^{\\prime \\prime} \\le N_{2}-1$, and $0 \\le m^{\\prime \\prime}, n^{\\prime} \\le N_{1}-1$. Let\u0026rsquo;s express the exponent part of $(1)$ as follows.\n$$ \\begin{align*} e^{-i2\\pi mn /N} \u0026amp;= e^{-i2\\pi (m^{\\prime}N_{1} + m^{\\prime \\prime})(n^{\\prime}N_{2} + n^{\\prime \\prime})/(N_{1}N_{2})} \\\\ \u0026amp;= e^{-i2\\pi (m^{\\prime}n^{\\prime}N_{1}N_{2} + m^{\\prime}n^{\\prime \\prime}N_{1} + m^{\\prime \\prime}n^{\\prime}N_{2} + m^{\\prime \\prime}n^{\\prime \\prime})/(N_{1}N_{2})} \\\\ \u0026amp;= e^{-i2\\pi m^{\\prime}n^{\\prime}} e^{-i2\\pi \\big( (m^{\\prime}n^{\\prime \\prime}/N_{2}) + (m^{\\prime \\prime}n^{\\prime}/N_{1}) + (m^{\\prime \\prime}n^{\\prime \\prime}/N) \\big)} \\\\ \u0026amp;= e^{-i2\\pi \\big( (m^{\\prime}n^{\\prime \\prime}/N_{2}) + (m^{\\prime \\prime}n^{\\prime}/N_{1}) + (m^{\\prime \\prime}n^{\\prime \\prime}/N) \\big)} \\\\ \\end{align*} $$\nSubstituting this into $(1)$ gives,\n$$ \\begin{align*} \\hat{a}_{m} \u0026amp;= \\sum_{n=0}^{N-1}e^{-i2\\pi mn /N} a_{n} \\\\ \u0026amp;= \\sum_{n^{\\prime \\prime}=0}^{N_{2}-1} \\sum_{n^{\\prime}=0}^{N_{1}-1} e^{-i2\\pi \\big( (m^{\\prime}n^{\\prime \\prime}/N_{2}) + (m^{\\prime \\prime}n^{\\prime}/N_{1}) + (m^{\\prime \\prime}n^{\\prime \\prime}/N) \\big)}a_{n^{\\prime}N_{2}+n^{\\prime \\prime}} \\\\ \u0026amp;= \\sum_{n^{\\prime \\prime}=0}^{N_{2}-1} \\left[ \\sum_{n^{\\prime}=0}^{N_{1}-1} e^{-i2\\pi m^{\\prime \\prime}n^{\\prime}/N_{1}}a_{n^{\\prime}N_{2}+n^{\\prime \\prime}} \\right] e^{-i2\\pi [ (m^{\\prime}n^{\\prime \\prime}/N_{2}) + (m^{\\prime \\prime}n^{\\prime \\prime}/N) ] } \\end{align*} $$\nAccording to the equation above, calculating $\\left[ \\sum_{n^{\\prime}=0}^{N_{1}-1} \\right]$ inside each bracket requires $N_{1}$ operations, and computing $\\sum_{n^{\\prime \\prime}=0}^{N_{2}-1}$ outside each bracket requires $N_{2}$ operations. Therefore, to calculate $\\hat{a}_{m}$, a total of $(N_{1} + N_{2})$ operations are needed. To obtain $\\hat{\\mathbf{a}}$, this must be repeated $N$ times, resulting in a total cost of $N(N_{1} + N_{2})$, which is a reduction from $N^{2}$.\nUpon closer inspection of the brackets, it is apparent that if $N_{1}$ is again a composite number, the same logic can be applied. Generally, when the length of the data is a composite number $N = N_{1} N_{2} \\cdots N_{k}$, the time complexity is reduced as follows.\n$$ \\mathcal{O}(N^{2}) \\searrow \\mathcal{O}\\big( N(N_{1} + N_{2} + \\cdots + N_{k}) \\big) $$\nNow, let\u0026rsquo;s assume $N$ is a power of $2$, $N = 2^{k}$. Then $\\log_{2}N = k$, and from $N^{2} = 2^{k}$, it is reduced to $2^{k}(2k)$, hence the time complexity is reduced as follows.\n$$ \\mathcal{O}(N^{2}) \\searrow \\mathcal{O}(2N \\log_{2}N) $$\nAside This method was proposed in 1965 by Cooley and Tukey2, hence it is also called the Cooley-Tukey algorithm. However, they were not the first to invent it. Gauss also researched a similar algorithm but did not publish it properly, so this fact became known later3.\nGerald B. Folland, Fourier Analysis and Its Applications (1992), p252-253\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. W. Cooley and J. W. Tukey, An algorithm for the machine calculation of complex Fourier series, Mathematics of Computation 19 (1965), 297-301.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. T. Heideman, D. H. Johnson, and C. S. Burms, Gauss and the history of the fast Fourier transform, Archive for the History of the Exact Sciences 34 (1985), 264-277.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3492,"permalink":"https://freshrimpsushi.github.io/en/posts/3492/","tags":null,"title":"The Fast Fourier Transform Algorithm"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 For a given estimator $T$, the estimated standard deviation of $T$ is called the standard error. $$ \\text{s.e.} \\left( T \\right) := \\sqrt{ \\widehat{ \\text{Var} \\left( T \\right) } } $$\nExplanation The reason why it is precisely defined as an estimator in the definition, not a statistic, is because the standard error becomes meaningless unless we are discussing whether it \u0026lsquo;matches or not\u0026rsquo; with the parameter $\\theta$ I want to estimate. That\u0026rsquo;s why, even though $\\theta$ never appears in the equation, it is purposely defined in terms of an estimator. Therefore, potential candidates for $T$ are obviously the sample mean $\\overline{X}$ or regression coefficients $\\beta_{k}$, and $\\text{s.e.} \\left( T \\right)$ becomes necessary because we are curious about their confidence intervals.\nUsually, since we learn about the standard error of $\\overline{X} = \\sum_{k=1}^{n} X_{k}$ $S / \\sqrt{n}$ as if it were the only kind of standard error from definitions like these, many believe it to be the sole form of standard error, when in reality, it is not even a definition but just a formula derived through calculation. Let\u0026rsquo;s calculate it without omitting as much as possible. $$ \\begin{align*} \\text{s.e.} \\left( \\overline{X} \\right) =\u0026amp; \\sqrt{ \\widehat{ \\text{Var} \\left( \\overline{X} \\right) } } \\\\ =\u0026amp; \\sqrt{ \\widehat{ \\text{Var} \\left( {{ 1 } \\over { n }} \\sum_{k=1}^{n} X_{k} \\right) } } \\\\ =\u0026amp; \\sqrt{ \\widehat{ {{ 1 } \\over { n^{2} }} \\text{Var} \\left( \\sum_{k=1}^{n} X_{k} \\right) } } \\\\ \\overset{\\text{iid}}{=} \u0026amp; \\sqrt{ \\widehat{ {{ 1 } \\over { n^{2} }} \\sum_{k=1}^{n} \\text{Var} \\left( X_{k} \\right) } } \\\\ =\u0026amp; \\sqrt{ {{ 1 } \\over { n^{2} }} \\sum_{k=1}^{n} \\widehat{ \\text{Var} \\left( X_{k} \\right) } } \\\\ =\u0026amp; \\sqrt{ {{ 1 } \\over { n^{2} }} \\sum_{k=1}^{n} S^{2} } \\\\ =\u0026amp; \\sqrt{ {{ 1 } \\over { n^{2} }} n S^{2} } \\\\ =\u0026amp; \\sqrt{ {{ 1 } \\over { n }} S^{2} } \\\\ =\u0026amp; {{ 1 } \\over { \\sqrt{n} }} S \\end{align*} $$ As you can see, the concepts of estimator and estimate differ, hence even in this simple example it can be quite confusing. Furthermore, since in many cases where standard error is actually used, the form of dividing sample variance by degrees of freedom and taking the square root is often utilized, it\u0026rsquo;s easy to misconstrue that form as the standard error itself. However, despite such intuition frequently being correct, the standard error isn\u0026rsquo;t defined by such methods but rather derived from mathematical progressions as shown.\nHadi. (2006). Regression Analysis by Example(4th Edition): p33.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2462,"permalink":"https://freshrimpsushi.github.io/en/posts/2462/","tags":null,"title":"Standard Definition of Standard Error"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview To achieve this, one can use the canonicalize() function of the Dates module1.\nCode using Dates\rtic = DateTime(2022,3,7,7,1,11)\rtoc = now()\rDates.canonicalize(toc-tic) The result of executing the above code is as follows.\njulia\u0026gt; using Dates\rjulia\u0026gt; tic = DateTime(2022,3,7,7,1,11)\r2022-03-07T07:01:11\rjulia\u0026gt; toc = now()\r2022-07-19T22:26:22.070\rjulia\u0026gt; Dates.canonicalize(toc-tic)\r19 weeks, 1 day, 15 hours, 25 minutes, 11 seconds, 70 milliseconds It automatically calculates and outputs up to weeks, precisely as multiples of smaller units.\nEnvironment OS: Windows julia: v1.7.0 https://discourse.julialang.org/t/get-difference-between-two-dates-in-seconds/11641/4\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2461,"permalink":"https://freshrimpsushi.github.io/en/posts/2461/","tags":null,"title":"How to Calculate the Difference Between Two Times in Seconds in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Theorem The keywords related to specifying the color of axes and ticks in Plots.jl are as follows.\nKeyword Name Function guidefontcolor Specify axis name color foreground_color_border, fgcolor_border Specify axis color foreground_color_axis, fgcolor_axis Specify tick color foreground_color_text, fgcolor_text Specify tick value color Adding x_ or y_ in front of the keyword name applies it to the respective axis only.\nCode1 Axis Names The keyword to specify the color of axis names is guidefontcolor. Axis names can be specified with xlabel, ylabel.\nx = randn(10, 3) plot(plot(x, guidefontcolor = :red), plot(x, x_guidefontcolor = :red), plot(x, y_guidefontcolor = :red), xlabel = \u0026#34;x label\u0026#34;, ylabel = \u0026#34;y label\u0026#34;, ) Axes The keyword to specify the color of axes is foreground_color_border.\nplot(plot(x, foreground_color_border = :red), plot(x, x_foreground_color_border = :red), plot(x, y_foreground_color_border = :red), xlabel = \u0026#34;x label\u0026#34;, ylabel = \u0026#34;y label\u0026#34;, ) Ticks The keyword to specify the color of ticks is foreground_color_axis. Setting it to false only removes the ticks.\nplot(plot(x, foreground_color_axis = :red), plot(x, x_foreground_color_axis = :red), plot(x, y_foreground_color_axis = false), xlabel = \u0026#34;x label\u0026#34;, ylabel = \u0026#34;y label\u0026#34;, ) Tick Values The keyword to specify the color of tick values is foreground_color_text. Setting it to false only removes the tick values.\nplot(plot(x, foreground_color_text = :red), plot(x, x_foreground_color_text = :red), plot(x, y_foreground_color_text = flase), xlabel = \u0026#34;x label\u0026#34;, ylabel = \u0026#34;y label\u0026#34;, ) Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0 See Also How to use colors How to use palettes How to use color gradients Package for color processing Colors.jl How to use RGB codes RGB(1, 0, 0) How to use HEX codes \u0026quot;#000000\u0026quot; How to specify the color of graph elements How to specify colors for each subplot How to specify the color of axes, axis names, ticks, and tick values How to specify background color https://docs.juliaplots.org/stable/generated/attributes_axis/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3490,"permalink":"https://freshrimpsushi.github.io/en/posts/3490/","tags":null,"title":"Specifying the Color of Axes, Axis Names, Ticks, and Tick Values in Julia Plots"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Overview This document organizes code that performs the same functions in Flux, PyTorch, and TensorFlow.\nJulia-Matlab-Python-R Cheat Sheet Let\u0026rsquo;s assume the following environment for Flux.\nusing Flux Let\u0026rsquo;s assume the following environment for PyTorch.\nimport torch\rimport torch.nn as nn\rimport torch.nn.functional as F Let\u0026rsquo;s assume the following environment for TensorFlow.\nimport tensorflow as tf\rfrom tensorflow import keras 1-Dimensional Tensor Ï§ÑÎ¶¨ÏïÑJulia\rÌååÏù¥ÌÜ†ÏπòPyTorch\rÌÖêÏÑúÌîåÎ°úÏö∞TensorFlow\rColumn Vectorcolumn vector\r[1 4 -1 2] [1;4;-1;2] ","id":3489,"permalink":"https://freshrimpsushi.github.io/en/posts/3489/","tags":null,"title":"Flux-PyTorch-TensorFlow Cheat Sheet"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Introducing tips for switching between 2D arrays and matrices in Julia, which may be the simplest, fastest, and most beautiful way to do it, especially in environments of Julia 1.7 or lower1.\nCode There are countless ways to switch between matrices and 2D arrays, not just the method introduced here. Since the goal itself is not difficult whether you code haphazardly or not, it\u0026rsquo;s better to consider not only the goal but also how Julia\u0026rsquo;s unique syntax was used when reading this carefully.\nFrom matrices to 2D arrays julia\u0026gt; M = rand(0:9, 3, 10)\r3√ó10 Matrix{Int64}:\r2 4 0 1 8 0 9 2 5 7\r5 2 1 5 4 3 7 2 7 3\r7 8 1 9 0 3 2 4 1 3 Let\u0026rsquo;s convert the matrix above to a 2D array.\njulia\u0026gt; [eachrow(M)...]\r3-element Vector{SubArray{Int64, 1, Matrix{Int64}, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}}, true}}:\r[2, 4, 0, 1, 8, 0, 9, 2, 5, 7]\r[5, 2, 1, 5, 4, 3, 7, 2, 7, 3]\r[7, 8, 1, 9, 0, 3, 2, 4, 1, 3]\rjulia\u0026gt; [eachcol(M)...]\r10-element Vector{SubArray{Int64, 1, Matrix{Int64}, Tuple{Base.Slice{Base.OneTo{Int64}}, Int64}, true}}:\r[2, 5, 7]\r[4, 2, 8]\r[0, 1, 1]\r[1, 5, 9]\r[8, 4, 0]\r[0, 3, 3]\r[9, 7, 2]\r[2, 2, 4]\r[5, 7, 1]\r[7, 3, 3] eachrow() and eachcol() return generators that extract each row and column of the matrix2, and through the splat operator3, handling them as variable arrays and putting them inside square brackets [] naturally turns them into an array.\nFrom 2D arrays to matrices julia\u0026gt; A = [rand(0:9,3) for _ in 1:10]\r10-element Vector{Vector{Int64}}:\r[5, 4, 9]\r[9, 7, 6]\r[9, 9, 6]\r[5, 9, 0]\r[0, 2, 8]\r[3, 9, 5]\r[1, 6, 0]\r[5, 7, 7]\r[1, 3, 5]\r[5, 4, 1] Let\u0026rsquo;s covert the above 2D array into a matrix.\njulia\u0026gt; hcat(A...)\r3√ó10 Matrix{Int64}:\r5 9 9 5 0 3 1 5 1 5\r4 7 9 9 2 9 6 7 3 4\r9 6 6 0 8 5 0 7 5 1\rjulia\u0026gt; hcat(A...)\u0026#39;\r10√ó3 adjoint(::Matrix{Int64}) with eltype Int64:\r5 4 9\r9 7 6\r9 9 6\r5 9 0\r0 2 8\r3 9 5\r1 6 0\r5 7 7\r1 3 5\r5 4 1\rjulia\u0026gt; vcat(A...)\r30-element Vector{Int64}:\r5\r4\r9\r9\r7\r6\r9\r9\r‚ãÆ\r7\r1\r3\r5\r5\r4\r1 You can use the hcat() function for merging arrays4. Fundamentally, hcat() and vcat() are fold functions as well as variadic functions, so the one-dimensional arrays, which are elements of the 2D array, have to be passed directly as arguments through the splat operator.\nComplete Code # matrix to 2d array\rM = rand(0:9, 3, 10)\r[eachrow(M)...]\r[eachcol(M)...]\r# 2d array to matrix\rA = [rand(0:9,3) for _ in 1:10]\rhcat(A...)\rhcat(A...)\u0026#39;\rvcat(A...) Environment OS: Windows julia: v1.7.0 https://discourse.julialang.org/t/plots-efficient-scatter-plot-of-a-2xn-array/31803/6\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://docs.julialang.org/en/v1/base/arrays/#Base.eachcol\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://docs.julialang.org/en/v1/base/base/#\u0026hellip;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://docs.julialang.org/en/v1/base/arrays/#Base.cat\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2459,"permalink":"https://freshrimpsushi.github.io/en/posts/2459/","tags":null,"title":"How to Convert between 2D Arrays and Matrices in Julia"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 $$ Y = \\beta_{0} + \\beta_{1} X_{1} + \\cdots + \\beta_{p} X_{p} + \\varepsilon $$ In multiple regression analysis, for the given $p$ independent variables $X_{1} , \\cdots , X_{p}$, when setting up a linear model as above, $\\beta_{0} , \\beta_{1} , \\cdots , \\beta_{p}$ is called the regression coefficient. $Y$ represents the dependent variable, and $\\varepsilon$ represents the randomly distributed error.\nFormula $$ \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; x_{11} \u0026amp; \\cdots \u0026amp; x_{p1} \\\\ 1 \u0026amp; x_{12} \u0026amp; \\cdots \u0026amp; x_{p2} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 1 \u0026amp; x_{1n} \u0026amp; \\cdots \u0026amp; x_{pn} \\end{bmatrix} \\begin{bmatrix} \\beta_{0} \\\\ \\beta_{1} \\\\ \\vdots \\\\ \\beta_{p} \\end{bmatrix} + \\begin{bmatrix} \\varepsilon_{1} \\\\ \\varepsilon_{2} \\\\ \\vdots \\\\ \\varepsilon_{n} \\end{bmatrix} $$ Given $n$ pieces of data and defining them as $p \u0026lt; n$, representing the linear multiple regression model by the design matrix is as above, and let\u0026rsquo;s briefly express it as $Y = X \\beta + \\varepsilon$. The least squares estimate vector $\\hat{\\beta}$ for $\\beta$ is as follows. $$ \\hat{\\beta} = \\begin{bmatrix} \\hat{\\beta}_{0} \\\\ \\hat{\\beta}_{1} \\\\ \\vdots \\\\ \\hat{\\beta}_{p} \\end{bmatrix} = \\left( X^{T} X \\right)^{-1} X^{T} Y $$ Furthermore, $\\hat{\\beta}$, being the best unbiased estimator for $\\beta$, is also called the Best Linear Unbiased Estimator, BLUE.\nDerivation 2 3 Our goal is $$ \\left\\| \\varepsilon \\right\\|_{2}^{2} = \\sum_{k=0}^{n} \\varepsilon_{k} = \\begin{bmatrix} \\varepsilon_{0} \u0026amp; \\varepsilon_{1} \u0026amp; \\cdots \u0026amp; \\varepsilon_{n} \\end{bmatrix} \\begin{bmatrix} \\varepsilon_{0} \\\\ \\varepsilon_{1} \\\\ \\vdots \\\\ \\varepsilon_{n} \\end{bmatrix} = \\varepsilon^{T} \\varepsilon $$ to minimize this. Since $\\varepsilon = Y - X \\beta$, finding $\\beta$ that minimizes $\\varepsilon^{T} \\varepsilon = \\left( Y - X \\beta \\right)^{T} \\left( Y - X \\beta \\right)$ suffices. Differentiating both sides by $\\beta$ $$ \\begin{align*} {{ d } \\over { d \\beta }} \\varepsilon^{T} \\varepsilon =\u0026amp; - 2 X^{T} \\left( Y - X \\beta \\right) \\\\ = \u0026amp; - 2 X^{T} \\left( Y - X \\beta \\right) \\\\ = \u0026amp; - 2 X^{T} Y + 2 X^{T} X \\beta \\end{align*} $$ yields $\\hat{\\beta}$ in the following form. $$ \\hat{\\beta} = \\argmin_{\\beta} \\varepsilon^{T} \\varepsilon = \\left( X^{T} X \\right)^{-1} X^{T} Y $$ Meanwhile, it is easy to see that $\\hat{\\beta}$ is an unbiased estimator for $\\beta$, and since it is derived using the least squares method, there exists no unbiased estimator of $\\beta$ with smaller variance, making it the best unbiased estimator.\n‚ñ†\nIf one is not fond of the differentiation by $\\beta$ in the derivation, an alternative approach is through matrix algebra. In least squares in matrix algebra, $$ X^{\\ast} Y = X^{\\ast} X \\hat{\\beta} $$ $\\hat{\\beta}$ satisfying this becomes the least squares solution, since $X \\in \\mathbb{R}^{n \\times p}$, thus $X^{\\ast} = X^{T}$, and consequently, we obtain $\\hat{\\beta} = \\left( X^{T} X \\right)^{-1} X^{T} Y$.\nSee Also Derivation of the simple regression coefficient estimators Multivariate normality of the regression coefficient vector Hadi. (2006). Regression Analysis by Example(4th Edition): p53.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHadi. (2006). Regression Analysis by Example(4th Edition): p82~84.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.stat.purdue.edu/~boli/stat512/lectures/topic3.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2458,"permalink":"https://freshrimpsushi.github.io/en/posts/2458/","tags":null,"title":"The Definition of Regression Coefficients and Derivation of Estimator Formulas"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview This document introduces how to send emails from Naver using the SMTPClient.jl package with SMTP 1. I use it to send reports to Kakao Mail when long-running simulations are finished, which helps to speed up my research.\nThis way, knowing when simulations are finished without having to check the server myself, as Jordy notifies me via personal chat.\nCode Regardless of the programming language, the first thing to do is to enable SMTP as \u0026lsquo;Enabled\u0026rsquo; in Naver Mail as shown below.\nJulia using Dates\rtic = now()\rfor t in 1:1000\rprintln(t)\rend\rtoc = now()\rusing SMTPClient\ropt = SendOptions(\risSSL = true,\rusername = \u0026#34;ÎÑ§Ïù¥Î≤ÑÏïÑÏù¥Îîî\u0026#34;,\rpasswd = \u0026#34;ÎπÑÎ∞ÄÎ≤àÌò∏\u0026#34;)\r#Provide the message body as RFC5322 within an IO\rbody = IOBuffer(\r\u0026#34;Date: ‚ñ∑eq1‚óÅtic\\r\\n\u0026#34; *\r\u0026#34;‚ñ∑eq2‚óÅ(Dates.canonicalize(toc - tic))\u0026#34; *\r\u0026#34;\\r\\n\u0026#34;)\rurl = \u0026#34;smtps://smtp.naver.com:465\u0026#34;\rrcpt = [\u0026#34;\u0026lt;ÏàòÏã†Ïûê@kakao.com\u0026gt;\u0026#34;]\rfrom = \u0026#34;\u0026lt;Î∞úÏã†Ïûê@naver.com\u0026gt;\u0026#34;\rresp = send(url, rcpt, from, body, opt) In the example above, the most critical part is url = \u0026quot;smtps://smtp.naver.com:465\u0026quot;. This needs to be appropriately changed to whichever server you\u0026rsquo;re using, not just Naver. For the sending time, I fixed it to the moment of sending the mail using the now() from the Dates module, but if this does not match the actual clock, there might be a delay of about 10 minutes before the mail is sent.\nPython Before trying with Julia, I first attempted with Python. Strangely, even using SSL and setting the port to 456 did not work, but disabling SSL and switching to port 587 did the job. The following code, based on a blog2 that explained Google\u0026rsquo;s case, works well for Naver.\nimport smtplib\rfrom email.mime.text import MIMEText\rsendEmail = \u0026#34;Î∞úÏã†Ïûê@naver.com\u0026#34;\rrecvEmail = \u0026#34;ÏàòÏã†Ïûê@kakao.com\u0026#34;\rpassword = \u0026#34;ÎπÑÎ∞ÄÎ≤àÌò∏\u0026#34;\rsmtpName = \u0026#34;smtp.naver.com\u0026#34; #smtp ÏÑúÎ≤Ñ Ï£ºÏÜå\rsmtpPort = 587 #smtp Ìè¨Ìä∏ Î≤àÌò∏\rtext = \u0026#34;Îß§Ïùº ÎÇ¥Ïö©\u0026#34;\rmsg = MIMEText(text) #MIMEText(text , _charset = \u0026#34;utf8\u0026#34;)\rmsg[\u0026#39;Subject\u0026#39;] = \u0026#34;ÏãúÎÆ¨Î†àÏù¥ÏÖò Ï¢ÖÎ£å\u0026#34;\rmsg[\u0026#39;From\u0026#39;] = sendEmail\rmsg[\u0026#39;To\u0026#39;] = recvEmail\rprint(msg.as_string())\rs=smtplib.SMTP( smtpName , smtpPort ) #Î©îÏùº ÏÑúÎ≤Ñ Ïó∞Í≤∞\rs.starttls() #TLS Î≥¥Ïïà Ï≤òÎ¶¨\rs.login( sendEmail , password ) #Î°úÍ∑∏Ïù∏\rs.sendmail( sendEmail, recvEmail, msg.as_string() ) #Î©îÏùº Ï†ÑÏÜ°, Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôòÌïòÏó¨ Î≥¥ÎÉÖÎãàÎã§.\rs.close() #smtp ÏÑúÎ≤Ñ Ïó∞Í≤∞ÏùÑ Ï¢ÖÎ£åÌï©ÎãàÎã§. Environment OS: Windows julia: v1.7.0 https://github.com/aviks/SMTPClient.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://gosmcom.tistory.com/72\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2457,"permalink":"https://freshrimpsushi.github.io/en/posts/2457/","tags":null,"title":"How to Send an Email via Naver in Julia"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Ïö©Ïñ¥ The number of independent data that can change the value when calculating a certain statistic is called the Degree of Freedom1.\nÏÑ§Î™Ö Why It\u0026rsquo;s Hard to Explain Degrees of Freedom When you become a freshman and study statistics, this thing called \u0026lsquo;degrees of freedom\u0026rsquo; really gets annoying. Aside from being difficult and frequently mentioned, it\u0026rsquo;s because you can hardly see its definition clearly stated in any textbook. This post also introduces it merely as a \u0026rsquo;term\u0026rsquo;, using expressions that can\u0026rsquo;t be considered as strict mathematical statements, such as \u0026lsquo;when calculating\u0026rsquo; or \u0026rsquo;that can change the value\u0026rsquo;.\nThe problem is, it‚Äôs understandable. It‚Äôs not just everyone being lazy and skipping it, but the concept of degrees of freedom itself feels stronger as something \u0026lsquo;acquired through experience\u0026rsquo; rather than \u0026lsquo;understood by studying\u0026rsquo;. Around sophomore or junior year, you start to get a rough idea of what degrees of freedom are, and by the time you go to graduate school, you can usually explain it pretty well, but reciting a definition is still hard.\nThe issue starts with the \u0026lsquo;positive feeling\u0026rsquo; that the expression itself gives. Whether it‚Äôs fashion, an open-world game, or democracy, degrees of freedom are considered good the higher or larger they are. Even the degrees of freedom that freshmen encounter for the first time are commonly calculated in ways such as \u0026lsquo;since the number of samples is $n$, we have $(n-1)$ degrees of freedom after subtracting $1$\u0026rsquo;. Without deep contemplation, it may seem like having more samples is better, so even the degrees of freedom in statistics might be perceived as a \u0026lsquo;positive or negative number\u0026rsquo;. However, in the context of handling and exploring them with precise formulas, degrees of freedom are just some numbers.\nAlso, it\u0026rsquo;s problematic that they appear too out of context, even frequently so. When learning about Analysis of Variance or regression analysis, suddenly degrees of freedom like $n-1$ and $n-p-1$ spill out, \u0026lsquo;calculated in ways that are too poorly explained\u0026rsquo;. Then, studying mathematical statistics, suddenly t-distribution and chi-squared distribution talk about parameters called degrees of freedom. Even more, F-distribution is said to have two degrees of freedom, but the meanings of those aren\u0026rsquo;t thoroughly clarified, leaving a weird feeling of somehow knowing them without fully understanding. This usually happens around sophomore or junior year, and by this time, it‚Äôs somewhat embarrassing to ask about degrees of freedom, yet it‚Äôs not something completely unknown, so people tend to awkwardly move on.\nEven acknowledging the necessity of those numbers, calling them \u0026lsquo;degrees of freedom\u0026rsquo; might seem meaningless at a glance. So, let\u0026rsquo;s empathize with why the term \u0026lsquo;degrees of freedom\u0026rsquo; is necessary.\nExtreme Example: What if There Were No Concept of Degrees of Freedom? One good way to explain a seemingly useless concept is to describe what kind of \u0026lsquo;cheating\u0026rsquo; is allowed in its absence. Let\u0026rsquo;s imagine something fun, setting aside the mathematical descriptions of what a statistic is like. Suppose we are given a sample $A$. $$ A = \\left\\{ 13, 7, 17, 3 \\right\\} $$ In this case, the number of samples is $n = 4$. But then, a junior comes up with a sample $B$, claiming to have \u0026lsquo;developed\u0026rsquo; it. $$ B = \\left\\{ 13, 7, 17, 3 , 14, 8, 18, 4 \\right\\} $$ The junior says that there are $8$ samples, twice as many as in $A$. Not stopping there, \u0026rsquo;they claim they can increase the number of samples as much as they want, up to $n \\to \\infty$ times, allowing all statistical techniques applicable to large samples\u0026rsquo;. However, it‚Äôs obvious at first glance that this sample is crudely forged, and the method was merely to add $1$ to the existing data to increase the number of samples.\nAt this moment, we must realize that we focused on the essence, $A$, not being deceived by the numbers presented by the junior, $B$. The junior\u0026rsquo;s created data is nothing but a knockoff of $$ B = B(A) = A \\cup (A+1) $$ $A$. The volume of the sample isn\u0026rsquo;t just about the number but is rightfully counted as the number of naturally uncontrollable ‚Äì in other words, \u0026lsquo;free\u0026rsquo; ‚Äì samples, and such a count that doesn\u0026rsquo;t allow \u0026lsquo;cheating\u0026rsquo; is called degrees of freedom.\nA Repeatedly Seen Example: $s^{2}$ Now, let\u0026rsquo;s consider the sample variance $s^{2}$, an example that almost always comes up in literature explaining degrees of freedom. The sample variance is calculated as follows when the sample mean $\\overline{x}$ is given. $$ s^{2} = {{ 1 } \\over { n-1 }} \\sum_{k=1}^{n} \\left( x_{k} - \\overline{x} \\right)^{2} $$ The important thing here is that the constant $\\overline{x} = \\sum_{k} x_{k} / n$ is already given. Regardless of which $x_{k_{0}}$ you choose, that $x_{k_{0}}$ can be reverse-calculated as a function $$ x_{k_{0}} = x_{k_{0}} \\left( \\left\\{ x_{k} : k \\ne k_{0} \\right\\} \\right) = n \\overline{x} - \\sum_{k \\ne k_{0}} x_{k} $$ that depends on the rest of the data. This is similar to how the junior\u0026rsquo;s data was represented in the form of $B = B(A)$ in the paragraph above. The true number of samples required to calculate $s^{2}$ in a genuine sense is not $n$ but $(n-1)$, and if only $x_{k_{0}}$ is fixed, $(n-1)$ samples $\\left\\{ x_{k} : k \\ne k \\right\\}$ can change the value of $s^{2}$ calculated under the constraint that the value of $\\overline{x}$ is maintained, therefore calling $(n-1)$ the degrees of freedom of $s^{2}$.\nSee Also Why the sample variance is divided by n-1 http://www.animatedsoftware.com/statglos/sgdegree.htm\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2456,"permalink":"https://freshrimpsushi.github.io/en/posts/2456/","tags":null,"title":"Degrees of Freedom in Statistics"},{"categories":"Î≥¥Ï°∞Ï†ïÎ¶¨","contents":"Definition $$ [a,b] := \\left\\{ x \\in \\mathbb{R} : a \\le x \\le b \\right\\} \\subset \\mathbb{R} $$\nFor two real numbers $a \\le b$, the set as described above is called an Interval. In particular, if both endpoints $a,b$ are included, it is notated as $\\left[ a,b \\right]$ using square brackets [] and is said to be Closed. If both endpoints $a,b$ are not included, it is notated as $\\left( a,b \\right)$ using parentheses () and is said to be Open. If only one of the endpoints is not included, it is called Clopen, and when only $a$ is included it is notated as $[a,b)$, and when only $b$ is included it is notated as $(a,b]$. In case one of the ends is absent, that is, if it is infinite, the following notation is used. $$ \\begin{align*} (-\\infty, b) \u0026amp;:= \\left\\{ x \\in \\mathbb{R} : x \\lt b \\right\\} \\subset \\mathbb{R} \\\\ (a, \\infty) \u0026amp;:= \\left\\{ x \\in \\mathbb{R} : a \\lt x \\right\\} \\subset \\mathbb{R} \\end{align*} $$ Explanation An interval is one of the most well-known subsets which has connectivity in a one-dimensional Euclidean space $\\mathbb{R}^{1}$. It is easy to understand, familiar, and something that one would often come across in various studies.\nNumerical Analysis In fields such as Numerical Analysis, there are scenarios where one deals with a multitude of points that are neither just two nor in any specific order as in $a,b$. Thus, the smallest interval containing a set of multiple points $S := \\left\\{ x_{1} , \\cdots , x_{n} \\right\\}$ is often denoted as follows. $$ \\mathscr{H} \\left\\{ x_{1} , \\cdots , x_{n} \\right\\} := \\left[ \\min S , \\max S \\right] $$ The fields that are interested in operations with intervals even have a specific area called Interval Arithmetic1.\nProgramming Languages I came across an interesting article while randomly searching for something out of curiosity when coding. 2 To summarize, it questions why in programming, instead of using $(0,n]$ or $[1,n]$, a clopen interval $[0,n)$ is used. I wanted to rewrite it, simplifying only the parts I agreed with, from a mathematician\u0026rsquo;s perspective.\nn = 10\rfor i in 0:n\rprint(n) In many programming languages including Python and MATLAB, similar codes are often used, and mostly, the execution result of that code is as follows. (Note that this code is neither Python nor MATLAB but a hypothetical language.)\n0123456789 What this means is, if it‚Äôs controlled by 0:n, then it is considered as a clopen interval $[0,n)$. This kind of thinking, or convention, has the advantage where if indexes are used starting from $0$ to $i = 0, 1, \\cdots , n-1$, then the \u0026rsquo;total number of iterations\u0026rsquo; fittingly comes out to be $n$. Using such an intuitive notation can significantly reduce errors and becomes a practical habit.\nMoreover, in languages like C, the same expression must be written as for(i=0; i\u0026lt;10; i++), but if one starts from 1 and ends exactly at 10, it should be compared with for(i=1; i\u0026lt;=10; i++). The operator itself becomes messier, shifting from \u0026lt; to \u0026lt;=, and in fact, when accessing arrays in C, 0 must be included. Therefore, that kind of loop might be stupidly written as for(i=0; i\u0026lt;=(10-1); i++).\nMeaning, confusing beginners at coding and being off by 1 is not always to torment you, but there might be some seemingly good reasons for it.\nhttps://en.wikipedia.org/wiki/Interval_arithmetic\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://nanite.tistory.com/56\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2453,"permalink":"https://freshrimpsushi.github.io/en/posts/2453/","tags":null,"title":"Definition of Intervals in Mathematics"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definitions 1 Given quantitative data,\nA value that is greater than $p \\%$ but less than $(100-p) \\%$ is called the $p$-percentile. The $100$-percentile and $0$-percentile (the largest and smallest values in the data) are referred to as the maximum, minimum values, respectively. The difference between the maximum and minimum values is called the data\u0026rsquo;s range $R$. The $25$-percentile is called the first quartile $Q_{1}$, and the $75$-percentile is called the third quartile $Q_{3}$. $\\left( Q_{3} - Q_{1} \\right)$ is called the interquartile range $\\text{IQR}$. The minimum, first quartile, median, third quartile, and maximum are the five statistics called the Five-Number Summary. $$ \\min \\qquad Q_{1} \\qquad \\text{median} \\qquad Q_{3} \\qquad \\max $$ Empirically, data that falls outside the following range is also referred to as an outlier. $$ \\left[ Q_{1} - 1.5 \\text{IQR} , Q_{3} + 1.5 \\text{IQR} \\right] $$ The lower limit is called the lower fence, and the upper limit is called the upper fence. Explanation Second Quartile The $50$-percentile, aka the second quartile, is essentially the median, so there is no need to define it separately when talking about the five-number summary. These summaries help to make an educated guess about the distribution of the data with a sufficient amount of data, and they should be the first thing to check regardless of the data being observed.\nOutlier An outlier is literally something that lies outside, meaning it falls outside the common range of data. Despite $Q_{1} - 1.5 \\text{IQR}$ being a rather small value and $Q_{3} + 1.5 \\text{IQR}$ being a rather large value, they are called outliers because they fall outside the expected range. Note that this is not a mathematically rigorous definition, as the terms \u0026rsquo;empirical\u0026rsquo; and \u0026lsquo;common data\u0026rsquo; suggest.\nMendenhall. (2012). Introduction to Probability and Statistics (13th Edition): p76, 60, 78~80.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2452,"permalink":"https://freshrimpsushi.github.io/en/posts/2452/","tags":null,"title":"Percentiles and Outliers"},{"categories":"Î≥¥Ï°∞Ï†ïÎ¶¨","contents":"Definitions Geometric Definition A circle is defined as the set of points in a plane that are at a given distance $r \u0026gt; 0$ from a given point. The ratio of a circle\u0026rsquo;s circumference $l$ to its diameter $2r$ is defined as the Pi $\\pi$. $$ \\pi := {{ l } \\over { 2r }} $$ Analytical Definition 1 $$ E (z) := \\sum_{k=0}^{\\infty} {{ z^{k} } \\over { k! }} $$ Let\u0026rsquo;s define the complex function $E : \\mathbb{C} \\to \\mathbb{C}$ as the series expansion of an exponential function, and through it, define the following function similar to the cosine function $C$. $$ C(x) := {{ E (ix) + E(-ix) } \\over { 2 }} $$ When $C(x)$, the smallest positive root that satisfies $C(x) = 0$ is called $x_{0}$, and twice this value is defined as Pi $\\pi$. $$ \\pi := 2 x_{0} $$\nDescription In this post, both the geometric (simple) and the analytical (complicated) definitions are introduced. Mathematics students beyond their junior year of college might smile subtly at the analytical definitions.\nThroughout human history, Pi has been an extremely important constant, being practically useful no later than the invention of the wheel. In particular, it is known that there were efficient and precise approximations like $$ {{ 22 } \\over { 7 }} = 3.142857 \\cdots \\approx \\pi $$ This value is far more accurate than what was taught during the so-called Yutori education era at the end of the 20th century in Japan, which significantly surpassed the educational standards of the time. (This was when they taught Pi as $3$ under the pretext of providing a relaxed education) 2\nSee Also Proof that Pi is an irrational number Walter Rudin, Principles of Mathmatical Analysis (3rd Edition, 1976): p178~183.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.joongang.co.kr/article/2572535\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2451,"permalink":"https://freshrimpsushi.github.io/en/posts/2451/","tags":null,"title":"Definition of Pi"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Overview This section explains and implements the pseudocode of an algorithm introduced in the paper \u0026ldquo;Computing Persistent Homology\u0026rdquo; by Zomorodian and Carlsson1. It takes a filtered complex constructed from an abstract simplicial complex and returns $\\mathcal{P}$-intervals, omitting the construction of computationally challenging persistent modules and calculating persistent homology through matrix reduction. Furthermore, the actual implementation does not even use matrix operations.\nDerivation Derivation of Zomorodian\u0026rsquo;s algorithm: It\u0026rsquo;s certain that without understanding the theoretical aspects of the algorithm, one could not comprehend the algorithm just by looking at the pseudocode. Even if one does not understand it perfectly, one should study enough to grasp why matrices suddenly disappear and why marking is necessary before moving on to implementation. Algorithm Let\u0026rsquo;s assume we have received a filtered complex as data before the algorithm operates.\nLet\u0026rsquo;s create a dictionary or table $T$ like the one above to store data and record information from the algorithm. For example, in a Julia DataFrame, you would copy the numbers in the data to epsilon, the alphabetic part to simplex, and add a boolean column marked to store the marking status, a slot to store the chains of the chain complex, and a column J to store integers that come out during the calculation.\nJulia arrays start at $1$, not $0$, and there are parts where indices are not considered for convenience of implementation, so there are cases where numbers are all wrong by $1~2$ like the screenshot above, but it\u0026rsquo;s not important at all, so don\u0026rsquo;t worry about it. Note that the slot for storing chains can freely switch between representations as a set and as a chain. For example, the calculation is on $\\mathbb{Z}_{2}$ so $$ a + (a - b) = 2 a - b = b \\pmod{2} $$ such calculation takes place, which is also the same as the following set operation $$ \\left\\{ a \\right\\} \\cup \\left\\{ a, -b \\right\\} = \\left\\{ b \\right\\} $$ In algebraic operations, the element $0$ is treated as \u0026rsquo;nonexistent\u0026rsquo; in the set and should be accepted as such. It might be unpleasant for those who like precise and meticulous notation, but it\u0026rsquo;s not entirely unreasonable, so let\u0026rsquo;s just move on. Also, the original paper derives the algorithm over a general field $F$, meaning every $q \\in F$ has an inverse $q^{-1} \\in F$, so calculations like $$ d = d - q^{-1} T[i] $$ are performed, but in this implementation, the binary field $\\mathbb{Z}_{2}$ is sufficient, so $q^{-1}$ is not calculated separately and is replaced for $\\Delta$ defined as $A \\Delta B := \\left( A \\cup B \\right) \\setminus \\left( A \\cap B \\right)$ like the following. $$ d = d \\Delta T[i] $$ The expression $\\deg$ appears too frequently as a (program) function, an index, and the degree of a polynomial function, causing confusion. Therefore, in $T$, it\u0026rsquo;s denoted as epsilon instead of deg. In fact, in simple level topological data analysis, the value of that column, the radius $\\varepsilon \u0026gt; 0$, usually increases to construct a filtered complex. $T$ assumes a perfect alignment according to the dimensions of the simplices, and accordingly, epsilon is expected to have a partial order. Pseudocode $\\left\\{ L_{k} \\right\\}$ = COMPUTEINTERVALS$(K)$\nInput: Receives a filtered complex $K$. The filtered complex must have at least two pieces of information: at what timing $\\deg \\in \\mathbb{Z}$ a certain simplex $\\sigma$ was added. Output: Obtains a set $\\left\\{ L_{k} \\right\\}_{k=0}^{\\dim K}$ of sets $L_{k}$ of $\\mathcal{P}$-intervals for $k = 0, \\cdots , \\dim K$. Side Effect: Modifies marked in table $T$ where data is recorded. $d$ = REMOVEPIVOTROWS$(\\sigma)$\nInput: Receives a $k$-dimensional simplex $\\sigma$. Output: Obtains an element of some $\\mathsf{C}_{k-1}$, which is a $(k-1)$-dimensional chain, meaning it\u0026rsquo;s operated on by $k$-dimensional simplices. $i$ = maxindex$d$\nInput: Receives the chain $d$. Output: Returns the largest index $i$ among all simplex included in chain $d$ in table $T$. For example, for maxindex(abc), it should return the largest $9$ among $5$ of ab, $6$ of bc, and $9$ of ac. $k$ = dim$d$\nInput: Receives a $k$-dimensional chain $d$. Output: Returns the integer $k$. $k$ = dim$\\sigma$\nInput: Receives a $k$-dimensional simplex $\\sigma$. Output: Returns the integer $k$. $k$ = deg$(\\sigma)$\nInput: Receives the simplex $\\sigma$. Output: Returns the integer epsilon corresponding to simplex $\\sigma$ in table $T$. For example, if deg(cd), it should return $2$ since epsilon of cd is $2$. Keywords\nMark is used in the form Mark $\\sigma$ to change the marked of the corresponding simplex $\\sigma$ to true. Store is used in the form Store $j$ and $d$ in $T[i]$ to store the integer $j$ in J of $T[i]$ and the chain $d$ in slot. Remove is used in the form Remove $x$ in $d$ to remove the term $x$ in the chain $d$. $\\sigma^{i}$ is the simplex at the $i$th position in table $T$, and $m$ is the length of $T$.\nfunction COMPUTEINTERVALS$(K)$\n# Initialization\nfor $k \\in 0:\\dim K$\n$L_{k} := \\emptyset$\nend for\nfor $j \\in 0:(m-1)$\n$d$ = REMOVEPIVOTROWS$\\left( \\sigma^{j} \\right)$\nif $d = \\emptyset$\n# $d$ being empty means it\u0026rsquo;s a candidate for a (non-pivot) zero column\nmark $\\sigma^{j}$\nelse\n# Must calculate the degree of $d$, so it must be the max of all terms\n# $d$ is a chain one dimension lower than $\\sigma^{j}$ and must be $i \u0026lt; j$\n$i$ = maxindex$d$\n$k$ = dim$d$\n$L_{k}$ = $L_{k} \\cup \\left\\{ \\left( \\deg \\sigma^{i}, \\deg \\sigma^{j} \\right) \\right\\}$\nend if\nend for\nfor $j \\in 0:(m-1)$\n# If it\u0026rsquo;s still not marked, it\u0026rsquo;s definitely a zero column\nif $\\sigma^{j}$ ismarked and $T[j]$ isempty\n$k$ = dim$d$\n# Corresponds to $H_{k-1}$ to $\\sum^{\\hat{e}_{i}} F[t]$, handling infinity\n$L_{k}$ = $L_{k} \\cup \\left\\{ \\left( \\deg \\sigma^{i}, \\infty \\right) \\right\\}$\nend if\nend for\nreturn $\\left\\{ L_{k} \\right\\}$\nend function\nfunction REMOVEPIVOTROWS$(\\sigma)$\n$k$ = $\\dim \\sigma$\n# Assuming $\\partial abc = ab - bc + ca$, ‚àÇ(\u0026quot;abc\u0026quot;) = [\u0026quot;ab\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;ca\u0026quot;]\n$d$ = $\\partial_{k} \\sigma$\nRemove not marked $(k-1)$-dimensional simplex in $d$\nwhile $d \\ne \\emptyset$\n$i$ = maxindex$d$\nif $T[i]$ isempty\nbreak\nend if\n# Since it\u0026rsquo;s $\\mathbb{Z}_{2}$, replace with symdiff (symmetric difference)\n$d$ = $d \\Delta T[i]$\nend while\nreturn $d$\nend function\nImplementation The result of the algorithm for the given example should be as follows: $$ \\begin{align*} L_{0} =\u0026amp; \\left\\{ \\left( 0, \\infty \\right) , \\left( 0,1 \\right) , \\left( 1,1 \\right) , \\left( 1,2 \\right) \\right\\} \\\\ L_{1} =\u0026amp; \\left\\{ \\left( 2,5 \\right) , \\left( 3,4 \\right) \\right\\} \\end{align*} $$\nThe result of the implementation in Julia is as follows. Except for the parts where the indices are precisely incorrect, it can be seen that it has been implemented correctly.\nFull Code As you can see, the code is written almost exactly following the notation of the original paper. For instance, the Julia-like code for $$ L_{k} = L_{k} \\cup \\left\\{ \\left( \\deg \\sigma^{i}, \\deg \\sigma^{j} \\right) \\right\\} $$ is push!(L_[k], (deg(œÉ‚Å±), deg(œÉ ≤))), but to make it look almost identical to the paper, it\u0026rsquo;s implemented as L_[k] = L_[k] ‚à™ [(deg(œÉ‚Å±), deg(œÉ ≤))].\nusing DataFrames\rdata = DataFrame([\r0 \u0026#34;a\u0026#34;\r0 \u0026#34;b\u0026#34;\r1 \u0026#34;c\u0026#34;\r1 \u0026#34;d\u0026#34;\r1 \u0026#34;ab\u0026#34;\r1 \u0026#34;bc\u0026#34;\r2 \u0026#34;cd\u0026#34;\r2 \u0026#34;ad\u0026#34;\r3 \u0026#34;ac\u0026#34;\r4 \u0026#34;abc\u0026#34;\r5 \u0026#34;acd\u0026#34;\r], [\u0026#34;epsilon\u0026#34;, \u0026#34;simplex\u0026#34;])\rT = copy(data)\rT[!, :\u0026#34;marked\u0026#34;] .= false\rT[!, :\u0026#34;slot\u0026#34;] .= [[]]\rT[!, :\u0026#34;J\u0026#34;] .= 0\rdimK = 2\rm = nrow(T)\rtest_œÉ = \u0026#34;abc\u0026#34;\rdim(œÉ) = length(œÉ)\rfunction deg(œÉ)\rreturn T.epsilon[findfirst(T.simplex .== œÉ)]\rend\rdeg(test_œÉ)\rfunction ‚àÇ(œÉ)\rk = dim(œÉ)\rreturn [œÉ[(1:k)[Not(t)]] for t = 1:k]\rend\r‚àÇ(test_œÉ)\rfunction maxindex(chain)\rreturn (T.simplex .‚àà Ref(chain)) |\u0026gt; findall |\u0026gt; maximum\rend\rmaxindex(‚àÇ(test_œÉ))\rfunction REMOVEPIVOTROWS(œÉ)\rk = dim(œÉ); d = ‚àÇ(œÉ)\rd = d[d .‚àà Ref(T[T.marked,:simplex])] # Remove unmarked terms in ‚ñ∑eq029‚óÅ\rwhile !(d |\u0026gt; isempty)\ri = maxindex(d)\rif T[i,:slot] |\u0026gt; isempty break end\rd = symdiff(d, T[i,:slot])\r# print(\u0026#34;d in empty\u0026#34;)\rend\rreturn d\rend\rREMOVEPIVOTROWS(test_œÉ)\rL_ = [[] for k = 0:dimK]\rfor j0 = 0:(m-1)\rj = j0+1\rœÉ ≤ = T[j,:simplex]\rd = REMOVEPIVOTROWS(œÉ ≤)\rif d |\u0026gt; isempty\rT[j,:marked] = true\relse\ri = maxindex(d); k = dim(œÉ ≤)\rœÉ‚Å± = T[i,:simplex]\rT[i,[:J,:slot]] = j0,d\rL_[k] = L_[k] ‚à™ [(deg(œÉ‚Å±), deg(œÉ ≤))]\rend\rend\rfor j0 = 0:(m-1)\rj = j0+1\rœÉ ≤ = T[j,:simplex]\rif (T[j,:marked]) \u0026amp;\u0026amp; (T[j,:slot] |\u0026gt; isempty) \u0026amp;\u0026amp; (T[j,:J] |\u0026gt; iszero)\rk = dim(œÉ ≤); L_[k] = L_[k] ‚à™ [(deg(œÉ ≤), Inf)]\rprint(\u0026#34;j: $j\u0026#34;)\rend\rend Zomorodian. (2005). Computing Persistent Homology: ch4\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2449,"permalink":"https://freshrimpsushi.github.io/en/posts/2449/","tags":null,"title":"Implementation of Zomorodian's Algorithm"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definition 1 Let\u0026rsquo;s assume we are given $n$ quantitative data.\nThe difference $\\left( \\overline{x} - x_{i} \\right)$ between the sample mean $\\overline{x}$ and the data is called the deviation. The value $s^{2}$, which is the sum of the squares of deviations divided by $n-1$, is known as the variance of a sample. $$ s^{2} := {{ \\sum \\left( x_{i} - \\overline{x} \\right)^{2} } \\over { n-1 }} $$ Taking the square root of the sample variance $s = \\sqrt{s^{2}}$ is referred to as the standard deviation. Description Dispersion refers to how spread out the data is, and it is also known as variability or spread. Variance is a measure of this dispersion and is considered the second most important statistic after the mean.\nSee Also When first encountering statistics, one might wonder why calculations involve squaring and why dividing by $n-1$ instead of $n$; these points can seem troublesome. As one majors in statistics and advances in their studies, they will encounter mathematical theories (which are by no means easy) that provide answers to these questions. If you are a freshman, it\u0026rsquo;s okay to just accept it for now.\nReasons for dividing the sample variance by $n-1$ Mathematical properties of descriptive statistics: The mean has the property of minimizing variance. Mathematical definition of variance in statistics Mendenhall. (2012). Introduction to Probability and Statistics (13th Edition): p60~63.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2448,"permalink":"https://freshrimpsushi.github.io/en/posts/2448/","tags":null,"title":"Definition of Variance in Basic Statistics"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Overview The paper \u0026ldquo;Computing Persistent Homology\u0026rdquo; by Zomorodian and Carlsson introduces an algorithm for deriving $\\mathcal{P}$-intervals from a Filtered Complex created by an Abstract Simplicial Complex, bypassing the construction of Persistent Modules that are challenging to handle computationally, and computing persistent homology through matrix reduction1.\nDerivation Part 0. Preliminary Investigation\nThe derivation of the algorithm starts by examining the form of a Persistence Complex depicted as above, crucial for understanding the subsequent mathematical expressions.\nThe numbers at the bottom are denoted as $\\deg$, forming a Filtered Complex as they increase from $0$ to $5$. $$ \\left\\{ a,b \\right\\} = K_{0} \\subset K_{1} \\subset K_{2} \\subset K_{3} \\subset K_{4} \\subset \\left( K_{4} \\cup \\left\\{ acd \\right\\} \\right) = K_{5} $$ Regardless of $\\deg$, $K$, as a $2$-Simplex, forms a Chain Complex in the context of Homology. $$ \\mathsf{C}_{2} \\overset{\\partial_{2}}{\\longrightarrow} \\mathsf{C}_{1} \\overset{\\partial_{1}}{\\longrightarrow} \\mathsf{C}_{0} $$ The algorithm aims to compute how algebraic topological information provided by data, such as Betti Numbers $\\beta_{k}$, emerges and disappears over $\\deg$. $$ \\begin{align*} L_{0} =\u0026amp; \\left\\{ \\left( 0, \\infty \\right) , \\left( 0,1 \\right) , \\left( 1,1 \\right) , \\left( 1,2 \\right) \\right\\} \\\\ L_{1} =\u0026amp; \\left\\{ \\left( 2,5 \\right) , \\left( 3,4 \\right) \\right\\} \\end{align*} $$\n$L_{0}$ consists of $\\mathcal{P}$-intervals showing when components appear and vanish, while $L_{1}$ comprises $\\mathcal{P}$-intervals indicating the emergence and disappearance of \u0026lsquo;holes\u0026rsquo; in space.\nPart 1. $\\partial_{1}$\nThe paper suggests that the computation is possible over any Field, focusing on calculations within a $\\mathbb{Z}_{2} [t]$-module, an Graded Module. The homogeneous basis for $\\mathsf{C}_{k}$ is denoted as $\\left\\{ e_{j} \\right\\}$ and for $\\mathsf{C}_{k-1}$ as $\\left\\{ \\hat{e}_{i} \\right\\}$, where \u0026lsquo;homogeneous\u0026rsquo; implies single-term expressions, not polynomials like $t^{2} + t$ but monomials like $t^{4}$.\n$$ \\deg M_{k} (i,j) = \\deg e_{j} - \\deg \\hat{e}_{i} $$ Familiarity with Homological Algebra implies constructing the Boundary Matrix $M_{k}$ corresponding to $\\partial_{k}$ and finding its Smith Normal Form $\\tilde{M}_{1}$. For $k=1$, the unique $M_{1}$ can be obtained, considering the matrix bases are homogeneous.\nConstructing a matrix using these bases can be seen as the inverse operation of applying $t^{n}$, a Group Action raising the degree in the graded module. Let\u0026rsquo;s perform a few direct calculations to grasp the concept. $$ \\begin{align*} \\deg M_{1} (2,5) =\u0026amp; \\deg ac - \\deg c = 3 - 1 = 2 = \\deg t^{2} \\\\ \\deg M_{1} (4,5) =\u0026amp; \\deg ac - \\deg a = 3 - 0 = 3 = \\deg t^{3} \\\\ \\deg M_{1} (2,2) =\u0026amp; \\deg bc - \\deg c = 1 - 1 = 0 = \\deg t^{0} = \\deg 1 \\end{align*} $$\nAs mentioned before, once we form the Echelon Form, specifically the Column-Echelon Form, it appears as shown below:\nRecalling linear algebra from undergraduate studies, the elements at the top of each column that are non-zero, marked with rectangles in the image, are known as pivots. Here, we introduce two auxiliary lemmas:\n(1): The diagonal elements of the Column-Echelon Form are the same as those in the Smith Normal Form. (2): If the pivot of the $i$th row in $\\tilde{M}_{k}$ is $\\tilde{M}_{k} (i,j) = t^{n}$, it corresponds to $\\sum^{\\deg \\hat{e}_{i}} F[t] / t^{n}$ in the Homology Group $H_{k-1}$, otherwise it corresponds to $\\sum^{\\deg \\hat{e}_{i}} F[t]$ in $H_{k-1}$. This equates to $L_{k-1}$ being composed of intervals $( \\deg \\hat{e}_{i} , \\deg \\hat{e}_{i} + n )$ and $( \\deg \\hat{e}_{i} , \\infty )$. In other words,\nBy auxiliary lemma (1), only column operations are needed to compute persistent homology, eliminating the need for row operations. According to auxiliary lemma (2), $L_{k-1}$ consists of intervals $( \\deg \\hat{e}_{i} , \\deg \\hat{e}_{i} + n )$ and $( \\deg \\hat{e}_{i} , \\infty )$. Since the pivot of the first row is $t^{1}$ and $\\deg d = 1$, we obtain $(1,1+1)$. Since the pivot of the second row is $t^{0}$ and $\\deg c = 1$, we obtain $(1,1+0)$. Since the pivot of the third row is $t^{1}$ and $\\deg b = 0$, we obtain $(0,0+1)$. Since there is no pivot for the fourth row and $\\deg a = 0$, we obtain $(0,\\infty)$. This matches precisely with the previously mentioned $L_{0}$, expressed as: $$ L_{0} = \\left\\{ (0, \\infty) , (0,1) , (1,1) , (1,2) \\right\\} $$\nPart 2. $\\partial_{2}$\nTo find $L_{1}$, the matrix form $M_{2}$ of $\\partial_{2}$ is as shown above. However, with the following auxiliary lemma, we can simplify and ease the calculation process:\n(3): To represent the standard basis of $\\mathsf{C}_{k+1}$ and $\\mathsf{Z}_{k}$ for $\\partial_{k+1}$, rows corresponding to $\\tilde{M}_{k}$ can simply be removed from $M_{k+1}$. In our specific context, this means that from the $1$-simplices $ab, bc, cd, ad, ac$ in $\\tilde{M}_{1}$, only the pivots $cd, bc, ab$ remain, so we can directly delete these from $M_{2}$. Intuitively, this implies that since these elements have already been used in dimension $k$, they are not needed for dimension $k+1$. By omitting the direct construction of column-echelon form $\\tilde{M}_{2}$ and removing those three rows, we obtain the truncated form $\\check{M}_{2}$ as follows:\n$$ \\begin{align*} z_{2} =\u0026amp; ac - bc - ab \\ z_{1} =\u0026amp; ad - bc - cd - ab \\end{align*} $$\nFollowing auxiliary lemma (2) again for the computation:\nThe pivot of the first row is $t^{1}$, and since $$ \\deg z_{2} = \\deg ( ac - bc - ab ) = \\max \\deg { ac , bc , ab } = 3, $$ we obtain the interval $(3,3+1)$. The pivot of the second row is $t^{3}$, and since $$ \\deg z_{1} = \\deg ( ad - bc - cd - ab ) = \\max \\deg { ad , bc , cd , ab } = 2, $$ we obtain the interval $(2,2+3)$. This exactly matches the previously mentioned $L_{1}$, expressed as: $$ L_{1} = { (2,5), (3,4) } $$\nRepeating this process for each dimension $\\dim K$ of the complex $K$ yields the desired algorithm. The dimensions of the matrix follow $\\partial_{k}$, and its elements are filled according to $\\deg$, which should help clarify the procedure.\n‚ñ†\nLemma (1) indicates that only column operations are necessary, suggesting no strict need for matrix representation. Moreover, lemma (3) allows for efficient procedure by boldly removing rows already computed, requiring capabilities like \u0026lsquo;marking\u0026rsquo; non-pivot columns. Consequently, the actual algorithm\u0026rsquo;s pseudocode is likely described using higher-level data structures, such as dictionaries or dataframes, rather than matrices directly, which can be quite challenging and confusing in practice.\nImplementation Zomorodian\u0026rsquo;s Algorithm Implementation: Introduces an almost literary translation of the paper\u0026rsquo;s pseudocode into the Julia language, accessible to anyone in the scientific community. Zomorodian. (2005). Computing Persistent Homology: ch4\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2447,"permalink":"https://freshrimpsushi.github.io/en/posts/2447/","tags":null,"title":"Derivation of Zomorodian's Algorithm"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definitions1 When given qualitative data, the category with the highest frequency is called the Mode. In the case of quantitative data, the class with the highest frequency is called the Modal Class.\nDescription Literally meaning \u0026rsquo;the most frequent value\u0026rsquo;, the mode disregards all information except for that singular value. Unless dealing with qualitative data, its significance greatly diminishes, making it not so important when handling real data. When viewed through a probability distribution, the mode becomes the point where the probability density function reaches its maximum value.\nSee Also Three Representative Values in Statistics: Mode, Median, Average Average Median Mode Mathematical Properties of Representative Values: The mode has the property of minimizing the Hamming Loss. Mendenhall. (2012). Introduction to Probability and Statistics (13th Edition): p57.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2446,"permalink":"https://freshrimpsushi.github.io/en/posts/2446/","tags":null,"title":"Definition of the Mode in Basic Statistics"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definition 1 Given $n$ quantitative data in ascending order, the value located in the middle of all the data is called the median $m$. If $n$ is odd, $m := x_{(n+1)/2}$ is used, and if $n$ is even, any values that satisfy the following are considered the median. $$ x_{1} \\le \\cdots \\le x_{ \\lceil {{ n+1 } \\over { 2 }} \\rceil } \\le m \\le x_{ \\lceil {{ n+1 } \\over { 2 }} \\rceil + 1} \\le \\cdots \\le x_{n} $$\nHere, $\\lceil \\cdot \\rceil : \\mathbb{R} \\to \\mathbb{Z}$ is the ceiling function.\nExplanation The median serves as a measure of center, which, compared to the average, is less sensitive to outliers but is not guaranteed to be unique. As mentioned in the definition, if the number of samples is even, there are infinitely many possible medians, though mathematically, in reality, it is simply narrowed down to one as follows. $$ m := \\left( x_{\\lceil {{ n+1 } \\over { 2 }} \\rceil} + x_{ \\lceil {{ n+1 } \\over { 2 }} \\rceil + 1} \\right) / 2 $$\nFor example, if the given data is $$ 1,2,5,8,9 $$ since the number of samples is odd, $m = 5$ in the middle is the median, and if it is $$ 1,2,2,4,7,81 $$ then $2 \\le m \\le 4$ are all medians, but it is usually reduced to $m = (2+4)/2 = 3$. Here, because of a large outlier like $81$, the average rises to $16.16$, but the median remains unaffected.\nSee also Three representational values in statistics: Mode, Median, Mean Mean Median Mode Mathematical Properties of Representative Values: The median has the property of minimizing the sum of deviations. Mendenhall. (2012). Introduction to Probability and Statistics (13th Edition): p55.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2444,"permalink":"https://freshrimpsushi.github.io/en/posts/2444/","tags":null,"title":"Definition of Median in Basic Statistics"},{"categories":"ÌôïÎ•†Î°†","contents":"Overview This is a summary of definitions and concepts for those who have already studied measure theory and probability. It is intended to be viewed when definitions are confusing or unrecognizable, and when a general review is needed.\nMeasure Theory Algebras An algebra of sets on nonempty set $X$ is a nonempty collection $\\mathcal{A}$ of subsets of $X$ is colsed under finite unions ans complements.\n$\\sigma$-algebra is an algebra that is closed under countable unions.\nNote:\n$\\mathcal{A}$ is also closed under intersections, because $E_{1} \\cap E_{2} = \\left( E_{1} \\cup E_{2} \\right)^{c} \\in \\mathcal{A}$ for $E_{1}, E_{2} \\in \\mathcal{A}$. $\\varnothing$, $X$ $\\in \\mathcal{A}$, since if $E \\in \\mathcal{A}$ we have $\\varnothing = E \\cap E^{c} \\in \\mathcal{A}$ and $X = E \\cup E^{c} \\in \\mathcal{A}$. If $X$ any topological space, the $\\sigma$-algebra generated by the family of open sets in $X$ is called the Borel $\\sigma$-algebra on $X$ and is denoted by $\\mathcal{B}_{X}$.\nBorel $\\sigma$-algebra is unique smallest $\\sigma$-algebra containing all open sets. Let $\\mathcal{E}$ be a $\\sigma$-algebra on $X$, then $(X, \\mathcal{E})$ is called a measurable space and $E \\in \\mathcal{E}$ is called ($\\mathcal{E}$-)measurable set.\nIn the following, we shall consider a fixed measurable space $(X, \\mathcal{E})$.\nMeasurable Functions A function $f : X \\to \\mathbb{R}$ is said to be ($\\mathcal{E}$-)measurable, if for every real number $\\alpha \\in \\mathbb{R}$ the set $\\left\\{ x \\in X : f(x) \\gt \\alpha \\right\\}$ belongs to $\\mathcal{E}$.\nGeneralization Let $(X, \\mathcal{E})$ and $(Y, \\mathcal{F})$ be a measurable spaces. A function $f : X \\to Y$ is called $(\\mathcal{E}, \\mathcal{F})$-measurable, if $f^{-1}(F) = \\left\\{ x \\in X : f(x) \\in F \\right\\}$ belongs to $\\mathcal{E}$ for all $F \\in \\mathcal{F}$.\nNote: A $\\mathcal{E}$-measurable function is equivalent to this definition in the case $(Y, \\mathcal{F}) = (\\mathbb{R}, \\mathcal{B}_{\\mathbb{R}})$.\nMeasures A measure on $\\mathcal{E}$ (or on $(X, \\mathcal{E})$, or simply on $X$ if $\\mathcal{E}$ is understood) is a function $\\mu : \\mathcal{E} \\to [0, \\infty]$ such that\nNull empty set: $\\mu (\\varnothing) = 0$. Countable additivity: If $\\left\\{ E_{j} \\right\\}$ is a sequence of disjoint sets in $\\mathcal{E}$, then $\\displaystyle \\mu \\left( \\bigcup\\limits_{j} E_{j} \\right) = \\sum\\limits_{j} \\mu (E_{j})$. A triple $(X, \\mathcal{E}, \\mu)$ is called a measure space and we shall be working on a fixed measure space $(X, \\mathcal{E}, \\mu)$.\nA Borel measure on $\\mathbb{R}$ is a measure whose domain is the Borel $\\sigma$-algebra $\\mathcal{B}_{\\mathbb{R}}$: $$ \\mu : \\mathcal{B}_{\\mathbb{R}} \\to [0, \\infty] $$\nFor two measures $\\mu$ and $\\nu$ on each $(X, \\mathcal{E})$ and $(Y, \\mathcal{F})$, measure $\\mu \\times \\nu$ is the product of $\\mu$ and $\\nu$ which is the unique measure on $\\mathcal{E} \\times \\mathcal{F}$ such that $\\mu \\times \\nu (E \\times F) = \\mu (E) \\nu (F)$ for all rectangles $E \\times F$.\nThe Integral A real-valued function $f$ is simple if it has only a finite number of values.\nA simple measurable function $\\varphi$ can be represented in the form $$ \\begin{equation} \\varphi = \\sum\\limits_{j=1}^{n} a_{j}\\chi_{E_{j}}, \\text{ where } E_{j} = \\varphi^{-1}(\\left\\{ a_{j} \\right\\}) \\text{ and } \\operatorname{range} (\\varphi) = \\left\\{ a_{1}, \\dots, a_{n} \\right\\}. \\end{equation} $$ where $\\chi_{E_{j}}$ is the characteristic function of $E_{j}$. We call this standard representation of $\\varphi$.\nIf $\\varphi$ simple measurable function with standard representation $(1)$, we define the integral of $\\varphi$ with respect to measure $\\mu$ by $$ \\int \\varphi d\\mu := \\sum\\limits_{j=1}^{n} a_{j}\\mu (E_{j}). $$ Notation: $$ \\int \\varphi d\\mu = \\int \\varphi = \\int \\varphi(x) d\\mu (x), \\qquad \\int = \\int_{X}. $$\nIf $f$ is measurable function on $(X, \\mathcal{E})$, we define the integral of $f$ with respect to $\\mu$ by $$ \\int f d\\mu := \\sup \\left\\{ \\int \\varphi d\\mu : 0 \\le \\varphi \\le f, \\varphi \\text{ is simple and measurable} \\right\\}. $$\nThe positive and negative parts of $f : X \\to \\mathbb{R}$ are defined repectively as $$ f^{+}(x) := \\max \\left( f(x), 0 \\right)),\\qquad f^{-1}(x) := \\min \\left(-f(x), 0 \\right)). $$ If $\\displaystyle \\int f^{+}$ and $\\displaystyle \\int f^{-}$ are both finite, then we say that $f$ is integrable. Also $\\left| f \\right| = f^{+} - f^{-}$.\nThe set of real-valued integrable functions is a vector space and the integral is a linear functional on it. This vector space is denoted as: $$ L = L(X, \\mathcal{E}, \\mu) = L(X, \\mu) = L(X) = L(\\mu), \\qquad L = L^{1} $$\n$L^{p}$ space For measure space $(X, \\mathcal{E}, \\mu)$ and $0 \\lt p \\lt \\infty$, we define $$ L^{p}(X, \\mathcal{E}, \\mu) := \\left\\{ f : X \\to \\mathbb{R} \\left| f \\text{ is measurable and } \\left( \\int \\left| f \\right|^{p} d\\mu \\right)^{1/p} \\lt \\infty \\right. \\right\\}. $$ $$ {} \\\\ {} \\\\ {} \\\\ $$\nProbability Theory Notation and Terminology $$ \\begin{array}{lll} \\text{Analysts\u0026rsquo; Term} \u0026amp;\u0026amp; \\text{Probabilists\u0026rsquo; Term} \\\\ \\hline \\text{Measure space } (X, \\mathcal{E}, \\mu) \\text{ such that } \\mu (X) = 1 \u0026amp;\u0026amp; \\text{Probability space } (\\Omega, \\mathcal{F}, P) \\\\ \\text{Measure } \\mu : \\mathcal{E} \\to \\mathbb{R} \\text{ such that } \\mu (X) = 1 \u0026amp;\u0026amp; \\text{Probability } P : \\mathcal{F} \\to \\mathbb{R} \\\\ (\\sigma\\text{-)algebra $\\mathcal{E}$ on $X$} \u0026amp;\u0026amp; (\\sigma\\text{-)field $\\mathcal{F}$ on $\\Omega$} \\\\ \\text{Mesurable set } E \\in \\mathcal{E} \u0026amp;\u0026amp; \\text{Event } E \\in \\mathcal{F} \\\\ \\text{Measurable real-valued function } f : X \\to \\mathbb{R} \u0026amp;\u0026amp; \\text{Random variable } X : \\Omega \\to \\mathbb{R} \\\\ \\text{Integral of } f, {\\displaystyle \\int f d\\mu} \u0026amp;\u0026amp; \\text{Expextation of } f, E(X) \\\\ f \\text{ is } L^{p} \u0026amp;\u0026amp; X \\text{ has finite $p$th moment} \\\\ \\text{Almost everywhere, a.e.} \u0026amp;\u0026amp; \\text{Almost surely, a.s.} \\end{array} $$\n$$ \\begin{align*} \\left\\{ X \\gt a \\right\\} \u0026amp;:= \\left\\{ w : X(w) \\gt a \\right\\} \\\\ P\\left( X \\gt a \\right) \u0026amp;:= P\\left( \\left\\{ w : X(w) \\gt a \\right\\} \\right) \\end{align*} $$\nBasic Definitions For measurable spacse $(\\Omega, \\mathcal{F})$ and $(\\mathbb{R}, \\mathcal{B}_{\\mathbb{R}})$, $(\\mathcal{F}, \\mathcal{B}_{\\mathbb{R}})$-mearsuable function $X : \\Omega \\to \\mathbb{R}$ is called random variable. Namely, $$ X^{-1}(B) \\in \\mathcal{F}\\qquad \\forall B \\in \\mathcal{B}_{\\mathbb{R}}. $$\nA probability (or probability measure) on $(\\Omega, \\mathcal{F})$ is measure $P : \\mathcal{F} \\to \\mathbb{R}$ such that $P(\\Omega) = 1$.\nIf $X$ is a random variable,\nexpectation: $\\displaystyle E(X) := \\int X dP$ variance: $\\sigma^{2}(X) := E\\left[ (X - E(X))^{2} \\right] = E(X^{2}) - E(X)^{2}$ The (probability) distribution of $X$ is a probability on $\\mathbb{R}$, $P_{X} : \\mathcal{B}_{\\mathbb{R}} \\to \\mathbb{R}$ such that $$ P_{X}(B) := P(X^{-1}(B)). $$\nThe distribution fuction of $X$ is defined as $$ F_{X}(a) := P_{X}\\left( (-\\infty, a] \\right) = P(X \\le a). $$\nFor any finite sequence of random variables $\\left\\{ X_{i} \\right\\}_{i=1}^{n}$, random vector $(X_{1}, \\dots, X_{n})$ is defined as a map from $\\Omega \\to \\mathbb{R}^{n}$: $$ (X_{1}, \\dots, X_{n})(x) := (X_{1}(x), \\dots, X_{n}(x)). $$ Note: $(X_{1}, \\dots, X_{n})^{-1}(B_{1} \\times \\cdots \\times B_{n})= X_{1}^{-1}(B_{1}) \\cap \\cdots \\cap X_{n}^{-1}(B_{n})$.\nFor $(X, Y) : \\Omega \\to \\mathbb{R}^{2}$, $$ (X, Y)^{-1} (a, b) = \\left\\{ x \\in \\Omega : X(x) = a \\right\\} \\cap \\left\\{ x \\in \\Omega : Y(x) = b \\right\\}. $$ Thus, for all Borel sets $B_{1}$ and $B_{2} \\in \\mathcal{B}_{\\mathbb{R}}$ we have $$ (X, Y)^{-1}(B_{1} \\times B_{2}) = (X, Y)^{-1}(B_{1}, B_{2}) = X^{-1}(B_{1}) \\cap Y^{-1}(B_{2}) $$ and extending to $\\mathbb{R}^{n}$ we obtain $$ \\begin{equation} \\begin{aligned} (X_{1}, \\dots, X_{n})^{-1}(B_{1} \\times \\cdots \\times B_{n}) \u0026amp;= (X_{1}, \\dots, X_{n})^{-1}(B_{1}, \\dots, B_{n}) \\\\ \u0026amp;= X_{1}^{-1}(B_{1}) \\cap \\cdots \\cap X_{n}^{-1}(B_{n}). \\end{aligned} \\end{equation} $$\nThe joint distribution of $X_{1}, \\dots, X_{n}$ is a probability distribution of $(X_{1}, \\dots, X_{n})$: $$ P_{(X_{1}, \\dots, X_{n})} : \\mathcal{B}_{\\mathbb{R}^{n}} \\to \\mathbb{R}, $$ $$ P_{(X_{1}, \\dots, X_{n})}(B_{1} \\times \\cdots \\times B_{n}) := P\\left( (X_{1}, \\dots, X_{n})^{-1}(B_{1} \\times \\cdots \\times B_{n}) \\right). $$\nIndependency For an event $E$ such that $P(E) \\gt 0$, a probability on $\\Omega$ $$ P_{E}(F) = P(E|F) := P(E \\cap F)/P(E) $$ is called conditional probability on $E$.\nIf $P_{E}(F) = P(F)$, then $F$ is said to be independent of $E$: $$ \\text{$F$ is independent of $E$} \\iff P(E \\cap F) = P(E)P(F). $$ A collection $\\left\\{ E_{j} \\right\\}$ of events in $\\Omega$ is indepencent if $$ P(E_{1} \\cap \\cdots \\cap E_{n}) = P(E_{1}) P(E_{2}) \\cdots P(E_{n}) = \\prod \\limits_{i=1}^{n} P(E_{j}) $$\nA collection $\\left\\{ X_{j} \\right\\}$ of random variables on $\\Omega$ is independent if the events $\\left\\{ X_{j}^{-1}(B_{j}) \\right\\}$ are independent for all Borel sets $B_{j} \\in \\mathcal{B}_{\\mathbb{R}}$, namely $$ P\\left(X_{1}^{-1}(B_{1}) \\cap \\cdots \\cap X_{n}^{-1}(B_{n})\\right) = \\prod \\limits_{j=1}^{n} P(X_{j}^{-1}(B_{j})). $$\nWe have from LHS by definition of distribution and $(2)$ $$ \\begin{align*} P\\left(X_{1}^{-1}(B_{1}) \\cap \\cdots \\cap X_{n}^{-1}(B_{n})\\right) \u0026amp;= P\\left( (X_{1}, \\dots, X_{n})^{-1}(B_{1} \\times \\cdots \\times B_{n}) \\right) \\\\ \u0026amp;= P_{(X_{1}, \\dots, X_{n})} \\left( B_{1} \\times \\cdots \\times B_{n} \\right). \\end{align*} $$ By the way, we have from RHS by definition of product measure and distribution $$ \\prod \\limits_{j=1}^{n} P(X_{j}^{-1}(B_{j})) = \\prod \\limits_{j=1}^{n} P_{X_{j}}(B_{j}) = \\left( \\prod \\limits_{j=1}^{n} P_{X_{j}} \\right) \\left( B_{1} \\times \\cdots \\times B_{n} \\right). $$ Therefore, if $\\left\\{ X_{j} \\right\\}$ are independent, then $$ P_{(X_{1}, \\dots, X_{n})} = \\prod\\limits_{j=1}^{n}P_{X_{j}}. $$\n$\\left\\{ X_{j} \\right\\}$ is an independent set of random variables if and only if the joint distribution of $\\left\\{ X_{j} \\right\\}$ is the product of their individual distributions.\nReferences Robert G. Bartle, The Elements of Integration and Lebesgue Measure (1995) Gerald B. Folland, Real Analysis: Modern Techniques and Their Applications (1999) ","id":3473,"permalink":"https://freshrimpsushi.github.io/en/posts/3473/","tags":null,"title":"Summary of Measure Theory and Probability Theory"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÍ≤ÄÏ†ï","contents":"Definition 1 2 In science, a statistical hypothesis refers to an assumption about a population, and the statistical decision-making process of accepting or rejecting this hypothesis is called statistical hypothesis testing. This process involves two competing hypotheses, where the hypothesis that the researcher wishes to support is called the alternative hypothesis $H_{1}$, and the hypothesis accepted when there is no substantial evidence to claim that the alternative hypothesis is true is called the null hypothesis $H_{0}$. The statistic used for hypothesis testing is called the test statistic.\nExplanation If you major in statistics, you\u0026rsquo;ll find yourself in a never-ending battle: null hypothesis $H_{0}$ vs alternative hypothesis $H_{1}$\u0026hellip; It may seem very difficult at first, but as you get to know it, you will find both annoyance and fondness, so don\u0026rsquo;t be too scared to learn about it.\nLet\u0026rsquo;s put aside the complex mathematical concepts found in textbooks (like critical region, test statistic, significance level, etc.) for a moment and imagine how hypothesis testing can emerge in everyday situations. Consider the scenario where a hypothetical pharmaceutical company A releases a new drug, a, that assists liver function, specifically by lowering one of the liver enzyme levels, AST:\nFor a to be commercialized, it must pass certain tests by regulatory authorities, such as the Food and Drug Administration, which obviously means proving that a lowers the AST levels. Naturally, this proof shouldn‚Äôt be as simplistic as ‚Äòjust bring in more than 10 people whose AST levels have dropped‚Äô but should make statistical sense. What about having more than 10 out of 100, or ‚Äòmore than 10% of all clinical trial participants‚Äô show reduced levels? This seems more rational than the previous notion, but one could still wonder if lowering AST from 500 to 490, even with 11-40 people, should be considered an effect. One method could be to divide into two groups: one that continuously takes drug a $1$ and another placebo group $2$, then compare the average results of their liver enzyme levels. Let\u0026rsquo;s say the average for the $1$ group is denoted as $\\mu_{1}$, and the average for the $2$ group is denoted as $\\mu_{2}$. The desired outcome for pharmaceutical company A might look something like this. $$ \\mu_{1} \u0026lt; \\mu_{2} $$ According to the definitions mentioned above, the alternative hypothesis can be established as follows. $$ H_{1}: \\mu_{1} \u0026lt; \\mu_{2} $$ Just looking at the formula, comparing the levels of 500 and 490 might still seem problematic. However, now we\u0026rsquo;re talking about statistics of a sample population, not just one or two individuals. For instance, even if it\u0026rsquo;s 500 vs 490, if the variance is 200, it could just be a fluke. But if the variance is around 2, then drug a seems to definitely lower AST levels. [ NOTE: The idea of using the variance of two groups to compare their means seems quite useful. This concept has been developed into what\u0026rsquo;s known as Analysis of Variance. ] But for now, let\u0026rsquo;s return to hypothesis testing. If the alternative hypothesis is established as shown above, the null hypothesis can be the following opposite content. $$ H_{0}: \\mu_{1} \\ge \\mu_{2} $$ It\u0026rsquo;s important to note that the condition for accepting the null hypothesis is \u0026rsquo;there is no substantial evidence that the alternative hypothesis is true\u0026rsquo;, not that the null hypothesis itself is being actively adopted. Acceptance of the null hypothesis comes from the inability to reject it, not because it has been proven to be true. For example, if explorer Columbus\u0026rsquo;s alternative hypothesis was \u0026rsquo;there exists the continent of America\u0026rsquo;, failing to find America on his first voyage doesn‚Äôt make the null hypothesis \u0026rsquo;the continent of America does not exist\u0026rsquo; true. It\u0026rsquo;s accepted for the time being because there\u0026rsquo;s no firm evidence yet, indicating that the absence of evidence is not evidence of absence. Fortunately, let\u0026rsquo;s say the alternative hypothesis $H_{1}$ is proven to be true statistically. Strictly speaking, however, what this analysis reveals is only that the group taking drug a has reduced AST levels. Analysts, who may not have as much expertise in the domain as clinicians or pathologists, can confidently say, \u0026lsquo;for some reason, the effect of the drug is definitely proven\u0026rsquo;, but this doesn\u0026rsquo;t serve as evidence for causality as to how drug a lowers AST levels. See Also A simple definition of hypothesis testing: Introduces a definition that\u0026rsquo;s easier to understand rather than being strictly rigorous. How to set null and alternative hypotheses: Explains possible issues with that definition. A complex definition of hypothesis testing: Introduces a relatively strict mathematical definition of hypothesis testing. Department of Statistics, Kyungpook National University. (2008). Statistics with Excel: p199.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMendenhall. (2012). Introduction to Probability and Statistics (13th Edition): p344.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2442,"permalink":"https://freshrimpsushi.github.io/en/posts/2442/","tags":null,"title":"Simplified Definition of Hypothesis Testing"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Definition 1 Let $K$ be a simplicial complex. A subset $L \\subset K$ is a Subcomplex of $K$ if it is a simplicial complex itself. $$ \\emptyset = K^{0} \\subset K^{1} \\subset \\cdots \\subset K^{m} = K $$ A Nested Sequence of subcomplexes of $K$ is called the Filtration of $K$. Generally, for all $i \\ge m$, it is presumed that $K^{i} = K^{m}$. When such a filtration exists, $K$ is referred to as a Filtered Complex.\nExplanation Ascending Chain The subcomplexes of the above-filtered complex illustrate a structure similar to an Ascending Chain with respect to $m = 0,\\cdots,5$. $$ K^{0} \\subset K^{1} \\subset K^{2} \\subset K^{3} \\subset K^{4} \\subset K^{5} $$ The term filtration suggests an image of the largest simplices being filtered out (in the ‚Üêleft direction) and gradually becoming smaller, although it is not always necessary in mathematics to imagine it solely in a reducing manner.\nTopological Data Analysis Complexes such as the Vietoris-Rips Complex or the Cech Complex are determined by a given radius $\\varepsilon \u0026gt; 0$, and listing the complexes obtained by incrementally increasing this $\\varepsilon$ effectively constitutes a filtered complex. Identifying the Persistency of topological properties that appear and disappear within such filtered complexes is a foundational approach of Topological Data Analysis in characterizing the features of data.\nSee Also Various Filtrations $$ A_{1} \\subset A_{2} \\subset \\cdots \\subset A_{n} \\subset \\cdots $$ Commonly, in mathematics, when a structure forms a Nested Sequence, it is referred to as a Filtration.\nFiltration of a Stochastic Process Filtration of Complexes Flag of Vector Spaces Zomorodian. (2005). Computing Persistent Homology: 2.2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2441,"permalink":"https://freshrimpsushi.github.io/en/posts/2441/","tags":null,"title":"Filtration of Complexes"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definition 1 A Parameter is a numerical descriptive measure associated with a population, while something computed from a sample is referred to as a Statistic.\nExplanation Although there can be various definitions of statistics, fundamentally, it is considered a field of study which primarily focuses on \u0026lsquo;what is a Parameter\u0026rsquo; especially in inferential statistics, a field slightly more abstract from general understanding and favored by majors, including Mathematical Statistics. From this perspective, statistics can be defined as a discipline that studies how to figure out the Parameters of a population through data.\nInterestingly, adding an s to Statistic turns it into Statistics, essentially becoming the subject of study itself. This signifies that statistics is fundamentally the study of statistics, particularly referred to as Estimators when concerning Parameters. For instance, the statistic of adding up all samples and dividing by their count, known as the Sample Mean $\\overline{x}$, is an estimator for finding out the population mean $\\mu$.\nSee Also Statistics and Estimators in Mathematical Statistics Hyperparameter Mendenhall. (2012). Introduction to Probability and Statistics (13th Edition): p50.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2440,"permalink":"https://freshrimpsushi.github.io/en/posts/2440/","tags":null,"title":"Parameter and Statistic in Basic Statistics"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definition 1 $$ \\overline{x} := {{ 1 } \\over { n }} \\sum_{k=1}^{n} x_{k} $$\nWhen $n$ quantitative data are given, the value obtained by adding all those values and dividing by $n$, denoted as $\\overline{x}$, is called the sample mean, arithmetic mean, or average.\nDescription There\u0026rsquo;s no need to explicitly explain how averages can efficiently summarize data. Anyone studying statistics beyond the undergraduate level should be able to address the following inquiries and know when to be cautious of averages:\nIs the average always reliable? Obviously not. There\u0026rsquo;s a famous joke going around the internet that the department with the highest average salary at the University of North Carolina is the Geography Department.2 As that amusing anecdote suggests, averages are vulnerable to outliers and may not always be appropriate to use as a representative value. When is it particularly risky? When the sample size is too small, there are many outliers, the distribution is not unimodal, amongst others. Although rare, it\u0026rsquo;s theoretically possible to envisage situations where the population mean does not exist. Why is it still considered so important? Because of the Central Limit Theorem. It\u0026rsquo;s this powerful theorem that states the probability distribution of the sample mean of any random sample from any distribution approaches a normal distribution as the sample size gets larger. Despite its simplicity, it forms the foundation of statistics and thus holds significant value. Those studying statistics should be mindful of when averages may lose their meaning, and develop the habit of scrutinizing data closely. In essence, knowing when not to rely on averages is just as crucial as knowing how to apply them correctly. The following tweet, albeit exaggerated, warns about how meaningless averages can become if the data is ignored:\nSee Also Three main statistical measures: Mode, Median, Mean Mean Median Mode Mathematical properties of measures of central tendency: The mean has the property of minimizing variance. Mendenhall. (2012). Introduction to Probability and Statistics (13th Edition): p54.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","id":2438,"permalink":"https://freshrimpsushi.github.io/en/posts/2438/","tags":null,"title":"Definition of Mean in Basic Statistics"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"ÏÑ§Î™Ö Using the Distributions.jl package, you can randomly sample from a given distribution.\n","id":3463,"permalink":"https://freshrimpsushi.github.io/en/posts/3463/","tags":null,"title":"Sampling Randomly from a Given Distribution in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Description1 In Julia, the function for random sampling is as follows:\nrand([rng=default_rng()], [S], [dims...]) rng stands for Random Number Generator, which specifies the random number generation algorithm. If you don\u0026rsquo;t understand what this means, it\u0026rsquo;s okay to leave it untouched.\nS likely stands for Set, and it is a variable that specifies the set from which the random sampling will occur. The variables that can be input for S include the following:\nObjects with indices AbstractDict or AbstractSet Strings Types (only integers and floating points are possible. Rational and irrational numbers are not allowed.) When the extraction set is specified as a type, if it\u0026rsquo;s an integer type, random numbers are drawn from the range of typemin(S):type(S) (does not support BigInt).\njulia\u0026gt; typemin(Int16), typemax(Int16)\r(-32768, 32767)\rjulia\u0026gt; typemin(Int32), typemax(Int32)\r(-2147483648, 2147483647)\rjulia\u0026gt; typemin(Int64), typemax(Int64)\r(-9223372036854775808, 9223372036854775807) If it\u0026rsquo;s a floating-point, random numbers are drawn from the range of $[0, 1)$.\njulia\u0026gt; rand(Float64)\r0.4949745522302659\rjulia\u0026gt; rand(ComplexF64)\r0.8560168003603014 + 0.16478582700545064im [dims...] denotes the dimensions of the array to be drawn. If it\u0026rsquo;s rand(S, m, n), it draws $m \\times n$ elements (including duplicates) from the set S and returns an array of shape $m \\times n$. If dimensions are not specified, a real number is returned. Be careful because real numbers and 1-dimensional vectors are distinctly differentiated. Also, be careful when you wish to obtain an array of shape $2\\times 3$ and input the dimensions as a tuple like (2,3), as it gets treated as a variable for S, yielding a completely different result.\njulia\u0026gt; rand(Float64) # Ïã§Ïàò Ï∂îÏ∂ú\r0.42226201756172266\rjulia\u0026gt; rand(Float64, 1) # ÏÑ±Î∂ÑÏù¥ Ïã§ÏàòÏù∏ 1x1 Î∞∞Ïó¥Î°ú Ï∂îÏ∂ú\r1-element Vector{Float64}:\r0.7361136057571305\rjulia\u0026gt; rand(2,3) # ÏÑ±Î∂ÑÏù¥ Ïã§ÏàòÏù∏ 2x3 Î∞∞Ïó¥Î°ú Ï∂îÏ∂ú 2√ó3 Matrix{Float64}:\r0.648742 0.364548 0.0550352\r0.0350098 0.56055 0.83297\rjulia\u0026gt; rand((2,3)) # 2ÏôÄ 3Ï§ëÏóêÏÑú Ï∂îÏ∂ú\r3 For more advanced content, refer to the following:\nHow to fix random seed How to randomly sample with weights How to randomly sample with a distribution Code Objects with Indices julia\u0026gt; rand((2,5))\r5\rjulia\u0026gt; rand(2:5)\r3\rjulia\u0026gt; rand([2,3,4,5])\r4\rjulia\u0026gt; rand([\u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;, 4])\r\u0026#34;x\u0026#34; Dictionary If the sampling set is a dictionary, the key-value pair itself is extracted.\njulia\u0026gt; d = Dict(2=\u0026gt;4, 3=\u0026gt;5, 4=\u0026gt;\u0026#34;6\u0026#34;)\rDict{Int64, Any} with 3 entries:\r4 =\u0026gt; \u0026#34;6\u0026#34;\r2 =\u0026gt; 4\r3 =\u0026gt; 5\rjulia\u0026gt; rand(d)\r4 =\u0026gt; \u0026#34;6\u0026#34;\rjulia\u0026gt; rand(d)\r2 =\u0026gt; 4 String If the sampling set is a string, a random character from the string is extracted.\njulia\u0026gt; str = \u0026#34;freshrimpsushi\u0026#34;\r\u0026#34;freshrimpsushi\u0026#34;\rjulia\u0026gt; rand(str)\r\u0026#39;e\u0026#39;: ASCII/Unicode U+0065 (category Ll: Letter, lowercase)\rjulia\u0026gt; rand(str)\r\u0026#39;h\u0026#39;: ASCII/Unicode U+0068 (category Ll: Letter, lowercase) Type julia\u0026gt; rand(Int32, 3)\r3-element Vector{Int32}:\r1552806175\r-384901411\r-1580189675\rjulia\u0026gt; rand(UInt32, 3)\r3-element Vector{UInt32}:\r0xd2f44f99\r0x166a8b9e\r0x92fe22dc\rjulia\u0026gt; rand(Float32, 3)\r3-element Vector{Float32}:\r0.59852564\r0.6247238\r0.23303497\rjulia\u0026gt; rand(ComplexF32, 3)\r3-element Vector{ComplexF32}:\r0.10872495f0 + 0.6622572f0im\r0.6408408f0 + 0.46815878f0im\r0.7766515f0 + 0.73314756f0im Environment OS: Windows11 Version: Julia 1.9.0 https://docs.julialang.org/en/v1/stdlib/Random/#Base.rand\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3462,"permalink":"https://freshrimpsushi.github.io/en/posts/3462/","tags":null,"title":"Sampling Randomly in Julia"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definitions 1 2 Complex Definition A bar chart made from the frequency distribution of quantitative data is called a histogram.\nSimple Definition A histogram is a bar chart where numerical data is divided into intervals, and the frequency of data within those intervals is counted, with the sizes represented as the heights of the bars.\nExplanation Histograms are an indispensable visualization technique in scientific literature, especially used to represent probability distributions when data involves uncertainty. While bar charts are widely accessible to the general public, histograms often require at least a minimum of additional explanation, as introduced in the simple definition.\nIn the screenshot above, column A represents a histogram made from given quantitative data. Unlike typical bar charts that separate bars to distinctly categorize them, histograms usually minimize gaps between bars to function as visual representations of probability distributions.\nNote: Bin In histograms, the size of an interval is called a bin. Being quantitative data, it\u0026rsquo;s a concept similar to the size of a class interval, and how bins are determined can significantly affect the appearance of the histogram. If the number of class intervals is reduced from five to two with the same data, the result is as shown below.\nAlthough only 13 samples are involved, reducing the number of class intervals drastically simplifies the distribution too much, failing to represent the original probability distribution. Relying on intuition to quickly grasp probability distributions is important, but being overly confident can lead to falling into the trap of subjectivity.\nSee also How to draw a histogram in Excel How to view histograms more finely in R Mendenhall. (2012). Introduction to Probability and Statistics (13th Edition): p25, 165.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nÍ≤ΩÎ∂ÅÎåÄÌïôÍµê ÌÜµÍ≥ÑÌïôÍ≥º. (2008). ÏóëÏÖÄÏùÑ Ïù¥Ïö©Ìïú ÌÜµÍ≥ÑÌïô: p29.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2432,"permalink":"https://freshrimpsushi.github.io/en/posts/2432/","tags":null,"title":"Histograms of Quantitative Data"},{"categories":"ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç","contents":"Overview1 140+ CSS color palettes with names.\nCode ","id":3459,"permalink":"https://freshrimpsushi.github.io/en/posts/3459/","tags":null,"title":"CSS color name tags"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definition 1 The frequency at which each observation of qualitative data appears is referred to as Frequency. Dividing the frequency by the total number of data and multiplying the relative frequency by 100 is called Relative Frequency and Percentage, respectively. How each frequency or relative frequency is distributed across several categories is known as Frequency Distribution. Explanation Frequency, often translated as frequency in the context of physics, in the context of statistics, means literally how often a particular data is found. However, the word \u0026ldquo;frequency\u0026rdquo; can cause confusion if not used academically, so it\u0026rsquo;s understood to be simply referred to as Frequency without the Hanja for frequency (È†ª).\nThough it\u0026rsquo;s written in somewhat complicated language, in fact, it just means \u0026ldquo;how many times\u0026rdquo;. For a very simple example, if a coin is flipped 50 times resulting in 40 heads and 10 tails, then their respective Frequencies are 40 and 10, and their Relative Frequencies are 0.8 and 0.2. Thinking conventionally, it would seem suspicious that the coin landed heads up so many times in this example. Our natural curiosity would lead us to question whether the coin is Fair, and understanding the Frequency Distribution allows us to proceed with statistical inference.\nSee Also Frequency of qualitative data Class of quantitative data Í≤ΩÎ∂ÅÎåÄÌïôÍµê ÌÜµÍ≥ÑÌïôÍ≥º. (2008). ÏóëÏÖÄÏùÑ Ïù¥Ïö©Ìïú ÌÜµÍ≥ÑÌïô: p16.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2426,"permalink":"https://freshrimpsushi.github.io/en/posts/2426/","tags":null,"title":"Qualitative Data Frequency"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definition 1 Statistics is a collection of methods for collecting, analyzing, representing, interpreting, and making decisions about data.\nDescriptive statistics consist of methods that use charts or graphs and summary measures to organize, present, and describe data. Inferential statistics consist of methods for making decisions or predictions about a population from a sample. Commentary Below is a story beyond the textbook.\nI personally would like to define statistics as \u0026ldquo;a field of applied mathematics that actively uses the theory of probability.\u0026rdquo;\nAlthough this may seem like only a characteristic of statistics rather than a definition, the theory supporting statistical learning‚Äîespecially inferential statistics‚Äîis indeed mathematical statistics, and the discussions relevant to what can be called statistical inference are largely based on probabilistic arguments. While not directly related to statistics, the physical theory that introduces probability theory to study the micro-world is also called statistical mechanics. Moreover, since the 2010s, machine learning, especially deep learning, has developed significantly, with technological levels for unstructured data rapidly increasing. They are producing very good results in areas that classic statistics has struggled with, such as natural language processing, computer vision, and reinforcement learning. Unfortunately, it\u0026rsquo;s almost difficult to view such fields as part of statistics. For these reasons, the definition of statistics mentioned in the definition might more accurately be called the definition of Data Science. Classical machine learning, even before the deep learning trend, was part of statistics as a nonparametric method, but looking back, it\u0026rsquo;s time to acknowledge that statistics is not the only data science and firmly establish its identity.\nHowever, there\u0026rsquo;s no need to be sad. Innately, statistics has a solid theoretical foundation, unlike approaches like deep learning, and there is growing disenchantment and exhaustion with performance-focused black-box techniques. Although it may seem somewhat diminished compared to its heyday as the entirety of data science, statistics still remains the largest field within applied mathematics.\nDepartment of Statistics, Kyungpook National University. (2008). Statistics with Excel: p2~3.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2424,"permalink":"https://freshrimpsushi.github.io/en/posts/2424/","tags":null,"title":"Definition of Statistics"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definition 1 Qualitative Variables Variables that measure qualitative characteristics are called qualitative variables.\nThe food is\u0026hellip; delicious / so-so / tasteless The color is\u0026hellip; red / blue / yellow The major is\u0026hellip; mathematics / statistics / physics Such qualitative variables are often referred to as categorical data.\nQuantitative Variables Variables that measure quantitative characteristics are called quantitative variables.\nAge is\u0026hellip; 20 years old / 31 years old / 11 years old Height is\u0026hellip; 170.0 cm / 170.5 cm / 162.1 cm Quantitative variables that take specific values, like age or vision, are called discrete variables, while those that take continuous values, like height or weight, are called continuous variables.\nExplanation The definitions may seem odd, but \u0026lsquo;qualitative\u0026rsquo; and \u0026lsquo;quantitative\u0026rsquo; are not terms we\u0026rsquo;re born knowing; we learn their academic meanings and apply them to everyday language. For instance, when assessing the quality of an item, we might say it has \u0026lsquo;high quality\u0026rsquo; without quantifying it with a specific number like \u0026lsquo;1432 units of good\u0026rsquo; or \u0026lsquo;17% better\u0026rsquo;.\nQualitative refers to characteristics that might have an order (good-bad-terrible) but are usually not numerically expressed. It\u0026rsquo;s fine if they\u0026rsquo;re categorized without order (German-French-Japanese). Quantitative refers to measurable amounts. The distinction between discrete and continuous variables here can be a bit tricky. Discrete Values? The term discrete values describes values that are distinct and separated, like natural numbers or marked scales. It\u0026rsquo;s an expression not commonly found in textbooks, and even I acknowledge it\u0026rsquo;s not ideal. A more fitting description might be:\nVariables that take countable values are called discrete variables. They are assumed to take only finite or countable values.\nHowever, such a mathematically precise description might not be immediately helpful in understanding what discrete variables are.\nCountable in this context means something can be counted in a way familiar to Indo-European languages, like English, French, or Spanish, where we can say \u0026lsquo;one, two, \u0026hellip;\u0026rsquo; and count \u0026lsquo;how many\u0026rsquo;. In English, nouns that can be counted this way are called countable nouns. Mathematically, it means there\u0026rsquo;s a one-to-one correspondence with the set of natural numbers.\nExamples might help clarify. These are typically discrete variables:\nThe number of pigs on a farm The number of traffic accident fatalities per year The number of pages in a textbook The age of infants\u0026hellip; \u0026lsquo;24-month-old boy\u0026rsquo;, \u0026lsquo;1 year 2 months girl\u0026rsquo;, etc. The number of 1L water bottles Some examples might be ambiguous:\nThe amount of water in 3 1L bottles\u0026hellip; If we\u0026rsquo;re talking about the amount of water, it\u0026rsquo;s continuous. Vision\u0026hellip; Commonly measured in increments of 0.1, but if only divided into groups like 0.5, 1.0, 1.5, it could be considered discrete, and depending on the data, even qualitative. Classification and Regression Problems In data science, problems are often classified as classification or regression problems based on whether the dependent variable is qualitative or quantitative.\nPrecautions Beginners working with data can make mistakes not because they don\u0026rsquo;t understand qualitative and quantitative variables, but because they\u0026rsquo;re not yet familiar with them. These are common mistakes, often encountered when studying complex topics like regression analysis, and there\u0026rsquo;s almost no opportunity to artificially develop intuition for these pitfalls. The following post might not explain everything but can give an idea of what to watch out for:\nRegression Analysis Involving Qualitative Variables Encoding It\u0026rsquo;s common to see encoding like men as $0$ and women as $1$, but just because there are numbers, it doesn\u0026rsquo;t make it a quantitative (discrete) variable.\nSuch encoding can also be used for privacy. Imagine medical data, which can be highly personal and specific enough to identify individuals just by the data. In such cases, data might be published with sensitive information simply represented by numbers, like psychiatric history or abortion status for women.\nRatings Similarly to encoding, ratings might seem quantitative but are still qualitative. For example, if high school graduates are rated as $0$, bachelor\u0026rsquo;s degree holders as $1$, and PhDs as $2$, it might seem quantitative but is qualitative. Terms like \u0026rsquo;low-educated\u0026rsquo; or \u0026lsquo;high-educated\u0026rsquo; are societal constructs and don\u0026rsquo;t necessarily imply a numerical order in the data.\nHex Codes Distinguishing between red and blue is qualitative, but what about different shades like pink, fuchsia, or crimson? If it\u0026rsquo;s about lipstick, it might still be qualitative, but for fabric colors with thousands of shades, they might be represented by RGB hex codes. While it\u0026rsquo;s rare to encounter such data, it\u0026rsquo;s important to remember that what intuitively seems qualitative can be expressed quantitatively.\nGender Data might categorize gender, and whether or not one agrees with the political correctness behind it, if the data presents it that way, it must be accepted as is.\nTrue story. For instance, there have been cases where gender was encoded with numbers, and someone unfamiliar with gender issues was confused by values like 2 or 3 in a dataset. The point is not to become an expert on gender issues but to avoid relying solely on intuition when analyzing data from unfamiliar domains.\nWhy Do We Need to Know This? These concepts are straightforward, yet critical to understand and differentiate accurately. We here includes researchers applying statistics, statistics majors, and anyone potentially working in data science, even with a different background.\nWhile we study and gain experience, our peers may be engaging in society in other ways. Unfortunately, they might not be as data-savvy, possibly ignoring the precautions mentioned here and making these common mistakes. Consider the general public, who might not question such errors, and even your boss might not be an exception.\nIt\u0026rsquo;s our responsibility to prevent these misunderstandings.\nMendenhall. (2012). Introduction to Probability and Statistics (13th Edition): p10.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2420,"permalink":"https://freshrimpsushi.github.io/en/posts/2420/","tags":null,"title":"Qualitative Variable and Quantitative Variable"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition The set of real invertible $n \\times n$ matrices is denoted by $\\mathrm{GL}(n, \\mathbb{R})$ or $\\mathrm{GL}_{n}(\\mathbb{R})$ and is called the general linear group of degree $n$general linear group of degree $n$.\n$$ \\mathrm{GL}(n, \\mathbb{R}) := \\left\\{ n \\times n \\text{ invertible matrix} \\right\\} = M_{n \\times n}(\\mathbb{R}) \\setminus {\\left\\{ A \\in M_{n \\times n}(\\mathbb{R}) : \\det{A} = 0 \\right\\}} $$\nExplanation Since it consists only of invertible matrices, it forms a group with respect to matrix multiplication. Moreover, it has a differentiable structure, making it a Lie group.\n","id":3450,"permalink":"https://freshrimpsushi.github.io/en/posts/3450/","tags":null,"title":"General Linear Group"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Theorem 1 2 Definitions of Covering and Lifting: Let\u0026rsquo;s denote the unit interval as $I = [0,1]$.\nAn open set $U \\subset X$ of $X$ is evenly covered by $p$ if for every $\\alpha \\in \\forall$, all corresponding restricted functions $p |_{\\widetilde{U}_{\\alpha}}$ are homeomorphisms, and $$ \\alpha_{1} \\ne \\alpha_{2} \\implies \\widetilde{U}_{\\alpha_{1}} \\cap \\widetilde{U}_{\\alpha_{2}} = \\emptyset $$ holds, meaning there exist disjoint open sets $\\widetilde{U}_{\\alpha} \\subset \\widetilde{X}$ in $\\widetilde{X}$ such that $$ p^{-1} \\left( U \\right) = \\bigsqcup_{\\alpha \\in \\forall} \\widetilde{U}_{\\alpha} $$ is satisfied. If $p : \\widetilde{X} \\to X$ is a surjective function and for every $x \\in X$, there exists an open neighborhood $U_{x} \\subset X$ of $x$ that is evenly covered by $p$, then $p : \\widetilde{X} \\to X$ is called a covering. The domain $\\widetilde{X}$ of the covering $p$ is called the covering space, and the codomain $X$ is called the base space. Let $n \\in \\mathbb{N}$. If $f : I^{n} \\to X$ and $\\widetilde{f} : I^{n} \\to \\widetilde{X}$ satisfy the following, $\\widetilde{f}$ is called a lift of $f$. $$ f = p \\circ \\widetilde{f} $$ Let\u0026rsquo;s denote a covering with sphere $S^{1}$ as its codomain by $p : \\mathbb{R} \\to S^{1}$.\nPath Lifting Theorem A continuous function $f : I \\to S^{1}$ has a lift $\\widetilde{f} : I \\to \\mathbb{R}$. Specifically, for given $x_{0} \\in S^{1}$ and $\\widetilde{x}_{0} \\in p^{-1} \\left( x_{0} \\right)$, there exists a unique $\\widetilde{f}$ satisfying $\\widetilde{f} \\left( 0 \\right) = \\widetilde{x}_{0}$.\nHomotopy Lifting Theorem A continuous function $F : I^{2} \\to S^{1}$ has a lift $\\widetilde{F} : I^{2} \\to \\mathbb{R}$. Specifically, for given $x_{0} \\in S^{1}$ and $\\widetilde{x}_{0} \\in p^{-1} \\left( x_{0} \\right)$, there exists a unique $\\widetilde{F}$ satisfying $\\widetilde{F} \\left( 0 , 0 \\right) = \\widetilde{x}_{0}$.\nExplanation Lifting Theorems are often mentioned as auxiliary theorems for studying the properties of the unit circle $S^{1}$. Formally, the distinction between path lifting and homotopy lifting is not significant.\nThe question most mathematicians should be curious about is whether a generalization for $f: I^{m} \\to X$, when $X \\ne S^{1}$, is possible. It\u0026rsquo;s a fact that lifting theorems can be discussed even for continuous functions $f: Y \\times I^{m} \\to X$ over compact spaces $Y$. However, such extensions are said to be overly complicated and practically useless for direct study.\nProof Strategy: We\u0026rsquo;ll only prove the path lifting theorem. Essentially, the proof of the homotopy lifting theorem is similar to that of the path lifting theorem. Like how the path lifting theorem is proved by subdividing the compact space $I$ into finite intervals, the homotopy lifting theorem involves subdividing the compact space $I^{2}$ into finite parts and repeating the same discussion.\nPart 1. Setting\nIf $p : \\widetilde{X} \\to X$ is a surjective function and for every $x \\in X$, there exists an open neighborhood $U_{x} \\subset X$ of $x$ that is evenly covered by $p$, then $p : \\widetilde{X} \\to X$ is called a covering. Since $p : \\mathbb{R} \\to S^{1}$ is a covering, for every $x \\in S^{1}$, there exists a neighborhood $U_{x} \\subset S^{1}$ of $x$ that is evenly covered by $p$.\nSince $I = [0,1]$ is compact, there exists a finite set of points $\\left\\{ a_{k} \\right\\}_{k=0}^{n} \\subset I$ satisfying $$ 0 = a_{0} \u0026lt; a_{1} \u0026lt; \\cdots \u0026lt; a_{n-1} \u0026lt; a_{n} = 1 $$ and whose intervals $\\left[ a_{k-1} , a_{k} \\right] \\subset I$ have images in $S^{1}$, especially satisfying the inclusion relation for some open set $U \\subset S^{1}$ as follows: $$ f \\left( \\left[ a_{k-1} , a_{k} \\right] \\right) \\subset U \\subset S^{1} $$ If we denote the disjoint preimages of $U$ under covering $p$ by $\\widetilde{U}_{t} := p^{-1} \\left( U_{t} \\right)$, each of them is homeomorphic to $U$ for every $t \\in \\mathbb{Z}$.\nPart 2. Inductive Construction\nLet\u0026rsquo;s specifically fix $x_{0} \\in S^{1}$ instead of any $x \\in S^{1}$, and denote one of the preimages under $p$ as $\\widetilde{x}_{0} := p^{-1} \\left( x_{0} \\right) \\in \\mathbb{R}$. According to the initial setting, there exists a bijection between these elements and $\\mathbb{Z}$, and it doesn\u0026rsquo;t matter which one is chosen.\nWe aim to define the lifting $\\widetilde{f}_{k}$ inductively for $\\left[ 0, a_{k} \\right]$, satisfying $\\widetilde{f}_{k} (0) = \\widetilde{x}_{0}$, instead of the entire $I$ at once, to eventually find $\\widetilde{f}$.\nFor $k = 0$, we simply set it as $\\widetilde{f}_{0} (0) = \\widetilde{x}_{0}$, with no other choice. Assume a unique continuous function $\\widetilde{f}_{k} : \\left[ 0 , a_{k} \\right] \\to \\mathbb{R}$ is defined for $k \\ne 0$. For some unique $\\widetilde{U} \\in \\left\\{ \\widetilde{U}_{t} \\right\\}_{t \\in \\mathbb{Z}}$, $\\widetilde{f} \\left( a_{k} \\right) \\in \\widetilde{U}$ holds. Since $\\widetilde{f}_{k}$ is continuous and interval $\\left[ a_{k} , a_{k+1} \\right]$ is path-connected, the extension function $\\widetilde{f}_{k+1}$, however defined, must map $\\left[ a_{k} , a_{k+1} \\right]$ strictly inside $\\widetilde{U}$. Since $p$ is a covering, a homeomorphism $p | \\widetilde{U}_{t} : \\widetilde{U}_{t} \\to U$ exists for all $t \\in \\mathbb{Z}$, leading to a unique function $\\rho_{k} : \\left[ a_{k} , a_{k+1} \\right] \\to \\widetilde{U}$ satisfying $$ p \\circ \\rho_{k} = f | \\left[ a_{k} , a_{k+1} \\right] $$ The existence of such function $\\rho_{k}$ is based on the existence of a homeomorphism as a restriction of $p$‚Äîin other words, due to its injectivity, ensuring $\\rho_{k} \\left( a_{k} \\right) = \\widetilde{f}_{k} \\left( a_{k} \\right)$ and the continuity of $\\rho_{k}$. Gluing Lemma: For a topological space $X,Y$ and two closed sets $A,B \\subset X$ satisfying $A \\cup B = X$, and two continuous functions $f : A \\to Y$ and $g : B \\to Y$ agree on all $x \\in A \\cap B$ as $f(x) = g(x)$, then the function $h$ defined as follows is continuous. $$ h(x) : = \\begin{cases} f(x), \u0026amp; x \\in A \\\\ g(x), \u0026amp; x \\in B \\end{cases} $$\nBy the Gluing Lemma, a unique continuous function $\\widetilde{f}_{k+1} : \\left[ 0 , a_{k+1} \\right] \\to \\mathbb{R}$ can be defined as follows: $$ \\widetilde{f}_{k+1} := \\begin{cases} \\widetilde{f}_{k} (s) \u0026amp; , \\text{if } s \\in \\left[ 0, a_{k} \\right] \\\\ \\rho_{k} (s) \u0026amp; , \\text{if } s \\in \\left[ a_{k} , a_{k+1} \\right] \\end{cases} $$ According to mathematical induction, there specifically exists a lifting to the spiral winding around $S^{1}$ as many times as the wheel of $t \\in \\mathbb{Z}$. Here, $k = 0, 1, \\cdots , n$ is not an index moving up and down in $\\mathbb{R}$ but an index that slices $S^{1}$ into finite parts while rotating.\nPart 3. Homotopy Lifting Theorem\nLet\u0026rsquo;s denote the set of integers from $0$ to $n-1$ simply as $0:n$. Just as we could choose $0 = a_{0} \u0026lt; \\cdots \u0026lt; a_{n} = 1$ based on the compactness of $I$, $I^{2}$ is also compact, allowing for the existence of finite natural numbers $n , m \\in \\mathbb{N}$ that subdivide the square into a grid. $$ \\begin{align*} 0 = a_{0} \u0026lt; \\cdots \u0026lt; a_{n} = 1 \\\\ 0 = b_{0} \u0026lt; \\cdots \u0026lt; b_{m} = 1 \\end{align*} $$ Defining each small square for $i = 0:n$ and $j = 0:m$ as $$ R_{i,j} := \\left[ a_{i-1}, a_{i} \\right] \\times \\left[ b_{j-1} , b_{j} \\right] \\subset I^{2} $$ yields a sequence of small rectangles as follows: $$ R_{0,0} , R_{0,1} , \\cdots , R_{0,m} , R_{1,0} \\cdots, R_{n,m} $$ Repeating the discussion from the path lifting theorem proves the homotopy lifting theorem.\n‚ñ†\nKosniowski. (1980). A First Course in Algebraic Topology: p137~138.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHatcher. (2002). Algebraic Topology: p29~31.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2419,"permalink":"https://freshrimpsushi.github.io/en/posts/2419/","tags":null,"title":"Proof of the Lifting Theorem in Algebraic Topology"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Overview In modern society, there is no intellectual who knows absolutely nothing about data. Even non-specialists with no interest can easily think of synonyms such as \u0026lsquo;knowledge about something\u0026rsquo; or \u0026lsquo;resources for communication\u0026rsquo; like data or information, to the extent that the concept of data has become universal and popularized. The following descriptions are merely attempts to define data a little more strictly from the perspective of data science.\nDefinition 1 A variable refers to a characteristic that changes according to perspective on time, individual, or object. The individual or object whose variable is measured is called an experimental unit, and the actual measurement taken from an experimental unit is called a measurement. The set of measurements is called data. Explanation Etymology of Data 2 The English word data means \u0026lsquo;facts that are given or acknowledged\u0026rsquo;, derived from the Latin verb \u0026ldquo;Do-\u0026rdquo; meaning \u0026rsquo;to give\u0026rsquo;, specifically from its past participle Datum meaning \u0026lsquo;given\u0026rsquo;. Data is the plural form of Datum.\nIronically, the origin of the word data points more accurately to the essence of data than any attempt to define it through characteristics or experiments as mentioned above. In the realm of data science, data is something that has been given or will be given to us, fundamentally different in quality from objects of new discoveries or creations.\nIn other words, data is inevitably, that is to say, given. To use a crude analogy, imagine inventing a durable light bulb. If you developed light bulb B from light bulb A with an average lifespan of 100 hours, you could measure the lifespan of each light bulb B (Object) by keeping the bulbs on until they burn out. This collection of measurements is the lifespan data of light bulb B, and those values are given solely based on light bulb B, not somehow derived from changing the data of light bulb A itself.\nVariables and Experiments? The term variable, meaning a changing number in Chinese characters, easily brings to mind numbers, and though numbers often appear in simplified explanations of data, the contemporary societal understanding of unstructured data doesn‚Äôt limit data to just numbers or categories. Data types include photos, documents, signals, stock prices, videos, network structures, and everything humans can perceive. Similarly, measurement, despite looking like a number because of the characters used, doesn\u0026rsquo;t necessarily need to be considered as a numeric value. It\u0026rsquo;s recommended to use the English term Measurement when possible.\nMoreover, experiment in \u0026ldquo;experimental unit\u0026rdquo; does not exclusively refer to activities conducted by scientists in lab coats. Just as an event occurring is called a \u0026lsquo;random experiment\u0026rsquo; in basic probability theory, it\u0026rsquo;s sufficient to understand it simply as a term for expression.\nPopulation and Sample The set of all measurements an investigator is interested in is called a population. A subset of the population is called a sample. \u0026hellip;From such definitions, it can be inferred that a lot of data realistically is a sample of a population. Meanwhile, the English expression of population, closely related to statistics, also means population in the sense of demographics, so be mindful of this.\nThe concept of statistics is fundamentally \u0026ldquo;wanting to know about a population but being unable to investigate the entire population, so characterizing the population through a sample\u0026rdquo;, that is, inferring the essence of the subject of interest through data.\nSee Also Definition of a Sample in Mathematical Statistics In mathematical statistics that undergraduate students encounter in their 2nd or 3rd year, a mathematical definition is given for the sample described in this post, and another expression for data, called a realization, is introduced.\nMendenhall. (2012). Introduction to Probability and Statistics (13th Edition): p8.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.etymonline.com/word/data\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2418,"permalink":"https://freshrimpsushi.github.io/en/posts/2418/","tags":null,"title":"Definition and Etymology of Data"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Definitions 1 2 Let $p : \\widetilde{X} \\to X$ be a continuous function between two topological spaces $\\widetilde{X}, X$. Denote any index set as $\\forall$, and let\u0026rsquo;s write the restriction function from $\\widetilde{U}_{\\alpha} \\subset \\widetilde{X}$ to $p$ simply as $p |_{\\widetilde{U}_{\\alpha}} : \\widetilde{U}_{\\alpha} \\to U$.\n$I = [0,1]$ is the unit interval from $0$ to $1$. $\\bigsqcup$ represents the union of disjoint sets. Covering An open set $U \\subset X$ of $X$ is evenly covered by $p$ if, for all $\\alpha \\in \\forall$ corresponding, all restriction functions $p |_{\\widetilde{U}_{\\alpha}}$ are homeomorphisms, and $$ \\alpha_{1} \\ne \\alpha_{2} \\implies \\widetilde{U}_{\\alpha_{1}} \\cap \\widetilde{U}_{\\alpha_{2}} = \\emptyset $$ is satisfied, that is, if $$ p^{-1} \\left( U \\right) = \\bigsqcup_{\\alpha \\in \\forall} \\widetilde{U}_{\\alpha} $$ applies for the disjoint open set $\\widetilde{U}_{\\alpha} \\subset \\widetilde{X}$ of $\\widetilde{X}$. If $p : \\widetilde{X} \\to X$ is a surjective function, and there exists an open neighborhood $U_{x} \\subset X$ of $x$ that is evenly covered by $p$ for all $x \\in X$, then $p : \\widetilde{X} \\to X$ is called a covering. The domain $\\widetilde{X}$ of covering $p$ is called covering space, and the codomain $X$ is called base space. Lift Let\u0026rsquo;s denote by $n \\in \\mathbb{N}$. If $f : I^{n} \\to X$ and $\\widetilde{f} : I^{n} \\to \\widetilde{X}$ satisfy the following, $\\widetilde{f}$ is called the lift of $f$. $$ f = p \\circ \\widetilde{f} $$ Examples Mathematical definitions are too complicated, let\u0026rsquo;s consider a simple example with $X = S^{1}$ and $\\widetilde{X} = \\mathbb{R}$. Frankly, the notions of covering and lift in the definitions generalize this example.\nIntuitive Lift Although written as $\\widetilde{X} = \\mathbb{R}$, this is depicted as a spiral embedded in $\\mathbb{R}^{3}$, which is analogous to representing the spiral $h : \\mathbb{R} \\to \\mathbb{R}^{3}$ as $$ s \\mapsto \\left( \\cos 2 \\pi s, \\sin 2 \\pi s , s \\right) $$ Defining a path from $I = [0,1]$ to $\\mathbb{R}$ as $$ \\widetilde{\\omega}_{n} (s) := ns $$ results in starting at $0$ and ending at $n$, winding around the spiral for $n \\in \\mathbb{Z}$ turns. Meanwhile, a sphere $S^{1}$ can be represented as a unit circle in $$ \\omega_{n} (s) := \\left( \\cos 2 \\pi n s , \\sin 2 \\pi n s \\right) $$ -dimensional space, naturally making the projection $p : (x,y,z) \\mapsto (x,y)$ a covering. Intuitively, $p$ appears as a projection that sends the unwound spiral onto a plane, whereas $\\widetilde{\\omega}_{n}$ lifts the repeatedly overlapped $\\omega_{n}$ into three-dimensional space, making it aptly called a lift. Expressed in formula, it becomes $$ \\omega_{n} = p \\circ \\widetilde{\\omega}_{n} $$ Now looking back at the definition, so far we have one intuitive example of $I^{1}$, and there is no reason not to call them covering or lift if all listed conditions are met. In the context of algebraic topology, an immediate possibility to consider is the lift of $I^{2}$, i.e., the lift in homotopy $H : I^{2} \\to X$.\nEvenly Cover is Too Hard The evenly cover written in the definitions might seem incredibly hard, but intuitively, it\u0026rsquo;s actually a simple concept.\nThe pre-image of $U \\subset S^{1}$ is represented as the union of disjoint sets on the spiral, each being homeomorphic with little pieces $U$. However, in this example, indices are conveniently assigned to correspond to integers $k$, and the form is simple, but realistically, how peculiar the index set $\\forall$ could be is unpredictable. Therefore, despite most mathematicians preferring easy and straightforward definitions, there\u0026rsquo;s no compromise on the description of evenly cover.\nKosniowski. (1980). A First Course in Algebraic Topology: p135. 144.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHatcher. (2002). Algebraic Topology: p29.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2417,"permalink":"https://freshrimpsushi.github.io/en/posts/2417/","tags":null,"title":"Covering and Lifting in Algebraic Topology"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Originally, Julia formats the data output to fit the size of the REPL beautifully, but sometimes we want to see the entire data comfortably. If the data is foo, you can print the entire data using show(stdout, \u0026quot;text/plain\u0026quot;, foo)1.\nCode julia\u0026gt; foo = rand(100,2)\r100√ó2 Matrix{Float64}:\r0.956438 0.663427\r0.790117 0.472821\r0.976134 0.198475\r0.727601 0.472336\r0.0469046 0.991999\r0.625807 0.26634\r0.490773 0.588481\r0.352966 0.426474\r0.585632 0.00185974\r‚ãÆ\r0.615713 0.707071\r0.891683 0.622176\r0.370576 0.937107\r0.430644 0.0439135\r0.535987 0.551992\r0.43273 0.217023\r0.345366 0.500033\r0.551719 0.0761454 Originally, ‚ãÆ is printed like above, but if it is printed in plain text, the entire data prints out as follows.\njulia\u0026gt; show(stdout, \u0026#34;text/plain\u0026#34;, foo)\r100√ó2 Matrix{Float64}:\r0.956438 0.663427\r0.790117 0.472821\r0.976134 0.198475\r0.727601 0.472336\r0.0469046 0.991999\r0.625807 0.26634\r0.490773 0.588481\r0.352966 0.426474\r0.585632 0.00185974\r0.13357 0.90977\r0.789999 0.137833\r0.11626 0.385958\r0.629265 0.40623\r0.111327 0.483414\r0.22717 0.0960839\r0.854027 0.690618\r0.00862816 0.426555\r0.292845 0.588308\r0.475157 0.935968\r0.936422 0.116917\r0.421748 0.335614\r0.354324 0.444122\r0.52423 0.311464\r0.306786 0.873037\r0.308008 0.70787\r0.0885757 0.558464\r0.0510476 0.840701\r0.320569 0.28571\r0.89837 0.517027\r0.218359 0.622536\r0.563148 0.488849\r0.508919 0.818068\r0.880726 0.550501\r0.555517 0.953056\r0.466298 0.29687\r0.816757 0.528656\r0.789289 0.294199\r0.51256 0.173814\r0.972556 0.11602\r0.438784 0.815105\r0.218237 0.257226\r0.0838205 0.535666\r0.287095 0.877342\r0.176927 0.942882\r0.855193 0.577759\r0.813356 0.488643\r0.407358 0.970933\r0.224252 0.455783\r0.430215 0.727\r0.0585314 0.727251\r0.77538 0.777196\r0.114963 0.610359\r0.445436 0.472755\r0.0565616 0.153393\r0.695217 0.00669471\r0.673818 0.284351\r0.308611 0.386984\r0.761394 0.32279\r0.017963 0.114759\r0.465956 0.788791\r0.970691 0.264864\r0.0953205 0.359958\r0.437556 0.283858\r0.323666 0.893141\r0.971015 0.109052\r0.117792 0.919322\r0.898883 0.947123\r0.248386 0.462831\r0.895525 0.434108\r0.526593 0.288652\r0.891208 0.848443\r0.344758 0.412774\r0.697527 0.592066\r0.531953 0.50251\r0.0565245 0.449993\r0.168528 0.783811\r0.129681 0.22014\r0.489568 0.232417\r0.875734 0.380527\r0.0207026 0.915546\r0.210948 0.476037\r0.822661 0.517793\r0.579839 0.0221691\r0.455027 0.920253\r0.932968 0.771582\r0.960643 0.841065\r0.0835567 0.943408\r0.578494 0.502968\r0.0655954 0.528926\r0.590831 0.41364\r0.840604 0.790515\r0.327964 0.269113\r0.615713 0.707071\r0.891683 0.622176\r0.370576 0.937107\r0.430644 0.0439135\r0.535987 0.551992\r0.43273 0.217023\r0.345366 0.500033\r0.551719 0.0761454 Environment OS: Windows julia: v1.7.0 https://stackoverflow.com/questions/49304329/how-to-show-all-elements-of-vectors-and-matrices-in-julia/67090474#67090474\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2416,"permalink":"https://freshrimpsushi.github.io/en/posts/2416/","tags":null,"title":"How to Print Without Omitting Data in Julia"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Definition 1 Given a topological space $X$ and a unit interval $I = [0,1]$,\nFor paths $f, g : I \\to X$ in $X$, when $f (1) = g(0)$, the product or composition $f \\cdot g$ of two paths is defined as: $$ f \\cdot g (s) := \\begin{cases} f \\left( 2s \\right) \u0026amp; , \\text{if } s \\in [0, 1/2] \\\\ g \\left( 2s - 1 \\right) \u0026amp; , \\text{if } s \\in [1/2, 1] \\end{cases} $$ For a path $f : I \\to X$, a path defined as $\\overline{f} : I \\to X$ when $\\overline{f} (s) := f (1-s)$ is called the inverse path of $f$. For all $s_{1} , s_{2} \\in I$, a path $c_{x_{0}}$ such that $c_{x_{0}} \\left( s_{1} \\right) = c_{x_{0}} \\left( s_{2} \\right) = x_{0}$, i.e., a constant function, is called a constant path. When $f (0) = f(1) = x_{0} \\in X$, i.e., the initial point and the terminal point of the path $f$ are the same, it is called a loop, and $x_{0} \\in X$ is called the basepoint. The set of all homotopy classes of loops $f$ based at $x_{0} \\in X$ is denoted as $\\pi_{1} \\left( X , x_{0} \\right)$. When defining a binary operation $\\ast$ on homotopy classes of two loops $[f] , [g] \\in \\pi_{1} \\left( X , x_{0} \\right)$ as $$ [f] \\ast [g] := \\left[ f \\cdot g \\right] $$ then the group $\\pi_{1} \\left( \\left( X , x_{0} \\right) \\right)$ is called the fundamental group. Usually, $\\ast$ is not even mentioned and is simply written as $[f] [g] = [f \\cdot g]$. Explanation In mathematics, anything with \u0026ldquo;Fundamental\u0026rdquo; attached to it is of great importance. Initially, one may feel reluctant about how loops could lead to creating a group, but when considering their homotopy instead of just a set of loops, it becomes relatively easy to imagine its significance as it primarily concerns the properties of the topological space.\nProduct of Paths The product of paths $f \\cdot g$, as evident from the equation, follows path $f$ until $1/2 \\le s \\le 1$ and then follows path $g$ from then on. That such a product remains continuous is guaranteed by the pasting lemma.\nPasting Lemma: For a topological space $X,Y$, given two closed sets $A,B \\subset X$ satisfying $A \\cup B = X$, and two continuous functions $f : A \\to Y$ and $g : B \\to Y$ such that for all $x \\in A \\cap B$, $f(x) = g(x)$, then a function defined as $h$ is a continuous function. $$ h(x) : = \\begin{cases} f(x), \u0026amp; x \\in A \\\\ g(x), \u0026amp; x \\in B \\end{cases} $$\nAlthough the concept is not difficult, the terminology may feel awkward. Since paths are essentially functions, referring to their composition can be confusing due to potential confusion with composite functions, and the term product might also be confusing if there\u0026rsquo;s any operation in $X$ that could be considered multiplication. However, contrary to concerns, when studying, the operation $[f] [g] = [f \\cdot g]$ within the homotopy classes is mainly mentioned, and describing $f \\cdot g$ in words is rare.\nInverses and Identity Elements in Fundamental Groups An inverse path can be perceived as erasing the path taken in the product of paths. To intuitively understand this, consider $\\overline{f}$ as simply being path $f$ but in the opposite direction.\nThen, the product $f \\cdot \\overline{f}$ with $\\overline{f}$ for any given path $f$ results in a loop since its starting and ending points are the same. Important to note is that the endpoint of $f$ and the starting point of $\\overline{f}$, $x_{1}$, either precisely hits or simply remains static at $x_{0}$, which is a constant path $c_{x_{0}}$, or is homotopically equivalent. Since $\\pi_{1} \\left( X, x_{0} \\right)$ is a set of homotopy classes, for all $f$, $$ f \\cdot \\overline{f} \\simeq c_{x_{0}} $$ would hold true. Seeing this, regardless of what $f$ is, its homotopy class $[f]$, through operation with the homotopy class of $\\overline{f}$, $\\left[ \\overline{f} \\right]$, always results in $\\left[ c_{x_{0}} \\right]$, and $c_{x_{0}}$ is evidently the identity element of $\\pi_{1} \\left( X , x_{0} \\right)$ from its definition.\nSimply Connected Spaces From the discussions so far, one might wonder about the necessity of $x_{0}$ in fundamental groups.\nFor example, as shown in the picture above, it\u0026rsquo;s conceivable to think of a loop that \u0026rsquo;erases\u0026rsquo; the path before reaching a new point $x_{1} \\in X$, making it seem indifferent to the choice of any basepoint $x_{0}$.\nChange of Basepoint in Fundamental Groups: Given a topological space $X$, let $h : I \\to X$ be a path from $x_{0}$ to $x_{1}$. The function defined as $\\beta_{h} : \\pi_{1} \\left( X , x_{1} \\right) \\to \\pi_{0} \\left( X_{1} , x_{0} \\right)$ according to $\\beta_{h} [f] := \\left[ h \\cdot f \\cdot \\overline{h} \\right]$ is an isomorphism, known as the Change of Basepoint.\nAccording to the above theorem, if $X$ is path-connected, then $\\pi_{1} \\left( X , x \\right)$ is isomorphic regardless of the choice of basepoint $x$, hence, it is sometimes represented as $\\pi_{1} \\left( X \\right)$ or more concisely as just $\\pi_{1} X$.\nEspecially, if a space is path-connected and its fundamental group $\\pi_{1} X$ is a trivial group, i.e., isomorphic to a finite group with only the identity element $e$ such that $\\pi_{1} X \\simeq \\left\\{ e \\right\\}$, then $X$ is considered a simply-connected space.\nConversely, this implies that the properties of a fundamental group can significantly vary with the choice of basepoint $x_{0}$, and even if it is path-connected, it is necessary to examine separately the algebraic properties it might ha\nHatcher. (2002). Algebraic Topology: p26~28.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2415,"permalink":"https://freshrimpsushi.github.io/en/posts/2415/","tags":null,"title":"Fundamental Group in Algebraic Topology"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Overview1 $$ \\includegraphics[height=20em]{https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png} $$\nThe MNISTmodified national institute of standards and technology database refers to a dataset of digit handwriting from American high school students and Census Bureau employees. It is commonly known as [MNIST].\nOfficial Website Description This dataset is frequently used as an example for beginners in machine learning/deep learning. NIST originally collected handwritten data in the following format for the evaluation of character recognition technology for automated sorting of handwritten postal codes. Yann LeCun took this handwritten data from high school students and Census Bureau employees, processed it, and created the MNIST. The image size is 28 x 28, and it consists of 60,000 training sets and 10,000 test sets.\n$$ \\includegraphics[height=30em]{https://www.nist.gov/sites/default/files/styles/960_x_960_limit/public/images/2019/04/27/sd19.jpg?itok=oETq77cZ} $$\nHow to Use Julia In Julia, the MNIST dataset can be used with the machine learning dataset package MLDatasets.jl. By default, it loads the training set in Float32 type. There are options to change this. The available methods are as follows:\ndataset[i]: Returns a tuple of the i-th features and target. dataset[:]: Returns a tuple of all features and target. length(dataset): Returns the number of data. convert2image(dataset, i): Converts the i-th data into a grayscale image. The ImageShow.jl package is required. julia\u0026gt; using MLDatasets\rjulia\u0026gt; train = MNIST()\rdataset MNIST:\rmetadata =\u0026gt; Dict{String, Any} with 3 entries\rsplit =\u0026gt; :train\rfeatures =\u0026gt; 28√ó28√ó60000 Array{Float32, 3}\rtargets =\u0026gt; 60000-element Vector{Int64}\rjulia\u0026gt; test = MNIST(Float64, :test)\rdataset MNIST:\rmetadata =\u0026gt; Dict{String, Any} with 3 entries\rsplit =\u0026gt; :test\rfeatures =\u0026gt; 28√ó28√ó10000 Array{Float64, 3}\rtargets =\u0026gt; 10000-element Vector{Int64}\rjulia\u0026gt; length(train), length(test)\r(60000, 10000)\rjulia\u0026gt; using Plots\rjulia\u0026gt; using ImageShow\rjulia\u0026gt; train.targets[1]\r5\rjulia\u0026gt; heatmap(convert2image(train, 1)) Since the labels are given as integers, one-hot encoding needs to be done separately.\njulia\u0026gt; train.targets[1:5]\r5-element Vector{Int64}:\r5\r0\r4\r1\r9\rjulia\u0026gt; using Flux\rjulia\u0026gt; Flux.onehotbatch(train.targets[1:5], 0:9)\r10√ó5 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\r‚ãÖ 1 ‚ãÖ ‚ãÖ ‚ãÖ\r‚ãÖ ‚ãÖ ‚ãÖ 1 ‚ãÖ\r‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ\r‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ\r‚ãÖ ‚ãÖ 1 ‚ãÖ ‚ãÖ\r1 ‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ\r‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ\r‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ\r‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ\r‚ãÖ ‚ãÖ ‚ãÖ ‚ãÖ 1 How to do one-hot encoding in Julia Flux How to implement MLP and train MNIST in Julia Flux Environment OS: Windows11 Version: Julia v1.8.2, MLDatasets v0.7.6, Plots v1.36.1, ImageShow v0.3.6, Flux v0.13.7 Gun-Woo Kwon and Ryeong Heo, Learning AI through Night History and Comics 2, p68\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3444,"permalink":"https://freshrimpsushi.github.io/en/posts/3444/","tags":null,"title":"MNIST Database"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Theorem Brief Description In any topological space, the relation of a homotopy defined between any two fixed points is an equivalence relation.\nDetailed Description Given a topological space $X$ and two points $x_{0}, x_{1} \\in X$, if the paths $f, g : I \\to X$ between two points are homotopic, as expressed by $f \\simeq g$, then this binary relation $\\simeq$ is an equivalence relation. Moreover, the equivalence classes created by this equivalence relation $\\simeq$ $\\left\\{ g : f \\simeq g \\right\\}$ are represented as $[f]$.\nExplanation At first glance, this theorem may be misunderstood to mean that all paths in the space $X$ with given points $x_{0}, x_{1}$ are represented only by the two points. However, that is only the case when a homotopy for all paths exists, and as a simple example, considering a torus reveals that with a hole in the middle of the space, not all paths can have a homotopy.\nFortunately, it holds in a general Euclidean space $\\mathbb{R}^{p}$, and more generally, one can conjecture that it would hold in a convex vector space as well.\nProof 1 To show that $\\simeq$ is reflective, symmetric, and transitive, Reflexivity is trivial since there exists a constant homotopy $\\left\\{ h_{t} = f \\right\\}$ between $f \\simeq f$. Symmetry is also trivial since for $h_{t}$ existing between $f$ and $g$, $\\left\\{ h_{1-t} \\right\\}$ exists as a homotopy between $g$ and $f$. Transitivity is a bit more complex. When the binary continuous function corresponding to path $f : I \\to X$ is $$ F : I \\times I \\to X $$ and the binary continuous function corresponding to path $g : I \\to X$ is $$ G : I \\times I \\to X $$ if the binary continuous function corresponding to a mediating path $h$ is defined as $$ H (s,t) = \\begin{cases} F \\left( s, 2t \\right) \u0026amp; , \\text{if } t \\in [0,1/2] \\\\ G \\left( s, 2t - 1 \\right) \u0026amp; , \\text{if } t \\in [1/2,1] \\end{cases} $$ then one can directly verify that a homotopy that makes $f \\simeq g$ possible exists if $f \\simeq h$ and $h \\simeq g$, which visually appears as if the domains of the two functions defined from $I^{2}$ are halved and then connected.\nThe discussion on whether the mentioned $h_{t}$ are well-defined as functions and truly continuous is omitted here.\n‚ñ†\nHatcher. (2002). Algebraic Topology: p26.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2413,"permalink":"https://freshrimpsushi.github.io/en/posts/2413/","tags":null,"title":"Homotopy Classes"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Julia supports [linear algebra](../../categories/Linear Algebra) as well as MATLAB does, if not better. The intuitive and elegant syntax of Julia gives a feeling that it has been well-designed since its inception1.\nCode julia\u0026gt; A = [ 1 0 3\r0 5 1\r3 1 9\r] 3√ó3 Matrix{Int64}:\r1 0 3\r0 5 1\r3 1 9 As you can see, defining matrices is intuitive and easy from the get-go. Now let\u0026rsquo;s look at some common functions that should exist. Links to related posts are provided in the subsection titles, and no further explanation is given.\nTrace tr() julia\u0026gt; tr(A)\r15 Determinant det() julia\u0026gt; det(A)\r-1.000000000000003 Inverse inv() julia\u0026gt; inv(A)\r3√ó3 Matrix{Float64}:\r-44.0 -3.0 15.0\r-3.0 6.10623e-16 1.0\r15.0 1.0 -5.0\rjulia\u0026gt; round.(Int64, inv(A))\r3√ó3 Matrix{Int64}:\r-44 -3 15\r-3 0 1\r15 1 -5 Diagonal matrix and diagonal elements diag(), diagm() julia\u0026gt; diag(A)\r3-element Vector{Int64}:\r1\r5\r9\rjulia\u0026gt; diagm([1,5,9])\r3√ó3 Matrix{Int64}:\r1 0 0\r0 5 0\r0 0 9 Norm norm() julia\u0026gt; norm(A, 1)\r23.0 Eigenvalues eigvals() julia\u0026gt; eigvals(A)\r3-element Vector{Float64}:\r-0.020282065792505244\r4.846013411157458\r10.174268654635046\rjulia\u0026gt; eigvecs(A)\r3√ó3 Matrix{Float64}:\r-0.944804 0.117887 0.305692\r-0.0640048 -0.981459 0.180669\r0.321322 0.151132 0.934832\rjulia\u0026gt; eigmax(A)\r10.174268654635046 Matrix Decomposition factorize() julia\u0026gt; factorize(A)\rBunchKaufman{Float64, Matrix{Float64}}\rD factor:\r3√ó3 Tridiagonal{Float64, Vector{Float64}}:\r-0.0227273 0.0 ‚ãÖ 0.0 4.88889 0.0\r‚ãÖ 0.0 9.0\rU factor:\r3√ó3 UnitUpperTriangular{Float64, Matrix{Float64}}:\r1.0 -0.0681818 0.333333\r‚ãÖ 1.0 0.111111\r‚ãÖ ‚ãÖ 1.0\rpermutation:\r3-element Vector{Int64}:\r1\r2\r3\rjulia\u0026gt; svd(A)\rSVD{Float64, Float64, Matrix{Float64}}\rU factor:\r3√ó3 Matrix{Float64}:\r-0.305692 0.117887 -0.944804\r-0.180669 -0.981459 -0.0640048\r-0.934832 0.151132 0.321322\rsingular values:\r3-element Vector{Float64}:\r10.174268654635044\r4.846013411157461\r0.02028206579250516\rVt factor:\r3√ó3 Matrix{Float64}:\r-0.305692 -0.180669 -0.934832\r0.117887 -0.981459 0.151132\r0.944804 0.0640048 -0.321322 Refer to the [Matrix Algebra](../../categories/Matrix Algebra) category\u0026rsquo;s [Matrix Decomposition](../../categories/Matrix Algebra#Matrix-Decomposition-and-Least-Squares) section. Depending on the form of the matrix, it automatically chooses the appropriate decomposition. Of course, if desired and the conditions are met, one can directly use a specific decomposition function.\nMatrix Operations julia\u0026gt; B = [\r1 0 1\r1 1 0\r2 1 1\r]\r3√ó3 Matrix{Int64}:\r1 0 1\r1 1 0\r2 1 1\rjulia\u0026gt; A + B\r3√ó3 Matrix{Int64}:\r2 0 4\r1 6 1\r5 2 10\rjulia\u0026gt; A - B\r3√ó3 Matrix{Int64}:\r0 0 2\r-1 4 1\r1 0 8\rjulia\u0026gt; A * B\r3√ó3 Matrix{Int64}:\r7 3 4\r7 6 1\r22 10 12\rjulia\u0026gt; A .* B\r3√ó3 Matrix{Int64}:\r1 0 3\r0 5 0\r6 1 9\rjulia\u0026gt; B / A\r3√ó3 Matrix{Float64}:\r-29.0 -2.0 10.0\r-47.0 -3.0 16.0\r-76.0 -5.0 26.0\rjulia\u0026gt; B * inv(A)\r3√ó3 Matrix{Float64}:\r-29.0 -2.0 10.0\r-47.0 -3.0 16.0\r-76.0 -5.0 26.0\rjulia\u0026gt; A / B\rERROR: SingularException(3) All the operations we consider common sense apply. Division is naturally the same as multiplying by the inverse of multiplication, and if the inverse matrix doesn\u0026rsquo;t exist like B, it raises a singular exception.\nBlock Matrix [] Compared to other languages, creating block matrices is incredibly convenient.\njulia\u0026gt; [A B]\r3√ó6 Matrix{Int64}:\r1 0 3 1 0 1\r0 5 1 1 1 0\r3 1 9 2 1 1\rjulia\u0026gt; [A;B]\r6√ó3 Matrix{Int64}:\r1 0 3\r0 5 1\r3 1 9\r1 0 1\r1 1 0\r2 1 1\rjulia\u0026gt; [A,B]\r2-element Vector{Matrix{Int64}}:\r[1 0 3; 0 5 1; 3 1 9]\r[1 0 1; 1 1 0; 2 1 1] Placing a space between two matrices stacks them horizontally, while a semicolon stacks them vertically. The comma doesn\u0026rsquo;t stack matrices but arranges them as an array, following the same syntax used for arrays in general.\nFull Code Content related to complex matrices and inner products is omitted, but included in the full code.\nusing LinearAlgebra\rA = [\r1 0 3\r0 5 1\r3 1 9\r]\rtr(A)\rdet(A)\rinv(A)\rround.(Int64, inv(A))\rdiag(A)\rdiagm([1,5,9])\rnorm(A, 1)\reigvals(A)\reigvecs(A)\reigmax(A)\rfactorize(A)\rsvd(A)\rB = [\r1 0 1\r1 1 0\r2 1 1\r]\rdet(B)\rrank(B)\reigvals(B)\rSymmetric(B) # |\u0026gt; issymmetric\rtranspose(B)\rB\u0026#39;\rC = [\rim im 1\r2 im 0\rim 1 2\r]\rC\u0026#39;\rB\u0026#39;B\rx = [1,2,3]\ry = [0,1,2]\rx\u0026#39;y\rA + B\rA - B\rA * B\rA .* B\rB / A\rB * inv(A)\r[A B]\r[A;B]\r[A,B]\rx\u0026#39; * y\ry * x\u0026#39; Environment OS: Windows julia: v1.7.0 https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2412,"permalink":"https://freshrimpsushi.github.io/en/posts/2412/","tags":null,"title":"How to Use the Linear Algebra Package in Julia"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Definitions 1 Let\u0026rsquo;s assume that the closed unit interval $I := [0,1]$ and the topological space $X$ are given.\nA continuous function $p : I \\to X$ from $x_{0}$ to $x_{1}$ satisfying the following for fixed points $x_{0} , x_{1} \\in X$ is called a path or path. $$ \\begin{align*} p(0) =\u0026amp; x_{0} \\\\ p(1) =\u0026amp; x_{1} \\end{align*} $$ For two paths $f \\equiv h_{0}$ and $g \\equiv h_{1}$, the set $\\left\\{ h_{t} \\right\\}_{t \\in [0,1]}$ of paths $h_{t} : I \\to X$ satisfying the following two conditions is called a Homotopy: (i): Independent of $t$, and $h_{t} (1) = x_{1}$. (ii): For all $s,t \\in I$, $H : I \\times I \\to X$ defined as $H(s,t) := h_{t} (s)$ is continuous. Depending on the context, either $H$ or $h_{t}$ itself is called a homotopy. When there exists a homotopy between two paths $f$ and $g$, it is said that $f$ and $g$ are Homotopic, which is denoted as $f \\simeq g$. Description Homotopy, simply put, refers to the functions that continuously join two given points, and the reason for considering this concept is to treat them mathematically as identical if the ways to connect two points are essentially the same. For example, in the illustration above, there are countless ways to join the point on the left with the point on the right, but in the aspect of (known to the public) topology, what does it matter whether you go straight or slightly sideways? [ NOTE: Here, the expression \u0026lsquo;slightly\u0026rsquo; means the \u0026lsquo;continuity\u0026rsquo; mentioned in the definition of $H$. ]\nThe diagram above shows that $H$ represents the function $h_{t}$ changing continuously according to $s$ in the unit square $I^{2}$.\nThe Meaning of Homotopy As mentioned before, the idea that two paths are homotopic can be understood to mean that by slightly altering one path, it can be turned into the other. However, in topology, exploring such \u0026lsquo;practical sameness\u0026rsquo; is to see the \u0026rsquo;true difference\u0026rsquo;.\nFor example, consider two paths connecting two points on a torus as shown above. Since a torus has a hole in the middle, there is no homotopy joining the blue path and the red path, making them not homotopic. It\u0026rsquo;s important to see that by examining not just \u0026lsquo;points to points\u0026rsquo; but \u0026rsquo;the relations between points,\u0026rsquo; we reach a stage where we can classify torus from non-torus convex shapes. Put grandly, studying homotopy is not merely a jargon-filled endeavor understandable only to non-specialists but a fresh methodology for viewing the essence of space.\nEquivalence Condition It\u0026rsquo;s not something to prove but just to mention passingly, but practically, the following definition might be more convenient to use.\n$f$ and $g$ being homotopic is equivalent to the existence of a continuous function $H : I \\times I \\to X$ satisfying the following two conditions:\n(i): For all $t \\in I$, $H(0,t) = x_{0}$ and $H(1,t) = x_{1}$. (ii): For all $s \\in I$, $H (s, 0) = f(s)$ and $H(s,1) = g(s)$. Homotopy as Path of Paths The following discussion might be a bit complex, so feel free to skip if it seems too daunting. $$ \\begin{align*} h_{t} (s) =\u0026amp; x_{0} \\to x_{1} \u0026amp; \\text{ as } s = 0 \\to 1 \\\\ h_{t} = \u0026amp; f \\to g \u0026amp; \\text{ as } t = 0 \\to 1 \\end{align*} \\qquad \\cdots ü§î ! $$\nFormally, a path $f,g : I \\to X$ in $X$ connecting two points $x_{0}, x_{1}$ is an element $f,g \\in C \\left( I, X \\right)$ of the space of continuous functions, and $h_{t} : I \\to C \\left( I , X \\right)$ is a path between two paths $f, g$ in that function space. $$ h_{t} \\in C \\left( I , C \\left( I , X \\right) \\right) $$ There\u0026rsquo;s no reason not to call it a path. The reason we don\u0026rsquo;t use such expressions explicitly in the definition is that mentioning the natural topology of $C \\left( I , X \\right)$ as a topological space just for the definition of homotopy is too much. After all, definitions are better when shorter, and to discuss homotopy, requiring the continuity of the bivariate function $H$ is sufficient.\nTalking about the continuity in a function space rather than $H$\u0026rsquo;s continuity would first require a topology on the function space, like the compact-open topology of a function space, which is overkill. Of course, just because the definition appears simple in the literature, we don\u0026rsquo;t necessarily need to stop at just knowing the definition. Homotopy has been simply defined above, but let\u0026rsquo;s take a moment with the remaining time to imagine beyond that. In mathematics, the function $$ F : Y \\to X $$ of any set $Y, X$ cannot but garner interest. Thinking about a function of functions, that is, a new function $$ H : Z \\to X^{Y} \\iff H : Z \\times Y \\to X $$ with domain $Z$ and codomain the function space $X^{Y}$, endlessly brings new research topics like sequences of functions or inner spaces. If you agree that such curiosity is natural, now imagine inserting the closed unit interval $I = [0,1]$ in place of $Z$ and $Y$. $$ H : I \\times I \\to X $$\nThis is nothing but what we saw in the definition of $H$. In other words, despite its complicated name, homotopy is merely\ndefined from $I \\times I$ and involves an area of obvious interest: continuous functions of continuous functions where only the starting and ending points are specified among a set of functions Not more than that. If homotopy seems unfamiliar and unintentionally large, be grateful for staying within the tiny scope of $I \\times I$ instead of the vast expanse of $Y,Z$.\nHatcher. (2002). Algebraic Topology: p25.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2411,"permalink":"https://freshrimpsushi.github.io/en/posts/2411/","tags":null,"title":"Definition of Homotopy"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview 1 Dates is a module that collects functions related to dates and times. It is inevitably useful not only for general programming but also for handling a lot of data, whether it\u0026rsquo;s related to time series or not1.\nCode Full Code using Dates\rÏò§Îäò = DateTime(2022,3,10)\rtypeof(Ïò§Îäò)\rpropertynames(Ïò§Îäò)\rÏò§Îäò.instant\rmyformat = DateFormat(\u0026#34;d-m-y\u0026#34;)\rÎÇ¥Ïùº = Date(\u0026#34;11-3-2022\u0026#34;, myformat)\rDates.dayname(ÎÇ¥Ïùº)\rÏùºÏ£ºÏùºÎí§ÍπåÏßÄ = Ïò§Îäò:Day(1):DateTime(2022,3,17)\rcollect(ÏùºÏ£ºÏùºÎí§ÍπåÏßÄ)\rDates.Day(ÏùºÏ£ºÏùºÎí§ÍπåÏßÄ[end]) - Dates.Day(Ïò§Îäò) DateTime Type julia\u0026gt; Ïò§Îäò = DateTime(2022,3,10)\r2022-03-10T00:00:00\rjulia\u0026gt; typeof(Ïò§Îäò)\rDateTime For instance, if you assigned the date of March 10th of the year 22 to today using the DateTime() function, then today would have the type DateTime. DateTime has a property called instant, which records time in milliseconds.\njulia\u0026gt; propertynames(Ïò§Îäò)\r(:instant,)\rjulia\u0026gt; Ïò§Îäò.instant\rDates.UTInstant{Millisecond}(Millisecond(63782553600000)) Format DateFormat() julia\u0026gt; myformat = DateFormat(\u0026#34;d-m-y\u0026#34;)\rdateformat\u0026#34;d-m-y\u0026#34;\rjulia\u0026gt; ÎÇ¥Ïùº = Date(\u0026#34;11-3-2022\u0026#34;, myformat)\r2022-03-11 This is often used when dates are written differently due to the difference between the East and the West.\nDay of the Week Dates.dayname() julia\u0026gt; Dates.dayname(ÎÇ¥Ïùº)\r\u0026#34;Friday\u0026#34; Returns the day of the week for the given date. Due to the absurdity of the Gregorian calendar, creating such a function myself would be surprisingly difficult.\nVector of Dates julia\u0026gt; ÏùºÏ£ºÏùºÎí§ÍπåÏßÄ = Ïò§Îäò:Day(1):DateTime(2022,3,17)\rDateTime(\u0026#34;2022-03-10T00:00:00\u0026#34;):Day(1):DateTime(\u0026#34;2022-03-17T00:00:00\u0026#34;)\rjulia\u0026gt; collect(ÏùºÏ£ºÏùºÎí§ÍπåÏßÄ)\r8-element Vector{DateTime}:\r2022-03-10T00:00:00\r2022-03-11T00:00:00\r2022-03-12T00:00:00\r2022-03-13T00:00:00\r2022-03-14T00:00:00\r2022-03-15T00:00:00\r2022-03-16T00:00:00\r2022-03-17T00:00:00 This is arguably the most useful part of the Julia date package. Vectorizing the span between specific points in time as above results in exactly what you would imagine. It\u0026rsquo;s challenging to create, but it\u0026rsquo;s rare to find syntax in other languages that integrates so well and provides such outstanding intuition.\nDate Subtraction - julia\u0026gt; Dates.Day(ÏùºÏ£ºÏùºÎí§ÍπåÏßÄ[end]) - Dates.Day(Ïò§Îäò)\r7 days Apparently, you can calculate the interval between two points in time with subtraction. Using Dates.canonicalize() allows for pretty output in hours, minutes, and seconds.\nEnvironment OS: Windows julia: v1.7.0 https://docs.julialang.org/en/v1/stdlib/Dates/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2410,"permalink":"https://freshrimpsushi.github.io/en/posts/2410/","tags":null,"title":"Using Date and Time Functions in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview 1 2 The Fastest Fourier Transform in the West (FFTW) is a software library developed by Matteo Frigo and Steven G. Johnson at the Massachusetts Institute of Technology (MIT) for computing the Discrete Fourier Transform. While there exists a Julia package named AbstractFFTs.jl for FFT implementation, it is not intended to be used on its own but rather to aid in the implementation of fast Fourier transforms, such as with FFTW.jl.\nThis package is mainly not intended to be used directly. Instead, developers of packages that implement FFTs (such as FFTW.jl or FastTransforms.jl) extend the types/functions defined in AbstractFFTs. This allows multiple FFT packages to co-exist with the same underlying fft(x) and plan_fft(x) interface.3\nSummary Fourier Transform: fft() Transform by column in a $2$-dimensional array: fft( ,[1]) Transform by row in a $2$-dimensional array: fft( ,[2]) Transform specific dimensions of an array: fft( ,[n‚ÇÅ, n‚ÇÇ, ...]) Inverse Fourier Transform: ifft() Frequency centering $0$: fftshift() Inverse: ifftshift() Frequency Sampling: fftfreq(n, fs=1) Code Fourier Transform In Julia, the notations for the Fourier Transform such as $\\mathcal{F}[f]$, $\\hat{f}$ are used directly in code. Let\u0026rsquo;s sample sine waves of frequencies $100$, $200$, $350$ at intervals of $1/1000$ and add them together.\nusing FFTW\rusing Plots\rusing LaTeXStrings\rFs = 1000 #ÏßÑÎèôÏàò\rT = 1/1000 #ÏÉòÌîåÎßÅ Í∞ÑÍ≤©\rL = 1000 #Ïã†Ìò∏Ïùò Í∏∏Ïù¥\rx = [i for i in 0:L-1].*T #Ïã†Ìò∏Ïùò ÎèÑÎ©îÏù∏\rf‚ÇÅ = sin.(2œÄ*100*x) #ÏßÑÎèôÏàòÍ∞Ä 100Ïù∏ ÏÇ¨Ïù∏Ìåå\rf‚ÇÇ = 0.5sin.(2œÄ*200*x) #ÏßÑÎèôÏàòÍ∞Ä 100Ïù∏ ÏÇ¨Ïù∏Ìåå\rf‚ÇÉ = 2sin.(2œÄ*350*x) #ÏßÑÎèôÏàòÍ∞Ä 100Ïù∏ ÏÇ¨Ïù∏Ìåå\rf = f‚ÇÅ + f‚ÇÇ + f‚ÇÉ Fourier Transform: fft() Inverse Fourier Transform: ifft() According to the definition, the Fourier Transform $f$ of $\\mathcal{F}f$ is only nonzero at $50$, $100$, $200$. By the definition of the Discrete Fourier Transform, we obtain symmetric values around the $y$ axis, but the frequency at $0$ is the first value by default. Therefore, if the aim is to check the frequency and amplitude of the signal, plotting only the first half is sufficient.\nFs = 1000 # ÏÉòÌîåÎßÅ Ï£ºÌååÏàò\r‚Ñ±f = fft(f) # Ìë∏Î¶¨Ïóê Î≥ÄÌôò\rŒæ = Fs*[i for i in 0:L/2-1]/L #Ï£ºÌååÏàò ÎèÑÎ©îÏù∏(Ï†àÎ∞ò)\rplot(Œæ, abs.(‚Ñ±f[1:Int(L/2)])*2/L, title=L\u0026#34;Fourier transform of ‚ñ∑eq10‚óÅ\u0026#34;, label=\u0026#34;\u0026#34;) xlabel!(\u0026#34;frequency\u0026#34;)\rylabel!(\u0026#34;amplitude\u0026#34;)\rsavefig(\u0026#34;fft.png\u0026#34;) Frequency Centering $0$ The output of a Fourier Transform inherently places the value at frequency $0$ first. To center the value at frequency $0$, use fftshift(). To reverse this, use ifftshift(), which is not ifft + shift, but rather the inversion + fftshift, meaning it is the inverse operation of fftshift().\np1 = plot(Œæ, abs.(‚Ñ±f), title=L\u0026#34;‚ñ∑eq11‚óÅ\u0026#34;, label=\u0026#34;\u0026#34;, yticks=[], xticks=[0, 100, 200, 350, 500, 1000]) p2 = plot(Œæ.-500, abs.(fftshift(‚Ñ±f)), title=L\u0026#34;‚ñ∑eq22‚óÅ\u0026#34;, label=\u0026#34;\u0026#34;, yticks=[], xticks=[-500,-350,-200,-100,0,100,200,350,500]) plot(p1, p2, size=(800,400))\rsavefig(\u0026#34;fftshift.png\u0026#34;) Multi-dimensional Fourier Transform To compare with the values of a 2-dimensional Fourier Transform, let\u0026rsquo;s first calculate the Fourier Transform values of $x = [1\\ 2\\ 3\\ 4]^{T}$.\njulia\u0026gt; x = [1.0; 2; 3; 4]\r4-element Vector{Float64}:\r1.0\r2.0\r3.0\r4.0\rjulia\u0026gt; fft(x)\r4-element Vector{ComplexF64}:\r10.0 + 0.0im\r-2.0 + 2.0im\r-2.0 + 0.0im\r-2.0 - 2.0im fft() automatically returns a 2-dimensional Fourier Transform when given a 2-dimensional array as input. Alternatively, fft(, [1,2]) means to compute the transform along the first and second dimensions, and it returns the same result.\njulia\u0026gt; y = [x x x x]\r4√ó4 Matrix{Float64}:\r1.0 1.0 1.0 1.0\r2.0 2.0 2.0 2.0\r3.0 3.0 3.0 3.0\r4.0 4.0 4.0 4.0\rjulia\u0026gt; fft(y)\r4√ó4 Matrix{ComplexF64}:\r40.0+0.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im\r-8.0+8.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im\r-8.0+0.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im\r-8.0-8.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im\rjulia\u0026gt; fft(y, [1,2])\r4√ó4 Matrix{ComplexF64}:\r40.0+0.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im\r-8.0+8.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im\r-8.0+0.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im\r-8.0-8.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im Therefore, to transform each column, use fft(, [1]), and to transform each row, use fft(, [2]).\njulia\u0026gt; fft(y, [1])\r4√ó4 Matrix{ComplexF64}:\r10.0+0.0im 10.0+0.0im 10.0+0.0im 10.0+0.0im\r-2.0+2.0im -2.0+2.0im -2.0+2.0im -2.0+2.0im\r-2.0+0.0im -2.0+0.0im -2.0+0.0im -2.0+0.0im\r-2.0-2.0im -2.0-2.0im -2.0-2.0im -2.0-2.0im\rjulia\u0026gt; fft(y, [2])\r4√ó4 Matrix{ComplexF64}:\r4.0+0.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im\r8.0+0.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im\r12.0+0.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im\r16.0+0.0im 0.0+0.0im 0.0+0.0im 0.0+0.0im Frequency Sampling fftfreq(n, fs=1) Returns the frequency domain of length $n$ with interval $fs/n$. As mentioned earlier, since the Fourier Transform positions the frequency at $0$ at the forefront, the first value sampled by fftfreq() is $0$. The first half is positive frequencies, and the latter half is negative. Hence, using fftshift() arranges them in ascending order according to the index.\njulia\u0026gt; fftfreq(4, 1)\r4-element Frequencies{Float64}:\r0.0\r0.25\r-0.5\r-0.25\rjulia\u0026gt; fftfreq(5, 1)\r5-element Frequencies{Float64}:\r0.0\r0.2\r0.4\r-0.4\r-0.2\rjulia\u0026gt; fftshift(fftfreq(4, 1))\r-0.5:0.25:0.25 Environment OS: Windows11 Version: Julia 1.8.2, FFTW 1.5.0 http://www.fftw.org/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/JuliaMath/FFTW.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/JuliaMath/AbstractFFTs.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3440,"permalink":"https://freshrimpsushi.github.io/en/posts/3440/","tags":null,"title":"How to Use Fast Fourier Transform (FFT) in Julia"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Definition 1 Let\u0026rsquo;s say an arbitrary set $X$ is given.\nA (Abstract Simplicial) Complex $A \\subset 2^{X}$ that satisfies the following among the finite subsets of the power set $2^{X}$ of $X$ is defined as: $$ \\alpha \\in A \\land \\beta \\subset \\alpha \\implies \\beta \\in A $$ The elements $\\alpha \\in A$ of the complex $A$ are called Simplices. The Dimension of a Simplex $\\alpha$ $\\dim$ is defined as the value obtained by subtracting $1$ from the cardinality of $\\alpha$. $$ \\dim \\alpha := | \\alpha | - 1 $$ The Dimension of the Complex $A$ is defined as the maximum value among the dimensions of all simplices in $A$. $$ \\dim A := \\max_{\\alpha \\in A} \\left( \\dim \\alpha \\right) $$ A proper subset $\\beta \\subsetneq \\alpha$ of the simplex $\\alpha$, which is not the empty set, is called a Face of $\\alpha$. The union $V(A)$ of all simplices in $A$, calculated as follows, is called the Vertex Set of $A$. $$ V(A) := \\bigcup_{\\alpha \\in A} \\alpha $$ If a subset $B \\subset A$ of a complex is a complex, it is called a Subcomplex. If there exists a bijective $b : V(A) \\to V(B)$ satisfying the following, two complexes $A, B$ are said to be Isomorphic. $$ \\alpha \\in A \\iff b (\\alpha) \\in B $$ For a (Geometric) Simplicial Complex $K$, the (Abstract) Simplicial Complex $A$ obtained by ignoring all its constructions but maintaining the relationships between vertices is called the Vertex Scheme of $K$, and in this case, $K$ is referred to as the Geometric Realization of $A$. Explanation The Abstract Simplicial Complex is, as its name suggests, an abstraction of the simplicial complex stripped of its geometric meaning. From a mathematician\u0026rsquo;s point of view, conditions like convex hulls are just annoying restrictions.\nFor example, when considering $X = \\mathbb{N}$ $$ \\begin{align*} T :=\u0026amp; \\left\\{ \\left\\{ 1 \\right\\}, \\left\\{ 2 \\right\\} , \\left\\{ 3 \\right\\}, \\left\\{ 4 \\right\\} , \\right. \\\\ \u0026amp; \\left\\{ 1,2 \\right\\}, \\left\\{ 2,3 \\right\\}, \\left\\{ 3,4 \\right\\}, \\left\\{ 4,1 \\right\\}, \\left\\{ 2,4 \\right\\} \\\\ \u0026amp; \\left. \\left\\{ 1,2,4 \\right\\} , \\left\\{ 2,3,4 \\right\\} \\right\\} \\end{align*} $$ it perfectly satisfies all the conditions of an abstract simplicial complex, and in this case, it‚Äôs completely fine to disregard any geometric meaning like the Euclidean space $\\mathbb{R}$. $T$ has $0$-dimensional simplices, $5$ $1$-dimensional simplices, and $2$ $2$-dimensional simplices, making the complex itself $2$-dimensional with the vertex set $V(T) = \\left\\{ 1,2,3,4 \\right\\}$. Meanwhile, if a Geometric Simplicial Complex $G$ is given, it\u0026rsquo;s entirely appropriate to consider $T$ as the vertex scheme of $G$.\nEdelsbrunner, Harer. (2010). Computational Topology An Introduction: p63~64.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2409,"permalink":"https://freshrimpsushi.github.io/en/posts/2409/","tags":null,"title":"Abstract Simplicial Complexes: Definitions"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In fields like machine learning, 32-bit floating point numbers are used instead of 64-bit ones for improving computation speed and saving memory. Therefore, in PyTorch, when tensors are created, their data type is fundamentally 32-bit floating point numbers by default. In Julia, there\u0026rsquo;s a machine learning package called Flux.jl, which takes Julia\u0026rsquo;s standard arrays as input for the neural networks it implements. The fact that it does not use separate data structures like tensors can be seen as an advantage, but the hassle of having to set the data type to Float32 manually can also be seen as a drawback. Below, we introduce a way to change the default data type.\nCode1 ChangePrecision.jl By using the @changeprecision macro, the default data type can be changed within a begin ... end block.\njulia\u0026gt; Pkg.add(\u0026#34;ChangePrecision\u0026#34;)\rjulia\u0026gt; using ChangePrecision\rjulia\u0026gt; rand(3)\r3-element Vector{Float64}:\r0.580516564576538\r0.33915094423556424\r0.3612907828959878\rjulia\u0026gt; @changeprecision Float32 begin\rrand(3)\rend\r3-element Vector{Float32}:\r0.0459705\r0.0033969283\r0.579983 Environment OS: Windows10 Version: Julia 1.8.2, ChangePrecision 1.0.0 https://stackoverflow.com/questions/68068823/how-to-change-default-float-to-float32-in-a-local-julia-environment\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3439,"permalink":"https://freshrimpsushi.github.io/en/posts/3439/","tags":null,"title":"How to Change Basic Data Types in Julia"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Theorem Let\u0026rsquo;s assume we are given an input set $X \\ne \\emptyset$ and a positive definite kernel $k: X \\times X \\to \\mathbb{R}$. Define the Training Dataset as $$ D := \\left\\{ \\left( x_{i} , y_{i} \\right) \\right\\}_{i=1}^{m} \\subset X \\times \\mathbb{R} $$ and a class in the Reproducing Kernel Hilbert Space $H_{k}$ as $$ \\mathcal{F} := \\left\\{ f \\in \\mathbb{R}^{X} : f \\left( \\cdot \\right) = \\sum_{i=1}^{\\infty} \\beta_{i} k \\left( \\cdot , z_{i} \\right) \\land \\beta_{i} \\in \\mathbb{R} \\land z_{i} \\in X \\land \\left\\| f \\right\\| \u0026lt; \\infty \\right\\} \\subset H_{k} $$ Consider an arbitrary objective function $c : \\left( D \\times \\mathbb{R} \\right) ^{m} \\to \\overline{\\mathbb{R}}$ and a monotonically increasing regularizer $g : \\mathbb{R} \\to [0,\\infty)$, defining the Regularized Objective Functional $L : \\mathcal{F} \\to \\overline{\\mathbb{R}}$ as follows: $$ L (f) := c \\left( \\left( x_{1}, y_{1}, f \\left( x_{1} \\right) \\right), \\cdots , \\left( x_{m}, y_{m}, f \\left( x_{m} \\right) \\right) \\right) + g \\left( \\left\\| f \\right\\| \\right) $$ Here, the norm $\\left\\| \\cdot \\right\\|$ in $H_{k}$ is given according to the positive definiteness of $k$ as follows: $$ \\left\\| \\sum_{i=1}^{\\infty} \\beta_{i} k \\left( \\cdot , z_{i} \\right) \\right\\|^{2} := \\sum_{i=1}^{\\infty} \\sum_{j=1}^{\\infty} \\beta_{i} \\beta_{j} k \\left( z_{i} , z_{j} \\right) \\ge 0 $$\n$\\mathbb{R}$ is the set of real numbers, and $\\overline{\\mathbb{R}}$ includes infinity $\\infty$ as an extended real number. $\\mathbb{R}^{X}$ is a function space collecting functions with domain $X$ and codomain $\\mathbb{R}$. A regularizer is a penalty function to prevent overfitting on data. A functional is, loosely speaking, a function that takes another function as input. Nonparametric The function $f \\in \\mathcal{F}$ that minimizes $L (f)$ for some $\\left\\{ \\alpha_{i} \\right\\}_{i=1}^{m} \\subset \\mathbb{R}$ is expressed in the following form: $$ f (\\cdot) = \\sum_{i=1}^{m} \\alpha_{i} k \\left( \\cdot , x_{i} \\right) $$\nSemiparametric Assuming a set of $M$ real functions defined in $X$ such that the rank of matrix $\\left( \\psi_{p} \\left( x_{i} \\right) \\right)_{ip}$ is $M$ for $\\left\\{ \\psi_{p} : X \\to \\mathbb{R} \\right\\}_{p=1}^{M}$, then for $f \\in \\mathcal{F}$ and $h \\in \\span \\left\\{ \\psi_{p} \\right\\}$, the $\\tilde{f} = f + h$ that minimizes $$ c \\left( \\left( x_{1}, y_{1}, \\tilde{f} \\left( x_{1} \\right) \\right) , \\cdots , \\left( x_{m}, y_{m}, \\tilde{f} \\left( x_{m} \\right) \\right) \\right) + g \\left( \\left\\| f \\right\\| \\right) $$ for some $\\left\\{ \\alpha_{i} \\right\\}_{i=1}^{m}, \\left\\{ \\beta_{p} \\right\\}_{p=1}^{M} \\subset \\mathbb{R}$ is expressed in the following form: $$ \\tilde{f} (\\cdot) = \\sum_{i=1}^{m} \\alpha_{i} k \\left( \\cdot , x_{i} \\right) + \\sum_{p=1}^{M} \\beta_{p} \\psi_{p} (\\cdot) $$\nExplanation It is recommended to read the following two posts first if possible:\nReproducing Kernel Hilbert Space Support Vector Machines Representers The Representer Theorem is one of the most important theorems in the context of classical machine learning, especially Support Vector Machines, stating that the objective function $f$ we wish to approximate for given data can be represented in the form of $$ f (\\cdot) = \\sum_{i=1}^{m} \\alpha_{i} k \\left( \\cdot , x_{i} \\right) $$ with respect to a suitable kernel $k$. Here, functions $$ k \\left( \\cdot , x_{i} \\right) = \\phi \\left( x_{i} \\right) (\\cdot)\\in H_{k} $$ with one of the kernel\u0026rsquo;s inputs fixed at $x_{i}$ are called representers. According to this theorem, any function fitted to the training data in the Reproducing Kernel Hilbert Space can be represented as a finite linear combination of representers. This aligns perfectly with the kernel trick for support vector machines in nonlinear regression.\nThis is analogous to the relationship between Deep Learning and the Cybenko Theorem. In the context of data science, representers $\\phi \\left( x_{i} \\right) (\\cdot)$ are also referred to as feature maps, implying that any data $X$ can be mapped into a Hilbert space where its features are known and represented by a finite sum of these features, justifying why many machine learning techniques we\u0026rsquo;ve learned so far work. While these techniques are valid in their own right even without mathematical guarantees, the Representer Theorem is crucial as it provides a theoretical foundation for them.\nObjective Function and Regularizer Although the objective function $c$ and regularizer $g$ are defined very generally in the theorem\u0026rsquo;s statement, in many cases, $c$ can be seen as the mean squared residual, $$ c = {{ 1 } \\over { m }} \\sum_{i=1}^{n} \\left( y_{i} - f \\left( x_{i} \\right) \\right)^{2} $$ measuring the fit between data and $f$, and $g$ can be a squared semi-norm penalty $g \\left( \\left\\| f \\right\\| \\right) = \\lambda \\left\\| f \\right\\|^{2}$1.\nIt\u0026rsquo;s important not to distinguish between the objective function and regularizer merely based on the appearance of the equations or the meanings of the words. The most emblematic application of the Representer Theorem is the Support Vector Machine, where the minimization problem handled in Soft Margin SVM is as follows: $$ \\begin{matrix} \\text{Minimize} \u0026amp; {{ 1 } \\over { 2 }} \\left\\| \\mathbf{w} \\right\\|_{2}^{2} + \\lambda \\sum_{k=1}^{n} \\xi_{k} \\\\ \\text{subject to} \u0026amp; \\left| f \\left( \\mathbf{x}_{k} \\right) \\right| \\ge 1 - \\xi_{k} \\\\ \u0026amp; \\xi_{k} \\ge 0 \\end{matrix} \\\\ k = 1, \\cdots , n $$\nHere, considering the optimization itself, the objective function for a constant $\\lambda \\ne 0$ is essentially $$ {{ 1 } \\over { 2 \\lambda }} \\left\\| \\mathbf{w} \\right\\|_{2}^{2} + \\sum_{k=1}^{n} \\xi_{k} $$ where $\\sum_{k=1}^{n} \\xi_{k}$, representing the discrepancy with data, becomes $c$, and ${{ 1 } \\over { 2 \\lambda }} \\left\\| \\mathbf{w} \\right\\|_{2}^{2}$ derived from the hyperplane of the Support Vector Machine $f (\\mathbf{x}) = \\mathbf{w}^{T} + b$ becomes $g$. This can be confusing depending on whether the focus is on mathematics or machine learning because\nThose with a stronger mathematical inclination see SVM as \u0026rsquo;linear regression first, then considering exceptions\u0026rsquo; and tend to minimize $\\left\\| \\mathbf{w} \\right\\|_{2}^{2}$ first, Those with a stronger data science inclination view SVM as \u0026lsquo;first succeeding in classifying data well, then finding the hyperplane with the largest margin\u0026rsquo; and tend to minimize $\\sum_{k=1}^{n} \\xi_{k}$ first. Both perspectives are understandable, and since the application of the Representer Theorem isn\u0026rsquo;t limited to just SVM, one should think and adapt actively to the problem at hand rather than seeking a mnemonic technique.\nProof 2 For simplicity, only the nonparametric representer theorem is proved as per the reference.\nPart 1. $f = \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) + v$\nDefinition of Reproducing Kernel: A function $k : X \\times X \\to \\mathbb{C}$ is called the reproducing kernel of $H$ if it satisfies the following two conditions:\n(i): Representer: For all $x \\in X$, $$ k \\left( \\cdot , x \\right) \\in H $$ (ii) Reproducing Property: For all $x \\in X$ and all $f \\in H$, $$ \\left\u0026lt; f , k \\left( \\cdot , x \\right) \\right\u0026gt; = f(x) = \\delta_{x} (f) $$ Particularly, for all $x_{1} , x_{2} \\in X$, $$ k \\left( x_{1} , x_{2} \\right) = \\left\u0026lt; k \\left( \\cdot , x_{2} \\right), k \\left( \\cdot , x_{1} \\right) \\right\u0026gt; $$ Define the (representer) function $\\phi : X \\to \\mathbb{R}^{X}$ in the reproducing kernel $k : X \\times X \\to \\mathbb{R}$ as $x \\mapsto k (\\cdot ,x)$. Since $k$ is a reproducing kernel, the function value of function $\\left( \\phi (x) \\right) (\\cdot)$ at any $x, x' \\in X$ is $$ \\left( \\phi (x) \\right) (x ') = k \\left( x' , x \\right) = \\left\u0026lt; \\phi \\left( x ' \\right) , \\phi (x) \\right\u0026gt; $$ where $\\left\u0026lt; \\cdot , \\cdot \\right\u0026gt;$ is the inner product in $H_{k}$. For a given $\\left\\{ x_{i} \\right\\}_{i=1}^{m}$, any function $f \\in \\mathcal{F}$ can be expressed as a sum of a part in $\\span \\left\\{ \\phi \\left( x_{i} \\right) \\right\\}_{i=1}^{m}$ and a part orthogonal to it, satisfying $$ \\left\u0026lt; v , \\phi \\left( x_{j} \\right) \\right\u0026gt; = 0 $$ for all $j$, and for some $\\left( \\alpha_{1} , \\cdots , \\alpha_{m} \\right) \\subset \\mathbb{R}^{m}$ as follows: $$ f = \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) + v $$ We will now argue that $c$ is independent of $v$ and when $v = 0$, $f$ minimizes $L(f)$ in $$ \\begin{align*} L (f) :=\u0026amp; c \\left( \\left( x_{1}, y_{1}, f \\left( x_{1} \\right) \\right), \\cdots , \\left( x_{m}, y_{m}, f \\left( x_{m} \\right) \\right) \\right) + g \\left( \\left\\| f \\right\\| \\right) \\\\ =\u0026amp; c + g \\end{align*} $$.\nPart 2. $c$ and $v$ are independent\nThe inner product of function $f = f(\\cdot)$ and the reproducing kernel $k \\left( \\cdot , x_{j} \\right)$, according to the reproducing property, is $$ \\begin{align*} =\u0026amp; \\left\u0026lt; f , k \\left( \\cdot , x_{j} \\right) \\right\u0026gt; \\\\ f \\left( x_{j} \\right) =\u0026amp; \\left\u0026lt; \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) + v , \\phi \\left( x_{j} \\right) \\right\u0026gt; \\\\ =\u0026amp; \\sum_{i=1}^{m} \\alpha_{i} \\left\u0026lt; \\phi \\left( x_{i} \\right) , \\phi \\left( x_{j} \\right) \\right\u0026gt; + 0 \\end{align*} $$ As this is independent of $v$, in $L (f) = c + g$, the expression dependent only on the training data $D$ and $f$, $$ c = c \\left( \\left( x_{1}, y_{1}, f \\left( x_{1} \\right) \\right), \\cdots , \\left( x_{m}, y_{m}, f \\left( x_{m} \\right) \\right) \\right) $$ is also independent of $v$.\nPart 3. $g$ is minimized when $v = 0$\n(1): $v$ is orthogonal to $\\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right)$, and (2): Since $g$ is assumed to be a monotonic function, we obtain $$ \\begin{align*} \u0026amp; g \\left( \\left\\| f \\right\\| \\right) \\\\ =\u0026amp; g \\left( \\left\\| \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) + v \\right\\| \\right) \\\\ =\u0026amp; g \\left( \\sqrt{\\left\\| \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) + v \\right\\|^{2} + \\left\\| v \\right\\|^{2}} \\right) \u0026amp; \\because (1) \\\\ \\ge\u0026amp; g \\left( \\left\\| \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) \\right\\| \\right) \u0026amp; \\because (2) \\end{align*} $$ As seen, the equality holds when $v = 0$, and for $g$ to be minimized, $v=0$ must hold. Meanwhile, from Part 2, we confirmed that $v$ cannot influence $c$, so setting it to $v = 0$ is acceptable, and the function $f$ that minimizes $L = c + g$ can be represented in the form of $$ f (\\cdot) = \\sum_{i=1}^{m} \\alpha_{i} k \\left( \\cdot , x_{i} \\right) $$\n‚ñ†\nWahba. (2019). Representer Theorem. https://pages.stat.wisc.edu/~wahba/ftp1/wahba.wang.2019submit.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSch√∂lkopf. (2001). A Generalized Representer Theorem. https://link.springer.com/chapter/10.1007/3-540-44581-1_27\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2408,"permalink":"https://freshrimpsushi.github.io/en/posts/2408/","tags":null,"title":"Proof of the Representation Theorem"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Definition 1 2 Input Space $X \\ne \\emptyset$ is the domain and the codomain is the set of complex numbers $\\mathbb{C}$, and let\u0026rsquo;s denote the space of functions $\\left( H , \\left\u0026lt; \\cdot , \\cdot \\right\u0026gt; \\right) \\subset \\mathbb{C}^{X}$ composed of mappings $f: X \\to \\mathbb{C}$ as a Hilbert space.\nReproducing Kernel Hilbert Space For a fixed datum $x \\in X$, the functional $\\delta_{x} : H \\to \\mathbb{C}$, which takes a function $f \\in H$ and returns its value at $x$, is called the (Dirac) Evaluation Functional at $x$. $$ \\delta_{x} (f) := f (x) $$ If the evaluation functional $\\delta_{x}$ is continuous for all $x \\in X$, then $H$ is called a Reproducing Kernel Hilbert Space (RKHS) and is sometimes denoted as $H_{k}$. A function $k : X \\times X \\to \\mathbb{C}$ is called the reproducing kernel of $H$ if it satisfies the following two conditions: (i) Representer: For all $x \\in X$, $$ k \\left( \\cdot , x \\right) \\in H $$ (ii) Reproducing Property: For all $x \\in X$ and all $f \\ in H$, $$ \\left\u0026lt; f , k \\left( \\cdot , x \\right) \\right\u0026gt; = f(x) = \\delta_{x} (f) $$ Especially, for all $x_{1} , x_{2} \\in X$, the following holds: $$ k \\left( x_{1} , x_{2} \\right) = \\left\u0026lt; k \\left( \\cdot , x_{2} \\right), k \\left( \\cdot , x_{1} \\right) \\right\u0026gt; $$ Positive Definite Kernel Let\u0026rsquo;s call a mapping $\\phi : X \\to H$ from the input space $X \\ne \\emptyset$ to the Hilbert space $\\left( H , \\left\u0026lt; \\cdot , \\cdot \\right\u0026gt; \\right)$ a feature map. In this context, $H$ is also referred to as the feature space. A function $k : X \\times X \\to \\mathbb{C}$ defined by the inner product $\\left\u0026lt; \\cdot , \\cdot \\right\u0026gt; : H \\times H \\to \\mathbb{C}$ in $\\left( H , \\left\u0026lt; \\cdot , \\cdot \\right\u0026gt; \\right)$ is called a kernel. $$ k \\left( x_{1} , x_{2} \\right) := \\left\u0026lt; \\phi \\left( x_{1} \\right) , \\phi \\left( x_{2} \\right) \\right\u0026gt; $$ For $m$ data points $\\left\\{ x_{1} , \\cdots , x_{m} \\right\\} \\subset X$, the matrix $K \\in \\mathbb{C}^{m \\times m}$ formed as follows is called the Gram Matrix of the kernel $k$. $$ K := \\left( k \\left( x_{i} , x_{j} \\right) \\right)_{ij} $$ If the Gram Matrix of $k$ is a positive definite matrix, then $k$ is called a positive definite kernel. In other words, a kernel $k$ whose Gram Matrix satisfies the following for all $\\left\\{ c_{1} , \\cdots , c_{m} \\right\\} \\subset \\mathbb{C}$ is a positive definite kernel. $$ \\sum_{i=1}^{m} \\sum_{j=1}^{m} c_{i} \\bar{c_{j}} K_{ij} \\ge 0 $$ Explanation Although the content is complex, let\u0026rsquo;s read it carefully as it\u0026rsquo;s been simplified as much as possible.\nThe Meaning of Hilbert Space in Data Science A Hilbert space is a complete space where an inner product is defined. In mathematics, an inner product is simply a bi-variable scalar function that satisfies certain conditions, but in machine learning, it can be thought of as a measure of similarity. In fact, the cosine similarity used to compare word frequencies between two documents also uses an inner product, and another naive example is when we have three vectors $$ A := \\left( 3, 0, 1 \\right) \\\\ B := \\left( 4, 1, 0 \\right) \\\\ C := \\left( 0, 2, 5 \\right) $$ it\u0026rsquo;s evident that $A$ and $B$ are similar, and both are different from $C$. Although this is still an intuitive inference, quantifying it through inner product yields: $$ A \\cdot B = 12 + 0 + 0 = 12 \\\\ A \\cdot C = 0 + 0 + 5 = 5 \\\\ B \\cdot C = 0 + 2 + 0 = 2 $$ This simple comparison of the absolute values of inner products explains the data better than just \u0026lsquo;it\u0026rsquo;s obvious\u0026rsquo;.\nNote that there are no specific assumptions about the input space $X$. In real applications, we cannot guarantee what kind of bad data we will handle. For example, if $X$ represents photos or document data, it does not make sense to take inner products of photos or documents.\nQ. If $X$ is a set of black and white photos, can\u0026rsquo;t we just consider the photos as matrices and take inner products based on pixel values? A. That would work, and that\u0026rsquo;s exactly what a feature map $\\phi : X \\to H$ does. In this case, $H$ becomes a space of functions defined on a rectangle $[a,b] \\times [c,d]$. Thinking in this way, the existence of a kernel itself is almost like bringing \u0026lsquo;difficult to handle data\u0026rsquo; into a space we are familiar with. Even if the meaning of inner products mentioned above doesn\u0026rsquo;t make sense, since an inner product space is a norm space and a metric space, most assumptions we consider necessary logically hold. An inner product $\\left\u0026lt; \\cdot , \\cdot \\right\u0026gt;$ induces a norm $$ \\left\\| f \\right\\| := \\sqrt{ \\left\u0026lt; f , f \\right\u0026gt; } $$ and a norm $\\left\\| f \\right\\|$ induces a metric $$ d (f,g) = \\left\\| f -g \\right\\| $$\nFrom a data science perspective, a norm itself quantifies data. For example, if we define the norm of a black and white photo as the sum of all pixel values, this alone can roughly evaluate how bright or dark the photo is. From a data science perspective, a distance tells us how different two data points are. Distinguishing between right and wrong, similar and different, is undoubtedly important. Apart from these reasons, sometimes in mathematical derivations, inner products become necessary. This post won\u0026rsquo;t cover all related examples as it would become too cluttered. Refer to the \u0026lsquo;Kernel Trick\u0026rsquo; section of the \u0026lsquo;Support Vector Machine\u0026rsquo; post.\nWhy a Function Space? Does it Have to be This Complicated? Most applications of mathematics involve finding \u0026rsquo;the function we want\u0026rsquo;.\nInterpolation finds a polynomial function that fills in between given data points. Statistical regression analysis is a technique for finding a line that best explains the data, which is a linear function. Deep learning approximates non-linear functions by incorporating activation functions because linear functions alone are insufficient. Fourier transform represents a function as a linear combination of trigonometric functions. There are countless examples like these. Returning to machine learning, the reason we consider function spaces is that ultimately, what we are looking for is a function. Even if it\u0026rsquo;s not explicitly stated, we want a function that returns the desired result for a given input. For example, a function that returns the number on a photo of a digit, or one that calculates the probability of loan repayment based on personal information. Such useful functions are unlikely to be simple, and we hope they can be represented as a sum of finitely many $\\phi_{k} (x) (\\cdot)$, which serve as bases. In particular, for $\\phi (x) = k (\\cdot , x)$, the proposition that some function $f$ can be found is precisely the Representer Theorem.\nRepresenter Theorem: In a Reproducing Kernel Hilbert Space, any function fitted to the training data can be represented as a finite linear combination of representers.\nIn summary, in machine learning (especially in the context of Support Vector Machines), what we seek is ultimately a function, so exploring the function space where they reside is inevitable.\nWhy is Dirac\u0026rsquo;s Name in Front of the Evaluation Functional? $$ \\delta_{x_{0}} (x) = \\begin{cases} 1 \u0026amp; , \\text{if } x = x_{0} \\\\ 0 \u0026amp; , \\text{if } x \\ne x_{0} \\end{cases} $$ Originally, the Dirac delta function is known as a function that only has a value at one point. Regardless of its precise definition and usage, its variations are typically named after Dirac if they have a non-zero value at only one point. To aid understanding, imagine two functions $f : \\mathbb{R} \\to \\mathbb{R}$, $\\delta_{x_{0}} : \\mathbb{R} \\to \\mathbb{R}$, and their inner product as $$ \\left\u0026lt; f, \\delta_{x_{0}} \\right\u0026gt; = \\sum_{x \\in \\mathbb{R}} f (x) \\delta_{x_{0}} (x) = f \\left( x_{0} \\right) $$ Though we normally use integration instead of summation for the inner product of functions, and summing over all $x \\in \\mathbb{R}$ is risky, the concept aligns with the idea.\nIn this sense, $\\delta_{x_{0}} (f)$ straightforwardly yields $f \\left( x_{0} \\right)$, \u0026lsquo;obtaining a single point\u0026rsquo; at $x_{0}$, hiding the aforementioned discussion.\nWhy it\u0026rsquo;s Called Reproducing Property The definition of RKHS is quite interesting. Usually, when we say \u0026lsquo;some space\u0026rsquo; in mathematics, we define it as the space where \u0026lsquo;some\u0026rsquo; exists, but RKHS is defined as a Hilbert space where \u0026rsquo;the evaluation functional is continuous at every point\u0026rsquo;, which seems out of the blue.\nRiesz Representation Theorem: Let $\\left( H, \\left\\langle \\cdot,\\cdot \\right\\rangle \\right)$ be a Hilbert space. For a linear functional $f \\in H^{ \\ast }$ and $\\mathbf{x} \\in H$, there exists a unique $\\mathbf{w} \\in H$ such that $f ( \\mathbf{x} ) = \\left\\langle \\mathbf{x} , \\mathbf{w} \\right\\rangle$ and $\\| f \\|_{H^{\\ast}} = \\| \\mathbf{w} \\|_{H}$.\nMoore-Aronszajn Theorem: If a positive definite kernel exists, then a unique RKHS corresponding to it also exists.\nAccording to this definition, the existence of a reproducing kernel in RKHS is not self-evident and requires proof. In fact, the Riesz Representation Theorem guarantees the unique existence of a reproducing kernel in RKHS. Interestingly, conversely, an RKHS corresponding to a reproducing kernel also uniquely exists.\nLet\u0026rsquo;s delve into the formulas in the definition.\nOriginally, the function $k : X \\times X \\to \\mathbb{C}$ could take $x_{1}, x_{2} \\in X$, but if we fix $x$ like in the definition, $k$ essentially becomes $k : y \\mapsto k (y,x)$, a function $k : X \\to \\mathbb{C}$. By blocking one input, it\u0026rsquo;s like $$ \\left\u0026lt; f , k \\left( \\cdot , x \\right) \\right\u0026gt; = f(x) $$ This expression is simply the inner product of two functions $f (\\cdot) : X \\to \\mathbb{C}$ and $k \\left( \\cdot , x \\right): X \\to \\mathbb{C}$. There\u0026rsquo;s no need to overcomplicate thinking, \u0026ldquo;How does $f$ come out and how does the inner product with $x$\u0026hellip;\u0026rdquo; It\u0026rsquo;s unnecessary. Since $f(x) \\in \\mathbb{C}$ is also just a result of the inner product, it\u0026rsquo;s just some complex number, the codomain being the set of complex numbers.\nHere, let\u0026rsquo;s discuss the naming of the reproducing property. The word Reproduction inherently carries the meaning of Re-(again, ÂÜç) -produce (create, Áîü), with its first translation being reproduction/generation, second being copying/duplication, and third being reproduction. Reproduction in the sense of breeding doesn\u0026rsquo;t fit, and copying doesn\u0026rsquo;t seem right as there\u0026rsquo;s no original to speak of.\nHowever, if we consider that inner-producting $f(\\cdot)$ and $k (\\cdot, x)$ to get $f(x)$ is \u0026lsquo;reproducing\u0026rsquo; the information contained in $f$ through the kernel, then wouldn\u0026rsquo;t it make sense? Imagine we have a function $y(t)$ dependent on time $t$, representing a YouTube video. We don\u0026rsquo;t see $y$ itself but the reproduction of $\\left\\{ y(t) : t \\in [0,T] \\right\\}$. In this analogy, the kernel $k$ \u0026lsquo;reproduces\u0026rsquo; the function values from $f$, not as the function itself but as its values, justifying the term \u0026lsquo;reproducing kernel\u0026rsquo;.\nFeature Map and Uncomfortable Notation Looking closely at the definitions of kernel and reproducing kernel, we notice that they don\u0026rsquo;t necessarily need each other for their definitions. A kernel is a kernel, and a reproducing kernel is a reproducing kernel, and they become the same when the feature map is also the representer, i.e., $$ \\phi (x) = k \\left( \\cdot , x \\right) $$ A feature map transforms original data into a form that\u0026rsquo;s easier for us to handle,\nand saying that a function is represented by such functions means it\u0026rsquo;s explained by certain features derived from the data. One issue is that even if one intuitively understands up to this point, the notation like $k \\left( \\cdot , x \\right)$ remains uncomfortable, and it\u0026rsquo;s hard to empathize with the motive behind defining kernels separately from their inner products and feature maps.\nSince a feature map is $\\phi : X \\to H$, its function value for $x \\in X$ is some function $\\lambda : X \\to \\mathbb{C}$, which usually isn\u0026rsquo;t confusing. More precisely, $\\phi (x)$ can be written as $$ \\left( \\phi (x) \\right) (\\cdot) = k \\left( \\cdot , x \\right) $$ Then why use such inconvenient notation with the dot $\\cdot$? Most people find it easier to understand with examples where not using such notation would cause more trouble. As mentioned earlier, whether it\u0026rsquo;s a kernel or a reproducing kernel, the space we consistently care about is the function space $H$, and the inner product in $H$ is between functions. First, let\u0026rsquo;s assume a function $f$ is represented by a linear combination of data representers $\\phi \\left( x_{i} \\right)$: $$ f (y) = \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) (y) = \\sum_{i=1}^{m} \\alpha_{i} \\left( \\phi \\left( x_{i} \\right) \\right) (y) $$ This already looks messy. Considering another function $g$ and different data $\\left\\{ x'_{j} \\right\\}_{j=1}^{n}$, we get $$ g (y) = \\sum_{j=1}^{n} \\beta_{j} \\left( \\phi \\left( x'_{j} \\right) \\right) (y) $$ Moreover, if we\u0026rsquo;re not using inner products, there\u0026rsquo;s no point in considering an inner product space. Writing down $\\left\u0026lt; f,g \\right\u0026gt;$ gives us $$ \\left\u0026lt; f,g \\right\u0026gt; = \\sum_{i=1}^{m} \\sum_{j=1}^{n} \\bar{\\alpha_{i}} \\beta_{j} \\left\u0026lt; \\phi \\left( x_{i} \\right) , \\phi \\left( x'_{j} \\right) \\right\u0026gt; $$ This is unnecessarily complicated. Before taking the inner product, we hardly need to deal with actual $y \\in X$ in the function space, and after taking the inner product, there\u0026rsquo;s no need to keep writing $\\phi$ and the inner product. Seeing this, the notation $$ f (\\cdot) = \\sum_{i=1}^{m} \\alpha_{i} k \\left( \\cdot , x_{i} \\right) \\\\ g (\\cdot) = \\sum_{j=1}^{n} \\beta_{j} k \\left( \\cdot , x'_{j} \\right) \\\\ \\left\u0026lt; f,g \\right\u0026gt; = \\sum_{i=1}^{m} \\sum_{j=1}^{n} \\bar{\\alpha_{i}} \\beta_{j} k \\left( x_{i} , x'_{j} \\right) $$ might not seem as cumbersome.\nReproducing Kernels are Positive Definite Given data $\\left\\{ x_{k} \\right\\}_{k=1}^{m}$, if $k$ is a kernel, then the following holds: $$ \\begin{align*} \u0026amp; \\sum_{i=1}^{m} \\sum_{j=1}^{m} \\bar{\\alpha_{i}} \\alpha_{j} k \\left( x_{i} , x_{j} \\right) \\\\ =\u0026amp; \\sum_{i=1}^{m} \\sum_{j=1}^{m} \\left\u0026lt; \\alpha_{i} \\phi \\left( x_{i} \\right) , \\alpha_{j} \\phi \\left( x_{j} \\right) \\right\u0026gt; \\\\ =\u0026amp; \\left\u0026lt; \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) , \\sum_{j=1}^{m} \\alpha_{j} \\phi \\left( x_{j} \\right) \\right\u0026gt; \\\\ =\u0026amp; \\left\\| \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) \\right\\|^{2} \\\\ \\ge \u0026amp; 0 \\end{align*} $$ As mentioned earlier, if we consider $\\phi : x \\mapsto k (\\cdot , x)$, the reproducing kernel $k$ is also a kernel and thus positive definite. This positive definiteness of kernels naturally appears in various properties related to kernels.\nKernels Outside of Functional Analysis (1) In general mathematics, a kernel often refers to the abstract algebra kernel $\\ker$. For a structure $Y$ where $0$ is defined, the kernel $\\ker f$ of a function $f : X \\to Y$ is defined as $\\ker f := f^{-1} \\left( \\left\\{ 0 \\right\\} \\right)$. (2) This concept is specialized in linear algebra as the kernel of a linear transformation. If you ask someone who isn\u0026rsquo;t specialized in functional analysis about kernels, nine out of ten times, they\u0026rsquo;ll think of meaning (1). If your background is in mathematics, you should at least know about (1), and even if not, you should be familiar with (2).\nNamed Kernels In the context of machine learning, the following kernels are known. 3 These might not seem like kernels at first glance, but they can be derived from the fact that the sum and product of kernels remain kernels.\nLinear Kernel: $$ k \\left( x_{1} , x_{2} \\right) = \\left\u0026lt; x_{1} , x_{2} \\right\u0026gt; $$ Polynomial Kernel: For $c \\ge 0$ and $d \\in \\mathbb{N}$, $$ k \\left( x_{1} , x_{2} \\right) = \\left( \\left\u0026lt; x_{1} , x_{2} \\right\u0026gt; + c \\right) ^{d} $$ Gaussian Kernel: For $\\sigma^{2} \u0026gt; 0$, $$ k \\left( x_{1} , x_{2} \\right) = \\exp \\left( - {{ \\left\\| x_{1} - x_{2} \\right\\| } \\over { 2 \\sigma^{2} }} \\right) $$ Sigmoid Kernel: For $w, b \\in \\mathbb{C}$, $$ k \\left( x_{1} , x_{2} \\right) = \\tanh \\left( w \\left\u0026lt; x_{1} , x_{2} \\right\u0026gt; + b \\right) $$ Sejdinovic, Gretton. (2014). What is an RKHS?: p7~11. http://www.stats.ox.ac.uk/~sejdinov/teaching/atml14/Theory_2014.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSch√∂lkopf. (2001). A Generalized Representer Theorem. https://link.springer.com/chapter/10.1007/3-540-44581-1_27\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJakkula. (2006). Tutorial on Support Vector Machine (SVM). https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2406,"permalink":"https://freshrimpsushi.github.io/en/posts/2406/","tags":null,"title":"Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Model 1 Simple Definition The method of finding a Support Vector Machine is to find a line or plane that best separates binary classifiable data.\nComplex Definition For an inner product space $X = \\mathbb{R}^{p}$ and labeling $Y = \\left\\{ -1, +1 \\right\\}$, let\u0026rsquo;s denote the Training Dataset composed of $n$ pieces of data as $D = \\left\\{ \\left( \\mathbf{x}_{k} , y_{k} \\right) \\right\\}_{k=1}^{n} \\subset X \\times Y$, and $$ \\begin{align*} X^{+} :=\u0026amp; \\left\\{ \\mathbf{x}_{k} \\in X : y_{k} = +1 \\right\\} \\\\ X^{-} :=\u0026amp; \\left\\{ \\mathbf{x}_{k} \\in X : y_{k} = -1 \\right\\} \\end{align*} $$\nSuppose a hyperplane created by a linear function $f \\left( \\mathbf{x} \\right) = \\mathbf{w}^{T} \\mathbf{x} + b$ with some weight $\\mathbf{w} \\in \\mathbb{R}^{p}$ and bias $b \\in \\mathbb{R}$ is $H : \\mathbf{w}^{T} \\mathbf{x} + b = 0$. The $\\mathbf{x}^{+} \\in X^{+}$s and $\\mathbf{x}^{-} \\in X^{-}$s closest to $H$ are called Support Vectors, and the distance $\\delta$ between them is called the Margin. The [machine learning](../../categories/Machine Learning) technique that finds $\\mathbf{w} , b$ that maximizes the margin while satisfying $$ \\begin{align*} f \\left( \\mathbf{x}^{+} \\right) =\u0026amp; +1 \\\\ f \\left( \\mathbf{x}^{-} \\right) =\u0026amp; -1 \\end{align*} $$\nis called Support Vector Machine (SVM).\n$\\mathbb{R}$ is a set of real numbers, and $\\mathbb{R}^{p}$ is the $p$-dimensional Euclidean space. $X \\times Y$ denotes the Cartesian product of two sets. $\\mathbf{w}^{T}$ is the transpose matrix of $\\mathbf{w}$, and $\\mathbf{w}^{T} \\mathbf{x}$ is the inner product $\\left\u0026lt; \\mathbf{w} , \\mathbf{x} \\right\u0026gt;$ of two vectors $\\mathbf{w}, \\mathbf{x}$. Explanation Simply put, it\u0026rsquo;s like finding a line or plane that divides orange and sky-blue data as shown in the next picture. The red arrows in the picture correspond to the support vectors.\nIn the picture, we found a line for $2$ dimensions and a plane for $3$ dimensions, but for larger $p$ dimensions, we need to find a hyperplane, which becomes harder to represent in a picture. However, the concept of dividing the space into two remains the same. Once binary classification is done with the training dataset, new data can be classified using $f$ as a linear classifier.\nObviously, even with the same binary classification data, the left side is better than the right, as the margin for the sky-blue data on the right is excessive. Specifically, how this is calculated is not necessary to know since packages handle it.\nFor undergraduate students, just understanding up to the simple definition and grasping the concept through pictures is sufficient for future use or comprehension of the terminology. For slightly more complex content, practical summary points, and Python example codes, there are plenty of well-organized documents available on domestic web platforms. 2 3 4\nInner Product Space As evident, SVM itself is not particularly complex conceptually, but the reason for introducing mathematical definitions and equations is due to the extensive theoretical discussions to follow.\nThe Euclidean space $\\mathbb{R}^{p}$ is naturally a vector space, an inner product space, and since an inner product space is a metric space, it is also a metric space. Emphasizing this is important because in the real world of data, assuming an inner product space is quite a good assumption. For example, images, documents, or molecular structures immediately raise concerns about whether they can be directly input into SVM. The definition implicitly uses terms like \u0026lsquo;close in distance\u0026rsquo; and linear functions $f$ involving inner products of vectors, which should not be taken for granted as theory approaches reality.\nSupport Vectors In geometric problems, those on the edge (Boundary) are typically called supports. For example, in the Minimum Enclosing Disk problem, the points on the circumference of the circle determining the circle are called supports. Similarly, the support vectors in SVM are also on the boundary, positioned $\\delta/2$ away from the sets $X^{+}, X^{-}$ and $\\mathbf{x}^{+}, \\mathbf{x}^{-}$.\nThere\u0026rsquo;s no guarantee that support vectors are unique for each $X^{+}, X^{-}$, but uniqueness is not important for the upcoming discussions, so let\u0026rsquo;s assume they are unique without losing generality. No data exists on the margin $H$, and $$ f \\left( \\mathbf{x} \\right) \\begin{cases} \\ge +1 \u0026amp; , \\text{if } \\mathbf{x} \\in X^{+} \\\\ \\le -1 \u0026amp; , \\text{if } \\mathbf{x} \\in X^{-} \\end{cases} $$ thus, for all $\\left\\{ \\mathbf{x}_{k} \\right\\}_{k=1}^{n}$s, $\\left| f \\left( \\mathbf{x}_{k} \\right) \\right| \\ge 1$ must hold.\nMaximizing the Margin Since support vectors are the closest points to $H$, the distance $\\delta/2$ to $H$ will be the distance when the support vectors fall in the direction $\\mathbf{w}$ perpendicular to $H$. This margin is the same whether for $\\mathbf{x}^{+}$ or $\\mathbf{x}^{-}$, and both being at a distance $\\delta/2$ from the hyperplane $H$ means the distance between the two support vectors is $$ \\delta \\mathbf{w} = \\mathbf{x}^{+} - \\mathbf{x}^{-} $$ where operations like $\\mathbf{x}^{+} - \\mathbf{x}^{-}$ are permitted under the assumption that $X$ is a vector space. Taking the inner product of both sides of $\\delta \\mathbf{w} = \\mathbf{x}^{+} - \\mathbf{x}^{-}$ with $\\mathbf{w}$, in other words, multiplying $\\mathbf{w}^{T}$ on the left side, gives $$ \\begin{align*} \u0026amp; \\delta \\mathbf{w} = \\mathbf{x}^{+} - \\mathbf{x}^{-} \\\\ \\implies \u0026amp; \\delta \\mathbf{w}^{T} \\mathbf{w} = \\mathbf{w}^{T} \\mathbf{x}^{+} - \\mathbf{w}^{T} \\mathbf{x}^{-} \\\\ \\implies \u0026amp; \\delta \\left\\| \\mathbf{w} \\right\\|_{2}^{2} = \\left( \\mathbf{w}^{T} \\mathbf{x}^{+} + b \\right) - \\left( \\mathbf{w}^{T} \\mathbf{x}^{-} + b \\right) \\\\ \\implies \u0026amp; \\delta \\left\\| \\mathbf{w} \\right\\|_{2}^{2} = +1 - (-1) \\\\ \\implies \u0026amp; \\delta \\left\\| \\mathbf{w} \\right\\|_{2}^{2} = 2 \\\\ \\implies \u0026amp; \\delta = {{ 2 } \\over { \\left\\| \\mathbf{w} \\right\\|_{2}^{2} }} \\end{align*} $$ by definition of $f$. Therefore, maximizing the margin is equivalent to minimizing the objective function $\\left\\| \\mathbf{w} \\right\\|_{2}^{2} / 2$, and in summary, SVM is an optimizer that solves the following optimization problem. $$ \\begin{matrix} \\text{Minimize} \u0026amp; {{ 1 } \\over { 2 }} \\left\\| \\mathbf{w} \\right\\|_{2}^{2} \\\\ \\text{subject to} \u0026amp; \\left| f \\left( \\mathbf{x}_{k} \\right) \\right| \\ge 1 \\end{matrix} \\\\ k = 1, \\cdots , n $$\nDerived Models As per the complex definition, SVM finds a linear function, whether it\u0026rsquo;s a line or hyperplane, and naturally, that wouldn\u0026rsquo;t be satisfactory.\nSoft Margin SVM Consider data like the following. SVM cannot perfectly binary classify it due to the mixed data in the middle.\nNote that we had to satisfy the condition $\\left| f \\left( \\mathbf{x}_{k} \\right) \\right| \\ge 1$ under the constraint that data couldn\u0026rsquo;t exist in the margin of support vectors. If we allow this inequality to be smaller than $1$, it would yield better results than giving up on binary classification altogether, even if it\u0026rsquo;s not perfect. If we denote this allowance for each data as $\\xi_{k} \\ge 0$, we get a new constraint $\\left| f \\left( \\mathbf{x}_{k} \\right) \\right| \\ge 1 - \\xi_{k}$. This weakened margin is called a Soft Margin.\nAlthough the constraint has been relaxed, completely loosening it to $\\xi_{l} = \\cdots = \\xi_{n} = 1$ would negate SVM altogether. To prevent this, a term like $\\sum_{k} \\xi_{k}$ can be added to the objective function as a penalty for making impossible binary classification possible. Of course, such a simple penalty could be meaningless or too sensitive depending on the data scale, so instead of using $0 \\le \\sum_{k} \\xi_{k} \\le n$ as is, it\u0026rsquo;s better to multiply it by a suitable positive number $\\lambda \u0026gt; 0$ and add it. $$ \\begin{matrix} \\text{Minimize} \u0026amp; {{ 1 } \\over { 2 }} \\left\\| \\mathbf{w} \\right\\|_{2}^{2} + \\lambda \\sum_{k=1}^{n} \\xi_{k} \\\\ \\text{subject to} \u0026amp; \\left| f \\left( \\mathbf{x}_{k} \\right) \\right| \\ge 1 - \\xi_{k} \\\\ \u0026amp; \\xi_{k} \\ge 0 \\end{matrix} \\\\ k = 1, \\cdots , n $$\nKernel Trick Given data like the above, it seems impossible to binary classify it with SVM, whether with a soft margin or not. However, it\u0026rsquo;s clear that sky-blue points are clustered closer to $0$, and orange points appear on the outside. To utilize this information, let\u0026rsquo;s create a new $z$-axis as follows. $$ \\phi (x,y) := (x,y, x^{2} + y^{2}) $$\nThe above picture is a capture of the one below. The below is a 3D space interactive with the mouse, so take a look around.\nWhile it was difficult to find a line that separates data in the original $\\mathbb{R}^{2}$, in the expanded $\\mathbb{R}^{3}$, we can now use SVM to classify data with a suitable plane. Naturally, one might ask, \u0026lsquo;So, is this good transformation $\\phi$ called a Kernel, and is using a kernel called the Kernel Trick?\u0026rsquo; The answer is half right and half wrong. $\\phi$ with an extra step, including the inner product, is what constitutes a kernel.\nReturning to Maximizing the Margin, let\u0026rsquo;s revisit the optimization problem given to us. $$ \\begin{matrix} \\text{Minimize} \u0026amp; {{ 1 } \\over { 2 }} \\left\\| \\mathbf{w} \\right\\|_{2}^{2} \\\\ \\text{subject to} \u0026amp; \\left| f \\left( \\mathbf{x}_{k} \\right) \\right| \\ge 1 \\end{matrix} \\\\ k = 1, \\cdots , n $$\nAlthough constraint $\\left| f \\left( \\mathbf{x}_{k} \\right) \\right| \\ge 1$ looks neat, it doesn\u0026rsquo;t help much when solving this problem. If we revert to the form in the original training dataset, for $k = 1 , \\cdots , n$, $$ \\begin{cases} f \\left( \\mathbf{x}_{k} \\right) \\ge 1 \u0026amp; , \\text{if } y_{k} = 1 \\\\ f \\left( \\mathbf{x}_{k} \\right) \\le -1 \u0026amp; , \\text{if } y_{k} = -1 \\end{cases} \\\\ \\implies \\begin{cases} y_{k} \\left( \\mathbf{w}^{T} \\mathbf{x}_{k} + b \\right) \\ge 1 \u0026amp; , \\text{if } y_{k} = 1 \\\\ y_{k} \\left( \\mathbf{w}^{T} \\mathbf{x}_{k} + b \\right) \\ge 1 \u0026amp; , \\text{if } y_{k} = -1 \\end{cases} \\\\ \\implies y_{k} \\left( \\mathbf{w}^{T} \\mathbf{x}_{k} + b \\right) \\ge 1 $$ must hold. The method of incorporating this constraint directly into the objective function, treating it as if there were no constraints, is the Lagrange Multiplier Method. For the objective function minus the terms multiplied by $y_{k} \\left( \\mathbf{w}^{T} \\mathbf{x}_{k} + b \\right) - 1 \\ge 0$ with $\\alpha_{k} \\ge 0$, we get the following optimization problem for $L(\\mathbf{w}, b)$: $$ \\begin{matrix} \\text{Minimize} \u0026amp; {{ 1 } \\over { 2 }} \\left\\| \\mathbf{w} \\right\\|_{2}^{2} - \\sum_{k=1}^{n} \\alpha_{k} \\left[ y_{k} \\left( \\mathbf{w}^{T} \\mathbf{x}_{k} + b \\right) - 1 \\right] \\\\ \\text{subject to} \u0026amp; \\alpha_{k} \\ge 0 \\end{matrix} \\\\ k = 1, \\cdots , n $$\nTo reiterate, our goal was to find $\\mathbf{w}, b$ that minimizes this objective function. The condition that makes the partial derivative of the objective function with respect to $\\mathbf{w}, b$ equal to $0$ is as follows: $$ \\begin{align*} {{ \\partial L } \\over { \\partial \\mathbf{w} }} = 0 \\implies \u0026amp; \\mathbf{w} = \\sum_{k=1}^{n} \\alpha_{k} y_{k} \\mathbf{x}_{k} \\\\ {{ \\partial L } \\over { \\partial b }} = 0 \\implies \u0026amp; 0 = \\sum_{k=1}^{n} \\alpha_{k} y_{k} \\end{align*} $$\nSubstituting this directly into $L$ yields $$ \\begin{align*} \u0026amp; L(\\mathbf{w},b) \\\\ =\u0026amp; {{ 1 } \\over { 2 }} \\left\\| \\mathbf{w} \\right\\|_{2}^{2} - \\sum_{k=1}^{n} \\alpha_{k} \\left[ y_{k} \\left( \\mathbf{w}^{T} \\mathbf{x}_{k} + b \\right) - 1 \\right] \\\\ =\u0026amp; {{ 1 } \\over { 2 }} \\mathbf{w}^{T} \\mathbf{w} - \\sum_{k=1}^{n} \\alpha_{k} y_{k} \\left( \\mathbf{w}^{T} \\mathbf{x}_{k} + b \\right) + \\sum_{k=1}^{n} \\alpha_{k} \\\\ =\u0026amp; {{ 1 } \\over { 2 }} \\mathbf{w}^{T} \\sum_{k=1}^{n} \\alpha_{k} y_{k} \\mathbf{x}_{k} - \\sum_{k=1}^{n} \\alpha_{k} y_{k}\\mathbf{w}^{T} \\mathbf{x}_{k} - b \\sum_{k=1}^{n} \\alpha_{k} y_{k} - \\sum_{k=1}^{n} \\alpha_{k} \\\\ =\u0026amp; - {{ 1 } \\over { 2 }} \\sum_{k=1}^{n} \\alpha_{k} y_{k} \\mathbf{w}^{T} \\mathbf{x}_{k} - b \\cdot 0 + \\sum_{k=1}^{n} \\alpha_{k} \\\\ =\u0026amp; \\sum_{k=1}^{n} \\alpha_{k} - {{ 1 } \\over { 2 }} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\alpha_{i} y_{i} a_{j} y_{j} \\mathbf{x}_{i}^{T} \\mathbf{x}_{j} \\\\ =\u0026amp; \\sum_{k=1}^{n} \\alpha_{k} - {{ 1 } \\over { 2 }} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\alpha_{i} a_{j} y_{i} y_{j} \\mathbf{x}_{i}^{T} \\mathbf{x}_{j} \\\\ =\u0026amp; L \\left( \\alpha_{1} , \\cdots , \\alpha_{n} \\right) \\end{align*} $$\nAs expected, to specifically calculate $\\mathbf{w}$ and $b$, the training data $\\left\\{ \\left( \\mathbf{x}_{k}, y_{k} \\right) \\right\\}_{k=1}^{n}$ is required.\nThe point to note here is that the inner product of $\\mathbf{x}_{i}$ and $\\mathbf{x}_{j}$ was used in the equation. Ultimately, we must perform an inner product, and if $X$ is not an inner product space, there\u0026rsquo;s no guarantee we can take this smooth path. Conversely, even if $X$ isn\u0026rsquo;t an inner product space, if the transformation $\\phi$ can send $X$ to an inner product space, considering SVM with the objective function $$ \\sum_{k=1}^{n} \\alpha_{k} - {{ 1 } \\over { 2 }} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\alpha_{i} a_{j} y_{i} y_{j} \\phi \\left( \\mathbf{x}_{i} \\right) ^{T} \\phi \\left( \\mathbf{x}_{j} \\right) $$ becomes plausible. In [Machine Learning](../../categories/Machine Learning), functions involving a transformation and inner product of two vectors $$ K \\left( \\mathbf{x}_{i}, \\mathbf{x}_{j} \\right) := \\left\u0026lt; \\phi \\left( \\mathbf{x}_{i} \\right) , \\phi \\left( \\mathbf{x}_{j} \\right) \\right\u0026gt; $$ are sometimes referred to as a Kernel. [ NOTE: Even within data science, there are other kernels that could be confused with this. The original mathematical kernel is a function with the same name but entirely different functionality. ]\nIf you can accept the content up to this point mathematically, you should understand why introducing a transformation $\\phi$, not even a kernel, is called the Kernel Trick, and why it\u0026rsquo;s important that it guarantees an inner product space afterwards.\nSeveral kernels that satisfy certain conditions can be considered, especially the original SVM can also be seen as using a Linear Kernel $$ K \\left( \\mathbf{x}_{i}, \\mathbf{x}_{j} \\right) = \\left\u0026lt; \\mathbf{x}_{i}, \\mathbf{x}_{j} \\right\u0026gt;^{1} = \\mathbf{x}_{i}^{T} \\mathbf{x}_{j} $$\nSee Also The Kernel Trick section dealt with mathematically simple content, but if you\u0026rsquo;re interested in deeper theories, go beyond SVM and study the following topics:\nKernels in Machine Learning and Reproducing Kernel Hilbert Spaces Proof of the Representation Theorem Code The following is Julia code implementing the kernel trick.\nstruct Sphere\rd::Int64\rend\rSphere(d) = Sphere(d)\rimport Base.rand\rfunction rand(Topology::Sphere, n::Int64)\rdirection = randn(Topology.d, n)\rboundary = direction ./ sqrt.(sum(abs2, direction, dims = 1))\rreturn boundary\rend\rusing Plots\rA = 0.3rand(Sphere(2), 200) + 0.1randn(2, 200)\rB = rand(Sphere(2), 200) + 0.1randn(2, 200)\rscatter(A[1,:],A[2,:], ratio = :equal, label = \u0026#34;+1\u0026#34;)\rscatter!(B[1,:],B[2,:], ratio = :equal, label = \u0026#34;-1\u0026#34;)\rpng(\u0026#34;raw.png\u0026#34;)\rPlots.plotly()\rœï(z) = z[1]^2 + z[2]^2\rscatter(A[1,:],A[2,:],œï.(eachcol(A)), ms = 1, label = \u0026#34;+1\u0026#34;)\rscatter!(B[1,:],B[2,:],œï.(eachcol(B)), ms = 1, label = \u0026#34;-1\u0026#34;)\rsavefig(\u0026#34;kernel.html\u0026#34;) Jakkula. (2006). Tutorial on Support Vector Machine (SVM). https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://ratsgo.github.io/machine%20learning/2017/05/23/SVM/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://bkshin.tistory.com/entry/Machine-Learning-2-Support-Vector-Machine-SVM\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://hleecaster.com/ml-svm-concept/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2402,"permalink":"https://freshrimpsushi.github.io/en/posts/2402/","tags":null,"title":"Support Vector Machine"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Definition 1 2 Simple Definition Let us assume a Euclidean space $\\left( \\mathbb{R}^{d} , \\left\\| \\cdot \\right\\|_{2} \\right)$ and a positive number $\\varepsilon \u0026gt; 0$ are given. For a finite set $S \\subset \\mathbb{R}^{d}$, a simplicial complex $\\text{VR}_{\\varepsilon} (S)$ that satisfies the following two conditions is called a Vietoris-Rips Complex.\n(i): It has $S$ as the set of vertices. (ii): A simplex $\\left[ v_{0} , v_{1} , \\cdots, v_{k} \\right]$ in $\\text{VR}_{\\varepsilon} (S)$ belongs to $\\text{VR}_{\\varepsilon} (S)$ if and only if for all $0 \\le i,j \\le k$, the following holds true. $$ \\left\\| v_{i} - v_{j} \\right\\|_{2} \\le 2 \\varepsilon $$ Complex Definition Given a metric space $\\left( X, d \\right)$ and a positive number $\\varepsilon \u0026gt; 0$, an abstract simplicial complex $\\text{VR}_{\\varepsilon} (S)$ defined as follows is called a Vietoris-Rips Complex. $$ \\text{VR}_{\\varepsilon} (S) := \\left\\{ \\sigma \\subset S : \\diam \\sigma \\le 2 \\varepsilon \\right\\} $$ Here, $\\diam$ denotes the Diameter, which is defined as the supremum of the distances between all points of the given set $\\sigma \\subset X$. $$ \\diam \\sigma := \\sup_{x_{1} , x_{2} \\in \\sigma} d \\left( x_{1} , x_{2} \\right) $$\nExplanation The Vietoris-Rips Complex, also commonly shortened to VR Complex or Rips Complex, can essentially be understood through its definition. Whether through the simple or complex definition, the core principle that defines a simplex\u0026rsquo;s eligibility is that all the distances between points included must be less than or equal to $2 \\varepsilon$. Visualizing this concept, one can think of vertices that are $0$-simplices at the center, with spheres of radius $\\varepsilon$. Then, based on these spheres touching one another, a $1$-simplex is formed if two vertices are connected in a $1$-simplex and further creating a $2$-simplex if three vertices connect within a $1$-simplex, which is how a VR Complex can be built.\nDifference Between Vietoris-Rips Complex and ƒåech Complex Vietoris-Rips Complex: $$\\text{VR}_{\\varepsilon} (S) := \\left\\{ \\sigma \\subset S : \\diam \\sigma \\le 2 \\varepsilon \\right\\}$$\nƒåech Complex: $$\\check{C}_{\\varepsilon} (S) := \\left\\{ \\sigma \\subset S : \\bigcap_{x \\in \\sigma} B_{d} \\left( x ; \\varepsilon \\right) \\ne \\emptyset \\right\\}$$\nThe following images compare the same dataset for the Vietoris-Rips Complex and the ƒåech Complex. The top is for $\\text{VR}_{\\varepsilon}$, and the bottom is for $\\check{C}_{\\varepsilon}$.\nThe Vietoris-Rips requires only the existence of a $k-1$-simplex as its face for including a $k$-simplex. In the example, since $1$-simplices $AB$, $BC$, and $CA$ exist, the $2$-simplex $ABC$ is included. On the contrary, the ƒåech Complex requires not only the inclusion of these faces but also that the $ABC$ itself is formed by the spheres intersecting at a single point. This means that constructing a ƒåech Complex is more stringent than constructing a Vietoris-Rips Complex, thereby leading to the following observation. $$ \\check{C}_{\\varepsilon} \\subset \\text{VR}_{\\varepsilon} $$ Furthermore, the following fact is known. $$ \\check{C}_{\\varepsilon} \\subset \\text{VR}_{\\varepsilon} \\subset \\check{C}_{2 \\varepsilon} $$ We can infer that perhaps the ƒåech Complex can contain a bit more information than the Vietoris-Rips Complex. $\\text{VR}_{\\varepsilon}$ states that as long as the given points are connected, the existence of a $k-1$-simplex is automatically confirmed. Essentially, there\u0026rsquo;s no difference between the existence of a simplex and all its faces; knowing one practically renders the other information redundant. Conversely, $\\check{C}_{\\varepsilon}$ cannot assure the existence of $ABC$ solely based on the existence of $AB$, $BC$, and $CA$, necessitating an additional verification. It can thus be expected that the ƒåech Complex examines data details more intricately than the Vietoris-Rips Complex.\nHowever, from the perspective of actual computation, constructing a Vietoris-Rips Complex is significantly cost-effective. Indeed, unlike $\\text{VR}_{\\varepsilon}$, which simply calculates the distance between fixed points, $\\check{C}_{\\varepsilon}$ not only lacks information on where the spheres intersect but also cannot determine if their intersection is shorter or longer than $\\varepsilon$. Overcoming this and constructing a ƒåech Complex might involve finding the smallest enclosing disk using techniques such as the Welzl\u0026rsquo;s algorithm, but each calculation is relatively expensive and must be repeated for all possible combinations of points.\nRaul Rabadan. (2020). Topological Data Analysis for Genomics and Evolution: p126.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEdelsbrunner, Harer. (2010). Computational Topology An Introduction: p74.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2401,"permalink":"https://freshrimpsushi.github.io/en/posts/2401/","tags":null,"title":"Definition of Vietoris-Rips Complex"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Overview Without considering the geometric meaning, if we just define it plainly, in Algebraic Topology, the Betti Number is merely the rank of the homology group in a chain complex. The problem is that such an explanation does not help those curious about the meaning of Betti numbers, and it\u0026rsquo;s also difficult to learn through examples because the specific calculation is daunting.\nIn this post, we introduce a theorem that answers at least the second question‚Äîhow to calculate Betti numbers‚Äîwith its detailed proof. According to the theorem introduced below, a certain matrix can be found according to the given chain complex, and through a series of calculations, the following explicit formula can be derived. $$ \\beta_{p} = \\rank ?_{1} - \\rank ?_{2} $$\nAlthough the best explanation for mathematical content is to convey it without using mathematics, in the case of Betti numbers, one can realize its fundamental principles through the process of deriving the formula. The proof may be quite difficult for undergraduates to follow, but it is written in detail without omissions, so it is recommended to at least give it a try.\nTheorem Definition of Homology Group:\nLet\u0026rsquo;s say $n \\in \\mathbb{N}_{0}$. Chain $$ \\cdots \\longrightarrow C_{n+1} \\overset{\\partial_{n+1}}{\\longrightarrow} C_{n} \\overset{\\partial_{n}}{\\longrightarrow} C_{n-1} \\longrightarrow \\cdots \\longrightarrow C_{1} \\overset{\\partial_{1}}{\\longrightarrow} C_{0} \\overset{\\partial_{0}}{\\longrightarrow} 0 $$ If it satisfies $$ \\partial_{n} \\circ \\partial_{n+1} = 0 $$ for all $n$, then $\\mathcal{C} := \\left\\{ \\left( C_{n}, \\partial_{n} \\right) \\right\\}_{n=0}^{\\infty}$ is called a Chain Complex. The Quotient Group $H_{n} := \\ker \\partial_{n} / \\text{Im} \\partial_{n+1}$ is called the $n$-th Homology Group of $\\mathcal{C}$. Homomorphism $\\partial_{n} : C_{n} \\longrightarrow C_{n-1}$ is called a Boundary or Differential Operator. Elements of $Z_{n} := \\ker \\partial_{n}$ are called $n$-Cycles, and elements of $B_{n} := \\text{Im} \\partial_{n+1}$ are called $n$-Boundaries. Standard Basis Decomposition of Free Chain Complexes Assuming that all $C_{p}$ of the Chain Complex $\\mathcal{C} := \\left\\{ \\left( C_{p}, \\partial_{p} \\right) \\right\\}$ are Free Groups with Finite Rank, there exist Subgroups $U_{p}, V_{p}, W_{p} \\subset C_{p}$ and for all $p$ and $Z_{p} := \\ker \\partial_{p}$ that satisfy the following. $$ \\begin{align*} C_{p} =\u0026amp; U_{p} \\oplus V_{p} \\oplus W_{p} \\\\ =\u0026amp; U_{p} \\oplus Z_{p} \\end{align*} $$ $$ \\begin{align*} \\partial_{p} \\left( U_{p} \\right) \\subset \u0026amp; W_{p} \\\\ Z_{p} =\u0026amp; V_{p} \\oplus W_{p} \\end{align*} $$ Of course, $Z_{p}$ is the Kernel of $\\partial_{p}$, so $\\partial_{p} \\left( V_{p} \\right) = 0$ and $\\partial_{p} \\left( W_{p} \\right) = 0$. Furthermore, the Restriction Function ${\\partial_{p}}_{| U_{p}} : U_{p} \\to W_{p-1}$ from $U_{p}$ to $\\partial_{p}$ has the following Smith Normal Form. $$ \\begin{bmatrix} b_{1} \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; \\cdots \u0026amp; b_{l} \\end{bmatrix} $$ Here, $b_{i} \\in \\mathbb{N}$ and $b_{1} \\mid \\cdots \\mid b_{l}$.\nEfficient Computability of Homology Groups 1 The Betti Number of $H_{p} \\left( \\mathcal{C} \\right)$ is called the $p$-th Betti Number of $\\mathcal{C}$. The $\\beta_{p}$ of a finite Complex $K$ is as follows. $$ \\beta_{p} = \\rank Z_{p} - \\rank B_{p} $$ Its specific values can be calculated by the Smith Normal Form of $\\partial_{p}$ as follows. In the diagram, the blue dotted line represents the diagonal components where $1$, the orange solid line represents the diagonal components where $1$ is not $0$, and all other components are $0$2.\nWhat is important here is the number $\\rank B_{p-1}$ of $1$ in the Smith Normal Form, and the number of zero columns $\\rank Z_{p}$.\nProof 3 Part 1. $B_{p} \\subset W_{p} \\subset Z_{p} \\subset C_{p}$\nLet\u0026rsquo;s say $$ \\begin{align*} Z_{p} :=\u0026amp; \\ker \\partial_{p} \\\\ B_{p} :=\u0026amp; \\text{Im} \\partial_{p+1} \\\\ W_{p} :=\u0026amp; \\left\\{ c_{p} \\in C_{p} : \\lambda c_{p} \\in B_{p} , \\forall m \\ne 0 \\right\\} \\end{align*} $$. In particular, $W_{p}$ becomes a Subgroup of $C_{p}$, and considering only $\\lambda = 1$, it weakens the condition of the Boundary $B_{p}$, so it is called a Weak Boundary.\nFrom the definition of $W_{p}$, if we consider $\\lambda \\ne 1$ $$ B_{p} \\subset W_{p} $$ From the definition of $Z_{p}$, since $\\forall z_{p} \\in Z_{p}$ is $\\partial_{p} z_{p} = 0$ and $Z_{p} = \\ker \\partial_{p}$ is $\\partial_{p} : C_{p} \\to C_{p-1}$ $$ Z_{p} \\subset C_{p} $$ Since $C_{p}$ is assumed to be a Free Group, it is Torsion-Free, meaning there does not exist $\\lambda \\ne 0$ that satisfies $\\lambda z_{p} = 0$ for any $\\forall z_{p} \\in Z_{p} \\subset C_{p}$. Meanwhile, for all $c_{p+1} \\in C_{p+1}$ $$ \\partial_{p+1} c_{p+1} = \\lambda z_{p} \\in W_{p} $$ If we apply $\\partial_{p}$ to both sides, $$ 0 = \\partial_{p} \\partial_{p+1} c_{p+1} = \\partial_{p} \\lambda z_{p} = \\lambda \\partial_{p} z_{p} $$ so $\\partial_{p} z_{p} = 0$ must hold. This means if $\\lambda z_{p} \\in W_{p}$ then $\\lambda z_{p} \\in Z_{p}$, $$ W_{p} \\subset Z_{p} $$ From such considerations, we obtain the following inclusion relationships. $$ B_{p} \\subset W_{p} \\subset Z_{p} \\subset C_{p} $$\nPart 2. $W_{p} \\subset Z_{p}$ is a Direct Summand of $Z_{p}$\nFrom the definition of the $p$-th Homology Group $H_{p} \\left( \\mathcal{C} \\right) = Z_{p} / B_{p}$ $$ \\text{proj}_{1} : Z_{p} \\to H_{p} \\left( \\mathcal{C} \\right) $$ is a Projection with a rank reduced by as much as the Coset $B_{p}$, and For the Torsion Subgroup $T_{p} \\left( \\mathcal{C} \\right) \\subset H_{p} \\left( \\mathcal{C} \\right)$ of $H_{p} \\left( \\mathcal{C} \\right)$ $$ \\text{proj}_{2} : H_{p} \\left( \\mathcal{C} \\right) \\to H_{p} \\left( \\mathcal{C} \\right) / T_{p} \\left( \\mathcal{C} \\right) $$ is also a projection. First Isomorphism Theorem: If a Homomorphism $\\phi : G \\to G'$ exists, then $$G / \\ker ( \\phi ) \\simeq \\phi (G)$$\nTherefore, defined as $\\text{proj} := \\text{proj}_{1} \\circ \\text{proj}_{2}$ $$ \\text{proj} : Z_{p} \\to H_{p} \\left( \\mathcal{C} \\right) / T_{p} \\left( \\mathcal{C} \\right) $$ is also a projection. Elements of $W_{p}$ are expressed as $\\partial_{p+1} d_{p+1}$, so the kernel of this projection $\\text{proj}$ is $W_{p}$, and since every projection is a Surjection, according to the First Isomorphism Theorem, $$ Z_{p} / W_{p} \\simeq H_{p} / T_{p} $$ holds. Here, regardless of how the right side of $H_{p}$ is formed, it\u0026rsquo;s reduced by the Torsion Subgroup $T_{p}$, so it\u0026rsquo;s torsion-free, thereby ensuring that the left side $Z_{p} / W_{p}$ is also torsion-free. Therefore, if $\\alpha_{1} , \\cdots , \\alpha_{k}$ is the basis of $Z_{p} / W_{p}$, and $\\alpha'_{1} , \\cdots , \\alpha'_{l} \\in W_{p}$ is the basis of $W_{p}$, then $\\alpha_{1} , \\cdots , \\alpha_{k}, \\alpha'_{1} , \\cdots , \\alpha'_{l}$ becomes the basis of $Z_{p}$. Thus, $Z_{p}$ can be expressed as a direct sum of the Subgroup $V_{p}$ with the basis $\\alpha_{1} , \\cdots , \\alpha_{k}$ and $W_{p}$.\nPart 3. Basis of $Z_{p}, B_{p-1}, W_{p-1}$\nHomomorphism\u0026rsquo;s Smith Normal Form: If the ranks of free Abelian groups $G$ and $G'$ are $n,m$ and $f : G \\to G'$, respectively, and $g$ is a homomorphism, then there exists a homomorphism $g$ with the following matrix. $$ \\begin{bmatrix} d_{1} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\ddots \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; d_{r} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\end{bmatrix} \\in \\mathbb{Z}^{m \\times n} $$ Here, $d_{1} , \\cdots, d_{r} \\in \\mathbb{N}$ and $d_{1} \\mid \\cdots \\mid d_{r}$, meaning $d_{k}$ must be a divisor of $d_{k+1}$.\n$\\partial_{p} : C_{p} \\to C_{p-1}$ has the following Smith Normal Form of the matrix $m \\times n$.\n$$ \\begin{matrix} \u0026amp; \\begin{matrix} e_{1} \u0026amp; \\cdots \u0026amp; e_{l} \u0026amp; e_{l} \u0026amp; \\cdots \u0026amp; e_{n} \\end{matrix} \\\\ \\begin{matrix} e'_{1} \\\\ \\vdots \\\\ e'_{l} \\\\ e'_{l} \\\\ \\vdots \\\\ e'_{m} \\end{matrix} \u0026amp; \\begin{bmatrix} d_{1} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\ddots \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; d_{r} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\end{bmatrix} \\end{matrix} $$\nHere, we will directly show the following three things:\n(1): $e_{l+1} , \\cdots , e_{n}$ is the basis of $Z_{p}$. (2): $b_{1} e'_{1} , \\cdots , b_{l} e'_{l}$ is the basis of $B_{p-1}$. (3): $e'_{1} , \\cdots , e'_{l}$ is the basis of $W_{p-1}$. Sub-proof\nAccording to the definition of $\\partial_{p}$, for a general $c_{p} \\in C_{p}$, the following holds. $$ c_{p} = \\sum_{i=1}^{n} a_{i} e_{i} \\implies \\partial_{p} c_{p} = \\sum_{i=1}^{l} a_{i} b_{i} e'_{i} $$ (1): Since $b_{i} \\ne 0$, the necessary and sufficient condition for $Z_{p} = \\ker \\partial_{p}$ is for $a_{i} = 0$ for any $i = 1 \\cdots , l$. Therefore, $e_{l+1} , \\cdots , e_{n}$ is the basis of $Z_{p}$. (2): Every $\\partial_{p} c_{p} \\in B_{p-1}$ can be expressed as a Linear Combination of $b_{1} e'_{1} , \\cdots , b_{l} e'_{l}$, and since $b_{i} \\ne 0$, $b_{1} e'_{1} , \\cdots , b_{l} e'_{l}$ is the basis of $B_{p-1}$. (3): Since $b_{i} e'_{i} = \\partial e_{i}$, first of all, $e'_{1}, \\cdots, e'_{l} \\in W_{p-1}$. Conversely, if we set $c_{p-1} \\in C_{p-1}$ as $$ c_{p-1} = \\sum_{i=1}^{m} d_{i} e'_{i} $$ and assume $c_{p-1} \\in W_{p-1}$, then since $W_{p-1}$ was defined as $W_{p-1} = \\left\\{ c_{p} \\in C_{p} : \\lambda c_{p} \\in B_{p} , \\forall m \\ne 0 \\right\\}$, $c_{p-1}$ can be expressed in the form of $$ \\lambda c_{p-1} = \\partial c_{p} = \\sum_{i=1}^{l} a_{i} b_{i} e'_{i} $$ for some $\\lambda \\ne 0$. Comparing coefficients, for $i \u0026gt; l$, we obtain $$ \\lambda d_{i} = 0 \\implies d_{i} = 0 $$ Therefore, $e'_{1} , \\cdots , e'_{l}$ is the basis of $W_{p-1}$. Part 4. Proof of \u0026lsquo;Standard Basis Decomposition of Free Chain Complexes\u0026rsquo;\nFor $C_{p}$ and $C_{p-1}$, if we consider the Free Group generated by $e_{1} , \\cdots , e_{l}$ appearing in the discussion so far as $U_{p}$, then since $Z_{p} = V_{p} \\oplus W_{p}$, we obtain $$ \\begin{align*} C_{p} =\u0026amp; U_{p} \\oplus Z_{p} \\\\ =\u0026amp; U_{p} \\oplus \\left( V_{p} \\oplus W_{p} \\right) \\end{align*} $$ as $\\partial V_{p} = \\partial W_{p} = 0$. Here, note that $W_{p}$ and $Z_{p}$ are unique according to $C_{p}$, but $U_{p}$ and $V_{p}$ do not necessarily have to be unique.\nPart 5. Proof of \u0026lsquo;Efficient Computability of Homology Groups\u0026rsquo;\nAccording to Part 4, for the Complex $K$, the following decomposition is guaranteed to exist. $$ \\begin{align*} C_{p} \\left( K \\right) =\u0026amp; U_{p} \\oplus V_{p} \\oplus W_{p} \\\\ Z_{p} =\u0026amp; V_{p} \\oplus W_{p} \\end{align*} $$\nProperties of Direct Sum: Let\u0026rsquo;s say $G = G_{1} \\oplus G_{2}$. If $H_{1}$ is a subgroup of $G_{1}$ and $H_{2}$ is a subgroup of $G_{2}$, then $H_{1}$ and $H_{2}$ can also be expressed as a direct sum, especially the following holds. $${{ G } \\over { H_{1} \\oplus H_{2} }} \\simeq {{ G_{1} } \\over { H_{1} }} \\oplus {{ G_{2} } \\over { H_{2} }}$$\n[1]: If we say $H_{1} \\simeq G_{1}$ and $H_{2} \\simeq \\left\\{ 0 \\right\\}$, then $$ G / G_{1} \\simeq G_{2} $$ [2]: If we say $H_{1} \\simeq \\left\\{ 0 \\right\\}$, then $$ {{ G } \\over { H_{2} }} \\simeq G_{1} \\oplus {{ G_{2} } \\over { H_{2} }}$$ Since it was $B_{p} \\subset W_{p} \\subset Z_{p} \\subset C_{p}$ in Part 1, according to the properties of the Direct Sum, $$ \\begin{align*} H_{p} \\left( K \\right) =\u0026amp; Z_{p} / B_{p} \\\\ =\u0026amp; \\left( {{ V_{p} \\oplus W_{p} } \\over { B_{p} }} \\right) \\\\ =\u0026amp; V_{p} \\oplus \\left( {{ W_{p} } \\over { B_{p} }} \\right) \u0026amp; \\because [2] \\\\ =\u0026amp; \\left( {{ Z_{p} } \\over { W_{p} }} \\right) \\oplus \\left( {{ W_{p} } \\over { B_{p} }} \\right) \u0026amp; \\because [1] \\end{align*} $$ is obtained. Here, in $H_{p} \\left( K \\right) = \\left( Z_{p} / W_{p} \\right) \\oplus \\left( W_{p} / B_{p} \\right)$,\n$Z_{p} / W_{p}$ is the Free part, and $W_{p} / B_{p}$ is the Torsion part. Therefore, the $p$-th Betti Number $\\beta_{p}$ of $K$ is calculated as follows. $$ \\begin{align*} \\beta_{p} =\u0026amp; \\rank H_{p} \\left( K \\right) \\\\ =\u0026amp; \\rank \\left[ \\left( Z_{p} / W_{p} \\right) \\oplus \\left( W_{p} / B_{p} \\right) \\right] \\\\ =\u0026amp; \\rank \\left( Z_{p} / W_{p} \\right) + \\rank \\left( W_{p} / B_{p} \\right) \\\\ =\u0026amp; \\left[ \\rank Z_{p} - \\rank W_{p} \\right] + \\left[ \\rank W_{p} - \\rank B_{p} \\right] \\\\ =\u0026amp; \\rank Z_{p} - \\rank B_{p} \\end{align*} $$\nMeanwhile, for the torsion part of $H_{p-1}(K)$ and $b_{1} | \\cdots | b_{l} \\in \\mathbb{N}$, the following Isomorphism can be known to exist. $$ W_{p-1} / B_{p-1} \\simeq \\left( {{ \\mathbb{Z} } \\over { b_{1} \\mathbb{Z} }} \\right) \\oplus \\cdots \\oplus \\left( {{ \\mathbb{Z} } \\over { b_{l} \\mathbb{Z} }} \\right) $$ Here, the fact that $b_{i} = 1$ for $i \\le l$, in other words, the rank of $B_{p-1}$ is $l$, is because $$ \\mathbb{Z} / b_{i} \\mathbb{Z} = \\mathbb{Z} / \\mathbb{Z} = \\left\\{ 0 \\right\\} $$ so the rank of $W_{p-1}$ is reduced by $l$.\n‚ñ†\nExample Torus $$ \\begin{align*} \\beta_{0} =\u0026amp; 1 \\\\ \\beta_{1} =\u0026amp; 2 \\\\ \\beta_{2} =\u0026amp; 1 \\end{align*} $$\nThe Betti numbers of a torus are known as above. Assuming the chain complex of this torus is defined as in the above figure, let\u0026rsquo;s just calculate $\\beta_{1} = 2$ as an example. There is also a way to calculate it by just mathematically pondering without using the formula derived above, but as you can read, it\u0026rsquo;s headache-inducingly difficult. In contrast, let\u0026rsquo;s see how convenient it is to \u0026rsquo;efficiently calculate homology\u0026rsquo;.\nHomomorphism\u0026rsquo;s Smith Normal Form: For Free Abelian Groups $G$ and $G'$, if $a_{1} , \\cdots , a_{n}$ is the basis of $G$, and $a_{1}' , \\cdots , a_{m}'$ is the basis of $G'$, and if the function $f : G \\to G'$ is a Homomorphism, then there exists a unique set of integers $\\left\\{ \\lambda_{ij} \\right\\} \\subset \\mathbb{Z}$ that satisfies the following. $$ f \\left( a_{j} \\right) = \\sum_{i=1}^{m} \\lambda_{ij} a_{i}' $$ Here, the matrix $\\left( \\lambda_{ij} \\right) \\in \\mathbb{Z}^{m \\times n}$ is called the Matrix of $f$ with respect to the bases of $G$ and $G'$.\nSince $\\beta_{1} = \\rank Z_{1} - \\rank B_{1}$, at least the Boundary Matrices $\\left( \\partial_{1} \\right)$ and $\\left( \\partial_{2} \\right)$ need to be found. For all $a , b, c \\in C_{1} (T)$, $$ \\begin{align*} \\partial_{1} (a) =\u0026amp; v - v = 0 = 0v \\\\ \\partial_{1} (b) =\u0026amp; v - v = 0 = 0v \\\\ \\partial_{1} (c) =\u0026amp; v - v = 0 = 0v \\end{align*} $$ is obtained. $Z_{p}$ is the number of zero vectors on the right side of the matrix, and $B_{p-1}$ is the number of $1$ in the matrix. Considering $\\partial_{2}$ next, $$ \\begin{align*} \\partial_{2} (U) =\u0026amp; -a -b +c \\\\ \\partial_{2} (L) =\u0026amp; a + b - c \\end{align*} $$ is obtained. Combining these, the $1$-th Betti Number $\\beta_{1}$ of the torus is calculated as follows. $$ \\beta_{1} = \\rank Z_{1} - \\rank B_{1} = 3 - 1 = 2 $$ Of course, this result is guaranteed to match the value obtained by using all sorts of mathematical knowledge, discussing what the Free Group is, what an Isomorphism is, and so on, according to the theorems introduced in this post. To speak a bit recklessly, one can \u0026lsquo;calculate\u0026rsquo; Betti numbers, that is, \u0026lsquo;homology\u0026rsquo;, just by following instructions without using the brain. On the other hand, to put it more positively, it opens the way to studying topology through computers.\nMunkres. (1984). Elements of Algebraic Topology: p58.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEdelsbrunner, Harer. (2010). Computational Topology An Introduction: p104.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMunkres. (1984). Elements of Algebraic Topology: p58~61.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2399,"permalink":"https://freshrimpsushi.github.io/en/posts/2399/","tags":null,"title":"Betti Number of Homology Group"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 $2$Qubit $\\ket{a, b} = \\ket{a} \\otimes \\ket{b}$ The exchange gateexchange gate $\\text{ex}$ is defined as follows.\n$$ \\begin{align*} \\text{ex} : (\\mathbb{C}^{2})^{\\otimes 2} \u0026amp;\\to (\\mathbb{C}^{2})^{\\otimes 2} \\\\ \\ket{a, b} \u0026amp;\\mapsto \\ket{b, a},\\quad \\forall a,b \\in \\left\\{ 0, 1 \\right\\} \\end{align*} $$\n$$ \\text{ex} (\\ket{a} \\otimes \\ket{b}) = \\ket{b} \\otimes \\ket{a} $$\nExplanation The exchange gate swaps the states of two qubits. The specific input and output are as follows.\n$$ \\text{ex} (\\ket{00}) = \\ket{00} \\\\[0.5em] \\text{ex} (\\ket{01}) = \\ket{10} \\\\[0.5em] \\text{ex} (\\ket{10}) = \\ket{01} \\\\[0.5em] \\text{ex} (\\ket{11}) = \\ket{11} $$\nMatrix representation is as follows.\n$$ \\text{ex} = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} $$\nKim Young-hoon \u0026amp; Heo Jae-seong, Quantum Information Theory (2020), p97\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3429,"permalink":"https://freshrimpsushi.github.io/en/posts/3429/","tags":null,"title":"Exchange Gate"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, this introduces how to schedule computations across multiple devices1. Honestly, I\u0026rsquo;m not quite sure myself.\nCode using Distributed\rip_ = []\rfor last in [160,161,162,163,164,32,33,34,35,36,43,44,45,46,47]\rpush!(ip_, join([155,230,211,last],\u0026#39;.\u0026#39;))\rend\rsort!(ip_)\rfor ip in ip_\raddprocs([(\u0026#34;chaos@\u0026#34; * ip, 8)]; dir =\u0026#34;/home/chaos\u0026#34;, exename = \u0026#34;julia\u0026#34;) #add slave node\\\u0026#39;s workers\rprintln(\u0026#34;ip $ip\u0026#34; * \u0026#34; passed\u0026#34;)\rend\rnworkers()\r@everywhere function f(n)\rreturn n^2 - n end\rA = pmap(f,1:20000)\rX = []\r@async @distributed for i in 1:200\rprint(f(i))\rpush!(X, f(i))\rend pmap works well, but @distributed does not.\nEnvironment OS: Windows julia: v1.7.0 https://thomaswiemann.com/assets/teaching/Fall2021-Econ-31720/Econ_31720_discussion_6.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2398,"permalink":"https://freshrimpsushi.github.io/en/posts/2398/","tags":null,"title":"Distributed Computing in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Julia provides a type of index that can reference multi-dimensional arrays, known as CatesianIndex1. Naturally, the naming Catesian comes from the Cartesian product, which is the product of sets.\nCode julia\u0026gt; M = rand(0:9, 4,4)\r4√ó4 Matrix{Int64}:\r9 3 7 0\r8 6 2 1\r3 8 4 9\r5 6 8 2 For example, let\u0026rsquo;s assume you want to access the element 9, which is in the 3rd row and 4th column of the matrix M.\njulia\u0026gt; pt = (3,4)\r(3, 4)\rjulia\u0026gt; M[pt]\rERROR: LoadError: ArgumentError: invalid index: (3, 4) of type Tuple{Int64, Int64}\rjulia\u0026gt; M[pt[1],pt[2]]\r9 Intuitively, it seems like you could simply use the tuple pt = (3,4), but people familiar with programming will recognize that this method has its flaws. Typically, when referencing a two-dimensional array, especially a matrix, you need to explicitly separate the two integers like pt[1],pt[2].\njulia\u0026gt; pt = CartesianIndex(3,4)\rCartesianIndex(3, 4)\rjulia\u0026gt; M[pt]\r9 Thankfully, Julia provides the CatesianIndex, which allows you to pass the index as a whole. By converting the tuple directly into a CatesianIndex, you get the desired result.\nFull Code M = rand(0:9, 4,4)\rpt = (3,4)\rM[pt]\rM[pt[1],pt[2]]\rpt = CartesianIndex(3,4)\rM[pt] Environment OS: Windows julia: v1.7.0 https://docs.julialang.org/en/v1/base/arrays/#Base.IteratorsMD.CartesianIndex\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2394,"permalink":"https://freshrimpsushi.github.io/en/posts/2394/","tags":null,"title":"Julia's Multidimensional Indices"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 For $n \\in \\mathbb{N}$, we call the following [unitary operator] $G$ a quantum gate or a $n$qubit gate.\n$$ G : \\left( \\mathbb{C}^{2} \\right)^{\\otimes n} \\to \\left( \\mathbb{C}^{2} \\right)^{\\otimes n} $$\nThe composition of quantum gates is called a quantum circuit. Here, $\\otimes$ is the tensor product of vector spaces.\nExplanation This is the quantum computer\u0026rsquo;s definition of gates and circuits as seen in classical computers. Since unitary operators are reversible, it is always possible to compute the inputs from the outputs in a quantum computer made up of quantum circuits.\nTypes Pauli gates Hadamard gate $H$ Phase gate $R_{\\theta}$ ÍπÄÏòÅÌõà¬∑ÌóàÏû¨ÏÑ±, ÏñëÏûê Ï†ïÎ≥¥ Ïù¥Î°† (2020), p93-96\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3424,"permalink":"https://freshrimpsushi.github.io/en/posts/3424/","tags":null,"title":"Quantum Gates and Quantum Circuits"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 $\\mathbb{C}$ Let\u0026rsquo;s denote the two unit vectors in the vector space $\\mathbb{C}^{2}$, $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$, and $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$ using Dirac notation as follows.\n$$ \\ket{0} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\qquad \\ket{1} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} $$\nThe element of the set $\\left\\{ \\ket{0}, \\ket{1} \\right\\}$ is called qubit.\n$\\mathbb{C}^{2}$\u0026rsquo;s $n$tensor product $\\left( \\mathbb{C}^{2} \\right)^{\\otimes n} = \\overbrace{\\mathbb{C}^{2} \\otimes \\cdots \\otimes \\mathbb{C}^{2}}^{n}$ standard basis\n$$ \\left\\{ \\ket{0} \\otimes \\cdots \\otimes \\ket{0}, \\dots, \\ket{1} \\otimes \\cdots \\otimes \\ket{1} \\right\\}$$\nis called $n$qubit.\nDescription A qubit is short for quantum bit. While a bit is the minimum unit of information processing in a classical computer, a qubit performs that role in a quantum computer.\nThe $n$qubit is simply denoted as follows. If $a = (a_{0}, a_{1}, \\dots, a_{n-1}) \\in \\left\\{ 0, 1 \\right\\}^{n}$ is called a $n$bit,\n$$ \\begin{align*} \\ket{a} \u0026amp;= \\ket{a_{0}, a_{1}, \\dots, a_{n-1}} \\\\ \u0026amp;= \\ket{a_{0} a_{1} \\dots a_{n-1}} \\\\ \u0026amp;= \\ket{a_{0}} \\otimes \\ket{a_{1}} \\otimes \\cdots \\otimes \\ket{a_{n-1}} \\end{align*} $$\nExample: $(\\mathbb{C}^{2}) ^{\\otimes 2}$ Let\u0026rsquo;s look at the simplest example, where $(\\mathbb{C}^{2}) ^{\\otimes 2} = \\mathbb{C}^{2} \\otimes \\mathbb{C}^{2} \\cong \\mathbb{C}^{4}$. The $2$qubit is denoted as follows.\n$$ \\ket{00} = \\ket{0,0} = \\ket{0} \\otimes \\ket{0},\\qquad \\ket{01} = \\ket{0,1} = \\ket{0} \\otimes \\ket{1} \\\\ \\ket{10} = \\ket{1,0} = \\ket{1} \\otimes \\ket{0},\\qquad \\ket{11} = \\ket{1,1} = \\ket{1} \\otimes \\ket{1} $$\nIf each of the $2$qubits is represented as a matrix, according to the definition of Kronecker product, it is as follows.\n$$ \\begin{align*} \\ket{00} \u0026amp;= \\ket{0} \\otimes \\ket{0} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\otimes \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\\\[1em] 0 \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix} \\\\ \\ket{01} \u0026amp;= \\ket{0} \\otimes \\ket{1} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\otimes \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\\\[1em] 0 \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix} \\\\ \\ket{10} \u0026amp;= \\ket{1} \\otimes \\ket{0} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\otimes \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\\\[1em] 1 \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{bmatrix} \\\\ \\ket{11} \u0026amp;= \\ket{1} \\otimes \\ket{1} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\otimes \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\\\[1em] 1 \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\end{align*} $$\nTherefore, $\\braket{ik | jl} = \\delta_{ij}\\delta_{kl}$. Here, $\\delta$ is the Kronecker delta. Any element of $(\\mathbb{C}^{2}) ^{\\otimes 2}$ is as follows.\n$$ \\begin{align*} \u0026amp; (\\alpha_{0}\\ket{0} + \\alpha_{1}\\ket{1}) \\otimes (\\beta_{0}\\ket{0} + \\beta_{1}\\ket{1})\\\\ \u0026amp;= \\alpha_{0}\\beta_{0} \\ket{0} \\otimes \\ket{0} + \\alpha_{0}\\beta_{1} \\ket{0} \\otimes \\ket{1} + \\alpha_{1}\\beta_{0} \\ket{1} \\otimes \\ket{0} + \\alpha_{1}\\beta_{1} \\ket{1} \\otimes \\ket{1} \\\\ \u0026amp;= \\alpha_{0}\\beta_{0} \\ket{00} + \\alpha_{0}\\beta_{1} \\ket{01} + \\alpha_{1}\\beta_{0} \\ket{10} + \\alpha_{1}\\beta_{1} \\ket{11} \\\\ \u0026amp;= \\alpha_{00}\\ket{00} + \\alpha_{01}\\ket{01} + \\alpha_{10}\\ket{10} + \\alpha_{11}\\ket{11} \\\\ \\end{align*} $$\nIn particular, if $\\left\\{ \\ket{a} \\right\\}_{a \\in \\left\\{ 0, 1 \\right\\}^{2}}$ is called the basis of $(\\mathbb{C}^{2}) ^{\\otimes 2}$, for any $\\ket{\\psi} \\in (\\mathbb{C}^{2}) ^{\\otimes 2}$,\n$$ \\ket{\\psi} = \\sum\\limits_{a \\in \\left\\{ 0, 1 \\right\\}^{2}} \\braket{a | \\psi} \\ket {a} = \\sum\\limits_{a \\in \\left\\{ 0, 1 \\right\\}^{2}} \\psi_{a} \\ket {a} $$\nThe inner product of $\\ket{\\psi}, \\ket{\\xi} \\in (\\mathbb{C}^{2}) ^{\\otimes 2}$ is,\n$$ \\braket{\\psi | \\xi} = \\sum\\limits_{a \\in \\left\\{ 0, 1 \\right\\}^{2}} \\overline{\\psi_{a}} \\xi_{a} $$\nHere, $\\overline{\\psi_{a}}$ is the conjugate complex of $\\psi_{a}$.\nSee Also Bit Quantum Gate Kim Young-Hoon \u0026amp; Heo Jae-Seong, Quantum Information Theory (2020), p93-95\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3423,"permalink":"https://freshrimpsushi.github.io/en/posts/3423/","tags":null,"title":"Qubits: The Basic Unit of Information in Quantum Computers"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, \u0026amp;\u0026amp; and || not only perform logical AND and OR operations but also execute short-circuit evaluation1. For instance, A \u0026amp;\u0026amp; B returns true only if both A and B are true, but in reality, if A is false, there is no need to check whether B is true or false; A \u0026amp;\u0026amp; B is false. Short-circuit evaluation essentially skips checking B. Skipping the calculation for B can lead to performance improvements in some cases.\nSee Also How to write conditional statements succinctly Speed Comparison M = rand(0:2, 10^4, 10^4);\rprint(first(M))\r@time if first(M) == 2 \u0026amp;\u0026amp; sum(M) \u0026lt; 1000\rprint(\u0026#34;!!\u0026#34;)\rend\r@time if sum(M) \u0026lt; 1000 \u0026amp;\u0026amp; first(M) == 2\rprint(\u0026#34;!!\u0026#34;)\rend The only difference between the two conditionals is the order of sum(M) \u0026lt; 1000 and first(M) == 2, yet they perform exactly the same task. However, since first(M) == 2 merely checks if the first element of matrix M is 2, and sum(M) sums up all elements, traversing through them, the latter relatively takes longer to compute.\njulia\u0026gt; M = rand(0:2, 10^4, 10^4);\rjulia\u0026gt; print(first(M))\r0 If the first element of M is 0 as shown above, there is no need to calculate sum(M) to see if sum(M) \u0026lt; 1000. The speeds can vary significantly just by changing the order.\njulia\u0026gt; @time if first(M) == 2 \u0026amp;\u0026amp; sum(M) \u0026lt; 1000\rprint(\u0026#34;!!\u0026#34;)\rend\r0.000009 seconds\rjulia\u0026gt; @time if sum(M) \u0026lt; 1000 \u0026amp;\u0026amp; first(M) == 2\rprint(\u0026#34;!!\u0026#34;)\rend\r0.040485 seconds (1 allocation: 16 bytes) Environment OS: Windows julia: v1.7.0 https://docs.julialang.org/en/v1/manual/control-flow/#Short-Circuit-Evaluation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2392,"permalink":"https://freshrimpsushi.github.io/en/posts/2392/","tags":null,"title":"Julia's Short Circuit"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition An element of the set $\\left\\{ 0, 1 \\right\\}$ is called a bitbit. An element of the set $\\left\\{ 0, 1 \\right\\}^{n}$ is called a $n$bit$n$bit.\nDescription The term bit is an abbreviation for binary digit. It is commonly described as \u0026ldquo;something that can have the value of either $0$ or $1$.\u0026rdquo; It is the smallest unit of information that a classical computer processes. In computer circuits, $1$ signifies the presence of an electrical signal, while $0$ signifies the absence of an electrical signal.\nThe smallest unit of information processed by a quantum computer is called a quantum bitqubit, adding quantum to bit.\nSee Also Boolean function Qubit ","id":3422,"permalink":"https://freshrimpsushi.github.io/en/posts/3422/","tags":null,"title":"Bit: Unit of Information Classical Computer"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Julia\u0026rsquo;s basic built-in functions are increasingly useful the more you know them. Without further ado, let\u0026rsquo;s learn through examples.\nCode x = [3, 7, 4, 5, 10, 3, 12, 3, 2, 4]\rargmin(x)\rargmax(x)\rfindmin(x)\rfindmax(x)\rextrema(x)\rfindfirst(x .== 3)\rfindlast(x .== 3)\rfindall(x .== 3)\rfindnext(x .== 3, 5)\rfindprev(x .== 3, 5) Optimal solutions argmin(),argmax(),findmin(),findmax(),extrema() Finding the optimal solutions.\nx = [3, 7, 4, 5, 10, 3, 12, 3, 2, 4]\rjulia\u0026gt; argmin(x)\r9\rjulia\u0026gt; argmax(x)\r7\ry = [7, 8, 9, 9, 7, 9]\rjulia\u0026gt; argmax(y)\r3\rjulia\u0026gt; findall(y.==maximum(y))\r3-element Vector{Int64}:\r3\r4\r6 argmin(),argmax() simply return the index of the optimal solution, i.e., the index where the value is the largest or smallest. If there are multiple indices, it returns the smallest one. So, in fact, argmax(x) $= \\min(\\argmax(x))$. The real $\\argmax$ is done using maximum() along with the findall() function.\nx = [3, 7, 4, 5, 10, 3, 12, 3, 2, 4]\rjulia\u0026gt; findmin(x)\r(2, 9)\rjulia\u0026gt; findmax(x)\r(12, 7) findmin(),findmax() return the optimal solution along with its value.\nx = [3, 7, 4, 5, 10, 3, 12, 3, 2, 4]\rjulia\u0026gt; extrema(x)\r(2, 12) Note that extrema() returns not the indices but only the values. This is similar to the range() function in R1.\nFirst/Last index meeting a condition findfirst(), findlast() x = [3, 7, 4, 5, 10, 3, 12, 3, 2, 4]\rjulia\u0026gt; findfirst(x .== 3)\r1\rjulia\u0026gt; findlast(x .== 3)\r8 Found the first and last index where 3 is located. If the shape of the array can be roughly anticipated, these can be used to improve the speed of the code.\nAll indices that meet a condition findall() x = [3, 7, 4, 5, 10, 3, 12, 3, 2, 4]\rjulia\u0026gt; findall(x .== 3)\r3-element Vector{Int64}:\r1\r6\r8 This is the most convenient to use and the most useful function in general programming. Used with maximum(), minimum(), it finds all $\\text{argmin}\nSpecific range of indices meeting a condition findnext(), findprev() julia\u0026gt; findnext(x .== 3, 5)\r6\rjulia\u0026gt; findprev(x .== 3, 5)\r1 Sometimes, we may need to search beyond exceptions. For instance, using findall() to find an element identical to the first element of an array would also find that first element itself, which could be cumbersome.\nEnvironment OS: Windows julia: v1.7.0 https://docs.julialang.org/en/v1/base/collections/#Base.extrema\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2390,"permalink":"https://freshrimpsushi.github.io/en/posts/2390/","tags":null,"title":"Julia's find functions"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Algorithm $R$ is a principal ideal domain, for every matrix $A \\in R^{m \\times n}$, there exists a unique Smith normal form. In other words, for the matrix $A \\in R^{m \\times n}$, there exists $d_{1} , \\cdots , d_{r} \\in R$ and invertible matrices $P \\in R^{m \\times m}$, $Q \\in R^{n \\times n}$ that satisfy $$ PAQ = \\begin{bmatrix} d_{1} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\ddots \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; d_{r} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\end{bmatrix} \\in R^{m \\times n} $$ where $d_{1} , \\cdots , d_{r}$ should not be $0$ in $R$, and must be $d_{1} \\mid \\cdots \\mid d_{r}$. More specifically, $d_{k} \\ne 0$ must be a divisor of $d_{k+1}$. The uniqueness ignores the unit multiples of $d_{k}$.\nProof 1 2 Strategy: An algorithm that uses row and column exchanges and Gaussian elimination to directly find the Smith normal form and prove its existence.\nEvery principal ideal domain is a unique factorization domain.\nMatrix $A$, being a matrix over a PID, is also a matrix over a UFD. Therefore, all elements except for the units and $0$, represented by $A_{ij}$, have a unique factorization, and the one with the least number of factors is called the Minimal Entry, denoted by $\\alpha \u0026gt; 0$.\nIt should be noted that in Munkres\u0026rsquo; textbook, the smallest element is chosen as $\\mathbb{Z}^{m \\times n}$, but in general principal ideal domains, which are not necessarily Euclidean domains, it can be tricky to consider something as \u0026lsquo;smallest\u0026rsquo;. In the general case of a PID, it makes sense to think about factorization to determine the minimal entry neatly. However, for simplicity, this post might use terms like \u0026lsquo;small\u0026rsquo; or $a \u0026lt; b$, which should be understood in terms of comparing the number of factors rather than the size of the elements.\nKeep in mind that the given matrix will continually change due to Gaussian elimination, so $\\alpha$ also continually changes in context.\nIt\u0026rsquo;s also worth noting that this algorithm specifically demonstrates that the Smith normal form can always be derived for the given $A$, although it\u0026rsquo;s not necessarily efficient and $P, Q$ is unknown.\nStep 1.\nIf $A$ is a zero matrix, it is already in Smith normal form, so proceed to Step 4. If $A$ is not a zero matrix, then do the following.\nFor ease of understanding, first swap rows and columns to bring $\\alpha$ to the top-left corner as $(1,1)$. Now, we will only focus near the first row and column of the given matrix. $$ A \\sim \\begin{bmatrix} \\alpha \u0026amp; A_{12} \u0026amp; \\cdots \u0026amp; \\\\ A_{21} \u0026amp; A_{22} \u0026amp; \\cdots \u0026amp; \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\end{bmatrix} $$\nStep 2. $k= 1, \\cdots , r$\n(Obviously, $r$ is unknown during the calculation. It naturally gets determined after the program ends.)\nFor all $i, j$, if $\\alpha \\mid A_{ij}$ then substitute $d_{k} \\gets \\alpha$. As $\\alpha \\mid A_{ij}$, it\u0026rsquo;s possible to repeat Gaussian elimination until all elements in the first row and column of $A$, except for $\\alpha$, become $0$. After the repetition, delete the $1$ row and $1$ column and return to Step 1. Now, the size of the matrix $A$ becomes $(m - k) \\times (n - k)$. If for some $i, j$, $\\alpha \\nmid A_{ij}$, then move to Step 3. Step 3.\nFrom here on, the discussion can apply to either rows or columns, so without loss of generality, we\u0026rsquo;ll only discuss $\\alpha \\ne 0$ and $A_{12}$. Essentially, Step 2 guarantees that for at least one of $i, j$, $\\alpha \\nmid A_{ij}$ is true, and the goal is to perform Case 1 below after making sure that $A_{ij}$ comes under $(1,2)$.\nEvery principal ideal domain is a Bezout domain: PID is a Bezout domain, so the extended Euclidean theorem applies. This means, for all $a, b \\in D$, there exists $m,n \\in D$ that satisfies $$ m a + n b = \\gcd \\left( a, b \\right) $$\nCase 1. If $\\alpha \\nmid A_{12}$\n$\\alpha$ is the minimal entry and since $\\alpha \\nmid A_{12}$, then $\\gcd \\left( \\alpha, A_{12} \\right) \u0026lt; \\alpha$. According to the extended Euclidean theorem, $$ m \\alpha + n A_{12} $$ there exists $m,n \\in D$ that makes $\\alpha$ smaller. By Gaussian elimination, add the column of $1$ multiplied by $m$ to the column of $2$ multiplied by $n$, and substitute it into the column of $2$. This new column\u0026rsquo;s first element, $A_{12}' = \\gcd \\left( \\alpha , A_{12} \\right)$, is not only smaller than the original $\\alpha$ but also a divisor of $\\alpha$, making it a candidate for a newer and smaller minimal entry. Swap the $1$ column and $2$ column and return to Step 1. (There might be a chance to find an even smaller minimal entry during the calculation.) Case 2. If $\\alpha \\mid A_{12}$\nSome $k \\in \\mathbb{Z}$ exists that satisfies $k \\alpha + A_{12} = 0$, so multiply $1$ column by $k$ and subtract it from the column of $2$. Then, this new column\u0026rsquo;s first element, $A_{12} ' $, becomes $0$. Repeat Step 3. Case 3. If $A_{12} = 0$\nRepeat the column exchange until $A_{12} \\ne 0$. If for all $j \\ne 1$, every $A_{1j}$ becomes $0$, then conduct Step 3 for $A_{21}$. If $\\alpha \\nmid A_{21}$, then $A_{21}' \u0026lt; \\alpha$. Update the minimal entry. If $\\alpha \\mid A_{21}$, make $A_{21} ' $ become $0$. If $A_{21} = 0$, it means the matrix now looks like this: $$ A \\sim \\begin{bmatrix} \\alpha \u0026amp; 0 \u0026amp; \\cdots \u0026amp; \\\\ 0 \u0026amp; A_{22} \u0026amp; \\cdots \u0026amp; \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\end{bmatrix} $$ Since $A_{21} = 0$, adding the row of $2$ to the row of $1$ keeps $\\alpha$ and results in the form $$ A \\sim \\begin{bmatrix} \\alpha \u0026amp; A_{22} \u0026amp; \\cdots \u0026amp; \\\\ 0 \u0026amp; A_{22} \u0026amp; \\cdots \u0026amp; \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\end{bmatrix} $$ Swap the $i$ row and the $2$ row and repeat Step 3. Even if all elements in the $1$ row and column except for $\\alpha$ are $0$, there still must be at least one pair of $i,j \\ge 2$ that satisfies $\\alpha \\nmid A_{ij}$, so Case 3 is repeated until eventually, $\\alpha \\nmid A_{12}$ must be true. Case 1 allows the value of $A_{11}$ to be continually reduced, Case 2 allows for making all elements other than $\\alpha$ in the first row and column become $0$, and Case 3 ensures that there will eventually be a $A_{ij}$ that satisfies $\\alpha \\nmid A_{ij}$ and is placed at $(1,2)$.\nStep 4. $d_{1} \\mid \\cdots \\mid d_{r}$\nThe only way to proceed to Step 4 is if the remaining $A$ from Step 1 is a zero matrix.\nThroughout Step 2, we\u0026rsquo;ve been noting $d_{k}$ like $d_{k} \\gets \\alpha$. That all $A_{ij}$ could be divided by the minimal entry $\\alpha$ indicates that any element created in the remaining matrix by the extended Euclidean theorem can be divided by this $\\alpha$. Therefore, $d_{1} \\mid \\cdots \\mid d_{r}$, and we obtain the following Smith normal form. $$ \\begin{bmatrix} d_{1} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\ddots \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; d_{r} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\end{bmatrix} \\in R^{m \\times n} $$ ‚ñ†\nMunkres. (1984). Elements of Algebraic Topology: p55~57.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/Smith_normal_form#Algorithm\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2389,"permalink":"https://freshrimpsushi.github.io/en/posts/2389/","tags":null,"title":"Proof of the Existence of Smith Normal Form"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview 1 In Julia, appending an exclamation mark ! at the very end of a function name is referred to as the bang convention. Such functions are characterized by modifying the arguments they are given.\nCode function add_1!(x)\rx .+= 1\rreturn x\rend\rfoo = [2,5,-1]\radd_1!(foo)\rfoo For example, executing the code above yields the following result.\njulia\u0026gt; foo = [2,5,-1]\r3-element Vector{Int64}:\r2\r5\r-1\rjulia\u0026gt; add_1!(foo)\r3-element Vector{Int64}:\r3\r6\r0\rjulia\u0026gt; foo\r3-element Vector{Int64}:\r3\r6\r0 The array foo was defined outside the function and was not only returned with each element increased by $1$ through add_1!(), but the argument itself was modified.\nDescription A representative method, pop!(), deletes the last element of an array while also returning it. If this function couldn\u0026rsquo;t modify the original array, users familiar with general programming would have found it difficult to use widely recognized data structures as is the case with Matlab or R, making it cumbersome.\nIt can be perceived similarly to how in Python, using a method instead of a function can change the data of a class. While not an exact explanation due to Julia\u0026rsquo;s design not supporting classes, it can still be conveniently used like the methods in Python when that feels more intuitive.\nEnvironment OS: Windows julia: v1.7.0 https://docs.julialang.org/en/v1/manual/style-guide/#bang-convention\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2388,"permalink":"https://freshrimpsushi.github.io/en/posts/2388/","tags":null,"title":"Julia's Exclamation Point Convention"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Problem Smallest Enclosing Disk Let\u0026rsquo;s denote it as $n \u0026gt; d$. In a $d$-dimensional Euclidean space, given a finite set $P = \\left\\{ p_{k} \\right\\}_{k=1}^{n} \\subset \\mathbb{R}^{d}$, the following optimization problem is referred to as the Smallest Enclosing Disk Problem: $$ \\begin{matrix} \\text{Minimize} \u0026amp; r \\ge 0 \\\\ \\text{subject to} \u0026amp; \\left\\| c - p_{k} \\right\\|_{2} \\le r \\end{matrix} \\\\ c \\in \\mathbb{R}^{d} , k = 1, \\cdots , n $$\nTips Here are some useful facts about this problem, though they may not be grand enough to be called theorems:\nIf $P$ are affinely independent, the disk\u0026rsquo;s boundary will contain between $2$ and $d+1$ points from $P$. Simply put, unless the points overlap or more than two lie on the same line, exactly $2 \\le m \\le d+1$ points uniquely determine the smallest enclosing disk. For example, in a $d = 2$-dimensional plane, a circle is uniquely determined by exactly three points. Generally, when $n \u0026gt; d+1$ points are given, it is believed to be impossible to find an explicit formula, not an algorithm, to solve this problem. The points that uniquely determine the smallest enclosing disk on the boundary are called supports, and it\u0026rsquo;s impossible to identify the supports just by looking at the points. The concept of points on the boundary being called supports is common in geometric problems. In Support Vector Machines, the supports refer to the points on the boundary. Therefore, developing an algorithm to solve this problem essentially means ensuring or finding a quick way to identify the boundary supports. However, the fundamental idea of the current algorithms is almost based on Welzl\u0026rsquo;s concept, and they are collectively referred to as the Welzl Algorithm1, with subsequent studies following this lineage. Solution Welzl\u0026rsquo;s Algorithm 2 Welzl\u0026rsquo;s Algorithm is a recursive solution to the smallest enclosing disk problem. It fundamentally involves adding and removing points one by one to find supports, and repeating this process to ensure the disk obtained encompasses all given points.\nWhen $n \\le d+1$ points are given, finding a disk that exactly encloses them is relatively simple, so we assume such a function exists. Though in actual implementation, this may not be as straightforward, the crux of the smallest enclosing disk problem lies elsewhere.\nPseudocode 3 $(c,r)$ = welzl$\\left( P, S \\right)$\nInput: Receives a set of given points $P = \\left\\{ p_{k} \\right\\}_{k=1}^{n} \\subset \\mathbb{R}^{d}$ and a set of candidate supporters $S \\subset P$. As mentioned in the tips, $\\left| S \\right| \\le d+1$ holds. Output: Obtains a tuple $(c,r)$ of the center $c$ and radius $r$ of the smallest disk enclosing all points of $P$. Let\u0026rsquo;s denote the closed ball with center $c$ and radius $r$ as $D = B \\left[ c,r \\right]$. $(c,r)$ = trivial$\\left( S \\right)$\nInput: Receives a set of points $S \\subset P$ where $\\left| S \\right| \\le d+1$ holds. Output: Obtains a tuple $(c,r)$ of the center $c$ and radius $r$ of the smallest disk enclosing all points of $S$. Assuming trivial is simpler than welzl, its pseudocode is not provided separately. function welzl$\\left( P, S \\right)$\n$S := \\emptyset$\nif $P = \\emptyset$ or $\\left| S \\right| = d+1$ then\nreturn trivial$\\left( S \\right)$\nelse\nchoose $p \\in P$\n$D := $ welzl$\\left( P \\setminus \\left\\{ p \\right\\}, S \\right)$\nif $p \\in D$ then\nreturn $D$\nend if\nend if\nreturn welzl$\\left( P \\setminus \\left\\{ p \\right\\} , S \\cup \\left\\{ p \\right\\} \\right)$\nend function\nwelzl is written as a recursive function, meaning the calculation begins with trivial. The appearance of choose in the pseudocode of welzl as choose $x \\in X$ indicates randomly selecting an element $x$ from the set $X$.\nIf you understand that returning welzl$\\left( P \\setminus \\left\\{ p \\right\\} , S \\cup \\left\\{ p \\right\\} \\right)$ at the end signifies the process of finding supports by sequentially removing points from $P$ and adding them to $S$, then you have essentially grasped the algorithm.\nExplanation Let\u0026rsquo;s unpack the constraints of the smallest enclosing disk. Finding $c$ and $r$ that satisfy $\\left\\| c - p_{k} \\right\\|_{2} \\le r$ means finding a center $c$ and radius $r$ that can at least enclose all given points. However, since the Euclidean space is vast, these constraints can always be met by arbitrarily choosing $r$ as long as $c$ is fixed. Naturally, our interest lies in minimizing $r$, i.e., finding the smallest ball that encloses the given points.\nThe Issue with Simplification Enclosing is not a widely used term across mathematics, but using enclosing directly in translation felt too lengthy and abstract, hence the chosen term. Initially, enclosing itself isn\u0026rsquo;t overwhelmingly more common than bounding. Moreover, the term disk is used here to mean a closed ball, but in English, terms like ball or sphere are also frequently used. Let\u0026rsquo;s not get too hung up on each word and its translation.\nHistory An early solution based on linear programming was known through Raimund Seidel.\nIn 1991, Emo Welzl proposed a recursive algorithm in his paper, setting a new standard, the so-called SOTA (State Of The Art), for the smallest enclosing disk problem. As of 2022, Welzl\u0026rsquo;s algorithm is still known to be the best for the general smallest enclosing disk problem, with many subsequent studies improving upon it.\nIn 1999, Bernd G√§rtner improved upon Welzl\u0026rsquo;s algorithm by incorporating applications of quadratic programming, making his approach more efficient.4 His implementation, written in C++, can be seen on the ETH Zurich website5.\nIn 2003, Kaspar Fischer introduced the use of the simplex method from linear programming and the Bland\u0026rsquo;s rule to write faster code,6 and in 2013, Thomas Larsson proposed a method that, while approximate, boasted speed and robustness.7\nThe research introduced thus far can be seen to follow a major lineage from Welzl to G√§rtner to Fischer upon reviewing their references.\nApplications A notable application of Welzl\u0026rsquo;s algorithm is the construction of ƒåech complexes.\nEdelsbrunner, Harer. (2010). Computational Topology An Introduction: p73~75.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWelzl. (1991). Smallest enclosing disks (balls and ellipsoids). https://doi.org/10.1007/BFb0038202\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/Smallest-circle_problem#Welzl's_algorithm\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG√§rtner. (1999). Fast and robust smallest enclosing balls. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.5783\u0026amp;rep=rep1\u0026amp;type=pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://people.inf.ethz.ch/gaertner/subdir/software/miniball.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKaspar Fischer. (2003). Fast Smallest-Enclosing-Ball Computation in High Dimensions. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.5783\u0026amp;rep=rep1\u0026amp;type=pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThomas Larsson. (2013). Fast and Robust Approximation of Smallest Enclosing Balls in Arbitrary Dimensions. https://doi.org/10.1111/cgf.12176\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2385,"permalink":"https://freshrimpsushi.github.io/en/posts/2385/","tags":null,"title":"Welzl Algorithm: Solution to Smallest Enclosing Disk Problem"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Buildup For convenience, we will develop the concept in the complex number space $\\mathbb{C}$, but $\\mathbb{R}$ or any vector space is also applicable. Let\u0026rsquo;s denote the set of functions from the finite set $\\Gamma$ to the complex number space as indicated by $\\mathbb{C}^{\\Gamma}$.\n$$ \\mathbb{C}^{\\Gamma} = \\left\\{ f : \\Gamma \\to \\mathbb{C} \\right\\} $$\nWhen $\\Gamma = \\mathbf{n} = \\left\\{ 1, \\dots, n \\right\\}$, it essentially becomes $\\mathbb{C}^{\\mathbf{n}} = \\mathbb{C}^{n}$, and the tensor product of vector spaces is defined as follows.\n$$ \\mathbb{C}^{\\Gamma_{1}} \\otimes \\mathbb{C}^{\\Gamma_{2}} := \\mathbb{C}^{\\Gamma_{1} \\times \\Gamma_{2}} $$\nAssuming $v_{i} \\in \\mathbb{C}^{\\Gamma_{i}}$ and $n_{i} = \\left| \\Gamma_{i} \\right|$, let the standard basis corresponding to $\\mathbb{C}^{\\Gamma_{i}}$ be denoted as $\\left\\{ e_{j_{i}} \\right\\}_{j_{i} \\in \\Gamma_{i}}$ respectively. Then, $v_{i}$ can be represented as follows.\n$$ \\begin{align*} v_{1} \u0026amp;: \\left\\{ 1, \\dots, n_{1} \\right\\} \\to \\mathbb{C} \u0026amp;\u0026amp;\u0026amp; v_{2} \u0026amp;: \\left\\{ 1, \\dots, n_{2} \\right\\} \\to \\mathbb{C} \\\\ v_{1} \u0026amp;= (v_{1}(1), \\dots, v_{1}(n_{1})) \\in \\mathbb{C}^{n_{1}} \u0026amp;\u0026amp;\u0026amp; v_{2} \u0026amp;= (v_{2}(1), \\dots, v_{2}(n_{2})) \\in \\mathbb{C}^{n_{2}} \\\\ \u0026amp; = \\sum \\limits_{j_{1} = 1}^{n_{1}}v_{1}(j_{1}) e_{j_{1}} \u0026amp;\u0026amp;\u0026amp;\u0026amp; = \\sum \\limits_{j_{2} = 1}^{n_{2}}v_{2}(j_{2}) e_{j_{2}} \\end{align*} $$\nThe elements of the tensor product $\\mathbb{C}^{\\Gamma_{1}} \\otimes \\mathbb{C}^{\\Gamma_{2}}$ that can be represented as $v_{1} \\otimes v_{2}$ are called the product vector of $v_{1}$ and $v_{2}$.\nDefinition The product vector $v_{1} \\otimes v_{2}$ of $v_{1}$ and $v_{2}$ is defined as follows.\n$$ \\begin{align*} v_{1} \\otimes v_{2} \u0026amp;= \\left( \\sum \\limits_{j_{1} \\in \\Gamma_{1}}v_{1}(j_{1}) e_{j_{1}} \\right) \\otimes \\left( \\sum \\limits_{j_{2} \\in \\Gamma_{2}}v_{2}(j_{2}) e_{j_{2}} \\right) \\\\ \u0026amp;:= \\sum\\limits_{(j_{1}, j_{2}) \\in \\Gamma_{1} \\times \\Gamma_{2}} \\left( \\prod\\limits_{i=1}^{2} v_{i}(j_{i}) \\right) e_{j_{1}} \\otimes e_{j_{2}} \\end{align*} $$\nIn this case, $v_{1} \\otimes v_{2}$ becomes an element of $\\mathbb{C}^{\\Gamma_{1}} \\otimes \\mathbb{C}^{\\Gamma_{2}}$ by the definition of the tensor product.\n$$ v_{1} \\otimes v_{2} := \\sum\\limits_{(j_{1}, j_{2}) \\in \\Gamma_{1} \\times \\Gamma_{2}} \\left( \\prod\\limits_{i=1}^{2} v_{i}(j_{i}) \\right) e_{j_{1}} \\otimes e_{j_{2}} \\in \\mathbb{C}^{\\Gamma_{1}} \\otimes \\mathbb{C}^{\\Gamma_{2}} $$\nExplanation Not all elements of $\\mathbb{C}^{\\Gamma_{1}} \\otimes \\mathbb{C}^{\\Gamma_{2}}$ can be represented as the product vector form of $v_{1} \\otimes v_{2}$. For example, the following vector can be expressed as the product of two vectors, but $(e_{1} \\otimes e_{1}) + (e_{2} \\otimes e_{2})$ cannot.\n$$ e_{1} \\otimes e_{1} - e_{1} \\otimes e_{2} + e_{2} \\otimes e_{1} - e_{2} \\otimes e_{2} = (e_{1} + e_{2}) \\otimes (e_{1} - e_{2}) $$\nAs a simple example, let‚Äôs further unpack the definition above. Let‚Äôs say $\\Gamma_{1} = \\left\\{ 1, 2 \\right\\}$, $\\Gamma_{2} = \\left\\{ 1, 2, 3 \\right\\}$. Assume $v_{i} \\in \\mathbb{C}^{\\Gamma_{i}}$. Let the standard basis corresponding to $\\mathbb{C}^{\\Gamma_{1}} = \\mathbb{C}^{2}$ be $\\left\\{ e_{j_{1}} \\right\\}_{j_{1} \\in \\Gamma_{1}}$, and the standard basis corresponding to $\\mathbb{C}^{\\Gamma_{2}} = \\mathbb{C}^{3}$ be $\\left\\{ e_{j_{2}} \\right\\}_{j_{2} \\in \\Gamma_{2}}$. Then, $v_{1}$, $v_{2}$ are as follows.\n$$ \\begin{align*} v_{1} \u0026amp;: \\left\\{ 1, 2 \\right\\} \\to \\mathbb{C} \u0026amp;\u0026amp;\u0026amp; v_{2} \u0026amp;: \\left\\{ 1, 2, 3 \\right\\} \\to \\mathbb{C} \\\\ v_{1} \u0026amp;= (v_{1}(1), v_{1}(2)) \\in \\mathbb{C}^{2} \u0026amp;\u0026amp;\u0026amp; v_{2} \u0026amp;= (v_{2}(1), v_{2}(2), v_{2}(3)) \\in \\mathbb{C}^{3} \\\\ \u0026amp; = \\sum \\limits_{j_{1} = 1}^{2}v_{1}(j_{1}) e_{j_{1}} \u0026amp;\u0026amp;\u0026amp;\u0026amp; = \\sum \\limits_{j_{2} = 1}^{3}v_{2}(j_{2}) e_{j_{2}} \\end{align*} $$\nThen, the product vector of $v_{1}$ and $v_{2}$ is as follows.\n$$ \\begin{align*} v_{1} \\otimes v_{2} \u0026amp;= (v_{1}(1), v_{1}(2)) \\otimes (v_{2}(1), v_{2}(2), v_{2}(3)) \\\\ \u0026amp;= \\left( \\sum \\limits_{j_{1} = 1}^{2} v_{1}(j_{1}) e_{j_{1}} \\right) \\otimes \\left( \\sum \\limits_{j_{2} = 1}^{3} v_{2}(j_{2}) e_{j_{2}} \\right) \\\\ \u0026amp;:= \\sum\\limits_{(j_{1}, j_{2}) \\in \\Gamma_{1} \\times \\Gamma_{2}} \\left( \\prod\\limits_{i=1}^{2} v_{i}(j_{i}) \\right) e_{j_{1}} \\otimes e_{j_{2}} \\in \\mathbb{C}^{\\Gamma_{1}} \\otimes \\mathbb{C}^{\\Gamma_{2}} \\\\ \u0026amp;= v_{1}(1)v_{2}(1)e_{1} \\otimes e_{1} + v_{1}(1)v_{2}(2)e_{1} \\otimes e_{2} + v_{1}(1)v_{2}(3)e_{1} \\otimes e_{3} \\\\ \u0026amp;\\quad + v_{1}(2)v_{2}(1)e_{1} \\otimes e_{1} + v_{1}(2)v_{2}(2)e_{1} \\otimes e_{2} + v_{1}(2)v_{2}(3)e_{1} \\otimes e_{3} \\\\ \u0026amp;= \\left( v_{1}(1)v_{2}(1), v_{1}(1)v_{2}(2), v_{1}(1)v_{2}(3), v_{1}(2)v_{2}(1), v_{1}(2)v_{2}(2), v_{1}(2)v_{2}(3) \\right) \\\\ \u0026amp;\\in \\mathbb{C}^{6} \\cong \\mathbb{C}^{\\Gamma_{1}} \\otimes \\mathbb{C}^{\\Gamma_{2}} \\end{align*} $$\nBy carefully observing the components of $v_{1} \\otimes v_{2}$, one could guess its relation to matrices.\nCoordinate Matrix Consider the matrix space $M_{m \\times n}(\\mathbb{C})$. If $E_{ij}$ has components $(i,j)$ as $1$ and the rest as $0$, it is called an $m \\times n$ matrix, and $\\left\\{ E_{ij} \\right\\}$ becomes the basis of $M_{m\\times n}(\\mathbb{C})$. Let $\\phi$ be a linear transformation that maps the basis vector $e_{i} \\otimes e_{j}$ of the tensor product $\\mathbb{C}^{m} \\otimes \\mathbb{C}^{n}$ to $E_{ij}$.\n$$ \\begin{align*} \\phi : \\mathbb{C}^{m} \\otimes \\mathbb{C}^{n} \u0026amp;\\to M_{m \\times n} (\\mathbb{C}) \\\\ e_{i} \\otimes e_{j} \u0026amp;\\mapsto E_{ij} \\end{align*} $$\nSince it maps a basis to a basis, it becomes an isomorphism. If two vectors $v \\in \\mathbb{C}^{m}$, $w \\in \\mathbb{C}^{n}$ are as follows,\n$$ v = \\sum_{i} \\alpha_{i}e_{i} = \\begin{bmatrix} \\alpha_{1} \\\\ \\vdots \\\\ \\alpha_{m} \\end{bmatrix} \\qquad w = \\sum_{j} \\beta_{j}e_{j} = \\begin{bmatrix} \\beta_{1} \\\\ \\vdots \\\\ \\beta_{n} \\end{bmatrix} $$\nSending the product vector $v, w$ through $\\phi$ results in the following.\n$$ \\begin{align*} \\phi ( v \\otimes w ) \u0026amp;= \\phi \\left( \\sum\\limits_{i,j} \\alpha_{i}\\beta_{j} e_{i} \\otimes e_{j} \\right) \\\\ \u0026amp;= \\sum\\limits_{i,j} \\alpha_{i}\\beta_{j} \\phi \\left( e_{i} \\otimes e_{j} \\right) \\\\ \u0026amp;= \\sum\\limits_{i,j} \\alpha_{i}\\beta_{j} E_{ij} \\\\ \u0026amp;= \\begin{bmatrix} \\alpha_{1}\\beta_{1} \u0026amp; \\cdots \u0026amp; \\alpha_{1}\\beta_{n} \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ \\alpha_{m}\\beta_{1} \u0026amp; \\cdots \u0026amp; \\alpha_{m}\\beta_{n} \\\\ \\end{bmatrix} \\\\ \u0026amp;= \\begin{bmatrix} \\alpha_{1} \\\\ \\vdots \\\\ \\alpha_{m} \\end{bmatrix} \\begin{bmatrix} \\beta_{1} \u0026amp; \\cdots \u0026amp; \\beta_{n} \\end{bmatrix} \\\\ \u0026amp;= vw^{T} \\end{align*} $$\nThis corresponds to a matrix whose elements are $\\alpha_{i}\\beta_{j}$. Therefore, by $\\phi$, the product vector $v \\otimes w$ corresponds to a single $m \\times n$. The matrix $\\phi (v \\otimes w) = vw^{T}$ is called the coordinate matrix of $v \\otimes w$ with respect to the standard basis. This concept can be seen as analogous to a vector\u0026rsquo;s coordinate vector.\nGeneralization For finite sets $\\Gamma_{i} (1 \\le i \\le r)$, $\\Gamma = \\Gamma_{1} \\times \\cdots \\times \\Gamma_{r}$, $v_{i} \\in \\mathbb{C}^{\\Gamma_{i}}$, the product vectors of $v_{i}$ are defined as follows.\n$$ \\begin{align*} v_{1} \\otimes \\cdots \\otimes v_{r} \u0026amp;= \\left( \\sum \\limits_{j_{1} \\in \\Gamma_{1}}v_{1}(j_{1}) e_{j_{1}} \\right) \\otimes \\cdots \\otimes \\left( \\sum \\limits_{j_{r} \\in \\Gamma_{r}}v_{r}(j_{r}) e_{j_{r}} \\right) \\\\ \u0026amp;:= \\sum\\limits_{(j_{1}, \\dots, j_{r}) \\in \\Gamma} \\left( \\prod\\limits_{i=1}^{r} v_{i}(j_{i}) \\right) e_{j_{1}} \\otimes \\cdots \\otimes e_{j_{r}} \\\\ \u0026amp;= \\in \\mathbb{C}^{\\Gamma_{1}} \\otimes \\cdots \\otimes \\mathbb{C}^{\\Gamma_{r}} \\end{align*} $$\nSee Also Tensor product of vector spaces $V \\otimes W$\n${}$ What is a tensor in physics: an easy definition of tensor Tensors defined on differential manifolds ","id":3415,"permalink":"https://freshrimpsushi.github.io/en/posts/3415/","tags":null,"title":"Tensor Product of Product Vectors"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, view is a data structure that quickly refers to a subarray of an array, making it seem cumbersome from a user\u0026rsquo;s perspective, although there might seem to be no difference. However, it returns a lighter array as it is lazily referenced. Therefore, in Julia code that is optimized even at a very basic level, it is easy to find the macro @views.\nCode Let\u0026rsquo;s refer to a submatrix of the matrix M.\nFunctional form: view() view(A, inds...)\nReturns a view according to inds... of A. However, this form is generally not preferred as it makes the code harder to read. By using the following macro, view can be used without much difference from the basic Julia syntax.\nMacro: @view The @view macro changes the context of the code referring to subarrays as if view has been applied.\nApply to the entire block: @views The @views macro applies @view to the entire following block. Thanks to this, simply adding @views like @views f(x) ... end in front of a function written comfortably without view automatically applies view.\nFull Code Speed Comparison fcopy() and fview() are functions that perform exactly the same function but differ in speed. At a glance, the speeds seem similar, but most of it is compilation time. Excluding this and comparing only the simple execution time, there is about a 4-times difference.\nEnvironment OS: Windows julia: v1.7.0 ","id":2384,"permalink":"https://freshrimpsushi.github.io/en/posts/2384/","tags":null,"title":"How to Quickly Reference Subarrays in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Buildup1 For convenience, the discussion unfolds with respect to the complex number space $\\mathbb{C}$, but it could equally apply to $\\mathbb{R}$ or any arbitrary vector space. Let\u0026rsquo;s denote the set of functions from a finite set $\\Gamma$ to a complex number space as $\\mathbb{C}^{\\Gamma}$.\n$$ \\mathbb{C}^{\\Gamma} = \\left\\{ f : \\Gamma \\to \\mathbb{C} \\right\\} $$\nLet $\\Gamma$ be $\\mathbf{n} = \\left\\{ 1, 2, \\dots, n \\right\\}$. If we denote a function that sends each $1 \\le i \\le n$ to a complex number $z_{i} \\in \\mathbb{C}$ as $(z_{1}, \\dots, z_{n})$, this is a function belonging to $\\mathbb{C}^{\\mathbf{n}}$, as well as a vector of the complex number ordered pair set $\\mathbb{C}^{n}$.\n$$ (z_{1}, \\dots, z_{n}) : i \\mapsto z_{i} $$\n$$ \\mathbb{C}^{n} := \\mathbb{C}^{\\mathbf{n}} = \\left\\{ (z_{1}, \\dots, z_{n}) \\vert z_{i} \\in \\mathbb{C} \\right\\} $$\nThus, $v \\in \\mathbb{C}^{\\Gamma}$ can be seen both as a function like $v : i \\mapsto z_{i}$, and as an ordered pair like $v = (z_{1}, \\dots, z_{\\left| \\Gamma \\right|})$.\nFor finite sets $\\Gamma_{1}$ and $\\Gamma_{2}$, the tensor product of two vector spaces $\\mathbb{C}^{\\Gamma_{1}}$ and $\\mathbb{C}^{\\Gamma_{2}}$ is defined as the function space (vector space) $\\mathbb{C}^{\\Gamma_{1} \\times \\Gamma_{2}}$ created from the product space $\\Gamma_{1} \\times \\Gamma_{2}$ of $\\Gamma_{1}$ and $\\Gamma_{2}$.\nDefinition2 For finite sets $\\Gamma_{1}$ and $\\Gamma_{2}$, the tensor product of two vector spaces $\\mathbb{C}^{\\Gamma_{1}}$ and $\\mathbb{C}^{\\Gamma_{2}}$ is defined as follows.\n$$ \\mathbb{C}^{\\Gamma_{1}} \\otimes \\mathbb{C}^{\\Gamma_{2}} := \\mathbb{C}^{\\Gamma_{1} \\times \\Gamma_{2}} $$\nHere, $\\Gamma_{1} \\times \\Gamma_{2}$ is the product space of $\\Gamma_{1}$ and $\\Gamma_{2}$.\nExplanation For a simple example, consider $\\Gamma_{1} = \\mathbf{2} = \\left\\{ 1, 2 \\right\\}$ and $\\Gamma_{2} = \\mathbf{3} = \\left\\{ 1, 2, 3 \\right\\}$. Let $\\Gamma$ be their product space.\n$$ \\Gamma = \\Gamma_{1} \\times \\Gamma_{2} = \\left\\{ (1,1), (1,2), (1,3), (2,1), (2,2), (2,3) \\right\\} $$\nLet\u0026rsquo;s denote its elements as follows.\n$$ e_{i} \\otimes e_{j} = (i, j) $$\nThen, following the logic in the overview, $v \\in \\mathbb{C}^{\\Gamma}$ can be seen as a function like $(i,j) \\mapsto \\alpha_{ij}$ and also like an ordered pair $\\left( \\alpha_{11}, a_{12}, a_{13}, a_{21}, a_{22}, a_{23} \\right)$. Therefore, $\\mathbb{C}^{\\Gamma}$ is a vector space with $\\left\\{ e_{i} \\otimes e_{j} : 1 \\le i \\le 2, 1 \\le j \\le 3 \\right\\}$ as its basis.\n$$ \\begin{align*} \\mathbb{C}^{\\Gamma} \u0026amp;= \\left\\{ \\sum\\limits_{i,j} \\alpha_{i,j} e_{i} \\otimes e_{j} : \\alpha_{ij} \\in \\mathbb{C} \\right\\} \\\\ \u0026amp;= \\left\\{ \\left( \\alpha_{11}, a_{12}, a_{13}, a_{21}, a_{22}, a_{23} \\right) : \\alpha_{ij} \\in \\mathbb{C} \\right\\} \\end{align*} $$\nThus, $\\mathbb{C}^{6}$ is isomorphic to.\n$$ \\mathbb{C}^{\\Gamma} = \\mathbb{C}^{2} \\otimes \\mathbb{C}^{3} \\cong \\mathbb{C}^{6} $$\nWhen $\\mathbb{C}$ is bundled into a product space, it might be easier to think that the places of variables increase, and when bundled as a tensor product, the places of indexes increase.\n$$ z_{1} \\in \\mathbb{C}\\qquad (z_{1},z_{2}) \\in \\mathbb{C} \\times \\mathbb{C}\\qquad (z_{1}, z_{2}, z_{3}) \\in \\mathbb{C}\\times \\mathbb{C} \\times \\mathbb{C} $$\n$$ (z_{1}, z_{2}) \\in \\mathbb{C}^{2} \\qquad (z_{11}, z_{12}, z_{21}, z_{22}) \\in \\mathbb{C}^{2} \\otimes \\mathbb{C}^{2} \\\\[1em] (z_{111}, z_{112}, z_{121}, z_{122}, z_{211}, z_{212}, z_{221}, z_{222}) \\in \\mathbb{C}^{2} \\otimes \\mathbb{C}^{2} \\otimes \\mathbb{C}^{2} $$\nEach $e_{i} \\otimes e_{j}$ corresponds to a standard basis vector of $\\mathbb{C}^{6}$ as follows.\n$$ e_{1} \\otimes e_{1} = \\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\\end{bmatrix} \\quad e_{1} \\otimes e_{2} = \\begin{bmatrix}0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\\end{bmatrix} \\quad e_{1} \\otimes e_{3} = \\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0\\end{bmatrix} \\\\[2em] e_{2} \\otimes e_{1} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0\\end{bmatrix} \\quad e_{2} \\otimes e_{2} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 0\\end{bmatrix} \\quad e_{2} \\otimes e_{3} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1\\end{bmatrix} $$\nWhen expressed as a Kronecker product of matrices, it is as follows.\n$$ e_{1} \\otimes e_{1} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\otimes \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} \\\\[1.5em] 0 \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix} \\quad e_{1} \\otimes e_{2} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\otimes \\begin{bmatrix} 0 \\\\ 1 \\\\ 0\\end{bmatrix} = \\begin{bmatrix} 1 \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} \\\\[1.5em] 0 \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix} \\\\[2em] e_{1} \\otimes e_{3} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\otimes \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\\\[1.5em] 0 \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix} \\quad e_{2} \\otimes e_{1} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\otimes \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} \\\\[1.5em] 1 \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix} \\\\[2em] e_{2} \\otimes e_{2} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\otimes \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} \\\\[1.5em] 1 \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{bmatrix} \\quad e_{2} \\otimes e_{3} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\otimes \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\\\[1.5em] 1 \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix} $$\nFurthermore, from this, it can be understood that the following holds.\n$$ \\mathbb{C} \\otimes \\mathbb{C}^{n} \\cong \\mathbb{C}^{n} \\qquad \\mathbb{C} \\otimes \\mathbb{C} \\cong \\mathbb{C} $$\nProperties $\\mathbb{C}^{n} \\otimes \\mathbb{C}^{m}$ is a vector space with respect to the following two operations. $(x_{1} \\otimes y_{1}) + (x_{2} \\otimes y_{2}) = (x_{1} + x_{2}) \\otimes (y_{1} + y_{2})$ $\\alpha (x \\otimes y) = (\\alpha x) \\otimes y = x \\otimes (\\alpha y)$ $\\mathbb{C}^{n} \\otimes \\mathbb{C}^{m} \\cong \\mathbb{C}^{nm}$ $\\dim (\\mathbb{C}^{n} \\otimes \\mathbb{C}^{m}) = \\dim(\\mathbb{C}^{n}) \\cdot \\dim(\\mathbb{C}^{m}) = nm$ See Also Product Vectors $v \\otimes w$\n${}$ What is a Tensor in Physics: A Simple Definition of Tensor Tensors Defined on Differential Manifolds Kim Young-Hoon \u0026amp; Heo Jae-Seong, Quantum Information Theory (2020), p3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKim Young-Hoon \u0026amp; Heo Jae-Seong, Quantum Information Theory (2020), p31\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3414,"permalink":"https://freshrimpsushi.github.io/en/posts/3414/","tags":null,"title":"Tensor Product of Vector Spaces"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Buildup Despite the complexity of the content, I made sure to leave detailed calculations and explanations to make it as understandable as possible. If you\u0026rsquo;re interested in homology, I highly recommend reading this.\nConsider a topological space $X$ of interest, represented through a $\\Delta$-complex structure according to a specific simplicial complex. As a small example, in the image on the right, the torus represents $X$, and the left side corresponds to the simplicial complex.\nDefinition of a simplex:\nThe convex hull of $v_{0}, v_{1} , \\cdots , v_{n} \\in \\mathbb{R}^{n+1}$, which are affinely independent, is called an $n$-simplex $\\Delta^{n}$, and the vectors $v_{k}$ are called vertices. Mathematically, it is expressed as follows. $$ \\Delta^{n} := \\left\\{ \\sum_{k} t_{k} v_{k} : v_{k} \\in \\mathbb{R}^{n+1} , t_{k} \\ge 0 , \\sum_{k} t_{k} = 1 \\right\\} $$ An $n-1$-simplex $\\Delta^{n-1}$ created by removing a vertex from $\\Delta^{n}$ is called a face of $\\Delta^{n}$. The union of all faces of $\\Delta^{n}$ is called the boundary of $\\Delta^{n}$ and is denoted as $\\partial \\Delta^{n}$. The interior of a simplex $\\left( \\Delta^{n} \\right)^{\\circ} := \\Delta^{n} \\setminus \\partial \\Delta^{n}$ is called an open simplex. Let\u0026rsquo;s say a simplicial complex is a complex made up of simplices, specifically forming a CW complex as follows:\nThe definition of $n$:\n$D^{n} \\subset \\mathbb{R}^{n}$ defined as follows is called an $n$-unit disk. $$ D^{n} := \\left\\{ \\mathbf{x} \\in \\mathbb{R}^{n} : \\left\\| \\mathbf{x} \\right\\| \\le 1 \\right\\} $$ A subset $e^{n}$ that is homeomorphic to $D^{n} \\setminus \\partial D^{n}$ is called an $n$-cell. Definition of CW Complex:\nA discrete set $X^{0} \\ne \\emptyset$ is considered as 0-cells. An $n$-skeleton $X^{n}$ is made by attaching $n$-cells $e_{\\alpha}^{n}$ to $X^{n-1}$ using the maps $\\phi_{\\alpha} : S^{n-1} \\to X^{n-1}$. $X := \\bigcup_{n \\in \\mathbb{N}} X^{n}$ becomes a topological space with a weak topology, then $X$ is called a cell complex. Definition Consider a topological space $X$ with a $\\Delta$-complex structure.\nLet\u0026rsquo;s denote the free abelian group with a basis of open $n$-simplices, or $n$-cells $e_{\\alpha}^{n}$ in $X$, as $\\Delta_{n} (X)$. Elements of $\\Delta_{n} (X)$ are called $n$-chains and are represented as formal sums with coefficients $k_{\\alpha} \\in \\mathbb{Z}$ as follows. $$ \\sum_{\\alpha} k_{\\alpha} e_{\\alpha}^{n} $$ Each $n$-cell $e_{\\alpha}^{n}$ corresponds to a characteristic map $\\sigma_{\\alpha} : \\Delta^{n} \\to X$, allowing representation as follows. $$ \\sum_{\\alpha} k_{\\alpha} \\sigma_{\\alpha} $$ The boundary homomorphism $\\partial_{n} : \\Delta_{n} (X) \\to \\Delta_{n-1} (X)$ is defined as follows, where $\\sigma_{\\alpha} | \\left[ v_{1} , \\cdots , \\hat{v}_{i} , \\cdots , v_{n} \\right]$ indicates the restriction of $\\sigma_{\\alpha}$ to an $n-1$-simplex in $X$. $$ \\partial _{n} \\left( \\sigma_{\\alpha} \\right) := \\sum_{i=0}^{n} \\left( -1 \\right)^{i} \\sigma_{\\alpha} | \\left[ v_{1} , \\cdots , \\hat{v}_{i} \\cdots , v_{n} \\right] $$ The quotient group $\\ker \\partial_{n} / \\text{Im} \\partial_{n+1}$ is denoted as $H_{n}^{\\Delta}$, and since $H_{n}^{\\Delta}$ is a homology group, it is called the $n$th simplicial homology group of $X$. The group $0$ is a magma defined on ${ 0 }$, essentially an empty algebraic structure. The homomorphism $\\partial^{2} = 0$ is a zero morphism. $\\text{Im}$ refers to the image. $\\ker$ refers to the kernel. In a set, the notation $\\hat{v}_{i}$ means excluding $v_{i}$, as follows: $$ { v_{1} , \\cdots , \\hat{v}_{i} , \\cdots , v_{n} } := { v_{1} , \\cdots , v_{n} } \\setminus { v_{i} } $$ Explanation The definition section might be overwhelming with its dense text. It\u0026rsquo;s normal if it\u0026rsquo;s not immediately clear. The explanation aims to be thorough and accessible, addressing points that were confusing during my study.\nWhy are elements of $\\Delta_{n} (X)$ called chains? Considering the notation $\\sigma_{\\alpha} : \\Delta^{n} \\to X$, we can abstract away whether $e_{\\alpha}^{n}$ is an element of $\\Delta^{n}$ or $X$. For $n=2$ and all coefficients $k_{\\alpha} = 1$, the geometric representation can be imagined as the figure on the right, denoted as $\\sum_{i=1}^{7} \\sigma_{i}$.\nThe term \u0026ldquo;chain\u0026rdquo; might make sense now, but it\u0026rsquo;s not crucial for understanding. What\u0026rsquo;s important is that the collection of $n$-chains in $\\Delta_{n} (X)$ forms a chain complex.\nIs $\\Delta_{n} (X)$ really a group? It\u0026rsquo;s crucial to note that the \u0026ldquo;formal sum\u0026rdquo; used to describe chains is not an algebraic operation within $\\Delta_{n} (X)$. This notation is merely symbolic. For example, the expression\n2üòÄ + üíé - 3üçå\rhas no mathematical meaning as it's unclear what \"twice üòÄ plus üíé minus three üçå\" would entail. This confusion is similar to the uncertainty in $\\sum\\_{\\alpha} k\\_{\\alpha} e\\_{\\alpha} \\simeq \\sum\\_{\\alpha} k\\_{\\alpha} \\sigma\\_{\\alpha}$ regarding\r- The addition of open simplices $e\\_{\\alpha}^{n}$, which is undefined\r- The interpretation of $\\sigma\\_{\\alpha}$, which is a function\r- The meaning of operations like $-3 e\\_{1}^{n} + 7 e\\_{2}^{n} \\simeq -3 \\sigma\\_{1} + 7 \\sigma\\_{2}$\rThankfully, these concerns are irrelevant to $\\Delta_{n} (X)$. If we define\n$\\sigma=$2üòÄ + üíé - 3üçå\ras an $n$-chain in $\\Delta\\_{n} (X)$, its inverse can be defined using the inverses of coefficients $k\\_{\\alpha} \\in (\\mathbb{Z}, +)$, resulting in\r$-\\sigma=$ (-2)üòÄ + (-1)üíé + 3üçå\rThis definition is sufficient regardless of the specific structure of $\\Delta_{n} (X)$. The identity element of $\\Delta_{n} (X)$ can be defined as $0 := \\sigma + (-\\sigma)$, and since $\\mathbb{Z}$ is an abelian group, so is $\\Delta_{n} (X)$. The operation $+$ in $(\\Delta_{n} (X), +)$ is induced from $(\\mathbb{Z}, +)$ but is distinct, and $\\Delta_{n} (X)$ is a free abelian group, with $\\sum_{\\alpha} k_{\\alpha} \\sigma_{\\alpha}$ now being an algebraic sum.\nIn summary:\nThe initial definition\u0026rsquo;s appearance of addition in $\\sum_{\\alpha} k_{\\alpha} \\sigma_{\\alpha}$ was merely notational, not an operation. The $+$ in $(\\Delta_{n} (X), +)$ is derived from $(\\mathbb{Z}, +)$ but is not the same. $(\\Delta_{n} (X), +)$ is a free abelian group, and $\\sum_{\\alpha} k_{\\alpha} \\sigma_{\\alpha}$ is now an algebraic sum. Why is $\\partial$ called the boundary? The definition of $\\partial_{n}$ may seem abstract, but the following illustration clarifies its meaning.\nFor example, for $\\partial_{2}$, we can perform the following calculation. $$ \\begin{align*} \u0026amp; \\partial _{2} \\left[ v_{0} ,v_{1}, v_{2} \\right] \\\\ =\u0026amp; \\sum_{i=0}^{2} (-1)^{i} \\left[ v_{0} ,v_{1}, v_{2} \\right] \\setminus \\left[ v_{i} \\right] \\\\ =\u0026amp; (-1)^{0} \\left[ v_{1}, v_{2} \\right] + (-1)^{1} \\left[ v_{0}, v_{2} \\right] + (-1)^{2} \\left[ v_{0}, v_{1} \\right] \\\\ =\u0026amp; \\left[ v_{1}, v_{2} \\right] - \\left[ v_{0}, v_{2} \\right] + \\left[ v_{0}, v_{1} \\right] \\end{align*} $$\nIf you\u0026rsquo;re studying homology, it\u0026rsquo;s generally accepted that the boundary of a triangle $\\left[ v_{0} ,v_{1}, v_{2} \\right]$ consists of the segments $\\left[ v_{1}, v_{2} \\right], \\left[ v_{0}, v_{2} \\right], \\left[ v_{0} , v_{1} \\right]$. The real challenge is understanding what $\\left[ v_{1}, v_{2} \\right] - \\left[ v_{0}, v_{2} \\right]$ means. How can segments be subtracted? And how about operations on 2-simplices like triangles?\nThese questions miss the point. Refocusing, $\\partial_{2} \\left[ v_{0} ,v_{1}, v_{2} \\right] \\in \\Delta_{1} (X)$ is simply a formal sum of the three elements $\\left[ v_{1}, v_{2} \\right], \\left[ v_{0}, v_{2} \\right], \\left[ v_{0} , v_{1} \\right]$. $$ (+1) \\left[ v_{1}, v_{2} \\right] + (-1) \\left[ v_{0}, v_{2} \\right] + (+1) \\left[ v_{0}, v_{1} \\right] $$\nDenoting these as $$ \\begin{align*} a := \\left[ v_{1}, v_{2} \\right] \\ b:= \\left[ v_{0}, v_{2} \\right] \\ c:= \\left[ v_{0} , v_{1} \\right] \\end{align*} $$ reveals the nature of $\\Delta_{1} (X)$. For example, a $1$-chain $x \\in \\Delta_{1} (X)$ can be represented with coefficients $k_{a} , k_{b} , k_{c} \\in \\mathbb{Z}$ as $$ x = k_{a} a + k_{b} b + k_{c} c $$\nViewing from the perspective of $a,b,c$, the free group $\\Delta_{1} (X) := F[{ a,b,c }]$ is constructed, essentially equivalent to $\\mathbb{Z}^{3} \\simeq \\mathbb{Z} \\oplus \\mathbb{Z} \\oplus \\mathbb{Z}$.\nThis shift in perspective is crucial for understanding subsequent examples. We must think algebraically rather than geometrically.\nExamples Consider the following scenario: $$ \\begin{align*} \\\\ \\partial_{n} :\u0026amp; \\Delta_{n} (X) \\to \\Delta_{n-1} (X) \\\\ H_{n}^{\\Delta} (X) =\u0026amp; \\ker \\partial_{n} / \\text{Im} \\partial_{n+1} \\end{align*} $$\nFor $n = 0$, $\\partial_{0} : \\Delta_{0} (X) \\to 0$ implies $\\ker \\partial_{0} = \\Delta_{0} (X)$.\nCircle $S^{1}$ For a circle $X = S^{1}$, there\u0026rsquo;s one 0-simplex (vertex $v$), one 1-simplex (edge $e$), and no $n$-simplices for $n \\ge 2$. The chain complex is structured as follows: $$ \\cdots \\longrightarrow 0 \\longrightarrow \\Delta_{1}\\left( S^{1} \\right) \\overset{\\partial_{1}}{\\longrightarrow} \\Delta_{0}\\left( S^{1} \\right) \\overset{\\partial_{0}}{\\longrightarrow} 0 $$\n$\\Delta_{1}(S^{1})$, being generated solely by $e$, is isomorphic to $\\mathbb{Z}$, and similarly, $\\Delta_{0}(S^{1})$ is isomorphic to $\\mathbb{Z}$ due to being generated by $v$ alone. Since $\\partial_{1}$ is a zero morphism: $$ \\partial e = v - v = 0 $$\nFor $n = 0$, $\\ker \\partial_{0} = \\Delta_{0} (S^{1})$, and since $\\partial_{1}$ is a zero morphism, its image is ${ 0 }$, leading to: $$ \\begin{align*} H_{0}^{\\Delta} \\left( S^{1} \\right) =\u0026amp; \\ker \\partial_{0} / \\text{Im} \\partial_{1} \\\\ \\simeq\u0026amp; \\Delta_{0} \\left( S^{1} \\right) / \\left\\{ 0 \\right\\} \\\\ \\simeq\u0026amp; \\mathbb{Z} \\end{align*} $$\nFor $n = 1$, $\\text{Im} \\partial_{2} = { 0 }$ since $\\partial_{1}$ is a zero morphism, and $\\ker \\partial_{1} = \\Delta_{1} (S^{1})$, resulting in: $$ \\begin{align*} H_{1}^{\\Delta} \\left( S^{1} \\right) =\u0026amp; \\ker \\partial_{1} / \\text{Im} \\partial_{2} \\\\ \\simeq\u0026amp; \\Delta_{1} \\left( S^{1} \\right) / \\left\\{ 0 \\right\\} \\\\ \\simeq\u0026amp; \\mathbb{Z} \\end{align*} $$\nFor $n \\ge 2$, $H_{n}^{\\Delta} (S_{1}) \\simeq 0$, summarizing as: $$ H_{n}^{\\Delta} \\left( S_{1} \\right) \\simeq \\begin{cases} \\mathbb{Z} \u0026amp; , \\text{if } n = 0, 1 \\\\ 0 \u0026amp; , \\text{if } n \\ge 2 \\end{cases} $$\nTorus $T^{2}$ Considering a torus $T^{2}$ as in the image, there\u0026rsquo;s one 0-simplex (vertex $v$), three 1-simplices (edges $a$, $b$, $c$), two 2-simplices ($U$, $L$), and no $n$-simplices for $n \\ge 3$. The chain complex is organized as follows: $$ \\cdots \\longrightarrow 0 \\longrightarrow \\Delta_{2}\\left( T \\right) \\overset{\\partial_{2}}{\\longrightarrow} \\Delta_{1}\\left( T \\right) \\overset{\\partial_{1}}{\\longrightarrow} \\Delta_{0}\\left( T \\right) \\overset{\\partial_{0}}{\\longrightarrow} 0 $$\nHence, the free groups $\\Delta_{n} (T)$ are: $$ \\Delta_{n} \\left( T \\right) \\simeq \\begin{cases} \\mathbb{Z}^{1} \u0026amp; , \\text{if } n = 0 \\\\ \\mathbb{Z}^{3} \u0026amp; , \\text{if } n = 1 \\\\ \\mathbb{Z}^{2} \u0026amp; , \\text{if } n = 2 \\\\ 0 \u0026amp; , \\text{if } n \\ge 3 \\end{cases} $$\nSince the edges $a$, $b$, $c$ connect to vertex $v$ at both ends: $$ \\begin{align*} \\partial a =\u0026amp; v - v = 0 \\\\ \\partial b =\u0026amp; v - v = 0 \\\\ \\partial c =\u0026amp; v - v = 0 \\end{align*} $$ and $\\partial_{1}$ is a zero morphism, similar to the circle case.\nFor $n = 0$, the situation mirrors that of the circle: $$ \\begin{align*} H_{0}^{\\Delta} \\left( T \\right) =\u0026amp; \\ker \\partial_{0} / \\text{Im} \\partial_{1} \\\\ \\simeq\u0026amp; \\Delta_{0} \\left( T \\right) / \\left\\{ 0 \\right\\} \\\\ \\simeq\u0026amp; \\mathbb{Z} \\end{align*} $$\nFor $n = 1$, since $\\partial_{1}$ is a zero morphism, $\\ker \\partial_{1} = \\Delta_{1} (T)$. The boundary homomorphism $\\partial_{2} : \\Delta_{2}(T) \\to \\Delta_{1}(T)$ yields: $$ \\partial_{2} U = a + b - c = \\partial_{2} L $$ and since ${ a, b, a + b - c }$ is a basis for $\\Delta_{1}(T)$, $H_{1}^{\\Delta}$ is isomorphic to the free group generated by $a$ and $b$, resulting in: $$ H_{1}^{\\Delta} \\left( T \\right) \\simeq \\mathbb{Z} \\oplus \\mathbb{Z} $$\nFor $n = 2$, $\\text{Im} \\partial_{3} = { 0 }$ and considering the dimensions of $\\Delta_{2}(T)$ and $\\Delta_{1}(T)$, we get: $$ \\begin{align*} H_{2}^{\\Delta} \\left( T \\right) =\u0026amp; \\ker \\partial_{2} / \\text{Im} \\partial_{3} \\\\ \\simeq\u0026amp; \\mathbb{Z}^{3-2} / \\left\\{ 0 \\right\\} \\\\ \\simeq\u0026amp; \\mathbb{Z} \\end{align*} $$\nFor $n \\ge 3$, $H_{n}^{\\Delta} (T) \\simeq 0$, summarizing as: $$ H_{n}^{\\Delta} \\left( T \\right) \\simeq \\begin{cases} \\mathbb{Z} \u0026amp; , \\text{if } n = 0 \\\\ \\mathbb{Z} \\oplus \\mathbb{Z} \u0026amp; , \\text{if } n = 1 \\\\ \\mathbb{Z} \u0026amp; , \\text{if } n = 2 \\\\ 0 \u0026amp; , \\text{if } n \\ge 3 \\end{cases} $$\nTheorem $H_{n}^{\\Delta}$ is a homology group Definition of a homology group:\nLet $n \\in \\mathbb{N}_{0}$. A sequence of abelian groups $C_{n}$ and homomorphisms $\\partial_{n} : C_{n} \\longrightarrow C_{n-1}$ forming a chain $$ \\cdots \\longrightarrow C_{n+1} \\overset{\\partial_{n+1}}{\\longrightarrow} C_{n} \\overset{\\partial_{n}}{\\longrightarrow} C_{n-1} \\longrightarrow \\cdots \\longrightarrow C_{1} \\overset{\\partial_{1}}{\\longrightarrow} C_{0} \\overset{\\partial_{0}}{\\longrightarrow} 0 $$ that satisfies $$ \\partial_{n} \\circ \\partial_{n+1} = 0 $$ for all $n$ is called a chain complex. The quotient group $H_{n} := \\ker \\partial_{n} / \\text{Im} \\partial_{n+1}$ is called the $n$th homology group of the complex. The homomorphism $\\partial_{n} : C_{n} \\longrightarrow C_{n-1}$ is called the boundary or differential operator. For the chain complex ${ (\\Delta_{n} (X), \\partial_{n}) }_{n=0}^{\\infty}$, $H_{n}^{\\Delta} := \\ker \\partial_{n} / \\text{Im} \\partial_{n+1}$ is a homology group. That is, $\\partial_{n} \\circ \\partial_{n+1}$ is a zero morphism for all $n \\in \\mathbb{N}$.\nProof Applying $\\partial_{n-1} \\circ \\partial_{n}$ to $\\sigma \\in \\Delta_{n}$ yields: $$ \\begin{align*} \u0026amp; \\left( \\partial_{n-1} \\circ \\partial_{n} \\right) \\left( \\sigma \\right) \\\\ =\u0026amp; \\partial_{n-1} \\left( \\partial_{n} \\left( \\sigma \\right) \\right) \\\\ =\u0026amp; \\partial_{n-1} \\left( \\sum_{i=0}^{n} \\left( -1 \\right)^{i} \\sigma_{\\alpha} | \\left[ v_{1} , \\cdots , \\hat{v}_{i} , \\cdots , v_{n} \\right] \\right) \\\\ =\u0026amp; \\sum_{j \u0026lt; i} \\left( -1 \\right)^{i} \\left( -1 \\right)^{j} \\sigma_{\\alpha} | \\left[ v_{1} , \\cdots , \\hat{v}_{i} , \\cdots , \\hat{v}_{j} , \\cdots , v_{n} \\right] \\\\ \u0026amp; + \\left( -1 \\right) \\sum_{j \u0026gt;i} \\left( -1 \\right)^{i} \\left( -1 \\right)^{j} \\sigma_{\\alpha} | \\left[ v_{1} , \\cdots , \\hat{v}_{i} , \\cdots , \\hat{v}_{j} , \\cdots , v_{n} \\right] \\\\ =\u0026amp; 0 \\end{align*} $$\nSuch proofs are often more illuminating with specific examples rather than generalizations. $$ \\begin{align*} \u0026amp; \\partial_{1} \\left( \\partial_{2} \\left[ v_{0}, v_{1} , v_{2} \\right] \\right) \\\\ =\u0026amp; \\partial_{1} \\left( \\left[ v_{1} , v_{2} \\right] - \\left[ v_{0}, v_{2} \\right] + \\left[ v_{0}, v_{1} \\right] \\right) \\\\ =\u0026amp; \\partial_{1} \\left[ v_{1} , v_{2} \\right] - \\partial_{1} \\left[ v_{0}, v_{2} \\right] + \\partial_{1} \\left[ v_{0}, v_{1} \\right] \\\\ =\u0026amp; \\left[ v_{2} \\right] - \\left[ v_{1} \\right] - \\left( \\left[ v_{2} \\right] - \\left[ v_{0} \\right] \\right) + \\left[ v_{1} \\right] - \\left[ v_{0} \\right] \\\\ =\u0026amp; 0 \\end{align*} $$\n‚ñ†\n","id":2383,"permalink":"https://freshrimpsushi.github.io/en/posts/2383/","tags":null,"title":"Definition of Simplicial Homology Group"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Broadcasting is one of the most important concepts in Julia, offering a convenient syntax for writing vectorized code1. It is used by placing a dot . before a binary operation or after a function. This represents the application of a function in a pointwise manner, which is a perfect expression of its purpose.\nFrom a programming perspective, broadcasting can be viewed as a simplification of using Map in Map and Reduce.\nCode Binary Operations For binary operations, we place a . before them. For example, to add a scalar $a \\in \\mathbb{R}$ to every element of a matrix $A \\in \\mathbb{Z}_{9}^{3 \\times 4}$, we use the following code.\njulia\u0026gt; A = rand(0:9, 3,4)\r3√ó4 Matrix{Int64}:\r5 6 3 3\r7 4 8 8\r0 2 2 7\rjulia\u0026gt; a = rand()\r0.23234165065465284\rjulia\u0026gt; A .+ a\r3√ó4 Matrix{Float64}:\r5.23234 6.23234 3.23234 3.23234\r7.23234 4.23234 8.23234 8.23234\r0.232342 2.23234 2.23234 7.23234 General Functions julia\u0026gt; f(x) = x^2 - 1\rf (generic function with 3 methods)\rjulia\u0026gt; f(a)\r-0.9460173573710713 Consider the function $f : \\mathbb{R} \\to \\mathbb{R}$, for example. Since this is a scalar function, it calculates well for $a \\in \\mathbb{R}$ as shown above.\njulia\u0026gt; f(A)\rERROR: LoadError: DimensionMismatch However, if we attempt to input a matrix $A$, we encounter a LoadError. Upon reflection, the very concept of squaring a matrix, especially a rectangular matrix like $A \\in \\mathbb{Z}_{9}^{3 \\times 4}$, is ambiguous, thus we cannot simply input it into a function like $f(x) = x^{2} - 1$. Yet, if what we desire is a matrix derived from taking the square of each value in matrix $A$ and then subtracting $1$, by placing a dot . as in f., we can apply the function $f : \\mathbb{R} \\to \\mathbb{R}$ to every element of the matrix.\njulia\u0026gt; f.(A)\r3√ó4 Matrix{Int64}:\r24 35 8 8\r48 15 63 63\r-1 3 3 48 Speed Comparison In many cases, broadcasting is also superior in terms of performance. However, when evaluating performance based on speed, there are some nuances to be aware of, which are crucial to understand as indicated below.\nFor instance, the following code squares the numbers from 1 to 100,000.\njulia\u0026gt; @time for x in 1:100000\rsqrt(x)\rend\r0.000001 seconds\rjulia\u0026gt; @time sqrt.(1:100000);\r0.000583 seconds (2 allocations: 781.297 KiB) Comparing simple speed, broadcasting is about 500 times slower than a for loop. However, this benchmark, derived from simple calculations, changes if we include processes such as storage ‚Äï then the story differs.\njulia\u0026gt; z = []\rAny[]\rjulia\u0026gt; @time for x in 1:100000\rpush!(z, sqrt(x))\rend\r0.005155 seconds (100.01 k allocations: 3.353 MiB)\rjulia\u0026gt; @time y = sqrt.(1:100000);\r0.000448 seconds (2 allocations: 781.297 KiB) Whether or not the process includes storage, the code with broadcasting remains unchanged. However, for a loop that needs to add values to an empty array, it\u0026rsquo;s about 10 times slower than vectorized code. This could be attributed to the cost of handling a dynamic array with push!() rather than sqrt() itself, but in any case, broadcasting turns out to be faster. Naturally, there are ways to make loops faster (for example, changing Any[] to Float64[] would help), but in most coding scenarios encountered in reality, using broadcasting is not only more convenient but also superior in speed.\nThis goes beyond merely conceptual issues, also relating to Julia being closer to a compiled language rather than an interpreted one1. If you were a compiler, wouldn\u0026rsquo;t you prefer compiling for a vector, whose type and size are specifically defined, over a for loop, where what happens next is uncertain?\nIt\u0026rsquo;s safe to say that in about 99% of functions, using the Julia developers\u0026rsquo; designed method is faster than crafting loops ourselves. There\u0026rsquo;s no need to force vectorization of code, but when it can be vectorized, it\u0026rsquo;s overwhelmingly\u0026hellip; indeed overwhelmingly faster. This is not unique to Julia, but is a characteristic of languages specialized in vector operations like Matlab, R. However, Julia sets itself apart by embracing the paradigm of functional programming while confidently asserting its speed advantage.\nEnvironment OS: Windows julia: v1.7.0 https://docs.julialang.org/en/v1/manual/arrays/#Broadcasting\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2382,"permalink":"https://freshrimpsushi.github.io/en/posts/2382/","tags":null,"title":"Julia's Broadcasting Syntax"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 The following vector-valued Boolean function is referred to as a Fredkin GateFredkin Gate.\n$$ F : \\left\\{ 0, 1 \\right\\}^{3} \\to \\left\\{ 0, 1 \\right\\}^{3} $$\n$$ F (a, b, c) = \\Big(a, (\\lnot a \\land b) \\lor (a \\land c), (\\lnot a \\land c) \\lor (a \\land b) \\Big) $$\n$\\text{CSWAP}$ GateControlled SWAP (CSWAP) Gate is also known as. Description Introduced by Edward FredkinEdward Fredkin, the Fredkin Gate swaps the remaining two values without altering the first input, if the first input is $1$. The specific computation is as follows.\n$$ \\begin{align*} F (0,0,0) \u0026amp;= (0, (\\lnot 0 \\land 0) \\lor (0 \\land 0), (\\lnot 0 \\land 0) \\lor (0 \\land 0)) = (0, 0 \\lor 0, 0 \\lor 0) = (0, 0, 0) \\\\ F (0,0,1) \u0026amp;= (0, (\\lnot 0 \\land 0) \\lor (0 \\land 1), (\\lnot 0 \\land 1) \\lor (0 \\land 0)) = (0, 0 \\lor 0, 1 \\lor 0) = (0, 0, 1) \\\\ F (0,1,0) \u0026amp;= (0, (\\lnot 0 \\land 1) \\lor (0 \\land 0), (\\lnot 0 \\land 0) \\lor (0 \\land 1)) = (0, 1 \\lor 0, 0 \\lor 0) = (0, 1, 0) \\\\ F (0,1,1) \u0026amp;= (0, (\\lnot 0 \\land 1) \\lor (0 \\land 1), (\\lnot 0 \\land 1) \\lor (0 \\land 1)) = (0, 1 \\lor 0, 1 \\lor 0) = (0, 1, 1) \\\\ F (1,0,0) \u0026amp;= (1, (\\lnot 1 \\land 0) \\lor (1 \\land 0), (\\lnot 1 \\land 0) \\lor (1 \\land 0)) = (1, 0 \\lor 0, 0 \\lor 0) = (1, 0, 0) \\\\ F (1,0,1) \u0026amp;= (1, (\\lnot 1 \\land 0) \\lor (1 \\land 1), (\\lnot 1 \\land 1) \\lor (1 \\land 0)) = (1, 0 \\lor 1, 0 \\lor 0) = (1, 1, 0) \\\\ F (1,1,0) \u0026amp;= (1, (\\lnot 1 \\land 1) \\lor (1 \\land 0), (\\lnot 1 \\land 0) \\lor (1 \\land 1)) = (1, 0 \\lor 0, 0 \\lor 1) = (1, 0, 1) \\\\ F (1,1,1) \u0026amp;= (1, (\\lnot 1 \\land 1) \\lor (1 \\land 1), (\\lnot 1 \\land 1) \\lor (1 \\land 1)) = (1, 0 \\lor 1, 0 \\lor 1) = (1, 1, 1) \\\\ \\end{align*} $$\nFrom the table, it is evident that $F$ is a reversible function and that composing $F$ twice results in an identity function.\n$$ \\operatorname{Id} = F \\circ F $$\nFurthermore, since $\\left\\{ F \\right\\}$ is functionally complete, $F$ is a universal gate.\nBoolean Function\rSymbol\r$F$\rTruth Table\rInput\rOutput\r$a$\r$b$\r$c$\r$a$\r$ (\\lnot a \\land b) \\lor (a \\land c)$\r$ (\\lnot a \\land c) \\lor (a \\land b)$\r$0$\r$0$\r$0$\r$0$\r$0$\r$0$\r$0$\r$0$\r$1$\r$0$\r$0$\r$1$\r$0$\r$1$\r$0$\r$0$\r$1$\r$0$\r$0$\r$1$\r$1$\r$0$\r$1$\r$1$\r$1$\r$0$\r$0$\r$1$\r$0$\r$0$\r$1$\r$0$\r$1$\r$1$\r$1$\r$0$\r$1$\r$1$\r$0$\r$1$\r$0$\r$1$\r$1$\r$1$\r$1$\r$1$\r$1$\r$1$\rSummary Assuming unrestricted use of projection and injection, the Fredkin Gate $F$ is a universal gate. In other words, $\\left\\{ F \\right\\}$ is functionally complete.\nProof Theorem\nThe set of $\\text{NOT}$ Gate and $\\text{AND}$ Gate, $\\left\\{ \\lnot, \\land \\right\\}$, is functionally complete.\nFollowing the theorem, demonstrating that projection, injection, and $F$ can appropriately represent $\\text{NOT}$ and $\\text{AND}$ concludes the proof.\n$\\text{NOT}$ Gate\n$$ \\lnot = p_{0} \\circ p_{1} \\circ F \\circ \\jmath_{2} \\circ \\imath_{1} $$\nHolds true. Since $\\jmath_{2} \\circ \\imath_{1} (a) = (a, 0, 1)$, the following is obtained:\n$$ \\begin{equation} F \\circ \\jmath_{2} \\circ \\imath_{1}(a) = F(a, 0, 1) = (a, a, \\lnot a) \\end{equation} $$\nTo eliminate the first two values, take $p_{0} \\circ p_{1}$, resulting in:\n$$ p_{0} \\circ p_{1} \\circ F \\circ \\jmath_{2} \\circ \\imath_{1} (a) = p_{0} \\circ p_{1} (a, a, \\lnot a) = \\lnot a $$\n‚Äª Additionally, applying $p_{2}$ to $(1)$ yields a duplication function.\n$\\text{AND}$ Gate\n$$ \\land = p_{0} \\circ p_{1} \\circ F \\circ \\imath_{2} $$\nHolds true. Initially, $F \\circ \\jmath_{2} (a, b)$ is as follows:\n$$ \\begin{align*} F \\circ \\jmath_{2} (a, b) = F(a, b, 0) \u0026amp;= (a, (\\lnot a \\land b) \\lor (a \\land 0), (\\lnot a \\land 0) \\lor (a \\land b)) \\\\ \u0026amp;= (a, (\\lnot a \\land b) \\lor 0, 0 \\lor (a \\land b)) \\\\ \u0026amp;= (a, \\lnot a \\land b, a \\land b) \\end{align*} $$\nTherefore, taking $p_{0} \\circ p_{1}$ results in:\n$$ p_{0} \\circ p_{1} \\circ F \\circ \\imath_{2} (a, b) = p_{0} \\circ p_{1} (a, \\lnot a \\land b, a \\land b) = a \\land b $$\n‚ñ†\nSee Also $\\text{AND}$ GateAND $\\text{OR}$ GateOR $\\text{NOT}$ GateNOT $\\text{XOR}$ GateXOR $\\text{NAND}$ GateNAND $\\text{NOR}$ GateNOR $\\operatorname{CNOT}$ Gate Toffoli Gate$\\text{CCNOT}$ Gate Kim Young-Hoon \u0026amp; Heo Jae-Sung, Quantum Information Theory (2020), p90-93\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3412,"permalink":"https://freshrimpsushi.github.io/en/posts/3412/","tags":null,"title":"Fredkin/CSWAP Gate"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"Definition1 The following vector-valued Boolean function is called a Toffoli gateToffoli gate.\n$$ T : \\left\\{ 0, 1 \\right\\}^{3} \\to \\left\\{ 0, 1 \\right\\}^{3} $$\n$$ T (a, b, c) = (a, b, (a \\land b) \\oplus c) $$\nThe $\\text{CCNOT}$ gateControlled Controlled NOT(CCNOT) gate is also known as. Description In the Toffoli gate, if the first two inputs are both $1$, the third input is inverted. In all other cases, the input and output are the same. The specific calculation is as follows.\n$$ \\begin{align*} T (0,0,0) \u0026amp;= (0, 0, (0 \\land 0) \\oplus 0) = (0, 0, 0 \\oplus 0) = (0, 0, 0) \\\\ T (0,0,1) \u0026amp;= (0, 0, (0 \\land 0) \\oplus 1) = (0, 0, 0 \\oplus 1) = (0, 0, 1) \\\\ T (0,1,0) \u0026amp;= (0, 1, (0 \\land 1) \\oplus 0) = (0, 1, 0 \\oplus 0) = (0, 1, 0) \\\\ T (0,1,1) \u0026amp;= (0, 1, (0 \\land 1) \\oplus 1) = (0, 1, 0 \\oplus 1) = (0, 1, 1) \\\\ T (1,0,0) \u0026amp;= (1, 0, (1 \\land 0) \\oplus 0) = (1, 0, 0 \\oplus 0) = (1, 0, 0) \\\\ T (1,0,1) \u0026amp;= (1, 0, (1 \\land 0) \\oplus 1) = (1, 0, 0 \\oplus 1) = (1, 0, 1) \\\\ T (1,1,0) \u0026amp;= (1, 1, (1 \\land 1) \\oplus 0) = (1, 1, 1 \\oplus 0) = (1, 1, 1) \\\\ T (1,1,1) \u0026amp;= (1, 1, (1 \\land 1) \\oplus 1) = (1, 1, 1 \\oplus 1) = (1, 1, 0) \\\\ \\end{align*} $$\nFrom the table above, it\u0026rsquo;s easy to see that $T$ is a reversible function and that applying $T$ twice composes to an identity function.\n$$ \\operatorname{Id} = T \\circ T $$\nFurthermore, since $\\left\\{ T \\right\\}$ is functionally complete, $T$ is a universal gate.\nÎ∂ÄÏö∏ Ìï®Ïàò\rÍ∏∞Ìò∏\rÏßÑÎ¶¨Ìëú\r$T$\rÏûÖÎ†•\rÏ∂úÎ†•\r$a$\r$b$\r$c$\r$a$\r$b$\r$(a \\land b) \\oplus c$\r$0$\r$0$\r$0$\r$0$\r$0$\r$0$\r$0$\r$0$\r$1$\r$0$\r$0$\r$1$\r$0$\r$1$\r$0$\r$0$\r$1$\r$0$\r$0$\r$1$\r$1$\r$0$\r$1$\r$1$\r$1$\r$0$\r$0$\r$1$\r$0$\r$0$\r$1$\r$0$\r$1$\r$1$\r$0$\r$1$\r$1$\r$1$\r$0$\r$1$\r$1$\r$1$\r$1$\r$1$\r$1$\r$1$\r$1$\r$0$\rSummary (Assuming unrestricted use of projection and injection), the Toffoli gate $T$ is a universal gate. In other words, $\\left\\{ T \\right\\}$ is functionally complete.\nProof Theorem\nIf duplication functions are allowed, $\\left\\{ \\uparrow \\right\\}$ is functionally complete. In other words, the $\\text{NAND}$ gate $\\uparrow$ is a universal gate.\nAccording to the theorem above, showing that projection, injection, and $T$ can be used appropriately to express the duplication function $\\text{cl}$ and the $\\text{NAND}$ gate completes the proof.\nDuplication Function\n$$ \\operatorname{cl} = p_{1} \\circ T \\circ \\imath_{2} \\circ \\jmath_{1} $$\nHolds. First, calculating $T \\circ \\imath_{2} \\circ \\jmath_{1} (a)$ gives the following.\n$$ T \\circ \\imath_{2} \\circ \\jmath_{1} (a) = T \\circ \\imath_{2} (a, 1) = T (a, 1, 0) $$\nHere, if $a = 1$, then $T(1, 1, 0) = (1, 1, 1)$; if $a = 0$, then $T(0, 1, 0) = (0, 1, 0)$, so the following holds.\n$$ T(a, 1, 0) = (a, 1, a) $$\nTherefore, by taking $p_{1}$,\n$$ p_{1} \\circ T \\circ \\imath_{2} \\circ \\jmath_{1} (a) = p_{1} (a, 1, a) = (a, a) = \\operatorname{cl}(a) $$\n$\\text{NAND}$ Gate\n$$ p_{0} \\circ p_{1} \\circ T \\circ \\jmath_{2} = \\uparrow \\\\ p_{0} \\circ p_{1} \\circ T \\circ \\jmath_{2} (a, b) = a \\uparrow b $$\nHolds. Calculating in order gives the following.\n$$ \\begin{align*} p_{0} \\circ p_{1} \\circ T \\circ \\jmath_{2} (a, b) \u0026amp;= p_{0} \\circ p_{1} \\circ T (a, b, 1) \\\\ \u0026amp;= p_{0} \\circ p_{1} (a, b, (a \\land b) \\oplus 1) \\\\ \u0026amp;= p_{0} (a, (a \\land b) \\oplus 1) \\\\ \u0026amp;= (a \\land b) \\oplus 1 \\\\ \u0026amp;= \\lnot(a \\land b) = a \\uparrow b \\end{align*} $$\nThe last line holds due to the properties of the $\\text{XOR}$ gate.\n‚ñ†\nKim Young-hoon and Heo Jae-seong, Quantum Information Theory (2020), pp. 89-93\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3411,"permalink":"https://freshrimpsushi.github.io/en/posts/3411/","tags":null,"title":"Toffoli/CCNOT Gate"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 The following vector-valued Boolean function is called the $\\operatorname{CNOT}$ gateControlled NOT (CNOT) gate.\n$$ \\operatorname{CNOT} : \\left\\{ 0, 1 \\right\\}^{2} \\to \\left\\{ 0, 1 \\right\\}^{2} $$\n$$ \\operatorname{CNOT} (a,b) = (a, a \\oplus b) $$\nIt is also known as the Feynman gate.Feynman gate 2 Description The specific calculations of the input and output of the $\\operatorname{CNOT}$ gate are as follows.\n$$ \\begin{align*} \\operatorname{CNOT} (0,0) \u0026amp;= (0, 0 \\oplus 0) = (0, 0) \\\\ \\operatorname{CNOT} (0,1) \u0026amp;= (0, 0 \\oplus 1) = (0, 1) \\\\ \\operatorname{CNOT} (1,0) \u0026amp;= (1, 1 \\oplus 0) = (1, 1) \\\\ \\operatorname{CNOT} (1,1) \u0026amp;= (1, 1 \\oplus 1) = (1, 0) \\end{align*} $$\nLooking at the table above, it is easy to see that $\\operatorname{CNOT}$ is a reversible function and that composing $\\operatorname{CNOT}$ twice results in an identity function.\n$$ \\operatorname{Id} = \\operatorname{CNOT} \\circ \\operatorname{CNOT} $$\nIf only the second value of the output is considered, it is similar to the $\\text{XOR}$ gate, hence it is also referred to as the reversible $\\text{XOR}$ gate..\nÎ∂ÄÏö∏ Ìï®Ïàò\rÍ∏∞Ìò∏\rÏßÑÎ¶¨Ìëú\r$\\operatorname{CNOT}$\rÏûÖÎ†•\rÏ∂úÎ†•\r$a$\r$b$\r$a$\r$a \\oplus b$\r$0$\r$0$\r$0$\r$0$\r$0$\r$1$\r$0$\r$1$\r$1$\r$0$\r$1$\r$1$\r$1$\r$1$\r$1$\r$0$\rKim Young-hoon and Heo Jae-seong, Quantum Information Theory (2020), pp. 88-89\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/Controlled_NOT_gate\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3410,"permalink":"https://freshrimpsushi.github.io/en/posts/3410/","tags":null,"title":"Controlled NOT(CNOT) Gate"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Definition Difficult Definition 1 $$ \\Delta^{k} \\in K $$\nA complex is called a Simplicial Complex if a finite set of simplices $K$ satisfies the following two conditions:\n(i): If $\\sigma \\in K$ and $\\tau$ is a face of $\\sigma$, then $\\tau \\in K$. $$ \\sigma \\in K \\land \\tau \\le \\sigma \\implies \\tau \\in K $$ (ii): If $\\sigma_{1}, \\sigma_{2} \\in K$, then $\\sigma_{1} \\cap \\sigma_{2}$ is either an empty set or a face of both $\\sigma_{1}$ and $\\sigma_{2}$. $$ \\sigma_{1} , \\sigma_{2} \\in K \\implies \\left( \\sigma_{1} \\cap \\sigma_{2} = \\empty \\right) \\lor \\left( \\sigma_{1} \\cap \\sigma_{2} \\le \\sigma_{1} \\land \\sigma_{1} \\cap \\sigma_{2} \\le \\sigma_{2} \\right) $$ $\\land$ is logically the symbol for \u0026lsquo;and\u0026rsquo;, an and operation. $\\lor$ is logically the symbol for \u0026lsquo;or\u0026rsquo;, an or operation. A face of simplex $x$ is a simplex created by removing one point from $x$. For simplices $\\tau$, $\\sigma$, $\\tau \\le \\sigma$ means that $\\tau$ is a face of $\\sigma$. Simple Definition A Simplicial Complex is a collection of simplices, where every connecting part is a simplex itself.\nExplanation Simplices are meaningful and useful on their own, but by forming a Simplicial Complex, one can obtain an approximation of almost any abstract object with geometric characteristics. 2 For example, the following is the Triangulation of a dolphin shape, which is a simplicial complex made up of maximum $2$-simplices (triangles).\nThe simple definition implies vaguely connecting sets, a notion often breezily introduced and passed over in many documents and lectures. This approach favors demonstrating practical and application aspects of the simplicial complex over a rigorous definition, as showing a figure tends to be more comprehensible and explanatory.\nNaturally, for solo study with a book, one must precisely understand the challenging definitions. A simplicial complex $K$ is originally a family of sets of simplices $\\Delta^{k}$, each being the convex hull of $k$ affinely independent points, thus allowing for considerations of intersections like $\\sigma_{1} \\cap \\sigma_{2}$.\nPolygon By definition, Polygons look like simplicial complexes but are not since they include shapes like rectangles.\nSee Also A simplicial complex is defined as such if a set $K$ satisfies all the given conditions, without specific restrictions on its exact appearance. Depending on how one defines simplices, countless complexes can be imagined, and even with the same points (data), the practical characteristics can greatly vary among simplicial complexes.\nEdelsbrunner, Harer. (2010). Computational Topology An Introduction: p63.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/Triangulation_(topology)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2379,"permalink":"https://freshrimpsushi.github.io/en/posts/2379/","tags":null,"title":"Definition of Simplicial Complexes"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"Definition1 Let\u0026rsquo;s assume that a set of Boolean functions $\\left\\{ f_{k} \\right\\} = \\left\\{ f_{k} : \\left\\{ 0, 1 \\right\\}^{n_{k}} \\to \\left\\{ 0, 1 \\right\\} \\right\\}_{k\\in \\Gamma}$ is given. $\\Gamma$ is a finite set. If any Boolean function\n$$ \\left\\{ 0, 1 \\right\\}^{n} \\to \\left\\{ 0, 1 \\right\\}\\quad (n \\in \\mathbb{N}) $$\ncan be expressed by the compositions of $\\left\\{ f_{k} \\right\\}$, then the set $\\left\\{ f_{k} \\right\\}$ is called functionally complete.\nTheorem The set of $\\text{NOT}$ gates and $\\text{AND}$ gates $\\left\\{ \\lnot, \\land \\right\\}$ is functionally complete.\nExplanation In other words, all Boolean functions can be made by repetitions of $\\text{NOT}$ and $\\text{AND}$. There are infinitely many sets that are functionally complete, which are not unique. For instance, because $a \\land b = \\lnot(\\lnot a \\lor \\lnot b)$, $\\left\\{ \\lnot, \\lor \\right\\}$ is also a functionally complete set. From this theorem, it can be proven that a set is functionally complete if it can be shown to produce both $\\text{AND}$ gates and $\\text{NOT}$ gates.\nExamples of functionally complete sets:\n$\\text{NAND}$ gates $\\text{NOR}$ gates $T$(Toffoli gates) $F$(Fredkin gates) $\\left\\{ \\lnot, \\lor \\right\\}$ $\\left\\{ \\oplus, \\land \\right\\}$ Of course, there are cases where a duplication function is needed. If these results are described in the language of computer circuits, it can be stated as follows. All logical operations can be:\nimplemented in circuits using only $\\text{NOT}$ gates and $\\text{AND}$ gates. implemented in circuits using only $\\text{NAND}$ gates and duplication functions. implemented in circuits using only $\\text{NOR}$ gates and duplication functions. implemented in circuits using only Toffoli gates. implemented in circuits using only Fredkin gates. Universal Gates Especially, when a set composed solely of itself $\\left\\{ f \\right\\}$ is functionally complete, such a $f$ is called a universal gate. A universal gate can express all Boolean functions by itself. $\\text{NAND}$, $\\text{NOR}$, $T$, $F$ are universal gates.\nKim Young-Hoon and Heo Jae-Seong, Quantum Information Theory (2020), p88\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3408,"permalink":"https://freshrimpsushi.github.io/en/posts/3408/","tags":null,"title":"What is a Functionally Complete Set?"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition The square of the sphere $1$, denoted as $S^{1} \\times S^{1} = [0,1] \\times [0,1]$, and the quotient space $T$ that is homeomorphic to it according to the map shown above, is called a Torus. In the figure, the donut shape on the far right is an example of a torus.\nDescription The torus is a space - more specifically, a figure - that is treated very preciously throughout mathematics. It invariably appears in the image of topology known to the public (like the doughnut is homeomorphic to a coffee cup and so on).\nPoincar√© Conjecture The Poincar√© conjecture, proposed by the great French mathematician Henri Poincar√© and proven by Grigori Perelman, states:\nPoincar√© Conjecture: If every simple closed curve on a closed $3$-dimensional manifold can be contracted to a point, then the space can be transformed into a sphere.\nAlthough the torus is not necessarily crucial to this conjecture, it serves as the simplest example that even non-specialists can instantly understand. For instance, if we were to loop a red string around the surface of the torus as shown in the picture, shrinking it to a point would be impossible due to the doughnut hole. The Poincar√© conjecture, conversely, asks if having such closed curves always contractible to a point guarantees that the space is a sphere without a doughnut hole.\nAlgebraic Topology In fact, to create a torus, a square $S^{1} \\times S^{1}$ is sufficient without the need for a simplex complex, i.e., a simplicial complex. However, to engage in meaningful algebraic investigations of the structure resulting from a $\\Delta$-complex](../2381), the following $6$ maps are necessary.\nThis is a projection view of the torus from above. $\\sigma_{a}$, $\\sigma_{b}$, $\\sigma_{v}$ represent mappings that act as a sort of \u0026lsquo;skeleton\u0026rsquo; in the naive method of creating a torus. $\\sigma_{b}$ rolls the square into a cylinder, and $\\sigma_{a}$ connects the ends of that cylinder to form a doughnut. Here, the vertices of the square must converge precisely to one point, and $\\sigma_{v}$ fulfills this role.\nThis is a side-projection view of the torus. $\\sigma_{U}$, $\\sigma_{L}$ map out the \u0026lsquo;faces\u0026rsquo;, so to speak, that fill in between the skeleton. It\u0026rsquo;s worth reiterating that $\\sigma_{c}$ is not strictly necessary when considering only the torus, but becomes relevant when viewing the square as a union of two triangles and pertaining to mapping their boundaries.\nPeriodic Boundary Conditions A torus can also be considered as a unit square $[0,1] \\times [0,1]$ with Periodic Boundary Conditions applied. In the following image, the golfer\u0026rsquo;s ball seems to exit beyond the boundary of $S^{1} \\times S^{1}$ at first glance. However, were this shot taken on a torus, the ball would end up falling behind the golfer.\nNaturally, this phenomenon doesn\u0026rsquo;t only occur on the left and right boundaries but also on the top and bottom periodic boundaries $b$. Viewing a square as a torus is thus a concise way of expressing that \u0026ldquo;boundaries have periodicity, so reaching one edge brings you out on the opposite edge.\u0026rdquo;\nInfinite Plane Though it sounds the same as periodic boundary conditions, viewing this space differently can open up new applications. Consider, for example, ignoring the geography where certain organisms are situated in ecological studies and assuming that the interactions among them occur uniformly throughout the entire space.\nImagine laying out the square, which unfolds the torus, as shown in the above figure, aligning with the boundary. A single torus thus effectively represents part of an infinite plane. If conducting a simulation, a simulation on a single torus could be considered, without loss of generality, as a simulation on an infinite plane.\nProperties Coordinate Chart Mapping The coordinate chart mapping of a 3-dimensional torus with the distance from the center to the tube as $R$ and the diameter of the tube as $r$ is as follows, regarding $(u_{1}, u_{2}) \\in [0, 2\\pi) \\times [0, 2\\pi)$:\n$$ \\mathbf{x}(u_{1}, u_{2}) = \\left( (R + r\\cos u_{2})\\cos u_{1}, (R + r\\cos u_{2})\\sin u_{1}, r\\sin u_{1} \\right) $$\nSimple Connectivity The torus $T^{2}$ is not simply connected.\n","id":2377,"permalink":"https://freshrimpsushi.github.io/en/posts/2377/","tags":null,"title":"What is a Torus in Mathematics?"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 The following Boolean function is called the $\\text{NOR}$ gateNOR gate or negated logical sum and is denoted as follows.\n$$ \\downarrow : \\left\\{ 0, 1 \\right\\}^{2} \\to \\left\\{ 0, 1 \\right\\} $$\n$$ 0\\downarrow 0 = 1,\\quad 0\\downarrow 1 = 0,\\quad 1\\downarrow 0 = 0,\\quad 1\\downarrow 1 = 0 $$\nDescription It is a composition of the $\\text{NOT}$ gate and the $\\text{OR}$ gate, and it is named $\\text{NOR}$ by borrowing $\\text{N(OT)}$ and $\\text{OR}$.\n$$ \\begin{equation} \\downarrow = \\lnot \\circ \\lor \\end{equation} $$\n$$ a \\downarrow b = \\lnot (a \\lor b) $$\nIt operates opposite to the $\\text{OR}$ gate and produces a true output only when all inputs are false. Furthermore, $\\left\\{ \\downarrow \\right\\}$ is functionally complete, which can be seen as obvious due to $(1)$.\nÎ∂ÄÏö∏ Ìï®Ïàò\rÍ∏∞Ìò∏\rÏßÑÎ¶¨Ìëú\r$\\text{NOR}$\r$a$\r$b$\r$a \\downarrow b$\r$0$\r$0$\r$1$\r$0$\r$1$\r$0$\r$1$\r$0$\r$0$\r$1$\r$1$\r$0$\rSummary If the replication function is allowed, then $\\left\\{ \\downarrow \\right\\}$ is functionally complete. In other words, $\\downarrow$ is a universal gate.\nProof Theorem\nThe set of $\\text{NOT}$ and $\\text{OR}$ gates, $\\left\\{ \\lnot, \\lor \\right\\}$, is functionally complete.\nAccording to the above theorem, it suffices to show that the $\\text{NOT}$ gate and the $\\text{OR}$ gate can be made only with the replication function $\\text{cl}$ and $\\downarrow$.\n$\\text{NOT}$ gate\n$$ \\lnot = \\downarrow \\circ \\operatorname{cl} \\\\ \\lnot a = a \\downarrow a $$\nholds.\n$$ \\begin{align*} \\downarrow \\circ \\operatorname{cl}(0) = 0 \\downarrow 0 = 1 = \\lnot 0 \\\\ \\downarrow \\circ \\operatorname{cl}(1) = 1 \\downarrow 1 = 0 = \\lnot 1 \\\\ \\end{align*} $$\n$\\text{OR}$ gate\n$$ \\lor = \\downarrow \\circ \\operatorname{cl} \\circ \\downarrow \\\\ a \\lor b = (a \\downarrow b) \\downarrow (a \\downarrow b) $$\nholds.\n$$ \\begin{align*} (0 \\downarrow 0) \\downarrow (0 \\downarrow 0) = (1 \\downarrow 1) = 0 = 0 \\lor 0 \\\\ (0 \\downarrow 1) \\downarrow (0 \\downarrow 1) = (0 \\downarrow 0) = 1 = 0 \\lor 1 \\\\ (1 \\downarrow 0) \\downarrow (1 \\downarrow 0) = (0 \\downarrow 0) = 1 = 1 \\lor 0 \\\\ (1 \\downarrow 1) \\downarrow (1 \\downarrow 1) = (1 \\downarrow 1) = 1 = 1 \\lor 1 \\\\ \\end{align*} $$\n‚ñ†\nKim Young-hoon and Heo Jae-seong, Quantum Information Theory (2020), p86-87\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3407,"permalink":"https://freshrimpsushi.github.io/en/posts/3407/","tags":null,"title":"NOR Gate"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 The following Boolean function is called a $\\text{NAND}$ GateNAND gate or Negated Logical Product and is denoted as follows.\n$$ \\uparrow : \\left\\{ 0, 1 \\right\\}^{2} \\to \\left\\{ 0, 1 \\right\\} $$\n$$ 0\\uparrow 0 = 1,\\quad 0\\uparrow 1 = 1,\\quad 1\\uparrow 0 = 1,\\quad 1\\uparrow 1 = 0 $$\nDescription It is a composition of the $\\text{NOT}$ Gate and $\\text{AND}$ Gate, and is named $\\text{NAND}$ by adopting $\\text{N(OT)}$ and $\\text{AND}$.\n$$ \\begin{equation} \\uparrow = \\lnot \\circ \\land \\end{equation} $$\n$$ a \\uparrow b = \\lnot (a \\land b) $$\nIt operates opposite to the $\\text{AND}$ Gate, outputting false only when all inputs are true. Additionally, $\\left\\{ \\uparrow \\right\\}$ is functionally complete, which is considered obvious due to $(1)$.\nÎ∂ÄÏö∏ Ìï®Ïàò\rÍ∏∞Ìò∏\rÏßÑÎ¶¨Ìëú\r$\\text{NAND}$\r$a$\r$b$\r$a \\uparrow b$\r$0$\r$0$\r$1$\r$0$\r$1$\r$1$\r$1$\r$0$\r$1$\r$1$\r$1$\r$0$\rSummary If the replication function is allowed, $\\left\\{ \\uparrow \\right\\}$ is functionally complete. In other words, $\\uparrow$ is a universal gate.\nProof Theorem\nThe set of $\\text{NOT}$ and $\\text{AND}$ Gates, $\\left\\{ \\lnot, \\land \\right\\}$, is functionally complete.\nAccording to the above theorem, it is sufficient to show that the $\\text{NOT}$ Gate and the $\\text{AND}$ Gate can be created solely using the replication function $\\text{cl}$ and $\\uparrow$.\n$\\text{NOT}$ Gate\n$$ \\lnot = \\uparrow \\circ \\operatorname{cl} \\\\ \\lnot a = a \\uparrow a $$\nholds.\n$$ \\begin{align*} \\uparrow \\circ \\operatorname{cl}(0) = 0 \\uparrow 0 = 1 = \\lnot 0 \\\\ \\uparrow \\circ \\operatorname{cl}(1) = 1 \\uparrow 1 = 0 = \\lnot 1 \\\\ \\end{align*} $$\n$\\text{AND}$ Gate\n$$ \\land = \\uparrow \\circ \\operatorname{cl} \\circ \\uparrow \\\\ a \\land b = (a \\uparrow b) \\uparrow (a \\uparrow b) $$\nholds.\n$$ \\begin{align*} (0 \\uparrow 0) \\uparrow (0 \\uparrow 0) = (1 \\uparrow 1) = 0 = 0 \\land 0 \\\\ (0 \\uparrow 1) \\uparrow (0 \\uparrow 1) = (0 \\uparrow 0) = 0 = 0 \\land 1 \\\\ (1 \\uparrow 0) \\uparrow (1 \\uparrow 0) = (0 \\uparrow 0) = 0 = 1 \\land 0 \\\\ (1 \\uparrow 1) \\uparrow (1 \\uparrow 1) = (1 \\uparrow 1) = 1 = 1 \\land 1 \\\\ \\end{align*} $$\n‚ñ†\nKim Young-Hoon \u0026amp; Heo Jae-Seong, Quantum Information Theory (2020), pp. 86-87\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3406,"permalink":"https://freshrimpsushi.github.io/en/posts/3406/","tags":null,"title":"NAND Gate"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 julia\u0026gt; Dict([\u0026#34;a\u0026#34;, \u0026#34;bc\u0026#34;] .=\u0026gt; [2,8])\rDict{String, Int64} with 2 entries:\r\u0026#34;a\u0026#34; =\u0026gt; 2\r\u0026#34;bc\u0026#34; =\u0026gt; 8 Given two arrays you want to use as keys and values, you can create a dictionary using Dict(Key .=\u0026gt; Value). Essentially, it\u0026rsquo;s nothing more than broadcasting the =\u0026gt; operator to create pairs.\nEnvironment OS: Windows julia: v1.7.0 https://discourse.julialang.org/t/create-a-dictionary-from-arrays-of-keys-and-values/13908/3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2375,"permalink":"https://freshrimpsushi.github.io/en/posts/2375/","tags":null,"title":"Creating Dictionaries from Arrays in Julia"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 The following Boolean function is referred to as a $\\text{XOR}$ gateXOR gate or exclusive disjunctionexclusive disjunction/or and is denoted as follows:\n$$ \\oplus : \\left\\{ 0, 1 \\right\\}^{2} \\to \\left\\{ 0, 1 \\right\\} $$\n$$ 0\\oplus 0 = 0,\\quad 0\\oplus 1 = 1,\\quad 1\\oplus 0 = 1,\\quad 1\\oplus 1 = 0 $$\nExplanation The $\\text{XOR}$ gate returns true when only one of the two truth values is true, i.e., when the number of true values is odd. In other words, it returns $0$ if the two values are the same and $1$ if they are different, making it useful for implementing a function to compare if two values are the same.\nThe period between 1974 and 1980, marked by the critique that \u0026ldquo;Perceptrons cannot solve the $\\text{XOR}$ problem,\u0026rdquo; leading to a stagnation in AI development, is referred to as the AI winterAI winter.\nÎ∂ÄÏö∏ Ìï®Ïàò\rÍ∏∞Ìò∏\rÏßÑÎ¶¨Ìëú\r$\\text{XOR}$\r$a$\r$b$\r$a \\oplus b$\r$0$\r$0$\r$0$\r$0$\r$1$\r$1$\r$1$\r$0$\r$1$\r$1$\r$1$\r$0$\rProperties This can be expressed with $\\text{NOT}$ gate, $\\text{AND}$ gate, and $\\text{OR}$ gate.\n$$ \\begin{align*} a \\oplus b \u0026amp;= (a \\land \\lnot b) \\lor (\\lnot a \\land b) \\\\ \u0026amp;= (a \\lor b) \\land (\\lnot a \\lor \\lnot b) \\\\ \u0026amp;= (a \\lor b) \\land \\lnot (a \\land b) \\end{align*} $$\n$a \\oplus 1 = \\lnot a$ is valid.\n$a \\oplus 0 = a$ is valid.\nKim Young-hoon¬∑Heo Jae-seong, Quantum Information Theory (2020), p85\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3405,"permalink":"https://freshrimpsushi.github.io/en/posts/3405/","tags":null,"title":"Exclusive Disjuction, XOR Gate"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Overview In mathematics, the term \u0026ldquo;Complex\u0026rdquo; usually refers to complex numbers, but in geometry or topology, \u0026ldquo;Complex\u0026rdquo; signifies something like the following terms.\nTerminology A Complex is made up of topologically simple $S$s, whose intersections are of a lower dimension but of the same kind as $S$.\nDescription As this ambiguous expression suggests, there isn\u0026rsquo;t exactly a \u0026lsquo;definition\u0026rsquo;.\nWhether we call the simple things a Simplex or refer to Complex as a Complex, minor details are not our focus. When we mention \u0026ldquo;Complex\u0026rdquo; in this context, one can just assume that\u0026rsquo;s what is being referred to and move on. A Complex can vary significantly depending on the method, and understanding its types becomes natural after seeing a few specific examples.\n","id":2374,"permalink":"https://freshrimpsushi.github.io/en/posts/2374/","tags":null,"title":"What is a Complex in Topology?"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 A Boolean function like the following is called a $\\text{NOT}$ gateNOT gate or logical negationnegation and is denoted as follows.\n$$ \\lnot : \\left\\{ 0, 1 \\right\\} \\to \\left\\{ 0, 1 \\right\\} $$\n$$ \\lnot 0 = 1,\\quad \\lnot 1 = 0 $$\nDescription The $\\text{NOT}$ gate returns the opposite of the input.\nÎ∂ÄÏö∏ Ìï®Ïàò\rÍ∏∞Ìò∏\rÏßÑÎ¶¨Ìëú\r$\\text{NOT}$\r$a$\r$\\lnot a$\r$0$\r$1$\r$1$\r$0$\rKim Young-hoon and Heo Jae-seong, Quantum Information Theory (2020), p84-85\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3404,"permalink":"https://freshrimpsushi.github.io/en/posts/3404/","tags":null,"title":"Negation, NOT Gate"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, complex numbers are natively supported, similar to R.\nCode Imaginary unit im julia\u0026gt; z = 3 + 4im\r3 + 4im im represents the pure imaginary unit $i = \\sqrt{-1}$. All the common arithmetic operations that we are familiar with can be used.\njulia\u0026gt; typeof(z)\rComplex{Int64}\rjulia\u0026gt; typeof(3.0 + 4.0im)\rComplexF64 (alias for Complex{Float64}) When checking the type, even though it\u0026rsquo;s the same complex number, the type of complex number it consists of differs. Similar to how in abstract algebra, it is distinguished whether it is an integer, in the case of $\\mathbb{Z} [i]$, or a real number, in the case of $\\mathbb{R} [i]$.\nReal and imaginary parts real(), imag() julia\u0026gt; real(z)\r3\rjulia\u0026gt; imag(z)\r4 Conjugate and modulus conj(), abs() julia\u0026gt; conj(z)\r3 - 4im\rjulia\u0026gt; abs(z)\r5.0 Note that here, the modulus abs() is not specifically redefined for complex numbers but is used in its general sense of absolute value. Julia has polymorphism, which allows for this design to be naturally well-implemented.\nGeneral complex functions julia\u0026gt; cos(z)\r-27.034945603074224 - 3.851153334811777im\rjulia\u0026gt; log(z)\r1.6094379124341003 + 0.9272952180016122im As expected, just like with absolute values, trigonometric functions and logarithmic functions are well defined for complex numbers $\\mathbb{C}$ and can be used directly in Julia without any special manipulation.\nComplete Code z = 3 + 4im\rreal(z)\rimag(z)\rconj(z)\rabs(z)\rcos(z)\rlog(z) Environment OS: Windows julia: v1.7.0 ","id":2373,"permalink":"https://freshrimpsushi.github.io/en/posts/2373/","tags":null,"title":"How to Use Complex Numbers in Julia"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 The following Boolean function is called $\\text{OR}$ GateOR gate or Disjunctiondisjunction, and it is denoted as follows.\n$$ \\lor : \\left\\{ 0, 1 \\right\\}^{2} \\to \\left\\{ 0, 1 \\right\\} $$\n$$ 0\\lor 0 = 0,\\quad 0\\lor 1 = 1,\\quad 1\\lor 0 = 1,\\quad 1\\lor 1 = 1 $$\nDescription $\\text{OR}$ Gate sends two truth values to one truth value, and it returns true if there is at least one true value among the two.\nÎ∂ÄÏö∏ Ìï®Ïàò\rÍ∏∞Ìò∏\rÏßÑÎ¶¨Ìëú\r$\\text{OR}$\r$a$\r$b$\r$a \\lor b$\r$0$\r$0$\r$0$\r$0$\r$1$\r$1$\r$1$\r$0$\r$1$\r$1$\r$1$\r$1$\rThis can be expressed with $\\text{NOT}$ Gate and $\\text{AND}$ Gate.\n$$ a \\lor b = \\lnot(\\lnot a \\land \\lnot b) $$\nKim Young-hoon¬∑Heo Jae-seong, Quantum Information Theory (2020), p84\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3403,"permalink":"https://freshrimpsushi.github.io/en/posts/3403/","tags":null,"title":"Disjunction, OR Gate"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Definition 1 In the Euclidean space $\\left( \\mathbb{R}^{n} , \\left\\| \\cdot \\right\\| \\right)$, the following shapes are defined.\nDefined as $D^{n} \\subset \\mathbb{R}^{n}$, this is called $n$-Unit Disk. $$ D^{n} := \\left\\{ \\mathbf{x} \\in \\mathbb{R}^{n} : \\left\\| \\mathbf{x} \\right\\| \\le 1 \\right\\} $$ Defined as $S^{n} \\subset \\mathbb{R}^{n+1}$, this is called $n$-Unit Sphere. $$ S^{n} := \\left\\{ \\mathbf{x} \\in \\mathbb{R}^{n+1} : \\left\\| \\mathbf{x} \\right\\| = 1 \\right\\} $$ An open subset $e^{n}$ that is homeomorphic to $D^{n} \\setminus \\partial D^{n}$ is also referred to as $n$-Cell. Properties The boundary of a $n$-disk is a $n$-sphere. In other words, the following holds true. $$ \\partial D^{n} = S^{n-1} $$\nExplanation Disks and spheres are easier to understand when viewed from the perspective of $n=2$. In terms of representation, a $2$-disk is like the disks we encounter in daily life, a completely filled circular plate, while the $2$-sphere represents just the surface of a sphere at a higher $2+1$ dimension, without volume but with surface area.\nAs defined, $D^{3}$, though it does not look like a disk, is indeed a disk. Meanwhile, a cell, as seen, is defined through homeomorphism, so it does not necessarily need to be accurately defined as a set like disks and spheres.\nThis can be understood to mean that cells are free in terms of shape, size, and position, and by thinking about cells in this way, the widely known appearance of topology is revealed.\nWhen $n=0$ When it\u0026rsquo;s $n = 0$, it is $D^{0} = \\left\\{ 0 \\right\\}$, and $e^{n}$ consists of a single point that is homeomorphic to it, but $S^{0}$ immediately implies that it has two points.\nSee Also General Definition of a Sphere A general sphere can be more mathematically defined through an inner product, and indeed, it can be easily generalized to an ellipsoid as well. However, disks and spheres are most commonly mentioned in topology, where specific coordinates or geometric properties are not strictly necessary.\nHatcher. (2002). Algebraic Topology: p xii.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2372,"permalink":"https://freshrimpsushi.github.io/en/posts/2372/","tags":null,"title":"Topology in Mathematics: Discs and Spheres"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 The following Boolean function is called the $\\text{AND}$ gateAND gate or logical conjunctionconjunction and is denoted as follows.\n$$ \\land : \\left\\{ 0, 1 \\right\\}^{2} \\to \\left\\{ 0, 1 \\right\\} $$\n$$ 0\\land 0 = 0,\\quad 0\\land 1 = 0,\\quad 1\\land 0 = 0,\\quad 1\\land 1 = 1 $$\nExplanation The $\\text{AND}$ gate sends two truth values to one truth value, and returns true only when both truth values are true.\nÎ∂ÄÏö∏ Ìï®Ïàò\rÍ∏∞Ìò∏\rÏßÑÎ¶¨Ìëú\r$\\text{AND}$\r$a$\r$b$\r$a \\land b$\r$0$\r$0$\r$0$\r$0$\r$1$\r$0$\r$1$\r$0$\r$0$\r$1$\r$1$\r$1$\rThis can be expressed with $\\text{NOT}$ gate and $\\text{OR}$ gate.\n$$ a \\land b = \\lnot(\\lnot a \\lor \\lnot b) $$\nKim Young-hoon and Heo Jae-sung, Quantum Information Theory (2020), p84\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3402,"permalink":"https://freshrimpsushi.github.io/en/posts/3402/","tags":null,"title":"Conjunction, AND Gate"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 The following function is called a Boolean function. For $n \\in \\mathbb{N}$,\n$$ f : \\left\\{ 0, 1 \\right\\}^{n} \\to \\left\\{ 0, 1 \\right\\} $$\nHere, $1 =$ means true, and $0 =$ means false.\nGeneralization For $n, m \\in \\mathbb{N} (m \\gt 2)$,\n$$ f : \\left\\{ 0, 1 \\right\\}^{n} \\to \\left\\{ 0, 1 \\right\\}^{m} $$\nThis is called a vector-valued Boolean function.\nExplanation Named after the British mathematician George Boole. George Boole was the founder of Boolean algebra, and by algebraically dealing with logic, he greatly influenced symbolic logic.\nThe Boolean function is also called a Boolean operation or a logical operation/connective.\nIn computer theory, since $1$ and $0$ respectively mean the presence and absence of an electrical signal, they are referred to as gates due to the understanding that electrical signals come in and out. Therefore, the combination of multiple gates is called a circuit.\nReversible Functions According to Landauer\u0026rsquo;s principle, energy is used every time information is lost, thus, there is an interest in one-to-one Boolean functions from a computing efficiency aspect. One-to-one Boolean functions are called reversible, and those that are not are called non reversible. To be reversible, it must naturally be $m=n$. The reversible functions include the following.\n$\\operatorname{CNOT}$ Gate Toffoli Gate Fredkin Gate Types $\\text{AND}$ Gate $\\text{OR}$ Gate $\\text{NOT}$ Gate $\\text{XOR}$ Gate $\\text{NAND}$ Gate $\\text{NOR}$ Gate\n${}$ Cloning function $\\text{cl}$ Projection $p_{i}$ Injection $\\imath_{i}$, $\\jmath_{i}$ Kim Young-Hoon \u0026amp; Hur Jae-Seong, Quantum Information Theory (2020), p85\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3401,"permalink":"https://freshrimpsushi.github.io/en/posts/3401/","tags":null,"title":"Boolean Functions"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rÏ†ïÏùò1 Ïù¥ÏÇ∞ÌôïÎ•†Î≥ÄÏàò $X$Ïóê ÎåÄÌï¥ÏÑú, $X=x$Ïù∏ ÏÇ¨Í±¥Ïùò Ï†ïÎ≥¥(Îüâ)information $I$Î•º Îã§ÏùåÍ≥º Í∞ôÏù¥ Ï†ïÏùòÌïúÎã§.\n$$ \\begin{equation} I(x) = -\\log_{2} p(x) \\end{equation} $$\n$p$Îäî $X$Ïùò ÌôïÎ•†ÏßàÎüâÌï®ÏàòÏù¥Îã§.\nÏÑ§Î™Ö Ï∂îÏÉÅÏ†Å Í∞úÎÖêÏù∏ Ï†ïÎ≥¥Ïóê ÎåÄÌïú Ï†ïÎüâÏ†ÅÏù∏ Ï†ïÏùòÎ•º Ï†úÏãúÌïú ÏÇ¨ÎûåÏùÄ ÎîîÏßÄÌÑ∏ ÎÖºÎ¶¨ÌöåÎ°ú Ïù¥Î°†Í≥º Ï†ïÎ≥¥Ïù¥Î°†ÏùÑ Ï∞ΩÏãúÌïú ÌÅ¥ÎûòÎìú ÏÑÄÎÑåClaude ShannonÏù¥Îã§. Ï†ïÎ≥¥ÎüâÎ•º 'ÌôïÎ•†Ïùò ÎßàÏù¥ÎÑàÏä§ Î°úÍ∑∏'Î°ú Ï†ïÏùòÌïú Í≤ÉÏùÑ Ï≤òÏùå Î≥º ÎïåÎäî Ïù¥Ìï¥Í∞Ä ÏïàÎêòÍ≤†ÏßÄÎßå, ÏÑ§Î™ÖÏùÑ Îì£Í≥† ÎÇòÎ©¥ Ïù¥Î≥¥Îã§ ÏûêÏó∞Ïä§Îü¨Ïö∏ Ïàò ÏóÜÎã§Îäî ÏÉùÍ∞ÅÏù¥ Îì§ Í≤ÉÏù¥Îã§.\nÏ†ïÎ≥¥Ïùò Í∞ÄÏπòÎäî ÏùºÏñ¥ÎÇòÍ∏∞ ÌûòÎì† ÏùºÏùºÏàòÎ°ù, Í∑∏Îü¨ÎãàÍπå ÏùºÏñ¥ÎÇ† ÌôïÎ•†Ïù¥ Ìù¨Î∞ïÌï†ÏàòÎ°ù ÌÅ¨Îã§. Í∞ÄÎ†π \u0026quot;ÎÇ¥Ïùº Î¨ºÎ¶¨Í≥º Í±¥Î¨ºÏóê Î¨ºÎ¶¨Í≥º ÌïôÍ≥ºÏû•ÎãòÏù¥ Ïò§Ïã†Îã§\u0026quot;Îäî Î¨∏Ïû•Ïù¥ Í∞ñÍ≥† ÏûàÎäî Ï†ïÎ≥¥ÎüâÏùÄ Í±∞Ïùò ÏóÜÎã§Í≥† Î≥º Ïàò ÏûàÎã§. ÎãπÏó∞Ìûà ÎÇ¥Ïùº ÌïôÍ≥ºÏû•Ïù¥ Ï∂úÍ∑ºÌï† Í≤ÉÏù¥Í∏∞ ÎïåÎ¨∏Ïù¥Îã§. Î∞òÎ©¥Ïóê \u0026quot;ÎÇ¥Ïùº Î¨ºÎ¶¨Í≥º Í±¥Î¨ºÏóê ÏïÑÏù¥Î∏åÍ∞Ä Ïò®Îã§\u0026quot;Îäî Î¨∏Ïû•ÏùÄ ÏôÑÏ†ÑÌûà ÌäπÍ∏â Ï†ïÎ≥¥Ïù¥Îã§. ÏïÑÏù¥Î∏åÍ∞Ä Îú¨Í∏àÏóÜÏù¥ Î¨ºÎ¶¨Í≥º Í±¥Î¨ºÏóê Îì±Ïû•Ìï† ÌôïÎ•†ÏùÄ Í±∞Ïùò ÏóÜÎã§ÏãúÌîºÌïòÎØÄÎ°ú, Ïù¥Îü∞ Ï†ïÎ≥¥Îäî Í∞ÄÏπòÍ∞Ä ÏïÑÏ£º ÎÜíÏùÄ Ï†ïÎ≥¥ÎùºÍ≥† Ìï† Ïàò ÏûàÎã§. Îã§Î•∏ ÏòàÎ°ú \u0026quot;ÎÇ¥Ïùº ÏÇºÏÑ±Ï†ÑÏûêÏùò Ï£ºÏãù ÏÉÅÏäπÌè≠Ïù¥ $1 \\%$ Ìè¨Ïù∏Ìä∏ Ïù¥ÎÇ¥Ïù¥Îã§\u0026quot;Îäî Í±∞Ïùò Í∞ÄÏπòÍ∞Ä ÏóÜÎäî Ï†ïÎ≥¥Ïù¥Í≤†ÏßÄÎßå, \u0026quot;ÎÇ¥Ïùº ÏÇºÏÑ±Ï†ÑÏûêÏùò Ï£ºÏãùÏù¥ ÏÉÅÌïúÍ∞ÄÎ•º ÏπúÎã§\u0026quot;Îäî ÏóÑÏ≤≠ÎÇú Ï†ïÎ≥¥Ïù¥Îã§. Îî∞ÎùºÏÑú ÏùºÏñ¥ÎÇ† ÌôïÎ•†Ïù¥ Ï†ÅÏùÄ ÏÇ¨Í±¥Ïù¥ ÎßéÏùÄ Ï†ïÎ≥¥Î•º Í∞ñÍ≥†ÏûàÎã§Í≥† Î≥º Ïàò ÏûàÎã§.\nÌôïÎ•†Ïùò Ìï®Ïà´Í∞íÏùÄ $0 \\le p \\le 1$Ïù¥ÎØÄÎ°ú, $p$Í∞Ä ÏûëÏùÑÏàòÎ°ù Ï†ïÎ≥¥Ïùò Ìï®Ïà´Í∞íÏù¥ Ïª§ÏßÄÎèÑÎ°ù ÌïòÎ†§Î©¥ ÎßàÏù¥ÎÑàÏä§ Î°úÍ∑∏Î•º Ï∑®ÌïòÎ©¥ ÎêúÎã§. Îî∞ÎùºÏÑú ÏûêÏó∞Ïä§ÎüΩÍ≤å Ï†ïÎ≥¥Î•º $(1)$Í≥º Í∞ôÏù¥ Ï†ïÏùòÌï† Ïàò ÏûàÎã§.\n$-\\log_{2}(x)$Ïùò ÏπòÏó≠Ïù¥ $[0, \\infty)$Ïù¥ÎØÄÎ°ú ÌôïÎ•†Ïù∏ $1$Ïù∏ ÏÇ¨Í±¥, Í∑∏Îü¨ÎãàÍπå Î∞òÎìúÏãú ÏùºÏñ¥ÎÇòÎäî ÏùºÏùÄ Ï†ïÎ≥¥ÎüâÏù¥ $0$Ïù¥Îã§. ÎòêÌïú ÏùºÏñ¥ÎÇ† ÌôïÎ•†Ïù¥ ÎÇÆÏïÑÏßàÏàòÎ°ù Ï†ïÎ≥¥Ïùò Í∞ÄÏπòÎäî Í≥ÑÏÜç Ïª§ÏßÑÎã§.\nÌôïÎ•†Î≥ÄÏàò $X$ ÏûêÏ≤¥Ïóê ÎåÄÌïú Ï†ïÎ≥¥ÎüâÏùÄ ÏóîÌä∏Î°úÌîºÎùº Î∂ÄÎ•∏Îã§.\nÍ∞ôÏù¥Î≥¥Í∏∞ ÌôïÎ•†Ï†ïÎ≥¥Ïù¥Î°†ÏóêÏÑú Ï†ïÏùòÎêòÎäî Ï†ïÎ≥¥ ÍπÄÏòÅÌõà¬∑ÌóàÏû¨ÏÑ±, ÏñëÏûê Ï†ïÎ≥¥ Ïù¥Î°† (2020), p246\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3398,"permalink":"https://freshrimpsushi.github.io/en/posts/3398/","tags":null,"title":"Í≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†ÏóêÏÑú Ï†ïÎ≥¥ÎüâÏù¥ÎûÄ?"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition The matrix of size $m\\times n$ with all elements being $0$ is called a zero matrix, and is denoted as $O_{m\\times n}$ or simply as $O$.\nDescription Other notations include $Z_{m \\times n}$, $Z$, $\\mathbf{0}_{m\\times n}$, or $\\mathbf{0}$. It is better to write the number $0$ in bold to avoid confusion (actually, it is better just to use $O$). A zero matrix is the identity element for matrix addition. That is, the following equation holds for any matrix $m\\times n$ $A$.\n$$ A + O_{m\\times n} = A = O_{m\\times n} + A $$\n","id":3394,"permalink":"https://freshrimpsushi.github.io/en/posts/3394/","tags":null,"title":"Zero Matrix"},{"categories":"ÏµúÏ†ÅÌôîÏù¥Î°†","contents":"Buildup For $x_{1} , x_{2} \\ge 0$, let\u0026rsquo;s say we have the following linear programming problem. $$ \\begin{matrix} \\text{Maximize} \u0026amp; \u0026amp; 2x_{1} \u0026amp; + \u0026amp; 3x_{2} \\\\ \\text{subject to} \u0026amp; \u0026amp; 4x_{1} \u0026amp; + \u0026amp; 8x_{2} \u0026amp; \\le \u0026amp; 12 \\\\ \u0026amp; \u0026amp; 2x_{1} \u0026amp; + \u0026amp; x_{2} \u0026amp; \\le \u0026amp; 3 \\\\ \u0026amp; \u0026amp; 3x_{1} \u0026amp; + \u0026amp; 2x_{2} \u0026amp; \\le \u0026amp; 4 \\end{matrix} $$\nOur goal is to find the optimal solution $x_{1}^{\\ast}, x_{2}^{\\ast}$ that maximizes the objective function $\\zeta = 2x_{1} + 3x_{2}$ under given constraints. However, upon examining the equation, it\u0026rsquo;s clear that there\u0026rsquo;s an upper bound to the maximum value even without solving the problem. From the first constraint, $$ 2x_{1} + 3x_{2} \\le 4x_{1} + 8x_{2} \\le 12 $$ and indeed, if both sides of $4x_{1} + 8x_{2} \\le 12$ are divided by $2$, $$ 2x_{1} + 3x_{2} \\le 2x_{1} + 4x_{2} \\le 6 $$ it can be seen that the value of the objective function cannot exceed $6$. Not only that, but considering the second constraint, $$ 2x_{1} + 3x_{2} = {{ 1 } \\over { 3 }} \\left( 4x_{1} + 8x_{2} + 2x_{1} + x_{2} \\right) \\le {{ 1 } \\over { 3 }} (12 + 3) = 5 $$ it\u0026rsquo;s possible to further reduce the upper bound as shown. In other words, $$ d_{1} x_{1} + d_{2} x_{2} \\le h $$ when there\u0026rsquo;s such an inequality, it suggests we could approach by narrowing down $h$. Since the objective function itself is bounded, continuing to reduce this upper limit until it can\u0026rsquo;t be reduced any further will eventually lead us to the minimum value of the upper limit, which turns out to be another optimization problem in itself. Intuitively, whether solving the original maximization problem or the problem of minimizing the upper limit, it seems we can arrive at the same conclusion.\nEspecially, the form of $d_{1} x_{1} + d_{2} x_{2} \\le h$ looks like it could be a constraint of \u0026lsquo;another linear programming problem.\u0026rsquo; Therefore, the \u0026lsquo;other linear programming problem\u0026rsquo; is defined as follows.\nDefinition 1 $$ \\begin{matrix} \\text{Maximize} \u0026amp; \\mathbf{c}^{T} \\mathbf{x} \\\\ \\text{subject to} \u0026amp; A \\mathbf{x} \\le \\mathbf{b} \\\\ \u0026amp; \\mathbf{x} \\ge \\mathbf{0} \\end{matrix} $$\nLet\u0026rsquo;s say there\u0026rsquo;s a linear programming problem given like above for matrices $A \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{b} \\in \\mathbb{R}^{m \\times 1}$, and $\\mathbf{c} \\in \\mathbb{R}^{n}$.\nThe linear programming problem to find the corresponding minimum upper bound is called the Dual Linear Program. $$ \\begin{matrix} \\text{Minimize} \u0026amp; \\mathbf{b}^{T} \\mathbf{y} \\\\ \\text{subject to} \u0026amp; A^{T} \\mathbf{y} \\ge \\mathbf{c} \\\\ \u0026amp; \\mathbf{y} \\ge \\mathbf{0} \\end{matrix} $$ As an expression opposed to the dual linear programming problem, the original maximization problem is called the Primal Linear Program. Explanation 2 Visually presenting the solutions of dual and primal illustrates it as above. The primal problem maximizes the objective function from below upwards, whereas the dual problem reduces the solution space from above downwards. When they exactly align, we can unequivocally accept that as the optimal solution.\nWhat is Duality? Duality universally appears in mathematics, denoting properties at a higher abstract level similar to symmetry, such as the dual space in functional analysis or geometric dual graphs.\nSee Also Duality in Linear Programming If one is not majoring in optimization but studying it as a single subject, knowing just the simplex method and duality in linear programming can be considered as covering everything. Of course, that doesn\u0026rsquo;t mean the process is necessarily easy.\nWhile the simplex method discusses a specific approach, duality is more about the theoretical‚Äîa purely mathematical discussion‚Äîthat there exists a dual problem to the primal problem, and their optimal solutions are equal. This is guaranteed by the following Duality Theorems.\nWeak Duality Theorem $$ \\sum_{j=1}^{n} c_{j} x_{j}^{\\ast} \\le \\sum_{i=1}^{m} b_{i} y_{i}^{\\ast} $$\nStrong Duality Theorem $$ \\sum_{j=1}^{n} c_{j} x_{j}^{\\ast} = \\sum_{i=1}^{m} b_{i} y_{i}^{\\ast} $$\nMatousek. (2007). Understanding and Using Linear Programming: p82.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nVanderbei. (2020). Linear Programming(5th Edition): p63.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2348,"permalink":"https://freshrimpsushi.github.io/en/posts/2348/","tags":null,"title":"Linear Programming Duality"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview1 The framestyle attribute allows changing the style of the plot\u0026rsquo;s axes and border. The possible options are as follows:\n:box :semi :axes :origin :zerolines :grid :none Code The default setting is :axes.\n‚ñ∑code1‚óÅ\nThe styles for each attribute are as follows.\n‚ñ∑code2‚óÅ\nhttps://docs.juliaplots.org/latest/generated/attributes_subplot/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3376,"permalink":"https://freshrimpsushi.github.io/en/posts/3376/","tags":null,"title":"How to Change Axis Style in Julia Plots `framestyle`e`"},{"categories":"ÏµúÏ†ÅÌôîÏù¥Î°†","contents":"Theorem A system of equations of the following form for Dictionary: $i = 1 , \\cdots , m$ is called a Dictionary. $$ \\begin{align*} \\zeta \u0026amp;=\u0026amp; \u0026amp; \u0026amp; \\sum_{j=1}^{n} c_{j} x_{j} \\\\ x_{n+i} \u0026amp;=\u0026amp; b_{i} \u0026amp;-\u0026amp; \\sum_{j=1}^{n} a_{ij} x_{j} \\end{align*} $$ Variables on the left side of $\\zeta$, excluding the one variable, are called basic variables, and variables on the right side are called nonbasic variables. Their indices are denoted as follows. $$ \\begin{align*} \\mathcal{B} :=\u0026amp; \\left\\{ n+1 , n+2 , \\cdots , n+m \\right\\} \\\\ \\mathcal{N} :=\u0026amp; \\left\\{ 1 , 2 , \\cdots , n \\right\\} \\end{align*} $$\nIn the Simplex Method of Linear Programming, selecting the index of the entering variable as the smallest one from $\\mathcal{N}$, and selecting the index of the leaving variable as the smallest one from $\\mathcal{B}$ is called Brand\u0026rsquo;s Rule. According to Brand\u0026rsquo;s Rule, the simplex method does not fall into a cycle.\nExplanation Although there are other methods to solve a linear programming problem besides the Simplex Method, and there is not only one pivot rule for updating the dictionary in the simplex method, the existence of Brand\u0026rsquo;s Rule guarantees that the simplex method can always solve linear programming problems. Understanding this theorem means that you can consider mastering the two most important concepts in linear programming, including the simplex method itself.\nProof 1 Strategy: It\u0026rsquo;s not easy. It will be shown that it is a contradiction to fall into a cycle when pivoting with Brand\u0026rsquo;s rule.\nPart 1. $\\zeta = v + \\sum_{j = 1}^{n+m} c_{j}^{\\ast} x_{j}$\nWithout loss of generality, let\u0026rsquo;s start the proof from the point where cycling occurs. For some $k \\in \\mathbb{N}$, the dictionary cycles as follows. $$ D_{0} , D_{1} , \\cdots, D_{k-1} , D_{0} , D_{1} , \\cdots $$ In this dictionary, variables that are basic in some and nonbasic in others are called fickle. Let the fickle with the largest index be $x_{t}$, and when the dictionary that has $x_{t}$ as the leaving variable is $D$, without loss of generality let it be so that $D$ can be written with respect to $\\forall i \\in \\mathcal{B}$ as follows. $$ \\begin{align*} \\zeta \u0026amp;=\u0026amp; v \u0026amp;+\u0026amp; \\sum_{j \\in \\mathcal{N}} c_{j} x_{j} \\\\ x_{n+i} \u0026amp;=\u0026amp; b_{i} \u0026amp;-\u0026amp; \\sum_{j \\in \\mathcal{N}} a_{ij} x_{j} \\end{align*} $$ Here, if $x_{s}$ is the entering variable, then $x_{t}$ is the leaving one, and still $t \\in \\mathcal{B}$ and $s \\in \\mathcal{N}$. Now let $D^{\\ast}$ be the dictionary where $x_{t}$ enters the basis, and suppose it can be written with respect to $\\forall i \\in \\mathcal{B}^{\\ast}$ as follows. $$ \\begin{align*} \\zeta \u0026amp;=\u0026amp; v^{\\ast} \u0026amp;+\u0026amp; \\sum_{j \\in \\mathcal{N}^{\\ast}} c_{j}^{\\ast} x_{j} \\\\ x_{n+i} \u0026amp;=\u0026amp; b_{i}^{\\ast} \u0026amp;-\u0026amp; \\sum_{j \\in \\mathcal{N}^{\\ast}} a_{ij}^{\\ast} x_{j} \\end{align*} $$ The fact that the simplex method has fallen into a cycle means that all $D_{1} , \\cdots, D_{k-1}$ are degenerated, and because of $v^{\\ast} = v$, for the objective function $\\zeta$, by setting it as $c_{j}^{\\ast} = 0$ for $j \\in \\mathcal{B}^{\\ast}$, it can be written as follows. $$ \\zeta = v + \\sum_{j = 1}^{n+m} c_{j}^{\\ast} x_{j} $$\nPart 2. $\\zeta = v + c_{s} y$\nAs in the form of the equation, let\u0026rsquo;s consider the situation where the entering variable $x_{s}$ increases and the other variables in $\\mathcal{N}$ are fixed at $0$, so that no variable becomes negative. In terms of equations, it\u0026rsquo;s $$ \\begin{align*} x_{s} =\u0026amp; y \\\\ x_{j} =\u0026amp; 0 \u0026amp; , j \\in \\mathcal{N} \\setminus \\left\\{ s \\right\\} \\\\ x_{i} =\u0026amp; b_{i} - a_{is} y \u0026amp; , i \\in \\mathcal{B} \\end{align*} $$ and this is about increasing $y$. By rewriting the objective function $\\zeta$ with respect to this, the following can be obtained. $$ \\zeta = v + c_{s} y $$\nPart 3.\nRewriting Part 1\u0026rsquo;s $\\zeta = v + \\sum_{j = 1}^{n+m} c_{j}^{\\ast} x_{j}$ with respect to $y$, $$ \\zeta = v + c_{s}^{\\ast} y + \\sum_{i \\in \\mathcal{B}} c_{i}^{\\ast} \\left( b_{i} - a_{is} y \\right) $$ and substituting the left side for Part 2\u0026rsquo;s $\\zeta = v + c_{s} y$, gives $$ \\left( c_{s} - c_{s}^{\\ast} + \\sum_{i \\in \\mathcal{B}} c_{i}^{\\ast} a_{is} \\right) y = \\sum_{i \\in \\mathcal{B}} c_{i}^{\\ast} b_{i} $$ This equation always holds for all $y$, regardless of what\u0026rsquo;s on the right side, so from this, it\u0026rsquo;s understood that what\u0026rsquo;s inside the parenthesis is always $0$. $$ \\begin{equation} c_{s} - c_{s}^{\\ast} + \\sum_{i \\in \\mathcal{B}} c_{i}^{\\ast} a_{is} = 0 \\end{equation} $$ In other words, if the entering variable is $x_{s}$, $$ \\begin{equation} c_{s} \u0026gt; 0 \\end{equation} $$ Moreover, since $x_{t}$ is the fickle with the largest index and $x_{s}$ was also a fickle, $s \u0026lt; t$ follows. Since the entering variable for $D^{\\ast}$ was $x_{t}$, $x_{s}$ is not an entering variable, $$ \\begin{equation} c_{s}^{\\ast} \\le 0 \\end{equation} $$\nAccording to $(1), (2), (3)$, $$ \\sum_{i \\in \\mathcal{B}} c_{i}^{\\ast} a_{is} \u0026lt; 0 $$ and there must exist a $r \\in \\mathcal{B}$ that satisfies the following. $$ c_{r}^{\\ast} a_{rs} \u0026lt; 0 $$ As a result, $c_{r}^{\\ast} \\ne 0$ and $r \\in \\mathcal{N}^{\\ast}$, thus $x_{r}$ is a fickle and $r \\le t$ follows.\nPart 4. $r \u0026lt; t$\nSince we are considering the simplex method, we can say two things:\nSince $x_{t}$ is the entering variable for $D^{\\ast}$, $c_{t}^{\\ast} \u0026gt; 0$ follows. Since $x_{t}$ is the leaving variable for $D$, $a_{ts} \u0026gt; 0$ follows. Therefore, $c_{t}^{\\ast} a_{ts} \u0026gt; 0$, but since $c_{r}^{\\ast} a_{rs} \u0026lt; 0$, $r \\ne t$, that is, up to $r \u0026lt; t$ can be asserted.\nPart 5.\nIf it\u0026rsquo;s $r \u0026lt; t$, then it must be $c_{r}^{\\ast} \\le 0$, because if it wasn\u0026rsquo;t and was $c_{r}^{\\ast} \u0026gt; 0$ instead, then according to Part 3, $r$ must have been the entering variable for $D^{\\ast}$. According to this and Part 3\u0026rsquo;s $c_{r}^{\\ast} a_{rs} \u0026lt; 0$, $$ \\begin{equation} a_{rs} \u0026gt; 0 \\end{equation} $$ On the other hand, that dictionaries have fallen into a cycle means that they all essentially represent the same solution, hence all fickle variables are $0$ in that dictionary, and especially $x_{r} = 0$. However, since $x_{r}$ is a basic variable in $D$, $$ \\begin{equation} b_{r} = 0 \\end{equation} $$ Following $(4)$ and $(5)$, $x_{r}$ is one of the candidates for the leaving variable in $D$, and since it is $r \u0026lt; t$ according to Part 4, following Brand\u0026rsquo;s rule, it should have been selected (left) instead of $x_{t}$ much earlier. This contradiction reveals that the assumption that the dictionary has fallen into a cycle even when using Brand\u0026rsquo;s rule is false.\n‚ñ†\nSee Also Fundamental Theorem of Linear Programming This theorem is used in the proof of the fundamental theorem of linear programming.\nVanderbei. (2020). Linear Programming(5th Edition): p34~36.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2344,"permalink":"https://freshrimpsushi.github.io/en/posts/2344/","tags":null,"title":"Simplex Method's Bland's Rule"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, \u0026lt;condition\u0026gt; \u0026amp;\u0026amp; \u0026lt;statement\u0026gt; executes \u0026lt;statement\u0026gt; when \u0026lt;condition\u0026gt; is true. As a function, it returns the result of \u0026lt;statement\u0026gt; if true, and if false, \u0026lt;statement\u0026gt; is not even evaluated.\nWhile it allows writing code efficiently and concisely, it may reduce readability. Moreover, even if you don\u0026rsquo;t use it frequently, you should understand it to read the code written by others. Without any context, encountering such syntax can be utterly incomprehensible.\nSee Also Short Circuit Code Basic Example ‚ñ∑code1‚óÅ\nSince 2 is even, push!(num, 2) is evaluated, and 2 is added to the empty array num.\nReturn ‚ñ∑code2‚óÅ\n\u0026amp;\u0026amp; acts as a function too, thus can return some value. Here, check is considered to have received check = push!(num, 4) as a return.\n‚ñ∑code3‚óÅ\nOn the other hand, if \u0026lt;statement\u0026gt; is false, it is not evaluated and \u0026amp;\u0026amp; itself returns false.\nNegation ‚ñ∑code4‚óÅ\nUse || instead of \u0026amp;\u0026amp;.\nComplete Code ‚ñ∑code5‚óÅ\nEnvironment OS: Windows julia: v1.6.3 ","id":2341,"permalink":"https://freshrimpsushi.github.io/en/posts/2341/","tags":null,"title":"How to Write Conditional Statements Concisely in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let\u0026rsquo;s refer to $W_{1}, W_{2}$ as a subspace of the vector space $V$. The sum of $W_{1}$ and $W_{2}$ is denoted as $W_{1} + W_{2}$ and defined as follows.\n$$ W_{1} + W_{2} := \\left\\{ x + y : x\\in W_{1}, y \\in W_{2} \\right\\} $$\nGeneralization2 Let $W_{1}, W_{2}, \\dots, W_{k}$ be a subspace of the vector space $V$. The sum of these subspaces is denoted as $W_{1} + \\cdots + W_{k}$ and defined as follows.\n$$ W_{1} + \\cdots + W_{k} = \\sum\\limits_{i=1}^{k}W_{i} := \\left\\{ v_{1} + \\cdots + v_{k} : v_{i} \\in W_{i} \\text{ for } 1 \\le i \\le k \\right\\} $$\nExplanation It doesn‚Äôt have to be a subspace; a subset can be defined without any issues.\nAs the definition suggests, it is not necessarily required to be a vector space; as long as the addition of elements is well-defined, it works. Therefore, $W_{1}$ and $W_{2}$ could be subgroups of a group and the definition would still apply. Conversely, without the addition of elements, it cannot be defined.\nSee Also Direct sum Stephen H. Friedberg, Linear Algebra (4th Edition, 2002), p22\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p275\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3371,"permalink":"https://freshrimpsushi.github.io/en/posts/3371/","tags":null,"title":"Sum of Subspaces in a Vector Space"},{"categories":"ÏµúÏ†ÅÌôîÏù¥Î°†","contents":"Buildup 1 Consider the following Linear Programming Problem for $x_{1} , x_{2} \\ge 0$. $$ \\begin{matrix} \\text{Maximize} \u0026amp; \u0026amp; x_{1} \u0026amp; + \u0026amp; x_{2} \\\\ \\text{subject to} \u0026amp;-\u0026amp; x_{1} \u0026amp; + \u0026amp; x_{2} \u0026amp; \\le \u0026amp; 1 \\\\ \u0026amp; \u0026amp; x_{1} \u0026amp; \u0026amp; \u0026amp; \\le \u0026amp; 3 \\\\ \u0026amp; \u0026amp; \u0026amp; \u0026amp; x_{2} \u0026amp; \\le \u0026amp; 2 \\end{matrix} $$ In other words, we want to maximize $x_{1} + x_{2}$ while satisfying all given constraints. To convert this into equation form, we introduce the so-called Slack Variable $x_{3}, x_{4}, x_{5} \\ge 0$, so that it can be represented as $$ \\begin{matrix} \\text{Maximize} \u0026amp; \u0026amp; x_{1} \u0026amp; + \u0026amp; x_{2} \\\\ \\text{subject to} \u0026amp;-\u0026amp; x_{1} \u0026amp; + \u0026amp; x_{2} \u0026amp; + \u0026amp; x_{3} \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; = \u0026amp; 1 \\\\ \u0026amp; \u0026amp; x_{1} \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; + \u0026amp; x_{4} \u0026amp; \u0026amp; \u0026amp; = \u0026amp; 3 \\\\ \u0026amp; \u0026amp; \u0026amp; \u0026amp; x_{2} \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; + \u0026amp; x_{5} \u0026amp; = \u0026amp; 2 \\end{matrix} $$ Subsequently, expressing it again as a dictionary or tableau turns the original $x_{1}$, $x_{2}$ into Nonbasic Variables which stay on the right side, and $x_{3}$, $x_{4}$, $x_{5}$ become Basic Variables that move to the left side, $$ \\begin{matrix} \\zeta \u0026amp; = \u0026amp; \u0026amp; 0 \u0026amp; + \u0026amp; x_{1} \u0026amp; + \u0026amp; x_{2} \\\\ x_{3} \u0026amp; = \u0026amp; \u0026amp; 1 \u0026amp; + \u0026amp; x_{1} \u0026amp; - \u0026amp; x_{2} \\\\ x_{4} \u0026amp; = \u0026amp; \u0026amp; 3 \u0026amp; - \u0026amp; x_{1} \u0026amp; \u0026amp; \\\\ x_{5} \u0026amp; = \u0026amp; \u0026amp; 2 \u0026amp; \u0026amp; \u0026amp; - \u0026amp; x_{2} \\end{matrix} $$ $$ \\mathcal{N} = \\left\\{ 1, 2 \\right\\} \\\\ \\mathcal{B} = \\left\\{ 3, 4, 5 \\right\\} $$ Here, $\\zeta = \\bar{\\zeta} + x_{1} + x_{2}$\u0026rsquo;s $\\bar{\\zeta}$ is the function value of the objective function for the optimal solution, which essentially means how optimized it is currently. By performing variable substitutions with the equations below, it might be possible to unify the signs of the nonbasic variables on the right side of $\\zeta$ to $-$. Therefore, when all nonbasic variables are substituted with $0$, $$ \\zeta = \\zeta_{?} - x_{?_{1}} - x_{?_{2}} $$ this form will yield the largest value. In other words, this is obtaining a feasible basis. The existence of a sign like $+$ among the nonbasic variable signs signifies that there is still potential for $\\zeta_{?}$ to increase, while all signs being $-$ means that there is no longer any way to increase $\\zeta_{?}$. This is the idea behind the Simplex Method. Although it seems like the problem is being solved algebraically, the term simplex is used because introducing the slack variable to create the equation form results in a solution space that is a simplex.\nPractical Application $$ \\begin{matrix} \\zeta \u0026amp; = \u0026amp; \u0026amp; 0 \u0026amp; + \u0026amp; x_{1} \u0026amp; + \u0026amp; x_{2} \\\\ x_{3} \u0026amp; = \u0026amp; \u0026amp; 1 \u0026amp; + \u0026amp; x_{1} \u0026amp; - \u0026amp; x_{2} \\\\ x_{4} \u0026amp; = \u0026amp; \u0026amp; 3 \u0026amp; - \u0026amp; x_{1} \u0026amp; \u0026amp; \\\\ x_{5} \u0026amp; = \u0026amp; \u0026amp; 2 \u0026amp; \u0026amp; \u0026amp; - \u0026amp; x_{2} \\end{matrix} $$ $$ \\mathcal{N} = \\left\\{ 1, 2 \\right\\} \\\\ \\mathcal{B} = \\left\\{ 3, 4, 5 \\right\\} \\\\ \\left( x_{1} , x_{2} , x_{3}, x_{4} , x_{5} \\right) = (0,0,1,3,2) \\\\ \\bar{\\zeta} = 0 $$\nLet\u0026rsquo;s actually solve the above example using the simplex method.\nGiven the form of $\\zeta$, both $x_{1}$, and $x_{2}$ can be increased, but knowing $x_{4} = 3 - x_{1}$ and $x_{5} = 2 - x_{2}$ from the constraints, it doesn\u0026rsquo;t seem to have much significance for now. Considering the condition for $x_{3}$, $$ x_{2} = 1 + x_{1} - x_{3} $$ the new dictionary is as follows.\n$$ \\begin{matrix} \\zeta \u0026amp; = \u0026amp; \u0026amp; 1 \u0026amp; + \u0026amp; 2x_{1} \u0026amp; - \u0026amp; x_{3} \\\\ x_{2} \u0026amp; = \u0026amp; \u0026amp; 1 \u0026amp; + \u0026amp; x_{1} \u0026amp; - \u0026amp; x_{3} \\\\ x_{4} \u0026amp; = \u0026amp; \u0026amp; 3 \u0026amp; - \u0026amp; x_{1} \u0026amp; \u0026amp; \\\\ x_{5} \u0026amp; = \u0026amp; \u0026amp; 1 \u0026amp; - \u0026amp; x_{1} \u0026amp; + \u0026amp; x_{3} \\end{matrix} $$ $$ \\mathcal{N} = \\left\\{ 1, 3 \\right\\} \\\\ \\mathcal{B} = \\left\\{ 2, 4, 5 \\right\\} \\\\ \\left( x_{1} , x_{2} , x_{3}, x_{4} , x_{5} \\right) = (0,1,0,3,2) \\\\ \\bar{\\zeta} = 1 $$\nAs can be seen in the equation, we have increased the value of the objective function by $1$ compared to before. This process of revising the dictionary is called Pivot Step2, and the variables like $x_{2}$ that move from nonbasic to basic are called Entering Variables, while those like $x_{3}$ moving from basic to nonbasic are called Leaving Variables3. It\u0026rsquo;s important not to get confused here; we\u0026rsquo;ve never actually changed the objective function itself, nor will we ever do so. As from the very beginning in the buildup, existing variables merely represent other variables, and only now do constant terms that weren\u0026rsquo;t visible before come into view.\nOur current task in the dictionary seems quite clear at this point. Increasing $x_{1}$ appears to double the value of the objective function. Using the same reasoning, choosing $x_{5}$ as the entering variable, $$ x_{1} = 1 + x_{3} - x_{5} $$ results in: $$ \\begin{matrix} \\zeta \u0026amp; = \u0026amp; \u0026amp; 3 \u0026amp; + \u0026amp; x_{3} \u0026amp; - \u0026amp; 2x_{5} \\\\ x_{1} \u0026amp; = \u0026amp; \u0026amp; 1 \u0026amp; + \u0026amp; x_{3} \u0026amp; - \u0026amp; x_{5} \\\\ x_{2} \u0026amp; = \u0026amp; \u0026amp; 2 \u0026amp; \u0026amp; \u0026amp; - \u0026amp; x_{5} \\\\ x_{4} \u0026amp; = \u0026amp; \u0026amp; 2 \u0026amp; - \u0026amp; x_{3} \u0026amp; + \u0026amp; x_{5} \\end{matrix} $$ $$ \\mathcal{N} = \\left\\{ 3, 5 \\right\\} \\\\ \\mathcal{B} = \\left\\{ 1, 2, 4 \\right\\} \\\\ \\left( x_{1} , x_{2} , x_{3}, x_{4} , x_{5} \\right) = (1,2,0,2,0) \\\\ \\bar{\\zeta} = 3 $$\nSince there\u0026rsquo;s still room for $x_{3}$ on the right side of $\\zeta$ to increase, using $x_{3}$ as the entering variable yields: $$ x_{3} = 2 - x_{4} + x_{5} $$ and consequently: $$ \\begin{matrix} \\zeta \u0026amp; = \u0026amp; \u0026amp; 5 \u0026amp; - \u0026amp; x_{4} \u0026amp; - \u0026amp; x_{5} \\\\ x_{1} \u0026amp; = \u0026amp; \u0026amp; 3 \u0026amp; - \u0026amp; x_{4} \u0026amp; - \u0026amp; \\\\ x_{2} \u0026amp; = \u0026amp; \u0026amp; 2 \u0026amp; \u0026amp; \u0026amp; - \u0026amp; x_{5} \\\\ x_{3} \u0026amp; = \u0026amp; \u0026amp; 2 \u0026amp; - \u0026amp; x_{4} \u0026amp; + \u0026amp; x_{5} \\end{matrix} $$ $$ \\mathcal{N} = \\left\\{ 4, 5 \\right\\} \\\\ \\mathcal{B} = \\left\\{ 1, 2, 3 \\right\\} \\\\ \\left( x_{1} , x_{2} , x_{3}, x_{4} , x_{5} \\right) = (3,2,2,0,0) \\\\ \\bar{\\zeta} = 5 $$\nNow, as all variable signs on the right side of $\\zeta$ are $-$, touching any variable won\u0026rsquo;t increase $\\zeta$ further, indicating that the optimization is complete. Indeed, by substituting $x_{1} = 3$ and $x_{2} = 2$ into the initially given linear programming problem $$ \\begin{matrix} \\text{Maximize} \u0026amp; \u0026amp; x_{1} \u0026amp; + \u0026amp; x_{2} \\\\ \\text{subject to} \u0026amp;-\u0026amp; x_{1} \u0026amp; + \u0026amp; x_{2} \u0026amp; \\le \u0026amp; 1 \\\\ \u0026amp; \u0026amp; x_{1} \u0026amp; \u0026amp; \u0026amp; \\le \u0026amp; 3 \\\\ \u0026amp; \u0026amp; \u0026amp; \u0026amp; x_{2} \u0026amp; \\le \u0026amp; 2 \\end{matrix} $$ and recalculating, it can be confirmed that all given constraints are well satisfied and the value of the objective function is precisely $\\zeta = \\bar{\\zeta} - 0 = 5$.\nMatousek. (2007). Understanding and Using Linear Programming: p57~60.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMatousek. (2007). Understanding and Using Linear Programming: p59.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nVanderbei. (2020). Linear Programming(5th Edition): p0.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2336,"permalink":"https://freshrimpsushi.github.io/en/posts/2336/","tags":null,"title":"Linear Programming: The Simplex Method"},{"categories":"ÏµúÏ†ÅÌôîÏù¥Î°†","contents":"Notation $$ \\begin{matrix} \\text{Maximize} \u0026amp; \\mathbf{c}^{T} \\mathbf{x} \\\\ \\text{subject to} \u0026amp; A \\mathbf{x} = \\mathbf{b} \\\\ \u0026amp; \\mathbf{x} \\ge \\mathbf{0} \\end{matrix} $$\nFor the matrix $A \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{b} \\in \\mathbb{R}^{m \\times 1}$, and $\\mathbf{c} \\in \\mathbb{R}^{n}$, it is said that the linear programming problem is represented in the form of equation form as above, and let\u0026rsquo;s denote its components as follows. $$ \\begin{align*} A =\u0026amp; \\left( a_{ij} \\right) \\\\ \\mathbf{b} =\u0026amp; \\left( b_{1} , \\cdots , b_{m} \\right) \\\\ \\mathbf{c} =\u0026amp; \\left( c_{1} , \\cdots , c_{n} \\right) \\\\ \\mathbf{x} =\u0026amp; \\left( x_{1} , \\cdots , x_{n} \\right) \\end{align*} $$\nDictionary 1 For $i = 1 , \\cdots , m$, the following form of a system of equations is called a Dictionary. $$ \\begin{align*} \\zeta \u0026amp;=\u0026amp; \u0026amp; \u0026amp; \\sum_{j=1}^{n} c_{j} x_{j} \\\\ x_{n+i} \u0026amp;=\u0026amp; b_{i} \u0026amp;-\u0026amp; \\sum_{j=1}^{n} a_{ij} x_{j} \\end{align*} $$\nVariables on the left-hand side other than $\\zeta$ are called Basic Variables, and those on the right-hand side are called Nonbasic Variables. First, let\u0026rsquo;s denote their indices as $$ \\begin{align*} \\mathcal{B} :=\u0026amp; \\left\\{ n+1 , n+2 , \\cdots , n+m \\right\\} \\\\ \\mathcal{N} :=\u0026amp; \\left\\{ 1 , 2 , \\cdots , n \\right\\} \\end{align*} $$ However, this is just a transcription of the initial linear programming problem, and with the progress of the solution, a bar is placed on the changing coefficients to express it as follows. $$ \\begin{align*} \\zeta \u0026amp;=\u0026amp; \\bar{\\zeta} \u0026amp;+\u0026amp; \\sum_{j \\in \\mathcal{N}} \\bar{c}_{j} x_{j} \\\\ x_{n+i} \u0026amp;=\u0026amp; \\bar{b}_{i} \u0026amp;-\u0026amp; \\sum_{j \\in \\mathcal{N}} \\bar{a}_{ij} x_{j} \\end{align*} $$ Here, $i \\in \\mathcal{B}$ and as indicated by the notation, $\\mathcal{N}$ and $\\mathcal{B}$ are not fixed sets but also change as the solution progresses.\nTableau 2 The simplex Tableau $\\mathcal{T}(B)$, determined by the feasible basis $B$, refers to the nth-order system of linear equations that has the same set of solutions as the given linear programming problem $A \\mathbf{x} = \\mathbf{b}, z = \\mathbf{c}^{T} \\mathbf{x}$. For $N := \\left\\{ 1 , \\cdots , n + m \\right\\} \\setminus B$, if $\\mathbf{x}_{B}$ is the vector of basic variables and $\\mathbf{x}_{N}$ is the vector of nonbasic variables, then for some vectors $\\mathbf{p} \\in \\mathbb{R}^{m}$, $\\mathbf{r} \\in \\mathbb{R}^{n-m}$ and matrix $Q \\in \\mathbb{R}^{m \\times (n-m)}$, it is represented as follows. $$ \\begin{align*} \\mathbf{x}_{B} \u0026amp;=\u0026amp; \\mathbf{p} \u0026amp;+\u0026amp; Q \\mathbf{x}_{N} \\\\ z \u0026amp;=\u0026amp; z_{0} \u0026amp;+\u0026amp; \\mathbf{r}^{T} \\mathbf{x}_{N} \\end{align*} $$\nExplanation Frankly speaking, the Dictionary and the Tableau are the same thing, and as can be seen from the quotations, it is merely a matter of preference for expressions among the authors. Of course, conceptually $B = \\mathcal{B}$ is the same as $N = \\mathcal{N}$, and the only difference is whether one is using the variables as they are or using matrix notation.\nIn preparation for posting, I looked through many textbooks on linear programming, and no author seemed to want to explain in detail about either the Dictionary or the Tableau. From \u0026lsquo;system of equations\u0026rsquo; onwards, students accustomed to a high degree of abstraction feel extreme anxiety and aversion to vague expressions like \u0026lsquo;in the following form\u0026rsquo; or \u0026lsquo;changing according to the algorithm\u0026rsquo;. While understanding these feelings, it also seemed that the authors themselves preferred to quickly move on to discussing linear programming itself rather than dwelling on notations. If one is truly interested in linear programming, it is recommended to somewhat gloss over and move on.\nVanderbei. (2020). Linear Programming(5th Edition): p14.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMatousek. (2007). Understanding and Using Linear Programming: p65.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2334,"permalink":"https://freshrimpsushi.github.io/en/posts/2334/","tags":null,"title":"Linear Programming: Dictionaries and Tableau"},{"categories":"ÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†","contents":"\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\r[ ÌéºÏπòÍ∏∞ ¬∑ Ï†ëÍ∏∞ ]\rÏñëÏûêÍ≥ÑÏÇ∞\rÎÖºÎ¶¨Í≤åÏù¥Ìä∏\rÎπÑÌä∏\r¬∑ Î∂ÄÏö∏Ìï®Ïàò(AND\r¬∑ OR\r¬∑ NOT\r¬∑ XOR\r¬∑ NAND\r¬∑ NOR\r¬∑ CNOT\r¬∑ CCNOT\r¬∑ CSWAP)\r¬∑ Î≤îÏö© Í≤åÏù¥Ìä∏\r¬∑ Î≥µÏ†ú Ìï®Ïàò\r¬∑ ÏÇ¨ÏòÅ\r¬∑ Ï£ºÏûÖ\rÏñëÏûêÍ≤åÏù¥Ìä∏\rÌÅêÎπÑÌä∏\r¬∑ ÏñëÏûê ÏñΩÌûò\r¬∑ ÏñëÏûê ÌöåÎ°ú\r¬∑ ÏñëÏûê Í≤åÏù¥Ìä∏(ÌååÏö∏Î¶¨ Í≤åÏù¥Ìä∏\r¬∑ ÏúÑÏÉÅ Í≤åÏù¥Ìä∏\r¬∑ ÏïÑÎã§ÎßàÎ•¥ Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CNOT\r¬∑ ÍµêÌôò Í≤åÏù¥Ìä∏\r¬∑ ÏñëÏûê CSWAP\r¬∑ ÏñëÏûê CSWAP)\r¬∑ ÏÜîÎ≤†Ïù¥-ÌÇ§ÌÉÄÏòàÌîÑ Ï†ïÎ¶¨\r¬∑ Î≥µÏ†ú Î∂àÍ∞Ä Ï†ïÎ¶¨\rÏ†ïÎ≥¥Ïù¥Î°†\rÍ≥†Ï†ÑÏ†ïÎ≥¥Ïù¥Î°†\rÏ†ïÎ≥¥Îüâ\r¬∑ ÏóîÌä∏Î°úÌîº(Í≤∞Ìï© ÏóîÌä∏Î°úÌîº\r¬∑ Ï°∞Í±¥Î∂Ä ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÎåÄÏ†Å ÏóîÌä∏Î°úÌîº\r¬∑ ÏÉÅÌò∏ Ï†ïÎ≥¥\r)\r¬∑ Î∂ÄÌò∏Ìôî\r¬∑ Î≥µÌò∏Ìôî\rÏñëÏûêÏ†ïÎ≥¥Ïù¥Î°†\rTBD\r¬∑ TBD\r¬∑ TBD\rÍ¥ÄÎ†® Î∂ÑÏïº\rÏÑ†ÌòïÎåÄÏàò\r¬∑ ÏñëÏûêÏó≠Ìïô\rDefinition1 2 Let\u0026rsquo;s assume the discrete random variable $X$ can take values $n$. Let\u0026rsquo;s denote the probability mass function of $x_{1}, x_{2}, \\dots, x_{n}$ as $X$. Then, the entropyShannon entropy $p$ or $X$ is defined as follows:\n$$ \\begin{equation} H(X) = H(p) := E\\left[ I(x_{i}) \\right] = \\sum_{i=1}^{n} p(x_{i}) I(x_{i}) = -\\sum_{i=1}^{n} p(x_{i}) \\log_{2}p(x_{i}) \\end{equation} $$\nHere, $p$ represents information content, and $H$ represents the expected value.\nIf $I$ is a continuous random variable,\n$$ H(X) = H(p) = - \\int_{-\\infty}^{\\infty} p(x)\\log_{2}p(x) dx $$\nExplanation Simply put, entropy is the expected value (average) of information. Entropy allows us to mathematically handle the efficiency of coding and the limits of communication.\nEntropy is often described as disorder. Here, order refers to rules, trends, patterns, etc. Therefore, high entropy means high disorder, indicating that it is difficult to discern patterns or rules for the random variable $E$.\nLet\u0026rsquo;s consider a biased coin flip. If the probability of getting heads is $X$, then the probability of tails is $X$, and the entropy is as follows:\n$$ H = -p\\log_{2}p - (1-p)\\log_{2}(1-p) $$\nIf we plot $p$ against $1-p$, it looks like this:\nWhen the probability of heads is $p$, the entropy is $H$ and is at its maximum. This means it\u0026rsquo;s most challenging to discern any pattern or rule in the coin flip. In fact, we can\u0026rsquo;t be sure which side of the coin will show up in a coin flip. If the probability of heads changes slightly, the entropy decreases. For example, if the probability of heads is $\\dfrac{1}{2}$, the entropy is about $H = -\\dfrac{1}{2}\\log_{2}\\dfrac{1}{2}-\\dfrac{1}{2}\\log_{2}\\dfrac{1}{2} = 1$, indicating lower disorder, meaning there is some rule or pattern (in this case, heads come up most of the time). This can be summarized as follows:\nHigh entropy = high disorder = no regularity or pattern = hard to predict the result Low entropy = low disorder = presence of regularity or pattern = easier to predict the result\rAs you can guess from the above example, generally, when there are $\\dfrac{95}{100}$ possible outcomes, the highest entropy occurs when all probabilities are equal to $0.28$.\nProperties Let\u0026rsquo;s assume the random variable $n$ can take values $\\dfrac{1}{n}$. Entropy $X$ has the following properties:\n$n$ is a concaveconcave function. For any $x_{1}, x_{2}, \\dots, x_{n}$, if $H$, then $H$. When all probabilities are equal to $x_{i}$, entropy is maximum, and its value is $p(x_{i}) = 1$. For a random vector $H(X) = 0$ with a mean of $p(x_{i}) = \\dfrac{1}{n}$ and a covariance matrix of $\\log_{2}n$, the following holds for its entropy: $$ \\begin{equation} H(X) \\le \\dfrac{1}{2}\\ln \\left[ (2 \\pi e)^{p} \\left| K \\right| \\right] \\end{equation} $$ $\\mathbf{0}$ is the determinant of the covariance matrix. If $K$ is normally distributed, equality holds. Given the mean $X \\in \\mathbb{R}^{n}$ and variance $\\left| K \\right|$, the distribution with the maximum entropy is the normal distribution. For the random variable $X$ and estimator $\\mu$, the following holds: $$ E\\left[ (X - \\hat{X})^{2} \\right] \\ge \\dfrac{1}{2\\pi e} e^{2H(X)} $$ Proof 4 For convenience, let\u0026rsquo;s denote $\\sigma^{2}$. Let\u0026rsquo;s assume $X$ is any probability density function that satisfies $\\hat{X}$. Let\u0026rsquo;s denote $\\mathbf{x} = X$ as the probability density function of the normal distribution $g$. $$ \\phi (\\mathbf{x}) = \\dfrac{1}{\\sqrt{(2\\pi)^{p} \\left| K \\right|}} \\exp \\left( -\\dfrac{1}{2}\\mathbf{x}^{T} K^{-1} \\mathbf{x} \\right) $$ First, we\u0026rsquo;ll show that formula $\\displaystyle \\int g(\\mathbf{x})x_{i}x_{j} d \\mathbf{x} = K_{ij}$ holds. Calculating $\\phi$ first,\n$$ \\begin{align*} \\ln \\phi (\\mathbf{x}) \u0026amp;= \\ln\\dfrac{1}{\\sqrt{(2\\pi)^{p} \\left| K \\right|}} - \\dfrac{1}{2}\\mathbf{x}^{T} K^{-1} \\mathbf{x} \\\\ \u0026amp;= C + \\sum a_{ij} x_{i} x_{j} \\end{align*} $$\nThe first term can be expressed as some constant $N(\\mathbf{0}, K)$, and the second term can also be expressed as a quadratic form dependent only on $\\displaystyle \\int g(\\mathbf{x}) \\ln \\phi (\\mathbf{x}) d \\mathbf{x} = \\int \\phi (\\mathbf{x}) \\ln \\phi (\\mathbf{x}) d \\mathbf{x}$. Therefore,\n$$ \\begin{align*} \\int g(\\mathbf{x}) \\ln \\phi (\\mathbf{x}) d \\mathbf{x} \u0026amp;= C \\int g(\\mathbf{x}) d \\mathbf{x} + \\int g(\\mathbf{x})\\sum a_{ij}x_{i}x_{j} d \\mathbf{x} \\\\ \u0026amp;= C + \\sum a_{ij} \\int g(\\mathbf{x}) x_{i}x_{j} d \\mathbf{x} \\\\ \u0026amp;= C + \\sum a_{ij}K_{ij} \\qquad \\text{by assumption for $g$} \\end{align*} $$\nAlso,\n$$ \\begin{align*} \\int \\phi (\\mathbf{x}) \\ln \\phi (\\mathbf{x}) d \\mathbf{x} \u0026amp;= C \\int \\phi (\\mathbf{x}) d \\mathbf{x} + \\int \\phi (\\mathbf{x})\\sum a_{ij}x_{i}x_{j} d \\mathbf{x} \\\\ \u0026amp;= C + \\sum a_{ij} \\int \\phi (\\mathbf{x}) x_{i}x_{j} d \\mathbf{x} \\\\ \u0026amp;= C + \\sum a_{ij}K_{ij} \\qquad \\text{by definition of covariance} \\end{align*} $$\nSince the relative entropy is always greater than or equal to $\\ln \\phi (\\mathbf{x})$,\n$$ \\begin{align*} 0 \u0026amp;\\le D(g \\| \\phi) \\\\ \u0026amp;= \\int g \\ln \\dfrac{g}{\\phi} \\\\ \u0026amp;= \\int g \\ln g - \\int g \\ln \\phi \\\\ \u0026amp;= - H(g) - \\int \\phi \\ln \\phi \\\\ \u0026amp;= - H(g) + H(\\phi) \\end{align*} $$\nThe entropy of the normal distribution is $C$, so,\n$$ H(X) = H(g) \\le H(\\phi) = \\dfrac{1}{2}\\ln \\left[ (2 \\pi e)^{n} \\left| K \\right| \\right] $$\nNow, let\u0026rsquo;s assume $K^{-1}$ is a one-dimensional random variable.\n$$ \\begin{align*} E\\left[ (X - \\hat{X})^{2} \\right] \u0026amp;\\ge \\min_{X} E\\left[ (X - \\hat{X})^{2} \\right] \\\\ \u0026amp;= E\\left[ (X - E(X))^{2} \\right] \\\\ \u0026amp;= \\Var(X) \\end{align*} $$\nFor a one-dimensional $a_{ji}$, we get the following equation:\n$$ \\begin{align*} \u0026amp;\u0026amp; H(X) \u0026amp;\\le \\dfrac{1}{2} \\ln(2\\pi e \\sigma^{2}) \\\\ \\implies \u0026amp;\u0026amp; 2H(X) \u0026amp;\\le \\ln(2\\pi e \\sigma^{2}) \\\\ \\implies \u0026amp;\u0026amp; e^{2H(X)} \u0026amp;\\le 2\\pi e \\sigma^{2} \\\\ \\implies \u0026amp;\u0026amp; \\dfrac{1}{2\\pi e}e^{2H(X)} \u0026amp;\\le \\sigma^{2} = \\Var(X) \\\\ \\end{align*} $$\nSubstituting into the above equation,\n$$ E\\left[ (X - \\hat{X})^{2} \\right] \\ge \\dfrac{1}{2\\pi e} e^{2H(X)} $$\nEntropy of the Normal Distribution The entropy of the normal distribution $0$ (when natural log is used) is as follows:\n$$ H = \\dfrac{1}{2} \\ln (2\\pi e \\sigma^{2}) = \\ln \\sqrt{2\\pi e \\sigma^{2}} $$\nThe entropy of the multivariate normal distribution $\\dfrac{1}{2}\\ln \\left[ (2 \\pi e)^{n} \\left| K \\right| \\right]$ is as follows:\n$$ H = \\dfrac{1}{2}\\ln \\left[ (2 \\pi e)^{n} \\left| K \\right| \\right] = \\dfrac{1}{2}\\ln (\\det (2\\pi e K)) $$\nSee Also Shannon entropy defined in probability information theory Entropy defined in thermodynamics Gibbs\u0026rsquo; entropy representation Kim Young-hoon¬∑Heo Jae-seong, Quantum Information Theory (2020), p246\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nStephen M. Barnett, Quantum Information (2009), p7-10\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3400,"permalink":"https://freshrimpsushi.github.io/en/posts/3400/","tags":null,"title":"Shannon Entropy in Classical Information Theory"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview The method of replacing with a specific value is inconvenient because it changes one column at a time, and when dealing with NaN throughout the dataframe, it seems more practical to use a better trick.\nCode julia\u0026gt; df = DataFrame(rand(1:9,3,3), :auto) ./ DataFrame(rand(0:1,3,3), :auto)\r3√ó3 DataFrame\rRow ‚îÇ x1 x2 x3 ‚îÇ Float64 Float64 Float64\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 5.0 Inf 7.0\r2 ‚îÇ Inf 8.0 Inf\r3 ‚îÇ 4.0 1.0 4.0 For instance, if you want to replace Inf with 0 in the dataframe above, you can do it in just one line as follows.\njulia\u0026gt; ifelse.(isinf.(df), 0, df)\r3√ó3 DataFrame\rRow ‚îÇ x1 x2 x3 ‚îÇ Float64 Float64 Float64\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 5.0 0.0 7.0\r2 ‚îÇ 0.0 8.0 0.0\r3 ‚îÇ 4.0 1.0 4.0 Of course, if you replace isinf with isnan in ifelse.(isinf.(df), 0, df), you can handle NaN, and you can change 0 to send to any value you prefer.\nFull Code using DataFrames, Random\rRandom.seed!(0)\rdf = DataFrame(rand(1:9,3,3), :auto) ./ DataFrame(rand(0:1,3,3), :auto)\rifelse.(isinf.(df), 0, df) See Also How to change specific values in a dataframe Environment OS: Windows julia: v1.6.3 ","id":2330,"permalink":"https://freshrimpsushi.github.io/en/posts/2330/","tags":null,"title":"How to Replace NaN with 0 in Julia DataFrames"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 The following is referred to as the coverage probability for the interval estimator $\\left[ L \\left( \\mathbf{X} \\right), U \\left( \\mathbf{X} \\right) \\right]$ of parameter $\\theta$. $$ P_{\\theta} \\left( \\theta \\in \\left[ L \\left( \\mathbf{X} \\right), U \\left( \\mathbf{X} \\right) \\right] \\right) = P \\left( \\theta \\in \\left[ L \\left( \\mathbf{X} \\right), U \\left( \\mathbf{X} \\right) \\right] | \\theta \\right) $$ The infimum of the coverage probability is called the confidence coefficient. $$ \\inf_{\\theta} P_{\\theta} \\left( \\theta \\in \\left[ L \\left( \\mathbf{X} \\right), U \\left( \\mathbf{X} \\right) \\right] \\right) $$ Explanation Confidence Interval The confidence coefficient is the same as the confidence level, and when the interval estimator and confidence level appear together, we call that interval a confidence interval.\nCutting out all the unnecessary talk, speaking purely mathematically, from the definition of the interval estimator, the interval estimator is indeed a random interval made from a statistic. Seeing this clean statistical definition might now give you a sense of what a confidence interval is. When explaining the difference from Bayesian credible intervals, if you make $N$ confidence intervals, yada yada, there\u0026rsquo;s no distribution of parameters so yada yada gets condensed into the expressions below. $$ P \\left( \\theta \\in \\left[ L \\left( \\mathbf{X} \\right), U \\left( \\mathbf{X} \\right) \\right] | \\theta \\right) $$ What is moving, changing, random, it was always the confidence interval itself, not $\\theta$. As shown in the formula, $\\theta$ is a constant, just given and stationary, and it\u0026rsquo;s the fluctuation around it. We don\u0026rsquo;t know nor need to know the distribution of $\\theta$ since it\u0026rsquo;s essentially a constant anyway.\nWhy Was It Confusing The inability to think this way comes from most of you seeing confidence intervals specifically written as numbers. Suppose the average is $3.14$ and at a confidence level of $95 \\%$, the confidence interval is $[3.00, 3.28]$.\nOnly a madman seeing this for the first time would think the confidence interval moves. Normal human intuition goes, \u0026ldquo;So, that means there\u0026rsquo;s a chance that $3.14$ is within $[3.00, 3.28]$, right? But there‚Äôs also a chance it might go outside with $5\\%$ probability? So even if we believe it, we shouldn\u0026rsquo;t fully trust it but rather to about 95%?\u0026rdquo; It\u0026rsquo;s unthinkable that it moves to $3.14$ becoming $3.30$ and thus going outside, rather than imagining the confidence interval being drawn as $[2.00, 2.28]$ and not covering $3.14$. $3.00 = L \\left( \\mathbf{x} \\right)$, and $3.28 = U \\left( \\mathbf{x} \\right)$ it is. Generalization to Confidence Sets In defining the confidence interval through the coverage probability, there was no need at all for the characteristics of the interval estimator. For example, assumptions such as topological connectedness were not necessary, leading to the generalization to sets themselves, called confidence sets. Naturally, a confidence set is a subset of the parameter space $\\Theta$, expressed as a random set $C \\left( \\mathbf{X} \\right)$ dependent on the sample $\\mathbf{X}$.\nSee Also An Easy Definition of Confidence Intervals Casella. (2001). Statistical Inference(2nd Edition): p418.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2329,"permalink":"https://freshrimpsushi.github.io/en/posts/2329/","tags":null,"title":"Definition of a Mathematical-Statistical Confidence Set"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let\u0026rsquo;s refer to $V$ as $F$-vector space, and $W \\le V$ as subspace. For $v \\in V$, the following set\n$$ \\left\\{ v \\right\\} + W := \\left\\{ v + w : w \\in W \\right\\} $$\nis called the coset of $W$ containing $v$. $+$ is the sum of sets.\nExplanation We often abbreviate $\\left\\{ v \\right\\} + W$ as $v + W$.\nConsidering the set of all cosets of $W$, denoted by $\\left\\{ v + W : v \\in V \\right\\}$, we define addition and scalar multiplication (by $F$) as follows:\n$$ (v_{1} + W) + (v_{2} + W) = (v_{1} + v_{2}) + W,\\quad \\forall v_{1}, v_{2} \\in V $$\n$$ a(v + W) = av + W\\quad \\forall v \\in V \\text{ and } a \\in F $$\nThen, this set again forms a $F$-vector space. This vector space is denoted by $V/W$, and is called the quotient space of $V$ modulo $W$.\nTheorem (a) $v + W$ being a subspace of $V$ is equivalent to $v \\in W$. (proof in algebra)\n(b) For $v_{1}, v_{2} \\in V$, $v_{1} + W = v_{2} + W$ being true is equivalent to $v_{1} - v_{2} \\in W$. (proof in algebra)\n(c) $V/W$ is a vector space, and the zero vector is $0_{V} + W = W$. ($0_{V}$ is the zero vector of $V$.)\nProof (a) Assuming $(\\Longrightarrow)$\nAssume $v + W$ is a subspace of $V$. Then, considering $0_{V}$ as the zero vector of $V$, $0_{V} \\in v + W$ holds. Therefore, for some $w \\in W$, $0_{V} = v + w$ and $w = -v \\in W$ hold. $W$ being a subspace of $V$ is closed under scalar multiplication, so $v = -(-v) \\in W$ holds.\nAssuming $(\\Longleftarrow)$\nAssume $v \\in W$. To show $v + W$ is a subspace of $V$, it suffices to show closure under addition and scalar multiplication. Let\u0026rsquo;s say $v + w_{1}, v + w_{2} \\in v + W$. Adding these two gives:\n$$ (v + w_{1}) + (v_{1} + w_{2}) = v + (v + w_{1} + w_{2}) $$\nSince $W$ is a subspace, it\u0026rsquo;s closed under addition, and by assumption $v$ is an element of $W$, so for some $w_{3} \\in W$, the following holds:\n$$ v + (v + w_{1} + w_{2}) = v + w_{3} \\in W $$\nNow, let\u0026rsquo;s say $a \\in F$. Then similarly, by assumption, for some $w_{4} \\in W$, the following holds:\n$$ a(v + w) = v + \\left( (a-1)v + aw \\right) = v + w_{4} \\in W $$\n‚ñ†\n(b) Assuming $(\\Longrightarrow)$\nAssume $v_{1} + W = v_{2} + W$. Then, for the zero vector $0_{V}$ of $V$ and some $w \\in W$, the following holds:\n$$ v_{1} + 0_{V} = v_{2} + w \\implies v_{1} - v_{2} = w \\in W $$\nAssuming $(\\Longleftarrow)$\nAssume $v_{1} - v_{2} \\in W$. Then:\n$$ \\begin{align*} v_{2} + W \u0026amp;= \\left\\{ v_{2} + w : w \\in W \\right\\} \\\\ \u0026amp;= \\left\\{ v_{2} + \\left( (v_{1} - v_{2}) + w \\right) : w \\in W \\right\\} \\\\ \u0026amp;= \\left\\{ v_{1} + w : w \\in W \\right\\} \\\\ \u0026amp;= v_{1} + W \\end{align*} $$\n‚ñ†\nSee Also Cosets in abstract algebra Properties of cosets Stephen H. Friedberg, Linear Algebra (4th Edition, 2002), p23\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3359,"permalink":"https://freshrimpsushi.github.io/en/posts/3359/","tags":null,"title":"Residual Classes and Quotient Spaces in Linear Algebra"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, A ? B : C is known as the Ternary Operator, which returns B if A is true and C otherwise. Just like binary operations are defined as functions in mathematics, the ternary operation is also a function. It\u0026rsquo;s similar to an if statement but has this fundamental difference, making it very useful once you\u0026rsquo;re accustomed to it. However, it can make the code less readable, so it\u0026rsquo;s not necessary to overuse it, but since others may use it, it\u0026rsquo;s good to get familiar with it to some extent.\nCode julia\u0026gt; x = iseven(2) ? \u0026#34;even\u0026#34; : \u0026#34;odd\u0026#34;; x\r\u0026#34;even\u0026#34;\rjulia\u0026gt; y = iseven(3) ? \u0026#34;even\u0026#34; : \u0026#34;odd\u0026#34;; y\r\u0026#34;odd\u0026#34; As seen above, these commands assign the string \u0026quot;even\u0026quot; or \u0026quot;odd\u0026quot; to variables x, y, depending on whether the given number is even or odd.\njulia\u0026gt; x * y\r\u0026#34;evenodd\u0026#34; Since it\u0026rsquo;s a function rather than a conditional statement, it allows for such convenient code. Trying to accomplish the same functionality using only if statements could unnecessarily lengthen the code due to issues like scope.\nComplete Code x = iseven(2) ? \u0026#34;even\u0026#34; : \u0026#34;odd\u0026#34;; x\ry = iseven(3) ? \u0026#34;even\u0026#34; : \u0026#34;odd\u0026#34;; y\rx * y Environment OS: Windows julia: v1.6.3 ","id":2328,"permalink":"https://freshrimpsushi.github.io/en/posts/2328/","tags":null,"title":"Julia's Ternary Operator ? :"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview To make replacements, use the replace!() method1. The first argument should be the column of the dataframe you want to change, and the second argument takes a pair A =\u0026gt; B. It\u0026rsquo;s important that it\u0026rsquo;s the dataframe\u0026rsquo;s column being specified here.\nCode julia\u0026gt; WJSN\r10√ó4 DataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161 Ï™ºÍº¨ÎØ∏\r2 ‚îÇ Îã§Ïõê 97 167 Î©îÎ≥¥Ï¶à\r3 ‚îÇ Î£®Îã§ 97 157 Ï™ºÍº¨ÎØ∏\r4 ‚îÇ ÏÜåÏ†ï 95 166 Î≥¥Ïä§Ï¶à\r5 ‚îÇ ÏàòÎπà 96 159 Ï™ºÍº¨ÎØ∏\r6 ‚îÇ Ïó∞Ï†ï 99 165 Î©îÎ≥¥Ï¶à\r7 ‚îÇ Ï£ºÏó∞ 98 172 Î≥¥Ïä§Ï¶à\r8 ‚îÇ ÏßÄÏó∞ 95 163 Î≥¥Ïä§Ï¶à\r9 ‚îÇ ÏßÑÏàô 99 162 Ï™ºÍº¨ÎØ∏\r10 ‚îÇ ÌòÑÏ†ï 94 165 Î≥¥Ïä§Ï¶à The example uses the WJSN dataframe as shown above.\njulia\u0026gt; replace!(WJSN.member, \u0026#34;ÏßÑÏàô\u0026#34; =\u0026gt; \u0026#34;Ïó¨Î¶Ñ\u0026#34;); WJSN\r10√ó4 DataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161 Ï™ºÍº¨ÎØ∏\r2 ‚îÇ Îã§Ïõê 97 167 Î©îÎ≥¥Ï¶à\r3 ‚îÇ Î£®Îã§ 97 157 Ï™ºÍº¨ÎØ∏\r4 ‚îÇ ÏÜåÏ†ï 95 166 Î≥¥Ïä§Ï¶à\r5 ‚îÇ ÏàòÎπà 96 159 Ï™ºÍº¨ÎØ∏\r6 ‚îÇ Ïó∞Ï†ï 99 165 Î©îÎ≥¥Ï¶à\r7 ‚îÇ Ï£ºÏó∞ 98 172 Î≥¥Ïä§Ï¶à\r8 ‚îÇ ÏßÄÏó∞ 95 163 Î≥¥Ïä§Ï¶à\r9 ‚îÇ Ïó¨Î¶Ñ 99 162 Ï™ºÍº¨ÎØ∏\r10 ‚îÇ ÌòÑÏ†ï 94 165 Î≥¥Ïä§Ï¶à The \u0026quot;Jinsuk\u0026quot; in the :member column was changed to \u0026quot;Yeoreum\u0026quot;. Note that replace!() was used here, not replace(), and that it was a specific column of the dataframe that was specified.\njulia\u0026gt; replace!(WJSN.unit, \u0026#34;Î≥¥Ïä§Ï¶à\u0026#34; =\u0026gt; \u0026#34;ÎçîÎ∏îÎûô\u0026#34;); WJSN\r10√ó4 DataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161 Ï™ºÍº¨ÎØ∏\r2 ‚îÇ Îã§Ïõê 97 167 Î©îÎ≥¥Ï¶à\r3 ‚îÇ Î£®Îã§ 97 157 Ï™ºÍº¨ÎØ∏\r4 ‚îÇ ÏÜåÏ†ï 95 166 ÎçîÎ∏îÎûô\r5 ‚îÇ ÏàòÎπà 96 159 Ï™ºÍº¨ÎØ∏\r6 ‚îÇ Ïó∞Ï†ï 99 165 Î©îÎ≥¥Ï¶à\r7 ‚îÇ Ï£ºÏó∞ 98 172 ÎçîÎ∏îÎûô\r8 ‚îÇ ÏßÄÏó∞ 95 163 ÎçîÎ∏îÎûô\r9 ‚îÇ Ïó¨Î¶Ñ 99 162 Ï™ºÍº¨ÎØ∏\r10 ‚îÇ ÌòÑÏ†ï 94 165 ÎçîÎ∏îÎûô The \u0026quot;Bozuz\u0026quot; in the :unit column was uniformly changed to \u0026quot;The Black\u0026quot;.\nComplete Code using DataFrames\rWJSN = DataFrame(\rmember = [\u0026#34;Îã§ÏòÅ\u0026#34;,\u0026#34;Îã§Ïõê\u0026#34;,\u0026#34;Î£®Îã§\u0026#34;,\u0026#34;ÏÜåÏ†ï\u0026#34;,\u0026#34;ÏàòÎπà\u0026#34;,\u0026#34;Ïó∞Ï†ï\u0026#34;,\u0026#34;Ï£ºÏó∞\u0026#34;,\u0026#34;ÏßÄÏó∞\u0026#34;,\u0026#34;ÏßÑÏàô\u0026#34;,\u0026#34;ÌòÑÏ†ï\u0026#34;],\rbirth = [99,97,97,95,96,99,98,95,99,94],\rheight = [161,167,157,166,159,165,172,163,162,165],\runit = [\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î≥¥Ïä§Ï¶à\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;,\u0026#34;Î≥¥Ïä§Ï¶à\u0026#34;,\u0026#34;Î≥¥Ïä§Ï¶à\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î≥¥Ïä§Ï¶à\u0026#34;]\r)\rWJSN\rreplace!(WJSN.member, \u0026#34;ÏßÑÏàô\u0026#34; =\u0026gt; \u0026#34;Ïó¨Î¶Ñ\u0026#34;); WJSN\rreplace!(WJSN.unit, \u0026#34;Î≥¥Ïä§Ï¶à\u0026#34; =\u0026gt; \u0026#34;ÎçîÎ∏îÎûô\u0026#34;); WJSN See Also How to replace all NaNs in a dataframe with 0 at once Environment OS: Windows julia: v1.6.3 https://dataframes.juliadata.org/stable/man/working_with_dataframes/#Replacing-Data\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2326,"permalink":"https://freshrimpsushi.github.io/en/posts/2326/","tags":null,"title":"How to Change a Specific Value in a DataFrame in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview 1 Use the freqtable() function from the FreqTables.jl package. It provides a similar functionality to the freq() function in R.\nCode Arrays julia\u0026gt; compartment = rand([\u0026#39;S\u0026#39;,\u0026#39;I\u0026#39;,\u0026#39;R\u0026#39;], 1000);\rjulia\u0026gt; freqtable(compartment)\r3-element Named Vector{Int64}\rDim1 ‚îÇ\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ\r\u0026#39;I\u0026#39; ‚îÇ 316\r\u0026#39;R\u0026#39; ‚îÇ 342\r\u0026#39;S\u0026#39; ‚îÇ 342 By inserting an array like shown above, it will count the frequency for each class.\nDataFrames freqtable() is particularly useful for dataframes. Let\u0026rsquo;s load the built-in data ToothGrowth, just like in the example of regression analysis with qualitative variables in R.\njulia\u0026gt; ToothGrowth = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;ToothGrowth\u0026#34;)\r60√ó3 DataFrame\rRow ‚îÇ Len Supp Dose ‚îÇ Float64 Cat‚Ä¶ Float64\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 4.2 VC 0.5\r2 ‚îÇ 11.5 VC 0.5\r3 ‚îÇ 7.3 VC 0.5\r4 ‚îÇ 5.8 VC 0.5\r‚ãÆ ‚îÇ ‚ãÆ ‚ãÆ ‚ãÆ\r58 ‚îÇ 27.3 OJ 2.0\r59 ‚îÇ 29.4 OJ 2.0\r60 ‚îÇ 23.0 OJ 2.0\r53 rows omitted\rjulia\u0026gt; freqtable(ToothGrowth, :Len)\r43-element Named Vector{Int64}\rLen ‚îÇ\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ\r4.2 ‚îÇ 1\r5.2 ‚îÇ 1\r5.8 ‚îÇ 1\r6.4 ‚îÇ 1\r‚ãÆ ‚ãÆ\r29.5 ‚îÇ 1\r30.9 ‚îÇ 1\r32.5 ‚îÇ 1\r33.9 ‚îÇ 1\rjulia\u0026gt; freqtable(ToothGrowth, :Supp)\r2-element Named Vector{Int64}\rSupp ‚îÇ\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ\r\u0026#34;OJ\u0026#34; ‚îÇ 30\r\u0026#34;VC\u0026#34; ‚îÇ 30\rjulia\u0026gt; freqtable(ToothGrowth, :Dose)\r3-element Named Vector{Int64}\rDose ‚îÇ\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ\r0.5 ‚îÇ 20\r1.0 ‚îÇ 20\r2.0 ‚îÇ 20 ToothGrowth contains data on the length of teeth (:Len) in guinea pigs fed different amounts of vitamin C or orange juice (:Supp). Calculating the frequencies for each column as shown tidies up the data nicely. It demonstrates that the data doesn‚Äôt necessarily have to be categorical.\njulia\u0026gt; freqtable(ToothGrowth, :Supp, :Dose)\r2√ó3 Named Matrix{Int64}\rSupp ‚ï≤ Dose ‚îÇ 0.5 1.0 2.0\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r\u0026#34;OJ\u0026#34; ‚îÇ 10 10 10\r\u0026#34;VC\u0026#34; ‚îÇ 10 10 10 Of course, this type of table is most effective for categorical data. Calculating the frequencies for :Supp, and :Dose automatically divides it into 2D categories for us.\njulia\u0026gt; freqtable(ToothGrowth, :Len, :Dose, :Supp)\r43√ó3√ó2 Named Array{Int64, 3}\r[:, :, Supp=\u0026#34;OJ\u0026#34;] =\rLen ‚ï≤ Dose ‚îÇ 0.5 1.0 2.0\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r4.2 ‚îÇ 0 0 0\r‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ\r33.9 ‚îÇ 0 0 0\r[:, :, Supp=\u0026#34;VC\u0026#34;] =\rLen ‚ï≤ Dose ‚îÇ 0.5 1.0 2.0\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r4.2 ‚îÇ 1 0 0\r‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ\r33.9 ‚îÇ 0 0 1 Calculating across more than 3 columns simply returns the class counts in a 2D table. At this point, it almost loses any meaning in terms of exploring or summarizing data.\nPerformance Comparison julia\u0026gt; @time for t in 1:10^4\rfreqtable(compartment)\rend\r@time for t in 1:10^4\rcount(compartment .== \u0026#39;S\u0026#39;)\rcount(compartment .== \u0026#39;I\u0026#39;)\rcount(compartment .== \u0026#39;R\u0026#39;)\rend\r0.068229 seconds (340.00 k allocations: 27.466 MiB)\r0.059198 seconds (180.00 k allocations: 134.125 MiB, 36.71% gc time) Leaving the table aside, the notion of counting frequencies itself seems useful. Several tests were conducted measuring the speed of manual counting versus using freqtable() to compute the frequencies all at once. Neither was consistently faster, fluctuating depending on the amount of data or the number of classes. Overall, freqtable() tended to be slower, but not by a huge margin. So, regardless of speed, it\u0026rsquo;s worth using thoughtfully when needed.\nFull Code using FreqTables\rcompartment = rand([\u0026#39;S\u0026#39;,\u0026#39;I\u0026#39;,\u0026#39;R\u0026#39;], 1000);\rfreqtable(compartment)\rusing RDatasets\rToothGrowth = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;ToothGrowth\u0026#34;)\rfreqtable(ToothGrowth, :Len)\rfreqtable(ToothGrowth, :Supp)\rfreqtable(ToothGrowth, :Dose)\rfreqtable(ToothGrowth, :Supp, :Dose)\rfreqtable(ToothGrowth, :Len, :Dose, :Supp)\r@time for t in 1:10^4\rfreqtable(compartment)\rend\r@time for t in 1:10^4\rcount(compartment .== \u0026#39;S\u0026#39;)\rcount(compartment .== \u0026#39;I\u0026#39;)\rcount(compartment .== \u0026#39;R\u0026#39;)\rend Environment OS: Windows julia: v1.6.3 FreqTables v0.4.5 https://github.com/nalimilan/FreqTables.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2324,"permalink":"https://freshrimpsushi.github.io/en/posts/2324/","tags":null,"title":"How to Calculate Frequency in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Overview Let $\\beta = v_{1}, \\dots, v_{k}$ be the set of eigenvectors of the linear transformation $T : V \\to V$. Then, it can be understood that $T$ maps $\\span{\\beta}$ to $\\span{\\beta}$. A subspace that maps itself to itself in this manner is defined as an invariant subspace.\nDefinition1 Let $V$ be a vector space, and $T : V \\to V$ a linear transformation. A subspace $W$ is called an $T$-invariant subspace if it satisfies the following condition:\n$$ T(W) \\subset W $$\nIn other words,\n$$ T(v) \\in W\\quad \\forall v \\in W $$\n$W$ is an $T$-invariant subspace.\nDescription For the linear transformation $T : V \\to V$, the following are examples of $T$-invariant subspaces:\n$\\left\\{ 0 \\right\\}$ $V$ Range $R(T)$ Null space $N(T)$ Eigenspace $E_{\\lambda}$ 1 and 2 are trivial. For any subset $A \\subset V$, since $T(A) \\subset R(T)$, $R(T)$ is $T$-invariant. Because $0 \\in N(T)$, $T(N(T)) \\subset N(T)$. Since $T(\\lambda x) = \\lambda (\\lambda x)$, $T(E_{\\lambda}) \\subset E_{\\lambda}$.\nIf $W$ is an invariant subspace of $T : V \\to V$, a restriction map $T|_{W} : W \\to W$ can naturally be defined. In this case, $T|_{W}$ inherits the properties of $T$, and the following theorem shows one relationship between $T$ and $T|_{W}$. Simply put, the characteristic polynomial of $T|_{W}$ is a factor of the characteristic polynomial of $T$. The conclusion itself can also be obtained as a corollary of another theorem.\nTheorem Let $V$ be a dimension vector space of dimension $n$, $T : V \\to V$ a linear transformation, and $W$ an $T$-invariant. Then, the characteristic polynomial of $T|_{W}$ divides the characteristic polynomial of $T$.\nProof Choose an ordered basis $\\gamma = \\left\\{ v_{1} ,\\dots, v_{k} \\right\\}$ of $W$. Then, extend it to an ordered basis $\\beta = \\left\\{ v_{1}, \\dots, v_{k}, v_{k+1}, \\dots, v_{n} \\right\\}$ of $V$. Let them be $A = \\begin{bmatrix} T \\end{bmatrix}_{\\beta}$ and $B_{1} = \\begin{bmatrix} T|_{W} \\end{bmatrix}_{\\gamma}$, respectively. Then, the matrix $A$ can be represented as the following block matrix.\n$$ A = \\begin{bmatrix} B_{1} \u0026amp; B_{2} \\\\ O \u0026amp; B_{3} \\end{bmatrix} $$\nLet $f(t)$ be the characteristic polynomial of $T$, and $g(t)$ the characteristic polynomial of $T|_{W}$. Then, by the determinant formula for block matrices (where $I$ is an identity matrix of appropriate dimension for matrix calculation), the following is obtained:\n$$ f(t) = \\det(A-tI) = \\det \\begin{bmatrix} B_{1}-tI \u0026amp; B_{2} \\\\ O \u0026amp; B_{3}-tI \\end{bmatrix} = g(t) \\det(B_{3}-tI) $$\nTherefore, $g(t)$ divides $f(t)$.\n‚ñ†\nSee Also Cyclic subspace Stephen H. Friedberg, Linear Algebra (4th Edition, 2002), p313-315\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3353,"permalink":"https://freshrimpsushi.github.io/en/posts/3353/","tags":null,"title":"Invariant Subspaces of Vector Spaces"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide Let\u0026rsquo;s say we have an example.csv file like the one above. When loading it into a dataframe, sometimes we want to create an entirely empty dataframe that only retains the column names, without importing all the data. This is necessary in cases where an empty dataframe is needed.\nusing CSV # Loading the dataframe with no rows df_empty = CSV.read(\u0026#34;example.csv\u0026#34;, DataFrame; limit = 0) In the resulting dataframe created above, it has all three columns intact but hasn\u0026rsquo;t imported any of their contents.\nCSV.read(limit = 1)\nBy using the limit = 1 option, the dataframe is loaded with only one line. CSV.read()[[false],:]\nBy not referring to any rows with a bit array of length $1$ [false], an empty dataframe remained. # Verifying column names remain intact column_names = names(df_empty) By checking the column names with the names() function, we can confirm that the column names are appropriately retained.\n# Inserting new data into the empty dataframe push!(df_empty, [1, \u0026#34;new_data\u0026#34;, 3.14]) When inserting new data with push!(), it works properly just like the original dataframe.\nWhat if just doing limit = 0? # Attempting to load dataframe with limit 0 to get empty dataframe df_empty_error = CSV.read(\u0026#34;example.csv\u0026#34;, DataFrame; limit = 0) A StackOverflowError occurs.\nEnvironment OS: Windows julia: v1.6.3 ","id":2322,"permalink":"https://freshrimpsushi.github.io/en/posts/2322/","tags":null,"title":"Reading Only Columns from a CSV File in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide 1 using RDatasets\riris = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;iris\u0026#34;)\rdescribe(iris) describe() function can be used. Let\u0026rsquo;s summarize the iris data.\njulia\u0026gt; describe(iris)\r5√ó7 DataFrame\rRow ‚îÇ variable mean min median max nmissing eltype\r‚îÇ Symbol Union‚Ä¶ Any Union‚Ä¶ Any Int64 DataType\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ SepalLength 5.84333 4.3 5.8 7.9 0 Float64\r2 ‚îÇ SepalWidth 3.05733 2.0 3.0 4.4 0 Float64\r3 ‚îÇ PetalLength 3.758 1.0 4.35 6.9 0 Float64\r4 ‚îÇ PetalWidth 1.19933 0.1 1.3 2.5 0 Float64\r5 ‚îÇ Species setosa virginica 0 CategoricalValue{String, UInt8} Environment OS: Windows julia: v1.6.3 https://dataframes.juliadata.org/stable/man/working_with_dataframes/#Summarizing-Data\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2320,"permalink":"https://freshrimpsushi.github.io/en/posts/2320/","tags":null,"title":"How to View Data Frame Summaries in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let\u0026rsquo;s define $V$ and $n$ as dimension vector spaces, $T : V \\to V$ as linear transformation. Let\u0026rsquo;s also define $\\lambda$ as the eigenvalue of $T$. The set defined as follows, $E_{\\lambda}$, is called the eigenspace of $T$ corresponding to the eigenvalue $\\lambda$.\n$$ E_{\\lambda} = V_{\\lambda} := \\left\\{ x \\in V : Tx = \\lambda x \\right\\} = N(T - \\lambda I) $$\nIn this case, $N$ is the null space.\nSimilarly, the eigenspace of a square matrix $A$ is defined as the eigenspace of $L_{A}$.\nExplanation Although there is a condition that to be an eigenvector, one must not be the zero vector, there is no specific condition in the definition of $E_{\\lambda}$ that $x$ must be an eigenvector. Therefore, $E_{\\lambda}$ is the set of eigenvectors corresponding to $\\lambda$ and the zero vector. It\u0026rsquo;s important to note that for $E_{\\lambda}$ to be a subspace, it must include the zero vector. Indeed, $E_{\\lambda}$ is a subspace of $V$ since $T$, being a linear transformation, is obviously closed under addition and scalar multiplication (subspace criterion). If we define $x, y \\in E_{\\lambda}$,\n$$ T(ax + y) = aT(x) + T(y) = a\\lambda x + \\lambda y = \\lambda (ax + y) $$\nthen $ax + y \\in E_{\\lambda}$ holds.\nGeometric Multiplicity The dimension of the eigenspace $E_{\\lambda}$ corresponding to eigenvalue $\\lambda$ is known as the geometric multiplicity of $\\lambda$.\nIn other words, it is the number of linearly independent eigenvectors corresponding to $\\lambda$, and thus, it is at least $1$. Its maximum value is related to the algebraic multiplicity.\nTheorem Let\u0026rsquo;s define the algebraic multiplicity of eigenvalue $\\lambda$ of $T$ as $m$. The algebraic multiplicity is greater than or equal to the geometric multiplicity.\n$$ 1 \\le \\dim E_{\\lambda} \\le m $$\nProof Let\u0026rsquo;s denote the ordered basis of $E_{\\lambda}$ by $\\gamma = \\left\\{ v_{1}, \\dots, v_{p} \\right\\}$. The expanded ordered basis of $V$ is denoted as $\\beta = \\left\\{ v_{1}, \\dots, v_{p}, v_{p+1}, \\dots, v_{n} \\right\\}$. The matrix representation of $T$ is referred to as $A = \\begin{bmatrix} T \\end{bmatrix}_{\\beta}$. Then $A$ is as follows in block matrix form:\n$$ A = \\begin{bmatrix} \\begin{bmatrix} T|_{E_{\\lambda}} \\end{bmatrix}_{\\gamma} \u0026amp; B \\\\ O_{n-p} \u0026amp; C \\end{bmatrix} $$\n$O_{n-p}$ is a $n-p \\times n-p$ zero matrix. In this case, for $1 \\le i \\le p$, since $Tv_{i} = \\lambda v_{i}$, the coordinate vector of $Tv_{i}$ is as follows:\n$$ \\begin{bmatrix} Tv_{i} \\end{bmatrix}_{\\gamma} = \\begin{bmatrix} 0 \\\\ \\vdots \\\\ \\lambda \\\\ \\vdots \\\\ 0 \\end{bmatrix}i\\text{-th row} $$\nTherefore, since $\\begin{bmatrix} T|_{E_{\\lambda}} \\end{bmatrix}_{\\gamma} = \\begin{bmatrix} \\begin{bmatrix} Tv_{1} \\end{bmatrix}_{\\gamma} \u0026amp; \\cdots \u0026amp; \\begin{bmatrix} Tv_{p} \\end{bmatrix}_{\\gamma} \\end{bmatrix}$,\n$$ A = \\begin{bmatrix} \\lambda I_{p} \u0026amp; B \\\\ O \u0026amp; C \\end{bmatrix} $$\n$I_{p}$ is a $p \\times p$ identity matrix.\nDeterminant of Block Matrices\nLet\u0026rsquo;s consider $A = \\begin{bmatrix} A_{1} \u0026amp; A_{2} \\\\ O \u0026amp; A_{3} \\end{bmatrix}$ to be a block matrix. Then, the following holds:\n$$ \\det A = \\det A_{1} \\det A_{3} $$\nHence, the characteristic polynomial of $T$ is as follows:\n$$ \\begin{align*} f(t) = \\det (A - t I_{n}) \u0026amp;= \\det \\begin{bmatrix} \\lambda I_{p} - \\lambda I_{p} \u0026amp; B \\\\ O \u0026amp; C - tI_{n-p} \\end{bmatrix} \\\\ \u0026amp; = \\det \\left( (\\lambda - t)I_{p} \\right) \\det \\left( C - tI_{n-p} \\right) \\\\ \u0026amp; = (\\lambda - t)^{p} \\det \\left( C - tI_{n-p} \\right) \\\\ \u0026amp; = (-1)^{p}(t - \\lambda)^{p} \\det \\left( C - tI_{n-p} \\right) \\\\ \\end{align*} $$\nThis shows that $(t - \\lambda)^{p}$ is a factor of the characteristic polynomial $f(t)$. Therefore, $f(t)$ has at least $\\lambda$ as a root of multiplicity $p$, and by the definition of algebraic multiplicity, the algebraic multiplicity is greater than or equal to the geometric multiplicity.\n‚ñ†\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p264\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3349,"permalink":"https://freshrimpsushi.github.io/en/posts/3349/","tags":null,"title":"Eigen Spaces of Linear Transformations and Geometric Multiplicity"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview The CategoricalArrays.jl package in Julia serves a similar function to factor in R.\nCode julia\u0026gt; A = [\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;green\u0026#34;]\r4-element Vector{String}:\r\u0026#34;red\u0026#34;\r\u0026#34;blue\u0026#34;\r\u0026#34;red\u0026#34;\r\u0026#34;green\u0026#34;\rjulia\u0026gt; B = categorical(A)\r4-element CategoricalArray{String,1,UInt32}:\r\u0026#34;red\u0026#34;\r\u0026#34;blue\u0026#34;\r\u0026#34;red\u0026#34;\r\u0026#34;green\u0026#34;\rjulia\u0026gt; levels(B)\r3-element Vector{String}:\r\u0026#34;blue\u0026#34;\r\u0026#34;green\u0026#34;\r\u0026#34;red\u0026#34; categorical() The categorical() function allows for casting a regular array to a categorical array.\nlevels() With the levels() function, one can view the categories. Naturally, there are no duplicates in categories, and even if an element corresponding to a category is missing from the array, the category itself remains.\njulia\u0026gt; B[2] = \u0026#34;red\u0026#34;; B\r4-element CategoricalArray{String,1,UInt32}:\r\u0026#34;red\u0026#34;\r\u0026#34;red\u0026#34;\r\u0026#34;red\u0026#34;\r\u0026#34;green\u0026#34;\rjulia\u0026gt; levels(B)\r3-element Vector{String}:\r\u0026#34;blue\u0026#34;\r\u0026#34;green\u0026#34;\r\u0026#34;red\u0026#34; This characteristic of maintaining categories regardless of the array\u0026rsquo;s state is very useful in certain coding contexts. It\u0026rsquo;s particularly beneficial in data analysis tasks, where subsets of the dataset are frequently handled. Knowing the categorical array in such cases can be a great help.\nOptimization Technically, instead of using levels(), using unique() on a regular array could achieve a similar implementation.\njulia\u0026gt; @time for t in 1:10^6\runique(A)\rend\r0.543157 seconds (6.00 M allocations: 579.834 MiB, 17.33% gc time)\rjulia\u0026gt; @time for t in 1:10^6\rlevels(B)\rend\r0.013324 seconds However, the speed difference is about 40 times. Since the categories get updated every time the array changes, there\u0026rsquo;s no need to undergo any separate computation process, allowing for immediate referencing.\nFull Code using CategoricalArrays\rA = [\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;green\u0026#34;]\rB = categorical(A)\rlevels(B)\rB[2] = \u0026#34;red\u0026#34;; B\rlevels(B)\r@time for t in 1:10^6\runique(A)\rend\r@time for t in 1:10^6\rlevels(B)\rend Environment OS: Windows julia: v1.6.3 CategoricalArrays v0.10.2 ","id":2318,"permalink":"https://freshrimpsushi.github.io/en/posts/2318/","tags":null,"title":"Julia's Categorical Array"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition 1 A $n$-simplex $\\Delta^{n}$, whose convex hull consists of affinely independent $v_{0}, v_{1} , \\cdots , v_{n} \\in \\mathbb{R}^{n+1}$, has vertices $v_{k}$. Formally, it is defined as follows: $$ \\Delta^{n} := \\left\\{ \\sum_{k} t_{k} v_{k} : v_{k} \\in \\mathbb{R}^{n+1} , t_{k} \\ge 0 , \\sum_{k} t_{k} = 1 \\right\\} $$ The faces of a $\\Delta^{n}$ are the $n-1$-simplices $\\Delta^{n-1}$ formed by removing a single vertex from $\\Delta^{n}$. The boundary of $\\Delta^{n}$ is the union of all its faces, denoted by $\\partial \\Delta^{n}$. The interior of a simplex $\\left( \\Delta^{n} \\right)^{\\circ} := \\Delta^{n} \\setminus \\partial \\Delta^{n}$ is called an Open Simplex. Affine independence means that $v_{1} - v_{0} , v_{2} - v_{0} , \\cdots , v_{n} - v_{0}$ is linearly independent. Description A simplex is a concept encountered in areas such as linear programming and algebraic topology, characterized by its simplicity, as its name suggests. In Korean, it is colloquially termed Îã®Ï≤¥.\n$n$-Simplex The difference between a convex hull and a $n$-simplex, as per the definition, lies only in the affine independence of the given vectors. Unlike the convex hull of a set $X$, it is precisely represented by exactly $v_{0}, v_{1} , \\cdots , v_{n}$, indicating it is a shape characterized solely by this representation.\n$$ \\left\\{ \\left( t_{0} , t_{1} , \\cdots , t_{n} \\right) \\in \\mathbb{R}^{n+1} : t_{k} \\ge 0 , \\sum_{k} t_{k} = 1 \\right\\} $$\nThis set is referred to as the Standard $n$-simplex. Considering only their combinations, regardless of the lengths of the vectors $v_{0}, v_{1} , \\cdots , v_{n}$, it is aptly called standardization.\nFor example, consider $\\Delta^{n} , n = 3,2,1,0$.\nAs seen, a $3$-simplex corresponds to a tetrahedron, a $2$-simplex to a triangle, a $1$-simplex to a line segment, and a $0$-simplex simply to a single point. The case where three points of a $2$-simplex lie on a single line is excluded by the assumption of affine independence. While a $n \\ge 4$ cannot be geometrically represented, there is no issue in generalizing it.\nBoundary and Open Simplex Fundamentally, the concepts of boundary and open simplex are no different from those of boundary and interior discussed in metric spaces, even the notation is identical.\nIn the example, faces of the tetrahedron, a $3$-simplex, are shown as triangles, a $2$-simplex, verifying that the term \u0026ldquo;face\u0026rdquo; fits perfectly. Even the faces of a $1$-simplex, a line segment, are the endpoints, the $0$-simplices. It makes perfect sense to refer to this collection of faces as the boundary.\nThe boundary $\\partial \\Delta^{3}$ and open simplex $\\left( \\Delta^{3} \\right)^{\\circ}$ of $\\Delta^{3}$ can be intuitively understood as shown in the picture.\nHatcher. (2002). Algebraic Topology: p103.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2317,"permalink":"https://freshrimpsushi.github.io/en/posts/2317/","tags":null,"title":"Definition of Simplex"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide Using the RDatasets.jl package should do the trick. The following is an example of how to load the simplest iris dataset. It includes a variety of datasets beyond the basic built-in ones, so make sure to check out GitHub1.\njulia\u0026gt; using RDatasets\rjulia\u0026gt; iris = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;iris\u0026#34;)\r150√ó5 DataFrame\rRow ‚îÇ SepalLength SepalWidth PetalLength PetalWidth Species\r‚îÇ Float64 Float64 Float64 Float64 Cat‚Ä¶\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 5.1 3.5 1.4 0.2 setosa\r2 ‚îÇ 4.9 3.0 1.4 0.2 setosa\r3 ‚îÇ 4.7 3.2 1.3 0.2 setosa\r‚ãÆ ‚îÇ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ\r149 ‚îÇ 6.2 3.4 5.4 2.3 virginica\r150 ‚îÇ 5.9 3.0 5.1 1.8 virginica\r145 rows omitted See Also How to Load Built-in Datasets in R Environment OS: Windows julia: v1.6.3 https://github.com/JuliaStats/RDatasets.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2316,"permalink":"https://freshrimpsushi.github.io/en/posts/2316/","tags":null,"title":"How to Load a Built-in Dataset in R Used in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition 1 A set of vectors $S := \\left\\{ v_{0} , v_{1}, \\cdots , v_{n} \\right\\} \\subset V$ is said to be Affinely Independent if the vectors in $S$ or $S$ itself are linearly independent. $$ v_{1} - v_{0} , v_{2} - v_{0} , \\cdots , v_{n} - v_{0} $$\nhttps://glossary.informs.org/ver2/mpgwiki/index.php?title=Affine_independence\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2315,"permalink":"https://freshrimpsushi.github.io/en/posts/2315/","tags":null,"title":"Definition of Affine Independence"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"## Guide For example, let\u0026#39;s check the version of the `Plots.jl` package. Press the `]` key in the REPL to enter the package mode. Here, if you type `status foo`, you can check the version of the `foo` package as follows. ![20211204_193048.png](20211204_193048.png#center) ## Environment - OS: Windows - julia: v1.6.3 ","id":2313,"permalink":"https://freshrimpsushi.github.io/en/posts/2313/","tags":null,"title":"How to Check Package Versions in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Use the isempty() function.\nCode julia\u0026gt; isempty([])\rtrue\rjulia\u0026gt; isempty(Set())\rtrue\rjulia\u0026gt; isempty(\u0026#34;\u0026#34;)\rtrue Though it\u0026rsquo;s mentioned as an array in the title, it actually could be a set or a string.\nOptimization Of course, checking if an array is empty by seeing if length() is $0$ might be fine too.\njulia\u0026gt; @time for t in 1:10^6\risempty([])\rend\r0.039721 seconds (1000.00 k allocations: 76.294 MiB, 27.85% gc time)\rjulia\u0026gt; @time for t in 1:10^6\rlength([]) == 0\rend\r0.041762 seconds (1000.00 k allocations: 76.294 MiB, 19.18% gc time) As you can see, for an empty array, both methods show no performance difference.\njulia\u0026gt; x = 1:10^6;\rjulia\u0026gt; @time for t in 1:10^6\risempty(x)\rend\r0.017158 seconds\rjulia\u0026gt; @time for t in 1:10^6\rlength(x) == 0\rend\r0.043243 seconds (1000.00 k allocations: 15.259 MiB) However, when the array is not empty, like above, you can see more than twice the speed difference. It\u0026rsquo;s natural that length() has to return the actual length while isempty() only needs to check if the first element exists. Considering aspects like readability or when using in conditional statements, using isempty() is more advisable.\nFull Code isempty([])\risempty(Set())\risempty(\u0026#34;\u0026#34;)\r@time for t in 1:10^6\risempty([])\rend\r@time for t in 1:10^6\rlength([]) == 0\rend\rx = 1:10^6\r@time for t in 1:10^6\risempty(x)\rend\r@time for t in 1:10^6\rlength(x) == 0\rend Environment OS: Windows julia: v1.6.3 ","id":2311,"permalink":"https://freshrimpsushi.github.io/en/posts/2311/","tags":null,"title":"How to Check if an Array is Empty in Julia"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Definitions 1 2 Let\u0026rsquo;s denote by $n \\in \\mathbb{N}_{0}$. A chain of abelian groups $C_{n}$ and homomorphisms $\\partial_{n} : C_{n} \\longrightarrow C_{n-1}$ $$ \\cdots \\longrightarrow C_{n+1} \\overset{\\partial_{n+1}}{\\longrightarrow} C_{n} \\overset{\\partial_{n}}{\\longrightarrow} C_{n-1} \\longrightarrow \\cdots \\longrightarrow C_{1} \\overset{\\partial_{1}}{\\longrightarrow} C_{0} \\overset{\\partial_{0}}{\\longrightarrow} 0 $$ that satisfies $$ \\partial_{n} \\circ \\partial_{n+1} = 0 $$ for all $n$ is called a Chain Complex. The quotient group $H_{n} := \\ker \\partial_{n} / \\text{Im} \\partial_{n+1}$ is called the $n$-th Homology Group of $\\mathcal{C}$. The homomorphism $\\partial_{n} : C_{n} \\longrightarrow C_{n-1}$ is called a Boundary or Differential operator. An element of $Z_{n} := \\ker \\partial_{n}$ is called a $n$-Cycle, and an element of $B_{n} := \\text{Im} \\partial_{n+1}$ is called a $n$-Boundary. A group $0$ is a magma as defined in $\\left\\{ 0 \\right\\}$. Essentially, it is an algebraic structure that is empty. The homomorphism $\\partial^{2} = 0$ is a zeromorphism. $\\text{Im}$ is an image. $\\ker$ is a kernel. Explanation It\u0026rsquo;s normal to feel puzzled. The definitions introduced are very strictly algebraic statements, so it\u0026rsquo;s recommended to quickly move on to simplicial homology for an intuitive understanding. (Although that isn\u0026rsquo;t particularly easy either) It can be difficult to grasp the algebraic terms for boundaries and differentials without looking at them geometrically.\nGeneralizability Actually, it\u0026rsquo;s known that the index set in a Chain Complex can not only be expanded to negative numbers beyond $\\mathbb{N}_{0} = \\left\\{ 0, 1, 2, \\cdots \\right\\}$ but also to real numbers. However, after $0$ as a reference point, moving towards negative entails a significant fade in topological or geometric meaning.\nExistence of Homology Groups Theorem\nLet\u0026rsquo;s assume $U, V, W$ is a vector space, and $T_{1} : U \\to V$, $T_{2} : V \\to W$ are linear transformations. Then, the following holds:\n$$ T_{2}T_{1} = 0 \\iff \\operatorname{Im} (T_{1}) \\subset \\ker (T_{2}) $$\nThe condition of a chain complex, $\\partial_{n} \\circ \\partial_{n+1} = 0$, is commonly abbreviated as $\\partial^{2} = 0$. No matter what $\\text{Im} \\partial_{n+1}$ is, after taking $\\partial_{n}$, it means that $0$ is generously defined to completely encompass $\\text{Im} \\partial_{n+1}$, implying $\\text{Im} \\partial_{n+1} \\subset \\ker \\partial_{n}$.\n$\\partial^{2} = 0$ leading to $\\ker \\partial_{n} / \\text{Im} \\partial_{n+1}$ might seem out of the blue, but historically, there was substantial research on algebraic structures that partition kernels into images as in $\\ker f / \\text{Im} g$, and $\\partial^{2} = 0$ was included in the definition more for its elegant expression than its intuitive meaning.\nBoundary and Differential The term for a $n$-cycle $Z_{n}$, ‚ÄúZyklus,‚Äù comes from German.\n$\\partial_{n}$, when viewed as the boundary of a simplex, naturally fits its naming, and the term differential, as defined in $$ \\lim_{h \\to 0} {{ f(x + h) - f(x) } \\over { h }} $$ like $$ \\partial \\left[ v_{0} , v_{1} \\right] = \\left[ v_{1} \\right] - \\left[ v_{0} \\right] $$, is understandably derived from the mathematical form of Difference. However, one cannot comprehend this from the bare definition of homology groups alone. These explanations only become plausible after the specific definition of $\\partial_{n}$ is given, and the universal applicability is understood. For now, it\u0026rsquo;s best to overlook the exact terminology and move forward.\nInfamy Homology is surprisingly well-known to the general public. While they might not remember the term \u0026ldquo;homology,\u0026rdquo; it has gained a cult-like popularity through stories on Twitter, becoming known as something even Seoul National University students can\u0026rsquo;t easily explain.\nHatcher. (2002). Algebraic Topology: p106.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMunkres. (1984). Elements of Algebraic Topology: p41.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2310,"permalink":"https://freshrimpsushi.github.io/en/posts/2310/","tags":null,"title":"Definition of Homology Groups"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition 1 Let $V$ be called a finite-dimensional vector space. Let $T : V \\to V$ be called a linear transformation. If there exists an ordered basis $\\beta$ for which the matrix representation $\\begin{bmatrix} T \\end{bmatrix}_{\\beta}$ of $T$ becomes a diagonal matrix, $T$ is said to be diagonalizable.\nFor a square matrix $A$, if the $L_{A}$ is diagonalizable, then the matrix $A$ is said to be diagonalizable.\nExplanation Suppose the linear transformation $T : V \\to V$ is diagonalizable. Let $\\beta = \\left\\{ v_{1}, \\dots, v_{n} \\right\\}$ be an ordered basis of $V$. And let $D = \\begin{bmatrix} T \\end{bmatrix}_{\\beta}$ be a diagonal matrix. Then, for each $v_{j} \\in \\beta$, we obtain the following.\n$$ T(v_{j}) = \\sum_{i} D_{ij} v_{i} = D_{jj}v_{j} $$\nIf it is said that $\\lambda_{j} = D_{jj}$,\n$$ T(v_{j}) = \\lambda_{j} v_{j} $$\nThe elements of the ordered basis that make $\\begin{bmatrix} T \\end{bmatrix}_{\\beta}$ a diagonal matrix satisfy such a special form of equation. Therefore, the vectors represented by such an ordered basis $\\beta$ simply involve multiplying each component by the scalar $\\lambda_{j}$, which is the same as applying the linear transformation $T$. These special vectors $v_{j}$ and scalars $\\lambda_{j}$ are called eigenvectors and eigenvalues, respectively. Thus, if we relate the condition of being diagonalizable to eigenvalues,\nExistence of $n$ linearly independent eigenvectors = Existence of a basis of eigenvectors $\\iff$ diagonalizable\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p245-246\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3335,"permalink":"https://freshrimpsushi.github.io/en/posts/3335/","tags":null,"title":"Diagonalizable Linear Transformation"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview People who have struggled with severe loneliness know, oh they know\nAnyone who has struggled with unknown errors while coding understands the critical importance of errors in programming\u0026hellip;\nIn Julia, errors can be thrown using the error() function or the @error macro. As of Julia v1.63, 25 types of built-in exceptions are defined1.\nCode julia\u0026gt; log(1 + 2im)\r0.8047189562170501 + 1.1071487177940904im Consider, for instance, when using the logarithmic function $\\log$ in a program, only real numbers should be allowed as input. However, Julia essentially provides an extension to complex numbers $\\log_{\\mathbb{C}}$ by default. The program running without errors is not an accomplishment. Unintended calculations can lead to unexpected problems, so if a calculation we do not want occurs, we should error out and not proceed.\nLet\u0026rsquo;s create a code that restricts the domain of the original log to real numbers $\\mathbb{R}$.\nerror() Function julia\u0026gt; function Rlog(x)\rif typeof(1 + 2im) \u0026lt;: Real\rreturn log(x)\relse\rerror(DomainError, \u0026#34;: Rlog allow real number only\u0026#34;)\rend\rend\rRlog(1 + 2im)\rERROR: LoadError: DomainError: Rlog allow real number only\rStacktrace:\r[1] error(::Type, ::String)\r@ Base .\\error.jl:42\r[2] Rlog(x::Complex{Int64})\r@ Main c:\\admin\\REPL.jl:7\r[3] top-level scope\r@ c:\\admin\\REPL.jl:11\rin expression starting at c:\\admin\\REPL.jl:11 In the above Rlog, if the input is not a real number, it is restricted to raise a DomainError.\n@error Macro julia\u0026gt; function Rlog2(x)\rif typeof(1 + 2im) \u0026lt;: Real\rreturn log(x)\relse\r@error \u0026#34;Rlog2 also allow Real number only\u0026#34;\rend\rend\rRlog2(1 + 2im)\r‚îå Error: Rlog2 also allow Real number only\r‚îî @ Main c:\\admin\\REPL.jl:17 In the above Rlog2, if the input is not a real number, it is limited to throw an error immediately.\nRaise and Throw both mean to cause an error to happen, and there\u0026rsquo;s no significant difference in the big picture. Raise is a term used in Python, etc., while Throw is used in Java, etc.\nFull Code log(1 + 2im)\rfunction Rlog(x)\rif typeof(1 + 2im) \u0026lt;: Real\rreturn log(x)\relse\rerror(DomainError, \u0026#34;: Rlog allow real number only\u0026#34;)\rend\rend\rRlog(1 + 2im)\rfunction Rlog2(x)\rif typeof(1 + 2im) \u0026lt;: Real\rreturn log(x)\relse\r@error \u0026#34;Rlog2 also allow Real number only\u0026#34;\rend\rend\rRlog2(1 + 2im) Environment OS: Windows julia: v1.6.3 https://docs.julialang.org/en/v1/manual/control-flow/#Built-in-Exceptions\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2309,"permalink":"https://freshrimpsushi.github.io/en/posts/2309/","tags":null,"title":"How to Handle Exceptions in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Overview The characteristic polynomial of linear transformation is defined. From the theorem below, it can be seen that solving equation $\\det(A - \\lambda I) = 0$ is equivalent to finding the eigenvalues. Therefore, it is quite natural to name $\\det(A - \\lambda I)$ the characteristic polynomial.\nTheorem1 Let\u0026rsquo;s say $F$ is any field, and $A \\in M_{n\\times n}(F)$. That $\\lambda \\in F$ is an eigenvalue of $A$ is equivalent to $\\det (A-\\lambda I) = 0$.\nProof Assume $\\lambda$ is an eigenvalue of $A$. Then,\n$$ \\begin{align*} \\lambda \\text{ is eigenvalue of } A \u0026amp;\\iff \\exist \\text{non-zero } v \\text{ such that } Av = \\lambda v \\\\ \u0026amp;\\iff \\exist \\text{non-zero } v \\text{ such that } (A - \\lambda I)v = 0 \\end{align*} $$\nConditions Equivalent to Invertibility\nLet\u0026rsquo;s say $A$ is a square matrix of size $n\\times n$. Then, the following propositions are all equivalent:\n$A$ is an invertible matrix. Homogeneous linear system $A\\mathbf{x}=\\mathbf{0}$ has only the trivial solution. $\\det{A} \\ne 0$ By the conditions equivalent to invertibility, $A - \\lambda I$ is not invertible, and $\\det (A - \\lambda I) = 0$.\nDefinition Let\u0026rsquo;s say $A \\in M_{n \\times n}(F)$. The polynomial $f(t) = \\det(A - tI)$ is called the characteristic polynomial of $A$. $f(t) = 0$ is called the characteristic equation.\nLet $V$ be a vector space of dimension $n$. Let $T : V \\to V$ be a linear transformation. Let $\\beta$ be an ordered basis of $V$. The characteristic polynomial $f(t)$ of $T$ is defined as the characteristic polynomial of the matrix representation of $T$. In other words, $f(t)$ is as follows.\n$$ f(t) = \\det\\left( \\begin{bmatrix} T \\end{bmatrix}_{\\beta} - t I \\right) $$\nExplanation According to the definition, the roots of the characteristic polynomial of $T : V \\to V$ are precisely the eigenvalues, and if the characteristic polynomial is factorable, $T$ has $n = \\dim(V)$ eigenvalues (not said to be distinct).\nBy definition, it might seem that the characteristic polynomial of $T$ depends on how the ordered basis $\\beta$ is chosen, but in reality, it does not. For this reason, the characteristic polynomial of the linear transformation $T$ is sometimes denoted as follows.\n$$ \\det (T - \\lambda I) $$\nLet\u0026rsquo;s check. If $\\beta$, $\\beta^{\\prime}$ are the ordered bases of $V$, and $Q$ is the change of basis matrix that converts $\\beta$ coordinates into $\\beta^{\\prime}$ coordinates, then,\n$$ \\begin{align*} \\det( \\begin{bmatrix} T \\end{bmatrix}_{\\beta} - tI) \u0026amp;= \\det( \\begin{bmatrix} T \\end{bmatrix}_{\\beta} - tI ) \\det Q^{-1} \\det Q \\\\ \u0026amp;= \\det Q^{-1} \\det( \\begin{bmatrix} T \\end{bmatrix}_{\\beta} - tI ) \\det Q \\\\ \u0026amp;= \\det \\left( Q^{-1} (\\begin{bmatrix} T \\end{bmatrix}_{\\beta} - tI) Q \\right) \\\\ \u0026amp;= \\det \\left( Q^{-1}\\begin{bmatrix} T \\end{bmatrix}_{\\beta}Q - tI \\right) \\\\ \u0026amp;= \\det \\left( \\begin{bmatrix} T \\end{bmatrix}_{\\beta^{\\prime}} - tI \\right) \\end{align*} $$\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p248\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3339,"permalink":"https://freshrimpsushi.github.io/en/posts/3339/","tags":null,"title":"Characteristics Polynomial of Linear Transformation"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview nrow(), ncol(), and size() can be used. Unlike with R, length() results in an error.\nCode julia\u0026gt; df = DataFrame(rand(100000,5), :auto)\r100000√ó5 DataFrame\rRow ‚îÇ x1 x2 x3 x4 x5 ‚îÇ Float64 Float64 Float64 Float64 Float64\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 0.474921 0.942137 0.0523668 0.588696 0.0176242\r2 ‚îÇ 0.842828 0.910385 0.216194 0.794668 0.664883\r3 ‚îÇ 0.0350312 0.96542 0.837923 0.920311 0.748409\r4 ‚îÇ 0.613249 0.731643 0.941826 0.688649 0.161736\r‚ãÆ ‚îÇ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ\r99998 ‚îÇ 0.767794 0.242687 0.965885 0.557483 0.723849\r99999 ‚îÇ 0.743936 0.67815 0.529923 0.247698 0.861302\r100000 ‚îÇ 0.628269 0.252583 0.985485 0.24541 0.942741\r99993 rows omitted df is a dataframe with 100,000 rows and 5 columns.\njulia\u0026gt; nrow(df)\r100000\rjulia\u0026gt; ncol(df)\r5\rjulia\u0026gt; size(df)\r(100000, 5) nrow() and ncol() return the number of rows and columns, respectively, and size() returns the size of the rows and columns as a tuple. By referencing them in the order of rows, columns, you can know the size of the rows and columns separately. At first glance, size() seems much more useful, but let\u0026rsquo;s compare their performances.\nOptimization julia\u0026gt; @time for i in 1:10^6\rnrow(df)\rend\r0.051730 seconds (1000.00 k allocations: 15.259 MiB)\rjulia\u0026gt; @time for i in 1:10^6\rsize(df)[1]\rend\r0.536297 seconds (3.00 M allocations: 61.035 MiB, 5.44% gc time) Above is a comparison of the speed of nrow() and size(). As expected, the single-function nrow() is faster. The test may seem forced by running it excessively, but in cases where the dataframe is significantly larger‚Äîhandling big data or using size() thinking it won‚Äôt make much difference can result in a waste of unnecessary time.\nAlso, there is a big difference in terms of code readability. nrow() and ncol() are function names commonly used in other languages and are undoubtedly the number of rows and columns, but size() greatly reduces readability due to the suffixing index. If possible, it is advised to use nrow() and ncol().\nFull Code using DataFrames\rdf = DataFrame(rand(100000,5), :auto)\rnrow(df)\rncol(df)\rsize(df)\r@time for i in 1:10^6\rnrow(df)\rend\r@time for i in 1:10^6\rsize(df)[1]\rend Environment OS: Windows julia: v1.6.3 ","id":2307,"permalink":"https://freshrimpsushi.github.io/en/posts/2307/","tags":null,"title":"How to Check DataFrame Size in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let $V$ be a finite-dimensional $F$-vector space. Let $T : V \\to V$ be a linear transformation. For $\\lambda \\in F$, $$ Tx = \\lambda x $$ a non-zero vector $x \\in V$ satisfying this is called an eigenvector of $T$.\nThe scalar $\\lambda \\in F$ is called the eigenvalue corresponding to the eigenvector $x$.\nExplanation Although one might find the term eigenvector replaced by the terms characteristic vector or proper vector, and eigenvalue replaced by characteristic value or proper value, the author has not encountered these terms.\nEigenvalues and eigenvectors are related to the diagonalization of linear transformations.\nTheorem A linear transformation $T : V \\to V$ on a $n$-dimensional vector space $V$ is diagonalizable if and only if there exists an ordered basis of $V$ made up of eigenvectors of $T$, denoted as $\\beta$. That is to say, $T$ is diagonalizable if there exist $n$ linearly independent eigenvectors of $T$.\nMoreover, if $T$ is diagonalizable, and if $\\beta = \\left\\{ v_{1}, \\dots, v_{n} \\right\\}$ is an ordered basis of eigenvectors of $T$, and if $D = \\begin{bmatrix} T \\end{bmatrix}_{\\beta}$, then $D$ is a diagonal matrix and $D_{jj}$ corresponds to the eigenvalue of $v_{j}$.\nSee Also Eigenvalue and Eigenvector of a matrix Stephen H. Friedberg, Linear Algebra (4th Edition, 2002), p245~264\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3337,"permalink":"https://freshrimpsushi.github.io/en/posts/3337/","tags":null,"title":"Eigenvalues and Eigenvectors of Finite-Dimensional Linear Transformations"},{"categories":"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù","contents":"Definition 1 Given an index set $I \\ne \\emptyset$, let\u0026rsquo;s refer to the set $A := \\left\\{ a_{i} : i \\in I \\right\\}$ as the alphabet, and its elements $a_{i} \\in A$ as letters. For an integer $n \\in \\mathbb{Z}$, expressions like $a_{i}^{n}$ are referred to as syllables. A finite juxtaposition of these, $w$, is called a word. A syllable $a_{i}^{n} a_{i}^{m}$ can be represented as $a_{i}^{n+m}$, this is called elementary contraction. A word that can no longer undergo elementary contraction is called a reduced word, especially $1 := a_{i}^{0}$ is called empty word. Let\u0026rsquo;s denote by $F [A]$, the set of all reduced words that can be formed with letters from the alphabet $A$. Define a binary operation $\\cdot : F[A]^{2} \\to F[A]$ on two words $w_{1} , w_{2} \\in F[A]$ such that $w_{1} \\cdot w_{2}$ appears in reduced form. The group $\\left( F[A], \\cdot \\right)$ is called the Free Group Generated by $A$. If $G$ is a group with elements of set $A := \\left\\{ a_{i} : i \\in I \\right\\}$ as generators, and there exists an isomorphism $\\phi : G \\to F [A]$ with $\\phi \\left( a_{i} \\right) = a_{i}$, then we say that $G$ is Free on $A$, and call $a_{i}$ the free generators of $G$. A group that is free on a set $A \\ne \\emptyset$ is defined as a Free Group, and the cardinality $|A|$ of set $A$ is called the rank of the free group. Explanation Despite the lengthy definitions, everything becomes straightforward with examples. Don\u0026rsquo;t be alarmed by terms like \u0026lsquo;alphabet\u0026rsquo; or \u0026lsquo;word\u0026rsquo;. The term algebra itself refers to the study of substituting numbers with letters. Considering this, the approach of applying operations to sets might have seemed too abstract at first. In fact, after defining free groups, the terms mentioned in definition 4 are hardly used. Let\u0026rsquo;s comfortably look at some examples.\nAlphabet and Letters $$ A = \\left\\{ a, b \\right\\} $$\nConsidering the above alphabet, there are only two letters, $a$ and $b$.\nSyllables and Words For the alphabet $A$, $$ a^{2} , b^{3}, b^{-1} $$ are all syllables. They are mentioned in the sense of being listed finitely and with duplication allowed, hence the term juxtaposition is used, and by definition, they are simply called words. $$ a^{2} b \\\\ bbab \\\\ b^{-2} a a a^{-2} b a^{-24} $$\nReduced Words and Empty Word As an example, let\u0026rsquo;s examine the process by which the last word $b^{-2} a a a^{-2} b a^{-24}$ is reduced. $$ \\begin{align*} \u0026amp; b^{-2} a a a^{-2} b a^{-24} \\\\ =\u0026amp; b^{-2} a^{2} a^{-2} b a^{-24} \\\\ =\u0026amp; b^{-2} a^{0} b a^{-24} \\\\ =\u0026amp; b^{-2} 1 b a^{-24} \\\\ =\u0026amp; b^{-2} b a^{-24} \\\\ =\u0026amp; b^{-1} a^{-24} \\end{align*} $$ Here, $a^{0} = 1$ functions much like an identity element, and indeed, it\u0026rsquo;s called the Empty Word. After becoming a group, we don\u0026rsquo;t necessarily have to write $1$ in the alphabet.\nFree Group Generated by $A$ From the buildup so far, $\\left( F[A], \\cdot \\right)$ naturally becomes a group. The identity element is the empty word $1$, and for every word $w$, there exists an inverse $w^{-1}$ that satisfies the following. $$ w \\cdot w^{-1} = w^{-1}\\cdot w = 1 $$ Originally, $F[A]$ is a group because specific identity and inverses are given. Thus, a free group is essentially \u0026lsquo;a group made to inevitably be a group\u0026rsquo;.\nGroups Free on $A$ $$ F[A] = \\left\\{ \\cdots , a^{-2} b^{-1} , a^{-1} b^{-1}, a^{-1}, b^{-1} , 1 , a , b , ab , a b a \\cdots \\right\\} $$ Listing the elements of $F[A]$ as shown above. Although the definitions so far are intuitive and easy to understand, our interest actually lies in the general case of $G$. For instance, considering the group of integers $\\left( \\mathbb{Z} , + \\right)$, since it\u0026rsquo;s a cyclic group with elements of $\\left\\{ 1 \\right\\}$ as generators and isomorphic to $F \\left[ \\left\\{ a \\right\\} \\right]$, it can be said to be free on $\\left\\{ a \\right\\}$.\nFree Groups and Rank From the examples so far, $\\mathbb{Z}$ is free on a singleton set $\\left\\{ a \\right\\}$ thus has a rank of $1$, and the free group generated by $A = \\left\\{ a,b \\right\\}$ is of rank $2$.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p341~342.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2306,"permalink":"https://freshrimpsushi.github.io/en/posts/2306/","tags":null,"title":"Free Groups in Abstract Algebra"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Named tuples can be used. The way to create a named tuple is by attaching a semicolon ; right after the left parenthesis. For example, if you say DataFrame(; x, y), a DataFrame is created with column names :x and :y, and the contents are x and y respectively.\nCode julia\u0026gt; MyCol7 = rand(5); B = 1:5;\rjulia\u0026gt; DataFrame(; MyCol7, B)\r5√ó2 DataFrame\rRow ‚îÇ MyCol7 B ‚îÇ Float64 Int64\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 0.911763 1\r2 ‚îÇ 0.93374 2\r3 ‚îÇ 0.116779 3\r4 ‚îÇ 0.467364 4\r5 ‚îÇ 0.473437 5 Environment OS: Windows julia: v1.6.3 ","id":2305,"permalink":"https://freshrimpsushi.github.io/en/posts/2305/","tags":null,"title":"How to Create a DataFrame with Variable Names as Column Names in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Named tuples are tuples that, unlike regular tuples, can be used like dictionaries or structures. They have an array of symbols as keys and allow access to values via those keys, all the while retaining their tuple-like usage.\nCode x = rand(Bool, 5); y = rand(Bool, 5);\rz = (; x, y)\rtypeof(z)\rz.x Let\u0026rsquo;s run the above code to see how named tuples are used.\njulia\u0026gt; z = (; x, y)\r(x = Bool[0, 0, 1, 1, 0], y = Bool[1, 1, 0, 0, 0])\rjulia\u0026gt; typeof(z)\rNamedTuple{(:x, :y), Tuple{Vector{Bool}, Vector{Bool}}} A simple way to create a named tuple is to just make a tuple and put a semicolon ; right after the opening parenthesis. For instance, (; x) is equivalent to (; x=x).\njulia\u0026gt; z.x\r5-element Vector{Bool}:\r0\r0\r1\r1\r0\rjulia\u0026gt; z[2]\r5-element Vector{Bool}:\r1\r1\r0\r0\r0 Named tuples can be accessed by the name of their symbols, as well as by their index.\nEnvironment OS: Windows julia: v1.6.3 ","id":2303,"permalink":"https://freshrimpsushi.github.io/en/posts/2303/","tags":null,"title":"Julia's Named Tuples"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition A vector space is a module that is a field for a given ring $R = F$.\n","id":2300,"permalink":"https://freshrimpsushi.github.io/en/posts/2300/","tags":null,"title":"F-Vector Spaces in Abstract Algebra"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definitions 1 An Abelian group $(G,+)$ with the identity element for multiplication $1 \\ne 0$, and a ring $(R,+,\\cdot)$ satisfy the following three conditions for the binary operation $$ \\mu : R \\times G \\to G $$, then $\\left( G, +, R, \\cdot ; \\mu \\right)$ is called an $R$-module:\n(M1) Bi-additivity: For $\\forall \\alpha, \\beta \\in R$ and $\\forall x,y \\in G$, $$ \\begin{align*} \\mu \\left( \\alpha + \\beta , x \\right) =\u0026amp; \\mu \\left( \\alpha , x \\right) + \\mu \\left( \\beta , x \\right) \\\\ \\mu \\left( \\alpha , x + y \\right) =\u0026amp; \\mu \\left( \\alpha , x \\right) + \\mu \\left( \\alpha , y \\right) \\end{align*} $$ (M2): For $\\forall \\alpha, \\beta \\in R$ and $\\forall x \\in G$, $$ \\mu \\left( \\alpha , \\mu \\left( \\beta , x \\right) \\right) = \\mu \\left( \\alpha \\beta , x \\right) $$ (M3): For $\\forall x \\in G$, $$ \\mu (1, x) = x $$ Here, $R$ is also referred to as the ground ring or base ring.\nExplanation Here, $\\mu$ is called the scalar multiplication, and the resulting element, the scalar product, is denoted as $\\mu (\\alpha, x) := \\alpha x$. According to this expression, the above three conditions can be represented as follows:\n(M1) Distributive law: $$ \\begin{align*} \\left( \\alpha + \\beta \\right) x =\u0026amp; \\alpha x + \\beta x \\\\ \\alpha \\left( x + y \\right) =\u0026amp; \\alpha x + \\alpha y \\end{align*} $$ (M2) Associative law: $$ \\alpha \\left( \\beta x \\right) = \\left( \\alpha \\beta \\right) x $$ (M3) Identity: $$ 1 x = x $$ These might feel familiar right from the term scalar multiplication, as they have been seen often in the definition of vector spaces in linear algebra. In this sense, an $R$-module is a generalization of the $F$-vector space.\nSee Also Vector space in linear algebra Vector space in abstract algebra The $F$-vector space discussed in the documents below is essentially no different from the above-mentioned vector spaces. However, the perspectives differ; the vector space in linear algebra is an abstraction of the intuitive Euclidean space, while the vector space in abstract algebra is truly regarded as \u0026lsquo;algebra\u0026rsquo;.\nConversely, the $R$-module generalizes the scalar field $F$ of the $F$-vector space into the scalar ring $R$, thus demonstrating its significance. From the perspective of group $G$, the addition of the ring $R$ and the new operation $\\mu$ could be deemed as forming an additive group.\nR-modules in abstract algebra $F$-Vector space in abstract algebra Sze-Tsen Hu. (1968). Introduction to Homological Algebra: p1.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2298,"permalink":"https://freshrimpsushi.github.io/en/posts/2298/","tags":null,"title":"Abstract Algebra in R-modules"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 Hypothesis Testing: $$ \\begin{align*} H_{0} :\u0026amp; \\theta \\in \\Theta_{0} \\\\ H_{1} :\u0026amp; \\theta \\in \\Theta_{0}^{c} \\end{align*} $$\nA power function $\\beta (\\theta)$ is said to be unbiased if it satisfies the following for all $\\theta_{0} \\in \\Theta_{0}$ and $\\theta_{1} \\in \\Theta_{0}^{c}$: $$ \\beta \\left( \\theta_{0} \\right) \\le \\beta \\left( \\theta_{1} \\right) $$ Let $\\mathcal{C}$ be a set comprising such hypothesis tests. A hypothesis test $A$ that has a power function $\\beta (\\theta)$, among the hypothesis tests in $\\mathcal{C}$, satisfies the following for all $\\theta \\in \\Theta_{0}^{c}$ and for any power function $\\beta ' (\\theta)$ of all hypothesis tests in $\\mathcal{C}$: $$ \\beta ' (\\theta) \\le \\beta (\\theta) $$ is called a (Uniformly) Most Powerful Test, UMP. Explanation Unbiased Power Function $$ \\beta (\\theta) := P_{\\theta} \\left( \\mathbf{X} \\in \\mathbb{R} \\right) $$ The power function varies depending on the probability $P$, precisely, the probability distribution of $X$ and the rejection region $R$; hence, it\u0026rsquo;s difficult to fully visualize the form of $\\beta$ based on the definition alone. Nonetheless, a sensibly good power function should ideally have higher detection power under the alternative hypothesis than under the null hypothesis. This property of maintaining higher detection power irrespective of how $\\theta_{0}$ and $\\theta_{1}$ are chosen is referred to as the unbiasedness of the power function. This concept of comparing power function values leads to the concept of the most powerful test discussed next.\nMost Powerful Test Most powerful\u0026hellip; Not something straight out of a thrilling boy‚Äôs comic, but literally the strongest hypothesis test.\nFrom the definition\u0026rsquo;s statement, for a test to be the most powerful means that for all $\\theta \\in \\Theta_{0}^{c}$ where the null hypothesis rightly should be rejected, no other power function $\\beta '$ can surpass the detection power of the most powerful test\u0026rsquo;s power function $\\beta$.\nCasella. (2001). Statistical Inference(2nd Edition): p387~388.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2293,"permalink":"https://freshrimpsushi.github.io/en/posts/2293/","tags":null,"title":"Power of a Nuisance Test and the Most Powerful Test"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition Let\u0026rsquo;s say $A$ is a matrix $m \\times n$.\n$$ A = \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\\\ \\end{bmatrix} $$\nConsider any vertical and horizontal lines that cut the matrix as follows.\n$$ A = \\left[ \\begin{array}{cc|ccc|c|} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \u0026amp; a_{14} \u0026amp; a_{15} \u0026amp; \\cdots \u0026amp; a_{1n-1} \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \u0026amp; a_{24} \u0026amp; a_{25} \u0026amp; \\cdots \u0026amp; a_{2n-1} \u0026amp; a_{2n} \\\\ \\hline a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \u0026amp; a_{34} \u0026amp; a_{35} \u0026amp; \\cdots \u0026amp; a_{3n-1} \u0026amp; a_{3n} \\\\ a_{41} \u0026amp; a_{42} \u0026amp; a_{43} \u0026amp; a_{44} \u0026amp; a_{45} \u0026amp; \\cdots \u0026amp; a_{4n-1} \u0026amp; a_{4n} \\\\ \\hline \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\\\ \\hline a_{m1} \u0026amp; a_{m2} \u0026amp; a_{m3} \u0026amp; a_{m4} \u0026amp; a_{m5} \u0026amp; \\cdots \u0026amp; a_{m-1n} \u0026amp; a_{mn} \\end{array} \\right] $$\nThe parts cut by each line are referred to as the blocks of $A$.\n$$ A_{11} = \\begin{bmatrix} a_{11} \u0026amp; a_{12} \\\\ a_{21} \u0026amp; a_{22} \\end{bmatrix},\\quad A_{12} = \\begin{bmatrix} a_{13} \u0026amp; a_{14} \u0026amp; a_{15}\\\\ a_{23} \u0026amp; a_{24} \u0026amp; a_{25} \\end{bmatrix},\\quad \\cdots,\\quad A_{kl} = \\begin{bmatrix} a_{m-1n} \u0026amp; a_{mn}\\end{bmatrix} $$\nA matrix $A$ represented as blocks like the following is called a block matrix.\n$$ A = \\begin{bmatrix} A_{11} \u0026amp; A_{12} \u0026amp; \\cdots \u0026amp; A_{1l} \\\\ A_{21} \u0026amp; A_{22} \u0026amp; \\cdots \u0026amp; A_{2l} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ A_{k1} \u0026amp; A_{k2} \u0026amp; \\cdots \u0026amp; A_{kl} \\\\ \\end{bmatrix} $$\nExplanation Handling matrices as block matrices simplifies matrix calculations. In fact, the calculation of block matrices can be done just like normal matrix calculations.\n$$ A = \\begin{bmatrix} A_{11} \u0026amp; A_{12} \\\\ A_{21} \u0026amp; A_{22} \\end{bmatrix}\\quad \\text{and} \\quad B = \\begin{bmatrix} B_{11} \u0026amp; B_{12} \\\\ B_{21} \u0026amp; B_{22} \\end{bmatrix} \\\\[1em] \\implies AB = \\begin{bmatrix} A_{11}B_{11} + A_{12}B_{21} \u0026amp; A_{11}B_{12} + A_{12}B_{22} \\\\ A_{21}B_{11} + A_{22}B_{21} \u0026amp; A_{21}B_{12} + A_{22}B_{22} \\end{bmatrix} $$\nTherefore, if the matrix is converted into a block matrix form including zero matrices or identity matrices, the matrix multiplication can be easily calculated.\n$$ A = \\begin{bmatrix} A_{11} \u0026amp; I \\\\ O \u0026amp; A_{22} \\end{bmatrix}\\quad \\text{and} \\quad B = \\begin{bmatrix} B_{11} \u0026amp; B_{12} \\\\ B_{21} \u0026amp; B_{22} \\end{bmatrix} \\\\[1em] \\implies AB = \\begin{bmatrix} A_{11}B_{11} + B_{21} \u0026amp; A_{11}B_{12} + B_{22} \\\\ A_{22}B_{21} \u0026amp; A_{22}B_{22} \\end{bmatrix} $$\nA matrix split into row vectors and column vectors is also a block matrix.\n$$ \\begin{align*} A =\u0026amp; \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{r}_{1} \\\\ \\mathbf{r}_{2} \\\\ \\vdots \\\\ \\mathbf{r}_{m} \\end{bmatrix} \\\\ =\u0026amp; \\begin{bmatrix} \\mathbf{c}_{1} \u0026amp; \\mathbf{c}_{2} \u0026amp; \\cdots \u0026amp; \\mathbf{c}_{n} \\end{bmatrix} \\end{align*} $$\nTherefore, $A \\mathbf{x}$ can be represented as follows.\n$$ \\begin{align*} A \\mathbf{x} \u0026amp;= \\begin{bmatrix} \\mathbf{c}_{1} \u0026amp; \\mathbf{c}_{2} \u0026amp; \\cdots \u0026amp; \\mathbf{c}_{n} \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix} \\\\ \u0026amp;= \\sum_{i}^{n} x_{i}\\mathbf{c}_{i} \\end{align*} $$\nFurthermore, let\u0026rsquo;s say $A$ is a matrix $m \\times p$ and $\\mathbf{a}_{i}$ is a row vector of $A$, and $B$ is a matrix $p \\times n$ and $\\mathbf{b}_{i}$ is a column vector of $B$. Then the multiplication of the two matrices is as follows.\n$$ AB = \\begin{bmatrix} \\mathbf{a}_{1} \\\\ \\mathbf{a}_{2} \\\\ \\vdots \\\\ \\mathbf{a}_{m} \\end{bmatrix} \\begin{bmatrix} \\mathbf{b}_{1} \u0026amp; \\mathbf{b}_{2} \u0026amp; \\cdots \u0026amp; \\mathbf{b}_{n} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{a}_{1} \\mathbf{b}_{1} \u0026amp; \\mathbf{a}_{1} \\mathbf{b}_{2} \u0026amp; \\cdots \u0026amp; \\mathbf{a}_{1} \\mathbf{b}_{n} \\\\ \\mathbf{a}_{2} \\mathbf{b}_{1} \u0026amp; \\mathbf{a}_{2} \\mathbf{b}_{2} \u0026amp; \\cdots \u0026amp; \\mathbf{a}_{2} \\mathbf{b}_{n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ \\mathbf{a}_{m} \\mathbf{b}_{1} \u0026amp; \\mathbf{a}_{m} \\mathbf{b}_{2} \u0026amp; \\cdots \u0026amp; \\mathbf{a}_{m} \\mathbf{b}_{n} \\\\ \\end{bmatrix} $$\nSummary Let\u0026rsquo;s say $A = \\begin{bmatrix} A_{1} \u0026amp; A_{2} \\\\ O \u0026amp; A_{3} \\end{bmatrix}$ is a block matrix. The following holds for its determinant.\n$$ \\det A = \\det A_{1} \\det A_{3} $$\nCorollary The determinant of the block matrix $A = \\begin{bmatrix} A_{1} \u0026amp; A_{2} \\\\ O \u0026amp; I \\end{bmatrix}$ is the same as $\\det A_{1}$. A matrix $A$ that can be expressed in the following form by taking permutations of rows and columns is called a reducible matrix, and its determinant $\\det A$ is either $\\det B \\det D$ or $-\\det B \\det D$. $$ \\widetilde{A} = \\begin{bmatrix} B \u0026amp; O \\\\ C \u0026amp; D \\end{bmatrix} $$ Proof The block matrix $A$ can be decomposed into the product of three block matrices as follows.\n$$ \\begin{align*} A \u0026amp;= \\begin{bmatrix} A_{1} \u0026amp; A_{2} \\\\ O \u0026amp; A_{3} \\end{bmatrix} \\\\ \u0026amp;= \\begin{bmatrix} IA_{1} + OO \u0026amp; IA_{2} + OI \\\\ OA_{1} + A_{3}O \u0026amp; OA_{2} + A_{3}I \\end{bmatrix} \\\\ \u0026amp;= \\begin{bmatrix} I \u0026amp; O \\\\ O \u0026amp; A_{3} \\end{bmatrix} \\begin{bmatrix} A_{1} \u0026amp; A_{2} \\\\ O \u0026amp; I \\end{bmatrix} \\\\ \u0026amp;= \\begin{bmatrix} I \u0026amp; O \\\\ O \u0026amp; A_{3} \\end{bmatrix} \\begin{bmatrix} IA_{1} + A_{2}O \u0026amp; IO + A_{2}I \\\\ OA_{1} + IO \u0026amp; OO + II \\end{bmatrix} \\\\ \u0026amp;= \\begin{bmatrix} I \u0026amp; O \\\\ O \u0026amp; A_{3} \\end{bmatrix} \\begin{bmatrix} I \u0026amp; A_{2} \\\\ O \u0026amp; I \\end{bmatrix} \\begin{bmatrix} A_{1} \u0026amp; O \\\\ O \u0026amp; I \\end{bmatrix} \\end{align*} $$\nSince the determinant of the product is the same as the product of determinants\n$$ \\begin{align*} \\det A \u0026amp;= \\det \\left( \\begin{bmatrix} I \u0026amp; O \\\\ O \u0026amp; A_{3} \\end{bmatrix} \\begin{bmatrix} I \u0026amp; A_{2} \\\\ O \u0026amp; I \\end{bmatrix} \\begin{bmatrix} A_{1} \u0026amp; O \\\\ O \u0026amp; I \\end{bmatrix} \\right) \\\\ \u0026amp;= \\det \\left( \\begin{bmatrix} I \u0026amp; O \\\\ O \u0026amp; A_{3} \\end{bmatrix} \\right) \\det \\left( \\begin{bmatrix} I \u0026amp; A_{2} \\\\ O \u0026amp; I \\end{bmatrix} \\right) \\det \\left( \\begin{bmatrix} A_{1} \u0026amp; O \\\\ O \u0026amp; I \\end{bmatrix} \\right) \\end{align*} $$\nConsidering the Laplace expansion of the determinant,\n$$ \\det \\left( \\begin{bmatrix} I \u0026amp; O \\\\ O \u0026amp; A_{3} \\end{bmatrix} \\right) = \\det A_{3},\\quad \\det \\left( \\begin{bmatrix} A_{1} \u0026amp; O \\\\ O \u0026amp; I \\end{bmatrix} \\right) = \\det A_{1}, $$\n$$ \\text{and} \\quad \\det \\left( \\begin{bmatrix} I \u0026amp; A_{2} \\\\ O \u0026amp; I \\end{bmatrix} \\right)=1 $$\nwe can see that\n$$ \\det A = \\det A_{1} \\det A_{3} $$\n‚ñ†\n","id":3323,"permalink":"https://freshrimpsushi.github.io/en/posts/3323/","tags":null,"title":"Block Matrices"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 Hypothesis Testing: $$ \\begin{align*} H_{0} :\u0026amp; \\theta \\in \\Theta_{0} \\\\ H_{1} :\u0026amp; \\theta \\in \\Theta_{0}^{c} \\end{align*} $$\nGiven the hypothesis testing above, let\u0026rsquo;s denote it as $\\alpha \\in [0,1]$.\nFor the parameter $\\theta$, the function $\\beta (\\theta) := P_{\\theta} \\left( \\mathbf{X} \\in \\mathbb{R} \\right)$ with the rejection region $R$ is called the Power Function. If $\\sup_{\\theta \\in \\Theta_{0}} \\beta (\\theta) = \\alpha$, then the given hypothesis test is called a Size $\\alpha$ hypothesis test. If $\\sup_{\\theta \\in \\Theta_{0}} \\beta (\\theta) \\le \\alpha$, then the given hypothesis test is called a Level $\\alpha$ hypothesis test. Explanation Power? In mathematics, power is usually discussed in terms of exponentiation pow or using the character ÂÜ™ to talk about power functions $f(x) = x^{-\\alpha}$. However, in the context of statistics, power simply refers to the strength of a Hypothesis Testing.\nThe Power of a Test? Since $\\beta$ is defined through the probability $P_{\\theta}$, its range is naturally a subset of $[0,1]$. A high value of $\\beta (\\theta)$ ‚Äì meaning high test power, or the strength of the test ‚Äì indicates the strength to reject the null hypothesis. One might wonder, isn\u0026rsquo;t rejecting the alternative hypothesis also a test? But notionally, when discussing any hypothesis test, it\u0026rsquo;s usually in reference to the null hypothesis, and since $R$ is the rejection region of the null, the focus should solely be on whether the null hypothesis is rejected or not.\nWe evaluate the goodness of a hypothesis test through the power function. If there is a better method of testing, we say it is More Powerful. This terminology suggests, unlike the general mathematical usage of \u0026ldquo;power\u0026rdquo;, that it indeed refers to \u0026ldquo;strength\u0026rdquo;. It\u0026rsquo;s a natural motivation in mathematical statistics to question whether a hypothesis test is reasonable or efficient.\nHowever, one should not blindly consider the power of a test as the sole measure of its quality. Consider a test $\\beta (\\theta) = 1 = 100 \\%$ that rejects the null hypothesis for any sample. While it may seem very powerful, its excessive strength fails to capture any Type I errors (rejecting a true null hypothesis).\nSize and Level The terms size and level are often used interchangeably, and their usage may vary. However, once defined as mentioned, it\u0026rsquo;s natural that the set of level $\\alpha$ tests includes the set of size $\\alpha$ tests. This distinction should be rigorously maintained in research topics that require careful consideration.\nWhat does $\\alpha$ mean? Whether it\u0026rsquo;s size or level, a high $\\alpha$ indicates the presence of parameters that have a high probability of rejecting the null hypothesis when it is true. A larger $\\alpha$ tends to reject the null hypothesis more liberally, and conversely, a smaller $\\alpha$ would result in a more conservative test. Such differences arise from the rejection region. Meanwhile, terms like Level and the discussions here naturally bring the concept of Significance Level to mind, but ultimately they are separate considerations and should not be forcibly linked. It‚Äôs better to understand them conceptually.\nExample: Normal Distribution $$ \\begin{align*} H_{0} :\u0026amp; \\theta \\le \\theta_{0} \\\\ H_{1} :\u0026amp; \\theta \u0026gt; \\theta_{0} \\end{align*} $$ Considering the hypothesis test for a random sample $X_{1} , \\cdots , X_{n}$ from a normal distribution $N \\left( \\theta , \\sigma^{2} \\right)$ with known variance, if the z-score is greater than a certain constant $c$, then the null hypothesis can be rejected. The power function $\\beta$ can be determined by converting the probability $P$ of having $\\displaystyle {{ \\bar{X} - \\theta_{0} } \\over { \\sigma / \\sqrt{n} }}$ into an expression in terms of $\\theta$. $$ \\begin{align*} \\beta \\left( \\theta \\right) =\u0026amp; P_{\\theta} \\left( {{ \\bar{X} - \\theta_{0} } \\over { \\sigma / \\sqrt{n} }} \u0026gt; c \\right) \\\\ =\u0026amp; P_{\\theta} \\left( {{ \\bar{X} - \\theta } \\over { \\sigma / \\sqrt{n} }} \u0026gt; c + {{ \\theta_{0} - \\theta } \\over { \\sigma / \\sqrt{n} }} \\right) \\\\ =\u0026amp; P_{\\theta} \\left( Z \u0026gt; c + {{ \\theta_{0} - \\theta } \\over { \\sigma / \\sqrt{n} }} \\right) \\end{align*} $$ Here, $\\displaystyle Z := {{ \\bar{X} - \\theta_{0} } \\over { \\sigma / \\sqrt{n} }}$ is a random variable that follows the standard normal distribution.\nCasella. (2001). Statistical Inference(2nd Edition): p383, 385.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2291,"permalink":"https://freshrimpsushi.github.io/en/posts/2291/","tags":null,"title":"Power Function of Hypothesis Testing"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Theorem1 Let $S$ be a finite subset of the finite-dimensional vector space $V$.\n(a) If $S$ generates $V$ but is not a basis of $V$, then elements of $S$ can be appropriately removed to reduce it to a basis of $V$.\n(b) If $S$ is linearly independent but not a basis of $V$, then elements can be suitably added to $S$ to extend it to a basis of $V$.\nCorollary Let $W \\le V$ be a subspace of the vector space $V$ of dimension $n$. Let $\\gamma = \\left\\{ \\mathbf{v}_{1}, \\dots, \\mathbf{v}_{k} \\right\\}$ be a basis of $W$. Then, suitable elements can be added to $\\gamma$ to extend it to a basis $\\beta = \\left\\{ \\mathbf{v}_{1}, \\dots, \\mathbf{v}_{k}, \\mathbf{v}_{k+1}, \\dots, \\mathbf{v}_{n} \\right\\}$ of $V$.\nProof (a) $\\span(S) = V$, but if $S$ is not a basis of $V$, it means that $S$ is linearly dependent. Therefore, some vector $\\mathbf{v}_{1}$ in $S$ can be expressed as a linear combination of the other vectors. By the addition/subtraction theorem, $S \\setminus \\left\\{ \\mathbf{v}_{1} \\right\\}$ also generates $V$. If $S \\setminus {\\mathbf{v}_{1}}$ is linearly independent, the proof is complete. If not linearly independent, the same logic can consider a generating set $S \\setminus \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2} \\right\\}$ for $V$. Repeating this process yields a set that is a basis of $V$ by removing suitable elements from $S$.\n(b) Assume $\\dim(V) = n$. If $S$ is linearly independent but not a basis of $V$, it means that $S$ does not generate $V$. Then, by the addition/subtraction theorem, adding some vector $\\mathbf{v}_{1} \\notin \\span(S)$ to $S$ produces $S \\cup \\left\\{ \\mathbf{v}_{1} \\right\\}$, which remains linearly independent. Repeating this process allows for adding suitable vectors to $S$ to obtain a linearly independent set with a number of elements equal to $n$. Since a set in a $n$-dimensional vector space that is linearly independent and consists of $n$ elements is a basis, the proof is complete.\n‚ñ†\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p251-254\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3321,"permalink":"https://freshrimpsushi.github.io/en/posts/3321/","tags":null,"title":"Expansion and Contraction of the Basis"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview When dealing with high-dimensional arrays in Julia and NumPy, PyTorch (hereinafter referred to collectively as Python for simplicity), it is important to pay attention to what each dimension signifies as they differ. This distinction arises because Julia\u0026rsquo;s arrays are column-major, whereas Python\u0026rsquo;s arrays are row-major. Note that Matlab, being column-major like Julia, does not have this discrepancy, so those familiar with Matlab need not be overly cautious, but those accustomed to Python should be careful not to make indexing errors.\nBe sure to distinguish between the dimensions of arrays and vectors as they are used interchangeably. Explanation 1-Dimensional Arrays In Julia, an array of size $n$ represents a $n$-dimensional column vector.\njulia\u0026gt; ones(3)\r3-element Vector{Float64}:\r1.0\r1.0\r1.0 In Python, an array of size $n$ represents a $n$-dimensional row vector.\n\u0026gt;\u0026gt;\u0026gt; import numpy as np\r\u0026gt;\u0026gt;\u0026gt; np.ones(3)\rarray([1., 1., 1.]) Although there is a difference between columns and rows, as it is a 1-dimensional array, there isn\u0026rsquo;t much to be cautious about in terms of indexing.\n2-Dimensional Arrays At first glance, up to 2 dimensions, they might not appear different. However, their significances are different thus requiring caution. In Julia, the dimensions of an array extend backwards. This means, for a $(m,n)$ array, there are $n$ 1-dimensional arrays (column vectors) of size $m$. Specifically, a $(3,2)$ array signifies having 2 3-dimensional column vectors.\njulia\u0026gt; ones(3,2)\r3√ó2 Matrix{Float64}:\r1.0 1.0\r1.0 1.0\r1.0 1.0 Additionally, as Julia is \u0026lsquo;column-major\u0026rsquo;, the index of elements increases from top to bottom first, and then left to right.\njulia\u0026gt; A = reshape(range(1,6), (3,2))\r3√ó2 reshape(::UnitRange{Int64}, 3, 2) with eltype Int64:\r1 4\r2 5\r3 6\rjulia\u0026gt; for i ‚àà 1:6\rprintln(A[i])\rend\r1\r2\r3\r4\r5\r6 On the other hand, new dimensions in Python arrays extend forwards. Meaning, for a $(m,n)$ array, there are $m$ 1-dimensional arrays (row vectors) of size $n$. The result below shows that the arrays are divided on a row basis.\n\u0026gt;\u0026gt;\u0026gt; np.ones([3,2])\rarray([[1., 1.],\r[1., 1.],\r[1., 1.]]) Therefore, at a glance, in both Julia and Python, a $(m,n)$ array is a $m \\times n$ matrix, but due to the differences between column-major and row-major, the order of indices change. The direction of indexing is up-down left-right in Julia, and left-right up-down in Python.\n# juliaÏóêÏÑú 2Ï∞®Ïõê Î∞∞Ïó¥Ïùò Ïù∏Îç±Ïã±ÏùÄ ÏúÑÏóêÏÑú ÏïÑÎûòÎ°ú, Í∑∏ Îã§Ïùå Ï¢åÏóêÏÑú Ïö∞Î°ú\rjulia\u0026gt; A = reshape(range(1,6), (3,2))\r3√ó2 reshape(::UnitRange{Int64}, 3, 2) with eltype Int64:\r1 4\r2 5\r3 6\r# pythonÏóêÏÑú 2Ï∞®Ïõê Î∞∞Ïó¥Ïùò Ïù∏Îç±Ïã±ÏùÄ Ï¢åÏóêÏÑú Ïö∞Î°ú, Í∑∏ Îã§Ïùå ÏúÑÏóêÏÑú ÏïÑÎûòÎ°ú \u0026gt;\u0026gt;\u0026gt; np.arange(6).reshape(3,2)\rarray([[0, 1],\r[2, 3],\r[4, 5]]) 3-Dimensional Arrays In Julia, new dimensions to the array are added backwards. Thus, a $(m,n,k)$ array consists of $k$ $(m,n)$ arrays.\njulia\u0026gt; ones(3,2,4)\r3√ó2√ó4 Array{Float64, 3}:\r[:, :, 1] =\r1.0 1.0\r1.0 1.0\r1.0 1.0\r[:, :, 2] =\r1.0 1.0\r1.0 1.0\r1.0 1.0\r[:, :, 3] =\r1.0 1.0\r1.0 1.0\r1.0 1.0\r[:, :, 4] =\r1.0 1.0\r1.0 1.0\r1.0 1.0 Conversely, in Python, a $(m,n,k)$ array consists of $m$ $(n,k)$ arrays.\n\u0026gt;\u0026gt;\u0026gt; np.ones([3,2,4])\rarray([[[1., 1., 1., 1.],\r[1., 1., 1., 1.]],\r[[1., 1., 1., 1.],\r[1., 1., 1., 1.]],\r[[1., 1., 1., 1.],\r[1., 1., 1., 1.]]]) In Machine Learning Considering image data, where $H=\\text{hieht}$ is height, $W=\\text{width}$ is width, $C=\\text{channel}$ is the number of channels, and $B=\\text{batch size}$ is batch size, in PyTorch, it is a $(B,C,H,W)$ array, and in Julia, it is a $(H,W,C,B)$ array.\nEnvironment OS: Windows11 Version: Julia 1.7.1, Python 3.9.2, numpy 1.19.5 ","id":3315,"permalink":"https://freshrimpsushi.github.io/en/posts/3315/","tags":null,"title":"Differences in Array Dimensions in Julia, Python (NumPy, PyTorch)"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition Let us assume there is a stochastic process $\\left\\{ X_{t} \\right\\}$ with a countable set as its state space.\nFor two points in time $t_{1} \u0026lt; t_{2}$, the transition probability $p_{ij} \\left( t_{1} , t_{2} \\right)$ is defined as follows: $$ p_{ij} \\left( t_{1} , t_{2} \\right) := P \\left( X_{t_{2}} = j \\mid X_{t_{1}} = i \\right) $$\nHere, the (current) state represented by $i$ is referred to as the source state, and the target state represented by $j$ is referred to as the target state. In particular, for a discrete stochastic process $\\left\\{ X_{t} \\right\\}_{t \\in \\mathbb{N}}$ where $t_{1} = n \\in \\mathbb{N}$ and $t_{2} = n + k \\in \\mathbb{N}$, the transition probability can be simply represented as: $$ \\begin{align*} p_{ij}^{(k)} :=\u0026amp; P \\left(n + k = j \\mid X_{n} = i \\right) \\\\ p_{ij} :=\u0026amp; p_{ij}^{(1)} \\end{align*} $$ If the transition probabilities do not depend on the time points but solely on the interval $\\Delta t = t_{2} - t_{1}$, in other words, if the following condition is satisfied, then it is called a stationary or homogeneous transition probability: $$ p_{ij} (\\Delta t) := \\left( X_{t_{2} - t_{1}} = j \\mid X_{0} = i \\right) $$ For stationary transition probabilities, the matrix function defined as $P(t)$ and $P^{(k)}$ is referred to as the transition probability matrix: $$ \\begin{align*} \\left( P(t) \\right)_{ij} :=\u0026amp; \\left( p_{ij} (t) \\right) \\\\ \\left( P^{(k)} \\right)_{ij} :=\u0026amp; \\left( p_{ij}^{(k)} \\right) \\end{align*} $$ Let the transition probability matrix $P(t)$ of a continuous stochastic process be a differentiable matrix function. The following matrix $$ Q := P\u0026rsquo; (0) $$\nis called the infinitesimal generator matrix, and its elements $\\left( Q \\right)_{ij}$ are called transition rates. See also Chapman-Kolmogorov equation ","id":2284,"permalink":"https://freshrimpsushi.github.io/en/posts/2284/","tags":null,"title":"Transition Probabilities of Stochastic Processes"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition A proposition about a parameter is called a Hypothesis. The problem of accepting hypothesis $H_{0}$ as true based on a given sample, or rejecting hypothesis $H_{0}$ and adopting hypothesis $H_{1}$ is called a Hypothesis Test. In hypothesis testing, the complementary hypotheses $H_{0}$, $H_{1}$ are called the Null Hypothesis and the Alternative Hypothesis, respectively. The subset $R \\subset \\Omega$ of the sample space $\\Omega$ that leads to the rejection of the null hypothesis $H_{0}$ is called the Rejection Region. Explanation Not only for students majoring in statistics, but one also encounters explanations about hypothesis testing even at an introductory level of statistics. Many may find it sufficient, but the definitions above talk about hypothesis testing in as mathematically rigorous, unambiguous, and exact a manner as possible.\nThe explanations below are written assuming the reader is somewhat familiar with the concept of hypothesis testing. Let\u0026rsquo;s grasp the concept mathematically.\nHypothesis According to the definition, a hypothesis is not just any \u0026lsquo;word\u0026rsquo; but a proposition. The mention that it is a proposition about a parameter is key. For instance, tests like \u0026rsquo;normality tests,\u0026rsquo; which appear to be about the distribution itself rather than parameters, are ultimately based on parameters upon closer inspection. For example, the Jarque-Bera test is a test of normality, which, in fact, conducts hypothesis testing through skewness and kurtosis.\nHypothesis Testing The word \u0026lsquo;adopting\u0026rsquo; is underlined, which is a word of caution. As you know, while almost all textbooks use both the expressions Reject and Accept, most professors caution against the use of the term \u0026lsquo;accept\u0026rsquo;. Accepting the alternative hypothesis means rather than truly accepting the alternative hypothesis as true, it\u0026rsquo;s more about rejecting the null hypothesis, and accepting the null hypothesis is not about actively \u0026lsquo;adopting\u0026rsquo; it but rather about not being able to reject it.\nWhen defining the null and alternative hypotheses, the term complementary is used, and this emphasizes that $H_{0}$ and $H_{1}$ are not necessarily logical negations of each other. In hypothesis testing, showing that the null hypothesis is not true doesn\u0026rsquo;t automatically mean that the alternative hypothesis is true. More pragmatically, an alternative hypothesis that cannot coexist with the null hypothesis is sufficient. For example, hypothesis testing like $$ H_{0} : \\theta = 0 \\\\ H_{1} : \\theta \u0026lt; 0 $$ is fine, but in cases like $$ H_{0} : \\theta \\in [-1,0] \\\\ H_{1} : \\theta \\in [0,+1] $$ where $\\theta = 0$, there\u0026rsquo;s a problem because both the null and alternative hypotheses could be true.\nRejection Region According to the definition, the rejection region is an event. If hypothesis testing is considered a single trial, then the probability of $H_{0}$ being rejected is the same as the probability of the rejection event occurring. If this probability is quite low, for example, lower than $\\alpha = 0.05$, yet it occurs, this is not an ordinary event but something noteworthy. In such storytelling, concepts like the significance level (p-value) come to mind naturally.\nSee Also A simple definition of hypothesis testing: Introduces definitions that are moderately easy to accept rather than being strictly rigid. How to determine null and alternative hypotheses: Explains any problems with those definitions. A rigorous definition of hypothesis testing: Introduces relatively strict mathematical statistical definitions of hypothesis testing. A simple definition of the rejection region ","id":2283,"permalink":"https://freshrimpsushi.github.io/en/posts/2283/","tags":null,"title":"Mathematical Statistical Hypothesis Testing Definition"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 Let\u0026rsquo;s denote $M$ as a Riemannian manifold, and $\\frak{X}(M)$ as the set of all vector fields on $M$.\n$$ \\frak{X}(M) = \\text{the set of all vector fileds of calss } C^{\\infty} \\text{ on } M $$\nThe curvature $R$ of $M$ is a function that maps $X, Y \\in \\frak{X}(M)$ to $R(X, Y) : \\frak{X}(M) \\to \\frak{X}(M)$. In this context, $R(X, Y)$ is given as follows.\n$$ \\begin{equation} R(X, Y) Z = \\nabla_{Y} \\nabla_{X} Z - \\nabla_{X} \\nabla_{Y} Z + \\nabla_{[X,Y]}Z, \\quad Z \\in \\frak{X}(M) \\end{equation} $$\nSuch $R$ is called the Riemannian curvature or Riemannian curvature tensor.\n$\\nabla$ is the Levi-Civita connection on $M$, $[ \\cdot, \\cdot]$ is the Lie bracket.\nExplanation In other words, $R$ maps two vector fields $X, Y$ to the function $R(X, Y)$, and then $R(X, Y)$ again maps vector field $Z$ as described by $(1)$. Therefore, it\u0026rsquo;s indeed appropriate to write it as follows.\n$$ R : \\frak{X}(M) \\times \\frak{X}(M) \\times \\frak{X}(M) \\to \\frak{X}(M) \\\\[1em] R(X,Y,Z) = \\nabla_{Y} \\nabla_{X} Z - \\nabla_{X} \\nabla_{Y} Z + \\nabla_{[X,Y]}Z, \\quad Z \\in \\frak{X}(M) $$\nHowever, as one can see from the value of $R(X,Y,Z)$, it neatly bundles into $Z$. Moreover, since $X, Y$ is used as the differentiating variable and $Z$ as the variable being differentiated, this notation conventionally distinguishes their roles as displayed in $R(X, Y) Z$.\nAlso, there is a difference in the sign conventions between textbooks for definition $(1)$, but essentially they are the same.\nRepeated Notation For the Riemann curvature tensor $R$, $R: \\frak{X}(M) \\times \\frak{X}(M) \\times \\frak{X}(M) \\times \\frak{X}(M) \\to \\mathcal{D}(M)$ is defined as follows.\n$$ R(X, Y, Z, W) := g(R(X, Y)Z, W) = \\left\\langle R(X, Y)Z, W \\right\\rangle $$\nThis is called the Riemann curvature tensor. The Riemann curvature tensor introduced in the definition is $R$, and this one is also $R$. The reason for this duplication is because they are essentially the same, with only a difference of multiplying a metric.\nCoordinate Representation Let\u0026rsquo;s denote the basis of $T_{p}M$ as $\\left\\{ X_{i} \\right\\}$. $R(X_{i},X_{j})X_{k}$ is notated as follows.\n$$ R(X_{i},X_{j})X_{k} = \\sum_{s}R_{ijk}^{s}X_{s} $$\n$R(X_{i}, X_{j}, X_{k}, X_{l})$ is notated as follows.\n$$ R_{ijkl} = R(X_{i}, X_{j}, X_{k}, X_{l}) = g\\left( R(X_{i}, X_{j})X_{k}, X_{l} \\right) = \\sum_{s}R_{ijk}^{s}g_{sl} $$\nExample: Euclidean Space Let\u0026rsquo;s denote as $M = \\mathbb{R}^{n}$. The Euclidean space is a flat space without curvature. Therefore, we expect to obtain $R(X,Y)Z = 0$. Conversely, if this result is not obtained, we can say that definition $(1)$ does not hold any meaningful value. Let $X, Z$ be set as follows.\n$$ X = (X^{1}, \\dots, X^{n}) = \\sum X^{i}\\dfrac{\\partial }{\\partial x_{i}} \\text{ and } Z = (Z^{1}, \\dots, Z^{n}) = \\sum Z^{k}\\dfrac{\\partial }{\\partial x_{k}} $$\n$\\nabla_{X}Z$ is as follows.\n$$ \\nabla_{X}Z = \\sum_{i,k} \\left( X^{i}\\dfrac{\\partial Z^{k}}{\\partial x_{i}} + \\sum_{j}X^{i}Z^{j}\\Gamma_{ij}^{k} \\right) \\dfrac{\\partial }{\\partial x_{k}} $$\nIn the case of Euclidean space, since $\\Gamma_{ij}^{k} = 0$, we obtain the following.\n$$ \\begin{align*} \\nabla_{X} Z \u0026amp;= \\sum_{i,k} X^{i} \\left( \\dfrac{\\partial Z^{k}}{\\partial x_{i}} \\right) \\dfrac{\\partial }{\\partial x_{k}} \\\\ \u0026amp;= \\sum_{k} \\left( \\sum_{i} X^{i} \\dfrac{\\partial Z^{k}}{\\partial x_{i}} \\right) \\dfrac{\\partial }{\\partial x_{k}} \\\\ \u0026amp;= \\sum_{k} X Z^{k} \\dfrac{\\partial }{\\partial x_{k}} \\\\ \u0026amp;= \\left( XZ^{1}, \\dots, XZ^{n} \\right) \\end{align*} $$\nSimilarly, we obtain the following.\n$$ \\nabla_{Y} \\nabla_{X} Z = \\left( YXZ^{1}, \\dots, YXZ^{n} \\right) $$\nTherefore,\n$$ \\begin{align*} R(X, Y) Z \u0026amp;= \\nabla_{Y} \\nabla_{X} Z - \\nabla_{X} \\nabla_{Y} Z + \\nabla_{[X,Y]}Z \\\\ \u0026amp;= \\left( YXZ^{1}, \\dots, YXZ^{n} \\right) - \\left( XYZ^{1}, \\dots, XYZ^{n} \\right) \\\\ \u0026amp;\\quad + \\left( (XY-YX)Z^{1}, \\dots, (XY-YX)Z^{n} \\right) \\\\ \u0026amp;= 0 \\end{align*} $$\n‚ñ†\nProperties (a) $R$ is bilinear. That is,\n$$ \\begin{align*} R(f X_{1} + gX_{2}, Y_{1}) \u0026amp;= fR(X_{1}, Y_{1}) + gR(X_{2}, Y_{1}) \\\\[1em] R(X_{1}, fY_{1} + gY_{2}) \u0026amp;= fR(X_{1}, Y_{1}) + gR(X_{1}, Y_{2}) \\end{align*} $$\nwhere $f, g \\in \\mathcal{D}(M)$, $\\quad X_{1}, X_{2}, Y_{1}, Y_{2} \\in \\frak{X}(M)$ are given.\n(b) For any $X, Y \\in \\frak{X}(M)$, $R(X, Y)$ is linear. That is,\n$$ \\begin{align*} R(X, Y) (Z + W) \u0026amp;= R(X, Y) Z + R(X, Y) W \\\\[1em] R(X, Y) fZ \u0026amp;= f R(X, Y) Z \\end{align*} $$\nwhere $f \\in \\mathcal{D}(M)$, $\\quad Z, W \\in \\frak{X}(M)$ are given.\nProof (b) The first property is trivial by the definition of connection. Thus, only the second line is proven.\n$$ R(X, Y) fZ = \\nabla_{Y} \\nabla_{X} fZ - \\nabla_{X} \\nabla_{Y} fZ + \\nabla_{[X,Y]}fZ $$\nFirstly, calculating the first term by the definition of the connection,\n$$ \\begin{align*} \\nabla_{Y} \\nabla_{X} (fZ) \u0026amp;= \\nabla_{Y}(f\\nabla_{X} Z + (Xf)Z) \\\\ \u0026amp;= \\nabla_{Y}(f\\nabla_{X}Z) + \\nabla_{Y}((Xf)Z) \\\\ \u0026amp;= f\\nabla_{Y}\\nabla_{X}Z + (Yf)\\nabla_{X}Z + (Xf)\\nabla_{Y}(Z) + (Y(Xf))Z \\end{align*} $$\nSimilarly calculating,\n$$ \\nabla_{X}\\nabla_{Y}(fZ) = f\\nabla_{X}\\nabla_{Y}Z + (Xf)\\nabla_{Y}Z + (Yf)\\nabla_{X}(Z) + (X(Yf))Z $$\nTherefore, we obtain the following.\n$$ \\begin{align*} \\nabla_{Y} \\nabla_{X} (fZ) - \\nabla_{X}\\nabla_{Y}(fZ) \u0026amp;= {\\color{blue}f\\nabla_{Y}\\nabla_{X}Z} + {\\color{red}\\cancel{\\color{black}(Yf)\\nabla_{X}Z}} + {\\color{green}\\cancel{\\color{black}(Xf)\\nabla_{Y}Z}} + YXfZ \\\\ \u0026amp;\\quad - \\left( {\\color{blue}f\\nabla_{X}\\nabla_{Y}Z} + {\\color{green}\\cancel{\\color{black}(Xf)\\nabla_{Y}Z}} + {\\color{red}\\cancel{\\color{black}(Yf)\\nabla_{X}Z}} + XYfZ \\right) \\\\ \u0026amp;= {\\color{blue}f(\\nabla_{Y}\\nabla_{X}Z - \\nabla_{X}\\nabla_{Y}Z)} + YXfZ - XYfZ \\\\ \u0026amp;= f(\\nabla_{Y}\\nabla_{X}Z - \\nabla_{X}\\nabla_{Y}Z) - ([X,Y]f)Z \\end{align*} $$\nAdditionally, since $\\nabla_{[X,Y]} fZ = f\\nabla_{[X,Y]}Z + ([X,Y]f)Z$, finally we calculate as follows.\n$$ \\begin{align*} R(X, Y) fZ \u0026amp;= \\nabla_{Y} \\nabla_{X} fZ - \\nabla_{X} \\nabla_{Y} fZ + \\nabla_{[X,Y]} fZ \\\\ \u0026amp;= f(\\nabla_{Y}\\nabla_{X}Z - \\nabla_{X}\\nabla_{Y}Z) - ([X,Y]f)Z + f\\nabla_{[X,Y]}Z + ([X,Y]f)Z \\\\ \u0026amp;= f(\\nabla_{Y}\\nabla_{X}Z - \\nabla_{X}\\nabla_{Y}Z) + f\\nabla_{[X,Y]}Z \\\\ \u0026amp;= f(\\nabla_{Y}\\nabla_{X}Z - \\nabla_{X}\\nabla_{Y}Z + \\nabla_{[X,Y]}Z) \\\\ \u0026amp;= fR(X, Y) Z \\end{align*} $$\n‚ñ†\nManfredo P. Do Carmo, Riemannian Geometry (Eng Edition, 1992), p89-90\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3314,"permalink":"https://freshrimpsushi.github.io/en/posts/3314/","tags":null,"title":"Differential Geometry of Curved Manifolds"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Overview The notation and numbering of references and formulas follow the conventions of the original paper. Physics-informed neural networks (referred to as PINN[pronounced \u0026lsquo;pin\u0026rsquo;]) are artificial neural networks designed to numerically solve differential equations, introduced in the 2018 Journal of Computational Physics paper Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. The authors of the paper are M. Raissi, P. Perdikaris, and G.E. Karniadakis from the departments of Applied Mathematics and Mechanical Engineering.\nThe physics information mentioned in this paper, although it may sound grandiose, simply refers to the given differential equations themselves. In other words, using the given differential equations when solving them with artificial neural networks is essentially the same as saying \u0026lsquo;using physics information\u0026rsquo; in this context. When reading machine learning papers, one should be cautious not to be swayed by such seemingly impressive terminology.\nThe reason PINN is receiving significant attention in the numerical solution of differential equations is likely due to the simplicity and ease of understanding of the idea behind the loss function, as well as its straightforward implementation. In fact, the paper introduces a very simple DNN as an example.\nCommonly, the model introduced in Section 3.1 is referred to as PINN.\n0. Abstract The authors describe PINN as \u0026lsquo;an artificial neural network trained to solve supervised learning problems while satisfying a given nonlinear partial differential equation\u0026rsquo;. The two main issues addressed in this paper are the \u0026lsquo;data-driven solution and data-driven discovery of partial differential equations\u0026rsquo;. To evaluate performance, problems in fluid mechanics, quantum mechanics, and diffusion equations were solved.\n1. Introduction Although recent advances in machine learning and data analysis have led to innovative results in scientific fields such as image recognition, cognitive science, and genomics, there is a challenge in complex physical, biological, and engineering systems to yield desired results with limited information (due to the high cost of data collection). In such a small data regime, the convergence of advanced technologies like DNNs, CNNs, and RNNs is not guaranteed.\nStudies on methods to learn physics information efficiently (i.e., solve differential equations with minimal data) were conducted in [4-6]. The extension to nonlinear problems was proposed in subsequent studies by Raissi, one of the authors of this paper, in [8,9].\n2. Problem setup The function represented by an artificial neural network is determined by its input values (coordinates $x, t$ of the solution $u$ in a partial differential equation) and parameters. Automatic differentiation is utilized to differentiate these two types of variables.\nSuch neural networks are constrained to respect any symmetries, invariances, or conservation principles originating from the physical laws that govern the observed data, as modeled by general time-dependent and nonlinear partial differential equations.\nThis sentence from the paper might seem complex, but simply put, it means that the proposed artificial neural network, PINN, must satisfy the given differential equations. This is because the condition of satisfying the differential equations is used as a loss function, as will be discussed later.\nThe aim of this paper is to present a new modeling and computational paradigm to advance deep learning in mathematical physics. To this end, as mentioned earlier, this paper mainly addresses two issues. One is the data-driven solution of partial differential equations, and the other is the data-driven discovery of partial differential equations. All the codes and datasets used can be found at https://github.com/maziarraissi/PINNs. In this paper, a simple MLP using hyperbolic tangent as the activation function is used without any regularization such as $L1$, $L2$, or dropout, as introduced in the regularization section. The structure of the neural network, optimizer, learning rate, etc., are specifically introduced in each example.\nThis paper deals with the general form of parameterized and nonlinear partial differential equations as follows:\n$$ \\begin{equation} u_{t} + \\mathcal{N}[u; \\lambda] = 0,\\quad x \\in \\Omega,\\quad t \\in [0,T] \\end{equation} $$\nHere, $u=u(t,x)$ is the hidden (i.e., not given or unknown) function, the solution of $(1)$ that we seek, and $\\mathcal{N}[\\cdot; \\lambda]$ is a nonlinear operator parameterized by $\\lambda$, with $\\Omega \\subset \\mathbb{R}^{D}$. Many problems in mathematical physics can be represented in this form. For instance, consider the one-dimensional viscous Burgers\u0026rsquo; equation:\n$$ u_{t} + uu_{x} = \\nu u_{xx} $$\nThis corresponds to the case in $(1)$ where $\\mathcal{N}[u; \\lambda] = \\lambda_{1} uu_{x} - \\lambda_{2}u_{xx}$ and $\\lambda = (\\lambda_{1}, \\lambda_{2})$. The two problems addressed for the given equation $(1)$ are as follows:\ndata-driven solution of PDEs: For a fixed $\\lambda$, what is the solution $u(t,x)$ of the system? data-driven discovery of PDEs: What are the parameters $\\lambda$ that best describe the observed data? 3. Data-driven solutions of partial differential equations Section 3 discusses the problem of finding data-driven solutions for partial differential equations of the following form:\n$$ \\begin{equation} u_{t} + \\mathcal{N}[u] = 0,\\quad x \\in \\Omega,\\quad t \\in [0,T] \\end{equation} $$\nThis corresponds to the situation in $(1)$ where the parameter $\\lambda$ is fixed. Section 3.1 and Section 3.2 will cover continuous time models and discrete time models respectively. The problem of finding the equations will be addressed in Section 4. The meaning of \u0026lsquo;data\u0026rsquo; mentioned here will be explained in detail below.\n3.1. Continuous time models Assuming $(t,x) \\in \\mathbb{R} \\times \\mathbb{R}$, then $u : \\mathbb{R}^{2} \\to \\mathbb{R}$. This will be approximated using an artificial neural network, employing a simple MLP implemented as follows. In Julia, it would be:\nusing Flux u = Chain( Dense(2, 10, relu), Dense(10, 10, relu), Dense(10, 1) ) In PyTorch, it would be:\nimport torch import torch.nn as nn import torch.nn.functional as F layers = [2, 10, 10, 1] class network(nn.Module): def __init__(self): super(network, self).__init__() layer_list = [nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)] self.linears = nn.ModuleList(layer_list) def forward(self, tx): u = tx for i in range(len(layers)-2): u = self.linears[i](u) u = F.relu(u) u = self.linears[-1](u) return u u = network() Now, $u$ represents the artificial neural network we\u0026rsquo;ve defined, with $2$ input nodes and $1$ output node. Let\u0026rsquo;s define the left-hand side of $(2)$ as a function $f = f(t,x; u)$ as follows:\n$$ \\begin{equation} f := u_{t} + \\mathcal{N}[u] \\end{equation} $$\nSince $u$ is an artificial neural network, $f$ also becomes a sort of artificial neural network with hidden layer parameters. The $f$ defined in this way is called a physics-informed neural network (PINN), which is, in essence, the given partial differential equation itself. The differentiation included in $f$ is implemented through automatic differentiation and shares the same parameters as $u$. If the artificial neural network $u$ accurately approximates the solution to $(2)$, the function values of $f$ should be zero everywhere. We can infer that we will train the artificial neural network in a direction where $ f \\to 0$.\nLet\u0026rsquo;s say $(t_{u}^{i}, x_{u}^{i})$ are points in the domain where the initial and boundary conditions are defined: $$ (t_{u}^{i}, x_{u}^{i}) \\in( \\Omega \\times \\left\\{ 0 \\right\\}) \\cup (\\partial \\Omega \\times [0, T]) $$ If $u_{\\ast}$ is the actual solution, having initial and boundary conditions means that the following values are given:\n$$ \\left\\{ t_{u}^{i}, x_{u}^{i}, u^{i} \\right\\}_{i=1}^{N_{u}},\\quad u^{i} = u_{\\ast} (t_{u}^{i}, x_{u}^{i}) $$\nTheoretically, we would have an infinite number of such values, but in numerical problems, we can only handle a finite number of points, so let\u0026rsquo;s say we have $N_{u}$ points. The artificial neural network $u$ should output $u^{i}$ when given $(t_{u}^{i}, x_{u}^{i})$ as input, making these pairs the inputs and corresponding labels:\n$$ \\text{input} = (t_{u}^{i}, x_{u}^{i}),\\qquad \\text{label} = u^{i} $$\nThis is precisely the \u0026lsquo;data\u0026rsquo; to be learned in PINN. We can now consider the following as the loss function:\n$$ MSE_{u} = \\dfrac{1}{N_{u}} \\sum\\limits_{i=1}^{N_{u}} \\left| u(t_{u}^{i},x_{u}^{i}) - u^{i} \\right|^{2} $$\nAdditionally, $f$ should satisfy $(2)$ at appropriate points (ideally at all points where the solution $u_{\\ast}$ is defined, but numerically we can only handle a finite number of points) $\\left\\{ t_{f}^{i}, x_{f}^{i} \\right\\}_{i=1}^{N_{f}}$. In the paper, these points are referred to as collocation points. We set the following as the loss function for the collocation points:\n$$ MSE_{f} = \\dfrac{1}{N_{f}}\\sum\\limits_{i=1}^{N_{f}} \\left| f(t_{f}^{i}, x_{f}^{i}) \\right|^{2} $$\nIn other words, $MSE_{f}$ getting closer to $0$ means satisfying the physical information (the partial differential equation). Therefore, the final loss function for training the artificial neural network $u$ is as follows:\n$$ MSE = MSE_{u} + MSE_{f} $$\nThe paper explains that using $MSE_{f}$ as a constraint for physical information, as done here, was first researched in [15, 16]. However, in the PINN paper, it was reviewed using modern computational tools and applied to more challenging dynamic systems.\nThe term physics-informed machine learning was first used in Wang\u0026rsquo;s study [17] on turbulence modeling. However, prior to PINN, studies simply employed machine learning algorithms like support vector machines, random forests, and FNNs. PINN is distinguished from these previous approaches by considering not only the derivatives with respect to the parameters commonly used in machine learning\nbut also the derivatives with respect to the coordinates $x, t$ of the solution. That is, if the solution approximated by an artificial neural network with parameter $w$ is denoted as $u(t,x; w)$, while previously proposed methods only utilized the partial derivatives $u_{w}$, PINN also uses $u_{t}$, $u_{x}$, etc., to find the solution. It explains that this approach allows for finding the solution well even with a small amount of data.\nDespite the fact that there is no theoretical guarantee that this procedure converges to a global minimum, our empirical evidence indicates that, if the given partial differential equation is well-posed and its solution is unique, our method is capable of achieving good prediction accuracy given a sufficiently expressive neural network architecture and a sufficient number of collocation points $N_{f}$.\nThe paper notes that although there is no theoretical guarantee for the convergence of the proposed method, empirical evidence suggests that if the given partial differential equation is well-posed and has a unique solution, and if there are a sufficient number of points, then high prediction accuracy can be achieved.\n3.1.1. Example (Schrodinger Equation) This example focuses on verifying the effectiveness of the proposed method for solutions with periodic boundary conditions and complex values. As an example, the Schrodinger Equation with the following initial and boundary conditions is considered:\n$$ \\begin{align*} ih_{t} + 0.5h_{xx} + \\left| h \\right|^{2}h \u0026amp;= 0,\\quad x\\in [-5, 5], t\\in[0, \\pi/2], \\\\ h(0,x) \u0026amp;= 2\\operatorname{sech} (x), \\\\ h(t,-5) \u0026amp;= h(t,5), \\\\ h_{x}(t,-5) \u0026amp;= h_{x}(t,5) \\end{align*} $$\nThe solution to the problem, $h_{\\ast}(t,x)$, is a function with complex-valued function outputs, namely $h_{\\ast} : [0, \\pi/2] \\times [-5, 5] \\to \\mathbb{C}$. However, instead of defining an artificial neural network that outputs complex numbers, we define it to output a 2-dimensional vector consisting of $u(t,x)$ representing the real part and $v(t,x)$ representing the imaginary part. In simple terms, it is defined as an MLP with 2 input nodes and 2 output nodes:\n$$ h(t,x) = \\begin{bmatrix} u(t,x) \\\\[0.5em] v(t,x) \\end{bmatrix} $$\nIn this problem, the PINN $f$ is defined as:\n$$ f := ih_{t} + 0.5h_{xx} + \\left| h \\right|^{2} h $$\nThe parameters of $h(t,x)$ and $f(t,x)$ are trained to minimize the loss for initial values $MSE_{0}$, the loss for boundary values $MSE_{b}$, and the loss for physical information $MSE_{f}$.\n$$ MSE = MSE_{0} + MSE_{b} + MSE_{f} $$\n$$ \\begin{align*} \\text{where } MSE_{0} \u0026amp;= \\dfrac{1}{N_{0}}\\sum_{i=1}^{N_{0}} \\left| h(0, x_{0}^{i}) - h_{0}^{i} \\right|^{2} \\qquad (h_{0}^{i} = 2\\operatorname{sech} (x_{0}^{i})) \\\\ MSE_{b} \u0026amp;= \\dfrac{1}{N_{b}}\\sum_{i=1}^{N_{b}} \\left( \\left| h(t_{b}^{i}, -5) - h(t_{b}^{i}, 5) \\right|^{2} + \\left| h_{x}(t_{b}^{i},-5) - h_{x}(t_{b}^{i},5) \\right|^{2} \\right) \\\\ MSE_{f} \u0026amp;= \\dfrac{1}{N_{f}} \\sum\\limits_{i=1}^{N_{f}} \\left| f(t_{f}^{i}, x_{f}^{i}) \\right|^{2} \\end{align*} $$\nBe aware that there is a typo in the formula for $MSE_{b}$ in the paper. Here, $\\left\\{ x_{0}^{i}, h_{0}^{i} \\right\\}_{i=1}^{N_{0}}$ are the initial value data, $\\left\\{ t_{b}^{i} \\right\\}_{i=1}^{N_{b}}$ are the collocation points at the boundary, and $\\left\\{ t_{f}^{i}, x_{f}^{i} \\right\\}_{i=1}^{N_{f}}$ are the collocation points for $f$.\nFor data generation, traditional spectral methods were used. The number of initial value data $N_{0} = 50$ and the number of boundary value data $N_{b} = 50$ were chosen randomly. Additionally, the number of collocation points for $f$ is $N_{f} = 20,000$. The artificial neural network was constructed by stacking\n5 linear layers each with 100 nodes, and hyperbolic tangent $\\tanh$ was used as the activation function between layers.\nFigure 1.\nIn Figure 1, the upper image shows the heatmap of the predicted solution $\\left| h(t, x) \\right|$. The lower images show how well the predicted solution matches the actual solution at times $t = 0.59, 0.79, 0.98$, respectively. The relative $L_{2}$-norm is $0.00197 = 1.97 \\cdot 10^{-3}$, which means the predicted solution differs by about $0.02\\%$ when compared to the accurate solution. Therefore, PINN can accurately capture the nonlinear behavior of the Schrodinger equation even with a small amount of initial data.\nThe continuous time model being discussed works well even with a few initial values but has a potential limitation in that a large number of collocation points $N_{f}$ are needed. This is not a significant issue when the spatial dimension is 2 or less, but in higher dimensions, the required number of collocation points can increase exponentially, which can be problematic. Therefore, in the next section, a more structured neural network that does not require many collocation points is presented, utilizing the classical Runge‚ÄìKutta time-stepping schemes.\n3.2. Discrete time models In Section 3.1, we approximated the solution over continuous time. In that case, the artificial neural network is trained simultaneously over the entire domain, providing an output for any arbitrary point $(x,t)$. In this section, unlike Section 3.1, we deal with discrete time. In other words, we will describe how to approximate the value at $t_{n+1}$ using an artificial neural network, given the value at $t_{n}$. Applying a $q$-stage Runge-Kutta method to $(2)$ yields the following: $$ u(t_{n+1}, x) = u(t_{n}, x) - \\Delta t \\sum_{j=1}^{q} b_{j}\\mathcal{N}\\left[ u(t_{n}+c_{j} \\Delta t, x) \\right] $$\nIf we denote $u^{n}(x) = u(t_{n}, x)$ and $u^{n+c_{j}} = u(t_{n} + c_{j}\\Delta t, x)$, then:\n$$ \\begin{equation} \\begin{aligned} u^{n+1} \u0026amp;= u^{n} - \\Delta t \\sum_{j=1}^{q} b_{j}\\mathcal{N}\\left[ u^{n+c_{j}}\\right] \\\\ \\text{where } u^{n+c_{j}} \u0026amp;= u^{n} - \\Delta t \\sum_{i=1}^{q} a_{j,i}\\mathcal{N}\\left[ u^{n+c_{i}}\\right] \\quad j=1,\\dots,q \\end{aligned}\\tag{7} \\end{equation} $$\nIn the $q+1$ equations above, let\u0026rsquo;s move all the $\\sum$ terms on the right-hand side to the left-hand side. Then, denote the left-hand side as $u_{i}^{n}$.\n$$ \\begin{equation} \\begin{aligned} u_{q+1}^{n} \u0026amp;:= u^{n+1} + \\Delta t \\sum_{j=1}^{q} b_{j}\\mathcal{N}\\left[ u^{n+c_{j}}\\right] = u^{n} \\\\ \\\\ u_{1}^{n} \u0026amp;:= u^{n+c_{1}} + \\Delta t \\sum_{i=1}^{q} a_{1,i}\\mathcal{N}\\left[ u^{n+c_{i}}\\right] = u^{n} \\\\ u_{2}^{n} \u0026amp;:= u^{n+c_{2}} + \\Delta t \\sum_{i=1}^{q} a_{2,i}\\mathcal{N}\\left[ u^{n+c_{i}}\\right] = u^{n} \\\\ \u0026amp;\\vdots \\\\ u_{q}^{n} \u0026amp;:= u^{n+c_{q}} + \\Delta t \\sum_{i=1}^{q} a_{q,i}\\mathcal{N}\\left[ u^{n+c_{i}}\\right] = u^{n} \\end{aligned}\\tag{9} \\end{equation} $$\nFrom this, we can see that all these values should be equal to $u^{n}$.\n$$ u^{n} = u_{1}^{n} = u_{2}^{n} = \\cdots = u_{q+1}^{n} \\tag{8} $$\nTherefore, the physics information mentioned in Section 3.2 refers to the given initial \u0026amp; boundary conditions and $(8)$. Now, to compute $u(t_{n+1}, x)$, we define two artificial neural networks. The artificial neural network used in Section 3.1 was $u$ which is expected to converge to the exact solution $u_{\\ast}$ and the differential equation $f$ that $u$ must satisfy, but here it\u0026rsquo;s slightly different. First, let\u0026rsquo;s define the artificial neural network $U$ as the following function:\n$$ U : \\mathbb{R} \\to \\mathbb{R}^{q+1} $$\nThat is, it\u0026rsquo;s a neural network with $1$ input node and $q+1$ output nodes. Let\u0026rsquo;s assume the output of this network is as follows:\n$$ U(x) = \\begin{bmatrix} u^{n+c_{1}}(x) \\\\[0.5em] u^{n+c_{2}}(x) \\\\ \\vdots \\\\[0.5em] u^{n+c_{q}}(x) \\\\[0.5em] u^{n+1}(x) \\end{bmatrix} \\tag{10} $$\nThis network corresponds to the neural_net defined within the PhysicsInformedNN class in the attached code.\nIn the learning process below, the last component of the output of $U$ is expected to converge to $u(t_{n+1}, x)$. The second neural network is defined using the output of $U$ and the definition in $(7)$ as follows.\n3.2.1. Example (Allen‚ÄìCahn equation) The example for the discrete time model deals with the Allen-Cahn equation, given the following initial condition and periodic boundary conditions:\n$$ \\begin{equation} \\begin{aligned} \u0026amp;u_{t} - 0.0001u_{xx} + 5 u^{3} - 5u = 0,\\qquad x\\in [-1, 1], t\\in[0, 1], \\\\ \u0026amp;u(0,x) = x^{2} \\cos (\\pi x), \\\\ \u0026amp;u(t,-1) = u(t,1), \\\\ \u0026amp;u_{x}(t,-1) = u_{x}(t,1) \\end{aligned}\\tag{12} \\end{equation} $$\nIn this example, the nonlinear operator included in $(9)$ is as follows:\n$$ \\mathcal{N}[u^{n+c_{j}}] = -0.0001u_{xx}^{n+c_{j}} + 5(u^{n+c_{j}})^{3} - 5u^{n+c_{j}} $$\nLet\u0026rsquo;s denote the value of $u$ at time step $t^{n}$ as $u^{n,i}$:\n$$ u^{n,i} = u^{n}(x^{n,i}) = u(t^{n}, x^{n,i}),\\qquad i=1,\\dots,N_{n} $$\nSince our problem is to compute $u^{n+1}$ given $u^{n}$, $\\left\\{ x^{n,i}, u^{n,i} \\right\\}_{i=1}^{N_{n}}$ is our given dataset. According to $(8)$, the following must hold for this dataset:\n$$ u^{n,i} = u_{1}^{n}(x^{n,i}) = \\cdots = u_{q+1}^{n}(x^{n,i}) $$\nSo, let\u0026rsquo;s set the following loss function, the sum of squared error (SSE), for this:\nIt\u0026rsquo;s unclear why $MSE$ is not used here, but $SSE$ is used for the discrete time model. The paper uses $MSE$ for continuous time models and $SSE$ for discrete time models, which suggests there might be a reason (even if experimental). $$ SSE_{n} = \\sum\\limits_{j=1}^{q+1} \\sum\\limits_{i=1}^{N_{n}} \\left| u_{j}^{n} (x^{n,i}) - u^{n,i} \\right|^{2} $$\nEach $u_{j}^{n}$ is computed according to $(9)$, with the calculations involving $u^{n+1}$ and $u^{n+c_{j}}$ being the output of the neural network $U$. This loss corresponds to net_U0 defined within the PhysicsInformedNN class in the attached code. Since the output of $U$ must satisfy the boundary conditions of $(12)$, we set the following loss function:\n$$ \\begin{align*} SSE_{b} \u0026amp;= \\sum\\limits_{i=1}^{q} \\left| u^{n+c_{i}}(-1) - u^{n+c_{i}}(1) \\right|^{2} + \\left| u^{n+1}(-1) - u^{n+1}(1) \\right|^{2} \\\\ \u0026amp;\\quad+ \\sum\\limits_{i=1}^{q} \\left| u_{x}^{n+c_{i}}(-1) - u_{x}^{n+c_{i}}(1) \\right|^{2} + \\left| u_{x}^{n+1}(-1) - u_{x}^{n+1}(1) \\right|^{2} \\\\ \\end{align*} $$\nThe final loss is the sum of these two:\n$$ SSE = SSE_{n} + SSE_{b} $$\nFigure 2.\nIn Fig. 2, the upper image shows the heatmap of the exact solution. The lower image shows the predicted values at $t=0.9$, given the $u$ at $t=0.1$. In the lower left image, the blue line represents the exact solution, and $\\color{red}\\mathsf{X\n}$ marks the points used as data. In the lower right image, the blue line is the exact solution, and the red line is the predicted solution.\nIn Implicit Runge-Kutta methods (IRK), solving simultaneous equations for all $j$ is required to compute $u^{n+c_{j}}$, meaning that the computational cost increases significantly as $q$ increases. However, the paper explains that the proposed method does not incur much additional cost even if $q$ increases. It also explains that while IRK may not be able to make accurate predictions with large time steps $\\Delta t$ when $q$ is small, PINN can still make accurate predictions even with large $\\Delta t$.\n4. Data-driven discovery of partial differential equations This chapter deals with the problem of finding the parameters $\\lambda$ of the partial differential equation $(1)$ when observational data is available. The details are explained below with examples.\n4.1. Continuous time models Let\u0026rsquo;s define $f$ as the left-hand side of $(1)$:\n$$ f = u_{t} + \\mathcal{N}[u; \\lambda] $$\nThe difference from $(3)$ in Section 3 is that $\\lambda$ is no longer a fixed constant but an unknown parameter that needs to be learned.\n4.1.1. Example (Navier‚ÄìStokes equation) Section 4.1.1 introduces an example related to real data of an incompressible fluid described by the Navier-Stokes equation. Consider the following 2-dimensional Navier-Stokes equation:\n$$ \\begin{equation} \\begin{aligned} u_{t} + \\lambda_{1}(uu_{x} + vu_{y}) \u0026amp;= -p_{x} + \\lambda_{2}(u_{xx} + u_{yy}) \\\\ v_{t} + \\lambda_{1}(uv_{x} + vv_{y}) \u0026amp;= -p_{y} + \\lambda_{2}(v_{xx} + v_{yy}) \\end{aligned} \\tag{15} \\end{equation} $$\nHere, $u(t,x,y)$ is the $x$ component of the fluid\u0026rsquo;s velocity vector, $v(t,x,y)$ is the $y$ component. And $p(t,x,y)$ is the pressure, $\\lambda = (\\lambda_{1}, \\lambda_{2})$ are unknown parameters. The solution to the Navier-Stokes equation satisfies the condition that the divergence is $0$, hence the following holds:\n$$ \\begin{equation} u_{x} + v_{y} = 0 \\tag{17} \\end{equation} $$\nLet\u0026rsquo;s assume some latent function $\\psi (t, x, y)$ such that:\n$$ u = \\psi_{y},\\quad v = -\\psi_{x} $$\nIn other words, the fluid\u0026rsquo;s velocity vector is set as $\\begin{bmatrix} \\psi_{y} \u0026amp; -\\psi_{x}\\end{bmatrix}$. This naturally satisfies $(17)$ since $u_{x} + v_{y} = \\psi_{yx} - \\psi_{xy} = 0$. Instead of obtaining $u$ and $v$ individually, we approximate $\\psi$ with an artificial neural network and derive $u, v$ as its partial derivatives. Let\u0026rsquo;s assume that the following measured information is available for the actual velocity vector field:\n$$ \\left\\{ t^{i}, x^{i}, y^{i}, u^{i}, v^{i} \\right\\}_{i=1}^{N} $$\nFrom this, we set the loss function as follows, remembering that $u = \\psi_{y}$ and $v = -\\psi_{x}$:\n$$ \\dfrac{1}{N} \\sum\\limits_{i=1}^{N} \\left( \\left| u(t^{i}, x^{i}, y^{i}) - u^{i} \\right|^{2} + \\left| v(t^{i}, x^{i}, y^{i}) - v^{i} \\right|^{2} \\right) $$\nAnd let\u0026rsquo;s rearrange the right-hand side of $(15)$ to the left-hand side and define them as $f$ and $g$, respectively.\n$$ \\begin{equation} \\begin{aligned} f \u0026amp;:= u_{t} + \\lambda_{1}(uu_{x} + vu_{y}) + p_{x} - \\lambda_{2}(u_{xx} + u_{yy}) \\\\ g \u0026amp;:= v_{t} + \\lambda_{1}(uv_{x} + vv_{y}) + p_{y} - \\lambda_{2}(v_{xx} + v_{yy}) \\end{aligned}\\tag{18} \\end{equation} $$\nThen the values of $f, g$ are expressed with $\\psi$ as follows. (Note that $p$ will also be approximated by a neural network)\n$$ \\begin{align*} f \u0026amp;= \\psi_{yt} + \\lambda_{1}(\\psi_{y} \\psi_{yx} - \\psi_{x}\\psi_{yy}) + p_{x} -\\lambda_{2}(\\psi_{yxx} + \\psi_{yyy}) \\\\ g \u0026amp;= -\\psi_{xt} + \\lambda_{1}(-\\psi_{y} \\psi_{xx} + \\psi_{x}\\psi_{xy}) + p_{y} + \\lambda_{2}(\\psi_{xxx} + \\psi_{xyy}) \\\\ \\end{align*} $$\nAdd the information that $f(t^{i}, x^{i}, y^{i}) = 0 = g(t^{i}, x^{i}, y^{i})$ to the loss function, and finally set it as follows:\n$$ \\begin{aligned} MSE \u0026amp;:= \\dfrac{1}{N} \\sum\\limits_{i=1}^{N} \\left( \\left| u(t^{i}, x^{i}, y^{i}) - u^{i} \\right|^{2} + \\left| v(t^{i}, x^{i}, y^{i}) - v^{i} \\right|^{2} \\right) \\\\ \u0026amp;\\qquad + \\dfrac{1}{N} \\sum\\limits_{i=1}^{N} \\left( \\left| f(t^{i}, x^{i}, y^{i}) \\right|^{2} + \\left| g(t^{i}, x^{i}, y^{i}) \\right|^{2} \\right) \\end{aligned} \\tag{19} $$\nNow let\u0026rsquo;s define an artificial neural network with $3$ input nodes and $2$ output nodes. Let\u0026rsquo;s assume its output to be $\\begin{bmatrix} \\psi (t, x, y) \u0026amp; p(t, x, y) \\end{bmatrix}$. Then, the above loss function can be computed.\nExperiments were conducted for cases with and without noise in the data, and in both cases, it was reported that $\\lambda_{1}, \\lambda_{2}$ could be predicted with high accuracy. It was also demonstrated that even if data for the pressure $p$ was not provided, the neural network could accurately approximate the parameters and $p$. The specific experimental settings, results, and how the reference solutions were obtained are detailed in the paper.\n5. Conclusions In this paper, we introduced the physics-informed neural network, a new structure of neural networks that is capable of encoding the physical laws satisfied by given data and can be described by partial differential equations. This result has revealed that deep learning can learn about physical models, which could be applied to various physical simulations.\nHowever, the authors note that the proposed method should not be considered as a replacement for traditional methods of solving partial differential equations, such as the finite element method or spectral methods. In fact, Runge-Kutta methods were utilized in conjunction with PINN in Section 3.2..\nThe authors also attempted to address questions about the hyperparameters required to implement PINN, such as how deep the neural network should be and how much data is needed. However, they observed that what is effective for one equation might not be effective for another.\n","id":3313,"permalink":"https://freshrimpsushi.github.io/en/posts/3313/","tags":null,"title":"Paper Review: Physics-Informed Neural Networks"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"English Translation Code println(ARGS[1] * \u0026#34; + \u0026#34; * ARGS[2] * \u0026#34; = \u0026#34; * string(parse(Float64, ARGS[1]) + parse(Float64, ARGS[2]))) Let\u0026rsquo;s say we have a file named example.jl that consists of a single line as shown above. In Julia, we can receive command line arguments as an array through ARGS, similar to how sys.argv works with command line arguments in Python. The code written is a program that takes two numbers and prints their sum. The execution result is as follows.\nEnvironment OS: Windows julia: v1.6.3 ","id":2280,"permalink":"https://freshrimpsushi.github.io/en/posts/2280/","tags":null,"title":"How to Insert Command Line Arguments in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"## Overview Symbolic operations in Julia can be used through the `SymEngine.jl`[^1] package. [^1]: https://symengine.org/SymEngine.jl/ ## Code ### Defining Symbols Symbols can be defined in the following way. julia\u0026gt; using SymEngine\njulia\u0026gt; x = symbols(:x) x\njulia\u0026gt; x, y = symbols(\u0026ldquo;x y\u0026rdquo;) (x, y)\njulia\u0026gt; @vars x, y (x, y)\njulia\u0026gt; x = symbols(:x) x\njulia\u0026gt; f = 2x + x^2 + cos(x) 2*x + x^2 + cos(x)\n### Vectors and Matrices julia\u0026gt; v = [symbols(\u0026ldquo;v_‚ñ∑eq1‚óÅi$j\u0026rdquo;) for i in 1:2, j in 1:3] 2√ó3 Matrix{Basic}: a_11 a_12 a_13 a_21 a_22 a_23\njulia\u0026gt; Av 2-element Vector{Basic}: v_1a_11 + v_2a_12 + v_3a_13 v_1a_21 + v_2a_22 + v_3*a_23\njulia\u0026gt; @vars a, b, c, d, x, y (a, b, c, d, x, y)\njulia\u0026gt; [a b; c d] * [a x; b y] 2√ó2 Matrix{Basic}: a^2 + b^2 ax + by ac + bd cx + dy\n### Differentiation Symbolic differentiation can also be used with the [`Calculus.jl`](../3135) package. julia\u0026gt; f = 2x + x^2 + cos(x) 2*x + x^2 + cos(x)\njulia\u0026gt; diff(f, x) 2 + 2*x - sin(x)\n## Environment - OS: Windows10 - Version: Julia v1.7.1, SymEngine v0.8.7 ","id":3311,"permalink":"https://freshrimpsushi.github.io/en/posts/3311/","tags":null,"title":"Methods for Symbolic Computation in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code In Julia, the run() function is used to execute a string wrapped in backticks `. This is similar to using the os.system() from the os module in Python.\njulia\u0026gt; txt = \u0026#34;helloworld\u0026#34; \u0026#34;helloworld\u0026#34; julia\u0026gt; typeof(`echo $txt`)\rCmd ÏúÑÏôÄ Í∞ôÏù¥ Î∞±Ìã±ÏúºÎ°ú Í∞êÏã∏ÏßÑ Î¨∏ÏûêÏó¥ÏùÄ CmdÎùºÎäî ÌÉÄÏûÖÏùÑ Í∞ÄÏßÄÍ≥†, run() Ìï®ÏàòÎ°úÏç® Ïã§ÌñâÌï† Ïàò ÏûàÎã§.\njulia\u0026gt; run(`cmd /C echo $txt`) helloworld Process(`cmd /C echo helloworld`, ProcessExited(0)) Limited to this example, on Windows, it becomes a bit complicated as you have to execute echo within cmd, but on Linux, you can simply use echo $txt. If you frequently use such commands on Windows, consider modifying the environment variables1.\nEnvironment OS: Windows julia: v1.6.3 https://docs.julialang.org/en/v1/manual/running-external-programs/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2278,"permalink":"https://freshrimpsushi.github.io/en/posts/2278/","tags":null,"title":"Executing External Programs in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code To convert a string str to a number of type type, use parse(type, str).\njulia\u0026gt; parse(Int, \u0026#34;21\u0026#34;)\r21\rjulia\u0026gt; parse(Float64, \u0026#34;3.14\u0026#34;)\r3.14 You might wonder why we can\u0026rsquo;t do something like Int64(\u0026quot;21\u0026quot;) as in Python\u0026hellip; That\u0026rsquo;s because changing \u0026lsquo;\u0026ldquo;21\u0026rdquo;\u0026rsquo; into 21 is not about changing types but interpreting the string \u0026quot;21\u0026quot; as a number, which justifies the use of parse1.\nEnvironment OS: Windows julia: v1.6.3 https://discourse.julialang.org/t/why-are-there-all-these-strange-stumbling-blocks-in-julia/92644/2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2276,"permalink":"https://freshrimpsushi.github.io/en/posts/2276/","tags":null,"title":"Converting String to Number in Julia"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 For a given matrix ‚ñ∑ eq01‚óÅ ‚ñ∑ eq02‚óÅ, if there exists a positive number ‚ñ∑ eq04‚óÅ that satisfies ‚ñ∑ eq03‚óÅ, then ‚ñ∑ eq02‚óÅ is referred to as nilpotent. In this case, ‚ñ∑ eq06‚óÅ is the zero matrix ‚ñ∑ eq01‚óÅ.\nExplanation Nil means \u0026lsquo;zero\u0026rsquo; or \u0026rsquo;none.\u0026rsquo; The meaning of potent is \u0026lsquo;powerful,\u0026rsquo; and it is the root of the word potential. Thus, the term nilpotent can be understood as \u0026lsquo;having the potential/possibility to become ‚ñ∑ eq08‚óÅ.\u0026rsquo; In mathematics, \u0026lsquo;power\u0026rsquo; signifies exponentiation, and \u0026lsquo;zero\u0026rsquo; refers to the number ‚ñ∑ eq08‚óÅ. Hence, the word nilpotent literally means \u0026rsquo;to become zero by exponentiation.\u0026rsquo;\nSummary [1]: Upper triangular matrices are nilpotent. (The converse is not true) [2]: For a square matrix ‚ñ∑ eq10‚óÅ, all of its eigenvalues being ‚ñ∑ eq08‚óÅ is equivalent to ‚ñ∑ eq02‚óÅ being a nilpotent matrix. Therefore, nilpotent matrices do not have an inverse matrix. [3]: The trace of a nilpotent matrix ‚ñ∑ eq02‚óÅ is ‚ñ∑ eq14‚óÅ. Proof [1] Shown by mathematical induction.\n[2] 2 $(\\implies)$\n$A$, being a square matrix, can be represented as $A = Q T Q^{\\ast}$ with some unitary matrix $Q$ and upper triangular matrix $T$. Since all eigenvalues of $A$ are ‚ñ∑ eq08‚óÅ, $T$ is an upper triangular matrix with all diagonal elements being $0$, and upper triangular matrices are nilpotent matrices, $T$ is a nilpotent matrix for some $k \\in \\mathbb{N}$ such that $T^{k} = O$. Therefore, at least for $k$, $A^{k} = Q T^{k} Q^{*} = O$, making $A$ a nilpotent matrix as well.\n$(\\impliedby)$\nLet\u0026rsquo;s say $A$ is a nilpotent matrix. $$ A^{k} = O $$ The determinant of a product equals the product of determinants, $$ (\\det(A))^{k} = \\det(A^{k}) = \\det(O) = 0 \\implies \\det(A) = 0 $$\n‚ñ†\n[3] Proof is omitted3.\nSee Also Nilpotent linear transformations Stephen H. Friedberg, Linear Algebra (4th Edition, 2002), p229\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://math.stackexchange.com/a/256012/459895\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://math.stackexchange.com/a/2078773/459895\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3307,"permalink":"https://freshrimpsushi.github.io/en/posts/3307/","tags":null,"title":"Power Matrix"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 A matrix $A = [a_{ij}]$ with all elements above the main diagonal being $0$ is called a lower triangular matrix.\n$$ A \\text{ is lower triangluar matrix if } a_{ij} = 0 \\text{ whenever } i \\lt j $$\nA matrix $A = [a_{ij}]$ with all elements below the main diagonal being $0$ is called an upper triangular matrix.\n$$ A \\text{ is upper triangluar matrix if } a_{ij} = 0 \\text{ whenever } i \\gt j $$\nEspecially, a triangular matrix with all main diagonal elements being $0$ is called a strictly (upper/lower) triangular matrix.\nDescription For example, let\u0026rsquo;s say $A$ is $4 \\times 5$. If $A$ is a lower triangular matrix, then\n$$ A= \\begin{bmatrix} a_{11} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ a_{21} \u0026amp; a_{22} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \u0026amp; 0 \u0026amp; 0 \\\\ a_{41} \u0026amp; a_{42} \u0026amp; a_{43} \u0026amp; a_{44} \u0026amp; 0 \\\\ \\end{bmatrix} $$\nIf it is an upper triangular matrix, then it is as follows.\n$$ A= \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \u0026amp; a_{14} \u0026amp; a_{15} \\\\ 0 \u0026amp; a_{22} \u0026amp; a_{23} \u0026amp; a_{24} \u0026amp; a_{25} \\\\ 0 \u0026amp; 0 \u0026amp; a_{33} \u0026amp; a_{34} \u0026amp; a_{35} \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; a_{44} \u0026amp; a_{44} \\\\ \\end{bmatrix} $$\nAccording to the definition, a diagonal matrix is both a lower triangular matrix and an upper triangular matrix.\nProperties The transpose of a lower triangular matrix is an upper triangular matrix, and the transpose of an upper triangular matrix is a lower triangular matrix.\nThe product of lower triangular matrices is a lower triangular matrix, and the product of upper triangular matrices is an upper triangular matrix.\nA necessary and sufficient condition for a triangular matrix to be invertible is that all main diagonal elements are not $0$.\nThe inverse of an invertible lower triangular matrix is a lower triangular matrix, and the inverse of an invertible upper triangular matrix is an upper triangular matrix.\nA strictly triangular square matrix is nilpotent. (The converse is not true)\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p21\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3305,"permalink":"https://freshrimpsushi.github.io/en/posts/3305/","tags":null,"title":"Triangular Matrix"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 Let us assume that parameter $\\theta$ is given. If an unbiased estimator $W^{\\ast}$ satisfies the following condition over all other unbiased estimators $W$, it is called the Best Unbiased Estimator or the Uniform Minimum Variance Unbiased Estimator (UMVUE). $$ \\text{Var}_{\\theta} W^{\\ast} \\le \\text{Var}_{\\theta} W \\qquad , \\forall \\theta $$\nExplanation UMVUE is sometimes simply referred to as MVUE, dropping the initial Uniform part. The term UMVUE might be too lengthy, and while the expression \u0026ldquo;Best\u0026rdquo; fits quite well, \u0026ldquo;Minimum Variance\u0026rdquo; is also very intuitive and since \u0026ldquo;Best\u0026rdquo; is not exactly an academic term, the phrase Best Unbiased Estimator is rarely used across both Korean and English.\nDifference from an Efficient Estimator At first glance, it may seem similar to an efficient estimator, but an efficient estimator lowers its variance exactly to the Cram√©r-Rao bound, making it an unbiased estimator that theoretically cannot be improved upon, while the Best Unbiased Estimator doesn\u0026rsquo;t have to reach this theoretical limit but merely needs to surpass all other unbiased estimators. Striving for the best does not guarantee efficiency, defined as $1$, and not minimizing the variance to its theoretical lower limit does not preclude being the Best Unbiased Estimator.\nBeing an efficient estimator makes it the Best Unbiased Estimator, but the converse does not hold.\nCasella. (2001). Statistical Inference(2nd Edition): p334.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2273,"permalink":"https://freshrimpsushi.github.io/en/posts/2273/","tags":null,"title":"Best Unbiased Estimator, Minimum Variance Unbiased Estimator UMVUE"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview 1 A Varargs Function, commonly mentioned in programming, is a function that can receive an unlimited number of arguments. In Julia, you can simply set a variable to accept variadic arguments by appending ... after it. Let\u0026rsquo;s understand this with an example code.\nAdditionally, this ... is called splat operator.2\nCode Isaac Newton famously discovered that adding the reciprocals of factorials simply converges to $e$ with the following theorem. $$ e = {{ 1 } \\over { 0! }} + {{ 1 } \\over { 1! }} + {{ 1 } \\over { 2! }} + \\cdots = \\sum_{k=0}^{\\infty} {{ 1 } \\over { k! }} $$ In this example, we will look at a sequence converging to Euler\u0026rsquo;s constant $e = 2.71828182 \\cdots$.\nfunction f(x...)\rzeta = 0\rfor x_ in x\rzeta += 1/prod(1:x_)\rend\rreturn zeta\rend As shown above, appending a dot after x to write x... automatically considers the given arguments as an array. The content of the function is as seen in the equation above, simply taking the reciprocal of factorials in order and adding them to return.\njulia\u0026gt; f(0)\r1.0\rjulia\u0026gt; f(0,1)\r2.0\rjulia\u0026gt; f(0,1,2)\r2.5\rjulia\u0026gt; f(0,1,2,3,4,5,6,7,8,9,10)\r2.7182818011463845 The execution result shows that as natural numbers are given longer, it gets closer to Euler\u0026rsquo;s constant. It\u0026rsquo;s noteworthy here that the variably entered arguments are automatically bundled into an array called x. For example, putting an array conceptually like the following could result in an error.\njulia\u0026gt; f(0:10)\rERROR: MethodError: no method matching (::Colon)(::Int64, ::UnitRange{Int64}) Environment OS: Windows julia: v1.6.3 https://docs.julialang.org/en/v1/manual/functions/#Varargs-Functions\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://docs.julialang.org/en/v1/base/base/#\u0026hellip;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2266,"permalink":"https://freshrimpsushi.github.io/en/posts/2266/","tags":null,"title":"How to Define Variadic Functions in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview To achieve this, use the eltype() function. It likely gets its name from element type.\nCode julia\u0026gt; set_primes = Set([2,3,5,7,11,13])\rSet{Int64} with 6 elements:\r5\r13\r7\r2\r11\r3\rjulia\u0026gt; arr_primes = Array([2,3,5,7,11,13])\r6-element Vector{Int64}:\r2\r3\r5\r7\r11\r13 Consider two types of containers that hold prime numbers up to $13$. Honestly, they contain the same data, but one is a set while the other is an array.\njulia\u0026gt; typeof(set_primes)\rSet{Int64}\rjulia\u0026gt; eltype(set_primes)\rInt64\rjulia\u0026gt; typeof(arr_primes)\rVector{Int64} (alias for Array{Int64, 1})\rjulia\u0026gt; eltype(arr_primes)\rInt64 Applying typeof() to these distinguishes whether one is a set or an array, whereas eltype() returns the type of elements inside the container, regardless of what the container itself is.\njulia\u0026gt; typeof(1:10)\rUnitRange{Int64}\rjulia\u0026gt; eltype(1:10)\rInt64\rjulia\u0026gt; typeof(1:2:10)\rStepRange{Int64, Int64}\rjulia\u0026gt; eltype(1:2:10)\rInt64 The difference between 1:10 and 1:2:10, as seen above, demonstrates how eltype() can be usefully applied in the world of Julia programming, which may seem excessively obsessed with types.\nEnvironment OS: Windows julia: v1.6.3 ","id":2264,"permalink":"https://freshrimpsushi.github.io/en/posts/2264/","tags":null,"title":"How to Check the Element Type Inside a Julia Container"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code You can use the default() function.\nusing Plots\rdefault(size = (400,400), color = :red)\rdefault(:size, (400,400))\rfor key in [:size, :color], value in [(400,400), :red]\rdefault(key, value)\rend There is a way to set it up like the ordinary plot() function, and there is a way to change them one by one by giving key and value. Usually, the former is more convenient, but in the case of very complicated settings, the latter method can also be used by utilizing loops.\nInitialization If you want to reset all default settings, you can use default().\nEnvironment OS: Windows julia: v1.6.3 ","id":2262,"permalink":"https://freshrimpsushi.github.io/en/posts/2262/","tags":null,"title":"How to Change the Basic Settings of a Julia Plot"},{"categories":"Í∏∞ÌïòÌïô","contents":"Theorem1 Let $(M,g)$ be a Riemannian manifold. Then, there uniquely exists an affine connection $\\nabla$ on $M$ satisfying the following:\n$\\nabla$ is symmetric. $\\nabla$ is compatible with $g$. Such $\\nabla$ specifically satisfies the following equation:\n$$ \\begin{align*} g(Z, \\nabla_{Y}X) =\u0026amp;\\ \\dfrac{1}{2}\\Big( X g(Y, Z) + Y g(Z, X) - Z g(X, Y) \\\\ \u0026amp;\\ - g([X, Z], Y) - g([Y, Z], X) - g([X, Y], Z) \\Big) \\tag{1} \\end{align*} $$\nDescription Such a connection $\\nabla$ is called the Levi-Civita (or Riemannian) connection.\nLet\u0026rsquo;s denote the basis of the tangent space as $\\left\\{ \\dfrac{\\partial }{\\partial x_{i}} \\right\\} \\overset{\\text{denote}}{=} \\left\\{ X_{i} \\right\\}$. By the definition of connection, $\\nabla_{X_{i}}X_{j}$ is also a vector field. Thus, it can be represented as a linear combination of $X_{k}$. By Einstein notation,\n$$ \\nabla_{X_{i}}X_{j} = \\sum_{k}\\Gamma_{ij}^{k}X_{k} = \\Gamma_{ij}^{k}X_{k} $$\nSince the vector field is determined by $X_{i}, X_{j}$, let\u0026rsquo;s denote the coefficients by $\\Gamma_{ij}^{k}$. These are called the coefficients of the connection $\\nabla$ or the Christoffel symbols of the connection. In differential geometry, the Christoffel symbols are defined as the coefficients of the second-order derivatives $\\mathbf{x}_{ij}$ of coordinate mappings $\\mathbf{x}$, and it can be shown that they are the same. By substituting $X_{i}, X_{j}, X_{k}$ into the left side of $(1)$,\n$$ \\begin{align*} g(\\nabla_{X_{j}}X_{i}, X_{k}) = g\\left( \\Gamma_{ji}^{l}X_{l}, X_{k} \\right) = \\Gamma_{ji}^{l}g_{lk} \\end{align*} $$\nCalculating the right side yields $[X_{i}, X_{j}] = 0$, hence,\n$$ \\begin{align*} \u0026amp; \\dfrac{1}{2}\\left( X_{i}g(X_{j}, X_{k}) + X_{j}g(X_{i}, X_{k}) - X_{k}g(X_{i}, X_{j}) \\right) \\\\ =\u0026amp; \\dfrac{1}{2}\\left( X_{i}g_{jk} + X_{j}g_{ik} - X_{k}g_{ij} \\right) \\\\ \\end{align*} $$\nTherefore,\n$$ \\begin{align*} \u0026amp;\u0026amp; \\Gamma_{ji}^{l}g_{lk} \u0026amp;= \\dfrac{1}{2}\\left( X_{i}g_{jk} + X_{j}g_{ik} - X_{k}g_{ij} \\right) \\\\ \\implies \u0026amp;\u0026amp; \\sum_{k}\\Gamma_{ji}^{l}g_{lk}g^{ks} \u0026amp;= \\sum_{k}\\dfrac{1}{2}g^{ks}\\left( X_{i}g_{jk} + X_{j}g_{ik} - X_{k}g_{ij} \\right) \\\\ \\implies \u0026amp;\u0026amp; \\Gamma_{ji}^{l}\\delta_{l}^{s} \u0026amp;= \\sum_{k}\\dfrac{1}{2}g^{ks}\\left( X_{i}g_{jk} + X_{j}g_{ik} - X_{k}g_{ij} \\right) \\\\ \\implies \u0026amp;\u0026amp; \\Gamma_{ji}^{s} \u0026amp;= \\sum_{k}\\dfrac{1}{2}g^{ks}\\left( X_{i}g_{jk} + X_{j}g_{ik} - X_{k}g_{ij} \\right) \\\\ \\end{align*} $$\nSummarizing, the following can be obtained:\n$$ \\Gamma_{ij}^{k} = \\dfrac{1}{2}g^{mk}\\left( \\dfrac{\\partial }{\\partial x_{i}}g_{jm} + \\dfrac{\\partial }{\\partial x_{j}}g_{im} - \\dfrac{\\partial }{\\partial x_{m}}g_{ij} \\right) $$\nThis is the same as the equation obtained for surfaces on $\\mathbb{R}^{3}$ in differential geometry. Particularly, in Euclidean space $\\mathbb{R}^{n}$, since the metric is constant as $g_{ij} = \\delta_{ij}$, it follows that $\\Gamma_{ij}^{k} = 0$.\nWhen initially defining affine connections, $\\nabla_{X}Y$ was not explicitly given and was defined only as an abstract concept satisfying certain properties. However, when the Riemannian metric $g$ is given to such a connection $\\nabla$, it is clear that $\\nabla_{X}Y$ is determined by the coefficients of the metric $g_{ij}$. If we denote this as $X = u^{i}X_{i}, Y= v^{j}X_{j}$, then\n$$ \\begin{align*} \\nabla_{X}Y = \\nabla_{u^{i}X_{i}}v^{j}X_{j} \u0026amp;= u^{i}X_{i}(v^{j})X_{j} + u^{i}v^{j}\\nabla_{X_{i}}X_{j} \\\\ \u0026amp;= u^{i}X_{i}(v^{j})X_{j} + u^{i}v^{j}\\Gamma_{ij}^{k}X_{k} \\\\ \u0026amp;= u^{i}X_{i}(v^{k})X_{k} + u^{i}v^{j}\\Gamma_{ij}^{k}X_{k} \\\\ \u0026amp;= \\left( u^{i}X_{i}(v^{k}) + u^{i}v^{j}\\Gamma_{ij}^{k}\\right)X_{k} \\\\ \u0026amp;= \\left( u^{i}X_{i}(v^{k}) + u^{i}v^{j}\\Gamma_{ij}^{k}\\right)X_{k} \\\\ \\end{align*} $$\nIf we denote this as $X = X^{i}\\dfrac{\\partial }{\\partial x_{i}}, Y = Y^{i}\\dfrac{\\partial }{\\partial x_{j}}$, then\n$$ \\begin{align*} \\nabla_{X}Y \u0026amp;= \\left( X^{i}\\dfrac{\\partial Y^{k}}{\\partial x_{i}} + X^{i}Y^{j}\\Gamma_{ij}^{k}\\right)\\dfrac{\\partial }{\\partial x_{k}} \\\\ \u0026amp;= \\sum_{i,k}\\left( X^{i}\\dfrac{\\partial Y^{k}}{\\partial x_{i}} + \\sum_{j}X^{i}Y^{j}\\Gamma_{ij}^{k}\\right)\\dfrac{\\partial }{\\partial x_{k}} \\end{align*} $$\nMoreover, the covariant derivative of the vector field $V = v^{j}X_{j}$ is as follows.\n$$ \\dfrac{DV}{dt} = \\sum_{k} \\left( \\dfrac{d v^{k}}{dt} + \\sum_{i,j} v^{j}\\frac{dc_{i}}{dt} \\Gamma_{ij}^{k} \\right) X_{k} $$\nProof Part 1. Uniqueness\nAssume that a connection $\\nabla$ satisfying the conditions of the theorem exists. Since $\\nabla$ is compatible, for vector fields $X,Y,Z \\in$ $\\mathfrak{X}(M)$, the following holds:\n$$ \\begin{align*} X g(Y, Z) =\u0026amp;\\ g(\\nabla_{X}Y, Z) + g(Y, \\nabla_{X}Z) \\\\ Y g(Z, X) =\u0026amp;\\ g(\\nabla_{Y}Z, X) + g(Z, \\nabla_{Y}X) \\\\ Z g(X, Y) =\u0026amp;\\ g(\\nabla_{Z}X, Y) + g(X, \\nabla_{Z}Y) \\\\ \\end{align*} $$\nBy adding the first equation and the second, and subtracting the third, as $\\nabla$ is symmetric, we obtain the following:\n$$ \\begin{align*} \u0026amp;\\ X g(Y, Z) + Y g(Z, X) - Z g(X, Y) \\\\ =\u0026amp;\\ g(\\nabla_{X}Y, Z) + {\\color{red}g(Y, \\nabla_{X}Z)} + {\\color{blue}g(\\nabla_{Y}Z, X)} + g(Z, \\nabla_{Y}X) - {\\color{red}g(\\nabla_{Z}X, Y)} - {\\color{blue}g(X, \\nabla_{Z}Y)} \\\\ =\u0026amp;\\ {\\color{red}g(\\nabla_{X}Z-\\nabla_{Z}X, Y)} + {\\color{blue}g(\\nabla_{Y}Z - \\nabla_{Z}Y, X)} + g(\\nabla_{X}Y, Z) + g(Z, \\nabla_{Y}X) \\\\ =\u0026amp;\\ g([X, Z], Y) - g([Y, Z], X) - g(\\nabla_{X}Y, Z) + g(Z, \\nabla_{Y}X) \\end{align*} $$\nArranging this with $0=g(\\nabla_{Y}X, Z)-g(\\nabla_{Y}X, Z)$ added yields:\n$$ X g(Y, Z) + Y g(Z, X) - Z g(X, Y) \\\\ = g([X, Z], Y) + g([Y, Z], X) + g([X, Y], Z) + 2g(Z, \\nabla_{Y}X) $$\nArranging the last term of the right side yields:\n$$ \\begin{align*} g(Z, \\nabla_{Y}X) =\u0026amp;\\ \\dfrac{1}{2}\\Big( X g(Y, Z) + Y g(Z, X) - Z g(X, Y) \\\\ \u0026amp;\\ - g([X, Z], Y) - g([Y, Z], X) - g([X, Y], Z) \\Big) \\tag{1} \\end{align*} $$\nNow, let\u0026rsquo;s assume that another connection $\\nabla^{\\prime}$ exists.\n$$ \\begin{align*} g(Z, \\nabla^{\\prime}_{Y}X) =\u0026amp;\\ \\dfrac{1}{2}\\Big( X g(Y, Z) + Y g(Z, X) - Z g(X, Y) \\\\ \u0026amp;\\ - g([X, Z], Y) - g([Y, Z], X) - g([X, Y], Z) \\Big) \\end{align*} $$\nSubtracting these two equations,\n$$ g(Z, \\nabla_{Y}X)-g(Z, \\nabla^{\\prime}_{Y}X) = g(Z, \\nabla_{Y}X - \\nabla^{\\prime}_{Y}X) = 0 $$\nAccording to the properties of inner product, for the above equation to hold for all $Z$, it must be $\\nabla_{Y}X - \\nabla^{\\prime}_{Y}X=0$. Therefore, such a connection $\\nabla$ is unique.\n$$ \\nabla_{Y}X = \\nabla^{\\prime}_{Y}X $$\nPart 2. Existence\nIf $\\nabla$ is defined as in $(1)$, it is well-defined and satisfies the conditions of the theorem well.\n‚ñ†\nManfredo P. Do Carmo, Riemannian Geometry (Eng Edition, 1992), p55-56\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3292,"permalink":"https://freshrimpsushi.github.io/en/posts/3292/","tags":null,"title":"Levi-Civita Connection, Riemannian Connection, Coefficients of Connection, Christoffel Symbols"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview When indexing, you can use the Not() function1. If you input the symbol of the column name as is, or an array of symbols, those columns are excluded from the indexing.\nCode using DataFrames\rWJSN = DataFrame(\rmember = [\u0026#34;Îã§ÏòÅ\u0026#34;,\u0026#34;Îã§Ïõê\u0026#34;,\u0026#34;Î£®Îã§\u0026#34;,\u0026#34;ÏÜåÏ†ï\u0026#34;,\u0026#34;ÏàòÎπà\u0026#34;,\u0026#34;Ïó∞Ï†ï\u0026#34;,\u0026#34;Ï£ºÏó∞\u0026#34;,\u0026#34;ÏßÄÏó∞\u0026#34;,\u0026#34;ÏßÑÏàô\u0026#34;,\u0026#34;ÌòÑÏ†ï\u0026#34;],\rbirth = [99,97,97,95,96,99,98,95,99,94],\rheight = [161,167,157,166,159,165,172,163,162,165],\runit = [\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;]\r) Let\u0026rsquo;s run the example code above and check the results.\njulia\u0026gt; WJSN\r10√ó4 DataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÌòÑÏ†ï 94 165 ÎçîÎ∏îÎûô\r2 ‚îÇ ÏÜåÏ†ï 95 166 ÎçîÎ∏îÎûô\r3 ‚îÇ ÏßÄÏó∞ 95 163 ÎçîÎ∏îÎûô\r4 ‚îÇ ÏàòÎπà 96 159 Ï™ºÍº¨ÎØ∏\r5 ‚îÇ Îã§Ïõê 97 167 Î©îÎ≥¥Ï¶à\r6 ‚îÇ Î£®Îã§ 97 157 Ï™ºÍº¨ÎØ∏\r7 ‚îÇ Ï£ºÏó∞ 98 172 ÎçîÎ∏îÎûô\r8 ‚îÇ Îã§ÏòÅ 99 161 Ï™ºÍº¨ÎØ∏\r9 ‚îÇ Ïó∞Ï†ï 99 165 Î©îÎ≥¥Ï¶à\r10 ‚îÇ ÏßÑÏàô 99 162 Ï™ºÍº¨ÎØ∏ The WJSN dataframe is as shown above.\njulia\u0026gt; WJSN[:,Not(:height)]\r10√ó3 DataFrame\rRow ‚îÇ member birth unit ‚îÇ String Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 Ï™ºÍº¨ÎØ∏\r2 ‚îÇ Îã§Ïõê 97 Î©îÎ≥¥Ï¶à\r3 ‚îÇ Î£®Îã§ 97 Ï™ºÍº¨ÎØ∏\r4 ‚îÇ ÏÜåÏ†ï 95 ÎçîÎ∏îÎûô\r5 ‚îÇ ÏàòÎπà 96 Ï™ºÍº¨ÎØ∏\r6 ‚îÇ Ïó∞Ï†ï 99 Î©îÎ≥¥Ï¶à\r7 ‚îÇ Ï£ºÏó∞ 98 ÎçîÎ∏îÎûô\r8 ‚îÇ ÏßÄÏó∞ 95 ÎçîÎ∏îÎûô\r9 ‚îÇ ÏßÑÏàô 99 Ï™ºÍº¨ÎØ∏\r10 ‚îÇ ÌòÑÏ†ï 94 ÎçîÎ∏îÎûô Only :height went in, so the :height column was removed.\njulia\u0026gt; WJSN[:,Not([:birth, :unit])]\r10√ó2 DataFrame\rRow ‚îÇ member height ‚îÇ String Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 161\r2 ‚îÇ Îã§Ïõê 167\r3 ‚îÇ Î£®Îã§ 157\r4 ‚îÇ ÏÜåÏ†ï 166\r5 ‚îÇ ÏàòÎπà 159\r6 ‚îÇ Ïó∞Ï†ï 165\r7 ‚îÇ Ï£ºÏó∞ 172\r8 ‚îÇ ÏßÄÏó∞ 163\r9 ‚îÇ ÏßÑÏàô 162\r10 ‚îÇ ÌòÑÏ†ï 165 The array of symbols [:birth, :unit] went in, so the :birth and :unit columns were removed.\nEnvironment OS: Windows julia: v1.6.3 https://dataframes.juliadata.org/stable/man/working_with_dataframes/#Taking-a-Subset\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2260,"permalink":"https://freshrimpsushi.github.io/en/posts/2260/","tags":null,"title":"How to Remove Specific Rows from a DataFrame in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview To draw vertical and horizontal lines, use the vline!() and hline!() functions respectively.\nCode @time using Plots\rplot(rand(100))\rhline!([0.5], linewidth = 2)\rvline!([25, 75], linewidth = 2)\rpng(\u0026#34;result\u0026#34;) The positions where lines are drawn should be passed as an array. If the array contains multiple elements, multiple lines will be drawn at once.\nEnvironment OS: Windows julia: v1.6.3 ","id":2258,"permalink":"https://freshrimpsushi.github.io/en/posts/2258/","tags":null,"title":"How to Insert Vertical and Horizontal Lines in Figures in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview RecipesBase.jl is a package that allows users to create their own styles for new plots, similar to how ggplot works in the R programming language, with its own unique syntax1 separate from the base Julia. Let\u0026rsquo;s learn through examples.\nCode using Plots\rusing DataFrames\rdf = DataFrame(x = 1:10, y = rand(10))\rplot(df)\r@userplot TimeEvolution\r@recipe function f(te::TimeEvolution)\rdf = te.args[1]\rlinealpha --\u0026gt; 0.5\rcolumn_names = names(df)\rfor (column_index, column_name) ‚àà enumerate(column_names)\r@series begin\rlabel --\u0026gt; column_name\rdf[:,column_index]\rend\rend\rend\rtimeevolution(df); png(\u0026#34;1\u0026#34;)\rtimeevolution(df, legend = :left); png(\u0026#34;2\u0026#34;) First, running the above code results in the following error:\njulia\u0026gt; df = DataFrame(x = 1:10, y = rand(10))\r10√ó2 DataFrame\rRow ‚îÇ x y\r‚îÇ Int64 Float64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 1 0.636532\r2 ‚îÇ 2 0.463764\r3 ‚îÇ 3 0.604559\r4 ‚îÇ 4 0.654089\r5 ‚îÇ 5 0.883409\r6 ‚îÇ 6 0.91667\r7 ‚îÇ 7 0.0609783\r8 ‚îÇ 8 0.602259\r9 ‚îÇ 9 0.460372\r10 ‚îÇ 10 0.479944\rjulia\u0026gt; plot(df)\rERROR: Cannot convert DataFrame to series data for plotting This is because plot() is not defined by default to draw pictures by taking a dataframe.\n@userplot and @recipe @userplot TimeEvolution\r@recipe function f(te::TimeEvolution)\r...\rend In the example, we will draw a line chart directly with the time series data.\n@userplot: Specifies the name of the function that will inherit the properties of the plot() function. Note that although case-sensitive here, the resulting function can only use lowercase. @recipe: Specifies the style of the plot explicitly. The name of the function that follows is usually conventionally f. f(te::TimeEvolution) df = te.args[1]\rlinealpha --\u0026gt; 0.5\rcolumn_names = names(df)\rfor (column_index, column_name) ‚àà enumerate(column_names)\r@series begin\rlabel --\u0026gt; column_name\rdf[:,column_index]\rend\rend Let\u0026rsquo;s understand the above code line by line.\ndf = te.args[1] It considers the first argument received as df. In this example, since it\u0026rsquo;s assumed that the argument provided is a dataframe, the abbreviation df is used. Keep in mind that f is not the function we will be using, and its argument te is also not directly utilized.\nlinealpha --\u0026gt; 0.5 The transparency of the lines to be drawn in this plot is set to 0.5. Note that this value is given with --\u0026gt;, not linealpha = 0.5, which is completely different from the common Julia syntax.\ncolumn_names = names(df)\rfor (column_index, column_name) ‚àà enumerate(column_names)\r...\rend Even if plot() direct maps a 2D array to a plot, the labels are automatically given as y1, y2, etc. To prevent this, labels will be given separately by fetching the column names of the dataframe as shown above. The enumerate() function is used to iterate through both the index and the column names simultaneously. For more details, see the explanation on enumerate().\n@series for ...\r@series begin\rlabel --\u0026gt; column_name\rdf[:,column_index]\rend\rend The @series macro specifies the data and its style that will be repeatedly drawn. The label of the column name is given with label --\u0026gt; column_name, and by writing df[:,column_index] in the last row, the data from that column name will be drawn. Note that the data to be drawn must be in the last row.\nResults As a result, we can now draw pictures in the style we specified with timeevolution() or timeevolution!().\ntimeevolution(df) It can be confirmed that even with a dataframe inserted, the picture is drawn successfully without error. The transparency of the line is 0.5, and the label is also exactly carried over from the column names in the dataframe.\ntimeevolution(df, legend = :left) We have arbitrarily adjusted the position of the legend. Despite no mention of legend when defining f, it can be confirmed to apply well. This is because timeevolution() inherits the rest of the elements of plot().\nEnvironment OS: Windows julia: v1.6.3 https://docs.juliahub.com/RecipesBase/8e2Mm/1.0.1/syntax/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2256,"permalink":"https://freshrimpsushi.github.io/en/posts/2256/","tags":null,"title":"How to Create Art Styles in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 For two vector spaces $V, W$, if there exists an invertible linear transformation $T : V \\to W$, then $V$ is said to be isomorphic to $W$, and is denoted as follows.\n$$ V \\cong W $$\nFurthermore, $T$ is called an isomorphism.\nExplanation By the equivalence condition of being invertible, saying $T$ is an isomorphism means that $T$ is a bijective function. Therefore, if there exists a bijective function $T : V \\to W$, then $V, W$ is isomorphic.\nThat $V, W$ is isomorphic means that there is virtually no difference between $V$ and $W$.\nTheorem Let $V, W$ be a finite-dimensional vector space. The necessary and sufficient condition for $V$ and $W$ to be isomorphic is that $\\dim (V) = \\dim (W)$ holds.\nCorollary Let $V$ be a vector space. The necessary and sufficient condition for $V$ to be isomorphic to $\\mathbb{R}^{n}$ is that $\\dim (V) = n$ holds.\nProof $(\\Longrightarrow)$\nAssume that $T : V \\to W$ is an isomorphism. Then, $T$ is invertible, and by the properties of invertible linear transformations,\n$$ \\dim (V) = \\dim (W) $$\n$(\\Longleftarrow)$\nAssuming $\\dim (V) = \\dim (W)$, let $\\beta = \\left\\{ \\mathbf{v}_{1}, \\dots, \\mathbf{v}_{n} \\right\\}, \\gamma = \\left\\{ \\mathbf{w}_{1}, \\dots, \\mathbf{w}_{n} \\right\\}$ be the basis for $V, W$, respectively. Then, the following linear transformation exists between finite-dimensional vector spaces.\n$$ T : V \\to W \\quad \\text{ by } \\quad T(\\mathbf{v}_{i}) = \\mathbf{w}_{i} $$\nMoreover, then $T(\\beta) = \\gamma$ is true, and since $T(\\beta)$ generates $R(T)$,\n$$ R(T) = \\span (T(\\beta)) = \\span (\\gamma) = W $$\nTherefore, $T$ is surjective. Then, since we assumed $\\dim (V) = \\dim (W)$, $T$ is also injective. Thus, there exists a bijective function $T : V \\to W$, and $V$ and $W$ are isomorphic.\n‚ñ†\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p102-103\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3287,"permalink":"https://freshrimpsushi.github.io/en/posts/3287/","tags":null,"title":"Homomorphism"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Using groupby() to divide by group and combine() for calculation is the way to go1.\ngroupby(df, :colname)\nReturns a GroupedDataFrame based on :colname. combine(gdf, :colname =\u0026gt; fun)\ngdf is a GroupedDataFrame divided by groups. :colname =\u0026gt; fun represents a pair of the symbol :colname, which is the name of the column containing the values to be calculated, and the calculation function fun. Code using DataFrames\rusing StatsBase\rWJSN = DataFrame(\rmember = [\u0026#34;Îã§ÏòÅ\u0026#34;,\u0026#34;Îã§Ïõê\u0026#34;,\u0026#34;Î£®Îã§\u0026#34;,\u0026#34;ÏÜåÏ†ï\u0026#34;,\u0026#34;ÏàòÎπà\u0026#34;,\u0026#34;Ïó∞Ï†ï\u0026#34;,\u0026#34;Ï£ºÏó∞\u0026#34;,\u0026#34;ÏßÄÏó∞\u0026#34;,\u0026#34;ÏßÑÏàô\u0026#34;,\u0026#34;ÌòÑÏ†ï\u0026#34;],\rbirth = [99,97,97,95,96,99,98,95,99,94],\rheight = [161,167,157,166,159,165,172,163,162,165],\runit = [\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;]\r)\rsort!(WJSN, :birth)\runique(WJSN, :unit)\runits = groupby(WJSN, :unit)\runits[1]\runits[2]\runits[3]\rcombine(units, :height =\u0026gt; mean) Let\u0026rsquo;s run the example code above and check the result.\njulia\u0026gt; WJSN\r10√ó4 DataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÌòÑÏ†ï 94 165 ÎçîÎ∏îÎûô\r2 ‚îÇ ÏÜåÏ†ï 95 166 ÎçîÎ∏îÎûô\r3 ‚îÇ ÏßÄÏó∞ 95 163 ÎçîÎ∏îÎûô\r4 ‚îÇ ÏàòÎπà 96 159 Ï™ºÍº¨ÎØ∏\r5 ‚îÇ Îã§Ïõê 97 167 Î©îÎ≥¥Ï¶à\r6 ‚îÇ Î£®Îã§ 97 157 Ï™ºÍº¨ÎØ∏\r7 ‚îÇ Ï£ºÏó∞ 98 172 ÎçîÎ∏îÎûô\r8 ‚îÇ Îã§ÏòÅ 99 161 Ï™ºÍº¨ÎØ∏\r9 ‚îÇ Ïó∞Ï†ï 99 165 Î©îÎ≥¥Ï¶à\r10 ‚îÇ ÏßÑÏàô 99 162 Ï™ºÍº¨ÎØ∏ The WJSN dataframe is as shown above.\nDividing by Group groupby() julia\u0026gt; units = groupby(WJSN, :unit)\rGroupedDataFrame with 3 groups based on key: unit\rFirst Group (4 rows): unit = \u0026#34;ÎçîÎ∏îÎûô\u0026#34;\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÌòÑÏ†ï 94 165 ÎçîÎ∏îÎûô\r2 ‚îÇ ÏÜåÏ†ï 95 166 ÎçîÎ∏îÎûô\r3 ‚îÇ ÏßÄÏó∞ 95 163 ÎçîÎ∏îÎûô\r4 ‚îÇ Ï£ºÏó∞ 98 172 ÎçîÎ∏îÎûô\r‚ãÆ\rLast Group (2 rows): unit = \u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§Ïõê 97 167 Î©îÎ≥¥Ï¶à\r2 ‚îÇ Ïó∞Ï†ï 99 165 Î©îÎ≥¥Ï¶à The dataframe was divided into three groups based on the :unit column.\njulia\u0026gt; units[1]\r4√ó4 SubDataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÌòÑÏ†ï 94 165 ÎçîÎ∏îÎûô\r2 ‚îÇ ÏÜåÏ†ï 95 166 ÎçîÎ∏îÎûô\r3 ‚îÇ ÏßÄÏó∞ 95 163 ÎçîÎ∏îÎûô\r4 ‚îÇ Ï£ºÏó∞ 98 172 ÎçîÎ∏îÎûô\rjulia\u0026gt; units[2]\r4√ó4 SubDataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÏàòÎπà 96 159 Ï™ºÍº¨ÎØ∏\r2 ‚îÇ Î£®Îã§ 97 157 Ï™ºÍº¨ÎØ∏\r3 ‚îÇ Îã§ÏòÅ 99 161 Ï™ºÍº¨ÎØ∏\r4 ‚îÇ ÏßÑÏàô 99 162 Ï™ºÍº¨ÎØ∏\rjulia\u0026gt; units[3]\r2√ó4 SubDataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§Ïõê 97 167 Î©îÎ≥¥Ï¶à\r2 ‚îÇ Ïó∞Ï†ï 99 165 Î©îÎ≥¥Ï¶à By indexing into the GroupedDataFrame like above, we can access the divided dataframes.\nCalculating by Group combine() julia\u0026gt; combine(units, :height =\u0026gt; mean)\r3√ó2 DataFrame\rRow ‚îÇ unit height_mean ‚îÇ String Float64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÎçîÎ∏îÎûô 166.5\r2 ‚îÇ Ï™ºÍº¨ÎØ∏ 159.75\r3 ‚îÇ Î©îÎ≥¥Ï¶à 166.0 The code above calculates the average mean of :height in the WJSN dataframe, which is grouped by :unit into the dataframe units. As mentioned in the overview, this StatBase.mean() is the function for calculating the average. Changing this to sum() calculates the sum, and to min() calculates the minimum value for each group. In this example, the average of :height by :unit was calculated, and the Ï™ºÍº¨ÎØ∏ group was found to have the lowest average at 159.75.\nhttps://stackoverflow.com/questions/64226866/groupby-with-sum-on-julia-dataframe\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2254,"permalink":"https://freshrimpsushi.github.io/en/posts/2254/","tags":null,"title":"Grouping and Calculating DataFrames in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let $V, W$ be a vector space, and $T : V \\to W$ be a linear transformation. If the linear transformation $U : W \\to V$ satisfies the following, then $U$ is called the inverse or inverse transformation of $T$.\n$$ TU = I_{W} \\quad \\text{and} \\quad UT = I_{V} $$\n$TU$ is the composition of $U$ and $T$, $I_{X} : X \\to X$ is the identity transformation. If $T$ has an inverse, $T$ is called an invertible transformation. If $T$ is invertible, the inverse $U$ is unique and denoted as $T^{-1} = U$.\nExplanation According to the definition, a transformation being invertible is equivalent to being a bijective function.\nProperties (a) $(TU)^{-1} = U^{-1}T^{-1}$\n(b) $(T^{-1})^{-1} = T$\n(c) If $T : V \\to W$ is a linear transformation and $V, W$ are vector spaces of the same dimension and finite dimension, then\n$$ \\rank (T) = \\dim (V) $$\n$\\rank (T)$ is the rank of $T$.\n(d) The inverse $T^{-1} : W \\to V$ of a linear transformation $T : V \\to W$ is also a linear transformation.\n(e) For an invertible linear transformation $T : V \\to W$, it\u0026rsquo;s necessary and sufficient for $V$ to be finite-dimensional if and only if $W$ is finite-dimensional. In this case, $\\dim(V) = \\dim(W)$ holds.\n(f) $T$ being invertible is equivalent to $[T]_{\\beta}^{\\gamma}$ being invertible. Furthermore, $[T^{-1}]_{\\beta}^{\\gamma} = ([T]_{\\beta}^{\\gamma})^{-1}$. In this case, $[T]_{\\beta}^{\\gamma}$ is the matrix representation of $T$.\nProof (d) Given $\\mathbf{x}_{1}, \\mathbf{x}_{2} \\in V$, and let $k$ be any constant. Then, since $T$ is linear, the following holds.\n$$ \\begin{align*} T^{-1} \\left( T(\\mathbf{x}_{1}) + k T(\\mathbf{x}_{2}) \\right) \u0026amp;= T^{-1} \\left( T(\\mathbf{x}_{1} + k \\mathbf{x}_{2}) \\right) \\\\ \u0026amp;= \\mathbf{x}_{1} + k \\mathbf{x}_{2} \\\\ \u0026amp;= T^{-1}\\left( T(\\mathbf{x}_{1}) \\right) + kT^{-1}\\left( T(\\mathbf{x}_{2}) \\right) \\end{align*} $$\n‚ñ†\n(e)2 Assume $V$ is finite-dimensional, and $\\beta = \\left\\{ \\mathbf{v}_{1}, \\dots, \\mathbf{v}_{n} \\right\\}$ is a basis for $V$. Then, $T(\\beta)$ spans the codomain $R(T)=W$.\n$$ \\span (T(\\beta)) = R(T) = W $$\nThus, $W$ is finite-dimensional. The converse also holds.\nNow, assume $V, W$ is finite-dimensional. Since $T$ is injective and surjective,\n$$ \\nullity (T) = 0 \\quad \\text{and} \\quad \\rank(T) = \\dim(R(T)) = \\dim(W) $$\nBy the dimension theorem,\n$$ \\dim(V) = \\rank(T) + \\nullity(T) = \\dim(W) $$\n‚ñ†\n(f)2 $(\\Longrightarrow)$\nAssume $T : V \\to W$ is invertible. Then, by (e), $\\dim(V) = n = \\dim(W)$. Thus, $[T]_{\\beta}^{\\gamma}$ is a $n \\times n$ matrix. As for the inverse $T^{-1}$ of $T$, since $T^{-1}T = I_{V}, TT^{-1} = I_{W}$,\n$I_{n} = [I_{V}]_{\\beta} = \\href{../3074}{[T^{-1}T]_{\\beta} = {[T^{-1}]_{\\gamma}^{\\beta}[T]_{\\beta}^{\\gamma}}}$\nSimilarly, $I_{n} = [I_{W}]_{\\beta} = [TT^{-1}]_{\\beta} = [T]_{\\beta}^{\\gamma}[T^{-1}]_{\\gamma}^{\\beta}$ is satisfied. Therefore, $[T]_{\\beta}^{\\gamma}$ is an invertible matrix, and its inverse is $([T]_{\\beta}^{\\gamma})^{-1} = [T^{-1}]_{\\gamma}^{\\beta}$.\n$(\\Longleftarrow)$\nAssume $A = [T]_{\\beta}^{\\gamma}$ is an invertible matrix. Then, a $n \\times n$ matrix $B$ satisfying $AB = BA = I$ exists. Then, the linear transformation $U : W \\to V$ defined as follows uniquely exists.\n$$ U(\\mathbf{w}_{j}) = \\sum_{i=1}^{n}B_{ij}\\mathbf{v}_{i} \\quad \\text{ for } j = 1,\\dots,n $$\nIn this case, $\\gamma = \\left\\{ \\mathbf{w}_{1}, \\dots, \\mathbf{w}_{n} \\right\\}, \\beta = \\left\\{ \\mathbf{v}_{1}, \\dots, \\mathbf{v}_{n} \\right\\}$. Hence, the matrix representation of $U$ is $[U]_{\\gamma}^{\\beta} = B$. Then, the following holds.\n$$ [UT]_{\\beta} = [U]_{\\gamma}^{\\beta} [T]_{\\gamma}^{\\beta} = BA = I_{n} = [I_{V}]_{\\beta} $$\nTherefore, $UT = I_{V}$, and similarly, $TU = I_{W}$ holds. Therefore, $T$ is an invertible transformation.\n‚ñ†\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p99-100\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p101\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3285,"permalink":"https://freshrimpsushi.github.io/en/posts/3285/","tags":null,"title":"Inverse of Linear Transformations"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview To achieve this, we can use unique(). More precisely, it leaves only one of the duplicates rather than deleting duplicated rows.\nCode using DataFrames\rWJSN = DataFrame(\rmember = [\u0026#34;Îã§ÏòÅ\u0026#34;,\u0026#34;Îã§Ïõê\u0026#34;,\u0026#34;Î£®Îã§\u0026#34;,\u0026#34;ÏÜåÏ†ï\u0026#34;,\u0026#34;ÏàòÎπà\u0026#34;,\u0026#34;Ïó∞Ï†ï\u0026#34;,\u0026#34;Ï£ºÏó∞\u0026#34;,\u0026#34;ÏßÄÏó∞\u0026#34;,\u0026#34;ÏßÑÏàô\u0026#34;,\u0026#34;ÌòÑÏ†ï\u0026#34;],\rbirth = [99,97,97,95,96,99,98,95,99,94],\rheight = [161,167,157,166,159,165,172,163,162,165],\runit = [\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;]\r)\rsort!(WJSN, :birth)\runique(WJSN, :unit) Let\u0026rsquo;s run the example code above and check its result.\njulia\u0026gt; WJSN\r10√ó4 DataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÌòÑÏ†ï 94 165 ÎçîÎ∏îÎûô\r2 ‚îÇ ÏÜåÏ†ï 95 166 ÎçîÎ∏îÎûô\r3 ‚îÇ ÏßÄÏó∞ 95 163 ÎçîÎ∏îÎûô\r4 ‚îÇ ÏàòÎπà 96 159 Ï™ºÍº¨ÎØ∏\r5 ‚îÇ Îã§Ïõê 97 167 Î©îÎ≥¥Ï¶à\r6 ‚îÇ Î£®Îã§ 97 157 Ï™ºÍº¨ÎØ∏\r7 ‚îÇ Ï£ºÏó∞ 98 172 ÎçîÎ∏îÎûô\r8 ‚îÇ Îã§ÏòÅ 99 161 Ï™ºÍº¨ÎØ∏\r9 ‚îÇ Ïó∞Ï†ï 99 165 Î©îÎ≥¥Ï¶à\r10 ‚îÇ ÏßÑÏàô 99 162 Ï™ºÍº¨ÎØ∏ The WJSN dataframe looks like the above.\nRemoving duplicated rows in a single column with unique() julia\u0026gt; unique(WJSN, :unit)\r3√ó4 DataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÌòÑÏ†ï 94 165 ÎçîÎ∏îÎûô\r2 ‚îÇ ÏàòÎπà 96 159 Ï™ºÍº¨ÎØ∏\r3 ‚îÇ Îã§Ïõê 97 167 Î©îÎ≥¥Ï¶à You can see that only one row remains for each :unit symbol.\nEnvironment OS: Windows julia: v1.6.3 ","id":2252,"permalink":"https://freshrimpsushi.github.io/en/posts/2252/","tags":null,"title":"How to Delete Duplicate Rows in DataFrames in Julia"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition For a given cumulative distribution function $F$, suppose $F_{\\theta}$ satisfies $F_{\\theta} (x) = F \\left( x - \\theta \\right)$ for all $x$.\n$\\left\\{ F_{\\theta} : \\theta \\in \\mathbb{R} \\right\\}$ is referred to as a Location Family.\nExample 1 Considering a random sample $X_{1} , \\cdots , X_{n}$ with parameter $\\theta$ that possesses a cumulative distribution function $F_{0} (x) = F (x - 0) = F(x)$, the sample $Z_{1} , \\cdots , Z_{n}$ can be expressed as $$ X_{i} = Z_{i} + \\theta $$. The length of the range as a statistical measure, $R = X_{n} - X_{(1)}$, should indeed be constant regardless of $\\theta$. This is because $\\theta$ merely increases or decreases the magnitude of values, not affecting their dispersion. In fact, the joint cumulative distribution function of $R$ is $$ \\begin{align*} F_{R} \\left( r ; \\theta \\right) =\u0026amp; P_{\\theta} \\left( R \\le r \\right) \\\\ =\u0026amp; P_{\\theta} \\left( X_{(n)} - X_{(1)} \\le r \\right) \\\\ =\u0026amp; P_{\\theta} \\left( \\max_{k} X_{k} - \\min_{k} X_{k} \\le r \\right) \\\\ =\u0026amp; P_{\\theta} \\left( \\max_{k} \\left( Z_{k} + \\theta \\right) - \\min_{k} \\left( Z_{k} + \\theta \\right) \\le r \\right) \\\\ =\u0026amp; P_{\\theta} \\left( \\max_{k} \\left( Z_{k} \\right) + \\theta - \\min_{k} \\left( Z_{k} \\right) - \\theta \\le r \\right) \\\\ =\u0026amp; P_{\\theta} \\left( Z_{(n)} - Z_{(1)} \\le r \\right) \\end{align*} $$. In other words, $R$ acts as an auxiliary statistic for $\\theta$.\nSee Also Exponential Family Scale Family Casella. (2001). Statistical Inference(2nd Edition): p283.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2251,"permalink":"https://freshrimpsushi.github.io/en/posts/2251/","tags":null,"title":"Location Family"},{"categories":"Í∏∞ÌïòÌïô","contents":"Buildup Given a vector field $\\mathbf{V}$ on a differentiable manifold, we can differentiate functions defined on the manifold using the vector field. Naturally, one might also want to differentiate the vector field itself. However, approaching the differentiation of the vector field $\\mathbb{R}^{3}$ in the sense of differential geometry proves to be impossible as follows.\nFirst Case\nLet\u0026rsquo;s consider $S \\subset \\mathbb{R}^{3}$ as a surface and $c : I \\to S$ as a curve given on $S$. Also, let\u0026rsquo;s say that $\\mathbf{V}$ is a vector field following $c$. Then, $\\mathbf{V}(t)$ becomes a tangent vector on $c(t)$.\n$$ \\mathbf{V}(t) \\in T_{c(t)}S $$\nThen, it can be represented as a coordinate vector like this:\n$$ \\mathbf{V}(t) = \\left( V_{1}(t), V_{2}(t), V_{3}(3) \\right) $$\nTherefore, one would desperately want to differentiate the vector like this:\n$$ \\dfrac{d \\mathbf{V}}{d t}(t) = \\left( V_{1}^{\\prime}(t), V_{2}^{\\prime}(t), V_{3}^{\\prime}(3) \\right) $$\nHowever, defining the derivative of $\\mathbf{V}$ like above generally does not result in a tangent vector.\n$$ \\dfrac{d \\mathbf{V}}{d t}(t) \\notin T_{c(t)}S $$\nDifferential geometry is interested in objects with intrinsic properties, but such a definition makes the derivative of the vector field not intrinsic. Therefore, the vector field is instead projected onto the tangent bundle $TS$ to treat it as a derivative. Let\u0026rsquo;s call $\\Pi : \\mathbb{R}^{3} \\to TS$ an orthogonal projection. Then, the derivative of the vector field is defined as follows:\n$$ \\dfrac{D \\mathbf{V}}{d t}(t) := \\Pi \\circ \\dfrac{d \\mathbf{V}}{d t}(t) $$\nThis is called the covariant derivative and is intrinsic.\nSecond Case\nConsider the differentiation of the function defined by the limit as follows.\n$$ \\dfrac{d \\mathbf{v}}{d t}(t) = \\lim\\limits_{h \\to 0} \\dfrac{\\mathbf{V}(t+h) - \\mathbf{V}(t)}{h} $$\nHowever, since $\\mathbf{V}(t+h) \\in T_{c(t+h)}S$ and $\\mathbf{V}(t) \\in T_{c(t)}S$, the two terms in the numerator are elements of different spaces. Therefore, addition operation is impossible.\nFor these reasons, the differentiation of the vector field is defined as an abstract concept that satisfies the formal conditions that differentiation must have.\nDefinition Let $\\mathfrak{X}(M)$1 be the set of $C^{\\infty}$ vector fields on a differentiable manifold $M$.\n$$ \\mathfrak{X}(M) := \\left\\{ \\text{all vector fields of class } C^{\\infty} \\text{ on } M \\right\\} $$\nLet $\\mathcal{D}(M)$ be the set of $C^{\\infty}$ functions defined on $M$.\n$$ \\mathcal{D}(M) := \\left\\{ \\text{all real-valued functions of class } C^{\\infty} \\text{ defined on } M \\right\\} $$\nThen, an affine connection $\\nabla$ on the differentiable manifold $M$ is\n$$ \\begin{align*} \\nabla : \\mathfrak{X}(M) \\times \\mathfrak{X}(M)\u0026amp; \\to \\mathfrak{X}(M) \\\\ (X, Y) \u0026amp;\\mapsto \\nabla_{X}Y \\end{align*} $$\ndefined as such a mapping, satisfying the following properties:\n$\\nabla_{fX + gY} Z = f \\nabla _{X}Z + g\\nabla_{Y}Z$ $\\nabla_{X}(Y + Z) = \\nabla_{X}Y + \\nabla_{X}Z$ $\\nabla_{X}(fX) = f\\nabla_{X}Y + X(f) Y$ Explanation In $\\nabla_{X}Y$, $X$ is the variable being differentiated, and $Y$ is the function being differentiated. Hence, 1. ~ 3. represent the following properties of differentiation, respectively.\n1.„ÄÄ$\\left( a\\dfrac{\\partial }{\\partial x} + b\\dfrac{\\partial }{\\partial y} \\right)f = a\\dfrac{\\partial f}{\\partial x} + b\\dfrac{\\partial f}{\\partial y}$\n2.„ÄÄ$\\dfrac{\\partial }{\\partial x}(f+ g) = \\dfrac{\\partial f}{\\partial x} + \\dfrac{\\partial g}{\\partial x}$\n3.„ÄÄ$\\dfrac{\\partial }{\\partial x}(fg) = \\dfrac{\\partial f}{\\partial x}g + f\\dfrac{\\partial g}{\\partial x}$\nTherefore, $\\nabla_{X}$ is interpreted as $\\dfrac{\\partial}{\\partial x}$, and $Y$ as $f$.\nTheorem $(\\nabla_{X}Y)(p)$ depends only on $X(p)$ and $Y(\\gamma (t))$. At this time, $\\gamma$ is\n$$ \\gamma : (-\\epsilon, \\epsilon) \\to M \\\\ \\gamma (0) = p \\\\ \\gamma^{\\prime}(0) = X(p) $$\na curve satisfying the condition.\nProof Choose a coordinate $\\mathbf{x} : U \\to M$. And let\u0026rsquo;s consider $X, Y$ as a vector field.\n$$ X = \\sum_{i} X_{i} \\dfrac{\\partial }{\\partial x_{i}},\\quad Y = \\sum_{j} Y_{j}\\dfrac{\\partial }{\\partial x_{j}} $$\nThen, due to the properties of $\\nabla$,\n$$ \\begin{align*} \\nabla_{X}Y =\u0026amp; \\nabla_{\\sum_{i} X_{i}\\frac{\\partial}{\\partial x_{i}}}\\sum_{j}Y_{j}\\dfrac{\\partial }{\\partial x_{j}} \\\\ =\u0026amp; \\sum_{i,j} \\nabla_{X_{i}\\frac{\\partial}{\\partial x_{i}}}Y_{j}\\dfrac{\\partial }{\\partial x_{j}} \u0026amp;\\text{by 1. and 2.}\\\\ =\u0026amp; \\sum_{i,j} X_{i}\\nabla_{\\frac{\\partial}{\\partial x_{i}}}Y_{j}\\dfrac{\\partial }{\\partial x_{j}} \u0026amp;\\text{by 1.} \\\\ =\u0026amp; \\sum_{i,j} X_{i} \\left( \\dfrac{\\partial Y_{j}}{\\partial x_{i}}\\dfrac{\\partial }{\\partial x_{j}} + Y_{j}\\nabla_{\\frac{\\partial}{\\partial x_{i}}}\\dfrac{\\partial }{\\partial x_{j}} \\right) \u0026amp;\\text{by 3.} \\end{align*} $$\nAt this point, $\\nabla_{\\frac{\\partial}{\\partial x_{j}}}\\dfrac{\\partial }{\\partial x_{j}}$ is a value that depends only on the choice of coordinates, independent of the vector field. Since this is also a vector field according to the definition of affine connection, if the coefficients are said to be $\\Gamma_{ij}^{k}$, it can be written as follows:\n$$ \\nabla_{\\frac{\\partial }{\\partial x_{i}}}\\dfrac{\\partial }{\\partial x_{j}} = \\sum_{k} \\Gamma_{ij}^{k} \\dfrac{\\partial }{\\partial x_{k}} $$\nSubstituting this,\n$$ \\begin{align*} \\nabla_{X}Y =\u0026amp; \\sum_{i,j} X_{i} \\left( \\dfrac{\\partial Y_{j}}{\\partial x_{i}}\\dfrac{\\partial }{\\partial x_{j}} + Y_{j}\\nabla_{\\frac{\\partial}{\\partial x_{i}}}\\dfrac{\\partial }{\\partial x_{j}} \\right) \\\\ =\u0026amp; \\sum_{i,j} X_{i} \\left( \\dfrac{\\partial Y_{j}}{\\partial x_{i}}\\dfrac{\\partial }{\\partial x_{j}} + Y_{j}\\sum_{k} \\Gamma_{ij}^{k} \\dfrac{\\partial }{\\partial x_{k}} \\right) \\\\ =\u0026amp; \\sum_{i,j} X_{i} \\dfrac{\\partial Y_{j}}{\\partial x_{i}}\\dfrac{\\partial }{\\partial x_{j}} + \\sum_{i,j,k} X_{i}Y_{j}\\Gamma_{ij}^{k} \\dfrac{\\partial }{\\partial x_{k}} \\end{align*} $$\nHere, since $i,j,k$ is a dummy index, let\u0026rsquo;s change $j$ in the previous term to $k$. Then,\n$$ \\begin{align*} \\nabla_{X}Y =\u0026amp; \\sum_{i,k} X_{i} \\dfrac{\\partial Y_{k}}{\\partial x_{i}}\\dfrac{\\partial }{\\partial x_{k}} + \\sum_{i,j,k} X_{i}Y_{j}\\Gamma_{ij}^{k} \\dfrac{\\partial }{\\partial x_{k}} \\\\ =\u0026amp; \\sum_{i,k} X_{i} \\left( \\dfrac{\\partial Y_{k}}{\\partial x_{i}} + \\sum_{j} Y_{j}\\Gamma_{ij}^{k}\\right) \\dfrac{\\partial }{\\partial x_{k}} \\\\ \\end{align*} $$\nHere, $\\Gamma_{ij}^{k}, \\dfrac{\\partial }{\\partial x_{k}}$ is determined by the given coordinates. Just like that, $\\dfrac{\\partial Y_{k}}{\\partial x_{i}}$ is also determined once $Y_{k}$ is given. Therefore, the above equation depends only on the value of $X(p), Y(\\gamma (t))$.\n‚ñ†\nIt is the Lie algebra X. \\mathfrak{X}\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3282,"permalink":"https://freshrimpsushi.github.io/en/posts/3282/","tags":null,"title":"Affine Connection"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, options related to subplots can be controlled through the layout option.\nEntering an integer automatically creates a grid of that many plots. Entering a 2-tuple of integers creates a grid exactly as specified. The @layout macro is used to create complex layouts of the Plots.GridLayout type. Code using Plots\rleft = plot(randn(100), color = :red)\rright = plot(randn(100), color = :blue)\rplot(left, right)\rpng(\u0026#34;easyone\u0026#34;)\rdata = rand(10, 6)\rplot(data, layout = 6)\rpng(\u0026#34;easytwo\u0026#34;)\rplot(data, layout = (3,2))\rpng(\u0026#34;easygrid\u0026#34;)\rl = @layout [p1 ; p2 p2]\rp = plot(\rplot(rand(10)),\rplot(rand(100)),\rplot(rand(1000)),\rlayout = l)\rpng(\u0026#34;hardgrid\u0026#34;) Simple Enumeration left = plot(randn(100), color = :red)\rright = plot(randn(100), color = :blue)\rplot(left, right) Just by grouping several plots together and plotting again, it becomes a subplot.\nSimple Layout layout plot(data, layout = 6) plot(data, layout = (3,2)) You can simply use an integer or provide a tuple to create the desired grid. Since it works the same way without providing an integer, it‚Äôs only necessary to remember the case where a tuple is given.\nComplex Layout @layout l = @layout [p1 ; p2 p2] Defined a Plots.GridLayout type l that directs the layout such that there\u0026rsquo;s one picture in the first row and two columns of pictures in the second row. By providing this as an input to layout, a much more complex layout is represented like this.\np = plot(\rplot(rand(10)),\rplot(rand(100)),\rplot(rand(1000)),\rlayout = l) Creating Empty Spaces _ In the example above, if you want to center the picture in the first row to be the same size as those below, you can create empty spaces on both sides. You can indicate an empty space with _. If you adjust the width to half of the total with {0.5w},\nl = @layout([_ p{0.5w} _; p p])\rplot(\rplot(rand(10)),\rplot(rand(100)),\rplot(rand(1000)),\rlayout = l) Environment OS: Windows julia: v1.6.3 ","id":2250,"permalink":"https://freshrimpsushi.github.io/en/posts/2250/","tags":null,"title":"Drawing Subplots with a Layout in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definitions1 Let\u0026rsquo;s call $V$ a vector space. A mapping $f$ from $V$ to $\\mathbb{C}$ (or $\\mathbb{R}$) is called a functional.\n$$ f : V \\to \\mathbb{C} $$\nIf $f$ is linear, it is called a linear functional.\nMore Detailed Definitions2 Let\u0026rsquo;s call $V$ a vector space over the field $F$. Here, the field $F$ itself becomes a $1$-dimensional vector space over $F$. A linear transformation $f : V \\to F$ is called a linear functional.\nIn other words, a linear functional is a linear transformation between a vector space and its field.\nExplanation The first definition given is the most common. Usually, it is not defined as abstractly as the second.\nWhen translating functional into Korean, it becomes \u0026lsquo;Î≤îÌï®Ïàò\u0026rsquo; without much nuance, but it is important to note in English that functional is not an adjective but a noun. Also, the translation of functional as Î≤îÌï®Ïàò (Ê±éÂáΩÊï∏) is influenced by generalized function.\nThe distinction from linear operators is only that the codomain is defined as $\\mathbb{R}$ or $\\mathbb{C}$, but this very difference makes it worthwhile to consider spaces such as dual spaces. Norm $\\| \\cdot \\| = \\| \\cdot \\|_{V}$ already becomes a functional in itself, and considering its usefulness in connection with measure theory is inevitable.\nExamples Trace Let\u0026rsquo;s assume $V = M_{n\\times n}(\\mathbb{R})$. Define the function $f$ as follows.\n$$ f : M_{n\\times n}(\\mathbb{R}) \\to \\mathbb{R} \\quad \\text{ by } \\quad f(A) = \\tr(A) $$\nThen $\\tr$ is the trace of a matrix. Thus, $f$ is a linear functional.\nFourier Coefficients Let\u0026rsquo;s assume $V$ is a vector space of continuous functions that satisfy $f : [0, 2\\pi] \\to \\mathbb{R}$. For a fixed $g \\in V$, define $h : V \\to \\mathbb{R}$ as follows.\n$$ h(f) = \\dfrac{1}{2\\pi} \\int_{0}^{2\\pi} f(x)g(x)dx $$\nThen $h$ is a linear functional. When $g$ is either $\\cos nx$ or $\\sin nx$, $h(f)$ becomes the Fourier coefficient of $f$.\nCoordinate Function Let\u0026rsquo;s consider $V$ as a finite-dimensional vector space. Assume $\\beta = \\left\\{ \\mathbf{v}_{1}, \\dots, \\mathbf{v}_{n} \\right\\}$ is the ordered basis of $V$. Let the coordinate vector of $\\mathbf{x} \\in V$ be as follows.\n$$ [\\mathbf{x}]_{\\beta} = \\begin{bmatrix} a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{n} \\end{bmatrix} $$\nNow, consider the following function for $1 \\le i \\le n$.\n$$ f_{i}(\\mathbf{x}) = a_{i} $$\nThen $f_{i}$ is a linear functional defined on $V$, called the $i$th coordinate function. Then, $f_{i}(\\mathbf{v}_{i}) = \\delta_{ij}$ holds true. $\\delta_{ij}$ is the Kronecker delta. Coordinate functions play an important role in discussing dual spaces.\nKreyszig. (1989). Introductory Functional Analysis with Applications: p103~104.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p119\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3281,"permalink":"https://freshrimpsushi.github.io/en/posts/3281/","tags":null,"title":"Linear Functional"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 Let $S$ be a statistic of sample $\\mathbf{X}$. If the distribution of $S \\left( \\mathbf{X} \\right)$ does not depend on the parameter $\\theta$, it is called an Ancillary Statistic.\nDescription Actually, nobody says ancillary statistic in conversation, they pronounce it as [ancillary statistic].\nIf a sufficient statistic has all the information about $\\theta$, then an ancillary statistic can be thought of as a statistic that has no information about $\\theta$ at all.\nFor example, consider a random sample $X_{1} , \\cdots , X_{n}$ from a normal distribution $N \\left( \\mu , \\sigma^{2} \\right)$. The sample variance $$ S^{2} = {{ 1 } \\over { n -1 }} \\sum_{k=1}^{n} X_{k}^{2} $$ is a sufficient statistic for the population variance $\\sigma^{2}$, but according to Student\u0026rsquo;s theorem, $$ {{ n-1 } \\over { \\sigma^{2} }} S^{2} \\sim \\chi_{n-1}^{2} $$ This means that the population variance $\\mu$ does not appear in the chi-squared distribution that the sample variance follows, and it is an ancillary statistic regarding $\\mu$.\nCasella. (2001). Statistical Inference(2nd Edition): p282.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2249,"permalink":"https://freshrimpsushi.github.io/en/posts/2249/","tags":null,"title":"Auxiliary Statistics"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview 1 The position of the legend can be freely adjusted with the legend option of the plot() function. Giving a 2-tuple comprised of values between $0$ and $1$ will exactly place it at that location, otherwise, it can be controlled by symbols.\nSymbols combine top/bottom and left/right in order. Adding an outer at the very beginning places the legend outside of the plot. Examples of symbols that can be created through combinations include:\n:bottom :left :bottomleft :outertopright Since the order must be connected, symbols like :leftbottom or :toprightouter are not allowed.\nCode data = randn(100, 2)\rplot(data)\rplot(data, legend = (0.5, 0.7)); png(\u0026#34;tuple\u0026#34;)\rSymbols = [:none, :bottom, :left, :bottomleft, :outertopright, :inline]\rfor symbol ‚àà Symbols\rplot(data, legend = symbol)\rpng(string(symbol))\rend Specifying exact location legend = (0.5, 0.7) The tuple (0.5, 0.7) places the legend at about 50% of the horizontal axis and 70% of the vertical height.\nRemoving the legend :none Top, Bottom, Left, Right :bottom, :left Combination :bottomleft Outside :outertopright The legend is moved outside of the plot. Note that this may distort the figure.\nEnd-of-line :inline Useful when there are many lines that are hard to distinguish by color, or when the last value is particularly important.\nEnvironment OS: Windows julia: v1.6.3 https://docs.juliaplots.org/latest/generated/attributes_subplot/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2248,"permalink":"https://freshrimpsushi.github.io/en/posts/2248/","tags":null,"title":"Adjusting the Position of the Legend in Julia Plots"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let\u0026rsquo;s say $V$ is a finite-dimensional vector space. When a specific order is assigned to a basis of $V$, it is called an ordered basis.\nLet\u0026rsquo;s say $\\beta = \\left\\{ \\mathbf{v}_{1}, \\dots, \\mathbf{v}_{n} \\right\\}$ is an ordered basis of $V$. Then, due to the uniqueness of basis representation, for $\\mathbf{v} \\in V$, scalars $a_{i}$ uniquely exist as follows.\n$$ \\mathbf{v} = a_{1}\\mathbf{v}_{1} + \\dots a_{n}\\mathbf{v}_{n} $$\n$a_{1},\\dots,a_{n}$ is called the coordinate of $\\mathbf{v}$ relative to basis $\\beta$. The matrix that has the $i$th coordinate as its $i$th component is called the coordinate vector of $\\mathbf{v}$ relative to $\\beta$ or coordinate matrix, and is denoted as $[\\mathbf{v}]_{\\beta}$.\n$$ [\\mathbf{v}]_{\\beta} = \\begin{bmatrix} a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{n} \\end{bmatrix} $$\nFurthermore, the ordered basis $\\beta$ is called a coordinate system.\nExplanation The basis is defined as a set, and the order in which the elements of the set are listed does not matter, which means $\\alpha = \\left\\{ \\mathbf{e}_{1}, \\mathbf{e}_{2}, \\mathbf{e}_{3} \\right\\} = \\left\\{ \\mathbf{e}_{2}, \\mathbf{e}_{3}, \\mathbf{e}_{1} \\right\\} = \\beta$. Therefore, to abstract the concept of \u0026lsquo;coordinate\u0026rsquo;, it is necessary to assign order to the elements of the basis. Now, if we say $\\alpha, \\beta$ is an ordered basis,\n$$ \\alpha = \\left\\{ \\mathbf{e}_{1}, \\mathbf{e}_{2}, \\mathbf{e}_{3} \\right\\} \\ne \\left\\{ \\mathbf{e}_{2}, \\mathbf{e}_{3}, \\mathbf{e}_{1} \\right\\} = \\beta $$\n$[\\mathbf{v}_{i}]_{\\beta} = \\mathbf{e}_{i}$ holds. $\\mathbf{e}_{i}$ is the standard basis.\nThe function $T : \\mathbf{v} \\mapsto [\\mathbf{v}]_{\\beta}$ becomes a linear transformation from $V$ to $\\mathbb{R}^{n}$.\nRegarding vector space $\\mathbb{R}^{n}$, $\\left\\{ \\mathbf{e}_{1}, \\dots, \\mathbf{e}_{n} \\right\\}$ is called the standard ordered basis.\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p79-80\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3279,"permalink":"https://freshrimpsushi.github.io/en/posts/3279/","tags":null,"title":"Order Basis and Coordinate Vectors"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview 1 To adjust the width and height of the figure, you can include the ratio option. Other recommended aliases include aspect_ratios, axis_ratio.\nratio = :none: The default value, where the figure\u0026rsquo;s size is adjusted to fit the ratio. ratio = :equal: Regardless of the figure\u0026rsquo;s size, the x and y axes are adjusted to a one-to-one ratio. ratio = Number: The ratio is adjusted according to Number. Number is given as the ratio in ${{ÏÑ∏Î°ú} \\over {Í∞ÄÎ°ú}} = {{\\Delta y} \\over {\\Delta x}}$. Code using Plots\rx = rand(100)\ry = randn(100)\rplot(x,y,seriestype = :scatter, ratio = :none)\rpng(\u0026#34;none\u0026#34;)\rplot(x,y,seriestype = :scatter, ratio = :equal)\rpng(\u0026#34;equal\u0026#34;)\rplot(x,y,seriestype = :scatter, ratio = 0.5)\rpng(\u0026#34;0.5\u0026#34;)\rplot(x,y,seriestype = :scatter, ratio = 1)\rpng(\u0026#34;1\u0026#34;)\rplot(x,y,seriestype = :scatter, ratio = 2)\rpng(\u0026#34;2\u0026#34;) Default :none plot(x,y,seriestype = :scatter, ratio = :none) One-to-One :equal plot(x,y,seriestype = :scatter, ratio = :equal) Specific Ratio Number Number is given as the ratio in ${{ÏÑ∏Î°ú} \\over {Í∞ÄÎ°ú}}$.\nplot(x,y,seriestype = :scatter, ratio = 0.5) plot(x,y,seriestype = :scatter, ratio = 1) plot(x,y,seriestype = :scatter, ratio = 2) Environment OS: Windows julia: v1.6.3 https://docs.juliaplots.org/latest/generated/attributes_subplot/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2246,"permalink":"https://freshrimpsushi.github.io/en/posts/2246/","tags":null,"title":"How to Adjust the Aspect Ratio of a Julia Set Picture"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 A Riemannian metric $g$ on a $n$-dimensional differentiable manifold $M$ is a function that maps each point $p \\in M$ to $g_{p}$. Here, $g_{p}$ is an inner product defined in the tangent space $p$ over $T_{p}M$.\n$$ \\begin{align*} g : M \u0026amp;\\to \\left\\{ \\text{all inner products on tangent space } T_{p}M \\right\\} \\\\ p \u0026amp;\\mapsto g_{p}=\\left\\langle \\cdot, \\cdot \\right\\rangle_{p} \\end{align*} $$\n$$ \\begin{align*} g_{p} : T_{p}M \\times T_{p}M \u0026amp;\\to \\mathbb{R} \\\\ (\\mathbf{X}_{p}, \\mathbf{Y}_{p}) \u0026amp;\\mapsto g_{p}(\\mathbf{X}_{p}, \\mathbf{Y}_{p})=\\left\\langle \\mathbf{X}_{p}, \\mathbf{Y}_{p} \\right\\rangle_{p} \\end{align*} $$\nIn this case, $g_{p}$ should be differentiable in the following sense:\nLet $\\mathbf{x} : U \\subset \\mathbb{R}^{n} \\to M$ be a coordinate system around $p$, and say that $\\mathbf{x}(x_{1}, \\dots, x_{n}) = p$. Then, the following $g_{ij} : \\mathbb{R}^{n} \\to \\mathbb{R}$ must be differentiable:\n$$ g_{ij} (x_{1}, \\dots, x_{n}) = \\left\\langle \\left. \\dfrac{\\partial }{\\partial x_{i}} \\right|_{p}, \\left. \\dfrac{\\partial }{\\partial x_{j}} \\right|_{p}\\right\\rangle_{p} $$\n$g_{ij}$ is called the local representation of the Riemannian metric. A differentiable manifold $(M, g)$ given a Riemannian metric is called a Riemannian manifold.\nExplanation Studying a Riemannian manifold $(M, g)$ is referred to as Riemannian geometry. $g$ is also referred to as the Riemannian structure. $g_{ij}$ is learned in differential geometry as the coefficient of the first fundamental form.\nLet\u0026rsquo;s say $\\mathbf{X}_{p}, \\mathbf{Y}_{p} \\in T_{p}M$. Then, since $T_{p}M$ is a $n$-dimensional vector space with basis $\\left\\{ \\left. \\dfrac{\\partial }{\\partial x_{i}} \\right|_{p} \\right\\}$,\n$$ \\mathbf{X}_{p} = X^{i}(p)\\left. \\dfrac{\\partial }{\\partial x_{i}} \\right|_{p} \\text{ and } \\mathbf{Y}_{p} = Y^{j}(p)\\left. \\dfrac{\\partial }{\\partial x_{j}} \\right|_{p} $$\nTherefore,\n$$ g_{p}(\\mathbf{X}_{p}, \\mathbf{Y}_{p}) = \\left\\langle \\mathbf{X}_{p}, \\mathbf{Y}_{p} \\right\\rangle = X^{i}(p)Y^{j}(p) \\left\\langle \\left. \\dfrac{\\partial }{\\partial x_{i}} \\right|_{p}, \\left. \\dfrac{\\partial }{\\partial x_{j}} \\right|_{p} \\right\\rangle = X^{i}(p)Y^{j}(p)g_{ij}(p) $$\nGeneralizing from $p$,\n$$ g(\\mathbf{X}, \\mathbf{Y}) = X^{i}Y^{j} \\left\\langle \\dfrac{\\partial }{\\partial x_{i}}, \\dfrac{\\partial }{\\partial x_{j}} \\right\\rangle = X^{i}Y^{j}g_{ij} $$\nAnother expression for the condition of differentiability is as follows:\nA function $g(\\mathbf{X}, \\mathbf{Y}) : M \\to \\mathbb{R}$ defined on the manifold is differentiable.\n$$ g(\\mathbf{X}, \\mathbf{Y}) (p) = g_{p} (\\mathbf{X}_{p}, \\mathbf{Y}_{p}), \\quad \\mathbf{X}_{p}, \\mathbf{Y}_{p} \\in T_{p}M $$\nIn this case, it is also denoted as $g(\\mathbf{X}, \\mathbf{Y})_{p} = g(\\mathbf{X}, \\mathbf{Y}) (p)$.\nIt is known that \u0026ldquo;all differentiable manifolds have a Riemannian metric.\u0026rdquo; Thus, the direction of research is not \u0026lsquo;conditions under which a manifold $M$ has a Riemannian metric\u0026rsquo;, but rather \u0026lsquo;what kind of good Riemannian metric can be given to a manifold $M$\u0026rsquo;.\nInduced Metric Given an immersion $f : M \\to N$ between differentiable manifolds $M, N$, suppose $(N, h)$ is a Riemannian manifold. The Riemannian metric $g$ on $M$ defined as follows is called the induced metric on $M$ by $f$.\n$$ g_{p}(v, w) := h_{f(p)}(df_{p}(v), df_{p}(w)) $$\nHere, $df_{p}$ is the derivative of $f$ at point $p$.\nEuclidean Space Consider Euclidean space as a differentiable manifold $M = \\mathbb{R}^{n}$. Then, $T_{p}\\mathbb{R}^{n} \\approx \\mathbb{R}^{n}$ and the basis $\\left\\{ \\dfrac{\\partial }{\\partial x}_{i} \\right\\}$ is the same as the standard basis $\\left\\{ e_{i} = (0, \\dots, 1, \\dots, 0) \\right\\}$ of Euclidean space. Therefore, the metric coefficients are as follows.\n$$ g_{ij} = \\left\\langle e_{i}, e_{j} \\right\\rangle = \\delta_{ij} $$\nHence, the Riemannian metric of Euclidean space is the inner product defined as standard in Euclidean space itself. Studying $(\\mathbb{R}^{n}, g)$ is referred to as Euclidean geometry.\nManfredo P. Do Carmo, Riemannian Geometry (Eng Edition, 1992), p38-39\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3276,"permalink":"https://freshrimpsushi.github.io/en/posts/3276/","tags":null,"title":"Riemann Metric and Riemann Manifolds"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Error using DataFrames, CSV\rexample = DataFrame(x = 1:10, Í∞Ä = \u0026#34;ÎÇòÎã§\u0026#34;)\rCSV.write(\u0026#34;example.csv\u0026#34;, example) When outputting to a CSV file in Julia, you can see a phenomenon where the Korean text becomes garbled, as shown above.\nCause The garbling isn\u0026rsquo;t actually due to the Korean text itself but a Unicode encoding issue, especially due to the UTF-8 encoding\u0026rsquo;s BOM. This can be solved by setting the encoding to UTF-8-sig in Python, among others.\nSolution 1 CSV.write(\u0026#34;example.csv\u0026#34;, example, bom = true) In CSV.jl, simply setting the option bom = true will output the text without it becoming garbled, as seen below.\nEnvironment OS: Windows julia: v1.6.3 https://csv.juliadata.org/stable/writing.html#CSV.write\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2244,"permalink":"https://freshrimpsushi.github.io/en/posts/2244/","tags":null,"title":"Solving Broken Characters when Exporting CSV in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview The Crayons.jl package is known for decorating text output in Julia1.\nIf you want to decorate using only built-in functions, you can use printstyled().\nCode using Crayons\rprint(Crayon(background = :red), \u0026#34;Îπ®Í∞ï\u0026#34;)\rprint(Crayon(foreground = :blue), \u0026#34;ÌååÎûë\u0026#34;)\rprint(Crayon(bold = true), \u0026#34;Î≥ºÎìú\u0026#34;)\rprint(Crayon(italics = true), \u0026#34;Ïù¥ÌÉ§Î¶≠\u0026#34;)\rprint(Crayon(bold = true, italics = true), \u0026#34;Î≥ºÎìú Ïù¥ÌÉ§Î¶≠\u0026#34;) Running the above console will give the following decorated result.\nCrayon(...)\nforeground: Changes the color of the text itself. It can be given as a symbol or an integer triple (r,g,b) or as an integer between 0 and 255. background: Changes the background color of the text. The method of passing arguments is the same as for foreground. The options that can be set as booleans are as follows. In the example above, both individual and simultaneous execution results are shown.\nbold: Bold text. italics: Italic text. underline: Underlined text. Environment OS: Windows julia: v1.6.3 https://github.com/KristofferC/Crayons.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2242,"permalink":"https://freshrimpsushi.github.io/en/posts/2242/","tags":null,"title":"- Text Formatting Package in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Let\u0026rsquo;s say we are given the Cosmic Girls dataframe as follows.\nWJSN = DataFrame(\rmember = [\u0026#34;Îã§ÏòÅ\u0026#34;,\u0026#34;Îã§Ïõê\u0026#34;,\u0026#34;Î£®Îã§\u0026#34;,\u0026#34;ÏÜåÏ†ï\u0026#34;,\u0026#34;ÏàòÎπà\u0026#34;,\u0026#34;Ïó∞Ï†ï\u0026#34;,\u0026#34;Ï£ºÏó∞\u0026#34;,\u0026#34;ÏßÄÏó∞\u0026#34;,\u0026#34;ÏßÑÏàô\u0026#34;,\u0026#34;ÌòÑÏ†ï\u0026#34;],\rbirth = [99,97,97,95,96,99,98,95,99,94],\rheight = [161,167,157,166,159,165,172,163,162,165],\r) julia\u0026gt; WJSN\r10√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161\r2 ‚îÇ Îã§Ïõê 97 167\r3 ‚îÇ Î£®Îã§ 97 157\r4 ‚îÇ ÏÜåÏ†ï 95 166\r5 ‚îÇ ÏàòÎπà 96 159\r6 ‚îÇ Ïó∞Ï†ï 99 165\r7 ‚îÇ Ï£ºÏó∞ 98 172\r8 ‚îÇ ÏßÄÏó∞ 95 163\r9 ‚îÇ ÏßÑÏàô 99 162\r10 ‚îÇ ÌòÑÏ†ï 94 165 The code to add a new column to the dataframe is as follows.\ndataframe[!, :\u0026quot;column_name\u0026quot;] = values To add a column for the unit, we get,\nWJSN[!, :\u0026#34;unit\u0026#34;] = [\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;Î©îÎ≥¥Ï¶à\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;,\u0026#34;Ï™ºÍº¨ÎØ∏\u0026#34;,\u0026#34;ÎçîÎ∏îÎûô\u0026#34;]\rjulia\u0026gt; WJSN\r10√ó4 DataFrame\rRow ‚îÇ member birth height unit ‚îÇ String Int64 Int64 String ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161 Ï™ºÍº¨ÎØ∏\r2 ‚îÇ Îã§Ïõê 97 167 Î©îÎ≥¥Ï¶à\r3 ‚îÇ Î£®Îã§ 97 157 Ï™ºÍº¨ÎØ∏\r4 ‚îÇ ÏÜåÏ†ï 95 166 ÎçîÎ∏îÎûô\r5 ‚îÇ ÏàòÎπà 96 159 Ï™ºÍº¨ÎØ∏\r6 ‚îÇ Ïó∞Ï†ï 99 165 Î©îÎ≥¥Ï¶à\r7 ‚îÇ Ï£ºÏó∞ 98 172 ÎçîÎ∏îÎûô\r8 ‚îÇ ÏßÄÏó∞ 95 163 ÎçîÎ∏îÎûô\r9 ‚îÇ ÏßÑÏàô 99 162 Ï™ºÍº¨ÎØ∏\r10 ‚îÇ ÌòÑÏ†ï 94 165 ÎçîÎ∏îÎûô Environment OS: Windows10 Version: Julia 1.7.1, DataFrames 1.3.2 ","id":3273,"permalink":"https://freshrimpsushi.github.io/en/posts/3273/","tags":null,"title":"Adding a New Column to a DataFrame in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 On two differentiable vector fields $X, Y$ on a differentiable manifold $M$, $[X, Y]$ is defined as follows, and is called the (Lie-)bracket or Lie algebra.\n$$ \\begin{equation} [X, Y] := XY - YX \\end{equation} $$\nExplanation Vector field $X, Y$ can be seen as an operator acting on $\\mathcal{D}(M)$, and $XY$ although not a vector field, $[X, Y] = XY - YX$ becomes a vector field.\n$(1)$ satisfying such equation is generally called a commutator.\nThe following theorem states that (a), (b), (c) are generally satisfied properties not only for Lie-brackets but also for commutators. Especially, (c) is known as the Jacobi identity.\nTheorem Let $X, Y, Z$ be a differentiable vector field on $M$. Let $a, b$ be a real number and $f, g$ be a differentiable function on $M$. Then, the following holds:\n(a) $[X, Y] = -[Y, X]$\n(b) $[aX + bY, Z] = a[X, Y] + b[Y, Z]$\n(c) $[ [X, Y], Z] + [ [Y, Z], X] + [ [Z, X], Y] = 0$\n(d) $[fX, gY] = fg[X, Y] + fX(g)Y - gY(f)X$\nProof (d) Since the differentiation of a product $X(gY) = X(g)Y + gXY$ holds,\n$$ \\begin{align*} [fX, gY] \u0026amp;= fX(gY) - gY(fX) \\\\ \u0026amp;= \\left( fX(g)Y + fgXY \\right) - \\left( gY(f)X - gfYX \\right) \\\\ \u0026amp;= fgXY - fgYX + fX(g)Y + gY(f)X\\\\ \u0026amp;= fg(XY - YX) + fX(g)Y + gY(f)X\\\\ \u0026amp;= fg[X, Y] + fX(g)Y + gY(f)X \\end{align*} $$\n‚ñ†\nManfredo P. Do Carmo, Riemannian Geometry (Eng Edition, 1992), p27-28\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3272,"permalink":"https://freshrimpsushi.github.io/en/posts/3272/","tags":null,"title":"Lie Brackets of Vector Fields"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code using Plots\rscatter(rand(100), randn(100))\rplot!([0,1],[0,1])\rpng(\u0026#34;example1\u0026#34;)\rplot!([.00,.25,.50],[-2,0,-2])\rpng(\u0026#34;example2\u0026#34;)\rŒ∏ = 0:0.01:2œÄ\rplot!(.5 .+ cos.(Œ∏)/3, 1.5sin.(Œ∏))\rpng(\u0026#34;example3\u0026#34;) Let\u0026rsquo;s learn how to insert line segments into the diagram by executing the code above.\nLine Segment plot!([0,1],[0,1]) Whether you draw just one line segment or something else, the method is the same. For a line segment, you need two points, so you just need to give an array of x coordinates and an array of y coordinates.\nMultiple Line Segments plot!([.00,.25,.50],[-2,0,-2]) y3 draws two line segments at once. The start and end points of the segments are connected.\nEllipse plot!(.5 .+ cos.(Œ∏)/3, 1.5sin.(Œ∏)) By applying the method used to draw multiple line segments, you can also draw an ellipse. Both grammatically and computationally, it\u0026rsquo;s relatively easier to draw compared to other languages.\nEnvironment OS: Windows julia: v1.6.3 ","id":2240,"permalink":"https://freshrimpsushi.github.io/en/posts/2240/","tags":null,"title":"Inserting a Line into a Julia Set Image"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 Let\u0026rsquo;s denote the joint probability density function or probability mass function of a sample $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{n} \\right)$ as $f(\\mathbf{x}|\\theta)$. When a realization $\\mathbf{x}$ is given, regarding $f(\\mathbf{x}|\\theta)$ as a function of $\\theta$ $$ L \\left( \\theta | \\mathbf{x} \\right) := f \\left( \\mathbf{x} | \\theta \\right) $$ is called the Likelihood Function.\nExplanation In the context of discussing maximum likelihood estimators, it is necessary for the sample to be iid, but when discussing the Likelihood Principle, it is perfectly fine to consider the random vector itself without specifically thinking about random variables.\nIf for the parameter $\\theta$, two parameters $\\theta_{1}$ and $\\theta_{2}$ $$ L \\left( \\theta_{1} | \\mathbf{x} \\right) \\ge L \\left( \\theta_{2} | \\mathbf{x} \\right) $$ then it is said that $\\theta_{1}$ is more Plausible than $\\theta_{2}$ regarding $\\theta$.\nCasella. (2001). Statistical Inference(2nd Edition): p290.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2239,"permalink":"https://freshrimpsushi.github.io/en/posts/2239/","tags":null,"title":"Definition of Likelihood Function"},{"categories":"Í∏∞ÌïòÌïô","contents":"Buildup1 Consider the easy definition of a vector field. In 3-dimensional space, a vector fieldvector function, vector field is a function $X : \\mathbb{R}^{3} \\to \\mathbb{R}^{3}$ that maps a 3-dimensional vector to another 3-dimensional vector. When considering this in the context of manifolds, $X$ maps a point $\\mathbb{R}^{3}$ on the differential manifold $p$ to a vector $\\mathbb{R}^{3}$ in $\\mathbf{v}$, treating this vector $\\mathbf{v}$ as an operator to consider as a directional derivative (= tangent vector). Therefore, a vector field is a function that maps a point $\\mathbb{R}^{3}$ on a manifold $p$ to a tangent vector $p$ at $\\mathbf{v}_{p} \\in T_{p}\\mathbb{R}^{3}$.\nThe codomain of a vector field is then the set of all tangent vectors at every point. Thus, a vector field $X$ is defined as the following function.\n$$ X : \\mathbb{R}^{3} \\to \\bigcup \\limits_{p\\in \\mathbb{R}^{3}} T_{p}\\mathbb{R}^{3} $$\nTo generalize this concept to manifolds, let\u0026rsquo;s define the tangent bundletangent bundle $M$ of a differential manifold $TM$ as follows.\n$$ TM := \\bigsqcup \\limits_{p\\in M} T_{p}M $$\nHere, $\\bigsqcup$ is a disjoint union.\nDefinition A vector fieldvector field $M$ on a differential manifold $X$ is a function that maps each point $p \\in M$ to a tangent vector $p$ at $X_{p} \\in T_{p}M$.\n$$ \\begin{align*} X : M \u0026amp;\\to TM \\\\ p \u0026amp;\\mapsto X_{p} \\end{align*} $$\nExplanation Values of a Vector Field Considering the definition of the tangent bundle, the element of $TM$ is $(p, X_{p})$, but it is mentioned in the definition that it maps $X_{p}$, which can raise questions.\n$$ \\begin{equation} TM := \\bigsqcup \\limits_{p \\in M } T_{p}M = \\bigcup_{p \\in M} \\left\\{ p \\right\\} \\times T_{p}M = \\left\\{ (p, X_{p}) : p \\in M, X_{p} \\in T_{p}M \\right\\} \\end{equation} $$\nSo, to be precise, according to the definition of the disjoint union, an element of $TM$ is indeed the ordered pair $(p, X_{p})$, but it is essentially treated as if it were $X_{p}$.\nThinking again about the definition of the tangent bundle, what we really want to do is not just collect ordered pairs $(p, X_{p})$ but to collect all tangent vectors at each point $p$. However, since each of $T_{p}M$ is isomorphic to $\\mathbb{R}^{n}$, there can be ambiguity when doing the union.\n$$ T_{p}M \\approxeq \\mathbb{R}^{n} \\approxeq T_{q}M $$\nFor example, if $M$ is a 3-dimensional manifold, there is ambiguity in treating the vector $T_{p}M \\approxeq \\mathbb{R}^{3}$ represented from $\\begin{bmatrix} 1 \u0026amp; 1 \u0026amp; 1\\end{bmatrix}^{T}$ and the vector $X_{p}$ represented from $T_{q}M \\approxeq \\mathbb{R}^{3}$ as the same. Therefore, defining $\\begin{bmatrix} 1 \u0026amp; 1 \u0026amp; 1\\end{bmatrix}^{T}$ as a set of ordered pairs is to make clear that $X_{q}$ and $TM$ are not the same and are distinctly different. From this, it naturally leads to considering a bijective function like $X_{p}$, treating it as $X_{q}$.\nIn some textbooks, to avoid this detailed explanation or assuming that readers adequately understand, the tangent bundle $\\iota_{p} : (p, X_{p}) \\mapsto X_{p}$ is sometimes defined as follows.\n$$ TM := \\bigcup\\limits_{p\\in M} T_{p}M = \\left\\{ X_{p} \\in T_{p}M : \\forall p \\in M \\right\\} $$\nOf course, as reiterated, the above definition and $(p, X_{p}) \\approx X_{p}$ are essentially the same. Also, note that the function value of $TM$ according to the above definition is a function $(1)$.\n$$ X_{p} : \\mathcal{D} \\to \\mathbb{R} $$\nVector Field as an Operator Let\u0026rsquo;s say $X$ is an $X_{p}$-dimensional differential manifold. Let the set of differentiable functions on $M$ be called $n$.\n$$ \\mathcal{D} = \\mathcal{D}(M) := \\left\\{ \\text{all real-valued functions of class } C^{\\infty} \\text{ defined on } M \\right\\} $$\nSee Also Set of differentiable functions on a differential manifold $M$ Set of differentiable vector fields on a differential manifold $\\mathcal{D} = \\mathcal{D}(M)$ Manfredo P. Do Carmo, Riemannian Geometry (Eng Edition, 1992), p25-27\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3270,"permalink":"https://freshrimpsushi.github.io/en/posts/3270/","tags":null,"title":"Vector Field on Differentiable Manifold"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code using DataFrames\rUnit1 = DataFrame(\rmember = [\u0026#34;Îã§ÏòÅ\u0026#34;,\u0026#34;Î£®Îã§\u0026#34;,\u0026#34;ÏàòÎπà\u0026#34;,\u0026#34;ÏßÑÏàô\u0026#34;],\rbirth = [99,97,96,99],\rheight = [161,157,159,162]\r)\rUnit2 = DataFrame(\rmember = [\u0026#34;ÏÜåÏ†ï\u0026#34;,\u0026#34;Ï£ºÏó∞\u0026#34;,\u0026#34;ÏßÄÏó∞\u0026#34;,\u0026#34;ÌòÑÏ†ï\u0026#34;],\rbirth = [95,98,95,94],\rheight = [166,172,163,165]\r)\rWJSN = vcat(Unit1, Unit2)\rpush!(WJSN, [\u0026#34;Îã§Ïõê\u0026#34;,97,167])\rpush!(WJSN, [\u0026#34;Ïó∞Ï†ï\u0026#34;,99,165])\rsort(WJSN, 3)\rsort(WJSN, :birth)\rsort(WJSN, [:birth, :height])\rsort(WJSN, :birth, rev = true) Let\u0026rsquo;s run the example code above and check the results.\njulia\u0026gt; WJSN\r10√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161\r2 ‚îÇ Î£®Îã§ 97 157\r3 ‚îÇ ÏàòÎπà 96 159\r4 ‚îÇ ÏßÑÏàô 99 162\r5 ‚îÇ ÏÜåÏ†ï 95 166\r6 ‚îÇ Ï£ºÏó∞ 98 172\r7 ‚îÇ ÏßÄÏó∞ 95 163\r8 ‚îÇ ÌòÑÏ†ï 94 165\r9 ‚îÇ Îã§Ïõê 97 167\r10 ‚îÇ Ïó∞Ï†ï 99 165 The WJSN dataframe looks like the above.\nSort by Column Number sort(df, cols::integer) Sorts based on the colsth column.\njulia\u0026gt; sort(WJSN, 3)\r10√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Î£®Îã§ 97 157\r2 ‚îÇ ÏàòÎπà 96 159\r3 ‚îÇ Îã§ÏòÅ 99 161\r4 ‚îÇ ÏßÑÏàô 99 162\r5 ‚îÇ ÏßÄÏó∞ 95 163\r6 ‚îÇ ÌòÑÏ†ï 94 165\r7 ‚îÇ Ïó∞Ï†ï 99 165\r8 ‚îÇ ÏÜåÏ†ï 95 166\r9 ‚îÇ Îã§Ïõê 97 167\r10 ‚îÇ Ï£ºÏó∞ 98 172 You can see that it is sorted based on the 3rd column, which is height.\nSort by Column Name sort(df, cols::Symbol) Sorts based on the column named by the symbol cols.\njulia\u0026gt; sort(WJSN, :birth)\r10√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÌòÑÏ†ï 94 165\r2 ‚îÇ ÏÜåÏ†ï 95 166\r3 ‚îÇ ÏßÄÏó∞ 95 163\r4 ‚îÇ ÏàòÎπà 96 159\r5 ‚îÇ Î£®Îã§ 97 157\r6 ‚îÇ Îã§Ïõê 97 167\r7 ‚îÇ Ï£ºÏó∞ 98 172\r8 ‚îÇ Îã§ÏòÅ 99 161\r9 ‚îÇ ÏßÑÏàô 99 162\r10 ‚îÇ Ïó∞Ï†ï 99 165 It is sorted based on :birth, which means the sorting criterion was birth.\nSorting Priority sort(df, cols::Array) Sorts according to the order of cols, assigning priority.\njulia\u0026gt; sort(WJSN, [:birth, :height])\r10√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÌòÑÏ†ï 94 165\r2 ‚îÇ ÏßÄÏó∞ 95 163\r3 ‚îÇ ÏÜåÏ†ï 95 166\r4 ‚îÇ ÏàòÎπà 96 159\r5 ‚îÇ Î£®Îã§ 97 157\r6 ‚îÇ Îã§Ïõê 97 167\r7 ‚îÇ Ï£ºÏó∞ 98 172\r8 ‚îÇ Îã§ÏòÅ 99 161\r9 ‚îÇ ÏßÑÏàô 99 162\r10 ‚îÇ Ïó∞Ï†ï 99 165 It is sorted by birth, but height is also considered. Compared to just sorting by birth, rows 2 and 3 have been reversed.\nSort in Reverse Order sort(df, rev::Bool=false) Set rev = true to sort in reverse order. The default value is false.\njulia\u0026gt; sort(WJSN, :birth, rev = true)\r10√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161\r2 ‚îÇ ÏßÑÏàô 99 162\r3 ‚îÇ Ïó∞Ï†ï 99 165\r4 ‚îÇ Ï£ºÏó∞ 98 172\r5 ‚îÇ Î£®Îã§ 97 157\r6 ‚îÇ Îã§Ïõê 97 167\r7 ‚îÇ ÏàòÎπà 96 159\r8 ‚îÇ ÏÜåÏ†ï 95 166\r9 ‚îÇ ÏßÄÏó∞ 95 163\r10 ‚îÇ ÌòÑÏ†ï 94 165 Environment OS: Windows julia: v1.6.3 ","id":2238,"permalink":"https://freshrimpsushi.github.io/en/posts/2238/","tags":null,"title":"How to Sort Dataframe in julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 Let\u0026rsquo;s call a $M$ a $n$-dimensional differentiable manifold. Let\u0026rsquo;s denote the tangent space at point $p \\in M$ as $T_{p}M$. The tangent bundle $TM$ of $M$ is defined as follows.\n$$ \\begin{align*} TM \u0026amp;:= \\bigsqcup \\limits_{p \\in M } T_{p}M \\\\ \u0026amp;= \\bigcup_{p \\in M} \\left\\{ p \\right\\} \\times T_{p}M \\\\ \u0026amp;= \\left\\{ (p, v) : p \\in M, v \\in T_{p}M \\right\\} \\end{align*} $$\nHere, $\\bigsqcup$ is a disjoint union.\nExplanation By definition, the tangent bundle is a set of all ordered pairs of all points on the differentiable manifold $M$ and all tangent vectors at those points. As can be seen in the disjoint union document, it\u0026rsquo;s possible to consider a natural mapping between $(p,v)$ and $v$, effectively treating them as the same thing, thus sometimes $\\bigsqcup$ is replaced by $\\bigcup$.\n$$ TM := \\bigcup_{p \\in M} T_{p}M $$\nIf $M$ is a $n$-dimensional differentiable manifold, then $TM$ itself becomes a $2n$-dimensional differentiable manifold again.\nManfredo P. Do Carmo, Riemannian Geometry (Eng Edition, 1992), p15-16\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3268,"permalink":"https://freshrimpsushi.github.io/en/posts/3268/","tags":null,"title":"Tangent Bundles on Differentiable Manifolds"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code using DataFrames\rUnit1 = DataFrame(\rmember = [\u0026#34;Îã§ÏòÅ\u0026#34;,\u0026#34;Î£®Îã§\u0026#34;,\u0026#34;ÏàòÎπà\u0026#34;,\u0026#34;ÏßÑÏàô\u0026#34;],\rbirth = [99,97,96,99],\rheight = [161,157,159,162]\r)\rUnit2 = DataFrame(\rmember = [\u0026#34;ÏÜåÏ†ï\u0026#34;,\u0026#34;Ï£ºÏó∞\u0026#34;,\u0026#34;ÏßÄÏó∞\u0026#34;,\u0026#34;ÌòÑÏ†ï\u0026#34;],\rbirth = [95,98,95,94],\rheight = [166,172,163,165]\r)\rWJSN = vcat(Unit1, Unit2)\rpush!(WJSN, [\u0026#34;Îã§Ïõê\u0026#34;,97,167])\rpush!(WJSN, [\u0026#34;Ïó∞Ï†ï\u0026#34;,99,165]) Let\u0026rsquo;s run the example code above and check the result.\nConcatenating Rows of Two Data Frames with vcat() julia\u0026gt; Unit1 = DataFrame(\rmember = [\u0026#34;Îã§ÏòÅ\u0026#34;,\u0026#34;Î£®Îã§\u0026#34;,\u0026#34;ÏàòÎπà\u0026#34;,\u0026#34;ÏßÑÏàô\u0026#34;],\rbirth = [99,97,96,99],\rheight = [161,157,159,162]\r)\r4√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161 2 ‚îÇ Î£®Îã§ 97 157 3 ‚îÇ ÏàòÎπà 96 159 4 ‚îÇ ÏßÑÏàô 99 162 julia\u0026gt; Unit2 = DataFrame(\rmember = [\u0026#34;ÏÜåÏ†ï\u0026#34;,\u0026#34;Ï£ºÏó∞\u0026#34;,\u0026#34;ÏßÄÏó∞\u0026#34;,\u0026#34;ÌòÑÏ†ï\u0026#34;],\rbirth = [95,98,95,94],\rheight = [166,172,163,165]\r)\r4√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ ÏÜåÏ†ï 95 166\r2 ‚îÇ Ï£ºÏó∞ 98 172\r3 ‚îÇ ÏßÄÏó∞ 95 163\r4 ‚îÇ ÌòÑÏ†ï 94 165\rjulia\u0026gt; WJSN = vcat(Unit1, Unit2)\r8√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161\r2 ‚îÇ Î£®Îã§ 97 157\r3 ‚îÇ ÏàòÎπà 96 159\r4 ‚îÇ ÏßÑÏàô 99 162\r5 ‚îÇ ÏÜåÏ†ï 95 166\r6 ‚îÇ Ï£ºÏó∞ 98 172\r7 ‚îÇ ÏßÄÏó∞ 95 163\r8 ‚îÇ ÌòÑÏ†ï 94 165 Of course, the columns of the two data frames must be the same.\nInserting a Row with push!() julia\u0026gt; push!(WJSN, [\u0026#34;Îã§Ïõê\u0026#34;,97,167])\r9√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161\r2 ‚îÇ Î£®Îã§ 97 157\r3 ‚îÇ ÏàòÎπà 96 159\r4 ‚îÇ ÏßÑÏàô 99 162\r5 ‚îÇ ÏÜåÏ†ï 95 166\r6 ‚îÇ Ï£ºÏó∞ 98 172\r7 ‚îÇ ÏßÄÏó∞ 95 163\r8 ‚îÇ ÌòÑÏ†ï 94 165\r9 ‚îÇ Îã§Ïõê 97 167\rjulia\u0026gt; push!(WJSN, [\u0026#34;Ïó∞Ï†ï\u0026#34;,99,165])\r10√ó3 DataFrame\rRow ‚îÇ member birth height ‚îÇ String Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Îã§ÏòÅ 99 161\r2 ‚îÇ Î£®Îã§ 97 157\r3 ‚îÇ ÏàòÎπà 96 159\r4 ‚îÇ ÏßÑÏàô 99 162\r5 ‚îÇ ÏÜåÏ†ï 95 166\r6 ‚îÇ Ï£ºÏó∞ 98 172\r7 ‚îÇ ÏßÄÏó∞ 95 163\r8 ‚îÇ ÌòÑÏ†ï 94 165\r9 ‚îÇ Îã§Ïõê 97 167\r10 ‚îÇ Ïó∞Ï†ï 99 165 When adding data with push!(), you must provide an array that matches the number of columns.\nEnvironment OS: Windows julia: v1.6.2 ","id":2236,"permalink":"https://freshrimpsushi.github.io/en/posts/2236/","tags":null,"title":"Inserting a New Row into a DataFrame in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Infinities.jl is a package that aids in using infinity symbols in Julia1. Surprisingly, infinity is quite useful in scientific computing coding.\nCode julia\u0026gt; 8 \u0026lt; Inf\rtrue The reason it\u0026rsquo;s mentioned that it helps in using infinity symbols, not just infinity, in the introduction is that you can actually use them without the package.\njulia\u0026gt; using Infinities\rjulia\u0026gt; 8 \u0026lt; ‚àû\rtrue\rjulia\u0026gt; -‚àû \u0026lt; 8\rtrue\rjulia\u0026gt; max(‚àû, 10, 11)\r‚àû\rjulia\u0026gt; sin(‚àû)\rERROR: MethodError: no method matching AbstractFloat(::Infinities.Infinity) As you can see, it possesses all the expected properties of infinity.\njulia\u0026gt; ‚Ñµ‚ÇÄ \u0026lt; ‚Ñµ‚ÇÅ\rtrue\rjulia\u0026gt; ‚Ñµ‚ÇÄ \u0026gt; ‚Ñµ‚ÇÅ\rfalse\rjulia\u0026gt; ‚àû == ‚Ñµ‚ÇÅ\rfalse\rjulia\u0026gt; ‚àû == ‚Ñµ‚ÇÄ\rtrue\rjulia\u0026gt; ‚àû === ‚Ñµ‚ÇÄ\rfalse Moreover, it allows the use of the cardinality of infinite sets with $\\aleph_{0}$ and $\\aleph_{1}$, which makes it possible to have the same infinity in terms of computation but still give them an order for sorting or comparison.\nEnvironment OS: Windows julia: v1.6.2 https://github.com/JuliaMath/Infinities.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2234,"permalink":"https://freshrimpsushi.github.io/en/posts/2234/","tags":null,"title":"Using Infinity in Julia"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 Consider the following linear system for matrix $A$:\n$$ A \\mathbf{x} = \\mathbf{b} $$\nIf $m \\gt n$, then there are more constraints than unknowns, and such a linear system is called an overdetermined system.\nIf $m \\lt n$, then there are less constraints than unknowns, and such a linear system is called an underdetermined system.\nTheorem 1 Consider the linear system for matrix $A$ with rank $r$ of $m \\times n$.\n$$ A \\mathbf{x} = \\mathbf{b} $$\nThe general solution of the above linear system has $n-r$ parameters.\nProof Dimension Theorem\n$$ \\rank(A) + \\nullity(A) = \\dim(A) $$\nFirst, by the dimension theorem, $\\nullity(A) = n-r$. Then, from the following theorem, the number of parameters equals the number of nullities.\nLet $\\mathbf{x}_{0}$ be any solution of $A\\mathbf{x} = \\mathbf{b}$. Let $S= \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{k} \\right\\}$ be the basis of $\\mathcal{N}(A)$. Then, every solution of $A\\mathbf{x} = \\mathbf{b}$ can be expressed as follows:\n$$ \\mathbf{x} = \\mathbf{x}_{0} + c_{1}\\mathbf{v}_{1} + c_{2}\\mathbf{v}_{2} + \\cdots + c_{k}\\mathbf{v}_{k} $$\nThis means that the number of parameters is equal to $\\nullity(A)$.\n‚ñ†\nTheorem 2 Consider the following linear system for matrix $A$:\n$$ A \\mathbf{x} = \\mathbf{b} $$\nOverdetermined\nIf the linear system is overdetermined, i.e., $m \\gt n$, then the linear system doesn\u0026rsquo;t have a solution for at least one vector $\\mathbf{b}$ in $\\mathbb{R}^{m}$, meaning it doesn\u0026rsquo;t have a general solution.\nUnderdetermined\nIf the linear system is underdetermined, i.e., $m \\lt n$, then the linear system either has no solution for all vectors $\\mathbf{b}$ in $\\mathbb{R}^{m}$ or has infinitely many solutions.\nProof Overdetermined\nIf $m \\gt n$, the column vectors of $A$ are in number $n$, so $\\mathbb{R}^{m}$ cannot be spanned (since the number of vectors is less than the number of dimensions). Therefore, there exists at least one vector $\\mathbf{b}$ that does not belong to the column space of $A$.\nAuxiliary Theorem\nThe necessary and sufficient condition for the linear system $A \\mathbf{x} = \\mathbf{b}$ to have a solution is that $\\mathbf{b}$ is an element of the column space of $A$.\nAccording to the auxiliary theorem, $A \\mathbf{x} = \\mathbf{b}$ does not have a solution.\nUnderdetermined\nAssume $m \\lt n$.\nIf there is no solution\nThen the proof is complete.\nIf there is a solution\nIf there is a solution, then by Theorem 1, the general solution has $n-r$ parameters. $r = \\rank (A)$ is at most the lesser of $m$ and $n$.\n$$ n-r \\le n-m \u0026gt; 0 $$\nThis implies that the general solution of the linear system has more than one parameter, meaning that if there is a solution, it is infinitely many.\n‚ñ†\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p259\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3265,"permalink":"https://freshrimpsushi.github.io/en/posts/3265/","tags":null,"title":"Supersaturated and Undersaturated Systems"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide 1 (@v1.6) pkg\u0026gt; status JuMP Status `C:\\Users\\rmsms\\.julia\\environments\\v1.6\\Project.toml` [4076af6c] JuMP v0.20.0 By pressing the ] key in the REPL, you enter the package mode. For example, if you want to upgrade a package version from v0.20.0 to v0.21, you can do so by appending @x.yy to the package as follows.\n(@v1.6) pkg\u0026gt; add JuMP@0.21 Resolving package versions... ... (@v1.6) pkg\u0026gt; status JuMP Status `C:\\Users\\rmsms\\.julia\\environments\\v1.6\\Project.toml` [4076af6c] JuMP v0.21.4 If you check the version again, you can verify that the package version has been successfully updated.\nEnvironment OS: Windows julia: v1.6.2 https://pkgdocs.julialang.org/dev/api/#General-API-Reference\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2232,"permalink":"https://freshrimpsushi.github.io/en/posts/2232/","tags":null,"title":"How to Install a Specific Version of a Package in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Overview We define the pullback on a differential manifold. If differential manifolds are complex, one can think of $M = \\mathbb{R}^{m}$ and $N = \\mathbb{R}^{n}$.\nDefinition1 Given two differential manifolds $M, N$ and a differentiable function $f : M \\to N$, we can consider a function $f^{\\ast}$ that maps $N$\u0026rsquo;s $k$-forms to $M$\u0026rsquo;s $k$-forms. Let $\\omega$ be a $k$-form on the manifold $N$, then a $k$-form $f^{\\ast}\\omega$ on the manifold $M$ is defined as the pullback of $\\omega$ as follows.\n$$ \\begin{equation} (f^{\\ast}\\omega)(p) (v_{1}, \\dots, v_{k}) := \\omega (f(p))\\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right),\\quad v_{i} \\in T_{p}M \\end{equation} $$\nExplanation The name pullback implies that, contrary to $f$ mapping from $M$ to $N$, $f^{\\ast}$ maps from $N$ to $M$. The definition and notation are quite complex, so let\u0026rsquo;s understand them step by step.\n$f^{\\ast}$ $f^{\\ast}$ is a map that sends $k$-forms of $N$ to $k$-forms of $M. Therefore, if $\\omega$ is a $k$-form of $N$, then $f^{\\ast}\\omega = f^{\\ast}(\\omega)$ is a $k$-form of $M.\n$f^{\\ast}\\omega (p)$ A $k$-form on the manifold $M$ maps $p \\in M$ to an element of $\\Lambda^{k}(T_{p}^{\\ast}M)$.\n$$ f^{\\ast}\\omega : M \\to \\Lambda^{k}(T_{p}^{\\ast}M) $$\n$$ \\Lambda^{k} (T_{p}^{\\ast}M) := \\left\\{ \\varphi : \\underbrace{T_{p}M \\times \\cdots \\times T_{p}M}_{k \\text{ times}} \\to \\mathbb{R}\\ | \\ \\varphi \\text{ is k-linear alternating map} \\right\\} $$\nIn other words, $f^{\\ast}\\omega (p) \\in \\Lambda^{k} (T_{p}^{\\ast}M)$ is also a function. By the definition of $\\Lambda^{k} (T_{p}^{\\ast}M)$, $f^{\\ast}\\omega (p)$ takes \u0026ldquo;$k$ tangent vectors at $p$\u0026rdquo; as variables. Thus, $(1)$ is the expression that specifically defines this function\u0026rsquo;s value. To emphasize that $f^{\\ast}(p)$ itself is a function, let\u0026rsquo;s use the following notation.\n$$ (f^{\\ast}\\omega)_{p} = f^{\\ast}\\omega (p) $$\n$\\omega (f(p))$ Since $\\omega$ is a $k$-form of $N$, it maps the point $f(p)$ of $N$ to an element of $\\Lambda^{k}(T_{f(p)}^{\\ast}N)$.\n$$ \\Lambda^{k} (T_{f(p)}^{\\ast}N) := \\left\\{ \\varphi : \\underbrace{T_{f(p)}N \\times \\cdots \\times T_{f(p)}N}_{k \\text{ times}} \\to \\mathbb{R}\\ | \\ \\varphi \\text{ is k-linear alternating map} \\right\\} $$\nBy the definition of $\\Lambda^{k} (T_{f(p)}^{\\ast}N)$, $\\omega (f(p))$ is also a function. $\\omega (f(p))$ takes \u0026ldquo;$k$ tangent vectors at $f(p)$\u0026rdquo; as variables. Here too, to emphasize that $\\omega (f(p))$ itself is a function, let\u0026rsquo;s use the following notation.\n$$ \\omega_{f(p)} = \\omega (f(p)) $$\n$df_{p}v_{i}$ $$ df_{p} : T_{p}M \\to T_{f(p)}N $$\nFor $f : M \\to N$, the differential $df_{p}$ of $f$ is defined as above. Therefore, if $v_{i} \\in T_{p}M$, then $df_{p}v_{i} = df_{p}(v_{i})$ is an element of $T_{f(p)}N$.\nNow, combining these, we obtain $(1)$.\n$$ (f^{\\ast}\\omega)_{p} (v_{1}, \\dots, v_{k}) := \\omega_{f(p)}\\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right),\\quad v_{i} \\in T_{p}M $$\nThe domains of these two functions show the following difference.\n$$ \\begin{align*} (f^{\\ast}\\omega)_{p} : \u0026amp;\u0026amp; \\underbrace{T_{p}M \\times \\cdots \\times T_{p}M}_{k \\text{ times}} \u0026amp;\\to \\mathbb{R} \\\\ \\omega_{f(p)} : \u0026amp;\u0026amp; \\underbrace{T_{f(p)}N \\times \\cdots \\times T_{f(p)}N}_{k \\text{ times}} \u0026amp;\\to \\mathbb{R} \\end{align*} $$\nThink of the differential $df_{p} : T_{p}M \\to T_{f(p)}N$ as bridging this difference. Hence, $df_{p}$ is also called push forward. For a $1$-form $\\varphi$, the following holds true.\n$$ \\begin{equation} \\varphi( dfv) = f^{\\ast}\\varphi(v) \\end{equation} $$\nPullback of $0$-forms Let\u0026rsquo;s consider $f : M \\to N$ as a function defined between two differential manifolds. Let $g : N \\to \\mathbb{R}$ be a function (a $0$-form of $N$). The pullback $f^{\\ast}g : M \\to \\mathbb{R}$ is defined as the following function (a $0$-form of $M$).\n$$ f^{\\ast}g := g \\circ f $$\nCoordinate Transformation Let\u0026rsquo;s assume a function $f : \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$ is given. Let $\\mathbf{x} = (x_{1}, \\dots ,x_{n}) \\in \\mathbb{R}^{n}$, and $\\mathbf{y} = (y_{1}, \\dots ,y_{m}) \\in \\mathbb{R}^{m}$.\n$$ f(x_{1}, \\dots, x_{n}) = (f_{1}(\\mathbf{x}), \\dots, f_{m}(\\mathbf{x}) )= (y_{1}, \\dots ,y_{m}) $$\nAnd let $\\omega = \\sum\\limits_{I} a_{I} dy_{I}$ be a $k$-form on $\\mathbb{R}^{m}$. Then the pullback $f^{\\ast}\\omega$ is as follows, based on these properties.\n$$ \\begin{align*} f^{\\ast} \\omega \u0026amp;= f^{\\ast} \\left( \\sum a_{I}dy_{I} \\right) \\\\ \u0026amp;= \\sum f^{\\ast} \\left( a_{I}dy_{I} \\right) \\\\ \u0026amp;= \\sum f^{\\ast}a_{I} f^{\\ast}dy_{I} \\\\ \u0026amp;= \\sum f^{\\ast}a_{I} f^{\\ast}(dy_{i1} \\wedge \\cdots \\wedge dy_{ik}) \\\\ \u0026amp;= \\sum f^{\\ast}a_{I} (f^{\\ast}dy_{i1} \\wedge \\cdots \\wedge f^{\\ast}dy_{ik}) \\end{align*} $$\nHere, due to $(2)$, $f^{\\ast}dy_{i1}(v) = dy_{i1}(df(v)) = d(y_{i1}\\circ f)(v) = df_{i1}(v)$, and $f^{\\ast}a_{I} = a_{I} \\circ f$, so,\n$$ \\begin{equation} f^{\\ast} \\omega = \\sum a_{I}(f_{1}, \\dots f_{m}) df_{i1} \\wedge \\cdots \\wedge df_{ik} \\end{equation} $$\nThis formula signifies coordinate transformation. Let\u0026rsquo;s see how it specifically works in the following example.\nExample Let\u0026rsquo;s assume a $1$-form $\\omega$ on $\\mathbb{R}^{2} \\setminus \\left\\{ 0, 0 \\right\\}$ is as follows.\n$$ \\omega = - \\dfrac{y}{x^{2} + y^{2}}dx + \\dfrac{x}{x^{2} + y^{2}}dy = a_{1}dx + a_{2}dy $$\nLet\u0026rsquo;s transform this $1$-form in Cartesian coordinates to polar coordinates. Let $U = \\left\\{ (r,\\theta) : 0 \\lt r, 0 \\le \\theta \\lt 2\\pi \\right\\}$. And let $f : U \\to \\mathbb{R}^{2}$ be as follows.\n$$ f(r,\\theta) = (r\\cos\\theta, r\\sin\\theta) = (f_{1}, f_{2}) $$\nNow, let\u0026rsquo;s calculate $df_{1}, df_{2}$. Since $f_{1} = r\\cos\\theta, f_{2}=r\\sin\\theta$,\n$$ \\begin{align*} df_{1} \u0026amp;= \\dfrac{\\partial f_{1}}{\\partial r}dr + \\dfrac{\\partial f_{1}}{\\partial \\theta}d\\theta = \\cos\\theta dr - r \\sin \\theta d\\theta \\\\ df_{2} \u0026amp;= \\dfrac{\\partial f_{2}}{\\partial r}dr + \\dfrac{\\partial f_{2}}{\\partial \\theta}d\\theta = \\sin\\theta dr + r \\cos \\theta d\\theta \\\\ \\end{align*} $$\nThen, by $(3)$,\n$$ \\begin{align*} f^{\\ast} \\omega \u0026amp;= a_{1}(f_{1}, f_{2})df_{1} + a_{2}(f_{1}, f_{2})df_{2} \\\\ \u0026amp;= - \\dfrac{f_{2}}{f_{1}^{2} + f_{2}^{2}}(\\cos\\theta dr - r \\sin \\theta d\\theta) + \\dfrac{f_{1}}{f_{1}^{2} + f_{2}^{2}}df_{2}(\\sin\\theta dr + r \\cos \\theta d\\theta) \\\\ \u0026amp;= - \\dfrac{r\\sin\\theta}{r^{2}\\cos^{2}\\theta + r^{2}\\sin^{2}\\theta}(\\cos\\theta dr - r \\sin \\theta d\\theta) \\\\ \u0026amp;\\quad + \\dfrac{r\\cos\\theta}{r^{2}\\cos^{2}\\theta + r^{2}\\sin^{2}\\theta}(\\sin\\theta dr + r \\cos \\theta d\\theta) \\\\ \u0026amp;= -\\dfrac{\\sin\\theta \\cos\\theta}{r}dr + \\sin^{2}\\theta d\\theta + \\dfrac{\\cos\\theta \\sin\\theta}{r}dr + \\cos^{2}\\theta d\\theta \\\\ \u0026amp;= d\\theta \\end{align*} $$\nTherefore,\n$$ \\int - \\dfrac{y}{x^{2} + y^{2}}dx + \\dfrac{x}{x^{2} + y^{2}}dy = \\int d\\theta $$\n‚ñ†\nProperties Let $M, N$ be differential manifolds of dimensions $m, n$ respectively, and let $f : M \\to N$. Let $\\omega, \\varphi$ be $k$-forms on $N$. Let $g$ be a $0$-form on $N$. Let $\\varphi_{i}$s be $1$-forms on $N. Then, the following hold true.\n$$ \\begin{align} f^{\\ast} (\\omega + \\varphi) =\u0026amp;\\ f^{\\ast}\\omega + f^{\\ast}\\varphi \\tag{a} \\\\ f^{\\ast} (g \\omega) =\u0026amp;\\ (f^{\\ast}g) (f^{\\ast}\\omega) \\tag{b} \\\\ f^{\\ast} (\\varphi_{1} \\wedge \\cdots \\wedge \\varphi_{k}) =\u0026amp;\\ f^{\\ast}(\\varphi_{1}) \\wedge \\cdots \\wedge f^{\\ast}(\\varphi_{k}) \\tag{c} \\end{align} $$\nHere, $+$ and $\\wedge$ represent the sum and wedge product of $k$-forms, respectively.\nLet $\\omega, \\varphi$ be arbitrary forms on $N. Let $L$ be a $l$-dimensional differential manifold, and let $g : L \\to N$.\n$$ \\begin{align*} f^{\\ast}(\\omega \\wedge \\varphi) \u0026amp;= (f^{\\ast}\\omega) \\wedge (f^{\\ast}\\varphi) \\tag{d} \\\\ (f \\circ g)^{\\ast} \\omega \u0026amp;= g^{\\ast}(f^{\\ast}\\omega) \\tag{e} \\end{align*} $$\nProof Proof $(a)$ $$ \\begin{align*} (f^{\\ast}(\\omega + \\varphi))_{p} (v_{1}, \\dots, v_{k}) =\u0026amp;\\ (\\omega + \\varphi)_{f(p)} \\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right) \\\\ =\u0026amp;\\ \\omega_{f(p)} \\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right) + \\varphi_{f(p)} \\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right) \\\\ =\u0026amp;\\ (f^{\\ast} \\omega)_{p}(v_{1}, \\dots, v_{k}) + (f^{\\ast} \\varphi)_{p}(v_{1}, \\dots, v_{k}) \\\\ =\u0026amp;\\ \\left( f^{\\ast}\\omega + f^{\\ast}\\varphi \\right)_{p}(v_{1}, \\dots, v_{k}) \\end{align*} $$\n‚ñ†\nProof $(b)$ Let\u0026rsquo;s define the product of a $0$-form $g$ and a $k$-form $\\omega$ as follows.\n$$ (g\\omega)(p) = g(p) \\omega (p) $$\nNote that $g(p) = g_{p}$ is a scalar, and $\\omega (p) = \\omega_{p}$ is a function. Then,\n$$ \\begin{align*} (f^{\\ast} (g\\omega))_{p} (v_{1}, \\dots, v_{k}) =\u0026amp;\\ g\\omega_{f(p)} \\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right) \\\\ =\u0026amp;\\ g_{f(p)} \\omega_{f(p)} (df_{p}v_{1}, \\dots, df_{p}v_{k}) \\\\ =\u0026amp;\\ g\\circ f(p) \\omega_{f(p)} (df_{p}v_{1}, \\dots, df_{p}v_{k}) \\\\ =\u0026amp;\\ (f^{\\ast}g)_{p} (f^{\\ast}\\omega)_{p} (v_{1}, \\dots, v_{k}) \\end{align*} $$\n‚ñ†\nProof $(c)$ $$ \\begin{align*} (f^{\\ast}\\left( \\varphi_{1} \\wedge \\cdots \\wedge \\varphi_{k} \\right))_{p} (v_{1}, \\dots, v_{k}) =\u0026amp;\\ (\\varphi_{1} \\wedge \\dots \\wedge \\varphi_{k})_{f(p)} \\left( df_{1}, \\dots, df_{k} \\right) \\\\ =\u0026amp;\\ \\det [\\varphi_{i}df(v_{j})] \\\\ =\u0026amp;\\ \\det [ f^{\\ast} \\varphi_{i}(v_{j})] \\\\ \\end{align*} $$\n‚ñ†\nManfredo P. Do Carmo, Differential Forms and Applications, p6-8\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3262,"permalink":"https://freshrimpsushi.github.io/en/posts/3262/","tags":null,"title":"Pull Back in Differential Geometry"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Despite many languages supporting dataframes, surprisingly, creating empty arrays can be a new and annoying task each time.\nCode Type Specification julia\u0026gt; using DataFrames\rjulia\u0026gt; df1 = DataFrame(x = Int64[], y = String[])\r0√ó2 DataFrame You actually just need to insert an empty array as data. At this point, a type is specified, but when there\u0026rsquo;s absolutely no data, neither column names nor types are visible.\njulia\u0026gt; push!(df1, [3, \u0026#34;three\u0026#34;])\r1√ó2 DataFrame\r‚îÇ Row ‚îÇ x ‚îÇ y ‚îÇ\r‚îÇ ‚îÇ Int64 ‚îÇ String ‚îÇ\r‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\r‚îÇ 1 ‚îÇ 3 ‚îÇ three ‚îÇ\rjulia\u0026gt; push!(df1, [3.14, \u0026#34;pi\u0026#34;])\r‚îå Error: Error adding value to column :x.\r‚îî @ DataFrames C:\\Users\\rmsms\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:1606\rERROR: InexactError: Int64(3.14) Once data is inserted, column names and types are displayed correctly. Be careful, as data will not be added if the type does not match.\nWithout Type Specification julia\u0026gt; df2 = DataFrame(x = [], y = String[])\r0√ó2 DataFrame\rjulia\u0026gt; push!(df2, [3, \u0026#34;three\u0026#34;])\r1√ó2 DataFrame\r‚îÇ Row ‚îÇ x ‚îÇ y ‚îÇ\r‚îÇ ‚îÇ Any ‚îÇ String ‚îÇ\r‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\r‚îÇ 1 ‚îÇ 3 ‚îÇ three ‚îÇ\rjulia\u0026gt; push!(df2, [3.14, \u0026#34;pi\u0026#34;])\r2√ó2 DataFrame\r‚îÇ Row ‚îÇ x ‚îÇ y ‚îÇ\r‚îÇ ‚îÇ Any ‚îÇ String ‚îÇ\r‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\r‚îÇ 1 ‚îÇ 3 ‚îÇ three ‚îÇ\r‚îÇ 2 ‚îÇ 3.14 ‚îÇ pi ‚îÇ If you don\u0026rsquo;t want to stress about the type of the dataframe, you can simply create an empty array of Any as shown above. Unlike when specifying types, you can see that the data is well inserted.\nEnvironment OS: Windows julia: v1.6.2 ","id":2230,"permalink":"https://freshrimpsushi.github.io/en/posts/2230/","tags":null,"title":"How to Make Empty DataFrame in julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition 1 The convex hull $C$ of a subset $X$ of a vector space $V$ refers to the intersection of all convex sets that contain $X$, and is mathematically defined as follows. $$ C = \\left\\{ \\sum_{k} t_{k} \\mathbf{x}_{k} : \\mathbf{x}_{k} \\in X, t_{k} \\ge 0 , \\sum_{k} t_{k} = 1 \\right\\} $$\nExplanation The equation mentioned in the definition isn\u0026rsquo;t exactly a definition per se. The expression $$ \\sum_{k} t_{k} \\mathbf{x}_{k} $$ written in set-builder notation within the set symbols, is called the convex combination of $\\left\\{ \\mathbf{x}_{k} \\right\\}_{k}$.\nThough it may sound complicated, it\u0026rsquo;s quite simple when seen through diagrams2, and the term convex hull is not so much important in itself but rather suddenly appears in contexts where one wishes to easily handle spaces in geometry, optimization theory, topological data analysis, etc.\nThe convex hull illustrated is really simple. It is the smallest convex set that encloses all points of $X$. The reason why it talks about the intersection of all convex sets in a mathematical sense is because expressions like \u0026lsquo;size\u0026rsquo; being \u0026lsquo;small\u0026rsquo; are not really intuitive in mathematics.\nMatousek. (2007). Understanding and Using Linear Programming: p49.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSheffar. (2020). Introductory Topological Data Analysis. https://arxiv.org/abs/2004.04108v1\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2228,"permalink":"https://freshrimpsushi.github.io/en/posts/2228/","tags":null,"title":"Definition of Convex Hull"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Explanation Use the hclust() function from the Clustering.jl package.\nhclust(d::AbstractMatrix; [linkage], [uplo], [branchorder]) It takes a distance matrix as input and returns the result of hierarchical clustering. The default method for calculating distances between clusters is single linkage.\nTo plot a dendrogram, use StatsPlots.jl instead of Plots.jl.\nCode using StatsPlots using Clustering using Distances using Distributions\ra = rand(Uniform(-1,1), 2, 25)\rscatt = scatter(a[1,:], a[2,:], label=false)\rsavefig(scatt, \u0026#34;julia_hclust_scatter.png\u0026#34;) D_a = pairwise(Euclidean(), a, a)\rSL = hclust(D_a, linkage=:single)\rplot_SL = plot(SL)\rp = plot(scatt, plot_SL, size=(800,400))\rsavefig(p, \u0026#34;julia_hclust.png\u0026#34;) ","id":3259,"permalink":"https://freshrimpsushi.github.io/en/posts/3259/","tags":null,"title":"How to Perform Hierarchical Clustering in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Overview Just as we defined the second-order differential form, we generalize to define the k-th order forms on the differential manifold $M$.\nIf the concept of a differential manifold is challenging, it can be simply thought of as $M = \\mathbb{R}^{n}$.\nBuild-up Let\u0026rsquo;s say $M$ is a $n$-dimensional differential manifold. $p \\in M$ is a point in $M$, and $T_{p}M$ is the tangent space at point $p$ in $M$. $T_{p}^{\\ast}M$ is the cotangent space, which is the dual space of the tangent space. Let\u0026rsquo;s define $\\Lambda^{k} (T_{p}^{\\ast}M)$ as a set of multilinear alternating functions as follows.\n$$ \\Lambda^{k} (T_{p}^{\\ast}M) := \\left\\{ \\varphi : \\underbrace{T_{p}M \\times \\cdots \\times T_{p}M}_{k \\text{ times}} \\to \\mathbb{R}\\ | \\ \\varphi \\text{ is k-linear alternating map} \\right\\} $$\nFor $\\varphi_{1}, \\dots, \\varphi_{k} \\in T_{p}^{\\ast}M$, we define the wedge product $\\wedge$ as follows, making $(\\varphi_{1} \\wedge \\varphi_{2} \\wedge \\cdots \\wedge \\varphi_{k})$ an element of $\\Lambda^{k} (T_{p}^{\\ast}M)$.\n$$ (\\varphi_{1} \\wedge \\varphi_{2} \\wedge \\cdots \\wedge \\varphi_{k})(v_{1}, v_{2}, \\dots, v_{k}) = \\det \\left[ \\varphi_{i}(v_{j}) \\right],\\quad i,j=1,\\dots,k $$\nFor convenience, let\u0026rsquo;s denote it as follows.\n$$ (dx_{i_{1}} \\wedge dx_{i_{2}} \\wedge \\cdots \\wedge dx_{i_{k}})_{p} \\overset{\\text{notation}}{=} (dx_{i_{1}})_{p} \\wedge (dx_{i_{2}})_{p} \\wedge \\cdots \\wedge (dx_{i_{k}})_{p} \\in \\Lambda^{k} (T_{p}^{\\ast}M) $$\nAt this point, $i_{1}, i_{2}, \\dots, i_{k} = 1, \\dots, n$. Thus, $\\Lambda^{k} (T_{p}^{\\ast}M)$ becomes a vector space.\nTheorem The set below\n$$ \\mathcal{B} = \\left\\{ (dx_{i_{1}} \\wedge dx_{i_{2}} \\wedge \\cdots \\wedge dx_{i_{k}})_{p} : i_{1} \\lt i_{2} \\lt \\cdots \\lt i_{k},\\ i_{j}\\in \\left\\{ 1,\\dots,n \\right\\} \\right\\} $$\nis a basis of $\\Lambda^{k} (T_{p}^{\\ast}M)$.\nProof According to the definition of a basis, it suffices to show that $\\mathcal{B}$ is linearly independent and generates $\\Lambda^{k} (T_{p}^{\\ast}M)$. For convenience, let\u0026rsquo;s denote the basis of the tangent space $T_{p}M$ of $M$ as follows.\n$$ \\left\\{ e_{i} \\right\\} = \\left\\{ \\dfrac{\\partial }{\\partial x_{i}} \\right\\} $$ ‚Äã\nPart 1. Linear Independence\nWe only need to show that the only solution to the following equation is where all $a_{i_{1}\\dots i_{k}}$ are $0$.\n$$ \\sum \\limits_{i_{1} \\lt \\cdots \\lt i_{k} } a_{i_{1}\\dots i_{k}}dx_{i_{1}} \\wedge dx_{i_{2}} \\wedge \\cdots \\wedge dx_{i_{k}} = 0 $$\nLet\u0026rsquo;s substitute\n$$ \\left(e_{j_{1}}, \\dots, e_{j_{k}} \\right),\\quad j_{1}\\lt \\cdots \\lt j_{k},\\ j_{\\ell} \\in \\left\\{ 1,\\dots, n \\right\\} $$\ninto it.\n$$ \\begin{align*} 0 =\u0026amp;\\ \\sum \\limits_{i_{1} \\lt \\cdots \\lt i_{k} } a_{i_{1}\\dots i_{k}}dx_{i_{1}} \\wedge dx_{i_{2}} \\wedge \\cdots \\wedge dx_{i_{k}}\\left(e_{j_{1}}, \\dots, e_{j_{k}} \\right) \\\\[1em] =\u0026amp;\\ \\sum \\limits_{i_{1} \\lt \\cdots \\lt i_{k} } a_{i_{1}\\dots i_{k}} \\begin{vmatrix} dx_{i_{1}}(e_{j_{1}}) \u0026amp; dx_{i_{1}}(e_{j_{2}}) \u0026amp; \\cdots \u0026amp; dx_{i_{1}}(e_{j_{k}}) \\\\[1em] dx_{i_{2}}(e_{j_{1}}) \u0026amp; dx_{i_{2}}(e_{j_{2}}) \u0026amp; \\cdots \u0026amp; dx_{i_{2}}(e_{j_{k}}) \\\\[1em] \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1em] dx_{i_{k}}(e_{j_{1}}) \u0026amp; dx_{i_{k}}(e_{j_{2}}) \u0026amp; \\cdots \u0026amp; dx_{i_{k}}(e_{j_{k}}) \\end{vmatrix} \\end{align*} $$\nLooking at the first column of the determinant, if there\u0026rsquo;s any element that is not $0$, then $j_{1} \\in \\left\\{ i_{1}, \\dots i_{k} \\right\\}$ must be the case. Applying this condition to subsequent columns yields the following result.\n$$ j_{1}, \\dots, j_{k} \\in \\left\\{ i_{1}, \\dots i_{k} \\right\\} $$\nHowever, since there are conditions that both indices $i$ and $j$ are $i_{1}\\lt \\cdots \\lt i_{k}$, $j_{1}\\lt \\cdots \\lt j_{k}$, $i_{\\ell} = j_{\\ell}$ holds.\n$$ 0 = a_{j_{1}\\dots j_{k}} $$\nBy the same reasoning, it\u0026rsquo;s found that all coefficients $a$ must be $0$.\nPart 2. Spanning\nIf $f \\in \\Lambda^{k} (T_{p}^{\\ast}M)$, we need to show that $f$ can be expressed as a linear combination of $\\mathcal{B}$, as follows.\n$$ f = \\sum \\limits_{i_{1} \\lt \\cdots \\lt i_{k} } a_{i_{1} \\dots i_{k}} dx_{i_{1}} \\wedge dx_{i_{2}} \\wedge \\cdots \\wedge dx_{i_{k}} $$\nLet\u0026rsquo;s define $g$ as follows.\n$$ g = \\sum \\limits_{i_{1} \\lt \\cdots \\lt i_{k} } f(e_{i_{1}},\\dots,e_{i_{k}}) dx_{i_{1}} \\wedge dx_{i_{2}} \\wedge \\cdots \\wedge dx_{i_{k}} $$\nThen, it becomes clear that $g$ is $f$. After substituting $(e_{i_{1}},\\dots,e_{i_{k}})$,\n$$ \\begin{align*} g(e_{i_{1}},\\dots,e_{i_{k}}) =\u0026amp;\\ \\sum \\limits_{i_{1} \\lt \\cdots \\lt i_{k} } f(e_{i_{1}},\\dots,e_{i_{k}}) dx_{i_{1}} \\wedge dx_{i_{2}} \\wedge \\cdots \\wedge dx_{i_{k}}(e_{i_{1}},\\dots,e_{i_{k}}) \\\\ =\u0026amp;\\ f(e_{i_{1}},\\dots,e_{i_{k}}) \\end{align*} $$\nTherefore, if we let,\n$$ f = g = \\sum \\limits_{i_{1} \\lt \\cdots \\lt i_{k} } a_{i_{1} \\dots i_{k}} dx_{i_{1}} \\wedge dx_{i_{2}} \\wedge \\cdots \\wedge dx_{i_{k}} $$\n‚ñ†\nDefinition The function $\\omega : M \\to \\Lambda^{k} (T_{p}^{\\ast}M)$ that maps the point $p \\in M$ as follows is defined as the k-th order form in $M$.\n$$ \\omega (p) = \\sum \\limits_{i_{1} \\lt \\cdots \\lt i_{k} } a_{i_{1}\\dots i_{k}}(p)(dx_{i_{1}} \\wedge dx_{i_{2}} \\wedge \\cdots \\wedge dx_{i_{k}})_{p},\\quad i_{j} \\in \\left\\{ 1, \\dots, n \\right\\} $$\n$$ \\omega = \\sum \\limits_{i_{1} \\lt \\cdots \\lt i_{k} } a_{i_{1}\\dots i_{k}}dx_{i_{1}} \\wedge dx_{i_{2}} \\wedge \\cdots \\wedge dx_{i_{k}} $$\nAt this point, $a_{i_{1}\\dots i_{k}} : M \\to \\mathbb{R}$ holds. If each $a_{i_{1}\\dots i_{k}}$ is differentiable, then $\\omega$ is called a k-th order differential form. Also, for convenience, let\u0026rsquo;s denote it as $I = (i_{1},\\dots,i_{k})$ and represent it as follows.\n$$ \\omega = \\sum \\limits_{I} a_{I}dx_{I} $$\n‚ñ†\nExplanation By definition, in a $n$-dimensional manifold, there can exist forms up to the k-th order. Moreover, a k-th order form in a $n$-dimensional manifold has $\\binom{n}{k}$ terms. Therefore, $\\Lambda^{k} (T_{p}^{\\ast}M)$ is a $\\binom{n}{k}$-dimensional vector space. Notably, a $0$-form on the differential manifold $M$ is defined by the function $f : M \\to \\mathbb{R}$ defined on $M$.\nFor example, up to 3rd order forms exist in $\\mathbb{R}^{3}$.\n0th order form: Functions on $\\mathbb{R}^{3}$ 1st order form: $a_{1}dx_{1} + a_{2}dx_{2} + a_{3}dx_{3}$ 2nd order form: $a_{12}dx_{1}\\wedge dx_{2} + a_{13}dx_{1}\\wedge dx_{3} + a_{23} dx_{2} \\wedge dx_{3}$ 3rd order form: $a_{123}dx_{1} \\wedge dx_{2} \\wedge dx_{3}$ See Also Cotangent space and first-order differential form Second-order differential form Kth order differential form ","id":3258,"permalink":"https://freshrimpsushi.github.io/en/posts/3258/","tags":null,"title":"kth Order Differential Forms"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code julia\u0026gt; findfirst(\u0026#34;li\u0026#34;, \u0026#34;multicolinearlity\u0026#34;)\r8:9\rjulia\u0026gt; findlast(\u0026#34;li\u0026#34;, \u0026#34;multicolinearlity\u0026#34;)\r14:15\rjulia\u0026gt; findnext(\u0026#34;l\u0026#34;, \u0026#34;multicolinearlity\u0026#34;, 1)\r3:3\rjulia\u0026gt; findnext(\u0026#34;l\u0026#34;, \u0026#34;multicolinearlity\u0026#34;, 4)\r8:8\rjulia\u0026gt; findnext(\u0026#34;l\u0026#34;, \u0026#34;multicolinearlity\u0026#34;, 9)\r14:14\rjulia\u0026gt; findfirst(r\u0026#34;t.+t\u0026#34;, \u0026#34;multicolinearlity\u0026#34;)\r4:16 findfirst(pattern, A)\nReturns a Range representing the interval matching pattern in the string A. The pattern can include regular expressions. In the last example, it finds and returns the interval from the first t to the last t. ","id":2226,"permalink":"https://freshrimpsushi.github.io/en/posts/2226/","tags":null,"title":"How to Find a Specific Pattern Location in Julia Strings"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Explanation When attempting to draw a dendrogram by using the plot() function after performing hierarchical clustering with hclust() on the given data, the following error occurs.\nusing Clustering using Distances using Plots\ra = rand(2, 10)\rD_a = pairwise(Euclidean(), a, a)\rSL = hclust(D_a, linkage=:single)\rdendrogram = plot(SL)\rERROR: LoadError: Cannot convert Hclust{Float64} to series data for plotting To draw a dendrogram, one should use StatsPlots.jl instead of Plots.jl.\nusing StatsPlots\rdendrogram = plot(SL)\rsavefig(dendrogram, \u0026#34;julia_dendrogram.png\u0026#34;) ","id":3257,"permalink":"https://freshrimpsushi.github.io/en/posts/3257/","tags":null,"title":"How to Draw a Dendrogram in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Overview We define the binary operation $\\wedge$ and, in the sense that we defined the first-order differential form, we define a second-order form for the differential manifold $M$.\nIf differential manifolds seem difficult, one can think of them as $M = \\mathbb{R}^{n}$.\nBuildup1 Let‚Äôs consider the first-order form $\\omega$.\n$$ \\begin{align*} \\omega : M \u0026amp;\\to T^{\\ast}M \\\\ p \u0026amp;\\mapsto \\omega_{p} \\end{align*} $$\nThis maps a point $p$ of a $n$-dimensional differential manifold $M$ to an element $\\omega_{p} \\in T_{p}^{\\ast}M$ of the cotangent space. Then, since $\\omega_{p}$ is an element of the dual space of $T_{p}M$, it is a functional as follows.\n$$ w_{p} : T_{p}M \\to \\mathbb{R} $$\nIn summary, the \u0026lsquo;first-order\u0026rsquo; form can be thought of as mapping the point $p$ to a function $\\omega_{p}$ taking \u0026lsquo;one\u0026rsquo; tangent vector at $p$ as a variable. In this sense, we will define the \u0026lsquo;second-order\u0026rsquo; form.\nWedge Product Let‚Äôs call the function $\\varphi : T_{p}M \\times T_{p}M \\to \\mathbb{R}$ a bilinear alternating function.\n$$ \\varphi (v_{1}, v_{2}) = - \\varphi (v_{2}, v_{1}),\\quad v_{i} \\in T_{p}M $$\nLet‚Äôs denote the set of such $\\varphi$s as $\\Lambda^{2} (T_{p}^{\\ast}M)$.\n$$ \\Lambda^{2} (T_{p}^{\\ast}M) := \\left\\{ \\varphi : T_{p}M \\times T_{p}M \\to \\mathbb{R}\\ | \\ \\varphi \\text{ is bilinear and alternate} \\right\\} $$\nNow, let‚Äôs define a binary operation $\\wedge : T_{p}^{\\ast}M \\times T_{p}^{\\ast}M \\to \\Lambda^{2} (T_{p}^{\\ast}M)$ that sends two elements of $T_{p}^{\\ast}M$ to $\\Lambda^{2} (T_{p}^{\\ast}M)$. This means to express the elements of $\\Lambda^{2} (T_{p}^{\\ast}M)$ in terms of elements of $T_{p}^{\\ast}M$. Then, when we say $\\varphi_{1}, \\varphi_{2} \\in T_{p}^{\\ast}M$, since $\\Lambda^{2} (T_{p}^{\\ast}M)$ is a set of alternating functions, the following must be true. (Note that the symbol $\\wedge$ itself is read as [wedge], and the binary operation $\\wedge$ is called the wedge product or exterior product. The TeX code is \\wedge)\n$$ \\varphi_{1} \\wedge \\varphi_{2} \\in \\Lambda^{2} (T_{p}^{\\ast}M) $$\n$$ (\\varphi_{1} \\wedge \\varphi_{2}) (v_{1}, v_{2}) = - (\\varphi_{1} \\wedge \\varphi_{2}) (v_{2}, v_{1}),\\quad v_{i} \\in T_{p}M $$\nIf we define $\\wedge$ as follows, it exactly satisfies the above condition.\n$$ (\\varphi_{1} \\wedge \\varphi_{2})(v_{1}, v_{2}) := \\det \\left[ \\phi_{i}(v_{j}) \\right] $$\nHere, $i$ represents the row index, and $j$ represents the column index. Of course, the wedge product $\\wedge$ itself becomes an alternating function.\nAlternating Property $$ \\begin{align*} (\\varphi_{1} \\wedge \\varphi_{2})(v_{1}, v_{2}) =\u0026amp;\\ \\det \\left[ \\varphi_{i}(v_{j}) \\right] \\\\ =\u0026amp;\\ \\begin{vmatrix} \\varphi_{1}(v_{1}) \u0026amp; \\varphi_{1}(v_{2}) \\\\ \\varphi_{2}(v_{1}) \u0026amp; \\varphi_{2}(v_{2}) \\end{vmatrix} \\\\ =\u0026amp;\\ - \\begin{vmatrix} \\varphi_{1}(v_{2}) \u0026amp; \\varphi_{1}(v_{1}) \\\\ \\varphi_{2}(v_{2}) \u0026amp; \\varphi_{2}(v_{1}) \\end{vmatrix} \u0026amp; \\text{by property of determinant} \\\\ =\u0026amp;\\ - (\\varphi_{1} \\wedge \\varphi_{2})(v_{2}, v_{1}) \\end{align*} $$\n‚ñ†\nLinearity $\\text{for } a\\in \\mathbb{R}$,\n$$ \\begin{align*} \u0026amp; (\\varphi_{1} \\wedge \\varphi_{2})(av_{1} + v_{2}, w) \\\\[1em] =\u0026amp;\\ \\begin{vmatrix} \\varphi_{1}(av_{1}+v_{2}) \u0026amp; \\varphi_{1}(w) \\\\ \\varphi_{2}(av_{1}+v_{2}) \u0026amp; \\varphi_{2}(w) \\end{vmatrix} \\\\[1em] =\u0026amp;\\ \\begin{vmatrix} a\\varphi_{1}(v_{1}) + \\varphi_{1}(v_{2}) \u0026amp; \\varphi_{1}(w) \\\\ a\\varphi_{2}(v_{1}) + \\varphi_{2}(v_{2}) \u0026amp; \\varphi_{2}(w) \\end{vmatrix} \u0026amp; \\text{by linearity of } \\varphi_{i} \\\\[1em] =\u0026amp;\\ \\begin{vmatrix} a\\varphi_{1}(v_{1}) \u0026amp; \\varphi_{1}(w) \\\\ a\\varphi_{2}(v_{1}) \u0026amp; \\varphi_{2}(w) \\end{vmatrix} + \\begin{vmatrix}\\varphi_{1}(v_{2}) \u0026amp; \\varphi_{1}(w) \\\\ \\varphi_{2}(v_{2}) \u0026amp; \\varphi_{2}(w) \\end{vmatrix} \u0026amp; \\text{by property of determinant} \\\\[1em] =\u0026amp;\\ a\\begin{vmatrix} \\varphi_{1}(v_{1}) \u0026amp; \\varphi_{1}(w) \\\\ \\varphi_{2}(v_{1}) \u0026amp; \\varphi_{2}(w) \\end{vmatrix} + \\begin{vmatrix} \\varphi_{1}(v_{2}) \u0026amp; \\varphi_{1}(w) \\\\ \\varphi_{2}(v_{2}) \u0026amp; \\varphi_{2}(w) \\end{vmatrix} \u0026amp; \\text{by property of determinant} \\\\[1em] =\u0026amp;\\ a(\\varphi_{1} \\wedge \\varphi_{2})(v_{1}, w) + (\\varphi_{1} \\wedge \\varphi_{2})(v_{2}, w) \\end{align*} $$\n‚ñ†\nBasis Now, let‚Äôs consider the wedge products of the basis $\\left\\{ (dx_{j})_{p} \\right\\}_{j}$s of $T_{p}^{\\ast}M$. If you are quick to catch on, you might guess that these will be the basis of $\\Lambda^{2} (T_{p}^{\\ast}M)$. For convenience, let‚Äôs denote it as follows.\n$$ (dx_{i} \\wedge dx_{j})_{p} \\overset{\\text{notation}}{=} (dx_{i})_{p} \\wedge (dx_{j})_{p} \\in \\Lambda^{2} (T_{p}^{\\ast}M) $$\nThen, $\\left\\{ (dx_{i} \\wedge dx_{j})_{p} : i \\lt j \\right\\}$ actually becomes the basis of $\\Lambda^{2} (T_{p}^{\\ast}M)$, and the following holds.\n$$ (dx_{i} \\wedge dx_{j})_{p} = - (dx_{j} \\wedge dx_{i})_{p},\\quad i \\ne j \\\\[1em] (dx_{i} \\wedge dx_{i})_{p} = 0 $$\nNow we are ready to define the second-order form.\nDefinition We define the function $\\omega : M \\to \\Lambda^{2} (T_{p}^{\\ast}M)$ that maps a point $p \\in M$ as follows as a second-order form in $M$.\n$$ \\omega (p) = a_{12}(p)(dx_{1} \\wedge dx_{2})_{p} + a_{13}(p)(dx_{1} \\wedge dx_{3})_{p} + a_{23}(p)(dx_{2} \\wedge dx_{3})_{p} $$\n$\\omega$ is simply denoted as follows.\n$$ \\begin{align*} \\omega =\u0026amp;\\ a_{12}dx_{1} \\wedge dx_{2} + a_{13}dx_{1} \\wedge dx_{3} + a_{23}dx_{2} \\wedge dx_{3} \\\\ =\u0026amp;\\ a_{ij}dx_{i}\\wedge dx_{j} (i \\lt j) \u0026amp; \\text{by Einstein notation} \\end{align*} $$\nAt this time, $a_{ij} : M \\to \\mathbb{R}$. If each of $a_{ij}$ is differentiable, $\\omega$ is called a second-order differential form.\nSee Also Cotangent Space and First-Order Differential Forms Second-Order Differential Forms k-th Order Differential Forms Manfredo P. Do Carmo, Differential Forms and Applications, p2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3256,"permalink":"https://freshrimpsushi.github.io/en/posts/3256/","tags":null,"title":"Second-Order Differential Form"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code julia\u0026gt; contains(\u0026#34;qwerty\u0026#34;, \u0026#34;er\u0026#34;)\rtrue\rjulia\u0026gt; contains(\u0026#34;qwerty\u0026#34;, \u0026#34;et\u0026#34;)\rfalse\rjulia\u0026gt; contains(\u0026#34;qwerty\u0026#34;, r\u0026#34;q?\u0026#34;)\rtrue contains(haystack::AbstractString, needle)\nReturns a boolean indicating whether needle is contained in haystack. needle can include regular expressions, such as r\u0026quot;...\u0026quot;. Note that \u0026lsquo;haystack\u0026rsquo; means a hay pile, referring to the idiom \u0026ldquo;a needle in a haystack\u0026rdquo;.\nEnvironment OS: Windows julia: v1.6.2 ","id":2224,"permalink":"https://freshrimpsushi.github.io/en/posts/2224/","tags":null,"title":"How to Check if a Specific String is Contained in Julia"},{"categories":"ÏµúÏ†ÅÌôîÏù¥Î°†","contents":"Definition 1 $$ \\begin{matrix} \\text{Maximize} \u0026amp; \\mathbf{c}^{T} \\mathbf{x} \\\\ \\text{subject to} \u0026amp; A \\mathbf{x} = \\mathbf{b} \\\\ \u0026amp; \\mathbf{x} \\ge \\mathbf{0} \\end{matrix} $$\nGiven matrices $A \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{b} \\in \\mathbb{R}^{m \\times 1}$, and $\\mathbf{c} \\in \\mathbb{R}^{n}$ for a Linear Programming Problem represented in the equation form, a set $B \\subseteq [n]$ with cardinality $m$ exists for the feasible solution $\\mathbf{x} \\in \\mathbb{R}^{n}$, satisfying the following two conditions, then $\\mathbf{x} = \\left( x_{1} , \\cdots , x_{n} \\right)$ is referred to as the Basic Feasible Solution:\n(i): $\\exists A_{B}^{-1}$ (ii): $x_{j} = 0 \\forall j \\notin B$ In this case, $x_{j}$ is called the Basic Variable, and the set $B$ is called the Basis. A feasible solution that is a basic feasible solution can be described as being basic.\n$\\mathbf{c}^{T}$ denotes [transpose]. A [feasible solution] refers to a solution that satisfies the constraints regardless of optimization. $[n] = \\left\\{ 1, \\cdots , n \\right\\}$ is a set of natural numbers from $1$ to $n$. $A_{B}$ is a square matrix formed by taking only the columns listed in set $B$ from matrix $A$. Explanation The definition might appear complicated due to its lengthiness, but it‚Äôs actually quite straightforward, so there‚Äôs no need to be intimidated.\nA basic feasible solution is merely a discussion about feasible solutions, so $\\mathbf{c} \\in \\mathbb{R}^{n}$ is completely disregarded.\nExample When it is stated as $$ \\begin{align*} A =\u0026amp; \\begin{bmatrix} 1 \u0026amp; 5 \u0026amp; 3 \u0026amp; 4 \u0026amp; 6 \\\\ 0 \u0026amp; 1 \u0026amp; 3 \u0026amp; 5 \u0026amp; 6 \\end{bmatrix} \\\\ \\mathbf{b} =\u0026amp; \\begin{bmatrix} 14 \\\\ 7 \\end{bmatrix} \\end{align*} $$, $\\mathbf{x} = (0,2,0,1,0)$ is a feasible solution that satisfies two constraints expressed in the equation form $$ \\begin{align*} 1 x_{1} + 5 x_{2} + 3 x_{3} + 4 x_{4} + 6 x_{5} =\u0026amp; 14 \\\\ 0 x_{1} + 1 x_{2} + 3 x_{3} + 5 x_{4} + 6 x_{5} =\u0026amp; 7 \\end{align*} $$. Here, only $x_{2}, x_{4}$ is used as components of $\\mathbf{x}$ , and since $$ A_{B} = \\begin{bmatrix} 5 \u0026amp; 4 \\\\ 1 \u0026amp; 5 \\end{bmatrix} $$ is nonsingular , the feasible solution $\\mathbf{x}$ is a basic feasible solution.\nGeometric Explanation Consider the case of $A \\in \\mathbb{R}^{1 \\times 3}$, i.e., a linear programming problem where there are $m=1$ constraints and the solution space dimension is $n = 3$.\nFrankly speaking, basic feasible solutions refer to the vertices (excluding $\\mathbf{0}$) in the above pyramid. Although we are currently only considering feasible solutions and not optimal ones, it is logically plausible to assume that the optimal solution would not randomly be located at the center of an edge. Since the objective function isn‚Äôt curving in a nonlinear way, if there exists an optimal solution, it would be among those three vertices, abstracting and generalizing the concept of the basic feasible solution.\nMoreover, this solution space is essentially a [simplex], leading to the idea behind the [simplex method].\nAlgebraic Explanation The existence of the inverse matrix $A_{B}^{-1}$ implies that the column vectors of the square matrix $A_{B}$ are [linearly independent], which means that it\u0026rsquo;s sufficient to consider exactly $m \\le n$ necessary variables out of all $n$ variables. Recalling the geometric explanation, needing only one dimension to represent each of the three vertices fits perfectly with this concept.\nMatousek. (2007). Understanding and Using Linear Programming: p45.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2223,"permalink":"https://freshrimpsushi.github.io/en/posts/2223/","tags":null,"title":"Linear Programming Problem Basis Solution"},{"categories":"Í∏∞ÌïòÌïô","contents":"Overview We define the cotangent space and the differential 1-form. If differential manifolds are challenging, one can think of it as $M = \\mathbb{R}^{n}$.\nWe use Einstein notation.\nCotangent Space1 Let\u0026rsquo;s consider a $M$ as a $n$-dimensional differential manifold. Then, the tangent space $T_{p}M$ at point $p \\in M$ becomes a $n$-dimensional vector space (function space), with the basis being $\\left\\{ \\mathbf{e}_{i} = \\left. \\frac{\\partial }{\\partial x_{i}}\\right|_{p} \\right\\}_{i}$.\nAt this time, the dual space $T_{p}^{\\ast}M$ of the tangent space $T_{p} M$ is called the cotangent space.\n$$ T_{p}^{\\ast}M := \\left\\{ \\psi : T_{p}M \\to \\mathbb{R}\\ |\\ \\psi \\text{ is continuous and linear} \\right\\} $$\nDescription Due to the properties of the dual space, $\\dim T_{p}M = n = \\dim T_{p}^{\\ast}M$, and the dual basis $\\left\\{ (dx_{j})_{p} \\right\\}$ is defined as the following function.\n$$ (dx_{j})_{p} : T_{p}M \\to \\mathbb{R} $$\n$$ (dx_{j})_{p} \\left(\\textstyle \\left. \\frac{\\partial }{\\partial x_{k}}\\right|_{p} \\right) = \\delta_{jk} = \\begin{cases} 1, \u0026amp; j=k \\\\ 0, \u0026amp; j\\ne k \\end{cases} $$\nAny $\\omega_{p} \\in T_{p}^{\\ast}M$ can be expressed as follows against the basis $\\left\\{ (dx_{j})_{p} \\right\\}$.\n$$ \\begin{align*} \\omega_{p} =\u0026amp;\\ (a_{p}^{1}, a_{p}^{2}, a_{p}^{3}),\\quad a_{p}^{i} \\in \\mathbb{R} \\\\[1em] =\u0026amp;\\ a_{p}^{1}(dx_{1})_{p} + a_{p}^{2}(dx_{1})_{p} + a_{p}^{3}(dx_{3})_{p} \\end{align*} $$\nThen, let\u0026rsquo;s consider the function $\\omega$ mapping each point $p \\in M$ to $\\omega_{p} \\in T_{p}^{\\ast}M$.\nDifferential 1-Form A $\\omega$ mapping each point $p\\in M$ on the differential manifold $M$ to the element $\\omega_{p} \\in T_{p}^{\\ast}M$ of the cotangent space is called a 1-form.\n$$ \\begin{align*} \\omega : M \u0026amp;\\to T^{\\ast}M \\\\ p \u0026amp;\\mapsto \\omega_{p} \\end{align*} $$\nIn this case, $T^{\\ast}M = \\bigcup \\limits_{p \\in M} T_{p}^{\\ast}M$ is called a cotangent bundle.\nDescription A 1-form is also known as a first-order form, and it is referred to as the exterior form of degree 1, field of linear form, etc., in English.\nIf a function is $a_{i}$, where $a_{i} : M \\to \\mathbb{R}$ and $a_{i}(p) = a_{p}^{i}$, then $\\omega_{p}$ can be expressed as follows.\n$$ \\begin{align*} \\omega_{p} = \\omega (p) =\u0026amp;\\ (a_{1}(p), a_{2}(p), a_{3}(p)) \\\\ =\u0026amp;\\ a_{1}(p)(dx_{1})_{p} + a_{2}(p)(dx_{1})_{p} + a_{3}(p)(dx_{3})_{p} \\end{align*} $$\nThen, $\\omega$ is as follows. When using Einstein\u0026rsquo;s notation,\n$$ \\omega = a_{1}dx_{1} + a_{2}dx_{2} + a_{3}dx_{3} = a_{i}dx_{i} $$\nIf each $a_{i}$ is a differentiable function, then $\\omega$ is called a differential form of degree 1.\n$\\mathbb{R}^{n}$\u0026rsquo;s $1$-Form This abstract talk might make it hard to understand its meaning. Differential forms provide the theoretical backdrop for dealing with $dx$ and $dy$ freely in calculus. Let\u0026rsquo;s look at an example in Euclidean space. Consider a function $f : \\mathbb{R}^{n} \\to \\mathbb{R}$. Then, the differentiation of $f$ is $df_{p} : T_{p}\\mathbb{R}^{n} \\to T_{f(p)}\\mathbb{R}$. If $v \\in T_{p}\\mathbb{R}^{n}$,\n$$ v = \\sum\\limits_{i} v_{i}\\dfrac{\\partial }{\\partial x_{i}} = v_{i}\\dfrac{\\partial }{\\partial x_{i}} = (v_{1}, \\dots, v_{n}) $$\nIf the coordinates of $\\mathbb{R}$ are $y$, then the basis of $T_{f(p)}\\mathbb{R}$ is $\\left\\{ \\dfrac{\\partial }{\\partial y} \\right\\}$, and substituting $v$ into the differential yields,\n$$ \\begin{align*} df_{p} (v) \u0026amp;= \\begin{bmatrix}\\dfrac{\\partial f}{\\partial x_{1}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial f}{\\partial x_{n}}\\end{bmatrix} \\begin{bmatrix}v_{1} \\\\ \\vdots \\\\ v_{n} \\end{bmatrix} \\\\ \u0026amp;= \\begin{bmatrix} v_{i} \\dfrac{\\partial f}{\\partial x_{i}}\\end{bmatrix} \\\\ \u0026amp;= \\left( v_{i} \\dfrac{\\partial f}{\\partial x_{i}} \\right) \\dfrac{\\partial }{\\partial y} \\end{align*} $$\nNow, let\u0026rsquo;s look at the $\\mathbb{R}^{n}$\u0026rsquo;s $1$-form $\\omega_{p} = \\dfrac{\\partial f}{\\partial x_{i}}dx_{i}$. By substituting $v$,\n$$ \\begin{align*} w_{p} (v) \u0026amp;= \\dfrac{\\partial f}{\\partial x_{i}}dx_{i} (v) \\\\ \u0026amp;= \\dfrac{\\partial f}{\\partial x_{i}}dx_{i} \\left( v_{j}\\dfrac{\\partial }{\\partial x_{j}} \\right) \\\\ \u0026amp;= \\dfrac{\\partial f}{\\partial x_{i}} v_{j}\\delta_{ij} \\\\ \u0026amp;= v_{i}\\dfrac{\\partial f}{\\partial x_{i}} \\end{align*} $$\nThen, in this case, since $\\mathbb{R}$\u0026rsquo;s dimension is $1$ anyway, the following holds true.\n$$ df_{p}(v) = \\begin{bmatrix} v_{i} \\dfrac{\\partial f}{\\partial x_{i}}\\end{bmatrix} = v_{i}\\dfrac{\\partial f}{\\partial x_{i}} = \\omega_{p}(v) $$\nTherefore, it can be understood that the $1$-form $\\omega_{p}$ on $\\mathbb{R}^{n}$ and the differential of the function defined on $\\mathbb{R}^{n}$ $df_{p}$ are the same. This is the essence of representing the total differential $df$ of scalar functions in calculus.\n$$ df = \\dfrac{\\partial f}{\\partial x}dx + \\dfrac{\\partial f}{\\partial y}dy + \\dfrac{\\partial f}{\\partial z}dz $$\nExamples If $f(x,y) = x^{2} + y^{2}$, then,\n$$ df = \\dfrac{\\partial f}{\\partial x}dx + \\dfrac{\\partial f}{\\partial y}dy = 2xdx + dydy $$\nIf $f(x,y) = e^{xy} + 3x$, then,\n$$ df = (ye^{xy} + 3)dx + xe^{xy}dy $$\nSee Also 2nd order differential form k-th order differential form Manfredo P. Do Carmo, Differential Forms and Applications, p1-2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3254,"permalink":"https://freshrimpsushi.github.io/en/posts/3254/","tags":null,"title":"Cotangent Space and First-Order Differential Forms"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Primes.jl is a package that deals with functions related to primes and prime factorization. The implementation of functions related to analytic number theory is still lacking.\nThis is not a comprehensive list of all the features of the package, but rather a selection of the useful ones. For more details, check the repository1.\nTypes Prime Factorization Primes.Factorization julia\u0026gt; factor(12)\r2^2 * 3\rjulia\u0026gt; factor(12)[1]\r0\rjulia\u0026gt; factor(12)[2]\r2\rjulia\u0026gt; factor(12)[3]\r1\rjulia\u0026gt; factor(12)[4]\r0 Prime factorization uses a unique data type that differentiates between base and exponent. Accessing a base as an index allows you to reference its exponent.\nFunctions Generating Primes prime(), primes() julia\u0026gt; using Primes\rjulia\u0026gt; prime(4)\r7\rjulia\u0026gt; primes(10)\r4-element Vector{Int64}:\r2\r3\r5\r7 prime(::Type{\u0026lt;:Integer}=Int, i::Integer)\nReturns the ith prime. primes([lo,] hi)\nReturns an array of primes up to hi. Prime Testing isprime() julia\u0026gt; isprime(7)\rtrue\rjulia\u0026gt; isprime(8)\rfalse isprime(n::Integer)\nReturns a boolean indicating whether n is a prime. This function\u0026rsquo;s implementation uses the Miller-Rabin primality test among others. Prime Factorization factor() julia\u0026gt; factor(24)\r2^3 * 3\rjulia\u0026gt; factor(Vector, 24)\r4-element Vector{Int64}:\r2\r2\r2\r3\rjulia\u0026gt; factor(Array, 24)\r4-element Vector{Int64}:\r2\r2\r2\r3\rjulia\u0026gt; factor(Set, 24)\rSet{Int64} with 2 elements:\r2\r3 factor(n::Integer) -\u0026gt; Primes.Factorization factor(ContainerType, n::Integer) -\u0026gt; ContainerType\nReturns the prime factorization of n. The implementation of this function uses the Pollard\u0026rsquo;s $p-1$ rho algorithm among others. If ContainerType is provided, it returns the result in the specified container, otherwise, it returns in its own data type, Primes.Factorization. Euler\u0026rsquo;s Totient Function julia\u0026gt; totient(12)\r4 totient(n::Integer)\nFor n=$n$, returns $\\displaystyle n \\prod_{p \\mid n} \\left( 1 - {{ 1 } \\over { p }} \\right)$ using Euler\u0026rsquo;s totient function $\\phi$. https://github.com/JuliaMath/Primes.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2222,"permalink":"https://freshrimpsushi.github.io/en/posts/2222/","tags":null,"title":"How to Use Factorization and Prime Number Functions in Julia"},{"categories":"ÏµúÏ†ÅÌôîÏù¥Î°†","contents":"Definition 1 For matrices $A \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{b} \\in \\mathbb{R}^{m \\times 1}$, and $\\mathbf{c} \\in \\mathbb{R}^{n}$, the following linear programming problem is called in standard form or equational form. $$ \\begin{matrix} \\text{Maximize} \u0026amp; \\mathbf{c}^{T} \\mathbf{x} \\\\ \\text{subject to} \u0026amp; A \\mathbf{x} = \\mathbf{b} \\\\ \u0026amp; \\mathbf{x} \\ge \\mathbf{0} \\end{matrix} $$\n$\\mathbf{c}^{T}$ means transpose. Optimization refers to maximization or minimization. Description Conversion to Standard Form In principle, any linear programming problem can be converted into standard form. Consider the following maximization problem, for example.\n$$ \\begin{matrix} \\text{Maximize} \u0026amp; 3 x_{1} - 2 x_{2} \\\\ \\text{subject to} \u0026amp; 2 x_{1} - x_{2} \\le 4 \\\\ \u0026amp; x_{1} + 3 x_{2} \\ge 5 \\\\ \u0026amp; x_{2} \\ge 0 \\end{matrix} $$\nThe basic idea of conversion is \u0026lsquo;consolidating inequalities\u0026rsquo;. The first constraint $$ 2 x_{1} - x_{2} \\le 4 $$ can in fact be represented as $$ 2 x_{1} - x_{2} + x_{3} = 4 $$ without any issue, regarding some $x_{3} \\ge 0$. Because $2 x_{1} - x_{2}$ supplements the amount by which $4$ is smaller. Variables that serve to loosen the equation in this manner are called slack variables. The second constraint $$ x_{1} + 3 x_{2} \\ge 5 $$ can be handled by multiplying both sides by $-1$ and introducing a new slack variable $x_{4}$, just as with the first constraint, becoming $$ - x_{1} - 3 x_{2} + x_{4} = - 5 $$. At a glance, $$ \\begin{matrix} \\text{Maximize} \u0026amp; 3 x_{1} - 2 x_{2} \\\\ \\text{subject to} \u0026amp; 2 x_{1} - x_{2} + x_{3} = 4 \\\\ \u0026amp; - x_{1} - 3 x_{2} + x_{4} = - 5 \\\\ \u0026amp; x_{2}, x_{3}, x_{4} \\ge 0 \\end{matrix} $$ seems to meet the conditions for equational form, but since there‚Äôs yet no constraint for $x_{1} \\ge 0$, it needs to be accommodated. Given that $x_{1}$ is allowed to be any real number, breaking it into the difference $x_{1} = y_{1} - z_{1}$ of two positive numbers removes $x_{1}$ from the equation, allowing it to be presented in equational form as follows. $$ \\begin{matrix} \\text{Maximize} \u0026amp; 3 \\left( y_{1} - z_{1} \\right) - 2 x_{2} \\\\ \\text{subject to} \u0026amp; 2 \\left( y_{1} - z_{1} \\right) - x_{2} + x_{3} = 4 \\\\ \u0026amp; - \\left( y_{1} - z_{1} \\right) - 3 x_{2} + x_{4} = - 5 \\\\ \u0026amp; y_{1}, z_{1}, x_{2}, x_{3}, x_{4} \\ge 0 \\end{matrix} $$\nGeometry of Equational Form Equation $A \\mathbf{x} = \\mathbf{b}$ forms a general plane, a hyperplane, and taking only the part that forms a cone shape within the Euclidean space according to condition $\\mathbf{x} \\ge \\mathbf{0}$. With the introduction of slack variables, the dimension increases, but the space to be explored for optimization is significantly simplified.\nThis solution space is none other than a simplex, and herein lies the idea for the simplex method.\nMatousek. (2007). Understanding and Using Linear Programming: p41.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2221,"permalink":"https://freshrimpsushi.github.io/en/posts/2221/","tags":null,"title":"Linear Programming Problem in Equation Form"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Polynomials.jl is a package that includes the representation and computation of polynomial functions. Since polynomials are mathematically simple, there\u0026rsquo;s a tendency to think their coding should be straightforward, too. However, once you start implementing the necessary features, it can become quite cumbersome. Of course, it\u0026rsquo;s not extremely difficult, but it\u0026rsquo;s generally better to use a package whenever possible.\nThis is not an exhaustive list of all features of the package, but rather a selection of potentially useful ones, so check the repository for more details1.\nGeneral Polynomial Functions Define a Polynomial Function by Coefficients Polynomial() julia\u0026gt; using Polynomials\rjulia\u0026gt; p = Polynomial([1,0,0,1])\rPolynomial(1 + x^3)\rjulia\u0026gt; q = Polynomial([1,1])\rPolynomial(1 + x)\rjulia\u0026gt; r = Polynomial([1,1], :t)\rPolynomial(1 + t)\rjulia\u0026gt; p(0)\r1\rjulia\u0026gt; p(2)\r9 Polynomial{T, X}(coeffs::AbstractVector{T}, [var = :x])\nIt returns the polynomial function itself. coeffs is an array of coefficients, with the constant term at the beginning and higher-order terms towards the end. var specifies the polynomial\u0026rsquo;s variable. As shown in the example, entering the symbol :t makes it a polynomial in t. Define a Polynomial Function by Data fit() julia\u0026gt; fit([-1,0,1], [2,0,2])\rPolynomial(2.0*x^2) fit(::Type{RationalFunction}, xs::AbstractVector{S}, ys::AbstractVector{T}, m, n; var=:x)\nIt returns the polynomial function that passes through points with coordinates $x$ at xs and $y$ at ys. Define a Polynomial Function by Roots roots() julia\u0026gt; fromroots([-2,2])\rPolynomial(-4 + x^2) fromroots(::AbstractVector{\u0026lt;:Number}; var=:x)\nIt returns the polynomial function with the provided array\u0026rsquo;s elements as roots. Operations +, -, *, √∑ julia\u0026gt; p + 1\rPolynomial(2 + x^3)\rjulia\u0026gt; 2p\rPolynomial(2 + 2*x^3) Adding or multiplying by a scalar results in the intuitive operation as above.\njulia\u0026gt; p + q\rPolynomial(2 + x + x^3)\rjulia\u0026gt; p - q\rPolynomial(-x + x^3)\rjulia\u0026gt; p * q\rPolynomial(1 + x + x^3 + x^4)\rjulia\u0026gt; p √∑ q\rPolynomial(1.0 - 1.0*x + 1.0*x^2) Arithmetic operations between polynomial functions are overridden with +, -, *, √∑.\nFinding Roots roots() julia\u0026gt; roots(p)\r3-element Vector{ComplexF64}:\r-1.0 + 0.0im\r0.4999999999999998 - 0.8660254037844383im\r0.4999999999999998 + 0.8660254037844383im roots(f::AbstractPolynomial)\nIt returns the roots of f as a vector. Differentiation derivative() julia\u0026gt; derivative(p, 3)\rPolynomial(6) derivative(f::AbstractPolynomial, order::Int = 1)\nIt returns the orderth derivative of f. Integration integrate() julia\u0026gt; integrate(p, 7)\rPolynomial(7.0 + 1.0*x + 0.25*x^4) integrate(f::AbstractPolynomial, C = 0)\nIt returns the indefinite integral of f with an integration constant of C. Special Polynomial Functions Laurent Polynomial Functions LaurentPolynomial() julia\u0026gt; LaurentPolynomial([4,3,2,1], -1)\rLaurentPolynomial(4*x‚Åª¬π + 3 + 2*x + x¬≤) LaurentPolynomial{T,X}(coeffs::AbstractVector, [m::Integer = 0], [var = :x])\nIt returns the Laurent polynomial function extended to integers for degree. The degree of the smallest term is given as m. Chebyshev Polynomial Functions ChebyshevT() julia\u0026gt; ChebyshevT([3,2,1])\rChebyshevT(3‚ãÖT_0(x) + 2‚ãÖT_1(x) + 1‚ãÖT_2(x)) ChebyshevT{T, X}(coeffs::AbstractVector)\nIt returns the Type I Chebyshev polynomial function. The formula\u0026rsquo;s T_n(x) is represented by $T_{n}(x) = \\cos \\left( n \\cos^{-1} x \\right)$. Environment OS: Windows julia: v1.6.2 https://juliamath.github.io/Polynomials.jl/stable/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2220,"permalink":"https://freshrimpsushi.github.io/en/posts/2220/","tags":null,"title":"How to Use Polynomials in Julia"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition A Weibull Distribution is a probability distribution with the following probability density function, given scale parameter $\\lambda \u0026gt; 0$ and shape parameter $k \u0026gt; 0$. $$ f(x) = {{ k } \\over { \\lambda }} \\left( {{ x } \\over { \\lambda }} \\right)^{k-1} e^{-(x/\\lambda)^{k}} \\qquad , x \\ge 0 $$\nTheorems [1] A Generalization of the Exponential Distribution: The Weibull Distribution becomes the Exponential Distribution when $k=1$. [2] A Generalization of the Rayleigh Distribution: The Weibull Distribution becomes the Rayleigh Distribution when $k=2$. Description As evident from its mathematical representation of the probability density function, the Weibull distribution is most commonly viewed as a generalization of the exponential distribution. Its applications are exceedingly varied, but the most representative one is in survival analysis, similar to the exponential distribution. However, unlike the constant failure rate in the exponential distribution, it changes according to $k$:\nIf $k\u0026lt;1$, the failure rate is seen to decrease over time. It is said to well explain phenomena where there is a sharp drop after a certain period, such as infant mortality. If $k=1$, the failure rate is constant over time, exactly as in the exponential distribution. If $k\u0026gt;1$, the failure rate is seen to increase over time. This is often mentioned in research papers estimating the incubation or recovery period of infectious diseases, especially viruses. Generalization to Three Parameters 1 A Three-parameter Weibull Distribution is a probability distribution with the following probability density function, given scale parameter $\\alpha \u0026gt; 0$, location parameter $\\beta \u0026gt; 0$, and shape parameter $\\gamma \u0026gt; 0$. $$ f(x) = {{ \\gamma } \\over { \\alpha }} \\left( {{ x-\\beta } \\over { \\alpha }} \\right)^{\\gamma-1} e^{- \\left( (x - \\beta) / \\alpha \\right)^{\\gamma}} \\qquad , x \\ge \\beta $$ If $X \\sim \\text{Weibull} (\\alpha, \\beta, \\gamma)$, then its mean and variance are as follows. $$ \\begin{align*} E(X) =\u0026amp; \\alpha \\Gamma \\left( 1 + {{ 1 } \\over { \\gamma }} \\right) + \\beta \\\\ \\text{Var} (X) =\u0026amp; \\alpha^{2} \\left[ \\Gamma \\left(1 + {{ 2 } \\over { \\gamma }} \\right) - \\left( \\Gamma \\left( 1 + {{ 1 } \\over { \\gamma }} \\right)^{2} \\right) \\right] \\end{align*} $$ Of course, if $X \\sim \\text{Weibull} (\\lambda, k)$ for the two parameters, it is as follows. $$ \\begin{align*} E(X) =\u0026amp; \\lambda \\Gamma \\left( 1 + {{ 1 } \\over { k }} \\right) \\\\ \\text{Var} (X) =\u0026amp; \\lambda^{2} \\left[ \\Gamma \\left(1 + {{ 2 } \\over { k }} \\right) - \\left( \\Gamma \\left( 1 + {{ 1 } \\over { k }} \\right)^{2} \\right) \\right] \\end{align*} $$\nHere, $\\Gamma$ is the Gamma function. Miller. (2006). A Derivation of the Pythagorean Won-Loss Formula in Baseball. https://arxiv.org/abs/math/0509698v4\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2219,"permalink":"https://freshrimpsushi.github.io/en/posts/2219/","tags":null,"title":"Weibull Distribution"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Concatenate Strings * julia\u0026gt; \u0026#34;oh\u0026#34; * \u0026#34;my\u0026#34; * \u0026#34;girl\u0026#34;\r\u0026#34;ohmygirl\u0026#34; Corresponds to the + in Python.\nConcatenate Multiple Strings string() julia\u0026gt; string(\u0026#34;oh\u0026#34;,\u0026#34;my\u0026#34;, \u0026#34;girl\u0026#34;)\r\u0026#34;ohmygirl\u0026#34; Corresponds to paste0() in R.\nJoining Items of a List of Strings join() julia\u0026gt; OMG = [\u0026#34;oh\u0026#34;,\u0026#34;my\u0026#34;, \u0026#34;girl\u0026#34;]\r3-element Vector{String}:\r\u0026#34;oh\u0026#34;\r\u0026#34;my\u0026#34;\r\u0026#34;girl\u0026#34;\rjulia\u0026gt; join(OMG)\r\u0026#34;ohmygirl\u0026#34; Corresponds to join() in Python.\nRepeat the Same String ^ julia\u0026gt; \u0026#34;=-\u0026#34; ^ 10\r\u0026#34;=-=-=-=-=-=-=-=-=-=-\u0026#34; Corresponds to * in Python. The expression of repetition as exponentiation is no coincidence, as in Python, the binary operation for connecting strings is +(sum), and repeating it is *(product). Similarly, in Julia, the operation for connecting strings is *(product), and repeating it becomes ^(exponent).\nWhy? Why not use +, which is more intuitive and easy to understand as in other languages? It\u0026rsquo;s because, from an algebraic, mathematical perspective, merging strings is closer to multiplication than addition and is more natural1. It would be best if you could understand what a Free Group in Algebra means, but even without such background knowledge, the representation of the product of x and y as x * y = xy in mathematics is acceptable. $$ x \\ast y = xy $$ Now consider appending the string \u0026quot;litol\u0026quot; to \u0026quot;xy\u0026quot;, creating \u0026quot;xylitol\u0026quot;. $$ xy \\ast litol = xylitol $$ It makes sense. Thinking about \u0026quot;xy\u0026quot; + \u0026quot;litol\u0026quot; now might feel a bit strange. The people who made Julia are seriously committed to such mathematical intuition.\nEnvironment OS: Windows julia: v1.6.2 https://discourse.julialang.org/t/why-are-there-all-these-strange-stumbling-blocks-in-julia/92644/40\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2218,"permalink":"https://freshrimpsushi.github.io/en/posts/2218/","tags":null,"title":"Concatenating Strings in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 using Plots\rx = rand(30)\ry = rand(30)\rz = rand(30)\rplot(x)\rplot!(y)\rplot!(z)\rpng(\u0026#34;result1\u0026#34;) In some cases, you might want to make only certain data labels appear in the legend, as shown above.\nlabel = \u0026quot;\u0026quot; plot(x, label = \u0026#34;\u0026#34;)\rplot!(y)\rpng(\u0026#34;result2\u0026#34;) In such cases, you can set the option label = \u0026quot;\u0026quot;. As you can see, the first data is displayed in the figure, but it does not appear in the legend.\nprimary = false plot!(z, primary = false)\rpng(\u0026#34;result3\u0026#34;) Another way is to set the primary = false option, as shown. The last data is plotted in orange and hidden in the legend. Since this is a side effect of turning off primary, it\u0026rsquo;s better to only tweak the label option if possible.\nEnvironment OS: Windows julia: v1.6.2 https://github.com/JuliaPlots/Plots.jl/issues/1388#issuecomment-363940741\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2216,"permalink":"https://freshrimpsushi.github.io/en/posts/2216/","tags":null,"title":"Hiding Specific Data Labels in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 You can use annotate!(). The following code is for drawing a picture that marks the maximum and minimum points in Brownian motion.\nusing Plots\rcd(@__DIR__)\rdata = cumsum(randn(100))\rplot(data, color = :black, legend = :none)\rannotate!(argmax(data), maximum(data), \u0026#34;max\\n\u0026#34;)\rannotate!(argmin(data), minimum(data), \u0026#34;\\nmin\u0026#34;)\rpng(\u0026#34;result\u0026#34;) Environment OS: Windows julia: v1.7.0 https://discourse.julialang.org/t/plots-annotate/37784\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2214,"permalink":"https://freshrimpsushi.github.io/en/posts/2214/","tags":null,"title":"How to Insert Text into a Julia Plot"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Environment OS: Windows julia: v1.6.2 Error julia\u0026gt; plot(data, color = :black,\rlabel = \u0026#34;Í∞í\u0026#34;, title = \u0026#34;Î∏åÎùºÏö¥Î™®ÏÖò\u0026#34;)\rGKS: glyph missing from current font: 48652\rGKS: glyph missing from current font: 46972\rGKS: glyph missing from current font: 50868\rGKS: glyph missing from current font: 47784\rGKS: glyph missing from current font: 49496 Cause The issue is due to the inability to find Korean fonts.\nSolution Both methods are not ideal, and alternative suggestions are always welcome. It is a fact that support for Korean is limited given that using Julia often does not require much Korean.\ndefault(fontfamily = \u0026quot;\u0026quot;) 1 plot(data, color = :black,\rlabel = \u0026#34;Í∞í\u0026#34;, title = \u0026#34;Î∏åÎùºÏö¥Î™®ÏÖò\u0026#34;, fontfamily = \u0026#34;\u0026#34;)\rdefault(fontfamily = \u0026#34;\u0026#34;)\rplot(data, color = :red,\rlabel = \u0026#34;Í∞í\u0026#34;, title = \u0026#34;Î∏åÎùºÏö¥Î™®ÏÖò\u0026#34;) Korean can be rendered by setting the plot() option fontfamily = \u0026quot;\u0026quot; or using default(fontfamily = \u0026quot;\u0026quot;). However, even if the specific font name is changed, it is confirmed that it does not recognize them properly, and when saving, it ends up not finding the font, resulting in the text being displayed as a blank space instead of being garbled as shown in the first image.\nPlots.plotly() 2 Plots.plotly()\rplot(data, color = :black,\rlabel = \u0026#34;Í∞í\u0026#34;, title = \u0026#34;Î∏åÎùºÏö¥Î™®ÏÖò\u0026#34;)\rsavefig(\u0026#34;result.html\u0026#34;) Using the plotly backend does render the Korean characters. However, it cannot save directly to *.png. Instead, it requires outputting to *.html first and then saving separately.\nCode using Plots\r#Plots.gr()\rdata = cumsum(randn(100))\rplot(data, color = :black,\rlabel = \u0026#34;Í∞í\u0026#34;, title = \u0026#34;Î∏åÎùºÏö¥Î™®ÏÖò\u0026#34;)\rplot(data, color = :black,\rlabel = \u0026#34;Í∞í\u0026#34;, title = \u0026#34;Î∏åÎùºÏö¥Î™®ÏÖò\u0026#34;, fontfamily = \u0026#34;\u0026#34;)\rdefault(fontfamily = \u0026#34;\u0026#34;)\rplot(data, color = :red,\rlabel = \u0026#34;Í∞í\u0026#34;, title = \u0026#34;Î∏åÎùºÏö¥Î™®ÏÖò\u0026#34;)\rsavefig(\u0026#34;result.png\u0026#34;)\rPlots.plotly()\rplot(data, color = :black,\rlabel = \u0026#34;Í∞í\u0026#34;, title = \u0026#34;Î∏åÎùºÏö¥Î™®ÏÖò\u0026#34;)\rsavefig(\u0026#34;result.html\u0026#34;) https://discourse.julialang.org/t/nice-fonts-with-plots-gr-and-latexstrings/60037\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://besixdouze.net/16\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2212,"permalink":"https://freshrimpsushi.github.io/en/posts/2212/","tags":null,"title":"Inserting Korean Text into Julia Plots"},{"categories":"ÏµúÏ†ÅÌôîÏù¥Î°†","contents":"Definition 1 A linear programming problem, shortly referred to as LP, is an optimization problem that is linear in both its objective function and constraints. Simply put, a linear problem looks to find $\\mathbf{x} \\in \\mathbb{R}^{n}$ for which the objective function $f: \\mathbb{R}^{n} \\to \\mathbb{R}$, given vectors $\\mathbf{c} \\in \\mathbb{R}^{n}$, is $$ f \\left( \\mathbf{x} \\right) := \\mathbf{c}^{T} \\mathbf{x} $$ and for given matrices $A \\in \\mathbb{R}^{m \\times n}$ and $\\mathbf{b} \\in \\mathbb{R}^{m \\times 1}$, it satisfies $$ A \\mathbf{x} \\le \\mathbf{b} $$ while optimizing the function value of $f$. It is generally represented as follows. $$ \\begin{matrix} \\text{Optimize} \u0026amp; \\mathbf{c}^{T} \\mathbf{x} \\\\ \\text{subject to} \u0026amp; A \\mathbf{x} \\le \\mathbf{b} \\end{matrix} $$ In such problems, any solution that meets the constraint conditions is called a Feasible Solution, among which the one that maximizes or minimizes the objective function is known as the Optimal Solution.\n$\\mathbf{c}^{T}$ means transpose. Optimization refers to either maximization or minimization. Explanation Definition The term linear is aptly named because both the objective function and constraints involved are linear. This means that the equations do not contain squared terms, logarithms, or any other form of nonlinear functions, and the constraints must also be in the form of (in)equality matrix expressions. This contrasts with problems expressed in equalities primarily dealt with in [Matrix Algebra](../../categories/Linear Algebra), [Linear Algebra](../../categories/Linear Algebra). $$ A \\mathbf{x} = \\mathbf{b} $$\nProgram here does not refer to computer applications as we commonly understand, but rather to schedules or tasks. In practical applications of linear programming, each variable $x_{1} , \\cdots , x_{n}$ can represent various elements such as time, energy, resources, etc.\nFor example, in economics or business management, maximizing these elements would likely correspond to utility, while minimizing them pertains to costs. If it involves creating an optimal work schedule by allocating employees with varying efficiencies and work hours to certain tasks, linear programming would be the foremost method to consider.\nExamples 2 $$ \\begin{matrix} \\text{Optimize} \u0026amp; x_{1} + x_{2} \\\\ \\text{subject to} \u0026amp; x_{1} \\ge 0 \\\\ \u0026amp; x_{2} \\ge 0 \\\\ \u0026amp; x_{2} - x_{1} \\le 1 \\\\ \u0026amp; x_{1} + 6 x_{2} \\le 15 \\\\ \u0026amp; 4 x_{1} - x_{2} \\le 10 \\end{matrix} $$\nLet\u0026rsquo;s consider the linear problem as mentioned above. While it may seem complicated at first glance due to the five conditions, the variables involved are only $x_{1}$ and $x_{2}$. When these are plotted on a $2$-dimensional plane, the following illustration shows the region that satisfies the conditions.\nAll points within this region are feasible solutions, as they, at a minimum, meet the constraint conditions. The goal is to find the point among these where the objective function $\\Lambda \\left( x_{1} , x_{2} \\right) = x_{1} + x_{2}$ is maximized. Geometrically, this is where the line of feasible solutions intersects $x_{1} + x_{2} = \\lambda$ in such a way that $\\lambda$ is maximized, or in other words, the point where the $y$-intercept of the line is the greatest.\nThe actual solution to this example is such that $\\lambda = 5$ is met by $\\left( x_{1} , x_{2} \\right) = (3,2)$. Interestingly, this solution might feel familiar. If one has gone through the standard educational curriculum, they might have encountered similar problems around their first year of high school. Thus, the basic idea behind this is simple enough that even students just graduated from middle school could grasp it. The term \u0026rsquo;linear\u0026rsquo; itself indicates that, regardless of how the solution is derived, the concept is straightforward.\nMatousek. (2007). Understanding and Using Linear Programming: p3.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMatousek. (2007). Understanding and Using Linear Programming: p1~2.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2207,"permalink":"https://freshrimpsushi.github.io/en/posts/2207/","tags":null,"title":"Definition of Linear Programming Problem"},{"categories":"Í∏∞ÌïòÌïô","contents":"Gauss-Bonnet Theorem Let\u0026rsquo;s consider $\\mathbf{x} : U \\to \\mathbb{R}^{3}$ as a simple connected geodesic coordinate chart, and $\\boldsymbol{\\gamma}(I) \\subset \\mathbf{x}(U)$, which is $\\boldsymbol{\\gamma}$, as piecewise regular curves. Also, let\u0026rsquo;s say that $\\boldsymbol{\\gamma}$ surrounds some region $\\mathscr{R}$. Then, the following holds true.\n$$ \\iint_{\\mathscr{R}} K dA + \\int_{\\boldsymbol{\\gamma}} \\kappa_{g} ds + \\sum \\alpha_{i} = 2\\pi $$\nHere, $K$ denotes the Gaussian curvature, $\\kappa_{g}$ denotes the geodesic curvature, and $\\alpha_{i}$ denotes the difference in angles at the junction point between intervals of $\\boldsymbol{\\gamma}$, referred to as jump angles.\nExplanation Since $\\boldsymbol{\\gamma}$ is assumed to be a curve that is regular piecewise, there will be points where the direction of the tangent suddenly changes, and the difference in angles at those points is denoted as $\\alpha_{i}$. If $\\boldsymbol{\\gamma}$ is a curve that smoothly connects overall, there will be no points where the angle jumps, hence, such $\\alpha_{i}$s are $0$. (See figure (a))\nThe theorem above is a result when the strong condition of being a geodesic coordinate chart is applied. In more general results, the Euler characteristic appears in the formula, as follows.\n$$ \\iint_{\\mathscr{R}} K dA + \\int_{C_{i}}\\kappa_{g}ds + \\sum\\alpha_{i} = 2\\pi \\chi(\\mathscr{R}) $$\nProof Since $\\mathbf{x}$ is a geodesic coordinate chart, let\u0026rsquo;s set the coefficients of the first fundamental form as follows.\n$$ \\left[ g_{ij} \\right] = \\begin{bmatrix} 1 \u0026amp; 0 \\\\ 0 \u0026amp; h^{2} \\end{bmatrix} $$\nAnd let\u0026rsquo;s denote $\\boldsymbol{\\gamma}(t) = \\mathbf{x}\\left( \\gamma^{1}(t), \\gamma^{2}(t) \\right)$. Now, let\u0026rsquo;s denote the angle between the tangents $\\mathbf{x}_{1}$ and $\\boldsymbol{\\gamma}$ as $T = \\boldsymbol{\\gamma}^{\\prime}$.\n$$ \\alpha (t) := \\angle ( \\mathbf{x}_{1}, T) $$\nWe will prove the theorem using the fact that the angle change of $\\alpha$ around the path, based on $\\boldsymbol{\\gamma}$, when making a full circle, is $\\mathbf{x}_{1}$. First, assume $T$ as a unit speed curve. And let\u0026rsquo;s denote $2 \\pi$ as a parallel vector field along $\\boldsymbol{\\gamma}$ satisfying the following. (Refer to the above figure (b))\n$$ P(t) = \\text{parallel vector field starting from a juction point s.t. } \\dfrac{P \\times T}{\\left\\| P \\times T \\right\\|} = \\mathbf{n} $$\nAnd let\u0026rsquo;s denote $P$ and $\\boldsymbol{\\gamma}$ respectively as the angles between $\\phi$ and $\\theta$, and $\\mathbf{x_{1}}$ and $P$.\n$$ \\phi (t) = \\angle(\\mathbf{x}_{1}, P),\\quad \\theta (t) = \\angle(P, T) $$\nIn other words, $P$, and differentiating this,\n$$ -\\sin \\phi (t) \\dfrac{d \\phi}{d t}(t) = \\left\\langle \\dfrac{d \\mathbf{x}_{1}(\\gamma^{1}(t), \\gamma^{2}(t))}{d t}, P(t) \\right\\rangle + \\left\\langle \\mathbf{x}_{1}, \\dfrac{d P}{d t}(t) \\right\\rangle $$\nSince $T$ is a parallel vector field along $\\left\\langle \\mathbf{x}_{1}, P(t) \\right\\rangle = \\cos\\phi (t)$, by definition, $P$ is perpendicular to $\\gamma$. $\\dfrac{dP}{dt}$ is tangent to $M$, so the latter term is $\\mathbf{x}_{1}$. Further calculations reveal,\n$$ \\begin{align*} \u0026amp;\\quad -\\sin \\phi (t) \\dfrac{d \\phi}{d t}(t) \\\\ \u0026amp;= \\left\\langle \\dfrac{d \\mathbf{x}_{1}(\\gamma^{1}(t), \\gamma^{2}(t))}{d t}, P(t) \\right\\rangle \\\\ \u0026amp;= \\Big[ \\mathbf{x}_{11}(\\gamma^{1}(t), \\gamma^{2}(t)) (\\gamma^{1})^{\\prime}(t) + \\mathbf{x}_{12}(\\gamma^{1}(t), \\gamma^{2}(t)) (\\gamma^{2})^{\\prime}(t) \\Big] \\cdot P(t) \\\\ \u0026amp;= \\Big[ \\left( L_{11}\\mathbf{n} + \\Gamma_{11}^{1}\\mathbf{x}_{1} + \\Gamma_{11}^{2}\\mathbf{x}_{2} \\right)(\\gamma^{1})^{\\prime}(t) + \\left( L_{12}\\mathbf{n} + \\Gamma_{12}^{1}\\mathbf{x}_{1} + \\Gamma_{12}^{2}\\mathbf{x}_{2} \\right)(\\gamma^{2})^{\\prime}(t) \\Big] \\cdot P(t) \\\\ \u0026amp;= \\Big[ \\left(\\Gamma_{11}^{1}\\mathbf{x}_{1} + \\Gamma_{11}^{2}\\mathbf{x}_{2} \\right)(\\gamma^{1})^{\\prime}(t) + \\left(\\Gamma_{12}^{1}\\mathbf{x}_{1} + \\Gamma_{12}^{2}\\mathbf{x}_{2} \\right)(\\gamma^{2})^{\\prime}(t) \\Big] \\cdot P(t) \\end{align*} $$\nThe second equality is due to the chain rule, the third equality is due to the definitions of the second fundamental form and the Christoffel symbols, and the fourth equality holds because $M$ and $0$ are perpendicular to each other.\nChristoffel symbols of the geodesic coordinate chart\nExcept for the below, everything is $P$.\n$$ \\Gamma_{22}^{1} = -hh_{1},\\quad \\Gamma_{12}^{2} = \\Gamma_{21}^{2} = \\dfrac{h_{1}}{h},\\quad \\Gamma_{22}^{2} = \\dfrac{h_{2}}{h} $$\nNow, organizing the terms that become $\\mathbf{n}$ yields the following.\n$$ -\\sin\\phi (t) \\phi^{\\prime}(t) = \\left\\langle \\dfrac{h_{1}}{h}(\\gamma^{2})^{\\prime}(t)\\mathbf{x}_{2}, P(t) \\right\\rangle = \\dfrac{h_{1}}{h}(\\gamma^{2})^{\\prime}(t) \\left\\langle \\mathbf{x}_{2}, P(t) \\right\\rangle\\tag{1} $$\nSince $0$, $0$ is a unit vector, and because $g_{11} = \\left\\langle \\mathbf{x}_{1}, \\mathbf{x}_{1} \\right\\rangle = 1$, $\\mathbf{x}_{1}$ holds. Therefore, $g_{12} = \\left\\langle \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\rangle = 0$ becomes a normal orthogonal basis of the tangent plane. Hence, any element $\\mathbf{x}_{1} \\perp \\mathbf{x}_{2}$ of the tangent plane is expressed as below.\n$$ P = \\left\\langle \\mathbf{x}_{1}, P \\right\\rangle\\mathbf{x}_{1} + \\left\\langle \\dfrac{\\mathbf{x}_{2}}{\\left\\| \\mathbf{x}_{2} \\right\\|}, P \\right\\rangle \\dfrac{\\mathbf{x}_{2}}{\\left\\| \\mathbf{x}_{2} \\right\\|} = \\cos\\phi \\mathbf{x}_{1} + \\sin\\phi \\dfrac{\\mathbf{x}_{2}}{h} $$\nAlso, substituting $\\left\\{ \\mathbf{x}_{1}, \\dfrac{\\mathbf{x}_{2}}{\\left\\| \\mathbf{x}_{2} \\right\\|} \\right\\}$ into $P$,\n$$ \\phi^{\\prime}(t) = -h_{1}(\\gamma^{2})^{\\prime}(t) $$\nTherefore, the total angle variation of $\\left\\langle \\mathbf{x}_{2}, P \\right\\rangle = \\left\\| x_{2} \\right\\|^{2} \\dfrac{\\sin \\phi}{h} = h\\sin \\phi$ is\n$$ \\delta \\phi = \\int_{\\boldsymbol{\\gamma}} \\phi^{\\prime} dt = - \\int_{\\boldsymbol{\\gamma}}h_{1}(\\gamma^{2})^{\\prime}(t)dt = - \\int_{\\boldsymbol{\\gamma}}h_{1} d\\gamma^{2} = - \\int_{\\boldsymbol{\\gamma}}h_{1} du^{2} \\tag{2} $$\nMoreover, the following equation will now be shown to hold.\n$$ \\text{Claim: } \\theta^{\\prime} = k_{g} $$\nSince $(1)$ is assumed, $\\phi$ holds, and differentiating this,\n$$ -\\sin\\theta (t)\\theta^{\\prime}(t) = \\left\\langle \\dfrac{d P}{d t}, T \\right\\rangle + \\left\\langle P, \\dfrac{d T}{d t} \\right\\rangle = \\left\\langle P, T^{\\prime} \\right\\rangle $$\nThe second equality holds because $\\boldsymbol{\\gamma}$ is parallel to $\\mathbf{x}$. By the definition of geodesic curvature, we obtain what we intend to show as follows.\n$$ \\begin{align*} \\kappa_{g} = \\left\\langle \\mathbf{S}, T^{\\prime} \\right\\rangle \u0026amp;= \\left\\langle (\\mathbf{n} \\times T), T^{\\prime} \\right\\rangle \\\\ \u0026amp;= \\left\\langle \\mathbf{n}, (T \\times T^{\\prime}) \\right\\rangle \\\\ \u0026amp;= \\left\\langle \\dfrac{P \\times T}{\\sin \\theta}, (T\\times T^{\\prime}) \\right\\rangle \u0026amp; \\because \\dfrac{P \\times T}{\\left\\| P \\times T \\right\\|} = \\mathbf{n} \\\\ \u0026amp;= \\left\\langle \\dfrac{1}{\\sin\\theta} P, (T\\times (T\\times T^{\\prime})) \\right\\rangle \\\\ \u0026amp;= \\left\\langle \\dfrac{1}{\\sin\\theta} P, -T^{\\prime} \\right\\rangle \\\\ \u0026amp;= \\theta^{\\prime}(t) \\end{align*} $$\nThe third and fifth equalities hold because the scalar triple product is commutative. Thus, we obtain the following.\n$$ \\delta \\theta = \\int_{\\boldsymbol{\\gamma}} \\theta^{\\prime} dt = \\int_{\\boldsymbol{\\gamma}} k_{g}dt \\tag{3} $$\nSince $u^{2}-$,\n$$ \\int_{\\boldsymbol{\\gamma}} \\alpha^{\\prime}dt = \\int_{\\boldsymbol{\\gamma}} \\phi^{\\prime}dt + \\int_{\\boldsymbol{\\gamma}} \\theta^{\\prime}dt $$\nDue to $\\theta (t) = \\angle(P, T)$ and $\\cos\\theta (t) = \\left\\langle P, T \\right\\rangle$, we obtain the following.\n$$ \\int_{\\boldsymbol{\\gamma}} \\alpha^{\\prime}dt + \\sum_{i}\\alpha_{i} = - \\int_{\\boldsymbol{\\gamma}}h_{1} du^{2} + \\int_{\\boldsymbol{\\gamma}} k_{g}dt + \\sum_{i}\\alpha_{i} $$\n$dP/dt$ surrounds $\\mathbf{n}$, so the left-hand side of the above equation is clearly the angle change of one full rotation, which is $\\alpha = \\phi + \\theta$.\n$$ {} - \\int_{\\boldsymbol{\\gamma}}h_{1} du^{2} + \\int_{\\boldsymbol{\\gamma}} k_{g}dt + \\sum_{i}\\alpha_{i} = 2 \\pi $$\nGreen\u0026rsquo;s Theorem\n$$ \\oint_{\\partial \\mathscr{R}} Pdx = - \\iint_{\\mathscr{R}} P_{y} dy dx $$\nGaussian curvature of the geodesic coordinate chart\n$$ K = -\\dfrac{h_{11}}{h} $$\nArea element of the surface\n$$ dA = \\sqrt{g} du^{1} du^{2} $$\nThe first term on the left-hand side can be rewritten using Green\u0026rsquo;s Theorem as follows.\n$$ \\begin{align*} {} - \\int_{\\boldsymbol{\\gamma}}h_{1} du^{2} \u0026amp;= - \\iint_{\\mathscr{R}}h_{11} du^{1}du^{2} \\\\ \u0026amp;= - \\iint_{\\mathscr{R}}\\dfrac{h_{11}}{h} h du^{1}du^{2} \\\\ \u0026amp;= - \\iint_{\\mathscr{R}}\\dfrac{h_{11}}{h} \\sqrt{g} du^{1}du^{2} \\\\ \u0026amp;= \\iint_{\\mathscr{R}} K dA \\end{align*} $$\nFinally, we arrive at the following conclusion.\n$$ \\iint_{R} K dA + \\int_{\\gamma} \\kappa_{g} ds + \\sum \\alpha_{i} = 2\\pi $$\n","id":3238,"permalink":"https://freshrimpsushi.github.io/en/posts/3238/","tags":null,"title":"Gauss-Bonnet Theorem"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 2 3 julia\u0026gt; replace(\u0026#34;qwerty\u0026#34;, \u0026#34;q\u0026#34;=\u0026gt;\u0026#34;Q\u0026#34;)\r\u0026#34;Qwerty\u0026#34;\rjulia\u0026gt; join(\u0026#34;qwerty\u0026#34;, \u0026#34;,\u0026#34;)\r\u0026#34;q,w,e,r,t,y\u0026#34;\rjulia\u0026gt; split(\u0026#34;qwerty\u0026#34;, \u0026#34;\u0026#34;)\r6-element Vector{SubString{String}}:\r\u0026#34;q\u0026#34;\r\u0026#34;w\u0026#34;\r\u0026#34;e\u0026#34;\r\u0026#34;r\u0026#34;\r\u0026#34;t\u0026#34;\r\u0026#34;y\u0026#34; Julia is not particularly outstanding in string processing, but maybe because of that, it has followed Python closely making it easy and quick to learn. Most of the already known functionalities are implemented, so apart from whether it\u0026rsquo;s a module or not, the usage is almost similar. Notably, when using replace(), \u0026quot;q\u0026quot;=\u0026gt;\u0026quot;Q\u0026quot; is not some unique syntax but directly using a pair.\nhttps://docs.julialang.org/en/v1/base/collections/#Base.replace-Tuple{Any,%20Vararg{Pair,%20N}%20where%20N}\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://docs.julialang.org/en/v1/base/strings/#Base.join\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://docs.julialang.org/en/v1/base/strings/#Base.split\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2205,"permalink":"https://freshrimpsushi.github.io/en/posts/2205/","tags":null,"title":"Handling Strings in Julia like in Python"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definitions Let $\\mathscr{R}$ be a region of the surface $M$. If every closed curve within $\\mathscr{R}$ is null-homotopic, then $\\mathscr{R}$ is said to be simply connected.\nDescription Easy examples such as $\\mathbb{R}^{2}$, disk $\\left\\{ x^{2} + y^{2} = r^{2} \\right\\}$, and sphere $\\mathbb{S}^{2}$ are immediately thought to be simply connected. However, as shown in the figure below, one can see that the torus $T^{2}$ is not simply connected. Unlike $\\gamma$, $\\alpha$ and $\\beta$ cannot be contracted to a single point.\n","id":3236,"permalink":"https://freshrimpsushi.github.io/en/posts/3236/","tags":null,"title":"Simple Connected Region"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Using the comparison operator $\\approx$, it only returns true when two values are sufficiently similar. ‚âà can be used by entering \\approx and then pressing Tab, just as in $\\TeX$.\njulia\u0026gt; œÄ ‚âà 3.141592653\rtrue\rjulia\u0026gt; œÄ ‚âà 3.14159265\rtrue\rjulia\u0026gt; œÄ ‚âà 3.1415926\rfalse\rjulia\u0026gt; œÄ ‚âà 3.141592\rfalse Environment OS: Windows julia: v1.7.0 ","id":2203,"permalink":"https://freshrimpsushi.github.io/en/posts/2203/","tags":null,"title":"How to Check Approximate Values in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 julia\u0026gt; d = Dict(\u0026#34;A\u0026#34;=\u0026gt;1, \u0026#34;B\u0026#34;=\u0026gt;2)\rDict{String, Int64} with 2 entries:\r\u0026#34;B\u0026#34; =\u0026gt; 2\r\u0026#34;A\u0026#34; =\u0026gt; 1\rjulia\u0026gt; push!(d,(\u0026#34;C\u0026#34;,3))\rERROR: MethodError: no method matching push!(::Dict{String, Int64}, ::Tuple{String, Int64})\rjulia\u0026gt; push!(d,\u0026#34;C\u0026#34; =\u0026gt; 3)\rDict{String, Int64} with 3 entries:\r\u0026#34;B\u0026#34; =\u0026gt; 2\r\u0026#34;A\u0026#34; =\u0026gt; 1\r\u0026#34;C\u0026#34; =\u0026gt; 3\rjulia\u0026gt; typeof(\u0026#34;C\u0026#34; =\u0026gt; 3)\rPair{String, Int64} Dictionaries in Julia are data types that pair Keys and Values, much like in other programming languages. A slight difference in Julia is that dictionaries are seen as a collection of Pairs. As can be seen in the provided execution example, a pair is an element that constitutes the dictionary. Keys and Values are linked through the right arrow =\u0026gt;, and they themselves take the form of a Pair data type.\nThe following example shows how to replace parts of a string in Julia.\njulia\u0026gt; replace(\u0026#34;qwerty\u0026#34;, \u0026#34;q\u0026#34;=\u0026gt;\u0026#34;Q\u0026#34;)\r\u0026#34;Qwerty\u0026#34; If there\u0026rsquo;s something that sets it apart from Python, it\u0026rsquo;s that pairs can exist independently of a dictionary. Instead of viewing the dictionary as a collection containing just one pair, pairs themselves can be viewed as data, which is why Julia code may utilize pairs in a way that seems like a new syntax. Regardless of whether you use it or not, it\u0026rsquo;s something you should be able to read.\nEnvironment OS: Windows julia: v1.6.3 https://docs.julialang.org/en/v1/base/collections/#Base.Dict\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2201,"permalink":"https://freshrimpsushi.github.io/en/posts/2201/","tags":null,"title":"From Julia: Dictionaries and Pairs"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview JLD.jl is a package that allows the storage of temporary data created while using Julia1. It is useful for managing the input and output of data in pure Julia projects. On the other hand, JLD2.jl, which further improves the intuitiveness of the JLD.jl interface, is also available. 2 The content introduced in this post should be taken as a rough understanding of these functionalities, and it is recommended to use JLD2.jl whenever possible as it supports backward compatibility without issues.\nIf you specifically need to read and write MATLAB\u0026rsquo;s mat files, not just files similar to mat files, then the MAT.jl package can be referred to.\nCode using JLD\rcd(@__DIR__); pwd()\rnumpad = reshape(1:9, 3,3)\rcube = zeros(Int64, 3,3,3)\rsave(\u0026#34;mydata.jld\u0026#34;, \u0026#34;numpad\u0026#34;,numpad, \u0026#34;cube\u0026#34;,cube)\rmydata = load(\u0026#34;mydata.jld\u0026#34;)\rmydata[\u0026#34;numpad\u0026#34;]\rmydata[\u0026#34;cube\u0026#34;] Execution Result julia\u0026gt; numpad = reshape(1:9, 3,3)\r3√ó3 reshape(::UnitRange{Int64}, 3, 3) with eltype Int64:\r1 4 7\r2 5 8\r3 6 9\rjulia\u0026gt; cube = zeros(Int64, 3,3,3)\r3√ó3√ó3 Array{Int64, 3}:\r[:, :, 1] =\r0 0 0\r0 0 0\r0 0 0\r[:, :, 2] =\r0 0 0\r0 0 0\r0 0 0\r[:, :, 3] =\r0 0 0\r0 0 0\r0 0 0\rjulia\u0026gt; save(\u0026#34;mydata.jld\u0026#34;, \u0026#34;numpad\u0026#34;,numpad, \u0026#34;cube\u0026#34;,cube)\r‚îå Warning: JLD incorrectly extends FileIO functions (see FileIO documentation)\r‚îî @ FileIO C:\\Users\\rmsms\\.julia\\packages\\FileIO\\5JdlO\\src\\loadsave.jl:215 The extension of the files saved should be *.jld. The names of each data to be stored are given as strings and assigned variables are sequentially appended, bundling the data together for storage.\njulia\u0026gt; mydata = load(\u0026#34;mydata.jld\u0026#34;)\r‚îå Warning: JLD incorrectly extends FileIO functions (see FileIO documentation)\r‚îî @ FileIO C:\\Users\\rmsms\\.julia\\packages\\FileIO\\5JdlO\\src\\loadsave.jl:215 Dict{String, Any} with 7 entries:\r\u0026#34;_creator\\\\JULIA_PATCH\u0026#34; =\u0026gt; 0x00000001\r\u0026#34;cube\u0026#34; =\u0026gt; [0 0 0; 0 0 0; 0 0 0]‚Ä¶\r\u0026#34;_creator\\\\WORD_SIZE\u0026#34; =\u0026gt; 64\r\u0026#34;numpad\u0026#34; =\u0026gt; [1 4 7; 2 5 8; 3 6 9]\r\u0026#34;_creator\\\\JULIA_MINOR\u0026#34; =\u0026gt; 0x00000006\r\u0026#34;_creator\\\\ENDIAN_BOM\u0026#34; =\u0026gt; 0x04030201\r\u0026#34;_creator\\\\JULIA_MAJOR\u0026#34; =\u0026gt; 0x00000001 As you can see, a dictionary is returned upon loading. The names given as strings during the saving process enter as keys, and the actual data is in the values. It can be referenced as a dictionary as follows.\njulia\u0026gt; mydata[\u0026#34;numpad\u0026#34;]\r3√ó3 reshape(::UnitRange{Int64}, 3, 3) with eltype Int64:\r1 4 7\r2 5 8\r3 6 9\rjulia\u0026gt; mydata[\u0026#34;cube\u0026#34;]\r3√ó3√ó3 Array{Int64, 3}:\r[:, :, 1] =\r0 0 0\r0 0 0\r0 0 0\r[:, :, 2] =\r0 0 0\r0 0 0\r0 0 0\r[:, :, 3] =\r0 0 0\r0 0 0\r0 0 0 JLD2 In the example, the process of creating a dictionary with strings was cumbersome, but with JLD2.jl, the same functionality can be conveniently used with named tuples.\nhttps://github.com/JuliaIO/JLD.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/JuliaIO/JLD2.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2199,"permalink":"https://freshrimpsushi.github.io/en/posts/2199/","tags":null,"title":"How to Store Data like .mat in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Region1 Consider a subset $\\mathscr{R}$ of a surface $M$. If $\\mathscr{R}$ is an open set, and for any two points in $\\mathscr{R}$ there exists a curve on $\\mathscr{R}$ containing both, then $\\mathscr{R}$ is called a region of $M$.\nBoundary For a region $\\mathscr{R}$ of a surface $M$, the following set $\\partial \\mathscr{R}$ is called the boundary of $\\mathscr{R}$.\n$$ \\partial \\mathscr{R} = \\left\\{ p \\notin \\mathscr{R} : \\exists \\left\\{ p_{j} \\right\\} \\subset \\mathscr{R} \\text{ such that } \\lim\\limits_{j \\to \\infty} p_{j} = p \\right\\} $$\nCurve Enclosing a Region If the image of curve $\\boldsymbol{\\gamma}$ is the boundary of region $\\mathscr{R}$, and the intrinsic normal $\\mathbf{S}$ of $\\boldsymbol{\\gamma}$ points inside while $-\\mathbf{S}$ points outside $\\mathscr{R}$, then it is said that curve $\\boldsymbol{\\gamma}$ bounds a region $\\mathscr{R}$.\nExplanation The intrinsic normal $\\mathbf{S}$ pointing inside means that the curve must rotate counterclockwise. For example, for a surface $M = \\mathbb{R}^{2}$, $\\mathscr{R} = \\left\\{ (x,y) \\in \\mathbb{R}^{2} : x^{2} + y^{2} \\lt 1 \\right\\}$ is a region of $M$. Also, curve $\\boldsymbol{\\alpha}(\\theta) = (\\cos \\theta, \\sin \\theta)$ is the boundary of $\\mathscr{R}$.\nOn the other hand, let\u0026rsquo;s say the surface $M$ is a torus $T^{2}$ as in the right picture below. If all points except the image of $\\boldsymbol{\\gamma}$ are considered the region $\\mathscr{R}$, then the boundary of $\\mathscr{R}$ becomes the image of $\\boldsymbol{\\gamma}$. However, since $-\\mathbf{S}$ of curve $\\boldsymbol{\\gamma}$ does not point outside but inside $\\mathscr{R}$, it is said that curve $\\boldsymbol{\\gamma}$ does not bound $\\mathscr{R}$.\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p180-181\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3230,"permalink":"https://freshrimpsushi.github.io/en/posts/3230/","tags":null,"title":"Differentiable Surfaces and Boundaries of Regions in Differential Geometry"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 Base.Iterators.enumerate() returns an iterator that allows referencing both the index and value of an array, similar to Python.\njulia\u0026gt; x = [3,5,4,1,2]\r5-element Vector{Int64}:\r3\r5\r4\r1\r2\rjulia\u0026gt; for (idx, value) in enumerate(x)\rprintln(\u0026#34;x[‚ñ∑eq1‚óÅvalue\u0026#34;)\rend\rx[1]: 3\rx[2]: 5\rx[3]: 4\rx[4]: 1\rx[5]: 2\rjulia\u0026gt; typeof(enumerate(x))\rBase.Iterators.Enumerate{Vector{Int64}} https://docs.julialang.org/en/v1/base/iterators/#Base.Iterators.enumerate\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2197,"permalink":"https://freshrimpsushi.github.io/en/posts/2197/","tags":null,"title":"How to Refer to Both Index and Value in Julia's Loops"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview When first encountering Julia, one might be perplexed by the symbol data type. Symbols are used with a preceding :, functioning simply by their name without any internal data. They are commonly used as names, labels, or dictionary keys1.\nExplanation In other programming languages, when giving options to a function, they are often provided as numbers or strings to clarify the meaning. For example, the following two functions illustrate this.\njulia\u0026gt; function foo0(x, option = 0)\rif option == 0\rreturn string(x)\relseif option == 1\rreturn Int(x)\relse\rerror(\u0026#34;wrong\u0026#34;)\rend\rend\rfoo0 (generic function with 2 methods)\rjulia\u0026gt; foo0(3.0, 0)\r\u0026#34;3.0\u0026#34;\rjulia\u0026gt; foo0(3.0, 1)\r3\rjulia\u0026gt; function foo1(x, option = \u0026#34;string\u0026#34;)\rif option == \u0026#34;string\u0026#34;\rreturn string(x)\relseif option == \u0026#34;Int\u0026#34;\rreturn Int(x)\relse\rerror(\u0026#34;wrong\u0026#34;)\rend\rend\rfoo1 (generic function with 2 methods)\rjulia\u0026gt; foo1(3.0, \u0026#34;string\u0026#34;)\r\u0026#34;3.0\u0026#34;\rjulia\u0026gt; foo1(3.0, \u0026#34;Int\u0026#34;)\r3 In contrast, the definition using a symbol is shown below. At first glance, it might seem no different from the two functions above.\njulia\u0026gt; function foo2(x, option = :string)\rif option == :string\rreturn string(x)\relseif option == :Int\rreturn Int(x)\relse\rerror(\u0026#34;wrong\u0026#34;)\rend\rend\rfoo2 (generic function with 2 methods)\rjulia\u0026gt; foo2(3.0, :string)\r\u0026#34;3.0\u0026#34;\rjulia\u0026gt; foo2(3.0, :Int)\r3 The reason for using symbols can be explained simply: they are not meant to change mid-program. Sometimes, this might be inconvenient, but unlike integers or strings, there is no chance of them unexpectedly changing.\nMoreover, symbols are true embodiments of assignment and command. From an interface perspective, there\u0026rsquo;s little difference between strings and symbols, but taking the example of receiving the string \u0026quot;Int\u0026quot; and interpreting it as a command to return an integer, versus directly receiving the symbol :Int and returning an integer without question, there is a subtle difference. Even if this difference doesn\u0026rsquo;t resonate, there\u0026rsquo;s no need to force understanding.\nOther instances of using symbols include column names in data frames, where it\u0026rsquo;s difficult or undesirable to distinguish variables from strings. While the notation might seem daunting due to its unfamiliarity, understanding its purpose and differences alleviates the concern.\nhttps://docs.julialang.org/en/v1/base/base/#Core.Symbol\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2195,"permalink":"https://freshrimpsushi.github.io/en/posts/2195/","tags":null,"title":"Symbols in Julia"},{"categories":"ÏÑ∏Ïù¥Î≤ÑÎ©îÌä∏Î¶≠Ïä§","contents":"Definition 1 The number of balls hit by the batter that land in the valid area, excluding fielder\u0026rsquo;s choices and errors, is called a hit, abbreviated as H. Hits are classified into four types: singles, doubles, triples, and home runs.\nSummary [1]: For Plate Appearances PA, At Bats AB, and Hits H, the following inequality is established: $$ \\begin{align*} H \\le AB \\le PA \\\\ ÏïàÌÉÄ \\le ÌÉÄÏàò \\le ÌÉÄÏÑù \\end{align*} $$ Explanation Fielder\u0026rsquo;s Choice and Error A fielder\u0026rsquo;s choice is when the batter survives due to the fielder deciding to throw to another base even though the batter could originally have been out. While not a hit, it counts towards the at-bat, thus lowering the batting average and slugging percentage.\nAn error is when the batter reaches base due to a mistake by the fielder, who could have made an out under normal defensive play.\nSabermetrics Hits are easier to understand than at-bats, as mentioned in the definition, only four cases exist. According to the record rules, data analysts don\u0026rsquo;t even need to know the terms \u0026ldquo;fielder\u0026rsquo;s choice\u0026rdquo; and \u0026ldquo;error.\u0026rdquo;\nExcluding fielder\u0026rsquo;s choices and errors, as mentioned in the definition, means minimizing the intervention of chance. It\u0026rsquo;s not just about reaching base by any means but counting \u0026ldquo;runs produced by the bat.\u0026rdquo; It\u0026rsquo;s fundamental cumulative stats for calculating a batter\u0026rsquo;s hitting metrics.\nhttps://www.mlb.com/glossary/standard-stats/hit\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2194,"permalink":"https://freshrimpsushi.github.io/en/posts/2194/","tags":null,"title":"Definition of a Hit in Baseball"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide 1 julia\u0026gt; x = rand(\u0026#39;a\u0026#39;:\u0026#39;c\u0026#39;, 10)\r10-element Vector{Char}:\r\u0026#39;a\u0026#39;: ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\r\u0026#39;a\u0026#39;: ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\r\u0026#39;b\u0026#39;: ASCII/Unicode U+0062 (category Ll: Letter, lowercase)\r\u0026#39;c\u0026#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase)\r\u0026#39;b\u0026#39;: ASCII/Unicode U+0062 (category Ll: Letter, lowercase)\r\u0026#39;c\u0026#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase)\r\u0026#39;c\u0026#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase)\r\u0026#39;c\u0026#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase)\r\u0026#39;b\u0026#39;: ASCII/Unicode U+0062 (category Ll: Letter, lowercase)\r\u0026#39;b\u0026#39;: ASCII/Unicode U+0062 (category Ll: Letter, lowercase) Let\u0026rsquo;s say we have an array as shown above. In the example, our goal is to select both 'a' and 'b'. Logically, one might think to broadcast with inclusion operator $\\in$, but the result is as follows.\njulia\u0026gt; x .‚àà [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;]\rERROR: DimensionMismatch(\u0026#34;arrays could not be broadcast to a common size; got a dimension with lengths 10 and 2\u0026#34;) A DimensionMismatch error was raised. This error occurred because broadcasting happened simultaneously to both the array x and the category ['a', 'b']. To interpret the error message, it\u0026rsquo;s confusing because the length 10 of x and the length 2 of ['a', 'b'] came in at the same time.\njulia\u0026gt; x .‚àà Ref([\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;])\r10-element BitVector:\r1\r1\r1\r0\r1\r0\r0\r0\r1\r1 In this case, you can solve the broadcasting problem with the Ref() function. This allows 'a' and 'b' in ['a', 'b'] to be treated as scalars and find only the places with these two characters.\nPrecautions julia\u0026gt; y = rand(\u0026#39;a\u0026#39;:\u0026#39;c\u0026#39;, 1, 10)\r1√ó10 Matrix{Char}:\r\u0026#39;b\u0026#39; \u0026#39;a\u0026#39; \u0026#39;b\u0026#39; \u0026#39;b\u0026#39; \u0026#39;a\u0026#39; \u0026#39;c\u0026#39; \u0026#39;a\u0026#39; \u0026#39;b\u0026#39; \u0026#39;b\u0026#39; \u0026#39;c\u0026#39; Consider the case of a $1 \\times 10$ matrix as shown above. At first glance, it might seem no different from the case seen in the guide above, but .‚àà is used in a completely different way.\njulia\u0026gt; y .‚àà [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;]\r2√ó10 BitMatrix:\r0 1 0 0 1 0 1 0 0 0\r1 0 1 1 0 0 0 1 1 0 As you can see, the first row indicates the position of 'a', and the second row indicates the position of 'b'. This is due to the difference between a vector and a matrix.\njulia\u0026gt; y .‚àà Ref([\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;])\r1√ó10 BitMatrix:\r1 1 1 1 1 0 1 1 1 0 Consistent results can be obtained when using Ref().\nEnvironment OS: Windows julia: v1.7.0 https://stackoverflow.com/a/59978386/12285249\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2193,"permalink":"https://freshrimpsushi.github.io/en/posts/2193/","tags":null,"title":"How to Check if Elements of an Array Belong to a List in Julia"},{"categories":"ÏÑ∏Ïù¥Î≤ÑÎ©îÌä∏Î¶≠Ïä§","contents":"Definition 1 The term At Bat, abbreviated as AB, refers to the number of times a batter\nhits a ball, reaches base on a fielder\u0026rsquo;s choice, reaches base on an error, or gets out (excluding sacrifice hits). Theorem [1]: The equation for a batter\u0026rsquo;s plate appearances (PA), at-bats (AB), walks (BB), hit by pitch (HBP), sacrifice bunts (SH), sacrifice fly (SF), and reaching base due to batter or runner interference $X$ is as follows: $$ \\begin{align*} PA =\u0026amp; AB + (BB + HBP) + (SH + SF) + X \\\\ ÌÉÄÏÑù =\u0026amp; ÌÉÄÏàò + ÏÇ¨ÏÇ¨Íµ¨ + Ìù¨ÏÉùÌÉÄ + X \\end{align*} $$ [2]: The following inequality holds true for plate appearances (PA) [../2190], at-bats (AB) [../2192], and hits (H) [../2194]: $$ \\begin{align*} H \\le AB \\le PA \\\\ ÏïàÌÉÄ \\le ÌÉÄÏàò \\le ÌÉÄÏÑù \\end{align*} $$ Explanation Fielder\u0026rsquo;s Choice and Error A Fielder\u0026rsquo;s Choice is when a fielder chooses to attempt an out at a different base instead of trying to put out the batter-runner, allowing the batter to reach base safely. Though it does not count as a hit, it counts towards at-bats, thus lowering batting and slugging percentages.\nAn Error is when a batter reaches base due to a misplayed ball that should have resulted in an out.\nSabermetrics These concepts are key records affecting batting average, slugging percentage, on-base percentage, and further, the OPS calculation. It‚Äôs advised for those unfamiliar with baseball to use theorem [1] for calculations since Fielder\u0026rsquo;s Choices and Errors can be confusing. In the Korean League (KBO), the definition excludes walks, sacrifice hits, and reaching on batter or runner interference from finished at-bats.2\nDifferences Between Plate Appearances and At-Bats To those unfamiliar with baseball, both might confusingly look like \u0026lsquo;ÌÉÄ„ÖÖ\u0026rsquo;. Simply put,\nPlate appearances are the number of times a player stands at the plate regardless of the bat‚Äôs involvement, At-bats are the number of times the bat physically contacts the ball.3 Since one cannot have an at-bat without standing at the plate, it is impossible for at-bats to exceed plate appearances. If a beneficial hit is considered a hit, then the inequality stated in theorem [2] applies. $$ ÏïàÌÉÄ \\le ÌÉÄÏàò \\le ÌÉÄÏÑù $$\nIt is known that explaining these records through specific game situations to novices has significantly less effect. Instead, we will understand the following records according to the mentioned inequality:\n(1) 4 plate appearances 3 at-bats 3 hits: In four chances, seized three opportunities, and all three contributed positively to the offense, which is a good record. (2) 5 plate appearances 1 at-bat 2 hits: Implies that a single swing sent at least two balls flying, which is an impossible record. (3) 5 plate appearances 2 at-bats 1 hit: In five chances, seized two opportunities, and among them, one resulted in a hit, making the inequality properly hold true. (3) 3 plate appearances 0 at-bats 0 hits: Despite being given three chances, not managing a single hit thus contributing nothing to the offense, which is a bad record. https://www.mlb.com/glossary/standard-stats/at-bat\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.koreabaseball.com/About/Committee/RecordRule.aspx\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nÎ¨ºÎ°† Ìù¨ÏÉùÌÉÄÎäî Ï†úÏô∏ÎêòÏßÄÎßå ÌÉÄÏÑùÍ≥º ÌÉÄÏàòÏùò Ï∞®Ïù¥ÎùºÎäî Îß•ÎùΩÏóêÏÑúÎäî Ï§ëÏöîÌïòÏßÄ ÏïäÎã§.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2192,"permalink":"https://freshrimpsushi.github.io/en/posts/2192/","tags":null,"title":"Definition of At-bats in Baseball"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Explanation 1D arrays (vectors) are defined as follows.\njulia\u0026gt; A = [1; 2; 3]\r3-element Vector{Int64}:\r1\r2\r3 Here, ; signifies moving to the next element based on the first dimension. By generalizing this, ;; signifies moving to the next element based on the second dimension.\njulia\u0026gt; A = [1; 2; 3;; 4; 5; 6]\r3√ó2 Matrix{Int64}:\r1 4\r2 5\r3 6 Similarly, arrays of three dimensions and above can be defined. Note that this code is possible from Julia version 1.7 onwards.\njulia\u0026gt; A = [1 2; 3 4;;; 5 6; 7 8]\r2√ó2√ó2 Array{Int64, 3}:\r[:, :, 1] =\r1 2\r3 4\r[:, :, 2] =\r5 6\r7 8\rjulia\u0026gt; A = [1 2; 3 4;;; 5 6; 7 8 ;;;; 9 10; 11 12;;; 13 14; 15 16]\r2√ó2√ó2√ó2 Array{Int64, 4}:\r[:, :, 1, 1] =\r1 2\r3 4\r[:, :, 2, 1] =\r5 6\r7 8\r[:, :, 1, 2] =\r9 10\r11 12\r[:, :, 2, 2] =\r13 14 Environment OS: Windows10 Version: Julia 1.7.1 ","id":3223,"permalink":"https://freshrimpsushi.github.io/en/posts/3223/","tags":null,"title":"How to Directly Define Multidimensional Arrays in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide while The while loop is no different from other languages.\njulia\u0026gt; while x \u0026lt; 10\rx += 1\rprint(\u0026#34;‚ñ∑eq1‚óÅi - \u0026#34;)\rend\r1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 -\rjulia\u0026gt; for i = 1:10\rprint(\u0026#34;‚ñ∑eq2‚óÅi - \u0026#34;)\rend\r1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - The three major looping styles used in Julia are as above. The top one is similar to the method used in R and Python, the second is similar to Matlab, and the most elegant expression is the third, which uses the Set comprehension method.\nNested Loops The following two loops function identically.\njulia\u0026gt; X = 1:4; Y = 8:(-1):5;\rjulia\u0026gt; for x ‚àà X\rfor y ‚àà Y\rprint(\u0026#34; (‚ñ∑eq3‚óÅy) = ‚ñ∑eq4‚óÅx + ‚ñ∑eq5‚óÅ(x + y)\u0026#34;)\rif y == 5 println() end\rend\r(1 + 8) = 9 (1 + 7) = 8 (1 + 6) = 7 (1 + 5) = 6\r(2 + 8) = 10 (2 + 7) = 9 (2 + 6) = 8 (2 + 5) = 7\r(3 + 8) = 11 (3 + 7) = 10 (3 + 6) = 9 (3 + 5) = 8\r(4 + 8) = 12 (4 + 7) = 11 (4 + 6) = 10 (4 + 5) = 9 It\u0026rsquo;s like writing code as if it were Pseudo Code. A note of caution is the following case where a tuple is given as an Iterator.\njulia\u0026gt; for (x,y) ‚àà (X, Y)\rprint(\u0026#34; (‚ñ∑eq3‚óÅy) = ‚ñ∑eq7‚óÅx + ‚ñ∑eq5‚óÅ(x + y)\u0026#34;)\rif y == 5 println() end\rend\r(1 + 8) = 9 (2 + 7) = 9 (3 + 6) = 9 (4 + 5) = 9 ","id":2191,"permalink":"https://freshrimpsushi.github.io/en/posts/2191/","tags":null,"title":"How to Use Elegant Loops in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Description By typing the right bracket ] in the Julia REPL, you can switch to package management mode. The available commands in package management mode are as follows.\nCommand Function add foo Adds the package foo. free foo Unpins the package version. help, ? Shows these commands. pin foo Pins the version of the package foo. remove foo, rm foo Removes the package foo. test foo Test-runs the package foo. status, st Shows all installed packages and their versions. Typing a package name shows only its version. undo Reverses the most recent action. update, up Updates all packages to their latest versions. Typing a package name updates only that specific package. Environment OS: Windows10 Version: Julia 1.7.1 ","id":3217,"permalink":"https://freshrimpsushi.github.io/en/posts/3217/","tags":null,"title":"List of Available Commands in Julia Package Management Mode"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"ÏÑ§Î™Ö This document outlines the process of calculating the Radon transform $\\mathcal{R}f$ of a phantom $f$ in Python and saving the results as a *.npy file. To load this file in Julia, one can use the PyCall.jl package.\nusing PyCall\rnp = pyimport(\u0026#34;numpy\u0026#34;) The above code is equivalent to executing import numpy as np in Python. This allows one to directly use the code written for numpy in Python to load $f$ and $\\mathcal{R}f$.\nf = np.load(\u0026#34;f.npy\u0026#34;)\rRf = np.load(\u0026#34;Rf.npy\u0026#34;) To check if it has been correctly loaded, let\u0026rsquo;s visualize it using a heatmap.\np1 = heatmap(reverse(f, dims=1), color=:viridis)\rp2 = heatmap(reverse(Rf, dims=1), color=:viridis)\rplot(p1, p2, size=(728,250)) Environment OS: Windows10 Version: Julia 1.6.2, PyCall 1.93.0 ","id":3215,"permalink":"https://freshrimpsushi.github.io/en/posts/3215/","tags":null,"title":"How to load a npy file in Julia"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition 1 A random network whose degree distribution follows a Pareto distribution is known as a Scale-free Network.\nDescription The term Scale-free (SF) network comes from the scale-invariance of the Pareto distribution. Being defined by its degree distribution, it strongly inherits the properties of that distribution. Mathematically, the degree $v \\in V(G)$ of nodes in a scale-free network $G$ can be described by some parameter $\\gamma \u0026gt; 0$ as follows. $$ P \\left( \\deg v = k \\right) \\sim k^{-\\gamma} $$ Like the Pareto distribution, SF networks are frequently found across the sciences and are known to be excellent models for describing social and natural phenomena. However, recent papers2 have warned against the universal applicability of SF networks, so caution is advised.\nOne prominent application is mimicking the underlying structure in certain dynamics. Given that it is derived from numerous real data, it is the first to be considered when a mathematically universal structure is needed for human relationships, traffic networks, ecosystems, etc., and is indeed widely used. Methods for artificially generating SF networks include the following models:\nChung-Lu Fitness Model Barab√°si-Albert Model The following is a visualization of an SF network generated by the Barab√°si-Albert model.\nIn the formula, the histogram of degree distribution should form a straight line when plotted on a log-log scale. In other words, $$ p(x) \\sim x^{-\\gamma} $$ when logs are taken on both sides of $$ \\log p (x) = - \\gamma \\log x $$ it becomes a straight line with a slope of $- \\gamma$. Actually, drawing it shows a clear straight line except for the area where hub nodes occur.\nAlbert. (2002). Statistical mechanics of complex networks. https://doi.org/10.1103/RevModPhys.74.47\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBroido. (20109). Scale-free networks are rare. https://doi.org/10.1038/s41467-019-08746-5\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2183,"permalink":"https://freshrimpsushi.github.io/en/posts/2183/","tags":null,"title":"Scale-Free Network"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Let\u0026rsquo;s say we want to draw a sine curve from $0$ to $2\\pi$ on the heatmap of the array $(5,5)$. You might want to write the code like this, but as you can see in the figure, it doesn\u0026rsquo;t output as desired.\nusing Plots\rA = rand(Bool, 5,5)\rheatmap(A, color=:greens)\rx = range(0, 2pi, length=100)\ry = sin.(x)\rplot!(x, y, color=:red, width=3) This is because the horizontal and vertical range of array $A$ is recognized as from $1$ to $5$. To solve this, you can specify the horizontal and vertical range of $A$ as below. Note that if you do not specify the range of array $A$ and only specify the range shown in the heatmap, it will be displayed as below.\nx‚Çê = range(0,2pi, length=5)\ry‚Çê = range(-1.5,1.5, length=5)\rp1 = heatmap(x‚Çê, y‚Çê, A, color=:greens, xlims=(0,2pi), ylims=(-1.5,1.5)) #Í∑∏Î¶º (Í∞Ä)\rp2 = heatmap(A, color=:greens, xlims=(0,2pi), ylims=(-1.5,1.5)) #Í∑∏Î¶º (ÎÇò) Now, if we redraw the sine curve on p1, it is drawn correctly as desired.\nplot!(x, y, color=:red, width=3) Environment OS: Windows10 Version: Julia 1.7.1, Plots 1.25.3 ","id":3213,"permalink":"https://freshrimpsushi.github.io/en/posts/3213/","tags":null,"title":"Overlaying Plots on Heatmaps in Julia"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 For the scale parameter $x_{0} \u0026gt; 0$ and the shape parameter $\\alpha \u0026gt; 0$, the following probability function is referred to as the Pareto Distribution, Power Law, or Scale-free Distribution:\nContinuous: For a constant $C$ that satisfies constant $\\displaystyle \\int_{x_{0}}^{\\infty} p(x) dx = 1$ $$ p(x) = C x^{-\\alpha} \\qquad , x \u0026gt; x_{0} $$ Discrete: For the Riemann zeta function $\\zeta$ $$ p_{k} = {{ 1 } \\over { \\zeta (\\alpha) }} k^{-\\alpha} \\qquad , k \\in \\mathbb{N} $$ Basic Properties [1] Moment generating function: The moment generating function of the Pareto distribution does not exist. [2] Mean and variance: If $X \\sim \\text{Pareto} \\left( x_{0}, \\alpha \\right)$, then $$ \\begin{align*} E (X) =\u0026amp; {{ \\alpha - 1 } \\over { \\alpha - 2 }} x_{0} \u0026amp; , \\alpha \u0026gt; 2 \\\\ \\text{Var} (X) =\u0026amp; {{ (\\alpha - 1) } \\over { \\left( \\alpha -2 \\right)^{2} (\\alpha - 3) }} x_{0}^{2} \u0026amp; , \\alpha \u0026gt; 3 \\end{align*} $$ Theorems [a] Scale-freeness: The Pareto distribution is the unique Scale-free Distribution. In other words, for all $b$, there exists some constant $\\alpha$ such that the following holds true. $$ p(bx) = g(b) p(x) \\implies p(x) = p(1) x^{-\\alpha} $$ [b] The $k$th moment: If $0 \u0026lt; k \u0026lt; \\alpha - 1$, then the $k$th moment exists and $$ E X^{k} = {{ \\alpha - 1 } \\over { \\alpha - 1 - k }} x_{0}^{k} $$ Description The Pareto distribution is a representative distribution that explains the prevalent inequality in the real world, closely related to the following concepts:\nHeaps\u0026rsquo; law and Zipf\u0026rsquo;s law: Empirical laws concerning the frequency of words. Book sales Traffic volume Earthquake magnitudes Diameters of craters Wealth Citation count Looking at the shape of the probability density function, one can intuitively understand that the greater the shape $\\alpha$, the more severe the inequality becomes. In economic terms, this means the rich have an endless amount of money, and the poor are plentiful.\nThe statement that the Pareto distribution possesses scale-freeness literally means there is no scale. For example, if two random variables follow the Poisson distribution with parameters $\\lambda_{1} = 10$ and $\\lambda_{2} = 1000$, depending on where you look, there can be a big difference, but the Pareto distribution essentially has no difference wherever you look. Mathematically, this corresponds to the conclusion being the same regardless of the value given to $b$.\nProof [1] The existence of a random variable\u0026rsquo;s moment generating function implies that the $k$th moment exists for all $k \\in \\mathbb{N}$. However, as specified in theorem [2], the $1$th moment of the Pareto distribution exists only when $\\alpha \u0026gt; 1$, thus the moment generating function cannot exist.\n‚ñ†\n[2] Strategy: Use the moment formula [b].\nGiven $$ \\begin{align*} EX^{1} =\u0026amp; {{ \\alpha - 1 } \\over { \\alpha - 1 - 1 }} x_{0}^{1} \\\\ =\u0026amp; {{ \\alpha - 1 } \\over { \\alpha - 2 }} x_{0}^{1} \\end{align*} $$, and since $\\displaystyle EX^{2} = {{ \\alpha - 1 } \\over { \\alpha - 3 }} x_{0}^{2}$, then $$ \\begin{align*} \\text{Var} X =\u0026amp; {{ \\alpha - 1 } \\over { \\alpha - 3 }} x_{0}^{2} - \\left[ {{ \\alpha - 1 } \\over { \\alpha - 2 }} x_{0}^{1} \\right]^{2} \\\\ =\u0026amp; \\left[ {{ 1 } \\over { \\alpha - 3 }} - {{ \\alpha - 1 } \\over { \\left( \\alpha - 2 \\right)^{2} }} \\right] (\\alpha - 1) x_{0}^{2} \\\\ =\u0026amp; \\left[ \\alpha^{2} - 4 \\alpha + 4 - \\alpha^{2} + 4 \\alpha - 3 \\right] {{ (\\alpha - 1) } \\over { (\\alpha - 3) \\left( \\alpha -2 \\right)^{2} }} x_{0}^{2} \\\\ =\u0026amp; {{ (\\alpha - 1) } \\over { \\left( \\alpha -2 \\right)^{2} (\\alpha - 3) }} x_{0}^{2} \\end{align*} $$\n‚ñ†\n[a] Assuming for all $b$, there exists some function $g$ such that $$ p(bx) = g(b) p(x) $$ holds true. Substituting $x = 1$ gives $p(b) = g(b) p(1)$, hence $g(b) = p(b) / p(1)$ and $$ p(bx) = {{ p(b) p(x) } \\over { p(1) }} $$ Differentiating with respect to $b$ yields $$ x p '(bx) = {{ p ' (b) p(x) } \\over { p(1) }} $$ Substituting $b=1$ and applying the trick using differentiation of logarithmic functions2 $$ \\begin{align*} \u0026amp; x p '(x) = {{ p ' (1) p(x) } \\over { p(1) }} \\\\ \\implies \u0026amp; {{ p '(x) } \\over { p(x) }} = {{ p '(1) } \\over { p(1) }} \\cdot {{ 1 } \\over { x }} \\\\ \\implies \u0026amp; {{ d \\log p(x) } \\over { dx }} = {{ p '(1) } \\over { p(1) }} \\cdot {{ 1 } \\over { x }} \\\\ \\implies \u0026amp; d \\log p(x) = {{ p '(1) } \\over { p(1) }} {{ 1 } \\over { x }} dx \\end{align*} $$ This forms a simple separable first-order differential equation, for some constant $\\text{constant}$, yielding $$ \\log p(x) = {{ p '(1) } \\over { p(1) }} \\log x + \\text{constant} $$ Substituting $x = 1$ shows $\\text{constant} = \\log p(1)$. Defining $\\displaystyle \\alpha := - {{ p '(1) } \\over { p(1) }}$ gives us the desired equation, $$ \\begin{align*} \u0026amp; \\log p(x) = - \\alpha \\log x + \\log p(1) \\\\ \\implies \u0026amp; \\log p(x) = \\log x^{-\\alpha} + \\log p(1) \\\\ \\implies \u0026amp; \\log p(x) = \\log x^{-\\alpha} p(1) \\\\ \\implies \u0026amp; p(x) = p(1) x^{-\\alpha} \\end{align*} $$\n‚ñ†\n[b] Since $0 \u0026lt; \\alpha -1$, from $\\displaystyle \\int_{x_{0}}^{\\infty} C x^{-\\alpha} dx = 1$ we obtain $C = \\left( \\alpha - 1 \\right) x_{0}^{\\alpha - 1}$. Therefore, $$ \\begin{align*} E X^{k} =\u0026amp; \\int_{x_{0}}^{\\infty} x^{k} C x^{-\\alpha} dx \\\\ =\u0026amp; C \\int_{x_{0}}^{\\infty} x^{k-\\alpha} dx \\\\ =\u0026amp; \\left( \\alpha - 1 \\right) x_{0}^{\\alpha - 1} \\left[ {{ 1 } \\over { k - \\alpha + 1 }} x^{k - \\alpha + 1} \\right]_{x_{0}}^{\\infty} \\\\ =\u0026amp; \\left( \\alpha - 1 \\right) x_{0}^{\\alpha - 1} \\left( 0 - {{ 1 } \\over { k - \\alpha + 1 }} x_{0}^{k - \\alpha + 1} \\right) \\\\ =\u0026amp; {{ \\alpha - 1 } \\over { \\alpha - 1 - k }} x_{0}^{k} \\end{align*} $$\n‚ñ†\nVisualization The following is Julia code that displays the probability density function of the Pareto distribution as a GIF.\n@time using LaTeXStrings @time using Distributions @time using Plots cd(@__DIR__) x = 1:0.1:10 A = collect(0.5:0.01:3.5); append!(A, reverse(A)) animation = @animate for Œ± ‚àà A plot(x, pdf.(Pareto(Œ±), x), color = :black, label = \u0026#34;Œ± = $(round(Œ±, digits = 2))\u0026#34;, size = (400,300)) xlims!(0,5); ylims!(0,4); title!(L\u0026#34;\\mathrm{pdf\\,of\\,Pareto}(\\alpha)\u0026#34;) end gif(animation, \u0026#34;pdf.gif\u0026#34;) Newman. (2005). Power laws, Pareto distributions and Zipf\u0026rsquo;s law. https://doi.org/10.1080/00107510500052444\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://math.stackexchange.com/a/391311\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2181,"permalink":"https://freshrimpsushi.github.io/en/posts/2181/","tags":null,"title":"Pareto Distribution"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 To use the LaTeXStrings library, prefix strings with L, like so L\u0026quot;...\u0026quot;.\n@time using Plots\r@time using LaTeXStrings\rplot(0:0.1:2œÄ, sin.(0:0.1:2œÄ), xlabel = L\u0026#34;x\u0026#34;, ylabel = L\u0026#34;y\u0026#34;)\rtitle!(L\u0026#34;\\mathrm{TeX\\,representation:\\,} y = \\sin x , x \\in [0, 2 \\pi]\u0026#34;) Note that the package name is precisely LaTeXStrings and regular text does not work with \\text{}; instead, use \\mathrm{}. For spaces, use \\,.\nEnvironment OS: Windows julia: v1.7.0 https://discourse.julialang.org/t/latex-code-for-titles-labels-with-plots-jl/1967/18\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2180,"permalink":"https://freshrimpsushi.github.io/en/posts/2180/","tags":null,"title":"Using TeX in Plots in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Description julia\u0026gt; x = [1 2 3]\r1√ó3 Matrix{Int64}:\r1 2 3\rjulia\u0026gt; y = [1 2 3 4]\r1√ó4 Matrix{Int64}:\r1 2 3 4\rjulia\u0026gt; x .+ y\rERROR: DimensionMismatch Two vectors of different sizes cannot perform element-wise operations by default. To implement this manually, one would have to use a double for loop, but fortunately, it can be easily calculated by treating one as a row vector and the other as a column vector, returning a 2D array with element-wise operations. This is also possible in MATLAB or Python NumPy.\nDespite differing sizes, it does not result in an error, caution is needed to ensure that it does not lead to unintended calculations.\njulia\u0026gt; x\u0026#39; .+ y\r3√ó4 Matrix{Int64}:\r2 3 4 5\r3 4 5 6\r4 5 6 7\rjulia\u0026gt; x\u0026#39; .* y\r3√ó4 Matrix{Int64}:\r1 2 3 4\r2 4 6 8\r3 6 9 12\rjulia\u0026gt; x\u0026#39; ./ y\r3√ó4 Matrix{Float64}:\r1.0 0.5 0.333333 0.25\r2.0 1.0 0.666667 0.5\r3.0 1.5 1.0 0.75 It is also possible to use transpose(x) instead of x'.\nEnvironment OS: Windows10 Version: Julia 1.6.2 ","id":3207,"permalink":"https://freshrimpsushi.github.io/en/posts/3207/","tags":null,"title":"Performing Operations on Vectors of Different Sizes Component-wise in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 The coefficients of the Riemannian curvature tensor $R_{ijk}^{l}$ are defined as follows.\n$$ R_{ijk}^{l} = \\dfrac{\\partial \\Gamma_{ik}^{l}}{\\partial u^{j}} - \\dfrac{\\partial \\Gamma_{ij}^{l}}{\\partial u^{k}} + \\sum_{p} \\left( \\Gamma_{ik}^{p} \\Gamma_{pj}^{l} - \\Gamma_{ij}^{p}\\Gamma_{pk}^{l}\\right) \\text{ for } 1 \\le i,j,k,l \\le 2 $$\nHere, $\\Gamma_{ij}^{k}$ is the Christoffel symbol.\nExplanation Since Christoffel symbols are intrinsic, the Riemann curvature tensor is also intrinsic.\nThe so-called coefficients that appear in differential geometry do not depend on the coordinate system. We call these entities tensors.\nThe Gauss equation provides an extrinsic expression of $R_{ijk}^{l}$ from the perspective of the second fundamental form and the Weingarten map.\nTheorems Gauss\u0026rsquo;s Equations $$ R_{ijk}^{l} = L_{ik}L_{j}^{l} - L_{ij}L_{k}^{l} $$\nCodazzi-Mainardi Equations $$ \\dfrac{\\partial L_{ij}}{\\partial u^{k}_{}} - \\dfrac{\\partial L_{ik}}{\\partial u^{j}} = \\sum\\limits_{l} \\left( \\Gamma_{ik}^{l}L_{lj} - \\Gamma_{ij}^{l}L_{lk} \\right) $$\nHere, $L_{j}^{i}$ is a component of the matrix representation of the Weingarten map.\nProof Both equations are proved simultaneously. Let $\\mathbf{x} : U \\to \\R^{3}$ be a coordinate patch mapping. Let $(u^{1}, u^{2})$ be the coordinates of $U$.\nGauss\u0026rsquo;s Formula\n$$ \\mathbf{x}_{ij} = L_{ij} \\mathbf{n} + \\sum \\limits_{l=1}^{2} \\Gamma_{ij}^{l} \\mathbf{x}_{l} $$\nFirst, by Gauss\u0026rsquo;s formula, we obtain the following.\n$$ \\begin{align*} \\mathbf{x}_{i j k} \u0026amp;= \\dfrac{\\partial}{\\partial u^{k}}\\left( L_{ij} \\mathbf{n} + \\sum \\limits_{l=1}^{2} \\Gamma_{ij}^{l} \\mathbf{x}_{l} \\right) \\\\ \u0026amp;= \\frac{\\partial L_{ij}}{\\partial u^{k}}\\mathbf{n} + L_{i j} \\mathbf{n}_{k}+\\sum\\limits_{l} \\frac{\\partial \\Gamma_{i j}^{l}}{\\partial u^{k}} \\mathbf{x}_{l}+\\sum\\limits_{l}\\Gamma_{i j}^{l} \\mathbf{x}_{l k} \\end{align*} $$\nHere, since $\\mathbf{n}_{k} = \\mathbf{x}_{k}\\mathbf{n} = - L(\\mathbf{x}_{k}) = -\\sum\\limits_{l}L_{k}^{l}\\mathbf{x}_{l}$, the second term is $L_{ij}\\mathbf{n}_{k} = -\\sum\\limits_{l} L_{i j} L_{k}^{l} \\mathbf{x}_{l}$. Also, applying Gauss\u0026rsquo;s formula to the fourth term again,\n$$ \\sum\\limits_{l} \\Gamma_{ij}^{l} \\mathbf{x}_{l k} = \\sum\\limits_{l} \\Gamma_{i j}^{l}L_{lk} \\mathbf{n} + \\sum\\limits_{l,m}\\Gamma_{i j}^{l}\\Gamma_{lk}^{m} \\mathbf{x}_{m} $$\nSubstituting this, we obtain the following.\n$$ \\begin{align*} \\mathbf{x}_{i j k} \u0026amp;= \\frac{\\partial L_{ij}}{\\partial u^{k}}\\mathbf{n} -\\sum\\limits_{l} L_{i j} L_{k}^{l} \\mathbf{x}_{l} + \\sum\\limits_{l} \\frac{\\partial \\Gamma_{i j}^{l}}{\\partial u^{k}} \\mathbf{x}_{l} + \\sum\\limits_{l} \\Gamma_{i j}^{l}L_{lk} \\mathbf{n} + \\sum\\limits_{l,m}\\Gamma_{i j}^{l}\\Gamma_{lk}^{m} \\mathbf{x}_{m} \\\\ \u0026amp;= \\frac{\\partial L_{ij}}{\\partial u^{k}}\\mathbf{n} -\\sum\\limits_{l} L_{i j} L_{k}^{l} \\mathbf{x}_{l} + \\sum\\limits_{l} \\frac{\\partial \\Gamma_{i j}^{l}}{\\partial u^{k}} \\mathbf{x}_{l} + \\sum\\limits_{l} \\Gamma_{i j}^{l}L_{lk} \\mathbf{n} + \\sum\\limits_{p,l}\\Gamma_{i j}^{p}\\Gamma_{pk}^{l} \\mathbf{x}_{l} \\\\ \u0026amp;= \\left( \\frac{\\partial L_{ij}}{\\partial u^{k}} + \\sum\\limits_{l} \\Gamma_{i j}^{l}L_{lk} \\right)\\mathbf{n} + \\sum\\limits_{l} \\left(\\frac{\\partial \\Gamma_{i j}^{l}}{\\partial u^{k}} - L_{i j} L_{k}^{l} + \\sum\\limits_{p}\\Gamma_{i j}^{p}\\Gamma_{pk}^{l} \\right)\\mathbf{x}_{l} \\end{align*} $$\n$l,m$ is a dummy index, so we change the index of the last term to $(l,m) \\to (p,l)$ and grouped the terms. Similarly, we obtain the following.\n$$ \\mathbf{x}_{ikj} = \\left( \\frac{\\partial L_{ik}}{\\partial u^{j}} + \\sum\\limits_{l} \\Gamma_{i k}^{l}L_{lj} \\right)\\mathbf{n} + \\sum\\limits_{l} \\left(\\frac{\\partial \\Gamma_{i k}^{l}}{\\partial u^{j}} - L_{i k} L_{j}^{l} + \\sum\\limits_{p}\\Gamma_{i k}^{p}\\Gamma_{pj}^{l} \\right)\\mathbf{x}_{l} $$\nAssuming the coordinate patch mapping $\\mathbf{x}$ is sufficiently differentiable,\n$$ \\mathbf{x}_{i j k}=\\frac{\\partial^{3} \\mathbf{x}}{\\partial u^{k} \\partial u^{j} \\partial u^{i}}=\\frac{\\partial^{3} \\mathbf{x}}{\\partial u^{j} \\partial u^{k} \\partial u^{i}}=\\mathbf{x}_{i k j} $$\n$\\left\\{ \\mathbf{x}_{1}, \\mathbf{x}_{2}, \\mathbf{n} \\right\\}$ is the basis of $\\mathbb{R}^{3}$, so each component of $\\mathbf{x}_{ijk}$ and $\\mathbf{x}_{ikj}$ must be the same. Therefore, we obtain the following.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\frac{\\partial L_{ij}}{\\partial u^{k}} + \\sum\\limits_{l} \\Gamma_{i j}^{l}L_{lk} \u0026amp;= \\frac{\\partial L_{ik}}{\\partial u^{j}} + \\sum\\limits_{l} \\Gamma_{i k}^{l}L_{lj} \\\\ \\implies \u0026amp;\u0026amp; \\frac{\\partial L_{ij}}{\\partial u^{k}} - \\frac{\\partial L_{ik}}{\\partial u^{j}} \u0026amp;= \\sum\\limits_{l} \\left( \\Gamma_{i k}^{l}L_{lj} - \\Gamma_{i j}^{l}L_{lk} \\right) \\end{align*} $$\nThe Codazzi-Mainardi equations are proved. Continuing with the same logic, the following equality holds.\n$$ \\frac{\\partial \\Gamma_{i j}^{l}}{\\partial u^{k}} - L_{i j} L_{k}^{l} + \\sum\\limits_{p}\\Gamma_{i j}^{p}\\Gamma_{pk}^{l} = \\frac{\\partial \\Gamma_{i k}^{l}}{\\partial u^{j}} - L_{i k} L_{j}^{l} + \\sum\\limits_{p}\\Gamma_{i k}^{p}\\Gamma_{pj}^{l} $$\nWell organized, we get the following.\n$$ L_{i k} L_{j}^{l} - L_{i j} L_{k}^{l} = \\frac{\\partial \\Gamma_{i k}^{l}}{\\partial u^{j}} - \\frac{\\partial \\Gamma_{i j}^{l}}{\\partial u^{k}} + \\sum\\limits_{p} \\left( \\Gamma_{i k}^{p}\\Gamma_{pj}^{l} - \\Gamma_{i j}^{p}\\Gamma_{pk}^{l} \\right) = R_{ijk}^{l} $$\nThe Gauss\u0026rsquo;s equations are proved.\n‚ñ†\nSee Also Riemann curvature tensor on differentiable manifolds Richard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p141-142 Let $\\mathbf{x} : U \\to \\mathbb{R}^{3}$ be a coordinate patch mapping on the surface $M$. Let $(u^{1}, u^{2})$ be the coordinates of $U$. Given the Christoffel symbols $\\mathbf{x}$ and the coefficients of the second fundamental form $\\Gamma_{ij}^{k}$ at $L_{ij}$.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3206,"permalink":"https://freshrimpsushi.github.io/en/posts/3206/","tags":null,"title":"Riemann Curvature Tensor, Gauss Equation, and Codazzi-Mainardi Equation in Differential Geometry"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 If the browser is in dark mode, you can clearly see that the background has been rendered transparent.\nYou just need to insert the :transparent symbol into the background_color option. It saves well as *.png, but it is said that it doesn\u0026rsquo;t save well as *.pdf.\nusing Plots\rplot(rand(10), background_color = :transparent)\rpng(\u0026#34;example\u0026#34;) As you can guess from the option name, if you put in a color symbol, it will be output in that color. For example, a picture drawn with :yellow looks like this.\nEnvironment OS: Windows julia: v1.6.2 https://discourse.julialang.org/t/save-figure-with-transparent-background-color-in-plots-jl/18808/3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2173,"permalink":"https://freshrimpsushi.github.io/en/posts/2173/","tags":null,"title":"How to Make a Transparent Background in Graphics with Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Fill up to a Specific Value1 Using attributes fillrange=a, fillalpha=b, fillcolor=:color in plot(), it colors with :color to the value a from the plotted curve with the transparency b. It works the same by writing fill=(a,b,:color). That is, the following two codes are the same.\nplot(x,y, fillrange=a, fillalpha=b, fillcolor=:color)\rplot(x,y, fill=(a,b,:color)) It seems to be a bug, but selecting the value of fillrange as $(0,1)$ does not get colored.\nusing Plots\rrandom_walk = cumsum(rand(20).-.5)\rp1 = plot(random_walk,fill=(1,0.2,:lime), lw=3, legend=:bottomright)\rp2 = plot(random_walk,fill=(2,0.2,:tomato), lw=3, legend=:bottomright)\rplot(p1, p2) Filling Between Two Curves By putting one of the curve\u0026rsquo;s function values into fillalpha, the area between two curves gets colored.\nrw = random_walk\rplot([rw rw.+1],fill=(rw.+1,0.2,:lime), lw=3, legend=:bottomright) Filling Inside a Closed Curve The inside gets colored if fillalpha\u0026rsquo;s value is chosen not only from $(0,1)$.\ntheta = range(0,2pi, length=40)\rx = cos.(theta)\ry = sin.(theta)\rplot(x, y, fill=(1,0.2,:lime), xlim=(-3,3), ylim=(-1.5,1.5), size=(800,400), lw=3) Environment OS: Windows10 Version: Julia 1.6.2, Plots 1.23.6 http://docs.juliaplots.org/latest/attributes/#fill\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3203,"permalink":"https://freshrimpsushi.github.io/en/posts/3203/","tags":null,"title":"Methods for Coloring Up to a Certain Value from Curves in Julia / Between Two Curves / Inside a Closed Curve"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 Let\u0026rsquo;s consider the principal curvature at a point $p$ on a surface $M$ be denoted as $\\kappa_{1}, \\kappa_{2}$. Let $L$ be referred to as the Weingarten map. The Gaussian curvature $K$ is defined as follows:\n$$ K := \\kappa_{1} \\kappa_{2} = \\det L = \\det ([{L^{i}}_{j}]) $$\nwhere ${L^{i}}_{j} = \\sum \\limits_{k} L_{kj}g^{ki}$ applies.\nFormula The product of the principal curvatures $$ K = \\kappa_{1} \\kappa_{2} $$\nGaussian curvature can be expressed with the Riemann curvature tensor. $$\n$$\nGaussian curvature can be expressed with Christoffel symbols. $$ K = $$\nThe Gaussian curvature at point $p$ can be shown using the Gauss map and area of the domain. $$ K = \\lim\\limits_{\\mathscr{R} \\to p} \\dfrac{A(\\nu (\\mathscr{R}))}{A(\\mathscr{R})} $$\nTheorems $H^{2} \\ge K$ holds.\nLet $\\mathbf{X}, \\mathbf{Y}$ be the orthonormal vectors at point $p$. Then, the following is true:\n$$ H = \\dfrac{1}{2}\\left( II(\\mathbf{X}, \\mathbf{X}) + II(\\mathbf{Y}, \\mathbf{Y}) \\right) $$\nLet $\\mathbf{Y} \\in T_{p}M$ be the unit tangent vector, $\\kappa_{n}$ be the normal curvature, and $\\theta$ be the angle between the principal directions $\\mathbf{X}_{1}$ and $\\mathbf{Y}$. The following holds: $$ H = \\dfrac{1}{2\\pi}\\int_{0}^{2\\pi}\\kappa_{n}d\\theta $$\nProof 3. Given that $\\kappa_{n} = II(\\mathbf{Y}, \\mathbf{Y})$ and $II(\\mathbf{Y}, \\mathbf{Y}) = \\kappa_{1}\\cos^{2}\\theta + \\kappa_{2}\\sin^{2}\\theta$,\n$$ \\begin{align*} \\dfrac{1}{2\\pi}\\int_{0}^{2\\pi}\\kappa_{n}d\\theta \u0026amp;= \\dfrac{1}{2\\pi}\\int_{0}^{2\\pi} \\kappa_{1}\\cos^{2}\\theta + \\kappa_{2}\\sin^{2}\\theta d\\theta \\\\ \u0026amp;= \\dfrac{1}{2\\pi} \\left( \\kappa_{1} \\int_{0}^{2\\pi} \\cos^{2} d\\theta + \\kappa_{2} \\int_{0}^{2\\pi}\\sin^{2}\\theta d\\theta \\right) \\\\ \u0026amp;= \\dfrac{1}{2\\pi} \\left( \\kappa_{1} \\pi + \\kappa_{2} \\pi \\right) \\\\ \u0026amp;= \\dfrac{\\kappa_{1} + \\kappa_{2}}{2} \\\\ \u0026amp;= H \\end{align*} $$\n(Refer to trigonometric integral table $(2), (3)$)\n‚ñ†\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p130\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3200,"permalink":"https://freshrimpsushi.github.io/en/posts/3200/","tags":null,"title":"Gaussian Curvature and Mean Curvature"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 A prime number is a natural number $p \\ge 2$ that has only $1$ and $p$ as its divisors. A natural number $m \\ge 2$ that is not a prime number is called a composite number. Explanation According to the definition, $2$ is naturally a prime number.\nThe scope of numbers dealt with in Number Theory is quite broad, extending to rational numbers, but the actual subject of interest could justifiably be called \u0026lsquo;prime number theory\u0026rsquo; due to the concentrated focus. The reason being, composite numbers can be expressed as the product of other prime numbers, and if some properties are identified for prime numbers, generalizing those properties tends to be relatively straightforward, which explains why many theorems in number theory require prime numbers as a condition.\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p46.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2163,"permalink":"https://freshrimpsushi.github.io/en/posts/2163/","tags":null,"title":"Prime and Composite Numbers"},{"categories":"Í∏∞ÌïòÌïô","contents":"Buildup1 To know in which direction and how much a surface $M$ is curved, it is sufficient to know the normal curvatures $\\kappa_{n}$ in each direction. In other words, knowing all $\\kappa_{n}$ at point $p$ allows us to understand how $M$ is bent. The first step towards this is to think about the maximum and minimum values of $\\kappa_{n}$. The following theorem applies to the unit tangent curve $\\boldsymbol{\\gamma}$:\nLemma\nIf $\\mathbf{T}$ is the tangent field of the unit speed curve $\\boldsymbol{\\gamma}$, then $\\kappa_{n} = II (\\mathbf{T}, \\mathbf{T})$ holds.\nTherefore, our goal is to find the maximum and minimum values of $II(\\mathbf{X}, \\mathbf{X}) = \\kappa_{n}$ for the tangent vector $\\mathbf{X} \\in T_{p}M$. Here, $II$ is the second fundamental form.\nThis problem is, in other words, a maximization (minimization) problem of $II(\\mathbf{X}, \\mathbf{X})$ with the constraint $\\left\\langle \\mathbf{X}, \\mathbf{X} \\right\\rangle = 1$. Such problems can be solved by the Lagrange multipliers method. Then, the problem we need to solve changes from finding the maximum (minimum) values of $II(\\mathbf{X}, \\mathbf{X})$ to finding the maximum (minimum) values of the following $f$. Considering the Weingarten map $L$, since $II(\\mathbf{X}, \\mathbf{X}) = \\left\\langle L(\\mathbf{X}), \\mathbf{X} \\right\\rangle$,\n$$ \\begin{align*} f(\\mathbf{X}, \\lambda) \u0026amp;= II(\\mathbf{X}, \\mathbf{X}) - \\lambda (\\left\\langle \\mathbf{X}, \\mathbf{X} \\right\\rangle - 1) \\\\ \u0026amp;= \\left\\langle L(\\mathbf{X}), \\mathbf{X} \\right\\rangle - \\lambda\\left\\langle \\mathbf{X}, \\mathbf{X} \\right\\rangle + \\lambda\\\\ \u0026amp;= \\left\\langle L(\\mathbf{X}) - \\lambda \\mathbf{X}, \\mathbf{X} \\right\\rangle + \\lambda\\\\ \\end{align*} $$\nExpressing this in terms of coordinate chart mapping $\\mathbf{x}$ gives, $\\mathbf{X} = X^{1}\\mathbf{x}_{1} + \\mathbf{X}^{2}\\mathbf{x}_{2}$, $L(\\mathbf{x}_{k}) = \\sum\\limits_{l}{L^{l}}_{k}\\mathbf{x}_{l}$,\n$$ \\begin{align*} f(\\mathbf{X}, \\lambda) \u0026amp;= f(X^{1}, X^{2}, \\lambda) \\\\ \u0026amp;= \\lambda + \\left\\langle \\sum\\limits_{i,j} {L^{i}}_{j}X^{j}\\mathbf{x}_{i} - \\sum\\limits_{j}\\lambda X^{j}\\mathbf{x}_{j}, \\sum\\limits_{k}X^{k}\\mathbf{x}_{k} \\right\\rangle \\\\ \u0026amp;= \\lambda + \\left\\langle {L^{i}}_{j}X^{j}\\mathbf{x}_{i} - \\lambda X^{j}\\mathbf{x}_{j}, X^{k}\\mathbf{x}_{k} \\right\\rangle \u0026amp; \\text{by } \\href{https://freshrimpsushi.github.io/posts/einstein-notation}{\\text{Einstein notation}} \\\\ \u0026amp;= \\lambda + {L^{i}}_{j}X^{j}X^{k}\\left\\langle \\mathbf{x}_{i}, \\mathbf{x}_{k} \\right\\rangle - \\lambda X^{j}X^{k} \\left\\langle \\mathbf{x}_{j}, \\mathbf{x}_{k} \\right\\rangle \\\\ \u0026amp;= \\lambda + {L^{i}}_{j}X^{j}X^{k}g_{ik} - \\lambda X^{j}X^{k} g_{jk} \\\\ \u0026amp;= \\lambda + {L^{i}}_{j}X^{j}X^{k}g_{ik} - \\lambda X^{j}X^{k} \\delta_{ij}g_{ik} \\\\ \u0026amp;= \\lambda + ({L^{i}}_{j} - \\lambda \\delta_{ij}) X^{j}X^{k}g_{ik} \\end{align*} $$\n$\\delta$ is the Kronecker delta. By the method of Lagrange multipliers, we obtain $\\dfrac{\\partial f}{\\partial X^{l}} = 0$. Since $L_{jk} = \\sum\\limits_{l}{L^{l}}_{k}g_{lj}$,\n$$ \\begin{align*} 0 = \\dfrac{\\partial f}{\\partial X^{l}} \u0026amp;= \\sum\\limits_{ijk} ({L^{i}}_{j} - \\lambda \\delta_{ij})\\delta_{jl}X^{k}g_{ik} + \\sum\\limits_{ijk} ({L^{i}}_{j} - \\lambda \\delta_{ij})\\delta_{kl}X^{j}g_{ik} \\\\ \u0026amp;= \\sum\\limits_{ik} ({L^{i}}_{l} - \\lambda \\delta_{il})X^{k}g_{ik} + \\sum\\limits_{ij} ({L^{i}}_{j} - \\lambda \\delta_{ij})X^{j}g_{il} \\\\ \u0026amp;= \\sum\\limits_{ik} {L^{i}}_{l}X^{k}g_{ik} - \\sum\\limits_{ik}\\lambda \\delta_{il}X^{k}g_{ik} + \\sum\\limits_{ij} {L^{i}}_{j}X^{j}g_{il} - \\sum\\limits_{ij}\\lambda \\delta_{ij}X^{j}g_{il} \\\\ \u0026amp;= \\sum\\limits_{k} L_{kl}X^{k} - \\sum\\limits_{k}\\lambda X^{k}g_{lk} + \\sum\\limits_{j} L_{lj}X^{j} - \\sum\\limits_{j}\\lambda X^{j}g_{jl} \\\\ \u0026amp;= \\sum\\limits_{j} \\left( L_{jl}X^{j} - \\lambda X^{j}g_{lj} + L_{lj}X^{j} - \\lambda X^{j}g_{jl} \\right) \\\\ \u0026amp;= 2\\sum\\limits_{j} \\left( L_{jl}X^{j} - \\lambda X^{j}g_{lj} \\right) = 2\\sum\\limits_{j}L_{jl}X^{j} - 2\\sum\\limits_{j}\\lambda X^{j}g_{lj} \\\\ \u0026amp;= 2\\sum\\limits_{j}L_{jl}X^{j} - 2\\sum\\limits_{j}\\lambda X^{j}g_{lj} \\\\ \u0026amp;= 2\\sum\\limits_{ij}{L^{i}}_{j}X^{j}g_{il} - 2\\sum\\limits_{ij}\\lambda X^{j}\\delta_{ij}g_{li} \\\\ \u0026amp;= 2\\sum\\limits_{ij}\\left( {L^{i}}_{j} - \\lambda\\delta_{ij} \\right)X^{j}g_{li} \\\\ \\end{align*} $$\n$$ \\implies \\sum\\limits_{ij}\\left( {L^{i}}_{j} - \\lambda\\delta_{ij} \\right)X^{j}g_{li} = 0 $$\nTherefore, for all $Y^{l}$, we obtain the following.\n$$ \\sum\\limits_{ijl}\\left( {L^{i}}_{j} - \\lambda\\delta_{ij} \\right)X^{j}Y^{l}g_{li} = 0 $$\nThis means that $\\forall \\mathbf{Y}=\\sum\\limits_{l}Y^{l}\\mathbf{x}_{l}$,\n$$ \\begin{align*} \\left\\langle L(\\mathbf{X}) - \\lambda \\mathbf{X}, \\mathbf{Y} \\right\\rangle \u0026amp;= \\left\\langle L\\left( \\sum\\limits_{j}X^{j}\\mathbf{x}_{j} \\right) - \\sum\\limits_{i}\\lambda X^{i} \\mathbf{x}_{i}, \\sum\\limits_{l}Y^{l}\\mathbf{x}_{l} \\right\\rangle \\\\ \u0026amp;= \\left\\langle \\sum\\limits_{ij}{L^{i}}_{j}X^{j}\\mathbf{x}_{i} - \\sum\\limits_{ij}\\lambda \\delta_{ij} X^{j} \\mathbf{x}_{i}, \\sum\\limits_{l}Y^{l}\\mathbf{x}_{l} \\right\\rangle \\\\ \u0026amp;= \\sum\\limits_{ijl}{L^{i}}_{j}X^{j}Y^{l}\\left\\langle \\mathbf{x}_{i}, \\mathbf{x}_{l} \\right\\rangle - \\sum\\limits_{ijl}\\lambda \\delta_{ij}X^{j}Y^{l}\\left\\langle \\mathbf{x}_{i}, \\mathbf{x}_{l} \\right\\rangle \\\\ \u0026amp;= \\sum\\limits_{ijl}({L^{i}}_{j} - \\lambda \\delta_{ij} )X^{j}Y^{l}g_{il} \\\\ \u0026amp;= 0 \\end{align*} $$\nHence, we obtain the following.\n$$ \\dfrac{\\partial f}{\\partial X^{l}} = 0 \\implies \\left\\langle L(\\mathbf{X}) - \\lambda \\mathbf{X}, \\mathbf{Y} \\right\\rangle = 0\\quad \\forall \\mathbf{Y} \\implies L(\\mathbf{X}) = \\lambda \\mathbf{X} $$\nTherefore, $\\lambda$ is an eigenvalue of $L$, and $\\mathbf{X}$ is the corresponding eigenvector. In particular, $\\mathbf{X}$ must satisfy the constraint $\\left\\langle \\mathbf{X}, \\mathbf{X} \\right\\rangle = 1$, hence it is a unit eigenvector.\nTherefore, it is concluded that for the two unit eigenvectors, $II(\\mathbf{X}, \\mathbf{X})$ takes the maximum (minimum) value.\nMoreover, let $B = \\left\\{ \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\}$ and, for convenience, represent the matrix representation of $L$ with the same notation as $L$, denoted by $L \\equiv \\left[ L \\right]_{B}$, then $\\lambda$ is the solution of the following equation.\n$$ \\begin{equation} \\begin{aligned} \\det(L - \\lambda I) \u0026amp;= (\\lambda - {L^{1}}_{1})(\\lambda - {L^{2}}_{2}) - {L^{1}}_{2}{L^{2}}_{1} \\\\ \u0026amp;= \\lambda^{2} - ({L^{1}}_{1}{L^{2}}_{2})\\lambda + ({L^{1}}_{1}{L^{2}}_{2} - {L^{1}}_{2}{L^{2}}_{1}) \\\\ \u0026amp;= \\lambda^{2} - \\tr(L) \\lambda + \\det(L) \\\\ \u0026amp;= 0 \\end{aligned} \\label{1} \\end{equation} $$\nLet\u0026rsquo;s denote the two solutions (eigenvalues) as $\\kappa_{1}, \\kappa_{2}$ ($\\kappa_{1} \\ge \\kappa_{2}$). The following theorem states that these two values are indeed the minimum and maximum values of $\\kappa_{n}$.\nTheorem On each point of the surface $M$, there exist 1. directions where the normal curvature is maximum and minimum, respectively, and 2. two directions that are orthogonal to each other.\nProof The two eigenvalues of $L$ are respectively the maximum and minimum values of the normal curvature. Following the discussion above, the normal curvature at point $p$ on $M$ in the direction of the eigenvectors of $L$ takes the maximum and minimum values. Let\u0026rsquo;s call the two eigenvalues of $L$ at point $p$ $\\kappa_{1}, \\kappa_{2}(\\kappa_{1} \\ge \\kappa_{2})$, and the corresponding eigenvectors $\\mathbf{X}_{1}, \\mathbf{X}_{2}$. Then, the maximum and minimum values of the normal curvature are as follows.\n$$ \\kappa_{n} = II(\\mathbf{X}_{i}, \\mathbf{X}_{i}) = \\left\\langle L(\\mathbf{X}_{i}), \\mathbf{X}_{i} \\right\\rangle = \\left\\langle \\kappa_{i}\\mathbf{X}_{i}, \\mathbf{X}_{i} \\right\\rangle = \\kappa_{i}\\left\\langle \\mathbf{X}_{i}, \\mathbf{X}_{i} \\right\\rangle = \\kappa_{i} $$\nTherefore, the larger eigenvalue $\\kappa_{1}$ is the maximum normal curvature, and the smaller value $\\kappa_{2}$ is the minimum normal curvature.\nThe two eigenvectors are orthogonal to each other. $\\kappa_{1} \\ne \\kappa_{2}$ In this case, since $L$ is self-adjoint,\n$$ \\kappa_{1} \\left\\langle \\mathbf{X}_{1}, \\mathbf{X}_{2} \\right\\rangle = \\left\\langle L(\\mathbf{X}_{1}), \\mathbf{X}_{2} \\right\\rangle = \\left\\langle \\mathbf{X}_{1}, L(\\mathbf{X}_{2}) \\right\\rangle = \\left\\langle \\mathbf{X}_{1}, \\kappa_{2} \\mathbf{X}_{2} \\right\\rangle = \\kappa_{2} \\left\\langle \\mathbf{X}_{1}, \\mathbf{X}_{2} \\right\\rangle \\\\ \\implies (\\kappa_{1} - \\kappa_{2}) \\left\\langle \\mathbf{X}_{1}, \\mathbf{X}_{2} \\right\\rangle = 0 $$\nBy assumption, $\\left\\langle \\mathbf{X}_{1}, \\mathbf{X}_{2} \\right\\rangle = 0$\n$\\kappa_{1} = \\kappa_{2}$ Lemma\nLet\u0026rsquo;s say $\\lambda$, $\\mathbf{X}$ are the eigenvalue and eigenvector of $L$ at point $p$ on surface $M$, respectively. Assuming the unit tangent vector $\\mathbf{Y} \\in T_{p}M$ satisfies $\\left\\langle \\mathbf{X}, \\mathbf{Y} \\right\\rangle = 0$. Then $\\mathbf{Y}$ is also an eigenvector.\nProof\nBy assumption, $\\left\\{ \\mathbf{X}, \\mathbf{Y} \\right\\}$ forms a basis of $T_{p}M$. Since $L$ is self-adjoint,\n$$ 0 = \\left\\langle \\lambda \\mathbf{X}, \\mathbf{Y} \\right\\rangle = \\left\\langle L(\\mathbf{X}), \\mathbf{Y} \\right\\rangle = \\left\\langle \\mathbf{X}, L(\\mathbf{Y}) \\right\\rangle = \\left\\langle \\mathbf{X}, a_{1} \\mathbf{X} + a_{2} \\mathbf{Y} \\right\\rangle $$\nTherefore, $a_{1}=0$ holds, and since $L(\\mathbf{Y}) = a_{2}\\mathbf{Y}$, $\\mathbf{Y}$ is also an eigenvector.\n‚ñ†\nAccording to the lemma, a unit vector orthogonal to $\\mathbf{X}_{1}$ is also an eigenvector. Therefore, it can be chosen as $\\mathbf{X}_{2}$.\n‚ñ†\nDefinition The eigenvalues $\\kappa_{1}, \\kappa_{2}$ of the Weingarten map $L$ defined at point $p\\in M$ are called the principal curvatures at point $p$ on the surface $M$. The eigenvectors of $L$ are called the principal directions at point $p$.\nA point where the two principal curvatures $\\kappa_{1}, \\kappa_{2}$ are equal is called an umbilic.\nIf the tangent vector at every point of a curve is the principal direction at that point on the surface $M$, then the curve is a line of curvature on a surface $M$.\nExplanation According to the discussion above, the larger (smaller) principal curvature is the maximum (minimum) normal curvature at point $p$.\nAll points of $S^{2}$ and $\\mathbb{R}^{2}$ are umbilics. [The converse is also true.]\nIn $\\eqref{1}$, by the relationship between roots and coefficients, $\\kappa_{1} \\kappa_{2} = \\det L$ holds, and this is called the Gaussian curvature. Also, $\\dfrac{\\kappa_{1} + \\kappa_{2}}{2} = \\dfrac{\\tr{L}}{2}$ is called the mean curvature.\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p127-129\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3194,"permalink":"https://freshrimpsushi.github.io/en/posts/3194/","tags":null,"title":"Curvature of a Principal Curve"},{"categories":"ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç","contents":"Code import pandas as pd\rdata = { \u0026#39;ÎÇòÏù¥\u0026#39; : [26,23,22,22,21,21,20,20,20,20,18,17], \u0026#39;ÌÇ§\u0026#39; : [160, 163, 163, 162, 164, 163, 164, 150, 158, 162, 172, 173], \u0026#39;Î≥ÑÎ™Ö\u0026#39; : [\u0026#39;Îï°Î™®\u0026#39;, \u0026#39;ÍπÄÏø†Îùº\u0026#39;, \u0026#39;Í¥ëÎ∞∞\u0026#39;, \u0026#39;Ïò§Î¶¨\u0026#39;, \u0026#39;ÍπÉÌÑ∏\u0026#39;, \u0026#39;ÏåàÎ¨¥\u0026#39;, \u0026#39;Î∞çÍµ¨Î¶¨\u0026#39;, \u0026#39;ÎÇòÎ∂ÄÌÇ§ ÏïºÏΩî\u0026#39;, \u0026#39;ÏõîÌÅ¥ÌÜ†ÎØ∏\u0026#39;, \u0026#39;Ï™ºÏú®\u0026#39;, \u0026#39;ÏïàÎåïÎåï\u0026#39;, \u0026#39;ÏõåÎá®\u0026#39;], \u0026#39;Íµ≠Ï†Å\u0026#39; : [\u0026#39;ÌïúÍµ≠\u0026#39;, \u0026#39;ÏùºÎ≥∏\u0026#39;, \u0026#39;ÌïúÍµ≠\u0026#39;, \u0026#39;ÌïúÍµ≠\u0026#39;, \u0026#39;ÌïúÍµ≠\u0026#39;, \u0026#39;ÌïúÍµ≠\u0026#39;, \u0026#39;ÌïúÍµ≠\u0026#39;, \u0026#39;ÌïúÍµ≠\u0026#39;, \u0026#39;ÏùºÎ≥∏\u0026#39;, \u0026#39;ÏùºÎ≥∏\u0026#39;, \u0026#39;ÌïúÍµ≠\u0026#39;, \u0026#39;ÌïúÍµ≠\u0026#39;] }\rindexName = [\u0026#39;Í∂åÏùÄÎπÑ\u0026#39;,\u0026#39;ÎØ∏ÏïºÏôÄÌÇ§ ÏÇ¨Ïø†Îùº\u0026#39;,\u0026#39;Í∞ïÌòúÏõê\u0026#39;, \u0026#39;ÏµúÏòàÎÇò\u0026#39;, \u0026#39;Ïù¥Ï±ÑÏó∞\u0026#39;, \u0026#39;ÍπÄÏ±ÑÏõê\u0026#39;, \u0026#39;ÍπÄÎØºÏ£º\u0026#39;, \u0026#39;ÏïºÎ∂ÄÌÇ§ ÎÇòÏΩî\u0026#39;, \u0026#39;ÌòºÎã§ ÌûàÌÜ†ÎØ∏\u0026#39;, \u0026#39;Ï°∞Ïú†Î¶¨\u0026#39;, \u0026#39;ÏïàÏú†ÏßÑ\u0026#39;, \u0026#39;Ïû•ÏõêÏòÅ\u0026#39;]\rdf = pd.DataFrame(data, index = indexName) The labels of the columns are obtained as .columns.\n\u0026gt;\u0026gt;\u0026gt; df.columns Index([\u0026#39;ÎÇòÏù¥\u0026#39;, \u0026#39;ÌÇ§\u0026#39;, \u0026#39;Î≥ÑÎ™Ö\u0026#39;, \u0026#39;Íµ≠Ï†Å\u0026#39;], dtype=\u0026#39;object\u0026#39;) \u0026gt;\u0026gt;\u0026gt; df.columns[2] \u0026#39;Î≥ÑÎ™Ö\u0026#39; The label of the row is obtained as .index. Note that it is not `.rows``.\n\u0026gt;\u0026gt;\u0026gt; df.index Index([\u0026#39;Í∂åÏùÄÎπÑ\u0026#39;, \u0026#39;ÎØ∏ÏïºÏôÄÌÇ§ ÏÇ¨Ïø†Îùº\u0026#39;, \u0026#39;Í∞ïÌòúÏõê\u0026#39;, \u0026#39;ÏµúÏòàÎÇò\u0026#39;, \u0026#39;Ïù¥Ï±ÑÏó∞\u0026#39;, \u0026#39;ÍπÄÏ±ÑÏõê\u0026#39;, \u0026#39;ÍπÄÎØºÏ£º\u0026#39;, \u0026#39;ÏïºÎ∂ÄÌÇ§ ÎÇòÏΩî\u0026#39;, \u0026#39;ÌòºÎã§ ÌûàÌÜ†ÎØ∏\u0026#39;, \u0026#39;Ï°∞Ïú†Î¶¨\u0026#39;, \u0026#39;ÏïàÏú†ÏßÑ\u0026#39;, \u0026#39;Ïû•ÏõêÏòÅ\u0026#39;], dtype=\u0026#39;object\u0026#39;) \u0026gt;\u0026gt;\u0026gt; df.index[10] \u0026#39;ÏïàÏú†ÏßÑ\u0026#39; ","id":3189,"permalink":"https://freshrimpsushi.github.io/en/posts/3189/","tags":null,"title":"How to Get Column and Row Labels of Data Frame in Python Pandas"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 == compares whether values are the same, and === operates differently depending on whether the values to be compared are Mutable or not.\nMutable: Checks if both terms refer to the same object, in other words, it returns whether the two variables can be programmatically distinguished or not. Immutable: Checks if both terms are of the same type, Checks if both terms have the same structure, And recursively checks if each element is == the same. julia\u0026gt; X = 1; Y = 1;\rjulia\u0026gt; X == Y\rtrue\rjulia\u0026gt; X === Y\rtrue\rjulia\u0026gt; X = [1]; Y = [1];\rjulia\u0026gt; X == Y\rtrue\rjulia\u0026gt; X === Y\rfalse For example, looking at the above execution result commonly seen in Python, the integer 1 is Immutable and programmatically indistinguishable, so both == and === return true. However, when looking at an array containing only 1, if a new element is added to X, X and Y can become different because they are Mutable, so == returns true for simply comparing values, while === returns false for comparing the objects themselves.\nYou can understand enough just by grasping this usage even if you don\u0026rsquo;t really know what objects mean.\nOptimization In Julia, which has weak object orientation, such differences are not significantly impactful. From the perspective of code optimization, the comparison of == and === shows the following level of performance difference in the comparison of Singletons.\nN = 10^7\rx = rand(0:9, N)\rjulia\u0026gt; @time for t ‚àà 1:N\rx[t] == 0\rend\r1.292501 seconds (30.00 M allocations: 610.336 MiB, 2.63% gc time)\rjulia\u0026gt; @time for t ‚àà 1:N\rx[t] === 0\rend\r1.016211 seconds (30.00 M allocations: 610.336 MiB, 2.77% gc time) A value is usually Immutable, so it\u0026rsquo;s understood that === is faster than ==.\nSuch differences might not be significant in most cases. Needless to say, non-Iterative tasks are much faster, like the following vector operations, where speed differences are negligible or none.\njulia\u0026gt; @time x .== 0;\r0.009509 seconds (6 allocations: 1.196 MiB)\rjulia\u0026gt; @time x .=== 0;\r0.009478 seconds (6 allocations: 1.196 MiB) Environment OS: Windows julia: v1.6.1 https://stackoverflow.com/a/38638838/12285249\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2157,"permalink":"https://freshrimpsushi.github.io/en/posts/2157/","tags":null,"title":"The Difference Between == and === in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 Let $M$ be a surface, and $p \\in M$ be a point on the surface. The map $L : T_{p}M \\to \\mathbb{R}^{3}$, defined as follows, is called the Weingarten map.\n$$ L (\\mathbf{X}) = - \\mathbf{X}\\mathbf{n} $$\nHere, $\\mathbf{X} \\in T_{p}M$ is a tangent vector, $\\mathbf{n}$ is a unit normal, and $\\mathbf{X}\\mathbf{n}$ is the directional derivative of $\\mathbf{n}$.\nProperties $L$ is a linear transformation that is $L : T_{p}M \\to T_{p}M$.\nSince $\\left\\{ \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\}$ is a basis for $T_{p}M$, if we denote it as $L(\\mathbf{x}_{k}) = \\sum\\limits_{l}{L^{l}}_{k}\\mathbf{x}_{l}$, the following holds:\n$${L^{l}}_{k} = \\sum_{i}L_{ik}g^{il} = \\sum_{i}L_{ki}g^{il}$$\nWhere, $L_{ij}$ is the coefficient of the second fundamental form, and $[g^{kl}]$ is the inverse matrix of the first fundamental form coefficients. When expressed as a matrix,\n$$ \\begin{bmatrix} {L^{l}}_{k} \\end{bmatrix} = \\begin{bmatrix} {L^{1}}_{1} \u0026amp; {L^{1}}_{2} \\\\ {L^{2}}_{1} \u0026amp; {L^{2}}_{2} \\end{bmatrix} = \\begin{bmatrix} g^{li} \\end{bmatrix} \\begin{bmatrix} L_{ik} \\end{bmatrix} $$\nExplanation The minus sign in the definition is there for convenience.\nThe Weingarten map can be understood as an operator that measures the rate of change of $\\mathbf{n}$ in each tangent direction at each point $p$. For this reason, it is also referred to as a shape operator.\nBy definition, $L$ is defined as a map that sends $T_{p}M$ to $\\mathbb{R}^{3}$, but in fact, it can be seen that it sends it to $T_{p}M$.\nIn other words, ${L^{l}}_{k}$ is the coefficient of the $l$-th basis of $L(\\mathbf{x_{k}})$. That is, if expressed as a coordinate vector for the basis $B = \\left\\{ \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\}$, it is as follows. $$ L(\\mathbf{x}_{k}) = {L^{1}}_{k}\\mathbf{x}_{1} + {L^{2}}_{k}\\mathbf{x}_{2} $$ $$ \\left[ L(\\mathbf{x}_{k}) \\right]_{B} = \\begin{bmatrix} {L^{1}}_{k} \\\\ {L^{2}}_{k} \\end{bmatrix} $$ Therefore, the matrix representation of $L$ is as follows. $$ [L]_{B} = \\begin{bmatrix} {L^{1}}_{1} \u0026amp; {L^{1}}_{2} \\\\ {L^{2}}_{1} \u0026amp; {L^{2}}_{2} \\end{bmatrix} $$ Furthermore, due to the properties of the first fundamental form, the following holds. $$ L_{ij} = \\sum_{l}L_{il}\\delta_{lj} = \\sum\\limits_{l,k} L_{il}g^{lk}g_{kj} = \\sum\\limits_{l,k} L_{li}g^{lk}g_{kj} = \\sum\\limits_{k}{L^{k}}_{i}g_{kj} $$\nSince $L$ is a linear transformation between finite-dimensional vector spaces, $\\tr{L}$ and $\\det(L)$ are invariants, and are respectively called the mean curvature and the Gaussian curvature.\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p125\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3188,"permalink":"https://freshrimpsushi.github.io/en/posts/3188/","tags":null,"title":"Bingarten Map"},{"categories":"ÌôïÎ•†ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Model 1 At time point $t$, let\u0026rsquo;s say the price of $S_{t}$ units of the underlying asset $1$, and assume that $S_{t}$ undergoes Geometric Brownian Motion. That is, for Standard Brownian Motion $W_{t}$, drift $\\mu \\in \\mathbb{R}$, and diffusion $\\sigma^{2} \u0026gt; 0$, $S_{t}$ is the solution to the following Stochastic Differential Equation. $$ d S_{t} = S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right) $$ When a risk-free rate $r \\in \\mathbb{R}$ is given, the price $F = F \\left( t, S_{t} \\right)$ of $1$ units of the derivative at time $t$ follows the following [Partial Differential Equation](../../categories/Partial Differential Equations). $$ r F = {{ \\partial F } \\over { \\partial t }} + r S_{t} {{ \\partial F } \\over { \\partial S_{t} }} + {{ 1 } \\over { 2 }} \\sigma^{2} S_{t}^{2} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} $$\nVariables $F \\left( t, S_{t} \\right)$: Derivatives refer to financial instruments such as futures and options. $S_{t}$: Underlying Assets are the commodities traded in derivatives, such as currency, bonds, and stocks. Parameters $r \\in \\mathbb{R}$: Represents the interest rate of Risk-free Assets. A typical example of a risk-free asset is a deposit. $\\sigma^{2} \u0026gt; 0$: Represents the market\u0026rsquo;s Volatility. Explanation Contrary to common misconceptions about derivatives, futures and options were created as means of hedging against uncertain futures. It was a way to reduce risk by paying a certain premium, even if it cost a bit. The problem was the lack of an appropriate method to price them, and traders traded derivatives based on experience. The Black-Scholes model is an equation that made it possible to mathematically explain the price of such derivatives.\nCommonly, the contributors to the Black-Scholes model (1973) are cited as Fischer Black, Myron Scholes, and Robert K. Merton, who introduced the \u0026lsquo;hedge-based derivation\u0026rsquo; in this post. Unfortunately, Black passed away in 1995, and Scholes and Merton were awarded the Nobel Prize in Economics in 1997. After the discovery of the Black-Scholes-Merton equation, the options market developed dazzlingly, and a new sub-discipline called financial engineering emerged in academia.\nThe Comedy of Black According to Wikipedia2, Black frequently changed majors during his PhD studies and had trouble settling down in one field. He switched from physics to mathematics, to computer science, and to artificial intelligence, but eventually made a significant contribution in economics.\nAlthough no reliable reference was found, it is said that Black, during his physics major, realized he couldn\u0026rsquo;t survive among the surrounding geniuses and became a pioneer in economics/finance, where there were no pioneers actively using mathematics, thus making a name for himself in a wasteland without science monsters.\nThe Tragedy of Scholes According to Namuwiki3, Scholes caused a sensation at the 1997 Nobel Economics Prize press conference by saying he would invest the prize money in stocks. The hedge fund Scholes was managing went bankrupt in 1998 due to overconfidence and excessive leverage, following Russia\u0026rsquo;s default. After the crisis, Scholes managed to return profits to investors and continued as a fund manager until retiring just before the subprime mortgage crisis erupted.\nAssumptions Before delving into the derivation, let\u0026rsquo;s check some assumptions.\nFactors such as commissions, taxes, and dividends are not considered Think of it as not considering resistance, temperature, or atmospheric pressure in a physics model, which are not the focus of the study. Additionally, it\u0026rsquo;s assumed that the trend $\\mu$ and $\\sigma$ are simply constants.\nDerivatives depend on the underlying assets and timing If the price of a derivative is independent of the underlying asset, there\u0026rsquo;s no need to use the terms \u0026lsquo;derivative\u0026rsquo; and \u0026lsquo;underlying\u0026rsquo;. It\u0026rsquo;s reasonable for the price of a derivative to change as the price of the underlying asset changes. If it doesn\u0026rsquo;t change over time (if it\u0026rsquo;s constant), then there\u0026rsquo;s no point in pondering the price of a derivative. Thus, it\u0026rsquo;s assumed that $F$ is a function of at least two factors $t$ and $S_{t}$, even if we can\u0026rsquo;t specify the exact form. $$ F = F \\left( t, S_{t} \\right) $$\nThe underlying asset undergoes Geometric Brownian Motion The primary application of Geometric Brownian Motion GBM is to explain the price fluctuations of underlying assets like stock prices. It assumes that the change in asset prices is proportional to the asset\u0026rsquo;s price, and that the price cannot become negative unless the asset is delisted, among other favorable assumptions. $$ d S_{t} = S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right) $$\nLet\u0026rsquo;s assume the price $p_{t}$ of some stock follows GBM. The return, defined as taking the log of dividing the closing price on day $t$ by the closing price on day $t-1$, $$ r_{t} = \\nabla \\log p_{t} = \\log {{ p_{t} } \\over { p_{t-1} }} $$ aligns with our intuition that the return should be positive if the price increases and negative if it decreases, regardless of the stock\u0026rsquo;s size. As explained in the \u0026ldquo;Log-normal Distribution\u0026rdquo; section, this return follows a normal distribution, focusing on the essence of growth and decay rather than simple fluctuations.\nRisk-free assets grow according to Malthusian growth The Malthusian growth model is the simplest model describing the growth of a population without any limitations or interventions and can be used as an assumption to explain the proliferation of risk-free assets in economics/finance. The risk-free rate is assumed to be a constant $r$, and the financial income is proportional to the size of asset $N_{t}$, so it can be expressed by the following [Ordinary Differential Equation](../../categories/Ordinary Differential Equations). $$ {{ d V_{t} } \\over { d t }} = r V_{t} $$\nArbitrage-free pricing: There\u0026rsquo;s no value difference between portfolios A mathematical explanation of the portfolio will be further detailed in this proof. The assumption of arbitrage-free pricing means that all portfolios we consider are balanced at the same value. For instance, if the value of portfolio $A$ is higher than $B$, a rational market participant would increase the proportion of the more valuable $A$ to make a profit, so there\u0026rsquo;s no reason to consider $B$. Therefore, it\u0026rsquo;s assumed that the portfolios we consider are already in a state where no further profits can be made through such arbitrage.\nFrictionless market: There are no restrictions on division and short selling Anyone who has traded stocks knows that there are minimum bidding units, so you can\u0026rsquo;t trade exactly the amount you want, and there are restrictions on short selling in the Korean stock market, where borrowed short selling (borrowing stocks) is the principle. Being able to divide trading units as desired and short sell without any restrictions can be considered as having no friction opposing actions.\nDerivation Part 1. Portfolio Composition\nLet\u0026rsquo;s assume we can only hold three types of assets:\nUnderlying Asset: Let\u0026rsquo;s say we hold $s$ units. Derivative: Let\u0026rsquo;s say we hold $f$ units. Risk-free Asset: An asset that is neither an underlying asset nor a derivative, which can be considered as cash. If we denote the value of all assets we hold at time $t$ as $V_{t}$, and if $S_{t}$ was the price of $1$ units of the underlying asset and $F \\left( t , S_{t} \\right)$ was the price of $1$ units of the derivative, it can be represented as follows. $$ V_{t} = f F \\left( t, S_{t} \\right) + s S_{t} $$ Composing a portfolio means adjusting the amounts of $f$ and $s$, in other words, strategizing on how to invest. Assuming that the trading volume generated by such portfolio composition significantly affects the market is irrational, so the prices of the underlying asset and derivative are independent of the choices of $f$ and $s$. In other words, the mathematical discussions that follow do not change regardless of how $f$ and $s$ are determined.\nIt\u0026rsquo;s important to note that $V_{t}$ is not the sum of the total assets. It\u0026rsquo;s easier to understand if you think of it as looking only at the stock balance, not the cash account. Let\u0026rsquo;s think about what portfolios could be:\nSavings $V_{t} = 0$: Clear the stock account and put everything into savings to receive interest. It might seem trivial to a scholar who knows nothing but mathematics, but it\u0026rsquo;s a legitimate strategy for dealing with market crashes or recessions. Individual Investor $V_{t} = 5 S_{t}$: Individuals should not touch derivatives. Most individual investors in countries where short selling is banned have this type of portfolio. For example, if $S_{t} = 81,200$ is the stock price of Samsung Electronics, this portfolio is my friend \u0026lsquo;Kim Soo-hyung\u0026rsquo;s account holding $5$ shares of Samsung Electronics. Hedge $\\displaystyle V_{t} = 1 \\cdot F- {{ \\partial F } \\over { \\partial S_{t} }} \\cdot S_{t}$: Consider buying a call option $1$ and short selling the underlying asset ${{ \\partial F } \\over { \\partial S_{t} }}$. If the price of the underlying asset increases significantly on the expiration date of the option, the call option will bring in a large profit, and if the price of the underlying asset falls, profit will have been made from the short sale early on. The options mentioned in the explanation of hedging and to be covered later are European Options, which are usually known as \u0026lsquo;options that can only be exercised on the expiration date\u0026rsquo;. American Options can be exercised at any time before maturity, but that\u0026rsquo;s not our concern here, so don\u0026rsquo;t be intimidated by the terms European and American.\nWe will derive the Black-Scholes equation from the last example, a portfolio that hedges a derivative with a spot short sale $$ V_{t} = 1 \\cdot F \\left( t, S_{t} \\right) - {{ \\partial F } \\over { \\partial S_{t} }} \\cdot S_{t} $$ Since it\u0026rsquo;s perfectly hedged, this portfolio is a risk-free asset, and the increment over time $t$ is $$ d V_{t} = d F - {{ \\partial F } \\over { \\partial S_{t} }} d S_{t} $$ Here, since $S_{t}$ is assumed to follow Geometric Brownian Motion, substituting $d S_{t}$ for $\\displaystyle S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right)$ yields $$ d V_{t} = d F - {{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right) $$ Considering the assumption of arbitrage-free pricing, the increment of this portfolio should be the same as that of a risk-free asset portfolio. If we assume there\u0026rsquo;s a price difference between the portfolios, profit could be made by liquidating one portfolio and investing in the other. Since we assumed risk-free assets grow according to Malthusian growth, the risk-free rate $r$ can be expressed by the following [Ordinary Differential Equation](../../categories/Ordinary Differential Equations). $$ {{ d V_{t} } \\over { d t }} = r V_{t} $$ Organizing these, we get $$ \\begin{align*} d V_{t} =\u0026amp; d F - {{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right) \\\\ d V_{t} =\u0026amp; r V_{t} dt \\end{align*} $$ thus, $$ \\begin{equation} r V_{t} dt = d F - {{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right) \\label{1} \\end{equation} $$ is obtained. Now, let\u0026rsquo;s use It√¥ calculus to find $dF$.\nPart 2. It√¥ Calculus\nIt√¥\u0026rsquo;s Lemma: Given an It√¥ Process $\\left\\{ X_{t} \\right\\}_{t \\ge 0}$, $$ d X_{t} = u dt + v d W_{t} $$ for function $V \\left( t, X_{t} \\right) = V \\in C^{2} \\left( [0,\\infty) \\times \\mathbb{R} \\right)$, if we set $Y_{t} := V \\left( t, X_{t} \\right)$, then $\\left\\{ Y_{t} \\right\\}$ is also an It√¥ Process, and the following holds. $$ \\begin{align*} d Y_{t} =\u0026amp; V_{t} dt + V_{x} d X_{t} + {{ 1 } \\over { 2 }} V_{xx} \\left( d X_{t} \\right)^{2} \\\\ =\u0026amp; \\left( V_{t} + V_{x} u + {{ 1 } \\over { 2 }} V_{xx} v^{2} \\right) dt + V_{x} v d W_{t} \\end{align*} $$\nIn Geometric Brownian Motion, distributing $S_{t}$ according to the distributive law gives $$ d S_{t} = \\mu S_{t} dt + \\sigma S_{t} d W_{t} $$ and, from It√¥\u0026rsquo;s Lemma, since $u = \\mu S_{t}$ and $v = \\sigma S_{t}$, we obtain $$ d F = \\left( {{ \\partial F } \\over { \\partial t }} + {{ \\partial F } \\over { \\partial S_{t} }} \\mu S_{t} + {{ 1 } \\over { 2 }} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} \\sigma^{2} S_{t}^{2} \\right) dt + {{ \\partial F } \\over { \\partial S_{t} }} \\sigma S_{t} d W_{t} $$ Substituting this into $\\eqref{1}$ for $d F$ gives $$ \\begin{align*} r V_{t} dt =\u0026amp; d F - {{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\mu dt - {{ \\partial F } \\over { \\partial S_{t} }} \\sigma S_{t} d W_{t} \\\\ =\u0026amp; \\left( {{ \\partial F } \\over { \\partial t }} + {\\color{Red}{{ \\partial F } \\over { \\partial S_{t} }} \\mu S_{t}} + {{ 1 } \\over { 2 }} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} \\sigma^{2} S_{t}^{2} \\right) dt + {\\color{Blue}{{ \\partial F } \\over { \\partial S_{t} }} \\sigma S_{t} d W_{t}} \\\\ \u0026amp; - {\\color{Red}{{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\mu dt} - {\\color{Blue}{{ \\partial F } \\over { \\partial S_{t} }} \\sigma S_{t} d W_{t}} \\\\ =\u0026amp; {{ \\partial F } \\over { \\partial t }} dt + {{ 1 } \\over { 2 }} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} \\sigma^{2} S_{t}^{2} dt \\end{align*} $$ Since the portfolio\u0026rsquo;s value $V_{t}$ was defined as $\\displaystyle V_{t} = F- {{ \\partial F } \\over { \\partial S_{t} }} S_{t}$, substituting this yields $$ r \\left( F- {{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\right) dt = {{ \\partial F } \\over { \\partial t }} dt + {{ 1 } \\over { 2 }} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} \\sigma^{2} S_{t}^{2} dt $$ Rearranging the equation for $rF$, we obtain the desired equation. $$ r F = {{ \\partial F } \\over { \\partial t }} + r S_{t} {{ \\partial F } \\over { \\partial S_{t} }} + {{ 1 } \\over { 2 }} \\sigma^{2} S_{t}^{2} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} $$\n‚ñ†\nByung-Seon Choi. (2012). Various Derivations of the Black-Scholes Formula\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/Fischer_Black\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://namu.wiki/w/Black-Scholes%20model#s-5\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2156,"permalink":"https://freshrimpsushi.github.io/en/posts/2156/","tags":null,"title":"Derivation of Black-Scholes Model"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition 1 Let\u0026rsquo;s say the following Stochastic Differential Equation (SDE) is given by $\\mu \\in \\mathbb{R}$ and $\\sigma^{2} \u0026gt; 0$. $$ d X_{t} = X_{t} \\left( \\mu dt + \\sigma d B_{t} \\right) $$ The solution of this SDE is found as a Stochastic Process for the initial value $X_{0}$, which is referred to as Geometric Brownian Motion. $$ X_{t} = X_{0} \\exp \\left[ \\left( \\mu - {{ \\sigma^{2} } \\over { 2 }} \\right) t + \\sigma B_{t} \\right] $$\nExplanation Geometric Brownian Motion (GBM) is famously known as a basic model describing the trend of indices in the fields of finance and economics. The term geometric seems to derive from the Geometric Series, which is the sum of an exponentially growing sequence, and has no relation to Geometry.\nLog-normal Distribution If we consider only the mathematical properties, excluding applications, the most notable characteristic of GBM is that it follows a normal distribution when logarithmically transformed, i.e., it follows a Log-normal Distribution. This is evident since $\\exp$ contains a Brownian Motion that follows a Normal Distribution.\nDynamics From the perspective of [Population Dynamics](../../categories/Population Dynamics), the system represented by GBM is merely the Malthusian Growth Model $N ' = r N$ with an added noise term $X_{t} \\sigma d B_{t}$. Although it\u0026rsquo;s not strictly necessary to define GBM as a solution to a Stochastic Differential Equation, knowing it as such provides great help in understanding due to its clear deterministic Ordinary Differential Equation properties.\nFinancial Engineering A prime application of GBM is to explain the fluctuation in prices of underlying assets such as stock prices. Just as the change in population is proportional to the total population, the change in the price of an asset is also proportional to the price of the asset, and assuming the asset does not get delisted, it cannot become negative, among other favorable assumptions.\nLet\u0026rsquo;s assume the price of a certain stock $p_{t}$ follows GBM. Taking the log of the division of the closing price on $t$ days by the closing price on $t-1$ days, $$ r_{t} = \\nabla \\log p_{t} = \\log {{ p_{t} } \\over { p_{t-1} }} $$ is referred to as the return‚ÄîReturn, which matches our intuition by being positive if the price has risen and negative if it has fallen, regardless of the size of the stock price. As explained in the Log-normal Distribution section, this return follows a normal distribution, and it\u0026rsquo;s interesting because it focuses on the essence of growth and degrowth of stock prices rather than simple ups and downs.\nStojkoski. (2020). Generalised Geometric Brownian Motion: Theory and Applications to Option Pricing. https://doi.org/10.3390/e22121432\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2154,"permalink":"https://freshrimpsushi.github.io/en/posts/2154/","tags":null,"title":"Geometric Brownian Motion"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 It\u0026rsquo;s quite simple, but a common mistake is to treat the negation operators ! and ~ not as unary operators but as functions, and use !. or ~.. They should be written as .! or .~ instead.\njulia\u0026gt; a = rand(1,10) .\u0026lt; 0.5\r1√ó10 BitMatrix:\r1 1 0 0 1 0 1 0 0 0\rjulia\u0026gt; .!(a)\r1√ó10 BitMatrix:\r0 0 1 1 0 1 0 1 1 1\rjulia\u0026gt; .~(a)\r1√ó10 BitMatrix:\r0 0 1 1 0 1 0 1 1 1 Environment OS: Windows julia: v1.6.0 https://discourse.julialang.org/t/negation-of-boolean-array/16159/2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2149,"permalink":"https://freshrimpsushi.github.io/en/posts/2149/","tags":null,"title":"How to Invert a Bit Array in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 using Gtk\rfile_name = open_dialog(\u0026#34;ÌååÏùº Ïó¥Í∏∞\u0026#34;) The string given as the first argument is the title of the dialog. When executed, you can see a \u0026lsquo;Open File\u0026rsquo; dialog popping up like this.\nEnvironment OS: Windows julia: v1.6.0 https://discourse.julialang.org/t/choose-a-file-interactively/10910/3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2143,"permalink":"https://freshrimpsushi.github.io/en/posts/2143/","tags":null,"title":"How to Open a Dialog Box and Select a File Like file.choose() in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Vector Field Along a Curve1 Definition Given a surface $M$ and a curve $\\alpha : \\left[ a, b \\right] \\to M$, let us consider a function $\\mathbf{X}$ that maps each $t \\in \\left[ a,b \\right]$ to a tangent vector at point $\\alpha (t)$ on surface $M$. This function $\\mathbf{X}$ is called a vector field along curve $\\alpha$vector field along a curve $\\alpha$.\n$$ \\mathbf{X} : \\left[ a, b \\right] \\to \\mathbb{R}^{3} \\\\ \\mathbf{X}(t) \\in T_{\\alpha (t)}M $$\nExplanation It\u0026rsquo;s important to note that the tangent vector mentioned in the definition is not the tangent vector of the curve $\\alpha$, but rather the tangent vector at point $\\alpha (t)$, which is an element of $T_{\\alpha (t)}M$. Since the tangent vector at each point $\\alpha (t)$ on the surface is not unique, the vector field along curve $\\alpha$ is not unique either. There are infinitely many vectors in the tangent plane, hence there are infinitely many vector fields as well.\nFor a simple example, given a curve $\\alpha (t)$ on surface $M$, the tangent vector field $\\mathbf{T}(t)$ of $\\alpha (t)$ becomes a vector field along $\\alpha$. $\\mathbf{S} = \\mathbf{n} \\times \\mathbf{T}$ is also a vector field along $\\alpha$.\n$\\mathbf{S}$ and $\\mathbf{T}$ form a basis of the tangent space, so every vector field $\\mathbf{X}$ along $\\alpha$ can be expressed as a linear combination of these.\n$$ \\mathbf{X}(t) = A(t)\\mathbf{T}(t) + B(t)\\mathbf{S}(t)\\quad \\text{for some } A,B:[a,b]\\to \\mathbb{R} $$\nDifferentiable Vector Field Definition A vector field $\\mathbf{X}(t)$ along $\\alpha (t)$ is differentiabledifferentiable if the function $\\mathbf{X} : \\left[ a, b \\right] \\to \\mathbb{R}^{3}$ is differentiable.\nExplanation Strictly speaking, it\u0026rsquo;s correct to say \u0026lsquo;$\\mathbf{X}$ is differentiable\u0026rsquo;, but it\u0026rsquo;s also convenient to say \u0026lsquo;$\\mathbf{X}(t)$ is differentiable\u0026rsquo;.\nParallel Vector Field Definition Given a differentiable vector field $\\mathbf{X}(t)$ along $\\alpha$, if $\\dfrac{d \\mathbf{X}}{dt}$ is perpendicular to surface $M$, then $\\mathbf{X}(t)$ is defined to be parallel along $\\alpha (t)$.\nExplanation As explained earlier, a vector field $\\alpha$ can be chosen arbitrarily, but the condition \u0026lsquo;a differentiable vector field $\\alpha$\u0026rsquo; sets a restriction for defining the concept of \u0026lsquo;parallel lines\u0026rsquo;.\nBeing perpendicular to surface $M$ means that $\\dfrac{d \\mathbf{X}}{dt}$ should have no component in the tangent direction, and only in the normal direction. The definition might not make much sense at first glance, so let\u0026rsquo;s look at the following examples.\nExample In a 2D Plane Consider a curve $\\boldsymbol{\\gamma}(t) = \\left( a(t), b(t), 0 \\right)$ on the $xy-$ plane. And let\u0026rsquo;s say $\\mathbf{X}(t) = \\left( A(t), B(t), 0 \\right)$ is a vector field along $\\boldsymbol{\\gamma}$. Then,\n$$ \\dfrac{d \\mathbf{X}}{dt} = \\left( \\dfrac{d A}{dt}, \\dfrac{d B}{dt}, 0 \\right) $$\nFor this vector to be perpendicular to the $xy-$ plane, the dot product with any vector $(x,y,0)$ must be $0$, leading to the following result.\n$$ \\dfrac{d A}{dt} = 0 = \\dfrac{d B}{dt} $$\nTherefore, $A(t), B(t)$ is a constant. If we illustrate this, it matches well with our intuitive understanding of \u0026lsquo;vectors that are parallel along curve $\\boldsymbol{\\gamma}$\u0026rsquo;.\nOn a Sphere Let $M$ be the unit sphere. Let ${\\color{6699CC}\\boldsymbol{\\gamma}(t)}$ be the equator. Consider a vector field ${\\color{295F2E}\\mathbf{X}_{\\boldsymbol{\\gamma}}(t) = (0, 0, 1)}$ along $\\boldsymbol{\\gamma}$. Then, since $\\dfrac{d \\mathbf{X}_{\\boldsymbol{\\gamma}}}{dt} = (0,0,0)$, it\u0026rsquo;s always perpendicular to $M$. Hence, $\\mathbf{X}_{\\boldsymbol{\\gamma}}$ is a vector field parallel along $\\boldsymbol{\\gamma}$. As seen in the 2D example, a constant vector field naturally becomes a parallel vector field.\nNow, consider a vector field ${\\color{295F2E}\\mathbf{X}_{\\boldsymbol{\\beta}} = \\left( -\\dfrac{\\sqrt{2}}{2}\\cos t, \\dfrac{\\sqrt{2}}{2}\\sin t, \\dfrac{\\sqrt{2}}{2} \\right)}$ along curves ${\\color{6699CC}\\boldsymbol{\\beta}(t) = \\left( \\dfrac{\\sqrt{2}}{2}\\cos t, \\dfrac{\\sqrt{2}}{2}\\sin t, \\dfrac{\\sqrt{2}}{2} \\right)}$ and $\\boldsymbol{\\beta}$. Then, ${\\color{f8c512}\\dfrac{d\\mathbf{X}_{\\boldsymbol{\\beta}}}{dt} = \\left( \\dfrac{\\sqrt{2}}{2}\\sin t, \\dfrac{\\sqrt{2}}{2}\\cos t, 0 \\right)}$, and if we plot this in 3D, it appears as follows.\nSince ${\\color{f8c512}\\dfrac{d\\mathbf{X}_{\\boldsymbol{\\beta}}}{dt}}$ is not perpendicular to the sphere, ${\\color{295F2E}\\mathbf{X}_{\\boldsymbol{\\beta}}}$ is not a vector field parallel along $\\boldsymbol{\\beta}$.\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p116-121\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3174,"permalink":"https://freshrimpsushi.github.io/en/posts/3174/","tags":null,"title":"Definition of Parallel Vector Field along a Curve on Surface"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 Let $z$ be the variable on the given axis, and $r\u0026gt;0$ be the distance from the $z-$ axis. Then, one can consider the curve $\\alpha$ on the $rz-$ plane as shown in the figure below.\nAs shown in the figure below, the surface obtained by rotating the curve $\\alpha$ about the $z-$ axis is called a surface of revolution.\nThe surface of revolution is expressed as follows.\n$$ \\mathbf{x}(t, \\theta) = \\left( r(t)\\cos \\theta, r(t)\\sin \\theta, z(t) \\right) $$\nThe $t-$ parametric curve of the surface of revolution is called a meridian, and the $\\theta-$ parametric curve is called a circle of latitude or parallel.\nExplanation Even if it is called a solid, it might not significantly impede communication, but strictly speaking, it is not a solid of revolution because it is hollow inside.\nAll meridians are geodesics. Unlike this, certain conditions are required for circles of latitude to become geodesics.\nTheorem If the curve $\\alpha (t) = \\left( r(t), z(t) \\right)$ is regular and one-to-one, then the surface of revolution $\\mathbf{x}(t, \\theta) = \\left( r(t)\\cos \\theta, r(t)\\sin \\theta, z(t) \\right)$ formed by $\\alpha$ is a simple surface. The condition for $\\theta$ is $-\\pi \\lt \\theta \\lt \\pi$.\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p86-87\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3170,"permalink":"https://freshrimpsushi.github.io/en/posts/3170/","tags":null,"title":"Rotational Surfaces in Differential Geometry"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 For two integers $n$ and $m \\ne 0$, if there exists an integer $k$ that satisfies the following, $n$ is divisible by $m$. $$ n = mk $$ In this case, $n$ is called a Multiple of $m$, and $m$ is called a Divisor of $n$, as indicated below. $$ m \\mid n $$ If $m$ cannot divide $n$, it is denoted by striking through as $m \\nmid n$. Let\u0026rsquo;s assume two non-$0$ integers $a$, $b$ are given. The largest common divisor that divides both is called the Greatest Common Divisor of $a$ and $b$, denoted as $\\gcd (a,b)$. If $\\gcd (a,b) = 1$, then $a$ and $b$ are said to be Relatively Prime. Explanation The concepts of Greatest Common Divisor and Relatively Prime are something most people have seen from their elementary school days.\nAs can be seen from the English expression Relatively Prime, contrary to many people\u0026rsquo;s language habits (even in the title of this post, where it‚Äôs written without a space, as if it‚Äôs a single word), Relatively Prime literally means relatively prime. Although Mutually might seem a more fitting word to express \u0026rsquo;each other\u0026rsquo; in English, Mutually has its own significant meaning across mathematics, hence Relatively is used. Here, \u0026lsquo;relatively\u0026rsquo; means that the two numbers $a$ and $b$ do not share any divisor other than $1$, making them essentially prime to each other. They may not be absolutely prime, but for each other, they can be considered as prime.\nSee Also Algebraic Generalization Generalized in Unique Factorization Domain.\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p30.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2137,"permalink":"https://freshrimpsushi.github.io/en/posts/2137/","tags":null,"title":"Greatest Common Divisor and Coprime"},{"categories":"Ìï®Ïàò","contents":"Definition1 Given a set $X$, the following function $I_{X} : X \\to X$ is called the identity function.\n$$ I_{X}(x) = x,\\quad \\forall x \\in X $$\nExplanation The following notations are commonly used.\n$$ I,\\quad \\text{id},\\quad \\text{1} $$\nTangent vectors on a differentiable manifold are defined as follows in $\\dfrac{d (f\\circ \\alpha)}{d t}$, where the function to be differentiated\n$$ f \\circ \\alpha = f \\circ I \\circ \\alpha = f \\circ \\mathbf{x} \\circ \\mathbf{x}^{-1} \\circ \\alpha $$\ncan be decomposed like this, allowing the tangent vector to be represented with respect to any coordinate system $\\mathbf{x}$ while making it independent of the choice of the coordinate system.\nExample Identity Matrix $$ I_{n\\times n} = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1 \\end{bmatrix} $$\nYou-Feng Lin, (2011). Set Theory (Set Theory: An Intuitive Approach, translated by Heungcheon Lee) (2011), p165\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3167,"permalink":"https://freshrimpsushi.github.io/en/posts/3167/","tags":null,"title":"Identity Function"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code In fact, Julia is not a very convenient language for things like string formatting. While there are methods that utilize the intrinsic capabilities of strings for printing to the console, often it\u0026rsquo;s more convenient to use the round() function\u0026rsquo;s default option, digits.\njulia\u0026gt; for k in 0:8\rprintln(round(œÄ, digits = k))\rend\r3.0\r3.1\r3.14\r3.142\r3.1416\r3.14159\r3.141593\r3.1415927\r3.14159265 Environment OS: Windows julia: v1.6.0 ","id":2133,"permalink":"https://freshrimpsushi.github.io/en/posts/2133/","tags":null,"title":"How to Round to a Specific Decimal Place in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Theorem1 The Christoffel symbols $\\Gamma_{ij}^{k}$ satisfy the following equation. In other words, they are intrinsic.\n$$ \\Gamma_{ij}^{k} = \\dfrac{1}{2} \\sum \\limits_{l=1}^{2} g^{lk} \\left( \\dfrac{\\partial g_{lj}}{\\partial u_{i}} - \\dfrac{\\partial g_{ij}}{\\partial u_{l}} + \\dfrac{\\partial g_{il}}{\\partial u_{j}} \\right) $$\nExplanation Gauss proved it.\nThe Christoffel symbols depend only on the Riemann metric and are independent of the normal vector. Therefore, by using Christoffel symbols, one can understand the structure of a surface without leaving the surface.\nProof First, the partial derivatives of each index of the Riemann metric coefficients are as follows.\n$$ \\dfrac{\\partial g_{il}}{\\partial u_{j}} = \\dfrac{\\partial}{\\partial u_{j}} \\left\\langle \\mathbf{x}_{i} , \\mathbf{x}_{l} \\right\\rangle = \\langle \\mathbf{x}_{ij} , \\mathbf{x}_{l} \\rangle + \\langle \\mathbf{x}_{i}, \\mathbf{x}_{lj} \\rangle $$\n$$ \\dfrac{\\partial g_{ij}}{\\partial u_{l}} = \\dfrac{\\partial}{\\partial u_{l}} \\left\\langle \\mathbf{x}_{i} , \\mathbf{x}_{j} \\right\\rangle = \\langle \\mathbf{x}_{il} , \\mathbf{x}_{j} \\rangle + \\langle \\mathbf{x}_{i}, \\mathbf{x}_{jl} \\rangle $$\n$$ \\dfrac{\\partial g_{lj}}{\\partial u_{i}} = \\dfrac{\\partial}{\\partial u_{i}} \\left\\langle \\mathbf{x}_{l} , \\mathbf{x}_{j} \\right\\rangle = \\langle \\mathbf{x}_{li} , \\mathbf{x}_{j} \\rangle + \\langle \\mathbf{x}_{l}, \\mathbf{x}_{ji} \\rangle $$\nSince $\\mathbf{\\mathbf{x}}_{ij} = \\mathbf{\\mathbf{x}}_{ji}$,\n$$ \\begin{align*} \\dfrac{\\partial g_{il}}{\\partial u_{j}} - \\dfrac{\\partial g_{ij}}{\\partial u_{l}} + \\dfrac{\\partial g_{lj}}{\\partial u_{i}} =\u0026amp;\\ \\langle \\mathbf{x}_{ij} , \\mathbf{x}_{l} \\rangle + \\langle \\mathbf{x}_{i}, \\mathbf{x}_{lj} \\rangle - \\langle \\mathbf{x}_{il} , \\mathbf{x}_{j} \\rangle - \\langle \\mathbf{x}_{i}, \\mathbf{x}_{jl} \\rangle + \\langle \\mathbf{x}_{li} , \\mathbf{x}_{j} \\rangle + \\langle \\mathbf{x}_{l}, \\mathbf{x}_{ji} \\rangle \\\\ =\u0026amp;\\ \\langle \\mathbf{x}_{ij} , \\mathbf{x}_{l} \\rangle + \\langle \\mathbf{x}_{l}, \\mathbf{x}_{ji} \\rangle \\\\ =\u0026amp;\\ 2 \\langle \\mathbf{x}_{ij} , \\mathbf{x}_{l} \\rangle \\end{align*} $$\nTherefore, the Christoffel symbols are\n$$ \\Gamma_{ij}^{k} = \\sum \\limits_{l=1}^{2} \\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle g^{lk} = \\dfrac{1}{2} \\sum \\limits_{l=1}^{2} \\left( \\dfrac{\\partial g_{lj}}{\\partial u_{i}} - \\dfrac{\\partial g_{ij}}{\\partial u_{l}} + \\dfrac{\\partial g_{il}}{\\partial u_{j}} \\right) g^{lk} $$\nExample Suppose we are given a Monge patch as in $\\mathbf{x}(u_{1}, u_{2}) = \\left( u_{1}, u_{2}, f(u_{1}, u_{2}) \\right)$. Then\n$$ \\mathbf{x}_{1} = \\partial_{u_{1}}\\mathbf{x} = (1,0,f_{1}) \\quad \\text{and} \\quad \\mathbf{x}_{2} = (0,1,f_{2}) $$\nAt this time, $f_{i} = \\partial_{u_{i}}f$ is. $\\Gamma_{11}^{1}$ can be obtained in the following two ways.\nExtrinsically computing $$ \\mathbf{x}_{1} \\times \\mathbf{x}_{2} = (-f_{1}, -f_{2}, 1) $$\nThe unit normal is\n$$ \\mathbf{n} = \\dfrac{(-f_{1}, -f_{2}, 1)}{\\sqrt{(f_{1})^{2} + (f_{2})^{2} + 1}} $$\nGauss formula\n$$ \\mathbf{x}_{ij} = L_{ij} \\mathbf{n} + \\sum \\limits_{k=1}^{2} \\Gamma_{ij}^{k} \\mathbf{x}_{k} $$\nThe second derivative of $\\mathbf{x}$ is as follows according to the Gauss formula.\n$$ \\mathbf{x}_{11} = (0, 0, f_{11}) = L_{11}\\mathbf{n} + \\Gamma_{11}^{1}\\mathbf{x}_{1} + \\Gamma_{11}^{2}\\mathbf{x}_{2} $$\nTherefore, the coefficients of the second fundamental form are $L_{ij} = \\langle \\mathbf{x}_{ij}, \\mathbf{n} \\rangle$\n$$ L_{11} = \\left\\langle (0,0,f_{11}), \\dfrac{(-f_{1}, -f_{2}, 1)}{\\sqrt{(f_{1})^{2} + (f_{2})^{2} + 1}}\\right\\rangle = \\dfrac{f_{11}}{\\sqrt{(f_{1})^{2} + (f_{2})^{2} + 1}} $$\nIf we break down $\\mathbf{x}_{11}$ into components, we get the following.\n$$ \\mathbf{x}_{11} = (0, 0, f_{11}) = \\dfrac{L_{11}}{\\sqrt{(f_{1})^{2} + (f_{2})^{2} + 1}}(-f_{1}, -f_{2}, 1) + \\Gamma_{11}^{1}(1,0,f_{1}) + \\Gamma_{11}^{2}(0,1,f_{2}) $$\nLooking at the first component, we obtain the following equation.\n$$ \\begin{align*} \u0026amp;\u0026amp; 0 =\u0026amp;\\ \\dfrac{L_{11}(-f_{1})}{\\sqrt{(f_{1})^{2} + (f_{2})^{2} + 1}} + \\Gamma_{11}^{1} \\\\[1em] \\implies\u0026amp;\u0026amp; \\Gamma_{11}^{1} =\u0026amp;\\ \\dfrac{L_{11}(f_{1})}{\\sqrt{(f_{1})^{2} + (f_{2})^{2} + 1}} \\\\[1em] \\implies\u0026amp;\u0026amp; \\Gamma_{11}^{1} =\u0026amp;\\ \\dfrac{f_{1} f_{11}}{(f_{1})^{2} + (f_{2})^{2} + 1} \\end{align*} $$\n‚ñ†\nIntrinsically computing According to the theorem above, $\\Gamma_{11}^{1}$ can be computed as follows.\n$$ \\begin{align*} \\Gamma_{11}^{1} =\u0026amp;\\ \\dfrac{1}{2} \\sum \\limits_{l=1}^{2} g^{l1} \\left( \\dfrac{\\partial g_{l1}}{\\partial u_{1}} - \\dfrac{\\partial g_{11}}{\\partial u_{l}} + \\dfrac{\\partial g_{1l}}{\\partial u_{1}} \\right) \\\\ =\u0026amp;\\ \\dfrac{1}{2} \\left[ g^{11} \\left( \\dfrac{\\partial g_{11}}{\\partial u_{1}} - \\dfrac{\\partial g_{11}}{\\partial u_{1}} + \\dfrac{\\partial g_{11}}{\\partial u_{1}} \\right) + g^{21} \\left( \\dfrac{\\partial g_{21}}{\\partial u_{1}} - \\dfrac{\\partial g_{11}}{\\partial u_{2}} + \\dfrac{\\partial g_{12}}{\\partial u_{1}} \\right) \\right] \\\\ =\u0026amp;\\ \\dfrac{1}{2} \\left[ g^{11} \\dfrac{\\partial g_{11}}{\\partial u_{1}} + 2g^{21}\\dfrac{\\partial g_{21}}{\\partial u_{1}} - g^{21}\\dfrac{\\partial g_{11}}{\\partial u_{2}} \\right] \\end{align*} $$\nThe coefficients of the first fundamental form are $g_{ij} = \\left\\langle \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\rangle$\n$$ \\left[ g_{ij} \\right] = \\begin{bmatrix} 1+(f_{1})^{2} \u0026amp; f_{1}f_{2} \\\\[1em] f_{1}f_{2} \u0026amp; 1 + (f_{2})^{2} \\end{bmatrix} $$\nThe inverse matrix is\n$$ \\left[ g_{ij} \\right]^{-1} = \\left[ g^{lk} \\right] = \\dfrac{1}{(f_{1})^{2} + (f_{2})^{2} + 1}\\begin{bmatrix} 1+(f_{2})^{2} \u0026amp; -f_{1}f_{2} \\\\[1em] -f_{1}f_{2} \u0026amp; 1 + (f_{1})^{2} \\end{bmatrix} $$\nSo, when we gather everything needed, we get the following.\n$$ \\begin{align*} \\dfrac{\\partial g_{11}}{\\partial u_{1}} =\u0026amp;\\ \\dfrac{\\partial }{\\partial u_{1}}\\left( 1+ (f_{1})^{2} \\right) = 2f_{1}f_{11} \\\\ \\dfrac{\\partial g_{21}}{\\partial u_{1}} =\u0026amp;\\ \\dfrac{\\partial }{\\partial u_{1}}\\left( f_{1}f_{2} \\right) = f_{11}f_{2} + f_{1}f_{21} \\\\ \\dfrac{\\partial g_{11}}{\\partial u_{2}} =\u0026amp;\\ \\dfrac{\\partial }{\\partial u_{2}}\\left( 1+ (f_{1})^{2} \\right) = 2f_{1}f_{12} \\end{align*} $$\nAnd\n$$ \\begin{align*} g^{11} =\u0026amp;\\ \\dfrac{1+(f_{2})^{2}}{(f_{1})^{2} + (f_{2})^{2} + 1} \\\\ g^{21} =\u0026amp;\\ \\dfrac{-f_{1}f_{2}}{(f_{1})^{2} + (f_{2})^{2} + 1} \\end{align*} $$\nNow, if we substitute, we get as follows.\n$$ \\begin{align*} \\Gamma_{11}^{1} =\u0026amp;\\ \\dfrac{1}{2} \\left[ g^{11} \\dfrac{\\partial g_{11}}{\\partial u_{1}} + 2g^{21}\\dfrac{\\partial g_{21}}{\\partial u_{1}} - g^{21}\\dfrac{\\partial g_{11}}{\\partial u_{2}} \\right] \\\\ =\u0026amp;\\ \\dfrac{1}{2} \\left[ \\dfrac{1+(f_{2})^{2}}{(f_{1})^{2} + (f_{2})^{2} + 1} 2f_{1}f_{11} + 2\\dfrac{-f_{1}f_{2}}{(f_{1})^{2} + (f_{2})^{2} + 1} \\left( f_{11}f_{2} + f_{1}f_{21} \\right)- \\dfrac{-f_{1}f_{2}}{(f_{1})^{2} + (f_{2})^{2} + 1}2f_{1}f_{12} \\right] \\\\ =\u0026amp;\\ \\dfrac{1}{(f_{1})^{2} + (f_{2})^{2} + 1}\\left[ \\left( 1+(f_{2})^{2} \\right)f_{1}f_{11} + \\left( -f_{1}f_{2} \\right) \\left( f_{11}f_{2} + f_{1}f_{21} \\right)- (-f_{1}f_{2})f_{1}f_{12} \\right] \\\\ =\u0026amp;\\ \\dfrac{1}{(f_{1})^{2} + (f_{2})^{2} + 1}\\left[ f_{1}f_{11} + f_{1}(f_{2})^{2}f_{11} - f_{1}(f_{2})^{2}f_{11} -(f_{1})^{2}f_{2}f_{21} + (f_{1})^{2}f_{2}f_{12} \\right] \\\\ =\u0026amp;\\ \\dfrac{1}{(f_{1})^{2} + (f_{2})^{2} + 1}\\left[ f_{1}f_{11} \\right] \\\\ =\u0026amp;\\ \\dfrac{f_{1}f_{11}}{(f_{1})^{2} + (f_{2})^{2} + 1} \\end{align*} $$\nWe can see that computing Christoffel symbols intrinsically is more complicated compared to when not doing so.\n‚ñ†\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p105-106\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3164,"permalink":"https://freshrimpsushi.github.io/en/posts/3164/","tags":null,"title":"The Christoffel Symbols are Intrinsic"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Theorem1 Let $f : \\mathbb{R}^{n} \\to \\mathbb{R}$ be $C^{k}$ function, and call it $\\mathbf{a} = (a_{1}, \\dots, a_{n}) \\in \\mathbb{R}^{n}$. Then, there exists $C^{k-2}$ function $h_{ij}$ that satisfies the following.\n$$ f(\\mathbf{x}) = f(\\mathbf{a}) + \\sum_{i} (x_{i} - a_{i})\\dfrac{\\partial f}{\\partial x_{i}}(\\mathbf{a}) + \\sum_{i,j}h_{ij}(\\mathbf{x})(x_{i} - a_{i}) (x_{j} - a_{j}) $$\nDescription It generalizes the Taylor theorem to functions of several variables.\nsecond-order\n$$ \\begin{align*} f(\\mathbf{x}) \u0026amp;= f(\\mathbf{a}) + \\sum\\limits_{i=1}^{n} (x_{i} - a_{i}) \\dfrac{\\partial f}{\\partial x_{i}}(\\mathbf{a}) + \\dfrac{1}{2!}\\sum\\limits_{i,j=1}^{n} (x_{i} - a_{i})^{2} \\dfrac{\\partial^{2} f}{\\partial x_{i} \\partial x_{j}}(\\mathbf{a}) + \\text{Remainder} \\\\ \u0026amp;= f(\\mathbf{a}) + (\\mathbf{x} - \\mathbf{a})^{T} \\nabla f (\\mathbf{a}) + \\dfrac{1}{2!}(\\mathbf{x} - \\mathbf{a})^{T} (H(\\mathbf{a})) (\\mathbf{x} - \\mathbf{a}) + \\text{Remainder} \\end{align*} $$\nHere, $\\nabla f$ is the $f$ gradient, and $H$ is the Hessian of $f$.\nFor the remainder term, the following form is also usefully employed.\n$$ f(\\mathbf{x} + \\mathbf{p}) = f(\\mathbf{x}) + \\mathbf{p}^{T}\\nabla f(\\mathbf{x} + t \\mathbf{p}) \\quad \\text{for some } t \\in (0,1) $$ $$ f(\\mathbf{x} + \\mathbf{p}) = f(\\mathbf{x}) + \\mathbf{p}^{T}\\nabla f(\\mathbf{x}) + \\dfrac{1}{2!}\\mathbf{p}^{T} H(\\mathbf{x} + t \\mathbf{p}) \\mathbf{p} \\quad \\text{for some } t \\in (0,1) $$\n$$ f(\\mathbf{x} + \\mathbf{p}) = f(\\mathbf{x}) + \\int_{0}^{1}\\mathbf{p}^{T}\\nabla f (\\mathbf{x} + t\\mathbf{p})dt $$\nProof $$ \\begin{align*} f(\\mathbf{x}) - f(\\mathbf{a}) =\u0026amp;\\ \\int_{0}^{1} \\dfrac{d}{dt} \\left[ f(t(\\mathbf{x} - \\mathbf{a}) + \\mathbf{a}) \\right]dt \\\\ =\u0026amp;\\ \\int_{0}^{1} \\left( \\sum_{i} \\dfrac{\\partial f}{\\partial x_{i}}\\left( t(\\mathbf{x} - \\mathbf{a}) + \\mathbf{a} \\right)(x_{i}-a_{i}) \\right) dt \u0026amp; \\text{by } \\href{https://freshrimpsushi.github.io/posts/3134}{\\text{chain rule}} \\\\ =\u0026amp;\\ \\sum_{i}(x_{i} - a_{i}) \\int_{0}^{1} \\left( \\dfrac{\\partial f}{\\partial x_{i}}\\left( t(\\mathbf{x} - \\mathbf{a}) + \\mathbf{a} \\right) \\right) dt \\end{align*} $$\nLet the integral part be denoted as $g_{i}(\\mathbf{x})$. If we denote $g_{i}(\\mathbf{x}) = \\displaystyle \\int_{0}^{1} \\left( \\dfrac{\\partial f}{\\partial x_{i}}\\left( t(\\mathbf{x} - \\mathbf{a}) + \\mathbf{a} \\right) \\right) dt$,\n$$ \\begin{equation} f(\\mathbf{x}) - f(\\mathbf{a}) = \\sum_{i}(x_{i} - a_{i}) \\int_{0}^{1} \\left( \\dfrac{\\partial f}{\\partial x_{i}}\\left( t(\\mathbf{x} - \\mathbf{a}) + \\mathbf{a} \\right) \\right) dt = \\sum_{i} g_{i}(\\mathbf{x}) (x_{i} - a_{i}) \\end{equation} $$\nThe value of $g_{i}(\\mathbf{a})$ is as follows.\n$$ g_{i}(\\mathbf{a}) = \\int_{0}^{1} \\dfrac{\\partial f}{\\partial x_{i}} \\left(t(\\mathbf{a} - \\mathbf{a}) + \\mathbf{a} \\right) dt = \\int_{0}^{1} \\dfrac{\\partial f}{\\partial x_{i}}\\left( \\mathbf{a} \\right) dt = \\dfrac{\\partial f}{\\partial x_{i}}\\left( \\mathbf{a} \\right) $$\nThen, using the same method that led to $(1)$, we can obtain the following equation.\n$$ g_{i}(\\mathbf{x}) - g_{i}(\\mathbf{a}) = \\sum_{j} h_{ij}(\\mathbf{x}) (x_{j}-a_{j}) $$\nNow, summarizing,\n$$ \\begin{align*} f(\\mathbf{x}) =\u0026amp;\\ f(\\mathbf{a}) + \\sum_{i}g_{i}(\\mathbf{x})(x_{i}-a_{i}) \\\\ =\u0026amp;\\ f(\\mathbf{a}) + \\sum_{i}\\left( g_{i}(\\mathbf{a}) + \\sum_{j} h_{ij}(\\mathbf{x}) (x_{j}-a_{j}) \\right)(x_{i}-a_{i}) \\\\ =\u0026amp;\\ f(\\mathbf{a}) + \\sum_{i} g_{i}(\\mathbf{a})(x_{i}-a_{i}) + \\sum_{i,j} h_{ij}(\\mathbf{x})(x_{i}-a_{i})(x_{j}-a_{j}) \\\\ =\u0026amp;\\ f(\\mathbf{a}) + \\sum_{i} \\dfrac{\\partial f}{\\partial x_{i}}\\left( \\mathbf{a} \\right)(x_{i}-a_{i}) + \\sum_{i,j} h_{ij}(\\mathbf{x})(x_{i}-a_{i})(x_{j}-a_{j}) \\end{align*} $$\n‚ñ†\nSee Also Taylor theorem Richard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p213-214\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3163,"permalink":"https://freshrimpsushi.github.io/en/posts/3163/","tags":null,"title":"Taylor's Theorem for Multivariable Functions"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 In differential geometry, a function that depends only on the coefficients of the first fundamental form ([eq2])(../3148) and not on the unit normal(../2110) is referred to as intrinsic. \u0026lt;!\u0026ndash; it means a quantity that depends only on the intrinsic g(Riemannian metric).\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p106\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3162,"permalink":"https://freshrimpsushi.github.io/en/posts/3162/","tags":null,"title":"Definitions of Intrinsic/Essential in Differential Geometry"},{"categories":"Í∏∞ÌïòÌïô","contents":"Ï†ïÎ¶¨1 Let\u0026rsquo;s call $\\mathbf{x} : U \\to \\R^{3}$ the coordinate patch. Let $(u_{1}, u_{2})$ be the coordinates of $U$.\nLet $\\mathbf{n}$ be the unit normal, $L_{ij} = \\left\\langle \\mathbf{x}_{ij}, \\mathbf{n} \\right\\rangle$ the coefficients of the second fundamental form, and $\\Gamma_{ij}^{k} = \\sum \\limits_{l=1}^{2} \\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle g^{lk} = \\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle g^{lk}$ the Christoffel symbols.\nThen, the following are true:\n(a) Gauss\u0026rsquo;s formulas:\n$$ \\mathbf{x}_{ij} = L_{ij} \\mathbf{n} + \\sum \\limits_{k=1}^{2} \\Gamma_{ij}^{k} \\mathbf{x}_{k} $$\n(b) For any unit speed curve $\\boldsymbol{\\gamma}(s) = \\mathbf{x}\\left( \\gamma^{1}(s), \\gamma^{2}(s) \\right)$,\n$$ \\kappa_{n} = \\sum \\limits_{i=1}^{2} \\sum \\limits_{j=1}^{2} L_{ij} (\\gamma^{i})^{\\prime} (\\gamma^{j})^{\\prime} $$\nAnd\n$$ \\kappa_{g}\\mathbf{S} = \\sum \\limits_{k=1}^{2} \\left[ u_{k}^{\\prime \\prime} + \\sum \\limits_{i,j=1}^{2} \\Gamma_{ij}^{k}(\\gamma^{i})^{\\prime}(\\gamma^{j})^{\\prime} \\right] \\mathbf{x}_{k} $$\nWhere $\\kappa_{n}$ is the normal curvature, $\\kappa_{g}$ is the geodesic curvature, and $\\mathbf{S} = \\mathbf{n} \\times \\mathbf{T}$.\nExplanation In fact, (a) is by itself a definition of $L_{ij}$ and $\\Gamma_{ij}^{k}$.\nFrom the result of (a), we obtain the following equation:\n$$ \\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle = \\sum \\limits_{k=1}^{2}\\Gamma_{ij}^{k}g_{kl} $$\nThis is called the first Christoffel symbol.\nProof (a) The unit normal is perpendicular to the tangent space, and since $\\left\\{ \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\}$ is a basis of the tangent space, $\\left\\{ \\mathbf{n}, \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\}$ becomes the basis of $\\R^{3}$. Therefore, all vectors of $\\R^{3}$ can be represented as a linear combination of these. Now, let\u0026rsquo;s represent $\\mathbf{x}_{ij}$ as follows:\n$$ \\mathbf{x}_{ij} = a_{ij}\\mathbf{n} + {b_{ij}}^{1}\\mathbf{x}_{1} + {b_{ij}}^{2}\\mathbf{x}_{2} $$\nTherefore, since $\\left\\langle \\mathbf{x}_{i}, \\mathbf{n} \\right\\rangle=0$, by the definition of the coefficients of the second fundamental form,\n$$ L_{ij} = \\left\\langle \\mathbf{x}_{ij}, \\mathbf{n} \\right\\rangle = \\left\\langle a_{ij}\\mathbf{n} + {b_{ij}}^{1}\\mathbf{x}_{1} + {b_{ij}}^{2}\\mathbf{x}_{2}, \\mathbf{n} \\right\\rangle = a_{ij} $$\nAlso, the coefficients of the Riemann metric are defined as follows:\n$$ \\begin{align*} \\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle =\u0026amp;\\ \\left\\langle a_{ij}\\mathbf{n} + {b_{ij}}^{1}\\mathbf{x}_{1} + {b_{ij}}^{2}\\mathbf{x}_{2}, \\mathbf{x}_{l} \\right\\rangle \\\\ \u0026amp;= {b_{ij}}^{1} \\left\\langle \\mathbf{x}_{1}, \\mathbf{x}_{l} \\right\\rangle + {b_{ij}}^{2} \\left\\langle \\mathbf{x}_{2}, \\mathbf{x}_{l} \\right\\rangle \\\\ \u0026amp;= {b_{ij}}^{1} g_{1l} + {b_{ij}}^{2} g_{2l} \\\\ \u0026amp;= \\sum \\limits_{m=1}^{2} {b_{ij}}^{m} g_{ml} \\\\ \u0026amp;= {b_{ij}}^{m} g_{ml} \\quad (\\text{Einstein notation}) \\end{align*} $$\nTherefore, $[g^{lk}]$ being the inverse of $[g_{ij}]$, the following equation holds:\n$$ \\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle g^{lk} = \\sum \\limits_{m=1}^{2} {b_{ij}}^{m} g_{ml}g^{lk} $$\nSumming the left-hand side over all $l$ gives the Christoffel symbols. Since $g_{ik}g^{kj} = {\\delta_{i}}^{j}$ holds for the Riemann metric,\n$$ \\Gamma_{ij}^{k} = \\sum \\limits_{l=1}^{2} \\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle g^{lk} = \\sum \\limits_{l=1}^{2} \\sum \\limits_{m=1}^{2} {b_{ij}}^{m} g_{ml}g^{lk} = \\sum \\limits_{m=1}^{2} {b_{ij}}^{m} {\\delta_{m}}^{k} = {b_{ij}}^{k} $$\nTherefore,\n$$ \\begin{align*} \\mathbf{x}_{ij} =\u0026amp;\\ a_{ij}\\mathbf{n} + {b_{ij}}^{1}\\mathbf{x}_{1} + {b_{ij}}^{2}\\mathbf{x}_{2} \\\\ =\u0026amp;\\ L_{ij} \\mathbf{n} + {\\Gamma_{ij}}^{1} \\mathbf{x}_{1} + {\\Gamma_{ij}}^{2} \\mathbf{x}_{2} \\\\ =\u0026amp;\\ L_{ij} \\mathbf{n} + \\sum \\limits_{k=1}^{2} \\Gamma_{ij}^{k} \\mathbf{x}_{k} \\end{align*} $$\n‚ñ†\n(b) Part 1. Calculation of $\\boldsymbol{\\gamma}^{\\prime \\prime}$\nCalculating the tangent vector of $\\boldsymbol{\\gamma}(s) = \\mathbf{x}\\left( \\gamma^{1}(s), \\gamma^{2}(s) \\right)$ gives the following result:\n$$ \\begin{align*} T(s) =\u0026amp;\\ \\dfrac{d \\boldsymbol{\\gamma}}{d s} \\\\ =\u0026amp;\\ \\dfrac{d}{ds} \\mathbf{x}(\\gamma^{1}, \\gamma^{2}) \\\\ =\u0026amp;\\ \\dfrac{\\partial \\mathbf{x}}{\\partial \\gamma^{1}}\\dfrac{d \\gamma^{1}}{ds} + \\dfrac{\\partial \\mathbf{x}}{\\partial \\gamma^{2}}\\dfrac{d \\gamma^{2}}{ds}\u0026amp; \\text{by } \\href{https://freshrimpsushi.github.io/posts/derivative-of-three-dimentional-scalar-vector-function}{\\text{chain rule}} \\\\ =\u0026amp;\\ \\mathbf{x}_{1}(\\gamma^{1})^{\\prime} + \\mathbf{x}_{2}(\\gamma^{2})^{\\prime} \\\\ =\u0026amp;\\ \\sum \\limits_{i=1}^{2}\\mathbf{x}_{i}(\\gamma^{i})^{\\prime} \\\\ =\u0026amp;\\ \\mathbf{x}_{i}(\\gamma^{i})^{\\prime} \\end{align*} $$\nIn the last equality, Einstein notation was used. Let\u0026rsquo;s calculate the acceleration. For someone familiar with Einstein notation and differential calculus, it can be calculated in one shot as follows:\n$$ \\boldsymbol{\\gamma} ^{\\prime \\prime} = \\dfrac{d}{ds}\\left( \\mathbf{x}_{i}(\\gamma^{i})^{\\prime} \\right) = \\mathbf{x}_{ij}(\\gamma^{j})^{\\prime}(\\gamma^{i})^{\\prime} + \\mathbf{x}_{i}(\\gamma^{i})^{\\prime \\prime} = \\sum \\limits_{i=1}^{2}\\left( \\sum\\limits_{j=1}^{2}\\mathbf{x}_{ij}(\\gamma^{j})^{\\prime}(\\gamma^{i})^{\\prime} + \\mathbf{x}_{i}(\\gamma^{i})^{\\prime \\prime} \\right) $$\nFor those not familiar with Einstein notation, detailing the calculation process gives the following:\n$$ \\begin{align*} \\boldsymbol{\\gamma}^{\\prime \\prime} =\u0026amp;\\ \\dfrac{d}{ds} \\left( \\mathbf{x}_{1}(\\gamma^{1})^{\\prime} + \\mathbf{x}_{2}(\\gamma^{2})^{\\prime} \\right) \\\\ =\u0026amp;\\ \\dfrac{d}{ds} \\left( \\mathbf{x}_{1}(\\gamma^{1})^{\\prime} \\right) +\\dfrac{d}{ds} \\left( \\mathbf{x}_{2}(\\gamma^{2})^{\\prime} \\right) \\\\ =\u0026amp;\\ \\dfrac{d}{ds} \\left( \\mathbf{x}_{1} \\right) (\\gamma^{1})^{\\prime} +\\mathbf{x}_{1} \\dfrac{d}{ds} \\left( (\\gamma^{1})^{\\prime} \\right) + \\dfrac{d}{ds} \\left( \\mathbf{x}_{2} \\right) (\\gamma^{2})^{\\prime} +\\mathbf{x}_{2} \\dfrac{d}{ds} \\left( (\\gamma^{2})^{\\prime} \\right) \\\\ =\u0026amp;\\ \\left( \\dfrac{\\partial \\mathbf{x}_{1}}{\\partial \\gamma^{1}}\\dfrac{d \\gamma^{1}}{ds} + \\dfrac{\\partial \\mathbf{x}_{1}}{\\partial \\gamma^{2}}\\dfrac{d \\gamma^{2}}{ds} \\right) (\\gamma^{1})^{\\prime} + \\mathbf{x}_{1} (\\gamma^{1})^{\\prime \\prime} + \\left( \\dfrac{\\partial \\mathbf{x}_{2}}{\\partial \\gamma^{1}}\\dfrac{d \\gamma^{1}}{ds} + \\dfrac{\\partial \\mathbf{x}_{2}}{\\partial \\gamma^{2}}\\dfrac{d \\gamma^{2}}{ds} \\right) (\\gamma^{2})^{\\prime} + \\mathbf{x}_{2} (\\gamma^{2})^{\\prime \\prime} \\\\ =\u0026amp;\\ \\left( \\mathbf{x}_{11}(\\gamma^{1})^{\\prime} + \\mathbf{x}_{12}(\\gamma^{2})^{\\prime} \\right)(\\gamma^{1})^{\\prime} + \\mathbf{x}_{1} (\\gamma^{1})^{\\prime \\prime} + \\left( \\mathbf{x}_{21}(\\gamma^{1})^{\\prime} + \\mathbf{x}_{22}(\\gamma^{2})^{\\prime} \\right)(\\gamma^{2})^{\\prime} + \\mathbf{x}_{2} (\\gamma^{2})^{\\prime \\prime} \\\\ =\u0026amp;\\ \\mathbf{x}_{11}(\\gamma^{1})^{\\prime}(\\gamma^{1})^{\\prime} + \\mathbf{x}_{12}(\\gamma^{2})^{\\prime}(\\gamma^{1})^{\\prime} + \\mathbf{x}_{1} (\\gamma^{1})^{\\prime \\prime} + \\mathbf{x}_{21}(\\gamma^{1})^{\\prime}(\\gamma^{2})^{\\prime} + \\mathbf{x}_{22}(\\gamma^{2})^{\\prime}(\\gamma^{2})^{\\prime} + \\mathbf{x}_{2} (\\gamma^{2})^{\\prime \\prime} \\\\ =\u0026amp;\\ \\left( \\mathbf{x}_{11}(\\gamma^{1})^{\\prime}(\\gamma^{1})^{\\prime} + \\mathbf{x}_{12}(\\gamma^{2})^{\\prime}(\\gamma^{1})^{\\prime} + \\mathbf{x}_{21}(\\gamma^{1})^{\\prime}(\\gamma^{2})^{\\prime} + \\mathbf{x}_{22}(\\gamma^{2})^{\\prime}(\\gamma^{2})^{\\prime} \\right) + \\mathbf{x}_{1} (\\gamma^{1})^{\\prime \\prime} + \\mathbf{x}_{2} (\\gamma^{2})^{\\prime \\prime} \\\\ =\u0026amp;\\ \\sum \\limits_{j=1}^{2}\\left( \\mathbf{x}_{1j}(\\gamma^{j})^{\\prime}(\\gamma^{1})^{\\prime} + \\mathbf{x}_{2j}(\\gamma^{j})^{\\prime}(\\gamma^{2})^{\\prime} \\right) + \\mathbf{x}_{1} u_{1}^{\\prime \\prime} + \\mathbf{x}_{2} (\\gamma^{2})^{\\prime \\prime} \\\\ =\u0026amp;\\ \\sum \\limits_{i=1}^{2} \\left(\\sum \\limits_{j=1}^{2} \\mathbf{x}_{ij}(\\gamma^{j})^{\\prime}(\\gamma^{i})^{\\prime} + \\mathbf{x}_{i} (\\gamma^{i})^{\\prime \\prime} \\right) \\\\ =\u0026amp;\\ \\mathbf{x}_{ij}(\\gamma^{j})^{\\prime}(\\gamma^{i})^{\\prime} + \\mathbf{x}_{i} (\\gamma^{i})^{\\prime \\prime} \\end{align*} $$\nPart 2.\nSubstituting Gauss\u0026rsquo;s formulas (a) into $\\boldsymbol{\\gamma}^{\\prime \\prime}$,\n$$ \\begin{align*} \\boldsymbol{\\gamma}^{\\prime \\prime} (s) \u0026amp;= \\sum \\limits_{i=1}^{2} \\sum \\limits_{j=1}^{2} \\mathbf{x}_{ij} (\\gamma^{i})^{\\prime} (\\gamma^{j})^{\\prime} + \\sum \\limits_{k=1}^{2} \\mathbf{x}_{k} (\\gamma^{k})^{\\prime \\prime} \\\\ \u0026amp;= \\sum \\limits_{i=1}^{2} \\sum \\limits_{j=1}^{2} \\left( L_{ij} \\mathbf{n} + \\sum \\limits_{k=1}^{2} \\Gamma_{ij}^{k} \\mathbf{x}_{k} \\right) (\\gamma^{i})^{\\prime} (\\gamma^{j})^{\\prime} + \\sum \\limits_{k=1}^{2} \\mathbf{x}_{k} (\\gamma^{k})^{\\prime \\prime} \\\\ \u0026amp;= \\sum \\limits_{i=1}^{2} \\sum \\limits_{j=1}^{2} L_{ij} (\\gamma^{i})^{\\prime} (\\gamma^{j})^{\\prime} \\mathbf{n} + \\sum \\limits_{k=1}^{2}\\left( (\\gamma^{k})^{\\prime \\prime} + \\sum \\limits_{i=1}^{2} \\sum \\limits_{j=1}^{2} \\Gamma_{ij}^{k} (\\gamma^{i})^{\\prime} (\\gamma^{j})^{\\prime} \\right)\\mathbf{x}_{k} \\end{align*} $$\nHowever, because it is expressed as $\\boldsymbol{\\gamma}^{\\prime \\prime} = \\kappa_{n}\\mathbf{n} + \\kappa_{g}\\mathbf{S}$in this way\n$$ \\kappa_{n} = \\sum \\limits_{i=1}^{2} \\sum \\limits_{j=1}^{2} L_{ij} (\\gamma^{i})^{\\prime} (\\gamma^{j})^{\\prime} $$\n$$ \\kappa_{g}\\mathbf{S} = \\sum \\limits_{k=1}^{2}\\left( (\\gamma^{k})^{\\prime \\prime} + \\sum \\limits_{i=1}^{2} \\sum \\limits_{j=1}^{2} \\Gamma_{ij}^{k} (\\gamma^{i})^{\\prime} (\\gamma^{j})^{\\prime} \\right)\\mathbf{x}_{k} $$\n‚ñ†\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p104-105\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3160,"permalink":"https://freshrimpsushi.github.io/en/posts/3160/","tags":null,"title":"Gauss's Theorem in Differential Geometry"},{"categories":"Í∏∞ÌïòÌïô","contents":"Buildup Let $\\mathbf{x} : U \\to \\mathbb{R}^{3}$ represent a coordinate mapping. In differential geometry, the characteristics and properties of geometric objects are described through differentiation. Therefore, the derivatives of the coordinate fragments $\\mathbf{x}$ appear in various theorems and formulas. For instance, the first-order derivatives $\\left\\{ \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\}$ become the basis of the tangent space $T_{p}M$. Hence, any tangent vector $\\mathbf{X} \\in T_{p}M$ can be expressed as follows:\n$$ \\mathbf{X} = X^{1}\\mathbf{x}_{1} + X^{2}\\mathbf{x}_{2} $$\nNow consider the second-order derivatives of the coordinate mapping, $\\mathbf{x}_{ij} = \\dfrac{\\partial^{2} \\mathbf{x}}{\\partial u_{i} \\partial u_{j}}$. Since this is a vector of $\\mathbb{R}^{3}$, it can be represented as a linear combination of the bases of $\\mathbb{R}^{3}$. However, we already know three vectors in $\\mathbb{R}^{3}$ that are orthogonal to each other, which are the first-order derivatives and the unit normal.\n$$ \\left\\{ \\mathbf{n}, \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\} $$\nThen, $\\mathbf{x}_{ij}$ can be expressed as follows:\n$$ \\mathbf{x}_{ij} = a_{ij} \\mathbf{n} + b^{1}_{ij} \\mathbf{x}_{1} + b^{2}_{ij} \\mathbf{x}_{2} $$\nThese coefficients $b_{ij}^{1}, b_{ij}^{2}$ are called Christoffel symbols. Now, let\u0026rsquo;s concretely determine these coefficients. According to the properties of the first fundamental form, the following holds:\n$$ \\begin{align*} \u0026amp;\u0026amp; \\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle \u0026amp;=\\ b_{ij}^{1}\\left\\langle \\mathbf{x}_{1}, \\mathbf{x}_{l} \\right\\rangle + b_{ij}^{2}\\left\\langle \\mathbf{x}_{2}, \\mathbf{x}_{l} \\right\\rangle \\\\ \u0026amp;\u0026amp; \u0026amp;=\\ \\sum\\limits_{k^{\\prime}=1}^{2}b_{ij}^{k^{\\prime}}\\left\\langle \\mathbf{x}_{k^{\\prime}}, \\mathbf{x}_{l} \\right\\rangle \\\\ \u0026amp;\u0026amp; \u0026amp;=\\ \\sum\\limits_{k^{\\prime}=1}^{2}b_{ij}^{k^{\\prime}} g_{k^{\\prime}l} \\\\ \\implies \u0026amp;\u0026amp; \\sum\\limits_{l=1}^{2}\\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle g^{lk} \u0026amp;=\\ \\sum\\limits_{l=1}^{2}\\sum\\limits_{k^{\\prime}=1}^{2}b_{ij}^{k^{\\prime}} g_{k^{\\prime}l}g^{lk} \\\\ \u0026amp;\u0026amp; \u0026amp;=\\ \\sum\\limits_{k^{\\prime}=1}^{2}b_{ij}^{k^{\\prime}} \\delta_{k^{\\prime}}^{k} \\\\ \u0026amp;\u0026amp; \u0026amp;=\\ b_{ij}^{k} \\end{align*} $$\nNow let\u0026rsquo;s denote these $b_{ij}^{k}$ as $\\Gamma_{ij}^{k}$ and define it as follows:\nDefinition The $\\Gamma_{ij}^{k}(1\\le i,j,k \\le 2)$ defined as follows is called the Christoffel symbol.\n$$ \\Gamma_{ij}^{k} := \\sum \\limits_{l=1}^{2} \\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle g^{lk} = \\left\\langle \\mathbf{x}_{ij}, \\mathbf{x}_{l} \\right\\rangle g^{lk} $$\nThe omitted equation for $\\sum$ uses the Einstein notation.\nExplanation Because of $\\mathbf{x}_{12} = \\mathbf{x}_{21}$, it follows that $\\Gamma_{12}^{k} = \\Gamma_{21}^{k}$.\nThe tangent components $b_{ij}^{k}$ of $\\mathbf{x}_{ij}$ are denoted as $\\Gamma_{ij}^{k}$ and called Christoffel symbols, and the normal component $a_{ij}$ of $\\mathbf{x}_{ij}$ is denoted as $L_{ij}$ and called the coefficient of the second fundamental form.\nThe Christoffel symbols introduced above specifically refer to the second Christoffel symbol. The first Christoffel symbol is defined as follows.\n$$ \\Gamma_{ij \\vert l} := \\sum \\limits_{k=1}^{2} \\Gamma_{ij}^{k}g_{kl} $$\nUsually, when referring to Christoffel symbols, it means the second symbol. G. B. Christoffel was the first to use these symbols, and at that time, the second symbol was written as $\\begin{Bmatrix} ij \\\\ k \\end{Bmatrix}$.\nSee also First fundamental form Second fundamental form ","id":3158,"permalink":"https://freshrimpsushi.github.io/en/posts/3158/","tags":null,"title":"Christoffel Symbols in Differential Geometry"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 When drawing a heatmap, sometimes it\u0026rsquo;s essential to fix the scale of values, so they don\u0026rsquo;t adjust with the numerical values. You can fix the color range using the clim option in the basic heatmap function.\nusing Plots\rcd(@__DIR__)\rheatmap(rand(4,4)); png(\u0026#34;1.png\u0026#34;)\rheatmap(rand(4,4), clim = (0,1)); png(\u0026#34;2.png\u0026#34;) The results are as follows. The first heatmap has no fixed range, but the second heatmap\u0026rsquo;s range is fixed between 0 and 1, as you can see.\nLimiting Only One Side heatmap(rand(4,4), clim = (0,Inf))\rheatmap(rand(4,4), clim = (-Inf,1)) If you want to set only an upper or a lower limit, you can do so by using Inf as shown above to open the bounds.\nEnvironment OS: Windows julia: v1.6.0 See Also In matplotlib.pyplot of Python https://discourse.julialang.org/t/setting-min-and-max-values-in-a-heatmap-plots-jl/36496\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2126,"permalink":"https://freshrimpsushi.github.io/en/posts/2126/","tags":null,"title":"How to Specify Heatmap Color Ranges in Julia"},{"categories":"ÌôïÎ•†ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition 1 $$ d X(t) = f \\left( t, X(t) \\right) dt + g \\left( t, X(t) \\right) d W_{t} \\qquad , t \\in \\left[ t_{0} , T \\right], T \u0026gt; 0 $$\nEquations of the form above are called Stochastic Differential Equations, abbreviated as SDEs. Here, $f$ and $g$ are called the drift and diffusion coefficient functions, respectively. For the initial condition $X_{0} := X \\left( t_{0} \\right)$, the integral form is represented as follows.\n$$ X(t) = X_{0} + \\int_{t_{0}}^{t} f \\left( s, X (s) \\right) ds + \\int_{t_{0}}^{t} g \\left( s, X (s) \\right) d W_{s} $$\nExplanation $$ d X_{t} = f \\left( t, X_{t}\\right) dt + g \\left( t, X_{t} \\right) d W_{t} $$\nIf this form doesn\u0026rsquo;t bother you, it\u0026rsquo;s either because you\u0026rsquo;ve studied Ito calculus very well or know very little about differential equations, one or the other. For someone familiar with differential equations but not with SDEs, naturally $g d W_{t}$ would be an eyesore. Unlike ODEs, SDEs incorporate this stochastic process, adding uncertainty to the model. Considering this term as $0$, that is, $g d W_{t} = 0$ as a nondeterministic system, we can see the following. $$ \\begin{align*} d X(t) =\u0026amp; f \\left( t, X(t) \\right) dt + g \\left( t, X(t) \\right) d W_{t} \\\\ =\u0026amp; f \\left( t, X(t) \\right) dt + 0 \\\\ =\u0026amp; f \\left( t, X(t) \\right) dt \\end{align*} $$ Dividing both sides by $dt$, we get $$ {{ d X (t) } \\over { dt }} = f \\left( t, X(t) \\right) $$ Therefore, we can see that we have reclaimed the look of a well-known non-autonomous system.\nDrift In this explanation, recalling drift in time series analysis makes it quite natural to refer to the coefficient function $f$ as drift. This is because, regardless of the latter term, $f dt$ is the driving force that allows the system to be managed as a system itself.\nDiffusion Then, referring to $g$ as diffusion naturally suggests its role or characteristic of spreading or dispersing. In stochastic differential equations, this points to the concept of white noise, and unique results like Ito\u0026rsquo;s lemma arise due to such noise.\nPanik. (2017). Stochastic Differential Equations: An Introduction with Applications in Population Dynamics Modeling: p133.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2125,"permalink":"https://freshrimpsushi.github.io/en/posts/2125/","tags":null,"title":"What is a Stochastic Differential Equation?"},{"categories":"Í∏∞ÌïòÌïô","contents":"Build-up Let $\\mathbf{x} : U \\to \\mathbb{R}^{3}$ be referred to as a chart. In differential geometry, the characteristics and properties of geometric objects are explained through differentiation. Hence, the derivatives of coordinate charts $\\mathbf{x}$ appear in various theorems and formulas. For instance, the first-order derivatives $\\left\\{ \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\}$ become the basis of the tangent space $T_{p}M$. Therefore, any tangent vector $\\mathbf{X} \\in T_{p}M$ can be expressed as follows.\n$$ \\mathbf{X} = X^{1}\\mathbf{x}_{1} + X^{2}\\mathbf{x}_{2} $$\nNow, let\u0026rsquo;s think about the second-order derivatives $\\mathbf{x}_{ij} = \\dfrac{\\partial^{2} \\mathbf{x}}{\\partial u_{i} \\partial u_{j}}$ of the chart. Since this is a vector in $\\mathbb{R}^{3}$, it can be represented as a linear combination of the basis of $\\mathbb{R}^{3}$. But we already know three vectors in $\\mathbb{R}^{3}$ that are perpendicular to each other, which are the first-order derivatives and the unit normal.\n$$ \\left\\{ \\mathbf{n}, \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\} $$\nThen, $\\mathbf{x}_{ij}$ can be represented as follows.\n$$ \\mathbf{x}_{ij} = a_{ij} \\mathbf{n} + b^{1}_{ij} \\mathbf{x}_{1} + b^{2}_{ij} \\mathbf{x}_{2} $$\nThe coefficients $a_{ij} = \\left\\langle \\mathbf{x}_{ij}, \\mathbf{n} \\right\\rangle$ of the $\\mathbf{n}$ terms of $\\mathbf{x}_{ij}$ are called the coefficients of the second fundamental form of $\\mathbf{x}$.\nDefinition The inner product of $\\mathbf{x}_{ij}$ and the unit normal $\\mathbf{n}$, denoted as $L_{ij}$, is called the coefficients of the second fundamental form.\n$$ L_{ij} := \\left\\langle \\mathbf{x}_{ij}, \\mathbf{n} \\right\\rangle $$\nLet $\\mathbf{X}, \\mathbf{Y}$ be a vector in the tangent space $T_{P}M$ of the surface $\\mathbf{x}$. Since the basis of the tangent space is $\\left\\{ \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\}$, it can be represented as follows.\n$$ \\mathbf{X} = X^{1}\\mathbf{x}_{1} + X^{2}\\mathbf{x}_{2} \\quad \\text{and} \\quad \\mathbf{Y} = Y^{1}\\mathbf{x}_{1} + Y^{2}\\mathbf{x}_{2} $$\nThe following bilinear form $II$ is defined as the second fundamental form of the surface $\\mathbf{x}$.\n$$ II (\\mathbf{X}, \\mathbf{Y}) = \\sum \\limits_{i=1}^{2} \\sum \\limits_{j=1}^{2} L_{ij}X^{i}Y^{j} = L_{ij}X^{i}Y^{j} = \\begin{bmatrix} X^{1} \u0026amp; X^{2}\\end{bmatrix} \\begin{bmatrix} L_{11} \u0026amp; L_{12} \\\\ L_{21} \u0026amp; L_{22} \\end{bmatrix} \\begin{bmatrix} Y^{1} \\\\ Y^{2}\\end{bmatrix} $$\nThe omission of $\\sum$ uses Einstein notation.\nExplanation Since $\\mathbf{x}_{12} = \\mathbf{x}_{21}$, then $L_{12} = L_{21}$.\nThe normal component $a_{ij}$ of $\\mathbf{x}_{ij}$ is denoted as $L_{ij}$ and called the coefficient of the second fundamental form, and the tangential components $b_{ij}^{k}$ of $\\mathbf{x}_{ij}$ are denoted as $\\Gamma_{ij}^{k}$ and called Christoffel symbols.\nIf the first fundamental form was related to the function of the length of curves on the surface, then the second fundamental form is an indicator of how much the surface is curved, related to the Gaussian curvature $\\kappa_{n}$ and related.\nThe first fundamental form is also called Riemannian metric, while the second fundamental form is simply referred to as the second fundamental form.\nSee Also First Fundamental Form Christoffel Symbols ","id":3156,"permalink":"https://freshrimpsushi.github.io/en/posts/3156/","tags":null,"title":"Second Fundamental Form in Differential Geometry"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview 1 In Python, zfill() actually serves as a method of the string class, filling the left side with zeros. Julia, on the other hand, offers the lpad() as a more versatile and widely applicable built-in function. While zfill() means to fill with zeros, lpad() signifies padding to the left.\nCode julia\u0026gt; lpad(\u0026#34;12\u0026#34;, 4, \u0026#34;0\u0026#34;)\r\u0026#34;0012\u0026#34;\rjulia\u0026gt; lpad(12, 4, \u0026#34;0\u0026#34;)\r\u0026#34;0012\u0026#34; Continuing from the overview, lpad() in Julia is more generic compared to zfill(). It\u0026rsquo;s not a method of the string, so it returns a string whether the argument is a string or a number.\njulia\u0026gt; lpad(12, 4)\r\u0026#34; 12\u0026#34;\rjulia\u0026gt; lpad(12, 4, \u0026#34;_\u0026#34;)\r\u0026#34;__12\u0026#34;\rjulia\u0026gt; lpad(12, 4, \u0026#34;_!\u0026#34;)\r\u0026#34;_!12\u0026#34;\rjulia\u0026gt; lpad(12, 4, \u0026#34;_?!\u0026#34;)\r\u0026#34;_?12\u0026#34;\rjulia\u0026gt; lpad(12, 7, \u0026#34;_?!\u0026#34;)\r\u0026#34;_?!_?12\u0026#34; The common reason for using such a function is to tidy up the output aligning spaces, not necessarily because zeros are needed. If no filling character is provided, it uses a space, and if a character or string is given, it intelligently fills it as seen above.\njulia\u0026gt; rpad(\u0026#34;left\u0026#34;, 6, \u0026#39;0\u0026#39;)\r\u0026#34;left00\u0026#34; Of course, there\u0026rsquo;s also the rpad() function. It has the same basic functionality, only differing in that it pads to the right.\nEnvironment OS: Windows julia: v1.6.0 https://docs.julialang.org/en/v1/base/strings/#Base.lpad\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2124,"permalink":"https://freshrimpsushi.github.io/en/posts/2124/","tags":null,"title":"How to Use zfill() in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Buildup1 $$ \\left\\{ T(s), N(s), B(s), \\kappa (s), \\tau (s) \\right\\} $$\nRecall how we used the Frenet-Serret apparatus when analyzing curves. When studying surfaces, we will consider similar concepts. When $\\boldsymbol{\\alpha}$ is the unit speed curve, the curvature of the curve was defined as the magnitude of acceleration $\\kappa = \\left| T^{\\prime} \\right| = \\left| \\boldsymbol{\\alpha}^{\\prime \\prime} \\right|$. It is natural to think about how curved a surface is by looking at how curved the curves on the surface are.\nConsider the surface given as $\\mathbf{x} : U\\subset \\R^{2} \\to M$. Let $\\boldsymbol{\\alpha}(s)$ be the unit speed curve on the simple surface $\\mathbf{x}$. Then let\u0026rsquo;s denote the Frenet-Serret apparatus for $\\boldsymbol{\\alpha}$ as follows.\n$$ \\left\\{ \\mathbf{T}, \\mathbf{N}, \\mathbf{B}, \\kappa, \\tau \\right\\} $$\nLet\u0026rsquo;s call the unit normal at point $p \\in M$ as $\\mathbf{n}$. Let\u0026rsquo;s define the set of all vectors that are point $p$ as $N_{p}M$.\n$$ N_{p}M := \\left\\{ r \\mathbf{n} : r \\in \\R \\right\\} = \\left\\{ \\text{all vectors perpendicular to } M \\text{ at } p \\right\\} $$\nThen by definition of the tangent plane, $T_{p}M$ is the orthogonal complement of $N_{p}M$.\n$$ N_{p}M ^{\\perp} = T_{p}M $$\nTherefore, $\\R^{3}$ is orthogonally decomposed as follows, and $\\boldsymbol{\\alpha}^{\\prime \\prime}$ can be expressed as the linear combination of vectors of the two spaces.\n$$ \\R^{3} = N_{p}M \\oplus T_{p}M \\quad \\text{and} \\quad \\boldsymbol{\\alpha}^{\\prime \\prime}(s) = n_{1}\\mathbf{n}(s) + n_{2}\\mathbf{n}^{\\perp}(s)\\quad (\\mathbf{n}\\in N_{p}M,\\ \\mathbf{n}^{\\perp}\\in T_{p}M) $$\nLet\u0026rsquo;s call $\\mathbf{T} = \\boldsymbol{\\alpha}^{\\prime}$ the tangent vector. Since $\\boldsymbol{\\alpha}$ is the unit speed vector, the following equation holds.\n$$ \\left| \\boldsymbol{\\alpha}^{\\prime}(s) \\right|^{2} = \\left| \\mathbf{T}(s) \\right|^{2} = \\left\\langle \\mathbf{T}, \\mathbf{T} \\right\\rangle = 1 $$\nDifferentiating both sides gives the following result by the derivative of dot product.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\left\\langle \\mathbf{T}, \\mathbf{T} \\right\\rangle^{\\prime} =\u0026amp;\\ 0 \\\\ \\implies \u0026amp;\u0026amp; \\left\\langle \\mathbf{T}^{\\prime}, \\mathbf{T} \\right\\rangle =\u0026amp;\\ 0 \\\\ \\implies \u0026amp;\u0026amp; \\left\\langle \\boldsymbol{\\alpha}^{\\prime \\prime}, \\mathbf{T} \\right\\rangle =\u0026amp;\\ 0 \\end{align*} $$\nTherefore, $\\boldsymbol{\\alpha}^{\\prime \\prime}$ is perpendicular to $\\mathbf{T}$. Separating $\\boldsymbol{\\alpha}^{\\prime \\prime}$, since $\\mathbf{n}$ and $\\mathbf{T}$ are perpendicular to each other, we obtain the following.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\left\\langle \\boldsymbol{\\alpha}^{\\prime \\prime}, \\mathbf{T} \\right\\rangle =\u0026amp;\\ 0 \\\\ \\implies \u0026amp;\u0026amp; \\left\\langle n_{1}\\mathbf{n} + n_{2}\\mathbf{n}^{\\perp}, \\mathbf{T} \\right\\rangle =\u0026amp;\\ 0 \\\\ \\implies \u0026amp;\u0026amp; \\left\\langle n_{1}\\mathbf{n}, \\mathbf{T} \\right\\rangle + \\left\\langle n_{2}\\mathbf{n}^{\\perp}, \\mathbf{T} \\right\\rangle =\u0026amp;\\ 0 \\\\ \\implies \u0026amp;\u0026amp; \\left\\langle n_{2}\\mathbf{n}^{\\perp}, \\mathbf{T} \\right\\rangle =\u0026amp;\\ 0 \\end{align*} $$\nTherefore, it can be known that $\\mathbf{n}^{\\perp}$ is a vector perpendicular to both $\\mathbf{n}$ and $\\mathbf{T}$. Let\u0026rsquo;s define the vector $\\mathbf{S}$ as follows.\n$$ \\mathbf{S} := \\mathbf{n}\\times \\mathbf{T} \\quad \\text{and} \\quad \\boldsymbol{\\alpha}^{\\prime \\prime} = n_{1}\\mathbf{n} + s\\mathbf{S} $$\n$\\mathbf{S}$ is called the intrinsic normal of $\\boldsymbol{\\alpha}$.\nDefinition The component $n_{1}$ of $\\mathbf{n}$ is called the normal curvature of the unit speed curve $\\boldsymbol{\\alpha}$, denoted as $\\kappa_{n}$.\n$$ \\kappa_{n} := \\left\\langle \\boldsymbol{\\alpha}^{\\prime \\prime}, \\mathbf{n} \\right\\rangle $$\nThe component $s$ of $\\mathbf{S}$ is called the geodesic curvature of the unit speed curve $\\boldsymbol{\\alpha}$, denoted as $\\kappa_{g}$.\n$$ \\kappa_{g} := \\left\\langle \\boldsymbol{\\alpha}^{\\prime \\prime}, \\mathbf{S} \\right\\rangle $$\nTherefore, the following equation holds.\n$$ \\kappa (s) \\mathbf{N}(s) = \\mathbf{T}^{\\prime}(s) = \\boldsymbol{\\alpha}^{\\prime \\prime}(s) = \\kappa_{n}(s)\\mathbf{n}(s) + \\kappa_{g}(s)\\mathbf{S}(s) $$\nExplanation The normal curvature $\\kappa_{n}$ is used to measure how much the surface $M$ is curved at $\\R^{3}$. The geodesic curvature $\\kappa_{g}$ is used to measure how much the curve $\\boldsymbol{\\alpha}$ is curved on the surface $M$. For example, a curve with the geodesic curvature $\\kappa_{g}$ equal to $0$ implies a straight line on the surface, i.e., a geodesic.\nSince $\\mathbf{n}, \\mathbf{S}$ is a unit vector, the following equation holds according to the definition above.\n$$ \\kappa^{2} = \\kappa_{n}^{2} + \\kappa_{g}^{2} $$\nRichard S. Millman and George D. parker, Elements of Differential Geometry (1977), p102-104\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3154,"permalink":"https://freshrimpsushi.github.io/en/posts/3154/","tags":null,"title":"Gauss Curvature and Geodesic Curvature"},{"categories":"ÌôïÎ•†ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Theorem 1 Given an It√¥ process $\\left\\{ X_{t} \\right\\}_{t \\ge 0}$, $$ d X_{t} = u dt + v d W_{t} $$ for a function $V \\left( t, X_{t} \\right) = V \\in C^{2} \\left( [0,\\infty) \\times \\mathbb{R} \\right)$, let $Y_{t} := V \\left( t, X_{t} \\right)$, then $\\left\\{ Y_{t} \\right\\}$ is also an It√¥ process and the following holds: $$ \\begin{align*} d Y_{t} =\u0026amp; V_{t} dt + V_{x} d X_{t} + {{ 1 } \\over { 2 }} V_{xx} \\left( d X_{t} \\right)^{2} \\\\ =\u0026amp; \\left( V_{t} + V_{x} u + {{ 1 } \\over { 2 }} V_{xx} v^{2} \\right) dt + V_{x} v d W_{t} \\end{align*} $$\n$C^{2}$ is a class of functions that are twice differentiable and their derivatives are continuous. $\\displaystyle V_{t} = {{ \\partial V } \\over { \\partial t }}$, $\\displaystyle V_{x} = {{ \\partial V } \\over { \\partial X_{t} }}$, and $\\displaystyle V_{xx} = {{ \\partial^{2} V } \\over { \\partial X_{t}^{2} }}$. $\\left( d X_{t} \\right)^{2} = d X_{t} \\cdot d X_{t}$ is calculated according to the following It√¥ multiplication table. $$ \\begin{align*} \\left( dt \\right)^{2} =\u0026amp; 0 \\\\ dt d W_{t} =\u0026amp; 0 \\\\ d W_{t} dt =\u0026amp; 0 \\\\ \\left( d W_{t} \\right)^{2} =\u0026amp; dt \\end{align*} $$ Therefore, $$ \\begin{align*} \\left( d X_{t} \\right)^{2} =\u0026amp; \\left( u dt + v d W_{t} \\right) \\left( u dt + v d W_{t} \\right) \\\\ =\u0026amp; u^{2} \\left( dt \\right)^{2} + 2 uv dt d W_{t} + v^{2} \\left( d W_{t} \\right)^ {2} \\\\ =\u0026amp; u^{2} \\cdot 0 + 2 \\cdot 0 + v^{2} dt \\\\ =\u0026amp; v^{2} dt \\end{align*} $$ is obtained. Explanation The It√¥ formula is also known as the It√¥ lemma or It√¥ chain rule and is a crucial theorem used throughout stochastic differential equations. Because it frequently appears in almost all calculations, it certainly merits being called a chain rule.\nThe proof is omitted here, but simply applies the multivariable Taylor theorem and disregards higher-order terms.\nExample Integrating a Wiener process by a Wiener process is intuitively difficult to understand. Formally, one might naturally expect a result like $\\displaystyle \\int_{0}^{t} W_{s} d W_{s} = {{ 1 } \\over { 2 }} W_{t}^{2}$, similar to Riemann integration, but let\u0026rsquo;s calculate and see if this is the case.\nBefore using the It√¥ formula, set the given It√¥ process to $u = 0$, $v = 1$ such that $$ d X_{t} = 0 dt + 1 d W_{t} $$ then $X_{t} = W_{t}$. Here, if we let $\\displaystyle Y_{t} := V \\left( t , X_{t} \\right) = {{ X_{t}^{2} } \\over { 2 }}$, $$ \\begin{align*} V_{t} =\u0026amp; {{ \\partial } \\over { \\partial t }} \\left( {{ 1 } \\over { 2 }} W_{t}^{2} \\right) = 0 \\\\ V_{x} =\u0026amp; {{ \\partial } \\over { \\partial W_{t} }} \\left( {{ 1 } \\over { 2 }} W_{t}^{2} \\right) = W_{t} \\\\ V_{xx} =\u0026amp; {{ \\partial^{2} } \\over { \\partial W_{t}^{2} }} \\left( {{ 1 } \\over { 2 }} W_{t}^{2} \\right) = {{ \\partial } \\over { \\partial W_{t} }} W_{t} = 1 \\end{align*} $$ then from $u = 0$, $v = 1$, $$ \\begin{align*} d \\left( {{ W_{t}^{2} } \\over { 2 }} \\right) =\u0026amp; \\left( V_{t} + V_{x} u + {{ 1 } \\over { 2 }} V_{xx} v^{2} \\right) dt + V_{x} v d W_{t} \\\\ =\u0026amp; \\left( 0 + W_{t} \\cdot 0 + {{ 1 } \\over { 2 }} \\cdot 1 \\cdot 1^{2} \\right) dt + W_{t} \\cdot 1 \\cdot d W_{t} \\\\ =\u0026amp; {{ 1 } \\over { 2 }} dt + W_{t} d W_{t} \\end{align*} $$ converting the differential form to the integral form yields $$ {{ W_{t}^{2} } \\over { 2 }} = {{ 1 } \\over { 2 }} t + \\int_{0}^{t} W_{s} d W_{s} $$ Summarizing gives the following. $$ \\int_{0}^{t} W_{s} d W_{s} = {{ 1 } \\over { 2 }} \\left( W_{t}^{2} - t \\right) $$ At first glance, the presence of the $1$th term $-t /2$, which was not in Riemann integration, might seem messy and inconvenient. However, considering taking the expectation, $$ t = \\text{Var} \\left( W_{t} \\right) = E \\left( W_{t}^{2} \\right) - 0^{2} $$ thus it disappears neatly as $$ E \\left( \\int_{0}^{t} W_{s} d W_{s} \\right) = {{ 1 } \\over { 2 }} \\left( t - t \\right) = 0 $$. The $1$th term is not just garbage generated due to a difference in calculation methods but has its own meaningful existence. If one concurs that the expectation when integrating a Wiener process by a Wiener process should be $0$, then one can intuitively accept the above conclusion.\nStochastic Integration 2 Let $a \u0026lt; b$ and $c$ be a constant and let $t \u0026gt; 0$.\n$$ \\begin{align*} \\int_{0}^{t} d W_{s} =\u0026amp; W_{t} \\\\ \\int_{a}^{b} c d W_{s} =\u0026amp; c \\left[ W_{b} - W_{a} \\right] \\end{align*} $$\nThe above two cases yield the same results as ordinary Riemann integration, but the following yields a unique result only seen in It√¥ integration.\n$$ \\begin{align*} \\int_{0}^{t} W_{s} d W_{s} =\u0026amp; {{ 1 } \\over { 2 }} W_{t}^{2} - {{ 1 } \\over { 2 }} t \\\\ \\int_{a}^{b} W_{s} d W_{s} =\u0026amp; {{ 1 } \\over { 2 }} \\left[ W_{b}^{2} - W_{a}^{2} \\right] - {{ 1 } \\over { 2 }} (b-a) \\\\ \\int_{0}^{t} s d W_{s} =\u0026amp; t W_{t} - \\int_{0}^{t} W_{s} ds = (t-1) W_{t} \\\\ \\int_{0}^{t} W_{s}^{2} d W_{s} =\u0026amp; {{ 1 } \\over { 3 }} W_{t}^{3} - \\int_{0}^{t} W_{s} ds \\\\ \\int_{0}^{t} e^{W_{s}} d W_{s} =\u0026amp; e^{W_{t}} - 1 - {{ 1 } \\over { 2 }} \\int_{0}^{t} e^{W_{s}} ds \\\\ \\int_{0}^{t} W_{t} e^{W_{s}} d W_{s} =\u0026amp; 1 + W_{t} e^{W_{t}} - e^{W_{t}} - {{ 1 } \\over { 2 }} \\int_{0}^{t} e^{W_{s}} \\left( 1 + W_{s} \\right) d W_{s} \\\\ \\int_{0}^{t} s W_{s} d W_{s} =\u0026amp; {{ t } \\over { 2 }} \\left( W_{t}^{2} - {{ t } \\over { 2 }} \\right) - {{ 1 } \\over { 2 }} \\int_{0}^{t} W_{s}^{2} ds \\\\ \\int_{0}^{t} \\left( W_{s}^{2} - s \\right) d W_{s} =\u0026amp; {{ 1 } \\over { 3 }} W_{t}^{3} - t W_{t} \\\\ \\int_{0}^{t} e^{-s/2 + W_{s}} d W_{s} =\u0026amp; e^{-t/2 + W_{t}} - 1 \\\\ \\int_{0}^{t} \\sin W_{s} d W_{s} =\u0026amp; 1 - \\cos W_{t} - {{ 1 } \\over { 2 }} \\int_{0}^{t} \\cos W_{s} ds \\\\ \\int_{0}^{t} \\cos W_{s} d W_{s} =\u0026amp; \\sin W_{t} + {{ 1 } \\over { 2 }} \\int_{0}^{t} \\sin W_{s} ds \\end{align*} $$\nEspecially regarding the expectation and variance, the following equations are known.\n$$ \\begin{align*} E \\left( \\int_{0}^{t} d W_{s} \\right) =\u0026amp; 0 \\\\ E \\left( \\int_{0}^{t} W_{s} d W_{s} \\right) =\u0026amp; 0 \\\\ \\text{Var} \\left( \\int_{0}^{t} W_{s} d W_{s} \\right) =\u0026amp; {{ t^{2} } \\over { 2 }} \\end{align*} $$\n√òksendal. (2003). Stochastic Differential Equations: An Introduction with Applications: p48.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPanik. (2017). Stochastic Differential Equations: An Introduction with Applications in Population Dynamics Modeling: p125.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2121,"permalink":"https://freshrimpsushi.github.io/en/posts/2121/","tags":null,"title":"Ito's Formula"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 2 Let $\\mathbf{x} : U \\to \\R^{3}$ be called a simple surface. Let the coordinates of $U$ be called $(u, v)$. For any point $(u_{0}, v_{0})$, the following curve is called the $u-$parameter curve at $v = v_{0}$ of $\\mathbf{x}$.\n$$ u \\mapsto \\mathbf{x}(u, v_{0}) $$\nThe following curve is called the $v-$parameter curve at $u = u_{0}$ of $\\mathbf{x}$.\n$$ v \\mapsto \\mathbf{x}(u_{0}, v) $$\nThe velocity vectors $\\dfrac{\\partial \\mathbf{x}}{\\partial u} = \\mathbf{x}_{u}=\\mathbf{x}_{1}$, $\\dfrac{\\partial \\mathbf{x}}{\\partial v} = \\mathbf{x}_{v}=\\mathbf{x}_{2}$ of the two parameter curves at point $(u_{0}, v_{0})$ are called the partial velocity vectors of $\\mathbf{x}$ at $(u_{0}, v_{0})$.\nExplanation The coordinates of $U$ are often also written as $(u^{1}, u^{2})$, so the above-mentioned curves are also called the $u^{1}$-curve and the $u^{2}$-curve, respectively.\nAccording to the definition, it can be understood that the surface $\\mathbf{x}$ is covered by a family of such parameter curves.\nThe grid formed by these two parameter curves is called a curvilinear coordinate system, which includes the spherical and cylindrical coordinate systems.\nBarrett O\u0026rsquo;Neill, Elementary Differential Geometry (Revised 2nd Edition, 2006), p139-141\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p84\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3152,"permalink":"https://freshrimpsushi.github.io/en/posts/3152/","tags":null,"title":"Parametric Curves on a Simple Surface"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code propertynames() You can check with the propertynames() function1. Since Julia has no classes, only structs2, all symbols returned by this function are precisely the names of properties only.\nThe following is code for creating an Erd≈ës‚ÄìR√©nyi network in the Graphs package, checking the number of nodes, and each node\u0026rsquo;s neighborhood. The propertynames() function was used on this network, and :ne and fadjlist properties were returned as symbols.\n‚ñ£code1‚ñ£\nfieldnames() This is a bit of a more complicated story, but not knowing it doesn\u0026rsquo;t really impact Julia programming.\nFundamentally, propertynames(x) is the same as fieldnames(typeof(x))3. Although not very significant as a function in practical use, the fact we can learn from this is that in Julia, the instance of a structure is called an object, the attributes a structure itself possesses are called fields, and the properties of an object existing as an instance are called properties.\nEnvironment OS: Windows julia: v1.6.0 https://docs.julialang.org/en/v1/base/base/#Base.propertynames\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/a/56352954\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://docs.julialang.org/en/v1/base/base/#Base.fieldnames\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2120,"permalink":"https://freshrimpsushi.github.io/en/posts/2120/","tags":null,"title":"Checking Struct Properties in Julia"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition Given a partial differential equation defined in an open set $\\Omega$, let\u0026rsquo;s assume the values of the unknown $u$ are given on the boundary $\\partial \\Omega$ of $\\Omega$. This is called a boundary condition. The partial differential equation together with the boundary condition is referred to as a boundary value problem.\nDescription The abbreviation BVP is commonly used.\nTo solve a boundary value problem means to find a solution $u$ that satisfies the boundary conditions within the given partial differential equation.\nExamples Dirichlet boundary conditions\n$$ u = 0 \\quad \\text{on } \\partial \\Omega $$\nNeumann boundary conditions\n$$ \\dfrac{\\partial u}{\\partial \\nu} = 0 \\quad \\text{on } \\partial \\Omega $$\nHere, $\\nu$ is the outward unit normal vector.\nMixed Dirichlet-Neumann boundary conditions[^1]\nWhen $\\partial \\Omega$ contains two different closed sets $\\Gamma_{1}$, $\\Gamma_{2}$,\n$$ \\begin{align*} u = 0\u0026amp; \\quad \\text{on } \\partial \\Gamma_{1} \\\\ \\dfrac{\\partial u}{\\partial \\nu} = 0\u0026amp; \\quad \\text{on } \\partial \\Gamma_{2} \\end{align*} $$\nRobin boundary conditions[^1]\n$$ u + \\dfrac{\\partial u}{\\partial \\nu} = 0 \\quad \\text{on } \\partial \\Omega $$\nSee Also Initial Value Problem (IVP) ‚ñ°re\n","id":3151,"permalink":"https://freshrimpsushi.github.io/en/posts/3151/","tags":null,"title":"Boundary Value Problems in Partial Differential Equations"},{"categories":"ÌôïÎ•†ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition 1 Given a probability space $( \\Omega , \\mathcal{F} , P)$ and a filtration $\\left\\{ \\mathcal{F}_{t} \\right\\}_{t \\ge 0}$, suppose that a Wiener process $\\left\\{ W_{t} \\right\\}_{t \\ge 0}$ is $\\mathcal{F}_{t}$-adapted, and for $f \\in \\mathcal{L}^{1} [0 , \\infty)$ and $g \\in \\mathcal{L}^{2} [0 , \\infty)$, we define a $1$-dimensional continuous $\\mathcal{F}_{t}$-adapted stochastic process $\\left\\{ X_{t} \\right\\}_{t \\ge 0}$ as a $1$-dimensional It√¥ Process. $$ X (t) := X_{0} + \\int_{0}^{t} f(s) ds + \\int_{0}^{t} g(s) d W_{s} $$\n$\\mathcal{L}^{p} (E)$ is the Lebesgue space consisting of functions with domain $E$. Explanation Normally, because there are many integral symbols, it is inconvenient to use the above definition as it is, so it is often expressed using Stochastic Differential. $$ d X(t) = f(t) dt + g(t) d W_{t} $$\nGeneralization 2 Suppose a $i \\ne j \\implies W_{i} (t) \\perp W_{j}$-dimensional Brownian motion $\\left\\{ \\mathbf{W}_{t} \\right\\}_{t \\ge 0} := \\left( W_{1} (t) , \\cdots , W_{m} (t) \\right)$ is $\\mathcal{F}_{t}$-adapted $$ \\begin{align*} \\mathbf{f} (t) = \\left( f_{1} (t) , \\cdots , f_{d} (t) \\right) \\in \u0026amp; \\mathcal{L}^{1} \\left( [0, \\infty)^{d} \\right) \\\\ \\mathbf{g} (t) = \\begin{bmatrix} g_{11} (t) \u0026amp; \\cdots \u0026amp; g_{1m} (t) \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ g_{d1} (t) \u0026amp; \\cdots \u0026amp; g_{dm} (t) \\end{bmatrix} \\in \u0026amp; \\mathcal{L}^{2} \\left( [0, \\infty)^{d \\times m} \\right) \\end{align*} $$ For vector functions $\\mathbf{f} : [0, \\infty) \\to \\mathbb{R}^{d}$ and matrix functions $\\mathbf{g} : [0, \\infty) \\to \\mathbb{R}^{d \\times m}$, we define a $d$-dimensional continuous $\\mathcal{F}_{t}$-adapted stochastic process $\\left\\{ \\mathbf{X}_{t} \\right\\}_{t \\ge 0}$ as a $d$-dimensional It√¥ Process. $$ \\mathbf{X} (t) := \\mathbf{X}_{0} + \\int_{0}^{t} \\mathbf{f}(s) ds + \\int_{0}^{t} \\mathbf{g}(s) d \\mathbf{W}_{s} $$ Of course, it can also be written in the form of the following stochastic differential. $$ d \\mathbf{X}(t) = \\mathbf{f}(t) dt + \\mathbf{g}(t) d \\mathbf{W}_{t} $$\nPanik. (2017). Stochastic Differential Equations: An Introduction with Applications in Population Dynamics Modeling: p120.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPanik. (2017). Stochastic Differential Equations: An Introduction with Applications in Population Dynamics Modeling: p127.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2119,"permalink":"https://freshrimpsushi.github.io/en/posts/2119/","tags":null,"title":"Ito Process"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition 1 2 Simple Definition A random network where links of a simple network are connected independently according to probability $p \\in [0,1]$ is called the Gilbert Model $\\mathbb{G}_{n,p}$.\nComplicated Definition Given a probability space $( \\Omega , \\mathcal{F} , P)$, and a network\u0026rsquo;s properties $2^{\\binom{n}{2}} \\subseteq 2^{\\binom{n}{2}}$ with $n$ labeled nodes. A function that is measurable with respect to $\\mathcal{F}$ and has the following probability mass function for the number of links $0 \\le m \\le \\binom{n}{2}$ is called the Gilbert Model. $$ P \\left( \\mathbb{G}_{n,p} = G \\right) = p^{m} \\left( 1 - p \\right)^{\\binom{n}{2} - m} \\qquad , \\forall G \\in \\mathscr{G}_{n,m} \\subset 2^{\\binom{n}{2}} $$\nExplanation The Gilbert model, along with the Erd≈ës-R√©nyi Model (ER Model), is mentioned in numerous documents, but in reality, many refer to the ER model when they actually use the Gilbert Model. There are differences between the two models. In fact, delving into it reveals they are different models enough to fill an entire thick book, but especially in the context of applied network theory, there is a strong tendency to lump these two together under the ER model. Although not a commonly used expression, it can also be called a Binomial Random Network given that its probability distribution is the binomial distribution.\n$\\mathbb{G}_{n,p}$ is expected to have approximately $\\displaystyle m = \\binom{n}{2} p \\approx {{ n^{2} p } \\over { 2 }}$ links. Unlike the ER model, which exactly has $m$ links, the number of links in the Gilbert Model is proportional to the network size by a coefficient $p$, but the number of links is not fixed.\nThe definition might seem complex at a glance, but the algorithm is actually simple. Sampling a network using the Gilbert Model follows this algorithm.\nAlgorithm Input\nAssume the number of nodes $n \\in \\mathbb{N}$ and the link probability $p \\in \\left( 0, 1 \\right)$ are given.\nStep 1. Initialization\nCreate a null graph $G$ with $n$ nodes.\nStep 2. Bernoulli Trials\nfor $i = 1 , \\cdots , n$\nfor $j = 1 , \\cdots , n$\nif $i \\ne j$\nAdd a link $ij$ to the network $G$ with probability $p$.$$G \\gets G + ij$$\nOutput\nObtain a simple graph $G \\in 2^{\\binom{n}{2}}$ with $n$ nodes and approximately $m \\approx n^{2} p / 2$ links.\nProperties [1]: The number of links sampled from the Gilbert Model $\\mathbb{G}_{n,p}$ exactly needing to be $m$ is the same as being sampled in $\\mathbb{G}_{n,m}$. [2] Degree distribution: If $\\lambda = np$, then when $n \\to \\infty$, the degree of each node converges in distribution to the Poisson distribution $\\displaystyle \\text{Poi} \\left( np \\right)$. $$ P \\left( \\deg v = k \\right) \\to {{ e^{-\\lambda} \\lambda^{k} } \\over { k! }} \\qquad , \\lambda \\approx np $$ Proof [1] Erd≈ës-R√©nyi Model: This random graph is called the Erd≈ës‚ÄìR√©nyi Graph $\\mathbb{G}_{n,m}$, with the following probability mass function. $$ P \\left( \\mathbb{G}_{n,m} = G \\right) = \\binom{\\binom{n}{2}}{m}^{-1} \\qquad , \\forall G \\in \\mathscr{G}_{n,m} $$\nClaim: For any $G_{0} \\in \\mathscr{G}_{n,m}$, it suffices to prove the following. $$ P \\left( \\mathbb{G}_{n,p} = G_{0} | \\mathbb{G}_{n,p} \\in \\mathscr{G}_{n,m} \\right) = \\binom{\\binom{n}{2}}{m}^{-1} $$\nObviously, the probability of having exactly $G_{0}$ links in $\\mathbb{G}_{n,p}$ is less than having $\\mathbb{G}_{n,p} \\in \\mathscr{G}_{n,m}$ links, i.e., sampling with the Gilbert Model and ending up with $m$ links in total. Representing this as an event gives $$ \\begin{align*} \\left\\{ \\mathbb{G}_{n,p} = G_{0} \\right\\} \u0026amp; \\subset \\left\\{ \\mathbb{G}_{n,p} \\in \\mathscr{G}_{n,m} \\right\\} \\\\ \\implies \\left\\{ \\mathbb{G}_{n,p} = G_{0} \\right\\} \u0026amp; \\cap \\left\\{ \\mathbb{G}_{n,p} \\in \\mathscr{G}_{n,m} \\right\\} = \\left\\{ \\mathbb{G}_{n,p} = G_{0} \\right\\} \\qquad \\cdots (\\star) \\end{align*} $$ Calculating each probability gives $\\displaystyle P \\left( \\mathbb{G}_{n,p} = G_{0} \\right) = p^{m} \\left( 1 - p \\right)^{\\binom{n}{2} - m}$ thus $$ \\begin{align*} \u0026amp; P \\left( \\mathbb{G}_{n,p} \\in \\mathscr{G}_{n,m} \\right) \\\\ =\u0026amp; P \\left( \\bigcup_{G \\in \\mathscr{G}_{n,m}} \\left\\{ \\mathbb{G}_{n,p} = G \\right\\} \\right) \\\\ =\u0026amp; \\sum_{G \\in \\mathscr{G}_{n,m}} P \\left( \\mathbb{G}_{n,p} = G \\right) \\\\ =\u0026amp; \\binom{\\binom{n}{2}}{m} p^{m} \\left( 1 - p \\right)^{\\binom{n}{2} - m} \\end{align*} $$ Now, the conditional probability can be shown as $$ \\begin{align*} P \\left( \\mathbb{G}_{n,p} = G_{0} | \\mathbb{G}_{n,p} \\in \\mathscr{G}_{n,m} \\right) =\u0026amp; {{ P \\left( \\mathbb{G}_{n,p} = G_{0} \\land \\mathbb{G}_{n,p} \\in \\mathscr{G}_{n,m} \\right) } \\over { P \\left( \\mathbb{G}_{n,p} \\in \\mathscr{G}_{n,m} \\right) }} \\\\ =\u0026amp; {{ P \\left( \\mathbb{G}_{n,p} = G_{0} \\right) } \\over { P \\left( \\mathbb{G}_{n,p} \\in \\mathscr{G}_{n,m} \\right) }} \u0026amp; \\because (\\star) \\\\ =\u0026amp; {{ p^{m} \\left( 1 - p \\right)^{\\binom{n}{2} - m} } \\over { \\binom{\\binom{n}{2}}{m} p^{m} \\left( 1 - p \\right)^{\\binom{n}{2} - m} }} \\\\ =\u0026amp; \\binom{\\binom{n}{2}}{m}^{-1} \\end{align*} $$ where $\\land$ is the logical product.\n[2] Given $n$ nodes and each node having a connection probability of $p$, the degree of the node depends on whether it is connected to the remaining $(n-1)$ other nodes, hence follows the binomial distribution $B(n-1,p)$. Expressing it with a formula yields the following. $$ P \\left( \\deg v = k \\right) = \\binom{n-1}{k} p^{k} \\left( 1 - p \\right)^{n-1-k} $$\nPoisson Distribution as a Limit of the Binomial Distribution: Let\u0026rsquo;s say $X_{n} \\sim B(n,p)$.\nIf $\\lambda \\approx np$, then $$ X_{n} \\overset{D}{\\to} \\text{Poi} (\\lambda) $$\nAccording to the lemma, the degree of nodes in a sufficiently large Gilbert network follows the Poisson distribution.\n‚ñ†\nVisualization Here are the sampled ER network and histogram of node degrees when $n = 50$, $p = 12\\%$.\nCode Here is the code using Graphs and GraphRecipes packages of Julia.\ncd(@__DIR__); pwd()\r@time using Graphs\r@time using Plots\r@time using GraphRecipes\rn = 50\rG_np = erdos_renyi(n, 6/n, seed = 0)\rplot_G_np = graphplot(G_np, title = \u0026#34;n = 50, p = 12%\u0026#34;, curves=false, size = (300,300), node_weights = degree(G_np).^2,\rnode_shape = :rect, nodecolor = :black, nodestrokealpha = 0.5, edgecolor = :black)\rpng(plot_G_np, \u0026#34;plot_G_np.png\u0026#34;)\rhistogram_G_np = histogram(degree(G_np), title = \u0026#34;Histogram of Degree\u0026#34;,\rcolor = :black, alpha = 0.8, label = :none, size = (300,300))\rpng(histogram_G_np, \u0026#34;histogram_G_np.png\u0026#34;) Generalization Chung-Lu Fitness Model Gilbert. (1959). Random Graphs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFrieze. (2015). Introduction to Random Graphs: p3.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2118,"permalink":"https://freshrimpsushi.github.io/en/posts/2118/","tags":["Ï§ÑÎ¶¨ÏïÑ"],"title":"Gilbert Model"},{"categories":"Í∏∞ÌïòÌïô","contents":"Buildup Riemannian metric is a concept that comes from the process of calculating the length of curves on a surface, and the process is as follows.\nLet\u0026rsquo;s say $\\boldsymbol{\\alpha}(t)$ is a regular curve moving on a simple surface $\\mathbf{x} : U \\to \\mathbb{R}^{3}$. Let\u0026rsquo;s say $(u_{1}, u_{2})$ are the coordinates in $U$. Then, $\\boldsymbol{\\alpha}$ can be expressed as follows.\n$$ \\boldsymbol{\\alpha}(t) = \\mathbf{x}(u_{1}(t), u_{2}(t)) $$\nAt this point, the length of $\\boldsymbol{\\alpha}$ at $a \\le t \\le b$ is defined as follows.\n$$ \\int_{a}^{b} \\left| \\dfrac{d \\boldsymbol{\\alpha}}{d t} \\right| dt $$\nIf we resolve the integrand function, it goes as follows.\n$$ \\begin{align*} \\left| \\dfrac{d \\boldsymbol{\\alpha}}{d t} \\right| =\u0026amp;\\ \\sqrt{\\left\\langle \\dfrac{d \\boldsymbol{\\alpha}}{d t} , \\dfrac{d \\boldsymbol{\\alpha}}{d t} \\right\\rangle} \\\\ =\u0026amp;\\ \\sqrt{\\left\\langle \\dfrac{d \\mathbf{x}(u_{1}, u_{2})}{d t} , \\dfrac{d \\mathbf{x}(u_{1}, u_{2})}{d t} \\right\\rangle} \\end{align*} $$\nBy the chain rule,\n$$ \\begin{align*} \\left| \\dfrac{d \\boldsymbol{\\alpha}}{d t} \\right| =\u0026amp;\\ \\sqrt{\\left\\langle \\dfrac{\\partial \\mathbf{x}}{\\partial u_{1}}\\dfrac{d u_{1}}{dt} + \\dfrac{\\partial \\mathbf{x}}{\\partial u_{2}}\\dfrac{d u_{2}}{dt}, \\dfrac{\\partial \\mathbf{x}}{\\partial u_{1}}\\dfrac{d u_{1}}{dt} + \\dfrac{\\partial \\mathbf{x}}{\\partial u_{2}}\\dfrac{d u_{2}}{dt} \\right\\rangle} \\\\ =\u0026amp;\\ \\sqrt{\\left\\langle \\mathbf{x}_{1}\\dfrac{d u_{1}}{dt} + \\mathbf{x}_{2}\\dfrac{d u_{2}}{dt}, \\mathbf{x}_{1}\\dfrac{d u_{1}}{dt} + \\mathbf{x}_{2}\\dfrac{d u_{2}}{dt} \\right\\rangle} \\end{align*} $$\nAt this point, $\\mathbf{x}_{1} := \\dfrac{\\partial \\mathbf{x}}{\\partial u_{1}}, \\mathbf{x}_{2} := \\dfrac{\\partial \\mathbf{x}}{\\partial u_{2}}$. Expanding and arranging the inner product,\n$$ \\begin{align*} \u0026amp; \\left| \\dfrac{d \\boldsymbol{\\alpha}}{d t} \\right| \\\\ =\u0026amp;\\ \\sqrt{\\left\\langle \\mathbf{x}_{1}\\dfrac{d u_{1}}{dt} + \\mathbf{x}_{2}\\dfrac{d u_{2}}{dt}, \\mathbf{x}_{1}\\dfrac{d u_{1}}{dt} + \\mathbf{x}_{2}\\dfrac{d u_{2}}{dt} \\right\\rangle} \\\\ =\u0026amp;\\ \\sqrt{\\left( \\dfrac{d u_{1}}{dt} \\right)^{2} \\left\\langle \\mathbf{x}_{1}, \\mathbf{x}_{1} \\right\\rangle + \\dfrac{d u_{1}}{dt}\\dfrac{d u_{2}}{dt} \\left\\langle \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\rangle + \\dfrac{d u_{2}}{dt}\\dfrac{d u_{1}}{dt} \\left\\langle \\mathbf{x}_{2}, \\mathbf{x}_{1} \\right\\rangle + \\left( \\dfrac{d u_{2}}{dt} \\right)^{2} \\left\\langle \\mathbf{x}_{2}, \\mathbf{x}_{2} \\right\\rangle} \\end{align*} $$\nHere, if we denote the dot product above by $g_{ij} = \\left\\langle \\mathbf{x}_{i}, \\mathbf{x}_{j} \\right\\rangle$, and arrange it as $\\sum$, it can be expressed as follows.\n$$ \\begin{align*} \\left| \\dfrac{d \\boldsymbol{\\alpha}}{d t} \\right| =\u0026amp;\\ \\sqrt{ \\sum \\limits_{i=1}^{2}\\sum \\limits_{j=1}^{2} g_{ij} \\dfrac{d u_{i}}{dt}\\dfrac{d u_{j}}{dt}} \\\\ =\u0026amp;\\ \\sqrt{ g_{ij} \\dfrac{d u_{i}}{dt}\\dfrac{d u_{j}}{dt}} \\end{align*} $$\nIn the second equality, the summation sign is omitted using Einstein notation.\nDefinition1 $g_{ij} = \\left\\langle \\mathbf{x}_{i}, \\mathbf{x}_{j} \\right\\rangle$ is called the coefficient of the Riemannian metric, or the coefficient of the first fundamental form.\nLet $M$ be the surface at $\\mathbb{R}^{3}$, referred as $p \\in M$. Let $\\mathbf{X}, \\mathbf{Y}$ be the tangent vector at $p$. Then, for the eigenmap $\\mathbf{x} : U \\to \\mathbb{R}^{3}$ of $M$, it is expressed as follows.\n$$ \\mathbf{X} = X^{1}\\mathbf{x}_{1} + X^{2}\\mathbf{x}_{2} \\quad \\text{and} \\quad \\mathbf{Y} = Y^{1}\\mathbf{x}_{1} + Y^{2}\\mathbf{x}_{2} $$\nThe following bilinear form $I$ is defined as the Riemannian metric of the surface $\\mathbf{x}$, or the first fundamental form.\n$$ I : T_{p}M \\times T_{p}M \\to \\mathbb{R} $$\n$$ I (\\mathbf{X}, \\mathbf{Y}) = \\sum \\limits_{i=1}^{2} \\sum \\limits_{j=1}^{2} g_{ij}X^{i}Y^{j} = g_{ij}X^{i}Y^{j} = \\begin{bmatrix} X^{1} \u0026amp; X^{2}\\end{bmatrix} \\begin{bmatrix} g_{11} \u0026amp; g_{12} \\\\ g_{21} \u0026amp; g_{22} \\end{bmatrix} \\begin{bmatrix} Y^{1} \\\\ Y^{2}\\end{bmatrix} $$\nThe determinant of the matrix of coefficients $\\left[ g_{ij} \\right]$ is denoted as $g$.\n$$ g := \\det (\\left[ g_{ij} \\right]) = \\begin{vmatrix} g_{11} \u0026amp; g_{12} \\\\ g_{21} \u0026amp; g_{22}\\end{vmatrix} = g_{11}g_{22} - g_{12}g_{21} $$\nThe $(k,l)$ component of the inverse matrix of the matrix $\\left[ g_{ij} \\right]$ is denoted as $g^{kl}$.\n$$ \\begin{align*} \\begin{pmatrix} g_{11} \u0026amp; g_{12} \\\\ g_{21} \u0026amp; g_{22} \\end{pmatrix} ^{-1} =\u0026amp;\\ \\dfrac{1}{\\det \\left[ g_{ij} \\right]} \\begin{pmatrix} g_{22} \u0026amp; - g_{21} \\\\ g_{12} \u0026amp; g_{22} \\end{pmatrix} = \\dfrac{1}{g} \\begin{pmatrix} g_{22} \u0026amp; - g_{21} \\\\ g_{12} \u0026amp; g_{22} \\end{pmatrix} \\\\[1em] =\u0026amp;\\ \\begin{pmatrix}\\dfrac{g_{22}}{g} \u0026amp; - \\dfrac{g_{21}}{g} \\\\[1em] -\\dfrac{g_{12}}{g} \u0026amp; \\dfrac{g_{11}}{g} \\end{pmatrix} \\\\[1em] =\u0026amp;\\ \\begin{pmatrix} g^{11} \u0026amp; g^{12} \\\\[1em] g^{21} \u0026amp; g^{22} \\end{pmatrix} \\end{align*} $$\nExplanation These days, the term \u0026ldquo;first fundamental form\u0026rdquo; is hardly used and mostly, the term \u0026ldquo;Riemannian metric\u0026rdquo; is used. The name \u0026ldquo;metric\u0026rdquo; is used because, as seen in the buildup, it is used for measuring the length of curves on the surface.\nNotations like $E = g_{11}$, $F=g_{21}=g_{12}$, $G=g_{22}$ are also widely used.\nThe reason the concept of Riemannian metric, which did not appear in curve theory, arises is because the basis of the tangent space $\\left\\{ \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\}$ is not generally an orthonormal basis. If it were orthonormal, $g_{ij} = \\delta_{ij}$, therefore it would be meaningless. Here, $\\delta$ is the Kronecker delta. Using the Riemannian metric and Einstein notation, the length of the curve $\\boldsymbol{\\alpha}$ on the surface can be expressed as follows.\n$$ \\begin{align*} L (\\boldsymbol{\\alpha}) =\u0026amp;\\ \\text{length of } \\boldsymbol{\\alpha} \\\\ =\u0026amp;\\ \\int_{a}^{b} \\sqrt{ g_{ij} \\dfrac{d u_{i}}{dt}\\dfrac{d u_{j}}{dt}} dt \\\\ =\u0026amp;\\ \\int_{a}^{b} \\sqrt{ g_{ij} \\alpha_{i}^{\\prime} \\alpha_{j}^{\\prime} } dt \\\\ =\u0026amp;\\ \\int_{a}^{b} \\sqrt{ E\\left( \\dfrac{d u_{1}}{dt} \\right)^{2} + 2F\\dfrac{d u_{1}}{dt}\\dfrac{d u_{2}}{dt} + G\\left( \\dfrac{d u_{2}}{dt} \\right)^{2}} dt \\end{align*} $$\nThe area of the surface is also defined by the integral of the Riemannian metric.\nFor a certain region $R$ on the simple surface $\\mathbf{x}$, let it be $Q = \\mathbf{x}^{-1}(R)$. In other words, $Q \\subset U \\subset \\R^{2}$. Then, the area of $R$ is as follows. $$ \\text{area of } R = \\iint _{Q} \\sqrt{g} du_{1}du_{2} = \\iint _{Q} \\left| \\mathbf{x}_{1} \\times \\mathbf{x}_{2} \\right| du_{1}du_{2} = \\iint _{Q} \\sqrt{EG-F^{2}} du_{1}du_{2} $$\nProperties For a simple surface $\\mathbf{x} : U \\to \\mathbb{R}^{3}$,\n(a) $g = \\left| \\mathbf{x}_{1} \\times \\mathbf{x}_{2} \\right|^{2}$\n(b) $g^{11} = \\dfrac{g_{22}}{g} \\quad \\text{and} \\quad g^{12} = g^{21} = -\\dfrac{g_{12}}{g} \\quad \\text{and} \\quad g^{22} = \\dfrac{g_{11}}{g}$\n(c) $\\forall i,j$, $\\sum \\limits_{k=1}^{2} g_{ik}g^{kj} = {\\delta_{i}}^{j}$\nHere, $\\delta$ is the Kronecker delta.\nProof (a) Due to the properties of the cross product and the definition of Riemannian metric, the following holds.\n$$ \\begin{align*} \\left| \\mathbf{x}_{1} \\times \\mathbf{x}_{2} \\right|^{2} =\u0026amp;\\ \\left| \\mathbf{x}_{1} \\right|^{2} \\left| \\mathbf{x}_{2} \\right|^{2} \\sin ^{2} \\theta \\\\ =\u0026amp;\\ \\left| \\mathbf{x}_{1} \\right|^{2} \\left| \\mathbf{x}_{2} \\right|^{2}\\left(1- \\cos ^{2} \\theta \\right) \\\\ =\u0026amp;\\ \\left| \\mathbf{x}_{1} \\right|^{2} \\left| \\mathbf{x}_{2} \\right|^{2}\\left(1- \\dfrac{\\mathbf{x}_{1} \\cdot \\mathbf{x}_{2}}{\\left| \\mathbf{x}_{1} \\right| \\left| \\mathbf{x}_{2} \\right| } \\right) \\\\ =\u0026amp;\\ \\left| \\mathbf{x}_{1} \\right|^{2} \\left| \\mathbf{x}_{2} \\right|^{2} - \\left( \\mathbf{x}_{1} \\cdot \\mathbf{x}_{2} \\right)^{2} \\\\ =\u0026amp;\\ g_{11}g_{22} - g_{12}g_{21} \\\\ =\u0026amp;\\ \\det( [g_{ij}] ) \\\\ =\u0026amp;\\ g \\end{align*} $$\n‚ñ†\n(b) It\u0026rsquo;s according to the definition.\n‚ñ†\n(c) Since $[g^{kl}]$ is the inverse matrix of $[g_{ij}]$, it naturally holds.\n$$ \\begin{align*} \\begin{pmatrix} 1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{pmatrix} =\u0026amp;\\ \\begin{pmatrix} g_{11} \u0026amp; g_{12} \\\\ g_{21} \u0026amp; g_{22} \\end{pmatrix} \\begin{pmatrix} g^{11} \u0026amp; g^{12} \\\\ g^{21} \u0026amp; g^{22} \\end{pmatrix} \\\\[1em] =\u0026amp;\\ \\begin{pmatrix} g_{11}g^{11}+g_{12}g^{21} \u0026amp; g_{11}g^{12} + g_{12}g^{22} \\\\[1em] g_{21}g^{11} + g_{22}g^{21} \u0026amp; g_{21}g^{12} + g_{22}g^{22} \\end{pmatrix} \\end{align*} $$\n‚ñ†\nSee Also The second fundamental form Christoffel symbols Riemannian metric Richard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p93-96\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3148,"permalink":"https://freshrimpsushi.github.io/en/posts/3148/","tags":null,"title":"First Basic Forms, Riemannian Metrics"},{"categories":"Ìï®Ïàò","contents":"Definition Sign function $\\mathrm{sgn} : \\mathbb{R} \\to \\mathbb{R}$ is defined as follows.\n$$ \\mathrm{sgn}(x) :=\\begin{cases} 1 \u0026amp; x\u0026gt;0 \\\\ 0 \u0026amp; x=0 \\\\ -1 \u0026amp; x\u0026lt;0 \\end{cases} $$\nExplanation It is mainly used to simplify the notation of equations or definitions. It is also written as $\\mathrm{sign}$.\nSee Also Sign of complex numbers ","id":3147,"permalink":"https://freshrimpsushi.github.io/en/posts/3147/","tags":null,"title":"Sign function"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 If for every point $M \\subset \\R^{3}$ of $P \\in M$, there exists an $C^{k}$ diffeomorphism $\\mathbf{x} : U \\subset \\R^{2} \\to M$ such that the image $\\mathbf{x}(U)$ contains some $\\epsilon-$neighborhood $N_{p}$ of $P$, then $M$ is called a $\\R^{3}$ surface.\nMoreover, for such two diffeomorphisms $\\mathbf{x} : U \\to \\R^{3}$ and $\\mathbf{y} : V \\to \\R^{3}$,\n$$ \\mathbf{y}^{-1} \\circ \\mathbf{x} : \\mathbf{x}^{-1}\\left( \\mathbf{x}(U) \\cap \\mathbf{y}(V) \\right) \\to \\mathbf{y}^{-1}\\left( \\mathbf{x}(U) \\cap \\mathbf{y}(V) \\right) $$\nis a $C^{k}$ coordinate transformation.\nDescription A $\\R^{3}$ surface is, simply put, a composition of the images of simple surfaces.\nAs with many definitions, it is not easy to judge based on the definition alone whether something is a surface or not. There is the following theorem regarding the determination of a surface.\nTheorem2 Let there be a differentiable function $g : \\R^{3} \\to \\R$ and a constant $c \\in \\R$. For a set $M = \\left\\{ (x,y,z) : g(x,y,z) = c \\right\\}$, if at some point of $M$\n$$ dg = \\dfrac{\\partial g}{\\partial x}dx + \\dfrac{\\partial g}{\\partial y}dy + \\dfrac{\\partial g}{\\partial z}dz \\ne 0 $$\nholds, then $M$ is a surface.\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p89\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBarrett O\u0026rsquo;Neill, Elementary Differential Geometry (Revised 2nd Edition, 2006), p133-134\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3146,"permalink":"https://freshrimpsushi.github.io/en/posts/3146/","tags":null,"title":"Definition of Surfaces in Differential Geometry"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definitions Simple Definition A graph that is created by a nondeterministic procedure or expressed according to some probability distribution is called a Random Graph.\nComplex Definition Given a probability space $( \\Omega , \\mathcal{F} , P)$, let $2^{\\binom{n}{2}}$ represent the collection of all labeled graphs with $n$ vertices, known as a graph family.\nA function $\\mathbb{G} : \\Omega \\to 2^{\\binom{n}{2}}$, which is $\\mathcal{F}$-measurable, is called a Random Graph. In other words, $\\mathbb{G}$ satisfies $\\mathbb{G}^{-1} \\left( B \\right) \\in \\mathcal{F}$ for all Borel sets $B \\in 2^{\\binom{n}{2}}$ of (graphs).\nDescription As network theory becomes increasingly applied across various fields in the 21st century, the discussion about Random Networks has also intensified. Like how a random variable in statistics signifies data, random networks in applied mathematics will signify the structure of some data we now hold, whether we like it or not.\nFor example, if a department views each student as a node and the SNS following status as links to create a network, it becomes a good example of a random network. While the rules for connecting nodes are clear, the actual form of the network cannot be accurately known until investigated (sampled). There would be a typical structure, but a different network would result each time the department is changed due to randomness.\nHowever, this explanation is too naive for mathematical thinking. In the complex definition, random graphs are defined in probability theory using measure theory in exactly the same way as random variables are defined. After all, a Random Variable is a function that maps an action or experiment $\\omega \\in \\Omega$ in reality to a Variable, and a Random Graph maps it to a Graph.\nWriting it by hand makes it easier to understand. If there\u0026rsquo;s a specific graph $G_{0}$, and the probability that a randomly made graph will be $G_{0}$ is $3/4$, then it can be written as follows. $$ P \\left( \\mathbb{G} = G_{0} \\right) = {{ 3 } \\over { 4 }} $$ In the above formula, the event is $\\left\\{ \\mathbb{G} = G_{0} \\right\\} \\in \\mathcal{F}$. Always remember that what goes into the function of probability is always an event. Random graphs are just Random Elements in standard probability theory, with the only difference being that their codomain is a graph family.\nExamples Consider the property $\\mathscr{G}_{n,m} \\subset 2^{\\binom{n}{2}}$ that a simple graph has $n$ labeled vertices and $m$ edges.\nA random graph with exactly $m$ links can be represented as $\\mathbb{G}_{n, m} : \\Omega \\to \\mathscr{G}_{n,m}$. The created graph, having $n$ nodes and $m$ links regardless of who creates it and the probability of doing so, ultimately doesn‚Äôt matter. In other words, no probability distribution has been assigned yet. The simplest probability distribution one can think of here is the uniform distribution where everyone has the same probability.\nSince a simple graph must connect different nodes, choosing $2$ out of $n$ nodes can have $\\binom{n}{2}$ links, and particularly choosing $m$ links to make $\\displaystyle \\left| \\mathscr{G}_{n,m} \\right| = \\binom{\\binom{n}{2}}{m}$. Hence, for all $G \\in \\mathscr{G}_{n,m}$, $$ P \\left( \\mathbb{G}_{n,m} = G \\right) = \\binom{\\binom{n}{2}}{m}^{-1} $$ This means that all graphs with $n$ nodes and $m$ links have an equal chance of being selected. Such a random graph $\\mathbb{G}_{n, m}$ with this probability distribution is the famous Erd≈ës‚ÄìR√©nyi model.\n","id":2114,"permalink":"https://freshrimpsushi.github.io/en/posts/2114/","tags":null,"title":"Random Graphs"},{"categories":"ÎÖºÎ¨∏ÏûëÏÑ±","contents":"Alpha $\\Alpha, \\alpha$ Alpha is read as \u0026ldquo;alpha\u0026rdquo;. The TeX codes are \\Alpha, \\alpha respectively.\nIt is the first letter of the Greek alphabet, and the phrase \u0026ldquo;alpha and omega\u0026rdquo; means \u0026ldquo;the beginning and the end.\u0026rdquo;\nIndex of an index set $\\alpha$ In differential geometry, a curve $\\alpha$ Curve used to define tangent vectors on a differential manifold $\\alpha$ Beta $\\Beta, \\beta$ Beta is read as \u0026ldquo;beta\u0026rdquo;. The TeX codes are \\Beta, \\beta respectively.\nBeta function $B$ Gamma $\\Gamma, \\gamma$ Gamma is read as \u0026ldquo;gamma\u0026rdquo;. The TeX codes are \\Gamma, \\gamma respectively.\nGamma function $\\Gamma$ In differential geometry, a curve $\\gamma$ Christoffel symbols $\\Gamma_{ij}^{k}$ Delta $\\Delta, \\delta$ Delta is read as \u0026ldquo;delta\u0026rdquo;. The TeX codes are \\Delta, \\delta respectively.\nIn calculus, a very small change $x$ $\\Delta x$ In physics, the Laplacian $\\Delta$ In partial differential equations, the Laplacian $\\Delta$ In mathematics, a very small positive number $\\delta$: $\\epsilon - \\delta$ argument Dirac delta function $\\delta$ Kronecker delta $\\delta_{ij}$ Epsilon $\\Epsilon, \\epsilon, \\varepsilon$ Epsilon is read as \u0026ldquo;epsilon\u0026rdquo;. The TeX codes are \\Epsilon, \\epsilon, \\varepsilon respectively.\nAlthough the correct pronunciation is epsilon, it is often pronounced as upsilon.\nIn mathematics, a very small positive number $\\epsilon$: $\\epsilon - \\delta$ argument In electromagnetism, the permittivity $\\epsilon$ Levi-Civita symbol $\\epsilon_{ijk}$ Zeta $\\Zeta, \\zeta$ Zeta is read as \u0026ldquo;zeta\u0026rdquo;. The TeX codes are \\Zeta, \\zeta respectively.\nIt is not widely used. Often used when running out of variables.\nRiemann zeta function $\\zeta$ Eta $\\Eta, \\eta$ Eta is read as \u0026ldquo;eta\u0026rdquo;. The TeX codes are \\Eta, \\eta respectively.\nLike zeta, it is used when there are no suitable variables available.\nIn particle physics, a baryon $\\eta$ Theta $\\Theta, \\theta, \\vartheta$ Theta is read as \u0026ldquo;theta\u0026rdquo;. The TeX codes are \\Theta, \\theta, \\vartheta respectively.\nIt is mostly considered to represent an angle.\nAngle $\\theta$ In variable separation, a function that has $\\theta$ as a variable $\\Theta (\\theta)$ Iota $\\Iota, \\iota$ Iota is read as \u0026ldquo;iota\u0026rdquo;. The TeX codes are \\Iota, \\iota respectively.\nIt is not commonly used.\nKappa $\\Kappa, \\kappa$ Kappa is read as \u0026ldquo;kappa\u0026rdquo;. The TeX codes are \\Kappa, \\kappa respectively.\nIn differential geometry, curvature $\\kappa$:\nNormal curvature $\\kappa _{n}$, Geodesic curvature $\\kappa_{g}$, [Principal curvature $\\kappa$] In quantum mechanics, a substitution constant for negative energy $\\kappa$](../1261) Lambda $\\Lambda, \\lambda$ Lambda is read as \u0026ldquo;lambda\u0026rdquo;. The TeX codes are \\Lambda, \\lambda respectively.\nEigenvalue $\\lambda$ In physics, wavelength $\\lambda$ Mu $\\Mu, \\mu$ Mu is read as \u0026ldquo;mu\u0026rdquo;. The TeX codes are \\Mu, \\mu respectively.\nMeasure $\\mu$ In electromagnetism, permeability $\\mu$ In particle physics, a muon $\\mu$ In statistics, mean $\\mu$ Nu $\\Nu, \\nu$ Nu is read as \u0026ldquo;nu\u0026rdquo;. The TeX codes are \\Nu, \\nu respectively.\nIn physics, frequency $\\nu$ In particle physics, neutrino $\\nu$ Xi $\\Xi, \\xi$ Xi is read as \u0026ldquo;xi\u0026rdquo;, also pronounced as \u0026ldquo;ksi\u0026rdquo; or \u0026ldquo;zai\u0026rdquo;. It\u0026rsquo;s the Xi apartment\u0026rsquo;s \u0026ldquo;Xi\u0026rdquo;. The TeX codes are \\Xi, \\xi respectively.\nIt is often used when running out of variables.\nVariable for the Fourier transform of $x$ $\\xi$ Riemann Xi function $\\xi$This is pronounced as \u0026ldquo;zai\u0026rdquo;. Omicron $\\Omicron, \\omicron$ Omicron is pronounced as \u0026ldquo;Omicron\u0026rdquo; and is almost the same shape as the alphabet $o$, so it is not used. The TeX codes are \\Omicron, \\omicron respectively.\nPi $\\Pi, \\pi$ Pi is pronounced as \u0026ldquo;pi\u0026rdquo; and represents the mathematical constant pi. The TeX codes are \\Pi, \\pi respectively.\nProduct symbol $\\Pi$ Pi, the mathematical constant $\\pi$ In particle physics, a pion meson $\\pi$ Rho $\\Rho, \\rho$ Rho is pronounced as \u0026ldquo;rho\u0026rdquo;. The TeX codes are \\Rho, \\rho respectively.\nRadius variable in cylindrical coordinates $\\rho$](../1795) In physics, density $\\rho$\nVolume charge density $\\rho$ Sigma $\\Sigma, \\sigma$ Sigma is pronounced as \u0026ldquo;sigma\u0026rdquo;. The TeX codes are \\Sigma, \\Sigma respectively.\nSummation symbol $\\Sigma$ Variance in statistics $\\sigma^{2}$ In electromagnetism, surface charge density $\\sigma$ In thermodynamics, [collision cross-section $\\sigma$] Tau $\\Tau, \\tau$ In mechanics, [torque $\\tau$](../167 4): It is also commonly written as $N$.\nUsed as a variable for time, instead of $t$. Twice the number pi $\\tau = 2\\pi$ Upsilon $\\Upsilon, \\upsilon, \\varUpsilon$ Upsilon is pronounced as \u0026ldquo;upsilon\u0026rdquo;. The TeX codes are \\Upsilon, \\upsilon, \\varUpsilon respectively.\nIn particle physics, an upsilon meson $\\varUpsilon$ Chi $\\Chi, \\chi$ Chi is pronounced as \u0026ldquo;chi\u0026rdquo;. Teachers advise not to write $x$ as $\\chi$ because it is actually chi $x$, not \u0026ldquo;x\u0026rdquo; $\\chi$. Please do not write it like this. The TeX codes are \\Chi, \\chi respectively.\nCharacteristic function $\\chi$ Psi $\\Psi, \\psi$ Psi is pronounced as \u0026ldquo;psi\u0026rdquo;. The TeX codes are \\Psi, \\psi respectively.\nAlong with $\\phi$, it is often used to represent an arbitrary function.\nIn quantum mechanics, wave function $\\psi$ Phi $\\Phi, \\phi ,\\varphi$ Phi is pronounced as \u0026ldquo;phi\u0026rdquo; or \u0026ldquo;fi\u0026rdquo;. It seems that in physics, it is often pronounced as \u0026ldquo;fi\u0026rdquo;, while in mathematics, it is pronounced as \u0026ldquo;phi\u0026rdquo;. The TeX codes are \\Phi, \\phi, \\varphi respectively.\nAlong with $\\psi$, it is often used to represent an arbitrary function.\nVariable in cylindrical coordinates $\\phi$](../1795) Variable in spherical coordinates $\\phi$](../152) In quantum mechanics, wave function $\\phi$ Omega $\\Omega, \\omega$ Omega is pronounced as \u0026ldquo;omega\u0026rdquo;. The TeX codes are Omega, omega respectively.\nIt is the last letter of the Greek alphabet, and the phrase \u0026ldquo;alpha and omega\u0026rdquo; means \u0026ldquo;the beginning and the end\u0026rdquo;, \u0026ldquo;everything\u0026rdquo;.\nIn partial differential equations, functional analysis, an open set $\\Omega$: It is commonly used notation along with $U$. In physics, the unit of resistance $\\Omega$ Solid angle of a sphere $\\Omega$ In physics, angular frequency $\\omega$ Variable for the Fourier transform of $t$ $\\omega$ Complex roots of a polynomial $\\omega$ ","id":3145,"permalink":"https://freshrimpsushi.github.io/en/posts/3145/","tags":null,"title":"How to Read and Write Greek Characters and Their Meaning in Mathematics and Science"},{"categories":"ÌôïÎ•†ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Buildup Before discussing stochastic integrals, it is crucial to define an essential probabilistic process called the Elementary Process. Elementary processes play a similar role to simple functions, which were necessary for defining the Lebesgue integral in [Measure Theory](../../categories/Measure Theory).\n$$ a = t_{0} \u0026lt; t_{1} \u0026lt; \\cdots \u0026lt; t_{k} = b $$ Considering such a partition in the Natural Domain $[a,b]$, an Elementary Process is defined as follows for indicator functions $\\chi$ and $\\mathcal{F}_{t_{j}}$-measurable functions (random variables) $e_{j}$: $$ \\phi (t,\\omega) := \\sum_{j=0}^{k-1} e_{j} (\\omega) \\chi_{ \\left[ t_{j} , t_{j+1} \\right] } (t) $$ Integrating this function with the Wiener Process $W(t)$ can be thought of in the same vein as the Riemann Sum: $$ \\int_{a}^{b} \\phi (t,\\omega) d W_{t} (\\omega) = \\sum_{j=0}^{k-1} e_{j} (\\omega) \\left[ W_{t_{j+1}} - W_{t_{j}} \\right] ( \\omega ) $$ Based on this, the following Stochastic Integral is defined.\nDefinition 1 The It√¥ Integral is defined as follows $f \\in m^{2} [a,b]$. $$ \\int_{a}^{b} f (t,\\omega) d W_{t} (\\omega) := \\lim_{n \\to \\infty} \\int_{a}^{b} \\phi_{n} (t,\\omega) d W_{t} (\\omega) $$ Here, the sequence $\\left\\{ \\phi_{n} \\right\\}_{n \\in \\mathbb{N}}$ is a sequence of elementary processes that satisfy the following: $$ \\lim_{n \\to \\infty} E \\left[ \\int_{a}^{b} \\left( f (t,\\omega) - \\phi_{n} (t,\\omega) \\right)^{2} dt \\right] = 0 $$\nExplanation In the definition, $\\left\\{ \\phi_{n} \\right\\}_{n \\in \\mathbb{N}}$ can be specifically chosen in any way as long as it satisfies condition $E \\int [f-\\phi_{n}]^{2} dt \\to 0$.\nBasic Properties 2 Let us assume $f, g \\in m^{2} [a,b]$ and a given filtration $\\left\\{ \\mathcal{F}_{t} \\right\\}_{t \\ge 0}$.\n[1] Measurability: $\\displaystyle \\int_{a}^{b} f d W_{t} = \\left( \\int_{a}^{b} f d W_{t} \\right) (\\omega)$ is $\\mathcal{F}_{b}$-measurable. [2] Linearity: For a constant $c$, $$ \\int_{a}^{b} \\left( c f + g \\right) d W_{t} = \\int_{a}^{b} c f d W_{t} + \\int_{a}^{b} g d W_{t} $$ [3] Additivity: For $a \u0026lt; c \u0026lt; b$, $$ \\int_{a}^{b} f d W_{t} = \\int_{a}^{c} f d W_{t} + \\int_{c}^{b} f d W_{t} $$ [4] Normality: If $f$ is independent with $\\omega \\in \\Omega$, in other words, if $f$ is deterministic $$ \\int_{a}^{b} f d W_{t} \\sim N \\left( 0, \\int_{a}^{b} \\left( f \\right)^{2} dt \\right) $$ [5] Bounded Random Variables: If $Z$ is $\\mathcal{F}_{b}$-measurable, then $Z f \\in m^{2}[a,b]$ and the following holds: $$ \\int_{a}^{b} Z f (t) d W_{t} = Z \\int_{a}^{b} f (t) d W_{t} $$ [6] Expectation: For the sub-sigma field $\\mathcal{F}_{a}$ $$ E \\left[ \\int_{a}^{b} f d W_{t} \\right] = E \\left[ \\int_{a}^{b} f d W_{t} | \\mathcal{F}_{a} \\right] = 0 $$ and, regarding $f,g$, the following holds: $$ E \\left( \\int_{a}^{b} f(t) d W_{t} \\int_{a}^{b} g(t) d W_{t} \\right) = E \\left( \\int_{a}^{b} f(t) g(t) d W_{t} \\right) $$ [7] It√¥ Isometry Equality: $$ E \\left( \\left| \\int_{a}^{b} f W_{t} \\right|^{2} \\right) = E \\left( \\int_{a}^{b} \\left| f \\right|^{2} W_{t} \\right) $$ This also applies to Conditional Expectations, satisfying the following: $$ E \\left( \\left| \\int_{a}^{b} f d W_{t} \\right|^{2} | \\mathcal{F}_{a} \\right) = E \\left( \\int_{a}^{b} \\left| f \\right|^{2} d W_{t} | \\mathcal{F}_{a} \\right) = \\int_{a}^{b} E \\left( \\left| f \\right|^{2} | \\mathcal{F}_{a} \\right) d W_{t} $$ [8] Let\u0026rsquo;s consider $f \\in m^2$ and $\\left\\{ f_{n} \\right\\}_{n \\in \\mathbb{N}} \\subset m^{2}$. If $n \\to \\infty$, then $$ E \\left[ \\int_{a}^{b} \\left( f_{n} - f \\right)^{2} dt \\right] \\to 0 $$ it converges as per $\\mathcal{L}_{2}$ Convergence when $n \\to \\infty$. $$ \\int_{a}^{b} f_{n} W_{t} \\to \\int_{a}^{b} f W_{t} $$ $\\mathcal{F}_{t}$ being a sub-sigma field of $\\mathcal{F}$ means both are Sigma Fields of $\\Omega$, but $\\mathcal{F}_{t} \\subset \\mathcal{F}$ applies. $f$ being a $\\mathcal{F}_{t}$-measurable function means that for all Borel Sets $B \\in \\mathcal{B}([0,\\infty))$, $f^{-1} (B) \\in \\mathcal{F}_{t}$ applies. √òksendal. (2003). Stochastic Differential Equations: An Introduction with Applications: p29.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPanik. (2017). Stochastic Differential Equations: An Introduction with Applications in Population Dynamics Modeling: p118.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2111,"permalink":"https://freshrimpsushi.github.io/en/posts/2111/","tags":null,"title":"Ito Calculus"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 Consider a point $p = \\mathbf{x}(a,b)$ on a coordinate patch $\\mathbf{x} : U \\to \\mathbb{R}^{3}$. If a vector $\\mathbf{X}$ is the velocity vector at $p$ of some curve $\\mathbf{x}(U)$ on the curve passing through $p$, then $\\mathbf{X}$ is defined as the tangent vector to the simple surface $\\mathbf{x}$.\nIn other words, if for any arbitrary $\\epsilon \u0026gt; 0$, there exists a suitably short curve $\\boldsymbol{\\alpha} : (-\\epsilon, \\epsilon) \\to \\mathbf{x}(U) \\subset \\mathbb{R}^{3}$ that satisfies the following condition\n$$ \\boldsymbol{\\alpha}(0) = p \\quad \\text{and} \\quad \\boldsymbol{\\alpha}^{\\prime}(0) = \\left. \\dfrac{d \\boldsymbol{\\alpha}}{d t}\\right|_{t=0}= \\mathbf{X} \\quad \\text{and} \\quad \\boldsymbol{\\alpha} (t) = \\mathbf{x}\\left( \\alpha_{1}(t), \\alpha_{2}(t) \\right) $$\nthen $\\mathbf{X}$ is called the tangent vector to the simple surface $\\mathbf{x}$.\nDescription The set of tangent vectors defined as above becomes a vector space by the theorem below and is actually the same as the tangent plane. Therefore, the tangent plane is called the tangent space.\nThe set of all tangent vectors to $M$ at point $p \\in M$ on the surface $M$ is denoted as $T_{p}M$ and called the tangent space. $$ T_{p}M = \\left\\{ \\text{all vectors tangent to } M \\text{ at } p \\right\\} $$\nThis way of definition is also used when defining tangent vectors on a differential manifold. At first glance, the reason for defining it through the consideration of such curves $\\boldsymbol{\\alpha}$ may not be readily accepted, but as you continue to study differential geometry or encounter generalizations to manifolds, it will naturally be understood.\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p83\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3142,"permalink":"https://freshrimpsushi.github.io/en/posts/3142/","tags":null,"title":"Tangent Vectors on Simple Surfaces"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition 1 Let a subset of the Euclidean space $2$ have coordinates $U \\subset \\mathbb{R}^{2}$ and $u_{1}$, then the directional derivatives $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$ can be referred to as follows on a simple surface $\\mathbf{x} : U \\to \\mathbb{R}^{3}$.\n$$ \\begin{align*} \\mathbf{x}_{1} := {{ \\partial \\mathbf{x} } \\over { \\partial u_{1} }} \u0026amp; , \u0026amp; \\mathbf{x}_{2} := {{ \\partial \\mathbf{x} } \\over { \\partial u_{2} }} \\end{align*} $$\nThe plane perpendicular to $p = \\mathbf{x} (a,b)$ at point $\\mathbf{x}_{1} \\times \\mathbf{x}_{2}$ is called the Tangent Plane at $p$ for $\\mathbf{x}$. The following defined $\\mathbf{n}$ is called the Unit Normal at $p$. $$ \\mathbf{n}(a,b) := {{ \\mathbf{x}_{1} \\times \\mathbf{x}_{2} } \\over { \\left| \\mathbf{x}_{1} \\times \\mathbf{x}_{2} \\right| }} $$ Explanation Just as thinking of a tangent when speaking of a curve is natural, so is considering the tangent plane of a surface. The tangent plane at $p$ is the plane that best approximates the surface around $p$.\nSince simple surfaces are defined by $\\mathbf{x}_{1} \\times \\mathbf{x}_{2} \\ne 0$, the existence of the normal $\\mathbf{n}$ is always guaranteed.\nFrom the following theorem, one can understand that the tangent plane is a set of tangent vectors and becomes a vector space. For this reason, the tangent plane is also called a tangent space. The tangent space on the surface $M$ at point $p$ is denoted as $T_{p}M$.\nTheorem 2 The set of all tangent vectors at point $p = \\mathbf{x}(a,b)$ of a simple surface $\\mathbf{x} : U \\to \\mathbb{R}^{3}$ is a $2$-dimensional vector space with a basis of $\\left\\{ \\mathbf{x}_{1}(a,b), \\mathbf{x}_{2}(a,b) \\right\\}$. Moreover, the tangent plane at $p$ is parallel to any line passing through some origin of $\\mathbb{R}^{3}$.\nProof The tangentvector $\\mathbf{x}_{1}, \\mathbf{x}_{2}$ at point $p$ is linearly independent. (Since $\\mathbf{x}_{1} \\times \\mathbf{x}_{2} \\ne \\mathbf{0}$) The set of all tangent vectors at $p$ is a vector space, thus it is at least a $2$-dimensional vector space. To show that this vector space is $2$-dimensional, it suffices to show that $\\left\\{ \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right\\}$ generates it.\nLet $\\mathbf{X}$ be a tangent vector at point $p$. And let $\\boldsymbol{\\gamma}$ be a curve on $\\mathbf{x}(U)$ such that $\\boldsymbol{\\gamma}(0) = p, \\dot{\\boldsymbol{\\gamma}}(0) = \\mathbf{X}$. And express $\\boldsymbol{\\gamma}(t)$ as follows.\n$$ \\boldsymbol{\\gamma}(t) = \\mathbf{x}\\left( \\gamma^{1}(t), \\gamma^{2}(t) \\right) $$\nThen, by the chain rule,\n$$ \\dfrac{d \\boldsymbol{\\gamma}}{d t} = \\dfrac{\\partial \\mathbf{x}}{\\partial u^{1}}\\dfrac{d \\gamma^{1}}{d t} + \\dfrac{\\partial \\mathbf{x}}{\\partial u^{2}}\\dfrac{d \\gamma^{2}}{d t} = \\sum_{i}\\dfrac{d \\gamma^{i}}{d t}\\mathbf{x}_{i} $$\n$$ \\implies \\mathbf{X} = \\dfrac{d \\boldsymbol{\\gamma}}{d t}(0) = \\sum_{i}\\dfrac{d \\gamma^{i}}{d t}(0)\\mathbf{x}_{i}(a,b) $$\nAs any tangent vector $\\mathbf{X}$ is represented as a linear combination of $\\left\\{ \\mathbf{x}_{i} \\right\\}$, $\\left\\{ \\mathbf{x}_{i} \\right\\}$ generates the set of all tangent vectors at $p$. Therefore, the set of all tangent vectors at $p=\\mathbf{x}(a,b)$ is a $2$-dimensional vector space with a basis of $\\left\\{ \\mathbf{x}_{1}(a,b), \\mathbf{x}_{2}(a,b) \\right\\}$.\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p81\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p84-85\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2110,"permalink":"https://freshrimpsushi.github.io/en/posts/2110/","tags":null,"title":"Intersection of a Plane and a Normal Vector"},{"categories":"ÌôïÎ•†ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition 1 2 Given that there is a probability space $( \\Omega , \\mathcal{F} , P)$,\nA sequence of sub sigma fields $\\left\\{ \\mathcal{F}_{t} \\right\\}_{t \\ge 0}$ of $\\mathcal{F}$ is called a Filtration if it satisfies the following: $$ \\forall s \u0026lt; t, \\mathcal{F}_{s} \\subset \\mathcal{F}_{t} $$ A stochastic process $g(t,\\omega) : [0,\\infty) \\times \\Omega \\to \\mathbb{R}^{n}$ is said to be $\\mathcal{F}_{t}$-Adapted if for all $t \\ge 0$, $\\omega \\mapsto g (t,\\omega)$ is $\\mathcal{F}_{t}$-measurable. For an interval $I := [a,b]$, the set of functions $f$ that satisfy the following three conditions is denoted as $m^{2} = m^{2} [a,b]$. This $I$, in particular, is called the Natural Domain of the Ito Integral. (i): $\\mathcal{B}$ is $\\mathcal{B} \\times \\mathcal{F}$-measurable with respect to the Borel sigma field of $[0, \\infty)$. (ii): $f (t,\\omega)$ is $\\mathcal{F}_{t}$-Adapted. (iii): It has the structure of a Hilbert space, i.e., $$ \\left\\| f \\right\\|_{2}^{2} \\left( [a,b] \\right) = E \\left( \\int_{a}^{b} \\left| f(t,\\omega) \\right|^{2} dt \\right) \u0026lt; \\infty $$ For $\\mathcal{F}_{t}$ to be a sub sigma field of $\\mathcal{F}$ means both are sigma fields of $\\Omega$, but $\\mathcal{F}_{t} \\subset \\mathcal{F}$. A function $f$ is $\\mathcal{F}_{t}$-measurable means for all Borel set $B \\in \\mathcal{B}([0,\\infty))$, $f^{-1} (B) \\in \\mathcal{F}_{t}$. Explanation Given a filtration, saying a stochastic process $f$ is $\\mathcal{F}_{t}$-measurable means it encompasses the history or information up to time $t$. Since a filtration is a sequence of increasingly larger sub sigma fields, it aligns with the notion that information grows over time.\nNaturally, the naming of $m^{2}$ space comes from the $L^{2}$ space as seen in condition (iii).\n√òksendal. (2003). Stochastic Differential Equations: An Introduction with Applications: p25.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPanik. (2017). Stochastic Differential Equations: An Introduction with Applications in Population Dynamics Modeling: p116.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2109,"permalink":"https://freshrimpsushi.github.io/en/posts/2109/","tags":null,"title":"m2 Space"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition 1 1 Let\u0026rsquo;s consider subsets $U \\subset \\mathbb{R}^{2}$ of a $2$-dimensional Euclidean space with coordinates $u_{1}$, $u_{2}$ to be open sets. If there exists a $C^{k}$ injective function $\\mathbf{x} : U \\to \\mathbb{R}^{3}$ that satisfies the following for all $p \\in U$, it is called a Simple Surface.\n$$ {{ \\partial \\mathbf{x} } \\over { \\partial u_{1} }} (p) \\times {{ \\partial \\mathbf{x} } \\over { \\partial u_{2} }} (p) \\ne \\mathbf{0} $$\nExplanation In the definition, the open set $U$ is drawn from the $2$-dimensional space, and it\u0026rsquo;s mapped into the $3$-dimensional space without overlapping parts (since it‚Äôs injective), whether it\u0026rsquo;s flat or curved. In that sense, a simple surface can be imagined as smoothly connecting flat pieces of $2$ dimensions within the $3$-dimensional space. It‚Äôs best to grasp the geometric definition of this surface as a function, but don\u0026rsquo;t worry if it doesn‚Äôt come to mind right away; just spend time getting familiar with it.\nThe reason for defining a surface as a mapping from 2-dimensional space to 3-dimensional space is to treat the surface as if it‚Äôs locally like a plane. For example, although the Earth is close in shape to a sphere, we experience its surface as if it\u0026rsquo;s a 2-dimensional plane from above. $U$ can be likened to a world map, and $\\mathbf{x}(U)$ to a globe.\nMeanwhile, the mathematical condition given in the definition is similar to the condition a regular curve must meet, as in $\\displaystyle {{ d \\mathbf{x} } \\over { d u }} (p) \\ne 0$. Intuitively, this means we‚Äôre immediately excluding any parts that are pointy or bizarrely twisted. Satisfying $\\dfrac{ \\partial \\mathbf{x} }{ \\partial u_{1} } (p) \\times \\dfrac{\\partial \\mathbf{x} }{ \\partial u_{2} } (p) \\ne \\mathbf{0}$ means that any directional partial derivative is not singular (not $0$), implying in some sense that we\u0026rsquo;re considering the geometry using two linearly independent (curve) axes.\nIf the simple surface is explicitly presented with coordinates and a graph, it‚Äôs also called a Monge Patch. For instance, if the simple surface $f$ is $f(x,y) = x^{2} + y^{2}$, its graph is $$ \\left\\{ \\left( x, y , x^{2} + y^{2} \\right) : (x,y) \\in \\mathbb{R}^{2} \\right\\} $$ and can be referred to as a Monge Patch.\nDefinition 2 2 Let‚Äôs consider subsets $U \\subset \\mathbb{R}^{2}$ of a $2$-dimensional Euclidean space with coordinates $u_{1}$, $u_{2}$ to be open sets. If the mapping $\\mathbf{x} : U \\to \\mathbb{R}^{3}$ is bijective and regular, then $\\mathbf{x}$ is called a coordinate patch.\nExplanation 3 For $\\mathbf{x} : U \\to \\mathbb{R}^{3}$ to be regular means that the rank of the Jacobian matrix of $\\mathbf{x}$ is the same as $2$. If we say $\\mathbf{x}(u,v) = (x_{1}(u,v), x_{2}(u,v), x_{3}(u,v))$, the Jacobian matrix of $\\mathbf{x}$ is as follows.\n$$ J = \\begin{bmatrix} \\dfrac{\\partial x_{1}}{\\partial u} \u0026amp; \\dfrac{\\partial x_{1}}{\\partial v} \\\\[1em] \\dfrac{\\partial x_{2}}{\\partial u} \u0026amp; \\dfrac{\\partial x_{2}}{\\partial v} \\\\[1em] \\dfrac{\\partial x_{3}}{\\partial u} \u0026amp; \\dfrac{\\partial x_{3}}{\\partial v} \\end{bmatrix} $$\nThe rank of this matrix being $2$ means that the dimension of its column space is $2$, implying $\\mathbf{x}_{u} = \\left( \\dfrac{\\partial x_{1}}{\\partial u}, \\dfrac{\\partial x_{2}}{\\partial u}, \\dfrac{\\partial x_{3}}{\\partial u} \\right)$ and $\\mathbf{x}_{v} = \\left( \\dfrac{\\partial x_{1}}{\\partial v}, \\dfrac{\\partial x_{2}}{\\partial v}, \\dfrac{\\partial x_{3}}{\\partial v} \\right)$ are linearly independent. Therefore, their cross product is not $\\mathbf{0}$.\n$$ \\mathbf{x}_{u} \\times \\mathbf{x}_{v} \\ne \\mathbf{0} $$\nThus, we can see that the two definitions are equivalent.\nMillman. (1977). Elements of Differential Geometry: p77.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBarrett O\u0026rsquo;Neill, Elementary Differential Geometry (Revised 2nd Edition, 2006), p130-131\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBarrett O\u0026rsquo;Neill, Elementary Differential Geometry (Revised 2nd Edition, 2006), p142\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2106,"permalink":"https://freshrimpsushi.github.io/en/posts/2106/","tags":null,"title":"Simple Surfaces, Coordinate Mapping"},{"categories":"Í∏∞ÌïòÌïô","contents":"Theorem1 Let\u0026rsquo;s call $M_{1}^{n}, M_{2}^{m}$ and $m, n$, respectively, $m, n$-dimensional differentiable manifolds. Let\u0026rsquo;s say $\\varphi : M_{1} \\to M_{2}$ is a differentiable function. And for every point $p \\in M_{1}$ and tangent vector $v \\in T_{p}M$, choose a differentiable curve\n$$\\alpha : (-\\epsilon, \\epsilon) \\to M_{1} \\text{ with } \\alpha (0) = p,\\ \\alpha^{\\prime}(0)=v$$\nLet\u0026rsquo;s set it as $\\beta = \\varphi \\circ \\alpha$. Then, the following mapping\n$$ d\\varphi_{p} : T_{p}M_{1} \\to T_{\\varphi(p)}M_{2} \\\\[1em] d\\varphi_{p}(v) = \\beta^{\\prime}(0) $$\nis a linear transformation that is independent of the choice of $\\alpha$.\nDefinition The mapping $d\\varphi_{p}$, defined as in the theorem above, is called the differential from $p$ to $\\varphi$.\nDescription It\u0026rsquo;s not the derivative, but the differential.\nSince the tangent vector acts on functions defined on a differentiable manifold, the differential $d\\varphi_{p}$ is a mapping from the function space to the function space. Moreover, it is clear from the conclusion of the proof that $d\\phi_{p}$ is the Jacobian for the function $\\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x}$.\n$$ \\text{differential} = \\text{Jacobian} $$\nLet\u0026rsquo;s recall the role of Jacobians. For example, suppose the integral of a function defined at $\\mathbb{R}^{2}$ is given as follows.\n$$ \\int \\int f(x,y) dx dy $$\nWhen changing coordinates to polar coordinates $(r,\\theta)$, it is necessary to multiply by the determinant of the Jacobian $\\displaystyle \\begin{vmatrix}\\dfrac{ \\partial x}{ \\partial r} \u0026amp; \\dfrac{ \\partial x}{ \\partial \\theta} \\\\ \\textstyle{} \\\\ \\dfrac{ \\partial y}{ \\partial r} \u0026amp; \\dfrac{ \\partial y}{ \\partial \\theta} \\end{vmatrix}=r$.\n$$ \\int \\int f(x,y) dx dy = \\int \\int f(r, \\theta) rdr d\\theta $$\nTherefore, the differential $d\\phi_{p}$ of $\\phi : M_{1} \\to M_{2}$ can be thought of as implementing the coordinate transformation between the differentiable manifolds $M_{1}$ and $M_{2}$ through their coordinate systems $\\mathbf{x}, \\mathbf{y}$.\nSince the Jacobian of the composition is equal to the product of the Jacobians, the following holds for $\\phi : M \\to N, \\psi : N \\to L$ and $p\\in M$,\n$$ d(\\psi \\circ \\phi)_{p} = d(\\psi)_{\\phi (p)} d(\\phi)_{p} $$\nUnderstanding the definition and significance of tangent vectors is crucial for comprehending the content of this document.\nProof Let\u0026rsquo;s call the coordinate system at point $p \\in M_{1}$ on $M_{1}$ as $\\mathbf{x} : U \\subset \\mathbb{R}^{n} \\to M_{1}$. Let\u0026rsquo;s denote the coordinates in $\\mathbb{R}^{n}$ as $(r_{1}, \\dots, r_{n}) \\in \\mathbb{R}^{n}$.\n$$ \\mathbf{x}(r_{1}, \\dots, r_{n}) = p \\quad \\text{and} \\quad \\mathbf{x}^{-1}(p) = \\left( x_{1}(p), \\dots, x_{n}(p) \\right) $$\nAnd let‚Äôs call the coordinate system at point $\\phi (p) \\in M_{2}$ on $M_{2}$ as $\\mathbf{y} : V \\subset \\mathbb{R}^{m} \\to M_{2}$. Let‚Äôs denote the coordinates in $\\mathbb{R}^{m}$ as $(s_{1}, \\dots, s_{m}) \\in \\mathbb{R}^{m}$.\n$$ \\mathbf{y}(s_{1}, \\dots, s_{m}) = \\phi (p) \\quad \\text{and} \\quad \\mathbf{y}^{-1}(\\phi (p)) = \\Big( y_{1}(\\phi (p)), \\dots, y_{m}(\\phi (p)) \\Big) $$\nBy the definition of the tangent vector, the tangent vector $\\beta^{\\prime}(0)$ at the point $\\phi (p)$ on $M_{2}$ is as follows. For the differentiable function $g : M_{2} \\to \\mathbb{R}$ defined on $M_{2}$,\n$$ \\begin{align*} \\beta^{\\prime}(0) g =\u0026amp;\\ \\dfrac{d}{dt}(g \\circ \\beta)(0) = \\dfrac{d}{dt}(g \\circ \\mathbf{y} \\circ \\mathbf{y}^{-1} \\circ \\beta)(0) \\\\ =\u0026amp;\\ \\dfrac{d}{dt}\\big( (g \\circ \\mathbf{y}) \\circ (\\mathbf{y}^{-1} \\circ \\beta)\\big)(0) \\\\ =\u0026amp;\\ \\sum \\limits_{j=1}^{m} \\left.\\dfrac{\\partial (g\\circ \\mathbf{y})}{\\partial s_{j}}\\right|_{t=0} \\dfrac{d (\\mathbf{y}^{-1} \\circ \\beta)_{j}}{d t}(0) \u0026amp; \\text{by } \\href{https://freshrimpsushi.github.io/posts/chaine-rule-for-multivariable-vector-valued-funtion}{\\text{chain rule}} \\\\ =\u0026amp;\\ \\sum \\limits_{j=1}^{m} y_{j}^{\\prime}(0) \\left.\\dfrac{\\partial (g\\circ \\mathbf{y})}{\\partial s_{j}}\\right|_{t=0} \\\\ =\u0026amp;\\ \\sum_{j=1}^{m} y_{j}^{\\prime}(0) \\left.\\dfrac{\\partial g}{\\partial y_{j}}\\right|_{t=0} \\end{align*} $$\nThe meaning of the operator $\\left.\\dfrac{\\partial }{\\partial y_{j}}\\right|_{t=0}$ here is to differentiate by pulling the domain of the non-differentiable function $g$ defined on $M_{2}$ to $\\mathbb{R}^{m}$ through composition with $\\mathbf{y}$. Now, let\u0026rsquo;s find $y_{j}^{\\prime}$.\n$$ y_{j}^{\\prime} = \\dfrac{d}{dt} (\\mathbf{y}^{-1} \\circ \\beta)_{j} $$\nAs with calculating the tangent vector, let\u0026rsquo;s consider $\\mathbf{y}^{-1} \\circ \\beta$ decomposed as follows:\n$$ \\mathbf{y}^{-1} \\circ \\beta = \\mathbf{y}^{-1} \\circ \\phi \\circ \\alpha = \\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x} \\circ \\mathbf{x}^{-1} \\circ \\alpha $$\nAnd consider the above equation as the composition of two functions, $\\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x}$ and $\\mathbf{x}^{-1} \\circ \\alpha$.\nPart 1. $\\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x}$\nSince $\\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x} : \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$,\n$$ \\begin{equation} \\mathbf{y}^{-1}\\left( \\phi (\\mathbf{x}(r_{1}, \\dots, r_{n})) \\right) = \\left( y_{1}(\\phi (\\mathbf{x}(r_{1}, \\dots, r_{n}))), \\dots, y_{m}(\\phi (\\mathbf{x}(r_{1}, \\dots, r_{n}))) \\right) \\end{equation} $$\nSimplified, this becomes\n$$ \\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x} (r_{1}, \\dots, r_{n}) = \\left( y_{1}, \\dots, y_{m}\\right) $$\nHere $y_{j}$ are technically functions concerning $\\phi (\\mathbf{x}(r_{1}, \\dots, r_{n}))$ as in $(1)$, but for simplicity, let‚Äôs denote them as functions concerning $(r_{1}, \\dots, r_{n})$.\n$$ y_{j} = y_{j}(r_{1}, \\dots, r_{n}),\\quad 1\\le j \\le m $$\nPart 2. $\\mathbf{x}^{-1} \\circ \\alpha$\nSince $\\mathbf{x}^{-1} \\circ \\alpha : \\mathbb{R} \\to \\mathbb{R}^{n}$,\n$$ \\mathbf{x}^{-1} (\\alpha (t)) = \\left( x_{i}(\\alpha (t)), \\dots, x_{n}(\\alpha (t)) \\right) $$\nHere again, for simplicity, each $x_{i}$ is denoted as if they are functions concerning $t$.\n$$ \\mathbf{x} \\circ \\alpha (t) = ( x_{i}(t), \\dots, x_{n}(t) ) $$\nNow, $(\\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x}) \\circ (\\mathbf{x}^{-1} \\circ \\alpha)$ is the composition of the function that is $\\mathbb{R} \\to \\mathbb{R}^{n}$ and the function that is $\\mathbb{R}^{n} \\to \\mathbb{R}^{m}$, so by the chain rule, we obtain the following.\n$$ \\begin{align*} \\dfrac{d}{dt} (\\mathbf{y}^{-1} \\circ \\beta)(0) =\u0026amp;\\ \\dfrac{d}{dt}(\\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x}) \\circ (\\mathbf{x}^{-1} \\circ \\alpha)(0) \\\\ =\u0026amp;\\ \\begin{bmatrix} \\sum \\limits_{i=1}^{n} \\left.\\dfrac{\\partial (\\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x})_{1}}{\\partial x_{i}}\\right|_{t=0} \\dfrac{d (\\mathbf{x}^{-1} \\circ \\alpha)_{i}}{d t}(0) \\\\ \\vdots \\\\ \\sum \\limits_{i=1}^{n} \\left.\\dfrac{\\partial (\\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x})_{m}}{\\partial x_{i}}\\right|_{t=0} \\dfrac{d (\\mathbf{x}^{-1} \\circ \\alpha)_{i}}{d t}(0) \\end{bmatrix} \\\\ =\u0026amp;\\ \\begin{bmatrix} \\sum \\limits_{i=1}^{n} \\left.\\dfrac{\\partial y_{1}}{\\partial x_{i}}\\right|_{t=0} \\dfrac{d x_{i}}{d t}(0) \\\\ \\vdots \\\\ \\sum \\limits_{i=1}^{n} \\left.\\dfrac{\\partial y_{m}}{\\partial x_{i}}\\right|_{t=0} \\dfrac{d x_{i}}{d t}(0) \\end{bmatrix} \\\\ =\u0026amp;\\ \\begin{bmatrix} \\sum \\limits_{i=1}^{n} \\dfrac{\\partial y_{1}}{\\partial x_{i}} x_{i}^{\\prime}(0) \\\\ \\vdots \\\\ \\sum \\limits_{i=1}^{n} \\dfrac{\\partial y_{m}}{\\partial x_{i}} x_{i}^{\\prime}(0) \\end{bmatrix} \\end{align*} $$\nTherefore,\n$$ y_{j}^{\\prime}(0) = \\dfrac{d}{dt} (\\mathbf{y}^{-1} \\circ \\beta)_{j}(0) = \\sum \\limits_{i=1}^{n} \\dfrac{\\partial y_{j}}{\\partial x_{i}} x_{i}^{\\prime}(0),\\quad 1\\le j \\le m $$\nThus, if we express $\\beta^{\\prime}(0)$ as a coordinate vector against the basis $\\left\\{ \\left.\\dfrac{\\partial }{\\partial y_{j}}\\right|_{t=0} \\right\\}$, it is as follows.\n$$ \\beta^{\\prime}(0) = \\sum_{j=1}^{m} y_{j}^{\\prime}(0) \\left.\\dfrac{\\partial}{\\partial y_{j}}\\right|_{t=0} = \\begin{bmatrix} y_{1}^{\\prime}(0) \\\\ \\vdots \\\\ y_{m}^{\\prime}(0) \\end{bmatrix} = \\begin{bmatrix} \\sum \\limits_{i=1}^{n} \\dfrac{\\partial y_{1}}{\\partial x_{i}} x_{i}^{\\prime}(0)\\\\ \\vdots \\\\ \\sum \\limits_{i=1}^{n} \\dfrac{\\partial y_{m}}{\\partial x_{i}} x_{i}^{\\prime}(0) \\end{bmatrix} $$\nTherefore, it can be seen that $\\beta^{\\prime}(0)$ does not depend on $\\alpha$.\nMeanwhile, the following is true for $\\alpha^{\\prime}(0) = v$.\n$$ v = \\alpha^{\\prime}(0) = \\sum \\limits_{i=1}^{n}x_{i}^{\\prime}(0) \\left.\\dfrac{\\partial }{\\partial x_{i}}\\right|_{t=0} = \\begin{bmatrix} x_{1}^{\\prime}(0) \\\\ \\vdots \\\\ x_{n}^{\\prime}(0) \\end{bmatrix} $$\nThus, organizing $\\beta^{\\prime}(0) = d\\phi_{p}(v)$ results in the following.\n$$ \\begin{align*} \\beta^{\\prime}(0) =\u0026amp;\\ \\begin{bmatrix} \\sum \\limits_{i=1}^{n} \\dfrac{\\partial y_{1}}{\\partial x_{i}} x_{i}^{\\prime}(0)\\\\ \\vdots \\\\ \\sum \\limits_{i=1}^{n} \\dfrac{\\partial y_{m}}{\\partial x_{i}} x_{i}^{\\prime}(0) \\end{bmatrix} \\\\ =\u0026amp;\\ \\begin{bmatrix} \\dfrac{\\partial y_{1}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial y_{1}}{\\partial x_{2}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial y_{1}}{\\partial x_{n}} \\\\[1em] \\dfrac{\\partial y_{2}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial y_{2}}{\\partial x_{2}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial y_{2}}{\\partial x_{n}} \\\\[1ex] \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1ex] \\dfrac{\\partial y_{m}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial y_{m}}{\\partial x_{2}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial y_{m}}{\\partial x_{n}} \\end{bmatrix} \\begin{bmatrix} x_{1}^{\\prime}(0) \\\\ \\vdots \\\\ x_{n}^{\\prime}(0) \\end{bmatrix} \\\\ =\u0026amp;\\ \\begin{bmatrix} \\dfrac{\\partial y_{1}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial y_{1}}{\\partial x_{2}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial y_{1}}{\\partial x_{n}} \\\\[1em] \\dfrac{\\partial y_{2}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial y_{2}}{\\partial x_{2}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial y_{2}}{\\partial x_{n}} \\\\[1ex] \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1ex] \\dfrac{\\partial y_{m}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial y_{m}}{\\partial x_{2}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial y_{m}}{\\partial x_{n}} \\end{bmatrix} v \\end{align*} $$\nTherefore, $d_{p}\\phi$ is a linear transformation represented by the following matrix.\n$$ d_{p}\\phi = \\begin{bmatrix} \\dfrac{\\partial y_{1}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial y_{1}}{\\partial x_{2}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial y_{1}}{\\partial x_{n}} \\\\[1em] \\dfrac{\\partial y_{2}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial y_{2}}{\\partial x_{2}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial y_{2}}{\\partial x_{n}} \\\\[1ex] \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1ex] \\dfrac{\\partial y_{m}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial y_{m}}{\\partial x_{2}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial y_{m}}{\\partial x_{n}} \\end{bmatrix} $$\nThis is also the Jacobian of the function $\\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x}$.\n$$ d\\phi_{p} = \\text{Jacobian of } \\mathbf{y}^{-1} \\circ \\phi \\circ \\mathbf{x} = \\dfrac{\\partial (y_{1}, \\dots, y_{m})}{\\partial (x_{1}, \\dots, x_{n})} $$\n‚ñ†\nManfredo P. Do Carmo, Riemannian Geometry (Eng Edition, 1992), p9-10\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3136,"permalink":"https://freshrimpsushi.github.io/en/posts/3136/","tags":null,"title":"Differentiation of Functions Defined on Differentiable Manifolds"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview1 The package is named Calculus.jl, but it does not support integration.\nIf automatic differentiation, as discussed in machine learning, is needed, refer to the Zygote.jl package.\nDifferentiation of Single Variable Function Derivative function derivative() It calculates the derivative of $f : \\R \\to \\R$.\nderivative(f) or derivative(f, :x): Returns the derivative $f^{\\prime}$. derivative(f, a): Returns the differential coefficient $f^{\\prime}(a)$. julia\u0026gt; f(x) = 1 + 2x + 3x^2\rf (generic function with 1 method)\rjulia\u0026gt; g(x) = sin(x)\rg (generic function with 1 method)\rjulia\u0026gt; derivative(f)\r#1 (generic function with 1 method)\rjulia\u0026gt; derivative(f, 1)\r7.99999999996842\rjulia\u0026gt; Df = derivative(f)\r#1 (generic function with 1 method)\rjulia\u0026gt; Dg = derivative(g)\r#1 (generic function with 1 method)\r#f\u0026#39;(x) = 2 + 6x\rjulia\u0026gt; Df(1)\r7.99999999996842\r#g\u0026#39;(x) = cos x\rjulia\u0026gt; Dg(pi)\r-0.9999999999441258 Composite functions can also be differentiated.\n#f‚àòg(x) = (2 + 6 sin x)cos x\rjulia\u0026gt; derivative(f‚àòg)\r#1 (generic function with 1 method)\rjulia\u0026gt; derivative(f‚àòg, pi/4)\r4.414213562300037\rjulia\u0026gt; (2+6sin(pi/4))cos(pi/4)\r4.414213562373095 Second derivative function second_derivative() It calculates the second derivative of $f : \\R \\to \\R$.\nThe function returned by derivative() can take integers as input, but second_derivative() cannot use integer types. Irrational number types are also not allowed.\njulia\u0026gt; derivative(f, 1)\r7.99999999996842\rjulia\u0026gt; second_derivative(f, 1)\rERROR: MethodError: no method matching eps(::Type{Int64})\rClosest candidates are:\reps() at float.jl:764\reps(::AbstractFloat) at float.jl:760\reps(::Type{Float16}) at float.jl:761\rjulia\u0026gt; second_derivative(f, 1.)\r5.9999956492003905\rjulia\u0026gt; second_derivative(g, pi)\rERROR: MethodError: no method matching eps(::Type{Irrational{:œÄ}})\rClosest candidates are:\reps() at float.jl:764\reps(::AbstractFloat) at float.jl:760\reps(::Type{Float16}) at float.jl:761\rjulia\u0026gt; second_derivative(g, convert(Float64, pi))\r-1.3553766145945872e-7\rjulia\u0026gt; second_derivative(g, 1pi)\r-1.3553766145945872e-7 Differentiation of Multivariable Function Gradient gradient() Returns the gradient of $f : \\mathbb{R}^{n} \\to \\mathbb{R}$.\nNote that when defining a multivariable function, it should not be defined as a function with multiple real variables. It must be defined as a single-variable function that takes a vector as input. If it\u0026rsquo;s not a function accepting a vector as input, differentiation can be performed, but the value cannot be calculated. For example, it should not be defined as $f_{1}$, but rather as $f_{2}$.\njulia\u0026gt; f‚ÇÅ(x,y,z) = x*y + z^2\rf‚ÇÅ (generic function with 1 method)\rjulia\u0026gt; Calculus.gradient(f‚ÇÅ)\r#2 (generic function with 1 method)\rjulia\u0026gt; ‚àáf‚ÇÅ = Calculus.gradient(f‚ÇÅ)\r#2 (generic function with 1 method)\rjulia\u0026gt; ‚àáf‚ÇÅ(1,1,1)\rERROR: MethodError: no method matching (::Calculus.var\u0026#34;#2#4\u0026#34;{typeof(f‚ÇÅ), Symbol})(::Int64, ::Int64, ::Int64)\rjulia\u0026gt; ‚àáf‚ÇÅ([1,1,1])\rERROR: MethodError: no method matching f‚ÇÅ(::Vector{Float64})\rjulia\u0026gt; Calculus.gradient(f‚ÇÅ, 1,1,1)\rERROR: MethodError: no method matching gradient(::typeof(f‚ÇÅ), ::Int64, ::Int64, ::Int64)\rjulia\u0026gt; Calculus.gradient(f‚ÇÅ, [1,1,1])\rERROR: MethodError: no method matching f‚ÇÅ(::Vector{Float64})\rjulia\u0026gt; f‚ÇÇ(x) = x[1]*x[2] + x[3]^2\rf‚ÇÇ (generic function with 1 method)\rjulia\u0026gt; Calculus.gradient(f‚ÇÇ, [1,1,1])\r3-element Vector{Float64}:\r1.0000000000235538\r1.0000000000235538\r1.9999999999737708\rjulia\u0026gt; ‚àáf‚ÇÇ = Calculus.gradient(f‚ÇÇ)\r#2 (generic function with 1 method)\rjulia\u0026gt; ‚àáf‚ÇÇ(1,1,1)\rERROR: MethodError: no method matching (::Calculus.var\u0026#34;#2#4\u0026#34;{typeof(f‚ÇÇ), Symbol})(::Int64, ::Int64, ::Int64)\rjulia\u0026gt; ‚àáf‚ÇÇ([1,1,1])\r3-element Vector{Float64}:\r1.0000000000235538\r1.0000000000235538\r1.9999999999737708 Hessian hessian() Returns the Hessian of $f : \\mathbb{R}^{n} \\to \\mathbb{R}$.\nSimilar to second_derivative(), it only accepts Float data types as input. Like gradient(), it can only return values for functions that take vectors as input.\njulia\u0026gt; hessian(f‚ÇÇ, [1.,1.,1.])\r3√ó3 Matrix{Float64}:\r3.88008e-7 1.0 0.0\r1.0 3.88008e-7 0.0\r0.0 0.0 2.0\rjulia\u0026gt; H = hessian(f‚ÇÇ)\r#7 (generic function with 1 method)\rjulia\u0026gt; H([1.,1.,1.])\r3√ó3 Matrix{Float64}:\r3.88008e-7 1.0 0.0\r1.0 3.88008e-7 0.0\r0.0 0.0 2.0 Jacobian jacobian() Returns the Jacobian of $f : \\mathbb{R}^{m} \\to \\mathbb{R}^{n}$.\nSimilar to second_derivative(), it only accepts Float data types as input. Like gradient(), it can only return values for functions that take vectors as input.\nUnlike other functions, using it like jacobian(f, [x, y, z]) is not possible.\njulia\u0026gt; h(x) = [x[1], x[1]*x[2], x[1]*x[3]^2]\rh (generic function with 2 methods)\rjulia\u0026gt; jacobian(h, [1.,1.,1.])\rERROR: MethodError: no method matching jacobian(::typeof(h), ::Vector{Float64})\rjulia\u0026gt; Jh = jacobian(h)\r(::Calculus.var\u0026#34;#g#5\u0026#34;{typeof(h), Symbol}) (generic function with 1 method)\rjulia\u0026gt; Jh([1.,1.,1.])\r3√ó3 Matrix{Float64}:\r1.0 0.0 0.0\r1.0 1.0 0.0\r1.0 0.0 2.0 Symbolic Differentiation Symbolic differentiation is also available in the SymEngine.jl package.\ndifferentiate() Performs symbolic differentiation.\nWhile it returns constant terms and $x$ neatly, for cases like $ax$ or $x^{n}$, it returns in the form of the product rule. For example, differentiating $3x^{2}$ would return it as the product of $3$ and $x^{2}$, seen as $\\dfrac{d 3}{dx} x^{2} + 3\\dfrac{d x^{2}}{dx}$. Even $x^{2}$ is seen as the product of $1$ and $x^{2}$.\njulia\u0026gt; differentiate(\u0026#34;1\u0026#34;, :x)\r0\rjulia\u0026gt; differentiate(\u0026#34;1 + x\u0026#34;, :x)\r1\rjulia\u0026gt; differentiate(\u0026#34;x^2\u0026#34;, :x)\r:(2 * 1 * x ^ (2 - 1))\rjulia\u0026gt; differentiate(\u0026#34;x^3\u0026#34;, :x)\r:(3 * 1 * x ^ (3 - 1))\rjulia\u0026gt; differentiate(\u0026#34;1 + x + x^2\u0026#34;, :x)\r:(1 + 2 * 1 * x ^ (2 - 1))\rjulia\u0026gt; differentiate(\u0026#34;1 + 2x + 3x^2 + 4x^3\u0026#34;, :x)\r:((0 * x + 2 * 1) + (0 * x ^ 2 + 3 * (2 * 1 * x ^ (2 - 1))) + (0 * x ^ 3 + 4 * (3 * 1 * x ^ (3 - 1))))\rjulia\u0026gt; differentiate(\u0026#34;x^2 * sin(x) + exp(x) * cos(x)\u0026#34;, :x)\r:(((2 * 1 * x ^ (2 - 1)) * sin(x) + x ^ 2 * (1 * cos(x))) + ((1 * exp(x)) * cos(x) + exp(x) * (1 * -(sin(x))))) Characters not specified as symbols are treated as constants, and if more than one symbol is input, it returns the differentiation for each symbol. However, writing \u0026quot;3yx\u0026quot; treats xy as a single variable, so it\u0026rsquo;s important to explicitly denote multiplication by writing it as 3x*y.\njulia\u0026gt; differentiate(\u0026#34;1 + x + 3yx + y^2\u0026#34;, :x)\r:(1 + (0yx + 3 * 0))\rjulia\u0026gt; differentiate(\u0026#34;1 + x + 3y*x + y^2\u0026#34;, :x)\r:(1 + ((0y + 3 * 0) * x + (3y) * 1))\rjulia\u0026gt; differentiate(\u0026#34;1 + x + 3yx + y^2\u0026#34;, [:x, :y])\r2-element Vector{Any}:\r:(1 + (0yx + 3 * 0))\r:((0yx + 3 * 0) + 2 * 1 * y ^ (2 - 1))\rjulia\u0026gt; differentiate(\u0026#34;1 + x + 3x*y + y^2\u0026#34;, [:x, :y])\r2-element Vector{Any}:\r:(1 + ((0 * x + 3 * 1) * y + (3x) * 0))\r:(((0 * x + 3 * 0) * y + (3x) * 1) + 2 * 1 * y ^ (2 - 1)) simplify() The return of differentiate() lacks readability, but simplify() neatly organizes it. However, it doesn\u0026rsquo;t perform properly if vectors are used as input.\njulia\u0026gt; simplify(differentiate(\u0026#34;1 + 2x + 3x^2 + 4x^3\u0026#34;, :x))\r:(2 + 3 * (2x) + 4 * (3 * x ^ 2))\rjulia\u0026gt; simplify(differentiate(\u0026#34;1 + x + 3x*y + y^2\u0026#34;, :x))\r:(1 + 3y)\rjulia\u0026gt; simplify(differentiate(\u0026#34;1 + x + 3x*y + y^2\u0026#34;, :y))\r:(3x + 2y)\rjulia\u0026gt; simplify(differentiate(\u0026#34;1 + x + 3x*y + y^2\u0026#34;, [:x, :y]))\r2-element Vector{Any}:\r:(1 + ((0 * x + 3 * 1) * y + (3x) * 0))\r:(((0 * x + 3 * 0) * y + (3x) * 1) + 2 * 1 * y ^ (2 - 1)) deparse() Turns the return of symbolic differentiation into a string.\njulia\u0026gt; a = differentiate(\u0026#34;1 + x + 3x*y + y^2\u0026#34;, :x)\r:(1 + ((0 * x + 3 * 1) * y + (3x) * 0))\rjulia\u0026gt; deparse(a)\r\u0026#34;1 + ((0 * x + 3 * 1) * y + (3 * x) * 0)\u0026#34;\rjulia\u0026gt; deparse(simplify(a))\r\u0026#34;1 + 3 * y\u0026#34; Verification check_derivative() One can check how much the derivative obtained by derivative() differs from the actual derivative. It\u0026rsquo;s implemented for the four types of derivatives excluding jacobian().\ncheck_derivative(f, Df, a): Returns the absolute value of derivative(f, a)-Df(a). julia\u0026gt; f(x) = 1 + x^2\rf (generic function with 1 method)\rjulia\u0026gt; Df(x) = 2x\rDf (generic function with 1 method)\rjulia\u0026gt; Calculus.check_derivative(f, Df, 1)\r2.6229241001374248e-11 Application Polynomials.jl Although derivative is implemented in Polynomials.jl itself, the derivatives can also be calculated with Calculus.derivative().\njulia\u0026gt; p = Polynomial([1,2,4,1])\rPolynomial(1 + 2*x + 4*x^2 + x^3)\rjulia\u0026gt; Polynomials.derivative(p)\rPolynomial(2 + 8*x + 3*x^2)\rjulia\u0026gt; Calculus.derivative(p)\r#1 (generic function with 1 method)\rjulia\u0026gt; Polynomials.derivative(p,2)\rPolynomial(8 + 6*x)\rjulia\u0026gt; Calculus.second_derivative(p)\r#6 (generic function with 1 method) Environment OS: Windows10 Version: Julia 1.6.2, Calculus 0.5.1 https://github.com/JuliaMath/Calculus.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3135,"permalink":"https://freshrimpsushi.github.io/en/posts/3135/","tags":null,"title":"How to Find Derivatives in Julia"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Theorem Let\u0026rsquo;s assume that two functions $\\mathbf{g} : D \\subset \\mathbb{R}^{m} \\to \\mathbb{R}^{k}$, $\\mathbf{f} : \\mathbf{g}(\\mathbb{R}^{k}) \\subset \\mathbb{R}^{k} \\to \\mathbb{R}^{n}$ are differentiable. Then, the composition of these two functions $\\mathbf{F} = \\mathbf{f} \\circ \\mathbf{g} : \\mathbb{R}^{m} \\to \\mathbb{R}^{n}$ is also differentiable, and the (total) derivative of $\\mathbf{F}$ satisfies the following.\n$$ \\mathbf{F}^{\\prime}(\\mathbf{x}) = \\mathbf{f}^{\\prime}\\left( \\mathbf{g}(\\mathbf{x}) \\right) \\mathbf{g}^{\\prime}(\\mathbf{x}) $$\nExplanation This is called the chain rule.\nIf we denote $\\mathbf{x} = (x_{1}, \\dots, x_{m})$, $\\mathbf{g}(\\mathbf{x}) = (g_{1}, \\dots, g_{k})$, $\\mathbf{f}(g_{1}, \\dots, g_{k}) = (f_{1}, \\dots, f_{n})$, the specific form of the formula can be represented by the following $n \\times m$ matrix from the definition of total derivative.\n$$ \\begin{align*} \\mathbf{F}^{\\prime} (\\mathbf{x}) =\u0026amp;\\ \\begin{bmatrix} \\dfrac{\\partial f_{1}(\\mathbf{g}(\\mathbf{x}))}{\\partial g_{1}} \u0026amp; \\dfrac{\\partial f_{1}}{\\partial g_{2}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial f_{1}}{\\partial g_{k}} \\\\[1em] \\dfrac{\\partial f_{2}}{\\partial g_{1}} \u0026amp; \\dfrac{\\partial f_{2}}{\\partial g_{2}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial f_{2}}{\\partial g_{k}} \\\\[1em] \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1em] \\dfrac{\\partial f_{n}}{\\partial g_{1}} \u0026amp; \\dfrac{\\partial f_{n}}{\\partial g_{2}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial f_{n}}{\\partial g_{k}} \\end{bmatrix} \\begin{bmatrix} \\dfrac{\\partial g_{1}(\\mathbf{x})}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial g_{1}}{\\partial x_{2}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial g_{1}}{\\partial x_{m}} \\\\[1em] \\dfrac{\\partial g_{2}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial g_{2}}{\\partial x_{2}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial g_{2}}{\\partial x_{m}} \\\\[1em] \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1em] \\dfrac{\\partial g_{k}}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial g_{k}}{\\partial x_{2}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial g_{k}}{\\partial x_{m}} \\end{bmatrix} \\\\[1em] =\u0026amp;\\ \\begin{bmatrix} \\dfrac{\\partial f_{1}}{\\partial g_{1}} \\dfrac{\\partial g_{1}}{\\partial x_{1}}+\\dfrac{\\partial f_{1}}{\\partial g_{2}}\\dfrac{\\partial g_{2}}{\\partial x_{1}} + \\cdots + \\dfrac{\\partial f_{1}}{\\partial g_{k}} \\dfrac{\\partial g_{k}}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial f_{1}}{\\partial g_{1}} \\dfrac{\\partial g_{1}}{\\partial x_{1}}+\\dfrac{\\partial f_{1}}{\\partial g_{2}}\\dfrac{\\partial g_{2}}{\\partial x_{m}} + \\cdots + \\dfrac{\\partial f_{1}}{\\partial g_{k}} \\dfrac{\\partial g_{k}}{\\partial x_{m}} \\\\[1em] \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1em] \\dfrac{\\partial f_{n}}{\\partial g_{1}} \\dfrac{\\partial g_{1}}{\\partial x_{1}}+\\dfrac{\\partial f_{n}}{\\partial g_{2}}\\dfrac{\\partial g_{2}}{\\partial x_{1}} + \\cdots + \\dfrac{\\partial f_{n}}{\\partial g_{k}} \\dfrac{\\partial g_{k}}{\\partial x_{1}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial f_{n}}{\\partial g_{1}} \\dfrac{\\partial g_{1}}{\\partial x_{1}}+\\dfrac{\\partial f_{n}}{\\partial g_{2}}\\dfrac{\\partial g_{2}}{\\partial x_{m}} + \\cdots + \\dfrac{\\partial f_{n}}{\\partial g_{m}} \\dfrac{\\partial g_{k}}{\\partial x_{m}} \\end{bmatrix} \\\\[1em] =\u0026amp;\\ \\begin{bmatrix} \\displaystyle \\sum\\limits_{\\ell =1}^{k} \\dfrac{\\partial f_{1}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\displaystyle \\sum\\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{1}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{m}} \\\\[1em] \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1em] \\displaystyle \\sum\\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{n}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\displaystyle \\sum\\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{n}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{m}} \\end{bmatrix} \\end{align*} $$\nIn Einstein notation, for $1 \\le i \\le n$, $1 \\le j \\le m$\n$$ \\mathbf{F}^{\\prime} = \\left[ F_{ij}^{\\prime} \\right] = \\begin{bmatrix} \\dfrac{\\partial f_{1}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial f_{1}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{m}} \\\\[1em] \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1em] \\dfrac{\\partial f_{n}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\dfrac{\\partial f_{n}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{m}} \\end{bmatrix} $$\n$$ F_{ij}^{\\prime} = \\dfrac{\\partial f_{i}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{j}} $$\nSince this is the most generalized form, various specific formulas can be obtained according to $k, m, n$.\nFormulas Case 1. $g : \\mathbb{R} \\to \\mathbb{R}$, $f : \\mathbb{R} \\to \\mathbb{R}$, $F = f \\circ g : \\mathbb{R} \\to \\mathbb{R}$\nWhen $x \\in \\mathbb{R}$, $g = g(x)$, $f = f(g(x))$,\n$$ F^{\\prime} = \\dfrac{d F}{d x} = \\dfrac{d f}{d g} \\dfrac{d g}{d x} $$\nProof\nCase 2. $\\mathbf{g} : \\mathbb{R} \\to \\mathbb{R}^{k}$, $f : \\mathbb{R}^{k} \\to \\mathbb{R}$, $F = f \\circ \\mathbf{g} : \\mathbb{R} \\to \\mathbb{R}$\nWhen $x \\in \\mathbb{R}$, $\\mathbf{g}(x) = (g_{1}, \\dots, g_{k})$, $f = f(g_{1}, \\dots ,g_{k})$,\n$$ F^{\\prime} = \\dfrac{d F}{d x} = \\sum \\limits_{\\ell=1}^{k}\\dfrac{\\partial f}{\\partial g_{\\ell}} \\dfrac{d g_{\\ell}}{d x} $$\nCase 3. $g : \\mathbb{R}^{m} \\to \\mathbb{R}$, $f : \\mathbb{R} \\to \\mathbb{R}$, $F = f \\circ g : \\mathbb{R}^{m} \\to \\mathbb{R}$\nWhen $\\mathbf{x} = (x_{1}, \\dots, x_{n}) \\in \\mathbb{R}^{n}$, $g = g(\\mathbf{x})$, $f = f(g(\\mathbf{x}))$,\n$$ F^{\\prime} = \\dfrac{d F}{d \\mathbf{x}} = \\begin{bmatrix} \\dfrac{d f}{d g} \\dfrac{\\partial g}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\dfrac{d f}{d g} \\dfrac{\\partial g}{\\partial x_{m}} \\end{bmatrix} $$\n$$ F_{j}^{\\prime} = \\dfrac{d f}{d g} \\dfrac{\\partial g}{\\partial x_{j}},\\quad 1 \\le j \\le m $$\nCase 4. $\\mathbf{g} : \\mathbb{R}^{m} \\to \\mathbb{R}^{k}$, $f : \\mathbb{R}^{k} \\to \\mathbb{R}$, $F = f \\circ \\mathbf{g} : \\mathbb{R}^{m} \\to \\mathbb{R}$\nWhen $\\mathbf{x} = (x_{1}, \\dots, x_{n}) \\in \\mathbb{R}^{n}$, $\\mathbf{g}(x) = (g_{1}, \\dots, g_{k})$, $f = f(g_{1}, \\dots, g_{k})$,\n$$ F^{\\prime} = \\dfrac{d F}{d \\mathbf{x}} = \\begin{bmatrix} \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{m}} \\end{bmatrix} $$\n$$ F_{j}^{\\prime} = \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{j}},\\quad 1 \\le j \\le m $$\nCase 5. $g : \\mathbb{R} \\to \\mathbb{R}$, $\\mathbf{f} : \\mathbb{R} \\to \\mathbb{R}^{n}$, $\\mathbf{F} = \\mathbf{f} \\circ g : \\mathbb{R} \\to \\mathbb{R}^{n}$\nWhen $x \\in \\mathbb{R}$, $g = g(x)$, $\\mathbf{f}(g(x)) = (f_{1}, \\dots, f_{n})$,\n$$ \\mathbf{F}^{\\prime} = \\dfrac{d \\mathbf{F}}{d x} = \\begin{bmatrix} \\dfrac{d f_{1}}{d g} \\dfrac{d g}{d x} \\\\[1em] \\vdots \\\\[1em] \\dfrac{d f_{n}}{d g} \\dfrac{d g}{d x} \\end{bmatrix} $$\n$$ F_{i}^{\\prime} = \\dfrac{d f_{i}}{d g} \\dfrac{d g}{d x},\\quad 1\\le i \\le n $$\nCase 6. $\\mathbf{g} : \\mathbb{R} \\to \\mathbb{R}^{k}$, $\\mathbf{f} : \\mathbb{R}^{k} \\to \\mathbb{R}^{n}$, $\\mathbf{F} = \\mathbf{f} \\circ \\mathbf{g} : \\mathbb{R} \\to \\mathbb{R}^{n}$\nWhen $x \\in \\mathbb{R}$, $\\mathbf{g}(x) = (g_{1}, \\dots, g_{k})$, $\\mathbf{f}(g_{1}, \\dots ,g_{k}) = (f_{1}, \\dots, f_{n})$,\n$$ \\mathbf{F}^{\\prime} = \\dfrac{d \\mathbf{F}}{d x} = \\begin{bmatrix} \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{1}}{\\partial g_{\\ell}} \\dfrac{d g_{\\ell}}{d x} \\\\[1em] \\vdots \\\\[1em] \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{n}}{\\partial g_{\\ell}} \\dfrac{d g_{\\ell}}{d x} \\end{bmatrix} $$\n$$ F_{i}^{\\prime} = \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{i}}{\\partial g_{\\ell}} \\dfrac{d g_{\\ell}}{d x},\\quad 1\\le i \\le n $$\nCase 7. $g : \\mathbb{R}^{m} \\to \\mathbb{R}$, $\\mathbf{f} : \\mathbb{R} \\to \\mathbb{R}^{n}$, $\\mathbf{F} = \\mathbf{f} \\circ g : \\mathbb{R}^{m} \\to \\mathbb{R}^{n}$\nWhen $\\mathbf{x} = (x_{1}, \\dots, x_{n}) \\in \\mathbb{R}^{n}$, $g = g(\\mathbf{x})$, $\\mathbf{f}(g(\\mathbf{x})) = (f_{1}, \\dots, f_{n})$,\n$$ \\mathbf{F}^{\\prime} = \\dfrac{d \\mathbf{F}}{d \\mathbf{x}} = \\begin{bmatrix} \\dfrac{d f_{1}}{d g} \\dfrac{\\partial g}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\dfrac{d f_{1}}{d g} \\dfrac{\\partial g}{\\partial x_{m}} \\\\[1em] \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1em] \\dfrac{d f_{n}}{d g} \\dfrac{\\partial g}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\dfrac{d f_{n}}{d g} \\dfrac{\\partial g}{\\partial x_{m}} \\end{bmatrix} $$\n$$ F_{ij}^{\\prime} = \\dfrac{d f_{i}}{d g} \\dfrac{\\partial g}{\\partial x_{j}},\\quad 1\\le i \\le n, 1 \\le j \\le m $$\nCase 8. $\\mathbf{g} : \\mathbb{R}^{m} \\to \\mathbb{R}^{k}$, $\\mathbf{f} : \\mathbb{R}^{k} \\to \\mathbb{R}^{n}$, $\\mathbf{F} = \\mathbf{f} \\circ \\mathbf{g} : \\mathbb{R}^{m} \\to \\mathbb{R}^{n}$\nWhen $\\mathbf{x} = (x_{1}, \\dots, x_{n}) \\in \\mathbb{R}^{n}$, $g(\\mathbf{x}) = (g_{1}, \\dots, g_{k})$, $\\mathbf{f}(g_{1}, \\dots, g_{k}) = (f_{1}, \\dots, f_{n})$,\n$$ \\mathbf{F}^{\\prime} = \\dfrac{d \\mathbf{F}}{d \\mathbf{x}} = \\begin{bmatrix} \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{1}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{1}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{m}} \\\\[1em] \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\[1em] \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{n}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{1}} \u0026amp; \\dots \u0026amp; \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{n}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{m}} \\end{bmatrix} $$\n$$ F_{ij}^{\\prime} = \\sum \\limits_{\\ell=1}^{k} \\dfrac{\\partial f_{i}}{\\partial g_{\\ell}} \\dfrac{\\partial g_{\\ell}}{\\partial x_{j}},\\quad 1\\le i \\le n, 1 \\le j \\le m $$\nProof Refer to the generalized proof.\n‚ñ†\n","id":3134,"permalink":"https://freshrimpsushi.github.io/en/posts/3134/","tags":null,"title":"Chain Rule for Multivariable Vector Functions"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code fill() function can be used. It serves a similar purpose to the rep() function in R.\n","id":2101,"permalink":"https://freshrimpsushi.github.io/en/posts/2101/","tags":null,"title":"How to Create an Array Filled with a Specific Value in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Buildup1 To define a tangent vector at each point on a differentiable manifold $M$, let\u0026rsquo;s assume a differentiable curve $\\alpha : (-\\epsilon , \\epsilon) \\to M$ is given. We would like to define the derivative $\\dfrac{d \\alpha}{dt}(0)$ at $t=0$ in $\\alpha$ as a tangent vector, like in differential geometry, but since the range of $\\alpha$ is $M$ (since it\u0026rsquo;s not guaranteed to be a metric space), we cannot speak of the derivative of $\\alpha$. For this reason, tangent vectors on a manifold are defined as functions, namely operators. If you\u0026rsquo;ve studied differential geometry, treating vectors as operators should be familiar. See the following explanation.\nDirectional derivative\nLet $\\mathbf{X} \\in T_{p}M$ be a tangent vector at point $p$ of surface $M$, and let $\\alpha (t)$ be a curve on $M$. Then $\\alpha : (-\\epsilon, \\epsilon) \\to M$ and $\\alpha (0) = p$ are satisfied, meaning $\\mathbf{X} = \\dfrac{d \\alpha}{d t} (0)$. Now, let function $f$ be a differentiable function defined in some neighborhood of point $p \\in M$ on surface $M$. Then, the directional derivativedirectional derivative $\\mathbf{X}f$ in the direction of $\\mathbf{X}$ is defined as follows:\n$$ \\mathbf{X} : \\mathcal{D} \\to \\mathbb{R}, \\quad \\text{where } \\mathcal{D} \\text{ is set of all differentiable functions near } p $$\n$$ \\mathbf{X} f := \\dfrac{d}{dt_{}} (f \\circ \\alpha) (0) $$\nAs shown in the definition above, if there is a fixed tangent vector $\\mathbf{X}$, then every time $f$ is given, $\\mathbf{X}f$ is determined. Therefore, a tangent vector is treated as an operator itself. The notation like $\\mathbf{X}f$ is used because it is viewed from the perspective of an operator. Tangent vectors on a differential manifold are similarly defined as functions that map real space through the composition with some curve $\\alpha$ every time a differentiable function $f$ is given on $M$.\nDefinition Let\u0026rsquo;s say $M$ is a $n$-dimensional differentiable manifold. A differentiable function $\\alpha : (-\\epsilon , \\epsilon) \\to M$ is called a differentiable curve at $M$. Assuming $\\alpha (0)=p\\in M$, let\u0026rsquo;s define the set $\\mathcal{D}$ as the set of differentiable functions at $p$.\n$$ \\mathcal{D} := \\left\\{ f : M \\to \\mathbb{R} | \\text{functions on } M \\text{that are differentiable at } p \\right\\} $$\nThen, the tangent vector $\\alpha^{\\prime}(0) : \\mathcal{D} \\to \\mathbb{R}$ at $\\alpha (0) = p$ is defined as the following function.\n$$ \\alpha^{\\prime} (0) f = \\dfrac{d}{dt} (f\\circ \\alpha)(0),\\quad f\\in \\mathcal{D} $$\nThe set of all tangent vectors at point $p\\in M$ is called the tangent spacetangent space and is denoted as $T_{p}M$.\nExplanation $f : M \\to \\mathbb{R}$ and $\\alpha : (-\\epsilon, \\epsilon) \\to M$ cannot be differentiated in the classical sense because their domains and ranges are not guaranteed to be metric spaces, but their composition $f \\circ \\alpha : (-\\epsilon, \\epsilon) \\to \\mathbb{R}$ can be differentiated.\nSince a tangent vector is determined whenever a differentiable curve $\\alpha$ is given, it can be thought that there are as many tangent vectors as there are differentiable curves. Moreover, even if two tangent vectors $\\mathbf{X}, \\mathbf{Y}$ are determined by two different curves $\\alpha$ and $\\beta$, if $\\mathbf{X}f = \\mathbf{Y}f$ holds for all $f \\in \\mathcal{D}$, then $\\mathbf{X}$ and $\\mathbf{Y}$ are considered the same tangent vector.\nThe reason the set of tangent vectors $T_{p}M$ is called a tangent space is that it is actually a $n$-dimensional vector space.\nFrom the theorem introduced below, it is possible to express the function value $\\alpha^{\\prime}(0)f$ of the tangent vector at point $p$ in terms of any coordinate system $\\mathbf{x} : U \\to M$ concerning $p$, and this value does not depend on the choice of $\\mathbf{x}$.\nExample Consider $T_{p}\\mathbb{R}^{3}$. When a differentiable curve $\\alpha : (-\\epsilon, \\epsilon) \\to \\mathbb{R}^{3}$ is determined, a 3-dimensional vector $\\alpha^{\\prime}(0) = \\mathbf{v} = (v_{1}, v_{2}, v_{3}) \\in \\mathbb{R}^{3}$ is determined. Therefore, according to the definition, the tangent vector for $f : \\mathbb{R}^{3} \\to \\mathbb{R}$ is as follows:\n$$ \\mathbf{X}f = \\dfrac{d (f\\circ \\alpha)}{d t}(0) = \\sum \\limits_{i} \\dfrac{\\partial f}{\\partial x_{i}}\\dfrac{d \\alpha_{i}}{d t}(0) = \\sum\\limits_{i} v_{i} \\dfrac{\\partial f}{\\partial x_{i}} $$\nThis is the same as the directional derivative in Euclidean space.\n$$ \\mathbf{v}[f] = \\nabla _{\\mathbf{v}}f = \\mathbf{v} \\cdot \\nabla f = \\sum \\limits_{i} v_{i} \\dfrac{\\partial f}{\\partial v_{i}} $$\nThe directional derivative is essentially the same as treating the vector as an operator. Therefore, $\\mathbf{X}$ can be considered an element of $\\mathbb{R}^{3}$, and the following holds:\n$$ T_{p}\\mathbb{R}^{3} \\approxeq \\mathbb{R}^{3} $$\nTheorem Let\u0026rsquo;s say a differentiable curve $\\alpha (0) = p$ and a coordinate system $\\mathbf{x} : U \\to M$ at point $p$ are given. $(u_{1}, \\dots, u_{n})$ are the coordinates of $\\mathbb{R}^{n}$,\n$$ (x_{1}(p), \\dots, x_{n}(p)) = \\mathbf{x}^{-1}(p) $$\nThen, the following formula holds:\n$$ \\begin{align*} \\alpha ^{\\prime} (0) f =\u0026amp;\\ \\sum \\limits_{i=1}^{n}x_{i}^{\\prime}(p) \\left.\\dfrac{\\partial (f\\circ \\mathbf{x})}{\\partial u_{i}}\\right|_{p} \\\\ =\u0026amp;\\ \\sum \\limits_{i=1}^{n}x_{i}^{\\prime}(\\alpha (0)) \\left.\\dfrac{\\partial f}{\\partial x_{i}}\\right|_{t=0} \\end{align*} $$\nHere, we simply denote it as $x_{i}^{\\prime}(0) = x_{i}^{\\prime}(\\alpha (0))$. Therefore, $\\alpha^{\\prime}(0)$ is defined as the following differential operator:\n$$ \\begin{equation} \\alpha ^{\\prime} (0) = \\sum \\limits_{i=1}^{n}x_{i}^{\\prime}(0) \\left.\\dfrac{\\partial }{\\partial x_{i}}\\right|_{t=0} \\end{equation} $$\nIf we express it as coordinate vectors for basis $\\left\\{ \\left.\\dfrac{\\partial }{\\partial x_{i}}\\right|_{t=0} \\right\\}$, it is as follows:\n$$ \\alpha ^{\\prime} (0) = \\begin{bmatrix} x_{1}^{\\prime}(0) \\\\ \\vdots \\\\ x_{n}^{\\prime}(0) \\end{bmatrix} $$\nProof Choose a coordinate system $\\mathbf{x} : U \\subset \\mathbb{R}^{n} \\to M$ such that $p = \\mathbf{x}(0)$ is satisfied. Consider $f\\circ \\alpha = f \\circ \\mathbf{x} \\circ \\mathbf{x}^{-1} \\circ \\alpha$ to express the tangent vector in terms of the coordinate system. Then, since $\\mathbf{x} \\circ \\mathbf{x}^{-1} = I$ is an identity function, any choice of coordinate system is irrelevant. Now, think of $f \\circ \\mathbf{x}$ and $\\mathbf{x}^{-1} \\circ \\alpha$ as one function each, and consider $f \\circ \\alpha$ as their composite function.\n$$ f \\circ \\alpha = (f \\circ \\mathbf{x}) \\circ (\\mathbf{x}^{-1} \\circ \\alpha) $$\nFirst, consider $f \\circ \\mathbf{x}$. Since $f \\circ \\mathbf{x} : \\mathbb{R}^{n} \\to \\mathbb{R}$, it can be expressed as follows and differentiated in the classical sense:\n$$ f \\circ \\mathbf{x} = f \\circ \\mathbf{x} (u) = f \\circ \\mathbf{x} (u_{1}, u_{2}, \\dots, u_{n}),\\quad u=(u_{1},\\dots,u_{n}) \\in \\mathbb{R}^{n} $$\n$\\mathbf{x}^{-1} \\circ \\alpha$ can also be expressed as follows since $\\mathbf{x}^{-1} \\circ \\alpha : \\mathbb{R} \\to \\mathbb{R}^{n}$, and it can be differentiated in the classical sense:\n$$ \\begin{align*} \\mathbf{x}^{-1} \\circ \\alpha (t) =\u0026amp;\\ (x_{1}(\\alpha (t)), x_{2}(\\alpha (t)), \\dots, x_{n}(\\alpha (t))) \\\\ =\u0026amp;\\ (x_{1}(t), x_{2}(t), \\dots, x_{n}(t)) \\end{align*} $$\nNote that $x_{i}$ is a function of $x_{i} : M \\to \\mathbb{R}$, and $x_{i}(t)$ is a simplified notation of $x_{i}(\\alpha (t))$.\nThinking this way, $f \\circ \\alpha$ is a composition of two functions, mapped as $\\mathbb{R} \\overset{\\mathbf{x}^{-1} \\circ \\alpha}{\\longrightarrow} \\mathbb{R}^{n} \\overset{f\\circ \\mathbf{x}}{\\longrightarrow} \\mathbb{R}$. Therefore, by the chain rule, the following holds:\n$$ \\dfrac{d}{d t}(f \\circ \\alpha) = \\dfrac{d}{dt} \\left( (f\\circ \\mathbf{x}) \\circ (\\mathbf{x}^{-1} \\circ \\alpha) \\right) = \\sum \\limits_{i=1}^{n}\\dfrac{\\partial (f\\circ \\mathbf{x})}{\\partial u_{i}} \\dfrac{d (\\mathbf{x}^{-1} \\circ \\alpha )_{i}}{d t} = \\sum \\limits_{i=1}^{n}\\dfrac{\\partial (f\\circ \\mathbf{x})}{\\partial u_{i}} \\dfrac{d x_{i}}{d t} $$\nThus, we obtain the following:\n$$ \\begin{align*} \\alpha^{\\prime}(0) f :=\u0026amp;\\ \\dfrac{d}{dt} (f\\circ \\alpha)(0) \\\\ =\u0026amp;\\ \\sum \\limits_{i=1}^{n} \\left.\\dfrac{\\partial (f\\circ \\mathbf{x})}{\\partial u_{i}}\\right|_{t=0} \\dfrac{d x_{i}}{d t}(0) \\\\ =\u0026amp;\\ \\sum \\limits_{i=1}^{n} \\left.\\dfrac{\\partial (f\\circ \\mathbf{x})}{\\partial u_{i}}\\right|_{t=0} x_{i}^{\\prime}(0) \\\\ =\u0026amp;\\ \\sum \\limits_{i=1}^{n} x_{i}^{\\prime}(0) \\left.\\dfrac{\\partial (f\\circ \\mathbf{x})}{\\partial u_{i}}\\right|_{t=0} \\end{align*} $$\nHere, let\u0026rsquo;s define $\\left.\\dfrac{\\partial }{\\partial x_{i}}\\right|_{t=0}$ as the following operator:\n$$ \\left.\\dfrac{\\partial }{\\partial x_{i}}\\right|_{t=0} f := \\left.\\dfrac{\\partial (f\\circ \\mathbf{x})}{\\partial u_{i}}\\right|_{t=0} $$\nSummarizing the meaning of $\\dfrac{\\partial f}{\\partial x_{i}}$:\n$f$ cannot be differentiated since its domain is $M$. Therefore, consider the composition with coordinate system $\\mathbf{x} : \\mathbb{R}^{n} \\to M$. This maps $\\mathbb{R}^{n}$ to $\\mathbb{R}$, thus can be differentiated in the classical sense. Therefore, $\\dfrac{\\partial f}{\\partial x_{i}}$ is defined as differentiating after composing $f$ with $\\mathbf{x}$ in Euclidean space $\\mathbb{R}^{n}$ at the $u_{i}$-th variable.\nFinally, we obtain the following:\n$$ \\begin{align*} \\alpha^{\\prime}(0) f =\u0026amp;\\ \\sum \\limits_{i=1}^{n} x_{i}^{\\prime}(0) \\left.\\dfrac{\\partial (f\\circ \\mathbf{x})}{\\partial u_{i}}\\right|_{t=0} \\\\ =\u0026amp;\\ \\sum \\limits_{i=1}^{n} x_{i}^{\\prime}(0) \\left.\\dfrac{\\partial }{\\partial x_{i}}\\right|_{t=0}f = \\ \\sum \\limits_{i=1}^{n} x_{i}^{\\prime}(0) \\left.\\dfrac{\\partial f}{\\partial x_{i}}\\right|_{t=0} \\end{align*} $$\n$$ \\implies \\alpha^{\\prime}(0) = \\sum \\limits_{i=1}^{n} x_{i}^{\\prime}(0) \\left.\\dfrac{\\partial }{\\partial x_{i}}\\right|_{t=0} $$\n‚ñ†\nSee Also Directional derivative in analysis Directional derivative in differential geometry Manfredo P. Do Carmo, Riemannian Geometry (Eng Edition, 1992), p6-8\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3132,"permalink":"https://freshrimpsushi.github.io/en/posts/3132/","tags":null,"title":"Tangent Vector on Differentiable Manifold"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 Given that $M_{1}, M_{2}$ are each a $n, m$-dimensional differentiable manifold, a mapping $\\varphi : M_{1} \\to M_{2}$ is defined to be differentiable at $p \\in M_{1}$ if it satisfies the following conditions:\nWhenever a coordinate system $\\mathbf{y} : V \\subset \\mathbb{R}^{m} \\to M_{2}$ is given in $\\varphi(p)$, there exists a coordinate system $\\mathbf{x} : U \\subset \\mathbb{R}^{n} \\to M_{1}$ in $p$ such that $\\varphi\\left( \\mathbf{x}(U) \\right) \\subset \\mathbf{y}(V)$ holds.\nThe mapping $\\mathbf{y}^{-1} \\circ \\varphi \\circ \\mathbf{x} : U \\subset \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$ is differentiable at $\\mathbf{x}^{-1}(p)$.\nExplanation Just like when defining differentiable manifolds, differentiation is defined through the coordinate system $\\mathbf{x}, \\mathbf{y}$.\nCondition 1. might look difficult at first, but on a closer look, it precisely matches the definition of the $\\epsilon -\\delta$ method or the sense of defining continuity in topology.\nFor condition 2., since $\\mathbf{y}^{-1} \\circ \\varphi \\circ \\mathbf{x}$ is a function from Euclidean space to Euclidean space, it is differentiable in the classical sense. This mapping is termed the expression of $\\varphi$ in coordinate systems $\\mathbf{x}$ and $\\mathbf{y}$.\nManfredo P. Do Carmo, Riemannian Geometry (Eng Edition, 1992), p5-6\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3130,"permalink":"https://freshrimpsushi.github.io/en/posts/3130/","tags":null,"title":"Differentiable Functions from a Differentiable Manifold to a Differentiable Manifold"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code The code to read a shp file named XsDB_Ï£ºÍ±∞Ïù∏Íµ¨_100M_TM.shp is as follows.\nusing Shapefile\rcd(@__DIR__)\rpath = \u0026#34;XsDB_Ï£ºÍ±∞Ïù∏Íµ¨_100M_TM.shp\u0026#34;\rtable = Shapefile.Table(path)\rusing DataFrames\rdf = DataFrame(table) Of course, just reading the file is limited in what can be done, and it is necessary to convert it to a dataframe to examine the data.\nExecution result 959660√ó16 DataFrame\rRow ‚îÇ geometry MEGA_NM MEGA_CD CTY_NM CTY_CD X_AXIS Y_AXIS HOUS POP POP_10 POP_20 POP_30 POP_40 POP_50 POP_60_O \\xb9\\xe8\\xc6\\xf7√≥ ‚îÇ Point‚Ä¶? String String String String Int64 Int64 Float64 Float64 Float64 Float64 Float64 Float64 Float64 Float64 String\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ Point(254298.0, 4.26549e5) \\xb0\\xe6\\xb1\\u2d75 41 \\xbf\\xa9\\xc1÷±\\xba 41730 365950 526450 10.08 24.56 4.64 1.92 1.84 4.72 4.32 7.12 biz-gis.com\r2 ‚îÇ Point(2.59622e5, 4.24405e5) \\xb0\\xe6\\xb1\\u2d75 41 \\xbf\\xa9\\xc1÷±\\xba 41730 371250 524250 1.42 3.47 0.81 0.29 0.52 0.52 0.59 0.74 biz-gis.com\r3 ‚îÇ Point(2.61134e5, 423221.0) \\xb0\\xe6\\xb1\\u2d75 41 \\xbf\\xa9\\xc1÷±\\xba 41730 372750 523050 1.26 3.08 0.68 0.28 0.35 0.49 0.45 0.83 biz-gis.com\r4 ‚îÇ Point(2.50311e5, 4.15806e5) \\xb0\\xe6\\xb1\\u2d75 41 \\xbf\\xa9\\xc1÷±\\xba 41730 361850 515750 10.08 25.2 3.68 2.96 1.68 4.4 6.0 6.48 biz-gis.com\r‚ãÆ ‚îÇ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ\r959658 ‚îÇ Point(2.09955e5, 2.46768e5) \\xc0\\xfc\\xb6\\xf3\\xbaœµ\\xb5 45 \\xbf\\xcf\\xc1÷±\\xba 45710 319750 347150 1.83 4.53 1.92 0.24 0.45 0.72 0.69 0.51 biz-gis.com\r959659 ‚îÇ Point(215588.0, 4.55344e5) \\xb0\\xe6\\xb1\\u2d75 41 \\xb3\\xb2\\xbe\\xe7\\xc1÷Ω\\xc3 41360 327550 555650 2.38 5.31 0.91 0.74 0.57 0.97 1.05 1.07 biz-gis.com\r959660 ‚îÇ Point(2.54717e5, 4.24754e5) \\xb0\\xe6\\xb1\\u2d75 41 \\xbf\\xa9\\xc1÷±\\xba 41730 366350 524650 1.26 3.07 0.58 0.24 0.23 0.59 0.54 0.89 biz-gis.com\r959653 rows omitted Environment OS: Windows julia: v1.5.0 ","id":2097,"permalink":"https://freshrimpsushi.github.io/en/posts/2097/","tags":null,"title":"How to Read SHP Files in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"## Summary To use the `trunc` function, simply pass `Int` as the first argument. ## Code julia\u0026gt; @time for t in 1:10^8 Int64(ceil(t/1000)) end 0.189653 seconds\njulia\u0026gt; @time for t in 1:10^8 trunc(Int64, ceil(t/1000)) end 0.128472 seconds\nThe two loops perform the identical task but with about a 1.5 times speed difference. The former drops the decimal points using `ceil` and type casts to `Int64`, whereas the latter returns an integer natively using the built-in capability of the `trunc` function, which is faster. People who are used to programming in other languages might find the straightforward commands like the upper loop more intuitive, but in Julia, there are many built-in functions that take a data type as the first argument to return a result, so the usage like in the lower loop will become more familiar. ## Environment - OS: Windows - julia: v1.5.0 ","id":2095,"permalink":"https://freshrimpsushi.github.io/en/posts/2095/","tags":null,"title":"How to truncate decimal points and convert to an integer in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition 1 A regular curve $\\beta (t)$ is said to be simple if $\\beta$ is an injective function or it is a closed curve with period $a \u0026gt; 0$ that satisfies the following for some integer $n \\in \\mathbb{Z}$: $$ \\beta \\left( t_{1} \\right) = \\beta \\left( t_{2} \\right) \\iff t_{1} - t_{2} = na $$\nExample Cases like the above, which cannot be represented as an injective function but are considered simple curves,\nare closed curves without any twisted parts. If there are twisted parts, it cannot satisfy the mathematical conditions at that point.\nMillman. (1977). Elements of Differential Geometry: p54.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2094,"permalink":"https://freshrimpsushi.github.io/en/posts/2094/","tags":null,"title":"Definition of a Simple Curve"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview To rename columns, you can use the rename!() function1.\nYou can rename them all at once by providing a list of strings, or individually.\nCode using DataFrames\rdf = DataFrame(rand(1:9, 10, 3), :auto)\rrename!(df, [\u0026#34;X\u0026#34;, \u0026#34;Y\u0026#34;, \u0026#34;Z\u0026#34;])\rrename!(df, :X =\u0026gt; :A) When executed, it first creates the following dataframe:\njulia\u0026gt; df = DataFrame(rand(1:9, 10, 3), :auto)\r10√ó3 DataFrame\rRow ‚îÇ x1 x2 x3 ‚îÇ Int64 Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 2 3 6\r2 ‚îÇ 9 2 4\r3 ‚îÇ 3 3 4\r4 ‚îÇ 3 3 3\r5 ‚îÇ 9 1 6\r6 ‚îÇ 3 1 5\r7 ‚îÇ 4 8 4\r8 ‚îÇ 9 8 4\r9 ‚îÇ 4 6 1\r10 ‚îÇ 1 9 7 Renaming All at Once julia\u0026gt; rename!(df, [\u0026#34;X\u0026#34;, \u0026#34;Y\u0026#34;, \u0026#34;Z\u0026#34;])\r10√ó3 DataFrame\rRow ‚îÇ X Y Z ‚îÇ Int64 Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 2 3 6\r2 ‚îÇ 9 2 4\r3 ‚îÇ 3 3 4\r4 ‚îÇ 3 3 3\r5 ‚îÇ 9 1 6\r6 ‚îÇ 3 1 5\r7 ‚îÇ 4 8 4\r8 ‚îÇ 9 8 4\r9 ‚îÇ 4 6 1\r10 ‚îÇ 1 9 7 Just provide a list of strings.\nRenaming One by One julia\u0026gt; rename!(df, :X =\u0026gt; :A)\r10√ó3 DataFrame\rRow ‚îÇ A Y Z ‚îÇ Int64 Int64 Int64 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 2 3 6\r2 ‚îÇ 9 2 4\r3 ‚îÇ 3 3 4\r4 ‚îÇ 3 3 3\r5 ‚îÇ 9 1 6\r6 ‚îÇ 3 1 5\r7 ‚îÇ 4 8 4\r8 ‚îÇ 9 8 4\r9 ‚îÇ 4 6 1\r10 ‚îÇ 1 9 7 This method, which is rarely seen in other languages, involves prefixing column names with : and mapping them with =\u0026gt;. In Julia, a variable that starts with : is a Symbol.\nEnvironment OS: Windows julia: v1.6.2 https://discourse.julialang.org/t/change-column-names-of-a-dataframe-previous-methods-dont-work/48026/2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2093,"permalink":"https://freshrimpsushi.github.io/en/posts/2093/","tags":null,"title":"Renaming Column Names of a DataFrame in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition 1 A regular curve $\\beta (t)$ being a closed curve is equivalent to being a periodic function $\\beta$.\nFormula: Length of a Closed Curve If $\\alpha (s)$ is the arc length parameterization of a closed curve $\\beta (t)$ with period $a\u0026gt;0$, then $\\alpha$ is a closed curve with period $L = \\int_{0}^{a} |d \\beta / dt| dt$. In other words, the length of the closed curve $\\beta$ is $L$.\nDerivation $$ \\begin{align*} s(t+a) =\u0026amp; \\int_{0}^{t+a}\\left|\\frac{d \\beta}{d t}\\right| d t \\\\ =\u0026amp; \\int_{0}^{a}\\left|\\frac{d \\beta}{d t}\\right| d t+\\int_{a}^{t+a}\\left|\\frac{d \\beta}{d t}\\right| d t \\\\ =\u0026amp; L+\\int_{0}^{t}\\left|\\frac{d \\beta}{d t}\\right| d t \\\\ =\u0026amp; L+s(t) \\end{align*} $$ To summarize, $s \\left( t + a \\right) = s(t) + L$, $$ \\begin{align*} \\alpha (s + L) =\u0026amp; \\alpha \\left( s (t) + L \\right) \\\\ =\u0026amp; \\alpha \\left( s (t + a) \\right) \\\\ =\u0026amp; \\beta (t + a) \\\\ =\u0026amp; \\beta (t) \\\\ =\u0026amp; \\alpha \\left( s(t) \\right) \\\\ =\u0026amp; \\alpha (s) \\end{align*} $$ Therefore, $\\alpha (s)$ is a closed curve. $a \u0026gt; 0$ being $$ \\beta (t + a) = \\beta (t) \\qquad , \\forall t $$ the smallest positive number satisfying, so $L\u0026gt;0$ also $$ \\alpha (s + L) = \\alpha (s) \\qquad , \\forall s $$ must be the smallest positive number satisfying. In other words, the length of $\\beta$ is $L$.\n‚ñ†\nMillman. (1977). Elements of Differential Geometry: p53.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2092,"permalink":"https://freshrimpsushi.github.io/en/posts/2092/","tags":null,"title":"Definition of a Closed Curve"},{"categories":"Ìï®Ïàò","contents":"Definition1 Let\u0026rsquo;s assume that function $f : X \\to Y$ is given. Let\u0026rsquo;s also assume that $U \\subset X \\subset V$ holds.\nContraction Mapping We call $f |_{U} \\to Y$ a contraction mapping of $f$ if it satisfies the following.\n$$ f|_{U} : U \\to Y \\quad \\text{and} \\quad f|_{U}(x) = f (x),\\quad \\forall x \\in U $$\nExtension We call $\\tilde{f} \\to Y$ an extension of $f$ if it satisfies the following.\n$$ \\tilde{f} : V \\to Y \\quad \\text{and} \\quad \\tilde{f}(x) = f (x),\\quad \\forall x \\in X $$\nExplanation Usually, instead of the translated terms contraction mapping (also known as restriction) and extension, the direct English pronunciations [restriction] and [extension] are used.\nSimply put, it\u0026rsquo;s about narrowing or widening the domain of the function while keeping its shape unchanged.\nAccording to the definition, it\u0026rsquo;s obvious that $f$ is a restriction of $\\tilde{f}$, and an extension of $f|_{U}$.\nErwin Kreyszig, Introductory Functional Analysis with Applications (1989), p99\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3123,"permalink":"https://freshrimpsushi.github.io/en/posts/3123/","tags":null,"title":"Expansion and Contraction of a Function"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition The following partial differential equation is called the Helmholtz equation.\n$$ \\nabla^{2}u(x) + k^{2} u(x) = \\Delta u(x) + k^{2} u(x) = (\\Delta + k^{2} )u(x) = 0,\\quad x \\in \\mathbb{R}^{n} $$\nHere, $\\nabla ^{2} = \\Delta$ is the Laplacian.\nExplanation It can also be expressed in the form of $-\\Delta u = \\lambda u$. Hence it is sometimes called the eigenvalue equation for the Laplace operator.\nIt can be derived from the wave equation, thus it is also referred to as the reduced wave equation1.\nUnlike the wave equation, which includes derivatives with respect to both time and space, the Helmholtz equation lacks the time term, making it a partial differential equation that depends only on the spatial variables.\nDerivation The wave equation is as follows:\n$$ \\Delta u(x,t) - \\dfrac{1}{c^{2}}\\dfrac{\\partial^{2} u(x,t)}{\\partial t^{2}} = 0 $$\nHere, $c$ represents the velocity of the wave.\nMethod 1 The solution to the wave equation, that is, the wave function, is as follows:\n$$ u (x,t) = u(x)u(t) = e^{ikx} e^{-i\\omega t} = e^{i(kx - \\omega t)} $$\nHere, $x , t$ represent space and time, respectively, and $k, \\omega$ represent the wave number and angular frequency. When the speed of the wave is $c$, the following relationship holds:\n$$ k = \\dfrac{\\omega}{c} $$\nTherefore, if we figure out $u_{tt}(x,t)$, it is as follows:\n$$ u_{tt}(x,t) = \\dfrac{\\partial ^{2}}{\\partial t^{2}}e^{i(kx - \\omega t)} = (-i \\omega)^{2}e^{i(kx - \\omega t)} = -\\omega^{2}e^{i(kx - \\omega t)} $$\nSubstituting this into the wave equation yields the Helmholtz equation.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\Delta u - \\dfrac{1}{c^{2}}\\dfrac{\\partial^{2} u}{\\partial t^{2}} =\u0026amp;\\ 0 \\\\[1em] \\implies \u0026amp;\u0026amp; \\Delta e^{i(kx - \\omega t)} + \\dfrac{\\omega^{2}}{c^{2}} e^{i(kx - \\omega t)} =\u0026amp;\\ 0 \\\\[1em] \\implies \u0026amp;\u0026amp; \\left( \\Delta e^{ikx} + k^{2} e^{ikx} \\right) e^{-i\\omega t}=\u0026amp;\\ 0 \\\\[1em] \\implies \u0026amp;\u0026amp; \\Delta e^{ikx} + k^{2} e^{ikx}=\u0026amp;\\ 0 \\\\[1em] \\implies \u0026amp;\u0026amp; \\Delta u(x) + k^{2} u(x) =\u0026amp;\\ 0 \\end{align*} $$\n‚ñ†\nMethod 2 Taking the Fourier transform of the wave equation with respect to $t$ gives:\n$$ \\begin{align*} \u0026amp;\u0026amp; \\Delta u(x,t) - \\dfrac{1}{c^{2}}u_{tt}(x,t) =\u0026amp;\\ 0 \\\\ \\implies \u0026amp;\u0026amp; \\widehat{\\Delta u}(x,\\omega) - \\dfrac{1}{c^{2}} \\widehat{u_{tt}}(x,\\omega) =\u0026amp;\\ 0 \\end{align*} $$\nHere, using the property of Fourier transform $\\widehat{u^{\\prime \\prime}}(\\omega) = - \\omega^{2} \\widehat{u}(\\omega)$ for the second term yields:\n$$ \\begin{align*} \u0026amp;\u0026amp; \\widehat{\\Delta u}(x,\\omega) + \\dfrac{\\omega^{2}}{c^{2}} \\widehat{u}(x,\\omega) =\u0026amp;\\ 0 \\\\[1em] \\implies \u0026amp;\u0026amp; \\widehat{\\Delta u}(x,\\omega) + k^{2} \\widehat{u}(x,\\omega) =\u0026amp;\\ 0 \\\\[1em] \\implies \u0026amp;\u0026amp; \\Delta u(x, t) + k^{2} u(x, t) =\u0026amp;\\ 0 \\end{align*} $$\nAssuming that $u(x,t)$ is separable in terms of variables,\n$$ \\begin{align*} \u0026amp;\u0026amp; \\Delta u(x, t) + k^{2} u(x, t) =\u0026amp;\\ 0 \\\\[1em] \\implies \u0026amp;\u0026amp; \\Delta u(x) u(t) + k^{2} u(x) u(t) =\u0026amp;\\ 0 \\\\[1em] \\implies \u0026amp;\u0026amp; \\Delta u(x) + k^{2} u(x) =\u0026amp;\\ 0 \\end{align*} $$\n‚ñ†\nMethod 3 Assuming that it is separable in variables as $u(x, t) = u(x)v(t)$, let\u0026rsquo;s organize the equation as follows:\n$$ \\begin{align*} \u0026amp;\u0026amp; \\dfrac{\\partial^{2} u(x, t)}{\\partial x^{2}} =\u0026amp;\\ \\dfrac{1}{c^{2}}\\dfrac{\\partial^{2} u(x, t)}{\\partial t^{2}} \\\\[1em] \\implies \u0026amp;\u0026amp; \\dfrac{d^{2} u}{d x^{2}} v =\u0026amp;\\ \\dfrac{1}{c^{2}}\\dfrac{d^{2} v }{d t^{2}} u \\\\[1em] \\implies \u0026amp;\u0026amp; \\dfrac{1}{u}\\dfrac{d^{2} u}{d x^{2}} =\u0026amp;\\ \\dfrac{1}{c^{2}} \\dfrac{1}{v}\\dfrac{d^{2} v }{d t^{2}} \\end{align*} $$\nThen, since the left-hand side is independent of $t$ and the right-hand side is independent of $x$, it can be concluded that both sides are constants relative to $x$ and $t$. Let\u0026rsquo;s call that constant $-k^{2}$. Then, we obtain:\n$$ \\begin{align*} \u0026amp;\u0026amp; \\dfrac{1}{u}\\dfrac{d^{2} u}{d x^{2}} =\u0026amp;\\ -k^{2} \\\\[1em] \\implies \u0026amp;\u0026amp; \\dfrac{d^{2} u}{d x^{2}} =\u0026amp;\\ -k^{2}u \\\\[1em] \\implies \u0026amp;\u0026amp; \\dfrac{d^{2} u}{d x^{2}} + k^{2}u =\u0026amp;\\ 0 \\end{align*} $$\n‚ñ†\nDavid Colton and Rainer Kress, Inverse Acoustic and Electromagnetic Scattering Theory (4th Edition, 2019), p15\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3122,"permalink":"https://freshrimpsushi.github.io/en/posts/3122/","tags":null,"title":"Helmholtz Equation"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview To calculate the distance between $n$ points, if there\u0026rsquo;s no need to create a matrix but just to compute the distance, using a k-d tree1, a data structure advantageous for multi-dimensional search, can enhance speed. All related algorithms are implemented in NearestNeighbors.jl, so refer to the official GitHub page.\nSpeed Comparison Let\u0026rsquo;s compare with the technique optimized for calculating distance matrices using the pairwise() function.\nusing Distances\rusing StatsBase\rusing Random\rusing NearestNeighbors\rRandom.seed!(0);\rŒµ = 0.01\rN = 10^4\rcoordinate = rand(2, N);\rstate = sample([\u0026#39;S\u0026#39;, \u0026#39;I\u0026#39;], Weights([0.1, 0.9]), N);\rS = coordinate[:, state .== \u0026#39;S\u0026#39;]\rI = coordinate[:, state .== \u0026#39;I\u0026#39;]\r@time sum(pairwise(Euclidean(),S,I) .\u0026lt; Œµ, dims = 1)\r@time kdtree = KDTree(S); contact = length.(inrange(kdtree, I, Œµ, true)) The result of running the above code is as follows. The last two command lines perform the same task, but the speed difference is about 500 times. In fact, the time complexity when searching in a k-d tree is $\\log n$, which is very efficient.\njulia\u0026gt; @time sum(pairwise(Euclidean(),S,I) .\u0026lt; Œµ, dims = 1)\r0.098394 seconds (14 allocations: 69.639 MiB, 8.23% gc Time)\r1√ó9004 Array{Int64,2}:\r0 0 1 0 0 0 0 ‚Ä¶ 1 0 0 0 0 0\rjulia\u0026gt; @time kdtree = KDTree(S); contact = length.(inrange(kdtree, I, Œµ, true))\r0.000213 seconds (22 allocations: 51.609 KiB)\r9004-element Array{Int64,1}:\r0\r0\r1\r0\r‚ãÆ\r0\r0\r0 Even setting aside the simple issue of speed, the approach using the k-d tree is more convenient from the perspective of using the results, as it returns a 1-dimensional array.\nEnvironment OS: Windows julia: v1.6.2 https://en.wikipedia.org/wiki/K-d_tree\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2088,"permalink":"https://freshrimpsushi.github.io/en/posts/2088/","tags":null,"title":"How to Calculate Distance using NearstNeibors.jl in julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition1 Let $M$ be an arbitrary set and $U_{\\alpha} \\subset \\mathbb{R}^{n}$ be an open set. For the function $1-1$ $\\mathbf{x}_{\\alpha} : U_{\\alpha} \\to M$, the ordered pair $\\left( M, \\left\\{ \\mathbf{x}_{\\alpha} \\right\\}_{\\alpha\\in \\mathscr{A}} \\right)$, or simply $M$, is defined as a differentiable manifold of dimension $n$ if the following conditions are met:\n$\\bigcup \\limits_{\\alpha} \\mathbf{x}_{\\alpha} \\left( U_{\\alpha} \\right) = M$ For $\\varnothing \\ne W = \\mathbf{x}_{\\alpha}\\left( U_{\\alpha} \\right) \\cap \\mathbf{x}_{\\beta}\\left( U_{\\beta} \\right)$, the mapping $\\mathbf{x}_{\\beta}^{-1} \\circ \\mathbf{x}_{\\alpha} : \\mathbf{x}_{\\alpha}^{-1}(W) \\to \\mathbf{x}_{\\beta}^{-1}(W)$ is differentiable. For all possible $\\alpha$ that satisfy conditions 1 and 2, the index family $\\left\\{ \\left( U_{\\alpha}, \\mathbf{x}_{\\alpha} \\right) \\right\\}$ is constructed. Description Also simply called a differentiable manifold or smooth manifold. A $n$-dimensional differential manifold is sometimes denoted by $M^{n}$.\nWhen $p \\in \\mathbf{x}_{\\alpha}(U_{\\alpha})$, $\\left( U_{\\alpha}, \\mathbf{x}_{\\alpha} \\right)$ or simply $\\mathbf{x}_{\\alpha}$ is called the coordinate system of $M$ at $p$, local coordinate system, or parameterization.\nThe $\\mathbf{x}_{\\alpha}(U_{\\alpha})$ is called the coordinate neighborhood at $p \\in M$.\nThe index family $\\left\\{ \\left( U_{\\alpha}, \\mathbf{x}_{\\alpha} \\right) \\right\\}$ satisfying condition 3. is called the differentiable structure on $M$\nFor $p \\in M$, functions $x_{i}$ that satisfy $\\mathbf{x}_{\\alpha}^{-1}(p) = \\left( x_{1}(p), \\dots, x_{n}(p) \\right)$ are called coordinate functions.\nBecause $M$ is given as a completely arbitrary set (i.e., not generally a metric space), there can be no discussion about whether $\\mathbf{x}_{\\alpha}$ is differentiable or not. Moreover, since $M$ is a union of various images, a suitably good condition is needed at each intersection $W = \\mathbf{x}_{\\alpha}\\left( U_{\\alpha} \\right) \\cap \\mathbf{x}_{\\beta}\\left( U_{\\beta} \\right)$, which is given here as the condition of being differentiable.\nDepending on the condition of mapping $\\mathbf{x}_{\\beta}^{-1} \\circ \\mathbf{x}_{\\alpha}$, the manifold is called various names. For instance, if the condition of being continuous is given instead of differentiable, then $M$ becomes a topological manifold. If the condition of being holomorphic is given, then $M$ becomes a complex manifold. Also, if $\\mathbf{x}_{\\beta}^{-1} \\circ \\mathbf{x}_{\\alpha} \\in C^{k}$, then $M$ is called a $C^{k}$ manifold. In differential geometry, the tool of differentiation is used to describe geometry, hence the handling of differentiable manifolds.\nThis content is a technical part, existing to avoid discussions about whether two differentiable structures are the same or different. Assuming that all such satisfying 1 and 2 have been gathered, it means, \u0026lsquo;How about this?\u0026rsquo;, \u0026lsquo;Is this also included?\u0026rsquo; such tackles should not be thrown.\nExample Euclidean Space $\\mathbb{R}^{n}$ $$ \\mathbb{R}^{n} = \\left\\{ (x_{1}, x_{2}, \\dots, x_{n}) : x_{i} \\in \\mathbb{R} \\right\\} $$\nIt\u0026rsquo;s natural to consider $\\mathbb{R}^{n}$ as a differentiable manifold because a manifold is locally similar to Euclidean space. Let\u0026rsquo;s call ${\\rm id}$ the identity operator.\nThe differentiable structure is established as $\\left\\{ \\left( U_{\\alpha}, {\\rm id} \\right) | U_{\\alpha} \\subset \\mathbb{R}^{n} \\text{ is open.} \\right\\}$.\nSince the identity operator is differentiable, it is established.\nFor all such pairs, the index family $\\left\\{ \\left( U_{\\alpha}, {\\rm id} \\right)\\right\\}$ is constructed.\nThus, $\\left( \\mathbb{R}^{n}, \\left\\{ {\\rm id} \\right\\} \\right)$ is a differentiable manifold.\n2-dimensional Sphere $\\mathbb{S}^{2}$ $$ \\mathbb{S}^{2} = \\left\\{ p \\in \\mathbb{R}^{3} : \\left\\| p \\right\\|=1 \\right\\} $$\nA 2-dimensional sphere can be represented with 6 coordinate patches as follows. For $(u,v) \\in U = \\left\\{ (u,v) : u^{2} + v^{2} \\lt 1 \\right\\}$,\nCoordinate Patch Definition Inverse $\\mathbf{x}_{1} = \\mathbf{x}_{(0,0,1)} : U \\to \\R^{3}$ $\\mathbf{x}_{(0,0,1)}(u, v) = \\left( u, v , \\sqrt{1- u^{2} -v^{2} } \\right)$ $\\mathbf{x}_{(0,0,1)}^{-1}(x, y, z) = (x,y)$ $\\mathbf{x}_{2} = \\mathbf{x}_{(0,0,-1)} : U \\to \\R^{3}$ $\\mathbf{x}_{(0,0,-1)}(u, v) = \\left( u, v , -\\sqrt{1- u^{2} -v^{2} } \\right)$ $\\mathbf{x}_{(0,0,-1)}^{-1}(x, y, z) = (x,y)$ $\\mathbf{x}_{3} = \\mathbf{x}_{(0,1,0)} : U \\to \\R^{3}$ $\\mathbf{x}_{(0,1,0)}(u, v) = \\left( u, \\sqrt{1- u^{2} -v^{2}}, v \\right)$ $\\mathbf{x}_{(0,1,0)}^{-1}(x, y, z) = (x,z)$ $\\mathbf{x}_{4} = \\mathbf{x}_{(0,-1,0)} : U \\to \\R^{3}$ $\\mathbf{x}_{(0,-1,0)}(u, v) = \\left( u, -\\sqrt{1- u^{2} -v^{2}}, v \\right)$ $\\mathbf{x}_{(0,-1,0)}^{-1}(x, y, z) = (x,z)$ $\\mathbf{x}_{5} = \\mathbf{x}_{(1,0,0)} : U \\to \\R^{3}$ $\\mathbf{x}_{(1,0,0)}(u, v) = \\left( \\sqrt{1- u^{2} -v^{2}}, u, v \\right)$ $\\mathbf{x}_{(1,0,0)}^{-1}(x, y, z) = (y,z)$ $\\mathbf{x}_{6} = \\mathbf{x}_{(-1,0,0)} : U \\to \\R^{3}$ $\\mathbf{x}_{(-1,0,0)}(u, v) = \\left( -\\sqrt{1- u^{2} -v^{2}}, u, v \\right)$ $\\mathbf{x}_{(-1,0,0)}^{-1}(x, y, z) = (y,z)$ $\\bigcup \\limits_{i=1}^6 \\mathbf{x}_{i} = \\mathbb{S}^{2}$ is established.\n$\\mathbf{x}_{(0,0,1)}^{-1} \\circ \\mathbf{x}_{(1,0,0)}$, being as follows, is differentiable.\n$$\\mathbf{x}_{(0,0,1)}^{-1} \\circ \\mathbf{x}_{(1,0,0)}(u,v) = \\mathbf{x}_{(0,0,1)}^{-1} \\left( \\sqrt{1- u^{2} -v^{2}}, u, v \\right) = \\left( \\sqrt{1- u^{2} -v^{2}}, u \\right) \\in C^{\\infty}$$\nIn this manner, for all pairs satisfying 1 and 2, the index family $\\left\\{ \\left( U_{\\alpha}, \\mathbf{x}_{\\alpha} \\right) \\right\\}$ is constructed. Thus, $\\left( \\mathbb{S}^{2} , \\left\\{ \\mathbf{x}_{\\alpha} \\right\\} \\right)$ is a differentiable manifold.\nManfredo P. Do Carmo, Riemannian Geometry (Eng Edition, 1992), p2-3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3116,"permalink":"https://freshrimpsushi.github.io/en/posts/3116/","tags":null,"title":"Differentiable Manifolds"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Theorem Let\u0026rsquo;s say a random sample $X_{1} , \\cdots , X_{n}$ has the same probability mass/density function $f \\left( x ; \\theta \\right)$ for a parameter $\\theta \\in \\Theta$. Statistic $Y = u_{1} \\left( X_{1} , \\cdots , X_{n} \\right)$ is a sufficient statistic for $\\theta$ if there exist two non-negative functions $k_{1} , k_{2} \\ge 0$ that satisfy the following. $$ f \\left( x_{1} ; \\theta \\right) \\cdots f \\left( x_{n} ; \\theta \\right) = k_{1} \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) ; \\theta \\right] k_{2} \\left( x_{1} , \\cdots , x_{n} \\right) $$ Here, $k_{2}$ must not depend on $\\theta$.\nProof Definition of Sufficient Statistic: For a function $H \\left( x_{1} , \\cdots , x_{n} \\right)$ that does not depend on $\\theta \\in \\Theta$, $$ {{ f \\left( x_{1} ; \\theta \\right) \\cdots f \\left( x_{n} ; \\theta \\right) } \\over { f_{Y_{1}} \\left( u_{1} \\left( x_{1} , \\cdots, x_{n} \\right) ; \\theta \\right) }} = H \\left( x_{1} , \\cdots , x_{n} \\right) $$ if that is true, then $Y_{1}$ is called a Sufficient Statistic for $\\theta$.\nWe prove this only for continuous probability distributions. Refer to Casella for proofs on discrete probability distributions.\n$(\\Rightarrow)$\nAs per the definition of sufficient statistic, it is obvious since $f_{Y_{1}}$ corresponds to $k_{1}$, and $H$ to $f_{2}$.\n$(\\Leftarrow)$\n$$ \\begin{align*} y_{1} \u0026amp;:= u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) \\\\ y_{2} \u0026amp;:= u_{2} \\left( x_{1} , \\cdots , x_{n} \\right) \\\\ \u0026amp;\\vdots \\\\ y_{n} \u0026amp;:= u_{n} \\left( x_{1} , \\cdots , x_{n} \\right) \\end{align*} $$\nLet\u0026rsquo;s denote the inverse functions of the above functions for convenience and represent the Jacobian as $J$.\n$$ \\begin{align*} x_{1} \u0026amp;:= w_{1} \\left( y_{1} , \\cdots , y_{n} \\right) \\\\ x_{2} \u0026amp;:= w_{2} \\left( y_{1} , \\cdots , y_{n} \\right) \\\\ \u0026amp;\\vdots \\\\ x_{n} \u0026amp;:= w_{n} \\left( y_{1} , \\cdots , y_{n} \\right) \\end{align*} $$\nThen, the joint probability density function $g$ of $Y_{1} , \\cdots , Y_{n}$ for $w_{i} = w_{i} \\left( y_{1} , \\cdots , y_{n} \\right)$ is $$ g \\left( y_{1} , \\cdots , y_{n} ; \\theta \\right) = k_{1} \\left( y_{1} ; \\theta \\right) k_{2} \\left( w_{1} , \\cdots , w_{n} \\right) \\left| J \\right| $$ and, the marginal probability density function $f_{Y_{1}}$ of $Y_{1}$ is $$ \\begin{align*} f_{Y_{1}} \\left( y_{1} ; \\theta \\right) =\u0026amp; \\int_{-\\infty}^{\\infty} \\cdots \\int_{-\\infty}^{\\infty} g \\left( y_{1} , \\dots , y_{n} ; \\theta \\right) d y_{2} \\cdots d y_{n} \\\\ =\u0026amp; k_{1} \\left( y_{1} ; \\theta \\right) \\int_{-\\infty}^{\\infty} \\cdots \\int_{-\\infty}^{\\infty} \\left| J \\right| k_{2} \\left( w_{1} , \\dots , w_{n} \\right) d y_{2} \\cdots d y_{n} \\end{align*} $$ $k_{2}$, being a function that does not depend on $\\theta$ and since $J$ also does not involve $\\theta$, the right-hand integral can be expressed as a function solely of $y_{1}$, which we\u0026rsquo;ll temporarily denote as $m \\left( y_{1} \\right)$. $$ f_{Y_{1}} \\left( y_{1} ; \\theta \\right) = k_{1} \\left( y_{1} ; \\theta \\right) m \\left( y_{1} \\right) $$ Here, if $m \\left( y_{1} \\right) = 0$, it is trivially $f_{Y_{1}} \\left( y_{1} ; \\theta \\right) = 0$. Now, assuming $m \\left( y_{1} \\right) \u0026gt; 0$, it can be written as follows. $$ k_{1} \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) ; \\theta \\right] = {{ f_{Y_{1}} \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) ; \\theta \\right] } \\over { m \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) \\right] }} $$ Substituting the given expression yields $$ \\begin{align*} f \\left( x_{1} ; \\theta \\right) \\cdots f \\left( x_{n} ; \\theta \\right) =\u0026amp; k_{1} \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) ; \\theta \\right] k_{2} \\left( x_{1} , \\cdots , x_{n} \\right) \\\\ =\u0026amp; {{ f_{Y_{1}} \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) ; \\theta \\right] } \\over { m \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) \\right] }} k_{2} \\left( x_{1} , \\cdots , x_{n} \\right) \\\\ =\u0026amp; f_{Y_{1}} \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) ; \\theta \\right] {{ k_{2} \\left( x_{1} , \\cdots , x_{n} \\right) } \\over { m \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) \\right] }} \\end{align*} $$ Since both $k_{2}$ and $m$ do not depend on $\\theta$, by definition, $Y_{1}$ is a sufficient statistic for $\\theta$.\n‚ñ†\n","id":2084,"permalink":"https://freshrimpsushi.github.io/en/posts/2084/","tags":null,"title":"Neumann Factorization Theorem Proof"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Definition 1 $$ g(t) := p(t) + i q(t) \\qquad , t \\in [a,b] $$\nLet\u0026rsquo;s assume for a real function $p, q : [a,b] \\to \\mathbb{R}$, a complex function $g : [a,b] \\to \\mathbb{C}$ is expressed as above. The definite integral from $[a,b]$ to $g$ is defined as follows. $$ \\int_{a}^{b} g(t) dt = \\int_{a}^{b} p(t) dt + i \\int_{a}^{b} q(t) dt $$ For $t \\in [a,b]$, the complex path integral following the path $\\mathscr{C} : z(t) = x(t) + i y(t)$ is defined as: $$ \\int_{\\mathscr{C}} f(z) dz = \\int_{a}^{b} f \\left( z(t) \\right) z\u0026rsquo;(t) dt $$\nDescription While the definition of an arc or curve $\\mathscr{C} : z(t)$ might be important in geometry, it isn\u0026rsquo;t particularly necessary to be exact for complex analysis, so we can somewhat overlook it. Instead of insisting on the explanations below, better to study curves properly in differential geometry and for now, it is sufficient to intuitively grasp the concept for $\\mathscr{C}$.\nIf there is no overlap in $\\mathscr{C}$, meaning the following is satisfied, it is called simple or Jordan. $$ z \\left( t_{1} \\right) = z \\left( t_{2} \\right) \\implies t_{1} = t_{2} \\qquad , \\forall t_{1}, t_{2} \\in [a,b] $$\nIf it\u0026rsquo;s differentiable everywhere and the derivative is not $0$, meaning the following is satisfied, it is considered smooth. $$ \\exists z\u0026rsquo;(t) \\ne 0 \\qquad , \\forall t \\in [a,b] $$\nJoining the ends of a finite number of (simple) smooth arcs results in a (simple) contour. Though translating this as a contour line might not convey the meaning well and in the context of complex analysis, it\u0026rsquo;s commonly used in situations where integrating along the contour in an anticlockwise direction, it could also be simplified as a path for $\\mathscr{C}$.\nWhen moving in the direction of $a \\to b$ if it\u0026rsquo;s $\\mathscr{C}$, then when moving in the direction of $b \\to a$ it\u0026rsquo;s expressed as $-\\mathscr{C}$. With parameters, it is as follows when $\\mathscr{C} : z(t) , a \\le t \\le b$. $$ -\\mathscr{C} : z(-t) , -b \\le t \\le -a $$\nIf only the exact positions of the endpoints are the same, that is, $z(a) = z(b)$ it is called a closed contour.\nLet me emphasize once more. Even if these explanations are not appealing to a good mathematician, skip them. It\u0026rsquo;s much more crucial if you can intuitively accept the following properties.\nBasic Properties Let\u0026rsquo;s say $f,g$ is piecewise continuous in $\\mathscr{C}$.\n[1]: For every $\\alpha , \\beta \\in \\mathbb{C}$ $$ \\int_{\\mathscr{C}} \\left( \\alpha f(z) + \\beta g(z) \\right) dz = \\alpha \\int_{\\mathscr{C}} f(z) dz + \\beta \\int_{\\mathscr{C}} g(z) dz $$ [2]: If the direction of $\\mathscr{C}$ is $a \\to b \\to c$ and consists of $\\mathscr{C}_{1}$ in the direction of $a \\to b$ and $\\mathscr{C}_{2}$ in the direction of $b \\to c$ $$ \\int_{\\mathscr{C}} f(z) dz = \\int_{\\mathscr{C}_{1}} f(z) dz + \\int_{\\mathscr{C}_{2}} f(z) dz $$ [3]: If the direction is reversed, the sign is reversed. $$ \\int_{ - \\mathscr{C}} f(z) dz = - \\int_{\\mathscr{C}} f(z) dz $$ Osborne (1999). Complex variables and their applications: p69~71.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2082,"permalink":"https://freshrimpsushi.github.io/en/posts/2082/","tags":null,"title":"Integration of Complex Functions"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Definition 1 $\\alpha \\in \\mathbb{C}$ being a zero of order $n$ of the function $f : \\mathbb{C} \\to \\mathbb{C}$ means that for some function $g$, where $\\displaystyle \\lim_{z \\to \\alpha} g(z) \\ne 0$, it can be expressed as follows: $$ f(z) = (z-\\alpha)^{n} g(z) $$\nTheorem Zeros are isolated:\nFor a zero $f$, we can take a radius such that no other zeros exist around it. For the zero $\\alpha$ of $f$, there exists a neighborhood $\\mathcal{N} (\\alpha)$ where $z \\in \\mathcal{N} (\\alpha) \\setminus \\left\\{ \\alpha \\right\\}$ to $f (z) \\ne 0$. Proof Without loss of generality, assume that $g$ is analytical at the zero of order $n$ $\\alpha$ of $f$ and let\u0026rsquo;s denote it as $g(\\alpha) = 2 \\beta \\ne 0$.\nSince $g$ is continuous at $\\alpha$, for all $\\beta$, there must exist a $\\delta \u0026gt; 0$ satisfying the following: $$ | z - \\alpha | \u0026lt; \\delta \\implies \\left| g(z) - g(\\alpha) \\right| \u0026lt; |\\beta| $$ Since we previously set as $g(\\alpha) = 2 \\beta$, by the triangle inequality, we have: $$ | z - \\alpha | \u0026lt; \\delta \\implies |g(z)| \\ge \\left| |g(\\alpha)| - \\left| g(z) - g(\\alpha) \\right| \\right| \u0026gt; |\\beta| $$ Since $|z-\\alpha| \u0026lt; \\delta$ leads to $|g(z)| \u0026gt; |\\beta|$, $\\alpha$ cannot be a zero of $g$. Given $f(z) = (z-\\alpha)^{n} g(z)$, specifically within this open ball $B \\left( \\alpha , \\delta \\right)$, only $\\alpha$ becomes the zero of $f$: $$ f(z) \\begin{cases} = 0 \u0026amp; , \\text{if } z = \\alpha \\\\ \\ne 0 \u0026amp; , \\text{if } z \\in B \\left( \\alpha , \\delta \\right) \\setminus \\left\\{ \\alpha \\right\\} \\end{cases} $$\n‚ñ†\nSee Also Zero in Abstract Algebra Osborne (1999). Complex variables and their applications: p66.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2080,"permalink":"https://freshrimpsushi.github.io/en/posts/2080/","tags":null,"title":"Zeros in Complex Analysis"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition If a function $f$ is infinitely differentiable, then $f$ is referred to as a smooth function.\nIf a function $f$ is differentiable and $f^{\\prime}$ is continuous, then $f$ is referred to as a smooth function.\nExplanation $y= \\left| x \\right|$ is sharp in $x=0$, making it impossible to differentiate in $x=0$. Therefore, it is described as smooth when differentiation works well at every point, and the differentiated function is not sharp anymore.\nIn analysis, functional analysis, etc., the term smooth is likely to mean the first definition. Especially when talking about function spaces, a smooth function refers to an element in the $C^{\\infty}$ space.\nOn the other hand, in calculus, geometry, etc., the term smooth is likely to mean the second definition. Here, the function does not necessarily have to be infinitely differentiable, and especially in calculus, being infinitely differentiable is not something that is intended to be defined and handled; thus, being smooth as in $C^{1}$ is considered to be a smooth function. It means the same as \u0026lsquo;continuously differentiable\u0026rsquo;.\n","id":3110,"permalink":"https://freshrimpsushi.github.io/en/posts/3110/","tags":null,"title":"Definition of Smooth Functions"},{"categories":"Ìï®Ïàò","contents":"Definition 1 If a function $\\phi (x,y)$ has a continuous second derivative in the region $\\mathscr{R}$ and is a solution to the Laplace\u0026rsquo;s equation, it is said to be harmonic. In other words, a harmonic function satisfies the following. $$ \\Delta \\phi = \\nabla^{2} \\phi = \\phi_{xx} + \\phi_{yy} = 0 $$ Especially, if a function $u(x,y), v(x,y)$ is harmonic and $u,v$ satisfies the Cauchy-Riemann equations, then $v(x,y)$ is referred to as the harmonic conjugate of $u(x,y)$. $$ \\begin{cases} u_{x} (x,y) = v_{y} (x,y) \\\\ u_{y} (x,y) = -v_{x} (x,y) \\end{cases} $$\nExplanation In a Narrow Sense In a narrow sense, harmonic functions or harmonic waves mean the sine function or cosine function, or their combination, the complex exponential function.\n$$ f(x) = A \\sin kx \\quad \\text{or} \\quad f(x) = e^{ix} = \\cos x + i \\sin x $$\nSpecifically, a time-harmonic function refers to a form in which a variable for time is added, as follows.\n$$ f(x,t) = e^{i(kx-\\omega t)} $$\nIn engineering, it is also called a stationary wave.\nOsborne (1999). Complex variables and their applications: p58~59.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2078,"permalink":"https://freshrimpsushi.github.io/en/posts/2078/","tags":null,"title":"Harmonic Function"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Buildup Let\u0026rsquo;s say a multivariable function $f = \\mathbb{R}^{n} \\to \\mathbb{R}$ is given. When trying to calculate the derivative of $f$, unlike the case with a univariable function, one must consider the rate of change in \u0026lsquo;which direction\u0026rsquo;. A familiar example is the partial derivative. The partial derivative considers the rate of change with respect to only one variable. For instance, the partial derivative $\\dfrac{\\partial f}{\\partial y}$ of $f=f(x,y,z)$ with respect to the variable $y$ takes into account the change in the function value of $f$ only in the direction of $(0,1,0)$.\nThe directional derivative is a concept meant to think about the rate of change towards any given direction, rather than in the directions of each variable separately.\nDefinition1 Let\u0026rsquo;s assume a multivariable function $f = \\mathbb{R}^{n} \\to \\mathbb{R}$ and a unit vector $\\mathbf{u} \\in \\mathbb{R}^{n}$ are given. If the following limit exists, it is called the directional derivative of $f$ in the direction $\\mathbf{u}$ at $\\mathbf{x}$ and is denoted by $\\nabla_{\\mathbf{u}}f(\\mathbf{x})$.\n$$ \\nabla _{\\mathbf{u}} f(\\mathbf{x}) := \\lim \\limits _{t \\to 0} \\dfrac{f (\\mathbf{x} + t \\mathbf{u}) - f(\\mathbf{x})}{t} $$\nExplanation Partial Differentiation\n$$ \\dfrac{\\partial f}{\\partial x_{i}}(\\mathbf{x}) = \\lim \\limits _{t \\to 0} \\dfrac{f (\\mathbf{x} + t \\mathbf{e}_{i}) - f(\\mathbf{x})}{t} $$\nThe definition of the directional derivative only differs from that of partial differentiation in that the $\\mathbf{e}_{i}$, which signifies the direction of each variable, is replaced by any arbitrary direction $\\mathbf{u}$. By generalizing it this way, one can see that the partial derivative is a special case of the directional derivative.\nThe following notations are used.\n$$ \\nabla _{\\mathbf{u}} f(\\mathbf{x}) = f_{\\mathbf{u}}^{\\prime}(\\mathbf{x}) = D _{\\mathbf{u}} f(\\mathbf{x}) = \\partial_{\\mathbf{u}}f(\\mathbf{x}) = \\dfrac{\\partial f}{\\partial \\mathbf{u}}(\\mathbf{x}) $$\nLet\u0026rsquo;s assume there\u0026rsquo;s a fixed unit vector $\\mathbf{u}$. Then, every time $f$ is given, $\\nabla _{\\mathbf{u}}f$ is determined, which means the vector $\\mathbf{u}$ itself can be considered an operator. Therefore, notations such as $\\mathbf{u}f$ or $\\mathbf{u}[f]$ are also used. Especially in differential geometry, tangent vectors are treated as operators, and it\u0026rsquo;s thought that \u0026ldquo;tangent vector = differentiation\u0026rdquo;. Refer to See Also for more information.\nFrom the theorem introduced below, it can be understood that the directional derivative can be expressed by partial derivatives.\nFurthermore, it can be shown that the value of the directional derivative is greatest when $\\mathbf{u}$ is in the same direction as the gradient $\\nabla f$, hence the direction of $\\nabla f$ is the same as that of the direction in which the rate of change of $f$ is the highest. Thus, it can be considered that the gradient notation does not have a subscript in $\\nabla$ because it is the directional derivative in \u0026rsquo;that highest rate of change direction\u0026rsquo;.\nTheorem The following equation holds between the directional derivative $\\nabla _{\\mathbf{u}} f$ of $f$ and its gradient $\\nabla f$.\n$$ \\nabla _{\\mathbf{u}} f = \\nabla f \\cdot \\mathbf{u} = \\dfrac{\\partial f}{\\partial x_{1}} u_{1} + \\dfrac{\\partial f}{\\partial x_{2}} u_{2} + \\dots + \\dfrac{\\partial f}{\\partial x_{n}} u_{n} $$\nProof Let\u0026rsquo;s say $g (t) = f (\\mathbf{x} + t \\mathbf{u})$. If we find the derivative of $g$, since the derivative of a scalar function is the gradient, by the chain rule,\n$$ g^{\\prime} (t) = f ^{\\prime} (\\mathbf{x} + t \\mathbf{u}) \\cdot \\mathbf{u} = \\nabla f (\\mathbf{x} + t \\mathbf{u}) \\cdot \\mathbf{u} $$\nThen we obtain the following.\n$$ g^{\\prime} (0) = \\nabla f (\\mathbf{x}) \\cdot \\mathbf{u} $$\nFurthermore, by the definition of the directional derivative, the following holds.\n$$ \\nabla _{\\mathbf{u}} f = \\lim \\limits _{t \\to 0} \\dfrac{f (\\mathbf{x} + t \\mathbf{u}) - f(\\mathbf{x})}{t} = \\lim \\limits _{t \\to 0} \\dfrac{ g(t) - g(0)}{t} = g^{\\prime}(0) = \\nabla f (\\mathbf{x}) \\cdot \\mathbf{u} $$\n‚ñ†\nSee Also Directional derivative in differential geometry Tangent vectors in Riemannian geometry Walter Rudin, Principles of Mathmatical Analysis (3rd Edition, 1976), p216-218\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3109,"permalink":"https://freshrimpsushi.github.io/en/posts/3109/","tags":null,"title":"Definition of Directional Derivative"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code using CSV, DataFrames\rA = rand(1:10, 10)\rB = zeros(10)\rAB = DataFrame(hcat(A,B), [\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;])\rCSV.write(\u0026#34;AB.csv\u0026#34;, AB) The write function of the CSV package allows you to easily output a two-dimensional array. A, B are one-dimensional arrays, which are combined using the hcat function to transform into a dataframe.\nExecution Result julia\u0026gt; using CSV, DataFrames\rjulia\u0026gt; A = rand(1:10, 10)\r10-element Array{Int64,1}:\r8\r5\r4\r3\r6\r4\r10\r6\r2\r9\rjulia\u0026gt; B = zeros(10)\r10-element Array{Float64,1}:\r0.0\r0.0\r0.0\r0.0\r0.0\r0.0\r0.0\r0.0\r0.0\r0.0\rjulia\u0026gt; AB = DataFrame(hcat(A,B), [\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;])\r10√ó2 DataFrame\rRow ‚îÇ A B ‚îÇ Float64 Float64\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 8.0 0.0\r2 ‚îÇ 5.0 0.0\r3 ‚îÇ 4.0 0.0\r‚ãÆ ‚îÇ ‚ãÆ ‚ãÆ\r9 ‚îÇ 2.0 0.0\r10 ‚îÇ 9.0 0.0\r5 rows omitted\rjulia\u0026gt; CSV.write(\u0026#34;AB.csv\u0026#34;, AB)\r\u0026#34;AB.csv\u0026#34; Here is the actual csv file that was output.\nSee Also How to fix broken characters when outputting CSV CSV.write(bom = true) Environment OS: Windows julia: v1.6.3 ","id":2073,"permalink":"https://freshrimpsushi.github.io/en/posts/2073/","tags":null,"title":"How to Output a 2D Array to a CSV File in Julia"},{"categories":"Í∏∞ÌïòÌïô","contents":"Formulas 1 If $\\alpha$ is a unit speed curve with $\\kappa (s) \\ne 0$ then $$ \\begin{align*} T^{\\prime}(s) =\u0026amp; \\kappa (s) N(s) \\\\ N^{\\prime}(s) =\u0026amp; - \\kappa (s) T(s) + \\tau (s) B(s) \\\\ B^{\\prime}(s) =\u0026amp; - \\tau (s) N(s) \\end{align*} $$\nDescription In matrix form, it can be expressed as follows. $$ \\begin{bmatrix} T \\\\ N \\\\ B \\end{bmatrix} ^{\\prime} = \\begin{bmatrix} 0 \u0026amp; \\kappa \u0026amp; 0 \\\\ - \\kappa \u0026amp; 0 \u0026amp; \\tau \\\\ 0 \u0026amp; - \\tau \u0026amp; 0 \\end{bmatrix} \\begin{bmatrix} T \\\\ N \\\\ B \\end{bmatrix} $$\nDerivation Lemma: In an $n$-dimensional inner product space $V$, if $E = \\left\\{ e_{1} , \\cdots , e_{n} \\right\\}$ is an orthogonal set, then $E$ forms a basis of $V$, and for all $v \\in V$ $$ v = \\sum_{k=1}^{n} \\left\u0026lt; v , e_{k} \\right\u0026gt; e_{k} $$\nDifferentiation of Inner Products: $$\\left\u0026lt; f, g \\right\u0026gt;^{\\prime} = \\left\u0026lt; f^{\\prime}, g \\right\u0026gt; + \\left\u0026lt; f, g^{\\prime} \\right\u0026gt;$$\nThe Frenet-Serret Frame $\\left\\{ T, N, B \\right\\}$ forms an orthogonal basis of $\\mathbb{R}^{3}$. It is directly derived using the above lemma.\nPart 1. $T^{\\prime}(s) = \\kappa (s) N(s)$\nFrom the definition of the normal vector, since $N(s) = {{ T^{\\prime}(s) } \\over { \\kappa (s) }}$ then $$ T^{\\prime}(s) = \\kappa (s) N(s) $$\nPart 2. $N^{\\prime}(s) = - \\kappa (s) T(s) + \\tau (s) B(s)$\nAccording to the lemma $$ N^{\\prime}(s) = \\left\u0026lt; N^{\\prime} , T \\right\u0026gt; T + \\left\u0026lt; N^{\\prime} , N \\right\u0026gt; N + \\left\u0026lt; N^{\\prime} , B \\right\u0026gt; B $$\nPart 2-1. $\\left\u0026lt; N^{\\prime} , T \\right\u0026gt; = -\\kappa$ Since $\\left\u0026lt; N, T \\right\u0026gt; = 0$, according to Part 1 $$ \\begin{align*} \u0026amp; 0^{\\prime} = \\left\u0026lt; N , T \\right\u0026gt;^{\\prime} = \\left\u0026lt; N^{\\prime} , T \\right\u0026gt; + \\left\u0026lt; N , T^{\\prime} \\right\u0026gt; \\\\ \\implies\u0026amp; \\left\u0026lt; N^{\\prime} , T \\right\u0026gt; = - \\left\u0026lt; N , T^{\\prime} \\right\u0026gt; \\\\ \\implies\u0026amp; \\left\u0026lt; N^{\\prime} , T \\right\u0026gt; = - \\left\u0026lt; N , \\kappa N \\right\u0026gt; = - \\kappa \\left| N^{2} \\right| = - \\kappa \\cdot 1 \\end{align*} $$ Part 2-2. $\\left\u0026lt; N^{\\prime} , N \\right\u0026gt; = 0$ Since $N$ is a unit vector, $\\left| N^{2} \\right| = 1$ and by differentiating both sides $$ \\begin{align*} \u0026amp; 0 = 1^{\\prime} = \\left\u0026lt; N , N \\right\u0026gt;^{\\prime} = 2 \\left\u0026lt; N , N^{\\prime} \\right\u0026gt; \\\\ \\implies\u0026amp; \\left\u0026lt; N , N^{\\prime} \\right\u0026gt; = 0 \\end{align*} $$ Part 2-3. $\\left\u0026lt; N^{\\prime} , B \\right\u0026gt; = \\tau$ Since $\\left\u0026lt; N, B \\right\u0026gt; = 0$, according to the definition of torsion $\\tau (s) := - \\left\u0026lt; B^{\\prime}(s) , N (s) \\right\u0026gt;$ $$ \\begin{align*} \u0026amp; 0^{\\prime} = \\left\u0026lt; N , B \\right\u0026gt;^{\\prime} = \\left\u0026lt; N^{\\prime} , B \\right\u0026gt; + \\left\u0026lt; N , B^{\\prime} \\right\u0026gt; \\\\ \\implies\u0026amp; \\left\u0026lt; N^{\\prime} , B \\right\u0026gt; = - \\left\u0026lt; N , B^{\\prime} \\right\u0026gt; \\\\ \\implies\u0026amp; \\left\u0026lt; N^{\\prime} , T \\right\u0026gt; = \\tau \\end{align*} $$ This leads to the following. $$ N^{\\prime}(s) = - \\kappa (s) T(s) + \\tau (s) B(s) $$\nPart 3. $B^{\\prime}(s) = - \\tau (s) N(s)$\nAccording to the lemma $$ B^{\\prime}(s) = \\left\u0026lt; B^{\\prime} , T \\right\u0026gt; T + \\left\u0026lt; B^{\\prime} , N \\right\u0026gt; N + \\left\u0026lt; B^{\\prime} , B \\right\u0026gt; B $$\nPart 3-1. $\\left\u0026lt; B^{\\prime} , T \\right\u0026gt; = 0$ Since $\\left\u0026lt; T, B \\right\u0026gt; = 0 = \\left\u0026lt; N, B \\right\u0026gt;$, according to Part 1 $$ 0 = \\left\u0026lt; T^{\\prime}, B \\right\u0026gt; + \\left\u0026lt; T, B^{\\prime} \\right\u0026gt; = \\kappa \\left\u0026lt; N, B \\right\u0026gt; + \\left\u0026lt; T, B^{\\prime} \\right\u0026gt; = \\left\u0026lt; T, B^{\\prime} \\right\u0026gt; $$ Part 3-2. $\\left\u0026lt; B^{\\prime} , N \\right\u0026gt; = -\\tau$ According to the definition of torsion and the symmetry of the inner product $$ \\left\u0026lt; B^{\\prime} , N \\right\u0026gt; = \\left\u0026lt; N , B^{\\prime} \\right\u0026gt; = - \\tau $$ Part 3-3. $\\left\u0026lt; B^{\\prime} , B \\right\u0026gt; = 0$ Since $\\alpha$ is assumed to be a unit speed curve, $B = T \\times N$ is also a unit vector. Similarly to Part 2-2 $$ 0 = \\left\u0026lt; B^{\\prime} , B \\right\u0026gt; $$ This leads to the following. $$ B^{\\prime}(s) = - \\tau (s) N(s) $$\n‚ñ†\nCorollaries Lancret\u0026rsquo;s Theorem: For a unit speed curve $\\alpha$ being a helix is equivalent to some constant $c \\in \\mathbb{R}$ for which $\\tau = c \\kappa$. The curvature of the unit speed curve $\\alpha$ being a constant $\\kappa \u0026gt; 0$ and the torsion being $\\tau = 0$ is equivalent to $\\alpha$ being an arc of a circle with radius $\\kappa^{-1}$. $\\alpha$ being a straight line is equivalent to all tangents of $\\alpha$ passing through some point $x_{0} \\in \\mathbb{R}^{3}$. Let\u0026rsquo;s take a unit speed curve $\\alpha$ with $\\kappa \\ne 0$. $\\alpha$ lying on a plane is equivalent to all tangent planes being parallel.\nIf all normal planes of the unit speed curve $\\alpha$ point towards some fixed point $\\mathbf{x}_{0} \\in \\mathbb{R}^{3}$, then $\\alpha$ lies on a sphere. Millman. (1977). Elements of Differential Geometry: p30.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2072,"permalink":"https://freshrimpsushi.github.io/en/posts/2072/","tags":null,"title":"Frenet-Serret Formulas"},{"categories":"ÎèôÏó≠Ìïô","contents":"Definition 1 For a space $X$ and a moment $t \\in T$, an operator $\\varphi^{t}$ is called a Flow. If the set of flows $F := \\left\\{ \\varphi^{t} \\right\\}_{t \\in T}$ satisfies $\\left( F , \\circ \\right)$ with respect to the function composition operation $\\circ$, then the triple $\\left( T, X, \\varphi^{t} \\right)$ is called a Dynamic System. $$ \\begin{align*} \\varphi^{0} =\u0026amp; \\text{id} \\\\ \\varphi^{t+s} =\u0026amp; \\varphi^{t} \\circ \\varphi^{s} \\end{align*} $$\nExplanation It is often said that maps correspond to $T = \\mathbb{Z}$ and differential equations correspond to $T = \\mathbb{R}$. This implies that dynamic systems are not strictly defined by only maps and differential equations.\nMany explain dynamic systems as systems where the State at any moment can be represented by past states, but this is neither rigorous nor particularly intuitive. For understanding the concept without mathematical expressions, it is better to study examples like dynamic systems represented by maps or dynamic systems represented by differential equations. And for those who like mathematical expressions, the above definition should be appealing.\nSee also Dynamic systems represented by maps Dynamic systems represented by differential equations Rigorous definition of dynamic systems Kuznetsov. (1998). Elements of Applied Bifurcation Theory(2nd Edition): p27.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2071,"permalink":"https://freshrimpsushi.github.io/en/posts/2071/","tags":null,"title":"Rigorous Definition of Dynamical Systems"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition 1 Let\u0026rsquo;s say $\\alpha$ is a unit speed curve.\nThe speed $\\kappa (s) := \\left| T^{\\prime}(s) \\right|$ of the tangent $T(s) = \\alpha^{\\prime} (s)$ is called the curvature $\\alpha (s)$. The function obtained by dividing the velocity $T^{\\prime}(s)$ of the tangent of $\\alpha$ by the curvature $\\kappa (s)$, namely, defined as $N$, is referred to as the Normal vector field. $$ N(s) := {{ T^{\\prime}(s) } \\over { \\left| T^{\\prime}(s) \\right| }} = {{ T^{\\prime}(s) } \\over { \\kappa (s) }},\\qquad \\kappa (s) \\ne 0 $$ The Binormal vector field is defined as follows: $$ B(s) := T(s) \\times N(s) $$ The scalar function defined as follows $\\tau$ is called Torsion. $$ \\tau (s) := - \\left\u0026lt; B^{\\prime}(s) , N (s) \\right\u0026gt; $$ The collection of tangent, normal, binormal, curvature, and torsion as defined above is called the Frenet-Serret Apparatus. $$ \\left\\{ T(s), N(s), B(s), \\kappa (s), \\tau (s) \\right\\} $$ Explanation Do not waste time worrying about the differences between speed and velocity in the definitions. If confused, it\u0026rsquo;s better to simply remember it as speed. Especially, the orthogonal set $\\left\\{ T(s), N(s), B(s) \\right\\}$ is called the Frenet-Serret Frame. Although $\\alpha$ is a unit speed curve in the definition, it can be generalized simply. Curvature While those studying the original text may be familiar with the pronunciation \u0026ldquo;curvature,\u0026rdquo; it\u0026rsquo;s more natural to write it as curvature in text.\nIn formulas, curvature simply represents how much the tangent (the direction) changes. The more a curve\u0026rsquo;s direction changes implies how curved it is, thus it\u0026rsquo;s a valid definition. Of course, if $\\kappa (s) = 0$ then the curve is a straight line.\nThe definition in the case of non-unit speed $\\alpha$ is as follows:\n$$ \\begin{equation} \\kappa (t) := \\dfrac{\\left| T^{\\prime}(t) \\right|}{\\left| \\alpha^{\\prime}(t) \\right|} \\end{equation} $$\nNormal As usual, Normal is not translated as \u0026lsquo;regular\u0026rsquo; but rather naturalized as \u0026lsquo;perpendicular\u0026rsquo;. Though it applies to Normal, considering it together with Binormal shows that this might not be the best translation. In the context of geometry, understanding Normal as \u0026lsquo;perpendicular\u0026rsquo; tends to be better for mental health. In this sense, being \u0026lsquo;Normal\u0026rsquo; could be interpreted as being \u0026lsquo;perpendicular\u0026rsquo; to something.\nThe magnitude of the normal vector is always fixed as $1$, and since $\\alpha^{\\prime} = T$, $N$ corresponds to the second derivative of $\\alpha$. Considering that torsion involves up to $B^{\\prime} = T^{\\prime} \\times N + T \\times N^{\\prime}$, it can be seen that to deal with the Frenet-Serret Apparatus, $\\alpha$ must be differentiable at least three times.\nIt\u0026rsquo;s also referred to as the Principle Unit Normal Vector.\nBinormal Binormal is naturalized as \u0026lsquo;Secondary Normal,\u0026rsquo; suggested by the name that it follows the normal. Following the interpretation of \u0026rsquo;normal\u0026rsquo; mentioned above, Bi (2, two) attached to Binormal gives the sense of \u0026lsquo;being perpendicular to both the tangent and normal\u0026rsquo;.\nThis becomes clearer with formulations. The very definition of Binormal being the cross product of tangent and normal, from the name alone, it appears to have been decided to be perpendicular to both tangent and normal.\nTorsion Torsion translates directly to \u0026rsquo;twisting\u0026rsquo; and even in Japanese incorporates Â§©Âú∞2 with Hiragana mixed in. Such translations attempt to preserve the meaning of Torsion, all being somewhat unclear, and the term \u0026rsquo;twisting\u0026rsquo; itself isn\u0026rsquo;t quite appropriate as an academic term, so it might be more comfortable to just call it [Torsion] as is.\nIt\u0026rsquo;s not particularly important whether minus $-$ is included; it‚Äôs merely convention.\nLooking at the formula, it\u0026rsquo;s incredibly difficult to understand why torsion is defined this way, and more study is needed to accept this formulaically. For now, it can be understood as \u0026lsquo;defining it this way makes many formulas neat,\u0026rsquo; but this definitely isn\u0026rsquo;t a good attitude when studying geometry. Let\u0026rsquo;s try to intuitively understand it, even if it seems forced.\nFollowing $\\alpha (s)$, the plane that is perpendicular to $B(s)$ is called the Osculating Plane3. If $B$ is constant, that is, always the same, then the osculating plane of the curve $\\alpha$ won\u0026rsquo;t change, hence it will lie within a plane as in $\\mathbb{R}^{3}$.\nMeanwhile, as mentioned earlier, since the speed of the normal vector is always $|N| = \\left| T^{\\prime} / \\left| T^{\\prime} \\right| \\right| = 1$, the magnitude of the torsion $\\tau$ is proportional to the magnitude of $B^{\\prime}$. Considering this with the above osculating plane, the magnitude of the torsion $\\left| - \\left\u0026lt; B^{\\prime}(s) , N (s) \\right\u0026gt; \\right|$ can be seen as a measure of \u0026lsquo;how much the curve attempts to deviate from the osculating plane\u0026rsquo;. As previously mentioned, if $B$ is constant and $B^{\\prime} = 0$, it means the curve has no intention of leaving its (osculating) plane.\nPhysical Meaning4 The curve $\\alpha$ can be seen as a position in physics. $\\alpha^{\\prime}$ is called velocity because $\\alpha$\u0026rsquo;s variable is considered as time, and the function\u0026rsquo;s value as position, in fact, this concept is a mathematical abstraction of the curve in differential geometry. Now, let\u0026rsquo;s assume a body is moving along the curve $\\alpha$. In physics, position is expressed as $\\mathbf{r}$.\n$$ \\alpha (t) = \\mathbf{r}(t) $$\nSince velocity is the derivative of position, $\\mathbf{v} = \\dfrac{d \\mathbf{r}}{dt} = \\dfrac{d \\alpha}{d t}$ is obtained. By the definition of tangent, $T = \\dfrac{\\alpha^{\\prime}}{\\left| \\alpha^{\\prime} \\right|} = \\dfrac{\\mathbf{v}}{v}$ is obtained.\n$$ \\mathbf{v} = v T $$\nNow, let\u0026rsquo;s differentiate both sides by $t$. The derivative of velocity is acceleration, so\n$$ \\mathbf{a} = \\dfrac{d \\mathbf{v}}{dt} = v^{\\prime} T + v T^{\\prime} $$\nBy $(1)$, we obtain the following:\n$$ \\kappa = \\dfrac{\\left| T^{\\prime} \\right|}{\\left| \\mathbf{r}^{\\prime} \\right|} = \\dfrac{\\left| T^{\\prime} \\right|}{v} \\implies \\left| T^{\\prime} \\right| = v\\kappa $$\nBy the definition of the normal, we obtain the following:\n$$ N = \\dfrac{T^{\\prime}}{\\left| T^{\\prime} \\right|} = \\dfrac{T^{\\prime}}{v\\kappa} \\implies T^{\\prime} = v\\kappa N $$\nTherefore, acceleration can be expressed as follows:\n$$ \\mathbf{a} = v^{\\prime}T + v^{2}\\kappa N $$\nThis shows that acceleration is a vector in the Osculating Plane and is represented as a linear combination of $T$ and $N$.\nMillman. (1977). Elements of Differential Geometry: p24~26.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://ja.wikipedia.org/wiki/Êç©„Çå_(‰ª£Êï∞Â≠¶)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMillman. (1977). Elements of Differential Geometry: p31.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJames Stewart, Calculus (5th Edition), p874-875\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2070,"permalink":"https://freshrimpsushi.github.io/en/posts/2070/","tags":null,"title":"Frenet-Serret Formulas: Curvature, Tangent, Normal, Binormal, Torsion"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition Let there be a given regular curve $\\alpha (t)$.\nThe vector field $\\displaystyle T(t) := {{ d \\alpha / d t } \\over { \\left| d \\alpha / d t \\right| }}$ is called the Tangent Vector Field. The line $l$ defined as follows in $t = t_{0}$ to $\\alpha$ is called the Tangent Line. $$ l := \\left\\{ \\mathbf{w} \\in \\mathbb{R}^{3} : \\mathbf{w} = \\alpha \\left( t_{0} \\right) + \\lambda T \\left( t_{0} \\right) , \\lambda \\in \\mathbb{R} \\right\\} $$ Explanation The tangent vector field is an extremely important vector function in differential geometry, considering the direction of the tangent to the regular curve while standardizing its magnitude to $1$. It represents only the direction regardless of how sharply the curve bends.\n","id":2066,"permalink":"https://freshrimpsushi.github.io/en/posts/2066/","tags":null,"title":"Tangent Lines and Tangent Vector Fields"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, Unicode (UTF-8) is allowed for variable names. Therefore, you can use not only Greek letters but also superscripts, subscripts, and even Korean or emojis. There\u0026rsquo;s no particular need to use them, but odd codes like the following work fine.\njulia\u0026gt; Œ±‚ÇÅ = 2\r2\rjulia\u0026gt; Œ±‚ÇÇ = 1\r1\rjulia\u0026gt; println(Œ±‚ÇÅ \\ast\\ Œ±‚ÇÇ)\r2\rjulia\u0026gt; ÏÇ¨Ïù∏(t) = sin(t)\rÏÇ¨Ïù∏ (generic function with 1 method)\rjulia\u0026gt; üòÇ = 1:20\r1:20\rjulia\u0026gt; ÏÇ¨Ïù∏.(üòÇ)\r20-element Array{Float64,1}:\r0.8414709848078965\r0.9092974268256817\r‚ãÆ\r0.14987720966295234\r0.9129452507276277 Greek Letters You can use all the Greek letters used in tex like the example above.\nSuperscripts, Subscripts Superscripts and subscripts can be used by typing numbers after \\_, \\^. They‚Äôre too small to use frequently, but Greek letters, English, or parentheses can also be used.\nEmoji Emojis can be entered like in other editors by pressing window + . (cmd + comma).\n","id":2065,"permalink":"https://freshrimpsushi.github.io/en/posts/2065/","tags":null,"title":"Writing Greek Characters and Subscripts in Julia Variable Names"},{"categories":"Ìï®Ïàò","contents":"Definition The inverse function of an exponential function is defined as the logarithmic function $\\log : (0,\\infty) \\to \\mathbb{R}$. If for all $x \\in (0,\\infty)$, $x = e^y$ then the logarithmic function is represented as: $$ \\log x := y(x) $$\n","id":2063,"permalink":"https://freshrimpsushi.github.io/en/posts/2063/","tags":null,"title":"Definition of Logarithmic Functions"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definitions 1 The mapping $\\alpha : (a,b) \\to \\mathbb{R}^{3}$ is referred to as a Curve. A point $t = t_{0}$ at the curve where $\\alpha^{\\prime} = \\dfrac{d \\alpha}{d t} = \\mathbf{0}$ is called a Singular Point. A curve $\\alpha \\in C^{k}$ for some $k \\in \\mathbb{N}$ where at all $t \\in (a,b)$, $\\displaystyle {{ d \\alpha } \\over { d t }} \\ne \\mathbf{0}$ is known as a Regular Curve. In other words, a regular curve is one without singular points. The derivative $\\alpha^{\\prime}(t_{0})$ of curve $\\alpha$ at $t=t_{0}$, when $t = t_{0}$, is called the velocity vector of $\\alpha$, and the derivative $\\alpha^{\\prime}$ of $\\alpha$ is referred to as the velocity vector field of $\\alpha$. Therefore, a regular curve is a curve whose velocity does not become $\\mathbf{0}$, which means, physically, that its direction of motion never reverses. The magnitude $\\left|\\alpha^{\\prime}(t_{0}) \\right|$ of the velocity of $\\alpha$ at $t = t_{0}$ is called speed. A curve with $\\left| \\alpha^{\\prime} \\right| = 1$ is called a Unit Speed Curve. $C^{k}$ is $k$ times differentiable and its derivative is a set of continuous functions. Explanation $$ \\alpha (t) := \\left( \\alpha_{1} (t) , \\alpha_{2} (t) , \\alpha_{3} (t) \\right) $$\nIn geometry, the object of interest is the figure, and note that in the definition, this figure has been represented as a function of the parameter $t$. This has allowed us to utilize many mathematical tools to study figures, especially in differential geometry where calculus is extensively used.\nA singular point is simply a point that is bent or has come to a stop. Depending on the perspective, a bent point can have two directions. Such points are difficult to handle and are not dealt with in undergraduate differential geometry. A \u0026lsquo;stopping point\u0026rsquo; is explained with an example.\nFor some $k \\in \\mathbb{N}$, that $\\alpha \\in C^{k}$ implies it is differentiable at least once, and how many times it can be differentiated is not very important. Generally, if it\u0026rsquo;s differentiable at least $k=1$ times, it\u0026rsquo;s simply considered Smooth.\nExample Straight Line $$ l(t) := \\left( t, t, t \\right) $$ According to the definition, there\u0026rsquo;s no reason why the straight line $l : \\mathbb{R} \\to \\mathbb{R}^{3}$ shouldn\u0026rsquo;t be considered a curve. In Korean, because the character for curve ÍµΩÏùÑ Í≥°Êõ≤ has the implication of bending, it may cause confusion, so it might be better to just read it according to its English pronunciation, curve.\nHelix $$ \\zeta (t) := \\left( \\cos t , \\sin t , t \\right) $$\nAccording to $0 \\to t \\to \\infty$, a helix is drawn as follows.\nIrregular Curve $$ \\beta (t) := \\left( t^{2} , t^{3} , t^{4} \\right) $$ If the above curve $\\beta$ is differentiated, then $$ \\beta^{\\prime} (t) := \\left( 2t , 3t^{2} , 4t^{3} \\right) $$ thus at $t = 0$, $\\displaystyle {{ d \\beta } \\over { d t }} (0) = \\mathbf{0}$ occurs. This singular point is not bent but literally comes to a stop following $t$ at $t=0$. Therefore, if the domain of $\\beta$ is $\\mathbb{R}$, it\u0026rsquo;s not a regular curve. However, if its domain does not include $0$, for example, $(0,\\infty)$, then it is a regular curve. Note that curves can be regular or not, depending on their domain.\nCode The following is the code to create the gif seen in the Helix example with Julia.\nusing Plots\rŒ∂(t) = (cos(t), sin(t), t)\ranim = @animate for T ‚àà 0.1:0.1:10\rt = 0:0.1:(T*œÄ)\rhelix = plot(Œ∂.(t), camera = (45,45), legend = :none)\rxlims!(-2,2); ylims!(-2,2); zlims!(0,40)\rend\rgif(anim, \u0026#34;helix.gif\u0026#34;) Millman. (1977). Elements of Differential Geometry: p15.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2062,"permalink":"https://freshrimpsushi.github.io/en/posts/2062/","tags":["Ï§ÑÎ¶¨ÏïÑ"],"title":"Definition of a Curve"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 Let\u0026rsquo;s say we have a partial differential equation defined on an open set $\\Omega=\\mathbb{R}^{n}$. When the time is $t=0$, the value of the unknown $u$ at $\\Omega$, that is, the initial value, is given. The problem of finding solutions to such partial differential equations is called the Cauchy problem or the initial value problem.\nExplanation The acronym IVP is commonly used.\nExample Solving the Cauchy problem for the heat equation means finding the solution under the following condition:\n$$ \\left\\{ \\begin{align*} u_{t} -\\Delta u \u0026amp;= 0 \u0026amp;\u0026amp; \\text{in } \\mathbb{R}^{n} \\times (0,\\infty) \\\\ u \u0026amp;= g \u0026amp;\u0026amp; \\text{on } \\mathbb{R}^{n} \\times \\left\\{ t=0 \\right\\} \\end{align*} \\right. $$\nSee Also Boundary Value Problem (BVP) Lawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p57\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3093,"permalink":"https://freshrimpsushi.github.io/en/posts/3093/","tags":null,"title":"Cauchy Problem, Initial Value Problem"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definitions Mathematical Definition 1 Let the probability mass/density function of a random sample $X_{1} , \\cdots , X_{n}$ for parameter $\\theta \\in \\Theta$ be $f(x;\\theta)$, and let the probability mass/density function for statistic $Y_{1} := u_{1} \\left( X_{1} , \\cdots , X_{n} \\right)$ be $f_{Y_{1}} \\left( y_{1}; \\theta \\right)$.\nFor $H \\left( x_{1} , \\cdots , x_{n} \\right)$, which does not depend on $\\theta \\in \\Theta$, $$ {{ f \\left( x_{1} ; \\theta \\right) \\cdots f \\left( x_{n} ; \\theta \\right) } \\over { f_{Y_{1}} \\left( u_{1} \\left( x_{1} , \\cdots, x_{n} \\right) ; \\theta \\right) }} = H \\left( x_{1} , \\cdots , x_{n} \\right) $$ then, $Y_{1}$ is called a Sufficient Statistic for $\\theta$.\nGeneral Definition 2 A statistic $T(\\mathbf{X})$ is called a Sufficient Statistic for parameter $\\theta$ if the conditional probability distribution of the given sample $\\mathbf{X}$ does not depend on $\\theta$.\nExplanation What the definitions mathematically imply is, intuitively, that $\\theta$ cancels out in both numerator and denominator‚Äïmeaning that the sufficient statistic $Y_{1}$ exactly captures the information of the random sample $X_{1} , \\cdots , X_{n}$. The term \u0026lsquo;sufficient\u0026rsquo; indicates that the information about $\\theta$ is \u0026lsquo;sufficiently\u0026rsquo; provided, and after removing the sufficient statistic, no information about $\\theta$ should remain.\nTo understand the concept of a sufficient statistic, let us refer to the following theorem.\nNeyman Factorization Theorem: Let a random sample $X_{1} , \\cdots , X_{n}$ have the same probability mass/density function $f \\left( x ; \\theta \\right)$ with respect to parameter $\\theta \\in \\Theta$. A statistic $Y = u_{1} \\left( X_{1} , \\cdots , X_{n} \\right)$ is a Sufficient Statistic for $\\theta$ if there exist two non-negative functions $k_{1} , k_{2} \\ge 0$ satisfying: $$ f \\left( x_{1} ; \\theta \\right) \\cdots f \\left( x_{n} ; \\theta \\right) = k_{1} \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) ; \\theta \\right] k_{2} \\left( x_{1} , \\cdots , x_{n} \\right) $$ Note, $k_{2}$ must not depend on $\\theta$.\nUnintuitive Example $$ X_{1} , \\cdots , X_{n} \\sim N \\left( \\mu , \\sigma^{2} \\right) $$\nEmpirically, understanding sufficient statistics usually begins from grasping why such things are calculated in the first place. A classic unintuitive example is the sufficient statistic for the population mean $\\mu$ of a normal distribution $N \\left( \\mu , \\sigma^{2} \\right)$. According to the factorization theorem, the sufficient statistic for $\\mu$ is $$ \\begin{align*} \\prod_{k=1}^{n} f \\left( x_{k} ; \\mu \\right) =\u0026amp; \\prod_{k=1}^{n} {{ 1 } \\over { \\sigma \\sqrt{2 \\pi} }} \\exp \\left( - {{ \\left( x_{i} - \\mu \\right)^{2} } \\over { 2 \\sigma^{2} }} \\right) \\\\ =\u0026amp; \\left( {{ 1 } \\over { \\sigma \\sqrt{2 \\pi} }} \\right)^{n} \\exp \\left( - \\sum_{k=1}^{n} {{ \\left( x_{i} - \\mu \\right)^{2} } \\over { 2 \\sigma^{2} }} \\right) \\\\ =\u0026amp; \\left( {{ 1 } \\over { \\sigma \\sqrt{2 \\pi} }} \\right)^{n} \\exp \\left( - \\sum_{k=1}^{n} {{ x_{i}^{2} } \\over { 2 \\sigma^{2} }} \\right) \\exp \\left( - \\sum_{k=1}^{n} {{ \\left( 2 x_{i} - \\mu^{2} \\right) } \\over { 2 \\sigma^{2} }} \\right) \\\\ =\u0026amp; \\left( {{ 1 } \\over { \\sigma \\sqrt{2 \\pi} }} \\right)^{n} \\exp \\left( - \\sum_{k=1}^{n} {{ x_{i}^{2} } \\over { 2 \\sigma^{2} }} \\right) \\cdot \\exp \\left( - {{ 1 } \\over { \\sigma^{2} }} \\sum_{k=1}^{n} x_{i} + {{ n(\\mu/\\sigma)^{2} } \\over { 2 \\ }} \\right) \\\\ =\u0026amp; k_{2} \\left( x_{1} , \\cdots , x_{n} \\right) \\cdot k_{1} \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) ; \\mu \\right] \\end{align*} $$ whether it is the sum of samples $\\sum_{k=1}^{n} X_{k}$ or the sample mean $\\overline{X}$ obtained by multiplying numerator and denominator by $n$. It\u0026rsquo;s good that, as per our intuition, the sample mean, which is an unbiased estimator, consistent estimator, and maximum likelihood estimator for $\\mu$, emerges. While it makes sense mathematically, it might still feel quite abstract.\nIntuitive Example $$ X_{1} , \\cdots , X_{n} \\sim U (0,\\theta) \\text{ with } f \\left( x ; \\theta \\right) = \\begin{cases} 1 \u0026amp; , \\text{if } x \\in (0,\\theta) \\\\ 0 \u0026amp; , \\text{otherwise} \\end{cases} = {{ 1 } \\over { \\theta }} I_{(0,\\theta)} (x) $$\nConsider, for example, a random sample from a uniform distribution $U(a,b)$ with maximum parameter $\\theta$. If the actual realization is $$ \\begin{bmatrix}2.3 \\\\ 1.2 \\\\ 1.7 \\\\ 0.1 \\\\ 1.1\\end{bmatrix} $$ and no more samples can be obtained, since the true mean of the uniform distribution $U(a,b)$ is ${{ b+a } \\over { 2 }}$, we could consider the following estimator: $$ {{ \\hat{\\theta} + 0 } \\over { 2 }} = {{ \\sum_{k} x_{k} } \\over { n }} \\implies \\hat{\\theta} \\overset{?}{=} {{ 2 \\sum_{k} x_{k} } \\over { n }} $$ It seems like a statistically not too bad guess. In fact, multiplying the calculated sample mean by $2$ gives $2.16$, which seems plausible. However, considering $2.3$ is in the sample, it\u0026rsquo;s impossible for $\\theta = 2.16$. No matter what, $\\theta$ should be at least as big as $2.3$, and intuitively, a rational estimate for $\\theta$ would simply be $\\hat{\\theta} = 2.3$. There\u0026rsquo;s no reason to think it‚Äôs bigger than $2.3$ based on the current sample. Let\u0026rsquo;s now actually find the sufficient statistic.\nProduct of Indicator Functions: $$ \\prod_{i=1}^{n} I_{(-\\infty, \\theta]} \\left( x_{i} \\right) = I_{(-\\infty, \\theta]} \\left( \\max_{i \\in [n]} x_{i} \\right) $$\nGiven this lemma and the factorization theorem, the sufficient statistic for $\\theta$ is $$ \\begin{align*} \\prod_{k=1}^{n} f \\left( x_{k} ; \\mu \\right) =\u0026amp; \\prod_{k=1}^{n} {{ 1 } \\over { \\theta }} I_{(0,\\theta)} \\left( x_{k} \\right) \\\\ = \u0026amp; {{ 1 } \\over { \\theta^{n} }} I_{(0,\\theta)} \\left( \\max x_{k} \\right) \\cdot 1 \\\\ = \u0026amp; k_{1} \\left[ u_{1} \\left( x_{1} , \\cdots , x_{n} \\right) ; \\theta \\right] k_{2} \\left( x_{1} , \\cdots , x_{n} \\right) \\end{align*} $$ thus the maximum value of the sample $\\max_{k} X_{k} = X_{(n)}$ can be sufficient. This simply means when considering information about $\\theta$, other samples are unnecessary, and considering only $\\max_{k} X_{k}$ is \u0026lsquo;sufficient\u0026rsquo;.\nThis idea diverges entirely from the mindset of extracting a lot of data to estimate parameters and approximating them elsewhere. It\u0026rsquo;s statistical inference approached by mathematics and formality against what seems to be mere intuitive speculation, allowing us to enter a deeper world of statistics.\nMinimal Sufficient Statistic In the Intuitive Example, we\u0026rsquo;ve intuitively confirmed that $\\max_{k} X_{k}$ is a sufficient statistic for $\\theta$. It seems there can\u0026rsquo;t be a better sufficient statistic than this, which leads us to the discussion on Minimal Sufficient Statistic.\nHogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p391.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCasella. (2001). Statistical Inference (2nd Edition): p272.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2061,"permalink":"https://freshrimpsushi.github.io/en/posts/2061/","tags":null,"title":"Sufficient Statistic"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 The following partial differential equation is called the wave equation.wave equation.\n$$ u_{tt} - \\Delta u =0 $$\nThis equation assumes the propagation speed of the wave as a constant $1$. If the propagation speed of the wave is denoted as $c$, then the wave equation becomes,\n$$ u_{tt} - c^{2}\\Delta u =0 $$\nIn the case of being nonhomogeneousnonhomogeneous,\n$$ u_{tt} - \\Delta u = f $$\n$U \\subset \\mathbb{R}^{n}$ is an open set $u : \\overline{U}\\times [0, \\infty) \\to \\mathbb{R}$ $t\u0026gt;0$ $x = (x_{1}, x_{2}, \\dots, x_{n}) \\in U$ $u=u(x, t)=u(x_{1}, \\dots, x_{n}, t)$ $\\Delta$ is a Laplacian $f:U \\times [0, \\infty) \\to \\mathbb{R}$ Description If the second order derivative with respect to time is replaced with terms related to position, it becomes the Helmholtz equation.\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p65-66\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3092,"permalink":"https://freshrimpsushi.github.io/en/posts/3092/","tags":null,"title":"Wave Equation"},{"categories":"Ìï®Ïàò","contents":"Overview The Exponential Function is a generalization of exponentiation that appears universally across all branches of mathematics. Although in original exponentiations the base $a \u0026gt; 0$ does not necessarily have to be $a = e$, the existence of the base change formula means that essentially, it doesn‚Äôt matter which base is used. For convenience, when referring to an exponential function, its base is commonly considered as $e$.\nDefinition 1 When $x, y \\in \\mathbb{R}$, for a complex number $z \\in \\mathbb{C}$, $\\exp : \\mathbb{C} \\to \\mathbb{C}$ is defined as follows: $$ \\exp z = e^{z} = e^{x + iy} = e^{x} \\left( \\cos y + i \\sin y \\right) $$\n$e = 2.71828182 \\cdots$ is the Euler\u0026rsquo;s constant. Derivation This has been equally covered in the curriculum, but I‚Äôll describe it with slightly more difficult terminology. For convenience, the base is unified as $e$, and I‚Äôll explain with a review sentiment rather than convincing in detail to the level of high school students.\nNatural Numbers $\\mathbb{N}$ The very foundation of the exponential function, its exponentiation, can naturally be expressed for some natural number $n \\in \\mathbb{N}$ as follows. Here, $n$ used as a superscript to $e$ intuitively represents how many times $e$ has been multiplied. $$ e^{n} = \\overbrace{e \\cdot e \\cdots e}^{n \\text{ Times}} $$ Furthermore, for two natural numbers $n, m \\in \\mathbb{N}$, the following can easily be confirmed: $$ e^{n+m} = e^{n} e^{m} $$\nInteger $\\mathbb{Z}$ According to the Field Axioms, for all real numbers $a \\ne 0$, an inverse element $a^{-1}$ for multiplication must exist. In other words, for all $a = e^{n}$, there exists an $a^{-1}$ that satisfies the following: $$ 1 = a \\cdot a^{-1} = e^{n} \\cdot a^{-1} $$ Intuitively, this corresponds to how many times $e$ is divided. Representing this inverse as $a^{-1} = e^{-n}$, the exponential function is thereby extended to all integers.\nRational Number $\\mathbb{Q}$ Consider $e^{n}$ that satisfies the following for two integers $n,m \\in \\mathbb{Z}$ and $a^{m}$: $$ a^{m} = e^{n} $$ This means that squaring $e$ by $n$ times results in $a^{m}$. Now, if we denote it as $a = e^{ {{ n } \\over { m }} }$, it can be expressed as: $$ a^{m} = \\left( e^{ {{ n } \\over { m }} } \\right)^{m} = \\overbrace{e^{ {{ n } \\over { m }} } \\cdots e^{ {{ n } \\over { m }} }}^{m \\text{ Times}} $$ Thus, it‚Äôs clear that the exponential function extends well to rational numbers.\nReal Number $\\mathbb{R}$ Due to the density of real numbers, there must exist a sequence of rational numbers $\\left\\{ r_{k} \\right\\}_{k=1}^{\\infty}$ that converges to every real number $x \\in \\mathbb{R}$. Accordingly, the exponentiation of $e$ for the real number $x \\in \\mathbb{R}$ is defined as follows: $$ \\exp(x) = e^{x} := \\lim_{k \\to \\infty} e^{r_{k}} $$\nComplex Number $\\mathbb{C}$ Polar Representation of Complex Numbers: A complex number $z \\ne 0$ corresponds to point $P(x,y)$ on the complex plane, and can be Polar Represented through the length of segment $\\overline{OP}$, $r := |z|$, and the counterclockwise angle $\\theta$ made with the $x$ axis as follows: $$ z = r \\left( \\cos \\theta + i \\sin \\theta \\right) $$\nFinally, the extension to complex functions occurs formally as above. From the citation above, $$ r = e^{x} \\\\ e^{iy} = \\cos y + i \\sin y $$ is naturally obtained, and thus it is defined as an exponential function, a type of complex function. $$ \\exp z = e^{z} = e^{x + iy} = e^{x} \\left( \\cos y + i \\sin y \\right) $$\nOsborne (1999). Complex variables and their applications: p24.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2060,"permalink":"https://freshrimpsushi.github.io/en/posts/2060/","tags":null,"title":"Exponential Functions"},{"categories":"Ìï®Ïàò","contents":"Definition 1 A Polynomial of degree $n$ is defined for $n \\in \\mathbb{N}_{0}$ and $\\left\\{ a_{k} \\right\\}_{k=0}^{n} \\subset \\mathbb{C}$ as follows: $$ P(z) := a_{0} + a_{1} z + \\cdots a_{n} z^{n} \\qquad , a_{n} \\ne 0 $$\nExplanation A polynomial function is one of the most basic functions that can be considered in all of mathematics, and it has been proven by the Fundamental Theorem of Algebra that there exactly $n$ roots exist.\nAccording to the definition, a constant function is also a polynomial. A polynomial can be differentiated infinitely many times. It is a continuous function. Abstract Algebra In the notation of abstract algebra, the set of such polynomial functions is denoted as $\\mathbb{C}[x]$. Here, the set of coefficients is not necessarily limited to the complex numbers $\\mathbb{C}$, and if a field $F$ is given, it can be represented as $F [ x ]$.\nThe degree of a polynomial can be infinitely large without any issues. In the case of $n = \\infty$, the set of such polynomials is denoted as $F[[x]]$.\nOsborne (1999). Complex variables and their applications: p24.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2058,"permalink":"https://freshrimpsushi.github.io/en/posts/2058/","tags":null,"title":"Polynomial Function"},{"categories":"Ìï®Ïàò","contents":"Overview Trigonometric functions are functions that associate the angles of a right triangle with their trigonometric ratios.\nDefinition The trigonometric functions sine and cosine $\\sin, \\cos : \\mathbb{R} \\to \\mathbb{R}$ are defined as follows.\n$$ \\sin \\theta := {{ y } \\over { \\sqrt{x^{2} + y^{2}} }} \\\\ \\cos \\theta := {{ x } \\over { \\sqrt{x^{2} + y^{2}} }} $$\nConsequently, secant, cosecant, tangent, and cotangent are defined as follows.\n$$ \\begin{align*} \\tan \\theta \u0026amp;:= {{ \\sin \\theta } \\over { \\cos \\theta }} \\qquad, \\cos \\theta \\ne 0 \\\\ \\cot \\theta \u0026amp;:= {{ \\cos \\theta } \\over { \\sin \\theta }} \\qquad, \\sin \\theta \\ne 0 \\\\ \\sec \\theta \u0026amp;:= {{ 1 } \\over { \\cos \\theta }} \\qquad, \\cos \\theta \\ne 0 \\\\ \\csc \\theta \u0026amp;:= {{ 1 } \\over { \\sin \\theta }} \\qquad, \\sin \\theta \\ne 0 \\end{align*} $$\nExtension to Complex Functions 1 The trigonometric functions sine and cosine $\\sin, \\cos : \\mathbb{C} \\to \\mathbb{C}$ are defined as follows.\n$$ \\sin z := {{ 1 } \\over { i2 }} \\left( e^{iz} - e^{-iz} \\right) \\\\ \\cos z := {{ 1 } \\over { 2 }} \\left( e^{iz} + e^{-iz} \\right) $$\nBasic Properties [1] Trigonometric functions are $2 \\pi$-periodic functions on the real axis. [2] The sine function is an odd function, and the cosine function is an even function. See also The relationship between trigonometric functions and hyperbolic functions in complex analysis The relationship between trigonometric functions and exponential functions in complex analysis Osborne (1999). Complex variables and their applications: p28.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2056,"permalink":"https://freshrimpsushi.github.io/en/posts/2056/","tags":null,"title":"Definition of Trigonometric Functions"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 Let us assume that a partial differential equation is given on an open set $\\Omega$. The following boundary conditions are referred to as Dirichlet boundary conditions. The problem of finding solutions to partial differential equations with Dirichlet boundary conditions is called the Dirichlet problem.\n$$ u = 0 \\quad \\text{on } \\partial \\Omega $$\nExplanation Nonhomogeneous Conditions The following boundary conditions are referred to as nonhomogeneous Dirichlet conditions, although, in many cases, there is no meticulous distinction made between homogeneous and nonhomogeneous.\n$$ u = g \\quad \\text{on } \\partial \\Omega $$\nExample For instance, solving the Dirichlet problem for Poisson\u0026rsquo;s equation involves finding $u$ that satisfies the following.\n$$ \\left\\{ \\begin{align*} -\\Delta u = f \u0026amp; \\quad \\text{in } \\Omega \\\\ u = 0 \u0026amp; \\quad \\text{on }\\partial \\Omega \\end{align*} \\right. $$\nSee Also Boundary value problem Neumann boundary conditions Robin boundary conditions Lawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p311-312\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3087,"permalink":"https://freshrimpsushi.github.io/en/posts/3087/","tags":null,"title":"Dirichlet Boundary Conditions"},{"categories":"Ìï®Ïàò","contents":"Definition A function defined as $f$ is called the absolute value function, and its values are denoted as shown in $|x|$.\n$$ |x| := f(x) = \\begin{cases} x \u0026amp;\\text{if } x\u0026gt;0 \\\\ 0 \u0026amp;\\text{if } x=0 \\\\ -x \u0026amp;\\text{if } x\u0026lt;0 \\end{cases},\\quad x\\in \\mathbb{R} $$\nExplanation Absolute value refers to the magnitude of a real number, and a generalization of this is the norm. The triangle inequality holds.\n$$ |x + y| \\le |x| + |y|,\\quad x \\in \\mathbb{R} $$\n","id":3083,"permalink":"https://freshrimpsushi.github.io/en/posts/3083/","tags":null,"title":"Absolute Value Function"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Buildup[^1] Recall the definition of the derivative of a univariate function.\n$$ \\lim \\limits_{h\\to 0} \\dfrac{f(x+h) - f(x)}{h} = f^{\\prime}(x) $$\nBy approximating the numerator on the left-hand side as a linear function of $h$, we get the following.\n$$ \\begin{equation} f(x+h) - f(x) = a h + r(h) \\label{1} \\end{equation} $$\nLet\u0026rsquo;s call $r(h)$ the remainder, satisfying the condition below.\n$$ \\lim \\limits_{h \\to 0} \\dfrac{r(h)}{h}=0 $$\nThen, dividing both sides of $\\eqref{1}$ by $h$ and taking the limit $\\lim_{h\\to 0}$, we get the following.\n$$ \\lim \\limits_{h\\to 0} \\dfrac{f(x+h) - f(x)}{h} = \\lim \\limits_{h\\to 0} \\dfrac{ah+ r(h)}{h} = a + \\lim \\limits_{h\\to 0} \\dfrac{r(h)}{h} = a $$\nHere, $a$ was the coefficient of the first-order term in the linear approximation of $h$. In this sense, $a$ is referred to as the derivative \u0026ldquo;coefficient\u0026rdquo; of $f$ at $x$. By slightly transforming the above equation, we can see that the derivative coefficient of $f$ at $x$ satisfies the equation for $a$.\n$$ \\lim \\limits_{h\\to 0} \\dfrac{f(x+h) - f(x) - ah}{h} = \\lim \\limits_{h\\to 0} \\dfrac{r(h)}{h} = 0 $$\nThis forms the basis for defining the derivative of a multivariable vector function.\nDefinition Let\u0026rsquo;s denote $E\\subset \\mathbb{R}^{n}$ as an open set, and $\\mathbf{x}\\in E$ accordingly. For $\\mathbf{f} : E \\to \\mathbb{R}^{m}$, if there exists a linear transformation $A\\in L(\\mathbb{R}^{n}, \\mathbb{R}^{m})$ for $\\mathbf{h} \\in \\mathbb{R}^{n}$ that satisfies the following, then $f$ is differentiable at $\\mathbf{x}$. Furthermore, $A$ is called the total derivative or simply the derivative of $f$ and is denoted by $\\mathbf{f}^{\\prime}(\\mathbf{x})$.\n$$ \\begin{equation} \\lim \\limits_{|\\mathbf{h}| \\to 0} \\dfrac{| \\mathbf{f} ( \\mathbf{x} + \\mathbf{h}) - \\mathbf{f} (\\mathbf{x}) - A( \\mathbf{h} )|}{|\\mathbf{h}|} = 0 \\label{2} \\end{equation} $$\nIf $\\mathbf{f}$ is differentiable at all points in $E$, then $\\mathbf{f}$ is said to be differentiable in $E$.\nExplanation The term \u0026ldquo;total\u0026rdquo; implies entirety, contrasting with partial derivatives. It\u0026rsquo;s not the total $\\check{}$ function, but the total $\\check{}$ derivative.\nIt is important to note that $\\mathbf{f}^{\\prime}(\\mathbf{x})$ is not a function value but a linear transformation satisfying $\\mathbf{f}^{\\prime}(\\mathbf{x}) : E \\subset \\R^{n} \\to \\R^{m}$. Therefore, $\\mathbf{f}^{\\prime}(\\mathbf{x}) = A$ can be represented as a matrix as follows.\n$$ \\mathbf{f}^{\\prime}(\\mathbf{x}) = A = \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\end{bmatrix} $$\nThen, the total derivative of $\\mathbf{f}$, $\\mathbf{f}^{\\prime}$, can be seen as a function mapping a certain matrix $A$ every time $\\mathbf{x} \\in E \\subset \\R^{n}$ is provided. This matrix can be easily obtained from the partial derivatives of $\\mathbf{f}$ and is also known as the Jacobian matrix.\n$$ \\mathbf{f}^{\\prime}(\\mathbf{x}) = \\begin{bmatrix} (D_{1}f_{1}) (\\mathbf{x}) \u0026amp; (D_{2}f_{1}) (\\mathbf{x}) \u0026amp; \\cdots \u0026amp; (D_{n}f_{1}) (\\mathbf{x}) \\\\ (D_{1}f_{2}) (\\mathbf{x}) \u0026amp; (D_{2}f_{2}) (\\mathbf{x}) \u0026amp; \\cdots \u0026amp; (D_{n}f_{2}) (\\mathbf{x}) \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ (D_{1}f_{m}) (\\mathbf{x}) \u0026amp; (D_{2}f_{m}) (\\mathbf{x}) \u0026amp; \\cdots \u0026amp; (D_{n}f_{m}) (\\mathbf{x}) \\end{bmatrix} $$\nThe total derivative is the ultimate generalization of differentiation for functions defined on finite dimensions, extending the domain and range of $\\mathbf{f}$ to Banach spaces as the Fr√©chet derivative. The properties that held for univariate functions naturally hold as well.\nUniqueness Chain Rule Theorem Uniqueness Let $E, \\mathbf{x}, \\mathbf{f}$ be as defined in the Definition. If $A_{1}, A_{2}$ satisfies $\\eqref{2}$, then the two linear transformations are equal.\n$$ A_{1} = A_{2} $$\nProof Let\u0026rsquo;s denote $B = A_{1} - A_{2}$. Then, by the triangle inequality, the following holds.\n$$ \\begin{align*} | B( \\mathbf{h} ) | \u0026amp;= \\left| A_{1}(\\mathbf{h}) - A_{2}(\\mathbf{h}) \\right| \\\\ \u0026amp;= | A_{1}(\\mathbf{h}) - \\mathbf{f} (\\mathbf{x} + \\mathbf{h}) - \\mathbf{f} (\\mathbf{x}) + \\mathbf{f} (\\mathbf{x} + \\mathbf{h}) + \\mathbf{f} (\\mathbf{x}) - A_{2}(\\mathbf{h}) | \\\\ \u0026amp;\\le | \\mathbf{f} (\\mathbf{x} + \\mathbf{h}) + \\mathbf{f} (\\mathbf{x}) - A_{1}(\\mathbf{h}) | + | \\mathbf{f} (\\mathbf{x} + \\mathbf{h}) + \\mathbf{f} (\\mathbf{x}) - A_{2}(\\mathbf{h}) | \\end{align*} $$\nThen, for a fixed $\\mathbf{h} \\ne \\mathbf{0}$, the equation below holds.\n$$ \\lim _{t \\to 0} \\dfrac{ | B( t\\mathbf{h} ) |}{| t\\mathbf{h} |} \\le \\lim _{t \\to 0}\\dfrac{ | \\mathbf{f} (\\mathbf{x} + t\\mathbf{h}) + \\mathbf{f} (\\mathbf{x}) - A_{1}(t\\mathbf{h}) |}{| t\\mathbf{h} |} + \\lim _{t \\to 0}\\dfrac{| \\mathbf{f} (\\mathbf{x} + t\\mathbf{h}) + \\mathbf{f} (\\mathbf{x}) - A_{2}(t\\mathbf{h}) |}{| t\\mathbf{h} |}=0 $$\nHowever, since $B$ is a linear transformation, the left-hand side is independent of $t$.\n$$ \\lim _{t \\to 0} \\dfrac{ | tB( \\mathbf{h} ) |}{| t\\mathbf{h} |} = \\lim _{t \\to 0} \\dfrac{ | B( \\mathbf{h} ) |}{| \\mathbf{h} |} = \\dfrac{ | B( \\mathbf{h} ) |}{| \\mathbf{h} |} \\le 0 $$\nSince $\\mathbf{h} \\ne \\mathbf{0}$, for the above equation to hold, it must be $B=0$. Thus, we obtain the following.\n$$ B=A_{1}-A_{2}=0 \\implies A_{1} = A_{2} $$\n‚ñ†\nChain Rule As defined, let\u0026rsquo;s consider $E \\subset \\R^{n}$ as an open set and $\\mathbf{f} : E \\to \\R^{m}$ as a function differentiable in $\\mathbf{x}_{0} \\in E$. Let $\\mathbf{g} : \\mathbf{f}(E) \\to \\R^{k}$ be a function differentiable in $\\mathbf{f}(\\mathbf{x}_{0}) \\in \\mathbf{f}(E)$. Also, let\u0026rsquo;s consider $\\mathbf{F} : E \\to \\R^{k}$ as the composition of $\\mathbf{f}$ and $\\mathbf{g}$.\n$$ \\mathbf{F} (\\mathbf{x}) = \\mathbf{g} \\left( \\mathbf{f}(\\mathbf{x}) \\right) $$\nThen, $\\mathbf{F}$ is differentiable in $\\mathbf{x}_{0}$, and the total derivative is as follows.\n$$ \\mathbf{F}^{\\prime} (\\mathbf{x}_{0}) = \\mathbf{g}^{\\prime} \\left( \\mathbf{f}(\\mathbf{x}_{0}) \\right) \\mathbf{f}^{\\prime} (\\mathbf{x}_{0}) $$\nProof Generalized proof for normed spaces\n‚ñ†\n","id":3082,"permalink":"https://freshrimpsushi.github.io/en/posts/3082/","tags":null,"title":"Partial Derivatives: Derivatives of Multivariable Vector Functions"},{"categories":"Ìï®Ïàò","contents":"Definition A function $f : \\mathbb{R} \\to \\mathbb{R}$ is said to be a $T$-periodic function if it satisfies the following for some constant $T \\ne 0$ and all $t \\in \\mathbb{R}$: ‚ñ∂e\n","id":2050,"permalink":"https://freshrimpsushi.github.io/en/posts/2050/","tags":null,"title":"Periodic Functions"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Definition The divergence of the gradient of the scalar function $u : \\mathbb{R}^{n} \\to \\mathbb{R}$ is called the Laplacian and is denoted as follows.\n$$ \\begin{align*} \\Delta u :\u0026amp;= \\mathrm{div}(\\nabla (u)) \\\\ \u0026amp;= \\mathrm{div} \\left( \\left( u_{x_{1}}, u_{x_{2}}, \\dots, u_{x_{n}} \\right) \\right) \\\\ \u0026amp;= u_{x_{1}x_{1}} + u_{x_{2}x_{2}} + \\cdots + u_{x_{n}x_{n}} \\\\ \u0026amp;= \\sum _{i=1}^{n} u_{x_{i}x_{i}} \\end{align*} $$\nHere, $u_{x_{i}}=\\dfrac{\\partial u}{\\partial x_{i}}$ is.\nExplanation In mathematics, the divergence is often denoted as $\\mathrm{div}$, and the Laplacian is usually denoted as $\\Delta$. However, in physics, the divergence is denoted as $\\nabla \\cdot$, so the notation for the Laplacian mainly uses $\\nabla ^{2}$.\n$$ \\nabla\\cdot( \\nabla (u))=\\nabla^{2}(u) = \\nabla^{2}u $$\nIf $D^{2}$ is called the multi-index notation, it is also equal to the trace of the Hessian matrix.\n$$ \\Delta u = \\sum_{i=1}^{n} u_{x_{i} x_{i}} = \\mathrm{tr} (D^{2}u) $$\n3-dimensional Cartesian coordinate system $$ \\Delta f = \\nabla ^{2} f = \\frac{ \\partial^{2} f}{ \\partial x^{2} }+\\frac{ \\partial^{2} f}{ \\partial y^{2}}+\\frac{ \\partial^{2} f}{ \\partial z^{2}} $$\n","id":3081,"permalink":"https://freshrimpsushi.github.io/en/posts/3081/","tags":null,"title":"Laplacian of a Scalar Field"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let us consider $V, W$ as a finite-dimensional vector space. Let\u0026rsquo;s say $\\beta = \\left\\{ \\mathbf{v}_{1}, \\dots, \\mathbf{v}_{n} \\right\\}$ and $\\gamma = \\left\\{ \\mathbf{w}_{1}, \\dots, \\mathbf{w}_{m} \\right\\}$ are the ordered bases for $V$ and $W$, respectively. Assume $T : V \\to W$ to be a linear transformation. Due to the uniqueness of basis representation, there exist unique scalars $a_{ij}$ that satisfy the following.\n$$ T(\\mathbf{v}_{j}) = \\sum_{i=1}^{m}a_{ij}\\mathbf{w}_{i} = a_{1j}\\mathbf{w}_{1} + \\cdots + a_{mj}\\mathbf{w}_{m} \\quad \\text{ for } 1 \\le j \\le n $$\nHere, the matrix $A$ defined by $A_{ij} = a_{ij}$ is called the matrix representation of $T$ relative to the bases $\\beta$ and $\\gamma$, and it is denoted by $[T]_{\\gamma, \\beta}$ or $[T]_{\\beta}^{\\gamma}$. Hence, the following equation holds.\n$$ [T]_{\\gamma, \\beta} [\\mathbf{x}]_{\\beta} = [T(\\mathbf{x})]_{\\gamma} = [T]_{\\beta}^{\\gamma}[\\mathbf{x}]_{\\beta} $$\nIntuitively, this can be seen as canceling out two adjacent (or duplicated in the subscript) $\\beta$s, and substituting $\\mathbf{x}$ into $T$.\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p80-81\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3078,"permalink":"https://freshrimpsushi.github.io/en/posts/3078/","tags":null,"title":"Matrix Representation of Linear Transformations"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Definition 1 The solution $x = \\sqrt{-1}$ of the quadratic equation $x^{2} +1 = 0$ is called an Imaginary Number. A number in the form of $z = x + iy$ for two real numbers $x,y \\in \\mathbb{R}$ is called a Complex Number, and is also denoted as $(x,y)$. Here, $\\text{Re} (z) = x$ and $\\text{Im} (z) = y$ are called the Real Part and Imaginary Part of $z$, respectively. The set of all complex numbers is denoted by $\\mathbb{C}$. Two complex numbers $z_{1}, z_{2} \\in \\mathbb{C}$ are said to be Equal when their real parts and imaginary parts are respectively equal. $$ \\text{Re} z_{1} = \\text{Re} z_{2} \\\\ \\text{Im} z_{1} = \\text{Im} z_{2} $$ The magnitude of a complex number is called the Modulus and is defined as follows. $$ | z | := \\sqrt{x^{2} + y^{2}} $$ Explanation Note that the imaginary part $\\text{Im} z = y \\in \\mathbb{R}$ is not multiplied by the imaginary unit $i$. In physics and engineering, since $i$ represents current, the imaginary unit is sometimes denoted as $j := \\sqrt{-1}$. In the curriculum, complex numbers are commonly indicated as $1 + 2i$ with $i$ written after the number, but in mathematics-oriented literature, the tendency is strong to denote it as $1 + i2$ with $i$ in front. This indicates the intention to treat $i$ not as a letter but as a number equal to any other, and it can be understood that this notation is practical as it makes the front the real part and the back the imaginary part around $i$. History Historically, the imaginary number was first introduced in Ars Magna, a work by Cardano (a pioneer of probability theory) in 1545. It was not fully accepted in the mathematical community until about the 19th century. Gauss named $i$ as Imaginary Number, the current term, and used it in the proof of the Fundamental Theorem of Algebra. The symbol $i$ itself appears in Euler\u0026rsquo;s memoir of 1777.\nComplex Plane 2 $$ \\mathbb{C} \\ni x + iy = (x,y) \\in \\mathbb{R}^{2} $$\nAs can be guessed from the definition, the set of complex numbers $\\mathbb{C}$ can be seen as, and actually corresponds to, a two-dimensional plane $\\mathbb{R}^{2}$. Literally, $x$ represents the $x$ axis, and $y$ represents the $y$ axis, which will now mean the real axis and imaginary axis, respectively. It is very logical that the modulus of a complex number is defined as $| z | := \\sqrt{x^{2} + y^{2}}$ when considering Pythagoras\u0026rsquo; Theorem.\nField Axioms $$ \\begin{align*} z_{1} + z_{2} =\u0026amp; \\left( \\text{Re} z_{1} + \\text{Re} z_{2} , \\text{Im} z_{1} + \\text{Im} z_{2} \\right) \\\\ z_{1} \\cdot z_{2} =\u0026amp; \\left( \\text{Re} z_{1} \\text{Re} z_{2} - \\text{Im} z_{1} \\text{Im} z_{2} , \\text{Re} z_{1} \\text{Im} z_{2} - \\text{Im} z_{1} \\text{Re} z_{2} \\right) \\end{align*} $$\nIf the binary operations Addition $+: \\mathbb{C}^{2} \\to \\mathbb{C}$ and Multiplication $\\cdot: \\mathbb{C}^{2} \\to \\mathbb{C}$ for two complex numbers $z_{1}, z_{2} \\in \\mathbb{C}$ are defined as above, then $\\mathbb{C}$ algebraically becomes a Field, and $\\mathbb{C}$ is called the Complex Field. Similar to the Real Field in introduction to analysis, all field axioms are satisfied.\nOsborne (1999). Complex variables and their applications: p1~4.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOsborne (1999). Complex variables and their applications: p8~9.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2046,"permalink":"https://freshrimpsushi.github.io/en/posts/2046/","tags":null,"title":"Definition of Complex Numbers"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"This article is written for math majors to understand the principles of the backpropagation algorithm.\nNotation Given an artificial neural network like the one shown above. Let $\\mathbf{x} = (x_{1}, x_{2}, \\dots, x_{n_{0}})$ be the inputinput, $y_{j}^{l}$ be the $j$th node of the $l$th layer, $\\hat{\\mathbf{y}} = (\\hat{y}_{1}, \\hat{y}_{2}, \\dots, \\hat{y}_{\\hat{n}})$ is the output output.\nLet $L \\in \\mathbb{N}$ be the number of hidden layers, and the components of $\\mathbf{n}=(n_{0}, n_{1}, \\dots, n_{L}, \\hat{n}) \\in \\mathbb{N}^{L+2}$ be the number of nodes in the input layer, $L$ hidden layers, and output layer, in that order. Also, for convenience, let the $0$th hidden layer be the input layer and the $L+1$th hidden layer be the output layer.\nLet $w_{ji}^{l}$ denote the weight connecting the $i$th node in the $l$th layer to the $j$th node in the next layer. Propagation from each layer to the next then occurs as shown in the image below.\nwhere $\\phi$ is an arbitrary activation function. Let us denote by $v_{i}^{l}$ the linear combination passed from the $l$th layer to the $j$th node of the next layer.\n$$ \\begin{align*} v_{j}^{l} \u0026amp;= \\sum _{i=1}^{n_{l}} w_{ji}^{l}y_{i}^{l} \\\\ y_{j}^{l+1} \u0026amp;= \\phi ( v_{j}^{l} ) = \\phi \\left( \\sum \\nolimits_{i=1}^{n_{l}} w_{ji}^{l}y_{i}^{l} \\right) \\end{align*} $$\nTo summarize, this looks like this\nSymbols Meaning $\\mathbf{x}=(x_{1}, x_{2}, \\dots, x_{n_{0}})$ input $y^{l}_{j}$ The $j$th node in the $l$th layer $\\hat{\\mathbf{y}} = (\\hat{y}_{1}, \\hat{y}_{2}, \\dots, \\hat{y}_{\\hat{n}} )$ output $n_{l}$ Number of nodes in the $l$th layer $w_{ji}^{l}$ The weight connecting the $i$th node in the $l$th layer to the $j$th node in the next layer. $\\phi$ Activation Functions $v_{j}^{l} = \\sum \\limits _{i=1} ^{n_{l}} w_{ji}^{l}y_{i}^{l}$ Linear Combination $y^{l+1}_{j} = \\phi (v_{j}^{l})$ Propagation from $l$th layer to next layer Theorem Let $E = E(\\hat{\\mathbf{y}})$ be a proper differentiable loss function, then the way to optimize $E$ is to update the weights $w_{ji}^{l}$ at each layer as follows. $$ \\begin{equation} w_{ji}^{l} \\leftarrow w_{ji}^{l} + \\alpha \\delta^{l}_{j} y_{i}^{l} \\label{thm} \\end{equation} $$\nWhere $\\alpha$ is the learning rate and $\\delta_{j}^{l}$ is as follows when $l=L$,\n$$ -\\delta_{j}^{L} = \\phi ^{\\prime} (v_{j}^{L}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{j}} $$\nFor $l \\in \\left\\{ 0,\\dots, L-1 \\right\\}$,\n$$ \\delta_{j}^{l} = \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i=1}^{n_{l}} \\delta_{i}^{l+1} w_{i j}^{l+1} $$\nExplanation Let\u0026rsquo;s look at $(1)$. It says that we rely on the $l$th nodes $y_{j}^{l}$ to update the weights between the $l$th and $l+1$th layers, which makes sense since the output of each layer ultimately determines the output $\\hat{\\mathbf{y}}$. Also, $y_{j}^{l}$ can be viewed as inputs as they propagate from the $l$th to the $l+1$th layer, which is similar to how a linear regression model is trained with LMSLeast Mean Squares.\n$$ \\mathbf{w} \\leftarrow \\mathbf{w} - \\alpha (\\mathbf{w}^{T}\\mathbf{x} - \\mathbf{y}) \\mathbf{x} $$\nThis optimization technique is called a back propagation algorithm because the outputs $y_{j}^{l}$ at each layer are computed from the input layer to the output layer, while the $\\delta_{j}^{l}$ for optimization are computed backwards from the output layer to the input layer as follows.\n$$ \\begin{align*} \\delta_{j}^{L} \u0026amp;= - \\phi ^{\\prime} (v_{j}^{L}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{j}} \\\\ \\delta_{j}^{L-1} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i} \\delta_{j}^{L} w_{ij}^{L} \\\\ \\delta_{j}^{L-2} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\delta_{i}^{L-1} w_{ij}^{L-1} \\\\ \\delta_{j}^{L-3} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-3}) \\sum _{i} \\delta_{i}^{L-2} w_{ij}^{L-2} \\\\ \u0026amp;\\vdots \\\\ \\delta_{j}^{1} \u0026amp;= \\phi ^{\\prime} (v_{j}^{1}) \\sum _{i} \\delta_{i}^{2} w_{ij}^{2} \\\\ \\delta_{j}^{0} \u0026amp;= \\phi ^{\\prime} (v_{j}^{0}) \\sum _{i} \\delta_{i}^{1} w_{ij}^{1} \\end{align*} $$\nProof Let\u0026rsquo;s say we\u0026rsquo;re done computing from the input layer to the output layer. We can modify the weights in such a way that the loss function $E$ decreases, using the gradient descent method.\n$$ \\begin{equation} w_{ji}^{l} \\leftarrow w_{ji}^{l} - \\alpha \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial w_{ji}^{l} } \\label{gradesent} \\end{equation} $$\nSince each $y_{i}^{l}$ is a given value, we can solve for the partial derivative in a computable form. The partial differential on the right hand side is given by the chain rule.\n$$ \\begin{equation} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial w_{ji}^{l}} = \\dfrac{\\partial E(\\hat{\\mathbf{y}}) }{\\partial v_{j}^{l}} \\dfrac{\\partial v_{j}^{l}}{\\partial w_{ji}^{l}} = \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial v_{j}^{l}} y_{i}^{l} \\label{chainrule} \\end{equation} $$\nLetting $-\\delta_{j}^{l}$ be the partial derivative of the right-hand side of $(3)$, we obtain $(1)$ from $(2)$.\n$$ w_{ji}^{l} \\leftarrow w_{ji}^{l} + \\alpha \\delta^{l}_{j} y_{i}^{l} $$\nFind $\\delta_{j}^{l}$ at each floor as follows.\nCase $l = L$\nFor $j \\in \\left\\{ 1, \\dots, \\hat{n} \\right\\}$, the following holds.\n$$ \\begin{equation} -\\delta_{j}^{L} = \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial v_{j}^{L}} = \\dfrac{\\partial E ( \\hat{\\mathbf{y}} ) } {\\partial \\hat{y}_{j}} \\dfrac{d \\hat{y}_{j}}{d v_{j}^{L}} \\label{deltamL} \\end{equation} $$\nSince $\\hat{y}_{j} =\\phi (v_{j}^{L})$, we get\n$$ -\\delta_{j}^{L} (t) =\\phi ^{\\prime} (v_{j}^{L}(t)) \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{j}} $$\n‚ñ†\nCase $l = L-1$\nFor $j \\in \\left\\{ 1, \\dots, n_{L-1} \\right\\}$, we have\n$$ -\\delta_{j}^{L-1} = \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial v_{j}^{L-1}} = \\dfrac{\\partial E ( \\hat{\\mathbf{y}} ) } {\\partial y_{j}^{L}} \\dfrac{d y_{j}^{L}}{d v_{j}^{L-1}} $$\nSince $y_{j}^{L} =\\phi (v_{j}^{L-1})$, we get\n$$ -\\delta_{j}^{L-1} = \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial y_{j}^{L}} \\dfrac{\\partial y_{j}^{L}}{\\partial v_{j}^{L-1}} = \\phi ^{\\prime} (v_{j}^{L-1}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{L}} $$\nThe partial derivative on the right-hand side is computed by the chain rule as follows.\n$$ \\begin{align*} -\\delta_{j}^{L-1} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{L}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{\\partial \\hat{y}_{i}}{\\partial y_{j}^{L}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{d \\hat{y}_{i}}{d v_{i}^{L}} \\dfrac{\\partial v_{i}^{L}}{\\partial y_{j}^{L}} \\end{align*} $$\nHere, by $(4)$ and ${\\color{green}v_{i}^{L}=\\sum_{j}w_{ij}^{L}y_{j}^{L}}$, we get the following.\n$$ \\begin{align} \u0026amp;\u0026amp; -\\delta_{j}^{L-1} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i=1} {\\color{blue}\\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{\\partial \\hat{y}_{i}}{\\partial v_{i}^{L}}} {\\color{green} \\dfrac{d v_{i}^{L}}{d y_{j^{L}}} } \\nonumber \\\\ \u0026amp;\u0026amp; \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i} {\\color{blue} -\\delta_{i}^{L}} {\\color{green} w_{ij}^{L} }\\nonumber \\\\ {}\\nonumber \\\\ \\implies \u0026amp;\u0026amp; \\delta_{j}^{L-1} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i} \\delta_{i}^{L} w_{ij}^{L} \\label{deltajL-1} \\end{align} $$\n‚ñ†\nCase $l = L-2$\nFor $j \\in \\left\\{ 1, \\dots, n_{L-2} \\right\\}$\n$$ -\\delta_{j}^{L-2} = \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial v_{j}^{L-2}} = \\dfrac{\\partial E ( \\hat{\\mathbf{y}} ) } {\\partial y_{j}^{L-1}} \\dfrac{d y_{j}^{L-1}}{d v_{j}^{L-2}} $$\nSince $y_{j}^{L-1} =\\phi (v_{j}^{L-2})$, we get\n$$ -\\delta_{j}^{L-2} = \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial y_{j}^{L-1}} \\dfrac{d y_{j}^{L-1}}{d v_{j}^{L-2}} = \\phi ^{\\prime} (v_{j}^{L-2}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{L-1}} $$\nThe partial derivative on the right-hand side is computed by the chain rule as follows.\n$$ \\begin{align*} -\\delta_{j}^{L-2} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{L-1}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{\\partial \\hat{y}_{i}}{\\partial y_{j}^{L-1}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{d \\hat{y}_{i}}{d v_{i}^{L}} \\dfrac{\\partial v_{i}^{L}}{\\partial y_{j}^{L-1}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{d \\hat{y}_{i}}{d v_{i}^{L}} \\sum _{k} \\dfrac{\\partial v_{i}^{L}}{\\partial y_{k}^{L}} \\dfrac{\\partial y_{k}^{L}}{\\partial y_{j}^{L-1}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{d \\hat{y}_{i}}{d v_{i}^{L}} \\sum _{k} \\dfrac{\\partial v_{i}^{L}}{\\partial y_{k}^{L}} \\dfrac{d y_{k}^{L}}{d v_{k}^{L-1}} \\dfrac{\\partial v_{k}^{L-1}}{\\partial y_{j}^{L-1}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{k} \\sum _{i} {\\color{blue}\\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{d \\hat{y}_{i}}{d v_{i}^{L}}} {\\color{red}\\dfrac{\\partial v_{i}^{L}}{\\partial y_{k}^{L}} } {\\color{green}\\dfrac{d y_{k}^{L}}{d v_{k}^{L-1}}} {\\color{purple}\\dfrac{d v_{k}^{L-1}}{\\partial y_{j}^{L-1}}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{k} \\sum _{i} {\\color{blue} -\\delta_{i}^{L}} {\\color{red} w_{ik}^{L}} {\\color{green} \\phi^{\\prime}(v_{k}^{L-1})} {\\color{purple} w_{kj}^{L-1}} \\end{align*} $$\nSo we get the following\n$$ \\delta_{j}^{L-2} = -\\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{k} \\sum _{i} \\delta_{i}^{L} w_{ik}^{L} \\phi^{\\prime}(v_{k}^{L-1}) w_{kj}^{L-1} $$\nThen, by $(5)$, the following holds.\n$$ \\sum _{i} \\delta_{i}^{L} w_{ik}^{L} \\phi^{\\prime}(v_{k}^{L-1}) = \\phi^{\\prime}(v_{k}^{L-1}) \\sum _{i} \\delta_{i}^{L} w_{ik}^{L} = \\delta_{k}^{L-1} $$\nTHerefore we get the following\n$$ \\begin{align*} \\delta_{j}^{L-2} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{k} \\delta_{k}^{L-1} w_{kj}^{L-1} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\delta_{i}^{L-1} w_{ij}^{L-1} \\end{align*} $$\n‚ñ†\nGeneralization: $l \\in \\left\\{ 1, \\dots, L-1 \\right\\}$\nBased on the above results, we can generalize as follows for $j \\in \\left\\{ 1, \\dots, n_{l} \\right\\}$,\n$$ -\\delta_{j}^{l} = \\phi ^{\\prime} (v_{j}^{l}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{l}} $$\nSolving the partial derivative on the right-hand side by the chain rule is as follows.\n$$ \\begin{align*} \u0026amp;\\quad \\delta_{j}^{l} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{\\partial \\hat{y}_{i_{(1)}}}{\\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(2)}} \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{i_{(2)}}^{L}} \\frac{\\partial y_{i_{(2)}}^{L}}{\\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(2)}} \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{i_{(2)}}^{L}} \\frac{d y_{i_{(2)}}^{L}}{d v_{i_{(2)}}^{L-1}} \\frac{\\partial v_{i_{(2)}}^{L-1}}{\\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(3)}} \\sum_{i_{(2)}} \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{i_{(2)}}^{L}} \\frac{d y_{i_{(2)}}^{L}}{d v_{i_{(2)}}^{L-1}} \\frac{\\partial v_{i_{(2)}}^{L-1}}{\\partial y_{i_{(3)}}^{L-1} } \\frac{\\partial y_{i_{(3)}}^{L-1} }{ \\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(3)}} \\sum_{i_{(2)}} \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{i_{(2)}}^{L}} \\frac{d y_{i_{(2)}}^{L}}{d v_{i_{(2)}}^{L-1}} \\frac{\\partial v_{i_{(2)}}^{L-1}}{\\partial y_{i_{(3)}}^{L-1} } \\frac{d y_{i_{(3)}}^{L-1} }{d v_{i_{(3)}}^{L-2} } \\frac{\\partial v_{i_{(3)}}^{L-2} }{ \\partial y_{j}^{l}} \\\\ \u0026amp; \\quad \\vdots \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(L-l)}} \\cdots \\sum_{i_{(3)}} \\sum_{i_{(2)}} \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{i_{(2)}}^{L}} \\frac{d y_{i_{(2)}}^{L}}{d v_{i_{(2)}}^{L-1}} \\frac{\\partial v_{i_{(2)}}^{L-1}}{\\partial y_{i_{(3)}}^{L-1} } \\frac{d y_{i_{(3)}}^{L-1} }{d v_{i_{(3)}}^{L-2} } \\frac{\\partial v_{i_{(3)}}^{L-2} }{ \\partial y_{i_{(4)}}^{L-2}} \\cdots \\frac{d y_{i_{(L-l+1)}}^{l+1} }{d v_{i_{(L-l+1)}}^{l} } \\frac{\\partial v_{i_{(L-l+1)}}^{l} }{ \\partial y_{j}^{l}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(L-l)}} \\cdots \\sum_{i_{(3)}} \\sum_{i_{(2)}} \\sum_{i_{(1)}} -\\delta_{i_{(1)}}^{L} w_{i_{(1)}i_{(2)}}^{L} \\phi^{\\prime}(v_{i_{(2)}}^{L-1}) w_{i_{(2)} i_{(3)}}^{L-1} \\phi^{\\prime}( v_{i_{(3)}}^{L-2} ) w_{i_{(3)} i_{(4)}}^{L-2} \\cdots \\phi^{\\prime}(v_{L-l+1}^{l})w_{i_{(L-l+1)} j}^{L} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(L-l)}} \\cdots \\sum_{i_{(3)}} \\sum_{i_{(2)}} \\delta_{i_{(2)}}^{L-1}w_{i_{(2)} i_{(3)}}^{L-1} \\phi^{\\prime}( v_{i_{(3)}}^{L-2} ) w_{i_{(3)} i_{(4)}}^{L-2} \\cdots \\phi^{\\prime}(v_{L-l+1}^{l})w_{i_{(L-l+1)} j}^{L} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(L-l)}} \\cdots \\sum_{i_{(3)}} \\delta_{i_{(3)}}^{L-2} w_{i_{(3)} i_{(4)}}^{L-2} \\cdots w_{i_{(L-l)} j}^{L} \\\\ \u0026amp;\\quad \\vdots \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(L-l)}} \\delta_{i_{(L-l)}}^{l+1} w_{i_{(l-l)} j}^{l} \\end{align*} $$\nTherefore to summarize\n$$ \\delta_{j}^{l} = \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i} \\delta_{i}^{l+1} w_{ij}^{l+1} $$\n‚ñ†\n","id":3077,"permalink":"https://freshrimpsushi.github.io/en/posts/3077/","tags":null,"title":"Back Propagation Algorithm"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition 1 Let\u0026rsquo;s assume that a vector space $X$ is given.\nThe set of points satisfying the following equation $L \\subset X$ or $\\alpha (t)$ itself is defined as a Line that passes through point $\\mathbf{x}_{0} \\in X$ and is parallel to vector $\\mathbf{v} \\ne 0$. $$ \\alpha (t) = \\mathbf{x}_{0} + t \\mathbf{v} \\qquad , t \\in \\mathbb{R} $$ The set of points satisfying the following equation $P \\subset X$ is defined as a Plane that passes through point $\\mathbf{x}_{0} \\in X$ and is perpendicular to vector $\\mathbf{n} \\ne 0$. $$ \\left\u0026lt; \\mathbf{x} - \\mathbf{x}_{0} , \\mathbf{n} \\right\u0026gt; = \\mathbf{0} $$ The set of points satisfying the following equation $S \\subset X$ is defined as a Sphere with center $\\mathbf{x}_{0} \\in X$ and Radius $r \u0026gt; 0$. $$ \\left\u0026lt; \\mathbf{x} - \\mathbf{x}_{0} , \\mathbf{x} - \\mathbf{x}_{0} \\right\u0026gt; = r^{2} $$ $\\left\u0026lt; \\cdot , \\cdot \\right\u0026gt;$ is the dot product. Line, Plane, and Sphere all in one LOL Millman. (1977). Elements of Differential Geometry: p8~10.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2042,"permalink":"https://freshrimpsushi.github.io/en/posts/2042/","tags":null,"title":"General Definitions of Lines, Planes, and Spheres"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Given linear transformations $T_{1} : V \\to W$ and $T_{2} : W \\to Z$, the transformation defined by $T_{2} T_{1}$ is called the composition of $T_{1}$ and $T_{2}$.\n$$ (T_{2} \\circ T_{1})(\\mathbf{x}) = T_{2}\\left( T_{1}(\\mathbf{x}) \\right) \\quad \\mathbf{x} \\in V $$\nExplanation The composition of linear transformations is often denoted simply as follows:\n$$ T_{2}T_{1}\\mathbf{x} = (T_{2} \\circ T_{1}) (\\mathbf{x}) $$\nIn finite dimensions, this is essentially the same as matrix multiplication, making it a natural notation.\nProperties1 2 Consider linear transformations $T_{1} : V \\to W$ and $T_{2} : W \\to Z$.\n(a) The composition $T_{2} T_{1}$ of $T_{1}$ and $T_{2}$ is also a linear transformation.\n(b) The following holds for $T, U_{1}, U_{2} \\in \\href{../3283}{L(V)}$ and $a \\in \\mathbb{R}$:\n$$ T(U_{1} + U_{2}) = TU_{1} + TU_{2} \\quad \\text{and} \\quad (U_{1} + U_{2})T = U_{1}T + U_{2}T \\\\[0.5em] T(U_{1}U_{2}) = (T_{1})U_{2} \\\\[0.5em] TI = IT = T \\\\[0.5em] a(U_{1}U_{2}) = (aU_{1})U_{2} = U_{1}(aU_{2}) $$\nIf $T_{1}, T_{2}$ is injective, then the following holds:\n(c) $T_{2} T_{1}$ is injective.\n(d) $(T_{2} T_{1})^{-1} = T_{1}^{-1} T_{2}^{-1}$\n(e) Let $V, W, Z$ be a finite-dimensional vector space, and let $\\alpha, \\beta, \\gamma$ be their ordered bases, respectively. And suppose $T : V \\to W$, $U : W \\to Z$ are linear transformations. Then,\n$$ [UT]_{\\alpha}^{\\gamma} = [U]_{\\beta}^{\\gamma}[T]_{\\alpha}^{\\beta} $$\n$[T]_{\\alpha}^{\\beta}$ is the matrix representation of $T$.\nProof (a) Given $\\mathbf{x}_{1}, \\mathbf{x}_{2} \\in V$ and let $k$ be any constant. Since $T_{1}, T_{2}$ is linear, the following holds:\n$$ \\begin{align*} (T_{2} T_{1})(\\mathbf{x}_{1} + k \\mathbf{x}_{2}) \u0026amp;= T_{2} \\left( T_{1} \\left( \\mathbf{x}_{1} + k \\mathbf{x}_{2} \\right) \\right) \\\\ \u0026amp;= T_{2} \\left( T_{1} ( \\mathbf{x}_{1} ) + k T_{1} ( \\mathbf{x}_{2} ) \\right) \\\\ \u0026amp;= T_{2} \\left( T_{1} ( \\mathbf{x}_{1} ) \\right) + k T_{2}\\left( T_{1} ( \\mathbf{x}_{2} ) \\right) \\\\ \u0026amp;= (T_{2} T_{1}) ( \\mathbf{x}_{1} ) + k (T_{2} T_{1})( \\mathbf{x}_{2} ) \\end{align*} $$\n‚ñ†\n(c) Suppose that $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$ are different vectors in $V$. Since $T_{1}$ is injective, $T_{1}(\\mathbf{x}_{1})$ and $T_{1}(\\mathbf{x}_{2})$ are different vectors. Thus, since $T_{2}$ is also injective, the following two vectors are also different:\n$$ (T_{2} T_{1})(\\mathbf{x}_{1}) = T_{2} \\left( T_{1}(\\mathbf{x}_{1}) \\right) \\quad \\text{and} \\quad (T_{2} T_{1})(\\mathbf{x}_{2}) = T_{2} \\left( T_{1}(\\mathbf{x}_{2}) \\right) $$\nTherefore, $T_{2} T_{1}$ is injective.\n‚ñ†\n(d) Let $\\mathbf{z}$ be the image of $\\mathbf{x} \\in V$ by $T_{2} T_{1}$.\n$$ \\mathbf{z} = (T_{2} T_{1}) ( \\mathbf{x} ) = T_{2} ( T_{1} (\\mathbf{x})) $$\nApplying $T_{2}^{-1}$ to both sides yields:\n$$ T_{2}^{-1}(\\mathbf{z}) = ( T_{2}^{-1} T_{2} T_{1}) ( \\mathbf{x} ) = T_{1} (\\mathbf{x}) $$\nFurther applying $T_{1}^{-1}$ to both sides yields:\n$$ ( T_{1}^{-1} T_{2}^{-1} )(\\mathbf{z}) = ( T_{1}^{-1} T_{1} ) ( \\mathbf{x} ) = \\mathbf{x} $$\nThus, the following is obtained:\n$$ (T_{1}^{-1} T_{2}^{-1}) ( (T_{2} T_{1} )(\\mathbf{x}) ) = \\mathbf{x} $$\n‚ñ†\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p465-468\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p86-89\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3074,"permalink":"https://freshrimpsushi.github.io/en/posts/3074/","tags":null,"title":"Composition of Linear Transformations"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview This section explains the interpolation convenience feature in Julia. Interpolation can be very handy as it allows for writing output statements in an easy and clean manner. Although it is not directly related to numerical analysis interpolation, the term intersects in meaning. For functionalities related to numerical analysis interpolation, refer to the usage of Interpolations.jl.\nCode The usage is quite straightforward. Simply write the variable inside the string with a dollar sign $Î•º Î∂ôÏù¥Î©¥ Î≥ÄÏàòÍ∞Ä ÏïåÏïÑÏÑú Î¨∏ÏûêÏó¥Ï≤òÎüº ÏùΩÌûåÎã§. Î≥ÄÏàò Í∑∏ÎåÄÎ°úÍ∞Ä ÏïÑÎãå Í≥ÑÏÇ∞Ïù¥ ÌïÑÏöîÌïòÎ©¥ Íµ≥Ïù¥ Î∞ñÏóêÏÑú Í≥ÑÏÇ∞Ìï† ÌïÑÏöî ÏóÜÏù¥ $() in front of it.\njulia\u0026gt; x = 12\r12\rjulia\u0026gt; y = -2\r-2\rjulia\u0026gt; println(\u0026#34;value of x, y: ‚ñ∑eq2‚óÅy\u0026#34;)\rvalue of x, y: 12, -2\rjulia\u0026gt; println(\u0026#34;value of x+y: $(x+y)\u0026#34;)\rvalue of x+y: 10 Environment OS: Windows julia: v1.5.0 ","id":2041,"permalink":"https://freshrimpsushi.github.io/en/posts/2041/","tags":null,"title":"How to Conveniently Print Variable Values in Julia, Interpolation"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let $T : V \\to W$ be a linear transformation.\nIf the range $R(T)$ of $T$ is finite-dimensional, the dimension of $R(T)$ is called the rank of $T$, denoted by:\n$$ \\mathrm{rank}(T) := \\dim (R(T)) $$\nIf the null space $N(T)$ of $T$ is finite-dimensional, the dimension of $N(T)$ is called the nullity of $T$, denoted by:\n$$ \\mathrm{nullity}(T) := \\dim\\left( N(T) \\right) $$\nExplanation This is a generalization of the notion of rank, nullity of matrices. In fact, if $V, W$ is finite-dimensional, then $T$ is essentially a matrix, and $N(T)$ is the null space of the matrix $M_{T}$ representing $T$. Since the nullity of a matrix is the dimension of its null space, the following holds:\n$$ \\mathrm{nullity}(T) = \\dim\\left( N(T) \\right) = \\dim (\\mathcal{N}(M_{T})) $$\nGeneralizing the dimension theorem for matrices to linear transformations gives the following theorem.\nTheorem If $T : V \\to W$ is a linear transformation and $V$ is finite-dimensional, the following holds:\n$$ \\mathrm{rank}(T) + \\mathrm{nullity}(T) = \\dim (V) $$\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p455-456\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3072,"permalink":"https://freshrimpsushi.github.io/en/posts/3072/","tags":null,"title":"Rank, Nullity, and Dimension Theorems of Linear Transformations"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let\u0026rsquo;s say $T : V \\to W$ is a linear transformation. The set of elements of $V$ that are mapped to $\\mathbf{0}$ by $T$ is called the kernel or null space, and is denoted as follows.\n$$ \\text{ker}(T) = N(T) := \\left\\{ \\mathbf{v} \\in V : T( \\mathbf{v} ) = \\mathbf{0} \\right\\} $$\nThe set of images under $\\mathbf{v} \\in V$ by $T$ is called the range or image of $T$, and is denoted as follows.\n$$ R(T) := \\left\\{ T(\\mathbf{v}) : \\forall \\mathbf{v} \\in V \\right\\} $$\nExplanation If $T : V \\to W$ is a linear transformation and $V, W$ is finite-dimensional, $T$ is essentially the same as a matrix, and $N(T)$ is the null space of the matrix representing $T$.\nTheorem Let\u0026rsquo;s consider $T : V \\to W$ to be a linear transformation. Then,\n(a) The kernel of $T$ is a subspace of $V$. (b) The range of $T$ is a subspace of $W$. Proof To show that it\u0026rsquo;s a subspace, we need to prove that it\u0026rsquo;s nonempty, and closed under addition and scalar multiplication.\n(a) If $T$ is a linear transformation, then according to $T(\\mathbf{0})=\\mathbf{0}$, $N(T)$ is not empty. Now, let $\\mathbf{v}_{1}, \\mathbf{v}_{2} \\in N(T)$ and consider $k$ to be any scalar. Then, the following holds.\n$$ \\begin{align*} T( \\mathbf{v}_{1} + \\mathbf{v}_{2} ) \u0026amp;= T(\\mathbf{v}_{1}) + T(\\mathbf{v}_{2}) = \\mathbf{0} + \\mathbf{0} = \\mathbf{0} \\\\ T( k\\mathbf{v}_{1}) \u0026amp;= kT(\\mathbf{v}_{1}) = k\\mathbf{0} = \\mathbf{0} \\end{align*} $$\nHence, $N(T)$ is a subspace of $V$.\n‚ñ†\n(b) If $T$ is a linear transformation, then, as per $T(\\mathbf{0})=\\mathbf{0}$, $R(T)$ is not empty. Now, let $\\mathbf{w}_{1}, \\mathbf{w}_{2} \\in R(T)$ and consider $k$ to be any scalar. Then, it suffices to show that there exists $\\mathbf{a}, \\mathbf{b} \\in V$ that satisfies the following.\n$$ T(\\mathbf{a}) = \\mathbf{w}_{1} + \\mathbf{w}_{2} \\quad \\text{and} \\quad T(\\mathbf{b}) = k\\mathbf{w}_{1} $$\nBut the statement $\\mathbf{w}_{1}, \\mathbf{w}_{2} \\in R(T)$ means that there exists $\\mathbf{v}_{1}, \\mathbf{v}_{2} \\in V$ that satisfies the following.\n$$ T(\\mathbf{v}_{1}) = \\mathbf{w}_{1} \\quad \\text{and} \\quad T(\\mathbf{v}_{2}) = \\mathbf{w}_{2} $$\nTherefore, the following equation holds.\n$$ \\begin{align*} \\mathbf{w}_{1} + \\mathbf{w}_{2} \u0026amp;= T(\\mathbf{v}_{1}) + T(\\mathbf{v}_{2}) = T(\\mathbf{v}_{1} + \\mathbf{v}_{2}) = T(\\mathbf{a}) \\\\ k\\mathbf{w}_{1} \u0026amp;= kT(\\mathbf{v}_{1}) = T(k\\mathbf{v}_{1})= T(\\mathbf{b}) \\end{align*} $$\nHence, $R(T)$ is a subspace of $W$.\n‚ñ†\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p455-456\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3071,"permalink":"https://freshrimpsushi.github.io/en/posts/3071/","tags":null,"title":"Linear Transformation: Kernel and Range"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition 1 Let\u0026rsquo;s say $V$ is a vector space. For two vectors $\\mathbb{u}, \\mathbb{v} \\in V$, $\\theta$ is defined as the angle between two vectors if it satisfies the following. $$ \\cos \\theta = {{ \\left\u0026lt; \\mathbb{u}, \\mathbb{v} \\right\u0026gt; } \\over { \\left| \\mathbb{u} \\right| \\left| \\mathbb{v} \\right| }} $$ If two vectors $\\mathbb{u}, \\mathbb{v}$ satisfy $\\left\u0026lt; \\mathbb{u}, \\mathbb{v} \\right\u0026gt; = 0$, then $\\mathbb{u}$ is said to be orthogonal or perpendicular to $\\mathbb{v}$, and is shown as $\\mathbb{u} \\perp \\mathbb{v}$.\n$\\left\u0026lt; \\cdot, \\cdot \\right\u0026gt;$ is the dot product, and $| \\cdot |$ is the length of the vector, which is calculated as $\\left| \\mathbb{u} \\right| := \\sqrt{ \\left\u0026lt; \\mathbb{u}, \\mathbb{u} \\right\u0026gt; }$. Explanation Although not everyone may agree, orthogonal has an abstract nuance and perpendicular has a geometric feel. Basically, it doesn\u0026rsquo;t matter which word you use, just bear in mind that \u0026lsquo;perpendicular\u0026rsquo; is not seriously a minor term as the tex symbol $\\perp$ uses \\perp.\nContrary to considering the dot product as the magnitude of vectors and inner angles in the curriculum, in multidimensional Euclidean space $V = \\mathbb{R}^{n}$, angles are rather thought through dot products. According to this generalized definition, one can think about the \u0026lsquo;difference in direction\u0026rsquo; of two vectors without the need for words like \u0026lsquo;coordinates\u0026rsquo;.\nApplication In applied mathematics, including machine learning, measures like cosine similarity are used based on this. For example, when the frequencies of specific words a, b, c are represented as vectors in two documents A and B, it becomes a measure to understand how similar the two documents are.\nIf the length of document B is overwhelmingly longer than document A, for example, 100 pages to 1000 pages, the frequency of words would naturally be proportional, so a simple frequency comparison would be meaningless. By using cosine similarity, instead of simple counts, one compares the directionality of the two documents, which can lead to more reasonable results.\nMillman. (1977). Elements of Differential Geometry: p3.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2038,"permalink":"https://freshrimpsushi.github.io/en/posts/2038/","tags":null,"title":"Definition of General Angles and Perpendicularity"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide Step 0. Install julia 1.6 or higher\nFrom version 1.6, you can add it to the environment variables during the installation process. Just check the indicated option and install. If using an older version, either install version 1.6 or higher, or follow the instructions below.\nStep 1. Check the Julia installation path\nCheck the installation path of Julia. If you haven\u0026rsquo;t altered anything, it should be stored in the following path.\nC:\\Users\\ÏÇ¨Ïö©ÏûêÎ™Ö\\AppData\\Local\\Programs\\Julia x.x.x\\bin Usually, C:\\Users\\Username\\AppData is a hidden folder, so don\u0026rsquo;t panic if it\u0026rsquo;s not visible.\nCheck if the julia.exe file is present in the said path. Copy the path for use in Step 3.\nStep 2. Edit environment variables\nPress Windows+s or search for \u0026lsquo;Edit the system environment variables\u0026rsquo; in the control panel.\nClick on Environment Variables(N).\nIn the User variables window, find Path and click Edit(E).\nStep 3. Add Julia path\nClick New(N) or the last row, enter the copied path from Step 1 as shown above, and click OK to finish editing the environmental variables.\nStep 4. Reboot\nAfter rebooting, you can confirm that Julia runs by executing the julia command in powershell, etc.\nEnvironment OS: Windows julia: v1.5.2 ","id":2036,"permalink":"https://freshrimpsushi.github.io/en/posts/2036/","tags":null,"title":"Using Julia in Windows CMD and PowerShell"},{"categories":"ÌôïÎ•†Î°†","contents":"Overview Shannon Entropy or Information Entropy is a measure of disorder defined by a probability variable, and can be viewed as a quantification of how uncertain it is in a probability distribution.\nEasy and Complex Definitions Discrete Entropy 1 When the probability mass function of a discrete random variable $X$ is $p(x)$, the entropy of $X$ is represented as follows. $$ H(X) := - \\sum p(x) \\log_{2} p(x) $$\nContinuous Entropy 2 When the value of a continuous random variable $X$ is a probability density function $f(x)$, the entropy of $X$ is represented as follows. $$ H(X) := - \\int_{-\\infty}^{\\infty} f(x) \\log_{2} f(x) dx $$\nHard yet Simple Definitions The expected value $H(X)$ of the Shannon information $I(X)$ for the random variable $X$ is called entropy. $$ H(X) := E(I(X)) $$\nExplanation When the probability mass function of a random variable $X, Y$ is $p, q$, entropy is also expressed as follows. $$ H(X) = H(p) \\\\ H(Y) = H(q) $$\nEntropy is a concept widely used across various fields of science, and no matter how it is defined, its abstract meaning is generally \u0026rsquo;the degree of disorder\u0026rsquo;. While it might seem unrelated to entropy in thermodynamics at first glance, according to Gibbs\u0026rsquo; entropy formulation, $$ S = - k_{B} \\sum_{i} P_{i} \\ln P_{i} $$ its form is strikingly similar, and historically, there is a deep connection. An anecdote says that when Claude Shannon first discovered $H(X)$ and its importance, he consulted John Von Neumann on what to name it, to which Von Neumann replied:\nFor two reasons, $H$ should be called entropy. First, that function has already been called entropy in thermodynamics. Second, because most people don‚Äôt really know what entropy is, so if you use the word \u0026rsquo;entropy\u0026rsquo; in any argument, you will win.\nDisorder Let‚Äôs see how the expected value of information, entropy, naturally represents disorder.\nConsider a Bernoulli distribution with probability $p$. For example, imagine tossing a coin rigged with a probability of $p \\in (0,1)$ for heads. The entropy of the random variable $X$ representing the coin\u0026rsquo;s heads or tails would be exactly calculated as follows. $$ H(X) = - p \\log_{2} p - (1-p) \\log_{2} (1-p) $$ The closer $p$ is to $0$ or $1$, the more uncertainty decreases and disorder increases. If there was a game of guessing heads or tails with a coin with a probability of heads being $90\\% $, one might as well choose heads slightly more favorably without needing to pick tails. Let\u0026rsquo;s actually calculate and see if this matches the intuition. If $p = 1/4$, then $$ \\begin{align*} H(X) =\u0026amp; - {{ 1 } \\over { 4 }} \\log_{2} {{ 1 } \\over { 4 }} - {{ 3 } \\over { 4 }} \\log_{2} {{ 3 } \\over { 4 }} \\\\ =\u0026amp; {{ 1 } \\over { 4 }} \\log_{2} 4 - {{ 3 } \\over { 4 }} \\left( \\log_{2} 3 - \\log_{2} 4 \\right) \\\\ =\u0026amp; {{ 1 } \\over { 2 }} - {{ 3 } \\over { 4 }} \\log_{2} 3 + {{ 3 } \\over { 2 }} \\\\ =\u0026amp; 2 - {{ 3 } \\over { 4 }} \\log_{2} 3 \\end{align*} $$ Calculating this value to a real number would be about $0.81$. Now calculating when $p = 1/2$ reveals $$ \\begin{align*} H(X) =\u0026amp; - {{ 1 } \\over { 2 }} \\log_{2} {{ 1 } \\over { 2 }} - {{ 1 } \\over { 2 }} \\log_{2} {{ 1 } \\over { 2 }} \\\\ =\u0026amp; {{ 1 } \\over { 2 }} + {{ 1 } \\over { 2 }} \\\\ =\u0026amp; 1 \\end{align*} $$ that the entropy is higher than when $p=1/4$. Indeed, this represents the most chaotic and disordered state where it‚Äôs completely unknowable whether heads or tails will come up.\nAs another example, consider a random variable $X$ following a uniform distribution $\\text{Uni}(a,b)$, its entropy can be simply calculated as $$ \\begin{align*} H(X) =\u0026amp; - \\int_{a}^{b} {{ 1 } \\over { b-a }} \\log_{2} {{ 1 } \\over { b-a }} dx \\\\ =\u0026amp; \\log_{2} \\left( b-a \\right) \\end{align*} $$ It has been said that entropy is a measure of disorder, and widening the interval between $b$ and $a$ means it becomes increasingly difficult to closely guess what value $X$ will take, thereby increasing $\\log_{2} (b-a)$ as well. This further examines how naturally entropy serves as a measure of disorderliness.\nLimits of the Easy Definition Anyone reasonably educated should see no difference between the easy and hard definitions. The latter is just more general and covers all that the former states. The reference cited defines discrete entropy for cases where events are finite and does a good job defining continuous entropy but points out a problem when approaching with the concept of limits.\nAbstractly speaking, since Shannon information is a random variable that aligns the original probability distribution per event with its amount of information, it doesn‚Äôt necessarily have to be defined as discrete or continuous, without the need to consider finite, infinite, countable, uncountable, integration ranges, etc. The definition of entropy can be simply arrived at as \u0026rsquo;the expected value of information\u0026rsquo; unless there is a problem with the definition of information itself.\nApplebaum. (2008). Probability and Information(2nd Edition): p108.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nApplebaum. (2008). Probability and Information(2nd Edition): p180.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2035,"permalink":"https://freshrimpsushi.github.io/en/posts/2035/","tags":null,"title":"Shannon Entropy: Entropy Defined by Random Variables"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Overview In subjects that utilize mathematics, the term Regularity Conditions usually refers to conditions that allow for a wide range of applications and make theoretical developments more comfortable. In mathematical statistics, they are as follows.\nAssumptions 1 Consider a random variable $X$ with probability density function $f \\left( x ; \\theta \\right)$ for a parameter $\\theta \\in \\Theta$. The random sample $X_{1} , \\cdots , X_{n}$ drawn iid from the same distribution as $X$ has the same probability density function $f(x ; \\theta)$ and realizations $\\mathbf{x} := \\left( x_{1} , \\cdots , x_{n} \\right)$. The following function $L$ is called the Likelihood Function. $$ L ( \\theta ; \\mathbf{x} ) := \\prod_{k=1}^{n} f \\left( x_{k} ; \\theta \\right) $$ Finally, let\u0026rsquo;s say $\\theta_{0}$ is the true value of $\\theta$.\n(R0): The probability density function $f$ is injective with respect to $\\theta$. In formula, it satisfies the following. $$ \\theta \\ne \\theta\u0026rsquo; \\implies f \\left( x_{k} ; \\theta \\right) \\ne f \\left( x_{k} ; \\theta\u0026rsquo; \\right) $$ (R1): The probability density function $f$ has the same support for all $\\theta$. (R2): The true value $\\theta_{0}$ is an interior point of $\\Omega$. (R3): The probability density function $f$ is twice differentiable with respect to $\\theta$. (R4): The integral $\\int f (x; \\theta) dx$ is twice differentiable with respect to $\\theta$, with the differentiation being interchangeable with the integral sign. (R5): The probability density function $f$ is thrice differentiable with respect to $\\theta$. Moreover, for all $\\theta \\in \\Theta$, there exists constants $c\u0026gt; 0$ and a function $M(x)$ satisfying $E_{\\theta_{0}} \\left[ M ( X ) \\right] \u0026lt; \\infty$ and the following. $$ \\left| {{ \\partial^{3} } \\over { \\partial \\theta ^{3} }} \\log f (x ; \\theta) \\right| \\le M (x) \\qquad , \\forall x \\in \\mathcal{S}_{X} , \\forall \\theta \\in \\left( \\theta_{0} - c , \\theta_{0} + c \\right) $$ Hogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p328, 334.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2029,"permalink":"https://freshrimpsushi.github.io/en/posts/2029/","tags":null,"title":"Regularity Conditions in Mathematical Statistics"},{"categories":"ÏµúÏ†ÅÌôîÏù¥Î°†","contents":"Simple Definitions Maximum and Minimum collectively are called the Optimum.\nIn the set $X$, the largest element is denoted as the maximum $\\max X$, and the smallest element as the minimum $\\min X$. For the function $f : X \\to \\mathbb{R}$, the largest function value is denoted as $\\max_{X} f$, and the smallest function value as $\\min_{X} f$. $\\mathbb{R}$ denotes the entire set of real numbers. Maximum and Minimum are Sino-Korean words, and value is a native Korean word. As of 2021, the correct terms are actually ÏµúÎåìÍ∞í for maximum and ÏµúÏÜüÍ∞í for minimum, but these are not very search engine friendly, so the \u0026lsquo;„ÖÖ\u0026rsquo; is omitted. Similarly, using ÂÄ§ (value) character to write ÏµúÎåÄÏπò, ÏµúÏÜåÏπò is also fine, but the most familiar terms have been chosen based on current language habits. Explanation From mathematicians\u0026rsquo; perspective, whether searching for something large or small does not really matter. Especially in optimization problems, when explaining algorithms in general, it\u0026rsquo;s simply referred to as optimization, without distinguishing between maximizing or minimizing.\nThe plural form of Maximum is Maxima, Minimum is Minima, and Optimum is Optima. It does not make sense to have multiple optimum values, hence these expressions should be understood as optimum points, not values, in context.\nOptimum value, in contrast with the extreme value, can be considered in the context of optimization problems as the global optimum, whereas the extreme value can be regarded as the local optimum. Usually, the term global is insignificant in this context.\nWhen the value and the set itself are not important in context, the expressions of set, element, and function can be arbitrary, so one must pay close attention.\nThe significance of this post is actually in defining the familiar terms of maximum and minimum in an unambiguous form of functions. If one can intuitively agree with the simple definition above, let\u0026rsquo;s also look at the complex definitions below.\nComplex Definitions Optimum of a Set Let us assume a totally ordered set $\\left( Y, \\le \\right)$ is given.\n$\\max, \\min : 2^{Y} \\to Y$ is a function that corresponds to the smallest or the largest element $y_{\\ast} \\in B$ of each subset $A \\in 2^{Y}$ of $Y$. $$ \\max : B \\mapsto y_{\\ast} \\ge b \\qquad , \\forall b \\in B \\\\ \\min : B \\mapsto y_{\\ast} \\le b \\qquad , \\forall b \\in B $$\nOptimum of a Function Given a set $X$ as the domain and $Y$ as the codomain of a set of functions $Y^{X}$.\nFor $A \\subset X$, $\\max_{A}, \\min_{A} : Y^{X} \\to Y$ is defined for the function $f : X \\to Y$, that is, $f \\in Y^{X}$, as follows. $$ \\max_{A} f = \\max f(A) \\\\ \\min_{A} f = \\min f(A) $$\n$f(A)$ is defined as the image of $f$ with respect to $A$, as follows. $$ f(A) := \\left\\{ f(a) : \\forall a \\in A \\right\\} $$ Examples For the set $[0,1)$, there is no maximum value, and the minimum value is $\\min [0, 1) = 0$.\nThe minimum value of the quadratic function $f(x) := 2x^{2} + 1$ is $\\min_{\\mathbb{R}} f = f(0) = 1$. If considering a maximum value within $A = [2,3] \\subset \\mathbb{R}$, it is $\\max_{a \\in A} f(a) = f(2) = 9$.\nEven in the examples above, notations can be messy, but as explained, it\u0026rsquo;s usually fine to gloss over.\n","id":2027,"permalink":"https://freshrimpsushi.github.io/en/posts/2027/","tags":null,"title":"Optimal Value: Maximum and Minimum"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Buildup Consider a random variable $X$ with a probability density function (pdf) $f \\left( x ; \\theta \\right)$ for parameter $\\theta \\in \\Theta$. A random sample $X_{1} , \\cdots , X_{n}$ drawn identically and independently (iid) from the same distribution as $X$ has the same pdf $f(x ; \\theta)$ and realization $\\mathbf{x} := \\left( x_{1} , \\cdots , x_{n} \\right)$. The function $L$ defined for this is called the Likelihood Function. $$ L ( \\theta ; \\mathbf{x} ) := \\prod_{k=1}^{n} f \\left( x_{k} ; \\theta \\right) $$ As will be discussed below, since we are interested in the maximum value of this function, it is more convenient to represent it as $l$ by taking the logarithm to convert the product $\\prod$ into the sum $\\sum$. $$ l ( \\theta ; \\mathbf{x} ) := \\sum_{k=1}^{n} \\log f \\left( x_{k} ; \\theta \\right) $$\nDefinition 1 The estimator $\\hat{\\theta} := \\hat{\\theta} \\left( \\mathbf{X} \\right)$ that satisfies the following is called the Maximum Likelihood Estimator (MLE). $$ \\hat{\\theta} = \\argmax L \\left( \\theta ; \\mathbf{X} \\right) $$\n$\\mathbf{X}$ is a random vector $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{n} \\right) $. $\\argmax g$ is the argument that maximizes function $g$, which is the value that makes $g$ the largest. Explanation Intuition Actually, ‚ÄòLikelihood‚Äô is more intuitive in English, meaning \u0026ldquo;plausibility\u0026rdquo;.\nFor example, let\u0026rsquo;s assume that the heights of any three men picked off the street were measured to be 169cm, 171cm, and 182cm, and that the heights of Korean males follow a normal distribution $N \\left( \\mu , \\sigma^{2} \\right)$. Since the probability density function of the normal distribution $f (x; \\mu)$ achieves its maximum value at the mean $x = \\mu$, the product defined by $L \\left( \\theta ; \\mathbf{x} \\right)$ is most likely to be the largest when $\\theta = \\mu$.\nNote that the main argument of function $L$ is not the data $\\mathbf{x}$ but $\\theta$. In other words, it is useful to imagine that $L$ is a function whose values do not change as $x$ is inserted into the pdf $f(x)$, but rather $f_{\\theta}$ itself moves left and right according to $\\theta$.\nSince we do not know much about the properties of $L$, we cannot confidently say that the place where $L$ is the largest is $\\theta = 171$, but it is definitely not $\\theta = 182$. The terms likelihood and $\\argmax$ may seem unfamiliar, but in essence, the Maximum Likelihood Estimator is simply ‚Äúthe most plausible value.‚Äù\nFormulas If $L$ is differentiable, the Maximum Likelihood Estimator satisfies the following Estimating Equation, which is a partial differential equation. $$ {{ \\partial l ( \\theta ) } \\over { \\partial \\theta }} = 0 $$ This is merely an extension of the solution used to find the maximum value of a function using derivatives in the curriculum. However, this area might seem unfamiliar and intimidating in textbooks, especially for statistics students, who often do not deal with differential equations after their freshman year in college. In reality, you won\u0026rsquo;t have to solve differential equations and it‚Äôs okay not to know about them, so don‚Äôt worry too much.\nHogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p209, 329.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2026,"permalink":"https://freshrimpsushi.github.io/en/posts/2026/","tags":null,"title":"Maximum Likelihood Estimator"},{"categories":"ÎèôÏó≠Ìïô","contents":"Overview The SIR model is one of the simplest and most widely varied compartmental models in epidemiology, offering a straightforward and intuitive explanation of the spread of diseases or information.\nModel 1 $$ \\begin{align*} {{d S} \\over {d t}} =\u0026amp; - {{ \\beta } \\over { N }} I S \\\\ {{d I} \\over {d t}} =\u0026amp; {{ \\beta } \\over { N }} S I - \\mu I \\\\ {{d R} \\over {d t}} =\u0026amp; \\mu I \\end{align*} $$\nVariables $S(t)$: Represents the number of individuals susceptible to the disease at time $t$. $I(t)$: Represents the number of individuals who can transmit the disease at time $t$. In the context of information spread, it also stands for the initial letter of Informed. $R(t)$: Represents the number of individuals who have recovered from the disease at time $t$. In the context of information spread, it may also stand for the initial letter of Refractory or Removed, indicating that they no longer respond or are irrelevant in the simulation. $N(t) = S(t) + I(t) + R(t)$: Represents the total population. If vital dynamics are not considered, it is usually regarded as a conserved quantity (constant), and if the variables are considered as proportions of the entire population, it is often denoted as $N(t) = 1$. Parameters $\\beta\u0026gt;0$: The infection rate. $\\mu\u0026gt;0$: The recovery rate. Explanation The vital dynamics mentioned in Variables literally consider the lifespan of each individual, where the total population itself changes through being born, aging, and dying. This is not usually emphasized unless talking about endemic diseases or analyses over very long periods.\nDerivation Lotka-Volterra Predator-Prey Model: $$ \\begin{align*} \\dot{x} =\u0026amp; a x - b y \\cdot x \\\\ \\dot{y} =\u0026amp; c x \\cdot y - d y \\end{align*} $$\nAs a special case of the Lotka-Volterra competition model, the derivation can be considered almost complete. Here, $S$ for the disease acts as the prey $S = x$, and $I$ naturally becomes the predator $I = y$. Assuming the prey has no resistance against the disease, which means $a = 0$, and setting $b = c := \\beta / N$, $d = \\mu$, we get\n$$ \\begin{align*} {{d S} \\over {d t}} =\u0026amp; - {{ \\beta } \\over { N }} I S \\\\ {{d I} \\over {d t}} =\u0026amp; {{ \\beta } \\over { N }} S I - \\mu I \\end{align*} $$\nSimply adding the rate of change of $R$ as $\\displaystyle {{d R} \\over {d t}} = \\mu I$ gives us the system for the SIR model.\n‚ñ†\nBasic Reproduction Number $$\\mathcal{R}_{0} = {{ \\beta } \\over { \\mu }}$$\nTo be precise, it would be possible to accurately get the eigenvalues with Jacobian matrices, but skipping the extensive calculations, let\u0026rsquo;s consider a quick and dirty method. At the beginning of the outbreak, that is at time $S \\approx N$, for the epidemic to eventually lead to a major outbreak, it must hold that $\\displaystyle {{ d I } \\over { d t }} \u0026gt; 0$. In other words, for $I(0) \u0026gt; 0$ $$ {{ \\beta } \\over { N }} N I - \\mu I \\approx ( \\beta - \\mu ) I \u0026gt; 0 $$ mathematically, if $\\displaystyle {{ \\beta } \\over { \\mu }} \u0026gt; 1$, then $I$ will keep increasing leading to a major outbreak. From this perspective, $\\displaystyle \\mathcal{R}_{0} := {{ \\beta } \\over { \\mu }}$ can also be called the Epidemic Threshold2.\nVariations SIRS Model: Temporary Immunity 34 Fundamentally, the R state assumes that individuals have acquired permanent immunity against the disease. However, incorporating a term like $\\nu R$ allows for reflecting the loss of immunity. Unlike the SIR model, it intuitively deals with endemic diseases.\n$$ \\begin{align*} {{d S} \\over {d t}} =\u0026amp; - {{ \\beta } \\over { N }} I S + \\nu R \\\\ {{d I} \\over {d t}} =\u0026amp; {{ \\beta } \\over { N }} S I - \\mu I \\\\ {{d R} \\over {d t}} =\u0026amp; \\mu I - \\nu R \\end{align*} $$\nCarriers 3 Carriers refer to individuals who spread the disease but show no clinical symptoms. If their number $C$ is constant, the SIR system could be modified like this:\n$$ \\begin{align*} {{d S} \\over {d t}} =\u0026amp; - {{ \\beta } \\over { N }} (I + C) S \\\\ {{d I} \\over {d t}} =\u0026amp; {{ \\beta } \\over { N }} S (I + C) - \\mu I \\\\ {{d R} \\over {d t}} =\u0026amp; \\mu I \\end{align*} $$\nVital Dynamics Similar to the logistic growth model, introducing the birth rate $r\u0026gt;0$ and mortality rate $\\gamma\u0026gt;0$ allows for considering vital dynamics. Here, the mortality rate applies equally regardless of infection status, and the growth rate also similarly affects the current total population $N(t) = S(t) + I(t) + R(t)$ regardless of infection status.\n$$ \\begin{align*} {{d S} \\over {d t}} =\u0026amp; - \\gamma S - {{ \\beta } \\over { N }} I S + r N \\\\ {{d I} \\over {d t}} =\u0026amp; - \\gamma I + {{ \\beta } \\over { N }} S I - \\mu I \\\\ {{d R} \\over {d t}} =\u0026amp; - \\gamma R + \\mu I \\end{align*} $$\nVertical Transmission Vertical Transmission or Mother-to-Child Transmission refers to infections5 directly passed from the mother to the newborn, with Hepatitis B virus being one of the examples. To incorporate this, the system obtained from the above vital dynamics can be modified by giving the vertical transmission probability $q \\in (0,1)$ like so:\n$$ \\begin{align*} {{d S} \\over {d t}} =\u0026amp; - \\gamma S - {{ \\beta } \\over { N }} I S + r ( 1- q) N \\\\ {{d I} \\over {d t}} =\u0026amp; - \\gamma I + {{ \\beta } \\over { N }} S I - \\mu I + r q N \\\\ {{d R} \\over {d t}} =\u0026amp; - \\gamma R + \\mu I \\end{align*} $$\n$r q N$ refers to the term for newborns born with the disease.\nAllen. (2006). An Introduction to Mathematical Biology: p273.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCapasso. (1993). Mathematical Structures of Epidemic Systems: p41.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCapasso. (1993). Mathematical Structures of Epidemic Systems: p9.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAllen. (2006). An Introduction to Mathematical Biology: p275.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://terms.naver.com/entry.nhn?docId=1115841\u0026amp;cid=40942\u0026amp;categoryId=32316\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2025,"permalink":"https://freshrimpsushi.github.io/en/posts/2025/","tags":null,"title":"SIR Model: The Most Basic Diffusion Model"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"## Code [^1] [^1]: https://docs.julialang.org/en/v1/manual/metaprogramming/ Julia supports [metaprogramming](../1457) at the language level. Here is the result of reading and executing a string as code itself. julia\u0026gt; text = \u0026ldquo;f(x) = 2x + 1; f(2)\u0026rdquo; \u0026ldquo;f(x) = 2x + 1; f(2)\u0026rdquo;\njulia\u0026gt; code = Meta.parse(text) :($(Expr(:toplevel, :(f(x) = begin #= none:1 =# 2x + 1 end), :(f(2)))))\njulia\u0026gt; eval(code) 5\n- `Meta.Parse()`: Ïù¥ Ìï®ÏàòÎ•º ÌÜµÌï¥ ÏûÖÎ†•Îêú Î¨∏ÏûêÏó¥ÏùÑ **ÌëúÌòÑÏãù**ÏúºÎ°ú Î∞îÍøî Î∞òÌôòÌïúÎã§.\r- `eval()`: ÌëúÌòÑÏãùÏùÑ **ÌèâÍ∞Ä**ÌïúÎã§. ÏúÑ ÏòàÏ†úÏΩîÎìúÏóêÏÑúÎäî $f(2)$ Í∞Ä Ïã§Ï†úÎ°ú ÌèâÍ∞ÄÎêòÏñ¥ Ìï®Ïà´Í∞íÏù∏ $5) ## Environment - OS: Windows - julia: v1.5.0 ","id":2024,"permalink":"https://freshrimpsushi.github.io/en/posts/2024/","tags":null,"title":"Metaprogramming in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Use the vec() function.\njulia\u0026gt; A = rand(0:9, 3,4)\r3√ó4 Array{Int64,2}:\r6 8 7 3\r2 9 3 2\r5 0 6 7\rjulia\u0026gt; vec(A)\r12-element Array{Int64,1}:\r6\r2\r5\r8\r9\r0\r7\r3\r6\r3\r2\r7 To the human eye, it appears the same as a 1-dimensional array, but it\u0026rsquo;s actually a 2-dimensional array by type, which can cause errors. This method can solve those cases. The following two commands look exactly the same, but there\u0026rsquo;s a difference between being a $\\mathbb{N}^{10 \\times 1}$ matrix or $\\mathbb{N}^{10 }$ vector.\njulia\u0026gt; b = rand(0:9, 10,1)\r10√ó1 Array{Int64,2}:\r4\r8\r0\r4\r7\r4\r4\r2\r4\r7\rjulia\u0026gt; vec(b)\r10-element Array{Int64,1}:\r4\r8\r0\r4\r7\r4\r4\r2\r4\r7 The Actual flatten() Function In fact, the real flatten() function is implemented in Base.Iterators. The result of its operation is as follows, and honestly, you might not want to use it. To be more precise, it\u0026rsquo;s not so much changing the array, but it might be necessary when using it as an iterator in loops or similar contexts. Honestly, it\u0026rsquo;s unnecessary.\njulia\u0026gt; c = rand(0:9, 3,3)\r3√ó3 Matrix{Int64}:\r7 7 4\r9 3 8\r4 4 5\rjulia\u0026gt; Iterators.flatten(c)\rBase.Iterators.Flatten{Matrix{Int64}}([7 7 4; 9 3 8; 4 4 5])\rjulia\u0026gt; vec(c)\r9-element Vector{Int64}:\r7\r9\r4\r7\r3\r4\r4\r8\r5 Environment OS: Windows julia: v1.5.0 ","id":2022,"permalink":"https://freshrimpsushi.github.io/en/posts/2022/","tags":null,"title":"How to Flatten an Array in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Conclusion Let\u0026rsquo;s calculate the distance between $n$ coordinates.\nIf it\u0026rsquo;s not necessary to calculate the distance between all coordinates, divide them into groups and create a rectangular distance matrix. The rectangular distance matrix can be calculated quickly and easily with the pairwise() function. Speed Comparison Let\u0026rsquo;s imagine doing a moving agent-based simulation for the SIR model. The original time complexity is $O \\left( n^{2} \\right)$, but if you divide it into $S$ and $I$ groups for calculation, the time complexity drops to $O \\left( n_{S} n_{I} \\right)$. Typically, the spread of diseases is implemented by calculating the distance matrix between $S$ and $I$ to judge whether they fall within a certain radius $\\varepsilon$, and by how much they have made contact. Let\u0026rsquo;s compare the speeds with this in mind.\nusing Distances\rusing StatsBase\rusing Random\rRandom.seed!(0);\rN = 10^4\rlocation = rand(2, N);\rstate = sample([\u0026#39;S\u0026#39;, \u0026#39;I\u0026#39;], Weights([0.1, 0.9]), N);\rS = location[:, state .== \u0026#39;S\u0026#39;]\rI = location[:, state .== \u0026#39;I\u0026#39;]\rfunction foo(S, I)\rcontact = Int64[]\rfor s in 1:996\rpush!(contact, sum(sum((I .- S[:,s]).^2, dims = 1) .\u0026lt; 0.1))\rend\rreturn contact\rend\r@time foo(S, I) Of course, the idea of dividing into groups to calculate improves performance significantly, not just in Julia but with any method used. The point is that there\u0026rsquo;s no need to loop through brute force when you can make good use of the Distance package\u0026rsquo;s pairwise() function.\njulia\u0026gt; @time foo(S, I);\r0.170835 seconds (7.98 k allocations: 210.854 MiB, 12.56% gc Time)\rjulia\u0026gt; @time sum(pairwise(Euclidean(),S,I) .\u0026lt; 0.1, dims = 1);\r0.087875 seconds (14 allocations: 69.639 MiB, 4.15% gc Time) These two commands do exactly the same thing, but in terms of speed, one is about twice as fast as the other, and in terms of allocation, the difference is so substantial that one might not even want to calculate it, not to mention that coding difficulty is much easier compared to looping.\nFurther Research 1 When the Euclidean distance is the distance function, using SqEuclidean() instead of Euclidean() omits the root taking calculation, thus speeding up the process. The following yields exactly the same results, but the speed difference is about 1.5 times.\njulia\u0026gt; @time sum(pairwise(Euclidean(),S,I) .\u0026lt; 0.1, dims = 1);\r0.091917 seconds (14 allocations: 69.639 MiB, 7.60% gc Time)\rjulia\u0026gt; @time sum(pairwise(SqEuclidean(),S,I) .\u0026lt; 0.01, dims = 1);\r0.061776 seconds (14 allocations: 69.639 MiB, 11.37% gc Time) Moreover, it can get even faster. At this point, simple code optimization will not be sufficient to increase speed, and a k-d tree2, a data structure favorable for multi-dimensional search, must be utilized. See how to quickly calculate distances with NearstNeighbors.jl.\nEnvironment OS: Windows julia: v1.5.0 https://github.com/JuliaStats/Distances.jl#pairwise-benchmark\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/K-d_tree\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2020,"permalink":"https://freshrimpsushi.github.io/en/posts/2020/","tags":null,"title":"Optimizing Distance Matrix Calculations in Julia"},{"categories":"ÎèôÏó≠Ìïô","contents":"Overview 1 Compartmental models in epidemiology serve as models for epidemic outbreaks, incorporating infectious diseases into population dynamics and dividing the \u0026lsquo;population\u0026rsquo; into several compartments.\nEpidemiology is the study of epidemics, unrelated to the mechanics discussed at shrimp sushi restaurants. Description Ever since Kermack and McKendrick devised what\u0026rsquo;s known as the SIR model, there have been numerous modifications and developments. All models that originate from this idea are essentially considered compartmental models in epidemiology. The most well-known model is the initial SIR model mentioned earlier, which divides the total population $N$ into three compartments:\n$S$ Susceptible: Healthy, can become sick $I$ Infected: Sick, spreading the disease $R$ Recovered: Recovered, immune These are represented as a simple autonomous system with respect to the transmission rate $\\beta \u0026gt; 0$ and the recovery rate $\\mu \u0026gt; 0$.\n$$ \\begin{align*} {{d S} \\over {d t}} =\u0026amp; - \\beta I S \\\\ {{d I} \\over {d t}} =\u0026amp; \\beta S I - \\mu I \\\\ {{d R} \\over {d t}} =\u0026amp; \\mu I \\end{align*} $$\nGeneral Structure of Bilinear Systems 2 Beretta and Capasso formalized the general form of many derived models as follows. $$ {{dz} \\over {dt}} = \\text{diag} (z) (e + A z) + c $$\n$n$ is the number of compartments. $z(t) \\in \\mathbb{R}^{n}$ is the time-dependent vector of compartments $t$. $e, c \\in \\mathbb{R}^{n}$ is a vector of constants. $A \\in \\mathbb{R}^{n \\times n}$ is a constant matrix represented by competitive coefficients. Why is it represented in this form? The system is usually derived based on the law of mass action, reasoning that $A$ and $B$ meet and react. They meet and react at a constant ratio in an ideal space, and the extent is proportional to their respective amounts, thus the reacting quantity is also proportional to $[A][B]$. Therefore, at least each compartment must be multiplied twice, but the phenomenon of three compartments coming together and reacting is uncommon in reality. Therefore, most linear models can be represented bilinearly.\nExample Taking the simple SIR model as an example, $$ {{ d } \\over { dt }} \\begin{bmatrix} S(t) \\\\ I(t) \\\\ R(t) \\end{bmatrix} = \\begin{bmatrix} S(t) \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; I(t) \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; R(t) \\end{bmatrix} \\left( \\begin{bmatrix} 0 \\\\ -\\mu \\\\ \\mu \\end{bmatrix} + \\begin{bmatrix} 0 \u0026amp; -\\beta \u0026amp; 0 \\\\ \\beta \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} \\begin{bmatrix} S(t) \\\\ I(t) \\\\ R(t) \\end{bmatrix} \\right) + \\mathbf{0} $$ it can be elaborated as $$ e = \\begin{bmatrix} 0 \\\\ -\\mu \\\\ \\mu \\end{bmatrix} \\\\ A = \\begin{bmatrix} 0 \u0026amp; -\\beta \u0026amp; 0 \\\\ \\beta \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} \\\\ c = \\mathbf{0} $$\nCapasso. (1993). Mathematical Structures of Epidemic Systems: p7.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCapasso. (1993). Mathematical Structures of Epidemic Systems: p10.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2019,"permalink":"https://freshrimpsushi.github.io/en/posts/2019/","tags":null,"title":"Dynamics Compartment Model"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview The usage of the function sample() which serves a similar role to R\u0026rsquo;s sample() or Python package numpy\u0026rsquo;s random.choice(), and the Weights function in Julia.\nCode 1 using StatsBase\ritems = 0:5\rweights = 0:5\rsample(items, Weights(weights))\r# With replacement\rmy_samps = sample(items, Weights(weights), 10)\r# Without replacement\rmy_samps = sample(items, Weights(weights), 2, replace=false) Execution Result julia\u0026gt; using StatsBase\rjulia\u0026gt; items = 0:5\r0:5\rjulia\u0026gt; weights = 0:5\r0:5\rjulia\u0026gt; sample(items, Weights(weights))\r5\rjulia\u0026gt; # With replacement\rjulia\u0026gt; my_samps = sample(items, Weights(weights), 10)\r10-element Array{Int64,1}:\r4\r3\r2\r1\r3\r3\r5\r5\r2\r2\rjulia\u0026gt; # Without replacement\rjulia\u0026gt; my_samps = sample(items, Weights(weights), 2, replace=false)\r2-element Array{Int64,1}:\r4\r5 Environment OS: Windows julia: v1.5.0 https://stackoverflow.com/a/27560273/12285249\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2018,"permalink":"https://freshrimpsushi.github.io/en/posts/2018/","tags":null,"title":"How to Weight and Random Sample in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Conclusion Comparing each element in an array using the Equal Operator == shows that Char is faster than integers.\nSpeed Comparison julia\u0026gt; integer = rand(1:5, N); print(typeof(integer))\rArray{Int64,1}\rjulia\u0026gt; character = rand([\u0026#39;S\u0026#39;,\u0026#39;E\u0026#39;,\u0026#39;I\u0026#39;,\u0026#39;R\u0026#39;,\u0026#39;D\u0026#39;], N); print(typeof(character))\rArray{Char,1}\rjulia\u0026gt; @time integer .== 1;\r0.009222 seconds (6 allocations: 1.196 MiB)\rjulia\u0026gt; @time character .== \u0026#39;S\u0026#39;;\r0.005266 seconds (7 allocations: 1.196 MiB) The above code identifies where 1 and S are located in an array made of integers and characters, respectively. Except for the difference between being an integer or a character, everything else is exactly the same, yet there\u0026rsquo;s a significant difference in time consumption, almost double. Therefore, using characters is recommended in the code optimization process as it\u0026rsquo;s a commonly used method.\nFurther Research julia\u0026gt; string = rand([\u0026#34;S\u0026#34;,\u0026#34;E\u0026#34;,\u0026#34;I\u0026#34;,\u0026#34;R\u0026#34;,\u0026#34;D\u0026#34;], N); print(typeof(string))\rArray{String,1}\rjulia\u0026gt; @time string .== \u0026#34;S\u0026#34;;\r0.072692 seconds (7 allocations: 1.196 MiB) As one would expect, using a String instead of a Character causes more than a tenfold increase in speed degradation.\nEnvironment OS: Windows julia: v1.5.0 ","id":2016,"permalink":"https://freshrimpsushi.github.io/en/posts/2016/","tags":null,"title":"Comparison of the Speed of the Equality Operator == for Characters and Integers in Julia"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Definition1 A function space defined as follows is called a weighted $L^{p}$ space or specifically a $w$-weighted $L^{p}$ space.\n$$ L_{w}^{p}(a,b):= \\left\\{ f : \\mathbb{R}\\to \\mathbb{C}\\ \\big|\\ \\int_{a}^{b} \\left| f(x) \\right|^{p}w(x)dx \u0026lt;\\infty \\right\\} $$\nHere, $w:\\mathbb{R}\\to[0,\\infty)$ is called a weight function.\nDescription It is one of the spaces that generalizes the $L^{p}$ space. When it is $w(x)=1$, $L_{w}^{p}=L^{p}$ holds. The norm of the weighted $L^{p}$ space is defined as follows for $1\\le p \u0026lt;\\infty$.\n$$ \\left\\| f\\right\\|_{p,w}=\\left\\| f\\right\\|_{L_{w}^{p}(a,b)}=\\left( \\int_{a}^{b}\\left| f(x) \\right|^{p}w(x)dx \\right)^{\\frac{1}{p}} $$\nIt is obvious that the above value is finite by the definition of the $L_{w}^{p}$ space. Especially, when it is $p=2$, the inner product can be defined as follows.\n$$ \\langle f,g \\rangle_{L_{w}^{2}(a,b)}=\\int_{a}^{b}f(x)\\overline{g(x)}w(x)dx,\\quad f,g \\in L_{w}^{2}(\\mathbb{R}) $$\nSimilar to the $L^{2}$ space, it becomes a Hilbert space.\nGerald B. Folland, Fourier Analysis and Its Applications (1992), p81\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1856,"permalink":"https://freshrimpsushi.github.io/en/posts/1856/","tags":null,"title":"Weighted Lp Spaces"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Summary 1 If random variables $X_{1} , \\cdots , X_{n}$ are iid and follow a normal distribution $N\\left( \\mu,\\sigma^{2} \\right)$, then\n(a): $$ \\overline{X} \\sim N\\left( \\mu , { {\\sigma^2} \\over {n} } \\right) $$ (b): $$ \\overline{X} \\perp S^2 $$ (c): $$ (n-1) { {S^2} \\over {\\sigma^2} } \\sim \\chi^2 (n-1) $$ (d): $$ T = { {\\overline{X} - \\mu } \\over {S / \\sqrt{n}} } \\sim t(n-1) $$ Sample mean $\\overline{X}$ and sample variance $S^{2}$ are defined as follows as random variables. $$ \\overline{X} := {{ 1 } \\over { n }} \\sum_{k=1}^{n} X_{k} \\\\ S^{2} := {{ 1 } \\over { n-1 }} \\sum_{k=1}^{n} \\left( X_{k} - \\overline{X} \\right)^{2} $$\nDescription It‚Äôs commonly used among statisticians, but in fact, it also has a name. It is divided into four parts, making it difficult to cite specifically.\n(b) is a fact that seems obvious if it‚Äôs obvious and strange if it‚Äôs strange, that is, despite both sample mean and sample variance coming from the same data, they are independent.\nInference about the population mean for small samples The proof of Student\u0026rsquo;s theorem is the derivation itself of hypothesis testing for the population mean with a small sample.\nProof (a) Since $\\displaystyle \\overline{X} = { { (X_1 + X_2 + \\cdots + X_n )} \\over {n}}$, when thinking about the sum of random variables that follow a normal distribution $$ \\overline{X} \\sim N \\left( \\mu, {{1} \\over {n}} \\sigma^2 \\right) $$\n‚ñ†\n(b) $\\mathbf{0}$ represents the zero vector. $\\mathbf{1} = (1, \\cdots , 1) = \\begin{bmatrix} 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix}$ represents a vector whose components are all $1$. $I$ represents an identity matrix. $A^{T}$ represents the transpose matrix of matrix $A$. Let\u0026rsquo;s say $\\displaystyle \\mathbf{v} := {{ 1 } \\over { n }} \\mathbf{1}$.\nRandom vector $X := \\left( X_{1} , \\cdots , X_{n} \\right)$ follows a multivariate normal distribution $$ \\begin{align*} \\overline{X} =\u0026amp; {{ 1 } \\over { n }} \\left( X_{1} + \\cdots + X_{n} \\right) \\\\ \u0026amp;= {{ 1 } \\over { n }} \\begin{bmatrix} 1 \u0026amp; \\cdots \u0026amp; 1 \\end{bmatrix} \\begin{bmatrix} X_{1} \\\\ \\vdots \\\\ X_{n} \\end{bmatrix} \\\\ =\u0026amp; {{ 1 } \\over { n }} \\mathbf{1}^{T} \\mathbf{X} \\\\ =\u0026amp; \\mathbf{v}^{T} \\mathbf{X} \\end{align*} $$\nNow, defining a random vector $\\mathbf{Y} := \\left( X_{1} - \\overline{X} , \\cdots , X_{n} - \\overline{X} \\right)$, some random vector $\\mathbf{W}$ can be represented as follows. $$ \\mathbf{W} = \\begin{bmatrix} \\overline{X} \\\\ \\mathbf{Y} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{v}^{T} \\\\ I - \\mathbf{1} \\mathbf{v}^{T} \\end{bmatrix} \\mathbf{X} $$\nSince $\\mathbf{W}$ is a linear transformation of random vectors that follow a multivariate normal distribution, it still follows a multivariate normal distribution, and its mean vector is $$ E \\mathbf{W} = \\begin{bmatrix} \\mathbf{v}^{T} \\\\ I - \\mathbf{1} \\mathbf{v}^{T} \\end{bmatrix} \\mu \\mathbf{1} = \\begin{bmatrix} \\mu \\\\ \\mathbf{0}_{n} \\end{bmatrix} $$ when taking the expected value of the above equation, and its covariance matrix $\\Sigma$ is $$ \\begin{align*} \\Sigma =\u0026amp; \\begin{bmatrix} \\mathbf{v}^{T} \\\\ I - \\mathbf{1} \\mathbf{v}^{T} \\end{bmatrix} \\sigma^{2} I \\begin{bmatrix} \\mathbf{v}^{T} \\\\ I - \\mathbf{1} \\mathbf{v}^{T} \\end{bmatrix}^{T} \\\\ =\u0026amp; \\sigma^{2} \\begin{bmatrix} 1/n \u0026amp; \\mathbf{0}_{n}^{T} \\\\ \\mathbf{0}_{n} \u0026amp; I - \\mathbf{1} \\mathbf{v}^{T} \\end{bmatrix} \\end{align*} $$. Here, it can be seen that $\\overline{X}$ is independent of $\\mathbf{Y}$, and $$ S^{2} = {{ 1 } \\over { n-1 }} \\sum_{k=1}^{n} \\left( X_{k} - \\overline{X} \\right)^{2} = {{ 1 } \\over { n-1 }} \\mathbf{Y}^{T} \\mathbf{Y} $$ therefore, $\\overline{X} \\perp S^{2}$ is true.\n‚ñ†\n(c) If it is said that $\\displaystyle V = \\sum_{i=1}^{n} \\left( { {X_{i} - \\mu } \\over {\\sigma} } \\right) ^2 $, then since $\\displaystyle { {X_{i} - \\mu } \\over {\\sigma} } \\sim N(0,1)$, it will be $V \\sim \\chi^2 (n)$,\n$$ \\begin{align*} V =\u0026amp; \\sum_{i=1}^{n} \\left( { {X_{i} - \\mu } \\over {\\sigma} } \\right) ^2 \\\\ =\u0026amp; \\sum_{i=1}^{n} \\left( { { ( X_{i} -\\overline{X} ) + ( \\overline{X} - \\mu ) } \\over {\\sigma} } \\right) ^2 \\\\ =\u0026amp; \\sum_{i=1}^{n} \\left( { { X_{i} -\\overline{X} } \\over {\\sigma} } \\right) ^2 + \\left( { { \\overline{X} - \\mu } \\over {\\sigma / \\sqrt{n} } } \\right) ^2 \\end{align*} $$\nWhere $$ \\sum_{i=1}^{n} \\left( { { X_{i} -\\overline{X} } \\over {\\sigma} } \\right) ^2 = { {n-1} \\over {\\sigma^2} } \\sum_{i=1}^{n} { { ( X_{i} -\\overline{X} ) ^ 2 } \\over {n-1} } = (n-1) { {S^2} \\over {\\sigma^2} } $$\nTo summarize $$ V = (n-1) { {S^2} \\over {\\sigma^2} } + \\left( { { \\overline{X} - \\mu } \\over {\\sigma / \\sqrt{n} } } \\right) ^2 $$\nSince it is $V \\sim \\chi^2 (n)$, and by (a) of Student\u0026rsquo;s theorem $$ \\left( { { \\overline{X} - \\mu } \\over {\\sigma / \\sqrt{n} } } \\right) \\sim N(0,1) $$ The square of the standard normal distribution follows a chi-squared distribution, so $$ \\left( { { \\overline{X} - \\mu } \\over {\\sigma / \\sqrt{n} } } \\right)^2 \\sim \\chi^2 (1) $$\nIn (b) of Student\u0026rsquo;s theorem, it was shown that $\\overline{X}$ and $S^2$ are independent, so if both sides are put into a form of moment-generating functions, $$ (1-2t)^{-n/2} = E \\left\\{ \\exp \\left( (n-1) { {S^2} \\over {\\sigma^2} } t \\right) \\right\\} (1-2t)^{-1/2} $$\nTherefore, the moment-generating function of $\\displaystyle (n-1) { {S^2} \\over {\\sigma^2} }$ is $(1-2t)^{-(n-1)/2}$\n‚ñ†\n(d) Derivation of Student\u0026rsquo;s t-distribution from normal and chi-squared distributions: If $W \\sim N(0,1)$ is true and $V \\sim \\chi^2 (r)$, $$ T = { {W} \\over {\\sqrt{V/r} } } \\sim t(r) $$\n$$ T = { {\\overline{X} - \\mu } \\over {S / \\sqrt{n}} } = { {( \\overline{X} - \\mu ) / (\\sigma / \\sqrt{n}) } \\over { \\sqrt{ (n-1) S^2 / ( \\sigma^2 ( n-1 ) ) } } } $$ In (a) of Student\u0026rsquo;s theorem, it was shown that $\\displaystyle \\overline{X} \\sim N\\left( \\mu , { {\\sigma^2} \\over {n} } \\right) $ and from (c) it was shown that $\\displaystyle (n-1) { {S^2} \\over {\\sigma^2} } \\sim \\chi^2 (n-1) $, $$ T \\sim t(n-1) $$\n‚ñ†\nHogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p195.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":203,"permalink":"https://freshrimpsushi.github.io/en/posts/203/","tags":null,"title":"Student's t-test Proof"},{"categories":"ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç","contents":"Overview A commonly used RGB color palette.\nCode ","id":2013,"permalink":"https://freshrimpsushi.github.io/en/posts/2013/","tags":null,"title":"RGB Color Cheat Sheet"},{"categories":"Ìï®Ïàò","contents":"Definitions A function $f: X \\to Y$, $g: f(X) \\to Z$ is defined as follows: the composition of $g$ with $f$ is called $h: X \\to Z$, and it is denoted by $h=g \\circ f$.\n$$ h(x) = (g\\circ f) (x) := g\\left( f(x) \\right) $$\n","id":3048,"permalink":"https://freshrimpsushi.github.io/en/posts/3048/","tags":null,"title":"Composition of Functions"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 A transformation is when a function $T : V \\to W$ maps from one vector space to another, that is $V$, $W$ are both vector spaces, we call $T$ a transformation.\nIf the transformation $T$ is a linear function, satisfying the following two conditions for any $\\mathbf{v},\\mathbf{u} \\in V$ and scalar $k$, it is called a linear transformation:\n$T(k \\mathbf{u}) = k T(\\mathbf{u})$ $T(\\mathbf{u} + \\mathbf{v}) = T(\\mathbf{u}) + T(\\mathbf{v})$ Specifically, if $W=\\mathbb{C}$, then $T$ is called a linear functional.\nExplanation Functions, mappings, transformations are essentially synonymous. However, in contexts involving vector spaces like linear algebra or functional analysis, the term transformation is primarily used, abbreviated as $T$.\nLinear transformations from finite dimensions to finite dimensions are often treated like matrix multiplication, depicted as follows:\n$$ T(\\mathbf{x}) = T\\mathbf{x} $$\nA linear transformation that satisfies $T : V \\to V$ on $V$ is sometimes called a linear operator on $V$. However, it doesn\u0026rsquo;t always have to be that the domain and codomain are identical to be called an operator. For practical reasons, several textbooks define $T : V \\to V$ as a linear operator.\n$$ \\text{linear transformation form } V \\text{ to } V \\to \\text{linear operator on } V $$\nThe set of all linear transformations from vector space $X$ to $Y$ is denoted as follows: $L(X, Y)$.2\n$$ L(X,Y) = \\mathcal{L}(X, Y) := \\left\\{ T : X \\to Y\\enspace |\\enspace T \\text{ is linear } \\right\\} $$\nMatrix transformation is a type of linear transformation.\nIdentity Transformation A linear transformation $I : V \\to V$ satisfies\n$$ I(\\mathbf{v}) = \\mathbf{v} $$\nfor all $\\mathbf{v} \\in V$ is called an identity transformation. Specifically, it might be denoted as $I_{V}$.\nZero Transformation A linear transformation $T_{0} : V \\to W$ satisfies\n$$ T_{0}(\\mathbf{v}) = \\mathbf{0}_{W} $$\nfor all $\\mathbf{v} \\in V$ is called a zero transformation. Here, $\\mathbf{0}_{W}$ is the zero vector in $W$. Also denoted as $O$, $0$, it is essentially a zero function.\nProperties If $T : V \\to W$ is a linear transformation, then the following hold:\n(a) $T(\\mathbf{0}) = \\mathbf{0}$\n(b) For all $\\mathbf{u}, \\mathbf{v} \\in V$, $T(\\mathbf{u} - \\mathbf{v}) = T(\\mathbf{u}) - T(\\mathbf{v})$\nProof (a) By the property of vector spaces, since $0\\mathbf{v} = \\mathbf{0}$,\n$$ T(\\mathbf{0}) = T( 0\\mathbf{u}) = 0T(\\mathbf{u}) = \\mathbf{0} $$\n‚ñ†\n(b) Similarly, due to the property of vector spaces that $-\\mathbf{v} = (-1)\\mathbf{v}$,\n$$ \\begin{align*} T(\\mathbf{u} - \\mathbf{v}) \u0026amp;= T \\big( \\mathbf{u} + (-1)\\mathbf{v} \\big) \\\\ \u0026amp;= T(\\mathbf{u}) + T\\big( (-1)\\mathbf{v} \\big) \\\\ \u0026amp;= T(\\mathbf{u}) + (-1)T(\\mathbf{v}) \\\\ \u0026amp;= T(\\mathbf{u}) - T(\\mathbf{v}) \\end{align*} $$\n‚ñ†\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p446-447\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWalter Rudin, Principles of Mathematical Analysis (3rd Edition, 1976), p207\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3026,"permalink":"https://freshrimpsushi.github.io/en/posts/3026/","tags":null,"title":"Linear Transformation"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 In a linear system, if the constant terms are all $0$, it is called homogeneous.\n$$ \\begin{align*} a_{11}x_{1} + a_{12}x_{2} + \\cdots + a_{1n}x_{n} \u0026amp;= 0 \\\\ a_{21}x_{1} + a_{22}x_{2} + \\cdots + a_{2n}x_{n} \u0026amp;= 0 \\\\ \u0026amp;\\vdots \\\\ a_{m1}x_{1} + a_{m2}x_{2} + \\cdots + a_{mn}x_{n} \u0026amp;= 0 \\end{align*} $$\nUnlike general linear systems, every homogeneous linear system always has a solution because if the constant terms are $0$, it obviously has $x_{1}=0, x_{2}=0, \\dots, x_{n}=0$ as a solution. This is called the trivial solution. Solutions that are not trivial are called nontrivial solutions. Since a homogeneous linear system always has a trivial solution, there are only the following two cases for its solutions:\nOnly the trivial solution exists.\nBoth the trivial solution and infinitely many nontrivial solutions exist.\nTheorem on Free Variables in Homogeneous Systems Let\u0026rsquo;s consider a homogeneous linear system with $n$ unknowns. Suppose that the number of non-$0$ rows in the reduced row echelon form of the augmented matrix is $r$. Then, the homogeneous system can be represented simply as follows.\n$$ \\begin{align*} \u0026amp; x_{1} \u0026amp; \u0026amp; \u0026amp; \u0026amp;+ (\\quad) \u0026amp;= 0 \u0026amp; \\\\ \u0026amp; \u0026amp; x_{2} \u0026amp; \u0026amp; \u0026amp;+ (\\quad) \u0026amp;= 0 \u0026amp; \\\\ \u0026amp; \u0026amp; \u0026amp; \\ddots \u0026amp; \u0026amp; \u0026amp; \\vdots \u0026amp; \\\\ \u0026amp; \u0026amp; \u0026amp; \u0026amp; x_{r} \u0026amp;+ (\\quad) \u0026amp;= 0 \u0026amp; \\end{align*} $$\nThis equation has $n-r$ free variables. Therefore, if $r \u0026lt; n$, there is at least one free variable, leading to infinitely many solutions. Hence, a homogeneous linear system with more unknowns than equations has infinitely many solutions.\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p17-19\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3020,"permalink":"https://freshrimpsushi.github.io/en/posts/3020/","tags":null,"title":"Simultaneous Homogeneous Linear Equations"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 An augmented matrix is said to be in echelon form if it satisfies the following conditions:\nIn rows that have a non-zero element, the first non-zero number is a 1, referred to as the leading 1.\nRows where all elements are zero are placed at the bottom.\nFor consecutive rows that contain non-zero elements, the leading 1 in the upper row must be to the left of the leading 1 in the row below.\nIf an echelon form matrix further satisfies the condition below, it is said to be in reduced echelon form:\nIn columns that contain a leading 1, all other elements must be zeros. The following matrices are in reduced echelon form:\n$$ \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 3 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 7 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; -1 \\end{bmatrix},\\quad \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix},\\quad \\begin{bmatrix} 0 \u0026amp; 1 \u0026amp; -2 \u0026amp; 0 \u0026amp; 1 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 3 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix},\\quad \\begin{bmatrix} 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \\end{bmatrix} $$\nThe following matrices are in echelon form but not in reduced echelon form:\n$$ \\begin{bmatrix} 1 \u0026amp; 4 \u0026amp; -3 \u0026amp; 7 \\\\ 0 \u0026amp; 1 \u0026amp; 6 \u0026amp; 2 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 5 \\end{bmatrix},\\quad \\begin{bmatrix} 1 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix},\\quad \\begin{bmatrix} 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 6 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; -1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} $$\nThe process of using elementary row operations on the augmented matrix of a given linear system to produce a reduced echelon form is referred to as the Gauss-Jordan elimination. The process of making all elements below a leading 1 into zeros is called forward elimination, and making all elements above a leading 1 into zeros is called backward elimination.\nProperties Every matrix has a unique reduced echelon form. In other words, regardless of the sequence of elementary row operations performed, the same reduced echelon form matrix is obtained.\nEchelon forms are not unique. That is, different echelon forms can be obtained depending on the sequence of elementary row operations.\nThe number of rows in an echelon form where all elements are zeros is the same, and the position of the leading 1s is also the same. These positions are referred to as the pivot positions.\nGeneral Solution2 When a linear system has infinitely many solutions, a set of parametric equations that generates solutions by substituting parameters is called the general solution of the linear system.\nConsider a linear system whose augmented matrix is transformed into the following reduced echelon form by elementary row operations:\n$$ \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 3 \u0026amp; -1 \\\\ 0 \u0026amp; 1 \u0026amp; -4 \u0026amp; 2 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} $$\nThen, the parametric equations are as follows:\n$$ x = -1 -3t,\\quad y = 2 + 4t, \\quad z = t $$\nIn this case, variables corresponding to the leading 1 are called leading variables, and the other variables are called free variables.\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p11\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p115\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3019,"permalink":"https://freshrimpsushi.github.io/en/posts/3019/","tags":null,"title":"Gaussian-Jordan Elimination"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Error ERROR: SystemError: opening file \u0026quot;C:\\\\Users\\\\rmsms\\\\.julia\\\\registries\\\\General\\\\Registry.toml\u0026quot;: No such file or directory\rCause It\u0026rsquo;s a really frustrating error, which, as the message indicates, occurs because the Registry.toml file does not exist at the specified path.\nSolution Delete the C:\\Users\\ÏÇ¨Ïö©ÏûêÏù¥Î¶Ñ\\.julia\\registries\\General folder and try again.\nThen, as shown above, the Registry.toml file will be created, and the installation will proceed normally.\n","id":2069,"permalink":"https://freshrimpsushi.github.io/en/posts/2069/","tags":null,"title":"Solving \\General\\Registry.toml: No such file or directory when Installing Julia Packages"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let $S = \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{r} \\right\\}$ be a subset of vector space $V$. If $S$ satisfies the following two conditions, then $S$ is called a basis of $V$.\n$S$ spans $V$.\n$$ V = \\text{span}(S) $$\n$S$ is linearly independent.\nExplanation As the name suggests, the concept of a basis corresponds to \u0026rsquo;the smallest thing that can create a vector space\u0026rsquo;. The condition of spanning has the meaning of \u0026lsquo;creating a vector space\u0026rsquo;, and being linearly independent has the meaning of being \u0026rsquo;the smallest\u0026rsquo;. Even though the notion of creating a vector space is understood, the need to be smallest may not be immediately clear. However, this can be easily understood with just one simple example. For instance, we do not represent a vector $(2,3)$ as\n$$ (2,3)=1(1,0) + 2(0,1) + 1(1,1) $$.\nBecause $(1,1)$ can be represented as a linear combination of $(1,0), (0,1)$. Thus, the above expression is merely an unnecessarily lengthy way of writing it. Therefore, being linearly independent ensures that when representing any vector as a linear combination of the basis, it is done in the neatest manner possible, including only what is necessary.\nIt is important to note that a basis for a vector space does not necessarily have to be unique. For example, $\\left\\{ (1,0) , (0,1) \\right\\}$ is a basis that spans $\\mathbb{R}^{2}$. However, according to the definition, $\\left\\{ (2,0) , (0,2) \\right\\}$ can also be a basis for $\\mathbb{R}^2$. And? Even $\\left\\{ (1,1) , (-1,1) \\right\\}$ has no problem being a basis that spans $\\mathbb{R}^2$. However, generally, in the case of $\\mathbb{R}^{n}$, a basis consisting of the following vectors is discussed.\n$$ \\mathbf{e}_{1} = (1,0,0,\\dots,0), \\quad \\mathbf{e}_{2}=(0,1,0,\\dots,0),\\quad \\mathbf{e}_{n}=(0,0,0,\\dots,1) $$\nSuch a basis is called standard basis for $\\mathbb{R}^{n}$. Each of $\\mathbf{e}_{i}$ is referred to as a standard unit vector. Especially for $n=3$, it is commonly denoted as follows.\n$$ \\begin{align*} \\hat{\\mathbf{x}} =\u0026amp;\\ \\mathbf{e}_{1} = \\hat{\\mathbf{x}}_{1} = \\mathbf{i}=(1,0,0) \\\\ \\hat{\\mathbf{y}} =\u0026amp;\\ \\mathbf{e}_{2} = \\hat{\\mathbf{x}}_{2} = \\mathbf{j}=(0,1,0) \\\\ \\hat{\\mathbf{z}} =\u0026amp;\\ \\mathbf{e}_{3} = \\hat{\\mathbf{x}}_{3} = \\mathbf{k}=(0,0,1) \\end{align*} $$\nFrom the following theorem, the concept of coordinates can also be talked about in abstract vector spaces. If $\\mathbf{v} \\in V$ is represented as $(1)$, $[\\mathbf{v}]_{S}$ is called the coordinate vector of $\\mathbf{v}$ relative to basis $S$.\n$$ [\\mathbf{v}]_{S} = \\begin{bmatrix} c_{1} \\\\ c_{2} \\\\ \\vdots \\\\ c_{n} \\end{bmatrix} $$\nTheorem: Uniqueness of Basis Representation Let $S = \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{n} \\right\\}$ be a basis of vector space $V$. Then, for every vector $\\mathbf{v} \\in V$,\n$$ \\begin{equation} \\mathbf{v} = c_{1}\\mathbf{v}_{1} + c_{2}\\mathbf{v}_{2} + \\cdots + c_{n}\\mathbf{v}_{n} \\end{equation} $$\nthere exists a unique way to represent it like this. In other words, there exists a unique ordered pair of coefficients $(c_{1},c_{2},\\dots,c_{n})$ that satisfies the above equation.\nProof Since $S$ spans $V$, by the definition of spanning, all vectors in $V$ can be expressed as a linear combination of $S$. Let\u0026rsquo;s say some vector $\\mathbf{v}$ can be expressed by the following two linear combinations.\n$$ \\begin{align*} \\mathbf{v} \u0026amp;= c_{1}\\mathbf{v}_{1} + c_{2}\\mathbf{v}_{2} + \\cdots + c_{n}\\mathbf{v}_{n} \\\\ \\mathbf{v} \u0026amp;= k_{1}\\mathbf{v}_{1} + k_{2}\\mathbf{v}_{2} + \\cdots + k_{n}\\mathbf{v}_{n} \\end{align*} $$\nSubtracting the equations from each other yields the following.\n$$ \\mathbf{0} = (c_{1} - k_{1}) \\mathbf{v}_{1} + (c_{2} - k_{2}) \\mathbf{v}_{2} + \\cdots + (c_{n} - k_{n}) \\mathbf{v}_{n} $$\nHowever, since $\\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{n}$ is linearly independent, the only solution that satisfies the above equation is\n$$ c_{1} - k_{1} = 0,\\quad c_{2} - k_{2} = 0,\\quad \\dots,\\quad c_{n} - k_{n} = 0 $$\nTherefore, the following holds.\n$$ c_{1} = k_{1},\\quad c_{2} = k_{2},\\quad \\dots,\\quad c_{n} = k_{n} $$\nHence, the two linear combination representations are identical.\n‚ñ†\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p240\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3017,"permalink":"https://freshrimpsushi.github.io/en/posts/3017/","tags":null,"title":"Basis of Vector Space"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide Step 1. Install Julia\nDownload the installation file from the Julia download page and run it.\nStep 2. Install VS Code\nDownload the installation file from the Visual Studio Code download page and run it.\nStep 3. Install Julia Extension\nOpen Extensions by clicking on the fifth icon from the left or pressing Ctrl + Shift + X. Search for \u0026lsquo;julia\u0026rsquo; and Julia Language Support will appear at the top.\nClick Install to install it.\nCreate a file with the .jl extension in the editor, write Julia code, and try running it in full by pressing Shift + Enter. The screenshot above has only one line, println(helloworld), to print out \u0026ldquo;helloworld\u0026rdquo;.\nEnvironment OS: Windows julia: v1.5.4 ","id":2067,"permalink":"https://freshrimpsushi.github.io/en/posts/2067/","tags":null,"title":"How to Install the Latest Version of Julia on Windows"},{"categories":"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ","contents":"Definition A set of functions $X$ is called a function space if it forms a vector space.\nExplanation In the function space $X$, the inner product is defined by integration as follows.\n$$ \\langle f, g \\rangle = \\int f(x) g(x) dx,\\quad f,g\\in X $$\nThe main function spaces considered include the following.\nSpace of continuous functions $C^{m}$\n$$ C^{m}(\\mathbb{R}) : =\\left\\{ f \\in C(\\mathbb{R}) : f^{(n)} \\text{ is continuous } \\forall n \\le m \\right\\} $$\nSpace of test functions $C_{c}^{\\infty} = \\mathcal{D}$ Schwartz space $\\mathcal{S}$ H√∂lder continuous function space Lebesgue space $L^{p}$\n$$ L^{p} (E) : = \\left\\{ f : \\int_{E} | f |^{p} dm \u0026lt; \\infty \\right\\} $$\nWeighted Lebesgue space Space of convergent sequences $\\ell^{p}$\nSobolev space $W^{m,\\ p}$\n$$ W^{m,\\ p}(\\Omega):=\\left\\{ u \\in L^p(\\Omega)\\ :\\ D^\\alpha u \\in L^p(\\Omega),\\ 0\\le |\\alpha | \\le m \\right\\} $$\nSee Also Function spaces in topology ","id":3032,"permalink":"https://freshrimpsushi.github.io/en/posts/3032/","tags":null,"title":"Various Function Spaces"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 Given a matrix $n\\times n$ $A$, for a non-zero column vector $\\mathbf{0}$ $n\\times 1$ and a constant $\\mathbf{x}$, the following equation is referred to as the eigenvalue equation or the eigenvalue problem.\n$$ \\begin{equation} A \\mathbf{x} = \\lambda \\mathbf{x} \\end{equation} $$\nFor a given $A$, a $\\mathbf{x}$ that satisfies the eigenvalue equation above is called the eigenvalue of $A$, and $n\\times 1$ is called the eigenvector corresponding to the eigenvalue $\\mathbf{x}$ of $A$.\nExplanation The definition above applies not only when $\\lambda \\in \\mathbb{R}$ and $\\mathbf{x} \\in \\mathbb{R}^{n}$, but also when $\\lambda \\in \\mathbb{C}$ and $\\mathbf{x} \\in \\mathbb{C}^{n}$. The condition \u0026ldquo;non-zero\u0026rdquo; is important because, as the following equation shows, if $\\mathbf{x} = \\mathbf{0}$, the equation always holds.\n$$ A \\mathbf{0} = \\mathbf{0} = \\lambda \\mathbf{0} $$\nGeometric Motivation If the direction of a vector $\\mathbf{x}$ remains the same after being transformed by the matrix $A$, this implies there exists some real number $\\lambda$ such that\n$$ A \\mathbf{x} = \\lambda \\mathbf{x} $$\nWhile the matrix $A$ itself does not possess any notion of direction, if it has eigenvectors, it can be said to indicate a specific direction. Thus, such vectors $\\mathbf{x}$ are named eigenvectors. Consider a matrix such as $2\\times 2$.\n$$ A = \\begin{bmatrix} 6 \u0026amp; 2 \\\\ 2 \u0026amp; 3 \\end{bmatrix} $$\nThen, vector $\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$, when transformed by $2\\times 2$, becomes $\\begin{bmatrix} 14 \\\\ 7 \\end{bmatrix}$ and maintains the same direction. If we multiply vector $\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$ by $\\lambda = 7$, the length of the vector also matches, satisfying the eigenvalue equation\n$$ \\begin{align*} A \\mathbf{x} \u0026amp;= \\lambda \\mathbf{x} \\\\ \\begin{bmatrix} 6 \u0026amp; 2 \\\\ 2 \u0026amp; 3 \\end{bmatrix} \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} \u0026amp;= 7 \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} \\end{align*} $$\nHence, $\\lambda=7$ is referred to as the eigenvalue. Upon closer inspection, although many eigenvectors can be found by scaling $\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$, the eigenvalue remains unchanged. Therefore, $\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$ is described as the eigenvector of $A$ corresponding to the eigenvalue $7$.\nBy extending this geometric discussion to a general context, eigenvalues algebraically satisfy the equation $A \\mathbf{x} = \\lambda \\mathbf{x}$, and the eigenvectors are the non-trivial solutions to the equation for the given $\\mathbf{x}$.\nSolving the Eigenvalue Equation To find the eigenvalues, one starts with the eigenvalue equation. Simplifying the equation $(1)$ yields:\n$$ \\begin{align*} \u0026amp;\u0026amp; A \\mathbf{x} \u0026amp;= \\lambda \\mathbf{x} \\\\ \\implies \u0026amp;\u0026amp; A \\mathbf{x} - \\lambda \\mathbf{x} \u0026amp;= \\mathbf{0} \\\\ \\implies \u0026amp;\u0026amp; A \\mathbf{x} - \\lambda I \\mathbf{x} \u0026amp;= \\mathbf{0} \\\\ \\implies \u0026amp;\u0026amp; \\left( A - \\lambda I \\right) \\mathbf{x} \u0026amp;= \\mathbf{0} \\end{align*} $$\nHere, the eigenvector must satisfy condition $\\mathbf{x} \\ne \\mathbf{0}$. The linear system above will have a non-zero solution if and only if the inverse of $\\left( A - \\lambda I \\right)$ does not exist, which is equivalent to the following equation.\n$$ \\det (A -\\lambda I) = 0 $$\nTherefore, $\\mathbf{x}$ satisfying the above equation becomes the eigenvalue of $A$. This equation is called the characteristic equation of $A$. For a $n\\times n$ matrix, $\\det (A -\\lambda I)$ becomes a polynomial of degree $n$, known as the characteristic polynomial.\nNote that the eigenvalues of $A+B$ may differ from the sum of the eigenvalues of $A$ and $B$, and similarly, the eigenvalues of $AB$ may not match the product of the eigenvalues of $A$ and $B$. Furthermore, as it can be seen from solving the equation, there is no guarantee that eigenvalues will always be real numbers.\nExamples Finding Eigenvalues As an example, consider again $A = \\begin{bmatrix} 6 \u0026amp; 2 \\\\ 2 \u0026amp; 3 \\end{bmatrix}$. Since $A-\\lambda I = \\begin{bmatrix} 6 - \\lambda \u0026amp; 2 \\\\ 2 \u0026amp; 3 - \\lambda \\end{bmatrix}$, solving the characteristic equation of $A$ yields:\n$$ \\begin{align*} \u0026amp;\u0026amp; \\det (A - \\lambda I) \u0026amp;= 0 \\\\ \\implies \u0026amp;\u0026amp; (6 - \\lambda)(3 - \\lambda) - 4 \u0026amp;= 0 \\\\ \\implies \u0026amp;\u0026amp; \\lambda^2 - 9 \\lambda + 18 - 4 \u0026amp;= 0 \\\\ \\implies \u0026amp;\u0026amp; (\\lambda - 2)(\\lambda - 7) \u0026amp;= 0 \\end{align*} $$\nTherefore, the eigenvalues of $A$ are $\\lambda = 2$ and $\\lambda = 7$. By substituting $2$ and $7$ for $\\mathbf{x}$, one can find the corresponding eigenvectors for each eigenvalue. Here, only the case for $\\lambda = 7$ is presented.\nFinding the Eigenvector Corresponding to $\\lambda = 7$ Substituting $\\lambda = 7$ into $(1)$ and simplifying yields:\n$$ \\begin{align*} \u0026amp;\u0026amp; \\begin{bmatrix} 6 \u0026amp; 2 \\\\ 2 \u0026amp; 3 \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\ x_{2} \\end{bmatrix} \u0026amp;= 7\\begin{bmatrix} x_{1} \\\\ x_{2} \\end{bmatrix} \\\\ \\implies \u0026amp;\u0026amp; \\begin{bmatrix} 6x_{1} + 2x_{2} \\\\ 2x_{1} + 3x_{2} \\end{bmatrix} \u0026amp;= \\begin{bmatrix} 7x_{1} \\\\ 7x_{2} \\end{bmatrix} \\\\ \\implies \u0026amp;\u0026amp; \\begin{bmatrix} -x_{1} + 2x_{2} \\\\ 2x_{1} - 4x_{2} \\end{bmatrix} \u0026amp;= \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\end{align*} $$\nSolving this results in:\n$$ \\left\\{ \\begin{align*} -x_{1} + 2x_{2} \u0026amp;= 0 \\\\ 2x_{1} - 4x_{2} \u0026amp;= 0 \\end{align*} \\right. $$\n$$ \\implies x_{1} = 2x_{2} $$\nThus, for all $0$ not equal to zero, the vector $\\begin{bmatrix} 2x_{2} \\\\ x_{2} \\end{bmatrix}$ is the eigenvector corresponding to $\\lambda = 7$. Typically, the simplest form or a unit vector with magnitude $1$ is chosen. Substituting $x_{2} = 1$ gives the following eigenvector:\n$$ A = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} $$\nProperties For a positive integer $k$, if $\\mathbf{x}$ is an eigenvalue of matrix $A$ and $n\\times 1$ is the corresponding eigenvector to $\\mathbf{x}$, then $\\lambda ^{k}$ is an eigenvalue of $A^{k}$, and $n\\times 1$ is the corresponding eigenvector to $\\lambda ^{k}$. Howard Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p291-292\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":319,"permalink":"https://freshrimpsushi.github.io/en/posts/319/","tags":null,"title":"Eigenvalues and Eigenvectors"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Definitions1 Let us define $E\\subset \\mathbb{R}^{n}$ as an open set, and $\\mathbf{x}\\in E$, and $\\mathbf{f} : E \\to \\mathbb{R}^{m}$. Let $\\left\\{ \\mathbf{e}_{1}, \\mathbf{e}_{2}, \\dots, \\mathbf{e}_{n} \\right\\}$, and $\\left\\{ \\mathbf{u}_{1}, \\mathbf{u}_{2}, \\dots, \\mathbf{u}_{m} \\right\\}$ be the standard basis of $\\mathbb{R}^{n}$ and $\\mathbb{R}^{m}$, respectively.\nThen, the components $f_{i} : \\mathbb{R}^{n} \\to \\mathbb{R}$ of $\\mathbf{f}$ are defined as follows.\n$$ \\mathbf{f} (\\mathbf{x}) = \\sum_{i=1}^{m} f_{i}(\\mathbf{x})\\mathbf{u}_{i}, \\quad \\mathbf{x} \\in E $$\nor\n$$ f_{i} (\\mathbf{x}) := \\mathbf{f} (\\mathbf{x}) \\cdot \\mathbf{u}_{i},\\quad i \\in \\left\\{ 1,\\dots, m \\right\\} $$\nIf the following limit exists, it is called the partial derivative of $f_{i}$ with respect to $x_{j}$, denoted by $D_{j}f_{i}$ or $\\dfrac{\\partial f_{i}}{\\partial x_{j}}$.\n$$ \\dfrac{\\partial f_{i}}{\\partial x_{j}} = D_{j}f_{i} := \\lim _{t \\to 0} \\dfrac{f_{i}(\\mathbf{x}+ t \\mathbf{e}_{j}) -f_{i}(\\mathbf{x})}{t} $$\nExplanation The term \u0026ldquo;partial\u0026rdquo; means biased or considering differentiation with respect only to one variable instead of all variables. This is in contrast to the total derivative.\nIt\u0026rsquo;s not a partial $\\check{}$ function, but a partial derivative of $\\check{}$.\nBetween the total derivative and the partial derivative of $\\mathbf{f}$, the following theorem holds.\nTheorem Let $E, \\mathbf{x}, \\mathbf{f}$ be as defined in Definitions. Suppose $\\mathbf{f}$ is differentiable at $\\mathbf{x}$. Then, each partial derivative $D_{j}f_{i}(\\mathbf{x})$ exists, and the following equation holds.\n$$ \\mathbf{f}^{\\prime}(\\mathbf{x})\\mathbf{e}_{j} = \\sum_{i=1}^{m} D_{j}f_{i}(\\mathbf{x})\\mathbf{u}_{i},\\quad j \\in \\left\\{ 1,\\dots, n \\right\\} $$\nCorollary $\\mathbf{f}^{\\prime}(\\mathbf{x})$ can be represented as the following matrix, which is a linear transformation.\n$$ \\mathbf{f}^{\\prime}(\\mathbf{x}) = \\begin{bmatrix} (D_{1}f_{1}) (\\mathbf{x}) \u0026amp; (D_{2}f_{1}) (\\mathbf{x}) \u0026amp; \\cdots \u0026amp; (D_{n}f_{1}) (\\mathbf{x}) \\\\ (D_{1}f_{2}) (\\mathbf{x}) \u0026amp; (D_{2}f_{2}) (\\mathbf{x}) \u0026amp; \\cdots \u0026amp; (D_{n}f_{2}) (\\mathbf{x}) \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ (D_{1}f_{m}) (\\mathbf{x}) \u0026amp; (D_{2}f_{m}) (\\mathbf{x}) \u0026amp; \\cdots \u0026amp; (D_{n}f_{m}) (\\mathbf{x}) \\end{bmatrix} $$\nThis is also known as the Jacobian matrix of $\\mathbf{f}$.\nProof Let us fix $j$. Assuming that $\\mathbf{f}$ is differentiable at $\\mathbf{x}$, the following equation holds.\n$$ \\mathbf{f}( \\mathbf{x} + t \\mathbf{e}_{j}) - \\mathbf{f}(\\mathbf{x}) = \\mathbf{f}^{\\prime}(\\mathbf{x})(t\\mathbf{e}_{j}) + \\mathbf{r}(t\\mathbf{e}_{j}) $$\nHere, $\\mathbf{r}(t\\mathbf{e}_{j})$ is a remainder that satisfies the following.\n$$ \\lim _{t \\to 0} \\dfrac{|\\mathbf{r}(t\\mathbf{e}_{j}) |}{t}=0 $$\nSince $\\mathbf{f}^{\\prime}(\\mathbf{x})$ is a linear transformation, the following holds.\n$$ \\dfrac{\\mathbf{f}( \\mathbf{x} + t \\mathbf{e}_{j}) - \\mathbf{f}(\\mathbf{x})}{t} = \\dfrac{\\mathbf{f}^{\\prime}(\\mathbf{x})(t\\mathbf{e}_{j})}{t} + \\dfrac{\\mathbf{r}(t\\mathbf{e}_{j})}{t} = \\mathbf{f}^{\\prime}(\\mathbf{x})(\\mathbf{e}_{j}) + \\dfrac{\\mathbf{r}(t\\mathbf{e}_{j})}{t} $$\nTaking the limit as $\\lim _{t \\to 0}$ on both sides gives us the following.\n$$ \\lim _{t \\to 0} \\dfrac{\\mathbf{f}( \\mathbf{x} + t \\mathbf{e}_{j}) - \\mathbf{f}(\\mathbf{x})}{t} = \\mathbf{f}^{\\prime}(\\mathbf{x})\\mathbf{e}_{j} $$\nExpressing $\\mathbf{f}$ in components yields:\n$$ \\begin{align*} \\mathbf{f}^{\\prime}(\\mathbf{x})\\mathbf{e}_{j} \u0026amp;= \\lim _{t \\to 0} \\dfrac{\\mathbf{f}( \\mathbf{x} + t \\mathbf{e}_{j}) - \\mathbf{f}(\\mathbf{x})}{t} \\\\ \u0026amp;= \\lim _{t \\to 0} \\dfrac{\\sum_{i=1}^{m} f_{i}( \\mathbf{x} + t \\mathbf{e}_{j})\\mathbf{u}_{i} - \\sum_{i=1}^{m} f_{i}(\\mathbf{x})\\mathbf{u}_{i}}{t} \\\\ \u0026amp;= \\sum_{i=1}^{m} \\lim _{t \\to 0} \\dfrac{f_{i}( \\mathbf{x} + t \\mathbf{e}_{j}) - f_{i}(\\mathbf{x})}{t} \\mathbf{u}_{i} \\end{align*} $$\nThen, by the definition of partial derivatives, we obtain:\n$$ \\mathbf{f}^{\\prime}(\\mathbf{x})\\mathbf{e}_{j} = \\sum_{i=1}^{m} D_{j}f_{i}(\\mathbf{x}) \\mathbf{u}_{i} $$\n‚ñ†\nExamples Suppose that $f : \\R^{3} \\to \\R, \\gamma : \\R \\to \\R^{3}$ is a differentiable function. Also,\n$$ \\gamma (t) = \\left( x(t), y(t), z(t) \\right) $$\nAnd let us denote the composition of $f$ and $\\gamma$ as $g = f \\circ \\gamma$.\n$$ g(t) = f \\circ \\gamma (t) = f \\left( \\gamma (t) \\right) $$\nThen, $g^{\\prime}$, by the chain rule, definition of partial derivatives, and the theorem introduced above, goes as follows.\n$$ \\begin{align*} \\dfrac{d g}{d t}(t_{0}) = g^{\\prime}(t_{0}) =\u0026amp;\\ f^{\\prime}(\\gamma (t_{0})) \\gamma^{\\prime}(t_{0}) \\\\ =\u0026amp;\\ \\begin{bmatrix} D_{1}f(\\gamma (t_{0})) \u0026amp; D_{2}f(\\gamma (t_{0})) \u0026amp; D_{3}f(\\gamma (t_{0})) \\end{bmatrix} \\begin{bmatrix} D\\gamma_{1} (t_{0}) \\\\ D\\gamma_{2} (t_{0}) \\\\ D\\gamma_{3} (t_{0}) \\end{bmatrix} \\\\ =\u0026amp;\\ \\begin{bmatrix} \\dfrac{\\partial f}{\\partial x}(\\gamma (t_{0})) \u0026amp; \\dfrac{\\partial f}{\\partial y}(\\gamma (t_{0})) \u0026amp; \\dfrac{\\partial f}{\\partial z}(\\gamma (t_{0})) \\end{bmatrix} \\begin{bmatrix} \\dfrac{d x}{d t}(t_{0}) \\\\ \\dfrac{d y}{d t}(t_{0}) \\\\ \\dfrac{d z}{d t}(t_{0}) \\end{bmatrix} \\\\ =\u0026amp;\\ \\dfrac{\\partial f}{\\partial x}(\\gamma (t_{0}))\\dfrac{d x}{d t}(t_{0}) + \\dfrac{\\partial f}{\\partial y}(\\gamma (t_{0}))\\dfrac{d y}{d t}(t_{0}) + \\dfrac{\\partial f}{\\partial z}(\\gamma (t_{0}))\\dfrac{d z}{d t}(t_{0}) \\end{align*} $$\nTherefore,\n$$ \\implies \\dfrac{d g}{d t} = \\dfrac{\\partial f}{\\partial x}\\dfrac{d x}{d t} + \\dfrac{\\partial f}{\\partial y}\\dfrac{d y}{d t} + \\dfrac{\\partial f}{\\partial z}\\dfrac{d z}{d t} $$\nWalter Rudin, Principles of Mathematical Analysis (3rd Edition, 1976), p215\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3036,"permalink":"https://freshrimpsushi.github.io/en/posts/3036/","tags":null,"title":"Partial Derivatives"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 Positive Definite Matrix A quadratic form $\\mathbf{x}^{\\ast} A \\mathbf{x}$ is\ncalled a positive definite matrix or quadratic form if it satisfies $\\mathbf{x}^{\\ast} A \\mathbf{x} \u0026gt; 0$ for all $\\mathbf{x} \\ne \\mathbf{0}$.\ncalled a negative definite matrix or quadratic form if it satisfies $\\mathbf{x}^{\\ast} A \\mathbf{x} \u0026lt; 0$ for all $\\mathbf{x} \\ne \\mathbf{0}$.\ncalled indefinite if it sometimes satisfies $\\mathbf{x}$ for the same quadratic form or matrix $A$.\nFor real matrices, one can think of replacing the part $\\mathbf{x}^{\\ast} A \\mathbf{x}$ with $\\mathbf{x}^{T} A \\mathbf{x}$ in the definition.\nPositive Semidefinite Matrix A quadratic form $\\mathbf{x}^{\\ast} A \\mathbf{x}$ is\ncalled a positive semidefinite matrix or quadratic form if it satisfies $\\mathbf{x}^{\\ast} A \\mathbf{x} \\ge 0$ for all $\\mathbf{x} \\ne \\mathbf{0}$.\ncalled a negative semidefinite matrix or quadratic form if it satisfies $\\mathbf{x}^{\\ast} A \\mathbf{x} \\le 0$ for all $\\mathbf{x} \\ne \\mathbf{0}$.\nExplanation Although these definitions are clean, a lot is omitted, making it hard to follow mentally. Let\u0026rsquo;s try to grasp the concepts gradually while looking at the formulas and explanations. Consider the case where the constants of the quadratic form are complex numbers, meaning $A$ is a Hermitian matrix. As shown in $A \\mathbf{x} = \\lambda \\mathbf{x}$, $\\lambda$ becomes the eigenvalue of $A$. Multiplying the left side of the equation by the conjugate transpose $\\mathbf{x}^{\\ast}$ results in:\n$$ \\mathbf{x}^{\\ast} A \\mathbf{x} = \\lambda \\mathbf{x}^{\\ast} \\mathbf{x} = \\lambda \\mathbf{x} \\cdot \\mathbf{x} = \\lambda | \\mathbf{x} |^{2} $$\nSince $\\mathbf{x} \\ne \\mathbf{0}$, this implies $|\\mathbf{x}| ^2 \u0026gt; 0$, and since the eigenvalues of a Hermitian matrix are real, $\\lambda |\\mathbf{x}| ^2$ is also real. Thus, $\\mathbf{x}^{\\ast} A \\mathbf{x}$ is real, and whether it is positive or negative can be determined. Although it may have been difficult to understand when written as a product of matrices and vectors, expressing it as $\\lambda |\\mathbf{x}| ^2$ makes it easier to comprehend.\nConsidering the sign of $\\lambda |\\mathbf{x}|^{2}$, since it is always $|\\mathbf{x}|^{2} \u0026gt;0$, one only needs to consider the sign of $\\lambda$. Ultimately, stating that for any non-zero vector the condition $\\mathbf{x}^{\\ast} A \\mathbf{x} \u0026gt; 0$ is met means that all eigenvalues of $A$ are positive. Conversely, a negative definite matrix implies that all its eigenvalues are negative. Now, one can think of definiteness as defining the concept of negative/positive to matrices that originally do not have this concept. This is encompassed in Theorem 1.\nAdditionally, according to the equivalence condition of invertible matrices, both positive and negative definite matrices do not have $0$ as an eigenvalue, making them invertible matrices. (Theorem 2)\nApplications In numerical linear algebra, there is particular interest in positive definiteness. Considering it as a condition, starting with a Hermitian matrix which, having all positive eigenvalues, is a very strong condition. In dynamics, the properties of negative definite matrices are used to study the stability of equilibrium points in the system. In statistics, it is fundamental that covariance matrices are positive semidefinite matrices, making them extremely important. Theorem 1 For a quadratic form $\\mathbf{x}^{\\ast} A\\mathbf{x}$,\nThe necessary and sufficient condition for $\\mathbf{x}^{\\ast} A\\mathbf{x}$ to be positive definite is that all eigenvalues of $A$ are positive.\nThe necessary and sufficient condition for $\\mathbf{x}^{\\ast} A\\mathbf{x}$ to be negative definite is that all eigenvalues of $A$ are negative.\nThe necessary and sufficient condition for $\\mathbf{x}^{\\ast} A\\mathbf{x}$ to be indefinite is that $A$ has at least one negative and at least one positive eigenvalue.\nTheorem 2 Positive definite and negative definite matrices are always invertible.\nTheorem 3 For a symmetric matrix $A$,\nIf $A$ is positive definite, then $\\mathbf{x}^{T}A\\mathbf{x}=1$ is an equation of an ellipse.\nIf $A$ is negative definite, then $\\mathbf{x}^{T}A\\mathbf{x}=1$ does not have a graph.\nIf $A$ is indefinite, then $\\mathbf{x}^{T}A\\mathbf{x}=1$ is an equation of a hyperbola.\nHoward Anton, Chris Rorres, Anton Kaul, Elementary Linear Algebra: Applications Version(12th Edition). 2019, p423\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":336,"permalink":"https://freshrimpsushi.github.io/en/posts/336/","tags":null,"title":"Definite matrix"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Properties Let $A,B$ be a $n\\times n$ matrix and $k$ be a constant. The determinant satisfies the following properties:\n(a) $\\det(kA) = k^{n}\\det(A)$\n(b) $\\det(AB) = \\det(A)\\det(B)$\n(c) $\\det(AB)=\\det(BA)$\n(d) If $A$ is an invertible matrix, then $\\det(A^{-1}) = \\dfrac{1}{\\det(A)}$\n(e) $\\det(A^{T}) = \\det(A)$. Here, $A^{T}$ is the transpose of $A$.\n","id":3015,"permalink":"https://freshrimpsushi.github.io/en/posts/3015/","tags":null,"title":"Properties of Determinants"},{"categories":"Í∏∞ÌïòÌïô","contents":"Overview1 Rotational surfaces are classified into three types according to the sign of the Gaussian curvature. Within each classification, surfaces with the same curvature share the same local intrinsic characteristics, even though they might have different global, extrinsic properties. In other words, they are locally isometric.\nRichard S. Millman and George D. Parker, Elements of Differential Geometry (1977), p153-154\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3034,"permalink":"https://freshrimpsushi.github.io/en/posts/3034/","tags":null,"title":"Classification of Surfaces of Revolution According to Gaussian Curvature"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definitions Let\u0026rsquo;s denote $A$ as the following $2 \\times 2$ matrix.\n$$ A = \\begin{bmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{bmatrix} $$\nThe determinant of $A$ is defined as follows and is denoted by $\\det(A)$.\n$$ \\det(A) := ad - bc $$\nExplanation To talk about determinants, we cannot skip discussing the very purpose of linear algebra. It wouldn\u0026rsquo;t be an exaggeration to say that most problems in mathematics boil down to \u0026lsquo;can we solve the equation?\u0026rsquo; For instance, consider the simple equation\n$$ ax = b $$\nIt\u0026rsquo;s easy to see that this equation has a solution, as long as $ a = 0$ is not zero. Similarly, the quadratic equation\n$$ a x^2 + b x + c = 0 $$\ncan be easily solved using the quadratic formula. Mathematicians, thus challenged themselves with increasingly difficult problems by elevating the degree of $x$. However, the unfortunate genius Abel proved that \u0026lsquo;Algebraic equations of degree five or higher do not have a general solution\u0026rsquo;.\nMeanwhile, another path was left to be explored by increasing either the number of unknowns or the number of equations itself. This is where determinants came into play. Despite how it might seem in Korean, determinants actually appeared before matrices historically1, and the English terms determinant and matrix are not directly related. The name determinant was given to this formula because it can determine whether or not a unique solution exists for a system of two linear equations with two unknowns as follows.\n$$ \\left\\{ \\begin{align*} ax + by \u0026amp;= 0 \\\\ cx + dy \u0026amp;= 0 \\end{align*} \\right. $$\nGiven the simultaneous equations as above, if $ad-bc = 0$, then there exists only the trivial solution $x=y=0$, and if $ad-bc \\ne 0$, it has a unique non-trivial solution. Therefore, $ad-bc$ serves as a formula that determines whether a given system of equations has a solution or not, hence the name.\nAs is well-known, systems of equations can be expressed in the form of matrices. A \u0026lsquo;simple\u0026rsquo; system of equations can be expressed as follows.\n$$ A \\mathbf{x} = \\mathbf{b} $$\nRemembering that the solution to $ax = b$ was $x = \\dfrac{b}{a}$, consider that $\\dfrac{1}{a}$ is the inverse of $a$, so multiplying both sides by it leaves only $x$. Tying this to the condition for the existence of a solution, $a= 0$ has no inverse, so there is no solution for $ax = b$. Similarly, whether a solution can be found for $A$ boils down to whether $A$ has an inverse. The existence of an inverse of $A$ itself signifies the existence of a solution for the linear system expressed by $A$, and finding this inverse is how a solution is determined. From this, we can understand that the condition for the existence of an inverse matrix of $A$ and the condition for the linear system expressed by $A$ to have a unique solution are the same.\nThe inverse matrix of $A = \\begin{bmatrix} a \u0026amp; b \\\\ c \u0026amp; d\\end{bmatrix}$ is as follows.\n$$ A^{-1} = \\dfrac{1}{ad-bc} \\begin{bmatrix} d \u0026amp; -b \\\\ -c \u0026amp; a \\end{bmatrix} $$\nThis is proven simply by directly multiplying $A$ and $A^{-1}$. If $\\det (A) = ad - bc = 0$, regardless of the shape of the matrix, the constant before $A^{-1}$ becomes $\\dfrac{1}{0}$, hence no inverse can exist. The term invertibility is sometimes referred to as nonsingularity for this reason. Singular translates to \u0026lsquo;peculiar\u0026rsquo;, but to stick to mathematical terminology, it roughly means \u0026lsquo;dividing by zero\u0026rsquo;.\nOn the other hand, from the perspective of a function that maps $n\\times n$ real numbers to $1$ real numbers, the determinant can be defined as follows:\nDefinition A function $ \\det : \\mathbb{R}^{n \\times n } \\to \\mathbb{R} $ is defined as the determinant if it satisfies the following conditions:\nFor the identity matrix $I_{n}$, $\\det(I_{n}) = 1$ For $1 \\le i,j \\le n$, $\\det \\begin{bmatrix} \\mathbb{r_{1}} \\\\ \\vdots \\\\ \\mathbb{r_{i}} \\\\ \\vdots \\\\ \\mathbb{r_{j}} \\\\ \\vdots \\\\ \\mathbb{r_{n}} \\end{bmatrix} = - \\det \\begin{bmatrix} \\mathbb{r_{1}} \\\\ \\vdots \\\\ \\mathbb{r_{j}} \\\\ \\vdots \\\\ \\mathbb{r_{i}} \\\\ \\vdots \\\\ \\mathbb{r_{n}} \\end{bmatrix}$ $\\det \\begin{bmatrix} k \\mathbb{r_{1}} + l \\mathbb{r_{1}}^{\\prime} \\\\ \\vdots \\\\ \\mathbb{r_{n}} \\end{bmatrix} = k \\det \\begin{bmatrix} \\mathbb{r_{1}} \\\\ \\vdots \\\\ \\mathbb{r_{n}} \\end{bmatrix} + l \\det \\begin{bmatrix} \\mathbb{r_{1}}^{\\prime} \\\\ \\vdots \\\\ \\mathbb{r_{n}} \\end{bmatrix}$ Explanation As such, generalizing the determinant makes it easier to discuss the existence or absence of solutions to systems of equations. This discussion is perfectly encapsulated in the theorem below.\n$$ \\forall A \\in \\mathbb{C}^{n \\times n},\\quad \\exists A^{-1} \\iff \\det{A} \\ne 0 $$\nIt\u0026rsquo;s nearly taken as a definition, so obvious it might seem. However, if we cannot explain why this theorem holds or question its obviousness, it‚Äôs as if we haven\u0026rsquo;t truly grasped the concept of determinants. Especially since the concept precedes the definition in the case of determinants, if it\u0026rsquo;s not comprehensible, it\u0026rsquo;s advisable to spend time understanding it.\nhttps://en.wikipedia.org/wiki/Determinant#History\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":252,"permalink":"https://freshrimpsushi.github.io/en/posts/252/","tags":null,"title":"Determinants"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 Let\u0026rsquo;s assume a linear system is given as follows.\n$$ \\begin{equation} \\begin{aligned} a_{11}x_{1} + a_{12}x_{2} + \\cdots + a_{1n}x_{n} \u0026amp;= b_{1}\\\\ a_{21}x_{1} + a_{22}x_{2} + \\cdots + a_{2n}x_{n} \u0026amp;= b_{2}\\\\ \u0026amp;\\vdots\\\\ a_{m1}x_{1} + a_{m2}x_{2} + \\cdots + a_{mn}x_{n} \u0026amp;= b_{m} \\end{aligned} \\label{linsys2} \\end{equation} $$\nThe representation of constants of a linear system in a matrix is called an augmented matrix.\n$$ \\begin{equation} \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \u0026amp; b_{1} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \u0026amp; b_{2} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \u0026amp; b_{m} \\end{bmatrix} \\label{augmented} \\end{equation} $$\nDescription Matrices were designed to solve systems of linear equations easily. For example, one could extract only the constants of $\\eqref{linsys2}$ and represent them like $\\eqref{augmented}$ or as follows.\n$$ \\begin{align*} \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix} \u0026amp;= \\begin{bmatrix} b_{1} \\\\ b_{2} \\\\ \\vdots \\\\ b_{m} \\end{bmatrix} \\\\ A\\mathbf{x} \u0026amp;= \\mathbf{b} \\end{align*} $$\nIn particular, when represented in an augmented matrix, the linear system can be solved through elementary row operations, which essentially are the same as the method of addition and subtraction taught in middle school.\nDefinition The following three operations are considered elementary row operations.\nMultiply a row by a constant that is not $0$.\nSwap the positions of two rows.\nAdd a multiple of one row to another row.\nExample Solving a system of equations through the method of addition and subtraction is akin to modifying the augmented matrix with elementary row operations to leave only one element in the last column of each row. In the language of linear algebra, this is \u0026rsquo;transforming the augmented matrix into a reduced row echelon form through elementary row operations'.\n$$ \\begin{array}{rcrcrcr} x \u0026amp;+\u0026amp; y \u0026amp;+\u0026amp; 2z \u0026amp;=\u0026amp;\\ 9 \\\\ 2x \u0026amp;+\u0026amp; 4y \u0026amp;-\u0026amp; 3z \u0026amp;=\u0026amp;\\ 1 \\\\ 3x \u0026amp;+\u0026amp; 6y \u0026amp;-\u0026amp; 5z \u0026amp;=\u0026amp;\\ 0 \\end{array} \\quad \\begin{bmatrix} 1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 9 \\\\ 2 \u0026amp; 4 \u0026amp; -3 \u0026amp; 1 \\\\ 3 \u0026amp; 6 \u0026amp; -5 \u0026amp; 0 \\end{bmatrix} $$\nMultiply the first row by $-2$ and add it to the second row.\n$$ \\begin{array}{rcrcrcr} x \u0026amp;+\u0026amp; y \u0026amp;+\u0026amp; 2z \u0026amp;=\u0026amp;\\ 9 \\\\ \u0026amp;\u0026amp; 2y \u0026amp;-\u0026amp; 7z \u0026amp;=\u0026amp;\\ -17 \\\\ 3x \u0026amp;+\u0026amp; 6y \u0026amp;-\u0026amp; 5z \u0026amp;=\u0026amp;\\ 0 \\end{array} \\quad \\begin{bmatrix} 1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 9 \\\\ 0 \u0026amp; 2 \u0026amp; -7 \u0026amp; -17 \\\\ 3 \u0026amp; 6 \u0026amp; -5 \u0026amp; 0 \\end{bmatrix} $$\nMultiply the first row by $-3$ and add it to the third row.\n$$ \\begin{array}{rcrcrcr} x \u0026amp;+\u0026amp; y \u0026amp;+\u0026amp; 2z \u0026amp;=\u0026amp;\\ 9 \\\\ \u0026amp;\u0026amp; 2y \u0026amp;-\u0026amp; 7z \u0026amp;=\u0026amp;\\ -17 \\\\ \u0026amp;\u0026amp; 3y \u0026amp;-\u0026amp;11z \u0026amp;=\u0026amp;\\ -27 \\end{array} \\quad \\begin{bmatrix} 1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 9 \\\\ 0 \u0026amp; 2 \u0026amp; -7 \u0026amp; -17 \\\\ 0 \u0026amp; 3 \u0026amp; -11 \u0026amp; -27 \\end{bmatrix} $$\nMultiply the second row by $\\dfrac{1}{2}$.\n$$ \\begin{array}{rcrcrcr} x \u0026amp;+\u0026amp; y \u0026amp;+\u0026amp; 2z \u0026amp;=\u0026amp;\\ 9 \\\\ \u0026amp;\u0026amp; y \u0026amp;-\u0026amp; \\dfrac{7}{2} z \u0026amp;=\u0026amp;\\ -\\dfrac{17}{2} \\\\ \u0026amp;\u0026amp; 3y \u0026amp;-\u0026amp;11z \u0026amp;=\u0026amp;\\ -27 \\end{array} \\quad \\begin{bmatrix} 1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 9 \\\\ 0 \u0026amp; 1 \u0026amp; -\\dfrac{7}{2} \u0026amp; -\\dfrac{17}{2} \\\\ 0 \u0026amp; 3 \u0026amp; -11 \u0026amp; -27 \\end{bmatrix} $$\nMultiply the second row by $-3$ and add it to the third row.\n$$ \\begin{array}{rcrcrcr} x \u0026amp;+\u0026amp; y \u0026amp;+\u0026amp; 2z \u0026amp;=\u0026amp;\\ 9 \\\\ \u0026amp;\u0026amp; y \u0026amp;-\u0026amp; \\dfrac{7}{2} z \u0026amp;=\u0026amp;\\ -\\dfrac{17}{2} \\\\ \u0026amp;\u0026amp; \u0026amp;-\u0026amp;\\dfrac{1}{2}z \u0026amp;=\u0026amp;\\ -\\dfrac{3}{2} \\end{array} \\quad \\begin{bmatrix} 1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 9 \\\\ 0 \u0026amp; 1 \u0026amp; -\\dfrac{7}{2} \u0026amp; -\\dfrac{17}{2} \\\\ 0 \u0026amp; 0 \u0026amp; -\\dfrac{1}{2} \u0026amp; -\\dfrac{3}{2} \\end{bmatrix} $$\nMultiply the third row by $-2$.\n$$ \\begin{array}{rcrcrcr} x \u0026amp;+\u0026amp; y \u0026amp;+\u0026amp; 2z \u0026amp;=\u0026amp;\\ 9 \\\\ \u0026amp;\u0026amp; y \u0026amp;-\u0026amp; \\dfrac{7}{2} z \u0026amp;=\u0026amp;\\ -\\dfrac{17}{2} \\\\ \u0026amp;\u0026amp; \u0026amp;\u0026amp;z \u0026amp;=\u0026amp;\\ 3 \\end{array} \\quad \\begin{bmatrix} 1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 9 \\\\ 0 \u0026amp; 1 \u0026amp; -\\dfrac{7}{2} \u0026amp; -\\dfrac{17}{2} \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 3 \\end{bmatrix} $$\nMultiply the second row by $-1$ and add it to the first row.\n$$ \\begin{array}{rcrcrcr} x \u0026amp;\u0026amp; \u0026amp;+\u0026amp; \\dfrac{11}{2}z \u0026amp;=\u0026amp;\\ \\dfrac{35}{2} \\\\ \u0026amp;\u0026amp; y \u0026amp;-\u0026amp; \\dfrac{7}{2} z \u0026amp;=\u0026amp;\\ -\\dfrac{17}{2} \\\\ \u0026amp;\u0026amp; \u0026amp;\u0026amp;z \u0026amp;=\u0026amp;\\ 3 \\end{array} \\quad \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; \\dfrac{11}{2} \u0026amp; \\dfrac{35}{2} \\\\ 0 \u0026amp; 1 \u0026amp; -\\dfrac{7}{2} \u0026amp; -\\dfrac{17}{2} \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 3 \\end{bmatrix} $$\nMultiply the third row by $-\\dfrac{11}{2}$ and add it to the first row, then multiply the third row by $\\dfrac{7}{2}$ and add it to the first row.\n$$ \\begin{array}{rcrcrcr} x \u0026amp;\u0026amp; \u0026amp;\u0026amp; \u0026amp;=\u0026amp;\\ 1 \\\\ \u0026amp;\u0026amp; y \u0026amp;\u0026amp; \u0026amp;=\u0026amp;\\ 2 \\\\ \u0026amp;\u0026amp; \u0026amp;\u0026amp;z \u0026amp;=\u0026amp;\\ 3 \\end{array} \\quad \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 2 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 3 \\end{bmatrix} $$\nTherefore, the solution of the given linear system is $x=1$, $y=2$, $z=3$.\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p6-8\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3014,"permalink":"https://freshrimpsushi.github.io/en/posts/3014/","tags":null,"title":"Augmented Matrices and Elementary Row Operations"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 For constants $a_{1}$, $a_{2}$, $\\dots$, $a_{n}$, $b$, we define a linear equation for variables $x_{1}$, $x_{2}$, $\\dots$, $x_{n}$ as follows.\n$$ \\begin{equation} a_{1}x_{1} + a_{2}x_{2} + \\cdots + a_{n}x_{n} = b \\label{lineq} \\end{equation} $$\nAt least one of $a$ is not $0$. In other words, not \u0026ldquo;all $a$ are $0$\u0026rdquo;. A finite set of linear equations is called a system of linear equations or simply a linear system, and the variables are called unknowns. In Korean, linear and first-order mean the same thing. A linear system consisting of $m$ linear equations for $n$ variables $x_{1}$, $x_{2}$, $\\dots$, $x_{n}$ is represented as follows.\n$$ \\begin{equation} \\begin{aligned} a_{11}x_{1} + a_{12}x_{2} + \\cdots + a_{1n}x_{n} \u0026amp;= b_{1} \\\\ a_{21}x_{1} + a_{22}x_{2} + \\cdots + a_{2n}x_{n} \u0026amp;= b_{2} \\\\ \u0026amp;\\vdots \\\\ a_{m1}x_{1} + a_{m2}x_{2} + \\cdots + a_{mn}x_{n} \u0026amp;= b_{m} \\end{aligned} \\label{linsys} \\end{equation} $$\nWhen represented as a matrix, it is as follows.\n$$ \\begin{align*} \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix} \u0026amp;= \\begin{bmatrix} b_{1} \\\\ b_{2} \\\\ \\vdots \\\\ b_{m} \\end{bmatrix} \\\\ A\\mathbf{x} \u0026amp;= \\mathbf{b} \\end{align*} $$\nExplanation The values of $x_{1}$, $x_{2}$, $\\dots$, $x_{n}$ that make the linear system true are called solutions. When a linear system is given, it must satisfy one of the following three cases. There are no other cases. The proof is introduced at the bottom of this article.\nThere is exactly one solution. There are infinitely many solutions. There is no solution. If there is at least one solution, the linear system is said to be consistent. If there is no solution, the linear system is said to be inconsistent.\nSpecifically, in the case of two variables, a linear equation means an equation of a line. If there is exactly one solution in a linear system with two variables, it means the case where the lines meet at one point. If there are infinitely many solutions, it means the case where the lines meet at infinitely many points, i.e., they overlap. If there is no solution, it means the case where there is no point where the lines meet.\nA linear equation with three variables means an equation of a plane, so depending on the solution of the linear system, it signifies how the planes overlap.\nExample Let\u0026rsquo;s solve the following linear system.\n$$ \\begin{align*} 4x -2y \u0026amp;= 1 \\\\ 16x -8y \u0026amp;= 4 \\end{align*} $$\nMultiplying the above equation by $-4$ and adding it to the below equation results in the following.\n$$ \\begin{align*} 4x -2y \u0026amp;= 1 \\\\ 0 \u0026amp;= 0 \\end{align*} $$\nThen, since the lower equation does not display any information, let\u0026rsquo;s only represent it with the upper equation.\n$$ 4x -2y = 1 $$\nIn this case, it geometrically means that the two lines coincide. In such a case, after arranging $x$ for $y$, it is denoted as $x = \\dfrac{1}{2}y + \\dfrac{1}{4}$, and then some arbitrary number $t$ is substituted into $y$ to represent the solution.\n$$ x = \\dfrac{1}{4} + \\dfrac{1}{2}t, \\quad y = t $$\nSuch $t$ is called a parameter, and the above equation is called parametric equations.\nProof2 A system of linear equations has no solution, one solution, or infinitely many solutions. There are no other cases.\nWhen there are two different solutions, the proof is completed by showing that there are infinitely many solutions. Let $\\mathbf{x}_{1}$, $\\mathbf{x}_{2}$ be two different solutions of the linear system $A\\mathbf{x} =\\mathbf{b}$. And let\u0026rsquo;s designate $\\mathbf{x}_{0} = \\mathbf{x}_{1} - \\mathbf{x}_{2}$. Since $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$ are two different solutions, $\\mathbf{x}_{0} \\ne \\mathbf{0}$. Moreover, the following equation holds:\n$$ A \\mathbf{x}_{0} = A (\\mathbf{x}_{1} - \\mathbf{x}_{2}) = \\mathbf{b} - \\mathbf{b} = \\mathbf{0} $$\nLet\u0026rsquo;s designate $k$ as an arbitrary constant. Then, by the above result, the following equation also holds:\n$$ \\begin{align*} A (\\mathbf{x}_{1} + k\\mathbf{x}_{0}) \u0026amp;= A\\mathbf{x}_{1} + A(k\\mathbf{x}_{0}) \\\\ \u0026amp;= A\\mathbf{x}_{1} + kA\\mathbf{x}_{0} \\\\ \u0026amp;= \\mathbf{b} + \\mathbf{0} \\\\ \u0026amp;= \\mathbf{b} \\end{align*} $$\nTherefore, $\\mathbf{x}_{1} + k\\mathbf{x}_{0}$ is also a solution of the linear system $A\\mathbf{x} = \\mathbf{b}$. Since this holds for any arbitrary constant $k$, there are infinitely many solutions.\n‚ñ†\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p2-6\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p62\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3013,"permalink":"https://freshrimpsushi.github.io/en/posts/3013/","tags":null,"title":"Simultaneous Linear Equations"},{"categories":"Ìï®Ïàò","contents":"Definition A function $f : X \\to Y$ is called linear if it satisfies the following two conditions for $x,x_{1},x_{2}\\in X$ and $a \\in \\mathbb{R}$,\n$f(ax) = af(x)$ $f(x_{1} + x_{2}) = f(x_{1}) + f(x_{2})$ Explanation If it is not linear, it is called nonlinear. The two conditions are sometimes combined as follows\n$$ f(ax_{1} + x_{2}) = af(x_{1}) + f(x_{2}) $$\nIf in 2., instead of being equal, it satisfies being less than or equal to $\\le$, it is called quasilinear.\nBilinear If a bivariate function $f = f(x,y)$ is linear with respect to each variable, it is called bilinear.\nMultilinear If a multivariate function $f= f(x_{1}, \\dots, x_{n})$ is linear with respect to each variable, it is called multilinear.\n","id":3037,"permalink":"https://freshrimpsushi.github.io/en/posts/3037/","tags":null,"title":"Linear Function"},{"categories":"ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç","contents":"Í∞úÏöî In this post, we\u0026rsquo;ll organize code that does the same thing in Julia, Matlab, Python, and R.\nCheat Sheet: Flux-PyTorch-TensorFlow Let\u0026rsquo;s say we have the following environment for Python.\nimport numpy as np Common Julia\rMatlab\rPython\rR\rcomment\r#comment %comment #comment #comment 2d grid\rX = kron(x, ones(size(y)))Y = kron(ones(size(x)), y) [X,Y] = meshgrid(x,y) np.meshgrid(x,y) How to create an n-dimensional meshgrid in Julia Type Julia\rMatlab\rPython\rR\rtype of elements\reltype(x) x.dtype changing type of elements\rconvert(Array{Float64},x) x.astype(\"float64\") type of x\rtypeof(x) type(x)#class of x Vector Julia\rMatlab\rPython\rR\rColumn vector\r[1 4 -1 2] [1;4;-1;2] np.array([1,4,-1,2]).reshape(-1,1) Row vector\r[1;; 4;; -1;; 2]or[1 4 -1 2]' [1 4 -1 2]or[1,4,-1,2] np.array([1,4,-1,2]) Zero vector\rzeros(n)#column vector zeros(n,1)#not zeros(n)#zeros(n)=zeros(n,n) np.zeros(n)#row vector matrix(0,n) Vector with only ones\rones(n)#column vector ones(n,1)#not ones(n)#ones(n)=ones(n,n) np.ones(n)#row vector n equally spaced sample(length)\rrange(0,stop=1,length=10)orLinRange(0,1,10) linspace(0,1,10)#row vector np.linspace(0,stop=1,num=10)#row vector n equally spaced sample(steps)\rrange(0, stop=1, step=0.1) 0 : 0.1 : 1 np.arange(0,1.001,0.1) n logarithmically spaced sample\r10 .^range(0,1,10) logspace(0,1,10)#row vector np.logspace(0,stop=1,num=10,base=10)#row vector Matrix Julia\rMatlab\rPython\rR\rzero matrix\rzeros(m,n) zeros(m,n) np.zeros([m,n]) matrix(0,m,n) flatten\rvec(x) x(:) np.ravel(x) return zeros with the same shape and dtype as a given x\rzero(x) np.zeros_like(x) return ones with the same shape and dtype as a given x\rfill!(similar(x), 1) np.ones_like(x) Ï∞®Ïõêdimensions\rndims(x) ndims(x) x.ndim ÌÅ¨Í∏∞size of matrix\rsize(x) size(x) x.shape ÏÑ±Î∂ÑÏùò Ïàònumber of elements\rlength(x) numel(x) x.size Í∞ÄÏû• ÌÅ∞ Ï∞®ÏõêÏùò Í∏∏Ïù¥length of largest dimension\rmaximum(size(x)) length(x) max(x.shape) Î¨¥ÏûëÏúÑ Ï∂îÏ∂úRandom sampling Julia\rMatlab\rPython\rR\rÍ∑†Îì±Î∂ÑÌè¨ ÎûúÎç§ Î≤°ÌÑ∞Uniformly distributed random vector rand(n)#column vector rand(n,1)#not rand(n)#rand(n)=rand(n,n) np.random.rand(n)#row vector Í∑†Îì±Î∂ÑÌè¨ ÎûúÎç§ ÌñâÎ†¨Uniformly distributed random matrix rand(m,n) rand(m,n) np.random.rand(m,n) ÌëúÏ§ÄÏ†ïÍ∑úÎ∂ÑÌè¨Normally distributed random numbers randn(m,n) randn(m,n) np.random.randn(m,n) Ìë∏Î¶¨Ïóê Î≥ÄÌôòFourier Transform Ï§ÑÎ¶¨ÏïÑÏóê ÎåÄÌï¥ÏÑú Îã§ÏùåÍ≥º Í∞ôÏùÄ ÌôòÍ≤ΩÏù¥ÎùºÍ≥† ÌïòÏûê.\nusing FFTW Julia\rMatlab\rPython\rR\rÌë∏Î¶¨Ïóê Î≥ÄÌôò Fourier transform\rfft(x) fft(x) np.fft.fft(x) fft(x) Ìë∏Î¶¨Ïóê Ïó≠Î≥ÄÌôò Inverse Fourier transform\rifft(x) ifft(x) np.fft.ifft(x) fft(y,inverse=TRUE)/length(y) Î≥¥Í∞ÑÎ≤ïInterpolation ÌååÏù¥Ïç¨Ïóê ÎåÄÌï¥ÏÑú Îã§ÏùåÍ≥º Í∞ôÏùÄ ÌôòÍ≤ΩÏù¥ÎùºÍ≥† ÌïòÏûê.\nfrom scipy.interpolate import griddata $X, Y, P, Z$Î•º 2Ï∞®Ïõê Î∞∞Ïó¥, $x, y$Î•º 1Ï∞®Ïõî Î∞∞Ïó¥Ïù¥ÎùºÍ≥† ÌïòÏûê.\nJulia\rMatlab\rPython\rR\r2Ï∞®Ïõê Î≥¥Í∞Ñ 2D interpolation\rZ=interp2(X,Y,P,x,y) Z=griddata((np.ravel(X),np.ravel(Y)),np.ravel(P),(x,y)) ÏãúÍ∞ÅÌôîVisualization Ï§ÑÎ¶¨ÏïÑÏóê ÎåÄÌï¥ÏÑú Îã§ÏùåÍ≥º Í∞ôÏùÄ ÌôòÍ≤ΩÏù¥ÎùºÍ≥† ÌïòÏûê.\nusing Plots ÌååÏù¥Ïç¨Ïóê ÎåÄÌï¥ÏÑú Îã§ÏùåÍ≥º Í∞ôÏùÄ ÌôòÍ≤ΩÏù¥ÎùºÍ≥† ÌïòÏûê.\nimport matplotlib.pyplot as plt 2Ï∞®Ïõê Ïù¥ÎØ∏ÏßÄÎ°ú Ï∂úÎ†•ÌïòÍ≥†Ïûê ÌïòÎäî Î∞∞Ïó¥ÏùÑ $A$ÎùºÍ≥† ÌïòÏûê.\nJulia\rMatlab\rPython\rR\rÏä§ÏºÄÏùº Î≤îÏúÑ ÏßÄÏ†ï Set scale range\rheatmap(A,clim=(a,b)) plt.imshow(A)plt.colorbar()plt.clim(a,b) ÏàòÌèâÏÑ† Horizon line\rhline!(a) plt.axhline(a) ÏàòÏßÅÏÑ† Vertical line\rvline!(a) plt.axvline(a) ","id":3031,"permalink":"https://freshrimpsushi.github.io/en/posts/3031/","tags":["Ï§ÑÎ¶¨ÏïÑ"],"title":"Cheat Sheet : Equivalent Codes in Julia, Matlab, Python, R"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition Unitary Matrix Let $A$ be a square complex matrix. $A$ is called a unitary matrix if it satisfies the following equation:\n$$ A^{-1}=A^{\\ast} $$\nHere, $A^{-1}$ is the inverse of $A$, $A^{\\ast}$ is the conjugate transpose of $A$.\nUnitary Diagonalization1 Consider a square matrix $A$ of size $n \\times n$. $A$ is said to be unitarily diagonalizable if it satisfies the following equation for some diagonal matrix $D$ and unitary matrix $P$:\n$$ P^{\\ast} A P = D $$\nA matrix $P$ that satisfies this condition is said to unitarily diagonalize the matrix $A$.\nDescription A unitary matrix is, simply put, an extension of the orthogonal matrix to complex matrices. Therefore, it retains the properties of an orthogonal matrix. The proof of the below equivalence conditions for a unitary matrix is replaced with the proof in Orthogonal Matrix.\nTheorem2 Equivalence Conditions for a Unitary Matrix: For a complex matrix $A$ of size $n \\times n$, the following propositions are all equivalent.\n$A$ is a unitary matrix.\nThe set of row vectors of $A$ is a normal orthogonal set in $\\mathbb{C}^n$.\nThe set of column vectors of $A$ is a normal orthogonal set in $\\mathbb{C}^n$.\n$A$ preserves the inner product. That is, for all $\\mathbf{x},\\mathbf{y}\\in \\mathbb{C}^{n}$, the following holds:\n$$ (A \\mathbf{x}) \\cdot (A\\mathbf{y}) = \\mathbf{x} \\cdot \\mathbf{y} $$\n$A$ preserves length. That is, for all $\\mathbf{x}\\in \\mathbb{C}^{n}$, the following holds: $$ \\left\\| A \\mathbf{x} \\right\\| = \\left\\| \\mathbf{x} \\right\\| $$\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p440\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p439\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3008,"permalink":"https://freshrimpsushi.github.io/en/posts/3008/","tags":null,"title":"Unitary Matrix"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Summary Let $A$ be a Hermitian matrix of size $n \\times n$. Then, the eigenvalues of $A$ are all real.\nExplanation In general, there is no guarantee that the eigenvalues of a matrix are real, but for Hermitian matrices, this can be verified through proof.\nIt may not be intuitively obvious, but the proof itself is relatively simple, and it is quite useful as a fact. It yields various good results when combined with concepts like positive-definiteness, so it is well worth knowing.\nProof Let\u0026rsquo;s say the eigenvalue of $A$ is $\\lambda$ and the corresponding eigenvector is $\\mathbf{x}$. Then, the eigenvalue equation is as follows.\n$$ A \\mathbf{x} = \\lambda \\mathbf{x} $$\nMultiplying both sides by $\\mathbf{x}^{\\ast}$ yields:\n$$ \\begin{equation} \\mathbf{x}^{\\ast} A \\mathbf{x} = \\lambda \\mathbf{x}^{\\ast} \\mathbf{x} \\end{equation} $$\nTaking the conjugate transpose $^{ \\ast }$ on both sides, by the properties of conjugate transpose, we get:\n$$ \\begin{align*} \\left( \\mathbf{x}^{\\ast} A \\mathbf{x} \\right) ^{\\ast} = \u0026amp; \\left( \\lambda \\mathbf{x}^{\\ast} \\mathbf{x} \\right) ^{\\ast} \\\\ \\implies \\mathbf{x}^{\\ast} A^{ \\ast } \\mathbf{x} = \u0026amp; \\overline{\\lambda} \\mathbf{x}^{ \\ast } \\mathbf{x} \\end{align*} $$\nSince $A$ is a Hermitian matrix, we have $A=A^{\\ast}$, and the equation can be rewritten as:\n$$ \\begin{equation} \\mathbf{x}^{\\ast} A \\mathbf{x} = \\overline{\\lambda} \\mathbf{x}^{ \\ast } \\mathbf{x} \\end{equation} $$\nBy $(1)$ and $(2)$, the following equation holds:\n$$ \\lambda \\mathbf{x}^{ \\ast } \\mathbf{x} = \\mathbf{x}^{ \\ast } A \\mathbf{x} = \\mathbf{x}^{ \\ast } A^{ \\ast } \\mathbf{x} = \\overline{\\lambda} \\mathbf{x}^{ \\ast } \\mathbf{x} $$\nTherefore, $$ ( \\lambda - \\overline{\\lambda} ) \\mathbf{x}^{ \\ast } \\mathbf{x} = 0 $$\nHowever, since $\\mathbf{x}$ is an eigenvector, it is not $\\mathbf{0}$. Therefore, $\\mathbf{x}^{\\ast} \\mathbf{x} \\ne \\mathbf{0}$ must be true. Hence,\n$$ \\lambda = \\overline{\\lambda} $$\nThis implies that $\\lambda$ is real.\n‚ñ†\nSee Also Proofs in Mathematical Physics ","id":310,"permalink":"https://freshrimpsushi.github.io/en/posts/310/","tags":null,"title":"The eigenvalues of a Hermitian matrix are always real"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition Let $A$ be a square complex matrix. If $A$ satisfies the following equation, it is called a Hermitian matrix or self-adjoint matrix.\n$$ A^{\\ast}=A $$\nHere, $A^{\\ast}$ is the conjugate transpose of $A$. If $A$ satisfies the following equation, it is called a skew-Hermitian matrix .\n$$ A^{\\ast}=-A $$\nExplanation If it is a real matrix, since $A^{\\ast}=A^{T}$, if it is a symmetric matrix, it is a Hermitian matrix. As can be seen from the following properties, the diagonal elements of a Hermitian matrix must be real. Therefore, if the matrix is small, it is easy to see at a glance whether it is a Hermitian matrix.\nFor the same reason that the diagonal elements of a Hermitian matrix must be real, the diagonal elements of a skew-Hermitian matrix are all $0$.\nProperties Let $A$ be a Hermitian matrix.\n(a) The diagonal elements of $A$ must be real.\n(b) The eigenvalues of $A$ are all real.\n(c) Eigenvectors having different eigenvalues of $A$ are orthogonal to each other.\n(b) In the context of quantum mechanics, \u0026lsquo;The expectation value of a Hermitian operator is always real\u0026rsquo;.\nProof (a) The transpose $A^{T}$ of matrix $A$ is obtained by reflecting the elements of $A$ across the main diagonal. Therefore, the diagonal elements of both matrices are always the same. This means $a_{ij}=\\overline{a_{ij}}$, so the diagonal elements are real.\n‚ñ†\n(b) (c) ","id":3007,"permalink":"https://freshrimpsushi.github.io/en/posts/3007/","tags":null,"title":"Hermitian Matrix"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition Let matrix $n\\times n$ be given as follows.\n$$ A= \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{n1} \u0026amp; a_{n2} \u0026amp; \\cdots \u0026amp; a_{nn} \\end{bmatrix} $$\nThe sum of the diagonal elements of $A$ is defined as the trace of $A$ and is denoted as follows.\n$$ \\text{tr}(A)=\\text{Tr}(A)=a_{11}+a_{22}+\\cdots + a_{nn}=\\sum \\limits_{i=1}^{n} a_{ii} $$\nExplanation The trace can also be thought of as a function as follows. Let $M_{n\\times n}(\\mathbb{R})$ be the set of $n\\times n$ matrices with real number components. Then, $\\text{Tr}$ is defined as the following function.\n$$ \\text{Tr} : M_{n\\times n} (\\mathbb{R}) \\to \\mathbb{R},\\quad \\text{Tr}(A)=\\sum \\limits_{i=1}^{n} a_{ii} $$\nProperties Let $A,B,C$ be a $n \\times n$ matrix, and let $k$ be a constant.\n(a) The trace of a scalar multiple is the same as the scalar multiple of the trace.\n$$ \\text{Tr}(kA)= k\\text{Tr}(A) $$\n(b) The trace of a sum is the same as the sum of the traces.\n$$ \\text{Tr}(A+B)=\\text{Tr}(A)+\\text{Tr}(B) $$\n(a)+(b) The trace is linear.\n$$ \\text{Tr}(kA+B)=k\\text{Tr}(A)+\\text{Tr}(B) $$\n(c) The trace of $AB$ and $BA$ is the same.\n$$ \\text{Tr}(AB) = \\text{Tr}(BA) $$\n(c\u0026rsquo;) Cyclic Property: From the above fact, it can be known that the following equation holds.\n$$ \\text{Tr}(ABC) = \\text{Tr}(BCA) = \\text{Tr}(CAB) $$\n(d) The trace of $A$ and $A^{T}$ is the same.\n$$ \\text{Tr}(A) = \\text{Tr}(A^{T}) $$\n","id":1924,"permalink":"https://freshrimpsushi.github.io/en/posts/1924/","tags":null,"title":"Trace"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition The multivariate normal distribution $N_{p} \\left( \\mu , \\Sigma \\right)$ has a probability density function based on the mean vector $\\mathbf{\\mu} \\in \\mathbb{R}^{p}$ and the covariance matrix $\\Sigma \\in \\mathbb{R}^{p \\times p}$ as follows:\n$$ f (\\textbf{x}) = \\left( (2\\pi)^{p} \\det \\Sigma \\right)^{-1/2} \\exp \\left[ - {{ 1 } \\over { 2 }} \\left( \\textbf{x} - \\mathbf{\\mu} \\right)^{T} \\Sigma^{-1} \\left( \\textbf{x} - \\mathbf{\\mu} \\right) \\right] \\qquad , \\textbf{x} \\in \\mathbb{R}^{p} $$\n$\\mathbf{x}^{T}$ denotes the transpose of $\\mathbf{x}$. Theorems $$ \\begin{align*} \\mathbf{X} =\u0026amp; \\begin{bmatrix} \\mathbf{X}_{1} \\\\ \\mathbf{X}_{2} \\end{bmatrix} \u0026amp; : \\Omega \\to \\mathbb{R}^{n} \\\\ \\mu =\u0026amp; \\begin{bmatrix} \\mu_{1} \\\\ \\mu_{2} \\end{bmatrix} \u0026amp; \\in \\mathbb{R}^{n} \\\\ \\Sigma =\u0026amp; \\begin{bmatrix} \\Sigma_{11} \u0026amp; \\Sigma_{12} \\\\ \\Sigma_{21} \u0026amp; \\Sigma_{22} \\end{bmatrix} \u0026amp; \\in \\mathbb{R}^{n \\times n} \\end{align*} $$ In the statements of the theorems below, unless otherwise specified, $\\mathbf{X}$, $\\mu$, and $\\Sigma$ refer to the same block matrix.\nLinear transformation of multivariate normal distribution The linear transformation $\\mathbf{Y} = A \\mathbf{X} + \\mathbf{b}$ of a random vector $\\mathbf{X} \\sim N_{n} \\left( \\mu , \\Sigma \\right)$ that follows a multivariate normal distribution, given matrix $A \\in \\mathbb{R}^{m \\times n}$ and vector $\\mathbf{b} \\in \\mathbb{R}^{m}$, still follows a multivariate normal distribution $N_{m} \\left( A \\mu + \\mathbf{b} , A \\Sigma A^{T} \\right)$.\nIndependence and zero correlation are equivalent in multivariate normal distributions Let there be a random vector $\\mathbf{X} \\sim N_{n} \\left( \\mu , \\Sigma \\right)$ that follows a multivariate normal distribution. Then, the following holds: $$ \\mathbf{X}_{1} \\perp \\mathbf{X}_{2} \\iff \\Sigma_{12} = \\Sigma_{21} = O $$\nConditional mean and variance of multivariate normal distribution Given a random vector $\\mathbf{X} \\sim N_{n} \\left( \\mu , \\Sigma \\right)$ that follows a multivariate normal distribution, the conditional probability vector $\\mathbf{X}_{1} | \\mathbf{X}_{2} : \\Omega \\to \\mathbb{R}^{m}$ still follows a multivariate normal distribution, specifically having the following mean vector and covariance matrix: $$ \\mathbf{X}_{1} | \\mathbf{X}_{2} \\sim N_{m} \\left( \\mu_{1} + \\Sigma_{12} \\Sigma_{22}^{-1} \\left( \\mathbf{X}_{2} - \\mu_{2} \\right) , \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21} \\right) $$\nMultivariate normality of regression coefficient vectors The estimators of regression coefficients $\\hat{\\beta}$ follow a multivariate normal distribution as follows: $$ \\hat{\\beta} \\sim N_{1+p} \\left( \\beta , \\sigma^{2} \\left( X^{T} X \\right)^{-1} \\right) $$\nMoment generating function The moment generating function of $X \\sim N_{p} \\left( \\mu , \\Sigma \\right)$ is as follows: $$ M_{X} \\left( \\mathbf{t} \\right) = \\exp \\left( \\mathbf{t}^{T} \\mu + {{ 1 } \\over { 2 }} \\mathbf{t}^{T} \\Sigma \\mathbf{t} \\right) \\qquad , \\mathbf{t} \\in \\mathbb{R}^{p} $$\nEntropy The entropy of the multivariate normal distribution $N_{p}(\\mu, \\Sigma)$ is as follows:\n$$ H = \\dfrac{1}{2}\\ln \\left[ (2 \\pi e)^{p} \\left| \\Sigma \\right| \\right] = \\dfrac{1}{2}\\ln (\\det (2\\pi e \\Sigma)) $$\n$\\left| \\Sigma \\right|$ is the determinant of the covariance matrix.\nSee Also Univariate normal distribution: When $p = 1$ followed by $\\mu \\in \\mathbb{R}^{1}$ and $\\Sigma \\in \\mathbb{R}^{1 \\times 1}$, the above probability density function exactly becomes the probability density function of the univariate normal distribution. ","id":1954,"permalink":"https://freshrimpsushi.github.io/en/posts/1954/","tags":null,"title":"Multivariate Normal Distribution"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition1 $p$-dimensional random vector $\\mathbf{X} = \\left( X_{1}, \\cdots , X_{p} \\right)$ is defined as follows for $\\text{Cov} (\\mathbf{X})$, which is called a Covariance Matrix.\n$$ \\left( \\text{Cov} \\left( \\mathbf{X} \\right) \\right)_{ij} := \\text{Cov} \\left( X_{i} , X_{j} \\right) $$\n$\\text{Cov}$ is covariance. Explanation To put the definition in simpler words, it is as follows.\n$$ \\text{Cov} \\left( \\mathbf{X} \\right) := \\begin{pmatrix} \\text{Var} \\left( X_{1} \\right) \u0026amp; \\text{Cov} \\left( X_{1} , X_{2} \\right) \u0026amp; \\cdots \u0026amp; \\text{Cov} \\left( X_{1} , X_{p} \\right) \\\\ \\text{Cov} \\left( X_{2} , X_{1} \\right) \u0026amp; \\text{Var} \\left( X_{2} \\right) \u0026amp; \\cdots \u0026amp; \\text{Cov} \\left( X_{2} , X_{p} \\right) \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ \\text{Cov} \\left( X_{p} , X_{1} \\right) \u0026amp; \\text{Cov} \\left( X_{p} , X_{2} \\right) \u0026amp; \\cdots \u0026amp; \\text{Var} \\left( X_{p} \\right) \\end{pmatrix} $$\nAll covariance matrices are positive semi-definite matrices. In other words, for all vectors $\\mathbf{x} \\in \\mathbb{R}^{p}$, the following holds true.\n$$ 0 \\le \\textbf{x}^{T} \\text{Cov} \\left( \\mathbf{X} \\right) \\textbf{x} $$\nTheorems [1]: If $\\mathbf{\\mu} \\in \\mathbb{R}^{p}$ is given as $\\mathbf{\\mu} := \\left( EX_{1} , \\cdots , EX_{p} \\right)$, $$ \\text{Cov} (\\mathbf{X}) = E \\left[ \\mathbf{X} \\mathbf{X}^{T} \\right] - \\mathbf{\\mu} \\mathbf{\\mu}^{T} $$ [2]: If a matrix of constants $A \\in \\mathbb{R}^{k \\times p}$ is given as $(A)_{ij} := a_{ij}$, $$ \\text{Cov} ( A \\mathbf{X}) = A \\text{Cov} \\left( \\mathbf{X} \\right) A^{T} $$ $A^{T}$ is the transpose of $A$. Proof [1] $$ \\begin{align*} \\text{Cov} \\left( \\mathbf{X} \\right) =\u0026amp; E \\left[ \\left( \\mathbf{X} - \\mathbf{\\mu} \\right) \\left( \\mathbf{X} - \\mathbf{\\mu} \\right)^{T} \\right] \\\\ =\u0026amp; E \\left[ \\mathbf{X} \\mathbf{X}^{T} - \\mathbf{\\mu} \\mathbf{X}^{T} - \\mathbf{X} \\mathbf{\\mu}^{T} + \\mathbf{\\mu} \\mathbf{\\mu}^{T} \\right] \\\\ =\u0026amp; E \\left[ \\mathbf{X} \\mathbf{X}^{T} \\right] - \\mathbf{\\mu} E \\left[ \\mathbf{X}^{T} \\right] - E \\left[ \\mathbf{X} \\right] \\mathbf{\\mu}^{T} + E \\left[ \\mathbf{\\mu} \\mathbf{\\mu}^{T} \\right] \\\\ =\u0026amp; E \\left[ \\mathbf{X} \\mathbf{X}^{T} \\right] - \\mathbf{\\mu} \\mathbf{\\mu}^{T} \\end{align*} $$\n‚ñ†\n[2] 2 $$ \\begin{align*} \\text{Cov} \\left( A \\mathbf{X} \\right) =\u0026amp; E \\left[ \\left( A\\mathbf{X} - A\\mathbf{\\mu} \\right) \\left( A\\mathbf{X} - A\\mathbf{\\mu} \\right)^{T} \\right] \\\\ =\u0026amp; E \\left[ A\\left(\\mathbf{X} -\\mathbf{\\mu} \\right) \\left( \\mathbf{X} - \\mathbf{\\mu} \\right)^{T} A^{T} \\right] \\\\ =\u0026amp; A E \\left[ \\left(\\mathbf{X} -\\mathbf{\\mu} \\right) \\left( \\mathbf{X} - \\mathbf{\\mu} \\right)^{T}\\right] A^{T} \\\\ =\u0026amp; A \\text{Cov}\\left( \\mathbf{X} \\right) A^{T} \\end{align*} $$\n‚ñ†\nHogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p126.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stats.stackexchange.com/a/106207/172321\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1950,"permalink":"https://freshrimpsushi.github.io/en/posts/1950/","tags":null,"title":"Covariance Matrix"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Definition Reinforcement learning is the process where an agent interacts with the environment to find a policy that maximizes the cumulative reward.\nDescription1 The elements comprising reinforcement learning are as follows:\nAgentagent: Decides actions based on a policy, given a state. Statestate: Refers to the situation in which the agent is placed. Actionaction: Refers to the choices available to the agent in a given state. Policypolicy: Refers to the strategy according to which the agent decides its actions in a given state. Rewardreward: Refers to the score the agent receives based on the actions it chooses in a given state. It can be considered the goal the agent aims to achieve. Environmentenvironment: When the agent decides an action in a given state, according to the MDP (Markov Decision Process), the next state and the corresponding reward are determined. Episodeepisode: Refers to the period from when the interaction between the agent and the environment begins to when it ends. This can be analogized in various scenarios as follows:\nReinforcement Learning Studying for Exams Go Game Agent Student Go Player State Days Left Until Exam Go Board Action Study, Drinking, Gaming, etc. Placing a Stone Policy Study Plan per Day Strategy Reward Exam Score Win/Loss Episode Exam Period One Game Problem of Reinforcement Learning: Grid Model A typical example to explain reinforcement learning is the grid world. Let\u0026rsquo;s consider a robot that can move one square at a time in four directions: up, down, left, and right, in the following $4 \\times 4$ grid. The starting square is randomly chosen from $\\boxed{\\ 2\\ }$ to $\\boxed{15}$, and the goal is to reach $\\fcolorbox{black}{darkgray}{\\ 1\\ }$ or $\\fcolorbox{black}{darkgray}{16}$ in the shortest distance possible.\nAgent In reinforcement learning, the agent is the subject of learning, although it does not exist in reality. Unlike other concepts defined later, such as random variables, the agent does not have a clear mathematical definition. Therefore, it\u0026rsquo;s possible to study the theory of reinforcement learning without the concept of an agent, and indeed, this is often the case. Essentially, in the theory of reinforcement learning, the policy is what represents the agent. However, for convenience, it\u0026rsquo;s common to think of the learning subject as an entity and express it as 'the agent acts', 'the state of the agent has changed', etc. The agent is merely something that appears to be learning in computer simulations (especially games). For instance, the movement of an agent in the grid model can be expressed simply as a sequence of states. $$ \\boxed{\\ 3\\ } \\to \\boxed{\\ 2\\ } \\to \\fcolorbox{black}{darkgray}{\\ 1\\ } $$ You only need to print the sequence $3, 2, 1$. Ultimately, what we want to obtain from reinforcement learning is essentially a policy, so learning can occur even without defining an agent. In short, an agent can be considered the visualization (materialization) of a policy.\nOf course, the above is true in theory and computer simulations. In actual applications such as autonomous driving, there is a need for drones or cars that move according to policies. In this case, robots or machines like drones and cars become agents, and without them, learning the policy would be impossible.\nState The statestate is a random variable, denoted by $S$. As the episode progresses sequentially over time, we use the index $t$ for time. Hence, the state function at time $t$ is denoted as $S_{t}$. The initial state is usually represented as $t=0$. Summarizing, $S_{t}$ is a function that gives function values for each of the squares at time $t$.\n$$ S_{t} \\left( \\boxed{ N } \\right) = n,\\quad 1\\le n \\le 16 $$\nIn this case, the set of all possible state values (the function values of the state function) is denoted as $\\mathcal{S}\\subset \\mathbb{R}$, and its elements are denoted as $s$.\n$$ \\mathcal{S} = \\left\\{ s_{1}, s_{2},\\dots \\right\\} $$\nTherefore, the state function for the above grid model is as follows.\n$$ S_{t} : \\left\\{ \\fcolorbox{black}{darkgray}{\\ 1\\ } , \\boxed{\\ 2\\ }, \\dots, \\boxed{15}, \\fcolorbox{black}{darkgray}{16} \\right\\} \\to \\mathcal{S} \\\\ S_{t} \\left( \\boxed{\\ n\\ } \\right) = s_{n} = n,\\quad 1\\le n \\le 16 $$\nThen, the probability that the state value at time $t$ was $s_6$ and changes to $s_{10}$ in the next time step is as follows.\n$$ P \\left( S_{t+1} = s_{10} | S_{t} = s_{6} \\right) $$\nA state where the episode ends once reached is called a terminal state. In the above grid model, the terminal states are $\\fcolorbox{black}{darkgray}{1}, \\fcolorbox{black}{darkgray}{16}$.\nAction The actionaction refers to the choices the agent can make in the current state, and it is also a random variable. Denoted as $A_{t}$, it represents the action at time $t$. In the grid model example above, one can choose up, down, left, or right in each of the squares from $\\boxed{2}$ to $\\boxed{15}$. The set of all possible action values (the function values of the action function) is denoted as $\\mathcal{A}\\subset \\mathbb{R}$, and its elements are denoted as $a$.\n$$ \\mathcal{A} = \\left\\{ a_{1}, a_{2}, \\dots \\right\\} $$\nThen, the action function at time $t$ is as follows.\n$$ A_{t} : \\left\\{ \\uparrow, \\rightarrow, \\downarrow, \\leftarrow \\right\\} \\to \\mathcal{A} \\\\ \\begin{cases} A_{t}(\\uparrow) = a_{1} \\\\ A_{t}(\\rightarrow) = a_{2} \\\\ A_{t}(\\downarrow) = a_{3} \\\\ A_{t}(\\leftarrow) = a_{4} \\end{cases} $$\nThe agent decides its actions based on probabilities given the current state. For example, the probability of choosing action $a_1$ in state $s_6$ at time $t$ is as follows.\n$$ P(A_{t} = a_{1} | S_{t} = s_{6}) $$\nPolicy The policypolicy specifies the probability of deciding action $a$ in state $s$ for all $s$ and $a$, denoted as $\\pi$. It\u0026rsquo;s analogous to a strategy in a game or war. In the grid model example, if the probability of deciding each action is $\\dfrac{1}{4}$, the policy $\\pi$ is as follows.\n$$ \\pi \\begin{cases} P(a_{1} | s_{2}) = \\dfrac{1}{4} \\\\ P(a_{2} | s_{2}) = \\dfrac{1}{4} \\\\ P(a_{3} | s_{2}) = \\dfrac{1}{4} \\\\ \\vdots \\\\ P(a_{2} | s_{15}) = \\dfrac{1}{4} \\\\ P(a_{3} | s_{15}) = \\dfrac{1}{4} \\\\ P(a_{4} | s_{15}) = \\dfrac{1}{4} \\end{cases} \\quad \\text{or} \\quad \\pi : \\mathcal{S} \\times \\mathcal{A} \\to [0,1] $$\nOf course, this is not an optimized policy. Considering just the case of $\\boxed{2}$, it\u0026rsquo;s better not to have any probability of going upwards as it would go out of the grid. Therefore, $\\pi_2$ can be said to be a better policy than $\\pi_1$ as shown in the illustration below.\nThe goal of reinforcement learning algorithms is to find the optimal policy. The question then arises, how do we find the optimal policy? It can be found through the value functionvalue function, which evaluates the quality of a policy.\nReward The rewardreward is a function that maps a real number based on the action chosen by the agent in a given state, denoted as $R_t$. The set of all reward values (the function values of the reward function) is denoted as $\\mathcal{R} \\subset \\mathbb{R}$, and its elements are denoted as $r$.\n$$ \\mathcal{R} = \\left\\{ r_{1}, r_{2}, \\dots \\right\\} \\\\ R_{t} = \\mathcal{S} \\times \\mathcal{A} \\to \\mathcal{R} $$\nA reward is received once at each time step, and the ultimate goal of reinforcement learning is to find a policy that maximizes the cumulative reward, the total reward received in an episode.\nOne might wonder why we focus on maximizing cumulative rewards rather than rewards at each time step. This can be easily understood through the analogy of studying for exams. During the exam period, spending every evening drinking and partying or playing games might be more enjoyable than studying. However, the cumulative reward, i.e., the exam score, would be terrible. Hence, even if studying is tiring and challenging in the moment, it\u0026rsquo;s considered better for the sake of future greater rewards.\nThe reward is a hyperparameter set by a person and should be appropriately decided based on the task the agent must perform. For instance, in the grid model example, if the grid is a maze and the agent is a robot escaping the maze, a reward of $-1$ for moving one square and a reward of $+10$ for reaching a terminal state can be set. If the grid is a park and the agent is a robot walking a pet, a reward of $0$ for moving one square and a reward of $+10$ for reaching a terminal state can be set.\nEnvironment The environmentenvironment is a function that decides the next state and reward based on the action chosen by the agent in a given state, i.e., $f : (s,a) \\mapsto (s^{\\prime},r)$. Therefore, it\u0026rsquo;s always challenging to find a perfect analogy in reality.\nLet\u0026rsquo;s say the state at time $t$ is $s_{t}$, and the action chosen at $s_{t}$ is $a_t$. Then, the next state\ndecided by the environment is $s_{t+1}$, and the reward is $r_{t+1}$. It can be represented as follows.\n$$ f(s_{t}, a_{t}) = (s_{t+1}, r_{t+1}) $$\nIf in the grid model example, the agent chose $\\uparrow$ at $\\boxed{7}$ and the environment decided the next state to be $\\boxed{3}$ and the reward to be $-1$, it can be expressed with the following formula.\n$$ f(s_{7}, a_{1}) = (s_{3}, -1) $$\nIf the strategy by which the agent decides actions is called a policy, the environment\u0026rsquo;s decision of the next state and reward is called the MDPmarkov decision process. The interaction between the agent and the environment can be illustrated as follows.\nEpisode The sequence of states, actions, and rewards determined by the interaction between the agent and the environment is called a trajectory or history. When the trajectory is finite, it\u0026rsquo;s referred to as an episode task. The exam period, Go game, and grid model examples mentioned earlier fall into this category.\n$$ s_{0}, a_{0}, s_{1}, r_{1}, a_{1}, s_{2}, r_{2}, \\dots, a_{T-1}, s_{T}, r_{T} \\\\ \\text{or} \\\\ (s_{0},) \\overset{a_{0}}{\\to} (s_{1}, r_{1}) \\overset{a_{1}}{\\to} (s_{2}, r_{2}) \\overset{a_{2}}{\\to} \\cdots \\overset{a_{T-1}}{\\to} (s_{T}, r_{T}) $$\nWhen the trajectory is infinite, it\u0026rsquo;s referred to as a continuing task. However, very long episodes are sometimes considered infinite.\n$$ s_{0}, a_{0}, s_{1}, r_{1}, a_{1}, s_{2}, r_{2}, \\dots, a_{t-1}, s_{t}, r_{t}, a_{t}, s_{t+1}, r_{t+1},\\dots \\\\ \\text{or} \\\\ (s_{0},) \\overset{a_{0}}{\\to} (s_{1}, r_{1}) \\overset{a_{1}}{\\to} (s_{2}, r_{2}) \\overset{a_{2}}{\\to} \\cdots \\overset{a_{t-1}}{\\to} (s_{t}, r_{t}) \\overset{a_{t}}{\\to} (s_{t+1}, r_{t+1}) \\overset{a_{t+1}}{\\to} \\cdots $$\nO Il-Seok, Machine Learning (MACHINE LEARNING). 2017, p466-480\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3029,"permalink":"https://freshrimpsushi.github.io/en/posts/3029/","tags":null,"title":"What is Reinforcement Learning in Machine Learning"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Theorem 1 If $\\left\\{ X_{k} \\right\\}_{k=1}^{n}$ are iid random variables following the probability distribution $\\left( \\mu, \\sigma^2 \\right) $, then when $n \\to \\infty$ $$ \\sqrt{n} {{ \\overline{X}_n - \\mu } \\over {\\sigma}} \\overset{D}{\\to} N (0,1) $$\n$\\overset{D}{\\to}$ means convergence in distribution. Explanation This theorem is widely acclaimed in statistics, along with the Law of Large Numbers. Despite being frequently discussed and applied, many encounter its proof only upon studying mathematical statistics. However, the proof itself is interesting, making the theorem even more valuable.\nProof Strategy: Use tricks involving the moment generating function and Taylor\u0026rsquo;s theorem.\nFirstly, assume that the moment generating function $M(t) = E(e^{t Y}), -h\u0026lt;t\u0026lt;h$ of $\\displaystyle Y := \\sqrt{n} {{ \\overline{X}_{n} - \\mu } \\over { \\sigma }}$ exists. By defining a new function $m(t) := E[e^{t(X-\\mu)}] = e^{-\\mu t} M(t)$, $$ \\begin{align*} M(t) =\u0026amp; E \\left( e^{ t \\sqrt{n} {{ \\overline{X}_n - \\mu } \\over {\\sigma}} } \\right) \\\\ =\u0026amp; E \\left( e^{ t {{ \\sum_{i=1}^{n} X_i - n \\mu } \\over {\\sigma \\sqrt{n} }} } \\right) \\\\ =\u0026amp; E \\left( e^{ t {{ X_1 - \\mu } \\over {\\sigma \\sqrt{n} }} } \\right) E \\left( e^{ t {{ X_2 - \\mu } \\over {\\sigma \\sqrt{n} }} } \\right) \\cdots E \\left( e^{ t {{ X_n - \\mu } \\over {\\sigma \\sqrt{n} }} } \\right) \\\\ =\u0026amp; E \\left( e^{ t {{ X - \\mu } \\over {\\sigma \\sqrt{n} }} } \\right) E \\left( e^{ t {{ X - \\mu } \\over {\\sigma \\sqrt{n} }} } \\right) \\cdots E \\left( e^{ t {{ X - \\mu } \\over {\\sigma \\sqrt{n} }} } \\right) \\\\ =\u0026amp; { \\left\\{ E \\left( e^{ t {{ X - \\mu } \\over {\\sigma \\sqrt{n} }} } \\right) \\right\\} }^n \\\\ =\u0026amp; { \\left\\{ m \\left( { {t} \\over {\\sigma \\sqrt{n} } } \\right) \\right\\} } ^{n} \\qquad , -h \u0026lt; { {t} \\over {\\sigma \\sqrt{n} } } \u0026lt; h \\end{align*} $$\nTaylor\u0026rsquo;s theorem: If the function $f(x)$ is continuous at $[a,b]$ and differentiable up to $n$ times at $(a,b)$, then for $x_{0} \\in (a,b)$, there exists $\\xi \\in (a,b)$ such that $\\displaystyle f(x) = \\sum_{k=0}^{n-1} {{( x - x_{0} )^{k}\\over{ k! }}{f^{(k)}( x_{0} )}} + {(x - x_{0} )^{n}\\over{ n! }}{f^{(n)}(\\xi)}$ is satisfied.\nApplying Taylor\u0026rsquo;s theorem to $n=2$ reveals that there exists $\\xi$ satisfying either $(-t,0)$ or $(0,t)$. Hence, $m(t)$ can be expressed as $$ m(t) = m(0) + m ' (0)t + { {m '' (\\xi) t^2} \\over {2} } $$ Meanwhile, $$ \\begin{cases} m(0)=1 \\\\ m ' (0) = E(X-\\mu) = 0 \\\\ m '' (0) = E[(X-\\mu)^2] = {\\sigma}^2 \\end{cases} $$ thus $\\displaystyle m(t) = 1 + { {m '' (\\xi) t^2} \\over {2} }$. Here comes the trick: by adding and then subtracting $\\displaystyle {{\\sigma^2 t^2} \\over {2}}$ on the right side, $$ m(t) = 1 + { { \\sigma^2 t^2} \\over {2} } + { { [ m '' (\\xi) - \\sigma^2 ] t^2} \\over {2} } $$ In other words, $$ M(t) = { \\left\\{ m \\left( { {t} \\over {\\sigma \\sqrt{n} } } \\right) \\right\\} } ^{n} = { \\left\\{ 1 + { { t^2} \\over {2n} } + { { [ m '' (\\xi) - \\sigma^2 ] t^2} \\over {2n \\sigma^2 } } \\right\\} } ^{n} $$\nAccording to Taylor\u0026rsquo;s theorem, since $\\xi$ lies between $\\displaystyle \\left( -{ {t} \\over {\\sigma \\sqrt{n} } },0 \\right)$ and $\\displaystyle \\left( 0,{ {t} \\over {\\sigma \\sqrt{n} } } \\right) $, when $n \\to \\infty$, $\\xi \\to 0$; thus, $ m '' (\\xi) \\to m '' (0) = \\sigma^2$. By eliminating the terms that converge to\n$$ \\lim _{n \\to \\infty} M(t) = \\lim _{n \\to \\infty} \\left( 1 + { { t^2} \\over {2n} } \\right)^{n} = e^{t^2 / 2} $$\nwhere $e^{t^2 / 2}$ is the moment generating function of the standard normal distribution,\n$$ \\sqrt{n} {{ \\overline{X}_n - \\mu } \\over {\\sigma}} \\overset{D}{\\to} N (0,1) $$\n‚ñ†\nHogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): 313~315.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":43,"permalink":"https://freshrimpsushi.github.io/en/posts/43/","tags":null,"title":"Central Limit Theorem Proof"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition Let $A$ be a square real matrix. $A$ is called an orthogonal matrix if it satisfies the following equation:\n$$ A^{-1} = A^{T} $$\nAnother way to express this condition is as follows:\n$$ AA^{T} = A^{T}A =I $$\nExplanation To put the definition in words, an orthogonal matrix is a matrix whose row vectors or column vectors are orthogonal unit vectors to each other. When extended to complex matrices, it is called a unitary matrix. A concrete example of an orthogonal matrix is the rotation matrix. The transformation that rotates a vector in the 2D plane counterclockwise by $\\theta$ is as follows:\n$$ A = \\begin{bmatrix} \\cos \\theta \u0026amp; -\\sin \\theta \\\\ \\sin \\theta \u0026amp; \\cos \\theta \\end{bmatrix} $$\nFrom the following formula, it can be seen that the rotation transformation is an orthogonal matrix for any $\\theta$.\n$$ A^{T} A = \\begin{bmatrix} \\cos \\theta \u0026amp; -\\sin \\theta \\\\ \\sin \\theta \u0026amp; \\cos \\theta \\end{bmatrix} \\begin{bmatrix} \\cos \\theta \u0026amp; \\sin \\theta \\\\ -\\sin \\theta \u0026amp; \\cos \\theta \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{bmatrix} = I $$\nProperties The transpose of an orthogonal matrix is an orthogonal matrix.\nThe inverse of an orthogonal matrix is an orthogonal matrix.\nThe product of two orthogonal matrices is an orthogonal matrix.\nThe determinant of an orthogonal matrix is either $1$ or $-1$.\n$$ \\det(A)=\\pm 1 $$\nEquivalent Conditions for an Orthogonal Matrix For a real matrix $A$, the following propositions are all equivalent:\n$A$ is an orthogonal matrix.\nThe set of row vectors of $A$ forms a(n) $\\mathbb{R}^n$ orthonormal set.\nThe set of column vectors of $A$ forms a(n) $\\mathbb{R}^n$ orthonormal set.\n$A$ preserves inner product. That is, for all $\\mathbf{x},\\mathbf{y}\\in \\mathbb{R}^{n}$, the following holds:\n$$ (A \\mathbf{x}) \\cdot (A\\mathbf{y}) = \\mathbf{x} \\cdot \\mathbf{y} $$\n$A$ preserves length. That is, for all $\\mathbf{x}\\in \\mathbb{R}^{n}$, the following holds: $$ \\left\\| A \\mathbf{x} \\right\\| = \\left\\| \\mathbf{x} \\right\\| $$\n","id":3009,"permalink":"https://freshrimpsushi.github.io/en/posts/3009/","tags":null,"title":"Orthogonal Matrix"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition: Inner Product of Two Column Vectors1 The inner product of two column vectors of size $n \\times 1$, $\\mathbf{u}$, $\\mathbf{v}$ $\\in \\mathbb{R}^{n}$ is defined as follows.\n$$ \\begin{equation} \\mathbf{u} \\cdot \\mathbf{v} := \\mathbf{u}^{T}\\mathbf{v}=u_{1}v_{1} + u_{2}v_{2} + \\cdots + u_{n}v_{n} \\label{EuclideanIP} \\end{equation} $$\nIn the case where $\\mathbf{u}$, $\\mathbf{v}$ $\\in \\mathbb{C}^{n}$, it is as follows.\n$$ \\mathbf{u} \\cdot \\mathbf{v} := \\mathbf{u}^{\\ast}\\mathbf{v}=u^{\\ast}_{1}v_{1}^{\\ } + u_{2}^{\\ast}v_{2}^{\\ } + \\cdots + u_{n}^{\\ast}v_{n}^{\\ } $$\nHere, $\\mathbf{u}$ is the conjugate transpose of $\\mathbf{u}$. Two vectors $\\mathbf{u}$, $\\mathbf{v}$ are said to be orthogonal to each other if they satisfy the following equation, and it is denoted as $\\mathbf{u} \\perp \\mathbf{v}$.\n$$ \\mathbf{u} \\cdot \\mathbf{v} = 0 $$\nThe norm or length of the column vector $\\mathbf{v}$ is defined as follows.\n$$ \\left\\| \\mathbf{v} \\right\\| := \\sqrt{\\mathbf{v} \\cdot \\mathbf{v}} $$\nA vector with norm $1$ is called a unit vecter. The distance between two vectors $\\mathbf{u}$, $\\mathbf{v}$ is represented as $d(\\mathbf{u}. \\mathbf{v})$ and defined as follows.\n$$ d(\\mathbf{u}, \\mathbf{v}) := \\left\\| \\mathbf{u} - \\mathbf{v} \\right\\| = \\sqrt{(\\mathbf{u}-\\mathbf{v}) \\cdot (\\mathbf{u}-\\mathbf{v})} = \\sqrt{(\\mathbf{u}-\\mathbf{v})^{\\ast} (\\mathbf{u}-\\mathbf{v})} $$\nExplanation In coordinate space, the inner product of two vectors is nothing but its representation as a matrix multiplication and its expansion to complex numbers. Therefore, $\\eqref{EuclideanIP}$ is called the Euclidean inner product or standard inner product. Thus, the notation $\\cdot$ is used for the inner product, but the general notation for the inner product is as follows.\n$$ \\left\\langle \\mathbf{u}, \\mathbf{v} \\right\\rangle $$\nBy definition, in the case of real matrices, $\\mathbf{u} \\cdot \\mathbf{v} = \\mathbf{v} \\cdot \\mathbf{u}$ holds, and in the case of complex matrices, $\\mathbf{u} \\cdot \\mathbf{v} = \\overline{\\mathbf{v} \\cdot \\mathbf{u}}$ holds.\nThe core concept of the inner product is \u0026lsquo;multiply the same components and sum them all,\u0026rsquo; which generalized for $n\\times n$ matrix is as follows.\nProperties Let $A$ be a $n\\times n$ real matrix and $\\mathbf{u},\\mathbf{v}$ a $n\\times 1$ real matrix. Then, the following equation holds.\n$$ \\begin{align*} A \\mathbf{u} \\cdot \\mathbf{v} \u0026amp;= \\mathbf{u} \\cdot A^{T} \\mathbf{v} \\\\ \\mathbf{u} \\cdot A \\mathbf{v} \u0026amp;= A^{T} \\mathbf{u} \\cdot \\mathbf{v} \\end{align*} $$\nIn the case of complex matrices, the following equation holds.\n$$ \\begin{align*} A \\mathbf{u} \\cdot \\mathbf{v} \u0026amp;= \\mathbf{u} \\cdot A^{\\ast} \\mathbf{v} \\\\ \\mathbf{u} \\cdot A \\mathbf{v} \u0026amp;= A^{\\ast} \\mathbf{u} \\cdot \\mathbf{v} \\end{align*} $$\nProof Since the method of proving the four formulas is the same, only the proof of the first formula is introduced.\nBy the properties of the transpose matrix, the following holds.\n$$ \\begin{align*} A \\mathbf{u} \\cdot \\mathbf{v} \u0026amp;= \\left( A \\mathbf{u} \\right)^{T} \\mathbf{v} \\\\ \u0026amp;= \\left( \\mathbf{u}^{T} A^{T} \\right) \\mathbf{v} \\\\ \u0026amp;= \\mathbf{u}^{T} \\left( A^{T} \\mathbf{v} \\right) \\\\ \u0026amp;= \\mathbf{u} \\cdot A^{T} \\mathbf{v} \\end{align*} $$\n‚ñ†\nSee Also General Definition of Inner Product General Definition of Norm General Definition of Distance Relationship between Inner Product, Norm, and Distance Howard Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p342\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3011,"permalink":"https://freshrimpsushi.github.io/en/posts/3011/","tags":null,"title":"Matrix Inner Product"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Definition Given open sets $A \\subset \\mathbb{C}$ and $f: A \\to \\mathbb{C}$, let us assume $\\alpha \\in A$.\nIf $\\displaystyle \\lim_{z \\to \\alpha } f(z) = f (\\alpha)$, then $f$ is said to be continuous at $\\alpha$, and if $f$ is continuous at every point in the complex domain $\\mathscr{R}$, then $f$ is said to be continuous on $\\mathscr{R}$. Especially, if $f$ is continuous throughout its domain, it is called a continuous function1.\nThe derivative of $f$ at $\\alpha$ is defined as following, and if the derivative exists at $\\alpha$, $f$ is said to be differentiable at $\\alpha$. $$ f ' (\\alpha) := \\lim_{h \\to 0} {{ f ( \\alpha + h ) - f ( \\alpha ) } \\over { h }} $$ Wherein $h \\in \\mathbb{C}$, it should be independent of the direction in the complex plane.\nIf $f$ is differentiable at every point in the complex domain $\\mathscr{R}$, then $f$ is said to be analytic on $\\mathscr{R}$. In particular, if $f:\\mathbb{C} \\to \\mathbb{C}$ is analytic at $\\mathbb{C}$, it is called an Entire function2.\nExplanation Unlike functions with the real number set $\\mathbb{R}$ as a domain, functions with $\\mathbb{C}$ as a domain generally do not carry the same geometric meaning. However, there is no reason why differentiation in complex analysis should not be referred to as differentiation in the formal definition. Of course, if we consider $\\mathbb{C} \\simeq \\mathbb{R}^{2}$ as the complex plane, it can still be seen as having a similar meaning to the slope. Analytic functions are also referred to as Regular Functions or Holomorphic Functions. However, the term \u0026ldquo;analytic function\u0026rdquo; is most commonly used, referring to the conditions for analytic continuation. The question \u0026ldquo;Why are these functions called analytic functions instead of simply differentiable functions?\u0026rdquo; may include the perspective from the time when complex analysis was developing. As mentioned, the concept of differentiation in the complex plane is just a formal definition and perhaps was meant not to be thought of in the same way as we considered in the real number space $\\mathbb{R}$. Osborne (1999). Complex variables and their applications: p39.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOsborne (1999). Complex variables and their applications: p50.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1929,"permalink":"https://freshrimpsushi.github.io/en/posts/1929/","tags":null,"title":"Analytic Functions"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition Let $A$ be a complex matrix of size $m \\times n $. Define $\\overline{A}$ as follows, and call it the conjugate matrix of $A$.\n$$ \\overline{A} :=\\begin{bmatrix} \\overline{a_{11}} \u0026amp; \\overline{a_{12}} \u0026amp; \\cdots \u0026amp; \\overline{a_{1n}} \\\\ \\overline{a_{21}} \u0026amp; \\overline{a_{22}} \u0026amp; \\cdots \u0026amp; \\overline{a_{2n}} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ \\overline{a_{m1}} \u0026amp; \\overline{a_{m2}} \u0026amp; \\cdots \u0026amp; \\overline{a_{mn}} \\end{bmatrix} = \\left[ \\overline{a_{ij}} \\right] $$\nHere, $\\overline{a}$ is the conjugate complex number of $a$. In other words, a matrix whose elements are the conjugate complex numbers of the elements of another matrix is called a conjugate matrix. Let $A$ be a complex matrix of size $m\\times n$ again. Define $A^{\\ast}$ as follows, and call it the conjugate transpose of $A$.\n$$ A^{\\ast} := \\overline{A^{T}} = \\left( \\overline{A} \\right) ^{T} $$\nDescription In addition to $A^{\\ast}$, other notations used are $A^{\\dagger}$ and $A^{H}$. $A^{\\dagger}$ is read as [Adagger], and $H$ of $A^{H}$ comes from the Hermitian matrix. In physics, especially in quantum mechanics, $A^{\\ast}$ is sometimes used only in the sense of a conjugate matrix. Thus, it is denoted as $A^{\\dagger}=(A^{\\ast})^{T}$. Meanwhile, in numerical linear algebra and elsewhere, $A^{\\dagger}$ is used as the notation for a \u0026lsquo;pseudoinverse\u0026rsquo;, which acts like an inverse matrix, though it is not actually one. Given the wide use of linear algebra, resolving such notation issues requires one to stay focused and closely follow the subject being studied at the time.\nProperties1 Let $A,B$ be any complex matrix, and let $k\\in \\mathbb{C}$.\n(a) $\\overline{\\overline{A}}=A$\n(b) $\\overline{(AB)} = \\overline{A}\\ \\overline{B}$\n(c) $(A^{\\ast})^{\\ast}=A$\n(d) $\\left( A \\pm B\\right)^{\\ast} = A^{\\ast} \\pm B^{\\ast}$\n(e) $(kA)^{\\ast}=\\overline{k}A^{\\ast}$\n(f) $\\left( AB \\right)^{\\ast} = B^{\\ast} A^{\\ast}$\nProof (a) (b) Obvious from the properties of conjugate complex numbers and the definition of matrix multiplication.\n‚ñ†\n(c) (d) (e) Proven by (a), properties of the transpose matrix $ \\left( A^{T} \\right) ^{T} = A $ , and the definition of matrix addition.\n‚ñ†\n(f) Proven by (b), properties of the transpose matrix $\\left( AB \\right) ^{T} = B^{T} A^{T}$.\n‚ñ†\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p437\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3006,"permalink":"https://freshrimpsushi.github.io/en/posts/3006/","tags":null,"title":"Conjugate Transpose Matrix"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 A square matrix $A$ is called a symmetric matrix if it satisfies the following equation:\n$$ A=A^{T} $$\nHere, $A^{T}$ is the transpose of $A$. $A$ is called an anti-symmetric matrix if it satisfies the following equation:\n$$ A =-A^{T} $$\nExplanation By the definition of the transpose, matrices that are not square cannot be symmetric or anti-symmetric. If $A$ is an anti-symmetric matrix, it follows from the definition that $a_{ii}=-a_{ii}$, so the diagonal elements must be $0$.\nProperties Let $A$ and $B$ be symmetric matrices of the same size, and let $k$ be an arbitrary constant.\n(a) $A^{T}$ is a symmetric matrix.\n(b) $A \\pm B$ is a symmetric matrix.\n(c) $kA$ is a symmetric matrix.\n(d) If $A$ is invertible, then $A^{-1}$ is also a symmetric matrix.\n(e) Let $A$ be the matrix $m \\times n$. Then $AA^{T}$ is an $m \\times m$ symmetric matrix, and $A^{T}A$ is an $n \\times n$ symmetric matrix.\n(f) If $A$ is invertible, then $A^{T}A$ and $AA^{T}$ are also invertible.\nProof (d) Let $A$ be an invertible matrix. Then $(A^{T})^{-1} = (A^{-1})^{T}$ applies, and thus $A^{-1}$ is also a symmetric matrix.\n‚ñ†\n(e) Let $A$ be the matrix $m \\times n$. Then the size of $AA^{T}$ is $(m \\times \\cancel{n} ) \\times (\\cancel{n} \\times m) = m \\times m$, and by the properties of transpose, the following holds:\n$$ (AA^{T})^{T}=AA^{T} $$\nTherefore, $AA^{T}$ is a symmetric matrix. The proof for $A^{T}A$ is the same.\n‚ñ†\n(f) By the properties of invertible matrices, if $A$ is invertible, then $A^{T}$ is also invertible, and the product of invertible matrices is invertible, therefore $AA^{T}$, $A^{T}A$ are also invertible.\n‚ñ†\nTheorem The necessary and sufficient condition for the product of two matrices to be symmetric is that the product of the two matrices is commutable.\nKeep in mind that the product of two matrices is generally not commutable.\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p72-74\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3005,"permalink":"https://freshrimpsushi.github.io/en/posts/3005/","tags":null,"title":"Symmetric Matrices, Skew-Symmetric Matrices"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Theorem If $T_n \\sim t(n)$ then $$ T_n \\ \\overset{D}{\\to} N(0,1) $$\n$N \\left( \\mu , \\sigma^{2} \\right)$ is a normal distribution with mean $\\mu$ and variance $\\sigma^{2}$. $t(r)$ is a t-distribution with degrees of freedom $r$. $\\overset{D}{\\to}$ respectively imply distribution convergence. Originally, the Student t-distribution was created for statistical analysis when the sample size is small. As the sample size increases, it becomes similar to the standard normal distribution, which in statistical terms is said to converge. Thus, without any special process, simply having a large sample induces the standard normal distribution.\nDerivation Definition of the t-distribution: For degrees of freedom $\\nu \u0026gt; 0$, the following probability density function defines a continuous probability distribution $t \\left( \\nu \\right)$ as the t-distribution. $$ f(x) = {{ \\Gamma \\left( {{ \\nu + 1 } \\over { 2 }} \\right) } \\over { \\sqrt{\\nu \\pi} \\Gamma \\left( {{ \\nu } \\over { 2 }} \\right) }} \\left( 1 + {{ x^{2} } \\over { \\nu }} \\right)^{- {{ \\nu + 1 } \\over { 2 }}} \\qquad ,x \\in \\mathbb{R} $$\nDefinition of the standard normal distribution: The following probability density function defines a normal distribution $N \\left( 0,1^{2} \\right)$ as the standard normal distribution. $$ f(z) = {{ 1 } \\over { \\sqrt{2 \\pi} }} \\exp \\left[ - {{ z^{2} } \\over { 2 }} \\right] $$\n$$ F_n(t) = \\int_{-\\infty}^{t} {{\\Gamma ( (n+1)/2 ) } \\over { \\sqrt{\\pi n} \\Gamma (n/2) }} { {1} \\over {(1 + y^{2} / n)^{(n+1)/2} } } dy $$ The cumulative distribution function of $T_n$ is given as above. Due to the continuity of $F_{n}$, $$ \\lim_{n \\to \\infty} F_n (t) = \\lim_{n \\to \\infty} \\int_{-\\infty}^{t} f_n (y) dy = \\int_{-\\infty}^{t} \\lim_{n \\to \\infty} f_n (y) dy $$ since $\\Gamma (1/2) = \\sqrt{\\pi} $, $\\displaystyle |f_n (y)| \\le 2 f_1 (y) = { {1} \\over {\\pi} } { {2} \\over {1 + y^2 } }$ is true and according to the differentiation of the arctangent function, $$ \\displaystyle\\lim_{n \\to \\infty} \\int_{-\\infty}^{t} f_n (y) dy\u0026lt; \\int_{-\\infty}^{t} 2 f_1 (y) dy = { {2} \\over {\\pi} } \\tan ^{-1} t \u0026lt; \\infty $$ Now, it is necessary to show where $\\displaystyle \\lim_{n \\to \\infty} f_n (y)$ specifically converges. First, let\u0026rsquo;s split $f_n$ as follows. $$ \\begin{align*} f_{n} (y) =\u0026amp; {{\\Gamma ( (n+1)/2 ) } \\over { \\sqrt{\\pi n} \\Gamma (n/2) }} { {1} \\over {(1 + y^{2} / n)^{(n+1)/2} } } \\\\ =\u0026amp; {{\\Gamma ( (n+1)/2 ) } \\over { \\sqrt{ n/2} \\Gamma (n/2) }} \\cdot { {1} \\over { \\sqrt{2 \\pi} (1 + y^{2} / n)^{(n+1)/2} } } \\\\ =\u0026amp; {{\\Gamma ( (n+1)/2 ) } \\over { \\sqrt{ n/2} \\Gamma (n/2) }} \\cdot { {1} \\over {(1 + y^{2} / n)^{1/2} } } \\cdot { {1} \\over {\\sqrt{2 \\pi }} } \\left( 1 + { {y^{2}} \\over {n} } \\right) ^{-n/2} \\end{align*} $$\nStirling\u0026rsquo;s Approximation: $$ \\lim_{n \\to \\infty} {{n!} \\over {e^{n \\ln n - n} \\sqrt{ 2 \\pi n} }} = 1 $$\nLet\u0026rsquo;s calculate the limit of the first term.\n1 By Stirling\u0026rsquo;s approximation, for sufficiently large $n \\in \\mathbb{N}$, $$ \\Gamma (n) \\approx e^{n \\ln n - n } \\sqrt{ 2 \\pi n} = \\left( {{ n } \\over { e }} \\right)^{n} \\sqrt { 2 \\pi n } $$ assuming for sufficiently large $n$, $$ \\begin{align*} {{ {\\Gamma ( (n+1)/2 ) } } \\over { { \\sqrt{ n / 2 } \\Gamma (n/2) } }} \\approx\u0026amp; \\sqrt{ {{ 2 } \\over { n }} } {{ \\left( {{ n+1 } \\over { 2e }} \\right)^{{{ n+1 } \\over { 2 }}} \\sqrt{ 2 \\pi (n+1)} } \\over { \\cdot \\left( {{ n } \\over { 2e }} \\right)^{{{ n } \\over { 2 }}} \\sqrt{ 2 \\pi n} }} \\\\ \\approx\u0026amp; \\sqrt{ {{ 2 } \\over { n }} } \\sqrt{ {{ n+1 } \\over { 2e }} } \\left( {{ n+1 } \\over { n }} \\right)^{n/2} \\sqrt{ {{ n+1 } \\over { n }} } \\\\ \\approx\u0026amp; \\sqrt{ {{ 1 } \\over { e }}} \\left( 1 + {{ 1 } \\over { n }} \\right)^{n/2} \\end{align*} $$ therefore, $$ \\lim_{n \\to \\infty} {{ {\\Gamma ( (n+1)/2 ) } } \\over { { \\sqrt{ n / 2 } \\Gamma (n/2) } }} = 1 $$ and the second term is $$ \\lim_{n \\to \\infty} { {1} \\over {(1 + y^{2} / n)^{1/2} } } =1 $$ and the third term is $$ \\lim_{n \\to \\infty} { {1} \\over {\\sqrt{2 \\pi }} } \\left( 1 + { {y^{2}} \\over {n} } \\right) ^{-n/2} = { {1} \\over {\\sqrt{2 \\pi }} } e ^{- y^{2} / 2} $$ thus, $$ F_n(t) = \\int_{-\\infty}^{t} { {1} \\over {\\sqrt{2 \\pi }} } e ^{- y^{2} / 2} dy $$ Hence, $T_n$ converges in distribution to a random variable that follows the standard normal distribution.\n‚ñ†\nhttps://math.stackexchange.com/a/3240565/459895\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":195,"permalink":"https://freshrimpsushi.github.io/en/posts/195/","tags":null,"title":"Deriving Standard Normal Distribution as a Limiting Distribution of Student's t-Distribution"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code The package provided for handling colors in Julia is Colors.jl. By loading the visualization package Plots.jl, one can also use the functionality within Colors.jl. Color codes representing the RGB space, such as RGB, BGR, RGB24, RGBX, XRGB, are supported and are subtypes of AbstractRGB. RGBA is RGB with added transparency.\njulia\u0026gt; using Plots\rjulia\u0026gt; subtypes(AbstractRGB)\r5-element Vector{Any}:\rBGR\rRGB\rRGB24\rRGBX\rXRGB\rjulia\u0026gt; subtypes(AbstractRGBA)\r2-element Vector{Any}:\rBGRA\rRGBA Strings By inputting a string such as \u0026quot;#FF0000\u0026quot; as a color keyword in the plot() function, one can use the HEX code, a hexadecimal RGB code. As one can see below, the reason why string input is also feasible seems to be because plot() automatically parses the string.\nusing Plots\rr = \u0026#34;#FF0000\u0026#34; # RÎπ®Í∞ÑÏÉâ RGB(255, 0, 0)Ïùò 6ÏûêÎ¶¨ HEX ÏΩîÎìú\rg = \u0026#34;#00FF0033\u0026#34; # Ìà¨Î™ÖÎèÑÍ∞Ä 0.2Ïù∏ Ï¥àÎ°ùÏÉâ RGBA(0, 255, 0, 0.2)Ïùò 8ÏûêÎ¶¨ HEX ÏΩîÎìú\rp = \u0026#34;#80F\u0026#34; # Î≥¥ÎùºÏÉâ RGB(255, 0, 136)Ïùò 3ÏûêÎ¶¨ HEX ÏΩîÎìú\rplot([1 2 3; 2 3 4], ones(2, 3), fillrange = 2,\rfillcolor = [r g p],\rlabel = [r g p]) Parsing HEX codes can be parsed in the form of colorant\u0026quot;#FF0000\u0026quot;.\njulia\u0026gt; r = colorant\u0026#34;#FF0000\u0026#34; # RÎπ®Í∞ÑÏÉâ RGB(255, 0, 0)Ïùò 6ÏûêÎ¶¨ HEX ÏΩîÎìú\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; g = colorant\u0026#34;#00FF0033\u0026#34; # Ìà¨Î™ÖÎèÑÍ∞Ä 0.2Ïù∏ Ï¥àÎ°ùÏÉâ RGBA(0, 255, 0, 0.2)Ïùò 8ÏûêÎ¶¨ HEX ÏΩîÎìú\rRGBA{N0f8}(0.0,1.0,0.0,0.2)\rjulia\u0026gt; p = colorant\u0026#34;#80F\u0026#34; # Î≥¥ÎùºÏÉâ RGB(255, 0, 136)Ïùò 3ÏûêÎ¶¨ HEX ÏΩîÎìú\rRGB{N0f8}(0.533,0.0,1.0)\rjulia\u0026gt; plot([1 2 3; 2 3 4], ones(2, 3), fillrange = 2,\rfillcolor = [r g p]) It can also be parsed as parse(RGB, \u0026quot;#FF0000\u0026quot;).\njulia\u0026gt; parse(RGB, \u0026#34;#FF0000\u0026#34;)\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; parse(RGBA, \u0026#34;#FF000080\u0026#34;)\rRGBA{N0f8}(1.0,0.0,0.0,0.502) Getting Color Names The hex() function returns the color\u0026rsquo;s HEX code as a string.\njulia\u0026gt; hex(colorant\u0026#34;red\u0026#34;)\r\u0026#34;FF0000\u0026#34;\rjulia\u0026gt; hex(colorant\u0026#34;rgb(0, 255, 128)\u0026#34;)\r\u0026#34;00FF80\u0026#34;\rjulia\u0026gt; hex(RGBA(1, 0.5, 0, 0.5), :RRGGBB)\r\u0026#34;FF8000\u0026#34;\rjulia\u0026gt; hex(RGBA(1, 0.5, 0, 0.5), :RRGGBBAA)\r\u0026#34;FF800080\u0026#34;\rjulia\u0026gt; hex(HSV(30,1.0,1.0), :AARRGGBB)\r\u0026#34;FFFF8000\u0026#34; See Also How to use colors in Plots How to use RGB color codes How to use HEX color codes Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0, Colors v0.12.10, FixedPointNumbers v0.8.4 See Also How to use colors How to use palettes How to use color gradients Packages for color processing Colors.jl How to use RGB codes RGB(1, 0, 0) How to use HEX codes \u0026quot;#000000\u0026quot; How to specify colors of graph elements How to specify colors of graphs in sub plots How to specify colors of axes, axis names, ticks, and tick values How to set background color ","id":1921,"permalink":"https://freshrimpsushi.github.io/en/posts/1921/","tags":null,"title":"How to Use Hexadecimal RGB Codes (HEX) in Julia"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Theorem1 Let $A$ be a square matrix of size $n\\times n$. Then the following propositions are all equivalent.\n(a) $A$ is an invertible matrix.\n(b) The homogeneous linear system $A\\mathbf{x}=\\mathbf{0}$ has only the trivial solution.\n(c) The reduced row echelon form of $A$ is $I_{n}$.\n(d) $A$ can be expressed as a product of elementary matrices.\n(e) $A\\mathbf{x}=\\mathbf{b}$ has a solution for all $n\\times 1$ matrices $\\mathbf{b}$.\n(f) $A\\mathbf{x}=\\mathbf{b}$ has exactly one solution for all $n\\times 1$ matrices $\\mathbf{b}$. That is, $\\mathbf{x}=A^{-1}\\mathbf{b}$ is satisfied.\n(g) $\\det (A) \\ne 0$\n(h) The column vectors of $A$ are linearly independent.\n(i) The row vectors of $A$ are linearly independent.\n(j) The column vectors of $A$ generate $\\mathbb{R}^{n}$.\n(k) The row vectors of $A$ generate $\\mathbb{R}^{n}$.\n(l) The column vectors of $A$ are a basis for $\\mathbb{R}^{n}$.\n(m) The row vectors of $A$ are a basis for $\\mathbb{R}^{n}$.\n(n) The rank of $A$ is $n$.\n(o) The nullity of $A$ is $0$.\n(p) The orthogonal complement of the null space of $A$ is $\\mathbb{R}^{n}$.\n(q) The orthogonal complement of the row space of $A$ is $\\mathbb{R}^{n}$.\n(r) None of the eigenvalues of $A$ is $0$.\n(s) $A^{T}A$ is invertible.\n(t) The kernel of $T_{A}$ is $\\left\\{ \\mathbf{0} \\right\\}$.\n(u) The image of $T_{A}$ is $\\mathbb{R}^{n}$.\n(v) $T_{A}$ is a one-to-one function.\nProof (a) $\\iff$ (b) $\\iff$ (c) $\\iff$ (d) (a) $\\iff$ (e) $\\iff$ (f) Howard Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p463\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3004,"permalink":"https://freshrimpsushi.github.io/en/posts/3004/","tags":null,"title":"Conditions for a Matrix Being Invertible"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Matrix(df) or Array(df) functions can be used to convert a DataFrame into an array of the same size. To create a DataFrame from an array, use DataFrame(array, :auto). In the past, the convert function was used, but it\u0026rsquo;s not applicable anymore, so be careful.\nusing DataFrames\rjulia\u0026gt; A = rand(5,3)\r5√ó3 Matrix{Float64}:\r0.678876 0.10431 0.827079\r0.621647 0.372007 0.29346\r0.756844 0.171237 0.0732631\r0.922519 0.0535938 0.121689\r0.164058 0.0684278 0.68446\rjulia\u0026gt; df = DataFrame(A, :auto)\r5√ó3 DataFrame\rRow ‚îÇ x1 x2 x3 ‚îÇ Float64 Float64 Float64\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 0.678876 0.10431 0.827079\r2 ‚îÇ 0.621647 0.372007 0.29346\r3 ‚îÇ 0.756844 0.171237 0.0732631\r4 ‚îÇ 0.922519 0.0535938 0.121689\r5 ‚îÇ 0.164058 0.0684278 0.68446\rjulia\u0026gt; Matrix(df)\r5√ó3 Matrix{Float64}:\r0.678876 0.10431 0.827079\r0.621647 0.372007 0.29346\r0.756844 0.171237 0.0732631\r0.922519 0.0535938 0.121689\r0.164058 0.0684278 0.68446\rjulia\u0026gt; Array(df)\r5√ó3 Matrix{Float64}:\r0.678876 0.10431 0.827079\r0.621647 0.372007 0.29346\r0.756844 0.171237 0.0732631\r0.922519 0.0535938 0.121689\r0.164058 0.0684278 0.68446\rjulia\u0026gt; Array(df) == Matrix(df)\rtrue ","id":1930,"permalink":"https://freshrimpsushi.github.io/en/posts/1930/","tags":null,"title":"Converting Between DataFrames and 2D Arrays in Julia"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Theorem If $X_{n} \\sim \\text{Poi} \\left( n \\right)$ and $\\displaystyle Y_{n} := {{ X_{n} - n } \\over { \\sqrt{n} }}$ are given $$ Y_{n} \\overset{D}{\\to} N(0,1) $$\n$N \\left( \\mu , \\sigma^{2} \\right)$ is a normal distribution with a mean of $\\mu$ and a variance of $\\sigma^{2}$. $\\text{Poi} (\\lambda)$ is a Poisson distribution with mean and variance of $\\lambda$. Explanation Considering the approximation of the binomial distribution to the Poisson distribution, it is obvious that the standard normal distribution can also be derived from the Poisson distribution.\nDerivation1 The moment generating function of $Y_{n}$, $M_{Y_{n}} (t)$, shows the convergence of the distribution.\nMoment generating function of the Poisson distribution: $$ m(t) = \\exp \\left[ \\lambda \\left( e^{t} - 1 \\right) \\right] \\qquad , t \\in \\mathbb{R} $$\nSince $X_{n} \\sim \\text{Poi} (n)$, $$ \\begin{align*} M_Y (t) =\u0026amp; E \\left[ \\text{exp} \\left( Y_{n} t \\right) \\right] \\\\ =\u0026amp; E \\left[ \\text{exp} \\left( {{ X_{n} - n } \\over { \\sqrt{n} }} t \\right) \\right] \\\\ =\u0026amp; E \\left[ \\text{exp} \\left( {{ X_{n} } \\over { \\sqrt{n} }} t \\right) \\text{exp} ( -t \\sqrt{n} ) \\right] \\\\ =\u0026amp; \\text{exp} ( -t \\sqrt{n} ) E \\left[ \\text{exp} \\left( X_{n} {{ t } \\over { \\sqrt{n} }} \\right) \\right] \\\\ =\u0026amp; \\text{exp} ( -t \\sqrt{n} ) \\exp \\left( n \\left( e^{t/\\sqrt{n}} - 1 \\right) \\right) \\end{align*} $$ Through the second argument\u0026rsquo;s Taylor expansion, $$ \\begin{align*} \u0026amp; \\text{exp} \\left( -t \\sqrt{n} + n \\left( 1 + {{t} \\over {\\sqrt{n}}} + {{1} \\over {2!}} {{t^2} \\over {n}} + {{1} \\over {3!}} {{t^3} \\over {n \\sqrt{n} }} + \\cdots - 1 \\right) \\right) \\\\ =\u0026amp; \\text{exp} \\left( -t \\sqrt{n} + n \\left( {{t} \\over {\\sqrt{n}}} + {{1} \\over {2!}} {{t^2} \\over {n}} + {{1} \\over {3!}} {{t^3} \\over {n \\sqrt{n} }} + \\cdots \\right) \\right) \\\\ =\u0026amp; \\text{exp} \\left( -t \\sqrt{n} + t \\sqrt{n} + {{t^2} \\over {2!}} + {{1} \\over {3!}} {{t^3} \\over { \\sqrt{n} }} + \\cdots \\right) \\\\ =\u0026amp; \\text{exp} \\left( {{t^2} \\over {2!}} + {{1} \\over {3!}} {{t^3} \\over { \\sqrt{n} }} + \\cdots \\right) \\end{align*} $$ Therefore, $$ \\lim_{n \\to \\infty} M_{Y_{n}} = e^{ t^2 \\over 2 } $$\n‚ñ†\nhttp://www.math.wm.edu/~leemis/chart/UDR/PDFs/PoissonNormal.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":197,"permalink":"https://freshrimpsushi.github.io/en/posts/197/","tags":null,"title":"Derivation of the Standard Normal Distribution as the Limiting Distribution of the Poisson Distribution"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide Old Version In julia v1.5.0, *.csv files were read as follows: In fact, Julia is not yet a language notably convenient for data input. However, if one desires speed, there may come a time when Julia should be chosen over Python, R, or Matlab. For instance, if one wants to load a *.csv file located just under the E drive, it can be entered as follows.\nusing CSV\rdata = CSV.read(\u0026#34;E:/example.csv\u0026#34;) The execution result shows that the *.csv file has been successfully read into a dataframe.\nNew Version Although the exact time is unknown, after julia v1.7.0, dataframes must be loaded separately as follows. using CSV, DataFrames\rdata = CSV.read(\u0026#34;E:/example.csv\u0026#34;, DataFrame) Environment OS: Windows ","id":1923,"permalink":"https://freshrimpsushi.github.io/en/posts/1923/","tags":null,"title":"How to Read *.csv Files in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide In Julia, parallel computing is commonly used, so it may be necessary to focus all of a computer\u0026rsquo;s resources on computation depending on the situation. Although there are various ways to change the number of threads, the most static and convenient method is to edit environmental variables.\nStep 1. Edit System Environmental Variables\nPress the Windows key or Windows+S to search for \u0026lsquo;Edit system environment variables\u0026rsquo;.\nWhen the System Properties window appears, click on \u0026lsquo;Environment variables\u0026rsquo;.\nStep 2. Find JULIA_NUM_THREADS\nFind the variable as shown above in user variables. This value is the number of threads. If it exists, choose \u0026lsquo;Edit\u0026rsquo;, if not, select \u0026lsquo;New\u0026rsquo; and proceed to Step 3..\nStep 3. Modify Variable Value\nIn the area indicated in the screenshot above, type the desired number of threads. The appropriate number of threads varies depending on the specs of the computer, but since we are dealing with an example, let\u0026rsquo;s modify it to $5$ threads.\nStep 4. Confirm\nusing Base.Threads\rnthreads() Let\u0026rsquo;s run the above code in the Julia console to check.\nIf it doesn\u0026rsquo;t reflect, try rebooting first. If that doesn\u0026rsquo;t work, then try modifying it in the system variables.\nEnvironment OS: Windows julia: v1.5.0 ","id":1933,"permalink":"https://freshrimpsushi.github.io/en/posts/1933/","tags":null,"title":"Changing the Number of Threads for Parallel Computing in Julia on Windows"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition Let $A$ be an arbitrary square matrix of size $n\\times n$. A matrix $L$ is called the left inverse matrix of $A$ if it satisfies the following equation with $A$ in a matrix multiplication.\n$$ LA=I_{n} $$\nHere, $I_{n}$ is the identity matrix of size $n\\times n$. A matrix $R$ that is capable of matrix multiplication with $A$ and satisfies the following equation is called the right inverse matrix of $A$.\n$$ AR=I_{n} $$\nIf $A$ has both a left/right inverse, they are equal and denoted as $A^{-1}$, and $A$ is called the inverse matrix.\n$$ A^{-1}A=I_{n}=AA^{-1} $$\nIf $A$ has an inverse matrix, it is called an invertible matrix or a nonsingular matrix. If $A$ does not have an inverse matrix, $A$ is called a singular matrix.\nExplanation By the definition, since $LA$ must have the size of $n\\times n$, $L$ must be a $n \\times n$ matrix, and so must $R$. The reason for limiting $A$ to square matrices is because $A^{-1}$ needs to be capable of being multiplied on both sides of $A$. Similarly, since matrix multiplication is not commutative, both left/right inverses must exist for it to be called an invertible matrix. In fact, if an arbitrary matrix has both a left and a right inverse, they are always the same.\nProperties Let $A$ and $B$ be arbitrary $n \\times n$ square matrices. Then the following holds.\n(a) If $A$ has a left inverse matrix $L$ and a right inverse matrix $R$, they are the same.\n$$ L=A^{-1}=R $$\n(b) If the inverse matrix of $A$ exists, it is unique.\n(c) $AB = I \\iff BA = I$\n(d) Let $A$ and $B$ be invertible matrices. Then the product of the two matrices $AB$ is also invertible, and its inverse is as follows.\n$$ (AB)^{-1}=B^{-1}A^{-1} $$\n(d\u0026rsquo;) The product of invertible matrices of the same size is also invertible, and its inverse is the same as the product of the inverses in reverse order. That is, if $A_{1},A_{2},\\dots,A_{n}$ is an invertible matrix, then the following holds.\n$$ \\left( A_{1}A_{2}\\cdots A_{n} \\right)^{-1} = A_{n}^{-1}\\cdots A_{2}^{-1} A_{1}^{-1} $$\n(e) If $AB$ is invertible, then both $A$ and $B$ are also invertible.\n(f) If $A$ is invertible, its transpose is also invertible and its inverse is as follows.\n$$ \\left( A^{T} \\right)^{-1} = \\left( A^{-1} \\right)^{T} $$\nTherefore, we can see that (c) $\\iff$ (d).\nProof (a) Let\u0026rsquo;s assume a $n\\times n$ matrix $A$ is given. Let $L$ be the left inverse matrix of $A$. Then the following equation holds.\n$$ LA=I_{n} $$\nLet\u0026rsquo;s say $R$ is the right inverse matrix of $A$. Multiplying $R$ to the right side of the equation above results in the following.\n$$ LAR = I_{n}R =R $$\nHowever, since $R$ is the right inverse matrix of $A$, $LAR=LI_{n}=L$ holds. Therefore, the equation above is as follows.\n$$ L=R $$\n‚ñ†\n(b) Assume an arbitrary square matrix $A$ has two different inverse matrices $B$ and $C$. Then the calculation goes as follows.\n$$ B=BI=B(AC)=(BA)C=IC=C $$\nHowever, this result contradicts the assumption that $B$ and $C$ are different. Therefore, the assumption is wrong, and if an inverse matrix exists, it is unique.\n‚ñ†\n(c) Without loss of generality, let\u0026rsquo;s only prove $BA = I \\implies AB = I$. Assume $BA = I$. Now consider the equation $A \\mathbf{x} = \\mathbf{0}$.\n$$ \\begin{align*} A\\mathbf{x} = \\mathbf{0} \u0026amp;\\implies B(A\\mathbf{x}) = B \\mathbf{0} \\\\ \u0026amp;\\implies (BA)\\mathbf{x} = \\mathbf{0} \\end{align*} $$\nSince we assumed $BA = I$, $\\mathbf{x} = \\mathbf{0}$ holds. Therefore, $A \\mathbf{x} = \\mathbf{0}$ only has trivial solutions.\nEquivalent conditions for an invertible matrix\nLet $A$ be a square matrix of size $n\\times n$. Then the following propositions are equivalent:\n$A$ is an invertible matrix. The homogeneous linear system $A\\mathbf{x}=\\mathbf{0}$ only has trivial solutions. According to the equivalent conditions for an invertible matrix, $A$ is invertible. Therefore, $A^{-1}$ exists, and\n$$ BA = I \\implies A(BA)A^{-1} = AIA^{-1} \\implies AB = I $$\n‚ñ†\n(d) Let\u0026rsquo;s assume $A$ and $B$ are invertible matrices of size $n\\times n$. Then $A^{-1}$ and $B^{-1}$ exist. First, multiplying $B^{-1}A^{-1}$ to the right of $AB$ results in the following.\n$$ \\begin{align*} (AB)(B^{-1}A^{-1}) \u0026amp;= ABB^{-1}A^{-1} \\\\ \u0026amp;= AI_{n}A^{-1} = AA^{-1} \\\\ \u0026amp;= I_{n}\\end{align*} $$\nMultiplying to the left results in the following.\n$$ \\begin{align*} (B^{-1}A^{-1})(AB) \u0026amp;= B^{-1}A^{-1}AB \\\\ \u0026amp;= B^{-1}I_{n}B = B^{-1}B \\\\ \u0026amp;= I_{n}\\end{align*} $$\nTherefore, $AB$ is an invertible matrix, and its inverse is $B^{-1}A^{-1}$.\n‚ñ†\n(d') This is a corollary to (d).\n‚ñ†\n(e) Let\u0026rsquo;s say the inverse matrix of $AB$ is $C$. Then $ABC=I_{n}$ holds. Therefore, by (c), $A$ is invertible, and $A^{-1}=BC$ holds. Also, since $CAB=I_{n}$, $B$ is also invertible, and $B^{-1}=CA$ holds.\n(f) Check if the product of two matrices results in the identity matrix. According to the properties of transpose matrices, it goes as follows.\n$$ A^{T} \\left( A^{-1} \\right)^{T} = \\left( A^{-1} A \\right) ^{T} = I^{T} = I $$\n$$ \\left( A^{-1} \\right)^{T} A^{T} = \\left( A A^{-1} \\right)^{T} = I^{T} = I $$\nTherefore\n$$ \\left( A^{T} \\right)^{-1} = \\left( A^{-1} \\right)^{T} $$\n‚ñ†\n","id":3003,"permalink":"https://freshrimpsushi.github.io/en/posts/3003/","tags":null,"title":"Inverse Matrix, Reversible Matrix"},{"categories":"ÎèôÏó≠Ìïô","contents":"Model $$ \\dot{N} = {{ r } \\over { K }} N ( K - N) $$\nVariables $N(t)$: Represents the population size of a group at time $t$. Parameters $r \\in \\mathbb{R}$ : Intrinsic Rate of Increase, growth occurs if it is greater than $0$, and decline occurs if it is less than $0$. It can also be defined by the difference $r:=b-d$ between the Birth Rate $b$ and Death Rate $d$. $K$: Carrying Capacity, describes the size of the environment that can support the population. Description This differential equation is also known as the Logistic Equation or Verhulst\u0026rsquo;s Equation.\nThe logistic growth model was designed to improve on the Malthusian growth model, which only predicts unrealistic perpetual increase in population. The more significant the population, the more it penalizes population growth, akin to adding a sort of Malthusian Trap to the equation. If the population size $N$ exceeds the carrying capacity $K$, then $(K-N) \u0026lt; 0$, resulting in a negative change $n '$ in population size, meaning the population will decrease. This idea is not merely speculative; let‚Äôs directly examine the derivation to understand how such a penalty works.\nDerivation Malthusian Growth Model: $$ \\dot{N} = r N $$\nIn such a simple model, the average growth rate per individual can be obtained by dividing both sides by $N$. Since the growth rate in the exponential growth model is constant regardless of how large the population grows, it remains a constant like this:\n$$ {{ \\dot{N} } \\over { N }} = r $$\nNow, let‚Äôs modify the RHS. We want the growth rate to decrease as the population increases, but there‚Äôs no clear consensus on how exactly it should decrease, so let‚Äôs assume it decreases linearly for simplicity. That means the individual growth rate will be depicted by a straight line, not a constant function.\nAs shown in the figure, modifying the RHS so that the equation of the line with the y-intercept of $K$ and the $N\u0026rsquo;/N$ intercept of $r$ results in\n$$ {{ \\dot{N} } \\over { N }} = {{ r } \\over { K }} ( K - N) $$\nMultiplying both sides by $N$ gives us\n$$ \\dot{N} = {{ r } \\over { K }} N ( K - N) $$\n‚ñ†\nFixed Points The logistic growth model has two fixed points, $N=0, N=K$, with $N=K$ being Lyapunov stable1.\nVisual Understanding Let\u0026rsquo;s visually understand the logistic growth model through a grid-based simulation.\nActions (In every cell, each turn)\nCalculation: Count how many elements there are in the up, down, left, right of each cell. Let the number calculated in the $i$ row $j$ column be $n_{ij}$. Diffusion: Each cell has a probability of $1-(1-\\beta)^{n_{ij}}$ to contain an element. Using only the simple action of diffusion in a grid space, one can see natural limits to growth due to the grid space being finite.\nHere is the comparison with the theoretical growth trend.\nAs seen, the simulation does not match the theory exactly; it tends to grow linearly rather than curving, with initial growth too steep. However, it\u0026rsquo;s essential to notice the inflection point where it starts to fill the environmental capacity. If we compare this to real life, it can be like bacteria growing in a petri dish. Even if they want to keep growing, they can\u0026rsquo;t grow indefinitely beyond the confines of the dish.\nThe reason for the discrepancy between theory and simulation is that the simulation isn\u0026rsquo;t sophisticated enough, and the model is too simple. Perhaps it was just bad luck in the simulation, but the impact of the grid cannot be ignored. However, in this case, it\u0026rsquo;s not merely about luck.\nIn fact, when comparing theoretical trends, this visualization appears closer to the Gompertz growth model. Considering tumor growth in grid space, the ratio of volume to surface area appears smaller, and although cell numbers increase, the cells actually capable of increasing the size of the tumor gradually diminish.\nCode Here is the Julia code to create the GIFs.\ncd(@__DIR__) # ÌååÏùº Ï†ÄÏû• Í≤ΩÎ°ú\r@time using Plots\r@time using Random\r@time using DifferentialEquations\rrow_size = 20\rcolumn_size = 20\rŒ≤ = 0.1 # Î≤àÏãùÎ•†\rŒ≥ = 0.1 # ÏÇ¨ÎßùÎ•†\r#---\rK = row_size*column_size\rfunction logistic_growth!(du,u,p,t)\rN = u[1]\rr = p\rdu[1] = dN = r/K*N*(K-N)\rend\ru0 = [1.0]\rp = 0.8\rtspan = (0.,18)\rprob = ODEProblem(logistic_growth!,u0,tspan,p)\rsol = solve(prob; saveat=(0.0:0.1:18))\rcompare = plot(sol,vars=(0,1),\rlinestyle = :dash, color = :black,\rsize = (400,300), label = \u0026#34;Theoretical\u0026#34;, legend=:topleft)\r#---\rmax_iteration = 180\rRandom.seed!(0);\rtime_evolution = Int64[]\rstage_lattice = zeros(Int64, row_size, column_size)\rstage_lattice[rand(1:row_size), rand(1:column_size)] = 1\rlet colormap_SI = cgrad([colorant\u0026#34;#EEEEEE\u0026#34;, colorant\u0026#34;#111111\u0026#34;])\ranim1 = @animate for t = (0:max_iteration)/10\rheatmap(reverse(stage_lattice,dims=1), color=colormap_SI,\rxaxis=false,yaxis=false,axis=nothing, size = [400,400], legend = false)\rI_lattice = (stage_lattice .== 1)\rcount_lattice =\rvcat(I_lattice[2:end, :], zeros(Int64, 1, column_size)) +\rvcat(zeros(Int64, 1, column_size), I_lattice[1:end-1, :]) +\rhcat(I_lattice[:, 2:end], zeros(Int64, row_size, 1)) +\rhcat(zeros(Int64, column_size, 1), I_lattice[:, 1:end-1])\rprobability_lattice = 1 .- (1-Œ≤).^count_lattice\rhit_lattice = probability_lattice .\u0026gt; rand(row_size, column_size)\rstage_lattice[hit_lattice] .= 1\rif sum(stage_lattice) ‚â• row_size*column_size\rcolormap_SI = cgrad([colorant\u0026#34;#111111\u0026#34;, colorant\u0026#34;#EEEEEE\u0026#34;])\rend\rpush!(time_evolution, sum(stage_lattice))\rend; gif(anim1, \u0026#34;logistic_growth_lattice.gif\u0026#34;, fps = 12)\rend\ranim2 = @animate for t = 1:max_iteration\rcompare = plot(sol,vars=(0,1),\rlinestyle = :dash, color = :black,\rlabel = \u0026#34;Theoretical\u0026#34;, legend=:bottomright)\rplot!(compare, 0.1:0.1:(t/10), time_evolution[1:t],\rcolor = colorant\u0026#34;#111111\u0026#34;, linewidth = 2, label = \u0026#34;Simulation\u0026#34;,\rsize = [400, 300])\rend; gif(anim2, \u0026#34;logistic_growth_time_evolution.gif\u0026#34;, fps = 12) From the diagrams used in the derivation, we can see that to the left of the fixed point, the population increases and moves to the right, while to the right, it decreases, moving to the left.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1915,"permalink":"https://freshrimpsushi.github.io/en/posts/1915/","tags":null,"title":"Logistic Growth Model: The Limits of Population Growth"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Theorem De Moivre-Laplace Theorem If $X_i \\sim B(1,p)$ and $Y_n = X_1 + X_2 + \\cdots + X_n$, then $Y_n \\sim B(n,p)$ and $$ { { Y_n - np } \\over {\\sqrt{ np(1-p) } } }\\overset{D}{\\to} N(0,1) $$\n$N \\left( \\mu , \\sigma^{2} \\right)$ is a normal distribution with mean $\\mu$ and variance $\\sigma^{2}$. $B(n,p)$ is a binomial distribution with $n$ trials and probability $p$. $\\overset{D}{\\to}$ denotes convergence in distribution. Description This theorem is also known as the De Moivre‚ÄìLaplace Theorem, and is widely known as a special case of the central limit theorem.\nFrom the beginning of learning statistics, it has been taught that as the sample size of a binomial distribution increases, it approximates a normal distribution. This is evident from experience, and the process of proof does not hold great significance, but it serves as a good example to concretely grasp convergence in distribution, which may not be intuitively obvious from formulas alone.\nDerivation $$ { { Y_n - np } \\over {\\sqrt{ np(1-p) } } } = \\sqrt{n} { { \\overline{X_n} - p } \\over { \\sqrt{p(1-p)} } } $$ Since $X_i \\sim B(1,p)$, we have $E(X_i ) = p$ and $\\text{Var}(X_i ) = p(1-p)$. Furthermore, by the central limit theorem, $$ \\sqrt{n} { { \\overline{X_n} - p } \\over { \\sqrt{p(1-p)} } } \\overset{D}{\\to} N(0,1) $$\n‚ñ†\n","id":196,"permalink":"https://freshrimpsushi.github.io/en/posts/196/","tags":null,"title":"Derivation of the Standard Normal Distribution as a Limiting Distribution of the Binomial Distribution"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide If you are someone who uses Julia, it\u0026rsquo;s likely that you\u0026rsquo;re comfortable with using multiple operating systems or computers, including servers. If there is file input/output involved, having to adjust the path each time the development environment changes can be quite bothersome. This is where the @__DIR__ macro comes in handy. Suppose you have a Julia code file like the following.\nTypically, when executed from the terminal, pwd() and @__DIR__ may appear to not be differentiated as seen below.\nThe difference between these two arises when using an IDE (Integrated Development Environment) such as Atom. Unlike pwd() which simply returns the current working directory, @__DIR__ informs you of the actual location of the code file. This can be extremely useful for complex and repetitive tasks where the working directory may be changed frequently, but the location of the executing code file is not as likely to change.\n","id":1935,"permalink":"https://freshrimpsushi.github.io/en/posts/1935/","tags":null,"title":"How to Determine the Location of Code Files Executed in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Guide In Julia, parallel computing is routinely used, so sometimes it\u0026rsquo;s necessary to focus all of a computer\u0026rsquo;s resources on the computation. There are several ways to change the number of threads, but the most static and convenient method is to edit the environment variables.\nStep 1. Edit System Environment Variables\nPress Ctrl + Alt + T to open the terminal and type gedit ~/.bashrc. A window for editing environment variables will pop up like this.\nStep 2. Modification\nAdd export JULIA_NUM_THREADS=5 at the very bottom. You can modify it with the desired number of threads where it\u0026rsquo;s indicated in the screenshot. The appropriate number of threads varies with the computer\u0026rsquo;s specifications, but since we\u0026rsquo;re dealing with an example, let\u0026rsquo;s modify it to $5$ arbitrarily.\nStep 3. Verification\nusing Base.Threads\rnthreads() Execute the above code in the Julia console to verify.\n","id":1937,"permalink":"https://freshrimpsushi.github.io/en/posts/1937/","tags":null,"title":"Changing the Number of Threads for Parallel Computing in Julia on Linux"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Theorem Let\u0026rsquo;s say $X_{n} \\sim B(n,p)$.\nIf $\\mu \\approx np$ then $$ X_{n} \\overset{D}{\\to} \\text{Poi} (\\mu) $$\n$B(n,p)$ is a binomial distribution with trials $n$ and probability $p$. $\\text{Poi} (\\lambda)$ is a Poisson distribution with mean and variance $\\lambda$. $\\overset{D}{\\to}$ means distribution convergence. Description Note that the condition $\\mu \\approx np$ is necessary here. Since $ np \\approx npq$, it implies $q = (1-p) \\approx 1$, i.e., $p \\approx 0$. This means that $p$ is very small.\nOn the other hand, because of $\\displaystyle p \\approx { {\\mu} \\over {n} }$, $n$ must be very large. The reason for this condition can be easily understood from the fact that the mean and variance are the same in a Poisson distribution.\nProof Consider the moment generating function $M_{X} (t)$. $$ M_{X} (t) = \\left\\{ (1-p) + p e^{t} \\right\\} ^{n} = \\left\\{ 1 + p (e^{t} - 1 ) \\right\\} ^{n} $$ Since $\\displaystyle p \\approx { {\\mu} \\over {n} } $, $$ M_{X} (t) = \\left\\{ 1 + { {\\mu (e^{t} - 1 )} \\over {n} } \\right\\} ^{n} $$ Therefore, $$ \\lim_{n \\to \\infty} M_{X} (t) = e^{ \\mu (e^{t} - 1 ) } $$ Since $ e^{ \\mu (e^{t} - 1 ) }$ is the moment generating function of $\\text{Poi}(\\mu)$, $X_{n}$ converges in distribution to $ \\text{Poi} (\\mu)$.\n‚ñ†\n","id":198,"permalink":"https://freshrimpsushi.github.io/en/posts/198/","tags":null,"title":"The Poisson Distribution as a Limiting Distribution of the Binomial Distribution"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 Let\u0026rsquo;s consider a matrix of size $m\\times n$ as $A$. The matrix obtained by swapping the rows and columns of $A$ is called the transpose of $A$ and is denoted by $A^{T}$ or $A^{t}$.\nDescription Following the definition, if $A$ is a $m \\times n$ matrix then $A^{T}$ will be a $n \\times m$ matrix. Also, the $i$th row of $A$ is the same as the $i$th column of $A^{T}$ and vice versa.\n$$ A=\\begin{bmatrix} 10 \u0026amp; 0 \u0026amp; 3 \\\\ 0 \u0026amp; 8 \u0026amp; 22 \\end{bmatrix} ,\\quad A^{T} = \\begin{bmatrix} 10 \u0026amp; 0 \\\\ 0 \u0026amp; 8 \\\\ 3 \u0026amp; 22 \\end{bmatrix} $$\nIt can be considered as being symmetric with respect to the main diagonal.\nProperties Let\u0026rsquo;s assume $r,s\\in \\mathbb{R}$ and $A,B$ are sizes that make the matrix operations well-defined in each case. Then, the following hold:\n(a) Linearity: $$\\left( rA + sB\\right)^{T}=r A^{T} + s B^{T}$$\n(b) The transpose of a product is equal to the product of the transposes in reverse order.\n$$ (AB)^{T}=B^{T}A^{T} $$\n(b\u0026rsquo;) The transpose of the product of several matrices is equal to the product of the transposes of those matrices in reverse order.\n$$ \\left( A_{1} A_{2}\\cdots A_{n} \\right)^{T} = A_{n}^{T} \\cdots A_{2}^{T} A_{1}^{T} $$\nProof (b) For the $m\\times n$ matrix $A$ and the $n\\times k$ matrix $C$\n$$ \\begin{align*} \\left[ { \\left( AC \\right) }^{ T } \\right] _{ km } \u0026amp;= \\sum _{ i=1 }^{ n }{ [A] _{ m i } { [C] } _{ i k } } \\\\ \u0026amp;= \\sum _{ i=1 }^{ n }{ { \\left[ { A }^{ T } \\right] } _{ i m } { \\left[ { C }^{ T } \\right] } _{ k i } } \\\\ \u0026amp;= \\sum _{ i=1 }^{ n }{ { \\left[ { C }^{ T } \\right] } _{ k i }{ \\left[ { A }^{ T } \\right] } _{ i m } } \\\\ \u0026amp;= { \\left[ { C }^{ T } { A }^{ T } \\right] } _{ km } \\end{align*} $$\nTherefore, if each element is the same, then the matrices are equal and thus the following equation holds.\n$$ \\left( AC \\right) ^{ T } = { C }^{ T } { A }^{ T } $$\n‚ñ†\n(b') This is a corollary to (b).\n‚ñ†\nJim Hefferon, Linear Algebra(4th Edition). 2020, p138\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3002,"permalink":"https://freshrimpsushi.github.io/en/posts/3002/","tags":null,"title":"Transpose Matrix"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code julia\u0026gt; f(x) = 2x + 1\rf (generic function with 1 method)\rjulia\u0026gt; g(x) = x^2\rg (generic function with 1 method)\rjulia\u0026gt; (g ‚àò f)(3)\r49 Description In Julia, function composition is similar to the pipe operator in programming. The main advantage of this composition is that it makes it easier for mathematicians to express formulas as code. The example above is simply a translation of the following formula into code.\n$$ f(x) := 2x + 1 \\\\ g(x) := x^2 \\\\ (g \\circ f) (3) $$\nLike many languages these days, treating functions as first-class citizens is the same, but dealing with function spaces as in pure mathematics might be considered a more extreme philosophy that has even influenced the syntax. Note that the function composition operator can be used by entering \\circ in tex syntax.\n","id":1942,"permalink":"https://freshrimpsushi.github.io/en/posts/1942/","tags":null,"title":"How to Use Composite Functions in Julia"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition A diagonal matrix of size $n\\times n$ with all diagonal elements being $1$ is called an identity matrix or unit matrix, denoted as $I_{n}$ or $I_{n\\times n}$.\n$$ I_{n\\times n}= \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1 \\end{bmatrix} $$\nDescription The identity matrix is the identity element for matrix multiplication. This means that for any $n\\times n$ matrix $A$, the following equation holds:\n$$ I_{n}A=A=AI_{n} $$\nProperties Determinant Since the identity matrix is a diagonal matrix, its determinant is $1$.\n$$ \\det I = 1 $$\n","id":3001,"permalink":"https://freshrimpsushi.github.io/en/posts/3001/","tags":null,"title":"Identity Matrix, Unit Matrix"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 Given a random variable $X$ and a sequence of random variables $\\left\\{ X_{n} \\right\\}$, if the following condition is satisfied when $n \\to \\infty$, we say that $X$ converges in distribution to $X_{n}$ and represent it as $X_{n} \\overset{D}{\\to} X$. $$ \\lim_{n \\to \\infty} F_{X_{n}} (x) = F_{X} (x) \\qquad, \\forall x \\in C_{F_{X}} $$\n$F_{X}$ is the cumulative distribution function of the random variable $X$. $C_{F_{X}}$ represents the set of points where the function $F_{X}$ is continuous. Explanation Convergence in Distribution is a concept defined in the sense of distribution\u0026rsquo;s convergence, similar to probability convergence. Converging for each $x \\in C_{F_{X}}$ means something similar to pointwise convergence of functions in analysis, and this similarity extends to the fact that if there is uniform convergence, there is pointwise convergence, as is the case with probability convergence leading to distribution convergence.\nIt is important to note that although we talk about distribution convergence, as precisely indicated in $X_{n} \\overset{D}{\\to} X$, \u0026lsquo;distribution convergence\u0026rsquo; also refers to the convergence of random variables. The pointwise convergence in the continuous part of the distribution function means not exactly that the random variable converges, but one of its properties, the distribution, converges. This, of course, is a much looser premise than the convergence of the random variable itself. Even if there is no difference from the perspective of distribution, it does not mean that the random variable essentially converges.\nIndeed, $X_{n} \\overset{D}{\\to} X$ and $Y_{n} \\overset{D}{\\to} Y$ do not guarantee that $X_{n} + Y_{n}$ converges in distribution to $X + Y$. Unlike probability convergence, distribution convergence only requires a light condition of pointwise convergence of the cumulative distribution function, so it lacks even these common properties.\nTheorems Let $X_{n} \\overset{D}{\\to} X$ be stated.\n[1] Continuous Mapping Theorem: For a continuous function $g$, $$ g\\left( X_{n} \\right) \\overset{D}{\\to} g (X) $$ [2]: If it converges in probability, it converges in distribution. That is, $$ X_{n} \\overset{P}{\\to} X \\implies X_{n} \\overset{D}{\\to} X $$ [3]: If it converges in distribution, it is probability bounded. [4] Slutsky‚Äôs Theorem2: For a constant $a,b$ and a random variable $A_{n}, B_{n} ,X_{n} , X$, if $a_{n} \\overset{P}{\\to} a $, $ B_{n} \\overset{P}{\\to} b $, and $ X_{n} \\overset{D}{\\to} X $, then $$ A_{n} + B_{n} X_{n} \\overset{D}{\\to} a + b X $$ Limit Distributions Meanwhile, if $X_{n} \\overset{D}{\\to} X$, then the distribution of $X$ is also called the asymptotic or limiting distribution of $\\left\\{ X_{n} \\right\\}$. For convenience, the distribution of $X$ is sometimes used directly, for instance, if $X \\sim N(0,1)$, it can be represented as follows3. $$ X_{n} \\overset{D}{\\to} N(0,1) $$\nExamples [a] Deriving Poisson distribution as the limit distribution of binomial distribution: Let $X_{n} \\sim B(n,p)$.\nIf $\\mu \\approx np$, then $$ X_{n} \\overset{D}{\\to} \\text{Poi} (\\mu) $$ [b] Deriving standard normal distribution as the limit distribution of binomial distribution: If $X_i \\sim B(1,p)$ and $Y_n = X_1 + X_2 + \\cdots + X_n$, then $Y_n \\sim B(n,p)$, $$ { { Y_n - np } \\over {\\sqrt{ np(1-p) } } }\\overset{D}{\\to} N(0,1) $$ [c] Deriving standard normal distribution as the limit distribution of Poisson distribution: If $X_{n} \\sim \\text{Poi} \\left( n \\right)$ and $\\displaystyle Y_{n} := {{ X_{n} - n } \\over { \\sqrt{n} }}$, $$ Y_{n} \\overset{D}{\\to} N(0,1) $$ [d] Deriving standard normal distribution as the limit distribution of Student t-distribution: If $T_n \\sim t(n)$, $$ T_n \\ \\overset{D}{\\to} N(0,1) $$\nWhy Limit Distributions are Needed From these asymptotic distributions, it\u0026rsquo;s clear that distribution convergence is insufficient to be called the convergence of the random variable itself. For example, in the binomial distribution, even if a sufficiently large distribution $n$ is given and it can be approximated to the normal distribution, the essence of the variable itself cannot mimic the normal distribution. No matter how large $n$ becomes, binomial distribution remains binomial, and normal distribution remains normal. However, since the distributions resemble each other, they might appear indistinguishable at a glance.\nNonetheless, the reason we consider distribution convergence is that being indistinguishable to that extent is sufficient, and sometimes, there\u0026rsquo;s no room left to compromise in conditions. As mentioned earlier, no matter how much it changes, a discrete probability distribution can never become a continuous probability distribution. Still, if we can immediately use a discrete probability distribution as a continuous one by introducing the concept of weak convergence, there\u0026rsquo;s no reason not to consider it.\nProofs [1][4] ‚ñ†\n[2] ‚ñ†\n[3] ‚ñ†\n[a] ‚ñ†\n[b] ‚ñ†\n[c] ‚ñ†\n[d] ‚ñ†\nRigorous Definition Distribution convergence defined by measure theory Hogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p208.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p306.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p300.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1888,"permalink":"https://freshrimpsushi.github.io/en/posts/1888/","tags":null,"title":"Convergence of Distributions in Mathematical Statistics"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Diagonal Matrix1 Let\u0026rsquo;s consider a matrix $A$ of size $n\\times m$. The elements whose row and column numbers are the same, that is, $a_{ii} (1 \\le i \\le \\min(n,m))$, are called the main diagonal elements. The imaginary line connecting the main diagonal elements is referred to as the main diagonal, or principal diagonal.\nA matrix $A$, in which all elements except for the main diagonal elements are $0$, is called a diagonal matrix.\n$$ A = [a_{ij}] = \\delta_{ij} = \\begin{cases} 1 \u0026amp; i=j \\\\ 0 \u0026amp; i \\ne j \\end{cases} $$\nHere, $\\delta$ is the Kronecker delta.\nExplanation $$ A=\\begin{bmatrix} \\color{red}{a_{11}} \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; \\color{red}{a_{22}} \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; \\color{red}{a_{33}} \\end{bmatrix} \\quad A=\\begin{bmatrix} \\color{red}{a_{11}} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; \\color{red}{a_{22}} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; \\color{red}{a_{33}} \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\color{red}{a_{44}} \u0026amp; 0 \\end{bmatrix} $$\nAs demonstrated in the example above, it is possible to define main diagonal elements and a diagonal matrix even if it\u0026rsquo;s not strictly a square matrix.\nBy definition, a diagonal matrix is both a lower triangular matrix and an upper triangular matrix.\nProperties Powers Let\u0026rsquo;s consider a diagonal matrix $A = \\begin{bmatrix} a_{ij}\\end{bmatrix}$ of size $n\\times n$. Then, the power of $A$ is as follows.\n$$ A^{k}=\\begin{bmatrix} (a_{11})^{k} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; (a_{22})^{k} \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; (a_{nn})^{k} \\end{bmatrix} $$\nInverse The inverse of $A$ is as follows. In other words, the property regarding powers naturally extends even when $k$ is negative.\n$$ A^{-1} = \\begin{bmatrix} \\dfrac{1}{a_{11}} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\dfrac{1}{a_{22}} \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; \\dfrac{1}{a_{nn}} \\end{bmatrix} $$\nDeterminant Considering cofactor expansion, the determinant of a diagonal matrix is the product of all the diagonal elements. For a diagonal matrix $n \\times n$, its determinant is,\n$$ \\det [a_{ij}] = a_{11} \\times \\cdots \\times a_{nn} $$\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p69-71\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1958,"permalink":"https://freshrimpsushi.github.io/en/posts/1958/","tags":null,"title":"Diagonal Matrix"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition A matrix $A$ is called a square matrix if the number of rows and columns of the matrix $A$ are equal.\nExplanation It is also referred to as a regular square matrix. Square matrices are easy to handle and possess various favourable properties.\nExamples Identity matrix\nInvertible matrix\nElementary matrix\nSymmetric matrix\nOrthogonal matrix\nHermitian matrix\nUnitary matrix\n","id":1956,"permalink":"https://freshrimpsushi.github.io/en/posts/1956/","tags":null,"title":"Square Matrix"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Scalar Multiplication The multiplication of an arbitrary matrix $A$ of size $m \\times n$ by a scalar $k$ is defined as multiplying each element of $A$ by $k$ and is denoted as follows:\n$$ kA = k\\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\end{bmatrix} := \\begin{bmatrix} ka_{11} \u0026amp; ka_{12} \u0026amp; \\cdots \u0026amp; ka_{1n} \\\\ ka_{21} \u0026amp; ka_{22} \u0026amp; \\cdots \u0026amp; ka_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; ka_{m2} \u0026amp; \\cdots \u0026amp; ka_{mn} \\end{bmatrix} $$\nBy definition, the multiplication of a scalar and a matrix is commutative, although the scalar is usually written in front.\n$$ kA = Ak $$\nAddition The addition of two matrices $A$ and $B$, each of size $m \\times n$, is defined as adding the elements in the same row and column and is denoted as follows:\n$$ \\begin{align*} A+B \u0026amp;= \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\end{bmatrix} + \\begin{bmatrix} b_{11} \u0026amp; b_{12} \u0026amp; \\cdots \u0026amp; b_{1n} \\\\ b_{21} \u0026amp; b_{22} \u0026amp; \\cdots \u0026amp; b_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ b_{m1} \u0026amp; b_{m2} \u0026amp; \\cdots \u0026amp; b_{mn} \\end{bmatrix} \\\\ \u0026amp;:=\\begin{bmatrix} a_{11} + b_{11} \u0026amp; a_{12} + b_{12} \u0026amp; \\cdots \u0026amp; a_{1n} + b_{1n} \\\\ a_{21} + b_{21} \u0026amp; a_{22} + b_{22} \u0026amp; \\cdots \u0026amp; a_{2n} + b_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} + b_{m1} \u0026amp; a_{m2} + b_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} + b_{mn} \\end{bmatrix} \\end{align*} $$\nAs can be seen from the definition, the addition of two matrices is only defined for matrices of the same size and is commutative.\n$$ A+B=BA $$\nMultiplication While multiplying a matrix by a scalar or adding two matrices is intuitively acceptable, multiplication is a bit different. Let‚Äôs first look at the multiplication of a row vector and a column vector.\nThe multiplication of a row vector $A=\\begin{bmatrix} a_{1} \u0026amp; a_{2} \u0026amp; \\cdots \u0026amp; a_{n} \\end{bmatrix}$ of size $1\\times n$ and a column vector $B= \\begin{bmatrix} b_{1} \\\\ b_{2} \\\\ \\vdots \\\\ b_{n} \\end{bmatrix}$ of size $n \\times 1$ is defined as follows:\n$$ \\begin{align*} AB =\\begin{bmatrix} a_{1} \u0026amp; a_{2} \u0026amp; \\cdots \u0026amp; a_{n} \\end{bmatrix}\\begin{bmatrix} b_{1} \\\\ b_{2} \\\\ \\vdots \\\\ b_{n} \\end{bmatrix} \u0026amp;:= a_{1}b_{1}+a_{2}b_{2} + \\cdots +a_{n}b_{n} \\\\ \u0026amp;= \\sum \\limits_{i=1}^{n}a_{i}b_{i} \\end{align*} $$\nIf we were to explain this definition in words, it would be \u0026ldquo;the sum of the products of the elements in the same order,\u0026rdquo; which is conceptually the same as the dot product of two vectors learned in high school.\n$$ \\begin{align*} \\vec{a} \u0026amp;=(a_{1},a_{2},a_{3}) \\\\ \\vec{b} \u0026amp;= (b_{1},b_{2},b_{3}) \\end{align*},\\quad \\vec{a} \\cdot \\vec{b} = a_{1}b_{1} + a_{2}b_{2} + a_{3}b_{3} $$\nThe multiplication of two matrices can be thought of as an extension of this concept. The multiplication of a $m\\times n$ matrix $A$ and a $m\\times k$ matrix $B$ is defined as follows:\n$$ \\begin{align*} AB \u0026amp;= \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\end{bmatrix} \\begin{bmatrix} b_{11} \u0026amp; b_{12} \u0026amp; \\cdots \u0026amp; b_{1k} \\\\ b_{21} \u0026amp; b_{22} \u0026amp; \\cdots \u0026amp; b_{2k} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ b_{n1} \u0026amp; b_{n2} \u0026amp; \\cdots \u0026amp; b_{nk} \\end{bmatrix} \\\\ \u0026amp;:= \\begin{bmatrix} \\sum_{i=1}^{n} a_{1i}b_{i1} \u0026amp; \\sum_{i=1}^{n} a_{1i}b_{i2} \u0026amp; \\cdots \u0026amp; \\sum_{i=1}^{n} a_{1i}b_{ik} \\\\ \\sum_{i=1}^{n} a_{2i}b_{i1} \u0026amp; \\sum_{i=1}^{n} a_{2i}b_{i2} \u0026amp; \\cdots \u0026amp; \\sum_{i=1}^{n} a_{2i}b_{ik} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ \\sum_{i=1}^{n} a_{mi}b_{i1} \u0026amp; \\sum_{i=1}^{n} a_{mi}b_{i2} \u0026amp; \\cdots \u0026amp; \\sum_{i=1}^{n} a_{mi}b_{ik} \\end{bmatrix} \\end{align*} $$\nAlthough the formula might seem complicated, it is merely the result of doing several multiplications of row vectors and column vectors. The element in the $n$ row and $k$ column of the resulting matrix $AB$ from the multiplication of $A$ and $B$ is the same as the dot product of the $n$ row of $A$ and the $k$ column of $B$. Therefore, the number of columns of $A$ and the number of rows of $B$ must be the same for the multiplication between them to be defined. Also, the multiplication of two matrices generally does not follow the commutative law.\n$$ AB \\ne BA $$\nThis can be easily verified with a simple example. If we say $A=\\begin{bmatrix} 1 \u0026amp; 1 \\\\ 0 \u0026amp; 1 \\end{bmatrix}$, $\\begin{bmatrix} 2 \u0026amp; -1 \\\\ 1 \u0026amp; 1 \\end{bmatrix}$, then\n$$ \\begin{align*} AB \u0026amp;=\\begin{bmatrix} 2+1 \u0026amp; -1+1 \\\\ 0+1 \u0026amp; 0+1 \\end{bmatrix}=\\begin{bmatrix} 3 \u0026amp; 0 \\\\ 1 \u0026amp; 1 \\end{bmatrix} \\\\ BA \u0026amp;=\\begin{bmatrix} 2+0 \u0026amp; 2-1 \\\\ 1+0 \u0026amp; 1+1 \\end{bmatrix} = \\begin{bmatrix} 2 \u0026amp; 1 \\\\ 1 \u0026amp; 2 \\end{bmatrix} \\end{align*} $$\nTherefore,\n$$ AB\\ne BA $$\nThe process of matrix multiplication can be visually represented as follows:\nProperties1 Let\u0026rsquo;s assume that $A$, $B$, and $C$ are arbitrary matrices of size $m \\times n$. Let $r$ and $s$ be arbitrary constants. The following properties of matrix operations hold:\n(a) Commutative law for addition: $A + B = B + A$\n(b) Associative law for addition: $A + (B + C) = (A + B) + C$\n(c) $(r + s)A = rA + sA$\n(d) $r(A + B) = rA + rB $\n(e) $(rs)A = r(sA)$\nAssuming $A$, $B$, and $C$ are arbitrary matrices of size $n\\times n$:\n(f) Associative law for multiplication: $A(BC) = (AB)C$\n(g) Distributive law for multiplication $A(B+C) = AB + AC \\quad \\\u0026amp; \\quad (A+B)C=AC + BC$\nIt should be noted again that the commutative law does not hold for matrix multiplication.\nJim Hefferon, Linear Algebra(4th Edition). 2020, p235\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1957,"permalink":"https://freshrimpsushi.github.io/en/posts/1957/","tags":null,"title":"Matrix Operations: Scalar Multiplication, Addition, and Multiplication"},{"categories":"Îß§Ìä∏Îû©","contents":"Imagesc imagesc function allows you to display a 2D array as a heatmap. colorbar is a setting that outputs a color bar indicating the scale.\nN=2^8;\rp=phantom(\u0026#39;Modified Shepp-Logan\u0026#39;,N);\rfigure()\rimagesc(p)\rcolorbar Saving Method 1 You can use the saveas function to save the figure displayed above. The setting gcf refers to the current figure. Then, the picture below is saved.\nN=2^8;\rp=phantom(\u0026#39;Modified Shepp-Logan\u0026#39;,N);\rfigure()\rimagesc(p)\rcolorbar\rsaveas(gcf,\u0026#39;phantom.png\u0026#39;) Method 2 You can also save directly from the figure window, as shown in the picture below.\nOther Languages In Julia ","id":1948,"permalink":"https://freshrimpsushi.github.io/en/posts/1948/","tags":null,"title":"How to Print and Save a 2D Array as a Heatmap Image in MATLAB"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 A matrix is an arrangement of numbers in the shape of a rectangle as follows:\n$$ A=\\begin{bmatrix} 10 \u0026amp; 0 \u0026amp; 3 \\\\ 0 \u0026amp; 8 \u0026amp; 22 \\end{bmatrix} $$\nEach of the arranged numbers is called an entry or element. A horizontal line is called a row, and a vertical line is called a column. Moreover, if a certain matrix has $m$ rows and $n$ columns, its size is denoted by $m \\times n$.\nIn the example above, the matrix $A$ has 2 rows and 3 columns, and its size is $2\\times 3$. It is important to note that $\\times$ does not mean multiplication. The size must be indicated clearly with the number of rows and columns, as in $2\\times 3$, and should never be written as $6$. For reference, a '$2 \\times 3$ matrix' is read as [two by three matrix].\nNotation Matrices are usually denoted as below with either square brackets [] or parentheses (), both of which are commonly seen. However, when writing by hand, it can be difficult to make parentheses look nice. Unlike denoting 2D or 3D space coordinates, it is standard to not place commas (,) between elements.\n$$ A=\\begin{bmatrix} 10 \u0026amp; 0 \u0026amp; 3 \\\\ 0 \u0026amp; 8 \u0026amp; 22 \\end{bmatrix} \\quad A=\\begin{pmatrix} 10 \u0026amp; 0 \u0026amp; 3 \\\\ 0 \u0026amp; 8 \u0026amp; 22 \\end{pmatrix} $$\nTypically, matrices are denoted in uppercase, and their elements in lowercase. For example, the element in the 1st row and 3rd column of matrix $A$ is $3$, and this is denoted as follows.\n$$ a_{13}=3 $$\nThe first subscript indicates the row position, and the second subscript indicates the column position. Similarly, the element in the $i$th row, $j$th column of a matrix, if it is $a_{ij}$, is denoted as $\\begin{bmatrix} a_{ij} \\end{bmatrix}$. The $(i,j)$ element of $A$ is denoted as $[A]_{ij}$.\n$$ A = \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\end{bmatrix} = \\begin{bmatrix} a_{ij} \\end{bmatrix},\\qquad [A]_{ij} = a_{ij} $$\nThe set of all $m\\times n$ matrices is denoted as follows.\n$$ M_{m \\times n} $$\nThe set of matrices of size $m\\times n$ with real $\\mathbb{R}$, complex $\\mathbb{C}$ elements are denoted respectively as follows.\n$$ M_{m\\times n}(\\mathbb{R}),\\quad M_{m \\times n}(\\mathbb{C}) $$\nMore abstractly, the set of $n \\times n$ matrices with elements in the field $F$ are denoted as $M_{m \\times n}(F)$.\nColumn Vectors and Row Vectors A vector is an arrangement of numbers horizontally or vertically. Thinking about this, a matrix can be seen as an arrangement of column vectors or row vectors. Let\u0026rsquo;s look at the matrix $A$ that has been continuously used as an example.\n$$ A= \\begin{bmatrix} 10 \u0026amp; 0 \u0026amp; 3 \\\\ 0 \u0026amp; 8 \u0026amp; 22 \\end{bmatrix} $$\nEach column of $A$ can be thought of as comprising the column vectors $\\begin{bmatrix} 10 \\\\ 0 \\end{bmatrix}$, $\\begin{bmatrix} 0 \\\\ 8 \\end{bmatrix}$, $\\begin{bmatrix} 3 \\\\ 22 \\end{bmatrix}$. Alternatively, it can be seen that each row consists of the row vectors $\\begin{bmatrix} 10 \u0026amp; 0 \u0026amp; 3 \\end{bmatrix}$, $\\begin{bmatrix} 0 \u0026amp; 8 \u0026amp; 22 \\end{bmatrix}$.\nJim Hefferon, Linear Algebra(4th Edition). 2020, p15\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1955,"permalink":"https://freshrimpsushi.github.io/en/posts/1955/","tags":null,"title":"Matrix Definitions"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition A sequence of numbers is called a vector.\nDescription In the general curriculum, a vector is learned as a \u0026lsquo;geometric object with magnitude and direction\u0026rsquo;. Since it\u0026rsquo;s the concept you first come across in physics, you inevitably become familiar with vectors of $3$ dimensions or less.\n$$ (3,4) = \\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix} $$ $$ (x,y,z) = \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} $$\nHowever, vectors can actually be generalized to more coordinates. It\u0026rsquo;s sufficient to just list more numbers below, for example, a $4$-dimensional vector considering time $t$ can be denoted as follows.\n$$ (t,x,y,z) = \\begin{bmatrix} t \\\\ x \\\\ y \\\\ z \\end{bmatrix} $$\nWhat does it mean to have vectors of more than $4$ dimensions? For instance, if you want to represent the position $(x,y,z)$ at time $t$ and the thermal energy $E$ for each oxygen molecule, you can extend it to $5$ dimensions as follows.\n$$ (t,x,y,z,E) = \\begin{bmatrix} t \\\\ x \\\\ y \\\\ z \\\\ E \\end{bmatrix} $$\nThe point is, there\u0026rsquo;s no need to be overly afraid of the length of the vector, that is, the increase in dimensions. In the endless world of mathematics given under a specific format, such expansion of dimensions is natural and obvious. In the same manner, it\u0026rsquo;s possible to think of vectors generalized up to $n$ dimensions, usually denoted by boldface $\\mathbf{x}$.\n$$ \\mathbf{x} = \\left( x_{1}, \\cdots , x_{n} \\right) = \\begin{bmatrix} x_{1} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix} $$\nFrom this simple definition, a $n$-dimensional vector is indistinguishable from a $n$-tuple. The farther you get from physics and closer to mathematics, the less you use expressions like $\\vec{x}$ with arrows, and as you enter into abstract and general mathematics, you get precise and strict definitions without terms like \u0026lsquo;coordinates\u0026rsquo; or \u0026lsquo;sequence\u0026rsquo;.\nSee Also Difficult Definitions of Vectors ","id":1947,"permalink":"https://freshrimpsushi.github.io/en/posts/1947/","tags":null,"title":"Definition of Vectors"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Formulas Let\u0026rsquo;s call $f=f(x,y,z)$ a scalar function. Let\u0026rsquo;s call $\\mathbf{A} = A_{x}\\hat{\\mathbf{x}} + A_{y}\\hat{\\mathbf{y}} + A_{z}\\hat{\\mathbf{z}}, \\mathbf{B} = B_{x}\\hat{\\mathbf{x}} + B_{y}\\hat{\\mathbf{y}} + B_{z}\\hat{\\mathbf{z}}$ a vector function. Then, the following equations hold.\nGradient\n(a) $\\nabla{(fg)}=f\\nabla{g}+g\\nabla{f}$\n(b) $\\nabla(\\mathbf{A} \\cdot \\mathbf{B}) = \\mathbf{A} \\times (\\nabla \\times \\mathbf{B}) + \\mathbf{B} \\times (\\nabla \\times \\mathbf{A})+(\\mathbf{A} \\cdot \\nabla)\\mathbf{B}+(\\mathbf{B} \\cdot \\nabla) \\mathbf{A}$\nDivergence\n(c) $\\nabla \\cdot (f\\mathbf{A}) = f(\\nabla \\cdot \\mathbf{A}) + \\mathbf{A} \\cdot (\\nabla f)$\n(d) $\\nabla \\cdot (\\mathbf{A} \\times \\mathbf{B}) = \\mathbf{B} \\cdot (\\nabla \\times \\mathbf{A}) - \\mathbf{A} \\cdot (\\nabla \\times \\mathbf{B})$\nCurl\n(e) $\\nabla \\times (f\\mathbf{A}) = (\\nabla f) \\times \\mathbf{A} + f(\\nabla \\times \\mathbf{A})$\n(f) $\\nabla \\times (\\mathbf{A} \\times \\mathbf{B}) = (\\mathbf{B} \\cdot \\nabla)\\mathbf{A} - (\\mathbf{A} \\cdot \\nabla)\\mathbf{B} + \\mathbf{A} (\\nabla \\cdot \\mathbf{B}) - \\mathbf{B} (\\nabla \\cdot \\mathbf{A})$\nDescription Throughout the proof, we use Einstein notation, so be careful not to get confused. That is, if the same index appears twice in an equation, it means the following.\n$$ x_{i}y_{i}=\\sum \\limits_{i=1}^{3} x_{i}y_{i}=x_{1}y_{1}+x_{2}y_{2}+x_{3}y_{3} $$\nAlso, you should be familiar with using Kronecker delta and Levi-Civita symbol and know the relationship between them to easily follow the proof.\nProof (a) Can be easily shown by the definition of gradient and the properties of differentiation.\n$$ \\begin{align*} \\nabla(fg) =\u0026amp;\\ \\dfrac{\\partial (fg)}{\\partial x} \\hat{\\mathbf{x}}+\\dfrac{\\partial (fg)}{\\partial y} \\hat{\\mathbf{y}} +\\dfrac{\\partial (fg)}{\\partial z} \\hat{\\mathbf{z}} \\\\ =\u0026amp;\\ \\left( g\\dfrac{\\partial f}{\\partial x} + f\\dfrac{\\partial g}{\\partial x} \\right) \\hat{\\mathbf{x}} +\\left( g\\dfrac{\\partial f}{\\partial y} + f\\dfrac{\\partial g}{\\partial y} \\right) \\hat{\\mathbf{y}} + \\left( g\\dfrac{\\partial f}{\\partial z} + f\\dfrac{\\partial g}{\\partial z} \\right) \\hat{\\mathbf{z}} \\\\ =\u0026amp;\\ g\\left( \\dfrac{\\partial f}{\\partial x}\\hat{\\mathbf{x}} +\\dfrac{\\partial f}{\\partial y}\\hat{\\mathbf{y}} + \\dfrac{\\partial f}{\\partial z}\\hat{\\mathbf{z}} \\right) + f\\left( \\dfrac{\\partial g}{\\partial x}\\hat{\\mathbf{x}} +\\dfrac{\\partial g}{\\partial y}\\hat{\\mathbf{y}} + \\dfrac{\\partial g}{\\partial z}\\hat{\\mathbf{z}} \\right) \\\\ =\u0026amp;\\ g\\nabla f+ f\\nabla g \\end{align*} $$\n‚ñ†\n(b) Calculating the left side directly, we get the following.\n$$ \\begin{align*} \\nabla \\left( \\mathbf{A}\\cdot \\mathbf{B} \\right) =\u0026amp;\\ \\frac{ \\partial \\left( \\mathbf{A}\\cdot \\mathbf{B} \\right)}{ \\partial x_{1}}\\mathbf{e}_{1}+\\frac{ \\partial \\left( \\mathbf{A}\\cdot \\mathbf{B} \\right)}{ \\partial x_{2}}\\mathbf{e}_{2}+\\frac{ \\partial \\left( \\mathbf{A}\\cdot \\mathbf{B} \\right)}{ \\partial x_{3}}\\mathbf{e}_{3} \\\\ =\u0026amp;\\ \\sum \\limits_{i=1}^{3} \\frac{ \\partial \\left( \\mathbf{A}\\cdot \\mathbf{B} \\right)}{ \\partial x_{i}}\\mathbf{e}_{i} \\\\ =\u0026amp;\\ \\sum \\limits_{i=1}^{3} \\frac{ \\partial \\left( \\sum _{j=1}^{3}A_{j}B_{j} \\right)}{ \\partial x_{i}}\\mathbf{e}_{i} \\\\ =\u0026amp;\\ \\sum \\limits_{i=1}^{3}\\sum \\limits_{j=1}^{3} \\frac{ \\partial \\left( A_{j}B_{j} \\right)}{ \\partial x_{i}}\\mathbf{e}_{i} \\end{align*} $$\nSimplifying with Einstein notation, we get the following.\n$$ \\nabla (\\mathbf{A} \\cdot \\mathbf{B}) = \\frac{\\partial(A_{j}B_{j})}{\\partial x_{i}}\\mathbf{e}_{i}=\\frac{\\partial A_{j}}{\\partial x_{i}} B_{j}\\mathbf{e}_{i}+A_{j} \\frac{\\partial B_{j}}{\\partial x_{i}} \\mathbf{e}_{i} $$\nThen, using the Kronecker delta, the equation can be expressed as follows.\n$$ \\begin{align*} \u0026amp;\u0026amp;\\frac{\\partial A_{j}}{\\partial x_{i}} B_{j}\\mathbf{e}_{i}+A_{j} \\frac{\\partial B_{j}}{\\partial x_{i}} \\mathbf{e}_{i} =\u0026amp;\\ {\\color{blue}\\delta_{jm}}\\frac{ \\partial {\\color{blue}A_{j}}}{ \\partial x_{i}} {\\color{blue}B_{m}} \\mathbf{e}_{i} + {\\color{blue}\\delta_{jm} A_{m}}\\frac{ \\partial {\\color{blue}B_{j}} }{ \\partial x_{i} }\\mathbf{e}_{i} \\\\ \u0026amp;\u0026amp; =\u0026amp;{\\color{red}\\delta_{il}}{\\color{blue}\\delta_{jm}}\\frac{ {\\color{red}\\partial} {\\color{blue}A_{j}}}{ {\\color{red}\\partial x_{i}} } {\\color{blue}B_{m}} {\\color{red}\\mathbf{e}_{l}} + {\\color{red}\\delta_{il}}{\\color{blue}\\delta_{jm} A_{m}} {\\color{red}\\frac{ \\partial {\\color{blue}B_{j}} }{ \\partial x_{i} }} {\\color{red}\\mathbf{e}_{l}} \\\\ \u0026amp;\u0026amp; =\u0026amp;{\\color{red}\\delta_{jl}}{\\color{blue}\\delta_{jm}} \\left( {\\color{red}\\frac{ \\partial {\\color{blue}A_{j}}}{ \\partial x_{i} }} {\\color{blue}B_{m}}\\color{red} {\\mathbf{e}_{l}} + {\\color{blue}A_{m}}{\\color{red}\\frac{ \\partial {\\color{blue}B_{j}} }{ \\partial x_{i} } \\mathbf{e}_{l} }\\right) \\\\ \\implies \u0026amp;\u0026amp; \\nabla \\left( \\mathbf{A} \\cdot \\mathbf{B} \\right) =\u0026amp;\\ \\delta_{jl}\\delta_{jm} \\left( \\frac{ \\partial A_{j} }{ \\partial x_{i} } B_{m} \\mathbf{e}_{l} + A_{m}\\frac{ \\partial B_{j} }{ \\partial x_{i} } \\mathbf{e}_{l} \\right) \\end{align*} $$\nFurthermore, since $\\epsilon_{ijk} \\epsilon_{klm} = \\delta_{il} \\delta_{jm} - \\delta_{im} \\delta_{jl}$, we can expand the equation as follows.\n$$ \\begin{align*} \\nabla(\\mathbf{A} \\cdot \\mathbf{B}) =\u0026amp;\\ (\\epsilon_{ijk} \\epsilon_{klm} + \\delta_{im} \\delta_{jl}) \\left(\\frac {\\partial A_{j}}{\\partial x_{i}}B_{m} \\mathbf{e}_{l} + A_{m} \\frac{\\partial B_{j}}{\\partial x_{i}}\\mathbf{e}_{l}\\right) \\\\ =\u0026amp;\\ \\epsilon_{ijk} \\epsilon_{klm } \\frac{\\partial A_{j}}{\\partial x_{i}}B_{m} \\mathbf{e}_{l} + \\epsilon_{ijk} \\epsilon_{klm} A_{m} \\frac{\\partial B_{j}}{\\partial x_{i}} \\mathbf{e}_{l} + \\delta_{im} \\delta_{jl} \\frac{\\partial A_{j}}{\\partial x_{i}} B_{m} \\mathbf{e}_{l} + \\delta_{im} \\delta_{jl}A_{m} \\frac{\\partial B_{j}}{\\partial x_{i}} \\mathbf{e}_{l} \\end{align*} $$\nHere, by the definition of the Levi-Civita symbol, since $\\epsilon_{ijk} \\dfrac{\\partial A_{j}}{\\partial x_{i}}=(\\nabla \\times \\mathbf{A})_{k}$ and $\\epsilon_{ijk} \\dfrac {\\partial B_{j}}{\\partial x_{i}}=(\\nabla \\times \\mathbf{B})_{k}$, we obtain the following result.\n$$ \\begin{align*} \\nabla (\\mathbf{A} \\cdot \\mathbf{B}) =\u0026amp;\\ \\epsilon _{ klm }(\\nabla \\times \\mathbf{A})_{ k }B_{ m }\\hat { \\mathbf{e}_{ l } }+\\epsilon _{ klm }A_{ m }(\\nabla \\times \\mathbf{B})_{ k }\\hat { \\mathbf{e}_{ l } }+\\frac { \\partial A_{ j } }{ \\partial x_{ i } }B_{ i }\\hat { e_{ j} }+A_{ i }\\frac { \\partial B_{ j } }{ \\partial x_{ i } }\\hat { \\mathbf{e}_{ j } } \\\\ =\u0026amp;\\ \\mathbf{B}\\times (\\nabla \\times \\mathbf{A})+\\mathbf{A} \\times (\\nabla \\times \\mathbf{B})+(\\mathbf{B} \\cdot \\nabla )\\mathbf{A}+(\\mathbf{A} \\cdot \\nabla )\\mathbf{B} \\end{align*} $$\n‚ñ†\n(c)‚Äã $$ \\begin{align*} \\nabla \\cdot (f \\mathbf{A}) =\u0026amp;\\ \\delta _{ ij }\\nabla _{ i }(fA_{ j }) \\\\ =\u0026amp;\\ \\delta _{ ij }(\\nabla _{ i }f)A_{ j }+\\delta _{ ij }f(\\nabla _{ i }A_{ j }) \\\\ =\u0026amp;\\ (\\nabla _{ i }f)A_{ i }+f(\\nabla _{ i }A_{ i }) \\\\ =\u0026amp;\\ (\\nabla f)\\cdot \\mathbf{A}+f(\\nabla \\cdot \\mathbf{A}) \\end{align*} $$\n‚ñ†\n(d) $$ \\begin{align*} \\nabla \\cdot (\\mathbf{A} \\times \\mathbf{B}) \u0026amp;= \\delta _{ ij }\\nabla _{ i }(\\mathbf{A} \\times \\mathbf{B})_{ j } \\\\ \u0026amp;= \\delta _{ ij }\\nabla _{ i }(\\epsilon _{ jkl }A_{ k }B_{ l }) \\\\ \u0026amp;= \\delta _{ ij }\\epsilon _{ jkl }\\nabla _{ i }(A_{ k }B_{ l }) \\\\ \u0026amp;= \\delta _{ ij }\\epsilon _{ jkl }(\\nabla _{ i }A_{ k })B_{ l }+\\delta _{ ij }\\epsilon _{ jkl }A_{ k }(\\nabla _{ i }B_{ l }) \\\\ \u0026amp;= (\\epsilon _{ jkl }\\nabla _{ j }A_{ k })B_{ l }+A_{ k }(\\epsilon _{ jkl }\\nabla _{ j }B_{ l }) \\\\ \u0026amp;= (\\nabla \\times A)_{ l }B_{ l }-A_{ k }(\\nabla \\times B)_{ k } \\\\ \u0026amp;= (\\nabla \\times \\mathbf{A})\\cdot \\mathbf{B}-\\mathbf{A}\\cdot (\\nabla \\times \\mathbf{B}) \\end{align*} $$\n‚ñ†\n(e)‚Äã $$ \\begin{align*} \\nabla \\times (f\\mathbf{A}) \u0026amp;= \\epsilon _{ ijk }\\nabla _{ i }(fA_{ j })\\mathbf{e}_{k} \\\\ \u0026amp;= \\epsilon _{ ijk }(\\nabla _{ i }f)A_{ j }\\mathbf{e}_{k}+\\epsilon _{ ijk }f(\\nabla _{ i }A_{ j })\\mathbf{e}_{k} \\\\ \u0026amp;= (\\nabla f)\\times \\mathbf{A}+f\\epsilon _{ ijk }(\\nabla _{ i }A_{ j })\\mathbf{e}_{k} \\\\ \u0026amp;= (\\nabla f)\\times \\mathbf{A}+f(\\nabla \\times \\mathbf{A}) \\\\ \u0026amp;= f(\\nabla \\times \\mathbf{A})-\\mathbf{A} \\times (\\nabla f) \\end{align*} $$\n‚ñ†\n(f) If you\u0026rsquo;re not familiar with Einstein notation, it may be difficult to follow the proof.\n$$ \\begin{align*} \u0026amp; \\nabla \\times (\\mathbf{A}\\times \\mathbf{B}) \\\\ =\u0026amp;\\ \\epsilon_{ijk} \\nabla_{i} \\left(\\mathbf{A}\\times \\mathbf{B}\\right)_{j} \\mathbf{e}_{k} \\\\ =\u0026amp;\\ \\epsilon_{ijk} \\nabla_{i} (\\epsilon_{jlm} A_{l} B_{m})\\mathbf{e}_{k} \\\\ =\u0026amp;\\ \\epsilon_{ijk} \\epsilon_{jlm} \\nabla_{i} (A_{l} B_{m}) \\mathbf{e}_{k} \\\\ =\u0026amp;\\ \\epsilon_{jki} \\epsilon_{jlm} \\left[ B_{m}(\\nabla_{i} A_{l}) \\mathbf{e}_{k} + A_{l} (\\nabla_{i} B_{m}) \\mathbf{e}_{k} \\right] \\\\ =\u0026amp;\\ (\\delta_{kl} \\delta_{im} - \\delta_{km} \\delta_{il} ) [ B_{m} (\\nabla_{i} A_{l} ) \\mathbf{e}_{k} + A_{l} ( \\nabla_{i} B_{m} ) \\mathbf{e}_{k} ] \\\\ =\u0026amp;\\ \\delta_{kl} \\delta_{im} B_{m} ( \\nabla_{i} A_{l}) \\mathbf{e}_{k} - \\delta_{km} \\delta_{il} B_{m} (\\nabla_{ i} A_{l} ) \\mathbf{e}_{k} + \\delta_{kl} \\delta_{im} A_{l} ( \\nabla_{i} B_{m} ) \\mathbf{e}_{k} - \\delta_{km} \\delta_{il} A_{l} ( \\nabla_{i} B_{m} ) \\mathbf{e}_{k} \\\\ =\u0026amp;\\ B_{i} ( \\nabla_{i} A_{k}) \\mathbf{e}_{k} - B_{k} (\\nabla_{i} A_{i} ) \\mathbf{e}_{k} + A_{k} ( \\nabla_{i} B_{i} ) \\mathbf{e}_{k} - A_{i} ( \\nabla_{i} B_{k} ) \\mathbf{e}_{k} \\\\ =\u0026amp;\\ (\\mathbf{B}\\cdot \\nabla )\\mathbf{A}-(\\nabla \\cdot \\mathbf{A})\\mathbf{B}+\\mathbf{A}(\\nabla \\cdot \\mathbf{B})-(\\mathbf{A}\\cdot \\nabla )\\mathbf{B} \\\\ =\u0026amp;\\ (\\mathbf{B}\\cdot \\nabla )\\mathbf{A}-(\\mathbf{A}\\cdot \\nabla )\\mathbf{B}+\\mathbf{A}(\\nabla \\cdot \\mathbf{B})-\\mathbf{B}(\\nabla \\cdot \\mathbf{A}) \\end{align*} $$\nThe fourth line holds due to $\\epsilon_{jki} \\epsilon_{jlm} = \\delta_{kl} \\delta_{im} - \\delta_{km} \\delta_{il}$. The seventh line holds due to Einstein Notation.\n‚ñ†\n","id":93,"permalink":"https://freshrimpsushi.github.io/en/posts/93/","tags":null,"title":"Product Rule Involving the Del Operator"},{"categories":"Îã®Ï∏µÏ¥¨ÏòÅ","contents":"Definition Let\u0026rsquo;s assume that a function $f :D \\to \\mathbb{R}$ is defined on some 2D domain $D\\subset \\mathbb{R}^{2}$. The Radon transform $\\mathcal{R}f$ of $f$ is defined as follows, for $s \\in \\mathbb{R}$, $\\boldsymbol{\\theta} = (\\cos \\theta, \\sin \\theta) \\in S^{1}$,\n$$ \\begin{align*} \\mathcal{R} f(s, \\boldsymbol{\\theta}):=\u0026amp;\\ \\int \\limits_{t=-\\infty}^{\\infty} f ( s \\boldsymbol{\\theta} + t \\boldsymbol{\\theta}^{\\perp} )dt \\\\ =\u0026amp;\\ \\int \\limits_{t=-\\infty} ^{\\infty} f \\left( s\\cos\\theta-t\\sin\\theta, s\\sin\\theta + t\\cos\\theta \\right)dt \\end{align*} $$\nExplanation Radon transform is a type of integral transform named after the Austrian mathematician Johann Radon (1887-1956).\nThe radioactive element radon is not named after the mathematician Radon, but rather its name comes from the word \u0026lsquo;radioactive\u0026rsquo; with the inert gas suffix \u0026lsquo;-on\u0026rsquo; added.\nThe geometric meaning of $\\mathcal{R} f (s, \\boldsymbol{\\theta})$ is the integration of $f$ at all points that are $s$ away from the origin and perpendicular to $\\boldsymbol{\\theta}$.\nWhile $f$ is a function of Cartesian coordinates $(x, y)$, the Radon transform $\\mathcal{R}f$ is a function of polar coordinates $(s, \\theta)$.\nThe Radon transform is one of the core principles of CT and is based on the physical law known as Beer-Lambert\u0026rsquo;s law. This law states that the intensity of X-rays decreases differently depending on the type of medium they pass through. A reduction in the intensity of X-rays means that the medium has absorbed the X-rays. The extent to which a medium absorbs light is referred to as the attenuated coefficient, absorption coefficient, or absorbance. The fact that different media have different attenuation coefficients is utilized in non-destructive inspection using X-rays in CT. The reason why bones appear white in X-ray images is because bones absorb more X-rays than other materials.\nAnother Expression of the Definition When $l_{s, \\theta}$ is considered as a line determined by polar coordinates $(s,\\theta)$,\n$$ \\mathcal{R} f(s, \\boldsymbol{\\theta}) = \\int _{l_{s, \\theta}} f $$\nThinking about the geometric meaning,\n$$ \\mathcal{R} f(s, \\boldsymbol{\\theta}) = \\int \\limits_{ \\mathbf{x} \\cdot \\boldsymbol{\\theta} = s} f (\\mathbf{x}) d \\mathbf{x} $$\nWhen defined as $\\boldsymbol{\\theta}^{\\perp} := \\left\\{ \\mathbf{u} : \\mathbf{u} \\cdot \\boldsymbol{\\theta} = 0 \\right\\}$,\n$$ \\mathcal{R} f(s, \\boldsymbol{\\theta}) = \\int \\limits_{ \\boldsymbol{\\theta}^{\\perp}} f (s \\boldsymbol{\\theta} + \\mathbf{u}) d \\mathbf{u} $$\nRegarding the Dirac delta function $\\delta$,\n$$ \\mathcal{R} f (s, \\boldsymbol{\\theta}) = \\int\\limits_{\\mathbb{R}^{2}} f( \\mathbf{x} ) \\delta ( \\mathbf{x} \\cdot \\boldsymbol{\\theta} - s) d \\mathbf{x} $$\nGeneralization For $s \\in \\mathbb{R}^{1}$, $\\boldsymbol{\\theta} \\in S^{n-1}$, the Radon transform $\\mathcal{R} : L^{2}(\\mathbb{R}^{n}) \\to L^{2}(Z_{n})$ is defined as follows.\n$$ \\mathcal{R} f (s, \\boldsymbol{\\theta}) = \\int\\limits_{\\mathbf{x} \\cdot \\boldsymbol{\\theta} = s} f(\\mathbf{x}) d \\mathbf{x} $$\nHere, $Z_{n} := \\mathbb{R}^{1} \\times S^{n-1}$ is a unit cylinder in $n+1$ dimensions.\nDerivation1 Let\u0026rsquo;s designate $x$ as the position, $I(x)$ as the intensity of X-rays, and $A(x)$ as the attenuation coefficient of the medium.\nBeer-Lambert Law\nThe rate of change of the intensity of X-rays is as follows.\n$$ \\begin{equation} \\frac{ dI }{ dx } = -A(x)I(x) \\end{equation} $$\nLet $x_{0}$ and $x_{1}$ represent the starting and ending positions of the X-rays, respectively, and $I_{0}$ and $I_{1}$ represent the intensity of the X-rays at each point. When we separate the variables in $(1)$ and integrate both sides, we obtain the following.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\int_{x_{0}}^{x_{1}} \\frac{1}{I(x)}dI \u0026amp;= - \\int_{x_{0}}^{x_{1}}A(x)dx \\\\ \\implies \u0026amp;\u0026amp; \\ln \\left( I_{1} \\right) - \\ln \\left( I_{0} \\right)\u0026amp;= -\\int_{x_{0}}^{x_{1}}A(x)dx \\\\ \\implies \u0026amp;\u0026amp; \\ln \\left( \\frac{I_{1}}{I_{0}}\\right) \u0026amp;= -\\int_{x_{0}}^{x_{1}}A(x)dx \\\\ \\implies \u0026amp;\u0026amp; \\ln \\left( \\frac{I_{0}}{I_{1}}\\right) \u0026amp;= \\int_{x_{0}}^{x_{1}}A(x)dx \\end{align*} $$\nLooking at this equation, $I_{0}$ is the intensity when the X-rays are shot, which is a known value. $I_{1}$ is the intensity after the X-rays have passed through the object, and this value is measured by the detector located at $x_{0}$. Therefore, the left side is a known value.\nThe range of integration on the right side is the path traveled by the X-rays we shot, so it is known. Hence, given the path $L$ of the X-rays and the intensities $I_{0}$, $I_{1}$ at both ends, we can obtain the value obtained by integrating $A(x)$ over the path $L$. This is referred to as the Radon transform of $A(x)$.\n$$ \\mathcal{R}f (L) := \\int_{L} f(x) dx = \\ln \\left( \\frac{I_{0}}{I_{1}}\\right) $$\nProperties The basic properties of the Radon transform are as follows.\nLinearity\n$$ \\mathcal{R} \\left( \\alpha f + \\beta g \\right) = \\alpha \\mathcal{R}f + \\beta \\mathcal{R}g $$\nShift Invariance\n$$ \\mathcal{R}T_{\\mathbf{a}}f (s, \\boldsymbol{\\theta}) = T_{\\mathbf{a} \\cdot \\boldsymbol{\\theta}}\\mathcal{R}f(s,\\boldsymbol{\\theta}) $$\nRotation Invariance\n$$ RAf = ARf $$\nDilation Invariance\n$$ RD_{r}f = \\dfrac{1}D_{r}Rf $$\nTimothy G. Feeman, The Mathematics of Medical Imaging: A Beginner\u0026rsquo;s Guide. Springer, 2010, p4\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1945,"permalink":"https://freshrimpsushi.github.io/en/posts/1945/","tags":null,"title":"Radon Transformation"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Description Differential equations with constant coefficients can be relatively easily solved using methods such as separation of variables or integrating factor method. However, differential equations with coefficients that include the independent variable, as shown below, cannot be easily solved.\n$$ \\begin{equation} P(x)\\dfrac{d^2 y}{dx^2} + Q(x)\\dfrac{dy}{dx}+R(x)y=0 \\label{1}\\end{equation} $$\nHere, $P$, $Q$, and $R$ are assumed to be polynomials without common factors. Equations of the above form include\nBessel\u0026rsquo;s equation\n$$ x^2 y^{\\prime \\prime} +xy^{\\prime}+(x^2-\\nu ^2)y=0,\\quad \\nu \\text{ is constant} $$\nLegendre\u0026rsquo;s equation\n$$ (1-x^2)y^{\\prime \\prime}-2xy^{\\prime}+l(l+1)y=0,\\quad l \\text{ is constant} $$\namong others. The goal in solving such differential equations is to find solutions in the form of power series.\nDefinition1 In $\\eqref{1}$, $x_{0}$ is called an ordinary point if $P(x_{0}) \\ne 0$. Since $P$ is continuous, there exists an open interval that includes $x_{0}$, denoted as $P(x) \\ne 0$. Our objective here is to find a power series solution to $\\eqref{1}$ in the vicinity of an ordinary point $x_{0}$. In other words, the solution to $\\eqref{1}$ is assumed to be a power series of the form\n$$ y=a_{0}+a_{1}(x-x_{0})+a_2(x-x_{0})^2+\\cdots = \\sum \\limits _{n=0}^\\infty a_{n}(x-x_{0})^n $$\nand converges within the radius of convergence $|x-x_{0}| \u0026lt; \\rho$. This method allows us to solve difficult differential equations with the independent variable $x$ in the coefficients.\nOn the other hand, $x_{0}$ is called a singular point if $P(x_{0})=0$. Among singular points,\n$$ \\lim \\limits_{x\\rightarrow x_{0}}(x-x_{0})\\frac{Q(x)}{P(x)} \u0026lt; \\infty\\quad \\mathrm{and}\\quad \\lim \\limits_{x\\rightarrow x_{0}} (x-x_{0})^{2}\\frac{R(x) }{P(x)}\u0026lt;\\infty $$\nthose satisfying this condition are called regular singular points. If it is not a regular singular point, it is called an irregular singular point. When $x_{0}$ is a regular singular point, the solution is assumed to start as follows.\n$$ y=\\sum \\limits_{n=0}^{\\infty}a_{n}x^{n+s} $$\nThis method of solving is known as the Frobenius method.\nExample Solve for the series solution of $y^{\\prime \\prime}+y=0$ and $-\\infty \u0026lt; x \u0026lt; \\infty$.\nAlthough the content is lengthy, it is not difficult, so take your time reading it. The given equation for the example may be sufficiently easily solved without resorting to a series solution, but the importance lies in practicing the method of solving through series solutions. Firstly, $y^{\\prime \\prime}+y=0$ is when $P(x)=1$, $Q(x)=0$, and $R(x)=1$. Thus, every point is an ordinary point, but for simplification, let\u0026rsquo;s choose $x_{0}=0$. Assume the given differential equation\u0026rsquo;s solution converges for the power series below at $|x| \u0026lt; \\rho$.\n$$ y=a_{0}+a_{1}x+a_2x^2+\\cdots = \\sum \\limits_{n=0}^\\infty a_{n}x^n $$\nTo insert into the differential equation, calculate $y^{\\prime \\prime}$ to get\n$$ y^{\\prime \\prime}=2a_2+3\\cdot 2 a_{3} x + \\cdots +n(n-1)a_{n}x^{n-2}+\\cdots = \\sum \\limits_{n=2} ^\\infty n(n-1)a_{n}x^{n-2} $$\nInserting $y$ and $y^{\\prime \\prime}$ into the given differential equation yields\n$$ \\sum \\limits_{n=2} ^\\infty n(n-1)a_{n}x^{n-2} + \\sum \\limits_{n=0}^\\infty a_{n}x^n=0 $$\nAn important point in the series solution method is to align the order of $x$. When substituting $n+2$ instead of $n$ for the first term of the series, it becomes as follows.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\sum \\limits_{n=0} ^\\infty (n+2)(n+1)a_{n+2}x^{n} + \\sum \\limits_{n=0}^\\infty a_{n}x^n\u0026amp;=0 \\\\ \\implies \u0026amp;\u0026amp; \\sum \\limits_{n=0} ^\\infty \\left[ (n+2)(n+1)a_{n+2}+ a_{n} \\right] x^{n}\u0026amp;=0 \\end{align*} $$\nFrom the properties of power series, for the above equation to hold, all coefficients must be $0$. Thus, we obtain the following equation.\n$$ \\begin{align*} \u0026amp;\u0026amp; (n+2)(n+1)a_{n+2}+ a_{n}\u0026amp;=0 \\\\ \\implies \u0026amp;\u0026amp; (n+2)(n+1)a_{n+2}\u0026amp;=-a_{n} \\\\ \\implies\u0026amp;\u0026amp; a_{n+2}\u0026amp;=\\dfrac{-1}{(n+2)(n+1)} a_{n} \\end{align*} $$\nThe formula that describes the relationship between the preceding and succeeding coefficients is called a recurrence relation. From the recurrence relation, each term\u0026rsquo;s coefficient can be determined. Since the $n+2$th coefficient can be found from the $n$th coefficient, knowing the first two coefficients, $a_{0}, a_{1}$, allows us to know all coefficients. Therefore, the series can be divided into two parts, grouped as $a_{0}$ and $a_{1}$. For even $n$ in general, it can be expressed as follows for $n=2k(k=1,2,\\dots)$.\n$$ \\begin{align*} a_2 \u0026amp;=\\dfrac{-1}{2\\cdot 1}a_{0}=\\dfrac{-1}{2!}a_{0} \\\\ a_{4} \u0026amp;=\\dfrac{-1}{4\\cdot 3}{a_2}=\\dfrac{-1}{4\\cdot 3}\\dfrac{-1}{2!}a_{0}=\\dfrac{1}{4!}a_{0} \\\\ a_{6}\u0026amp;=\\dfrac{-1}{6!}a_{0} \\\\ \u0026amp;\\vdots \\\\ a_{n} \u0026amp;=a_{2k}=\\dfrac{(-1)^k}{(2k)!}a_{0} \\end{align*} $$\nFor odd $n$ in general, it can be expressed as follows for $n=2k+1(k=1,2,\\dots)$.\n$$ \\begin{align*} a_{3} \u0026amp;=\\dfrac{-1}{3\\cdot 2}a_{1}=\\dfrac{-1}{3!}a_{1} \\\\ a_{5}\u0026amp;=\\dfrac{-1}{5 \\cdot 4}a_{3}=\\dfrac{-1}{5\\cdot 4}\\dfrac{-1}{3!}a_{0}=\\dfrac{1}{5!}a_{1} \\\\ a_{7}\u0026amp;=\\dfrac{-1}{7!}a_{1} \\\\ \u0026amp;\\vdots \\\\ a_{n} \u0026amp;=a_{2k+1}=\\dfrac{(-1)^k}{(2k+1)!}a_{1} \\end{align*} $$\nInserting and organizing the above results into $y$ gives the following.\n$$ \\begin{align*} y\u0026amp;= a_{0}+a_{1}x-\\dfrac{a_{0}}{2!}x^2-\\dfrac{a_{1}}{3!}x^3+\\cdots +\\dfrac{(-1)^na_{0}}{(2n)!}x^{2n}+\\dfrac{ (-1)^{n} a_{1}}{(2n+1)!} x^{2n+1} +\\cdots \\\\ \u0026amp;=a_{0}\\left[ 1-\\dfrac{1}{2!}x^2+\\dfrac{1}{4!}x^4+\\cdots + \\dfrac{(-1)^n}{(2n)!}x^{2n} + \\cdots \\right] + a_{1} \\left[ x-\\dfrac{1}{3!}x^3 +\\dfrac{1}{5!}x^5+\\cdots +\\dfrac{ (-1)^n}{(2n+1)!}x^{2n+1} +\\cdots \\right] \\\\ \u0026amp;= a_{0} \\sum \\limits_{n=0}^\\infty \\dfrac{(-1)^n } {(2n)!} x^{2n}+a_{1}\\sum \\limits_{n=0}^\\infty \\dfrac{(-1)^n}{(2n+1)!}x^{2n+1} \\end{align*} $$\nWe have found the two solutions and the general solution for the given second-order differential equation. The general solution is represented as a linear combination of the below two independent solutions. $$ y_{1}(x)=\\sum \\limits_{n=0}^\\infty \\dfrac{(-1)^n } {(2n)!} x^{2n},\\quad y_{2}(x)=\\sum \\limits_{n=0}^\\infty \\dfrac{(-1)^n}{(2n+1)!}x^{2n+1} $$\nUsing the ratio test, it can be seen that both series $y_{1}, y_{2}$ converge for all $x$. Moreover, these two series exactly match the Taylor series of $\\cos$ and $\\sin$. This means $y=a_{0}\\cos x+a_{1}\\sin x$, which is the same as the solution obtained through solving second-order differential equations with constant coefficients.\n‚ñ†\nWilliam E. Boyce, Boyce\u0026rsquo;s Elementary Differential Equations and Boundary Value Problems (11th Edition, 2017), p195-219\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":888,"permalink":"https://freshrimpsushi.github.io/en/posts/888/","tags":null,"title":"Solution of Differential Equations Using Series Solutions"},{"categories":"ÎèôÏó≠Ìïô","contents":"Model $$ \\dot{N} = rN $$\nVariables $N(t)$: Represents the population size of a group at time $t$. Parameters $r \\in \\mathbb{R}$ : The Intrinsic Rate of Increase, if greater than $0$, the population grows, if less than $0$, it declines. It can also be defined by the difference $r:=b-d$ between Birth Rate $b$ and Death Rate $d$. Description Population Dynamics is the first pathway through which dynamics leads to mathematical biology, offering a mathematical approach to topics like population size or species coexistence. The Malthus growth model is one of the simplest of such models, where the population size of a species, breeding ideally (without obstacles), can be represented by a simple ordinary differential equation. The given equation is a separable first-order differential equation, hence its solution for the initial population $N_{0}$\n$$ N(t) = N_{0} e^{rt} $$\nis obtained like this, and since the expression involves an exponential function, it is perfectly described as Exponential Growth Model. The name Malthus Growth Model is derived from Thomas Robert Malthus, the author of An Essay on the Principle of Population.\nOne may wonder what use is a population model, but more advanced models are actually used in the biotech field, relating to the number of germs, viruses, or certain nucleotide sequences, and many application models are based on the approach to \u0026lsquo;moving quantitative variables\u0026rsquo; themselves beyond the meaning of population size. For instance, Gordon Moore, co-founder of Intel, stated that \u0026ldquo;the performance of semiconductor integrated circuits doubles every two years,\u0026rdquo; which exactly means exponential growth, now called Moore\u0026rsquo;s Law. It\u0026rsquo;s not that Moore applied the Malthus growth model directly, but rather that the phenomenon of growth is generally explained this way. Besides the bio-field, this concept of growth can apply to customers using a service or the principal sum of risk-free assets in economics/management, or conversely, nuclear decomposition can be viewed as the negative growth of the number of nuclei.\nDerivation Modeling the growth of a population can be imagined by considering bacteria that reproduce by binary fission. The rate of increase in population size is proportional not only to their individual growth rates but also to the total population size itself. For example, consider a Petri dish $A$ with $10$ bacteria and another dish $B$ with $20$ bacteria. After a certain period, when the population size has doubled, dish $A$ would have $20$ bacteria, and dish $B$ would have $40$. In other words,\n$$ (N = 10 \\text{Ïùº ÎïåÏùò Ï¶ùÍ∞ÄÎüâ}) = 10 \\\\ (N = 20 \\text{Ïùº ÎïåÏùò Ï¶ùÍ∞ÄÎüâ}) = 20 $$\nAssuming this holds using the variable $N$,\n$$ (N \\text{Ïùò Ï¶ùÍ∞ÄÎüâ}) = N $$\nModifying the equation to consider growth rate, for some real number $r \\in \\mathbb{R}$,\n$$ (N \\text{Ïùò Î≥ÄÌôîÎüâ}) = rN $$\nis obtained. If $r\u0026gt;0$, the change in population is positive, indicating an increase in population size, and if $r\u0026lt;0$, the change is negative, indicating a decrease over time. To express this change not verbally but mathematically, differentiation is needed. At time $t$, the rate of change of $N$ is $dN / dt$, modifying the left-hand side yields:\n$$ {{dN} \\over {dt}} = r N $$\n‚ñ†\nLimitations While the term differential equations might seem daunting, one can appreciate that each step of derivation stems from a common-sense premise. However, despite the seemingly rational premise, the biggest issue with this model is its total failure to reflect reality. Though it might be appropriate as the first textbook example due to its simplicity, it\u0026rsquo;s practically useless for any substantial application.\nActual population growth inevitably encounters what is known as the Malthusian Trap. Continuing with the Petri dish example, the dish, being a constrained environment, can neither forever sustain growth and reproduction with the provided nutrients nor offer infinite space. Eventually, a point will be reached where growth slows down, and ideal exponential growth stops.\nWhile this model is the simplest, it\u0026rsquo;s rarely used to fit actual population sizes directly; it either holds meaning as a first-order term itself or various models are applied to overcome its unrealistic aspects. Methods considering death or competition between multiple species could be contemplated.\nVisual Understanding Let\u0026rsquo;s visually comprehend the Malthus growth model through an agent-based simulation.\nActions (Every agent, on each turn)\nReproduce: With probability b, creates a new agent at its location. Die: With probability d, is removed from the simulation. b # Î≤àÏãùÎ•†\rd # ÏÇ¨ÎßùÎ•†\rreplicated = (rand(N) .\u0026lt; b) # Î≤àÏãù ÌåêÏ†ï\rnew\\_coordinate = coordinate[replicated,:]\rcoordinate = coordinate[rand(N) .\u0026gt; d,:] # ÏÇ¨Îßù ÌåêÏ†ï\rcoordinate = cat(coordinate, new\\_coordinate, dims = 1); Checking how the system changes with the system-specific intrinsic growth rate parameter $r$ suffices, given the simple actions of reproduction and death used by agents.\nNote that the reproduction probability b used in the simulation and the system\u0026rsquo;s birth rate $b$, along with the death probability d and the system\u0026rsquo;s death rate $d$, are generally not the same. Fitting the simulation exactly to an autonomous system described by differential equations required finding reasonably appropriate parameters through intuition.\nIn the case of $r\u0026gt;0$ N0 = 50 # Ï¥àÍ∏∞ Ïù∏Íµ¨Ïàò\rb = 0.05 # Î≤àÏãùÎ•†\rd = 0.02 # ÏÇ¨ÎßùÎ•† Although there might be some initial hesitation in simulation, since the birth rate surpasses the death rate, explosive growth ultimately occurs.\nIn the case of $r\u0026lt;0$ N0 = 50 # Ï¥àÍ∏∞ Ïù∏Íµ¨Ïàò\rb = 0.04 # Î≤àÏãùÎ•†\rd = 0.05 # ÏÇ¨ÎßùÎ•† It almost precisely follows the theoretical path to extinction.\nIn the case of $r=0$ N0 = 50 # Ï¥àÍ∏∞ Ïù∏Íµ¨Ïàò\rb = 0.05 # Î≤àÏãùÎ•†\rd = 0.05 # ÏÇ¨ÎßùÎ•† While the differential equation representation suggests no change with an initial value at the fixed point, the simulation shows fluctuations due to moment-to-moment luck, occasionally nearing extinction before recovering. This motion seems like a kind of Brownian motion, and indeed, increasing the population or lowering the birth and death rates would maintain a more stable equilibrium state.\nIt\u0026rsquo;s actually Geometric Brownian Motion. Code Below is the Julia code used in this post.\ncd(@__DIR__) # ÌååÏùº Ï†ÄÏû• Í≤ΩÎ°ú\r@time using Plots\r@time using Random\r@time using Distributions\r@time using LinearAlgebra\r@time using DifferentialEquations\r#---\rfunction malthusian_growth!(du,u,p,t)\rN = u[1]\rr = p\rdu[1] = dN = r*N\rend\ru0 = [50.0]\rp = 2.65\rtspan = (0.,1.8)\rprob = ODEProblem(malthusian_growth!,u0,tspan,p)\rsol = solve(prob; saveat=(0.0:0.1:1.8))\rcompare = plot(sol,vars=(0,1),\rlinestyle = :dash, color = :black,\rsize = (400,300), label = \u0026#34;Theoretical\u0026#34;, legend=:topleft)\r#---\rN0 = 50 # Ï¥àÍ∏∞ Ïù∏Íµ¨Ïàò\rb = 0.05 # Î≤àÏãùÎ•†\rd = 0.02 # ÏÇ¨ÎßùÎ•†\rmax_iteration = 180 # ÏãúÎÆ¨Î†àÏù¥ÏÖò Í∏∞Í∞Ñ\rgaussian2 = MvNormal([0.0; 0.0], 0.03I) # 2Ï∞®Ïõê Ï†ïÍ∑úÎ∂ÑÌè¨\rRandom.seed!(0)\rtime_evolution = [] # Ïù∏Íµ¨ÏàòÎ•º Í∏∞Î°ùÌïòÍ∏∞ ÏúÑÌïú\rlet\rcoordinate = rand(gaussian2, N0)\u0026#39;\rN = N0\ranim = @animate for t = (0:max_iteration)/100\rrow2 = @layout [a{0.6h}; b]\rfigure = plot(size = [300,500], layout = row2)\rplot!(figure[1], coordinate[:,1], coordinate[:,2], Seriestype = :scatter,\rmarkercolor = RGB(1.,94/255,0.), markeralpha = 0.4, markerstrokewidth\t= 0.1,\raspect_ratio = 1, title = \u0026#34;t = $t\u0026#34;,\rxaxis=true,yaxis=true,axis=nothing, legend = false)\rxlims!(figure[1], -10.,10.)\rylims!(figure[1], -10.,10.)\rreplicated = (rand(N) .\u0026lt; b) # Î≤àÏãù ÌåêÏ†ï\rnew_coordinate = coordinate[replicated,:]\rcoordinate = coordinate[rand(N) .\u0026gt; d,:] # ÏÇ¨Îßù ÌåêÏ†ï\rcoordinate = cat(coordinate, new_coordinate, dims = 1);\rN = size(coordinate, 1)\rpush!(time_evolution, N)\rcoordinate = coordinate + rand(gaussian2, N)\u0026#39;\rif t \u0026lt; 0.9\rplot!(figure[2], sol,vars=(0,1),\rlinestyle = :dash, color = :black,\rlabel = \u0026#34;Theoretical\u0026#34;, legend=:bottomright)\relse\rplot!(figure[2], sol,vars=(0,1),\rlinestyle = :dash, color = :black,\rlabel = \u0026#34;Theoretical\u0026#34;, legend=:topleft)\rend\rplot!(figure[2], 0.0:0.01:t, Time_evolution,\rcolor = RGB(1.,94/255,0.), linewidth = 2, label = \u0026#34;Simulation\u0026#34;,\ryscale = :log10, yticks = 10 .^(1:4))\rylims!(figure[2], 0.,min(time_evolution[end]*2,10000.))\rend\rgif(anim, \u0026#34;malthusian_growth_integration1.gif\u0026#34;, fps = 18)\rend\r#---\rfunction malthusian_growth!(du,u,p,t)\rN = u[1]\rr = p\rdu[1] = dN = r*N\rend\ru0 = [50.0]\rp = -1\rtspan = (0.,1.8)\rprob = ODEProblem(malthusian_growth!,u0,tspan,p)\rsol = solve(prob; saveat=(0.0:0.1:1.8))\rcompare = plot(sol,vars=(0,1),\rlinestyle = :dash, color = :black,\rsize = (400,300), label = \u0026#34;Theoretical\u0026#34;, legend=:topleft)\r#---\rN0 = 50 # Ï¥àÍ∏∞ Ïù∏Íµ¨Ïàò\rb = 0.04 # Î≤àÏãùÎ•†\rd = 0.05 # ÏÇ¨ÎßùÎ•†\rmax_iteration = 180 # ÏãúÎÆ¨Î†àÏù¥ÏÖò Í∏∞Í∞Ñ\rgaussian2 = MvNormal([0.0; 0.0], 0.03I) # 2Ï∞®Ïõê Ï†ïÍ∑úÎ∂ÑÌè¨\rRandom.seed!(0)\rtime_evolution = [] # Ïù∏Íµ¨ÏàòÎ•º Í∏∞Î°ùÌïòÍ∏∞ ÏúÑÌïú\rlet\rcoordinate = rand(gaussian2, N0)\u0026#39;\rN = N0\ranim = @animate for t = (0:max_iteration)/100\rrow2 = @layout [a{0.6h}; b]\rfigure = plot(size = [300,500], layout = row2)\rplot!(figure[1], coordinate[:,1], coordinate[:,2], Seriestype = :scatter,\rmarkercolor = RGB(1.,94/255,0.), markeralpha = 0.4, markerstrokewidth\t= 0.1,\raspect_ratio = 1, title = \u0026#34;t = $t\u0026#34;,\rxaxis=true,yaxis=true,axis=nothing, legend = false)\rxlims!(figure[1], -10.,10.)\rylims!(figure[1], -10.,10.)\rreplicated = (rand(N) .\u0026lt; b) # Î≤àÏãù ÌåêÏ†ï\rnew_coordinate = coordinate[replicated,:]\rcoordinate = coordinate[rand(N) .\u0026gt; d,:] # ÏÇ¨Îßù ÌåêÏ†ï\rcoordinate = cat(coordinate, new_coordinate, dims = 1);\rN = size(coordinate, 1)\rpush!(time_evolution, N)\rcoordinate = coordinate + rand(gaussian2, N)\u0026#39;\rplot!(figure[2], sol,vars=(0,1),\rlinestyle = :dash, color = :black,\rlabel = \u0026#34;Theoretical\u0026#34;, legend=:topright)\rplot!(figure[2], 0.0:0.01:t, Time_evolution,\rcolor = RGB(1.,94/255,0.), linewidth = 2, label = \u0026#34;Simulation\u0026#34;,\ryscale = :log10, yticks = 10 .^(1:4))\rylims!(figure[2], 0., 50.)\rend\rgif(anim, \u0026#34;malthusian_growth_integration2.gif\u0026#34;, fps = 18)\rend\r#---\rfunction malthusian_growth!(du,u,p,t)\rN = u[1]\rr = p\rdu[1] = dN = r*N\rend\ru0 = [50.0]\rp = 0\rtspan = (0.,3.)\rprob = ODEProblem(malthusian_growth!,u0,tspan,p)\rsol = solve(prob; saveat=(0.0:0.1:3.0))\rcompare = plot(sol,vars=(0,1),\rlinestyle = :dash, color = :black,\rsize = (400,300), label = \u0026#34;Theoretical\u0026#34;, legend=:topleft)\r#---\rN0 = 50 # Ï¥àÍ∏∞ Ïù∏Íµ¨Ïàò\rb = 0.05 # Î≤àÏãùÎ•†\rd = 0.05 # ÏÇ¨ÎßùÎ•†\rmax_iteration = 300 # ÏãúÎÆ¨Î†àÏù¥ÏÖò Í∏∞Í∞Ñ\rgaussian2 = MvNormal([0.0; 0.0], 0.03I) # 2Ï∞®Ïõê Ï†ïÍ∑úÎ∂ÑÌè¨\rRandom.seed!(0)\rtime_evolution = [] # Ïù∏Íµ¨ÏàòÎ•º Í∏∞Î°ùÌïòÍ∏∞ ÏúÑÌïú\rlet\rcoordinate = rand(gaussian2, N0)\u0026#39;\rN = N0\ranim = @animate for t = (0:max_iteration)/100\rrow2 = @layout [a{0.6h}; b]\rfigure = plot(size = [300,500], layout = row2)\rplot!(figure[1], coordinate[:,1], coordinate[:,2], Seriestype = :scatter,\rmarkercolor = RGB(1.,94/255,0.), markeralpha = 0.4, markerstrokewidth\t= 0.1,\raspect_ratio = 1, title = \u0026#34;t = $t\u0026#34;,\rxaxis=true,yaxis=true,axis=nothing, legend = false)\rxlims!(figure[1], -10.,10.)\rylims!(figure[1], -10.,10.)\rreplicated = (rand(N) .\u0026lt; b) # Î≤àÏãù ÌåêÏ†ï\rnew_coordinate = coordinate[replicated,:]\rcoordinate = coordinate[rand(N) .\u0026gt; d,:] # ÏÇ¨Îßù ÌåêÏ†ï\rcoordinate = cat(coordinate, new_coordinate, dims = 1);\rN = size(coordinate, 1)\rpush!(time_evolution, N)\rcoordinate = coordinate + rand(gaussian2, N)\u0026#39;\rplot!(figure[2], sol,vars=(0,1),\rlinestyle = :dash, color = :black,\rlabel = \u0026#34;Theoretical\u0026#34;, legend=:topleft)\rplot!(figure[2], 0.0:0.01:t, Time_evolution,\rcolor = RGB(1.,94/255,0.), linewidth = 2, label = \u0026#34;Simulation\u0026#34;,\ryscale = :log10, yticks = 10 .^(1:4))\rylims!(figure[2], 0., 100.)\rend\rgif(anim, \u0026#34;malthusian_growth_integration3.gif\u0026#34;, fps = 18)\rend ","id":1871,"permalink":"https://freshrimpsushi.github.io/en/posts/1871/","tags":["Ï§ÑÎ¶¨ÏïÑ"],"title":"Malthus Growth Model: Ideal Population Growth"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Although the original Sakura Sushi restaurant tends to add much more detailed explanations, to emphasize how easy it is to create animated GIFs in Julia, we will keep this explanation as brief as possible.\nEven setting aside simulating a random walk, creating an animated GIF like the one above can be very difficult and demanding, depending on the language. However, Julia makes this incredibly easy with the @animate macro and gif() function. The principle is simple. Attach the macro in front of a loop and draw the frames one by one as the loop executes. Once the frames are gathered into a variable, simply putting them into the gif() function is all it takes. The fps option allows you to set the speed of the animated GIF by specifying frames per second.\nusing Plots\rrandom\\_walk = cumsum(rand(100).-.5)\ranim = @animate for t in 1:100\rplot(random\\_walk[1:t], legend = :none)\rend; gif(anim, \u0026#34;example.gif\u0026#34;, fps = 10) Be mindful that if you don\u0026rsquo;t specify a different path, it will be saved in your documents. By making good use of this, one can create amazing animated GIFs like the one shown below.\n","id":1863,"permalink":"https://freshrimpsushi.github.io/en/posts/1863/","tags":null,"title":"Making GIFs in Julia"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition A subset $M$ of a vector space $V$ is called a convex set if the following equation holds:\n$$ \\lambda x +(1-\\lambda)y \\in M,\\quad \\forall \\lambda\\in[0,1],\\ \\forall x,y \\in M $$\nDescription Verbally, this equation means \u0026quot;$M$ is a convex set implies that every vector lying between any two vectors in $M$ also belongs to $M$\u0026quot;. Also, if $M$ is a subspace, it is closed under addition and scalar multiplication, making it a convex set.\n","id":1914,"permalink":"https://freshrimpsushi.github.io/en/posts/1914/","tags":null,"title":"Convex Sets in Vector Spaces"},{"categories":"ÏïåÍ≥†Î¶¨Ï¶ò","contents":"Definition The following five bases are referred to as the Canonical Bases:\nPurine bases: Adenine $A$, Guanine $G$ Pyrimidine bases: Cytosine $C$, Thymine $T$, Uracil $U$ Description Thymine is only used in DNA, while Uracil is used in RNA. Therefore, by checking whether $T$ or $U$ is used in the data, one can tell whether it is a DNA or RNA base sequence.\nA Base Pair is formed by two bases capable of hydrogen bonding, with one selected from each of the purine and pyrimidine bases. Among them, there are $A-T, A-U, G-C$ possible cases.\n$A-T$ and $A-U$ are connected by 2 hydrogen bonds, and $G-C$ by 3 hydrogen bonds. DNA has a double helical structure due to base pairing. Therefore, if $A$ is on one strand, $T$ must be on the opposite strand. $$ A-T \\\\ C-G \\\\ C-G \\\\ G-C \\\\ T-A \\\\ T-A \\\\ A-T \\\\ C-G $$ For example, with a DNA sample like the one above, knowing one strand is enough. Thus, when acquiring data, one can simply read the left side and record it like this: ACCGTTAC. The significance of the double helical structure is essentially a \u0026lsquo;backup\u0026rsquo;. Indeed, RNA, which is made of a single strand and has an unstable structure, often causes problems. However, DNA can stably pass on genetic information to future generations as the opposite strand can serve as a reference when problems arise on one strand.\n","id":1832,"permalink":"https://freshrimpsushi.github.io/en/posts/1832/","tags":null,"title":"Key Bases and Base Pairs in Bioinformatics"},{"categories":"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ","contents":"Definition1 Let $\\left( X, \\left\\langle \\cdot, \\cdot \\right\\rangle \\right)$ be an inner product space. If two elements $\\mathbf{x}, \\mathbf{y}\\in X$ satisfy $\\left\\langle \\mathbf{x}, \\mathbf{y} \\right\\rangle =0$, then $\\mathbf{y}$ and $\\mathbf{x}$ are said to be orthogonal and denoted as follows.\n$$ \\mathbf{x} \\perp \\mathbf{y} $$\nIf the set of elements $X$, $\\left\\{ \\mathbf{x}_{k} \\right\\}_{k\\in \\mathbb{N}}$, satisfies the following equation, it is called an orthogonal system or an orthogonal set.\n$$ \\left\\langle \\mathbf{x}_{k}, \\mathbf{x}_{\\ell} \\right\\rangle =0\\quad \\forall k\\ne \\ell $$\nIf the orthogonal system $\\left\\{ \\mathbf{x}_{k} \\right\\}_{k\\in \\mathbb{N}}$ satisfies the following equation, it is called an orthonormal system or an orthonormal set.\n$$ \\left\\| \\mathbf{x}_{k} \\right\\| =1\\quad \\forall k\\in \\mathbb{N} $$\nExplanation In an inner product space, since the norm is defined as $\\left\\| \\cdot \\right\\|:=\\sqrt{\\left\\langle \\cdot,\\cdot \\right\\rangle }$, redefining the orthonormal system gives the following equation.\n$$ \\left\\| \\mathbf{x}_{k} \\right\\| = \\left\\langle \\mathbf{x}_{k},\\mathbf{x}_{\\ell} \\right\\rangle = \\begin{cases} 1 \u0026amp; \\text{if}\\ k=\\ell \\\\ 0 \u0026amp; \\text{if}\\ k\\ne \\ell \\end{cases} $$\nMoreover, there is no need for the orthogonal system to be defined specifically for a countable set.\nDefinition2 Let $A$ be an arbitrary index set, and $\\alpha$, $\\beta$ be indices of $A$. If the set of elements $X$, $\\left\\{ \\mathbf{x}_{\\alpha} \\right\\}_{\\alpha \\in A}$, satisfies the following equation, it is called an orthogonal system or an orthogonal set.\n$$ \\left\\langle \\mathbf{x}_{\\alpha}, \\mathbf{x}_{\\beta} \\right\\rangle =0\\quad \\forall \\alpha \\ne \\beta $$\nIf the orthogonal system $\\left\\{ \\mathbf{x}_{\\alpha} \\right\\}_{\\alpha \\in A}$ satisfies the following equation, it is called an orthonormal system or an orthonormal set.\n$$ \\left\\| \\mathbf{x}_{\\alpha} \\right\\| =1\\quad \\forall \\alpha \\in A $$\nExplanation Therefore, for the orthonormal system $\\left\\{ \\mathbf{x}_{\\alpha} \\right\\}_{\\alpha \\in A}$, the following equation is obtained.\n$$ \\left\\langle \\mathbf{x}_{\\alpha},\\mathbf{x}_{\\beta} \\right\\rangle =\\begin{cases} 1 \u0026amp; \\text{if}\\ \\alpha=\\beta \\\\ 0 \u0026amp; \\text{if}\\ \\alpha \\ne \\beta \\end{cases} $$\nOle Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p66-67\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWalter Rudin, Real and Complex Analysis (3rd Edition, 1987), p82-83\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1912,"permalink":"https://freshrimpsushi.github.io/en/posts/1912/","tags":null,"title":"Orthogonality, Orthogonal Sets, and Orthonormal Sets in Inner Product Spaces"},{"categories":"ÏïåÍ≥†Î¶¨Ï¶ò","contents":"Build-up A polymer is a large molecule composed of repeating monomeric units linked by chemical synthesis. Phosphoric Acid is a type of inorganic oxyacid, with the chemical formula $H_{3}PO_{4}$. A monosaccharide with five carbon atoms is called Pentose. The molecule that functions as the basic unit of genetic information is known as a Nitrogenous base or simply Base. A nucleotide is a molecule that consists of phosphate-pentose-base and becomes the monomeric unit of nucleic acids. Essential for life processes, the polymer of nucleotides is called Nucleic Acid. The nucleic acid that forms a chain structure based on the pentose ribose is called Ribo Nucleic Acid (RNA). The nucleic acid that consists of two long strands of nucleotide polymers twisted together into a double helix structure is called Deoxyribo Nucleic Acid (DNA). DNA or RNA are known as Genetic Material. Comparison with Chromosomes If we accept these explanations as definitions, then DNA and RNA, beyond being genetic materials, are actually existing polymers, and depending on what bases constitute the nucleotides, their combinations could be infinite. RNA follows the form of an ordered chain, while DNA has its chains form base pairs and a double helix structure. This means that by looking into genetic materials and recording their order, we can obtain genetic information.\nWith this information age as a starting point, we declare a departure from chemistry and biology. If we focus on the differences with chromosomes, then DNA or RNA getting twisted and clumped together forms a chromosome, whereas the act of reading and noting down information forms the nucleotide sequence. Chromosomes are physical entities, whereas nucleotide sequences are data.\nDefinition The arrangement of the bases of genetic material in sequence is known as a Nucleic Sequence. Major Bases and Characters In the context of bioinformatics, the major bases are limited to five characters $A, T, G, C, U$. These, in order from the front, represent adenine, thymine, guanine, cytosine, and uracil; from a computer science perspective, the information encoded nucleotide sequences become strings of these five characters. It\u0026rsquo;s important to understand that what data analysts are dealing with are not DNA or RNA themselves but their nucleotide sequences.\nThe primary issue in dealing with nucleotide sequences is that their sizes are not small by any means. For instance, the human genome is comprised of a whopping 3.3 billion base pairs, requiring more intelligent approaches than the naive method of reading from front to back for analyzing them and producing meaningful results.\nMoreover, the direction of nucleotide sequences can be determined by checking upstream and downstream, so there‚Äôs no need to worry about nucleotide sequences being reversed.\n","id":1828,"permalink":"https://freshrimpsushi.github.io/en/posts/1828/","tags":null,"title":"Bioinformatics: DNA Sequencing"},{"categories":"Ìë∏Î¶¨ÏóêÌï¥ÏÑù","contents":"Overview The definition and notation of the Fourier transform vary depending on the needs and preferences of the author. Therefore, before dealing with the Fourier transform in textbooks, lectures, research papers, etc., it is common to clarify the definition and notation. If you skip over the definition thinking it is a concept you know, you might find the equations odd, so it is necessary to check carefully. Of course, the most important thing is that all these definitions are essentially the same, so there is no need to be too concerned about the notation or the definition itself. This document introduces the advantages and disadvantages, as well as the differences, of each definition.\nDescription1 The Fourier transform can be naturally induced by thinking of a Fourier series of a function whose period is the entire set of real numbers. In this process, the Fourier transform and the inverse Fourier transform are defined as follows:\nFourier Transform Inverse Fourier Transform $\\displaystyle \\hat{f}(\\xi):=\\int _{-\\infty} ^{\\infty}f(x)e^{-i \\xi x}dx$ $\\displaystyle f(x):=\\frac{1}{2\\pi}\\int _{-\\infty} ^{\\infty}\\hat{f}(\\xi)e^{i \\xi x}d\\xi$ Here, $\\hat{}$ is read as \u0026ldquo;hat\u0026rdquo;. $\\hat{f}(\\xi)$ is read as \u0026ldquo;F hat of xi\u0026rdquo;. When one wants to emphasize the feeling of being an operator, the feeling of being an integral transform, or when one needs to use the ${}^{\\prime}$ symbol for derivative together with the $\\hat{}$ symbol, or to avoid confusion, it may be written in the following notation:\nFourier Transform Inverse Fourier Transform $\\mathcal{F}:L^{1} \\to L^{1}$ $\\mathcal{F}^{-1}:L^{1} \\to L^{1}$ $\\displaystyle \\mathcal{F}f(\\xi):=\\int _{-\\infty} ^{\\infty}f(x)e^{-i \\xi x}dx$ $\\displaystyle \\mathcal{F}^{-1}f(x):=\\frac{1}{2\\pi}\\int _{-\\infty} ^{\\infty}f(\\xi)e^{i \\xi x}d\\xi$ The notation $\\mathscr{F}$ is also used. Apart from the notation differences, the definition of the Fourier transform itself may differ as follows:\nFourier Transform Inverse Fourier Transform $\\displaystyle \\hat{f}(\\xi):=\\frac{1}{\\sqrt{2\\pi}}\\int _{-\\infty} ^{\\infty}f(x)e^{-i \\xi x}dx$ $\\displaystyle f(x):=\\frac{1}{\\sqrt{2\\pi}}\\int _{-\\infty} ^{\\infty}\\hat{f}(\\xi)e^{i \\xi x}d\\xi$ $\\displaystyle \\hat{f}(\\xi):=\\int _{-\\infty} ^{\\infty}f(x)e^{-2\\pi i \\xi x}dx$ $\\displaystyle f(x):=\\int _{-\\infty} ^{\\infty}\\hat{f}(\\xi)e^{2\\pi i \\xi x}d\\xi$ For the sake of clarity in the explanation, let\u0026rsquo;s denote each of the above definitions as follows.\n$$ \\tilde{f}(\\xi):=\\frac{1}{\\sqrt{2\\pi}}\\int _{-\\infty} ^{\\infty}f(x)e^{-i \\xi x}dx \\quad \\text{and} \\quad \\check{f}(\\xi):=\\int _{-\\infty} ^{\\infty}f(x)e^{-2\\pi i \\xi x}dx $$\nThe variety of definitions for the Fourier transform can be seen in the table below.\nPlancherel Theorem Convolution Fourier Transform of Derivatives $\\| \\hat{f} \\|^{2} =2\\pi\\left\\| f \\right\\|^{2}$ $(f \\ast g)\\hat{}=\\hat{f}\\hat{g}$ $(f^{\\prime})\\hat{} (\\xi)=i\\xi \\hat{f}(\\xi)$ $\\| \\tilde{f} \\|^{2}=\\left\\| f \\right\\|^{2}$ $(f \\ast g)\\tilde{}=\\sqrt{2\\pi}\\tilde{f}\\tilde{g}$ $(f^{\\prime})\\tilde{} (\\xi)=i\\xi \\tilde{f}(\\xi)$ $\\| \\check{f} \\|^{2}=\\left\\| f \\right\\|^{2}$ $(f \\ast g)\\check{}=\\check{f}\\check{g}$ $(f^{\\prime})\\check{} (\\xi)=2\\pi i\\xi \\check{f}(\\xi)$ As can be seen in the table, depending on the definition, the formula where the constant $2\\pi$ appears can differ. Therefore, the definition can change depending on what formula one wants to simplify. Empirically, in fields like signal and image processing, definitions like $\\check{f}$ are often used. Also, in the definition of the Fourier transform, there might not be a minus sign $(-)$ in the exponent. In that case, since it will be on the inverse side, do not be confused even if it is different from the definition you know.\nGerald B. Folland, Fourier Analysis and Its Applications (1992), p223-224\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1898,"permalink":"https://freshrimpsushi.github.io/en/posts/1898/","tags":null,"title":"Several Definitions and Notations of Fourier Transform"},{"categories":"ÏïåÍ≥†Î¶¨Ï¶ò","contents":"Buildup Polymers are high molecular compounds formed by the repeating connection of monomers through chemical synthesis. Phosphoric Acid is a type of inorganic oxyacid, with the chemical formula $H_{3}PO_{4}$. Monosaccharides with five carbon atoms are called Pentoses. Molecules that function as the basic unit of genetic information are called Nitrogenous bases, or simply Bases. A molecule composed of phosphate, pentose, and a base, serving as the building block of nucleic acids, is called a Nucleotide. Nucleic Acids, essential for biological phenomena, are polymers of nucleotides. The nucleic acid that forms a chain structure based on the pentose ribose is called Ribo Nucleic Acid (RNA). The nucleic acid with two long strands of nucleotide polymers twisted together in a double-helix structure is called Deoxyribo Nucleic Acid (DNA). DNA or RNA is referred to as Genetic Material. Differences between DNA and RNA These terms might seem insignificant on their own in the field of bioinformatics, but not knowing them might make you feel foolish, so it is recommended to look them up on Wikipedia in your free time.\nThe differences between DNA and RNA are as follows:\nDNA has base pairs making it double-stranded, and RNA is single-stranded. Thus, DNA is much more stable than RNA. DNA uses $A,T,C,G$ as major bases, while RNA uses $A,U,C,G$. Definition A Chromosome is when the genetic material in a cell, scattered in the nucleus in the form of chromatin, becomes condensed. Comparison with Base Sequence Chromosomes are observed during cell division in eukaryotes, usually inherited one from each parent, forming a pair. In humans, there are 22 pairs of autosomes and one pair of XY sex chromosomes.\nIf you\u0026rsquo;re interested in understanding the differences between base sequences, think of DNA or RNA being twisted and clumped together to form chromosomes, while base sequences are like notes taken to read and write down information. Chromosomes are physical entities, whereas base sequences are data.\nEven in bioinformatics, unless there is a specific interest in the physical structure, data analysts might not deal with chromosomes. However, it‚Äôs still important to know what each term refers to avoid confusion when dealing with DNA, RNA, genes, genomes, etc.\n","id":1827,"permalink":"https://freshrimpsushi.github.io/en/posts/1827/","tags":null,"title":"Biomedical Informatics: DNA, RNA, Chromosomes"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview The Distance Matrix is commonly used in simulations based on Particle Dynamics and Moving Agents, but it is often difficult to find a ready-made function for this purpose, and coding it from scratch can be daunting. In Julia, you can easily calculate a distance matrix using the pairwise() function and the Euclidean() function from the Distances package1.\nThe dims option allows you to specify the direction of rows and columns. As you can see, given a $\\mathbb{R}^{5 \\times 3}$ matrix, it is possible to calculate the distances of $5$dimensional vectors for $3$ instances or the distances of $3$dimensional vectors for $5$ instances.\nCode using Distances\rcoordinate = [2 3 4; 5 1 3; 1 7 5; 1 7 6; 2 4 3]\rpairwise(Euclidean(), coordinate; dims=1)\rpairwise(Euclidean(), coordinate; dims=2) The result of running the above code is as follows.\njulia\u0026gt; using Distances\rjulia\u0026gt; coordinate = [2 3 4; 5 1 3; 1 7 5; 1 7 6; 2 4 3]\r5√ó3 Array{Int64,2}:\r2 3 4\r5 1 3\r1 7 5\r1 7 6\r2 4 3\rjulia\u0026gt; pairwise(Euclidean(), coordinate; dims=1)\r5√ó5 Array{Float64,2}:\r0.0 3.74166 4.24264 4.58258 1.41421\r3.74166 0.0 7.48331 7.81025 4.24264\r4.24264 7.48331 0.0 1.0 3.74166\r4.58258 7.81025 1.0 0.0 4.3589\r1.41421 4.24264 3.74166 4.3589 0.0\rjulia\u0026gt; pairwise(Euclidean(), coordinate; dims=2)\r3√ó3 Array{Float64,2}:\r0.0 9.64365 7.07107\r9.64365 0.0 3.31662\r7.07107 3.31662 0.0 Optimization How to optimize distance matrix calculation https://discourse.julialang.org/t/pairwise-distances-from-a-single-column-or-vector/29415/3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1799,"permalink":"https://freshrimpsushi.github.io/en/posts/1799/","tags":null,"title":"How to Compute Distance Matrices in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Size Specification julia\u0026gt; empty = Array{Float64, 2}(undef, 3, 4)\r3√ó4 Array{Float64,2}:\r3.39519e-313 3.18299e-313 4.66839e-313 1.061e-313\r4.03179e-313 5.51719e-313 1.6976e-313 4.24399e-314\r2.97079e-313 4.66839e-313 7.00259e-313 5.0e-324 Executing the code above results in an empty array being created. Occasionally, it may seem like a strange value such as 1.76297e-315 is entered, but this is a value very close to 0, so it\u0026rsquo;s not a major issue for initialization.\nArray{X, Y}(undef, ...) creates an array of size ... filled with uninitialized values of data type X and dimension Y. The key here is undef.\nResizable Arrays In the case of a one-dimensional array, an empty array can be simply made by not putting anything inside the parentheses.\njulia\u0026gt; empty = Array{Float64, 1}()\rFloat64[]\rjulia\u0026gt; empty = Array{Float64, 2}()\rERROR: MethodError: no method matching Array{Float64,2}()\rClosest candidates are:\rArray{Float64,2}(::UndefInitializer, ::Int64, ::Int64) where T at boot.jl:408\rArray{Float64,2}(::UndefInitializer, ::Int64...) where {T, N} at boot.jl:412\rArray{Float64,2}(::UndefInitializer, ::Tuple{Int64,Int64}) where T at boot.jl:416\r...\rStacktrace:\r[1] top-level scope at REPL[85]:1 However, trying to do the same for a two-dimensional array will result in a MethodError as shown above. Of course, it\u0026rsquo;s possible to create an empty array by making an array of one-dimensional arrays, but from a speed perspective, it is recommended to use the native syntax as it is.\njulia\u0026gt; empty = Array{Array{Float64, 1}, 1}()\rArray{Float64,1}[] A Simpler Method Using curly braces like below makes creating arrays even more straightforward.\njulia\u0026gt; empty = Float64[]\rFloat64[]\rjulia\u0026gt; empty = Array{Float64, 1}[]\rArray{Float64,1}[]\rjulia\u0026gt; empty = Array{Float64, 2}[]\rArray{Float64,2}[] Environment OS: Windows julia: v1.5.0 ","id":1797,"permalink":"https://freshrimpsushi.github.io/en/posts/1797/","tags":null,"title":"How to Create an Empty Array in Julia"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition The Laplacian of a 3D scalar function $f=f(x,y,z)$ is the divergence of its gradient $f$ and is denoted by $\\nabla^{2}$.\n$$ \\nabla ^{2} f := \\nabla \\cdot(\\nabla f)= \\frac{ \\partial^{2} f}{ \\partial x^{2} }+\\frac{ \\partial^{2} f}{ \\partial y^{2}}+\\frac{ \\partial^{2} f}{ \\partial z^{2}} $$\nExplanation The name Laplacian comes from the French mathematician Laplace. The notation $\\nabla^{2}$ is used for convenience. In mathematics (theory of partial differential equations), the notation $\\Delta$ is more commonly used. In a nutshell, the Laplacian is an extension of the second-order derivative. If the gradient is an extension of the first-order derivative into three dimensions, then the Laplacian is an extension of the second-order derivative into three dimensions. You might have learned the following content in high school calculus.\n1\nWhile the first-order derivative simply provides information on whether function $f$ is increasing or decreasing, the second-order derivative gives information on how it is increasing or decreasing. The formula for the Laplacian of $f$, as shown above, is nothing more than the formula for divergence with an additional differentiation.\nDerivation There\u0026rsquo;s really nothing to derive.\n$$ \\begin{align*} \\nabla \\cdot (\\nabla f) \u0026amp;= \\nabla \\cdot \\left( \\frac{ \\partial f}{ \\partial x },\\frac{ \\partial f}{ \\partial y},\\frac{ \\partial f}{ \\partial z} \\right) \\\\ \u0026amp;= \\frac{ \\partial ^{2} f }{ \\partial x^{2} }+\\frac{ \\partial ^{2} f }{ \\partial y^{2} } + \\frac{ \\partial ^{2}f }{ \\partial z^{2} } \\end{align*} $$\n‚ñ†\nSee Also Del operator $\\nabla$ Gradient $\\nabla f$ Divergence $\\nabla \\cdot \\mathbf{F}$ Curl $\\nabla \\times \\mathbf{F}$ Laplacian $\\nabla^{2} f$ EBS 2021 Academic year University Entrance Exam Special Calculus p.70\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1879,"permalink":"https://freshrimpsushi.github.io/en/posts/1879/","tags":null,"title":"Laplacian of a Scalar Function in the Three-Dimensional Cartesian Coordinate System"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 A random variable $X$ and a sequence of random variables $\\left\\{ X_{n} \\right\\}$ are said to converge in probability to $X$ as $n \\to \\infty$ if they satisfy the following, and it is denoted by $X_{n} \\overset{P}{\\to} X$. $$ \\forall \\varepsilon \u0026gt; 0 , \\lim_{n \\to \\infty} P \\left[ \\left| X_{n} - X \\right| \u0026lt; \\varepsilon \\right] = 1 $$\nExplanation The condition for convergence in probability is exactly as it\u0026rsquo;s defined in terms of probabilities, which simply means that as $n$ increases, the two random variables are likely to be equal with a very small error $\\varepsilon$. This is precisely what is meant by convergence in probability. In equations, this is represented by the following equivalent but more convenient expression. $$ \\forall \\varepsilon \u0026gt; 0 , \\lim_{n \\to \\infty} P \\left[ \\left| X_{n} - X \\right| \\ge \\varepsilon \\right] = 0 $$ As is known, a random variable is a function from a sample space to real numbers, and comparing two functions in terms of their difference $\\varepsilon$ makes it analogous to the uniform convergence of functions in analytical terms. This analogy extends to the fact that if there is uniform convergence, there is pointwise convergence, just as if there is convergence in probability, there is convergence in distribution. If the sudden appearance of epsilon is unwelcome, it\u0026rsquo;s time to get familiar with it or give up on mathematical statistics. In statistics, saying $n$ increases is not just about sending some number to infinity, it mathematically represents the assumption of having a sufficiently large sample size, and if one cannot discuss the sample size in theoretical statistical development using probability theory, then there\u0026rsquo;s essentially nothing to be done. No matter how awkward analysis may seem to the reader, an effort should be made to at least read and understand Part 1. of the proof [3] presented in this post. Here are some intuitive properties of probability convergence.\nTheorem Let\u0026rsquo;s assume $X_{n} \\overset{P}{\\to} X$.\n[1] Continuous Mapping Theorem: For a continuous function $g$, $$ g\\left( X_{n} \\right) \\overset{P}{\\to} g (X) $$ [2]: Convergence in probability implies convergence in distribution. That is, $$ X_{n} \\overset{P}{\\to} X \\implies X_{n} \\overset{D}{\\to} X $$ [3]: If $a \\in \\mathbb{R}$ is constant and $ Y_{n} \\overset{P}{\\to} Y$, $$ aX_{n} \\overset{P}{\\to} a X \\\\ X_{n} + Y_{n} \\overset{P}{\\to} X + Y \\\\ X_{n} Y_{n} \\overset{P}{\\to} XY $$ Proof [1] There are proofs beyond the undergraduate level, and it\u0026rsquo;s not necessary to delve into the depth of mathematical statistics to understand. It\u0026rsquo;s acceptable to just accept and move on.\n‚ñ†\n[2] Direct deduction.\n‚ñ†\n[3] Part 1. $aX_{n} \\overset{P}{\\to} a X $\nAlthough it can also be directly concluded from the Continuous Mapping Theorem, we choose to conduct a direct deduction as an example of an analytical proof. It\u0026rsquo;s trivially true if $a = 0$, so let us assume $a \\ne 0$.\nIf we define $\\varepsilon \u0026gt; 0$, then by dividing $|a|$ inside the probability of $P$, we obtain the following equation. $$ \\begin{align*} P \\left( \\left| a X_{n} - aX \\right| \\ge \\varepsilon \\right) =\u0026amp; P \\left( |a| \\left| X_{n} - X \\right| \\ge \\varepsilon \\right) \\\\ =\u0026amp; P \\left( \\left| X_{n} - X \\right| \\ge {{ \\varepsilon } \\over { |a| }} \\right) \\end{align*} $$ Given the assumption that $X_{n} \\overset{P}{\\to} X$ as $n \\to \\infty$, the last term converges to $0$ as $n \\to \\infty$, hence taking the limit for the first term yields the following. $$ \\lim_{n \\to \\infty} P \\left( \\left| a X_{n} - aX \\right| \\ge \\varepsilon \\right) = 0 $$\nPart 2. $X_{n} + Y_{n} \\overset{P}{\\to} X + Y$\nIt\u0026rsquo;s not too difficult as long as you don\u0026rsquo;t confuse the direction of the inequality. According to the Triangle Inequality, $$ \\left| \\left( X_{n} - X \\right) + \\left( Y_{n} - Y \\right) \\right| \\le \\left| X_{n} - X \\right| + \\left| Y_{n} - Y \\right| $$ Following the diagram below the inclusion relation of the two events $$ \\color{blue}{\\left( \\left| X_{n} - X \\right| + \\left| Y_{n} - Y \\right| \\ge \\varepsilon \\right) } \\subset \\color{orange}{ \\left[ \\left( \\left| X_{n} - X \\right| \\ge \\varepsilon / 2 \\right) \\cup \\left( \\left| Y_{n} - Y \\right| \\ge \\varepsilon / 2 \\right) \\right] } $$ is evident. Now assuming $\\varepsilon \\le \\left| \\left( X_{n} - X \\right) + \\left( Y_{n} - Y \\right) \\right|$, $$ \\begin{align*} P \\left[ \\left| \\left( X_{n} + Y_{n} \\right) - \\left( X + Y \\right) \\right| \\ge \\varepsilon \\right] =\u0026amp; P \\left[ \\left| \\left( X_{n} - X \\right) + \\left( Y_{n} - Y \\right) \\right| \\ge \\varepsilon \\right] \\\\ \\le \u0026amp; P \\left[ \\color{blue}{ \\left| X_{n} - X \\right| + \\left| Y_{n} - Y \\right| \\ge \\varepsilon } \\right] \\\\ \\le \u0026amp; P \\left[ \\color{orange}{ \\left( \\left| X_{n} - X \\right| \\ge \\varepsilon / 2 \\right) \\cup \\left( \\left| Y_{n} - Y \\right| \\ge \\varepsilon / 2 \\right) } \\right] \\\\ \\le \u0026amp; P \\left[ \\left| X_{n} - X \\right| \\ge \\varepsilon / 2 \\right] + P \\left[ \\left| Y_{n} - Y \\right| \\ge \\varepsilon / 2 \\right] \\end{align*} $$ since the last term converges to $0$ as $n \\to \\infty$, we obtain the following. $$ \\lim_{n \\to \\infty} P \\left[ \\left| \\left( X_{n} + Y_{n} \\right) - \\left( X + Y \\right) \\right| \\ge \\varepsilon \\right] \\le 0 $$\nPart 3. $X_{n} Y_{n} \\overset{P}{\\to} XY$\n$$ g(x) := x^{2} $$ is a continuous function, so by theorem [1] $X_{n} \\overset{P}{\\to} X$, and $$ \\begin{align*} X_{n} Y_{n} =\u0026amp; {{ 1 } \\over { 2 }} X_{n}^{2} + {{ 1 } \\over { 2 }} Y_{n}^{2} - {{ 1 } \\over { 2 }} \\left( X_{n} - Y_{n} \\right)^{2} \\\\ \u0026amp;\\overset{P}{\\to}\u0026amp; {{ 1 } \\over { 2 }} X^{2} + {{ 1 } \\over { 2 }} Y^{2} - {{ 1 } \\over { 2 }}\\left( X - Y \\right)^{2} \\\\ =\u0026amp; XY \\end{align*} $$\n‚ñ†\nRigorous Definition Probability Convergence Defined via Measure Theory Hogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p295.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1789,"permalink":"https://freshrimpsushi.github.io/en/posts/1789/","tags":null,"title":"Probability Convergence in Mathematical Statistics"},{"categories":"ÌôïÎ•†Î°†","contents":"Theorem 1 The following is a measure-theoretic description of the continuous mapping theorem.\nFor metric spaces $\\left( S , d \\right)$ and $\\left( S' , d\u0026rsquo; \\right)$, let us say $g : S \\to S'$ is continuous from $C_{g} \\subset S$. For a random element $X$ in $S$, concerning a sequence of random elements converging to $X$ in $\\left\\{ X_{n} \\right\\}_{n \\in \\mathbb{N}}$, the following holds if $P \\left( X \\in C_{g} \\right) = 1$. $$ X_{n} \\overset{D}{\\to} X \\implies g \\left( X_{n} \\right) \\overset{D}{\\to} g(X) \\\\ X_{n} \\overset{P}{\\to} X \\implies g \\left( X_{n} \\right) \\overset{P}{\\to} g(X) \\\\ X_{n} \\overset{\\text{a.s.}}{\\to} X \\implies g \\left( X_{n} \\right) \\overset{\\text{a.s.}}{\\to} g(X) $$\n$C_{g} \\subset S$ denotes the set of points where the function $g$ is continuous. $\\overset{P}{\\to}$, $\\overset{D}{\\to}$, $\\overset{\\text{a.s.}}{\\to}$ each represent convergence in probability, convergence in distribution, and almost sure convergence, respectively. Explanation The property that convergence holds even when applying continuous functions is a phenomenon that can be commonly observed in mathematics, no matter how convergence is defined. However, the term Continuous Mapping Theorem is predominantly used in the field of probability theory. A famous corollary is Slutsky\u0026rsquo;s Theorem, which is introduced only at an undergraduate level of mathematical statistics as a statement.\nSlutsky\u0026rsquo;s Theorem2: For a constant $a,b$ and a random variable $A_{n}, B_{n} ,X_{n} , X$, if $a_{n} \\overset{P}{\\to} a $, $ B_{n} \\overset{P}{\\to} b $, $ X_{n} \\overset{D}{\\to} X $, then $$ A_{n} + B_{n} X_{n} \\overset{D}{\\to} a + b X $$\nAlthough it is assumed that the fact itself can be used in basic subjects like undergraduate mathematical statistics, it is not easy to find a proof that is easy to understand without background knowledge, hence a proof involving measure theory was introduced. If you are an undergraduate student lacking understanding of real analysis, it is normal not to understand the proof, and there is no need to be disappointed. Instead, it is sufficient to think that you need to learn more difficult mathematics and to use it as a fact for the time being.\nProof Convergence in Distribution It can be obtained as a corollary to the portmanteau theorem.\n‚ñ†\nConvergence in Probability Fix $\\varepsilon \u0026gt; 0$ and define the following set $C_{g}^{\\delta} \\subset C_{g}$ for any $\\delta \u0026gt; 0$. $$ C_{g}^{\\delta}:= \\left\\{ x \\in C_{g} \\mid \\exists y : y \\in B \\left( x;\\delta \\right) \\land g(y) \\notin B ' \\left( g(x) ; \\varepsilon \\right) \\right\\} $$ This set collects points $x$ where the function $g$ is continuous within a radius $\\delta$, while it is possible to choose $y$ sufficiently far from both $g(y)$ and $g(x)$. Naturally, as $\\delta \u0026gt; 0$ decreases, the likelihood of existence of such $y$ within the radius also decreases, and it is trivially $\\displaystyle \\lim_{\\delta \\to 0} C_{g}^{\\delta} = \\emptyset$. Now, assume $d\u0026rsquo; \\left( g(X) , g \\left( X_{n} \\right) \\right) \\ge \\varepsilon$ for argument\u0026rsquo;s sake. At least one of the following three must be true:\n(1): $d \\left( X , X_{n} \\right) \u0026gt; \\delta$: Initially, $X$ and $X_{n}$ are too far apart, so whether $g$ is continuous or not, $g(X)$ and $ g \\left( X_{n} \\right) $ are also far apart. (2): $X \\in C_{g}^{\\delta}$: Although $X$ is continuous, for $X_{n}$ within radius $\\delta$, the distance between $g(X_{n})$ and $g (X)$ is far. (3): $X \\notin C_{g}$: $X$ is not continuous, hence $g(X)$ and $g \\left( X_{n} \\right)$ are far apart. Presenting this using probability $$ P \\left( d\u0026rsquo; \\left( g \\left( X_{n} \\right) , g(X) \\right) \u0026gt; \\varepsilon \\right) \\le P \\left( d \\left( X_{n} , X \\right) \\ge \\delta \\right) + P \\left( X \\in C_{g}^{\\delta} \\right) + P \\left( X \\notin C_{g} \\right) $$ the right-hand side terms are\n(1): since $X_{n} \\overset{P}{\\to} X$ by premise, for all $\\delta \u0026gt;0$ $$ \\lim_{n \\to \\infty} P \\left( d \\left( X_{n} , X \\right) \\ge \\delta \\right) = 0 $$ (2): since it was said $\\displaystyle \\lim_{\\delta \\to 0} C_{g}^{\\delta} = \\emptyset$ above $$ \\lim_{\\delta \\to 0} P \\left( X \\in C_{g}^{\\delta} \\right) = 0 $$ (3): since $P \\left( X \\in C_{g} \\right) = 1$ by premise $$ P \\left( X \\notin C_{g} \\right) = P \\left( X \\in C_{g}^{c} \\right) = 0 $$ Summarizing $$ \\lim_{n \\to \\infty} P \\left( d\u0026rsquo; \\left( g \\left( X_{n} \\right) , g (X) \\right) \u0026gt; \\varepsilon \\right) = 0 $$\n‚ñ†\nAlmost Sure Convergence For points $\\omega \\in C_{g}$ where $g$ is continuous, $$ \\lim_{n \\to \\infty} X_{n} (\\omega) = X (\\omega) \\implies \\lim_{n \\to \\infty} g \\left( X_{n} (\\omega) \\right) = g \\left( X (\\omega) \\right) $$ Viewing as events and showing the inclusion $$ \\left[ \\lim_{n \\to \\infty} X_{n} (\\omega) = X (\\omega) \\right] \\subset \\left[ \\lim_{n \\to \\infty} g \\left( X_{n} (\\omega) \\right) = g \\left( X (\\omega) \\right) \\right] $$ since by premise $X_{n} \\overset{\\text{a.s.}}{\\to} X$, namely $\\displaystyle P \\left( \\lim_{n \\to \\infty } X_{n} = X , X \\in C_{g} \\right) = 1$ $$ \\begin{align*} P \\left[ \\lim_{n \\to \\infty} g \\left( X_{n} (\\omega) \\right) = g \\left( X (\\omega) \\right) \\right] \\ge \u0026amp; P \\left[ \\lim_{n \\to \\infty} g \\left( X_{n} (\\omega) \\right) = g \\left( X (\\omega) \\right) , X \\in C_{g} \\right] \\\\ \\ge \u0026amp; P \\left[ \\lim_{n \\to \\infty} X_{n} (\\omega) = X (\\omega) , X \\in C_{g} \\right] \\\\ =\u0026amp; 1 \\end{align*} $$\n‚ñ†\nhttps://en.wikipedia.org/wiki/Continuous_mapping_theorem\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p306.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1787,"permalink":"https://freshrimpsushi.github.io/en/posts/1787/","tags":null,"title":"Proof of the Continuity Mapping Theorem"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem 1 Assuming $F$, $G$ are differentiable in the interval $[a,b]$, and $F^{\\prime}=f$, $G^{\\prime}=g$ are integrable. Then, the following equation holds:\n$$ \\begin{align*} \\int _{a} ^{b} F(x)g(x)dx \u0026amp;= F(b)G(b)-F(a)G(a)-\\int _{a} ^{b}f(x)G(x)dx \\\\ \u0026amp;= \\left[ F(x)G(x) \\right]_{a}^{b} -\\int _{a} ^{b}f(x)G(x)dx \\end{align*} $$\nDescription This result is called the integration by parts. Memorizing it as Integration-Differential-Integration makes it easy. What to integrate is kept on both sides as is, and what to differentiate is written on the front as is, and differentiated on the back.\n$$ \\begin{align*} \\int Fg \u0026amp;= \\left[ FG \\right] - \\int fG \\\\ \u0026amp;= \\left[ \\text{Í∑∏ÎÉ•}\\cdot\\text{Ï†ÅÎ∂Ñ} \\right] - \\int \\text{ÎØ∏Î∂Ñ}\\cdot\\text{Ï†ÅÎ∂Ñ} \\end{align*} $$\nProof Being differentiable implies continuity, and continuity implies integrability, thus $F, G$ is also integrable. Now, let\u0026rsquo;s assume $H(x)=F(x)G(x)$. Then, by the product rule of differentiation, the following holds.\n$$ H^{\\prime}(x)=F(x)g(x)+f(x)G(x) $$\nSince integration is linear, and the product of functions preserves integrability, $H^{\\prime}$ is integrable. Then, by the Fundamental Theorem of Calculus Part 2, the definite integral of $H^{\\prime}$ is calculated as follows.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\int _{a} ^{b}H^{\\prime}(x)dx \u0026amp;= H(b)-H(a) \\\\ \\implies \u0026amp;\u0026amp; \\int _{a} ^{b}H^{\\prime}(x)dx \u0026amp;= F(b)G(b)-F(a)G(a) \\\\ \\implies \u0026amp;\u0026amp; \\int _{a} ^{b}F(x)g(x) + f(x)G(x) dx \u0026amp;= F(b)G(b)-F(a)G(a) \\\\ \\implies \u0026amp;\u0026amp; \\int _{a} ^{b}F(x)g(x)dx \u0026amp;=F(b)G(b)-F(a)G(a)-\\int _{a} ^{b}f(x)G(x) \\end{align*} $$\n‚ñ†\nWalter Rudin, Principles of Mathematical Analysis (3rd Edition, 1976), p134\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1867,"permalink":"https://freshrimpsushi.github.io/en/posts/1867/","tags":null,"title":"Integration by Parts"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 Given that function $f$ is Riemann integrable on the interval $[a,b]$, and there exists a function $F$ that is differentiable on $[a,b]$, satisfying $F^{\\prime}=f$. Then, the following holds true.\n$$ \\int_{a}^{b} f(x) dx= F(b)-F(a) $$\nExplanation This theorem is famously known as the Fundamental Theorem of Calculus Part 2, often abbreviated as FTC2[^Funcamental Theorem of Calculus1]. It implies that the definite integral of $f$ is represented by the difference of the values of the antiderivative $F$ at the endpoints.\nProof Assuming $\\varepsilon \u0026gt;0$ is given. Since $f$ is integrable on $[a,b]$, by the necessary and sufficient condition, there exists a partition $P=\\left\\{a= x_{0}, \\cdots, x_{n}=b \\right\\}$ of interval $[a,b]$ that satisfies the following.\n$$ U(P,f)-L(P,f) \u0026lt; \\varepsilon $$\nSince $F$ is assumed to be differentiable, hence continuous, by the Mean Value Theorem, there exists a $t_{i}\\in [x_{i-1},x_{i}]$ that satisfies the following.\n$$ F(x_{i})-F(x_{i-1})=f(t_{i})\\Delta x_{i},\\quad (i=1,\\dots,n) $$\nAdding the above equation for all $i$, we get:\n$$ \\begin{align*} \\sum \\limits _{i=1} ^{n} f(t_{i})\\Delta x_{i}\u0026amp;=\\left( F(b)-F(x_{n-1}) \\right)+\\cdots+\\left( F(x_{1})-F(a) \\right) \\\\ \u0026amp;= F(b) -F(a) \\end{align*} $$\nAuxiliary Lemma\n$$ \\left| \\sum \\limits_{i=1} ^{n} f(t_{i})\\Delta \\alpha_{i} - \\int _{a} ^{b}f (x)d\\alpha (x) \\right| \u0026lt; \\varepsilon $$\nBy the above auxiliary lemma, the following is true.\n$$ \\begin{align*} \\left| \\sum \\limits _{i=1} ^{n} f(t_{i})\\Delta \\alpha_{i} - \\int _{a} ^{b}f (x)d\\alpha (x) \\right| \u0026amp;= \\left|\\big( F(b)-F(a) \\big) - \\int _{a} ^{b}f (x)d\\alpha (x) \\right| \\\\ \u0026amp;\u0026lt; \\varepsilon \\end{align*} $$\nHere, since $\\varepsilon$ is arbitrary positive number, we obtain:\n$$ \\int _{a} ^{b}f (x)d\\alpha (x)=F(b)-F(a) $$\n‚ñ†\nSee Also FTC1\nFTC2 in Calculus\nWalter Rudin, Principles of Mathmatical Analysis (3rd Edition, 1976), p134\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1866,"permalink":"https://freshrimpsushi.github.io/en/posts/1866/","tags":null,"title":"The Fundamental Theorem of Calculus in Analysis"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Definition [^1] The logistic function is derived as $y ' = y(1-y)$, which is a solution to the differential equation. $$ y(t) = {{ 1 } \\over { 1 + e^{-t} }} $$\nExplanation In a more general form, it can also be expressed as $\\displaystyle f(x) := {{ L } \\over { 1 + e^{-k(x-x_{0})} }}$. The logistic function, which is a sigmoid function, is widely mentioned in various fields such as dynamics, statistics, deep learning, biology, due to its many applications.\nLogistic? The question is why it is called the \u0026rsquo;logistic function\u0026rsquo;. Looking up the meaning of Logistic reveals terms like \u0026lsquo;related to logistics\u0026rsquo;, \u0026lsquo;related to military logistics\u0026rsquo;, or \u0026lsquo;related to symbolic logic\u0026rsquo;, which seem to have no connection to the function\u0026rsquo;s form at a glance. Logistic regression is a classification technique that applies logistic function within regression analysis, and this again has no relation to military logistics or symbolic logic.\nThe most plausible explanation perhaps lies in considering the meaning behind the logistic differential equation $y\u0026rsquo;=y(1-y)$, the framework from which the logistic function emerged. The logistic differential equation is often mentioned as a population growth model and is extensively used in many fields. It describes a scenario where the growth of a population explosively increases and then slows down due to factors like food scarcity.\nHere, \u0026lsquo;food\u0026rsquo; can be interpreted in various contexts: as jobs for employees, as oxygen for aerobic bacteria, etc. Perhaps \u0026lsquo;Logistic\u0026rsquo; was chosen as a sophisticated term capable of aptly describing \u0026rsquo;that something\u0026rsquo;. Logistics does not solely refer to food supplies but covers everything needed for war, and likewise, logistics doesn\u0026rsquo;t only denote specific goods. To align with its meaning outside the realm of science and engineering, this may be the most fitting interpretation.\n","id":1775,"permalink":"https://freshrimpsushi.github.io/en/posts/1775/","tags":null,"title":"What is a Logistic Function?"},{"categories":"ÎèôÏó≠Ìïô","contents":"Theorem $2$ Consider a manifold $\\mathcal{P}$ and a function $f,g \\in C^{r} \\left( \\mathcal{P} \\right)$ such that the following vector field is given as a differential equation: $$ \\dot{x} = f(x,y) \\\\ \\dot{y} = g(x,y) $$ If $\\mathcal{M}$ represents an invariant set with a finite number of fixed points, then the omega limit set $\\omega (p)$ of $p \\in \\mathcal{M}$ satisfies one of the following three conditions:\n(1): $\\omega (p)$ is a singleton set, meaning it contains only one fixed point. (2): $\\omega (p)$ is a closed orbit. (3): $\\omega (p)$ consists of orbits $\\gamma$ that satisfy the following for some fixed points $p_{1} , \\cdots , p_{n}$ of $i,j \\in [1,n]$: $$ \\alpha ( \\gamma ) = \\left\\{ p_{i} \\right\\} \\\\ \\omega ( \\gamma ) = \\left\\{ p_{j} \\right\\} $$ Explanation A metric space is naturally a $T_{1}$ space, and in $T_{1}$, singleton sets are closed sets, so it can be said that $\\omega (p) = \\left\\{ p \\right\\}$ is naturally a closed orbit. However, in the context of the statement, let\u0026rsquo;s differentiate the case that includes only one fixed point as something else.\nIn fact, in the Poincar√©-Bendixson theorem, chaos doesn\u0026rsquo;t even need to be defined, and the statement that chaos does not occur is close to a corollary. What the theorem tells us is just a classification of omega limit sets, and it is deduced that chaos cannot occur because it is precisely made up of what we know. However, due to such theorems, the interest in chaos theory is able to definitively move beyond the dimension $2$.\nThe intuitive understanding of the theorem is not very difficult. If $\\mathcal{M}$ is not bounded, it cannot be chaotic in the first place, and if it is bounded, it cannot extend indefinitely, so the flow must either narrow down and rotate or spread out and rotate. However, unlike in the dimension $3$, in the dimension $2$, a line divides the plane into two regions, so one of the regions must always be abandoned. This is metaphorically like abandoning the remaining part of the bounded space $\\mathcal{M}$ as time passes. If you try to pass through the flow you have already passed to use an area you have not passed yet, at that moment, it becomes a closed orbit, and eventually, it converges to a fixed point or a closed orbit, making it impossible to cause chaos.\nProof 1 Strategy: As befitting a theorem named after Poincar√©, it\u0026rsquo;s topologically oriented. Let $\\Sigma$ be a continuous, connected arc in the interior $\\mathcal{P}$.\nIf the normal vector at all points of $\\Sigma$ and the vector field do not have an inner product of $0$ and do not change sign, then $\\Sigma$ is said to transverse the vector field of $\\mathcal{P}$. This concept can also be thought of for just one point, where the vector field and $\\Sigma$ would not be tangent at that point. In terms of the flow\u0026rsquo;s sense, it not only meets at a point but also penetrates $\\Sigma$.\nLet\u0026rsquo;s represent the flow created by the given vector field as $\\phi_{t}$, and represent the orbit of a point $p \\in \\mathcal{P}$ under the flow $\\phi_{t}$ for positive time as $O_{+}(p)$. Let\u0026rsquo;s represent the orbit that a point $p_{i}$ reaches $p_{j}$ following the flow of time $t$ under the flow $\\phi_{t}$ as $\\widehat{p_{i} p_{j}} \\subset O_{+} (p)$. The omega limit set denoted as $\\omega ( \\cdot )$ was originally defined for a given point, but the $\\omega \\left( X \\right)$ for some set $X$ can be thought of as follows: $$ \\omega (X) := \\bigcup_{x \\in X} \\omega (x) $$ The same applies to the alpha limit set denoted as $\\alpha ( \\cdot )$.\nIn addition, the following auxiliary theorems will be used continuously.\nAuxiliary Theorem (Properties of Omega Limit Sets): Let the whole space be the Euclidean space $X = \\mathbb{R}^{n}$ and a point $p \\in \\mathcal{M}$ of the compact invariant set $\\mathcal{M}$ in the flow $\\phi_{t} ( \\cdot )$ is given:\n[1]: $\\omega (p) \\ne \\emptyset$ [2]: $\\omega (p)$ is a closed set. [3]: $\\omega (p)$ is invariant under the flow, i.e., $\\omega (p)$ is a union of orbits. [4]: $\\omega (p)$ is a connected space. First, the omega limit sets that occur in dimension $2$ will not be in the form of having an area, so the omega limit sets mentioned below can be thought of in the form of some curve.\nPart 1.\nIf $\\Sigma \\subset \\mathcal{M}$ is an arc that crosses the vector field, and since $\\mathcal{M}$ is an invariant set in the dimension $2$ vector field, $\\Sigma$ cannot go out of $\\mathcal{M}$ against the flow of the vector field. Therefore, for any $p \\in \\mathcal{M}$, if we call the $k$th point where $O_{+} (p)$ and $\\Sigma$ meet as $p_{k}$, then it must be $p_{k}\\subset \\widehat{p_{k-1} p_{k+1}} \\subset O_{+} (p)$. In other words, the flow is converging to some inner core while meeting $\\Sigma$, and it doesn\u0026rsquo;t happen that the intersection points get closer and then move away again.\nPart 2. The omega limit set $\\omega (p)$ of $p \\in \\mathcal{M}$ intersects $\\Sigma$ at most at one point.\nThis will be shown by contradiction. Assume that $\\omega (p)$ and $\\Sigma$ intersect at two different points $q , \\overline{q}$.\nThen, by the definition of the omega limit set, when $n \\to \\infty$, a sequence $\\left\\{ q_n \\right\\}_{n \\in \\mathbb{N}} , \\left\\{ \\overline{q}_n \\right\\}_{n \\in \\mathbb{N}} \\subset O_{+} (p)$ that satisfies $$ q_{n} \\to q \\\\ \\overline{q}_{n} \\to \\overline{q} $$ exists. However, according to Part 1, these intersection points are arranged in a sequence $p_{1} , p_{2} , \\cdots$, so there is a contradiction to the assumption. Therefore, $\\omega (p)$ and $\\Sigma$ either do not meet at all or meet at only one point if they do. [ NOTE: In the case of a torus, this logic cannot be applied directly, but the same conclusion can be reached by dividing it into pieces so that it becomes a shape like $\\mathcal{M}$. ]\nPart 3. If $\\omega (p)$ does not include fixed points, it is a closed orbit.\nAfter showing that the orbit $O_{+}(q)$ of $q \\in \\omega (p)$ is a closed orbit, it needs to be shown that it is $\\omega (p) = O_{+} (q)$.\nPart 3-1. Orbit $O_{+}(q)$ is closed. If we pick a point $x \\in \\omega (q)$, according to auxiliary theorem [2], since $\\omega (p)$ is closed and a union of orbits without fixed points, $x$ must also not be a fixed point. Be careful not to get confused with $p,q$, the assumption is that $\\omega (p)$ does not have fixed points, and since $x$ is said to be $x \\in \\omega (q)$, there is no guarantee that it is necessarily $x \\in \\omega (p)$, but it can be concluded that it is not a fixed point anyway. Now, let\u0026rsquo;s take one arc $\\Sigma_{x}$ that crosses the vector field of this non-fixed point $x$. According to Part 1., the sequence of intersections $\\left\\{ q_{n} \\right\\}_{n \\in \\mathbb{N}}$ of $\\Sigma_{x}$ and $O_{+} (q)$ is $q_{n} \\to x$ when $n \\to \\infty$, and since $x \\in \\mathcal{M}$, according to Part 2., for $\\forall n \\in \\mathbb{N}$, it must be $q_{n} = x$. Since $x$ is not a fixed point, if $O_{+} (q)$ intersects with $x$, it must cross and then return to intersect again repeatedly. Since it is said here that $x \\in \\omega (q)$, $O_{+}(q)$ actually intersects with $x$ without stopping or pausing as it approaches $x$, and therefore, $O_{+}(q)$ becomes a closed orbit. Part 3-2. $O_{+}(q) = \\omega (p)$ If we take one arc $\\Sigma_{q}$ that crosses the vector field from point $q \\in \\omega (p)$, according to Part 2, $\\omega (p)$ and $\\Sigma_{q}$ meet only at $q$. According to auxiliary theorem [3], since $\\omega (p)$ is a union of orbits, if $q \\in \\omega (p)$ then $O_{+} (q) \\subset \\omega (p)$, but since $\\omega (p)$ does not contain fixed points and is a connected space, it must be exactly $O_{+}(q) = \\omega (p)$. Part 4. For $p \\in \\mathcal{M}$, if $p_{1} , p_{2} \\in \\omega (p)$ are different fixed points of the vector field, there exists at most one orbit $\\gamma \\subset \\omega (p)$ that satisfies $\\alpha (\\gamma) = \\left\\{ p_{1} \\right\\}$ and $\\omega (\\gamma) = \\left\\{ p_{2} \\right\\}$.\nThis will be shown by contradiction. If there are two different orbits connecting two points, there would be some area $\\mathcal{K}$ with an area between the two orbits, and a contradiction will be derived from there. Assume that there exist two different orbits $\\gamma_{1} , \\gamma_{2} \\subset \\omega (p)$ satisfying the following conditions. $$ \\alpha \\left( \\gamma_{i} \\right) = \\left\\{ p_{1} \\right\\} \\\\ \\omega \\left( \\gamma_{i} \\right) = \\left\\{ p_{2} \\right\\} $$ Let\u0026rsquo;s take one point each from these orbits, $q_{1} \\in \\gamma_{1}$, $q_{2} \\in \\gamma_{2}$, and take arcs that cross the vector field from $q_{1}$ and $q_{2}$ as $\\Sigma_{1}, \\Sigma_{2}$.\nSince $\\gamma_{1} , \\gamma_{2} \\subset \\omega (p)$, according to Part 2, let\u0026rsquo;s say $O_{+} (p)$ intersects with $\\Sigma_{1}$ at one point $a$ and then $\\Sigma_{2}$ intersects at one point $b$. Then, in the dimension $2$ manifold, there will be a subregion $\\color{red}{\\mathcal{K}}$ surrounded by the following path.\n$$ q_{1} \\overset{\\Sigma_{1}}{\\to} a \\overset{ O_{+} (p) }{ \\to } b \\overset{\\Sigma_{2}}{\\to} q_{2} \\overset{ \\omega (\\gamma) }{ \\to } p_{2} \\overset{ \\gamma_{1} }{ \\gets } q_{1} $$ The notation $\\displaystyle x \\overset{\\mathcal{C}}{\\to} y$ was used to mean that point $x,y$ was connected to curve $\\mathcal{C}$. The flow starting from $\\color{red}{\\mathcal{K}}$ cannot go over $\\gamma_{1} , \\gamma_{2}$, so $\\color{red}{\\mathcal{K}}$ becomes an invariant set. However, the fact that the orbit $O_{+}(p)$ starting from $p$ cannot exit once it enters $\\color{red}{\\mathcal{K}}$ means that neither $\\gamma_{1}$ nor $\\gamma_{2}$ can belong to $\\omega (p)$. For example, if you think about $\\gamma_{2}$, $q_{2} \\overset{\\gamma_{2}}{\\to} p_{2}$ may belong to $\\omega (p)$, but it cannot go to the front part, $p_{1} \\overset{\\gamma_{2}}{\\to} q_{2}$. Therefore, the claim that the entire $\\gamma_{2}$ belongs to $\\omega (p)$ cannot be made, and it contradicts $\\gamma_{1} , \\gamma_{2} \\subset \\omega (p)$.\nPart 5.\nIn this part only, let\u0026rsquo;s call a point that is not a fixed point a Regular Point. There\u0026rsquo;s no need to limit this to just this part, but since the expression Regular is often used in academia regardless of the field, using it without caution or warning can cause great confusion.\nCase 1. If $\\omega (p)$ only has fixed points Since $\\mathcal{M}$ has a finite number of fixed points and $\\omega (p)$ is a connected space, it must have only one fixed point. Case 2. If $\\omega (p)$ only has regular points According to Part 3, $\\omega (p)$ is a closed orbit. Case 3. If $\\omega (p)$ has both fixed and regular points Consider the orbit $\\gamma \\subset \\omega (p)$ consisting only of regular points. Since $\\gamma$ consists only of regular points, according to Part 3, $\\omega ( \\gamma )$ and $\\alpha (\\gamma)$ are closed orbits, but they must also have fixed points. However, according to auxiliary theorem [4], since $\\omega ( \\gamma )$ is a connected space, the closed orbit and the fixed point cannot be separated, and the fixed point must be located at one point on the closed orbit, which means $\\omega ( \\gamma )$ is a singleton set containing only fixed points. The same discussion can be repeated for $\\alpha ( \\gamma )$, so all regular points of $\\omega (p)$ have fixed points as their omega and alpha limit points.\n$\\omega (p)$ must fall into one of these three cases. This concludes the proof.\n‚ñ†\nWiggins. (2003). Introduction to Applied Nonlinear Dynamical Systems and Chaos Second Edition(2nd Edition): 118~120.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1788,"permalink":"https://freshrimpsushi.github.io/en/posts/1788/","tags":null,"title":"Proof of Poincar√© bendixson Theorem"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition Given the integral transform $J$ and two functions $f$, $g$, a function $f \\ast g$ fulfilling the conditions below is defined as the convolution of $f$ and $g$ with respect to $J$.\n$$ J(f \\ast g)=(Jf)(Jg) $$\nExplanation According to the definition, the convolution, being the integral transform of a product, can be divided into the product of integral transforms. This means that two functions, which were bound in a single integral, can be separated into two integrals. It\u0026rsquo;s a useful technique when finding the inverse of a forward operator expressed as an integral.\nThe term convolution generally refers to the convolution of the Fourier transform without specific mention.\nFourier Transform $$ (f \\ast g)(x) =\\int _{-\\infty} ^{\\infty}f(y)g(x-y)dy $$\nLaplace Transform $$ (f \\ast g)(x) = \\int_{0}^{x}f(x-y)g(y)dy $$\nMellin Transform $$ ( f\\times g)(x)=\\int _{0} ^{\\infty} f(y)g \\left( \\frac{x}{y} \\right)\\frac{dy}{y} $$\n","id":1848,"permalink":"https://freshrimpsushi.github.io/en/posts/1848/","tags":null,"title":"Convolution's General Definition"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition If a map $J$ from a function space to a function space is defined as the following integral, then $J$ is called an integral transform.\n$$ (Jf) (x) = \\int_{a}^{b} K(x,t)f(t)dt $$\n$$ J : f(\\cdot) \\mapsto \\int_{a}^{b} K(\\cdot,t)f(t)dt $$\nIn this case, $K$ is referred to as the kernel of $J$. If a map from $Jf$ to $f$ exists, it is denoted as $J^{-1}$ and called the inverse transform of $J$.\nDescription Since integration is linear, integral transforms are linear transforms.\nThe integration domain does not necessarily have to be bounded. It can be $a=-\\infty$, $b=\\infty$, or both. Although integral transforms can be created arbitrarily according to the definition, to have meaningful interpretations, solving the given problem should be easier in terms of $Jf$ than in $f$, or an inverse transformation should exist, allowing free conversion between $Jf$ and $f$. Examples of integral transforms include the following.\nFourier transform $\\mathcal{F}$:\n$$ \\mathcal{F}f(\\xi)=\\int _{-\\infty} ^{\\infty} f(x)e^{i \\xi x}dx,\\quad K(x,\\xi)=e^{i\\xi x} $$\nLaplace transform $\\mathcal{L}$:\n$$ \\mathcal{L}f(s)=\\int _{0} ^{\\infty}f(t)e^{-st}dt,\\quad K(t,s)=e^{-st} $$\nMellin transform $\\mathcal{M}$:\n$$ \\mathcal{M}f(s)=\\int_{0}^{\\infty} f(x)x^{s-1}dx,\\quad K(x,s)=x^{s-1} $$\nRadon transform $\\mathcal{R}$:\n$$ \\mathcal{R}f(s,\\theta)=\\int_{-\\infty}^{\\infty}f(s\\cos\\theta-t\\sin\\theta, s\\sin\\theta+t\\cos\\theta)dt $$\nSee Also Convolution ","id":1847,"permalink":"https://freshrimpsushi.github.io/en/posts/1847/","tags":null,"title":"Integral Transformation"},{"categories":"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ","contents":"Theorem1 Let $(H, \\langle \\cdot ,\\cdot \\rangle)$ be an inner product space. Then, the following inequality holds, and it is called the Cauchy-Schwarz inequality.\n$$ \\left| \\langle x,y \\rangle \\right| \\le \\langle x,x \\rangle^{1/2} \\langle y,y \\rangle ^{1/2},\\quad \\forall x,y \\in H $$\nExplanation Since a norm can be defined from the inner product, it can also be expressed as the following equation.\n$$ \\left| \\left\\langle x, y \\right\\rangle \\right| \\le \\left\\| x \\right\\| \\left\\| y \\right\\|,\\quad \\forall x,y\\in H $$\nProof Case 1. $x=0$ or $y=0$\nWithout loss of generality, let it be $x=0$. Then, by the definition of the inner product,\n$$ \\left| \\langle 0,y \\rangle \\right| = \\left| \\langle 0x,y \\rangle \\right| =0\\left| \\langle x,y\\rangle \\right|=0 $$\nThus, it holds.\nCase 2. If $x\\ne0$, $y\\ne0$ and $\\langle x,y \\rangle \\in \\mathbb{R}$\nBy the definition of the inner product,\n$$ \\begin{align*} 0 \\le\u0026amp; \\left\\langle x-\\frac{\\langle x,y \\rangle}{\\langle y,y \\rangle} y, x-\\frac{\\langle x,y \\rangle}{\\langle y,y \\rangle} y \\right\\rangle \\\\ =\u0026amp;\\ \\langle x,x \\rangle - \\frac{\\langle x,y \\rangle}{\\langle y,y \\rangle} \\langle x,y \\rangle -\\frac{\\langle x,y \\rangle}{\\langle y,y \\rangle} \\langle y,x \\rangle +\\frac{\\langle x,y \\rangle^{2}}{\\langle y,y \\rangle^{2}}\\langle y,y \\rangle \\end{align*} $$\nSince $\\langle x,y \\rangle \\in \\mathbb{R}$, then $\\langle x,y\\rangle=\\overline{\\langle y,x \\rangle}=\\langle y,x \\rangle$. Therefore,\n$$ \\begin{align*} 0 \\le\u0026amp; \\langle x,x \\rangle - 2\\frac{\\langle x,y \\rangle}{\\langle y,y \\rangle} \\langle x,y \\rangle +\\frac{\\langle x,y \\rangle^{2}}{\\langle y,y \\rangle^{2}}\\langle y,y \\rangle \\\\ =\u0026amp;\\ \\langle x,x \\rangle - 2\\frac{\\langle x,y \\rangle^{2}}{\\langle y,y \\rangle} +\\frac{\\langle x,y \\rangle^{2}}{\\langle y,y \\rangle} \\\\ =\u0026amp;\\ \\langle x,x \\rangle - \\frac{\\langle x,y \\rangle^{2}}{\\langle y,y \\rangle} \\end{align*} $$\nSince $\\langle y,y \\rangle \u0026gt;0$, multiply both sides to get\n$$ \\begin{align*} \u0026amp;\u0026amp; 0 \\le\u0026amp; \\langle x,x \\rangle \\langle y,y \\rangle - \\langle x,y \\rangle ^{2} \\\\ \\implies \u0026amp;\u0026amp; \\langle x,y \\rangle ^{2} \\le\u0026amp; \\langle x,x \\rangle \\langle y,y \\rangle \\\\ \\implies \u0026amp;\u0026amp; \\left| \\langle x,y \\rangle \\right| \\le\u0026amp; \\langle x,x \\rangle ^{1/2} \\langle y,y \\rangle ^{1/2} \\end{align*} $$\nCase 3. If $x\\ne0$, $y\\ne 0$ and $\\langle x,y\\rangle \\in \\mathbb{C}$\nLet $\\left| \\lambda \\right| =1$ and choose one $\\lambda \\in \\mathbb{C}$ that satisfies $\\lambda \\langle x,y \\rangle\\in [0,\\infty)$. Then,\n$$ \\left| \\langle x,y \\rangle \\right| =\\left| \\lambda \\right| \\left| \\langle x,y \\rangle \\right|=\\left| \\lambda \\langle x,y \\rangle \\right|= \\lambda\\langle x,y \\rangle =\\langle \\lambda x,y \\rangle $$\nTherefore, by Case 2,\n$$ \\begin{align*} \\left| \\langle x,y \\rangle \\right| =\u0026amp;\\ \\langle \\lambda x,y \\rangle \\\\ \\le\u0026amp; \\langle \\lambda x, \\lambda x \\rangle ^{1/2} \\langle y,y \\rangle ^{1/2} \\\\ =\u0026amp;\\ \\langle x,x\\rangle^{1/2}\\langle y,y\\rangle ^{1/2} \\end{align*} $$\n‚ñ†\nOle Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p62-23\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1843,"permalink":"https://freshrimpsushi.github.io/en/posts/1843/","tags":null,"title":"Inner Product Spaces and the Cauchy-Schwarz Inequality"},{"categories":"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ","contents":"Definition1 Let\u0026rsquo;s consider $X$ as a vector space. For $\\mathbf{x}, \\mathbf{y}, \\mathbf{z} \\in X$ and $\\alpha, \\beta \\in \\mathbb{C}$(or $\\mathbb{R}$), the following conditions satisfied by a function\n$$ \\langle \\cdot , \\cdot \\rangle : X \\times X \\to \\mathbb{C} $$\nare defined as the inner product, and $\\left( X, \\langle \\cdot ,\\cdot \\rangle \\right)$ is called an inner product space.\nLinearity: $$\\langle \\alpha \\mathbf{x} + \\beta \\mathbf{y} ,\\mathbf{z} \\rangle =\\alpha \\langle \\mathbf{x},\\mathbf{z}\\rangle + \\beta \\langle \\mathbf{y},\\mathbf{z}\\rangle$$ Conjugate symmetry: $$\\langle \\mathbf{x},\\mathbf{y} \\rangle = \\overline{ \\langle \\mathbf{y},\\mathbf{x} \\rangle}$$ Positive-definiteness: $$\\langle \\mathbf{x},\\mathbf{x} \\rangle \\ge 0 \\quad \\text{and} \\quad \\langle \\mathbf{x},\\mathbf{x} \\rangle = 0\\iff \\mathbf{x}=0$$ Explanation From linearity and conjugate symmetry, the following equation is obtained.\n$$ \\begin{align*} \\langle \\mathbf{x},\\alpha \\mathbf{y}+\\beta \\mathbf{z} \\rangle =\u0026amp;\\ \\overline{\\langle \\alpha \\mathbf{y}+\\beta \\mathbf{z} ,\\mathbf{x} \\rangle} \\\\ =\u0026amp;\\ \\overline{\\alpha \\langle \\mathbf{y},\\mathbf{x} \\rangle +\\beta \\langle \\mathbf{z},\\mathbf{x} \\rangle} \\\\ =\u0026amp;\\ \\overline{\\alpha}\\overline{\\langle \\mathbf{y},\\mathbf{x} \\rangle}+\\overline{\\beta} \\overline{\\langle \\mathbf{z},\\mathbf{x} \\rangle} \\\\ =\u0026amp;\\ \\overline{\\alpha}\\langle \\mathbf{x},\\mathbf{y}\\rangle + \\overline{\\beta} \\langle \\mathbf{x},\\mathbf{z} \\rangle \\end{align*} $$\nThis means it is antilinear regarding the second element. In physics, engineering, etc., the inner product might be defined slightly differently. For example, it can be defined as being antilinear with respect to the first component, and linear with the second. Meanwhile, in an inner product space, the Cauchy-Schwarz inequality is established as below.\nLet\u0026rsquo;s say $(X, \\langle \\cdot ,\\cdot \\rangle)$ is an inner product space. Then, the following inequality holds, which is called the Cauchy-Schwarz inequality.\n$$ \\left| \\langle \\mathbf{x},\\mathbf{y} \\rangle \\right| \\le \\langle \\mathbf{x},\\mathbf{x} \\rangle^{1/2} \\langle \\mathbf{y},\\mathbf{y} \\rangle ^{1/2},\\quad \\forall \\mathbf{x},\\mathbf{y} \\in X $$\nMoreover, an norm can be defined from an inner product.\n$$ \\left\\| \\mathbf{x} \\right\\| := \\sqrt{\\langle \\mathbf{x},\\mathbf{x} \\rangle},\\quad \\mathbf{x}\\in X $$\nThis naturally derived norm from an inner product is also referred to as the associated norm. Also, given a norm, the distance can be defined from the norm, thus enabling discussion on the property of the metric space, which is completeness. A complete inner product space is called a Hilbert space.\nProperties Cauchy-Schwarz inequality: For any $\\mathbf{x},\\mathbf{y}\\in X$,\n$$ \\left| \\langle \\mathbf{x},\\mathbf{y} \\rangle \\right| \\le \\left\\| \\mathbf{x} \\right\\| \\left\\| \\mathbf{y} \\right\\| $$\nParallelogram law: For any $\\mathbf{x},\\mathbf{y}\\in X$,\n$$ \\left\\| \\mathbf{x} + \\mathbf{y} \\right\\|^{2} + \\left\\| \\mathbf{x} - \\mathbf{y} \\right\\|^{2} = 2 \\left( \\left\\| \\mathbf{x} \\right\\| ^{2}+ \\left\\| \\mathbf{y} \\right\\| ^{2} \\right) $$\nThe polarization identity in a complex vector space: For a complex inner product space $X$ and any $\\mathbf{x},\\mathbf{y}\\in X$,\n$$ \\langle \\mathbf{x},\\mathbf{y} \\rangle = \\frac{1}{4} \\Big( \\left\\| \\mathbf{x} + \\mathbf{y} \\right\\|^{2} - \\left\\| \\mathbf{x} - \\mathbf{y} \\right\\|^{2} + i \\left( \\left\\| \\mathbf{x} + iy \\right\\|^{2} - \\left\\| \\mathbf{x} - iy \\right\\|^{2} \\right) \\Big) $$\nThe polarization identity in a real vector space: For a real inner product space $X$ and any $\\mathbf{x},\\mathbf{y}\\in X$,\n$$ \\langle \\mathbf{x},\\mathbf{y}\\rangle = \\frac{1}{4} \\left( \\left\\| \\mathbf{x}+\\mathbf{y} \\right\\|^{2} - \\left\\| \\mathbf{x}-\\mathbf{y} \\right\\| ^{2} \\right) $$\nNorm versus inner product: For any $\\mathbf{x} \\in X$,\n$$ \\left\\| \\mathbf{x} \\right\\| =\\sup \\left\\{ \\left| \\langle \\mathbf{x},\\mathbf{y} \\rangle \\right| : \\mathbf{y}\\in X, \\left\\| \\mathbf{y} \\right\\| =1 \\right\\} $$\nOle Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p61-65\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1842,"permalink":"https://freshrimpsushi.github.io/en/posts/1842/","tags":null,"title":"Inner product spaces"},{"categories":"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ","contents":"Description Let\u0026rsquo;s say an inner space $\\left( X, \\langle\\cdot, \\cdot\\rangle \\right)$ is given. Then, one can naturally define a norm as follows from the inner product.\n$$ \\begin{equation} \\left\\| x \\right\\| := \\sqrt{ \\langle x, x\\rangle},\\quad x\\in X \\end{equation} $$\nHence, if it is an inner space, then it\u0026rsquo;s a normed space. Subsequently, one can define a distance from the norm thus defined.\n$$ \\begin{equation} d(x,y):=\\left\\| x -y \\right\\| =\\sqrt{ \\langle x-y, x-y \\rangle},\\quad x,y\\in X \\end{equation} $$\nTherefore, if it is an inner space, then it is both a normed space and a metric space. Some textbooks mention metric spaces upfront and then use the concepts of norm or inner product, and that\u0026rsquo;s precisely because of this reason. Although it is mentioned as a metric space, it is assumed to be given an inner space.\nConversely, saying \u0026lsquo;an inner space $X$ is given\u0026rsquo; is synonymous with saying \u0026lsquo;a metric space $X$ is given\u0026rsquo;, \u0026lsquo;a normed space $X$ is given\u0026rsquo;. Additionally, the concept of completeness is defined in metric spaces, but the reason one can say a normed space or an inner space is complete is because distance can be defined through inner product and norm. The proof is not difficult through the definitions, so I will only introduce about $(1)$.\nTheorem If it is an inner space, then it is a normed space.\nProof Let\u0026rsquo;s assume an inner space $X$ is given. And let\u0026rsquo;s say $x,y\\in X$ and $c\\in \\mathbb{C}$. Then, by the definition of inner product,\n$$ \\left\\| x \\right\\| \\ge 0 $$\nholds. Also, by the definition of inner product,\n$$ \\left\\| x \\right\\| =0 \\iff x=0 $$\nholds. Similarly, by the definition of inner product,\n$$ \\begin{align*} \\left\\| cx \\right\\| =\u0026amp;\\ \\sqrt{ \\langle cx,cx\\rangle } \\\\ =\u0026amp;\\ \\sqrt{ \\left| c \\right| ^{2} \\langle x,x \\rangle} \\\\ =\u0026amp;\\ \\left| c \\right| \\sqrt{\\langle x,x \\rangle} \\\\ =\u0026amp;\\ \\left| c \\right| \\left\\| x \\right\\| \\end{align*} $$\nholds. The last condition also holds by the definition of the inner product:\n$$ \\begin{align*} \\left\\| x + y \\right\\|^{2} =\u0026amp;\\ \\langle x+y,x+y \\rangle \\\\ =\u0026amp;\\ \\langle x,x+y\\rangle +\\langle y,x+y \\rangle \\\\ =\u0026amp;\\ \\langle x,x\\rangle + \\langle x,y\\rangle + \\langle y,x\\rangle + \\langle y,y\\rangle \\\\ =\u0026amp;\\ \\left\\| x \\right\\|^{2}+\\langle x,y \\rangle +\\overline{ \\langle x,y \\rangle}+ \\left\\| y \\right\\| ^{2} \\\\ \\le\u0026amp; \\left\\| x \\right\\| ^{2} + 2 \\left| \\langle x,y \\rangle \\right| + \\left\\| y \\right\\| ^{2} \\\\ \\le\u0026amp; \\left\\| x \\right\\|^{2} +2\\langle x,x \\rangle ^{1/2}\\langle y,y \\rangle^{1/2} + \\left\\| y \\right\\|^{2} \\\\ =\u0026amp;\\ \\left\\| x \\right\\|^{2}+2\\left\\| x \\right\\|\\left\\| y \\right\\| +\\left\\| y \\right\\|^{2} \\\\ =\u0026amp;\\ \\left( \\left\\| x \\right\\| + \\left\\| y \\right\\| \\right)^{2} \\end{align*} $$\nThe fifth line holds because for any complex number $c\\in \\mathbb{C}$, $c+\\overline{c} \\in \\mathbb{R}$ holds. The sixth line is satisfied by the Cauchy-Schwarz inequality. Hence,\n$$ \\left\\| x \\right\\| := \\sqrt{\\langle x,x \\rangle} $$\n$\\left\\| \\cdot \\right\\|$ defined as above satisfies the definition of a norm.‚ñ†\n","id":1840,"permalink":"https://freshrimpsushi.github.io/en/posts/1840/","tags":null,"title":"Relations among Inner Product Spaces, Normed Spaces, and Metric Spaces"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 If the estimator $T$ of $\\theta$ satisfies the following, then $T$ is called the unbiased estimator of $\\theta$. $$ E T = \\theta $$\nExplanation Especially, among the unbiased estimators for $\\theta$, the one with the smallest variance is called the minimum variance unbiased estimator.\nUnbiasedness refers to the property of not having any bias. For example, when we assume $X_{i} \\sim \\left( \\mu , \\sigma^{2} \\right)$, if we use the sample mean $\\displaystyle \\overline{X} = {{ 1 } \\over { n }} \\sum_{i} X_{i}$ as the estimator for $\\mu$, since $\\displaystyle E \\overline{X} = \\mu$, then $\\overline{X}$ becomes an unbiased estimator of $\\mu$. This might seem obvious at first, but the fact that an estimator perfectly estimates the parameter is a very important characteristic and not at all a given. For instance, let\u0026rsquo;s consider the variance and sample variance.\nExample If we assume $$ X_{i} \\sim \\left( \\mu , \\sigma^{2} \\right) $$, the unbiased estimator for variance is as follows: $$ S^{2} := {{1} \\over {n-1}} \\sum_{i=1}^{n} \\left( X_{i} - \\overline{X} \\right)^{2} $$ As known, unlike the sample mean, the sample variance sums up all squared deviations and divides by $n-1$ not $n$. The reason we divide by $n-1$ when calculating the sample variance why we divide by $n-1$ when calculating sample variance can be explained in various ways depending on the person\u0026rsquo;s level of understanding, but the most accurate formulaic explanation is \u0026lsquo;in order for the sample variance to be an unbiased estimator\u0026rsquo;.\nProof 2 If we assume $$ \\mu := E \\overline{X} \\\\ \\sigma^{2} := E X_{i} ^{2} - \\mu^{2} $$, then $$ \\begin{align*} E \\left( \\overline{X}^{2} \\right) - \\mu^{2} =\u0026amp; E \\left( \\overline{X}^{2} \\right) - \\left( E \\overline{X} \\right)^{2} \\\\ =\u0026amp; \\text{Var} \\overline{X} \\\\ =\u0026amp; \\text{Var} \\left( {{1} \\over {n}} \\sum_{i=1}^{n} X_{i} \\right) \\\\ =\u0026amp; {{1} \\over {n^{2}}} \\sum_{i=1}^{n} \\text{Var} X_{i} \\\\ =\u0026amp; {{1} \\over {n^{2}}} n \\sigma^{2} \\\\ =\u0026amp; {{\\sigma^{2}} \\over {n}} \\end{align*} $$, thus the expected value of the sample variance $S^{2}$ is $$ \\begin{align*} E S^{2} =\u0026amp; (n-1)^{-1} E \\sum_{i=1}^{n} \\left( X_{i} - \\overline{X} \\right)^{2} \\\\ =\u0026amp; (n-1)^{-1} \\left[ \\sum_{i=1}^{n} E X_{i}^{2} - \\sum_{i=1}^{n} E \\overline{X} ^{2} \\right] \\\\ =\u0026amp; (n-1)^{-1} \\left[ \\sum_{i=1}^{n} \\left( \\sigma^{2} + \\mu^{2} \\right) - n \\left( \\mu^{2} + {{\\sigma^{2}} \\over {n}} \\right) \\right] \\\\ =\u0026amp; (n-1)^{-1} \\left[ n\\sigma^{2} + n \\mu^{2} - n \\mu^{2} - \\sigma^{2} \\right] \\\\ =\u0026amp; (n-1)^{-1} (n-1) \\sigma^{2} \\\\ =\u0026amp; \\sigma^{2} \\end{align*} $$\n‚ñ†\nHogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p208.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p137.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1745,"permalink":"https://freshrimpsushi.github.io/en/posts/1745/","tags":null,"title":"Unbiased Estimator"},{"categories":"ÎèôÏó≠Ìïô","contents":"Definition1 Consider a space $X$ and a function $f,g : X \\to X$, the vector field, and map are expressed as follows. $$ \\dot{x} = f(x) \\\\ x \\mapsto g(x) $$ Let $S \\subset X$.\n(V): $\\forall x_{0} \\in S$ is called an invariant set under the vector field $\\dot{x}=f(x)$ if for all $t \\in \\mathbb{R}$ it satisfies: $$ x(t,x_{0}) \\in S $$ (M): $\\forall x_{0} \\in S$ is called an invariant set under the map $x \\mapsto g(x)$ if for all $n \\in \\mathbb{Z}$ it satisfies: $$ g^{n} (x_{0}) \\in S $$ Invariant Sets can also be called as follows depending on the condition:\nIf the invariant set $S$ is considered up to time $t \\ge 0$ or $n \\ge 0$, it is called a Positively Invariant Set; Conversely, if it is considered up to time $t \\le 0$ or $n \\le 0$, it is called a Negatively Invariant Set. If the invariant set $S$ forms a structure of a differentiable manifold in $C^{r}$, it is called a $C^{r}$ Invariant Manifold. Explanation An invariant set refers to a set that cannot escape, whether in the past or in the future. Not being able to escape to the past means, in other words, that it is not allowed to come in from outside of the invariant set. Because all times $\\mathbb{R}$ are considered, it\u0026rsquo;s more appropriate to imagine it as an already determined \u0026lsquo;space\u0026rsquo; rather than a \u0026lsquo;movement\u0026rsquo; which is dynamic.\nNot only are manifolds mentioned, but also the exploration of the space itself, which makes many people think of the connection with Topological Mathematics, as historically, dynamics and Topological Mathematics come from the same root, so it\u0026rsquo;s inevitable for familiar things to frequently appear from both sides. A scholar who left significant achievements in both areas is Henri Poincar√© who is also known for the \u0026lsquo;Poincar√© Conjecture\u0026rsquo;. Since at that time, they were not distinguished, to say that he left achievements in both fields might be inappropriate. The early 1900s was the beginning era of Topological Mathematics and dynamics, and the theories developed by scholars like Poincar√© should be seen as diverging according to their interests.\nThe major methods for finding the existence of invariant sets in a given system include the Hadamard\u0026rsquo;s Method and the Liapunov-Perron Method, and there is also a lot of interest regarding their stability and differentiability.\nWiggins. (2003). Introduction to Applied Nonlinear Dynamical Systems and Chaos Second Edition(2nd Edition): p28.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1079,"permalink":"https://freshrimpsushi.github.io/en/posts/1079/","tags":null,"title":"Invariant Sets in Dynamics"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition Let\u0026rsquo;s assume a function $f :X \\to \\mathbb{R}$ is given in a metric space $X$. If $f$ is not continuous at $x\\in X$, $f$ is said to be discontinuous at $x$ or to have a discontinuity at $x$. $f: (a,b) \\to \\mathbb{R}$ is assumed.\nFor any point $x$, let $a \\le x \u0026lt;b$. Consider a sequence of points $(x,b)$ that converges to $x$ and call it $\\left\\{ t_{n} \\right\\}$. If for every $\\left\\{ t_{n} \\right\\}$ $$ \\lim \\limits_{n \\to \\infty}f(t_{n})=q $$ holds, we denote it as $f(x+)=q$ and call $q$ the right-hand limit of $f$ at $x$.\nFor any point $x$, let $a\u0026lt; x \\le b$. Consider a sequence of points $(a,x)$ that converges to $x$ and call it $\\left\\{ t_{n} \\right\\}$. If for every $\\left\\{ t_{n} \\right\\}$ $$ \\lim \\limits_{n\\to\\infty} f(t_{n})=q $$ holds, we denote it as $f(x-)=q$ and call $q$ the left-hand limit of $f$ at $x$.\nExplanation To talk about discontinuity in detail, we define the concepts of left-hand limit and right-hand limit as above. It should be noted that the left-hand limit and right-hand limit are not only defined at points of discontinuity but can be defined at any point.\nThe definition has been rigorously given in the language of analysis, but the concept itself is no different from the left-hand limit and right-hand limit learned in high school. The idea is to call the limit a right-hand limit if the sequence of function values converges when considering a sequence converging to $x$ composed only of points greater than $x$, and the opposite case a left-hand limit. According to the above definition, it is clear that the following fact holds. In high school, the below proposition was the definition of continuity.\nTheorem For any point $x\\in (a,b)$, the existence of the limit $\\lim \\limits_{t \\to x}f(t)$\n$$ f(x+)=f(x-)=\\lim \\limits_{t\\to x }f(t) $$\nis equivalent to the statement.\n","id":1830,"permalink":"https://freshrimpsushi.github.io/en/posts/1830/","tags":null,"title":"Limits from the Left and the Right Strictly Defined in Analysis"},{"categories":"Ìï®Ïàò","contents":"Definition Let\u0026rsquo;s assume the function $f:[a,b] \\rightarrow \\mathbb{R}$ is given. For $x_{1}$, $x_{2}$, $\\in [a,b]$\n$$ x_{1} \\lt x_{2} \\ \\implies f(x_{1}) \\le f(x_{2}) $$\nIf it satisfies, then $f$ is said to be monotonically increasing or $f$ is called a monotone increasing function. Conversely,\n$$ x_{1} \\lt x_{2} \\ \\implies f(x_{1}) \\ge f(x_{2}) $$\nIf it satisfies, then $f$ is said to be monotonically decreasing or $f$ is called a monotone decreasing function.\nIf $f$ is either a monotone increasing function or a monotone decreasing function, then $f$ is referred to as a monotone function.\nExplanation To monotonically increase means that as the variable increases, the function value does not decrease at least. Conversely, to monotonically decrease means it does not increase at least.\nDefinition The below expression\n$$ x_{1} \\lt x_{2} \\implies f(x_{1}) \\lt f(x_{2}) $$\nIf satisfied by $f$, it is called a strictly increasing function. Conversely,\n$$ x_{1} \\lt x_{2} \\implies f(x_{1}) \\gt f(x_{2}) $$\nIf satisfied by $f$, it is called a strictly decreasing function.\n","id":848,"permalink":"https://freshrimpsushi.github.io/en/posts/848/","tags":null,"title":"Monotonic Functions, Increasing Functions, Decreasing Functions"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 If $f :[a,b] \\to \\mathbb{R}$ is a continuous function and is differentiable at $x\\in [a,b]$, and if $g : f([a,b])\\to \\mathbb{R}$ is differentiable at $f (x)\\in f([a,b])$, and if we define $h : [a,b] \\to \\mathbb{R}$ as follows.\n$$ h(t)=g\\left( f(t) \\right)\\quad (a\\le t \\le b) $$\nThen, $h$ is differentiable at $x$ and its value is as follows.\n$$ h^{\\prime}(x)=g^{\\prime}(f(x))f^{\\prime}(x) $$ Using the composite function symbol, it can be represented as: $$ ( g \\circ f)^{\\prime}(x)=g^{\\prime}(f(x))f^{\\prime}(x) $$\nExplanation This result is commonly referred to as the chain rule.\nHere, $f^{\\prime}(x)$ is also called the inner derivative. If we denote $y=f(x)$, $z=g(y)$, and represent it using Leibniz\u0026rsquo;s notation, it can be expressed as follows. $$ \\frac{dz}{dx}=\\frac{dz}{dy}\\frac{dy}{dx} $$\nThe reason why Leibniz\u0026rsquo;s notation is convenient is because the left side of the above equation looks as though it‚Äôs being simplified like the right side. $\\dfrac{dy}{dx}$ is not \u0026ldquo;dx over dy\u0026rdquo; but the derivative of $y$, yet treating it like a fraction perfectly fits its meaning.\nProof First, let\u0026rsquo;s define the function $G$ as follows.\n$$ G(f(t)) :=\\begin{cases} \\frac{g(f(x))-g(f(t))}{f(x)-f(t)} -g^{\\prime}(f(x)) \u0026amp; f(t) \\ne f(x) \\\\ 0 \u0026amp; f(t)=f(x)\\end{cases},\\quad (t\\in[a,b]) $$\nThen, for all $f(t)$, the following holds.\n$$ \\lim \\limits_{ f(s) \\to f(t) } G(f(s))=G(f(t)) $$\nSince this is a condition for continuity, $G$ is a continuous function. Furthermore, the following holds.\n$$ h(x)-h(t) = g(f(x))-g(f(t))=\\Big( f(x)-f(t) \\Big) \\Big( g^{\\prime}(f(x))+G(f(t)) \\Big) $$\nThen, by the properties of limits, the equation below holds.\n$$ \\begin{align*} h^{\\prime}(x) =\u0026amp;\\ \\lim \\limits_{t \\to x} \\frac{ h(x)-h(t)}{x-t} \\\\ =\u0026amp;\\ \\lim \\limits_{t \\to x} \\frac{ \\Big( f(x)-f(t) \\Big) \\Big( g^{\\prime}(f(x))+G(f(t)) \\Big)}{x-t} \\\\ =\u0026amp;\\ \\lim \\limits_{t \\to x} \\left[ g^{\\prime}(f(x))\\frac{ f(x)-f(t) }{x-t}+G(f(t))\\frac{f(x)-f(t) }{x-t} \\right] \\\\ =\u0026amp;\\ \\lim \\limits_{t \\to x} \\left[ g^{\\prime}(f(x))\\frac{ f(x)-f(t) }{x-t}\\right]+\\lim \\limits_{t \\to x} \\left[G(f(t))\\frac{ f(x)-f(t) }{x-t} \\right] \\\\ =\u0026amp;\\ \\lim \\limits_{t \\to x} g^{\\prime}(f(x))\\lim \\limits_{t \\to x}\\frac{ f(x)-f(t) }{x-t}+\\lim \\limits_{t \\to x}G(f(t))\\lim \\limits_{t \\to x}\\frac{ f(x)-f(t) }{x-t} \\\\ =\u0026amp;\\ g^{\\prime}(f(x))f^{\\prime}(x)+0\\cdot f^{\\prime}(x) \\\\ =\u0026amp;\\ g^{\\prime}(f(x))f^{\\prime}(x) \\end{align*} $$\n‚ñ†\nWalter Rudin, Principles of Mathmatical Analysis (3rd Edition, 1976), p105\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1823,"permalink":"https://freshrimpsushi.github.io/en/posts/1823/","tags":null,"title":"The Chain Rule of Differentiation in Analysis"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 Let\u0026rsquo;s say $f, g : [a,b] \\to \\mathbb{R}$. If $f,g$ is differentiable at $x\\in [a,b]$, then $f+g$, $fg$, and $f/g$ are also differentiable at $x$ and the following equation holds.\n$$ \\begin{align} (f+g)^{\\prime}(x) \u0026amp;=f^{\\prime}(x)+g^{\\prime}(x) \\\\ (fg)^{\\prime}(x) \u0026amp;= f^{\\prime}(x)g(x)+f(x)g^{\\prime}(x) \\\\ \\left( \\frac{f}{g} \\right)^{\\prime}(x) \u0026amp;= \\frac{f^{\\prime}(x)g(x)-f(x)g^{\\prime}(x)}{g^{2}(x)} \\end{align} $$\nHowever, $(3)$ holds when $g(x)\\ne 0$.\nDescription $(2)$ is commonly referred to as the product rule of differentiation.\nProof $(1)$ By the definition of differentiation and the properties of the limit of functions, the following is true.\n$$ \\begin{align*} (f+g)^{\\prime}(x) \u0026amp;=\\lim \\limits_{t \\to x} \\frac{(f+g)(x)-(f+g)(t)}{x-t} \\\\ \u0026amp;= \\lim \\limits_{t \\to x} \\frac{(f(x)+g(x))-(f(t)+g(t))}{x-t} \\\\ \u0026amp;= \\lim \\limits_{t \\to x} \\frac{(f(x)-f(t))+(g(x)+g(t))}{x-t} \\\\ \u0026amp;= \\lim \\limits_{t \\to x} \\left[ \\frac{f(x)-f(t)}{x-t}+\\frac{g(x)+g(t)}{x-t} \\right] \\\\ \u0026amp;= \\lim \\limits_{t \\to x} \\frac{f(x)-f(t)}{x-t}+ \\lim \\limits_{t \\to x}\\frac{g(x)+g(t)}{x-t} \\\\ \u0026amp;= f^{\\prime}(x)+g^{\\prime}(x) \\end{align*} $$\n‚ñ†\n$(2)$ The following holds by the definition of differentiation and the properties of the limit of functions.\n$$ \\begin{align*} (fg)^{\\prime}(x) \u0026amp;= \\lim \\limits_{t \\to x} \\frac{(fg)(x)-(fg)(t)}{x-t} \\\\ \u0026amp;= \\lim \\limits_{t \\to x}\\frac{f(x)g(x)-f(t)g(t)}{x-t} \\\\ \u0026amp;= \\lim \\limits_{t \\to x}\\frac{f(x)g(x) {\\color{blue}-f(t)g(x)+f(t)g(x)}-f(t)g(t)}{x-t} \\\\ \u0026amp;= \\lim \\limits_{t \\to x}\\left[ \\frac{f(x)g(x) -f(t)g(x)}{x-t} + \\frac{f(t)g(x)-f(t)g(t)}{x-t} \\right] \\\\ \u0026amp;= \\lim \\limits_{t \\to x}\\left[ \\frac{f(x) -f(t)}{x-t}g(x) + f(t)\\frac{g(x)-g(t)}{x-t} \\right] \\\\ \u0026amp;= \\lim \\limits_{t \\to x} \\left[\\frac{f(x) -f(t)}{x-t}g(x)\\right] + \\lim \\limits_{t \\to x} \\left[ f(t)\\frac{g(x)-g(t)}{x-t} \\right] \\\\ \u0026amp;= \\lim \\limits_{t \\to x}\\frac{f(x) -f(t)}{x-t}\\lim \\limits_{t \\to x}g(x) + \\lim \\limits_{t \\to x} f(t)\\lim \\limits_{t \\to x}\\frac{g(x)-g(t)}{x-t} \\\\ \u0026amp;= f^{\\prime}(x)g(x)+f(x)g^{\\prime}(x) \\end{align*} $$\n‚ñ†\n$(3)$ Proved by a similar method to $(2)$.\n$$ \\begin{align*} \\left( \\frac{f}{g} \\right)^{\\prime}(x) \u0026amp;= \\lim \\limits_{ t \\to x } \\frac{(f/g)(x) -(f/g)(t)}{x-t} \\\\ \u0026amp;= \\lim \\limits_{ t \\to x } \\frac{f(x)/g(x) -f(t)/g(t)}{x-t} \\\\ \u0026amp;= \\lim \\limits_{ t \\to x } \\frac{f(x)/g(x) {\\color{blue}-f(x)/g(t)+f(x)/g(t)}- f(t)/g(t)}{x-t} \\\\ \u0026amp;= \\lim \\limits_{ t \\to x } \\left[ \\frac{f(x)/g(x) - f(x)/g(t) }{x-t}+\\frac{f(x)/g(t)-f(t)/g(t)}{x-t} \\right] \\\\ \u0026amp;= \\lim \\limits_{ t \\to x } \\left[ \\frac{\\frac{f(x){\\color{blue}g(t)}}{g(x){\\color{blue}g(t)}} -\\frac{f(x){\\color{blue}g(x)}}{g(t){\\color{blue}g(x)}} }{x-t}+\\frac{\\frac{f(x){\\color{blue}g(x)}}{g(t){\\color{blue}g(x)}}-\\frac{f(t){\\color{blue}g(x)}}{g(t){\\color{blue}g(x)}}}{x-t} \\right] \\\\ \u0026amp;= \\lim \\limits_{ t \\to x } \\frac{1}{g(x)g(t)} \\left[ {\\color{red}\\frac{f(x)g(t)-f(x)g(x) }{x-t}}+\\frac{f(x)g(x)-f(t)g(x)}{x-t} \\right] \\\\ \u0026amp;= \\lim \\limits_{ t \\to x }\\frac{1}{g(x)g(t)} \\left[\\frac{f(x)g(x)-f(t)g(x)}{x-t}{\\color{red}-\\frac{f(x)g(x)-f(x)g(t) }{x-t}} \\right] \\\\ \u0026amp;= \\lim \\limits_{ t \\to x }\\frac{1}{g(x)g(t)} \\left[\\frac{f(x)-f(t)}{x-t}g(x)-f(x)\\frac{g(x)-g(t) }{x-t} \\right] \\\\ \u0026amp;= \\lim \\limits_{ t \\to x }\\frac{1}{g(x)g(t)} \\lim \\limits_{ t \\to x } \\left[\\frac{f(x)-f(t)}{x-t}g(x)-f(x)\\frac{g(x)-g(t) }{x-t} \\right] \\\\ \u0026amp;= \\frac{1}{g^{2}(x)}\\left[ f^{\\prime}(x)g(x)-f(x)g^{\\prime}(x) \\right] \\\\ \u0026amp;= \\frac{f^{\\prime}(x)g(x)-f(x)g^{\\prime}(x)}{g^{2}(x)} \\end{align*} $$\n‚ñ†\nWalter Rudin, Principles of Mathmatical Analysis (3rd Edition, 1976), p104-105\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1821,"permalink":"https://freshrimpsushi.github.io/en/posts/1821/","tags":null,"title":"Differentiable Function Properties"},{"categories":"ÎèôÏó≠Ìïô","contents":"Definition Given a space $X$ and a function $f \\in C^{1}(X,X)$, consider the following vector field given as a differential equation: $$ \\dot{x} = f(x) $$ Let $\\overline{x}$ be a fixed point of this autonomous system and the eigenvalues of $D f \\left( \\overline{x} \\right)$ be described as $\\lambda_{1} , \\cdots , \\lambda_{m}$.\nHyperbolic: Hyperbolic Fixed Points1 Hyperbolic: If the real parts of all eigenvalues of $D f \\left( \\overline{x} \\right)$ are not $0$, then $\\overline{x}$ is said to be hyperbolic. $$ \\text{Re} \\left( \\lambda_{1} \\right) \\ne 0 , \\cdots , \\text{Re} \\left( \\lambda_{m} \\right) \\ne 0 $$ Saddle: If $\\overline{x}$ is hyperbolic and $D f \\left( \\overline{x} \\right)$ has at least one eigenvalue with a positive real part and one with a negative real part, then $\\overline{x}$ is called a saddle. $$ \\exists i, j \\in [1,m] : \\text{Re} \\left( \\lambda_{i} \\right) \u0026gt; 0 \\land \\text{Re} \\left( \\lambda_{j} \\right) \u0026lt; 0 $$ Sink : If the real parts of all eigenvalues of $D f \\left( \\overline{x} \\right)$ are negative, then $\\overline{x}$ is said to be stable and called a sink. $$ \\text{Re} \\left( \\lambda_{1} \\right) \u0026lt; 0 , \\cdots , \\text{Re} \\left( \\lambda_{m} \\right) \u0026lt; 0 $$ Source : If the real parts of all eigenvalues of $D f \\left( \\overline{x} \\right)$ are positive, then $\\overline{x}$ is said to be unstable and called a source. $$ \\text{Re} \\left( \\lambda_{1} \\right) \u0026gt; 0 , \\cdots , \\text{Re} \\left( \\lambda_{m} \\right) \u0026gt; 0 $$ Elliptic: Elliptic Fixed Points2 Elliptic, Center : If all eigenvalues of $D f \\left( \\overline{x} \\right)$ are purely imaginary, then $\\overline{x}$ is said to be elliptic and called a center. $$ \\text{Im} \\left( \\lambda_{1} \\right) = \\lambda_{1} , \\cdots , \\text{Im} \\left( \\lambda_{m} \\right) = \\lambda_{m} $$ $\\Re$ and $\\Im$ are functions that extract only the real and imaginary parts, respectively, from complex numbers. Description Although not explicitly stated in the definition, the distinction between hyperbolic and non-hyperbolic can be roughly equated with the simplicity of the system. In analyzing systems dynamically, the primary issue often arises when an eigenvalue is $0$; being hyperbolic means one does not have to worry about such nuisances, simplifying the analysis.\nExamples Consider the Duffing oscillator as an example: $$ \\begin{align*} \\dot{x} =\u0026amp; y \\\\ \\dot{y} =\u0026amp; x - x^{3} - \\delta y \\qquad , \\delta \\ge 0 \\end{align*} $$ The fixed points of the Duffing oscillator are $(x,y) = (0,0) , (\\pm 1 , 0)$ and its Jacobian is: $$ D \\mathbb{f} = \\begin{bmatrix} 0 \u0026amp; 1 \\\\ 1 - 3 x^{2} \u0026amp; - \\delta \\end{bmatrix} $$ Thus, the Jacobian at the fixed points is: $$ D \\mathbb{f} (0,0) = \\begin{bmatrix} 0 \u0026amp; 1 \\\\ 1 \u0026amp; - \\delta \\end{bmatrix} \\\\ D \\mathbb{f} (\\pm1,0) = \\begin{bmatrix} 0 \u0026amp; 1 \\\\ -2 \u0026amp; - \\delta \\end{bmatrix} $$ Calculating the eigenvalues yields, when $(0,0)$: $$ \\det ( D \\mathbb{f} (0,0) - \\lambda E ) = \\det \\begin{bmatrix} -\\lambda \u0026amp; 1 \\\\ 1 \u0026amp; -\\lambda - \\delta \\end{bmatrix} = \\lambda^{2} + \\delta \\lambda - 1 $$ According to the quadratic formula: $$ \\lambda_{1,2} = {{ -\\delta \\pm \\sqrt{\\delta^{2} + 4 } } \\over { 2 }} $$ The eigenvalues of $D \\mathbb{f} (0,0)$ always include a positive and a negative number, thus the fixed point $(0,0)$ is a saddle. Similarly, calculating the eigenvalues for $D \\mathbb{f} (\\pm1,0)$ yields: $$ \\lambda_{1,2} = {{ -\\delta \\pm \\sqrt{\\delta^{2} - 8 } } \\over { 2 }} $$ Therefore, the eigenvalues of $D \\mathbb{f} (\\pm1,0)$ are all negative when $\\delta \u0026gt; 0$, and the fixed point $(\\pm1,0)$ is a sink. However, when $\\delta = 0$, the eigenvalues are purely imaginary $\\lambda_{1,2} = \\pm \\sqrt{2} i$, making the fixed point $(\\pm1,0)$ a center.\nIn the above example, we determined the Jacobian at each fixed point and examined how stability changes based on the settings of the parameter $\\delta$. Such analysis, if the system is represented by a vector field, is a common approach used in any paper on dynamics. At least once, be sure to try it yourself.\nWiggins. (2003). Introduction to Applied Nonlinear Dynamical Systems and Chaos Second Edition(2nd Edition): p12.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWiggins. (2003). Introduction to Applied Nonlinear Dynamical Systems and Chaos Second Edition(2nd Edition): p12.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1733,"permalink":"https://freshrimpsushi.github.io/en/posts/1733/","tags":null,"title":"Classification of Fixed Points in Autonomous Systems"},{"categories":"Ìë∏Î¶¨ÏóêÌï¥ÏÑù","contents":"Formulas The complex Fourier series of a function $f$ defined over the interval $[-L,\\ L)$ is given by:\n$$ f(t) = \\sum \\limits_{n=-\\infty}^{\\infty} c_{n} e^{i\\frac{n\\pi t}{L}} $$\nHere, the complex Fourier coefficients are as follows:\n$$ c_{n} = \\dfrac{1}{2L}\\int_{-L}^{L}f(t)e^{-i\\frac{n \\pi t}{L} }dt $$\nThe Fourier coefficients satisfy the following equation:\n$$ \\begin{align*} a_{0} \u0026amp; = 2 c_{0} \\\\ a_{n} \u0026amp;= c_{n}+c_{-n} \\\\ b_{n} \u0026amp;= i(c_{n}-c_{-n}) \\\\ c_{n} \u0026amp;= \\frac{1}{2} (a_{n}-ib_{n}) \\\\ c_{-n} \u0026amp;= \\frac{1}{2} (a_{n}+ib_{n}) \\end{align*} $$\nIt\u0026rsquo;s a form that is used more frequently than the trigonometric form because it is simpler.\nProof Fourier series\n$$ \\begin{equation} f(t) = \\dfrac{a_{0}}{2}+\\sum \\limits_{n=1}^{\\infty} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L} + b_{n}\\sin\\dfrac{n\\pi t }{L} \\right) \\end{equation} $$\n$$ \\begin{align*} \\text{where}\\quad a_{0} =\u0026amp;\\ \\dfrac{1}{L}\\int_{-L}^{L}f(t)dt \\\\ a_{n} =\u0026amp;\\ \\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{n\\pi t}{L} dt \\\\ b_{n} =\u0026amp;\\ \\dfrac{1}{L}\\int_{-L}^{L}f(t)\\sin\\dfrac{n\\pi t}{L}dt \\\\ \\end{align*} $$\nUsing the Euler\u0026rsquo;s formula, the cosine and sine functions can be expressed as complex exponential functions as follows:\n$$ \\begin{align*} \\cos \\dfrac{n\\pi t}{L} \u0026amp;= \\dfrac{e^{i\\frac{n\\pi t}{L}} + e^{-i\\frac{n\\pi t}{L}} }{2} \\\\ \\sin \\dfrac{n \\pi t}{L} \u0026amp;= \\dfrac{e^{i\\frac{n\\pi t}{L}} - e^{-i\\frac{n\\pi t}{L}} }{2i} \\end{align*} $$\nSubstituting this into $(1)$ yields:\n$$ f(t)=\\dfrac{a_{0}}{2}+\\sum \\limits_{n=1}^{\\infty} \\left( a_{n} \\dfrac{e^{i\\frac{n\\pi t}{L}} + e^{-i\\frac{n\\pi t}{L}} }{2} + b_{n}\\dfrac{e^{i\\frac{n\\pi t}{L}} - e^{-i\\frac{n\\pi t}{L}} } {2i} \\right) $$\nGrouping terms based on the exponential function gives:\n$$ f(t) = \\dfrac{a_{0}}{2}+\\sum \\limits_{n=1}^{\\infty} \\left( \\dfrac{1}{2}\\left(a_{n}-ib_{n} \\right)e^{i\\frac{n\\pi t}{L}} +\\dfrac{1}{2}\\left(a_{n} + ib_{n} \\right) e^{-i\\frac{n\\pi t}{L} } \\right) $$\nIf we denote $c_{0}=\\dfrac{a_{0}}{2}$, $c_{n}=\\dfrac{1}{2}\\left(a_{n}-ib_{n} \\right)$, and $c_{-n}=\\dfrac{1}{2}\\left(a_{n} + ib_{n} \\right)$ as follows:\n$$ f(t) =c_{0}+\\sum \\limits_{n=1}^{\\infty} \\left( c_{n}e^{i\\frac{n\\pi t}{L}} +c_{-n} e^{-i\\frac{n\\pi t}{L} } \\right) $$\nAnd organize the indices into a single one:\n$$ f(t) = \\sum \\limits_{n=-\\infty}^{\\infty} c_{n} e^{i\\frac{n \\pi t}{L} } $$\nAlso, if we compute $c_{0}$, $c_{n}$, and $c_{-n}$:\n$$ \\begin{align*} c_{0} \u0026amp;=\\dfrac{a_{0}}{2}=\\dfrac{1}{2L}\\int_{-L}^{L}f(t)dt \\\\ c_{n}\u0026amp;=\\dfrac{1}{2}\\left(a_{n}-ib_{n} \\right)=\\dfrac{1}{2L}\\int_{-L}^{L}f(t)e^{-i\\frac{n \\pi t}{L} }dt \\quad (n=1,\\ 2,\\ \\cdots ) \\\\ c_{-n}\u0026amp;=\\dfrac{1}{2}\\left(a_{n} + ib_{n} \\right)=\\dfrac{1}{2L}\\int_{-L}^{L}f(t)e^{i\\frac{n \\pi t}{L} }dt \\quad (n=-1,\\ -2,\\ \\cdots) \\end{align*} $$\nThen:\n$$ c_{n} = \\dfrac{1}{2L}\\int_{-L}^{L}f(t)e^{-i\\frac{n \\pi t}{L} }dt \\quad (n=0,\\ \\pm 1,\\ \\pm 2,\\ \\cdots) $$\n‚ñ†\n","id":964,"permalink":"https://freshrimpsushi.github.io/en/posts/964/","tags":null,"title":"Fourier Series in Complex Notation"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definitions1 Partial Differential Equations For a natural number $k \\in \\mathbb{N}$ and an open set $U \\subset \\mathbb{R}^{n}$, the following expression is called a $k$-order partial differential equation.\n$$ \\begin{equation} F(D^{k}u(x), D^{k-1}u(x),\\cdots,Du(x),u(x),x)=0\\quad (x\\in U) \\end{equation} $$\nHere, $D^{k}u$ is the multi-index notation. $F$ is given as follows, and the unknown $u$ is as follows.\n$$ F : {\\mathbb{R}}^{n^{k}}\\times{\\mathbb{R}}^{n^{k-1}}\\times \\cdots \\times \\mathbb{R}^{n}\\times \\mathbb{R}\\times U \\to \\mathbb{R} \\\\ u : U \\to \\mathbb{R} $$\nSystem of Partial Differential Equations Given $\\mathbf{F} : {\\mathbb{R}}^{mn^{k}}\\times{\\mathbb{R}}^{mn^{k-1}}\\times \\cdots \\times \\mathbb{R}^{mn}\\times \\mathbb{R}^{m}\\times U \\to \\mathbb{R}^{m}$ and the unknowns $\\mathbf{u}:U \\to \\mathbb{R}^{m}$, $\\mathbf{u}=(u^{1},\\cdots,u^{m})$, the expression below\n$$ \\mathbf{F}(D^{k}\\mathbf{u}(x),D^{k-1}\\mathbf{u}(x),\\cdots,D\\mathbf{u}(x),\\mathbf{u}(x),x)=\\mathbf{0}\\quad (x\\in U) $$\nis called a $k$-order system of partial differential equations.\nExplanation Partial differential equations are commonly abbreviated as PDEs. Solving a PDE means finding all $u$ that satisfy $(1)$, and such $u$ are called solutions.\nFinding a solution means\nIdeally, finding a simple and explicit solution, When that\u0026rsquo;s not possible, determining the existence of a solution or other characteristics. In most cases, $U, \\Omega \\subset \\mathbb{R}^{n}$ in a partial differential equation represents an open set, and the variable $t$ always represents time, where $t\\ge 0$. Also,\n$$ Du=D_{x}u=(u_{x_{1}},\\cdots,u_{x_{n}}) $$\nrepresents the gradient of $u$. Here, $x=(x_{1},\\cdots,x_{n})$.\nClassification Partial differential equations can be classified based on linearity as follows.\nLinear The partial differential equation $(1)$ is said to be linear if it satisfies the following equation for a given function $a_{\\alpha}, f$.\n$$ \\sum _{| \\alpha | \\le k} a_{\\alpha}(x) D^{\\alpha} u = f(x) $$\nIf $f=0$, it is called a homogeneous linear PDE. If it\u0026rsquo;s not linear, it\u0026rsquo;s called non-linear. 2nd-order linear partial differential equations are further classified as:\nHyperbolic PDE Parabolic PDE Elliptic PDE Semilinear A partial differential equation $(1)$ is called semilinear if it satisfies the following.\n$$ \\sum _{| \\alpha | = k} a_{\\alpha}(x) D^{\\alpha} u + a_{0}\\left( D^{k-1}u, \\dots, Du, u, x \\right) = 0 $$\nIn other words, a semilinear pde means a partial differential equation whose coefficients of the derivative of order $k$ (the highest order) depend only on $x$. For example,\nReaction-diffusion equation $$ u_{t} - \\Delta u = f(u) \\qquad (\\text{e.g. } f(u) = u^{2}) $$ Quasilinear A partial differential equation $(1)$ is called quasilinear if it satisfies the following.\n$$ \\sum _{| \\alpha | = k} a_{\\alpha}(D^{k-1}u, \\dots, Du, u, x)D^{\\alpha} u + a_{0}\\left( D^{k-1}u, \\dots, Du, u, x \\right) = 0 $$\nExamples include\nInviscid Burgers\u0026rsquo; equation $$ u_{t} + uu_{xx} = 0 $$ Fully Non-linear Non-linear equations that are not quasilinear are called fully nonlinear.\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p1-3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1818,"permalink":"https://freshrimpsushi.github.io/en/posts/1818/","tags":null,"title":"Partial Differential Equations"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Summary The divergence of the vector function $\\mathbf{F}=\\mathbf{F}(q_{1},q_{2},q_{3})=F_{1}\\hat{\\mathbf{q}}_{1}+F_{2}\\hat{\\mathbf{q}}_{2}+F_{3}\\hat{\\mathbf{q}}_{3}$ in curvilinear coordinates is as follows.\n$$ \\nabla \\cdot \\mathbf{F}=\\frac{1}{h_{1}h_{2}h_{3}}\\left[ \\frac{ \\partial }{ \\partial q_{1} }(h_{2}h_{3}F_{1})+\\frac{ \\partial }{ \\partial q_{2} }(h_{1}h_{3}F_{2})+\\frac{ \\partial }{ \\partial q_{3} }(h_{1}h_{2}F_{3}) \\right] $$\n$h_{i}$ is the scale factor.\nFormulas Cartesian coordinates:\n$$ h_{1}=h_{2}=h_{3}=1 $$\n$$ \\begin{align*} \\nabla \\cdot \\mathbf{F} =\\frac{\\partial F_{x}}{\\partial x}+\\frac{\\partial F_{y}}{\\partial y}+\\frac{\\partial F_{z}}{\\partial z} \\end{align*} $$\nCylindrical coordinates:\n$$ h_{1}=1,\\quad h_{2}=\\rho,\\quad h_{3}=1 $$\n$$ \\begin{align*} \\nabla \\cdot \\mathbf{F} \u0026amp;= \\frac{1}{\\rho} \\left( \\frac{\\partial (\\rho F_{\\rho})}{\\partial \\rho} + \\frac{\\partial (F_{\\phi})}{\\partial \\phi} + \\frac{\\partial (\\rho F_{z})}{\\partial z} \\right) \\\\ \u0026amp;= \\frac{1}{\\rho} \\frac{\\partial (\\rho F_{\\rho})}{\\partial \\rho} + \\frac{1}{\\rho}\\frac{\\partial F_{\\phi}}{\\partial \\phi} + \\frac{\\partial F_{z}}{\\partial z} \\end{align*} $$\nSpherical coordinates: $$ h_{1}=1,\\quad h_{2}=r\\quad, h_{3}=r\\sin\\theta $$\n$$ \\begin{align*} \\nabla \\cdot \\mathbf{F} \u0026amp;= \\frac{1}{r^{2}\\sin\\theta}\\left( \\frac{\\partial (r^{2}\\sin\\theta F_{r})}{\\partial r}+\\frac{\\partial (r\\sin\\theta F_{\\theta})}{\\partial \\theta}+\\frac{\\partial (rF_{\\phi})}{\\partial \\phi} \\right) \\\\ \u0026amp;= \\frac{1}{r^{2}}\\frac{\\partial (r^{2} F_{r})}{\\partial r}+\\frac{1}{r\\sin\\theta}\\frac{\\partial (\\sin\\theta F_{\\theta})}{\\partial \\theta}+\\frac{1}{r\\sin\\theta}\\frac{\\partial F_{\\phi}}{\\partial \\phi} \\end{align*} $$\nDerivation In the 3D Cartesian coordinate system, the divergence $\\nabla \\cdot \\mathbf{F}$ of the vector function $\\mathbf{F}$ told us how $\\mathbf{F}$ flows. We can get the divergence in the curvilinear coordinates in the same way. Let\u0026rsquo;s first compute it only in the direction of $q_{1}$ axis. The amount passing through $d\\mathbf{a}_{1}$ and $d\\mathbf{a}_{2}$ can be calculated by the inner product of the two vectors. The computation is the same as in the Cartesian coordinates, so some parts are omitted.\n$$ \\begin{align*} \\mathbf{F}(q_{1}+dq_{1},q_{2},q_{3})\\cdot d\\mathbf{a}_{1} \u0026amp;= F_{1}(q_{1}+dq_{1},q_{2},q_{3})h_{2}h_{3}dq_{2}dq_{3} \\\\ \\mathbf{F}(q_{1},q_{2},q_{3})\\cdot d\\mathbf{a}_{2} \u0026amp;=- F_{1}(q_{1},q_{2},q_{3})h_{2}h_{3}dq_{2}dq_{3} \\end{align*} $$\nAnd the sum of these two is the influx (outflux).\n$$ \\begin{align*} \u0026amp;F_{1}(q_{1}+dq_{1},q_{2},q_{3})h_{2}h_{3}dq_{2}dq_{3}- F_{1}(q_{1},q_{2},q_{3})h_{2}h_{3}dq_{2}dq_{3} \\\\ =\u0026amp; \\frac{F_{1}(q_{1}+dq_{1},q_{2},q_{3})h_{2}h_{3}- F_{1}(q_{1},q_{2},q_{3})h_{2}h_{3} }{dq_{1}}dq_{1}dq_{2}dq_{3} \\\\ \\approx \u0026amp;\\frac{ \\partial (F_{1}h_{2}h_{3})}{ \\partial q_{1}}dq_{1}dq_{2}dq_{3} \\end{align*} $$\nIn the same way, if calculated for $q_{2}$ and $q_{3}$, it is as follows.\n$$ \\frac{ \\partial (F_{2}h_{1}h_{3})}{ \\partial q_{2}}dq_{1}dq_{2}dq_{3}\\quad \\text{and} \\quad \\frac{ \\partial (F_{3}h_{1}h_{2})}{ \\partial q_{3}}dq_{1}dq_{2}dq_{3} $$\nAdding these gives the amount of $\\mathbf{F}$ entering or leaving, and dividing it by the volume $dV=h_{1}h_{2}h_{3}dq_{1}dq_{2}dq_{3}$ gives the influx (outflux) per unit volume.\n$$ \\begin{align*} \u0026amp; \\frac{ \\partial (F_{1}h_{2}h_{3})}{ \\partial q_{1}}dq_{1}dq_{2}dq_{3}+\\frac{ \\partial (F_{2}h_{1}h_{3})}{ \\partial q_{2}}dq_{1}dq_{2}dq_{3}+\\frac{ \\partial (F_{3}h_{1}h_{2})}{ \\partial q_{3}}dq_{1}dq_{2}dq_{3} \\\\ =\u0026amp;\\ \\left( \\frac{ \\partial (F_{1}h_{2}h_{3})}{ \\partial q_{1}}+\\frac{ \\partial (F_{2}h_{1}h_{3})}{ \\partial q_{2}}+\\frac{ \\partial (F_{3}h_{1}h_{2})}{ \\partial q_{3}} \\right)dq_{1}dq_{2}dq_{3} \\\\ \\frac{1}{dV}\\times \\implies \u0026amp;\\frac{1}{h_{1}h_{2}h_{3}}\\left( \\frac{ \\partial (F_{1}h_{2}h_{3})}{ \\partial q_{1}}+\\frac{ \\partial (F_{2}h_{1}h_{3})}{ \\partial q_{2}}+\\frac{ \\partial (F_{3}h_{1}h_{2})}{ \\partial q_{3}} \\right) \\end{align*} $$\n‚ñ†\nSee also Formulas for gradient, divergence, curl, and Laplacian in curvilinear coordinates Gradient Divergence Curl Laplacian ","id":1817,"permalink":"https://freshrimpsushi.github.io/en/posts/1817/","tags":null,"title":"Divergence of Vector Functions in Curvilinear Coordinates"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 Let the probability density function $f (x; \\theta)$ of the random variable $X$ and the samples $X_{1} , \\cdots , X_{n}$ with a Confidence Coefficient $\\alpha \\in (0,1)$ be given. $$ L := L \\left( X_{1} , \\cdots , X_{n} \\right) \\\\ U := U \\left( X_{1} , \\cdots , X_{n} \\right) $$ It is said that the statistic $L \u0026lt; U$ is defined as above, then the interval $(L,U) \\subset \\mathbb{R}$ satisfying the following is called the $( 1 - \\alpha)100 \\%$ confidence interval for the parameter $\\theta$. $$ 1-\\alpha = P \\left[ \\theta \\in \\left( L,U \\right) \\right] $$\nExplanation In fact, the confidence interval can be generalized into a broader space as a confidence region, and from the standpoint of learning basic statistics, defining it mathematically like above could be unnecessarily complicated. However, now that the definitions of random variables, samples, and statistics have become mathematically solid, we can continue a more rigorous discussion.\nWhat\u0026rsquo;s important in this definition of confidence intervals is that $L$ and $U$ are statistics. Although the confidence interval is presented as an interval, which allows us to perceive it spatially, in fact, the confidence intervals that were calculated in statistics before mathematical statistics would have been found by calculating its upper $U$ and lower $L$ limits. For example, if $X$ follows the standard normal distribution $N(0,1)$, the $1-\\alpha$ confidence interval for $\\mu$ would have been calculated as follows. $$ L := \\overline{X} - {{ S } \\over { \\sqrt{n} }} z_{\\alpha/2} \\\\ U := \\overline{X} + {{ S } \\over { \\sqrt{n} }} z_{\\alpha/2} $$ Let\u0026rsquo;s pay attention to the fact that what actually \u0026ldquo;moves\u0026rdquo; in this interval estimation for $\\mu$ to find the confidence interval are the ends of the interval $L,U$. At a glance, it might seem like we are interested in the probability of $\\mu$ randomly changing and falling within the confidence interval, but calling $L,U$ a \u0026ldquo;statistic\u0026rdquo; is precisely to prevent such misinterpretations.\nSee Also Complex definitions of confidence intervals Hogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p218.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1732,"permalink":"https://freshrimpsushi.github.io/en/posts/1732/","tags":null,"title":"Easy Definition of Confidence Intervals"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Theorem In a curvilinear coordinate system, the gradient of a scalar function $f=f(q_{1},q_{2},q_{3})$ is as follows.\n$$ \\nabla f= \\frac{1}{h_{1}}\\frac{ \\partial f }{ \\partial q_{1} } \\hat{\\mathbf{q}}_{1} + \\frac{1}{h_{2}}\\frac{ \\partial f }{ \\partial q _{2}}\\hat{\\mathbf{q}}_{2}+\\frac{1}{h_{3}}\\frac{ \\partial f }{ \\partial q_{3} } \\hat{\\mathbf{q}}_{3}=\\sum \\limits _{i=1} ^{3}\\frac{1}{h_{i}}\\frac{ \\partial f}{ \\partial q_{i}}\\hat{\\mathbf{q}}_{i} $$\n$h_{i}$ is the scale factor.\nFormulas Cartesian Coordinate System:\n$$ h_{1}=h_{2}=h_{3}=1 $$\n$$ \\nabla f= \\frac{\\partial f}{\\partial x}\\mathbf{\\hat{\\mathbf{x}} }+ \\frac{\\partial f}{\\partial y}\\mathbf{\\hat{\\mathbf{y}}} + \\frac{\\partial f}{\\partial z}\\mathbf{\\hat{\\mathbf{z}}} $$\nCylindrical Coordinate System:\n$$ h_{1}=1,\\quad h_{2}=\\rho,\\quad h_{3}=1 $$\n$$ \\nabla f = \\frac{\\partial f}{\\partial \\rho}\\boldsymbol{\\hat \\rho} + \\frac{1}{\\rho}\\frac{\\partial f}{\\partial \\phi}\\boldsymbol{\\hat \\phi} + \\frac{\\partial f}{\\partial z}\\mathbf{\\hat{\\mathbf{z}}} $$\nSpherical Coordinate System:\n$$ h_{1}=1,\\quad h_{2}=r\\quad, h_{3}=r\\sin\\theta $$\n$$ \\nabla f= \\frac{\\partial f}{\\partial r} \\mathbf{\\hat r} + \\frac{1}{r}\\frac{\\partial f}{\\partial \\theta} \\boldsymbol{\\hat \\theta} + \\frac{1}{r\\sin\\theta}\\frac{\\partial f}{\\partial \\phi}\\boldsymbol{\\hat \\phi} $$\nDerivation In the three-dimensional Cartesian coordinate system, $\\mathbf{a}$, which satisfies the following equation, is defined as the gradient of $f$, and is denoted as $\\nabla f$.\n$$ d f =\\mathbf{a} \\cdot d\\mathbf{r} $$\nThe same definition is applied to any curvilinear coordinate system. The total differential of $f$ is as follows.\n$$ d f = \\frac{ \\partial f}{ \\partial q_{1} }dq_{1}+\\frac{ \\partial f}{ \\partial q_{2}}dq_{2}+\\frac{ \\partial f}{ \\partial q_{3}}dq_{3} $$\nIn a curvilinear coordinate system, the infinitesimal change in the position vector $\\mathbf{r}$ is as follows.\n$$ d\\mathbf{r}=h_{1}dq_{1}\\hat{\\mathbf{q}}_{1}+h_{2}dq_{2}\\hat{\\mathbf{q}}_{2}+h_{3}dq_{3}\\hat{\\mathbf{q}}_{3} $$\nNow, what we seek is $\\mathbf{a}$ that satisfies the equation below.\n$$ \\begin{equation} df=\\mathbf{a} \\cdot d\\mathbf{r} \\end{equation} $$\nGiven $\\mathbf{a}=a_{1}\\hat{\\mathbf{q}}_{1}+a_{2}\\hat{\\mathbf{q}}_{2}+a_{3}\\hat{\\mathbf{q}}_{3}$, then $(1)$ is as follows.\n$$ \\frac{ \\partial f}{ \\partial q_{1} }dq_{1}+\\frac{ \\partial f}{ \\partial q_{2}}dq_{2}+\\frac{ \\partial f}{ \\partial q_{3}}dq_{3} = a_{1}h_{1}dq_{1}+a_{2}h_{2}dq_{2}+a_{3}h_{3}dq_{3} $$\nTherefore, given $a_{i}=\\dfrac{1 }{h_{i}}\\dfrac{ \\partial f}{ \\partial q_{i} }$, the following holds true.\n$$ \\quad \\mathbf{a}=\\frac{1 }{h_{1}}\\frac{ \\partial f}{ \\partial q_{1} }\\hat{\\mathbf{q}}_{1}+\\frac{1 }{h_{2}}\\frac{ \\partial f}{ \\partial q_{2} }\\hat{\\mathbf{q}}_{2}+\\frac{1 }{h_{3}}\\frac{ \\partial f}{ \\partial q_{3} }\\hat{\\mathbf{q}}_{3} $$\nNow, the vector $\\mathbf{a}$ defined as the gradient of $f$ and denoted as $\\nabla f$.\n‚ñ†\nSee Also Formulas for Gradient, Divergence, Curl, and Laplacian in Curvilinear Coordinates Gradient Divergence Curl Laplacian ","id":1816,"permalink":"https://freshrimpsushi.github.io/en/posts/1816/","tags":null,"title":"Gradient of a Scalar Function in Curvilinear Coordinates"},{"categories":"Ìë∏Î¶¨ÏóêÌï¥ÏÑù","contents":"Definition1 If the function $f:\\mathbb{R} \\to \\mathbb{R}$ is a piecewise polynomial on interval $\\mathbb{R}$, it is called a spline on $\\mathbb{R}$. The points where the polynomial changes are called knots.\nExplanation As can be seen from the definition, a spline does not have to be a continuous function. The following function $f$ is an example of a spline.\n$$ f(x) = \\begin{cases} 0 \u0026amp; x\\in[\\infty,0] \\\\ 2x^{2}\u0026amp;x\\in(0,1] \\\\ 2-x \u0026amp; x\\in (1,4] \\\\ \\frac{1}{16}x^{3} \u0026amp; x\\in(4,\\infty] \\end{cases} $$\nIn the above case, $x=0$, $x=1$, and $x=4$ are knots. A B-spline is a spline with good properties. A $B$-B-spline $N_{1}$ is defined using the indicator function on interval $[0,1]$ as follows:\n$$ N_{1}(x) :=\\chi_{[0,1]}(x)\\quad , x\\in \\mathbb{R} $$\nAnd for $m \\in \\mathbb{N}$, B-spline $N_{m+1}$ is defined as follows:\n$$ \\begin{equation} N_{m+1}(x) := (N_{m} * N_{1})(x)\\end{equation} $$\nHere, $\\ast$ is a convolution. $m$ is called the order of the B-spline $N_{m}$. By definition $(1)$, the following is true:\n$$ \\begin{align*} N_{m} =\u0026amp;\\ N_{m-1}*N_{1} \\\\ =\u0026amp;\\ N_{m-2}*N_{1}*N_{1} \\\\ =\u0026amp;\\ N_{m-3}*N_{1}*N_{1}*N_{1} \\\\ =\u0026amp;\\ \\underbrace{N_{1}N_{1}N_{1}\\cdotsN_{1}}_{m} \\end{align} $$\nAlso, from the definition of $N_{1}$ and convolution, the following formula holds true:\n$$ N_{m+1}(x)=\\int _{-\\infty} ^{\\infty}N_{m}(x-t)N_{1}(t)dt=\\int_{0}^{1}N_{m}(x-t)dt $$\nThe picture below shows the graphs of $N_{2}$ and $N_{3}$ from left to right.\nProperties A B-spline of order $m\\in \\mathbb{N}$ satisfies the following properties:\n(a) $\\mathrm{supp}N_{m}=[0,m]$ $\\text{and}$ $N_{m}(x)\u0026gt;0 \\text{ for } x\\in(0,m) $\n(b) $\\displaystyle \\int _{-\\infty} ^{\\infty} N_{m}(x)dx=1$\n(c) For $m\\ge 2$, the following formula holds true:\n$$ \\begin{equation} \\sum \\limits_{k \\in \\mathbb{Z}} N_{m}(x-k)=1,\\quad \\forall x\\in \\mathbb{R} \\end{equation} $$\n(c\u0026rsquo;) When $m=1$, the above formula holds true for $x\\in \\mathbb{R}\\setminus \\mathbb{Z}$.\nSee Also B-splines in Numerical Analysis Ole Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p203-204\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1815,"permalink":"https://freshrimpsushi.github.io/en/posts/1815/","tags":null,"title":"Spline, B-Spline in Analysis"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 12 A function $T$ of a sample $X_{1} , \\cdots , X_{n}$ from a random variable $X$ is called a Statistic. $$ T := T \\left( X_{1} , \\cdots , X_{n} \\right) $$ When the distribution function of $X$ is expressed as $f(x; \\theta)$ or $p(x; \\theta)$, if $T$ serves to capture $\\theta$, then $T$ is referred to as an Estimator of $\\theta$. The probability distribution of a statistic is known as its [Sampling Distribution]. Description The realization of an Estimator is called an Estimate. Parameters are often scalar $\\theta \\in \\mathbb{R}$, and in such cases, $T$ is also termed as a Point Estimator of $\\theta$. For example, when there is a random sample following a normal distribution $N \\left( \\mu, \\sigma^{2} \\right)$, the estimator for the population mean $\\mu$ is as follows. $$ \\overline{X} := {{ 1 } \\over { n }} \\sum_{k = 1}^{n} X_{k} $$ If there is actual data $x_{1} , \\cdots , x_{n}$, the estimate of $\\mu$ is as follows. $$ \\overline{x} := {{ 1 } \\over { n }} \\sum_{k = 1}^{n} x_{k} $$\nSee Also Statistic in Basic Statistics In basic statistics, instead of describing it as a function of a sample, it\u0026rsquo;s more intuitively defined as \u0026lsquo;something calculated\u0026rsquo;. Essentially they mean the same thing but this may be a better definition for freshmen or those not familiar with mathematics.\nExamples of Statistics Excluding things like means or variances, examples of statistics specifically termed \u0026lsquo;statistics\u0026rsquo; include:\nSufficient Statistic: A statistic that contains all information about a parameter within the distribution. Minimum Sufficient Statistic: A sufficient statistic that satisfies a specific condition. Ancillary Statistic: In contrast to a sufficient statistic, it does not convey any information about the parameters. Complete Statistic: A statistic that possesses the properties one would logically expect a statistic to have. Examples of Estimators Examples of estimators include:\nUnbiased Estimator: An estimator that does not possess any bias. Consistent Estimator: An estimator that estimates the parameter accurately in the limit. Maximum Likelihood Estimator: The estimator that maximizes the likelihood. Efficient Estimator: An estimator related to the variance of the statistic. Hogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p208.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCasella. (2001). Statistical Inference(2nd Edition): p211.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1730,"permalink":"https://freshrimpsushi.github.io/en/posts/1730/","tags":null,"title":"Statistical Measures and Estimators in Mathematical Statistics"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definitions 1 The actual outcome of a random variable $X$ is called its realization and is usually represented by the lowercase letter $x$. A set of random variables from the same probability distribution as $X$, with a sample size of $n$, is called a sample, represented as follows: $$ X_{1} , X_{2} , \\cdots , X_{n} $$ If the random variable $X_{1} , \\cdots , X_{n}$ is iid, then a set with size $n$ is called a random sample. Explanation With these definitions, mathematical statistics establishes contact with actual statistical analysis. Handling the realization of random samples pertains to statistical analysis, and mathematical statistics serves as a significant beacon for how to manage those data. While the data of interest, the conclusions sought, and the methods employed may differ, mathematical statistics fundamentally supports the theoretical base necessary for their analysis.\nIn fact, outside of mathematical statistics textbooks, the term realization is rarely used, and typically, there are other terms used to refer directly to these realizations, such as values, data, or observations. However, the convention of using uppercase for random variables and lowercase for data is followed in almost all statistics textbooks.\nSee Also Definition of Data in Introductory Statistics At the undergraduate freshman and sophomore level, introductory statistics courses define data as the collection of results actually measured from experimental units or trials.\nHogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p208.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1715,"permalink":"https://freshrimpsushi.github.io/en/posts/1715/","tags":null,"title":"Random Sampling in Mathematical Statistics"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Overfitting The phenomenon where the training loss decreases, but the test loss (or validation loss) does not decrease or rather increases is called overfitting.\nExplanation There is also a term called underfitting, which basically means the opposite, but frankly, it\u0026rsquo;s a meaningless term and not often used in practice.\nA crucial point in machine learning is that the function trained with the available data must also work well with new data. Therefore, there is a term called generalization performance, referring to the model\u0026rsquo;s performance on unseen data. If likening to entrance exams, a student who scores perfect on mock exams but performs poorly on the actual college entrance exam can be considered as having overfitted to the mock exam questions. On the other hand, a student who scores well on mock exams and similarly well on the actual exam has good generalization performance.\nRegularization Any method that modifies the algorithm to reduce the test loss (not training loss) is called regularization.1\nGoodfellow defines regularization as \u0026ldquo;any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.\u0026rdquo;\nIn other words, all methods to prevent overfitting are collectively called regularization. The first encounter in machine learning or deep learning studies is usually dropout.\nTypes $\\ell_{1}$ regularization $\\ell_{2}$ regularization Weight decay Early stopping Dropout Batch normalization Label smoothing Data augmentation Flooding See Also Standardization: Usually refers to the process in statistics of adjusting the mean of the data to $0$ and the variance to $1$. Normalization: Typically refers to the process of placing data within a specific range. Regularization: Usually refers to the process to prevent overfitting in machine learning. Ian Goodfellow, Yoshua Bengio, and Aaron Courville. (2016) Deep Learning. MIT Press\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1807,"permalink":"https://freshrimpsushi.github.io/en/posts/1807/","tags":null,"title":"What is Overfitting and Regularization in Machine Learning?"},{"categories":"Ï¥àÌï®ÏàòÎ°†","contents":"Definition The set of functions $\\phi : \\mathbb{R}^{n} \\to \\mathbb{C}$ that satisfy the following two conditions is called the Schwartz space, denoted by $\\mathcal{S}(\\mathbb{R}^{n})$. An element $\\phi$ of the Schwartz space is called a Schwartz function.\n(a) $\\phi \\in $ $C^{\\infty}$\n(b) For any multi-index $\\alpha$, $\\beta$, the following holds: $\\left| \\mathbf{x}^{\\beta}D^{\\alpha}\\phi (\\mathbf{x}) \\right| \u0026lt;\\infty$. Here, for $\\beta=(\\beta_{1}, \\beta_{2},\\dots,\\beta_{n})$,\n$$ \\mathbf{x}^{\\beta}=x_{1}^{\\beta_{1}}x_{2}^{\\beta_{2}}\\dots x_{n}^{\\beta_{n}} $$\n(b) can be rewritten as:\n$$ \\mathbf{x}^{ \\beta}D^{\\alpha}\\phi (\\mathbf{x})\\to 0 \\text{ as } \\left| \\mathbf{x} \\right|\\to \\pm \\infty \\quad \\forall \\alpha, \\beta $$\nDescription It defines the multiplication, differentiation, and various operations of distributions on test functions. With this sense, one could attempt to define the Fourier transform of distributions as follows:\n$$ \\widehat{T^{}}(\\phi):=T \\big( \\hat{\\phi} \\big) $$\nHowever, even if $\\phi$ is a test function, it may not have a compact support and thus may not qualify as a test function. Therefore, the Fourier transform of a distribution might not be well-defined. Thus, to ensure the Fourier transform is well-defined, the test function space was extended to newly define the Schwartz space.\nLooking at (a), unlike the condition for test functions, there\u0026rsquo;s no requirement for compact support. This is why condition (b) was added. Test functions, having the strong requirement of compact support, did not need to impose restrictions on the shape of functions. In contrast, since Schwartz functions do not need to have compact support, condition (b), which ensures the function values decrease more rapidly than any polynomial at the ends of the real line, becomes necessary. Indeed, showing that the test function space is a proper subset of the Schwartz function space demonstrates it has been properly extended.\n$$ \\mathcal{D}(\\mathbb{R}^{n}) \\subsetneq \\mathcal{S}(\\mathbb{R}^{n}) $$\nProperties1 Let\u0026rsquo;s say $\\phi, \\psi \\in \\mathcal{S}(\\mathbb{R}^{n})$.\n$\\mathcal{S}(\\mathbb{R}^{n})$ is a vector space. $\\mathcal{S}(\\mathbb{R}^{n})$ is closed under multiplication. $$ \\psi \\phi \\in \\mathcal{S}(\\mathbb{R}^{n}) $$ $\\mathcal{S}(\\mathbb{R}^{n})$ is closed under multiplication by the polynomial $P$. $$ P\\phi \\in \\mathcal{S}(\\mathbb{R}^{n}) $$ $\\mathcal{S}(\\mathbb{R}^{n})$ is closed under differentiation. $$ \\phi^{\\prime} \\in \\mathcal{S}(\\mathbb{R}^{n}) $$ $\\mathcal{S}(\\mathbb{R}^{n})$ is invariant under translations and multiplication by the complex exponential function. $$ \\phi (x+y), \\phi (x)e^{i\\xi \\cdot x} \\in \\mathcal{S}(\\mathbb{R}^{n}) $$ Schwartz functions are integrable. $$ \\int\\limits_{\\mathbb{R}^{n}} \\left| \\phi (x) \\right| dx \\lt \\infty $$ Robert Strichartz, A Guide to Distribution Theory and Fourier Transforms (1994), p30\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1805,"permalink":"https://freshrimpsushi.github.io/en/posts/1805/","tags":null,"title":"Schwartz Space and Schwartz Functions"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Buildup The most common way to express a position in three-dimensional space is the Cartesian coordinate system. Named after Descartes, who devised it, it is also widely known as the orthogonal coordinate system. However, in specific situations, it might be difficult to represent the position using the Cartesian coordinate system. For instance, let\u0026rsquo;s consider an object performing rotational motion on a two-dimensional plane. Then, it would be much simpler to express the position of this object with $(r,\\theta)$ rather than with $(x,y)$. Although referred to as specific situations, in reality, these situations appear quite often when solving physical problems. Therefore, there is a need to introduce a coordinate system other than the Cartesian coordinate system to solve such problems, and the well-arranged mathematical solution for this is the curvilinear coordinate system. A coordinate system in three-dimensional space must meet the following conditions to be considered appropriate:\n(a) It must be transformable to and from the Cartesian coordinate system. (b) Each coordinate\u0026rsquo;s direction must be perpendicular to each other. Since there is no reason to create a new coordinate system if it cannot be transformed to and from the existing coordinate system, (a) is essential. Moreover, considering how mathematically useful the dot product is, a coordinate system that does not satisfy (b) would also not be a good coordinate system. Now let\u0026rsquo;s express the coordinates of the new curvilinear coordinate system with $q_{1}$, $q_{2}$, $q_{3}$. Thus, according to condition (a), it should be expressed as follows:\n$$ \\begin{equation*} \\begin{aligned} x \u0026amp;= x(q_{1},q_{2},q_{3}) \\\\ y \u0026amp;= y(q_{1},q_{2},q_{3}) \\\\ z \u0026amp;= z(q_{1},q_{2},q_{3}) \\end{aligned} \\quad \\text{and} \\quad \\begin{aligned} q_{1} \u0026amp;= q_{1}(x,y,z) \\\\ q_{2} \u0026amp;= q_{2}(x,y,z) \\\\ q_{3} \u0026amp;= q_{3}(x,y,z) \\end{aligned} \\end{equation*} $$\nAlso, let\u0026rsquo;s represent each coordinate\u0026rsquo;s unit vector with $\\hat{\\mathbf{q}}_{1}$, $\\hat{\\mathbf{q}}_{2}$, $\\hat{\\mathbf{q}}_{3}$. Furthermore, let\u0026rsquo;s assume the order of each coordinate follows the right-hand rule. This can be represented as follows with condition (b):\n$$ \\hat{\\mathbf{q}}_{i}\\cdot \\hat{\\mathbf{q}}_{j}=\\delta_{ij} $$\n$$ (\\hat{\\mathbf{q}}_{1}\\times \\hat{\\mathbf{q}}_{2})\\cdot \\hat{\\mathbf{q}}_{3}\u0026gt;0 $$\nSince the area equals length$^{2}$, and volume equals length$^{3}$, let\u0026rsquo;s see how length is expressed in the curvilinear coordinate system. Suppose the coordinates of a certain position vector $\\mathbf{r}$ changed slightly. However, considering various coordinate systems, the variables do not necessarily have to be in length units. For example, when the angle $\\theta$ in the polar coordinate system changes, the distance the position changes is expressed as the arc length $l=r\\theta$. Therefore, if something that corrects the components of $d\\mathbf{r}$ to have the dimensions of length is called $h_{i}$, then $d\\mathbf{r}$ can be expressed as follows:\n$$ d\\mathbf{r}=h_{1}dq_{1}\\hat{\\mathbf{q}_{1}}+h_{2}dq_{2}\\hat{\\mathbf{q}_{2}}+h_{3}dq_{3}\\hat{\\mathbf{q}_{3}} $$\nTherefore, the square of the infinitesimal length is as follows:\n$$ \\begin{equation} ds^{2}=d\\mathbf{r}\\cdot d\\mathbf{r}=(h_{1}dq_{1})^{2}+(h_{2}dq_{2})^{2}+(h_{3}dq_{3})^{2} \\end{equation} $$\nMoreover, the infinitesimal volume is as follows:\n$$ dV=h_{1}h_{2}h_{3}dq_{1}dq_{2}dq_{3} $$\nNow, let\u0026rsquo;s find out how something that corrects each component to have a length dimension, $h_{i}$, is expressed. Meanwhile, the change in $\\mathbf{r}=\\mathbf{r}(q_{1},q_{2},q_{3})$, known as the total differential, is as follows:\n$$ d\\mathbf{r}= \\frac{ \\partial \\mathbf{r}}{ \\partial q_{1}}dq_{1}+\\frac{ \\partial \\mathbf{r}}{ \\partial q_{2}}dq_{2}+\\frac{ \\partial \\mathbf{r}}{ \\partial q_{3}}dq_{3} $$\nThen, the square of the length changed by $\\mathbf{r}$ is as follows:\n$$ \\begin{equation} \\begin{aligned} ds^{2} \u0026amp;= d \\mathbf{r}^{2}=d\\mathbf{r}\\cdot d\\mathbf{r} \\\\ \u0026amp;= \\left( \\frac{ \\partial \\mathbf{r}}{ \\partial q_{1}}dq_{1}+\\frac{ \\partial \\mathbf{r}}{ \\partial q_{2}}dq_{2}+\\frac{ \\partial \\mathbf{r}}{ \\partial q_{3}}dq_{3} \\right) \\cdot \\left( \\frac{ \\partial \\mathbf{r}}{ \\partial q_{1}}dq_{1}+\\frac{ \\partial \\mathbf{r}}{ \\partial q_{2}}dq_{2}+\\frac{ \\partial \\mathbf{r}}{ \\partial q_{3}}dq_{3} \\right) \\\\ \u0026amp;= \\frac{ \\partial \\mathbf{r}}{ \\partial q_{1} }\\cdot\\frac{ \\partial \\mathbf{r}}{ \\partial q_{1}}dq_{1}dq_{1} + \\frac{ \\partial \\mathbf{r}}{ \\partial q_{1} }\\cdot\\frac{ \\partial \\mathbf{r}}{ \\partial q_{2}}dq_{1}dq_{2}+\\frac{ \\partial \\mathbf{r}}{ \\partial q_{1} }\\cdot\\frac{ \\partial \\mathbf{r}}{ \\partial q_{3}}dq_{1}dq_{3} \\\\ \u0026amp;\\quad + \\frac{ \\partial \\mathbf{r}}{ \\partial q_{2} }\\cdot\\frac{ \\partial \\mathbf{r}}{ \\partial q_{1}}dq_{2}dq_{1} + \\frac{ \\partial \\mathbf{r}}{ \\partial q_{2} }\\cdot\\frac{ \\partial \\mathbf{r}}{ \\partial q_{2}}dq_{2}dq_{2}+\\frac{ \\partial \\mathbf{r}}{ \\partial q_{2} }\\cdot\\frac{ \\partial \\mathbf{r}}{ \\partial q_{3}}dq_{2}dq_{3} \\\\ \u0026amp;\\quad + \\frac{ \\partial \\mathbf{r}}{ \\partial q_{3} }\\cdot\\frac{ \\partial \\mathbf{r}}{ \\partial q_{1}}dq_{3}dq_{1} + \\frac{ \\partial \\mathbf{r}}{ \\partial q_{3} }\\cdot\\frac{ \\partial \\mathbf{r}}{ \\partial q_{2}}dq_{3}dq_{2}+\\frac{ \\partial \\mathbf{r}}{ \\partial q_{3} }\\cdot\\frac{ \\partial \\mathbf{r}}{ \\partial q_{3}}dq_{3}dq_{3} \\end{aligned} \\end{equation} $$\nAt this point, the following holds:\n$$ \\begin{align*} \\frac{ \\partial \\mathbf{r}}{ \\partial q_{i} } \u0026amp;= \\frac{ \\partial (x\\hat{\\mathbf{x}}+y\\hat{\\mathbf{y}}+\\hat{z\\mathbf{z}})}{ \\partial q_{i} } \\\\ \u0026amp;= \\frac{ \\partial x}{ \\partial q_{i}}\\hat{\\mathbf{x}}+\\frac{ \\partial y}{ \\partial q_{i}}\\hat{\\mathbf{y}}+\\frac{ \\partial z}{ \\partial q_{i}}\\hat{\\mathbf{z}} \\end{align*} $$\nHence, the following is obtained:\n$$ \\frac{ \\partial \\mathbf{r}}{ \\partial q_{i}}\\cdot \\frac{ \\partial \\mathbf{r}}{ \\partial q_{j}} = \\frac{ \\partial x}{ \\partial q_{i}}\\frac{ \\partial x}{ \\partial q_{j}}+ \\frac{ \\partial y}{ \\partial q_{i}}\\frac{ \\partial y}{ \\partial q_{j}}+\\frac{ \\partial z}{ \\partial q_{i}}\\frac{ \\partial z}{ \\partial q_{j}} $$\nIf the above equation is simply represented by $g_{ij}=\\frac{ \\partial \\mathbf{r}}{ \\partial q_{i}}\\cdot \\frac{ \\partial \\mathbf{r}}{ \\partial q_{j}}$, then $(2)$ is as follows:\n$$ \\begin{equation} \\begin{aligned} ds^{2} \u0026amp;= g_{11}dq_{1}^{2}+g_{12}dq_{1}dq_{2}+g_{13}dq_{1}dq_{3} \\\\ \u0026amp;\\quad + g_{21}dq_{2}dq_{1}+g_{22}dq_{2}^{2}+g_{23}dq_{2}dq_{3} \\\\ \u0026amp;\\quad + g_{31}dq_{3}dq_{1}+g_{32}dq_{3}dq_{2}+g_{33}dq_{3}^{2} \\\\ \u0026amp;= \\sum \\limits _{i,j=1}^{3}g_{ij}dq_{i}dq_{j} \\end{aligned} \\end{equation} $$\nNow, if we compare $(1)$ and $(3)$, the result is as follows:\n$$ g_{ij}=\\begin{cases} h_{i}^{2}, \u0026amp;i=j \\\\ 0, \u0026amp;i\\ne j \\end{cases} $$\nHere, $h_{i}=\\sqrt{g_{ii}}=\\sqrt{\\dfrac{ \\partial \\mathbf{r}}{ \\partial q_{i} }\\cdot \\dfrac{ \\partial \\mathbf{r}}{ \\partial q_{i} }}$ is referred to as the scale factor. It multiplies variables that are not in length units to convert them into length units.\nBy generalizing the coordinate space\u0026rsquo;s coordinate system to the curvilinear coordinate system, the Cartesian coordinate system can be thought of as a curvilinear coordinate system with $h_{1}=h_{2}=h_{3}=1$. The scale factors commonly used in each curvilinear coordinate system are as follows:\nProof\nPolar coordinate system:\n$$ h_{1}=1,\\quad h_{2}=r $$\nCylindrical coordinate system:\n$$ h_{1}=1, \\quad h_{2}=\\rho,\\quad h_{3}=1 $$\nSpherical coordinate system:\n$$ h_{1}=1,\\quad h_{2}=r,\\quad h_{3}=r\\sin\\theta $$\n","id":1774,"permalink":"https://freshrimpsushi.github.io/en/posts/1774/","tags":null,"title":"Curvilinear Coordinates in Three-Dimensional Space"},{"categories":"Ï¥àÌï®ÏàòÎ°†","contents":"Buildup Let\u0026rsquo;s recall the idea of defining the differentiation of distributions. There exists a regular distribution $T_{u}$ for $u \\in {L}_{\\mathrm{loc}}^1(\\Omega)$. If $u$ is differentiable, by applying the integration by parts, the following equation holds, and the derivative of $T_{u}$ is defined as $T_{u^{\\prime}}$, which corresponds to the derivative of $u$, $u^{\\prime}$.\n$$ \\begin{align*} T_{u}^{\\prime}(\\phi) \u0026amp;:= T_{u^{\\prime}}(\\phi) \\\\ \u0026amp;= \\int u^{\\prime}(x)\\phi (x)dx \\\\ \u0026amp;= \\left[ u(x) \\phi (x) \\right]_{-\\infty}^{\\infty} -\\int u(x)\\phi ^{\\prime} (x) dx \\\\ \u0026amp;= -\\int u(x)\\phi ^{\\prime} (x) dx \\\\ \u0026amp;= -T_{u}(\\phi^{\\prime}) \\end{align*} $$\nBut, suppose $u(x)$ is not differentiable at $\\Omega$. Nonetheless, the corresponding distribution $T_{u}$ to $u$ has the following derivative by definition.\n$$ T_{u}^{\\prime}(\\phi) = T_{u}(\\phi^{\\prime}) $$\nTherefore, if there exists $v(x)$ that satisfies the following equation, it can be treated as the derivative of $u(x)$.\n$$ -T_{u}(\\phi^{\\prime}) = -\\int u(x)\\phi ^{\\prime} (x) dx = \\int v(x)\\phi (x)dx = T_{v}(\\phi) $$\nExtending this idea to the multi-index $\\alpha$ results in the following.\n$$ (-1)^{|\\alpha|} \\int_{\\Omega} u(x){D}^{\\alpha}\\phi (x)dx = \\int_{\\Omega}v_{\\alpha}(x)\\phi (x)dx, \\quad \\forall\\ \\phi \\in \\mathcal{D}(\\Omega) $$\nDefinition1 Let‚Äôs denote by $u \\in {L}_{\\mathrm{loc}}^1(\\Omega)$. If there exists $v_{\\alpha}$ that satisfies the following equation, it is called the weak derivative or the distributional derivative of $u$.\n$$ \\begin{align*} T_{{v}_{\\alpha}} \u0026amp;= {D}^{\\alpha}T_{u} \u0026amp; \\text{in } \\mathcal{D}^{\\ast}(\\Omega) \\\\ \\int_{\\Omega}v_{\\alpha}(x)\\phi (x)dx \u0026amp;= (-1)^{|\\alpha|} \\int_{\\Omega} u(x){D}^{\\alpha}\\phi (x)dx \u0026amp; \\forall\\ \\phi \\in \\mathcal{D}(\\Omega) \\end{align*} $$\nExplanation For a simple explanation, refer to here.\nExample Let‚Äôs assume $u$ and $v$ are defined as follows in the interval $(-1, 1)$.\n$$ u(x) = |x| \\quad \\text{and} \\quad v(x) = \\begin{cases} 1 \u0026amp; 0 \\lt x \\lt 1 \\\\ 0 \u0026amp; x=0 \\\\ -1 \u0026amp; -1 \\lt x \\lt 0 \\end{cases} $$ Then, since $u$ is not differentiable at $x=0$, the derivative cannot be defined at $(-1,1)$, but $v$ becomes the weak derivative of $u$. It can be verified through the following process that $v$ is the weak derivative of $u$. Let\u0026rsquo;s denote by $\\phi \\in \\mathcal{D}(\\Omega)$. Then, the following equation holds.\n$$ \\begin{align*} -\\int_{-1}^1 u(x) \\phi^{\\prime}(x)dx \u0026amp;= -\\int_{-1}^{0} |x| \\phi^{\\prime}(x) dx -\\int_{0}^{1} |x| \\phi^{\\prime}(x) dx \\\\ \u0026amp;= -\\int_{-1}^{0} -x \\phi^{\\prime}(x) dx -\\int_{0}^{1} x \\phi^{\\prime}(x) dx \\\\ \u0026amp;= -\\left( [-x\\phi (x)]_{-1}^{0} +\\int_{-1}^{0}\\phi (x)dx \\right) - \\left( [x\\phi (x)]_{0}^1-\\int_{0}^1 \\phi (x)dx \\right) \\\\ \u0026amp;= \\int_{-1}^{0} -1 \\cdot \\phi (x) dx + \\int_{0}^{1}\\ 1 \\cdot \\phi (x) dx \\\\ \u0026amp;= \\int_{-1}^1v(x)\\phi (x) dx \\end{align*} $$\nIn fact, the value of $v(x)$ is equal to $u^{\\prime}(x)$ at places where $x \\ne 0$, and in $x=0$, it takes the midpoint of the left and right derivatives of $u(x)$. Therefore, it can be seen that there is no problem treating $v(x)$ as the derivative of $u(x)$.\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p22\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1085,"permalink":"https://freshrimpsushi.github.io/en/posts/1085/","tags":null,"title":"Derivative Approximation"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Definition Let\u0026rsquo;s call $(X, \\left\\| \\cdot \\right\\|)$ as a normed space. For a sequence $\\left\\{ x_{n} \\right\\}$ of $X$,\n$$ \\lim \\limits_{n \\to \\infty} \\left\\| x - x_{n} \\right\\| = 0,\\quad x\\in X $$\nit is said to converge to $x$ if it satisfies the following condition, and it is represented as follows.\n$$ x_{n} \\to x \\text { as } n \\to \\infty \\quad \\text{or} \\quad x=\\lim \\limits_{n\\to\\infty}x_{n} $$\nExplanation To define convergence, a distance is needed, but since distance can be naturally defined as $d(x,y)=\\left\\| x - y \\right\\|$ in normed spaces (../1840), it\u0026rsquo;s similar to the definition in metric spaces except that the metric is replaced with a norm.\nIf for every $\\epsilon \u0026gt;0$, there exists a natural number $N\\in \\mathbb{N}$ satisfying the equation below, then the sequence $\\left\\{ x_{n} \\right\\}$ is said to converge to $x$.\n$$ \\left\\| x - x_{n} \\right\\|\u0026lt;\\epsilon \\quad \\forall n \\ge N $$\nCompared to weak convergence, it is also referred to as strongly converging.\n$$ \\begin{align*} \u0026amp; x_{n} \\text{ converges to } x \\\\ =\u0026amp;\\ x_{n} \\text{ converges in norm to } x \\\\ =\u0026amp;\\ x_{n} \\text{ converges strongly to } x \\end{align*} $$\n","id":1800,"permalink":"https://freshrimpsushi.github.io/en/posts/1800/","tags":null,"title":"Convergence of Sequences in Normed Spaces"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition Let\u0026rsquo;s assume that a multivariable function $f : \\mathbb{R}^{n} \\to \\mathbb{R}$ is given. The change of $f(\\mathbf{x})$ according to the change of variable $\\mathbf{x} = (x_{1}, x_{2}, \\dots, x_{n})$ is denoted as $df$, and this is called the total differential or exact differential of $f$.\n$$ \\begin{equation} df = \\frac{ \\partial f}{ \\partial x_{1} }dx_{1} + \\frac{ \\partial f}{ \\partial x_{2} }dx_{2} + \\cdots + \\frac{ \\partial f}{ \\partial x_{n} }dx_{n} \\label{1} \\end{equation} $$\nExplanation The above definition means that the change in value of $f$ according to the change in variable $\\mathbf{x}$ is\naccumulated by multiplying each component's change $dx_{i}$ with the rate of change of $f$ due to each component's change $\\dfrac{\\partial f}{\\partial x_{i}}$, resulting in $\\dfrac{ \\partial f}{ \\partial x_{i} }dx_{i}$. This notation is intuitive and convenient, as can be seen in the following equation. When we say $f=f(x,y,z)$,\n$$ \\dfrac{df}{dx} = \\frac{ \\partial f}{ \\partial x}\\dfrac{dx}{dx} + \\frac{ \\partial f}{ \\partial y}\\dfrac{dy}{dx} + \\frac{ \\partial f}{ \\partial z}\\dfrac{dz}{dx} = \\dfrac{\\partial f}{\\partial x} $$\nIn physics, it often appears in the following form. Regarding $\\left( x(t), y(t), z(t) \\right)$,\n$$ \\dfrac{d f}{d t} = \\frac{ \\partial f}{ \\partial x}\\dfrac{dx}{dt} + \\frac{ \\partial f}{ \\partial y}\\dfrac{dy}{dt} + \\frac{ \\partial f}{ \\partial z}\\dfrac{dz}{dt} $$\nDerivation For a function of two variables, $\\eqref{1}$ can be derived as follows. Let\u0026rsquo;s assume $z=f(x,y)$ is given. The total differential of $z$ is the change in $z$ when variables $x$, $y$ change, so it can be represented as follows.\n$$ dz = f(x+dx,y+dy)-f(x,y) $$\nHere, by subtracting and adding $f(x,y+dy)$ on the right side, and then arranging the equation, it looks like the following. $$ \\begin{align*} dz \u0026amp;= f(x+dx,y+dy) {\\color{blue}-f(x,y+dy)+f(x,y+dy)}-f(x,y) \\\\ \u0026amp;= [f(x+dx,y+dy) -f(x,y+dy)]+[f(x,y+dy)-f(x,y)] \\\\ \u0026amp;= \\frac{f(x+dx,y+dy) -f(x,y+dy)}{dx}dx+\\frac{f(x,y+dy)-f(x,y)}{dy}dy \\\\ \u0026amp;\\approx \\frac{ \\partial f}{ \\partial x}dx + \\frac{ \\partial f}{ \\partial y }dy \\\\ \u0026amp;= \\frac{ \\partial z}{ \\partial x}dx+\\frac{ \\partial z}{ \\partial y}dy \\end{align*} $$\n‚ñ†\n","id":1773,"permalink":"https://freshrimpsushi.github.io/en/posts/1773/","tags":null,"title":"Total Differentiation, Exact Differentiation"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition The continuous probability distribution with the following probability density function is called a Cauchy distribution. $C$ $$ f(x) = {1 \\over \\pi} {1 \\over {x^2 + 1}} \\qquad , x \\in \\mathbb{R} $$\nExplanation It may seem like all probability distributions would have a mean and variance, but in reality, that\u0026rsquo;s not always the case. A prime example of this is the Cauchy distribution, which at a glance resembles the normal distribution but has thicker tails on both sides. Regardless of the parameters, since there is no moment-generating function, it means that everything involving moments‚Äîincluding the population mean and variance‚Äîcannot exist.\nOf course, whether or not there\u0026rsquo;s a population mean, a sample mean can still be calculated. In fact, for a Cauchy distribution translated by $\\theta$ along the $x$ axis, the mle of $\\theta$ $\\hat{\\theta}$ appears as the sample mean.\nMeanwhile, the probability density function of the t-distribution is: $$ g(y) = {{\\Gamma ( (n+1)/2 ) } \\over { \\sqrt{\\pi n} \\Gamma (n/2) }} { {1} \\over {(1 + y^{2} / n)^{(n+1)/2} } } $$ Thus, the Cauchy distribution can be seen as a t-distribution with degrees of freedom $n=1$.\nSummary The moment-generating function of the Cauchy distribution does not exist.\nProof1 The probability distribution function of the Cauchy distribution is given by $\\displaystyle f(x) = {1 \\over \\pi} {1 \\over {x^2 + 1}}, -\\infty \u0026lt; x \u0026lt; \\infty$. To show that the moment-generating function $\\displaystyle E(e^{tx}) = \\int_{-\\infty}^{\\infty} e^{tx} {1 \\over \\pi} {1 \\over {x^2 + 1}} dx$ diverges, consider when $t\u0026gt;0$ then, by the Mean Value Theorem, $$ {{e^{tx} - e^0} \\over {tx - 0}} = { { e^{tx} - 1 } \\over {tx} } = e^{\\xi} \\ge e^0 = 1 $$ there exists a $0\u0026lt; \\xi \u0026lt; tx$ that satisfies the above equation. A little rearrangement of the equation yields the following inequality: $$ e^{tx} \\ge 1 + tx \\ge tx $$ Returning to the integral: $$ \\begin{align*} E(e^{tx}) \\ge\u0026amp; \\int_{-\\infty}^{\\infty} e^{tx} {1 \\over \\pi} {1 \\over {x^2 + 1}} dx \\\\ \\ge\u0026amp; \\int_{0}^{\\infty} e^{tx} {1 \\over \\pi} {1 \\over {x^2 + 1}} dx \\\\ \\ge\u0026amp; \\int_{0}^{\\infty} {1 \\over \\pi} {tx \\over {x^2 + 1}} dx \\\\ =\u0026amp; { t \\over {2 \\pi} } \\left[ \\ln (x^2+1) \\right]_{0}^{\\infty} \\\\ =\u0026amp; \\infty \\end{align*} $$ Therefore, the moment-generating function of the Cauchy distribution does not exist.\n‚ñ†\nCode The following is Julia code that displays the probability density functions of the Cauchy distribution, the t-distribution, and the Cauchy distribution.\n@time using LaTeXStrings\r@time using Distributions\r@time using Plots\rcd(@__DIR__)\rx = -4:0.1:4\rplot(x, pdf.(Cauchy(), x),\rcolor = :red,\rlabel = \u0026#34;Cauchy\u0026#34;, size = (400,300))\rplot!(x, pdf.(TDist(3), x),\rcolor = :orange,\rlabel = \u0026#34;t(3)\u0026#34;, size = (400,300))\rplot!(x, pdf.(TDist(30), x),\rcolor = :black, linestyle = :dash,\rlabel = \u0026#34;t(30)\u0026#34;, size = (400,300))\rplot!(x, pdf.(Normal(), x),\rcolor = :black,\rlabel = \u0026#34;Standard Normal\u0026#34;, size = (400,300))\rxlims!(-4,5); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pdf\\,of\\, t}(\\nu)\u0026#34;)\rpng(\u0026#34;pdf\u0026#34;) Hogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p63.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":147,"permalink":"https://freshrimpsushi.github.io/en/posts/147/","tags":null,"title":"Cauchy Distribution: A Distribution Without a Mean"},{"categories":"Ï¥àÌï®ÏàòÎ°†","contents":"Buildup The distribution cannot be differentiated in the same manner as functions defined over real numbers since its domain is a function space. However, for regular distributions, there is a corresponding locally integrable function $u\\in L_{\\mathrm{loc}}^{1}$, expressed as follows.\n$$ T_{u}(\\phi) =\\int u(x)\\phi (x) dx,\\quad \\phi \\in \\mathcal{D} $$\nHence, the action $S$ on $u$ could yield $Su=u^{\\prime}$; if $u^{\\prime}$ remains a locally integrable function, then there exists a corresponding distribution $T_{u^{\\prime}}$. Therefore, the idea is to think of the action $S$ on $u$ as if it were the action on $T_{u}$. This idea is extended over all distributions to define the differentiation of distributions.\nBelow, we assume $u\\in C^{\\infty}$, although it\u0026rsquo;s not strictly necessary. You could also simply discuss up to the $n$th derivative with $u \\in C^{n}$.\nLet\u0026rsquo;s say a smooth function $u\\in C^{\\infty}$ is given. The test function $\\phi$ has a compact support, so it\u0026rsquo;s harmless to assume that $u$ is defined over some compact set $K$ that contains the support of the test function. Since smooth functions on a compact set are locally integrable, we can consider the corresponding regular distribution $T_{u}$ for $u$.\nMeanwhile, $u$, being a smooth function, is differentiable, and $u^{\\prime}$, being locally integrable, has a corresponding regular distribution $T_{u^{\\prime}}$. Thus, by applying the integration by parts to the test function $\\phi \\in \\mathcal{D}$, it can be represented as follows.\n$$ \\begin{align*} T_{u^{\\prime}}(\\phi) \u0026amp;= \\int u^{\\prime}(x)\\phi (x)dx \\\\ \u0026amp;= \\left[ u(x) \\phi (x) \\right]_{-\\infty}^{\\infty} -\\int u(x)\\phi ^{\\prime} (x) dx \\end{align*} $$\nHere, since $\\phi$ has compact support, the first term is $0$. Hence, we obtain the following.\n$$ T_{u^{\\prime}}(\\phi)=-\\int u(x)\\phi ^{\\prime} (x) dx=-T_{u}(\\phi^{\\prime}) $$\nDefinition1 The derivative of the distribution $T$ is defined as follows.\n$$ (DT)(\\phi):= -T(D\\phi) $$\nHere, $D$ is the differentiation operator. For the multi-index $\\alpha$, it is as follows.\n$$ (D^{\\alpha}T)(\\phi):= \\left| -1 \\right|^{\\left| \\alpha \\right| } T(D^{\\alpha}\\phi) $$\nSince the derivative of a test function is also a test function, there is no problem with the domain, and apart from that aspect, it is simply multiplied by the constant term $\\left| -1 \\right|^{\\left| \\alpha \\right|}$, thus $D^{\\alpha}T$ is also a distribution. Of course, this can be proved using the definition of distributions, but it is not strictly necessary.\nGerald B. Folland, Fourier Analysis and Its Applications (1992), p308-309\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1084,"permalink":"https://freshrimpsushi.github.io/en/posts/1084/","tags":null,"title":"Differentiation of Distributions"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition For a vector function $\\mathbf{F}(x,y,z)=F_{x}\\hat{\\mathbf{x}}+F_{y}\\hat{\\mathbf{y}} + F_{z}\\hat{\\mathbf{z}}$, the following scalar function is defined as the divergence $\\mathbf{F}$ of $\\mathbf{F}(x,y,z)=F_{x}\\hat{\\mathbf{x}}+F_{y}\\hat{\\mathbf{y}} + F_{z}\\hat{\\mathbf{z}}$ and is denoted by $\\nabla \\cdot \\mathbf{F}$.\n$$ \\begin{equation} \\nabla \\cdot \\mathbf{F} := \\frac{ \\partial F_{x}}{ \\partial x} + \\frac{ \\partial F_{y}}{ \\partial y }+ \\frac{ \\partial F_{z}}{ \\partial z} \\label{divergence} \\end{equation} $$\nExplanation Geometrically, if $\\nabla \\cdot \\mathbf{F}\u0026gt;0$, it means that $\\mathbf{F}$ is spreading out or diverging. If $\\nabla \\cdot \\mathbf{F}\u0026lt;0$, it means that $\\mathbf{F}$ is converging or moving inward. If $\\nabla \\cdot \\mathbf{F}=0$, it means that $\\mathbf{F}$ is neither diverging nor converging, indicating an equilibrium where the amount going out equals the amount coming in.\nDivergence is translated as \u0026ldquo;divergence\u0026rdquo;. To maintain consistency with using gradient for slope and curl for rotation, it is denoted as divergence instead of using the literal translation.\nIt is important to note that the value defined as $\\dfrac{ \\partial F_{x}}{ \\partial x} + \\dfrac{ \\partial F_{y}}{ \\partial y }+ \\dfrac{ \\partial F_{z}}{ \\partial z}$ is denoted by $\\nabla \\cdot \\mathbf{F}$. While $\\nabla$ is referred to as the del operator, considering it as inherently meaningful can lead to confusion with $\\nabla \\cdot \\mathbf{F}$ or $\\nabla \\times \\mathbf{F}$ being mistaken for dot and cross products. Therefore, $\\nabla$ should be understood merely as a convenient notation, and it might be better to think of the del operator as equivalent to gradient. The details continue below.\nImportant Points $\\nabla \\cdot \\mathbf{F}$ is not the dot product of $\\nabla$ and $\\mathbf{F}$ $\\nabla \\cdot \\mathbf{F}$ is absolutely not the dot product of $\\nabla$ and $\\mathbf{F}$.\rA dot product is fundamentally an operation between two vectors. Thinking of $\\nabla \\cdot \\mathbf{F}$ as a dot product implies considering $\\nabla$ as a vector.\n$$ \\nabla \\overset{?}{=}\\dfrac{ \\partial }{ \\partial x}\\hat{\\mathbf{x}} +\\dfrac{ \\partial }{ \\partial y}\\hat{\\mathbf{y}}+\\dfrac{ \\partial }{ \\partial z}\\hat{\\mathbf{z}} = \\left( \\dfrac{ \\partial }{ \\partial x},\\ \\dfrac{ \\partial }{ \\partial y},\\ \\dfrac{ \\partial }{ \\partial z} \\right) $$\nIndeed, thinking in this way conveniently matches the definition of divergence $(1)$.\n$$ \\nabla \\cdot \\mathbf{F} = \\left( \\dfrac{ \\partial }{ \\partial x},\\ \\dfrac{ \\partial }{ \\partial y},\\ \\dfrac{ \\partial }{ \\partial z} \\right) \\cdot \\left( F_{x}, F_{y}, F_{z} \\right) = \\frac{ \\partial F_{x}}{ \\partial x} + \\frac{ \\partial F_{y}}{ \\partial y }+ \\frac{ \\partial F_{z}}{ \\partial z} $$\nHowever, if this were truly a dot product, the commutative property would imply an odd conclusion as follows:\n$$ \\mathbf{F} \\cdot \\nabla = F_{x} \\dfrac{\\partial }{\\partial x} + F_{y} \\dfrac{\\partial }{\\partial y} + F_{z} \\dfrac{\\partial }{\\partial z} \\overset{?}{=} \\frac{ \\partial F_{x}}{ \\partial x} + \\frac{ \\partial F_{y}}{ \\partial y }+ \\frac{ \\partial F_{z}}{ \\partial z} = \\nabla \\cdot \\mathbf{F} $$\nIn reality, $\\nabla \\cdot$ represents an operator that maps a vector function $\\mathbf{F}(x,y,z)$ to a scalar function $\\frac{ \\partial F_{x}(x,y,z)}{ \\partial x} + \\frac{ \\partial F_{y}(x,y,z)}{ \\partial y }+ \\frac{ \\partial F_{z}(x,y,z)}{ \\partial z}$. This means that $\\operatorname{div}$, when defined as follows, simply yields $\\dfrac{ \\partial F_{x}}{ \\partial x} + \\dfrac{ \\partial F_{y}}{ \\partial y }+ \\dfrac{ \\partial F_{z}}{ \\partial z}$ for every substitution of $\\mathbf{F}$. This intuitive understanding explains why $\\operatorname{div}(\\mathbf{F})$ is denoted as $\\nabla \\cdot \\mathbf{F}$ instead of a direct interpretation. In advanced mathematics, divergence is often denoted differently, reflecting a less intuitive handling of 3D vectors than in physics.\nThen, why can\u0026rsquo;t $\\nabla \\cdot \\mathbf{F}$ be considered a non-commutative dot product? It\u0026rsquo;s because in $\\nabla \\cdot \\mathbf{F}$, $\\nabla \\cdot$ itself is a function (operator), and $\\mathbf{F}$ is a variable. In contrast, $\\mathbf{F} \\cdot \\nabla$ is an operator by itself. Therefore, $\\nabla \\cdot \\mathbf{F}$ represents the function value of $\\nabla \\cdot$, while $\\mathbf{F} \\cdot \\nabla$ is a function awaiting variable substitution. The notation $\\mathbf{F} \\cdot \\nabla$ intuitively represents function $f$. $f$ is an operator that takes the vector function $\\mathbf{A}$ as a variable and applies $\\left( F_{x}\\dfrac{\\partial }{\\partial x} + F_{y}\\dfrac{\\partial }{\\partial y} + F_{z}\\dfrac{\\partial }{\\partial z} \\right)$ to each component.\n$$ \\begin{align*} f (\\mathbf{A}) \\overset{\\text{definition}}{=}\u0026amp; \\left( F_{x}\\dfrac{\\partial A_{x}}{\\partial x} + F_{y}\\dfrac{\\partial A_{x}}{\\partial y} + F_{z}\\dfrac{\\partial A_{x}}{\\partial z} \\right)\\hat{\\mathbf{x}} \\\\ \u0026amp;\\quad+ \\left( F_{x}\\dfrac{\\partial A_{y}}{\\partial x} + F_{y}\\dfrac{\\partial A_{y}}{\\partial y} + F_{z}\\dfrac{\\partial A_{y}}{\\partial z} \\right)\\hat{\\mathbf{y}} \\\\ \u0026amp;\\quad+ \\left( F_{x}\\dfrac{\\partial A_{z}}{\\partial x} + F_{y}\\dfrac{\\partial A_{z}}{\\partial y} + F_{z}\\dfrac{\\partial A_{z}}{\\partial z} \\right)\\hat{\\mathbf{z}} \\\\ \\overset{\\text{notation}}{=}\u0026amp; (\\mathbf{F}\\cdot \\nabla) (\\mathbf{A}) \\end{align*} $$\nWhen a scalar function $\\phi$ exists as a variable, it is considered as follows:\n$$ \\begin{align*} f (\\phi) \\overset{\\text{definition}}{=}\u0026amp; F_{x}\\dfrac{\\partial \\phi}{\\partial x} + F_{y}\\dfrac{\\partial \\phi}{\\partial y} + F_{z}\\dfrac{\\partial \\phi}{\\partial z} \\\\ \\overset{\\text{notation}}{=}\u0026amp; (\\mathbf{F}\\cdot \\nabla) (\\phi) \\end{align*} $$\nThus, $\\nabla \\cdot \\mathbf{F}$ and $\\mathbf{F}\\cdot \\nabla$ should not be understood as the dot product of $\\nabla$ and $\\mathbf{F}$, but as functions in themselves. This explanation applies not only to divergence but also to gradient $\\nabla f$ and curl $\\nabla \\times \\mathbf{F}$.\nDerivation First, consider a small volume in 3D space as shown below.\nOur goal is to understand how $\\mathbf{F}$ appears at each point within this small volume. Analogously, if $\\mathbf{F}$ represents heat, we aim to determine the direction and speed of flow, or if $\\mathbf{F}$ represents water, whether it is entering or exiting through a tap or drain. Let\u0026rsquo;s calculate for the $x$ axis direction first. The amount of $\\mathbf{F}$ passing through $d\\mathbf{a}_{1}$ can be calculated by the dot product.\n$$ \\begin{align} \\mathbf{F}(x+dx) \\cdot d\\mathbf{a}_{1} \u0026amp;= \\left( F_{x}(x+dx)\\hat{\\mathbf{x}}+F_{y}(x+dx)\\hat{\\mathbf{y}}+F_{z}(x+dx)\\hat{\\mathbf{z}} \\right) \\cdot dydz\\hat{\\mathbf{x}} \\nonumber \\\\ \u0026amp;= F_{x}(x+dx)dydz \\end{align} $$\nIf $F_{x}(x+dx)dydz \u0026gt;0$, it indicates the amount of $\\mathbf{F}$ exiting the small volume, and if $F_{x}(x+dx)dydz\u0026lt;0$, the amount entering. Similarly, the amount of $\\mathbf{F}$ exiting through $d\\mathbf{a}_{2}$ is as follows.\n$$ \\begin{equation} \\mathbf{F}(x) \\cdot d \\mathbf{a}_{2} = F_{x}(x)\\hat{\\mathbf{x}} \\cdot(-dydz\\hat{\\mathbf{x}})=-F_{x}(x)dydz \\end{equation} $$\nTherefore, $(2) + (3)$ represents the net flux of $\\mathbf{F}$ in the $x$ direction.\n$$ \\begin{align*} (2) + (3) \u0026amp;=\\left[ F_{x}(x+dx) -F_{x}(x)\\right]dydz \\\\ \u0026amp;= \\frac{F_{x}(x+dx) -F_{x}(x) }{dx}dxdydz \\end{align*} $$\nSince $dx$ is a small length, it can be approximated as follows. Thus, the amount of $\\mathbf{F}$ entering or exiting the small volume in the $x$ direction is expressed as:\n$$ \\frac{ \\partial F_{x}}{ \\partial x}dxdydz $$ Calculating similarly for the $y$ and $z$ directions yields:\n$$ \\frac{ \\partial F_{y}}{ \\partial y}dxdydz \\quad \\text{and} \\quad \\frac{ \\partial F_{z}}{ \\partial z}dxdydz $$\nSumming these gives the total flux of $\\mathbf{F}$ entering or exiting the small volume, and dividing by $dxdydz$ gives the flux per unit volume.\n$$ \\frac{ \\partial F_{x}}{ \\partial x}+\\frac{ \\partial F_{y}}{ \\partial y}+\\frac{ \\partial F_{z}}{ \\partial z} $$\nFrom now on, this will be referred to as the divergence of $\\mathbf{F}$ and denoted by $\\nabla \\cdot \\mathbf{F}$.\n$$ \\nabla \\cdot \\mathbf{F} := \\frac{ \\partial F_{x}}{ \\partial x}+\\frac{ \\partial F_{y}}{ \\partial y}+\\frac{ \\partial F_{z}}{ \\partial z} $$\n‚ñ†\nAs derived, it\u0026rsquo;s important to remember that $\\nabla \\cdot \\mathbf{F}$ is not the dot product of $\\nabla$ and $\\mathbf{F}$.\nRelated Formulas Linearity:\nProduct Rule:\n$$ \\nabla \\cdot (f\\mathbf{A}) = f(\\nabla \\cdot \\mathbf{A}) + \\mathbf{A} \\cdot (\\nabla f) $$ $$ \\nabla \\cdot (\\mathbf{A} \\times \\mathbf{B}) = \\mathbf{B} \\cdot (\\nabla \\times \\mathbf{A}) - \\mathbf{A} \\cdot (\\nabla \\times \\mathbf{B}) $$\nSecond Derivative:\n$$ \\nabla \\cdot (\\nabla T) = \\dfrac{\\partial^{2} T}{\\partial x^{2}} + \\dfrac{\\partial ^{2} T} {\\partial y^{2}} + \\dfrac{\\partial ^{2} T}{\\partial z^{2}} $$ $$ \\nabla (\\nabla \\cdot \\mathbf{A} ) $$ $$ \\nabla \\cdot (\\nabla \\times \\mathbf{A})=0 $$\nGauss\u0026rsquo;s Theorem (Divergence Theorem)\n$$ \\int_\\mathcal{V} \\nabla \\cdot \\mathbf{ F} dV = \\oint _\\mathcal{S} \\mathbf{F} \\cdot d \\mathbf{S} $$\nIntegration Formulas\n$$ \\int_{\\mathcal{V}} \\left[ T \\nabla^{2} U + (\\nabla T) \\cdot (\\nabla U) \\right] d \\tau = \\oint_{\\mathcal{S}} (T \\nabla U) \\cdot d \\mathbf{a} $$ $$ \\int_{\\mathcal{V}} \\left( T \\nabla^{2} U - U \\nabla^{2} T \\right) d \\tau = \\oint_{\\mathcal{S}} \\left( T \\nabla U - U \\nabla T \\right) \\cdot d \\mathbf{a} $$\nPartial Integration\n$$ \\int_{\\mathcal{V}}\\mathbf{A} \\cdot (\\nabla f)d\\tau = \\oint_{\\mathcal{S}}f\\mathbf{A} \\cdot d \\mathbf{a}-\\int_{\\mathcal{V}}f(\\nabla \\cdot \\mathbf{A})d\\tau $$\nSee Also Del Operator $\\nabla$ ","id":1796,"permalink":"https://freshrimpsushi.github.io/en/posts/1796/","tags":null,"title":"Divergence of Vector Function in Cartesian Cooridenates System"},{"categories":"Ìï®Ïàò","contents":"Definition For $A \\subset X$, the function defined as $\\chi_{A} : X \\to \\mathbb{R}$ is referred to as the characteristic function or the indicator function.\n$$ \\chi _{A}(x) := \\begin{cases} 1, \u0026amp; x\\in A \\\\ 0 ,\u0026amp; x \\notin A \\end{cases} $$\nExplanation $\\chi$ is the Greek letter chi. The reason our math teacher used to say you should not write the letter x as $\\chi$ but should instead use $x$ is precisely because $\\chi$ is not x. Especially since it has such a strong meaning, it should not be used carelessly.\nIn the mathematics department, it is almost never called a characteristic function in practice, but rather read directly as [characteristic function]. It is frequently used for changing the integration range in equations involving definite integrals, for example, as follows. $$ \\int _{a} ^{b}f(x)g(x) dx=\\int _{-\\infty}^{\\infty}\\chi_{[a,b]}f(x)g(x)dx $$\nDepending on the subject, it is also sometimes represented by the bold 1. There isn‚Äôt really a consensus on which is used more, but $\\chi$ tends to have its own meaning in various fields while $\\mathbf{1}$ is generally used specifically for indicator functions. Therefore, in papers rather than books, $\\mathbf{1}$ seems to be used more often than $\\chi$. $$ \\mathbf{1}_{A} = \\chi _{A}(x) $$\n","id":1790,"permalink":"https://freshrimpsushi.github.io/en/posts/1790/","tags":null,"title":"Characteristic Function, Indicator Function"},{"categories":"Ï¥àÌï®ÏàòÎ°†","contents":"In the test function space, \u0026lsquo;convergence\u0026rsquo; is defined in a special way. Normally, when a space $X$ is given, convergence is defined using the norm or distance defined in $X$. However, in the test function space, convergence is defined under stronger conditions to properly define and handle distributions.\nDefinition Let $\\Omega \\subset \\mathbb{R}^n$ be an open set, and $\\left\\{ \\phi _{j} \\right\\}$ be a sequence of test functions. We say that $\\left\\{ \\phi_{j} \\right\\}$ converges to $0$ in the sense of $\\mathcal{D}(\\Omega)$ if the following two conditions are satisfied, denoted as:\n$$ \\phi_{j} \\overset{\\mathcal{D}}{\\to} 0 $$\n(a) There exists a $K \\Subset \\Omega$ that satisfies $\\mathrm{supp} (\\phi_{j}) \\subset K\\quad \\forall\\ j$.\n(b) For each multi-index $\\alpha$, $D^{\\alpha}\\phi_{j}$ converges uniformly to $0$.\n$$ D^{\\alpha}\\phi_{j} \\rightrightarrows 0 $$\nHere, $\\mathrm{supp}$ refers to the support.\nExplanation The terminology may vary slightly depending on the author, but the term itself is not important.\nConverges in the sense of the space $\\mathcal{D}$: converge in the sense of the space $\\mathcal{D}$1\nConverges in $\\mathcal{D}$: converge in $\\mathcal{D}$2\nOf course, if there\u0026rsquo;s no confusion in the context of a specific textbook or lecture, it can be simply denoted as $\\phi_{j} \\to 0$. According to definition (b), if it converges in $\\mathcal{D}$, it also satisfies the usual meaning of convergence. The above definition can be generally written for all $\\phi$ as follows, not just for $0$.\nLet $\\Omega \\subset \\mathbb{R}^n$ be an open set, and $\\left\\{ \\phi _{j} \\right\\}$ be a sequence of test functions. We say that $\\left\\{ \\phi_{j} \\right\\}$ converges to $\\phi$ in the sense of $\\mathcal{D}(\\Omega)$ if the following two conditions are satisfied, denoted as $\\phi_{j} \\to \\phi \\text{ in } D(\\Omega)$:\n(a) There exists a $K \\Subset \\Omega$ that satisfies $\\mathrm{supp} (\\phi_{j}-\\phi) \\subset K\\quad \\forall\\ j$.\n(b) For each multi-index $\\alpha$, $D^{\\alpha}\\phi_{j}$ converges uniformly to $D^{\\alpha} \\phi$. $$ D^{\\alpha}\\phi_{j} \\rightrightarrows D^{\\alpha}\\phi $$\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p19-20\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDaniel Eceizabarrena perez, Distribution Theory and Fundamental Solutions of Differential Operators (2015), p3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1077,"permalink":"https://freshrimpsushi.github.io/en/posts/1077/","tags":null,"title":"Convergence in the Space of Test Functions"},{"categories":"Ï¥àÌï®ÏàòÎ°†","contents":"Definition1 2 Let $\\Omega \\subset \\mathbb{R}^{n}$ be an open set. A continuous linear functional $T : \\mathcal{D}(\\Omega) \\to \\mathbb{C}$ on the space of test functions is defined as a distribution. That is, a distribution is an element of the dual space of the test function space. Thus\n$$ T \\in \\mathcal{D}^{\\ast} $$\nand we call $D^{\\ast}$ the (Schwartz) distribution space.\nExplanation The name distribution seems to be influenced by the Dirac delta function being designed to represent point masses like mass concentrated at a single point. While it directly translates to distribution, mathematicians call it a distribution. The other name, generalized function, was given because it rigorously defines concepts like the Dirac delta function, which strictly speaking are not functions. An important part in the definition of distributions is the continuity. According to the equivalence conditions for a function to be continuous, the continuity of a distribution $T$ means the following.\n$$ \\phi_{j} \\to \\phi \\implies T(\\phi_{j}) \\to T(\\phi) $$\nHowever, convergence in the space of test functions is defined a bit specially. So, if we restate the definition of a distribution specifically, it goes as follows.\nA functional $T : \\mathcal{D}(\\Omega) \\to \\mathbb{C}$ on the space of test functions $\\mathcal{D}(\\Omega)$ is a distribution if it is linear and continuous.\n(a) $T(a\\phi + b \\psi ) = aT(\\phi)+bT(\\psi)\\quad (\\phi,\\psi\\in \\mathcal{D},\\ a,b\\in\\mathbb{C})$\n(b) $\\phi_{j} \\to \\phi \\text{ in } \\mathcal{D} \\implies T(\\phi_{j}) \\to T(\\phi)$\nUnder the condition that the following are satisfied for a sequence of functions $\\left\\{ \\phi_{j} \\right\\}$ in $\\mathcal{D}(\\Omega)$, we define $\\phi_{j} \\to \\phi \\text{ in } \\mathcal{D}$.\n(c) There exists $K \\Subset \\Omega$ that satisfies $\\mathrm{supp} (\\phi_{j}-\\phi) \\subset K\\quad \\forall\\ j$.\n(d) For each multi-index $\\alpha$, $D^{\\alpha}\\phi_{j}$ uniformly converges to $D^{\\alpha} \\phi$.\nFollowing the definition of a distribution, the Dirac delta function can be defined as follows.\n$$ \\begin{align*} \\delta_{a} : \\mathcal{D} \u0026amp;\\to \\mathbb{C} \\\\ \\phi \u0026amp;\\mapsto \\phi (a) \\end{align*} $$\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p19-20\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGerald B. Folland, Fourier Analysis and Its Applications (1992), p306-307\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1009,"permalink":"https://freshrimpsushi.github.io/en/posts/1009/","tags":null,"title":"Distributions, Generalized Functions"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Definition Let $\\Omega \\subset \\mathbb{R}^{n}$ be called an open set.\nDefinition 11 For every bounded measurable set $K \\subset \\Omega$,\n$$ \\int_{K} \\left| u(x) \\right| dx \\lt \\infty $$\na function $u : \\Omega \\to \\mathbb{C}$ satisfying this is said to be locally integrable with respect to (the Lebesgue measure).\nDefinition 22 Let the function $u$ be defined almost everywhere on $\\Omega$. For every open set $U \\Subset \\Omega$ when $u \\in L^{1}(U)$, then $u$ is said to be locally integrable on $\\Omega$.\nNotation The set of locally integrable functions is denoted as follows.\n$$ L_{\\text{loc}}^{1}(\\Omega) := \\left\\{ u : \\Omega \\to \\mathbb{C} \\Big| u \\text{ is locally integrable.}\\right\\} $$\nExplanation By the definition, the following inclusion relationships are trivially established.\n$$ \\href{../592}{L^{1}(\\Omega)} \\subset L_{\\text{loc}}^{1}(\\Omega) $$\n$$ \\href{../1594}{C(\\Omega)} \\subset L_{\\text{loc}}^{1}(\\Omega) $$\nProperties Locally integrable functions can be extended to distributions. Gerald B. Folland, Real Analysis: Modern Techniques and Their Applications (2nd Edition, 1999), p95\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p20\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1783,"permalink":"https://freshrimpsushi.github.io/en/posts/1783/","tags":null,"title":"Locally Integrable Function"},{"categories":"Ï¥àÌï®ÏàòÎ°†","contents":"Theorem1 For every $u \\in L_{\\mathrm{loc} }^1(\\Omega) $, there exists a distribution $T_{u} \\in D^{\\ast}(\\Omega)$ defined as follows:\n$$ T_{u} (\\phi) := \\int_{\\Omega} u(x)\\phi (x)dx, \\quad \\phi \\in D(\\Omega) $$\nDescription $\\mathcal{D}(\\Omega)$ is the space of test functions. The distribution defined as above is called a regular distribution. Moreover, the above expression can be regarded as the inner product of $u$ and $\\phi$ from the viewpoint of inner product spaces, hence it can also be denoted as follows.\n$$ T_{u}(\\phi)=\\langle u , \\phi \\rangle $$\nAccording to the theorem above, locally integrable functions can be treated as if they were distributions. Calling a distribution a generalized function also stems from this rationale.\nProof To show that $T_{u}$ defined as above is a distribution, we must prove that it is a continuous and linear functional. Being linear is evident since it is defined by integration, so we just need to demonstrate continuity. Remember, continuity here means continuity with respect to the convergence in the space of test functions.\nLet\u0026rsquo;s assume $\\phi_{j} \\rightarrow \\phi\\ \\ \\mathrm{in}\\ D(\\Omega)$. Then by the definition of convergence, there exists $K \\Subset\\Omega$ as follows.\n$$ \\mathrm{supp}(\\phi_{j}-\\phi) \\subset K\\quad \\forall\\ j $$\nSince $u$ is locally integrable, the following equation holds for $M\u0026gt;0$.\n$$ \\begin{align*} \\left| T_{u}(\\phi_{j})-T_{u}(\\phi) \\right| \u0026amp;= \\left| \\int_{K} u(x)\\left( \\phi_{j}(x) -\\phi (x) \\right) dx \\right| \\\\ \u0026amp; \\le \\sup \\limits_{x\\in K} \\left| \\phi_{j} (x) - \\phi (x) \\right| \\int_{K} |u(x)|dx \\\\ \u0026amp;\\le \\sup \\limits_{x\\in K} \\left| \\phi_{j} (x) - \\phi (x) \\right|M \\end{align*} $$\nGiven the assumption that $\\phi_{j}(x) \\rightrightarrows \\phi (x)$, the following holds.\n$$ \\sup \\limits_{x\\in K} \\left| \\phi_{j} (x) - \\phi (x) \\right|M \\to 0 \\quad \\text{as } j \\rightarrow \\infty $$\nTherefore, the following is true.\n$$ T_{u}( \\phi_{j} ) \\rightarrow T_{u}(\\phi) \\quad \\text{as } j \\rightarrow \\infty $$\nThus, $T_{u}$ is continuous in $\\mathcal{D}$.\n‚ñ†\nIt would be convenient if all distributions were of the form described above, but unfortunately, that is not the case.\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p20-21\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1078,"permalink":"https://freshrimpsushi.github.io/en/posts/1078/","tags":null,"title":"Proving that All Locally Integrable Functions Can Be Extended to Distributions"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 A continuous probability distribution $t \\left( \\nu \\right)$, known as the t-distribution, is defined for degrees of freedom $\\nu \u0026gt; 0$ as having the following probability density function: $$ f(x) = {{ \\Gamma \\left( {{ \\nu + 1 } \\over { 2 }} \\right) } \\over { \\sqrt{\\nu \\pi} \\Gamma \\left( {{ \\nu } \\over { 2 }} \\right) }} \\left( 1 + {{ x^{2} } \\over { \\nu }} \\right)^{- {{ \\nu + 1 } \\over { 2 }}} \\qquad ,x \\in \\mathbb{R} $$\n$\\Gamma (\\nu)$ is the gamma function. Description The t-distribution is widely known for its discovery and publication by William S. Gosset, who worked at the Guinness brewery, still famous for its beer. At that time, being bound to the company, he submitted his work under the pseudonym Student, hence it is also called the Student\u0026rsquo;s t-distribution. For freshmen in statistics, it is initially encountered for small samples, which are assumed to follow a normal distribution but in reality do not exceed 30 samples. It is considered to converge to the normal distribution when $\\nu \\ge 30$.\nMeanwhile, the distribution when $\\nu = 1$ is called the Cauchy distribution.\nBasic Properties Moment Generating Function [1]: The moment generating function does not exist for the $t$-distribution. Mean and Variance [2]: If $X \\sim t (\\nu)$ then $$ \\begin{align*} E(X) =\u0026amp; 0 \u0026amp; \\qquad , \\nu \u0026gt;1 \\\\ \\text{Var}(X) =\u0026amp; {{ \\nu } \\over { \\nu - 2 }} \u0026amp; \\qquad , \\nu \u0026gt; 2 \\end{align*} $$ Theorem Let us assume two random variables $W,V$ are independent and $W \\sim N(0,1)$, $V \\sim \\chi^{2} (r)$.\n$k$th Moment [a]: If $k \u0026lt; r$, then $\\displaystyle T := { {W} \\over {\\sqrt{V/r} } }$ is the $k$th moment and $$ E T^{k} = E W^{k} {{ 2^{-k/2} \\Gamma \\left( {{ r } \\over { 2 }} - {{ k } \\over { 2 }} \\right) } \\over { \\Gamma \\left( {{ r } \\over { 2 }} \\right) r^{-k/2} }} $$ Derived from Standard Normal and Chi-square Distributions [b]: $${ {W} \\over {\\sqrt{V/r} } } \\sim t(r)$$ Deriving Standard Normal Distribution as the Limiting Distribution of Student\u0026rsquo;s t-Distribution [c]: If $T_n \\sim t(n)$ then $$ T_n \\ \\overset{D}{\\to} N(0,1) $$ Deriving the F-Distribution [d]: A random variable $X \\sim t(\\nu)$ following a t-distribution with degrees of freedom $\\nu \u0026gt; 0$ is defined as $Y$, and follows an F-distribution $F (1,\\nu)$. $$ Y := X^{2} \\sim F (1,\\nu) $$ $N \\left( \\mu , \\sigma^{2} \\right)$ is a normal distribution with mean $\\mu$ and variance $\\sigma^{2}$. $\\chi^{2} \\left( r \\right)$ is a chi-square distribution with degrees of freedom $r$. Proof [1] The existence of the moment generating function for a random variable implies the existence of all $k$th moments for every $k \\in \\mathbb{N}$. However, as theorem [a] states, the $k$th moment of the t-distribution exists only when $k \u0026lt; r$, thus the moment generating function cannot exist.\n‚ñ†\n[2] Using the moment formula [a].\n‚ñ†\n[a] Chi-square distribution moments: Let $X \\sim \\chi^{2} (r)$. If $k \u0026gt; - r/ 2$, then the $k$th moment exists and $$ E X^{k} = {{ 2^{k} \\Gamma (r/2 + k) } \\over { \\Gamma (r/2) }} $$\nMultiplying both sides of $k \u0026lt; r$ by $-1/2$ results in $-k/2 \u0026gt; -r/2$, hence $$ \\begin{align*} E T^{k} =\u0026amp; E \\left[ W^{k} \\left( {{ V } \\over { r }} \\right)^{-k/2} \\right] \\\\ =\u0026amp; E W^{k} E \\left( {{ V } \\over { r }} \\right)^{-k/2} \\\\ =\u0026amp; E W^{k} {{ 2^{-k/2} \\Gamma \\left( {{ r } \\over { 2 }} - {{ k } \\over { 2 }} \\right) } \\over { \\Gamma \\left( {{ r } \\over { 2 }} \\right) r^{-k/2} }} \\end{align*} $$\n‚ñ†\n[b] Derived directly from the joint density function.\n‚ñ†\n[c] Using the Stirling approximation on the probability density function.\n‚ñ†\n[d] Circumventing by the ratio of chi-square distributions.\n‚ñ†\nCode Below is Julia code displaying the probability density functions for the Cauchy distribution, t-distribution, and Cauchy distribution.\n@time using LaTeXStrings @time using Distributions @time using Plots cd(@__DIR__) x = -4:0.1:4 plot(x, pdf.(Cauchy(), x), color = :red, label = \u0026#34;Cauchy\u0026#34;, size = (400,300)) plot!(x, pdf.(TDist(3), x), color = :orange, label = \u0026#34;t(3)\u0026#34;, size = (400,300)) plot!(x, pdf.(TDist(30), x), color = :black, linestyle = :dash, label = \u0026#34;t(30)\u0026#34;, size = (400,300)) plot!(x, pdf.(Normal(), x), color = :black, label = \u0026#34;Standard Normal\u0026#34;, size = (400,300)) xlims!(-4,5); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pdf\\,of\\, t}(\\nu)\u0026#34;) png(\u0026#34;pdf\u0026#34;) Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p191.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1667,"permalink":"https://freshrimpsushi.github.io/en/posts/1667/","tags":null,"title":"t-Distribution"},{"categories":"Ï¥àÌï®ÏàòÎ°†","contents":"Definition1 Let an open set $\\Omega \\subset \\mathbb{R}^{n}$ and a function $\\phi : \\Omega \\to \\mathbb{C}$ be given. If $\\phi$ is infinitely differentiable, and all its derivatives are continuous and have a compact support, it is called a test function. The function space of test functions is denoted by $C_{c}^{\\infty}(\\Omega)$ or simply as $\\mathcal{D}(\\Omega)$.\nExplanation It is also called a test function or testing function. The reason $\\phi$ is named a test function is not that we want to deal with $\\phi$ itself, but because we intend to define some other function and study its properties using $\\phi$. Specifically, test functions are used to rigorously define functions with mathematical ambiguities such as the Dirac delta function. An example of a test function is a mollifier.\nTheorem2 If $\\phi$ is a test function, then its derivative is also a test function.\n$$ \\phi \\in \\mathcal{D}(\\Omega) \\implies \\frac{ \\partial \\phi}{ \\partial x_{i}} \\in \\mathcal{D}(\\Omega) (i=1,\\cdots,n) $$\nIn this case, $x=(x_{1},\\cdots,x_{n})\\in \\mathbb{R}^{n}$.\nProof It is trivial that $\\dfrac{ \\partial \\phi}{ \\partial x_{i}} \\in C^{\\infty}$ by the definition of the test function. Let\u0026rsquo;s assume $x_{0} \\notin \\mathrm{supp} \\phi$. Then $x_{0} \\in \\left( \\mathrm{supp} \\phi \\right)^{c}$, and since the support is a closed set, $(\\mathrm{supp} \\phi)^{c}$ is open. Therefore, there exists some neighborhood $N_{x_{0}}$ that contains $x_{0}$, according to the definition of an open set. Also, by the definition of support, $\\phi=0$ on $N_{x_{0}}$, and naturally $\\dfrac{ \\partial \\phi}{ \\partial x_{i}}=0$. This implies $x_{0} \\notin \\mathrm{supp} \\dfrac{ \\partial \\phi}{ \\partial x_{i}}$. Hence, the following holds:\n$$ \\mathrm{supp} \\frac{ \\partial \\phi}{ \\partial x_{i} } \\subset \\mathrm{supp} \\phi $$\nSince a closed subset of a compact set is compact, $\\mathrm{supp} \\dfrac{ \\partial \\phi}{ \\partial x_{i}}$ is compact.‚ñ†\nCorollary Let us assume $\\phi,\\phi_{1},\\phi_{2} \\in \\mathcal{D}(\\mathbb{R}^{n})$, $x_{0}\\in \\mathbb{R}^{n}$, $a \\in \\mathbb{R}\\setminus \\left\\{ 0 \\right\\}$, $\\psi \\in C^{\\infty}(\\mathbb{R}^{n})$. Then the following holds:\n(a) $\\phi (x-x_{0})$, $\\phi (-x)$, $\\phi (ax)\\in \\mathcal{D}(\\mathbb{R}^{n})$\n(b) $\\psi \\phi \\in \\mathcal{D}(\\mathbb{R}^{n})$\n(c) $\\phi_{1} * \\phi_{2} \\in \\mathcal{D}$\nThe proof is omitted as it is obvious.\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p19-20\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDaniel Eceizabarrena perez, Distribution Theory and Fundamental Solutions of Differential Operators (2015), p1-3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1782,"permalink":"https://freshrimpsushi.github.io/en/posts/1782/","tags":null,"title":"Test Functions and Test Function Space"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"The term \u0026ldquo;functional analysis\u0026rdquo; is indeed intriguing, especially when considering the word \u0026ldquo;functional\u0026rdquo; instead of merely \u0026ldquo;function analysis.\u0026rdquo; At first glance, \u0026ldquo;functional\u0026rdquo; appears to be an adjective form of \u0026ldquo;function,\u0026rdquo; suggesting meanings like \u0026ldquo;function-like\u0026rdquo; or \u0026ldquo;pertaining to functions.\u0026rdquo; This notion can also be found in another name for functionals, \u0026ldquo;generalized functions.\u0026rdquo; The question arises as to why these are not simply called functions. To understand this, let\u0026rsquo;s look at the general definition of a functional:\nFor a vector space $X$, a function $f$ called a functional is defined as follows:\n$$ f : X \\to \\mathbb{C} $$\nThis definition might prompt the question, \u0026ldquo;If $f$ is a function according to the above definition, why is it named a functional?\u0026rdquo; Although it\u0026rsquo;s understandable to assign a special name to functions satisfying certain conditions, the reason behind the specific choice of \u0026ldquo;functional\u0026rdquo; (implying something function-like) may not be immediately clear.\nTo grasp why something would be labeled as \u0026ldquo;function-like\u0026rdquo; rather than a function, it\u0026rsquo;s essential to consider the context in which functional analysis emerged. People learning mathematics today understand functions as follows:\nA correspondence $f$ is said to exist from $X$ to $Y$ if, for every $x_{1}, x_{2} \\in X$, there exist $f(x_{1})$ and $f(x_{2})$ that satisfy $x_{1} = x_{2} \\implies f(x_{1}) = f(x_{2})$.\n$$ f : X \\to Y $$\nWhen rigorously defined using set theory, it becomes:\nGiven two non-empty sets $X$ and $Y$, a binary relation $f \\subset (X,Y)$ is called a function if it satisfies the following, represented as $f : X \\to Y$:\n$$ (x ,y_{1}) \\in f \\land (x,y_{2}) \\in f \\implies y_{1} = y_{2} $$\nAs seen in these definitions, there are no specific conditions on sets $X$ and $Y$; whether they are sets of numbers or function spaces does not matter. However, to mathematicians in the late 19th century, a function was not perceived this way. They thought of functions primarily as mappings from values to values, essentially as formulas that provide one value from another, similar to how functions are introduced in middle school.\nThis view was somewhat natural because the rigorous definition of functions, as shown above, was developed through set theory, which was founded by Cantor, born in 1845. Thus, it\u0026rsquo;s not surprising that mathematicians up to the early 20th century considered functions mainly in terms of numerical formulas. The term \u0026ldquo;function\u0026rdquo; itself suggests a certain functionality or operation.\nConsider the following function:\nFor a differentiable function $f$ over a closed interval $[a,b]$, the length of the curve $y=f(x)$ is defined as follows:\n$$ L(f)=\\int_{a}^{b} \\sqrt{1+ f^{\\prime}(x)^{2}}dx $$\nTo the mathematicians of the time, $L$ was not considered a function because it mapped functions to values, not values to values. Hence, $L$ could be termed a \u0026ldquo;function of functions,\u0026rdquo; but since it was not strictly a function, there was ambiguity in terminology. Volterra referred to them as \u0026ldquo;functions of lines,\u0026rdquo; and the French mathematician Hadamard proposed calling these \u0026ldquo;function-like functions of functions\u0026rdquo; fonctionnelles. This term later became \u0026ldquo;functional\u0026rdquo; in English.\nAfter functions were rigorously defined using set theory, functionals became considered functions too. However, the term \u0026ldquo;functional\u0026rdquo; continues to be used, particularly because it clearly indicates that the domain is a space of functions, much like how a \u0026ldquo;collection\u0026rdquo; or \u0026ldquo;family\u0026rdquo; refers to a set of sets. Despite the conceptual overlap between functionals and functions, the term \u0026ldquo;functional\u0026rdquo; has persisted, likely to avoid confusion. The field of study being named functional analysis likely also played a role. Over time, the term \u0026ldquo;functional\u0026rdquo; has evolved to refer to mappings from vector spaces to complex number spaces.\nDistribution Theory As discussed, the term \u0026ldquo;functional\u0026rdquo; was originally coined to describe entities that were like functions but not exactly functions. However, once functions were defined through set theory, functionals became recognized as functions. Interestingly, functionals ended up being used to describe entities that truly were \u0026ldquo;not functions but function-like.\u0026rdquo; The Dirac delta function, first conceptualized by Poisson and Cauchy during their study of Fourier analysis and later popularized by the theoretical physicist Paul Dirac in quantum mechanics, is an example of such an entity. Its naive definition satisfies certain conditions that imply divergence, meaning the delta function is not strictly a function but rather a state or condition.\nIn 1950, after 15 years of research, the French mathematician Laurent-Moise Schwartz rigorously defined the delta function in the book \u0026ldquo;Theorie des distributions.\u0026rdquo; He introduced the concept of smooth functions called test functions and their space, denoted as $\\mathcal{D}$. Distributions are mappings from $\\mathcal{D}$ to $\\mathbb{C}$ and are considered functionals. Although initially functional referred to entities not traditionally regarded as functions, it eventually came to be used in developing a theory for entities that are not functions in the conventional sense but are treated as such, marking a fascinating turn of events.\n","id":1780,"permalink":"https://freshrimpsushi.github.io/en/posts/1780/","tags":null,"title":"Why Functional is Named Functional"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Theorem Two independent random variables $W,V$ where $W \\sim N(0,1)$ and $V \\sim \\chi^{2} (r)$, then $$ T = { {W} \\over {\\sqrt{V/r} } } \\sim t(r) $$\n$N \\left( \\mu , \\sigma^{2} \\right)$ is a normal distribution with mean $\\mu$ and variance $\\sigma^{2}$. $\\chi^{2} \\left( r \\right)$ is a chi-squared distribution with degrees of freedom $r$. $t(r)$ is a t-distribution with degrees of freedom $r$. Description If this theorem is approached solely through statistics, it appears more practical and historically closer to the definition of the t-distribution.\nDerivation1 Strategy: Direct deduction through the joint probability density function.\nDefinition of normal distribution: A continuous probability distribution $N \\left( \\mu,\\sigma^{2} \\right)$ with the following probability density function for $\\mu \\in \\mathbb{R}$ and $\\sigma \u0026gt; 0$ is called a normal distribution. $$ f(x) = {{ 1 } \\over { \\sqrt{2 \\pi} \\sigma }} \\exp \\left[ - {{ 1 } \\over { 2 }} \\left( {{ x - \\mu } \\over { \\sigma }} \\right)^{2} \\right] \\qquad, x \\in \\mathbb{R} $$\nDefinition of chi-squared distribution: A continuous probability distribution $\\chi^{2} (r)$ with the following probability density function for degrees of freedom $r \u0026gt; 0$ is called a chi-squared distribution. $$ f(x) = {{ 1 } \\over { \\Gamma (r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} \\qquad , x \\in (0, \\infty) $$\nSince the probability density functions of $W,V$ $f_{1} , f_{2}$ are given as $$ f_1 (w) := { {1} \\over {\\sqrt{2 \\pi }} } e ^{- w^{2} / 2} \\\\ \\displaystyle f_2 (v) ={ 1 \\over { \\Gamma ({r \\over 2}) 2^{r \\over 2} } } v^{ {r \\over 2} - 1 } e^{-{{v} \\over 2}} $$ the joint probability density function of $W$ and $V$ $h$ for $w \\in \\mathbb{R}$ and $v \\in (0,\\infty)$ is as follows: $$ h(w,v) = { {1} \\over {\\sqrt{2 \\pi }} } e ^{- w^{2} / 2} { 1 \\over { \\Gamma ({r \\over 2}) 2^{r \\over 2} } } v^{ {r \\over 2} - 1 } e^{-{{v} \\over 2}} $$ Now, if $\\displaystyle T := { {W} \\over {\\sqrt{V/r} } }$ and $U := V$, then $w = t\\sqrt{u} / \\sqrt{r}$ and $v = u$, therefore $$ \\left| J \\right| = \\begin{vmatrix} {{\\sqrt{u}} \\over {\\sqrt{r}}} \u0026amp; 0 \\\\ {{t} \\over {2 \\sqrt{ur}}} \u0026amp; 1 \\end{vmatrix} = \\sqrt{{{ u } \\over { r }}} $$ Thus, the joint probability density function of $T, U$ is $$ \\begin{align*} g(t,u) =\u0026amp; h({ {w} \\over {\\sqrt{v/r} } },u) |J| \\\\ =\u0026amp; { {1} \\over {\\sqrt{2 \\pi } \\Gamma (r/2) 2^{r/2} } } u^{r/2 -1} \\exp \\left\\{ -{{u} \\over {2} } \\left( 1 + { {t^2} \\over {r} } \\right) \\right\\} { {\\sqrt{u} } \\over {\\sqrt{r} } } \\end{align*} $$ The marginal probability density function of $T$ is $$ \\begin{align*} g(t) =\u0026amp; \\int_{-\\infty}^{\\infty} g(t,u) du \\\\ =\u0026amp; \\int_{0}^{\\infty} { {1} \\over {\\sqrt{2 \\pi r} \\Gamma (r/2) 2^{r/2} } } u^{(r+1)/2 -1} \\exp \\left\\{ -{{u} \\over {2} } \\left( 1 + { {t^2} \\over {r} } \\right) \\right\\} du \\end{align*} $$ Substituting with $\\displaystyle z := {{u} \\over {2}} \\left( 1 + {{t^2} \\over {r}} \\right)$ gives $$ \\begin{align*} g(t) =\u0026amp; \\int_{0}^{\\infty} { {1} \\over {\\sqrt{2 \\pi r} \\Gamma (r/2) 2^{r/2} } } \\left( { {2z} \\over {1 + t^2 / r} }\\right)^{(r+1)/2-1} e^{-z} \\left( { {2} \\over {1+ t^2 / r} } \\right) dz \\\\ =\u0026amp; { {1} \\over {\\sqrt{\\pi r} \\Gamma (r/2) } } \\int_{0}^{\\infty} {{ 1 } \\over { \\sqrt{2} 2^{r/2} }}z^{(r+1)/2-1} \\left( { {2} \\over {1 + t^2 / r} }\\right)^{(r+1)/2-1} e^{-z} \\left( { {2} \\over {1+ t^2 / r} } \\right) dz \\\\ =\u0026amp; { {1} \\over {\\sqrt{\\pi r} \\Gamma (r/2) } } \\int_{0}^{\\infty} {{ 1 } \\over { 2^{(r+1)/2} }}z^{(r+1)/2-1} \\left( { {2} \\over {1 + t^2 / r} }\\right)^{(r+1)/2} e^{-z} dz \\\\ =\u0026amp; { {1} \\over {\\sqrt{\\pi r} \\Gamma (r/2) } } \\int_{0}^{\\infty}z^{(r+1)/2-1} \\left( { {1} \\over {1 + t^2 / r} }\\right)^{(r+1)/2} e^{-z} {{ \\Gamma \\left( (r+1)/2 \\right) } \\over { \\Gamma \\left( (r+1)/2 \\right) }} dz \\\\ =\u0026amp; { {\\Gamma \\left( (r+1)/2 \\right)} \\over {\\sqrt{\\pi r} \\Gamma (r/2) } } \\left( { {1} \\over {1 + t^2 / r} }\\right)^{(r+1)/2} \\int_{0}^{\\infty} {{ 1 } \\over { \\Gamma \\left( (r+1)/2 \\right) }} z^{(r+1)/2-1} e^{-z} dz \\\\ =\u0026amp; { {\\Gamma \\left( (r+1)/2 \\right)} \\over {\\sqrt{\\pi r} \\Gamma (r/2) } } \\left( { {1} \\over {1 + t^2 / r} }\\right)^{(r+1)/2} \\cdot 1 \\end{align*} $$ The integrand becomes the probability density function of the gamma distribution $\\Gamma \\left( {{ r + 1 } \\over { 2 }} , 1 \\right) $, avoiding complex calculations. Upon simplification, $$ g(t) = {{\\Gamma ( (r+1)/2 ) } \\over { \\sqrt{\\pi r} \\Gamma (r/2) }} { {1} \\over {(1 + t^{2} / r)^{(r+1)/2} } } $$ This is the probability density function of the t-distribution with degrees of freedom $r$. $$ T = { {W} \\over {\\sqrt{V/r} } } \\sim t(r) $$\n‚ñ†\nHogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): 191-192.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":204,"permalink":"https://freshrimpsushi.github.io/en/posts/204/","tags":null,"title":"Derivation of the Student's t-Distribution from Independent Normal Distributions and the Chi-Squared Distribution"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition For a scalar function $f=f(x,y,z)$, the following vector function is defined as the gradient of $f$, denoted by $\\nabla f$:\n$$ \\nabla f := \\frac{ \\partial f}{ \\partial x }\\hat{\\mathbf{x}}+\\frac{ \\partial f}{ \\partial y}\\hat{\\mathbf{y}}+\\frac{ \\partial f}{ \\partial z}\\hat{\\mathbf{z}} = \\left( \\dfrac{\\partial f}{\\partial x}, \\dfrac{\\partial f}{\\partial y}, \\dfrac{\\partial f}{\\partial z} \\right) $$\nExplanation The gradient is translated into English as gradient, slope, or incline. The terms \u0026lsquo;slope\u0026rsquo; and \u0026lsquo;incline\u0026rsquo; are old translations of the gradient and are not commonly used nowadays. Also, \u0026lsquo;slope\u0026rsquo; is a Sino-Korean word for gradient, so it\u0026rsquo;s essentially the same. The gradient is actually a vector, so the term \u0026lsquo;slope\u0026rsquo; seems insufficient to fully capture the meaning of the gradient. Here at Sashimi Sushi, we prefer to use the term \u0026lsquo;gradient\u0026rsquo; consistently.\nGeometrically, $\\nabla f$ represents the direction in which $f$ changes most rapidly. In other words, the direction in which the rate of increase of $f$ is highest at the point $(x,y,z)$ is the vector $\\left( \\dfrac{\\partial f(x,y,z)}{\\partial x}, \\dfrac{\\partial f(x,y,z)}{\\partial y}, \\dfrac{\\partial f(x,y,z)}{\\partial z} \\right)$. This is just an extension of the concept of differential coefficients to multiple dimensions. If $f$ is increasing, the differential coefficient is positive; if $f$ is decreasing, the coefficient is negative.\nMeanwhile, it\u0026rsquo;s important to note that $\\left( \\dfrac{\\partial f}{\\partial x}, \\dfrac{\\partial f}{\\partial y}, \\dfrac{\\partial f}{\\partial z} \\right)$ is denoted as $\\nabla f$ in the definition. While $\\nabla$ is called the del operator, thinking of it as having its own meaning can lead to misunderstandings, such as misinterpreting $\\nabla \\cdot \\mathbf{F}$ or $\\nabla \\times \\mathbf{F}$ as dot products or cross products. Thus, $\\nabla$ should be understood merely as a convenient notation, and it\u0026rsquo;s better to think of the gradient, divergence, and curl collectively as del operators, or even to consider the del operator as equivalent to the gradient. More details will follow below.\nPoints of Attention $\\nabla f$ is not the product of $\\nabla$ and $f$ An important aspect of understanding the gradient is recognizing that $\\nabla f$ is not the product of the vector $\\nabla = \\left( \\frac{\\partial }{\\partial x}, \\frac{\\partial }{\\partial y}, \\frac{\\partial }{\\partial z} \\right)$ and the scalar $f$. It may seem intuitive and appealing to interpret it this way, but it\u0026rsquo;s actually the opposite. $\\nabla$ is presented as a vector like $\\left( \\frac{\\partial }{\\partial x}, \\frac{\\partial }{\\partial y}, \\frac{\\partial }{\\partial z} \\right)$ to make it appear like a product of a vector and a scalar. If $\\nabla f$ were really the product of the vector $\\nabla$ and the scalar $f$, then, since the product of a vector and a scalar is commutative, the following strange equation would hold:\n$$ \\nabla f = \\left( \\dfrac{\\partial f}{\\partial x}, \\dfrac{\\partial f}{\\partial y}, \\dfrac{\\partial f}{\\partial z} \\right) \\overset{?}{=} \\left( f\\dfrac{\\partial }{\\partial x}, f\\dfrac{\\partial }{\\partial y}, f\\dfrac{\\partial }{\\partial z} \\right) = f\\nabla $$\nThis odd result arises because $\\nabla$ is not actually a vector, and $\\nabla f$ is not a product of a vector and a scalar. $\\nabla$ is an operator that maps the scalar function $f(x,y,z)$ to the vector function $\\left( \\frac{\\partial f(x,y,z)}{\\partial x}, \\frac{\\partial f(x,y,z)}{\\partial y}, \\frac{\\partial f(x,y,z)}{\\partial z} \\right)$. Let\u0026rsquo;s define a function $\\operatorname{grad}$ that takes $f$ as a variable like this:\n$$ \\begin{equation} \\operatorname{grad} (f) = \\left( \\dfrac{\\partial f}{\\partial x}, \\dfrac{\\partial f}{\\partial y}, \\dfrac{\\partial f}{\\partial z} \\right), \\quad f=f(x,y,z) \\end{equation} $$\nIn this definition, there is no need for explanations about the product of a vector and a scalar. $\\operatorname{grad}$ is just a function (operator) that, when given the variable $f$, follows the rule in $(1)$ to determine its function value. However, $\\operatorname{grad} (f)$\u0026rsquo;s function value, when denoted as $\\operatorname{grad} = \\nabla$, becomes a convenient and intuitive notation, and it\u0026rsquo;s helpful to explain it as a vector $\\nabla = \\left( \\frac{\\partial }{\\partial x}, \\frac{\\partial }{\\partial y}, \\frac{\\partial }{\\partial z} \\right)$.\nSimilarly to how Leibniz\u0026rsquo;s notation for differentiation isn\u0026rsquo;t an exact explanation of the underlying principle but is used for convenience and ease of understanding, $\\nabla f$ also appears as a product of a vector and a scalar for computational convenience, though that\u0026rsquo;s not its true nature.\nWhat about $f\\nabla$? Following the explanation above, since $\\nabla$ is a function, $\\nabla f = \\nabla(f)$ represents the function value obtained when the variable $f$ is substituted into the function $\\nabla$. On the other hand, $f \\nabla$ is a function in itself, which when another function $g$ is substituted as a variable, maps to a function value as follows:\n$$ (f\\nabla) (g) = f\\left( \\dfrac{\\partial g}{\\partial x}, \\dfrac{\\partial g}{\\partial y}, \\dfrac{\\partial g}{\\partial z} \\right) = \\left( f\\dfrac{\\partial g}{\\partial x}, f\\dfrac{\\partial g}{\\partial y}, f\\dfrac{\\partial g}{\\partial z} \\right) $$\nOf course, when looking at the function value $f \\nabla g$, it can be seen as substituting $g$ into $f \\nabla$, or as the product of the scalar function $f$ and the vector function $\\nabla g$.\nDerivation 1-Dimension Look at the above picture. The differential coefficient of $f_{1}$ at point $x=2$ is $4$. This value not only tells how much the function $f_{1}$ is inclined at $x=2$, but also indicates that the graph of $f_{1}$ increases in the direction where $x$ increases, as suggested by the $+$ sign in front of $4$. Therefore, the differential coefficient $4$ should be understood not merely as a scalar, but as a 1-dimensional vector $4\\hat{\\mathbf{x}}$.\nSimilarly, the differential coefficient of $f_{2}$ at $x=2$ is $-3$. This includes the meaning that the inclination is $3$ and also implies that as $x$ increases, the graph of $f_{2}$ decreases. In other words, if we think of the sign as indicating direction, the direction of the differential coefficient points towards where the graph of the function increases. Put differently, following the direction indicated by the differential coefficient leads to the peak of the graph.\nBefore extending to 3 dimensions, recall that the differential coefficient of $y$ at $x$, $\\dfrac{ d y}{ d x}=a$, can be written as if it were a fraction. Although this is not a mathematically rigorous way to handle differentiation, it helps understand the geometric meaning and has its advantages. Leibniz thought of $dy$ and $dx$ as very small changes in $y$ and $x$, respectively, and called the ratio between these changes the differential coefficient.\n$$ dy=adx $$\nAs an aside, this helps understand why $a$ is called a differential \u0026lsquo;coefficient\u0026rsquo;.\n3D Now, let\u0026rsquo;s assume a 3D scalar function $f=f(x,y,z)$ and a position vector $\\mathbf{r}=x\\hat{\\mathbf{x}}+y\\hat{\\mathbf{y}}+z\\hat{\\mathbf{z}}$ are given. The change in $f$ is expressed through total differentiation.\n$$ \\begin{equation} df=\\frac{ \\partial f}{ \\partial x }dx + \\frac{ \\partial f}{ \\partial y}dy+\\frac{ \\partial f}{ \\partial z}dz \\end{equation} $$\nThe change in $\\mathbf{r}$ is as follows:\n$$ d\\mathbf{r}=dx\\hat{\\mathbf{x}}+dy\\hat{\\mathbf{y}}+dz\\hat{\\mathbf{z}} $$\nNow, as in the 1D case, let\u0026rsquo;s find something that represents the ratio between $df$ and $d\\mathbf{r}$. Since $df$ is a scalar and $d\\mathbf{r}$ is a vector, that \u0026lsquo;something\u0026rsquo; must be a vector, and $df$ can be imagined as the dot product of that \u0026lsquo;something\u0026rsquo; with $d\\mathbf{r}$. Therefore, let\u0026rsquo;s denote that \u0026lsquo;something\u0026rsquo; as $\\mathbf{a}=a_{1}\\hat{\\mathbf{x}}+a_{2}\\hat{\\mathbf{y}}+a_{3}\\hat{\\mathbf{z}}$ and express it as follows:\n$$ \\begin{align*} df=\\mathbf{a}\\cdot d\\mathbf{r}\u0026amp;=(a_{1}\\hat{\\mathbf{x}}+a_{2}\\hat{\\mathbf{y}}+a_{3}\\hat{\\mathbf{z}})\\cdot(dx\\hat{\\mathbf{x}}+dy\\hat{\\mathbf{y}}+dz\\hat{\\mathbf{z}}) \\\\ \u0026amp;= a_{1}dx+a_{2}dy+a_{3}dz \\end{align*} $$\nComparing this with $(2)$ yields the following result:\n$$ \\mathbf{a}=\\frac{ \\partial f}{ \\partial x}\\hat{\\mathbf{x}}+\\frac{ \\partial f}{ \\partial y}\\hat{\\mathbf{y}}+\\frac{ \\partial f}{ \\partial z}\\hat{\\mathbf{z}} $$\nFrom now on, let\u0026rsquo;s denote this vector $\\mathbf{a}$ as $\\nabla f$ and call it the gradient of $f$. The direction of the gradient points to where the function $f$ increases most significantly, and its magnitude represents the extent of this increase.\nRelated Formulas Linearity:\n$$ \\nabla (f + g) = \\nabla f + \\nabla g $$\nProduct Rule:\n$$ \\nabla{(fg)}=f\\nabla{g}+g\\nabla{f} $$ $$ \\nabla(\\mathbf{A} \\cdot \\mathbf{B}) = \\mathbf{A} \\times (\\nabla \\times \\mathbf{B}) + \\mathbf{B} \\times (\\nabla \\times \\mathbf{A})+(\\mathbf{A} \\cdot \\nabla)\\mathbf{B}+(\\mathbf{B} \\cdot \\nabla) \\mathbf{A} $$\nSecond Derivative:\n$$ \\nabla \\cdot (\\nabla T) = \\dfrac{\\partial^{2} T}{\\partial x^{2}} + \\dfrac{\\partial ^{2} T} {\\partial y^{2}} + \\dfrac{\\partial ^{2} T}{\\partial z^{2}} $$ $$ \\nabla \\times (\\nabla T)= \\mathbf{0} $$ $$\\nabla (\\nabla \\cdot \\mathbf{A} ) $$\nFundamental Theorem of Gradient\n$$ T(b)-T(a) = \\int _{a}^{b} (\\nabla T) \\cdot d\\mathbf{l} $$\nIntegration Formulas\n$$ \\int_{\\mathcal{V}} (\\nabla T) d \\tau = \\oint_{\\mathcal{S}} T d \\mathbf{a} $$ $$ \\int_{\\mathcal{V}} \\left[ T \\nabla^{2} U + (\\nabla T) \\cdot (\\nabla U) \\right] d \\tau = \\oint_{\\mathcal{S}} (T \\nabla U) \\cdot d \\mathbf{a} $$ $$ \\int_{\\mathcal{V}} \\left( T \\nabla^{2} U - U \\nabla^{2} T \\right) d \\tau = \\oint_{\\mathcal{S}} \\left( T \\nabla U - U \\nabla T \\right) \\cdot d \\mathbf{a} $$ $$ \\int_{\\mathcal{S}} \\nabla T \\times d \\mathbf{a} = - \\oint_{\\mathcal{P}} T d \\mathbf{l} $$\nPartial Integration\n$$ \\int_{\\mathcal{V}}\\mathbf{A} \\cdot (\\nabla f)d\\tau = \\oint_{\\mathcal{S}}f\\mathbf{A} \\cdot d \\mathbf{a}-\\int_{\\mathcal{V}}f(\\nabla \\cdot \\mathbf{A})d\\tau $$ $$ \\int_{\\mathcal{S}} f \\left( \\nabla \\times \\mathbf{A} \\right)\\mathbf{A} \\cdot d \\mathbf{a} = \\int_{\\mathcal{S}} \\left[ \\mathbf{A} \\times \\left( \\nabla f \\right) \\right] \\cdot d\\mathbf{a} + \\oint_{\\mathcal{P}} f\\mathbf{A} \\cdot d\\mathbf{l} $$\nSee Also Del Operator $\\nabla$ Gradient $\\nabla f$ Divergence $\\nabla \\cdot \\mathbf{F}$ Curl $\\nabla \\times \\mathbf{F}$ Laplacian $\\nabla^{2} f$ ","id":1778,"permalink":"https://freshrimpsushi.github.io/en/posts/1778/","tags":null,"title":"Gradient of Scalar Function in Cartesian Coordinate System"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Summary If $X \\sim N(\\mu,\\sigma ^2)$ then $$ V=\\left( { X - \\mu \\over \\sigma} \\right) ^2 \\sim \\chi ^2 (1) $$\n$N \\left( \\mu , \\sigma^{2} \\right)$ is a normal distribution with mean $\\mu$ and variance $\\sigma^{2}$. $\\chi^{2} \\left( 1 \\right)$ is a chi-squared distribution with degrees of freedom $1$. Description In general, Student\u0026rsquo;s theorem is widely used to generalize this.\nAnyone studying statistics must always know as a fact that the square of the standard normal distribution follows a chi-squared distribution. When one can assume some data follows a normal distribution, if the variance of the standardized data is excessively high or low, one can immediately guess there is an issue. Naturally, this is applied in many statistical tests, and having or lacking theoretical intuition on this is as different as heaven and earth.\nConversely, it is more common sense to explore what distribution the square of data following a standard normal distribution, perhaps the square of residuals, follows rather than first recalling the definition of chi-squared distribution and exploring its properties.\nProof 1 If we set $\\displaystyle W := {(X-\\mu) \\over \\sigma }$ then we get $W \\sim N(0,1)$.\nDefinition of standard normal distribution: A normal distribution $N \\left( 0,1^{2} \\right)$ with the following probability density function is called a standard normal distribution. $$ f(z) = {{ 1 } \\over { \\sqrt{2 \\pi} }} \\exp \\left[ - {{ z^{2} } \\over { 2 }} \\right] $$\nIf the cumulative distribution function of $V$ is denoted by $F$, then $$ \\begin{align*} F(v) =\u0026amp; P(V \\le v) \\\\ =\u0026amp; P \\left( W^2 \\le v \\right) \\\\ =\u0026amp; P \\left( \\sqrt{v} \\le W \\le \\sqrt{v} \\right) \\\\ =\u0026amp; \\int_{-\\sqrt{v}}^{\\sqrt{v}} { 1 \\over \\sqrt{ 2 \\pi } } e^{-{{w^2} \\over 2}} dw \\\\ =\u0026amp; 2 \\int_{0}^{\\sqrt{v}} { 1 \\over \\sqrt{ 2 \\pi } } e^{-{{w^2} \\over 2}} dw \\end{align*} $$ Substituting with $w := \\sqrt{x}$ yields $$ F(v) = 2\\int_{0}^{v} { 1 \\over \\sqrt{ 2 \\pi } } e^{-{{x} \\over 2}} {1 \\over {2 \\sqrt{x} } } dx $$ According to the fundamental theorem of calculus, the probability density function $f$ of $v$ is $$ f(v) = F ' (v) = { 1 \\over {\\sqrt{ 2 \\pi } } } e^{-{{v} \\over 2}}{ 1 \\over {v^{1 \\over 2}} } $$\nEuler\u0026rsquo;s reflection formula: $$ {\\Gamma (1-x) \\Gamma ( x )} = { {\\pi} \\over {\\sin \\pi x } } $$\nBy the reflection formula, since $\\displaystyle \\sqrt{\\pi} = \\Gamma \\left( {{ 1 } \\over { 2 }} \\right)$ $$ f(v) = { 1 \\over { \\Gamma ({1 \\over 2}) 2^{1 \\over 2} } } v^{ - {1 \\over 2} } e^{-{{v} \\over 2}} $$\nDefinition of gamma distribution: A continuous probability distribution $\\Gamma ( k , \\theta )$ with the following probability density function for $k, \\theta \u0026gt; 0$ is called a gamma distribution. $$ f(x) = {{ 1 } \\over { \\Gamma ( k ) \\theta^{k} }} x^{k - 1} e^{ - x / \\theta} \\qquad , x \u0026gt; 0 $$\nIn conclusion, $V$ has the probability density function of a gamma distribution $\\displaystyle \\Gamma \\left( {{ 1 } \\over { 2 }} , 2 \\right)$.\nRelationship between gamma and chi-squared distributions: $$ \\Gamma \\left( { r \\over 2 } , 2 \\right) \\iff \\chi ^2 (r) $$\nTherefore, $\\displaystyle \\Gamma \\left( {1 \\over 2}, 2 \\right) \\sim \\chi^2 (1)$ and $$ \\left( { X - \\mu \\over \\sigma} \\right) ^2 \\sim \\chi ^2 (1) $$\n‚ñ†\nHogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): 175-176.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":148,"permalink":"https://freshrimpsushi.github.io/en/posts/148/","tags":null,"title":"The Square of a Standard Normal Distribution Follows a Chi-Square Distribution with One Degree of Freedom"},{"categories":"Îß§Ìä∏Îû©","contents":"Method clear Command Typing clear in the command window will reset the workspace.\nClearing Workspace (Alt+T+O) Right-clicking on the workspace window allows you to select \u0026lsquo;Clear Workspace (O)\u0026rsquo;. Pressing it resets the workspace. This can also be done using the shortcut Alt+T+O, but it does not work when an editor is opened.\nDeleting by Selection You can delete by dragging to select everything or by pressing Ctrl+a to select all and then pressing Delete.\nOther Languages In R ","id":1758,"permalink":"https://freshrimpsushi.github.io/en/posts/1758/","tags":null,"title":"How to Initialize the Workspace and Remove All Variables in MATLAB"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition A continuous probability distribution $N \\left( \\mu,\\sigma^{2} \\right)$ with a probability density function as follows, given mean $\\mu \\in \\mathbb{R}$ and variance $\\sigma^{2} \u0026gt; 0$, is called Normal Distribution.\n$$ f(x) = {{ 1 } \\over { \\sqrt{2 \\pi} \\sigma }} \\exp \\left[ - {{ 1 } \\over { 2 }} \\left( {{ x - \\mu } \\over { \\sigma }} \\right)^{2} \\right] \\qquad, x \\in \\mathbb{R} $$\nIn particular, a Standard Normal Distribution is defined by the following probability density function $N \\left( 0,1^{2} \\right)$.\n$$ f(z) = {{ 1 } \\over { \\sqrt{2 \\pi} }} \\exp \\left[ - {{ z^{2} } \\over { 2 }} \\right] $$\nDescription Another name for the normal distribution is Gaussian Distribution. Historically, it became well known when Gauss introduced the normal distribution in his studies on the method of least squares in 1809. Though it\u0026rsquo;s not definitive that Gauss was the first to realize the essence of normal distribution, he certainly deserves the nickname associated with it.\nIn 1794, at the mere age of seventeen, Gauss was inspired about a method to determine the true value from measurements encountered in daily life or research. Counting his steps along a frequently traveled path, he collected data and plotted it on a graph to obtain a bell-shaped curve. This discovery was made in an era before the concept of histograms existed. Gauss himself thought these concepts of normal distribution and the method of least squares were already widely known and commonly used technologies1. Truly an overwhelming display of genius. Additionally, Gaussian integrals are often used in numerous calculations related to normal distribution.\nSince then, the normal distribution has been extensively studied and has become an indispensable tool across all sciences. It\u0026rsquo;s so familiar that laypeople often mistakenly believe that statistics simply assumes data follows a normal distribution and then calculates the mean and variance to conclude. While it would be disappointing if such undervaluation led to pursuing a degree in statistics, maybe that level of explanation is sufficient for non-specialists. It\u0026rsquo;s a statement on how important and powerful the normal distribution is.\nBasic Properties Moment Generating Function [1]: $$m(t) = \\exp \\left( \\mu t + {{ \\sigma^{2} t^{2} } \\over { 2 }} \\right) \\qquad , t \\in \\mathbb{R}$$ Mean and Variance [2] : If $X \\sim N\\left( \\mu , \\sigma^{2} \\right)$ then $$ \\begin{align*} E(X) =\u0026amp; \\mu \\\\ \\text{Var} (X) =\u0026amp; \\sigma^{2} \\end{align*} $$ Sufficient Statistics and Maximum Likelihood Estimator [3] : Given a random sample $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{n} \\right) \\sim N \\left( \\mu , \\sigma^{2} \\right)$ following the normal distribution. The sufficient statistics $T$ and maximum likelihood estimator $\\left( \\hat{\\mu}, \\widehat{\\sigma^{2}} \\right)$ are as follows. $$ \\begin{align*} T =\u0026amp; \\left( \\sum_{k} X_{k}, \\sum_{k} X_{k}^{2} \\right) \\\\ \\left( \\hat{\\mu}, \\widehat{\\sigma^{2}} \\right) =\u0026amp; \\left( {{ 1 } \\over { n }} \\sum_{k} X_{k}, {{ 1 } \\over { n }} \\sum_{k} \\left( X_{k} - \\overline{X} \\right)^{2} \\right) \\end{align*} $$\nEntropy [4] : When choosing the natural logarithm, the entropy of the normal distribution is as follows. $$ H = \\ln \\sqrt{2\\pi e \\sigma^{2}} $$ Theorems The importance of the normal distribution can be succinctly listed without need for lengthy explanations. Observe the following:\nCentral Limit Theorem [a]: If $\\left\\{ X_{k} \\right\\}_{k=1}^{n}$ are iid random variables with probability distribution $\\left( \\mu, \\sigma^2 \\right) $, then $$ \\sqrt{n} {{ \\overline{X}_n - \\mu } \\over {\\sigma}} \\overset{D}{\\to} N (0,1) $$ Relationship with Chi-Squared Distribution [b]: If $X \\sim N(\\mu,\\sigma ^2)$ then $$ V=\\left( { X - \\mu \\over \\sigma} \\right) ^2 \\sim \\chi ^2 (1) $$ Derivation of Standard Normal Distribution as Limiting Distribution of Binomial Distribution [c]: If $X_i \\sim B(1,p)$ and $Y_n = X_1 + X_2 + \\cdots + X_n$, then $Y_n \\sim B(n,p)$ $$ { { Y_n - np } \\over {\\sqrt{ np(1-p) } } }\\overset{D}{\\to} N(0,1) $$ Derivation of Standard Normal Distribution as Limiting Distribution of Poisson Distribution [d]: If $X_{n} \\sim \\text{Poi} \\left( n \\right)$ and $\\displaystyle Y_{n} := {{ X_{n} - n } \\over { \\sqrt{n} }}$, then $$ Y_{n} \\overset{D}{\\to} N(0,1) $$ Derivation of Standard Normal Distribution as Limiting Distribution of Student\u0026rsquo;s t-Distribution [e]: If $T_n \\sim t(n)$, then $$ T_n \\ \\overset{D}{\\to} N(0,1) $$ Derivation of t-Distribution from Normal and Chi-Squared Distributions [f]: Given two random variables $W,V$ are independent and $W \\sim N(0,1)$, $V \\sim \\chi^{2} (r)$, then $$ T = { {W} \\over {\\sqrt{V/r} } } \\sim t(r) $$ Proofs Strategy: Start by deriving the moment generating function of the standard normal distribution by making the exponent a complete square to enable the use of Gaussian integration, then obtain the moment generating function of the normal distribution through substitution.\nGaussian Integration: $$ \\int_{-\\infty}^{\\infty} e^{-x^2} dx= \\sqrt{\\pi} $$\n[1] 2 Given $\\displaystyle Z := {{ X - \\mu } \\over { \\sigma }} \\sim N(0,1)$, its moment generating function is\n$$ \\begin{align*} m_{Z}(t) =\u0026amp; \\int_{-\\infty}^{\\infty} \\exp (tz) {{ 1 } \\over { \\sqrt{2 \\pi} }} \\exp \\left[ - {{ 1 } \\over { 2 }} z^{2} \\right] dz \\\\ =\u0026amp; {{ 1 } \\over { \\sqrt{\\pi} }} \\int_{-\\infty}^{\\infty} {{ 1 } \\over { \\sqrt{2} }} \\exp \\left[ - {{ 1 } \\over { 2 }} z^{2} + tz \\right] dz \\\\ =\u0026amp; {{ 1 } \\over { \\sqrt{\\pi} }} \\int_{-\\infty}^{\\infty} {{ 1 } \\over { \\sqrt{2} }} \\exp \\left[ - {{ 1 } \\over { 2 }} \\left( z - t \\right)^{2} + {{ t^{2} } \\over { 2 }} \\right] dz \\\\ =\u0026amp; {{ 1 } \\over { \\sqrt{\\pi} }} \\int_{-\\infty}^{\\infty} {{ 1 } \\over { \\sqrt{2} }} \\exp \\left[ - {{ 1 } \\over { 2 }} \\left( z - t \\right)^{2} \\right] \\exp \\left[ {{ t^{2} } \\over { 2 }} \\right] dz \\\\ =\u0026amp; \\exp \\left[ {{ t^{2} } \\over { 2 }} \\right] {{ 1 } \\over { \\sqrt{\\pi} }} \\int_{-\\infty}^{\\infty} {{ 1 } \\over { \\sqrt{2} }} \\exp \\left[ - w^{2} \\right] \\sqrt{2} dw \\\\ =\u0026amp; \\exp \\left[ {{ t^{2} } \\over { 2 }} \\right] \\end{align*} $$\nThen, the moment generating function for $X \\sim N \\left( \\mu , \\sigma^{2} \\right)$ is\n$$ \\begin{align*} m_{X}(t) =\u0026amp; E \\left[ \\exp ( t X ) \\right] \\\\ =\u0026amp; E \\left[ \\exp \\left( t (\\sigma Z + \\mu) \\right) \\right] \\\\ =\u0026amp; \\exp(\\mu t) E \\left[ \\exp \\left( t \\sigma Z \\right) \\right] \\\\ =\u0026amp; \\exp(\\mu t) \\exp \\left( {{ t^{2} \\sigma^{2} } \\over { 2 }} \\right) \\\\ =\u0026amp; \\exp \\left( \\mu t + {{ \\sigma^{2} t^{2} } \\over { 2 }} \\right) \\end{align*} $$\n‚ñ†\n[2] Direct deduction using the moment generating function.\n‚ñ†\n[3] Direct deduction.\n‚ñ†\n[4] Direct deduction.\n‚ñ†\n[a] Application of the moment method.\n‚ñ†\n[b] Direct derivation using the probability density function. Utilizes the relationship between gamma functions, gamma distribution, and chi-squared distribution.\n‚ñ†\n[c] Proven using the central limit theorem.\n‚ñ†\n[d] Proven using the moment generating function.\n‚ñ†\n[e] Not easy. The convergence of the probability density function is shown through Stirling\u0026rsquo;s approximation.\n‚ñ†\n[f] Simple yet complex. Direct deduction using the probability density function.\n‚ñ†\nCode Below is some Julia code showing probability density functions for Cauchy distribution, t-distribution, and Cauchy distribution.\n@time using LaTeXStrings\r@time using Distributions\r@time using Plots\rcd(@__DIR__)\rx = -4:0.1:4\rplot(x, pdf.(Cauchy(), x),\rcolor = :red,\rlabel = \u0026#34;Cauchy\u0026#34;, size = (400,300))\rplot!(x, pdf.(TDist(3), x),\rcolor = :orange,\rlabel = \u0026#34;t(3)\u0026#34;, size = (400,300))\rplot!(x, pdf.(TDist(30), x),\rcolor = :black, linestyle = :dash,\rlabel = \u0026#34;t(30)\u0026#34;, size = (400,300))\rplot!(x, pdf.(Normal(), x),\rcolor = :black,\rlabel = \u0026#34;Standard Normal\u0026#34;, size = (400,300))\rxlims!(-4,5); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pdf\\,of\\, t}(\\nu)\u0026#34;)\rpng(\u0026#34;pdf\u0026#34;) Hubert Mania. (2010). The Passionate Pursuit: A Biography of Gauss that Precisely Uncovers the Absolute Order in the World of Cold Numbers, p69~72.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p171~172.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1645,"permalink":"https://freshrimpsushi.github.io/en/posts/1645/","tags":null,"title":"Normal Distribution"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition For a vector function $\\mathbf{F}(x,y,z)=(F_{x},F_{y},F_{z})=F_{x}\\hat{\\mathbf{x}} + F_{y}\\hat{\\mathbf{y}} + F_{z}\\hat{\\mathbf{z}}$, the following vector is defined as the curl of $\\mathbf{F}$, denoted as $\\nabla \\times \\mathbf{F}$.\n$$ \\begin{align} \\nabla \\times \\mathbf{F} \u0026amp;= \\left( \\dfrac{ \\partial F_{z}}{ \\partial y }-\\dfrac{ \\partial F_{y}}{ \\partial z} \\right)\\hat{\\mathbf{x}}+ \\left( \\dfrac{ \\partial F_{x}}{ \\partial z }-\\dfrac{ \\partial F_{z}}{ \\partial x} \\right)\\hat{\\mathbf{y}}+ \\left( \\dfrac{ \\partial F_{y}}{ \\partial x }-\\dfrac{ \\partial F_{x}}{ \\partial y} \\right)\\hat{\\mathbf{z}} \\label{def1} \\\\ \u0026amp;=\\begin{vmatrix} \\hat{\\mathbf{x}} \u0026amp; \\hat{\\mathbf{y}} \u0026amp; \\hat{\\mathbf{z}} \\\\ \\dfrac{ \\partial }{ \\partial x} \u0026amp; \\dfrac{ \\partial }{ \\partial y } \u0026amp; \\dfrac{ \\partial }{ \\partial z} \\\\ F_{x} \u0026amp; F_{y} \u0026amp;F_{z}\\end{vmatrix} \\label{def2} \\end{align} $$\n$(2)$ serves as an easy-to-remember formula for the curl of $\\mathbf{F}$. Think of it as a determinant and expand accordingly. Explanation Curl translates to rotation. However, since the term \u0026lsquo;rotation\u0026rsquo; is too common and may lead to confusion with rotation instead of curl, the term \u0026lsquo;curl\u0026rsquo; is preferred at the Fresh Shrimp Sushi Restaurant.\n$\\nabla \\times \\mathbf{F}$ is a vector that indicates in which direction the physical quantity $\\mathbf{F}$ is rotating. If you place the direction of $\\nabla \\times \\mathbf{F}$ as the axis (thumb) and apply the right-hand rule, the direction in which your right hand wraps around corresponds to the direction of rotation of $\\mathbf{F}$. The magnitude of the vector $\\nabla \\times \\mathbf{F}$ represents the extent of the rotation.\nUsing Einstein notation and Levi-Civita symbol, it can be expressed as follows. If $\\nabla_{j} = \\dfrac{\\partial }{\\partial x_{j}}$ is denoted,\n$$ \\nabla \\times \\mathbf{F} = \\epsilon_{ijk}\\hat{\\mathbf{e}}_{i}\\nabla_{j}F_{k} $$\nMeanwhile, note that the value denoted as $(1)$ in the definition is expressed as $\\nabla \\times \\mathbf{F}$. Although $\\nabla$ is referred to as the del operator, thinking of it as having a meaning on its own could easily lead to confusion, mistaking $\\nabla \\cdot \\mathbf{F}$ or $\\nabla \\times \\mathbf{F}$ as the dot product and cross product, respectively. Hence, it\u0026rsquo;s best to understand $\\nabla$ merely as a convenient notation, and it might be even better to think of the del operator as synonymous with the gradient. The del operators, encompassing the gradient, divergence, and curl, will be discussed in more detail below.\nPoints to Note $\\nabla \\times \\mathbf{F}$ is not the cross product of $\\nabla$ and $\\mathbf{F}$ $\\nabla \\times \\mathbf{F}$ is definitely not the cross product of $\\nabla$ and $\\mathbf{F}$.\r$\\nabla \\times \\mathbf{F}$ is merely a vector containing some information about $\\mathbf{F}$. We think of $\\nabla$ as a vector like $\\nabla = \\dfrac{ \\partial }{ \\partial x}\\hat{\\mathbf{x}} + \\dfrac{ \\partial }{ \\partial y}\\hat{\\mathbf{y}} + \\dfrac{ \\partial }{ \\partial z}\\hat{\\mathbf{z}}$, and the result matches perfectly with $(1)$, so it\u0026rsquo;s denoted as $\\nabla \\times \\mathbf{F}$ for convenience. Assuming $\\nabla$ is an actual vector would lead to strange results.\nThe following equation holds for two vectors $\\mathbf{A}, \\mathbf{B}$:\n$$ \\nabla \\times (\\mathbf{A} \\times \\mathbf{B}) = (\\mathbf{B} \\cdot \\nabla)\\mathbf{A} - (\\mathbf{A} \\cdot \\nabla)\\mathbf{B} + \\mathbf{A} (\\nabla \\cdot \\mathbf{B}) - \\mathbf{B} (\\nabla \\cdot \\mathbf{A}) $$\nIf $\\nabla$ were truly a vector, we could substitute it into the above formula and obtain the following results.\n$$ \\nabla \\times (\\nabla \\times \\mathbf{F})=(\\mathbf{F} \\cdot \\nabla)\\nabla - (\\nabla \\cdot \\nabla)\\mathbf{F} + \\nabla (\\nabla \\cdot \\mathbf{F}) - \\mathbf{F} (\\nabla \\cdot \\nabla) $$\nHowever, the correct result is as follows.\n$$ \\nabla \\times (\\nabla \\times \\mathbf{F})=\\nabla(\\nabla \\cdot \\mathbf{F})-\\nabla ^{2} \\mathbf{F} $$\nAnother example exists. Since the cross product of vectors has the property of anticommutativity, if $\\nabla \\times \\mathbf{F}$ were a cross product, the following equation should hold:\n$$ \\nabla \\times \\mathbf{F} \\overset{?}{=} - \\mathbf{F} \\times \\nabla $$\nTherefore, $\\nabla$ is not a vector, and it can be understood that $\\nabla \\times \\mathbf{F}$ is not the cross product of $\\nabla$ and $\\mathbf{F}$. Instead of being a vector, $\\nabla \\times$ should be considered as a function in itself. In physics, functions that take other functions as variables are called operators.\nSo, what\u0026rsquo;s the difference between $\\nabla \\times \\mathbf{F}$ and $\\mathbf{F} \\times \\nabla$? $\\nabla \\times$ is an operator defined as follows, taking a vector function as its variable:\n$$ \\nabla \\times (\\mathbf{F}) = \\left( \\dfrac{ \\partial F_{z}}{ \\partial y }-\\dfrac{ \\partial F_{y}}{ \\partial z} \\right)\\hat{\\mathbf{x}}+ \\left( \\dfrac{ \\partial F_{x}}{ \\partial z }-\\dfrac{ \\partial F_{z}}{ \\partial x} \\right)\\hat{\\mathbf{y}}+ \\left( \\dfrac{ \\partial F_{y}}{ \\partial x }-\\dfrac{ \\partial F_{x}}{ \\partial y} \\right)\\hat{\\mathbf{z}} $$\nIn other words, $\\nabla \\times \\mathbf{F}$ is the function value when the variable $\\mathbf{F}$ is substituted into the operator (function) $\\nabla \\times$. Of course, this in turn is a vector function of the variables $(x,y,z)$. While $\\nabla \\times \\mathbf{F}$ is the function value of $\\nabla \\times$, $\\mathbf{F} \\times \\nabla$ is an operator in itself. Although it\u0026rsquo;s not a commonly used expression, it can be defined as the following differential operator if we were to define it.\n$$ \\begin{align*} \\mathbf{F} \\times \\nabla \u0026amp;= \\begin{vmatrix} \\hat{\\mathbf{x}} \u0026amp; \\hat{\\mathbf{y}} \u0026amp; \\hat{\\mathbf{z}} \\\\ F_{x} \u0026amp; F_{y} \u0026amp;F_{z} \\\\ \\dfrac{ \\partial }{ \\partial x} \u0026amp; \\dfrac{ \\partial }{ \\partial y } \u0026amp; \\dfrac{ \\partial }{ \\partial z} \\end{vmatrix} \\\\ \u0026amp;= \\left( F_{y}\\dfrac{ \\partial }{ \\partial z} - F_{z}\\dfrac{ \\partial }{ \\partial y} \\right)\\hat{\\mathbf{x}} + \\left( F_{z}\\dfrac{ \\partial }{ \\partial x} - F_{x}\\dfrac{ \\partial }{ \\partial z} \\right)\\hat{\\mathbf{y}} + \\left( F_{x}\\dfrac{ \\partial }{ \\partial y} - F_{y}\\dfrac{ \\partial }{ \\partial x} \\right)\\hat{\\mathbf{z}} \\end{align*} $$\nDerivation Now, let\u0026rsquo;s consider a function that indicates the direction of rotation (clockwise or counterclockwise) of a rotating vector function. It\u0026rsquo;s important to note that no direction within the plane of rotation can specify the direction of rotation. Look at the diagram below.\nVector $-\\hat{\\mathbf{x}}$ can explain the movement at point $A$, but not at point $B$. Vector $\\hat{\\mathbf{y}}$ can explain the movement at point $C$, but not at point $D$. Vector $\\hat{\\mathbf{x}} + \\hat{\\mathbf{y}}$ can explain the path $F$, but not $G$. This is also true for clockwise rotation. Now, you should sense the need to move out of the plane of rotation to specify the direction of rotation. In fact, there\u0026rsquo;s already a good method to determine this: using the right-hand rule, which determines the axis of rotation in the direction of the thumb when the right hand wraps around. Therefore, in the $xy$-plane, the axis (direction) of counterclockwise rotation is $\\hat{\\mathbf{z}}$, and the axis (direction) of clockwise rotation is $-\\hat{\\mathbf{z}}$.\nNow, let\u0026rsquo;s find a value that indicates the $\\hat{\\mathbf{z}}$ direction when $\\mathbf{F}$ is rotating counterclockwise in the $xy$-plane, in other words, a positive value. Let\u0026rsquo;s represent the rotation simply with a rectangle as below.\nPath ‚ë† moves from point $a$ to point $b$, and let\u0026rsquo;s say $\\mathbf{F}(a) = (1,0,0)$ and $\\mathbf{F}(b) = (0,1,0)$. Then, as $x$ changes by +1 from point $a$ to $b$, and $F_{y}$ also changes by +1, we obtain the following.\n$$ \\dfrac{\\partial F_{y}}{\\partial x} \\gt 0 $$\nIn the same manner, on the path where the point moves from $b$ to $c$, $y$ changes by +1, and $F_{x}$ changes by -1. Checking all four paths, we find that:\n$$ \\dfrac{\\partial F_{y}}{\\partial x} \\gt 0 \\quad \\text{in path $\\textcircled{1}$, $\\textcircled{3}$} $$\n$$ \\dfrac{\\partial F_{x}}{\\partial y} \\lt 0 \\quad \\text{in path $\\textcircled{2}$, $\\textcircled{4}$} $$\nTherefore, for a vector $\\mathbf{F}$ that rotates counterclockwise as above, the value below is always positive:\n$$ \\dfrac{\\partial F_{y}}{\\partial x} - \\dfrac{\\partial F_{x}}{\\partial y} \\gt 0 $$\nConversely, if $\\mathbf{F}$ is rotating clockwise, the above value is always negative. Now, we can define the operator $\\operatorname{curl}_{xy}$, which indicates the direction and magnitude of rotation in the $xy$-plane when the vector function $\\mathbf{F}$ is substituted:\n$$ \\operatorname{curl}_{xy} (\\mathbf{F}) = \\left( \\dfrac{\\partial F_{y}}{\\partial x} - \\dfrac{\\partial F_{x}}{\\partial y} \\right) \\hat{\\mathbf{z}} $$\nThe sign of the $\\hat{\\mathbf{z}}$ component of this function indicates the direction of rotation of $\\mathbf{F}$ in the $xy$-plane: If it\u0026rsquo;s positive (+), $\\mathbf{F}$ rotates counterclockwise in the $xy$-plane. If it\u0026rsquo;s negative (-), $\\mathbf{F}$ rotates clockwise in the $xy$-plane. If it\u0026rsquo;s zero (0), there is no rotation. The magnitude of the $\\hat{\\mathbf{z}}$ component of this function indicates how rapidly $\\mathbf{F}$ is rotating in the $xy$-plane. Applying this discussion similarly to the $yz$-plane and the $zx$-plane, we can define the vector $\\nabla \\times \\mathbf{F}$, which indicates the direction and magnitude of rotation of $\\mathbf{F}$ in 3-dimensional space, as follows.\n$$ \\nabla \\times \\mathbf{F} := \\left( \\dfrac{\\partial F_{z}}{\\partial y} - \\dfrac{\\partial F_{y}}{\\partial z} \\right)\\hat{\\mathbf{x}} + \\left( \\dfrac{\\partial F_{x}}{\\partial z} - \\dfrac{\\partial F_{z}}{\\partial x} \\right)\\hat{\\mathbf{y}} + \\left( \\dfrac{\\partial F_{y}}{\\partial x} - \\dfrac{\\partial F_{x}}{\\partial y} \\right)\\hat{\\mathbf{z}} $$\n‚ñ†\nRelated formulas Linearity: $$ \\nabla \\times (\\mathbf{A} + \\mathbf{B}) = \\nabla \\times \\mathbf{A} + \\nabla \\times \\mathbf{B} $$\nMultiplication rule:\n$$ \\nabla \\times (f\\mathbf{A}) = f(\\nabla \\times \\mathbf{A}) - \\mathbf{A} \\times (\\nabla f) $$\n$$ \\nabla \\times (\\mathbf{A} \\times \\mathbf{B}) = (\\mathbf{B} \\cdot \\nabla)\\mathbf{A} - (\\mathbf{A} \\cdot \\nabla)\\mathbf{B} + \\mathbf{A} (\\nabla \\cdot \\mathbf{B}) - \\mathbf{B} (\\nabla \\cdot \\mathbf{A}) $$\n2nd derivative:\n$$ \\nabla \\times (\\nabla f) = \\mathbf{0} $$\n$$ \\nabla \\times (\\nabla \\times \\mathbf{F}) = \\nabla (\\nabla \\cdot \\mathbf{F}) - \\nabla^{2} \\mathbf{F} $$\nStokes\u0026rsquo; theorem $$ \\int_{\\mathcal{S}} (\\nabla \\times \\mathbf{v} )\\cdot d\\mathbf{a} = \\oint_{\\mathcal{P}} \\mathbf{v} \\cdot d\\mathbf{l} $$\nIntegral formulas $$ \\int_{\\mathcal{V}} (\\nabla \\times \\mathbf{v}) d \\tau = - \\oint_{\\mathcal{S}} \\mathbf{v} \\times d \\mathbf{a} $$\n$$ \\int_{\\mathcal{S}} \\nabla T \\times d \\mathbf{a} = - \\oint_{\\mathcal{P}} T d \\mathbf{l} $$\nIntegration by parts $$ \\int_{\\mathcal{S}} f \\left( \\nabla \\times \\mathbf{A} \\right)\\mathbf{A} \\cdot d \\mathbf{a} = \\int_{\\mathcal{S}} \\left[ \\mathbf{A} \\times \\left( \\nabla f \\right) \\right] \\cdot d\\mathbf{a} + \\oint_{\\mathcal{P}} f\\mathbf{A} \\cdot d\\mathbf{l} $$\n$$ \\int_{\\mathcal{V}} \\mathbf{B} \\cdot \\left( \\nabla \\times \\mathbf{A} \\right) d\\tau = \\int_{\\mathcal{V}} \\mathbf{A} \\cdot \\left( \\nabla \\times \\mathbf{B} \\right) d\\tau + \\oint_{\\mathcal{S}} \\left( \\mathbf{A} \\times \\mathbf{B} \\right) \\cdot d \\mathbf{a} $$\nProof Linearity Using Einstein notation and Levi-Civita symbol, if we denote $\\nabla_{j} = \\dfrac{\\partial }{\\partial x_{j}}$, then:\n$$ \\begin{align*} \\left[ \\nabla \\times (\\mathbf{A} + \\mathbf{B}) \\right]_{i} \u0026amp;= \\epsilon_{ijk} \\nabla_{j} (\\mathbf{A} + \\mathbf{B})_{k} \\\\ \u0026amp;= \\epsilon_{ijk} \\nabla_{j} (A_{k} + B_{k}) \\\\ \u0026amp;= \\epsilon_{ijk} \\nabla_{j}A_{k} + \\epsilon_{ijk} \\nabla_{j}B_{k} \\\\ \u0026amp;= [\\nabla \\times \\mathbf{A}]_{i} + [\\nabla \\times \\mathbf{B}]_{i} \\\\ \\end{align*} $$\nThe third equality holds because $\\dfrac{\\partial (A_{k} + B_{k})}{\\partial x_{j}} = \\dfrac{\\partial A_{k}}{\\partial x_{j}} + \\dfrac{\\partial B_{k}}{\\partial x_{j}}$. ‚ñ†\nFurther reading Del Operator $\\nabla$ Gradient $\\nabla f$ Divergence $\\nabla \\cdot \\mathbf{F}$ Curl $\\nabla \\times \\mathbf{F}$ Laplacian $\\nabla^{2} f$ ","id":1752,"permalink":"https://freshrimpsushi.github.io/en/posts/1752/","tags":null,"title":"Curl of Vector Functions in 3D Cartesian Coordinates"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Summary If two random variables $U,V$ are independent and it is assumed that $U \\sim \\chi^{2} ( r_{1})$, $V \\sim \\chi^{2} ( r_{2})$ then $$ {{ U / r_{1} } \\over { V / r_{2} }} \\sim F \\left( r_{1} , r_{2} \\right) $$\nExplanation If two data follow the Chi-squared distribution and are independent, it might be possible to explain their ratio using distribution theory. In statistics in general, it is assumed that the squared standardized residuals follow the Chi-squared distribution, which is why the F-test is commonly used. While the proof itself is not crucial, understanding why the F-test is used in many analyses provides vital insight, making it an essential fact for students of mathematical statistics.\nDerivation1 Strategy: Direct deduction using the joint density function of Chi-squared distributions.\nDefinition of Chi-squared distribution: A continuous probability distribution for a given degree of freedom $r \u0026gt; 0$ that has the following probability density function $\\chi^{2} (r)$ is called the Chi-squared distribution. $$ f(x) = {{ 1 } \\over { \\Gamma (r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} \\qquad , x \\in (0, \\infty) $$\nDefinition of F-distribution: A continuous probability distribution for a given degree of freedom $r_{1}, r_{2} \u0026gt; 0$ that has the following probability density function $F \\left( r_{1} , r_{2} \\right)$ is called the F-distribution. $$ f(x) = {{ 1 } \\over { B \\left( r_{1}/2 , r_{2} / 2 \\right) }} \\left( {{ r_{1} } \\over { r_{2} }} \\right)^{r_{1} / 2} x^{r_{1} / 2 - 1} \\left( 1 + {{ r_{1} } \\over { r_{2} }} x \\right)^{-(r_{1} + r_{2}) / 2} \\qquad , x \\in (0, \\infty) $$\nSince $U,V$ are independent, the joint density function with respect to $u,v \\in (0,\\infty)$ is as follows. $$ h(u,v) = {{ 1 } \\over { \\Gamma \\left( {{ r_{1} } \\over { 2 }} \\right) \\Gamma \\left( {{ r_{2} } \\over { 2 }} \\right) 2^{(r_{1} + r_{2})/2} }} u^{r_{1}/2 - 1} v^{r_{2}/2 - 1} e^{-(u+v)/2} $$ Now, if we set $\\displaystyle W:= {{ U/r_{1} } \\over { V / r_{2} }}$ and $Z := V$, then $u = (r_{1}/r_{2})zw$ and $v = z$, thus $$ \\left| J \\right| = \\begin{vmatrix} (r_{1}/r_{2})z \u0026amp; (r_{1}/r_{2})w \\\\ 0 \u0026amp; 1 \\end{vmatrix} = (r_{1}/r_{2})z \\ne 0 $$ Therefore, the joint density function of $W,Z$ with respect to $w,z \\in (0,\\infty)$ is $$ g(w,z) = {{ 1 } \\over { \\Gamma \\left( {{ r_{1} } \\over { 2 }} \\right) \\Gamma \\left( {{ r_{2} } \\over { 2 }} \\right) 2^{(r_{1} + r_{2})/2} }} \\left( {{ r_{1} z w } \\over { r_{2} }} \\right)^{{{ r_{1} - 2 } \\over { 2 }}} z^{{{ r_{2} - 2 } \\over { 2 }}} \\exp \\left[ - {{ z } \\over { 2 }} \\left( {{ r_{1} w } \\over { r_{2} }} + 1 \\right) \\right] {{ r_{1} z } \\over { r_{2} }} $$ The marginal density function $g_{1}$ of $W$ is set to $\\displaystyle y:= {{ z } \\over { 2 }} \\left( {{ r_{1} w } \\over { r_{2} }} + 1 \\right)$, thus $$ \\begin{align*} g_{1} (w) =\u0026amp; \\int_{-\\infty}^{\\infty} g(w,z) dz \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} {{ 1 } \\over { \\Gamma \\left( {{ r_{1} } \\over { 2 }} \\right) \\Gamma \\left( {{ r_{2} } \\over { 2 }} \\right) 2^{(r_{1} + r_{2})/2} }} \\left( {{ r_{1} z w } \\over { r_{2} }} \\right)^{{{ r_{1} - 2 } \\over { 2 }}} z^{{{ r_{2} - 2 } \\over { 2 }}} \\exp \\left[ - {{ z } \\over { 2 }} \\left( {{ r_{1} w } \\over { r_{2} }} + 1 \\right) \\right] {{ r_{1} z } \\over { r_{2} }} dz \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} {{ (r_{1} / r_{2})^{r_{1} / 2} w^{r_{1}/2 - 1} } \\over { \\Gamma \\left( {{ r_{1} } \\over { 2 }} \\right) \\Gamma \\left( {{ r_{2} } \\over { 2 }} \\right) 2^{(r_{1} + r_{2})/2} }} \\left( {{ 2y } \\over { {{ r_{1} } \\over { r_{2} }} w + 1 }} \\right)^{{{ r_{1} + r_{2} } \\over { 2 }} - 1} e^{-y} \\left( {{ 2 } \\over { {{ r_{1} } \\over { r_{2} }} w + 1 }} \\right) dy \\\\ =\u0026amp; {{ \\Gamma \\left( {{ r_{1} + r_{2} } \\over { 2 }} \\right) \\left( {{ r_{1} } \\over { r_{2} }} \\right)^{r_{1} / 2} } \\over { \\Gamma \\left( {{ r_{1} } \\over { 2 }} \\right) \\Gamma \\left( {{ r_{2} } \\over { 2 }} \\right) }} {{ w^{r_{1}/2 - 1} } \\over { \\left( 1 + {{ r_{1} } \\over { r_{2} }} w \\right)^{(r_{1} + r_{2}) / 2} }} \\\\ =\u0026amp; {{ 1 } \\over { B \\left( r_{1}/2 , r_{2} / 2 \\right) }} \\left( {{ r_{1} } \\over { r_{2} }} \\right)^{r_{1} / 2} w^{r_{1} / 2 - 1} \\left( 1 + {{ r_{1} } \\over { r_{2} }} w \\right)^{-(r_{1} + r_{2}) / 2} \\end{align*} $$ Therefore $$ W \\sim F (r_{1} , r_{2}) $$\n‚ñ†\nHogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): 193-194.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1643,"permalink":"https://freshrimpsushi.github.io/en/posts/1643/","tags":null,"title":"Derivation of F-distribution from Two Independent Chi-squared Distributions"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Damped Harmonic Oscillation1 When the spring constant is denoted as $k$, the equation of motion for a simple harmonic oscillator is as follows.\n$$ m \\ddot {x}+kx=0 $$\nThe simple harmonic motion only considers the restoring force by the spring. However, in reality, other external forces such as frictional forces also affect the motion of the object, so they cannot be ignored. So, let\u0026rsquo;s assume there is a frictional force that acts proportional to the speed. This force is called a retarding force. The motion of an oscillator with this retarding force at play is referred to as damped harmonic oscillation. Specific examples include air resistance. If the retarding force is as follows, $-c\\dot{x}$, then the equation of motion is as described below.\n$$ \\begin{align*} \u0026amp;\u0026amp; m \\ddot{x} +c \\dot{x} +kx\u0026amp;=0 \\\\ \\implies \u0026amp;\u0026amp; \\ddot{x} +\\frac{c}{m} \\dot{x} +\\frac{k}{m}x\u0026amp;=0 \\end{align*} $$\nHere, let\u0026rsquo;s substitute with ${\\omega_{0}}^{2}=\\frac{k}{m}$, and let it be $\\gamma = \\frac{c}{2m}$. At this point, consider $\\omega_{0}$ as the natural angular frequency, and $\\gamma $ as the damping factor. Hence, the equation of motion can be written as below.\n$$ \\ddot{x} + 2\\gamma \\dot{x} + {\\omega_{0}} ^{2} x=0 $$\nThis kind of differential equation can easily be solved using the differential operator $D:=\\frac{ d }{ d t}$. Applying the differential operator to the above equation of motion yields the following.\n$$ \\begin{align*} \u0026amp;\u0026amp; D^{2}x + 2\\gamma D x + {\\omega_{0}} ^{2} x \u0026amp;=0 \\\\ \\implies \u0026amp;\u0026amp; \\left( D^{2} +2\\gamma D + {\\omega_{0}} ^{2} \\right)x \u0026amp;=0 \\end{align*} $$\nTherefore, one needs to solve $D^{2}+2\\gamma D +{\\omega_{0}}^{2}=0$. The solution to this equation is provided below, according to the quadratic formula.\n$$ D=-\\gamma \\pm \\sqrt{\\gamma ^{2} -{\\omega_{0}} ^{2} } $$\nThus,\n$$ Dx = \\left( -\\gamma \\pm \\sqrt{\\gamma ^{2} -{\\omega_{0}} ^{2}} \\right)x $$\nThis is a simple first-order differential equation, so the solution can be obtained as follows.\n$$ \\begin{equation} x(t)=Ae^{(-\\gamma + \\sqrt{\\gamma ^{2} -{\\omega_{0}}^{2}})t }+Be^{(-\\gamma - \\sqrt{\\gamma ^{2} -{\\omega_{0}}^{2}})t } \\label{eq1} \\end{equation} $$\nIn this equation, $A$, $B$ are constants. Since the exponent includes a root, the graph of the above formula varies depending on the value of $\\gamma ^{2}-{\\omega_{0}}^{2}$.\nOverdamping $$ \\gamma ^{2} - {\\omega_{0}}^{2}\u0026gt;0 $$\nWhen a mass attached to a spring is pulled from its equilibrium position and then released, it returns to the equilibrium point but does not oscillate as the damping force is strong, as shown in the picture above.\nCritical Damping $$ {\\gamma} ^{2} -{\\omega_{0}}^{2}=0 $$\nIn this case, the two solutions of $\\eqref{eq1}$ are the same. Thus, the second solution needs to be found and is known as follows.\n$$ x(t)=Ae^{-\\gamma t} +Bte^{-\\gamma t} $$\nLike the overdamping, there are no oscillations, but it reaches the vicinity of the equilibrium point at a much faster speed compared to overdamping.\nUnderdamping $$ \\gamma^{2} -{\\omega_{0}}^{2} \u0026lt;0 $$\nFor simplicity, let\u0026rsquo;s denote $i\\omega_{d}=\\sqrt{\\gamma^{2} - {\\omega_{0}} ^{2}}$ as d, taken from the first letter of damped. Then, the equation of motion is as follows.\n$$ x(t) = e^{-\\gamma t}\\left( A e^{i\\omega_{d}t} + Be^{-i\\omega_{d}t} \\right) $$\nThe position $x$ must be real, so it must satisfy $x^{\\ast}(t)=x(t)$. $^{\\ast}$ means conjugate complex numbers. From this, the following condition is derived.\n$$ Ae^{i\\omega_{d}t}+Be^{-i\\omega_{d}t}=A^{\\ast}e^{-i\\omega_{d}t}+B^{\\ast}e^{i\\omega_{d}t} \\implies B=A^{\\ast} $$\nTherefore, the equation of motion is as follows.\n$$ x(t) = e^{-\\gamma t}\\left( A e^{i\\omega_{d}t} + A^{\\ast}e^{-i\\omega_{d}t} \\right) $$\nAnd if we denote as $A=a+ib$, the following equation holds.\n$$ x(t) = e^{-\\gamma t}\\left[ a\\left( e^{i\\omega_{d}t}+e^{-i\\omega_{d}t}\\right) + ib\\left( e^{i\\omega_{d}t}-e^{-i\\omega_{d}t}\\right) \\right] $$\nApplying Euler\u0026rsquo;s formula yields the following.\n$$ x(t) = e^{-\\gamma t}\\left[ 2a\\cos (\\omega_{d}t)-2b\\sin (\\omega_{d}t) \\right] $$\nThen, according to the sum and difference identities for some real numbers $A$, $\\phi_{0}$, the following holds.\n$$ x(t)=e^{-\\gamma t}A \\cos(\\omega_{d}t+\\phi_{0}) $$\nDue to $e^{-\\gamma t}$, while the amplitude decreases exponentially, it includes $\\cos$, hence oscillates unlike the first two cases.\nSimulation Depending on the difference in the frequency and the damping factor, a damped harmonic oscillator can be categorized into overdamped, critically damped, and underdamped situations. Being able to visually observe how an oscillator moves in each of these situations greatly aids in understanding. With Julia, not only can one easily graph these situations, but it\u0026rsquo;s also simple to create and save them as gif files. Below is the code to create and save damped harmonic oscillator animations, along with the actual execution screen.\nusing Plots\rO_Œ≥=3\rO_œâ=1\rfunction Overdamping(x)\r0.5exp((-O_Œ≥+sqrt(O_Œ≥^2-O_œâ^2))*x)+0.5exp((-O_Œ≥-sqrt(O_Œ≥^2-O_œâ^2))*x)\rend\rC_Œ≥=1\rC_œâ=1\rfunction Criticaldamping(x)\rexp(-C_Œ≥*x)+x*exp(-C_Œ≥*x)\rend\rU_Œ≥=1\rU_Œ≥=U_Œ≥^2\rU_œâ=5\rU_œâ=U_œâ^2\rfunction Underdamping(x)\rreal(exp.(-U_Œ≥*x).*cos.(1im*sqrt(Complex(U_Œ≥-U_œâ))*x))\rend\rp = plot([Overdamping, Criticaldamping, Underdamping], zeros(0),label=[\u0026#34;Overdamping\u0026#34; \u0026#34;Criticaldamping\u0026#34; \u0026#34;Underdamping\u0026#34;], xlim=(0,15), ylim=(-0.7,1.2))\ranim = Animation()\rfor x = range(0, stop=15, length = 200)\rpush!(p, x, Float64[Overdamping(x), Criticaldamping(x), Underdamping(x)])\rframe(anim)\rend\rgif(anim,\u0026#34;Damping_fps30.gif\u0026#34;,fps=30) See Also Simple Harmonic Motion Forced Oscillation Multiple Spring Oscillation Coupled Oscillation Grant R. Fowles and George L. Cassiday, Analytical Mechanics (7th Edition, 2005), p96-100\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1736,"permalink":"https://freshrimpsushi.github.io/en/posts/1736/","tags":["Ï§ÑÎ¶¨ÏïÑ"],"title":"Damped Harmonic Oscillation"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Definition1 The Fourier Transform of the function $f$\n$$ \\widehat{f} (\\gamma ) := \\int_{\\mathbb{R}} f(x) e^{-2 \\pi i x \\gamma} dx, \\quad \\gamma \\in \\mathbb{R} $$\ncan also be represented as the following operator $\\mathcal{F}$.\n$$ (\\mathcal{F} f) (\\gamma ) := \\widehat{f} ( \\gamma ) $$\nDescription Fourier Transform is widely used throughout analysis and the two expressions $\\widehat{f}$ and $\\mathcal{F} f$ essentially do not differ, but there is a slight nuance in the use of symbols. When emphasis is on practical calculation, formulas, and quick notation, $\\widehat{f}$ is preferred, and when the properties and order of operations as an operator are important, $\\mathcal{F}$ is preferred.\nLet us define $f,g \\in L^{1}$.\nFor $a \\in \\mathbb{R}$ $$ \\mathcal{F} T_{a} = E_{-a} \\mathcal{F} $$\nFor $b \\in \\mathbb{R}$ $$ \\mathcal{F} E_{b} = T_{b} \\mathcal{F} $$\nFor $c \\ne 0$ $$ \\mathcal{F} D_{c} = D_{1/c} \\mathcal{F} $$\nConvolution: $$ \\mathcal{F} ( f \\ast\\ g) = (\\mathcal{F} f \\cdot \\mathcal{F} g) $$\n1~3: $T_{a}, E_{b}, D_{c}$ refers to Translation, Modulation, Dilation.\n4: $\\ast$ is Convolution convolution, and $\\cdot$ simply means the product of functions. In other words, for $\\gamma \\in \\mathbb{R}$\n$$ \\widehat{f \\ast\\ g} (\\gamma) = \\widehat{f} (\\gamma) \\widehat{g} (\\gamma) $$\nLet $f , g \\in L^{2}$.\nNorm: $$ \\left\\| \\mathcal{F} f \\right\\|_{2} = \\left\\| f \\right\\|_{2} $$\nInner Product:\n$$ \\langle \\mathcal{F} f , \\mathcal{F} g \\rangle = \\langle f , g \\rangle $$\nThe above properties are well-known ones in Fourier analysis, represented again in the language of operator theory.\nProof Refer to here for the proofs of 1~4.\n‚ñ†\nSee Also Derivation of Fourier Transform Various Definitions and Notations of Fourier Transform Various Interpretations of Fourier Transform Ole Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p126-127\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1640,"permalink":"https://freshrimpsushi.github.io/en/posts/1640/","tags":null,"title":"Operators as Fourier Transforms"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Theorem Let $X$ be a compact metric space, $Y$ be a metric space, and $f:X\\to Y$ be continuous. Then $f(X)$ is compact.\nThe compactness condition cannot be omitted.\nProof Let $\\left\\{ O_\\alpha \\right\\}$ be an open cover of $f(X)$. Since $f$ is continuous, by the equivalence condition, each preimage $f^{-1}(O_{\\alpha})$ is also an open set in $X$. Therefore, $\\left\\{ f^{-1}(O_{\\alpha}) \\right\\}$ is an open cover of $X$, and since $X$ is compact,\n$$ X \\subset f^{-1}(O_{\\alpha_{1}})\\cup \\cdots \\cup f^{-1}(O_{\\alpha_{n}}) $$\nthere exists $\\alpha_{1},\\cdots,\\alpha_{n}$ satisfying the above equation. Thus, by the definition of preimage, the following is true:\n$$ f(X) \\subset O_{\\alpha_{1}}\\cup \\cdots \\cup O_{\\alpha_{n}} $$\nHence, $f(X)$ is compact.\n‚ñ†\nCorollary Let $X$ be a compact metric space, and $\\mathbf{f} :X\\to \\mathbb{R}^{k}$ be continuous. Then $\\mathbf{f}(X)$ is closed and bounded. Also, $\\mathbf{f}$ is bounded.\nDefinition Given a real-valued function $\\mathbf{f}: E \\to \\mathbb{R}^{k}$, if for every $x \\in E$\n$$ \\left|\\mathbf{f}(x) \\right| \\le M $$\nthere exists a real $M$ satisfying the above condition, then $\\mathbf{f}$ is called bounded.\nProof By the equivalent condition for compactness in Euclidean space and the theorem above, $\\mathbf{f}(X)$ is closed and bounded. Since $\\mathbf{f}(X)$ is bounded, $\\mathbf{f}$ is also bounded.\n‚ñ†\n","id":1724,"permalink":"https://freshrimpsushi.github.io/en/posts/1724/","tags":null,"title":"Continuity and Compactness in Metric Spaces"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definitions Let\u0026rsquo;s define a function $f : E \\to Y$ for two metric spaces $\\left( X , d_{X} \\right)$, $\\left( Y , d_{Y} \\right)$ and a subset $E\\subset X$.\nLet\u0026rsquo;s say $p \\in E$. For any $\\varepsilon \u0026gt; 0$, if there exists $\\delta\u0026gt;0$ such that\n$$ x \\in E \\quad \\text{and} \\quad d_{X}(p, x ) \u0026lt; \\delta \\implies d_{Y}(f(p) , f(x) ) \u0026lt; \\varepsilon $$\nis satisfied, then $f$ is said to be continuous at $p \\in E$. If $f$ is continuous at every point of $E$, $f$ is called a continuous function on $E$.\nFor any $ \\varepsilon \u0026gt; 0$, if there exists $\\delta\u0026gt;0$ such that\n$$ d_{X}(x_{1}, x_{2} ) \u0026lt; \\delta \\land x_{1}, x_{2} \\in E \\implies d_{Y}(f(x_{1}) , f(x_{2}) ) \u0026lt; \\varepsilon $$\nis satisfied, then $f$ is said to be uniformly continuous on $E$.\n$\\land$ is a logical \u0026lsquo;and\u0026rsquo; represented by the logical conjunction symbol. Explanation Continuity and uniform continuity can be defined beyond $\\mathbb{R}$ for metric spaces. What\u0026rsquo;s different from continuity in $\\mathbb{R}$ is that it is possible to generalize by changing $d_{1}$ and $d_{2}$.\nOn the other hand, a more sophisticated expression is used, such that for any $B_{d_{Y}} (f(p) , \\varepsilon )$, if there exists $B_{d_{X}} (p , \\delta)$ which satisfies $f(B_{d_{X}} (p , \\delta)) \\subset B_{d_{Y}} (f(p) , \\varepsilon )$, then $f$ is said to be continuous at $p \\in X$. Although it might seem too abstract and intimidating at first, you might find this expression becomes more comfortable as you keep observing it. Considering the generalization to topological spaces, it might be better to become accustomed sooner rather than later.\nTheorem: Equivalent Conditions of a Continuous Function For a function $f:X \\to Y$, the following conditions are equivalent.\n$f : X \\to Y$ is continuous.\n$\\forall x \\in X,\\ \\displaystyle \\lim_{n \\to \\infty} p_{n} = p \\implies \\lim_{n \\to \\infty} f(p_{n}) = f(p)$\nFor all open sets $O$ in $Y$, $f^{-1} ( O )$ is an open set in $X$.\nFor all closed sets $C$ in $Y$, $f^{-1} ( C )$ is a closed set in $X$.\nThese characteristics can be useful in proving that a given function is continuous.\nAt first glance, the image above seems like a counterexample to the fourth condition. For the closed interval $[c,d]$, its preimage $f^{-1} [c,d]$ is $(a,b)$, and as we know, $(a,b)$ is an open interval. However, since $f : (a,b) \\to \\mathbb{R}$, $(a,b)$ becomes the entire space, and the entire space is a closed set, so it does not contradict the proposition.\n","id":384,"permalink":"https://freshrimpsushi.github.io/en/posts/384/","tags":null,"title":"Continuous and Uniformly Continuous in Metric Spaces"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Theorem 1 For two metric spaces $(X,d_{X})$ and $(Y,d_{Y})$, suppose that $E\\subset X$ and $p \\in E$, and $f : E \\to Y$. Then, the following three propositions are equivalent.\n(1a) $f$ is continuous at $p$.\n(1b) $ \\lim \\limits_{x \\to p} f(x)=f(p)$.\n(1c) For $\\lim \\limits_{n\\to\\infty} p_{n}=p$ that is $\\left\\{ p_{n} \\right\\}$, $\\lim \\limits_{n\\to\\infty} f(p_{n})=f(p)$.\nProof (1a) $\\iff$ (1b)\nThis is trivial by the definition of limit and continuity. ‚ñ†\n(1b) $\\iff$ (1c)\n‚ñ†\n","id":1722,"permalink":"https://freshrimpsushi.github.io/en/posts/1722/","tags":null,"title":"Equivalent Conditions for a Function to Be Continuous in a Metric Space"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Theorem Let $X$ be a compact metric space, and let $f : X \\to \\mathbb{R}$ be continuous. Then, it is as follows.\n$$ M = \\sup \\limits_{x\\in X} f(x),\\quad m=\\inf \\limits_{x \\in X}f(x) $$\nThen,\n$$ M=f(p),\\quad m=f(q) $$\nthere exists a $q,p\\in X$ that satisfies this. In other words: for every $x$,\n$$ f(q)\\le f(x) \\le f(p) $$\nthere exists a $q,p \\in X$ that satisfies this. This is called the extreme value theorem.\nExplanation The compactness condition is necessary.\nThis theorem guarantees that $f(X)$ includes the maximum and minimum values of $f$. Without any conditions, by the definition of supremum and infimum, there is no guarantee that $M$, $m$ are included in $f(X)$, but the assumption that $X$ is compact and $f$ is continuous makes $M,m\\in f(X)$ valid.\nProof Since $f$ is continuous in a compact space, $f(X)$ is compact. According to the equivalent condition for compactness in Euclidean space, $f(X)$ is a closed and bounded set of real numbers.\nAuxiliary theorem\nLet $E$ be a non-empty set of real numbers and bounded above. And let $y=\\sup E$. Then, $y \\in \\overline{E}$. Furthermore, if $E$ is closed, then $y \\in E$.\nThen, the proof is complete by the auxiliary theorem.\n‚ñ†\nSee Also Extreme value theorem in topological spaces ","id":1725,"permalink":"https://freshrimpsushi.github.io/en/posts/1725/","tags":null,"title":"Maximum and Minimum Theorem in Metric Spaces"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Theorem Let $(X,d_{X})$ be a compact metric space, $(Y,d_{Y})$ a metric space, and $f:X\\to Y$ continuous. Then, $f$ is uniformly continuous on $X$.\nExplanation The condition of being compact cannot be omitted.\nProof Suppose we are given any positive number $\\varepsilon \u0026gt;0$. Since $f$ is assumed to be continuous, by definition, for each point $p\\in X$, there exists a positive number $\\delta_{p}$ satisfying the following equation:\n$$ \\forall q\\in X,\\quad d_{X}(p,q)\u0026lt;\\delta_{p} \\implies d_{Y}(f(p),f(q))\u0026lt;\\frac{\\varepsilon}{2} $$\nNow consider the following set:\n$$ N_{p}:= \\left\\{ q : d_{X}(p,q)\u0026lt;\\frac{1}{2}\\delta_{p} \\right\\} $$\nSince $p \\in N_{p}$, the collection of all $N_{p}$ becomes an open cover of $X$. Since $X$ is assumed to be compact, there exists $p_{1},\\cdots,p_{n}$ satisfying the following equation:\n$$ \\begin{equation} X \\subset N_{p_{1}}\\cup \\cdots \\cup N_{p_{n}} \\tag{2} \\label{eq1} \\end{equation} $$\nLet us now set $\\delta=\\frac{1}{2} \\min (\\delta_{p_{1}},\\cdots,\\delta_{p_{n}})$. Then, $\\delta$ is clearly positive. Now consider two points $p,q \\in X$ satisfying $d_{X}(p,q)\u0026lt;\\delta$. Then, by $\\eqref{eq1}$, there exists $m(1\\le m \\le n)$ satisfying $p \\in N_{p_{m}}$. Therefore, the following holds:\n$$ d_{X}(p,p_{m}) \\le \\frac{1}{2}\\delta_{p_{m}} $$\nThen, the following equation holds:\n$$ d_{X}(q,p_{m}) \\le d_{X}(q,p) + d_{X}(p,p_{m}) \u0026lt; \\delta + \\frac{1}{2}\\delta_{p_{m}} \\le \\delta _{p_{m}} $$\nTherefore,\n$$ d_{X}(p,q)\u0026lt;\\delta \\implies d_{Y}(f(p),f(q))\\le d_{Y}(f(p),f(p_{m})) + d_{Y}(f(p_{m}),f(q))\u0026lt;\\frac{1}{2}\\varepsilon+\\frac{1}{2}\\varepsilon=\\varepsilon $$\nThus, $f$ is uniformly continuous.\n‚ñ†\n","id":1727,"permalink":"https://freshrimpsushi.github.io/en/posts/1727/","tags":null,"title":"Proof that Continuous Functions on Compact Metric Spaces are Uniformly Continuous"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definition Let $\\left\\{ p_{n} \\right\\}$ be a sequence of points in a metric space $(X,d)$. If for every positive number $\\varepsilon$, there exists a positive number $N$ such that\n$$ n\\ge N,\\ m\\ge N \\implies d(p_{n},p_{m})\u0026lt;\\varepsilon $$\nis satisfied, then $\\left\\{ p_{n} \\right\\}$ is called a Cauchy sequence.\nIf every Cauchy sequence in a metric space $X$ converges to a point in $X$, then $X$ is called a complete space.\nExplanation From the following theorem, it can be seen that every compact metric space and Euclidean space is complete.\nTheorem (a) In a metric space, every converging sequence is a Cauchy sequence.\n(b) Let $X$ be a compact metric space and $\\left\\{ p_{n} \\right\\}$ be a Cauchy sequence in $X$. Then, $\\left\\{ p_{n} \\right\\}$ converges to some $p\\in X$.\n(c) In $\\mathbb{R}^{k}$, all Cauchy sequences converge.\n(a) and (b) together imply \u0026lsquo;In a compact metric space, converging sequences and Cauchy sequences are equivalent.\u0026rsquo;\nProof (a) Let $p_{n} \\to p$ and $\\varepsilon \u0026gt;0$ be given. Then, there exists $N$ satisfying $\\forall n \\ge N,\\ d(p,p_{n})\u0026lt;\\varepsilon$. Therefore, the following is satisfied:\n$$ d(p_{n},p_{m}) \\le d(p_{n},p)+d(p,p_{m})\u0026lt;2\\varepsilon,\\quad \\forall m,n\\ge N $$\nTherefore, by definition, $\\left\\{ p_{n} \\right\\}$ is a Cauchy sequence.\n‚ñ†\n(b) Let $\\left\\{ p_{n} \\right\\}$ be a Cauchy sequence in the compact metric space $X$. And let it be said for any natural number $N$:\n$$ E_{N}=\\left\\{ p_{N},p_{N+1},p_{N+2},\\cdots\\right\\} $$\nThen, the following is satisfied:\n$$ \\begin{equation} \\lim \\limits_{N\\to\\infty}\\mathrm{diam\\ }\\overline{E_{N}}=0 \\label{eq1} \\end{equation}$$\nMoreover, $\\overline{E_{N}}$ is a closed subset of the compact space $X$, so $\\overline{E_{N}}$ is compact. It is also evident that the following equation is satisfied:\n$$ E_{N}\\supset E_{N+1} \\quad \\text{and} \\quad \\overline{E_{N}}\\supset \\overline{E_{N+1}} $$\nTherefore, from the above conditions, it can be seen that there exists a unique $p \\in X$ satisfying $\\forall N \\in \\mathbb{N},\\ p \\in \\overline{E_{N}}$1. Now, let $\\varepsilon \u0026gt;0$ be given. Then, by $\\eqref{eq1}$,\n$$ N \\ge N_{0}\\implies \\mathrm{diam\\ }\\overline{E_{N}}\u0026lt; \\varepsilon $$\na $N_{0}$ exists that satisfies the condition. But since $\\mathrm{diam\\ }\\overline{E}=\\mathrm{diam\\ }E$ and $p \\in \\overline{E_{N}}$, for all $q \\in E_{N}$, $d(p,q)\u0026lt;\\varepsilon$ is satisfied. In other words, the following is implied:\n$$ n \\ge N_{0} \\implies d(p_{n},p)\u0026lt; \\varepsilon $$\nThis is the definition of $p_{n}\\to p$, therefore $\\lim \\limits_{n\\to\\infty} p_{n}=p$\n‚ñ†\n(c) Let $\\left\\{ \\mathbf{x}_{n} \\right\\}$ be a Cauchy sequence in $\\mathbb{R}^{k}$. Assuming $E_{N}$ as the proof of (b), then\n$$ \\mathrm{diam\\ } E_{N} \u0026lt;1 $$\nlet a $N$ be chosen that satisfies the condition. And\n$$ r=\\max \\left\\{ d(\\mathbf{x}_{N},\\mathbf{x}_{1}),\\ d(\\mathbf{x}_{N},\\mathbf{x}_{2}),\\ \\cdots,\\ d(\\mathbf{x}_{N},\\mathbf{x}_{N-1}),\\ 1 \\right\\} $$\nsince $\\forall m,n \\in \\mathbb{N},\\ d(\\mathbf{x}_{n},\\mathbf{x}_{m}) \u0026lt;r$, $\\left\\{ \\mathbf{x}_{n} \\right\\}$ is bounded. Therefore, $\\overline{ \\left\\{ \\mathbf{x}_{n} \\right\\}}$ is a closed and bounded subset of $\\mathbb{R}^{k}$, hence compact. Therefore, $\\left\\{ \\mathbf{x}_{n} \\right\\}$ is a Cauchy sequence in a compact space, and thus by (b), $\\left\\{ \\mathbf{x}_{n} \\right\\}$ converges.\n‚ñ†\nSee theorem (b)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1718,"permalink":"https://freshrimpsushi.github.io/en/posts/1718/","tags":null,"title":"Convergence of Cauchy Sequences in Metric Spaces"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definitions1 If there exists a point $p \\in X$ such that the sequence $\\left\\{ p_{n} \\right\\}$ of points in a metric space $(X,d)$ satisfies the following condition, the sequence $\\left\\{ p_{n} \\right\\}$ is said to converge to $p$, and it is denoted by $p_{n} \\rightarrow p$ or $\\lim \\limits_{n\\to \\infty}p_{n}=p$.\n$$ \\forall \\varepsilon \u0026gt;0,\\ \\exists N\\in \\mathbb{N}\\ \\mathrm{s.t}\\ n\\ge N \\implies d(p_{n},p)\u0026lt;\\varepsilon $$\nIf $\\left\\{ p_{n} \\right\\}$ does not converge, it diverges. Furthermore, the set of all $p_{n}$s is called the range of $\\left\\{ p_{n} \\right\\}$. If the range of $\\left\\{ p_{n} \\right\\}$ is bounded, the sequence $\\left\\{ p_{n} \\right\\}$ is said to be bounded.\nTheorems Let $\\left\\{ p_{n} \\right\\}$ be a sequence in a metric space $(X,d)$.\n(a) A necessary and sufficient condition for $p_{n}\\to p$ is that every neighborhood of $p$ contains all terms of $\\left\\{ p_{n} \\right\\}$ except for a finite number.\n(b) If $p_{n} \\to p$ and $p_{n} \\to p^{\\prime}$, then $p=p^{\\prime}$.\n(c) If $\\left\\{ p_{n} \\right\\}$ converges, it is bounded.\n(d) Given $E\\subset X$. If $p$ is a limit point of $E$, there exists a sequence $\\left\\{ p_{n} \\right\\}$ from $E$ that satisfies $p=\\lim \\limits_{n \\to \\infty}p_{n}$. Furthermore, if $\\left\\{ p_{n} \\right\\}$ is a set of distinct points, the converse also holds.\nProofs (a) $(\\implies)$\nSuppose $p_{n} \\to p$. Given any positive number $\\varepsilon \u0026gt;0$, let $V$ be a neighborhood of $p$ with radius $\\varepsilon$. According to the definition of a neighborhood, the following holds:\n$$ d(p,q)\u0026lt;\\varepsilon\\quad \\implies q\\in V $$\nHowever, by assumption, there exists a $N$ that satisfies the following condition for the given $\\varepsilon$:\n$$ \\forall n \\ge N,\\ d(p_{n},p) \u0026lt;\\varepsilon $$\nTherefore, all points $p_{n}$, except for a finite number, are included in $V$.\n$(\\impliedby)$\nAssume every neighborhood of $p$ contains all but a finite number of points $\\left\\{ p_{n} \\right\\}$. Given any positive number $\\varepsilon\u0026gt;0$, let $V$ be a neighborhood of $p$ with radius $\\varepsilon$. Then, by assumption, a $N$ exists that satisfies the following condition:\n$$ n \\ge N \\implies p_{n}\\in V $$\nSince $V$ is a neighborhood of $p$, the following holds:\n$$ \\forall n \\ge N,\\quad d(p_{n},p)\u0026lt;\\varepsilon $$\nTherefore, $p_{n}\\to p$.\n‚ñ†\n(b) Given any positive number $\\varepsilon \u0026gt;0$. By assumption, there exist two positive numbers $N$, $N^{\\prime}$ that satisfy the following condition:\n$$ \\begin{align*} n\\ge N \u0026amp; \\implies d(p_{n},p) \u0026lt;\\frac{\\varepsilon}{2} \\\\ n\\ge N^{\\prime} \u0026amp; \\implies d(p_{n},p) \u0026lt;\\frac{\\varepsilon}{2} \\end{align*} $$\nThen, for $n \\ge \\max(N,N^{\\prime})$, the following equation holds:\n$$ d(p,p^{\\prime}) \\le d(p,p_{n}) + d(p_{n},p^{\\prime})\u0026lt;\\varepsilon $$\nSince $\\varepsilon$ is any positive number,\n$$ d(p,p^{\\prime})=0 $$\nand by the definition of distance, $p=p^{\\prime}$.\n‚ñ†\n(c) Assume that $\\left\\{ p_{n} \\right\\}$ converges to $p$. By assumption, there exists a positive number $N$ that satisfies the following equation:\n$$ n \\ge N \\implies d(p_{n},p)\u0026lt;1 $$\nNow, let\n$$ r=\\max \\left\\{ 1,\\ d(p_{1},p),\\ \\cdots,\\ d(p_{N},p) \\right\\} $$\nThen, for all $n$,\n$$ d(p_{n},p)\\le r $$\nso $\\left\\{ p_{n} \\right\\}$ is bounded.\n‚ñ†\n(d) $(\\implies)$\nAssume $E\\subset X$ and that $p$ is a limit point of $E$. By definition of a limit point, for each $n$,\n$$ d(p_{n},p) \u0026lt; \\frac{1}{n} $$\nexists a $p_{n}\\in E$. Now, given any positive number $\\varepsilon \u0026gt;0$ and $N\\varepsilon\u0026gt;1$ satisfying $N$, the following holds for $ n \u0026gt;N$:\n$$ d(p_{n},p)\u0026lt; \\frac{1}{n}\u0026lt;\\frac{N}{n}\\varepsilon\u0026lt;\\varepsilon $$\nTherefore, $\\left\\{ p_{n} \\right\\}$ converges to $p$.\n$(\\impliedby)$\nAssume there exists a sequence $\\left\\{ p_{n} \\right\\}$ of distinct points from $E$ that satisfies $p=\\lim \\limits_{n\\to\\infty}p_{n}$. Then, for all positive numbers $\\varepsilon \u0026gt;0$,\n$$ n \\ge N \\implies d(p_{n},p)\u0026lt; \\varepsilon $$\nexists a $N$. Let $V_{\\varepsilon}$ be a neighborhood of $p$ with radius $\\varepsilon$. Thus, $V_{\\varepsilon}$ includes $p_{n} \\in E (n\\ge N)$ which is not $p$, proving $p$ is a limit point of $E$.\n‚ñ†\nWalter Rudin, Principles of Mathematical Analysis (3rd Edition, 1976), p47-48, 55-58\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1713,"permalink":"https://freshrimpsushi.github.io/en/posts/1713/","tags":null,"title":"Convergence of Sequences in Metric Spaces"},{"categories":"Ìï®Ïàò","contents":"Definition The function defined as $\\zeta : \\mathbb{C} \\setminus \\left\\{ 1 \\right\\} \\to \\mathbb{C}$ is called the Riemann Zeta Function. $$ \\zeta (s) := \\sum_{n \\in \\mathbb{N}} n^{-s} = \\prod_{p : \\text{prime}} \\left( 1- {p^{-s}} \\right)^{-1} $$\nRelated Theorems [0] Ramanujan Sum: If $\\displaystyle \\sum_{n \\in \\mathbb{N}} x^{n-1} = {{ 1 } \\over { 1-x }}$ is accepted to hold even at $|x| = 1$, $$ \\zeta (0) = 1 + 1 + 1 + 1 + \\cdots = - {{ 1 } \\over { 2 }} $$\n[1] Ore\u0026rsquo;s Proof: The reason why $\\zeta (1)$ is undefined is as follows. $$ \\zeta (1) = \\sum_{n \\in \\mathbb{N}} {{ 1 } \\over { n }} = \\infty $$\n[2] Euler\u0026rsquo;s Proof: $$ \\zeta (2) = \\sum_{n \\in \\mathbb{N}} {{ 1 } \\over { n^{2} }} = {{ \\pi^{2} } \\over { 6 }} $$\n[a] Relation with the Gamma Function: If $\\text{Re} (s) \u0026gt; 1$, then $$ \\zeta (s) \\Gamma (s) = \\mathcal{M} \\left[ {{ 1 } \\over { e^{x} - 1 }} \\right] (s) = \\int_{0}^{\\infty} {{ x^{s-1} } \\over { e^{x} - 1 }} dx $$\n[b] Relation with the Dirichlet Eta Function: $$ \\eta (s) := \\sum_{n \\in \\mathbb{N}} (-1)^{n-1} n^{-s} $$\nDescription The zeta function converges for complex numbers greater than $1$ in real part, that is, for $\\text{Re} (s) \u0026gt; 1$ within $s$ and has a relation with the Gamma Function. It has been particularly of interest in number theory and complex analysis and is infamous for being the subject of the Riemann Hypothesis.\n","id":1626,"permalink":"https://freshrimpsushi.github.io/en/posts/1626/","tags":null,"title":"Riemann Zeta Function"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definition For $a_{i},b_{i} \\in \\mathbb{R} (1\\le i \\le k)$, the set $I=[a_{1},b_{1}] \\times [a_{2},b_{2}]\\times \\cdots \\times [a_{k},b_{k}]$ is called a $k$-cellk-cell. Here, $\\times$ represents the Cartesian product of sets.\nTheorem 1 Let\u0026rsquo;s assume a sequence of closed intervals on $\\mathbb{R}$, $\\left\\{ I_{n} \\right\\}$, satisfies $I_{n}\\supset I_{n+1}\\ (n=1,2,\\cdots)$. Then, the following holds true.\n$$ \\bigcap_{i=1}^{\\infty}I_{n}\\ne \\varnothing $$\nProof Let\u0026rsquo;s denote $I_{n}=[a_{n},b_{n}]$. Also, let $E=\\left\\{ a_{n} : n=1,2,\\cdots \\right\\}$. Then, $E\\ne \\varnothing$ and is upper bounded by $b_{1}$1. Now, let\u0026rsquo;s define $x=\\sup E$. For any two positive numbers $m$ and $n$,\n$$ a_{n} \\le a_{m+n} \\le b_{m+n} \\le b_{m} $$\nholds true, thus for all $n$, $x\\le b_{n}$. Moreover, since $x$ is the upper bound of $E$, it\u0026rsquo;s trivial that for all $n$, $a_{n} \\le x$. Therefore, for all $n$, $a_{n}\\le x \\le b_{n}$, which implies $x\\in I_{n}\\ \\forall n$. Thus,\n$$ x\\in \\bigcap _{i=1}^{n}I_{n} $$\n‚ñ†\nTheorem 2 Let $\\left\\{ I_{n} \\right\\}$ be a sequence of $k$-cells satisfying $I_{n}\\supset I_{n+1}(n=1,2,\\cdots)$. Then, $\\bigcap _{i=1}^{n}I_{n}\\ne\\varnothing$.\nTheorem 2 is an extension of Theorem 1 to $\\mathbb{R}^{k}$.\nProof Let\u0026rsquo;s represent $I_{n}$ as follows.\n$$ I_{n}=\\left\\{ \\mathbf{x}=(x_{1},\\cdots,x_{k}) : a_{n,j} \\le x_{j} \\le b_{nj},\\quad(1\\le j \\le k;\\ n=1,2,\\cdots) \\right\\} $$\nThat is, $I_{n}=I_{n,1}\\times \\cdots\\times I_{n,k}\\ (I_{n,j}=[a_{n,j},b_{n,j}])$. By Theorem 1, for each $I_{n,j}$, there exists $x_{j}^{\\ast}\\in I_{n,j} \\ (a_{n,j} \\le x_{j}^{\\ast} \\le b_{n,j})$. Therefore,\n$$ \\mathbf{x^{\\ast}} =(x_{1}^{\\ast},\\cdots ,x_{k}^{\\ast})\\in I_{n} ,\\quad (n=1,2,\\cdots) $$\n‚ñ†\nTheorem 3 Every $k$-cell is compact.\nProof Let\u0026rsquo;s consider an arbitrary $k$-cell $I$ as follows.\n$$ I=I^{1}\\times \\cdots \\times I^{k}=[a_{1},b_{1}]\\times \\cdots \\times [a_{k},b_{k}] $$\nAnd let\u0026rsquo;s define as follows.\n$$ \\mathbf{x}=(x_{1},\\cdots,x_{k}) \\quad \\text{and} \\quad a_{j} \\le x_{j} \\le b_{j}(1\\le j \\le k) $$\nNow, let\u0026rsquo;s consider $\\delta$ as follows.\n$$ \\delta =\\left( \\sum \\limits_{j=1}^{k}(b_{j})-a_{j})^{2} \\right)^{{\\textstyle \\frac{1}{2}}}=|\\mathbf{b}-\\mathbf{a}| $$\nHere, $\\mathbf{a}=(a_{1},\\cdots,a_{n})$, $\\mathbf{b}=(b_{1},\\cdots,b_{n})$. Then, $\\delta$ is the same as the distance between $\\mathbf{b}$ and $\\mathbf{a}$. Therefore,\n$$ |\\mathbf{x}-\\mathbf{y}| \\le \\delta \\quad \\forall \\mathbf{x},\\mathbf{y}\\in I $$\nis valid. Now the proof begins in earnest, using a proof by contradiction. That is, assume that a $k$-cell is not compact. Then, by the definition of compactness, it\u0026rsquo;s the same as assuming that some open cover $\\left\\{ O_{\\alpha} \\right\\}$ of $I$ does not have a finite subcover. Let\u0026rsquo;s denote $c_{j}=(a_{j}+b_{j})/2$. Then, each $I^{j}$ can be divided into $[a_{j},c_{j}]$, $[c_{j},b_{j}]$ using $c_{j}$, creating $2^{k}$ 1-cells. Their union is naturally $I$, and by assumption, at least one of them cannot be covered by any finite subcover of $\\left\\{ O_{\\alpha} \\right\\}$. Let\u0026rsquo;s call this cell $I_{1}$. Then, by choosing intervals in the same way as $I_{1}$ was chosen from $I$, we can obtain a sequence $\\left\\{ I_{n} \\right\\}$ satisfying the following three rules.\n$(\\mathrm{i})$ $I\\supset I_{1} \\supset I_{2}\\supset \\cdots$\n$(\\mathrm{ii})$ Each $I_{n}$ cannot be covered by any finite subcover of $\\left\\{ O_{\\alpha} \\right\\}$.\n$(\\mathrm{iii})$ $|\\mathbf{x}-\\mathbf{y}|\\le 2^{-n}\\delta,\\quad \\forall \\mathbf{x},\\mathbf{y}\\in I_{n}$\nThen, by $(\\mathrm{i})$ and Theorem 2, there exists $\\mathbf{x}^{\\ast}\\in I_{n}$ for all $n$. Since $\\left\\{ O_{\\alpha} \\right\\}$ is an open cover of $I$, there is some $\\alpha$ for which $\\mathbf{x}^{\\ast}\\in O_{\\alpha}$. As $O_{\\alpha}$ is an open set, there exists $r\u0026gt;0$ such that $|\\mathbf{x}^{\\ast}-\\mathbf{y}|\u0026lt;r \\implies \\mathbf{y}\\in O_{\\alpha}$. On the other hand, $n$ can be sufficiently large so that $2^{-n}\\delta\u0026lt;r$. Then, by $(\\mathrm{iii})$, $I_{n}\\subset O_{\\alpha}$. However, this contradicts $(\\mathrm{ii})$, so the assumption is wrong. Therefore, every $k$-cell is compact.\n‚ñ†\nFrom the above facts, we can prove the following useful theorems.\nEquivalent Conditions for Compactness in Euclidean Space For a subset $E\\subset \\mathbb{R}^{k}(\\mathrm{or}\\ \\mathbb{C}^{k})$ of the real (or complex) space, the following three propositions are equivalent.\n(a) $E$ is closed and bounded.\n(b) $E$ is compact.\n(c) Every infinite subset\nof $E$ has an accumulation point $p \\in E$.\nHere, the equivalence of (a) and (b) is known as the Heine-Borel theorem. An $E$ satisfying (c) is said to be \u0026lsquo;compact with respect to accumulation points\u0026rsquo; or \u0026lsquo;having the Bolzano-Weierstrass property\u0026rsquo;. The equivalence of (b) and (c) holds in metric spaces but is not generally true in topological spaces.\nProof (a) $\\implies$ (b)\nAssuming (a), there exists a $k$-cell $I$ such that $E \\subset I$. Since $I$ is compact, and a closed subset of a compact set is compact, $E$ is compact.\n(b) $\\implies$ (c)\nThis is proved by contradiction.\nLet $S$ be an infinite subset of a compact set $E$. Assume that $S$ has no accumulation point. Then, every $p\\in E$ has at most one point of $S$ in its neighborhood $N_{p}$. When $p \\in S$, that one point is $p$ itself. And this implies that the open cover $\\left\\{ N_{p} \\right\\}$ does not have a finite subcover for $S$. Since $S \\subset E$, similarly, there\u0026rsquo;s no finite subcover for $E$ either, contradicting the assumption that $E$ is compact. Hence, $S$ has an accumulation point $p \\in E$.\n(c) $\\implies$ (a)\nThis is proved by contradiction.\npart 1. $E$ is bounded\nLet\u0026rsquo;s assume $E$ is not bounded. Then, $E$ contains points $\\mathbf{x}_{n}$ satisfying the following inequality.\n$$ |\\mathbf{x}_{n}| \u0026gt;n\\quad (n=1,2,\\cdots) $$\nLet\u0026rsquo;s denote $S=\\left\\{ \\mathbf{x}_{n} :n=1,2,\\cdots\\right\\}$. $S$ is infinite and obviously does not have an accumulation point in $\\mathbb{R}^{k}, contradicting (c). Thus, $E$ is bounded.\npart 2. $E$ is closed\nLet\u0026rsquo;s assume $E$ is not closed. Then, by definition, there exists an accumulation point $\\mathbf{x}_{0}$ of $E$ that is not included in $E. Now, for $n=1,2,\\cdots$, let\u0026rsquo;s consider $\\mathbf{x}_{n} \\in E$ satisfying the following conditions.\n$$ \\left|\\mathbf{x}_{n}-\\mathbf{x}_{0} \\right| \u0026lt; {\\textstyle \\frac{1}{n}} $$\nLet\u0026rsquo;s denote the set of such $\\mathbf{x}_{n}$ as $S$. $S$ is infinite and has $\\mathbf{x}_{0}$ as an accumulation point. If $\\mathbf{x}_{0}$ is the only accumulation point of $S$, then $\\mathbf{x}_{0}\\notin E$ contradicts (c), proving $E$ is closed. Now, consider $\\mathbf{y} \\ne\\mathbf{x}_{0}$ in $\\mathbb{R}^{k}$. Then,\n$$ \\begin{align*} \\left| \\mathbf{x}_{n} - \\mathbf{y} \\right| \u0026amp; \\ge \\left|\\mathbf{x}_{0} - \\mathbf{y} \\right| - \\left|\\mathbf{x}_{n}-\\mathbf{x}_{0} \\right| \\\\ \u0026amp; \\ge \\left| \\mathbf{x}_{0} - \\mathbf{y} \\right| -\\frac{1}{n} \\end{align*} $$\nFor sufficiently large $n$, the following holds true.\n$$ \\begin{equation} \\left| \\mathbf{x}_{n} - \\mathbf{y} \\right| \\ge \\left| \\mathbf{x}_{0}- \\mathbf{y} \\right|-\\frac{1}{n} \\ge \\frac{1}{2}\\left|\\mathbf{x}_{0}-\\mathbf{y} \\right| \\label{eq1} \\end{equation} $$\nFurthermore, as $n$ increases, $\\mathbf{x}_{n}$ gets closer to $\\mathbf{x}_{0}$. This fact, along with $\\eqref{eq1}$, implies that we can find a neighborhood of $\\mathbf{y}$ that contains no point other than $\\mathbf{y}$ as $n$ increases. Thus, $\\mathbf{y}$ is not an accumulation point of $S$, proving $\\mathbf{x}_{0}$ is the only accumulation point of $S. This contradicts (c), proving $E$ is closed.\n‚ñ†\nBolzano-Weierstrass Theorem Every bounded infinite subset of $\\mathbb{R}^{k}$ has an accumulation point $p \\in \\mathbb{R}^{k}$.\nProof Let $E$ be a bounded infinite subset of $\\mathbb{R}^{k}$. Since $E$ is bounded, there exists a $k$-cell $I$ such that $E \\subset I. As $k$-cells are compact, $I$ is compact. Then, by the equivalent condition for compactness in $\\mathbb{R}^{k}$ $(b)\\implies (c)$, $E$ has an accumulation point $p \\in I \\subset \\mathbb{R}^{k}$.\n‚ñ†\nSee Also Specialization of Riesz\u0026rsquo;s Theorem Riesz\u0026rsquo;s Theorem in normed spaces indicates the compactness of the closed unit ball $\\overline{B (0;1)}$ as an equivalent condition of finite dimension. The $k$-cell $[0,1]^{k}$ in Euclidean space is compact, and since there is a homeomorphism with the closed unit ball, Riesz\u0026rsquo;s theorem can be seen as a generalization of the compactness of the $k$-cell.\nAny $b_{n}$ will suffice.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1711,"permalink":"https://freshrimpsushi.github.io/en/posts/1711/","tags":null,"title":"Every k Cell is Compact"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Definition1 Translation is defined as $T_{a} : L^{2} \\to L^{2}$ for $a \\in \\mathbb{R}$ as follows. $$ \\left( T_{a} f \\right) (x) := f(x-a) $$\nModulation is defined as $E_{b} : L^{2} \\to L^{2}$ for $b \\in \\mathbb{R}$ as follows. $$ \\left( E_{b} f \\right) (x) := e^{2 \\pi i b x} f(x) $$\nDilation is defined as $D_{c} : L^{2} \\to L^{2}$ for $c \u0026gt; 0$ as follows. $$ \\left( D_{c} f \\right) (x) := {{ 1 } \\over { \\sqrt{c} }} f \\left( {{ x } \\over { c }} \\right) $$\nExplanation The linear operators mentioned above are commonly used in the space of $L^{2}$. Although in Korean they are translated to translation, modulation, and dilation respectively, it might be easier to understand them directly in English due to the mathematical context.\nThe $e^{2 \\pi i b x}$ multiplied in modulation is literally an abstracted rotation.\nThe $\\displaystyle {{ 1 } \\over { \\sqrt{c} }}$ multiplied in dilation can be seen as being squared to match the norm $\\left\\| \\cdot \\right\\|_{2}$. Especially for $c = 1/2$, $D$ defined as follows plays a special role.\n$$ ( D f ) (x) := \\sqrt{2} f (2x) $$\n$D$ is written as follows for convenience with respect to $j \\in \\mathbb{Z}$.\n$$ ( D^{j} f ) (x) := \\sqrt{2}^{j} f \\left( 2^{j} x \\right) $$\nProperties For all $a, b \\in \\mathbb{R}$, $c \u0026gt; 0$, and $f,g \\in L^{1}$,\n$T_{a} , E_{b}, D_{c}$ is a bounded linear operator.\nInverse operator: $T_{a} , E_{b}, D_{c}$ is unitary.\nCommutation relations:\n$$ (T_{a} E_{b} f ) (x) = e^{- 2 \\pi i b a} (E_{b} T_{a} f ) (x) \\\\ (T_{a} D_{c} f ) (x) = (D_{c} T_{a/c} f ) (x) \\\\ (D_{c} E_{b} f ) (x) = (E_{b/c} D_{c} f ) (x) $$\nRelation with Fourier transform:\n$$ \\mathcal{F} T_{a} = E_{-a} \\mathcal{F} \\\\ \\mathcal{F} E_{b} = T_{b} \\mathcal{F} \\\\ \\mathcal{F} D_{c} = D_{1/c} \\mathcal{F} $$\nRegarding $D$, the following can be obtained about $j, k \\in \\mathbb{Z}$ as corollaries of the above theorems.\n$$ T_{k} D^{j} = D^{j} T_{2^{j} k } \\\\ D^{j} T_{k} = T_{2^{-j}k} D^{j} \\\\ \\left( D^{j} \\right)^{ \\ast } = D^{-j} $$\nProof 1. Part 1. Linear\nFor all $f,g \\in L^{2}$ and $\\alpha , \\beta \\in \\mathbb{C}$,\n$$ \\begin{align*} T_{a} \\left( \\alpha f + \\beta g \\right)(x) =\u0026amp; \\left( \\alpha f + \\beta g \\right)(x-a) \\\\ =\u0026amp; \\alpha f (x-a) + \\beta g (x-a) \\\\ =\u0026amp; \\alpha T_{a} f (x) + \\beta T_{a} g (x) \\end{align*} $$\nTherefore, $T_{a}$ is linear.\n$$ \\begin{align*} E_{b} \\left( \\alpha f + \\beta g \\right)(x) =\u0026amp; e^{ 2 \\pi i b x } \\left( \\alpha f + \\beta g \\right)(x) \\\\ =\u0026amp; \\alpha e^{ 2 \\pi i b x } f (x) + \\beta e^{ 2 \\pi i b x } g (x) \\\\ =\u0026amp; \\alpha E_{b} f (x) + \\beta E_{b} g (x) \\end{align*} $$\nTherefore, $E_{b}$ is linear.\n$$ \\begin{align*} D_{c} \\left( \\alpha f + \\beta g \\right)(x) =\u0026amp; {{ 1 } \\over { \\sqrt{c} }} \\left( \\alpha f + \\beta g \\right) \\left( {{ x } \\over { c }} \\right) \\\\ =\u0026amp; \\alpha {{ 1 } \\over { \\sqrt{c} }} f (x) + \\beta {{ 1 } \\over { \\sqrt{c} }} g (x) \\\\ =\u0026amp; \\alpha D_{c} f (x) + \\beta D_{c} g (x) \\end{align*} $$\nTherefore, $D_{c}$ is linear.\nPart 2. Bounded\nSubstitute as $t := x - a$,\n$$ \\begin{align*} \\left\\| T_{a} f \\right\\|_{2} =\u0026amp; \\int_{-\\infty}^{\\infty} \\left| T_{a} f \\left( x \\right) \\right|^{2} dx \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} \\left| f \\left( x - a \\right) \\right|^{2} dx \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} \\left| f \\left( t \\right) \\right|^{2} dt \\\\ =\u0026amp; \\left\\| f \\right\\|_{2} \\end{align*} $$\nTherefore, $T_{a}$ is bounded. Since $\\left| e^{2 \\pi i b x } \\right| =1$,\n$$ \\begin{align*} \\left\\| E_{b} f \\right\\|_{2} =\u0026amp; \\int_{-\\infty}^{\\infty} \\left| E_{b} f \\left( x \\right) \\right|^{2} dx \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} \\left| e^{2 \\pi i b x } f \\left( x \\right) \\right|^{2} dx \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} 1 \\cdot \\left| f \\left( t \\right) \\right|^{2} dt \\\\ =\u0026amp; \\left\\| f \\right\\|_{2} \\end{align*} $$\nTherefore, $E_{b}$ is bounded. Substitute as $t := x/c$,\n$$ \\begin{align*} \\left\\| D_{c} f \\right\\|_{2} =\u0026amp; \\int_{-\\infty}^{\\infty} \\left| D_{c} f \\left( x \\right) \\right|^{2} dx \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} \\left| {{ 1 } \\over { \\sqrt{c} }} f \\left( {{ x } \\over { c }} \\right) \\right|^{2} dx \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} {{ 1 } \\over { c }} \\left| f \\left( t \\right) \\right|^{2} c dt \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} \\left| f \\left( t \\right) \\right|^{2} dt \\\\ =\u0026amp; \\left\\| f \\right\\|_{2} \\end{align*} $$\nTherefore, $D_{c}$ is bounded.\n‚ñ†\nOle Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p120-122\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1616,"permalink":"https://freshrimpsushi.github.io/en/posts/1616/","tags":null,"title":"Translation in L2 Spaces: Translations, Modulations, Dilations"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Theorem1 In a metric space $X$, a closed (relative to $X$) subset of a compact set $K$ is compact.\nProof Given a metric space $X$ where $F\\subset K \\subset X$ and assuming $F$ is a closed set in $X$ and $K$ is a compact set. Let $\\left\\{ V_{\\alpha}\\right\\}$ be an arbitrary open cover of $F$. By adding $F^{c}$, let\u0026rsquo;s denote it as $\\Omega=\\left\\{ V_\\alpha \\right\\}\\cup \\left\\{ F^{c} \\right\\}$. Then $\\Omega$ becomes an open cover of $K$. Assuming that $K$ is compact, then there exists some finite subcover $\\Phi$ of $\\Omega$ such that:\n$$ F \\subset K\\subset \\Phi $$\nLet\u0026rsquo;s consider two cases.\ncase 1. $F^{c} \\notin \\Phi$\nThen $\\Phi$ is a finite subcover of $\\left\\{ V_{\\alpha} \\right\\}$, so $F$ is compact.\ncase 2. $F^{c} \\in \\Phi$\nIf we set $\\Psi=\\Omega \\setminus \\left\\{ F^{c} \\right\\}$ then since $F^{c}\\cap F=\\varnothing$, it still holds that $F\\subset \\Psi$. Therefore $\\Psi$ is a finite subset of $\\left\\{ V_{\\alpha} \\right\\}$, making $F$ compact.\n‚ñ†\nCorollary In a metric space $X$, suppose $F$ is closed and $K$ is compact. Then $F\\cap K$ is compact.\nProof $F \\cap K$ is a closed set as it is the intersection of closed sets. Thus, as a closed subset of the compact set $K$, it is compact.\n‚ñ†\nWalter Rudin, Principles of Mathmatical Analysis (3rd Edition, 1976), p37-38\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1706,"permalink":"https://freshrimpsushi.github.io/en/posts/1706/","tags":null,"title":"Closed Subsets of Compact Sets in Metric Spaces are Compact"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definition Open Cover Given a metric space $(X,d)$ and a subset $E\\subset X$, a set $\\left\\{ O_{\\alpha} \\right\\}$ of open sets that satisfies the following equation is called an open cover of $E$.\n$$ E\\subset \\bigcup _{\\alpha} O_{\\alpha} $$\nA subset of an open cover is called a subcover. In particular, a subcover with a finite number of elements is called a finite subcover.\nCompactness Let\u0026rsquo;s assume we have a subset $K$ of a metric space $X$. If every open cover of $K$ has a finite subcover, then $K$ is said to be compact. In other words, if we can still have an open cover by selecting a finite number of open sets, then $K$ is called compact. Expressing this condition with an equation, if for some $\\alpha_{1},\\cdots ,\\alpha_{n}$\n$$ K\\subset O_{\\alpha_{1}}\\cup \\cdots O_{\\alpha_{n}} $$\nis satisfied, then $K$ is compact.\nExplanation The importance of compactness comes from whether a given space retains or loses the property of being compact depending on what the entire space is considered to be. That is to say, compactness is an inherent quality of the set itself. Without going too far, even when observing the concept of openness, there is no guarantee that the property of being open is preserved when the entire space is expanded, hence the term relatively open exists. As one continues to study, it becomes apparent that the condition of being compact plays an important role in various theorems. Compactness is a property bestowed upon a set regardless of the entire space, as confirmed by the theorem below. First, we will use the term compact in $X$ when $K\\subset X$ is compact with respect to the entire space $X$.\nTheorem Consider two metric spaces $X$, $Y$ and suppose $K\\subset Y \\subset X$. Then the following two propositions are equivalent.\n(a) $K$ is compact in $X$.\n(b) $K$ is compact in $Y$.\nProof Lemma\nLet two metric spaces $X$, $Y$ be given, and suppose $E \\subset Y \\subset X$. Then the two following propositions are equivalent:$(d)$ $E$ is relatively open with respect to $Y$.$(e)$ For some open set $O_{X}$ of $X$, $E=Y \\cap O_{X}$ holds.\n(a) $\\Longrightarrow$ (b)\nAssume that $K$ is compact in $X$. Let $\\left\\{ O_{\\alpha}^{Y} \\right\\}$ be a set of open sets in $Y$ that satisfies $K\\subset \\bigcup_{\\alpha} O_{\\alpha}^{Y}$. In other words, assume $\\left\\{ O_{\\alpha}^{Y} \\right\\}$ to be any open cover of $K$ with respect to $Y$. Then, by the lemma,\n$$ O_{\\alpha}^{Y}=Y\\cap O_{\\alpha}^{X},\\quad \\forall \\alpha $$\nan open set $O_{\\alpha}^{X}$ in $X$ exists that satisfies the equation. Then $\\left\\{ O_{\\alpha}^{X} \\right\\}$ forms an open cover of $K$ with respect to $X$. Thus, by assumption, for some $\\alpha_{1},\\cdots,\\alpha_{n}$, the following equation holds:\n$$ K \\subset O_{\\alpha_{1}}^{X}\\cup\\cdots \\cup O_{\\alpha_{n}}^{X} $$\nHowever, since $K\\subset Y$, the following is true:\n$$ \\begin{align*} K \u0026amp; \\subset Y \\cap (O_{\\alpha_{1}}^{X}\\cup\\cdots \\cup O_{\\alpha_{n}}^{X}) \\\\ \u0026amp;= (Y \\cap O _{\\alpha_{1}}^{X})\\cup\\cdots \\cup(Y \\cap O_{\\alpha_{n}}^{X}) \\\\ \u0026amp;= O_{\\alpha_{1}}^{Y}\\cup\\cdots \\cup O_{\\alpha_{n}}^{Y} \\end{align*} $$\nTherefore, any arbitrary open cover $\\left\\{ O_{\\alpha}^{Y} \\right\\}$ of $K$ with respect to $Y$ has a finite subcover satisfying\n$$ K \\subset O_{\\alpha_{1}}^{Y}\\cup\\cdots \\cup O_{\\alpha_{n}}^{Y} $$\nhence, $K$ is compact in $Y$.\n(a) $\\Longleftarrow$ (b)\nSuppose that $K$ is compact in $Y$. Let $\\left\\{ O_{\\alpha}^{X} \\right\\}$ be a set of open sets in $X$ that satisfies $K\\subset \\bigcup_{\\alpha} O_{\\alpha}^{X}$. In other words, take $\\left\\{ O_{\\alpha}^{X} \\right\\}$ as any open cover of $K$ with respect to $X$. Then, set $O_{\\alpha}^{Y}$ as follows:\n$$ O_{\\alpha}^{Y}=Y\\cap O_{\\alpha}^{X},\\quad \\forall \\alpha $$\nBy the lemma, $O_{\\alpha}^{Y}$ becomes an open set in $Y$. Therefore, $\\left\\{ O_{\\alpha}^{Y} \\right\\}$ forms an open cover of $K$. Then, by assumption, for some $\\alpha_{1},\\cdots,\\alpha_{n}$, the following equation holds:\n$$ K \\subset O_{\\alpha_{1}}^{Y}\\cup \\cdots \\cup O_{\\alpha_{n}}^{Y} $$\nHowever, since for each $\\alpha$, $O_{\\alpha}^{Y} \\subset O_{\\alpha}^{X}$ is true, the following holds:\n$$ K\\subset O_{\\alpha_{1}}^{X}\\cup \\cdots \\cup O_{\\alpha_{n}}^{X} $$\nTherefore, as every arbitrary open cover always has a finite subcover, $K$ is compact in $X$.\n{{qed}}\nSee Also Compactness in Topological Spaces === ```markdown ## ÂÆöÁæ© ### „Ç™„Éº„Éó„É≥„Ç´„Éê„Éº [Ë∑ùÈõ¢Á©∫Èñì](../381) $(X,d)$„Å®ÈÉ®ÂàÜÈõÜÂêà $E\\subset X$„Åå‰∏é„Åà„Çâ„Çå„Åü„Å®„Åô„Çã„ÄÇ‰ª•‰∏ã„ÅÆÂºè„ÇíÊ∫Ä„Åü„Åô[ÈñãÈõÜÂêà](../1700)„ÅÆÈõÜÂêà $\\left\\\\{ O\\_{\\alpha} \\right\\\\}$„Çí $E$„ÅÆ**„Ç™„Éº„Éó„É≥„Ç´„Éê„Éº** „Å®Ë®Ä„ÅÜ„ÄÇ $$\rE\\subset \\bigcup \\_{\\alpha} O\\_{\\alpha}\r$$ --- „Ç™„Éº„Éó„É≥„Ç´„Éê„Éº„ÅÆÈÉ®ÂàÜÈõÜÂêà„ÇíÈÉ®ÂàÜ„Ç´„Éê„Éº„Å®Ë®Ä„ÅÜ„ÄÇÁâπ„Å´„ÄÅË¶ÅÁ¥†„ÅåÊúâÈôêÂÄã„ÅÆÈÉ®ÂàÜ„Ç´„Éê„Éº„ÇíÊúâÈôêÈÉ®ÂàÜ„Ç´„Éê„Éº„Å®Ë®Ä„ÅÜ„ÄÇ ### „Ç≥„É≥„Éë„ÇØ„Éà Ë∑ùÈõ¢Á©∫Èñì $X$„ÅÆÈÉ®ÂàÜÈõÜÂêà $K$„Åå‰∏é„Åà„Çâ„Çå„Åü„Å®„Åô„Çã„ÄÇ„ÇÇ„Åó $K$„ÅÆÂÖ®„Å¶„ÅÆ„Ç™„Éº„Éó„É≥„Ç´„Éê„Éº„Å´ÊúâÈôêÈÉ®ÂàÜ„Ç´„Éê„Éº„ÅåÂ≠òÂú®„Åô„Çå„Å∞„ÄÅ$K$„ÅØ**„Ç≥„É≥„Éë„ÇØ„Éà**„Åß„ÅÇ„Çã„Å®„ÅÑ„ÅÜ„ÄÇË®Ä„ÅÑÊèõ„Åà„Çã„Å®„ÄÅÊúâÈôêÂÄã„ÅÆÈõÜÂêà„Å†„ÅëÈÅ∏„Çì„Åß„ÇÇ„Åæ„Å†„Ç™„Éº„Éó„É≥„Ç´„Éê„Éº„Åß„ÅÇ„Çå„Å∞„ÄÅ$K$„Çí„Ç≥„É≥„Éë„ÇØ„Éà„Å®Ë®Ä„ÅÜ„ÄÇÂºè„ÅßË°®„Åô„Å®„ÄÅ‰Ωï„Çâ„Åã„ÅÆ $\\alpha\\_{1},\\cdots ,\\alpha\\_{n}$„Å´ÂØæ„Åó„Å¶ $$\rK\\subset O\\_{\\alpha\\_{1}}\\cup \\cdots O\\_{\\alpha\\_{n}}\r$$ „ÅåÊ∫Ä„Åü„Åï„Çå„Çå„Å∞„ÄÅ$K$„ÅØ„Ç≥„É≥„Éë„ÇØ„Éà„Åß„ÅÇ„Çã„ÄÇ ## Ë™¨Êòé „Ç≥„É≥„Éë„ÇØ„Éà„ÅåÈáçË¶Å„Åß„ÅÇ„ÇãÁêÜÁî±„ÅØ„ÄÅÂÖ®‰ΩìÁ©∫Èñì„Çí‰Ωï„Å´„Åô„Çã„Åã„Å´„Çà„Å£„Å¶„ÄÅ„Åù„ÅÆÈõÜÂêà„Åå„Ç≥„É≥„Éë„ÇØ„Éà„Å®„ÅÑ„ÅÜÊÄßË≥™„ÇíÂæó„Åü„ÇäÂ§±„Å£„Åü„Çä„Åô„Çã„Åã„Çâ„Åß„ÅÇ„Çã„ÄÇ„Å§„Åæ„Çä„ÄÅ**„Ç≥„É≥„Éë„ÇØ„Éà„ÅØ„Åù„ÅÆÈõÜÂêà„ÅåÊåÅ„Å§Âõ∫Êúâ„ÅÆÊÄßË≥™**„Å®„ÅÑ„ÅÜÊÑèÂë≥„Åß„ÅÇ„Çã„ÄÇ[ÈñãÊîæ](../1700)„Å®„ÅÑ„ÅÜÊ¶ÇÂøµ„ÇíË¶ã„Å¶„ÇÇ„ÄÅÂÖ®‰ΩìÁ©∫Èñì„ÇíÊã°Â§ß„Åô„ÇãÊôÇ„Å´„ÄÅÈñã„Åã„Çå„Å¶„ÅÑ„Çã„Å®„ÅÑ„ÅÜÊÄßË≥™„Åå‰øùÊåÅ„Åï„Çå„Çã‰øùË®º„Åå„Å™„ÅÑ„Åü„ÇÅ„Å´„ÄÅ[Áõ∏ÂØæÁöÑ„Å´Èñã„Åã„Çå„Å¶„ÅÑ„Çã](../1703)„Å®„ÅÑ„ÅÜË°®Áèæ„Åå„ÅÇ„Çã„ÄÇÂ≠¶„Å≥Á∂ö„Åë„Çã„Å®„ÄÅ[„Ç≥„É≥„Éë„ÇØ„Éà„Å®„ÅÑ„ÅÜÊù°‰ª∂„ÅåÊßò„ÄÖ„Å™ÂÆöÁêÜ„ÅßÈáçË¶Å„Å™ÂΩπÂâ≤„ÇíÊûú„Åü„Åô](../1728)„Åì„Å®„ÅåÂàÜ„Åã„Çã„ÄÇ„Ç≥„É≥„Éë„ÇØ„Éà„ÅØÂÖ®‰ΩìÁ©∫Èñì„Å®ÁÑ°Èñ¢‰øÇ„Å´ÈõÜÂêà„Å´‰∏é„Åà„Çâ„Çå„ÇãÊÄßË≥™„Åß„ÅÇ„Çã„Å®„ÄÅ‰ª•‰∏ã„ÅÆÂÆöÁêÜ„ÇíÈÄö„Åò„Å¶Á¢∫Ë™ç„Åß„Åç„Çã„ÄÇ„Åæ„Åö„ÄÅ$K\\subset X$„ÅåÂÖ®‰ΩìÁ©∫Èñì $X$„Å´ÂØæ„Åó„Å¶„Ç≥„É≥„Éë„ÇØ„Éà„Åß„ÅÇ„ÇãÊôÇ„ÄÅ$X$„Å´„Åä„ÅÑ„Å¶„Ç≥„É≥„Éë„ÇØ„Éà„Å®„ÅÑ„ÅÜË°®Áèæ„Çí‰Ωø„ÅÜ„ÄÇ ## ÂÆöÁêÜ ‰∫å„Å§„ÅÆË∑ùÈõ¢Á©∫Èñì $X$„ÄÅ$Y$„Å´„Å§„ÅÑ„Å¶ $K\\subset Y \\subset X$„Å®„Åô„Çã„ÄÇ„Åô„Çã„Å®„ÄÅ‰ª•‰∏ã„ÅÆ‰∫å„Å§„ÅÆÂëΩÈ°å„ÅØÂêåÂÄ§„Åß„ÅÇ„Çã„ÄÇ **(a)** $K$„ÅØ $X$„Åß„Ç≥„É≥„Éë„ÇØ„Éà„Åß„ÅÇ„Çã„ÄÇ **(b)** $K$„ÅØ $Y$„Åß„Ç≥„É≥„Éë„ÇØ„Éà„Åß„ÅÇ„Çã„ÄÇ ## Ë®ºÊòé \u0026gt; [Ë£úÂä©ÂÆöÁêÜ](../1703) \u0026gt; \u0026gt; ‰∫å„Å§„ÅÆË∑ùÈõ¢Á©∫Èñì $X$„ÄÅ$Y$„Åå‰∏é„Åà„Çâ„Çå„Åü„Å®„Åô„Çã„ÄÇ„Åù„Åó„Å¶ $E \\subset Y \\subset X$„Å®„Åô„Çã„ÄÇ„Åô„Çã„Å®„ÄÅ‰ª•‰∏ã„ÅÆ‰∫å„Å§„ÅÆÂëΩÈ°å„ÅØÂêåÂÄ§„Åß„ÅÇ„Çã„ÄÇ$(d)$ $E$„Åå $Y$„Å´ÂØæ„Åó„Å¶[Áõ∏ÂØæÁöÑ„Å´Èñã„Åã„Çå„Å¶„ÅÑ„Çã„ÄÇ](../1703)$(e)$ $X$„ÅÆ„ÅÇ„ÇãÈñãÈõÜÂêà $O\\_{X}$„Å´„Å§„ÅÑ„Å¶„ÄÅ$E=Y \\cap O\\_{X}$„ÅåÊàê„ÇäÁ´ã„Å§„ÄÇ - **(a)** $\\Longrightarrow$ **(b)** $K$„Åå $X$„Åß„Ç≥„É≥„Éë„ÇØ„Éà„Åß„ÅÇ„Çã„Å®‰ªÆÂÆö„Åô„Çã„ÄÇ$\\left\\\\{ O\\_{\\alpha}^{Y} \\right\\\\}$„Çí $Y$„ÅßÈñã„Åã„Çå„Å¶„ÅÑ„ÇãÈõÜÂêà„ÅÆÈõÜÂêà„Å®„Åó„ÄÅ$K\\subset \\bigcup\\_{\\alpha} O\\_{\\alpha}^{Y}$„ÇíÊ∫Ä„Åü„Åô„Å®„Åô„Çã„ÄÇ„Å§„Åæ„Çä„ÄÅ$\\left\\\\{ O\\_{\\alpha}^{Y} \\right\\\\}$„Çí $K$„ÅÆ$Y$„Å´ÂØæ„Åô„Çã‰ªªÊÑè„ÅÆ„Ç™„Éº„Éó„É≥„Ç´„Éê„Éº„Å®„Åô„Çã„Çè„Åë„Åß„ÅÇ„Çã„ÄÇ„Åô„Çã„Å®„ÄÅË£úÂä©ÂÆöÁêÜ„Å´„Çà„Å£„Å¶ $$\rO\\_{\\alpha}^{Y}=Y\\cap O\\_{\\alpha}^{X},\\quad \\forall \\alpha\r$$ $X$„ÅßÈñã„Åã„Çå„Å¶„ÅÑ„ÇãÈõÜÂêà $O\\_{\\alpha}^{X}$„ÅåÂ≠òÂú®„Åô„Çã„ÄÇ„Åô„Çã„Å®„ÄÅ$\\left\\\\{ O\\_{\\alpha}^{X} \\right\\\\}$„ÅØ $K$„ÅÆ$X$„Å´ÂØæ„Åô„Çã„Ç™„Éº„Éó„É≥„Ç´„Éê„Éº„Å®„Å™„Çã„ÄÇ„Åô„Çã„Å®„ÄÅ‰ªÆÂÆö„Å´„Çà„Çä„ÄÅ‰Ωï„Çâ„Åã„ÅÆ $\\alpha\\_{1},\\cdots,\\alpha\\_{n}$„Å´ÂØæ„Åó„Å¶‰ª•‰∏ã„ÅÆÂºè„ÅåÊàêÁ´ã„Åô„Çã„ÄÇ $$\rK \\subset O\\_{\\alpha\\_{1}}^{X}\\cup\\cdots \\cup O\\_{\\alpha\\_{n}}^{X}\r$$ „Åó„Åã„Åó„ÄÅ$K\\subset Y$„Å™„ÅÆ„Åß„ÄÅÊ¨°„ÅåÊàêÁ´ã„Åô„Çã„ÄÇ $$\r\\begin{align*}\rK \u0026amp; \\subset Y \\cap (O\\_{\\alpha\\_{1}}^{X}\\cup\\cdots \\cup O\\_{\\alpha\\_{n}}^{X}) \\\\\\ \u0026amp;= (Y \\cap O \\_{\\alpha\\_{1}}^{X})\\cup\\cdots \\cup(Y \\cap O\\_{\\alpha\\_{n}}^{X}) \\\\\\ \u0026amp;= O\\_{\\alpha\\_{1}}^{Y}\\cup\\cdots \\cup O\\_{\\alpha\\_{n}}^{Y}\r\\end{align*}\r$$ „Åó„Åü„Åå„Å£„Å¶„ÄÅ$K$„ÅÆ $Y$„Å´ÂØæ„Åô„Çã‰ªªÊÑè„ÅÆ„Ç™„Éº„Éó„É≥„Ç´„Éê„Éº $\\left\\\\{ O\\_{\\alpha}^{Y} \\right\\\\}$„ÅÆÊúâÈôêÈÉ®ÂàÜ„Ç´„Éê„Éº„Åå $$\rK \\subset O\\_{\\alpha\\_{1}}^{Y}\\cup\\cdots \\cup O\\_{\\alpha\\_{n}}^{Y}\r$$ „ÇíÊ∫Ä„Åü„Åô„ÅÆ„Åß„ÄÅ$K$„ÅØ $Y$„Åß„Ç≥„É≥„Éë„ÇØ„Éà„Åß„ÅÇ„Çã„ÄÇ - **(a)** $\\Longleftarrow$ **(b)** $K$„Åå $Y$„Åß„Ç≥„É≥„Éë„ÇØ„Éà„Åß„ÅÇ„Çã„Å®‰ªÆÂÆö„Åô„Çã„ÄÇ$\\left\\\\{ O\\_{\\alpha}^{X} \\right\\\\}$„Çí $K\\subset \\bigcup\\_{\\alpha} O\\_{\\alpha}^{X}$„ÇíÊ∫Ä„Åü„Åô $X$„ÅÆÈñãÈõÜÂêà„ÅÆÈõÜÂêà„Å®„Åô„Çã„ÄÇ„Å§„Åæ„Çä„ÄÅ$\\left\\\\{ O\\_{\\alpha}^{X} \\right\\\\}$„Çí $K$„ÅÆ$X$„Å´ÂØæ„Åô„Çã‰ªªÊÑè„ÅÆ„Ç™„Éº„Éó„É≥„Ç´„Éê„Éº„Å®„Åó„Å¶ÈÅ∏„Å∂„Çè„Åë„Åß„ÅÇ„Çã„ÄÇ„Åù„Åó„Å¶„ÄÅ$O\\_{\\alpha}^{Y}$„Çí‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å´Ë®≠ÂÆö„Åô„Çã„ÄÇ $$\rO\\_{\\alpha}^{Y}=Y\\cap O\\_{\\alpha}^{X},\\quad \\forall \\alpha\r$$ „Åô„Çã„Å®„ÄÅË£úÂä©ÂÆöÁêÜ„Å´„Çà„Å£„Å¶ $O\\_{\\alpha}^{Y}$„ÅØ $Y$„ÅßÈñã„Åã„Çå„Å¶„ÅÑ„ÇãÈõÜÂêà„Å´„Å™„Çã„ÄÇ„Åó„Åü„Åå„Å£„Å¶„ÄÅ$\\left\\\\{ O\\_{\\alpha}^{Y} \\right\\\\}$„ÅØ $K$„ÅÆ„Ç™„Éº„Éó„É≥„Ç´„Éê„Éº„Å´„Å™„Çã„ÄÇ„Åô„Çã„Å®„ÄÅ‰ªÆÂÆö„Å´„Çà„Çä„ÄÅ‰Ωï„Çâ„Åã„ÅÆ $\\alpha\\_{1},\\cdots,\\alpha\\_{n}$„Å´ÂØæ„Åó„Å¶‰ª•‰∏ã„ÅÆÂºè„ÅåÊàêÁ´ã„Åô„Çã„ÄÇ $$\rK \\subset O\\_{\\alpha\\_{1}}^{Y}\\cup \\cdots \\cup O\\_{\\alpha\\_{n}}^{Y}\r$$ „Åó„Åã„Åó„ÄÅÂêÑ $\\alpha$„Å´ÂØæ„Åó„Å¶ $O\\_{\\alpha}^{Y} \\subset O\\_{\\alpha}^{X}$„Å™„ÅÆ„Åß„ÄÅÊ¨°„ÅåÊàêÁ´ã„Åô„Çã„ÄÇ $$\rK\\subset O\\_{\\alpha\\_{1}}^{X}\\cup \\cdots \\cup O\\_{\\alpha\\_{n}}^{X}\r$$ „Åó„Åü„Åå„Å£„Å¶„ÄÅ$K$„ÅÆ‰ªªÊÑè„ÅÆ„Ç™„Éº„Éó„É≥„Ç´„Éê„Éº„ÅåÂ∏∏„Å´ÊúâÈôêÈÉ®ÂàÜ„Ç´„Éê„Éº„ÇíÊåÅ„Å§„ÅÆ„Åß„ÄÅ$K$„ÅØ $X$„Åß„Ç≥„É≥„Éë„ÇØ„Éà„Åß„ÅÇ„Çã„ÄÇ ‚ñ†\n## ÂêåÊôÇ„Å´Ë¶ã„Çã - [‰ΩçÁõ∏Á©∫Èñì„Åß„ÅÆ„Ç≥„É≥„Éë„ÇØ„ÉàÊÄß](../489)[](../489) ","id":1705,"permalink":"https://freshrimpsushi.github.io/en/posts/1705/","tags":null,"title":"Compactness in Metric Spaces"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":" Let $(X,d)$ be a metric space. Suppose $p \\in X$ and $E \\subset X$.\nThe set that contains all $q$s satisfying $d(q,p)\u0026lt;r$ is defined as the neighborhood of point $p$ and is denoted by $N_{r}(p)$. Here $r$ is called the radius of $N_{r}(p)$. When it\u0026rsquo;s possible to omit the metric, it can also be denoted as $N_{p}$.\nIf every neighborhood of $p$ contains $q$s with $q\\ne p$ and $q\\in E$, then $p$ is called a limit point of $E$.\nIf all the limit points of $E$ are contained in $E$, then $E$ is said to be closed.\nIf there exists a neighborhood $N$ of $p$ satisfying $N\\subset E$, then $p$ is called an interior point of $E$.\nIf all the points of $E$ are interior points of $E$, then $E$ is said to be open.\nSummary Let\u0026rsquo;s define $\\left\\{ O_{\\alpha} \\right\\}$ as the collection of open sets and $\\left\\{ C_{\\alpha} \\right\\}$ as the collection of closed sets in the metric space $X$. Then\n(a) The union of open sets $\\bigcup_{\\alpha} O_{\\alpha}$ is also an open set.\n(b) The intersection of closed sets $\\bigcap_{\\alpha} C_{\\alpha}$ is also a closed set.\n(c) The finite intersection of open sets $\\bigcap_{i=1}^{n}O_{i}$ is also an open set.\n(d) The finite union of closed sets $\\bigcup _{i=1}^{n} C_{i}$ is also a closed set.\nWithout the condition of being finite, $(c)$ and $(d)$ do not hold. This can be shown through a counterexample.\nProof (a) Let $O=\\bigcup_{\\alpha} O_{\\alpha}$. If $p \\in O$, for some $\\alpha$, $p \\in O_{\\alpha}$. Therefore, by the definition of an open set, $p$ is an interior point of $O_{\\alpha}$. Also, by the definition of an interior point, $p$ is an interior point of $O$. For any $p\\in O$, since $p$ is an interior point of $O$, $O$ is an open set.\n‚ñ†\n(b) De Morgan\u0026rsquo;s Theorem Let $\\left\\{ E_{\\alpha}\\right\\}$ be a collection of sets $E_{\\alpha}$. Then the following formula holds. $$ \\left( \\bigcup \\limits_{\\alpha}E_{\\alpha} \\right)^{c}=\\bigcap \\limits_{\\alpha} (E_{\\alpha})^{c} $$\nThe proof is introduced below.\nBy De Morgan\u0026rsquo;s theorem, the following holds.\n$$ \\left( \\bigcap_{\\alpha} C_{\\alpha} \\right)^{c}=\\bigcup_{\\alpha}(C_{\\alpha})^{c} \\tag{1} $$\nSince $C_{\\alpha}$ is a closed set, $(C_{\\alpha})^{c}$ is an open set. Therefore, by (a), $\\bigcup_{\\alpha}(C_{\\alpha})^{c}=\\left( \\bigcap_{\\alpha} C_{\\alpha} \\right)^{c}$ is an open set. Hence, $\\bigcap_{\\alpha} C_{\\alpha}$, being the complement of an open set, is a closed set.\n‚ñ†\n(c) Let $O=\\bigcap_{i=1}^{n}O_{i}$. Then, for any point $p\\in O$, $p\\in O_{i}\\ (i=1,\\cdots,n)$ holds for all $i$. Therefore, by the definition of an open set and an interior point, for each $i$,\n$$ N_{i} \\subset O_{i} \\quad (i=1,\\cdots,n) $$\na neighborhood of $p$ with radius $r_{i}$ exists. Let\u0026rsquo;s denote this by $r=\\min (r_{1},\\cdots,r_{n})$. Then, let $N=N_{r}(p)$. Since $N$ is the neighborhood with the smallest radius, the following holds.\n$$ N\\subset O_{i} \\quad (i=1,\\cdots,n) $$\nThus, $N \\subset O$ holds and by the definition of an interior point, $p$ is an interior point of $O$. For any $p\\in O$, since $p$ is always an interior point of $O$, $O$ is an open set.\n‚ñ†\n(d) By De Morgan\u0026rsquo;s theorem, the following holds.\n$$ \\left( \\bigcup_{i=1}^{n}C_{i} \\right)^{c} = \\bigcap _{i=1}^{n} (C_{i})^{c} $$\nSince $C_{i}$ is closed, by auxiliary theorem 2, $(C_{i})^{c}$ is open. Then, by $(c)$, $\\bigcap_{i=1}^{n}(C_{i})^{c}=\\left( \\bigcup _{i=1}^{n}C_{i} \\right)^{c}$ is an open set. Therefore, again by auxiliary theorem 2, $\\bigcup _{i=1}^{n}C_{i}$ is a closed set.\n‚ñ†\nProof of De Morgan\u0026rsquo;s Theorem Proof using truth tables\npart 1. $\\left( \\bigcup \\limits_{\\alpha}E_{\\alpha} \\right)^{c} \\subset \\bigcap \\limits_{\\alpha} (E_{\\alpha})^{c}$\nLet $x\\in \\left( \\bigcup \\limits_{\\alpha}E_{\\alpha} \\right)^{c}$. Then, by the definition of the complement, the following holds.\n$$ \\begin{align*} \u0026amp;\u0026amp; x \u0026amp;\\notin \\bigcup \\limits_{\\alpha}E_{\\alpha} \\\\ \\implies\u0026amp;\u0026amp; x\u0026amp;\\notin E_{\\alpha}\\quad \u0026amp;\\forall \\alpha \\\\ \\implies\u0026amp;\u0026amp; x\u0026amp;\\in(E_{\\alpha})^{c}\\quad \u0026amp;\\forall \\alpha \\\\ \\implies\u0026amp;\u0026amp; x\u0026amp;\\in \\bigcap\\limits_{\\alpha}(E_{\\alpha})^{c} \\end{align*} $$\nTherefore,\n$$ \\left( \\bigcup \\limits_{\\alpha}E_{\\alpha} \\right)^{c} \\subset \\bigcap \\limits_{\\alpha} (E_{\\alpha})^{c} $$\npart 2. $\\left( \\bigcup \\limits_{\\alpha}E_{\\alpha} \\right)^{c} \\supset \\bigcap \\limits_{\\alpha} (E_{\\alpha})^{c}$\nLet $x\\in \\bigcap \\limits_{\\alpha} (E_{\\alpha})^{c}$. Then, the following holds.\n$$ \\begin{align*} \u0026amp;\u0026amp; x \u0026amp;\\in (E_{\\alpha})^{c} \u0026amp;\\forall \\alpha \\\\ \\implies \u0026amp;\u0026amp; x \u0026amp;\\notin E_{\\alpha} \u0026amp;\\forall \\alpha \\\\ \\implies\u0026amp;\u0026amp; x\u0026amp;\\notin \\bigcup \\limits_{\\alpha}E_{\\alpha} \\\\ \\implies \u0026amp;\u0026amp; x \u0026amp;\\in \\left( \\bigcup \\limits_{\\alpha} E_{\\alpha} \\right)^{c} \\end{align*} $$\nTherefore,\n$$ \\left( \\bigcup \\limits_{\\alpha}E_{\\alpha} \\right)^{c} \\supset \\bigcap \\limits_{\\alpha} (E_{\\alpha})^{c} $$\n‚ñ†\n","id":1702,"permalink":"https://freshrimpsushi.github.io/en/posts/1702/","tags":null,"title":"Properties of Open and Closed Sets in Metric Spaces"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definitions Let\u0026rsquo;s say $(X,d)$ is a metric space. Suppose $p \\in X$ and $E \\subset X$.\nA set that contains all $q$ satisfying $d(q,p)\u0026lt;r$ is defined as the neighborhoodneighborhood of point $p$, denoted by $N_{r}(p)$. In this case, $r$ is called the radius of $N_{r}(p)$. If it\u0026rsquo;s permissible to omit the distance, it can also be denoted as $N_{p}$.\nIf every neighborhood of $p$ includes a $q$ that is $q\\ne p$ and $q\\in E$, then $p$ is called a limit pointlimit point of $E$.\nIf all limit points of $E$ are included in $E$, then $E$ is said to be closedclosed.\nIf there exists a neighborhood $N$ satisfying $N\\subset E$ for $p$, then $p$ is called an interior pointinterior point of $E$.\nIf every point of $E$ is an interior point of $E$, then $E$ is said to be openopen.\nThe set of all limit points of $E$ is called the derived setderived set of $E$, denoted by $E^{\\prime}$.\nThe union of $E$ and $E^{\\prime}$ is called the closureclosure, denoted by $\\overline{E}=E\\cup E^{\\prime}$.\nTheorem 1 For $A,B\\subset X$, the following equations hold:\n(1a) $A\\subset B \\implies A^{\\prime} \\subset B^{\\prime}$\n(1b) $(A\\cup B)^{\\prime}=A^{\\prime}\\cup B^{\\prime}$\n(1c) $(A \\cap B)^{\\prime} \\subset A^{\\prime}\\cap B^{\\prime}$\nProof (1a) Assume $A\\subset B$. And let $p\\in A^{\\prime}$. Then $p$ is a limit point of $A$, so by the definition of a limit point, every neighborhood $N$ of $p$ includes a $q$ that is $q\\ne p$ and $q\\in A$. Assuming $A\\subset B$, the statement means that every neighborhood $N$ of $p$ includes a $q$ that is $q\\ne p$ and $q\\in B$. Therefore, by the definition of a limit point, $p \\in B^{\\prime}$ is established.\n‚ñ†\n(1b) part 1. $A^{\\prime} \\cup B^{\\prime} \\subset (A\\cup B)^{\\prime}$\nSince $A\\subset A\\cup B$ and $B \\subset A\\cup B$, by $(a1)$, it follows that:\n$$ A^{\\prime} \\subset (A\\cup B)^{\\prime} \\quad \\text{and} \\quad B^{\\prime} \\subset (A \\cup B)^{\\prime} $$\nTherefore,\n$$ A^{\\prime} \\cup B^{\\prime} \\subset (A\\cup B)^{\\prime} $$\npart 2. $(A\\cup B)^{\\prime} \\subset A^{\\prime}\\cup B^{\\prime}$\nLet\u0026rsquo;s say $p \\in (A\\cup B)^{\\prime}$. Then, by the definition of a limit point, every neighborhood $N$ of $p$ includes a $q$ that is $q\\ne p$ and $q\\in A\\cup B$. Rewriting $q\\in A\\cup B$ as $q\\in A \\text{ or } q\\in B$ means $p \\in A^{\\prime} \\text{ or } p\\in B^{\\prime}$. Therefore, $p\\in A^{\\prime}\\cup B^{\\prime}$, so it follows that:\n$$ (A\\cup B)^{\\prime} \\subset A^{\\prime}\\cup B^{\\prime} $$\npart 3.\nCombining the above results yields:\n$$ A^{\\prime}\\cup B^{\\prime} = (A\\cup B)^{\\prime} $$\n‚ñ†\n(1c) Since $A\\cap B \\subset A$ and $A\\cap B \\subset B$, by (1a), it follows that:\n$$ (A\\cap B)^{\\prime} \\subset A^{\\prime} \\quad \\text{and} \\quad (A\\cap B)^{\\prime} \\subset B^{\\prime} $$\nTherefore,\n$$ (A\\cap B)^{\\prime} \\subset A^{\\prime}\\cap B^{\\prime} $$\n‚ñ†\nTheorem 2 For $A,B \\subset X$, the following equations hold:\n(2a) $A\\subset B \\implies \\overline{A} \\subset \\overline{B}$\n(2b) $\\overline{A\\cup B} = \\overline{A}\\cup \\overline{B}$\n(2c) $\\overline{A\\cap B} \\subset \\overline{A}\\cap \\overline{B}$\nProof (2a) Assuming $A \\subset B$, by (1a), $A^{\\prime} \\subset B^{\\prime}$ is established. Therefore,\n$$ \\overline{A} = A\\cup A^{\\prime} \\subset B \\cup B^{\\prime} = \\overline{B} $$\n‚ñ†\n(2b) part 1. $\\overline{A\\cup B}\\subset \\overline{A}\\cup \\overline{B}$\nLet\u0026rsquo;s say $p \\in \\overline{A\\cup B}$. This means $p\\in A\\cup B$ or $p \\in (A\\cup B)^{\\prime}$.\ncase 1-1. $p \\in A\\cup B$\nIn this case, $p \\in A$ or $p \\in B$. But since $A \\subset \\overline{A}$ and $B \\subset \\overline{B}$,\n$$ p\\in \\overline{A}\\ \\text{or} \\ p \\in \\overline{B}\\implies p \\in \\overline{A}\\cup \\overline{B} $$\ncase 1-2. $p\\in (A\\cup B)^{\\prime}$\nBy (1b), $p\\in (A\\cup B)^{\\prime}=A^{\\prime}\\cup B^{\\prime}$ is established. This means $p\\in A^{\\prime}$ or $p\\in B^{\\prime}$. But since $A^{\\prime} \\subset \\overline{A}$ and $B^{\\prime} \\subset \\overline{B}$, similarly to the previous case,\n$$ p\\in \\overline{A}\\ \\text{or} \\ p \\in \\overline{B}\\implies p \\in \\overline{A}\\cup\\overline{B} $$\nBy case 1-1, 1-2, the following is established:\n$$ \\overline{A\\cup B}\\subset \\overline{A}\\cup \\overline{B} $$\npart 2. $\\overline{A}\\cup \\overline{B} \\subset \\overline{A\\cup B}$\nSince $A \\subset A\\cup B$ and $B\\subset A\\cup B$, by $(b1)$, the following is established:\n$$ \\overline{A} \\subset \\overline{A\\cup B}\\quad \\text{and} \\quad \\overline{B}\\subset \\overline{A\\cup B} $$\nTherefore,\n$$ \\overline{A}\\cup \\overline{B} \\subset \\overline{A\\cup B} $$\n‚ñ†\n(2c) Let\u0026rsquo;s say $p \\in \\overline{A\\cap B}$. Then, $p\\in A\\cap B$ or $p\\in (A \\cap B)^{\\prime}$.\ncase 1. $p\\in A\\cap B$\nIn this case, $p \\in A$ while $p \\in B$. But since $A\\subset \\overline{A}$ and $B\\subset \\overline{B}$,\n$$ p\\in A \\ \\text{and} \\ \\ p \\in B \\implies p\\in \\overline{A} \\ \\text{and} \\ p \\in \\overline{B} \\implies p\\in \\overline{A}\\cap \\overline{B} $$\ncase 2. $p \\in (A\\cap B)^{\\prime}$\nBy (1a), $(A\\cap B)^{\\prime}\\subset A^{\\prime}$ and $(A\\cap B)^{\\prime} \\subset B^{\\prime}$ are established. But since $A^{\\prime}\\subset \\overline{A}$ and $B^{\\prime} \\subset \\overline{B}$,\n$$ p\\in A^{\\prime} \\ \\text{and} \\ p\\in B^{\\prime} \\implies p\\in \\overline{A}\\quad \\text{and} \\quad p\\in \\overline{B}\\implies p\\in \\overline{A}\\cap \\overline{B} $$\n‚ñ†\nTheorem 3 For metric spaces $(X,d)$ and $E \\subset X$, the following facts hold:\n(3a) $\\overline{E}$ is closed.\n(3b) $E=\\overline{E}$ being equivalent to $E$ being closed.\n(3c) For a closed set $F\\subset X$ satisfying $E\\subset F$, $\\overline{E} \\subset F$ holds.\n(3a) and (3c) imply that $\\overline{E}$ is the smallest closed subset of $X$ that includes $E$.\nProof (3a) Let\u0026rsquo;s say $p \\in X$ and $p \\notin \\overline{E}$. In other words, $p \\in (\\overline{E})^{c}$. Then $p$ is neither a point of $E$ nor of $E^{\\prime}$. Therefore, by the definition of an accumulation point, $p$ has at least one neighborhood $N$ where $N\\cap E=\\varnothing$ is true. Therefore, since $N\\subset (\\overline{E})^{c}$ and $p$ was any point of $(\\overline{E})^{c}$, by the definition of an interior point, every point of $(\\overline{E})^{c}$ is an interior point, which means $(\\overline{E})^{c}$ is an open set. Since $(\\overline{E})^{c}$ is an open set, $\\overline{E}$ is a closed set.1\n‚ñ†\n(3b) $(\\implies)$\nSince $E=\\overline{E}=E \\cup E^{\\prime}$, all accumulation points of $E$ are elements of $E$. This is the definition of a closed set, so $E$ is closed. Or it can be immediately understood from the definitions of closure and being closed.\n$(\\impliedby)$\nBy the definition of a closed set, all accumulation points of $E$ are included in $E$. Therefore, $\\overline{E}=E\\cup E^{\\prime}=E$\n‚ñ†\n(3c) Let $F$ be a closed set with $E\\subset F \\subset X$. Then, by (3b), $F^{\\prime} \\subset \\overline{F}=F$ is true. Also, by (2a), $E^{\\prime} \\subset F^{\\prime} \\subset F$ is true. Therefore, the following holds:\n$$ E \\subset F \\quad \\text{and} \\quad E^{\\prime}\\subset F $$\nTherefore,\n$$ E\\cup E^{\\prime} =\\overline{E} \\subset F $$\n‚ñ†\nTheorem 4 Let $E$ be a non-empty set of real numbers and suppose it is bounded above. Let $y=\\sup E$. Then, $y \\in \\overline{E}$ is true. Moreover, if $E$ is closed, then $y \\in E$ is true.\nProof If $y \\in \\overline{E}$ holds, then the subsequent propositions are trivial by (3a), so we will only prove $y \\in \\overline{E}$. The proof is divided into two cases.\ncase 1. $y \\in E$\n$$ y \\in E \\subset \\overline{E} $$\nTherefore, it holds.\ncase 2. $y \\notin E$\nThen, for every positive number $h\u0026gt;0$, there exists $x\\in E$ satisfying $y-h\u0026lt;x\u0026lt;y$. This means that every neighborhood of $y$, which is $N_{h}(y)$, must contain an element of $E$. Therefore, by definition, $y$ is an accumulation point of $E$. Thus, $y\\in E\\cup E^{\\prime}=\\overline{E}$\n‚ñ†\nRefer to Theorem 2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1701,"permalink":"https://freshrimpsushi.github.io/en/posts/1701/","tags":null,"title":"Closure and Derived Set in Metric Space"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definition Let\u0026rsquo;s say $(X,d)$ is a metric space. Suppose $p \\in X$ and $E \\subset X$.\nThe set that includes all $q$s satisfying $d(q,p)\u0026lt;r$ is defined as the neighborhoodneighborhood of point $p$ and is denoted as $N_{r}(p)$. Here, $r$ is called the radius of $N_{r}(p)$. If the distance can be omitted, it may also be denoted as $N_{p}$.\nIf all neighborhoods of $p$ contain $q$, which is $q\\ne p$ and $q\\in E$, then $p$ is called a limit pointlimit point of $E$.\nIf $p\\in E$ and $p$ is not a limit point of $E$, then $p$ is called an isolated pointisolated point of $E$.\nIf all limit points of $E$ are included in $E$, then $E$ is said to be closedclosed.\nIf there exists a neighborhood $N$ satisfying $N\\subset E$, then $p$ is called an interior pointinterior point of $E$.\nIf every point of $E$ is an interior point of $E$, then $E$ is said to be openopen.\nThe set that includes all $p$s that are $p \\in X$ and $p \\notin E$ is called the complementcomplement of $E$ and is denoted as $E^{c}$.\nIf $E$ is closed and every point of $E$ is a limit point of $E$, then $E$ is said to be perfectperfect.\nIf there exists a point $q\\in X$ and a real number $M$ satisfying $\\forall p\\in E,\\ d(p,q)\u0026lt;M$, then $E$ is said to be boundedbounded.\nIf every point of $X$ is either a limit point of $E$ or a point of $E$, then $E$ is said to be densedense in $X$.\nThe set of all limit points of $E$ is called the derived setderived set of $E$ and is denoted as $E^{\\prime}$.\nThe union of $E$ and $E^{\\prime}$ is called the closureclosure and is denoted as $\\overline{E}=E\\cup E^{\\prime}$.\nExplanation The concepts of openness, limit points, denseness, interior points, etc., mentioned above can be defined through different statements but are essentially the same. Why each concept is defined and named as such can be easily grasped by directly drawing them in one or two dimensions. An isolated point is defined as a point that is not a limit point, so it cannot be both an isolated and a limit point at the same time. Conversely, open and closed sets are defined based on separate conditions, so contrary to the intuitive feeling their names might convey, there can exist sets that are both open and closed, or neither open nor closed. An example of the former is $\\mathbb{R}^{2}$, and an example of the latter is $\\left\\{ {\\textstyle \\frac{1}{n}}\\ |\\ n\\in \\mathbb{N} \\right\\}$. Considering the definitions of interior points and neighborhoods, the condition for $x$ to be an interior point of $E$ is the same as the existence of some positive number $\\varepsilon\u0026gt;0$ such that\n$$ d(x,p) \u0026lt;\\varepsilon \\implies x \\in E $$\nis satisfied. Several theorems and proofs related to the above concepts are introduced, following the notation from the definitions.\nTheorem 1 All neighborhoods are open sets.\nProof Let\u0026rsquo;s say $E=N_{r}(p)$. Also, consider any $q \\in E$. Then, by the definition of a neighborhood, there must exist a positive real number $h$ that satisfies the following equation:\n$$ d(p,q)=r-h\u0026lt;r $$\nThen, by the definition of distance, for all $s$ that satisfy $d(q,s)\u0026lt;h$, the following equation holds:\n$$ d(p,s)\\le d(p,q)+d(q,s)\u0026lt;(r-h)+h=r $$\nTherefore, by the definition of a neighborhood, $s \\in E$ is true. This shows that any point $s$ within the neighborhood $N_{h}(q)$ of $q$ is an element of $E$. Hence, $N_{h}(q) \\subset E$, meaning $q$ is an interior point of $E$. Since we initially considered $q$ to be any point of $E$, all points of $E$ are interior points. Therefore, $E$ is an open set.\n‚ñ†\nTheorem 2 A set $E$ being an open set is equivalent to $E^c$ being a closed set.\nProof $(\\impliedby)$\nAssume $E^c$ is closed. Now, for any $p\\in E$, since $p \\notin E^c$ and by the definition of being closed, $p$ is not a limit point of $E^c$. Thus, there exists a neighborhood $N$ satisfying $N \\cap E^c=\\varnothing$. This implies $N \\subset E$ and, by the definition of an interior point, $p$ is an interior point of $E$. Since any $p\\in E$ is an interior point of $E$, by definition, $E$ is an open set.\n$(\\implies)$\nAssume $E$ is open. And let $p$ be a limit point of $E^{c}$. Then, by the definition of a limit point, every neighborhood of $p$ contains at least one point of $E^{c}$. Thus, every neighborhood of $p$ does not include $E$, which means $p$ is not an interior point of $E$. Since we assumed $E$ is open, $p\\notin E$ is true. Therefore, since all limit points $p$ of $E^{c}$ are included in $E^{c}$, $E^{c}$ is closed.\n‚ñ†\nTheorem 3 Let\u0026rsquo;s say $p$ is a limit point of $E$. Then, the neighborhood of $p$ contains infinitely many points of $E$.\nThis can be expressed differently as \u0026lsquo;A finite set does not have a limit point\u0026rsquo;, \u0026lsquo;A set with a limit point is an infinite set\u0026rsquo;.\nProof Assume the neighborhood $N$ of $p$ includes only a finite number of elements of $E$. And let $q_{1},q_{2},\\cdots,q_{n}$ be points of $N\\cap E$ that are not $p$. Also, let $r$ be the minimum of the distances between $p$ and $q_{i}$.\n$$ r= \\min \\limits _{1\\le i \\le n}d(p,q_{i}) $$\nSince each $q_{i}$ is different from $p$, all distances are positive, and the minimum of positive numbers is also positive, thus $r\u0026gt;0$ is true. Now, consider another neighborhood $N_{r}(p)$ of $p$. Then, by the definitions of neighborhood and distance, $N_{r}(p)$ contains no $q_{i}$. Thus, by the definition of a limit point, $p$ is not a limit point of $E$. This contradicts the fact that $p$ is a limit point of $E$. Therefore, by reductio ad absurdum, the assumption is incorrect, proving the theorem.\n‚ñ†\nCorollary A set with only a finite number of points does not have a limit point.\nTheorem 4 For a metric space $(X,d)$ and $E \\subset X$, the following facts hold: $(a)$ $\\overline{E}$ is closed.$(b)$ Being $E=\\overline{E}$ is equivalent to $E$ being closed.$(c)$ For all closed sets $F\\subset X$ satisfying $E\\subset F$, $\\overline{E} \\subset F$ holds.\n$(a)$ and $(c)$ imply that $\\overline{E}$ is the smallest closed subset of $X$ that contains $E$.\n","id":1700,"permalink":"https://freshrimpsushi.github.io/en/posts/1700/","tags":null,"title":"Neighborhood, Limit Point, Open, Closed in Metric Space"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 The continuous probability distribution $F \\left( r_{1} , r_{2} \\right)$, which has the following probability density function for degrees of freedom $r_{1}, r_{2} \u0026gt; 0$, is called the F-distribution. $$ f(x) = {{ 1 } \\over { B \\left( r_{1}/2 , r_{2} / 2 \\right) }} \\left( {{ r_{1} } \\over { r_{2} }} \\right)^{r_{1} / 2} x^{r_{1} / 2 - 1} \\left( 1 + {{ r_{1} } \\over { r_{2} }} x \\right)^{-(r_{1} + r_{2}) / 2} \\qquad , x \\in (0, \\infty) $$\n$B(r_{1} / 2, r_{2}/2)$ refers to the beta function. Basic Properties Moment Generating Function [1]: The F-distribution does not have a moment-generating function. Mean and Variance [2]: If $X \\sim F ( r_{1} , r_{2})$, then $$ \\begin{align*} E(X) =\u0026amp; {{ r_{2} } \\over { r_{2} - 2 }} \u0026amp; \\qquad , r_{2} \u0026gt; 2 \\\\ \\text{Var}(X) =\u0026amp; {{ 2 r_{2}^{2} (r_{1} + r_{2} - 2) } \\over { r_{1} (r_{2} -2)^{2} (r_{2} - 4) }} \u0026amp; \\qquad , r_{2} \u0026gt; 4 \\end{align*} $$ Theorem Let two random variables $U,V$ be independent with $U \\sim \\chi^{2} ( r_{1})$ and $V \\sim \\chi^{2} ( r_{2})$.\n$k$th Moment [a]: If $d_{2} \u0026gt; 2k$, then $\\displaystyle F := {{ U / r_{1} } \\over { V / r_{2} }}$ exists as the $k$th moment $$ E F^{k} = \\left( {{ r_{2} } \\over { r_{1} }} \\right)^{k} E U^{k} E V^{-k} $$ Derived from the Chi-Squared Distribution [b]: $${{ U / r_{1} } \\over { V / r_{2} }} \\sim F \\left( r_{1} , r_{2} \\right)$$ Derived from the Beta Distribution [c]: A random variable $X \\sim F \\left( r_{1}, r_{2} \\right)$ that follows the F-distribution with degrees of freedom $r_{1} , r_{2}$ is defined as $Y$, which follows the beta distribution $\\text{Best} \\left( {{ r_{1} } \\over { 2 }} , {{ r_{2} } \\over { 2 }} \\right)$. $$ Y := {{ \\left( r_{1} / r_{2} \\right) X } \\over { 1 + \\left( r_{1} / r_{2} \\right) X }} \\sim \\text{Beta} \\left( {{ r_{1} } \\over { 2 }} , {{ r_{2} } \\over { 2 }} \\right) $$ Derived from the t-Distribution [d]: A random variable $X \\sim t(\\nu)$ that follows the t-distribution with degrees of freedom $\\nu \u0026gt; 0$ is defined as $Y$, which follows the F-distribution $F (1,\\nu)$. $$ Y := X^{2} \\sim F (1,\\nu) $$ Reciprocality [e]: If $X \\sim F \\left( r_{1}, r_{2} \\right)$, then the distribution of its reciprocal is as follows. $$ {{ 1 } \\over { X }} \\sim F \\left( r_{2}, r_{1} \\right) $$ $\\chi^{2} \\left( r \\right)$ is a chi-squared distribution with degrees of freedom $r$. Explanation Just as the t-distribution is called the Student t-distribution, the F-distribution is also referred to as the Snedecor F-distribution, named after the statistician George Snedecor.2\nThe probability density function of the F-distribution may seem incredibly complex at first glance, but in reality, there is little need to manipulate the formula itself. Understanding the relationship with the chi-squared distribution is of utmost importance. Just as the chi-squared distribution can be used for goodness-of-fit tests, the F-distribution can be used to compare the variances of two populations. As can be directly seen in theorem [b], since the F-distribution is expressed as a ratio of data following the chi-squared distribution, if this statistic deviates too much from $1$, it can be inferred that the variances of the two distributions are different.\nProof [1] The existence of a moment-generating function for a random variable means that the $k$th moment exists for all $k \\in \\mathbb{N}$. However, as per theorem [a], the $k$th moment of the F-distribution exists when $k \u0026lt; d_{2} / 2$, thus a moment-generating function cannot exist.\n‚ñ†\n[2] Use the moment formula stated in [a].\n‚ñ†\n[a] Substituting with $t = {{ r_{1} } \\over { r_{2} }} x$ results in $dt = {{ r_{1} } \\over { r_{2} }} dx$, so $$ \\begin{align*} E F^{k} =\u0026amp; \\int_{0}^{\\infty} x^{k} {{ 1 } \\over { B \\left( r_{1}/2 , r_{2} / 2 \\right) }} \\left( {{ r_{1} } \\over { r_{2} }} \\right)^{r_{1} / 2} x^{r_{1} / 2 - 1} \\left( 1 + {{ r_{1} } \\over { r_{2} }} x \\right)^{-(r_{1} + r_{2}) / 2} dx \\\\ =\u0026amp; {{ 1 } \\over { B \\left( r_{1}/2 , r_{2} / 2 \\right) }} \\left( {{ r_{1} } \\over { r_{2} }} \\right)^{r_{1} / 2} \\int_{0}^{\\infty} x^{k + r_{1} / 2 - 1} \\left( 1 + {{ r_{1} } \\over { r_{2} }} x \\right)^{-(r_{1} + r_{2}) / 2} dx \\\\ =\u0026amp; {{ 1 } \\over { B \\left( r_{1}/2 , r_{2} / 2 \\right) }} \\left( {{ r_{1} } \\over { r_{2} }} \\right)^{r_{1} / 2} \\int_{0}^{\\infty} \\left( {{ r_{2} } \\over { r_{1} }} t \\right)^{k + r_{1} / 2 - 1} \\left( 1 + t \\right)^{-(r_{1} + r_{2}) / 2} {{ r_{2} } \\over { r_{1} }} dt \\\\ =\u0026amp; {{ 1 } \\over { B \\left( r_{1}/2 , r_{2} / 2 \\right) }} \\left( {{ r_{1} } \\over { r_{2} }} \\right)^{r_{1} / 2} \\left( {{ r_{2} } \\over { r_{1} }} \\right)^{k + r_{1} / 2}\\int_{0}^{\\infty} t^{k + r_{1} / 2 } \\left( 1 + t \\right)^{-r_{1}/2 - r_{2}/ 2} dt \\\\ =\u0026amp; {{ 1 } \\over { B \\left( r_{1}/2 , r_{2} / 2 \\right) }} \\left( {{ r_{2} } \\over { r_{1} }} \\right)^{k }\\int_{0}^{\\infty} t^{k + r_{1} / 2 } \\left( 1 + t \\right)^{-(r_{1}/2+k) - (r_{2}/ 2-k)} dt \\end{align*} $$\nRepresentation of the beta function as a definite integral: $$ B(p,q)=\\int_{0}^{\\infty}\\frac{ t^{p-1} }{ (1+t)^{p+q}}dt $$\nRelationship between the beta and gamma functions: $$ B(p,q) = {{\\Gamma (p) \\Gamma (q)} \\over {\\Gamma (p+q) }} $$\n$$ \\begin{align*} EF^{k} =\u0026amp; {{ 1 } \\over { B \\left( r_{1}/2 , r_{2} / 2 \\right) }} \\left( {{ r_{2} } \\over { r_{1} }} \\right)^{k } B \\left( {{ r_{1} } \\over { 2 }} + k, {{ r_{2} } \\over { 2 }} - k \\right) \\\\ =\u0026amp; \\left( {{ r_{2} } \\over { r_{1} }} \\right)^{k } {{ \\Gamma (r_{1}/2 + r_{2}/2) } \\over { \\Gamma (r_{1}/2 ) \\Gamma ( r_{2}/2) }} {{ \\Gamma (r_{1}/2 + k) \\Gamma ( r_{2}/2 - k) } \\over { \\Gamma (r_{1}/2 +k + r_{2}/2 - k) }} \\\\ =\u0026amp; \\left( {{ r_{2} } \\over { r_{1} }} \\right)^{k } {{ 1 } \\over { \\Gamma (r_{1}/2 ) \\Gamma ( r_{2}/2) }} {{ \\Gamma (r_{1}/2 + k) \\Gamma ( r_{2}/2 - k) } \\over { 1 }} \\\\ =\u0026amp; \\left( {{ r_{2} } \\over { r_{1} }} \\right)^{k } {{ \\Gamma (r_{1}/2 + k) 2^{k}} \\over { \\Gamma (r_{1}/2 ) }} {{ 2^{-k} \\Gamma ( r_{2}/2 - k) } \\over { \\Gamma ( r_{2}/2) }} \\end{align*} $$\nMoment of the chi-squared distribution: Let\u0026rsquo;s say $X \\sim \\chi^{2} (r)$. If $k \u0026gt; - r/ 2$, then the $k$th moment exists $$ E X^{k} = {{ 2^{k} \\Gamma (r/2 + k) } \\over { \\Gamma (r/2) }} $$\n$$ E F^{k} = \\left( {{ r_{2} } \\over { r_{1} }} \\right)^{k } E U^{k} E V^{-k} $$\n‚ñ†\n[b] Derive directly from the joint density function.\n‚ñ†\n[c] Derive directly from the variable change.\n‚ñ†\n[d] Circumvent as a ratio of the chi-squared distributions.\n‚ñ†\n[e] Since the numerator and the denominator are reversed, it is trivial according to theorem [b]. From a practical statistician\u0026rsquo;s point of view, defining the F-distribution according to theorem [b] and deriving the probability density function accordingly is more natural.\n‚ñ†\nSee Also Generalization: Non-central F-distribution Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p194.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCasella. (2001). Statistical Inference(2nd Edition): p222.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1606,"permalink":"https://freshrimpsushi.github.io/en/posts/1606/","tags":null,"title":"F-distribution"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 The chi-square distribution refers to a continuous probability distribution $\\chi^{2} (r)$ with the following probability density function, defined over the degrees of freedom $r \u0026gt; 0$. $$ f(x) = {{ 1 } \\over { \\Gamma (r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} \\qquad , x \\in (0, \\infty) $$\n$\\Gamma$ represents the gamma function. Basic Properties Moment Generating Function [1]: $$m(t) = (1-2t)^{-r/2} \\qquad , t \u0026lt; {{ 1 } \\over { 2 }}$$ Mean and Variance [2] If the mean and variance are: $X \\sim \\chi^{2} (r)$, then $$ \\begin{align*} E(X) =\u0026amp; r \\\\ \\text{Var} (X) =\u0026amp; 2r \\end{align*} $$ Sufficient Statistics [3]: Suppose a random sample $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{n} \\right) \\sim \\chi^{2} (r)$ following the chi-square distribution is given. The sufficient statistic $T$ for $r$ is as follows. $$ T = \\left( \\prod_{i} X_{i} \\right) $$ Theorems $k$th Moment [a]: Let $X \\sim \\chi^{2} (r)$. If $k \u0026gt; - r/ 2$, then the $k$th moment exists and $$ E X^{k} = {{ 2^{k} \\Gamma (r/2 + k) } \\over { \\Gamma (r/2) }} $$ Relationship with the Gamma Distribution [b]: $$\\Gamma \\left( { r \\over 2 } , 2 \\right) \\iff \\chi ^2 (r)$$ Derivation of the F-Distribution [c]: If two random variables $U,V$ are independent and $U \\sim \\chi^{2} ( r_{1})$, $V \\sim \\chi^{2} ( r_{2})$, then $$ {{ U / r_{1} } \\over { V / r_{2} }} \\sim F \\left( r_{1} , r_{2} \\right) $$ Relationship with the Square of a Standard Normal Distribution [d]: If $X \\sim N(\\mu,\\sigma ^2)$, then $$ V=\\left( { X - \\mu \\over \\sigma} \\right) ^2 \\sim \\chi ^2 (1) $$ Explanation The chi-square distribution is widely used throughout statistics, often first encountered in goodness-of-fit tests or analysis of variance, among others.\nTheorem [d] is particularly important as the converse of this theorem allows detecting issues with the normality of residuals when the squared standardized residuals do not follow the chi-square distribution $\\chi^{2} (1)$.\nProof Strategy [1], [a]: Use the trick of taking stuff out of the definite integral sign and changing it to a gamma function through substitution integration.\nDefinition of the Gamma Function: $$ \\Gamma (x) := \\int_{0}^{\\infty} y^{x-1} e^{y} dy $$\n[1] By substituting as $y=x(1/2-t)$, since ${{ 1 } \\over { 1/2 - t }}dy = dx$ $$ \\begin{align*} m(t) =\u0026amp; \\int_{0}^{\\infty} e^{tx} {{ 1 } \\over { \\Gamma (r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} dx \\\\ =\u0026amp; {{ 1 } \\over { \\Gamma (r/2) 2^{r/2} }} \\int_{0}^{\\infty} x^{r/2-1} e^{x(1/2-t)} dx \\\\ =\u0026amp; {{ 1 } \\over { \\Gamma (r/2) 2^{r/2} }} \\int_{0}^{\\infty} \\left( {{ y } \\over { 1/2 -t }} \\right)^{r/2-1} e^{y} {{ 1 } \\over { 1/2 - t }} dy \\\\ =\u0026amp; (1/2-t)^{-r/2}{{ 1 } \\over { \\Gamma (r/2) 2^{r/2} }} \\int_{0}^{\\infty} y^{r/2-1} e^{y} dy \\\\ =\u0026amp; (1-2t)^{-r/2}{{ 1 } \\over { \\Gamma (r/2) }} \\int_{0}^{\\infty} y^{r/2-1} e^{y} dy \\end{align*} $$ according to the definition of the gamma function $$ m(t) = (1-2t)^{-r/2} \\qquad , t \u0026lt; {{ 1 } \\over { 2 }} $$\n‚ñ†\n[2] Substituting into the moment formula [a].\n‚ñ†\n[a] By substituting as $y = x/2$, since $2 dy = dx$ $$ \\begin{align*} EX^{k} =\u0026amp; \\int_{0}^{\\infty} x^{k} {{ 1 } \\over { \\Gamma (r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} dx \\\\ =\u0026amp; {{ 1 } \\over { \\Gamma (r/2) 2^{r/2} }} \\int_{0}^{\\infty} x^{r/2+k-1} e^{-x/2} dx \\\\ =\u0026amp; {{ 1 } \\over { \\Gamma (r/2) 2^{r/2} }} \\int_{0}^{\\infty} 2^{r/2+k-1} y^{r/2+k-1} e^{-y} 2dy \\\\ =\u0026amp; {{ 2^{k} } \\over { \\Gamma (r/2) }} \\int_{0}^{\\infty} y^{(r/2+k)-1} e^{-y} 2dy \\end{align*} $$ according to the definition of the gamma function $$ E X^{k} = {{ 2^{k} \\Gamma (r/2 + k) } \\over { \\Gamma (r/2) }} $$\n‚ñ†\n[b] Shown through the moment-generating function.\n‚ñ†\n[c] Deduced directly from the joint density function.\n‚ñ†\n[d] Deduced directly from the probability density function.\n‚ñ†\nSee Also Generalization: Non-central Chi-square Distribution Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p161.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1600,"permalink":"https://freshrimpsushi.github.io/en/posts/1600/","tags":null,"title":"Chi-Squared Distribution"},{"categories":"Í∏∞ÌïòÌïô","contents":"Definition The set of points on a plane whose sum of distances to two fixed points $F$, $F^{\\prime}$ is constant, are called an ellipse.\nThe components of an ellipse are as follows.\n$F$, $F^{\\prime}$ are called foci.\n$a$ is called the semimajor axis, and $b$ is called the semiminor axis. $b=\\sqrt{1-\\epsilon^{2}}a$ is satisfied.\n$\\epsilon$ is called the eccentricity of the ellipse. It represents how ellipsed is compressed, and the foci are $\\epsilon a$ away from the center of the ellipse. It can also be denoted as $k$ or $e$.\n$$ \\epsilon^{2}=k^{2}=e^{2} =\\begin{cases} \\frac{a^{2}-b^{2}}{a^{2}} ,\u0026amp;0\u0026lt;b\u0026lt;a \\\\ \\frac{b^{2}-a^{2}}{b^{2}}, \u0026amp;0\u0026lt;a\u0026lt;b \\end{cases} $$\nThe distance $\\alpha$ from a focus to a point where a line perpendicular to the major axis meets the ellipse is called the latus rectum. $\\alpha = (1-\\epsilon^{2})a$ is satisfied.\n$r_{0}$ is the distance from a focus to the pericenter, and $r_{0}=(1-\\epsilon)a$ is satisfied.\n$r_{1}$ is the distance from a focus to the apocenter $ÍπåÏßÄÏùò Í±∞Î¶¨Ïù¥Î©∞ $, and $Í∞Ä ÏÑ±Î¶ΩÌïúÎã§.\nÏÑ§Î™Ö Îëê Ï¥àÏ†êÏù¥ Í∞ôÏúºÎ©¥ ÏõêÏù¥Í∏∞ ÎïåÎ¨∏Ïóê, Î≥¥ÌÜµ ÌÉÄÏõêÏù¥ÎùºÍ≥† ÌïòÎ©¥ Îëê Ï¥àÏ†êÏù¥ ÏÑúÎ°ú Îã§Î•¥Îã§Îäî Í≤ÉÏùÑ ÏùòÎØ∏ÌïúÎã§.\nÌåêÎ≥ÑÎ≤ï Ï£ºÏñ¥ÏßÑ Ïù¥Ï∞®Í≥°ÏÑ† $, $Ïóê ÎåÄÌï¥ÏÑú $, $Î•º ÌåêÎ≥ÑÏãùÏù¥Îùº ÌïúÎã§. ÌåêÎ≥ÑÏãùÏù¥ ÏùåÏàòÏù∏ Ïù¥Ï∞®Í≥°ÏÑ†ÏùÄ ÌÉÄÏõêÏù¥Îã§.\nÌÉÄÏõêÏùò Î∞©Ï†ïÏãù ÌÉÄÏõêÏùò Ï§ëÏã¨Ïù¥ $, $Ïù¥Í≥† Ïû•Î∞òÍ≤ΩÏù¥ $, $, Îã®Î∞òÍ≤ΩÏù¥ $, $Ïù∏ ÌÉÄÏõêÏùò Î∞©Ï†ïÏãùÏùÄ ÏïÑÎûòÏôÄ Í∞ôÎã§.\n$$ \\frac{(x-x_{0})^{2}}{a^{2}}+\\frac{(y-y_{0})^{2}}{b^{2}}=1 $$\nÍ∑π Ï¢åÌëúÏóêÏÑú Ï¥àÏ†êÏù¥ ÏõêÏ†êÏù∏ ÌÉÄÏõêÏùò Î∞©Ï†ïÏãù Í∑π Ï¢åÌëúÍ≥ÑÏóêÏÑú ÌÉÄÏõêÏùò Î∞©Ï†ïÏãùÏùÄ ÏïÑÎûòÏôÄ Í∞ôÎã§.\n$$ r = \\frac{\\alpha}{1+\\epsilon \\cos \\theta} $$\nÌòπÏùÄ\n$$ r = \\frac{b^{2}/a}{1+\\frac{\\sqrt{a^{2}-b^{2}}}{a}\\cos\\theta} $$\nÌÉÄÏõêÏùò ÎÑìÏù¥ Ïû•Î∞òÍ≤ΩÏù¥ $, $, Îã®Î∞òÍ≤ΩÏù¥ $, $Ïù∏ ÌÉÄÏõêÏùò ÎÑìÏù¥ $, $Îäî ÏïÑÎûòÏôÄ Í∞ôÎã§.\n$$ A=ab\\pi $$\nÌÉÄÏõêÏùò ÎëòÎ†à ÏúÑ Í∑∏Î¶ºÍ≥º Í∞ôÏùÄ ÌÉÄÏõêÏùò ÎëòÎ†àÎäî ÏïÑÎûòÏôÄ Í∞ôÎã§.\n$$ 4b\\int _{0} ^{{\\textstyle \\frac{\\pi}{2}}} \\sqrt{ 1-k^{2}\\sin^{2} \\theta } d\\theta ,\\quad k^{2}=\\frac{b^{2}-a^{2} }{b^{2}} $$\nÏ†ú2 Ï¢Ö ÌÉÄÏõê Ï†ÅÎ∂Ñ ÏïÑÎûòÏùò Ï†ÅÎ∂ÑÏùÑ Í∞ÅÍ∞Å Ï†ú2Ï¢Ö ÏôÑÏ†Ñ ÌÉÄÏõê Ï†ÅÎ∂Ñ, Ï†ú2Ï¢Ö Î∂àÏôÑÏ†Ñ ÌÉÄÏõê Ï†ÅÎ∂Ñ Ïù¥ÎùºÍ≥† ÌïúÎã§.\n$$ E(k)=\\int_{0}^{{\\textstyle \\frac{\\pi}{2}}}\\sqrt{1-k^{2} \\sin ^{2} \\theta} d\\theta $$\n$$ E(\\phi, k)=\\int_{0}^{\\phi}\\sqrt{1-k^{2} \\sin ^{2} \\theta}d\\theta $$\nÌÉÄÏõêÏùò ÏùºÎ∞òÌôî, ÏùºÎ¶ΩÏÜåÏù¥Îìú ÏÑ†Ìòï Î≥ÄÌôò $, $Ïóê ÎåÄÌï¥ $, $Ï∞®Ïõê Îã®ÏúÑÍµ¨ $, $ Ïùò Ïù¥ÎØ∏ÏßÄ $, $ ÏùÑ ÏùºÎ¶ΩÏÜåÏù¥ÎìúÎùºÍ≥† ÌïúÎã§. $, $Ïùò Í≥†Ïú†Í∞í $, $ÏôÄ Í∑∏Ïóê Îî∞Î•∏ Îã®ÏúÑ Í≥†Ïú†Î≤°ÌÑ∞ $ are stated. The axis of the ellipsoid are denoted by $u_{1} , \\cdots , u_{m}$ satisfying $Ïóê ÎåÄÌï¥ $.\n","id":1685,"permalink":"https://freshrimpsushi.github.io/en/posts/1685/","tags":null,"title":"Ellipse"},{"categories":"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ","contents":"Definitions Let\u0026rsquo;s consider a function $f : \\mathbb{R} \\to \\mathbb{C}$ in the function space $\\mathbb{C}^{\\mathbb{R}}$.\nThe support of a function $f$ is defined as the closed set obtained by taking the closure of the set of points where the function value is not $0$. $$ \\text{supp} f = \\overline{\\left\\{ x \\in \\mathbb{R} : f(x) \\ne 0 \\right\\}} $$\nIf $\\text{supp} f$ is bounded, then $f$ is said to have a compact support because the closure is a closed set, and a set that is closed and bounded in the real number space is compact.\n$U\\Subset V$ is $\\overline{U} \\subset V$ and $\\overline{U}$ being compact means that $\\mathrm{supp}(f) \\Subset U$ means that $f$ has a compact support in $U$. It is also written as $\\subset \\subset$.\nThe set of continuous functions forms a vector space and is called a space of continuous functions, denoted as follows:\n$$ C(\\mathbb{R}) := \\left\\{f \\text{ is continuous} \\right\\} $$\nIf there\u0026rsquo;s confusion with $C^{1}$, it is sometimes written as $C^{0}$.\nThe vector space of continuous functions that have a compact support is denoted as follows:\n$$ C_{c} (\\mathbb{R}) := \\left\\{ f \\in C(\\mathbb{R}) : f \\text{ has compact support} \\right\\} $$\nThe vector space of continuous functions whose function value converges to $0$ when $x \\to \\pm \\infty$ is denoted as follows:\n$$ C_{0} ( \\mathbb{R} ) := \\left\\{ f \\in C(\\mathbb{R}) : f(x) \\to 0 \\text{ as } x \\to \\pm \\infty \\right\\} $$\nThe vector space of continuous functions that are differentiable up to $m$ times, and all of its derivatives are continuous is denoted as follows:\n$$ C^{m}(\\mathbb{R}) :=\\left\\{ f \\in C(\\mathbb{R}) : f^{(n)} \\text{ is continuous } \\forall n \\le m \\right\\} $$\nHere, $C^{0}(\\mathbb{R})$ means $C(\\mathbb{R})$. A function that is an element of $C^{m}$ is called a $m$-times continuously differentiable function.\nThe vector space of infinitely differentiable functions, all of whose derivatives are continuous, is denoted as follows: $$ C^{\\infty}(\\mathbb{R})=\\bigcap _{m=0}^{\\infty}C^{m}(\\mathbb{R}) $$ An element of $C^{\\infty}$ is referred to as a smooth function.\n‚Äª Depending on the author, $C_{0}$ is sometimes used in the sense of $C_{c}$, so be sure to check the notation defined in the textbook.\nExplanation In Sobolev spaces, theory of distributions, etc., $C_{c}^{\\infty}$ is mainly dealt with.\nNaturally, $C_{c} (\\mathbb{R})$ is a subspace of $C_{0} (\\mathbb{R})$. Although both are superior spaces compared to the mere space of continuous functions $C (\\mathbb{R})$, one must be cautious that they do not become a Banach space with respect to the operator norm $\\left\\| \\cdot \\right\\|_{\\infty} $. For example, consider the following $\\left\\{ f_{k} \\right\\}_{k \\in \\mathbb{N}} \\subset C_{c} (\\mathbb{R})$\n$$ f_{k} (x) := \\begin{cases} {{ \\sin x } \\over { x }} \\chi_{[ - k \\pi , k \\pi ]} (x) \u0026amp; , x \\ne 0 \\\\ 1 \u0026amp; , x = 0 \\end{cases} $$\n$f_{k}$ converges to the following sinc function $\\text{sinc} \\in C_{0} (\\mathbb{R}) \\setminus C_{c} (\\mathbb{R})$ while having a compact support $[-k \\pi , k \\pi]$ for all $k \\in \\mathbb{N}$.\n$$ \\text{sinc} x = \\begin{cases} {{ \\sin x } \\over { x }} \u0026amp; , x \\ne 0 \\\\ 1 \u0026amp; , x = 0 \\end{cases} $$\nAs a Metric Space1 Let\u0026rsquo;s refer to the set of continuous real-valued functions on the interval $[0, 1]$ as $X = C[0, 1]$. And let‚Äôs define the [metric] $d$ as follows.\n$$ d(x, y) := \\int\\limits_{0}^{1} \\left| x(t) - y(t) \\right| dt \\qquad \\forall x, y \\in X $$\nThen, the [metric space] $(X, d)$ is not a complete space. Let\u0026rsquo;s consider the function $x_{m}$ as shown in the image (a) below.\nIf we say $n \\gt m$, for any $\\varepsilon \\gt 0$, whenever $m \\gt 1/\\varepsilon$, $1 \\cdot \\frac{1}{m} \\lt \\varepsilon$ holds; hence, by $d(x_{m}, x_{n}) \\lt \\varepsilon$, $\\left\\{ x_{m} \\right\\}$ is a Cauchy sequence.\nHowever, since $x_{m}(t) = 0$ and $(t \\in [0, 1/2])$, and $x_{m}(t) = 1$ and $(t \\in [a_{m}, 1])$, the following holds.\n$$ \\begin{align*} d(x_{m}, x) \u0026amp;= \\int\\limits_{0}^{1} \\left| x_{m(t)} - x(t) \\right| dt \\\\ \u0026amp;= \\int\\limits_{0}^{\\frac{1}{2}} \\left| 0 - x(t) \\right| dt + \\int\\limits_{\\frac{1}{2}}^{a_{m}} \\left| x_{m(t)} - x(t) \\right| dt + \\int\\limits_{a_{m}}^{1} \\left| 1 - x(t) \\right| dt \\\\ \u0026amp;= \\int\\limits_{0}^{\\frac{1}{2}} \\left| x(t) \\right| dt + \\int\\limits_{\\frac{1}{2}}^{a_{m}} \\left| x_{m(t)} - x(t) \\right| dt + \\int\\limits_{a_{m}}^{1} \\left| 1 - x(t) \\right| dt \\\\ \\end{align*} $$\nSince each of the integrands is greater than or equal to $0$, for $d(x_{m}, x)$ to converge to $0$, each of the integrand functions must be $0$. Hence, $x$ at $t\\in[0, \\frac{1}{2})$ is $x(t) = 0$, and at $t\\in (\\frac{1}{2}, 1]$ is $x(t) = 1$. Clearly, it is not continuous, thus $x \\notin X$, and $\\left\\{ x_{m} \\right\\}$ does not converge to $X$.\nAs a Normed Space2 The space of continuous functions $C[0, 1]$ becomes a complete space, i.e., a complete normed (Banach) space, when given the maximum value as a norm, rather than an integral. In other words, $\\left\\| \\cdot \\right\\|$ is a Banach space with the norm $(C[0, 1], \\left\\| \\cdot \\right\\|)$ defined as follows.\n$$ \\left\\| f \\right\\| := \\max\\limits_{t \\in [0, 1]} \\left| f(t) \\right|,\\qquad f \\in C[0, 1] $$\nErwin Kreyszig, Introductory Functional Analysis with Applications (1978), p38\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nErwin Kreyszig, Introductory Functional Analysis with Applications (1978), p61-62\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1594,"permalink":"https://freshrimpsushi.github.io/en/posts/1594/","tags":null,"title":"The Support of Functions and the Class of Continuous Function Spaces"},{"categories":"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ","contents":"Definition If a Schauder basis $\\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}}$ of a Hilbert space $H$ is a normal orthogonal system, then $\\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}}$ is called the Orthonormal Basis of $H$.\nTheorem1 Equivalent Conditions for Orthonormal Basis [1]: Assuming $H$ is a Hilbert space. For the normal orthogonal system $\\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}} \\subset H$ of $H$, the following are all equivalent. (i): $\\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}} \\subset H$ is the Orthonormal Basis of $H$. (ii): For all $\\mathbf{x}\\in H$: $$ \\mathbf{x}= \\sum_{k \\in \\mathbb{N}} \\langle \\mathbf{x}, \\mathbf{e}_{k} \\rangle \\mathbf{e}_{k} $$ (iii): For all $\\mathbf{x}, \\mathbf{y} \\in H$: $$ \\langle \\mathbf{x}, \\mathbf{y} \\rangle = \\sum_{k \\in \\mathbb{N}} \\langle \\mathbf{x}, \\mathbf{e}_{k} \\rangle \\langle \\mathbf{e}_{k} , \\mathbf{y} \\rangle $$ (iv): For all $\\mathbf{x}\\in H$: $$ \\sum_{k \\in \\mathbb{N}} \\left| \\langle \\mathbf{x}, \\mathbf{e}_{k} \\rangle \\right|^{2} = \\left\\| \\mathbf{x}\\right\\|^{2} $$ (v): $\\overline{\\text{span}} \\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}} = H$ (vi): If $\\mathbf{x}\\in H$ and for all $k \\in \\mathbb{N}$ if $\\langle \\mathbf{x}, \\mathbf{e}_{k} \\rangle = 0$ then $\\mathbf{x}= \\mathbf{0}$ Unitary Operators and Orthonormal Basis [2]: If $\\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}}$ is considered the orthonormal basis of $H$, then the orthonormal basis of $H$ is exactly represented as $\\left\\{ U \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}}$ with respect to the unitary operator $U : H \\to H$. Description Especially, it is said that all orthonormal bases of $H$ are characterized by the unitary operator $U$, similar to the result in theorem [2].\nProof Refer to references for the proof of [1].\n[2] Let also $\\left\\{ \\mathbf{v}_{k} \\right\\}_{k \\in \\mathbb{N}}$ be the orthonormal basis of $H$. Define the operator $U : H \\to H$ as follows: $$ U \\left( \\sum_{k \\in \\mathbb{N}} c_{k} \\mathbf{e}_{k} \\right) := \\sum_{k \\in \\mathbb{N}} c_{k} \\mathbf{v}_{k} \\qquad , \\forall {c_{k}}_{k \\in \\mathbb{N}} \\in l^{2} $$ Then, $U$ is bounded, bijective, and $\\mathbf{v}_{k} = U \\mathbf{e}_{k}$.\nSince $\\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}}$ is the orthonormal basis of $H$, according to (i) $\\implies$ (ii), $\\mathbf{v} ,\\mathbf{w} \\in H$ can be represented as follows:\n$$ \\mathbf{v} = \\sum_{k \\in \\mathbb{N}} \\left\\langle \\mathbf{v} , \\mathbf{e}_{k} \\right\\rangle \\mathbf{e}_{k} \\\\ \\mathbf{w} = \\sum_{k \\in \\mathbb{N}} \\left\\langle \\mathbf{w} , \\mathbf{e}_{k} \\right\\rangle \\mathbf{e}_{k} $$\nThen, by the definition of $U$ and (i) $\\implies$ (iii),\n$$ \\begin{align*} \\left\\langle U^{ \\ast } U \\mathbf{v} , \\mathbf{w} \\right\\rangle =\u0026amp; \\left\\langle U \\mathbf{v} , U \\mathbf{w} \\right\\rangle \\\\ =\u0026amp; \\left\\langle \\sum_{k \\in \\mathbb{N}} \\left\\langle \\mathbf{v} , \\mathbf{e}_{k} \\right\\rangle \\mathbf{e}_{k} , \\sum_{k \\in \\mathbb{N}} \\left\\langle \\mathbf{w} , \\mathbf{e}_{k} \\right\\rangle \\mathbf{e}_{k} \\right\\rangle \\\\ =\u0026amp; \\sum_{k \\in \\mathbb{N}} \\left\\langle \\mathbf{v} , \\mathbf{e}_{k} \\right\\rangle \\overline{\\left\\langle \\mathbf{w} , \\mathbf{e}_{k} \\right\\rangle} \\\\ =\u0026amp; \\left\\langle \\mathbf{v} , \\mathbf{w} \\right\\rangle \\end{align*} $$\nIn other words, since $U^{ \\ast } U = I$, $U$ is a unitary operator, and it is bijective having the inverse operator $U^{-1} = U^{ \\ast }$. Meanwhile, assuming $U$ is unitary from the assumption produces\n$$ \\left\\langle U \\mathbf{e}_{i} , U \\mathbf{e}_{j} \\right\\rangle = \\left\\langle U^{ \\ast } U \\mathbf{e}_{i} , \\mathbf{e}_{j} \\right\\rangle = \\left\\langle \\mathbf{e}_{i} , \\mathbf{e}_{j} \\right\\rangle = \\delta_{ij} $$\nThat is, $\\left\\{ U \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}}$ is an orthonormal set. To show that it becomes the basis of $H$, let\u0026rsquo;s assume $\\left\\langle \\mathbf{v} , U \\mathbf{e}_{k} \\right\\rangle = 0$ for all $k \\in \\mathbb{N}$. Then, for all $k \\in \\mathbb{N}$, $\\left\\langle U^{ \\ast } \\mathbf{v} , \\mathbf{e}_{k} \\right\\rangle = 0$, thus $U^{ \\ast } \\mathbf{v} = \\mathbf{0}$ must hold. It was already shown that $U^{ \\ast } = U^{-1}$, so applying $U$ to both sides yields $\\mathbf{v} = \\mathbf{0}$. Consequently, according to (vi) $\\implies$ (i), it can be confirmed that $\\left\\{ U \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}} \\subset H$ becomes the orthonormal basis of $H$.\n‚ñ†\nOle Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p80-83\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1593,"permalink":"https://freshrimpsushi.github.io/en/posts/1593/","tags":null,"title":"Hilbert Space's Orthonormal Basis and Unitary Operator"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Law of Universal Gravity1 The law of universal gravity, announced by Newton through his Principia in 1687, is a physical law that simply states \u0026ldquo;every object attracts every other object\u0026rdquo;. To describe this concept in detail:\nEvery particle of matter in the universe with mass attracts every other particle with a force that is directly proportional to the product of their masses and inversely proportional to the square of the distance between their centers.\nThe above statement, when expressed in mathematical terms, is as follows:\n$$ \\mathbf{F}_{ij} = G\\frac{m_{i}m_{j}}{r_{ij}^{2}}\\frac{\\mathbf{r}_{ij}}{|\\mathbf{r}_{ij}|} $$\n$\\mathbf{F}_{ij}$ denotes the force experienced by a particle $i$ with mass $m_{i}$ due to the influence of another particle $j$ with mass $m_{j}$. According to the law of action-reaction, $\\mathbf{F}_{ij}=-\\mathbf{F}_{ji}$ holds true. The proportionality constant $G$ is known as the gravitational constant, and its value in SI units is as follows:\n$$ G=(6.67259\\pm0.00085)\\times 10^{-11}\\mathrm{Nm^{2}kg^{-2}} $$\nThis force $\\mathbf{F}$ is called gravity.\nGrant R. Fowles and George L. Cassiday, Analytical Mechanics (7th Edition, 2005), p219-220\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1678,"permalink":"https://freshrimpsushi.github.io/en/posts/1678/","tags":null,"title":"Law of Universal Gravitation: Gravity"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Angular Momentum1 Momentum is a physical quantity that represents the state of motion of a moving object. The larger the mass and the faster the speed, the greater the momentum. In physics, there is an interest in how the motion of an object changes. Therefore, the force, which is the cause of changing the state of motion of an object, is expressed as a change in momentum.\n$$ \\mathbf{F}=\\frac{d \\mathbf{p}}{dt} $$\nNow, we are trying to define a similar physical quantity for rotational motion. In rotational motion, unlike translational motion, there is a radius of rotation which affects the motion of the body. Hence, the quantity that represents the state of motion of a rotating body is called angular momentum, and is defined as follows.\n$$ \\mathbf{L}=\\mathbf{r}\\times \\mathbf{p} $$\nSince linear momentum is the product of mass and velocity, it does not change with the origin, but angular momentum includes the position vector $\\mathbf{r}$, so its value can change depending on where the origin is set. It should be noted that defining it this way is reasonable and natural upon verification of several facts.\nTorque In translational motion, the physical quantity representing the state of motion is momentum and the change in momentum is referred to as force. Similarly, in rotational motion, the physical quantity representing the state of motion is angular momentum, and the change in angular momentum can be something that changes the state of rotational motion. This physical quantity is called Torque and is denoted by $\\mathbf{N}$.\n$$ \\mathbf{N}=\\frac{ d \\mathbf{L}}{ dt } $$\nExpanding the right-hand side of the above equation yields the following.\n$$ \\begin{align*} \\frac{ d \\mathbf{L}}{ dt }\u0026amp;=\\frac{ d (\\mathbf{r}\\times \\mathbf{p})}{ dt } \\\\ \u0026amp;=\\frac{d \\mathbf{r}}{dt}\\times \\mathbf{p}+\\mathbf{r}\\times \\frac{ d \\mathbf{p}}{ dt } \\\\ \u0026amp;= \\mathbf{v}\\times \\mathbf{p} + \\mathbf{r}\\times\\mathbf{F} \\end{align*} $$\nSince $\\mathbf{p} = m\\mathbf{v}$, it follows that $\\mathbf{v}\\times \\mathbf{p}=\\mathbf{v}\\times(m\\mathbf{v})=\\mathbf{0}$. Therefore, we obtain the equation below.\n$$ \\frac{ d \\mathbf{L}}{ dt }=\\mathbf{r} \\times \\mathbf{F} $$\nAccording to the above equation, if the net force is $\\mathbf{0}$, there is no change in angular momentum, meaning that the state of rotational motion does not change. It can be confirmed that the definition of angular momentum accurately reflects real physical phenomena. Furthermore, from the above equation, the formula for torque can be derived as follows.\n$$ \\mathbf{N}=\\mathbf{r} \\times \\mathbf{F} $$\nConsider a body moving in a straight line. Assume that an external force is applied in the same direction as the direction of movement. Then, since the direction is the same as those of $\\mathbf{r}$ and $\\mathbf{F}$, the torque is $\\mathbf{0}$. Torque changes angular momentum, but if it is $\\mathbf{0}$, it means that the state of the body\u0026rsquo;s rotational motion does not change. In reality, the state of a body moving in a straight line not rotating remains \u0026ldquo;not rotating.\u0026rdquo; Therefore, we can understand that this formula accurately represents real physical phenomena. Additionally, for bodies that rotate under a central force, since the direction of the position vector $\\mathbf{r}$ and the central force $\\mathbf{F}$ are the same, torque becomes $\\mathbf{0}$, preserving angular momentum. This fact leads to the derivation of the law of areas. Torque is what causes changes in rotational motion, and how those changes are made is determined by the right-hand rule. As can be seen in the gif2 above, if the torque direction is upwards, according to the right-hand rule, the status of the body changes to move counterclockwise.\nGrant R. Fowles and George L. Cassiday, Analytical Mechanics (7th Edition, 2005), p226-227\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/Torque\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1674,"permalink":"https://freshrimpsushi.github.io/en/posts/1674/","tags":null,"title":"Angular Momentum and Torque"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Newton\u0026rsquo;s Laws of Motion 1 English mathematician and physicist Isaac Newton presented three laws about motion in 1687 in Principia as follows:\nAn object not subjected to an external force does not change its state of motion.\nThe change in motion is proportional to the applied force on the object.\nWhen object 1 applies a force to object 2, object 2 simultaneously applies a force equal in magnitude and opposite in direction on object 1.\nThese three laws are collectively called Newton\u0026rsquo;s laws of motion, and are individually referred to as the 1st, 2nd, and 3rd laws, respectively. Furthermore, the branch of science that describes the motion of objects based on these laws is called Newtonian mechanics or classical mechanics.\nFirst Law Commonly known as the law of inertia. Inertia is a property inherent to all objects that describes their resistance to changes in their motion. In other words, a stationary object does not attempt to move, and a moving object does not attempt to stop. This property is inertia. A stationary object requires an external force to move, and conversely, a moving object requires an external force to stop. The space where this law applies well is called an inertia frame of reference. By this definition, it\u0026rsquo;s understood that accelerating frames are not inertial frames. For example, when viewing a stationary (seated) object in an accelerating car from another frame of reference, the object appears to be accelerating, meaning its state of motion is changing without an external force.\nSecond Law The second law is mainly\n$$ \\mathbf{F}=m\\mathbf{a} $$\nexpressed by this formula. However, a more detailed expression is as follows.\n$$ \\mathbf{F}=\\frac{ d \\mathbf{p}}{ d t} $$\nNewton defined the physical quantity that represents the motion of an object as momentum. He also defined force as something that changes the state of motion of an object. Therefore, a change in the state of motion of an object means that its momentum is changing. This leads to the formula that the force $\\mathbf{F}$ applied to an object is proportional to the rate of change of momentum, which is exactly what the above formula signifies.\nThird Law Commonly called the law of action and reaction. Among the two forces described in the law, one is referred to as action, and the other, reaction.\nGrant R. Fowles and George L. Cassiday, Analytical Mechanics (7th Edition, 2005), p47-58\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1671,"permalink":"https://freshrimpsushi.github.io/en/posts/1671/","tags":null,"title":"Newton's Laws of Motion"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Mass1 In Newton\u0026rsquo;s laws of motion, inertia is described as the property that resists changes in motion. That is, the greater the inertia, the harder it is to move, and the smaller the inertia, the easier it is to move. This exactly aligns with our experience that it\u0026rsquo;s harder to push a heavier object than a lighter one. Hence, the magnitude of inertia can be expressed by the magnitude of mass. Mass refers to how heavy or light an object is. This defines the meaning of mass. Below explains how to define the value of mass.\nLet\u0026rsquo;s assume there are two objects. Let\u0026rsquo;s call their masses $m_{1}$ and $m_{2}$, respectively. And let\u0026rsquo;s say they are moved in opposite directions by the same force. To put it simply, imagine a situation where a spring is nestled between the two objects, pressed and then released from both sides. The two objects are propelled at speeds $\\mathbf{v}_{1}$ and $\\mathbf{v}_{2}$, respectively. At this point, the ratio of the masses of the two objects is defined as follows.\n$$ \\frac{m_{2}}{m_{1}}=\\left|\\frac{\\mathbf{v}_{1}}{\\mathbf{v}_{2}} \\right| $$\nBy taking the mass $m_{1}$ of object 1 as the standard, the masses of other objects (materials) can be determined.\nMomentum and Force The product of an object\u0026rsquo;s mass and velocity is called momentum, written as $\\mathbf{p}$. To distinguish it from angular momentum, it is also referred to as linear momentum.\n$$ \\mathbf{p}=m\\mathbf{v} $$\nMomentum, as the name suggests, is a physical quantity that a moving object has. Therefore, a change in an object\u0026rsquo;s motion means that the object\u0026rsquo;s momentum has increased or decreased. Then, the change in motion mentioned in Newton\u0026rsquo;s second law can be said to be the change in momentum over time. Furthermore, since force is said to change the motion of an object, Newton\u0026rsquo;s second law can be expressed as the following equation from the definition of momentum.\n$$ \\begin{equation} \\mathbf{F}=k\\frac{ d \\mathbf{p}}{ d t } \\end{equation} $$\nIn other words, \u0026rsquo;the force $\\mathbf{F}$ applied to an object is proportional to the change in the object\u0026rsquo;s momentum\u0026rsquo;. Here, $k$ is the proportionality constant. Assuming that the mass $m$ of the object does not change over time (as is the case from high school to college physics in many situations), the above equation can be written as follows.\n$$ \\mathbf{F}=k\\frac{d(m\\mathbf{v})}{dt}=km\\frac{d \\mathbf{v}}{dt}=km\\mathbf{a} $$\nHere, $\\mathbf{a}$ is the acceleration that an object with mass $m$ has when force $\\mathbf{F}$ is applied to it. If the proportionality constant is $k=1$, it becomes that famous equation.\n$$ \\mathbf{F}=m\\mathbf{a} $$\nFrom Newton\u0026rsquo;s laws of motion and the above definitions, the conservation of momentum principle naturally follows. The left side of $(1)$ is the net force acting on the system (or particle system), and the right side is the rate of change of the system\u0026rsquo;s momentum. If there is no external force, the rate of change of momentum is $0$, thus indicating that momentum is conserved.\nGrant R. Fowles and George L. Cassiday, Analytical Mechanics (7th Edition, 2005), p\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1673,"permalink":"https://freshrimpsushi.github.io/en/posts/1673/","tags":null,"title":"Physics: The Definition of Mass, Force, and Momentum"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Definition A system of particles is referred to as a particle system.\nDescription 1 When the position vectors of particles with masses $m_{1}$, $m_2$, $\\cdots$, and $m_{n}$ are $\\mathbf{r}_{1}$, $\\mathbf{r}_{2}$, $\\cdots$, and $\\mathbf{r}_{n}$, respectively, the center of mass of this particle system is defined as follows.\n$$ \\mathbf{r}_{cm}=\\frac{m_{1}\\mathbf{r}_{1}+m_{2}\\mathbf{r}_{2}+\\cdots + m_{n}\\mathbf{r}_{n}}{m_{1}+ m_{2}+ \\cdots+ m_{n}}=\\frac{\\sum m_{i}\\mathbf{r}_{i}}{m} $$\nHere, $m=\\sum \\limits_{i}m_{i}$ denotes the total mass of the particle system. The subscript $cm$ stands for \u0026ldquo;center of mass\u0026rdquo;. Thus, the velocity of the center of mass is naturally defined as follows.\n$$ \\begin{equation} \\mathbf{v}_{cm}=\\frac{m_{1}\\mathbf{v}_{1}+m_{2}\\mathbf{v}_{2}+\\cdots + m_{n}\\mathbf{v}_{n}}{m_{1}+ m_{2}+ \\cdots+ m_{n}}=\\frac{\\sum m_{i}\\mathbf{v}_{i}}{m} \\label{velocity-of-cm} \\end{equation} $$\nIn a three-dimensional Cartesian coordinate system, if $\\mathbf{r}_{i}=x_{i}\\hat{\\mathbf{x}}+y_{i}\\hat{\\mathbf{y}}+z_{i}\\hat{\\mathbf{z}}$, then the mass center for each coordinate is as follows.\n$$ x_{cm}=\\frac{\\sum m_{i}x_{i} }{m},\\quad y_{cm}=\\frac{\\sum m_{i}y_{i} }{m},\\quad z_{cm}=\\frac{\\sum m_{i}z_{i} }{m} $$\nThe linear momentum of this particle system is naturally defined as the sum of the momentum of each particle.\n$$ \\mathbf{p}=\\sum \\mathbf{p}_{i}=\\sum m_{i}\\mathbf{v}_{i} $$\nThen, it can be understood that, according to $(1)$, the linear momentum of the particle system can be expressed as the product of the total mass of the particle system and the velocity of its mass center.\n$$ \\mathbf{p}=\\sum m_{i}\\mathbf{v}_{i}=m\\mathbf{v}_{cm} $$\nNow, let\u0026rsquo;s assume the forces acting on each of these particles from an external source are $\\mathbf{F}_{1}$, $\\mathbf{F}_{2}$, $\\cdots$, and $\\mathbf{F}_{n}$. Also, let\u0026rsquo;s define the force experienced by particle $i$ due to particle $j$ as $\\mathbf{F}_{ij}$. Then, the equation of motion for particle $i$ is as follows.\n$$ \\mathbf{F}_{i} + \\sum \\limits_{j=1}^{n}\\mathbf{F}_{ij}=m_{i}\\ddot{\\mathbf{r}_{i}}=\\dot{\\mathbf{p}_{i}} $$\nTherefore, summing up all the forces on the entire particle system yields the following.\n$$ \\sum \\limits_{i=1}^{n}\\mathbf{F}_{i}+\\sum \\limits _{i=1}^{n}\\sum \\limits_{j=1}^{n}\\mathbf{F}_{ij}=\\sum \\limits_{i=1}^{n}\\dot{\\mathbf{p}_{i}} $$\nHere, a particle does not exert any force on itself, so $\\mathbf{F}_{ii}=\\mathbf{0}$ equals zero. Also, in the second term of the equation, $\\mathbf{F}_{ij}$ and $\\mathbf{F}_{ji}$ represent the forces exerted by particle $i$ on particle $j$ and by particle $j$ on particle $i$, respectively. According to the law of action and reaction, since their magnitudes are the same but their directions are opposite, when added together, they equal $\\mathbf{0}$. Thus, the second term is $\\mathbf{0}$. Therefore, the overall equation of motion for the particle system is as follows.\n$$ \\sum \\limits _{i=1} ^{n} \\mathbf{F}_{i}=\\dot{\\mathbf{p}_{i}}=m\\mathbf{a}_{cm} $$\nIn other words, the acceleration of the center of mass in a particle system is the same as the acceleration of a single particle with the total mass of the system when subjected to the total external force acting on the system.\nGrant R. Fowles and George L. Cassiday, Analytical Mechanics (7th Edition, 2005), p275-277\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1670,"permalink":"https://freshrimpsushi.github.io/en/posts/1670/","tags":null,"title":"Center of Mass and Linear Momentum of a Particle System"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Definition1 Let\u0026rsquo;s call $(X, \\left\\| \\cdot \\right\\|)$ a normed space. If there exists a unique sequence of scalars $\\left\\{ a_{k} \\right\\}_{k \\in \\mathbb{N}}$ that satisfies the following for every element $\\mathbf{x}\\in X$ in $X$, then $\\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}} \\subset X$ is called the Schauder basis of $X$.\n$$ \\mathbf{x}= \\sum_{k \\in \\mathbb{N}} a_{k} \\mathbf{e}_{k} $$\nDescription The basis of a vector space is called the Schauder basis, especially when discussing \u0026lsquo;infinite\u0026rsquo; linear combinations. Since it deals with infinity, it is closely related to properties of Banach spaces, and especially for Hilbert spaces, the following useful theorem is known.\nEquivalent Conditions for an Orthonormal Basis: Let\u0026rsquo;s say $H$ is a Hilbert space. For the orthonormal system $\\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}} \\subset H$ of $H$, the following are all equivalent.\n(i): $\\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}} \\subset H$ is an orthonormal basis of $H$. (ii): For all $\\mathbf{x}\\in H$, $$ \\mathbf{x}= \\sum_{k \\in \\mathbb{N}} \\langle \\mathbf{x}, \\mathbf{e}_{k} \\rangle \\mathbf{e}_{k} $$ (iii): For all $\\mathbf{x}, \\mathbf{y} \\in H$, $$ \\langle \\mathbf{x}, \\mathbf{y} \\rangle = \\sum_{k \\in \\mathbb{N}} \\langle \\mathbf{x}, \\mathbf{e}_{k} \\rangle \\langle \\mathbf{e}_{k} , \\mathbf{y} \\rangle $$ (iv): For all $\\mathbf{x}\\in H$, $$ \\sum_{k \\in \\mathbb{N}} \\left| \\langle \\mathbf{x}, \\mathbf{e}_{k} \\rangle \\right|^{2} = \\left\\| \\mathbf{x}\\right\\|^{2} $$ (v): $\\overline{\\text{span}} \\left\\{ \\mathbf{e}_{k} \\right\\}_{k \\in \\mathbb{N}} = H$ (vi): If $\\mathbf{x}\\in H$ and for all $k \\in \\mathbb{N}$, $\\langle \\mathbf{x}, \\mathbf{e}_{k} \\rangle = 0$ implies $\\mathbf{x}= \\mathbf{0}$ See also Basis of a finite-dimensional vector space: Hamel basis Ole Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p42\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1583,"permalink":"https://freshrimpsushi.github.io/en/posts/1583/","tags":null,"title":"Infinite-Dimensional Vector Spaces and Schauder Bases"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 This article is based on the Riemann-Stieltjes integral. If set to $\\alpha=\\alpha (x)=x$, it is the same as the Riemann integral. Let\u0026rsquo;s say $f$ is integrable by Riemann(-Stieltjes) from $[a,b]$. Then, for a constant $c\\in \\mathbb{R}$, $cf$ is also integrable from $[a,b]$, and its value is as follows. $$ \\int_{a}^{b}cf d\\alpha = c\\int_{a}^{b}f d\\alpha $$\nLet two functions $f_{1}$, $f_{2}$ be integrable by Riemann(-Stieltjes) from $[a,b]$. Then, $f_{1}+f_{2}$ is also integrable, and its value is as follows. $$ \\int _{a} ^{b}(f_{1}+f_{2})d\\alpha = \\int _{a} ^{b} f_{1}d\\alpha + \\int_{a}^{b} f_{2} d\\alpha $$\nIt means that integration is linear.\n$$ \\int _{a} ^{b}(f_{1}+cf_{2})d\\alpha = \\int _{a} ^{b} f_{1}d\\alpha + c\\int_{a}^{b} f_{2} d\\alpha $$\nThe reason for specifically mentioning sums and constant multiples separately is because they are proven separately.\nAuxiliary Theorem For a function $f$ that is integrable by Riemann(-Stieltjes) from $[a,b]$ and any positive number $\\varepsilon\u0026gt; 0$, there exists a partition $P$ of $[a,b]$ that satisfies the following equation.\n$$ \\begin{align} U(P,f,\\alpha) \\lt \\int_{a}^{b}f d\\alpha +\\varepsilon \\tag{L1} \\\\ \\int_{a}^{b}f d\\alpha -\\varepsilon \\lt L(P,f,\\alpha) \\tag{L2} \\end{align} $$\n$U$, $L$ are respectively the Riemann(-Stieltjes) upper sum and lower sum.\nProof $\\eqref{L1}$ Let\u0026rsquo;s say an arbitrary positive number $\\varepsilon \\gt 0$ is given. Then, by the necessary and sufficient condition for integrability, there exists a partition $P$ that satisfies the following equation.\n$$ U(P,f,\\alpha)-L(P,f,\\alpha) \\lt \\varepsilon $$\nSince $L(P,f,\\alpha) \\le \\displaystyle \\int_{a}^{b}fd\\alpha$, the following holds.\n$$ U(P,f,\\alpha)-\\int_{a}^{b}f d\\alpha\\le U(P,f,\\alpha)-L(P,f,\\alpha) \\lt \\varepsilon $$\nTherefore, the summary is as follows.\n$$ U(P,f,\\alpha ) \\lt \\int_{a}^{b}f d\\alpha +\\varepsilon $$\n‚ñ†\n$\\eqref{L2}$ As in the proof of $\\eqref{L1}$, there exists a partition $P$ that satisfies the following.\n$$ U(P,f,\\alpha)-L(P,f,\\alpha) \\lt \\varepsilon $$\nSince $\\displaystyle \\int_{a}^{b}fd\\alpha \\le U(P,f,\\alpha)$, the following holds.\n$$ \\int_{a}^{b}f d\\alpha-L(P,f,\\alpha)\\le U(P,f,\\alpha)-L(P,f,\\alpha) \\lt \\varepsilon $$\nTherefore, the summary is as follows.\n$$ \\int_{a}^{b}f d\\alpha -\\varepsilon \\lt L(P,f,\\alpha) $$\n‚ñ†\nProof When $f_{1}, f_{2}, f$ is integrable, it will be shown that $f_{1}+f_{2}, cf$ is also integrable and that its actual value is equal to $\\displaystyle \\int f_{1} + \\int f_{2}, c\\int f$.\n1. Case 1. $c=0$\nIt is obvious that $cf=0$ is integrable. It is also obvious that the following equation holds.\n$$ \\int_{a}^{b}0fd\\alpha=0=0\\int_{a}^{b}fd\\alpha $$\nCase 2. $c\u0026gt;0$\nLet\u0026rsquo;s say an arbitrary positive number $\\varepsilon \u0026gt;0$ is given. Then, by the necessary and sufficient condition for integrability, there exists a partition $P=\\left\\{ a=x_{0} \\lt \\cdots \\lt x_{i} \\lt \\cdots \\lt x_{n}=b\\right\\}$ that satisfies the following.\n$$ \\begin{equation} U(P,f,\\alpha) - L(P,f,\\alpha)\u0026lt;\\frac{\\varepsilon}{c} \\end{equation} $$\nLet\u0026rsquo;s set it as follows.\n$$ \\begin{align*} M_{i} \u0026amp;= \\sup _{[x_{i-1}, x_{i}]} f(x) \\\\ m_{i} \u0026amp;= \\inf _{[x_{i-1}, x_{i}]} f(x) \\\\ M_{i}^{c} \u0026amp;= \\sup _{[x_{i-1}, x_{i}]} cf(x) \\\\ m_{i}^{c} \u0026amp;= \\inf _{[x_{i-1}, x_{i}]} cf(x) \\end{align*} $$\nSince $c\u0026gt;0$, $cM_{i} = M_{i}^{c}$ holds, and $cm_{i} = m_{i}^{c}$. Then, by the definition of Riemann-(Stieltjes) sum and $(1)$, the following holds.\n$$ \\begin{align} U(P,cf,\\alpha)- L(P,cf,\\alpha) \u0026amp;= \\sum \\limits_{i=1}^{n}M_{i}^{c}\\Delta \\alpha_{i}-\\sum \\limits_{i=1}^{n}m_{i}^{c}\\Delta \\alpha_{i} \\nonumber\\\\ \u0026amp;= \\sum \\limits_{i=1}^{n}cM_{i}\\Delta \\alpha_{i}-\\sum \\limits_{i=1}^{n}cm_{i}\\Delta \\alpha_{i} \\nonumber\\\\ \u0026amp;= c\\left( \\sum \\limits_{i=1}^{n}M_{i}\\Delta \\alpha_{i}-\\sum \\limits_{i=1}^{n}m_{i}\\Delta \\alpha_{i} \\right) \\nonumber\\\\ \u0026amp;= c\\Big[ U(P,f,\\alpha)-L(P,f,\\alpha)\\Big] \\nonumber\\\\ \u0026amp;\\lt \\varepsilon \\end{align} $$\nTherefore, by the necessary and sufficient condition for integrability, $cf$ is integrable. Since the integral is less than the upper sum, the following holds.\n$$ c \\int_{a}^{b}fd \\alpha \\le cU(P,f,\\alpha) = U(P,cf,\\alpha) $$\nThen, by $(2)$ and the Auxiliary Theorem, the following holds.\n$$ c\\int _{a}^{b}f d\\alpha \\le U(P,cf,\\alpha) lt \\int _{a}^{b} cf d\\alpha +\\varepsilon $$\nSince $\\varepsilon$ is assumed to be any positive number, the following holds.\n$$ \\begin{equation} c\\int_{a}^{b}fd\\alpha \\le \\int_{a}^{b}cfd\\alpha \\end{equation} $$\nThe process of proving the opposite inequality is similar. By $(1)$ and the Auxiliary Theorem, the following holds.\n$$ cU(P,f,\\alpha) \\le c\\int_{a}^{b}fd\\alpha +\\varepsilon $$\nAlso, the following equation holds.\n$$ \\int_{a}^{b} cfd\\alpha \\le U(P,cf,\\alpha)=cU(P,f,\\alpha) $$\nFrom the above two equations, the following equation is obtained.\n$$ \\int_{a}^{b} cfd \\alpha \\le cU(P,f,\\alpha)\u0026lt; c\\int_{a}^{b}fd\\alpha +\\varepsilon $$\nSince $\\varepsilon$ is any positive number, the following holds.\n$$ \\begin{equation} \\int_{a}^{b} cf d\\alpha \\le c\\int_{a}^{b}fd\\alpha \\end{equation} $$\nBy $(3)$ and $(4)$, the following holds.\n$$ \\int_{a}^{b}cfd\\alpha = c\\int_{a}^{b}fd\\alpha $$\nCase 3. $c=-1$\nThe proof process is similar to Case 2. First, let\u0026rsquo;s say an arbitrary positive number $\\varepsilon$ is given. Since $f$ is integrable, by the necessary and sufficient condition for integrability, there exists a partition $P$ for the given $\\varepsilon$ that satisfies the following.\n$$ U(P,f,\\alpha) - L(P,f,\\alpha) \u0026lt;\\varepsilon $$\nNow, let\u0026rsquo;s set it as follows.\n$$ \\begin{align*} M_{i} \u0026amp;= \\sup _{[x_{i-1},x_{i}]}f \\\\ m_{i} \u0026amp;= \\inf_{[x_{i-1},x_{i}]}f \\\\ M_{i}^{\\ast} \u0026amp;= \\sup _{[x_{i-1},x_{i}]}(-f) \\\\ m_{i}^{\\ast} \u0026amp;= \\inf_{[x_{i-1},x_{i}]}(-f) \\end{align*} $$\nSince $M_{i}=-m_{i}^{\\ast}$ and $m_{i}=-M_{i}^{\\ast}$, $M_{i}-m_{i}=M_{i}^{\\ast}-m_{i}^{\\ast}$ holds. Therefore, the following holds.\n$$ \\begin{align*} U(P,-f,\\alpha)-L(P,-f,\\alpha) \u0026amp;= \\sum\\limits_{i=1}^{n}M_{i}^{\\ast}\\Delta \\alpha_{i}-\\sum\\limits_{i=1}^{n}m_{i}^{\\ast}\\Delta \\alpha_{i} \\\\ \u0026amp;= \\sum\\limits_{i=1}^{n}M_{i}\\Delta \\alpha_{i} - \\sum\\limits_{i=1}^{n}m_{i}\\Delta\\alpha_{i} \\\\ \u0026amp;= U(P,f,\\alpha) -L(P,f,\\alpha) \\\\ \u0026amp;\\lt \\varepsilon \\end{align*} $$\nTherefore, $-f$ is integrable.\nAs in the proof of Case 2., by the Auxiliary Theorem, the following holds.\n$$ U(P,-f,\\alpha) \\lt \\int_{a}^{b}(-f)d\\alpha +\\varepsilon $$\nAlso, the following equation holds.\n$$ -\\int_{a}^{b}fd\\alpha\\le -L(P,f,\\alpha)=U(P,-f,\\alpha) \\lt \\int_{a}^{b}(-f)d\\alpha + \\varepsilon $$\nSince $\\varepsilon$ is any positive number, the following holds. $$ -\\int_{a}^{b}fd\\alpha \\le \\int_{a}^{b}(-f)d\\alpha $$\nThen, by the Auxiliary Theorem, the following equation holds.\n$$ \\int_{a}^{b}(-f)d\\alpha -\\varepsilon \\lt L(P,-f,\\alpha)=-U(P,f,\\alpha)\\le-\\int_{a}^{b}fd\\alpha $$\nSince $\\varepsilon$ is any positive number, the following holds.\n$$ \\int_{a}^{b}(-f)d\\alpha \\le -\\int_{a}^{b}fd\\alpha $$\nTherefore, the following is obtained.\n$$ \\int_{a}^{b}(-f)d\\alpha =-\\int_{a}^{b}fd\\alpha $$\nCase 4. $c \\lt 0 \\quad \\text{and} \\quad c\\ne -1$\nIt holds by Case 2. and Case 3.\n‚ñ†\n2. Let\u0026rsquo;s say $f=f_{1}+f_{2}$. Let $P$ be any partition of $[a,b]$. Then, by the definition of Riemann(-Stieltjes) upper and lower sums, the following holds.\n$$ \\begin{equation} \\begin{aligned} L(P,f_{1},\\alpha) + L(P,f_{2},\\alpha)\u0026amp; \\le L(P,f,\\alpha) \\\\ \u0026amp;\\le U(P,f,\\alpha) \\\\ \u0026amp;\\le U(P,f_{1},\\alpha) +U(P,f_{2},\\alpha) \\end{aligned} \\end{equation} $$\nLet\u0026rsquo;s say an arbitrary positive number $\\varepsilon \u0026gt; 0$ is given. Then, by the necessary and sufficient condition for integrability, there exists a partition $P_{j}$ that satisfies the following.\n$$ U(P_{j},f_{j},\\alpha)-L(P_{j},f_{j},\\alpha)\u0026lt;\\varepsilon,\\quad (j=1,2) $$\nNow, let\u0026rsquo;s consider $P$ again as a common refinement of $P_{1}$ and $P_{2}$. Then, by $(5)$, the following holds.\n$$ \\begin{align*} U(P,f,\\alpha)-L(P,f,\\alpha) \u0026amp;\\le \\left[ U(P,f_{1},\\alpha)-L(P,f_{1},\\alpha) \\right] + \\left[ U(P,f_{2},\\alpha)-L(P,f_{2},\\alpha) \\right] \\\\ \u0026amp;\u0026lt; \\varepsilon \\end{align*} $$\nTherefore, by the necessary and sufficient condition for integrability, $f$ is integrable. Then, by the Auxiliary Theorem, the following equation holds.\n$$ U(P,f_{j},\\alpha)\u0026lt;\\int _{a}^{b}f_{j}d\\alpha+\\varepsilon,\\quad (j=1,2) $$\nFurthermore, by definition, since the upper sum is greater than the integral, the following holds.\n$$ \\int_{a}^{b}fd\\alpha \\le U(P,f,\\alpha) $$\nFrom the above equation and the third inequality of $(5)$, the following holds.\n$$ \\begin{align*} \\int_{a}^{b}fd\\alpha \u0026amp;\\le U(P,f,\\alpha) \\\\ \u0026amp;\\le U(P,f_{1},\\alpha)+U(P,f_{2},\\alpha) \\\\ \u0026amp;\u0026lt; \\int_{a}^{b}f_{1}d\\alpha +\\int_{a}^{b}f_{2}d\\alpha + 2\\varepsilon \\end{align*} $$\nSince $\\varepsilon$ is any positive number, the following holds.\n$$ \\begin{equation} \\int_{a}^{b} fd\\alpha \\le \\int_{a}^{b}f_{1}d\\alpha + \\int_{a}^{b} f_{2}d\\alpha \\label{6} \\end{equation} $$\nProving the opposite direction of the inequality completes the proof. Since it\u0026rsquo;s already shown above that a constant multiple of an integrable function is also integrable, $-f_{1}, -f_{2}$ is known to be integrable. Therefore, repeating the above process for these two functions yields the following equation.\n$$ \\int_{a}^{b}(-f)d\\alpha \\le \\int_{a}^{b}(-f_{1})d\\alpha + \\int_{a}^{b} (-f_{2})d\\alpha $$\nFurthermore, since $\\displaystyle \\int (-f)d\\alpha=-\\int fd\\alpha$, by multiplying both sides by $-1$, the following is obtained.\n$$ \\begin{equation} \\int_{a}^{b}fd\\alpha \\ge \\int_{a}^{b}f_{1}d\\alpha + \\int_{a}^{b} f_{2}d\\alpha \\label{7} \\end{equation} $$\nTherefore, by $(6)$ and $(7)$, the following is obtained.\n$$ \\int_{a}^{b}fd\\alpha = \\int_{a}^{b}f_{1}d\\alpha + \\int_{a}^{b} f_{2}d\\alpha $$\n‚ñ†\nWalter Rudin, Principles of Mathematical Analysis (3rd Edition, 1976), p128-129\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1666,"permalink":"https://freshrimpsushi.github.io/en/posts/1666/","tags":null,"title":"Linearity of Riemann(-Stieltjes) Iintegral"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition Planar Graph A planar graph is a graph that can be drawn on a plane without any edges crossing each other.\nExplanation When a planar graph is drawn, the regions that are demarcated on the plane are called faces. The following planar graph $K_{4}$ has four faces $f_{1}, f_{2}, f_{3}, f_{4}$, and among them, the one that is not bounded $f_{4}$ is called an infinite face.\nPlanar Graphs, as the name suggests, refer to graphs that can be drawn on a plane without any overlapping parts. To understand them better, it\u0026rsquo;s more helpful to see what non-planar graphs look like. For instance, the complete graph $K_{5}$ and the bipartite graph $K_{3,3}$ are not planar because, no matter how you try, there will be crossing edges.\nNaturally, mathematicians would be curious about the conditions that make a graph planar. Regarding this, a generalized theorem is known for the example above.\nTheorem Kuratowski\u0026rsquo;s Theorem 1 A graph is planar if and only if none of its subgraphs is homeomorphic to $K_{5}$ or $K_{3,3}$.\nSignificance Simply put, this theorem guarantees that if something similar to $K_{5}$ or $K_{3,3}$ is included, the graph is not planar, and if these are absent, then it is planar. At first glance, it might seem that this theorem makes everything about planar graphs clear, but graph theory has spawned a vast array of concepts and problems rooted in planar graphs. Starting with the simplest generalization that allows $k \\in \\mathbb{N}$ edges to overlap, it extends to commonly encountered disciplines in mathematics like duality, argumentative geometry dealing with dots, lines, and surfaces, and even combinatorial topology, which is interested in the structure of space itself, marking the beginning of a monumental journey.\nThus, while it\u0026rsquo;s not said that those who aren\u0026rsquo;t majoring in graphs necessarily need to be familiar with various theorems about planar graphs and skilled in proving them, it\u0026rsquo;s certainly a concept worth knowing to understand the broader world of mathematics. As definitions go, you don\u0026rsquo;t need a vast mathematical background to understand planar graphs in the first place. Just, let\u0026rsquo;s at least know about it.\nAutism Test One of the older internet memes, this problem is called the Autism Test. The problem sets a constraint that water, electricity, and gas must be supplied to three houses without the lines crossing and claims \u0026ldquo;it\u0026rsquo;s difficult but possible.\u0026rdquo; If we look at this purely as a mathematical problem, we can argue that it\u0026rsquo;s impossible based on Kuratowski\u0026rsquo;s Theorem. The reason these memes are called \u0026lsquo;Autism Tests\u0026rsquo; is perhaps because they\u0026rsquo;re a sort of contemptuous, derogatory joke, suggesting that \u0026lsquo;insisting on solving something impossible and trying to consider all possibilities looks similar to autism.\u0026rsquo;\nApproaching it non-mathematically, there exists a solution like the one above. In fact, the wholesome fun of the autism test lies in such forced or ingenious cheats that break the conditions of the problem.\nWilson. (1970). Introduction to Graph Theory: p2.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1565,"permalink":"https://freshrimpsushi.github.io/en/posts/1565/","tags":null,"title":"Planar Graphs and Kuratowski's Theorem"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Buildup1 When the mass is $m$, the damping factor is $\\gamma$, and the spring constant is $k$, the equation of motion representing the vibration of an object hung on a spring is as follows.\n$$ m x^{\\prime \\prime} + \\gamma x^{\\prime} + kx = F $$\nLetting $x_{1}=x$, $x_{2}=x_{1}^{\\prime}$, the above equation of motion can be expressed as the following system.\n$$ \\begin{align*} x_{1}^{\\prime}(t) =\u0026amp;\\ x_{2}(t) \\\\ x_{2}^{\\prime} (t) =\u0026amp;\\ x_{1}^{\\prime \\prime}(t) = -\\dfrac{\\gamma}{m}x_{2}(t)-\\dfrac{k}{m}x_{1}(t)-\\dfrac{1}{m}F(t) \\end{align*} $$\nThis can be represented as a matrix as follows.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\begin{pmatrix}x_{1}^{\\prime} \\\\ x_{2}^{\\prime}\\end{pmatrix} =\u0026amp;\\ \\begin{pmatrix} 0 \u0026amp; 1 \\\\ -\\dfrac{k}{m} \u0026amp; -\\dfrac{\\gamma}{m} \\end{pmatrix} \\begin{pmatrix} x_{1} \\\\ x_{2} \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ -\\dfrac{1}{m}F \\end{pmatrix} \\\\ \\implies\u0026amp;\u0026amp; \\mathbf{x}^{\\prime}(t) =\u0026amp;\\ A\\mathbf{x}(t)+g(t) \\end{align*} $$\nIn the case of $g(t)=0$ being a homogeneous equation, it can be seen that solving a second-order differential equation simplifies to solving a matrix multiplication problem with solution $\\mathbf{x}^{\\prime}=A\\mathbf{x}$.\nGeneralization Let $x_{1}$, $x_{2}$, $\\cdots$, $x_{n}$ be functions of $t$. Let $F_{1}$, $F_{2}$, $\\cdots$, $F_{n}$ be functions of $x_{1}$, $x_{2}$, $\\cdots$, $x_{n}$. Then, the system of first-order differential equations for $x_{i}(t),$ $1\\le i \\le n$ is as follows.\n$$ \\begin{align*} x_{1}^{\\prime}(t) =\u0026amp;\\ F_{1}(t,x_{1},x_{2},\\cdots,x_{n}) \\\\ x_{2}^{\\prime}(t) =\u0026amp;\\ F_{2}(t,x_{1},x_{2},\\cdots,x_{n}) \\\\ \\vdots \u0026amp; \\\\ x_{n}^{\\prime}(t) =\u0026amp;\\ F_{n}(t,x_{1},x_{2},\\cdots,x_{n}) \\end{align*} \\tag{1} $$\nWhen each $F_{i}$ is linear, it is called a linear system, and if not, it is called a nonlinear system. The more general form of a first-order linear differential equation system is as follows.\n$$ \\begin{align*} x_{1}^{\\prime}(t) =\u0026amp;\\ p_{11}(t)x_{1}(t)+\\cdots p_{1n}(t)x_{n}(t) + g_{1}(t) \\\\ x_{2}^{\\prime}(t) =\u0026amp;\\ p_{21}(t)x_{1}(t)+\\cdots p_{2n}(t)x_{n}(t) + g_{2}(t) \\\\ \\vdots \u0026amp; \\\\ x_{n}^{\\prime}(t) =\u0026amp;\\ p_{n1}(t)x_{1}(t)+\\cdots p_{nn}(t)x_{n}(t) + g_{n}(t) \\end{align*} $$\n$$ \\mathbf{x}^{\\prime}(t) = \\mathbf{P}(t)\\mathbf{x}(t) + \\mathbf{g}(t) $$\nHere, $\\mathbf{x}$, $\\mathbf{g}$ are vector-valued functions, and $\\mathbf{P}$ is a matrix function. If each $g_{i}(t)$ is $0$, it is called a homogeneous system; otherwise, it is called a nonhomogeneous system.\nSolutions The solution to the ODE system $(1)$ over interval $I : \\alpha \\lt t \\lt \\beta$ consists of $n$ functions that are differentiable at each point on interval $I$.\n$$ x_{1} = \\phi_{1}(t),\\quad x_{2} = \\phi_{2}(t),\\quad \\dots,\\quad x_{n} = \\phi_{n}(t) $$\nInitial Conditions For fixed $t_{0} \\in I$ and the $x_{i}^{0}$s, the following $n$ conditions are called initial conditions.\n$$ x_{1}(t_{0}) = x_{1}^{0},\\quad x_{2}(t_{0}) = x_{2}^{0},\\quad \\cdots,\\quad x_{n}(t_{0}) = x_{n}^{0} \\tag{2} $$\nCombining the ODE system $(1)$ with initial conditions $(2)$ is called the initial value problem, commonly abbreviated as IVP. \u0026lsquo;Finding the solution to the initial value problem\u0026rsquo; is referred to as \u0026lsquo;solving the initial value problem\u0026rsquo;. The solution to the initial value problem is guaranteed to exist and be unique by Picard\u0026rsquo;s theorem.\nWilliam E. Boyce, Boyce\u0026rsquo;s Elementary Differential Equations and Boundary Value Problems (11th Edition, 2017), p281-283\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1659,"permalink":"https://freshrimpsushi.github.io/en/posts/1659/","tags":null,"title":"First-Order Linear Differential Equation System"},{"categories":"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ","contents":"Buildup1 Let us assume that we are given bounded linear operators $T : K \\to H$ in Hilbert spaces $\\left( H, \\left\\langle \\cdot , \\cdot \\right\\rangle_{H} \\right)$ and $\\left( K, \\left\\langle \\cdot , \\cdot \\right\\rangle_{K} \\right)$. Then, for any fixed element $\\mathbf{w} \\in H$, the following defined $\\Phi : K \\to \\mathbb{C}$ becomes a linear functional $\\Phi \\in K^{ \\ast }$.\n$$ \\Phi \\mathbf{v} := \\left\\langle T \\mathbf{v} , \\mathbf{w} \\right\\rangle_{H} $$\nAccording to the Riesz Representation Theorem, in the Hilbert space $K$, there must uniquely exist an element $T^{ \\ast } \\mathbf{w} \\in K$ for all $\\mathbf{v} \\in K$ that satisfies the following.\n$$ \\Phi \\mathbf{v} = \\left\\langle \\mathbf{v} , T^{ \\ast } \\mathbf{w} \\right\\rangle_{K} $$\nAlthough we cannot know what $T^{ \\ast } \\mathbf{w} \\in K$ specifically is for the previously fixed element $\\mathbf{w} \\in H$, $T^{ \\ast }$ can be seen as the operator $T^{ \\ast } : H \\to K$ that maps $\\mathbf{w}$ to $T^{ \\ast } \\mathbf{w}$. From this discussion, the following concept can be introduced.\nDefinition Let $H,K$ be a Hilbert space. For a bounded linear operator $T : K \\to H$, the $T^{ \\ast } : H \\to K$ that satisfies the following is called the adjoint operator of $T$.\n$$ \\left\\langle T \\mathbf{v} , \\mathbf{w} \\right\\rangle_{H} = \\left\\langle \\mathbf{v} , T^{ \\ast } \\mathbf{w} \\right\\rangle_{K} ,\\quad \\forall \\mathbf{v} \\in K $$\nExplanation Also known as dual operator. It is also denoted by $T^{\\#}$.\nThe adjoint operator has properties such as:\n$T^{ \\ast }$ is linear and bounded. $\\left( T^{ \\ast } \\right)^{ \\ast } = T$ $\\left\\| T^{ \\ast } \\right\\| = \\left\\| T \\right\\|$ Meanwhile, when $H = K$, adjoint operators that have the following good properties are called by a more special name. Let $H$ be a Hilbert space and $T : H \\to H$ be linear and bounded1.\nIf $T = T^{ \\ast }$, then $T$ is called self-adjoint. If $TT^{ \\ast } = T^{ \\ast }T = I$, then $T$ is called unitary. If $T$ is self-adjoint, then for all $\\mathbf{v} , \\mathbf{w} \\in H$,\n$$ \\left\\langle T \\mathbf{v} , \\mathbf{w} \\right\\rangle = \\left\\langle \\mathbf{v} , T \\mathbf{w} \\right\\rangle $$\nIf $T$ is unitary, then for all $\\mathbf{v} , \\mathbf{w} \\in H$,\n$$ \\left\\langle T \\mathbf{v} , T \\mathbf{w} \\right\\rangle = \\left\\langle \\mathbf{v} , \\mathbf{w} \\right\\rangle $$\nFrom the definition, unitary $T$ is reversible,\n$$ T^{-1} = T^{ \\ast } $$\nEspecially, unitary operators have a very important property related to the normal orthogonal basis.\nOle Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p71-72\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1562,"permalink":"https://freshrimpsushi.github.io/en/posts/1562/","tags":null,"title":"Hilbert Space Adjoint Operators"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Explanation One of the methods to solve differential equations is to use the differential operator. Let\u0026rsquo;s define the differential operator $D$ as follows.\n$$ D:= \\frac{d}{dx} $$\nWhen explicitly expressing the variable being differentiated, it is also denoted as $D_{x}$. For partial differentiation, it is represented as follows.\n$$ \\partial _{x}:=\\frac{ \\partial }{ \\partial x},\\quad \\partial_{y}=\\frac{ \\partial }{ \\partial y} $$\nUsing the differential operator, the differential equation is expressed as follows.\n$$ \\begin{align*} y^{\\prime \\prime}+4y^{\\prime}-y=0 \u0026amp;\u0026amp; \\implies\u0026amp;\u0026amp; D^{2}y+4Dy-y=0 \\\\ \u0026amp;\u0026amp; \u0026amp;\u0026amp; (D^{2}+4D-1)y=0 \\end{align*} $$ Here, the solution $y=0$ is physically meaningless. Therefore, solving the differential equation changes to solving a quadratic equation for the constant $r$ that satisfies $Dy=ry$ $$ r^{2}+4r-1=0 $$ Solving $Dy=ry$ is essentially an eigenvalue problem, so solving the eigenvalue problem is virtually the same as solving the differential equation. Since the differential operator includes differentiation, special attention must be paid to the order of operations. For example, $D$ and $x$ do not commute, hence $Dx\\ne xD$ is true. Given that $y$ is a function concerning $x$, $$ Dxy=D(xy)=\\frac{ d }{ d x }(xy)=y+xy^{\\prime}=y+xDy=(xD+1)y $$ thus $$ Dx=xD+1 $$ is true. There are useful properties regarding the differential operator as follows.\nProperties $$ \\begin{align*} D(D+x) \u0026amp;= D^{2}+xD+1 \\tag{a} \\\\ (D-a)(D-b)=(D-b)(D-a) \u0026amp;= D^{2}-(a+b)D+ab \\tag{b} \\\\ (D+1)(D^{2}-D+1) \u0026amp;= D^{3}+1 \\tag{c} \\\\ Dx \u0026amp;= xD+1 \\tag{d} \\\\ (D-x)(D+x) \u0026amp;=D^{2}-x^{2}+1 \\tag{e} \\\\ (D+x)(D-x) \u0026amp;= D^{2}-x^{2}-1 \\tag{f} \\end{align*} $$\nProof Since the proof method is the same, some proof processes are omitted.\n$(a)$ $$ \\begin{align*} D(D+x)y \u0026amp;= D(y^{\\prime}+xy) \\\\ \u0026amp;= y^{\\prime \\prime}+y+xy^{\\prime} \\\\ \u0026amp;= D^{2}y+xDy+y \\\\ \u0026amp;= (D^{2}+xD+1)y \\end{align*} $$ Therefore, $$ D(D+x) = D^{2}+xD+1 $$\n‚ñ†\n$(b)$ $$ \\begin{align*} (D-a)(D-b)y \u0026amp;=(D-a)(y^{\\prime}-by) \\\\ \u0026amp;= y^{\\prime \\prime}-ay^{\\prime}-by^{\\prime}+aby \\\\ \u0026amp;= D^{2}y-(a+b)Dy+aby \\\\ \u0026amp;=[D^{2}-(a+b)D+ab]y \\\\ \u0026amp;=[D^{2}-(b+a)D+ba]y \\\\ \u0026amp;=(D-b)(D-a)y \\end{align*} $$ Therefore, $$ (D-a)(D-b)=(D-b)(D-a) = D^{2}-(a+b)D+ab $$ ‚ñ†\n$(e)$ $$ \\begin{align*} (D-x)(D+x)y \u0026amp;= (D-x)(y^{\\prime}+xy) \\\\ \u0026amp;= y^{\\prime \\prime} -xy^{\\prime} +y+xy^{\\prime}-x^{2}y \\\\ \u0026amp;= D^{2}y+(1-x^{2})y \\\\ \u0026amp;= (D^{2}-x^{2}+1)y \\end{align*} $$ Therefore $$ (D-x)(D+x)=D^{2}-x^{2}+1 $$\n‚ñ†\n","id":1638,"permalink":"https://freshrimpsushi.github.io/en/posts/1638/","tags":null,"title":"What is a Differential Operator in Physics?"},{"categories":"Ìï®Ïàò","contents":"Buildup The differential equation below is referred to as the modified Bessel equation.\n$$ x^2 y^{\\prime \\prime} + xy^{\\prime}-(x^2-\\nu^2)y=0 $$\nIt is a form of the Bessel equation where the sign of the term $y$ has been changed to $+ \\rightarrow -$. The solution to this differential equation is given by the formula for differential equations that have Bessel equation solutions, as follows.\n$$ y=Z_{\\nu}(ix)=AJ_{\\nu}(ix)+BN_{\\nu}(ix) $$\nThe two commonly used forms of the solution are referred to as modified Bessel functions. In particular, $I_{\\nu}$ is called the modified Bessel function of the first kind, and $K_{\\nu}$ is called the modified Bessel function of the second kind.\nDefinition The modified Bessel function of the first kind $I_{\\nu}$ and the modified Bessel function of the second kind $K_{\\nu}$ are defined as follows.\n$$ \\begin{align*} I_{\\nu}(x)\u0026amp;=i^{-\\nu}J_{\\nu}(ix) \\\\ \\\\ K_{\\nu}(x) \u0026amp;= \\frac{\\pi}{2}i^{\\nu+1}\\left[ J_{\\nu}(ix)+iN_{\\nu}(ix) \\right] \\\\ \u0026amp;= \\frac{\\pi}{2}i^{\\nu+1}H_{p}^{(1)}(ix) \\\\ \u0026amp;=\\frac{\\pi}{2}\\frac{I_{-\\nu}(x)-I_{\\nu}(x)}{\\sin (\\nu\\pi )} \\end{align*} $$\nHere, $J_{\\nu}$ $H_{\\nu}^{(1)}(x)$ are Hankel functions.\nExplanation The reason for multiplication by $i$ upfront is to ensure that for real $x$, the values of $I_{\\nu}(x)$ and $K_{\\nu}(x)$ are real. This situation is similar to that in which the solutions of $y^{\\prime \\prime}+y=0$ are $\\cos x$ and $\\sin x$, and the solutions of $y^{\\prime \\prime}-y=0$ are $\\cosh x=\\cos (ix)$ and $\\sinh (x)=\\sin (ix)$. Due to these characteristics of the equations, $I_{\\nu}$ and $K_{\\nu}$ are also referred to as hyperbolic Bessel functions.\nIntegral Form An integral form was made known by Olver et al. in 20101.\n$$ I_{\\nu} (z) = {{ \\left( {{ z } \\over { 2 }} \\right)^{\\nu} } \\over { \\sqrt{\\pi} \\Gamma \\left( \\nu + {{ 1 } \\over { 2 }} \\right) }} \\int_{-1}^{1} e^{zt} \\left( 1 - t^{2} \\right)^{\\nu - {{ 1 } \\over { 2 }}} dt $$\nSuch modified Bessel functions are crucial not only in mathematical physics but also in areas like directional statistics, and they appear in the Mat√©rn function, which is one of the plausible choices for the semivariogram in spatial statistical analysis.\nSungkyu Jung. \u0026ldquo;Geodesic projection of the von Mises‚ÄìFisher distribution for projection pursuit of directional data.\u0026rdquo; Electron. J. Statist. 15 (1) 984 - 1033, 2021. https://doi.org/10.1214/21-EJS1807\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1624,"permalink":"https://freshrimpsushi.github.io/en/posts/1624/","tags":null,"title":"Modified Bessel Equation and Modified Bessel Function"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition[^1] A second solution of the Bessel equation is called the Neumann function, denoted by $N_{\\nu}(x)$ or $Y_{\\nu}(x)$. For non-integer $\\nu$,\n$$ N_{\\nu}(x)=Y_{\\nu}(x)=\\frac{\\cos (\\nu \\pi)J_{\\nu}(x)-J_{-\\nu}(x)}{\\sin (\\nu\\pi)} $$\nFor integer $\\nu$, it is defined by the limit. For $n\\in \\mathbb{Z}$, $\\nu \\in \\mathbb{R}\\setminus\\mathbb{Z}$,\n$$ N_{n}(x)=\\lim \\limits_{\\nu \\rightarrow n}N_{\\nu}(x) $$\nHere, $J_{\\pm \\nu}(x)$ is the first kind Bessel function. Thus, the general solution of the Bessel equation is as follows.\n$$ y(x)=AJ_{\\nu}(x)+BN_{\\nu}(x) $$\nHere $A$, $B$ are arbitrary constants.\nExplanation $$ x^{2}y^{\\prime \\prime} + xy^{\\prime} +(x^{2}-\\nu^{2})y=0 $$\nThe series solution of the above Bessel equation is denoted as $J_{\\pm\\nu}(x)$ and is called the $\\nu$th first kind Bessel function.\n$$ J_{\\nu}(x)=\\sum \\limits_{n=0}^{\\infty} \\frac{(-1)^{n} }{\\Gamma (n+1) \\Gamma (n+\\nu+1)} \\left(\\frac{x}{2} \\right)^{2n+\\nu} $$\n$$ J_{-\\nu}(x)=\\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}}{\\Gamma (n+1)\\Gamma (n-\\nu+1)} \\left( \\frac{x}{2} \\right)^{2n-\\nu} $$\nAs you can see, since the two solutions are independent, the general solution is as follows.\n$$ y(x)=AJ_{\\nu}(x)+BJ_{-\\nu}(x) $$\nHowever, when $\\nu$ is an integer, the two solutions are not linearly independent. Therefore, a second solution independent of $J_{\\nu}(x)$ must be found when $\\nu$ is an integer.\nConsider briefly $\\sin x$ and $\\cos x$. The two functions are linearly independent. However, any linear combination of $\\sin x$ and $\\cos x$ is also linearly independent of $\\sin x$. With this idea, any linear combination of $J_{\\nu}(x)$ and $J_{-\\nu}(x)$ is considered the second solution of the Bessel equation.\n$$ \\begin{equation} N_{\\nu}(x)=\\frac{\\cos (\\nu \\pi)J_{\\nu}(x)-J_{-\\nu}(x)}{\\sin (\\nu\\pi)} \\label{eq1} \\end{equation} $$\n$N_{\\nu}(x)$ is independent of $J_{\\nu}(x)$ regardless of the condition of $\\nu$. However, a problem arises again if $\\nu$ is an integer, then\n$$ N_{\\nu}(x)=\\frac{\\cos (\\nu \\pi)J_{\\nu}(x)-J_{-\\nu}(x)}{\\sin (\\nu\\pi)}=\\frac{(-1)^{\\nu}J_{\\nu}(x)-(-1)^{\\nu}J_{\\nu}(x)}{0}=\\frac{0}{0} $$\nit becomes undefined. Therefore, when $\\nu$ is an integer, it is defined using the limit as follows.\n$$ N_{n}(x)=\\lim \\limits_{\\nu \\rightarrow n}N_{\\nu}(x)\\quad \\text{for }n\\in \\mathbb{Z},\\ \\nu \\in \\mathbb{R}\\setminus \\mathbb{Z} $$\nAt this time, the above limit exists for arbitrary $x \\ne 0$.\nSummary For integer $\\nu$, the Bessel function $J_{\\pm \\nu}(x)$ satisfies the following equation. In other words, it is not independent.\n$$ J_{-\\nu}(x)=(-1)^{\\nu}J_{\\nu}(x) $$\nProof $$ J_{-\\nu}(x)=\\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}}{\\Gamma (n+1)\\Gamma (n-\\nu+1)} \\left( \\frac{x}{2} \\right)^{2n-\\nu} $$\nBy substituting $n=k+\\nu$, then\n$$ J_{-\\nu}(x)=\\sum \\limits_{k=-\\nu}^{\\infty}\\frac{(-1)^{k+\\nu}}{\\Gamma (k+\\nu+1)\\Gamma (k+1)} \\left( \\frac{x}{2} \\right)^{2k+\\nu} $$\nSince the gamma function diverges for $0$ and negative integers, when $k=-\\nu,-\\nu+1,\\cdots,-1$, the denominator\u0026rsquo;s $\\Gamma (k+1)$ diverges, making $J_{-\\nu}(x)=0$. Therefore,\n$$ \\begin{align*} J_{-\\nu}(x)\u0026amp;=\\sum \\limits_{k=-\\nu}^{\\infty}\\frac{(-1)^{k+\\nu}}{\\Gamma (k+\\nu+1)\\Gamma (k+1)} \\left( \\frac{x}{2} \\right)^{2k+\\nu} \\\\ \u0026amp;=\\sum \\limits_{k=0}^{\\infty}\\frac{(-1)^{k+\\nu}}{\\Gamma (k+\\nu+1)\\Gamma (k+1)} \\left( \\frac{x}{2} \\right)^{2k+\\nu} \\\\ \u0026amp;=(-1)^{\\nu}\\sum \\limits_{k=0}^{\\infty}\\frac{(-1)^{k}}{\\Gamma (k+\\nu+1)\\Gamma (k+1)} \\left( \\frac{x}{2} \\right)^{2k+\\nu} \\\\ \u0026amp;=(-1)^{\\nu}J_{\\nu}(x) \\end{align*} $$\n‚ñ†\n","id":1618,"permalink":"https://freshrimpsushi.github.io/en/posts/1618/","tags":null,"title":"The Second Series Solution of the Bessel Equation: Bessel Functions of the Second Kind, Neumann Functions, Weber Functions"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 The arithmetic function defined as follows $u$ is called the unit function. $$ u(n) := 1 $$\nBasic Properties [1] Unit series: Equals the number of divisors $\\sigma_{0}$. In other words, $$ \\sum_{d \\mid n} u(d) = \\sigma_{0} (n) $$ [2] Completely multiplicative: For all $m,n \\in \\mathbb{N}$, $u(mn) = u(m) u(n)$ Explanation $$ \\begin{matrix} n \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 4 \u0026amp; 5 \u0026amp; 6 \u0026amp; 7 \u0026amp; 8 \u0026amp; 9 \u0026amp; 10 \\\\ u (n) \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \\\\ \\sum_{d \\mid n} u(d) \u0026amp; 1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 3 \u0026amp; 2 \u0026amp; 4 \u0026amp; 2 \u0026amp; 4 \u0026amp; 3 \u0026amp; 4 \\end{matrix} $$ As can be inferred from the name \u0026ldquo;unit function\u0026rdquo;, it is a very important function. Considering convolution, the series $F$ of any arithmetic function $f$ is actually expressed as follows. $$ f \\ast\\ u = F $$\nProof [1] $$ \\sum_{d \\mid n} u(d) = \\sum_{d \\mid n} 1 = \\sigma_{0} (n) $$ Trivial due to the definition of the divisor function.\n‚ñ†\n[2] $$ u(mn) = 1 = 1 \\cdot 1 = u(m) u(n) $$\n‚ñ†\nApostol. (1976). Introduction to Analytic Number Theory: p31.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1547,"permalink":"https://freshrimpsushi.github.io/en/posts/1547/","tags":null,"title":"In Analytic Number Theory"},{"categories":"Ìï®Ïàò","contents":"Definition Legendre Polynomials are defined in several ways.\nAs Solutions to a Differential Equation Legendre polynomials are solutions to the following Legendre differential equation.\n$$ (1-x^{2}) \\dfrac{d^{2} y}{dx^{2}} -2x\\dfrac{dy}{dx} + l(l+1) y = 0 $$\nRodrigues\u0026rsquo; Formula The following function $P_{l}$ is called a Legendre polynomial.\n$$ P_{l}(x) = \\dfrac{1}{2^{l} l!} \\dfrac{d^{l}}{dx^{l}}(x^{2}-1)^{l} $$\nThis is known as Rodrigues\u0026rsquo; formula.\nUsing Orthogonality Description By definition, $P_{n}$ is indeed a polynomial \u0026lsquo;function\u0026rsquo;, but it is conventionally called Legendre \u0026lsquo;polynomial\u0026rsquo;. This is not only the case in Korean, but also in English-speaking countries, where it is called the Legendre polynomial.\nLegendre polynomials are used in various fields such as mathematics, physics, and engineering. They have many nice mathematical properties, including orthogonality, and appear as solutions to the Laplace equation in spherical coordinates.\nProperties ","id":1611,"permalink":"https://freshrimpsushi.github.io/en/posts/1611/","tags":null,"title":"Legendre Polynomials"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 For $\\alpha , \\beta \u0026gt; 0$, the continuous probability distribution $\\text{Beta}(\\alpha,\\beta)$, called the beta Distribution, has the following probability density function: $$ f(x) = {{ 1 } \\over { B(\\alpha,\\beta) }} x^{\\alpha - 1} (1-x)^{\\beta - 1} \\qquad , x \\in [0,1] $$\n$B$ represents the beta function. Basic Properties Moment Generating Function [1]: $$m(t) = 1 + \\sum_{k=1}^{\\infty} \\left( \\prod_{r=0}^{k-1} {{ \\alpha + r } \\over { \\alpha + \\beta + r }} {{ t^{k} } \\over { k! }} \\right) \\qquad , t \\in \\mathbb{R}$$ Mean and Variance [2]: If $X \\sim \\text{Beta}(\\alpha,\\beta)$, then $$ \\begin{align*} E(X) =\u0026amp; {\\alpha \\over {\\alpha + \\beta} } \\\\ \\text{Var} (X) =\u0026amp; { { \\alpha \\beta } \\over {(\\alpha + \\beta + 1) { ( \\alpha + \\beta ) }^2 } } \\end{align*} $$ Sufficient Statistics [3]: Suppose a random sample $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{n} \\right) \\sim \\text{Beta} \\left( \\alpha, \\beta \\right)$ following a beta distribution is given. The sufficient statistic $T$ for $\\left( \\alpha, \\beta \\right)$ is as follows: $$ T = \\left( \\prod_{i} X_{i}, \\prod_{i} \\left( 1 - X_{i} \\right) \\right) $$\nTheorems Derivation from Gamma Distribution [a]: If two random variables $X_{1},X_{2}$ are independent and $X_{1} \\sim \\Gamma ( \\alpha_{1} , 1)$, $X_{2} \\sim \\Gamma ( \\alpha_{2} , 1)$ are given, then $$ {{ X_{1} } \\over { X_{1} + X_{2} }} \\sim \\text{beta} \\left( \\alpha_{1} , \\alpha_{2} \\right) $$ Derivation from F-distribution [b]: For a random variable $X \\sim F \\left( r_{1}, r_{2} \\right)$ following an F-distribution with degrees of freedom $r_{1} , r_{2}$, the defined $Y$ follows a beta distribution. $$ Y := {{ \\left( r_{1} / r_{2} \\right) X } \\over { 1 + \\left( r_{1} / r_{2} \\right) X }} \\sim \\text{Beta} \\left( {{ r_{1} } \\over { 2 }} , {{ r_{2} } \\over { 2 }} \\right) $$ Description Just as the gamma distribution comes from the gamma function, the beta distribution is named after the beta function. The beta function has the following relationship with the gamma function, allowing it to be expressed via gamma functions. $$ B(p,q) = {{\\Gamma (p) \\Gamma (q)} \\over {\\Gamma (p+q) }} $$ In fact, the gamma distribution can induce a beta distribution.\nJust like the beta function can be seen as a generalization of binomial coefficients, careful observation of the beta distribution\u0026rsquo;s probability density function reveals its resemblance to the probability mass function of a binomial distribution $P(k) = { _n {C} _k }{ p ^ k }{ (1-p) ^ { n - k } }$. Although it doesn\u0026rsquo;t precisely match the definition of a beta distribution, if one considers $\\alpha$ as the number of successes and $\\beta$ as the number of failures, the resemblance is noticeable in: $$ n = \\alpha + \\beta \\\\ \\displaystyle p = {{\\alpha } \\over {\\alpha + \\beta}} \\\\ \\displaystyle q = {{\\beta } \\over {\\alpha + \\beta}} $$ In fact, in Bayesian analysis, it is used as the conjugate prior distribution of a binomial distribution.\nProof [1] Though the equations are complex, there is no logical difficulty.\nExponential function series expansion: $$ { { e ^ x } }=\\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ n } }{ n! } } $$\nEuler integration: $$ B(p,q)=\\int_0^1 t^{p-1}(1-t)^{q-1}dt $$\n$$ \\begin{align*} m(t) =\u0026amp; \\int_{0}^{1} e^{tx} {{ 1 } \\over { B(\\alpha,\\beta) }} x^{\\alpha - 1} (1-x)^{\\beta - 1} dx \\\\ =\u0026amp; {{ 1 } \\over { B(\\alpha,\\beta) }} \\int_{0}^{1} \\left( \\sum_{k=0}^{\\infty} {{ (tx)^{k} } \\over { k! }} \\right) x^{\\alpha - 1} (1-x)^{\\beta - 1} dx \\\\ =\u0026amp; {{ 1 } \\over { B(\\alpha,\\beta) }} \\sum_{k=0}^{\\infty} {{ t^{k} } \\over { k! }} \\int_{0}^{1} x^{\\alpha + k - 1} (1-x)^{\\beta - 1} dx \\\\ =\u0026amp; {{ 1 } \\over { B(\\alpha,\\beta) }} \\sum_{k=0}^{\\infty} {{ t^{k} } \\over { k! }} B \\left( \\alpha + k , \\beta \\right) \\\\ =\u0026amp; \\sum_{k=0}^{\\infty} {{ t^{k} } \\over { k! }} {{ B \\left( \\alpha + k , \\beta \\right) } \\over { B(\\alpha,\\beta) }} \\\\ =\u0026amp; {{ t^{0} } \\over { 0! }} {{ B \\left( \\alpha + 0 , \\beta \\right) } \\over { B(\\alpha,\\beta) }} + \\sum_{k=1}^{\\infty} {{ t^{k} } \\over { k! }} {{ B \\left( \\alpha + k , \\beta \\right) } \\over { B(\\alpha,\\beta) }} \\end{align*} $$\nRelationship between Beta function and Gamma function: $$B(p,q) = {{\\Gamma (p) \\Gamma (q)} \\over {\\Gamma (p+q) }}$$\nExpanding the Beta function into Gamma functions results in:\n$$ \\begin{align*} m(t) =\u0026amp; 1 + \\sum_{k=1}^{\\infty} {{ t^{k} } \\over { k! }} {{ B \\left( \\alpha + k , \\beta \\right) } \\over { B(\\alpha,\\beta) }} \\\\ =\u0026amp; 1 + \\sum_{k=1}^{\\infty} {{ t^{k} } \\over { k! }} {{ \\Gamma ( \\alpha + k ) \\Gamma ( \\beta ) } \\over { \\Gamma \\left( \\alpha + \\beta + k \\right) }} {{ \\Gamma ( \\alpha + \\beta ) } \\over { \\Gamma \\left( \\alpha \\right) \\Gamma \\left( \\beta \\right) }} \\\\ =\u0026amp; 1 + \\sum_{k=1}^{\\infty} {{ t^{k} } \\over { k! }} {{ \\Gamma ( \\alpha + k ) } \\over { \\Gamma \\left( \\alpha + \\beta + k \\right) }} {{ \\Gamma ( \\alpha + \\beta ) } \\over { \\Gamma \\left( \\alpha \\right) }} \\\\ =\u0026amp; 1 + \\sum_{k=1}^{\\infty} {{ t^{k} } \\over { k! }} {{ \\Gamma ( \\alpha + k ) } \\over { \\Gamma \\left( \\alpha \\right) }} {{ \\Gamma ( \\alpha + \\beta ) } \\over { \\Gamma \\left( \\alpha + \\beta + k \\right) }} \\\\ =\u0026amp; 1 + \\sum_{k=1}^{\\infty} {{ t^{k} } \\over { k! }} {{ \\Gamma ( \\alpha ) \\prod_{r=0}^{k-1} ( \\alpha + r) } \\over { \\Gamma \\left( \\alpha \\right) }} {{ \\Gamma ( \\alpha + \\beta ) } \\over { \\Gamma \\left( \\alpha + \\beta \\right) \\prod_{r=0}^{k-1} ( \\alpha + \\beta + r) }} \\\\ =\u0026amp; 1 + \\sum_{k=1}^{\\infty} {{ t^{k} } \\over { k! }} \\prod_{r=0}^{k-1} {{ \\alpha + r } \\over { \\alpha + \\beta + r }} \\end{align*} $$\n‚ñ†\n[2] Derive directly.\n‚ñ†\n[3] Though $(1 - x)$ may make one uncomfortable, just derive directly.\n[a] Derive directly using the probability density function.\n‚ñ†\n[b] Derive directly using the probability density function.\n‚ñ†\nCode Below is the Julia code that displays the probability density function of the beta distribution as a GIF.\n@time using LaTeXStrings @time using Distributions @time using Plots cd(@__DIR__) x = 0:0.01:1 B = collect(0.1:0.1:10.0); append!(B, reverse(B)) animation = @animate for Œ≤ ‚àà B plot(x, pdf.(Beta(0.5, Œ≤), x), color = :black, label = \u0026#34;Œ± = 0.5, Œ≤ = $(rpad(Œ≤, 3, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300)) xlims!(0,1); ylims!(0,5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,Beta} (0.5, \\beta)\u0026#34;) end gif(animation, \u0026#34;pdf0.gif\u0026#34;) animation = @animate for Œ≤ ‚àà B plot(x, pdf.(Beta(1, Œ≤), x), color = :black, label = \u0026#34;Œ± = 1, Œ≤ = $(rpad(Œ≤, 3, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300)) xlims!(0,1); ylims!(0,5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,Beta} (1, \\beta)\u0026#34;) end gif(animation, \u0026#34;pdf1.gif\u0026#34;) animation = @animate for Œ≤ ‚àà B plot(x, pdf.(Beta(2, Œ≤), x), color = :black, label = \u0026#34;Œ± = 2, Œ≤ = $(rpad(Œ≤, 3, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300)) xlims!(0,1); ylims!(0,5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,Beta} (2, \\beta)\u0026#34;) end gif(animation, \u0026#34;pdf2.gif\u0026#34;) Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p165.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1540,"permalink":"https://freshrimpsushi.github.io/en/posts/1540/","tags":null,"title":"Beta Distribution"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 The differential equation given below is called the associated Legendre differential equation.\n$$ \\begin{equation} \\begin{aligned} \u0026amp;\u0026amp;(1-x^{2})\\frac{ d^{2}y }{ dx^{2} }-2x \\frac{dy}{dx}+\\left[ +l(l+1)-\\frac{m^{2}}{1-x^{2}} \\right]y =\u0026amp;\\ 0 \\\\ \\mathrm{or} \u0026amp;\u0026amp; \\frac{ d }{ dx } \\left[ (1-x^{2})y^{\\prime} \\right] +\\left[ l(l+1)-\\frac{m^{2}}{1-x^{2}} \\right]y =\u0026amp;\\ 0 \\end{aligned} \\label{1} \\end{equation} $$\nThe solution to the associated Legendre differential equation is denoted as $P_{l}^{m}(x)$, and this is called the associated Legendre polynomial or the generalized Legendre polynomial.\n$$ \\begin{align*} P_{l}^{m}(x)\u0026amp;= (1-x ^{2})^{\\frac{|m|}{2}} \\frac{ d^{|m|} }{ dx^{|m|} } P_{l}(x) \\\\ \u0026amp;=(1-x ^{2})^{\\frac{|m|}{2}} \\frac{ d^{|m|} }{ dx^{|m|} }\\left[ \\dfrac{1}{2^{l} l!} \\dfrac{d^{l}}{dx^{l}}(x^2-1)^{l}\\right] \\end{align*} $$\nHere, $P_{l}(x)$ is the Legendre polynomial. In cases distinguished by the sign of $m$,\n$$ P_{l}^{m}(x) = (1-x ^{2})^{\\frac{m}{2}} \\dfrac{1}{2^{l} l!} \\dfrac{d^{l+m}}{dx^{l+m}}(x^2-1)^{l} $$\n$$ P_{l}^{-m}=(-1)^{m}\\frac{(l-m)!}{(l+m)!}P_{l}^{m}(x) $$\nThe associated Legendre polynomials appear when solving the Laplace equation in spherical coordinates. Here, the constants $l$, $m$ are related to the quantum numbers in quantum mechanics.\nSolution For $m=0$, it\u0026rsquo;s the Legendre differential equation. Based on the solution for this case, we can also find a solution for when it is $m\\ne 0$. Initially, since the solution to the associated Legendre differential equation is determined by the constants $l$, $m$, let‚Äôs denote it as follows.\n$$ y=P_{l}^{m}(x) $$\nSubstitute this into $\\eqref{1}$ and organize it as below.\n$$ \\begin{equation} \\frac{ d }{ dx }\\left[ (1-x^{2})\\frac{ d P_{l}^{m}(x)}{ dx } \\right]+\\left[ l(l+1)-\\frac{m^{2}}{1-x^{2}} \\right]P_{l}^{m}(x)=0 \\label{2} \\end{equation} $$\nAnd let\u0026rsquo;s assume that the solution has the form below.\n$$ P_{l}^{m}(x)=(1-x^{2})^{\\frac{|m|}{2}}u(x) $$\nDifferentiating $x$ once gives\n$$ \\frac{ d P_{l}^{m}(x)}{ d x }=-|m|x(1-x^{2})^{\\frac{|m|}{2}-1}u(x)+(1-x^{2})^{\\frac{|m|}{2}}u^{\\prime}(x) $$\nSubstituting this into the first term of $\\eqref{2}$ and organizing gives the following.\n$$ \\begin{align*} \\frac{ d }{ dx }\\left[ (1-x^{2})\\frac{ d P_{l}^{m}(x)}{ dx } \\right] =\u0026amp;\\ \\frac{ d }{ dx }\\left[ -|m|x(1-x^{2})^{\\frac{|m|}{2}}u(x)+(1-x^{2})^{\\frac{|m|}{2}+1}u^{\\prime}(x) \\right] \\\\ =\u0026amp;\\ -|m|(1-x^{2})^{\\frac{|m|}{2}}u(x)+|m|^{2}x^{2}(1-x^{2})^{\\frac{|m|}{2}-1}u(x) \\\\ \u0026amp; -|m|x(1-x^{2})^{\\frac{|m|}{2}}u^{\\prime}(x)-(|m|+2)x(1-x^{2})^{\\frac{|m|}{2}}u^{\\prime}(x) \\\\ \u0026amp; +(1-x^{2})^{\\frac{|m|}{2}+1}u^{\\prime \\prime}(x) \\\\ =\u0026amp;\\ (1-x^{2})^{\\frac{|m|}{2}+1}u^{\\prime \\prime}(x)-2(|m|+1)(1-x^{2})^{\\frac{|m|}{2}}u^{\\prime}(x) \\\\ \u0026amp; -[|m|(|m|+1)x^{2}-|m|] (1-x^{2})^{\\frac{|m|}{2}-1}u(x) \\end{align*} $$\nMultiplying both sides by $\\dfrac{1}{(1-x^{2})^{|m|/2}}$ gives\n$$ \\begin{align*} \u0026amp;\\frac{1}{(1-x^{2})^{|m|/2}}\\frac{ d }{ dx }\\left[ (1-x^{2})\\frac{ d P_{l}^{m}(x)}{ dx } \\right] \\\\ =\u0026amp;\\ (1-x^{2})u^{\\prime \\prime}(x)-2(|m|+1)xu^{\\prime}(x) -[|m|(|m|+1)x^{2}-|m|] (1-x^{2})^{-1}u(x) \\end{align*} $$\nTherefore, multiplying both sides of $\\eqref{2}$ by $\\dfrac{1}{(1-x^{2})^{|m|/2}}$ gives\n$$ \\begin{equation} \\begin{aligned} \u0026amp;(1-x^{2})u^{\\prime \\prime}(x)-2(|m|+1)xu^{\\prime}(x) \\\\ \u0026amp;-\\left( \\frac{|m|(|m|+1)x^{2}-|m|}{1-x^{2}}+l(l+1)-\\frac{m^{2}}{1-x^{2}}\\right)u(x)=0 \\end{aligned} \\label{1} \\end{equation} $$\nOrganizing the coefficients of $u(x)$ gives the following.\n$$ \\begin{align*} \u0026amp;\\frac{|m|(|m|+1)x^{2}-|m|}{1-x^{2}}+l(l+1)-\\frac{m^{2}}{1-x^{2}} \\\\ =\u0026amp;\\ \\frac{|m|(|m|+1)x^{2}-|m|+l(l+1)(1-x^{2})-m^{2}}{1-x^{2}} \\\\ =\u0026amp;\\ \\frac{-m^{2}(1-x^{2})-|m|(1-x^{2})+l(l+1)(1-x^{2})}{1-x^{2}} \\\\ =\u0026amp;\\ l(l+1)-m^{2}-|m| \\\\ =\u0026amp;\\ l(l+1)-|m|(|m|+1) \\end{align*} $$\nThus, $\\eqref{3}$ is organized into the form below.\n$$ \\begin{equation} (1-x^{2})\\frac{ d^{2} u }{ d x^{2} }-2(|m|+1)x\\frac{ d u}{ dx }+[l(l+1)-|m|(|m|+1)]u=0 \\label{4} \\end{equation} $$\nIf it is $m=0$, it indeed becomes the Legendre differential equation. Therefore, the solution for when it is $|m|=0$ is $P_{l}^{0}(x)=P_{l}(x)$. Now, let‚Äôs differentiate $(4)$ relative to $x$ again. Organizing the coefficients gives the following equation.\n$$ \\begin{equation} (1-x^{2}) \\frac{ d^{3} u }{ d x^{3} } -2[(|m|+1)+1]x\\frac{ d^{2} u}{ dx^{2} }+[l(l+1)-(|m|+1)(|m|+2)]\\frac{ d u}{ d x}=0 \\label{5} \\end{equation} $$\nDifferentiating $\\eqref{5}$ relative to $x$ again and organizing the coefficients gives the following.\n$$ \\begin{equation} (1-x^{2}) \\frac{ d^{4} u }{ d x^{4} } -2[(|m|+2)+1]x\\frac{ d^{3} u}{ dx^{3} }+[l(l+1)-(|m|+2)(|m|+3)]\\frac{ d^{2} u}{ d x^{2}}=0 \\label{6} \\end{equation} $$\nExamining the equations above shows that when $\\eqref{4}$ is substituted with $u$ into $\\dfrac{ d u}{ d x }$, and $|m|$ is substituted with $|m|+1$ into $\\eqref{5}$, we can obtain $\\eqref{5}$. Using the same method of substitution for $\\eqref{5}$ gives $\\eqref{6}$. From this, we can learn that the solution when it is $|m|=0$ is $P_{l}(x)$, when it is $|m|=1$ it is $\\dfrac{ d }{ d x }P_{l}(x)$, and when it is $|m|=2$ it is $\\dfrac{d^{2}}{dx^{2}}P_{l}(x)$. Therefore, generalizing this gives the following.\n$$ u(x)=\\frac{d^{|m|}}{dx^{{|m|}}}P_{l}(x) $$\nTherefore, the associated Legendre polynomials are as follows.\n$$ \\begin{align*} P_{l}^{m}(x)\u0026amp;= (1-x ^{2})^{\\frac{|m|}{2}} \\frac{ d^{|m|} }{ dx^{|m|} } P_{l}(x) \\\\ \u0026amp;=(1-x ^{2})^{\\frac{|m|}{2}} \\frac{ d^{|m|} }{ dx^{|m|} }\\left[ \\dfrac{1}{2^{l} l!} \\dfrac{d^{l}}{dx^{l}}(x^2-1)^{l}\\right] \\end{align*} $$\n‚ñ†\nMary L. Boas, Mathematical Methods in the Physical Sciences (3rd Edition, 2008), p597-598\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1605,"permalink":"https://freshrimpsushi.github.io/en/posts/1605/","tags":null,"title":"Associated Legendre Differential Equations and Polynomials"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":"Overview Time-independent Schr√∂dinger equation $$ H\\psi=\\left(-\\frac{\\hbar^{2}}{2m}\\frac{ d ^{2} }{ d x^{2} }+V\\right)\\psi=E\\psi \\\\ H\\psi=\\left(-\\frac{\\hbar^{2}}{2m}\\nabla^{2}+V\\right)\\psi=E\\psi $$\nTime-dependent Schr√∂dinger equation $$ i\\hbar\\frac{ \\partial \\psi}{ \\partial t}=\\left(-\\frac{\\hbar^{2}}{2m}\\frac{ \\partial ^{2} }{\\partial x^{2} }+V\\right)\\psi \\\\ i\\hbar\\frac{ \\partial \\psi}{ \\partial t}=\\left(-\\frac{\\hbar^{2}}{2m}\\nabla^{2}+V\\right)\\psi $$\nThe Schr√∂dinger equation refers to a partial differential equation related to the complex wave function\u0026rsquo;s energy, position, and time. Simply put, in classical mechanics, it is\n$$ F=ma $$\nUsing this, the wave function in various potential situations and the energy of the wave function can be calculated. First, the wave function for time and position with wave number $k$ and angular frequency $\\omega$ in one dimension is as follows.\n$$ \\psi (x,t)=e^{i(kx-\\omega t)} \\tag{1} $$\nTo simplify the equation, the preceding constants have been omitted. The de Broglie relation is as follows.\n$$ \\lambda=\\frac{h}{p} $$\n$$ k=\\frac{p}{\\hbar} \\tag{2} $$\nFrom Planck\u0026rsquo;s blackbody radiation and Einstein\u0026rsquo;s photoelectric effect, the following relationship is obtained.\n$$ E=h\\nu=\\hbar \\omega \\tag{3} $$\n$\\nu=\\frac{\\omega}{2\\pi}$ is the frequency of the particle. Quantum mechanics is described through wave functions, operators, and eigenvalue equations, so let\u0026rsquo;s derive the Schr√∂dinger equation using this.\nTime-independent Schr√∂dinger equation The aim is to obtain an energy operator $E_{op}$ with an eigenfunction as wave function $\\psi$, and eigenvalue as the energy $E$ of $\\psi$. Since the energy of a particle is kinetic energy + potential energy,\n$$ E=\\frac{p^{2}}{2m}+V $$\nAccording to the de Broglie relation $(2)$, we have $p=k\\hbar$,\n$$ E=\\frac{\\hbar^{2}k^{2}}{2m}+V $$\nMultiplying both sides by the wave function $\\psi$,\n$$ \\frac{\\hbar^{2}k^{2}}{2m}\\psi+V\\psi=E\\psi \\tag{4} $$\nAt this time, since the wave function is $(1)$,\n$$ \\frac{d^{2}\\psi }{dx^{2} }=-k^{2}\\psi\\quad \\implies\\quad -\\frac{\\hbar^{2}}{2m}\\frac{d^{2}\\psi }{dx^{2} }=\\frac{\\hbar^{2}k^{2}}{2m}\\psi $$\nTherefore, $(4)$ is\n$$ \\begin{align*} \u0026amp;\u0026amp;-\\frac{\\hbar^{2}}{2m}\\frac{ d ^{2}\\psi}{ dx^{2} }+V\\psi=E\\psi \\\\ \\implies \u0026amp;\u0026amp;\\left(-\\frac{\\hbar^{2}}{2m}\\frac{ d ^{2}}{ dx^{2} }+V\\right)\\psi=E\\psi \\end{align*} $$\nThis equation is called the time-independent Schr√∂dinger equation. Also, the energy operator\n$$ -\\frac{\\hbar^{2}}{2m}\\frac{ d ^{2}}{ dx^{2} }+V=H $$\nis simply referred to as $H$ and is called the Hamiltonian. In three dimensions, the Hamiltonian and the Schr√∂dinger equation are as follows.\n$$ H=-\\frac{\\hbar^{2}}{2m}\\nabla^{2}+V $$\n$$ \\left(-\\frac{\\hbar^{2}}{2m}\\nabla^{2}+V\\right)\\psi=E\\psi \\tag{5} $$\nUsing $H$, the time-independent Schr√∂dinger equation can be simply represented as\n$$ H\\psi=E\\psi $$\nTime-dependent Schr√∂dinger equation According to $(3)$, the energy of a particle is expressed by the angular frequency $\\omega$ and Planck\u0026rsquo;s constant $\\hbar$. The angular frequency can be obtained by differentiating the wave function $(1)$ with respect to time. $$ \\frac{ \\partial \\psi}{ \\partial t }=-i\\omega\\psi $$ Therefore, $$ E\\psi=\\hbar \\omega \\psi=i\\hbar\\frac{ \\partial \\psi}{ \\partial t } $$ By substituting this into $(5)$, we obtain the time-dependent Schr√∂dinger equation. $$ i\\hbar\\frac{ \\partial \\psi}{ \\partial t}=\\left(-\\frac{\\hbar^{2}}{2m}\\frac{ \\partial ^{2} }{ \\partial x^{2} }+V\\right)\\psi \\\\ i\\hbar\\frac{ \\partial \\psi}{ \\partial t}=\\left(-\\frac{\\hbar^{2}}{2m}\\nabla^{2}+V\\right)\\psi $$\n","id":1598,"permalink":"https://freshrimpsushi.github.io/en/posts/1598/","tags":null,"title":"Derivation of the Schr√∂dinger Equation"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition The general solution for the polar and azimuthal angles in the spherical coordinate system for the Laplace equation is as follows, and this is called Spherical harmonics.\n$$ Y_{l}^{m}(\\theta,\\phi)=e^{im\\phi}P_{l}^{m}(\\cos \\theta) $$\nHere, $l$ is $l=0,1,2\\cdots$ and $m$ is an integer that satisfies $ -l \\le m \\le l$. Also, $P_{l}^{m}(\\cos\\theta)$ is as follows.\n$$ \\begin{align*} P_{l}^{m}(\\cos \\theta)\u0026amp;= (1-\\cos ^{2}\\theta)^{\\frac{|m|}{2}} \\frac{ d^{|m|} }{ dx^{|m|} } P_{l}(x) \\\\ \u0026amp; =(1-\\cos ^{2}\\theta)^{\\frac{|m|}{2}} \\frac{ d^{|m|} }{ dx^{|m|} }\\left[ \\dfrac{1}{2^l l!} \\dfrac{d^l}{dx^l}(x^2-1)^l \\right] \\end{align*} $$\n","id":1580,"permalink":"https://freshrimpsushi.github.io/en/posts/1580/","tags":null,"title":"Spherical Harmonics: General Solutions for the Polar and Azimuthal Angles in the Spherical Coordinate Laplace's Equation"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 For a prime number $p_{1} , \\cdots , p_{k}$, let\u0026rsquo;s express a natural number $n$ as follows. The arithmetic function $\\mu$ defined as such is called the M√∂bius function. $$ \\mu (n) := \\begin{cases} 1 \u0026amp;, n=1 \\\\ (-1)^{k} \u0026amp;, a_{1} = \\cdots = a_{k} = 1 \\\\ 0 \u0026amp; , \\text{otherwise} \\end{cases} $$\nBasic Properties [1] M√∂bius series: It\u0026rsquo;s an identity $I$. In other words, $$ \\sum_{d \\mid n } \\mu (d) = I(n) $$ [2] Multiplicativity: For all $m, n \\in \\mathbb{N}$ that satisfy $\\gcd (m,n) = 1$, $\\mu (mn) = \\mu (m) \\mu (n)$ Description $$ \\begin{matrix} n \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 4 \u0026amp; 5 \u0026amp; 6 \u0026amp; 7 \u0026amp; 8 \u0026amp; 9 \u0026amp; 10 \\\\ \\mu (n) \u0026amp; 1 \u0026amp; -1 \u0026amp; -1 \u0026amp; 0 \u0026amp; -1 \u0026amp; 1 \u0026amp; -1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\ \\sum_{d \\mid n} \\mu (d) \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\end{matrix} $$ The M√∂bius function, simply put, is a function that only cares about numbers that are not multiplied by the same prime number $2$ or more times. If a prime number is not multiplied more than $2$ times, its sign only changes depending on whether the prime numbers are used an even or odd number of times. However, this is just an explanation of the definition. The M√∂bius function itself may not have an intuitive meaning, but it is a major function that appears endlessly throughout number theory, especially in analytic number theory.\nProof [1] Let\u0026rsquo;s say $n = p_{1}^{a_{1}} \\cdots p_{k}^{a_{k}} \u0026gt; 1$, then according to the binomial theorem, $$ \\begin{align*} \u0026amp; \\sum_{d \\mid n } \\mu (d) \\\\ =\u0026amp; \\mu (1) \\\\ \u0026amp; + \\mu (p_{1}) + \\cdots + \\mu (p_{k}) \\\\ \u0026amp; + \\mu (p_{1}p_{2}) + \\cdots + \\mu (p_{k-1}p_{k}) \\\\ \u0026amp; \\vdots \\\\ \u0026amp; + \\mu (p_{1}p_{2} \\cdots p_{k-1}p_{k}) \\\\ =\u0026amp; 1 \\\\ \u0026amp; + \\underbrace{(-1) + \\cdots + (-1)}_{k} \\\\ \u0026amp; + \\underbrace{1 + \\cdots + 1}_{k(k-1)/2} \\\\ \u0026amp; \\vdots \\\\ \u0026amp; + (-1)^{k} \\\\ =\u0026amp; 1 + \\binom{k}{1} (-1) + \\binom{k}{2}(-1)^{2} + \\cdots + \\binom{k}{k} (-1)^{k} \\\\ =\u0026amp; [1 + (-1)]^{k} \\end{align*} $$\n‚ñ†\n[2] If either $m$ or $n$ has a prime square as a divisor, then from the definition of $\\mu$, $\\mu (mn) = 0$ and therefore $\\mu (m) \\mu (n) = 0$, then $$ \\mu (mn) = \\mu (m) \\mu (n) $$ Hence, let\u0026rsquo;s assume $m$ and $n$ are in the form where each prime is multiplied only once. $$ m = p_{1} \\cdots p_{s} \\\\ n = q_{1} \\cdots q_{t} $$ Then, $$ \\mu (mn) = (-1)^{s + t} = (-1)^{s} (-1)^{t} = \\mu (m) \\mu (n) $$\n‚ñ†\nApostol. (1976). Introduction to Analytic Number Theory: p24.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1531,"permalink":"https://freshrimpsushi.github.io/en/posts/1531/","tags":null,"title":"The Moebius Function in Analytic Number Theory"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition In the graph $G$, the set of paths whose origin is $v \\in V(G)$ and destination is $w \\in V(G)$ is represented as $P(v,w)$, and let\u0026rsquo;s denote the set of cycles that include $v \\in V(G)$ as $C(v)$. Also, let\u0026rsquo;s present the length of a walk $x$ as $l(x)$.\nThe distance $d$ between two vertices $v,w \\in V(G)$ is defined as the smallest value among the lengths of paths where $v$ is the origin and $w$ is the destination. In other words, $$ d(v,w) := \\min_{v,w \\in V(G)} \\left\\{ l(x) : x \\in P(v,w) \\right\\} $$ The set of vertices $N^{i} (v) \\subset V(G)$ whose distance from vertex $v \\in V(G)$ is exactly $i$ is called a $i$-neighborhood. The diameter $\\text{diam}$ of graph $G$ is defined as the largest distance among all pairs of vertices. In other words, $$ \\text{diam} (G) := \\sup_{v,w \\in V(G)} \\left\\{ d(v,w) : v \\ne w \\right\\} $$ The girth $\\text{girth}$ of graph $G$ is defined as the smallest length among all cycles. In other words, $$ \\text{girth}(G) := \\min_{v \\in V(G)} \\left\\{ l(x) : x \\in C(v) \\right\\} $$ Description The distance between vertices in a graph is also called a Geodesic Distance. This naming is considered valid because, unlike the Euclidean distance, it represents the actual number of steps taken to reach from one vertex to another. For instance, in the following graph, $d(v,w)$ cannot be less than $2$ in any case, and equals $d(v,w) = 2$.\nThe definition of diameter might seem odd at first glance. By analogy, consider a circle $x^2 + y^2 = r^2$. When any two points on the circle are chosen, the furthest distance between them occurs when the points are symmetrically positioned across the center of the circle. Obviously, this distance is $2r$, which is what we refer to as the diameter of the circle. For instance, the diameter of the graph above is $2$.\nGirth, conceptually, refers to the size of the smallest cycle in a graph. Though not explicitly mentioned, if a graph does not contain any cycles, its girth is considered to be infinite. Also, it\u0026rsquo;s self-evident that the minimum value of girth in any graph cannot be less than $3$. For example, as shown in the diagram below, even though there are several cycles, the length of the smallest cycle is $3$, so the girth is $3$.\n","id":1530,"permalink":"https://freshrimpsushi.github.io/en/posts/1530/","tags":null,"title":"Distance, Neighborhood, Diameter, Perimeter in a Graph"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Explanation In physics, an operator refers to a function that maps a function to another function. Among these, the del operator refers to a function that, given a function, results in a function that has the derivative of the given function as its function value. If the term operator is unfamiliar, you can simply understand it as a rule that computes a target. For example, if you insert $f$ into the function $\\dfrac{d}{dx}$, the function value $f^{\\prime}$ comes out.\n$$ \\dfrac{d }{dx} \\left( f \\right) = f^{\\prime} $$\nThe del operator is usually introduced as follows.\n$$ \\nabla = \\frac{ \\partial }{ \\partial x }\\hat{\\mathbf{x}}+\\frac{ \\partial }{ \\partial y }\\hat{\\mathbf{y}}+\\frac{ \\partial }{ \\partial z }\\hat{\\mathbf{z}} $$\nAs shown in the equation above, it is treated as if it were a vector, so it is sometimes denoted as $\\vec{\\nabla}$. By using this, we learn three operations on a scalar function $f$ and a vector function $\\mathbf{A}=A_{x}\\hat{\\mathbf{x}}+A_{y}\\hat{\\mathbf{y}}+A_{z}\\hat{\\mathbf{z}}$. The three operations below are, from top to bottom, the Gradient of $f$, the Divergence of $\\mathbf{A}$, and the Curl of $\\mathbf{A}$.\n$$ \\begin{align*} \\nabla f\u0026amp;=\\frac{ \\partial f }{ \\partial x }\\hat{\\mathbf{x}}+\\frac{ \\partial f }{ \\partial y }\\hat{\\mathbf{y}}+\\frac{ \\partial f }{ \\partial z }\\hat{\\mathbf{z}} \\\\ \\nabla \\cdot \\mathbf{A}\u0026amp;= \\frac{ \\partial A_{x} }{ \\partial x }+\\frac{ \\partial A_{y} }{ \\partial y }+\\frac{ \\partial A_{z} }{ \\partial z } \\\\ \\nabla\\times \\mathbf{A}\u0026amp;= \\left( \\frac{\\partial A_{z}}{\\partial y} - \\frac{\\partial A_{y}}{\\partial z} \\right)\\hat{\\mathbf{x}} + \\left( \\frac{\\partial A_{x}}{\\partial z} - \\frac{ \\partial A_{z}}{\\partial x} \\right)\\hat{\\mathbf{y}} + \\left( \\frac{\\partial A_{y}}{\\partial x}-\\frac{\\partial A_{x}}{\\partial y} \\right)\\hat{\\mathbf{z}} \\end{align*} $$\nAs you can see, if you understand $\\nabla$ as a vector, you can naturally accept the above calculation. However, understanding it this way is incorrect. When complex formulas appear, incorrect calculations can be made in many parts. Especially when the del operator is heavily involved in the formula, the calculation process and results may not be understood, leading to a waste of time.\nThe reason for writing the right-hand side value or vector the same way as the left-hand side is simply because it fits intuitively well; however, in reality, it is not the inner or outer product of $\\nabla$ and $\\mathbf{A}$. If you go into each document and look at the derivation process, you can understand it. Therefore, forget about the del operator and understand $\\nabla f$, $\\nabla \\cdot \\mathbf{A}$, and $\\nabla \\times \\mathbf{A}$ as whole values or vectors.\n(X) $\\nabla f$ = Multiplication of the del operator and scalar function\n(O) $\\nabla f$ = A vector function that has as its components the derivatives of the given scalar function in three spatial coordinates, and has information about in which direction and how much $f$ increases.\nOr\nFor the vector function $\\mathbf{A} = (A_{x}, A_{y}, A_{z})$, $$ \\frac{ d A_{x} }{ d x }+\\frac{ d A_{y} }{ d y }+\\frac{ dA_{z} }{ d z } $$ Mathematical expressions of such form frequently appear in physics, so instead of always writing them out in full, it\u0026rsquo;s agreed to simply express them as $$ \\nabla \\cdot \\mathbf{A} $$ Conveniently defined as $\\nabla = (\\frac{ \\partial }{ \\partial x }, \\frac{ \\partial }{ \\partial y }, \\frac{ \\partial }{ \\partial z })$ because it\u0026rsquo;s intuitive and fits perfectly.\nis the correct understanding.\nSince the inner product of two vectors is commutable, if one thinks of $\\nabla$ as a vector, one may think of $\\nabla\\cdot \\mathbf{A}$ and $\\mathbf{A}\\cdot \\nabla$ as the same. The two formulas are entirely different. Since $\\nabla$ pertains to differentiation, the order is very important.\nUnderstanding that the results of $x\\left(\\dfrac{df}{dx}\\right)$ and $\\dfrac{d(xf)}{dx}$ are not the same should make it easier. Therefore, $\\mathbf{A}\\cdot \\nabla$ should not be understood as the inner product of two vectors but as a symbol created for easy expression because $A_{x}\\frac{ \\partial }{ \\partial x }+A_{y}\\frac{ \\partial }{ \\partial y }+A_{z}\\frac{ \\partial }{ \\partial z }$ is too long. Another example is\n$$ \\nabla \\times (\\mathbf{A} \\times \\mathbf{B}) = (\\mathbf{B} \\cdot \\nabla)\\mathbf{A} - (\\mathbf{A} \\cdot \\nabla)\\mathbf{B} + \\mathbf{A} (\\nabla \\cdot \\mathbf{B}) - \\mathbf{B} (\\nabla \\cdot \\mathbf{A}) $$\nwhich may lead one to mistakenly think that\n$$ \\nabla \\times (\\nabla \\times \\mathbf{A})=(\\mathbf{A} \\cdot \\nabla)\\nabla - (\\nabla \\cdot \\nabla)\\mathbf{A} + \\nabla (\\nabla \\cdot \\mathbf{A}) - \\mathbf{A} (\\nabla \\cdot \\nabla) $$\nis valid when in reality\n$$ \\nabla \\times (\\nabla \\times \\mathbf{A})=\\nabla(\\nabla \\cdot \\mathbf{A})-\\nabla ^{2} \\mathbf{A} $$\nis the correct formula. This example follows a similar context to the fact that the results of $\\dfrac{d}{dx} (fg)=\\dfrac{df}{dx}g+f\\dfrac{dg}{dx}$ and $\\dfrac{d}{dx} \\left( \\dfrac{df}{dx} \\right) =\\dfrac{d^2 f}{dx^2}$ are entirely different.\nSee Also Del Operator $\\nabla$ Gradient $\\nabla f$ Divergence $\\nabla \\cdot \\mathbf{F}$ Curl $\\nabla \\times \\mathbf{F}$ Laplacian $\\nabla^{2} f$ ","id":1575,"permalink":"https://freshrimpsushi.github.io/en/posts/1575/","tags":null,"title":"PhysicsÏóêÏÑúÏùò Del Ïó∞ÏÇ∞Ïûê"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":"Definition For two operators $A, B$, $AB - BA$ is defined as the commutator of $A, B$ as follows.\n$$ [A,B]=AB-BA $$\nExplanation When first encountering the definition of a commutator, one might wonder why it is not $AB - BA = 0$. However, since operators can be represented as matrices, and the multiplication of two matrices does not obey the commutative law, different results can appear depending on the order of multiplication.\nTo study quantum mechanics, a generalization of vectors, matrices, and inner products is necessary. Operators, being vectors (matrices), can thus be represented as matrices. Two operators whose commutator is $0$ are said to commute. The reason for using commutators is to make calculations faster. For instance, let $p$ be the momentum operator and $x$ be position. Given the following equation for a wave function $\\psi$:\n$$ p x \\psi - xp\\psi = [p, x]\\psi $$\nIf the value of $[p,x]$ is unknown, one has to solve it as shown on the left side. That is, apply $x$ to $\\psi$ and then apply $p$ to it (first term), and subtract the result of applying $p$ to $\\psi$ and then $x$ to it (second term), which makes the calculation lengthy. However, knowing the value of $[p,x]$ simplifies the cumbersome calculation process as shown on the right side. The commutator of these two is $[p,x]=-i\\hbar$, so one can immediately know the answer is $-i\\hbar \\psi$.\nAnti-commutator Meanwhile, the anti-commutator is defined as follows.\n$$ \\left\\{A,B\\right\\}=AB+BA $$\n","id":1574,"permalink":"https://freshrimpsushi.github.io/en/posts/1574/","tags":null,"title":"In Quantum Mechanics, What is a Commutator?"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition 1 Let there be a given graph $G$.\nA finite sequence of edges is called a walk and is denoted as follows: $$ v_{0} v_{1} , v_{1} v_{2} , \\cdots , v_{m-1} v_{m} \\\\ v_{0} \\rightarrow v_{1} \\rightarrow v_{2} \\rightarrow \\cdots \\rightarrow v_{m-1} \\rightarrow v_{m} $$ Here, $v_{0}$ is called the initial vertex, $v_{m}$ is called the final vertex, and $m$ is called the length. If all edges in a walk are different, it is called a trail. If all vertices in a walk are different, it is called a path. If the initial and final vertices of a walk are the same, it is called closed. A closed path is called a cycle. These concepts can be similarly defined for directed graphs as well, and can also be defined for infinite graphs as follows:\nLet $G$ be an infinite graph. In the definitions below, walks can be replaced with trails, paths, cycles. 6. A (finite) walk is exactly the same as a walk in a conventional graph. 7. A one-way infinite walk is defined as follows: $$ v_{0} \\to v_{1} \\to v_{2} \\to \\cdots $$ 8. A two-way infinite walk is defined as follows: $$ \\cdots \\to v_{-2} \\to v_{-1} \\to v_{0} \\to v_{1} \\to v_{2} \\to \\cdots $$\nExplanation In the definition of a path, the initial and final vertices are exceptions. In other words, if $v_{0} = v_{m}$, it can be a path, hence a \u0026lsquo;closed path\u0026rsquo; can exist. Meanwhile, in the definitions of a path and a trail, if all vertices are different, then all edges must also be different, so a path is also a trail.\nA cycle is, simply put, a \u0026rsquo;loop shape\u0026rsquo; found in a graph, and it\u0026rsquo;s a concept widely used throughout graph theory. For example, the following figure shows that there are a total of three cycles in the graph:\nFurthermore, the following theorem is known about cycles.\nTheorem If every vertex of a finite graph $G$ has a degree of $2$ or more, then $G$ contains a cycle.\nProof Since $G$ would obviously contain a cycle if it has loops or multiple edges, we assume that $G$ is a simple graph.\nFix a random vertex $v_{0} \\in V(G)$ and consider the following path: $$ v_{0} \\to v_{1} \\to v_{2} \\to \\cdots $$ As the degree of every vertex is $2$ or more, according to the assumption, it\u0026rsquo;s guaranteed that we can continue to select any vertex adjacent to the previous vertex $v_{i}$, excluding $v_{i-1}$. However, since $G$ is a finite graph, we will inevitably select a vertex $v_{k}$ that is already part of the path. Thus, the path $v_{k} \\to \\cdots \\to v_{k}$, whose initial and final vertices are $v_{k}$, is confirmed to exist as a cycle in $G$.\n‚ñ†\nWilson. (1970). Introduction to Graph Theory: p27.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1528,"permalink":"https://freshrimpsushi.github.io/en/posts/1528/","tags":null,"title":"Walks, Trails, Paths, and Cycles in Graph Theory"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 For $\\alpha \\in \\mathbb{C}$, the following $\\sigma_{\\alpha} : \\mathbb{N} \\to \\mathbb{C}$ is defined as a divisor function. $$ \\sigma_{\\alpha} (n) := \\sum_{d \\mid n} d^{\\alpha} $$\nBasic Properties [1] Multiplicativity: For all $m, n \\in \\mathbb{N}$ that satisfy $\\gcd (m,n) = 1$, $\\sigma_{\\alpha} (mn) = \\sigma_{\\alpha} (m) \\sigma_{\\alpha} (n)$ [2]: For a prime $p$ and natural number $a$, $$ \\sigma_{\\alpha} \\left( p^{a} \\right) = \\begin{cases} a +1 \u0026amp; , \\alpha = 0 \\\\ {{ p^{\\alpha (a+1)} - 1 } \\over { p^{\\alpha} - 1 }} \u0026amp;,\\alpha \\ne 0 \\end{cases} $$ Explanation Especially\nIf $\\alpha = 0$, it can also be represented by the function $d := \\sigma_{0}$ that indicates the number of divisors. If $\\alpha = 1$, it becomes the sigma function of elementary number theory $\\sigma := \\sigma_{1}$. Proof [1] Dirichlet product and multiplicative property: If $f$ and $g$ are multiplicative functions, then $f \\ast\\ g$ is also a multiplicative function.\nLet\u0026rsquo;s define the unit function $u$ and the power function $N^{\\alpha}$ as follows. $$ u(n) := 1 \\\\ N^{\\alpha} (n) := n^{\\alpha} $$ Since $u$ and $N^{\\alpha}$ are multiplicative functions, their convolution $$ \\left( N^{\\alpha} \\ast\\ u \\right)(n) = \\sum_{d \\mid n} N^{\\alpha} (d) u \\left( {{ d } \\over { n }} \\right) = \\sum_{d \\mid n} d^{\\alpha} = \\sigma_{\\alpha} (n) $$ must also be a multiplicative function.\n‚ñ†\n[2] Since the divisors of $p^{a}$ are $1 , p , \\cdots ,p^{a}$, $$ \\sigma_{\\alpha} ( n) = 1 + p^{\\alpha} + \\cdots + p^{a\\alpha} $$ if $\\alpha = 0$, $$ \\sigma_{\\alpha} ( n) = \\underbrace{1 + 1 + \\cdots + 1}_{a+1} = a + 1 $$ if $\\alpha \\ne 0$, according to the geometric series formula, $$ \\sigma_{\\alpha} ( n) = {{ p^{\\alpha (a+1)} - 1 } \\over { p^{\\alpha} - 1 }} $$\n‚ñ†\nApostol. (1976). Introduction to Analytic Number Theory: p38.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1527,"permalink":"https://freshrimpsushi.github.io/en/posts/1527/","tags":null,"title":"Divisor Function in Analytic Number Theory"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Theorem $$ \\Gamma \\left( { r \\over 2 } , 2 \\right) \\iff \\chi ^2 (r) $$\nDescription The gamma distribution and the chi-square distribution have the following properties.\nProof Strategy: It is shown that the moment-generating functions of the two distributions can be represented in the same form.\nThe moment-generating function of the chi-square distribution $\\chi ^2 (r)$ is $\\displaystyle m_{1}(t) = (1- 2t)^{- {r \\over 2} }$, and the moment-generating function of the gamma distribution $\\Gamma (k, \\theta)$ is $m_{2}(t) = (1-\\theta t)^{-k}$. By substituting $\\displaystyle k = {r \\over 2}$ and $\\theta = 2$ into the moment-generating function of the gamma distribution, we get $$ m_{2}(t) = (1-\\theta t)^{-k} = (1- 2t)^{- {r \\over 2} } =m_{1}(t) $$\n‚ñ†\n","id":135,"permalink":"https://freshrimpsushi.github.io/en/posts/135/","tags":null,"title":"The Relationship Between the Gamma Distribution and the Chi-Squared Distribution"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition 1 A graph is called a Regular Graph if all vertices have the same degree. Specifically, if all vertices have a degree of $r$, it is called a $r$-Regular Graph. In other words, a graph $G$ that satisfies the following is referred to as a $r$-Regular Graph. $$ \\deg (v) = r \\qquad , \\forall v \\in V(G) $$ A $2$-Regular connected graph is called a Cycle. Examples Regular Graphs Petersen Graph Platonic Graphs: These are graphs representing Platonic solids. Like the Petersen graph, they are $3$-Regular Graphs, and only the following five exist.\nComplete Graphs: When the number of vertices in a graph is $n$, the $(n-1)$-Regular Graph becomes a Complete Graph. Cycles Cycles represent the simplest form of graphs and receive a lot of interest in pure graph theory. Of course, it\u0026rsquo;s not exactly about cycle graphs themselves, but about parts within a graph that form a cycle shape. [ NOTE: A graph with just one edge removed from a cycle is also called a Path. ] You can understand why a $2$-Regular is called a cycle just by looking at the shape of a cycle.\nThe following example explains why a cycle needs to be connected to truly be a cycle. The next graph, consisting of two components, is indeed $2$-Regular, but since it can be represented as a union of two cycles, it is inappropriate to call it a true cycle. Of course, each of $A$ and $B$ is a cycle.\nWilson. (1970). Introduction to Graph Theory: p17.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1522,"permalink":"https://freshrimpsushi.github.io/en/posts/1522/","tags":null,"title":"Regular Graph"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Theorem $$ \\Gamma \\left(1, { 1 \\over \\lambda } \\right) \\iff \\text{exp} (\\lambda) $$\nDescription If we think about the intuitive definition of the exponential distribution, it\u0026rsquo;s about the interest in the amount of time it takes for a certain event to occur. If we were to relate this to a discrete probability distribution, the geometric distribution would correspond to this.\nIn this sense, the generalization of the geometric distribution in terms of the \u0026rsquo;number of occurrences\u0026rsquo; is the negative binomial distribution. From this perspective, the generalization of the exponential distribution could be considered the gamma distribution. Here, the \u0026rsquo;number of occurrences\u0026rsquo; corresponds from $\\displaystyle \\Gamma \\left( k, { 1 \\over \\lambda } \\right)$ to $k$ in the gamma distribution, but since the parameter $k$ of the gamma distribution does not necessarily have to be an integer, it is problematic to consider them completely equivalent.\nIn the gamma distribution, note that $\\displaystyle { 1 \\over \\lambda }$ is taken instead of $\\lambda$, which is the parameter of the exponential distribution. Don\u0026rsquo;t think too hard about it; just knowing this much should be sufficient.\nProof Strategy: We show that the moment generating functions of the two distributions can be expressed in the same form.\nThe moment generating function of the exponential distribution $\\text{exp} (\\lambda)$ is $\\displaystyle m_{1}(t) := (1- {t \\over \\lambda})^{-1}$, and the moment generating function of the gamma distribution $\\Gamma (k, \\theta)$ is $\\displaystyle m_{2}(t) := (1-\\theta t)^{-k}$. When we substitute $ k = 1$ and $\\displaystyle \\theta = { 1 \\over \\lambda }$ into the moment generating function of the gamma distribution, $$ m_{2}(t) = (1 - \\theta t)^{-k} = (1- {t \\over \\lambda})^{-1} =m_{1}(t) $$\n‚ñ†\n","id":133,"permalink":"https://freshrimpsushi.github.io/en/posts/133/","tags":null,"title":"Relationship between Gamma Distribution and Exponential Distribution"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 For $\\forall n \\in \\mathbb{N}$, if an arithmetic function $f$ that is not $f(n) = 0$ satisfies the following, it is called a multiplicative function. $$ f(mn) = f(m) f(n) \\qquad,\\gcd(m,n)=1 $$ If a multiplicative function satisfies the following condition, it is called a completely multiplicative function. $$ f(mn) = f(m) f(n) \\qquad,m,n \\in \\mathbb{N} $$ Basic Properties [1]: If $f$ is multiplicative, then $f(1) = 1$. [2]: That $f$ is a multiplicative function is equivalent to for all primes $p_{1} , \\cdots , p_{r}$ and all $a_{1} , \\cdots, a_{r} \\in \\mathbb{N}$, $f \\left( p_{1}^{a_{1}} \\cdots p_{r}^{a_{r}} \\right) = f \\left( p_{1}^{a_{1}} \\right) \\cdots f \\left( p_{r}^{a_{r}} \\right)$. [3]: If $f$ is multiplicative, for primes $p$ that satisfy $p \\mid n$, $$ \\sum_{d \\mid n} \\mu (d) f(d) = \\prod_{p \\mid n} \\left( 1 - f(p) \\right) $$ [4]: If $f$ is multiplicative, then $f$ being a completely multiplicative function is equivalent to for all primes $p$ and all $a \\in \\mathbb{N}$, $f \\left( p^{a} \\right) = \\left[ f(p) \\right]^{a}$. [5]: If $f$ is multiplicative, then $f$ being a completely multiplicative function is equivalent to the inverse of $f$ with respect to Dirichlet convolution $f^{-1}$ being represented as follows. $$ f^{-1} (n) = \\mu (n) f (n) $$ [6]: If $f$ is completely multiplicative, then $F(n) := \\sum_{d \\mid n} f(d)$ is multiplicative. $\\mu$ is the M√∂bius function. Description Naturally, being completely multiplicative implies being multiplicative.\nAn arithmetic function being multiplicative is akin to the \u0026lsquo;independent\u0026rsquo; condition spoken of across mathematics. Since function values can be thought of in smaller fragments, it naturally harbors rich mathematical properties.\nTheorem [1] is derived very simply but implies $f(1) \\ne 0$, which becomes a critical condition for the set of multiplicative functions to form a group.\nProof [1] Since $f(1) = f( 1 \\cdot 1) = f(1) f(1)$, $f(1) = 1$ must hold.\n‚ñ†\n[2] $(\\Rightarrow)$\nSince $f$ is multiplicative and always $\\gcd \\left( p^{a} , q^{b} \\right) = 1$ for different primes $p \\ne q$, $$ \\begin{align*} f \\left( p_{1}^{a_{1}} \\cdots p_{r}^{a_{r}} \\right) =\u0026amp; f \\left( p_{1}^{a_{1}} \\right) f \\left( p_{2}^{a_{2}} \\cdots p_{r}^{a_{r}} \\right) \\\\ =\u0026amp; f \\left( p_{1}^{a_{1}} \\right) f \\left( p_{2}^{a_{2}} \\right) f \\left( p_{3}^{a_{3}} \\cdots p_{r}^{a_{r}} \\right) \\\\ =\u0026amp; f \\left( p_{1}^{a_{1}} \\right) \\cdots f \\left( p_{r}^{a_{r}} \\right) \\end{align*} $$\n$(\\Leftarrow)$\nIf we set $m = p_{1}^{a_{1}} \\cdots p_{r}^{a_{r}}$, $n = q_{1}^{b_{1}} \\cdots q_{s}^{b_{s}}$, and $\\gcd(m,n) =1$, then $$ \\begin{align*} f(mn) =\u0026amp; f \\left( p_{1}^{a_{1}} \\cdots p_{r}^{a_{r}} q_{1}^{b_{1}} \\cdots q_{s}^{b_{s}} \\right) \\\\ =\u0026amp; f \\left( p_{1}^{a_{1}} \\right) \\cdots f \\left( p_{r}^{a_{r}} \\right) f \\left( q_{1}^{b_{1}} \\right) \\cdots f \\left( q_{s}^{b_{s}} \\right) \\\\ =\u0026amp; f \\left( p_{1}^{a_{1}} \\cdots p_{r}^{a_{r}} \\right) f \\left( q_{1}^{b_{1}} \\cdots q_{s}^{b_{s}} \\right) \\\\ =\u0026amp; f(m)f(n) \\end{align*} $$\n‚ñ†\n[3] Strategy: The properties of the M√∂bius function must be used.\nDefinition of the M√∂bius function: Given a prime $p_{1} , \\cdots , p_{k}$, let a natural number $n$ be represented as $n = p_{1}^{a_{1}} \\cdots p_{k}^{a_{k}}$. The arithmetic function $\\mu$ defined as follows is called the M√∂bius function. $$ \\mu (n) := \\begin{cases} 1 \u0026amp;, n=1 \\\\ (-1)^{k} \u0026amp;, a_{1} = \\cdots = a_{k} = 1 \\\\ 0 \u0026amp; , \\text{otherwise} \\end{cases} $$ Multiplicativity: For all $m, n \\in \\mathbb{N}$ that satisfy $\\gcd (m,n) = 1$, $\\mu (mn) = \\mu (m) \\mu (n)$\n$$ g(n) := \\sum_{d \\mid n} \\mu (d) f(d) $$ And let\u0026rsquo;s say $m$ satisfies $g(m,n) = 1$. Then, for $d = ab$ that satisfies $a \\mid m$ and $b \\mid n$, $\\gcd(a,b) = 1$ also holds, so we can consider sigma separately. Also, since $\\mu$ is multiplicative and $f$ is multiplicative by the premise, $$ \\begin{align*} g(mn) =\u0026amp; \\sum_{ab \\mid mn} \\mu (ab) f(ab) \\\\ =\u0026amp; \\sum_{a \\mid m \\\\ b \\mid n} \\mu (ab) f(ab) \\\\ =\u0026amp; \\sum_{a \\mid m \\\\ b \\mid n} \\mu (a) \\mu (b) f(a) f(b) \\\\ =\u0026amp; \\sum_{a \\mid m} \\mu (a) f(a) \\sum_{b \\mid n} \\mu (b) f(b) \\\\ =\u0026amp; g(m)g(n) \\end{align*} $$\nTherefore, $g$ is also multiplicative. Then, according to Theorem [2], $g \\left( p_{1}^{a_{1}} \\cdots p_{r}^{a_{r}} \\right) = g \\left( p_{1}^{a_{1}} \\right) \\cdots g \\left( p_{r}^{a_{r}} \\right)$, so we only need to calculate $g \\left( p^{a} \\right)$ for a fixed prime $p$. According to Theorem [1], $f(1)=1$ and $\\mu (1) = 1$, and for higher orders $k \\ge 2$, all $\\mu (p^{k}) = 0$, $$ \\begin{align*} g \\left( p^{a} \\right) =\u0026amp; \\sum_{d \\mid p^{a}} \\mu (d) f(d) \\\\ =\u0026amp; \\mu (1) f(1) + \\mu (p) f(p) \\\\ =\u0026amp; 1 \\cdot 1 - 1 \\cdot f(p) \\\\ =\u0026amp; 1 - f(p) \\end{align*} $$ Summarizing for natural numbers $n = p_{1}^{a_{1}} \\cdots p_{r}^{a_{r}}$ results in $$ g(n) = \\prod_{p \\mid n} g \\left( p^{a} \\right) = \\prod_{p \\mid n} \\left( 1 - f(p) \\right) $$\n‚ñ†\n[4] $(\\Rightarrow)$\nSince $f$ is completely multiplicative, $$ f \\left( p^{a} \\right) = f(p) \\left( p^{a-1} \\right) = \\left[ f(p) \\right]^{2} \\left( p^{a-2} \\right) = \\cdots = \\left[ f \\left( p \\right) \\right]^{a} $$\n$(\\Leftarrow)$\nLet\u0026rsquo;s consider that for a prime $p_{1} , \\cdots , p_{s}$, an integer $a_{1} , \\cdots, a_{s} , b_{1} , \\cdots , b_{s} \\in \\mathbb{N}_{0}$, and a natural number $c_{1}, \\cdots , c_{t} \\in \\mathbb{N}$, any $m$ and $n$ are represented as follows. $$ m = p_{1}^{a_{1}} \\cdots p_{t}^{a_{t}} \\\\ n = p_{1}^{b_{1}} \\cdots p_{t}^{b_{t}} \\\\ mn = p_{1}^{c_{1}} \\cdots p_{t}^{c_{t}} $$ If $m$ and $n$ do not have prime $p_{i}$ as a divisor, then $a_{i} = 0$ and $b_{i} = 0$, respectively. Since $f$ is multiplicative, $$ \\begin{align*} f(mn) =\u0026amp; f \\left( p_{1}^{c_{1}} \\cdots p_{t}^{c_{t}} \\right) \\\\ =\u0026amp; f \\left( p_{1}^{c_{1}}) \\cdots f( p_{t}^{c_{t}} \\right) \\\\ =\u0026amp; \\left[ f ( p_{1}) \\right]^{c_{1}} \\cdots \\left[ f ( p_{t}) \\right]^{c_{t}} \\\\ =\u0026amp; \\left[ f ( p_{1}) \\right]^{a_{1}} \\left[ f ( p_{1}) \\right]^{b_{1}} \\cdots \\left[ f ( p_{t}) \\right]^{a_{t}} \\left[ f ( p_{t}) \\right]^{b_{t}} \\\\ =\u0026amp; \\left[ f ( p_{1}) \\right]^{a_{1}} \\cdots \\left[ f ( p_{t}) \\right]^{a_{t}} \\left[ f ( p_{1}) \\right]^{b_{1}} \\cdots \\left[ f ( p_{t}) \\right]^{b_{t}} \\\\ =\u0026amp; \\left[ f ( p_{1}^{a_{1}}) \\right] \\cdots \\left[ f ( p_{t}^{a_{t}}) \\right] \\left[ f ( p_{1}^{b_{1}}) \\right] \\cdots \\left[ f ( p_{t}^{b_{t}}) \\right] \\\\ =\u0026amp; f \\left( p_{1}^{a_{1}} \\cdots p_{t}^{a_{t}} \\right) f \\left( p_{1}^{b_{1}} \\cdots p_{t}^{b_{t}} \\right) \\\\ =\u0026amp; f(m)f(n) \\end{align*} $$\n‚ñ†\n[5] $(\\Rightarrow)$\nLet\u0026rsquo;s say $g(n) := \\mu (n) f(n)$.\nSince $f$ is completely multiplicative and $\\displaystyle \\sum_{d \\mid n } \\mu (d) = I(n)$, $$ \\begin{align*} (gf)(n) =\u0026amp; \\sum_{d \\mid n} \\mu (d) f (d) f \\left( {{ n } \\over { d }} \\right) \\\\ =\u0026amp; f(n) \\sum_{d \\mid n} \\mu (d) \\\\ =\u0026amp; f(n) I(n) \\end{align} $$ In Theorem [1], since $f(1) = 1$ and the identity function $I$ is $I(n) = 0$ in $n \u0026gt; 1$, $f(n) I(n) = I(n)$. Summarizing, $(g \\ast\\ f) (n) = I (n)$, so $g = f^{-1}$.\n$(\\Leftarrow)$\nFor any prime $p$ and natural number $a \\in \\mathbb{N}$, let\u0026rsquo;s set $n = p^{a}$.\nIf $f^{-1} (n) := \\mu (n) f (n)$ then $$ \\begin{align*} \\sum_{d \\mid n} \\mu (d) f (d) f \\left( {{ n } \\over { d }} \\right) =\u0026amp; \\sum_{d \\mid n} f^{-1} (d) f \\left( {{ n } \\over { d }} \\right) \\\\ =\u0026amp; (f^{-1} \\ast\\ f ) (n) \\\\ =\u0026amp; I(n) \\\\ =\u0026amp; 0 \\end{align*} $$\nDefinition of the M√∂bius function: Given a prime $p_{1} , \\cdots , p_{k}$, let a natural number $n$ be represented as $n = p_{1}^{a_{1}} \\cdots p_{k}^{a_{k}}$. The arithmetic function $\\mu$ defined as follows is called the M√∂bius function. $$ \\mu (n) := \\begin{cases} 1 \u0026amp;, n=1 \\\\ (-1)^{k} \u0026amp;, a_{1} = \\cdots = a_{k} = 1 \\\\ 0 \u0026amp; , \\text{otherwise} \\end{cases} $$\nAccording to the definition of the M√∂bius function, if $k \\ge 2$ then $\\mu (p^{k} ) = 0$, $$ \\mu (1) f(1) f \\left( p^{a} \\right) + \\mu (p) f(p) f \\left( p^{a-1} \\right) + 0 + \\cdots + 0 = 0 $$ Since the premise is that $f$ is a multiplicative function, according to Theorem [1], $f(1) = 1$. Meanwhile, the M√∂bius function is $\\mu (1) = 1$ and $\\mu (p) = -1$, therefore, $$ 1 \\cdot 1 \\cdot f \\left( p^{a} \\right) + (-1) \\cdot f(p) f \\left( p^{a-1} \\right) = 0 $$ Summarizing, $$ f \\left( p^{a} \\right) = f(p) f \\left( p^{a-1} \\right) $$ When recursively resolved, $f \\left( p^{a} \\right) = f(p)^{a}$, therefore, by Theorem [4], $f$ is completely multiplicative.\n‚ñ†\n[6] If we assume $\\gcd (m,n) = 1$, we can distinguish the divisors of $m$ from those of $n$. For convenience, let\u0026rsquo;s say $a_{1} , \\cdots, a_{M}$ are the divisors of $m$, and $b_{1} , \\cdots , b_{N}$ are the divisors of $n$. $$ \\begin{align*} F(mn) =\u0026amp; \\sum_{d \\mid mn} f(d) \\\\ =\u0026amp; f(1) + f(a_{1}) + \\cdots + f (a_{M}) + f(b_{1}) + \\cdots + f(b_{N}) \\\\ \u0026amp; + f(a_{1}b_{N}) + \\cdots + f(a_{M} b_{1}) + \\cdots + f(a_{1} a_{2} b_{N}) + \\cdots + f(mn) \\\\ =\u0026amp; \\sum_{a \\mid m} f(a) \\sum_{b \\mid n} f(b) \\\\ =\u0026amp; F(m) F(n) \\end{align*} $$\n‚ñ†\nApostol. (1976). Introduction to Analytic Number Theory: p33.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1521,"permalink":"https://freshrimpsushi.github.io/en/posts/1521/","tags":null,"title":"Arithmetic Functions' Multiplicative Properties"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition 1 Given a simple graph $G$.\nIf $E(G) = \\emptyset$, then $G$ is called a null graph. If $E \\left( \\overline{G} \\right) = \\emptyset$, then $G$ is called a complete graph. Description A null graph is literally an empty graph. The reason why we use the term Null instead of Empty is that even if $G \\ne \\emptyset$, it has no meaning as a graph. For example, if there are only vertices like the following picture, there is hardly a reason to call it a graph. However, similar to how the number $0$ is incredibly important in mathematics, null graphs are very frequently mentioned throughout graph theory.\nA complete graph is originally defined as the complement $\\overline{G} $ of the original graph $G$. That $\\overline{G}$ is a null graph means all vertices of the original graph $G$ are connected without exception. For instance, the following is the complement of the graph above.\nSubsequent Definitions In particular, a complete graph with the number of vertices $n$ is denoted as $K_{n}$.\nIf a complete graph is a subgraph of some graph, it is called a clique. The largest $n$ of the clique $K_{n}$ in graph $G$ is called the clique number $\\omega (G)$ of $G$, and The clique number of the complement $\\overline{G}$ of $G$ is called the independence number $\\beta (G) := \\omega \\left( \\overline{G} \\right)$ of $G$. Meanwhile, a directed complete graph is called a tournament. Wilson. (1970). Introduction to Graph Theory: p17.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1520,"permalink":"https://freshrimpsushi.github.io/en/posts/1520/","tags":null,"title":"Null Graphs and Complete Graphs"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 For $k, \\theta \u0026gt; 0$, it is called the Gamma Distribution which has the following probability density function $\\Gamma ( k , \\theta )$. $$ f(x) = {{ 1 } \\over { \\Gamma ( k ) \\theta^{k} }} x^{k - 1} e^{ - x / \\theta} \\qquad , x \u0026gt; 0 $$\n$\\Gamma$ represents the Gamma function. The probability density function of the Gamma distribution can also be defined as follows for $\\alpha , \\beta \u0026gt; 0$. Essentially, it\u0026rsquo;s just a matter of whether it\u0026rsquo;s $\\theta = {{ 1 } \\over { \\beta }}$. $$ f(x) = {{ \\beta^{\\alpha } } \\over { \\Gamma ( \\alpha ) }} x^{\\alpha - 1} e^{ - \\beta x} \\qquad , x \u0026gt; 0 $$ Fundamental Properties Moment Generating Function [1]: $$m(t) = \\left( 1 - \\theta t\\right)^{-k} \\qquad , t \u0026lt; {{ 1 } \\over { \\theta }}$$ Mean and Variance [2]: If $X \\sim \\Gamma ( \\alpha , \\beta )$, then $$ \\begin{align*} E(X) =\u0026amp; k \\theta \\\\ \\text{Var} (X) =\u0026amp; k \\theta^{2} \\end{align*} $$ Sufficient Statistic [3]: Let\u0026rsquo;s say we have a random sample $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{n} \\right) \\sim \\Gamma \\left( k, \\theta \\right)$ that follows a Gamma distribution. The sufficient statistic for $\\left( k, \\theta \\right)$ is as follows: $T$. $$ T = \\left( \\prod_{i} X_{i}, \\sum_{i} X_{i} \\right) $$\nTheorems Scaling [a]: If $X \\sim \\Gamma ( k , \\theta )$, then for scalar $c \u0026gt; 0$, $c X \\sim \\Gamma ( k , c \\theta )$ Relationship with Poisson Distribution [b]: For all natural numbers $k$, $$ \\int_{\\mu}^{\\infty} { { z^{k-1} e^{-z} } \\over { \\Gamma (k) } } dz = \\sum_{x=0}^{k-1} { { {\\mu}^{x} e^{-\\mu} } \\over {x!} } $$ Relationship with Exponential Distribution [c]: $$\\Gamma \\left(1, { 1 \\over \\lambda } \\right) \\iff \\text{exp} (\\lambda)$$ Relationship with Chi-squared Distribution [d]: $$\\Gamma \\left( { r \\over 2 } , 2 \\right) \\iff \\chi ^2 (r)$$ Derivation of Beta Distribution [e]: If two random variables $X_{1},X_{2}$ are independent and $X_{1} \\sim \\Gamma ( \\alpha_{1} , 1)$, $X_{2} \\sim \\Gamma ( \\alpha_{2} , 1)$, then $$ {{ X_{1} } \\over { X_{1} + X_{2} }} \\sim \\text{beta} \\left( \\alpha_{1} , \\alpha_{2} \\right) $$ Explanation The Gamma Distribution is a function named after the Gamma function, and the fact that the integral of its probability density function equates to $1$ originates from Euler integrals. Rather than having an intuitive meaning, it\u0026rsquo;s artificially derived due to its statistically useful properties. Such distributions are also referred to as Sampling Distributions, and the Gamma distribution, thanks to its unique shape, takes on various forms and provides many convenient properties.\nBayesian In Bayesian analysis, it is also used as the conjugate prior distribution for the Poisson distribution.\nProofs [1] When $\\displaystyle t \u0026lt; {{ 1 } \\over { \\theta }}$, let $\\displaystyle y := x {{ ( 1 - \\theta t ) } \\over { \\theta }}$ then $\\displaystyle dy = {{ ( 1 - \\theta t ) } \\over { \\theta }} dx$, $$ \\begin{align*} m(t) =\u0026amp; \\int_{0}^{\\infty} e^{tx} {{ 1 } \\over { \\Gamma ( k ) \\theta^{k} }} x^{k - 1} e^{ - x / \\theta} dx \\\\ =\u0026amp; \\int_{0}^{\\infty} {{ 1 } \\over { \\Gamma ( k ) \\theta^{k} }} x^{k - 1} e^{ x (t - 1 / \\theta) } dx \\\\ =\u0026amp; \\int_{0}^{\\infty} {{ 1 } \\over { \\Gamma ( k ) \\theta^{k} }} x^{k - 1} e^{ - x {{( 1 - \\theta t)} \\over {\\theta}} } dx \\\\ =\u0026amp; \\int_{0}^{\\infty} {{ 1 } \\over { \\Gamma ( k ) \\theta^{k} }} \\left( {{ y \\theta } \\over { 1 - \\theta t }} \\right)^{k - 1} e^{ - y } {{ \\theta } \\over { 1 - \\theta t }}dy \\\\ =\u0026amp; \\left( {{ 1 } \\over { 1 - \\theta t }} \\right)^{k } \\int_{0}^{\\infty} {{ \\theta^{k} } \\over { \\Gamma ( k ) \\theta^{k} }} y^{k-1} e^{ - y } dy \\end{align*} $$ According to Euler\u0026rsquo;s integration, $\\displaystyle \\int_{0}^{\\infty} {{ 1 } \\over { \\Gamma ( k ) }} y^{k-1} e^{ - y } dy = 1$. $$ m(t) = \\left( 1 - \\theta t\\right)^{-k} \\qquad , t \u0026lt; {{ 1 } \\over { \\theta }} $$\n‚ñ†\n[2] Direct deduction.\n‚ñ†\n[3] Direct deduction.\n[a] If we set $X \\sim \\Gamma ( k , \\theta )$ and $c \u0026gt;0$, then $Y = c X$, $$ \\begin{align*} m_{X}(t) =\u0026amp; \\int_{0}^{\\infty} e^{tx} {{ 1 } \\over { \\Gamma ( k ) \\theta^{k} }} x^{k - 1} e^{ - x / \\theta} dx \\\\ =\u0026amp; \\int_{0}^{\\infty} e^{tx} {{ c^{k} } \\over { \\Gamma ( k ) (c\\theta)^{k} }} x^{k - 1} e^{ - cx / c\\theta} dx \\\\ =\u0026amp; \\int_{0}^{\\infty} e^{{{ t } \\over { c }} cx} {{ 1 } \\over { \\Gamma ( k ) (c\\theta)^{k} }} (cx)^{k - 1} e^{ - cx / c\\theta} c dx \\\\ =\u0026amp; \\int_{0}^{\\infty} e^{{{ t } \\over { c }} y} {{ 1 } \\over { \\Gamma ( k ) (c\\theta)^{k} }} y^{k - 1} e^{ - y / c\\theta} dy \\end{align*} $$ According to [1] the moment generating function, $$ \\begin{align*} m_{Y}(t) =\u0026amp; E \\left( e^{tY} \\right) \\\\ =\u0026amp; E \\left( e^{tcX} \\right) \\\\ =\u0026amp; \\int_{0}^{\\infty} e^{{{ tc } \\over { c }} y} {{ 1 } \\over { \\Gamma ( k ) (c\\theta)^{k} }} y^{k - 1} e^{ - y / c\\theta} dy \\\\ =\u0026amp; \\int_{0}^{\\infty} e^{tz} {{ 1 } \\over { \\Gamma ( k ) (c\\theta)^{k} }} z^{k - 1} e^{ - z / c\\theta} dz \\\\ =\u0026amp; (1 - c \\theta)^{-k} \\end{align*} $$ Therefore, $Y \\sim \\Gamma ( k , c \\theta)$.\n‚ñ†\n[b] Shown by mathematical induction.\n‚ñ†\n[c] Shown by the moment generating function.\n‚ñ†\n[d] Shown by the moment generating function.\n‚ñ†\nCode Here is a Julia code that displays the probability density function of the gamma distribution as an animated gif.\n@time using LaTeXStrings\r@time using Distributions\r@time using Plots\rcd(@__DIR__)\rx = 0:0.1:20\rŒò = collect(0.1:0.1:10.0); append!(Œò, reverse(Œò))\ranimation = @animate for Œ∏ ‚àà Œò\rplot(x, pdf.(Gamma(1, Œ∏), x),\rcolor = :black,\rlabel = \u0026#34;r = 1, Œ∏ = $(rpad(Œ∏, 4, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300))\rxlims!(0,20); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,} \\Gamma (1, \\theta)\u0026#34;)\rend\rgif(animation, \u0026#34;pdf1.gif\u0026#34;)\ranimation = @animate for Œ∏ ‚àà Œò\rplot(x, pdf.(Gamma(2, Œ∏), x),\rcolor = :black,\rlabel = \u0026#34;r = 2, Œ∏ = $(rpad(Œ∏, 4, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300))\rxlims!(0,20); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,} \\Gamma (2, \\theta)\u0026#34;)\rend\rgif(animation, \u0026#34;pdf2.gif\u0026#34;)\ranimation = @animate for Œ∏ ‚àà Œò\rplot(x, pdf.(Gamma(4, Œ∏), x),\rcolor = :black,\rlabel = \u0026#34;r = 4, Œ∏ = $(rpad(Œ∏, 4, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300))\rxlims!(0,20); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,} \\Gamma (4, \\theta)\u0026#34;)\rend\rgif(animation, \u0026#34;pdf4.gif\u0026#34;) Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p158.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1517,"permalink":"https://freshrimpsushi.github.io/en/posts/1517/","tags":null,"title":"Gamma Distribution"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition 1 For a given graph $G$, graph $H$ is said to be a subgraph of $G$ if it satisfies $V(H) \\subset V(G)$ and $ E(H) \\subset E(G)$.\nExplanation It is important not to denote $H$ being a subgraph of $G$ as $H \\subset G$. The concept of a subgraph serves not so much as a focus of interest in graph theory itself but rather as a natural and common term.\nExamples By defining a subgraph, the following can be considered as examples:\nComponent The components of a disconnected graph $D$ are all subgraphs of $D$.\nGraph Subtraction Given graph $G$:\nFor edge: $e \\in E(G)$, $E(G) - e$ is defined as the graph with the edge $e$ of $G$ removed, and naturally, it becomes a subgraph of $G$. This operation of graph subtraction $-$ can also be extended to sets of edges. $E(G) - E$ is defined as the graph with the subset of edges $E$ of $G$ removed, and likewise, it becomes a subgraph of $G$. For vertex: $v \\in V(G)$, $E(G) - v$ is defined as the graph with the vertex $v$ of $G$ and all edges attached to $v$ removed. This can also be extended to sets of vertices. $E(G) - V$ is defined as the graph with the subset of vertices $V$ of $G$ and all their attached edges removed, and naturally, it becomes a subgraph of $G$. Graph contraction: Note the symbol $-$ in the two subtraction operations mentioned above. The set subtraction symbol $\\setminus$ is used to mean the contraction of an edge in a graph. Contracting an edge means removing the edge $e$ and treating the two endpoints $v$ and $w$ as the same. Such operations of graph subtraction are very convenient tools when discussing algorithms for constructing graphs, etc.\nSpanning If subgraph $H$ of $G$ satisfies $V\\left( H \\right) = V(G)$, $H$ is referred to as Spanning of $G$. Simply put, it\u0026rsquo;s a subgraph where vertices remain as is, but only edges might have been removed. It falls under the case of edge removal in graph subtraction.\nInduced Graph If subgraph $H$ of $G$ satisfies $$ E \\left( H \\right) = \\left\\{ uv \\in E(G) : u,v \\in V \\left( H \\right) \\right\\} $$, it is called an Induced Graph. An induced graph, unlike spanning which may have edges removed without a specific rule and thus only vertices preserved, ensures that if vertices are preserved, their connecting edges are preserved as well. Consequently, it can be inferred that the induced graph inherits some properties of the original graph $G$.\nWilson. (1970). Introduction to Graph Theory: p12.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1513,"permalink":"https://freshrimpsushi.github.io/en/posts/1513/","tags":null,"title":"Subgraph"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition 1 Let\u0026rsquo;s consider two graphs $G_{1}$ and $G_{2}$ and let $V(G_{1}) \\cap V(G_{2}) = \\emptyset$.\nThe union $G = G_{1} \\cup G_{2}$ of two graphs is a graph that has a vertex set $V(G_{1}) \\cup V(G_{2})$ and an edge set $E (G_{1}) \\cup E ( G_{2} )$. If graph $H$ cannot be represented as the union of other graphs, then $H$ is said to be connected; otherwise, it is disconnected. Each connected graph within a disconnected graph is called a component. Especially, if the graph becomes disconnected by the removal of edge $b \\in G$, then $b$ is called a bridge. Description These definitions are similar to the way connectivity is defined in topology.\nAlthough connectivity, as purely defined in graph theory, seems like an important topic, ironically, since disconnected components can be completely treated separately, it is enough to consider connected graphs only. It\u0026rsquo;s not that connectivity isn\u0026rsquo;t important, but usually, for research purposes, there\u0026rsquo;s no need to think about disconnected cases.\nConnectivity becomes an important issue when dealing with analysis reflecting real data or applied network theory involving random networks. Whether a random network is surely a connected graph or not is a significant issue in various simulations. Consider a case where the connectivity of the network is not guaranteed. Isolated nodes are mostly ineffective in most mathematical models, and even without isolated nodes, a disaster may occur where only a part of the network is considered while the rest is discarded.\nSummary 2 Let\u0026rsquo;s assume that a simple graph $G$ has $n$ vertices. If $G$ has $k$ components, then the number of edges $m$ of $G$ satisfies the following. $$ n-k \\le m \\le (n-k)(n-k+1)/2 $$\nProof Part 1. $n-k \\le m$\nWhen $G$ is a null graph, $n=k$ and thus $m=0$, so $ n-k = 0 \\le 0 = m$ holds.\nAssume that $n - k \\ge m$ holds when $G$ has $k$ components. Let\u0026rsquo;s define the minimum number of edges required for $G$ to have $k$ components as $m_{0}$. Removing one edge will result in $k+1$ components and $m_{0}-1$ edges. Therefore, $n - (k + 1) \\le m_{0} - 1$, and by organizing, we obtain $n - k \\le m_{0}$.\nFrom these two facts, it follows by mathematical induction that $n-k \\le m$ generally holds.\nPart 2. $m \\le (n-k)(n-k+1)/2$\nSuppose all components of $G$ are complete graphs. Then, there will be two complete graphs $K_{i}$, $K_{j}$ with $1 \\le j \\le i \\le n$. Changing these two graphs to $K_{i+1}$, and $K_{j-1}$ respectively, the total number of vertices remains unchanged, but the total number of edges changes as follows: $$ \\left[ (i+1)i - i(i-1) \\right]/2 - \\left[ j(j-1) - (j-1)(j-2) \\right]/2 = i - j + 1 $$ This is positive; hence, for $m$ to be maximized, $G$ must have one complete graph with $(n-k+1)$ vertices and $k-1$ isolated vertices. Therefore, the number of edges of $G$ will be $(n-k)(n-(k-1))/2$, and we obtain the desired result.\n‚ñ†\nWilson. (1970). Introduction to Graph Theory: p10.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWilson. (1970). Introduction to Graph Theory: p27.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1512,"permalink":"https://freshrimpsushi.github.io/en/posts/1512/","tags":null,"title":"Graphical Set Notation"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Summary When the time it takes for an event to occur is given by $X_{k}$, and if $X_{k} \\sim \\exp (\\lambda)$, then the number of occurrences of an event per unit time is given by $N$, and $\\displaystyle N \\sim \\text{Poi} (\\lambda)$\n","id":296,"permalink":"https://freshrimpsushi.github.io/en/posts/296/","tags":null,"title":"The Relationship between Exponential Distribution and Poisson Distribution"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 The continuous probability distribution $\\exp ( \\lambda)$ with the following probability density function, for $\\lambda \u0026gt; 0$, is called an Exponential Distribution. $$ f(x) = \\lambda e^{-\\lambda x} \\qquad , x \\ge 0 $$\nDepending on the book, the parameter might be its reciprocal, $\\displaystyle \\theta = {{ 1 } \\over { \\lambda }}$. Basic Properties Moment Generating Function [1]: $$m(t) = {{ \\lambda } \\over { \\lambda - t }} \\qquad , t \u0026lt; \\lambda$$ Mean and Variance [2]: If $X \\sim \\exp ( \\lambda)$, then $$ \\begin{align*} E(X) =\u0026amp; {{ 1 } \\over { \\lambda }} \\\\ \\text{Var} (X) =\u0026amp; {{ 1 } \\over { \\lambda^{2} }} \\end{align*} $$ Sufficient Statistic and Maximum Likelihood Estimator [3]: Let $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{n} \\right) \\sim \\exp \\left( \\lambda \\right)$ be a given random sample. The sufficient statistic $T$ and maximum likelihood estimator $\\hat{\\lambda}$ for $\\lambda$ are as follows. $$ \\begin{align*} T =\u0026amp; \\sum_{k=1}^{n} X_{k} \\\\ \\hat{\\lambda} =\u0026amp; {{ n } \\over { \\sum_{k=1}^{n} X_{k} }} \\end{align*} $$\nTheorems Memorylessness [a]: If $X \\sim \\exp ( \\lambda ) $, then $$ P ( X \\ge s + t \\mid X \\ge s ) = P (X \\ge t) $$ Relationship with Gamma Distribution [b]: $$\\Gamma \\left(1, { 1 \\over \\lambda } \\right) \\iff \\text{exp} (\\lambda)$$ Generalization to Weibull Distribution [c]: The exponential distribution is the distribution for $k=1$ in the Weibull distribution. $$ f(x) = {{ k } \\over { \\theta }} \\left( {{ x } \\over { \\theta }} \\right)^{k-1} e^{-(x/\\theta)^{k}} \\qquad , x \\ge 0 $$ Explanation Relationship with Geometric Distribution The exponential distribution is the distribution that follows the time until an event of interest occurs, and can also be seen as a continuous version of the geometric distribution. Thinking of the geometric distribution as a generalization for the number of occurrences, the generalization of the number of occurrences for the exponential distribution might be considered to be the gamma distribution.\nRelationship with Poisson Distribution On the other hand, while the Poisson distribution and the exponential distribution both focus on similar phenomena, they differ in that one is concerned with the number of events per unit time, and the other with the time until an event occurs. This relationship between the two distributions is why some books use the same Greek letter $\\lambda$ for both. Especially considering the mean of the Poisson distribution is $\\lambda$ and the mean of the exponential distribution is $\\displaystyle {{ 1 } \\over { \\lambda }}$, the relationship between the two distributions could be perceived as a kind of \u0026lsquo;inverse\u0026rsquo;.\nProof [1] Only when $t \u0026lt; \\lambda$ $$ \\begin{align*} m(t) =\u0026amp; \\int_{0}^{\\infty} e^{tx} f(x) dx \\\\ =\u0026amp; \\int_{0}^{\\infty} e^{tx} \\lambda e^{-\\lambda x} dx \\\\ =\u0026amp; \\lambda \\int_{0}^{\\infty} e^{(t - \\lambda ) x} dx \\\\ =\u0026amp; \\lambda {{ 1 } \\over { t - \\lambda }} [ 0 - 1 ] \\\\ =\u0026amp; {{ \\lambda } \\over { \\lambda - t }} \\end{align*} $$\n‚ñ†\n[2] By direct derivation.\n‚ñ†\n[3] By direct derivation.\n‚ñ†\n[a] Derived using conditional probability.\n‚ñ†\n[b] Shown by the moment generating function.\n‚ñ†\n[c] It\u0026rsquo;s self-evident from the probability density function.\n‚ñ†\nVisualization The following is Julia code showcasing the probability density function of the exponential distribution via an animated gif.\n@time using LaTeXStrings\r@time using Distributions\r@time using Plots\rcd(@__DIR__)\rx = 0:0.1:10\rŒõ = collect(0.1:0.1:5.0); append!(Œõ, reverse(Œõ))\ranimation = @animate for Œª ‚àà Œõ\rplot(x, pdf.(Exponential(Œª), x),\rcolor = :black,\rlabel = \u0026#34;Œª = $(round(Œª, digits = 2))\u0026#34;, size = (400,300))\rxlims!(0,10); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pdf\\,of\\,} \\exp(\\lambda)\u0026#34;)\rend\rgif(animation, \u0026#34;pdf.gif\u0026#34;) Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p159.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1510,"permalink":"https://freshrimpsushi.github.io/en/posts/1510/","tags":null,"title":"Exponential Distribution"},{"categories":"ÎèôÏó≠Ìïô","contents":"Definition 1 Flow Given a space $X$ and a function $f : X \\to X$, suppose we have the following vector field presented as a differential equation. $$ \\dot{x} = f(x) $$ For a time variable $t$ and an initial value $x_{0}$, the solution to the autonomous differential equation is called a flow, which is denoted as $F(t, x_{0})$. For a fixed unit time $t = T$, $F_{T}(x) := F(T,x)$ is called a time-$T$ map.\nTime Evolution Regarding the projection $P : X \\to \\mathbb{R}^{1}$ that typically retains only one coordinate, when $P \\left( F \\left( t, x_{0} \\right) \\right)$ is viewed as a function of time $t$, it is also called time evolution.\nDescription A flow is also referred to as a trajectory or a phase space. [ NOTE: This is a homonym with the phase space generally mentioned in mathematics, but conceptually, there is no major correlation. ]\nFrom its definition, it can be observed that the flow $F$ describes changes according to $t$ by fixing the initial value $x_{0}$. The time-$T$ map was introduced to handle continuous dynamical systems with maps, originally expressed through differential equations. This allows the discussion in multidimensional maps to be extended to differential equations.\nExample Let\u0026rsquo;s consider a simple autonomous system such as $\\dot{x} = x$: Since the solution to this system is simply $x = x_{0} e^{t}$, the flow of this system for an initial value $x_{0}$ would be $F(t,x_{0}) = x_{0} e^{t}$. Meanwhile, without fixing the initial value, a system that starts from $x$ is verified through the time-$T$ map when time $T$ has passed. The time-$T$ map maps $x$ to $x e^{T}$ after time $T$ has passed as follows: $$ F_{T} : x \\mapsto x e^{T} $$ Although it might not be a commonly used expression in dynamics, if one wishes to represent it like a general multidimensional map, the following equation could be formed: $$ F_{T+1} (x) = F_{1} \\left( F_{T}(x) \\right) $$\nYorke. (1996). CHAOS: An Introduction to Dynamical Systems: p277.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1507,"permalink":"https://freshrimpsushi.github.io/en/posts/1507/","tags":null,"title":"Autonomous Systems: Flow and Time-T Maps"},{"categories":"ÎèôÏó≠Ìïô","contents":"Definition 1 Given a space $V$ and function $f : V \\to V$, assume the following vector field is given as a differential equation: $$ \\dot{v} = f(v) $$\nIf variable $t$ is included in the differential equation and $t$ is not explicitly shown, it is referred to as an Autonomous Differential Equation. If a constant function $f_{0} (v)$ is a solution to the autonomous differential equation $\\dot{v} = f(v)$, then $f_{0}$ is called an Equilibrium Point. Description Autonomous Systems Dynamical systems expressed by autonomous differential equations are referred to as Autonomous Systems. Geometrically, since most are expressed as vector fields, they are simply called vector fields in the appropriate context. Usually, variable $t$ represents time, and the fact that the equation includes variable $t$ without explicitly showing it, for example, refers to an equation like the following: $$ \\dot{y} = y $$ A non-trivial solution to the above differential equation is $y = e^t$. The reason for the term autonomous becomes clear when considering non-autonomous differential equations, which are, as the name suggests, differential equations where variable $t$ is explicitly shown. An example would be as follows, with the addition of term $\\sin t$: $$ \\dot{y} = y + \\sin t $$ Systems represented by such differential equations can be seen as being influenced by some external interference over time $t$, rather than being $y$ itself. In this sense, calling equations that are not non-autonomous, autonomous differential equations seems appropriate.\nFixed Points Equilibrium Points have a physical sense to them, and in mathematics, the term Fixed Point is preferred. In a system, a fixed point, as the name suggests, does not move. A point not moving means that the derivative indicating the change of position is entirely $0$, and since it\u0026rsquo;s a fixed point, it\u0026rsquo;s a constant function. Strictly speaking, it\u0026rsquo;s an element of the function space $C^{1} (X)$ constituted by the solutions to the differential equation rather than the domain $X$ defined for the function, i.e., it\u0026rsquo;s a fixed point as a function. However, depending on the textbook, it may also be loosely referred to as an element of $X$ that is a fixed point.\nNotation in Differential Equations In differential geometry, the notation of differentiation with respect to $s$ and $t$: $$ {{ df } \\over { ds }} = f^{\\prime} \\quad \\text{and} \\quad {{ df } \\over { dt }} = \\dot{f} $$ Whether it\u0026rsquo;s dot $\\dot{}$ or prime $'$, differentiation is differentiation, but in the context of differential geometry, symbols can be differentiated as shown above. Usually, $s$ represents the parameter of a unit speed curve, and $t = t(s)$ represents the parameter of a curve reparametrized by the length of the curve.\nAlthough not strictly necessary, in dynamics, the notation using dot $\\dot{y}$ is often used in place of prime $y '$, as dynamics generally deals with vector fields in terms of changes over time $t$.\nExamples Consider the Lorenz attractor as an example: $$ \\begin{cases} \\dot{x} = - \\sigma x + \\sigma y \\\\ \\dot{y} = - xz + \\rho x - y \\\\ \\dot{z} = xy - \\beta z \\end{cases} $$ Fixed points can be obtained by substituting $0$ for all left sides, since they describe points that do not move on domain $\\mathbb{R}^3$. $$ \\begin{cases} \\displaystyle 0 = - \\sigma x + \\sigma y \\\\ \\displaystyle 0 = - xz + \\rho x - y \\\\ \\displaystyle 0 = xy - \\beta z \\end{cases} $$ Through simple calculations, the following three fixed points $F_{i}$ can be found: $$ F_{1} = F_{1}(t) = (0,0,0) \\\\ F_{2} = F_{2}(t) = \\left( \\sqrt{\\beta (\\rho - 1)},\\sqrt{\\beta (\\rho - 1)}, (\\rho-1) \\right) \\\\ F_{3} = F_{3}(t) = \\left( -\\sqrt{\\beta (\\rho - 1)},-\\sqrt{\\beta (\\rho - 1)}, (\\rho-1) \\right) $$ Note that it is expressed as a function like $F_{i} = F_{i} (t)$. At first glance, $F_{i}$ seems like a point in $\\mathbb{R}^{3}$, but according to its definition, it\u0026rsquo;s obtained as a constant function whose value does not change over time $t$ and as a solution to the Lorenz differential equation. Conceptually, there\u0026rsquo;s no difference from a point in three-dimensional space.\nSee Also Dynamical systems represented by maps Dynamical systems represented by differential equations Rigorous definition of dynamical systems Yorke. (1996). CHAOS: An Introduction to Dynamical Systems: p271~277.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1505,"permalink":"https://freshrimpsushi.github.io/en/posts/1505/","tags":null,"title":"Dynamical Systems Described by Differential Equations and Equilibrium Points"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definition 1 Let\u0026rsquo;s assume a directed graph $G$ is given.\nIf an edge $vw$ exists, we say that the edge leaves from $v$ and enters into $w$.\nThe number of edges entering vertex $v$ is called the Indegree and is denoted as $\\deg^{-} (v)$. The number of edges leaving vertex $v$ is called the Outdegree and is denoted as $\\deg^{+}(v)$. A vertex that is $\\deg^{-} (v) = 0$ is called a Source, and a vertex that is $\\deg^{+} (v) = 0$ is called a Sink. A point that is neither a Source nor a Sink is called Internal. If an edge $vw$ exists, we say that vertex $v,w$ is incident to edge $vw$.\nThe number of edges incident to vertex $v$ is called the Degree and is denoted as $\\deg (v)$. A vertex with a degree of $0$ is called an Isolated Vertex. A vertex with a degree of $1$ is called an End Vertex. The maximum degree of graph $G$ is denoted as $\\Delta (G)$, and the minimum degree is denoted as $\\delta (G)$.\nExplanation Incidentally, the term \u0026ldquo;being incident\u0026rdquo; is not exactly a good euphemism. When two vertices $v,w$ are connected by edge $e$, $v$ and $w$ are said to be Adjacent, and the term \u0026ldquo;being incident\u0026rdquo; is used to describe $v,w$ that is attached to edge $e$. Originally, the adjective Incident has meanings such as accompanying or following.\nThe concept of degree has attracted a lot of interest for a long time in graph theory because it\u0026rsquo;s an easily conceivable \u0026rsquo;number\u0026rsquo;, especially in pure mathematics where simple graphs are often handled, leading to extensive research on degrees.\nDirected Graph For example, in the following graph, red represents the indegree and blue represents the outdegree. Naturally, the sum of the indegree and outdegree is the same.\nHere, a vertex with an indegree of $0$ is called a source. The name source makes sense because it only leaves without entering, similar to sinks and sources in dynamical systems.\nDegree For example, in the next graph, one can calculate the degree of each vertex. Let\u0026rsquo;s verify that the degree is the sum of the indegree and outdegree when the directed graph is represented as just a simple graph. [ NOTE: A graph with the directions removed like this is called the Underlying Graph of the original directed graph. ]\nIn the following graph, vertices $C$ and $F$ are End Vertices, and $H$ is an Isolated Vertex.\nNote that in applied mathematics, if only $H$ is absent, that is, if the network is fully connected, such a node as $D$ is called a Hub. Hubs typically describe elements that have a significant impact on the entire network or can mediate all communications.\nRegular Graph Especially, a graph where every vertex has the same degree, denoted as $\\delta (G) = \\Delta (G)$, is called a Regular Graph.\nWilson. (1970). Introduction to Graph Theory: p12.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1496,"permalink":"https://freshrimpsushi.github.io/en/posts/1496/","tags":null,"title":"Graph Theory: Degree"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 An arithmetic function $f^{-1}$ is said to be the (Dirichlet) inverse of another arithmetic function $f$ if there exists a unique arithmetic function $f^{-1}$ satisfying the following equation $f$. $$ f \\ast\\ f^{-1} = f^{-1} \\ast\\ f = I $$\nHere, $I$ is the identity function with respect to convolution. Theorem [1]: If an arithmetic function $f$ is $f(1) \\ne 0$, then its inverse $f^{-1}$ uniquely exists and is represented by the following recursive function. $$ f^{-1}(n) = \\begin{cases} \\displaystyle {{1} \\over {f(1)}} \u0026amp;,n=1 \\\\ \\displaystyle {{-1} \\over {f(1)}} \\sum_{d \\mid n , d \u0026lt; n } f \\left( {{ n } \\over { d }} \\right) f^{-1}(d) \u0026amp;, n \u0026gt; 1\\end{cases} $$ [2]: If for two arithmetic functions $f$ and $g$, $f(1) \\ne 0$ and $g(1) \\ne 0$ are satisfied, then $$ (f \\ast\\ g)^{-1} = g^{-1} \\ast\\ f^{-1} = f^{-1} \\ast\\ g^{-1} $$ Explanation Unlike the inverse functions commonly dealt with in most mathematics, the Dirichlet inverse is not an inverse in the sense of mapping but in an algebraic sense. This naturally leads one to think of algebraic structures, and the existence and uniqueness of such an inverse become questions of interest. Fortunately, the existence of an inverse is guaranteed by satisfying a very simple condition.\nEspecially for multiplicative arithmetic functions, the existence of an inverse is assured for the following reasons: $$ f(1) = f(1 \\cdot 1 ) = f(1) f(1) = 1 \\ne 0 $$ From these facts, the condition for the set of arithmetic functions to form an Abelian group becomes $f(1) \\ne 0$.\nProof [1] Since $\\displaystyle I(n) = \\left[ {{ 1 } \\over { n }} \\right]$, when $n=1$, $\\left( f \\ast\\ f^{-1} \\right)(1) = I(1) = 1$, and therefore, $\\displaystyle f^{-1}(1) = {{ 1 } \\over { f(1) }}$. Because $f(1) \\ne 0$, $f^{-1}(1)$ is also unique. If $n \u0026gt;1$, then $\\left( f \\ast\\ f^{-1} \\right)(n) = I(n) = 0$, thus $$ \\sum_{d \\mid n} f \\left( {{ n } \\over { d }} \\right) f^{-1} (d) = 0 $$ Removing terms that are $n=d$, $$ f(1) f^{-1}(n) + \\sum_{d \\mid n \\\\ d \u0026lt; n} f \\left( {{ n } \\over { d }} \\right) f^{-1} (d) = 0 $$ Summarizing, $$ f^{-1}(n) = {{-1} \\over {f(1)}} \\sum_{d \\mid n \\\\ d \u0026lt; n } f \\left( {{ n } \\over { d }} \\right) f^{-1}(d) $$ Since it has been shown that $f^{-1}(1) \\ne 0$ uniquely exists for the case of $n=1$, by mathematical induction, $f^{-1}(n)$ also uniquely exists.\n‚ñ†\n[2] Strategy: Once existence is proved, direct calculation is possible due to the properties of convolution.\nProperties of convolution:\n(1) Associative law: $$ \\left( f \\ast g \\right) \\ast k = f \\ast (g \\ast k) $$ (2) Commutative law: $$ f \\ast\\ g = g \\ast\\ f $$ Based on the above [1], since $f(1) \\ne 0$ and $g(1) \\ne 0$, $f^{-1}$ and $g^{-1}$ uniquely exist. Likewise, $$ (f \\ast\\ g) (1) = \\sum_{ d \\mid 1} f(d)g(1/d) = f(1) g(1) \\ne 0 $$ Therefore, $\\left( f \\ast g \\right)^{-1}$ also uniquely exists. Then by the associative law of convolution, $$ \\begin{align*} (f \\ast\\ g) \\ast ( g^{-1} \\ast\\ f^{-1} ) =\u0026amp; f \\ast (g * g^{-1} ) \\ast\\ f^{-1} \\\\ =\u0026amp; f \\ast\\ I \\ast\\ f^{-1} \\\\ =\u0026amp; f * f^{-1} \\\\ =\u0026amp; I \\end{align*} $$ Since $\\left( f \\ast g \\right)^{-1}$ is unique, $\\left( f \\ast g \\right)^{-1} = g^{-1} \\ast\\ f^{-1}$ must be true. Additionally, by the commutative law of convolution, $$ (f \\ast\\ g)^{-1} = g^{-1} \\ast\\ f^{-1} = f^{-1} \\ast\\ g^{-1} $$\n‚ñ†\nApostol. (1976). Introduction to Analytic Number Theory: p30.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1494,"permalink":"https://freshrimpsushi.github.io/en/posts/1494/","tags":null,"title":"Inverse of Dirichlet Products"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Formulas $X \\sim \\text{Poi}(\\lambda)$ Surface $$ E(X) = \\lambda \\\\ \\text{Var}(X) = \\lambda $$\nDerivation Strategy: Directly deduce from the definition of the Poisson distribution. The trick of splitting factorials and series is important.\nDefinition of Poisson Distribution: For $\\lambda \u0026gt; 0$, an discrete probability distribution that has the following probability mass function $\\text{Poi} ( \\lambda )$ is called a Poisson distribution. $$ p(x) = {{ e^{-\\lambda} \\lambda^{x} } \\over { x! }} \\qquad , x = 0 , 1 , 2, \\cdots $$\nMean $$ \\begin{align*} E(X) =\u0026amp; \\sum _{ x=0 }^{ \\infty }{ x\\frac { { \\lambda ^ x }{ e ^ { - \\lambda } } }{ x! } } \\\\ =\u0026amp; { e ^ { - \\lambda } }\\sum _{ x=0 }^{ \\infty }{ x\\frac { { \\lambda ^ x } }{ x! } } \\\\ =\u0026amp; { e ^ { - \\lambda } }\\sum _{ x=1 }^{ \\infty }{ \\frac { { \\lambda \\cdot \\lambda } ^{ x-1 } }{ (x-1)! } } \\\\ =\u0026amp; { \\lambda e } ^{ -\\lambda } \\sum _{ x=1 }^{ \\infty }{ \\frac { { \\lambda } ^{ x-1 } }{ (x-1)! } } \\\\ =\u0026amp; \\lambda { e ^ { - \\lambda } }{ e^ \\lambda } \\\\ =\u0026amp; \\lambda \\end{align*} $$\n‚ñ†\nVariance $$ \\begin{align*} E({ X }^{ 2 }) =\u0026amp; \\sum _{ x=0 }^{ \\infty }{ { x } ^{ 2 } \\frac { { \\lambda ^ x }{ e ^ { - \\lambda } } }{ x! } } \\\\ =\u0026amp; { e ^ { - \\lambda } }\\sum _{ x=1 }^{ \\infty }{ x\\frac { { \\lambda ^ x } }{ (x-1)! } } \\\\ =\u0026amp; { e ^ { - \\lambda } }\\sum _{ x=1 }^{ \\infty }{ \\frac { { (x-1+1)\\lambda } ^{ x } }{ (x-1)! } } \\\\ =\u0026amp; { e ^ { - \\lambda } }\\sum _{ x=1 }^{ \\infty }{ \\frac { { (x-1)\\lambda } ^{ x }+{ \\lambda ^ x } }{ (x-1)! } } \\\\ =\u0026amp; { e ^ { - \\lambda } }\\sum _{ x=1 }^{ \\infty }{ \\left\\{ \\frac { { (x-1)\\lambda } ^{ x } }{ (x-1)! }+\\frac { { \\lambda ^ x } }{ (x-1)! } \\right\\} } \\\\ =\u0026amp; { e ^ { - \\lambda } }\\left\\{ \\sum _{ x=2 }^{ \\infty }{ \\frac { { \\lambda ^ x } }{ (x-2)! } }+\\sum _{ x=1 }^{ \\infty }{ \\frac { { \\lambda ^ x } }{ (x-1)! } } \\right\\} \\\\ =\u0026amp; { e ^ { - \\lambda } }\\left\\{ \\sum _{ x=2 }^{ \\infty }{ \\frac { { { \\lambda ^ 2 }\\cdot \\lambda } ^{ x-2 } }{ (x-2)! } }+\\sum _{ x=1 }^{ \\infty }{ \\frac { { \\lambda \\cdot \\lambda } ^{ x-1 } }{ (x-1)! } } \\right\\} \\\\ =\u0026amp; { e ^ { - \\lambda } }({ \\lambda ^ 2 }{ e^ \\lambda }+\\lambda { e^ \\lambda }) \\\\ =\u0026amp; { \\lambda ^ 2 }+\\lambda \\end{align*} $$ Therefore $$ \\text{Var} (X)=E({ X }^{ 2 })-{ \\left\\{ E(X) \\right\\} } ^{ 2 } ={ (\\lambda }^{ 2 }+\\lambda )-{ \\lambda }^{ 2 }=\\lambda $$\n‚ñ†\n","id":61,"permalink":"https://freshrimpsushi.github.io/en/posts/61/","tags":null,"title":"Mean and Variance of the Poisson Distribution"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definitions 1 For $\\lambda \u0026gt; 0$, we refer to the following probability mass function as the Poisson Distribution that has a discrete probability distribution $\\text{Poi} ( \\lambda )$. $$ p(x) = {{ e^{-\\lambda} \\lambda^{x} } \\over { x! }} \\qquad , x = 0 , 1 , 2, \\cdots $$\nBasic Properties Moment Generating Function [1]: $$m(t) = \\exp \\left[ \\lambda \\left( e^{t} - 1 \\right) \\right] \\qquad , t \\in \\mathbb{R}$$ Mean and Variance [2]: If $X \\sim \\text{Poi}(\\lambda)$ then $$ \\begin{align*} E(X) =\u0026amp; \\lambda \\\\ \\text{Var}(X) =\u0026amp; \\lambda \\end{align*} $$ Sufficient Statistic and Maximum Likelihood Estimation [3]: Suppose we have a random sample $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{n} \\right) \\sim \\text{Poi} \\left( p \\right)$. The sufficient statistic $T$ and maximum likelihood estimate $\\hat{\\lambda}$ for $\\lambda$ are as follows. $$ \\begin{align*} T =\u0026amp; \\sum_{k=1}^{n} X_{k} \\\\ \\hat{\\lambda} =\u0026amp; {{ 1 } \\over { n }} \\sum_{k=1}^{n} X_{k} \\end{align*} $$\nTheorem Derivation of Poisson Distribution as a Limit Distribution of Binomial Distribution [a]: Let $X_{n} \\sim B(n,p)$. If $\\mu \\approx np$ then $$ X_{n} \\overset{D}{\\to} \\text{Poi} (\\mu) $$\nDerivation of Standard Normal Distribution as a Limit Distribution of Poisson Distribution [b]: If $X_{n} \\sim \\text{Poi} \\left( n \\right)$ and $\\displaystyle Y_{n} := {{ X_{n} - n } \\over { \\sqrt{n} }}$ then $$ Y_{n} \\overset{D}{\\to} N(0,1) $$ Explanation Naming The probability mass function of Poisson distribution may seem complicated at first, but it actually originates from the series expansion of the exponential function. $$ e^{x} = 1 + {{ x } \\over { 1 ! }} + {{ x^{2} } \\over { 2! }} + {{ x^{3} } \\over { 3! }} + \\cdots $$ The parameter $x = \\lambda$ is usually assumed to be fixed, so dividing both sides by constant $e^{\\lambda}$ yields $$ 1 = {{ e^{-\\lambda} \\lambda^{0} } \\over { 0! }} + {{ e^{-\\lambda} \\lambda^{1} } \\over { 1! }} + {{ e^{-\\lambda} \\lambda^{2} } \\over { 2! }} + {{ e^{-\\lambda} \\lambda^{3} } \\over { 3! }} + \\cdots $$ Thus, the sum of all probability mass functions of the Poisson distribution is $1$. Unlike binomial distribution, geometric distribution, or negative binomial distribution, the Poisson distribution doesn\u0026rsquo;t derive its name from its formula.\nThe great physicist and mathematician, Poisson, proposed in his 1837 paper Research on the Probability of Judgments in Criminal and Civil Matters that the probability of certain events occurring within a unit time follows a specific distribution. This distribution was named the Poisson distribution after him, and his name is still attached to numerous probability theories and statistical techniques.\nDistribution with Equal Mean and Variance Before various applications, the Poisson distribution itself is an interesting topic of research. One of the most notable properties of the Poisson distribution is that its mean and variance are equal to the parameter $\\lambda$.\nRelationship with Exponential Distribution Meanwhile, the Poisson and exponential distributions focus on similar phenomena, with the former concerned with the number of events occurring in a unit time, and the latter with the time until an event occurs. This relationship between the two distributions led some texts to use the same Greek letter $\\lambda$ for both. Especially when considering that the mean of the Poisson distribution is $\\lambda$, and the mean of the exponential distribution is $\\displaystyle {{ 1 } \\over { \\lambda }}$, one can perceive the relationship between the two distributions as a kind of \u0026lsquo;inverse\u0026rsquo;.\nProof [1] $$ \\begin{align*} m(t) =\u0026amp; \\sum_{x=0}^{n} e^{tx} p(x) \\\\ =\u0026amp; \\sum_{x=0}^{n} e^{tx} {{ \\lambda^{x} e^{-\\lambda} } \\over { x! }} \\\\ =\u0026amp; e^{-\\lambda} \\sum_{x=0}^{n} {{ \\left( e^{t}\\lambda \\right)^{x} } \\over { x! }} \\\\ =\u0026amp; e^{-\\lambda} e^{\\lambda e^{t}} \\\\ =\u0026amp; \\exp \\left[ -\\lambda + \\lambda e^{t} \\right] \\\\ =\u0026amp; \\exp \\left[ \\lambda ( e^{t} - 1) \\right] \\end{align*} $$\n‚ñ†\n[2] Direct deduction.\n‚ñ†\n[3] Direct deduction.\n‚ñ†\n[a] Approximation via moment generating function.\n‚ñ†\n[b] Approximation by omitting terms in Taylor expansion.\n‚ñ†\nCode Below is a Julia code that demonstrates the probability mass function of Poisson distribution in an animated GIF.\n@time using LaTeXStrings\r@time using Distributions\r@time using Plots\rcd(@__DIR__)\rx = 0:20\rŒõ = collect(1:0.1:10); append!(Œõ, reverse(Œõ))\ranimation = @animate for Œª ‚àà Œõ\rscatter(x, pdf.(Poisson(Œª), x),\rcolor = :black,\rlabel = \u0026#34;Œª = $(round(Œª, digits = 2))\u0026#34;, size = (400,300))\rxlims!(0,10); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,Poi}(\\lambda)\u0026#34;)\rend\rgif(animation, \u0026#34;pmf.gif\u0026#34;) Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p152.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1491,"permalink":"https://freshrimpsushi.github.io/en/posts/1491/","tags":null,"title":"Poisson Distribution"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 A arithmetic function defined as follows $I$ is called the identity function. $$ I(n) := \\left[ {{ 1 } \\over { n }} \\right] $$\n[1] Identity series: This is the unit function $u$. In other words, $$ \\sum_{d \\mid n}I(d) = u(n) = 1 $$ [2] Completely multiplicative: For all $n , m \\in \\mathbb{N}$, $I (mn) = I(m) I(n)$ [a] Identity element for convolution: For all arithmetic functions $f$, $$ I \\ast\\ f = f \\ast\\ I = f $$ $\\left[ x \\right] = \\lceil x \\rceil$ is called the floor function and represents the largest integer less than or equal to $x$. Explanation $$ \\begin{matrix} n \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 4 \u0026amp; 5 \u0026amp; 6 \u0026amp; 7 \u0026amp; 8 \u0026amp; 9 \u0026amp; 10 \\\\ I(n) \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ \\sum_{d \\mid n} I(d) \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \\end{matrix} $$ In most of mathematics, the name identity function is given to the function whose elements of the domain map to themselves as in $i(x) = x$, but at least in analytic number theory, it‚Äôs called the norm $N (n) = n$. As seen in $I$, it can be called an identity because it always exists as the identity element for convolution $\\ast$.\nProof [1] $\\displaystyle I(n) = \\left[ {{ 1 } \\over { n }} \\right] = \\begin{cases} 1 \u0026amp; , n=1 \\\\ 0 \u0026amp;, n\u0026gt;1 \\end{cases}$ is true. Therefore, $$ \\sum_{d \\mid n}I(d) = 1 + 0 + \\cdots = 1 $$\n‚ñ†\n[2] Case 1. $m = n = 1$ $$ I ( mn ) = I(1) = 1 = 1 \\cdot 1 = I(1) I(1) = I(m) I(n) $$ Case 2. $m = 1 \\land n \u0026gt; 1$ $$ I(mn) = I (n) = 1 \\cdot I (n) = I(m) I(n) $$ Case 3. $m \u0026gt; 1 \\land n = 1$ $$ I(mn) = I (m) = I(m) \\cdot 1 = I(m) I(n) $$ Case 4. $m \u0026gt; 1 \\land n \u0026gt; 1$ $$ I(mn) = 0 = 0 \\cdot 0 = I(m) I(n) $$ ‚ñ†\n[a] Since $d$ is a divisor of $n$, in the case of $d \\ne n$, $\\displaystyle \\left[ {{ d } \\over { n }} \\right] = 0$ and $$ (f \\ast\\ I)(n) = \\sum_{d \\mid n} f(d) I \\left( {{ n } \\over { d }} \\right) = \\sum_{d \\mid n} f(d) \\left[ {{ d } \\over { n }} \\right] = f(n) $$ According to the commutative law of convolution of arithmetic functions, $f \\ast\\ I = I \\ast\\ f = f$\n‚ñ†\nApostol. (1976). Introduction to Analytic Number Theory: p30.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1490,"permalink":"https://freshrimpsushi.github.io/en/posts/1490/","tags":null,"title":"Identity for Dirichlet Products"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Differential Equations This has been explained as intuitively as possible for those studying undergraduate physics.\nA differential equation is, simply put, an equation that involves derivatives. Without any complications, since acceleration is the second derivative of position, the most famous physics formula $F=ma$ is also a differential equation.\nThe polynomial $x^{3}+3x+1=0$ is called a third-degree equation because its highest order is 3. Similarly, when the maximum number of times differentiated in a differential equation is $n$, that differential equation is called a $n$th-order differential equation. While it is often referred to as an nth-degree equation, it is more accurately an nth-order equation. Consider that $f^{\\prime \\prime}$ is called the second-order derivative, not the second derivative.\nLet\u0026rsquo;s now accept and move on with the following facts:\nJust as a $n$th-degree equation has $n$ solutions, a $n$th-order differential equation also has $n$ solutions. The solution to a differential equation is also a solution when linearly combined. A linear combination is the addition of the given objects multiplied by constants each, for example, the linear combination of $x$ and $y$ for constants $a, b$ would be expressed as $ax+by$.\nGeneral Solution The general solution refers to a general form that can represent all solutions of a differential equation. The most familiar example of a general solution is the quadratic formula. The quadratic formula\n$$ x = \\dfrac{-b \\pm \\sqrt{b^{2}-4ac}}{2a} $$\nrepresents the most general form of all solutions to a quadratic equation of the form $ax^{2} + bx + c = 0$. Let\u0026rsquo;s give another example. The solution to \u0026ldquo;find a function whose graph passes through $(0,3)$\u0026rdquo; could be\n$$ y=x+3,\\quad y=3x+3,\\quad y=5x+3 $$\namong others. If we want to succinctly represent all possible solutions at once, it would be as follows:\n$$ y=ax+3 $$\nTherefore, $y=ax+3$ is the general solution to the problem.\nSolutions Solving a differential equation means to find its general solution. The following four differential equations are frequently encountered when studying physics. Therefore, it\u0026rsquo;s good to memorize the solutions once they are understood.\nLet $X=X(x)$ be a function of one variable, and $\\alpha$ a constant.\nFirst-Order Differential Equations $$ \\frac{ d X}{ dx }=\\alpha X $$\nThe task is to find a function that, when differentiated, gives itself. As known from high school, this refers to $e^{x}$. The answer satisfying the condition of constant $\\alpha$ is:\n$$ X(x)=e^{\\alpha x} $$\nSince any coefficient multiplied in front still holds, the general solution is:\n$$ X(x)=Ae^{\\alpha x} $$\nWhere $A$ is an arbitrary constant.\nSecond-Order Differential Equations with Positive Coefficient $$ \\begin{equation} \\frac{ d^{2}X }{ dx^{2} }=\\alpha ^{2} X \\end{equation} $$\nA function that still remains itself and keeps its sign when differentiated twice is also the exponential function $e^{x}$. The answer that satisfies the condition of constant $\\alpha$ is:\n$$ X(x)=e^{\\alpha x} $$\nThe reason for writing the constant as $\\alpha$ instead of $\\alpha ^{2}$ in $(1)$ is to cleanly express the solution. If expressed with $\\alpha$, the solution would be $X(x)=e^{\\sqrt{\\alpha}x}$, which is less clean than the above case. And since $(-1)\\times (-1)=1$:\n$$ X(x)=e^{-\\alpha x} $$\nIt\u0026rsquo;s also known that $(1)$ satisfies this solution. Therefore, the general solution is:\n$$ X(x)=Ae^{\\alpha x}+Be^{-\\alpha x} $$\nHere $A$, $B$ are constants.\nSecond-Order Differential Equations with Negative Coefficient $$ \\frac{ d ^{2}X}{ dx^{2} }=-\\alpha^{2}X \\tag{2} $$\nA function that remains itself but changes sign when differentiated twice is well known to be $\\cos x$ and $\\sin x$. The answer that satisfies the conditions for constants is:\n$$ X(x)=\\cos (\\alpha x),\\quad X(x)=\\sin ( \\alpha x) $$\nTherefore, the general solution is:\n$$ X(x)=A\\cos (\\alpha x) +B\\sin (\\alpha x) \\tag{3} $$\nHere $A$, $B$ are constants. However, since the exponent of the exponential function includes the complex number $i$, it satisfies $(2)$ similarly, meaning $X(x)=e^{i\\alpha x}$ and $X(x)=e^{-i\\alpha x}$ are also solutions. Thus, the general solution is:\n$$ X(x)=Ce^{i\\alpha x}+De^{-i\\alpha x} \\tag{4} $$\nHere $C$, $D$ are constants. By Euler\u0026rsquo;s formula $e^{i\\alpha x}=\\cos (\\alpha x) + i \\sin (\\alpha x)$, sine and cosine functions can be interchanged with exponential functions, which means $(3)$ and $(4)$, while notationally different, are the same expression. In quantum mechanics, where the solution is a complex function (wave function), it\u0026rsquo;s common to use the exponential form including $i$, and in mechanics, where the solution is clearly a real function, it\u0026rsquo;s often expressed with $\\cos$.\nSecond-Order Differential Equations with a Constant Term $$ \\begin{equation} \\frac{ d ^{2} X}{ d x^{2}}=\\pm\\alpha^{2}X+\\beta \\end{equation} $$\n$(1)$ and $(2)$ can be briefly expressed without coefficients as follows:\n$$ \\frac{ d ^{2}X}{ d x^{2} }\\pm X=0 $$\nThis implies that differentiating $X$ and $X$ twice results in the same output, except for the sign difference. However, the inclusion of a constant term in the differential equation, as in $(5)$, implies differences beyond just the sign. To make $X$ and $X^{\\prime \\prime}$ differ by only the constant term, it\u0026rsquo;s simple. Consider that $X$ has a constant term. A constant term disappears upon a single differentiation, and naturally, it\u0026rsquo;s gone upon the second. Thus, incorporating another suitable constant multiplied by the constant term in $X$ solves it. The solution for $X^{\\prime \\prime}=\\alpha^{2} X + \\beta$ is:\n$$ X(x)=Ae^{\\alpha x} + B e^{-\\alpha x} - \\dfrac{\\beta}{\\alpha^{2}} $$\nAnd the solution for $X^{\\prime \\prime}=-\\alpha ^{2}X+C$ is:\n$$ X(x)=Ce^{i\\alpha x}+De^{-i\\alpha x} - \\dfrac{\\beta}{\\alpha^{2}} $$\nUpon inserting these into $(5)$, their validity can be confirmed.\n","id":1538,"permalink":"https://freshrimpsushi.github.io/en/posts/1538/","tags":null,"title":"Differential Equations for Physics: Solutions to Commonly Encountered Differential Equations"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 Given $r \\in \\mathbb{N}$ and $p \\in (0,1]$, a discrete probability distribution $\\text{NB}(r,p)$ with the following probability mass function is called the Negative Binomial Distribution. $$ p(x) = \\binom{r+x-1}{x-1} p^{r}(1-p)^{x} \\qquad, x = 0,1,2,\\cdots $$\nBasic Properties Moment Generating Function [1]: $$m(t) = \\left[ {{ p } \\over { 1 - (1-p) e^{t} }} \\right]^{r} \\qquad , t \u0026lt; -\\log (1-P)$$ Mean and Variance [2]: If $X \\sim \\text{NB}(r, p)$, then $$ \\begin{align*} E(X) =\u0026amp; {{ r (1-p) } \\over { p }} \\\\ \\text{Var}(X) =\u0026amp; {{ r (1-p) } \\over { p^{2} }}\\end{align*} $$ Description The negative binomial distribution is concerned with the number of trials needed for an event with a probability $p$ to occur $r$ times. For example, consider how many times one must flip a coin until it lands on heads twice. Given that the probability of landing on heads is $50%$, it would take about two flips to get heads once, and needing that to happen one more time gives us an expected value of $4$.\nIntuitively, the negative binomial distribution can be seen as a generalization of the geometric distribution with the number of successes $r$ generalized. In fact, when the number of successes is one, i.e., $r = 1$, it exactly becomes the geometric distribution.\nNaming The reason for calling it a negative binomial distribution is because the shape of its probability mass function is related to the negative binomial coefficient.\nTheorem Generalization of Geometric Distribution [b]: If $Y = X_{1} + \\cdots + X_{r}$ and $X_{i} \\overset{\\text{iid}}{\\sim} \\text{Geo}(p)$, then $Y \\sim \\text{NB}(r,p)$ Proof [1] Negative Binomial Coefficient: $$ (-1)^{k} \\binom{-r}{k} = \\binom{r + k - 1}{ k } $$\n$$ \\begin{align*} m(t) =\u0026amp; \\sum_{x=0}^{\\infty} e^{tx} p(x) \\\\ =\u0026amp; \\sum_{x=0}^{\\infty} e^{tx} \\binom{r+x-1}{x} p^{r} (1-p)^{x} \\\\ =\u0026amp; p^{r}\\sum_{x=0}^{\\infty} \\binom{-r}{x} (-1)^{x} \\left[ (1-p) e^{t} \\right]^{x} \\\\ =\u0026amp; p^{r}\\sum_{x=0}^{\\infty} \\binom{-r}{x} \\left[ - (1-p) e^{t} \\right]^{x} \\end{align*} $$\nBinomial Series: If $|x| \u0026lt; 1$, then for $\\alpha \\in \\mathbb{C}$, $\\displaystyle (1 + x )^{\\alpha} = \\sum_{k=0}^{\\infty} \\binom{\\alpha}{k} x^{k}$\nBased on the binomial series, since $\\displaystyle \\sum_{x=0}^{\\infty} \\binom{-r}{x} \\left[ - (1-p) e^{t} \\right]^{x} = \\left[ 1 - (1-p) e^{t} \\right]^{-r}$, $$ m(t) = \\left[ {{ p } \\over { 1 - (1-p) e^{t} }} \\right]^{r} \\qquad , t \u0026lt; -\\log (1-P) $$\n‚ñ†\n[2] Using the concept of Generalization of Geometric Distributions.\n‚ñ†\n[b] When the probability mass function of a geometric distribution is defined as $p(x) = p (1-p)^{x} \\qquad,x=0,1,2,\\cdots$, its moment generating function is as follows: $$ m(t) = p \\left( 1 - (1-p) e^{t} \\right)^{-1} $$ Since the random variables $X_1, X_2, \\cdots , X_r$, which are mutually independent, follow $\\text{Geo} (p)$, the moment generating function for $Y$ is $$ \\begin{align*} M_Y(t) =\u0026amp; E(e^{Yt}) \\\\ =\u0026amp; E(e^{(X_1+X_2+\\cdots+X_r)t}) \\\\ =\u0026amp; E(e^{X_1 t}) E(e^{X_2 t}) \\cdots E(e^{X_r t}) \\\\ =\u0026amp; \\prod_{i=1}^r p { (1 - (1-p) e^t ) }^{-1} \\\\ =\u0026amp; p^r \\left\\{ (1 - (1-p) e^t ) \\right\\}^{-r} \\end{align*} $$ This is identical to the moment generating function for the negative binomial distribution $\\text{NB}(r,p)$, therefore $Y \\sim \\text{NB}(r,p)$\n‚ñ†\nCode Below is a Julia code to show the probability mass function of the negative binomial distribution as a gif.\n@time using LaTeXStrings\r@time using Distributions\r@time using Plots\rcd(@__DIR__)\rx = 0:20\rP = collect(0.2:0.01:0.8); append!(P, reverse(P))\ranimation = @animate for p ‚àà P\rscatter(x, pdf.(NegativeBinomial(5, p), x),\rcolor = :black, markerstrokecolor = :black,\rlabel = \u0026#34;r = 5, p = $(rpad(p, 4, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300))\rxlims!(0,20); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,NB}(5, p)\u0026#34;)\rend\rgif(animation, \u0026#34;pmf5.gif\u0026#34;)\ranimation = @animate for p ‚àà P\rscatter(x, pdf.(NegativeBinomial(10, p), x),\rcolor = :black, markerstrokecolor = :black,\rlabel = \u0026#34;r = 10, p = $(rpad(p, 4, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300))\rxlims!(0,20); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,NB}(10, p)\u0026#34;)\rend\rgif(animation, \u0026#34;pmf10.gif\u0026#34;) Hogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p145.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1489,"permalink":"https://freshrimpsushi.github.io/en/posts/1489/","tags":null,"title":"Negative Binomial Distribution"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 For two arithmetic functions $f$, $g$, the arithmetic function $h$ satisfying the following is called the Dirichlet product of $f$ and $g$. $$ h(n) = \\sum_{d \\mid n} f(d) g \\left( {{ n } \\over { d }} \\right) $$ The Dirichlet product can be represented as either $h (n) = \\left( f \\ast g \\right) (n) $ or $h = f \\ast g$.\nExplanation The Dirichlet product, as can be inferred from its form, is also called a convolution. It can be guessed that merely denoting an arithmetic function as $a_{d}$, $b_{n/d}$ in this definition would be quite inconvenient.\nFor convolution $\\ast$, the set of arithmetic functions has the following basic algebraic properties. If one is interested in analytic number theory, it is natural to think of the abelian group $(A,*)$ obtained by applying binary operation $\\ast$ to the set of arithmetic functions $A$. Unfortunately, the accurate answer is \u0026rsquo;no\u0026rsquo;, but by providing more appropriate conditions, it can form an abelian group.\nMoreover, the convolution can be generalized such that one of the two functions being multiplied does not have to be an arithmetic function.\nBasic Properties [1] Associative law: $$ \\left( f \\ast g \\right) \\ast k = f \\ast (g \\ast k) $$ [2] Commutative law: $$ f \\ast g = g \\ast f $$ Proof [1] Let\u0026rsquo;s say $A = f \\ast g$, $B := (g \\ast k)$, then $$ \\begin{align*} \\left( f \\ast g \\right) \\ast k =\u0026amp; A \\ast k \\\\ =\u0026amp; \\sum_{cm = n} A(m) k(c) \\\\ =\u0026amp; \\sum_{cm=n} \\left[ \\sum_{ab=m} f(a) g(b) \\right] k(c) \\\\ =\u0026amp; \\sum_{abc=n} f(a) g(b) k(c) \\\\ =\u0026amp; \\sum_{am=n} f(a) \\left[ \\sum_{bc=m} g(b) k(c) \\right] \\\\ =\u0026amp; \\sum_{am=n} f(a) B(m) \\\\ =\u0026amp; f \\ast B \\\\ =\u0026amp; f \\ast (g \\ast k) \\end{align*} $$\n‚ñ†\n[2] $$ \\begin{align*} \\left( f \\ast g \\right)(n) =\u0026amp; \\sum_{d \\mid n} f(d) g \\left( {{ n } \\over { d }} \\right) \\\\ =\u0026amp; \\sum_{ab=n} f(a) g(b) \\\\ =\u0026amp; \\sum_{ab=n} g(b) f(a) \\\\ =\u0026amp; \\sum_{d \\mid n} g(d) f\\left( {{ n } \\over { d }} \\right) \\\\ =\u0026amp; (g \\ast f)(n) \\end{align*} $$\n‚ñ†\nGeneralization Generalized Dirichlet product Apostol. (1976). Introduction to Analytic Number Theory: p29.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1488,"permalink":"https://freshrimpsushi.github.io/en/posts/1488/","tags":null,"title":"Arithmetic Functions' Dirichlet Convolution"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 A function whose domain is the set of natural numbers $\\mathbb{N}$ and whose range is the set of real numbers $\\mathbb{R}$ or the set of complex numbers $\\mathbb{C}$ is called an arithmetic function.\nDescription In analytic number theory, there is interest in the properties and relationships of various arithmetic functions, including examples such as:\nIdentity function $I$ Divisor function $\\sigma_{\\alpha}$ Norm $N$ Divisor function $\\sigma_{\\alpha}$ M√∂bius function $\\mu$ Euler‚Äôs totient function $\\varphi$ Unit function $u$ Mangoldt function $\\Lambda$ Liouville function $\\lambda$ The definition of an arithmetic function might not seem new‚Äîit\u0026rsquo;s essentially just a sequence. Indeed, sequences have always been functions, though in many areas of mathematics, the term itself is commonly used distinct from functions. However, in (analytic) number theory, since the subjects of interest are naturally numbers, having $\\mathbb{N}$ or $\\mathbb{Z}$ as the domain is sufficient, and there\u0026rsquo;s hardly a reason to distinguish between a sequence and a function. However, since they are treated more closely as functions, the term arithmetic function is used. Formally, even though the domain is not a vector field, the fact that the range is $\\mathbb{R}$ or $\\mathbb{C}$ is similar to functionals.\nFurthermore, there is interest in the series of arithmetic functions. For example, for a given arithmetic function $f$, finding $\\displaystyle F(n) = \\sum_{d \\mid n} f(d)$. $\\displaystyle \\sum_{d \\mid n}$ involves calculations for all divisors $d$ of $n$, which can be understood in a similar sense to calculating $\\displaystyle \\sum_{k=1}^{\\infty}$ in general analysis.\nApostol. (1976). Introduction to Analytic Number Theory: p24.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1487,"permalink":"https://freshrimpsushi.github.io/en/posts/1487/","tags":null,"title":"Arithmetic Functions in Analytic Number Theory"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Julia\u0026rsquo;s latest version as of this post is v1.3.1.\nGuide Step 1. Download Julia Download the file that matches your CPU\u0026rsquo;s bit from Generic Linux Binaries for x86.\nStep 2. Unzip and Move Unzip it.\nMove the folder to where Julia is to be stored. This can be any location of your preference, but this post has moved it to /home/[username]/julia-1.3.1.\nStep 3. Symbolic Link Use the following command to create a symbolic link.\nsudo ln -s /home/[Ïú†Ï†ÄÏù¥Î¶Ñ]/julia-1.3.1/bin/julia /usr/bin/julia By running Julia through the command, you can confirm that version 1.3.1 is installed properly.\nIf You Don\u0026rsquo;t Need the Latest Version sudo apt-get install julia Using the above command, you can quickly install without setting up a symbolic link. However, this method does not install the latest stable version.\nEnvironment OS: Ubuntu 18.04 ","id":1511,"permalink":"https://freshrimpsushi.github.io/en/posts/1511/","tags":null,"title":"Installing the Latest Version of Julia on Linux"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 For $p \\in (0,1]$, the discrete probability distribution $\\text{Geo}(p)$ that follows the probability mass function as shown above, is called the Geometric Distribution. $$ p(x) = p (1 - p)^{x-1} \\qquad , x = 1 , 2, 3, \\cdots $$\nTake special care with the domain and the formula as there are two definitions used. Basic Properties Moment Generating Function [1]: $$m(t) = {{ p e^{t} } \\over { 1 - (1-p) e^{t} }} \\qquad , t \u0026lt; -\\log (1-p)$$ Mean and Variance [2]: If $X \\sim \\text{Geo} (p)$ then $$ \\begin{align*} E(X) =\u0026amp; {{ 1 } \\over { p }} \\\\ \\text{Var}(X) =\u0026amp; {{ 1-p } \\over { p^{2} }} \\end{align*} $$ Sufficient Statistic and Maximum Likelihood Estimator [3]: Suppose a random sample $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{n} \\right) \\sim \\text{Geo} \\left( p \\right)$ is given. The sufficient statistic $T$ and maximum likelihood estimator $\\hat{p}$ for $p$ are as follows. $$ \\begin{align*} T =\u0026amp; \\sum_{k=1}^{n} X_{k} \\\\ \\hat{p} =\u0026amp; {{ n } \\over { \\sum_{k=1}^{n} X_{k} }} \\end{align*} $$ Theorems Memorylessness [a]: If $X \\sim \\text{Geo} (p)$ then $$ P(X \\ge s+ t ,|, X \\ge s) = P(X \\ge t) $$ Generalization to Geometric Distribution [b]: If $Y = X_{1} + \\cdots + X_{r}$ and $X_{i} \\overset{\\text{iid}}{\\sim} \\text{Geo}(p)$ then $Y \\sim \\text{NB}(r,p)$ Explanation Relation with Exponential Distribution The geometric distribution is interested in how many trials it takes to achieve success with probability $0 \u0026lt; p \\le 1$. Its probability mass function represents the probability of failing $x-1$ times with probability $(1-p)$ before finally succeeding with probability $p$. This characteristic allows it to be seen as the discretization of exponential distribution.\nNaming The distribution is called the geometric distribution because its probability mass function has the form of a geometric sequence. If we set $a := p$, $r := (1-p)$, we get a familiar formula with $p(x) = a r ^{x-1}$. Indeed, when computing the moment-generating function, the formula for a geometric series appears.\nProof [1] $$ \\begin{align*} M(t) =\u0026amp; \\sum_{x=1}^{\\infty} e^{tx} p(x) \\\\ =\u0026amp; \\sum_{x=1}^{\\infty} e^{tx} p (1-p)^{x-1} \\\\ =\u0026amp; p e^{t} \\sum_{x=1}^{\\infty} \\left[ e^{t}(1-p) \\right]^{x-1} \\end{align*} $$ When $ t \u0026lt; -\\log (1-p)$, according to the formula for a geometric series, $$ p e^{t} \\sum_{x=1}^{\\infty} \\left[ e^{t}(1-p) \\right]^{x-1} = {{ p e^{t} } \\over { 1 - (1-p) e^{t} }} $$\n‚ñ†\n[2] There are two methods.\n‚ñ†\n[3] Direct deduction.\n‚ñ†\n[a] Deduced using conditional probability.\n‚ñ†\n[b] Deduced using the moment generating function.\n‚ñ†\nCode Below is a Julia code that shows the probability mass function of the geometric distribution as a gif.\n@time using LaTeXStrings @time using Distributions @time using Plots cd(@__DIR__) x = 0:20 P = collect(0.01:0.01:0.5); append!(P, reverse(P)) animation = @animate for p ‚àà P scatter(x, pdf.(Geometric(p), x), color = :black, markerstrokecolor = :black, label = \u0026#34;p = $(rpad(p, 4, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300)) xlims!(0,20); ylims!(0,0.3); title!(L\u0026#34;\\mathrm{pmf\\,of\\,Geo}(p)\u0026#34;) end gif(animation, \u0026#34;pmf.gif\u0026#34;) Hogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p145.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1486,"permalink":"https://freshrimpsushi.github.io/en/posts/1486/","tags":null,"title":"Geometric Distribution"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 The discrete probability distribution $\\text{Bin}(n,p)$ with the following probability mass function for $n \\in \\mathbb{N}$ and $p \\in [0,1]$ is called the Binomial Distribution. $$ p(x) = \\binom{n}{x} p^{x} (1-p)^{n-x} \\qquad , x = 0 , 1, \\cdots n $$\nBasic Properties Moment Generating Function [1]: $$m(t) = \\left[ (1-p) + pe^{t} \\right]^{n} \\qquad , t \\in \\mathbb{R}$$ Mean and Variance [2]: If $X \\sim \\text{Bin}(n,p)$ then $$ \\begin{align*} E(X) =\u0026amp; np \\\\ \\text{Var}(X) =\u0026amp; np(1-p) \\end{align*} $$ Theorems Deriving the Poisson Distribution as a Limiting Distribution of the Binomial Distribution [a]: Let $X_{n} \\sim B(n,p)$. If $\\mu \\approx np$ then $$ X_{n} \\overset{D}{\\to} \\text{Poi} (\\mu) $$ Deriving the Standard Normal Distribution as a Limiting Distribution of the Binomial Distribution [b]: If $X_i \\sim B(1,p)$ and $Y_n = X_1 + X_2 + \\cdots + X_n$ then $Y_n \\sim B(n,p)$ and $$ { { Y_n - np } \\over {\\sqrt{ np(1-p) } } }\\overset{D}{\\to} N(0,1) $$ Explanation Bernoulli Distribution The Binomial Distribution originates from the Bernoulli Trial, which is the simplest form of probability experiment most humans can think of. A Bernoulli trial has only two possible outcomes, success with probability $0 \\le p \\le 1$ or failure, and generalizing this to $n$ times yields the Binomial Distribution. Conversely, the Bernoulli Distribution is a special case of the Binomial Distribution when $n=1$.\nMultinomial Distribution Furthermore, generalizing from a binary outcome, success or failure, to $k$ possible outcomes yields the Multivariate Distribution $M (n; p_{1} , \\cdots , p_{k})$ known as the Multinomial Distribution. Its probability mass function is given as follows: $$ p(x_{1} , \\cdots , x_{k}) = {{ n! } \\over { x_{1} ! \\cdots x_{k}! }} p_{1}^{x_{1}} \\cdots p_{k}^{x_{k}} $$\nProof [1] $$ \\begin{align*} M(t) =\u0026amp; \\sum_{x=0}^{n} e^{tx} p(x) \\\\ =\u0026amp; \\sum_{x=0}^{n} e^{tx} \\binom{n}{x} p^{x} (1-p)^{n-x} \\\\ =\u0026amp; \\sum_{x=0}^{n} \\binom{n}{x} \\left( pe^{t} \\right)^{x} (1-p)^{n-x} \\end{align*} $$ According to the Binomial Theorem $$ \\sum_{x=0}^{n} \\binom{n}{x} \\left( pe^{t} \\right)^{x} (1-p)^{n-x} = \\left[ pe^{t} + (1-p) \\right]^{n} $$\n‚ñ†\n[2] Strategy: Although it can be derived using algebraic tricks similar to those in the curriculum, let\u0026rsquo;s use the theory of mathematical statistics to derive it more easily since we\u0026rsquo;ve also derived the moment generating function.\nThe derivative of $M$ is $$ M ' (t) = n \\left[ (1-p) + pe^{t} \\right]^{n-1} \\left( pe^{t} \\right) $$ Since by the definition of the moment generating function $ E(X) = M ' (0):$ is given, $$ \\mu := E(X) = M ' (0) = np $$ The second derivative of $M$ is $$ M '' (t) = n \\left[ (1-p) + pe^{t} \\right]^{n-1} \\left( pe^{t} \\right) + n(n-1) \\left[ (1-p) + pe^{t} \\right]^{n-2} \\left( pe^{t} \\right)^{2} $$ Since $M '' (0) = np + n(n-1)p^{2}$, $$ \\begin{align*} \\text{Var}(X) =\u0026amp; E \\left( X^{2} \\right) - \\mu^{2} \\\\ =\u0026amp; M '' (0) - (np)^{2} \\\\ =\u0026amp; np + n(n-1)p^{2} - n^{2}p^{2} \\\\ =\u0026amp; np(1-p) \\end{align*} $$\n‚ñ†\n[a] Approximated by the moment generating function.\n‚ñ†\n[b] Approximated similarly to the Central Limit Theorem.\n‚ñ†\nCode Following is Julia code displaying the probability mass function of the binomial distribution as a GIF.\n@time using LaTeXStrings @time using Distributions @time using Plots cd(@__DIR__) x = 0:20 P = collect(0.0:0.01:1.0); append!(P, reverse(P)) animation = @animate for p ‚àà P scatter(x, pdf.(Binomial(10, p), x), color = :black, markerstrokecolor = :black, label = \u0026#34;n = 10, p = $(rpad(p, 4, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300)) xlims!(0,20); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,Bin}(10, p)\u0026#34;) end gif(animation, \u0026#34;pmf10.gif\u0026#34;) animation = @animate for p ‚àà P scatter(x, pdf.(Binomial(20, p), x), color = :black, markerstrokecolor = :black, label = \u0026#34;n = 20, p = $(rpad(p, 4, \u0026#39;0\u0026#39;))\u0026#34;, size = (400,300)) xlims!(0,20); ylims!(0,0.5); title!(L\u0026#34;\\mathrm{pmf\\,of\\,Bin}(20, p)\u0026#34;) end gif(animation, \u0026#34;pmf20.gif\u0026#34;) Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p142.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1480,"permalink":"https://freshrimpsushi.github.io/en/posts/1480/","tags":["Ï§ÑÎ¶¨ÏïÑ"],"title":"Binomial Distribution"},{"categories":"Ï†ïÏàòÎ°†","contents":"Prime numbers A list of primes up to the 10,000th.\nDownload\r2 3 5 7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97 101 103 107 109 113 127 131 137 139 149 151 157 163 167 173 179 181 191 193 197 199 211 223 227 229 233 239 241 251 257 263 269 271 277 281 283 293 307 311 313 317 331 337 347 349 353 359 367 373 379 383 389 397 401 409 419 421 431 433 439 443 449 457 461 463 467 479 487 491 499 503 509 521 523 541 547 557 563 569 571 577 587 593 599 601 607 613 617 619 631 641 643 647 653 659 661 673 677 683 691 701 709 719 727 733 739 743 751 757 761 769 773 787 797 809 811 821 823 827 829 839 853 857 859 863 877 881 883 887 907 911 919 929 937 941 947 953 967 971 977 983 991 997 1009 1013 1019 1021 1031 1033 1039 1049 1051 1061 1063 1069 1087 1091 1093 1097 1103 1109 1117 1123 1129 1151 1153 1163 1171 1181 1187 1193 1201 1213 1217 1223 1229 1231 1237 1249 1259 1277 1279 1283 1289 1291 1297 1301 1303 1307 1319 1321 1327 1361 1367 1373 1381 1399 1409 1423 1427 1429 1433 1439 1447 1451 1453 1459 1471 1481 1483 1487 1489 1493 1499 1511 1523 1531 1543 1549 1553 1559 1567 1571 1579 1583 1597 1601 1607 1609 1613 1619 1621 1627 1637 1657 1663 1667 1669 1693 1697 1699 1709 1721 1723 1733 1741 1747 1753 1759 1777 1783 1787 1789 1801 1811 1823 1831 1847 1861 1867 1871 1873 1877 1879 1889 1901 1907 1913 1931 1933 1949 1951 1973 1979 1987 1993 1997 1999 2003 2011 2017 2027 2029 2039 2053 2063 2069 2081 2083 2087 2089 2099 2111 2113 2129 2131 2137 2141 2143 2153 2161 2179 2203 2207 2213 2221 2237 2239 2243 2251 2267 2269 2273 2281 2287 2293 2297 2309 2311 2333 2339 2341 2347 2351 2357 2371 2377 2381 2383 2389 2393 2399 2411 2417 2423 2437 2441 2447 2459 2467 2473 2477 2503 2521 2531 2539 2543 2549 2551 2557 2579 2591 2593 2609 2617 2621 2633 2647 2657 2659 2663 2671 2677 2683 2687 2689 2693 2699 2707 2711 2713 2719 2729 2731 2741 2749 2753 2767 2777 2789 2791 2797 2801 2803 2819 2833 2837 2843 2851 2857 2861 2879 2887 2897 2903 2909 2917 2927 2939 2953 2957 2963 2969 2971 2999 3001 3011 3019 3023 3037 3041 3049 3061 3067 3079 3083 3089 3109 3119 3121 3137 3163 3167 3169 3181 3187 3191 3203 3209 3217 3221 3229 3251 3253 3257 3259 3271 3299 3301 3307 3313 3319 3323 3329 3331 3343 3347 3359 3361 3371 3373 3389 3391 3407 3413 3433 3449 3457 3461 3463 3467 3469 3491 3499 3511 3517 3527 3529 3533 3539 3541 3547 3557 3559 3571 3581 3583 3593 3607 3613 3617 3623 3631 3637 3643 3659 3671 3673 3677 3691 3697 3701 3709 3719 3727 3733 3739 3761 3767 3769 3779 3793 3797 3803 3821 3823 3833 3847 3851 3853 3863 3877 3881 3889 3907 3911 3917 3919 3923 3929 3931 3943 3947 3967 3989 4001 4003 4007 4013 4019 4021 4027 4049 4051 4057 4073 4079 4091 4093 4099 4111 4127 4129 4133 4139 4153 4157 4159 4177 4201 4211 4217 4219 4229 4231 4241 4243 4253 4259 4261 4271 4273 4283 4289 4297 4327 4337 4339 4349 4357 4363 4373 4391 4397 4409 4421 4423 4441 4447 4451 4457 4463 4481 4483 4493 4507 4513 4517 4519 4523 4547 4549 4561 4567 4583 4591 4597 4603 4621 4637 4639 4643 4649 4651 4657 4663 4673 4679 4691 4703 4721 4723 4729 4733 4751 4759 4783 4787 4789 4793 4799 4801 4813 4817 4831 4861 4871 4877 4889 4903 4909 4919 4931 4933 4937 4943 4951 4957 4967 4969 4973 4987 4993 4999 5003 5009 5011 5021 5023 5039 5051 5059 5077 5081 5087 5099 5101 5107 5113 5119 5147 5153 5167 5171 5179 5189 5197 5209 5227 5231 5233 5237 5261 5273 5279 5281 5297 5303 5309 5323 5333 5347 5351 5381 5387 5393 5399 5407 5413 5417 5419 5431 5437 5441 5443 5449 5471 5477 5479 5483 5501 5503 5507 5519 5521 5527 5531 5557 5563 5569 5573 5581 5591 5623 5639 5641 5647 5651 5653 5657 5659 5669 5683 5689 5693 5701 5711 5717 5737 5741 5743 5749 5779 5783 5791 5801 5807 5813 5821 5827 5839 5843 5849 5851 5857 5861 5867 5869 5879 5881 5897 5903 5923 5927 5939 5953 5981 5987 6007 6011 6029 6037 6043 6047 6053 6067 6073 6079 6089 6091 6101 6113 6121 6131 6133 6143 6151 6163 6173 6197 6199 6203 6211 6217 6221 6229 6247 6257 6263 6269 6271 6277 6287 6299 6301 6311 6317 6323 6329 6337 6343 6353 6359 6361 6367 6373 6379 6389 6397 6421 6427 6449 6451 6469 6473 6481 6491 6521 6529 6547 6551 6553 6563 6569 6571 6577 6581 6599 6607 6619 6637 6653 6659 6661 6673 6679 6689 6691 6701 6703 6709 6719 6733 6737 6761 6763 6779 6781 6791 6793 6803 6823 6827 6829 6833 6841 6857 6863 6869 6871 6883 6899 6907 6911 6917 6947 6949 6959 6961 6967 6971 6977 6983 6991 6997 7001 7013 7019 7027 7039 7043 7057 7069 7079 7103 7109 7121 7127 7129 7151 7159 7177 7187 7193 7207 7211 7213 7219 7229 7237 7243 7247 7253 7283 7297 7307 7309 7321 7331 7333 7349 7351 7369 7393 7411 7417 7433 7451 7457 7459 7477 7481 7487 7489 7499 7507 7517 7523 7529 7537 7541 7547 7549 7559 7561 7573 7577 7583 7589 7591 7603 7607 7621 7639 7643 7649 7669 7673 7681 7687 7691 7699 7703 7717 7723 7727 7741 7753 7757 7759 7789 7793 7817 7823 7829 7841 7853 7867 7873 7877 7879 7883 7901 7907 7919 7927 7933 7937 7949 7951 7963 7993 8009 8011 8017 8039 8053 8059 8069 8081 8087 8089 8093 8101 8111 8117 8123 8147 8161 8167 8171 8179 8191 8209 8219 8221 8231 8233 8237 8243 8263 8269 8273 8287 8291 8293 8297 8311 8317 8329 8353 8363 8369 8377 8387 8389 8419 8423 8429 8431 8443 8447 8461 8467 8501 8513 8521 8527 8537 8539 8543 8563 8573 8581 8597 8599 8609 8623 8627 8629 8641 8647 8663 8669 8677 8681 8689 8693 8699 8707 8713 8719 8731 8737 8741 8747 8753 8761 8779 8783 8803 8807 8819 8821 8831 8837 8839 8849 8861 8863 8867 8887 8893 8923 8929 8933 8941 8951 8963 8969 8971 8999 9001 9007 9011 9013 9029 9041 9043 9049 9059 9067 9091 9103 9109 9127 9133 9137 9151 9157 9161 9173 9181 9187 9199 9203 9209 9221 9227 9239 9241 9257 9277 9281 9283 9293 9311 9319 9323 9337 9341 9343 9349 9371 9377 9391 9397 9403 9413 9419 9421 9431 9433 9437 9439 9461 9463 9467 9473 9479 9491 9497 9511 9521 9533 9539 9547 9551 9587 9601 9613 9619 9623 9629 9631 9643 9649 9661 9677 9679 9689 9697 9719 9721 9733 9739 9743 9749 9767 9769 9781 9787 9791 9803 9811 9817 9829 9833 9839 9851 9857 9859 9871 9883 9887 9901 9907 9923 9929 9931 9941 9949 9967 9973 10007 10009 10037 10039 10061 10067 10069 10079 10091 10093 10099 10103 10111 10133 10139 10141 10151 10159 10163 10169 10177 10181 10193 10211 10223 10243 10247 10253 10259 10267 10271 10273 10289 10301 10303 10313 10321 10331 10333 10337 10343 10357 10369 10391 10399 10427 10429 10433 10453 10457 10459 10463 10477 10487 10499 10501 10513 10529 10531 10559 10567 10589 10597 10601 10607 10613 10627 10631 10639 10651 10657 10663 10667 10687 10691 10709 10711 10723 10729 10733 10739 10753 10771 10781 10789 10799 10831 10837 10847 10853 10859 10861 10867 10883 10889 10891 10903 10909 10937 10939 10949 10957 10973 10979 10987 10993 11003 11027 11047 11057 11059 11069 11071 11083 11087 11093 11113 11117 11119 11131 11149 11159 11161 11171 11173 11177 11197 11213 11239 11243 11251 11257 11261 11273 11279 11287 11299 11311 11317 11321 11329 11351 11353 11369 11383 11393 11399 11411 11423 11437 11443 11447 11467 11471 11483 11489 11491 11497 11503 11519 11527 11549 11551 11579 11587 11593 11597 11617 11621 11633 11657 11677 11681 11689 11699 11701 11717 11719 11731 11743 11777 11779 11783 11789 11801 11807 11813 11821 11827 11831 11833 11839 11863 11867 11887 11897 11903 11909 11923 11927 11933 11939 11941 11953 11959 11969 11971 11981 11987 12007 12011 12037 12041 12043 12049 12071 12073 12097 12101 12107 12109 12113 12119 12143 12149 12157 12161 12163 12197 12203 12211 12227 12239 12241 12251 12253 12263 12269 12277 12281 12289 12301 12323 12329 12343 12347 12373 12377 12379 12391 12401 12409 12413 12421 12433 12437 12451 12457 12473 12479 12487 12491 12497 12503 12511 12517 12527 12539 12541 12547 12553 12569 12577 12583 12589 12601 12611 12613 12619 12637 12641 12647 12653 12659 12671 12689 12697 12703 12713 12721 12739 12743 12757 12763 12781 12791 12799 12809 12821 12823 12829 12841 12853 12889 12893 12899 12907 12911 12917 12919 12923 12941 12953 12959 12967 12973 12979 12983 13001 13003 13007 13009 13033 13037 13043 13049 13063 13093 13099 13103 13109 13121 13127 13147 13151 13159 13163 13171 13177 13183 13187 13217 13219 13229 13241 13249 13259 13267 13291 13297 13309 13313 13327 13331 13337 13339 13367 13381 13397 13399 13411 13417 13421 13441 13451 13457 13463 13469 13477 13487 13499 13513 13523 13537 13553 13567 13577 13591 13597 13613 13619 13627 13633 13649 13669 13679 13681 13687 13691 13693 13697 13709 13711 13721 13723 13729 13751 13757 13759 13763 13781 13789 13799 13807 13829 13831 13841 13859 13873 13877 13879 13883 13901 13903 13907 13913 13921 13931 13933 13963 13967 13997 13999 14009 14011 14029 14033 14051 14057 14071 14081 14083 14087 14107 14143 14149 14153 14159 14173 14177 14197 14207 14221 14243 14249 14251 14281 14293 14303 14321 14323 14327 14341 14347 14369 14387 14389 14401 14407 14411 14419 14423 14431 14437 14447 14449 14461 14479 14489 14503 14519 14533 14537 14543 14549 14551 14557 14561 14563 14591 14593 14621 14627 14629 14633 14639 14653 14657 14669 14683 14699 14713 14717 14723 14731 14737 14741 14747 14753 14759 14767 14771 14779 14783 14797 14813 14821 14827 14831 14843 14851 14867 14869 14879 14887 14891 14897 14923 14929 14939 14947 14951 14957 14969 14983 15013 15017 15031 15053 15061 15073 15077 15083 15091 15101 15107 15121 15131 15137 15139 15149 15161 15173 15187 15193 15199 15217 15227 15233 15241 15259 15263 15269 15271 15277 15287 15289 15299 15307 15313 15319 15329 15331 15349 15359 15361 15373 15377 15383 15391 15401 15413 15427 15439 15443 15451 15461 15467 15473 15493 15497 15511 15527 15541 15551 15559 15569 15581 15583 15601 15607 15619 15629 15641 15643 15647 15649 15661 15667 15671 15679 15683 15727 15731 15733 15737 15739 15749 15761 15767 15773 15787 15791 15797 15803 15809 15817 15823 15859 15877 15881 15887 15889 15901 15907 15913 15919 15923 15937 15959 15971 15973 15991 16001 16007 16033 16057 16061 16063 16067 16069 16073 16087 16091 16097 16103 16111 16127 16139 16141 16183 16187 16189 16193 16217 16223 16229 16231 16249 16253 16267 16273 16301 16319 16333 16339 16349 16361 16363 16369 16381 16411 16417 16421 16427 16433 16447 16451 16453 16477 16481 16487 16493 16519 16529 16547 16553 16561 16567 16573 16603 16607 16619 16631 16633 16649 16651 16657 16661 16673 16691 16693 16699 16703 16729 16741 16747 16759 16763 16787 16811 16823 16829 16831 16843 16871 16879 16883 16889 16901 16903 16921 16927 16931 16937 16943 16963 16979 16981 16987 16993 17011 17021 17027 17029 17033 17041 17047 17053 17077 17093 17099 17107 17117 17123 17137 17159 17167 17183 17189 17191 17203 17207 17209 17231 17239 17257 17291 17293 17299 17317 17321 17327 17333 17341 17351 17359 17377 17383 17387 17389 17393 17401 17417 17419 17431 17443 17449 17467 17471 17477 17483 17489 17491 17497 17509 17519 17539 17551 17569 17573 17579 17581 17597 17599 17609 17623 17627 17657 17659 17669 17681 17683 17707 17713 17729 17737 17747 17749 17761 17783 17789 17791 17807 17827 17837 17839 17851 17863 17881 17891 17903 17909 17911 17921 17923 17929 17939 17957 17959 17971 17977 17981 17987 17989 18013 18041 18043 18047 18049 18059 18061 18077 18089 18097 18119 18121 18127 18131 18133 18143 18149 18169 18181 18191 18199 18211 18217 18223 18229 18233 18251 18253 18257 18269 18287 18289 18301 18307 18311 18313 18329 18341 18353 18367 18371 18379 18397 18401 18413 18427 18433 18439 18443 18451 18457 18461 18481 18493 18503 18517 18521 18523 18539 18541 18553 18583 18587 18593 18617 18637 18661 18671 18679 18691 18701 18713 18719 18731 18743 18749 18757 18773 18787 18793 18797 18803 18839 18859 18869 18899 18911 18913 18917 18919 18947 18959 18973 18979 19001 19009 19013 19031 19037 19051 19069 19073 19079 19081 19087 19121 19139 19141 19157 19163 19181 19183 19207 19211 19213 19219 19231 19237 19249 19259 19267 19273 19289 19301 19309 19319 19333 19373 19379 19381 19387 19391 19403 19417 19421 19423 19427 19429 19433 19441 19447 19457 19463 19469 19471 19477 19483 19489 19501 19507 19531 19541 19543 19553 19559 19571 19577 19583 19597 19603 19609 19661 19681 19687 19697 19699 19709 19717 19727 19739 19751 19753 19759 19763 19777 19793 19801 19813 19819 19841 19843 19853 19861 19867 19889 19891 19913 19919 19927 19937 19949 19961 19963 19973 19979 19991 19993 19997 20011 20021 20023 20029 20047 20051 20063 20071 20089 20101 20107 20113 20117 20123 20129 20143 20147 20149 20161 20173 20177 20183 20201 20219 20231 20233 20249 20261 20269 20287 20297 20323 20327 20333 20341 20347 20353 20357 20359 20369 20389 20393 20399 20407 20411 20431 20441 20443 20477 20479 20483 20507 20509 20521 20533 20543 20549 20551 20563 20593 20599 20611 20627 20639 20641 20663 20681 20693 20707 20717 20719 20731 20743 20747 20749 20753 20759 20771 20773 20789 20807 20809 20849 20857 20873 20879 20887 20897 20899 20903 20921 20929 20939 20947 20959 20963 20981 20983 21001 21011 21013 21017 21019 21023 21031 21059 21061 21067 21089 21101 21107 21121 21139 21143 21149 21157 21163 21169 21179 21187 21191 21193 21211 21221 21227 21247 21269 21277 21283 21313 21317 21319 21323 21341 21347 21377 21379 21383 21391 21397 21401 21407 21419 21433 21467 21481 21487 21491 21493 21499 21503 21517 21521 21523 21529 21557 21559 21563 21569 21577 21587 21589 21599 21601 21611 21613 21617 21647 21649 21661 21673 21683 21701 21713 21727 21737 21739 21751 21757 21767 21773 21787 21799 21803 21817 21821 21839 21841 21851 21859 21863 21871 21881 21893 21911 21929 21937 21943 21961 21977 21991 21997 22003 22013 22027 22031 22037 22039 22051 22063 22067 22073 22079 22091 22093 22109 22111 22123 22129 22133 22147 22153 22157 22159 22171 22189 22193 22229 22247 22259 22271 22273 22277 22279 22283 22291 22303 22307 22343 22349 22367 22369 22381 22391 22397 22409 22433 22441 22447 22453 22469 22481 22483 22501 22511 22531 22541 22543 22549 22567 22571 22573 22613 22619 22621 22637 22639 22643 22651 22669 22679 22691 22697 22699 22709 22717 22721 22727 22739 22741 22751 22769 22777 22783 22787 22807 22811 22817 22853 22859 22861 22871 22877 22901 22907 22921 22937 22943 22961 22963 22973 22993 23003 23011 23017 23021 23027 23029 23039 23041 23053 23057 23059 23063 23071 23081 23087 23099 23117 23131 23143 23159 23167 23173 23189 23197 23201 23203 23209 23227 23251 23269 23279 23291 23293 23297 23311 23321 23327 23333 23339 23357 23369 23371 23399 23417 23431 23447 23459 23473 23497 23509 23531 23537 23539 23549 23557 23561 23563 23567 23581 23593 23599 23603 23609 23623 23627 23629 23633 23663 23669 23671 23677 23687 23689 23719 23741 23743 23747 23753 23761 23767 23773 23789 23801 23813 23819 23827 23831 23833 23857 23869 23873 23879 23887 23893 23899 23909 23911 23917 23929 23957 23971 23977 23981 23993 24001 24007 24019 24023 24029 24043 24049 24061 24071 24077 24083 24091 24097 24103 24107 24109 24113 24121 24133 24137 24151 24169 24179 24181 24197 24203 24223 24229 24239 24247 24251 24281 24317 24329 24337 24359 24371 24373 24379 24391 24407 24413 24419 24421 24439 24443 24469 24473 24481 24499 24509 24517 24527 24533 24547 24551 24571 24593 24611 24623 24631 24659 24671 24677 24683 24691 24697 24709 24733 24749 24763 24767 24781 24793 24799 24809 24821 24841 24847 24851 24859 24877 24889 24907 24917 24919 24923 24943 24953 24967 24971 24977 24979 24989 25013 25031 25033 25037 25057 25073 25087 25097 25111 25117 25121 25127 25147 25153 25163 25169 25171 25183 25189 25219 25229 25237 25243 25247 25253 25261 25301 25303 25307 25309 25321 25339 25343 25349 25357 25367 25373 25391 25409 25411 25423 25439 25447 25453 25457 25463 25469 25471 25523 25537 25541 25561 25577 25579 25583 25589 25601 25603 25609 25621 25633 25639 25643 25657 25667 25673 25679 25693 25703 25717 25733 25741 25747 25759 25763 25771 25793 25799 25801 25819 25841 25847 25849 25867 25873 25889 25903 25913 25919 25931 25933 25939 25943 25951 25969 25981 25997 25999 26003 26017 26021 26029 26041 26053 26083 26099 26107 26111 26113 26119 26141 26153 26161 26171 26177 26183 26189 26203 26209 26227 26237 26249 26251 26261 26263 26267 26293 26297 26309 26317 26321 26339 26347 26357 26371 26387 26393 26399 26407 26417 26423 26431 26437 26449 26459 26479 26489 26497 26501 26513 26539 26557 26561 26573 26591 26597 26627 26633 26641 26647 26669 26681 26683 26687 26693 26699 26701 26711 26713 26717 26723 26729 26731 26737 26759 26777 26783 26801 26813 26821 26833 26839 26849 26861 26863 26879 26881 26891 26893 26903 26921 26927 26947 26951 26953 26959 26981 26987 26993 27011 27017 27031 27043 27059 27061 27067 27073 27077 27091 27103 27107 27109 27127 27143 27179 27191 27197 27211 27239 27241 27253 27259 27271 27277 27281 27283 27299 27329 27337 27361 27367 27397 27407 27409 27427 27431 27437 27449 27457 27479 27481 27487 27509 27527 27529 27539 27541 27551 27581 27583 27611 27617 27631 27647 27653 27673 27689 27691 27697 27701 27733 27737 27739 27743 27749 27751 27763 27767 27773 27779 27791 27793 27799 27803 27809 27817 27823 27827 27847 27851 27883 27893 27901 27917 27919 27941 27943 27947 27953 27961 27967 27983 27997 28001 28019 28027 28031 28051 28057 28069 28081 28087 28097 28099 28109 28111 28123 28151 28163 28181 28183 28201 28211 28219 28229 28277 28279 28283 28289 28297 28307 28309 28319 28349 28351 28387 28393 28403 28409 28411 28429 28433 28439 28447 28463 28477 28493 28499 28513 28517 28537 28541 28547 28549 28559 28571 28573 28579 28591 28597 28603 28607 28619 28621 28627 28631 28643 28649 28657 28661 28663 28669 28687 28697 28703 28711 28723 28729 28751 28753 28759 28771 28789 28793 28807 28813 28817 28837 28843 28859 28867 28871 28879 28901 28909 28921 28927 28933 28949 28961 28979 29009 29017 29021 29023 29027 29033 29059 29063 29077 29101 29123 29129 29131 29137 29147 29153 29167 29173 29179 29191 29201 29207 29209 29221 29231 29243 29251 29269 29287 29297 29303 29311 29327 29333 29339 29347 29363 29383 29387 29389 29399 29401 29411 29423 29429 29437 29443 29453 29473 29483 29501 29527 29531 29537 29567 29569 29573 29581 29587 29599 29611 29629 29633 29641 29663 29669 29671 29683 29717 29723 29741 29753 29759 29761 29789 29803 29819 29833 29837 29851 29863 29867 29873 29879 29881 29917 29921 29927 29947 29959 29983 29989 30011 30013 30029 30047 30059 30071 30089 30091 30097 30103 30109 30113 30119 30133 30137 30139 30161 30169 30181 30187 30197 30203 30211 30223 30241 30253 30259 30269 30271 30293 30307 30313 30319 30323 30341 30347 30367 30389 30391 30403 30427 30431 30449 30467 30469 30491 30493 30497 30509 30517 30529 30539 30553 30557 30559 30577 30593 30631 30637 30643 30649 30661 30671 30677 30689 30697 30703 30707 30713 30727 30757 30763 30773 30781 30803 30809 30817 30829 30839 30841 30851 30853 30859 30869 30871 30881 30893 30911 30931 30937 30941 30949 30971 30977 30983 31013 31019 31033 31039 31051 31063 31069 31079 31081 31091 31121 31123 31139 31147 31151 31153 31159 31177 31181 31183 31189 31193 31219 31223 31231 31237 31247 31249 31253 31259 31267 31271 31277 31307 31319 31321 31327 31333 31337 31357 31379 31387 31391 31393 31397 31469 31477 31481 31489 31511 31513 31517 31531 31541 31543 31547 31567 31573 31583 31601 31607 31627 31643 31649 31657 31663 31667 31687 31699 31721 31723 31727 31729 31741 31751 31769 31771 31793 31799 31817 31847 31849 31859 31873 31883 31891 31907 31957 31963 31973 31981 31991 32003 32009 32027 32029 32051 32057 32059 32063 32069 32077 32083 32089 32099 32117 32119 32141 32143 32159 32173 32183 32189 32191 32203 32213 32233 32237 32251 32257 32261 32297 32299 32303 32309 32321 32323 32327 32341 32353 32359 32363 32369 32371 32377 32381 32401 32411 32413 32423 32429 32441 32443 32467 32479 32491 32497 32503 32507 32531 32533 32537 32561 32563 32569 32573 32579 32587 32603 32609 32611 32621 32633 32647 32653 32687 32693 32707 32713 32717 32719 32749 32771 32779 32783 32789 32797 32801 32803 32831 32833 32839 32843 32869 32887 32909 32911 32917 32933 32939 32941 32957 32969 32971 32983 32987 32993 32999 33013 33023 33029 33037 33049 33053 33071 33073 33083 33091 33107 33113 33119 33149 33151 33161 33179 33181 33191 33199 33203 33211 33223 33247 33287 33289 33301 33311 33317 33329 33331 33343 33347 33349 33353 33359 33377 33391 33403 33409 33413 33427 33457 33461 33469 33479 33487 33493 33503 33521 33529 33533 33547 33563 33569 33577 33581 33587 33589 33599 33601 33613 33617 33619 33623 33629 33637 33641 33647 33679 33703 33713 33721 33739 33749 33751 33757 33767 33769 33773 33791 33797 33809 33811 33827 33829 33851 33857 33863 33871 33889 33893 33911 33923 33931 33937 33941 33961 33967 33997 34019 34031 34033 34039 34057 34061 34123 34127 34129 34141 34147 34157 34159 34171 34183 34211 34213 34217 34231 34253 34259 34261 34267 34273 34283 34297 34301 34303 34313 34319 34327 34337 34351 34361 34367 34369 34381 34403 34421 34429 34439 34457 34469 34471 34483 34487 34499 34501 34511 34513 34519 34537 34543 34549 34583 34589 34591 34603 34607 34613 34631 34649 34651 34667 34673 34679 34687 34693 34703 34721 34729 34739 34747 34757 34759 34763 34781 34807 34819 34841 34843 34847 34849 34871 34877 34883 34897 34913 34919 34939 34949 34961 34963 34981 35023 35027 35051 35053 35059 35069 35081 35083 35089 35099 35107 35111 35117 35129 35141 35149 35153 35159 35171 35201 35221 35227 35251 35257 35267 35279 35281 35291 35311 35317 35323 35327 35339 35353 35363 35381 35393 35401 35407 35419 35423 35437 35447 35449 35461 35491 35507 35509 35521 35527 35531 35533 35537 35543 35569 35573 35591 35593 35597 35603 35617 35671 35677 35729 35731 35747 35753 35759 35771 35797 35801 35803 35809 35831 35837 35839 35851 35863 35869 35879 35897 35899 35911 35923 35933 35951 35963 35969 35977 35983 35993 35999 36007 36011 36013 36017 36037 36061 36067 36073 36083 36097 36107 36109 36131 36137 36151 36161 36187 36191 36209 36217 36229 36241 36251 36263 36269 36277 36293 36299 36307 36313 36319 36341 36343 36353 36373 36383 36389 36433 36451 36457 36467 36469 36473 36479 36493 36497 36523 36527 36529 36541 36551 36559 36563 36571 36583 36587 36599 36607 36629 36637 36643 36653 36671 36677 36683 36691 36697 36709 36713 36721 36739 36749 36761 36767 36779 36781 36787 36791 36793 36809 36821 36833 36847 36857 36871 36877 36887 36899 36901 36913 36919 36923 36929 36931 36943 36947 36973 36979 36997 37003 37013 37019 37021 37039 37049 37057 37061 37087 37097 37117 37123 37139 37159 37171 37181 37189 37199 37201 37217 37223 37243 37253 37273 37277 37307 37309 37313 37321 37337 37339 37357 37361 37363 37369 37379 37397 37409 37423 37441 37447 37463 37483 37489 37493 37501 37507 37511 37517 37529 37537 37547 37549 37561 37567 37571 37573 37579 37589 37591 37607 37619 37633 37643 37649 37657 37663 37691 37693 37699 37717 37747 37781 37783 37799 37811 37813 37831 37847 37853 37861 37871 37879 37889 37897 37907 37951 37957 37963 37967 37987 37991 37993 37997 38011 38039 38047 38053 38069 38083 38113 38119 38149 38153 38167 38177 38183 38189 38197 38201 38219 38231 38237 38239 38261 38273 38281 38287 38299 38303 38317 38321 38327 38329 38333 38351 38371 38377 38393 38431 38447 38449 38453 38459 38461 38501 38543 38557 38561 38567 38569 38593 38603 38609 38611 38629 38639 38651 38653 38669 38671 38677 38693 38699 38707 38711 38713 38723 38729 38737 38747 38749 38767 38783 38791 38803 38821 38833 38839 38851 38861 38867 38873 38891 38903 38917 38921 38923 38933 38953 38959 38971 38977 38993 39019 39023 39041 39043 39047 39079 39089 39097 39103 39107 39113 39119 39133 39139 39157 39161 39163 39181 39191 39199 39209 39217 39227 39229 39233 39239 39241 39251 39293 39301 39313 39317 39323 39341 39343 39359 39367 39371 39373 39383 39397 39409 39419 39439 39443 39451 39461 39499 39503 39509 39511 39521 39541 39551 39563 39569 39581 39607 39619 39623 39631 39659 39667 39671 39679 39703 39709 39719 39727 39733 39749 39761 39769 39779 39791 39799 39821 39827 39829 39839 39841 39847 39857 39863 39869 39877 39883 39887 39901 39929 39937 39953 39971 39979 39983 39989 40009 40013 40031 40037 40039 40063 40087 40093 40099 40111 40123 40127 40129 40151 40153 40163 40169 40177 40189 40193 40213 40231 40237 40241 40253 40277 40283 40289 40343 40351 40357 40361 40387 40423 40427 40429 40433 40459 40471 40483 40487 40493 40499 40507 40519 40529 40531 40543 40559 40577 40583 40591 40597 40609 40627 40637 40639 40693 40697 40699 40709 40739 40751 40759 40763 40771 40787 40801 40813 40819 40823 40829 40841 40847 40849 40853 40867 40879 40883 40897 40903 40927 40933 40939 40949 40961 40973 40993 41011 41017 41023 41039 41047 41051 41057 41077 41081 41113 41117 41131 41141 41143 41149 41161 41177 41179 41183 41189 41201 41203 41213 41221 41227 41231 41233 41243 41257 41263 41269 41281 41299 41333 41341 41351 41357 41381 41387 41389 41399 41411 41413 41443 41453 41467 41479 41491 41507 41513 41519 41521 41539 41543 41549 41579 41593 41597 41603 41609 41611 41617 41621 41627 41641 41647 41651 41659 41669 41681 41687 41719 41729 41737 41759 41761 41771 41777 41801 41809 41813 41843 41849 41851 41863 41879 41887 41893 41897 41903 41911 41927 41941 41947 41953 41957 41959 41969 41981 41983 41999 42013 42017 42019 42023 42043 42061 42071 42073 42083 42089 42101 42131 42139 42157 42169 42179 42181 42187 42193 42197 42209 42221 42223 42227 42239 42257 42281 42283 42293 42299 42307 42323 42331 42337 42349 42359 42373 42379 42391 42397 42403 42407 42409 42433 42437 42443 42451 42457 42461 42463 42467 42473 42487 42491 42499 42509 42533 42557 42569 42571 42577 42589 42611 42641 42643 42649 42667 42677 42683 42689 42697 42701 42703 42709 42719 42727 42737 42743 42751 42767 42773 42787 42793 42797 42821 42829 42839 42841 42853 42859 42863 42899 42901 42923 42929 42937 42943 42953 42961 42967 42979 42989 43003 43013 43019 43037 43049 43051 43063 43067 43093 43103 43117 43133 43151 43159 43177 43189 43201 43207 43223 43237 43261 43271 43283 43291 43313 43319 43321 43331 43391 43397 43399 43403 43411 43427 43441 43451 43457 43481 43487 43499 43517 43541 43543 43573 43577 43579 43591 43597 43607 43609 43613 43627 43633 43649 43651 43661 43669 43691 43711 43717 43721 43753 43759 43777 43781 43783 43787 43789 43793 43801 43853 43867 43889 43891 43913 43933 43943 43951 43961 43963 43969 43973 43987 43991 43997 44017 44021 44027 44029 44041 44053 44059 44071 44087 44089 44101 44111 44119 44123 44129 44131 44159 44171 44179 44189 44201 44203 44207 44221 44249 44257 44263 44267 44269 44273 44279 44281 44293 44351 44357 44371 44381 44383 44389 44417 44449 44453 44483 44491 44497 44501 44507 44519 44531 44533 44537 44543 44549 44563 44579 44587 44617 44621 44623 44633 44641 44647 44651 44657 44683 44687 44699 44701 44711 44729 44741 44753 44771 44773 44777 44789 44797 44809 44819 44839 44843 44851 44867 44879 44887 44893 44909 44917 44927 44939 44953 44959 44963 44971 44983 44987 45007 45013 45053 45061 45077 45083 45119 45121 45127 45131 45137 45139 45161 45179 45181 45191 45197 45233 45247 45259 45263 45281 45289 45293 45307 45317 45319 45329 45337 45341 45343 45361 45377 45389 45403 45413 45427 45433 45439 45481 45491 45497 45503 45523 45533 45541 45553 45557 45569 45587 45589 45599 45613 45631 45641 45659 45667 45673 45677 45691 45697 45707 45737 45751 45757 45763 45767 45779 45817 45821 45823 45827 45833 45841 45853 45863 45869 45887 45893 45943 45949 45953 45959 45971 45979 45989 46021 46027 46049 46051 46061 46073 46091 46093 46099 46103 46133 46141 46147 46153 46171 46181 46183 46187 46199 46219 46229 46237 46261 46271 46273 46279 46301 46307 46309 46327 46337 46349 46351 46381 46399 46411 46439 46441 46447 46451 46457 46471 46477 46489 46499 46507 46511 46523 46549 46559 46567 46573 46589 46591 46601 46619 46633 46639 46643 46649 46663 46679 46681 46687 46691 46703 46723 46727 46747 46751 46757 46769 46771 46807 46811 46817 46819 46829 46831 46853 46861 46867 46877 46889 46901 46919 46933 46957 46993 46997 47017 47041 47051 47057 47059 47087 47093 47111 47119 47123 47129 47137 47143 47147 47149 47161 47189 47207 47221 47237 47251 47269 47279 47287 47293 47297 47303 47309 47317 47339 47351 47353 47363 47381 47387 47389 47407 47417 47419 47431 47441 47459 47491 47497 47501 47507 47513 47521 47527 47533 47543 47563 47569 47581 47591 47599 47609 47623 47629 47639 47653 47657 47659 47681 47699 47701 47711 47713 47717 47737 47741 47743 47777 47779 47791 47797 47807 47809 47819 47837 47843 47857 47869 47881 47903 47911 47917 47933 47939 47947 47951 47963 47969 47977 47981 48017 48023 48029 48049 48073 48079 48091 48109 48119 48121 48131 48157 48163 48179 48187 48193 48197 48221 48239 48247 48259 48271 48281 48299 48311 48313 48337 48341 48353 48371 48383 48397 48407 48409 48413 48437 48449 48463 48473 48479 48481 48487 48491 48497 48523 48527 48533 48539 48541 48563 48571 48589 48593 48611 48619 48623 48647 48649 48661 48673 48677 48679 48731 48733 48751 48757 48761 48767 48779 48781 48787 48799 48809 48817 48821 48823 48847 48857 48859 48869 48871 48883 48889 48907 48947 48953 48973 48989 48991 49003 49009 49019 49031 49033 49037 49043 49057 49069 49081 49103 49109 49117 49121 49123 49139 49157 49169 49171 49177 49193 49199 49201 49207 49211 49223 49253 49261 49277 49279 49297 49307 49331 49333 49339 49363 49367 49369 49391 49393 49409 49411 49417 49429 49433 49451 49459 49463 49477 49481 49499 49523 49529 49531 49537 49547 49549 49559 49597 49603 49613 49627 49633 49639 49663 49667 49669 49681 49697 49711 49727 49739 49741 49747 49757 49783 49787 49789 49801 49807 49811 49823 49831 49843 49853 49871 49877 49891 49919 49921 49927 49937 49939 49943 49957 49991 49993 49999 50021 50023 50033 50047 50051 50053 50069 50077 50087 50093 50101 50111 50119 50123 50129 50131 50147 50153 50159 50177 50207 50221 50227 50231 50261 50263 50273 50287 50291 50311 50321 50329 50333 50341 50359 50363 50377 50383 50387 50411 50417 50423 50441 50459 50461 50497 50503 50513 50527 50539 50543 50549 50551 50581 50587 50591 50593 50599 50627 50647 50651 50671 50683 50707 50723 50741 50753 50767 50773 50777 50789 50821 50833 50839 50849 50857 50867 50873 50891 50893 50909 50923 50929 50951 50957 50969 50971 50989 50993 51001 51031 51043 51047 51059 51061 51071 51109 51131 51133 51137 51151 51157 51169 51193 51197 51199 51203 51217 51229 51239 51241 51257 51263 51283 51287 51307 51329 51341 51343 51347 51349 51361 51383 51407 51413 51419 51421 51427 51431 51437 51439 51449 51461 51473 51479 51481 51487 51503 51511 51517 51521 51539 51551 51563 51577 51581 51593 51599 51607 51613 51631 51637 51647 51659 51673 51679 51683 51691 51713 51719 51721 51749 51767 51769 51787 51797 51803 51817 51827 51829 51839 51853 51859 51869 51871 51893 51899 51907 51913 51929 51941 51949 51971 51973 51977 51991 52009 52021 52027 52051 52057 52067 52069 52081 52103 52121 52127 52147 52153 52163 52177 52181 52183 52189 52201 52223 52237 52249 52253 52259 52267 52289 52291 52301 52313 52321 52361 52363 52369 52379 52387 52391 52433 52453 52457 52489 52501 52511 52517 52529 52541 52543 52553 52561 52567 52571 52579 52583 52609 52627 52631 52639 52667 52673 52691 52697 52709 52711 52721 52727 52733 52747 52757 52769 52783 52807 52813 52817 52837 52859 52861 52879 52883 52889 52901 52903 52919 52937 52951 52957 52963 52967 52973 52981 52999 53003 53017 53047 53051 53069 53077 53087 53089 53093 53101 53113 53117 53129 53147 53149 53161 53171 53173 53189 53197 53201 53231 53233 53239 53267 53269 53279 53281 53299 53309 53323 53327 53353 53359 53377 53381 53401 53407 53411 53419 53437 53441 53453 53479 53503 53507 53527 53549 53551 53569 53591 53593 53597 53609 53611 53617 53623 53629 53633 53639 53653 53657 53681 53693 53699 53717 53719 53731 53759 53773 53777 53783 53791 53813 53819 53831 53849 53857 53861 53881 53887 53891 53897 53899 53917 53923 53927 53939 53951 53959 53987 53993 54001 54011 54013 54037 54049 54059 54083 54091 54101 54121 54133 54139 54151 54163 54167 54181 54193 54217 54251 54269 54277 54287 54293 54311 54319 54323 54331 54347 54361 54367 54371 54377 54401 54403 54409 54413 54419 54421 54437 54443 54449 54469 54493 54497 54499 54503 54517 54521 54539 54541 54547 54559 54563 54577 54581 54583 54601 54617 54623 54629 54631 54647 54667 54673 54679 54709 54713 54721 54727 54751 54767 54773 54779 54787 54799 54829 54833 54851 54869 54877 54881 54907 54917 54919 54941 54949 54959 54973 54979 54983 55001 55009 55021 55049 55051 55057 55061 55073 55079 55103 55109 55117 55127 55147 55163 55171 55201 55207 55213 55217 55219 55229 55243 55249 55259 55291 55313 55331 55333 55337 55339 55343 55351 55373 55381 55399 55411 55439 55441 55457 55469 55487 55501 55511 55529 55541 55547 55579 55589 55603 55609 55619 55621 55631 55633 55639 55661 55663 55667 55673 55681 55691 55697 55711 55717 55721 55733 55763 55787 55793 55799 55807 55813 55817 55819 55823 55829 55837 55843 55849 55871 55889 55897 55901 55903 55921 55927 55931 55933 55949 55967 55987 55997 56003 56009 56039 56041 56053 56081 56087 56093 56099 56101 56113 56123 56131 56149 56167 56171 56179 56197 56207 56209 56237 56239 56249 56263 56267 56269 56299 56311 56333 56359 56369 56377 56383 56393 56401 56417 56431 56437 56443 56453 56467 56473 56477 56479 56489 56501 56503 56509 56519 56527 56531 56533 56543 56569 56591 56597 56599 56611 56629 56633 56659 56663 56671 56681 56687 56701 56711 56713 56731 56737 56747 56767 56773 56779 56783 56807 56809 56813 56821 56827 56843 56857 56873 56891 56893 56897 56909 56911 56921 56923 56929 56941 56951 56957 56963 56983 56989 56993 56999 57037 57041 57047 57059 57073 57077 57089 57097 57107 57119 57131 57139 57143 57149 57163 57173 57179 57191 57193 57203 57221 57223 57241 57251 57259 57269 57271 57283 57287 57301 57329 57331 57347 57349 57367 57373 57383 57389 57397 57413 57427 57457 57467 57487 57493 57503 57527 57529 57557 57559 57571 57587 57593 57601 57637 57641 57649 57653 57667 57679 57689 57697 57709 57713 57719 57727 57731 57737 57751 57773 57781 57787 57791 57793 57803 57809 57829 57839 57847 57853 57859 57881 57899 57901 57917 57923 57943 57947 57973 57977 57991 58013 58027 58031 58043 58049 58057 58061 58067 58073 58099 58109 58111 58129 58147 58151 58153 58169 58171 58189 58193 58199 58207 58211 58217 58229 58231 58237 58243 58271 58309 58313 58321 58337 58363 58367 58369 58379 58391 58393 58403 58411 58417 58427 58439 58441 58451 58453 58477 58481 58511 58537 58543 58549 58567 58573 58579 58601 58603 58613 58631 58657 58661 58679 58687 58693 58699 58711 58727 58733 58741 58757 58763 58771 58787 58789 58831 58889 58897 58901 58907 58909 58913 58921 58937 58943 58963 58967 58979 58991 58997 59009 59011 59021 59023 59029 59051 59053 59063 59069 59077 59083 59093 59107 59113 59119 59123 59141 59149 59159 59167 59183 59197 59207 59209 59219 59221 59233 59239 59243 59263 59273 59281 59333 59341 59351 59357 59359 59369 59377 59387 59393 59399 59407 59417 59419 59441 59443 59447 59453 59467 59471 59473 59497 59509 59513 59539 59557 59561 59567 59581 59611 59617 59621 59627 59629 59651 59659 59663 59669 59671 59693 59699 59707 59723 59729 59743 59747 59753 59771 59779 59791 59797 59809 59833 59863 59879 59887 59921 59929 59951 59957 59971 59981 59999 60013 60017 60029 60037 60041 60077 60083 60089 60091 60101 60103 60107 60127 60133 60139 60149 60161 60167 60169 60209 60217 60223 60251 60257 60259 60271 60289 60293 60317 60331 60337 60343 60353 60373 60383 60397 60413 60427 60443 60449 60457 60493 60497 60509 60521 60527 60539 60589 60601 60607 60611 60617 60623 60631 60637 60647 60649 60659 60661 60679 60689 60703 60719 60727 60733 60737 60757 60761 60763 60773 60779 60793 60811 60821 60859 60869 60887 60889 60899 60901 60913 60917 60919 60923 60937 60943 60953 60961 61001 61007 61027 61031 61043 61051 61057 61091 61099 61121 61129 61141 61151 61153 61169 61211 61223 61231 61253 61261 61283 61291 61297 61331 61333 61339 61343 61357 61363 61379 61381 61403 61409 61417 61441 61463 61469 61471 61483 61487 61493 61507 61511 61519 61543 61547 61553 61559 61561 61583 61603 61609 61613 61627 61631 61637 61643 61651 61657 61667 61673 61681 61687 61703 61717 61723 61729 61751 61757 61781 61813 61819 61837 61843 61861 61871 61879 61909 61927 61933 61949 61961 61967 61979 61981 61987 61991 62003 62011 62017 62039 62047 62053 62057 62071 62081 62099 62119 62129 62131 62137 62141 62143 62171 62189 62191 62201 62207 62213 62219 62233 62273 62297 62299 62303 62311 62323 62327 62347 62351 62383 62401 62417 62423 62459 62467 62473 62477 62483 62497 62501 62507 62533 62539 62549 62563 62581 62591 62597 62603 62617 62627 62633 62639 62653 62659 62683 62687 62701 62723 62731 62743 62753 62761 62773 62791 62801 62819 62827 62851 62861 62869 62873 62897 62903 62921 62927 62929 62939 62969 62971 62981 62983 62987 62989 63029 63031 63059 63067 63073 63079 63097 63103 63113 63127 63131 63149 63179 63197 63199 63211 63241 63247 63277 63281 63299 63311 63313 63317 63331 63337 63347 63353 63361 63367 63377 63389 63391 63397 63409 63419 63421 63439 63443 63463 63467 63473 63487 63493 63499 63521 63527 63533 63541 63559 63577 63587 63589 63599 63601 63607 63611 63617 63629 63647 63649 63659 63667 63671 63689 63691 63697 63703 63709 63719 63727 63737 63743 63761 63773 63781 63793 63799 63803 63809 63823 63839 63841 63853 63857 63863 63901 63907 63913 63929 63949 63977 63997 64007 64013 64019 64033 64037 64063 64067 64081 64091 64109 64123 64151 64153 64157 64171 64187 64189 64217 64223 64231 64237 64271 64279 64283 64301 64303 64319 64327 64333 64373 64381 64399 64403 64433 64439 64451 64453 64483 64489 64499 64513 64553 64567 64577 64579 64591 64601 64609 64613 64621 64627 64633 64661 64663 64667 64679 64693 64709 64717 64747 64763 64781 64783 64793 64811 64817 64849 64853 64871 64877 64879 64891 64901 64919 64921 64927 64937 64951 64969 64997 65003 65011 65027 65029 65033 65053 65063 65071 65089 65099 65101 65111 65119 65123 65129 65141 65147 65167 65171 65173 65179 65183 65203 65213 65239 65257 65267 65269 65287 65293 65309 65323 65327 65353 65357 65371 65381 65393 65407 65413 65419 65423 65437 65447 65449 65479 65497 65519 65521 65537 65539 65543 65551 65557 65563 65579 65581 65587 65599 65609 65617 65629 65633 65647 65651 65657 65677 65687 65699 65701 65707 65713 65717 65719 65729 65731 65761 65777 65789 65809 65827 65831 65837 65839 65843 65851 65867 65881 65899 65921 65927 65929 65951 65957 65963 65981 65983 65993 66029 66037 66041 66047 66067 66071 66083 66089 66103 66107 66109 66137 66161 66169 66173 66179 66191 66221 66239 66271 66293 66301 66337 66343 66347 66359 66361 66373 66377 66383 66403 66413 66431 66449 66457 66463 66467 66491 66499 66509 66523 66529 66533 66541 66553 66569 66571 66587 66593 66601 66617 66629 66643 66653 66683 66697 66701 66713 66721 66733 66739 66749 66751 66763 66791 66797 66809 66821 66841 66851 66853 66863 66877 66883 66889 66919 66923 66931 66943 66947 66949 66959 66973 66977 67003 67021 67033 67043 67049 67057 67061 67073 67079 67103 67121 67129 67139 67141 67153 67157 67169 67181 67187 67189 67211 67213 67217 67219 67231 67247 67261 67271 67273 67289 67307 67339 67343 67349 67369 67391 67399 67409 67411 67421 67427 67429 67433 67447 67453 67477 67481 67489 67493 67499 67511 67523 67531 67537 67547 67559 67567 67577 67579 67589 67601 67607 67619 67631 67651 67679 67699 67709 67723 67733 67741 67751 67757 67759 67763 67777 67783 67789 67801 67807 67819 67829 67843 67853 67867 67883 67891 67901 67927 67931 67933 67939 67943 67957 67961 67967 67979 67987 67993 68023 68041 68053 68059 68071 68087 68099 68111 68113 68141 68147 68161 68171 68207 68209 68213 68219 68227 68239 68261 68279 68281 68311 68329 68351 68371 68389 68399 68437 68443 68447 68449 68473 68477 68483 68489 68491 68501 68507 68521 68531 68539 68543 68567 68581 68597 68611 68633 68639 68659 68669 68683 68687 68699 68711 68713 68729 68737 68743 68749 68767 68771 68777 68791 68813 68819 68821 68863 68879 68881 68891 68897 68899 68903 68909 68917 68927 68947 68963 68993 69001 69011 69019 69029 69031 69061 69067 69073 69109 69119 69127 69143 69149 69151 69163 69191 69193 69197 69203 69221 69233 69239 69247 69257 69259 69263 69313 69317 69337 69341 69371 69379 69383 69389 69401 69403 69427 69431 69439 69457 69463 69467 69473 69481 69491 69493 69497 69499 69539 69557 69593 69623 69653 69661 69677 69691 69697 69709 69737 69739 69761 69763 69767 69779 69809 69821 69827 69829 69833 69847 69857 69859 69877 69899 69911 69929 69931 69941 69959 69991 69997 70001 70003 70009 70019 70039 70051 70061 70067 70079 70099 70111 70117 70121 70123 70139 70141 70157 70163 70177 70181 70183 70199 70201 70207 70223 70229 70237 70241 70249 70271 70289 70297 70309 70313 70321 70327 70351 70373 70379 70381 70393 70423 70429 70439 70451 70457 70459 70481 70487 70489 70501 70507 70529 70537 70549 70571 70573 70583 70589 70607 70619 70621 70627 70639 70657 70663 70667 70687 70709 70717 70729 70753 70769 70783 70793 70823 70841 70843 70849 70853 70867 70877 70879 70891 70901 70913 70919 70921 70937 70949 70951 70957 70969 70979 70981 70991 70997 70999 71011 71023 71039 71059 71069 71081 71089 71119 71129 71143 71147 71153 71161 71167 71171 71191 71209 71233 71237 71249 71257 71261 71263 71287 71293 71317 71327 71329 71333 71339 71341 71347 71353 71359 71363 71387 71389 71399 71411 71413 71419 71429 71437 71443 71453 71471 71473 71479 71483 71503 71527 71537 71549 71551 71563 71569 71593 71597 71633 71647 71663 71671 71693 71699 71707 71711 71713 71719 71741 71761 71777 71789 71807 71809 71821 71837 71843 71849 71861 71867 71879 71881 71887 71899 71909 71917 71933 71941 71947 71963 71971 71983 71987 71993 71999 72019 72031 72043 72047 72053 72073 72077 72089 72091 72101 72103 72109 72139 72161 72167 72169 72173 72211 72221 72223 72227 72229 72251 72253 72269 72271 72277 72287 72307 72313 72337 72341 72353 72367 72379 72383 72421 72431 72461 72467 72469 72481 72493 72497 72503 72533 72547 72551 72559 72577 72613 72617 72623 72643 72647 72649 72661 72671 72673 72679 72689 72701 72707 72719 72727 72733 72739 72763 72767 72797 72817 72823 72859 72869 72871 72883 72889 72893 72901 72907 72911 72923 72931 72937 72949 72953 72959 72973 72977 72997 73009 73013 73019 73037 73039 73043 73061 73063 73079 73091 73121 73127 73133 73141 73181 73189 73237 73243 73259 73277 73291 73303 73309 73327 73331 73351 73361 73363 73369 73379 73387 73417 73421 73433 73453 73459 73471 73477 73483 73517 73523 73529 73547 73553 73561 73571 73583 73589 73597 73607 73609 73613 73637 73643 73651 73673 73679 73681 73693 73699 73709 73721 73727 73751 73757 73771 73783 73819 73823 73847 73849 73859 73867 73877 73883 73897 73907 73939 73943 73951 73961 73973 73999 74017 74021 74027 74047 74051 74071 74077 74093 74099 74101 74131 74143 74149 74159 74161 74167 74177 74189 74197 74201 74203 74209 74219 74231 74257 74279 74287 74293 74297 74311 74317 74323 74353 74357 74363 74377 74381 74383 74411 74413 74419 74441 74449 74453 74471 74489 74507 74509 74521 74527 74531 74551 74561 74567 74573 74587 74597 74609 74611 74623 74653 74687 74699 74707 74713 74717 74719 74729 74731 74747 74759 74761 74771 74779 74797 74821 74827 74831 74843 74857 74861 74869 74873 74887 74891 74897 74903 74923 74929 74933 74941 74959 75011 75013 75017 75029 75037 75041 75079 75083 75109 75133 75149 75161 75167 75169 75181 75193 75209 75211 75217 75223 75227 75239 75253 75269 75277 75289 75307 75323 75329 75337 75347 75353 75367 75377 75389 75391 75401 75403 75407 75431 75437 75479 75503 75511 75521 75527 75533 75539 75541 75553 75557 75571 75577 75583 75611 75617 75619 75629 75641 75653 75659 75679 75683 75689 75703 75707 75709 75721 75731 75743 75767 75773 75781 75787 75793 75797 75821 75833 75853 75869 75883 75913 75931 75937 75941 75967 75979 75983 75989 75991 75997 76001 76003 76031 76039 76079 76081 76091 76099 76103 76123 76129 76147 76157 76159 76163 76207 76213 76231 76243 76249 76253 76259 76261 76283 76289 76303 76333 76343 76367 76369 76379 76387 76403 76421 76423 76441 76463 76471 76481 76487 76493 76507 76511 76519 76537 76541 76543 76561 76579 76597 76603 76607 76631 76649 76651 76667 76673 76679 76697 76717 76733 76753 76757 76771 76777 76781 76801 76819 76829 76831 76837 76847 76871 76873 76883 76907 76913 76919 76943 76949 76961 76963 76991 77003 77017 77023 77029 77041 77047 77069 77081 77093 77101 77137 77141 77153 77167 77171 77191 77201 77213 77237 77239 77243 77249 77261 77263 77267 77269 77279 77291 77317 77323 77339 77347 77351 77359 77369 77377 77383 77417 77419 77431 77447 77471 77477 77479 77489 77491 77509 77513 77521 77527 77543 77549 77551 77557 77563 77569 77573 77587 77591 77611 77617 77621 77641 77647 77659 77681 77687 77689 77699 77711 77713 77719 77723 77731 77743 77747 77761 77773 77783 77797 77801 77813 77839 77849 77863 77867 77893 77899 77929 77933 77951 77969 77977 77983 77999 78007 78017 78031 78041 78049 78059 78079 78101 78121 78137 78139 78157 78163 78167 78173 78179 78191 78193 78203 78229 78233 78241 78259 78277 78283 78301 78307 78311 78317 78341 78347 78367 78401 78427 78437 78439 78467 78479 78487 78497 78509 78511 78517 78539 78541 78553 78569 78571 78577 78583 78593 78607 78623 78643 78649 78653 78691 78697 78707 78713 78721 78737 78779 78781 78787 78791 78797 78803 78809 78823 78839 78853 78857 78877 78887 78889 78893 78901 78919 78929 78941 78977 78979 78989 79031 79039 79043 79063 79087 79103 79111 79133 79139 79147 79151 79153 79159 79181 79187 79193 79201 79229 79231 79241 79259 79273 79279 79283 79301 79309 79319 79333 79337 79349 79357 79367 79379 79393 79397 79399 79411 79423 79427 79433 79451 79481 79493 79531 79537 79549 79559 79561 79579 79589 79601 79609 79613 79621 79627 79631 79633 79657 79669 79687 79691 79693 79697 79699 79757 79769 79777 79801 79811 79813 79817 79823 79829 79841 79843 79847 79861 79867 79873 79889 79901 79903 79907 79939 79943 79967 79973 79979 79987 79997 79999 80021 80039 80051 80071 80077 80107 80111 80141 80147 80149 80153 80167 80173 80177 80191 80207 80209 80221 80231 80233 80239 80251 80263 80273 80279 80287 80309 80317 80329 80341 80347 80363 80369 80387 80407 80429 80447 80449 80471 80473 80489 80491 80513 80527 80537 80557 80567 80599 80603 80611 80621 80627 80629 80651 80657 80669 80671 80677 80681 80683 80687 80701 80713 80737 80747 80749 80761 80777 80779 80783 80789 80803 80809 80819 80831 80833 80849 80863 80897 80909 80911 80917 80923 80929 80933 80953 80963 80989 81001 81013 81017 81019 81023 81031 81041 81043 81047 81049 81071 81077 81083 81097 81101 81119 81131 81157 81163 81173 81181 81197 81199 81203 81223 81233 81239 81281 81283 81293 81299 81307 81331 81343 81349 81353 81359 81371 81373 81401 81409 81421 81439 81457 81463 81509 81517 81527 81533 81547 81551 81553 81559 81563 81569 81611 81619 81629 81637 81647 81649 81667 81671 81677 81689 81701 81703 81707 81727 81737 81749 81761 81769 81773 81799 81817 81839 81847 81853 81869 81883 81899 81901 81919 81929 81931 81937 81943 81953 81967 81971 81973 82003 82007 82009 82013 82021 82031 82037 82039 82051 82067 82073 82129 82139 82141 82153 82163 82171 82183 82189 82193 82207 82217 82219 82223 82231 82237 82241 82261 82267 82279 82301 82307 82339 82349 82351 82361 82373 82387 82393 82421 82457 82463 82469 82471 82483 82487 82493 82499 82507 82529 82531 82549 82559 82561 82567 82571 82591 82601 82609 82613 82619 82633 82651 82657 82699 82721 82723 82727 82729 82757 82759 82763 82781 82787 82793 82799 82811 82813 82837 82847 82883 82889 82891 82903 82913 82939 82963 82981 82997 83003 83009 83023 83047 83059 83063 83071 83077 83089 83093 83101 83117 83137 83177 83203 83207 83219 83221 83227 83231 83233 83243 83257 83267 83269 83273 83299 83311 83339 83341 83357 83383 83389 83399 83401 83407 83417 83423 83431 83437 83443 83449 83459 83471 83477 83497 83537 83557 83561 83563 83579 83591 83597 83609 83617 83621 83639 83641 83653 83663 83689 83701 83717 83719 83737 83761 83773 83777 83791 83813 83833 83843 83857 83869 83873 83891 83903 83911 83921 83933 83939 83969 83983 83987 84011 84017 84047 84053 84059 84061 84067 84089 84121 84127 84131 84137 84143 84163 84179 84181 84191 84199 84211 84221 84223 84229 84239 84247 84263 84299 84307 84313 84317 84319 84347 84349 84377 84389 84391 84401 84407 84421 84431 84437 84443 84449 84457 84463 84467 84481 84499 84503 84509 84521 84523 84533 84551 84559 84589 84629 84631 84649 84653 84659 84673 84691 84697 84701 84713 84719 84731 84737 84751 84761 84787 84793 84809 84811 84827 84857 84859 84869 84871 84913 84919 84947 84961 84967 84977 84979 84991 85009 85021 85027 85037 85049 85061 85081 85087 85091 85093 85103 85109 85121 85133 85147 85159 85193 85199 85201 85213 85223 85229 85237 85243 85247 85259 85297 85303 85313 85331 85333 85361 85363 85369 85381 85411 85427 85429 85439 85447 85451 85453 85469 85487 85513 85517 85523 85531 85549 85571 85577 85597 85601 85607 85619 85621 85627 85639 85643 85661 85667 85669 85691 85703 85711 85717 85733 85751 85781 85793 85817 85819 85829 85831 85837 85843 85847 85853 85889 85903 85909 85931 85933 85991 85999 86011 86017 86027 86029 86069 86077 86083 86111 86113 86117 86131 86137 86143 86161 86171 86179 86183 86197 86201 86209 86239 86243 86249 86257 86263 86269 86287 86291 86293 86297 86311 86323 86341 86351 86353 86357 86369 86371 86381 86389 86399 86413 86423 86441 86453 86461 86467 86477 86491 86501 86509 86531 86533 86539 86561 86573 86579 86587 86599 86627 86629 86677 86689 86693 86711 86719 86729 86743 86753 86767 86771 86783 86813 86837 86843 86851 86857 86861 86869 86923 86927 86929 86939 86951 86959 86969 86981 86993 87011 87013 87037 87041 87049 87071 87083 87103 87107 87119 87121 87133 87149 87151 87179 87181 87187 87211 87221 87223 87251 87253 87257 87277 87281 87293 87299 87313 87317 87323 87337 87359 87383 87403 87407 87421 87427 87433 87443 87473 87481 87491 87509 87511 87517 87523 87539 87541 87547 87553 87557 87559 87583 87587 87589 87613 87623 87629 87631 87641 87643 87649 87671 87679 87683 87691 87697 87701 87719 87721 87739 87743 87751 87767 87793 87797 87803 87811 87833 87853 87869 87877 87881 87887 87911 87917 87931 87943 87959 87961 87973 87977 87991 88001 88003 88007 88019 88037 88069 88079 88093 88117 88129 88169 88177 88211 88223 88237 88241 88259 88261 88289 88301 88321 88327 88337 88339 88379 88397 88411 88423 88427 88463 88469 88471 88493 88499 88513 88523 88547 88589 88591 88607 88609 88643 88651 88657 88661 88663 88667 88681 88721 88729 88741 88747 88771 88789 88793 88799 88801 88807 88811 88813 88817 88819 88843 88853 88861 88867 88873 88883 88897 88903 88919 88937 88951 88969 88993 88997 89003 89009 89017 89021 89041 89051 89057 89069 89071 89083 89087 89101 89107 89113 89119 89123 89137 89153 89189 89203 89209 89213 89227 89231 89237 89261 89269 89273 89293 89303 89317 89329 89363 89371 89381 89387 89393 89399 89413 89417 89431 89443 89449 89459 89477 89491 89501 89513 89519 89521 89527 89533 89561 89563 89567 89591 89597 89599 89603 89611 89627 89633 89653 89657 89659 89669 89671 89681 89689 89753 89759 89767 89779 89783 89797 89809 89819 89821 89833 89839 89849 89867 89891 89897 89899 89909 89917 89923 89939 89959 89963 89977 89983 89989 90001 90007 90011 90017 90019 90023 90031 90053 90059 90067 90071 90073 90089 90107 90121 90127 90149 90163 90173 90187 90191 90197 90199 90203 90217 90227 90239 90247 90263 90271 90281 90289 90313 90353 90359 90371 90373 90379 90397 90401 90403 90407 90437 90439 90469 90473 90481 90499 90511 90523 90527 90529 90533 90547 90583 90599 90617 90619 90631 90641 90647 90659 90677 90679 90697 90703 90709 90731 90749 90787 90793 90803 90821 90823 90833 90841 90847 90863 90887 90901 90907 90911 90917 90931 90947 90971 90977 90989 90997 91009 91019 91033 91079 91081 91097 91099 91121 91127 91129 91139 91141 91151 91153 91159 91163 91183 91193 91199 91229 91237 91243 91249 91253 91283 91291 91297 91303 91309 91331 91367 91369 91373 91381 91387 91393 91397 91411 91423 91433 91453 91457 91459 91463 91493 91499 91513 91529 91541 91571 91573 91577 91583 91591 91621 91631 91639 91673 91691 91703 91711 91733 91753 91757 91771 91781 91801 91807 91811 91813 91823 91837 91841 91867 91873 91909 91921 91939 91943 91951 91957 91961 91967 91969 91997 92003 92009 92033 92041 92051 92077 92083 92107 92111 92119 92143 92153 92173 92177 92179 92189 92203 92219 92221 92227 92233 92237 92243 92251 92269 92297 92311 92317 92333 92347 92353 92357 92363 92369 92377 92381 92383 92387 92399 92401 92413 92419 92431 92459 92461 92467 92479 92489 92503 92507 92551 92557 92567 92569 92581 92593 92623 92627 92639 92641 92647 92657 92669 92671 92681 92683 92693 92699 92707 92717 92723 92737 92753 92761 92767 92779 92789 92791 92801 92809 92821 92831 92849 92857 92861 92863 92867 92893 92899 92921 92927 92941 92951 92957 92959 92987 92993 93001 93047 93053 93059 93077 93083 93089 93097 93103 93113 93131 93133 93139 93151 93169 93179 93187 93199 93229 93239 93241 93251 93253 93257 93263 93281 93283 93287 93307 93319 93323 93329 93337 93371 93377 93383 93407 93419 93427 93463 93479 93481 93487 93491 93493 93497 93503 93523 93529 93553 93557 93559 93563 93581 93601 93607 93629 93637 93683 93701 93703 93719 93739 93761 93763 93787 93809 93811 93827 93851 93871 93887 93889 93893 93901 93911 93913 93923 93937 93941 93949 93967 93971 93979 93983 93997 94007 94009 94033 94049 94057 94063 94079 94099 94109 94111 94117 94121 94151 94153 94169 94201 94207 94219 94229 94253 94261 94273 94291 94307 94309 94321 94327 94331 94343 94349 94351 94379 94397 94399 94421 94427 94433 94439 94441 94447 94463 94477 94483 94513 94529 94531 94541 94543 94547 94559 94561 94573 94583 94597 94603 94613 94621 94649 94651 94687 94693 94709 94723 94727 94747 94771 94777 94781 94789 94793 94811 94819 94823 94837 94841 94847 94849 94873 94889 94903 94907 94933 94949 94951 94961 94993 94999 95003 95009 95021 95027 95063 95071 95083 95087 95089 95093 95101 95107 95111 95131 95143 95153 95177 95189 95191 95203 95213 95219 95231 95233 95239 95257 95261 95267 95273 95279 95287 95311 95317 95327 95339 95369 95383 95393 95401 95413 95419 95429 95441 95443 95461 95467 95471 95479 95483 95507 95527 95531 95539 95549 95561 95569 95581 95597 95603 95617 95621 95629 95633 95651 95701 95707 95713 95717 95723 95731 95737 95747 95773 95783 95789 95791 95801 95803 95813 95819 95857 95869 95873 95881 95891 95911 95917 95923 95929 95947 95957 95959 95971 95987 95989 96001 96013 96017 96043 96053 96059 96079 96097 96137 96149 96157 96167 96179 96181 96199 96211 96221 96223 96233 96259 96263 96269 96281 96289 96293 96323 96329 96331 96337 96353 96377 96401 96419 96431 96443 96451 96457 96461 96469 96479 96487 96493 96497 96517 96527 96553 96557 96581 96587 96589 96601 96643 96661 96667 96671 96697 96703 96731 96737 96739 96749 96757 96763 96769 96779 96787 96797 96799 96821 96823 96827 96847 96851 96857 96893 96907 96911 96931 96953 96959 96973 96979 96989 96997 97001 97003 97007 97021 97039 97073 97081 97103 97117 97127 97151 97157 97159 97169 97171 97177 97187 97213 97231 97241 97259 97283 97301 97303 97327 97367 97369 97373 97379 97381 97387 97397 97423 97429 97441 97453 97459 97463 97499 97501 97511 97523 97547 97549 97553 97561 97571 97577 97579 97583 97607 97609 97613 97649 97651 97673 97687 97711 97729 97771 97777 97787 97789 97813 97829 97841 97843 97847 97849 97859 97861 97871 97879 97883 97919 97927 97931 97943 97961 97967 97973 97987 98009 98011 98017 98041 98047 98057 98081 98101 98123 98129 98143 98179 98207 98213 98221 98227 98251 98257 98269 98297 98299 98317 98321 98323 98327 98347 98369 98377 98387 98389 98407 98411 98419 98429 98443 98453 98459 98467 98473 98479 98491 98507 98519 98533 98543 98561 98563 98573 98597 98621 98627 98639 98641 98663 98669 98689 98711 98713 98717 98729 98731 98737 98773 98779 98801 98807 98809 98837 98849 98867 98869 98873 98887 98893 98897 98899 98909 98911 98927 98929 98939 98947 98953 98963 98981 98993 98999 99013 99017 99023 99041 99053 99079 99083 99089 99103 99109 99119 99131 99133 99137 99139 99149 99173 99181 99191 99223 99233 99241 99251 99257 99259 99277 99289 99317 99347 99349 99367 99371 99377 99391 99397 99401 99409 99431 99439 99469 99487 99497 99523 99527 99529 99551 99559 99563 99571 99577 99581 99607 99611 99623 99643 99661 99667 99679 99689 99707 99709 99713 99719 99721 99733 99761 99767 99787 99793 99809 99817 99823 99829 99833 99839 99859 99871 99877 99881 99901 99907 99923 99929 99961 99971 99989 99991 100003 100019 100043 100049 100057 100069 100103 100109 100129 100151 100153 100169 100183 100189 100193 100207 100213 100237 100267 100271 100279 100291 100297 100313 100333 100343 100357 100361 100363 100379 100391 100393 100403 100411 100417 100447 100459 100469 100483 100493 100501 100511 100517 100519 100523 100537 100547 100549 100559 100591 100609 100613 100621 100649 100669 100673 100693 100699 100703 100733 100741 100747 100769 100787 100799 100801 100811 100823 100829 100847 100853 100907 100913 100927 100931 100937 100943 100957 100981 100987 100999 101009 101021 101027 101051 101063 101081 101089 101107 101111 101113 101117 101119 101141 101149 101159 101161 101173 101183 101197 101203 101207 101209 101221 101267 101273 101279 101281 101287 101293 101323 101333 101341 101347 101359 101363 101377 101383 101399 101411 101419 101429 101449 101467 101477 101483 101489 101501 101503 101513 101527 101531 101533 101537 101561 101573 101581 101599 101603 101611 101627 101641 101653 101663 101681 101693 101701 101719 101723 101737 101741 101747 101749 101771 101789 101797 101807 101833 101837 101839 101863 101869 101873 101879 101891 101917 101921 101929 101939 101957 101963 101977 101987 101999 102001 102013 102019 102023 102031 102043 102059 102061 102071 102077 102079 102101 102103 102107 102121 102139 102149 102161 102181 102191 102197 102199 102203 102217 102229 102233 102241 102251 102253 102259 102293 102299 102301 102317 102329 102337 102359 102367 102397 102407 102409 102433 102437 102451 102461 102481 102497 102499 102503 102523 102533 102539 102547 102551 102559 102563 102587 102593 102607 102611 102643 102647 102653 102667 102673 102677 102679 102701 102761 102763 102769 102793 102797 102811 102829 102841 102859 102871 102877 102881 102911 102913 102929 102931 102953 102967 102983 103001 103007 103043 103049 103067 103069 103079 103087 103091 103093 103099 103123 103141 103171 103177 103183 103217 103231 103237 103289 103291 103307 103319 103333 103349 103357 103387 103391 103393 103399 103409 103421 103423 103451 103457 103471 103483 103511 103529 103549 103553 103561 103567 103573 103577 103583 103591 103613 103619 103643 103651 103657 103669 103681 103687 103699 103703 103723 103769 103787 103801 103811 103813 103837 103841 103843 103867 103889 103903 103913 103919 103951 103963 103967 103969 103979 103981 103991 103993 103997 104003 104009 104021 104033 104047 104053 104059 104087 104089 104107 104113 104119 104123 104147 104149 104161 104173 104179 104183 104207 104231 104233 104239 104243 104281 104287 104297 104309 104311 104323 104327 104347 104369 104381 104383 104393 104399 104417 104459 104471 104473 104479 104491 104513 104527 104537 104543 104549 104551 104561 104579 104593 104597 104623 104639 104651 104659 104677 104681 104683 104693 104701 104707 104711 104717 104723 104729\n","id":2339,"permalink":"https://freshrimpsushi.github.io/en/posts/2339/","tags":null,"title":"List of decimals to the 10,000th"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code While the original sushi restaurant with fresh shrimp includes detailed explanations, Julia wants to omit explanations on purpose to emphasize how easy it is to do parallel processing.\nusing Base.Threads\rfor i in 1:10\rprintln(i^2)\rend If you want to parallelize the above loop, you just need to prepend @threads to the for loop.\n@threads for i in 1:10\rprintln(i^2)\rend However, if I must add one piece of advice, it is that not everything gets faster with parallel processing. Proper use of parallel processing can yield very high performance, but just because it\u0026rsquo;s easier to write code doesn\u0026rsquo;t mean optimization is easy as well. Take your time to measure and pay attention to the execution time.\nEnvironment OS: Windows julia: v1.5.0 ","id":1474,"permalink":"https://freshrimpsushi.github.io/en/posts/1474/","tags":null,"title":"How to Parallel Process in Julia"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":"Generalization of Vectors Linear Algebra might be a new concept for science students who haven\u0026rsquo;t studied it yet. To them, a vector refers to a physical quantity with magnitude and direction, representing a point in 3-dimensional space, often denoted as $\\vec{x} = (x_{1}, x_{2}, x_{3})$. This definition is sufficient for studying classical mechanics and electromagnetism. However, in quantum mechanics, concepts like Fourier Analysis, Inner Product of Functions emerge, making it essential to understand the generalized definition of vectors to avoid significant difficulties in studying.\nIn linear algebra, a vector is an abstraction of the intuitive concept of vectors. Entities that have the same properties as 3-dimensional space vectors are collectively referred to as vectors, and the set of these vectors is called a vector space. These properties are the ones that we naturally associate with points in 3-dimensional space. For instance:\nThe sum of two vectors is also a vector. A vector multiplied by a scalar is also a vector. Therefore, a point in 3-dimensional space qualifies as a vector, and the 3-dimensional space itself becomes a vector space. Below are two critical examples in quantum mechanics. Both matrices and functions can be vectors.\nExamples Matrices Consider a set of matrices of size $m \\times n$. Adding two such matrices still results in an $m \\times n$ matrix, and multiplying a matrix by any scalar yields an $m \\times n$ matrix. Hence, this set forms a vector space, and each matrix is considered a vector.\nRealizing that there\u0026rsquo;s essentially no difference between representing a vector as an ordered pair $\\mathbf{x} = (x_{1}, x_{2}, x_{3})$ and representing it as a $1 \\times 3$ matrix $\\mathbf{x} = \\begin{bmatrix} x_{1} \u0026amp; x_{2} \u0026amp; x_{3} \\end{bmatrix}$ might make the concept of matrices being vectors more intuitive.\nFunctions Consider the set of continuous functions. If $f$ and $g$ are continuous functions, their sum $f+g$ is also a continuous function. Similarly, multiplying any continuous function by a scalar, $cf$, results in another continuous function. Therefore, the set of continuous functions forms a vector space, and each continuous function within is a vector.\nIn fact, recalling the notation for vector functions, where the function values are 3-dimensional vectors, can help in understanding this concept.\n$$ f(x,y,z) = (xy, yz, z^{2}) $$\nGeneralization of Inner Product The inner product is an operation that is extremely useful when dealing with vectors. Just as we generalized the concept of vectors, let\u0026rsquo;s generalize the concept of inner products. Instead of using the dot $\\cdot$ for traditional inner products, we use angle brackets $\\left\\langle \\ ,\\ \\right\\rangle$. If $\\mathbf{x} = \\left( x_{1}, x_{2}, x_{3} \\right)$ and $\\mathbf{y}=\\left( y_{1}, y_{2}, y_{3} \\right)$, we represent the inner product as follows:\n$$ \\mathbf{x} \\cdot \\mathbf{y} = x_{1}y_{1} + x_{2}y_{2} + x_{3}y_{3} = \\left\\langle \\mathbf{x}, \\mathbf{y} \\right\\rangle $$\nIn quantum mechanics, instead of a comma, a bar $|$ is used in the middle.\n$$ \\mathbf{x} \\cdot \\mathbf{y} = \\braket{\\mathbf{x} \\vert \\mathbf{y} } $$\nThis is referred to as Dirac Notation. The essence of generalizing vectors lies in the concept that anything satisfying the \u0026lsquo;properties we attribute to vectors\u0026rsquo; can be called a vector, regardless of what it is. The same applies to the generalization of inner products; the concept of \u0026lsquo;adding up the product of each corresponding component\u0026rsquo; is maintained. Depending on the vector space being dealt with, the definition of inner product can vary as follows:\nExamples Matrices Consider two matrices $A = \\begin{pmatrix} a_{11} \u0026amp; a_{12} \\ a_{21} \u0026amp; a_{22} \\end{pmatrix}, B = \\begin{pmatrix} b_{11} \u0026amp; b_{12} \\ b_{21} \u0026amp; b_{22} \\end{pmatrix}$. Their inner product is defined as the \u0026lsquo;sum of the products of corresponding components\u0026rsquo;, just like the inner product of 3-dimensional vectors.\n$$ \\braket{ A \\vert B } = a_{11}b_{11} + a_{12}b_{12} + a_{21}b_{21} + a_{22}b_{22} $$\nFunctions Since we have established that functions are also vectors, we can define the inner product of two functions. The inner product of functions is defined as follows, using definite integration:\n$$ \\braket{\\psi \\vert \\phi} = \\int \\psi^{\\ast}(x) \\phi (x) dx $$\nHere, $\\psi^{\\ast}$ represents the complex conjugate of $\\psi. Be mindful of the notation ambiguity. The reasons for defining the inner product of functions this way are well explained in 'Why the Inner Product of Functions is Defined Using Definite Integration'.\nWave Functions in Quantum Mechanics In quantum mechanics, a wave function represents the state of a particle with respect to position and time and is typically expressed using exponential functions.\n$$ \\psi (x,t) = e^{i(kx + \\omega t)} $$\nThey are commonly denoted by $\\psi$ and $\\phi$, pronounced as [psi] and [phi], respectively. $k$ is the wave number, satisfying the relationship with momentum, $p = \\hbar k$. Here, $\\hbar$ is a constant, so $k$ can be considered equivalent to momentum in quantum mechanics. $\\omega$ is the angular frequency, satisfying the energy relationship, $E = \\hbar \\omega$.\nHilbert Space The rigorous definition of a Hilbert Space is a 'complete inner product space'. While understanding its mathematical significance is beneficial, it\u0026rsquo;s not essential for undergraduate physics students studying quantum mechanics. The important thing to note is that a collection with very favorable properties is named Hilbert Space and that the set of wave functions constitutes a Hilbert Space. This means various excellent mathematical tools can be utilized to handle wave functions.\n","id":1509,"permalink":"https://freshrimpsushi.github.io/en/posts/1509/","tags":null,"title":"Vector, Inner Product, Wave Function, Hilbert Space in Quantum Mechanics"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition For a linear transformation $A \\in \\mathbb{R}^{m \\times m}$, the image $AN$ of a $m$-dimensional unit sphere $N := \\left\\{ \\mathbb{x} \\in \\mathbb{R}^{m} : \\left\\| \\mathbb{x} \\right\\|_{2} = 1 \\right\\}$ is called an ellipsoid. The eigenvalues $\\sigma_{1}^{2} \u0026gt; \\cdots \\ge \\sigma_{m}^{2} \\ge 0$ of $A$ and the corresponding unit eigenvectors $u_{1} , \\cdots , u_{m}$ are referred to as the axes of the ellipsoid for $\\sigma_{i} u_{i}$.\nExplanation A $m$-dimensional unit sphere consists of points that are centered at $\\mathbb{0} \\in \\mathbb{R}^{m}$ with radius $1$. When $m=2$, it becomes the well-known unit circle.\nAn ellipsoid is also called an ellipsoidal body or hyperellipse. Rather than saying the terms ellipsoidal surface or ellipsoidal sphere are incorrect, it‚Äôs more insightful to grasp the definition based on the context being read. In some contexts, an ellipsoid refers to a fully solid object, whereas in others it may refer only to the outer shell.\nGeometry If one is sufficiently familiar with linear transformations, it can be easily understood why this is referred to as an extension of an ellipse into higher dimensions. Intuitively, one can imagine flattening a unit sphere along one axis by applying $A = \\begin{bmatrix} 2 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{bmatrix}$. This happens as solutions to the equation of a circle $N : x^{2} + y^{2} = 1$ are transformed through $A$ into solutions for $\\displaystyle AN : {{ x^{2} } \\over { 2 }} + y^{2} = 1$. Since the eigenvalues of $A$ are $\\sqrt{2}^{2} , \\sqrt{1}^{2}$, it is evident that the axes of ellipsoid $AN$ are naturally $\\sqrt{2}(1,0)$ and $\\sqrt{1}(0,1)$.\nLinear Algebra The reason for explicitly referring to eigenvalues as $\\sigma_{i}^{2}$ when discussing ellipsoids is due to their close relationship with singular value decomposition (SVD). Singular value decomposition is a method that finds some $\\sigma_{i}\u0026gt;0$, $v_{i} \\in \\mathbb{R}^{n}$, and $u_{i} \\in \\mathbb{R}^{m}$ satisfying\n$$ A v_{i} = \\sigma_{i} u_{i} $$\nfor $A \\in \\mathbb{R}^{m \\times n}$. As proved in the existence of singular value decomposition, $\\sigma_{i}^{2}$ are the eigenvalues for $A^{T}A$, and the unit eigenvectors $u_{1} , \\cdots , u_{m}$ are mutually independent. From this perspective, referring to $\\sigma_{i} u_{i}$ as axes is a natural definition.\nGeneralization As can be understood from the linear algebraic explanation, the concept of ellipsoids can also be generalized for $A \\in \\mathbb{R}^{m \\times n}$. However, from the reader\u0026rsquo;s perspective, understanding the relationship between singular values and eigenvalues might be challenging, and the geometric meaning becomes significantly weakened. Therefore, an introduction to the definition concerning $A \\in \\mathbb{R}^{m \\times m}$ was necessary. If one successfully grasps this abstract definition, they could accept a more general definition of ellipsoids concerning the rank $r = \\dim C (A)$ of $A$ set to $\\sigma_{r+1} = \\cdots = \\sigma_{m} = 0$. However, in this broader context, $\\sigma_{i}^{2}$ can no longer be referred to as the eigenvalues of $A$, and talking about singular value decomposition, one would only have ‚Äúsome positive number $\\sigma_{i}\u0026gt;0$‚Äù to mention.\n","id":1471,"permalink":"https://freshrimpsushi.github.io/en/posts/1471/","tags":null,"title":"Generalization of the Ellipse: Ellipsoid"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 For $\\nu \\in \\mathbb{R}$, a differential equation of the following form is called a $\\nu$ order Bessel equation.\n$$ \\begin{align*} \u0026amp;\u0026amp; x^{2} y^{\\prime \\prime} +xy^{\\prime}+(x^{2}-\\nu^{2})y \u0026amp;= 0 \\\\ \\text{or} \u0026amp;\u0026amp; y^{\\prime \\prime}+\\frac{1}{x} y^{\\prime} + \\left( 1-\\frac{\\nu^{2}}{x^{2}} \\right)y \u0026amp;= 0 \\end{align*} $$\nExplanation The Bessel equation emerges when solving the wave equation in spherical coordinates. The coefficients are not constant but depend on the independent variable $x$. Since, at $x=0$, the following equation is satisfied, $x=0$ is a regular singular point.\n$$ \\lim \\limits_{x\\rightarrow 0} x \\frac{x}{x^{2}}=1\u0026lt;\\infty,\\quad \\lim\\limits_{x\\rightarrow 0}x^{2}\\frac{x^{2}-\\nu^{2}}{x^{2}}=-\\nu^{2} \u0026lt; \\infty $$\nTherefore, the solution can be found using the Frobenius method, and the series solution is as follows.\n$$ \\begin{align*} J_{\\nu}(x) \u0026amp;= \\sum \\limits_{n=0}^{\\infty} \\frac{(-1)^{n} }{\\Gamma (n+1) \\Gamma (n+\\nu+1)} \\left(\\frac{x}{2} \\right)^{2n+\\nu} \\\\ J_{-\\nu}(x) \u0026amp; =\\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}}{\\Gamma (n+1)\\Gamma (n-\\nu+1)} \\left( \\frac{x}{2} \\right)^{2n-\\nu} \\end{align*} $$\nThis is called the Bessel function of the first kind of order nu. Here, $\\Gamma (x)$ is the gamma function. By looking at the order of both series, we can see that they are linearly independent. Therefore, the general solution to the $\\nu$ order Bessel equation is as follows.\n$$ y(x)=AJ_{\\nu}(x)+BJ_{-\\nu}(x) $$\nHowever, this only applies when $\\nu$ is not an integer. If $\\nu$ is an integer, since $J_{\\nu}$ and $J_{-\\nu}$ are not independent, we need to find the second solution, also known as the Neumann function.\nSolution Let\u0026rsquo;s assume the solution to the Bessel equation is the following power series.\n$$ \\begin{equation} y=\\sum \\limits_{n=0}^{\\infty}a_{n}x^{n+r}=x^{r}(a_{0}+a_{1}x+a_{2}x^{2}+\\cdots)=a_{0}x^{r}+a_{1}x^{r+1}+a_{2}x^{r+2}+\\cdots \\label{1} \\end{equation} $$\nFirst, let\u0026rsquo;s slightly modify the form of the Bessel equation. Since $x(xy^{\\prime})^{\\prime}=x^{2}y^{\\prime \\prime}+xy^{\\prime}$, the Bessel equation can be expressed as follows.\n$$ x(xy^{\\prime})+(x^{2}-\\nu^{2})y=0 $$\nTo substitute into the Bessel equation, let\u0026rsquo;s find $x(xy^{\\prime})^{\\prime}, x^{2}y$ from $\\eqref{1}$, as follows.\n$$ \\begin{align*} y^{\\prime} \u0026amp;=ra_{0}x^{r-1}+(r+1)a_{1}x^{r}+(r+2)a_{2}x^{r+1}+\\cdots \\\\ xy^{\\prime}\u0026amp;=ra_{0}x^{r}+(r+1)a_{1}x^{r+1}+(r+2)a_{2}x^{r+2}+\\cdots \\\\ (xy^{\\prime})^{\\prime}\u0026amp;=r^{2}a_{0}x^{r-1}+(r+1)^{2}a_{1}x^{r}+(r+2)^{2}a_{2}x^{r+1}+\\cdots \\\\ x(xy^{\\prime})^{\\prime}\u0026amp;=r^{2}a_{0}x^{r}+(r+1)^{2}a_{1}x^{r+1}+(r+2)^{2}a_{2}x^{r+2}+\\cdots \\\\ \u0026amp;= \\sum \\limits_{n=0}^{\\infty} a_{n}(r+n)^{2}x^{n+r} \\end{align*} $$\nSubstituting this into the Bessel equation yields the following.\n$$ \\begin{align*} \u0026amp;\u0026amp;\u0026amp;\\left( r^{2}a_{0}x^{r}+(r+1)^{2}a_{1}x^{r+1}+(r+2)^{2}a_{2}x^{r+2}+\\cdots \\right) +(x^{2}-\\nu^{2})\\left( a_{0}x^{r}+a_{1}x^{r+1}+a_{2}x^{r+2}+\\cdots \\right) \\\\ \\implies\u0026amp;\u0026amp;\u0026amp; \\left( r^{2}a_{0}x^{r}+(r+1)^{2}a_{1}x^{r+1}+(r+2)^{2}a_{2}x^{r+2}+\\cdots \\right) +\\left( a_{0}x^{r+2}+a_{1}x^{r+3}+a_{2}x^{r+4}+\\cdots \\right) \\\\ \u0026amp;\u0026amp;\u0026amp;+ \\left( -\\nu^{2}a_{0}x^{r}-\\nu^{2}a_{1}x^{r+1}-\\nu^{2}a_{2}x^{r+2}+\\cdots \\right) \\end{align*} $$\nRearranging this to match the order of $x$,\n$$ \\begin{align*} a_{0}(r^{2}-\\nu^{2})x^{r}+a_{1}\\left( (r+1)^{2}-\\nu^{2} \\right)x^{r+1} +\\left(a_{2}(r+2)^{2}-a_{2}\\nu^{2} +a_{0} \\right)x^{r+2}\u0026amp; \\\\ +\\cdots + (a_{n}(r+n)^{2}-a_{n}\\nu^{2}+a_{n-2})x^{n+r}+\\cdots \u0026amp;= 0 \\end{align*} $$\nFor the equation to always hold for any $x$, all coefficients must be $0$. Let\u0026rsquo;s examine the first term.\n$$ a_{0}(r^{2}-\\nu^{2})=0 $$\nSince $a_{0}\\ne 0$, we have $r=\\pm\\nu$. Now, let\u0026rsquo;s look at the second term.\n$$ a_{1}\\left( (r+1)^{2}-\\nu^{2} \\right)=0 $$\nGiven the condition that $r=\\pm \\nu$, the expression inside the parentheses can never be $0$. Therefore, $a_{1}=0$. From the third term onwards, the coefficient is generally expressed as follows.\n$$ a_{n}(r+n)^{2}-a_{n}\\nu^{2}+a_{n-2}=0 $$\nArranging this,\n$$ \\begin{equation} a_{n}=\\frac{-a_{n-2}}{(r+n)^{2}-\\nu^{2}} \\label{2} \\end{equation} $$\nCombining the previously obtained $a_{1}=0$ with the above condition, one can see that for all odd $n$, $a_{n}=0$ applies. Therefore, we only need to derive when $n$ is even.\nCase 1. $r=\\nu$\nIn this case, $\\eqref{2}$ is\n$$ a_{n}=\\frac{- a_{n-2}}{n^{2}+2n\\nu}=\\frac{-a_{n-2}}{n(n+2\\nu)} $$\nSince we are only interested in when $n$ is even, let\u0026rsquo;s denote $n$ as $2n$. Then,\n$$ a_{2n}=\\frac{-a_{2n-2}}{2n(2n+2\\nu)}=\\frac{-a_{2n-2}}{2^{2}n(n+\\nu)} $$\nNow, starting from $a_{2}$, we can derive as follows.\n$$ \\begin{align*} a_{2} \u0026amp; =\\frac{-a_{0}}{2^{2}\\cdot 1(\\nu+1)} \\\\ a_{4} \u0026amp;= \\frac{-a_{2}}{2^{2}\\cdot 2(\\nu+2)}=\\frac{a_{0}}{2^{4}\\cdot2\\cdot1(\\nu+1)(\\nu+2)} \\\\ a_{6} \u0026amp;=\\frac{-a_{4}}{2^{2}\\cdot3 (\\nu+3)}=\\frac{-a_{0}}{2^{6}\\cdot3\\cdot2\\cdot1(\\nu+1)(\\nu+2)(\\nu+3)} \\\\ \\vdots \\\\ a_{2n}\u0026amp;=\\frac{(-1)^{n}a_{0}}{2^{2n}n!(\\nu+1)(\\nu+2)\\cdots(\\nu+n)} \\end{align*} $$ Using the gamma function simplifies the expression. The gamma function has the following properties.\n$$ \\Gamma (\\nu+1)=\\nu\\Gamma (\\nu) \\implies \\dfrac{1}{\\nu} = \\dfrac{\\Gamma (\\nu)}{\\Gamma (\\nu+1)} $$\nUsing this, we obtain the following.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\frac{1}{\\nu+1}\u0026amp;=\\frac{\\Gamma (\\nu+1)}{\\Gamma (\\nu+2)}\u0026amp; \\\\ \\implies \u0026amp;\u0026amp; \\frac{1}{(\\nu+1)(\\nu+2)}\u0026amp;=\\frac{\\Gamma (\\nu+1)}{(\\nu+2)\\Gamma (\\nu+2)}=\\frac{\\Gamma (\\nu+1)}{\\Gamma (\\nu+3)} \\\\ \\implies \u0026amp;\u0026amp; \\frac{1}{(\\nu+1)(\\nu+2)(\\nu+3)}\u0026amp;=\\frac{\\Gamma (\\nu+1)}{(\\nu+3)\\Gamma (\\nu+3)} =\\frac{\\Gamma (\\nu+1)}{\\Gamma (\\nu+4)} \\\\ \\implies \u0026amp;\u0026amp; \u0026amp;\\vdots \\\\ \\implies \u0026amp;\u0026amp; \\frac{1}{(\\nu+1)\\cdots(\\nu+n)}\u0026amp;=\\frac{\\Gamma (\\nu+1)}{\\Gamma (\\nu+n+1)} \\end{align*} $$\nSubstituting this back into the coefficients we derived earlier, and expressing the factorial as a gamma function, each coefficient becomes as follows.\n$$ \\begin{align*} a_{2} \u0026amp; =\\frac{-a_{0}\\Gamma (\\nu +1)}{2^{2} 1! \\Gamma (\\nu+2)} \\\\ a_{4} \u0026amp;= \\frac{a_{0} \\Gamma (\\nu+1)}{2^{4} 2!\\Gamma (\\nu+3)} \\\\ a_{6} \u0026amp;=\\frac{-a_{0}\\Gamma (\\nu+1)}{2^{6}3!\\Gamma (\\nu+4)} \\\\ \\vdots \\\\ a_{2n}\u0026amp;=\\frac{(-1)^{n}\\Gamma (\\nu+1)}{2^{2n}\\Gamma (n+1)\\Gamma (\\nu+n+1)}a_{0} \\end{align*} $$\nSubstituting this into $\\eqref{1}$,\n$$ \\begin{align*} y \u0026amp;= \\sum\\limits_{n=0}^{\\infty}a_{2n}x^{2n+\\nu} \\\\ \u0026amp;= \\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}a_{0}\\Gamma (\\nu+1)}{2^{2n}\\Gamma (n+1)\\Gamma (\\nu+n+1)}x^{2n+\\nu} \\end{align*} $$\nArranging the form,\n$$ y=\\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}2^{\\nu}a_{0}\\Gamma (\\nu+1)}{\\Gamma (n+1)\\Gamma (n+\\nu+1)} \\left(\\frac{x}{2}\\right)^{2n+\\nu} $$\nIf we let $a_{0}=\\frac{1}{2^{\\nu} \\Gamma (\\nu+1)}$,\n$$ J_{\\nu}(x)=\\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}}{\\Gamma (n+1)\\Gamma (n+\\nu+1)} \\left(\\frac{x}{2}\\right)^{2n+\\nu} $$\nThis is referred to as the Bessel function of the first kind of order $\\nu$.\nCase 2. $r=-\\nu$\nThis case is simply the result of Case 1. with $\\nu$ changed to $-\\nu$. The solution process is completely the same, so we will only list the key results without detailed calculation steps and explanations.\n$$ a_{n}=\\frac{- a_{n-2}}{n(n-2\\nu)} $$\n$$ \\begin{align*} a_{2n}\u0026amp;=\\frac{ -a_{2n-2}}{ 2^{2}n(n-\\nu) } \\\\ \u0026amp;=\\frac{(1-)^{n}a_{0}}{2^{2n}n!(1-\\nu)(2-\\nu)\\cdots(n-\\nu)} \\end{align*} $$\n$$ \\frac{1}{(1-\\nu)(2-\\nu)\\cdots(n-\\nu)}=\\frac{\\Gamma (1-\\nu)}{\\Gamma (n-\\nu+1)} $$\n$$ a_{2n}=\\frac{(-1)^{n}\\Gamma (1-\\nu)}{2^{2n}\\Gamma (n+1)\\Gamma (n-\\nu+1)} $$\n$$ \\begin{align*} y \u0026amp;=\\sum \\limits _{n=0} ^{\\infty} a_{2n}x^{2n-\\nu} \\\\ \u0026amp;=\\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}a_{0}\\Gamma (1-\\nu)}{2^{2n}\\Gamma (n+1)\\Gamma (n-\\nu+1)}x^{2n-\\nu} \\\\ \u0026amp;=\\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}2^{-\\nu}a_{0}\\Gamma (1-\\nu)}{\\Gamma (n+1)\\Gamma (n-\\nu+1)} \\left( \\frac{x}{2} \\right)^{2n-\\nu} \\end{align*} $$\n$$ a_{0}=\\frac{2^{\\nu}}{\\Gamma (1-\\nu)} $$\n$$ J_{-\\nu}(x)=\\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}}{\\Gamma (n+1)\\Gamma (n-\\nu+1)} \\left( \\frac{x}{2} \\right)^{2n-\\nu} $$\n‚ñ†\nMary L. Boas, Mathematical Methods in the Physical Sciences (3rd Edition, 2008), p601-604\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1503,"permalink":"https://freshrimpsushi.github.io/en/posts/1503/","tags":null,"title":"Series Solution of the Bessel Equation: Bessel Functions of the First Kind"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 A random variable $X_{1} , \\cdots , X_{n}$ is said to be pairwise independent if it satisfies the following. $$ i \\ne j \\implies X_{i} \\perp X_{j} $$ A continuous random variable $X_{1} , \\cdots , X_{n}$ whose joint probability density function $f$ satisfies the condition with respect to each of its probability density functions $f_{1} , \\cdots , f_{n}$ is said to be mutually independent. $$ f(x_{1} , \\cdots , x_{n} ) \\equiv f_{1} (x_{1}) \\cdots f_{n} (x_{n}) $$ A discrete random variable $X_{1} , \\cdots , X_{n}$ whose joint probability mass function $p$ satisfies the following condition with each of its probability density functions $p_{1} , \\cdots , p_{n}$ is said to be mutually independent. $$ p(x_{1} , \\cdots , x_{n} ) \\equiv p_{1} (x_{1}) \\cdots p_{n} (x_{n}) $$ Random variables $X_{1} , \\cdots , X_{n}$ that are mutually independent and have the same distribution are called iid (Independent and Identically Distributed). Explanation The concept of being pairwise independent is less about its own importance but more about conveying the nuance of a less ideal condition that does not satisfy the nice condition of mutual independence. Naturally, mutual independence implies pairwise independence, but not vice versa. A prominent counterexample of this is the Bernstein distributions. iid is a favorite assumption in mathematical statistics since mutual independence is mathematically manageable and each random variable is identically distributed. For example, if the distribution is $D$, then $X_{1} , \\cdots , X_{n}$ are said to be iid random variables following distribution $D$, which can also be represented as follows. $$ X_{1} , \\cdots , X_{n} \\overset{\\text{iid}}{\\sim} D $$ Theorems [1] Expectation: If $X_{1} , \\cdots , X_{n}$ are mutually independent, for some function $u_{1} , \\cdots , u_{n}$ applied to each, $$ E \\left[ u_{1}(X_{1}) \\cdots u_{n}(X_{n}) \\right] = E \\left[ u_{1}(X_{1}) \\right] \\cdots E \\left[ u_{n}(X_{n}) \\right] $$ [2] Moment Generating Function: If $X_{1} , \\cdots , X_{n}$ are mutually independent and each has a moment-generating function $M_{i}(t) \\qquad , -h_{i} \u0026lt; t \u0026lt; h_{i}$, the moment-generating function of their linear combination $\\displaystyle T := \\sum_{i=1}^{n} a_{i} X_{i}$ is $$ M_{T} (t) = \\prod_{i=1}^{n} M_{i} \\left( a_{i} t \\right) \\qquad , -\\text{min}_{i=1, \\cdots, n} h_{i} \u0026lt; t \u0026lt; \\text{min}_{i=1, \\cdots, n} h_{i} $$ Hogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p122~125.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1469,"permalink":"https://freshrimpsushi.github.io/en/posts/1469/","tags":null,"title":"Independence and iid of Random Variables"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 If for two random variables $X_{1}, X_{2}$, the joint probability density function $f$ or the probability mass function $p$ satisfies the following conditions for the probability density functions $f_{1}, f_{2}$ or the probability mass functions $p_{1}, p_{2}$ of $X_{1}, X_{2}$, then $X_{1}, X_{2}$ are said to be independent, and is denoted as $X_{1} \\perp X_{2}$. $$ f(x_{1} , x_{2} ) \\equiv f_{1}(x_{1})f_{2}(x_{2}) \\\\ p(x_{1} , x_{2} ) \\equiv p_{1}(x_{1})p_{2}(x_{2}) $$\nTheorem The following are equivalent for continuous random variables, though the statement also holds for discrete random variables for convenience.\nThe following are all equivalent:\n[1]: $X_{1} \\perp X_{2}$ [2] Probability density function: $$ f (x_{1} , x_{2}) \\equiv f_{1}(x_{1}) f_{2}(x_{2}) $$ [3] Cumulative distribution function: For all $(x_{1} ,x_{2}) \\in \\mathbb{R}^{2}$ $$ F (x_{1} , x_{2}) = F_{1}(x_{1}) F_{2}(x_{2}) $$ [4] Probability: For all constants $a\u0026lt;b$ and $c \u0026lt; d$ $$ P(a \u0026lt; X_{1} \\le b, c \u0026lt; X_{2} \\le d) = P(a \u0026lt; X_{1} \\le b) P ( c \u0026lt; X_{2} \\le d) $$ [5] Expectation: If $E \\left[ u (X_{1}) \\right]$ and $E \\left[ u (X_{2}) \\right]$ exist $$ E \\left[ u(X_{1}) u(X_{2}) \\right] = E \\left[ u (X_{1}) \\right] E \\left[ u (X_{2}) \\right] $$ [6] Moment generating function: If the joint moment generating function $M(t_{1} , t_{2})$ exists $$ M(t_{1} , t_{2}) = M (t_{1} , 0 ) M( 0, t_{2} ) $$ Explanation As one can see from the forms of equivalent conditions above, independence means the condition that the entangled (joint) functions can be separated into a product form. This can be seen as an abstraction of the independence of events, which can separate probabilities as $$ P(A \\mid B) = {{ P(A B) } \\over { P(B) }} \\overset{\\text{ind}}{\\implies} P(AB) = P(A \\mid B) P(B) = P(A) P(B) $$ Understanding independence intuitively is important, but in studying mathematical statistics, it is necessary to pay more attention to its mathematical form.\nSee Also Independence of random variables defined in measure theory Hogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p112.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1461,"permalink":"https://freshrimpsushi.github.io/en/posts/1461/","tags":null,"title":"Probability Variables Independence in Mathematical Statistics"},{"categories":"ÏµúÏ†ÅÌôîÏù¥Î°†","contents":"Definition The problem of finding $x^{ \\ast } = \\argmin_{x} f(x)$ that makes the function value of function $f : \\mathbb{R}^{n} \\to \\mathbb{R}$ minimum is known as the Optimization Problem, and the algorithm to solve this problem is called an Optimization Technique. The given function $f$ in the optimization problem is specifically referred to as the Objective Function. $x^{ \\ast }$ is called the Global Optimizer if for all $x$, $f(x^{ \\ast }) \\le f(x)$ is satisfied. If there exists a neighborhood $\\mathcal{N}$ of $x^{ \\ast }$ satisfying $f(x^{ \\ast }) \\le f(x)$ for all $x \\in \\mathcal{N}$, then $x^{ \\ast }$ is called a Local Optimizer. In these definitions, the direction of the inequality can be reversed, i.e., the explanations still apply if the maximization is discussed instead, and they are collectively referred to as optimization.\nExplanation People who use optimization techniques may talk about \u0026lsquo;maximizing profits\u0026rsquo; or \u0026lsquo;minimizing costs\u0026rsquo;, but whether it is maximum or minimum is not a significant issue for mathematicians. The reason why minimization is near-synonymous with optimization is that the algorithms used for minimization problems can also be applied to maximization problems simply by multiplying by $-1$, and because mathematically significant functions like metrics or norms have the set of real numbers greater than or equal to $0$ as their codomain, meaning a minimum value exists.\nWith the recent trend in deep learning, the objective function (or cost function, loss function) is usually assumed to be smooth, but there is no guarantee that it must be so, therefore algorithms and methods to overcome this have also been studied. The domain of the objective function does not necessarily have to be $\\mathbb{R}^{n}$.\nGlobal Optimizer While the existence of an optimizer may be shown with just a few simple conditions, there is no theorem that can prove a local optimizer is a global optimizer. Ideally, everyone would want to find the optimizer, but in practice, it is rare for anyone to truly expect the solution they found to be the optimizer. There are many optimization problems but no \u0026lsquo;optimized\u0026rsquo; optimization technique that fits all, which is why numerous improvement algorithms have been developed.\nStrictness and Isolation of Optimizers In most cases, the following definitions are meaningless, but are mentioned here nonetheless.\nIf there exists a neighborhood $\\mathcal{N}$ of $x^{ \\ast }$ satisfying $f(x^{ \\ast }) \u0026lt; f(x)$ for all $x \\in \\mathcal{N}$, then $x^{ \\ast }$ is called a Strict Local Optimizer. If there exists a unique neighborhood $\\mathcal{N}$ of $x^{ \\ast }$ satisfying $f(x^{ \\ast }) \u0026lt; f(x)$ for all $x \\in \\mathcal{N}$, then $x^{ \\ast }$ is called an Isolated Local Optimizer. ","id":1463,"permalink":"https://freshrimpsushi.github.io/en/posts/1463/","tags":null,"title":"Optimization Techniques in Mathematics"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition For a discrete random variable $X_{1}, X_{2}, \\cdots , X_{n}$, the following $p_{2, \\cdots , n \\mid 1}$, given $X_{1} = x_{1}$, is called the joint conditional probability mass function of $ X_{2}, \\cdots , X_{n}$: $$ p_{2, \\cdots , n \\mid 1} ( x_{2} , \\cdots ,x_{n} \\mid X_{1} = x_{1} ) = {{ p_{1, \\cdots , n}(x_{1} , x_{2} , \\cdots , x_{n}) } \\over { p_{1}( X_{1} = x_{1} ) }} $$ For a continuous random variable $X_{1}, X_{2}, \\cdots , X_{n}$, the following $f_{2, \\cdots , n \\mid 1}$, given $X_{1} = x_{1}$, is called the joint conditional probability density function of $ X_{2}, \\cdots , X_{n}$: $$ f_{2, \\cdots , n \\mid 1} ( x_{2} , \\cdots ,x_{n} \\mid X_{1} = x_{1} ) = {{ f_{1, \\cdots , n}(x_{1} , x_{2} , \\cdots , x_{n}) } \\over { f_{1}( X_{1} = x_{1} ) }} $$ When a function $u$ for $X_{2} , \\cdots , X_{n}$ is given, the following, given $X_{1} = x_{1}$, is called the conditional expectation of $u( X_{2}, \\cdots , X_{n} )$: $$ \\begin{align*} \u0026amp; E \\left[ u \\left( X_{2} , \\cdots , X_{n} \\right) \\mid X_{1} = x_{1} \\right] \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} \\cdots \\int_{-\\infty}^{\\infty} u (x_{2} , \\cdots , x_{n}) f_{2 , \\cdots , n \\mid 1} (x_{2} , \\cdots, x_{n} \\mid X_{1} = x_{1}) dx_{2} \\cdots , dx_{n} \\end{align*} $$ Theorem [1] Conditional Variance: $$ \\begin{align*} \\text{Var} (X_{2} | X_{1} = x_{1}) =\u0026amp; E \\left[ \\left( X_{2} - E (X_{2} \\mid X_{1} = x_{1}) \\right)^{2} \\mid X_{1} = x_{1} \\right] \\\\ =\u0026amp; E \\left( X_{2}^{2} \\mid X_{1} = x_{1} \\right) - \\left[ E(X_{2} \\mid X_{1} = x_{1}) \\right]^{2} \\end{align*} $$ [2]: $E \\left[ E (X_{2} | X_{1}) \\right] = E (X_{2} )$ [3]: If $\\text{Var}(X_{2})$ exists, then $\\text{Var} \\left[ E \\left( X_{2} \\mid X_{1} \\right) \\right] \\le \\text{Var} (X_{2})$ Explanation As was the case in the curriculum level, conditional probability and conditional expectation belong to the most challenging sections to calculate in mathematical statistics. Putting everything else aside, the computations inevitably become more numerous because it involves multivariate variables. Of course, the concept of conditionality is worth this complexity. On the other hand, unlike mathematical statistics, which mainly relies on calculus, the studies progress to probability theory based on measure theory, making the calculations considerably more straightforward. The main point is, \u0026lsquo;do not ignore it, but do not obsess over it either.\u0026rsquo;\nSee Also Conditional Probability Distribution Defined by Measure Theory Conditional Expectation Defined by Measure Theory ","id":1458,"permalink":"https://freshrimpsushi.github.io/en/posts/1458/","tags":null,"title":"Probability Distributions under Conditional Probability in Mathematical Statistics"},{"categories":"Ìï®Ïàò","contents":"Definition Euler Integrals The following two integrals are referred to as Euler integrals.\n$(a)$ Euler integral of the first kind: Beta function $$ B(p,q)=\\int_{0}^1 t^{p-1}(1-t)^{q-1}dt,\\quad p\u0026gt;0,\\quad q\u0026gt;0 $$ $(b)$ Euler integral of the second kind: Gamma function $$ \\Gamma (p) = \\int_{0}^\\infty t^{p-1}e^{-t}dt,\\quad p\u0026gt;0 $$ Explanation Euler Integral of the First Kind 1-1. Beta Function: If the gamma function is considered a generalization of the factorial, then the beta function can be seen as a generalization of the binomial coefficient. $$ \\begin{pmatrix} n \\\\ k \\end{pmatrix}=\\frac{ 1 }{ (n+1)B(n-k+1,k+1) } $$ 1-2. Properties of Beta Function $$ B(p,q)=B(q,p) $$ $$ B(p,q)=B(p+1,q)+B(p,q+1) $$ $$ B(p+1,q)=\\frac{ p }{p+q}B(p,q),\\quad B(p,q+1)=\\frac{ q }{p+q }B(p,q) $$ $$ B(p,p)=\\frac{ 1 }{ 2^{2p-1} }B(p,{\\textstyle \\frac{ 1 }{ 2 }}) $$ 1-3. Various Representations of Beta Function\n$$ B(p,q)=\\int_{0}^{a}\\left( \\frac{ t }{ a }\\right)^{p-1} \\left( 1-\\frac{ t}{a}\\right)^{q-1}\\frac{ 1 }{a }dt=\\frac{ 1 }{ a^{p+q-1} }\\int_{0}^{a}t^{p-1}(a-t)^{q-1}dt $$ By substituting $t \\rightarrow \\dfrac{ t }{ a }$ into the definition of the beta function, it can be obtained immediately. $$ B(p,q)=2\\int_{0}^{\\pi/2}(\\sin\\theta)^{2p-1} (\\cos \\theta )^{2q-1}d\\theta $$ $$ B(p,q)=\\int_{0}^{\\infty} \\frac{ t^{p-1} }{(1+t)^{p+q}}dt $$ $$ B(p,q)=\\frac{ \\Gamma (p) \\Gamma (q) }{ \\Gamma (p+q) } $$ Euler Integral of the Second Kind 2-1. Gamma Function: If the beta function is considered a generalization of the binomial coefficient, then the gamma function can be seen as a generalization of the factorial. $$ \\Gamma (n)=(n-1)! $$ 2-2. Properties of Gamma Function $$ \\Gamma (p+1) = p \\Gamma (p) $$ $$ \\Gamma (p) \\Gamma (1-p) = \\frac{ \\pi }{ \\sin (\\pi p) } $$ There are also several important formulas that include the gamma function. ‚ñ∂eq15‚óÄ ","id":1483,"permalink":"https://freshrimpsushi.github.io/en/posts/1483/","tags":null,"title":"Euler Integrals: Beta Function and Gamma Function"},{"categories":"Ìï®Ïàò","contents":"Theorem $$ B(p,q) = {{\\Gamma (p) \\Gamma (q)} \\over {\\Gamma (p+q) }} $$\nExplanation The Beta function is defined as $\\displaystyle B(p,q) := \\int_{0}^{1} t^{p-1} (1-t)^{q-1} dt $, and, like the Gamma function, it is an important function applied in many fields. Since the Gamma function can be easily calculated using the recursive relationship, the Beta function can also be calculated easily using the above relation. Intuitively, it can be seen as a generalization of the binomial coefficient, and since factorials appear, it naturally has a lot of relations with the Gamma function.\nProof If $\\displaystyle \\Gamma (p) = \\int_{0}^{\\infty} u^{p-1} e^{-u} du $ and $\\displaystyle \\Gamma (q) = \\int_{0}^{\\infty} v^{p-1} e^{-v} dv $, then $$ \\begin{align*} \\Gamma (p) \\Gamma (q) \u0026amp;= \\int_{0}^{\\infty} u^{p-1} e^{-u} du \\int_{0}^{\\infty} v^{p-1} e^{-v} dv \\\\ \u0026amp;= \\int_{0}^{\\infty} \\int_{0}^{\\infty} u^{p-1} v^{q-1} e^{-u} e^{-v} du dv \\end{align*} $$ Substituting with $u + v = z$, $u = zt$, and $v = z( 1 - t)$ to get $$ \\begin{align*} \\Gamma (p) \\Gamma (q) \u0026amp;= \\int_{0}^{\\infty} \\int_{0}^{1} (zt)^{p-1} (z(1-t))^{q-1} e^{-u-v} z dt dz \\\\ \u0026amp;= \\int_{0}^{\\infty} \\int_{0}^{1} z^{p+q+1} t^{p-1} (1-t)^{q-1} e^{-z} dt dz \\\\ \u0026amp;= \\int_{0}^{\\infty} z^{p+q+1} e^{-z} \\int_{0}^{1} t^{p-1} (1-t)^{q-1} dt dz \\\\ \u0026amp;= \\int_{0}^{\\infty} z^{p+q+1} e^{-z} dz \\int_{0}^{1} t^{p-1} (1-t)^{q-1} dt \\\\ \u0026amp;= \\Gamma (p + q) B(p, q) \\end{align*} $$ Upon arranging, $$ {{\\Gamma (p) \\Gamma (q)} \\over {\\Gamma (p+q) }} = B(p,q) $$ ‚ñ†\nCorollary: Symmetry of the Beta Function $$ B(p,q) = B(q,p) $$\nIt\u0026rsquo;s also simple to the extent of being foolish to prove it with substitution, as $\\displaystyle B(p,q) = {{\\Gamma (p) \\Gamma (q)} \\over {\\Gamma (p+q) }} = {{\\Gamma (q) \\Gamma (p)} \\over {\\Gamma (q+p) }} = B(q,p) $ is enough.\n","id":1481,"permalink":"https://freshrimpsushi.github.io/en/posts/1481/","tags":null,"title":"Relationship between Beta Function and Gamma Function"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Macros in Julia provide convenience features when coding, being executed in front of a scope. For example, if you want to know how much time your program is consuming, you can write it as follows.\n@time for t in 1:10\rfoo()\rbar()\rend Examples There are many types, but the following macros are especially widely used:\n@time: Measures the execution time of the function or scope that follows. When it\u0026rsquo;s unclear how to optimize in some situations, measuring the time first makes it easier to choose the better option. In some languages, writing code to measure the time can be cumbersome, but in Julia, a single macro tells you not only the execution time but also the amount of memory used. @.: Adds a dot (.) to the operations in the subsequent expression. @threads: A macro that makes it easier to implement parallel processing. @animate: A macro that easily bakes GIFs. Environment OS: Windows julia: v1.5.0 ","id":1454,"permalink":"https://freshrimpsushi.github.io/en/posts/1454/","tags":null,"title":"Julia's Powerful Convenience Features, Macros"},{"categories":"Ìï®Ïàò","contents":"Factorial For a natural number $n$, $n!$ is defined as $n$factorialÏù¥Îùº ÏùΩÍ≥† ÏïÑÎûòÏôÄ Í∞ôÏù¥ Ï†ïÏùòÌïúÎã§.\n$$ n!=n\\cdot(n-1)\\cdot(n-2)\\cdots 2\\cdot 1 =\\prod\\limits_{k=1}^n k $$\nÏÑ§Î™Ö ÎßéÏùÄ Í≥≥ÏóêÏÑú ÏãùÏùÑ ÍπîÎÅîÌïòÍ≤å ÌëúÌòÑÌïòÍ∏∞ ÏúÑÌï¥ ÏÇ¨Ïö©ÎêúÎã§. $0$Ìå©ÌÜ†Î¶¨ÏñºÏùÄ $0!:=1$ÏúºÎ°ú Ï†ïÏùòÌïúÎã§. Ìå©ÌÜ†Î¶¨ÏñºÏùò Ï†ïÏùòÏó≠ÏùÑ ÏùºÎ∞òÌôîÌï¥ÏÑú Í∞êÎßàÌï®ÏàòÎùºÎäî Í≤ÉÏùÑ Ï†ïÏùòÌï† ÏàòÎèÑ ÏûàÎã§.\nÎçîÎ∏î Ìå©ÌÜ†Î¶¨Ïñº ÏûêÏó∞Ïàò $n$Ïóê ÎåÄÌï¥ÏÑú $n!!$ÏùÑ $n$ÎçîÎ∏îÌå©ÌÜ†Î¶¨Ïñº Ïù¥Îùº ÏùΩÍ≥† ÏïÑÎûòÏôÄ Í∞ôÏù¥ Ï†ïÏùòÌïúÎã§.\n$$ n!!=n\\cdot (n-2)\\cdot (n-4) \\cdot (n-6) \\cdots $$\nÏÑ§Î™Ö Ìå©ÌÜ†Î¶¨ÏñºÏù¥ $n$ÏóêÏÑúÎ∂ÄÌÑ∞ $1$Ïî© Î∫Ä Í∞íÏùÑ Í≥±Ìï¥ÎÇòÍ∞ÄÎäî Í≤ÉÏù¥ÏóàÎã§Î©¥ ÎçîÎ∏î Ìå©ÌÜ†Î¶¨ÏñºÏùÄ $n$ÏóêÏÑúÎ∂ÄÌÑ∞ $2$Ïî© Î∫Ä Í∞íÏùÑ Í≥±Ìï¥ÎÇòÍ∞ÄÎäî Í≤ÉÏù¥Îã§. Îî∞ÎùºÏÑú $n$Ïù¥ ÏßùÏàòÏù¥Î©¥ $2$ÏóêÏÑú Í≥±ÏÖàÏù¥ ÎÅùÎÇòÍ≥†, ÌôÄÏàòÏù¥Î©¥ $1$ÏóêÏÑú Í≥±ÏÖàÏù¥ ÎÅùÎÇúÎã§.$n$Ïù¥ ÏßùÏàòÏù¥Î©¥,\n$$ n!!=\\prod \\limits_{k=1}^{\\frac{n}{2}}(2k)=n\\cdot(n-2)\\cdots 4\\cdot 2 $$\n$n$Ïù¥ ÌôÄÏàòÏù¥Î©¥,\n$$ n!!=\\prod \\limits_{k=1}^{\\frac{n+1}{2}}(2k-1)=n\\cdot(n-2)\\cdots 3\\cdot 1 $$\nÏòàÎ•ºÎì§Ïñ¥ $7!!=7\\cdot 5\\cdot 3\\cdot 1=105$Ïù¥Í≥† $10!!=10\\cdot 8\\cdot 6\\cdot 4\\cdot 2=3840$\n$n!!$ÏùÄ $(n!)!$Í≥º ÌëúÍ∏∞Î≤ïÏù¥ Ìó∑Í∞àÎ¶¨Í∏∞ ÎïåÎ¨∏Ïóê ÏûêÏ£º Ïì∞Ïù¥ÏßÄÎäî ÏïäÎäîÎã§. Î¨ºÎ°† Ïã§Ï†úÎ°ú Ïì∏ÎßåÌïú Í≥≥Ïù¥ ÎßéÏßÄÎèÑ ÏïäÎã§. Îã§Îßå ÏñëÏûêÏó≠Ìïô Îì±ÏóêÏÑú Î≥µÏû°Ìïú ÏàòÏãùÏùÑ Îã§Î£∞ Îïå Ìé∏ÏùòÎ•º ÏúÑÌï¥ ÏÇ¨Ïö©ÌïòÍ∏¥ ÌïúÎã§. Ìå©ÌÜ†Î¶¨ÏñºÍ≥º ÎßàÏ∞¨Í∞ÄÏßÄÎ°ú $0!!=1$ÏúºÎ°ú Ï†ïÏùòÌïúÎã§.\nÎ©ÄÌã∞ Ìå©ÌÜ†Î¶¨Ïñº ÏûêÏó∞Ïàò $n\u0026gt;k$Ïóê ÎåÄÌï¥ÏÑú $n!^{(k)}=n!_{k}$Î•º ÏïÑÎûòÏôÄ Í∞ôÏù¥ Ï†ïÏùòÌïòÍ≥† Î©ÄÌã∞ Ìå©ÌÜ†Î¶¨ÏñºÏù¥Îùº ÌïúÎã§.\n$$ n!^{(k)}=n\\cdot(n-k)\\cdot (n-2k) \\cdot (n-3k)\\cdots $$\nÏÑ§Î™Ö Í∞êÎßàÌï®ÏàòÍ∞Ä Ìå©ÌÜ†Î¶¨ÏñºÏùò Ï†ïÏùòÏó≠ÏùÑ ÌôïÏû•Ìïú Í≤ÉÏù¥ÎùºÎ©¥ Î©ÄÌã∞ Ìå©ÌÜ†Î¶¨ÏñºÏùÄ Ìå©ÌÜ†Î¶¨ÏñºÏùò ÏÑ±Ïßà Í∑∏ ÏûêÏ≤¥Î•º ÌôïÏû•Ìïú Í≤ÉÏù¥ÎùºÍ≥† Î≥º Ïàò ÏûàÎã§. ÎçîÎ∏î Ìå©ÌÜ†Î¶¨ÏñºÎèÑ Î≥º ÏùºÏù¥ Ï†ÅÍ∏∞ ÎïåÎ¨∏Ïóê ÎãπÏó∞Ìûà Î©ÄÌã∞ Ìå©ÌÜ†Î¶¨ÏñºÏùÄ Îçî ÎßåÎÇòÍ∏∞ Ïñ¥Î†µÎã§. $n$ÏóêÏÑúÎ∂ÄÌÑ∞ ÎäêÎÇåÌëú Í∞ØÏàòÎßåÌÅº Î∫Ä Í∞íÏùÑ ÏùåÏàòÍ∞Ä ÎÇòÏò§Í∏∞ Ï†ÑÍπåÏßÄ Í≥±Ìï¥ÎÇòÍ∞ÄÎ©¥ ÎêúÎã§. ÏòàÎ•º Îì§Ïñ¥\n$$ 9!!!!=9\\cdot 5\\cdot 1,\\quad 8!!!=8\\cdot 5\\cdot 2 $$\n$0\u0026lt;n \\le k$Ïù∏ Í≤ΩÏö∞ÏóêÎäî $n!^{(k)}=1$ÏúºÎ°ú Ï†ïÏùòÌïòÍ≥† $-k \u0026lt; n\\le 0$Ïù∏ Í≤ΩÏö∞ÏóêÎäî $n!^{(k)}=1$.\nJoke ","id":1477,"permalink":"https://freshrimpsushi.github.io/en/posts/1477/","tags":null,"title":"Factorial, Double Factorial, Multi Factorial"},{"categories":"Ìï®Ïàò","contents":"Non-negative Integers and the Gamma Function For $\\alpha \u0026gt;0$, $$ \\int_{0}^{\\infty} e^{-\\alpha x} dx=\\left[-\\frac{1}{\\alpha}e^{-\\alpha x}\\right]_{0}^{\\infty}=\\frac{1}{\\alpha} $$ Differentiating both sides with respect to $\\alpha$, according to the Leibniz integral rule, allows the differentiation to move under the integration sign, thus giving $$ \\begin{align*} \u0026amp;\u0026amp;\\int_{0}^\\infty -xe^{-\\alpha x}dx\u0026amp;=-\\frac{1}{\\alpha^2} \\\\ \\implies \u0026amp;\u0026amp; \\int_{0}^\\infty xe^{-\\alpha x}dx \u0026amp;= \\frac{1}{\\alpha ^2} \\end{align*} $$ Continuing to differentiate gives $$ \\begin{align*} \\int_{0}^\\infty x^2e^{-\\alpha x}dx\u0026amp;=\\frac{2}{\\alpha^3} \\\\ \\int_{0}^\\infty x^3e^{-\\alpha x}dx\u0026amp;=\\frac{3\\cdot 2}{\\alpha^4} \\\\ \\int_{0}^\\infty x^4e^{-\\alpha x}dx \u0026amp;=\\frac{4\\cdot 3\\cdot 2}{\\alpha^5} \\\\ \u0026amp;\\vdots \\\\ \\int_{0}^\\infty x^ne^{-\\alpha x}dx\u0026amp;=\\frac{n!}{\\alpha^{n+1}} \\end{align*} $$ If we set this as $\\alpha =1$, then $$ \\int_{0}^\\infty x^n e^{-x}dx=n! \\quad n=1,2,3,\\cdots $$ From the above equation, the reason why $0!=1$ is naturally explained. If we say $n=0$, then $$ 0!=\\int_{0}^\\infty e^{-x}dx=\\left[-e^{-x}\\right]_{0}^\\infty=1 $$ Hence, $0!:=1$ can be naturally defined.\nRecurrence Relation of Gamma Function $n$ does not have to be an integer to define the function using the above integral value. This is called the Gamma function. Usually, when it is an integer, it is written as $n$, and if not, it is written as $p$. $$ \\Gamma (p)=\\int_{0}^\\infty x^{p-1}e^{-x}dx,\\quad p\u0026gt;0 \\tag{1} $$ The reason why the range is $p\u0026gt;0$ is that the improper integral converges only in this range. When $p\\le 0$, the above integral diverges, so it cannot be used to define $\\Gamma (p)$. When $p\\le 0$, the method of defining the Gamma function is introduced further below. Also note that it is $\\Gamma (p)=(p-1)!$ not $\\Gamma (p)= p!$. If $p$ is an integer, then the Gamma function becomes the same as the factorial, hence it is obvious that $\\Gamma (n+1)=n \\Gamma (n)$ holds. However, this also holds when $p$ is not an integer. First, substituting $p+1$ for $p$ in $(1)$ yields $$ \\Gamma (p+1)=\\int_{0}^\\infty x^pe^{-x}dx,\\quad p\u0026gt;-1, \\tag{2} $$ Partially integrating the right side of $(2)$ gives $$ \\begin{align*} \\int_{0}^{\\infty} x^{p}e^{-x}dx\u0026amp;= \\int_{0}^{\\infty} (-x^{p})(-e^{-x})dx \\\\ \u0026amp;= \\left[-x^{p}e^{-x}\\right]_{0}^{\\infty}+\\int_{0}^{\\infty} px^{p-1}e^{-x}dx \\\\ \u0026amp;= p\\int_{0}^{\\infty} x^{p-1}e^{-x}dx \\\\ \u0026amp;=p\\Gamma (p) \\end{align*} $$ Therefore, combining the above result and $(2)$ yields $$ \\Gamma (p+1)=p\\Gamma (p),\\quad p\u0026gt;-1 \\tag{3} $$ $(3)$ is called the recurrence relation of the Gamma function. This allows expressions involving the Gamma function to be simplified. For example, $$ \\frac{\\Gamma (1/4)}{\\Gamma (9/4)}=\\frac{\\Gamma (1/4)}{\\frac{5}{4}\\Gamma (5/4)}=\\frac{\\Gamma (1/4)}{\\frac{5}{4}\\frac{1}{4}\\Gamma (1/4)}=\\frac{16}{5} $$\nExtending the Gamma Function to Negative Numbers The recurrence relation allows for defining the Gamma function for negative numbers. Examining $(3)$ reveals that $-1\u0026lt;p\u0026lt;0$ can be inserted into the Gamma function on the right side. Therefore, the Gamma function for $p\u0026lt;0$ is defined as follows. $$ \\Gamma (p)=\\frac{1}{p}\\Gamma (p+1),\\quad p\u0026lt;0 $$ For example, $\\Gamma (-3/5)=-\\frac{5}{3}\\Gamma (2/5 )$ and $\\Gamma (-8/5)=-\\frac{5}{8}\\Gamma (-3/5)=\\frac{25}{24}\\Gamma (2/5)$. When $p=0$, it can be shown to diverge as follows. Since $\\Gamma (1)=0!=1$, $$ \\lim \\limits_{p \\rightarrow 0} \\Gamma (p)=\\lim \\limits_{p \\rightarrow 0} \\frac{\\Gamma (p+1)}{p}=\\infty $$\nSee Also Euler integrals For a simpler understanding of the Gamma function: Generalization of Factorial, Gamma Function The Gamma Function in Physics ","id":1476,"permalink":"https://freshrimpsushi.github.io/en/posts/1476/","tags":null,"title":"Derivation of the Gamma Function"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Summary Let\u0026rsquo;s assume that $f(x,t)$ and $\\dfrac{\\partial f}{\\partial x}(x,t)$ are consecutive. Then, the following equation holds.\n$$ \\frac{d}{dx} \\int_{a}^b f(x,t)dt = \\int_{a}^b\\frac{\\partial f}{\\partial x}(x,t)dt $$\nDescription Being able to interchange the order of differentiation and integration is undoubtedly useful.\nBesides, there are many theorems or formulas related to differentiation and integration named after Leibniz.\nProof Since if continuous, then integrable, let\u0026rsquo;s assume $u$ as follows.\n$$ u(x):=\\int_{a}^b f(x,t)dt $$\nThen, the following is true.\n$$ \\begin{equation} \\begin{aligned} \\frac{ u(x+h)-u(x)}{h} \u0026amp;= \\frac{\\int_{a}^{b} f(x+h,t)dt -\\int_{a}^{b}f(x,t)dt}{h} \\\\ \u0026amp;= \\frac{ \\int_{a}^{b} \\big[f(x+h,t)-f(x,t) \\big] dt}{h} \\\\ \u0026amp;= \\int_{a}^{b} \\frac{f(x+h,t)-f(x,t)}{h}dt \\end{aligned} \\end{equation} $$\nMoreover, for a fixed $y$, applying the Mean Value Theorem to $f(x,y)$, there exists $c\\in[x,x+h]$ that satisfies the following equation.\n$$ \\frac{f(x+h,t)-f(x,t)}{h}=\\frac{\\partial f}{\\partial x}(c,t) $$\nIntegrating both sides with respect to $t$, by $(1)$, the following is true.\n$$ \\frac{u(x+h)-u(x)}{h}=\\int_{a}^{b}\\frac{\\partial f}{\\partial x}(c,t) dt $$\nNow, for any given $\\epsilon \u0026gt;0$, let\u0026rsquo;s say $\\epsilon_{0}=\\dfrac{\\epsilon}{b-a}$. Since $[x,x+h]\\times [a,b]$ is compact and by assumption $\\dfrac{\\partial f}{\\partial x}$ is uniformly continuous on a compact interval, then for sufficiently small $h$, the following is true.\n$$ \\left| \\frac{\\partial f}{\\partial x}(x+h,t)-\\frac{\\partial f}{\\partial x} (x,t)\\right| \u0026lt; \\epsilon_{0} $$\nAlso, since $c\\in[x,x+h]$, by the definition of uniform continuity, the following is true.\n$$ \\left| \\frac{\\partial f}{\\partial x}(c,t)-\\frac{\\partial f}{\\partial x} (x,t)\\right| \u0026lt; \\epsilon_{0} $$\nNow, calculating we obtain the following.\n$$ \\begin{align*} \u0026amp; \\left| \\lim \\limits_{h\\rightarrow 0}\\frac{u(x+h,t)-u(x,t)}{h} - \\int_{a}^{b} \\frac{\\partial f}{\\partial x}(x,t)dt\\right| \\\\ =\u0026amp;\\ \\left| \\lim \\limits_{h\\rightarrow 0}\\int_{a}^{b}\\frac{\\partial f}{\\partial x}(c,t) dt - \\int_{a}^{b} \\frac{\\partial f}{\\partial x}(x,t)dt\\right| \\\\ =\u0026amp;\\ \\left| \\lim \\limits_{h \\rightarrow 0} \\int_{a}^{b}\\left[ \\frac{\\partial f}{\\partial x}(c,t)-\\frac{\\partial f}{\\partial x}(x,t) \\right] dt\\right| \\\\ =\u0026amp;\\ \\lim \\limits_{h \\rightarrow 0}\\left| \\int_{a}^{b}\\left[ \\frac{\\partial f}{\\partial x}(c,t)-\\frac{\\partial f}{\\partial x}(x,t) \\right] dt\\right| \\\\ \\le\u0026amp; \\lim \\limits_{h \\rightarrow 0} \\int_{a}^{b}\\left| \\frac{\\partial f}{\\partial x}(c,t)-\\frac{\\partial f}{\\partial x}(x,t) \\right| dt \\\\ \\le\u0026amp; \\lim \\limits_{h \\rightarrow 0} \\int_{a}^{b} \\epsilon_{0}dt \\\\ =\u0026amp;\\ \\lim \\limits_{h \\rightarrow 0} (b-a)\\epsilon_{0} \\\\ =\u0026amp;\\ \\epsilon \\end{align*} $$\nThis equation holds for any given $\\epsilon\u0026gt;0$, hence the following is obtained.\n$$ \\lim \\limits_{h\\rightarrow 0} \\frac{u(x+h,t)-u(x,t)}{h}=\\int_{a}^{b}\\frac{\\partial f}{\\partial x}(x,t)dt $$\nAlso, since $\\displaystyle u(x):=\\int_{a}^b f(x,t)dt$, the following is true.\n$$ \\frac{d}{dx} \\int_{a}^b f(x,t)dt = \\int_{a}^b\\frac{\\partial f}{\\partial x}(x,t)dt $$\n‚ñ†\nSee Also Leibniz\u0026rsquo;s Rule for Differentiation ","id":1475,"permalink":"https://freshrimpsushi.github.io/en/posts/1475/","tags":null,"title":"Leibniz Integral Rule"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Julia supports the pipeline operator, highlighting its strength in handling data.\nCode julia\u0026gt; (1:5) .|\u0026gt; (x -\u0026gt; sqrt(x+2)) .|\u0026gt; sin |\u0026gt; minimum\r0.4757718381527513\rjulia\u0026gt; minimum(sin.((x -\u0026gt; sqrt(x+2)).(1:5)))\r0.4757718381527513 The example code above puts the array $[1,2,3,4,5]$ into $\\sqrt{x + 2}$, and then puts the result into $\\sin$ to obtain the smallest value. The code above and below produces exactly the same results. It goes without saying how useful the pipeline can be when writing complex code. Just remember to always use a dot when inserting arrays to treat each element individually, similar to the use of the pipeline in other languages.\nOther Languages Pipeline operator in R Environment OS: Windows julia: v1.5.0 ","id":1450,"permalink":"https://freshrimpsushi.github.io/en/posts/1450/","tags":null,"title":"How to Use Pipe Operators in Julia"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 A Random Vector is defined as $X = (X_{1} , \\cdots , X_{n})$ for $n$ number of probability variables $X_{i}$ defined in sample space $\\Omega$. The range $X(\\Omega)$ of $X$ is also called a space. A function that satisfies the following $F_{X} : \\mathbb{R}^{n} \\to [0,1]$ is called the Joint Cumulative Distribution Function of $X$. $$ F_{X}\\left( x_{1}, \\cdots , x_{n} \\right) := P \\left[ X_{1} \\le x_{1} , \\cdots , X_{n} \\le x_{n} \\right] $$ If there exists a function satisfying the following for some $h_{1} , \\cdots , h_{n} \u0026gt;0$, it is known as the Moment Generating Function of $X$. $$ M_{X} (t_{1}, \\cdots , t_{n}) := E \\left[ e^{\\sum_{k=1}^{n} t_{k} X_{k} } \\right] = E \\left[ \\prod_{k=1}^{n} e^{t_{k} X_{k}} \\right] \\\\ |t_{1}| \u0026lt; h_{1} , \\cdots , |t_{n} | \u0026lt; h_{n} $$ Discrete D1: If the space of $X$ is a countable set, $X$ is said to be a Discrete Random Vector. D2: The following $p_{X} : \\mathbb{R}^{n} \\to [0,1]$ is called the Joint Probability Mass Function of the discrete random vector $X$. $$ p_{X} (x_{1} , \\cdots , x_{n}) := P \\left[ X_{1} = x_{1} , \\cdots , X_{n} = x_{n} \\right] $$ D3: The following $P_{X_{k}} (x_{k})$ about $1 \\le k \\le n$ is called the Marginal Probability Mass Function. $$ P_{X_{k}} (x_{k}) := \\sum_{x_{1}} \\cdots \\sum_{x_{k-1}}\\sum_{x_{k+1}} \\cdots \\sum_{x_{n}} p_{X} (x_{1} , \\cdots , x_{n}) $$ D4: $S_{X}:= \\left\\{ \\mathbb{x} \\in \\mathbb{R}^{n} : p_{X}(\\mathbb{x}) \u0026gt; 0 \\right\\}$ is referred to as the Support of $X$. Continuous C1: If the cumulative distribution function $F_{X} = F_{X_{1} , \\cdots , X_{n}}$ of probability variable $X$ is continuous at all $\\mathbb{x} \\in \\mathbb{R}^{n}$, then $X$ is considered a Continuous Random Vector. C2: The following $f_{X} : \\mathbb{R}^{n} \\to [0,\\infty)$ is known as the Joint Probability Density Function of the continuous random vector $X$. $$ F_{X} (x_{1}, \\cdots, x_{n}) = \\int_{-\\infty}^{x_{1}} \\cdots \\int_{-\\infty}^{x_{n}} f_{\\mathbb{x}} (t_{1} , \\cdots , t_{n}) dt_{1} \\cdots d t_{n} $$ C3: The following $f_{X_{k}} (t_{k})$ about $1 \\le k \\le n$ is known as the Marginal Probability Density Function. $$ f_{X_{k}}(t_{k}) := \\int_{\\infty}^{x_{1}} \\cdots \\int_{\\infty}^{x_{k-1}} \\int_{\\infty}^{x_{k+1}} \\cdots \\int_{\\infty}^{x_{n}} f_{X}(t_{1} , \\cdots , t_{n}) dt_{1} \\cdots d_{k-1} d_{k+1} \\cdots d_{n} $$ C4: $S_{X} := \\left\\{ \\mathbb{t} \\in \\mathbb{R}^{n} : f_{X} ( \\mathbb{t} ) \u0026gt; 0 \\right\\}$ is referred to as the Support of $X$. Originally, Random Vector is translated as ÌôïÎ•† Î≤°ÌÑ∞(Random Vector), but to avoid confusion with terms like Stochastic or Probabilistic after graduating high school, it is kept in its original wording. Originally, Joint Cumulative Distribution Function is translated as Í≤∞Ìï© ÌôïÎ•† Î∂ÑÌè¨, but to avoid potential confusion with independence or dependence, it is kept in its original wording. Originally, Marginal Distribution is translated as Ï£ºÎ≥Ä Î∂ÑÌè¨, but similar to how Marginal in economics might not convey its meaning well, it is kept in its original wording. Explanation Multivariate probability distribution is a generalization of univariate probability distribution to multiple dimensions, and while it inherently differs due to having multiple variables, at least at the undergraduate level of mathematical statistics, it can sufficiently differ through calculus skills. Let\u0026rsquo;s take a look at how they differ:\n1: What should not be confused is that the random vector $X : \\Omega^{n} \\to \\mathbb{R}^{n}$ is still a function. Hence, its range can be thought of, and through this, they can be classified into discrete and continuous types regarding multivariate. C2: Continuous joint density functions are generally defined to meet the following, excluding $A \\subset \\mathbb{R}^{n}$ where the probability is $0$, according to the fundamental theorem of calculus. $$ {{ \\partial^{n} } \\over { \\partial x_{1} \\cdots \\partial x_{n} }} F_{X} (\\mathbb{x}) = f(\\mathbb{x}) $$ D3, C3: Although the equation is complex, simply put, it changes the joint probability distribution exclusively to the distribution concerning probability variable $X_{k}$. Contrary to how the word marginal in economics corresponds with the concept of differentiation, in mathematical statistics, it involves integrating or summing up to eliminate variables of no interest. Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p75~84.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1449,"permalink":"https://freshrimpsushi.github.io/en/posts/1449/","tags":null,"title":"Multivariate Probability Distributions in Mathematical Statistics"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, lambdas are defined as follows:\n(x -\u0026gt; 3x^2 - 2x + 3)(1) This corresponds to defining the anonymous function $\\lambda : \\mathbb{Z} \\to \\mathbb{Z}$, substituting $1$ into it, and obtaining the function value $4$. $$ \\lambda : x \\mapsto ( 3 x^{2} - 2 x + 3 ) \\\\ \\lambda (1) = 4 $$ Indeed, lambda expressions themselves are not a Julia-specific feature but almost naturally supported, having been influenced by functional languages including MATLAB and Python. It is likely that learners interested in Julia have already had extensive experience using lambda expressions. However, for readers who may not know that \u0026lsquo;it\u0026rsquo; they have been using was a lambda expression, or who still do not know its true value, we introduce two immediately applicable examples especially for them.\nExample 1: Sorting lists by a different metric Sorting lists can be quite straightforward with built-in functions, but one might want to sort based on priority across categories in multi-dimensional arrays or to sort original data by different criteria. In such cases, you can easily write the code by inserting the corresponding function as a lambda expression into the by option of the sort() function.\njulia\u0026gt; # Example 1\rjulia\u0026gt; example = rand(-20:20,10)\r10-element Array{Int64,1}:\r3\r8\r19\r-12\r-20\r9\r-13\r19\r13\r2\rjulia\u0026gt; sort(example, by=(x -\u0026gt; abs(x)))\r10-element Array{Int64,1}:\r2\r3\r8\r9\r-12\r-13\r13\r19\r19\r-20 The above task represents sorting randomly selected integers from smallest to largest absolute values. It\u0026rsquo;s not impossible without lambda expressions, but it\u0026rsquo;s not as simple as it seems. By modifying the given lambda expression (x -\u0026gt; abs(x)), coders should be able to easily write the code they want.\nApplication of Example 1 Suppose a dictionary called value is created as follows. In this case, code to sort by the size of dictionary values can be simply written using a lambda expression as sort(value,by=(x -\u0026gt; value[x])), and the result is as follows. Example 2: Calculating frequency in a list Languages that prioritize data like R even have built-in functions for it, but this frequency calculation is not as straightforward as it might seem. While not complex enough to be called an algorithm, it can be quite involving when actually implemented. This can also be easily solved using a lambda function!\njulia\u0026gt; # Example 2\rjulia\u0026gt; example = rand(1:3,10); println(example)\r[3, 1, 2, 2, 3, 2, 3, 1, 3, 3]\rjulia\u0026gt; uexample = sort(unique(example))\r3-element Array{Int64,1}:\r1\r2\r3\rjulia\u0026gt; counts = map(x-\u0026gt;count(y-\u0026gt;x==y,example),uexample)\r3-element Array{Int64,1}:\r2\r3\r5 The above task is about counting the frequencies of randomly chosen integers. The problem was solved simply by identifying the classes of data with unique() and then counting each element corresponding to those classes.\nEnvironment OS: Windows julia: v1.5.0 ","id":1448,"permalink":"https://freshrimpsushi.github.io/en/posts/1448/","tags":null,"title":"Lambda Expressions in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Resizing Images To resize images, you can use the imresize function from the Images package. The function name is the same as in Matlab.\nimresize(X, ratio=a): Returns the image of array X scaled by a factor of a. Unlike Matlab, you must explicitly write ratio=a.\nimresize(X, m, n): Returns the image of array X resized to m rows and n columns. Below are example codes and their results.\nusing Images\rX=load(\u0026#34;example\\_{i}mage2.jpg\u0026#34;)\rY1=imresize(X, ratio=0.5)\rY2=imresize(X,500,500)\rY3=imresize(X,1500,1500)\rY4=imresize(X,700,1000)\rY5=imresize(X,1000,1300)\rY6=imresize(X,300,300)\rsave(\u0026#34;X.png\u0026#34;,colorview(RGB,X))\rsave(\u0026#34;Y1=imresize(0.5).png\u0026#34;,colorview(RGB,Y1))\rsave(\u0026#34;Y2=imresize(500,500).png\u0026#34;,colorview(RGB,Y2))\rsave(\u0026#34;Y3=imresize(1500,1500).png\u0026#34;,colorview(RGB,Y3))\rsave(\u0026#34;Y4=imresize(700,1000).png\u0026#34;,colorview(RGB,Y4))\rsave(\u0026#34;Y5=imresize(1000,1300).png\u0026#34;,colorview(RGB,Y5))\rsave(\u0026#34;Y6=imresize(300,300).png\u0026#34;,colorview(RGB,Y6)) See Also How to Resize Images in Matlab Environment OS: Windows10 Version: 1.5.3 (2020-11-09) ","id":1466,"permalink":"https://freshrimpsushi.github.io/en/posts/1466/","tags":null,"title":"How to Change Image Size in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code using Images\rcd(\u0026#34;C:/Users/rmsms/OneDrive/examples\u0026#34;)\rpwd()\rexample = load(\u0026#34;example.jpg\u0026#34;)\rtypeof(example)\rsize(example)\rgray1 = Gray.(example)\rtypeof(gray1)\rsize(gray1)\rM = convert(Array{Float64},gray1)\rtypeof(M)\rsize(M)\rcolorview(Gray, M.^(1/2))\rsave(\u0026#34;rgb.png\u0026#34;, colorview(RGB, example))\rsave(\u0026#34;gray1.png\u0026#34;, colorview(Gray, gray1))\rsave(\u0026#34;gray2.png\u0026#34;, colorview(Gray, transpose(gray1)))\rsave(\u0026#34;gray3.png\u0026#34;, colorview(Gray, M.^(1/2))) Let\u0026rsquo;s briefly understand the example code from top to bottom:\ncd() : Change Directory, changes the working directory to the desired location.\npwd() : Print Working Directory, prints the working directory. If you want to follow the example exactly, download the above file to your working directory and rename it to example.jpg.\nload() : Loads an image file in the working directory. The type of the loaded image is Array{RGB{Normed{UInt8,8}},2}. This is slightly different from other languages where a color image is represented by a tensor by combining three matrices. In fact, such an approach has caused a lot of confusion due to the lack of a unified standard across color spaces and libraries. Julia instead uses a single type and understands it as a two-dimensional array for width and height. The image is printed on the Plot panel the moment it is loaded. Gray() : Used to convert the image to grayscale. It is important to note that what is actually used is not Gray() but Gray.(). This indicates that the function itself converts a single pixel to grayscale, and putting a dot applies it to all pixels.\nsize() : Returns the size of the image. As mentioned, it does not treat color and grayscale as tensors of different shapes but as arrays of the same size with different data types. Convert() : Converted the gray1 image into Array{Float64}, i.e., a matrix. Thus, 0 represents black and 1 represents white in the matrix used to express the grayscale image.\ncolorview() : This function itself is used to print images or matrices. There‚Äôs no need to convert the matrix back into an image as one can directly check the image on the Plot panel. In the example code, the square root of each element of the matrix $M$ was taken. Since all elements of the matrix belong to $[0,1]$, this transformation corresponds to generally brightening the image. save() : Saves the images in the working directory:gray1.png : Saved in grayscale.gray2.png : Saved in grayscale and in the transpose matrix state.gray3.png : Saved in grayscale and in a brightened state.rgb.png : Saved with the original colors.\nEnvironment OS: Windows julia: v1.5.0 ","id":1446,"permalink":"https://freshrimpsushi.github.io/en/posts/1446/","tags":null,"title":"How to Load Images in Julia and Save Them as Matrices"},{"categories":"Îß§Ìä∏Îû©","contents":"Methods tic\rX1=rand(2^7);\rX2=rand(2^8);\rX3=rand(2^9);\rX4=rand(2^10);\rX5=rand(2^11);\rtoc\rY1=imrotate(X1,45,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rtoc\rY2=imrotate(X2,45,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rtoc\rY3=imrotate(X3,45,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rtoc\rY4=imrotate(X4,45,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rtoc\rY5=imrotate(X5,45,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rtoc tic: Starts a stopwatch for measuring execution time. toc: Returns the current time on the stopwatch. Note that it\u0026rsquo;s not measuring the time between toc and toc. To measure the computation time of calculating Y1~Y6 in the example code above, you should enter the code as follows.\ntic\rX1=rand(2^7);\rX2=rand(2^8);\rX3=rand(2^9);\rX4=rand(2^10);\rX5=rand(2^11);\rtoc\rtic\rY1=imrotate(X1,45,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rtoc\rtic\rY2=imrotate(X2,45,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rtoc\rtic\rY3=imrotate(X3,45,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rtoc\rtic\rY4=imrotate(X4,45,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rtoc\rtic\rY5=imrotate(X5,45,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rtoc Other Languages In R ","id":1467,"permalink":"https://freshrimpsushi.github.io/en/posts/1467/","tags":null,"title":"Measuring Code Execution Time in MATLAB"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Image Rotation imrotate(X, theta): Rotates array X by theta radians. Note that, unlike in MATLAB where the angle unit is degrees ($^{\\circ})$, the angle unit here is radians. Additionally, unlike MATLAB, it rotates clockwise. If no other variables are inputted, the interpolation method defaults to bilinear, and the rotated image is not cropped. Examples of rotating the original image X by $90^\\circ=\\pi/2$, $180^\\circ=\\pi$, and $270^\\circ=\\frac{3}{2}\\pi$, along with their results, are shown below.\nusing Images\rusing Interpolations\rX=load(\u0026#34;example\\_{i}mage.png\u0026#34;)\rY1=imrotate(X,pi/2)\rY2=imrotate(X,pi)\rY3=imrotate(X,pi*3/2) As shown, when rotated like this, the original array fits perfectly, so there is no change in the size of the image. However, when rotated by an angle that is not a multiple of $90$, it does not align with the original shape. Therefore, the image expands to represent all points of the original image. If one wishes to maintain the original size of the image, one can add the axes() variable.\nY4=imrotate(X,pi/6)\rY5=imrotate(X,pi/6,axes(X)) Additionally, using Constant() from the Interpolations package allows you to apply the nearest1 interpolation method. Since it only uses the nearest point for calculation, the accuracy is lower but the computation is faster. Conversely, bilinear2 involves the calculation of all four surrounding points, so it is relatively slower but more accurate. Being more accurate here means that there is less damage to the image upon rotation. Look at the pictures below. The images are large, so at first glance, there might not seem to be a difference, but upon zooming in, the differences between the two interpolation methods become clear.\nY6=imrotate(X,pi/6,Constant()) See Also How to Rotate Images in MATLAB Environment OS: Windows10 Version: 1.5.3 (2020-11-09) Nearest-neighbor interpolation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBilinear interpolation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1462,"permalink":"https://freshrimpsushi.github.io/en/posts/1462/","tags":null,"title":"How to Rotate Image Arrays in Julia"},{"categories":"Îß§Ìä∏Îû©","contents":"Methods imresize(A, scale): Returns a new image by adjusting the size of A by a factor of scale. If A is a 10x10 image and a scale of 0.5 is input, it returns a 5x5 image. You can also adjust the size directly as follows.\nimresize(A, [m n]): Returns an image with m rows and n columns. Below are example codes and their results. X=imread(\u0026#39;test\\_{i}mage.jpg\u0026#39;);\rfigure()\rimshow(X)\rsaveas(gcf,\u0026#39;X.png\u0026#39;)\rtitle(\u0026#39;X\u0026#39;)\rY1=imresize(X,0.5);\rY2=imresize(X,[500 500]);\rY3=imresize(X,[700 500]);\rY4=imresize(X,[500,700]);\rfigure()\rimshow(Y1)\rsaveas(gcf,\u0026#39;Y1.png\u0026#39;)\rtitle(\u0026#39;Y1=imresize(X,0.5)\u0026#39;)\rfigure()\rimshow(Y2)\rsaveas(gcf,\u0026#39;Y2.png\u0026#39;)\rtitle(\u0026#39;Y2=imresize(X,[500 500])\u0026#39;)\rfigure()\rimshow(Y3)\rsaveas(gcf,\u0026#39;Y3.png\u0026#39;)\rtitle(\u0026#39;Y3=imresize(X,[700 500])\u0026#39;)\rfigure()\rimshow(Y4)\rsaveas(gcf,\u0026#39;Y4.png\u0026#39;)\rtitle(\u0026#39;Y4=imresize(X,[500,700])\u0026#39;) In other languages In Julia ","id":1465,"permalink":"https://freshrimpsushi.github.io/en/posts/1465/","tags":null,"title":"Resizing Images in MATLAB"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Let\u0026rsquo;s say $A = \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 1 \\\\ 0 \u0026amp; 3 \u0026amp; 0 \\\\ 2 \u0026amp; 3 \u0026amp; 4\\end{pmatrix}$.\nTranspose Matrix julia\u0026gt; A =[1 2 1;\r0 3 0;\r2 3 4]\r3√ó3 Array{Int64,2}:\r1 2 1\r0 3 0\r2 3 4\rjulia\u0026gt; transpose(A)\r3√ó3 LinearAlgebra.Transpose{Int64,Array{Int64,2}}:\r1 0 2\r2 3 3\r1 0 4\rjulia\u0026gt; A\u0026#39;\r3√ó3 LinearAlgebra.Adjoint{Int64,Array{Int64,2}}:\r1 0 2\r2 3 3\r1 0 4 When the elements of a matrix are real numbers, transpose() and ' return the same matrix, but the data type is subtly different. This is because ' is not exactly transpose but conjugate transpose. Therefore, for real matrices, it effectively returns the same matrix, but for complex matrices, it returns a completely different result.\njulia\u0026gt; A_complex=[1+im 2 1+im;\r0 3 0+im;\r2 3+im 4]\r3√ó3 Array{Complex{Int64},2}:\r1+1im 2+0im 1+1im\r0+0im 3+0im 0+1im\r2+0im 3+1im 4+0im\rjulia\u0026gt; transpose(A_complex)\r3√ó3 LinearAlgebra.Transpose{Complex{Int64},Array{Complex{Int64},2}}:\r1+1im 0+0im 2+0im\r2+0im 3+0im 3+1im\r1+1im 0+1im 4+0im\rjulia\u0026gt; A_complex\u0026#39;\r3√ó3 LinearAlgebra.Adjoint{Complex{Int64},Array{Complex{Int64},2}}:\r1-1im 0+0im 2+0im\r2+0im 3+0im 3-1im\r1-1im 0-1im 4+0im Power julia\u0026gt; A =[1 2 1;\r0 3 0;\r2 3 4]\r3√ó3 Array{Int64,2}:\r1 2 1\r0 3 0\r2 3 4\rjulia\u0026gt; A^2\r3√ó3 Array{Int64,2}:\r3 11 5\r0 9 0\r10 25 18\rjulia\u0026gt; A*A\r3√ó3 Array{Int64,2}:\r3 11 5\r0 9 0\r10 25 18\rjulia\u0026gt; A^3\r3√ó3 Array{Int64,2}:\r13 54 23\r0 27 0\r46 149 82\rjulia\u0026gt; A*A*A\r3√ó3 Array{Int64,2}:\r13 54 23\r0 27 0\r46 149 82 A^2 and A*A return exactly the same result. Likewise, A^3 and A*A*A are the same.\nElement-wise Multiplication, Element-wise Division julia\u0026gt; A =[1 2 1;\r0 3 0;\r2 3 4]\r3√ó3 Array{Int64,2}:\r1 2 1\r0 3 0\r2 3 4\rjulia\u0026gt; A.*A\r3√ó3 Array{Int64,2}:\r1 4 1\r0 9 0\r4 9 16\rjulia\u0026gt; A./A\r3√ó3 Array{Float64,2}:\r1.0 1.0 1.0\rNaN 1.0 NaN\r1.0 1.0 1.0 Returns the result of multiplying or dividing each element.\nHorizontal Flip, Vertical Flip julia\u0026gt; A =[1 2 1;\r0 3 0;\r2 3 4]\r3√ó3 Array{Int64,2}:\r1 2 1\r0 3 0\r2 3 4\rjulia\u0026gt; reverse(A,dims=1)\r3√ó3 Array{Int64,2}:\r2 3 4\r0 3 0\r1 2 1\rjulia\u0026gt; reverse(A,dims=2)\r3√ó3 Array{Int64,2}:\r1 2 1\r0 3 0\r4 3 2 reverse(A,dims=1) returns the vertically flipped matrix of $A$ and is equivalent to flipud(A) in MATLAB. reverse(A,dims=2) returns the horizontally flipped matrix of $A$ and is equivalent to fliplr(A) in MATLAB.\nInverse Matrix julia\u0026gt; A =[1 2 1;\r0 3 0;\r2 3 4]\r3√ó3 Array{Int64,2}:\r1 2 1\r0 3 0\r2 3 4\rjulia\u0026gt; inv(A)\r3√ó3 Array{Float64,2}:\r2.0 -0.833333 -0.5\r0.0 0.333333 0.0\r-1.0 0.166667 0.5 Returns the inverse matrix of $A$. If the inverse matrix cannot be found, it throws an error.\nEnvironment OS: Windows10 Version: 1.5.3 (2020-11-09) ","id":1460,"permalink":"https://freshrimpsushi.github.io/en/posts/1460/","tags":null,"title":"Functions for 2D Array Operations in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Heatmap Using the heatmap function from the Plots package, you can output a 2D array as a heatmap image, and with the savefig function, you can save the resulting image. The @__DIR__ macro tells you the location of the Julia code file.\n# code1 However, if you compare array A with the heatmap image, you may notice that the top and bottom of the array are flipped in the heatmap image. The reason the output image is created this way is official crab talk says it\u0026rsquo;s because each element\u0026rsquo;s position is thought of not in terms of rows and columns but rather as coordinates in a Cartesian coordinate system. That is, for example, in the matrix $A$, the value 19 is not seen as an element in the 4th row and 4th column but as an element in Cartesian coordinates $(4,4)$. This explains why the matrix and the image are flipped upside down with respect to each other.\nTherefore, to make the output look the same as the array, you can add the yflip=true option1.\n# code2 Moreover, users familiar with MATLAB can use the color=:bgy option to get an output that closely matches MATLAB\u0026rsquo;s default colors.\n# code3 Color Themes The following are some of the available color themes.\nSee Also From MATLAB Environment OS: Windows10 Version: 1.5.3 (2020-11-09) https://github.com/JuliaPlots/Makie.jl/issues/46#issuecomment-357023505\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1459,"permalink":"https://freshrimpsushi.github.io/en/posts/1459/","tags":null,"title":"How to output and save arrays as heatmap images in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Julia, like Python, supports the set data type. As with any set data type, it is incredibly useful for those who use it and utterly ignored by those who don\u0026rsquo;t. Given that Julia\u0026rsquo;s design is closely aligned with mathematics, its implementation of set concepts and operations is robust, making it an important feature to understand. Perhaps the most distinct difference from other languages, especially Python, is the ability to use Unicode symbols as part of the code. If you are using Juno in the Atom editor, you can autocomplete such TeX codes as shown above. In this context, $\\in$ is not merely a symbol but actually describes whether an element belongs to a set.\nCode julia\u0026gt; X = Set([1,2,3,1]); print(X)\rSet([2, 3, 1])\rjulia\u0026gt; X[1]\rERROR: MethodError: no method matching getindex(::Set{Int64}, ::Int64)\rStacktrace:\r[1] top-level scope at REPL[23]:1\rjulia\u0026gt; for i in X print(i) end\r231 The code above means to define a set $X$ as $X := \\left\\{ 1, 2, 3, 1 \\right\\} = \\left\\{ 2,3,1 \\right\\}$. As in mathematics, the concept of duplicates and order does not exist. Therefore, referencing the first index will result in an error. However, the data type is still iterable like in Python, meaning it can be used in loops.\njulia\u0026gt; if 1‚ààX print(\u0026#34;!\u0026#34;) else print(\u0026#34;?\u0026#34;) end\r!\rjulia\u0026gt; if 0‚ààX print(\u0026#34;!\u0026#34;) else print(\u0026#34;?\u0026#34;) end\r?\rjulia\u0026gt; if 0‚àâX print(\u0026#34;!\u0026#34;) else print(\u0026#34;?\u0026#34;) end\r!\rjulia\u0026gt; if [1,2] ‚äÜ X print(\u0026#34;!\u0026#34;) else print(\u0026#34;?\u0026#34;) end\r!\rjulia\u0026gt; if [0,1,2] ‚äÜ X print(\u0026#34;!\u0026#34;) else print(\u0026#34;?\u0026#34;) end\r? If this feels like reading an equation, you are ready to use the set data type effectively. It is important to note that such operations are not exclusive to the set data type; they are equally applicable to lists. Even if the set data type feels unfamiliar, as long as you are comfortable with sets, using Julia\u0026rsquo;s set operators should pose no problem. Note that the relation of containment should be written as \\subseteq $\\subseteq$, not \\subset $\\subset$.\njulia\u0026gt; Y = [\u0026#34;1\u0026#34;,\u0026#34;2\u0026#34;,3]\r3-element Array{Any,1}:\r\u0026#34;1\u0026#34;\r\u0026#34;2\u0026#34;\r3\rjulia\u0026gt; ‚à™(X,Y)\rSet{Any} with 5 elements:\r\u0026#34;1\u0026#34;\r2\r3\r\u0026#34;2\u0026#34;\r1\rjulia\u0026gt; ‚à©(X,Y)\rSet{Int64} with 1 element:\r3\rjulia\u0026gt; ‚à©(Y,X)\r1-element Array{Any,1}:\r3\rjulia\u0026gt; setdiff(X,Y); X\rSet{Int64} with 3 elements:\r2\r3\r1\rjulia\u0026gt; setdiff!(X,Y); X\rSet{Int64} with 2 elements:\r2\r1 Naturally, since it deals with sets, both union and intersection can be expressed similarly to mathematical equations. The difference between the second and third lines is the order of operations. $X$ is a set data type in Julia, while $Y$ is defined as an array, and the returned value follows the data type of the first argument. This distinction is crucial in a strongly typed language like Julia and must be thoroughly understood. The difference function is defined in two ways: setdiff() simply returns the set difference, while setdiff!() updates the set itself.\nEnvironment OS: Windows julia: v1.5.0 ","id":1442,"permalink":"https://freshrimpsushi.github.io/en/posts/1442/","tags":null,"title":"Sets and Operators in Julia"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 For a random variable $X$ and some positive number $h\u0026gt;0$, if $E(e^{tX})$ exists in $-h\u0026lt; t \u0026lt; h$, then $M(t) = E( e^{tX} )$ is defined as the Moment Generating Function of $X$.\nExplanation The moment generating function (mgf) is a concept often encountered relatively early in mathematical statistics, yet its unfamiliar definition and seemingly contextless introduction can make it a source of dislike for the subject. The challenge with understanding mgf typically stems from textbooks diving straight into its definition and application, leaving readers knowing what it is but not why it takes its form or its purpose. Essentially, the term \u0026lsquo;moment generating function\u0026rsquo; is constructed by combining \u0026lsquo;moment\u0026rsquo; and \u0026lsquo;generating function\u0026rsquo;. For those readers pressed for time, but wanting the key points:\nThere\u0026rsquo;s no need to understand what a moment is: Fundamentally, a moment is an abstract concept encompassing means, variances, etc. While moments can become meaningful statistical measures when manipulated appropriately according to their order, they are not inherently meaningful in a statistical sense. It\u0026rsquo;s sufficient to know the moment itself without forcing a connection to specific statistical measures. The moment generating function is merely a type of generating function: While generating functions are simply a general expression of a polynomial function, knowing that the moment generating function takes coefficients that are moments allows for a more accurate understanding of its properties. Decomposing the moment generating function using a Maclaurin series yields the following. [ NOTE: The rationale behind setting the radius of convergence to $-h\u0026lt;t\u0026lt;h$ in the definition is illustrated here. ] $$ \\begin{align*} M(t) =\u0026amp; E(e^{tX}) \\\\ =\u0026amp; 1 + E(tX) + {{E(t^2 X^2)} \\over {2!}} + \\cdots \\end{align*} $$ Since expectation has linearity, it can be represented as a generating function for $t$, as shown below. $$ M(t) = 1 + E(X) t+ {{E( X^2) t^2 } \\over {2!}} + \\cdots $$ Note that the coefficient of the $t^k$ term is a constant multiple $\\displaystyle {{E(X^{k})} \\over {k!}} $ of the $k$-th moment. Now, by differentiating both sides $n$ times with respect to $t$ and substituting $t=0$, we get: $$ M^{(n)} (0) = E(X^{n}) $$ Therefore, it can be said that the function $M$ generates moments, and thus it is appropriate to refer to it as the moment generating function. Had $M$ not been directly provided in the definition or had there only been mention of a generating function, it would have been considerably easier to grasp.\nConsidering random variables $X$ and $Y$ with moment generating functions $M_{X}$ and $M_{Y}$ respectively, if we assume these moment generating functions are identical. Moments are a concept devised to calculate statistical measures ultimately of interest in statistics. If all terms\u0026rsquo; moments are equal, then it can be said that $X$ and $Y$ follow the same distribution. Following this theorem, if the distributions have moment generating functions, it\u0026rsquo;s reasonable to compare these functions as equivalents of the distributions themselves. Although distribution functions, expressed as integrals, are convenient for representing probabilities, they are less so for handling distributions themselves. This is where the utility of moment generating functions comes in, as they\u0026rsquo;re frequently used when mathematically discussing which distribution a random variable follows.\nSummary Let $X$ and $Y$ be random variables with moment generating functions $M_{X}$ and $M_{Y}$, and cumulative distribution functions $F_{X}$ and $F_{Y}$, respectively. For all $ z \\in \\mathbb{R}$, $F_{X} (z) = F_{Y}(z)$ being true is equivalent to having some $h\u0026gt;0$ and for all $t \\in (-h,h)$, $M_{X}(t) = M_{Y}(t)$ being true.\n$\\mathbb{R}$ represents the set of real numbers. Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p59.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":248,"permalink":"https://freshrimpsushi.github.io/en/posts/248/","tags":null,"title":"What is the Moment Generating Function?"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 For two random variables $X, Y$, the following $\\rho = \\rho (X,Y)$, defined as the Pearson Correlation Coefficient, is: $$ \\rho = { {\\text{Cov} (X,Y)} \\over {\\sigma_X \\sigma_Y} } $$\n$\\sigma_{X}$, $\\sigma_{Y}$ are the standard deviations of $X$, $Y$ respectively. Explanation The Pearson Correlation Coefficient is a measure of whether two variables have a (linear) correlation. If close to $1$ or $‚Äì1$, it is considered to have a correlation, and if $0$, it is considered to have none.\nIt is important to note that correlation and independence are not the same concept. Correlation only checks if the two variables form a linear graph. Lack of correlation does not necessarily mean independence, but if they are independent, it can be said there\u0026rsquo;s no correlation. This reverse is only true when the two variables follow a normal distribution.\nProperties The Pearson correlation coefficient does not exceed $[-1,1]$. That is, $$ ‚Äì 1 \\le \\rho \\le 1 $$\nProof Two methods of proof will be introduced.\nProof using Cauchy-Schwarz inequality $$ \\rho = { {\\text{Cov} (X,Y)} \\over {\\sigma_X \\sigma_Y} } = {1 \\over n} \\sum_{k=1}^{n} { \\left( { { x_k - \\mu_{X} } \\over {\\sigma_X} } \\right) \\left( { { y_k - \\mu_{Y} } \\over {\\sigma_Y} } \\right) } $$ Squaring both sides gives $$ \\rho ^2 = {1 \\over {n^2} } \\left\\{ \\sum_{k=1}^{n} { \\left( { { x_k - \\mu_{X} } \\over {\\sigma_X} } \\right) \\left( { { y_k - \\mu_{Y} } \\over {\\sigma_Y} } \\right) } \\right\\} ^ 2 $$\nCauchy-Schwarz inequality: $$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\\ge { (ax+by) }^{ 2 } $$\nBy the Cauchy-Schwarz inequality $$ {1 \\over {n^2} } \\left\\{ \\sum_{k=1}^{n} { \\left( { { x_k - \\mu_{X} } \\over {\\sigma_X} } \\right) \\left( { { y_k - \\mu_{Y} } \\over {\\sigma_Y} } \\right) } \\right\\} ^ 2 \\le {1 \\over {n^2} } \\sum_{k=1}^{n} { \\left( { { x_k - \\mu_{X} } \\over {\\sigma_X} } \\right) ^ 2 } \\sum_{k=1}^{n} { \\left( { { y_k - \\mu_{Y} } \\over {\\sigma_Y} } \\right) ^ 2 } $$ Rearranging the right side gives $$ \\begin{align*} \u0026amp; {1 \\over {n^2} } \\sum_{k=1}^{n} { \\left( { { x_k - \\mu_{X} } \\over {\\sigma_X} } \\right) ^ 2 } \\sum_{k=1}^{n} { \\left( { { y_k - \\mu_{Y} } \\over {\\sigma_Y} } \\right) ^ 2 } \\\\ =\u0026amp; {1 \\over { {\\sigma_X}^2 {\\sigma_Y}^2 } } \\sum_{k=1}^{n} { \\left( { { x_k - \\mu_{X} } \\over { \\sqrt{n} } } \\right) ^ 2 \\sum_{k=1}^{n} \\left( { { y_k - \\mu_{Y} } \\over {\\sqrt{n}} } \\right) ^ 2 } \\\\ =\u0026amp; {1 \\over { {\\sigma_X}^2 {\\sigma_Y}^2 } } {\\sigma_X}^2 {\\sigma_Y}^2 \\\\ =\u0026amp; 1 \\end{align*} $$ Since $\\rho ^2 \\le 1$, $$ -1 \\le \\rho \\le 1 $$\n‚ñ†\nProof using the definition of covariance Setting $\\text{Var}(Y)={ \\sigma _ Y }^2, \\text{Var}(X)={ \\sigma _ X }^2$, $\\displaystyle Z= \\frac { Y }{ \\sigma _Y } - \\rho \\frac { X }{ \\sigma _X }$ to be the definition of covariance gives $$ \\begin{align*} \\text{Var}(Z)\u0026amp;=\\frac { 1 }{ { \\sigma _ Y }^2 }\\text{Var}(Y)+\\frac { { \\rho ^ 2 } }{ { \\sigma _ X }^2 }\\text{Var}(X)-2\\frac { \\rho }{ { \\sigma _X } { \\sigma _Y } }\\text{Cov}(X,Y) \\\\ =\u0026amp; \\frac { 1 }{ { \\sigma _ Y }^2 }{ \\sigma _ Y }^2+\\frac { { \\rho ^ 2 } }{ { \\sigma _ X }^2 }{ \\sigma _ X }^2-2\\rho \\cdot \\rho \\\\ \u0026amp;=1+{ \\rho ^ 2 }-2{ \\rho ^ 2 } \\\\ \u0026amp;=1-{ \\rho ^ 2 } \\end{align*} $$ Because of $\\text{Var}(Z)\\ge 0$, $$ \\begin{align*} 1-{ \\rho ^ 2 }\\ge 0 \\implies\u0026amp; { \\rho ^ 2 }-1\\le 0 \\\\ \\implies\u0026amp; (\\rho +1)(\\rho ‚Äì1)\\le 0 \\\\ \\implies\u0026amp; -1\\le \\rho \\le 1 \\end{align*} $$\n‚ñ†\nHogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p104.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":57,"permalink":"https://freshrimpsushi.github.io/en/posts/57/","tags":null,"title":"Pearson Correlation Coefficient"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Julia is a language that mixes the advantages of R, Python, and Matlab. Arrays are fundamental to programming, and their usage reveals traces of these languages.\nCode Matrix julia\u0026gt; M = [1. 2. ; 3. 4.]\r2√ó2 Array{Float64,2}:\r1.0 2.0\r3.0 4.0\rjulia\u0026gt; size(M)\r(2, 2)\rjulia\u0026gt; length(M)\r4 For matrices, the syntax is defined and used almost exactly like Matlab. The size() function is used just like in Matlab, and serves the same purpose as the .shape property in Python‚Äôs numpy package. length(), unlike in Matlab, returns the total number of elements.\n2D Arrays julia\u0026gt; x = [[1,2,3,4] for _ in 1:4]; x\r4-element Array{Array{Int64,1},1}:\r[1, 2, 3, 4]\r[1, 2, 3, 4]\r[1, 2, 3, 4]\r[1, 2, 3, 4] Placing loops inside arrays is a usage commonly seen in Python. This allows for a similar replication of the rep() function from R.\nSlicing julia\u0026gt; y = [3,2,5,1,4]\r5-element Array{Int64,1}:\r3\r2\r5\r1\r4\rjulia\u0026gt; y[[4,2,1,5,3]]\r5-element Array{Int64,1}:\r1\r2\r3\r4\r5\rjulia\u0026gt; y[3:end]\r3-element Array{Int64,1}:\r5\r1\r4\rjulia\u0026gt; y[3:4] .= -1; y\r5-element Array{Int64,1}:\r3\r2\r-1\r-1\r4 Indexing is similar to R, where providing an array of indexes will print the elements in that order. Seeing that the last index of an array is represented as end suggests that slicing is influenced by Matlab. Finally, using .= to directly assign -1 to the 3rd and 4th elements is also reminiscent of Matlab.\nIndexing julia\u0026gt; x = [1 2; 3 4]\r2√ó2 Array{Int64,2}:\r1 2\r3 4\rjulia\u0026gt; x[1,:]\r2-element Array{Int64,1}:\r1\r2\rjulia\u0026gt; x[[1],:]\r1√ó2 Array{Int64,2}:\r1 2\rjulia\u0026gt; x[1,1] = -1; x\r2√ó2 Array{Int64,2}:\r-1 2\r3 4 What is peculiar is that the result of indexing can vary depending on how it is performed. Conceptually, inserting the same thing should yield the same result; however, if elements are entered, the result is in elements, and if an array is entered, the result is in array form. This makes Julia hard to use while also providing significant help in implementing sophisticated features.\nEnvironment OS: Windows julia: v1.5.0 ","id":1437,"permalink":"https://freshrimpsushi.github.io/en/posts/1437/","tags":null,"title":"Slicing and Indexing of Arrays in Julia"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definitions and Properties The covariance of probability variables $X$ and $Y$, whose means are $\\mu_{X}$ and $\\mu_{Y}$ respectively, is defined as $\\text{Cov} (X ,Y) : = E \\left[ ( X - \\mu_{X} ) ( Y - \\mu_{Y} ) \\right]$. Covariance has the following properties:\n[1]: $\\text{Var} (X) = \\text{Cov} (X,X)$ [2]: $\\text{Cov} (X,Y) = \\text{Cov} (Y, X)$ [3]: $\\text{Var} (X + Y) = \\text{Var} (X) + \\text{Var} (Y) + 2 \\text{Cov} (X,Y)$ [4]: $\\text{Cov} (X + Y , Z ) = \\text{Cov}(X,Z) + \\text{Cov}(Y,Z)$ [5]: $\\text{Cov} (aX + b , cY + d ) = ac \\text{Cov}(X,Y)$ Explanation Covariance indicates the linear correlation between two variables and, unlike variance, can also be negative as well as $0$.\nProof [1] $$ \\begin{align*} \\text{Cov} (X ,X) =\u0026amp; E[ ( X - \\mu_{X} ) ( X - \\mu_{X} ) ] \\\\ =\u0026amp; E[ ( X - \\mu_{X} )^2 ] \\\\ =\u0026amp; \\text{Var} (X) \\end{align*} $$\n‚ñ†\n[2] $$ \\begin{align*} \\text{Cov} (X ,Y) =\u0026amp; E[ ( X - \\mu_{X} ) ( Y - \\mu_{Y} ) ] \\\\ =\u0026amp; E[ ( Y - \\mu_{Y} ) ( X - \\mu_{X} ) ] \\\\ =\u0026amp; \\text{Cov} (X ,Y) \\end{align*} $$\n‚ñ†\n[3] $$ \\begin{align*} \\text{Var} (X + Y) =\u0026amp; E [ ( X + Y - \\mu_{X} - \\mu_{Y} )^2 ] \\\\ =\u0026amp; E \\left[ \\left\\{ ( X - \\mu_{X} ) + (Y - \\mu_{Y} ) \\right\\} ^2 \\right] \\\\ =\u0026amp; E \\left[ ( X - \\mu_{X} )^2 + 2 ( X - \\mu_{X} ) (Y - \\mu_{Y} )+ (Y - \\mu_{Y} )^2 \\right] \\\\ =\u0026amp; E[ ( X - \\mu_{X} )^2] + 2 E [ ( X - \\mu_{X} ) (Y - \\mu_{Y} ) ] + E [ (Y - \\mu_{Y} )^2 ] \\\\ =\u0026amp; \\text{Var} (X) + 2 \\text{Cov} (X,Y) + \\text{Var} (Y) \\end{align*} $$\n‚ñ†\n[4] $$ \\begin{align*} \\text{Cov} (X + Y , Z ) =\u0026amp; E \\left[ ( X + Y - \\mu_{X} - \\mu_{Y} ) ( Z - \\mu_{Z} ) \\right] \\\\ =\u0026amp; E \\left[ \\left\\{ ( X - \\mu_{X} ) + ( Y - \\mu_{Y} ) \\right\\} ( Z - \\mu_{Z} ) \\right] \\\\ =\u0026amp; E \\left[ ( X - \\mu_{X} ) ( Z - \\mu_{Z} ) \\right] + E \\left[ ( Y - \\mu_{Y} ) ( Z - \\mu_{Z} ) \\right] \\\\ =\u0026amp; \\text{Cov}(X,Z) + \\text{Cov}(Y,Z) \\end{align*} $$\n‚ñ†\n[5] $$ \\begin{align*} \\text{Cov} (aX + b , cY + d ) =\u0026amp; E \\left[ ( aX + b - a \\mu_{X} - b ) ( cY + d - c \\mu_{Y} - d ) \\right] \\\\ =\u0026amp; E \\left[ ( aX - a \\mu_{X} ) ( cY - c \\mu_{Y} ) \\right] \\\\ =\u0026amp; E \\left[ a c ( X - \\mu_{X} ) ( Y - \\mu_{Y} ) \\right] \\\\ =\u0026amp; ac E \\left[( X - \\mu_{X} ) ( Y - \\mu_{Y} ) \\right] \\\\ =\u0026amp; ac \\text{Cov}(X,Y) \\end{align*} $$\n‚ñ†\nSee Also Covariance matrix $\\Sigma$ ","id":425,"permalink":"https://freshrimpsushi.github.io/en/posts/425/","tags":null,"title":"Various Properties of Covariance"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Theorem The mean $E ( X ) = \\mu_{X}$ and variance $\\text{Var} (X) = E [ ( X - \\mu_{X} )^2 ]$ have the following properties:\n[1]: $E(X + Y) = E(X) + E(Y)$ [2]: $E(aX + b) = a E(X) + b$ [3]: $\\text{Var} (X) \\ge 0$ [4]: $\\text{Var} ( X ) = E(X^2) - \\mu_{X}^2$ [5]: $\\text{Var} (aX + b) = a^2 \\text{Var} (X)$ Explanation As they relate to mean and variance, these are very important properties. Specifically, [1] and [2] are properties known as Linearity, which make handling equations very convenient.\nProof [1] For discrete cases $$ \\begin{align*} E ( X + Y ) =\u0026amp; \\sum (xp(x) + yp(y) ) \\\\ =\u0026amp; \\sum xp(x) + \\sum yp(y) \\\\ =\u0026amp; E(X) + E(Y) \\end{align*} $$ For continuous cases $$ \\begin{align*} E ( X + Y ) =\u0026amp; \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} (x + y) f(x,y) dx dy \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} x f(x,y) dx dy + \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} y f(x,y) dx dy \\\\ =\u0026amp; E(X) + E(Y) \\end{align*} $$\n‚ñ†\n[2] For discrete cases $$ \\begin{align*} E ( aX + b ) =\u0026amp; \\sum \\left( a x p(x) + b p(x) \\right) \\\\ =\u0026amp; a \\sum x p(x) + b \\sum p(y) \\\\ =\u0026amp; a E(X) + b \\end{align*} $$ For continuous cases $$ \\begin{align*} E ( aX + b ) =\u0026amp; \\int_{-\\infty}^{\\infty} (ax+b) f(x) dx \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} a xf(x) dx + \\int_{-\\infty}^{\\infty} b f(x) dx \\\\ =\u0026amp; a \\int_{-\\infty}^{\\infty} xf(x) dx + b \\int_{-\\infty}^{\\infty} f(x) dx \\\\ =\u0026amp; a E(X) + b \\end{align*} $$\n‚ñ†\n[3] Since $( X - \\mu_{X} )^2 \\ge 0$, then $\\text{Var} (X) = E [ ( X - \\mu_{X} )^2 ] \\ge 0$\n‚ñ†\n[4] $$ \\begin{align*} \\text{Var} (X) =\u0026amp; E [ ( X - \\mu_{X} )^2 ] \\\\ =\u0026amp; E (X^2 - 2 \\mu_{X} X + \\mu_{X}^2 ) \\\\ =\u0026amp; E (X^2) - 2 \\mu_{X} E(X) + \\mu_{X}^2 \\\\ =\u0026amp; E(X^2) - \\mu_{X}^2 \\end{align*} $$\n‚ñ†\n[5] According to theorem [2], if $Y = a X + b$ then $\\mu_{Y} = a \\mu_{X} + b$ and $$ \\begin{align*} \\text{Var} (Y) =\u0026amp; E [ ( Y - \\mu_{Y} )^2 ] \\\\ =\u0026amp; E [ ( aX + b - a \\mu_{X} - b )^2 ] \\\\ =\u0026amp; E [ a^2 ( X - \\mu_{X} )^2 ] \\\\ =\u0026amp; a^2 \\text{Var} (X) \\end{align*} $$\n‚ñ†\n","id":424,"permalink":"https://freshrimpsushi.github.io/en/posts/424/","tags":null,"title":"Properties of Mean and Variance"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Summary Let\u0026rsquo;s assume that we have given data $X = \\left\\{ x_{1} , \\cdots , x_{n} \\right\\}$.\n[0]: The $\\theta$ that minimizes $\\displaystyle h(\\theta)=\\sum_{i=1}^{n} {|x_i - \\theta|}^{0}$ is $$ \\argmin_{\\theta} h \\left( \\theta \\right) = \\text{mode}(X) $$ [1]: The $\\theta$ that minimizes $\\displaystyle h(\\theta)=\\sum_{i=1}^{n} {|x_i - \\theta|}^{1}$ is $$ \\argmin_{\\theta} h \\left( \\theta \\right) = \\text{median}(X) $$ [2]: The $\\theta$ that minimizes $\\displaystyle h(\\theta)=\\sum_{i=1}^{n} {|x_i - \\theta|}^{2}$ is $$ \\argmin_{\\theta} h \\left( \\theta \\right) = \\text{mean}(X) $$ Explanation In terms of linear algebra terminology, it can be stated as follows:\n[0]: Minimizing the $l^{0}$-norm is equivalent to the mode. [1]: Minimizing the $l^{1}$-norm is equivalent to the median. [2]: Minimizing the $l^{2}$-norm is equivalent to the mean. These theorems provide mathematical justifications as to why specific values are considered representative. Especially, the case [2] implies that the mean is the representative value that minimizes variance, which could answer the question of \u0026lsquo;why is variance defined this way\u0026rsquo;.\nProof Mode Strategy: The $l^{0}$-norm counts not the degree of non-equality but the number of inequalities.\n$$ \\left| x_{i} - \\theta \\right|^{0} := \\begin{cases} 1 \u0026amp; , \\theta \\ne x_{i} \\\\ 0 \u0026amp; , \\theta = x_{i} \\end{cases} $$ Therefore, the $\\theta$ that minimizes $\\displaystyle h(\\theta)=\\sum_{i=1}^{n} {|x_i - \\theta|}^{0} = 1 + 0 + 1 + \\cdots 1+ 1$ is $\\text{mode}(X)$\n‚ñ†\nMedian Strategy: Start by simplifying according to the definition of absolute values. Pair the largest and smallest terms in the data to eliminate variables and reduce them to constant terms. This makes it easy to find the variable term that needs to be minimized last.\nLet\u0026rsquo;s denote it as $ x_{(1)} \\le x_{(2)} \\le \\cdots \\le x_{(n)}$.\nPart 1. $\\theta \\in [x_{(1)} , x_{(n)} ]$ Assuming $\\theta \u0026lt; x_{(1)}$, all $x_{(i)}$ are smaller than $\\theta$, so $$ h(\\theta)=\\sum_{i=1}^{n} {\\left( x_{(i)} - \\theta \\right) } \u0026gt; \\sum_{i=1}^{n} { \\left( x_{(i)} - x_{(1)} \\right) } $$ Assuming $ x_{(n)} \u0026lt; \\theta$, all $x_{(i)}$ are larger than $\\theta$, so $$ h(\\theta)=\\sum_{i=1}^{n} { \\left( \\theta - x_{(i)} \\right) } \u0026gt; \\sum_{i=1}^{n} { \\left( x_{(n)} - x_{(i)} \\right) } $$ Therefore, regardless of what $\\theta$ specifically is, it must initially be $\\theta \\in [x_{(1)} , x_{(n)} ]$.\nPart 2.\nFor $\\theta_{0} \\in [x_{(1)} , x_{(n)} ]$ $$ \\begin{align*} h(\\theta_{0}) =\u0026amp; \\sum_{i=1}^{n} | x_{(i)} - \\theta_{0} | \\\\ =\u0026amp; \\sum_{i=2}^{n-1} | x_{(i)} - \\theta_{0} | + ( \\theta_{0} - x_{(1)} ) + ( x_{(n)} - \\theta_{0} ) \\\\ =\u0026amp; \\sum_{i=2}^{n-1} | x_{(i)} - \\theta_{0} | + ( x_{(n)} - x_{(1)} ) \\end{align*} $$\nFor $\\theta_{1} \\in [x_{(2)} , x_{(n-1)} ] \\subset [x_{(1)} , x_{(n)} ]$ $$ \\begin{align*} h(\\theta_{1}) =\u0026amp; \\sum_{i=1}^{n} | x_{(i)} - \\theta_{1} | \\\\ =\u0026amp; \\sum_{i=2}^{n-1} | x_{(i)} - \\theta_{1} | + ( x_{(n)} - x_{(1)} ) \\\\ =\u0026amp; \\sum_{i=3}^{n-2} | x_{(i)} - \\theta_{1} | + ( x_{(n-1)} - x_{(2)} ) + ( x_{(n)} - x_{(1)} ) \\end{align*} $$\nThis way, whenever a suitable $\\theta_{k} \\in [x_{(1+k)} , x_{(n-k)} ]$ is chosen, $( x_{(n-k)} - x_{(1+k)} )$ can be brought outside the sigma notation. Since these terms are determined by the data $X$, they are constant terms. For convenience, let‚Äôs express their sum as follows. $$ C_{k} : = \\sum_{j=0}^{k} \\left( x_{(n-j)} - x_{(j+1)} \\right) $$\nPart 3.\nCase 3-1. $ n$ is odd\nAccording to Part 2. $$ \\begin{align*} h ( \\theta ) =\u0026amp; \\sum_{i=1}^{n} | x_{(i)} - \\theta | \\\\ =\u0026amp; \\sum_{i=1+k}^{n-k} | x_{(i)} - \\theta | + C_{k} \\\\ =\u0026amp; \\left| x_{\\left( {{n+1} \\over {2}} \\right)} - \\theta \\right| + C_{{{n-1} \\over {2}} - 1} \\end{align*} $$ Therefore, the value that minimizes $h( \\theta )$ is $\\theta = x_{\\left( {{n+1} \\over {2}} \\right)}$. Case 3-2. $ n$ is even\nAccording to Part 2. $$ \\begin{align*} h ( \\theta ) =\u0026amp; \\sum_{i=1}^{n} | x_{(i)} - \\theta | \\\\ =\u0026amp; \\sum_{i=1+k}^{n-k} | x_{(i)} - \\theta | + C_{k} \\\\ =\u0026amp; \\left| x_{\\left( {{n} \\over {2}} \\right)} - \\theta \\right| + \\left| x_{\\left( {{n} \\over {2}} + 1 \\right)} - \\theta \\right| + C_{{{n} \\over {2}} - 2} \\end{align*} $$ In this case, all $\\displaystyle \\theta \\in \\left[ x_{ \\left( {{n} \\over {2}} \\right)} , x_{ \\left( {{n} \\over {2}} + 1 \\right)} \\right]$ make $h ( \\theta )$ minimized. Eventually, whether $n$ is even or odd, the $\\theta$ that minimizes $h ( \\theta)$ is the median of $X$.\n‚ñ†\nMean Strategy: It can be easily derived through differentiation.\n$$ {{ d } \\over { d \\theta }} \\sum_{i=1}^{n} \\left( x_{i} - \\theta \\right) = \\sum_{i=1}^{n} 2 \\left( x_{i} - \\theta \\right) = 0 $$ The $\\theta$ that satisfies the above equation minimizes $\\displaystyle h(\\theta)=\\sum_{i=1}^{n} {|x_i - \\theta|}^{2}$, thus $$ \\displaystyle\\sum_{i=1}^{n} 2 \\left( x_{i} - \\theta \\right) = 0 \\implies \\sum_{i=1}^{n} x_{i} = n \\theta \\implies \\theta = {{ 1 } \\over { n }} \\sum_{i=1}^{n} x_{i} $$\n‚ñ†\nSee Also Three Statistical Measures: Mode, Median, Mean ","id":49,"permalink":"https://freshrimpsushi.github.io/en/posts/49/","tags":null,"title":"Mathematical Proof of the Properties of Representative Values"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition: Expectation, Mean, and Variance Let\u0026rsquo;s assume that we have a given random variable $X$.\nIf the probability density function $f(x)$ of a continuous random variable $X$ satisfies $\\displaystyle \\int_{-\\infty}^{\\infty} |x| f(x) dx \u0026lt; \\infty$, then $E(X)$, defined as follows, is called the Expectation of $X$. $$ E(X) := \\int_{-\\infty}^{\\infty} x f(x) dx $$\nIf the probability mass function $p(x)$ of a discrete random variable $X$ satisfies $\\displaystyle \\sum_{x} |x| p(x) \u0026lt; \\infty$, then $E(X)$, defined as follows, is called the Expectation of $X$. $$ E(X) := \\sum_{x} x p(x) $$\nIf $\\mu = E(X)$ exists, it is defined as the Mean of $X$.\nIf $\\sigma^2 = E((X - \\mu)^2)$ exists, it is defined as the Variance of $X$.\nThe Meaning of Abstraction If we were to reduce statistics to a single, simple expression, it could be seen as the study of \u0026ldquo;So, what\u0026rsquo;s the average?\u0026rdquo; The \u0026lsquo;mean\u0026rsquo; is a statistical quantity that is quite intuitive and easy to calculate as a representative value. However, to explain various phenomena in the world, such a simple level is insufficient, and thus, it becomes abstracted in the form of \u0026rsquo;expectation\u0026rsquo;. Expectation is a concept that applies not only to discrete distributions but also to continuous distributions through the idea of partitioning methods. This writing discusses that very \u0026lsquo;abstraction\u0026rsquo;.\nAlthough mathematical statistics certainly contains material on statistical theory, its nature is closer to a branch of mathematics when considered. Therefore, an effort to understand mathematical statistics with the mindset of a mathematician, like other branches of mathematics, is necessary. One of the tasks of a mathematician is to come up with strict definitions that do not conflict with intuition or theories already presented in the world, turning everything, objects, phenomena, or even things beyond those, into symbols and enabling the study of all those things in place.\nThe definitions of mean and variance have no intuitive meaning left and simply appear in the form of taking the expectation of a random variable. It\u0026rsquo;s not of interest how these definitions connect to the mean and variance in reality. Rather, learners who are so accustomed to the concepts of mean and variance that they take them for granted are expected to adapt to the symbols in reverse. Indeed, learners at the level of studying mathematical statistics probably won\u0026rsquo;t have much trouble accepting such definitions.\nWith the abstraction of the mean and the establishment of the concept of expectation, scholars discover more possibilities. Beyond the limitations of simple summation or integration, they begin to handle them by introducing basic theories of algebra or analysis. Naturally, the interest of scholars shifts from abstraction to generalization.\nDefinition: Moments For a natural number $m$, $E( X^m )$ is defined as the $m$th Moment of $X$.\nThe Meaning of Generalization Merely reading the definition of moments reveals that the first moment, $E(X^1)$, is the mean of $X$. A bit further thought reveals that the second moment, $E(X^2)$, can also become the variance through some manipulation.\nThe first moment is essentially the same concept as the mean, and the second moment corresponds to the variance. Conversely, it can be said that among the moments, the first corresponds to the mean, and the second corresponds to the variance.\nNaturally, scholars with intuition would speculate that the third or fourth moments might also provide some important information. [ NOTE: Specifically, these are referred to as Skewness and Kurtosis.] Research direction now reverses, with theories not explaining discovered facts but rather seeking hidden facts through theories.\nThis methodology can be easily found in natural sciences as well as in statistics. While mathematical statistics leans more towards mathematics than statistics, as it approaches the essence of the existence of the discipline, it regains the appearance of statistics. The term moment, though used in physics and other fields, doesn\u0026rsquo;t necessarily need to carry a specific meaning in statistics. It suffices to know it as a term used when explaining the supporting theories of mathematical statistics.\nOn the other hand, one might wonder why it\u0026rsquo;s necessary to take the absolute value in $\\displaystyle \\int_{-\\infty}^{\\infty} |x| f(x) dx \u0026lt; \\infty$, the existence condition of the expectation, $x$. Even if guaranteeing existence and calculating specific values differ, there seems to be no need to use a different formula for the expectation $E(X)$ of $X$.\nThis might be somewhat clarified by observing the following theorem. If one considers not just the simplest discussion of $X$ but the generalization to $g(X)$, then $E(X)$ could indeed be considered a special case as defined for the identity function $g(x) = x$.\nTheorem For the random variable $X$, let\u0026rsquo;s say $Y$ appears in the form of $Y := g(X)$ for some function $g$.\n[1]: If $X$ is a continuous random variable with probability density function $f_{X}$ and satisfies $\\displaystyle \\int_{-\\infty}^{\\infty} |g(x)| f_{X} (x) dx \u0026lt; \\infty$, then $$ E (Y) = \\int_{-\\infty}^{\\infty} g(x) f_{X} (x) dx $$ [2]: If $X$ is a discrete random variable with probability mass function $p_{X}$ and satisfies $\\displaystyle \\sum_{x} |g(x)| p_{X} (x) \u0026lt; \\infty$, then $$ E (Y) = \\sum_{x} g(x) p_{X} (x) $$ See Also Mean as a Representative Value Expectation Defined by Measure Theory ","id":246,"permalink":"https://freshrimpsushi.github.io/en/posts/246/","tags":null,"title":"Expectation, Mean, Variance, and Moments in Mathematical Statistics"},{"categories":"ÏïåÍ≥†Î¶¨Ï¶ò","contents":"Definition Greedy algorithm is a method of making choices that only considers the current moment and selects the best possible option.\nDescription As its name suggests, the greedy algorithm focuses on the immediate without taking a long-term perspective. Speaking positively, it\u0026rsquo;s always trying to do its best, but this may not always be wise when looking at the bigger picture. Consider the following example:\nLet\u0026rsquo;s say there\u0026rsquo;s a problem of finding a path from the left 0 to the right 1. Not just finding any path, but one that crosses the fewest nodes. The optimal solution would be 0-A-C-E-1(3). However, the greedy algorithm would choose the path that seems longest at each moment. Hence, if this problem was approached with a greedy algorithm, the solution would be 0-B-D-F-G-H-1(5), incurring an extra cost of 2 compared to the optimal solution. If the first choice wasn‚Äôt 0-B, or even if it was D-E instead of D-F, a better solution could have been chosen.\nIn this manner, the greedy algorithm is more likely considered a \u0026lsquo;foolish approach\u0026rsquo; rather than a \u0026lsquo;good algorithm\u0026rsquo; in most contexts. However, for problems complex enough to necessitate an algorithm, like the example above, it won\u0026rsquo;t be as simple as just taking a quick look. That\u0026rsquo;s why usually, a naive solution using the greedy algorithm is attempted first, and then an improved algorithm is developed.\n","id":1434,"permalink":"https://freshrimpsushi.github.io/en/posts/1434/","tags":null,"title":"Greedy Algorithm"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 Let us assume that probability $P$ is defined in the sample space $\\Omega$.\nA function $X : \\Omega \\to \\mathbb{R}$ whose domain is the sample space is called a Random Variable. The range $X(\\Omega)$ of a random variable is also called its Space. A function $F_{X} : \\mathbb{R} \\to [0,1]$ that satisfies the following is called the Cumulative Distribution Function (cdf) of $X$. $$ F_{X}(x) = P_{X}\\left( (-\\infty,x] \\right) = P \\left( \\left\\{ \\omega \\in \\Omega : X(\\omega) \\le x \\right\\} \\right) $$ Discrete D1: If the space of the random variable $X$ is a countable set, then $X$ is called a Discrete Random Variable and is said to follow a discrete probability distribution. D2: The following $p_{X} : \\mathbb{R} \\to [0,1]$ is called the Probability Mass Function (pmf) of the discrete random variable $X$. $$ p_{X}(x) := P\\left( X=x \\right) $$ D3: $\\mathcal{S}_{X} := \\left\\{ x \\in \\mathbb{R} : p_{X}(x) \u0026gt; 0 \\right\\}$ is called the Support of $X$. Continuous C1: If the cumulative distribution function $F_{X}$ of the random variable $X$ is continuous at all $x \\in \\mathbb{R}$, then $X$ is called a Continuous Random Variable and is said to follow a continuous probability distribution. C2: A function $f_{X} : \\mathbb{R} \\to [0,\\infty)$ that satisfies the following is called the Probability Density Function (pdf) of the continuous random variable $X$, and $X$ is said to be Absolutely Continuous. $$ F_{X}(x) = \\int_{-\\infty}^{x} f_{X}(t) dt $$ C3. $\\mathcal{S}_{X} := \\left\\{ t \\in \\mathbb{R} : f_{X}(t) \u0026gt; 0 \\right\\}$ is called the Support of $X$. Explanation Support, or support set, simply put, is a collection that marks the section we are interested in. It\u0026rsquo;s not a commonly used term, but it certainly conveys what probability theory wants to express. Probability doesn\u0026rsquo;t care about something definitive, and a probability of $0$ means that it will never occur. Thus, $\\mathcal{S}$ can be seen as \u0026lsquo;a really important set\u0026rsquo; or \u0026lsquo;a set we must know\u0026rsquo;, allowing us to direct our limited energy not towards the entirety of $\\Omega$ but towards $\\mathcal{S}$.\nEven when encountering probability in high school, teachers would emphatically state that \u0026lsquo;a random variable is a function\u0026rsquo;. However, genuinely conceptualizing and treating random variables as functions requires a higher level of abstraction. Although the definitions introduced here are not yet mathematically strict, describing the concept of probability with sets and functions is not an easy task. Don\u0026rsquo;t despair if you don\u0026rsquo;t understand immediately, and don\u0026rsquo;t gloss over it if you think you do.\nFrom the definitions, one can notice an essential difference between discrete and continuous random variables, which extends into a formal difference. At the undergraduate level, it can be confusing, but it is crucial to understand that the addition of a Jacobian happens only when dealing with continuous random variables.\nSummary For a continuous random variable $X$ with the support $\\mathcal{S}_{X}$ and a differentiable injective function $g$, if we define a random variable $Y$ as $Y:=g(X)$, then the probability density function of $Y$ is derived as follows with respect to $y \\in \\mathcal{S}_{Y}$. [ NOTE: In fact, since $g$ is not assumed to be bijective, the existence of inverse function $g^{-1}$ is not always guaranteed. ] $$ f_{Y} (y) = f_{X} \\left( g^{-1}(y) \\right) \\left| {{ d x } \\over { d y }} \\right| $$\nHere, $\\mathcal{S}_{Y}$ is the support of $Y$, and $x$ means $x = g^{-1}(y)$. Proof $g$ is injective and continuous, so it is either increasing or decreasing. Let\u0026rsquo;s think about it in cases.\nCase 1. If $g$ is increasing $$ \\begin{align*} F_{Y}(y) =\u0026amp; P \\left( Y \\le y \\right) \\\\ =\u0026amp; P \\left( g(X) \\le y \\right) \\\\ =\u0026amp; P \\left( X \\le g^{-1}(y) \\right) \\\\ =\u0026amp; F_{X}\\left( g^{-1}(y) \\right) \\end{align*} $$ According to the fundamental theorem of calculus, the probability density function of $Y$ is $$ \\begin{align*} f_{Y}(y) =\u0026amp; {{ d } \\over { d y }} F_{Y}(y) \\\\ =\u0026amp; {{ d } \\over { d y }} \\int_{-\\infty}^{x} f_{X}(t) dt \\\\ =\u0026amp; {{ d } \\over { d x }} \\int_{-\\infty}^{x} f_{X}(t) dt {{ d x } \\over { d y }} \\\\ =\u0026amp; f_{X} \\left( x \\right) {{ d x } \\over { d y }} \\\\ =\u0026amp; f_{X} \\left( g^{-1} (y) \\right) {{ d x } \\over { d y }} \\end{align*} $$ Since $g$ is increasing, $\\displaystyle {{ d x } \\over { d y }} = {{ d g^{-1}(y) } \\over { d y }} \u0026gt;0$, and therefore $$ {{ d x } \\over { d y }} = \\left| {{ d x } \\over { d y }} \\right| $$\nCase 2. If $g$ is decreasing $$ \\begin{align*} F_{Y}(y) =\u0026amp; P \\left( Y \\le y \\right) \\\\ =\u0026amp; P \\left( g(X) \\le y \\right) \\\\ =\u0026amp; P \\left( X \\le g^{-1}(y) \\right) \\\\ =\u0026amp; 1- F_{X}\\left( g^{-1}(y) \\right) \\end{align*} $$ Similarly, $\\displaystyle f_{Y}(y) = - f_{X} \\left( g^{-1} (y) \\right) {{ d x } \\over { d y }}$. Since $g$ is decreasing, $\\displaystyle {{ d x } \\over { d y }} \u0026lt; 0$, and therefore $$ - {{ d x } \\over { d y }} = \\left| {{ d x } \\over { d y }} \\right| $$\n‚ñ†\nStrict Definition Probability variables and probability distributions defined by Measure Theory Cumulative Distribution Function defined by Measure Theory Discrete Probability Distribution in Measure Theory Absolute Continuity in Measure Theory Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p32~41.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1433,"permalink":"https://freshrimpsushi.github.io/en/posts/1433/","tags":null,"title":"Probability Variables and Probability Distribution in Mathematical Statistics"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition Let\u0026rsquo;s define a measurable space $(S,\\mathcal{S})$ with respect to the Borel sigma field $\\mathcal{S}:= \\mathcal{B}(S)$ of a metric space $S$.\nWhen random variables $X$ and stochastic processes $\\left\\{ X_{n} \\right\\}_{n \\in \\mathbb{N}}$ defined in a probability space $(\\Omega, \\mathcal{F}, P)$ are $n \\to \\infty$, for all $f \\in C_{b}(S)$, if the following is satisfied, then it is said to Converge in Distribution $X$ and is denoted as $X_{n} \\overset{D}{\\to} X$. $$ \\int_{\\Omega} f(X_{n}) dP \\to \\int_{\\Omega} f(X) dP $$\n$C_{b}(S)$ represents the set of bounded continuous functions defined by $S$. $$ C_{b}(S) := \\left\\{ f:S \\to \\mathbb{R} \\mid f\\text{ is bounded and continuous} \\right\\} $$ Theorem [1]: If the sequence $\\left\\{ P_{n} \\right\\}_{n \\in \\mathbb{N}}$ of probability measures defined in $(S,\\mathcal{S})$ satisfies $$ P_{n} \\left( X^{-1} (B) \\right) := P \\left( X_{n}^{-1} (B) \\right) $$ for all Borel sets $B \\in \\mathcal{B} \\left( \\mathbb{R} \\right)$, then the following holds. $$ X_{n} \\overset{D}{\\to} X \\iff P_{n} \\overset{W}{\\to} P $$ [2]: It is equivalent that $X_{n} \\overset{D}{\\to} X$ and every subsequence $\\left\\{ X_{n '} \\right\\} \\subset \\left\\{ X_{n} \\right\\}$ of all $\\left\\{ X_{n} \\right\\}$ has a subsequence $\\left\\{ X_{n ''} \\right\\} \\subset \\left\\{ X_{n '} \\right\\}$ satisfying $X_{n ''} \\overset{D}{\\to} X$. In formulaic terms, it is expressed as follows. $$ X_{n} \\overset{D}{\\to} X \\iff \\forall \\left\\{ X_{n '} \\right\\} \\subset \\left\\{ X_{n} \\right\\}, \\exists \\left\\{ X_{n ''} \\right\\} \\subset \\left\\{ X_{n '} \\right\\} : X_{n ''} \\overset{D}{\\to} X $$ [3] Continuous Mapping Theorem: Define $C_{h} : = \\left\\{ x \\in S : h \\text{ is continuous at } x \\right\\}$ as the set of points where $h$ is continuous for measurable functions $h : (S , \\mathcal{S}) \\to (S ' , \\mathcal{S} ')$. If $X_{n} \\overset{D}{\\to} X$ and $P(X \\in C_{h}) = 1$, then $h(X_{n}) \\overset{D}{\\to} h(X)$. Expressed in formulas, it is as follows. $$ X_{n} \\overset{D}{\\to} X \\land P(X \\in C_{h}) = 1 \\implies h(X_{n}) \\overset{D}{\\to} h(X) $$ Description [1]: As introduced in the theorem, a $P_{n}$ defined this way is called an Induced Probability Measure. It‚Äôs important to note that $X_{n} \\overset{D}{\\to} X$ distinguishes between the convergence of probability \u0026lsquo;variables\u0026rsquo; and $P_{n} \\overset{W}{\\to} P$, the convergence of probability \u0026lsquo;measures\u0026rsquo;. [2]: At first glance, this theorem might seem forced, but it becomes an important property when considered alongside the concept of relative compactness. [3]: Continuous Mapping Theorem is actually generalizable to almost sure convergence, in addition to probability convergence. Given that $h$ is also a function, and probability variables are functions as well, one should be able to naturally consider the use of composite functions $h \\circ X$. Contemplating whether the following formula makes sense for $A \\in \\mathcal{S} ' $ and grasping the process of understanding it is necessary. $$ P \\left( h(X)^{-1} (A) \\right) = P \\left( X \\in h^{-1}(A) \\right) $$ The notation that distributions are the same for all $f \\in C_{b}(S)$ is sometimes used as $\\overset{D}{=}$. Its definition is as follows for all $A \\in \\mathcal{S} ' $ and continuous functions $h:S \\to S'$. $$ h(X) \\overset{D}{=} h(Y) \\overset{\\text{def}}{\\iff} P \\left( h(X)^{-1}(A) \\right) = P \\left( h(Y)^{-1}(A) \\right) $$ Thinking back on the expression of convergence, it proceeds as follows. $$ h\\left( X_{n} \\right) \\overset{D}{\\to} h(X) \\iff P \\left( h\\left( X_{n} \\right)^{-1}(A) \\right) \\to P \\left( h(X)^{-1}(A) \\right) $$ Proof [1] For all $f \\in C_{b}(S)$ $$ \\begin{align*} P_{n} \\overset{W}{\\to} P \\iff \u0026amp; \\int_{S} f dP_{n} \\to \\int_{S} f dP \\\\ \\iff \u0026amp; \\int_{\\Omega} f(X_{n}) dP \\to \\int_{\\Omega} f(X) dP \\\\ \\iff \u0026amp; X_{n} \\overset{D}{\\to} X \\end{align*} $$\n‚ñ†\n[2] Assume that there exists $f \\in C_{b}(S)$ for which $X_{n} \\overset{D}{\\to} X$ does not hold $$ \\int_{\\Omega} f(X_{n}) dP \\to \\int_{\\Omega} f(X) dP $$. That is, assuming $$ \\left| \\int_{\\Omega} f(X_{n '}) dP - \\int_{\\Omega} f(X) dP \\right| \u0026gt; \\varepsilon $$ that there exists a subsequence index $\\left\\{ n' \\right\\}$ satisfying $\\varepsilon \u0026gt; 0$. However, this is a contradiction because there always exists a subsequence of subsequence indexes $\\left\\{ n'' \\right\\}$ satisfying $$ \\int_{\\Omega} f(X_{n ''}) dP \\to \\int_{\\Omega} f(X) dP $$\nIt is trivially true if we set $(\\impliedby)$ as $\\left\\{ n'' \\right\\} = \\left\\{ n \\right\\}$.\n‚ñ†\n[3] Let\u0026rsquo;s denote the probability measure induced by $X$ as $P_{X}(A) := P \\left( X^{-1}(A) \\right) = P(X \\in A)$. $$ \\overline{h^{-1}(B)} \\subset h^{-1}(B) \\cup C_{h}^{c} $$ Considering all closed sets $B$ in $S'$, the above inclusion relationship holds. For an arbitrary $x \\in \\overline{h^{-1}(B)}$, since $h$ preserves closure for the continuous part, containing $h^{-1}(B)$ and the preimage of the non-continuous part includes $C_{h}^{c}$. Since the closure $\\overline{h^{-1}(B)}$ is a closed set in $S$ $$ \\begin{align*} \u0026amp; \\limsup_{n \\to \\infty} P \\left( h ( X_{n} ) \\in B \\right) \\\\ =\u0026amp; \\limsup_{n \\to \\infty} P \\left( X_{n} \\in h^{-1} (B) \\right) \\\\ =\u0026amp; \\limsup_{n \\to \\infty} P_{X} \\left( h ( X_{n} )^{-1}(B) \\right) \\\\ =\u0026amp; \\limsup_{n \\to \\infty} P_{X} \\left( \\left[ X_{n}^{-1} \\circ h^{-1} \\right] (B) \\right) \\\\ =\u0026amp; \\limsup_{n \\to \\infty} P_{X} \\left( X_{n}^{-1} \\left( h^{-1} (B) \\right) \\right) \\\\ =\u0026amp; \\limsup_{n \\to \\infty} P_{n} \\left( h^{-1} (B)\\right) \\\\ \\le \u0026amp; \\limsup_{n \\to \\infty} P_{n} \\left( \\overline{h^{-1} (B)} \\right) \\end{align*} $$\nPortmanteau Theorem: Let\u0026rsquo;s say the space $S$ is both a metric space $( S , \\rho)$ and a measurable space $(S,\\mathcal{B}(S))$. The following are all equivalent.\n(1): $P_{n} \\overset{W}{\\to} P$ (2): For all bounded, uniformly continuous functions $f$, $\\displaystyle \\int_{S} f dP_{n} \\to \\int_{S}f d P$ (3): For all closed sets $F$, $\\displaystyle \\limsup_{n\\to\\infty} P_{n}(F) \\le P(F)$ (4): For all open sets $G$, $\\displaystyle P(G) \\le \\liminf_{n\\to\\infty} P_{n}(G)$ (5): For all $P(\\partial A) = 0$, $\\displaystyle \\lim_{n\\to\\infty} P_{n}(A) = P(A)$ of every $A$ Following [1], if $X_{n} \\overset{D}{\\to} X$, then $P_{n} \\overset{W}{\\to} P_{X}$, and by the assumption $P_{X}(X \\in C_{h}^{c}) = 0$ and $(1) \\implies (3)$ of the Portmanteau theorem $$ \\begin{align*} \\limsup_{n \\to \\infty} P_{X} \\left( h ( X_{n} )^{-1}(B) \\right) \\le \u0026amp; \\limsup_{n \\to \\infty} P_{n} \\left( \\overline{h^{-1} (B)} \\right) \\\\ \\le \u0026amp; P_{X} \\left( \\overline{h^{-1} (B)} \\right) \\\\ \\le \u0026amp; P_{X} \\left( h^{-1} (B) \\cup C_{h}^{c} \\right) \\\\ \\le \u0026amp; P _{X}\\left( h^{-1} (B) \\right) + P_{X} \\left( C_{h}^{c} \\right) \\\\ \\le \u0026amp; P_{X} \\left( h^{-1} (B) \\right) \\\\ \\le \u0026amp; P_{X} \\left( X^{-1} \\left( h^{-1} (B) \\right) \\right) \\\\ \\le \u0026amp; P_{X} \\left( \\left( h(X) \\right)^{-1} (B) \\right) \\end{align*} $$ Showing $\\displaystyle P_{X} \\left( \\left( h(X) \\right)^{-1} (B) \\right) \\le \\liminf_{n \\to \\infty} P_{X} \\left( h ( X_{n} )^{-1}(B) \\right)$ by the same method $$ \\lim_{n \\to \\infty} P_{X} \\left( h ( X_{n} )^{-1}(B) \\right) = P_{X} \\left( \\left( h(X) \\right)^{-1} (B) \\right) $$\n‚ñ†\nSee Also Convergence in distribution defined in Mathematical Statistics Almost Sure Convergence $\\implies$ Convergence in Probability $\\implies$, Convergence in Distribution (Weak Convergence) Renewed\nAugust 19, 2023, by Daeshik Ryu, corrected a typo in statement [1] ($P_{n} (A) := P \\left( X_{n}^{-1} (A)\\right)$ ‚Üí $P_{n} \\left( X^{-1} (B) \\right) := P \\left( X_{n}^{-1} (B)\\right)$) ","id":1432,"permalink":"https://freshrimpsushi.github.io/en/posts/1432/","tags":null,"title":"Convergence of Distributions Defined by Measure Theory"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Definition 1 An experiment that can be repeated under the same conditions is referred to as a Random Experiment. The set $\\Omega$ of all possible outcomes that can be obtained from a random experiment is called the Sample Space. The set of outcomes in the sample space that we are interested in, i.e., $B \\subset \\Omega$ is called an Event, and these sets are represented as $\\mathcal{B}$. A function $P : \\mathcal{B} \\to \\mathbb{R}$ that satisfies the following three conditions is called Probability: (i): For all $B \\in \\mathcal{B}$, $P(B) \\ge 0$ (ii): For the entire space $\\Omega \\in \\mathcal{B}$, $P(\\Omega) = 1$ (iii) Additive Law of Probability: For a sequence of mutually exclusive events $\\left\\{ B_{i} \\right\\}_{i=1}^{\\infty}$, i.e., $n \\ne m \\implies B_{n} \\cap B_{m} = \\emptyset$, for $\\left\\{ B_{i} \\right\\}$ $$ P \\left( \\bigcup_{i=1}^{\\infty} B_{i} \\right) = \\sum_{i=1}^{\\infty} P \\left( B_{i} \\right) $$ Explanation Even though it is called mathematical statistics, the basic concepts remain the same as those used in the curriculum‚Äôs probability and undergraduate-level probability theory. Regardless of the theoretical basis, the concepts cannot change even if expressions and reasoning may vary. Don‚Äôt be overwhelmed by sets and functions, and take your time to read through the explanations:\nEvents and Sample Space One difference from high school-level probability and statistics is the more active use of sets to describe the concept of probability. Though the concepts of probability at the undergraduate level in mathematical statistics might still retain vague expressions such as \u0026lsquo;random experiment\u0026rsquo; or \u0026lsquo;interested in,\u0026rsquo; these might seem strict and difficult at first glance. It\u0026rsquo;s normal, so don\u0026rsquo;t worry.\nAssuming human height follows a normal distribution, the sample space $\\Omega$ becomes the set of real numbers $\\mathbb{R}$ itself. Although height must always be positive, let‚Äôs put aside such unnecessary strictness for now. Then, an event $B$ would be represented by a set that includes the height $x$ of a man named Adam when measured. For example, $[172,190] \\subset \\Omega$ would be the event that the measured height is at least 172 and at most 190. This measurement is the random experiment described in the definition, and the measured value $x$ is an outcome, with all possible outcomes being compiled into the sample space. Even if you can\u0026rsquo;t grasp this abstraction, it might not significantly impede your study of mathematical statistics. However, be prepared that this may weaken your foundation.\nThe next step in abstraction is formalization. Event $B \\subset \\Omega$ belongs to the power set $\\mathscr{P}(\\Omega)$ of $\\Omega$. Let\u0026rsquo;s check a few relationships for the collection of these $\\mathcal{B}$. $$ B \\subset \\Omega \\\\ \\mathcal{B} \\not\\subset \\Omega \\\\ B \\in \\mathscr{P}(\\Omega) \\\\ B \\in \\mathcal{B} \\\\ B \\notin \\Omega \\\\ \\mathcal{B} \\subset \\mathscr{P}(\\Omega) $$\nProbability The reason for using such complex expressions is because the domain of the probability (function) $P$ has to be the events rather than the sample space $\\Omega$ itself. From a high school level perspective, it might be considered irrelevant what the exact probability of Adam\u0026rsquo;s height being 181 ($x=181$) is, and it should instead calculate probabilities like being taller than 180 but shorter than 182 ($180\u0026lt;x\u0026lt;182$) as $\\displaystyle \\int_{180}^{182}f(x) dx \u0026gt; 0$. Probability is a function that quantifies the likelihood of an event from $0$ to $1$.\nFor the entire space, i.e., $\\Omega$, $P(\\Omega)=1$ means, intuitively, \u0026rsquo;the probability of anything happening is 100%.\u0026rsquo; Formally, it can be explained as \u0026ldquo;nothing can be more certain than what is bound to occur.\u0026rdquo;\nExclusive Events An event $A \\subset \\Omega$ that satisfies the following is called an Exclusive Event of $B$. $$ P \\left( B \\cap A \\right) = 0 $$ Obvious examples of exclusive events include $\\emptyset$ or $B^{C}$, but it\u0026rsquo;s important to remember that the definition doesn‚Äôt exactly say $B \\cap A = \\emptyset$. Exclusive events are defined probabilistically, and it‚Äôs not concerned with how these sets actually look like as concrete sets.\nRigorous Definition Probability rigorously defined through measure theory Hogg et al. (2013). Introduction to Mathematical Statistics(7th Edition): p11.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1431,"permalink":"https://freshrimpsushi.github.io/en/posts/1431/","tags":null,"title":"Probability and the Addition Law of Probability in Mathematical Statistics"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Description Using circshifr(A, (n,m)), you can shift the rows of the array A $n$ positions down, and the columns $m$ positions to the right. (n,m) must be a tuple of integers, and negative numbers are also possible. If negative, it shifts in the opposite direction.\nFor arrays of 3 dimensions or more, it is applied to each smallest 2-dimensional array respectively.\nCode 2D array julia\u0026gt; A = transpose(reshape(1:25,5,5))\r5√ó5 LinearAlgebra.Transpose{Int64,Base.ReshapedArray{Int64,2,UnitRange{Int64},Tuple{}}}:\r1 2 3 4 5\r6 7 8 9 10\r11 12 13 14 15\r16 17 18 19 20\r21 22 23 24 25\rjulia\u0026gt; circshift(A, (-1,0))\r5√ó5 Array{Int64,2}:\r6 7 8 9 10\r11 12 13 14 15\r16 17 18 19 20\r21 22 23 24 25\r1 2 3 4 5\rjulia\u0026gt; circshift(A, (0,3))\r5√ó5 Array{Int64,2}:\r3 4 5 1 2\r8 9 10 6 7\r13 14 15 11 12\r18 19 20 16 17\r23 24 25 21 22\rjulia\u0026gt; circshift(A, (-1,3))\r5√ó5 Array{Int64,2}:\r8 9 10 6 7\r13 14 15 11 12\r18 19 20 16 17\r23 24 25 21 22\r3 4 5 1 2 Higher-dimensional array julia\u0026gt; B = reshape(1:4*4*3,4,4,3)\r4√ó4√ó3 reshape(::UnitRange{Int64}, 4, 4, 3) with eltype Int64:\r[:, :, 1] =\r1 5 9 13\r2 6 10 14\r3 7 11 15\r4 8 12 16\r[:, :, 2] =\r17 21 25 29\r18 22 26 30\r19 23 27 31\r20 24 28 32\r[:, :, 3] =\r33 37 41 45\r34 38 42 46\r35 39 43 47\r36 40 44 48\rjulia\u0026gt; circshift(B,(-1,0))\r4√ó4√ó3 Array{Int64,3}:\r[:, :, 1] =\r2 6 10 14\r3 7 11 15\r4 8 12 16\r1 5 9 13\r[:, :, 2] =\r18 22 26 30\r19 23 27 31\r20 24 28 32\r17 21 25 29\r[:, :, 3] =\r34 38 42 46\r35 39 43 47\r36 40 44 48\r33 37 41 45\rjulia\u0026gt; circshift(B,(0,2))\r4√ó4√ó3 Array{Int64,3}:\r[:, :, 1] =\r9 13 1 5\r10 14 2 6\r11 15 3 7\r12 16 4 8\r[:, :, 2] =\r25 29 17 21\r26 30 18 22\r27 31 19 23\r28 32 20 24\r[:, :, 3] =\r41 45 33 37\r42 46 34 38\r43 47 35 39\r44 48 36 40\rjulia\u0026gt; circshift(B,(-1,2))\r4√ó4√ó3 Array{Int64,3}:\r[:, :, 1] =\r10 14 2 6\r11 15 3 7\r12 16 4 8\r9 13 1 5\r[:, :, 2] =\r26 30 18 22\r27 31 19 23\r28 32 20 24\r25 29 17 21\r[:, :, 3] =\r42 46 34 38\r43 47 35 39\r44 48 36 40\r41 45 33 37 julia\u0026gt; C = reshape(1:3*3*2*4,3,3,2,4)\r3√ó3√ó2√ó4 reshape(::UnitRange{Int64}, 3, 3, 2, 4) with eltype Int64:\r[:, :, 1, 1] =\r1 4 7\r2 5 8\r3 6 9\r[:, :, 2, 1] =\r10 13 16\r11 14 17\r12 15 18\r[:, :, 1, 2] =\r19 22 25\r20 23 26\r21 24 27\r[:, :, 2, 2] =\r28 31 34\r29 32 35\r30 33 36\r[:, :, 1, 3] =\r37 40 43\r38 41 44\r39 42 45\r[:, :, 2, 3] =\r46 49 52\r47 50 53\r48 51 54\r[:, :, 1, 4] =\r55 58 61\r56 59 62\r57 60 63\r[:, :, 2, 4] =\r64 67 70\r65 68 71\r66 69 72\rjulia\u0026gt; circshift(C,(1,1))\r3√ó3√ó2√ó4 Array{Int64,4}:\r[:, :, 1, 1] =\r9 3 6\r7 1 4\r8 2 5\r[:, :, 2, 1] =\r18 12 15\r16 10 13\r17 11 14\r[:, :, 1, 2] =\r27 21 24\r25 19 22\r26 20 23\r[:, :, 2, 2] =\r36 30 33\r34 28 31\r35 29 32\r[:, :, 1, 3] =\r45 39 42\r43 37 40\r44 38 41\r[:, :, 2, 3] =\r54 48 51\r52 46 49\r53 47 50\r[:, :, 1, 4] =\r63 57 60\r61 55 58\r62 56 59\r[:, :, 2, 4] =\r72 66 69\r70 64 67\r71 65 68 Environment OS: Windows10 Version: 1.5.3 (2020-11-09) ","id":1453,"permalink":"https://freshrimpsushi.github.io/en/posts/1453/","tags":null,"title":"Translating Arrays in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"ÏΩîÎìú julia\u0026gt; x1=[1 2 3]\r1√ó3 Array{Int64,2}:\r1 2 3\rjulia\u0026gt; x2=[1, 2, 3]\r3-element Array{Int64,1}:\r1\r2\r3\rjulia\u0026gt; x3=[i for i in 1:3]\r3-element Array{Int64,1}:\r1\r2\r3\rjulia\u0026gt; x4=[i for i in 1:3:10]\r4-element Array{Int64,1}:\r1\r4\r7\r10\rjulia\u0026gt; x5=[i for i in 1:3:11]\r4-element Array{Int64,1}:\r1\r4\r7\r10 x1 is a 2-dimensional array. Since it looks like a row vector, if you input only one coordinate component, it is recognized as a row vector. x2, x3, x4, x5 are 1-dimensional arrays.\nx=[i for i in n:m] returns an array with elements ranging from $n$ to $m$ with an interval of $1$. x=[i for i in n:k:m] returns an array with elements ranging from $n$ to $m$ with an interval of $k$. The last element is the largest number that is less than or equal to $m$. This method of including a for loop inside a list to create a list is called List Comprehension in languages such as Python.\njulia\u0026gt; x6=1:3\r1:3\rjulia\u0026gt; x7=1:3:10\r1:3:10\rjulia\u0026gt; x9=1:3:11\r1:3:10 Although it doesn\u0026rsquo;t actually happen, you can think of arrays like x3, x4, x5 as being created as described above. As shown in the photo below, although the data types are different, they can be used in the same way as what was created above.\nrange(n,stop=m,length=k): This is exactly the same as lispace(n,m,k) in MATLAB. Let\u0026rsquo;s find out the specific differences through the example code and results below. julia\u0026gt; x9=range(1,stop=10)\r1:10\rjulia\u0026gt; x10=range(1,length=15)\r1:15\rjulia\u0026gt; x11=range(1,stop=10,length=15)\r1.0:0.6428571428571429:10.0\rjulia\u0026gt; x12=range(1,length=15,stop=10)\r1.0:0.6428571428571429:10.0 Similarly, you can think of the same vector being created, even though the actual data type is different. Unlike MATLAB, you can input only one of the second or third variables, and changing the order of input doesn\u0026rsquo;t matter.\nFirst line returns a vector with the first element being $1$ and the last element $10$. Since nothing else is input, the interval between elements is $1$. Second line returns a vector with the first element being $1$ and a total of $15$ elements. The interval automatically becomes $1$, similar to a vector created with x=range(1,stop=15) or x=1:15. Third line returns a vector with the first element being $1$, the last element $10$, and a total of $15$ elements. Therefore, the interval automatically becomes $9/14=0.6428571428571429$. Since it is not an integer, it naturally returns a vector with real number elements. Also, it is the same as one created with x=1.0:0.6428571428571429:10.0. Fourth line returns a vector exactly the same as the one returned in the third line. ÌÉÄÏñ∏Ïñ¥ How to create equally spaced row vectors in MATLAB ÌôòÍ≤Ω OS: Windows10 Version: 1.5.0 ","id":1452,"permalink":"https://freshrimpsushi.github.io/en/posts/1452/","tags":null,"title":"Various Methods of Creating Vectors in Julia"},{"categories":"ÏßëÌï©Î°†","contents":"Definitions 1 A relation $\\le$ in a set $A$ that is reflexive, transitive, and antisymmetric is called a Partial Order, and $(A,\\le)$ is referred to as a partially ordered set. Saying that $A$ is a partially ordered set means that it satisfies the following for all elements $a,b \\in A$. $$ a \\le b \\land b \\le a \\implies a = b $$ Given a partially ordered set $(A, \\le)$, for all $a,b \\in A$, if $a \\le b$ or $b \\le a$, then $\\le$ is called a Total Order in $A$, and $(A,\\le)$ is called a Totally Ordered Set. Explanation In the definition, $\\le$ is just a symbol and does not necessarily have to be an inequality sign comparing sizes. Of course, inequalities or inclusion relations can be partial orders, but the converse is not true. For example, in the alphabet, following \u0026lsquo;a\u0026rsquo; is \u0026lsquo;b\u0026rsquo;, and it doesn‚Äôt matter if it is represented as $a \\le b$ using just symbols. In fact, in computer science, \u0026lsquo;a\u0026rsquo; corresponds to ASCII code $0000001_{(2)}$, and \u0026lsquo;b\u0026rsquo; corresponds to ASCII code $00000010_{(2)}$, and the order between characters can also be represented by the binary relations of their sizes.\nIn fact, totally ordered sets might be something that anyone with compulsory education could easily recall, whereas it may not come as readily to mind what constitutes sets that are not. A good example of a totally ordered set is the set of natural numbers $\\mathbb{N}$, and this applies to the sets of integers $\\mathbb{Z}$, rational numbers $\\mathbb{Q}$, and real numbers $\\mathbb{R}$ as well. However, once you reach complex numbers $\\mathbb{C}$, there is not a naturally defined order.\nDefining partial orders before total orders is mathematically much more natural for that reason. Consider the following five sets, which naturally have partial orders. $$ A = \\left\\{ 1 \\right\\} \\\\ B = \\left\\{ 1,2 \\right\\} \\\\ C = \\left\\{ 1,3 \\right\\} \\\\ D = \\left\\{ 1,2,3 \\right\\} \\\\ E = \\left\\{ 1,2,4 \\right\\} $$ Thinking of the inclusion relationship of sets, $$ A \\subset B \\subset D \\\\ A \\subset B \\subset E \\\\ A \\subset C \\subset D $$ Visually, this complex shape can be understood at a glance. These non-linear forms represent natural relationships that are common enough to be found in our everyday lives. Upon reflection, a purely linearly stacking relationship might seem more unusual. Even the set of natural numbers $\\mathbb{N}$, according to Von Neumann\u0026rsquo;s construction, is not exactly \u0026lsquo;intuitive\u0026rsquo;. Thus, it might be easier to understand total orders as simply when a partial order is linearly defined across an entire set.\nÏù¥Ìù•Ï≤ú Ïó≠, You-Feng Lin. (2011). ÏßëÌï©Î°†(Set Theory: An Intuitive Approach): p289.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1421,"permalink":"https://freshrimpsushi.github.io/en/posts/1421/","tags":null,"title":"Partially Ordered Set"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 Given a metric space $(X,d)$ and $\\varepsilon\u0026gt;0$,\nA finite set $A_{\\varepsilon} \\subset X$ that satisfies $B_{d}(x,\\varepsilon) \\cap A_{\\varepsilon} \\ne \\emptyset$ for all $x \\in X$ is called a $\\varepsilon$-net for $X$. If for all $\\varepsilon \u0026gt; 0$, there exists a $\\varepsilon$-net $A_{\\varepsilon}$ for $X$, then $X$ is said to be Totally Bounded. Explanation Totally bounded spaces are often also called precompact spaces.\n$\\varepsilon$-Net Calling $A_{\\varepsilon}$ a net is quite intuitive when considering the condition $B_{d}(x,\\varepsilon) \\cap A_{\\varepsilon} \\ne \\emptyset$. If you translate the formula into words, it means, for the given space $X$, any point you pick is caught in $A_{\\varepsilon}$. If every point is caught within the allowed error $\\varepsilon$, it makes sense to call this a net.\nTotally Bounded Considering only a finite cover for all $\\varepsilon\u0026gt;0$ means that $X$ can be covered, which implies that $X$ is truly small and manageable. That a space is totally bounded means it can be thought of in finite segments while being a metric space, making each segment easy to imagine.\nIf you feel a sense of d√©j√† vu with the condition $B_{d}(x,\\varepsilon) \\cap A_{\\varepsilon} \\ne \\emptyset$ that makes $A_{\\varepsilon}$ a $\\varepsilon$-net, it‚Äôs fine to think of yourself as quite familiar with topology. This condition almost mirrors the criterion for determining whether a space is separable. Indeed, the conceptual difference between density and this lies in whether it\u0026rsquo;s finite or infinite. It\u0026rsquo;s harder to satisfy conditions for a finite set than an infinite set, and the subsequent theorem naturally holds true.\nTheorem [1]: Totally bounded spaces are separable. [2]: For metric spaces, being compact is equivalent to being complete and totally bounded. Proof [1] Finite sets are countable, which is trivial from the definition of separable spaces.\n‚ñ†\n[2] Deduced by detouring through sequential compactness.\n‚ñ†\nMunkres. (2000). Topology(2nd Edition): p275.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1420,"permalink":"https://freshrimpsushi.github.io/en/posts/1420/","tags":null,"title":"Completely Bounded Space"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Method 1 using LinearAlgebra\rusing Pkg\rPkg.add(\u0026#34;Plots\u0026#34;)\rPkg.add(\u0026#34;Distributions\u0026#34;)\rusing Plots The above code demonstrates importing the LinearAlgebra and Pkg packages and installing the Plots, Distribution packages using the .add() function. The keyword using to import packages is somewhat reminiscent of the language used in mathematics when applying a theorem or argument. Installing packages is more akin to R than Python, and its usage closely resembles that of Python. Similar to R, package names must be enclosed in double quotes, and it\u0026rsquo;s common to write package names in Pascal Case1 and frequently append an -s to make them plural2, which can be confusing.\nMethod 2 By typing ] in the REPL, you switch to the Package Manager environment as shown above. Pressing backspace will take you back to the REPL environment. Entering add package_name in the package manager environment will install the specified package.\n(@v1.5) pkg\u0026gt; add Plots Resolving package versions... Updating `C:\\Users\\rydbr\\.julia\\environments\\v1.5\\Project.toml` [91a5bcdd] + Plots v1.0.14 No Changes to `C:\\Users\\rydbr\\.julia\\environments\\v1.5\\Manifest.toml A notation method that capitalizes the first letter of each word. As seen in the example code, linear algebra is written as LinearAlgebra, with the first letter of each word capitalized and spaces omitted.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAs seen in the example code, Plot and Distribution need to be referred to as Plots and Distributions, respectively.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1416,"permalink":"https://freshrimpsushi.github.io/en/posts/1416/","tags":null,"title":"Installing and Using Packages in Julia"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 Let\u0026rsquo;s assume that a topological space $(X,\\mathscr{T})$ and a subset $A \\subset X$ are given. Then, the following set\n$$ \\mathscr{T}_{A} =\\left\\{ A\\cap U\\ :\\ U\\in \\mathscr{T} \\right\\} $$\nis a topology on $A$. In this case, $\\mathscr{T}_{A}$ is referred to as the Subspace Topology or Relative Topology. Moreover, the topological space $(A, \\mathscr{T}_{A})$ is called the Subspace of $(X,\\mathscr{T})$.\nTheorem [0]: For a topological space $(X, \\mathscr{T}$) and a subset $A \\subset X$, $$ \\mathscr{T}_{A} = \\left\\{ A\\cap U\\ :\\ U \\in \\mathscr{T}\\right\\} $$\nbecomes a topology on $A$.\nGiven a topological space $X$ and a subspace $A$, the equivalence condition for a set in subspace $A$ to be open or closed is as follows:\n[a1]: The necessary and sufficient condition for $V\\subset A$ to be an open set in $A$ is the existence of an open set $U$ in $X$ that satisfies $V= A\\cap U$. [b1]: The necessary and sufficient condition for $F\\subset A$ to be a closed set in $A$ is the existence of a closed set $E$ in $X$ that satisfies $F=A\\cap E$. Being an open (closed) set in a subspace does not guarantee the same property in the entire space. If a subspace is an open (closed) set with respect to the entire space, then this property is preserved in the entire space. Let\u0026rsquo;s consider a topological space $(X,\\mathscr{T})$, a subspace $(A,\\mathscr{T}_{A})$, and a subset $B\\subset A\\subset X$:\n[a2]: If $B$ is an open set in the subspace $A$ and $A$ is an open set in $X$, then $B$ is an open set in $X$. [b2]: If $B$ is a closed set in the subspace $A$ and $A$ is a closed set in $X$, then $B$ is a closed set in $X$. [3]: Let\u0026rsquo;s say $\\mathscr{B}$ is a basis of topological space $(X,\\mathscr{T})$. Then, $$ \\mathscr{B}_{A} =\\left\\{ A\\cap B\\ :\\ B\\in \\mathscr{B} \\right\\} $$\nis a basis for the subspace $(A,\\mathscr{T}_{A})$.\nExplanation To avoid confusion, let\u0026rsquo;s clarify several notations. If $(X,\\mathscr{T})$ is the entire space,\n$$ \\mathscr{T}_{A}=\\left\\{A\\cap U\\ :\\ U \\in \\mathscr{T} \\right\\} $$\nis the topology of the subset $A$. Hence, it forms the subspace $(A,\\mathscr{T}_{A})$. $\\mathscr{B}$ is a basis of the entire set $X$. $\\mathscr{B}_{A}$ is a collection of intersections between each element of the entire set\u0026rsquo;s basis and $A$. This becomes the basis of the subset $A$, as per the theorem.\n$$ \\mathscr{T}_{\\mathscr{B}_{A}}=\\left\\{U_{A}\\subset A\\ :\\ \\forall\\ x \\in U_{A},\\ \\exists\\ (A\\cap B) \\in \\mathscr{B}_{A}\\ \\ \\text{s.t.}\\ x\\in (A\\cap B) \\subset U_{A}\\right\\} $$\nMoreover, the core is that $\\mathscr{T}_{\\mathscr{B}_{A}}$ is equivalent to $\\mathscr{T}_{A}$. The content may feel complex. To summarize, it goes as follows:\nIntersections between elements of the entire space\u0026rsquo;s basis and $A$ form the basis of $A$. The topology generated by this basis is $\\mathscr{T}_{\\mathscr{B}_{A}}$. The topology $\\mathscr{T}_{\\mathscr{B}_{A}}$ generated in 2 consists of sets that are intersections between open sets of $X$ and $A$, which is $\\mathscr{T}_{A}$. Proof [0] $(T1)$: Since $A \\cap \\varnothing =\\varnothing$ and $A \\cap X=A$, both the empty set and the entire set belong to $\\mathscr{T}_{A}$. $(T2)$: Let\u0026rsquo;s assume $V_\\alpha \\in \\mathscr{T}_{A}( \\alpha \\in \\Lambda)$. By the definition of $\\mathscr{T}_{A}$, for each $V_\\alpha$, there exists $U_\\alpha$ satisfying $V_\\alpha = A \\cap U_\\alpha$. By the definition of topology, $U=\\cup_{\\alpha \\in \\Lambda} U_\\alpha \\in \\mathscr{T}$. Thus, $$ \\bigcup_{\\alpha \\in \\Lambda} V_\\alpha = \\bigcup_{\\alpha \\in \\Lambda} (A \\cap U_\\alpha ) =A\\cap (\\cup_{\\alpha \\in \\Lambda} U_\\alpha ) =A\\cap U \\in \\mathscr{T}_{A} $$\nand hence $\\bigcup _{\\alpha \\in \\Lambda} V_\\alpha \\in \\mathscr{T}_{A}$ is true.\n$(T3)$: Let\u0026rsquo;s assume $V_{1},\\ \\cdots\\ ,V_{n} \\in \\mathscr{T}_{A}$. Similarly, for each $V_{i}$, there exists $U_{i}$ satisfying $V_{i} =A \\cap U_{i}$. And since $U=\\cap _{i} U_{i} \\in \\mathscr{T}$, $$ \\bigcap _{i=1}^n V_{i} = \\bigcap_{i=1}^n (A\\cap U_{i}) = A\\cap \\left( \\bigcap_{i=1}^n U_{i} \\right) =A\\cap U \\in \\mathscr{T}_{A} $$\nis true. Therefore, $\\bigcap_{i=1}^n V_{i} \\in \\mathscr{T}_{A}$ is true.\nBy satisfying three conditions of topology, $\\mathscr{T}_{A}$ is a topology on $A$.\n‚ñ†\n[a1] Refer to the proof in metric spaces. It\u0026rsquo;s trivial by the definition of $\\mathscr{T}_{A}$.\n‚ñ†\n[b1] $(\\implies)$ If $F$ is a closed set in $A$, then $A-F$ is an open set in $A$. Hence, by [a1], there exists an open set $U$ in $X$ satisfying $A-F=A\\cap U$. Since $U$ is an open set, $E=X-U$ is a closed set in $X$. Then,\n$$ A\\cap E=A\\cap (X-U)=A-(A\\cap U)=A-(A-F)=F $$\n$(\\Longleftarrow )$ If $E$ is a closed set in $X$, then $X-E$ is an open set in $X$. Thus, by [a1], $A \\cap (X-E)$ is an open set in $A$. Since $F^c=A-(A\\cap E)=A\\cap(X-E)$, $F ^c$ is an open set in $A$. Therefore, $F$ is a closed set in $A$.\n‚ñ†\n[a2] If $B$ is an open set in $A$, by [a1], there exists an open set $U$ in $X$ satisfying $B=A\\cap U\\ (U\\in \\mathscr{T})$. By assumption, $A$ is an open set in $X$. Therefore, $B$ is the intersection of open sets in $X$, thus an open set in $X$.\n‚ñ†\n[b2] If $B$ is a closed set in\n$A$, by [b1], there exists a closed set $E$ in $X$ satisfying $B=A\\cap E$. By assumption, $A$ is a closed set in $X$, and $B$ is the intersection of closed sets, thus $B$ is also a closed set in $X$.\n‚ñ†\n[3] Part 1. $\\mathscr{B}_{A}$ is a basis for $A$.\n[b1]: For any $x\\in A$, since $A\\subset X$, $x\\in X$ is true. Since $\\mathscr{B}$ is a basis of $X$, by definition, there exists $B$ satisfying $x \\in B \\in \\mathscr{B}$. Hence, there exists $A\\cap B \\in \\mathscr{B}_{A}$ satisfying $x\\in (A\\cap B ) \\in \\mathscr{B}_{A}$. [b2]: For any $A\\cap B_{1}$, $A\\cap B_{2}$, and $x\\in \\Big( (A\\cap B_{1} ) \\cap (A \\cap B_{2}) \\Big)$, $$ (A\\cap B_{1})\\cap (A \\cap B_{2})=A\\cap B_{1}\\cap B_{2} $$ so, $x\\in (B_{1}\\cap B_{2})$ is true. Since $\\mathscr{B}$ is a basis of $X$, by definition, there exists $B_{3}$ satisfying $x\\in B_{3} \\subset ( B_{1}\\cap B_{2})$. Therefore, $$ x \\in (A\\cap B_{3})\\subset \\Big( A\\cap (B_{1}\\cap B_{2}) \\Big)=(A\\cap B_{1}) \\cap (A\\cap B_{2}) $$ As it satisfies the two conditions for being a basis according to conditions for a basis, $\\mathscr{B}_{A}$ is the basis for subset $A$.\nPart 2. $\\mathscr{T}_{\\mathscr{B}_{A}}=\\mathscr{T}_{A}$ is true.\n$(\\subset)$ Since $\\mathscr{B}$ is a basis of $(X,\\mathscr{T})$, $\\mathscr{T}_{\\mathscr{B}}=\\mathscr{T}$ and, therefore, $\\mathscr{B}\\subset \\mathscr{T_{\\mathscr{B}}}=\\mathscr{T}$ is true. Hence, for every $B \\in \\mathscr{B}$, $B\\in \\mathscr{T}$ is true. By the definition of $\\mathscr{T}_{A}$, $A\\cap B \\in \\mathscr{T}_{A}$ is true. Thus, $$ \\mathscr{B}_{A} \\subset \\mathscr{T}_{A} $$ $\\mathscr{T}_{\\mathscr{B}_{A}}$ is the smallest topology containing $\\mathscr{B}_{A}$, so $$ \\mathscr{T}_{\\mathscr{B}_{A}} \\subset \\mathscr{T}_{A} $$\n$(\\supset )$ Assume $V \\in \\mathscr{T}_{A}$. By [a1], there exists $U\\in \\mathscr{T}$ satisfying $V=A\\cap U$. For any point $x\\in V \\subset A$ of $V$, $x \\in U$ is true. Since $\\mathscr{B}$ is the basis generating $\\mathscr{T}$, there exists $B\\in \\mathscr{B}$ satisfying $x\\in B \\subset U$. Therefore, $A \\cap B \\in \\mathscr{B}_{A}$ satisfies $$ x\\in (A\\cap B) \\subset (A\\cap U) =V $$ This meets the condition for $V$ to belong to the topology $\\mathscr{T}_{\\mathscr{B}_{A}}$ generated by $\\mathscr{B}_{A}$, so $V \\in \\mathscr{T}_{\\mathscr{B}_{A}}$ is true. Therefore, $$ \\mathscr{T}_{\\mathscr{B}_{A}} \\supset \\mathscr{T}_{A} $$ ‚ñ†\nMunkres. (2000). Topology(2nd Edition): p89.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1439,"permalink":"https://freshrimpsushi.github.io/en/posts/1439/","tags":null,"title":"Subspace Topology, Relative Topology"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition Let space $S$ be both a metric space $( S , \\rho)$ and a measurable space $(S,\\mathcal{B}(S))$.\nMeasure Theory When a measure $\\mu$ defined on $S$ and a sequence of measures $\\left\\{ \\mu_n \\right\\}_{n \\in \\mathbb{N}}$ is $n \\to \\infty$, it is said to converge weakly to measure $\\mu$ if it satisfies the following for all $f \\in C_{b}(S)$: $$ \\int_{S} f d\\mu_{n} \\to \\int_{S} f d\\mu $$ It is denoted as $\\mu_{n}\\overset{W}{\\to}\\mu$.\nProbability Theory When a probability $P$ and a sequence of probabilities $\\left\\{ P_n \\right\\}_{n \\in \\mathbb{N}}$ defined on $S$ is $n \\to \\infty$, it is said to converge weakly to probability $P$ if it satisfies the following for all $f \\in C_{b}(S)$: $$ \\int_{S} f dP_{n} \\to \\int_{S} f dP $$ It is denoted as $P_{n}\\overset{W}{\\to}P$.\n$C_{b}(S)$ represents the set of bounded continuous functions defined on $S$ as follows: $$ C_{b}(S) := \\left\\{ f:S \\to \\mathbb{R} \\mid f\\text{ is bounded and continuous} \\right\\} $$ $\\displaystyle \\int_{S} f dP$ can be simply denoted as $\\displaystyle Pf := \\int_{S} f dP$. Description A primary application of the weak convergence of measures is in probability theory. This post is written assuming readers who are familiar with statistics rather than those new to topology. If your background is in mathematics, you can comfortably read about topology and see what aspects of it are needed in probability theory.\nStatistics In fact, weak convergence of probabilities (measures) can be seen as convergence in distribution explained by measure theory. Convergence in distribution encountered in mathematical statistics, for a single variable probability variable, is said to be $X_{n} \\overset{D}{\\to} X$ when there exists a cumulative distribution function $F_{X_{n}}$ for $X_{n}$ so that for every point $x \\in X$ where the cumulative distribution function $F_{X}$ is continuous, the following condition is met: $$ \\lim_{n\\to\\infty} F_{X_{n}}(x) = F(x) $$ Note that the above two formulas are similar in satisfying the condition for all $f \\in C_{b}(S)$. $$ \\lim_{n\\to\\infty} P_{n} f = P f $$ Do not think of a sequence of probabilities (measures) as something difficult; first approach it intuitively. The formula indicates that $f$ converges to $P f$ with a weight of $P_{n}$. The functions dealt with in probability theory are ultimately random variables, which could possibly be represented as $X_{n}\\equiv P_{n}f$, $X \\equiv Pf$. $$ X_{n} \\overset{D}{\\to}X \\overset{?}{\\iff} P_{n} \\overset{W}{\\to} P $$ What is not visible in the left formula is every point $x \\in S$ where $X$ is continuous, and in the right formula, it\u0026rsquo;s every bounded continuous function $f \\in C_{b}(S)$.\nTopology To discuss weak convergence, it is essential to be familiar with basic topology. Fortunately, spaces discussed in measure theory are quite intuitive, so knowing about metric spaces is sufficient for now. That space $S$ being both a metric space $( S , \\rho)$ and $(S,\\mathcal{B}(S))$ a measurable space means that $S$ contains the smallest sigma field that includes all open balls $B_{\\rho}(x , \\varepsilon) := \\left\\{ y \\in S : \\rho (x,y) \u0026lt; \\varepsilon \\right\\}$ created by distance function $\\rho$ for all $x \\in S$ and all $\\varepsilon\u0026gt;0$, i.e., the Borel sigma field $\\mathcal{B}(S)$.\nOpen sets are unions of open balls, and by the nature of sigma fields, their complements are also included in $\\mathcal{B}(S)$, meaning all closed sets must also belong to $\\mathcal{B}(S)$. For a simple example, consider $S=\\mathbb{R}$; $\\mathcal{B}(\\mathbb{R})$ consists of the following open and closed sets: $$ \\emptyset, \\mathbb{R}, [0,7], (-\\infty, \\pi) , \\left\\{ 1 \\right\\}, (-1,1) \\cap (0,9) $$ Moreover, according to other conditions of sigma fields, the following sets with mixed open and closed properties are also included. It would be nice to feel that the mentioned sets here are relatively intuitive. $$ [0,1), (-\\infty,\\pi], [\\pi , \\infty) , \\left\\{ 1 \\right\\} \\cup (-3,-2) $$ If you still find it difficult and cannot accept the definitions, it is recommended to study topology when you have the time. Of course, starting with topology to study probability theory might seem inefficient. But it\u0026rsquo;s not about efficiency; the experience itself can be very beneficial. Topology has many shocking, perverse, and extreme examples that abound. Experiencing the spicy taste of abstract mathematics will make you appreciate studying nice spaces like metric spaces and help develop a mathematical sense.\nHere is a useful theorem regarding this topic:\nTheorem Let $P$ be a probability defined in $(S,\\mathcal{B}(S))$. Then there exist closed sets $F_{\\varepsilon}$ and open sets $G_{\\varepsilon}$ that satisfy the following for all $A \\in \\mathcal{B}(S)$ and $\\varepsilon\u0026gt;0$: $$ F_{\\varepsilon}\\subset A \\subset G_{\\varepsilon} \\\\ P ( G_{\\varepsilon} \\setminus F_{\\varepsilon}) \u0026lt; \\varepsilon $$ Based on this theorem, the following corollary can be obtained: $$ \\begin{align*} P(A) =\u0026amp; \\sup \\left\\{ P(F) : F \\in \\mathcal{B}(S) \\text{ is closed in S} \\right\\} \\\\ =\u0026amp; \\inf \\left\\{ P(G) : G \\in \\mathcal{B}(S) \\text{ is open in S} \\right\\} \\end{align*} $$\nNeedless to say, since any topological space was originally $A^{\\circ} \\subset A \\subset \\overline{A}$, it must be possible to assert the existence of slightly smaller open sets and slightly larger closed sets than $A$, but it\u0026rsquo;s not as obvious that there exist slightly smaller closed sets and slightly larger open sets that satisfy $P ( G_{\\varepsilon} \\setminus F_{\\varepsilon}) \u0026lt; \\varepsilon$. This becomes apparent after confirming that probability $P$ is continuous because it is a measure.\nIndeed, looking at the above picture might be easier to understand than hearing a hundred words. This property enables finding a narrow band to navigate around the boundary $\\partial A$ of $A$ whenever $\\varepsilon \u0026gt; 0$ is given.\nSee Also Almost Surely Convergence $\\implies$ Probability Convergence $\\implies$ Distribution Convergence(Weak Convergence) Weak Convergence in Hilbert Space ","id":1410,"permalink":"https://freshrimpsushi.github.io/en/posts/1410/","tags":null,"title":"Convergence in Measure"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Theorem If the pi system $\\mathcal{P}$ is a subset of the lambda system $\\mathcal{L}$, then there exists a sigma field $\\sigma ( \\mathcal{P} )$ that satisfies $\\mathcal{P} \\subset \\sigma ( \\mathcal{P} ) \\subset \\mathcal{L}$.\n$\\sigma ( \\mathcal{P} )$ represents the smallest sigma field that contains all elements of $\\mathcal{P}$. Explanation At first glance, the statement might look rather simple, but as with such theorems, its proof is quite long and complicated. Let\u0026rsquo;s think about what roles the pi system $\\mathcal{P}$ and the lambda system $\\mathcal{L}$ play here.\nPi System and Lambda System:\nThe following is called a $\\pi$-system if it satisfies $$ A, B \\in \\mathcal{P} \\implies A \\cap B \\in \\mathcal{P} $$ The following are conditions that a $\\lambda$-system meets if it satisfies: (i): $\\emptyset \\in \\mathcal{L}$ (ii): $A \\in \\mathcal{L} \\implies A^{c} \\in \\mathcal{L}$ (iii): For all $i \\ne j$, when $\\displaystyle A_{i} \\cap A_{j} = \\emptyset$, then $\\displaystyle \\left\\{ A_{n} \\right\\}_{n \\in \\mathbb{N}} \\subset \\mathcal{L} \\implies \\bigcup_{n \\in \\mathbb{N}} A_{n} \\in \\mathcal{L}$ Measure theory, as the name suggests, is a theory about measuring things, so we inevitably have to consider measurable spaces and, whatever we do, there needs to be a sigma field. However, finding the exact sigma field suitable for a given problem might not be as easy as it seems. If there\u0026rsquo;s a constraint that this problem\u0026rsquo;s sigma field should be larger than the pi system but not larger than the lambda system, then through this theorem, one could obtain a specific sigma field $\\sigma ( \\mathcal{P} )$.\nThis means that when facing a daunting problem of finding a sigma field, one can start by creating a relatively easier-to-construct pi system. The lambda system must be built to include this simpler pi system, which process is typically more specific and easier than \u0026lsquo;just finding some sigma field\u0026rsquo;.\n","id":1405,"permalink":"https://freshrimpsushi.github.io/en/posts/1405/","tags":null,"title":"Dinkin's Pi-Lambda Theorem"},{"categories":"ÌôïÎ•†Î°†","contents":"Probability Convergence Defined Rigorously Given a probability space $( \\Omega , \\mathcal{F} , P)$.\nA sequence of random variables $\\left\\{ X_{n} \\right\\}_{n \\in \\mathbb{N}}$ is said to converge in probability to a random variable $X$ if it converges in measure to $X$, denoted as $X_{n} \\overset{P}{\\to} X$.\nIf you\u0026rsquo;re not yet familiar with measure theory, the term probability space can be disregarded. Explanation The convergence of $\\left\\{ X_{n} \\right\\}_{n \\in \\mathbb{N}}$ to $X$ means, for all $\\varepsilon \u0026gt; 0$, $$ \\lim_{n \\to \\infty} P \\left( \\left\\{ \\omega \\in \\Omega : | X_{n}(\\omega) - X(\\omega) | \\ge \\varepsilon \\right\\} \\right) = 0 $$ and in a more familiar form, it can be shown as follows: $$ \\lim_{n \\to \\infty} P \\left( | X_{n}(\\omega) - X(\\omega) | \u0026lt; \\varepsilon \\right) = 1 $$ Since a sequence of random variables is a stochastic process, it is inferred to be useful in the theory of stochastic processes.\nProperties of probability convergence from measure convergence:\n[3] If $X_{n}$ converges to $X$ almost surely, it implies probability convergence. [4] If $X_{n}$ converges to $X$ in $\\mathcal{L}_{p}$ convergence, it implies probability convergence. Since probability $P$ is a measure, it inherits the properties of measure convergence.\nSee Also Probability Convergence Defined in Mathematical Statistics Almost Sure Convergence $\\implies$ Probability Convergence $\\implies$ Distribution Convergence $\\mathcal{L}_{p}$ Convergence $\\implies$ Probability Convergence ","id":1397,"permalink":"https://freshrimpsushi.github.io/en/posts/1397/","tags":null,"title":"Convergence of Probabilities Defined by Measure Theory"},{"categories":"ÏßëÌï©Î°†","contents":"Definition 1 For any given set $X$, $\\text{card} X$ that satisfies the following properties is defined as the Cardinality of $X$.\n(i): $X = \\emptyset \\iff \\text{card} X = 0$ (ii): $A \\sim B \\iff \\text{card} A = \\text{card} B$ (iii): For some natural number $k$, if $X \\sim \\left\\{ 1 , 2, \\cdots , k \\right\\}$ then $\\text{card} X = k$ Specifically, the cardinality of a finite set is called a finite cardinality, and that of an infinite set is called a transfinite cardinality.\nFor two sets $A$ and $B$, if $A$ is equivalent to some subset of $B$ but $B$ is not equivalent to any subset of $A$, then it is said that $\\text{card} A$ is smaller than $\\text{card} B$, which is represented as follows: $$ \\text{card} A \u0026lt; \\text{card} B $$ For two disjoint sets $A$ and $B$, each having cardinalities $a = \\text{card} A$ and $b =\\text{card} B$ respectively, the cardinality of their union is called the sum of the cardinalities $a$ and $b$, and is represented as follows: $$ \\text{card} \\left( A \\cup B \\right):= a+b $$ For two sets $A$ and $B$, each having cardinalities $a = \\text{card} A$ and $b =\\text{card} B$ respectively, the cardinality of their Cartesian product is called the product of the cardinalities $a$ and $b$, and is represented as follows: $$ \\text{card} \\left( A \\times B \\right):= ab $$ For two sets $A$ and $B$, each having cardinalities $a = \\text{card} A$ and $b =\\text{card} B$ respectively, the cardinality of the set of all functions with domain $A$ and codomain $B$ $B^{A}$ is called the $b$ to the power of $a$ (cardinality), and is represented as follows: $$ \\text{card} \\left( B^{A} \\right):= b^{a} $$ Explanation Cardinality is an \u0026lsquo;abstraction of the size of a set\u0026rsquo;, and it is reasonable to say that it was introduced to make mathematically meaningful comparisons for infinite sets as well. Since it comes from the concept of the size of a set, it is often represented simply as $|X| := \\text{card} X$ when set theory is not the core or for convenience.\nCardinality has the following algebraic properties similar to natural numbers.\nBasic Properties 1 Let\u0026rsquo;s say $x,y,z$ is a cardinality.\n[1]: $$|A| \\le |B| \\land |A| \\ge |B| \\implies |A| = |B|$$ [2]: $$x + y = y+x \\\\ (x+y) + z = x + (y + z)$$ [3]: $$xy = yx \\\\ (xy)z = x(yz) \\\\ x ( y+z) = xy + xz$$ [4]: $$z^{x} z^{y} = z^{x+y} \\\\ \\left( z^{y} \\right)^{x} = z^{yx}$$ Translated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p241.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1395,"permalink":"https://freshrimpsushi.github.io/en/posts/1395/","tags":null,"title":"Cardinality of a Set"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition Let\u0026rsquo;s assume that a measure space $( X , \\mathcal{E} , \\mu)$ is given.\nGiven a set of Lebesgue integrable functions $\\Phi \\subset \\mathcal{L}^{1}$, if for every $\\varepsilon\u0026gt;0$, there exists $\\delta \u0026gt; 0$ that satisfies $$ \\mu (E) \u0026lt; \\delta \\implies \\sup_{f \\in \\Phi} \\int_{ E } \\left| f \\right| d \\mu \u0026lt; \\varepsilon $$ then $\\Phi$ is said to be uniformly integrable.\nExplanation The concept of uniform integrability approaches the set concept as suggested by the term Uniformly, meaning that if it belongs to $\\Phi$, there has to be a possibility for any function to make the norm $l_{1}$ value simultaneously smaller than $\\varepsilon$, that is, to have a narrow $E$ or in other words, a small $\\delta \u0026gt; \\mu (E)$. Explaining it this way as a set might be mathematically rigorous but not intuitively easy to understand. As an example of a set of functions, think of the sequence $\\left\\{ f_{n} \\right\\}_{n=1}^{\\infty}$, which can be explained more easily as follows: $$ \\mu (E) \u0026lt; \\delta \\implies \\sup_{n \\in \\mathbb{N}} \\int_{ E } \\left| f_{n} \\right| d \\mu \u0026lt; \\varepsilon $$ However, the reason for hesitation in using this representation is because a sequence is after all a countable set. From the standpoint of real analysis, which must serve as the basis of various theories, there seems to be an uncomfortable restriction of possibilities.\nOn the other hand, a good example of uniform integrability is the uniformly integrable martingale in the theory of stochastic processes.\n","id":1392,"permalink":"https://freshrimpsushi.github.io/en/posts/1392/","tags":null,"title":"Uniform Integrability"},{"categories":"ÏßëÌï©Î°†","contents":"Theorem 1 The open interval $(0,1)$ is an uncountable set.\nProof The set of real numbers $\\mathbb{R}$ is not a countable set, which is shown by the absence of a \u0026lsquo;one-to-one correspondence\u0026rsquo; between the set of real numbers and any countable set. This demonstrates that there is no one-to-one correspondence between the set of natural numbers and the open interval $(0,1)$, which can be obtained as a corollary.\nCantor proved this in an astonishing method, which remained as an achievement named \u0026lsquo;diagonal argument\u0026rsquo;. Regardless of the result, it\u0026rsquo;s a proof that can be appreciated for its beauty alone, so even if it doesn\u0026rsquo;t make sense after reading it a few times, keep reading until it does.\nProof Assuming that a one-to-one correspondence $f : \\mathbb{N} \\to (0,1)$ exists, ${ a } _{ ij }$ can be represented with $j$th digit after the decimal point as follows: $$ f(i)=0. { a } _{ i1 } { a } _{ i2 } { a } _{ i3 } { a } _{ i4 } \\cdots $$ Then, for natural numbers $i \\in \\mathbb{N}$, it could be represented in an arrangement like: $$ f(1)=0. { a } _{ 11 } { a } _{ 12 } { a } _{ 13 } { a } _{ 14 } \\cdots \\\\ f(2)=0. { a } _{ 21 } { a } _{ 22 } { a } _{ 23 } { a } _{ 24 } \\cdots \\\\ f(3)=0. { a } _{ 31 } { a } _{ 32 } { a } _{ 33 } { a } _{ 34 } \\cdots \\\\ \\vdots \\\\ f(k)=0. { a } _{ k1 } { a } _{ k2 } { a } _{ k3 } { a } _{ k4 } \\cdots \\\\ \\vdots $$ Here, let\u0026rsquo;s define $z \\in (0,1)$ as follows: $$ z=0. { z } _{ 1 } { z } _{ 2 } { z } _{ 3 } { z } _{ 4 } \\cdots, \\left( { z } _{ j } = \\begin{cases} 2 \u0026amp; { a } _{ jj } \\text{Í∞Ä ÌôÄÏàòÏùº Îïå} \\\\ 1 \u0026amp; { a } _{ jj } \\text{Í∞Ä ÏßùÏàòÏùº Îïå} \\end{cases} \\right) $$ This picks numbers whose parity is opposite to the numbers $a_{11} , a_{22} , \\cdots$ located on the diagonal in the above arrangement. Let\u0026rsquo;s just look at whether the $i$th digit after the decimal point of $z$ and $f(i)$ is odd or even. If $ { z }_{ i }$ is even, then ${ a } _{ ii }$ is odd, and if $\\ { z } _{ i }$ is odd, then ${ a } _{ ii }$ is even, hence $$ z\\neq f(1) \\\\ z\\neq f(2) \\\\ z\\neq f(3) \\\\ \\vdots \\\\ z\\neq f(k) \\\\ \\vdots $$ is true. Since $z \\neq f(i)$ for all natural numbers $i$, and $z \\notin f(\\mathbb{N}) $ while $f$ is a one-to-one correspondence, then $f(\\mathbb{N})=(0,1)$ and since $z \\in (0,1)$, $z\\in f(\\mathbb{N})$ must be true. This contradicts the assumption, so the one-to-one correspondence $f : \\mathbb{N} \\to (0,1)$ does not exist.\n‚ñ†\nÏù¥Ìù•Ï≤ú Ïó≠, You-Feng Lin. (2011). ÏßëÌï©Î°†(Set Theory: An Intuitive Approach): p231.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":109,"permalink":"https://freshrimpsushi.github.io/en/posts/109/","tags":null,"title":"Cantor's Diagonal Argument"},{"categories":"ÏßëÌï©Î°†","contents":"Definitions 1 A set $X$ is called a countable set if it is either a finite set or $X \\sim \\mathbb{N}$. A set that is not countable is called an uncountable set. $\\mathbb{N}$ is the set of natural numbers. $X \\sim Y$\u0026rsquo;s $\\sim$ denotes the equivalence of sets. Explanation The concept of countable sets might not be intuitively accepted by Easterners, including Koreans. This comes from a fundamental difference in thought between the language groups of Indo-European languages, including English, and our mindset. As known, European languages have gender for nouns, and verbs and adjectives inflect according to number and case, presenting \u0026lsquo;hard to sympathize with\u0026rsquo; grammatical characteristics. Especially regarding numbers, before even touching on grammar, there\u0026rsquo;s a lot of puzzlement about why such distinctions are made, and this linguistic mindset difference manifests itself in the difference between Eastern and Western mathematics.\nTo count means to be able to count \u0026lsquo;one, two, \u0026hellip;\u0026rsquo; and how many items there are. For instance, humans, wrist watches, and oranges. Uncountable things include water or bread, which have a quantity, not a count, and can be arbitrarily divided. Thus, A dog means one dog and Dogs means several dogs, but Dog would mean dog meat. Obviously, context exists in language, and it\u0026rsquo;s not interpreted this extremely, but it\u0026rsquo;s possible.\nIt seems explaining the why behind this distinction is harder than explaining that we also use weird expressions. For example, in East Asian countries including Korea, we use \u0026lsquo;useless\u0026rsquo; units like person for people, animal for creatures, long thin objects receive a unit, as do thin broad objects and buildings, etc. It doesn\u0026rsquo;t mean these expressions are never used in English or that Korean always uses them, but it\u0026rsquo;s important that we naturally accept them at the base of our thought process.\nThat is, although one could simply say \u0026ldquo;one pencil,\u0026rdquo; if someone asks to \u0026ldquo;borrow one pencil,\u0026rdquo; the natural feeling that it doesn\u0026rsquo;t feel odd to count pencils by the unit decides the real language habit. If one doesn\u0026rsquo;t fully internalize English to the bone, even if their English is good enough to not hinder communication, the usage of articles like a, the could be all over the place, feeling awkward. That\u0026rsquo;s just how language is. You accept it, and there\u0026rsquo;s no choice but to accept it. And the differences between languages are essentially nothing to worry about since it\u0026rsquo;s just how things always have been.\n[1]: If $X \\sim \\mathbb{Z}$, then $X$ is a countable set. [2]: If $X \\sim \\mathbb{Q}$, then $X$ is a countable set. [3]: If $X \\sim \\mathbb{R}$, then $X$ is an uncountable set. Surprisingly, such differences also manifest in actual mathematics, and, as [3] suggests, it\u0026rsquo;s possible to explicitly propose uncountable sets. This fact was proven by the father of set theory, Georg Cantor, who himself was amazed by the existence of such uncountable sets. But could such concepts, not to mention the distinction between singular and plural, have emerged in East Asian mathematics? While it\u0026rsquo;s not possible to say for sure, it took a staggering 2500 years after Pythagoras for a single genius to discover uncountable sets. If pure mathematics had developed in the East, there might have been amazing discoveries from an Eastern perspective, but the concepts of countable and uncountable sets are definitely a legacy left by the Indo-European languages.\nProof Perhaps Cantor had initially tried to prove that all infinite sets are countable. Because intuitively, that seems simpler, and if true, it means all sets can be thought of as being brought down to natural numbers. To follow Cantor\u0026rsquo;s journey, let\u0026rsquo;s look at the proofs of [1] and [2] first.\n[1] We show that there exists a bijection between $\\mathbb{N}$ and $\\mathbb{Z}$. By defining the following correspondence, it becomes a bijection. $$ (1,2,3,4,5, \\cdots ) \\mapsto (0,-1,1,-2,2, \\cdots ) $$\n‚ñ†\n[2] We show that there exists a bijection between $\\mathbb{N}$ and $\\mathbb{Q}$. Let\u0026rsquo;s define the following correspondence. $$ \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 6 \u0026amp; 7 \u0026amp; \\cdots \\\\ 3 \u0026amp; 5 \u0026amp; 8 \u0026amp; \\ddots \u0026amp; \\\\ 4 \u0026amp; 9 \u0026amp; \\ddots \u0026amp; \u0026amp; \\\\ 10 \u0026amp; \\ddots \u0026amp; \u0026amp; \\\\ \\vdots \u0026amp; \u0026amp; \\end{bmatrix} \\mapsto \\begin{bmatrix} 1/1 \u0026amp; 1/2 \u0026amp; 1/3 \u0026amp; 1/4 \u0026amp; \\cdots \\\\ 2/1 \u0026amp; 2/2 \u0026amp; 2/3 \u0026amp; \\ddots \u0026amp; \\\\ 4/1 \u0026amp; 4/2 \u0026amp; \\ddots \u0026amp; \u0026amp; \\\\ 5/1 \u0026amp; \\ddots \u0026amp; \u0026amp; \\\\ \\vdots \u0026amp; \u0026amp; \\end{bmatrix} $$ After simplifying, there will be duplicate elements and those that are not. For example, $2/2 = 1/1$ is therefore a duplicate. Now, let\u0026rsquo;s correspond these elements with non-duplicate elements multiplied by $-1$ in order. $$ \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 6 \u0026amp; 7 \u0026amp; \\cdots \\\\ 3 \u0026amp; 5 \u0026amp; 8 \u0026amp; \\ddots \u0026amp; \\\\ 4 \u0026amp; 9 \u0026amp; \\ddots \u0026amp; \\\\ 10 \u0026amp; \\ddots \u0026amp; \\\\ \\vdots \u0026amp; \u0026amp; \\end{bmatrix} \\mapsto \\begin{bmatrix} 1/1 \u0026amp; 1/2 \u0026amp; 1/3 \u0026amp; 1/4 \u0026amp; \\cdots \\\\ 2/1 \u0026amp; -(1/1) \u0026amp; 2/3 \u0026amp; \\ddots \u0026amp; \\\\ 4/1 \u0026amp; -(1/2) \u0026amp; \\ddots \u0026amp; \u0026amp; \\\\ 5/1 \u0026amp; \\ddots \u0026amp; \u0026amp; \\\\ \\vdots \u0026amp; \u0026amp; \\end{bmatrix} $$ Then, this correspondence becomes a bijection.\n‚ñ†\n[3] Even from middle school, when we learn about numbers, we go through natural numbers, integers, rational numbers, real numbers, and complex numbers. Clearly, Cantor would have tried to find a bijection that demonstrated $\\mathbb{N} \\sim \\mathbb{R}$. However, it\u0026rsquo;s likely that these attempts failed one after another, and eventually, he tried to prove that such a bijection does not exist. The method he used at this point is the famous Cantor\u0026rsquo;s diagonal argument.\nTranslated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p219.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1383,"permalink":"https://freshrimpsushi.github.io/en/posts/1383/","tags":null,"title":"Countable and Uncountable Sets"},{"categories":"ÏßëÌï©Î°†","contents":"## Definition [^1] [^1]: Translated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p205, 215. 1. If there exists a [bijection](../471) $f : X \\to Y$ between two [sets](../1316) $X,Y$, then $X$ and $Y$ are said to be **equipotent** and denoted as $X \\sim Y$. 2. If for some non-[empty set](../1337) $X$, any [proper subset](../1329) $Y \\subsetneq X$ satisfies $X \\sim Y$, then $X$ is called an **infinite set**. 3. Any set that is not infinite is called a **finite set**. ## Explanation 1. When trying to explain infinity without employing set theory, the concept of equipotency is often likened to a shepherd letting sheep out of a pen. If one prepares enough pebbles and puts one into a basket every time a sheep leaves the pen, then the number of sheep that have left will equal the number of pebbles. Conversely, when bringing sheep back into the pen, one can count them by removing a pebble from the basket for each sheep. If these numbers match exactly, then the shepherd has not lost any sheep. Abstractly, putting pebbles into and taking them out of a basket corresponds to the mapping represented by a bijection $f$. For instance, the set of natural numbers $\\mathbb{N}$ has a bijection $g(n) = 2n$ existing with the set of even numbers $2 \\mathbb{N}$, showing they are equipotent. Such a correspondence also exists for a closed interval $[0,1]$ via $g(x) = 2x$ showing that $[0,1] \\sim [0,2]$. Notice that $2 \\mathbb{N} \\subsetneq \\mathbb{N}$ and $[0,1] \\subsetneq [0,2]$. While the concept of equipotence was introduced to explain the size of sets, it does not lead to an inclusion relationship. 2. Note that the definition of an infinite set avoids using the word \u0026#39;infinite\u0026#39;. This implies that the essence of infinity \u0026#39;allows for something between the whole and its part\u0026#39;. Thus, infinity, which naturally arises in human intuition, differs and led to the birth of set theory, often explained through metaphors like the **Hilbert\u0026#39;s hotel**. ## Basic Properties The following are the basic properties that finite and infinite sets possess. Understanding the concept of equipotency should make these fairly straightforward to grasp. - [0] The [empty set](../1337) is a [finite set](../1381). - [1] The superset of an infinite set is an infinite set. - [2] The subset of a finite set is a [finite set](../1381). - [3] If equipotent with an infinite set, it is an infinite set. - [4] If equipotent with a [finite set](../1381), it is a finite set. - [5] The difference set, subtracting a finite set from an infinite set, is an infinite set. ","id":1381,"permalink":"https://freshrimpsushi.github.io/en/posts/1381/","tags":null,"title":"Finite Sets and Infinite Sets Strictly Defined by Set Theory"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code julia\u0026gt; typeof(0)\rInt64\rjulia\u0026gt; typeof(0.0)\rFloat64\rjulia\u0026gt; typeof(0 == 0.0)\rBool\rjulia\u0026gt; typeof(Bool)\rDataType\rjulia\u0026gt; typeof(NaN)\rFloat64\rjulia\u0026gt; typeof(Inf)\rFloat64\rjulia\u0026gt; typeof(\u0026#39;O\u0026#39;)\rChar\rjulia\u0026gt; typeof(\u0026#34;Ohmygirl\u0026#34;)\rString\rjulia\u0026gt; typeof(\u0026#34;O\u0026#34;)\rString Julia includes all sorts of types. $0$ and $0.0$ are the same $0$, but have different types, and as you can see, even a type like Bool has a type named DataType. Like in C, String is an array of Chars, differentiated by whether it uses double or single quotes.\n","id":1379,"permalink":"https://freshrimpsushi.github.io/en/posts/1379/","tags":null,"title":"Julia's Types and Annotations"},{"categories":"ÏßëÌï©Î°†","contents":"Definition 1 Let\u0026rsquo;s say $x \\in X$, $y \\in Y$, and $f: X \\to Y$ are functions.\nFor every $x_{1}, x_{2} \\in X$, if $x_{1} \\ne x_{2} \\implies f(x_{1}) \\ne f(x_{2})$ then $f$ is called injective. If $f(X) = Y$, then $f$ is called surjective. If $f$ is both injective and surjective, it is called bijective. $I : X \\to X$ that satisfies $I(x) = x$ is called an Identity Function. For every $x, y$, if $f(x) = y$ and $f^{-1} (y) = x$ is satisfied, then $f^{-1} : Y \\to X$ is called the Inverse Function of $f$. Basic Properties [1]: The identity function is bijective. [2]: $f$ being bijective is equivalent to the existence of inverse function $f^{-1}$. Explanation Injective functions are also called one-to-one, or one-to-one functions. Surjective functions are also called onto. Bijective functions are also referred to as one-to-one correspondence. In entrance exams, the concept of one-to-one correspondence might not seem very important, but it truly is. Many students struggling with math have either never heard of it or think it\u0026rsquo;s useless for problem-solving. Although not entirely incorrect, not knowing this concept likely means being unaware of other necessary problem-solving elements as well.\nEven students who are relatively good at math might only truly understand the significance of bijective functions when they encounter university-level math. The notion of one-to-one correspondence is not limited to set theory but is a crucial concept in the vast domain of mathematics, regardless of the subject area. However, because of its powerful implications, paradoxically, mathematicians often research ways to relax the conditions for bijection. This includes methods to deduce bijection under different conditions or use functions as if they are bijective even when they are not.\nTo briefly illustrate its importance, it\u0026rsquo;s so critical that saying \u0026lsquo;it\u0026rsquo;s important to know correctly\u0026rsquo; would be an understatement. Like it or not, bijections feature across various subjects, so not fully understanding them by the time of graduation is arguably more challenging.\nTranslated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p165, 181~187.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":471,"permalink":"https://freshrimpsushi.github.io/en/posts/471/","tags":null,"title":"Injection, Surjection, Bijection, Inverse Function"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Julia has been developed at MIT and publicly released in 2012, aiming for a language that is both highly productive and fast. It achieves speeds comparable to C or Fortran while also providing a high-level syntax similar to Python or R, among absorbing benefits from various other languages. As of November 2019, it\u0026rsquo;s true that Julia is somewhat lagging due to the rapid advancement of GPUs and the prevalence of deep learning, but there is still no language that surpasses Julia in terms of convenience and speed in the academic field.\nIf you have any questions or comments about Julia, post them on the Freshrimp Sushi Community üí¨.\nKey Features Let\u0026rsquo;s take a look at Julia\u0026rsquo;s features:\nIt\u0026rsquo;s fast. No other words are needed. The benchmarks show that it is on par with C and Fortran. It\u0026rsquo;s simple. If optimization isn\u0026rsquo;t a concern, programming in Julia is quite similar to Matlab, R, or Python. The unnecessary hassle of rewriting the same code in C for optimization after implementing a program in these languages does not exist. Instead, it only requires improving through coding techniques appropriate for Julia. Similarly, if the user is familiar with Matlab, R, or Python, picking up Julia can be quick. In reality, due to the high productivity of these languages, Julia feels easy regardless of the base programming language. It\u0026rsquo;s free. MATLAB supports powerful linear algebra but is expensive, and Julia can be 10 to 1,000 times faster depending on the optimization. Additionally, using the MATLAB.jl package allows for writing code in a similar style to MATLAB, making it convenient for users skilled in MATLAB to transition. Packages from other languages can be easily imported. The biggest weakness of a new language, and one of the main reasons languages like Fortran or Python are used, is the package ecosystem. For Python, the package PyCall.jl enables direct calling of Python functions. Although Julia is sufficiently high-performing on its own, it allows calling C or Fortran functions through the ccall() function. C++ is also supported through the Cpp.jl package. Specialized for parallel processing. Unlike other languages that have developed related packages after the fact, Julia was developed from the ground up with parallel processing in mind. Indeed, depending on the program, it could be not just convenient but central to optimization. ","id":1374,"permalink":"https://freshrimpsushi.github.io/en/posts/1374/","tags":null,"title":"Julia Programming Language"},{"categories":"ÏßëÌï©Î°†","contents":"Definition 1 For functions $f: X \\to Y$ and $B \\subset Y$, $f^{-1}(B): = \\left\\{ x \\in X \\ | \\ f(x) \\in B \\right\\}$ is called the preimage or inverse image according to $f$ of $B$.\nExplanation Though the notation is similar, one cannot say that the inverse image and the inverse function are related just by the definitions alone, and one should not confuse them.\nSome people might find [preimage] more natural in English as opposed to how naturally \u0026ldquo;inverse image\u0026rdquo; sounds in Korean. This might be because the Chinese character for inverse, which simply means \u0026lsquo;where it came from,\u0026rsquo; fits the concept of inverse image well. In contrast, the term [inverse] might remind one of inverse functions, hence people might consciously avoid using it. Of course, there are also simpler reasons like [preimage] being easier to pronounce, thus being used more often, and the prefix \u0026lsquo;pre-\u0026rsquo; being unfamiliar, thus avoided.\nBasic Properties [1] Empty set: $$ f ( \\emptyset ) = \\emptyset $$ [2] Singleton set: $$ x \\in X \\implies f \\left( \\left\\{ x \\right\\} \\right) = \\left\\{ f(x) \\right\\} $$ [3] Monotonicity: $$ A \\subset B \\subset X \\implies f (A) \\subset f(B) \\\\ C \\subset D \\subset Y \\implies f^{-1} (C) \\subset f^{-1} (D) \\\\ f(X) \\subset Y \\iff X \\subset f^{-1} (Y) $$ [4] Union: $$ f \\left( \\bigcup_{\\gamma \\in \\Gamma} A_{\\gamma} \\right)= \\bigcup_{\\gamma \\in \\Gamma } f \\left( A_{\\gamma} \\right) \\\\ f^{-1} \\left( \\bigcap_{\\gamma \\in \\Gamma} A_{\\gamma} \\right) = \\bigcap_{\\gamma \\in \\Gamma } f^{-1} \\left( A_{\\gamma} \\right) $$ [5] Intersection: $$ f^{-1} \\left( \\bigcup_{\\gamma \\in \\Gamma} A_{\\gamma} \\right)= \\bigcup_{\\gamma \\in \\Gamma } f^{-1} \\left( A_{\\gamma} \\right) \\\\ f \\left( \\bigcap_{\\gamma \\in \\Gamma} A_{\\gamma} \\right) {\\color{red}\\subset} \\bigcap_{\\gamma \\in \\Gamma } f \\left( A_{\\gamma} \\right) $$ [6] Difference set: $$ f (A) \\setminus f (B) \\subset f (A \\setminus B) \\\\ f^{-1} (C) \\setminus f^{-1}(D) = f^{-1} (C \\setminus D) $$ Note especially in [5], [6] that a function cannot preserve the intersection as it is. To satisfy equality, $f$ must be injective.\nUnlike the concept of bijection and inverse function, which one can become familiar with through repetition, it\u0026rsquo;s necessary to learn about the inverse image quickly and accurately. Skimming over the concept of inverse image can lead to a lack of intuition about null spaces in linear algebra, which, if not addressed, can even affect abstract algebra. Since there are many properties different from the function\u0026rsquo;s range, it is not just the opposite; one must study properly to fully understand.\nTranslated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p173.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":472,"permalink":"https://freshrimpsushi.github.io/en/posts/472/","tags":null,"title":"The Original Image of a Function"},{"categories":"ÏßëÌï©Î°†","contents":"Definitions 1 Let\u0026rsquo;s assume two sets $X$, $Y$ that are not empty sets are given.\nA binary relation $f \\subset (X,Y)$ is called a function if it satisfies the following and is denoted as $f : X \\to Y$. $$ (x ,y_{1}) \\in f \\land (x,y_{2}) \\in f \\implies y_{1} = y_{2} $$ For the function $f : X \\to Y$, $\\text{Dom} (f) = X$ is called the domain of $f$, and $Y$ is called the codomain of $f$. Given a subset $A \\subset X$ of the domain, $f(A):= \\left\\{ f(x) \\in Y \\ | \\ x \\in A \\right\\}$ is called the image of $A$ under $f$. Especially, the image of the domain $X$ under $f$, $\\text{Im} f := f(X)$, is called the range of $f$. A function whose domain is the set of natural numbers $\\mathbb{N}$ is called a sequence. The set of all functions that have the domain $A$ and the codomain $B$ is denoted as $B^{A}$. Explanation At the curriculum level, it\u0026rsquo;s said that \u0026lsquo;a correspondence $f : X \\to Y$ from $X$ to $Y$ is a function if for every element $x_{1}, x_{2} \\in X$, there exist $f(x_{1})$ and $f(x_{2})$ in $Y$ satisfying $x_{1} = x_{2} \\implies f(x_{1}) = f(x_{2})$. However, this \u0026lsquo;correspondence\u0026rsquo; or \u0026lsquo;mapping\u0026rsquo; was somewhat ambiguous in expression. In mathematics beyond undergraduate levels, concepts related to functions are rigorously defined through set theory using the notion of relations. The explanation that a function yields only one output for an input is more suited to functions in computer science. You may wonder why it\u0026rsquo;s necessary to define the range separately. For example, if we consider $f(x) = x^2$, it is obvious that the function values belong to $\\left[ 0,\\infty \\right)$, and there seems no need to set it unnecessarily large like $f : \\mathbb{R} \\to \\mathbb{R}$. Essentially, the range is just a subset of the codomain, and it\u0026rsquo;s hard to understand why we bother setting aside values that won\u0026rsquo;t be used in practice.\nThis misunderstanding comes from thinking only of overly simple examples; not all functions can have their ranges easily predicted from the beginning. All that can be ensured when defining a function is that for $x \\in X$, there exists a $f(x) \\in Y$, but what that is, is unknown. If there is a complex function like $$ f(x) = \\sin \\ln \\sqrt{x} + \\int_{1}^{3^x} {{1} \\over {7t+t^2}} dt $$ identifying its range from the beginning is not possible, nor necessary. Generally, knowing the range is important mainly when defining composite functions. The definition of a sequence as simply an arrangement of numbers is simpler and more general, confirming it\u0026rsquo;s more than just counting numbers. Its codomain can be functions, any incredibly unique set, and this abstraction not only cleanly expresses the concept of sequences but also allows for flexible application in many mathematical fields dealing with infinity. The concept of a set of functions might be unfamiliar, but in abstract mathematics, sets such as function spaces are routinely mentioned. Understanding why notations like $B^{A}$ are used becomes easier when recalling concepts like cardinals. For instance, considering all functions whose codomain is $B$ and domain is $A$, like $$ e \\mapsto 1 \\text{ or } 2 \\text{ or } 3 \\\\ \\pi \\mapsto 1 \\text{ or } 2 \\text{ or } 3 $$ all possible combinations result in $9 = 3^2 = |B|^{|A|}$. Translated by Heung-Chun Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p157~159.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":470,"permalink":"https://freshrimpsushi.github.io/en/posts/470/","tags":null,"title":"Functions and Mappings Rigorously Defined by Set Theory, Sequences"},{"categories":"ÏßëÌï©Î°†","contents":"Definition 1 Let\u0026rsquo;s say a equivalence relation $R$ is defined on a set $X$. For $x \\in X$, $x / R := \\left\\{ y \\in X : y R x \\right\\}$ is called the equivalence class of $x$. The set of all equivalence classes given by $X$ is represented as $X / R := \\left\\{ x / R : x \\in X \\right\\}$.\nExplanation Though the expression might look a bit messy, it\u0026rsquo;s not a difficult concept at all if you think of an example. On the set of natural numbers $\\mathbb{N}$, let\u0026rsquo;s say that if the remainder when divided by $3$ is the same, they are equivalent, and if $x,y \\in \\mathbb{Z}$ are equivalent, let it be represented as $x \\equiv y \\pmod{3}$. Since $5,7$ have different remainders when divided by $3$, which are $2,1$ respectively, they are not equivalent but $11,17$, having the remainder $2$ when divided by $3$, can be written as $11 \\equiv 17 \\pmod{3}$. $$ 1 \\equiv 4 \\equiv 7 \\equiv 10 \\equiv \\cdots \\pmod{3} \\\\ 2 \\equiv 5 \\equiv 8 \\equiv 11 \\equiv \\cdots \\pmod{3} \\\\ 3 \\equiv 6 \\equiv 9 \\equiv 12 \\equiv \\cdots \\pmod{3} $$ As can be seen from the calculation above, the equivalence class of $1$ is $( 1 / \\equiv) = \\left\\{ 1, 4, 7, 10, \\cdots \\right\\}$, and the equivalence class of $2$ is $(2 / \\equiv) = \\left\\{ 2, 5, 8, 11, \\cdots \\right\\}$, and the equivalence class of $3$ is $(3 / \\equiv) = \\left\\{ 3, 6, 9, 12, \\cdots \\right\\}$. From numbers larger than $3$, these three equivalence classes repeat, and thus, $$ (\\mathbb{N} / \\equiv) = \\left\\{ 1 / \\equiv , 2 / \\equiv , 3 / \\equiv \\right\\} $$ As can be seen from the example above, equivalence classes have the following common-sense properties.\nBasic Properties [1] $x / R \\ne \\emptyset$ [2] $ x / R \\cap y / R \\ne \\emptyset \\iff xRy$ [3] $x/R = y/R \\iff x R y$ [4] $x / R \\cap y / R \\ne \\emptyset \\iff x/R = y/R $ Proof [1] Since $R$ is an equivalence relation on $X$, by reflexivity, for all $x \\in X$, $x R x$, and $x \\in x / R$ must hold.\n‚ñ†\nStrategy [2][3]: Take an arbitrary $z$, separate from $x,y$, and connect the equations using the symmetry and transitivity of the equivalence relation.\n[2] $x/R$ and $y/R$ are not empty sets and are equivalence relations on $X$, so $x/R \\cap y/R \\ne \\emptyset$, which is equivalent to $$ \\begin{align*} \u0026amp; z \\in x / R \\land z \\in y / R \\\\ \\iff \u0026amp; z R x \\land z R y \\\\ \\iff \u0026amp; x R z \\land z R y \\\\ \\iff \u0026amp; x R y \\end{align*} $$ for some $z$.\n‚ñ†\n[3] $( \\implies )$ If $x/R = y/R$, then $x/R \\cap y/R \\ne \\emptyset$, so by [2], $x R y$\n$( \\impliedby )$ If $x R y$, for all $z \\in x / R$, $z R x$. Since $x R y$, by the transitivity of $R$, $z R y$ and $z \\in y / R$. To summarize, $$ z \\in x / R \\implies z \\in y / R $$ If we change it to the form of a set inclusion relation, $$ x / R \\subset y / R $$ Similarly, we can obtain $ y / R \\subset x / R$, so $$ x / R = y / R $$\n‚ñ†\n[4] Following the principle of syllogism, from [2] and [3], $$ x / R \\cap y / R \\ne \\emptyset \\iff xRy \\iff x/R = y/R $$\n‚ñ†\nÏù¥Ìù•Ï≤ú Ïó≠, You-Feng Lin. (2011). ÏßëÌï©Î°†(Set Theory: An Intuitive Approach): p147.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1050,"permalink":"https://freshrimpsushi.github.io/en/posts/1050/","tags":null,"title":"Homotopy Type"},{"categories":"ÏßëÌï©Î°†","contents":"Definition 1 A partition of a set $X$ consists of all subsets $A,B,C$ of $X$ that satisfy the following conditions:\n(i): $$A,B \\in \\mathscr{P} \\land A \\ne B \\implies A \\cap B = \\emptyset$$ (ii): $$\\bigcup_{C \\in \\mathscr{P} } C = X$$ Explanation Although the mathematical expression might seem complex, simply put, it\u0026rsquo;s just about dividing the entire set into several parts without omission. If there\u0026rsquo;s leeway to delve into the mathematical definitions, it would be better to pay attention to details such as the partition $\\mathscr{P}$ of $X$ being a subset of the power set $2^{X} = \\mathscr{P} (X)$ of $X$.\nAs a simple example, consider the set of integers $\\mathbb{Z}$. The set that includes the set of even numbers $2 \\mathbb{Z} = \\left\\{ \\cdots , -2 , 0 , 2 , \\cdots \\right\\}$ and the set of odd numbers $1 + 2 \\mathbb{Z} = \\left\\{ \\cdots , -3 , -1 , 1 , 3 , \\cdots \\right\\}$ becomes a partition of $\\mathbb{Z}$. Here, $\\mathscr{P} \\subset 2^{\\mathbb{Z}}$ is a set that contains subsets of $\\mathbb{Z}$, and the number of elements is $2$. It\u0026rsquo;s good to practice understanding exactly what belongs where and whether it is an element or a set, according to the definition, without glossing over.\nTranslated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p147.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1049,"permalink":"https://freshrimpsushi.github.io/en/posts/1049/","tags":null,"title":"Partition of a Set"},{"categories":"ÏßëÌï©Î°†","contents":"Definition 1 A binary relation that is reflexive, symmetric, and transitive is called an equivalence relation.\nExplanation To put the concept of an equivalence relation in non-mathematical terms, it\u0026rsquo;s like saying \u0026ldquo;it\u0026rsquo;s all the same.\u0026rdquo;\nWhile it\u0026rsquo;s not always necessary to have a reason when studying mathematics, if there were to be a practical reason for studying mathematics, it could be said to \u0026ldquo;simplify complex concepts into easier, more manageable areas to comfortably solve problems.\u0026rdquo; In order to discuss this, one must be able to express that things are \u0026ldquo;essentially the same,\u0026rdquo; which is exactly what an equivalence relation is.\nExamples of equivalence relations include $=$, $\\equiv$, $\\iff$, but just these examples might not fully illustrate why equivalence relations are important in mathematics. It feels too natural now to adopt a new perspective.\nFor instance, let\u0026rsquo;s say we have a set like $Q$. If we represent the ordered pair $(n,m)$ as $\\displaystyle (n,m) = {{n} \\over {m}}$, then $Q$ is essentially the same as the well-known set of rational numbers, $\\mathbb{Q}$. However, upon closer inspection, we cannot say that $Q$ and $\\mathbb{Q}$ are the same set because $(2,3)$ and $(4,6)$ are different elements in $Q$, whereas $\\displaystyle {{2} \\over {3}}$ and $\\displaystyle {{4} \\over {6}}$ are considered the same element in $\\mathbb{Q}$. The difference between $Q$ and $\\mathbb{Q}$ lies in whether there is simplification or not.\nIn $\\mathbb{Q}$, we can discover a familiar equivalence relation. If we call this equivalence relation $\\sim$, it can be defined as follows: $$ {{ a } \\over { b }} \\sim {{ c } \\over { d }} \\iff ad = bc $$ In fact, considering $\\displaystyle {{2} \\over {3}}$ and $\\displaystyle {{4} \\over {6}}$, since $2 \\cdot 6 = 12 = 3 \\cdot 4$, it follows that $\\displaystyle {{2} \\over {3}} \\sim {{4} \\over {6}}$, meaning the two elements can be said to be equivalent in $\\mathbb{Q}$. On the other hand, without such an equivalence relation being given in $Q$, although we know $(2,3)$ and $(4,6)$ are essentially the same, we cannot expressly say so.\nThus, the process of stating that things that are originally the same as being the same may seem needless and overly theoretical at first glance. Our intuition already knows they are the same, but it feels like we\u0026rsquo;re saying the same thing again using difficult language and symbols. However, rigor is considered a supreme value in mathematics, and this process is unavoidable while simultaneously, it can be used to break through the limits of mathematics. For instance, consider bending a line segment and joining the ends together as shown in the picture. When it was a line segment, the two points were clearly different. However, by applying an equivalence relation and treating the two points as essentially the same, a completely new loop is created. The field of topology studies such phenomena, expressing the act of \u0026ldquo;joining\u0026rdquo; in mathematical terms through the use of equivalence relations.\nTranslated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p141.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1033,"permalink":"https://freshrimpsushi.github.io/en/posts/1033/","tags":null,"title":"Equivalence Relations in Mathematics"},{"categories":"ÏßëÌï©Î°†","contents":"Definition 1 For two sets $X,Y$, $$ R := \\left\\{ (x,y): x \\in X , y \\in Y \\right\\} \\subset X \\times Y $$ is defined as a (binary) relation and is represented as follows: $$ (x,y) \\in R \\iff x R y $$ $x R y \\iff y R^{-1} x$ satisfying $$ R^{-1} : \\left\\{ (y,x): (a,b) \\in R \\right\\} $$ is called the inverse relation of $R$. For all $x \\in X$, $ R \\subset X^{2}$ satisfying the following condition is called reflexive: $$ x R x $$ For all $x,y \\in X$, $ R \\subset X^{2}$ satisfying the following condition is called symmetric: $$ x R y \\implies y R x $$ For all $x,y,z \\in X$, $ R \\subset X^{2}$ satisfying the following condition is called transitive: $$ x R y \\land y R z \\implies x R z $$ For all $x,y \\in X$, $ R \\subset X^{2}$ satisfying the following condition is called antisymmetric: $$ x R y \\land y R x \\implies x = y $$ Explanation Binary relations are not ambiguously described as \u0026lsquo;something being related to something in some way\u0026rsquo; but can be clearly defined using Cartesian product. A relation is precisely a subset of a Cartesian product, and by looking at $x R y$, one should not understand it as \u0026lsquo;$x$ is somehow related to $y$\u0026rsquo;. Attention should be paid not to overlook the concept by just getting the intuitive understanding; otherwise, reading about \u0026lsquo;relations\u0026rsquo; will become difficult whenever they come up.\nEspecially, a binary relation that is reflexive, symmetric, and transitive is called an equivalence relation. These properties are profoundly important throughout mathematics.\nExample Binary Relation and Inverse Relation The function $f : X \\to Y$ is a binary relation where, for all $x$, there exists a $y \\in Y$ satisfying $y = f(x)$ and, for all $x_{1} , x_{2} \\in X$, $$ x_{1} = x_{2} \\implies f(x_{1}) = f(x_{2}) $$ is satisfied. Of course, if its inverse function $f^{-1}$ exists, then $f^{-1}$ becomes the inverse relation of $f$.\nReflexive Relation An example of a reflexive relation is equality $=$, where $x=x$ always holds.\nSymmetric Relation An example of a symmetric relation is independence $\\perp$, where $$ X \\perp Y \\implies Y \\perp X $$ always holds.\nTransitive Relation An example of a transitive relation is the inequality $\u0026lt;$, where $$ x \u0026lt; y \\land y \u0026lt; z \\implies x \u0026lt; z $$ always holds.\nAntisymmetric Relation An example of an antisymmetric relation is the inclusion relation $\\subset$, where $$ A \\subset B \\land B \\subset A \\implies A = B $$ always holds.\nTranslated by Heungchun Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p137~141.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":960,"permalink":"https://freshrimpsushi.github.io/en/posts/960/","tags":null,"title":"Mathematical Binary Relations"},{"categories":"ÏßëÌï©Î°†","contents":"Definition 1 For any two objects $a$, $b$, $(a,b)$ is called an Ordered Pair. For any two sets $A$, $B$, the set of ordered pairs $(a,b)$ of $a \\in A$, $b \\in B$ is called the Cartesian Product of $A$ and $B$ and is represented as follows. $$ A \\times B := \\left\\{ (a,b): a \\in A \\land b \\in B \\right\\} $$ Explanation The reason why the term \u0026lsquo;product\u0026rsquo; is used in the Cartesian product comes from considering the number of elements a set has, resulting in $| A \\times B | = | A | \\times |B|$. For a single set $X$, $X \\times X$ is represented as $X^{2}$. If you consider the set of real numbers $\\mathbb{R}$, then $\\mathbb{R}^2 = \\mathbb{R} \\times \\mathbb{R}$ can be seen as the set containing all points on the Coordinate Plane. This implies that by multiplying the set $\\mathbb{R}$, containing all points on the Line, we can obtain the coordinate plane $\\mathbb{R}^2$. The term \u0026lsquo;Cartesian\u0026rsquo; in Cartesian product is used because Ren√© Descartes, who devised this coordinate plane and introduced it to the mathematical world, opening up the world of analytic geometry, is the one attributed with its invention. Although Descartes lived much earlier than Cantor and did not directly contribute to set theory, conceptually, he was ahead, making him fully deserving of this nomenclature‚Äôs honor.\nSuch Cartesian products can naturally be generalized, and as an example, the three-dimensional space $\\mathbb{R}^{3}$ as well as the general Euclidean space $\\mathbb{R}^{p}, p \\in \\mathbb{N}$ can be considered. Although it might be hard to imagine, the Cartesian product can be extended beyond natural numbers.\nSummary Meanwhile, the following distributive laws hold for the Cartesian product.\nDistributive Laws For any sets $A$, $B$, $C$: $$ A \\times (B \\cap C) = ( A \\times B) \\cap (A \\times C) \\\\ A \\times (B \\cup C) = ( A \\times B) \\cup (A \\times C) \\\\ A \\times (B \\setminus C) = ( A \\times B) \\setminus (A \\times C) $$\nSee Also Cartesian Product of Sets Cartesian Product of Groups Cartesian Product of Topological Spaces Translated by Heung-cheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p129~131.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1360,"permalink":"https://freshrimpsushi.github.io/en/posts/1360/","tags":null,"title":"Cartesian Product of Sets"},{"categories":"ÏßëÌï©Î°†","contents":"Definitions A set whose elements are sets themselves is called a Family. The elements of a family are called Members. When each element of a set $\\Gamma$ corresponds to a set $A_{\\gamma}$ with $\\gamma$ as the index, $\\Gamma$ as the index set, and $\\left\\{ A_{\\gamma} : \\gamma \\in \\Gamma \\right\\}$ as the indexed family. Explanation Though the term \u0026lsquo;Family\u0026rsquo; was originally introduced as a refined term for \u0026lsquo;set of sets\u0026rsquo;, this expression was merely to avoid the uncomfortable notion of a \u0026lsquo;set of sets\u0026rsquo;; yet, it still remains counterintuitive. Creating new terminology just to denote a set having sets as elements is odd. It implies that the term Family is solely introduced for convenience.\nConsider the following family as an example: $$ \\mathcal{F}=\\left\\{\\left\\{ 1 \\right\\} , \\mathbb{R} , \\mathbb{Q}, \\emptyset , \\mathbb{R} \\right\\} $$ $\\mathcal{F}$ can be called a family since all its elements are sets. It is noteworthy that $\\mathbb{R}$ is used repeatedly. This notation indicates that a family is not just a simple set of sets, nor is it strictly a set of sets in the precise sense. It is strictly for convenience. In that context, the term family cannot derive anything other than Family from the English expression, failing to capture its intended meaning. Even the term \u0026lsquo;member\u0026rsquo; is refined as \u0026lsquo;component\u0026rsquo;, which is not a convenient expression either, hence this blog will retain the terms Family and Member.\nSimilarly, indexing as \u0026lsquo;subscript\u0026rsquo; is overly refined. Let\u0026rsquo;s construct an indexed family for $\\mathcal{F}$ as shown above. Fortunately, being a finite set, if we set $$ A_{1} = \\left\\{ 1 \\right\\} \\\\ A_{2} = \\mathbb{R} \\\\ A_{3} = \\mathbb{Q} \\\\ A_{4} = \\emptyset \\\\ A_{5} = \\mathbb{R} $$ for $\\Gamma = \\left\\{ 1,2,3,4,5 \\right\\}$, we obtain $\\mathcal{F} = \\left\\{ A_{\\gamma} : \\gamma \\in \\Gamma \\right\\}$. Note that while $A_{2} = \\mathbb{R}$ and $A_{5} = \\mathbb{R}$, this allowance for duplication is not to undermine the foundation of set theory but for the sake of convenient expression. For the same reason, a family is also referred to as a Collection. It might seem circular since in English, a set is defined using the term Collection, but as mentioned earlier, it‚Äôs all for the sake of convenience, so don\u0026rsquo;t overthink it; just follow the convention of the material you are working with.\nOn the other hand, indexes don\u0026rsquo;t necessarily have to maintain an order or be specifically numbered. Consider setting $\\Gamma = \\mathbb{R}$ and thinking of $A_{\\gamma}$ as intervals $[k , k+1)$ over $k \\in \\mathbb{Z}$. Thus, $\\gamma \\in \\mathbb{R}$ results in $A_{\\pi} = [3,4)$, $A_{\\sqrt{10}} = [3,4)$, making it possible to locate the corresponding $A_{\\gamma}$ for every $\\gamma \\in \\Gamma$. Such peculiar configurations might seem unnecessary, but take Topology, for example, where such sets are used as naturally as one breathes.\nFor any family $\\mathcal{F}$, the following expressions are used:\nUnion: $$ \\bigcup \\mathcal{F} = \\bigcup_{A \\in \\mathcal{F}} \\left\\{ x \\in U : \\exists A \\in \\mathcal{F} , x \\in A \\right\\} $$ Intersection: $$ \\bigcap \\mathcal{F} = \\bigcap_{A \\in \\mathcal{F}} \\left\\{ x \\in U : \\forall A \\in \\mathcal{F} , x \\in A \\right\\} $$ Basic Properties For $\\left\\{ A_{\\gamma} : \\gamma \\in \\Gamma \\right\\}$, the following holds:\n[1] Form of the Principle of Inclusion: For the universal set $U$, $$ \\bigcup_{\\gamma \\in \\emptyset} A_{\\gamma} = \\emptyset \\\\ \\bigcap_{\\gamma \\in \\emptyset} A_{\\gamma} = U $$ [2] Generalization of De Morgan\u0026rsquo;s Theorem: $$ \\left( \\bigcup_{\\gamma \\in \\Gamma} A_{\\gamma} \\right)^{c} = \\bigcap_{\\gamma \\in \\Gamma} A_{\\gamma}^{c} \\\\ \\left( \\bigcap_{\\gamma \\in \\Gamma} A_{\\gamma} \\right)^{c} = \\bigcup_{\\gamma \\in \\Gamma} A_{\\gamma}^{c} $$ [3] Distributive Law: About the set $B$, $$ \\left( \\bigcup_{ \\gamma \\in \\Gamma } A_{\\gamma} \\right) \\cap B = \\bigcup_{\\gamma \\in \\Gamma} \\left( A_{\\gamma} \\cap B \\right) \\\\ \\left( \\bigcap_{ \\gamma \\in \\Gamma } A_{\\gamma} \\right) \\cup B = \\bigcap_{\\gamma \\in \\Gamma} \\left( A_{\\gamma} \\cup B \\right) $$ ","id":1358,"permalink":"https://freshrimpsushi.github.io/en/posts/1358/","tags":null,"title":"Sets and Indices"},{"categories":"ÌôïÎ•†Î°†","contents":"Definitions Let\u0026rsquo;s assume a probability space $( \\Omega , \\mathcal{F} , P)$ is given. A random variable $\\tau$ with an integer value greater than or equal to $0$ for all $n \\in \\mathbb{N}_{0}$ that satisfies $(\\tau = n) \\in \\mathcal{F}_{n}$ with respect to the filtration $\\left\\{ \\mathcal{F}_{n} \\right\\}$ is called a Stopping Time.\nFor a Borel set $B \\in \\mathcal{B}(\\mathbb{R})$, $(\\tau \\in B) = \\tau^{-1} (B)$ is, therefore, the same as $\\tau^{-1} ( \\left\\{ n \\right\\} )$. Examples The intuitive concept of stopping time refers to the moment when an event of interest occurs‚Äîbeing observed. For example, $\\tau = 8$ means knowing the information $\\mathcal{F}_{8}$ while the event of interest occurs at $n=8$. At first glance, the condition for stopping time might seem too easy. However, the challenge lies in satisfying it for all $n \\in \\mathbb{N}_{0}$.\nLet\u0026rsquo;s say $Y_{1}, Y_{2} , \\cdots \\overset{iid}{\\sim} B(1,p)$. In other words, each $Y_{n}$ follows the Bernoulli distribution with probability $p$, and the results up to $Y_{5}$ are as follows: $$ \\begin{matrix} Y_{1} \u0026amp; Y_{2} \u0026amp; Y_{3} \u0026amp; Y_{4} \u0026amp; Y_{5} \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1 \\end{matrix} $$\n(1) When it\u0026rsquo;s not a stopping time: If we set $\\tau$ as $\\tau:= \\max \\left\\{ k: Y_{k} = 0 \\right\\}$, in the above case, $\\tau$ is calculated as follows: $$ \\begin{matrix} Y_{1} \u0026amp; Y_{2} \u0026amp; Y_{3} \u0026amp; Y_{4} \u0026amp; Y_{5} \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1 \\\\ \\tau = 1 \u0026amp; \\tau = 2 \u0026amp; \\tau = 2 \u0026amp; \\tau = 4 \u0026amp; \\tau = 5 \\end{matrix} $$ Here, $\\tau$ must satisfy the following to be a stopping time: $$ (\\tau = n ) = \\left( Y_{n} = 0 , Y_{n+1} = 1 , \\cdots \\right) $$ This precisely means $Y_{n} = 0$, and afterwards, it must always be $1$. Regardless of what $n \\in \\mathbb{N}$ is, it\u0026rsquo;s impossible to know the outcome without conducting the trial. Therefore, $\\tau$ cannot be a stopping time.\n(2) When it becomes a stopping time: If we set $\\tau$ as $\\tau:= \\min \\left\\{ k: Y_{k} = 1 \\right\\}$, in the above case, $\\tau$ is calculated as follows: $$ \\begin{matrix} Y_{1} \u0026amp; Y_{2} \u0026amp; Y_{3} \u0026amp; Y_{4} \u0026amp; Y_{5} \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1 \\\\ \\tau = 0 \u0026amp; \\tau = 0 \u0026amp; \\tau = 3 \u0026amp; \\tau = 3 \u0026amp; \\tau = 3 \\end{matrix} $$ $\\tau$ is already not concerned with what comes in the future since the event of interest has occurred at $n=3$, becoming a stopping time.\nExplanation Note in the above examples that while $\\max$ was not suitable as a stopping time, $\\min$ became a stopping time. In this sense, stopping time can intuitively be considered as the \u0026rsquo;timing when something happens for the first time\u0026rsquo;. Meanwhile, one must not forget that, in a strict mathematical definition, $\\tau$ is still a random variable. When a stochastic process $\\left\\{ X_{n} \\right\\}_{n \\in \\mathbb{N}_{0}}$ is given, the condition for $X_{\\tau}$ to $\\omega \\in \\Omega$ means the following: $$ X_{\\tau} = X_{\\tau} ( \\omega )= X_{\\tau (\\omega)} ( \\omega ) $$ For instance, if $\\tau (\\omega_{1}) = 5$, then it becomes an equation where $X_{\\tau} (\\omega_{1}) = X_{5} ( \\omega_{1})$ . $\\tau$ represents \u0026lsquo;sometime when an event may occur\u0026rsquo;, thus it\u0026rsquo;s a \u0026lsquo;function\u0026rsquo; that maps all respective $\\omega \\in \\Omega$ to some $n \\in \\mathbb{N}_{0}$ even before being called a \u0026lsquo;stopping time\u0026rsquo;. Clinging to intuitive understanding and forgetting this point will make the deployment of all formulas involving stopping time painful. Remember well.\n","id":1351,"permalink":"https://freshrimpsushi.github.io/en/posts/1351/","tags":null,"title":"Stopping Times in Stochastic Processes"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Definition 1 If a sequence of functions $\\left\\{ f_{n} \\right\\}_{n \\in \\mathbb{N}}$ satisfies the following for some function $f$, then $\\left\\{ f_{n} \\right\\}$ is said to converge to $f$ in $L^{p}$.\n$$ \\lim_{n \\to \\infty} \\left\\| f_{n} - f \\right\\|_{p} = 0 $$\nThe sequence $\\left\\{ f_{n} \\right\\}_{n \\in \\mathbb{N}}$ is said to be Cauchy in $L^{p}$ if it satisfies the following.\n$$ \\lim_{n, m \\to \\infty} \\left\\| f_{n} - f_{m} \\right\\|_{p} = 0 $$\nExplanation Of course, $\\left\\| \\cdot \\right\\|_{p}$ is defined as the following with respect to $p$-norm.\n$$ \\left\\| f \\right\\|_{p} := \\left( \\int_{E} | f |^{p} dm \\right) ^{{{1} \\over {p}}} $$\nThe statement that a sequence of functions converges in $L^{p}$ means convergence in the sense of norm. In the properties of Lebesgue space, when $p \\le q$, if $f_{n}$ converges in $L^{q}$, it means convergence in $L^{p}$.\nSee Also Convergence in $L^{p}$ $\\implies$ Measure Convergence Bartle. (1995). The Elements of Integration and Lebesgue Measure: p58.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1394,"permalink":"https://freshrimpsushi.github.io/en/posts/1394/","tags":null,"title":"Lp Convergence"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition Let\u0026rsquo;s assume that a probability space $( \\Omega , \\mathcal{F} , P)$ is given.\nA sequence $\\left\\{ \\mathcal{F}_{n} \\right\\}_{n \\in \\mathbb{N}}$ of sub-œÉ-fields of $\\mathcal{F}$ is called a filtration if it satisfies the following: $$ \\forall n \\in \\mathbb{N}, \\mathcal{F}_{n} \\subset \\mathcal{F}_{n+1} $$ Given a filtration $\\left\\{ \\mathcal{F}_{n} \\right\\}_{n \\in \\mathbb{N}}$, a sequence $\\left\\{ X_{n} \\right\\}_{n \\in \\mathbb{N}}$ of ordered pairs formed by sequences of $\\mathcal{F}_{n}$-measurable Lebesgue integrable random variables $X_{n}$ is called a martingale if it satisfies the following: $$ \\forall n \\in \\mathbb{N}, E \\left( X_{n+1} | \\mathcal{F}_{n} \\right) = X_{n} $$ $\\mathcal{F}_{n}$ being a sub-œÉ-field of $\\mathcal{F}$ means that both are œÉ-fields of $\\Omega$, but $\\mathcal{F}_{n} \\subset \\mathcal{F}$ holds. $X_{n}$ being a $\\mathcal{F}_{n}$-measurable function means that for all Borel sets $B \\in \\mathcal{B}(\\mathbb{R})$, $X_{n}^{-1} (B) \\in \\mathcal{F}_{n}$ holds true. Explanation Submartingales and Supermartingales are referred to as follows, respectively. Remembering the inequality as sub if the right-hand side decreases, and super if it increases, may be less confusing. $$ \\forall n \\in \\mathbb{N}, E \\left( X_{n+1} | \\mathcal{F}_{n} \\right) \\ge X_{n} \\\\ \\forall n \\in \\mathbb{N}, E \\left( X_{n+1} | \\mathcal{F}_{n} \\right) \\le X_{n} $$ Of course, being both a submartingale and a supermartingale is equivalent to being a martingale. Therefore, if a theorem holds for either submartingales or supermartingales, it can also be directly applied to martingales.\nIntuitively understanding martingales starts with thinking of the œÉ-field as a collection of events, \u0026ldquo;information\u0026rdquo;:\nFiltration: $\\forall n \\in \\mathbb{N}, \\mathcal{F}_{n} \\subset \\mathcal{F}_{n+1}$, meaning that having a larger œÉ-field implies having more information. In the definition of martingales, the process $X_{n}$ being $\\mathcal{F}_{n}$-measurable means that as the actual data $x_{n}$ is observed, the œÉ-field $\\mathcal{F}_{n}$ also expands and it is safe to assume that all information up to $n$ has been acquired. Martingales: $\\forall n \\in \\mathbb{N}, E \\left( X_{n+1} | \\mathcal{F}_{n} \\right) = X_{n}$ means assuming that knowing the information $\\mathcal{F}_{n}$ up to $n$, the next scenario $X_{n+1}$ will also be similar to $X_{n}$. If the expected value of $X_{n+1}$ can be derived regardless of the previously gathered $\\mathcal{F}_{n}$, such a stochastic process is no different from white noise and fails to be a subject for statistical analysis. Hence, the intuitive definition of a martingale can be seen as a \u0026ldquo;stochastic process where we can obtain mathematically and statistically better outcomes with some advantageous information.\u0026rdquo; Origin In a French village called \u0026lsquo;Martigues,\u0026rsquo; what\u0026rsquo;s colloquially known as the \u0026lsquo;double or nothing strategy\u0026rsquo; was popular. This strategy involves making a higher bet to compensate for a loss in the previous round, safeguarding against the psychological factors aside, whether this is a wise strategy still needs contemplation. Mathematically, the essence of such a strategy is summarized in the formula $$ E \\left( X_{n+1} | X_{1} , \\cdots , X_{n} \\right) = X_{n+1} $$ pointing out the gambler\u0026rsquo;s fallacy with \u0026lsquo;I\u0026rsquo;ve been losing continuously, so I must win this time\u0026rsquo;, explaining why the Martingale betting is futile.\nExamples (1) Let\u0026rsquo;s consider an autoregressive process $AR(1)$ $X_{n+1} = X_{n} + \\varepsilon_{n}$. If filtration is given, then since all information regarding $X_{n}$ is known, according to the properties of conditional expectation $$ \\begin{align*} E \\left( X_{n+1} | \\mathcal{F}_{n} \\right) =\u0026amp; E \\left( X_{n} + \\varepsilon_{n} | \\mathcal{F}_{n} \\right) \\\\ =\u0026amp; E \\left( X_{n} | \\mathcal{F}_{n} \\right) + E \\left( \\varepsilon_{n} | \\mathcal{F}_{n} \\right) \\\\ =\u0026amp; X_{n} + E \\left( \\varepsilon_{n} | \\mathcal{F}_{n} \\right) \\\\ =\u0026amp; X_{n} + E ( \\varepsilon_{n} ) \\\\ =\u0026amp; X_{n} \\end{align*} $$ , thus $\\left\\{ (X_{n}, \\mathcal{F}_{n}) \\right\\}$ becomes a martingale.\n(2) Assuming $\\left\\{ X_{n} \\right\\}_{n \\in \\mathbb{N}}$ are independent of each other, and $E(X_{n}) = 0$ and $\\displaystyle S_{n}:= \\sum_{i =1}^{n} X_{i}$, then $$ \\begin{align*} E(S_{n+1} | \\mathcal{F}_{n} ) =\u0026amp; S_{n} + E( X_{n+1} | \\mathcal{F}_{n} ) \\\\ =\u0026amp; S_{n} + E( X_{n+1} ) \\\\ =\u0026amp; S_{n} + 0 \\end{align*} $$ , thus $\\left\\{ (S_{n}, \\mathcal{F}_{n}) \\right\\}$ becomes a martingale.\nMeanwhile, given a convex function $\\phi$ and a martingale, one can create a submartingale as shown above.\nTheorem Given a martingale $\\left\\{ (X_{n}, \\mathcal{F}_{n}) \\right\\}$ and a convex function $\\phi: \\mathbb{R} \\to \\mathbb{R}$, $( \\phi (X_{n}) , \\mathcal{F}_{n} )$ is a submartingale.\nProof Conditional Jensen\u0026rsquo;s Inequality: Assuming that a probability space $( \\Omega , \\mathcal{F} , P)$ and a sub-œÉ-field $\\mathcal{G} \\subset \\mathcal{F}$ are given, and $X$, is a random variable. For a convex function $\\phi: \\mathbb{R} \\to \\mathbb{R}$ and $\\phi (X) \\in \\mathcal{L}^{1} ( \\Omega ) $ $$ \\phi \\left( E \\left( X | \\mathcal{G} \\right) \\right) \\le E \\left( \\phi (X) | \\mathcal{G} \\right) $$\nAccording to Conditional Jensen\u0026rsquo;s Inequality $$ E \\left( \\phi (X_{n+1}) | \\mathcal{F}_{n} \\right) \\ge \\phi \\left( E \\left( X_{n+1} | \\mathcal{F}_{n} \\right) \\right) = \\phi ( X_{n} ) $$\n‚ñ†\nCorollary As a corollary, setting $p \\ge 1$ to $\\phi (x) = | x |^{p}$, $\\left\\{ |X_{n}|^p , \\mathcal{F}_{n} \\right\\}$ is always a submartingale.\nSee also Various filtrations $$ A_{1} \\subset A_{2} \\subset \\cdots \\subset A_{n} \\subset \\cdots $$ Universally in mathematics, structures forming nested sequences like above are referred to as filtrations.\nFiltration of stochastic processes Filtration of a complex Flag of a vector space ","id":1349,"permalink":"https://freshrimpsushi.github.io/en/posts/1349/","tags":null,"title":"The Definition of Martingale"},{"categories":"ÏßëÌï©Î°†","contents":"Axioms $$ \\exists U \\left( \\emptyset \\in U \\land \\forall X ( X \\in U \\implies S(X) \\in U) \\right) $$ There exists a set $U$ that contains the empty set and $X$ as elements, and also contains $S(X)$ as an element.\nFor a set $X$, $S(X)$ is defined as a set that is equivalent to $S(X):= X \\cup \\left\\{ X \\right\\}$. Explanation Rather than tediously explaining why this is called the infinity axiom, it\u0026rsquo;s better to look at the proof of the existence of the set of natural numbers $\\mathbb{N}$.\nTheorem: Existence of the Set of Natural Numbers $\\mathbb{N}$ exists.\nProof Strategy: By using the construction method proposed by von Neumann, which corresponds natural numbers themselves to sets, the set of natural numbers $\\mathbb{N}$ is directly constructed. Thereby, $\\mathbb{N}$ exists and immediately possesses the properties of natural numbers.\nLet\u0026rsquo;s define the empty set $\\emptyset$ and its $S(n)$ as follows. $$ 0 : = \\emptyset \\\\ ( n + 1 ):= S(n) = n \\cup \\left\\{ n \\right\\} $$ Then, $$ 1 = 0+1 = S ( 0 ) = \\left\\{ 0 \\right\\} \\\\ 2 = 1+1 = S ( 1 ) = \\left\\{ 0, \\left\\{ 0 \\right\\} \\right\\} = \\left\\{ 0, 1 \\right\\} \\\\ 3 = 2+1 = S ( 2 ) = \\left\\{ 0, \\left\\{ 0 \\right\\}, \\left\\{ 0, \\left\\{ 0 \\right\\} \\right\\} \\right\\} = \\left\\{ 0, 1, 2 \\right\\} \\\\ \\vdots $$ By the infinity axiom, $\\mathbb{N} = \\left\\{ 1, 2, 3, \\cdots \\right\\}$ exists and satisfies the following property. $$ n_{1} \\in n_{2} \\iff n_{1} \u0026lt; n_{2} \\\\ n_{1} \\subset n_{2} \\iff n_{1} \\le n_{2} $$\n‚ñ†\nThe claim that there are infinitely many natural numbers is somehow true, but in fact, no one in this universe has ever seen infinitely many natural numbers. No matter how long, consistently, or many natural numbers one seeks, it\u0026rsquo;s impossible to prove inductively that an infinite set exists. The infinity axiom was introduced to explain this infinity, and intuitively, there\u0026rsquo;s absolutely no reason to reject it.\n","id":1348,"permalink":"https://freshrimpsushi.github.io/en/posts/1348/","tags":null,"title":"Axiom of Infinity"},{"categories":"ÏßëÌï©Î°†","contents":"Axioms 1 $$ \\forall X \\exists P \\forall A ( A \\subset X \\implies A \\in P) $$ For any set $X$, there exists a set $P$ that contains every subset of $X$ as an element.\nExplanation The power set of $X$ is generally denoted by $\\mathcal{P} (X)$ or $2^{X}$, the reason being if the number of elements of a finite set $X$ is denoted by $|X|$, then $\\left| \\mathcal{P} (X) \\right| =2^{|X|}$. It\u0026rsquo;s not always about the number, so the more someone uses set theory, the more they prefer expressions like $2^{X}$.\nOne can guess to some extent from the fact that the number of elements increases exponentially, but a power set $2^{X}$ is quite, very large compared to $X$. Moreover, according to the axiom of power set, there also exists a power set of a power set, thus, one can think of sets that grow in size indefinitely in this manner.\nAs an example of a power set, consider the following:\n$$ X = \\left\\{ 1,2 \\right\\} $$\n$$ 2^{X} = \\left\\{ \\emptyset , \\left\\{ 1 \\right\\} , \\left\\{ 2 \\right\\}, \\left\\{ 1,2 \\right\\} \\right\\} $$ Note that the empty set $\\emptyset$ and the original set $X$ belong to $2^{X}$. The following are some basic properties of power sets. That the empty set is also an element of $2^{X}$ might be awkward at first encounter, but one should naturally accept it since an empty set is also a set and a set can be an element of a set.\nBasic Properties [1]: $A \\subset X \\iff A \\in 2^{X}$ [2]: $\\emptyset \\in 2^{X}$ [3]: $X \\in 2^{X}$ If one\u0026rsquo;s concept of set inclusion is weak, it\u0026rsquo;s naturally confusing. Unfortunately, when one first encounters set theory, power sets are not used extensively and there aren\u0026rsquo;t particularly good practice problems to get accustomed to. Realistically, one must think time is the remedy and slowly get used to it.\nÏù¥Ìù•Ï≤ú Ïó≠, You-Feng Lin. (2011). ÏßëÌï©Î°†(Set Theory: An Intuitive Approach): p83.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1346,"permalink":"https://freshrimpsushi.github.io/en/posts/1346/","tags":null,"title":"Power Set Axiom"},{"categories":"ÏßëÌï©Î°†","contents":"Axiom $$ \\forall X \\left( \\exists U \\left( \\forall a \\left( a \\in x \\land x \\in X \\implies a \\in U \\right) \\right) \\right) $$ For any set $X$, there exists a set $U$ that contains all the elements of the elements of $X$.\nDefinition of Union 1 The axiom of union guarantees the existence of the union defined as follows: $$ x \\in A \\lor x \\in B \\iff x \\in A \\cup B $$ For any two sets $A$ and $B$, the set containing elements that belong to at least one of them is called the union of $A$ and $B$, and is represented as $A \\cup B$.\nExplanation The axiom of union and the definition of union are distinctly different. Although a definition is merely a statement of a concept, and the axiom guarantees its existence, the phrase \u0026ldquo;containing the elements of the elements\u0026rdquo; in the explanation of the axiom of union differs. If one speaks of the elements of element1 as element2, then element1 is necessarily a set, and the shape of element1 has been guaranteed existence through the pairing axiom and appears similar to $\\left\\{ A, B \\right\\}$\u0026rsquo;s $A$ and $B$. In other words, the union can be seen as being created through an operation $\\cup$ between $A$ and $B$, and the concept of union as intended by the axiom of union refers to something like $U(X) := \\left\\{ a \\in x : x \\in X \\right\\}$ when a set of sets like $X = \\left\\{ A, B \\right\\}$ is given.\nWhile this distinction might not mean much when dealing with mathematics below the undergraduate level, one should precisely understand and move on if they wish to understand the axiom out of curiosity or on the rare occasion it is needed.\nBasic Properties For the subsets $A$, $B$, and $C$ of the set $X$, the following hold:\n[1] Identity Law: $$ A \\cup \\emptyset = A \\\\ A \\cap X = A $$ [2] Idempotent Law: $$ A \\cup A = A \\\\ A \\cap A = A $$ [3] Commutative Law: $$ A \\cup B = B \\cup A \\\\ A \\cap B = B \\cap A $$ [4] Associative Law: $$ A \\cup ( B \\cup C) = (A \\cup B) \\cup C \\\\ A \\cap (B \\cap C) = ( A \\cap B ) \\cap C $$ [5] Distributive Law: $$ A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C) \\\\ A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C) $$ [6] De Morgan\u0026rsquo;s Theorem: $$ (A \\cup B)^{c} = A^{c} \\cap B^{c} \\\\ (A \\cap B)^{c} = A^{c} \\cup B^{c} $$ [7] $$ (A \\setminus B)^{c} = A^{c} \\cup B $$ Proof [7] $$ \\begin{align*} x \\in (A \\setminus B)^{c} \u0026amp;\\iff x \\notin A \\setminus B \\\\ \u0026amp;\\iff x \\notin A \\text{ or } x \\in B \\\\ \u0026amp;\\iff x \\in A^{c} \\text{ or } x \\in B \\\\ \u0026amp;\\iff x \\in A^{c} \\cup B \\end{align*} $$\n‚ñ†\nTranslation by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p87.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1344,"permalink":"https://freshrimpsushi.github.io/en/posts/1344/","tags":null,"title":"Union axiom"},{"categories":"ÏßëÌï©Î°†","contents":"Axioms 1 $$ \\forall X \\exists A \\forall a \\left( a \\in A \\iff ( a \\in X \\land p(a)) \\right) $$ For any set $X$, there exists a subset $A$ composed of elements that have property $p$.\n$p(x)$ is a propositional function in $X$. Explanation The reason why $A$ is limited to a subset of $X$ is to prevent problems like Russell\u0026rsquo;s paradox. The reason it is not called an axiom but an axiom schema is that there are infinitely many such axioms, depending on the infinitely many $p(x)$. If there are two different propositional functions $p_{1}(x)$ and $p_{2}(x)$, what guarantees the existence of $\\left\\{ a \\in X : p_{2}(a) \\text{ is truth} \\right\\} \\subset X$ is not the \u0026lsquo;Classification Axiom for $p_{1}(x)$\u0026rsquo; but the \u0026lsquo;Classification Axiom for $p_{2}(x)$\u0026rsquo;.\nDefinition of Intersection and Difference Sets 2 The axiom schema of classification guarantees the existence of an intersection as defined below.\n$$ x \\in A \\land x \\in B \\iff x \\in A \\cap B $$ For any two sets $A$, $B$, the set of elements belonging to both is called the intersection of $A$ and $B$, denoted as $A \\cap B$.\nRegarding the set $A$, the given propositional function is $p(x): x \\in B$, which can be specifically written as $A \\cap B= \\left\\{ x \\in A : x \\in B \\right\\}$. If $A \\cap B = \\emptyset$, then $A$ and $B$ are called disjoint.\nOf course, the axiom schema of classification not only guarantees the existence of intersections but also the existence of all subsets satisfying a specific condition. This can be seen as the method of specifying conditions itself, one way of expressing sets.\n$$ x \\in A \\land x \\notin B \\iff x \\in A \\setminus B $$ For any two sets $A$, $B$, the set of elements that belong to $A$ but not to $B$ is called the difference set of $A$ with respect to $B$, denoted as $A \\setminus B$.\nThe set $U$ is called the complement of $A$, denoted as $A^{c}$. In considering the complement, the set $U$ is also referred to as the universal set.\nAlthough set theory is infinite, not all branches of mathematics need to explore the entire abstract world. Typically, a certain universal set is predetermined as needed, and areas such as topology often use these concepts. Here are a few properties of complements and universal sets.\nBasic Properties Let\u0026rsquo;s assume sets $A$, $B$ are any subsets of the universal set $U$.\n[1] $$ \\left(A^{c} \\right)^{c} = A $$ [2] $$ \\emptyset^{c} = U \\\\ U^{c} = \\emptyset $$ [3] $$ A \\cap A^{c} = \\emptyset \\\\ A \\cup A^{c} = U $$ [4] $$ A \\subset B \\implies B^{c} \\subset A^{c} $$ [5] $$ A \\setminus B = A \\cap B^{c} $$ Proof [5] $$ \\begin{align*} x \\in A \\setminus B \u0026amp;\\iff x \\in A \\text{ and } x \\notin B \\\\ \u0026amp;\\iff x \\in A \\text{ and } x \\in B^{c} \\\\ \u0026amp;\\iff x \\in A \\cap B^{c} \\end{align*} $$\n‚ñ†\nTranslated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p81.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTranslated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p87, 95.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1341,"permalink":"https://freshrimpsushi.github.io/en/posts/1341/","tags":null,"title":"Classification Axiomatic Form"},{"categories":"ÏßëÌï©Î°†","contents":"Axioms 1 $$ \\exists X \\forall x \\left( \\lnot \\left( x \\in X \\right) \\right) $$ A set $X$ that does not contain any elements exists, and this set $X$ is defined as the empty set.\nExplanation The empty set is typically denoted as $\\emptyset$. Meanwhile, the empty set can also be viewed as a set with $0$ elements, and sets that can be defined in terms of the number of elements include the following:\nSingleton Set: A set with only one element is called a singleton set. Finite Set: If the number of elements in a set belongs to $\\mathbb{N}$, it is called a finite set. Infinite Set: If a set is neither an empty set nor a finite set, it is called an infinite set. Here, the definitions of finite and infinite sets are somewhat messy, but they are rigorously redefined later.\nNote that a singleton set $\\left\\{ x \\right\\}$ is, after all, a set, and $x$ is distinctly different as an element of $\\left\\{ x \\right\\}$. Furthermore, in modern mathematics, even definitions like $x := \\left\\{ x \\right\\}$ are not permitted.\nThe reason to differentiate between the axiom of the empty set and the definition of the empty set is precisely because the two are different. The empty set itself can certainly be defined regardless of the empty set axiom. However, whether it truly exists is another matter. We intuitively understand the existence of the empty set, but a mere definition cannot guarantee that. This is similar to the axiom of completeness in analysis.\nThe non-obviousness of the existence of the empty set might become clear when considering the definition of a set. We said that a set is a collection of distinguishable objects as the subjects of our intuition or thought, and the objects belonging to a set are called elements. According to this definition, the empty set should not have any \u0026lsquo;distinguishable entities\u0026rsquo; at all, yet having a collection without anything to collect is clearly odd. Nevertheless, as humans are too familiar with the \u0026lsquo;presence of absence\u0026rsquo;, we add such axioms in order to deal with the empty set.\nRegardless of understanding or empathizing with this non-obviousness, the existence of the empty set can be derived from other axioms. Since fewer axioms are generally better, textbooks usually omit the empty set axiom.\nTranslated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p75.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1337,"permalink":"https://freshrimpsushi.github.io/en/posts/1337/","tags":null,"title":"Empty Set Axiom"},{"categories":"ÏßëÌï©Î°†","contents":"Definition 1 $$ A \\subset B \\iff \\forall x (x\\in A \\implies x \\in B) $$ For any set $A$, $B$, if all elements of $A$ are also elements of $B$, then $A$ is a Subset of $B$, and $B$ is a Superset of $A$, denoted as $A \\subset B$.\nExplanation If it\u0026rsquo;s $A \\subset B$ and $B \\not\\subset A$, then $A$ is called a Proper Subset of $B$, and denoted as $A \\subsetneq B$.\nAs a minor note, $A \\subset B$ means $A$ is included in $B$, and $a \\in A$ means $a$ belongs to $A$. Although it might seem the same to many, there are often confusions in actual language habits, and most people won\u0026rsquo;t fuss over it as long as they understand each other. However, inclusion is a relation defined between sets, and $a \\in A$ is not referred to as \u0026rsquo;the belonging relation of a set and an element\u0026rsquo;, which is a difference worth knowing.\nSummary: Transitivity of Inclusion For any set $A$, $B$, $C$, $$A \\subset B \\land B \\subset C \\implies A \\subset C$$\nProof According to the assumption, $$ A \\subset B \\iff \\forall x (x\\in A \\implies x \\in B) \\\\ B \\subset C \\iff \\forall x (x\\in B \\implies x \\in C) $$ By the syllogism, $$ \\forall x (x\\in A \\implies x \\in C) \\iff A \\subset C $$\n‚ñ†\nTranslated by Heung-Chun Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p77.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1329,"permalink":"https://freshrimpsushi.github.io/en/posts/1329/","tags":null,"title":"Set Inclusion"},{"categories":"Îß§Ìä∏Îû©","contents":"Method linspace(a,b,n): Returns a row vector of $[a,b]$ divided into $n$ equal intervals. If the number of elements is not specified, it returns a $1\\times 100$ vector. It is used when the number of intervals is important, not the length of the intervals.\na: m :b : Returns a row vector of $[a,b]$ divided by equal intervals of $m$. If the interval is not specified, the interval is set to $1$. It is used when the length of the interval is important, not the number of intervals. There may not be a natural number $n$ that satisfies $b=a+n\\cdot m$. In this case, the endpoint is not $b$, but the largest number satisfying $a+n\\cdot m$.\nx1=linspace(1,10,10)\rx2=linspace(1,10)\rx3=linspace(5,55,2^5)\ry1=1:3\ry2=1:1/13:2\ry3=3:1/7:7 In other languages In Julia ","id":1376,"permalink":"https://freshrimpsushi.github.io/en/posts/1376/","tags":null,"title":"How to Create Equally Spaced Row Vectors in MATLAB"},{"categories":"ÌôïÎ•†Î°†","contents":"Theorem Given a probability space $( \\Omega , \\mathcal{F} , P)$:\n[1] From measure theory: If measurable functions $f$, $g$ are $\\mathcal{F}$-measurable, then there exists a Borel function $h : \\mathbb{R} \\to \\mathbb{R}$ satisfying $g = h (f)$. [2] Application in probability theory: If random variables $X$, $Y$ are $\\sigma (X)$-measurable, then there exists a Borel function $h : \\mathbb{R} \\to \\mathbb{R}$ satisfying $E(Y | X) = h(X)$. [3]: If $X$ is $\\mathcal{F}$-measurable, then $$E(X|\\mathcal{F}) =X \\text{ a.s.}$$. [4]: For sigma field $\\mathcal{G} = \\left\\{ \\emptyset , \\Omega \\right\\}$, $$E(X|\\mathcal{G}) = E(X) \\text{ a.s.}$$. [5]: For constant $c$ and all sigma fields $\\mathcal{G}$, $$E(c|\\mathcal{F}) = c \\text{ a.s.}$$. [6]: For constant $c$, $$E(cX | \\mathcal{G}) = c E(X | \\mathcal{G}) \\text{ a.s.}$$. [7]: $$E(X+Y | \\mathcal{G}) = E(X | \\mathcal{G}) + E(Y| \\mathcal{G}) \\text{ a.s.}$$. [8]: If $X \\ge 0 \\text{ a.s.}$, then $$E(X | \\mathcal{G}) \\ge 0 \\text{ a.s.}$$. [9]: If $X \\ge Y \\text{ a.s.}$, then $$E(X | \\mathcal{G}) \\ge E(Y | \\mathcal{G}) \\text{ a.s.}$$. [10]: $$\\left| E( X | \\mathcal{G} ) \\right| \\le E ( | X | | \\mathcal{G} ) \\text{ a.s.}$$. [11]: For all sigma fields $\\mathcal{G}$, $$E \\left[ E ( X | \\mathcal{G} ) \\right] = E(X)$$. $\\sigma (X) = \\left\\{ X^{-1} (B) : B \\in \\mathcal{B}(\\mathbb{R}) \\right\\}$ represents the smallest sigma field generated by the random variable $X$, denoted as $\\Omega$. A function $Z$ being $\\mathcal{F}$-measurable means for all Borel sets $B \\in \\mathcal{B}(\\mathbb{R})$, $Z^{-1} (B) \\in \\mathcal{F}$ holds. A Borel function is a function $f : \\mathbb{R} \\to \\mathbb{R}$ for which $f^{-1} (B)$ is a Borel set for all Borel sets $B \\in \\mathcal{B}(\\mathbb{R})$. Explanation [1],[2]: These theorems indicate that the conditional expectation of $Y$ given $X$ can be represented by some function dependent on $X$. Specifically, given the value of $X$, it is represented as $E(Y | X = a) = h(a)$. [2] is a corollary of [1], ensuring that basic properties of expectation commonly used in elementary probability theory are almost surely guaranteed. Linearity [5]~[7]: The linearity of expectation, denoted as $E(aX + b | \\mathcal{G}) = aE(X | \\mathcal{G}) + b$, is preserved even conditionally. Sigma Fields as Information [3] $E(X | \\mathcal{F}) = X$: Considering the meaning of the formula, if the random variable $X$ is $\\mathcal{F}$-measurable, it means that the sigma field $\\mathcal{F}$ has all the information about $X$. Conversely, this is why it\u0026rsquo;s called measurable. Therefore, $E(X|\\mathcal{F})$ can be directly perceived without any interference. A $X$, fully known on $\\mathcal{F}$, doesn\u0026rsquo;t need to be calculated through $E$. For example, when playing a game where you earn 1 dollar for each face of a 6-sided die, the expected earnings are 3.5 dollars. This is calculated because we don\u0026rsquo;t know which face of the die will appear. However, if the sigma field $\\mathcal{F}$ is precisely given in my mind before throwing the die, the face of the die $X$ can be accurately measured, and thus how many dollars will be received is known. Even if one has to pay 3.5 dollars each game, by not playing the losing games and only playing the winning ones, one can avoid losses. In this sense, random number hacking corresponds to an attack technique that steals the sigma field (random number table) and makes what should have been random deterministic. If successful, cryptographic systems relying on randomness, such as bank security cards or OTPs, are compromised. Since $\\sigma (X)$ is defined as the smallest sigma field knowing all about $X$, it naturally follows $E(X| \\sigma (X)) = X$, denoted as $E(X|X) = X$ according to the introduced notation.\n[4] $E(X|\\mathcal{G}) = E(X)$: Considering the meaning of the formula, the trivial sigma field $\\mathcal{G} = \\left\\{ \\emptyset , \\Omega \\right\\}$ gives no information about $X$, thus necessitating a scan of the entire probability space $\\Omega$ to calculate $\\displaystyle \\int_{\\Omega} X d P$. [10] $\\left| E( X | \\mathcal{G} ) \\right| \\le E ( | X | | \\mathcal{G} )$: Following the properties of absolute value, $$ - E ( | X | | \\mathcal{G} ) \\le E( X | \\mathcal{G} ) \\le E ( | X | | \\mathcal{G} ) $$ [11] $E \\left[ E ( X | \\mathcal{G} ) \\right] = E(X)$: This equality is useful in various proofs in probability theory, mainly used as a trick when $E(X)$ is difficult to calculate directly, but given some $\\mathcal{G}$, $E(X|\\mathcal{G})$ becomes easier to compute. Proof [1] Define $h : \\mathbb{R} \\to \\mathbb{R}$ for $z \\in \\mathbb{R}$ as $h(z) := \\left( g \\circ f^{-1} ( \\left\\{ z \\right\\} ) \\right)$.\nIf $\\left\\{ z \\right\\} \\in \\mathcal{B}(\\mathbb{R})$, since $f$ is $\\mathcal{F}$-measurable, $f^{-1}(\\left\\{ z \\right\\}) \\in \\mathcal{F}$ holds, and since $g$ is also $\\mathcal{F}$-measurable, $h$ is well-defined and satisfies $g (\\omega) = ( h \\circ f ) ( \\omega )$.\nFor all Borel sets $B \\in \\mathcal{B}(\\mathbb{R})$, consider $$ h^{-1}(B) = (f \\circ g^{-1})(B) = f \\left( g^{-1} (B) \\right) $$, since $g^{-1} (B) \\in \\mathcal{F}$, we have $f(g^{-1} (B) ) \\in \\mathcal{B}(\\mathbb{R})$. As $h^{-1}(B) \\in \\mathcal{B}(\\mathbb{R})$ holds for all $B \\in \\mathcal{B}(\\mathbb{R})$, $h$ is a Borel function.\n‚ñ†\n[2] $E ( Y | X ) = E ( Y | \\sigma (X) )$ is a $\\sigma (X)$-measurable random variable by the definition of conditional expectation, and $X$ is also a $\\sigma (X)$-measurable random variable by definition. Therefore, by [1], let\u0026rsquo;s denote $\\mathcal{F} = \\sigma (X)$ and set $$ f = X \\\\ g = E ( Y | X ) $$, then there exists a Borel function $h : \\mathbb{R} \\to \\mathbb{R}$ satisfying $E(Y|X) = h(X)$.\n‚ñ†\nStrategies [3]~[7]: Convert to integral form, show that definite integrals are equal, and then apply the following theorem, named Lebesgue Integration Lemma for this post.\nProperties of Lebesgue Integration: $$ \\forall A \\in \\mathcal{F}, \\int_{A} f dm = 0 \\iff f = 0 \\text{ a.e.} $$\n[3] Since $X$ uniquely exists satisfying $\\displaystyle \\int_{A} X dP = \\int_{A} X dP$ for all $A \\in \\mathcal{F}$, by the definition of conditional expectation, $X = E(X| \\mathcal{F})$ is the conditional expectation of $X$ with respect to $\\mathcal{F}$. Therefore, for all $A \\in \\mathcal{F}$, $$ \\int_{A} E(X |\\mathcal{F}) dP = \\int_{A} X dP $$ and by the Lebesgue Integration Lemma\n, we have $X = E(X |\\mathcal{F}) \\text{ a.s.}$.\n‚ñ†\n[4] By the definition of conditional expectation, we have $\\displaystyle \\int_{A} E(X |\\mathcal{G}) dP = \\int_{A} X dP$.\nCase 1. $A = \\emptyset$\n$$ 0 = \\int_{\\emptyset} E(X |\\mathcal{G}) dP = \\int_{\\emptyset} X dP = 0 $$\nCase 2. $A = \\Omega$\n$$ \\int_{\\Omega} E(X |\\mathcal{G}) dP = \\int_{\\Omega} X dP = E(X) = E(X) P(\\Omega) = E(X) \\int_{\\Omega} 1 dP = \\int_{\\Omega} E(X) dP $$\nIn either case, by the Lebesgue Integration Lemma, we have $X = E(X |\\mathcal{G}) \\text{ a.s.}$.\n‚ñ†\n[5] Given $c \\in \\mathcal{G}$ and $E(c | \\mathcal{G}) \\in \\mathcal{G}$, by the definition of conditional expectation, for all $A \\in \\mathcal{G}$, $$ \\int_{A} E(c |\\mathcal{G}) dP = \\int_{A} X dP $$ and therefore, by the Lebesgue Integration Lemma, we have $c = E(c | \\mathcal{G}) \\text{ a.s.}$.\n‚ñ†\n[6] By the definition of conditional expectation and the linearity of Lebesgue integration, for all $A \\in \\mathcal{G}$, $$ \\begin{align*} \\int_{A} E( cX |\\mathcal{G}) dP =\u0026amp; \\int_{A} cX dP \\\\ =\u0026amp; c \\int_{A} X dP \\\\ =\u0026amp; c \\int_{A} E(X|\\mathcal{G}) dP \\\\ =\u0026amp; \\int_{A} c E(X|\\mathcal{G}) dP \\end{align*} $$ and by the Lebesgue Integration Lemma, we have $E( cX |\\mathcal{G}) = c E(X|\\mathcal{G}) dP \\text{ a.s.}$.\n‚ñ†\n[7] By the definition of conditional expectation and the linearity of Lebesgue integration, for all $A \\in \\mathcal{G}$, $$ \\begin{align*} \\int_{A} E( X+Y |\\mathcal{G}) dP =\u0026amp; \\int_{A} (X+Y) dP \\\\ =\u0026amp; \\int_{A} X dP +\\int_{A} Y dP \\\\ =\u0026amp; \\int_{A} E(X|\\mathcal{G}) dP + \\int_{A} E(Y|\\mathcal{G}) dP \\\\ =\u0026amp; \\int_{A} \\left[ E(X|\\mathcal{G}) + E(Y|\\mathcal{G}) \\right] dP \\end{align*} $$ and by the Lebesgue Integration Lemma, $$ E( X +Y |\\mathcal{G}) = E(X|\\mathcal{G}) + E(Y|\\mathcal{G}) dP \\text{ a.s.} $$\n‚ñ†\n[8] Assuming $E( X |\\mathcal{G}) \u0026lt; 0$ leads to a contradiction, thus $E( X |\\mathcal{G}) \\ge 0 \\text{ a.s.}$ must hold.\n‚ñ†\n[9] Assuming $Z := X - Y \\ge 0$ and by [8], $$ E(X-Y | \\mathcal{G}) \\ge 0 $$ and by the linearity of conditional expectation, $$ E(X| \\mathcal{G}) - E(Y | \\mathcal{G}) \\ge 0 \\text{ a.s.} $$\n‚ñ†\n[10] Part 1. $X \\ge 0$\nIf $X \\ge 0$, then $|X| = X$ holds, leading to $$ E( |X| |\\mathcal{G}) = E(X|\\mathcal{G}) $$\nBy [8], we have $E(X|\\mathcal{G}) \\ge 0$, similarly leading to $E(X|\\mathcal{G}) = \\left| E(X|\\mathcal{G}) \\right|$, $$ E( |X| |\\mathcal{G}) = E(X|\\mathcal{G}) = \\left| E(X|\\mathcal{G}) \\right| $$\nPart 2. $X \u0026lt; 0$\nBy [6], $$ E( |X| |\\mathcal{G}) = E( -X |\\mathcal{G}) = - E(X |\\mathcal{G}) = \\left| E(X|\\mathcal{G}) \\right| $$\nPart 3. $X = X^{+} - X^{-}$\nBy the triangle inequality, $$ \\left| E(X|\\mathcal{G}) \\right| \\le \\left| E( X^{+} |\\mathcal{G}) \\right| + \\left| E( X^{-} |\\mathcal{G}) \\right| $$ Given $X^{+} , X^{-} \\ge 0$, by Part 1, $$ \\left| E(X|\\mathcal{G}) \\right| \\le E( \\left| X^{+} \\right| |\\mathcal{G}) + E( \\left| X^{-} \\right| | \\mathcal{G}) $$\nBy [7] and the expression of absolute value $|f| = |f^{+}| + |f^{-}|$, $$ \\begin{align*} \\left| E(X|\\mathcal{G}) \\right| \\le \u0026amp; E( \\left| X^{+} \\right| + \\left| X^{-} \\right| | \\mathcal{G}) \\\\ =\u0026amp; E( \\left| X \\right| | \\mathcal{G}) \\text{ a.s.} \\end{align*} $$\n‚ñ†\n[11] $$ \\begin{align*} E \\left[ E( X | \\mathcal{G} ) \\right] =\u0026amp; \\int_{\\Omega} E ( X | \\mathcal{G} ) d P \\\\ =\u0026amp; \\int_{\\Omega} X d P \\\\ =\u0026amp; E(X) \\end{align*} $$\n‚ñ†\n","id":1322,"permalink":"https://freshrimpsushi.github.io/en/posts/1322/","tags":null,"title":"Properties of Conditional Expectation"},{"categories":"ÏïåÍ≥†Î¶¨Ï¶ò","contents":"Buildup When solving a problem, if the solution to a larger problem includes the solution to a smaller problem, it is said to have an Optimal Substructure. An easy example of a problem with an optimal substructure is calculating the Fibonacci numbers. The $n$-th Fibonacci number is calculated as $a_{n} = a_{n-1} + a_{n-2}$, thus, the larger problem $a_{n}$ includes the smaller problems $a_{n-1}$ and $a_{n-2}$.\nA simple way to solve this is to use a recursive function. Although most problems that have an optimal substructure seem solvable with recursion, actual implementation reveals that it\u0026rsquo;s immensely inefficient due to duplicated calls.\nDefinition Dynamic Programming is a technique used to circumvent these difficulties, advisable under the following conditions:\n(i): The given problem has an optimal substructure. (ii): Implementing it with a recursive function is inefficient. Example The concept of dynamic programming is simple. It saves the solution to small problems while omitting duplicate calls. For instance, to calculate the 6th Fibonacci number $a_{6}$, instead of $$ a_{1} = 1 \\\\ a_{2} = 1 \\\\ a_{3} = 2 \\\\ a_{4} = 3 \\\\ a_{5} = 5 $$ calculating it repeatedly, it is stored in memory, and only the last $a_{4}$ and $a_{5}$ are called to calculate $a_{6} = a_{5} + a_{4} = 8$. This is called Memoization1.\nDespite how it\u0026rsquo;s explained, it doesn\u0026rsquo;t seem particularly Dynamic. Originally, the term derived from the field of control, where solutions are progressively saved in a table. However, according to Bellman, the designer of dynamic programming, as stated directly in his writings, he chose the term dynamic simply because it sounded cool and was favorable for obtaining funding.\nBelow is a gif comparing the calculation of $a_{36}=14930352$ using both methods and their respective execution times. Dynamic programming took just over 0.01 seconds, while recursion took more than 5 seconds. This difference magnifies as $n$ increases. Theoretically, it can be shown that for a given $n$, recursion uses exponential time, while dynamic programming uses linear time, in a simple proof.\nCode import Time\rdef fibo1(n) :\rif n==1 or n==2 :\rreturn 1\relse :\rreturn fibo1(n-1) + fibo1(n-2)\rdef fibo2(n) :\rmemoization = [1,1]\rfor i in range(n-2) :\rmemoization.append(memoization[-1]+memoization[-2])\rreturn memoization[-1]\rstart = Time.time() print(fibo2(36))\rprint(\u0026#34;ÎèôÏ†Å ÌîÑÎ°úÍ∑∏ÎûòÎ∞çÏúºÎ°ú Í≥ÑÏÇ∞Ìï† Îïå Í±∏Î¶∞ ÏãúÍ∞Ñ : %5.3f\u0026#34; % (time.time() - start))\rstart = Time.time() print(fibo1(36))\rprint(\u0026#34;Ïû¨Í∑ÄÌï®ÏàòÎ°ú Í≥ÑÏÇ∞Ìï† Îïå Í±∏Î¶∞ ÏãúÍ∞Ñ : %5.3f\u0026#34; % (time.time() - start)) Derived from Memo, it is not Memorization but Memoization.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1262,"permalink":"https://freshrimpsushi.github.io/en/posts/1262/","tags":null,"title":"Dynamic Programming"},{"categories":"ÏßëÌï©Î°†","contents":"Definitions 1 Set: A collection of distinct objects that are the subjects of our intuition or thought is called a set. Element: An object that belongs to a set is called an element. Propositional Function: For an element $x$ of the set $U$, a proposition $p(x)$ that is either true or false is called a propositional function in $U$. Explanation In mathematics, the concept of a set is as important as nearly a native language. It might even be better than natural language because it eliminates ambiguity that necessarily follows and allows for logic to be developed through its definition and form alone. Usually, elements are denoted by lowercase letters, and sets by uppercase letters. If $a$ belongs to $A$, it is denoted as $a \\in A$ and said that $a$ is an element of $A$. Of course, it is not mandatory to represent elements and sets with uppercase and lowercase letters, respectively. The set of all natural numbers is commonly represented as $\\mathbb{N}$, and there is no problem in denoting it as $N \\in \\mathbb{N}$. Enumeration: The set of natural numbers $\\mathbb{N}$ can be represented as $\\left\\{ 1 , 2, 3, \\cdots \\right\\}$. This method of directly writing the elements of a set is called the roster method. Set-Builder Notation: Unlike the roster method, sets can also be expressed as collections containing only those elements that satisfy a certain condition. For example, if you want to represent the set containing only natural numbers larger than $5$, it can be denoted as for a propositional function $p(x): x \u0026gt; 5$ by $\\left\\{ x \\in \\mathbb{N} : p(x) \\text{ is truth} \\right\\}$. This can be more simply denoted as $\\left\\{ x \\in \\mathbb{N} : x \u0026gt; 5 \\right\\}$ without separately defining the propositional function. This notation is called set-builder notation. It is important to note that a propositional function is defined as the propositional function itself. Although it conforms to the definition of a function in set theory, it is important that it can be defined solely by propositions. If this is unclear, the use of set-builder notation might become challenging due to the potential for functions to be circularly defined. Meanwhile, a propositional function is also called a logical formula. Translated by Heung-Chun Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p47, 73, 81, 85.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1316,"permalink":"https://freshrimpsushi.github.io/en/posts/1316/","tags":null,"title":"Definition of Sets and Propositional Functions"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition Let\u0026rsquo;s assume a probability space $( \\Omega , \\mathcal{F} , P)$ is given.\nIf $\\mathcal{G}$ is a sub sigma-field of $\\mathcal{F}$ and the random variable $X \\in \\mathcal{L}^{1} ( \\Omega )$ is integrable, for all $A \\in \\mathcal{G}$, $$ \\int_{A} Y d P = \\int_{A} X d P $$ a $\\mathcal{G}$-measurable random variable $Y$ uniquely exists satisfying the above, then $Y := E ( X | \\mathcal{G} )$ is defined as the conditional expectation of $X$ given $\\mathcal{G}$.\nEven though I\u0026rsquo;d like to say you can ignore the term probability space if you have not encountered measure theory yet, understanding the content of this post is nearly impossible without any knowledge of measure theory at all. That $\\mathcal{G}$ is a sub sigma-field of $\\mathcal{F}$ means both are sigma-fields of $\\Omega$, with $\\mathcal{G} \\subset \\mathcal{F}$ being true. That $Y$ is a $\\mathcal{G}$-measurable function means for every Borel set $B \\in \\mathcal{B}(\\mathbb{R})$, $Y^{-1} (B) \\in \\mathcal{G}$ holds true. Explanation In the mathematical definition, $\\mathcal{G}$ becomes a probability space $( \\Omega , \\mathcal{G} , P)$, which is not as vast as the original probability space $( \\Omega , \\mathcal{F} , P)$ but has a bit more information given. Therefore, $$ \\int_{A} X d P = \\int_{A} Y d P = \\int_{A} E ( X | \\mathcal{G} ) d P $$ indicates that the calculation remains the same within that reduced space, which means we\u0026rsquo;ve successfully pulled down the probability $P$ from $\\mathcal{F}$ to $\\mathcal{G}$ while keeping its properties intact.\nAlso, from the format of the definition, since $E ( X | \\mathcal{G} )$ exists as a $\\mathcal{G}$-measurable random variable, it should be naturally accepted that the expected value is a variable random, and measurable with respect to the given sigma field.\nWhile the definition may not be intuitively difficult to grasp, its expression might feel somewhat unfamiliar. The $\\sigma (X) := \\left\\{ X^{-1} (B) : B \\in \\mathcal{B}(\\mathbb{R}) \\right\\}$ regarding the random variable $X$ becomes the smallest sigma field $\\sigma (X) \\subset \\mathcal{F}$ generated by $X$, which is often stated in familiar terms as: $$ E(Y|X) = E \\left( Y | \\sigma (X) \\right) $$ However, although this can be stated, getting accustomed to this approach is much easier if one intends to continue studying measure-based probability theory. Considering it, $E(Y|X)$ was conceptually intuitive but was a painfully complex notation for handling formulas or making direct calculations. It\u0026rsquo;s time to let it go without regret.\nThe existence of the conditional expectation is warranted by the Radon-Nikodym Theorem. Understanding the theorem is crucial, but the proof itself is not difficult.\nProof Case 1. $X \\ge 0$\n$$ P_{\\mathcal{G}}(A) := \\int_{A} X d P $$ If defined as $P_{\\mathcal{G}}$ for all $A \\in \\mathcal{G}$, $P_{\\mathcal{G}}$ becomes a measure on $\\mathcal{G}$, and $P_{G} \\ll P$ holds.\nIf the two sigma-finite measures $\\nu$, $\\mu$ on the measurable space $( \\Omega , \\mathcal{F} )$ satisfy $\\nu \\ll \\mu$ according to the Radon-Nikodym Theorem, for all $A \\in \\mathcal{F}$, $\\mu$-almost everywhere $h \\ge 0$ and $$ \\nu (A) = \\int_{A} h d \\mu $$ a $\\mathcal{F}$-measurable function $f$ uniquely exists in accordance to $\\mu$.\nFollowing the theorem, if we define $\\nu = P_{\\mathcal{G}}$ and $\\mu = P$, for all $A \\in \\mathcal{G}$, $$ P_{\\mathcal{G}} (A) = \\int_{A} Y d P $$ a $Y \\ge 0$ uniquely exists, satisfying the above. According to the initial definition of $P_{\\mathcal{G}}$, $Y$ becomes the conditional expectation of $X$ given $\\mathcal{G}$.\nCase 2. General case\nYou can decompose $X$ into two parts $X^{+} , X^{-} \\ge 0$ and use the same method as in Case 1..\n‚ñ†\n","id":1315,"permalink":"https://freshrimpsushi.github.io/en/posts/1315/","tags":null,"title":"Conditional Expectation of Random Variables Defined by Measure Theory"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definitions 1 Let a measurable space $( X , \\mathcal{E} )$ be given.\nIf $\\mu (X) \u0026lt; \\infty$, then $\\mu$ is called a finite measure. When $$\\displaystyle X = \\bigcup_{i=1}^{\\infty} E_{i} \\qquad , E_{i} \\in \\mathcal{E}$$ for all $i \\in \\mathbb{N}$ such that $\\mu ( E_{i} ) \u0026lt; \\infty$, it is called a sigma-finite measure. Also, the ordered pair $(X, \\mathcal{E}, \\mu)$ is called a sigma-finite measure space. If for all $\\mu ( E ) = \\infty$ there exists a subset $F \\in \\mathcal{E}$ of $E$ satisfying $0 \u0026lt; \\mu (F) \u0026lt; \\infty$, then $\\mu$ is called a semifinite measure. When $\\nu$ is a signed measure on the given measurable space and the total variation $| \\nu |$ is a finite (sigma-finite) measure, then $\\nu$ is called a finite (sigma-finite) measure. Explanation A typical example of a finite measure is probability. Sigma-finite measures are a relaxation of the condition for finite measures on the entire set $X$. The $E_{i}$ that make up the whole set must be finite, but their sum $\\displaystyle \\sum_{i \\in \\mathbb{N}} \\mu ( E_{i} )$ doesn\u0026rsquo;t need to be finite. In other words, whether $\\mu (X)=\\infty$ or $\\mu (X) \u0026lt;\\infty$ doesn\u0026rsquo;t matter. According to the definition, sigma-finite measures that are $\\mu (X)\u0026lt;\\infty$ become finite measures. The key point in the definition of a semifinite measure is that $F$ satisfies $0 \u0026lt; \\mu (F)$. Without this condition, the sigma algebra would include the empty set, so all measures could satisfy this condition. Not all sigma-finite measures are semifinite, but the reverse is not true. The following conditions can easily be seen to be equivalent. $(a)$ $\\nu$ is sigma-finite. $(b)$ $\\nu^+$, $\\nu^-$ are sigma-finite. $(c)$ $| \\nu |=\\nu^+ + \\nu^-$ is sigma-finite. Bartle. (1995). The Elements of Integration and Lebesgue Measure: p19~20.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1314,"permalink":"https://freshrimpsushi.github.io/en/posts/1314/","tags":null,"title":"Finite Sigma Measures"},{"categories":"Îß§Ìä∏Îû©","contents":"Methods $m \\times n$ Given a data in the form of a matrix, let\u0026rsquo;s call it $A$. If you want to use only a specific part of matrix $A$, you can use the following method.\nB=A(a:b, c:d) Running the code as above, $B$ becomes a $(b-a) \\times (d-c)$ matrix containing the data from row $a$ to $b$, column $c$ to $d$ of matrix $A$. Below is the example code and its result.\nfor k=1:9\rfor l=1:9\rA(k,l)=10*k+l;\rend\rend\rA\ra1=A(3:7,4:9)\ra2=A(2:5,1:6) :: If you want to extract the entire rows or columns, you can use a colon. $a3$ extracts the entire columns, and $a4$ extracts the entire rows.\na3=A(3:7,:)\ra4=A(:,4:9) Using a colon is useful when extracting specific rows or columns.\na5=A(3,:)\ra6=A(:,9) ","id":1362,"permalink":"https://freshrimpsushi.github.io/en/posts/1362/","tags":null,"title":"Selecting Specific Rows and Columns in a Matrix in MATLAB"},{"categories":"ÏßëÌï©Î°†","contents":"Law 1 $$ \\left[ p(1) \\land \\left( p(n) \\implies p(n+1) \\right) \\right] \\implies \\forall n \\in \\mathbb{N} : p(n) $$ Regarding the proposition $p(n) (n=1,2,3, \\cdots )$, if $p(1)$ is true and assuming $p(n)$, then if $p(n+1)$ holds, $p(n)$ is true.\nExplanation When a formula holds for natural numbers, a powerful proof method called Peano\u0026rsquo;s Fifth Axiom is especially potent, or simply called induction without the \u0026lsquo;mathematical\u0026rsquo; prefix. Originally, induction refers to deriving certain conclusions by empirically collecting phenomena or entities, but in mathematics, it\u0026rsquo;s understood as mathematical induction without explanation.\nMathematical induction seems difficult to understand at first but becomes extremely easy once understood. As can be inferred from its alias, Peano\u0026rsquo;s Fifth Axiom, it‚Äôs considered an axiom because it\u0026rsquo;s inherently logical. Mathematical Induction Mathematical induction is often likened to dominoes:\n(1) The first domino falls. It\u0026rsquo;s an apparent fact that the first domino falls, simply because you topple it yourself. Similarly, in proofs, this is usually shown easily by substituting $1$ into the proposition. (2) The falling of a previous domino topples the next one. If the $n$th domino falls, it topples the $(n+1)$th domino as well. In a row of dominoes, the notion that a domino would topple the next one is plausible. Demonstrating this is the essence and the most challenging part of mathematical induction. **(3) If the above is true, toppling the first domino results in all dominoes falling. Let\u0026rsquo;s say you\u0026rsquo;ve toppled the first domino. Accordingly, from (2), the $1$th domino topples the $2$th domino. Again, from (2), the $2$th domino in turn topples the $3$th domino. And again, from (2), the $n$th domino in turn topples the $(n+1)$th domino. Thus, all dominoes topple the next leading to every single domino falling, no matter how many there are. Returning to mathematical induction, when $p(1)$ holds, so does $p(1+1)$, meaning $p(2)$ holds. When $p(2)$ holds, $p(2+1)$ holds, and when $p(n)$ holds, $p(n+1)$ holds.\nBut isn\u0026rsquo;t assuming $p(n)$ a circular argument? It can be confusing why one might assume $p(n)$ holds when first encountering mathematical induction, and I too was puzzled by this in high school. However, what we are actually demonstrating is not that $p(n)$ itself holds, but that if $p(n)$ holds, then $p(n+1)$ also holds. Therefore, mathematical induction is considered a form of indirect proof.\nFrankly, it doesn\u0026rsquo;t matter whether $n$ holds for all cases or not. If a false conclusion is drawn from a false assumption, the logic in-between is sound. If it holds true, then $p(1)$ holds, thus it applies to all natural numbers. This is the true conclusion of the proof. At least one true proposition $p(1)$ must exist to justify the validity of $p(n)$ for all natural numbers. Translated by Heung-Chun Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p63, 367.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":118,"permalink":"https://freshrimpsushi.github.io/en/posts/118/","tags":null,"title":"Mathematical Induction"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition 1 Let\u0026rsquo;s assume given a measurable space $( \\Omega , \\mathcal{F} )$. If measures $\\nu$, $\\mu$ satisfy $$ \\mu (A) = 0 \\implies \\nu (A) = 0 $$ for all $A \\in \\mathcal{F}$, then $\\nu$ is said to be absolutely continuous with respect to $\\mu$ and is denoted by $\\nu \\ll \\mu$.\nExplanation As the notation $\\nu \\ll \\mu$ suggests, $\\mu$ has a strong sense of \u0026lsquo;dominating\u0026rsquo; over $\\nu$. The question is why we call this \u0026lsquo;absolute continuity\u0026rsquo;. I have looked for a good explanation for a long time, but for learners at the level of studying real analysis, there is no easier way to understand than proving the following equivalent condition.\nTheorem $\\nu \\ll \\mu$ $\\iff$ $\\forall \\varepsilon \u0026gt; 0$, $\\exists \\delta \u0026gt; 0 : F \\in \\mathcal{F}, \\mu ( F ) \u0026lt; \\delta \\implies \\nu (F) \u0026lt; \\varepsilon $\nProof Let\u0026rsquo;s assume that for all $n \\in \\mathbb{N}$ there exists a sequence $\\left\\{ F_{n} \\right\\}_{n \\in \\mathbb{N}} \\subset \\mathcal{F}$ that satisfies $\\displaystyle \\mu ( F_{n} ) \u0026lt; {{1} \\over {2^n}}$ and $\\nu (F_{n}) \u0026gt; \\varepsilon$.\nIf we set $\\displaystyle A : = \\bigcap_{n \\in \\mathbb{N}} F_{n}$, then $\\mu (A) = 0$, but $\\nu (A) \\ne 0$, hence, there is a contradiction with $\\mu (A) = 0 \\implies \\nu (A) = 0$.\n$(\\Leftarrow)$\nIf we set $\\forall \\varepsilon \u0026gt; 0$ about $\\delta = \\varepsilon$, $$\\mu (A) = 0 \\implies \\nu (A) = 0$$\n‚ñ†\nSee Also Absolute continuity of real functions Absolute continuity of measures Absolute continuity of signed measures Bartle. (1995). The Elements of Integration and Lebesgue Measure: p84.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1309,"permalink":"https://freshrimpsushi.github.io/en/posts/1309/","tags":null,"title":"Absolute Continuity of Measures"},{"categories":"ÏßëÌï©Î°†","contents":"Law 1 $$ (p \\land \\lnot q) \\to c \\iff p \\to q $$\n$c$ implies a contradiction. Explanation Reductio ad absurdum or proof by contradiction is a proof technique that is widely used throughout mathematics. However, those who encounter this method for the first time may find the term unfamiliar and may resist it. Or there might be people who, although they have become accustomed to it, do not understand how it works.\nLet\u0026rsquo;s try to understand proof by contradiction by reading the following:\n(1) The conclusion $q$ is either true or false. This is obvious due to the law of the excluded middle2. (2) However, if $\\lnot q$ is true and leads to a contradiction, we can at least conclude that $\\lnot q$ cannot be true. (3) As stated in (1), since $q$ is either true or false, if $\\lnot q$ is false, then $q$ must be true. (4) Therefore, $p \\to q$. If this is difficult to understand, let\u0026rsquo;s check with an example unrelated to math:\n$p$: I have two arms. $q$: I have at least one arm. $p \\to q$: If I have two arms, I have at least one. At first glance, disregarding the fact that it\u0026rsquo;s a proof by contradiction, it seems too apparent. If I don\u0026rsquo;t have at least one arm, how can I have two? But this obvious logic is exactly what proof by contradiction is:\nFirst, let\u0026rsquo;s deny the conclusion $q$ and assume that I have no arms. But according to the assumption $p$, I have two arms, which is a contradiction. Thus, the assumption that I have no arms, $\\lnot q$, must be incorrect. Of course, this is when the assumption that I have two arms, $p$, stands, hence $p \\to q$. Proof $$ \\begin{align*} (p \\land \\lnot q) \\to c \\iff \u0026amp; \\lnot ( p \\land \\lnot q ) \\lor c \\\\ \\iff \u0026amp; \\lnot (p \\land \\lnot q) \\\\ \\iff \u0026amp; \\lnot p \\lor q \\\\ \\iff \u0026amp; p \\to q \\end{align*} $$\n‚ñ†\nTranslated by Heungchun Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p39.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIt cannot be true and false at the same time.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":117,"permalink":"https://freshrimpsushi.github.io/en/posts/117/","tags":null,"title":"Mathematical Logic Proof by Contradiction"},{"categories":"ÏßëÌï©Î°†","contents":"Law 1 $$ p \\to q \\iff \\lnot q \\to \\lnot p $$\nExplanation If a proposition is true, then its contrapositive is also true; if a proposition is false, then its contrapositive is also false. Of course, if the converse holds, then the inverse of the original proposition also holds through contraposition.\nThese expressions might be too difficult for those not familiar with mathematics. Let\u0026rsquo;s understand it through an intuitive example:\n$p$ : The weather is hot $q$ : Sweating occurs $p \\to q$ : If the weather is hot, then sweating occurs If it is true that sweating occurs when the weather is hot, then if there is no sweating, we can conclude that, at least, it is not because the weather is hot.\nProof $$ \\begin{align*} p \\to q \\iff \u0026amp; \\lnot p \\lor q \\\\ \\iff \u0026amp; \\lnot p \\lor \\lnot (\\lnot q) \\\\ \\iff \u0026amp; \\lnot (\\lnot q) \\lor \\lnot p \\\\ \\iff \u0026amp; \\lnot q \\to \\lnot p \\end{align*} $$\n‚ñ†\nTranslated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p29.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":116,"permalink":"https://freshrimpsushi.github.io/en/posts/116/","tags":null,"title":"Mathematical Proof of the Counterfactual"},{"categories":"Îß§Ìä∏Îû©","contents":"Properties The properties of a graph can be specified as follows.\nGraph Color Marker Line Style Red r Dot . Solid - Green g Star * Dotted : Blue b X x Dash-dot -. Black k Circle o (letter o) Dashed -- Yellow y Plus + Magenta m Square s White w Diamond d Cyan c Star p Triangle down v Triangle up ^ Triangle left \u0026lt; Triangle right \u0026gt; Hexagon h Example x=linspace(0,1,20);\ry=x.^3+3.*x.^2+3.*x+1;\rfigure()\rplot(x,y,\u0026#39;ro\u0026#39;)\rhold on\rplot(x,y+1,\u0026#39;g-\u0026#39;)\rplot(x,y+2,\u0026#39;c:\u0026#39;)\rplot(x,y+3,\u0026#39;k--\u0026#39;)\rlegend({\u0026#39;ro\u0026#39;, \u0026#39;g-\u0026#39;, \u0026#39;c:\u0026#39;, \u0026#39;k--\u0026#39;}) ","id":1330,"permalink":"https://freshrimpsushi.github.io/en/posts/1330/","tags":null,"title":"How to Specify Colors, Line Styles, and Marker Types in MATLAB Graphs"},{"categories":"ÏßëÌï©Î°†","contents":"Theorem 1 [1] De Morgan\u0026rsquo;s Laws: $$ \\lnot (p \\land q) \\iff \\lnot p \\lor \\lnot q \\\\ \\lnot(p \\lor q) \\iff \\lnot p \\land \\lnot q $$ [2] De Morgan\u0026rsquo;s Theorem: $$ (A \\cup B)^{c} = A^{c} \\cap B^{c} \\\\ (A \\cap B)^{c} = A^{c} \\cup B^{c} $$ Description De Morgan\u0026rsquo;s Laws and De Morgan\u0026rsquo;s Theorems refer to propositions and sets, respectively, but in everyday language, they are often not distinguished. Whether it‚Äôs called a law or a theorem, attaching De Morgan- means that by negating or taking the complement, the propositions or sets and symbols inside the parenthesis \u0026lsquo;flip\u0026rsquo;, that\u0026rsquo;s how it is understood.\nMeanwhile, according to mathematical induction, not only is the following generalization possible, but it can also be extended to index families. $$ \\begin{align*} \\begin{matrix} \\displaystyle \\left( \\bigcup_{i=1}^{\\infty} X_{i} \\right)^{c} = \\bigcap_{i=1}^{\\infty} (X_{i})^{c} \\\\ \\displaystyle \\left( \\bigcap_{i=1}^{\\infty} X_{i} \\right)^{c} = \\bigcup_{i=1}^{\\infty} (X_{i})^{c} \\end{matrix} \u0026amp;\\qquad \\\u0026amp; \\begin{matrix} \\displaystyle\\left( \\bigcup_{\\alpha \\in \\forall } X_{\\alpha} \\right)^{c} = \\bigcap_{\\alpha \\in \\forall} (X_{\\alpha})^{c} \\\\ \\displaystyle \\left( \\bigcap_{\\alpha \\in \\forall} X_{\\alpha} \\right)^{c} = \\bigcup_{\\alpha \\in \\forall } (X_{\\alpha})^{c} \\end{matrix} \\end{align*} $$\nProof [1] Proven by truth tables.\nPart 1. $\\lnot (p \\land q) \\iff \\lnot p \\lor \\lnot q$\nPart 2. $\\lnot(p \\lor q) \\iff \\lnot p \\land \\lnot q$\n‚ñ†\n[2] Part 1. $(A \\cup B)^{c} = A^{c} \\cap B^{c}$\n$$\\begin{align*} x \\in (A \\cup B)^{c} \\iff \u0026amp; \\lnot (x \\in A \\cup B) \\\\ \\iff \u0026amp; \\lnot ( x \\in A \\lor x \\in B ) \\\\ \\iff \u0026amp; \\lnot ( x \\in A ) \\land \\lnot ( x \\in B ) \\\\ \\iff \u0026amp; x \\in A^{c} \\land x \\in B^{c} \\\\ \\iff \u0026amp; x \\in ( A^{c} \\cap B^{c} ) \\end{align*} $$\nPart 2. $(A \\cap B)^{c} = A^{c} \\cup B^{c}$\n$$\\begin{align*} x \\in (A \\cap B)^{c} \\iff \u0026amp; \\lnot (x \\in A \\cap B) \\\\ \\iff \u0026amp; \\lnot ( x \\in A \\land x \\in B ) \\\\ \\iff \u0026amp; \\lnot ( x \\in A ) \\lor \\lnot ( x \\in B ) \\\\ \\iff \u0026amp; x \\in A^{c} \\lor x \\in B^{c} \\\\ \\iff \u0026amp; x \\in ( A^{c} \\cup B^{c} ) \\end{align*} $$\n‚ñ†\nÏù¥Ìù•Ï≤ú Ïó≠, You-Feng Lin. (2011). ÏßëÌï©Î°†(Set Theory: An Intuitive Approach): p29, 115.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1306,"permalink":"https://freshrimpsushi.github.io/en/posts/1306/","tags":null,"title":"Proof of De Morgan's Laws"},{"categories":"Îß§Ìä∏Îû©","contents":"Method imrotate(I,angle,method,bbox)\nI: Image to be rotated. angle: The angle of rotation in degrees. method: The interpolation method. Options are \u0026rsquo;nearest\u0026rsquo;, \u0026lsquo;bilinear\u0026rsquo;, \u0026lsquo;bicubic\u0026rsquo;. If nothing is specified, \u0026rsquo;nearet\u0026rsquo; is applied. X = phantom(\u0026#39;Modified Shepp-Logan\u0026#39;,64);\rfigure()\rimagesc(X)\rtitle(\u0026#39;X\u0026#39;)\rY1=imrotate(X,30,\u0026#39;nearest\u0026#39;,\u0026#39;crop\u0026#39;);\rY2=imrotate(X,30,\u0026#39;bilinear\u0026#39;,\u0026#39;crop\u0026#39;);\rY3=imrotate(X,30,\u0026#39;bicubic\u0026#39;,\u0026#39;crop\u0026#39;);\rfigure()\rsubplot(1,3,1)\rimagesc(Y1)\rtitle(\u0026#39;Y1 - nearest\u0026#39;)\rsubplot(1,3,2)\rimagesc(Y2)\rtitle(\u0026#39;Y2 - bilinear\u0026#39;)\rsubplot(1,3,3)\rimagesc(Y3)\rtitle(\u0026#39;Y3 - bicubic\u0026#39;) bbox: Specifies the size of the output image. \u0026rsquo;loose\u0026rsquo; enlarges the size of the output image to include parts that exceed the original size due to rotation. \u0026lsquo;crop\u0026rsquo; cuts the rotated image to fit the size of the original image. If nothing is specified, \u0026rsquo;loose\u0026rsquo; is applied. X = phantom(\u0026#39;Modified Shepp-Logan\u0026#39;,64);\rfigure()\rimagesc(X)\rtitle(\u0026#39;X - 64*64\u0026#39;)\rY1=imrotate(X,30,\u0026#39;nearest\u0026#39;,\u0026#39;loose\u0026#39;);\rY2=imrotate(X,30,\u0026#39;nearest\u0026#39;,\u0026#39;crop\u0026#39;);\rfigure()\rsubplot(1,2,1)\rimagesc(Y1)\rtitle(\u0026#39;Y1 - loose 88*88\u0026#39;)\rsubplot(1,2,2)\rimagesc(Y2)\rtitle(\u0026#39;Y2 - crop 64*64\u0026#39;) In Other Languages In Julia ","id":1328,"permalink":"https://freshrimpsushi.github.io/en/posts/1328/","tags":null,"title":"Rotating an Image in MATLAB"},{"categories":"ÏßëÌï©Î°†","contents":"Definition 1 A proposition that is true for all logical possibilities is called a Tautology. A proposition that is false for all logical possibilities is called a Contradiction.\nFor $p$, $q$, if the conditional statement $p \\to q$ is a tautology, it is called an Implication and represented as follows: $$ p \\implies q $$ For $p$, $q$, if the biconditional statement $p \\to q$ is a tautology, it is called Equivalence and represented as follows: $$ p \\iff q $$ Explanation The term contradiction is almost never used, and instead, the word contradiction is often used. Symbolically, tautology and contradiction are denoted as Tautology $t$, Contradiction $c$, respectively.\nAccording to the truth table, $p$ might be true or false, but $p \\lor \\lnot p$ is always true. Considering the definition of a proposition, if $p$ is true or false, it logically means it‚Äôs true. Hence, a tautology is such a proposition that, disregarding the \u0026lsquo;fact\u0026rsquo;, just by its form, it can only be true.\nPeople who are not interested in mathematics might think math is complex and difficult, but what one realizes as they study more is that mathematicians are desperately struggling not to \u0026rsquo;think\u0026rsquo;. Humanity has far too many combinations of \u0026lsquo;words\u0026rsquo;, and it\u0026rsquo;s daunting to assess each and every one of them for correctness. Thus, for at least \u0026rsquo;things that can be recognized just by their form\u0026rsquo;, they wish to exert only that much effort to grasp.\nImplication means to include the meaning, which fits perfectly as a refined expression for Imply, but it‚Äôs extremely rare for Korean speakers to interpret Imply as implication.\nLaws 1 For any propositions $p$, $q$, $r$, the following hold:\n[1] Law of Addition: $$ p \\implies p \\lor q $$ [2] Laws of Simplification: $$ p \\land q \\implies p \\\\ p \\land q \\implies q $$ [3] Laws of Absorption: $$ p \\land ( p \\lor q) \\iff p \\\\ p \\lor ( p \\land q ) \\iff p $$ [4] Law of Double Negation: $$ \\lnot ( \\lnot p) \\iff p $$ [5] Laws of Commutativity: $$ p \\land q \\iff q \\land p \\\\ p \\lor q \\iff q \\lor p $$ [6] Laws of Idempotency: $$ p \\land p \\iff p \\\\ p \\lor p \\iff p $$ [7] Laws of Associativity: $$ (p \\land q) \\land r \\iff p \\land (q \\land r) \\\\ (p \\lor q) \\lor r \\iff p \\lor (q \\lor r) $$ [8] Laws of Distributivity: $$ p \\land (q \\lor r) \\iff (p \\land q) \\lor (p \\land r) \\\\ p \\lor (q \\land r) \\iff (p \\lor q) \\land (p \\lor r) $$ These laws should be as natural as breathing to humans engaging in logical thought, and for those in STEM fields, the special laws listed below should be second nature. The closer your major is to the formal sciences‚Äîcomputer science, statistics, mathematics‚Äîthe sooner you should become familiar with them:\n[9] De Morgan\u0026rsquo;s Laws: $$ \\lnot (p \\land q) \\iff \\lnot p \\lor \\lnot q \\\\ \\lnot(p \\lor q) \\iff \\lnot p \\land \\lnot q $$ [10] Contrapositive Law: $$ (p \\to q) \\iff (\\lnot q \\to \\lnot p) $$ [11] Reductio ad Absurdum: $$ (p \\land \\lnot q) \\to c \\iff p \\to q $$ [12] Syllogism: $$ (p \\to q) \\land (q \\to r) \\implies (p \\to r) $$ English Notation The English notations for the theorems introduced in this post are as follows:\n[1] Law of Addition [2] Laws of Simplification [3] Laws of Absorption [4] Law of Double Negation [5] Laws of Commutativity [6] Laws of Idempotency [7] Laws of Associativity [8] Laws of Distributivity [9] De Morgan\u0026rsquo;s Laws [10] Contrapositive Law [11] Reductio ad Absurdum [12] Syllogism Especially, [11] Reductio ad Absurdum is also called the law of absurdity, and [12] Syllogism is also known as the Law of Transitivity.\nÏù¥Ìù•Ï≤ú Ïó≠, You-Feng Lin. (2011). ÏßëÌï©Î°†(Set Theory: An Intuitive Approach): p25.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1304,"permalink":"https://freshrimpsushi.github.io/en/posts/1304/","tags":null,"title":"Contrapositive and Converse Propositions"},{"categories":"Îß§Ìä∏Îû©","contents":"Zero Matrix zeros(): Returns a zero matrix. zeros(n): Returns a $n\\times n$ zero matrix. zeros(m,n): Returns a $n\\times m$ zero matrix. zeros(size(A)): Returns a zero matrix of the same size as matrix A. Matrix with All Elements as 1 ones(): Returns a matrix where all elements are 1. However, for operations between two matrices, it\u0026rsquo;s more convenient to just use 1. It\u0026rsquo;s obvious that the code below is much simpler in the example code. ones(n): Returns a $n\\times n$ matrix where all elements are 1. ones(m,n): Returns a $n\\times m$ matrix where all elements are 1. ones(size(A)): Returns a matrix of the same size as matrix A where all elements are 1. A=[1 2 3; 4 -2 3; 5 3 7]\rones(size(A))./A\r1./A Identity Matrix eye(): Returns the identity matrix. eye(n): Returns a $n\\times n$ identity matrix. eye(m,n): Returns a $n\\times m$ identity matrix. eye([m,n]): Returns a $n\\times m$ identity matrix where elements on the main diagonal are 1 and other elements are 0. eye(n,'like',A): Returns a $n\\times n$ identity matrix of the same data type as matrix A. If A is a complex matrix, it returns a complex identity matrix. If no size is specified, it returns a matrix of the same size as A. eye([2,3])\reye(3,6)\rA=[1+i 3-i]\reye(3, \u0026#39;like\u0026#39;, A)\reye(3,4 \u0026#39;like\u0026#39;, A) Random Numbers rand(): Returns a random number between 0 and 1. The probability of each number being drawn is the same. The official Matlab website describes this as \u0026lsquo;uniformly distributed random numbers\u0026rsquo;. rand(n): Returns a $n\\times n$ matrix composed of random numbers between 0 and 1. rand(m,n): Returns a $m\\times n$ matrix composed of random numbers between 0 and 1. rand(n,'like',A): Returns a $n\\times n$ matrix composed of random numbers of the same data type as matrix A. If A is a complex matrix, it returns a complex matrix. If no size is specified, it returns a matrix of the same size as A. ","id":1327,"permalink":"https://freshrimpsushi.github.io/en/posts/1327/","tags":null,"title":"Creating Special Matrices in MATLAB"},{"categories":"Îß§Ìä∏Îû©","contents":"Multiplication times(), .*: Returns the result of multiplying each element of two matrices. The operation can only proceed if the two matrices are of the exact same size, or one of them is a scalar, or if one is a row vector with the same row size, or a column vector with the same column size. If the sizes are different, the smaller matrix is treated as if it were the same size as the larger matrix, filling the empty spaces with the same values. For example, a scalar becomes a matrix where all elements are the same, and a row vector transforms into a matrix where all rows are identical. If this is confusing, refer to the formula below. .* can be understood as element-wise multiplication since it combines a dot and a multiplication symbol. The symbols for other element-wise operations are created in the same manner.\n$$ A=\\begin{pmatrix} a_{1} \u0026amp; a_2 \u0026amp; a_{3} \\end{pmatrix},\\quad B=\\begin{pmatrix} b_{1} \\\\ b_2 \\\\ b_{3} \\\\ b_{4} \\end{pmatrix} \\quad \\implies \\quad \\begin{align*} A.B\u0026amp;=\\begin{pmatrix} a_{1} \u0026amp; a_2 \u0026amp; a_{3} \\\\ a_{1} \u0026amp; a_2 \u0026amp; a_{3} \\\\ a_{1} \u0026amp; a_2 \u0026amp; a_{3} \\\\ a_{1} \u0026amp; a_2 \u0026amp; a_{3} \\end{pmatrix} \\begin{pmatrix} b_{1} \u0026amp; b_{1} \u0026amp; b_{1} \\\\ b_2 \u0026amp; b_2 \u0026amp; b_2 \\\\ b_{3} \u0026amp; b_{3} \u0026amp; b_{3} \\\\ b_{4} \u0026amp; b_{4} \u0026amp; b_{4} \\end{pmatrix} \\\\ \u0026amp;= \\begin{pmatrix} a_{1}b_{1} \u0026amp; a_2b_{1} \u0026amp; a_{3}b_{1} \\\\ a_{1}b_2 \u0026amp; a_2b_2 \u0026amp; a_{3} b_2 \\\\ a_{1}b_{3} \u0026amp; a_2 b_{3} \u0026amp; a_{3} b_{3} \\\\ a_{1}b_{4} \u0026amp; a_2 b_{4} \u0026amp; a_{3} b_{4} \\end{pmatrix} \\end{align} $$\nExample codes and their output are shown below.\nA=[2 1 -3; 4 0 3]\rB=[1 2 3]\rC=[3; 1]\ra=A.*B\rb=A.*C\rc=B.*C\rd=3.*A Division rdivide(), ./: Returns the result of dividing each element of two matrices. The note about the size of matrices is the same as for .*. This can be used to easily calculate a matrix where each element is the reciprocal of matrix A, as 1./A.\nExample codes and their output are shown below.\nA=[2 1 -3; 4 0 3]\rB=[1 2 3]\rC=[3; 1]\ra=rdivide(A,B)\rb=A./C\rc=B./C\rd=1./A Power power(), .^: If A.^B, it returns the result where each element of A is the base and each element of B is the exponent. Example codes and their output are shown below.\nA=[2 1 -3; 4 0 3]\rB=[1 2 3]\rC=[3; 1]\ra=power(A,B)\rb=A.^C\rc=B.^C\rd=3.^A ","id":1326,"permalink":"https://freshrimpsushi.github.io/en/posts/1326/","tags":null,"title":"How to Perform Element-wise Operations on Two Matrices in MATLAB"},{"categories":"Îß§Ìä∏Îû©","contents":"Functions size(): Returns a row vector that contains the lengths of the rows and columns of the matrix.\nIt is useful for creating a zero matrix of the same size as the matrix being dealt with.\nzeros(size(A)): Returns a zero matrix of the same size as A.\nlength(): Returns the larger number among the rows and columns.\nIn the case of row vectors and column vectors, it is the same as the number of elements, so numel() is the same. Also, since size() returns the size of the rows and columns, length(A)=max(size(A)).\nnumel(): Returns the number of elements of the matrix.\nExample code and output are as follows.\nA=[1 2 3];\rB=[1 2 3 4 ; 2 3 4 1 ; 3 4 1 2];\rC=zeros(3,8);\ra=size(A)\rb=size(B)\rc=size(C)\rd=length(A)\re=length(B)\rf=length(C)\rg=numel(A)\rh=numel(B)\ri=numel(C) ","id":1323,"permalink":"https://freshrimpsushi.github.io/en/posts/1323/","tags":null,"title":"Matrix Size and Related Functions in MATLAB"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definition Let us assume an open set $\\Omega \\subset \\mathbb{R}^n$ is given. Then, $\\Omega_{\u0026lt;\\delta}$ and $\\Omega_{\u0026gt;\\delta}$ are defined as follows.\n$$ \\begin{align*} \\Omega_{\u0026lt;\\delta} :=\u0026amp; \\left\\{ x\\in\\Omega : \\mathrm{dist}(x, \\mathrm{bdry}\\Omega)\u0026lt;\\delta \\right\\} \\\\ \\Omega_{\u0026gt;\\delta} :=\u0026amp; \\left\\{ x\\in\\Omega : \\mathrm{dist}(x, \\mathrm{bdry}\\Omega)\u0026gt;\\delta \\right\\} \\end{align*} $$\nExplanation Such sets are usefully employed in partial differential equations, functional analysis, etc. Depending on the textbook, there are cases where it\u0026rsquo;s $\\Omega_\\delta=\\Omega_{\u0026lt;\\delta}$1 and cases where it\u0026rsquo;s $\\Omega_\\delta=\\Omega_{\u0026gt;\\delta}$2. In those instances, it\u0026rsquo;s best to faithfully follow the notation used in the class or textbook. Fresh Shrimp Sushi House uses both definitions, hence the notation was defined as above.\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p82\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p713\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1317,"permalink":"https://freshrimpsushi.github.io/en/posts/1317/","tags":null,"title":"Sets Outside/Inside a Certain Distance from the Boundary of a Set"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition1 Given two signed measures $\\nu$, $\\nu$. If there exists a $E,F\\ \\in \\mathcal{E}$ that satisfies the following three conditions for $\\nu$, $\\mu$, we say that the two signed measures $\\nu$, $\\mu$ are and denote it as $\\nu \\perp \\mu$ or $\\mu \\perp \\nu$:\n$E \\cup F=X$ $E \\cap F=\\varnothing$ $E$ is a null set with respect to $\\nu$, and $F$ is a null set with respect to $\\mu$. Also, the expressions \u0026lsquo;$\\nu$ is singular with respect to $\\mu$\u0026rsquo; and \u0026lsquo;$\\mu$ is singular with respect to $\\nu$\u0026rsquo; all mean the same thing.\nExplanation Let $\\mu_{n}$ be the Lebesgue measure in $\\mathbb{R}^n$. And let $\\delta_{x_{0}}$ be defined as the Dirac measure as follows:\n$$ \\delta_{x_{0}} (E) := \\begin{cases} 1 \u0026amp; x_{0} \\in E \\\\ 0 \u0026amp; x_{0} \\notin E \\end{cases} $$\nSuppose $E=\\left\\{ x_{0} \\right\\}$, $F=\\mathbb{R}^n-E$. Then $E\\cup F=\\mathbb{R}^n$ and $E \\cap F=\\varnothing$. Furthermore, $F$ is $\\delta_{x_{0}}-\\mathrm{null}$ and $E$ is $\\mu_{n} -\\mathrm{null}$, so the Lebesgue measure and the Dirac measure are mutually singular.\n$$ \\delta_{x_{0}} \\perp \\mu_{n} $$\nGerald B. Folland, Real Analysis: Modern Techniques and Their Applications (2nd Edition, 1999), p87\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1310,"permalink":"https://freshrimpsushi.github.io/en/posts/1310/","tags":null,"title":"Mutually Singular"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition Equation $\\mathbb{Z} [ \\omega ] := \\left\\{ a + \\omega b : a, b \\in \\mathbb{Z} \\right\\}$ is called the Eisenstein Ring, and its elements are referred to as Eisenstein Integers.\nTheorem [1]: $\\overline{ \\omega } = \\omega^{2} = - (1 + \\omega)$ [2]: $( a \\pm \\omega b ) + ( c \\pm \\omega d) = (a \\pm c) + \\omega (b \\pm d)$ [3]: $( a + \\omega b )( c + \\omega d) = (ac - bd) + \\omega (ad - bd + bc)$ Description $\\omega$ represents the complex roots $\\displaystyle \\omega := {{-1 + \\sqrt{-3}} \\over {2}} = e^{2 \\pi i/3 }$ of the cubic equation $x^3 +1 = 0$, and $\\mathbb{Z} [\\omega]$ is a simple extension of the integer ring $\\mathbb{Z}$. As interesting as Gaussian Integers with a bit more complex calculations, it essentially shares similarities with Gaussian Integers, making it not too unfamiliar. In the complex plane, $i$ forms a square lattice with $1,i,-1,-i$, and $\\omega$ forms a triangular lattice with $1, - \\omega^2, \\omega, -1, \\omega^2, -\\omega$.\nJust like there are Gaussian Primes for Gaussian Integers, there are also Eisenstein Primes for Eisenstein Integers.\nOn the field of $\\mathbb{Z} [i]$, the following conventional formula manipulation is possible: $$ \\begin{align*} (7 + \\omega 2)(4 - \\omega 2) =\u0026amp; (28 + 4) + \\omega (- 14 +4 +8 ) \\\\ =\u0026amp; 32 - \\omega 2 \\end{align*} $$ Also, given a natural number $n \\in \\mathbb{N}$, one can consider $\\mathbb{Z}_{n}[i]$ for a finite ring $\\mathbb{Z}_{n}$ as well. For example, when stating $n = 7$, the development changes as follows: $$ \\begin{align*} (7 + i2)(4 -i 2) =\u0026amp; (28 + 4) + \\omega (- 14 +4 +8 ) \\\\ =\u0026amp; 32 - \\omega 2 \\\\ \u0026amp; \\equiv 4 - \\omega 2 \\pmod{7} \\\\ \u0026amp; \\equiv 4 + \\omega 5 \\pmod{7} \\end{align*} $$ Note how naturally the use of congruence is employed. If it works in $\\mathbb{Z} [i]$, it seems only logical that it works in $\\mathbb{Z} [\\omega]$ as well. Just like repeatedly powering $i$ does not produce higher terms, likewise, $\\omega$ can also lower the degree as in $\\omega^2 = -(1+\\omega)$. Of course, this is not merely computation but a fact mathematically guaranteed by the properties of a simple extension.\nMeanwhile, $2$ and $3$ are the smallest even and odd primes respectively. Interestingly, the deeper one delves into the properties of Gaussian Integers, the more one becomes fixated on $i$, and similarly, with Eisenstein Integers on $3$. Interestingly enough, $\\overline{i} = i^3$ and it is found that $\\overline{\\omega} = \\omega^2$, showcasing the beauty of pure mathematics the more one looks into it.\nThe zero-divisor graph of the Eisenstein Ring was studied by Alcam.\nProof [1] By the definition of $\\omega$ and the properties of conjugate $$ \\begin{align*} \\omega^2 =\u0026amp; \\left( e^{2 \\pi i/3 } \\right)^2 \\\\ =\u0026amp; - e^{ \\pi i/3 } \\\\ =\u0026amp; - {{ 1 + i \\sqrt{3} } \\over { 2 }} \\\\ =\u0026amp; \\overline{ \\left( { -1 + i \\sqrt{3} } \\over { 2 } \\right) } \\\\ =\u0026amp; \\overline{ \\omega } \\\\ =\u0026amp; - (1 + \\omega) \\end{align*} $$\n‚ñ†\n[2] Since $\\mathbb{Z} [ \\omega ]$ is a ring, and associative and commutative laws hold for addition $$ \\begin{align*} ( a \\pm \\omega b ) + ( c \\pm \\omega d) =\u0026amp; a \\pm \\omega b + c \\pm \\omega d \\\\ =\u0026amp; a \\pm c + \\omega b \\pm \\omega d \\\\ =\u0026amp; (a \\pm c) + \\omega (b \\pm d) \\end{align*} $$\n‚ñ†\n[3] According to theorems [1] and [2] $$ \\begin{align*} ( a + \\omega b )( c + \\omega d) =\u0026amp; ac + \\omega ad + \\omega bc -(1 + \\omega) bd \\\\ =\u0026amp; (ac - bd) + \\omega (ad - bd + bc) \\end{align*} $$\n‚ñ†\n","id":1289,"permalink":"https://freshrimpsushi.github.io/en/posts/1289/","tags":null,"title":"Eisenstein Integer"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Theorem1 (a) Let $\\nu$ be a signed measure defined on a measurable space $(X, \\mathcal{E})$. Then there exist a positive set $P$ and a negative set $N$ for $\\nu$, satisfying the following:\n$$ P \\cup N=X \\quad \\text{and} \\quad P \\cap N =\\varnothing $$\nSuch a $X=P \\cup N$ is called a Hahn decomposition for $\\nu$.\n(b) Let $P^{\\prime}, N^{\\prime}$ be another pair of sets satisfying (a). Then the following sets are null sets for $\\nu$:\n$$ (P-P^{\\prime}) \\cup (P^{\\prime}-P)=(N-N^{\\prime}) \\cup (N^{\\prime}-N) $$\nThis can be denoted using the symmetric difference symbol as follows:\n$$ P\\Delta P^{\\prime}=N\\Delta N^{\\prime} $$\nExplanation (a) For any given measurable space, it is possible to separate the set $X$ into positive and negative sets with respect to $\\nu$ defined on the measurable space.\n(b) As stated above, even if there are multiple ways to divide the set $X$, essentially, there is no difference. $P$ and $P^{\\prime}$, $N$ and $N^{\\prime}$ always differ by only a null set, so they may be different from the set perspective but are the same from the measure perspective.\nProof Strategies: The** proof of this theorem itself is not very difficult, but the flow of the proof is not trivial, so I will explain it concretely before starting. First, define some positive set $P$. Then define $N$ as $N:=X-P$. If $N$ is a negative set, then the proof for (a) is complete. Before proving that $N$ is a negative set, we will verify that $N$ has two properties as defined above. Finally, we will use proof by contradiction. Assuming $N$ is not a negative set, we will complete the proof by showing that a contradiction arises using the two properties.\nWithout loss of generality, assume that $\\nu$ does not take the value $+\\infty$. For the other case, the same proof applies by considering $-\\nu$. Let $C$ be the collection of all positive sets in $\\mathcal{E}$. Then, by assumption, $\\nu$ does not take the value $+\\infty$, so there exists $M$ defined as below:\n$$ M:=\\sup \\limits_{P \\in C } \\nu (P) \u0026lt; \\infty $$\nNow, we can show that there exists a maximizer $P$ satisfying $\\nu (P)=M$. Consider the following maximizing sequence $\\left\\{ P_{j} \\right\\}$:\n$$ \\lim \\limits_{j \\rightarrow \\infty} \\nu (P_{j})=M $$\nSince there is no containment relationship between $P_{j}$\u0026rsquo;s, consider the following $\\tilde{P_{j}}$:\n$$ \\tilde{P_{j}} :=\\bigcup \\limits_{k=1}^j P_{k} $$\nThen, $\\nu (P_{j}) \\le \\nu (\\tilde{P_{j}}) \\le M$, so $\\left\\{ \\tilde{P_{j}} \\right\\}$ is a maximizing sequence. Also, it is obvious that $\\tilde{P_{1}} \\subset \\tilde{P_2}\\subset \\cdots $ by definition. Now, define $P$ as follows:\n$$ P := \\bigcup \\limits_{j=1}^\\infty \\tilde{P_{j}} $$\nThen, the following holds:\n$$ \\nu (P)=\\lim \\limits_{j\\rightarrow \\infty} \\nu (\\tilde{P_{j}})=M $$\nThus, we have shown the existence of a maximizer satisfying $\\nu (P)=M$. Moreover, since $P$ is the countable sum of positive sets, it is a positive set. In fact, such $P$ and $N:=X-P$ are the decomposition mentioned in the theorem. The process of proving that $N$ is such a negative set remains. Let\u0026rsquo;s now consider $N:=X \\setminus P$. As explained above, the proof ends if we show that $N$ is a negative set. First, let\u0026rsquo;s prove that such $N$ has the following two properties:\nClaim 1 $N$ does not contain any positive set with a measure value greater than $0$. In other words, it does not contain any non-null positive set. That is, if $\\nu (E)\u0026gt;0$ and $E$ is a positive set, then $E \\not \\subset N$.\nNote that it is possible for a set $E \\subset N$ to exist that is neither a positive nor a negative set. In other words, a subset of $N$ can be 1. a null set, 2. a negative set, or 3. a set that is neither positive nor negative.\nProof\nSuppose $E\\subset N$ is a positive set and $\\nu (E) \u0026gt;0$. Then, by the definition of $N$, $E$ and $P$ are disjoint sets. Therefore, the following holds:\n$$ \\nu (P \\cup E)=\\nu (P)+\\nu (E) $$\nHowever, since $\\nu (P)=M$, the following holds:\n$$ \\nu (P \\cup E)=\\nu (P)+\\nu (E)\u0026gt;M $$\nBut this contradicts the assumption that $M=\\sup \\nu (F)\\ \\forall F\\in \\mathcal{E}$. Therefore, there does not exist $E \\subset N$ such that $E$ is a positive set and $\\nu (E)\u0026gt;0$.\nClaim 2 If $A \\subset N$ and $\\nu (A)\u0026gt;0$, then there exists $B \\subset A$ such that $\\nu (B) \u0026gt; \\nu (A)$.\nProof\nLet\u0026rsquo;s say $A \\subset N$ and $\\nu (A)\u0026gt;0$. Then, by Claim 1, $A$ is not a positive set. Therefore, it is neither a null set nor a positive set. Hence, there exists $C$ satisfying the following conditions2:\n$$ C \\subset A,\\ \\nu (C) \u0026lt;0 $$\nNow, let\u0026rsquo;s define $B:=A-C$. Then, the following holds:\n$$ \\nu (A)=\\nu (B)+\\nu (C) \u0026lt; \\nu (B) $$\nNow, let\u0026rsquo;s assume $N$ is not a negative set. By showing that a contradiction arises using the above two properties, we prove that $N$ is a negative set.\nPart 1.\nLet $\\left\\{ A_{j} \\right\\}$ be a sequence of subsets of $N$. Let $\\left\\{ n_{j} \\right\\}$ be a sequence of natural numbers. Assuming $N$ is not a negative set, there exists some $B \\subset N$ with $\\nu (B) \u0026gt;0$. Let\u0026rsquo;s say the smallest $n_{j}$ satisfying $\\nu (B) \u0026gt; \\frac{1}{n_{j}}$ is $n_{1}$, and let\u0026rsquo;s call such $B$ as $A_{1}$. Since $\\nu (B)=\\nu (A_{1})\u0026gt;0$, the process done for $N$ can be applied to $A_{1}$ equally.\nPart 2\nAgain, there exists some $B\\subset A_{1}$ with $\\nu (B)\u0026gt;0$, and by Claim 2, $\\nu (B) \u0026gt; \\nu (A_{1})$. Therefore, there exists a natural number $n$ such that $\\nu (B) \u0026gt; \\nu (A_{1})+\\frac{1}{n}$. Let\u0026rsquo;s call the smallest such natural number $n_2$, and such $B$ as $A_2$.\nPart 3\nRepeating the same process, $n_{j}$ is the smallest natural number for which there exists some $B \\subset A_{j-1}$ satisfying $\\nu (B)\u0026gt;\\nu (A_{j-1}) + \\dfrac{1}{n_{j}}$, and such $B$ is called $A_{j}$. Now, let\u0026rsquo;s define $A=\\bigcap \\nolimits_{1}^\\infty A_{j}$. Since $\\nu$ is assumed not to take the value $+\\infty$ and by the property of signed measure $(B)$, the following holds:\n$$ \\begin{align*} +\\infty \\gt \\nu (A) \u0026amp;= \\nu \\left(\\bigcap \\nolimits_{1}^\\infty A_{j} \\right) \\\\ \u0026amp;= \\lim \\limits_{j \\rightarrow \\infty} \\nu (A_{j}) \\\\ \u0026amp;\\ge \\lim \\limits_{j\\rightarrow \\infty} \\left( \\nu (A_{j-1}) +\\frac{1}{n_{j}} \\right) \\\\ \u0026amp;\\ge \\lim \\limits_{j\\rightarrow \\infty} \\left( \\nu (A_{j-2}) + \\frac{1}{n_{j-1}} +\\frac{1}{n_{j}} \\right) \\\\ \u0026amp;\\vdots \\\\ \u0026amp;\\ge \\lim \\limits_{j\\rightarrow \\infty} \\left( \\nu (A_{1}) + \\frac{1}{n_{2}}+\\cdots +\\frac{1}{n_{j}} \\right) \\\\ \u0026amp;\\ge \\lim \\limits_{j\\rightarrow \\infty} \\left( \\frac{1}{n_{1}}+ \\frac{1}{n_{2}}+\\cdots +\\frac{1}{n_{j}} \\right) \\\\ \u0026amp;= \\sum \\limits_{j=1}^\\infty \\frac{1}{n_{j}} \\end{align*} $$\nSince the series is finite, the limit is $0$.\n$$ \\lim \\limits_{j\\rightarrow \\infty} \\frac{1}{n_{j}} =0 $$\nTherefore, we obtain the following:\n$$ \\begin{equation} \\lim \\limits_{j\\rightarrow \\infty} n_{j} =\\infty \\label{eq1} \\end{equation} $$\nHowever, as seen in Part 1, by Claim 2, there exists some natural number $n$ for which there exists $B \\subset A$ satisfying $\\nu (B) \u0026gt; \\nu (A) +\\dfrac{1}{n}$. Then, by the definition of $A$, $A \\subset A_{j-1}$, and by Claim 2, the sequence $\\left\\{ \\nu (A_{j}) \\right\\}$ is increasing. Therefore, since $\\nu (A) =\\lim \\limits_{j \\rightarrow \\infty} \\nu (A_{j})$, $\\nu (A) \u0026gt; \\nu (A_{j-1})$.\nAdditionally, by $(1)$, for sufficiently large $j$, $n_{j} \u0026gt;n$. Therefore, the following holds:\n$$ \\nu (B) \u0026gt; \\nu (A) +\\frac{1}{n}\u0026gt;\\nu (A_{j-1}) +\\frac{1}{n} \u0026gt; \\nu (A_{j-1}) +\\frac{1}{n_{j}} $$\nBut this contradicts the definition of $n_{j}$ and $A_{j}$. Therefore, the assumption that $N$ is not a negative set is wrong. Hence, $N$ is a negative set.\nLet\u0026rsquo;s consider $P^{\\prime}$, $N^{\\prime}$ as another decomposition satisfying the theorem. Then, the following holds:\n$$ P^{\\prime} \\cup N^{\\prime} =X \\quad \\text{and} \\quad P^{\\prime}\\cap N^{\\prime} =\\varnothing $$\nTherefore, we can see that $P-P^{\\prime} \\subset P$, $P-P^{\\prime}\\subset N^{\\prime}$. Then, $P-P^{\\prime}$ is both a positive set and a negative set, which is only possible if it\u0026rsquo;s a null set, so $P-P^{\\prime}$ is $\\nu-\\mathrm{null}$. Similarly, $\\nu -\\mathrm{null}$ can be shown for $P^{\\prime}-P$, $N-N^{\\prime}$, and $N^{\\prime}-N$.\n‚ñ†\nGerald B. Folland, Real Analysis: Modern Techniques and Their Applications (2nd Edition, 1999), p86-87\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIf not, A must be either a null set or a positive set by definition.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1308,"permalink":"https://freshrimpsushi.github.io/en/posts/1308/","tags":null,"title":"Hahn Decomposition Theorem"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition1 Let us call $\\nu$ on $(X,\\mathcal{E})$ a sign measure. And let us denote $E,F \\in \\mathcal{E}$. Then\nWhen $\\nu (F) \\ge 0,\\ \\forall F\\subset E$, we call $E$ regarding $\\nu$ a positive set or simply positive.\nWhen $\\nu (F) \\le 0,\\ \\forall F\\subset E$, we call $E$ regarding $\\nu$ a negative set or simply negative.\nWhen $\\nu (F)=0,\\ \\forall F\\subset E$, we call $E$ regarding $\\nu$ a null set or $\\nu$-null.\nExplanation According to the definition, the null set is a set that is both a positive set and a negative set at the same time. It\u0026rsquo;s easy to misunderstand the definitions of positive set and negative set, so it\u0026rsquo;s crucial to understand them correctly. $E$ is not called a positive set when $\\mu (E)\u0026gt;0$. For $E$ to be called a positive set, for every measurable subset $F\\in\\mathcal{E}$ of it, $\\mu (F) \\ge 0$ must be satisfied. Naturally, this condition implies that $\\nu (E) \u0026gt;0$ holds. To summarize:\n$$ E\\ \\mathrm{is\\ positive\\ set\\ for\\ }\\nu \\implies \\nu (E)\u0026gt;0 \\\\ \\nu (E)\u0026gt;0 \\not\\implies E\\ \\mathrm{is\\ positive\\ set\\ for\\ }\\nu $$\nThe same applies to negative sets and null sets. The above discussion is only applicable to sign measures. The case is a bit different for absolute measures. When $\\mu$ is called an absolute measure, since it always has a function value greater or equal to $0$, $\\mu (E)=0$ being equal to $E$ being $\\nu$-null are equivalent. The same goes for discussions about positive sets. Therefore, there\u0026rsquo;s no need to specifically use the terms positive set or null set for absolute measures. See the diagram below.\nIf we integrate the function $f$ over the interval $E_2$ using the Riemann integral, its value is certainly positive, but we do not call $E_2$ a positive set. In the example of the above figure, an interval that does not have any point where the function value is less than zero is a positive set. In the diagram, $E_{1}$, $E_{3}$ are positive sets, and $E_{5}$ is a negative set. $E_2$, $E_{4}$ are neither positive sets, negative sets, nor null sets. The most important point here is that a certain $E \\in \\mathcal{E}$ does not necessarily have to be a positive or negative set.\nSummary (a) A measurable subset of a positive set is also a positive set.\n(b) The countable union of arbitrary positive sets is also a positive set.\nProof (a) It\u0026rsquo;s trivial by the definition of a positive set.\n(b) Let $P_{1},\\ P_2,\\ \\cdots$ be a positive set. And let us define $Q_{n}$ as follows.\n$$ Q_{1}=P_{1},\\quad Q_{n}=P_{n}-\\left( \\bigcup \\nolimits_{j=1}^{n-1}P_{j} \\right)\\ \\forall\\ n\u0026gt;1 $$\nThen $Q_{n} \\subset P_{n}$ and each of $Q_{n}$ is disjoint. Therefore, $Q_{n}$ is a positive set by (a). Also, the following equation holds.\n$$ \\bigcup \\nolimits_{1}^{\\infty} P_{j}=\\bigcup \\nolimits_{1}^{\\infty} Q_{j} $$\nNow, let $E$ be any measurable subset of $\\bigcup \\nolimits _{1}^\\infty P_{n}$.\n$$ E \\in \\left( \\bigcup \\nolimits _{1}^\\infty Q_{n} \\right)=\\left( \\bigcup \\nolimits _{1}^\\infty P_{n} \\right) $$\nThen, proving $\\nu (E) \\ge 0$ concludes the proof. By the definition of $E$, the following equation is established. $$ E= \\bigcup \\limits_{j=1}^\\infty \\left( Q_{j} \\cap E \\right) $$ Since each $Q_{n}$ is disjoint, by the countable additivity of sign measures, the following holds.\n$$ \\nu (E) = \\nu \\left(\\bigcup \\nolimits_{j=1}^\\infty \\left( Q_{j} \\cap E \\right) \\right) =\\sum \\limits_{j=1}^\\infty \\nu \\left( Q_{j} \\cap E \\right) $$\nSince $Q_{n}$ is a positive set and $(Q_{j}\\cap E ) \\subset Q_{j}$, the right side of the equation must be at least $0$.\n$$ \\nu (E) =\\sum \\limits_{j=1}^\\infty \\nu \\left( Q_{j} \\cap E \\right) \\ge 0 $$\n‚ñ†\nGerald B. Folland, Real Analysis: Modern Techniques and Their Applications (2nd Edition, 1999), p86\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1303,"permalink":"https://freshrimpsushi.github.io/en/posts/1303/","tags":null,"title":"Positive Set, Negative Set, Null Set"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition 1 Let\u0026rsquo;s assume a Probability Space $( \\Omega , \\mathcal{F} , P)$ is given.\nA function $X : \\Omega \\to \\mathbb{R}$ that satisfies $X^{-1} (B) \\in \\mathcal{F}$ for every Borel Set $B \\in \\mathcal{B} (\\mathbb{R})$ is called a Random Variable. $\\mathcal{F}_{X}$ defined as follows is called the Sigma Field generated by $X$. $$ \\mathcal{F}_{X} := X^{-1} ( \\mathcal{B} ) = \\sigma (X) = \\left\\{ X^{-1} (B) \\in \\Omega : B \\in \\mathcal{B}( \\Omega ) \\right\\} $$ Measure $P_{X}$ defined as follows is called the Probability Distribution of $X$. $$ P_{X} (B) := P ( X^{-1} (B) ) $$ If you haven\u0026rsquo;t encountered measure theory yet, you can ignore the term probability space. Explanation Just like the probability space, a random variable can also be rigorously defined within Measure Theory.\nSaying $X^{-1} (B) \\in \\mathcal{F}$ means that $X$ maps elements of $\\Omega$ to real numbers allowing the use of relations like $P(a \\le X \\le b)$ while ensuring that the pre-images of Borel sets belong to the Sigma Field, thus limiting what is considered an Event to reasonable sets only. At first glance, it might seem overly abstract, but paradoxically, its goal is to counter excessive abstraction. According to the definition, a random variable $X$ is not only a real function but also a Measurable Function, and if $\\Omega = \\mathbb{R}$, then $\\mathcal{F} = \\mathcal{B} \\left( \\mathbb{R} \\right)$, making it a Borel function $X : \\mathbb{R} \\to \\mathbb{R}$. Basic theorems in mathematical statistics are sufficient at this level. Beyond this, generalization to multivariate random variables is simply done by defining $X : \\Omega \\to \\mathbb{R}^{p}$ that satisfies $X^{-1} (B) \\in \\mathcal{F}$ for every Borel set $B \\in \\mathcal{B} (\\mathbb{R}^{p})$. Naturally, $X$ can be expressed as a vector $X = ( X_{1}, \\cdots , X_{p})$ for each random variable $X_{i} : \\Omega \\to \\mathbb{R}$ and is called a Probability Vector. When this leads to a sequence of random variables, it is called a Stochastic Process, and more generally, a Random Element. For a Sigma Field $\\mathcal{G}$, if $Y^{-1} ( \\mathcal{B} ) \\in \\mathcal{G}$, then $Y$ is $\\mathcal{G}$-measurable, and naturally, according to the definition of $\\mathcal{F}_{X}$, $X$ is $\\mathcal{F}_{X}$-measurable. It might be confusing with all the definitions, but if you think about it step by step, it\u0026rsquo;s not difficult at all. Since $X^{-1} (B) \\in \\mathcal{F}$, you can think of it as if reversing the function, which leads to $X^{-1} : \\mathcal{B} (\\mathbb{R}) \\to \\mathcal{F}$. This way, $P_{X} : = ( P \\circ X^{-1} )$ can be understood as $$ P_{X} : \\mathcal{B} (\\mathbb{R}) \\to \\mathcal{F} \\to [0,1] $$ and is merely a composite function that maps any values between $0$ and $1$ for a given Borel set $B$. For example, $[-3,-2]$ is naturally a Borel set of $\\mathbb{R}$, and depending on how the random variable $Y$ is defined, it enables calculations like $P_{Y} ( [-3,-2] ) = 0.7$. See Also Random Variables and Probability Distributions as defined in Mathematical Statistics Capinski. (1999). Measure, Integral and Probability: p66~68.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1288,"permalink":"https://freshrimpsushi.github.io/en/posts/1288/","tags":null,"title":"Probability Variables and Probability Distributions Defined by Measure Theory"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition1 Let $(X, \\mathcal{E})$ be a measurable space. A function $\\nu : \\mathcal{E} \\to \\overline{\\mathbb{R}}$ which takes extended real values and satisfies the conditions below is called a signed measure.\n$\\nu ( \\varnothing ) = 0$ At most one of $\\pm \\infty$ can have a function value of $\\nu$. In other words, if $-\\infty \\in \\nu (\\mathcal{E})$ then $+\\infty \\notin \\nu (\\mathcal{E})$, and if $+\\infty \\in \\nu (\\mathcal{E})$ then $-\\infty \\notin \\nu (\\mathcal{E})$. Let $\\left\\{E_{j}\\right\\}$ be a sequence of mutually exclusive sets in $\\mathcal{E}$. Then it satisfies $\\nu \\left( \\bigcup \\nolimits_{j=1}^\\infty E_{j} \\right) =\\sum \\limits_{j=1}^\\infty \\nu (E_{j})$. When $\\nu (\\cup _{1}^\\infty E_{j})$ is finite, the sum on the right converges absolutely. Explanation Simply put, it is a generalization of measure that allows for negative values. Therefore, if it is a measure, it is also a signed measure. When mentioning measure and signed measure together, to emphasize, a measure is sometimes called a positive measure. A specific example of a signed measure is the Riemann integral.\nMeanwhile, since a measure always has to have a non-negative function value, it can be thought of as taking the absolute value of any function\u0026rsquo;s Riemann integral. Also, every signed measure can be represented as the difference between two measures.\n$$ \\nu = \\mu_{1} -\\mu_2 $$\nProperties Let $\\nu$ be a signed measure defined on a measurable space $(X,\\mathcal{E})$.\nContinuity from below:\nLet $\\left\\{ E_{j} \\right\\}_{1}^\\infty \\subset \\mathcal{E}$ be a monotone increasing sequence, which means $E_{1} \\subset E_2 \\subset \\cdots$. Then the following holds: $$ \\mu\\left( \\bigcup \\nolimits _{1}^\\infty E_{j} \\right)= \\lim \\limits_{j\\rightarrow \\infty} \\mu (E_{j}) $$\nContinuity from above:\nLet $\\left\\{ E_{j} \\right\\}_{1}^\\infty \\subset \\mathcal{E}$ be a monotone decreasing sequence, which means $E_{1} \\supset E_2 \\supset \\cdots$. And let $\\mu (E_{1})\u0026lt;\\infty$. Then the following holds: $$ \\mu\\left(\\bigcap \\nolimits _{1}^\\infty E_{j} \\right)= \\lim \\limits_{j\\rightarrow \\infty} \\mu (E_{j}) $$\nFundamentally, the proofs are the same as in measure1. The proof in the context of measures required countable additivity, and since signed measures also have countable additivity, the proof method is the same. Therefore, it is omitted.\nSee Also Measure Complex Measure See properties (C), (D)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1301,"permalink":"https://freshrimpsushi.github.io/en/posts/1301/","tags":null,"title":"Signed Measures"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition Let $(X,\\mathcal{E})$ be a measurable space. A function $\\mu : \\mathcal{E} \\to \\overline{\\mathbb{R}}$ that takes extended real values is called a measure if it satisfies the following three conditions:\n(a) $\\mu ( \\varnothing ) = 0$\n(b) $\\mu (E) \\ge 0,\\quad \\forall E\\in \\mathcal{E}$\n(c) Suppose $\\left\\{E_{j}\\right\\}$ are sequences of mutually disjoint sets in $\\mathcal{E}$. Then the following holds:\n$$ \\mu \\left( \\bigcup _{j=1}^\\infty E_{j} \\right) =\\sum \\limits_{j=1}^\\infty \\mu (E_{j}) $$\nThe ordered pair $(X,\\mathcal{E}, \\mu)$ is called a measure space.\nTwo sets $E_{1}$, $E_2$ are said to be disjoint if they satisfy $E_{1} \\cap E_2=\\varnothing$.\nExplanation Replacing condition $\\mu$ with $\\mu\\ :\\ \\mathcal{E} \\rightarrow [0,\\infty]$ includes (b), so it can be omitted.\nCondition (c) refers to countable additivity. It\u0026rsquo;s important to note that it only applies to mutually disjoint sets.\nWhen mentioning both signed measures and measures together, for emphasis, measures are also referred to as positive measures.\nProperties Let $(X,\\mathcal{E},\\mu)$ be a measure space.\n(A) Monotonicity: If $E,F\\in \\mathcal{E}$ and $E\\subset F$, then $\\mu (E) \\le \\mu (F)$.\n(B) Countable sub-additivity: If $\\left\\{ E_{j} \\right\\}_{1}^\\infty$ are sequences of elements in $\\mathcal{E}$, then $\\mu \\left( \\bigcup_{1}^\\infty E_{j} \\right) \\le \\sum _{1}^\\infty \\mu (E_{j})$.\n(C) Continuity from below: Suppose $\\left\\{ E_{j} \\right\\}_{1}^\\infty \\subset \\mathcal{E}$ is a monotonically increasing sequence, i.e., $E_{1} \\subset E_2 \\subset \\cdots$. Then the following holds: $$ \\mu\\left( \\bigcup \\nolimits _{1}^\\infty E_{j} \\right)= \\lim \\limits_{j\\rightarrow \\infty} \\mu (E_{j}) $$\n(D) Continuity from above: Suppose $\\left\\{ E_{j} \\right\\}_{1}^\\infty \\subset \\mathcal{E}$ is a monotonically decreasing sequence, i.e., $E_{1} \\supset E_2 \\supset \\cdots$. And let $\\mu (E_{1})\u0026lt;\\infty$. Then the following holds: $$ \\mu\\left(\\bigcap \\nolimits _{1}^\\infty E_{j} \\right)= \\lim \\limits_{j\\rightarrow \\infty} \\mu (E_{j}) $$\nProof (A) Let\u0026rsquo;s say $E \\subset F$. Then $F=F\\setminus E+ E$ is true. Since $E$ and $F\\setminus E$ are mutually disjoint, by the definition of measure (c), the following holds:\n$$ \\mu (F) = \\mu (F\\setminus E+ E) = \\mu (F\\setminus E) + \\mu (E) $$\nThen, by the definition of measure (b), the following holds:\n$$ \\mu (F\\setminus E) + \\mu (E) \\ge \\mu (E) $$\nTherefore, the following is obtained:\n$$ \\mu (F) \\ge \\mu (E) $$\n‚ñ†\n(B) Let\u0026rsquo;s say $F_{1}=E_{1}$. And for $k\u0026gt;1$, say $F_{k}=E_{k} \\setminus \\left( \\bigcup_{1}^{k-1} E_{j} \\right)$. Then each $F_{k}$ is mutually disjoint and $\\bigcup_{1}^n F_{j}=\\bigcup_{1}^n E_{j},\\ \\forall n$. Also, for each $j$, $F_{j} \\subset E_{j}$ holds. Therefore, the following holds:\n$$ \\mu \\left( \\bigcup \\nolimits_{1}^\\infty E_{j}\\right)=\\mu \\left( \\bigcup \\nolimits_{1}^\\infty F_{j}\\right)=\\sum \\limits_{1}^\\infty \\mu (F_{j}) \\le \\sum \\limits_{1}^\\infty\\mu (E_{j}) $$\nThe second equality holds because of the definition of measure (c). The last inequality is due to (A).\n‚ñ†\n(C) Let\u0026rsquo;s say $E_{0}:= \\varnothing$. And let\u0026rsquo;s say $F_{j}=E_{j}\\setminus E_{j-1}$. Then each $F_{j}$ is mutually disjoint. Also, $\\bigcup _{1}^\\infty F_{j} =\\bigcup_{1}^\\infty E_{j}$ holds. Therefore, the following holds:\n$$ \\begin{align*} \\mu \\left( \\bigcup \\nolimits_{1}^\\infty E_{j}\\right) \u0026amp;= \\mu \\left( \\bigcup \\nolimits_{1}^\\infty F_{j}\\right) \\\\ \u0026amp;= \\sum_{1}^\\infty \\mu (F_{j}) \\\\ \u0026amp;= \\sum \\limits_{1}^\\infty \\mu (E_{j} \\setminus E_{j-1} ) \\\\ \u0026amp;= \\lim \\limits_{n \\rightarrow \\infty} \\sum \\limits_{1} ^n \\mu (E_{j}\\setminus E_{j-1} ) \\\\ \u0026amp;= \\lim \\limits_{n \\rightarrow \\infty} \\mu (E_{n}) \\\\ \u0026amp;= \\lim \\limits_{j \\rightarrow \\infty} \\mu (E_{j}) \\end{align*} $$\nThe second equality holds because of the definition of measure (c).\n‚ñ†\n(D) Let\u0026rsquo;s say $F_{j}=E_{1} \\setminus E_{j}$. Then $F_{1} \\subset F_2 \\subset \\cdots$ holds. Also, $\\mu (E_{1})=\\mu (F_{j})+\\mu (E_{j})$, and $\\bigcup_{1}^\\infty F_{j}=E_{1} \\setminus \\left( \\bigcap_{1}^\\infty E_{j} \\right)$ holds. Since $E_{1}= \\bigcup_{1}^\\infty F_{j}+\\bigcap_{1}^\\infty E_{j}$, the following holds:\n$$ \\begin{align*} \\mu (E_{1}) \u0026amp;= \\mu \\left( \\bigcap \\nolimits_{1}^\\infty E_{j}\\right) + \\mu \\left( \\bigcup \\nolimits _{1}^\\infty F_{j} \\right) \\\\ \u0026amp;= \\mu \\left( \\bigcap \\nolimits_{1}^\\infty E_{j}\\right) + \\lim \\limits_{j \\rightarrow \\infty} \\mu ( F_{j} ) \\\\ \u0026amp;= \\mu \\left( \\bigcap \\nolimits_{1}^\\infty E_{j}\\right) + \\lim \\limits_{j \\rightarrow \\infty}\\big[ \\mu ( E_{1} )-\\mu (E_{j}) \\big] \\\\ \u0026amp;= \\mu ( E_{1} )+ \\mu \\left( \\bigcap \\nolimits_{1}^\\infty E_{j}\\right) -\\lim \\limits_{j \\rightarrow \\infty}\\mu (E_{j}) \\end{align*} $$\nThe second equality is due to (C). Since $\\mu (E_{1}) \u0026lt; \\infty$, the following is obtained:\n$$ \\mu \\left( \\bigcap \\nolimits_{1}^\\infty E_{j}\\right) = \\lim \\limits_{j \\rightarrow \\infty}\\mu (E_{j}) $$\n‚ñ†\nSee also Lebesgue measure Borel measure Signed measure Complex measure ","id":1302,"permalink":"https://freshrimpsushi.github.io/en/posts/1302/","tags":null,"title":"General Definitions of Measure"},{"categories":"ÏïåÍ≥†Î¶¨Ï¶ò","contents":"Definition The time it takes to solve a given problem is called time complexity, and the memory requirements are referred to as space complexity.\nExample Asymptotic notation is a very useful means for expressing these. Let\u0026rsquo;s take a look at an example of time complexity.\nConstant Time $O(1)$ Algorithms that can finish regardless of $n$, essentially taking no time. For example, finding the third element in $\\mathbb{x} = [4,3,8,-1,-9,0,5,7,2,6]$ just returns $8$ without caring how $\\mathbb{x}$ looks.\nLinear Time $O(n)$ Takes time proportional to $n$. For example, finding the maximum value in $\\mathbb{x} = [4,3,8,-1,-9,0,5,7,2,6]$ can be done in $8$ tries, but to ensure that it is indeed the maximum value, the rest of the elements must also be checked. Though the expression may seem a bit poor, linear time algorithms are considered quite fast in reality.\nQuadratic Time $O(n^2)$ Takes time proportional to $n^2$. For example, if sorting $\\mathbb{x} = [4,3,8,-1,-9,0,5,7,2,6]$ in order of size, find the maximum value, place it at the end, and repeat with the remaining array. Since finding the maximum value each time takes $n, n-1, \\cdots , 1$ time, their sum becomes $\\displaystyle \\sum_{k=1}^{n} k = {{ n (n+1)} \\over {2}} = O(n^2)$ according to the formula for the sum of an arithmetic series. Although a smarter method might exist, there\u0026rsquo;s no need to contemplate a more foolish method.\nCubic Time $O(n^3)$ Takes time proportional to $n^3$. For an example, consider multiplying matrices $n=2^{k}$ by $n \\times n$, thinking of calculating $A, B \\in \\mathbb{R}^{n \\times n}$ multiplied by $C = AB$. Then, using the Jordan Block matrix representation, compute the multiplication of the following eight ${{n} \\over {2}} \\times {{n} \\over {2}}$ matrices. $$ AB= \\begin{bmatrix} A_{1} \u0026amp; A_{2} \\\\ A_{3} \u0026amp; A_{4} \\end{bmatrix} \\begin{bmatrix} B_{1} \u0026amp; B_{2} \\\\ B_{3} \u0026amp; B_{4} \\end{bmatrix} = \\begin{bmatrix} C_{1} \u0026amp; C_{2} \\\\ C_{3} \u0026amp; C_{4} \\end{bmatrix} = C $$\n$$ C_{1} = A_{1}B_{1} + A_{2} B_{3} $$\n$$ C_{2} = A_{1}B_{2} + A_{2} B_{4} $$\n$$ C_{3} = A_{3}B_{1} + A_{4} B_{3} $$\n$$ C_{4} = A_{3}B_{2} + A_{4} B_{4} $$ Continue this computation, since the time it takes to do one calculation is $T(n)$ and if the running time outside the repetition is $c$ then $\\displaystyle T(n) = 8 T \\left( {{n} \\over {2}} \\right) + c$, $$ \\begin{align*} T(n) =\u0026amp; 8 T \\left( {{n} \\over {2}} \\right) + c \\\\ =\u0026amp; 8 \\left[ 8 T \\left( {{n} \\over {4}} \\right) + c \\right] + c \\\\ =\u0026amp; 8 \\left[ 64 T \\left( {{n} \\over {8}} \\right) + 8 c + c \\right] + c \\\\ =\u0026amp; 8^3 T \\left( {{n} \\over {8}} \\right) + (1+8+8^2)c \\\\ =\u0026amp; 8^3 T \\left( {{n} \\over {8}} \\right) + {{8^3 - 1} \\over {8 - 1}}c \\\\ \u0026amp; \\vdots \u0026amp; \\\\ \\approx\u0026amp; 8^{\\log_{2} n} ( T(1) + c ) \\\\ =\u0026amp; n^{\\log_{2} 8} ( T(1) + c ) \\\\ =\u0026amp; n^{3} ( T(1) + c ) \\\\ =\u0026amp; \\Theta ( n^3 ) \\end{align*} $$ that\u0026rsquo;s why. Matrix multiplication is almost without exception and is done a lot in applied areas involving math. However, $n^3$ is somewhat large. Just $n=100$ becomes a whopping $n^3 = 10^6$. Can we further reduce the computation here? It seems there\u0026rsquo;s nothing more to reduce when we\u0026rsquo;re already not doing unnecessary calculations. However, an amazing method called the Strassen algorithm can reduce this even further. This is the beauty of algorithms.\nLogarithmic Time $O \\left( \\log (n) \\right)$ This means incredibly fast. Suppose there\u0026rsquo;s a problem of finding the position of $0$ in a sorted array $\\text{sort} (\\mathbb{x}) = [-9,-1,0,2,3,4,5,6,7,8]$. An intuitive method is to choose a middle element, check if it\u0026rsquo;s greater or less than $0$, and if greater, discard the right side, if less, discard the left side of the array to narrow down and find it. This is called binary search. Since the time it takes for one calculation is $T(n)$ and the time it takes to compare is $c$, $$ \\begin{align*} T(n) =\u0026amp; T \\left( {{n} \\over {2}} \\right) + c \\\\ =\u0026amp; \\left[ T \\left( {{n} \\over {4}} \\right) + c \\right] + c \\\\ =\u0026amp; T \\left( {{n} \\over {4}} \\right) + 2 c \\\\ =\u0026amp; T \\left( {{n} \\over {8}} \\right) + 3 c \\\\ \u0026amp; \\vdots \u0026amp; \\\\ \\approx\u0026amp; T \\left( 1 \\right) + c \\log_{2} n \\\\ =\u0026amp; O \\left( \\log_{2} (n) \\right) \\end{align*} $$ that\u0026rsquo;s why. It\u0026rsquo;s fine to say that $O( \\log (n)))$ according to the logarithm base change formula, but originally in computer science, if there\u0026rsquo;s no specific mention of the log base, it\u0026rsquo;s usually not $e = 2.7182\u0026hellip;$ but $2$, so no need to worry about the expression.\nExponential Time $O(2^n)$ This means it takes an incredibly long time. Using recursion to calculate the Fibonacci sequence is very inefficient because the time it takes to calculate the $n$ Fibonacci number $a_{n}$ is $T(n)$ and the time it takes to add the two previous terms is $c$, so for the golden ratio $\\phi = 1.618\u0026hellip;$, $$ \\begin{align*} T(n) =\u0026amp; T(n-1) + T(n-2) + c \\\\ =\u0026amp; [ T(n-2) + T(n-3) + c ] + T(n-2) + c \\\\ =\u0026amp; 2 T(n-2) + T(n-3) + (1+1) c \\\\ =\u0026amp; 3 T(n-3) + 2 T(n-4) + (1+1+2) c \\\\ =\u0026amp; 5 T(n-4) + 3 T(n-5) + (1+1+2 + 3) c \\\\ =\u0026amp; 8 T(n-6) + 5 T(n-4) + (1+1+2+3+5) c \\\\ \u0026amp; \\vdots \u0026amp; \\\\ =\u0026amp; c \\sum_{k=1}^{n} a_{n} \\\\ \\approx\u0026amp; {{\\phi^{n-1}-1} \\over {\\phi-1}} c \\\\ =\u0026amp; \\Omega ( \\phi^n ) \\end{align*} $$ that\u0026rsquo;s why. The last part is approximated using the formula for the sum of a geometric series since $\\displaystyle \\phi \\approx {{a_{n}} \\over {a_{n-1}}}$. Such algorithms are practically impossible to use, so look for solutions like dynamic programming, or conversely, exploiting such time complexities could be applied to cryptography.\n","id":1283,"permalink":"https://freshrimpsushi.github.io/en/posts/1283/","tags":null,"title":"Time Complexity and Space Complexity"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 Given a time series data $\\left\\{ p_{t} \\right\\}$.\nWhen the variance of $\\left\\{ p_{t} \\right\\}$ depends on $t$, $\\left\\{ p_{t} \\right\\}$ is said to have Heteroscedasticity. The phenomenon of the variance of $\\left\\{ p_{t} \\right\\}$, which has Heteroscedasticity, increasing and decreasing repeatedly is referred to as Volatility Clustering. The following defined $r_{t}$ is referred to as (Log) Return in $t$. $$ r_{t} := \\nabla \\log p_{t} = \\log {{ p_{t} } \\over { p_{t-1} }} $$ Explanation Heteroscedasticity is read as [heteroscedasticity] and Volatility Clustering as [volatility clustering]. There are few documents in Korean that explain these two terms, probably because those who study this see no need to simplify the terminology. While writing and reading about Heteroscedasticity and Volatility Clustering does not feel particularly unnatural, when speaking, the long words are often pronounced as they are.\nHeteroscedasticity ARIMA models are interested in the mean of the data, as is the case with most statistical analyses. What matters is how the actual values move. But not only the values themselves depend on time; the variation itself can also change over time. That\u0026rsquo;s why the word Heteroscedasticity was coined. If the variance of time series data is always constant regardless of time, the term would be unnecessary.\nThe interest in the variance of time series is mainly in the field of economics and finance. Changes in data signify changes in value, and can be directly used when discussing the risk of an asset. Since risk is just another form of profit, it certainly is a matter of interest. Time series data is commonly written as $\\left\\{ y_{t} \\right\\}$, but when focusing on Heteroscedasticity, writing it as $\\left\\{ p_{t} \\right\\}$ is also for that reason. $p_{t}$\u0026rsquo;s $p$ comes from Price.\nVolatility Clustering The phenomenon where the variance increases and decreases is called Volatility Clustering, and the reason for having such a term is simple. There are no instances where the volatility in the market only increases or decreases, and even if there were, it would not be complex enough to require statistical analysis. This could be described more elegantly in statistical terms, but for now, let\u0026rsquo;s stick to this explanation.\nReturn Return is a useful expression for identifying and analyzing Heteroscedasticity. By taking the log, if $p_{t}$ is greater than $p_{t-1}$ (if the price goes up), it becomes a positive number, and if it\u0026rsquo;s smaller (if the price goes down), a negative number. Multiplying by 100 makes it easier to view as a percentage. Since it uses the rate of change rather than just how big or small the difference is, another advantage is that it is less affected by the unique characteristics of the data.\nPractice The graph above is drawn by extracting only DAX from the built-in data EuStockMarkets, showing the German DAX index from 1991 to 1999.\nReturn is drawn as shown above, and if the image with the highlight seems to show that the volatility is alternating between high and low, then it can be considered that Volatility Clustering has been understood.\nEven if it doesn\u0026rsquo;t seem so, that\u0026rsquo;s fine. It is the role of statistics to solidify such \u0026lsquo;arguments based on sensation\u0026rsquo;, and no statistical techniques have been applied yet.\nCode ‚ñ†cod\nCryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p277~279.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1272,"permalink":"https://freshrimpsushi.github.io/en/posts/1272/","tags":["R"],"title":"Heteroskedasticity and Volatility Clustering in Time Series Analysis"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 $\\mathbb{Z} [i] := \\left\\{ a + i b : a, b \\in \\mathbb{Z} \\right\\}$ is called a Gaussian Ring, and its elements are called Gaussian Integers.\nTheorems [1]: $\\overline{i} = i^{3}$ [2]: $( a \\pm ib ) + ( c \\pm id) = (a \\pm c) + i (b \\pm d)$ [3]: $( a + ib )( c + id) = (ac - bd) + i (ad + bc)$ Explanation $i$ is a complex root of the quadratic equation $x^2 +1 = 0$, and $\\mathbb{Z} [i]$ is an extension of the integer ring $\\mathbb{Z}$. It is similar to the extension of the real number field $\\mathbb{R}$ to the complex number field $\\mathbb{C} = \\mathbb{R} [i]$, and the principle behind it is not much different. There is no reason why complex numbers should be considered unthinkable, even when discussing integers where even irrational numbers are not taboo. In fact, they are simpler than irrational numbers.\nJust as there are prime numbers among integers, there are Gaussian primes among Gaussian integers. On $\\mathbb{Z} [i]$, the following conventional formulaic development is possible: $$ \\begin{align*} (7 + i2)(4 -i 2) =\u0026amp; (28 + 4) + i (- 14 +8 ) \\\\ =\u0026amp; 32 - i 6 \\end{align*} $$ Also, given a natural number $n \\in \\mathbb{N}$, for a finite ring $\\mathbb{Z}_{n}$, $\\mathbb{Z}_{n}[i]$ can also be considered. For example, when $n = 7$, the development changes as follows: $$ \\begin{align*} (7 + i2)(4 -i 2) =\u0026amp; (28 + 4) + i (- 14 + 8 ) \\\\ =\u0026amp; 32 - i 6 \\\\ \u0026amp; \\equiv 4 - i 6 \\pmod{7} \\\\ \u0026amp; \\equiv 4 + i \\pmod{7} \\end{align*} $$ Note how naturally the use of congruences comes into play. The desire to generalize $\\mathbb{Z}$ to $\\mathbb{Z} [i]$ is something natural to mathematicians, to an extent that it might be hard to explain in words. While it may be uncertain if it could compare to the innovations brought about by allowing $i$ in calculus, it is clear that number theory too has been enriched and made more beautiful. Just consider the Fundamental Theorem of Algebra, in $\\mathbb{Z} [i]$, there is no messy talk of a $d$th degree polynomial equation having possibly more than $d$ solutions. With the introduction of complex numbers, it can simply be said to have exactly $d$ solutions.\nA step further in the integer systems includes Eisenstein Integers.\nThe zero divisor graph of the Gaussian Ring has been studied by Osba.\nProofs [1] According to the definition of $i$ and the properties of conjugate, $$ \\overline{i} = -i = i^{3} $$\n‚ñ†\n[2] Since $\\mathbb{Z} [i]$ is a ring, and the additive operation satisfies the associative and commutative laws, $$ \\begin{align*} ( a \\pm ib ) + ( c \\pm id) =\u0026amp; a \\pm ib + c \\pm id \\\\ =\u0026amp; a \\pm c + ib \\pm id \\\\ =\u0026amp; (a \\pm c) + i (b \\pm d) \\end{align*} $$\n‚ñ†\n[3] From [2], $$ \\begin{align*} ( a + ib )( c + id) =\u0026amp; ac + ibc + iad + (- 1)bd \\\\ =\u0026amp; (ac - bd) + i (ad + bc) \\end{align*} $$\n‚ñ†\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p267.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1267,"permalink":"https://freshrimpsushi.github.io/en/posts/1267/","tags":null,"title":"Gaussian Integers"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 An multiplicative norm $N : D \\to \\mathbb{Z}$ on an integral domain $D$ with respect to all $\\alpha , \\beta \\in D$ is defined by the following conditions:\n(i): $N (\\alpha) = 0 \\iff \\alpha = 0$ (ii): $N ( \\alpha \\beta ) = N ( \\alpha ) N ( \\beta )$ Theorem Let $p \\in \\mathbb{Z}$ be a prime.\n[1]: If a multiplicative norm $N$ is defined on $D$, then $N(1) = 1$ and for all units $u \\in D$, $| N ( u ) | = 1$ [2]: If all $\\alpha \\in D$ that satisfy $| N ( \\alpha )| =1$ are units in $D$, then any $\\pi \\in D$ that satisfies $| N ( \\pi ) | = p$ is an irreducible element in $D$. A unit is an element that has a multiplicative inverse. Explanation While the term norm typically presupposes $N (\\alpha) \\ge 0$, the conditions such as $\\nu ( \\alpha) = N ( \\alpha)$ added for $\\alpha \\ne 0$ often make it a multiplicative as well as a Euclidean norm. General guarantees cannot be made; however, it\u0026rsquo;s rare to find motivation to study algebraic structures that do not even conform to this level of common sense. If a norm is defined, it is almost certainly safe to assume $N : D \\to \\mathbb{N}_{0}$.\nThe definition of a norm provides significant aid in understanding the arithmetic structure of an integral domain $D$. In algebraic number theory, various norms suited to the domain are defined, allowing algebraic structures that don\u0026rsquo;t seem to fall within the realm of number theory to be \u0026lsquo;pulled in\u0026rsquo; for study. Needless to say, they are directly applicable to number theory. Interesting examples include Gaussian integers $\\mathbb{Z} [i]$$i$, $\\omega$ and Eisenstein integers $\\mathbb{Z} [\\omega]$(../1291).\nAccording to theorem [2], even if we know little about an element $\\pi$ of that $D$, merely knowing that $N ( \\pi )$ is prime ensures that $\\pi$ is an irreducible element in $D$. As is known, a prime $p$ is an irreducible element in $\\mathbb{Z}$, and $N$ through condition (ii) can be viewed as preserving the properties of an irreducible element from $D$ to $\\mathbb{Z}$.\nProof [1] Strategy: Ripping apart an element of $D$ via condition (ii) naturally leads to deduction.\nFor the identity element $1 \\in D$, computing $N(1)$ yields $$ N(1) = N \\left( 1 \\cdot 1 \\right) = N (1) N (1) $$ Therefore, $N(1)$. Furthermore, if $u \\in D$ is a unit, its inverse $u^{-1} \\in D$ exists by definition, hence $$ 1 = N ( 1) = N ( u u^{-1} ) = N (u ) N (u^{-1}) $$ Of course, since $N (u)$ is an integer, it must be $| N ( u) | =1$.\n‚ñ†\n[2] Given that all $u \\in D$ satisfying $| N(u) | = 1$ are units in $D$. If $\\pi \\in D$ is such that $| N ( \\pi ) | = 1$ and $\\pi = \\alpha \\beta$, then $$ p = | N ( \\pi ) | = | N ( \\alpha ) N ( \\beta ) | $$ Since $p$ is prime, it must be that $| N ( \\alpha ) | = 1$ or $| N ( \\beta ) | = 1$. Given the assumption, one of $\\alpha$ or $\\beta$ must be a unit in $D$, thus $\\pi$ becomes an irreducible element in $D$.\n‚ñ†\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p410.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1259,"permalink":"https://freshrimpsushi.github.io/en/posts/1259/","tags":null,"title":"Integral Domain Norm"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition The set defined as follows is called the extended real number system.\n$$ \\overline{ \\mathbb{R} } := \\mathbb{R} \\cup \\left\\{ -\\infty, +\\infty\\right\\} $$\nExplanation In fields such as analysis, for convenience, the set $\\mathbb{R}$ is often replaced with $\\overline{ \\mathbb{R} }$. $\\pm \\infty$ is not a number, but for convenience, it is treated as one and added to $\\mathbb{R}$. Within the extended real number system, the rules for comparison and operations are as follows.\nFor all $x \\in \\mathbb{R}$,\n$$ -\\infty \u0026lt; x \u0026lt;+\\infty $$\n$$ (\\pm \\infty) + (\\pm \\infty) = \\pm \\infty $$\n$$ x + (\\pm \\infty)=\\pm \\infty+x=\\pm \\infty $$\n$$ \\dfrac{x}{+\\infty}=0=\\dfrac{x}{-\\infty} $$\n$$ (\\pm \\infty)(\\pm\\infty)=+ \\infty $$\n$$ (\\pm \\infty)(\\mp \\infty)=- \\infty $$\n$$ x(\\pm \\infty)=(\\pm \\infty)x=\\begin{cases} \\pm \\infty \u0026amp; x\u0026gt;0 \\\\ 0 \u0026amp; x=0 \\\\ \\mp \\infty \u0026amp; x\u0026lt;0 \\end{cases} $$\nNote that $(\\pm \\infty)+(\\mp \\infty)$ is undefined.\nTheorem $\\overline{ \\mathbb{R} }$ is a complete ordered set.\nFor a given $A \\subset \\overline{ \\mathbb{R} }$, there exists $\\sup A$ and $\\inf A$.\nFor $a \\in \\mathbb{R}$, $(a, +\\infty]$ is a neighborhood of $+\\infty$.\n","id":1252,"permalink":"https://freshrimpsushi.github.io/en/posts/1252/","tags":null,"title":"Extended Real Number System"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Theorem Let $X$ be an arbitrary set. Given a non-empty set $A \\subset \\mathcal{P}(X)$, there exists the smallest $\\sigma$-algebra, $\\mathcal{E}_{A}$, that contains $A$.\nProof We define $\\mathcal{E}_{A}$ and show that it is an $\\sigma$-algebra and then prove that it is the smallest1.\nLet $S$ be the set of all $\\sigma$-algebras that contain $A$.\n$$ S:= \\left\\{ \\mathcal{E} \\subset \\mathcal{P}(X)\\ :\\ \\mathcal{E}\\ \\mathrm{is\\ } \\sigma \\mathrm{-algebra, \\ } A \\subset \\mathcal{E} \\right\\} $$\nThen, it is obvious that $\\mathcal{P}(X) \\in S$. Therefore, $S \\ne \\varnothing$. Now, let $\\mathcal{E}_{A} := \\bigcap \\limits_{\\mathcal{E} \\in S} \\mathcal{E}$. Then, $A \\subset \\mathcal{E}_{A}$. Furthermore, it can be shown that $\\mathcal{E}_{A}$ is an $\\sigma$-algebra.\n$\\sigma$-algebra\nGiven a set $X$, the collection []../1358) of subsets of $X$, $\\mathcal{E} \\subset \\mathcal{P}(X)$, satisfying the below conditions is called an $\\sigma$-algebra.\n(D1) $\\varnothing, X \\in \\mathcal{E}$ (D2) $E \\in \\mathcal{E} \\implies E^c \\in \\mathcal{E}$ (D3) $E_{k} \\in \\mathcal{E}\\ (\\forall k \\in \\mathbb{N}) \\implies \\bigcup_{k=1}^\\infty E_{k} \\in \\mathcal{E}$ (D4) $E_{k} \\in \\mathcal{E}\\ (\\forall\\ k \\in \\mathbb{N}) \\implies \\bigcap_{k=1}^\\infty E_{k} \\in \\mathcal{E}$ (D1)\nSince each $\\mathcal{E}$ is an $\\sigma$-algebra, it is obvious that $\\varnothing$, and $X$ is included. So by the definition of $\\mathcal{E}_{A}$, $\\varnothing$, and $X\\in \\mathcal{E}_{A}$ are obvious.\n(D2)\nLet $E \\in \\mathcal{E}_{A}$. Then, by the definition of $\\mathcal{E}_{A}$, $E \\in \\mathcal{E}$ holds for each $\\mathcal{E}$. Each $\\mathcal{E}$ is an $\\sigma$-algebra, so $E^c \\in \\mathcal{E}$ holds. Therefore, by the definition of $\\mathcal{E}_{A}$, $E^c \\in \\mathcal{E}_{A}$ holds.\n(D3)\nAs shown in condition (D2), using the definition of $\\mathcal{E}_{A}$ and the fact that each $\\mathcal{E}$ is an $\\sigma$-algebra, this can be easily proven. (D4) automatically follows from (D3) according to De Morgan\u0026rsquo;s laws.\nTherefore, $\\mathcal{E}_{A}$ satisfies conditions (D1) ~ (D4), hence it is an $\\sigma$-algebra. Now, let another $\\sigma$-algebra that contains $A$ be $\\mathcal{E}^{\\prime}$. Then, by the definition of the set $S$, $\\mathcal{E}^{\\prime} \\in S$ and obviously $\\mathcal{E}_{A} \\subset \\mathcal{E}^{\\prime}$ holds. Therefore, $\\mathcal{E}_{A}$ is the smallest $\\sigma$-algebra that includes $A$.\n‚ñ†\nDefinition At this time, $\\mathcal{E}_{A}$ is called the $\\sigma$-algebra generated by A and is denoted as $\\mathcal{G}(A)$.\nLet the pair $(X,\\mathcal{T})$ be called a topological space. By the definition of topology, $\\mathcal{T} \\subset \\mathcal{P}(X)$ holds. Therefore, according to the above theorem, the smallest $\\sigma$-algebra that includes $\\mathcal{T}$ exists. This is denoted as $\\mathcal{B}_\\sigma (X) :=\\mathcal{G}(\\mathcal{T})$ and is called the Borel $\\sigma$-algebra on the topological space $(X,\\mathcal{T})$ or simply Borel algebra.\nThe element of $\\mathcal{B}_\\sigma (X)$ is called a Borel set and the pair $(X,\\mathcal{B}_\\sigma (X) )$ is called a Borel measurable space.\nSimply put, the Borel algebra is the smallest $\\sigma$-algebra that contains all open sets. Especially, all measures defined in Borel algebra are called Borel measures.\nSee Also Borel sets in real space It means that the sigma field with unnecessary parts minimized. In this sense, the Borel sigma field is especially useful in discussing probability theory.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1251,"permalink":"https://freshrimpsushi.github.io/en/posts/1251/","tags":null,"title":"Borel Sigma-Algebra, Borel Measurable Space"},{"categories":"Îß§Ìä∏Îû©","contents":"Method The subplot() function can be used to print multiple figures on one page. The first and second parameters respectively indicate the rows and columns of the chessboard on which images will be displayed, deciding the layout of the figures. The third parameter determines the sequence in which the specific figure will be placed.\nBelow is the code and the actual output.\nX1=Phantom();\rX2=radon(X1);\rX3=fft(X2);\rX4=iradon(X2,0:179);\rsubplot(2,2,1)\rimagesc(X1)\rtitle(\u0026#34;Phantom\u0026#34;);\rsubplot(2,2,2)\rimagesc(X2)\rtitle(\u0026#34;radon\u0026#34;);\rsubplot(2,2,3)\rimagesc(abs(X3))\rtitle(\u0026#34;fft\u0026#34;);\rsubplot(2,2,4)\rimagesc(X4)\rtitle(\u0026#34;iradon\u0026#34;); ","id":1247,"permalink":"https://freshrimpsushi.github.io/en/posts/1247/","tags":null,"title":"How to Output Multiple Figures on One Page in MATLAB"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Method 1 Explanation The Runge-Kutta method, like the Adams method, comes in various forms and determines $\\gamma_{j}$ and $V_{j}$ through complex algebraic operations. Among them, the 4th-order Runge-Kutta method, often abbreviated as RK4, is the most popularly used.\n4th-order Runge-Kutta method: $$ \\begin{align*} y_{n+1} =\u0026amp; y_{n} + {{h} \\over {6}} \\left[ V_{1} + 2 V_{2} + 2 V_{3} + V_{4} \\right] \\\\ V_{1} =\u0026amp; f(x_{n} , y_{n}) \\\\ V_{2} =\u0026amp; f \\left( x_{n} + {{h} \\over {2}} , y_{n} + {{h} \\over {2}} V_{1} \\right) \\\\ V_{3} =\u0026amp; f \\left( x_{n} + {{h} \\over {2}} , y_{n} + {{h} \\over {2}} V_{2} \\right) \\\\ V_{4} =\u0026amp; f \\left( x_{n} + h , y_{n} + h V_{3} \\right) \\end{align*} $$\nFrom the formula, you can see that to proceed one step $h$, data up to the point $\\displaystyle {{h} \\over {2}}$ is used. For a more generalized explanation, refer to See also.\nIntuitive Derivation Let‚Äôs break down the terms one by one and think using the simplest Euler method (Assuming $\\displaystyle x_{n+ {{1} \\over {2}} } : = x_{n} + {{h} \\over {2}}$, $y_{n+ {{1} \\over {2}} } \\approx Y(x_{n + {{h} \\over {2}} } )$ for convenience.) $$ V_{1} = f(x_{n} , y_{n} ) $$ is the differential coefficient $y_{n} ' $ at the point $x_{n}$. $$ \\begin{align*} V_{2} =\u0026amp; f \\left( x_{n} + {{h} \\over {2}} , y_{n} + {{h} \\over {2}} f \\left( x_{n} , y_{n} \\right) \\right) \\\\ =\u0026amp; f \\left( x_{n + {{1} \\over {2}} } , y_{n + {{1} \\over {2}} } \\right) \\end{align*} $$ is the differential coefficient $\\displaystyle y_{n + {{1} \\over {2}} } ' $ at the point $x_{n+{{1} \\over {2}} }$. $$ V_{3} = f \\left( x_{n} + {{h} \\over {2}} , y_{n} + {{h} \\over {2}} f \\left( x_{n + {{1} \\over {2}} } , y_{n + {{1} \\over {2}} } \\right) \\right) $$ is also by the backward Euler method, $\\displaystyle V_{3} = f \\left( x_{n + {{1} \\over {2}} } , y_{n + {{1} \\over {2}} } \\right) $, the differential coefficient $\\displaystyle y_{n + {{1} \\over {2}} } ' $ at the point $x_{n+{{1} \\over {2}} }$. $$ \\begin{align*} V_{4} =\u0026amp; f \\left( x_{n} + h , y_{n} + h V_{3} \\right) \\\\ =\u0026amp; f \\left( x_{n} + {{h} \\over {2}} + {{h} \\over {2}} , y_{n} + {{h} \\over {2}} V_{3} + {{h} \\over {2}} V_{3} \\right) \\\\ =\u0026amp; f \\left( x_{n + {{h} \\over {2}}} + {{h} \\over {2}} , y_{n + {{h} \\over {2}}} + {{h} \\over {2}} V_{3} \\right) \\end{align*} $$ Furthermore, by the backward Euler method, it is the differential coefficient $\\displaystyle y_{n + 1} ' $ at the point $x_{n+ 1 }$. $$ {{h} \\over {6}} \\left[ V_{1} + 2 V_{2} + 2 V_{3} + V_{4} \\right] $$ is especially a weighted average that uses data up to the point $x_{n+{{1} \\over {2}} }$ and gives a weight to the point $x_{n+{{1} \\over {2}} }$ to proceed one step $h$.\nAlthough more calculations can be added, from RK4 onwards, the order of convergence doesn\u0026rsquo;t increase as much as the amount of computation anymore. Even if not increased, if the problem is not stiff, RK4 is often sufficient, and its coding is also comparatively easy, which is why it is widely used.\nImplementation R The following is the code to implement RK4 in R and draw the Lorenz attractor in 3D.\nlibrary(rgl)\rRK4\u0026lt;-function(ODE,v,h=10^(-2)){\rV1 = ODE(v)\rV2 = ODE(v + (h/2)*V1)\rV3 = ODE(v + (h/2)*V2)\rV4 = ODE(v + h*V3)\rv = v + (h/6)*(V1 + 2*V2 + 2*V3 + V4)\rreturn(v)\r}\rlorenz\u0026lt;-function(v,rho=28,sigma=10,beta=8/3){\rdvdt = v\rdvdt[1] = sigma*(v[2]-v[1])\rdvdt[2] = v[1]*(rho-v[3])-v[2]\rdvdt[3] = v[1]*v[2] - beta*v[3]\rreturn(dvdt)\r}\rtraj\u0026lt;-numeric(0)\rv=c(1,1,1)\rfor(i in 1:10000){\rtraj\u0026lt;-rbind(traj,v)\rv=RK4(lorenz,v)\r}\rplot3d(traj,type=\u0026#39;l\u0026#39;)\rplot(traj[,1],traj[,3],type=\u0026#39;l\u0026#39;) Executing the code yields the following 3D plot.\nJulia Below is the implementation of the same content in Julia.\nusing Plots\rfunction RK4(ODE::Function,v::Array{Float64,1},h=10^(-2))\rV1 = ODE(v)\rV2 = ODE(v .+ (h/2)*V1)\rV3 = ODE(v .+ (h/2)*V2)\rV4 = ODE(v .+ h*V3)\rreturn @. v + (h/6)*(V1 + 2*V2 + 2*V3 + V4)\rend\rfunction lorenz(v::Array{Float64,1}; œÅ=28.,œÉ=10.,Œ≤=8/3)\rdvdt = deepcopy(v)\rdvdt[1] = œÉ*(v[2]-v[1])\rdvdt[2] = v[1]*(œÅ-v[3])-v[2]\rdvdt[3] = v[1]*v[2] - Œ≤*v[3]\rreturn dvdt\rend\rfunction lorenz_attracter(v::Array{Float64,1}, endtime = 10000)\rx,y,z = [v[1]], [v[2]], [v[3]]\rfor t in 1:endtime\rnewx,newy,newz = RK4(lorenz,[x[end], y[end], z[end]])\rpush!(x, newx)\rpush!(y, newy)\rpush!(z, newz)\rend\rreturn x,y,z\rend\rresult = lorenz_attracter([1.,1.,1.])\rplot(result) See also Explicit Runge-Kutta methods Implicit Runge-Kutta methods Atkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p420. Given the initial value problem $\\begin{cases} y ' = f(x,y) \\\\ y( x_{0} ) = Y_{0} \\end{cases}$ for the continuous function $f$ defined in $D \\subset \\mathbb{R}^2$, let\u0026rsquo;s assume the interval $(a,b)$ is divided into nodes as in $a \\le x_{0} \u0026lt; x_{1} \u0026lt; \\cdots \u0026lt; x_{n} \u0026lt; \\cdots x_{N} \\le b$. Particularly, for sufficiently small $h \u0026gt; 0$, if $x_{j} = x_{0} + j h$, then for the initial value $y_{0} = Y_{0}$ $$ y_{n+1} = y_{n-1} + h \\sum_{j=1}^{p} \\gamma_{j} V_{j} $$\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":796,"permalink":"https://freshrimpsushi.github.io/en/posts/796/","tags":null,"title":"Fourth-order Runge-Kutta method"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 Let\u0026rsquo;s say $\\left\\{ X_{t} \\right\\}_{t=1}^{n}$, $\\left\\{ Y_{t} \\right\\}_{t=1}^{n}$ are stochastic processes.\nThe following defined $\\rho_{k}$ is called the cross-correlation function at lag $k$. $$ \\rho_{k} (X,Y) := \\text{cor} \\left( X_{t} , Y_{t-k} \\right) = \\text{cor} \\left( X_{t+k} , Y_{t} \\right) $$ The following defined $r_{k}$ is called the sample cross-correlation function at lag $k$. $$ r_{k} := {{ \\sum \\left( X_{t} - \\overline{X} \\right) \\left( Y_{t-k} - \\overline{Y} \\right) } \\over { \\sqrt{ \\sum \\left( X_{t} - \\overline{X} \\right)^2 } \\sqrt{ \\left( Y_{t-k} - \\overline{Y} \\right)^2 } }} $$ Explanation The cross-correlation function is a function for understanding the correlation between two time series data. Except for being applied to time series, it is essentially the Pearson correlation coefficient.\nThe sample CCF, $r_{k}$, is an estimate of the CCF, $\\rho_{k}$, and if $\\left\\{ X_{t} \\right\\}_{t=1}^{n}$, $\\left\\{ Y_{t} \\right\\}_{t=1}^{n}$ are independent while having stationarity, it is said to follow a normal distribution as follows. $$ r_{k} \\sim N \\left( 0 , {{ 1 } \\over { n}} \\left[ 1 + 2 \\sum_{k=1}^{\\infty} \\rho_{k} ( X , Y) \\right] \\right) $$ This can be used for hypothesis testing similar to regression analysis.\nTest Let\u0026rsquo;s say it\u0026rsquo;s $\\displaystyle Y_{t} = e_{t} + \\sum_{k=0}^{m} \\beta_{k} X_{t-k}$.\n$H_{0}$: $\\beta_{k} = 0$ meaning, $X_{t}$ and $Y_{t-k}$ are uncorrelated. $H_{1}$: $\\beta_{k} \\ne 0$ meaning, $X_{t}$ and $Y_{t-k}$ are correlated. Interpretation Under the null hypothesis, assuming both $\\rho_{k} ( X , Y) = 0$ and $\\displaystyle N \\left( 0 , {{ 1 } \\over { n }} \\right)$, the standard error becomes $\\displaystyle {{1} \\over {\\sqrt{n}}}$. Therefore, if there is a desire to perform hypothesis testing at the significance level $\\alpha$, check if $| r_{k} |$ exceeds the confidence interval upper limit $\\displaystyle {{z_{1- \\alpha/2}} \\over {\\sqrt{n} }}$. If it does, it becomes a candidate for a significant lag; if not, it is considered to be uncorrelated.\nSee Also ACF: Autocorrelation function PACF: Partial autocorrelation function EACF: Extended autocorrelation function Cryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p261~262.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1227,"permalink":"https://freshrimpsushi.github.io/en/posts/1227/","tags":null,"title":"Cross-Correlation Function"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":" üöß Ïù¥ Ìè¨Ïä§Ìä∏Îäî ÏïÑÏßÅ Ïù¥Í¥Ä ÏûëÏóÖÏù¥ ÏôÑÎ£åÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§ üöß\nReflection Coefficients and Transmission Coefficients The reflection coefficient (reflectivity) and transmission coefficient (transmissibility) of a wave function can be represented as follows: $$ R=\\left| \\frac{j_{ref}}{j_{inc}} \\right|,\\quad T=\\left| \\frac{j_{trans}}{j_{inc}}\\right| $$ Here, $j$ is the probability flow. $inc$ refers to the incident $(\\mathrm{incident})$. $R$, and $ref$ represent the reflected $(\\mathrm{reflection})$. $T$, and $trans$ denote the transmitted $(\\mathrm{transmission})$.\nWhen a particle with energy $E$ encounters a potential barrier higher than its energy, reflection and transmission occur. From a classical perspective, the particle would not penetrate but purely reflect. However, in the quantum world, due to the wave-like nature of particles, transmission can occur probabilistically. This is referred to as quantum tunneling. It means that the ratio of reflection and transmission is represented by the ratio of the probability flow of incident, reflected, and transmitted waves. Flux$(\\mathrm{flux}$, flux$)$ is the amount of a physical quantity passing through a point per unit time. Therefore, if one wishes to know the ratio of reflection and transmission of the wave function, one should look at the ratio of the flux of the reflected and transmitted waves to the flux of the incident wave. That is, \u0026ldquo;reflectivity=(flux of reflected wave)/(flux of incident wave)\u0026rdquo;, \u0026ldquo;transmissibility=(flux of transmitted wave)/(flux of incident wave)\u0026rdquo; can be represented. But in quantum mechanics, the wave function of a particle signifies the probability of finding the particle, with probability current density $j(x,t)$ existing as a physical quantity representing the flow of probability. In fact, $j(x,t)$ represents the flux of the wave function as confirmed. Given a wave function $\\psi=A e^{ikx}$, the wave function passing through interval $\\Delta x$ can be represented as $|\\psi|^2 \\Delta x =|\\psi \\psi^{\\ast}| \\Delta x=P\\Delta x$. The reason why it is $\\psi$ and not $|\\psi|^2$ is because the physical quantity we deal with is real. Since wave function $\\psi$ is a complex function, it is represented by $|\\psi \\psi^{\\ast}|$ to show real values. Here, $P=|\\psi \\psi^{\\ast}|=|Ae^{ikx} A^{\\ast}e^{-ikx}|=|AA^{\\ast}|=|A|^2$. Since flux is the amount flowing per unit time, the flux of $\\psi$ is $$ F=|A|^2\\dfrac{\\Delta x}{\\Delta t} $$ When thinking about a very short period of time, $\\dfrac{\\Delta x}{\\Delta t}=v$. In quantum mechanics, we deal with momentum rather than speed, so $v=\\frac{p}{m}$, and the momentum in quantum mechanics is $p=\\hbar k$, therefore $$ F=|A|^2\\frac{\\hbar k}{m} $$ Calculating the probability flow of $\\psi$ shows that it exactly matches the values above. $$ \\begin{align*} j =\u0026amp;\\ \\frac{\\hbar }{2mi}\\left( \\psi* \\frac{\\partial \\psi}{\\partial x} -\\psi\\frac{\\partial \\psi^{\\ast}}{\\partial x} \\right) \\\\ =\u0026amp;\\ \\frac{\\hbar}{2mi}\\left( A^{\\ast}e^{-ikx}(ik)Ae^{ikx}-Ae^{ikx}(-ik)A^{\\ast}e^{-ikx}\\right) \\\\ =\u0026amp;\\ \\frac{\\hbar}{2mi} \\left( ikAA^{\\ast}+ikAA^{\\ast}\\right) \\\\ =\u0026amp;\\ \\frac{\\hbar k}{m}|A|^2 \\end{align*} $$ Thus, the ratio of the probability flow of the incident wave to the reflected wave represents the reflectivity, and the ratio of the probability flow of the incident wave to the transmitted wave represents the transmissibility. Suppose the wave function is given as a real function as follows. $$ u=Ae^{kx} $$ Then, the probability flow of the wave $j$ is $0$. $$ \\begin{align*} j =\u0026amp;\\ \\frac{\\hbar }{2mi}\\left( u^{\\ast} \\frac{\\partial u}{\\partial x} -u\\frac{\\partial u^{\\ast}}{\\partial x} \\right) \\\\ =\u0026amp;\\ \\frac{\\hbar }{2mi}\\left( u \\frac{\\partial u}{\\partial x} -u\\frac{\\partial u}{\\partial x} \\right) \\\\ =\u0026amp;\\ 0 \\end{align*} $$\n","id":1241,"permalink":"https://freshrimpsushi.github.io/en/posts/1241/","tags":null,"title":"Reflection and Transmission of Wave Functions"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Buildup PACF helps in determining the order of $AR(p)$, while ACF is helpful in setting the order for $MA(q)$. However, when applying to $ARMA(p,q)$ model, due to the invertibility of ARMA models, $AR(p)$ may appear as $MA(\\infty)$, and $MA(q)$ may appear as $AR(\\infty)$. Therefore, various methods have been devised to circumvent these issues and find the ARMA model.\nDefinition The Extended Autocorrelation Function is one such method, defined as EACF for lags $k$ and $j$, described as follows: $$ W_{t,k,j} := Y_{t} - \\tilde{\\phi}_{1} Y_{t-1} - \\cdots - \\tilde{\\phi}_{k} Y_{t-k} $$\nExplanation Understanding EACF just from its definition is impossible, so let\u0026rsquo;s comprehend it through equations. Given lags $k$ and $j$, an ARMA model $ARMA(k,j)$ can be expressed as follows: $$ Y_{t} = \\sum_{i = 1}^{k} \\phi_{i} Y_{t-i} + e_{t} - \\sum_{i = 1}^{j} \\theta_{i} e_{t-i} $$ Here, performing a multiple regression analysis with $Y_{t}$ as $Y_{t-1} , \\cdots , Y_{t-k}$ yields the regression coefficients $\\tilde{\\phi}_{1} , \\cdots , \\tilde{\\phi}_{k}$, which are estimates of $\\phi_{1} , \\cdots , \\phi_{k}$. And the residuals would disastrously appear as the following: $$ Y_{t} - \\sum_{i = 1}^{k} \\tilde{\\phi}_{i} Y_{t-i} = e_{t} - \\sum_{i = 1}^{j} \\theta_{i} e_{t-i} $$ However, on closer inspection, by setting the left side as $W_{t,k,j}$, we can achieve the $MA(j)$ model. $$ W_{t,k,j} = e_{t} - \\sum_{i = 1}^{j} \\theta_{i} e_{t-i} $$ Then, $W_{t,k,j}$ follows a normal distribution $\\displaystyle N \\left( 0 , {{1} \\over {n - k - j}}\\right)$, just as ACF did, and this is used for hypothesis testing.\nTo simplify, this approach essentially disentangles the complex ARMA model $ARMA(k,j)$ by specifying lag $k$ to eliminate $AR(k)$, and then by specifying lag $j$ to solely consider $MA(j)$ for targeted analysis. The reason it is aptly named Extended Autocorrelation Function is because it ultimately requires the use of ACF to discern $MA(j)$.\nExercise Since the lags are listed on two axes, unlike ACF or PACF, it\u0026rsquo;s impossible to draw a correlogram 1 and instead, a table that merely indicates whether the null hypothesis is rejected or not with O and X is used. However, this table is not based on actual data but is a theoretical schematic that should emerge from analyzing an ideally working $ARMA(1,1)$ model. It\u0026rsquo;s rarely this clean in reality.\nThe method to read the table is as follows:\nStep 1. Find a vertex where a line continues horizontally to the right from the upper left. Step 2. From the vertex, find the line that drops diagonally right-downward forming an acute angle with a horizontal line. Step 3. If both lines are identified, analyze with the corresponding $ARMA(p,q)$ at the vertex. Following this method, in the given illustration, $ARMA(1,1)$ at the vertex O* becomes a candidate model. As one might guess after studying time series to some extent and reading the explanation thoroughly, the actual analysis often involves a lot of subjective and vague parts. The only way to get accustomed to this is by actively performing many analyses.\nSee Also ACF : Autocorrelation Function PACF : Partial Autocorrelation Function CCF : Cross-correlation Function Selecting ARMA models with EACF in R Technically, it could be drawn in three dimensions, but it\u0026rsquo;s avoided because it\u0026rsquo;s inconvenient to look at. The analyst only needs to check whether it falls inside or outside the confidence interval.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1213,"permalink":"https://freshrimpsushi.github.io/en/posts/1213/","tags":null,"title":"Extended Autocorrelation Function"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 Let $\\left\\{ Y_{t} \\right\\}_{t=1}^{n}$ be a stochastic process, and for lag $k$, let the residuals obtained by regressing $Y_{t}$ on $Y_{t-1}, \\cdots , Y_{t-(k-1)}$ be $\\widehat{e_{t}}$, and the residuals obtained by regressing $Y_{t-k}$ on $Y_{t-1}, \\cdots , Y_{t-(k-1)}$ be $\\widehat{e_{t-k}}$.\nThe following defined $\\phi_{kk}$ is referred to as the partial autocovariance function at lag $k$. $$ \\phi_{kk} := \\text{cor} ( \\widehat{e_{t}} , \\widehat{e_{t-k}} ) $$ The following defined $\\phi_{kk}$ is referred to as the sample partial autocovariance function at lag $k$. $$ \\widehat{ \\phi_{kk} } := {{ r_{k} - \\sum_{j=1}^{k-1} \\phi_{(k-1),j} r_{k-j} } \\over { 1 - \\sum_{j=1}^{k-1} \\phi_{(k-1),j} r_{j} }} \\\\ \\phi_{k,j} := \\phi_{(k-1),j} - \\phi_{kk} \\phi_{(k-1),(k-j)} $$ $r_{k}$ is the sample autocorrelation function at lag $k$. Description Partial autocorrelation function is about understanding the autocorrelation while eliminating the influence of $Y_{t-1}, \\cdots , Y_{t-(k-1)}$ that lies between $Y_{t}$ and $Y_{t-k}$, focusing solely on the relationship between the two. Although the definition might initially appear complicated with sudden mentions of regression analysis, the concept is actually simple. Consider only $\\widehat{e_{t}}$. Regressing $Y_{t}$ on $Y_{t-1}, \\cdots , Y_{t-k+1}$ means to find the value of $\\beta_{1} , \\cdots , \\beta_{k-1}$ that fits into the following equation: $$ Y_{t} = \\beta_{1} Y_{t-1} + \\cdots \\beta_{k-1} Y_{t-(k-1)} + \\widehat{e_{t}} $$ To rewrite it, $$ \\widehat{e_{t}} = Y_{t} - \\left( \\beta_{1} Y_{t-1} + \\cdots \\beta_{k-1} Y_{t-(k-1)} \\right) $$ This implies that the parts of $\\widehat{e_{t}}$ that can be explained by $Y_{t-1}, \\cdots , Y_{t-(k-1)}$ are eliminated. Similarly, $\\widehat{e_{t-k}}$ has also removed any portion that could be explained by $Y_{t-1}, \\cdots , Y_{t-(k-1)}$, meaning calculating $\\text{cor} ( \\widehat{e_{t}} , \\widehat{e_{t-k}} )$ is essentially examining the correlation solely between $Y_{t}$ and $Y_{t-k}$ without $Y_{t-1}, \\cdots , Y_{t-(k-1)}$. This focus only on the variables of interest is why the term \u0026lsquo;partial\u0026rsquo; autocorrelation function is fitting. [ NOTE: Despite the simplicity of the concept, calculating the sPACF was quite challenging until Levinson and Durbin proposed a method that facilitated the recursive calculation of $\\widehat{ \\phi_{kk} }$. ]\nMathematical Explanation Mathematically, considering that $Y_{t}$ comes from $AR(p)$, and since $\\displaystyle Y_{t} = \\sum_{k=1}^{p} \\phi_{k} Y_{t-k} + e_{t}$, calculating the coefficient $\\phi_{k}$ for $Y_{t-k}$ by excluding other variables aids in identifying the $AR(p)$ model.\nsPACF $\\widehat{\\phi_{kk}}$ is an estimator for PACF $\\phi_{kk}$, and if $Y_{t}$ originates from a $AR(p)$ model, then for $k\u0026gt;p$, it follows a normal distribution $\\displaystyle N \\left( 0 , {{ 1 } \\over { n }} \\right)$. Represented as $$ \\widehat{\\phi_{kk}} \\sim N \\left( 0 , {{ 1 } \\over { n }} \\right) $$ , this is utilized for hypothesis testing.\nTest Given $\\displaystyle Y_{t} = \\sum_{k=1}^{p} \\phi_{k} Y_{t-k} + e_{t}$ and assuming $k = 1 , \\cdots , p$,\n$H_{0}$: $AR(0) \\iff \\theta_{k} = 0$, meaning, $Y_{t}$ does not follow an autoregressive model. $H_{1}$: $AR(k) \\iff \\theta_{k} \\ne 0$, meaning, $Y_{t}$ has a partial autocorrelation at lag $k$. Interpretation Under the null hypothesis, both $p=0$ and $\\widehat{\\phi_{kk}} \\sim N \\left( 0 , {{ 1 } \\over { n }} \\right)$ are assumed, and the standard error becomes $\\displaystyle {{1} \\over {\\sqrt{n}}}$. Therefore, if wanting to perform hypothesis testing at significance level $\\alpha$, check if $| \\phi_{k} |$ surpasses the upper confidence limit $\\displaystyle {{ z_{1 - \\alpha/2} } \\over { \\sqrt{n} }}$. If it exceeds, it\u0026rsquo;s considered a significant lag; if not, it\u0026rsquo;s deemed to have no partial autocorrelation.\nPractice ar1.s data comes from a $AR(1)$ model in the TSA package. When analyzing with an actual ARIMA model, it\u0026rsquo;s also crucial to determine if the absolute value of the estimate exceeds twice the standard error to consider it significant.\nAdditionally, using the acf() function in the TSA package draws a correlogram for various $k$ like above. Without needing to mentally calculate, if it exceeds the line, it\u0026rsquo;s significant; if not, it\u0026rsquo;s considered insignificant. It\u0026rsquo;s typically calculated at significance level $5 \\%$.\nThe method of directly drawing lines as shown above is recommended to verify understanding of hypothesis testing using the partial autocorrelation function. Though it\u0026rsquo;s just one line of code in R, executing it even once allows acceptance that $\\widehat{\\phi}_{kk}$ follows a normal distribution, with its standard error calculated as $\\displaystyle \\text{se} ( r_{k} ) = {{1} \\over {\\sqrt{n}}}$.\nCode library(TSA)\rdata(ar1.s); win.graph(6,4); pacf(ar1.s)\rarima(ar1.s, order=c(1,0,0))\rabline(h=1.96*1/sqrt(length(ar1.s)),col=\u0026#39;red\u0026#39;) See Also ACF: Autocorrelation Function EACF: Extended Autocorrelation Function CCF: Cross-Correlation Function Cryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p112.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1211,"permalink":"https://freshrimpsushi.github.io/en/posts/1211/","tags":null,"title":"Autocorrelation Function"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"The Hahn-Banach Theorem for Real Numbers1 Let $X$ be a $\\mathbb{R}$-vector space and assume that $Y \\subset X$. Let us define $p : X \\to \\mathbb{ R}$ as a sublinear linear functional of $X$. Now, assume that $y^{\\ast} : Y \\to \\mathbb{ R}$ satisfies the following condition as a $\\mathbb{R}$-linear functional of $Y$.\n$$ y^{\\ast}(y) \\le p(y)\\quad \\forall y\\in Y $$\nThen, there exists a linear functional $x^{\\ast} : X \\to \\mathbb{R}$ of $X$ that satisfies the following conditions:\n(a) $x^{\\ast}(y)=y^{\\ast}(y),\\quad \\forall y \\in Y$\n(b) $x^{\\ast}(x) \\le p(x),\\quad \\forall x \\in X$\nExplanation To say that $\\mathbb{R}-$ is a vector space means it is a vector space over the field $\\mathbb{R}$. In other words, it means that the conditions for scalar multiplication of a vector space, $(M1)$~$(M5)$, hold true for real numbers. Similarly, the term $\\mathbb{R}$-linear means that the two properties of linearity, specifically scalar multiplication, hold true for real numbers.\nSince $X, Y$ is a $\\mathbb{R}$-vector space, the terms linear and $\\mathbb{R}$-linear mean the same. If this concept is confusing, think of $\\mathbb{R}$-, $\\mathbb{C}$- as non-existent in this text for ease of understanding the proof. Later, when applying the Hahn-Banach theorem to normed spaces, the function $p$ corresponds to the norm. The proof of the theorem stated above is omitted and will be used as a lemma for proving the Hahn-Banach theorem for complex numbers.\nThe Hahn-Banach Theorem for Complex Numbers2 Let $X$ be a $\\mathbb{C}$-vector space and assume that $Y \\subset X$. Let us define $p : X \\to \\mathbb{ R}$ as the following sublinear functional.\n$$ p(\\lambda x)=|\\lambda| p(x),\\quad x\\in X, \\lambda \\in \\mathbb{C} $$\nAnd assume that $y^{\\ast} : Y \\to \\mathbb{ C}$ satisfies the following condition as a linear functional of $Y$.\n$$ \\begin{equation} \\text{Re}\\left( y^{\\ast}(y) \\right) \\le p(y),\\quad \\forall y\\in Y \\end{equation} $$\nThen, there exists a linear functional $x^{\\ast} : X \\to \\mathbb{C}$ of $X$ that satisfies the following conditions:\n$x^{\\ast}(y)=y^{\\ast}(y),\\quad \\forall y \\in Y$ $\\text{Re}(x^{\\ast}(x)) \\le p(x),\\quad \\forall x \\in X$ Explanation Compared to the theorem for real numbers, the codomain of $p$ being $\\mathbb{R}$ remains unchanged because, as mentioned above, when $X$ is a normed space, $p$ corresponds to the norm. $X$, $Y$ are $\\mathbb{C}$-vector spaces and since $\\mathbb{R} \\subset \\mathbb{C}$, they also satisfy the conditions for being a $\\mathbb{R}$-vector space. This is because if all conditions for a vector space, $(M1)$~$(M5)$, hold true for all complex numbers, they automatically hold true for all real numbers as well. Similarly, $y^{\\ast}$, $x^{\\ast}$ being $\\mathbb{C}$-linear means they also satisfy the condition of being $\\mathbb{R}-$ linear.\nProof Define the function $\\psi : Y \\to \\mathbb{ R}$ as follows:\n$$ \\psi (y) = \\text{Re} ( y^{\\ast}(y) ) $$\nThen, it can be shown that $\\psi$ is also a $\\mathbb{C}$-linear functional of $Y$. This is a trivial result since $\\mathrm{ Re}$ and $y^{\\ast}$ are linear, and the demonstration is very straightforward, thus omitted. By the definition of $\\psi$ and $(1)$, the following equation holds:\n$$ \\psi(y)= \\text{Re} \\left( y^{\\ast}(y) \\right) \\le |y^{\\ast}(y)| \\le p(y) $$\nTherefore, by the Hahn-Banach theorem for real numbers, there exists a $\\mathbb{R}$-linear functional $\\Psi : X \\to \\mathbb{ R}$ of $X$ that satisfies:\n$$ \\Psi (y) = \\psi (y),\\quad \\forall y \\in Y $$\n$$ \\Psi (x) \\le p(x),\\quad \\forall x \\in X $$\nNext, define a new function $\\Phi : X \\to \\mathbb{ C}$ as follows. The final goal is to show that the defined $\\Phi$ is the $x^{\\ast}$ mentioned in the theorem.\n$$ \\Phi (x) := \\Psi (x) -i \\Psi(ix) $$\nThen, $\\Phi$ can be seen as a linear functional of $X$. Since $\\Psi$ is $\\mathbb{R}$-linear, linearity with respect to addition and multiplication by real numbers is trivial, so only $\\Phi(ix)=i\\Phi(x)$ needs to be verified.\n$$ \\begin{align*} \\Phi(ix) =\u0026amp;\\ \\Psi(ix) -i \\Psi( -x) \\\\ =\u0026amp;\\ \\Psi(ix)+i\\Psi(x) \\\\ =\u0026amp;\\ -i^2 \\Psi(ix)+i\\Psi(x) \\\\ =\u0026amp;\\ i \\big( \\Psi(x)-i\\Psi(ix) \\big) \\\\ =\u0026amp;\\ i\\Phi(x) \\end{align*} $$\n$\\Phi$ satisfying (a) can be shown as follows. If we assume $y \\in Y$,\n$$ \\begin{align*} \\Phi(y) =\u0026amp;\\ \\Psi (y) -i \\Psi(iy) \\\\ =\u0026amp;\\ \\psi(y) -i\\psi(iy) \\\\ =\u0026amp;\\ \\text{Re} \\left( y^{\\ast}(y) \\right)-i\\text{Re} \\left( y^{\\ast}(iy) \\right) \\\\ =\u0026amp;\\ \\text{Re} \\left( y^{\\ast}(y) \\right) +\\text{Im} \\left(-iy^{\\ast}(iy) \\right) \\\\ =\u0026amp;\\ \\text{Re} \\left( y^{\\ast}(y) \\right) +\\text{Im} \\left( y^{\\ast}(y) \\right) \\\\ =\u0026amp;\\ y^{\\ast}(y) \\end{align*} $$\nProving that $\\Phi$ satisfies (b) is even simpler.\n$$ \\mathrm{Re }\\left( \\Phi(x) \\right) = \\Psi(x) \\le p(x) $$\nTherefore, since $\\Phi$ is a linear functional of $X$ and satisfies (a), (b), $x^{\\ast}=\\Phi$ exists.\n‚ñ†\nThe Hahn-Banach Theorem for Seminorms Let $X$ be a $\\mathbb{C}$-vector space and assume that $Y \\subset X$. Let $p : X \\to \\mathbb{ R}$ be a seminorm of $X$. And assume that $y^{\\ast} : Y \\to \\mathbb{ C}$ satisfies the following condition as a linear functional of $Y$.\n$$ | y^{\\ast}(y) | \\le p(y),\\quad \\forall y\\in Y $$\nThen, there exists a linear functional $x^{\\ast} : X \\to \\mathbb{C}$ of $X$ that satisfies the following conditions:\n$x^{\\ast}(y)=y^{\\ast}(y),\\quad \\forall y \\in Y$\n$| x^{\\ast}(x) | \\le p(x),\\quad \\forall x \\in X$\nProof From the definitions of seminorm and sublinear, if $p$ is a seminorm, it automatically satisfies the conditions of being sublinear.\nIt is trivial that the following equation is satisfied:\n$$ \\text{Re} \\left( y^{\\ast}(y) \\right) \\le |y^{\\ast}(y) | \\le p(y) $$\nTherefore, by the Hahn-Banach theorem for complex numbers, there exists a linear functional $x^{\\ast} : X \\to \\mathbb{C}$ of $X$ that satisfies the following two conditions:\n$$ x^{\\ast}(y)=y^{\\ast}(y) \\quad \\forall y \\in Y $$\n$$ \\text{Re} \\left( x^{\\ast}(x) \\right) \\le p(x) \\quad \\forall x \\in X $$\nLet\u0026rsquo;s assume $S = \\left\\{ \\lambda \\in \\mathbb{C} : | \\lambda | =1 \\right\\}$. Then,\n$$ \\begin{align*} \\text{Re} \\left( \\lambda x^{\\ast}(x) \\right) =\u0026amp;\\ \\text{Re} \\left( \\lambda x^{\\ast}(\\lambda x) \\right) \\\\ \\le \u0026amp; p(\\lambda x) \\\\ =\u0026amp;\\ |\\lambda| p(x)=p(x) \\quad \\forall x \\in X \\end{align*} $$\nFor a fixed $x \\in X$, a $\\lambda \\in S$ that satisfies $|x^{\\ast}(x)|=\\lambda x^{\\ast}(x)$ can always be found. Thus, for that particular $\\lambda$, the following equation holds:\n$$ | x^{\\ast}(x) | =\\lambda x^{\\ast}(x) = \\text{Re} \\left( \\lambda x^{\\ast}(x) \\right) \\le p(x), \\quad \\forall x \\in X $$\nSince the linear functional $x^{\\ast}$ of $X$ satisfies both conditions, the proof is complete.\n‚ñ†\nAppendix For a fixed $x$, let\u0026rsquo;s say $x^{\\ast}(x)=a+ib$. If we assume $\\lambda=c+id$, then because of the condition on $\\lambda$, $c^2+d^2 =1$, thus $\\lambda=c+i\\sqrt{1-c^2}$ holds. Also, $|x^{\\ast}(x)|=\\sqrt{a^2+b^2}$ holds. Considering $\\lambda x^{\\ast}(x)=(ac-b\\sqrt{1-c^2})+i(a\\sqrt{1-c^2}+bc)$, and since $|x^{\\ast}(x)|$ is a non-negative real number,\n$$ \\begin{align*} \u0026amp;\u0026amp; a\\sqrt{1-c^2}+bc =\u0026amp;\\ 0 \\\\ \\implies\u0026amp;\u0026amp; a^2(1-c^2) =\u0026amp;\\ b^2c^2 \\\\ \\implies\u0026amp;\u0026amp; a^2 =\u0026amp;\\ (a^2+b^2)c^2 \\\\ \\implies\u0026amp;\u0026amp; c^2 =\u0026amp;\\ \\dfrac{a^2}{a^2+b^2} \\tag{2} \\end{align*} $$\nFor convenience, let\u0026rsquo;s denote $c=\\dfrac{a}{\\sqrt{a^2+b^2}}$. And let\u0026rsquo;s set $d=\\dfrac{-b}{\\sqrt{a^2+b^2}}$. Then, $(2)$ and $c^2+d^2=1$ hold true. Also, $|x^{\\ast}(x)|=ac-bd=\\sqrt{a^2+b^2}$ is true. Therefore, for a fixed $x$, if $x^{\\ast}(x)=a+ib$, then for $\\lambda=\\dfrac{a}{\\sqrt{a^2+b^2}}-i\\dfrac{b}{\\sqrt{a^2+b^2}}\\in S$, $|x^{\\ast}(x)|=\\lambda x^{\\ast}(x)$ holds true.\nhttp://mathonline.wikidot.com/the-hahn-banach-theorem-real-version\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttp://mathonline.wikidot.com/the-hahn-banach-theorem-complex-version\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1230,"permalink":"https://freshrimpsushi.github.io/en/posts/1230/","tags":null,"title":"Hahn Banach Theorem for Real, Complex, Seminorm"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition1 If in some $E$ containing $a$, $f$ is defined and the limit\n$$ f^{\\prime} (a) := \\lim_{h \\to 0} {{ f (a + h ) - f(a) } \\over { h }}=\\lim \\limits_{x\\rightarrow a}\\frac{f(x)-f(a)}{x-a} $$\nexists, then $f$ is said to be differentiable at $a$, and $f^{\\prime} (a)$ is called the derivative of $f$ at $a$.\nIf $f$ is differentiable at every point $a \\in E$, then $f$ is said to be differentiable on $E$. When $f$ is differentiable on $E$, $f^{\\prime}$ defined on $E$ is called the derivative of $f$.\nDescription The most welcome concept when studying analysis is differentiation. This is because, unlike sequences or integrals that reveal their complexity, differentiation retains its original essence. Despite the introduction of multiple integrals and partial derivatives, it remains relatively easy and straightforward compared to other concepts. The specific mention of \u0026lsquo;real space\u0026rsquo; and partial derivatives in the context of differentiation hints at its potential expansion into multidimensional spaces.\nSummary (a) Continuity: If $f$ is differentiable at $a \\in E$, then it is continuous at $a \\in E$.\n(b) Chain Rule: $( g \\circ f)' ( a ) = g \u0026rsquo; ( f (a) ) f '(a)$\n(c) Inverse Function Theorem: Suppose $f : E \\to \\mathbb{R}$ is a one-to-one continuous function on an open interval $E$. (i) If for some $a \\in E$, $b = f(a)$ and (ii): $f ' (a) \\ne 0$ exists, then $f^{-1}$ is differentiable at $a$, and\n$$ \\left( f^{-1} \\right)' (b) = {{ 1 } \\over { f '(a) }} $$\nWilliam R. Wade, An Introduction to Analysis (4th Edition, 2010), p98-99\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1210,"permalink":"https://freshrimpsushi.github.io/en/posts/1210/","tags":null,"title":"Differentiation of Functions Defined in Real Number Space"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Definition1 Let $X$ be a vector space. A function $\\left\\| \\cdot \\right\\| : X \\to \\mathbb{R}$ is called a semi norm of $X$ if it satisfies the following three conditions:\n(a) $\\left\\| x \\right\\| \\ge 0,\\quad \\forall\\ x \\in X$\n(b) $|cx|=|c|\\left\\| x \\right\\|,\\quad \\forall\\ x\\in X,\\ \\forall\\ c \\in\\mathbb{C}$\n(c) $\\left\\| x + y \\right\\| \\le \\left\\| x \\right\\| + \\left\\| y \\right\\|,\\quad \\forall\\ x,y\\in X$\nExplanation The definition of a norm without $\\left\\| x \\right\\|=0 \\iff x = 0$.\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p101\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1229,"permalink":"https://freshrimpsushi.github.io/en/posts/1229/","tags":null,"title":"Semi Norm"},{"categories":"Ìï®Ïàò","contents":"Definition1 If a function $f : X \\to Y$ satisfies the following two conditions, it is called sublinear. For $x,x_{1},x_{2}\\in X$ and $a \\in \\mathbb{R}$,\n$f(ax) = af(x)$ $f(x_{1} + x_{2}) \\le f(x_{1}) + f(x_{2})$ Explanation If the second condition holds as an equality, it is linear, and if it holds as an inequality, it is sublinear.\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p54\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1333,"permalink":"https://freshrimpsushi.github.io/en/posts/1333/","tags":null,"title":"Semi-linear Function"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 Let\u0026rsquo;s say $\\left\\{ Y_{t} \\right\\}_{t=1}^{n}$ is a stochastic process.\n$\\mu_{t} := E ( Y_{t} )$ is called the mean function. The following defined $\\gamma_{ t , s }$ is called the autocovariance function. $$ \\gamma_{t , s} : = \\text{cov} ( Y_{t} , Y_{s} ) = E ( Y_{t} - \\mu_{t} ) E ( Y_{s} - \\mu_{s} ) $$ The following defined $\\rho_{ t , s }$ is called the autocorrelation function. $$ \\rho_{ t , s } := \\text{cor} ( Y_{t} , Y_{s} ) = {{ \\gamma_{t , s} } \\over { \\sqrt{ \\gamma_{t , t} \\gamma_{s , s} } }} $$ The following defined $\\rho_{ k }$ is called the autocorrelation function for lag $k$. $$ \\rho_{ k } := \\text{cor} ( Y_{t} , Y_{t-k} ) = {{ \\gamma_{t , t - k} } \\over { \\sqrt{ \\gamma_{t , t} \\gamma_{t-k , t-k} } }} $$ The following defined $r_{ k }$ is called the sample autocorrelation function for lag $k$. $$ r_{ k } := {{ \\sum_{t = k+1}^{n} \\left( Y_{t} - \\overline{Y} \\right) \\left( Y_{t-k} - \\overline{Y} \\right) } \\over { \\sum_{t=1}^{n} \\left( Y_{t} - \\overline{Y} \\right)^2 }} $$ Explanation Autocorrelation function is a function for understanding the auto-correlation of time series data, focusing on how similar to itself it is, even if it\u0026rsquo;s the same variable, but at a certain lag. In contrast to the idea of regression analysis, which is interested in the correlation between different variables, it treats itself as divided into $Y_{t}$ and $Y_{t-k}$ at lag $k$ like two variables.\nMathematical Explanation Mathematically, if we think $Y_{t}$ came from $MA(q)$, then since it is $\\displaystyle Y_{t} = e_{t} - \\sum_{k=1}^{q} \\theta_{k} e_{t-k}$, $Y_{t}$ can be viewed as a sum of several normal distributions, and since $\\rho_{k}$ equals to $\\theta_{k}$, it is useful for finding the $MA(q)$ model.\nsACF $r_{k}$ is an estimate of ACF $\\rho_{k}$, and if $Y_{t}$ came from the $MA(q)$ model, then when $k \u0026gt; q$, it follows the normal distribution $\\displaystyle N \\left( \\rho_{k} , {{1} \\over {n}} \\left[ 1 + 2 \\sum_{j=1}^{q} \\rho_{j}^{2} \\right]^2 \\right)$. Expressed mathematically, it is $$ r_{k} \\sim N \\left( \\rho_{k} , {{1} \\over {n}} \\left[ 1 + 2 \\sum_{j=1}^{q} \\rho_{j}^{2} \\right]^2 \\right) $$ which is used for hypothesis testing.\nTests Given $\\displaystyle Y_{t} = e_{t} - \\sum_{k=1}^{q} \\theta_{k} e_{t-k}$ and assume $k = 1 , \\cdots , q$.\n$H_{0}$: $MA(0) \\iff \\theta_{k} = 0$, namely, $Y_{t}$ does not follow the moving average model. $H_{1}$: $MA(k) \\iff \\theta_{k} \\ne 0$, namely, $Y_{t}$ has an autocorrelation at lag $k$. Interpretation Under the null hypothesis, since $\\rho_{k} = \\theta_{k} = 0$ for all $k$, assume $q = 0$ and $\\displaystyle r_{k} \\sim N \\left( 0 , {{1} \\over {N }} \\right)$, and the standard error becomes $\\displaystyle {{1} \\over {\\sqrt{n} }}$. Therefore, if you want to conduct a hypothesis test at the significance level $\\alpha$, check whether $| \\theta_{k} |$ exceeds the upper confidence limit $\\displaystyle {{ z_{1 - \\alpha/2} } \\over { \\sqrt{n} }}$. If it exceeds, it becomes a candidate for significant lag; if not, it is considered to have no autocorrelation.\nPractice The ma1.2.s data is a sample data from the TSA package derived from the $MA(1)$ model. When analyzing with the actual ARIMA model, the significance of the coefficient is also determined based on whether the absolute value of the estimate exceeds twice the standard error.\nUsing the acf() function of the TSA package, it produces a correlogram for various $k$ like the above. Without having to calculate in your head, if it exceeds the line, it is considered significant; if not, it is considered not significant. It is calculated at a default significance level $5 \\%$.\nNote that, even if it slightly exceeds $k=6$, it is statistically significant, but it is not considered to have an actual autocorrelation. Such cases of slight exceeding are very common in time series analysis, and for mental health, it is recommended to show flexibility and accept it as it is.\nDrawing lines yourself as shown above is recommended as a way to confirm if you properly understood hypothesis testing using the autocorrelation function. With just one line of code in R, by running it at least once yourself, you can accept that $r_{k}$ follows a normal distribution, and the standard error is calculated as $\\displaystyle \\text{se} ( r_{k} ) = {{1} \\over {\\sqrt{n}}}$ without complicated formulas.\nCode library(TSA)\rdata(ma1.2.s); win.graph(6,4); acf(ma1.2.s)\rarima(ma1.2.s, order=c(0,0,1))\rabline(h=1.96*1/sqrt(length(ma1.2.s)),col=\u0026#39;red\u0026#39;) See Also PACF: Partial Autocorrelation Function EACF: Extended Autocorrelation Function CCF: Cross-Correlation Function Cryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p11, 109.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1209,"permalink":"https://freshrimpsushi.github.io/en/posts/1209/","tags":["R"],"title":"Autocorrelation Function"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition1 Let us assume $E \\subset \\mathbb{R}$ is a non-empty set and define $f : E \\to \\mathbb{R}$. If for every $\\varepsilon \u0026gt; 0$,\n$$ | x_{1} - x_{2} | \u0026lt; \\delta \\land x_{1} , x_{2} \\in E \\implies | f(x_{1}) - f(x_{2}) | \u0026lt; \\varepsilon $$\nthere exists a $\\delta\u0026gt;0$ satisfying the above equation, then $f$ is said to be uniformly continuous on $E$.\n$\\land$ represents the logical \u0026lsquo;and\u0026rsquo; symbol, known as the logical conjunction. Explanation The concept of continuity of a function itself is about a point as in $a \\in E$, while uniform continuity considers the entire set $E$. For example, consider the continuous function $f (x) := x^2$.\nLet us assume $E \\subset \\mathbb{R}$ is a non-empty set and define $f : E \\to \\mathbb{R}$.\n(a) Compact Metric Space: If $f$ is continuous and $E$ is a bounded closed interval, then $f$ is uniformly continuous.\n(b) Preservation of Convergence: If $f$ is uniformly continuous and $\\left\\{ x_{n} \\right\\}_{n=1}^{\\infty}$ is Cauchy, then $\\left\\{ f(x_{n}) \\right\\}$ is also Cauchy.\n(1) $E = (0,1)$ If we take $\\delta = \\dfrac{\\varepsilon}{2}$ to be,\nthen for all $x_{1} , x_{2} \\in (0,1)$, when we say $| x_{1} - x_{2} | \u0026lt; \\delta$,\n$$ \\begin{align*} | f(x_{1}) - f(x_{2}) | =\u0026amp; | x_{1}^{2} - x_{2}^{2} | \\\\ =\u0026amp; | x_{1} - x_{2} | | x_{1} + x_{2} | \\\\ \\le \u0026amp; 2 | x_{1} - x_{2} | \\\\ \u0026amp; \u0026lt; \u0026amp; 2 \\delta \\\\ =\u0026amp; \\varepsilon \\end{align*} $$\naccording to the definition, $f$ is uniformly continuous on $E = ( 0 , 1 )$.\n(2) $E = \\mathbb{R}$ Let\u0026rsquo;s assume $f$ is uniformly continuous on $E$. Even when $\\varepsilon = 1$ is given,\n$$ | x_{1} - x_{2} | \u0026lt; \\delta \\land x_{1} , x_{2} \\in E \\implies | f(x_{1}) - f(x_{2}) | \u0026lt; 1 $$\na $\\delta$ must exist. However, according to the Archimedean principle, we can choose a $n \\in \\mathbb{N}$ satisfying $n \\delta \u0026gt; 1$. Then, for $x_{1} = n$, $x_{2} = \\left( n + \\dfrac{ \\delta }{2} \\right)$,\n$$ \\begin{align*} 1 \u0026amp; \u0026lt; \u0026amp; n \\delta \\\\ \u0026lt;\u0026amp; n \\delta + {{ \\delta^{2} } \\over { 4 }} \\\\ =\u0026amp; \\left| n^2 - \\left( n + {{ \\delta } \\over {2}} \\right)^2 \\right| \\\\ =\u0026amp; \\left| f( n ) - f \\left( n + {{ \\delta } \\over {2}} \\right) \\right| \\\\ =\u0026amp; | f (x_{1} ) - f ( x_{2} ) | \\\\ \u0026lt;\u0026amp; 1 \\end{align*} $$\nThis leads to a contradiction, given $1 \u0026lt; 1$. Hence, $f$ is not uniformly continuous on $E = \\mathbb{R}$.\nConsidering $g(x) = x$, no matter what domain $E$ we consider, by taking $\\delta = \\varepsilon$, it satisfies the conditions for uniform continuity. From such examples, it\u0026rsquo;s intuitive to think that uniformly continuous functions are a type of \u0026lsquo;gentle\u0026rsquo; function. It makes sense that $g$ will diverge as $x$ approaches infinity. However, unlike $f(x) = x^2$, it does not grow violently but maintains a certain line. It\u0026rsquo;s a natural principle that gentle things are easier to handle than violent ones, and it also makes sense that uniformly continuous functions have better conditions than mere continuous functions.\nLet\u0026rsquo;s think about the case in (b) where only continuity is assumed without the assumption of uniform continuity.\n$\\displaystyle h(x) := {{1} \\over {x}}$ is a continuous function, and if we take $\\displaystyle x_{n} := {{1} \\over {n}}$, then $\\left\\{ x_{n} \\right\\}$ is a Cauchy sequence converging to $0$. However, since $\\displaystyle h (x_{n} ) = {{1} \\over { {{1} \\over {n}} }} = n$, it is understood that $\\left\\{ h ( x_{n} ) \\right\\}$ is not a Cauchy sequence.\nWilliam R. Wade, An Introduction to Analysis (4th Edition, 2010), p92\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1207,"permalink":"https://freshrimpsushi.github.io/en/posts/1207/","tags":null,"title":"Uniform Continuity of Functions"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Definition1 Let\u0026rsquo;s call $X$ a vector space. If there exists a function $\\left\\| \\cdot \\right\\| : X \\to \\mathbb{R}$ that satisfies the following three conditions, then $\\left\\| \\cdot \\right\\|$ is called the norm of $X$, and $(X,\\left\\| \\cdot \\right\\| )$ is called a normed space.\n(a) $\\left\\| x \\right\\| \\ge 0,\\quad \\forall\\ x \\in X$ and $\\left\\| x \\right\\|=0 \\iff x = 0$\n(b) $|cx|=|c|\\left\\| x \\right\\|,\\quad \\forall\\ x\\in X,\\ \\forall\\ c \\in\\mathbb{C}$\n(c) $\\left\\| x + y \\right\\| \\le \\left\\| x \\right\\| + \\left\\| y \\right\\|,\\quad \\forall\\ x,y\\in X$\nExplanation The norm of the normed space $X$ can be represented as below:\n$$ \\left\\| x \\right\\|_{X},\\quad \\left\\| x, X \\right\\|, \\quad \\left\\| x ; X \\right\\| $$\n(a) Without the condition of $\\left\\| x \\right\\|=0 \\iff x = 0$, it becomes a seminorm.\n(b) means that $\\left\\| x - y \\right\\| =|y -x|$ holds.\n(c) is called the triangle inequality, and the inequality below is called the reverse triangle inequality. For normed spaces $(X, \\left\\| \\cdot \\right\\| )$ and $x, y \\in X$, the following inequality holds:\n$$ \\left| \\left\\| x \\right\\| - \\left\\| y \\right\\|\\ \\right| \\le \\left\\| x- y \\right\\| $$\nThe norm is a continuous mapping.\nNormed Space as a Metric Space and Topological Space Given a norm, a distance can be naturally defined. Therefore, a normed space becomes a metric space.\n$$ d(x,y) = d_{X}(x,y) = \\left\\| x - y \\right\\|_{X} $$\nGiven the distance, an open ball can be defined as below:\n$$ B_{d}(x,r)=B_{r}(x):=\\left\\{ y\\in X\\ :\\ \\left\\| x - y \\right\\|_{X} \u0026lt;r \\right\\} $$\nThe collection of all open balls forms a basis in the topological sense on $X$. In other words, the open balls defined by the norm of $X$ can create a topology on $X$. This resulting topology on $X$ is called the norm topology2. Additionally, if the topology of topological vector space $X$ is the norm topology, $X$ is called normable.\nIn summary, saying that $X$ is a normed space implies that $X$ is a vector space, a metric space, and a topological space. Therefore, in functional analysis, a given normed space is naturally treated as a metric space and a topological space as well.\nProof3 By the triangle inequality,\n$$ \\left\\| x \\right\\|= | (x-y) +y| \\le |x-y| + \\left\\| y \\right\\| $$\nholds. Therefore,\n$$ \\begin{equation} \\left\\| x \\right\\| - \\left\\| y \\right\\| \\le \\left\\| x- y \\right\\| \\end{equation} $$\nSimilarly,\n$$ \\left\\| y \\right\\| = | (y - x) + x| \\le \\left\\| y- x \\right\\| + \\left\\| x \\right\\| $$\nthus,\n$$ \\begin{equation} \\left\\| y \\right\\| - \\left\\| x \\right\\| \\le \\left\\| y- x \\right\\|=\\left\\| x - y \\right\\| \\end{equation} $$\nholds. Therefore, by $(1), (2)$,\n$$ \\left| \\ \\left\\| x \\right\\| -\\left\\| y \\right\\|\\ \\right| \\le \\left\\| x- y \\right\\| $$\n‚ñ†\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p4-5\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFrom the perspective of distance, this is called the metric topology.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOle Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p30\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1225,"permalink":"https://freshrimpsushi.github.io/en/posts/1225/","tags":null,"title":"What is a Norm Space?"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition Let\u0026rsquo;s say a set that is not an empty set is called $E \\subset \\mathbb{R}$, and $f : E \\to \\mathbb{R}$. If there exists $\\delta\u0026gt;0$ for every $\\varepsilon \u0026gt; 0$ such that\n$$ | x - a | \u0026lt; \\delta \\implies | f(x) - f(a) | \u0026lt; \\varepsilon $$\nis satisfied, $f$ is said to be continuous at $a \\in E$, and if it is continuous at every point of $E$, $f$ is called a continuous function.\nExplanation When defining continuity in high school,\nThe function value $f(a)$ exists. The limit $\\lim \\limits_{x \\to a}$ exists. $f(a) = \\lim \\limits_{x \\to a}$ is true. When these three conditions are met, $f$ is said to be continuous at $x = a$. If you‚Äôve accepted the epsilon-delta argument, you‚Äôll realize that this definition isn‚Äôt really different from what is taught in high school.\nThe fact that whenever $| x - a | \u0026lt; \\delta$, $| f(x) - f(a) | \u0026lt; \\varepsilon$, means if $x$ moves very slightly around $a$, then $f(x)$ will also move very slightly from $f(a)$. In other words, if you change $x$ and put it into $f$, the function value does not change \u0026lsquo;drastically\u0026rsquo;, i.e., discontinuously. In other words, continutity, if imagined as a graph, means \u0026rsquo;not breaking\u0026rsquo;.\nAmong high school students, there are quite a few who intuitively accept \u0026lsquo;unbroken\u0026rsquo; functions as continuous functions. As a counterexample, $f(x) := {{ 1 } \\over { x }}$ is broken at $x=0$ but is continuous at every point in the domain $\\mathbb{R}^{ \\ast } = \\mathbb{R} \\setminus \\left\\{ 0 \\right\\}$, therefore, it is indeed a continuous function. Usually, not knowing wouldn\u0026rsquo;t affect life, but if you didn\u0026rsquo;t know, take this chance to clearly understand the concept.\nTheorem That $f$ is continuous at $a \\in E$ is equivalent to the following.\n$$ \\lim \\limits_{n \\to \\infty} x_{n} = a \\implies \\lim \\limits_{n \\to \\infty} f( x_{n} ) = f(a) $$\nThe theorem indicates that due to the continuity of the function, $\\lim \\limits_{n \\to \\infty}$ can move in and out of $f$. In many fields outside of mathematics, continuity is often taken for granted without proper verification, which, from a mathematician‚Äôs standpoint, should be rigorously scrutinized.\n","id":1206,"permalink":"https://freshrimpsushi.github.io/en/posts/1206/","tags":null,"title":"Newly Defined Continuous Functions in University Mathematics"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition1 Let $I$ be an interval containing $a \\in \\mathbb{R}$, and suppose that $f$ is a function defined at $I \\setminus \\left\\{ a \\right\\}$. If for every $\\epsilon \u0026gt; 0$, there exists a $\\delta\u0026gt;0$ such that\n$$ 0 \u0026lt; | x - a | \u0026lt; \\delta \\implies | f(x) - L | \u0026lt; \\varepsilon $$\nis satisfied, then we say that $f(x)$ converges to $L \\in \\mathbb{R}$ as $x \\to a$ approaches $a \\in \\mathbb{R}$.\nExplanation The term \u0026ldquo;epsilon-delta\u0026rdquo; comes from, as you can see, epsilon $\\varepsilon$ and delta $\\delta$ appearing in the definition. It\u0026rsquo;s an expression first used by Cauchy, the \u0026ldquo;father of analysis\u0026rdquo;, where epsilon and delta represent error $\\varepsilon$rror and distance $\\delta$istance, respectively.\nAs you can see, the expression is very complex and far from intuitive, which is why it is initially difficult to grasp. Like the limit of a sequence, there is both a reason for redefining it this way and a reason for its complicated definition, but understanding these reasons and truly understanding epsilon-delta are two different matters. In fact, understanding epsilon-delta is not enough; it only becomes useful after getting used to it.\nTo get a grip on it, imagine shooting game. In this game, you have a gun $f$ and are shooting at a specified target $L$ from a set position $a$, where whether you hit the target or not is judged within an allowed error $\\varepsilon$. Of course, if you couldn‚Äôt move at all from $a$, you wouldn‚Äôt be able to hit the target. Let\u0026rsquo;s assume the shooter can determine how much they need to move to hit the target when given an error $\\varepsilon$ and thus can propose an allowable distance $\\delta$.\nThe given gun is $f(x) := 2x$, and with it, aiming at $x$ and shooting results in hitting $2x$. To judge if this gun is proper, one might test if it can hit $L=0$ from $a=0$. But can a gun with scattered hit points really hit the target? Let\u0026rsquo;s examine a few cases in practice.\n**Case 1. $\\varepsilon = 12$\nThe first allowable error is given generously as $\\varepsilon = 12$. Since only $| f(x) - L | \u0026lt; \\varepsilon$ needs to be satisfied, shooting from $x$ to meet $| f(x) | \u0026lt; 12$ will be considered a hit. So, $x$ must not exceed the absolute value of $6$, meaning as long as it is $| x | \u0026lt; 6$, it will meet $| f(x) | \u0026lt; 12$. Rewriting it as an equation:\n$$ | x | \u0026lt; 6 \\implies | f(x) | \u0026lt; 12 $$\nThis shows that, with an allowable error of $\\varepsilon = 12$, we can identify an allowable distance $\\delta = 6$ in which the gun $f$ can hit the target $L = 0$ from $a = 0$. Of course, a smaller distance would also work, but there is no need to make it harder than necessary.\n**Case 2. $\\varepsilon = 6$\nThe second allowable error is given as $\\varepsilon = 6$. Just like before, satisfying $| f(x) | \u0026lt; 6$ is all it takes, hence the necessary allowable distance $\\delta = 3$ can be presented.\n**Case 3. $\\varepsilon \u0026gt; 0$\nAs we have seen, no matter how the allowable error $\\varepsilon \u0026gt; 0$ is set, we can present an allowable distance $\\delta = \\varepsilon / 2$ to hit the target. Being able to specify $\\delta$ for every $\\varepsilon\u0026gt; 0$ essentially means the following:\n$$ \\forall \\varepsilon \u0026gt; 0 , \\exists \\delta : | x - 0 | \u0026lt; \\delta \\implies | f(x) - 0 | \u0026lt; \\varepsilon $$\nRewritten in familiar terms, it becomes $\\lim_{x \\to 0} 2x = 0$. Until now, we demonstrated that when $x \\to 0$, it implies $2x \\to 0$. The shooting analogy is no longer needed, but to reiterate, it means with the gun $f$, you can hit the target $L = 0$ from $a = 0$.\nFor example, when explaining that $\\delta (12) =6$ exists, that $\\delta (6) = 3$ exists, and so on, you might have felt some understanding. As you read through the explanation, you suddenly proved $\\lim_{x \\to 0} 2x = 0$, but such an analogy might be forgettable due to its lack of cohesion. Now, let\u0026rsquo;s consider why epsilon-delta is difficult.\nIntuition: The sensation of using epsilon-delta and the feeling of ‚Äòapproaching infinitely close‚Äô like $x \\to a$ and $f(x) \\to L$ feels different\nIn fact, this is the real reason for using epsilon-delta, but for now, it might not be \u0026lsquo;convincing\u0026rsquo; why the existence of $\\delta$ equates to something like $\\lim_{x \\to a} f(x) = L$. If this is the only obstacle, it doesn‚Äôt mean you failed to understand epsilon-delta; it\u0026rsquo;s just unfamiliar. Whether it\u0026rsquo;s $| x - a | \u0026lt; \\delta$ or $| f(x) - L | \u0026lt; \\varepsilon$, $\\delta$ isn‚Äôt thought of as a \u0026rsquo;large number\u0026rsquo;. It\u0026rsquo;s perceived as a sufficiently small positive number that \u0026lsquo;suppresses\u0026rsquo; $| x - a |$ and $| f(x) - L |$, ultimately leading to the following thought process:\n$$ | x - a | \u0026lt; \\delta \\implies \\lim_{\\delta \\to 0} | x - a | = 0 \\implies x \\to a $$\n$$ | f(x) - L | \u0026lt; \\varepsilon \\implies \\lim_{\\varepsilon \\to 0} | f(x) - L | = 0 \\implies f(x) \\to L $$\nTerminology: The phrase \u0026lsquo;$\\delta$ exists\u0026rsquo; doesn\u0026rsquo;t quite resonate\nIn reality, this isn‚Äôt about literally creating $\\delta$ but rather about presenting it in relation to $\\varepsilon$. If you\u0026rsquo;ve managed to express $\\delta$ as a function $\\delta = \\delta ( \\varepsilon )$ of $\\varepsilon$, then since the existence of $\\varepsilon \u0026gt; 0$ is already assumed, $\\delta$ exists as well.\nOrder: The condition is $|x - a| \u0026lt; \\delta \\implies | f(x) - L | \u0026lt; \\varepsilon$, but the order of thought is opposite\nThis is a really confusing part because the form of $\\implies$ might make it seem like the order should go from front to back. However, as made clear by \u0026ldquo;for all $\\varepsilon \u0026gt; 0$\u0026rdquo;, $| f(x) - L | \u0026lt; \\varepsilon$ must be considered first before $| x - a | \u0026lt; \\delta$. If you don\u0026rsquo;t know what $\\varepsilon$ is, then it\u0026rsquo;s not worth pondering.\nConsidering these three reasons while re-reading the explanation will be helpful. If you have understood, now a few odd points might appear, such as caring only about $| x - a | \u0026lt; \\delta$ instead of $0 \u0026lt; | x - a | \u0026lt; \\delta$, suddenly no more mentioning whether $f$ is a proper gun, or not being able to hit the target without moving from $a$, etc. These are merely analogies twisted in various ways to make epsilon-delta as intuitive as possible. Important is not to focus on irrelevant parts but to use concentration on logically necessary proofs.\nWilliam R. Wade, An Introduction to Analysis (4th Edition, 2010), p68\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1204,"permalink":"https://freshrimpsushi.github.io/en/posts/1204/","tags":null,"title":"Epsilon-Delta Argument"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":" imbedding and embedding mean the same thing. Embedding is translated as insertion, embedding, incorporating, burying, etc. Definition1 Let $(X, \\left\\| \\cdot \\right\\|_{X}), (Y, \\left\\| \\cdot \\right\\|_{Y})$ be a normed space. If the following two conditions are satisfied for $X$ and $Y$, then $X$ is said to be embedded into $Y$, and $I : X \\to Y$ is called the embedding.\n$X$ is a subspace of $Y$.\nFor all $x \\in X$, the identity operator $I : X \\to Y$ defined by $Ix = x$ is continuous.\nExplanation Since the identity operator is linear, the second condition is equivalent to $I$ being bounded. Thus, it can be rewritten as follows.\n$$ \\exists M \\gt 0 \\text{ such that } \\left\\| Ix \\right\\|_{{Y}} \\le M \\left\\| x \\right\\|_{X},\\quad x \\in X $$\nIf the embedding operator $I$ is compact, then $X$ is said to be compactly embedded into $Y$.\n$f : X \\to Y$ being an isometric embedding means that $f : X \\to f(X)$ is an isometric mapping. By Theorem 2, it can be known that every metric space can be isometrically embedded into a complete metric space. That is, every metric space can be treated as a subset of a complete metric space.\nTheorems Theorem 1 Let $X, Y$ be a metric space. Let $f : X \\to Y$ be an isometric mapping. Then, $f$ is an embedding.\nTheorem 2 Let $(X, d_{X})$ be a metric space. Let $(Y,d_{Y})$ be a complete metric space. Then, an isometric embedding $f : X \\to Y$ exists.\nSee Also Embedding in Topology Embedding in Differential Manifolds Robert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p9\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1214,"permalink":"https://freshrimpsushi.github.io/en/posts/1214/","tags":null,"title":"Embeddings in Mathematics, Insertion Mappings"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition Let $\\left\\{ x_{n} \\right\\}_{n \\in \\mathbb{N}}$, $\\left\\{ y_{n} \\right\\}_{n \\in \\mathbb{N}}$ be sequences of real numbers.\n$\\displaystyle \\limsup_{n \\to \\infty} x_{n} := \\lim_{n \\to \\infty} \\left( \\sup_{k \\ge n} x_{k} \\right)$ is called the limit supremum of $\\left\\{ x_{n} \\right\\}$. $\\displaystyle \\liminf_{n \\to \\infty} y_{n} := \\lim_{n \\to \\infty} \\left( \\inf_{k \\ge n} y_{k} \\right)$ is called the limit infimum of $\\left\\{ y_{n} \\right\\}$. Where $\\displaystyle \\sup_{k \\ge n} x_{k} := \\sup \\left\\{ x_{k} : k \\ge n \\right\\}$ and $\\displaystyle \\inf_{k \\ge n} x_{k} := \\inf \\left\\{ x_{k} : k \\ge n \\right\\}$.\nProperties (a): $$ \\liminf_{n \\to \\infty} x_{n} \\le x \\le \\limsup_{n \\to \\infty} x_{n} $$ (b): $$ \\liminf_{n \\to \\infty} x_{n} = x = \\limsup_{n \\to \\infty} x_{n} \\iff \\lim_{n \\to \\infty} x_{n} = x $$ (c): $$ \\begin{align*} - \\liminf_{n \\to \\infty} x_{n} =\u0026amp; \\limsup_{n \\to \\infty} ( - x_{n} ) \\\\ - \\limsup_{n \\to \\infty} x_{n} =\u0026amp; \\liminf_{n \\to \\infty} ( - x_{n} ) \\end{align*} $$ (d): If $x_{n} \\le y_{n}$, then $$ \\begin{align*} \\limsup_{n \\to \\infty} x_{n} \\le\u0026amp; \\limsup_{n \\to \\infty} y_{n} \\\\ \\liminf_{n \\to \\infty} x_{n} \\le\u0026amp; \\liminf_{n \\to \\infty} y_{n} \\end{align*} $$ Explanation The concept of limit supremum is widely useful throughout analysis, introduced for convenience whether one agrees with it immediately or not. Intuitively, it helps to think about supremum and infimum while \u0026lsquo;discarding the initial part of the sequence\u0026rsquo;.\nFor example, when $\\displaystyle x_{k} = {{ 1 } \\over { k }}$, let\u0026rsquo;s inspect the actual process of calculating $\\displaystyle \\sup_{k \\ge n} \\left\\{ x_{k} \\right\\}$.\n$$ n=3 : \\sup \\left\\{ {{ 1 } \\over { 3 }} , {{ 1 } \\over { 4 }} , {{ 1 } \\over { 5 }} , \\cdots \\right\\} = {{ 1 } \\over { 3 }} $$\n$$ n=4 : \\sup \\left\\{ \\quad {{ 1 } \\over { 4 }} , {{ 1 } \\over { 5 }} , \\cdots \\right\\} = {{ 1 } \\over { 4 }} $$\n$$ n=5 : \\sup \\left\\{ \\quad \\quad {{ 1 } \\over { 5 }} , \\cdots \\right\\} = {{ 1 } \\over { 5 }} $$\n$$ n \\to \\infty : \\sup_{k \\ge n} \\left\\{ {{ 1 } \\over { k }} : k \\in \\mathbb{N} \\right\\} = 0 $$\nThus, discarding the initial part implies that we are interested in speaking about a sufficiently large $n$, and ultimately, it helps us understand its relevance to $\\lim$.\nGiven $\\displaystyle \\lim_{n \\to \\infty} \\left\\{ {{1} \\over {k}} : k \\ge n \\right\\} = \\emptyset$, therefore, not having $\\displaystyle \\sup \\lim_{n \\to \\infty} \\left\\{ x_{n} \\right\\}$ might make one appreciate why it\u0026rsquo;s sometimes necessary to introduce expressions like $\\displaystyle \\limsup_{n \\to \\infty} = \\lim_{n \\to \\infty} \\sup_{k \\ge n}$. While limits are considered, it\u0026rsquo;s sufficient to have $n$, hence it\u0026rsquo;s reasonable to think in terms of the limit of another sequence $s_{n}$.\nOn the other hand, considering $\\displaystyle y_{n} = {{1} \\over {(-2)^{n-1}}}$ gives us $\\sup \\left\\{ y_{n} \\right\\} = 1$ and $\\displaystyle \\inf \\left\\{ y_{n} \\right\\} = - {{1} \\over {2}}$ but\n$$ \\limsup_{n \\to \\infty} y_{n} = \\liminf_{n \\to \\infty} y_{n} = 0 $$\nThis serves as an example for property (b).\n","id":1198,"permalink":"https://freshrimpsushi.github.io/en/posts/1198/","tags":null,"title":"Limits Supremum and Limits Infimum"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Definition 1 Given a continuous function defined in $D \\subset \\mathbb{R}^2$ for the initial value problem given in $\\begin{cases} y ' = f(x,y) \\\\ ( y( x_{0} ) , \\cdots , y(x_{p}) ) = (Y_{0}, \\cdots , Y_{p} ) \\end{cases}$, let\u0026rsquo;s say we have broken down interval $(a,b)$ into nodes like $a \\le x_{0} \u0026lt; x_{1} \u0026lt; \\cdots \u0026lt; x_{n} \u0026lt; \\cdots x_{N} \\le b$. Especially for a sufficiently small $h \u0026gt; 0$, if we say $x_{j} = x_{0} + j h$, then for the initial value and $0 \\le p \\le m$, if $a_{p} \\ne 0$ or $b_{p} \\ne 0$, the following is called a $(p+1)$-step method. $$ y_{n+1} = \\sum_{j=0}^{p} a_{j} y_{n-j} + h \\sum_{j = -1}^{p} b_{j} f (x_{n-j} , y_{n-j} ) $$\nExplanation Of course, it is permissible to think of a sufficiently large $q \\ge 1$ and $f \\in C^{q}(D)$ defined from $D \\subset \\mathbb{R}^2$. Especially in this general form, if particularly $p=0$ and $a_{0} = 1 , b_{0} = 1 , b_{-1} = 0$ then it becomes the Euler method.\nMultistep methods generally have a higher accuracy as they use more data information compared to one-step methods. For the initial value problem given in $\\begin{cases} y ' = f(x,y) \\\\ ( y( x_{0} ) , \\cdots , y(x_{p}) ) = (Y_{0}, \\cdots , Y_{p} ) \\end{cases}$, let\u0026rsquo;s consider the truncation error as $$ T_{n} (Y) := Y_{n+1} - \\sum_{j=0}^{p} a_{j} Y_{n-j} + h \\sum_{j = -1}^{p} b_{j} Y\u0026rsquo;_{n-j} $$ and write this as $\\displaystyle \\tau_{n} (Y) := {{1} \\over {h}} T_{n} (Y) $, if it satisfies $\\displaystyle \\lim_{h \\to 0} \\max_{x_{p} \\le x_{n} \\le b} | \\tau_{n} (Y) | = 0$, then the method is said to have a consistency condition. It might look complicated when written in equations but simply put, this means the speed at which the truncation error decreases is faster than the speed at which $h$ decreases. Where $$ \\tau (h) : = \\max_{x_{p} \\le x_{n} \\le b} | \\tau_{n} (Y) | = O (h^m) $$ among $m$, the highest number is called the method\u0026rsquo;s order of convergence.\nEspecially if $b_{-1} = 0$, then $y_{n+1}$ is referred to as an explicit method because it appears only in the left side. If $b_{-1} \\ne 0$, then because $y_{n+1}$ appears on both sides, it is referred to as an implicit method. While explicit methods are convenient for calculations, generally known implicit methods perform well but require additional calculations.\nAtkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p357.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":693,"permalink":"https://freshrimpsushi.github.io/en/posts/693/","tags":null,"title":"Multistep Methods"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Summary Let\u0026rsquo;s assume that the solution $Y(x)$ to the initial value problem $\\begin{cases} y ' = f(x,y) \\\\ y( x_{0} ) = Y_{0} \\end{cases}$, defined in $[x_{0} , b] \\times \\mathbb{R}$ for $f$, is twice differentiable in $[x_{0} , b]$. If $f$ satisfies strong Lipschitz condition $$ |f(x,y_{1} ) - f(x,y_{2}) | \\le K | y_{1} - y_{2} | $$ for all $x_{0} \\le x \\le b$, $ y_{1} , y_{2} \\in \\mathbb{R}$, and $K \\ge 0$, then for the solution $\\left\\{ y_{n} ( x_{ n } ) \\ : \\ x_{0} \\le x_{n} \\le b \\right\\} $ obtained by Euler\u0026rsquo;s method, we have $$ \\max_{ x_{0 } \\le x_{n} \\le b } | Y_{x_{n}} - y_{h} (x_{n}) | \\le \\epsilon^{( b - x_{0} ) K} | \\epsilon_{0} | + \\left[ {{ \\epsilon^{(b- x_{0}) K } - 1 } \\over {K}} \\right] \\tau (h) $$ where $\\tau (h) = {{h} \\over {2}} \\left\\| Y\u0026rsquo;\u0026rsquo; \\right\\|_{\\infty}$ and $\\epsilon_{0} = Y_{0} - y_{h} (x_{0 } )$.\nSee Also Strong Lipschitz condition $\\implies$ Lipschitz condition $\\implies$ Local Lipschitz condition\nDescription To sum up what has been a lengthy explanation, there\u0026rsquo;s a slightly stronger condition than the Lipschitz condition that speaks to the accuracy of solutions derived from Euler\u0026rsquo;s method. Unlike the case with just the Lipschitz condition, which assumes continuity, the strong Lipschitz condition also considers differentiability.\nProof 1 $$ x_{n+1} - x_{n} = h $$\n$$ Y_{n} := Y(x_{n} ) $$\n$$ y_{n} := y(x_{n}) $$ Let\u0026rsquo;s denote the error at the $n$th step by $\\epsilon_{n} : = Y(x_{n}) - y (x_{n} )$.\nIf we perform an $2$th order Taylor expansion of $Y(x_{n+1} )$ with respect to $ x_{n}$, for some $x_{n} \\le \\xi_{n} \\le x_{n+1}$, $$ Y_{n+1} = Y_{n} + h Y\u0026rsquo;_{n} + {{h^2} \\over {2}} Y\u0026rsquo;\u0026rsquo; ( \\xi_{n} ) $$ Let\u0026rsquo;s conveniently denote it as $\\displaystyle \\tau_{n} := {{h} \\over {2}} Y\u0026rsquo;\u0026rsquo; ( \\xi_{n} )$, $$ Y_{n+1} = Y_{n} + h Y\u0026rsquo;_{n} + h \\tau_{n} $$\n$$ \\max_{n} | \\tau_{n} | \\le \\tau (h) $$ Subtracting the equation obtained by Euler\u0026rsquo;s method, $y_{n+1} = y_{n} + h f ( x_{n} , y_{n} )$, from both sides, $$ Y_{n+1} - y_{n+1} = Y_{n} - y_{n} + h ( f( x_{n} , Y_{n} ) - f (x_{n} , y_{n}) ) + h \\tau_{n} $$ If we express it in terms of $\\epsilon_{n}$, $$ \\epsilon_{n+1} = \\epsilon_{n} + h ( f( x_{n} , Y_{n} ) - f (x_{n} , y_{n}) ) + h \\tau_{n} $$ Taking the absolute value of both sides, $$ | \\epsilon_{n+1} | \\le | \\epsilon_{n} | + h | f( x_{n} , Y_{n} ) - f (x_{n} , y_{n}) | + h | \\tau (h) | $$ By the Lipschitz condition, $$ | \\epsilon_{n+1} | \\le | \\epsilon_{n} | + h K | Y_{n} - y_{n} | + h | \\tau (h) | $$ To summarize, $$ | \\epsilon_{n+1} | \\le (1 + hK ) | \\epsilon_{n} | + h | \\tau (h) | $$ Solving it recursively, $$ | \\epsilon_{n+1} | \\le (1 + hK )^n | \\epsilon_{0} | + [ 1 + (1 + hK) + \\cdots + (1 + hK)^{n-1} ] h | \\tau (h) | $$ By the Sum formula of a finite geometric series, $$ | \\epsilon_{n+1} | \\le (1 + hK )^n | \\epsilon_{0} | + \\left[ {{ (1+ hK)^{n} - 1} \\over {hK }} \\right] h | \\tau (h) | $$\nFollowing the Bernoulli\u0026rsquo;s inequality: $(1 + x )^{ \\alpha } \\le e^{ x \\alpha }$\nAccording to a corollary of Bernoulli\u0026rsquo;s inequality, because $ (1 + hK )^n \\le e^{hKn}$, $$ | \\epsilon_{n} | \\le e^{( b - x_{0} ) K} | \\epsilon_{0} | + \\left[ {{ e^{(b- x_{0}) K } - 1 } \\over {K}} \\right] \\tau (h) $$\n‚ñ†\nAdditional Conditions Now, let\u0026rsquo;s think about adding a condition from $\\displaystyle | \\epsilon_{n+1} | \\le | \\epsilon_{n} | + h K | Y_{n} - y_{n} | + h | \\tau (h) | $ due to the Lipschitz condition up to $\\displaystyle {{\\partial f (x,y) } \\over { \\partial y }} \\le 0$. To beautify the expression, $$ | \\epsilon_{n+1} | \\le (1 + hK) | \\epsilon_{n} | + {{h^2} \\over {2}} | Y\u0026rsquo;\u0026rsquo; ( \\xi_{n } ) | $$ By the Mean valuetheorem, $$ K = \\left| {{f(x,y_{1} ) - f(x,y_{2}) } \\over {y_{1} - y_{2}}} \\right| = \\left| {{ \\partial f ( x_{n} , \\zeta_{n} ) } \\over { \\partial y }} \\right| $$ there exists $\\zeta_{n} \\in \\mathscr{H} \\left\\{ y_{h} (x_{n} ) , Y ( x_{n} ) \\right\\}$ that satisfies. If $h$ is sufficiently small so that $\\displaystyle 1+ h {{ \\partial f ( x_{n} , \\zeta_{n} ) } \\over { \\partial y }} \\ge -1$, then $$ | \\epsilon_{n+1} | \\le | \\epsilon_{n} | + {{h^2} \\over {2}} | Y\u0026rsquo;\u0026rsquo; ( \\xi_{n } ) | $$ Solving this inequality recursively as well, $$ | \\epsilon_{n} | \\le | \\epsilon_{0} | + {{h^2} \\over {2}} [ |Y\u0026rsquo;\u0026rsquo; ( \\xi_{0 } ) | + \\cdots + |Y\u0026rsquo;\u0026rsquo; ( \\xi_{n-1 } ) | ] $$ Therefore, $$ | \\epsilon_{n} | \\le | \\epsilon_{0} | + {{h^2} \\over {2}} n \\left\\| Y\u0026rsquo;\u0026rsquo; \\right\\|_{\\infty} $$ since $nh = b - x_{0}$, $$ | \\epsilon_{n} | \\le | \\epsilon_{0} | + {{h} \\over {2}} \\left\\| Y\u0026rsquo;\u0026rsquo; \\right\\|_{\\infty} ( b - x_{0}) $$ This means that the condition $\\displaystyle {{\\partial f (x,y) } \\over { \\partial y }} \\le 0$ has linearly reduced the upper bound of the error, which would have increased exponentially with respect to $(b - x_{0})$ originally. Fortunately, many problems found in natural phenomena satisfy this assumption, thereby significantly reducing the error.\nAtkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p347. $$ x_{i} : = x_{0} + ih $$\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":689,"permalink":"https://freshrimpsushi.github.io/en/posts/689/","tags":null,"title":"Strong Lipschitz Condition and Error of the Euler Method"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Method 1 $D \\subset \\mathbb{R}^2$ defines a continuous function $f$ for the initial value problem given by $\\begin{cases} y ' = f(x,y) \\\\ y( x_{0} ) = Y_{0} \\end{cases}$. Suppose the interval $(a,b)$ is divided into nodes like $a \\le x_{0} \u0026lt; x_{1} \u0026lt; \\cdots \u0026lt; x_{n} \u0026lt; \\cdots x_{N} \\le b$. Particularly for a sufficiently small $h \u0026gt; 0$, if it is assumed that $x_{j} = x_{0} + j h$, then for the initial value $y_{0} \\simeq Y_{0}$, $$ y_{n+1} = y_{n} + h f ( x_{n} , y_{n} ) $$\nExplanation Euler\u0026rsquo;s method is conceptually a very simple approach but demonstrates core ideas in numerical analysis. Of course, there are many problems associated with it today, but conversely, this means there is much room for improvement. Therefore, it\u0026rsquo;s not so much the Euler method itself that is important, but rather the process of its derivation that needs to be carefully understood.\nDerivation Taylor Expansion If you expand $Y(x_{n+1} )$ up to the $2$ term in relation to $x_{n}$ using Taylor expansion, $$ Y ( x_{n+1} ) = Y ( x_{n} ) + ( x_{n+1} - x_{n}) y ' ( x_{n} ) + {{( x_{n+1} - x_{n})^2} \\over {2}} Y\u0026rsquo;\u0026rsquo; ( \\xi_{n} ) $$ then simplifying gives $$ Y ( x_{n+1} ) = Y ( x_{n} ) + h y ' ( x_{n} ) + {{h^2} \\over {2}} Y\u0026rsquo;\u0026rsquo; ( \\xi_{n} ) $$ Now, discarding the error term $\\displaystyle {{h^2} \\over {2}} Y\u0026rsquo;\u0026rsquo; ( \\xi_{n} )$, $$ y_{n+1} = y_{n} + h f ( x_{n} , y_{n} ) $$\n‚ñ†\nWhat is immediately clear from the derivation using Taylor expansion is that as $h$ decreases, so does the error. Moreover, there‚Äôs no particular reason why the Taylor approximation must be exactly up to the $2$ term, which implies that increasing the order will reduce the error.\nNumerical Integration The definite integral of $[x_{n} , x_{n+1}]$ to $Y\u0026rsquo;(t) = f (t, Y(t))$ is $$ \\int_{x_{n}}^{x_{n+1}} f(t,Y(t)) dt = Y(x_{n+1}) - Y(x_{n}) $$ Although there is a slight error, through numerical integration, since $\\displaystyle \\int_{x_{n}}^{x_{n+1}} f(t,Y(t)) dt \\simeq h f(x_{n} , Y(x_{n}) ) $, $$ y_{n+1} - y_{n} = h f ( x_{n} , y_{n} ) $$\n‚ñ†\nConsidering the idea of the method of rectangles, it can be inferred that the error decreases as $h$ becomes smaller. As seen in the figure, there is a significant difference between the actual integral value and the numerically calculated value, but using the trapezoidal method or Simpson\u0026rsquo;s method would reduce the error.\nImplementation Below is code written in R.\nEuler\u0026lt;-function(f,Y\\_0,a,b,h=10^(-3))\r{\rY \u0026lt;- t(Y\\_0)\rnode \u0026lt;- seq(a,b,by=h)\rfor(x in node)\r{\rY\u0026lt;-rbind(Y,Y[length(Y[,1]),]+h*f(x,Y[length(Y[,1]),]))\r}\rreturn(Y)\r}\rf\u0026lt;-function(x,y) {y}\rout\u0026lt;-Euler(f,seq(1,1,len=100),0,2)\rout[,1]\rg\u0026lt;-function(x,y) {1/(1+x^2) + - 2*(y^(2))}\rout\u0026lt;-Euler(g,seq(0,0,len=100),0,2,h=0.2)\rout[,1] Atkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p341.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":687,"permalink":"https://freshrimpsushi.github.io/en/posts/687/","tags":null,"title":"Euler Method in Numerical Analysis"},{"categories":"Ï†ïÏàòÎ°†","contents":"Algorithm 1 Given a semiprime $N$, if $p$ is a smooth prime, then the factorization $N = pq$ of $N$ can be found as follows:\nStep 1.\n$a := 2$ and $L := 1$ are set.\nStep 2.\n$d := \\gcd ( a^{L} - 1 , N )$ is calculated.\nStep 3.\nIf $1\u0026lt; d \u0026lt; N$, then $d = p$, a divisor of $N$, is found and we are done. Otherwise, it is updated as $L := (L+1)!$. If $L$ becomes too large, revert to $L := 1$ and update it as $a : = a+ 1$. Then return to Step 2.\nExplanation The Pollard $p-1$ factorization algorithm exploits the weakness of smooth primes similar to the Pollig-Hellman algorithm. A single prime number becoming a weakness makes the prime factorization problem easily solvable. Because of this attack method, cryptographic systems that rely on the difficulty of the prime factorization problem cannot use smooth primes as their secret keys.\nPrincipally, it is not necessary to start with $a=2$ as in Step 1 or to use $L = n!$ as in Step 2. It\u0026rsquo;s simply used because, if $p$ is smooth, then there is a high probability of successfully calculating $d := \\gcd ( a^{L} - 1 , N )$.\nProof $$ (p-1) \\mid L \\\\ (q-1) \\nmid L $$ Assuming $p$ is smooth, it is easy to satisfy the condition for $L = n!$. This means for some $i,j \\in \\mathbb{Z}$ and $k \\in \\mathbb{N}$, the following holds. $$ \\begin{align*} L =\u0026amp; i ( p -1 ) \\\\ L =\u0026amp; j ( q -1 ) + k \\end{align*} $$\nFermat\u0026rsquo;s Little Theorem: For a prime $p$ and an integer $a$ coprime to $p$, $a^{p-1} \\equiv 1 \\pmod{p}$\nIn $\\pmod{p}$, $$ \\begin{align*} a^{L} \u0026amp; \\equiv a^{( p - 1 ) i } \\\\ \u0026amp; \\equiv 1^{i} \\\\ \u0026amp; \\equiv 1 \\pmod{p} \\end{align*} $$ In $\\pmod{q}$, $$ \\begin{align*} a^{L} \u0026amp; \\equiv a^{( q - 1 ) j + k } \\\\ \u0026amp; \\equiv 1^{j} a^{k} \\\\ \u0026amp; \\equiv a^{k} \\pmod{q} \\end{align*} $$ Here, since $k \\ne 0$, there is a high probability that $a^{k} \\ne 1 \\pmod{q}$. This means $$ p \\mid a^{L} -1 $$\n$$ q \\nmid a^{L} -1 $$ This implies that $p$ is a divisor of $a^{L} -1$, and since $p$ is also a divisor of $N$, calculating the greatest common divisor of the two numbers results in $$ p = \\gcd \\left( a^{L} - 1 , N \\right) $$\n‚ñ†\nSee Also Prime Factorization Security Algorithms Utilizing the Difficulty of Prime Factorization Problem RSA Public Key Cryptosystem Goldwasser-Micali Probabilistic Key Cryptosystem Attack Algorithms on the Prime Factorization Problem Pollard\u0026rsquo;s p-1 Factorization Algorithm Conditions Under Which the Prime Factorization of Semiprimes Becomes Easy Hoffstein. (2008). An Introduction to Mathematical Cryptography: p133~135.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1187,"permalink":"https://freshrimpsushi.github.io/en/posts/1187/","tags":null,"title":"Proof of the Pollard p-1 Factoring Algorithm"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition The differential equation below is called the $\\nu$th order Bessel\u0026rsquo;s equation.\n$$ \\begin{align*} x^2 y^{\\prime \\prime} +xy^{\\prime} +(x^2-\\nu^2)y =\u0026amp;\\ 0 \\\\ x(xy^{\\prime})^{\\prime} + (x^2- \\nu ^2) y =\u0026amp;\\ 0 \\\\ y^{\\prime \\prime}+\\frac{1}{x} y^{\\prime} + \\left( 1-\\frac{\\nu^{2}}{x^{2}} \\right)y =\u0026amp;\\ 0 \\end{align*} $$\nDescription The solution to the Bessel\u0026rsquo;s equation is called the Bessel function.\nBessel functions are often seen in physics, engineering, and more, especially in problems involving cylindrical symmetry. For this reason, Bessel functions are also known as cylinder functions, though this term is less commonly used.\nDerivation In two-dimensional polar coordinates, the wave equation is given as follows.\n$$ \\begin{equation} \\dfrac{\\partial ^2 u}{\\partial t^2} = c^2 \\left( \\dfrac{\\partial ^2 u}{\\partial r^2}+\\frac{1}{r}\\dfrac{\\partial u}{\\partial r}+\\frac{1}{r^2} \\dfrac{\\partial ^2 u}{\\partial \\theta ^2}\\right) \\end{equation} $$\n$c$ is a constant. Let\u0026rsquo;s assume that the solution $u$ to the above equation is a function that can be separated into variables.\n$$ u(t, r, \\theta)=T(t)R(r)\\Theta (\\theta) $$\nSubstituting $(1)$ gives\n$$ T^{\\prime \\prime}R\\Theta=c^2\\left( TR^{\\prime \\prime}\\Theta + \\dfrac{1}{r}TR^{\\prime}\\Theta + \\frac{1}{r^2}TR\\Theta^{\\prime \\prime} \\right) $$\nDividing both sides by $c^2TR\\Theta$ gives\n$$ \\dfrac{T^{\\prime \\prime}}{c^2T}=\\dfrac{R^{\\prime \\prime}}{R}+\\dfrac{R^{\\prime}}{rR}+\\dfrac{\\Theta^{\\prime \\prime}}{r^2\\Theta} $$\nThe left-hand side is a function solely of $t$, and the right-hand side is a function of $r$ and $\\theta$, thus both sides of the equation must be constant. If the left-hand side were not constant with respect to $t$, changing the value of $t$ would change the left-hand side without altering the right, breaking the equality. Therefore, for all $t$, $r$, and $\\theta$, both sides must be constant. Let\u0026rsquo;s call this constant $-\\mu ^2$. Then,\n$$ \\begin{equation} \\dfrac{T^{\\prime \\prime}}{c^2T}=\\dfrac{R^{\\prime \\prime}}{R}+\\dfrac{R^{\\prime}}{rR}+\\dfrac{\\Theta^{\\prime \\prime}}{r^2\\Theta}=-\\mu^2 \\end{equation} $$\nFirst, let\u0026rsquo;s examine the equation for $r$ and $\\theta$.\n$$ \\dfrac{R^{\\prime \\prime}}{R}+\\dfrac{R^{\\prime}}{rR}+\\dfrac{\\Theta^{\\prime \\prime}}{r^2\\Theta}=-\\mu^2 $$\nMultiply both sides by $r^2$ and separate the equation into terms for $r$ and $\\theta$,\n$$ \\dfrac{r^2R^{\\prime \\prime}}{R}+\\dfrac{rR^{\\prime}}{R}+r^2\\mu^2=-\\dfrac{\\Theta^{\\prime \\prime}}{\\Theta} $$\nBoth sides of the equation, for reasons mentioned earlier, must also be constant. Let\u0026rsquo;s call this constant $\\nu^2$. Then, we get the following equation.\n$$ \\begin{equation} -\\dfrac{\\Theta^{\\prime \\prime}}{\\Theta}=\\nu^2 \\quad \\implies \\quad \\Theta^{\\prime \\prime} =-\\nu^2 \\Theta \\quad \\end{equation} $$\nReturning to $(2)$ and organizing the equation for $t$ yields\n$$ \\begin{equation} T^{\\prime \\prime}=-c^2\\mu^2T \\end{equation} $$\nSubstituting $(3)$ and $(4)$ into $(2)$ and organizing appropriately gives the following.\n$$ \\begin{align*} \u0026amp;\u0026amp;\\dfrac{-c^2 \\mu^2 T}{c^2T}=\\dfrac{R^{\\prime \\prime}}{R}+\\frac{R^{\\prime}}{rR}+\\dfrac{-\\nu^2\\Theta}{r^2\\Theta} \\\\ \\implies \u0026amp;\u0026amp;\\frac{1}{R}R^{\\prime \\prime}+\\dfrac{1}{rR}R^{\\prime}+\\left(\\mu^2-\\frac{\\nu^2}{r^2}\\right) =0 \\\\ \\implies \u0026amp;\u0026amp; r^2R^{\\prime \\prime}(r)+rR^{\\prime}(r)+(\\mu^2r^2-\\nu^2)R(r)=0 \\end{align*} $$\nNow, let\u0026rsquo;s introduce a substitution $\\mu r=x$. And then let it be as follows.\n$$ R(r)=f(\\mu r)=f(x),\\quad R^{\\prime}(r)=\\mu f^{\\prime}(\\mu r)=\\mu f^{\\prime}(x),\\quad R^{\\prime \\prime}(r)=\\mu^2 f^{\\prime \\prime}(\\mu r)=\\mu^2 f^{\\prime \\prime}(x) $$\nSubstituting these equations into the ones we obtained earlier gives\n$$ \\begin{align*} \u0026amp;\u0026amp; \\frac{x^2}{\\mu^2}\\mu^2f^{\\prime \\prime}(x) + \\dfrac{x}{\\mu}\\mu f(x)+(x^2-\\nu^2)f(x)=\u0026amp;\\0 \\\\ \\implies \u0026amp;\u0026amp; x^2f^{\\prime \\prime}(x) + x f(x)+(x^2-\\nu^2)f(x)=\u0026amp;\\0 \\end{align*} $$\nThe above equation is known as the $\\nu$th order Bessel\u0026rsquo;s equation. It is commonly found in the following form.\n$$ \\begin{align*} x^2 y^{\\prime \\prime} +xy^{\\prime} +(x^2-\\nu^2)y=\u0026amp;\\0 \\\\ x(xy^{\\prime})^{\\prime}+(x^2 \\nu ^2) y=\u0026amp;\\0 \\end{align*} $$\nThe first solution to this equation is as follows, and it is called the first kind Bessel function.\n$$ J_{\\nu}(x)=\\sum \\limits_{n=0}^{\\infty}\\frac{(-1)^{n}}{\\Gamma (n+1)\\Gamma (n+\\nu+1)} \\left( \\frac{x}{2} \\right)^{2n+\\nu} $$\nThe second solution is as follows, and it is called the second kind Bessel function.‚Äã‚Äã‚Äã\n$$ N_{\\nu}(x)=Y_{\\nu}(x)=\\frac{\\cos (\\nu \\pi)J_{\\nu}(x)-J_{-\\nu}(x)}{\\sin (\\nu\\pi)} $$\nTherefore, the general solution to the Bessel\u0026rsquo;s equation is as follows.\n$$ y(x)=AJ_{\\nu}(x)+BN_{\\nu}(x) $$\nIn this case, $A$ and $B$ are constants.\n","id":1195,"permalink":"https://freshrimpsushi.github.io/en/posts/1195/","tags":null,"title":"Derivation of Bessel's Equation"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definitions1 2 $\\mathbb{N}$ represents the set of natural numbers, and $\\mathbb{R}$ represents the set of real numbers.\nA function with a domain of $\\mathbb{N}$ is called a sequence.\nFor a sequence of natural numbers $\\left\\{ n_{k} \\right\\}_{ k \\in \\mathbb{N}}$, $\\left\\{ x_{n_{k}} \\right\\}_{ k \\in \\mathbb{N}}$ is called a subsequence of $\\left\\{ x_{n} \\right\\}_{ n \\in \\mathbb{N}}$.\nIf for every $x \\in \\left\\{ x_{n} \\right\\}_{ n \\in \\mathbb{N}}$ there exists $M \\in \\mathbb{R}$ such that $x \\le M$ is satisfied, then $\\left\\{ x_{n} \\right\\}_{ n \\in \\mathbb{N}}$ is bounded above, and if there exists $m \\in \\mathbb{R}$ such that $m \\le x$ is satisfied, then it is bounded below; if it is bounded above and below, it is simply bounded.\nLet\u0026rsquo;s say $\\left\\{ x_{n } \\right\\}_{n = 1}^{\\infty}$ is a sequence of real numbers. If for every $\\varepsilon \u0026gt; 0$ there exists $N \\in \\mathbb{N}$ such that $$n \\ge N \\implies | x_{n} - a | \u0026lt; \\varepsilon$$ is satisfied, then $\\left\\{ x_{n } \\right\\}$ is said to converge to $a \\in \\mathbb{R}$, denoted $\\lim \\limits_{n\\to \\ \\infty}x_{n}=a$.\nIf $\\left\\{ x_{n } \\right\\}$ does not converge, it is said to diverge.\nIf for every $M \\in \\mathbb{R}$ there exists $N \\in \\mathbb{N}$ such that $n \\ge N \\implies x_{n} \u0026gt; M$ is satisfied, $$ \\lim \\limits_{n\\to \\infty} x_{n} = +\\infty \\quad \\text{ or } \\quad x_{n} \\to +\\infty $$ is denoted.\nIf for every $M \\in \\mathbb{R}$ there exists $N \\in \\mathbb{N}$ such that $n \\ge N \\implies x_{n} \u0026lt; M$ is satisfied, $$ \\lim \\limits_{n\\to \\infty} x_{n} = -\\infty \\quad \\text{ or } \\quad x_{n} \\to -\\infty $$ is denoted.\nExplanation When you first encounter the definitions of convergence and divergence in university, it seems like an arrow going nowhere with confusing terms such as $\\varepsilon$, $M$, and $N$ popping up. Honestly, you might not want to learn it. From the perspective of an undergrad, not knowing this new definition of limits doesn\u0026rsquo;t mean they don\u0026rsquo;t understand the concept of limits at all, especially because it feels like if they can just somehow get through the midterms, they\u0026rsquo;ll never have to deal with it again. Of course, this is a foolish thought.\nLooking back at high school, teachers did use phrases like \u0026ldquo;grows infinitely large\u0026rdquo; or \u0026ldquo;sent to infinity\u0026rdquo; when talking about $n \\to \\infty$, but somehow, they seemed overly cautious about treating sequences as \u0026ldquo;something moving\u0026rdquo;. It\u0026rsquo;s because they are educated people.\nThe reason for using strict definitions instead of intuition is that strict definitions are, in fact, easier. While intuition works quickly for \u0026lsquo;simple sequences\u0026rsquo; that might appear in the SATs, there\u0026rsquo;s a deficiency when dealing with \u0026lsquo;complex sequences\u0026rsquo;, which is why strict definitions were introduced. Historically, despite British mathematics significantly outpacing continental mathematics since Newton, the insistence on intuitionism led to the loss of academic dominance to the continent.\nThe biggest stumbling block in learning about sequence convergence isn\u0026rsquo;t the inherent difficulty but the annoyance from \u0026lsquo;having to\u0026rsquo; \u0026lsquo;complicatedly\u0026rsquo; \u0026rsquo;re-learn\u0026rsquo; something that seems easily approachable. For instance, taking an unnecessarily roundabout way to solve an easy problem like $\\displaystyle \\lim_{n \\to \\infty} {{n + 3} \\over {2n}} = {{1} \\over {2}}$ feels this way.\nThe problem is not so much that learning is difficult, but rather not wanting to learn, and unfortunately, teaching sequences worth the difficulty of understanding to students who struggle with it is a very difficult task. To aid in understanding and empathy, the following two theorems are introduced.\nTheorems Let $\\left\\{ w_{n} \\right\\}, \\left\\{ x_{n} \\right\\}, \\left\\{ y_{n} \\right\\}$ be a sequence of real numbers, and let\u0026rsquo;s say it is $a \\in \\mathbb{R}$.\n(a) The Sandwich Theorem:\n$$ \\displaystyle \\lim_{n \\to \\infty} x_{n} = \\lim_{n \\to \\infty} y_{n} = a $$\nIf this holds and\n$$ n \\ge N_{0} \\implies x_{n} \\le w_{n} \\le y_{n} $$\na $N_{0} \\in \\mathbb{N}$ exists that satisfies\n$$ \\displaystyle \\lim_{n \\to \\infty} w_{n} = a $$\n(b) The Comparison Theorem:\n$$ n \\ge N_{0} \\implies x_{n} \\le y_{n} $$\nIf a $N_{0} \\in \\mathbb{N}$ exists that satisfies\n$$ \\displaystyle \\lim_{n \\to \\infty} x_{n} \\le \\lim_{n \\to \\infty} y_{n} $$\nOf course, both the Sandwich Theorem and the Comparison Theorem seem to obviously hold from an intuitive standpoint. They aren\u0026rsquo;t particularly hard facts. But how exactly will you, who resists the new definitions of convergence, prove these facts?\nWhile these two theorems were confidently used without proof even at the high school level, they were actually hypotheses accepted through common-sense guessing rather than logical deduction. Considering how often human common sense is wrong, the need for strict proof becomes understandable, at least for STEM students.\nFollowing the definitions of convergence, the proofs of these theorems are not difficult, but assuming this is the reader\u0026rsquo;s first encounter with such reasoning, they are shown in as much detail as possible. Reading the proofs, one might consistently feel that there\u0026rsquo;s an obsession with the existence of $N$, and indeed there is. When demonstrating convergence, it\u0026rsquo;s not crucial to establish an inequality where $| x_{n} - a |$ becomes smaller than $\\varepsilon$; showing the existence of $N$ satisfying the equation is the priority.\nTo put it bluntly, when demonstrating the convergence of a sequence, how $\\varepsilon$ was found does not matter. According to the definition, as long as $N$ exists, the sequence converges, so one should first focus on the existence of $N$. Failing to understand this leads to ignoring given $N_{1}$ and $N_{2}$ in the problem and laying out plausible inequalities only to present a logically collapsed argument.\nProofs (a) Strategy: Rather than vaguely sending to infinity, it specifically demonstrates the existence of $N$ meeting $n \\ge N \\implies| w_{n} - a | \u0026lt; \\varepsilon$ by breaking down inequality.\nLet\u0026rsquo;s assume $\\varepsilon \u0026gt; 0$.\nGiven $\\displaystyle \\lim_{n \\to \\infty} x_{n} = \\lim_{n \\to \\infty} y_{n} = a$, therefore\n$$ n \\ge N_{1} \\implies | x_{n} - a | \u0026lt; \\varepsilon $$\n$$ n \\ge N_{2} \\implies | y_{n} - a | \u0026lt; \\varepsilon $$\na $N_{1} , N_{2} \\in \\mathbb{N}$ exists satisfying these. Summarizing the necessary parts,\n$$ n \\ge N_{1} \\implies a - \\varepsilon \u0026lt; x_{n} $$\n$$ n \\ge N_{2} \\implies y_{n} \u0026lt; a + \\varepsilon $$\nMeanwhile, assuming a $N_{0} \\in \\mathbb{N}$ exists that satisfies $n \\ge N_{0} \\implies x_{n} \\le w_{n} \\le y_{n}$, and organizing neatly,\n$$ n \\ge N_{1} \\implies a - \\varepsilon \u0026lt; x_{n} $$\n$$ n \\ge N_{0} \\implies x_{n} \\le w_{n} \\le y_{n} $$\n$$ n \\ge N_{2} \\implies y_{n} \u0026lt; a + \\varepsilon $$\nThe existence of $N_{0}$, $N_{1}$, and $N_{2}$ already assures us that an $N := \\max \\left\\{ N_{0} , N_{1} , N_{2} \\right\\}$ exists. Then, for such $N$ when $n \\ge N$,\n$$ a - \\varepsilon \u0026lt; x_{n} \\le w_{n} \\le y_{n} \u0026lt; a + \\varepsilon $$\nIn other words, for the previously proven existing $N$,\n$$ n \\ge N \\implies | w_{n} - a | \u0026lt; \\varepsilon $$ According to the definition of convergence, we obtain $\\displaystyle \\lim_{n \\to \\infty} w_{n} = a$.\n‚ñ†\n(b) Strategy: The outcome is negated and shown not to satisfy the inequality. This logical progression is difficult to use when perceiving sequences as \u0026ldquo;something moving.\u0026rdquo; Rather, it\u0026rsquo;s better to imagine catching an infinitely growing $n$ and fixing it to use mathematical skill.\n$$ x := \\lim_{n \\to \\infty} x_{n} $$\n$$ y := \\lim_{n \\to \\infty} y_{n} $$\nAssuming $x \u0026gt; y$, meaning\n$$ n \\ge N_{1} \\implies | x_{n} - x | \u0026lt; \\varepsilon $$\n$$ n \\ge N_{2} \\implies | y_{n} - y | \u0026lt; \\varepsilon $$\nThere are natural numbers $N_{1}$, $N_{2}$ existing that satisfy these, and expanding the absolute value,\n$$ n \\ge N_{3} \\implies \\begin{cases} - \\varepsilon + x\u0026lt; x_{n} \\\\ y_{n} \u0026lt; y + \\varepsilon \\end{cases} $$\n$$ N_{3} \u0026gt; N_{0} $$\na $N_{3} : = \\max \\left\\{ N_{0} +1 , N_{1} , N_{2} \\right\\}$ also exists. Now assuming $\\displaystyle \\varepsilon := {{ x - y} \\over {2}}$ means $\\varepsilon \u0026gt; 0$, and by assumption for all $n \\ge N_{3}$,\n$$ \\begin{align*} y_{n} \u0026lt;\u0026amp; y + \\varepsilon \\\\ =\u0026amp; y + \\left( {{x - y} \\over {2}} \\right) \\\\ =\u0026amp; x - \\left( {{x - y} \\over {2}} \\right) \\\\ =\u0026amp; x - \\varepsilon \\\\ \u0026lt;\u0026amp; x_{n} \\end{align*} $$\nHowever, since $N_{3} \u0026gt; N_{0}$, a contradiction arises with $n \\ge N_{0} \\implies x_{n} \\le y_{n}$. Therefore, we get $x \\le y$.\n‚ñ†\nSee also Why the definition of sequence convergence is complex William R. Wade, An Introduction to Analysis (4th Edition, 2010), Chapter 2.1-2.2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWalter Rudin, Principles of Mathematical Analysis (3rd Edition, 1976), Chapter 3.1-3.4\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1184,"permalink":"https://freshrimpsushi.github.io/en/posts/1184/","tags":null,"title":"Redefining the Limits of Sequences in University Mathematics"},{"categories":"Ï†ïÏàòÎ°†","contents":"Buildup Let\u0026rsquo;s call them Alice, Bob, and Eve from left to right. Alice and Bob are the parties exchanging messages, and Eve is a passive attacker interested in the message. The orange box represents information only known by Alice, the sky blue box is information only known by Bob, and the black box represents information that is public (also known by Eve).\nAlice has a message $m \\in \\mathbb{N}$ she needs to receive from Bob.\nAlgorithm 1 Key Setup: Alice selects and publishes a large prime number\u0026rsquo;s product $N=pq$ which satisfies $\\gcd \\left( e , (p-1)(q-1) \\right) = 1$ and $e$.\nEncryption: Bob computes $c \\equiv m^{e} \\pmod{N}$ and makes it public.\nDecryption: Alice finds $d$ that satisfies $de \\equiv 1 \\pmod{(p-1)(q-1)}$ and calculates $x \\equiv c^{d} \\equiv m \\pmod{N}$ to obtain $x=m$. Eve realistically cannot know $d$, therefore she cannot know $m$.\nDescription The RSA Public Key Cryptosystem was developed by Ronald Rivest, Adi Shamir, and Leonard Adleman and is abbreviated as RSA, named after the first letters of their last names. The three were awarded the Turing Award in 2002 for this achievement.\nIt is based not only on the difficulty of the discrete logarithm problem like the ElGamal Public Key Cryptosystem but also on the difficulty of the prime factorization problem, making it worthwhile to find large primes just for its robustness. Moreover, it is a system that is fun to study because it\u0026rsquo;s not just theoretical or outdated but is actually used worldwide today. A potentially fatal attack method is the Shor\u0026rsquo;s Algorithm, based on quantum computers, but the commercialization of quantum computers is far off, so it will remain active for the foreseeable future.\nProof Decryption Alice knows the prime factorization $N = pq$ of $N$, so she can find $e$ that satisfies $\\gcd \\left( e , (p-1)(q-1) \\right) = 1$.\nExtended Euclidean Theorem: For two integers $a,b$, there always exists an integer solution to $aX + bY = \\gcd (a,b)$.\nFor two integers $e$, $(p-1)(q-1)$, $$ e X + (p-1)(q-1) Y = 1 $$ there exists an integer solution $\\begin{cases} X=d \\\\ Y = - k \\end{cases}$, which means $$ de = 1 + k (p-1)(q-1) $$ In other words, $d$, i.e., the inverse of $e$ in the ring $\\mathbb{Z}_{(p-1)(q-1)}$, and since Alice knows $p$, $q$, she can easily find $d$. [ NOTE: The existence of a multiplicative inverse in a ring is not at all trivial, which highlights the necessity of condition $\\gcd \\left( e , (p-1)(q-1) \\right) = 1$. ]\nEuler\u0026rsquo;s Totient Theorem: $$ \\gcd(a,m) = 1 \\implies a^{ \\phi (m) } \\equiv 1 \\pmod{m} $$\nSince $\\gcd \\left( e , (p-1)(q-1) \\right) = 1$, the inverse of $e$, $d$, is found as follows: $$ d = e^{-1} = e^{\\phi \\left( (p-1)(q-1) \\right) -1} $$ It simply involves exponentiation of $e$, so it can be easily and quickly calculated using the exponentiation by squaring method. Let\u0026rsquo;s consider the case where $\\gcd ( c , pq ) = 1$ is satisfied and the case where it is not.\nCase 1. $\\gcd ( c , pq ) = 1$\nIt reduces to a problem of finding a modular square root of congruence equations.\nMultiplicative property of the Totient function: $$ \\gcd (p , q) =1 \\implies \\phi ( p q ) = \\phi (p) \\phi (q) $$\n$\\phi (p) = p-1$ and $\\phi (q) = q-1$ so $$ \\phi (pq) = \\phi (p) \\phi (q) = (p-1)(q-1) $$\nEuler\u0026rsquo;s Totient Theorem: $$ \\gcd(c,N) = 1 \\implies c^{ \\phi (N) } \\equiv 1 \\pmod{N} $$\n$c^{(p-1)(q-1)} = c^{ \\phi (pq ) }$ so $$ \\begin{align*} \\left( c^{d} \\right)^{e} \u0026amp; \\equiv c^{de} \\\\ \u0026amp; \\equiv c^{1 + k (p-1)(q-1)} \\\\ \u0026amp; \\equiv c \\cdot \\left( c^{(p-1)(q-1)} \\right)^{k} \\\\ \u0026amp; \\equiv c \\cdot 1^{k} \\\\ \u0026amp; \\equiv c \\pmod{pq} \\end{align*} $$\nCase 2. $\\gcd ( c , pq ) \\ne 1$\n$$ C \\equiv c^{(p-1)(q-1)} \\pmod{pq} $$ If $c$ is a multiple of $pq$ then $x^{e} \\equiv 0$, therefore $x = 0$ is necessary and meaningless. Hence, assume that $c$ is a multiple of either $p$ or $q$, but it doesn\u0026rsquo;t matter which one, so let\u0026rsquo;s assume it\u0026rsquo;s a multiple of $q$. Then, for some $n_{0} \\in \\mathbb{Z}$ and $p$ not a multiple of some $K \\in \\mathbb{Z}$, $$ \\begin{align*} C =\u0026amp; c^{(p-1)(q-1)} + (pq) \\cdot n_{0} \\\\ =\u0026amp; \\left[ qK \\right]^{(p-1)(q-1)} + p \\cdot q n_{0} \\end{align*} $$ there exists $q n_{0}$ satisfying the above equation, so $$ c^{(p-1)(q-1)} \\equiv \\left[ (qK)^{q-1} \\right]^{p-1} \\pmod{p} $$\nPart 1. $\\left( c^{d} \\right)^{e} \\equiv c \\pmod{p}$\nFermat\u0026rsquo;s Little Theorem: For a prime $p$ and an integer $a$ relatively prime to $p$, $a^{p-1} \\equiv 1 \\pmod{p}$\nSince $K$ is not a multiple of $p$, $\\left[ (qK)^{q-1} \\right]$ is relatively prime to $p$, $$ \\begin{align*} \\left( c^{d} \\right)^{e} \u0026amp; \\equiv c^{de} \\\\ \u0026amp; \\equiv c^{1 + k (p-1)(q-1)} \\\\ \u0026amp; \\equiv c \\cdot \\left[ (qK)^{k(q-1)} \\right]^{p-1} \\\\ \u0026amp; \\equiv c \\cdot 1 \\pmod{p} \\end{align*} $$\nPart 2. $\\left( c^{d} \\right)^{e} \\equiv c \\pmod{q}$\n$$ \\begin{align*} \\left( c^{d} \\right)^{e} \u0026amp; \\equiv c^{de} \\\\ \u0026amp; \\equiv \\left[ qK \\right]^{de} \\\\ \u0026amp; \\equiv 0 \\\\ \u0026amp; \\equiv qK \\\\ \u0026amp; \\equiv c \\pmod{q} \\end{align*} $$\nPart 3. $\\left( c^{d} \\right)^{e} \\equiv c \\pmod{pq}$\nMultiplication of Modulos: If $\\gcd ( m_{1} , m_{2} ) = 1$ then $\\begin{cases} a \\equiv b \\pmod{ m_{1} } \\\\ a = b \\pmod{ m_{2} } \\end{cases} \\implies a \\equiv b \\pmod{ m_{1} m_{2} }$\nFrom Part 1, 2, $\\begin{cases} \\left( c^{d} \\right)^{e} \\equiv c \\pmod{p} \\\\ \\left( c^{d} \\right)^{e} \\equiv c \\pmod{q} \\end{cases}$ is obtained, so we get: $$ \\left( c^{d} \\right)^{e} \\equiv c \\pmod{pq} $$\nTherefore, $x=c^{d}$ exists as a solution to $x^{e} \\equiv c \\pmod{pq}$ under any circumstances. Also, another solution $u$, if it exists, can easily be shown to always appear as $u \\equiv c^{d} \\pmod{pq}$.\n‚ñ†\nEncryption Eve knows $e$, but to find the inverse $d$, she must solve the prime factorization problem $N=pq$. Since this is very difficult, Bob can securely transmit the message $m$ to Alice.\n‚ñ†\nSee Also Prime Factorization Security Algorithms Utilizing the Difficulty of Prime Factorization Problem RSA Public Key Cryptosystem Goldwasser-Micali Probabilistic Key Cryptosystem Attack Algorithms on the Prime Factorization Problem Pollard\u0026rsquo;s p-1 Prime Factorization Algorithm Conditions under Which the Prime Factorization Problem for Semiprimes Is Easily Solved Hoffstein. (2008). An Introduction to Mathematical Cryptography: p115~122.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1173,"permalink":"https://freshrimpsushi.github.io/en/posts/1173/","tags":null,"title":"Proof of the RSA Public Key Cryptosystem"},{"categories":"Îß§Ìä∏Îû©","contents":"Method When labeling graphs in MATLAB to indicate what each axis represents, you can use xlabel and ylabel. It\u0026rsquo;s also possible to use special symbols, bold, and italic styles.\nx=-3*pi:0.2:3* pi;\ry=sin(x-pi/6);\rplot(x,y);\rxlabel(\u0026#39;\\beta\u0026#39;), ylabel(\u0026#39;\\nabla f(x)\u0026#39;),; x=-3*pi:0.2:3* pi;\ry=sin(x-pi/6);\rplot(x,y);\rxlabel(\u0026#39;ÏßÑÌè≠{\\bf Volt}\u0026#39;), ylabel(\u0026#39;ÏãúÍ∞Ñ{\\it sec}{\\sl sec}{\\rm sec}\u0026#39;); Symbol Code Name Symbol Code Name Symbol Code Name $\\alpha$ \\alpha Alpha $\\beta$ \\beta Beta $\\gamma$ \\gamma Gamma $\\delta$ \\delta Delta $\\epsilon$ \\epsilon Epsilon $\\zeta$ \\zeta Zeta $\\eta$ \\eta Eta $\\theta$ \\theta Theta $\\vartheta$ \\vartheta Vartheta $\\iota$ \\iota Iota $\\kappa$ \\kappa Kappa $\\lambda$ \\lambda Lambda $\\mu$ \\mu Mu $\\nu$ \\nu Nu $\\xi$ \\xi Xi $\\pi$ \\pi Pi $\\rho$ \\rho Rho $\\sigma$ \\sigma Sigma $\\varsigma$ \\varsigma Varsigma $\\tau$ \\tau Tau $\\upsilon$ \\upsilon Upsilon $\\phi$ \\phi Phi $\\chi$ \\chi Chi $\\psi$ \\psi Psi $\\omega$ \\omega Omega $\\Gamma$ \\Gamma Capital Gamma $\\Delta$ \\Delta Capital Delta $\\Theta$ \\Theta Capital Theta $\\Lambda$ \\Lambda $ ÎåÄÎ¨∏Ïûê ÎûåÎã§ $ \\Xi $ \\Pi $ \\Pi ÎåÄÎ¨∏Ïûê ÌååÏù¥ $ \\Sigma $ \\Sigma $ \\Phi $ \\Phi ÎåÄÎ¨∏Ïûê Ìîº $ \\Psi $ \\Psi $ \\forall $ \\forall $ \\exists $ \\exsits $ \\surd $ \\surd $ \\cong $ \\cong $ \\equiv $ \\equiv $ \\Re $ \\Re $ \\otimes $ \\otimes $ \\oplus $ \\oplus $ \\cap $ \\cap $ \\subset $ \\subset $ \\subseteq $ \\subseteq $ \\supseteq $ \\supseteq $ \\rceil $ \\rceil $ \\lfloor $ \\lfloor $ \\displaystyle \\int $ \\int $ \\perp $ \\perp $ \\vee $ \\vee $ \\langle $ \\langle $ \\neg $ \\neg $ \\sim $ \\sim $ \\times $ \\times $ \\leq $ \\leq $ \\propto $ \\propto $ \\neq $ \\neq $ \\infty $ \\infty $ \\clubsuit $ \\clubsuit $ \\heartsuit $ \\heartsuit $ \\spadesuit $ \\spadesuit $ \\leftrightarrow $ \\leftrightarrow $ \\uparrow $ \\uparrow $ \\rightarrow $ \\rightarrow $ \\leftarrow $ \\leftarrow $ \\partial $ \\partial $ \\div $ \\div $ \\wp $ \\wp $ \\oslash $ \\oslash $ \\ldots $ \\ldots $ \\prime $ \\prime ","id":1191,"permalink":"https://freshrimpsushi.github.io/en/posts/1191/","tags":null,"title":"List of Special Symbols Available for Graphs in MATLAB"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition For a given natural number $N$, finding prime numbers $p_{1} , \\cdots , p_{n}$ and natural numbers $r_{1} , \\cdots , r_{n}$ that satisfy $N = p_{1}^{r_{1}} \\cdots p_{n}^{r_{n}}$ is called prime factorization.\n","id":775,"permalink":"https://freshrimpsushi.github.io/en/posts/775/","tags":null,"title":"Prime Factorization"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Definition We can find the Lipschitz condition in the statement of Existence-Uniqueness Theorem for First Order Differential Equations.\nFor a continuous function defined in $D \\subset \\mathbb{R}^2$ with an initial value problem given by $\\begin{cases} y ' = f(x,y) \\\\ y( x_{0} ) = Y_{0} \\end{cases}$, if $f$ satisfies the Lipschitz condition for all $(x,y_{1}) , (x , y_{2} ) \\in D$ and $K \u0026gt; 0$, $$ |f(x,y_{1} ) - f(x,y_{2}) | \\le K | y_{1} - y_{2} | $$ then there exists a unique solution $Y(x)$ in an appropriate interval $I := [ x_{0} - \\alpha , x_{0} + \\alpha ]$ for $(x_{0} , Y_{0}) \\in D^{\\circ}$.\nExplanation If we translate the Lipschitz condition into a more familiar expression, we can represent it as $$ \\left| { f(x,y_{1} ) - f(x,y_{2}) } \\over { y_{1} - y_{2} } \\right| \\le K $$. Even in the worst-case scenario, $$ K = \\max_{(x,y) \\in D} \\left| {{ \\partial f(x,y) } \\over { \\partial y }} \\right| $$, so the boundedness of the derivative of $f$ becomes a similar condition. This means that there won‚Äôt be a sudden change in the function values, at least for the initial value $( x_{0} , Y_{0} )$, indicating that among them, there are problems that are easy to solve.\nThis condition is necessary to explain the concept of stability. Let\u0026rsquo;s consider a slight variation $\\delta (x)$, $\\epsilon$ added to the initial value problem given in the assumption: $$ \\begin{cases} y ' (x ; \\epsilon) = f(x, Y(x ;\\epsilon ) ) + \\delta (x) \\\\ Y( x_{0} ; \\epsilon ) = Y_{0} + \\epsilon \\end{cases} $$. Though these two problems are mathematically different, if $| \\delta |$ and $ | \\epsilon |$ are sufficiently small and the Lipschitz condition is satisfied, then the following holds.\nFor a continuous function defined in $D \\subset \\mathbb{R}^2$ with an initial value problem given by $\\begin{cases} y ' (x ; \\epsilon) = f(x, Y(x ;\\epsilon ) ) + \\delta (x) \\\\ Y( x_{0} ; \\epsilon ) = Y_{0} + \\epsilon \\end{cases}$, if $f$ satisfies the Lipschitz condition, then there exists a unique solution $Y(x ; \\delta, \\epsilon )$ satisfying $| \\epsilon | \\le \\epsilon_{0}$ and $ | \\delta |_{\\infty}$ in an appropriate interval $I := [ x_{0} - \\alpha , x_{0} + \\alpha ]$ and sufficiently small $\\epsilon_{0} \u0026gt;0$ for $(x_{0} , Y_{0}) \\in D^{\\circ}$.\nThe importance of stability in solving differential equations arises when considering numerical approximations. It would be problematic to have to overhaul the entire model every time a slight numerical change occurs with new data being added continuously. Let‚Äôs take an example to understand what happens when the Lipschitz condition is not satisfied. The solution to the initial value problem $$ \\begin{cases} y ' = 100 y - 101 e^{-x} \\\\ y( 0 ) = 1 \\end{cases} $$ is simply obtained as $y = e^{-x}$. If we change the initial value to $y(0) = 1 + \\epsilon$, the solution becomes $y = e^{-x} + \\epsilon e^{100x}$, and if $| \\epsilon |$ is not considerably small, the error becomes too large. Therefore, the original solution obtained without changing the initial value becomes impractical to use, and in such cases, it is said to be ill-conditioned. Conversely, if for an increasing $x$, $\\displaystyle \\int_{x_{0}}^{x} {{ \\partial f (t, Y(t) ) } \\over {\\partial y }} dt$ is bounded by a small positive number, it is said to be well-conditioned. The set of Lipschitz continuous functions in interval $I$ is also represented as $C^{0,1} ( I )$.\nSee Also Strong Lipschitz Condition $\\implies$ Lipschitz Condition $\\implies$ Local Lipschitz Condition\n","id":684,"permalink":"https://freshrimpsushi.github.io/en/posts/684/","tags":null,"title":"Lipschitz Condition"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Overview Hamilton\u0026rsquo;s principle, functionals, action, and variation are explained here in a way that is as simple as possible. If you have not found a satisfactory explanation elsewhere, it is recommended to read through to the end. This has been written so that even freshmen and sophomores in college can understand it.\nLagrangian Mechanics1 When an object moves from time $t_{1}$ to $t_{2}$, the integral of the Lagrangian over the path of motion is called the actionaction and is denoted as $J$.\n$$ \\begin{equation} J=\\int_{t_{1}}^{t_{2}} L dt \\end{equation} $$\nAmong all possible paths of motion, the action of the actual path of motion is the minimum. The LagrangianLagrangian is defined as the difference between the kinetic energy and potential energy and is commonly denoted as $L$.\n$$ L = T-V $$\nThis is briefly referred to as Hamilton\u0026rsquo;s variational principle or the principle of least action. The reason it is called the principle of least action is because the integral in $(1)$ is called action. Although minimum and extremum are different concepts, let\u0026rsquo;s assume they mean the same thing here. Precisely, it would be correct to say extremum (either maximum or minimum). Based on the Marion textbook, this is probably the first content of Lagrangian mechanics you will learn in the first semester, and according to the Fowles textbook, in the second semester. However, it was very difficult to understand this content by sticking to the textbook alone. New concepts appear without kindly explaining what they are. For example, the Fowles textbook introduces the following equation:\n$$ \\begin{equation} \\delta J =\\delta \\int_{t_{1}}^{t_{2}} L dt = 0 \\end{equation} $$\nAnd the explanation for the newly introduced symbol $\\delta$ is as follows:\n\"$\\delta$ is the variation of the total integral for the extremum.\"\nHow can one understand what $\\delta$ means after reading this? They barely teach what variation is and then proceed with calculations recklessly. It\u0026rsquo;s too slow to read line by line without understanding why the equations hold, making it very difficult to grasp the content. Therefore, the author aims to explain Lagrangian mechanics as kindly as possible for students new to it. First, it is necessary to organize the terms used when describing Hamilton\u0026rsquo;s principle.\nFunctional Many sources refer to the integral in $(2)$ as a functional, but it is normal for physics students to not know what a functional is. You might commonly know a function as something where if you input a real number, you get a real number (or a complex number) as the output.\n$$ f(x)=x^2,\\quad g(x)=e^{2x} $$\nHowever, considering the mathematical definition of a function, there\u0026rsquo;s no need for the input to be a number and for the output to be a number. Since a function is something that gives a corresponding result when something is input, there\u0026rsquo;s no restriction on what can be input. If a function maps input functions to a number, that function is called a functionalfunctional. For example, the function $F$ defined below is a functional.\n$$ {\\color{blue}F\\big( {\\color{orange}f(x)} \\big)} := {\\color{red}\\int_{1}^{2} f(x) dx} $$\nThat is, the function $F$ takes any function and integrates it from $1$ to $2$ to get a function value. In reality, when you calculate\n$$ {\\color{blue}F( {\\color{orange} e^{x} })} = \\int_{1}^2 e^x dx = {\\color{red}e^2-e},\\quad {\\color{blue}F({\\color{orange}x^2})}=\\int_{1}^2 x^{2} dx = {\\color{red}\\frac{7}{3} } $$\nsuch a function that yields a real number (or a complex number) upon inserting a function is called a functional. The following content will discuss that action is precisely a functional because it produces some value when \u0026rsquo;the Lagrangian for each path of motion\u0026rsquo; is input, which is a function. There\u0026rsquo;s a post on the blog about the mathematical content of functionals, but it won\u0026rsquo;t be introduced here. It might be more confusing to read, so it\u0026rsquo;s recommended not to read it unless you\u0026rsquo;re curious. If you\u0026rsquo;re curious, search for functional in the top right search bar, read about it, and if you don\u0026rsquo;t understand, just forget it.\nAction and Lagrangian The difference between kinetic energy and potential energy is called the Lagrangian and is denoted as $L$.\n$$ L=T-V $$\nSince the Lagrangian depends on velocity, position, and time, if the position is denoted as $y$, it can also be denoted as follows:\n$$ L=L(y^{\\prime},\\ y,\\ t) $$\nThe name Lagrangian comes from the French mathematician Joseph Louis Lagrange. The integral of the Lagrangian over time is called action or act and is commonly denoted as $J$.\n$$ J = \\int_{t_{1}}^{t_{2}} L dt = \\int_{t_{1}}^{t_{2}} L(y^{\\prime},\\ y,\\ t) dt $$\nHamilton\u0026rsquo;s Principle Devised by the British mathematician William Rowan Hamilton in 1834, the principle states that the path actually taken by a body will make the action minimal. This is not a provable fact but one of the basic principles existing in nature, as if $F=ma$. For example, let\u0026rsquo;s say we want to know the path a body takes when thrown from a high place to the ground. There could be countless paths we might imagine, but there\u0026rsquo;s something special about the actual path the body takes. That is, when integrating the Lagrangian over each path, the integral of the Lagrangian over the actual path the body takes is the smallest. That is, the path that minimizes the action is the actual path the body takes. Hence, Hamilton\u0026rsquo;s principle is also known as the principle of least action. Based on this principle, dealing with the motion of a body is Lagrangian mechanicsLagrangian mechanics. The amazing thing is that Lagrangian mechanics, though appearing entirely different, yields the same results as Newtonian mechanics. That is, only the method of expression is different, but the essence is the same. Newtonian mechanics deals with the motion of bodies based on vector calculations, whereas Lagrangian mechanics describes mechanics by calculating scalars (energy).\nVariation Simply put, the content explained above is organized mathematically. As an easy example, consider the problem of finding the minimum value of a quadratic function.\nLet\u0026rsquo;s say we are given a quadratic function like the one in the picture above. The minimum value of the function is $1$, and the place where the function value is minimal is $x=3$. At the point where it has a minimum (extremum) value, the slope is $0$, so we know that when differentiated, $0$. Therefore,\n$$ \\dfrac{dy}{dx} \\bigg|_{x=3}=0 $$\nThis content will be applied directly to the principle of least action.\nIn the picture above, let\u0026rsquo;s denote the actual path of motion of the body as $y(0, t)$. Let\u0026rsquo;s call any possible path the body can take as $y(\\alpha, t)=y(0,t)+\\alpha \\eta (t)$, as shown in the picture above. Note that $\\eta$ is the Greek letter eta. $\\alpha \\eta (t)$ can be thought of as the error when compared to the actual path. As can be seen from the picture and formula, when there is no error, that is, $\\alpha=0$, the possible arbitrary path $y(\\alpha, t)$ becomes the actual path. Furthermore, the principle of least action is the content that among all possible paths, the action for the actual path is the minimum value. Combining the two pieces of content and applying the example mentioned above, when differentiating the action and substituting $\\alpha=0$, the result is that the value is $0$.\n$$ \\dfrac{\\partial J}{\\partial \\alpha}=\\dfrac{\\partial }{\\partial \\alpha} \\int_{t_{1}}^{t_{2}} L\\big( y^{\\prime}(\\alpha,t),\\ y(\\alpha,t),\\ t \\big) dt =0 $$\nThis can be simply denoted as follows, and $\\delta J$ is called the variation of $J$.\n$$ \\delta J = 0 $$\nThat is, it can be understood as $\\delta=\\dfrac{\\partial }{\\partial \\alpha}$. Therefore, the following equation holds:\n$$ \\delta \\dot{y}=\\dfrac{\\partial }{\\partial \\alpha}\\frac{dy}{dt}=\\dfrac{d}{dt}\\frac{\\partial y}{\\partial \\alpha}=\\dfrac{d}{dt}\\delta y $$\nSee Also Euler-Lagrange Equation Grant R. Fowles and George L. Cassiday, Analytical Mechanics (7th Edition, 2005), p417-420\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1182,"permalink":"https://freshrimpsushi.github.io/en/posts/1182/","tags":null,"title":"Lagrangian Mechanics and Hamiltons Variational Principle"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definition Let\u0026rsquo;s say $\\left( X, d \\right)$ for a metric space.\nWhen there exists an open set $O$ that satisfies $x \\in O \\subset A$, $x$ is called an Interior Point of $A$.\nThe set of interior points of $A$, $A^{\\circ}$, is called the Interior of $A$.\nThe union $\\overline{A} : = A \\cup a '$ of $A$ and its codomain is called the Closure of $A$.\nWhen it‚Äôs both $x \\in \\overline{A}$ and $x \\in \\overline{X \\setminus A}$, $x$ is called a Boundary Point of $A$.\n$\\partial A : = \\overline{A} \\cap \\overline{X \\setminus A}$ is called the Boundary of $A$.\nExplanation Though it might not be essential to define, the set outside of $\\overline{A}$ in contrast to the interior is called the Exterior.\nThe open set and these concepts can be defined differently but are essentially the same.\nThese definitions are such that anyone can understand them if they read them carefully. Let\u0026rsquo;s quickly grasp them through diagrams.\n$$ A $$\nConsider these concepts when the given set is as above.\n$$ A^{\\circ} $$\nThe Interior is the largest open subset of $X$ that is contained within $A$.\n$$ \\overline{A} $$\nThe Closure is the smallest closed subset of $X$ that contains $A$.\n$$ \\partial A $$\nThe Boundary can be seen as a subset of $X$ that is the Closure minus the Interior.\nWhile distinguishing between the Interior and Closure is not particularly difficult, the Boundary might be confusing at first glance, depending on whether it‚Äôs a dotted or solid line. If it‚Äôs a border, just consider it as the Boundary, no ifs or buts.\nThrough such definitions, the following properties can essentially be seen as the definitions of open and closed sets.\nProperties: Open and Closed Sets Let\u0026rsquo;s say $A$ is a subset of the metric space $X$.\n$A$ being an open set is equivalent to $A = A^{\\circ}$.\n$A$ being a closed set is equivalent to $A = \\overline{A}$.\nOf course, these properties can be proven, but it‚Äôs perfectly fine to accept them as facts.\n","id":383,"permalink":"https://freshrimpsushi.github.io/en/posts/383/","tags":null,"title":"Inner Enclosure Boundary in Metric Spaces"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition Given a point $x \\in \\mathbb{R}$ on the real line and a subset $A \\subset \\mathbb{R}$, if for any open set $O$ containing $x$, $ O \\cap ( A \\setminus \\left\\{ x \\right\\} ) \\ne \\emptyset $ holds, then $x$ is defined as a Limit Point. The set of limit points of $A$ is called the Derived set of $A$, and is denoted by $a '$.\nExplanation In the above definition, it\u0026rsquo;s also fine if the condition is $( O \\setminus \\left\\{ x \\right\\} ) \\cap A \\ne \\emptyset$. Intuitively, as an example, the derived set of $[a,b]$ is still $[a,b]$.\nSince there\u0026rsquo;s no requirement for the limit points to be inside the given set, the derived set of $(a,b)$ is also $[a,b]$. In English terms, this is very similar to the concept of Limit expressed as $\\lim$. On closer inspection, satisfying the condition for \u0026lsquo;any open set\u0026rsquo; isn‚Äôt much different from the concept of a limit. Although the condition is not too difficult for mathematicians to accept, it could be confusing due to the way it\u0026rsquo;s expressed.\nIf we were to differentiate the two terms though, a limit is the \u0026lsquo;value to which a function converges,\u0026rsquo; whereas a limit point refers to all possible \u0026lsquo;candidates\u0026rsquo; that could become a limit. The limit of the sequence $\\displaystyle {{1} \\over {n}}$ is $0$, and there\u0026rsquo;s only one limit point, which is $0$. However, for the interval $(a,b)$, the derived set becomes $[a,b]$, not specifying what exactly the limit is. What can be understood from this is that when discussing limit points, there is no premise that it is unique. It would be beneficial to grasp the concept by proving the simple theorems below.\nTheorems (a) Finite sets have no limit points.\n(b) $\\mathbb{Q} ' = \\mathbb{R}$\nProof (a) According to the definition, since a singleton set $A:=\\left\\{ x \\right\\}$ will fail $A \\setminus \\left\\{ x \\right\\} = \\emptyset$ no matter how $O$ is chosen, $x$ cannot satisfy the conditions for a limit point.\n‚ñ†\n(b) As rational numbers are also real numbers, this can be easily verified by the density of real numbers.\n‚ñ†\nSee also Accumulation points in metric spaces ","id":379,"permalink":"https://freshrimpsushi.github.io/en/posts/379/","tags":null,"title":"The Accumulation Point in the Set of Real Numbers"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Buildup1 Let\u0026rsquo;s consider the initial value problem of the Hamilton-Jacobi equation that depends only on $H$ as $Du$ for the Hamilton-Jacobi equation.\n$$ \\begin{equation} \\left\\{ \\begin{aligned} u_{t} + H(Du)\u0026amp;=0 \u0026amp;\u0026amp; \\text{in } \\mathbb{R}^n \\times (0,\\infty) \\\\ u\u0026amp;=g \u0026amp;\u0026amp; \\text{on } \\mathbb{R}^n \\times \\left\\{ t=0 \\right\\} \\end{aligned} \\right. \\label{eq1} \\end{equation} $$\nGenerally, the Hamiltonian depends on the spatial variables as in the form of $H(Du, x)$, but let\u0026rsquo;s say here it is not affected by $x$. Also, let\u0026rsquo;s assume the following for the Hamiltonian $H\\in C^\\infty$.\n$$ \\begin{cases} H \\mathrm{\\ is\\ convex} \\\\ \\lim \\limits_{|p|\\to \\infty} \\dfrac{H(p)}{|p|}=\\infty \\end{cases} $$\nAnd if we say $L=H^{\\ast}$, the Lagrangian $L$ also satisfies the same characteristics. Lastly, let\u0026rsquo;s assume the initial value $g : \\mathbb{R}^n \\to \\mathbb{R}$ is Lipschitz continuous. That is,\n$$ \\mathrm{Lip}(g):=\\sup \\limits_{x,y\\in \\mathbb{R}^n \\\\ x \\ne y} \\dfrac{ |g(x)-g(y)| }{|x-y|} \u0026lt; \\infty $$\nFurthermore, the characteristic equation of the given Hamilton-Jacobi equation $\\eqref{eq1}$ is as follows.\n$$ \\begin{align*} \\dot{\\mathbf{p}}(s) \u0026amp;= -D_{x}H \\big( \\mathbf{p}(s), \\mathbf{x}(s) \\big) \\\\ \\dot{z}(s) \u0026amp;= D_{p} H\\big( \\mathbf{p}(s),\\ \\mathbf{x}(s)\\big)\\cdot \\mathbf{p}(s) -H\\big( \\mathbf{p}(s), \\mathbf{x}(s)\\big) \\\\ \\dot{\\mathbf{x}}(s) \u0026amp;= D_{p}H\\big( \\mathbf{p}(s), \\mathbf{x}(s) \\big) \\end{align*} $$\nHere, since $H$ is assumed to be independent of $x$, it can be rewritten as follows.\n$$ \\begin{align*} \\dot{\\mathbf{p}} \u0026amp;= 0 \\\\ \\dot{z} \u0026amp;= D H( \\mathbf{p} )\\cdot \\mathbf{p} -H ( \\mathbf{p} ) \\\\ \\dot{\\mathbf{x}} \u0026amp;= DH ( \\mathbf{p}) \\end{align*} $$\nAt this time, it is $t(s)=s, p(s)=Du(x(s), s), z(s)=u(x(s), s)$. Since there is no need to distinguish between the differentiation with respect to $p$ and $x$, the subscript of $D$ was omitted. Since the Euler-Lagrange equation holds for fixed start and end points, if there exists a solution to the given Hamilton-Jacobi equation $\\eqref{eq1}$, then it is a local in time solution as follows.\n$$ u= u(x,t) \\in C^2\\big( \\mathbb{R}^n \\times [0,T]\\big) $$\nIn the above characteristic equation, the first and third equations are Hamilton\u0026rsquo;s equations that satisfy the Euler-Lagrange equation from the minimization problem of action defined by Lagrangian $L=H*$.\nIf $H$ and $L$ are differentiable at $p$ and $v\\in \\mathbb{R}^n$, then all the following contents are equivalent.\n$$ \\begin{cases} p\\cdot v=L(v) + H(p) \\\\ p=DL(v) \\\\ v=DH(p) \\end{cases} $$\nAt this time, it is defined as $p=D_{v}L(v)$, so using the above lemma, we obtain the following.\n$$ \\begin{align*} \\dot{z}(s) \u0026amp;= DH(\\mathbf{p})\\cdot \\mathbf{p}-H(\\mathbf{p}) \\\\ \u0026amp;= \\mathbf{v} \\cdot \\mathbf{p}-H(\\mathbf{p}) \\\\ \u0026amp;= L(\\mathbf{v})+H(\\mathbf{p})-H(\\mathbf{p}) \\\\ \u0026amp;= L(\\mathbf{v}) = L\\big(\\dot{\\mathbf{x}}(s)\\big) \\end{align*} $$\nTherefore, if we find $z(t)$, it is as follows.\n$$ \\begin{align*} z(t) \u0026amp;= \\int_{0}^t \\dot{z}(s)dx +z(0) \\\\ \u0026amp;= \\int_{0}^tL \\big( \\dot{\\mathbf{x}}(s) \\big) + u\\big( \\mathbf{x}(0),\\ 0\\big) \\\\ \u0026amp;= \\int_{0}^t L\\big( \\dot{\\mathbf{x}}(s)\\big) ds +g\\big(\\mathbf{x}(0) \\big) \\end{align*} $$\nHowever, at this time, since it was $z(t)=u(x(t), t)$ in the above condition, we obtain the following.\n$$ u(x,t)=\\int_{0}^t L\\big( \\dot{\\mathbf{x}}(s)\\big) ds +g\\big(\\mathbf{x}(0) \\big) \\quad (0 \\le t \u0026lt;T) $$\nThis is a local in time smooth solution, so the question remains whether a global in time weak solution can be obtained. Returning to the minimization problem of action, the difference from when the Euler-Lagrange equation was derived is that only the endpoint is fixed.\nLet\u0026rsquo;s say a fixed $x \\in \\mathbb{R}^n, t\u0026gt;0$ is given. And let\u0026rsquo;s say the admissible class $\\mathcal{A}$ is as follows.\n$$ \\mathcal{A}=\\left\\{ \\mathbf{w}\\in C^1\\big( [0,t];\\mathbb{R}^n \\big)\\ :\\ \\mathbf{w}(t)=x \\right\\} $$\nAnd let\u0026rsquo;s consider the minimization problem of the following action.\n$$ \\mathbf{w}(\\cdot) \\in \\mathcal{A} \\mapsto \\int_{0}^t L\\big( \\dot{\\mathbf{w}}(s)\\big) ds + g(\\mathbf{w}(0)) $$\nIf a minimizer $\\mathbf{x}(\\cdot)$ exists, then it is $\\mathbf{p}(s):=DL(\\dot{\\mathbf{x}}(s))$, satisfies the Euler-Lagrange equation, and therefore also satisfies the Hamilton equation. Thus, as in the case of the local in time solution obtained earlier, the solution will be given as follows.\n$$ u(x,t)=\\int_{0}^tL\\big( \\dot{\\mathbf{x}}(s)\\big)ds +g \\big( \\mathbf{x}(0) \\big) $$\nBased on the above content, if a global in time weak solution exists, it can be defined as follows.\n$$ \\begin{equation} u(x,t):=\\inf \\limits_{\\mathbf{w} \\in \\mathcal{A}} \\left\\{ \\int_{0}^t L\\big( \\dot{\\mathbf{w}}(s) \\big)ds + g\\big( \\mathbf{w}(0) \\big) \\right\\} \\label{eq2} \\end{equation} $$\nTheorem Let\u0026rsquo;s say $x \\in \\mathbb{R}^n$ and $t\u0026gt;0$. Then, the solution to the minimization problem of $\\eqref{eq2}$ is given as follows.\n$$ u(x,t) = \\min \\limits_{y \\in \\mathbb{R}^n} \\left\\{ tL\\left( \\dfrac{x-y}{t} \\right) +g(y) \\right\\} $$\nThis is called the Hopf-Lax formula.\nProof First, we show that it holds for $\\inf$, and then actually show that it becomes $\\min$ in order.\nStep 1.\nThere exists an arbitrary fixed $y \\in \\mathbb{R}^n, t\\in \\mathbb{R}$. And let\u0026rsquo;s define $\\mathbf{w}$ as follows.\n$$ \\mathbf{w}(s) :=y+\\frac{s}{t}(x-y) \\quad (0 \\le s \\le t) $$\nThen $\\mathbf{w}(0)=y$ and $\\mathbf{w}(t)=x$. Then $\\mathbf{w}$ is an element of the admissible class $\\mathcal{A}$.\n$$ \\mathcal{A}= \\left\\{ \\mathbf{w}(\\cdot) \\ \\big| \\ \\mathbf{w}(0)=y,\\ \\mathbf{w}(t)=x\\right\\} $$\nThen, by the definition of ~, the following inequality holds.\n$$ \\begin{align*} u(x,t) \u0026amp; \\le\u0026amp; \\int_{0}^t L \\left( \\frac{x-y}{t}\\right)ds + g(y) \\\\ \u0026amp;= tL\\left( \\frac{x-y}{t}\\right)+g(y) \\end{align*} $$\nSince this inequality holds for all $y \\in \\mathbb{R}^n$, we obtain the following.\n$$ u(x,t) \\le \\inf \\limits_{y \\in \\mathbb{R}^n} \\left(t L\\left(\\frac{x-y}{t} \\right) +g(y)\\right) $$\nStep 2.\nLet\u0026rsquo;s say $\\mathbf{w}(\\cdot) \\in \\mathcal{A}$. Then $\\mathbf{w}(\\cdot) \\in C^1([0;t];\\mathbb{R}^n)$ and $\\mathbf{w}(t)=x$.\nJensen\u0026rsquo;s Inequality\nSuppose the function $f$ is convex. Then, the following formula holds. $$ f \\left( -\\!\\!\\!\\!\\!\\! \\int_{U} u dx \\right) \\le -\\!\\!\\!\\!\\!\\! \\int_{U} f(u) dx $$\nThen, by the above lemma, the following holds.\n$$ L \\left( \\frac{1}{t}\\int_{0}^t \\dot{\\mathbf{w}}(s) dx\\right) \\le \\dfrac{1}{t}\\int_{0}^t L \\big( \\dot{\\mathbf{w}(s)} \\big)ds $$\nAnd let\u0026rsquo;s say the starting point is $y$, $\\mathbf{w}(0)=y$. Then, the above inequality is as follows.\n$$ \\begin{align*} \u0026amp;\u0026amp; L\\left( \\dfrac{1}{t} \\big( \\mathbf{w}(t)-\\mathbf{w}(0) \\big) \\right) \u0026amp;\\le \\dfrac{1}{t}\\int_{0}^tL \\big( \\dot{\\mathbf{w}}(s) \\big)ds\n\\\\ \\implies\u0026amp;\u0026amp; L\\left( \\dfrac{x-y}{t} \\right) \u0026amp;\\le \\dfrac{1}{t}\\int_{0}^tL \\big( \\dot{\\mathbf{w}}(s) \\big)ds \\end{align*} $$\nMultiply both sides by $t$ and add $g(y)$ to get the following.\n$$ tL\\left( \\dfrac{x-y}{t} \\right) + g(y) \\le \\int_{0}^tL \\big( \\dot{\\mathbf{w}}(s) \\big)ds + g(y) $$\nSince the right-hand side\u0026rsquo;s $\\inf$ is $u(x,t)$, it is as follows.\n$$ tL\\left( \\dfrac{x-y}{t} \\right) + g(y) \\le u(x,t) $$\nFinally, taking $\\inf \\limits_{y\\in \\mathbb{R}^n}$ on both sides, we obtain the following.\n$$ \\inf \\limits_{y \\in \\mathbb{R}^n} \\left( tL\\left( \\dfrac{x-y}{t} \\right) + g(y) \\right) \\le u(x,t) $$\nTherefore, by Step 1. and Step 2., the following holds.\n$$ \\begin{equation} u(x,t) = \\inf \\limits_{y \\in \\mathbb{R}^n} \\left( tL\\left( \\dfrac{x-y}{t} \\right) + g(y) \\right) \\label{eq3} \\end{equation} $$\nStep 3.\nLet\u0026rsquo;s say $\\left\\{y_{k} \\right\\}_{k=1}^\\infty$ is a minimizing sequence for $\\eqref{eq3}$. Then, the following holds.\n$$ \\begin{equation} tL\\left( \\dfrac{x-y_{k}}{t} \\right) + g(y_{k}) \\to u(x,t)\\in [-\\infty, \\infty) \\quad \\mathrm{as}\\ k\\to \\infty \\label{eq4} \\end{equation} $$\nFirst, assume $\\left\\{y_{k} \\right\\}$ is not bounded. We will show this assumption leads to a contradiction, proving that $\\left\\{ y_{k} \\right\\}$ is bounded. By assumption, $|y_{k}| \\to \\infty$ and $y_{k}=0$, $k$ are at most finite. Therefore, let\u0026rsquo;s consider a subsequence that only satisfies $y_{k}\\ne 0$ again as $\\left\\{ y_{k} \\right\\}$. The following holds.\n$$ \\left| \\dfrac{x-y_{k}}{t} \\right| \\to \\infty $$\nThen, by the properties of the Lagrangian $L$, the following holds.\n$$ a_{k}:= \\dfrac{L\\left( \\dfrac{x-y_{k}}{t}\\right)}{\\left| \\dfrac{x-y_{k}}{t}\\right|} \\to \\infty $$\nTherefore, $L\\left( \\dfrac{x-y_{l}}{t}\\right) \\to \\infty$ and multiplying by a constant yields the same result.\n$$ \\begin{equation} tL\\left( \\dfrac{x-y_{k}}{t}\\right) \\to \\infty \\label{eq5} \\end{equation} $$\nRewriting the Lipschitz condition of $g$ is as follows.\n$$ \\dfrac{|g(x)-g(y_{k})|}{|x-y_{k}|} \\le \\mathrm{Lip}(g)=C \\quad \\forall \\ k \\in \\mathbb{N} $$\nTherefore, we obtain the following.\n‚ñ∂eq32\n‚óÄ\nAdding $\\eqref{eq5}$ to both sides gives the following.\n$$ tL\\left( \\dfrac{x-y_{k}}{t}\\right)+ g(x) -g(y_{k}) \\le C|x-y_{k}|+ tL\\left( \\dfrac{x-y_{k}}{t}\\right) \\quad \\mathrm{for\\ large}\\ k $$\nAppropriately rearranging the above formula yields the following.\n$$ tL\\left( \\dfrac{x-y_{k}}{t}\\right)-C|x-y_{k}| + g(x) \\le tL\\left( \\dfrac{x-y_{k}}{t}\\right) + g(y_{k}) $$\nRewritten, it is as follows.\n$$ a_{k}|x-y_{k}| -C|x-y_{k}| + g(x) =|x-y_{k}|(a_{k}-C)+g(x) \\le tL\\left( \\dfrac{x-y_{k}}{t}\\right) + g(y_{k}) $$\nSince $a_{k}\\to \\infty$ and $|x-y_{k}| \\to \\infty$, the left side diverges to $\\infty$ and the right side also diverges. Therefore, by the definition of $u(x,t)$, $u(x,t)\\to \\infty$ is true. This is a contradiction to $\\eqref{eq4}$, so $\\left\\{ y_{k} \\right\\}$ is bounded.\nSince $\\left\\{ y_{k} \\right\\}$ is bounded, let\u0026rsquo;s assume $y_{k} \\to y_{0}$. Then, the following holds.\n$$ tL \\left( \\dfrac{x-y_{k}}{t} \\right)+g(y_{k}) \\to tL \\left( \\dfrac{x-y_{0}}{t}\\right)+g(y_{0}) =\\min\\limits_{y \\in \\mathbb{R}^n}\\left( tL \\left( \\dfrac{x-y}{t}\\right)+g(y) \\right) $$\nThen, by $\\eqref{eq4}$, the following holds.\n$$ tL\\left( \\dfrac{x-y_{k}}{t} \\right) + g(y_{k}) \\to u(x,t)\\in [-\\infty, \\infty) \\quad \\mathrm{as}\\ k\\to \\infty $$\nTherefore, we obtain the following.\n$$ u(x,t) = \\min \\limits_{y \\in \\mathbb{R}^n} \\left( tL\\left( \\dfrac{x-y}{t} \\right) +g(y) \\right) $$\n‚ñ†\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p122-124\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1174,"permalink":"https://freshrimpsushi.github.io/en/posts/1174/","tags":null,"title":"Hopf-Lax Formula"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition Let\u0026rsquo;s define a subset $E \\ne \\emptyset$ of $\\mathbb{R}$, function $f : E \\to \\mathbb{R}$, and sequence of functions $\\left\\{ f_{n} : E \\to \\mathbb{R} \\right\\}_{n=1}^{\\infty}$. If there exists $N \\in \\mathbb{N}$ for every $\\varepsilon \u0026gt; 0$ satisfying $n \\ge N \\implies | f_{n} (x) - f(x) | \u0026lt; \\varepsilon$, then sequence $f_{n}$ converges uniformly to $f$ in $E$, denoted by:\n$$ f_n \\rightrightarrows f $$\nor\n$$ f_{n} \\overset{\\text{unif}}{\\to} f $$\nor\n$$ f_{n} \\to f \\quad \\text{uniformly} $$\nExplanation Unlike pointwise convergence, which only concerns the convergence of function values, uniform convergence pays attention to whether the sequence of functions $f_{n}$ actually converges to the function $f$. A sequence that converges uniformly has a stronger condition and thus possesses more properties.\nTo put it another way, uniform convergence is equipped with stronger conditions to ensure the functions retain the \u0026ldquo;basic\u0026rdquo; properties that mathematicians assume they \u0026ldquo;should\u0026rdquo; have for research. Unlike pointwise convergent function sequences, the properties of $f_{n}$ are preserved in $f$ for uniformly convergent sequences.\nTheorem Suppose sequence $f_{n}$ uniformly converges to $f$ in $E$.\n(a) Continuity: If $f_{n}$ is continuous at $x_{0} \\in E$, then $f$ is also continuous at $x_{0} \\in E$.\n(b) Differentiability: If $f_{n}$ is differentiable at $E = (a,b)$ and $f_{n} ' $ converges uniformly in $E$, then $f$ is also differentiable in $E$, and\n$$ \\lim_{n \\to \\infty} {{ d } \\over { dx }} f_{n} (x) = {{ d } \\over { dx }} \\left( \\lim_{n \\to \\infty} f_{n} (x) \\right) $$\n(c) Integrability: If $f_{n}$ is integrable at $E = [a,b]$, then $f$ is also integrable in $E$, and\n$$ \\lim_{n \\to \\infty} \\int_{a}^{b} f_{n} (x) dx = \\int_{a}^{b} \\left( \\lim_{n \\to \\infty} f_{n} (x) \\right) dx $$\nThe ability of $\\int_{a}^{b}$ and $\\displaystyle {{ d } \\over { dx }}$ to freely move within $\\displaystyle \\lim_{n \\to \\infty}$ is a very desirable property. If someone asks why this is beneficial, it\u0026rsquo;s akin to finding the answer within the question. In fields other than mathematics, sequences of functions may appear without considering concepts like uniform convergence and still use the properties of uniform sequences as if they were obvious. However, if the operations became impossible without uniform convergence, it would create a nightmarish scenario.\nSee Also Difference between pointwise and uniform convergence of function sequences ","id":1154,"permalink":"https://freshrimpsushi.github.io/en/posts/1154/","tags":null,"title":"Uniform Convergence of Function Series"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition Let us define a function $f : E \\to \\mathbb{R}$ for the subset $E \\ne \\emptyset$ of $\\mathbb{R}$. If the sequence of functions $\\left\\{ f_{n} : E \\to \\mathbb{R} \\right\\}_{n=1}^{\\infty}$ satisfies $f(x) = \\lim \\limits_{n \\to \\infty} f_{n} (X)$ for each $x \\in E$, then it is said to converge pointwise to $f_{n}$ in $E$, denoted by:\n$$ f_{n} \\to f $$\nExplanation Rewriting the above definition using the epsilon-delta argument gives the following necessary and sufficient condition.\nFor every $\\varepsilon \u003e 0$ and $x \\in E$, there exists a $N \\in \\mathbb{N}$ that satisfies $n \\ge N \\implies | f_{n} (x) - f(x) | \u003c \\varepsilon$.\rSequences are merely \u0026lsquo;functions whose domains are $\\mathbb{N}$,\u0026rsquo; so there is no issue with having a set of functions as their range, making it possible to think of terrifying entities like the sequence of functions $\\left\\{ f_{n} \\right\\}_{n \\in \\mathbb{N}}$. If you\u0026rsquo;re still loosely thinking of sequences as \u0026lsquo;points moving on a line as $n$ increases\u0026rsquo;, it will be hard to accept.\nWith the emergence of new sequences comes the need to discuss new types of convergence. The concept of pointwise convergence does not seem too difficult since if there is more than one exception in $E$, it cannot be considered convergence in $E$. So, why exactly is the common-sense \u0026lsquo;convergence\u0026rsquo; specifically called \u0026lsquo;pointwise convergence\u0026rsquo;?\nThe reason is obviously because pointwise convergence alone is insufficient when discussing the convergence of the function itself. In fact, \u0026lsquo;better convergence\u0026rsquo; compared to pointwise convergence is essentially considered \u0026rsquo;not sufficiently good convergence\u0026rsquo;. Frankly, considering $f_{n} (x)$, if one fixes a specific $x_{0}$, it appears as $a_{n} := f_{n} (x_{0} )$, so there is no need to bother with the concept of a sequence of functions.\nHere are examples where the original properties of $f_{n}$ are not maintained when it is said to converge pointwise to $f$ in $E$.\nTheorems Assume that in $E$, $f_{n}$ converges pointwise to $f$.\n(a) Even if $f_{n}$ is differentiable, $f$ may not be differentiable.\n(b) Even if $f_{n}$ is integrable, $f$ may not be integrable.\n(c) Even if $f_{n}, f$ is differentiable, $\\lim \\limits_{n \\to \\infty} \\dfrac{d}{dx} f_{n} (x) = \\dfrac{d}{dx} \\left( \\lim \\limits_{n \\to \\infty} f_{n} (x) \\right)$ may not hold.\n(d) Even if $f_{n}, f$ is integrable, $\\displaystyle \\lim \\limits_{n \\to \\infty} \\int_{a}^{b} f_{n} (x) dx = \\int_{a}^{b} \\left( \\lim \\limits_{n \\to \\infty} f_{n} (x) \\right) dx$ may not hold.\nEspecially, (a) is an example that also demonstrates non-preservation of continuity.\nProof Counterexample (a) Let\u0026rsquo;s define $f_{n} , f$ in $E = [0,1]$ as follows.\n$$ \\begin{align*} f_{n} (x) \u0026amp;:= x^{n} \\\\ f(x) \u0026amp;:= \\begin{cases} 0 \u0026amp;, 0 \\le x \u0026lt; 1 \\\\ 1 \u0026amp;, x=1 \\end{cases} \\end{align*} $$\nObviously, in $E$, it converges pointwise to $f_{n} \\to f$. However, while $f_{n}$ is differentiable in $[0,1]$, $f$ is not continuous in $x=1$ and therefore not differentiable.\n‚ñ†\nCounterexample (b) Let\u0026rsquo;s define $f_{n} , f$ in $E = [0,1]$ as follows.\n$$ \\begin{align*} f_{n} (x) \u0026amp;:= \\begin{cases} 1 \u0026amp;, x = {{ p } \\over { m }} , p \\in \\mathbb{Z} , m \\in \\left\\{ 1 , \\cdots , n \\right\\} \\\\ 0 \u0026amp;, \\text{otherwise} \\end{cases} \\\\ f(x) \u0026amp;:= \\begin{cases} 1 \u0026amp;, x \\in \\mathbb{Q} \\\\ 0 \u0026amp;, \\text{otherwise} \\end{cases} \\end{align*} $$\nThe setting of $f_{n}$ is somewhat complex, with $f_{1} (x)$ being $1$ only at $ x \\in \\left\\{ 0 , 1 \\right\\}$, $f_{2} (x)$ being $1$ only at $\\displaystyle x \\in \\left\\{ 0 , {{ 1 } \\over { 2 }} , 1 \\right\\}$, and $f_{3} (x)$ being $1$ only at $x \\in \\left\\{ 0 , {{ 1 } \\over { 3 }} , {{ 1 } \\over { 2 }} , {{ 2 } \\over { 3 }} , 1 \\right\\}$. Proceeding in this manner, eventually, it will be $1$ only at every $x \\in \\mathbb{Q}$, and thus, we know it converges pointwise to $f_{n} \\to f$ in $E$. However, while $f_{n}$ is integrable in $[0,1]$, the Dirichlet function $f$ is not integrable.\n‚ñ†\nCounterexample (c) Let\u0026rsquo;s define $f_{n} , f$ in $E = [0,1]$ as follows.\n$$ \\begin{align*} f_{n} (x) \u0026amp;:= {{ x^{n} } \\over { n }} \\\\ f(x) \u0026amp;:= 0 \\end{align*} $$\nObviously, in $E$, it converges pointwise to $f_{n} \\to f$, and each of the derivatives is found as\n$$ \\begin{align*} f\u0026rsquo;_{n} (x) =\u0026amp; x^{n-1} \\\\ f '(x) =\u0026amp; 0 \\end{align*} $$\nHowever, in $x=1$,\n$$ 1 = \\lim \\limits_{n \\to \\infty} \\dfrac{d}{dx} f_{n} (1) \\ne \\dfrac{d}{dx} \\left( \\lim \\limits_{n \\to \\infty} f_{n} (1) \\right) = 0 $$\n‚ñ†\nCounterexample (d) Let\u0026rsquo;s define $f_{n} , f$ in $E = [0,1]$ as follows.\n$$ \\begin{align*} f_{1} (x) \u0026amp;:= 1 \\\\ f_{n} (x) \u0026amp;:= \\begin{cases} n^2 x \u0026amp;, 0 \\le x \u0026lt; {{ 1 } \\over { n }} \\\\ 2n - n^2 x \u0026amp;, {{ 1 } \\over { n }} \\le x \u0026lt; {{ 2 } \\over { n }} \\\\ 0 \u0026amp;, {{ 2 } \\over { n }} \\le x \\le 1 \\end{cases} \\\\ f(x) \u0026amp;:= 0 \\end{align*} $$\nThough $f_{n}$ looks complex, it is pretty straightforward when looking at the above diagram, and one can tell it converges pointwise to $f_{n} \\to f$ in $E$. Here, $\\displaystyle \\int_{0}^{1} f_{n} (x) dx$ is the same as the area inside the triangle with a height of $n$ and base length of ${{ 2 } \\over { n }}$, so $n$ always equals $1$ regardless. However,\n$$ \\int_{0}^{1} f(x) dx = \\int_{0}^{1} 0 dx = 0 $$\nHence,\n$$ 1 = \\lim \\limits_{n \\to \\infty} \\int_{0}^{1} f_{n} (x) dx \\ne \\int_{0}^{1} \\left( \\lim \\limits_{n \\to \\infty} f_{n} (x) \\right) dx = 0 $$\n‚ñ†\nSee Also Difference between pointwise convergence and uniform convergence of a sequence of functions ","id":1148,"permalink":"https://freshrimpsushi.github.io/en/posts/1148/","tags":null,"title":"Pointwise Convergence of Function Sequences"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"There are two ways to derive the Hamilton equations. One is from the Euler-Lagrangian equations, and the other, which will be introduced in this article, is from the characteristic equations of the Hamilton-Jacobi equation.\nDefinition1 The following partial differential equation is called the general Hamilton-Jacobi equation.\n$$ G(Du, u_{t}, u, x, t)=u_{t}+H(Du, x)=0 $$\n$t \u0026gt;0 \\in \\mathbb{R}$ $x \\in \\mathbb{R}^{n}$ $u : \\mathbb{R}^{n} \\to \\mathbb{R}$ Here, the differential operator $D$ follows the multi-index notation, and let us always consider differentiation with respect to the spatial variable $x$, that is, $D=D_{x}$, and $Du=D_{x}u=(u_{x_{1}}, \\cdots, u_{x_{n}})$. And $H : \\mathbb{R}^n \\times \\mathbb{R}^n \\rightarrow \\mathbb{R}$ is called the Hamiltonian.\nCharacteristic Equation For convenience, assume that $H \\in C^{\\infty} \\big(\\mathbb{R}^{n} \\times (0,\\infty) \\big)$. Given such a Hamilton-Jacobi equation, let\u0026rsquo;s simplify the expression by combining space-time variables into one as $y$.\n$$ y=(x,t)=(x_{1}, \\cdots, x_{n}, t) $$\nAlso, the time derivative and spatial derivative of $u$ are together represented as $q$.\n$$ \\begin{align*} q \u0026amp;=q(Du, u_{t}) =q(u_{x_{1}}, u_{x_{2}},\\dots, u_{x_{n}}, u_{t}) \\\\ \u0026amp;= (p, p_{n+1}) =(p_{1}, p_{2}, \\dots, p_{n}, p_{n+1}) \\end{align*} $$\nLastly, if we say $z=u$, the Hamilton-Jacobi equation can be represented as below.\n$$ \\begin{equation} G(q, z, y)=p_{n+1}+H(p, x)=0 \\quad \\forall (q, z, y)\\in\\mathbb{R}^{n+1}\\times \\mathbb{R} \\times \\big( \\mathbb{R}^n\\times (0, \\infty) \\big) \\label{eq1} \\end{equation} $$\nSolving for the derivative of $G$, we get the following.\n$$ \\begin{align} D_{q} G(q, z, y) \u0026amp;= (G_{p_{1}}, \\cdots, G_{p_{n+1}})=\\big(H_{p_{1}}(p,x), \\dots , H_{p_{n}}(p,x), 1\\big)=\\big( D_{p} H(p,x), 1\\big) \\label{eq2} \\\\ D_{z} G(q, z, y) \u0026amp;= G_{z}=0 \\label{eq3} \\\\ D_{y} G(q, z, y) \u0026amp;= \\big( G_{y_{1}}, \\cdots, G_{y_{n+1}} \\big)=\\big( H_{x_{1}}(p,x), \\cdots, H_{x_{n}}(p,x), H_{t}(p,x) \\big) =\\big( D_{x}H (p,x), 0\\big) \\label{eq4} \\end{align} $$\nMoreover, the characteristic equation of $G(q,z,y)$ is as follows.\n$$ \\left\\{ \\begin{align*} \\dot{q}(s) \u0026amp;= -D_{y} G\\big(q(s), z(s), y(s) \\big)-D_{z} G\\big(q(s), z(s), y(s) \\big)q(s) \\\\ \\dot{z}(s) \u0026amp;= D_{q} G\\big(q(s), z(s), y(s) \\big) \\cdot q(s) \\\\ \\dot{y}(s) \u0026amp;= D_{q} G\\big(q(s), z(s), y(s) \\big) \\end{align*} \\right. $$\nThen $\\dot{q}(s)$ is as follows.\n$$ \\begin{align*} \\dot{ q}(s) \u0026amp;= -D_{y} G\\big(q(s), z(s), y(s) \\big)-D_{z} G\\big(q(s), z(s), y(s) \\big)q(s) \\\\ \u0026amp;= -D_{y} G\\big(q(s), z(s), y(s) \\big) \\\\ \u0026amp;=- (D_{x} H(p,x), 0) \\end{align*} $$\nThe second equality is by $\\eqref{eq2}$, and the third equality is by $\\eqref{eq4}$. Since $q=(p, p_{n+1})$, each component of $\\dot{q}$ is as follows.\n$$ \\begin{align*} \\dot{p}^{i}(s) \u0026amp;= -H_{x_{i}} \\big( p(s), x(s) \\big) \u0026amp;( i=1,\\dots,n) \\\\ \\dot{p}^{n+1}(s) \u0026amp;= 0 \\end{align*} $$\n$\\dot{z}(s)$ is as follows.\n$$ \\begin{align*} \\dot{z}(s) \u0026amp;= D_{q} G\\big(q(s), z(s), y(s) \\big) \\cdot q(s) \\\\ \u0026amp;= \\Big( D_{p}H\\big(p(s), x(s) \\big), 1 \\Big)\\cdot\\big( p(s), p_{n+1}(s) \\big) \\\\ \u0026amp;= D_{p} H\\big( p(s), x(s)\\big)\\cdot p(s) +p_{n+1}(s) \\\\ \u0026amp;= D_{p} H\\big( p(s), x(s)\\big)\\cdot p(s) -H\\big( p(s), x(s)\\big) \\end{align*} $$\nThe second equality is by $\\eqref{eq2}$, and the fourth equality is by $\\eqref{eq1}$. $\\dot{y}(s)$ is as follows.\n$$ \\begin{align*} \\dot{y}(s) \u0026amp;= D_{q}G\\big(q(s), z(s), y(s) \\big) \\\\ \u0026amp;= \\big(D_{p}H(p,x), 1 \\big) \\end{align*} $$\nSince $y=(x,t)$, each component of $\\dot{y}=(\\dot{x}, \\dot{t})$ is as follows.\n$$ \\begin{cases} \\dot{x}(s) = D_{p}H\\big( p(s), x(s) \\big) \\\\ \\dot{t}(s)=1 \\end{cases} $$\nFrom the results above, we can consider $s$ to be equivalent to $t$. By synthesizing everything we calculated so far, we obtain the characteristic equations of the Hamilton-Jacobi equation as follows.\n$$ \\begin{align*} \\dot{p}(s) \u0026amp;= -D_{x}H \\big( p(s), x(s) \\big) \\\\ \\dot{z}(s) \u0026amp;= D_{p} H\\big( p(s), x(s)\\big)\\cdot p(s) -H\\big( p(s), x(s)\\big) \\\\ \\dot{x}(s) \u0026amp;= D_{p}H\\big( p(s), x(s) \\big) \\end{align*} $$\nHere, specifically groups the first and third equations as Hamilton\u0026rsquo;s equations.\n‚ñ†\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p113-114\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1162,"permalink":"https://freshrimpsushi.github.io/en/posts/1162/","tags":null,"title":"Hamilton-Jacobi Equation and Hamiltonian Equation"},{"categories":"Îß§Ìä∏Îû©","contents":"Method Matlab provides the functionality to import data from Excel files. First, click on \u0026lsquo;Import Data\u0026rsquo; from the Home menu.\nSelect the Excel file that contains the data you want to import.\nThen, you can select which data to import, which is automatically selected initially. Confirm and click \u0026lsquo;Import Selected\u0026rsquo;.\nFrom \u0026lsquo;Import Selected\u0026rsquo;, click on \u0026lsquo;Import Data\u0026rsquo;.\nThen, the data from the Excel file is input into a variable with the same name as the Excel file. However, since this is not an array but a table, you need to use table2array() to convert it into an array to use it as desired. The example code and result when the title of the imported Excel file is X are as follows.\nX1=table2array(X) See Also How to Save Data Calculated in MATLAB into an Excel File ","id":1163,"permalink":"https://freshrimpsushi.github.io/en/posts/1163/","tags":null,"title":"Importing Excel Data into MATLAB"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 Lagrangian\nLet\u0026rsquo;s assume a smooth function $L : \\mathbb{R}^n \\times \\mathbb{R}^n \\to \\mathbb{R}$ is given. This is called the Lagrangian and is denoted as follows.\n$$ L = L(v,x)=L(v_{1}, \\dots, v_{n}, x_{1}, \\dots, x_{n}) \\quad v,x\\in \\mathbb{R}^{n} \\\\ D_{v}L = (L_{v_{1}}, \\dots, L_{v_{n}}), \\quad D_{x}L = (L_{x_{1}}, \\dots, L_{x_{n}}) $$\nThe reason for using variables $v, x$ is because, in physics, each variable actually signifies velocity and position.\nAction, Admissible class\nFor two fixed points $x,y \\in \\mathbb{R}^{n}$ and time $t\u0026gt;0$, the following defined functional $I$ is called action.\n$$ I[ \\mathbf{w}(\\cdot)] := \\int_{0}^tL(\\dot{\\mathbf{w}}(s), \\mathbf{w}(s) ) ds \\quad \\left( \\dot{„ÄÄ}=\\dfrac{d}{ds}\\right) $$\nIn this case, the function $\\mathbf{w}(\\cdot)=\\big( w^1(\\cdot), \\cdots, w^n(\\cdot) \\big)$ is an element of the admissible class defined as follows $\\mathcal{A}$.\n$$ \\mathcal{A} := \\left\\{ \\mathbf{w}(\\cdot) = \\in C^2 \\big([0,t];\\mathbb{R}^n \\big) \\ \\big| \\ \\mathbf{w}(0)=y, \\mathbf{w}(t)=x\\right\\} $$\nIn other words, $\\mathcal{A}$ means the set of all paths that are twice continuously differentiable, starting from position $y$ to $x$ as time flows from $0$ to $t$.\nDescription The goal of the calculus of variations is to find $\\mathbf{x} \\in \\mathcal{A}$ that makes the integral value of action $I$ minimum. This $\\mathbf{x}$ is called the minimizer of $I$.\n$$ I[ \\mathbf{x} (\\cdot) ] = \\inf_{\\mathbf{w}(\\cdot)\\in \\mathcal{A}} I[\\mathbf{w}(\\cdot)] $$\nSuch $\\mathbf{x}$ is sought because the path that minimizes the action of the Lagrangian is actually the path along which an object moves. In essence, this is for understanding the motion of an object, which fundamentally equates to solving $F=ma$. In classical mechanics, the Lagrangian specifically refers to the difference between kinetic energy and potential energy.\nRegarding the determination of minimizers, there\u0026rsquo;s the following theorem.\nTheorem Assume $\\mathbf{x}(\\cdot) \\in \\mathcal{A}$ is the minimizer of action $I$. Then, $\\mathbf{x}(\\cdot)$ satisfies the following equation.\n$$ -\\dfrac{d}{ds} \\Big[ D_{v}L\\big( \\dot{\\mathbf{x}}(s), \\mathbf{x}(s) \\big) \\Big] + D_{x}L\\big( \\dot{\\mathbf{x}}(s), \\mathbf{x}(s)\\big)=0 \\quad (0 \\le s \\le t) $$\nThis equation is called the Euler-Lagrange equations.\nIt\u0026rsquo;s important to note that although a minimizer satisfies the Euler-Lagrange equations, satisfying the Euler-Lagrange equations does not necessarily mean it\u0026rsquo;s a minimizer. Similar to how differentiating at the minimum value gives $0$, but not every point where differentiation gives $0$ is a minimum. In this sense, $\\mathbf{x}(\\cdot) \\in \\mathcal{A}$ satisfying the Euler-Lagrange equations is called a critical point of $I$. Therefore, while a minimizer is a critical point, not all critical points are minimizers.\nProof Assume $\\mathbf{x} \\in \\mathcal{A}$ is the minimizer of action $I$.\nStep 1.\nLet\u0026rsquo;s presume the function $\\mathbf{y} : [0,t] \\to \\mathbb{R}^{n}, \\mathbf{y}(\\cdot) = (y^1(\\cdot), \\cdots, y^n(\\cdot) )$ satisfies the following equation as a smooth function.\n$$ \\begin{equation} \\mathbf{y}(0)=\\mathbf{y}(t)=\\mathbf{0} \\label{eq1} \\end{equation} $$\nAnd for any $\\tau \\in \\mathbb{R}$, define $\\mathbf{w}(\\cdot)$ as follows.\n$$ \\mathbf{w}(\\cdot) : = \\mathbf{x}(\\cdot) + \\tau \\mathbf{y}(\\cdot) \\in \\mathcal{A} $$\nThen $\\mathbf{w}$ represents a path that has the same start and end points as $\\mathbf{x}$ but differs by $\\tau \\mathbf{y}(\\cdot)$ in between. Furthermore, since $\\mathbf{x}(\\cdot)$ is the minimizer of $I$, the following equation holds.\n$$ I[\\mathbf{x}(\\cdot)] \\le I[\\mathbf{w}(\\cdot)]=I[\\mathbf{x}(\\cdot) + \\tau \\mathbf{y}(\\cdot)] =: i(\\tau) $$\nAlso, the function $i$ has a minimum value at $\\tau=0$ by definition of a minimizer. Therefore, if the derivative of $i$ exists, it is $i^{\\prime}(0)=0$.\nStep 2.\nAs defined above, $i$ is as follows.\n$$ i(\\tau) = \\int_{0} ^t L\\big( \\dot{\\mathbf{x}}(s) + \\tau \\dot{\\mathbf{y}}(s), \\mathbf{x}(s)+ \\tau \\mathbf{y}(s) \\big)ds $$\nSince $L$, $\\mathbf{y}$ are smooth functions, by differentiating $i$, we get the following.\n$$ i^{\\prime}(\\tau) = \\int_{0}^t \\sum_{i=1}^{n} \\left[ L_{v_{i}} ( \\dot{\\mathbf{x}} + \\tau \\dot{\\mathbf{y}}, \\mathbf{x}+ \\tau \\mathbf{y} )\\dot{y}^i + L_{x_{i}} ( \\dot{\\mathbf{x}} + \\tau \\dot{\\mathbf{y}}, \\mathbf{x}+ \\tau \\mathbf{y} ) y^i \\right] ds $$\nSubstituting $\\tau=0$, we obtain the following result from Step 1.\n$$ 0=i^{\\prime}(0) = \\int_{0}^t \\sum_{i=1}^{n} \\left[ L_{v_{i}} ( \\dot{\\mathbf{x}} , \\mathbf{x})\\dot{y}^i + L_{x_{i}} ( \\dot{\\mathbf{x}} , \\mathbf{x} )y^i \\right] ds $$\nApplying partial integration to each term of $L_{v_{i}}\\dot{y}^i$, and by the assumption $\\mathbf{y}(0)=\\mathbf{y}(t)=\\mathbf{0}$, we get the following.\n$$ \\int_{0}^t L_{v_{i}}\\dot{y}^i ds = \\left. L_{v_{i}}y^i \\right]_{0}^t- \\int_{0}^t \\dfrac{d}{ds}L_{v_{i}}y^i=\\int_{0}^t-\\dfrac{d}{ds} L_{v_{i}}y^i $$\nTherefore, the following equation holds.\n$$ 0=i^{\\prime}(0) = \\sum_{i=1}^{n} \\int_{0}^t \\left[ -\\dfrac{d}{ds} L_{v_{i}} ( \\dot{\\mathbf{x}} , \\mathbf{x})\\ + L_{x_{i}} ( \\dot{\\mathbf{x}} , \\mathbf{x} ) \\right]y^i ds $$\nThe result of Step 2. satisfies for all smooth functions $\\mathbf{y} : [0,t] \\to \\mathbb{R}^n$ that fulfill $\\eqref{eq1}$. Therefore, the value inside the brackets must be $0$. Thus, the following is true.\n$$ -\\dfrac{d}{ds} L_{v_{i}}( \\dot{\\mathbf{x}}, \\mathbf{x} ) +L_{x_{i}}( \\dot{\\mathbf{x}}, \\mathbf{x}) =0 $$\n‚ñ†\nThis result leads to the Hamiltonian equations.\nSee Also The principle of least action in physics Lawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p115-117\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1157,"permalink":"https://freshrimpsushi.github.io/en/posts/1157/","tags":null,"title":"Lagrangians and Euler-Lagrange Equations in Partial Differential Equations"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Definition Let\u0026rsquo;s assume $f : [a,b] \\to \\mathbb{R}$ is integrable over $[a,b]$ and $[a,b]$ is divided into nodes at intervals of $\\displaystyle h:= {{b-a} \\over {n}}$, like $a = x_{0} \u0026lt; \\cdots \u0026lt; x_{n} = b$. The numerical integration operator $I_{n}^{1}$, defined as follows, is called the trapezoidal rule. $$ I_{n}^{1} (f) := \\displaystyle \\sum_{k=1}^{n} {{h} \\over {2}} \\left( f(x_{k-1}) + f(x_{k} ) \\right) $$\nTheorem Let\u0026rsquo;s say $f \\in C^2 [a,b]$. The error $E_{1}^{1}$ and the asymptotic error $\\tilde{E}_{n}^{1}$ of the trapezoidal rule can be summarized as follows:\n[1]: $$E_{1}^{1} (f) = - {{1} \\over {12}} h^{3} f '' ( \\xi )$$ [2]: $$\\tilde{E}_{n}^{1} (f) = - {{ h^2 } \\over {12}} [ f '(b) - f '(a) ]$$ Explanation If we expand $I_{n}^{1} (f)$, it can be written as follows: $$ I_{n}^{1} (f) = h \\left[ {{1} \\over {2}} f(x_{0}) + f ( x_{1} ) + \\cdots + f ( x_{n-1} ) + {{1} \\over {2}} f(x_{n} ) \\right] $$ The trapezoidal rule is one of the simplest methods for calculating the numerical integration of a definite integral $\\displaystyle I (f) = \\int_{a}^{b} f(x) dx$. This method can be easily thought of even if one only knows about the method of finite sums.\nProof 1 [1] Strategy: Since the trapezoid is a linear interpolation of the given function, we can use the properties of polynomial interpolation.\n$$ I_{1}^{1} (f) := \\left( {{ b - a } \\over { 2 }} \\right) [ f(a) + f(b) ] $$ This can be regarded as approximating the integral of the function by linearly interpolating $f$ over the interval $[a,b]$ to $I(f)$. Then, the error $E_{n}^{1} (f)$ between the actual $I(f)$ and $I_{1}^{1} (f)$ for some $\\xi \\in [a,b]$ is computed as follows.\nPolynomial interpolation:\n[4] Error with the actual function: For a function $(n+1)$ times differentiable over $f : \\mathbb{R} \\to \\mathbb{R}$ and for some $\\xi \\in \\mathscr{H} \\left\\{ x_{0} , \\cdots , x_{n} \\right\\}$, the polynomial interpolation $p_{n}$ of $f$ satisfies the following for some $t \\in \\mathbb{R}$: $$ f(t) - p_{n} (t) = {{ (t - x_{0}) \\cdots (t - x_{n}) } \\over { (n+1)! }} f^{(n+1)} ( \\xi ) $$ $$ \\begin{align*} E_{1}^{1} (f) :=\u0026amp; I(f) - I_{1}^{1} (f) \\\\ =\u0026amp; \\int_{a}^{b} \\left[ f(x) - {{ f(b) ( x - a ) - f(a) (x - b) } \\over { b - a }} \\right] dx \\\\ =\u0026amp; \\int_{a}^{b} \\left[ f(x) - p_{1} (x) \\right] dx \\\\ =\u0026amp; {{1} \\over {2}} f '' ( \\xi ) \\int_{a}^{b} (x-a) (x-b) dx \\\\ =\u0026amp; \\left[ {{1} \\over {2}} f '' ( \\xi ) \\right] \\left[ - {{1} \\over {6}} (b-a)^{3} \\right] \\\\ =\u0026amp; - {{1} \\over {12}} (b-a)^{3} f '' ( \\xi ) \\\\ =\u0026amp; - {{1} \\over {12}} h^{3} f '' ( \\xi ) \\end{align*} $$\n‚ñ†\n[2] Strategy: If we derive the Riemann sums, what follows naturally deduces from the Fundamental Theorem of Calculus.\nAccording to Theorem [1], the error between the actual $I(f)$ and $I_{n}^{1} (f)$ for some $\\xi_{k} \\in [x_{k-1}, x_{k} ]$ is computed as follows: $$ \\begin{align*} \\displaystyle E_{n}^{1} (f) =\u0026amp; I (f) - I_{n}^{1} (f) \\\\ =\u0026amp; \\sum_{k=1}^{n} \\left( - {{ h^3 } \\over { 12 }} f '' ( \\xi_{k} ) \\right) \\end{align*} $$ Regarding this, $$ \\begin{align*} \\lim_{n \\to \\infty} {{ E_{n}^{1} (f) } \\over { h^2 }} =\u0026amp; \\lim_{n \\to \\infty} {{1} \\over {h^2}} \\sum_{k=1}^{n} \\left( - {{ h^3 } \\over { 12 }} f '' ( \\xi_{k} ) \\right) \\\\ =\u0026amp; - {{ 1 } \\over { 12 }} \\lim_{ n \\to \\infty} \\sum_{k=1}^{n} h f '' ( \\xi_{k} ) \\\\ =\u0026amp; - {{ 1 } \\over { 12 }} \\int_{a}^{b} f ''(x) dx \\\\ =\u0026amp; - {{ 1 } \\over { 12 }} [ f '(b) - f '(a) ] \\end{align*} $$ Therefore, $$ \\lim_{n \\to \\infty} {{\\tilde{E}_{n} (f) } \\over { E_{n} (f) }} = 1 $$\n$$ E_{n}^{1} (f) \\approx \\tilde{E}_{n}^{1} (f) = - {{ h^2 } \\over { 12 }} [ f '(b) - f '(a) ] $$\n‚ñ†\nAtkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p253.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1130,"permalink":"https://freshrimpsushi.github.io/en/posts/1130/","tags":null,"title":"Trapezoidal Rule"},{"categories":"Îß§Ìä∏Îû©","contents":"Method When you want to organize the data calculated in MATLAB into Excel and the amount of data is not too much, you can manually copy and paste. However, for a matrix of data like 128*128 shown in the picture above, that method is not feasible. In this case, you can use xlswrite to save the data into an Excel file.\nCompared to the picture above, xlswrite('test', Y) has been added at the last line. The data Y is created as an Excel file named test.\nThe Excel file has been created in the specified folder. When opened, the 128*128 matrix values are automatically organized.\nSee Also How to load data from Excel in MATLAB ","id":1150,"permalink":"https://freshrimpsushi.github.io/en/posts/1150/","tags":null,"title":"How to Save Data Calculated in MATLAB to an Excel File"},{"categories":"Îß§Ìä∏Îû©","contents":"Method To comment out a section that you want, drag to select the area and then press Ctrl+R. This will comment out the entire selected portion. To undo, drag to select the same area and press Ctrl+T, which will remove the % from each line.\n","id":1149,"permalink":"https://freshrimpsushi.github.io/en/posts/1149/","tags":null,"title":"How to Comment and Uncomment Multiple Lines at Once in MATLAB"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Definition 1 Let\u0026rsquo;s assume that $f : [a,b] \\to \\mathbb{R}$ is integrable over $[a,b]$, and $[a,b]$ is divided into nodes like $a = x_{0} \u0026lt; \\cdots \u0026lt; x_{n} = b$.\nThe integral operator $I$ is defined as $\\displaystyle I(f) := \\int_{a}^{b} f(x) dx$. The integral operator $I_{n}$ is defined as $\\displaystyle I_{n} (f) := \\sum_{k=1}^{n} \\int_{x_{k-1}}^{x_{k}} f(x) dx$. The error $E_{n}$ is defined as $E_{n} (f) := I (f) - I_{n} ( f )$. $\\displaystyle \\lim_{n \\to \\infty} {{\\tilde{E}_{n} (f) } \\over { E_{n} (f) }} = 1$, satisfying $\\tilde{E}_{n}$, is referred to as the asymptotic error for $E_{n}$. Explanation No one would dispute that calculating definite integrals is one of the goals of numerical analysis. In fact, the idea behind the method of exhaustion suggests that the more we divide the space, the better we can approximate the value of the integral. Thus, when it comes to numerical integration of interest in numerical analysis, it is about how much error there is, how to integrate when not in a closed interval, etc.\nExample Trapezoidal Rule As an example of numerical integration, let\u0026rsquo;s take a look at the trapezoidal rule for $f \\in C^2 [a,b]$. The Trapezoidal Rule approximates the value for $I(f)$ by linearly interpolating $f$ over the interval $[a,b]$ and taking the integral of that function as the approximation for $I(f)$.\n$$ I_{1}^{1} (f) := \\left( {{ b - a } \\over { 2 }} \\right) [ f(a) + f(b) ] $$ In this case, the actual error between $I(f)$ and $I_{1}^{1} (f)$ $E_{1}^{1} (f)$ can be computed as follows for some $\\xi \\in [a,b]$.\nPolynomial Interpolation:\n[4] Error with the actual function: For a differentiable $f : \\mathbb{R} \\to \\mathbb{R}$ up to $(n+1)$ times and for some $\\xi \\in \\mathscr{H} \\left\\{ x_{0} , \\cdots , x_{n} \\right\\}$, the polynomial interpolation of $f$ $p_{n}$ satisfies $\\displaystyle f(t) - p_{n} (t) = {{ (t - x_{0}) \\cdots (t - x_{n}) } \\over { (n+1)! }} f^{(n+1)} ( \\xi )$ for some $t \\in \\mathbb{R}$. $$ \\begin{align*} \\displaystyle E_{1}^{1} (f) :=\u0026amp; I(f) - I_{1}^{1} (f) \\\\ =\u0026amp; \\int_{a}^{b} \\left[ f(x) - {{ f(b) ( x - a ) - f(a) (x - b) } \\over { b - a }} \\right] dx \\\\ =\u0026amp; \\int_{a}^{b} \\left[ f(x) - p_{1} (x) \\right] dx \\\\ =\u0026amp; {{1} \\over {2}} f '' ( \\xi ) \\int_{a}^{b} (x-a) (x-b) dx \\\\ =\u0026amp; \\left[ {{1} \\over {2}} f '' ( \\xi ) \\right] \\left[ - {{1} \\over {6}} (b-a)^{3} \\right] \\\\ =\u0026amp; - {{1} \\over {12}} (b-a)^{3} f '' ( \\xi ) \\end{align*} $$\nComposite Trapezoidal Rule Now, considering dividing $[a,b]$ into $n$ intervals and approximating the integral at each $[x_{k-1} , x_{k} ]$ using the trapezoidal rule, the method is called the (Composite) Trapezoidal Rule. $$ I_{n}^{1} (f) := \\sum_{k=1}^{n} {{ h } \\over { 2 }} \\left( f (x_{k-1}) + f( x_{k} ) \\right) $$ Then, the actual error between $I(f)$ and $I_{n}^{1} (f)$ can be computed as follows for some $\\xi_{k} \\in [x_{k-1}, x_{k} ]$. $$ \\begin{align*} \\displaystyle E_{n}^{1} (f) =\u0026amp; I (f) - I_{n}^{1} (f) \\\\ =\u0026amp; \\sum_{k=1}^{n} \\left( - {{ h^3 } \\over { 12 }} f '' ( \\xi_{k} ) \\right) \\\\ =\u0026amp; - {{ h^3 n } \\over { 12 }} \\left( {{ 1 } \\over { n }} \\sum_{k=1}^{n} f '' ( \\xi_{k} ) \\right) \\end{align*} $$ Here, since $\\displaystyle \\left( {{ 1 } \\over { n }} \\sum_{k=1}^{n} f '' ( \\xi_{k} ) \\right)$ is the average of $f\u0026rsquo;\u0026rsquo; ( \\xi_{k} )$, due to the Intermediate Value Theorem, there must exist some $\\xi \\in [a,b]$ that satisfies $\\displaystyle \\min_{x \\in [a,b]} f ''(x) \\le f ''( \\xi ) \\le \\max_{x \\in [a,b]} f ''(x)$. Thus, $$ E_{n}^{1} (f) = - {{ (b-a) h^2 } \\over {12}} f '' (\\xi ) $$ Seeing the error formulated like this lets us understand that the wider the interval $[a,b]$, the larger the error becomes, and the smaller $h$ is, the more accurate it gets. However, due to $f\u0026rsquo;\u0026rsquo; ( \\xi ) $, we can\u0026rsquo;t know how much exactly it offsets. To overcome this, the asymptotic error is calculated as follows. $$ \\begin{align*} \\lim_{n \\to \\infty} {{ E_{n}^{1} (f) } \\over { h^2 }} =\u0026amp; \\lim_{n \\to \\infty} {{1} \\over {h^2}} \\sum_{k=1}^{n} \\left( - {{ h^3 } \\over { 12 }} f '' ( \\xi_{k} ) \\right) \\\\ =\u0026amp; - {{ 1 } \\over { 12 }} \\lim_{ n \\to \\infty} \\sum_{k=1}^{n} h f '' ( \\xi_{k} ) \\\\ =\u0026amp; - {{ 1 } \\over { 12 }} \\int_{a}^{b} f ''(x) dx \\\\ =\u0026amp; - {{ 1 } \\over { 12 }} [ f '(b) - f '(a) ] \\end{align*} $$ If we only know the error $E_{n}^{1} (f)$, according to the Theorem, we know that $f\u0026rsquo;\u0026rsquo; ( \\xi )$ exists but couldn\u0026rsquo;t specify its value. But now, $$ \\tilde{E}_{n}^{1} (f) := \\lim_{n \\to \\infty} E_{n}^{1} (f) $$ for sufficiently large $n$, it can be understood that $$ E_{n}^{1} (f) \\approx - {{ h^2 } \\over { 12 }} [ f '(b) - f '(a) ] = \\tilde{E}_{n}^{1} (f) $$ which makes it relatively simple and accurate to ascertain the error. Moreover, there\u0026rsquo;s no reason to stop at just knowing the extent of the error. If we can predict the error before even calculating, we can also correct for the error from the beginning. $$ I(f) - I_{n}^{1} (f) \\approx \\tilde{E}_{n}^{1} (f) \\implies I(f) \\approx I_{n}^{1} (f) + \\tilde{E}_{n}^{1} (f) $$\nCorrected Trapezoidal Rule Let\u0026rsquo;s define the operator for calculating $I(f)$ as follows. $$ CT_{n} (f) := h \\left[ {{1} \\over {2}} f (x_{0} ) + f (x_{1} ) + \\cdots + f (x_{n-1} ) + {{1} \\over {2}} f (x_{n} ) \\right] - {{ h^2 } \\over { 12 }} [ f '(b) - f '(a) ] $$\nThis method is referred to as the (Corrected) Trapezoidal Rule. [ NOTE: If you\u0026rsquo;ve followed the improvement process of the trapezoidal rule, you\u0026rsquo;d realize that there\u0026rsquo;s no need to distinguish between them explicitly. Simply calling it the trapezoidal rule would convey the meaning. ]\nImplementation The results of calculating $\\displaystyle \\int_{0}^{\\pi} e^{x} \\cos (x) dx = -{{e^{\\pi} + 1} \\over {2}} \\approx - 12.0703$ using $I_{n}^{1}$ and $CT_{n}$ are as follows.\nThe first column represents $n$, the second $\\left| I(f) - I_{n}^{1} (f) \\right|$, and the third $\\left| I(f) - CT (f) \\right|$. It can be observed that the error decreases by a factor of $\\displaystyle {{1} \\over {4}}$ when the number of nodes is doubled in the composite trapezoidal rule, and by $\\displaystyle {{1} \\over {16}}$ in the corrected trapezoidal rule. It‚Äôs evident that the corrected trapezoidal rule performs significantly better, especially in terms of speed.\nBelow is an example code written in Python.\nimport numpy as np\rdef f(x) :\rreturn np.exp(x)*np.cos(x)\rdef d(f,x,tol=10**(-8)) :\rh=1\rd1=1\rd2=0\rwhile(abs(d1-d2)\u0026gt;tol) :\rd1=d2\rd2=(f(x+h)-f(x))/h\rh=h/2\rreturn(d2)\rdef I(f,a,b,n) :\rh=(b-a)/n\rx=np.linspace(a,b,n+1)\rx=f(x)\rx[0]=x[0]/2\rx[-1]=x[-1]/2\rreturn(h*sum(x))\rdef CT(f,a,b,n) :\rh=(b-a)/n\rx=np.linspace(a,b,n+1)\rx=f(x)\rx[0]=x[0]/2\rx[-1]=x[-1]/2\rreturn(h*sum(x)-(h**2)*(d(f,b)-d(f,a))/12)\rTV=-(np.exp(np.pi)+1)/2\rprint(\u0026#34;True Value : %2.4f\u0026#34; % TV)\rprint(\u0026#34;| n | I(f) Err | CT(f) Err |\u0026#34;)\rprint(\u0026#34;=\u0026#34;*30)\rfor n in range(1,10) :\rprint(\u0026#34;| %3d | %8.2e | %8.2e |\u0026#34; % (2**n,abs(TV-I(f,0,np.pi,2**n)),abs(TV-CT(f,0,np.pi,2**n)))) Atkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p249.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1128,"permalink":"https://freshrimpsushi.github.io/en/posts/1128/","tags":null,"title":"Numerical Integration"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definitions1 Let\u0026rsquo;s define $f^{+}$ and $f^{-}$ for a function $f : X \\to \\mathbb{R}$ as follows.\n$$ \\begin{align*} f^{+} (x) \u0026amp;:= \\max \\left\\{ f(x),\\ 0 \\right\\} \\\\ f^{-} (x) \u0026amp;:= \\max \\left\\{ -f(x),\\ 0 \\right\\} \\end{align*} $$\nWe call $f^{+}$ the positive part of $f$, and $f^{-}$ the negative part of $f$.\nDescription Despite their names, both $f^{+}$ and $f^{-}$ are non-negative functions. It might not be immediately clear why these are referred to as the positive and negative parts, respectively. Let‚Äôs look at the figure below.\nAs you can see from the figure, the positive part $f^{+}$ exactly represents the parts where the value of $f$ is positive, and $f^{-}$ represents (as positive values) the parts where the value of $f$ is negative. It\u0026rsquo;s easy to see that the following formulas hold based on the above definitions.\n$$ f=f^{+} -f^{-},\\quad |f|=f^{+}+f^{-} $$\n$$ \\begin{array}{c} f^{+}=\\frac{1}{2}(|f| + f),\\quad f^{-}=\\frac{1}{2}(|f|-f) \\end{array} $$\nTheorem (1) Let\u0026rsquo;s assume that the three functions $f,g,h : X \\to \\mathbb{R}$ satisfy the conditions below.\n$$ f(x)=g(x)-h(x), \\quad \\min \\left\\{ g(x),\\ h(x) \\right\\} \\ge 0\\ \\quad \\forall\\ x \\in X $$\nThen, the following formula holds.\n$$ f^{+} (x) \\le g(x), \\quad f^{-} (x) \\le h(x) \\quad \\forall\\ x \\in X $$\nThis means that when any function is represented as the difference of two non-negative functions, the positive part $f^{+}$ and the negative part $f^{-}$ of $f$ are the smallest functions that satisfy this.\n(2) If $f$ is a measurable function, then $f^{\\pm}$ is also measurable.\nProof (1) For any $x$, since $ f(x)=g(x)-h(x)$ and $h(x) \\ge 0$, it follows that $f(x) \\le g(x)$. Also, by assumption, $0 \\le g(x)$. Because $g(x)$ is greater than or equal to both $f(x)$ and $0$, it is also greater than or equal to the larger of the two. Therefore, the following holds.\n$$ f^{+}(x) = \\max \\left\\{ f(x), 0 \\right\\} \\le g(x) $$\nFor any $x$, since $-f(x)=h(x)-g(x)$ and $g(x) \\ge 0$, it follows that $-f(x) \\le h(x)$. Also, by assumption, $0 \\le h(x)$. Because $h(x)$ is greater than or equal to both $-f(x)$ and $0$, it is also greater than or equal to the larger of the two. Therefore, the following holds.\n$$ f^{-}(x) = \\max \\left\\{ -f(x), 0 \\right\\} \\le h(x) $$\n‚ñ†\nSee Also Methods of expressing the absolute value of any function as two non-negative functions Robert G. Bartle, The Elements of Integration and Lebesgue Measure (1995), p10\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1145,"permalink":"https://freshrimpsushi.github.io/en/posts/1145/","tags":null,"title":"Methods of Expressing an Arbitrary Function as Two Non-negative Functions"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition1 Let‚Äôs call $(X, \\mathcal{E})$ a measurable space. Let\u0026rsquo;s define the set $S_{f}(\\alpha)$ as follows.\n$$ S_{f}(\\alpha):=\\left\\{ x\\in X\\ |\\ f(x) \u0026gt;\\alpha \\right\\} = f^{-1}\\left( (\\alpha, \\infty) \\right),\\quad \\forall \\alpha \\in \\mathbb{R} $$\nIf for every real number $\\alpha \\in \\mathbb{R}$, $S_{f}(\\alpha) \\in \\mathcal{E}$ holds, then the function $f : X \\to \\overline{\\mathbb{R}}$ taking extended real values is called $\\mathcal{E}$-measurable or simply measurable.\nExplanation Especially, if $X=\\mathbb{R}$, it is called Lebesgue measurable. When determining whether a function is measurable or not, it\u0026rsquo;s useful to check if it conforms to the above definition, and there\u0026rsquo;s a useful theorem for that.\nTheorem For the function $f : X \\to \\overline{\\mathbb{R}}$, the following four conditions are equivalent:\n(a) For every $\\alpha \\in \\mathbb{R}$, $A_{\\alpha} = S_{f}(\\alpha) =\\left\\{ x\\in X : f(x) \u0026gt; \\alpha \\right\\}$ $\\in$ $\\mathcal{E}$. (b) For every $\\alpha \\in \\mathbb{R}$, $B_{\\alpha}=\\left\\{ x\\in X : f(x) \\le \\alpha \\right\\}$ $\\in$ $\\mathcal{E}$. (c) For every $\\alpha \\in \\mathbb{R}$, $C_{\\alpha}=\\left\\{ x\\in X : f(x) \\ge \\alpha \\right\\}$ $\\in$ $\\mathcal{E}$. (d) For every $\\alpha \\in \\mathbb{R}$, $D_{\\alpha}=\\left\\{ x\\in X : f(x) \u0026lt; \\alpha \\right\\}$ $\\in$ $\\mathcal{E}$. Proof First, since $A_{\\alpha}$ and $B_{\\alpha}$ are complements of each other, according to the property of œÉ-algebra (D2), (a) and (b) are equivalent. Similarly, (c) and (d) are equivalent. Therefore, showing that (a) and (c) are equivalent completes the proof.\n$\\sigma$-Algebra\nLet\u0026rsquo;s say the set $X$ is given. A collection $\\mathcal{E} \\subset \\mathcal{P}(X)$ of subsets of $X$ that satisfies the below conditions is called a $\\sigma$-algebra:\n(D1) $\\varnothing, X \\in \\mathcal{E}$ (D2) $E \\in \\mathcal{E} \\implies E^c \\in \\mathcal{E}$ (D3) $E_{k} \\in \\mathcal{E}\\ (\\forall k \\in \\mathbb{N}) \\implies \\bigcup_{k=1}^\\infty E_{k} \\in \\mathcal{E}$ (D4) $E_{k} \\in \\mathcal{E}\\ (\\forall\\ k \\in \\mathbb{N}) \\implies \\bigcap_{k=1}^\\infty E_{k} \\in \\mathcal{E}$ (a) $\\implies$ (c) Assuming condition (a) holds, for every $n\\in \\mathbb{N}$, $A_{\\alpha-\\frac{1}{n}}\\in\\mathcal{E}$ holds. And $C_{\\alpha}=\\bigcap_{n=1}^\\infty A_{\\alpha-\\frac{1}{n}}$. Therefore, by definition (D3) of the $\\sigma$-algebra, $C_{\\alpha} \\in \\mathcal{E}$ holds.\n(c) $\\implies$ (a) Assuming condition (c) holds, for every $n\\in \\mathbb{N}$, $C_{\\alpha+\\frac{1}{n}}\\in\\mathcal{E}$ holds. And $A_{\\alpha}=\\bigcup_{n=1}^\\infty C_{\\alpha+\\frac{1}{n}}$. Therefore, by definition (D3) of the $\\sigma$-algebra, $A_{\\alpha} \\in \\mathcal{E}$ holds.\n‚ñ†\nRobert G. Bartle, The Elements of Integration and Lebesgue Measure (1995), p8\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1135,"permalink":"https://freshrimpsushi.github.io/en/posts/1135/","tags":null,"title":"Predictable Functions"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 Auxiliary Definitions Let\u0026rsquo;s say $A \\subset C(X)$ for $X$.\nIf for any distinct $x_{1}, x_{2} \\in X$, there always exists $f \\in A$ that satisfies $f(x_{1}) \\ne f(x_{2})$, then we say $A$ separates the points of $X$. If $X$ is a metric space and for all $\\varepsilon \u0026gt; 0$ and $f \\in C(X)$ there exists $g \\in A$ that satisfies $| g - f | \u0026lt; \\varepsilon$, then $A$ is said to be uniformly dense in $C(X)$. $C \\left( X \\right)$ is a class of continuous function spaces with domain $X$ and codomain $\\mathbb{R}$. The Stone-Weierstrass Theorem Suppose $X$ is a compact metric space. If $A$ is an algebra of $C(X)$ that includes constant functions and separates the points of $X$, then $A$ is uniformly dense in $C(X)$.\nExplanation The Stone-Weierstrass theorem assures that continuous functions can be approximated by other functions. However, this statement might feel overly abstract. The Stone-Weierstrass theorem for polynomials in $1$-dimension is written as follows:\nWeierstrass Approximation Theorem: If $f$ is continuous on $[a,b]$, for given $\\epsilon \u0026gt; 0$, there exists a polynomial function $p(x)$ satisfying $\\displaystyle \\max_{x \\in [a,b]} | f(x) - p (x) | \u0026lt; \\epsilon$.\nWhile the plain statement that $p(x)$ exists holds its charm, reflecting on its significance now, it seems overly modest. Considering $\\epsilon$ as a form of tolerance, it\u0026rsquo;s fair to say, \u0026ldquo;Given any continuous function, it can be represented by a polynomial function.\u0026rdquo;\nProof Strategy: It\u0026rsquo;s by no means easy. For $F \\in C(X)$, we specifically work with the closure $\\overline{A}$ of $A$ to find a $G$ that makes $| F - G | \u0026lt; \\varepsilon$ possible. To construct $G$, since $\\overline{A}$ is a closed algebra, we must utilize good properties, and after pinpointing such a $G$, presenting just one sequence of $A$ that converges to it concludes the process.\nPart 1. $a, b \\in \\mathbb{R} , x_{1} \\ne x_{2} \\implies \\exists f \\in A : \\begin{cases} f(x_{1}) = a \\\\ f(x_{2}) = b \\end{cases}$\nSince $A$ separates the points of $X$, for any distinct $x_{1} , x_{2}$, there exists $g \\in A$ that satisfies $g(x_{1} ) \\ne g (x_{2} )$.\nAlgebra: A set $A$ in $C(X)$ is called an algebra if it satisfies the following three conditions:\n(i): $\\emptyset \\ne A \\subset C(X)$ (ii): $f,g \\in A \\implies (f+g) , fg \\in A$ (iii): $f \\in A , c \\in \\mathbb{R} \\implies cf \\in A$ $$ f(t) := a {{ g(t) - g(x_{2} ) } \\over { g(x_{1} ) - g( x_{2} ) }} + b {{ g(t) - g(x_{1} ) } \\over { g(x_{2} ) - g( x_{1} ) }} $$\nSince $A$ is an algebra that includes constant functions, it also includes constant functions with value $g(x_{1}) , g(x_{2})$, and for $a, b \\in \\mathbb{R}$, defining $f$ as above, we have $f \\in A$, and substituting $t=x_{1} , x_{2}$ yields $f(x_{1}) = a$ and $f(x_{2} ) = b$.\nPart 2. $f_{1} ,f_{2} \\in \\overline{A} \\implies ( f_{1} \\land f_{2} ), ( f_{1} \\lor g_{2} ) \\in \\overline{A}$\n$\\land$ and $\\lor$ imply the following for $f,g \\in C(X)$ and $x \\in X$: $$ \\begin{align*} (f \\land g) (x) :=\u0026amp; \\min \\left\\{ f(x) , g(x) \\right\\} \\\\ (f \\lor g) (x) :=\u0026amp; \\max \\left\\{ f(x) , g(x) \\right\\} \\end{align*} $$\nProperty of Uniform Closure: Let\u0026rsquo;s say $A \\subset C(X)$ for the metric space $X$. If every sequence $\\left\\{ f_{n} \\in A : n \\in \\mathbb{N} \\right\\}$ of $A$ converges to some $f \\in A$ as $n \\to \\infty$, then $A$ is considered uniformly closed if $\\displaystyle | f - f_{n} | \\to 0$. If $X$ is a compact metric space and $A$ is a uniformly closed algebra of $C(X)$ that includes constant functions, the following holds: $$ f,g \\in A \\implies (f \\land g), ( f \\lor g ) \\in A $$\nConsidering the uniform closure $\\displaystyle \\overline{A} := \\left\\{ f \\in C(X) : \\lim_{n \\to \\infty} | f_{n} - f | = 0, f_{n} \\in A \\right\\}$ of $A$, since $A$ is an algebra, $\\overline{A}$ is also an algebra, and by the property of uniform closure,\n$$ f_{1} ,f_{2} \\in \\overline{A} \\implies (f_{1} \\land f_{2}), ( f_{1} \\lor f_{2} ) \\in \\overline{A} $$\nPart 3. $\\displaystyle | F - G | \u0026lt; {{\\varepsilon} \\over {2}}$\nWhenever $F \\in C(X)$ and $\\displaystyle {{\\varepsilon} \\over {2}} \u0026gt; 0$ are given, we aim to prove that $G \\in \\overline{A}$ satisfying $\\displaystyle | F - G | \u0026lt; {{\\varepsilon} \\over {2}}$ exists.\nPart 3-1. $\\displaystyle g_{x_{0}} ( x ) \u0026lt; F(x) + {{\\varepsilon} \\over {2}}$\nFixing $x_{0} \\in X$ and setting $y \\ne x_{0}$, according to Part 1, there exists a continuous function $f_{y} \\in A \\subset \\overline{A} \\subset C(X)$ satisfying\n$$ \\begin{align*} f_{y} (x_{0}) =\u0026amp; F ( x_{0} ) \\\\ f_{y} ( y ) =\u0026amp; F ( y ) \\end{align*} $$ Since $f_{y}$ and $F$ are continuous functions, $$ V_{y} := \\left\\{ x \\in X : f_{y} (x) \u0026lt; F(x) + {{ \\varepsilon } \\over { 2 }} \\right\\} $$ is an open set, and $$ X = \\bigcup_{y \\ne x_{0}} V_{y} $$ Thus, since $X$ is a compact set, there exist finite elements $y_{1} , \\cdots , y_{N_{1}} \\in X$ satisfying $$ X = \\bigcup_{i=1}^{N_{1}} V_{i} $$ Now, for $i = 1 , \\cdots , N_{1}$, if we define it as $$ \\begin{align*} f_{i} :=\u0026amp; f_{y_{i}} \\\\ g_{y_{0}} :=\u0026amp; f_{1} \\land \\cdots \\land f_{N_{1}} \\end{align*} $$ then by Part 2, we have $g_{x_{0}} \\in \\overline{A}$. Substituting $x = x_{0}$, we get $$ \\begin{align*} g_{x_{0}} ( x_{0} ) =\u0026amp; f_{1} ( x_{0} ) \\land \\cdots \\land f_{N_{1}} ( x_{0} ) \\\\ =\u0026amp; F ( x_{0} ) \\land \\cdots \\land F ( x_{0} ) \\\\ =\u0026amp; F ( x_{0} ) \\end{align*} $$ If $x \\in X$, it means that $x$ belongs to at least one of $V_{y_{1}} , \\cdots , V_{y_{N_{1}}}$, so for at least one $1 \\le k \\le N_{1}$, $$ f_{k} (x) \u0026lt; F(x) + {{\\varepsilon} \\over {2}} $$ holds, and by the definition of $g_{x_{0}}$, for all $i = 1, \\cdots , N_{1}$, $g_{x_{0}} ( x ) \\le f_{i} (x)$, thus we obtain $$ g_{x_{0}} ( x ) \u0026lt; F(x) + {{\\varepsilon} \\over {2}} $$\nPart 3-2. $\\displaystyle F(x) - {{\\varepsilon} \\over {2}} \u0026lt; G(x) \u0026lt; F(x) + {{\\varepsilon} \\over {2}}$\nSimilarly to $\\left\\{ V_{y_{i}} \\right\\}_{i=1}^{N_{1}}$, let\u0026rsquo;s define a finite collection of open sets $\\left\\{ W_{x_{i}} \\right\\}_{i=1}^{N_{2}}$ that cover $X$ as follows: $$ W_{x_{i}} := \\left\\{ x \\in X : g_{x_{i}} (x) \u0026gt; F(x) - {{ \\varepsilon } \\over { 2 }} \\right\\} $$ Just like in Part 3-1, for each $x_{1}, \\cdots , x_{N_{2}}$, the respective $g_{x_{i}}$ satisfies $$ g_{x_{i}} ( x ) \u0026gt; F(x) - {{\\varepsilon} \\over {2}} $$ for $x_{i} \\in X$. Now, let\u0026rsquo;s define the following functions for $i = 1, \\cdots , N_{2}$: $$ \\begin{align*} g_{i} :=\u0026amp; g_{x_{i}} \\\\ G :=\u0026amp; g_{1} \\lor \\cdots \\lor g_{N_{2}} \\end{align*} $$ Then, for all $x \\in X$, we have $\\displaystyle G(x) \u0026gt; F(x) - {{\\varepsilon} \\over {2}}$. Meanwhile, if $x \\in X$, it signifies that $x$ belongs to at least one of $W_{x_{1}} , \\cdots , W_{x_{N_{2}}}$, hence for at least one $j$, $$ F(x) - {{\\varepsilon} \\over {2}} \u0026lt; g_{j} \\le G(x) $$\nIn summary, for all $x \\in X$, since $\\displaystyle F(x) - {{\\varepsilon} \\over {2}} \u0026lt; G(x) \u0026lt; F(x) + {{\\varepsilon} \\over {2}}$, we derive $$ | F(x) - G(x) | \u0026lt; {{\\varepsilon} \\over {2}} $$\nPart 4. $A$ is Uniformly Dense\nSince $\\overline{A}$ is the uniform closure of $A$, there exists a sequence $\\left\\{ G_{n} \\right\\}_{n \\in \\mathbb{N}}$ of $A$ that converges to $G \\in \\overline{A}$. In other words, for all $\\displaystyle {{\\varepsilon} \\over {2}} \u0026gt;0$, there exists $N \\in \\mathbb{N}$ satisfying $$ n \\ge N \\implies | G_{n} - G | \u0026lt; {{\\varepsilon} \\over {2}} $$ For all $\\varepsilon \u0026gt; 0$ and given function $F \\in C(X)$, with $G \\in \\overline{A}$ satisfying $$ | F(x) - G(x) | \u0026lt; {{\\varepsilon} \\over {2}} $$ and $N$ satisfying $$ | G_{N} - G | \u0026lt; {{\\varepsilon} \\over {2}} $$ we always have $$ \\begin{align*} | F - G_{N} | \\le \u0026amp; | F - G | + | G - G_{N} | \\\\ =\u0026amp; {{\\varepsilon} \\over {2}} + {{\\varepsilon} \\over {2}} \\\\ =\u0026amp; \\varepsilon \\end{align*} $$ That is, for all $\\varepsilon \u0026gt; 0$ and given function $F \\in C(X)$, there always exists $G_{N} \\in A$ that satisfies $| F - G_{N} | \u0026lt; \\varepsilon$, hence $A$ is uniformly dense in $C(X)$.\n‚ñ†\nWilliam R. Wade, An Introduction to Analysis (4th Edition, 2010), p379-381\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1117,"permalink":"https://freshrimpsushi.github.io/en/posts/1117/","tags":null,"title":"Proof of the Stone-Weierstrass Theorem"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Buildup Although it is true that computers are overwhelmingly faster at numerical calculations than humans, it isn\u0026rsquo;t because they understand transcendental functions or irrational numbers. For instance, when asked to calculate $\\displaystyle \\sin {{ \\pi } \\over {6}} = {{1} \\over { 2 }}$, instead of drawing a right triangle and finding the ratio of the hypotenuse to the height using the geometric definition of trigonometric functions, it uses polynomial functions to expand into a series and calculates it through basic arithmetic.\nFrom the computer\u0026rsquo;s perspective, it doesn\u0026rsquo;t particularly care what $\\displaystyle \\sin x \\approx x - {{x^3} \\over {3!}} + {{x^5} \\over {5!}}$ truly means. It just uses the polynomial equation available because it can perform arithmetic operations faster than humans. And the existence of such polynomial functions is always guaranteed by the following theorem.\nStone-Weierstrass Theorem: If $f$ is continuous on $[a,b]$, then for a given $\\epsilon \u0026gt; 0$, there exists a polynomial function $p(x)$ satisfying $\\displaystyle \\max_{x \\in [a,b]} | f(x) - p (x) | \u0026lt; \\epsilon$.\nHowever, thinking about it \u0026lsquo;from the computer\u0026rsquo;s standpoint\u0026rsquo;, it\u0026rsquo;s clear that calculating numbers like $\\displaystyle {{\\pi^{31} } \\over {31!}}$ can be quite challenging for computers as well. First of all, both the numerator and the denominator are pretty long, so just storing the large numbers before even starting the calculation is a task, not to mention it doesn\u0026rsquo;t have the concept of altering the order of operations to reduce calculation time like humans do. [ NOTE: In fact, such techniques are implemented in applied mathematics fields like cryptography using algorithms like Exponentiation by Squaring. ] Moreover, \u0026lsquo;from the human\u0026rsquo;s standpoint\u0026rsquo;, it\u0026rsquo;s known that Taylor series only assure convergence at sufficiently small $(-h, h)$, which essentially means the calculation using Taylor\u0026rsquo;s formula is pointwise.\nAlthough Taylor expansion is theoretically one of the most powerful tools in the history of mathematics, from the considerations above, it\u0026rsquo;s understandable that it may not be the best formula for numerical calculations1. In other words, if one wishes to calculate $f(x)$ as $$ f(x) \\approx \\sum_{k=0}^{n} a_{k} \\varphi_{n} (x) $$, then $\\displaystyle \\left\\{ \\varphi_{n} (x) = {{x^{n}} \\over {n!}} : n \\ge 0 \\right\\}$ is not a good basis.\nGram-Schmidt Process: Every finite-dimensional inner product space has an orthonormal basis.\nFortunately, since the set of polynomial functions $\\mathbb{Q} [ x ]$ forms a finite-dimensional normed vector space, it\u0026rsquo;s guaranteed to possess an orthonormal basis. In numerical analysis, the focus is particularly on bases with the following properties:\nWhat Makes a Good Basis? (i): $\\displaystyle p_{n} (x)$ should be represented as a linear combination of $\\displaystyle \\left\\{ \\varphi_{n} (x) \\in \\mathbb{Q} [ x ] : n \\ge 0 \\right\\}$, and there should exist $n \\in \\mathbb{N}$ that makes $\\displaystyle \\max_{x \\in [a,b]} | f(x) - p_{n} (x) |$ as small as desired. (ii): It\u0026rsquo;s preferable for $p_{n} (x)$ to be calculated as $\\displaystyle p_{n} (x) = \\sum_{k=0}^{n} a_{k} \\varphi_{n} (X)$. That is, it\u0026rsquo;s better to add new terms for reducing errors rather than completely recalculating each time. (iii): It\u0026rsquo;s good for $| a_{n} |$ to converge quickly to $0$. In other words, the fewer terms added, the quicker the convergence. The reason for considering the set of polynomial functions with rational coefficients $\\mathbb{Q} [ x ]$ instead of $\\mathbb{R} [ x ]$ is simple. It\u0026rsquo;s because computers can\u0026rsquo;t understand irrational numbers when performing numerical calculations.\nAtkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p199.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1107,"permalink":"https://freshrimpsushi.github.io/en/posts/1107/","tags":null,"title":"Function Approximation in Numerical Analysis"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition A power series is denoted by $S(x) : = \\sum \\limits_{k=0}^{\\infty} a_{k} ( x - x_{0} )^{k}$, and the Center of $S(x)$ is denoted by $x_{0}$. When $S(x)$ converges absolutely for $|x - x_{0}| \u0026lt; R$ and diverges for $|x - x_{0}| \u0026gt; R$, $R$ is called the Radius of Convergence of $S(x)$. The largest interval on which $S(x)$ converges is called the Interval of Convergence. If there exists a power series $\\sum \\limits_{k=0}^{\\infty} a_{k} ( x - x_{0} )^{k} = f(x)$ centered at $x_{0} \\in (c,d)$ in the interval of convergence $[c,d] \\subset (a,b)$, then $f$ is said to be Analytic at $(a,b)$. If for all $n$, $a_{n}=b_{n}$ holds, then two power series $\\sum \\limits_{n=0}^\\infty a_n(x-x_0) ^n$ and $\\sum \\limits_{n=0}^\\infty b_n(x-x_0) ^n$ are considered equal. If $a_0=a_1=a_2=\\cdots=0$ then $\\sum \\limits_{n=0}^\\infty a_n(x-x_0)^{n}=0,\\quad \\forall x$ Explanation For someone studying Analysis for the first time in their undergraduate course, it might be unclear why \u0026lsquo;Calculus\u0026rsquo; and \u0026lsquo;Analysis\u0026rsquo; are separated, and why Analysis focuses so much on sequences and series. However, if one has studied up to power series without losing interest, they might get at least a hint.\nIf asked why one studies Analysis, it\u0026rsquo;s reasonable to answer \u0026rsquo;to bring down difficult functions to easier ones\u0026rsquo;. For example, transcendental functions are difficult, but polynomials are easy. If that transcendental function is analytic, it is fortunate. Analytic functions are those that can be expanded into series, and a function that can be expressed as a series can, in turn, be resolved into a sum of polynomials.\nPower series are a key concept in basic Analysis, especially with many conditions attached to their convergence. Despite being infinite series, they are surprisingly \u0026lsquo;sensible\u0026rsquo; and have many good properties.\nSummary (a) If $R := \\lim_{k \\to \\infty} {{ | a_{k} | } \\over { | a_{k+1} | }}$ exists, then $R$ is the radius of convergence of $S(x)$. (b) If the radius of convergence $R \u0026gt; 0$ exists, then $S(x)$ diverges for all $x \\notin [ x_{0} - R , x_{0} + R ]$. (c) If the radius of convergence $R \u0026gt; 0$ exists, then $S(x)$ converges absolutely for all $x \\in ( x_{0} - R , x_{0} + R )$. (d) If the radius of convergence $R \u0026gt; 0$ exists, then $S(x)$ converges uniformly on all $[a,b] \\subset ( x_{0} - R , x_{0} + R )$. (e) If the radius of convergence $R \u0026gt; 0$ exists, then $S(x)$ is continuous on $( x_{0} - R , x_{0} + R )$. (f) If the radius of convergence $R \u0026gt; 0$ exists, then $S(x)$ is infinitely differentiable on $( x_{0} - R , x_{0} + R )$ $$ S^{(k)} (x) = \\sum \\limits_{n=k}^{\\infty} {{n!} \\over {(n-k)!}} a_{n} (x - x_{0} )^{n-k} $$ (g) If $S(x)$ converges on $[a,b]$, it is integrable on $[a,b]$ $$ \\int_{a}^{b} S(x) dx = \\sum \\limits_{k=0}^{\\infty} a_{k} \\int_{a}^{b} (x - x_{0} )^{k} dx $$ See Also Generating Functions ","id":1090,"permalink":"https://freshrimpsushi.github.io/en/posts/1090/","tags":null,"title":"Power Series"},{"categories":"Ìë∏Î¶¨ÏóêÌï¥ÏÑù","contents":"Buildup The process of deriving the Fourier transform also derived the definition of the inverse transform. However, this was simply explained to aid understanding, and the transformation formula was not accurately derived. The Fourier inverse transformation is as follows:\n$$ \\begin{equation} f(x) =\\dfrac{1}{2\\pi} \\int \\hat{f}(\\xi) e^{i\\xi x}d\\xi \\end{equation} $$\nThis equation implies that from $f$, we can obtain $\\hat{f}$ and from $\\hat{f}$, we can retrieve $f$ again. This might seem obvious or trivial, but it\u0026rsquo;s not at all. For instance, consider differentiation and integration. When we differentiate a polynomial, we lose the constant term, which cannot be retrieved through integration. However, the Fourier transform preserves information. From $f$, we obtain the Fourier transform $\\hat{f}$, and by applying the inverse transform to this $\\hat{f}$, we can obtain $f$ exactly as it was.\n$$ \\begin{equation} \\hat{f} (\\xi) := \\int f(x) e^{-i\\xi x}dx \\end{equation} $$\nWhen defining the Fourier transform as above, $(1)$ becomes its inverse as demonstrated below.\nFourier Inverse Transform Theorem Let\u0026rsquo;s define the Fourier transform of $f$ as $\\hat{f}$ in $(2)$. Assume $f$ is integrable and piecewise continuous. At points of discontinuity, $f$ is defined as follows:\n$$ f(x)=\\dfrac{1}{2} \\big[ f(x-)+f(x+)\\big] $$\nThen, the following equation holds:\n$$ f(x)=\\lim \\limits_{\\epsilon \\rightarrow 0}\\dfrac{1}{2\\pi}\\int\\hat{f}(\\xi)e^{i\\xi x}e^{-\\epsilon^2\\xi^2/2}d\\xi $$\nMoreover, if we assume that $\\hat{f} \\in$ is $L^1$, then $f$ is continuous and\n$$ f(x) =\\dfrac{1}{2\\pi}\\int\\hat{f}(\\xi) e^{i\\xi x}d\\xi = \\mathcal{F}^{-1}[\\hat{f}] (x) $$\nCorollary If we assume $\\hat{f}=\\hat{g}$, then $f=g$ follows.\nProof $$ f=\\mathcal{F}^{-1}[\\hat{f}]=\\mathcal{F}^{-1}[\\hat{g}] $$\nTherefore,\n$$ f=\\mathcal{F}^{-1}[\\hat{g}]=\\mathcal{F}^{-1}\\mathcal{F}[g]=g $$\n‚ñ†\nExplanation Upon observing this corollary, one might think, \u0026lsquo;Isn\u0026rsquo;t this obvious?\u0026rsquo; but it\u0026rsquo;s not at all. Consider the operation of differentiation. Suppose $f(x)=x^2+1$, $g(x)=x^2+4$. In this case, the fact that $f^{\\prime}(x)=2x=g^{\\prime}(x)$ does not guarantee $f(x)=g(x)$.\nProof Strategy:\nTo solve the problem easily, a cutoff function will be used. A cutoff function has the effect of cutting off outside a certain range when multiplied and taken to a limit, hence the name. It is used to maintain the original value near the origin and to converge to $0$ as it moves away from the origin. It\u0026rsquo;s a concept similar to a mollifier. If this explanation is difficult to understand, it\u0026rsquo;s okay to skip it. Either way, such a cutoff function will be multiplied into the equation to derive the inverse transformation.\n$$ \\eta (\\xi)=\\dfrac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}, \\quad \\eta_\\epsilon (\\xi)=\\dfrac{1}{\\epsilon}\\eta \\left( \\frac{\\xi}{\\epsilon} \\right)=\\dfrac{1}{\\epsilon\\sqrt{2\\pi}}e^{-\\frac{x^2}{2\\epsilon^2}} $$\nMultiplying this cutoff function yields\n$$ \\dfrac{1}{2\\pi}\\int\\hat{f} (\\xi) e^{i\\xi x}e^{-\\epsilon^2\\xi^2/2}d\\xi $$\nThis equation, by the definition of the Fourier transform, is as follows.\n$$ \\dfrac{1}{2\\pi}\\int \\int f(y) e^{-i\\xi y}dy e^{i\\xi x}e^{-\\epsilon^2\\xi^2/2}d\\xi $$\nUsing the definition of the Fourier transform and convolution, among others, the equation is transformed as follows:\n$$ \\begin{align*} \\dfrac{1}{2\\pi}\\int \\int f(y) e^{-i\\xi y}dy e^{i\\xi x}e^{-\\epsilon^2\\xi^2/2}d\\xi \u0026amp;= \\dfrac{1}{2\\pi}\\int {\\color{blue}\\int} f(y) {\\color{blue}e^{-i\\xi (y-x)}e^{-\\epsilon^2\\xi^2/2}}dy {\\color{blue}d\\xi} \\\\ \u0026amp;= \\dfrac{1}{2\\pi}\\int {\\color{blue}\\mathcal{F} \\left[ e^{-\\epsilon^2 \\xi^2 /2}\\right] (y-x)} f(y) dy \\\\ \u0026amp;= \\dfrac{1}{2\\pi}\\int {\\color{blue}\\sqrt{\\dfrac{2\\pi}{\\epsilon^2}}e^{-\\frac{(y-x)^2}{2\\epsilon^2}}} f(y) dy \\\\ \u0026amp;= \\int \\dfrac{1}{\\epsilon \\sqrt{2\\pi}} e^{-\\frac{(x-y)^2}{2\\epsilon^2}} f(y) dy \\\\ \u0026amp;= \\int \\eta_\\epsilon (x-y)f(y) dy \\\\ \u0026amp;= f \\ast \\eta_\\epsilon (x) \\end{align*} $$\nThe third equality used the formula below.\nFourier Transform of a Gaussian Function\nThe Fourier transform of a Gaussian function $f(x)=e^{-Ax^2}$ is as follows:\n$$ \\mathcal{F}[f] (\\xi) = \\mathcal{F} \\left[ e^{-Ax^2} \\right] (\\xi)=\\sqrt{\\frac{\\pi}{A}}e^{-\\frac{\\xi ^2}{4A}} $$\nThen, assuming $f$ is piecewise continuous, the mollification of $f$ converges as follows.\n$$ \\begin{align*} \\lim \\limits_{\\epsilon \\rightarrow 0} \\dfrac{1}{2\\pi}\\int\\hat{f} (\\xi) e^{i\\xi x}e^{-\\epsilon^2\\xi^2/2}d\\xi \u0026amp;= \\lim \\limits_{\\epsilon \\rightarrow 0} f \\ast \\eta_\\epsilon (x) \\\\ \u0026amp;= \\dfrac{1}{2} \\big[ f(x-)+f(x+)\\big] \\\\ \u0026amp;= f(x) \\end{align*} $$\nFurthermore, assuming $\\hat{f} \\in L^1$,\n$$ \\left| e^{i\\xi x}e^{-\\epsilon^2|\\xi|^2 /2} \\hat{f}(\\xi) \\right| \\le \\left| \\hat{f}(\\xi) \\right| $$\nthus, by the Dominated Convergence Theorem,\n$$ \\begin{align*} f(x) \u0026amp;= \\lim \\limits_{\\epsilon \\rightarrow 0} \\dfrac{1}{2\\pi}\\int\\hat{f} (\\xi) e^{i\\xi x}e^{-\\epsilon^2\\xi^2/2}d\\xi \\\\ \u0026amp;= \\dfrac{1}{2\\pi}\\int \\lim \\limits_{\\epsilon \\rightarrow 0} \\hat{f} (\\xi) e^{i\\xi x}e^{-\\epsilon^2\\xi^2/2}d\\xi \\\\ \u0026amp;= \\dfrac{1}{2\\pi}\\int \\hat{f} (\\xi) e^{i\\xi x}d\\xi \\end{align*} $$\nTherefore,\n$$ f(x)=\\dfrac{1}{2\\pi}\\int \\hat{f} (\\xi) e^{i\\xi x}d\\xi $$\n‚ñ†\n","id":1112,"permalink":"https://freshrimpsushi.github.io/en/posts/1112/","tags":null,"title":"Fourier Inversion Theorem"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Model 1 An operator defined as $\\nabla_{s} Y_{t} := Y_{t} - Y_{t-s}$ is called the Seasonal Difference. If $W_{t} := \\nabla^{d} \\nabla_{s}^{D} Y_{t}$ is defined as $\\left\\{ W_{t} \\right\\}_{t \\in \\mathbb{N}}$, and if $ARMA(P,Q)$ and $\\left\\{ Y_{t} \\right\\}_{t \\in \\mathbb{N}}$ is $ARMA(p,q)$, then $\\left\\{ Y_{t} \\right\\}_{t \\in \\mathbb{N}}$ is called a Seasonal ARIMA process $ARIMA(p,d,q)\\times(P,D,Q)_{s}$. This form is called the Seasonal ARIMA model. Explanation Today\u0026rsquo;s temperature is, of course, mostly influenced by yesterday\u0026rsquo;s temperature, but fundamentally, it is hot in the summer and cold in the winter. There may be unusually cold days or exceptionally warm winters, but globally, it must follow the seasons. Such a macroscopic cyclical characteristic is called Seasonality.\nFor example, AirPassenger is data on the number of airline passengers monthly from 1949 to 1960, showing a pattern of peaking during the vacation season in summer and gradually decreasing. There are years with more or less traffic, and there is a tendency for an increase over the years, but still, there is a clear seasonality on an annual cycle.\nOf course, seasonality needn\u0026rsquo;t necessarily be related to the \u0026lsquo;seasons\u0026rsquo;; it can refer to weekly trends depending on the day of the week, daily cycles, or even turns in a board game. If there is a sequence, it can eventually be seen as time series data, but abstractly approached, it does not even need to relate to time properties.\nThe definition of the Seasonal ARIMA process might look quite complex at first glance, but its concept doesn‚Äôt go beyond that of an ARIMA process. Mathematically, it only looks messy due to the extended differences; obtaining some elegant insights is difficult. It\u0026rsquo;s reasonable to just consider it as \u0026rsquo;there\u0026rsquo;s a larger flow\u0026rsquo;.\nCryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p233~234.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1067,"permalink":"https://freshrimpsushi.github.io/en/posts/1067/","tags":null,"title":"Seasonal ARIMA Model"},{"categories":"Ìë∏Î¶¨ÏóêÌï¥ÏÑù","contents":"Theorem[^1] Let\u0026rsquo;s consider $\\cal{F}f, \\hat{f}$ as the Fourier transform of $f$. Let $f \\in L^{1}$. Then, the following properties hold for the Fourier transform:\n(a) For any real number $a$, $$ \\mathcal{F} \\left[ f(x-a) \\right] ( \\xi ) = e^{-ia\\xi}\\hat{f}(\\xi) \\quad \\mathrm{and} \\quad \\mathcal{F} \\left[ e^{iax}f(x)\\right] (\\xi) = \\hat{f}(\\xi-a) $$\n(b) Define $f_\\delta (x) := \\frac{1}{\\delta}f ( \\frac{x}{\\delta} )$ for $\\delta \u0026gt;0$. Then, $$ \\mathcal{F}\\left[ f_\\delta \\right] (\\xi ) = (\\mathcal{F}f)(\\delta \\xi) \\quad \\mathrm{and} \\quad \\mathcal{F} \\left[ f(\\delta x) \\right] (\\xi) = ( \\mathcal{F} f ) _{\\delta} (\\xi) $$\n(c) Assume $f$ is continuous and piecewise smooth. Then, $$ \\mathcal{F} \\left[ f^{\\prime} \\right] (\\xi) = i \\xi \\mathcal{F} f (\\xi) $$\nMeanwhile, if $xf(x)$ is integrable,\n$$ \\mathcal{F} \\left[ xf(x) \\right] (\\xi) = i ( \\mathcal{F} f ) ^{\\prime} (\\xi) $$\n(d) If $g\\in L^{1}$, $$ \\mathcal{F} \\left[ f \\ast g \\right] (\\xi)= \\hat{f} (\\xi) \\hat{g}(\\xi) $$\nHere, $f \\ast g$ is the convolution of $f$ and $g$.\n(d\u0026rsquo;) For $\\left\\{ f_{n} \\right\\} \\subset L^{1}$, $$ \\mathcal{F}\\left[ f_{1} \\ast f_{2} \\ast \\cdots \\ast f_{n} \\right]=\\hat{f_{1}} \\hat{f_{2}} \\cdots \\hat{f_{n}} $$\nExplanation (a) This means the operations of translation and multiplication by an exponential function switch under the transformation. Translating and then transforming multiplies by an exponential function, and multiplying by an exponential function and then transforming results in translation. (b) Similarly, multiplying the variable by $\\delta$ and taking the operation of $_\\delta$ on the function switch under the transformation. (c) The derivative\u0026rsquo;s Fourier transform is the same as multiplying the Fourier transform by a constant $i\\xi$.\nProof (a) $$ \\begin{align*} \\mathcal{F} \\left[ f(x-a) \\right] (\\xi) \u0026amp;= \\int f(x-a)e^{-i\\xi x} dx \\\\ \u0026amp;= \\int f(y)e^{-i\\xi (y+a)} dy \\\\ \u0026amp;= e^{-ia\\xi} \\int f(y)e^{-i\\xi y}dy \\\\ \u0026amp;= e^{-ia\\xi} \\hat{f}(\\xi) \\end{align*} $$\nThe second equality holds by substitution with $x-a=y$.\n$$ \\begin{align*} \\mathcal{F}\\left[ e^{iax}f(x) \\right] (\\xi) \u0026amp;= \\int f(x)e^{-i\\xi x}e^{iax} dx \\\\ \u0026amp;= \\int f(x) e^{-i(\\xi-a)x}dx \\\\ \u0026amp;= \\hat{ f }(\\xi-a) \\end{align*} $$\nThe third equality follows from the definition of the Fourier transform.\n‚ñ†\n(b) Similarly to (a), it can be easily proved.\n$$ \\begin{align*} \\mathcal{F} \\left[ f_\\delta \\right] (\\xi) \u0026amp;= \\displaystyle {\\int} f_\\delta (x) e^{-i\\xi x} dx \\\\ \u0026amp;= {\\displaystyle \\int} \\dfrac{1}{\\delta}f \\left( \\frac{x}{\\delta} \\right)e^{-i\\xi x} dx \\\\ \u0026amp;= \\displaystyle{ \\int} f(y) e^{-i(\\delta \\xi )y} dy \\\\ \u0026amp;= \\hat{f}(\\delta\\xi) \\end{align*} $$\nThe second equality holds by substitution with $\\frac{x}{\\delta}=y$.\n$$ \\begin{align*} \\mathcal{F} \\left[ f(\\delta x) \\right] (\\xi) \u0026amp;= \\displaystyle{ \\int} f(\\delta x)e^{-i\\xi x}dx \\\\ \u0026amp;= \\dfrac{1}{\\delta} \\displaystyle{ \\int} f(y)e^{-i(\\xi / \\delta)y} dy \\\\ \u0026amp;= \\dfrac{1}{\\delta} \\hat{f} ( \\xi / \\delta) \\\\ \u0026amp;= \\hat{f}_{\\delta}(\\xi) = ( \\mathcal{F }f )_{\\delta} (\\xi) \\end{align*} $$\nThe third equality holds by substitution with $\\delta x=y$.\n‚ñ†\n(c) First,\n$$ \\int_{0}^\\infty f^{\\prime}(x)dx=\\lim \\limits_{t \\rightarrow \\infty} \\int_{0}^tf^{\\prime}(x)dt=\\lim \\limits_{t \\rightarrow \\infty} f(t)-f(0) $$\nand since $f^{\\prime} \\in L^{1}$, $\\displaystyle \\int f^{\\prime}(x)dx$ exists, and therefore $\\lim \\limits_{t \\rightarrow \\infty} f(t)$ exists. By assumption, because $f \\in L^{1}$, its value is $0$. This is the same even when $\\lim \\limits_{t \\rightarrow -\\infty}f(t)$, so\n$$ \\begin{equation} \\lim \\limits_{x \\rightarrow \\pm \\infty} f(x)=0 \\label{eq1} \\end{equation} $$\nTherefore,\n$$ \\begin{align*} \\mathcal{F} \\left[ f^{\\prime} \\right] (\\xi) \u0026amp;= \\int f^{\\prime}(x)e^{-i\\xi x} dx \\\\ \u0026amp;= \\left[ e^{-i\\xi x} f(x)\\right]_{-\\infty}^\\infty + i\\xi \\int f(x) e^{-i \\xi x} dx \\\\ \u0026amp;= i \\xi \\int f(x) e^{-i\\xi x}dx \\\\ \u0026amp;= i \\xi \\hat{f}(\\xi) \\end{align*} $$\nThe second equality follows from partial integration. The third equality holds by $\\eqref{eq1}$.\n$$ \\begin{align*} \\mathcal{F} \\left[ xf(x) \\right] (\\xi) \u0026amp;= \\int x f(x)e^{-i \\xi x}dx \\\\ \u0026amp;= i\\dfrac{d}{d\\xi} \\int f(x) e^{-i \\xi x}dx \\\\ \u0026amp;= i\\dfrac{d}{d \\xi} \\mathcal{F} f (\\xi) \\\\ \u0026amp;= i (\\mathcal{F} f )^{\\prime}(\\xi) \\end{align*} $$\n‚ñ†\n(d) Considering the general definition of convolution, (d) is in fact a definition rather than a property.\n$$ \\begin{align*} \\mathcal{F} \\left[ f \\ast g \\right] (\\xi) \u0026amp;= \\int (f \\ast g)(x)e^{-i \\xi x}dx \\\\ \u0026amp;= \\int \\left[ \\int f(x-y)g(y)dy\\right]e^{-i \\xi x}dx \\\\ \u0026amp;= \\int \\left[ \\int f(x-y)g(y)dy\\right]e^{-i \\xi (x-y)}e^{-i\\xi y}dx \\\\ \u0026amp;= \\int \\int f(x-y)g(y)e^{-i \\xi (x-y)}e^{-i\\xi y}dydx \\\\ \u0026amp;= \\int \\int f(x-y)g(y)e^{-i \\xi (x-y)}e^{-i\\xi y}dxdy \\\\ \u0026amp;= \\int \\left[ \\int f(x-y)e^{-i \\xi (x-y)}dx \\right] g(y)e^{-i \\xi y} dy \\\\ \u0026amp;= \\int \\left[ \\int f(z)e^{-i \\xi z}dz \\right] g(y)e^{-i \\xi y} dy \\\\ \u0026amp;= \\int \\hat{f}(\\xi) g(y)e^{-i \\xi y} dy \\\\ \u0026amp;= \\hat{f}(\\xi)\\int g(y)e^{-i \\xi y} dy \\\\ \u0026amp;= \\hat{f}(\\xi) \\hat{g}(\\xi) \\end{align*} $$\nThe seventh equality holds by substitution with $x-y=z$.\n‚ñ†\n(d') Since convolution is associative, it immediately follows from (d).\n‚ñ†\n","id":1101,"permalink":"https://freshrimpsushi.github.io/en/posts/1101/","tags":null,"title":"Properties of Fourier Transform"},{"categories":"Ìï®Ïàò","contents":"Given a function $f : X \\to Y$, let $a, b \\in X$, $a_{i} \\in X\\ (i=1,\\cdots)$.\nSubadditive Function A function $f$ is called a subadditive function when it satisfies the following equation:\n$$ f(a+b) \\le f(a)+f(b) $$\nThe absolute value is an example.\n$$ |3+(-4)| \\le |3|+|-4| $$\nAnother example, if we have $f(x)=2x+3$ then\n$$ 13=f(2+3) \\le f(2)+f(3)=7+9=16 $$\nAdditive Function A function $f$ is called an additive function when it satisfies the following equation:\n$$ f(a+b) = f(a)+f(b) $$\nThis is the case where equality holds in subadditivity.\nFor example, if $f(x)=4x$\n$$ 20=f(2+3)=f(2)+f(3)=20 $$\nIf set $E_{1},\\ E_2$ satisfies $E_{1} \\cap E_2 = \\emptyset$ and let the number of elements in $n(E_{i})=E_{i}$ be\n$$ n(E_{1} \\cup E_2) = n(E_{1}) + n(E_2) $$\nCountably Subadditive Function A function $f$ is called a countably subadditive function when it satisfies the following equation:\n$$ f \\left( \\sum_{i=1}^\\infty a_{i} \\right) \\le \\sum \\limits_{i=1}^\\infty f(a_{i}) $$\nFrom subadditivity and additivity, it can be seen that this also holds for any arbitrary number of $N$ elements. If it holds for a countable number of elements, it is said to have countable subadditivity. An example of countable subadditivity is outer measure.\nCountably Additive Function A function $f$ is called a countably additive function when it satisfies the following equation:\n$$ f \\left( \\sum_{i=1}^\\infty a_{i} \\right) = \\sum \\limits_{i=1}^\\infty f(a_{i}) $$\nThis is the case where equality holds in countable subadditivity.\nFor distinct elements, the outer measure is countably additive. If $E_{i} \\cap E_{j} =\\emptyset \\quad \\forall\\ i,j$ then\n$$ \\mu^{\\ast} \\left( \\bigsqcup _{i=1}^\\infty E_{i} \\right) = \\sum _{i=1}^\\infty \\mu^{\\ast}(E_{i}) $$\nSubmultiplicative Function A function $f$ is called a submultiplicative function when it satisfies the following equation:\n$$ f(ab) \\le f(a)f(b) $$\nThis applies the same properties of addition to multiplication.\nMultiplicative Function A function $f$ is called a multiplicative function when it satisfies the following equation:\n$$ f(ab) = f(a)f(b) $$\nThis is the case where equality holds in submultiplicativity.\n","id":1096,"permalink":"https://freshrimpsushi.github.io/en/posts/1096/","tags":null,"title":"Additive and Multiplicative Functions"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Description Let $\\Omega \\subset \\mathbb{R}^{n}$ be called an open set. Suppose we are given two constants $1 \\lt p \\lt \\infty, 1 \\lt p^{\\prime} \\lt \\infty$ that satisfy the following equation:\n$$ \\dfrac{1}{p} + \\dfrac{1}{p^{\\prime}} = 1 \\left(\\text{or } p^{\\prime} = \\frac{p}{p-1} \\right) $$\nIf $u \\in L^p(\\Omega)$, $v\\in L^{p^{\\prime}}(\\Omega)$, then $uv \\in L^1(\\Omega)$ and the inequality below holds.\n$$ \\| uv \\|_{1} = \\int_{\\Omega} |u(x)v(x)| dx \\le \\| u \\|_{p} \\| v \\|_{p^{\\prime}} $$\nThe inequality in the above theorem is called the H√∂lder\u0026rsquo;s inequality. From H√∂lder\u0026rsquo;s inequality, the following two corollaries can easily be shown to hold.\nTheorem1 Theorem 1 Suppose three constants $p\u0026gt;0, q\u0026gt;0, r\u0026gt;0$ satisfy $\\dfrac{1}{p} + \\dfrac{1}{q} = \\dfrac{1}{r}$ and if $u \\in {L}^{p}(\\Omega), v \\in {L}^{q}(\\Omega)$, then $uv \\in L^{r}(\\Omega)$ and the inequality below holds.\n$$ \\| uv \\|_{r} = \\left( \\int_{\\Omega} |u(x)v(x)|^{r} dx \\right)^{1/r} \\le \\| u \\|_{p} \\| v \\|_{q} $$\nIn the case of $r=1$, it equals H√∂lder\u0026rsquo;s inequality.\nProof By assumption,\n$$ \\dfrac{1}{p}+\\dfrac{1}{q}=\\dfrac{1}{r} \\implies \\dfrac{1}{p/r}+\\dfrac{1}{q/r}=1 $$\nAnd since we assumed that $u \\in L^p(\\Omega)$, $\\left( \\int_{\\Omega}|u|^p dx \\right)^{1/p} \u0026lt; \\infty$, therefore,\n$$ \\left( \\int_{\\Omega}|u^r|^{\\frac{p}{r}} dx \\right)^{1/p} \u0026lt; \\infty \\implies \\left( \\int_{\\Omega}|u^r|^{\\frac{p}{r}} dx\\right)^{r/p} \u0026lt; \\infty $$\nThus, $u^r \\in {L}^{p/r}(\\Omega)$ and $v^r \\in{L}^{q/r}(\\Omega)$ can be confirmed in the same way. So by H√∂lder\u0026rsquo;s inequality,\n$$ \\int_{\\Omega} |u(x)v(x)|^{r} dx = \\int_{\\Omega} |u^{r}(x)v^{r}(x) | dx \\le \\| u^r \\|_{p/r} \\|v^r\\|_{q/r} $$\nRewriting the right side in integral form,\n$$ \\begin{align*} \\int_{\\Omega} |u(x)v(x)|^{r} dx \\le\u0026amp; \\left(\\int_{\\Omega} |u(x)^{r}|^{p/r} dx \\right)^{q/p} \\left(\\int_{\\Omega} |v(x)^r|^{q/r} dx \\right)^{r/q} \\\\ =\u0026amp;\\ \\left(\\int_{\\Omega}|u(x)|^{p} dx \\right)^{r/p} \\left(\\int_{\\Omega} |v(x)|^{q} dx \\right)^{r/q} \\end{align*} $$\nTaking the power of $\\dfrac{1}{r}$ to both sides,\n$$ \\left( \\int_{\\Omega} |u(x)v(x)|^rdx \\right)^{1/r} \\le \\left(\\int_{\\Omega}|u(x)|^{p} dx \\right)^{1/p} \\left(\\int_{\\Omega} |v(x)|^{q} dx \\right)^{1/q} $$\nTherefore,\n$$ \\| uv \\|_{r} = \\left( \\int_{\\Omega} |u(x)v(x)|^rdx \\right)^{1/r} \\le \\| u \\|_{p} \\| v\\|_{q} $$\n‚ñ†\nTheorem 2 Let\u0026rsquo;s say for $1\\le j \\le N$, $p_{j}\u0026gt;0$ and $\\sum\\limits_{j=1}^N\\dfrac{1}{{p}_{j}}=\\dfrac{1}{{p}_{1}}+\\dfrac{1}{{p}_2}+\\cdots+\\dfrac{1}{{p}_{N}}=\\dfrac{1}{r}$. And suppose $u=\\prod _{j=1}^N u_{j}=u_{1}u_2\\dots u_{N}$ and $u_{j}\\in L^{{p}_{j}}(\\Omega)$. Then $u\\in {L}^r (\\Omega)$ and the inequality below holds.\n$$ \\| u \\|_{r} = \\left( \\int_{\\Omega} |u(x)|^{r} dx \\right)^{1/r} \\le \\prod_{j=1}^{N} \\| u_{j} \\|_{{p}_{j}} = \\| u_{1} \\|_{{p}_{1}} \\cdots \\| u_{N} \\|_{p_{N}} $$\nThe above Theorem 1 can be seen to hold not only for two functions but also for any $N$ number of functions.\nProof We use mathematical induction. First, when $N=2$, it holds by Theorem 1. Then, assuming it holds for $N=k$, showing it also holds for $N=k+1$ completes the proof.\nLet\u0026rsquo;s say $\\sum\\limits_{j=1}^k \\dfrac{1}{{p}_{j}}=\\dfrac{1}{r}$ and it holds for $N=k$. Then, the following holds.\n$$ \\left\\| \\prod_{j=1}^N u_{j} \\right\\|_{r} \\le \\| u_{1} \\|_{p_{1}} \\| u_{2} \\|_{p_{2}} \\cdots \\| u_{k} \\|_{p_{k}} $$\nNow, let\u0026rsquo;s say $\\sum_{j=1}^{k+1}\\dfrac{1}{{p}_{j}}=\\dfrac{1}{r}+\\dfrac{1}{{p}_{k+1}}=\\dfrac{1}{r^{\\prime}}$. Then,\n$$ \\begin{align*} \\| u \\|_{r^{\\prime}} =\u0026amp;\\ \\left\\| \\left( \\prod_{j=1}^k u_{j} \\right) u_{k+1} \\right\\|_{r^{\\prime}} \\\\ \\le\u0026amp; \\left\\| \\prod \\limits_{j=1}^{k+1}u_{j} \\right\\|_{r} \\| u_{k+1} \\|_{p_{k+1}} \\\\ \\le\u0026amp; \\| u_{1} \\|_{p_{1}} \\| u_{2} \\|_{p_{2}} \\cdots \\| u_{k} \\|_{p_{k}} \\| u_{k+1} \\| _{p_{k+1}} \\\\ =\u0026amp;\\ \\prod \\limits_{j=1}^{k+1} \\| u_{j}\\|_{p_{j}} \\end{align*} $$\nThe second line holds by Theorem 1. The third line holds by assumption. Therefore, assuming it holds for $N=k$ means it also holds for $N=k+1$. Thus, the proof is completed by mathematical induction.‚ñ†\nSee also H√∂lder\u0026rsquo;s inequality in Euclidean space H√∂lder\u0026rsquo;s inequality Robert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p24-25\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1091,"permalink":"https://freshrimpsushi.github.io/en/posts/1091/","tags":null,"title":"Generalized H√∂lder's Inequality, Corollaries of H√∂lder's Inequality"},{"categories":"Ìë∏Î¶¨ÏóêÌï¥ÏÑù","contents":"Definition Fourier Transform as a Function The Fourier transform of function $f \\in$ $L^{1}$ is defined as follows.\n$$ \\hat{f}(\\xi) := \\int_{-\\infty}^{\\infty} f(t) e^{-i \\xi t}dt $$\nFourier Transform as an Operator The operator $\\mathcal{F} : L^{1} \\to$ $C_{0}$ defined as follows is called the Fourier transform.\n$$ \\mathcal{F}[f] (\\xi) = \\int_{-\\infty}^{\\infty} f(t) e^{-i \\xi t}dt $$\nExplanation As seen in the definition, the term Fourier transform refers to both the operator $\\mathcal{F}$ itself and the functional value $\\hat{f} = \\mathcal{F}f = \\mathcal{F}[f]$ of $\\mathcal{F}$. It\u0026rsquo;s guaranteed by the Riemann-Lebesgue lemma that the codomain of $\\mathcal{F}$ is $C_{0}$. Moreover, it can be easily shown that the following holds for $f \\in L^{1}$,\n$$ \\left\\| \\mathcal{F}f \\right\\|_{\\infty} \\le \\left\\| f \\right\\|_{1} $$\nProof\n$$ \\begin{align*} \\left\\| \\mathcal{F}f \\right\\|_{\\infty} = \\max\\limits_{\\xi \\in \\mathbb{R}} \\left| \\mathcal{F}f(\\xi) \\right| \u0026amp;= \\max\\limits_{\\xi \\in \\mathbb{R}} \\left| \\int_{-\\infty}^{\\infty} f(t) e^{-i \\xi t}dt \\right| \\\\ \u0026amp;\\le \\max\\limits_{\\xi \\in \\mathbb{R}} \\int_{-\\infty}^{\\infty} \\left| f(t) e^{-i \\xi t} \\right| dt \\\\ \u0026amp;= \\int_{-\\infty}^{\\infty} \\left| f(t) \\right| dt = \\left\\| f \\right\\|_{1} \\end{align*} $$\nThe Fourier transform is a type of integral transform and its inverse transform is as follows.\n$$ f(t) = \\mathcal{F}^{-1}\\hat{f}(t) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{i t \\xi} d \\xi $$\nThe preceding constant $\\dfrac{1}{2\\pi}$ can be attached either at the front of the inverse transform or at the front of the transform, or $\\frac{1}{\\sqrt{2\\pi}}$ can be attached on both sides. This depends on the author\u0026rsquo;s convenience and does not fundamentally make any difference. Also, from the definition, one can see that $f$ must satisfy being integrable, that is, satisfy condition $f\\in L^{1}$, for the Fourier transform to be well-defined. If $\\hat{f}$ is also integrable, the Fourier inverse transform is well-defined as well.\nFourier Transform of Multivariable Functions The Fourier transform of multivariable functions is defined as follows. The Fourier transform of multivariable function $f \\in L^{1}(\\mathbb{R}^{n})$ is,\n$$ \\mathcal{F}f(\\boldsymbol{\\xi}):=\\int f(x)e^{-i \\boldsymbol{\\xi} \\cdot \\mathbf{x} }d\\mathbf{x} $$\n$$ \\mathcal{F} f(\\xi_{1},\\ \\cdots ,\\ \\xi_{n}) := \\int_{-\\infty}^{\\infty} \\dots \\int_{-\\infty}^{\\infty} f(x_{1},\\ \\cdots,\\ x_{n})e^{-i(\\xi_{1} x_{1}+\\cdots+\\xi_{n} x_{n})}dx_{1}\\cdots dx_{n} $$\nNotation There are two common notations for the Fourier transform of $f$.\n$$ \\mathcal{F}(f),\\quad \\hat{f} $$\nIn textbooks, it depends on which symbol the author prefers to use, but both are widely used. Although the right-hand hat symbol might seem convenient, it can be confusing, so when precision is required, it\u0026rsquo;s better to use the left-hand expression. For example, if the input function\u0026rsquo;s symbol itself gets lengthy, using the hat symbol can be confusing or not aesthetically pleasing. In such cases, using $\\mathcal{F}$ makes the meaning of the formula clear and neat. For instance, the Fourier transform of $W_{c}f$ is better represented as shown below by using $\\mathcal{F}$.\n$$ \\mathcal{F}(\\mathcal{W}_{c}f),\\quad \\hat{\\mathcal{W}_{c}f},\\quad \\widehat{\\mathcal{W}_{c}f} $$\nHowever, when there\u0026rsquo;s no room for confusion, the hat symbol is more convenient. Just like that, having various notations for the same concept also applies to differentiation.\n$$ f^{\\prime}, \\quad \\dfrac{df}{dx} $$\nThe advantages and disadvantages of the two notations $\\hat{f}$ and $\\mathcal{F}$ are similar to how in differentiation, the left-hand Newton\u0026rsquo;s notation has better economy and convenience, while the right-hand Leibniz\u0026rsquo;s notation has superiority in terms of rigor and precision when calculating things like the chain rule.\nDerivation1 Functions defined over a finite interval can be approximated using Fourier series. While useful, this only applies to periodic functions, so a similar tool for non-periodic functions is needed. This is where the idea of the Fourier transform comes from. The key concept in deriving the Fourier transform is thinking of non-periodic functions as if they have the entire real number line as their period, with the period repeating once across the entire line.\nLet\u0026rsquo;s say $f$ is a function defined in the interval $[-L,L)$. Then the Fourier series and complex Fourier coefficients of $f$ are as follows.\n$$ \\begin{equation} f(t)=\\sum \\limits_{n=-\\infty}^{\\infty} c_{n} e^{i\\frac{n\\pi t}{L}} \\end{equation} $$\n$$ c_{n} = \\dfrac{1}{2L}\\int_{-L}^{L}f(t)e^{-i\\frac{n \\pi t}{L} }dt $$\nLet\u0026rsquo;s perform the following variable substitution.\n$$ \\Delta \\xi = \\dfrac{\\pi}{L},\\quad \\xi_{n}=n\\Delta\\xi=\\dfrac{n\\pi}{L} $$\nThen $(1)$ becomes as follows.\n$$ f(t) = \\sum \\limits_{n=-\\infty}^{\\infty} c_{n} e^{i\\xi_{n} t}, \\quad c_{n} = \\dfrac{1}{2L}\\int_{-L}^{L}f(t)e^{-i \\xi_{n} t }dt $$\nMultiply $f(t)$ by an appropriate constant and let the integration term of $c_{n}$ be $\\hat{f}(\\xi_{n})$\n$$ f(t)=\\dfrac{L}{\\pi}\\sum \\limits_{n=-\\infty}^{\\infty} c_{n} e^{i\\xi_{n} t}\\Delta \\xi , \\quad c_{n} = \\dfrac{1}{2L}\\hat{f}(\\xi_{n}) $$\nAssume that $f(t)$ converges rapidly to $0$ when $t \\rightarrow \\pm \\infty$. Then extending the integration interval for $c_{n}$ from $[-L,L)$ to $(-\\infty,\\infty)$ should not significantly alter the original $c_{n}$.\n$$ c_{n} \\approx \\dfrac{1}{2L} \\int_{-\\infty}^{\\infty} f(t) e^{-i\\xi_{n} t}dt $$\nThis is a function of $\\xi_{n}$ alone, so let\u0026rsquo;s call it $c_{n} = \\frac{1}{2L}\\hat{f}(\\xi_{n})$. Inserting into $f(t)$ yields\n$$ f(t) \\approx \\dfrac{1}{2 \\pi}\\sum \\limits_{n=-\\infty}^{\\infty} \\hat{f}(\\xi_{n}) e^{i\\xi_{n} t}\\Delta \\xi $$\nThis looks very similar to a Riemann sum. Now, if we take the limit as $L\\rightarrow \\infty$, we get $\\Delta\\xi \\rightarrow 0$, and the equation becomes equal while the sum turns into integration.\n$$ f(t) = \\dfrac{1}{2 \\pi}\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{i\\xi t} d\\xi \\quad \\text{and} \\quad \\hat{f}(\\xi)=\\int_{-\\infty}^{\\infty} f(t) e^{-i\\xi t}dt $$\nAt this point, $\\hat{f}$ is called the Fourier transform of $f$, and $f$ is called the Fourier inverse transform of $\\hat{f}$.\nGerald B. Folland, Fourier Analysis and Its Applications (1992), p204-205\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1086,"permalink":"https://freshrimpsushi.github.io/en/posts/1086/","tags":null,"title":"Fourier Transform"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Summary: Equivalence Conditions of an Orthonormal Set Let $\\left\\{ \\phi_{n} \\right\\}_{1}^\\infty$ be an orthonormal set of $L^2(a,b)$ and denote $f \\in L^2(a,b)$. Then, the following conditions are equivalent.\n$(a)$ For all $n$, if $\\left\\langle f, \\phi_{n} \\right\\rangle=0$ then $f=0$.\n$(b)$ For all $f\\in L^2(a,b)$, the series $\\sum_{1}^\\infty \\left\\langle f,\\phi_{n}\\right\\rangle\\phi_{n}$ converges to $f$ in the norm sense. That is, the following equation holds:\n$$ f=\\sum_{1}^\\infty \\left\\langle f,\\phi_{n}\\right\\rangle\\phi_{n} $$\n$(c)$ For all $f \\in L^2(a,b)$, it satisfies the following equation known as Parseval\u0026rsquo;s equation:\n$$ \\| f \\|^2 = \\sum \\limits_{n=1}^{\\infty} \\left| \\left\\langle f,\\phi_{n} \\right\\rangle \\right|^{2} $$\nExplanation The orthonormal set satisfying $(a) - (c)$ is called an orthonormal basis or a complete orthonormal set.\nObserving these three conditions reveals that the orthonormal basis serves a role equivalent to a basis in finite-dimensional vector spaces.\nWhen $\\left\\{ \\phi_{n} \\right\\}$ is an orthonormal basis, the constants $\\left\\langle f, \\phi_{n}\\right\\rangle$ are called (generalized) Fourier coefficients.\nThe series $\\sum \\left\\langle f, \\phi_{n}\\right\\rangle\\phi_{n}$ is referred to as a (generalized) Fourier series.\nLemma\nAssume $f \\in L^2(a,b)$ and that $\\left\\{ \\phi_{n} \\right\\}$ is an orthonormal set in $L^2(a,b)$. Then the series $\\sum \\left\\langle f,\\phi_{n} \\right\\rangle\\phi_{n}$ converges in the norm sense. And it satisfies the following inequality:\n$$ \\left\\| \\sum \\left\\langle f,\\phi_{n}\\right\\rangle \\phi_{n} \\right\\| \\le | f| $$\nProof $(a) \\implies (b)$\nAssume $(a)$. Then, by the lemma, $\\sum \\left\\langle f, \\phi_{n} \\right\\rangle\\phi_{n}$ converges in the norm sense. Let\u0026rsquo;s define the difference of the series as $g$.\n$$ g=f-\\sum \\limits_{n=1}^{\\infty} \\left\\langle f, \\phi_{n} \\right\\rangle\\phi_{n} $$\nThen, it can be shown that $g=0$.\n$$ \\begin{align*} \\left\\langle g,\\phi_{m} \\right\\rangle \u0026amp;=\\ \\left\\langle f,\\phi_{m}\\right\\rangle - \\sum \\limits_{n=1}^{\\infty}\\left\\langle f,\\phi_{n} \\right\\rangle \\left\\langle \\phi_{n}, \\phi_{m} \\right\\rangle \\\\ \u0026amp;=\\ \\left\\langle f,\\phi_{m}\\right\\rangle - \\left\\langle f,\\phi_{m}\\right\\rangle \\\\ \u0026amp;=\\ 0 \\end{align*} $$\nTherefore, by assumption, $g=0$. Thus, $f= \\sum_{n=1}^\\infty \\left\\langle f, \\phi_{n} \\right\\rangle\\phi_{n}$\n‚ñ†\n$(b) \\implies (c)$\nAssume $(b)$. Then, since $f=\\sum_{1}^\\infty \\left\\langle f, \\phi_{n}\\right\\rangle\\phi_{n}$,\n$$ \\begin{align*} \\| f \\|^2 \u0026amp;=\\ \\left\\| \\sum \\limits_{n=1}^{\\infty} \\left\\langle f, \\phi_{n} \\right\\rangle \\phi_{n} \\right\\| ^2 \\\\ \u0026amp;= \\left\\| \\lim \\limits_{N \\rightarrow \\infty} \\sum \\limits_{n=1} ^{N} \\left\\langle f, \\phi_{n} \\right\\rangle\\phi_{n} \\right\\| ^2 \\\\ \u0026amp;= \\lim \\limits_{N \\rightarrow \\infty} \\left\\| \\sum \\limits_{n=1} ^{N} \\left\\langle f, \\phi_{n} \\right\\rangle\\phi_{n} \\right\\| ^ 2 \\\\ \u0026amp;= \\lim \\limits_{N \\rightarrow \\infty} \\sum _{n=1}^{N} | \\left\\langle f,\\phi_{n} \\right\\rangle |^2 \\\\ \u0026amp;= \\sum \\limits _{n=1} ^{\\infty} | \\left\\langle f, \\phi_{n} \\right\\rangle |^2 \\end{align*} $$\nThe third equation holds because the series converges in the norm sense by assumption. The fourth equation is valid due to the Pythagorean theorem.\n‚ñ†\n$(c) \\implies (a)$\nAssume $(c)$. Then,\n$$ \\| f \\|^2 =\\sum \\limits _{n=1} ^{\\infty}\\left| \\left\\langle f,\\phi_{n} \\right\\rangle \\right|^{2} $$\nTherefore, for all $n$, if $\\left\\langle f, \\phi_{n} \\right\\rangle=0$, then $f=0$ is true.\n‚ñ†\n","id":1082,"permalink":"https://freshrimpsushi.github.io/en/posts/1082/","tags":null,"title":"Complete Orthonormal Basis and Complete Orthonormal Set"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Formulas For different data $x_{0} , \\cdots , x_{n}$ of $(x_{0}, f(x_{0} )) , \\cdots , (x_{n} , f( x_{n} ) )$, $$ p_{n} (x) =\\sum_{i=0}^{n} f [ x_{0} , \\cdots , x_{i} ] \\prod_{j=0}^{i-1} (x - x_{j} ) $$\nDescription Though it seems complicated, when actually expanding for $n=0,1,2$, it simplifies as follows. $$ \\begin{align*} p_{0} (x) =\u0026amp; f(x_{0}) \\\\ p_{1} (x) =\u0026amp; f( x_{0} ) + (x - x_{0} ) f [ x_{0} , x_{1} ] \\\\ p_{2} (x) =\u0026amp; f( x_{0} ) + (x - x_{0} ) f [ x_{0} , x_{1} ] + ( x - x_{0} ) ( x - x_{1} ) f [ x_{0} , x_{1} , x_{2} ] \\end{align*} $$ Newton\u0026rsquo;s divided differences formula uses divided differences for representing polynomial interpolation, and although it seems more complex than Lagrange\u0026rsquo;s formula, it\u0026rsquo;s much more convenient when data needs to be updated. Newton\u0026rsquo;s divided differences formula recursively expresses as $$ p_{n} (x) = p_{n-1}(x) + f[x_{0} , \\cdots , x_{n} ] \\prod_{i=0}^{n-1} (x - x_{i}) $$ which means, if only Lagrange\u0026rsquo;s formula existed, one would need to go through the trouble of calculating the inverse matrix of size $(n+1) \\times (n+1)$ again even though $p_{n-1}$ is already known. Regardless of the calculation method, the result is exactly the same as Lagrange\u0026rsquo;s formula, so if there is not much data added, Newton\u0026rsquo;s divided differences formula can be very useful.\nMoreover, by utilizing the fact that it is exactly the same but looks different from Lagrange\u0026rsquo;s formula, various useful theorems about divided differences can be proven.\nDerivation Strategy: If the difference between $p_{n}$ and $p_{n-1}$ is called $C$, then the highest-order term coefficients of $p_{n}$ and $C$ must be the same, so by calculating the coefficient of $C$ indirectly, the recursion formula is derived.\nIf it is said that $$ p_{n}(x) = p_{n-1}(x) + C(x) $$, then $\\deg C = n$ and for $i= 0, \\cdots, (n-1)$, $$ p_{n}(x_{i}) = f(x_{i}) = p_{n-1}(x_{i}) $$ thus for some constant $a_{n} \\ne 0$, $$ C (x) = a_{n} (x - x_{0}) \\cdots (x - x_{n-1}) $$ appears like this. Since the highest order terms of $p_{n}$ and $C$ are the same, it needs to be shown that $a_{n} = f [ x_{0} , \\cdots , x_{n}]$ holds. Let‚Äôs say polynomial interpolation obtained from data $\\left\\{ x_{0}, \\cdots , x_{k} \\right\\}$ with $x_{k}$ removed is $\\left\\{ x_{0}, \\cdots , x_{k-1} \\right\\}$ and the polynomial interpolation obtained from data $\\left\\{ x_{1}, \\cdots , x_{k} \\right\\}$ missing $x_{0}$ is $R_{k-1}(x)$. Each alphabet indicates Left and Right respectively. Let‚Äôs set $p_{k}$ as follows. $$ p_{k}(x) := {{ (x-x_{0}) R_{k-1} (x) - (x-x_{k}) L_{k-1} (x) } \\over { x_{k} - x_{0} }} $$ Then, for $i=1,\\cdots , k-1$, $$ p_{k}(x_{0}) = L_{k-1} (x_{0}) = f(x_{0}) $$\n$$ p_{k}(x_{i}) = L_{k-1} (x_{i}) = R_{k-1} (x_{i}) = f(x_{i}) $$\n$$ p_{k}(x_{k}) = R_{k-1} (x_{k}) = f(x_{k}) $$ Therefore, it\u0026rsquo;s guaranteed that $p_{k}$ accurately interpolates the given data. When the highest order term‚Äôs coefficient of $p_{k}$ is called $a_{k}$, it will be shown by mathematical induction that $a_k = f[ x_{0} , \\cdots , x_{k} ]$ holds.\nWhen $k=1$, $$ p_{1}(x) = {{ (x-x_{0}) f(x_{1}) - (x-x_{k}) f(x_{0}) (x) } \\over { x_{1} - x_{0} }} $$ thus, the coefficient of the highest order term $x$ is $$ a_{1} = {{ f(x_{1} - x_{0}) } \\over { x_{1} - x_{0} }} = f[x_{0},x_{1}] $$ Assuming $k \u0026gt; 1$ is valid when $a_{k-1} = f[ x_{0} , \\cdots , x_{k-1} ]$ holds, the coefficient of the highest order term of $L_{k-1}$ is $f[ x_{0} , \\cdots , x_{k-1} ]$, and the highest order term‚Äôs coefficient of $R_{k-1}$ is $f[ x_{1} , \\cdots , x_{k} ]$. Breaking down the fraction form of $p_{k}$, $$ p_{k}(x) = {{ R_{k-1} (x) - L_{k-1} (x) } \\over { x_{k} - x_{0} }} x + {{ x_{k} L_{k-1} (x) - x_{0} R_{k-1} (x) } \\over { x_{k} - x_{0} }} $$ Therefore, the coefficient of the highest order term $p_{k}(x)$ is $$ a_{k} = {{ f[ x_{1} , \\cdots , x_{k} ]- f[ x_{0} , \\cdots , x_{k-1} ] } \\over { x_{k} - x_{0} }} = f[ x_{0} , \\cdots , x_{k} ] $$ By mathematical induction, for all natural numbers $n$, $$ a_{n} = f [ x_{0} , \\cdots , x_{n}] $$\n‚ñ†\n","id":1025,"permalink":"https://freshrimpsushi.github.io/en/posts/1025/","tags":null,"title":"Derivation of Newton's Forward Difference Formula"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Overview1 The scalar and vector potentials for a moving point charge are called retarded potentials, and they are as follows.\n$$ \\begin{align*} V(\\mathbf{r},\\ t) \u0026amp;= \\dfrac{1}{4\\pi\\epsilon_{0}} \\int \\dfrac{ \\rho (\\mathbf{r}^{\\prime},\\ t_{r}) }{ \\cR } d\\tau^{\\prime} \\\\[1em] \\mathbf{A}( \\mathbf{r},\\ t) \u0026amp;= \\dfrac{\\mu_{0}}{4\\pi} \\int \\dfrac{\\mathbf{J}(\\mathbf{r}^{\\prime},\\ t_{r})}{\\cR}d\\tau^{\\prime} \\end{align*} $$\nHere, $t_{r}$ is the retarded time.\nRetarded Time If the charge and current distribution do not change over time, the scalar and vector potentials satisfy the following Poisson\u0026rsquo;s equations.\n$$ \\nabla^2 V=-\\dfrac{1}{\\epsilon_{0}} \\rho,\\quad \\nabla^2 \\mathbf{A}=-\\mu_{0}\\mathbf{J} $$\nSolving these yields:\n$$ \\begin{equation} V(\\mathbf{r})=\\dfrac{1}{4\\pi\\epsilon_{0}} \\int \\dfrac{ \\rho (\\mathbf{r}^{\\prime}) }{ \\cR } d\\tau^{\\prime},\\quad \\mathbf{A}( \\mathbf{r} ) = \\dfrac{\\mu_{0}}{4\\pi} \\int \\dfrac{\\mathbf{J}(\\mathbf{r}^{\\prime})}{\\cR}d\\tau^{\\prime} \\end{equation} $$\n$\\bcR$ is the separation vector.\nHowever, since electromagnetic waves propagate at the speed of light, if the current distribution moves, the \u0026ldquo;current moment\u0026rsquo;s\u0026rdquo; potential is not due to the current distribution but rather due to the distribution at \u0026ldquo;some past moment\u0026rdquo;. It\u0026rsquo;s important that it is not the current distribution that matters, but the distribution from \u0026ldquo;some past moment\u0026rdquo; when the electromagnetic wave started. The distance traveled is $\\cR$, and with the speed of light being $c$, the moment the electromagnetic wave started, reaching the current moment $\\mathbf{r}$, is as follows.\n$$ t_{r} \\equiv t-\\dfrac{\\cR}{c} $$\nThis is called the retarded time. To put it more simply, the news arriving at \u0026ldquo;the current moment\u0026rdquo; $t$ started at the time corresponding to the retarded time. It is expressed as a moment in time, rather than time itself, for this reason. When dealing with a moving point charge or current distribution, the separation vector is not $\\mathbf{r}-\\mathbf{r}^{\\prime}$, but $\\bcR=\\mathbf{r}-\\mathbf{w}$.\nRetarded Potentials Thus, when the charge distribution changes over time, in other words, when the charge moves, the generalization of $(1)$ is as follows.\n$$ V(\\mathbf{r},\\ t)=\\dfrac{1}{4\\pi\\epsilon_{0}} \\int \\dfrac{ \\rho (\\mathbf{r}^{\\prime},\\ t_{r}) }{ \\cR } d\\tau^{\\prime},\\quad \\mathbf{A}( \\mathbf{r},\\ t) = \\dfrac{\\mu_{0}}{4\\pi} \\int \\dfrac{\\mathbf{J}(\\mathbf{r}^{\\prime},\\ t_{r})}{\\cR}d\\tau^{\\prime} $$\n$\\rho (\\mathbf{r}^{\\prime}, t_{r})$ is the charge density at point $\\mathbf{r}^{\\prime}$ when the time is $t_{r}$. The two potentials described above are called retarded potentials. These equations were not mathematically derived. Instead, they were reasonably explained with physically correct logic. Although there is a logical leap, fortunately, the results match reality well. To prove this, it must be checked whether the newly obtained potentials satisfy the following wave equation $(2)$ and the Lorentz gauge $(3)$.\n$$ \\begin{equation} \\begin{aligned} \\Box ^2 V \u0026amp;= -\\dfrac{1}{\\epsilon_{0}}\\rho \\\\ \\Box ^2 \\mathbf{A} \u0026amp;= -\\mu_{0}\\mathbf{J} \\end{aligned} \\end{equation} $$\n$$ \\begin{equation} \\nabla \\cdot \\mathbf{A} = -\\mu_{0} \\epsilon_{0} \\frac{\\partial V}{\\partial t} \\end{equation} $$\nThis thorough verification is necessary because applying the same logic to electric and magnetic fields, instead of potentials, results in outcomes that do not match reality.\nDavid J. Griffiths, Introduction to Electrodynamics (4th Edition, 2014), pp. 480-483\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1075,"permalink":"https://freshrimpsushi.github.io/en/posts/1075/","tags":null,"title":"Delayed Potential on Continuous Distribution of Delay Times"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Formula 1 Given different $x_{0} , \\cdots , x_{n}$ data $(x_{0}, y_{0}) , \\cdots , (x_{n} , y_{n})$, let\u0026rsquo;s say $\\displaystyle l_{i} (x) := \\prod_{i \\ne j} \\left( {{ x - x_{j} } \\over { x_{i} - x_{j} }} \\right)$, then $$ p_{n} (x) = \\sum_{i=0}^{n} y_{i} l_{i} (X) $$\nDescription Lagrange\u0026rsquo;s formula is the simplest method among those to find polynomial interpolation.\nDerivation Strategy: Prove that $l_{i}$ is the Kronecker delta function with respect to the index.\n$$ l_{i} (x_{i}) = \\prod_{i \\ne j} \\left( {{ x_{i} - x_{j} } \\over { x_{i} - x_{j} }} \\right) = 1 $$\n$$ l_{i} (x_{j}) = \\prod_{i \\ne j} \\left( {{ x_{j} - x_{j} } \\over { x_{i} - x_{j} }} \\right) = 0 $$ Summarizing, it is $l_{i}(x_{j}) = \\delta_{ij}$. $$ p_{n}(x) = y_{0} l_{0}(x) + y_{1} l_{1}(x) + \\cdots y_{n} l_{n}(X) $$ If we set this, for all $i=0,1, \\cdots , n$, $$ p_{n}(x_{i}) =0 + \\cdots + y_{i} \\cdot 1 + \\cdots + 0 = y_{i} $$ holds.\n‚ñ†\nAtkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p134.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1023,"permalink":"https://freshrimpsushi.github.io/en/posts/1023/","tags":null,"title":"Lagrange's Formula Derivation"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Explanation1 When emphasizing that x and p are variables of a partial differential equation, they are denoted in normal font as $x,p \\in \\mathbb{R}^{n}$, and when emphasizing them as functions of $s$, they are denoted in bold font as $\\mathbf{x}, \\mathbf{p} \\in \\mathbb{R}^{n}$. Characteristic Equations\n$$ \\begin{cases} \\dot{\\mathbf{p}} (s) = -D_{x}F\\big(\\mathbf{p}(s),\\ z(s),\\ \\mathbf{x}(s) \\big)-D_{z}F\\big(\\mathbf{p}(s),\\ z(s),\\ \\mathbf{x}(s) \\big)\\mathbf{p}(s) \\\\ \\dot{z}(s) = D_{p}F\\big(\\mathbf{p}(s),\\ z(s),\\ \\mathbf{x}(s) \\big) \\cdot \\mathbf{p}(s) \\\\ \\dot{\\mathbf{x}}(s) = D_{p}F\\big(\\mathbf{p}(s),\\ z(s),\\ \\mathbf{x}(s) \\big) \\end{cases} $$\nThe solution of nonlinear first-order partial differential equations using characteristic equations varies slightly depending on how the differential equation is given. This is distinguished by the linearity of the given differential equation and differs for cases of linear, quasi-linear, and fully nonlinear. The stronger the nonlinearity, the more challenging it is.\nSolution Homogeneous Linear If the given partial differential equation is completely linear, it can be solved most easily. The condition for $\\mathbf{p}(s)$ in the characteristic equation is so simple that it is unnecessary. Consider the following linear and homogeneous differential equation.\n$$ \\begin{equation} F(Du, u, x) = \\mathbf{b}(x)\\cdot Du(x)+c(x)u(x)=0 \\quad (x\\in \\Omega \\subset \\mathbb{R}^{n}) \\label{eq1} \\end{equation} $$\nHere, if we set the variables of $F$ as $p, z, x$, it would be as follows.\n$$ \\begin{equation} F(p,\\ z,\\ x)=\\mathbf{b}(x)\\cdot p +c(x)z=b_{1}p_{1}+\\cdots +b_{n}p_{n}+cz = 0 \\label{eq2} \\end{equation} $$\nIf we calculate $D_{p}F$, it would be as follows.\n$$ D_{p}F=(F_{p_{1}}, \\dots, F_{p_{n}})=(b_{1}, \\dots, b_{n})=\\mathbf{b}(x) $$\nThen, the characteristic equation is as follows.\n$$ \\begin{align*} \\dot{\\mathbf{x}}(s) \u0026amp;= \\mathbf{b}(x) \\\\ \\dot{z}(s) \u0026amp;= \\mathbf{b}(\\mathbf{x}(s))\\cdot \\mathbf{p}(s) \\end{align*} $$\nBy $(2)$, $\\dot{z}(s)$ is as follows.\n$$ \\dot{z}(s) = -c(\\mathbf{x}(s))z $$\nTherefore, the characteristic equation for a homogeneous linear first-order partial differential equation is as follows.\n$$ \\left\\{ \\begin{align*} \\dot{\\mathbf{x}}(s)\u0026amp;=\\mathbf{b}(x) \\\\ \\dot{z}(s) \u0026amp;= -c(\\mathbf{x}(s))z \\end{align*} \\right. $$\nHere, it can be seen through an example that the characteristic equation for $\\mathbf{p}(s)$ is not necessary to solve the problem.\nExample Suppose the following differential equation is given.\n$$ \\left\\{ \\begin{align*} x_{1} u_{x_{2}} - x_{2} u_{x_{1}} \u0026amp;= u \u0026amp;\u0026amp; \\text{in } \\Omega \\\\ u\u0026amp;=g \u0026amp;\u0026amp; \\text{on } \\Gamma \\end{align*} \\right. $$\n$\\Omega=\\left\\{ x_{1}\u0026gt;0,\\ x_{2}\u0026gt;0 \\right\\}$ $\\Gamma=\\left\\{ x_{1}\u0026gt;0,\\ x_{2}=0 \\right\\}$ Then in $(1)$, $\\mathbf{b}=(-x_{2},\\ x_{1}), c=-1$. Thus, the characteristic equation is as follows.\n$$ \\left\\{ \\begin{align*} \\dot{x}^{1} \u0026amp;= -x^{2} \\\\ \\dot{x}^{2} \u0026amp;=x^{1} \\\\ \\dot{z}\u0026amp;=z \\end{align*} \\right. $$\nSince this is a simple ordinary differential equation, it can be easily solved as follows.\n$$ \\left\\{ \\begin{align*} x^{1}(s) \u0026amp;=x^{0}\\cos s \\\\ x^{2}(s)\u0026amp;=x^{0} \\sin s \\\\ z(s)\u0026amp;=z^{0}e^s=g(x^{0})e^s \\end{align*} \\right. $$\nHere, $x^{0}$ is a constant set to pass through the $x_{1}-$axis $(\\Gamma)$ when $s=0$. Then, by the boundary condition $z=u=g\\ \\mathrm{on}\\ \\Gamma$, when $s=0$, $z(0)=z^{0}=g(x^{0})$. Now, fix the point $(x_{1},\\ x_{2}) \\in \\Omega$.\n$$ (x_{1},\\ x_{2})=(x^{1}(s),\\ x^{2}(s)) = (x^{0} \\cos (s),\\ x^{0} \\sin (s)) $$\nThen, for $s\u0026gt;0, x^{0}\u0026gt;0$, we obtain the following.\n$$ x_{1}^{2} + x_{2}^{2} = (x^{0})^{2}\\cos^{2}(s) + (x^{0})^{2}\\sin^{2}(s) = (x^{0})^{2} \\implies x^{0}=({x_{1}}^{2}+{x_{2}}^{2})^{1/2} \\\\ \\dfrac{x_{2}}{x_{1}} = \\dfrac{x^{0}\\sin (s)}{x^{0} \\cos (s)} = \\tan (s) \\implies s=\\arctan \\left( \\frac{x_{2}}{x_{1}} \\right) $$\nTherefore, the solution of the equation is as follows.\n$$ \\begin{align*} u(x)\u0026amp;=u(x^{1}(s),\\ x^{2}(s)) \\\\ \u0026amp;= z(s) \\\\ \u0026amp;=g(x^{0})e^s \\\\ \u0026amp;= g(({x_{1}}^{2}+{x_{2}}^{2})^{1/2})e^{\\arctan \\left(\\frac{x_{2}}{x_{1}}\\right)} \\end{align*} $$\n‚ñ†\nQuasi-Linear The following describes cases where the given differential equation is linear with respect to the highest order of differentiation. As we are dealing with first-order differential equations, it refers to cases where they are linear with respect to first-order derivatives.\n$$ F(Du,\\ u,\\ x)=\\mathbf{b}(x,\\ u(x))\\cdot Du(x)+c(x,\\ u(x))=0 $$\nHere, if we set the variables of $F$ as $p, z, x$, it would be as follows.\n$$ \\begin{equation} F(p, z, x)=\\mathbf{b}(x, z)\\cdot p + c(x, z)=b_{1}p_{1} + \\cdots + b_{n} p_{n} +c=0 \\label{eq3} \\end{equation} $$\nIf we calculate $D_{p}F$, it would be as follows.\n$$ D_{p}F=(F_{p_{1}},\\ \\cdots,\\ F_{p_{n}})=(b_{1},\\ \\cdots,\\ b_{n})=\\mathbf{b}(x,\\ z) $$\nThen, the characteristic equation is as follows.\n$$ \\begin{align*} \\dot{\\mathbf{x}}(s) \u0026amp;= \\mathbf{b}(\\mathbf{x}(s),\\ z(s)) \\\\ \\dot{z}(s) \u0026amp;= \\mathbf{b}(\\mathbf{x}(s),\\ z(s))\\mathbf{p}(s)=-c(\\mathbf{x}(s),\\ z(s)) \\end{align*} $$\nThe second equality for $\\dot{z}$ is valid due to $(3)$. Even in this case, the condition for $\\mathbf{p}(s)$ is not necessary to solve the problem.\nExample Suppose the following differential equation is given.\n$$ \\left\\{ \\begin{align*} u_{x_{1}} + u_{x_{2}} \u0026amp;= u^{2} \u0026amp;\u0026amp; \\text{in } \\Omega \\\\ u\u0026amp;=g \u0026amp;\u0026amp; \\text{on } \\Gamma \\end{align*} \\right. $$\n$\\Omega=\\left\\{ x_{2}\u0026gt;0 \\right\\}$ $\\Gamma=\\left\\{x_{2}=0 \\right\\}$ Then in $(3)$, $\\mathbf{b}=(1,\\ 1)$, $c=-z^{2}$. Thus, the characteristic equation is as follows.\n$$ \\left\\{ \\begin{align*} \\dot{x}^{1} \u0026amp;=1, \\dot{x}^{2}=1 \\\\ \\dot{z} \u0026amp;= z^{2} \\end{align*} \\right. $$\nSince these are simple ordinary differential equations, they can be solved as follows.\n$$ \\left\\{ \\begin{align*} x^{1}(s) \u0026amp;= x^{0}+s, x^{2}(s)=s \\\\ z(s)\u0026amp;=\\frac{z^{0}}{1-sz^{0}}=\\frac{g(x^{0})}{1-sg(x^{0})} \\end{align*} \\right. $$ $x^{0}$ is a constant set to pass through the $x_{2}-$axis $(\\Gamma)$ when $s=0$. Now, fix the point $(x_{1},\\ x_{2}) \\in \\Omega$.\n$$ (x_{1}, x_{2})=(x^{1}(s), x^{2}(s))=(x^{0}+s, s) $$\nThen, for $s\u0026gt;0, x^{0} \\in \\mathbb{R}$, we obtain the following. $$ s=x_{2}, \\quad x^{0}=x_{1}-x_{2} $$\nTherefore, the solution of the equation is as follows.\n$$ \\begin{align*} u(x) \u0026amp;= u(x^{1}(s),\\ x^{2}(s)) \\\\ \u0026amp;= z(s) \\\\ \u0026amp;= \\frac{g(x^{0})}{1-sg(x^{0})} \\\\ \u0026amp;= \\frac{g(x_{1}-x_{2})}{1-x_{2}g(x_{1}-x_{2})} \\end{align*} $$\nOf course, this is only valid when $1-x^{2}g(x_{1}-x_{2})\\ne 0$.\n‚ñ†\nFully Nonlinear Suppose the following differential equation is given.\n$$ \\begin{align*} u_{x_{1}}u_{x_{2}} \u0026amp;= u \u0026amp;\u0026amp; \\text{in } \\Omega \\\\ u \u0026amp;= x_{2}^{2} \u0026amp;\u0026amp; \\text{on } \\Gamma \\end{align*} $$\n$\\Omega=\\left\\{ x_{1}\u0026gt;0 \\right\\}$ $\\Gamma=\\left\\{x_{1}=0 \\right\\}$ If we set the variables of $F$ as $P, z, x$, it would be as follows.\n$$ F(p, z, x)=p_{1}p_{2}-z $$\nThus, the characteristic equation is as follows.\n$$ \\begin{align*} \\dot{p}^{1} \u0026amp;= p^{1},\\quad \\dot{p}^{2}=p^{2} \\\\ \\dot{z} \u0026amp;= 2p^{1}p^{2} \\\\ \\dot{x}^{1} \u0026amp;= p^{2},\\quad \\dot{x}^{2}=p^{1} \\end{align*} $$\nFirst, if we solve the differential equation for $p$, it would be as follows.\n$$ p^{1}(s)=p_{1}^{0}e^s,\\ \\ p^{2}(s)=p_{2}^{0}e^s $$\nHere, $p_{1}^{0}=p(0)$, $p_{2}^{0}=p(0)$. Then, since $\\dot{z}(s)=2p_{1}^{0}p_{2}^{0}e^{2s}$, $z$ is as follows.\n$$ z(s)=p_{1}^{0}p_{2}^{0}e^{2s}+C $$\nSince $z(0)=z^{0}=p_{1}^{0}p_{2}^{0}+C$, $C=z^{0}-p_{1}^{0}p_{2}^{0}$. Therefore, it is as follows.\n$$ z(s)=z^{0}+p_{1}^{0}p_{2}^{0}(e^{2s}-1) $$\nSimilarly, if we calculate $x^{1}$ and $x^{2}$, it would be as follows.\n$$ \\begin{equation} \\left\\{ \\begin{aligned} p^{1}(s) \u0026amp;= p_{1}^{0}e^s \\\\ p^{2}(s) \u0026amp;= p_{2}^{0}e^s \\\\ z(s) \u0026amp;= z^{0}+p_{1}^{0}p_{2}^{0}(e^{2s}-1) \\\\ x^{1}(s) \u0026amp;= p_{2}^{0}(e^s-1) \\\\ x^{2}(s) \u0026amp;= x^{0}+p_{1}^{0}(e^s-1) \\end{aligned} \\right. \\label{eq4} \\end{equation} $$\nHere, $x^{0}$ is a constant set to pass through the $x_{1}-$axis $(\\Gamma)$ when $s=0$. Since $u_{x_{2}}=p^{2}$ and by the boundary condition $u=x_{2}^{2}$ when $x_{1}=0$ ($s=0$), $p_{2}^{0}=u(0,\\ x^{0})=2x^{0}$. Also, as the given differential equation is $u_{x_{1}}u_{x_{2}}=u$, $p_{1}^{0}p_{2}^{0}=z^{0}=(x^{0})^{2}$ and $p_{1}^{0}=\\frac{x^{0}}{2}$. If we substitute all these into $(4)$, we obtain the following.\n$$ \\left\\{ \\begin{align*} p^{1}(s) \u0026amp;= \\frac{x^{0}}{2}e^s \\\\ p^{2}(s) \u0026amp;= 2x^{0}e^s \\\\ z(s) \u0026amp;= (x^{0})^{2}e^{2s} \\\\ x^{1}(s) \u0026amp;= 2x^{0}(e^s-1) \\\\ x^{2}(s) \u0026amp;= x^{0}+\\frac{x^{0}}{2}(e^s-1) \\end{align*} \\right. $$\nNow, fix the point $(x_{1}, x_{2})\\in \\Omega$.\n$$ (x_{1}, x_{2})=(x^{1}(s), x^{2}(s))=\\left( 2x^{0}(e^s -1), \\frac{x^{0}}{2}(e^s+1) \\right) $$\nThen, for $s,\\ x^{0}$, we obtain the following.\n$$ x^{0}=\\frac{4x_{2}-x_{1}}{4},\\ \\ e^s=\\frac{x_{1}+4x_{2}}{4x_{2}-x_{1}} $$\nTherefore, the solution of the equation is as follows.\n$$ u(x)=u(x^{1}(s),\\ x^{2}(s))=z(s)=(x^{0})^{2}e^{2s}=\\dfrac{(x_{1}+4x_{2})^{2}}{16} $$\n‚ñ†\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p99-102\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1074,"permalink":"https://freshrimpsushi.github.io/en/posts/1074/","tags":null,"title":"Solution of Nonlinear First Order PDE Using Characteristic Equations"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Notation1 A nonlinear first-order partial differential equation is denoted as follows.\n$$ \\begin{equation} F(Du, u, x) = F(p, z, x) = 0 \\label{eq1} \\end{equation} $$\n$\\Omega \\subset \\mathbb{R}^{n}$ is an open set $x\\in \\Omega$ $F : \\mathbb{R}^n \\times \\mathbb{R}^n \\times \\bar{ \\Omega } \\to \\mathbb{R}$ is the given function $u : \\bar{ \\Omega } \\to \\mathbb{R}$ is the variable of $F$ Description Solving a nonlinear first-order partial differential equation $F$ means finding a variable $u$ that satisfies $F=0$ for the given $F$. Here, let $x$ be a variable that encompasses both time and space.\n$$ x=(x_{1}, \\dots, x_{n}=t) $$\nThe function $F$ is denoted as follows.\n$$ F=F(p, z, x)=F(p_{1}, \\dots, p_{n}, z, x_{1}, \\cdots, x_{n}) $$\n$p=Du(x) \\in\\mathbb{R}^n$ $z=u(x)\\in \\mathbb{R}$ $x\\in \\bar{ \\Omega }$ And the function $F$ is assumed to be sufficiently smooth to be differentiable. This is generally the case, so it\u0026rsquo;s not particularly a strong condition. Then, the gradient of $F$ with respect to each variable is as follows.\n$$ \\begin{cases} D_{p} F=(F_{p_{1}},\\ \\cdots,\\ F_{p_{n}}) \\\\ D_{z}F=Fz \\\\ D_{x}F=(F_{x_{1}},\\ \\cdots,\\ F_{x_{n}} )\\end{cases} $$\nThe Clairaut\u0026rsquo;s equation is represented using this notation as follows.\n$$ F(Du,\\ u,\\ x)=xDu+f(Du) $$\nBoundary Value Problem Differential equations $\\eqref{eq1}$ are commonly given along with boundary conditions. In such cases, they are denoted as follows.\n$$ \\begin{align*} F(Du,\\ u,\\ x)\u0026amp;=0 \u0026amp;\u0026amp; \\text{in } \\mathbb{\\Omega} \\\\ u\u0026amp;=g \u0026amp;\u0026amp; \\text{on } \\Gamma \\end{align*} $$ In this case, $\\Gamma \\subset \\partial \\Omega, g : \\Gamma \\to \\mathbb{R}$.\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p91-92\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1071,"permalink":"https://freshrimpsushi.github.io/en/posts/1071/","tags":null,"title":"Notation for Nonlinear First-Order Partial Differential Equations"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Definition 1 For different $x_{0} , \\cdots , x_{n}$ data $(x_{0}, y_{0}) , \\cdots , (x_{n} , y_{n})$, a polynomial function $p$ that satisfies $p (x_{i} ) = y_{i}$ and $\\deg p \\le n$ is called Polynomial Interpolation.\nTheorem Existence and Uniqueness [1]: For the given data, there exists a unique $p$. Lagrange\u0026rsquo;s Formula [2]: $$p_{n} (x) = \\sum_{i=0}^{n} y_{i} l_{i} (X)$$ Newton\u0026rsquo;s Divided Difference Formula [3]: $$p_{n} (x) = f(x_{0}) + \\sum_{i=1}^{n} f [ x_{0} , \\cdots , x_{i} ] \\prod_{j=0}^{i-1} (x - x_{j} )$$ Error Analysis [4]: For a $(n+1)$ times differentiable function $f : \\mathbb{R} \\to \\mathbb{R}$ and some $\\xi \\in \\mathscr{H} \\left\\{ x_{0} , \\cdots , x_{n} \\right\\}$, the polynomial interpolation $p_{n}$ of $f$ satisfies the following for some $t \\in \\mathbb{R}$. $$\\displaystyle f(t) - p_{n} (t) = {{ (t - x_{0}) \\cdots (t - x_{n}) } \\over { (n+1)! }} f^{(n+1)} ( \\xi )$$ $\\mathscr{H} \\left\\{ a,b,c, \\cdots \\right\\}$ represents the smallest interval that includes $a,b,c, \\cdots$. Explanation Polynomial interpolation is simplified in Korean as Îã§Ìï≠Ïãù Î≥¥Í∞ÑÎ≤ï.\nCondition $\\deg p \\le n$ The condition $\\deg p \\le n$ implies there\u0026rsquo;s not always a guarantee that a $p$ satisfying $\\deg p = n$ exists. For instance, when $n=2$, if the three points lie in a straight line as shown above, a $p_{2} (x) = a_{2} x^{2} + a_{1} x + a_{0}$ passing through $(n+1)=3$ points does not exist, while a lower degree $p_{1} (x) = a_{1} x + a_{0}$ does. This actually means that $p_{2} (x) = a_{2} x^{2} + a_{1} x + a_{0}$ was found, but in cases where $a_{2} = 0$.\nLagrange\u0026rsquo;s Formula and Newton\u0026rsquo;s Divided Difference Formula are the same Though formulas [2] and [3] appear different, they are essentially the same due to [1]. The core difference between the two formulas is merely how $p_{n}$ is represented. Functionally, the significant difference is that Newton\u0026rsquo;s Divided Difference Formula is easier to update when new data is added.\nError with the Actual Function Theorem [4] shows how much difference there is between the interpolating $p_{n}$ and the actual function $f$. Generally, the divergence rate of $(n+1)!$ is very fast, so the accuracy of interpolation $p_{n}$ increases with more data. However, this formula does not necessarily discuss convergence. For a simple example, consider when $t$ is very, very far from $\\mathscr{H} \\left\\{ x_{0} , \\cdots , x_{n} \\right\\}$. Moreover, if the value of $f$ worsens with each differentiation, and that even surpasses the divergence rate of $(n+1)!$, it can turn weird.\nProof [1] Strategy: Show the uniqueness of the coefficients $a_{0} , a_{1} , \\cdots , a_{n}$ of $p_{n}$ that satisfy $y_{i} = p_{n} (x_{i}) = a_{0} + a_{1} x_{i} + \\cdots + a_{n} x_{i}^{n}$ for all $i = 0, \\cdots , n$ by representing a system of $(n+1)$ equations in matrix form and simultaneously ensuring the existence and uniqueness of the inverse matrix.\nDefine $$ \\mathbb{y} := \\begin{bmatrix} y_{0} \\\\ y_{1} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix}, X := \\begin{bmatrix} 1 \u0026amp; x_{0} \u0026amp; \\cdots \u0026amp; x_{0}^{n} \\\\ 1 \u0026amp; x_{1} \u0026amp; \\cdots \u0026amp; x_{1}^{n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 1 \u0026amp; x_{n} \u0026amp; \\cdots \u0026amp; x_{n}^{n} \\end{bmatrix} , \\mathbb{a} := \\begin{bmatrix} a_{0} \\\\ a_{1} \\\\ \\vdots \\\\ a_{n} \\end{bmatrix} $$ and represent the simultaneous equations in matrix form, and then $$ \\begin{bmatrix} y_{0} \\\\ y_{1} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; x_{0} \u0026amp; \\cdots \u0026amp; x_{0}^{n} \\\\ 1 \u0026amp; x_{1} \u0026amp; \\cdots \u0026amp; x_{1}^{n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 1 \u0026amp; x_{n} \u0026amp; \\cdots \u0026amp; x_{n}^{n} \\end{bmatrix} \\begin{bmatrix} a_{0} \\\\ a_{1} \\\\ \\vdots \\\\ a_{n} \\end{bmatrix} $$ Now, the problem has changed to finding a solution $\\mathbb{a}$ that satisfies $\\mathbb{y} = X \\mathbb{a}$.\nVandermonde matrix determinant: The determinant of $X$ is $\\displaystyle \\det X = \\prod_{1 \\le i \u0026lt; j \\le n } (x_{j} - x_{i})$\nSince the $x_{0} , \\cdots , x_{n}$ are different by assumption, $\\det X \\ne 0$, and $X^{-1}$ exists. Thus, $\\mathbb{a} = X^{-1} \\mathbb{y}$ also exists. Meanwhile, since the inverse of a given matrix is unique, $\\mathbb{a}$ is also unique.\n‚ñ†\n[2] Seen through the Kronecker delta function.\n‚ñ†\n[3] Calculated honestly using the divided differences.\n‚ñ†\n[4] Strategy: Define new dummy functions and avoid direct calculation by using their differentiability. Since the setting is complex, it is actually easier to understand from the back.\nClaim: For $E (x) := f(x) - p_{n} (X)$, the following holds. $$ E(t) = {{ (t - x_{0}) \\cdots (t - x_{n}) } \\over { (n+1)! }} f^{(n+1)} ( \\xi ) $$\nPart 1.\nFirstly, if $t$ is the same as the nodal points $x_{0} , \\cdots , x_{n}$, it trivially holds, so assume $t$ is different from these nodal points. $$ \\begin{align*} \\Psi (x) :=\u0026amp; (x - x_{0} ) (x - x_{1}) \\cdots (x - x_{n}) \\\\ G (x) :=\u0026amp; E(x) - {{ \\Psi (x) } \\over { \\Psi (t) }} E(t) \\end{align*} $$ Upon defining the new functions as above, since $f$, $p_{n}$, and $\\Psi$ are $(n+1)$ times differentiable, $G$ is also $(n+1)$ times differentiable.\nPart 2.\nSubstituting $x = x_{i}$ into $G$ leads to $E(x_{i}) = f(x_{i}) - p_{n} (x_{i}) = 0$ and $\\Psi (x_{i} ) = 0$, thus $$ G(x_{i}) = E(x_{i} ) - {{ \\Psi (x_{i}) } \\over { \\Psi (t) }} E(t) = 0 $$ Substituting $x = t$ into $G$ leads to $\\displaystyle {{ \\Psi (t) } \\over { \\Psi (t) }} = 1$, thus $$ G(t) = E(t) - E(t) =0 $$ Therefore, $G$ has $(n+2)$ different zero $x_{0} , \\cdots , x_{n} , t$s.\nPart 3.\nFor convenience, let\u0026rsquo;s say $x_{n+1} :=t$.\nRolle\u0026rsquo;s theorem: If function $f(x)$ is continuous on $[a,b]$, differentiable on $(a,b)$, and $f(a)=f(b)$, then there exists at least one $c$ in $(a,b)$ that satisfies $f ' (c)=0$.\nFor all $i=0, \\cdots , n$, $$ G(x_{i}) = 0 = G(x_{i+1}) $$ hence, by Rolle\u0026rsquo;s theorem, there exists $x'_{i} \\in \\mathscr{H} \\left\\{ x_{i} , x_{i+1} \\right\\}$ satisfying $g ' ( x\u0026rsquo;_{i}) = 0$, and similarly for all $i=0, \\cdots , (n-1)$, $$ g ' (x\u0026rsquo;_{i}) = 0 = g ' (x\u0026rsquo;_{i+1}) $$ hence, by Rolle\u0026rsquo;s theorem, there exists $x''_{i} \\in \\mathscr{H} \\left\\{ x\u0026rsquo;_{i} , x\u0026rsquo;_{i+1} \\right\\}$ satisfying $G''( x\u0026rsquo;\u0026rsquo;_{i}) = 0$. By inductively using Rolle\u0026rsquo;s theorem $(n+1)$ times, it can be guaranteed that there exists $\\xi \\in \\mathscr{H} \\left\\{ x_{0} , \\cdots , x_{n+1} \\right\\}$ satisfying $$ G^{(n+1)} ( \\xi ) = 0 $$\nMeanwhile, since $p_{n}$ is a $n$ degree polynomial, $$ E^{(n+1)} (x) = f^{(n+1)} ( x) $$ The highest degree term of $\\Psi$ is $x^{n+1}$, so $$ \\Psi^{(n+1)} (x) = (n+1)! $$ Differentiating both sides of $\\displaystyle G (x) = E(x) - {{ \\Psi (x) } \\over { \\Psi (t) }} E(t)$ $(n+1)$ times with respect to $x$ gives $$ G^{(n+1)} (x) = f^{(n+1)} ( x) - {{ (n+1)! } \\over { \\Psi (t) }} E(t) $$ Substituting $x=\\xi$ into $G^{(n+1)}$ and $f^{(n+1)}$ yields $$ 0 = f^{(n+1)} ( \\xi ) - {{ (n+1)! } \\over { \\Psi (t) }} E(t) $$ Since $E (t) = f(t) - p_{n} (t)$, it follows that $$ f(t) - \\sum_{j=0}^{n} f( x_{j} ) l_{j} (t) = {{ (t - x_{0}) \\cdots (t - x_{n}) } \\over { (n+1)! }} f^{(n+1)} ( \\xi ) $$\n‚ñ†\nAtkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p131.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1021,"permalink":"https://freshrimpsushi.github.io/en/posts/1021/","tags":null,"title":"Polynomial Interpolation"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Definition 1 For a given pair of data $(n+1)$ and $(x_{0}, y_{0}) , \\cdots , (x_{n} , y_{n})$, the method or the function itself that satisfies $f (x_{i} ) = y_{i}$ while possessing some specific property is called interpolation.\nDescription For example, consider the situation where there\u0026rsquo;s data available as shown above, but the middle part is missing. Of course, it\u0026rsquo;s best to have actual data, but if not, there might be a situation where we need to make predictions to fill in the gaps. In this sense, the term Interpolation is appropriate because it involves filling in the missing parts.\nThe simplest example of interpolation is Linear Interpolation, where points are connected by straight lines. This type of interpolation has the advantage of being intuitive; however, it is not possible to differentiate at each data point. Therefore, if a method is needed to smoothly connect the points as shown below, linear interpolation cannot be used. As such, interpolation isn\u0026rsquo;t limited to just one method, and it\u0026rsquo;s necessary to find the method that meets one\u0026rsquo;s needs or preferences.\nAtkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p131.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1016,"permalink":"https://freshrimpsushi.github.io/en/posts/1016/","tags":null,"title":"Interpolation in Numerical Analysis"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition[^1] A multi-index with order $|\\alpha|$ is a tuple $\\alpha=(\\alpha_{1}, \\alpha_{2}, \\cdots, \\alpha_{n})$ whose components are non-negative integers. Here, $| \\alpha|$ is defined as follows.\n$$ |\\alpha| = \\sum _{i}^{n} \\alpha_{i} = \\alpha_{1} + \\cdots + \\alpha_{n} $$\nNotation For $x = (x_{1}, x_{2}, \\dots, x_{n}) \\in \\mathbb{R}^{n}$, $x^{\\alpha}$ is defined as follows.\n$$ x^{\\alpha} := x_{1}^{\\alpha_{1}} x_{2}^{\\alpha_{2}} \\cdots x_{n}^{\\alpha_{n}} $$\nThe multi-index is often used to represent partial derivatives as follows.\n$$ \\begin{align*} D^\\alpha :=\u0026amp;\\ \\dfrac{\\partial ^{|\\alpha|} } {{\\partial x_{1}}^{\\alpha_{1}}\\cdots {\\partial x_{n}}^{\\alpha_{n}}} \\\\ =\u0026amp;\\ \\left( \\frac{ \\partial }{ \\partial x_{1}} \\right)^{\\alpha_{1}}\\left( \\frac{ \\partial }{ \\partial x_{2}} \\right)^{\\alpha_{2}}\\cdots \\left( \\frac{ \\partial }{ \\partial x_{n}} \\right)^{\\alpha_{n}} \\\\ =\u0026amp;\\ \\partial^{\\alpha_{1}}_{x_{1}}\\cdots\\partial^{\\alpha_{n}}_{x_{n}} \\end{align*} $$\nFor example, if $\\alpha=(2,1,0)$, then $D^{\\alpha} u(x)$ means the following.\n$$ D^{\\alpha} u(x)=\\dfrac{ \\partial^3 u(x)} {\\partial x_{1} \\partial x_{1} \\partial x_{2}}=\\dfrac{ \\partial^3 u(x)} {\\partial x_{1} ^{2} \\partial x_{2}} $$\nAlso, for an integer $k \\ge 0$, $D^k$ is defined as follows.\n$$ D^ku:=\\left\\{ D^{\\alpha} u : |\\alpha|=k \\right\\} $$\n$D^{k}u$ is a set that collects all $D^{\\alpha} u$ for every multi-index $\\alpha$ with order $k$. Note that $k$ is a non-negative integer, not a multi-index. Once an order is assigned to the elements of $D^{k}u$, meaning determined which component is which, $D^k u$ can be thought of as a point in $\\mathbb{R}^{k}$.[^2] See the following example.\nCase 1. $k=1$\nIt means the gradient.\n$$ D^1 u=Du:=(u_{x_{1}},\\ u_{x_{2}},\\ \\cdots,\\ u_{x_{n}})=\\nabla u \\ \\in \\ \\mathbb{R^n} $$\nCase 2. $k=2$\nIt means the Hessian matrix.\n$$ D^2u := \\begin{pmatrix} u_{x_{1}x_{1}} \u0026amp; \\cdots \u0026amp; u{x_{1}x_{n}} \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\cdots \\\\ u_{x_{n}x_{1}} \u0026amp; \\cdots \u0026amp; u_{x_{n}x_{n}} \\end{pmatrix} \\in \\ \\mathbb{R^2} $$\nEspecially, in the case of the Laplacian $u$, it is the same as summing all the diagonal components of the Hessian matrix of $u$.\n$$ \\Delta u=\\nabla^2=\\nabla \\cdot \\nabla u=\\mathrm{div} Du = \\sum_{i=1}^nu_{x_{i}x_{i}} = \\mathrm{tr} (D^2u) $$\n","id":1062,"permalink":"https://freshrimpsushi.github.io/en/posts/1062/","tags":null,"title":"Multi Index Notation"},{"categories":"Î¨ºÎ¶¨Ìïô","contents":"Definitions A wave expressed as a sine function is called a sine wave.\nDescription The general form of a sine wave is as follows. The reason why it\u0026rsquo;s referred to as a sine wave even though the equation is $\\cos$ is explained below, as the real part of the complex wave function is $\\cos$. $\\sin$ is the imaginary part.\n$$ f(x,t) = A \\cos \\big( k(x-vt)+\\delta \\big) $$\nHere, $A$ is the wave\u0026rsquo;s amplitude, the variable $k(z-vt)+\\delta$ of the cosine function is called the phase, and $\\delta$ is the phase constant. Adding $2\\pi$ to the phase constant does not change $f(x,t)$. Therefore, in most cases, values within the range of $0\\le \\delta \\lt 2\\pi$ are used as the phase constant. $k$ is the wave number and has the following relationship with the wavelength $\\lambda$.\n$$ k=\\dfrac{2\\pi}{\\lambda} $$\nThe time it takes for a wave to complete one full cycle is called the period. Since time=distance/speed, the period of the wave $T$ is\n$$ T=\\dfrac{\\lambda}{v} = \\dfrac{2 \\pi}{kv} $$\nSince the period is the time it takes for one vibration, the frequency $\\nu$, which is the number of vibrations per unit time, is naturally the inverse of the period.\n$$ \\nu=\\dfrac{1}{T}=\\dfrac{v}{\\lambda} $$\nAngular frequency is commonly denoted as $\\omega$ and represents the vibration in terms of uniform circular motion. It\u0026rsquo;s the angle turned per unit time, measured in radians.\n$$ \\omega=2\\pi \\nu=2\\pi\\dfrac{1}{T}=kv $$\nIf you represent $(1)$ in terms of angular frequency, you get\n$$ f(x,t)=A \\cos \\big( kx-\\omega t +\\delta \\big) $$\nThis is the wave function moving to the right with wave number $k$ and angular frequency $\\omega$.\nAs shown in the figure above, $\\dfrac{\\delta}{k}$ is defined as the distance the wave function lags behind the origin. Therefore, if the direction of the wave propagation changes, the sign of the phase constant also changes. If the wave moves to the left, it means it lags behind as it moved to the right. Thus, the wave function moving to the left with wave number $k$ and angular frequency $\\omega$ is as follows.\n$$ f(x,t)=A \\cos \\big( kx+\\omega t -\\delta \\big) $$\nHowever, since the cosine function is an even function, the above equation is the same as the equation below. $$ f(x,t)=A \\cos \\big( -kx-\\omega t +\\delta \\big) $$\nThis indicates that compared to the right-moving wave function $(2)$ with wave number $k$ and angular frequency $\\omega$, only the sign of the wave number $k$ is different. In other words, by changing the sign of the wave number $k$, you get a wave that has the same amplitude, phase constant, frequency, wavelength, etc., but moves in the opposite direction.\nComplex Wave Function Since the wave function can be expressed as a cosine, it can also be represented in the form of a complex exponential function using Euler\u0026rsquo;s formula. The reason for specifically dealing with the complex wave function, including its imaginary part, is because in many respects, complex functions are more convenient for calculations. Using $e^{ix}=\\cos x +i\\sin x$ to express $(2)$ results in\n$$ f(x,t)=\\text{Re}(Ae^{i(kx-\\omega t +\\delta)}) $$\nHere, $\\text{Re}(a+ib)=a$ represents the real part. Since $f$ is the function representing only the real part of $Ae^{i(kx-\\omega t +\\delta)}$, let\u0026rsquo;s call it $\\tilde{f}=Ae^{i(kx-\\omega t +\\delta)}$. In other words, $\\text{Re}(\\tilde{f})=f$. Then, it can be simplified as follows.\n$$ \\tilde{f}(x,t)=Ae^{i(kx-\\omega t+\\delta)}=Ae^{i\\delta}e^{i(kx-\\omega t)}=\\tilde{A}e^{i(kx-\\omega t)} $$\nThe wave function $f(x,t)$ discussed in this article is the real part of the complex wave function.\n$$ f(x,t)=\\text{Re}\\big( \\tilde{f}(x,t) \\big) $$\n","id":1066,"permalink":"https://freshrimpsushi.github.io/en/posts/1066/","tags":null,"title":"Sine Waves and Complex Wave Functions"},{"categories":"ÏµúÏ†ÅÌôîÏù¥Î°†","contents":"Definition 1 A scalar function $\\varphi : \\mathbb{R}^{n} \\to \\mathbb{R}$ is called a Cost Function. An algorithm that finds $\\mathbb{x}_{n+1}$ that satisfies $\\varphi ( \\mathbb{x}_{n+1} ) \u0026lt; \\varphi ( \\mathbb{x}_{n} )$ in $\\mathbb{x} = \\mathbb{x}_{n}$ to minimize the cost function $ \\varphi ( \\mathbb{x} )$ is called the Descent Method.\nExplanation Let‚Äôs consider building a house as an example for a cost function, $\\varphi$. The resources required for building a house would include wood, stone, steel, glass, labor costs, real estate, etc., which ultimately boil down to the issue of \u0026lsquo;how much money needs to be spent\u0026rsquo;. In this scenario, $\\varphi$ becomes the function that maps the vector of resources into a scalar of cost. A common question would be \u0026lsquo;what is the minimum cost\u0026rsquo;. Meanwhile, in fields like machine learning, the cost function is also referred to as a loss function, where the question becomes \u0026lsquo;when is the difference between actual values and predicted values minimized\u0026rsquo;.\nNo matter the problem, it can be abstractly summarized as \u0026lsquo;finding the minimum value of a scalar function\u0026rsquo;. The descent method is a method to solve this issue by finding the scalar\u0026rsquo;s local minimum on a $n$ dimensional manifold. It\u0026rsquo;s important to note that it finds a local minimum, not necessarily the minimum. If $\\varphi$ is convex, the descent method might locate the global minimum, but generally, it can only guarantee finding local minima.\nGradient Descent Among various descent methods, gradient descent is the most popular. It finds the local minimum by utilizing the gradient of the cost function. For practical applications of this method, it is recommended to learn about Gradient Descent in Machine Learning.\nFor an appropriate $\\alpha\u0026gt;0$, $\\mathbb{x}_{n+1} := \\mathbb{x}_{n} - \\alpha \\nabla \\varphi ( \\mathbb{x}_{n} )$ is called Gradient Descent.\n$- \\nabla \\varphi ( \\mathbb{x}_{n} )$ indicates the direction in which the manifold decreases most steeply, so if $\\alpha$ is suitable, $\\left\\{ \\mathbb{x}_{n} \\right\\}$ is expected to converge to a local minimum.\nHowever, while this method is straightforward and easy, it\u0026rsquo;s not necessarily faster compared to other methods in terms of convergence speed and is a greedy algorithm. This means it optimizes for the largest decrease at each step locally but might not be the best approach globally.\nCode Below is an implementation of gradient descent in R code, using the numDeriv package to calculate the gradient.\nlibrary(numDeriv)\roptimizer\u0026lt;-function(f,x0,alpha=0.01){\rwhile(abs(f(x0))\u0026gt;10^(-8)){\rx0\u0026lt;-x0-alpha*grad(f,x0)\r}\rreturn(x0)\r}\rz\u0026lt;-function(v){\rreturn((v[1]-2)^2+(v[2]-3)^2)\r}\roptimizer(z,c(0,0))\rz(c(1.999945,2.999918)) The result of executing the above code is as follows:\nThis result is a simple example that demonstrates finding the point which minimizes $z(x,y) = (x-2)^2 + (y-3)^2$. On the following surface, the point where $z$ is minimized is $(2,3)$.\nSee Also Gradient Descent in Machine Learning Atkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p113.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1012,"permalink":"https://freshrimpsushi.github.io/en/posts/1012/","tags":null,"title":"Gradient Descent in Mathematics"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Definition A gradient, specifically referred to as the total derivative of a scalar field $f : \\mathbb{R}^{n} \\to \\mathbb{R}$, is denoted by $\\nabla f$.\n$$ \\begin{align*} \\nabla f := f^{\\prime} =\u0026amp; \\begin{bmatrix} D_{1}f \u0026amp; D_{2}f \u0026amp; \\cdots \u0026amp; D_{n}f\\end{bmatrix} \\\\ =\u0026amp; \\begin{bmatrix} \\dfrac{\\partial f}{\\partial x_{1}} \u0026amp; \\dfrac{\\partial f}{\\partial x_{2}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial f}{\\partial x_{n}} \\end{bmatrix} \\\\ =\u0026amp; \\dfrac{\\partial f}{\\partial x_{1}}\\hat{x}_{1} + \\dfrac{\\partial f}{\\partial x_{2}}\\hat{x}_{2} + \\dots + \\dfrac{\\partial f}{\\partial x_{n}}\\hat{x}_{n} \\end{align*} $$\nDescription Simply put, the gradient is a derivative of a multivariable function. The gradient of a 3-dimensional scalar function, often used in physics and other fields, is as follows.\n$$ \\nabla f = \\dfrac{\\partial f}{\\partial x}\\hat{\\mathbf{x}} + \\dfrac{\\partial f}{\\partial y}\\hat{\\mathbf{y}} + \\dfrac{\\partial f}{\\partial z}\\hat{\\mathbf{z}} = \\left( \\dfrac{\\partial f}{\\partial x}, \\dfrac{\\partial f}{\\partial y}, \\dfrac{\\partial f}{\\partial z} \\right) $$\nA noteworthy aspect is that the derivative of a scalar function, which has scalar function values, becomes a vector function with vector function values. This may be considered obvious from the definition of the total derivative, yet it can also be intuitively understood.\nFor example, consider the image above. This image visually represents the function $z : \\mathbb{R}^{2} \\to \\mathbb{R}$, defined as $z(x,y) = x^2 - y^2$. Unlike functions of the form $y = f(x)$ with only one variable, when thinking about the rate of change of a function with more than two variables, it\u0026rsquo;s necessary to consider not just the magnitude but also the direction of change.\nReflecting this concept, directional derivatives refer to the derivatives in any given direction. Therefore, a multivariable function has an infinitely many directional derivatives, but as demonstrated in the theorem below, the gradient points in the direction of the greatest rate of change.\nProof Let\u0026rsquo;s define the direction vector $\\mathbb{d} : = ( d_1 , \\cdots , d_n )$ that makes $\\left\\| \\mathbb{d} \\right\\| = 1$ possible. By the multivariate Taylor\u0026rsquo;s theorem,\n$$ f \\left( x_{0} + h \\mathbb{d} \\right) = f ( \\mathbb{x}_{0} ) + h \\left[ {{ \\partial f ( \\mathbb{x}_{0} ) } \\over { \\partial x_{1} }} d_{1} + \\cdots + {{ \\partial f ( \\mathbb{x}_{0} ) } \\over { \\partial x_{n} }} d_{n} \\right] + O (h^2) $$\nWhen converted to matrix form,\n$$ f \\left( x_{0} + h \\mathbb{d} \\right) - f ( \\mathbb{x}_{0} ) = h \\begin{bmatrix} {{ \\partial f ( \\mathbb{x}_{0} ) } \\over { \\partial x_{1} }} \\\\ \\vdots \\\\ {{ \\partial f ( \\mathbb{x}_{0} ) } \\over { \\partial x_{n} }} \\end{bmatrix} \\cdot \\begin{bmatrix} d_{1} \\\\ \\vdots \\\\ d_{n} \\end{bmatrix} + O (h^2) $$\nAnd in vector form,\n$$ {{ f \\left( x_{0} + h \\mathbb{d} \\right) - f ( \\mathbb{x}_{0} )} \\over {h}} = \\nabla f \\left( \\mathbb{x}_{0} \\right) \\cdot \\mathbb{d} + O (h) $$\nWhen $h \\to 0$,\n$$ \\nabla f \\left( \\mathbb{x}_{0} \\right) \\cdot \\mathbb{d} = \\lim_{h \\to 0} {{ f \\left( x_{0} + h \\mathbb{d} \\right) - f ( \\mathbb{x}_{0} )} \\over {h}} $$\nThat $\\mathbb{b}$ has the same direction as the slope from $\\mathbb{x}_{0}$ to $f$ means that $\\mathbb{d}$\n$$ \\lim_{h \\to 0} {{ f \\left( x_{0} + h \\mathbb{d} \\right) - f ( \\mathbb{x}_{0} )} \\over {h}} $$\nmaximizes this, implying that the unit vector in question is $\\displaystyle \\mathbb{d} = {{\\nabla f \\left( \\mathbb{x}_{0} \\right) } \\over { \\left\\| \\nabla f \\left( \\mathbb{x}_{0} \\right) \\right\\| }}$. Therefore,\n$$ \\nabla f \\left( \\mathbb{x}_{0} \\right) = \\left\\| \\nabla f \\left( \\mathbb{x}_{0} \\right) \\right\\| \\mathbb{d} $$\nbecomes the gradient of $f$ from $\\mathbb{x}_{0}$.\n‚ñ†\nSee Also Gradient in 3-dimensional Cartesian coordinates Differential coefficient of a vector field: Jacobian matrix ","id":1010,"permalink":"https://freshrimpsushi.github.io/en/posts/1010/","tags":null,"title":"Gradient of Scalar Field"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Definition $D \\subset \\mathbb{R}^{n}$ is defined as the matrix $H \\in \\mathbb{R}^{n \\times n}$ for a multivariate scalar function $f : D \\to \\mathbb{R}$ is called the Hessian matrix of $f$.\n$$ H := \\begin{bmatrix} {{\\partial^2 f } \\over {\\partial x_{1}^2 }} \u0026amp; \\cdots \u0026amp; {{\\partial^2 f } \\over { \\partial x_{1} \\partial x_{n} }} \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ {{\\partial^2 f } \\over {\\partial x_{n} \\partial x_{1} }} \u0026amp; \\cdots \u0026amp; {{\\partial^2 f_{m} } \\over {\\partial x_{n}^2 }} \\end{bmatrix} $$\nDescription For the Hessian of $f$, the following notations are used.\n$$ H,\\quad H(f),\\quad H_{f},\\quad \\mathbf{H},\\quad \\nabla^{2}f $$\nNote that $\\nabla^{2}$ is often used as a notation for the Laplacian.\nIf the Jacobian matrix corresponds to the high-dimensional derivative of a function, then the Hessian matrix can be seen as the high-dimensional second derivative. It might not appear as frequently as the Jacobian matrix, but it does appear occasionally in unexpected places like mathematical statistics. Also, note that the Hessian matrix is defined only for scalar functions.\n","id":992,"permalink":"https://freshrimpsushi.github.io/en/posts/992/","tags":null,"title":"What is a Hessian Matrix?"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Definition An non-linear function that mimics the threshold of real-life organisms is known as an activation function.\nMathematical Definition In deep learning, a non-linear scalar function $\\sigma : \\mathbb{R}^{n} \\to \\mathbb{R}$ is referred to as an activation function.\nOf course, there are exceptions like the softmax which don\u0026rsquo;t fit into this definition. Explanation On the other hand, a vector function is called a layer.\nIf there is an expression or code indicating that the activation function defined by $\\sigma : \\mathbb{R} \\to \\mathbb{R}$ takes a vector as input, it means that it is applied element-wise.\n$$ \\sigma (\\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n} \\end{bmatrix}) = \\begin{bmatrix} \\sigma (x_{1}) \\\\ \\sigma (x_{2}) \\\\ \\vdots \\\\ \\sigma (x_{n}) \\end{bmatrix} $$\nMotivation Threshold refers to the minimum intensity of stimulus required for an organism to produce a response. Deep learning simulates this by applying an activation function to the computation result of each node and passing it to the next layer. Without this nonlinear adjustment, there would be no point in having multiple computations across hidden layers in deep learning. There are various types of activation functions, and which one is best is truly a case-by-case matter. There is hardly any theory on how the performance changes depending on which activation function is used; it\u0026rsquo;s more about trying different ones and sticking with the one that yields good results.\nExamples Step Function $$u (x) := \\begin{cases} 0 \u0026amp; , x\u0026lt;0 \\\\ 1 \u0026amp; x \\ge 0 \\end{cases} $$\nThe step function fits the concept of the threshold the most, but it‚Äôs difficult to use in practice because it oversimplifies the computational result. It‚Äôs good to think that other activation functions were designed to act like step functions but are not exactly step functions.\nSigmoid Function The most famous among sigmoid functions is perhaps the logistic function $\\displaystyle \\sigma (x) := {{1} \\over { 1 + e^{-x} }}$, which looks like a continuous version of step functions. The range is different, but $\\tanh x$ was used for a similar reason. Recently, it has fallen out of favor due to the problem known as gradient vanishing.\nReLu(Rectified Linear Unit) Function $$\\operatorname{ReLU} (x) := \\max \\left\\{ 0 , x \\right\\}$$\nThis function was designed to overcome the issues with the sigmoid function. If it‚Äôs $x \u0026lt;0$, the function value is entirely killed, and it‚Äôs only when it exceeds $0$ that it is passed on as is, which is characteristic of an activation function.\n","id":991,"permalink":"https://freshrimpsushi.github.io/en/posts/991/","tags":null,"title":"Activation Functions in Deep Learning"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Definition Let a multivariable vector function $\\mathbb{f} : D \\to \\mathbb{R}^{m}$ defined by $D \\subset \\mathbb{R}^{n}$ be defined for each scalar function $f_{1} , \\cdots , f_{m} : D \\to \\mathbb{R}$ as follows:\n$$ \\mathbb{f} ( x_{1} , \\cdots , x_{n} ) : = \\begin{bmatrix} f_{1} ( x_{1} , \\cdots , x_{n} ) \\\\ \\vdots \\\\ f_{m} ( x_{1} , \\cdots , x_{n} ) \\end{bmatrix} $$\nIt is called the Jacobian matrix of $\\mathbb{f}$.\nDescription The following notation is also often used:\n$$ J = \\dfrac{\\partial (f_{1}, \\dots f_{m})}{\\partial (x_{1}, \\dots, x_{n})} $$\nThe Jacobian matrix of $\\mathbb{f}$ is also represented by defining an operator $D$ that makes $D \\mathbb{f} := J$. The name Jacobian matrix comes from the 19th-century German mathematician Carl Gustav Jacob Jacobi, so it\u0026rsquo;s correct to write and read it as Jacobian matrix, but in fact, $J$ is very often read as \u0026lsquo;Jacobian\u0026rsquo;.\nIt is also called the total derivative, referring to the derivative of a multivariable vector function. Therefore, if a Jacobian matrix exists for a multivariable function, it is said to be differentiable, and conversely, a differentiable function $f : \\mathbb{R} \\to \\mathbb{R}$ can be thought of as having a Jacobian matrix of size $1 \\times 1$. In simple terms, the Jacobian matrix is the matrix of the derivative of a vector function.\nTypically, it is first encountered in calculus together with polar coordinates, where\n$$ \\int_{B} \\int_{A} f(x,y) dx dy $$\nif you change the Cartesian coordinates used to $x= r \\cos \\theta$, $y= r \\sin \\theta$ as well known,\n$$ \\int_{B} \\int_{A} f( r \\cos \\theta , r \\sin \\theta ) r dr d \\theta $$\nan additional $r$ is attached as follows. This is because\n$$ \\begin{bmatrix} {{\\partial x } \\over {\\partial r }} \u0026amp; {{\\partial x } \\over {\\partial \\theta }} \\\\ {{\\partial y } \\over {\\partial r }} \u0026amp; {{\\partial y } \\over {\\partial \\theta }} \\end{bmatrix} = \\begin{bmatrix} \\cos \\theta \u0026amp; \\sin \\theta \\\\ -r \\sin \\theta \u0026amp; r \\cos \\theta \\end{bmatrix} $$\nthe determinant of the matrix is derived as $r \\cos^2 \\theta + r \\sin^2 \\theta = r$. In the same sense, the Jacobian matrix is essentially the same concept already encountered in high school when doing variable substitution for integration. For example,\n$$ \\int_{0}^{1} ( 27x^3 + 9 x^2 + 3 x ) dx $$\nconsider doing the substitution like $3x = y$ when calculating. If this is viewed as $y$ being the function $y(x) = 3x$ of $x$, then its Jacobian matrix is\n$$ \\begin{bmatrix} {{\\partial 3x } \\over {\\partial x }} \\end{bmatrix} = \\begin{bmatrix} 3 \\end{bmatrix} $$\nThis is the same as differentiating both sides of $3x = y$ with respect to their variables to obtain $3dx = dy$.\nSee Also Differential coefficients of scalar fields: Del operator Coordinate transformation and Jacobian ","id":989,"permalink":"https://freshrimpsushi.github.io/en/posts/989/","tags":null,"title":"Jacobian Matrix or Jacobi Matrix"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Definition Deep learning is a type of machine learning that uses artificial neural networks, especially employing multiple layers when constructing these networks.\nMotivation Just like the human brain is composed of a complex network of neurons, deep learning also enhances performance by making the connections in artificial neural networks more complex. Similar to how the stimuli received by sensory cells are transmitted to the brain through the spinal cord, artificial neural networks pass calculations through multiple layers. These layers are called hidden layers.\nMoreover, just as every person\u0026rsquo;s brain is different, based on the structure of the artificial neural network, there are problems it can solve well and problems it cannot. Therefore, constructing an artificial neural network that fits well with the problem and optimizing it is also a hot issue in this field.\n","id":996,"permalink":"https://freshrimpsushi.github.io/en/posts/996/","tags":null,"title":"What is Deep Learning?"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Overview The Gradient Descent Algorithm is the simplest method among algorithms that find the local minimum of the loss function by using the gradient of the loss function.\nDescription Here, the loss function $L$ is considered a function of weights and biases with the dataset $X$ being fixed. If the input data looks like $\\mathbb{x} \\in \\mathbb{R}^{m}$, then $L$ becomes a function of $(w_{1} , w_{2} , \\cdots , w_{m} , b) \\in \\mathbb{R}^{m+1}$. Even with the same data, the value of the loss function varies depending on the weights and biases, and a decrease in the loss function indicates a better model has been made.\nThe Gradient Descent follows the manifold created by this function $L$ to find the optimal weights that result in a local minimum. To understand this principle in more detail, it\u0026rsquo;s beneficial to study about the gradient descent in numerical analysis.\nThe loss function\u0026rsquo;s value for the first chosen vector of weights and biases $\\mathbb{w}_{1} \\in \\mathbb{R}^{m+1}$ can be further reduced to $\\mathbb{w}_{2}$ by some appropriate positive number $\\alpha$ as computed by $$ \\mathbb{w}_{2} := \\mathbb{w}_{1} - \\alpha \\nabla L (\\mathbb{w}_{1} ) $$. Repeating this, $$ \\mathbb{w}_{n+1} := \\mathbb{w}_{n} - \\alpha \\nabla L (\\mathbb{w}_{n} ) $$, can also further decrease the value of the loss function. This process of updating $\\mathbb{w}_{n}$ is called Backpropagation. In machine learning, $\\alpha$ is referred to as the Learning Rate, and depending on this value, the gradient descent may or may not succeed.\nSuccess is as depicted above, where repeated calculations accurately find the weights and biases that make $L$ a local minimum. Especially, in the picture, it is both a local and absolute minimum, though usually, a local minimum may not definitely be the absolute minimum.\nIf $\\alpha$ is too large, the values change significantly, speeding up the learning process, but if it\u0026rsquo;s excessively large, it could fail to converge, as shown above. This is referred to as Overshooting.\nConversely, if $\\alpha$ is too small, mathematical convergence is guaranteed, but the change is so minimal that it takes too much time, and if it gets stuck in a local minimum, it can\u0026rsquo;t escape from its vicinity.\nThis is the basic concept of gradient descent, and in practice, various techniques are utilized to mitigate such issues.\nStochastic Gradient Descent Applying gradient descent after each mini-batch is called stochastic gradient descent or SGD. Some sources describe it as follows:\nLearning with batch learning: Batch gradient descent Learning with mini-batch learning: Mini-batch gradient descent Learning with online learning: Stochastic gradient descent However, this distinction is practically useless. Typically in deep learning, only mini-batch learning is used, and setting the batch size to $1$ turns it into online learning. Thus, in actual deep learning practices, \u0026ldquo;gradient descent = stochastic gradient descent = mini-batch gradient descent\u0026rdquo; is an acceptable interpretation.\nThe term \u0026ldquo;stochastic\u0026rdquo; doesn\u0026rsquo;t need to be heavily emphasized. If the entire dataset is seen as a population, then learning with mini-batches is akin to repeatedly learning from sample populations, hence the term \u0026ldquo;stochastic\u0026rdquo; is appropriate.\nSee Also Gradient Descent in Optimization Theory Stochastic Gradient Descent in Optimization Theory ","id":987,"permalink":"https://freshrimpsushi.github.io/en/posts/987/","tags":null,"title":"Gradient Descent and Stochastic Gradient Descent in Machine Learning"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Overview Without a doubt, this is the easiest explanation about tensors, so if you\u0026rsquo;re an undergraduate in physics who came here because you don\u0026rsquo;t know what a tensor is, I highly recommend reading this.\nWe\u0026rsquo;re not accepting corrections about mathematical inaccuracies. Teaching someone who hasn\u0026rsquo;t learned about negative numbers that \u0026lsquo;you can\u0026rsquo;t subtract a larger number from a smaller number\u0026rsquo;, or someone who hasn\u0026rsquo;t learned about complex numbers that \u0026lsquo;you can\u0026rsquo;t have a negative number under a square root\u0026rsquo; is not considered teaching incorrect information. The purpose of this article is not to teach the exact definition of a tensor, but to prevent unnecessary time wastage in trying to understand tensors.\nAs you study physics and move up the grades, you will come across something called a tensor. The first tensor I remember seeing was the moment of inertia tensor in mechanics.\n$$ \\mathbf{I} =\\overleftrightarrow{\\mathbf{I}}= \\begin{pmatrix} I_{xx} \u0026amp; I_{xy} \u0026amp; I_{xz} \\\\ I_{yx} \u0026amp; I_{yy} \u0026amp; I_{yz} \\\\ I_{zx} \u0026amp; I_{zy} \u0026amp;I_{zz} \\end{pmatrix} $$\nAt the time, as a sophomore, it was impossible for me to understand what this was. Despite searching through various books or online, it was difficult to grasp what a tensor was1. I forced myself to try and understand the concept of a tensor despite lacking the necessary knowledge to accurately grasp it. I was as interested in physics as I was in mathematics; hence, I couldn\u0026rsquo;t just use or accept the definition and meaning of a tensor without knowing what exactly it was. However, it\u0026rsquo;s clear that this isn\u0026rsquo;t a good attitude towards studying physics.\nWhile it\u0026rsquo;s possible to accept and understand the mathematical definition of a tensor, doing so would require deep knowledge in linear algebra2. This goes far beyond the mathematics needed for undergraduate physics. Studying mathematics is certainly helpful for studying physics, but this case is an overkill. Trying to understand tensors mathematically could very well ruin your mechanics midterm. So, for an undergraduate in physics, it\u0026rsquo;s important to simply \u0026lsquo;feel\u0026rsquo; what a tensor is. It\u0026rsquo;s enough to look at various examples to understand why it\u0026rsquo;s needed, how, and when it\u0026rsquo;s used. Much of physics uses mathematics loosely, but that\u0026rsquo;s because the mathematical rigor is guaranteed. Since tensors too have this rigor guaranteed, there\u0026rsquo;s no need for undergraduates studying physics to chase after this rigor.\nThe concept of a tensor arises because there are physical quantities that cannot be represented solely by scalars and vectors. In fact, tensors can represent all physical quantities, making them a general concept that includes scalars and vectors. So, you can just use tensors without mentioning scalars and vectors. However, that would be inefficient and not helpful at all when first learning physics, so tensors that are scalars and vectors are not specifically called tensors. In undergraduate physics, what is often referred to as a tensor is represented by a $3\\times 3$ matrix. If you hate reading long articles or can\u0026rsquo;t understand them, thinking \u0026lsquo;a 3x3 matrix is considered a tensor, I guess,\u0026rsquo; is fine. As far as undergraduate studies are concerned, this isn\u0026rsquo;t an incorrect explanation.\nClassification of Tensors Tensors are generally denoted as $(m,n)$-tensor or $\\binom{m}{n}$tensor. Here, $m$ represents the dimension of space, and $n$ represents the number of subscripts attached to the components of the tensor. In this case, the number of components of a tensor is $m^{n}$. In most physics excluding relativity, space is always 3-dimensional, so it\u0026rsquo;s always $m=3$. Therefore, without specifically mentioning how many $m$s there are, tensors are classified into $0$order tensors, $1$order tensors, and so on, based on the value of $n$.\n$0$Order Tensor=Scalar $0$ order tensor signifies a $\\binom{3}{0}$tensor, and this is equivalent to a scalar. A typical example of a $0$order tensor is mass. In 3-dimensional space, mass is simply represented by $m$, so there are 0 subscripts, making it a $0$order tensor. However, this is usually referred to as a scalar, not a tensor. The number of components is $3^0=1$.\n$1$Order Tensor=Vector $1$ order tensor signifies a $\\binom{3}{1}$tensor, and this is equivalent to a vector. A typical example of a $1$order tensor is velocity. In 3-dimensional space, velocity is denoted by $\\mathbf{v}=(v_{x},v_{y},v_{z})$, and since there\u0026rsquo;s one subscript attached to its components, it\u0026rsquo;s a $1$order tensor. However, this is usually referred to as a vector, not a tensor. The number of components is $3^1=3$.\n$2$Order Tensor A $2$ order tensor refers to a $\\binom{3}{2}$tensor. Consider the following $3 \\times 3$ matrix.\n$$ A=\\begin{pmatrix} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\\\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \\end{pmatrix} $$\nThe components of the matrix are represented by $a_{ij}$, and since there are two subscripts, it‚Äôs a $2$order tensor. Usually, undergraduate physics textbooks refer to a $3 \\times 3$ matrix as being a tensor, rather than specifically calling it a $2$order tensor. The Kronecker delta $\\delta_{ij}$ also has two subscripts, hence it is a $2$order tensor. However, textbooks don\u0026rsquo;t typically call the Kronecker delta a tensor.\n$$ \\begin{align*} \\delta_{ij}\u0026amp;=\\begin{cases} 1 \u0026amp; \\mathrm{if} \\quad i=j \\\\ 0 \u0026amp; \\mathrm{if} \\quad i\\ne j \\end{cases} \\\\ \u0026amp;= \\begin{pmatrix} \\delta_{11} \u0026amp; \\delta_{12} \u0026amp; \\delta_{13} \\\\ \\delta_{21} \u0026amp; \\delta_{22} \u0026amp;\\delta_{23} \\\\ \\delta_{31} \u0026amp;\\delta_{32} \u0026amp;\\delta_{33} \\end{pmatrix} = \\begin{pmatrix} 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix} \\end{align*} $$\nThe number of components is $3^2=9$.\n$3$Order Tensor A notable example is the Levi-Civita symbol.\n$$ \\epsilon_{ijk}=\\begin{cases} 1 \u0026amp; \\mathrm{if} \\quad ijk=123=231=312 \\\\ -1 \u0026amp; \\mathrm{if} \\quad ijk=132=213=321 \\\\ 0 \u0026amp; \\mathrm{if} \\quad i=j \\ \\mathrm{or}\\ j=k\\ \\mathrm{or} \\ k=i \\end{cases} $$\nSince there are three subscripts, it‚Äôs a $3$order tensor. However, textbooks usually don\u0026rsquo;t refer to the Levi-Civita symbol as a tensor. The number of components is $3^3=27$.\n$4$Order Tensor By now, you should understand that a $4$order tensor refers to a physical quantity with four subscripts, but tensors of $4$order and higher don\u0026rsquo;t appear in undergraduate physics.\nWikipedia explains tensors as the most general concept possible, which also means it‚Äôs explained in the most difficult way possible.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe level of linear algebra commonly taught to second-year mathematics students is far from sufficient.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1040,"permalink":"https://freshrimpsushi.github.io/en/posts/1040/","tags":null,"title":"In Physics, What is a Tensor"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Formulas Maxwell\u0026rsquo;s Equations\n$(\\text{i}) \\quad \\nabla \\cdot \\mathbf{E}=\\dfrac{1}{\\epsilon_{0}}\\rho$ (Gauss\u0026rsquo;s Law)\n$(\\text{ii}) \\quad \\nabla \\cdot \\mathbf{B}=0$ (Gauss\u0026rsquo;s Law for Magnetism)\n$(\\text{iii}) \\quad \\nabla \\times \\mathbf{E} = -\\dfrac{\\partial \\mathbf{B}}{\\partial t}$ (Faraday\u0026rsquo;s Law)\n$(\\text{iv}) \\quad \\nabla \\times \\mathbf{B} = \\mu_{0} \\mathbf{J}+\\mu_{0}\\epsilon_{0}\\dfrac{\\partial \\mathbf{E}}{\\partial t}$ (Amp√®re\u0026rsquo;s Law)\nDescription1 Before Maxwell completed the Maxwell\u0026rsquo;s equations, the four equations concerning the electric field and the magnetic field were as follows:\n$(\\text{i}) \\quad \\nabla \\cdot \\mathbf{E}=\\dfrac{1}{\\epsilon_{0}}\\rho$\n$(\\text{ii}) \\quad \\nabla \\cdot \\mathbf{B}=0$\n$(\\text{iii}) \\quad \\nabla \\times \\mathbf{E} = -\\dfrac{\\partial \\mathbf{B}}{\\partial t}$\n$(\\text{iv}) \\quad \\nabla \\times \\mathbf{B} = \\mu_{0} \\mathbf{J}$\nTheoretically, nearly all of electromagnetism can be explained with just these four equations concerning the divergence and the curl of the electric and magnetic fields. They weren\u0026rsquo;t grouped together without reason. However, there was a significant error in the above formula $\\text{(iv)}$. Since the divergence of curl is always $0$, taking the divergence of $(\\text{iv})$ results in the following.\n$$ \\begin{equation} 0 = \\nabla \\cdot (\\nabla \\times \\mathbf{B})=\\mu_{0} (\\nabla \\cdot \\mathbf{J}) \\ne 0 \\end{equation} $$\nHere is where a problem arises. While Amp√®re\u0026rsquo;s Law holds well with a constant current, making the right side $0$, it is not generally the case.\nTo make the right side $0$, an idea comes from using the continuity equation and Gauss\u0026rsquo;s law to change the right side:\n$$ \\nabla \\cdot \\mathbf{J}=-\\dfrac{\\partial \\rho}{\\partial t}=-\\dfrac{ \\partial( \\epsilon_{0} \\nabla \\cdot \\mathbf{E})}{\\partial t}=-\\nabla \\cdot \\left(\\epsilon_{0} \\dfrac{\\partial \\mathbf{E}}{\\partial t } \\right) $$\nTherefore, using $\\mathbf{J}+\\epsilon_{0}\\dfrac{\\partial \\mathbf{E} }{\\partial t}$ instead of $\\mathbf{J}$ can make the right side of $(1)$ become $0$. The corrected $\\text{(iv)}$ is as follows:\n$$ \\text{(iv)} \\quad \\nabla \\times \\mathbf{B} = \\mu_{0}\\mathbf{J} + \\mu_{0}\\epsilon_{0}\\dfrac{\\partial \\mathbf{E}}{\\partial t} $$\nThe modified formula still satisfies magnetostatics, correcting the faulty part without violating the existing laws. Indeed, there is a reason this was corrected later by Maxwell. Many laws of electromagnetism were discovered and proven through experiments. However, the difference in magnitudes between the two terms of the above formula is usually so significant that it was incredibly hard to discover experimentally.\n$$ \\left| \\epsilon_{0}\\dfrac{\\partial \\mathbf{E}}{\\partial t} \\right| \\ll \\left| \\mathbf{J} \\right| $$\nThe formula modified by Maxwell encapsulates the idea that 'a changing electric field generates a magnetic field'. This was confirmed in 1888 by Hertz\u0026rsquo;s electromagnetic wave experiment.\nDavid J. Griffiths, Introduction to Electrodynamics (4th Edition, 2014), p356-359\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1038,"permalink":"https://freshrimpsushi.github.io/en/posts/1038/","tags":null,"title":"Maxwell's Equations"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Definition Let $D$ be a subset $D\\subset \\mathbb{R}^{n}$ of the $n$-dimensional Euclidean space.\nFunctions having $D$ as their domain are called function of several variables. $f : D \\to \\mathbb{R}$ is called a scalar function. For a scalar function $f_{1} , \\cdots , f_{m} : D \\to \\mathbb{R}$, $\\mathbb{f} : D \\to \\mathbb{R}^{m}$ defined as follows is called a vector-valued function. $$ \\mathbb{f} ( x_{1} , \\cdots , x_{n} ) : = \\begin{bmatrix} f_{1} ( x_{1} , \\cdots , x_{n} ) \\\\ \\vdots \\\\ f_{m} ( x_{1} , \\cdots , x_{n} ) \\end{bmatrix} $$ Explanation Function of Several Variables Terms to denote a function of several variables include function of several variables, multivariable function, multivariate function, etc.\nThe term function of several variables is mainly used in analysis, including calculus. Originally, whether it\u0026rsquo;s a scalar function or a vector-valued function, it\u0026rsquo;s just a function. The term is used only to easily distinguish their codomains. From the perspective of linear algebra, if a vector-valued function is $m=1$, it can be said to become a scalar function, so there is essentially no conceptual difference.\nScalar Function As an example of scalar functions, consider $ F ( m , a ) := ma$. Whether $m$ is mass or $a$ is acceleration, to a mathematician, it should appear as a $2$-dimensional vector like $(m , a) \\in \\left( [0,\\infty) \\times \\mathbb{R} \\right) \\subset \\mathbb{R}^2$. $ma$ is simply the product of the two real numbers $m$ and $a$, and since $ma \\in \\mathbb{R}$, it well satisfies the condition of a scalar function. Meanwhile, in vector calculus, it is also called a Scalar Field since there is a scalar value corresponding to every point in the given space.\nVector-valued Function As an example of vector-valued functions, consider\n$$ \\mathbb{q} ( m , v , a ) : = \\begin{bmatrix} ma \\\\ mv \\\\ {{1} \\over {2}} m v^2 \\end{bmatrix} $$. To a physicist, the components might respectively be force, momentum, and kinetic energy, but simply considering it as a vector-valued function it\u0026rsquo;s nothing more than $\\mathbb{q} : D \\to \\mathbb{R}^3$. Meanwhile, in vector calculus, it is also called a Vector Field since there is a vector corresponding to every point in the given space.\n","id":970,"permalink":"https://freshrimpsushi.github.io/en/posts/970/","tags":null,"title":"Scalar Functions and Vector-valued Functions"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Definition When an estimate for the data $Y = \\begin{bmatrix} y_{1} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix}$ is given as $\\widehat{Y} = \\begin{bmatrix} \\widehat{ y_{1} } \\\\ \\vdots \\\\ \\widehat{y_{n}} \\end{bmatrix}$, the scalar function $L : \\mathbb{R}^{n} \\to [ 0 , \\infty )$ that represents the discrepancy between the data and its estimate is called a loss function.\nAlternate Names The loss function is used as an indicator to evaluate how much the estimated value of data obtained through learning differs from the actual data. The larger this value, the more incorrect it is, and if this value is $0$, it means there is \u0026rsquo;no loss,\u0026rsquo; which implies a perfect estimate. This is not much different from the metric as discussed in mathematics.\nSince the term was originally used in economics, $L$ is sometimes referred to as the Cost Function.\nTypes The following two are representative types of loss functions, and it\u0026rsquo;s sufficient to know only as much as needed to use them appropriately.\nMSE(Mean of Squared Error) $$ L \\left( \\widehat{Y} \\right) := {{1} \\over {n}} \\sum_{i=1}^{n} ( y_{i} - \\widehat{ y_{i} } )^2 $$ MSE is a time-honored loss function, which can be meaningfully used when $y_{i} \\in \\mathbb{R}$.\nCross Entropy $$ L \\left( \\widehat{Y} \\right) := - {{1} \\over {n}} \\sum_{i=1}^{n} \\left\u0026lt; y_{i} , \\log \\left( \\sigma ( \\hat{y_{i}} ) \\right) \\right\u0026gt; $$\nCross Entropy becomes effective when doing what is known as one-hot encoding, and computes using the probabilities that $\\widehat{Y}$ estimated for each category, when $Y$ is categorical data. It is primarily used in classification problems.\nOne-hot encoding simply refers to the mapping to the standard basis. When there are $m$ classes, the standard basis in $\\mathbb{R}^{n}$ is denoted by $\\beta = \\left\\{ e_{i} \\right\\}_{i=1}^{m}$, and each of $y_{i}$ and $\\hat{y_{i}}$ is\n$$ y_{i} \\in \\mathbb{R}^{m},\\qquad \\hat{y}_{i} \\in \\beta $$\nrepresented as a vector like above. For example, when there are 3 classes in $Y$, if $y_{i}$ belongs to the 1st class then $y_{i} = [1,0,0]^{t}$, if it belongs to the $3$ class then $y_{i} = [0,0,1]^{t}$ is how it is represented.\n$\\sigma$ is the softmax function, a function that bounds the given vector\u0026rsquo;s values within $[0,1]$ and satisfies the conditions of a probability distribution. $\\left\u0026lt; \\cdot , \\cdot \\right\u0026gt;$ is the dot product. Since $\\sigma ( \\hat{y_{i}} ) \\in [0,1]$, it leads to $\\log \\left( \\sigma ( \\hat{y_{i}} ) \\right) \u0026lt; 0$ and $y_{i}$ is therefore either $0$ or $1$ thus $$ L \\left( \\widehat{Y} \\right) = - {{1} \\over {n}} \\sum_{i=1}^{n} \\left\u0026lt; y_{i} , \\log \\left( \\sigma ( \\hat{y_{i}} ) \\right) \\right\u0026gt; \\ge 0 $$ can be easily checked.\nThe individual components of the estimate $\\hat{ y_{i} } = ( \\hat{ y_{i1} } , \\cdots , \\hat{y_{ij}} , \\cdots , \\hat{y_{im}} )$ of $y_{i} = ( y_{i1} , \\cdots , y_{ij} , \\cdots , y_{im} )$ have higher values as the probability increases, and lower values as it decreases. When these are input into the softmax function, the more likely probabilities are adjusted closer to $1$ and the less likely ones closer to $0$. If the actual component was $1$ but was calculated with a lower probability, then $- 1 \\cdot \\log (c)$ being $c\\ll 1$ will result in a significantly large value. Conversely, even if the actual component was $0$ and the probability was calculated to be high, $- 0 \\cdot \\log(c)$ would not be very significant. Thus, it can be easily surmised that the cross entropy will skyrocket the more mistakes are made.\nSee Also Loss Function in Numerical Analysis ","id":967,"permalink":"https://freshrimpsushi.github.io/en/posts/967/","tags":null,"title":"Loss Functions in Machine Learning"},{"categories":"Í∑∏ÎûòÌîÑÏù¥Î°†","contents":"Definitions 1 A set comprising vertices and lines connecting vertices is called a graph or a network. Let\u0026rsquo;s denote the set of vertices as $V$ and the set of lines as $E$. Elements of $V(G) := V$ are called vertices or nodes of $G$. Elements of $E(G) := E$ are called edges or links of $G$. An edge that connects to the same vertex is called a loop. If two vertices are connected by an edge, they are said to be adjacent. A graph with directed edges is called a digraph. A graph with a finite number of vertices, with only one edge connecting two vertices, no loops, and not being a digraph, is called a simple graph. Explanation Although not always, there is a tendency to prefer the term graph in pure mathematics and network in applied mathematics, even though the concepts are the same. However, whether one or the other, there are synonyms, and each term has significant influence in its field, so they are not usually used interchangeably.\nGenerally, a graph is as freely shaped as illustrated above. The black circles represent each vertex, which do not embody the concept of location. In pure graph theory, the order of a graph is usually referred to the cardinality $n = |V(G)|$ of the vertex set. The order of the above graph is $5$. The edges connecting vertices similarly only represent their relationships without embodying shape or length concepts. Note that Edge is correctly pronounced [ÏóêÏßÄ] rather than [ÏóóÏßÄ] as often intuitively thought by Koreans. In pure graph theory, the size of a graph is usually referred to the cardinality $m = |E(G)|$ of the edge set. The size of the above graph is $8$. However, in applied network theory, size often refers to the graph\u0026rsquo;s order $|V(G)|$. This distinction must be made according to the context of the field. The vertex at the top left has an edge connecting to itself, which is why it is called a loop. Being adjacent means to be connected by an edge, emphasizing the relationship rather than any visible distance. If two vertices $u, v$ are adjacent, it is represented as $u \\sim v$, and the set of vertices adjacent to vertex $v \\in V(G)$ in graph $G$ is represented as the neighborhood $v$ like $N_{G} (v)$. A digraph, as shown above, is a graph with directional edges. In a digraph, edges are sometimes called arcs. An edge going from vertex $u$ to $v$ is denoted as $u \\to v$, with $u$ called the tail and $v$ called the head. The term simple graph might sound complicated, but simply put, it refers to a clean graph like the above picture without loops, multi-edges, or directions. Generally, graph theory tends to focus on such simple structures. Complex Definitions These definitions, while making the concept of graphs easier to understand, somewhat lack rigor. Thus, the following more complex definitions are introduced. The concepts are essentially the same as those simply defined above, so there should not be much difficulty in understanding them if one is familiar with mathematical expressions.\n$G := \\left( V, \\sim \\right)$ is called a graph or a network with respect to a set $V \\ne \\emptyset$ and a binary relation $\\sim \\subset V^2$. Elements of $V(G) := V$ are called vertices or nodes of $G$. Elements of $E(G) := \\sim$ are called edges or links of $G$. For $v \\in V(G)$, $(v,v) \\in E(G)$ is called a loop. If for $v_{1} , v_{2} \\in V(G)$, $(v_{1} , v_{2} ) \\in E(G)$ is true, then $v_{1}$ and $v_{2}$ are said to be adjacent. If $\\sim$ is not a symmetric relation, it\u0026rsquo;s called a digraph. For a finite set $V$ with a symmetric relation $\\sim \\subset \\left\\{ (v_{1} , v_{2} ) \\in V^2 \\mid v_{1} \\ne v_{2} \\right\\}$ acting as edges and having only one edge connecting two vertices, the graph is called a simple graph. Wilson. (1970). Introduction to Graph Theory: p8~9.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":966,"permalink":"https://freshrimpsushi.github.io/en/posts/966/","tags":null,"title":"Graphs and Networks in Mathematics"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Definition An artificial neural network (ANN) is a network mimicking the nervous system of actual organisms.\nMathematical Definition In deep learning, a vector function $W : \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$ is referred to as a layer. In deep learning, a nonlinear scalar function $\\sigma : \\mathbb{R} \\to \\mathbb{R}$ is referred to as an activation function. The composition $\\sigma \\circ W$ of layers and activation functions is called an artificial neural network. Motivation The nervous system is composed of neurons. A nerve cell body receives stimuli through dendrites and transmits electrical stimuli through axons. Many organisms, including humans, have evolved such simple neuronal connections to be suitable for their environments. As a result, the nervous system is capable of complex tasks such as detecting light, moving legs, remembering, or imagining.\nThe artificial neural network refers to a network that mimics neurons, with the nerve cell body as a node and the axon as a link. Each node, like a nerve cell body, performs calculations that can yield meaningful results from receiving and transmitting information.\nExample As a simple example, consider the problem of understanding the correlation between data $Y := \\begin{bmatrix} 5 \\\\ 7 \\\\ 9 \\end{bmatrix}$ and $X := \\begin{bmatrix} 2.2 \\\\ 3.1 \\\\ 3.9 \\end{bmatrix}$ regarding $Y$ and $X$.\nSince this problem is quite easy, one can guess without difficulty that there is a linear correlation like $Y \\approx {\\color{red}2} X + \\color{blue}{1}$.\nIf we solve this problem through simple regression analysis $Y \\gets X$, it becomes a problem of finding the least square solution $( \\color{blue} {\\beta_{0} } , {\\color{red}\\beta_{1}} )$ when represented by a design matrix. $$ \\begin{bmatrix} 5 \\\\ 7 \\\\ 9 \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; 2.2 \\\\ 1 \u0026amp; 3.1 \\\\ 1 \u0026amp; 3.9 \\end{bmatrix} \\begin{bmatrix} \\color{blue} {\\beta_{0} } \\\\ {\\color{red}\\beta_{1}} \\end{bmatrix} $$\nOn the other hand, the artificial neural network for this problem can be configured as follows:\nFirst, let\u0026rsquo;s assume a relationship like $Y = {\\color{red}w} X + \\color{blue}{b}$. In this case, $\\color{red}{w}$ is called the Weight, and $\\color{blue}{b}$ is called the Bias. The node receiving the given data $\\begin{bmatrix} 2.2 \\\\ 3.1 \\\\ 3.9 \\end{bmatrix}$ first randomly calculates $\\begin{bmatrix} {\\color{red}w_{1}} 2.2 +\\color{blue}{b_{1}} \\\\ {\\color{red}w_{1}} 3.1 +\\color{blue}{b_{1}} \\\\ {\\color{red}w_{1}} 3.9 +\\color{blue}{b_{1}} \\end{bmatrix}$ using $( {\\color{red}w_{1}} , \\color{blue}{b_{1}} )$ and passes it to node $Y$.\nIf these roughly guessed values are unsatisfactory, one continues to update with better weights until satisfactory results are obtained.\nIn this sense, artificial neural networks can be seen as implementing the concept of Machine Learning, where machines learn on their own, and this process has evolved into Deep Learning, which is more complex yet efficient.\nTheoretical Aspect Those familiar with statistics or mathematics often express strong aversion to these techniques due to the lack of theoretical foundations. There is no known condition for minimizing errors or optimizing learning, and often the reasons why certain functions are used are unknown. But if a new paper\u0026rsquo;s technique improves performance in benchmarks, there is nothing to argue against it.\nWhile there might have been scholars who attempted a mathematical approach to these things, the sad reality is that by the time some progress is made in research, the industry has already moved on, rendering these efforts outdated. From the perspective of someone studying theory, it seems hardly worthwhile.\nNevertheless, these techniques cannot be underestimated because the performance is too good to mistrust the results. Deep learning is an irresistible temptation in data science. Even if the trend passes quickly, the performance is overwhelmingly beneficial to learn, and while it may not be as rigorous as mathematics, the field is laying its own theoretical foundations so it\u0026rsquo;s not bad to keep an open mind.\nSee Also Mathematical basis of deep learning, proof of the Cybenko theorem ","id":962,"permalink":"https://freshrimpsushi.github.io/en/posts/962/","tags":null,"title":"What is an Artificial Neural Network?"},{"categories":"ÎèôÏó≠Ìïô","contents":"Definition Chaotic Orbit1 An orbit of map $f : \\mathbb{R} \\to \\mathbb{R}$ is said to be chaotic if it satisfies the following conditions:\n(i) It is not asymptotically periodic. (ii): $h (x_{1} ) \u0026gt; 0$ A bounded orbit is an $M \\in \\mathbb{R}$ for which there exists a $|x_{n} | \u0026lt; M$ that satisfies all $n \\in \\mathbb{N}$. $h(x_{1} )$ refers to the Lyapunov exponent. Chaotic Map A map $f$ is said to be chaotic if there exists a periodic-$n$ orbit for all $n \\in \\mathbb{N}$.\nExplanation Based on English pronunciation, Chaos is closer to [kay-oss] rather than [ka-oss], and Chaotic is closer to [kay-ott-ik] instead of [ka-ot-tik], hence the transliteration to chaotic. In mathematics, when conditions and equations are given, one can find the desired answers. However, in a chaotic orbit, since the Lyapunov exponent is positive, no matter how much the map is iterated, it does not synchronize or attract, and it is even impossible to find a similar periodic orbit. This defines mathematically the fact that the distant future cannot be predicted, no matter how well the current conditions are known.\nOne point to clarify is that the existence of a chaotic orbit in a system created by map $f$ does not mean that the system itself is chaotic.\nGeneralization Chaos in Multidimensional Maps Yorke. (1996). CHAOS: An Introduction to Dynamical Systems: p110.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":864,"permalink":"https://freshrimpsushi.github.io/en/posts/864/","tags":null,"title":"Chaos in One-Dimensional Maps"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition When $s\u0026lt; t \u0026lt; t+u$, a stochastic process $\\left\\{ W_{t} \\right\\}$ that satisfies the following conditions is called a Wiener Process:\n(i): $W_{0} = 0$ (ii): $\\left( W_{t+u} - W_{t} \\right) \\perp W_{s}$ (iii): $\\left( W_{t+u} - W_{t} \\right) \\sim N ( 0, u )$ (iv): The sample paths of $W_{t}$ are almost surely continuous. Basic Properties [1]: $\\displaystyle W_{t} \\sim N ( 0 , t )$ [2]: $\\displaystyle E ( W_{t} ) = 0$ [3]: $\\displaystyle \\text{Var} ( W_{t} ) = t$ [4]: $\\displaystyle \\text{cov} ( W_{t} , W_{s} ) = E (W_{t}W_{s}) = {{1} \\over {2}} (|t| + |s| - |t-s|) = \\min \\left\\{ t , s \\right\\}$ Description The Wiener Process is also called Brownian Motion.\n(ii): Having $\\left( W_{t+u} - W_{t} \\right) \\perp W_{s}$ means that\n(iii): The increments follow a normal distribution $N(0,t)$, signifying that the Wiener Process does not care about specific points in time, but the uncertainty increases as the difference between two points in time increases.\n(iv): The fact that sample paths are almost surely continuous means that if there is a point following the Wiener process, the chance of it \u0026rsquo;teleporting\u0026rsquo; is as if $0$. If it\u0026rsquo;s too hard to understand, knowing that it does not make sudden leaps is enough.\n[1]: An interesting fact is that the probability density function of $W_{t}$ $$ f_{W_{t}} (x,t) = {{1} \\over { \\sqrt{ 2 \\pi t } }} e^{ - {{x^2} \\over {2t} } } $$ becomes the solution to the heat equation $$ {{\\partial u } \\over { \\partial t }} = {{1} \\over {2}} {{\\partial^2 u } \\over { \\partial x^2 }} $$.\n[4]: It\u0026rsquo;s not common to see the covariance expressed as the minimum of something. It‚Äôs highly recommended to follow the proof process and understand how it was derived.\nProof [1] By (i) and (iii), $W_{t} = W_{t} - 0 = W_{t} - W_{0} \\sim N ( 0 , t )$\n‚ñ†\n[2] Since $W_{t}$ follows a normal distribution by [1], $\\displaystyle E ( W_{t} ) = 0$\n‚ñ†\n[3] Since $W_{t}$ follows a normal distribution by [1], $\\displaystyle \\text{Var} ( W_{t} ) = t$\n‚ñ†\n[4] Let $t \u0026gt; s$ then by the definition of covariance and [2] $$ \\text{cov} ( W_{t} , W_{s} ) = E \\left( \\left[ W_{t} - E ( W_{t} ) \\right] \\left[ W_{s} - E ( W_{s} ) \\right] \\right) = E \\left( W_{t} W_{s} \\right) $$\n$W_{t} = ( W_{t} - W_{s} ) + W_{s}$ therefore\n$$ \\begin{align*} E \\left( W_{t} W_{s} \\right) =\u0026amp; E \\left[ \\left( ( W_{t} - W_{s} ) + W_{s} \\right) \\cdot W_{s} \\right] \\\\ =\u0026amp; E \\left[ ( W_{t} - W_{s} ) \\cdot W_{s} \\right] + E \\left( W_{s}^{2} \\right) \\end{align*} $$\nThe first term by (ii) and [2]\n$$ E \\left[ ( W_{t} - W_{s} ) \\cdot W_{s} \\right] = E ( W_{t} ) \\cdot E ( W_{t} - W_{s} ) = 0 $$\nThe second term by [3]\n$$ E \\left( W_{s}^{2} \\right) - 0^2 = E \\left( W_{s}^{2} \\right) - \\left[ E ( W_{s} ) \\right]^2 = \\text{Var} ( W_{s} ) = s $$\nSummarizing $\\displaystyle \\text{cov} ( W_{t} , W_{s} ) = s$. Similarly, the same result is obtained when $s \u0026gt; t$\n$$ \\text{cov} ( W_{t} , W_{s} ) = \\min \\left\\{ t , s \\right\\} $$\n‚ñ†\n","id":957,"permalink":"https://freshrimpsushi.github.io/en/posts/957/","tags":null,"title":"Wiener Process"},{"categories":"ÎèôÏó≠Ìïô","contents":"Definition1 Let the smallest natural number satisfying $f^{k} (p) = p$ for maps $f : X \\to X$ and $p \\in X$ be $k \\in \\mathbb{N}$.\nFor map $f : X \\to X$ and point $x \\in X$, the set $\\left\\{ x , f(x) , f^{2} , \\cdots \\right\\}$ under $f$ is called the orbit of $x$. Here, $x$ is called the initial value of the orbit. An orbit $\\left\\{ p , f (p) , f^{2} (p) , \\cdots \\right\\}$ with the initial value $p$ is called a Periodic-$k$ Orbit, and $p$ is called a Periodic-$k$ Point. If $p$ is a sink of $f^{k}$, then its Periodic-$k$ Orbit is called a (Periodic) Sink, and if it\u0026rsquo;s a source of $f^{k}$, its Periodic-$k$ Orbit is called a (Periodic) Source. If for some $N \\in \\mathbb{N}$ and all $n \\ge N$, $f^{n+k} (p) = f^{n} (p)$ is satisfied, then $p$ is said to be Eventually Periodic. If there exists a periodic orbit $\\left\\{ x_{1} , \\cdots , x_{n} \\right\\}$ satisfying $\\displaystyle \\lim_{n \\to \\infty} | f^{n} (p) - x_{n} | = 0$ for orbit $\\left\\{ p , f (p) , f^{2} (p) , \\cdots , f^{n} (p) , \\cdots \\right\\}$, then $\\left\\{ p , f (p) , f^{2} (p) , \\cdots , f^{n} (p) , \\cdots \\right\\}$ is said to be Asymptotically Periodic. Explanation The existence of a Periodic-$k$ Orbit essentially means that $f^{k}$ has a fixed point. Thus, having a cycle or a fixed point simply becomes a matter of how many times the map is applied. Therefore, after conceptual study, all theorems and higher concepts are aligned to express based on the fixed point. Let\u0026rsquo;s consider \u0026lsquo;period\u0026rsquo; as a generalization of \u0026lsquo;fixed point\u0026rsquo; for natural numbers.\nAn orbit becoming exactly like its $\\left\\{ x_{1} , \\cdots , x_{n} \\right\\}$ while being Asymptotically Periodic can also be considered Eventually Periodic. Moreover, an orbit converging to a Periodic Sink orbit is Asymptotically Periodic.\nMeanwhile, for $X = \\mathbb{R}$, one can consider the following simple theorem.\nTheorem2 Let us call the Periodic-$k$ Orbit of $f$ as $\\left\\{ p_{1} , p_{2} , \\cdots , p_{k} \\right\\}$.\nIf $\\left| f '(p_{1}) \\cdots f '(p_{k}) \\right| \u0026lt; 1$, then $\\left\\{ p_{1} , p_{2} , \\cdots , p_{k} \\right\\}$ is a sink, and if $\\left| f '(p_{1}) \\cdots f '(p_{k}) \\right| \u0026gt; 1$, $\\left\\{ p_{1} , p_{2} , \\cdots , p_{k} \\right\\}$ is a source.\nProof By the chain rule,\n$$ \\begin{align*} ( f^{k} )' ( p_{1} ) =\u0026amp; \\left( f \\left( f^{k-1} \\right) \\right)' ( p_{1} ) \\\\ =\u0026amp; f ' \\left( \\left( f^{k-1} \\right) \\right) \\left( f^{k-1} \\right)' ( p_{1} ) \\\\ =\u0026amp; f ' \\left( \\left( f^{k-1} \\right) \\right) f ' \\left( \\left( f^{k-2} \\right) \\right) \\cdots f ' ( p_{1} ) \\\\ =\u0026amp; f ' ( p_{k} ) f ' ( p_{k-1} ) \\cdots f ' ( p_{1} ) \\end{align*} $$\nFor a smooth $f : \\mathbb{R} \\to \\mathbb{R}$, let\u0026rsquo;s say some $p \\in \\mathbb{R}$ is a fixed point.\n[1] If $| f ' (p) | \u0026lt; 1$, then $p$ is a sink.\n[2] If $| f ' (p) | \u0026gt; 1$, then $p$ is a source.\nApplying The Criterion for Sinks and Sources in 1-Dimensional Maps to $| ( f^{k} )' ( p_{1} ) | = | f ' ( p_{k} ) f ' ( p_{k-1} ) \\cdots f ' ( p_{1} ) |$ yields the desired result.\n‚ñ†\nYorke. (1996). CHAOS: An Introduction to Dynamical Systems: p13, 108.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nYorke. (1996). CHAOS: An Introduction to Dynamical Systems: p10.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":858,"permalink":"https://freshrimpsushi.github.io/en/posts/858/","tags":null,"title":"Map System's Orbit"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÍ≤ÄÏ†ï","contents":"Hypothesis Testing Given that we have quantitative data $\\left\\{ x_{i} \\right\\}_{i = 1}^{n}$.\n$H_{0}$: Data $\\left\\{ x_{i} \\right\\}_{i = 1}^{n}$ follows a normal distribution. $H_{1}$: Data $\\left\\{ x_{i} \\right\\}_{i = 1}^{n}$ does not follow a normal distribution. Explanation The Jarque-Bera test is used to test for normality as a hypothesis test, typically to demonstrate the presence of normality. This is one of the rare cases where the acceptance of the null hypothesis matches the analyst\u0026rsquo;s intention, hence it is important to understand the hypothesis accurately.\nThe difference from the Shapiro-Wilk test is that it uses skewness and kurtosis for the test. The normal distribution has both a population skewness and population kurtosis of $0$, and the test statistic $JB$ based on the sample skewness $g_{1}$ and sample kurtosis $g_{2}$ follows a chi-squared distribution with degrees of freedom $2$. $$ JB := {{n g_{1}^2} \\over {6}} + {{n g_{2}^2} \\over {24}} \\sim \\chi^{2} (2) $$ Regardless, since it is a normality test, it doesn\u0026rsquo;t particularly matter which one you use, but the Jarque-Bera test uses skewness that is sensitive to outliers, often revealing normality after removing outliers more frequently compared to the Shapiro-Wilk test. Although it cannot be guaranteed for this reason alone, it is typically used in time series analysis rather than regression analysis to demonstrate normality. In practice, the jarque.bera.test() function in the tseries package of R performs the Jarque-Bera test.\nCode Exercise Create the following two random samples to actually conduct the Jarque-Bera test.\nN is data from a normal distribution, and geo is data from a geometric distribution.\nThe test results appear exactly as expected.\nComplete Code Below is an example code in R.\nlibrary(tseries)\rset.seed(150421)\rN\u0026lt;-rnorm(100)\rwin.graph(4,4); hist(N)\rjarque.bera.test(N)\rgeo\u0026lt;-rgeom(100,0.5)\rwin.graph(4,4); hist(geo)\rjarque.bera.test(geo) See Also Shapiro-Wilk Test ","id":949,"permalink":"https://freshrimpsushi.github.io/en/posts/949/","tags":null,"title":"Harke-Bera Test"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 2 The following partial differential equation is referred to as the heat equation or the diffusion equation.\n$$ \\dfrac{\\partial u}{\\partial t} = \\dfrac{\\partial^{2} u}{\\partial x^{2}} $$\nWhen the spatial coordinate is $n$-dimensional, $$ \\dfrac{\\partial u}{\\partial t} = \\Delta u = \\nabla^{2}u $$ here, $\\Delta = \\nabla^{2} = \\sum\\limits_{i=1}^{n} \\dfrac{\\partial^{2} }{\\partial x_{i}^{2}}$ refers to the Laplacian.\nWhen there is an external force $f = f(x,t)$, $$ \\dfrac{\\partial u}{\\partial t} = \\dfrac{\\partial^{2} u}{\\partial x^{2}} + f $$\nWhen there is a diffusion coefficient $a = a(x) \u0026gt; 0$, $$ \\dfrac{\\partial u}{\\partial t} = \\dfrac{\\partial }{\\partial x} \\left[ a(x) \\dfrac{\\partial u}{\\partial x} \\right] $$\nInitial and Boundary Conditions The heat equation typically comes with initial and boundary conditions. The solution cannot be uniquely determined by initial conditions alone. Let\u0026rsquo;s say that $u$ is a function defined at $\\Omega \\times [0, T]$,\n$$ \\text{initial condition : } u(x, 0) = g(x) \\quad \\text{ on } \\Omega \\times \\left\\{ 0 \\right\\} $$\n$$ \\text{boundary condition : } u(x, t) = h(x, t) \\quad \\text{ on } \\partial \\Omega \\times [0, T] $$\n$\\partial \\Omega$ is the boundary of $\\Omega$.\nExplanation This is a form where a term regarding time is added to the Laplace equation. Since the Laplace equation is independent of the flow of time, it is an equation for an equilibrium state, whereas the heat equation is affected by the flow of time, hence, it is an equation for a state where some physical quantity is flowing (diffusing). The reason it is named the heat equation stems from its first emergence in thermodynamics.\nDerivation Let\u0026rsquo;s say $U \\subset \\mathbb{R}^n$ is an open set and represents a physical space. Let $u:U\\times (0,\\ \\infty) \\to \\mathbb{R}$ be the density function of some physical quantity. Then, $u(x,\\ t)$ represents the density at a point $x\\in U$ at time $t\u0026gt;0$. Assume a certain open set $V$ is $V \\Subset U$ and satisfies $V\\in C^{\\infty}$. Also, let $\\mathbf{F} : U \\times (0, \\infty) \\to \\mathbb{R}^n$ be the flux of $u$. Then, the following equation must hold between $u$ and $\\mathbf{F}$.\n$$ \\dfrac{d}{dt}\\int_{V}u(x,t)dx = -\\int_{\\partial V}\\mathbf{F}(x, t) \\cdot \\nu (x) dS(x) $$\nThe left side talks about the change in quantity $u$ in some space, and the right side talks about the amount that went in or out at the boundary of that space. Unless it generates or annihilates by itself, the amount stays constant. If there is a change in the internal physical quantity, there must be something coming in or going out, and the values of both are the same.\nTake, for instance, a room with people freely entering and leaving. Let there be an observer $A$ inside the room counting changes in the number of people. Let there be another observer $B$ at the door adding $+1$ for every person leaving, and $-1$ for every person entering. If 3 people left the room, the change measured by $A$ inside the room is -3, and the count by $B$ at the door is 3. This is why there is a minus sign on the right side.\nSince $u \\in C^{2}$, integrating the left side\u0026rsquo;s derivative inside, and applying Green\u0026rsquo;s theorem on the right side gives the following.\n$$ \\int_{V} u_{t}(x,t)dx=-\\int_{V} \\nabla \\cdot \\mathbf{F}(x,t)dx\\quad \\forall t\u0026gt;0 $$\nTherefore, we obtain the following.\n$$ u_{t}=-\\nabla \\cdot \\mathbf{F}\\quad \\mathrm{in}\\ U\\times(0,\\infty) $$\nJust as when deriving the Laplace equation, if $F$ is a quantity proportional to the gradient of $u$, then we have $\\mathbf{F}=-aDu$, and obtain the following.\n$$ u_{t}=-\\nabla \\cdot(-aDu)=a\\nabla \\cdot Du=a\\Delta u $$\nIf we set $a=1$, we obtain the heat equation.\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p44\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Iserles, A First Course in the Numerical Analysis of Differential Equations (2nd, 2009), p349-351\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1001,"permalink":"https://freshrimpsushi.github.io/en/posts/1001/","tags":null,"title":"Heat Equation, Diffusion Equation"},{"categories":"Ìë∏Î¶¨ÏóêÌï¥ÏÑù","contents":"Definition Let\u0026rsquo;s assume that two functions $f$ and $g$ defined in $\\mathbb{R}$ are given. If the integral below exists, it is called the convolution of the two functions $f$ and $g$, and is denoted by $f \\ast g$.\n$$ f \\ast g(x):=\\int _{-\\infty} ^{\\infty} f(y)g(x-y)dy $$\nIf $f$ and $g$ are discrete functions, they are defined as follows.\n$$ (f \\ast g)(m)=\\sum \\limits_{n}f(n)g(m-n) $$\nExplanation Although there is a translation as convolution, the term convolution is more commonly used. Generally, the above definition is learned as convolution, but more generally, it is a convolution regarding Fourier transform which is an integral transform. It is used in various fields because it has many good properties such as commutative law, distributive law, etc.\nIn the case of discrete convolution, it is defined a bit differently in analytic number theory.\nThe conditions for convolution to be defined are as follows:\n(a)\nIf $f\\in L^{1}$ and $|g|\u0026lt;M$, then\n$$ \\left| \\int f(y)g(x-y)dy \\right| \\le \\int \\left| f(y)g(x-y) \\right|dy \\le M\\int \\left| f(y) \\right|dy \\lt \\infty $$\n(b)\nIf $\\left| f \\right| \\le M$ and $g\\in L^{1}$, then\n$$ \\left| \\int f(y)g(x-y)dy \\right| \\le \\int \\left| f(y) g(x-y) \\right|dy \\le M\\int \\left| g(x-y) \\right|dy \\lt \\infty $$\n(c)\nLet\u0026rsquo;s assume $f,g\\in L^{2}$ and $\\tilde{g}_{x}(y)=g(x-y)$. Then $\\tilde{g}_{x}\\in L^{2}$ and $\\left\\| g \\right\\|_{2}=\\left\\| \\tilde{g}_{x} \\right\\|_{2}$, and by the Cauchy-Schwarz inequality,\n$$ \\begin{align*} \\left| \\int f(y)g(x-y)dy \\right| \u0026amp;= \\left| \\int f(y)\\tilde{g}_{x}(y)dy \\right| \\\\ \u0026amp; = \\left| \\left\\langle f,\\tilde{g}_{x} \\right\\rangle \\right| \\\\ \u0026amp;\\le \\left\\| f \\right\\|_{2} \\left\\| \\tilde{g}_{x} \\right\\|_{2} \\\\ \u0026amp;\u0026lt;\\infty \\end{align*} $$\n(d)\nIf $f$ is bounded except for the closed interval $[a,b]$ where it is $0$ and when $g$ is piecewise continuous,\n$$ \\int _{-\\infty} ^{\\infty} f(y)g(x-y)dy=\\int _{a}^{b}f(y)g(x-y)dy\u0026lt;\\infty $$\n","id":1000,"permalink":"https://freshrimpsushi.github.io/en/posts/1000/","tags":null,"title":"Definition of Convolution"},{"categories":"Ï†ïÏàòÎ°†","contents":"Review 1 Assume element $g$ of group $G = F_{p}$ has an order of $N$. Then, the Discrete Logarithm problem $g^{x} = h$ becomes relatively easy to solve under the following conditions:\n(i): $p$ is a smooth prime number. (ii): $p \\equiv 3 \\pmod{4}$ and $a$ are quadratic residues modulo $p$. Proof (i) If $p$ is a smooth prime, the Pohlig-Hellman algorithm can be used, so the Discrete Logarithm problem is relatively easy to solve.\n‚ñ†\n(ii) $$ x^{2} \\equiv a \\pmod{p} $$ $a$ being a quadratic residue modulo $p$ means there exists a solution that satisfies the above congruence equation. If the remainder of prime $p$ divided by $4$ is $3$, $$ b \\equiv a^{(p+1)/4} \\pmod{p} $$ then for some $a \\equiv g^{2k} \\pmod{p}$, $$ \\begin{align*} b^{2} \\equiv \u0026amp; a^{{ p+1 } \\over { 2 }} \u0026amp; \\pmod{p} \\\\ \\equiv \u0026amp; \\left( g^{2k} \\right)^{{ p+1 } \\over { 2 }} \u0026amp; \\pmod{p} \\\\ \\equiv \u0026amp; g^{(p+1)k} \u0026amp; \\pmod{p} \\\\ \\equiv \u0026amp; g^{2k + (p-1)k} \u0026amp; \\pmod{p} \\\\ \\equiv \u0026amp; a \\cdot \\left( g^{p-1} \\right)^{k} \u0026amp; \\pmod{p} \\\\ \\equiv \u0026amp; a \u0026amp; \\pmod{p} \\end{align*} $$ thus it becomes a solution to the given congruence equation. With this formula, the square root of $a$ can be found very quickly, making the Discrete Logarithm problem relatively easy to solve.\n‚ñ†\nSee Also Discrete Logarithm problem Security algorithms utilizing the difficulty of the Discrete Logarithm problem Diffie-Hellman Key Exchange algorithm ElGamal Public Key Cryptosystem Attack algorithms for the Discrete Logarithm problem Shanks\u0026rsquo; algorithm Pohlig-Hellman algorithm Conditions under which the Discrete Logarithm problem is easily solved Hoffstein. (2008). An Introduction to Mathematical Cryptography: p84~92.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":942,"permalink":"https://freshrimpsushi.github.io/en/posts/942/","tags":null,"title":"Discrete Logarithm Problems Solved Easily Under Certain Conditions"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 $\\ U \\in \\mathbb{R}^n$ is an open set $\\ x\\in U$ $u=u(x) : \\overline{U} \\rightarrow \\mathbb{R}^n$ Laplace\u0026rsquo;s Equation The partial differential equation below is called Laplace\u0026rsquo;s equation.\n$$ \\Delta u=0 $$\nHere, $\\Delta$ is the Laplacian. A $u$ that satisfies Laplace\u0026rsquo;s equation is specifically called a harmonic function.\nPoisson\u0026rsquo;s Equation The nonhomogeneous Laplace\u0026rsquo;s equation is called Poisson\u0026rsquo;s equation.\n$$ -\\Delta u = f $$\nExplanation Laplace\u0026rsquo;s equation appears in various parts of physics. In most cases, $u$ represents the density of some physical quantity in equilibrium. In equilibrium, when it is said that $V \\subset U$, the following equation holds.\n$$ \\int_{\\partial V}\\mathbf{F} \\cdot \\boldsymbol{\\nu}dS=0 $$\n$\\mathbf{F}$ is the flux density of $u$, $\\boldsymbol{\\nu}$ is the outward unit normal vector.\nThe meaning of the equation is that the net flux of $u$ is $0$. For example, suppose there is a space in thermal equilibrium. Then there is no heat entering from the outside into the space, and no heat leaving from the inside to the outside. That is, there is no flow of heat at the boundary of that space. This statement is the same as saying that the net flux is $0$. Applying the Green-Gauss theorem here gives the following equation.\n$$ 0 = \\int_{\\partial V} \\mathbf{F} \\cdot \\nu dS=\\int_{V} \\nabla \\cdot \\mathbf{F} dx \\\\ \\implies \\nabla \\cdot \\mathbf{F}=0 $$\nHere, let\u0026rsquo;s assume $\\mathbf{F}$ is a value proportional to the gradient $Du$ of $u$. In many cases, it is convenient to assume it in the opposite direction for physical reasons. The second law of thermodynamics (heat always flows from high to low) can be mentioned as an example.\n$$ \\begin{equation} \\mathbf{F}=-aDu \\label{eq1} \\end{equation} $$\nIn this case, $a\u0026gt;0$.\nIf $u$ represents the concentration of a chemical substance, temperature, or electrostatic potential, then $\\eqref{eq1}$ respectively mean Fick\u0026rsquo;s law of diffusion, Fourier\u0026rsquo;s law of heat conduction, Ohm\u0026rsquo;s law of electrical conduction.\nFrom the above content, the Laplace\u0026rsquo;s equation is derived.\n$$ \\nabla \\cdot \\mathbf{F} = \\nabla \\cdot (-aDu)=-a\\Delta u=0 \\\\ \\implies \\Delta u = 0 $$\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p20-21\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":997,"permalink":"https://freshrimpsushi.github.io/en/posts/997/","tags":null,"title":"Laplace's Equation and Poisson's Equation"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Model 1 For the given white noise $\\left\\{ e_{t} \\right\\}_{t \\in \\mathbb{N}}$, it is defined as $$ \\nabla^{d} Y_{t} := \\sum_{i = 1}^{p} \\phi_{i} \\nabla^{d} Y_{t-i} + e_{t} - \\sum_{i = 1}^{q} \\theta_{i} e_{t-i} $$ and this form is referred to as the $(p,d,q)$th ARIMA process $ARIMA (p,d,q)$. Such a form of time series analysis model is called ARIMA model.\nExplanation $ARI(p,d) \\iff ARIMA(p,d,0)$ is referred to as AR model, and $IMA(d,q) \\iff ARIMA(0,d,q)$ as MA model, though these terms are not commonly used. Preferably, expressions like $ARIMA(p,d,0)$ or $ ARIMA(0,d,q)$ are favored.\nAlthough the formula looks complicated, it‚Äôs not as difficult as it seems, as it merely involves changing $Y_{t}$ to $\\nabla^{d} Y_{t}$ in the ARMA model $$ Y_{t} = \\sum_{i = 1}^{p} \\phi_{i} Y_{t-i} + e^{t} - \\sum_{i = 1}^{q} \\theta_{i} e_{t-i} $$. It‚Äôs about analyzing data that has obtained stationarity through $d$ times of differencing in the ARMA model framework.\nCryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p992.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":941,"permalink":"https://freshrimpsushi.github.io/en/posts/941/","tags":null,"title":"Arima Model"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 Let $U\\subset \\mathbb{R}^{n}$ be an open set. Let the boundary of $U$ be $\\partial U$, which is a $\\partial U \\in C^1$. Then, the following outward unit normal vector can be defined:\n$$ \\boldsymbol{\\nu}=(\\nu^{1}, \\nu^{2}, \\dots, \\nu^{n}) \\quad \\text{and} \\quad |\\boldsymbol{\\nu}|=1 $$\n$\\boldsymbol{\\nu}$ is a vector that touches a point on the boundary, has a magnitude of 1, and points outward. Let it be $u \\in C^{1}(\\bar{U})$. Then, the directional derivative $\\dfrac{\\partial u}{\\partial \\nu}$ is defined as follows:\n$$ \\dfrac{\\partial u}{\\partial \\nu} := \\boldsymbol{\\nu} \\cdot Du=(\\nu^1,\\cdots,\\nu^n)\\cdot(u_{x_{1}}, \\cdots, u_{x_{n}}) $$\n$D=D^{1}$ is the multi-index notation, and $Du$ is the gradient of $u$.\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p710-711\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":988,"permalink":"https://freshrimpsushi.github.io/en/posts/988/","tags":null,"title":"Exterior Unit Normal Vector"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Theorem Let\u0026rsquo;s assume $u, v \\in C^2( \\bar{U})$. Then, the following expressions hold:\n(i) $\\displaystyle \\int_{U} \\Delta u dx=\\int_{\\partial U} \\dfrac{\\partial u}{\\partial \\nu}dS$\n(ii) $\\displaystyle \\int_{U} Dv \\cdot Du dx = -\\int_{U} u \\Delta v dx+\\int_{\\partial U}\\dfrac{\\partial v}{\\partial \\nu}udS$\n(iii) $\\displaystyle \\int_{U} (u\\Delta v - v\\Delta u )dx = \\int_{\\partial U} \\left( \\dfrac{\\partial v}{\\partial \\nu}u - \\dfrac{\\partial u}{\\partial \\nu} v\\right)dS$\nThese are collectively referred to as Green\u0026rsquo;s formula.\n$\\Delta$ is Laplacian $D$ is Gradient $\\nu$ is Outward unit normal vector Proof Partial integration formula\nLet\u0026rsquo;s assume $u, v \\in C^1(\\bar{U})$. Then, the following formula holds:\n$$ \\int_{U} u_{x_{i}}vdx = -\\int_{U} uv_{x_{i}}dx + \\int_{\\partial U} uv\\nu^{i} dS\\quad (i=1,\\dots , n) $$\n(i) By substituting $u$ with $u_{x_{i}}$, and $v$ with $1$ in the partial integration formula, we obtain the following formula.\n$$ \\int_{U} u_{x_{i} x_{i}}dx = \\int_{\\partial U} u_{x_{i}}\\nu^{i} dS \\quad (i=1,\\cdots , n) $$\nSumming up for all $i=1,\\cdots, n$ gives:\n$$ \\int_{U} (u_{x_{1} x_{1}}+\\cdots +u_{x_{n} x_{n}} )dx = \\int_{\\partial U}( u_{x_{1}}\\nu^{1} +\\cdots u_{x_{n}}\\nu^n)dS $$\nBy the definition of Laplacian and $\\dfrac{\\partial u}{\\partial \\nu}:=\\boldsymbol{\\nu}\\cdot Du$, the following is true.\n$$ \\int_{U} \\Delta u dx=\\int_{\\partial U} \\dfrac{\\partial u}{\\partial \\nu}dS $$\n‚ñ†\n(ii) By substituting $v$ with $v_{x_{i}}$ in the partial integration formula, we obtain the following formula.\n$$ \\int_{U} u_{x_{i}}v_{x_{i}}dx = -\\int_{U} uv_{x_{i}x_{i}}dx + \\int_{\\partial U} uv_{x_{i}}\\nu^{i} dS \\quad (i=1,\\cdots , n) $$\nSumming up for all $i=1,\\cdots ,n$ gives:\n$$ \\int_{U} (u_{x_{1}}v_{x_{1}}+\\cdots +u_{x_{n}}v_{x_{n}} )dx = -\\int_{U} u(v_{x_{1}x_{1}}+\\cdots v_{x_{n} x_{n}})dx + \\int_{\\partial U} ( v_{x_{1}}\\nu^1 +\\cdots v_{x_{n}}\\nu^n )udS $$\nWhich simplifies to:\n$$ \\int_{U} Du\\cdot Dvdx = -\\int_{U} u\\Delta vdx + \\int_{\\partial U} \\dfrac{\\partial v}{\\partial \\nu}u dS $$\n‚ñ†\n(iii) Switching the places of $u$ and $v$ in (ii) gives the following formula.\n$$ \\int_{U} Du \\cdot Dv dx = -\\int_{U} v \\Delta u dx+\\int_{\\partial U}\\dfrac{\\partial u}{\\partial \\nu}vdS $$\nSubtracting (ii) from the above formula gives:\n$$ 0= -\\int_{U} ( v \\Delta u -u\\Delta v) dx+\\int_{\\partial U} \\left( \\dfrac{\\partial u}{\\partial \\nu}v -\\dfrac{\\partial v}{\\partial \\nu}u \\right)dS $$\nWhich simplifies to:\n$$ -\\int_{U} ( v \\Delta u -u\\Delta v) dx=\\int_{\\partial U} \\left( \\dfrac{\\partial v}{\\partial \\nu}u -\\dfrac{\\partial u}{\\partial \\nu}v \\right)dS $$\n‚ñ†\nSee also Green\u0026rsquo;s theorem in calculus ","id":974,"permalink":"https://freshrimpsushi.github.io/en/posts/974/","tags":null,"title":"Green's Theorem"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Definition A Divided Difference of a function $f : \\mathbb{R} \\to \\mathbb{R}$ for distinct $x_{1} , \\cdots , x_{n}$ is defined as follows:\n$$ \\begin{align*} f[x_{0}] :=\u0026amp; f( x_{0} ) \\\\ f [ x_{0} , x_{1} ] :=\u0026amp; {{ f ( x_{1} ) - f ( x_{0} ) } \\over { x_{1} - x_{0} }} \\\\ f [ x_{0} , x_{1} , x_{2} ] :=\u0026amp; {{ f [ x_{1} , x_{2} ] - f [ x_{0} , x_{1} ] } \\over { x_{2} - x_{0} }} \\\\ f [ x_{0} , \\cdots , x_{n} ] :=\u0026amp; {{ f [ x_{1} , \\cdots , x_{n} ] - f [ x_{0} , \\cdots , x_{n-1} ] } \\over { x_{n} - x_{0} }} \\end{align*} $$\nTheorem [1]: $f [ x_{0} , \\cdots , x_{n} ]$ is always the same regardless of the order of $x_{0} , \\cdots , x_{n}$. [2]: $$f [ x_{0} , \\cdots , x_{n} ] = \\sum_{i=0}^{n} {{ f( x_{i} ) } \\over { \\prod_{j \\in \\left\\{ 0 , \\cdots , n \\right\\} \\setminus \\left\\{ i \\right\\} } ( x_{i} - x_{j} ) }}$$ [3]: There exists $\\xi$ that satisfies the following.$$f\u0026rsquo; ( \\xi ) = f [ x_0 , x_{1} ]$$ [4]: There exists $\\xi$ that satisfies the following.$${{1} \\over {n!}} f^{(n)} ( \\xi ) =f [ x_{0} , \\cdots , x_{n} ]$$ [3]\u0026rsquo;: $$f [ x_{i} , x_{i} ] = f ' ( x_{i} )$$ [4]\u0026rsquo;: $$f [ \\underbrace{ x_{i} , \\cdots , x_{i} }_{ n+1 } ] = {{1} \\over {n!}} f^{(n)} ( x_{i} )$$ $\\mathscr{H} \\left\\{ a,b,c, \\cdots \\right\\}$ denotes the smallest interval that includes $a,b,c, \\cdots$. Explanation Divided differences greatly save space when expressing various theories of numerical analysis.\nTheorem [2] is especially useful in actual calculations, since it is expressed as $$ f [ x_{0} , x_{1} , x_{2} ] = {{ f( x_{0} ) } \\over { ( x_{0} - x_{1} ) ( x_{0} - x_{2} ) }} + {{ f( x_{1} ) } \\over { ( x_{1} - x_{2} ) ( x_{1} - x_{0} ) }} + {{ f( x_{2} ) } \\over { ( x_{2} - x_{0} ) ( x_{2} - x_{1} ) }} $$, allowing for iterative calculations to be simplified compared to the original definition.\n[3] is essentially Mean Value Theorem, and if you have ever considered the concept of \u0026lsquo;instantaneous rate of change\u0026rsquo; when differentiating, this will help you understand why divided differences can replace differentiation and why it\u0026rsquo;s called Divided Difference. Theorem [4] can be generalized in this manner. The proof can be thought of as the variables of divided differences becoming infinitely close, or taking a limit, which can be seen in [3]\u0026rsquo;, [4]\u0026rsquo; as derivatives of degree $n$. Such a conceptual approach overcomes the limitations arising from the definition of divided differences and enriches the theory of numerical analysis.\nExample Let\u0026rsquo;s calculate some divided differences for $f(x) := x^2 + 1$ simply.\nFor one point, $$ f[3] = f(3) = 10 $$\nFor two points, $$ f[0,5] = {{ f(0) - f(5) } \\over { 0 - 5}} = {{1 - 26 } \\over { -5 }} = 5 $$\nFor three points, $$ \\begin{align*} f[2,3,-1] =\u0026amp; {{ \\displaystyle {{ f(2) - f( 3) } \\over { 2 - 3 }} - {{ f(3) - f(-1) } \\over { 3 - (-1) }} } \\over { 2 - (-1) }} \\\\ =\u0026amp; {{ \\displaystyle {{ 5 - 10 } \\over { -1 }} - {{ 10 - 2 } \\over { 4 }} } \\over { 3}} \\\\ =\u0026amp; {{ 5 -2 } \\over {3}} \\\\ =\u0026amp; 1 \\end{align*} $$ Divided differences can obviously be calculated for a finite vector, but usually, most applications go up to $n=2$, and beyond that, it\u0026rsquo;s rarely used.\nImplementation Here is an implementation of divided differences in R code, which takes a function $f$ and a vector $\\mathbb{x} = ( x_{0} , \\cdots , x_{n} )$ to return $f [ x_{0} , \\cdots , x_{n} ]$.\nf\u0026lt;-function(x) {x^2 + 1}\rdd\u0026lt;-function(f,X){\rif(length(X)==1) {return(f(X))}\rtemp\u0026lt;-numeric(0)\rfor(i in 1:length(X)) {temp[i]\u0026lt;-prod(X[i]-X[-i])}\rreturn(sum(f(X)/temp))\r}\rdd(f,c(3))\rdd(f,c(0,5))\rdd(f,c(2,3,-1)) The result of executing the above code is as follows, and it\u0026rsquo;s confirmed to exactly match the hand calculation for $f(x) = x^2 +1$.\nProof [2] Strategy: Compare the degrees of Lagrange\u0026rsquo;s formula and Newton\u0026rsquo;s divided difference formula.\n$$ \\Psi_{n} (x) := (x-x_{0}) \\cdots (x - x_{n}) $$ Differentiating $\\Psi_{n}$ with respect to $x$ and substituting $x = x_{j}$ gives $$ \\Psi\u0026rsquo;_{n} (x_{j}) := (x-x_{0}) \\cdots (x - x_{j-1})(x - x_{j+1}) \\cdots (x - x_{n}) $$\n$$ \\implies {{ \\Psi (x)_{n} } \\over { (x - x_{j}) \\Psi\u0026rsquo;_{n}(x_{j}) }} \\equiv {{ (x - x_{0} ) \\cdots (x - x_{j-1} ) (x - x_{j+1} ) \\cdots (x - x_{n} ) } \\over { (x_{j} - x_{0} ) \\cdots (x_{j} - x_{j-1} ) (x_{j} - x_{j+1} ) \\cdots (x_{j} - x_{n} ) }} = l_{j} (x) $$ According to Lagrange\u0026rsquo;s formula, the polynomial interpolation of $f$ is $$ p_{n} (x) = \\sum_{j=0}^{n} {{ \\Psi_{n} (x) } \\over { (x - x_{j}) \\Psi\u0026rsquo;_{n} (x_{j}) }} \\cdot f( x_{j}) $$ Therefore, since the coefficient of the highest order term of $p_{n}$ is $\\displaystyle \\sum_{j=0}^{n} {{ f( x_{j}) } \\over { \\Psi\u0026rsquo;_{n} (x_{j}) }}$, and in Newton\u0026rsquo;s divided difference formula, the coefficient of the highest order term of $p_{n}$ is $f [x_{0} , \\cdots , x_{n} ]$, $$ f [ x_{0} , \\cdots , x_{n} ] = \\sum_{i=0}^{n} {{ f( x_{i} ) } \\over { \\displaystyle \\prod_{j \\in \\left\\{ 0 , \\cdots , n \\right\\} \\setminus \\left\\{ i \\right\\} } ( x_{i} - x_{j} ) }} $$\n‚ñ†\n[1] By Theorem [2], changing the order within $[x_{0} , \\cdots , x_{n}]$ is just changing the order of addition when calculating $\\displaystyle \\sum_{i=0}^{n} {{ f( x_{i} ) } \\over { \\displaystyle \\prod_{j \\in \\left\\{ 0 , \\cdots , n \\right\\} \\setminus \\left\\{ i \\right\\} } ( x_{i} - x_{j} ) }}$, so it\u0026rsquo;s always the same.\n‚ñ†\n[4] Strategy: Compare the degrees of Lagrange\u0026rsquo;s formula and Newton\u0026rsquo;s divided difference formula.\nIf we say $p_{n}(x) = p_{n-1}(x) + C(x)$, then $\\deg C = n$ and for $i= 0, \\cdots, (n-1)$, $p_{n}(x_{i}) = f(x_{i}) = p_{n-1}(x_{i})$, so for some constant $a_{n} \\ne 0$ we have $C (x) = a_{n} (x - x_{0}) \\cdots (x - x_{n-1})$. Substituting $C(x)$ with $x=x_{n}$ gives $$ C(x_{n} ) = p_{n} (x_{n}) - p_{n-1}(x_{n}) $$\n$$ C (x_{n}) = a_{n} (x_{n} - x_{0}) \\cdots (x_{n} - x_{n}) $$ Since $p_{n}$ is the polynomial interpolation of $f$, it becomes $p_{n} (x_{n}) = f(x_{n})$, $$ a_{n} (x_{n} - x_{0}) \\cdots (x_{n} - x_{n-1}) = f (x_{n}) - p_{n-1}(x_{n}) $$\n$$ a_{n} = {{ f (x_{n}) - p_{n-1}(x_{n-1}) } \\over { (x_{n} - x_{0}) \\cdots (x_{n} - x_{n-1}) }} $$\nError between polynomial interpolation and actual function: For some $\\xi \\in \\mathscr{H} \\left\\{ x_{0} , \\cdots , x_{n-1} \\right\\}$, the polynomial interpolation $p_{n-1}$ of $f$ for $n$-times differentiable $f : \\mathbb{R} \\to \\mathbb{R}$ is for some $x_{n} \\in \\mathbb{R}$ $$ f(x_{n}) - p_{n-1} (x_{n}) = {{ (x_{n} - x_{0}) \\cdots (x_{n} - x_{n-1}) } \\over { n! }} f^{(n)} ( \\xi ) $$\nAccording to the formula of Error between polynomial interpolation and actual function, $$ a_{n} = {{ f^{(n)} ( \\xi ) } \\over { n! }} $$ Meanwhile, since the coefficient of the highest order term of $p_{n}$ in Newton\u0026rsquo;s divided difference formula is $a_{n} = f [x_{0} , \\cdots , x_{n} ]$, $$ {{1} \\over {n!}} f^{(n)} ( \\xi ) =f [ x_{0} , \\cdots , x_{n} ] $$\n‚ñ†\n[3] It\u0026rsquo;s trivial by Theorem [4].\n‚ñ†\n","id":969,"permalink":"https://freshrimpsushi.github.io/en/posts/969/","tags":null,"title":"Differential Stages in Numerical Analysis"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition The average value of a function between $[a,\\ b]$ and $f(x)$ is equivalent to dividing the integral of the function over the interval by the length of the interval.\n$$ \\dfrac{1}{b-a}\\int_{a}^bf(x)dx $$\nDerivation Let\u0026rsquo;s denote a partition of the interval $[a,\\ b]$ as $P$.\n$$ P=\\left\\{ x_{1},\\ x_{2},\\ \\cdots ,\\ x_{n} \\right\\} $$\nIn this case, $a=x_{1} \u0026lt; x_{2} \u0026lt; \\cdots \u0026lt; x_{n}=b$ and the distance between each point is the same. Also, $\\Delta x=x_{i+1}-x_{i}$. We seek to approximate the average value of $f(x)$ by dividing $f(x_{i})$\u0026rsquo;s sum by $n$.\n$$ \\dfrac{ f(x_{1}) + f(x_{2}) + \\cdots +f(x_{n}) } {n} $$\nThis implies that as $n$ increases, it will become closer to the average of the function values. Multiplying both numerator and denominator by $\\Delta x$ gives the following.\n$$ \\dfrac{\\Big( f(x_{1}) + f(x_{2}) + \\cdots +f(x_{n}) \\Big)\\Delta x} {n \\Delta x} $$\nSince $n\\Delta x=b-a$, it follows that:\n$$ \\dfrac{\\Big( f(x_{1}) + f(x_{2}) + \\cdots +f(x_{n}) \\Big)\\Delta x} {b-a} $$\nTaking the limit where $n \\rightarrow \\infty$ and $\\Delta x \\rightarrow 0$, the numerator becomes $\\int_{a}^bf(x)dx$.\n$$ \\dfrac{1}{b-a}\\int_{a}^bf(x)dx $$\n‚ñ†\nExample The average of one period of a trigonometric function is $0$.\nCosine Function\nThe average over one period of $\\cos (kx)$ is as follows: $$ \\int_{0}^\\frac{2\\pi}{k} \\cos(kx)dx = \\dfrac{1}{k}\\left[ \\sin(kx)\\right]_{0}^{\\frac{2\\pi}{k}} =\\dfrac{1}{k}(\\sin 2\\pi -\\sin 0 ) =0 $$\nSine Function\nThe average over one period of $\\sin (kx)$ is as follows: $$ \\int_{0}^\\frac{2\\pi}{k} \\sin(kx)dx = \\dfrac{-1}{k}\\left[ \\cos(kx)\\right]_{0}^{\\frac{2\\pi}{k}} =\\dfrac{-1}{k}(\\cos 2\\pi -\\cos 0 ) =0 $$\nSee Also Mean Value Theorem for Integrals ","id":983,"permalink":"https://freshrimpsushi.github.io/en/posts/983/","tags":null,"title":"Mean of Function Values"},{"categories":"Ï†ïÏàòÎ°†","contents":"Algorithm Let\u0026rsquo;s say that an element $g$ of a group $G$ has order $N = q_{1}^{r_{1}} q_{2}^{r_{2}} \\cdots q_{t}^{r_{t}}$. Then, the discrete logarithm problem $g^{x} = h$ can be solved in no more than $\\displaystyle O \\left( \\sum_{i=1}^{t} S_{q_{i}^{r_{i}}} + \\log N \\right)$ steps according to the following algorithm.\nStep 1.\nCompute $\\displaystyle g_{i} : = g^{N / q_{i}^{r_{i}}}$ and $\\displaystyle h_{i} := h^{N / q_{i}^{r_{i}}}$.\nStep 2.\nFind the solution $y_{i}$ to the discrete logarithm problem $g_{i}^{y} = h_{i}$ using Shanks\u0026rsquo; algorithm.\nStep 3.\nFind $1 \\le x \\le N$ that satisfies $\\begin{cases} x \\equiv y_{1} \\pmod{ q_{1}^{r_{1}} } \\\\ \\qquad \\vdots \\\\ x \\equiv y_{t} \\pmod{ q_{t}^{r_{t}} } \\end{cases}$ using the Chinese Remainder Theorem.\n$S_{q_{i}^{r_{i}}}$ is the time it takes for Shanks\u0026rsquo; algorithm, which is about $\\displaystyle O \\left( S_{q_{i}^{r_{i}}} \\right) \\approx O \\left( q_{i}^{r_{i} / 2} \\right) $. Shanks\u0026rsquo; algorithm is an attack method that can be used when the order is known. The Pollard-Rho algorithm utilizes the fact that if $p$ is smooth, then the factorization of $(p-1)$ becomes easier, making it easier to find $\\displaystyle g_{i} = g^{N / q_{i}^{r_{i}}}$. The order of the created $g^{i}$ is trivially $q_{i}^{r_{i}}$, removing the constraint of using Shanks\u0026rsquo; algorithm. This involves reducing the original problem into smaller problems, solving them individually, and then obtaining the answer using the Chinese Remainder Theorem.\nProof Part 1. Existence\nThat $x$ is a solution to $g^{x} = h$ means that for all $i = 1, \\cdots , t$, there exists $z_{i}$ that satisfies $x = y_{i} + q_{i}^{r_{i}} z_{i}$.\nPart 1-1. $\\displaystyle {{N} \\over { q_{i}^{r_{i}} } } x \\equiv {{N} \\over { q_{i}^{r_{i}} } } \\log_{g} ( h ) \\pmod{N} $\nBy the definition of $N$ and $g_{i} , y_{i} , h_{i}$, $$ \\begin{align*} \\left( g^{x} \\right)^{N / q_{i}^{r_{i}} } =\u0026amp; \\left( g^{y_{i} + q_{i}^{r_{i}} z_{i}} \\right)^{N / q_{i}^{r_{i}} } \\\\ =\u0026amp; \\left( g^{ N / q_{i}^{r_{i}} } \\right)^{ y_{i} } \\cdot g^{N z_{i} } \\\\ =\u0026amp; \\left( g^{ N / q_{i}^{r_{i}} } \\right)^{ y_{i} } \\\\ =\u0026amp; g_{i}^{ y_{i} } \\\\ =\u0026amp; h_{i} \\\\ =\u0026amp; h^{N / q_{i}^{r_{i}} } \\end{align*} $$ is obtained. To organize, $$ \\left( g^{x} \\right)^{N / q_{i}^{r_{i}} } = h^{N / q_{i}^{r_{i}} } $$ and taking the logarithm gives $$ {{N} \\over { q_{i}^{r_{i}} } } x \\equiv {{N} \\over { q_{i}^{r_{i}} } } \\log_{g} ( h ) \\pmod{N} $$ Part 1-2. $\\displaystyle \\sum_{i=1}^{t} {{N} \\over { q_{i}^{r_{i}} } } c_{i} = 1$\nIt is trivial that $\\displaystyle \\gcd \\left( {{N} \\over { q_{1}^{r_{1}} } } , \\cdots , {{N} \\over { q_{t}^{r_{t}} } } \\right) = 1$ holds according to the definition of $N$, and by the Extended Euclidean Theorem, $$ {{N} \\over { q_{1}^{r_{1}} } } c_{1} + \\cdots + {{N} \\over { q_{t}^{r_{t}} } } c_{t} = 1 $$ there exists $c_{1} , \\cdots , c_{t} \\in \\mathbb{Z}$. Part 1-3. $x = \\log_{g} (h) \\pmod{N}$\nFrom Part 1-1, $$ {{N} \\over { q_{i}^{r_{i}} } } x \\equiv {{N} \\over { q_{i}^{r_{i}} } } \\log_{g} ( h ) \\pmod{N} $$ Multiplying both sides of by $c_{i}$ gives $$ {{N} \\over { q_{i}^{r_{i}} } } c_{i} x \\equiv {{N} \\over { q_{i}^{r_{i}} } } c_{i} \\log_{g} ( h ) \\pmod{N} $$ Adding this from $i=1$ to $t$ gives $$ \\sum_{i=1}^{t} {{N} \\over { q_{i}^{r_{i}} } } c_{i} x \\equiv \\sum_{i=1}^{t} {{N} \\over { q_{i}^{r_{i}} } } c_{i} \\log_{g} ( h ) \\pmod{N} $$ $x$ and $log_{g} (h)$ are independent of index $i$, so $$ x \\sum_{i=1}^{t} {{N} \\over { q_{i}^{r_{i}} } } c_{i} \\equiv \\log_{g} ( h ) \\sum_{i=1}^{t} {{N} \\over { q_{i}^{r_{i}} } } c_{i} \\pmod{N} $$ From Part 1-2, since $\\displaystyle \\sum_{i=1}^{t} {{N} \\over { q_{i}^{r_{i}} } } c_{i} = 1$, it follows $$ x \\equiv \\log_{g} (h) \\pmod{N} $$ Part 2. Time Complexity\nSince Step 2 is repeated for every $i = 1, \\cdots , t$, it takes $\\displaystyle O \\left( S_{q_{i}^{r_{i}}} \\right) $. Moreover, because using the Chinese Remainder Theorem in Step 3 takes time $O ( \\log N )$, $\\displaystyle O \\left( \\sum_{i=1}^{t} S_{q_{i}^{r_{i}}} + \\log N \\right)$\n‚ñ†\nCode The following is the implementation of the Pollard-Rho algorithm in R. Factorization code, Code for finding the order, Shanks\u0026rsquo; algorithm, Exponentiation by squaring, and Code using the Chinese Remainder Theorem were used.\nprime = read.table(\u0026#34;../attachment\r/cfile8.uf@25411C3C5968BBE322F0D4.txt\u0026#34;); prime = prime[,1]\rfactorize\u0026lt;-function(p)\r{\rq=p\rfactors\u0026lt;-numeric(0)\ri=1; j=1\rwhile(q!=1)\r{\rif(q%%prime[i]) {i=i+1}\relse\r{\rq\u0026lt;-q/prime[i]\rfactors[j]\u0026lt;-prime[i]\ri=1\rj=j+1\r}\r}\rreturn(factors)\r}\rorder\u0026lt;-function(g,p,h=1) #Calculate a order of g in modulo p\r{\rqe\u0026lt;-table(factorize(p-1))\rqe\u0026lt;-rbind(as.numeric(names(qe)),qe)\rdivisor\u0026lt;-qe[1,1]^(0:qe[2,1])\rif((length(qe)/2)==1) {return(qe[1,1]^qe[2,1])}\rfor(i in 2:(length(qe)/2)) {divisor=c(divisor%*%t(qe[1,i]^(0:qe[2,i])))}\rfor(i in divisor) {if((FPM(g,i,p))%%p==1) break;}\rreturn(i)\r}\rFPM\u0026lt;-function(base,power,mod) #It is equal to (base^power)%%mod\r{\ri\u0026lt;-0\rif (power\u0026lt;0) {\rwhile((base*i)%%mod != 1) {i=i+1}\rbase\u0026lt;-i\rpower\u0026lt;-(-power)}\rif (power==0) {return(1)}\rif (power==1) {return(base%%mod)}\rn\u0026lt;-0\rwhile(power\u0026gt;=2^n) {n=n+1}\rA\u0026lt;-rep(1,n)\rA[1]=base\rfor(i in 1:(n-1)) {A[i+1]=(A[i]^2)%%mod}\rfor(i in n:1) {\rif(power\u0026gt;=2^(i-1)) {power=power-2^(i-1)}\relse {A[i]=1} }\rfor(i in 2:n) {A[1]=(A[1]*A[i])%%mod}\rreturn(A[1])\r}\rshanks\u0026lt;-function(g,h,p)\r{\rN\u0026lt;-order(g,p)\rn\u0026lt;-1+floor(sqrt(N))\rgn\u0026lt;-FPM(g,-n,p) #gn := g^{-n}\rx\u0026lt;-p\rList_1\u0026lt;-numeric(n+1)\rList_1[1]=1\rfor(i in 1:n) {List_1[i+1]=(List_1[i]*g)%%p}\rList_2\u0026lt;-numeric(n+1)\rList_2[1]=h\rfor(i in 1:n) {List_2[i+1]=(List_2[i]*gn)%%p}\rfor(i in 0:n+1) {\rfor(j in 0:n+1) {\rif (List_1[i]==List_2[j]) {x[length(x)+1]\u0026lt;-((i-1)+(j-1)*n)}\r}\r}\rreturn(min(x))\r}\rCRA\u0026lt;-function(S) #Algorithm of chinese remainder theorem\r{\rr\u0026lt;-S[,1] # matrix S express below sysyem.\rmod\u0026lt;-S[,2] # x = r[1] (mod mod[1])\rn\u0026lt;-length(r) # x = r[2] (mod mod[2])\r# x = r[3] (mod mod[3])\rA\u0026lt;-seq(r[1],to=mod[1]*mod[2],by=mod[1])\rfor(i in 2:n)\r{\rB=seq(r[i],to=mod[1]*mod[i],by=mod[i])\rr[1]=min(A[A %in% B])\rmod[1]=mod[1]*mod[i]\rif (i\u0026lt;n) {A=seq(r[1],to=mod[1]*mod[i+1],by=mod[1])}\r}\rreturn(r[1])\r}\rPHA\u0026lt;-function(g,h,p){\rN\u0026lt;-order(g,p)\rm_\u0026lt;-table(factorize(N))\rm_\u0026lt;-rbind(as.numeric(names(m_)),m_)\rm_\u0026lt;-c(data.frame(m_)[1,]^data.frame(m_)[2,])\ry_\u0026lt;-numeric(0)\rfor(i in 1:length(m_)){\rg_i\u0026lt;-FPM(g,N/m_[i],p)\rh_i\u0026lt;-FPM(h,N/m_[i],p)\ry_[i]\u0026lt;-shanks(g_i,h_i,p)\r}\rreturn(CRA(cbind(y_,m_)))\r}\rPHA(7,166,433)\rFPM(7,47,433)\rPHA(10,243278,746497)\rFPM(10,223755,746497)\rPHA(2,39183497,41022299)\rFPM(2,33703314,41022299) The result of running the above code is as follows, and it has been checked that it works correctly by verifying with exponentiation by squaring.\nSee Also Discrete logarithm problem Security Algorithms Utilizing the Difficulty of the Discrete Logarithm Problem Diffie-Hellman Key Exchange Algorithm ElGamal Public Key Cryptosystem Attack Algorithms on the Discrete Logarithm Problem Shanks\u0026rsquo; Algorithm Pollard-Rho Algorithm Conditions Under Which the Discrete Logarithm Problem Is Easily Solved ","id":940,"permalink":"https://freshrimpsushi.github.io/en/posts/940/","tags":null,"title":"Proof of Pollard's Rho Algorithm"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÍ≤ÄÏ†ï","contents":"Hypothesis Testing Given quantitative data $\\left\\{ x_{i} \\right\\}_{i = 1}^{n}$.\n$H_{0}$: Data $\\left\\{ x_{i} \\right\\}_{i = 1}^{n}$ follows a normal distribution. $H_{1}$: Data $\\left\\{ x_{i} \\right\\}_{i = 1}^{n}$ does not follow a normal distribution. Description The Shapiro-Wilk test is a hypothesis test used to assess the normality of data, usually to demonstrate that normality is present. It\u0026rsquo;s one of the rare occasions where having the null hypothesis accepted matches \u0026rsquo;the analyst\u0026rsquo;s intention\u0026rsquo;, hence understanding the hypothesis precisely is crucial.\nCode Practice In R, the shapiro.test() function allows for an easy conduct of the Shapiro-Wilk test. Generate the following two random samples and actually perform the Shapiro-Wilk test.\nN represents data from a normal distribution, and geo represents data from a geometric distribution.\nThe test results exactly as expected.\nFull Code Below is an example of the R code.\nset.seed(150421)\rN\u0026lt;-rnorm(100)\rwin.graph(4,4); hist(N)\rshapiro.test(N)\rgeo\u0026lt;-rgeom(100,0.5)\rwin.graph(4,4); hist(geo)\rshapiro.test(geo) See Also Jarque-Bera Test ","id":939,"permalink":"https://freshrimpsushi.github.io/en/posts/939/","tags":null,"title":"Shapiro-Wilk Test"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Buildup The reason why transformations are necessary in time series is to give a \u0026ldquo;penalty\u0026rdquo; for increasing variance over time, to keep the variance constant, and to achieve stationarity. The square root $\\sqrt{}$ and log $\\log$ are often used because the amount reduced is greater for larger values. Of course, when variance decreases, it means that the trend of data converges to some point, thus no time series analysis is needed before the transformation.\nTest 1 Box-Cox Transformation: $$g(x) := \\begin{cases} \\displaystyle {{ x^{\\lambda} - 1 } \\over { \\lambda }} \u0026amp; , \\lambda \\ne 0 \\\\ \\log x \u0026amp; , \\lambda = 0 \\end{cases}$$\nWhen it is not clear just by looking whether to take a transformation or which transformation is appropriate, we usually use the hypothesis test of Box-Cox transformation, which can also be used to justify why no further transformation is needed.\nPractice Let\u0026rsquo;s load the built-in data, UKgas.\nUKgas is data recorded quarterly on the consumption of gas in the UK, and as you can see, the fluctuations become more severe as the years go by. In such cases of non-constant variance, it is difficult to conduct a smooth analysis. Therefore, making the data easier to handle by taking transformations like logs is essential.\nTaking a transformation, we can see that the variance has noticeably become more uniform, though not perfect.\nCode Below is an example code.\nUKgas\rwin.graph(4,4); plot(UKgas,main=\u0026#39;UKgas\u0026#39;)\rlog(UKgas)\rwin.graph(4,4); plot(log(UKgas),main=\u0026#39;log(UKgas)\u0026#39;) See Also Transformation in Regression Analysis Cryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p101.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":938,"permalink":"https://freshrimpsushi.github.io/en/posts/938/","tags":["R"],"title":"Transformation in Time Series Analysis"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definitions A prime number $p$ that has many divisors is called a smooth prime if $(p-1)$. A number that can be represented as a product of prime numbers less than or equal to $B$ is called a $B$-smooth number. $\\psi ( X , B )$ represents the number of $B$-smooth numbers less than or equal to $X$. Description As an example of a smooth prime, consider $p=37$ where $(p-1)$ is expressed as a product of small prime numbers such as $p-1 = 36 = 2^2 3^2$. The concept of smoothness was introduced to describe primes not suitable for cryptography as cryptography advanced.\nExamples of $5$-smooth numbers include $$ 2,3,4,5,6,8,9,10,12,15,16,18 \\cdots $$ and examples of numbers that are not $5$-smooth numbers include $$ 7,11,13, 14, 17,19,21,22,23,26,28,29,31,33\\cdots $$\n$\\psi : \\mathbb{N}^2 \\to \\mathbb{N}_{0}$ is a typical counting function. For instance, if we consider $\\psi (25,5)$, there are $2,3,4,5,6,8,9,10,12, $$ 15,16,18 ,20,24,25$ $5$-smooth numbers less than or equal to $25$, which can be represented as $\\psi (25,5) = 15$.\n","id":927,"permalink":"https://freshrimpsushi.github.io/en/posts/927/","tags":null,"title":"Smooth Primes"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition A function $f$ is said to be piecewise continuous on an interval $I$ if it satisfies the conditions below:\nIt has a finite number of discontinuities $x_{1},\\ x_{2},\\ \\cdots ,\\ x_{n} \\in I$.\nAt each point of discontinuity, it has both a left-hand limit and a right-hand limit.\n$$ \\left|\\lim \\limits_{x\\rightarrow x_{i}^{+}} f(x) \\right| \u0026lt; \\infty \\quad \\text{and} \\quad \\left|\\lim_{x \\rightarrow x_{i}^{-}}f(x)\\right|\u0026lt;\\infty \\quad (i=1,\\ \\cdots ,\\ n) $$\nIf a function $f$ is infinitely differentiable at all places except a finite number of points of discontinuity, it is called piecewise smooth.\nExplanation Some definitions consider a function to be piecewise continuous if it satisfies only condition 1. In simple terms, if you divide the function at its discontinuities, and each resultant segment is continuous, then the function is considered piecewise continuous.\nThere are various translations such as piecewise continuity, sectional continuity, and segmental continuity.\n","id":972,"permalink":"https://freshrimpsushi.github.io/en/posts/972/","tags":null,"title":"Continuity in Every Piece, Smoothness in Every Segment"},{"categories":"Ï†ïÏàòÎ°†","contents":"Algorithm 1 Let us say the element $g$ of the group $G$, with an identity element of $e$, has an order of $N$. Then, the discrete logarithm problem $g^{x} = h$ can be solved in at most $O \\left( \\sqrt{N} \\log N \\right)$ steps according to the following algorithm.\nStep 1.\n$n: = 1 + \\lfloor \\sqrt{N} \\rfloor $\nStep 2.\nCreate two lists $A := \\left\\{ e , g , g^{2} , \\cdots , g^{n} \\right\\}$ and $B := \\left\\{ h , hg^{-n} , hg^{-2n} , \\cdots , hg^{-n^2} \\right\\}$.\nStep 3.\nFind $g^{i} = h g^{-jn} \\in A \\cap B$.\nStep 4.\n$x = i + jn$ is the solution to $g^{x} = h$.\nExplanation Fundamentally, if the element $g$ of the group $G$ has an order of $N$, then the discrete logarithm problem $g^{x} = h$ can be solved in at most $O (N) $ steps. That $g$ has an order of $N$ means that at least $g^{N} = e$ holds true. Hence, it is easy to verify that among $ 0, 1, \\cdots , N-1$, there exists a $x$ that satisfies $g^{x} = h$.\nThe Shanks\u0026rsquo; algorithm reduces this computational load down to $O \\left( \\sqrt{N} \\log N \\right)$. If it\u0026rsquo;s a discrete logarithm problem applied to cryptography, since $N$ would be a significantly large number, reducing the computation by more than half has a significant meaning.\nThe terms baby steps and giant steps come from the lists of $A$ made by multiplying $g$ and the lists of $B$ made by multiplying $g^{-n}$.\nProof Part 1. Existence\nWe must show that $\\left( A \\cap B \\right) \\ne \\emptyset$ holds true.\nWhen $x$ is divided by $n$, let the quotient be $q$, and the remainder be $r$. Then, it can be represented as $x = nq + r$.\nThen, since $\\sqrt{N} \u0026lt; n$, $$ q = {{ x - r } \\over { n }} \u0026lt; {{ N } \\over { n }} \u0026lt; n $$ and $$ \\begin{align*} \u0026amp; g^{x} = h \\\\ \\implies \u0026amp; g^{ nq + r } = h \\\\ \\implies \u0026amp; g^{ r } = h g^{ - nq } \\end{align*} $$ it follows. Because of $r \u0026lt; n$, $g^{r} \\in A$, and because of $q \u0026lt; n$, $h g^{ - nq } \\in B$.\nPart 2. Time Complexity\nTo find $A \\cap B$, the list must be sorted, and using the most appropriate comparison sorting algorithm, $O ( n \\log n )$ calculations are necessary.\nSince $n \\approx \\sqrt{N}$, $$ \\begin{align*} O \\left( n \\log n \\right) =\u0026amp; O \\left( \\sqrt{N} \\log \\sqrt{N} \\right) \\\\ =\u0026amp; O \\left( {{1} \\over {2}} \\sqrt{N} \\log N \\right) \\\\ =\u0026amp; O \\left( \\sqrt{N} \\log N \\right) \\end{align*} $$\n‚ñ†\nCode Below is the implementation of Shank\u0026rsquo;s algorithm in R language. Prime factorization code and Order finding code were used.\nprime = read.table(\u0026#34;../attachment\r/cfile8.uf@25411C3C5968BBE322F0D4.txt\u0026#34;); prime = prime[,1]\rfactorize\u0026lt;-function(p)\r{\rq=p\rfactors\u0026lt;-numeric(0)\ri=1; j=1\rwhile(q!=1)\r{\rif(q%%prime[i]) {i=i+1}\relse\r{\rq\u0026lt;-q/prime[i]\rfactors[j]\u0026lt;-prime[i]\ri=1\rj=j+1\r}\r}\rreturn(factors)\r}\rorder\u0026lt;-function(g,p,h=1) #Calculate a order of g in modulo p\r{\rqe\u0026lt;-table(factorize(p-1))\rqe\u0026lt;-rbind(as.numeric(names(qe)),qe)\rdivisor\u0026lt;-qe[1,1]^(0:qe[2,1])\rif((length(qe)/2)==1) {return(qe[1,1]^qe[2,1])}\rfor(i in 2:(length(qe)/2)) {divisor=c(divisor%*%t(qe[1,i]^(0:qe[2,i])))}\rfor(i in divisor) {if((FPM(g,i,p))%%p==1) break;}\rreturn(i)\r}\rshanks\u0026lt;-function(g,h,p)\r{\rN\u0026lt;-order(g,p)\rn\u0026lt;-1+floor(sqrt(N))\rgn\u0026lt;-FPM(g,-n,p) #gn := g^{-n}\rx\u0026lt;-p\rList\\_1\u0026lt;-numeric(n+1)\rList\\_1[1]=1\rfor(i in 1:n) {List\\_1[i+1]=(List\\_1[i]*g)%%p}\rList\\_2\u0026lt;-numeric(n+1)\rList\\_2[1]=h\rfor(i in 1:n) {List\\_2[i+1]=(List\\_2[i]*gn)%%p}\rfor(i in 0:n+1) {\rfor(j in 0:n+1) {\rif (List\\_1[i]==List\\_2[j]) {x[length(x)+1]\u0026lt;-((i-1)+(j-1)*n)}\r}\r}\rreturn(min(x))\r}\rshanks(11,21,71)\rFPM(11,37,71)\rshanks(156,116,593)\rFPM(156,59,593)\rshanks(650,2213,3571)\rFPM(650,319,3571) The result of running the above code is as follows, and it was verified to work correctly through checking with exponentiation by squaring.\nSee also Discrete logarithm problem Security algorithms utilizing the difficulty of the discrete logarithm problem Diffie-Hellman key exchange algorithm ElGamal public key cryptosystem Attack algorithms for the discrete logarithm problem Shanks\u0026rsquo; algorithm Pollard\u0026rsquo;s rho algorithm Conditions under which the discrete logarithm problem is easily solved Hoffstein. (2008). An Introduction to Mathematical Cryptography: p80.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":917,"permalink":"https://freshrimpsushi.github.io/en/posts/917/","tags":null,"title":"Shor's Algorithm Proof"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 Define operator $B$ as $B Y_{t} = Y_{t-1}$, referred to as Backshift. Define operator $\\nabla$ as $\\nabla := 1 - B$ and $\\nabla^{r+1} = \\nabla \\left( \\nabla^{r} Y_{t} \\right)$, referred to as Differencing. Explanation According to the definition of differencing, the $1$th difference is calculated as $$ \\nabla Y_{t} = Y_{t} - Y_{t-1} $$, and the $2$th difference is calculated as $$ \\begin{align*} \\nabla^2 Y_{t} =\u0026amp; \\nabla \\left( \\nabla Y_{t} \\right) \\\\ =\u0026amp; \\nabla \\left( Y_{t} - Y_{t-1} \\right) \\\\ =\u0026amp; \\nabla Y_{t} - \\nabla Y_{t-1} \\\\ =\u0026amp; ( Y_{t} - Y_{t-1} ) - ( Y_{t-1} - Y_{t-2} ) \\\\ =\u0026amp; Y_{t} - 2 Y_{t-1} + Y_{t-2} \\end{align*} $$. In other words, applying differencing twice to $Y_{t}$ does not result in $Y_{t} - Y_{t-2}$. Such extended differencing is separately defined as seasonal differencing.\nThe need for differencing in time series arises because it is convenient when dealing with data that has a Trend. In time series analysis, a trend refers to the \u0026rsquo;tendency of data values to increase or decrease over a certain period\u0026rsquo;. In this case, there are concerns about stationarity. Therefore, appropriate differencing is carried out as a preprocessing step to ensure data stationarity. A single differencing may be sufficient for mere increases or decreases, but more complex shapes may require more differencing.\nWhen unsure whether differencing is appropriate or how much to apply, the Dickey-Fuller test is commonly used both to endorse the extent of differencing needed and to justify why no further differencing is necessary.\nPractice Let\u0026rsquo;s look at the oil.price data from the TSA package.\noil.price is data on crude oil prices from 1986 to 2005. There is a strong upward trend, indicating a lack of stationarity. Such data is difficult to analyze, so differencing is applied to remove the trend.\nDifferencing in R is very easy. Using the diff() function returns the differenced data, dropping the first observation. Though not often used, the option lag=n also allows for simple calculation of the $n$th difference.\nDespite the fluctuations, the differenced result shows movement around $0$ on average.\nCode Below is an example R code.\nlibrary(TSA)\rdata(oil.price); oil.price\rwin.graph(4,4); plot(oil.price,main=\u0026#39;oil.price\\\u0026#39;)\rdiff(oil.price)\rwin.graph(4,4); plot(diff(oil.price),main=\u0026#39;‚àáoil.price\\\u0026#39;)\rdiff(oil.price,lag=2) See Also Differencing in numerical analysis Cryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p90.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":916,"permalink":"https://freshrimpsushi.github.io/en/posts/916/","tags":["R"],"title":"Differencing in Time Series Analysis"},{"categories":"Ï†ïÏàòÎ°†","contents":"Buildup From left to right, let\u0026rsquo;s name them Alice, Bob, and Eve. Alice and Bob are the parties exchanging messages, and Eve is a passive attacker interested in the message. The orange box represents information known only to Alice, the sky-blue box represents information known only to Bob, and the black box represents public information (also known to Eve).\nAlice has a message $m \\in \\mathbb{N}$ to receive from Bob.\nAlgorithm 1 $\\mathbb{F}_{p}^{ \\ast } = \\mathbb{F}_{p} \\setminus \\left\\{ 0 \\right\\} = \\left\\{ 1, g , g^2 , \\cdots , g^{p-2} \\right\\}$ Let\u0026rsquo;s say it\u0026rsquo;s a cyclic group with $(p-1)$ elements.\nKey Setup: Publicly choose a very large prime number $p$ and $\\text{ord}_{p} (g)$, which is a large prime number, as $g \\in \\mathbb{F}_{p}^{ \\ast }$.\nAlice decides on a key $1 \\le a \\le p-1$, known only to herself, and computes $A \\equiv g^{a} \\pmod{p}$ to make it public.\nEncryption: Generate a one-time random key $k$. Bob calculates $c_{1} \\equiv g^{k} \\pmod{p}$ and $c_{2} \\equiv m A^{k} \\pmod{p}$ to transmit $(c_{1} , c_{2})$ to Alice.\nDecryption: Using $(c_{1} , c_{2})$, Alice computes $x \\equiv (c_{1}^{a} )^{-1} c_{2} \\equiv m \\pmod{p}$ to obtain $x = m$. It\u0026rsquo;s realistically impossible for Eve to know $a$, therefore, she can\u0026rsquo;t know $m$.\nExplanation In fact, there\u0026rsquo;s no need for the order $\\text{ord}_{p} (g)$ of $g$ to be large in the system itself, but choosing a number with a large order is better to reduce the possibility of obtaining it by brute force.\nProof Decryption Since Alice knows $a$, and $c_{1} \\equiv g^{k} \\pmod{p}$ and $c_{2} \\equiv m A^{k} \\pmod{p}$, she can easily compute $$ \\begin{align*} (c_{1}^{a} )^{-1} c_{2} \u0026amp; \\equiv \\left( g^{ak} \\right)^{-1} \\cdot c_{2} \\\\ \u0026amp; \\equiv \\left( g^{ak} \\right)^{-1} \\cdot \\left( m A^{k} \\right) \\\\ \u0026amp; \\equiv \\left( g^{ak} \\right)^{-1} \\cdot \\left( m \\left( g^{a} \\right)^{k} \\right) \\\\ \u0026amp; \\equiv m \\left( g^{ak} \\right)^{-1} \\cdot g^{ak} \\\\ \u0026amp; \\equiv m \\pmod{p} \\end{align*} $$ without knowing $k$.\n‚ñ†\nEncryption Since Eve only knows $c_{1}$ and $c_{2}$, not $a$ and $k$, she cannot know the discrete logarithm problem ${g}^{x} \\equiv c_{1}^{a} \\pmod{p}$, and even if she did, she would need to solve it directly. Since this is very difficult, Bob can safely transmit the message $m$ to Alice.\n‚ñ†\nSee Also Discrete logarithm problem Security algorithms utilizing the difficulty of the discrete logarithm problem Diffie-Hellman key exchange algorithm ElGamal public key cryptosystem Attack algorithms on the discrete logarithm problem Shanks\u0026rsquo; algorithm Pollard\u0026rsquo;s rho algorithm Conditions under which the discrete logarithm problem is easily solvable Hoffstein. (2008). An Introduction to Mathematical Cryptography: p70.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":915,"permalink":"https://freshrimpsushi.github.io/en/posts/915/","tags":null,"title":"ElGamal Public Key Cryptosystem Proof"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Formulas The following expressions hold true for vector integration involving the del operator.\n(a)\n$$ \\int_{\\mathcal{V}}\\mathbf{A} \\cdot (\\nabla f)d\\tau = \\oint_{\\mathcal{S}}f\\mathbf{A} \\cdot d \\mathbf{a}-\\int_{\\mathcal{V}}f(\\nabla \\cdot \\mathbf{A})d\\tau $$\n(b)\n$$ \\int_{\\mathcal{S}} f \\left( \\nabla \\times \\mathbf{A} \\right)\\mathbf{A} \\cdot d \\mathbf{a} = \\int_{\\mathcal{S}} \\left[ \\mathbf{A} \\times \\left( \\nabla f \\right) \\right] \\cdot d\\mathbf{a} + \\oint_{\\mathcal{P}} f\\mathbf{A} \\cdot d\\mathbf{l} $$\n(c)\n$$ \\int_{\\mathcal{V}} \\mathbf{B} \\cdot \\left( \\nabla \\times \\mathbf{A} \\right) d\\tau = \\int_{\\mathcal{V}} \\mathbf{A} \\cdot \\left( \\nabla \\times \\mathbf{B} \\right) d\\tau + \\oint_{\\mathcal{S}} \\left( \\mathbf{A} \\times \\mathbf{B} \\right) \\cdot d \\mathbf{a} $$\nExplanation Partial integration is a method that simplifies the integration of the product of a function $(f\\ or\\ \\mathbf{A}$ and the derivative of a function $(\\nabla f\\ or\\ \\nabla \\cdot \\mathbf{A})$.\nPartial Integration $\\dfrac{d}{dx}\\left( fg \\right) = f\\dfrac{dg}{dx}+g\\dfrac{df}{dx}$ Integrating both sides yields\n$$ \\int_{a}^b \\dfrac{d}{dx} \\left(fg\\right) = (fg)\\Big|_{a}^b=\\int_{a}^b f\\left(\\dfrac{dg}{dx}\\right)dx+\\int_{a}^bg\\left(\\dfrac{df}{dx}\\right)dx \\\\ \\implies \\int_{a}^b f\\left(\\dfrac{dg}{dx}\\right)dx = (fg)\\Big|_{a}^b-\\int_{a}^bg\\left(\\dfrac{df}{dx}\\right)dx $$\nProof (a) Using Product Rule 3\n$$ \\nabla \\cdot (f\\mathbf{A}) = \\mathbf{A} \\cdot (\\nabla f) + f(\\nabla \\cdot \\mathbf{A}) $$\nIntegrating both sides with respect to volume gives\n$$ \\int_{\\mathcal{V}} \\nabla \\cdot (f\\mathbf{A})d\\tau = \\int_{\\mathcal{V}}\\mathbf{A} \\cdot (\\nabla f)d\\tau + \\int_{\\mathcal{V}}f(\\nabla \\cdot \\mathbf{A})d\\tau $$\nApplying the Divergence Theorem to the left hand side gives\n$$ \\oint_{\\mathcal{S}}f\\mathbf{A} \\cdot d \\mathbf{a} = \\int_{\\mathcal{V}}\\mathbf{A} \\cdot (\\nabla f)d\\tau + \\int_{\\mathcal{V}}f(\\nabla \\cdot \\mathbf{A})d\\tau $$\nUpon simplification, we get\n$$ \\int_{\\mathcal{V}}f(\\nabla \\cdot \\mathbf{A})d\\tau = \\oint_{\\mathcal{S}}f\\mathbf{A} \\cdot d \\mathbf{a}-\\int_{\\mathcal{V}}\\mathbf{A} \\cdot (\\nabla f)d\\tau $$\nOr equivalently,\n$$ \\int_{\\mathcal{V}}\\mathbf{A} \\cdot (\\nabla f)d\\tau = \\oint_{\\mathcal{S}}f\\mathbf{A} \\cdot d \\mathbf{a}-\\int_{\\mathcal{V}}f(\\nabla \\cdot \\mathbf{A})d\\tau $$\n‚ñ†\n(b) (c) ","id":959,"permalink":"https://freshrimpsushi.github.io/en/posts/959/","tags":null,"title":"Partial Integration of Expressions Containing the Del Operator"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Model 1 White noise $\\left\\{ e_{t} \\right\\}_{t \\in \\mathbb{N}}$ is defined as $$ Y_{t} := \\phi_{1} Y_{t-1} + \\phi_{2} Y_{t-2} + \\cdots + \\phi_{p} Y_{t-p} +e_{t} - \\theta_{1} e_{t-1} - \\theta_{2} e_{t-2} - \\cdots - \\theta_{q} e_{t-q} $$ such a process is called a $(p,q)$th order autoregressive moving average process $ARMA(p,q)$.\nExplanation The ARMA model is simply a combination of the Moving Average Process and the Autoregressive Process. For instance, if it is of order $(1,1)$, then it is expressed as $$ ARMA(1,1) : Y_{t} = \\phi Y_{t-1} + e_{t} - \\theta e_{t-1} $$ However, since the ARMA model still has some limitations as a model, Differencing is used to improve it, leading to the more commonly used ARIMA model. Essentially, all are eventually considered as ARMA models.\nCryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p77.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":914,"permalink":"https://freshrimpsushi.github.io/en/posts/914/","tags":null,"title":"Autoregressive Moving Average Model"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Model 1 White noise $\\left\\{ e_{t} \\right\\}_{t \\in \\mathbb{N}}$ is defined as in $Y_{t} := \\phi_{1} Y_{t-1} + \\phi_{2} Y_{t-2} + \\cdots + \\phi_{p} Y_{t-p} + e_{t}$ and is called an $p$th order autoregressive process $AR(p)$.\n(1): $AR(1) : Y_{t} = \\phi Y_{t-1} + e_{t}$ (2): $AR(2) : Y_{t} = \\phi_{1} Y_{t-1} + \\phi_{2} Y_{t-2} + e_{t}$ (p): $AR(p) : Y_{t} = \\phi_{1} Y_{t-1} + \\phi_{2} Y_{t-2} + \\cdots + \\phi_{p} Y_{t-p} + e_{t}$ (‚àû): $AR( \\infty ) : Y_{t} = e_{t} + \\phi_{1} Y_{t-1} + \\phi_{2} Y_{t-2} + \\cdots $ $\\mathbb{N}$ represents the set of natural numbers $\\left\\{ 1, 2, 3 , \\cdots \\right\\}$. Explanation $AR(p)$ is called an \u0026lsquo;autoregressive process\u0026rsquo; because it literally takes the form of a regression equation where previous times of itself are viewed as independent variables. It is evident that independence among the variables is not assumed. Moreover, it does not require stationarity, and, for example, it is not difficult to surmise that $AR(1) : Y_{t} = \\phi Y_{t-1} + e_{t}$ might show simple movements such as increasing, decreasing, or oscillating.\nCryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p66.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":910,"permalink":"https://freshrimpsushi.github.io/en/posts/910/","tags":null,"title":"Autoregressive Process"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 Let\u0026rsquo;s say that for a prime number $p$, the identity element in the Galois Field $\\mathbb{F}_{p} := \\mathbb{Z} / p \\mathbb{Z}$ is $0$.\nThen, for a primitive root $g \\ne 0$ of $\\mathbb{F}_{p}$, a function $\\log_{g} : \\mathbb{F}_{p}^{ \\ast } \\to \\mathbb{Z} / (p-1) \\mathbb{Z}$ defined on a cyclic group $\\mathbb{F}_{p} ^{ \\ast } := \\mathbb{F}_{p} \\setminus \\left\\{ 0 \\right\\} = \\left\u0026lt; g \\right\u0026gt;$ that satisfies the following is called a Discrete Logarithm. $$ g^{ \\log_{g} (h) } \\equiv h \\pmod{p} $$\nExplanation The existence of $\\mathbb{F}_{p} ^{ \\ast }$ is guaranteed by the Primitive Root Theorem.\nIn fact, the discrete logarithm becomes an isomorphism because it applies to all $a,b \\in \\mathbb{F}_{p}^{ \\ast }$ such that $\\log_{g} (ab) = \\log_{g} (a) + \\log_{g} (b)$.\nUnlike ordinary logs, the log in cryptography is useful because of the difficulty of its calculation, for given $k$, $$ g^{k} \\equiv x \\pmod{p} $$ finding $x$ that satisfies it is not too difficult using the method of successive squaring, however, for a given $h$, $$ g^{x} \\equiv h \\pmod{p} $$ finding $x$ that satisfies it is hard. This is called the Discrete Logarithm Problem, and it possesses essential properties of a cipher, making it widely used throughout cryptography.\nMoreover, the discrete logarithm problem can also be generalized over group $\\left( G , \\ast\\ \\right)$. The issue itself still asks $$ g \\ast\\ \\cdots \\ast\\ g = h $$ how many times one must find $g \\ast\\ g$ to satisfy it. This implies that the limitation of cryptography is not in number theory.\nSee Also Discrete Logarithm Problem Cryptographic Algorithms that Utilize the Difficulty of the Discrete Logarithm Problem Diffie-Hellman Key Exchange Algorithm ElGamal Public Key Cryptosystem Attack Algorithms on the Discrete Logarithm Problem Shanks\u0026rsquo; Algorithm Pollard\u0026rsquo;s Rho Algorithm Conditions where the Discrete Logarithm Problem is Easily Solvable Hoffstein. (2008). An Introduction to Mathematical Cryptography: p63.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":911,"permalink":"https://freshrimpsushi.github.io/en/posts/911/","tags":null,"title":"Discrete Logarithms"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Model 1 The process defined as follows for white noise $\\left\\{ e_{t} \\right\\}_{t \\in \\mathbb{N}}$ and according to $Y_{t} := e_{t} - \\theta_{1} e_{t-1} - \\theta_{2} e_{t-2} - \\cdots - \\theta_{q} e_{t-q}$, is called the $q$th order moving average process $MA(q)$.\n(1): $MA(1) : Y_{t} = e_{t} - \\theta e_{t-1}$ (2): $MA(2) : Y_{t} = e_{t} - \\theta_{1} e_{t-1} - \\theta_{2} e_{t-2}$ (q): $MA(q) : Y_{t} = e_{t} - \\theta_{1} e_{t-1} - \\theta_{2} e_{t-2} - \\cdots - \\theta_{q} e_{t-q}$ (‚àû): $MA( \\infty ) : Y_{t} = e_{t} - \\theta_{1} e_{t-1} - \\theta_{2} e_{t-2} - \\cdots$ $\\mathbb{N}$ denotes the set of natural numbers $\\left\\{ 1, 2, 3 , \\cdots \\right\\}$. Explanation The green, red, orange, and purple lines in the following figure are referred to as moving average lines.\nMoving average lines are widely used in graphs, especially in the stock market, as they allow observing the overall trend rather than the extreme changes day by day. However, it might be difficult to understand why $MA(q)$ is called a \u0026ldquo;moving average process\u0026rdquo; just by looking at the formula. As a simple example, consider $MA(2) : Y_{t} = e_{t} - \\theta_{1} e_{t-1} - \\theta_{2} e_{t-2}$, which becomes $\\displaystyle Y_{t} = {{ e_{t-1} + e_{t-2} } \\over {2}} + e_{t}$ when $\\displaystyle \\theta_{1} = \\theta_{2} = - {{1} \\over {2}}$.\nIf a variable is growing or declining smoothly, that is, with minimal local fluctuations, then looking at the moving averages would be meaningless. Similarly, moving averages merely smooth out changes without altering the scale itself. Similarly, $MA(q)$ focuses on identifying patterns over shorter periods than $q$, not on the specific values or overall trends. In other words, it can only be used with data that has stationarity.\nCryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p57.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":909,"permalink":"https://freshrimpsushi.github.io/en/posts/909/","tags":null,"title":"Moving Average Process"},{"categories":"Ï†ïÏàòÎ°†","contents":"Buildup Let\u0026rsquo;s imagine that Alice wants to convey a message to Bob. If there were only two people in the world, this message would be shared exclusively between them, with no reason to hide it. [ NOTE: In cryptography, Alice and Bob are names commonly used to represent $A$ and $B$, respectively. ] However, suppose there is a third person, Eve. Eve might not necessarily have bad intentions, but she is interested in the message Alice wants to convey to Bob. On the other hand, Alice wants only Bob to know the message she sends. [ NOTE: In cryptography, Eve refers to an \u0026lsquo;Eavesdropper\u0026rsquo;, represented by $E$, and plays the role of a passive attacker who only attempts to intercept messages. ] Therefore, Alice tries to send the message in a way that Eve cannot understand. This is a motif that anyone, as a human, can empathize with in \u0026lsquo;cryptography\u0026rsquo;.\nWhen Alice transforms the message so only Bob can understand, it is called Encryption, and when Bob restores the transformed message to its original form, it is called Decryption. Moreover, the message before encryption is called the Plaintext, denoted by $\\mathcal{M}$, and the collection of these messages is referred to as the set, whereas the message after encryption is called the Ciphertext, denoted by $\\mathcal{C}$, and its collection is referred to as another set. Encryption and decryption are performed based on certain rules, and a Key is shared so that a third party, even if they know these rules, cannot decrypt the message. If the collection of such keys is called $\\mathcal{K}$, then encryption and decryption can be mathematically represented as follows.\nDefinition 1 The function $e : \\mathcal{K} \\times \\mathcal{M} \\to \\mathcal{C}$ is called Encryption, and is also denoted as $e_{k} : \\mathcal{M} \\to \\mathcal{C}$. The function $d : \\mathcal{K} \\times \\mathcal{C} \\to \\mathcal{M}$ is called Decryption, and is also denoted as $d_{k} : \\mathcal{C} \\to \\mathcal{M}$. However, $e_{k}$ and $d_{k}$ must be inverse functions of each other. In other words, for all $m \\in \\mathcal{M}$, $d_{k} \\left( e_{k} ( m ) \\right) = m$ must hold.\nYet, there are too many such corresponding relationships, and among them, a usable cipher must satisfy the following conditions.\nA cryptographic system $( \\mathcal{K} , \\mathcal{M} , \\mathcal{C} , e , d )$ is useful when it has the following properties:\n(i): For all $k \\in \\mathcal{K}$ and $m \\in \\mathcal{M}$, it must be easy to compute $e_{k} (m)$. (ii): For all $k \\in \\mathcal{K}$ and $c \\in \\mathcal{C}$, it must be easy to compute $d_{k} (c)$. (iii): Without knowing $k$, even if $c_{1} , \\cdots , c_{n} \\in \\mathcal{C}$ is given, considering $d_{k} ( c_{1} ) , \\cdots , d_{k} ( c_{n} )$ must be difficult to compute. Explanation In summary, a useful cryptographic system is one where only those qualified can easily see the message, and those who are not cannot see it. It would be best if there were no attackers intercepting the message, but even if there are, the content must not be revealed. Moreover, if encryption and decryption take too long even for the parties involved in communication, it might compromise too much of the functionality of communication despite having good security.\nHoffstein. (2008). An Introduction to Mathematical Cryptography: p37.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":908,"permalink":"https://freshrimpsushi.github.io/en/posts/908/","tags":null,"title":"Encryption and Decryption in Cryptography"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition The following differential equation is referred to as the Chebyshev Differential Equation:\n$$ (1-x^2)\\dfrac{d^2 y}{dx^2} -x\\dfrac{dy}{dx}+n^2 y=0 $$\nDescription It\u0026rsquo;s a form that includes the independent variable $x$ in the coefficient, and assuming that the solution is in the form of a power series, it can be solved. The solution to the Chebyshev equation is called the Chebyshev polynomial, often denoted as $T_{n}(x)$.\nSolution $$ \\begin{equation} (1-x^2)y^{\\prime \\prime} -xy^{\\prime}+\\lambda^2 y=0 \\label{1} \\end{equation} $$\nLet\u0026rsquo;s assume the solution to the given Chebyshev differential equation is as follows:\n$$ y=a_{0}+a_{1}(x-x_{0})+a_2(x-x_{0})^2+\\cdots=\\sum \\limits_{n=0}^\\infty a_{n}(x-x_{0})^n $$\nWhen it is $x=0$, since the coefficient of $y^{\\prime \\prime}$ is $(1-x^2)|_{x=0}=1\\ne 0$, let\u0026rsquo;s set it to $x_{0}=0$. Then,\n$$ \\begin{equation} y=a_{0}+a_{1}x+a_2x^2+\\cdots=\\sum \\limits_{n=0}^\\infty a_{n}x^n \\label{2} \\end{equation} $$\nWe start solving by assuming a series solution, but at the end of the solution, we find that the terms of $y$ are finite. Now, to substitute into $\\eqref{1}$, let\u0026rsquo;s find $y^{\\prime}$ and $y^{\\prime \\prime}$.\n$$ y^{\\prime}=a_{1}+2a_2x+3a_{3}x^2+\\cdots=\\sum \\limits_{n=1}^\\infty na_{n}x^{n-1} $$\n$$ y^{\\prime \\prime}=2a_2+3\\cdot 2a_{3}x+4\\cdot 3 a_{4}x^2 +\\cdots = \\sum \\limits_{n=2} n(n-1)a_{n}x^{n-2} $$\nSubstituting $y, y^{\\prime}, y^{\\prime \\prime}$ into $\\eqref{1}$ yields the following:\n$$ (1-x^2)\\sum \\limits_{n=2}^\\infty n(n-1)a_{n}x^{n-2} -x\\sum \\limits_{n=1}^\\infty na_{n}x^{n-1}+\\lambda^2 \\sum \\limits_{n=0}^\\infty a_{n}x^n=0 $$\nExpanding and rearranging the first term\u0026rsquo;s coefficient $(1-x^2)$ gives:\n$$ \\sum \\limits_{n=2}^\\infty n(n-1)a_{n}x^{n-2} -x^2\\sum \\limits_{n=2}^\\infty n(n-1)a_{n}x^{n-2} -x\\sum \\limits_{n=1}^\\infty na_{n}x^{n-1}+\\lambda^2 \\sum \\limits_{n=0}^\\infty a_{n}x^n = 0 $$\n$$ \\implies \\sum \\limits_{n=2} ^\\infty n(n-1)a_{n}x^{n-2} -\\sum \\limits_{n=2}^\\infty n(n-1)a_{n}x^{n} -\\sum \\limits_{n=1}^\\infty na_{n}x^{n}+\\lambda^2 \\sum \\limits_{n=0}^\\infty a_{n}x^n = 0 $$\nThe key here is to match the order of $x$. While the rest are all expressed as $x^n$, only the first series is expressed as $x^{n-2}$, so substituting $n+2$ instead of $n$ yields:\n$$ \\sum \\limits_{n=0} ^\\infty (n+2)(n+1)a_{n+2}x^{n} -\\sum \\limits_{n=2}^\\infty n(n-1)a_{n}x^{n} -\\sum \\limits_{n=1}^\\infty na_{n}x^{n}+\\lambda^2 \\sum \\limits_{n=0}^\\infty a_{n}x^n=0 $$\nSince the second series starts from the term $x^2$, we extract the term where $n=0,1$ from the rest of the series, and group constant terms with constant terms, and first-order terms with first-order terms:\n$$ \\left[ 2\\cdot 1 a_2+\\lambda^2 a_{0} \\right]+\\left[ 3\\cdot 2 a_{3}-a_{1}+\\lambda^2a_{1} \\right]x \\\\ + \\sum \\limits_{n=2}^\\infty \\left[ (n+2)(n+1)a_{n+2}-n(n-1)a_{n}-na_{n}+\\lambda^2a_{n} \\right] x^n=0 $$\nFor this equation to hold, all coefficients must be $0$.\n$$ 2\\cdot 1 a_2+\\lambda^2 a_{0} = 0 $$\n$$ 3\\cdot 2 a_{3}-a_{1}+\\lambda^2a_{1} =0 $$\n$$ (n+2)(n+1)a_{n+2}-n(n-1)a_{n}-na_{n}+\\lambda^2a_{n}=0 $$\nOrganizing each gives:\n$$ \\begin{align} a_2 \u0026amp;= -\\dfrac{\\lambda^2}{2 \\cdot 1}a_{0} \\label{3} \\\\ a_{3} \u0026amp;=-\\dfrac{\\lambda^2-1^2}{3\\cdot 2} a_{1} \\label{4} \\\\ a_{n+2} \u0026amp;= -\\dfrac{\\lambda^2-n^2}{(n+2)(n+1)}a_{n} \\label{5} \\end{align} $$\nHaving obtained the recurrence relation $\\eqref{5}$, we can determine all coefficients if we just know the values of $a_{0}$ and $a_{1}$. From $\\eqref{3}, \\eqref{5}$, obtaining the coefficients of even-order terms:\n$$ \\begin{align*} a_{4} \u0026amp;= -\\dfrac{\\lambda^2-2^2}{4\\cdot 3}a_2=\\dfrac{\\lambda^2(\\lambda^2-2^2)}{4!}a_{0} \\\\ a_{6} \u0026amp;= -\\dfrac{\\lambda^2-4^2}{6\\cdot 5}a_{4}= -\\dfrac{\\lambda^2(\\lambda^2-2^2)(\\lambda^2-4^2)}{6!}a_{0} \\\\ \u0026amp;\\vdots \\end{align*} $$\nIf we say $n=2m (m=1,2,3,\\cdots)$ then:\n$$ a_{n}=a_{2m}=(-1)^m \\dfrac{\\lambda^2(\\lambda^2-2^2)\\cdots(\\lambda^2-(2m-2)^2)}{(2m)!}a_{0} $$\nSimilarly, obtaining the coefficients of odd-order terms from $\\eqref{4}, \\eqref{5}$:\n$$ \\begin{align*} a_{5} \u0026amp;= -\\dfrac{\\lambda^2-3^2}{5\\cdot 4}a_{3}=\\dfrac{(\\lambda^2-1^2)(\\lambda^2-3^2)}{5!}a_{1} \\\\ a_{7} \u0026amp;= -\\dfrac{\\lambda^2-5^2}{7\\cdot 6 }a_{5}=-\\dfrac{(\\lambda^2-1^2)(\\lambda^2-3^2)(\\lambda^2-5^2)}{7!}a_{1} \\\\ \u0026amp;\\vdots \\end{align*} $$\nIf we say $n=2m+1 (m=1,2,3,\\cdots)$ then:\n$$ a_{n}=a_{2m+1}=(-1)^m\\dfrac{(\\lambda^2-1^2)(\\lambda^2-3^2) \\cdots (\\lambda^2-(2m-1)^2)}{(2m+1)!}a_{1} $$\nSubstituting the obtained coefficients into $\\eqref{2}$ to find the solution gives:\n$$ \\begin{align*} y = \u0026amp;a_{0}+a_{1}x -\\dfrac{\\lambda^2}{2!}a_{0}x^2-\\dfrac{\\lambda^2-1^2}{3!} a_{1}x^3 + \\dfrac{\\lambda^2(\\lambda^2-2^2)}{4!}a_{0}x^4 \\\\ \u0026amp;+\\dfrac{(\\lambda^2-1^2)(\\lambda^2-3^2)}{5!}a_{1}x^5+ \\cdots +(-1)^m \\dfrac{\\lambda^2(\\lambda^2-2^2)\\cdots(\\lambda^2-(2m-2)^2)}{(2m)!}a_{0}x^{2m} \\\\ \u0026amp;+(-1)^m\\dfrac{(\\lambda^2-1^2)(\\lambda^2-3^2) \\cdots (\\lambda^2-(2m-1)^2)}{(2m+1)!}a_{1}x^{2m+1}+\\cdots\\quad(m=1,2,3,\\cdots) \\end{align*} $$\nHere, grouping even-order terms as $a_{0}$ and odd-order terms as $a_{1}$ and organizing gives:\n$$ \\begin{align*} y\u0026amp;=a_{0}\\left[1-\\dfrac{\\lambda^2}{2!}x^2+\\dfrac{\\lambda^2(\\lambda^2-2^2)}{4!}x^4+\\sum \\limits_{m=3}^\\infty (-1)^m \\dfrac{\\lambda^2(\\lambda^2-2^2)\\cdots(\\lambda^2-(2m-2)^2)}{(2m)!} x^{2m} + \\cdots \\right] \\\\ \u0026amp; + a_{1}\\left[x-\\dfrac{\\lambda^2-1^2}{3!}x^3+\\dfrac{(\\lambda^2-1^2)(\\lambda^2-3^2)}{5!}x^5+\\sum \\limits_{m=3}^\\infty (-1)^m\\dfrac{(\\lambda^2-1^2)(\\lambda^2-3^2) \\cdots (\\lambda^2-(2m-1)^2)}{(2m+1)!} x^{2m+1} + \\cdots\\right] \\end{align*} $$\nIf we call the first bracket $y_{0}$ and the second bracket $y_{1}$, then the general solution of the Chebyshev equation is as follows:\n$$ y=a_{0}y_{0}+a_{1}y_{1} $$\nThe two series $y_{0}$ and $y_{1}$ are known to converge within the range of $|x|\u0026lt;1$ according to the ratio test. Because of $\\eqref{5}$, $\\dfrac{a_{n+2}}{a_{n}}=\\dfrac{n^2-\\lambda^2}{(n+2)(n+1)}=\\dfrac{n^2-\\lambda^2}{n^2+3n+2}$, so if we use the ratio test:\n$$ \\lim \\limits_{n \\rightarrow \\infty} \\dfrac{n^2-\\lambda^2}{n^2+3n+2}x^2=x^2\u0026lt;1 $$\n$$ \\implies -1\u0026lt;x\u0026lt;1 $$\nHowever, in many problems, $x=\\cos \\theta$, $\\lambda$ appear in the form of non-negative integers, and we seek solutions that converge for all $\\theta$. In other words, the goal is to find solutions that also converge at $x=\\pm 1$. Fortunately, when $\\lambda$ is an integer, the desired solution exists, and depending on the value of $\\lambda$, only one of the two solutions $y_{0}, y_{1}$ must exist. When $\\lambda$ is $0$ or an even number, $y_{1}$ diverges, and $y_{0}$ becomes a finite-term polynomial with only even-order terms. When $\\lambda$ is odd, $y_{0}$ diverges, and $y_{1}$ becomes a finite-term polynomial with only odd-order terms. The summary is as follows:\nValue of $\\lambda$ $y_{0}$ $y_{1}$ Solution of the equation $0$ or even Finite-term polynomial Diverges $y=a_{0}y_{0}$ Odd Diverges Finite-term polynomial $y=a_{1}y_{1}$ Case 1. When $\\lambda$ is $0$ or even\nWhen $\\lambda=0$, from the second term, it takes $\\lambda^2$ as a factor, becoming all $0$, thus $y_{0}=1$\nWhen $\\lambda=2$, from the fourth term, it takes $(\\lambda^2-2^2)$ as a factor, becoming all $0$, thus $y_{0}=1-x^2$\nWhen $\\lambda=4$, from the sixth term, it takes $(\\lambda^2-4^2)$ as a factor, becoming all $0$, thus $y_{0}=1-8x^2+8x^4$\nAnd when $\\lambda=0$, $x=1$ diverges at $y_{1}=1+\\frac{1}{3!}+\\frac{1\\cdot3^2}{5!}+\\cdots$. The same applies to other even numbers. Therefore, when $\\lambda$ is $0$ or an even number, the solution becomes a finite-term polynomial with only even-order terms. That is, we obtain a form of the solution that only remains up to a specific term of the series $y_{0}$. The opposite result is obtained when $\\lambda$ is odd.\nCase 2. When $\\lambda$ is odd\nWhen $\\lambda=1$, from the third term, it takes $(\\lambda^2-1^2)$ as a factor, becoming all $0$, thus $y_{1}=x$\nWhen $\\lambda=3$, from the fifth term, it takes $(\\lambda^2-3^2)$ as a factor, becoming all $0$, thus $y_{1}=-3x+4x^3$\nWhen $\\lambda=5$, from the seventh term, it takes $(\\lambda^2-5^2)$ as a factor, becoming all $0$, thus $y_{1}=5x-20x^3+16x^5$\nWhen $\\lambda=1$, $x^2=1$ diverges at $y_{0}$, and the same applies to other odd numbers. Therefore, when $\\lambda$ is odd, the solution becomes a finite-term polynomial with only odd-order terms. That is, we obtain a form of the solution that only remains up to a specific term of the series $y_{1}$.\nIt\u0026rsquo;s also noted that when $\\lambda$ is negative, it\u0026rsquo;s the same as when $\\lambda$ is positive, which can be seen by examining $y_{0}$ and $y_{1}$. For instance, the case of $\\lambda=2$ is the same as the case of $\\lambda=-2$, and the case of $\\lambda=1$ is the same as the case of $\\lambda=-1$. Therefore, we only need to consider $\\lambda$ within the range of non-negative integers. Selecting $a_{0}$ and $a_{1}$ appropriately, when $x=1$, the solution becomes $y(x)=1$, this is called the Chebyshev polynomial and is commonly denoted as $T_{n}(x)$. The first few Chebyshev polynomials are as follows.\n$$ \\begin{align*} T_{0}(x) \u0026amp;= 1 \\\\ T_{1}(x) \u0026amp;= x \\\\ T_2(x) \u0026amp;= 2x^2-1 \\\\ T_{3}(x) \u0026amp;= 4x^3-3x \\\\ T_{4}(x) \u0026amp;= 8x^4-8x^2+1 \\\\ T_{5}(x) \u0026amp;= 16x^5-20x^3+5x \\\\ \\vdots \u0026amp; \\end{align*} $$\nSee Also Chebyshev Differential Equation and Chebyshev Polynomial ","id":955,"permalink":"https://freshrimpsushi.github.io/en/posts/955/","tags":null,"title":"Series Solution of Chebyshev Differential Equation"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 Time series data is said to have stationarity when its mean and variance are constant over time.\nDescription It\u0026rsquo;s not normalÊ≠£Â∏∏ as in standard, but stationarityÂÆöÂ∏∏.\nThe fact that data is stationary means that its mean and variance are stabilized, making it easier to analyze. If the data is not stationary, it becomes difficult to analyze, hence preprocessing is carried out to induce stationarity. Usually, if the mean is not constant, differencing is applied, and if the variance is not constant, a transformation is applied.\nLet\u0026rsquo;s look at the following four graphs.\nDifficult Data: Not only does it show a complex fluctuation pattern, but the values tend to increase over time, and the extent of this increase becomes more significant. It\u0026rsquo;s not hard to predict future trends, but it\u0026rsquo;s very difficult to express them neatly in a formula. Constant Mean: It\u0026rsquo;s not difficult because it spreads around a fixed 0, but the problem is the widening range. Constant Variance: Each pattern has a consistent shape, but one needs to explain the trend of increasing values over time. Stationary Data: Since both mean and variance are constant, one only needs to well explain the recurring fluctuations. Thus, having stationary data is a very good thing, and in fact, it can be said to be a prerequisite for using time series analysis.\nMeanwhile, if for every point in time $t_{1} , t_{2} , \\cdots , t_{n}$ and for every time lag $k$, $Y_{t_{1}} , Y_{t_{2}} , \\cdots , Y_{t_{n}}$ and $Y_{t_{1} - k} , Y_{t_{2} - k} , \\cdots , Y_{t_{n} - k}$ have the same joint distribution, then the stochastic process $\\left\\{ Y_{t} \\right\\}$ is said to be strictly stationary. However, this condition is too ideal, and thus it\u0026rsquo;s not commonly mentioned.\nCode win.graph(); par(mfrow=c(2,2))\rplot(AirPassengers,main=\u0026#39;Îã§Î£®Í∏∞ Ïñ¥Î†§Ïö¥ Îç∞Ïù¥ÌÑ∞\u0026#39;)\rplot(diff(AirPassengers),main=\u0026#39;ÏùºÏ†ïÌïú ÌèâÍ∑†\u0026#39;)\rplot(log(AirPassengers),main=\u0026#39;ÏùºÏ†ïÌïú Î∂ÑÏÇ∞\u0026#39;)\rplot(diff(log(AirPassengers)),main=\u0026#39;Ï†ïÏÉÅÏ†Å Îç∞Ïù¥ÌÑ∞\u0026#39;) See Also Stationarity in Spatial Processes Cryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p16.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":907,"permalink":"https://freshrimpsushi.github.io/en/posts/907/","tags":["R"],"title":"Stability in Time Series Analysis"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 A sequence $\\left\\{ e_{t} \\right\\}_{t = 1}^{\\infty}$ of independent identically distributed (iid) random variables $e_{t}$ is called White Noise.\niid stands for independent identically distributed, meaning that they are independent from each other and share the same distribution. Description Following the definition of a sequence of random variables, it is naturally a stochastic process. Particularly, if $E ( e_{t} ) = 0$, then the stochastic process $\\left\\{ Y_{t} \\right\\}_{t = 1}^{\\infty}$ defined as $Y_{t} : = \\begin{cases} e_{1} \u0026amp; , t=1 \\\\ Y_{t-1} + e_{t} \u0026amp; , t \\ne 1 \\\\ \\end{cases}$ becomes a random walk.\nIn statistics, it\u0026rsquo;s acknowledged that a 100% perfect explanation of an observed phenomenon is impossible. If a problem could be perfectly explained, there would be no need to solve it using statistics. Irrespective of the model, errors are inevitable, which statistics interpret as a \u0026rsquo;lack of information\u0026rsquo;. It would be beneficial to have as much information as possible, but it\u0026rsquo;s impossible to know everything about the universe, and when actually using it, cost issues arise too.\nIn this regard, white noise can be seen as the \u0026lsquo;inevitable error\u0026rsquo; that occurs in time series analysis. As the data is obtained from reality and not created ideally, it necessarily includes some. Although it might be negligible at first, as time passes, it could accumulate and become significantly large. Therefore, the forecasts in time series analysis become less reliable the further into the future they go, eventually losing their meaning.\nSee Also Random Walk from the Perspective of Stochastic Processes Cryer. (2008). Time Series Analysis: With Applications in R(2nd Edition): p17.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":904,"permalink":"https://freshrimpsushi.github.io/en/posts/904/","tags":null,"title":"Time Series Analysis: White Noise"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":"Wave Function The wave function is a function in quantum mechanics that represents the motion state of a particle depending on time and position. It is usually denoted by $u$, $\\psi$, $\\Psi$. In the context of Shrimp Sushi Restaurant, the wave function regarding position and time is denoted by $\\psi (x,t)$, and the wave function regarding position, independent of time, is denoted by $u(x)$.\nProbabilistic Interpretation The method of understanding the state of a particle through its wave function is based on the statistical (probabilistic) interpretation by Max Born. Here, the square of the magnitude of the wave function integrated over a certain interval is given the meaning as the probability of finding the particle within that interval.\n$$ \\int _{a} ^b |\\psi (x,t)|^2dx \\\\[1em] = \\text{The probability that a particle exists in the interval } [a,b] \\text{ at time } t $$\nThus, in quantum mechanics, $\\left| \\psi (x,\\ t) \\right|^2$ is treated as the probability density function for the existence of a particle at a point $x$ when the time is $t$. Hence, the above expression means the probability of the particle existing in the interval $[a, b]$ when the time is $t$. Then, as the particle must exist somewhere, the integral value over the total interval must be $1$.\n$$ \\int_{-\\infty}^{\\infty} |\\psi (x,\\ t)|^2 dx=1 $$\nThis condition stems from the perspective of interpreting the wave function probabilistically.\nNormalization However, looking at the formula below, when $\\psi$ satisfies the Schroedinger Equation, it can be understood that $a\\psi$, being a constant multiple of it, also satisfies the Schroedinger Equation.\n$$ H\\psi = E\\psi \\implies aH\\psi = aE\\psi \\implies H(a\\psi) = E(a\\psi) $$\nApplying the above interpretation to $a\\psi$, it becomes ${\\displaystyle \\int _{-\\infty}^{\\infty}} |a\\psi|^2 dx=a^2 \\ne 1$, making it impossible to interpret this value as a probability. Therefore, to give a probabilistic meaning, the size of the wave function must be adjusted so that the integral value over the entire range becomes $1$. This process is referred to as normalization.\nIn quantum mechanics, it is essential to normalize the wave function. For instance, considering a wave function $\\psi$ whose integral is as follows.\n$$ \\begin{equation} \\int_{-\\infty}^{\\infty} |\\psi|^2dx=9 \\end{equation} $$\nThen, it is not handled as it is. If both sides are divided by $9$, it becomes ${\\displaystyle \\int_{-\\infty}^{\\infty} }|\\frac{1}{3}\\psi|^2dx=1$, making it interpretable in a probabilistic manner. Here, normalizing $\\psi$ results in $\\frac{1}{3}\\psi$, which is referred to as the normalized wave function. In quantum mechanics, the function handled is the normalized $\\frac{1}{3}\\psi$.\nSquare-integrable Meanwhile, it is not a problem if the integral value of the probability density of the wave function, like $(1)$, is not $1$. It can be adjusted through normalization. The issue arises when the integral value diverges. Therefore, the wave function satisfying the Schr√∂dinger Equation must meet the following equation.\n$$ \\int_{-\\infty}^{\\infty} |\\psi (x,\\ t)|^2dx \u0026lt;\\infty $$\nThe wave function meeting this condition is called a square-integrable function. A square-integrable wave function must converge to $0$ when $x \\rightarrow \\pm \\infty$. If not, it means that the area under the graph of the wave function does not converge, indicating it is not square-integrable.\n","id":945,"permalink":"https://freshrimpsushi.github.io/en/posts/945/","tags":null,"title":"Probabilistic Interpretation and Normalization of Wave Functions in Quantum Mechanics"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Description Time Series can be simply seen as a stochastic process obtained from real data. The stock index is a good example of a time series as its value changes with uncertainty over time. Time series analysis aims to understand and predict the movement of a dependent variable over time.\nThe biggest difference between time series analysis and regression analysis is that, while regression analysis assumes that the independent variables are independent from each other and have their own independence, time series analysis assumes that variables have autocorrelation. Also, regression analysis does not care about the order of data, whereas time series considers the influence of previous data on subsequent data important for the analysis.\nStocks are also a good example of autocorrelation. In the KOSDAQ market, whether the face value of a stock will rise or fall cannot be known, but if it is 10,000 won per share today, it could go up to at most 13,000 won or drop to 7,000 won tomorrow. Of course, this is because current laws do not allow for fluctuations of more than 30%p, but the face value of tomorrow $Y_{t+1}$ is definitely dependent on the face value of today $y_{t} = 10000$. Thus, even though it fluctuates randomly, the goal of time series analysis is to catch changes that are somewhat correlated with the current data. [ NOTE: The face value of tomorrow is represented as a capital letter because it is still unknown and thus considered a random variable, while the face value of today is represented as a lowercase letter because it is already known data. ]\n","id":900,"permalink":"https://freshrimpsushi.github.io/en/posts/900/","tags":null,"title":"Time Series Analysis"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Definition1 The electric current is defined as the amount of charge that passes through a given point in a conductor per unit of time, denoted by $I$. Thus, a negative charge moving to the left and a positive charge moving to the right constitute an electric current of the same sign.\nThe amount of Coulomb passing per unit of time is called ampere.\n$$ 1 [A] = 1 [C/s] $$\nExplanation Ampere was French, and the actual pronunciation is closer to [am-pear]. Hence, though it is called the Amp√®re\u0026rsquo;s law, when referring to units, it must be referred to as ampere.\nThe notation $I$ originates from the first letter of the intensity of current.\nLine Current Density The above figure shows a charge with a line charge density of $\\lambda$ moving along a conductor at speed $\\mathbf{v}$. Since distance = speed x time, the unit length is $v\\Delta t$. The amount of charge within a unit length is obtained by multiplying the unit length by the line charge density.\n$$ \\Delta q=\\lambda v \\Delta t $$\nThe electric current is the amount of charge that passes through in a unit of time, so the amount of charge passing through point $P$ during $\\Delta t$ is:\n$$ I=\\dfrac{\\Delta q}{\\Delta t}=\\dfrac{\\lambda v \\Delta t}{\\Delta t}=\\lambda v $$\nThe electric current is a vector, so if we include its direction, it is represented as follows:\n$$ \\mathbf{I}=\\lambda \\mathbf{v} $$\nWhen electric current flows along a conductor, its direction is clear (parallel to the conductor) and need not be specifically mentioned. However, when dealing with electric currents flowing on surfaces or through volumes, the direction must be clearly stated. The Lorentz force experienced by a conductor through which electric current flows due to an external magnetic field $\\mathbf{B}$ is:\n$$ \\mathbf{F}_{\\text{mag}}=\\int (\\mathbf{v} \\times \\mathbf{B} ) dq=\\int (\\mathbf{v} \\times \\mathbf{B} ) \\lambda dl=\\int (\\mathbf{I} \\times \\mathbf{B}) dl $$\nHere, since the directions of $\\mathbf{I}$ and $d\\mathbf{l}$ are the same:\n$$ \\mathbf{F}_{\\text{mag}} = \\int I (d\\mathbf{l} \\times \\mathbf{B}) $$\nUsually, since the current flowing through a conductor is constant, it can be taken outside the integral:\n$$ \\mathbf{F}_{\\text{mag}}=I \\int (d\\mathbf{l} \\times \\mathbf{B}) $$\nSurface Current Density The current flowing on a surface is explained as surface current density $\\mathbf{K}$. It is the current that flows across a unit width of length and is expressed as follows mathematically:\n$$ \\mathbf{K}=\\dfrac{d \\mathbf{l}} {dl_\\perp} $$\nTo put this concept into easier terms, since $\\mathbf{I}=\\dfrac{d\\mathbf{q} }{dt}$:\n$$ \\dfrac{d \\mathbf{I} }{dl_{\\perp}}=\\dfrac{d^2 \\mathbf{q}}{dl_{\\perp} dt} $$\nTherefore, the surface current density is the amount of charge that passes per unit time, per unit width of length. When the surface charge density is $\\sigma$ and the velocity of charge is $\\mathbf{v}$, the surface current density is:\n$$ \\mathbf{K}=\\sigma \\mathbf{v} $$\nThe magnetic force experienced by a surface current due to an external magnetic field is:\n$$ \\mathbf{F}_{\\text{mag}}=\\int(\\mathbf{v}\\times \\mathbf{B})\\sigma da=\\int (\\mathbf{K} \\times \\mathbf{B})da $$\nThis is the formula for the current seen earlier with the current $\\mathbf{I}$ replaced with surface current density $\\mathbf{K}$.\nVolume Current Density Likewise, when current flows through a certain space, it is explained as volume current density $\\mathbf{J}$. It is the current that flows per unit area and is mathematically expressed as:\n$$ \\mathbf{J}=\\dfrac {d\\mathbf{I}} {da_{\\perp}} $$\nTherefore, conversely, the current $I$ passing through surface $\\mathcal{S}$ can generally be represented as follows:\n$$ I = \\int_{\\mathcal{S}}J da_{\\perp} = \\int_{\\mathcal{S}}\\mathbf{J}\\cdot d\\mathbf{a} $$\nThen, according to the Divergence Theorem, the total amount of charge that exits volume $\\mathcal{V}$ is as follows:\n$$ \\oint_{\\mathcal{S}}\\mathbf{J}\\cdot d\\mathbf{a} = \\int_{\\mathcal{V}} (\\nabla \\cdot \\mathbf{J}) d \\tau $$\nSimilarly, since $\\dfrac {d\\mathbf{I}} {da_{\\perp}}=\\dfrac{d^2 \\mathbf{q} } {da_{\\perp}{dt}}$, the volume current density is the amount of charge that passes per unit of time, per unit area. If the volume charge density is $\\rho$ and the speed of the charge is $\\mathbf{v}$, the volume current density is:\n$$ \\mathbf{J}=\\rho \\mathbf{v} $$\nThe magnetic force experienced by a volume current is:\n$$ \\mathbf{F}_{\\text{mag}}=\\int (\\mathbf{v} \\times \\mathbf{B} )\\rho d\\tau = \\int (\\mathbf{J} \\times \\mathbf{B} ) d\\tau $$\nDavid J. Griffiths, Introduction to Electrodynamics (4th Edition, 2014), p234-241\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":898,"permalink":"https://freshrimpsushi.github.io/en/posts/898/","tags":null,"title":"Current and Current Density"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Explanation1 In electrostatics, the electric field is easily handled by using a property called $\\nabla \\times \\mathbf{E} = \\mathbf{0}$ to define the scalar potential $V$. Similarly, in magnetostatics, the vector potential $A$ is defined and used by utilizing a property called $\\nabla \\cdot \\mathbf{B} = 0$. Let\u0026rsquo;s say the magnetic field $\\mathbf{B}$ is the curl of some vector $\\mathbf{A}$.\n$$ \\mathbf{B}=\\nabla \\times \\mathbf{A} $$\nSince the divergence of a curl is 0, naturally, the following equation holds.\n$$ \\nabla \\cdot \\mathbf{B} = \\nabla \\cdot (\\nabla \\times \\mathbf{A}) = 0 $$\nTherefore, the vector $\\mathbf{A}$ which becomes the magnetic field when the curl is taken is defined as the vector potential of the magnetic field. The key in dealing with the scalar potential of the electric field was that the value of the potential itself was not important, but the difference of potentials was. Therefore, a difference of constant $K$ did not affect handling the electric field. Similarly, the vector potential $\\mathbf{A}$ can be chosen as a vector that makes its divergence $0$. It doesn\u0026rsquo;t matter if the vector\u0026rsquo;s divergence is not $0$, but the equation becomes cleanest when $\\nabla \\cdot \\mathbf{A}=0$ is satisfied. Substituting the vector potential $\\mathbf{A}$ into the differential form of Amp√®re\u0026rsquo;s law, we obtain the following equation.\n$$ \\nabla \\times \\mathbf{B}=\\nabla \\times (\\nabla \\times \\mathbf{A} ) = \\nabla(\\nabla \\cdot \\mathbf{A})-\\nabla ^2 \\mathbf{A} = \\mu_{0} \\mathbf{J} $$\n(Refer to) If it\u0026rsquo;s $\\nabla \\cdot \\mathbf{A}=0$, Amp√®re\u0026rsquo;s law neatly becomes as follows.\n$$ \\begin{equation} \\nabla ^2 \\mathbf{A}=-\\mu_{0} \\mathbf{J} \\label{1} \\end{equation} $$\nLet\u0026rsquo;s see why we can freely set $\\mathbf{A}$ as a function whose divergence is $0$. Let\u0026rsquo;s denote a potential whose divergence is not $0$ as $\\mathbf{A}_{0}$. Call $\\mathbf{A}$, which is obtained by adding the gradient of some arbitrary scalar $\\lambda$ to it.\n$$ \\mathbf{A}=\\mathbf{A}_{0} + \\nabla \\lambda $$\nTaking the curl on both sides, since the curl of a gradient is $\\mathbf{0}$,\n$$ \\nabla \\times \\mathbf{A} = \\nabla \\times \\mathbf{A}_{0} + \\nabla \\times (\\nabla\\lambda)=\\nabla \\times \\mathbf{A}_{0} $$\nThus, the curl of the two vectors $\\mathbf{A}, \\mathbf{A}_{0}$ is the same, and the following holds.\n$$ \\mathbf{B}=\\nabla \\times \\mathbf{A} = \\nabla \\times \\mathbf{A}_{0} $$\nTherefore, adding the gradient of any arbitrary scalar to the vector potential does not affect the representation of the magnetic field. To determine the condition for scalar $\\lambda$, taking the divergence of the two vector potentials,\n$$ \\nabla \\cdot \\mathbf{A} = \\nabla \\cdot \\mathbf{A}_{0} + \\nabla^2 \\lambda $$\nTherefore, by choosing $\\lambda$ that satisfies $\\nabla ^2 \\lambda=-\\nabla \\cdot \\mathbf{A}_{0}$, we can make the divergence of the vector potential $\\mathbf{A}$ into $0$. If it holds that $\\nabla \\cdot \\mathbf{A}_{0}=0$ at a very far distance, the following equation is obtained.\n$$ \\lambda=\\dfrac{1}{4 \\pi}\\int \\dfrac{\\nabla \\cdot \\mathbf{A}_{0} } {\\cR} d\\tau^{\\prime} $$\nSolving $(1)$ to directly find $\\mathbf{A}$ (at a very far distance when $\\mathbf{J}=0$),\n$$ \\mathbf{A}(\\mathbf{r})=\\dfrac{\\mu_{0}}{4\\pi} \\int \\dfrac{\\mathbf{J} (\\mathbf{r}^{\\prime}) }{\\cR} d\\tau^{\\prime} $$\nAs the equation suggests, if the direction of the current is constant, the direction of the vector potential and the current are the same. The vector potentials for line currents and surface currents are\n$$ \\mathbf{A}=\\dfrac{\\mu_{0}}{4\\pi} \\int \\dfrac{\\mathbf{I} } {\\cR} dl^{\\prime}=\\dfrac{\\mu_{0} I}{4\\pi} \\int \\dfrac{1}{\\cR} d\\mathbf{l}^{\\prime} $$\n$$ \\mathbf{A}=\\dfrac{\\mu_{0}}{4\\pi}\\int \\dfrac{K}{\\cR} da^{\\prime} $$\nDavid J. Griffiths, Introduction to Electrodynamics (4th Edition, 2014), p262-263\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":923,"permalink":"https://freshrimpsushi.github.io/en/posts/923/","tags":null,"title":"Magnetic Vector Potential"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Definition1 A moving charge (current) creates a magnetic field $\\mathbf{B}$ around it. The force experienced by a charge $Q$ moving at velocity $\\mathbf{v}$ in a magnetic field $\\mathbf{B}$ is given by:\n$$ \\begin{equation} \\mathbf{F}_{m}=Q(\\mathbf{v} \\times \\mathbf{B}) \\end{equation} $$\nThis force is called the magnetic force, and the above formula is known as the Lorentz force law.\nExplanation As with the definition of an electric field, when a moving charge experiences a force like $(1)$ surrounding a current, we call $\\mathbf{B}$ the magnetic field produced by the current.\nIt is said that the Lorentz force law was actually discovered by Oliver Heaviside. When there is an electric field, the general formula, including the electric force due to Coulomb\u0026rsquo;s law, is as follows:\n$$ \\mathbf{F}=Q\\left[ \\mathbf{E} + (\\mathbf{v}\\times\\mathbf{B}) \\right] $$\nThis is a fundamental axiom of electromagnetic theory and an experimental law.\nDavid J. Griffiths, Introduction to Electrodynamics (4th Edition, 2014), p227-229\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":896,"permalink":"https://freshrimpsushi.github.io/en/posts/896/","tags":null,"title":"Magnetism and the Law of Lorentz Force"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Definition1 A steady current refers to the flow of charge that continues without changing in amount or direction.\nDescription Since the current does not change over time, the magnetic field created by the steady current also does not change over time. The \u0026lsquo;direction of progress\u0026rsquo; mentioned here is a different concept from the direction of a vector we commonly think of. It means that as long as the flow continues in one direction, even if it flows through a curved conductor, the direction of progress does not change. Let\u0026rsquo;s denote the volume charge density as $\\rho$, and the volume current density as $\\mathbf{J}$. If the current generated by this is a steady current, then by definition, the following equation holds.\n$$ \\dfrac{\\partial \\rho}{\\partial t} = 0 \\quad \\text{and} \\quad \\dfrac{\\partial \\mathbf{J}}{\\partial t}=0 $$\nTherefore, according to the continuity equation, the following equation applies.\n$$ \\nabla \\cdot \\mathbf{J} = 0 $$\nOf course, steady current is theoretical, and it does not actually exist, so the discussion on steady current is entirely theoretical. However, in many areas of physics, such theory closely approximates reality.\nFormula The magnetic field created by a steady current can be calculated with the following formula, which is called the Biot-Savart Law.\n$$ \\mathbf{B}(\\mathbf{r})=\\dfrac{ \\mu_{0}}{4\\pi}\\int \\dfrac{\\mathbf{I} \\times \\crH}{\\cR ^2}dl^{\\prime}=\\dfrac{ \\mu_{0}}{4\\pi} I \\int \\dfrac{d \\mathbf{l}^{\\prime} \\times \\crH}{\\cR ^2} $$\nHere, $\\bcR$ refers to the displacement vector, and the constant $\\mu$ is the permeability. $\\mu_{0}$ is the permeability in a vacuum. The Biot-Savart law for surface and volume currents is represented using surface current density and volume current density.\n$$ \\begin{align*} \\mathbf{B}(\\mathbf{r}) =\u0026amp;\\ \\dfrac{ \\mu_{0}}{4\\pi}\\int \\dfrac{\\mathbf{K}(\\mathbf{r}^{\\prime}) \\times \\crH}{\\cR ^2}da^{\\prime} \\\\ \\mathbf{B}(\\mathbf{r}) =\u0026amp;\\ \\dfrac{ \\mu_{0}}{4\\pi}\\int \\dfrac{\\mathbf{J}(\\mathbf{r}^{\\prime}) \\times \\crH}{\\cR ^2}d\\tau^{\\prime} \\end{align*} $$\nExample Calculate the magnetic field at a point located at a perpendicular distance $s$ from a wire carrying a steady current of $I$.\n$$ \\begin{align*} |d\\mathbf{l}^{\\prime} \\times \\crH | =\u0026amp;\\ |d\\mathbf{l}^{\\prime}||\\crH|\\sin \\alpha \\\\ =\u0026amp;\\ dl^{\\prime} \\sin \\alpha \\\\ =\u0026amp;\\ dl^{\\prime} \\sin \\left( \\theta + \\frac{\\pi}{2} \\right) \\\\ =\u0026amp;\\ dl^{\\prime} \\cos \\theta \\end{align*} $$\nSince $l^{\\prime}=s\\tan \\theta$,\n$$ dl^{\\prime}=\\dfrac{s}{\\cos ^2 \\theta}d\\theta $$\nSince $s=\\cR \\cos \\theta$,\n$$ \\dfrac{1}{\\cR ^2}=\\dfrac{\\cos ^2 \\theta}{s^2} $$\nSubstituting into the Biot-Savart Law, and calculating the magnitude of $\\mathbf{B}(\\mathbf{r})$,\n$$ \\begin{align*} B =\u0026amp;\\ \\left| \\dfrac{ \\mu_{0}}{4\\pi} I \\int \\dfrac{d \\mathbf{l}^{\\prime} \\times \\crH}{\\cR ^2} \\right| \\\\ =\u0026amp;\\ \\dfrac{ \\mu_{0}}{4\\pi} I \\int \\dfrac{ \\left| d \\mathbf{l}^{\\prime} \\times \\crH \\right| }{\\cR ^2} \\\\ =\u0026amp;\\ \\dfrac{\\mu_{0} I}{4\\pi} \\int \\left( \\dfrac{\\cos ^2 \\theta}{s^2} \\right) \\left( \\dfrac{s}{\\cos^2\\theta} \\right) \\cos \\theta d\\theta \\\\ =\u0026amp;\\ \\dfrac{\\mu_{0} I}{4\\pi s} \\int \\cos \\theta d\\theta \\end{align*} $$ If it had been a case for a segment of wire as shown in diagram$(2)$, then the integration limits would be from $\\theta _{1}$ to $\\theta_2$. Since the example is regarding an infinitely long wire, as in diagram $(2)$, situations are like $\\theta_{1}=-\\dfrac{\\pi}{2}$, $\\theta_2=\\dfrac{\\pi}{2}$. Therefore, the magnitude of the magnetic field is $$ \\begin{align*} B =\u0026amp;\\ \\dfrac{\\mu_{0} I}{4\\pi s} \\int_{-\\frac{\\pi}{2} }^{\\frac{\\pi}{2}} \\cos \\theta d\\theta \\\\ =\u0026amp;\\ \\dfrac{\\mu_{0} I}{4\\pi s} \\left(\\sin {\\textstyle \\frac{\\pi}{2}}- \\sin {\\textstyle \\frac{-\\pi}{2}} \\right) \\\\ =\u0026amp;\\ \\dfrac{\\mu_{0} I}{2\\pi s} \\end{align*} $$\nIts direction is out of the paper according to the right-hand rule. If the right-hand side is set as $\\hat{\\mathbf{z}}$ in the cylindrical coordinate system,\n$$ \\mathbf{B}=\\dfrac{\\mu_{0} I}{2\\pi s} \\hat{\\boldsymbol{\\phi}} $$\n‚ñ†\nDavid J. Griffiths, Introduction to Electrodynamics (4th Edition, 2014), p241-245\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":899,"permalink":"https://freshrimpsushi.github.io/en/posts/899/","tags":null,"title":"Steady Current and Biot-Savart Law"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Theorem1 Let\u0026rsquo;s call something a vector and an area in 3D space as $\\mathbf{v}, \\mathcal{S}$, respectively. The area vector of $\\mathcal{S}$ is denoted as $d\\mathbf{a}$, the border of $\\mathcal{S}$ as $\\mathcal{P}$, and the path moving along $\\mathcal{P}$ as $d\\mathbf{l}$. Then, the following equation holds:\n$$ \\int_{\\mathcal{S}} (\\nabla \\times \\mathbf{v} )\\cdot d\\mathbf{a} = \\oint_{\\mathcal{P}} \\mathbf{v} \\cdot d\\mathbf{l} $$\nThis is called Stokes\u0026rsquo; theorem or the fundamental theorem for curl.\nIncidentally, outside of theorem names, as used in the shrimp sushi restaurant, the word \u0026lsquo;rotation\u0026rsquo; alone is used as \u0026lsquo;curl\u0026rsquo;.\nExplanation The theorem can be explained as follows:\nThe total amount of rotation of vector $\\mathbf{v}$ within a certain region $\\mathcal{S}$ (left side) is the same as the sum of the values of vector $\\mathbf{v}$ along the border $\\mathcal{P}$ of that region (right side). For those studying physics, understanding the meaning behind Stokes\u0026rsquo; theorem is far more important than understanding its proof.\nSince $d\\mathbf{l}$ is a closed path, it doesn\u0026rsquo;t matter from which point or in which direction we start, the outcome remains unaffected. Thus, the direction of the area vector $d\\mathbf{a}$ is determined by the right-hand rule.\nWithout looking at the picture, it might be hard to understand that the total amount of rotation within the area and the total amount along the path are the same. Let\u0026rsquo;s look at the picture below.\nThe integral value is determined solely by the boundary $\\mathcal{P}$ of $\\mathcal{S}$ Since Stokes\u0026rsquo; theorem is an equation, regardless of what shape $\\mathcal{S}$ is in, if its boundary is the same curve $\\mathcal{P}$, the integral value always remains the same. Therefore, what the surface looks like is irrelevant. As shown in the picture below, even if there are various surfaces, if their edges are the same, then $\\int (\\nabla \\times \\mathbf{v})\\cdot d\\mathbf{a}$ has the same value. Therefore, the integral value is determined by the boundary of $\\mathcal{S}$.\nThe integral value for a closed surface $\\mathcal{S}$ is always $0$ In the case of a closed surface, since the length of the border is $0$, the length of the path is $0$, and the right-side closed path integral is always $0$. Hence, the following result is obtained:\n$$ \\int_{\\mathcal{S}} (\\nabla \\times \\mathbf{v} )\\cdot d\\mathbf{a} = 0 = \\oint_{\\mathcal{P}} \\mathbf{v} \\cdot d\\mathbf{l} $$\nIf it\u0026rsquo;s hard to understand that the length of the border of a closed surface is $0$, look at the picture below.\nDavid J. Griffiths, Í∏∞Ï¥àÏ†ÑÏûêÍ∏∞Ìïô(Introduction to Electrodynamics, ÍπÄÏßÑÏäπ Ïó≠)(4th Edition). 2014, p37-38\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":937,"permalink":"https://freshrimpsushi.github.io/en/posts/937/","tags":null,"title":"Stokes' Theorem"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Multiple Expansion When a distribution of charges is viewed from sufficiently far away, it appears almost as though it were a point charge. In other words, if the total charge of the charge distribution is $Q$, it would feel as if there\u0026rsquo;s a single point charge with charge $Q$ when viewed from afar. This means that the potential can be approximated as $\\dfrac{1}{4\\pi\\epsilon_{0}} \\dfrac{Q}{r}$.\nBut if the total charge is $0$, then the question arises as to whether it\u0026rsquo;s correct to approximate the potential as $0$. Multiple expansion is the answer to how to express the potential as an approximate formula when the total charge is $0$. Expressing the potential $V(\\mathbf{r})$ as a series with respect to $\\dfrac{1}{r^{n}}$ is called a multipole expansion.\nThe potential at position $\\mathbf{r}$ is as follows.\n$$ \\begin{equation} V(\\mathbf{r}) = \\dfrac{1}{4\\pi\\epsilon_{0}} \\int \\dfrac{1}{\\cR}\\rho (\\mathbf{r}^{\\prime})d\\tau^{\\prime} \\label{1} \\end{equation} $$\nWhere $\\bcR = \\mathbf{r} - \\mathbf{r}^{\\prime} (\\cR = \\left| \\bcR \\right|)$ is the separation vector.\nBy using the law of cosines to find the magnitude of $\\cR$,\n$$ \\begin{align*} \\cR ^2 =\u0026amp;\\ r^2+(r^{\\prime})^2-2rr^{\\prime}\\cos\\alpha \\\\ =\u0026amp;\\ r^2\\left[1+\\left(\\dfrac{r^{\\prime}}{r}\\right)^2-2\\dfrac{r^{\\prime}}{r}\\cos\\alpha\\right] \\\\ =\u0026amp;\\ r^2\\left[1+\\dfrac{r^{\\prime}}{r}\\left( \\dfrac{r^{\\prime}}{r}-2\\cos\\alpha\\right)\\right] \\end{align*} $$\nFor convenience, let\u0026rsquo;s completely substitute the second term in the angle brackets with $\\epsilon=\\dfrac{r^{\\prime}}{r}\\left( \\dfrac{r^{\\prime}}{r}-2\\cos\\alpha \\right)$. Then the following holds true.\n$$ \\cR=r\\sqrt{1+\\epsilon} \\implies \\dfrac{1}{\\cR} = \\dfrac{1}{r}(1+\\epsilon)^{-1/2} $$\nIf $\\mathbf{r}$ is a place very far from the charge distribution, then $\\dfrac{r^{\\prime}}{r}$ becomes a very small value and $\\epsilon \\ll 1$ is valid.\nBinomial Series\nIf $|x| \u0026lt; 1$, then,\n$$ (1 + x )^{\\alpha} = 1 + \\alpha x + \\dfrac{\\alpha (\\alpha-1)}{2!}x^{2} + \\dfrac{\\alpha (\\alpha-1)(\\alpha-2)}{3!}x^{3} + \\cdots $$\nTherefore, $(1+\\epsilon)^{-1/2}$ can be solved as a binomial series.\n$$ \\dfrac{1}{\\cR} = \\dfrac{1}{r}(1+\\epsilon)^{-1/2} = \\dfrac{1}{r}\\left( 1- \\dfrac{1}{2}\\epsilon+\\dfrac{3}{8}\\epsilon ^2 -\\dfrac{5}{16}\\epsilon ^3 +\\cdots \\right) $$\nSubstituting $\\epsilon$ back into its original form,\n$$ \\dfrac{1}{\\cR}=\\dfrac{1}{r}\\left[ 1- \\dfrac{1}{2}\\dfrac{r^{\\prime}}{r}\\left( \\dfrac{r^{\\prime}}{r}-2\\cos\\alpha \\right) +\\dfrac{3}{8}\\left( \\dfrac{r^{\\prime}}{r} \\right)^2 \\left( \\dfrac{r^{\\prime}}{r}-2\\cos\\alpha \\right) ^2 -\\dfrac{5}{16}\\left( \\dfrac{r^{\\prime}}{r}\\right)^3 \\left( \\dfrac{r^{\\prime}}{r}-2\\cos\\alpha \\right) ^3 +\\cdots \\right] $$\nOrganizing according to each order of $\\dfrac{r^{\\prime}}{r}$ gives the following. For detailed process, see the Appendix.\n$$ \\dfrac{1}{\\cR}=\\dfrac{1}{r}\\left[ 1+\\left(\\dfrac{r^{\\prime}}{r}\\right)\\left( \\cos\\alpha \\right) +\\left( \\dfrac{r^{\\prime}}{r} \\right)^2 \\left( \\dfrac{3\\cos^2\\alpha -1 }{2}\\right) +\\left( \\dfrac{r^{\\prime}}{r}\\right)^3 \\left( \\dfrac{5\\cos^2\\alpha-3\\cos\\alpha}{2} \\right) +\\cdots \\right] $$\nHere, each bracket can be expressed as the series in the form of $\\sum \\limits_{n=0}^{\\infty} a_{n}\\left( \\dfrac{r^{\\prime}}{r}\\right)^n$. Each coefficient $a_{n}$ is as follows.\n$$ \\begin{align*} a_{0} =\u0026amp;\\ 1 \\\\ a_{1} =\u0026amp;\\ \\cos\\alpha \\\\ a_{2} =\u0026amp;\\ \\dfrac{3\\cos^2\\alpha-1}{2} \\\\ a_{3} =\u0026amp;\\ \\left( \\dfrac{5\\cos^2\\alpha-3\\cos\\alpha}{2} \\right) \\\\ \\vdots \u0026amp; \\end{align*} $$\nThis is the same as the Legendre polynomial $P_{n}(\\cos \\alpha)$ for $\\cos\\alpha$. Therefore, summarizing,\n$$ \\dfrac{1}{\\cR}=\\dfrac{1}{r}\\sum\\limits_{n=0}^{\\infty}\\left( \\dfrac{r^{\\prime}}{r}\\right)^n P_{n}(\\cos\\alpha) $$\nSubstituting this into the potential formula $\\eqref{1}$ and bringing out $r$, which is independent of the integration, gives us the following.\n$$ V(\\mathbf{r})=\\dfrac{1}{4\\pi\\epsilon_{0}}\\sum \\limits_{n=0}^{\\infty} \\dfrac{1}{r^{n+1}} \\int (r^{\\prime})^nP_{n}(\\cos\\alpha) \\rho (\\mathbf{r}^{\\prime}) d\\tau^{\\prime} $$\nExpanding this series again results in\n$$ \\begin{align*} V(\\mathbf{r}) = \\dfrac{1}{4\\pi\\epsilon_{0}} \\bigg[ \u0026amp;\\dfrac{1}{r} \\int r^{\\prime}\\cos\\alpha \\rho (\\mathbf{r}^{\\prime})d\\tau^{\\prime} \\\\ \u0026amp;+ \\dfrac{1}{r^2}\\int r^{\\prime}\\cos\\alpha \\rho (\\mathbf{r}^{\\prime})d\\tau^{\\prime} + \\dfrac{1}{r^3}\\int(r^{\\prime})^2\\dfrac{3\\cos^2\\alpha -1 }{2}\\rho (\\mathbf{r}^{\\prime})d\\tau^{\\prime} + \\cdots \\bigg] \\end{align*} $$\nThe first term is the potential created by a monopole, the second term is by a dipole, and the third term is by a quadrupole. The $n$th term is related to the $2^{n-1}$-polar term.\nDipole Moment and Dipole Term Since the multipole expansion is a series with respect to the reciprocal of $r$, usually, when $r$ is large, the monopole term is the largest. mono refers to monopole.\n$$ V_{\\text{mono}}(\\mathbf{r}) = \\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{Q}{r} $$\nIf the total charge of the gathered charges is $0$, then the monopole term is $0$. Otherwise, $+$ and $-$ can pair up to make $0$, but since there can only be one monopole term, it isn\u0026rsquo;t possible. Hence, if the dipole term isn\u0026rsquo;t $0$, then the dipole term is the largest. dip refers to dipole.\n$$ V_{\\text{dip}}(\\mathbf{r})=\\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{1}{r^2}\\int r^{\\prime} \\cos \\alpha \\rho (\\mathbf{r}^{\\prime})d\\tau^{\\prime} $$\nHere, since $\\hat{\\mathbf{r}}\\cdot\\mathbf{r}^{\\prime}=r^{\\prime}\\cos\\alpha$,\n$$ V_{\\text{dip}}(\\mathbf{r})=\\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{1}{r^2}\\hat{\\mathbf{r}}\\cdot\\int \\mathbf{r}^{\\prime} \\rho (\\mathbf{r}^{\\prime})d\\tau^{\\prime} $$\nThis integral value is independent of $\\mathbf{r}$ and is specifically named the dipole moment of the charge distribution, denoted as $\\mathbf{p}$.\n$$ \\mathbf{p}=\\int\\mathbf{r}^{\\prime}\\rho (\\mathbf{r}^{\\prime})d\\tau^{\\prime} $$\nThe dipole moment allows for a simple representation of the dipole\u0026rsquo;s potential.\n$$ V_{\\text{dip}}(\\mathbf{r})=\\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{\\mathbf{p}\\cdot\\hat{\\mathbf{r}} } {r^2} $$\nAppendix $$ 1- \\dfrac{1}{2}\\dfrac{r^{\\prime}}{r}\\left( \\dfrac{r^{\\prime}}{r}-2\\cos\\alpha \\right) +\\dfrac{3}{8}\\left( \\dfrac{r^{\\prime}}{r} \\right)^{2} \\left( \\dfrac{r^{\\prime}}{r}-2\\cos\\alpha \\right)^2 -\\dfrac{5}{16}\\left( \\dfrac{r^{\\prime}}{r}\\right)^3 \\left( \\dfrac{r^{\\prime}}{r}-2\\cos\\alpha \\right)^3 +\\cdots $$\nExpanding the square and cubic terms from the above equation yields\n$$ 1- \\dfrac{1}{2}\\dfrac{r^{\\prime}}{r}\\left( \\dfrac{r^{\\prime}}{r}-2\\cos\\alpha \\right) +\\dfrac{3}{8}\\left( \\dfrac{r^{\\prime}}{r} \\right)^2 \\left[ \\left( \\dfrac{r^{\\prime}}{r}\\right)^2-\\dfrac{4r^{\\prime}\\cos\\alpha}{r}+4\\cos^2\\alpha \\right] $$\n$$ -\\dfrac{5}{16}\\left( \\dfrac{r^{\\prime}}{r}\\right)^3 \\left[ \\left( \\dfrac{r^{\\prime}}{r}\\right)^3 -3\\left(\\dfrac{r^{\\prime}}{r}\\right)^22\\cos\\alpha + 3\\left( \\dfrac{r^{\\prime}}{r}\\right)4\\cos^2\\alpha-8\\cos^3\\alpha \\right] +\\cdots $$\nNow, organizing according to the order of $\\dfrac{r^{\\prime}}{r}$ gives\n$$ 1+\\left(\\dfrac{r^{\\prime}}{r}\\right)\\cos\\alpha +\\left(\\dfrac{r^{\\prime}}{r}\\right)^2\\left(-\\dfrac{1}{2} +\\dfrac{3}{2}\\cos^2\\alpha \\right)+\\left( \\dfrac{r^{\\prime}}{r} \\right)^3 \\left( -\\dfrac{3}{2}\\cos\\alpha +\\dfrac{5}{2}\\cos^3\\alpha \\right) + \\cdots $$\nUpon organizing this gives\n$$ 1+\\left(\\dfrac{r^{\\prime}}{r}\\right)\\left( \\cos\\alpha \\right) +\\left( \\dfrac{r^{\\prime}}{r} \\right)^2 \\left( \\dfrac{3\\cos^2\\alpha -1 }{2}\\right) +\\left( \\dfrac{r^{\\prime}}{r}\\right)^3 \\left( \\dfrac{5\\cos^2\\alpha-3\\cos\\alpha}{2} \\right) +\\cdots $$\n","id":936,"permalink":"https://freshrimpsushi.github.io/en/posts/936/","tags":null,"title":"Multipole Expansion of Potential and Dipole Moments"},{"categories":"Ìë∏Î¶¨ÏóêÌï¥ÏÑù","contents":"Definition The series for $2L$-periodic function $f$ is defined as the Fourier series of $f$ as follows:\n$$ \\begin{align*} \\lim \\limits_{N \\rightarrow \\infty} S^{f}_{N}(t) \u0026amp;= \\lim \\limits_{N \\to \\infty}\\left[ \\dfrac{a_{0}}{2}+\\sum \\limits_{n=1}^{N} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L} + b_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right] \\\\ \u0026amp;= \\dfrac{a_{0}}{2}+\\sum \\limits_{n=1}^{\\infty} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L} + b_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\end{align*} $$\nHere, each coefficient $a_{0}, a_{n}, b_{n}$ is called the Fourier coefficient, and its value is as follows:\n$$ \\begin{align*} \\\\ a_{0} \u0026amp;=\\dfrac{1}{L}\\int_{-L}^{L}f(t)dt \\\\ a_{n} \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{n\\pi t}{L} dt \\\\ b_{n} \u0026amp;=\\dfrac{1}{L}\\int_{-L}^{L}f(t)\\sin \\dfrac{n\\pi t}{L}dt \\end{align*} $$\nDescription The Fourier series represents any function as a series expansion of trigonometric functions, famously developed by the French mathematician Joseph Fourier for solving heat equations. The term \u0026ldquo;any function\u0026rdquo; is used because if there is a function defined on a certain interval $(a,b)$, it can be replicated (Ctrl+C, Ctrl+V) to produce a $(b-a)$-periodic function.\nThe core principle is to express it as a linear combination of orthogonal trigonometric functions, analogous to decomposing $(4,-1,7)$ as follows in three-dimensional vectors:\n$$ (4,-1,7) = a_{1}\\hat{\\mathbf{e}}_{1} + a_{2}\\hat{\\mathbf{e}}_{1} + a_{3}\\hat{\\mathbf{e}}_{1} $$\nIndeed, the Fourier series of $f$ not only has minimal error with $f$ but also converges pointwise under well-defined conditions to $f$.\n$$ f(t) = \\dfrac{a_{0}}{2}+\\sum \\limits_{n=1}^{\\infty} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L}t + b_{n}\\sin\\dfrac{n\\pi t}{L} \\right) $$\nDerivation Regression Analysis1 Part 1\nThe goal is to express the function $f(t)$ as a linear combination of $1, \\cos \\dfrac{\\pi t}{L}, \\cos\\dfrac{2\\pi t}{L}, \\cdots, \\sin \\dfrac{\\pi t}{L}, \\sin \\dfrac{2\\pi t}{L}, \\cdots $s. Thus, assuming $S^{f}_{N}(t)=\\dfrac{1}{2}{\\alpha_{0}}+\\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right)$, $f(t)$ can be represented as follows:\n$$ f(t)=S^{f}_{N}(t)+e_{N}(t) $$\n$e_{N}(t)$ is the difference between $f(t)$ and the approximation $S_{N}^{f} (t)$. The smallest difference $S_{N}^{f}(t)$ leads to the closest series expansion to $f(t)$. Let\u0026rsquo;s define $e_{N}$ as the mean square error2.\n$$ e_{N}=\\dfrac{1}{2L}\\int_{-L}^{L} [e_{N}(t) ]^{2}dt=\\dfrac{1}{2L}\\int_{-L}^{L} \\left[ f(t)-S^{f}_{N} (t) \\right]^{2} dt $$\nPart 2\n$$ \\begin{align*} e_{N} \u0026amp;= \\dfrac{1}{2L}\\int_{-L}^{L} \\left[ f(t)-S^{f}_{N}(t) \\right]^{2} dt \\\\ \u0026amp;= \\dfrac{1}{2L}\\int_{-L}^{L} \\left[ f(t)-\\dfrac{1}{2}{\\alpha_{0}}-\\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]^{2} dt \\end{align*} $$\nLet the coefficients that minimize the mean square error $e_{N}$ be $\\alpha_{0},\\ \\alpha_{n},\\ \\beta_{n}$, $a_{0}$, $a_{n}$, respectively. The conditions that minimize $e_{N}$ are called the normal equations.\n$$ \\dfrac{\\partial e_{N}}{\\partial \\alpha_{0}}=0,\\ \\ \\dfrac{\\partial e_{N}}{\\partial \\alpha_{n}}=0,\\ \\ \\dfrac{\\partial e_{N}}{\\partial \\beta_{n}}=0\\quad (m=1,\\ 2,\\ \\cdots,\\ N) $$\nThen, $a_{0}$, $a_{n}$, $b_{n}$ can be calculated as follows:\nPart 2.1 $a_{0}$\n$$ \\begin{align*} \\dfrac{\\partial e_{N}}{\\partial \\alpha_{0}} \u0026amp;= \\dfrac{1}{2L}\\int_{-L}^{L} \\dfrac{\\partial}{\\partial \\alpha_{0}} \\left[ f(t)-\\dfrac{1}{2} {\\alpha_{0}}-\\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]^{2} dt \\\\ \u0026amp;= 2\\cdot \\dfrac{-1}{2} \\cdot \\dfrac{1}{2L} \\int_{-L}^{L} \\left[ f(t)-\\dfrac{1}{2}{\\alpha_{0}}-\\sum \\limits_{n=1}^{N} \\left( \\alpha_ {N} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac {n\\pi t}{L} \\right) \\right] dt \\\\ \u0026amp;= \\dfrac{-1}{2L}\\int_{-L}^{L}f(t) dt + \\dfrac{1}{2L}\\int_{-L}^{L}\\dfrac{1}{2}\\alpha_{0} dt +\\dfrac{1}{2L}\\int_{-L}^{L} \\sum \\limits_ {n=1}^{N}\\left( \\alpha_{n}\\cos \\dfrac{n\\pi t}{L}+\\beta_{n} \\sin \\dfrac{n \\pi t}{L} \\right) dt \\\\ \u0026amp;= \\dfrac{-1}{2L}\\int_{-L}^{L}f(t) dt + \\dfrac{1}{2L}\\int_{-L}^{L}\\dfrac{1}{2}\\alpha_{0} dt \\\\ \u0026amp;= \\dfrac{-1}{2L}\\int_{-L}^{L}f(t) dt +\\dfrac{1}{2}\\alpha_{0} \\\\ \u0026amp;= 0 \\end{align*} $$\nThe fourth equality holds because the integral of a trigonometric function over one period is $0$.\n$$ a_{0} = \\dfrac{1}{L} \\int_{-L}^{L}f(t)dt $$\nPart 2.2 $a_{n}$\nChoose any $m \\in \\left\\{ 1,2,\\dots,N \\right\\}$.\n$$ \\begin{align*} \\dfrac{\\partial e_{N}}{\\partial \\alpha_{m}} \u0026amp;= \\dfrac{1}{2L}\\int_{-L}^{L} \\dfrac{\\partial}{\\partial \\alpha_{m}} \\left[ f(t)-\\dfrac{1}{2} {\\alpha_{0}}-\\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]^{2} dt \\\\ \u0026amp;= 2\\cdot \\dfrac{1}{2L} \\int_{-L}^{L} \\left( - \\cos \\dfrac{m\\pi t}{L} \\right)\\left[ f(t)-\\dfrac{1}{2}{\\alpha_{0}}-\\sum \\limits_{n=1}^ {N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L} +\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]dt \\\\ \u0026amp;= -\\dfrac{1}{L} \\int_{-L}^{L} f(t)\\cos\\dfrac{m\\pi t}{L} dt +\\dfrac{1}{L}\\int_{-L}^{L} \\dfrac{1}{2}\\alpha_{0}\\cos\\dfrac{m\\pi t}{L} dt \\\\ \u0026amp;\\quad + \\dfrac{1}{L} \\int_{-L}^{L} \\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n\\pi t}{L} + \\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\cos\\dfrac{m\\pi t}{L}dt \\\\ \u0026amp;= -\\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{m\\pi t}{L} dt + \\dfrac{1}{L}\\alpha_{m} \\int_{-L}^{L}\\cos\\dfrac{m\\pi t}{L}\\cos\\dfrac{m\\pi t} {L} dt\\\\ \u0026amp;= -\\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{m\\pi t}{L} dt + \\alpha_{m} \\\\ \u0026amp;= 0 \\end{align*} $$\nThe fourth and fifth equalities hold due to the orthogonality of trigonometric functions.\n$$ a_{n}= \\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{n\\pi t}{L} dt \\quad (n=1, 2, \\cdots, N) $$\nPart 2.3 $b_{n}$\nChoose any $m \\in \\left\\{ 1,2,\\dots,N \\right\\}$.\n$$ \\begin{align*} \\dfrac{\\partial e_{N}}{\\partial \\beta_{m}} \u0026amp;= \\dfrac{1}{2L}\\int_{-L}^{L} \\dfrac{\\partial}{\\partial \\beta_{m}} \\left[ f(t)-\\dfrac{1}{2} {\\alpha_{0}}-\\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]^{2} dt \\\\ \u0026amp;= 2\\cdot \\dfrac{1}{2L} \\int_{-L}^{L} \\left( - \\sin \\dfrac{m\\pi t}{L} \\right)\\left[ f(t)-\\dfrac{1}{2}{\\alpha_{0}}-\\sum \\limits_{n=1}^ {N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L} +\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]dt \\\\ \u0026amp;= -\\dfrac{1}{L} \\int_{-L}^{L} f(t)\\sin\\dfrac{m\\pi t}{L} dt +\\dfrac{1}{L}\\int_{-L}^{L} \\dfrac{1}{2}\\alpha_{0}\\sin\\dfrac{m\\pi t}{L} dt \\\\ \u0026amp;\\quad +\\dfrac{1}{L} \\int_{-L}^{L} \\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n\\pi t}{L} + \\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\sin\\dfrac{m\\pi t}{L}dt \\\\ \u0026amp;= -\\dfrac{1}{L}\\int_{-L}^{L} f(t)\\sin\\dfrac{m\\pi t}{L} dt + \\dfrac{1}{L}\\beta_{m} \\int_{-L}^{L}\\sin\\dfrac{m\\pi t}{L}\\sin\\dfrac{m\\pi t} {L} dt \\\\ \u0026amp;= -\\dfrac{1}{L}\\int_{-L}^{L} f(t)\\sin\\dfrac{m\\pi t}{L} dt + \\beta_{m} \\\\ \u0026amp;=0 \\end{align*} $$\nThe fourth and fifth equalities hold due to the orthogonality of trigonometric functions.\n$$ b_{n}=\\dfrac{1}{L}\\int_{-L}^{L}f(t)\\sin\\dfrac{n\\pi t}{L}dt \\quad (n=1, 2, \\cdots, N) $$\nPart 3 Using the obtained $a_{0}$, $a_{n}$, $b_{n}$ to express $f(t)$ results in the same.\n$$ \\begin{align*} f(t) \u0026amp;= S^{f}_{N}(t)+e_{N}(t) \\\\[1em] \\text{where } S^{f}_{N}(t) \u0026amp;= \\dfrac{a_{0}}{2}+\\sum \\limits_{n=1}^{N} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L} + b_{n}\\sin\\dfrac{n\\pi t} {L} \\right) \\\\ a_{0} \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L}f(t)dt \\\\ a_{n} \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{n\\pi t}{L} dt \\\\ b_{n} \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L}f(t)\\sin\\dfrac{n\\pi t}{L}dt \\end{align*} $$\nTaking the limit for $N$ yields\n$$ \\lim \\limits_{N \\rightarrow \\infty} S_{N}^{f} (t)=\\dfrac{a_{0}}{2}+\\sum \\limits_{n=1}^{\\infty} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L} + b_{n} \\sin\\dfrac{n\\pi t}{L} \\right) $$\nThe above series is called the Fourier series of $f$, and $a_{0}$, $a_{n}$, $b_{n}$ are called the Fourier coefficients of $f$.\n‚ñ†\nByung Sun Choi, Introduction to Fourier Analysis (2002), pp. 51-53\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRSS is the mean square error.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":929,"permalink":"https://freshrimpsushi.github.io/en/posts/929/","tags":null,"title":"Derivation of Fourier Series"},{"categories":"Ìë∏Î¶¨ÏóêÌï¥ÏÑù","contents":"Definition Dirichlet Kernel $D_{n}$ is defined as follows.\n$$ \\begin{equation} D_{n}(t) := \\dfrac{1}{2}+\\sum \\limits_{k=1}^{n} \\cos kt \\end{equation} $$\nExplanation The Dirichlet kernel is related to delta functions, exponential functions, etc., and appears in Fourier analysis. Here are some related theorems and their proofs.\nTheorem 1 The Dirichlet Kernel satisfies the following equation.\n$$ D_{n}(t)=\\dfrac{\\sin\\left(n+\\frac{1}{2}\\right) t}{2\\sin \\frac{1}{2}t} $$\nProof If we express the cosine function as a complex exponential form, we get the following.\n$$ \\begin{align*} D_{n}(t) =\u0026amp;\\ \\dfrac{1}{2}+\\dfrac{1}{2}\\sum \\limits_{k=1}^n( e^{ikt}+e^{-ikt} ) \\\\ =\u0026amp;\\ \\dfrac{1}{2} \\left[ 1+\\sum \\limits_{k=1}^{n} (e^{ikt}+e^{-ikt} ) \\right] \\\\ =\u0026amp;\\ \\dfrac{1}{2} \\sum \\limits_{k=-n}^{n} e^{ikt} \\end{align*} $$\nIn this case\nGeometric Series Summation Formula\n$$ \\sum_{k=1}^{n} a_{k}= \\dfrac{a (r^{n} -1) }{ r-1 } $$\nUsing this, with the first term being $a_{1}=e^{-int}$ and the common ratio $r=e^{it}$, we can arrange it as follows.\n$$ \\begin{align*} D_{n}(t) =\u0026amp;\\ \\dfrac{1}{2} \\sum \\limits_{k=-n}^{n} e^{ikt} = \\dfrac{1}{2} \\sum \\limits_{k=1}^{2n+1} e^{i(k-n-1)t} \\\\ =\u0026amp;\\ \\dfrac{1}{2} \\dfrac{ ( e^{-int} ) \\left( e^{i(2n+1)t -1} \\right) }{e^{it}-1} \\\\ =\u0026amp;\\ \\dfrac{1}{2}e^{-int}\\dfrac{e^{i(n+\\frac{1}{2}) t }-e^{-i(n+\\frac{1}{2})t} }{e^{i\\frac{1}{2}t}-e^{-i\\frac{1}{2}t }} \\dfrac{e^{i(n+\\frac{1}{2})t}} {e^{i\\frac{1}{2}t}} \\\\ =\u0026amp;\\ \\dfrac{1}{2}\\dfrac{e^{i(n+\\frac{1}{2}) t }-e^{-i(n+\\frac{1}{2})t} }{e^{i\\frac{1}{2}t}-e^{-i\\frac{1}{2}t }} \\dfrac{e^{i(n+\\frac{1}{2})t}} {e^{i(n+\\frac{1}{2})t}} \\\\ =\u0026amp;\\ \\dfrac{1}{2}\\dfrac{\\sin (n+\\frac{1}{2})t} {\\sin \\frac{1}{2} t} \\end{align*} $$\nIn the last equality, we used that $\\sin x = \\dfrac{e^{ix} - e^{-ix}}{2i}$.\n‚ñ†\nTheorem 2 Let\u0026rsquo;s say the following equation is the $2L$-periodic function $f(t)$\u0026rsquo;s Fourier series partial sum.\n$$ \\begin{equation} S_{N} ^{f} (t)=\\dfrac{1}{2}a_{0}+\\sum \\limits_{n=1}^{N} \\left( a_{n}\\cos\\dfrac{n\\pi t}{L}+b_{n}\\sin\\frac{n\\pi t}{L} \\right) \\end{equation} $$\nThen, the partial sum $S_{N}^{f}(t)$ can be represented as an integral including the Dirichlet kernel as follows.\n$$ S_{N}^{f} (t)=\\dfrac{1}{L}\\int_{-L}^{L}f(x)D_{n}\\left(\\dfrac{\\pi (x-t)}{L}\\right)dx $$\nProof After calculating the Fourier coefficients $a_{0}$, $a_{n}$, $b_{n}$, we get the following.\n$$ \\begin{align*} a_{0} \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L} f(x) dx \\\\ a_{n} \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L}f(x)\\cos\\dfrac{n\\pi x}{L} dx \\\\ b_{n} \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L}f(x)\\sin\\dfrac{n\\pi x}{L} dx \\end{align*} $$\nThen we obtain the following equation.\n$$ \\begin{align*} \u0026amp; a_{n} \\cos\\dfrac{n\\pi t}{L} + b_{n} \\sin\\dfrac{n\\pi t}{L} \\\\ =\u0026amp;\\ \\left( \\dfrac{1}{L}\\int_{-L}^{L}f(x)\\cos\\dfrac{n\\pi x}{L} dx \\right) \\cos\\dfrac{n\\pi t}{L} + \\left( \\dfrac{1}{L}\\int_{-L}^{L}f(x)\\sin\\dfrac{n\\pi x}{L} dx \\right)\\sin\\dfrac{n\\pi t}{L} \\\\ =\u0026amp;\\ \\dfrac{1}{L}\\int_{-L}^{L}f(x) \\left[ \\cos\\dfrac{n\\pi x}{L} \\cos\\dfrac{n\\pi t}{L} + \\sin\\dfrac{n\\pi x}{L} \\sin\\dfrac{n\\pi t}{L} \\right] dx \\end{align*} $$\nThen, by the sum and difference identities for trigonometric functions, we get the following equation.\n$$ a_{n}\\cos\\dfrac{n\\pi t}{L} + b_{n}\\cos\\dfrac{n\\pi t}{L} = \\dfrac{1}{L}\\int_{-L}^{L}f(x) \\left[ \\cos\\dfrac{n\\pi (x-t)}{L} \\right] dx $$\nSubstituting this into $(2)$ yields the following.\n$$ \\begin{align*} S_{N} ^{f} (t) =\u0026amp;\\ \\dfrac{1}{2}a_{0}+\\sum \\limits_{n=1}^{N} \\left( a_{n}\\cos\\dfrac{n\\pi t}{L}+b_{n}\\sin\\frac{n\\pi t}{L} \\right) \\\\ =\u0026amp;\\ \\dfrac{1}{2}\\dfrac{1}{L}\\int_{-L}^{L} f(x)dx+\\sum\\limits_{n=1}^{N}\\left( \\dfrac{1}{L}\\int_{-L}^{L}f(x) \\left[ \\cos\\dfrac{n\\pi (x-t)}{L} \\right] dx \\right) \\\\ =\u0026amp;\\ \\dfrac{1}{L} \\int_{-L}^{L} f(x) \\left[ \\dfrac{1}{2} + \\sum\\limits_{n=1}^{N} \\cos \\dfrac{n\\pi (x-t)}{L}\\right]dx \\\\ =\u0026amp;\\ \\dfrac{1}{L}\\int_{-L}^{L}f(x)D_{n}\\left(\\dfrac{\\pi (x-t)}{L}\\right)dx \\end{align*} $$\nIn the last equality, the definition of the Dirichlet kernel was used.\n‚ñ†\nTheorem 3 For any integer $n \\in \\mathbb{Z}$, the following equation holds.\n$$ \\begin{equation} \\dfrac{1}{L}\\int_{-L}^{L}D_{n}\\left( \\dfrac{\\pi (x-t)}{L} \\right)dx=1 \\end{equation} $$\nProof Let\u0026rsquo;s substitute $\\dfrac{\\pi (x-t)}{L}=y$. Then, the left side of $(3)$ is as follows.\n$$ \\begin{align*} \u0026amp;\\dfrac{1}{L}\\int_{-\\pi -\\frac{\\pi}{L}t}^{\\pi-\\frac{\\pi}{L}t} D_{n}(y) \\dfrac{L}{\\pi}dy \\\\ =\u0026amp;\\ \\dfrac{1}{\\pi}\\int_{-\\pi -\\frac{\\pi}{L}t}^{\\pi-\\frac{\\pi}{L}t} \\left( \\dfrac{1}{2} + \\sum \\limits_{n=1}^{N} \\cos ny \\right) dy \u0026amp; \\text{ by } (1) \\\\ =\u0026amp;\\ \\dfrac{1}{2\\pi}\\int_{-\\pi -\\frac{\\pi}{L}t}^{\\pi-\\frac{\\pi}{L}t} dy+ \\sum \\limits_{n=1}^{N} \\int_{-\\pi -\\frac{\\pi}{L}t}^{\\pi-\\frac{\\pi}{L}t} \\cos ny dy \\\\ =\u0026amp;\\ \\dfrac{1}{2\\pi} 2\\pi + \\sum \\limits_{n=1}^{N} \\int_{-\\pi -\\frac{\\pi}{L}t}^{\\pi-\\frac{\\pi}{L}t} \\cos ny dy \\\\ =\u0026amp;\\ 1 \\end{align*} $$\nAt this point, the reason why the second term integrates to become $0$ is because $\\cos 0y=1$ and $\\cos ny (n\\ne 0)$ are orthogonal to each other.\n‚ñ†\n","id":932,"permalink":"https://freshrimpsushi.github.io/en/posts/932/","tags":null,"title":"Dirichlet Kernel"},{"categories":"Ìï®Ïàò","contents":" üöß Ïù¥ Ìè¨Ïä§Ìä∏Îäî ÏïÑÏßÅ Ïù¥Í¥Ä ÏûëÏóÖÏù¥ ÏôÑÎ£åÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§ üöß\n**\n**Inner Product The inner product of two complex functions $f$ and $g$ defined in the interval $[a,b]$ is defined as follows. $$ \\left\\langlef, g\\right\\rangle:=\\int_{a}^b f(x) \\overline{g(x)} dx $$ Therefore, the inner product of the same two functions is $$ \\left\\langle f,f \\right\\rangle=\\int_{a}^b f(x) \\overline{f(x)} dx = \\int_{a}^b \\left| f(x) \\right| ^2 dx $$ Why the inner product of functions is defined as an integral\nOrthogonality $(\\mathrm{orthogonal})$ If two complex functions $f$ and $g$ satisfy the following equation, \u0026lsquo;$f$ and $g$ are orthogonal in the interval $[a,b]$**.\u0026rsquo; $$ \\left\\langle f,g \\right\\rangle=\\int_{a}^b f(x) \\overline{g(x)} dx=0 $$ Since the inner product of the two functions is defined as an integral, it is natural to say that they are orthogonal when the integral value is $0$.\nOrthogonal Set and Orthogonality ** If functions $\\phi_{1}$, $\\phi_2$, $\\phi_{3}$, $\\cdots$ satisfy the following equation, the set $\\left\\{\\phi_{1},\\ \\phi_2,\\ \\phi_{3}, \\cdots \\right\\}$ of these functions is called an orthogonal set and this set of functions is said to have orthogonality. $$ \\left\\langle \\phi_{m},\\phi_{n} \\right\\rangle = \\int_{a}^b \\phi_{m} (x) \\overline{ \\phi_{n}(x) } dx=0\\ \\ (m\\ne n) $$ In simple terms, an orthogonal set refers to a set of functions that are orthogonal to other functions.\nNorm of a Function $(\\mathrm{norm})$ Once the inner product is defined, the norm can be defined. The norm of the complex function $f$ is defined as follows. $$ | f | = \\left\\langle f,f\\right\\rangle^{ \\frac{1}{2} } := \\left( \\int_{a}^b \\left| f(x) \\right| ^2 dx \\right) ^{ \\frac{1}{2} } $$\nNormalization $(\\mathrm{normalization})$ For any function $f$, multiplying it by an appropriate constant so that the norm of $f$ becomes $1$ is called normalization. A function that has undergone normalization is called a normalized$(\\mathrm{normalized})$ function or normalization function. Therefore, if the normalized function of $f$ is denoted as $f_{\\mathrm{normal}}$, then $$ f_{\\mathrm{normal}}=\\frac{1}{ | f | }f $$\n**Orthonormal Set If the elements of the orthogonal set $\\left\\{ \\phi_{1}, \\phi_{2}, \\cdots \\right\\}$ satisfy the following conditions, that set is called an orthonormal set. $$ \\left\\langle \\phi_{m},\\phi_{n} \\right\\rangle = \\int_{a}^b \\phi_{m} (x) \\overline{ \\phi_{n}(x) } dx=\\delta_{mn} $$ Therefore, an orthonormal set refers to a set of orthogonal elements that have been normalized. $\\delta_{mn}$ is the Kronecker delta. The condition that the inner product with oneself equals 1 is added from the orthogonal set. For example, in the 3-dimensional orthogonal coordinate system, $\\left\\{ \\hat{\\mathbf{x}},\\ \\hat{\\mathbf{y}},\\ \\hat{\\mathbf{z}} \\right\\}$ is an orthonormal set.\n**Examples Assume $f_{0}(x)=1$, $f_{1}(x)=x$, $f_2(x)=x^2+ax+b$.\nShow that $f_{0}$ and $f_{1}$ are orthogonal in $[-1,1]$Solution $$ \\begin{align} \\left\\langle f_{0},f_{1} \\right\\rangle \u0026amp;= \\int_{-1}^{1} x dx \\\\ \u0026amp;= \\left. \\dfrac{1}{2}x^2 \\right]_{-1}^{1} = \\dfrac{1}{2}-\\dfrac{1}{2}=0 \\end{align} $$ ‚ñ†\n2. Find constants $a$ and $b$ that make $f_2$ orthogonal to both $f_{0}$ and $f_{1}$.Solution $$ \\begin{align*} \\left\\langle f_2,f_{0} \\right\\rangle \u0026amp;= \\int_{-1}^{1} (x^2+ax+b) dx \\\\ \u0026amp;= \\left. \\frac{1}{3}x^3 +\\frac{a}{2}x^2+bx \\right]_{-1}^{1} \\\\ \u0026amp;= \\left( \\frac{1}{3}+\\frac{a}{2}+b\\right) - \\left( -\\frac{1}{3}+\\frac{a}{2}-b \\right) \\\\ \u0026amp;= \\frac{2}{3}+2b =0 \\end{align*} $$ $$ \\begin{align*} \\left\\langle f_2,f_{1} \\right\\rangle \u0026amp;= \\int_{-1}^{1}( x^3+ax^2+bx) dx \\\\ \u0026amp;= \\left. \\frac{1}{4}x^4 +\\frac{a}{3}x^3+\\frac{b}{2}x^2 \\right]_{-1}^{1} \\\\ \u0026amp;= \\left( \\frac{1}{4}+\\frac{a}{3}+\\frac{b}{2}\\right) - \\left( \\frac{1}{4}-\\frac{a}{3}+\\frac{b}{2} \\right) \\\\ \u0026amp;= \\frac{2}{3}a=0 \\end{align*} $$ Therefore, $a=0$, $b=-\\dfrac{1}{3}$ ‚ñ†\n**Find the normalized functions of $f_{0}$, $f_{1}$, and $f_2$.Solution $$ \\left\\langlef_{0},f_{0} \\right\\rangle=\\int_{-1}^{1} 1 dx =2 $$ $$ \\left\\langlef_{1},f_{1} \\right\\rangle=\\int_{-1}^{1} x^2 dx =\\frac{2}{3} $$\n$$ \\left\\langlef_2,f_2 \\right\\rangle=\\int_{-1}^{1} \\left( x^2-\\frac{1}{3} \\right )\\left( x^2-\\frac{1}{3} \\right) dx =\\frac{8}{45} $$ Therefore, the normalized functions of $f_{0}$, $f_{1}$, and $f_2$ are, respectively, $$ \\frac{1}{\\sqrt{2}}f_{0},\\quad \\sqrt{\\frac{3}{2}}f_{1},\\quad \\sqrt{\\frac{45}{8}}f_2 $$ ‚ñ†\n","id":926,"permalink":"https://freshrimpsushi.github.io/en/posts/926/","tags":null,"title":"Orthogonal Functions and Orthogonal Sets: Normalized Orthogonal Sets and Norms of Functions"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition A stochastic process $\\left\\{ X_{n} \\right\\}$ whose state space is the set of integers $\\left\\{ \\cdots , -2 , -1, 0 , 1 , 2 , \\cdots \\right\\}$ and starts from state $0$ is referred to as a generalized random walk if the probability of decreasing by $1$ in the next step is $p$, and the probability of increasing by $1$ is $(1-p)$.\nExplanation A random walk, which is a very simple example among stochastic processes, typically has equal probabilities of moving left or right. A generalized random walk simply varies these probabilities. It is not difficult to guess that if the probabilities of moving left or right are the same, the process would oscillate around the starting state $0$. However, if one side has a higher probability, it would diverge towards that side over time.\nOn the other hand, one can consider the gambler‚Äôs ruin problem as a case where the state space is finite.\nSummary If $\\displaystyle p = {{1} \\over {2}}$, then state $0$ is recurrent, and if $\\displaystyle p \\ne {{1} \\over {2}}$, then state $0$ is transient.\nProof If $\\displaystyle \\sum_{n=1}^{\\infty} p_{00}^{(n)}= \\infty$, then $0$ is recurrent, and if $\\displaystyle \\sum_{n=1}^{\\infty} p_{00}^{(n)} \u0026lt; \\infty$, then $0$ is transient. Firstly, the probability of returning to state $0$ after an odd number of moves is certainly $0$, hence $$ p_{00}^{ ( 2n - 1 )} = 0 $$ Returning to state $0$ after $2n $ moves means moving left exactly $n$ times and right $n$ times, so $$\\displaystyle p_{00}^{ ( 2n )} = \\binom{2n}{n} p^{n} (1-p)^{n}$$ Now, it is sufficient to check whether this diverges or converges.\nStirling\u0026rsquo;s approximation: $$\\lim_{n \\to \\infty} {{n!} \\over { n^{ n + 1/2} e^{- n} \\sqrt{ 2 \\pi } }} = 1$$\nCalculating factorials is hard, and since $n$ is assumed to be infinite, Stirling‚Äôs approximation is used. $$ \\begin{align*} p_{00}^{ ( 2n )} \\approx\u0026amp; {{ (2n)^{2n + 1/2} e^{-2n} \\sqrt{ 2 \\pi } } \\over { \\left( n^{n + 1/2} e^{-n} \\sqrt{ 2 \\pi } \\right)^{2} }} \\left( p ( 1 - p ) \\right)^{n} \\\\ =\u0026amp; {{ (2n)^{2n } \\sqrt{2n} } \\over { \\left( n^{n } \\right)^{2} n \\sqrt{ 2 \\pi } }} \\left( p ( 1 - p ) \\right)^{n} \\\\ =\u0026amp; {{ 4^{n} n^{2n} \\sqrt{ 2n } } \\over { n^{2n} n \\sqrt{ 2 \\pi } }} \\left( p ( 1 - p ) \\right)^{n} \\\\ =\u0026amp; {{ \\left( 4 p ( 1 - p ) \\right)^{n} } \\over { \\sqrt{ \\pi n } }} \\end{align*} $$\nCase 1. $\\displaystyle p = {{1} \\over {2}}$\np-series test: $\\displaystyle \\sum _{ n=1 }^{ \\infty }{ 1 \\over {n^p} }$ converging is equivalent to $p\u0026gt;1$.\nBy the p-test, $\\displaystyle \\sum_{n=1}^{\\infty} {{ \\left( 4 p ( 1 - p ) \\right)^{n} } \\over { \\sqrt{ \\pi n } }} = {{1} \\over { \\sqrt{ \\pi } }} \\sum_{n=1}^{\\infty} {{1} \\over { \\sqrt{n} } }$ diverges, and state $0$ is recurrent.\nCase 2. $\\displaystyle p \\ne {{1} \\over {2}}$\nRatio test: for $\\displaystyle r = \\lim_{n \\to \\infty} { {|a_{n+1}|} \\over {|a_{n}|} }$, if $r\u0026lt;1$ then $\\displaystyle \\sum _{ n=1 }^{ \\infty }{ { a }_{ n }}$ absolutely converges, if $r\u0026gt;1$ then $\\displaystyle \\sum _{ n=1 }^{ \\infty }{ { a }_{ n }}$ diverges.\n$$\\lim_{ n \\to \\infty } \\left| {{ {{ \\left( 4 p ( 1 - p ) \\right)^{n+1} } \\over { \\sqrt{ \\pi ( n + 1 ) } }} } \\over { {{ \\left( 4 p ( 1 - p ) \\right)^{n} } \\over { \\sqrt{ \\pi n } }} }} \\right| = \\lim_{n \\to \\infty } {{ 4 p ( 1 - p ) } \\over { \\sqrt{ (n+1) / n } }} = 4p (1 - p) \u0026lt; 1$$ Therefore, by the ratio test, $$\\sum_{n=1}^{\\infty} {{ \\left( 4 p ( 1 - p ) \\right)^{n} } \\over { \\sqrt{ \\pi n } }}$$ converges and state $0$ is transient.\n‚ñ†\nSee also Random walks in time series ","id":870,"permalink":"https://freshrimpsushi.github.io/en/posts/870/","tags":null,"title":"Generalized Random Walk"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Theorem 1 For a prime number $p$ and a natural number $n$, a finite field with cardinality $p^{n}$ is defined as the Galois Field of order $p^{n}$, denoted as $\\text{GF} \\left( p^{n} \\right)$. Finite fields are exclusively Galois Fields, and for a given $p$ and $n$, the Galois Field is uniquely determined.\nThe uniqueness implies that even if there are different fields, an isomorphism exists, making them essentially the same field. Description Even though no one believed in the existence of finite fields when Gauss first conceived the concept, it is now established that finite fields not only exist but are also unique and their specific structures have been identified. This eliminates the need for redundant research.\nFor instance, there is no need to ponder the existence of a field with $10$ elements, and since $\\text{GF} \\left( p \\right) = \\mathbb{Z}_{p}$ is an integer ring, we already know a lot about it. If more information is desired, one can approach through $\\mathbb{Z}_{p}$ without clinging to abstract definitions, and vice versa.\nProof 2 Part 1. All finite fields are Galois Fields.\nLet\u0026rsquo;s denote a finite extension field of field $F$ as $E$ and its degree over $F$ as $n := \\left[ E : F \\right]$.\nIf we set $| F | = q$, then $E$ is a $n$-dimensional vector space over $F$, hence $|E| = q^{n}$. A field has a multiplicative identity, and if the characteristic is $0$, an isomorphic subring exists, leading to an infinite field. Therefore, the characteristic of a finite field must be a finite natural number. If the characteristic of finite field $E$ is $p \\ne 0$, then since $E$ has a multiplicative identity $1$, it must be $p \\cdot 1 = 0$. Being a domain, $$ p \\cdot 1 = ( p_{1} \\cdot 1 ) ( p_{2} \\cdot 1 ) = 0 $$ cannot have a $p_{1}, p_{2} \\in \\mathbb{Z}$ satisfying it, thus $p$ must be a prime number. Consequently, $E$ has a subfield isomorphic to the prime field $\\mathbb{Z}_{p}$, and since $\\left| \\mathbb{Z}_{p} \\right| = p$, it follows that $|E| = p^{n}$.\nPart 2. Existence of Galois Fields\nPart 2-1. Zeros of $x^{p^{n}} - x$\nConsider the algebraic closure $\\overline{F}$ of a field $F$ with characteristic $p$, $\\left( x^{p^{n}} - x \\right)$.\nSince $\\overline{F}$ is algebraically closed, $\\left( x^{p^{n}} - x \\right) \\in \\overline{F} [ x ]$ factors into linear terms of $1$. A readily observable fact is $$ x^{p^{n}} - x = ( x - 0 ) \\left( x^{p^{n}-1} - 1 \\right) $$ thus $0$ becomes a zero in $\\left( x^{p^{n}} - x \\right)$. Considering another zero $\\alpha \\ne 0$ of $f(x) := x^{p^{n}-1} - 1$, $f \\left( \\alpha \\right) = 0$ hence $$ 0 = f \\left( \\alpha \\right) = \\alpha^{p^{n} - 1} - 1 \\implies \\alpha^{p^{n} - 1} = 1 $$ By this, expressing $f(x)$ as a product of $\\left( x - \\alpha \\right)$, $$ \\begin{align*} f(x) =\u0026amp; x^{p^{n}-1} - 1 \\\\ =\u0026amp; x^{p^{n}-1} - \\alpha^{p^{n}-1} \\\\ =\u0026amp; (x - \\alpha ) \\left( x^{p^{n} - 2 } + \\alpha x^{p^{n} - 3 } + \\cdots + \\alpha^{p^{n} - 3 } x + \\alpha^{p^{n} - 2} \\right) \\end{align*} $$ For convenience, let\u0026rsquo;s denote the second factor as $$ g(x) := \\left( x^{p^{n} - 2 } + \\alpha x^{p^{n} - 3 } + \\cdots + \\alpha^{p^{n} - 3 } x + \\alpha^{p^{n} - 2} \\right) $$ thus, $g(x)$ has $p^{n} - 1$ terms. Substituting $x = \\alpha$ gives $$ g ( \\alpha ) = \\alpha^{p^{n} - 2} \\cdot \\left( p^{n} - 1 \\right) = {{\\alpha^{p^{n} - 1}} \\over { \\alpha }} \\left( p^{n} - 1 \\right) $$ Previously, we stated that $\\alpha \\ne 0$ is a zero of $f(x)$, hence $\\alpha^{p^{n}-1} - 1 = 0$, and since we assumed the characteristic is the prime number $p$, $$ g ( \\alpha ) = {{1} \\over { \\alpha }} \\cdot (0 - 1) = - {{1} \\over { \\alpha }} \\ne 0 $$ Therefore, $\\alpha$ is not a repeated root of $f(x) = 0$, and the same applies to other non-$\\alpha$ zeros. Consequently, $\\left( x^{p^{n}} - x \\right)$ has precisely $p^{n}$ distinct zeros.\nPart 2-2. Freshman\u0026rsquo;s Dream\nConsidering $\\alpha , \\beta \\in F$, computing $\\left( \\alpha + \\beta \\right)^{p}$ by the binomial theorem yields $$ \\begin{align*} \\left( \\alpha + \\beta \\right)^{p} =\u0026amp; \\sum_{k=1}^{p} \\binom{p}{k} \\alpha^{k} \\beta^{p - k} \\\\ =\u0026amp; \\alpha^{p} + \\sum_{k=2}^{p-1} {{p!} \\over { ( p - k )! ( k )! }} \\alpha^{k} \\beta^{p - k} + \\beta^{p} \\\\ =\u0026amp; \\alpha^{p} + \\beta^{p} + p \\sum_{k=2}^{p-1} {{ ( p - 1 )! } \\over { ( p - k )! ( k )! }} \\alpha^{k} \\beta^{p - k} \\end{align*} $$ Since the characteristic of $F$ is $p$, the last term becomes $0$, thus $$ \\left( \\alpha + \\beta \\right)^{p} = \\alpha^{p} + \\beta^{p} $$ Taking $p$ to the power on both sides once more gives $$ \\left( \\left( \\alpha + \\beta \\right)^{p} \\right)^{p} = \\left( \\alpha^{p} \\right)^{p} + \\left( \\beta^{p} \\right)^{p} $$ Simplifying, we get $\\left( \\alpha + \\beta \\right)^{p^{2}} =\\alpha^{p^2} + \\beta^{p^2}$, and repeating this $n$ times results in $$ \\left( \\alpha + \\beta \\right)^{p^{n}} =\\alpha^{p^n} + \\beta^{p^n} $$\nNow, consider the algebraic closure $\\overline{ \\mathbb{Z}_{p} }$ of $\\mathbb{Z}_{p}$.\nLet\u0026rsquo;s denote the set of all zeros in $\\left( x^{p^{n}} - x \\right) \\in \\overline{ \\mathbb{Z}_{p} } [ x ]$ as $K \\subset \\overline{ \\mathbb{Z}_{p} } $, and its elements as $\\alpha , \\beta \\in K$.\nPart 2-3. $K$ is a Galois Field.\n(i) Closure under addition: $$ \\begin{cases} \\alpha^{p^{n}} - \\alpha = 0 \\\\ \\beta^{p^{n}} - \\beta = 0 \\end{cases} $$ Adding both sides, by Part 2-2 $\\left( \\alpha + \\beta \\right)^{p^{n}} =\\alpha^{p^n} + \\beta^{p^n}$, $$ \\left( \\alpha^{p^{n}} + \\beta^{p^{n}} \\right) - ( \\alpha + \\beta ) = \\left( \\alpha + \\beta \\right)^{p^{n}} - ( \\alpha + \\beta ) = 0 $$ thus, $( \\alpha + \\beta ) \\in K$. (ii) Additive identity: Since $0^{p^{n}} - 0 = 0$, $0 \\in K$. (iii) Additive inverse: If $\\left( - \\alpha \\right)^{p^{n}} = \\left( - 1 \\right)^{^{p^{n}}} \\left( \\alpha \\right)^{p^{n}} = \\left( - 1 \\right)^{^{p^{n}}} \\alpha$, If $p=2$, then $-1 = 1$, so $\\left( -\\alpha \\right) = \\alpha \\in K$. Since $p \\ne 2$ is an odd prime, $\\left( - \\alpha \\right)^{p^{n}} - ( - \\alpha ) = 0$, i.e., $( - \\alpha ) \\in K$. (iv) Closure under multiplication: Since $\\left( \\alpha \\beta \\right)^{p^{n}} = \\alpha^{p^{n}} \\beta^{p^{n}} = \\alpha \\beta$, $\\left( \\alpha \\beta \\right)^{p^{n}} - \\alpha \\beta = 0$, thus $\\alpha \\beta \\in K$. (v) Multiplicative identity: Since $1^{p^{n}} - 1 = 0$, $1 \\in K$. (vi) Multiplicative inverse: For $\\alpha \\ne 0$, taking the inverse of $\\displaystyle \\left( \\alpha \\right)^{p^{n}} = \\alpha$ gives $\\displaystyle {{1} \\over {\\left( \\alpha \\right)^{p^{n}} }} = {{1} \\over { \\alpha }}$, thus $$ \\left( {{1} \\over { \\alpha }} \\right)^{p^{n}} - {{1} \\over { \\alpha }} = 0 $$ so $\\alpha^{-1} \\in K$. (vii): $| K | = p^{n}$: The characteristic of $\\mathbb{Z}_{p}$ is $p$, so by Part 2-1, $\\left( x^{p^{n}} - x \\right)$ has precisely $p^{n}$ distinct zeros. Therefore, $K$ is a Galois Field of order\n$p^{n}$.\nPart 3. Uniqueness of Galois Fields\nFrom Part 1, the characteristic of $F$ is the prime number $p$, and from Part 2-1, operations in the algebraic closure $\\overline{F}$ of $F$, considering the multiplicative identity $1_{F}$ of $F$ as $1_{\\mathbb{Z}_{p}}$, are essentially the same as operations in the algebraic closure $\\overline{\\mathbb{Z}}_{p}$ of $\\mathbb{Z}_{p}$.\nPart 3-1. The nature of a field with cardinality $p^{n}$, $E \\subset \\overline{\\mathbb{Z}}_{p}$ 3\nLagrange\u0026rsquo;s Theorem: If $H$ is a subgroup of a finite group $G$, then $|H|$ is a divisor of $|G|$.\nConsidering the group $\\left( E^{\\ast} , \\times \\right)$ under multiplication $\\times$ for a field $\\left( E , + , \\times \\right)$ with cardinality $p^{n}$, $E^{\\ast}$ consists of $p^{n} - 1$ elements excluding the multiplicative identity $0 \\in E$ of $E$ and the identity $1 \\in E^{\\ast}$. The order of $\\alpha \\in E^{\\ast}$, the cardinality of the cyclic group generated by $\\alpha$, is a divisor of $p^{n} - 1$ by Lagrange\u0026rsquo;s Theorem, hence $$ \\alpha^{p^{n} - 1} = 1 \\implies a^{p^{n}} = \\alpha $$ In other words, all elements of $E$ are zeros of $x^{p^{n}} - x$ and, by the Fundamental Theorem of Algebra, the elements of the field $E$ with cardinality $p^{n}$ within the algebraic closure $\\overline{\\mathbb{Z}}_{p}$ of $\\mathbb{Z}_{p}$ are precisely the zeros of $\\left( x^{p^{n}} - x \\right) \\in \\mathbb{Z}_{p} [x]$.\nPart 3-2. Minimal Polynomials\nAccording to Part 2-1 and Part 3-1, for a given $p$ and $n$, there exists a field $E$ consisting entirely of zeros of $\\left( x^{p^{n}} - x \\right)$, and considering the characteristic of $F$ as $p$, the operations on its coefficients are the same as those in the prime field $\\mathbb{Z}_{p}$. By Part 2-3 and Part 1, $E$ is a Galois Field containing the prime field $\\mathbb{Z}_{p}$ as a subfield and satisfies $|E| = p^{n}$, and again by Part 2-1, $E$ is the minimal splitting field of $\\left( x^{p^{n}} - x \\right)$.\nProperties of Minimal Splitting Fields: All minimal splitting fields are isomorphic.\nHence, for a given $p$ and $n$, the Galois Field is unique.\n‚ñ†\nCorollary: Freshman\u0026rsquo;s Dream As an interesting fact, the equation from Part 2-2 $$ \\left( \\alpha + \\beta \\right)^{p^{n}} =\\alpha^{p^n} + \\beta^{p^n} $$ is known as the Freshman\u0026rsquo;s Dream. It\u0026rsquo;s named because, from the perspective of a newcomer to the subject, the ability to distribute exponentiation inside a bracket would make solving complex problems straightforward without detailed expansions. Notably, in number theory, a similar result can be derived for congruences $\\left( \\alpha + \\beta \\right)^{p^{n}} \\equiv \\alpha^{p^n} + \\beta^{p^n} \\pmod{ p }$ without mentioning the characteristic.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p300.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p302~304.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p301\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":820,"permalink":"https://freshrimpsushi.github.io/en/posts/820/","tags":null,"title":"Galois Field"},{"categories":"Ìï®Ïàò","contents":"Formula The explicit formula for the Legendre polynomials is as follows.\n$$ P_{l}(x)=\\dfrac{1}{2^{l} l!} \\dfrac{d^{l}}{dx^{l}}(x^{2}-1)^{l} \\tag{1} $$\nDescription This formula is used to obtain the $l$th Legendre polynomial, known as the Rodrigues\u0026rsquo; formula. Originally, it referred to the explicit form of the Legendre polynomials, but later it became a universal name for formulas representing the explicit form of special functions expressed as polynomials.\nDerivation The Legendre polynomial $P_{l}$ refers to the solution of the following Legendre differential equation.\n$$ (1 - x^{2}) \\dfrac{d^{2} y}{d x^{2}} - 2x \\dfrac{d y}{d x} + l(l+1)y = 0 $$\nThus, the proof is complete if it is shown that $(1)$ is a solution to the above differential equation.\nFirst, when we set $v=(x^2-1)^l$, we will show that $\\dfrac{d^lv}{dx^l}$ is a solution to the Legendre equation. Later, normalization is performed to satisfy $P_{l}(1) = 1$, obtaining $(1)$.\n$$ \\dfrac{dv}{dx}=l(2x)(x^2-1)^{l-1} $$\nMultiplying both sides by $(x^2-1)$ yields the following equation.\n$$ (x^2-1)\\dfrac{dv}{dx}=2lx(x^2-1)^l=2lxv $$\nDifferentiating both sides $l+1$ times yields the following, according to the Leibniz rule.\n$$ \\sum \\limits_{k=0}^{l+1} {}_{l+1}\\mathrm{C}_{k} \\dfrac{ d^{l+1-k}}{dx^{l+1-k} } \\left( \\dfrac{dv}{dx} \\right) \\dfrac{d^k}{dx^k} (x^2-1) = 2l\\sum \\limits_{k=0}^{l+1} {}_{l+1}\\mathrm{C} _{k} \\dfrac{d^{l+1-k} v}{dx^{l+1-k}} \\dfrac{d^k x}{dx^k} $$\nAt this time, the left side remains only when $k \\ge 3$ is $\\dfrac{d^k}{dx^k}(x^2-1)=0$, so only the term $k=0,2,3$ remains. The right side remains only when $k \\ge 2$ is $\\dfrac{d^kx}{dx^k}=0$, so only the term $k=1,2$ remains. Thus, we obtain the following.\n$$ (x^2-1)\\dfrac{d^{l+2} v}{dx^{l+2}} + (l+1)(2x)\\dfrac{d^{l+1}v}{dx^{l+1}}+\\dfrac{l(l+1)}{2!}2\\dfrac{d^l v}{dx^l}=2lx\\dfrac{d^{l+1} v}{dx^{l+1}} + 2l(l+1)\\dfrac{d^lv}{dx^l} $$\nBy grouping like terms together and arranging them properly, the following is obtained.\n$$ (1-x^2)\\left( \\dfrac{d^l v}{dx^l} \\right)^{\\prime \\prime} -2x\\left( \\dfrac{d^lv}{dx^l} \\right)^{\\prime} + l(l+1)\\dfrac{d^lv}{dx^l}=0 $$\nThis has the same form as the Legendre equation. That is, $\\dfrac{d^l v}{dx^l}$ becomes a solution to the Legendre equation.\n$$ P_{l}(x)= \\dfrac{d^l}{dx^l}(x^2-1)^l $$\nLet\u0026rsquo;s find the coefficient that satisfies $P_{l}(1) = 1$. Factorizing $(x^2-1)^l$ into $(x-1)^l(x+1)^l$ and differentiating $l$ times using the Leibniz rule yields the following.\n$$ \\begin{align*} \u0026amp;\\quad \\ P_{l}(x) \\\\ \u0026amp;= \\dfrac{d^l}{dx^l} \\left[ (x-1)^l (x+1)^l \\right] \\\\ \u0026amp;= \\sum\\limits_{k=0}^l {}_{l}\\mathrm{C}_{k} \\dfrac{d^{l-k}}{dx^{l-k}}(x-1)^l \\dfrac{d^k}{dx^k}(x+1)^l \\\\ \u0026amp;= {}_{l}\\mathrm{C}_{0} l! (x+1)^l + {}_{l}\\mathrm{C}_{1} l!(x-1) l(x+1)^{l-1}+{}_{l}\\mathrm{C}_2\\dfrac{l!}{2}(x-1)^2l(l-1)(x+1)^{l-2}+\\cdots \\end{align*} $$\nFrom the second term onwards, because it includes the factor $(x-1)$, when $x=1$, $0$ is true. Therefore, $P_{l}(1)=l! 2^l$, and to make this value $1$, it must be divided by $\\dfrac{1}{2^l l!}$. Therefore, we finally obtain the following Rodrigues\u0026rsquo; formula.\n$$ P_{l}(x)=\\dfrac{1}{2^l l!}\\dfrac{d^l}{dx^l}(x^2-1)^l $$\n‚ñ†\n","id":895,"permalink":"https://freshrimpsushi.github.io/en/posts/895/","tags":null,"title":"Rodrigues Formula for Legendre Polynomial"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition A discrete-time Markov chain (DTMC), or simply a Markov Chain, is a discrete stochastic process $\\left\\{ X_{n} \\right\\}$ satisfying the following, provided the state space is a countable set: $$ p \\left( X_{n+1} = j \\mid X_{n} = i , X_{n-1} = k , \\cdots , X_{0} = l \\right) = p \\left( X_{n+1} = j \\mid X_{n} = i \\right) $$\nSee Also Continuous Markov Chain Description $p_{ij}:= p \\left( X_{n+1} = j \\mid X_{n} = i \\right)$ is called the Transition Probability, where $i$ represents the Source State, and $j$ represents the Target State. The transition probability after $k$ steps is represented as $p_{ij}^{(k)}: = p \\left( X_{n+k} = j \\mid X_{n} = i \\right)$.\nA Markov Chain refers to a stochastic process where the probability of the next step, given the entire history, is the same as the probability given only the current state. In simpler terms, if one accurately knows the current state, the past does not influence the future of the process, a property often referred to as Memorylessness. Naturally, such an assumption significantly simplifies calculations or anything alike.\nConsider modeling the probability of precipitation as a Markov chain. Whether it rained yesterday or not, let\u0026rsquo;s assume the probability of rain tomorrow only depends on whether it rained today. Let the state of it raining be represented by $0$, and the state of no rain by $1$. $$\\begin{matrix} p_{00} = 0.7 \u0026amp; p_{01} = 0.3 \\\\ p_{10} = 0.4 \u0026amp; p_{11} = 0.6 \\end{matrix}$$ This means, if it rained today, the probability of rain tomorrow is $70 %$ and no rain is $30 %$; if it did not rain today, the probability of no rain tomorrow is $60 %$ and rain is $40 %$.\nNow, $$P:= \\begin{bmatrix} p_{00} \u0026amp; p_{01} \\\\ p_{10} \u0026amp; p_{11} \\end{bmatrix} = \\begin{bmatrix} 0.7 \u0026amp; 0.3 \\\\ 0.4 \u0026amp; 0.6 \\end{bmatrix} $$ using a matrix, we can simplify such probability calculations. This matrix is referred to as the Transition Probability Matrix, and the transition probability matrix after $k$ steps is represented as $P^{(k)}:= \\left( p_{ij}^{ ( k ) } \\right)$. A useful property of the transition probability matrix is $P^{(n)} = P^{n}$, which can be proven through the Chapman-Kolmogorov equation.\nIf it rained today, the probability of rain in two days is $$ \\begin{align*} P^{ (2) } =\u0026amp; P^{2} \\\\ =\u0026amp; \\begin{bmatrix} 0.7 \u0026amp; 0.3 \\\\ 0.4 \u0026amp; 0.6 \\end{bmatrix} \\begin{bmatrix} 0.7 \u0026amp; 0.3 \\\\ 0.4 \u0026amp; 0.6 \\end{bmatrix} \\\\ =\u0026amp; \\begin{bmatrix} 0.61 \u0026amp; 0.39 \\\\ 0.52 \u0026amp; 0.48 \\end{bmatrix} \\end{align*} $$ and matches precisely with $p_{00}^{(2)} = (0.7)^2 + (0.3) (0.4) = 0.61$. Typically, our interest in problems is more complex and inclined towards the distant future, thus handling such matrices becomes essential.\nFormal Definition of the Transition Probability Matrix Note that the sum of elements in the same row of the transition probability matrix must always equal $1$, naturally, since the sum of the probabilities of all next steps equals $1$. This property can be formally represented as $\\displaystyle \\sum_{j} p_{ij} = 1$. Depending on where one studies stochastic processes, this property might even be accepted as a definition.\n","id":859,"permalink":"https://freshrimpsushi.github.io/en/posts/859/","tags":null,"title":"Discrete Markov Chains"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 The following differential equation is called the Legendre differential equation.\n$$ (1-x^2)\\dfrac{d^2 y}{dx^2} -2x\\dfrac{dy}{dx}+l(l+1) y=0 $$\nThe solution to the Legendre differential equation is called the Legendre polynomial, commonly denoted as $P_{l}(x)$. The first few Legendre polynomials according to $l$ are as follows.\n$$ \\begin{align*} P_{0}(x) =\u0026amp;\\ 1 \\\\ P_{1}(x) =\u0026amp;\\ x \\\\ P_2(x) =\u0026amp;\\ \\dfrac{1}{2}(3x^2-1) \\\\ P_{3}(x) =\u0026amp;\\ \\dfrac{1}{2}(5x^3-3x) \\\\ P_{4}(x) =\u0026amp;\\ \\dfrac{1}{8}(35x^4-30x^2+3) \\\\ P_{5}(x) =\u0026amp;\\ \\dfrac{1}{8}(63x^5-70x^3+15x) \\\\ \\vdots\u0026amp; \\end{align*} $$\nDescription The Legendre differential equation is also introduced in the following form.\n$$ \\dfrac{d}{dx}\\left[ (1-x)^2 \\dfrac{dy}{dx} \\right] +l(l+1)y=0 $$\nThis is expressed in terms of Sturm-Liouville theory. Expanding and rearranging the first term yields the same equation. The generalized form of the Legendre differential equation as below is called the associated Legendre differential equation.\n$$ (1-x^2)\\dfrac{d^2 y}{dx^2} -2x\\dfrac{dy}{dx}+\\left( \\dfrac{-m^2}{1-x^2} +l(l+1) \\right) y=0 $$\nHere, if $m=0$, it becomes the Legendre differential equation.\nThe Legendre equation appears in physics and engineering, especially when solving the Laplace equation in spherical coordinates. Physics majors may encounter it when calculating potential in spherical coordinates in electromagnetism, or when solving the Schr√∂dinger equation in spherical coordinates in quantum mechanics. Because the solution process is lengthy, textbooks usually only write down the solution expressed by Rodrigues\u0026rsquo; formula. In fact, physics students do not necessarily need to be too curious about the solution.\nSolution Assuming the solution has the form of a power series with the independent variable $x$, it can be solved.\n$$ \\begin{equation} (1-x^2)y^{\\prime \\prime} -2xy^{\\prime}+l(l+1) y=0 \\label{1} \\end{equation} $$\nAssume the solution to the Legendre differential equation is as follows.\n$$ y=a_{0}+a_{1}(x-x_{0})+a_2(x-x_{0})^2+\\cdots=\\sum \\limits_{n=0}^\\infty a_{n}(x-x_{0})^n $$\nWhen $x=0$, the coefficient of $y^{\\prime \\prime}$ becomes $(1-x^2)|_{x=0}=1\\ne 0$, so we assume it as $x_{0}=0$. Then the series solution is\n$$ \\begin{equation} y=a_{0}+a_{1}x+a_2x^2+\\cdots=\\sum \\limits_{n=0}^\\infty a_{n}x^n \\label{2} \\end{equation} $$\nAlthough we assumed the solution as a series, at the end of the solution, we find that the terms of $y$ are finite. Now, to substitute for $\\eqref{1}$, let\u0026rsquo;s find $y^{\\prime}$ and $y^{\\prime \\prime}$.\n$$ y^{\\prime}=a_{1}+2a_2x+3a_{3}x^2+\\cdots=\\sum \\limits_{n=1}^\\infty na_{n}x^{n-1} $$\n$$ y^{\\prime \\prime}=2a_2+3\\cdot 2a_{3}x+4\\cdot 3 a_{4}x^2 +\\cdots = \\sum \\limits_{n=2} n(n-1)a_{n}x^{n-2} $$\nNow, substituting $y, y^{\\prime}, y^{\\prime \\prime}$ into $\\eqref{1}$,\n$$ (1-x^2)\\sum \\limits_{n=2}^\\infty n(n-1)a_{n}x^{n-2} -2x\\sum \\limits_{n=1}^\\infty na_{n}x^{n-1}+l(l+1) \\sum \\limits_{n=0}^\\infty a_{n}x^n=0 $$\nExpanding the coefficient of the first term $(1-x^2)$ and rearranging gives\n$$ \\sum \\limits_{n=2}^\\infty n(n-1)a_{n}x^{n-2} -x^2\\sum \\limits_{n=2}^\\infty n(n-1)a_{n}x^{n-2} -2x\\sum \\limits_{n=1}^\\infty na_{n}x^{n-1}+l(l+1) \\sum \\limits_{n=0}^\\infty a_{n}x^n=0 $$\n$$ \\implies \\sum \\limits_{n=2} ^\\infty n(n-1)a_{n}x^{n-2} -\\sum \\limits_{n=2}^\\infty n(n-1)a_{n}x^{n} -2\\sum \\limits_{n=1}^\\infty na_{n}x^{n}+l(l+1) \\sum \\limits_{n=0}^\\infty a_{n}x^n=0 $$\nThe key here is matching the order of $x$. While the rest are expressed as $x^n$, only the first series is expressed as $x^{n-2}$, so substituting $n+2$ instead of $n$,\n$$ \\sum \\limits_{n=0} ^\\infty (n+2)(n+1)a_{n+2}x^{n} -\\sum \\limits_{n=2}^\\infty n(n-1)a_{n}x^{n} -2\\sum \\limits_{n=1}^\\infty na_{n}x^{n}+l(l+1) \\sum \\limits_{n=0}^\\infty a_{n}x^n=0 $$\nSince the second series starts from the $x^2$ term, taking out the term where $n=0,1$ from the rest of the series and grouping constant terms with constant terms, and first-order terms with first-order terms,\n$$ \\left[ 2\\cdot 1 a_2+l(l+1)a_{0} \\right]+\\left[ 3\\cdot 2 a_{3}-2a_{1}+l(l+1)a_{1} \\right]x \\\\ + \\sum \\limits_{n=2}^\\infty \\left[ (n+2)(n+1)a_{n+2}-n(n+1)a_{n}-2na_{n}+l(l+1)a_{n} \\right] x^n=0 $$\nFor the above equation to hold, all coefficients must be $0$.\n$$ 2\\cdot 1 a_2+l(l+1)a_{0} =0 $$\n$$ 3\\cdot 2 a_{3}-2a_{1}+l(l+1)a_{1} =0 $$\n$$ (n+2)(n+1)a_{n+2}-n(n+1)a_{n}-2na_{n}+l(l+1)a_{n}=0 $$\nOrganizing each gives\n$$ \\begin{equation} a_2=-\\dfrac{l(l+1)}{2 \\cdot 1}a_{0} \\label{3} \\end{equation} $$\n$$ \\begin{equation} a_{3}=-\\dfrac{(l+2)(l-1)}{3\\cdot 2} a_{1} \\label{4} \\end{equation} $$\n$$ \\begin{equation} a_{n+2}=-\\dfrac{(l+n+1)(l-n)}{(n+2)(n+1)}a_{n} \\label{5} \\end{equation} $$\nUsing $\\eqref{3}, \\eqref{4}, \\eqref{5}$, knowing just the values of $a_{0}$ and $a_{1}$ allows us to determine all coefficients. Calculating the coefficients of even-order terms with $\\eqref{3}$ and $\\eqref{5}$,\n$$ \\begin{align*} a_{4} =\u0026amp;\\ - \\dfrac{(l+3)(l-2)}{ 4 \\cdots 3}a_2 = \\dfrac{l(l-2)(l+1)(l+3)}{4!}a_{0} \\\\ a_{6} =\u0026amp;\\ -\\dfrac{(l+5)(l-4)}{6\\cdot5} a_{4} = -\\dfrac{ l(l-2)(l-4)(l+1)(l+3)(l+5)}{6!} a_{0} \\\\ \\vdots\u0026amp; \\end{align*} $$\nIf we set $n=2m\\ (m=1,2,3,\\cdots)$,\n$$ a_{n}=a_{2m}=(-1)^m \\dfrac{l(l-2)\\cdots (l-2m+4)(l-2m+2)(l+1)(l+3)\\cdots(l+2m-3)(l+2m-1)}{(2m)!}a_{0} $$\nSimilarly, calculating the coefficients of odd-order terms with $\\eqref{4}$ and $\\eqref{5}$,\n$$ \\begin{align*} a_{5} =\u0026amp;\\ -\\dfrac{(l+4)(l-3)}{5\\cdot 4}a_{3} = \\dfrac{(l+2)(l+4)(l-1)(l-3)}{5!}a_{1} \\\\ a_{7} =\u0026amp;\\ -\\dfrac{(l+6)(l-5)}{7\\cdot 6}a_{5} = -\\dfrac{(l+2)(l+4)(l+6)(l-1)(l-3)(l-5)}{7!}a_{1} \\\\ \\vdots\u0026amp; \\end{align*} $$\nIf we set $n=2m+1\\ (m=1,2,3,\\cdots)$,\n$$ a_{n}=a_{2m+1}=(-1)^m\\dfrac{(l+2)(l+4)\\cdots(l+2m-2)(l+2m)(l-1)(l-3)\\cdots(l-2m+3)(l-2m+1)}{(2m+1)!}a_{1} $$\nSubstituting these coefficients into $\\eqref{2}$ to find the solution,\n$$ \\begin{align*} y =\u0026amp;\\a_{0}+a_{1}x -\\dfrac{l(l+1)}{2!}a_{0}x^2-\\dfrac{(l+2)(l-1)}{3!}a_{1}x^3 + \\dfrac{l(l-2)(l+1)(l+3)}{4!}a_{0}x^4+\\dfrac{(l+2)(l+4)(l-1)(l-3)}{5!}a_{1}x^5 \\\\ \u0026amp;+ \\cdots +(-1)^m \\dfrac{l(l-2)\\cdots (l-2m+4)(l-2m+2)(l+1)(l+3)\\cdots(l+2m-3)(l+2m-1)}{(2m)!}a_{0}x^{2m} \\\\ \u0026amp;+ (-1)^m\\dfrac{(l+2)(l+4)\\cdots(l+2m-2)(l+2m)(l-1)(l-3)\\cdots(l-2m+3)(l-2m+1)}{(2m+1)!}a_{1}x^{2m+1} +\\cdots \\end{align*} $$\nGrouping even-order terms as $a_{0}$ and odd-order terms as $a_{1}$,\n$$ \\begin{align*} y =\u0026amp;\\a_{0}\\left[1-\\dfrac{l(l+1)}{2!}x^2+\\dfrac{l(l-2)(l+1)(l+3)}{4!}x^4 \\right. \\\\ \u0026amp;\\left.+\\sum \\limits_{m=3}^\\infty (-1)^m \\dfrac{l(l-2)\\cdots (l-2m+4)(l-2m+2)(l+1)(l+3)\\cdots(l+2m-3)(l+2m-1)}{(2m)!} x^{2m} \\right] \\\\ \u0026amp;+ a_{1}\\left[x- \\dfrac{(l+2)(l-1)}{3!}x^3+\\dfrac{(l+2)(l+4)(l-1)(l-3)}{5!}x^5 \\right. \\\\ \u0026amp; \\left. +\\sum \\limits_{m=3}^\\infty (-1)^m\\dfrac{(l+2)(l+4)\\cdots(l+2m-2)(l+2m)(l-1)(l-3)\\cdots(l-2m+3)(l-2m+1)}{(2m+1)!} x^{2m+1} \\right] \\end{align*} $$\nSetting the first parenthesis as $y_{0}$ and the second as $y_{1}$, the general solution to the Legendre equation is as follows.\n$$ y=a_{0}y_{0}+a_{1}y_{1} $$\nThe two series $y_{0}$ and $y_{1}$ converge in the interval of $|x|\u0026lt;1$ according to the ratio test. By $\\eqref{5}$, since $\\dfrac{a_{n+2}}{a_{n}}=-\\dfrac{(l+n+1)(l-n)}{(n+2)(n+1)}=\\dfrac{(n+l+1)(n-l)}{(n+2)(n+1)}$, using the ratio test,\n$$ \\lim \\limits_{n \\rightarrow \\infty} \\dfrac{(n+l+1)(n-l)}{(n+2)(n+1)}x^2=x^2\u0026lt;1 $$\n$$ \\implies -1\u0026lt;x\u0026lt;1 $$\nHowever, in many problems, $x=\\cos \\theta$ and $l$ appear as non-negative integers, and the goal is to find solutions that converge for all $\\theta$. That is, to find solutions that also converge at $x=\\pm 1$. Fortunately, when $l$ is an integer, the desired solution exists, and depending on the value of $l$, only one of $y_{0}, y_{1}$ exists. If $l$ is $0$ or even, $y_{1}$ diverges, and $y_{0}$ becomes a finite-term polynomial with only even-order terms. If $l$ is odd, $y_{0}$ diverges, and $y_{1}$ becomes a finite-term polynomial with only odd-order terms. The summary is as follows.\nValue of $l$ $y_{0}$ $y_{1}$ Equation\u0026rsquo;s Solution $0$ or even Finite-term polynomial Diverge $y=a_{0}y_{0}$ Odd Diverge Finite-term polynomial $y=a_{1}y_{1}$ Case 1. If $l$ is $0$ or even\nFor $l=0$, from the 2nd term, taking $l$ as a factor, all become $0$, so $y_{0}=1$\nFor $l=2$, from the 4th term, taking $(l-2)$ as a factor, all become $0$, so $y_{0}=1-3x^2$\nFor $l=4$, from the 6th term, taking $(l-4)$ as a factor, all become $0$, so $y_{0}= 1-10x^2+\\dfrac{35}{3}x^4$\nWhen $l=0$, $x^2=1$ becomes $y_{1}=1+\\frac{1}{3}+\\frac{1}{5}+\\cdots$, which diverges by the integral test. The same applies to other even numbers. Thus, when $l$ is $0$ or even, the solution is a finite-term polynomial with only even-order terms. That is, we obtain a solution that only retains specific terms of the series $y_{0}$.\nCase 2. If $l$ is odd\nThe opposite result appears compared to even cases.\nFor $l=1$, from the 3rd term, taking $(l-1)$ as a factor, all become $0$, so $y_{1}=x$\nFor $l=3$, from the 5th term, taking $(l-3)$ as a factor, all become $0$, so $y_{1}=x-\\dfrac{5}{3}x^3$\nFor $l=5$, from the 7th term, taking $(l-5)$ as a factor, all become $0$, so $y_{1}=x-\\dfrac{14}{3}x^3+\\dfrac{21}{5}x^5$\nWhen $l=1$, $x^2=1$ diverges, and the same applies to other odd numbers. Thus, when $l$ is odd, the solution is a finite-term polynomial with only odd-order terms. That is, we obtain a solution that only retains specific terms of the series $y_{1}$.\nAnd if $l$ is negative, it is the same as when $l$ is a non-zero integer, as can be seen by examining $y_{0}$ and $y_{1}$. For example, the case of $l=2$ is the same as that of $l=-3$, and the case of $l=1$ is the same as that of $l=-2$. Therefore, it suffices to consider only when $l$ is a non-negative integer. Choosing the values of $a_{0}$ and $a_{1}$ wisely to make the solution $x=1$ when $y(x)=1$, this is called the Legendre polynomial, denoted as $P_{l}(x)$. The first few Legendre polynomials are as follows.\n$$ \\begin{align*} P_{0}(x) =\u0026amp;\\ 1 \\\\ P_{1}(x) =\u0026amp;\\ x \\\\ P_2(x) =\u0026amp;\\ \\dfrac{1}{2}(3x^2-1) \\\\ P_{3}(x) =\u0026amp;\\ \\dfrac{1}{2}(5x^3-3x) \\\\ P_{4}(x) =\u0026amp;\\ \\dfrac{1}{8}(35x^4-30x^2+3) \\\\ P_{5}(x) =\u0026amp;\\ \\dfrac{1}{8}(63x^5-70x^3+15x) \\end{align*} $$\nThe above result can also be obtained directly using Rodrigues\u0026rsquo; formula.\n‚ñ†\nMary L. Boas, Mathematical Methods in the Physical Sciences, translated by Jun-gon Choi (3rd Edition, 2008), p577-580\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":889,"permalink":"https://freshrimpsushi.github.io/en/posts/889/","tags":null,"title":"Series Solution of Legendre Differential Equation: Legendre Polynomial"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Summary $$ \\dfrac{d}{dx} (fg)=\\dfrac{df}{dx}g+f\\dfrac{dg}{dx} $$\n$$ \\begin{align*} \\dfrac{d^n}{dx^n}(fg)\u0026amp;=\\sum \\limits_{k=0}^{n}\\frac{n!}{(n-k)!k!}\\dfrac{d^{n-k}f}{dx^{n-k}}\\dfrac{d^k g}{dx^k} \\\\ \u0026amp;=\\sum \\limits_{k=0}^{n}{}_{n}\\mathrm{C}_{k} \\dfrac{d^{n-k}f}{dx^{n-k}}\\dfrac{d^k g}{dx^k} \\\\ \u0026amp;=\\sum \\limits_{k=0}^{n} \\binom{n}{k} \\dfrac{d^{n-k}f}{dx^{n-k}}\\dfrac{d^k g}{dx^k} \\end{align*} $$\nDescription Also known as Leibniz\u0026rsquo;s rule.\nThe first equation is a well-known formula, often referred to as the product rule or the rule of product for differentiation. It simply expresses the result when the product of two functions is differentiated once. More generally, the equation below represents the result when differentiated $n$ times. Since a polynomial can become $0$ by being differentiated repeatedly, the result can be easily calculated without directly differentiating $n$ times.\nThere are also many theorems or formulas related to differentiation and integration named after Leibniz.\nProof Let\u0026rsquo;s call $D$ the following differential operator.\n$$ D=\\dfrac{d}{dx} $$\nFor example, $Df(x)=\\dfrac{df(x)}{dx}$ is. If $D$ is used to express the differentiation of $fg$, it looks like the following.\n$$ \\dfrac{d}{dx}(fg)=gDf+fDg $$\nAt this time, let\u0026rsquo;s say $D_{f}$ is an operator that only applies to $f$, and $D_{g}$ is an operator that only applies to $g$. Then, the above formula is expressed as follows.\n$$ (D_{f}+D_{g})(fg)=gDf+fDg $$\nThen you get:\n$$ \\dfrac{d}{dx}(fg)=(D_{f}+D_{g})(fg) $$\n$$ \\dfrac{d^2}{dx^2}(fg)=D(D_{f}+D_{g})(fg) $$\nAt this point, since $D$ is a differential operator, the order of operations doesn\u0026rsquo;t matter. In other words, it means $DD_{f}f=D_{f}Df$. Thus, the formula is as follows.\n$$ \\begin{align*} \\dfrac{d^2}{dx^2}(fg) \u0026amp;= D(D_{f}+D_{g})(fg) \\\\ \u0026amp;= (D_{f}+D_{g})D(fg) \\\\ \u0026amp;= (D_{f}+D_{g})(D_{f}+D_{g})(fg) \\\\ \u0026amp;= (D_{f}+D_{g})^2 (fg) \\end{align*} $$\nAs mentioned above, since $D$ allows for the commutativity of multiplication, it can be expressed as the last line. Extended to $n$ times of differentiation, it looks like the following.\n$$ \\dfrac{d^n}{dx^n} (fg)=(D_{f}+D_{g})^n(fg) $$\nSince the commutative law holds, the binomial theorem can be applied. Using the binomial theorem, you get:\n$$ \\begin{align*} \\dfrac{d^n}{dx^n} (fg) \u0026amp;= (D_{f}+D_{g})^n(fg) \\\\ \u0026amp;= \\sum \\limits_{k=0} ^n {}_{n}\\mathrm{C} _{k} {D_{f}}^{n-k} {D_{g}}^{k}(fg) \\\\ \u0026amp;=\\sum \\limits_{k=0} ^n {}_{n}\\mathrm{C} _{k} {D_{f}}^{n-k} f{D_{g}}^{k}g \\\\ \u0026amp;= \\sum \\limits_{k=0} ^n {}_{n}\\mathrm{C} _{k} \\dfrac{d^{n-k}f}{dx^{n-k}} \\dfrac{d^k g}{dx^k} \\\\ \u0026amp;= \\sum \\limits_{k=0} ^n {}_{n}\\mathrm{C} _{k} f^{(n-k)} g^{(k)} \\end{align*} $$\n‚ñ†\nExample 1 Find $\\dfrac{d^7}{dx^7}( x \\sin x)$. If $x$ and $\\sin x$ are set respectively as $g$ and $f$ from the proof above, by Leibniz\u0026rsquo;s rule,\n$$ \\dfrac{d^7}{dx^7}( x \\sin x)=\\sum \\limits_{k=0} ^7 {}_{7} \\mathrm{C}_{k} \\dfrac{d ^{n-k} } {dx^{n-k} }(\\sin x) \\dfrac{d^k}{dx^k} (x) $$\nWhen $k \\ge 2$, since it is $\\dfrac{d^k}{dx^k}(x)=0$, only the two terms $k=0,1$ remain. Therefore,\n$$ \\begin{align*} \\dfrac{d^7}{dx^7} ( x \\sin x ) \u0026amp;= {}_{7} \\mathrm{C} _{0} \\dfrac{d^7}{dx^7}(\\sin x) x + {}_{7}\\mathrm{C}_{1} \\dfrac{d^6}{dx^6} (\\sin x) \\\\ \u0026amp;= -x \\cos x -7\\sin x \\end{align*} $$\n‚ñ†\n2 Find $\\dfrac{d^{10}}{dx^{10}} ( x^2 e^{-x} )$. If $x^2$ and $e^{-x}$ are set respectively as $g$ and $f$ from the proof above, by Leibniz\u0026rsquo;s rule,\n$$ \\dfrac{d^{10}}{dx^{10}} (x^2 e^{-x}) = \\sum \\limits _{k=0} ^{10} {}_{10} \\mathrm{C} _{k} \\dfrac{d^{10-k}}{dx^{10-k}}(e^{-x}) \\dfrac{d^k}{dx^k} ( x^2) $$\nWhen $k \\ge 3$, since it is $\\dfrac{d^k}{dx^k} (x^2)=0$, only the three terms that are $k=0,1,2$ remain. Therefore,\n$$ \\begin{align*} \\dfrac{d^{10} } {dx^{10} } (x^2 e^{-x}) \u0026amp;= {}_{10} \\mathrm{C}_{0} \\dfrac{d^{10}}{dx^{10}} (e^{-x}) x^2 + {}_{10} \\mathrm{C} _{1} \\dfrac{d^9}{dx^9}(e^{-x}) \\dfrac{d}{dx}(x^2) + {}_{10}\\mathrm{C}_2 \\dfrac{d^8}{dx^8} ( e^{-x} ) \\dfrac{d^2}{dx^2} (x^2) \\\\ \u0026amp;= x^2 e^{-x} -20 x e^{-x} + 90e^{-x} \\end{align*} $$\n‚ñ†\nSee Also Leibniz\u0026rsquo;s integration rule ","id":884,"permalink":"https://freshrimpsushi.github.io/en/posts/884/","tags":null,"title":"Proof of Leibniz's Theorem"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Definition1 Let\u0026rsquo;s assume a sequence $\\left\\{ a_{n} \\right\\}$ is given. Then, let\u0026rsquo;s define the following notation.\n$$ \\sum \\limits_{n=p}^{q} a_{n} = a_{p} + a_{p+1} + \\cdots + a_{q}\\quad (p \\le q) $$\nDefine the partial sum $s_{n}$ of $\\left\\{ a_{n} \\right\\}$ as follows.\n$$ s_{n} = \\sum \\limits_{k=1}^{n} a_{k} $$\nThen, we can think of a sequence $\\left\\{ s_{n} \\right\\}$ of these $s_{n}$. The limit of sequence $\\left\\{ s_{n} \\right\\}$ is called the infinite series or simply, the series of $\\left\\{ a_{n} \\right\\}$, and is denoted as follows.\n$$ \\sum \\limits_{n = 1}^{\\infty} a_{n} = \\lim \\limits_{n \\to \\infty} s_{n} = \\lim\\limits_{n \\to \\infty}\\sum \\limits_{k=1}^{n} a_{k} $$\nIf $\\left\\{ s_{n} \\right\\}$ converges to $s$, it is denoted as follows and the series is said to converge.\n$$ \\sum \\limits_{n = 1}^{\\infty} a_{n} = s $$\nIf $\\left\\{ s_{n} \\right\\}$ does not converge, the series is said to diverge. In the case of divergence,\nIf for every $M \\in \\mathbb{R}$, there exists $N \\in \\mathbb{N}$ such that $n \\ge N \\implies s_{n} \u0026gt; M$ is satisfied, $$ \\sum \\limits_{n = 1}^{\\infty} a_{n} = \\infty $$ it is denoted as follows.\nIf for every $M \\in \\mathbb{R}$, there exists $N \\in \\mathbb{N}$ such that $n \\ge N \\implies x_{n} \u0026lt; M$ is satisfied, $$ \\sum \\limits_{n = 1}^{\\infty} a_{n} = -\\infty $$ it is denoted as follows.\nExplanation A series is a rigorous mathematical definition of the ambiguous concept of adding up infinitely many terms. It is also denoted simply as $\\sum a_{n}$.\nWalter Rudin, Principles of Mathmatical Analysis (3rd Edition, 1976), p59\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":886,"permalink":"https://freshrimpsushi.github.io/en/posts/886/","tags":null,"title":"Series, Infinite Series"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition The range of the random variable $X: \\Omega \\to E$ is called the state space. The set of random variables $\\left\\{ X_{t} \\mid t \\in [ 0 , \\infty ) \\right\\}$ is called a continuous stochastic process. The sequence of random variables $\\left\\{ X_{n} \\mid n = 0, 1, 2, \\cdots \\right\\}$ is called a discrete stochastic process. Explanation The term \u0026lsquo;process\u0026rsquo; in stochastic process often makes the concept difficult to understand because it doesn\u0026rsquo;t quite match the initial definition of a \u0026lsquo;process\u0026rsquo; as we commonly understand it in terms of algorithms or sequences of actions. The reason why it\u0026rsquo;s specifically described as a \u0026lsquo;sequence of random variables\u0026rsquo; or \u0026lsquo;a set of random variables\u0026rsquo; is because, after graduating high school, a sequence is defined as a \u0026lsquo;function whose domain is the set of natural numbers\u0026rsquo;.\nFunction? Sequence? Set? In this sense, a stochastic process is essentially \u0026lsquo;a function that maps random variables to a temporal variable $t$ or $n$. What really matters is \u0026lsquo;when and how does the probability occur?\u0026rsquo;, there\u0026rsquo;s no need to overcomplicate thinking in terms of sets or sequences. People are curious about the probability of it raining today, but they are also interested in the probability of rainfall tomorrow and the day after tomorrow. If we can designate $p ( X_{n} = \\text{ rain } )$ as the probability of rain on D+n, where today is D+0, tomorrow is D+1, and the day after tomorrow is D+2, then you\u0026rsquo;ve perfectly understood the concept of stochastic processes.\nThe study of stochastic processes can be learned at various levels across many majors, and the terminology can vary from one textbook to another. When first getting into the field of stochastic information theory, it\u0026rsquo;s more important to grasp intuitive concepts than to get hung up on precise definitions.\nExamples Gambling Take the Coin Toss GameCash Process, for example. In this game, you toss a coin and gain $1$ points for heads and lose $1$ points for tails. The game ends when the player decides to stop, and if the final score is positive, the player receives a thousand Won per point; if negative, the player owes a thousand Won per point. The score starts at $0$ points.\nFirst, the state space of this game is the set of integers $\\left\\{ \\cdots, (- 2) , (-1) , 0 , 1 , 2 , \\cdots \\right\\}$, which represents the player\u0026rsquo;s score. When the player has tossed the coin $n$ times, the probability that the score is $x$ points is represented by $p( X_{n} = x)$. Especially, if the coin has not been tossed at all, the score is certain to be $0$ points, meaning $p ( X_{0} = 0 ) = 1$ can be stated with certainty.\nHere, $X_{1}$ is either $(-1)$ or $1$, just as $X_{2}$ is one of the three $(-2) , 0 , 2$. As the number of trials $n$ changes, the random variable $X_{n}$ changes too.\nSimulating the above game demonstrates how the scores fluctuate randomly, a phenomenon known as Brownian Motion. If one had quit after $10$ rounds, they would have won two thousand Won, but quitting around $400$ rounds would have resulted in a significant loss, and quitting around $900$ rounds would have led to a substantial win.\nStudy of stochastic processes can also provide answers to \u0026lsquo;when is the best time to quit?\u0026rsquo;. Everyone wonders about when the next opportunity will come or how much risk they\u0026rsquo;re taking, especially if they achieved a reasonable goal and are tempted to try their luck further.\nStocks Another example is the stock market.\nOf course, stock movements are not entirely random. However, predicting the trend a year from now by looking at charts like the above is incredibly difficult. Studying stochastic processes is not about becoming a chartist but rather the opposite. Understanding what affects price fluctuations, quickly acquiring information, and creating accurate models can guarantee a worry-free life if kept personal (though, of course, this is impossible).\nMathematically, stochastic processes can also be viewed as nondeterministic dynamical systems.\nCode Below is an example code for simulating the cash process using R.\nset.seed(150421)\rtoss\u0026lt;-sample(c(-1,1),10,replace=T)\rwin.graph(4,4)\rplot(cumsum(toss),type=\u0026#39;l\u0026#39;,main=\u0026#39;10Ìöå Î∞òÎ≥µ\u0026#39;)\rabline(h=0)\rtoss\u0026lt;-sample(c(-1,1),1000,replace=T)\rwin.graph(4,4)\rplot(cumsum(toss),type=\u0026#39;l\u0026#39;,main=\u0026#39;1000Ìöå Î∞òÎ≥µ\u0026#39;)\rabline(h=0) ","id":857,"permalink":"https://freshrimpsushi.github.io/en/posts/857/","tags":["R"],"title":"What is a Stochastic Process?"},{"categories":"ÎèôÏó≠Ìïô","contents":"Definitions1 A function $f : X \\to X$ whose domain and codomain are the same is called a Map. A map that is the composition of $f$ $k$ times is denoted as $f^{k}$. $p \\in X$ that satisfies $f(p) = p$ is called a Fixed Point. If there exists a $\\epsilon \u0026gt; 0$ that satisfies $\\displaystyle \\lim_{k \\to \\infty} f^{k} (x) = p$ for all $x \\in N_{ \\epsilon } ( p )$, then the fixed point $p$ is called a Sink. If there exists a $\\epsilon \u0026gt; 0$ that satisfies $f^{ \\infty } (x) \\notin N_{\\epsilon } (p)$ for all $x \\in N_{\\epsilon } (p)$ except $p$, then the fixed point $p$ is referred to as a Source. $N_{ \\epsilon } ( p ) = B ( p ; \\epsilon )$ refers to the neighborhood containing all points within the radius $\\epsilon$ of $p$. Examples The map defined by $X$ forms a dynamical system by mapping each point $x_{t-1}$ to $x_{t}$. A simple example is a point that moves $60$ in direction $x$ whenever time $t$ changes by $1$. The position of this point can be represented as follows. $$ x_{t} = f(x_{t-1}) = x_{t-1} + 60 $$ Another example of a map is $f(x) = x^3$, which means that $0$ and $\\pm 1$ are fixed points. Among them, every number in the sufficiently small interval $( - 1, 1)$ including $0$ becomes smaller when squared and eventually converges to $0$, making it a sink. Thinking of any interval that includes $\\pm 1$, if its size is greater than $1$, the magnitude increases each time it is cubed, making it a source. A sink is a sort of \u0026lsquo;convergence point\u0026rsquo; where nearby points gather, while a source is a sort of \u0026lsquo;divergence point\u0026rsquo; where points that were close begin to move away from each other. Therefore, a sink is also called a Stable fixed point, and a source is called an Unstable fixed point.\nThis is similar to the sink and source in graph theory.\nSee Also Dynamical systems expressed by maps Dynamical systems expressed by differential equations Rigorous definition of dynamical systems Yorke. (1996). CHAOS: An Introduction to Dynamical Systems: p5, 9.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":856,"permalink":"https://freshrimpsushi.github.io/en/posts/856/","tags":null,"title":"Representing Dynamical Systems and Fixed Points with Maps"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÍ≤ÄÏ†ï","contents":"Hypothesis Testing Let\u0026rsquo;s refer to the model obtained through logistic regression as $M$.\n$H_{0}$: $M$ is appropriate. $H_{1}$: $M$ is not appropriate. Description The Hosmer-Lemeshow goodness of fit test is a representative hypothesis test used to determine the adequacy of logistic regression models.\nAlthough it\u0026rsquo;s a very simple test, the null hypothesis and the alternative hypothesis can be confusing. While it‚Äôs true that there is no good or bad in hypothesis testing, honestly speaking, if you are performing regression analysis, it\u0026rsquo;s usually to understand some correlation, and thus, one hopes to reject the null hypothesis of the F-test. This aspect is similar in t-tests, where learners familiar enough with regression analysis to study logistic regression end up adopting the non-intuitive intuition that \u0026lsquo;a smaller p-value equals success\u0026rsquo;.\nTherefore, there can be moments of surprise when the results of the Hosmer-Lemeshow goodness of fit test deviate from \u0026rsquo;that intuition\u0026rsquo;, despite the analysis being properly conducted. This is why it\u0026rsquo;s necessary to precisely check what the null hypothesis and the alternative hypothesis are.\nCaution Recently, weaknesses of the Hosmer-Lemeshow goodness of fit test have been pointed out , and it is said to be not highly recommended1.\nSee Also Logistic regression How to conduct a Hosmer-Lemeshow test in R https://twitter.com/f2harrell/status/1228423023834718208\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":852,"permalink":"https://freshrimpsushi.github.io/en/posts/852/","tags":null,"title":"Hosmer-Lemeshow Goodness of Fit Test"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definitions 1 In an integral domain $D$, if there exists a Euclidean norm $\\nu : D \\setminus \\left\\{ 0 \\right\\} \\to \\mathbb{N}_{0}$ that satisfies the following two conditions, then $D$ is called a Euclidean domain:\n(i): For all $a,b \\in D (b \\ne 0 )$, there exists $q$ and $r$ such that $$ a = bq + r $$ is satisfied. In this case, either $r = 0$ or $\\nu (r) \u0026lt; \\nu (b)$ must hold. (ii): For all $a,b \\in D (b \\ne 0 )$, $\\nu ( a ) \\le \\nu ( ab )$ $\\mathbb{N}_{0}$ denotes the set including the natural numbers along with $0$. Theorems Let the identity of a Euclidean domain $D$ be $0$, the unit element $1$, and the Euclidean norm $\\nu$.\n[1]: Every ED is a PID. [2]: Every ED is a UFD. [3]: For all $d \\in D$ not equal to $0$, $\\nu (1) \\le \\nu (d)$ [4]: $u \\in D$ is a unit element $\\iff$ $\\nu ( u ) = \\nu (1)$ PID refers to a principal ideal domain, while UFD indicates a unique factorization domain. The unit element is the identity for multiplication $1$, and a unit is an element with a multiplicative inverse. Explanations The term \u0026ldquo;Euclidean domain\u0026rdquo; may not be very long, but the abbreviation ED is often used.\nConditions (i) and (ii) are naturally satisfied in the ring of integers $\\mathbb{Z}$, making it a Euclidean domain because there exists a Euclidean norm $\\nu ( n ) := | n |$. Originally, the term Euclidean norm is derived from the Euclidean algorithm in number theory.\nConsidering a field $F$ and $F [ x ]$, it becomes a Euclidean domain by defining a Euclidean norm $\\nu ( f(x) ) : = \\deg ( f(x) )$. The division theorem applies to this condition.\nDiagramming various domains like above easily shows how many favorable properties ED has.\nProofs [1] Let\u0026rsquo;s refer to an ideal of $D$ as $N$.\n$N = \\left\\{ 0 \\right\\} = \\left\u0026lt; 0 \\right\u0026gt;$ is naturally a principal ideal, so let\u0026rsquo;s consider $N \\ne \\left\\{ 0 \\right\\}$.\nFor all $n \\in N$ not equal to $0$, one can find $b \\ne 0$ that satisfies $$ \\nu (b) \\le \\nu (n) $$ . If we call this $a \\in N$, then by condition (i) $$ a = b q + r $$ must exist $q,r \\in D$. Since $N = Nq$ is an ideal, $r = a - bq$ is also an element existing in $N$. $b$ being the element that minimizes $\\nu (b)$ implies that according to condition (ii), it must be $r=0$. That all elements $a \\in N$ are represented as $a = bq$ means $N = \\left\u0026lt; b \\right\u0026gt;$, hence all ideals $N$ are principal ideals.\n‚ñ†\n[2] Since ED is a PID, and PID is UFD, hence ED is UFD.\n‚ñ†\n[3] By condition (ii), $$ \\nu (1) \\le \\nu ( 1 d) = \\nu (d) $$\n‚ñ†\n[4] $( \\implies )$\nSince $u$ is a unit, its inverse $u^{-1}$ exists so $$ \\nu ( u ) \\le \\nu ( u u^{-1} ) = \\nu (1) $$ and by theorem [3], $\\nu (1) \\le \\nu (1)$ thus $$ \\nu ( u ) = \\nu (1) $$\n$( \\impliedby )$\nIf we let $1 = uq + r$, then by theorem [2], $\\nu ( u) = \\nu (1)$ is the smallest except for $\\nu (0)$. Since theorem [3] states that $\\nu ( r) \u0026lt; \\nu (u)$ satisfies only if $r=0$, $1 = uq$, and $u$ becomes a unit.\n‚ñ†\nSee also Euclidean domain $\\implies$ Principal ideal domain $\\implies$ Unique factorization domain $\\implies$ Integral domain Euclidean domain $\\implies$ Principal ideal domain $\\implies$ Noetherian ring Fraleigh. (2003). A first course in abstract algebra(7th Edition): p401.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":838,"permalink":"https://freshrimpsushi.github.io/en/posts/838/","tags":null,"title":"Euclidean Geometry"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Buildup Let\u0026rsquo;s think about performing $Y \\gets X_{1} , \\cdots, X_{p}$. Here, $Y$ can be a categorical variable, particularly one with only two classes, such as male and female, success and failure, positive and negative, $0$ and $1$, etc. For convenience, let\u0026rsquo;s just call it $Y=0$ or $Y=1$. In cases where the dependent variable is binary, the interest is \u0026lsquo;what is $Y$ when we look at independent variables $ X_{1} , \\cdots X_{p}$\u0026rsquo;.\nHowever, since $Y$ is a qualitative variable, it cannot be expressed by the linear combination $y = \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}$ of regression coefficients and variables as in ordinary regression analysis. Therefore, we aim to approach it by calculating the probability that it is $Y=1$.\nGiven $X=x$, let\u0026rsquo;s set the probability that it is $Y=1$ as follows: $$\\displaystyle \\pi := P ( Y = 1 | X = x ) = {{ e^{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}} } \\over { 1+ e^{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}} }}$$\n(i) The exponential function is always greater than $0$, and since the denominator is greater than the numerator in $\\pi$, it is $ 0 \u0026lt; \\pi \u0026lt; 1$. (ii) Naturally, the probability that it is $Y = 0$ is $$ \\begin{align*} 1 - \\pi =\u0026amp; P ( Y = 0 | X = x ) \\\\ =\u0026amp; 1 - {{ e^{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}} } \\over { 1+ e^{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}} }} \\\\ =\u0026amp; {{ 1 } \\over { 1+ e^{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}} }} \\end{align*} $$ and thus $$\\displaystyle { { \\pi } \\over { 1 - \\pi } } = { { \\displaystyle {{ e^{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}} } \\over { 1+ e^{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}} }} } \\over { \\displaystyle {{ 1 } \\over { 1+ e^{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}} }} } } = e^{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}} $$. Taking the natural log of both sides gives us $$\\displaystyle \\ln \\left( { { \\pi } \\over { 1 - \\pi } } \\right) = \\beta_{0} + \\beta_{1} x_{1} + \\cdots \\beta_{p} x_{p}$$. Taking the log in this way is called a Logit Transformation, and $\\displaystyle \\ln \\left( { { \\pi } \\over { 1 - \\pi } } \\right)$ is referred to as the Logit.\nModel 1 A multiple regression analysis $\\displaystyle \\ln \\left( { { \\pi } \\over { 1 - \\pi } } \\right) \\gets X_{1} , \\cdots, X_{p}$ that takes the logit as the dependent variable is called Logistic Regression.\nBy applying the inverse transformation of the logit transformation to the values obtained from the logistic model, we can obtain the original probabilities $\\pi$ we wanted to know. When a coefficient $\\beta_{i}$ of $X_{i}$ is positive, it means that as $X_{i}$ increases, the probability of $Y=1$ increases, and a negative coefficient means that as $X_{i}$ increases, the probability of $Y=0$ increases.\nMoreover, logistic regression can also be a classification technique by suggesting an appropriate Threshold for the probability, although it is also a prediction technique as it informs the probability of outcomes given certain conditions.\nSee Also The reason it is called logistic is due to the use of the logistic function. Results of logistic regression analysis in R Hosmer-Lemeshow goodness-of-fit test Multiple regression analysis Hadi. (2006). Regression Analysis by Example(4th Edition): p318~320.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":832,"permalink":"https://freshrimpsushi.github.io/en/posts/832/","tags":null,"title":"Logistic Regression"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definitions 1 A domain $D$, that is neither $0$ nor a field, in which every element (except for 0 and units) has a unique factorization into irreducible elements is said to be a Unique Factorization Domain. In a Unique Factorization Domain $D$, for $a_{1} , \\cdots , a_{n}$ if $d \\mid a_{i}$ and every divisor of $a_{i}$ divides $d$, then $d$ is called the Greatest Common Divisor of $a_{1} , \\cdots , a_{n}$, denoted by $\\gcd$. Let a polynomial in a Unique Factorization Domain $D$ be denoted by $f(x) := a_{0} + a_{1} x + \\cdots + a_{n} x^{n}$. If $\\gcd ( a_{0} , a_{1} , \\cdots , a_{n} ) = 1$, then $f(x) \\in D [ x ]$ is said to be Primitive. A unit is the identity element $1$ with respect to multiplication, and a field element is an element that has a multiplicative inverse. Theorems 2 [1]: Every PID is a UFD. [2] Fundamental Theorem of Arithmetic: $\\mathbb{Z}$ is a UFD. [3] Gauss\u0026rsquo;s Lemma: If $D$ is a UFD, then the product of primitive polynomials in $D [ x ]$ is also primitive. [4]: If $D$ is a UFD, then $D [ x ]$ is also a UFD. [5]: If $F$ is a field, then $F[ x_{1} , \\cdots , x_{n} ]$ is a UFD. Explanation The term \u0026ldquo;Unique Factorization Domain\u0026rdquo; is often shortened to UFD because it\u0026rsquo;s quite lengthy.\nUFD The existence of a finite factorization of elements means that a given element can be represented as a product of a finite number of irreducible elements. The utility of UFDs lies in the ability to decompose larger objects into more manageable pieces. Even if we cannot specifically identify these components in all cases, the mere existence of such factorization is greatly helpful. It makes the domain conform to our \u0026ldquo;common sense\u0026rdquo; of computation.\nThere are many examples of UFDs. For instance, as mentioned in Theorem [2], the ring of integers $\\mathbb{Z}$ is one. However, consider a simple extension field $\\mathbb{Z} ( \\sqrt{ - 5 } )$ obtained by adding $\\sqrt{-5}$ to the ring of integers. Here, while $21 \\in \\mathbb{Z} ( \\sqrt{ - 5 } )$ has a prime factorization $21 = 3 \\cdot 7$, $21 = ( 1 + 2 \\sqrt{-5}) ( 1 - 2 \\sqrt{-5}) $ is also possible making the factorization not unique, and we can easily verify that $\\mathbb{Z} ( \\sqrt{ - 5 } )$ is not a Unique Factorization Domain.\nPrimitive Function? Being primitive in this context has nothing to do with the notion of a primitive function in calculus, which refers to not being able to factor out coefficients uniformly across the polynomial, unlike being able to encapsulate $(3 x^2 + 6 x + 3) \\in \\mathbb{Z} [ x ]$ as $3 ( x^2 + 2x + 1)$.\nFundamental Theorem of Arithmetic Unlike the statement in number theory, the fact that the ring of integers $\\mathbb{Z}$ is a UFD is summarized here. Obviously, a myriad of concepts are mobilized for this declaration, but higher-level number theory often expresses such ideas in algebraic terminologies, making the study of algebra indispensable. Even if one does not major in algebra, lacking knowledge in it is like being in the dark.\nGauss\u0026rsquo;s Lemma Gauss\u0026rsquo;s Lemma is more interesting than one might think. For example, considering $(5x + 1) , (2x^2 + 3x + 1) \\in \\mathbb{Z} [ x ]$, its product is $( 10 x^3 + 17 x^2 + 8 x + 1 )$, which can\u0026rsquo;t obviously be factored by some greatest common divisor $a \\in \\mathbb{Z}$. One might expect to stumble upon at least one counter-example eventually, but thanks to Gauss\u0026rsquo;s Lemma, such futile efforts are unnecessary.\nProof [1] Part 1. Existence\nIf $D$ is a PID, then $d \\in D$ can be expressed as a finite product of irreducible elements $p_{1} , \\cdots , p_{r}$, like so $a = p_{1} \\cdots p_{r}$.\nPart 2. Uniqueness\nSuppose there are other irreducible elements $q_{1} , \\cdots , q_{s}$ such that $a = q_{1} \\cdots q_{s}$ is also possible.\nSince irreducible elements in a PID are prime, for some $1 \\le j \\le s$, $p_{1} \\mid q_{j}$ must hold. $$ p_{1} p_{2} \\cdots p_{r} = p_{1} u_{1} q_{2} \\cdots q_{s} $$ Cancelling $p_{1}$ from both sides gives $$ p_{2} \\cdots p_{r} = u_{1} q_{2} \\cdots q_{s} $$ Repeatedly applying the same logic up to $i=r$ yields $$ 1 = u_{1} \\cdots u_{r} q_{r+1} \\cdots q_{s} $$ Since $q_{r+1} \\cdots q_{s}$ is irreducible, it must divide $r=s$.\n‚ñ†\n[2] Every ideal of $\\mathbb{Z}$ is of the form $\\left\u0026lt; n \\right\u0026gt; = n \\mathbb{Z}$, making it a PID, and by Theorem [1], a UFD.\n‚ñ†\n[3] $$ \\begin{align*} f(x) \u0026amp;:= a_{0} + a_{1} x + \\cdots + a_{n} x^n \\\\ g(x) \u0026amp;:= b_{0} + b_{1} x + \\cdots + b_{m} x^m \\end{align*} $$ Consider primitive polynomials $f(x) , g(x) \\in D[x]$ as shown above.\nLet $p \\in D$ be an irreducible element.\nSince $f(x)$ is primitive, $\\gcd ( a_{0} , \\cdots , a_{n} ) = 1$, and $p$ can\u0026rsquo;t divide all of $a_{0} , \\cdots , a_{n}$. Let the first coefficient that $p$ fails to divide among those be $a_{r}$. Similarly, since $g(x)$ is primitive, $\\gcd ( b_{0} , \\cdots , b_{m} ) = 1$, and $p$ can\u0026rsquo;t divide all of $b_{0} , \\cdots , b_{m}$. Let the first coefficient that $p$ fails to divide among those be $b_{s}$. Then the coefficient of the $( r + s)$ term of $f(x)g(x)$ is $$ c_{r+s} = ( a_{0} b_{r+s} + \\cdots + a_{r-1} b_{s+1} ) + a_{r} b_{s} + ( a_{r+1} b_{s-1} + \\cdots + a_{r+s} b_{0} ) $$ And by definition,\nfor $a_{r}$: $$ p \\mid ( a_{0} b_{r+s} + \\cdots + a_{r-1} b_{s+1} ) $$ for $b_{s}$: $$ p \\mid ( a_{r+1} b_{s-1} + \\cdots + a_{r+s} b_{0} ) $$ However, since $p \\nmid a_{r} b_{s}$, the given $p$ can\u0026rsquo;t divide $f(x) g(x)$. The same applies to all irreducible elements, making $f(x) g(x)$ primitive.\n‚ñ†\n[4] Let the degree of $f(x) \\in D[x]$ be $n$.\nThen, $f(x)$ can be factored into $$ f (x) = g_{1} (x) \\cdots g_{r} (x)) $$ And for each $i = 1 , \\cdots , r$, the factors can be expressed as the product of a primitive function $h_{i} (x) \\in D[x]$ and $c_{i} \\in D$, as in $$ g_{i} (x) = c_{i} h_{i} (x) $$ This $c_{i}$ is called the Content of $g_{i} (x)$, leading to $$ f(x) = c_{1} h_{1} (x) \\cdots c_{r} h_{r} (x) $$ Since the content is unique for given $g_{i} (x)$ and $h_{i} (x)$, the factorization of $f(x)$ is unique disregarding the order and scalar multiplication of factors.\n‚ñ†\n[5] Factorization of Polynomials:\n[2]: If $F$ is a field, all non-constant polynomials $f(x) \\in F [ x ]$ can be factored into irreducible elements, and this factorization is unique. By the definition of UFD, $F [x_{1} ]$ is a UFD, and by Theorem [4], $F [ x_{1} , x_{2} ]$ is also a UFD. Repeating this for a finite number of $x_{3} , \\cdots , x_{n}$ leads to the conclusion that $F[ x_{1} , \\cdots , x_{n} ]$ is a UFD.\n‚ñ†\nSee Also Euclidean Domain $\\implies$ Principal Ideal Domain $\\implies$ Unique Factorization Domain $\\implies$ Integrally Closed Domain Fraleigh. (2003). A first course in abstract algebra(7th Edition): p390, 395~396.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p394~399.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":827,"permalink":"https://freshrimpsushi.github.io/en/posts/827/","tags":null,"title":"Unique Factorization Domain"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Overview The problem of variable selection inevitably involves the subjectivity of the analyst, but a numerical indicator that helps draw as objective a conclusion as possible was needed. If such values could be calculated, it would provide a clear answer to when to stop the variable selection procedure. However, there are various types of criteria, and applying different criteria can lead to different results.\nIndicators [^1] Explained Variance $R^2$ The explained variance is calculated by $\\displaystyle R^2 = 1 - {{ \\text{ SSE } } \\over { \\text{ SST} }}$ and can be interpreted that the closer it is to $1$, the better the model explains the data.\nHowever, as a criterion for variable selection, it is not appropriate if the number of independent variables differs among the compared models.\nAdjusted Explained Variance $R_{a}^2$ In regression analysis, increasing the number of variables means there is more data available, and the explained variance $R^{2}$ will always increase. In contrast, the adjusted explained variance is calculated by $\\displaystyle R^{2}_{a} = 1 - {{ \\text{ SSE } / (n - p - 1) } \\over { \\text{ SST} / (n - 1) }}$, reflecting the number of variables.\nThe adjusted explained variance $R^{2}_{a}$ applies a penalty for the number of variables, overcoming the drawback of explained variance, which becomes meaningless when the number of variables differs. Although not a popular criterion for variable selection, it is an indispensable indicator since, unlike other criteria that are relative and only meaningful when comparing models, the adjusted explained variance also indicates how well a model explains the data on its own. It can be useful if one is looking for the model with the highest explanatory power, not necessarily the optimal model.\nAkaike Information Criterion $\\text{AIC}_{p}$ For $p$ independent variables, the Akaike Information Criterion is calculated by $\\displaystyle \\text{AIC}_{p} := n \\ln \\left( {{ \\text{SSE}_{p} } \\over {n}} \\right) + 2(p+1) $. AIC is the most favored metric in actual analysis, judging the model with the lower AIC as better.\nThe second term in the formula applies a penalty as $p$ increases, meaning the more variables there are. A downside of AIC is that comparisons become inaccurate when the sample $n$ differs. It might seem odd that $n$ could differ when analyzing with the same data but changing only the variables; however, this can be a critical issue if certain variables have many missing values.\nBayes Information Criterion $\\text{ BIC }_{p}$ For $p$ independent variables, the Bayes Information Criterion is calculated by $\\displaystyle \\text{BIC}_{p} := n \\ln \\left( {{ \\text{SSE}_{p} } \\over {n}} \\right) + ( p +1 ) \\ln n $. Similar to AIC, but with a modified last term, it complements AIC, and likewise, the lower value is considered better.\nMallows $C_{p}$ For $p$ independent variables, Mallows $C_{p}$ is calculated by $\\displaystyle C_{p} := {{ \\text{SSE}_{p} } \\over { \\hat{\\sigma}^2 }} + ( 2p - n )$.\n$C_{p}$ selects variables in a direction with less bias, and it is considered better as it gets closer to $C_{p} \\approx p$. It means there is less bias. If an analysis that must be cautious about bias is being conducted, it would be useful and mathematically neat, but recently, techniques that reduce variance significantly, even at the cost of some bias, to finely tune the fitting have been gaining popularity, making it less popular.\n","id":826,"permalink":"https://freshrimpsushi.github.io/en/posts/826/","tags":null,"title":"Variable Selection Criteria in Statistical Analysis"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 Let\u0026rsquo;s assume that the $p \\ne 0$ of the integral domain $D$ is not a field.\nPID An integral domain $D$ is called a Principal Ideal Domain (PID) if every ideal in $D$ is a principal ideal.\nConsequent Definitions Let\u0026rsquo;s say a commutative ring $R$ has a unity $1$. If for $a,b \\in R$ there exists $c \\in R$ that satisfies $b=ac$, then $a$ divides $b$ or $a$ is a factor of $b$, denoted as $a \\mid b$. If $a \\mid b$ and $b \\mid a$, then $a,b$ are called associates. For $\\forall a,b \\in D$ and $p=ab$, if one of $a$ or $b$ is a unit, then $p$ is called an irreducible element. For $\\forall a,b \\in D$, if $p \\mid ab$, then $p$ is called a prime element, which is either $p \\mid a$ or $p \\mid b$. A unity is the multiplicative identity $1$, a unit is an element with a multiplicative inverse. Theorem 2 Let\u0026rsquo;s assume $D$ is a principal ideal domain.\n[1]: $D$ is a Noetherian ring. [2]: Every element in $D$ that is neither $0$ nor a unit can be expressed as a product of irreducible elements of $D$. [3]: If $\\left\u0026lt; p \\right\u0026gt;$ is a maximal ideal of $D$ and $p$ is an irreducible element in $D$. [4]: Every irreducible element in $D$ is a prime element. Explanation The term \u0026ldquo;Principal Ideal Domain\u0026rdquo; is often abbreviated as PID due to its length.\nNote that associative in \u0026ldquo;associates\u0026rdquo; shares the same spelling with associative in \u0026ldquo;associative property\u0026rdquo; but is a noun, indicating a relation where two elements can be expressed as products of a unit.\nExamples Integer Ring $\\mathbb{Z}$ In the integer ring $\\mathbb{Z}$, all ideals can be expressed as principal ideals like $n \\mathbb{Z} = \\left\u0026lt; n \\right\u0026gt;$.\nAll Fields $\\mathbb{F}$ Gaussian Integer Ring $\\mathbb{Z} [i]$ and Eisenstein Integer Ring $\\mathbb{Z} [\\omega]$ The Gaussian integer ring and the Eisenstein integer ring are rings formed by adding the imaginary unit $i := \\sqrt{-1}$ or $\\omega := (-1)^{1/3}$ to the integer ring $\\mathbb{Z}$, respectively.\nProof [1] Definition of Noetherian Ring: Let\u0026rsquo;s consider a ring $N$.\nAn ascending chain $\\left\\{ S_{i} \\right\\}_{i \\in \\mathbb{N} }$ of ideals in $N$ that satisfies $S_{1} \\le S_{2} \\le \\cdots$ is called an Ascending Chain. If for an ascending chain $\\left\\{ S_{i} \\right\\}_{i \\in \\mathbb{N} }$, there exists $n \\in \\mathbb{n}$ satisfying $S_{n} = S_{n+1} = \\cdots$, it is called Stationary. Meaning, at some point, the ideals in the chain no longer increase. A ring in which every ascending chain of ideals is stationary is called a Noetherian Ring. Consider an ascending chain of ideals $N_{1} \\le N_{2} \\le \\cdots$ in $D$ and its union $\\displaystyle N := \\bigcup_{k=1}^{ \\infty } N_{k}$. For some $i, j \\in \\mathbb{N}$, if we assume $$ a \\in N_{i} \\\\ b \\in N_{j} \\\\ N_{i} \\le N_{j} $$, then $( N_{j} , + , \\cdot )$, defined as an ideal, is a subring, and there exists an additive inverse $(-b) \\in N_{j}$ for $b$. Since $ab \\in N_{j}$, we have $(a-b), ab \\in N$, and by the subring test, $N$ is a subring of $D$. Moreover, since $N_{i}$ is an ideal, for all $d \\in D$, $d a = a d$ holds, and because of $da \\in N$, $N$ is an ideal of $D$.\nSince $D$ is a PID, all ideals are principal ideals, and for some $c \\in N$, it can be expressed as $N = \\left\u0026lt; c \\right\u0026gt;$. Here, since $\\displaystyle N = \\bigcup_{k=1}^{ \\infty } N_{k}$, if $c \\in N$, then a natural number $r \\in \\mathbb{N}$ exists satisfying $c \\in N_{r}$. $c \\in N_{r}$ implies the existence of a principal ideal smaller than $c$ with $c$ as its generator. Mathematically, $$ \\left\u0026lt; c \\right\u0026gt; \\le N_{r} \\le N_{r+1} \\le \\cdots \\le N = \\left\u0026lt; c \\right\u0026gt; $$, leading to $N_{r} = N_{r+1} = \\cdots$. Hence, $D$ is a Noetherian ring.\n‚ñ†\n[2] If $d$ is an irreducible element, there is nothing to prove. Assuming a non-unit element $d_{1}, c_{1} \\in D$, let\u0026rsquo;s express it as $d = d_{1} c_{1}$.\nThen $\\left\u0026lt; d \\right\u0026gt; \\le \\left\u0026lt; d_{1} \\right\u0026gt;$, and by continually defining $d_{i} := d_{i+1} c_{i+1}$, we get an ascending chain $$ \\left\u0026lt; d \\right\u0026gt; \\le \\left\u0026lt; d_{1} \\right\u0026gt; \\le \\left\u0026lt; d_{2} \\right\u0026gt; \\le \\cdots $$. However, according to theorem [1], there must exist an end $a_{r}$ to this chain, and $a_{r}$ simultaneously becomes an irreducible factor of $a$. By setting the irreducible element dividing $d$ as $p_{1}$ and considering a non-unit element $f_{1}$ such that $d = p_{1} f_{1}$, we have $\\left\u0026lt; d \\right\u0026gt; \\le \\left\u0026lt; f_{1} \\right\u0026gt;$, and by continually defining $f_{i} := p_{i+1} f_{i+1}$, we get an ascending chain $$ \\left\u0026lt; d \\right\u0026gt; \\le \\left\u0026lt; f_{1} \\right\u0026gt; \\le \\left\u0026lt; f_{2} \\right\u0026gt; \\le \\cdots $$. This chain must also end at some point $f_{s}$ according to theorem [1], making $f_{s}$ an irreducible factor of $f_{i}$.\nThis process, repeated a finite number of times, confirms that $d$ can be expressed as a product of irreducible elements.\n‚ñ†\n[3] $( \\implies )$\nAssuming that $p$, an irreducible element, is expressed as $p=ab$ with respect to a maximal ideal $\\left\u0026lt; p \\right\u0026gt;$ of $D$ and a non-unit element $a,b$.\nThen $\\left\u0026lt; p \\right\u0026gt; \\le \\left\u0026lt; a \\right\u0026gt;$, but if $\\left\u0026lt; p \\right\u0026gt; = \\left\u0026lt; a \\right\u0026gt;$, then $b$ must be a unit, leading to the actuality of $\\left\u0026lt; p \\right\u0026gt; \\lneq \\left\u0026lt; a \\right\u0026gt;$. Since $\\left\u0026lt; p \\right\u0026gt;$ is a maximal ideal, it must be $\\left\u0026lt; a \\right\u0026gt; = D = \\left\u0026lt; 1 \\right\u0026gt;$, making $a$ and $1$ associates. In summary:\nIf $\\left\u0026lt; p \\right\u0026gt; \\ne \\left\u0026lt; a \\right\u0026gt;$, then $a$ is a unit, and If $\\left\u0026lt; p \\right\u0026gt; = \\left\u0026lt; a \\right\u0026gt;$, then $b$ is a unit, making $p$ an irreducible element by necessity.\n$( \\impliedby )$\nAssuming a prime element $p=ab$ and $\\left\u0026lt; p \\right\u0026gt; \\le \\left\u0026lt; a \\right\u0026gt;$,\nIf $a$ is a unit, then $\\left\u0026lt; a \\right\u0026gt; = D$, causing no issues, but if $a$ is not a unit, then $b$ must necessarily be a unit.\nIf $b$ is a unit, it means for some $u \\in D$, $bu =1$ holds, and since $$ pu = abu = a $$, we get $\\left\u0026lt; p \\right\u0026gt; \\ge \\left\u0026lt; a \\right\u0026gt;$, meaning $\\left\u0026lt; p \\right\u0026gt; = \\left\u0026lt; a \\right\u0026gt;$ must hold. In summary:\nEither $\\left\u0026lt; a \\right\u0026gt; = D$ must hold or $\\left\u0026lt; a \\right\u0026gt; = \\left\u0026lt; p \\right\u0026gt;$ must hold, making $\\left\u0026lt; p \\right\u0026gt;$ a maximal ideal.\n‚ñ†\n[4] If $p$ is an irreducible element, then $\\left\u0026lt; p \\right\u0026gt;$, by theorem [3], is a maximal ideal and hence a prime ideal.\nIf $p$ divides $ab$, then $(ab) \\in \\left\u0026lt; p \\right\u0026gt;$ holds, and since $\\left\u0026lt; p \\right\u0026gt;$ is a prime ideal, either $a \\in \\left\u0026lt; p \\right\u0026gt;$ or $b \\in \\left\u0026lt; p \\right\u0026gt;$ holds. Rewritten differently, if $p \\mid ab$, then either $p \\mid a$ or $p \\mid b$, making $p$ a prime element.\n‚ñ†\nSee Also Euclidean Domain $\\implies$ Principal Ideal Domain $\\implies$ Unique Factorization Domain $\\implies$ Integral Domain Euclidean Domain $\\implies$ Principal Ideal Domain $\\implies$ Noetherian Ring Fraleigh. (2003). A first course in abstract algebra (7th Edition): p389~391, 394.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFraleigh. (2003). A first course in abstract algebra (7th Edition): p392~393.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":825,"permalink":"https://freshrimpsushi.github.io/en/posts/825/","tags":null,"title":"Principal Ideal Domain"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition $N$ is referred to as a ring.\nWhen the ideals of $N$ satisfy $S_{1} \\le S_{2} \\le \\cdots$, it is called an Ascending Chain. For the ascending chain $\\left\\{ S_{i} \\right\\}_{i \\in \\mathbb{N} }$, if there exists $n \\in \\mathbb{n}$ that satisfies $S_{n} = S_{n+1} = \\cdots$, it is said to be Stationary. In other words, in a stationary ascending chain, the ideal does not increase any further from a certain point onwards. A ring in which all ascending chains are stationary is called a Noetherian ring. Conversely, for chains that decrease gradually, the term Descending is used. Explanation Chains are not a concept exclusive to ideals, and in set theory, they are dealt with much more rigorously and generally by defining partially ordered sets or relations. However, the place where ascending chains are usually needed is in algebra, and there is no need to understand it in such a complicated way in algebra.\nThe existence of the largest thing in a certain repetitive structure within a finite place is not as obvious as it might seem. Therefore, the condition of being a Noetherian ring is a very favorable one, and the following famous theorem has been applied in various fields.\nHilbert\u0026rsquo;s Basis Theorem If $N$ is a Noetherian ring, then $N [ x_{1} , \\cdots , x_{n} ]$ is also a Noetherian ring.\nSee Also Euclidean domain $\\implies$ Principal ideal domain $\\implies$ Noetherian ring ","id":823,"permalink":"https://freshrimpsushi.github.io/en/posts/823/","tags":null,"title":"Brain Ventricular Enlargement"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Overview Think about performing Multiple Regression Analysis $Y \\gets X_{1} , \\cdots, X_{p}$. Principal Component Analysis, abbreviated as PCA in English, is, in simple terms, a method of \u0026lsquo;restructuring\u0026rsquo; quantitative variables so that they are properly independent for analysis. From the perspective of multivariate data analysis, it has the significance of \u0026lsquo;dimension reduction\u0026rsquo; as a means to explain phenomena with fewer variables.\nTo properly understand the theoretical derivation of principal component analysis, knowledge of Linear Algebra, and if possible, Numerical Linear Algebra is required. If it\u0026rsquo;s completely confusing, try reading and understanding Steps 3 and 4 as well. If you\u0026rsquo;re somewhat confident in Mathematical Statistics, it would also be good to read the post on Principal Component Analysis in Mathematical Statistics.\nDerivation 1 Step 1. Data with $p$ independent variables and $n$ samples standardized\n$$ \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; x_{11} \u0026amp; \\cdots \u0026amp; x_{1p} \\\\ 1 \u0026amp; x_{21} \u0026amp; \\cdots \u0026amp; x_{2p} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 1 \u0026amp; x_{n1} \u0026amp; \\cdots \u0026amp; x_{np} \\end{bmatrix} \\begin{bmatrix} \\beta_{0} \\\\ \\beta_{1} \\\\ \\vdots \\\\ \\beta_{p} \\end{bmatrix} $$\ncan be expressed as $Y = X \\beta + \\varepsilon$ using the design matrix. Here, a matrix $X$ standardized to matrix $Z$ means for the $j$th independent variable $X_{j}$, its sample mean $\\overline{ x_{j} }$ and sample standard deviation $s_{ X_{j} }$, the $(i,j)$-component is\n$$ \\left( Z \\right)_{ij}: = {{ x_{ij} } - \\overline{ x_{j} } \\over { s_{ X_{j} } }} $$\n. Then, for the new regression coefficient\n$$ \\Theta := \\begin{bmatrix} \\theta_{1} \\\\ \\theta_{2} \\\\ \\vdots \\\\ \\theta_{p} \\end{bmatrix} $$\n, we can obtain the design matrix equation for regression analysis without an intercept as $Y = Z \\Theta + \\varepsilon$. This $Z = \\begin{bmatrix} Z_{1} \u0026amp; \\cdots \u0026amp; Z_{p} \\end{bmatrix}$ becomes a matrix $( n \\times p )$ consisting of vector $X_{1} , \\cdots , X_{p}$ standardized to $Z_{1} , \\cdots , Z_{p}$.\nStep 2.\nConsidering the spectral decomposition, $Z^{T} Z$ is a symmetric matrix, and thinking about its definition, $\\displaystyle {{1} \\over {n-1}} Z^{T} Z$ becomes the covariance matrix for $Z_{1} , \\cdots , Z_{p}$. Especially, since $Z$ is a standardized matrix, it also serves as a correlation coefficient matrix. According to Spectral Theory\n$$ \\begin{cases} Z^{T} Z = Q \\Lambda Q^{T} \\\\ Q^{T} Q = Q Q^{T} = I \\end{cases} $$\n, there exist an orthogonal matrix\n$$ Q = \\begin{bmatrix} q_{11} \u0026amp; q_{12} \u0026amp; \\cdots \u0026amp; q_{1p} \\\\ q_{21} \u0026amp; q_{22} \u0026amp; \\cdots \u0026amp; q_{2p} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ q_{p1} \u0026amp; q_{p2} \u0026amp; \\cdots \u0026amp; q_{pp} \\end{bmatrix} $$\nthat satisfies it, and a diagonal matrix\n$$ \\Lambda = \\text{diag} ( \\lambda_{1} , \\lambda_{2} , \\cdots , \\lambda_{p} ) = \\begin{bmatrix} \\lambda_{1} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\lambda_{2} \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; \\lambda_{p} \\end{bmatrix} $$\ncomposed of the eigenvalues of $Z^{T} Z$. Now, for convenience, let\u0026rsquo;s assume $\\lambda_{1} \\ge \\lambda_{2} \\ge \\cdots \\ge \\lambda_{p}$ and think of $Z$ as a matrix reorganized accordingly.\nStep 3. Composition of Principal Components\nSince $I = QQ^{T}$, $$ Y = Z \\Theta + \\varepsilon = Z Q Q^{T} \\Theta + \\varepsilon $$ where we set $C := ZQ $ and $\\alpha := Q^{T} \\Theta$, $$ Y = C \\alpha + \\varepsilon $$ the Principal Components for $C = \\begin{bmatrix} C_{1} \u0026amp; \\cdots \u0026amp; C_{p} \\end{bmatrix}$ are $C_{1} , \\cdots , C_{p}$. The form of the $j$th principal component is\n$$ C_{j} = q_{1j} Z_{1} + \\cdots + q_{pj} Z_{p} = \\sum_{i=1}^{p} q_{ij} Z_{j} $$\n, restructuring the original independent variables into a linear combination.\nStep 4.\nThe independence of the principal components can also be confirmed by the following calculation: $$ \\begin{align*} \u0026amp; Z^{T} Z = Q \\Lambda Q^{T} \\\\ \\implies\u0026amp; Q^{T} Z^{T} Z Q = \\Lambda \\\\ \\implies\u0026amp; \\left( Z Q \\right) ^{T} \\left( Z Q \\right) = \\Lambda \\\\ \\implies\u0026amp; C^{T} C = \\Lambda \\end{align*} $$ In other words, $$ C_{j}^{T} C_{j} = \\begin{cases} \\lambda_{j} \u0026amp; , i=j \\\\ 0 \u0026amp; , i \\ne j \\end{cases} $$ This means the principal components are necessarily independent, and if the eigenvalue $\\lambda_{j}$ is close to $0$, it implies that $\\displaystyle C_{j} = \\sum_{i=1}^{p} q_{ij} Z_{j}$ is close to a zero vector, indicating that $Z_{1} , \\cdots , Z_{p}$ may have multicollinearity.\n‚ñ†\nLimitations Principal Component Regression Analysis $Y \\gets C_{1} , \\cdots , C_{p}$ circumvents the issue of multicollinearity by removing variables with problematic eigenvalues. Moreover, since it uses significantly fewer variables compared to the original regression analysis, it can be said that the dimension has been reduced.\nAt first glance, principal component analysis may seem like a panacea, but that is not always the case. Firstly, the fact that standardization is required to create $Z$ means that there are many difficulties in dealing with qualitative variables or transformations, and this \u0026lsquo;restructuring\u0026rsquo; process makes the analysis itself harder to understand.\nConsidering that statistics are necessary even for those who do not understand statistics, this point is quite fatal. For example, if principal component analysis is used for analyzing the Korean economy, instead of easily understandable figures like the unemployment rate $X_{2}$ or average starting salary $X_{7}$, it might be expressed in strange terms like \u0026lsquo;comprehensive employment index\u0026rsquo; $C_{4}$. Even the analyst, who might have produced a usable regression formula, may not grasp its true meaning, which could lead to a disaster. (In computer science, prediction and classification are more important than understanding data, so this downside is not taken as seriously.)\nAlso, if none of the principal components are excluded and $Y \\gets C_{1} , \\cdots , C_{p}$ is used as is, there\u0026rsquo;s no difference from the original $Y \\gets X_{1} , \\cdots , X_{p}$, which means giving up the original data itself. It might still be necessary to use it, but if not, there\u0026rsquo;s no reason to. Even when using it, it\u0026rsquo;s crucial to be fully aware of its disadvantages and limitations.\nCondition Number 1 Meanwhile, the Condition Number, a numerical indicator for diagnosing multicollinearity through the eigenvalues obtained in the derivation process\n$$ \\kappa := \\sqrt{ {{ \\lambda_{1} } \\over { \\lambda_{p} }} } $$\n, can be calculated. Empirically, if $\\kappa \u0026gt; 15$, it\u0026rsquo;s presumed there is multicollinearity in the original data, although it\u0026rsquo;s not widely used.\nSee Also Multicollinearity How to do Principal Component Regression Analysis in R Principal Component Analysis in Mathematical Statistics Hadi. (2006). Regression Analysis by Example(4th Edition): p255~257.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":812,"permalink":"https://freshrimpsushi.github.io/en/posts/812/","tags":null,"title":"Principal Component Analysis in Statistics"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"=\nThis article is based on the Riemann-Stieltjes integral. If set as $\\alpha=\\alpha (x)=x$, it is the same as the Riemann integral.\nTheorem If function $f$ is continuous on $[a,b]$, then it is Riemann(-Stieltjes) integrable on $[a,b]$.\nProof Suppose $\\epsilon \u0026gt;0$ is given. And let\u0026rsquo;s say we chose $\\eta\u0026gt;0$ that satisfies $\\left[ \\alpha (b) - \\alpha (a) \\right] \\eta \u0026lt; \\epsilon$. Since $[a,b]$ is compact as it is closed and bounded, and continuous functions on a compact set are uniformly continuous, $f$ is uniformly continuous. Therefore, by the definition of uniform continuity, there exists $\\delta \u0026gt;0$ for which the following equation holds.\n$$ |x-t|\u0026lt;\\delta \\implies |f(x)-f(t)|\u0026lt;\\eta\\quad \\forall x, t \\in [a,b] $$\nBy the definition of uniform continuity, any positive number can satisfy the place of $\\eta$, so the $\\eta$ we chose above satisfies it naturally.\nLet\u0026rsquo;s say the partition $P$ of $[a,b]$ was given to satisfy $\\Delta x_{i} \u0026lt;\\delta (i=1,\\cdots,n)$. Also, let\u0026rsquo;s consider the following.\n$$ M_{i}=\\sup\\limits_{[x_{i-1},x_{i}]}f(x) \\quad \\text{and} \\quad m_{i}=\\inf\\limits_{[x_{i-1},x_{i}]}f(x) $$\nThen by the condition that $f$ is uniformly continuous, the following is true.\n$$ M_{i}-m_{i} \\le \\eta \\quad (i=1,\\cdots,n) $$\nThen we obtain the following equation.\n$$ \\begin{align*} U(P,f,\\alpha) - L(P,f,\\alpha) \u0026amp;= \\sum \\limits_{i=1}^n (M_{i}-m_{i})\\Delta \\alpha_{i} \\\\ \u0026amp; \\le \\sum \\limits _{i=1} ^n \\eta \\Delta \\alpha_{i} \\\\ \u0026amp;= \\eta \\sum \\limits_{i=1}^n \\Delta \\alpha_{i} \\\\ \u0026amp;= \\eta \\left[ \\big( \\alpha ( x_{2}) -\\alpha (a) \\big) + \\cdots + \\big( \\alpha ( b) -\\alpha (x_{n-1}) \\big)\\right] \\\\ \u0026amp;=\\eta \\left[ \\alpha ( b) - \\alpha (a) \\right] \\\\ \u0026amp;\u0026lt; \\epsilon \\end{align*} $$\nAs for the beginning part of the proof, we chose $\\eta$ such that it satisfies the last equation, so it is natural that the last line holds. This equation is the equivalence condition for being integrable, therefore $f$ is integrable.\n‚ñ†\n","id":847,"permalink":"https://freshrimpsushi.github.io/en/posts/847/","tags":null,"title":"Continuous Functions are Riemann-Stieltjes Integrable"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Explanation1 The electric field is a special vector function that always has a curl (rotation) of $\\mathbf{0}$. From this characteristic, we introduce a scalar function called electric potential. The potential is denoted as $V$ and has the following relationship with the electric field $\\mathbf{E}$.\n$$ \\mathbf{E} = -\\nabla V $$\nTherefore, if we know the potential $V$, we can know the electric field $\\mathbf{E}$. Since the potential is a scalar function, it\u0026rsquo;s easier to find the potential than to directly find the vector function, the electric field. The relationship between electric field and potential is similar to that between gravity and potential energy. However, since the unit of electric field is not a force, the potential is not exactly potential energy but rather just potential.\nThe following result means that the electric field is precisely the gradient of the potential, and knowing the potential allows us to calculate its gradient to find the electric field. Moreover, this concept is applicable not only to electric fields but also to all vector functions with a curl of $\\mathbf{0}$.\nDerivation Through the process of proving that $\\nabla \\times \\mathbf{E}=0$, we found out that the line integral of the electric field over a closed path is $0$. In the image above, combining path $1$ and path $2$ forms a closed path going from point $\\mathbf{a}$ back to point $\\mathbf{a}$. Therefore,\n$$ \\int _{1} \\mathbf{E} \\cdot d\\mathbf{l} + \\int_2 \\mathbf{E} \\cdot d\\mathbf{l} =0 $$\nthe integral values of path $1$ and path $2$ are the same in magnitude but opposite in sign. If we reverse path $1$ so both paths go from point $\\mathbf{a}$ to point $\\mathbf{b}$, then they have the same value.\nSince the line integral of the electric field is independent of the path, the integral from a reference point $\\mathcal{O}$ to location $\\mathbf{r}$ always has the same value. Therefore, let\u0026rsquo;s define the scalar function $V$ as follows.\n$$ V(\\mathbf{r} ) \\equiv - \\int _\\mathcal{O} ^{\\mathbf{r}} \\mathbf{E} \\cdot d \\mathbf{l} $$\nThen, by the definition of potential, the following formula holds.\n$$ \\begin{align*} V(\\mathbf{b} )- V( \\mathbf{a} ) =\u0026amp;\\ -\\int _\\mathcal{O} ^{\\mathbf{b}} \\mathbf{E} \\cdot d\\mathbf{l} +\\int_\\mathcal{O} ^{\\mathbf{a}} \\mathbf{E} \\cdot d \\mathbf{l} \\\\ =\u0026amp;\\ -\\int_\\mathbf{a} ^\\mathbf{b} \\mathbf{E} \\cdot d\\mathbf{l} \\end{align*} $$\nFundamental Theorem of Gradients\n$$ T(b)-T(a) = \\int _{a}^{b} (\\nabla T) \\cdot d\\mathbf{l} $$\nAlso, by the fundamental theorem of gradients, the following formula is valid.\n$$ V( \\mathbf{b} ) - V (\\mathbf{a} ) = \\int_{\\mathbf{a}}^{\\mathbf{b}}\\left( \\nabla V \\right) \\cdot d\\mathbf{l} $$\nTherefore, since $\\displaystyle \\int_\\mathbf{a} ^ \\mathbf{b} \\left( \\nabla V \\right) \\cdot d\\mathbf{l} = -\\int_\\mathbf{a} ^\\mathbf{b} \\mathbf{E} \\cdot d\\mathbf{l}$,\n$$ \\mathbf{E} = -\\nabla V $$\n‚ñ†\nDavid J. Griffiths, Introduction to Electrodynamics (4th Edition, 2014), p86-87\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":845,"permalink":"https://freshrimpsushi.github.io/en/posts/845/","tags":null,"title":"Potential"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Ï†ïÎ¶¨ Electric Field\u0026rsquo;s Curl is always $\\mathbf{0}$.\n$$ \\nabla \\times \\mathbf{E} = \\mathbf{0} $$\nProof1 We will derive a general result from the special case where a point charge is located at the origin. The electric field due to a point charge at a distance of $r$ from the origin is as follows.\n$$ \\mathbf{E}=\\dfrac{1}{4 \\pi \\epsilon_{0} } \\dfrac{q}{r^2} \\hat{\\mathbf{r}} $$\nIf we perform a path integral of the electric field from point $\\mathbf{a}$ to point $\\mathbf{b}$ in a spherical coordinate system, we obtain the following.\n$$ \\begin{align*} \\int_\\mathbf{a} ^\\mathbf{b} \\mathbf{E} \\cdot d\\mathbf{l} =\u0026amp;\\ \\int_\\mathbf{a}^\\mathbf{b} \\left( \\dfrac{1}{4 \\pi \\epsilon_{0}} \\dfrac{q}{r^2} \\hat{\\mathbf{r}} \\right) \\cdot \\left( dr \\hat{\\mathbf{r}} + rd\\theta\\hat{\\boldsymbol{\\theta}} + r\\sin\\theta d\\phi \\hat{\\boldsymbol{\\phi}} \\right) \\\\ =\u0026amp;\\ \\int_\\mathbf{a}^\\mathbf{b} \\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{q}{r^2}dr \\\\ =\u0026amp;\\ \\dfrac{q}{4 \\pi \\epsilon_{0}} \\int_\\mathbf{a}^\\mathbf{b} \\dfrac{1}{r^2} dr = \\dfrac{q}{4 \\pi \\epsilon_{0}} \\left[ -\\dfrac{1}{r} \\right]_{r_{a}}^{r_{b}} \\\\ =\u0026amp;\\ \\dfrac{q}{4 \\pi \\epsilon_{0}} \\left( \\dfrac{1}{r_{a}}-\\dfrac{1}{r_{b}} \\right) \\end{align*} $$\nHere, $r_{a}$ and $r_{b}$ are the distances from the origin to point $\\mathbf{a}$ and point $\\mathbf{b}$, respectively. As can be seen from the result of the above integration, the integral over a closed path is $0$.\n$$ \\oint \\mathbf{E} \\cdot d \\mathbf{l} = 0 $$\nStokes\u0026rsquo; Theorem\n$$ \\int_{\\mathcal{S}} \\left( \\nabla \\times \\mathbf{v} \\right) \\cdot d\\mathbf{a} = \\oint _{\\mathcal{P} }\\mathbf{v} \\cdot d \\mathbf{l} $$\nUsing Stokes\u0026rsquo; Theorem\n$$ \\int \\left( \\nabla \\times \\mathbf{E} \\right) \\cdot d\\mathbf{a} =\\oint \\mathbf{E} \\cdot d\\mathbf{l}=0 $$\ntherefore, it can be seen that it must be $\\nabla \\times \\mathbf{E} = \\mathbf{0}$. Since the integral over any arbitrary area must yield $\\mathbf{0}$, it can only be $\\nabla \\times \\mathbf{E} = \\mathbf{0}$.\nThe electric field for several point charges is the same as adding up the electric fields for each point charge. For continuously distributed charges, only change $\\sum$ to $\\int$. Therefore, it is $\\mathbf{E}=\\mathbf{E}_{1} + \\mathbf{E}_2+\\mathbf{3}+\\cdots$, and since the curl of each electric field is $\\mathbf{0}$, their sum is naturally $\\mathbf{0}$.\n$$ \\begin{align*} \\nabla \\times \\mathbf{E} =\u0026amp;\\ \\nabla \\times (\\mathbf{E}_{1} + \\mathbf{E}_2+\\mathbf{3}+\\cdots ) \\\\ =\u0026amp;\\ (\\nabla \\times \\mathbf{E}_{1}) +(\\nabla \\times \\mathbf{E}_2 )+(\\nabla \\times \\mathbf{E}_{3})+\\cdots \\\\ =\u0026amp;\\ \\mathbf{0} \\end{align*} $$\n‚ñ†\nDavid J. Griffiths, Í∏∞Ï¥àÏ†ÑÏûêÍ∏∞Ìïô(Introduction to Electrodynamics, ÍπÄÏßÑÏäπ Ïó≠) (4th Edition, 2014), p84-85\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":844,"permalink":"https://freshrimpsushi.github.io/en/posts/844/","tags":null,"title":"Electric Field Curl"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 Consider performing multiple regression analysis $Y \\gets X_{1} , \\cdots, X_{p}$. If among the independent variables $ X_{1} , \\cdots, X_{p}$ there is a strong correlation between the independent variables, then it is said that there is multicollinearity.\nPractice Initially, the very idea that independent variables are dependent violates the assumptions of regression analysis and indeed leads to numerical problems that make the analysis results unreliable. It can be a task in itself to determine whether there is multicollinearity in the data.\nData Exploration Let\u0026rsquo;s load the MplsDemo data from built-in data.\nMplsDemo is data estimating population (total population), white (percentage of white), black (percentage of black), foreignBorn (foreign-born), hhIncome (household income), poverty (poverty), and collegeGrad (rate of college graduates) by districts in Minneapolis, USA.\nAfter regression analysis, the hypothesis testing appears unproblematic, the explanatory power is satisfactory, and the residuals seem fine. However, if you look closely at the regression coefficients, having more white people appears to increase the number of college graduates, and having more foreign-born also increases the number of college graduates. Although this data does not have accurate information for all races, this seems odd. Also, the fact that a higher income increases the number of graduates but poverty does not impact at all is somewhat disconcerting.\nLooking at the scatter plot, it seems normal that white and household income have a positive correlation, and black, foreign-born have a negative correlation. Poverty is ambiguous, but if anything, it shows a weak negative correlation. However, the positive regression coefficients for black and foreign-born suggest that this data has not been properly explained. Although the explanatory power itself is above 0.8, which is decent, there is definitely something unsettling. When considering multicollinearity, it\u0026rsquo;s troubling that the white population seems to have a strong correlation with other variables.\nModel Modification Let\u0026rsquo;s remove the independent variable white representing the white population ratio and run the regression analysis again.\nThe new analysis results have explained the anticipated regression relationship in a relatively sensible manner even though the explanatory power has fallen by nearly 10%. Foreign-born coefficient is still a bit odd, but since regression coefficients are not significant, it seems unnecessary to worry about them. From here, how to handle the data for more refined analysis entirely depends on the analyst.\nDetection of Multicollinearity There are situations that highly suggest the presence of multicollinearity, such as:\nF-test is passed, but the individual regression coefficients do not pass the t-test The signs of the regression coefficients are opposite to what was expected to the point of being contradictory When data is added or removed, the existing regression coefficients change drastically In case 1, it\u0026rsquo;s a relief in the sense that multicollinearity has been detected. Regardless of how to handle the data and solve the problem, the fact that multicollinearity has been identified is a good thing.\nCase 2 is easy to detect because it\u0026rsquo;s contrary to intuition, but depending on the \u0026rsquo;expected\u0026rsquo; results and data, it can be very difficult to identify multicollinearity. If you\u0026rsquo;re trying to find out factors affecting plant growth, you can somewhat predict whether sunlight, water amount, and soil quality, which are independent variables, are helpful or not. However, unraveling unknown problems in social sciences can make the analyst\u0026rsquo;s intuition unreliable. Even if there is multicollinearity, the analysis might seem correct, which could lead to analysis results that completely fail to explain the actual phenomena without proper review.\nIn case 3, it can be difficult to pay attention to each regression coefficient individually when there are many independent variables, and one might overlook this issue even when looking directly at it. Data here not only refers to independent variables but could also be some outliers.\nRegardless of the case, the analysis might be flawed, leading to issues, and explanatory power $R^2$ can be a cue to suspect multicollinearity. However, there is no clear standard for how good the explanatory power should be, incorrect analysis can still show high explanatory power, and even this factor can be quite subjective, making it unreliable. In reality, it\u0026rsquo;s rarer for data acquired to have entirely independent variables. It might not be enough to mention multicollinearity, but it\u0026rsquo;s common for there to be some relationship, causing ambiguous effects.\nAs in the example, identifying through scatter plots is not always foolproof. Certainly, scatter plots can quickly reveal the relationship between two variables, but if there is a complex relationship between multiple variables as in $X_{1}+ X_{2} + X_{3} = 1$, it can be difficult to detect with the eyes.\nNumerical Indicators Naturally, one must consider numerical indicators. The most popularly used is the Variance Inflation Factor (VIF), which is useful for detecting multicollinearity. However, since VIF doesn\u0026rsquo;t follow a probability distribution, hypothesis testing is not possible. Hence, it is claimed based on an empirically set threshold, which can also be ambiguous and problematic. Regression analysis is to some extent a battle with multicollinearity.\nBesides VIF, there are other indicators like the condition number obtained through principal component analysis, but these are not used frequently.\nCode The following is an example code.\ninstall.packages(\u0026#39;car\u0026#39;)\rlibrary(car)\rDATA=MplsDemo; head(DATA)\rwin.graph()\rplot(DATA[,-1])\rout0\u0026lt;-lm(collegeGrad~.-neighborhood,data=DATA)\rsummary(out0)\rwin.graph(4,4)\rplot(out0$residuals, main=\u0026#34;ÏûîÏ∞®\u0026#34;)\rout1\u0026lt;-lm(collegeGrad~.-neighborhood-white,data=DATA)\rsummary(out1) Hadi. (2006). Regression Analysis by Example(4th Edition): p222.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":808,"permalink":"https://freshrimpsushi.github.io/en/posts/808/","tags":["R"],"title":"Multicollinearity"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Definition1 The flux of an electric field $\\mathbf{E}$ passing through a surface $\\mathcal S$ is defined as follows.\n$$ \\Phi_{E} \\equiv \\int_{\\mathcal S} \\mathbf{E} \\cdot d\\mathbf{a} $$\nLet\u0026rsquo;s consider $\\mathcal{S}$ as some closed surface. Let the total charge inside the closed surface be $Q_{\\text{in}}$. Then, the following equation holds.\n$$ \\oint_{\\mathcal{S}} \\mathbf{E} \\cdot d\\mathbf{a} = \\frac{1}{\\epsilon_{0}}Q_{\\mathrm{in}} $$\nThis is known as Gauss\u0026rsquo;s law.\nFlux Flux, or flux density, refers to the amount of a physical quantity passing perpendicularly through a given surface. For example, water or gas flowing through a pipe does so parallel to the perpendicular surface of the pipe, thus, the amount flowing is the same as the flux. However, electric fields do not flow along a conduit. Therefore, the flux of an electric field is determined by taking the dot product. When taking the dot product, components that are not parallel result in zero.\nAssuming the electric field lines pass through a surface as shown in the figure above. What we are interested in here is the degree to which it passes perpendicular to the surface. As we all know, vectors can be decomposed. Let\u0026rsquo;s break down the electric field lines into directions perpendicular and parallel to the surface. Then it would look like the figure below. Our goal is to find the $\\mathbf{E}_\\parallel$ indicated in the figure. Since the magnitude of the surface vector $d\\mathrm{a}$ is $1$, it can be calculated with the following equation using the dot product.\n$$ \\mathbf{E}_\\parallel=\\mathbf{E} \\cdot d\\mathbf{a} $$\nFollowing the method above, the flux of the electric field with respect to the given surface is defined as follows.\n$$ \\Phi_{E} \\equiv \\int_{\\mathcal S} \\mathbf{E} \\cdot d\\mathbf{a} $$\nGauss\u0026rsquo;s Law (Integral Form) The essence of Gauss\u0026rsquo;s Law is that charges outside a closed surface have no effect on the flux.\nAs illustrated, the flux caused by electric field lines piercing through a closed surface from the outside is calculated twice, at both ends of the surface. The direction of the surface vector on a closed surface is always defined outward. Since the direction of the surface vectors at both ends is opposite, the magnitude of the flux passing through is the same but the direction is different. When these two are added together, it results in $0$, indicating that charges outside the closed surface do not affect the flux.\nDerivation Now, let\u0026rsquo;s consider a point charge $Q$ located at the center of a sphere with radius $r$. Let\u0026rsquo;s calculate the flux of electric field $\\mathbf{E}$ passing through the spherical surface. Representing the electric field by Coulomb\u0026rsquo;s law yields the following result.\n$$ \\begin{align*} \\Phi_{E} \u0026amp;= \\oint \\mathbf{E} \\cdot d\\mathbf{a} \\\\ \u0026amp;= \\int_{0}^{2\\pi} \\int_{0}^\\pi \\left( \\frac{1}{4\\pi\\epsilon_{0} q r^{2}} \\hat{\\mathbf{r}} \\right) \\cdot \\left( r^{2}\\sin\\theta d\\theta d \\phi \\hat{\\mathbf{r}} \\right) \\\\ \u0026amp;= \\frac{1}{4\\pi\\epsilon_{0}}Q \\int_{0}^{2\\pi}d\\phi \\int_{0}^\\pi \\sin\\theta d\\theta \\\\ \u0026amp;= \\frac{1}{4\\pi\\epsilon_{0}}Q (2\\pi)(2) \\\\ \u0026amp;= \\frac{1}{\\epsilon_{0}}Q \\end{align*} $$\nIt can be seen that the result is independent of the radius $r$. This is because the surface area of the sphere is proportional to $r^{2}$, and the electric field is inversely proportional to $r^{2}$. They cancel each other out, not affecting the result. In case there are multiple point charges inside the surface, they are simply added together. This is because the electric field of multiple point charges is simply the sum according to the superposition principle. For example, if there are point charges $Q_{1}$ and $Q_{2}$, and if it is $Q=Q_{1}+Q_{2}$, the result is as follows.\n$$ \\begin{align*} \\oint \\mathbf{E} \\cdot d\\mathbf{a} \u0026amp;= \\oint \\left( \\sum \\limits_{i=1}^{2} \\mathbf{E}_{i} \\right) \\cdot d\\mathbf{a} \\\\ \u0026amp;= \\oint \\left( \\mathbf{E}_{1} + \\mathbf{E}_{2} \\right) \\cdot d\\mathbf{a} \\\\ \u0026amp;= \\oint \\mathbf{E}_{1} \\cdot d\\mathbf{a} + \\oint \\mathbf{E}_{2} \\cdot d\\mathbf{a} \\\\ \u0026amp;= \\frac{1}{\\epsilon_{0}}Q_{1}+\\frac{1}{\\epsilon_{0}}Q_{2} \\\\ \u0026amp;= \\frac{1}{\\epsilon_{0}}(Q_{1}+Q_{2})=\\frac{1}{\\epsilon_{0}}Q \\end{align*} $$\nNaturally, the result would be the same for more than three point charges. Thus, when the total charge inside a closed surface is $Q_{\\text{in}}$ and the total electric field created by the charges is $\\mathbf{E}$, the following equation holds.\n$$ \\begin{equation} \\oint \\mathbf{E} \\cdot d\\mathbf{a} = \\dfrac{1}{\\epsilon_{0}}Q_{\\text{in}} \\label{1} \\end{equation} $$\nDifferential Form Divergence Theorem\n$$ \\int_\\mathcal{V} \\nabla \\cdot \\mathbf{v} d\\tau = \\oint _{S} \\mathbf{v} \\cdot d \\mathbf{a} $$\nApplying the divergence theorem to $\\eqref{1}$ gives us the following equation.\n$$ \\int_{\\mathcal{V}} \\nabla \\cdot \\mathbf{E} d\\tau = \\oint _{\\mathcal{S}} \\mathbf{E} \\cdot d \\mathbf{a} = \\frac{1}{\\epsilon_{0}}Q_{\\text{in}} $$\nLet\u0026rsquo;s denote the charge per unit volume as the volume charge density $\\rho$. Then, the relationship between the total charge within a volume $Q_\\mathrm{in}$ and $\\rho$ is as follows.\n$$ Q_\\mathrm{in}=\\int_\\mathcal{V} \\rho d\\tau $$\nCombining the results of the two equations above yields the following.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\int_\\mathcal{V} \\nabla \\cdot \\mathbf{E} d\\tau \u0026amp;= \\int_\\mathcal{V} \\frac{1}{\\epsilon_{0}}\\rho d\\tau \\\\ \\implies \u0026amp;\u0026amp; \\nabla \\cdot \\mathbf{E} \u0026amp;= \\frac{1}{\\epsilon_{0}}\\rho \\end{align*} $$\nThis is referred to as Gauss\u0026rsquo;s Law in differential form and is one of Maxwell\u0026rsquo;s equations.\nDavid J. Griffiths, Introduction to Electrodynamics (Translated by Jin-Seung Kim)(4th Edition). 2014, p73-77\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":635,"permalink":"https://freshrimpsushi.github.io/en/posts/635/","tags":null,"title":"Electric Flux and Gauss's Law"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 A field $F$ and an abelian group $V$ are said to form a vector space over $F$ if all elements $\\alpha , \\beta \\in F$ and $x, y \\in V$ satisfy the following conditions. Elements of $F$ are called scalars, and elements of $V$ are called vectors.\n(i): $\\alpha x \\in V$ (ii): $\\alpha ( \\beta x) = ( \\alpha \\beta ) x$ (iii): $\\alpha (x + y) = \\alpha x + \\alpha y$ (iv): $1 x = x$ Let\u0026rsquo;s denote the index set as $I$ and define $\\left\\{ x_{i} \\right\\}_{i \\in I} \\subset V$.\nFor some $\\left\\{ \\alpha_{i} \\right\\}_{ i \\in I} \\subset F$, $\\displaystyle \\sum_{i \\in I} \\alpha_{i} x_{i}$ is said to be a linear combination of $\\left\\{ x_{i} \\right\\}_{i \\in I}$. If all elements of $V$ can be represented as linear combinations of $M$, $ \\left\\{ x_{i} \\right\\}_{i \\in I}$ is said to generate $V$, denoted as $\\text{span} \\left\\{ x_{i} \\right\\}_{i \\in I} = V$. If there exists a $\\left\\{ x_{i} \\right\\}_{i \\in I}$ satisfying $\\text{span} \\left\\{ x_{i} \\right\\}_{i \\in I} = V$ for a finite set $I$, then $V$ is said to be finite-dimensional. If the only case satisfying $\\displaystyle \\sum_{i \\in I} \\alpha_{i} x_{i} = 0$ for all $\\left\\{ x_{i} \\right\\}_{i \\in I}$ is $\\alpha_{i} = 0$, then $\\left\\{ x_{i} \\right\\}_{i \\in I}$ is linearly independent over $F$; otherwise, it is linearly dependent. When $\\text{span} \\left\\{ x_{i} \\right\\}_{i \\in I} = V$, if $\\left\\{ x_{i} \\right\\}_{i \\in I}$ is linearly independent, then $\\left\\{ x_{i} \\right\\}_{i \\in I}$ is the basis of $V$. When the basis of a finite-dimensional vector space $V$ is denoted by $M$, the cardinality of $M$ is called the dimension of $V$, represented as $\\dim V$. Description This concept might already be familiar from linear algebra and can be described as an abstract algebra without the \u0026lsquo;algebra\u0026rsquo; name attached. For a simple example, the ring of polynomial functions $\\mathbb{R} [ x ]$ easily verifies to be a vector space with $1 , x , \\cdots , x^{n}$ as its basis.\nSee Also Vector space in linear algebra Vector space in abstract algebra The $F$-vector spaces discussed in the documents below are essentially no different from the vector spaces mentioned above. However, the perspective can vary: in linear algebra, a vector space is an abstraction of the intuitive Euclidean space, whereas in abstract algebra, it brings that abstraction into the true meaning of \u0026lsquo;algebra\u0026rsquo;.\nOn the contrary, the $R$-module generalizes the scalar field $F$ of the $F$-vector space to a scalar ring $R$, and thus, its significance lies in generalization. From the perspective of group $G$, since a new operation $\\mu$ is added to ring $R$, it also falls under the category of modules.\nR-module in abstract algebra $F$-vector space in abstract algebra Fraleigh. (2003). A first course in abstract algebra(7th Edition): p274~280.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":806,"permalink":"https://freshrimpsushi.github.io/en/posts/806/","tags":null,"title":"Vector Spaces in Abstract Algebra"},{"categories":"Ï†ÑÏûêÍ∏∞Ìïô","contents":"Coulomb\u0026rsquo;s Law1 The force exerted on a test charge $Q$ placed at a distance $\\cR$ away from a fixed point charge $q$ is known as the Coulomb force, and its equation is as follows.\n$$ \\mathbf{F} = \\dfrac{1}{4\\pi \\epsilon_{0}} \\dfrac{qQ}{\\cR ^2} \\crH $$\nThis is referred to as Coulomb\u0026rsquo;s Law.\nDescription Coulomb‚Äôs Law is an empirical law derived from repeated experiments. Therefore, it cannot be mathematically proven. It is easier to understand if one thinks of it as analogous to axioms in mathematics. $\\epsilon_{0}$ represents the permittivity of free space, and its value is $8.85 \\times 10^{-12} \\dfrac{\\mathrm C^2}{\\mathrm N \\cdot \\mathrm m^2}$. On the other hand, the formula at the top of the text is expressed in International System of Units. If it is represented in Gaussian system, it looks like this:\n$$ \\mathbf{F} = \\dfrac{qQ}{\\cR ^2} \\crH $$\nThis replaces the constant of proportionality in the International System of Units with $1$. That is to say $\\dfrac{1}{4\\pi\\epsilon_{0}} \\equiv 1$. In other words, the easy way to convert SI units to Gaussian units is to replace $\\epsilon_{0}$ with $\\dfrac{1}{4\\pi}$.\nElectric Field Point Charge Distribution Let\u0026rsquo;s now imagine that there are several point charges around the test charge $Q$. Then, the force exerted on $Q$ can simply be added linearly from each of the point charges. This means that the interaction between $Q$ and $q_{1}$ is not affected by $q_{2}, q_{3}, \\dots$. This is called the Superposition Principle.\n$$ \\begin{align*} \\mathbf{F} \u0026amp;= F_{1}+F_{2}+\\cdots + F_{n} \\\\ \u0026amp;= \\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{q_{1}Q}{{\\cR_{1}}^2}\\crH_{1} +\\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{q_{2}Q}{{\\cR_{2}}^2}\\crH_{2}+\\cdots +\\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{q_{n}Q}{{\\cR_{n}}^2}\\crH_{n} \\\\ \u0026amp;= Q\\left( \\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{q_{1}}{{\\cR_{1}}^2}\\crH_{1} +\\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{q_{2}}{{\\cR_{2}}^2}\\crH_{2}+\\cdots +\\dfrac{1}{4\\pi\\epsilon_{0}}\\dfrac{q_{n}}{{\\cR_{n}}^2}\\crH_{n} \\right) \\\\ \u0026amp;= Q\\mathbf{E} \\end{align*} $$\nHere, the portion within the parentheses is defined as the electric field created by the source charges $q_{1},\\ q_{2},\\ \\cdots ,\\ q_{n}$, and it is denoted as $\\mathbf{E}$.\n$$ \\mathbf{E}(\\mathbf {r}) =\\dfrac{1}{4\\pi \\epsilon_{0}} \\sum \\limits_{i=1}^n \\dfrac{q_{i}}{{\\cR_{i}}^2}\\crH_{i} $$\nContinuous Charge Distribution When the charge is continuously distributed, it is expressed with an integral instead of a sum.\n$$ \\sum \\rightarrow \\int \\\\ \\mathbf{E}(\\mathbf {r}) =\\dfrac{1}{4\\pi \\epsilon_{0}} \\int \\dfrac{1}{\\cR^2}\\crH dq $$\nIn the case of line charge, $dq=\\lambda dl^{\\prime}$. Here, $\\lambda$ is the linear charge density. The electric field created by a line charge is as follows.\n$$ \\mathbf{E}(\\mathbf {r}) =\\dfrac{1}{4\\pi \\epsilon_{0}} \\int _\\mathcal{P} \\dfrac{\\lambda (\\mathbf{r}^{\\prime})}{\\cR^2} \\crH dl^{\\prime} $$\nIn the case of surface charge, $dq=\\sigma da^{\\prime}$. Here, $\\sigma$ is the surface charge density. The electric field created by a surface charge is as follows.\n$$ \\mathbf{E}(\\mathbf {r}) =\\dfrac{1}{4\\pi \\epsilon_{0}} \\int _\\mathcal{S} \\dfrac{\\sigma (\\mathbf{r}^{\\prime})}{\\cR^2} \\crH da^{\\prime} $$\nIn the case of volume charge, $dq=\\rho d\\tau^{\\prime}$. Here, $\\rho$ is the volume charge density. The electric field created by a volume charge is as follows.\n$$ \\mathbf{E}(\\mathbf {r}) =\\dfrac{1}{4\\pi \\epsilon_{0}} \\int _\\mathcal{V} \\dfrac{\\rho (\\mathbf{r}^{\\prime})}{\\cR^2} \\crH d\\tau^{\\prime} $$\nDavid J. Griffiths, Introduction to Electrodynamics, Translated by Jin-Seung Kim (4th Edition). 2014, p65-70\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":836,"permalink":"https://freshrimpsushi.github.io/en/posts/836/","tags":null,"title":"Coulomb's Law and Electric Fields"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 For primes $p \\ne 2$ and $a \u0026lt; p$, if there exists a solution to the congruence equation $x^{2} \\equiv a \\pmod{p}$, then $a$ is called a Quadratic Residue QR modulo $p$. If $a$ is not a quadratic residue, it is called a Non-Quadratic Residue NR.\nExplanation Simply put, a quadratic residue is a number for which a square root exists in $\\pmod{p}$.\nFor example, consider the prime $7$ $$ 1^2 \\equiv 1 \\pmod{7} \\\\ 2^2 \\equiv 4 \\pmod{7} \\\\ 3^2 \\equiv 2 \\pmod{7} \\\\ 4^2 \\equiv 2 \\pmod{7} \\\\ 5^2 \\equiv 4 \\pmod{7} \\\\ 6^2 \\equiv 1 \\pmod{7} $$ $1,2,4$ is a QR and $3,5,6$ is an NR. Considering the prime $11$ $$ 1^2 \\equiv 1 \\pmod{11} \\\\ 2^2 \\equiv 4 \\pmod{11} \\\\ 3^2 \\equiv 9 \\pmod{11} \\\\ 4^2 \\equiv 5 \\pmod{11} \\\\ 5^2 \\equiv 3 \\pmod{11} \\\\ 6^2 \\equiv 3 \\pmod{11} \\\\ 7^2 \\equiv 5 \\pmod{11} \\\\ 8^2 \\equiv 9 \\pmod{11} \\\\ 9^2 \\equiv 4 \\pmod{11} \\\\ 10^2 \\equiv 1 \\pmod{11} $$ $1,3,4,5,9$ is a QR and the rest $2,6,7,8,10$ are NR. Interestingly, QRs appear symmetrically, which is natural because $$ (p-q)^2 \\equiv p^2-2pq+q^2 \\equiv q^2 \\pmod{p} $$ Also, there are always exactly the same number of QRs and NRs.\nSummary For primes larger than $2$, $p$, there are exactly $\\displaystyle {(p-1) \\over 2}$ QRs and NRs.\nProof The list of all numbers squared from $1$ to $p-1$ is as follows. $$ 1^2, 2^2, \\cdots , (p-1)^2 $$ However, as we\u0026rsquo;ve seen $$ (p-q)^2 \\equiv p^2-2pq+q^2 \\equiv q^2 \\pmod{p} $$ so whether we look at $1$ or $p-1$, it\u0026rsquo;s the same, and whether we look at $2$ or $p-2$, it\u0026rsquo;s the same. Therefore, it is sufficient to only look at half of the original number $$ 1^2, 2^2, \\cdots , \\left( {{ p-1 } \\over { 2 }} \\right)^2 $$ These numbers are all QRs by the definition of QRs, so if we can show that all these numbers are different, then we can say that there are exactly $\\displaystyle {(p-1) \\over 2}$ QRs. Similarly, since a natural number smaller than $p$ in $\\pmod{p}$ is either a QR or an NR, if there are exactly $\\displaystyle {(p-1) \\over 2}$ QRs, then there must also be exactly $\\displaystyle {(p-1) \\over 2}$ NRs. The formal proof uses reductio ad absurdum. Let $b_1$ and $b_2$ be two different natural numbers smaller than $\\displaystyle {{(p-1)} \\over {2}}$.\nAssuming ${b_1}^2 \\equiv {b_2}^2 \\pmod{p}$ holds, then $$ {b_1}^2 - {b_2}^2 \\equiv 0 \\pmod{p} $$ Therefore, for some integer $k$, ${b_1}^2 - {b_2}^2 = pk$, and the prime $p$ is a divisor of $({b_1} + {b_2})({b_1} - {b_2})$. However, since $b_1$ and $b_2$ are assumed to be smaller than $\\displaystyle {{(p-1)} \\over {2}}$, $({b_1} + {b_2})$ is smaller than $(p-1)$. Hence, $p$ cannot be a divisor of $({b_1} + {b_2})$, and must therefore be a divisor of $({b_1} - {b_2})$. However, by the same reasoning $|{b_1} - {b_2}|$ is smaller than $(p-1)$, so it must be $0$ to be divided by $p$. That means, ${b_1} = {b_2}$, but we assumed $b_1$ and $b_2$ to be two different natural numbers smaller than $\\displaystyle {{(p-1)} \\over {2}}$, so this is a contradiction. Therefore, ${b_1}^2 \\neq {b_2}^2 \\pmod{p}$ and there are exactly $\\displaystyle {(p-1) \\over 2}$ QRs.\n‚ñ†\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p143.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":137,"permalink":"https://freshrimpsushi.github.io/en/posts/137/","tags":null,"title":"Quadratic Residues and Non-Quadratic Residues"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"This article is based on the Riemann-Stieltjes integral. If we set $\\alpha=\\alpha (x)=x$, it is the same as Riemann integral.\nTheorem1 A necessary and sufficient condition for a function $f$ to be Riemann(-Stieltjes) integrable on $[a,b]$ is that for every $\\epsilon \u0026gt;0$, there exists a partition $P$ of $[a,b]$ that satisfies $U(P,f,\\alpha) - L(P,f,\\alpha) \u0026lt; \\epsilon$.\n$$ \\begin{equation} f \\in \\mathscr{R} (\\alpha) \\text{ on } [a,b] \\\\ \\iff \\forall\\epsilon \u0026gt;0, \\exists P\\text{ s.t. } U(P,f,\\alpha) - L(P,f,\\alpha) \u0026lt; \\epsilon \\end{equation} $$\nThis condition is practically used when proving integrability.\nProof Given the assumptions below:\n$f : [a,b] \\to \\mathbb{R}$ is bounded. $\\alpha : [a,b] \\to \\mathbb{R}$ is a monotonically increasing function. $P$ is referred to as a partition of $[a,b]$. $(\\implies)$\nSuppose $f$ is a Riemann(-Stieltjes) integrable function and $\\epsilon \u0026gt; 0$ is given. By the definition of lower and upper integration, for every partition $P$, the following holds.\n$$ L(P,f,\\alpha) \\le \\underline{\\int _{a}^{b}} f d\\alpha = \\int _{a} ^{b} f d\\alpha $$\nTherefore, there exists a partition $P_{1}$ that satisfies:\n$$ \\begin{equation} \\int _{a} ^{b} f d\\alpha - L(P_{1},f,\\alpha) \u0026lt; \\frac{\\epsilon}{2} \\end{equation} $$\nSimilarly, the following is true.\n$$ \\int _{a} ^{b} f d\\alpha = \\overline {\\int _{a} ^{b}} f d\\alpha \\le U(P,f,\\alpha) $$\nThus, there exists a partition $P_{2}$ that satisfies:\n$$ \\begin{equation} U(P_2,f,\\alpha) - \\int _{a}^{b} f d\\alpha \u0026lt; \\frac{\\epsilon}{2} \\end{equation} $$\nNow, let\u0026rsquo;s call $P^{\\ast}$ the common refinement of $P_{1}$ and $P_{2}$. Then, since the refinement of the upper(sum) or lower(sum) is smaller(or larger) than the partition, by $(2)$, $(3)$, the following holds.\n$$ \\begin{align*} U(P^{\\ast},f,\\alpha) \u0026amp;\\le U(P_2,f,\\alpha) \\\\ \u0026amp;\\lt {\\color{blue}\\int _{a} ^{b} f d\\alpha} + \\frac{\\epsilon}{2} \\\\ \u0026amp;\\lt {\\color{blue} L(P_{1},f,\\alpha) + \\frac{\\epsilon}{2} } + \\frac{\\epsilon}{2} \\\\ \u0026amp;= L(P_{1},f,\\alpha) + \\epsilon \\\\ \u0026amp;\\le L(P^{\\ast},f,\\alpha) + \\epsilon \\end{align*} $$\nTherefore, there exists a partition $P^{\\ast}$ that satisfies $U(P^{\\ast},f,\\alpha)-L(P^{\\ast},f,\\alpha) \u0026lt; \\epsilon$.\n‚ñ†\n$(\\impliedby)$\nAssume for all $\\epsilon \u0026gt;0$, there exists a partition $P$ of $[a,b]$ that satisfies $U(P,f,\\alpha) - L(P,f,\\alpha) \u0026lt; \\epsilon$. By the definition of upper and lower integration, the following equation holds.\n$$ L(P,f,\\alpha) \\le \\underline {\\int _{a} ^{b}} f d\\alpha \\le \\overline{ \\int _{a} ^{b}}f d\\alpha \\le U(P,f,\\alpha) $$\nIf $A\u0026lt;B\u0026lt;C\u0026lt;D$, then $C-B\u0026lt;D-A$. Thus, using the assumption and the above equation, we obtain:\n$$ 0 \\le \\overline {\\int _{a}^{b}} f d\\alpha -\\underline{\\int _{a} ^{b}} f d\\alpha \u0026lt; \\epsilon $$\nFor this to be true for all positive numbers $\\epsilon$, the following must hold:\n$$ \\overline {\\int _{a}^{b}} f d\\alpha -\\underline{\\int _{a} ^{b}} f d\\alpha=0 $$\nTherefore, the following is true, and it is the definition of integrability for $f$, meaning $f$ is integrable.\n$$ \\overline {\\int _{a}^{b}} f d\\alpha =\\underline{\\int _{a} ^{b}} f d\\alpha $$\n‚ñ†\nCorollaries2 (a) If for some partition $P$ and $\\varepsilon \u0026gt;0$, $(1)$ holds, then $(1)$ also holds for all refinements of $P$.\n(b) If for a partition $P=\\left\\{ x_{0},\\cdots,x_{n} \\right\\}$, $(1)$ holds and we denote it by $s_{i},t_{i}\\in [x_{i-1},x_{n}]$, then the following inequality is true. $$ \\sum \\limits _{i=1} ^{n} \\left| f(s_{i}) -f(t_{i}) \\right| \\Delta \\alpha_{i} \u0026lt;\\varepsilon $$\n(c) If $f$ is integrable and the assumption of (b) holds, then the following formula is true. $$ \\left| \\sum \\limits _{i=1} ^{n} f(t_{i})\\Delta \\alpha_{i} - \\int _{a} ^{b}f (x)d\\alpha (x) \\right| \u0026lt; \\varepsilon $$\nProof (a) Let\u0026rsquo;s call $P^{\\ast}$ a refinement of $P$. Then, by the properties of refinements, the following holds.\n$$ U(P^{\\ast},f,\\alpha) -L(P^{\\ast},f,\\alpha)\u0026lt;U(P,f,\\alpha) -L(P,f,\\alpha) \u0026lt;\\varepsilon $$\nThus, (a) is true.\n‚ñ†\n(b) Let\u0026rsquo;s denote the following for $x\\in[x_{i-1},x_{i}]$:\n$$ M_{i}=\\sup f(x) \\quad \\text{and} \\quad m_{i}=\\inf f(x) $$\nThen for all $s_{i},t_{i}\\in [x_{i-1},x_{i}]$, the following is true.\n$$ \\left| f(s_{i})-f(t_{i}) \\right| \u0026lt; M_{i}-m_{i},\\quad i=1,\\cdots,n $$\nTherefore, by the definition of upper and lower sum, the following holds.\n$$ \\begin{align*} \\sum \\limits _{i=1} ^{n} \\left| f(s_{i})-f(t_{i}) \\right| \\Delta \\alpha_{i} \u0026amp;\u0026lt; \\sum \\limits _{i=1} ^{n}(M_{i}-m_{i})\\Delta \\alpha_{i} \\\\ \u0026amp;=U(P,f,\\alpha)-L(P,f,\\alpha) \\\\ \u0026amp;\u0026lt; \\varepsilon \\end{align*} $$\n‚ñ†\n(c) Continuing with the notation used in the previous proofs, it is self-evident by the definition of upper and lower sums that the following is true.\n$$ L(P,f,\\alpha) \\le \\sum \\limits _{i=1} ^{n} f(t_{i})\\Delta \\alpha_{i} \\le U(P,f,\\alpha) $$\nAlso, by the definition of integration, the following is obviously true.\n$$ L(P,f,\\alpha) \\le \\int _{a} ^{b} f(x)d\\alpha (x) \\le U(P,f,\\alpha) $$\nTherefore, by the above two formulas, the following is true.\n$$ \\left| \\sum \\limits _{i=1} ^{n} f(t_{i})\\Delta \\alpha_{i} - \\int _{a} ^{b}f (x)d\\alpha (x) \\right| \u0026lt; \\varepsilon $$\n‚ñ†\nWalter Rudin, Principles of Mathematical Analysis (3rd Edition, 1976), p124-125\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWalter Rudin, Principles of Mathematical Analysis (3rd Edition, 1976), p125\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":833,"permalink":"https://freshrimpsushi.github.io/en/posts/833/","tags":null,"title":"Necessary and Sufficient Conditions for Riemann(-Stieltjes) Integrability"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"This post is based on the Riemann-Stieltjes integral. If we set as $\\alpha=\\alpha (x)=x$, it is the same as the Riemann integral.\nDefinition If $P^{\\ast}$ and $P$ are partitions of $[a,b]$ and satisfy $P \\subseteq P^{\\ast}$, then $P^{\\ast}$ is called a refinement of $P$. Hence, every point in $P$ is a point in $P^{\\ast}$.\nFor any two partitions $P_{1}$ and $P_{2}$, $P_{3}=P_{1} \\cup P_{2}$ is called the common refinement of $P_{1}$ and $P_{2}$.\nRecall how integrals were defined in high school by dividing a given graph into $n$ equal parts, and taking the limit as $n$ goes to infinity. This makes it easy to understand the role of refinements.\nTheorem Let\u0026rsquo;s say $P^{\\ast}$ is a refinement of $P$. Then the following two equations hold:\n$$ \\begin{align} L(P,f,\\alpha) \u0026amp;\\le L(P^{\\ast},f,\\alpha) \\label{eq1} \\\\ U(P^{\\ast},f,\\alpha) \u0026amp;\\le U(P,f,\\alpha) \\label{eq2} \\end{align} $$\nHere, $L$ and $U$ are, respectively, the Riemann(-Stieltjes) upper and lower sums.\nIn other words, as the partition is refined, the lower sum increases and the upper sum decreases.\nProof Before proving, let\u0026rsquo;s state the following:\n$f : [a,b] \\to \\mathbb{R}$ is bounded. $\\alpha : [a,b] \\to \\mathbb{R}$ is a monotonically increasing function. Let $P$ be a partition of $[a,b]$. Let\u0026rsquo;s say $P^{\\ast}$ is a refinement of $P$ with just one more point and call this point $x^{\\ast}$. Suppose for some $i=1,\\cdots ,n$, we have $x_{i-1} \u0026lt; x^{\\ast} \u0026lt; x_{i}$.\n$\\eqref{eq1}$ The Riemann(-Stieltjes) lower sum for $P$ is as follows:\n$$ \\begin{align*} L(P,f,\\alpha) \u0026amp;= \\sum \\limits _{i=1} ^n m_{i} \\Delta \\alpha_{i} \\\\ \u0026amp;= m_{1}\\Delta \\alpha_{1} + \\cdots + m_{i} \\left[ \\alpha (x_{i}) - \\alpha (x_{i-1}) \\right] + \\cdots + m_{n}\\Delta \\alpha_{n} \\\\ \u0026amp;= m_{1}\\Delta \\alpha_{1} + \\cdots + m_{i} \\left[ \\alpha (x_{i}) -\\alpha (x^{\\ast}) \\right] + m_{i} \\left[ \\alpha (x^{\\ast})- \\alpha (x_{i-1}) \\right] + \\cdots + m_{n}\\Delta \\alpha_{n} \\end{align*} $$\nAnd let\u0026rsquo;s set the following:\n$$ \\begin{align*} w_{1} \u0026amp;= \\inf f(x) \u0026amp;(x_{i-1} \\le x \\le x^{\\ast}) \\\\ w_2\u0026amp;= \\inf f(x) \u0026amp;(x^{\\ast} \\le x \\le x_{i}) \\end{align*} $$\nThen, since $m_{i}=\\inf f(x)\\ \\ (x_{i-1} \\le x \\le x_{i})$, the following holds:\n$$ m_{i} \\le w_{1} \\quad \\text{and} \\quad m_{i} \\le w_2 $$\nTherefore, we obtain the following:\n$$ \\begin{align*} m_{i} \\left[ \\alpha (x_{i}) - \\alpha (x^{\\ast}) \\right] + m_{i}\\left[ \\alpha (x^{\\ast}) - \\alpha (x_{i-1}) \\right] \u0026amp;\\le w_2 \\left[ \\alpha (x_{i}) - \\alpha (x^{\\ast}) \\right] + w_{1}\\left[ \\alpha (x^{\\ast}) - \\alpha (x_{i-1}) \\right] \\\\ \u0026amp;= w_{1}\\left[ \\alpha (x^{\\ast}) - \\alpha (x_{i-1}) \\right] + w_2 \\left[ \\alpha (x_{i}) - \\alpha (x^{\\ast}) \\right] \\end{align*} $$\nThus, the following holds:\n$$ \\begin{align*} L(P,f,\\alpha) \u0026amp;= m_{1}\\Delta \\alpha_{1} + \\cdots + m_{i} \\left[ \\alpha (x_{i}) -\\alpha (x^{\\ast}) \\right] + m_{i} \\left[ \\alpha (x^{\\ast})- \\alpha (x_{i-1}) \\right] + \\cdots + m_{n}\\Delta \\alpha_{n} \\\\ \u0026amp;\\le w_{1}\\Delta \\alpha_{1} + \\cdots + w_{1}\\left[ \\alpha (x^{\\ast}) - \\alpha (x_{i-1}) \\right] + w_2 \\left[ \\alpha (x_{i}) - \\alpha (x^{\\ast}) \\right] + \\cdots + m_{n}\\Delta \\alpha_{n} \\\\ \u0026amp;= L(P^{\\ast},f,\\alpha) \\end{align*} $$\n‚ñ†\n$\\eqref{eq2}$ The proof follows the same method as for $\\eqref{eq1}$. The Riemann(-Stieltjes) upper sum for $P$ is as follows:\n$$ \\begin{align*} U(P,f,\\alpha) \u0026amp;= \\sum \\limits _{i=1} ^n M_{i} \\Delta \\alpha_{i} \\\\ \u0026amp;= M_{1}\\Delta \\alpha_{1} + \\cdots + M_{i} \\left[ \\alpha (x_{i}) - \\alpha (x_{i-1}) \\right] + \\cdots + M_{n}\\Delta \\alpha_{n} \\\\ \u0026amp;= M_{1}\\Delta \\alpha_{1} + \\cdots + M_{i} \\left[ \\alpha (x_{i}) -\\alpha (x^{\\ast}) \\right] + M_{i} \\left[ \\alpha (x^{\\ast})- \\alpha (x_{i-1}) \\right] + \\cdots + M_{n}\\Delta \\alpha_{n} \\end{align*} $$\nAnd let\u0026rsquo;s set the following:\n$$ \\begin{align*} W_{1} \u0026amp;= \\sup f(x)\u0026amp; (x_{i-1} \\le x \\le x^{\\ast}) \\\\ W_2\u0026amp;= \\sup f(x)\u0026amp;(x^{\\ast} \\le x \\le x_{i}) \\end{align*} $$ Then, since $M_{i}=\\sup f(x)\\ \\ (x_{i-1} \\le x \\le x_{i})$, the following holds:\n$$ W_{1} \\le M_{i} \\quad \\text{and} \\quad W_2 \\le M_{i} $$\nTherefore, we obtain the following:\n$$ \\begin{align*} M_{i} \\left[ \\alpha (x_{i}) - \\alpha (x^{\\ast}) \\right] + M_{i}\\left[ \\alpha (x^{\\ast}) - \\alpha (x_{i-1}) \\right] \u0026amp; \\ge W_2 \\left[ \\alpha (x_{i}) - \\alpha (x^{\\ast}) \\right] + W_{1}\\left[ \\alpha (x^{\\ast}) - \\alpha (x_{i-1}) \\right] \\\\ \u0026amp;= W_{1}\\left[ \\alpha (x^{\\ast}) - \\alpha (x_{i-1}) \\right] + W_2 \\left[ \\alpha (x_{i}) - \\alpha (x^{\\ast}) \\right] \\end{align*} $$\nThus, the following holds:\n$$ \\begin{align*} U(P,f,\\alpha) \u0026amp;= M_{1}\\Delta \\alpha_{1} + \\cdots + M_{i} \\left[ \\alpha (x_{i}) -\\alpha (x^{\\ast}) \\right] + M_{i} \\left[ \\alpha (x^{\\ast})- \\alpha (x_{i-1}) \\right] + \\cdots + M_{n}\\Delta \\alpha_{n} \\\\ \u0026amp;\\ge W_{1}\\Delta \\alpha_{1} + \\cdots + W_{1}\\left[ \\alpha (x^{\\ast}) - \\alpha (x_{i-1}) \\right] + W_2 \\left[ \\alpha (x_{i}) - \\alpha (x^{\\ast}) \\right] + \\cdots + M_{n}\\Delta \\alpha_{n} \\\\ \u0026amp;= U(P^{\\ast},f,\\alpha) \\end{align*} $$\n‚ñ†\n","id":830,"permalink":"https://freshrimpsushi.github.io/en/posts/830/","tags":null,"title":"Segmentation"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 Let\u0026rsquo;s call the field extension of field $F$ as $E$. For a non-constant function $f(x) \\in F [ x ]$, if it satisfies $f( \\alpha ) = 0$ for $\\alpha \\in E$, it is called algebraic over $F$, and if not, it is called transcendental. When $F = \\mathbb{Q}$, $E = \\mathbb{C}$, if $\\alpha \\in \\mathbb{C}$ is algebraic, it is called an algebraic number, and if transcendental, a transcendental number.\nExplanation For example, if there is a polynomial $ f(x) = x^2 - 2 $, there may be no rational root that satisfies $f(x) = 0$, but in the extended field $\\mathbb{R}$ from $\\mathbb{Q}$, there exists a root $\\sqrt{2}$. However, for numbers like $\\pi$, they cannot be derived in this manner. Thus, although both $\\sqrt{2}$ and $\\pi$ are irrational numbers, $\\sqrt{2}$ is an algebraic number, and $\\pi$ is a transcendental number.\nSurprisingly, the concepts of algebraic and transcendental numbers are familiar starting from high school. It is often heard that what distinguishes arts and sciences in high school is the calculus of transcendental functions, which usually comes with explanations about algebraic and transcendental numbers.\nAt the high school level, it is commonly explained that if it can be a solution to a polynomial equation with integer coefficients, it is an algebraic number; otherwise, it is a transcendental number. This can be neatly summarized as $F = \\mathbb{Q}$, $E = \\mathbb{C}$ when speaking in the language of abstract algebra.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p267.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":799,"permalink":"https://freshrimpsushi.github.io/en/posts/799/","tags":null,"title":"Algebraic Numbers and Transcendental Numbers"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Overview The Riemann-Stieltjes integral is a generalization of the Riemann integral, sometimes simply referred to as Stieltjes integral. The Riemann integral is a special case of the Riemann-Stieltjes integral where $\\alpha (x)=x$.\nThe process of defining the Riemann-Stieltjes integral is the same as the process of defining the Riemann integral, so details on the notation and buildup are omitted here.\nDefinition Let $\\alpha : [a,b] \\to \\mathbb{R}$ be a monotonically increasing function, and let $\\Delta \\alpha_{i}=\\alpha (x_{i})-\\alpha (x_{i-1})$. Then, since $\\alpha$ is a monotonically increasing function, $\\Delta \\alpha_{i} \\ge 0$ holds.\nFor a bounded function $f : [a,b] \\to \\mathbb{R}$ and a partition $P$ of $[a,b]$, define $U, L$ as follows.\n$$ \\begin{align} U(P,f,\\alpha) \u0026amp;:= \\sum \\limits _{i=1} ^n M_{i} \\Delta \\alpha_{i} \\\\ L(P,f,\\alpha) \u0026amp;:= \\sum \\limits_{i=1} ^n m_{i} \\Delta \\alpha_{i} \\end{align} $$\nDefine $(1), (2)$ as the upper and lower Riemann-Stieltjes sums of $f$ for $\\alpha$ in $[a,b]$.\nTaking the $\\inf, \\sup$ over all possible partitions $P$ of interval $[a,b]$ for $(1), (2)$ gives us the upper and lower Riemann-Stieltjes integrals of $f$ for $\\alpha$ in $[a,b]$.\n$$ \\begin{align*} \\overline {\\int _{a} ^b} f d\\alpha \u0026amp;:= \\inf\\limits_{P} U(P,f,\\alpha) \\\\ \\underline {\\int _{a} ^b} f d\\alpha \u0026amp;:= \\sup\\limits_{P} L(P,f,\\alpha) \\end{align*} $$\nIf the upper and lower integrals are equal, it is referred to as the Riemann-Stieltjes integral of $f$ for $\\alpha$ in $[a,b]$ and is denoted as follows.\n$$ \\int _{a} ^b f d\\alpha = \\int _{a}^b f(x) d\\alpha (x) = \\overline {\\int _{a} ^b} f d\\alpha = \\underline {\\int _{a} ^b} f d\\alpha $$\nIf the Stieltjes integral of $f$ exists, then $f$ is Riemann-Stieltjes integrable for $\\alpha$ in $[a,b]$, denoted as:\n$$ f \\in \\mathscr{R}(\\alpha) = \\left\\{ f : f \\text{ is Riemann-Stieltjes integrable} \\right\\} $$\n","id":829,"permalink":"https://freshrimpsushi.github.io/en/posts/829/","tags":null,"title":"Riemann-Stieltjes Integral"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 Theorem If $a^{n} \\equiv 1 \\pmod{p}$, then $\\text{ord}_{p} (a) \\mid n$.\nExplanation For example, consider $p=7$. $$ \\begin{align*} 1^{1} \\equiv \u0026amp; 1 \\pmod{ 7 } \\\\ 2^{3} \\equiv \u0026amp; 1 \\pmod{ 7 } \\\\ 3^{6} \\equiv \u0026amp; 1 \\pmod{ 7 } \\\\ 4^{3} \\equiv \u0026amp; 1 \\pmod{ 7 } \\\\ 5^{6} \\equiv \u0026amp; 1 \\pmod{ 7 } \\\\ 6^{2} \\equiv \u0026amp; 1 \\pmod{ 7 } \\end{align*} $$ Here, the order of $6$ is $2$, the order of $2, 4$ is $3$, and the order of $3,5$ is $6$.\nEspecially in the above theorem, if we set $n=p-1$, we can easily verify that $2,3,6$ divides $p-1= 6$. Furthermore, according to Fermat\u0026rsquo;s Little Theorem, for a prime number $p$, it always holds that $a^{p-1} \\equiv 1 \\pmod{p}$, thus we know $\\text{ord}_{p} (a) \\mid (p-1)$ is true.\nProof If we set $G := \\gcd ( \\text{ord}_{p} (a) , n )$, then there exists $s,t$ that satisfies $G = \\text{ord}_{p}(a) \\cdot s + n \\cdot t$.\nBy the definition of order and by assumption, $$ a^{G} = a^{ \\text{ord}_{p}(a) \\cdot s + n \\cdot t} = \\left( a^{ \\text{ord}_{p}(a) } \\right)^s \\cdot \\left( a^{n} \\right)^{t} \\equiv 1 \\cdot 1 \\pmod{p} $$ since $\\text{ord}_{p}(a)$ is defined as the smallest natural number $e$ that satisfies $a^{e} \\equiv 1 \\pmod{p}$, it follows that $G = \\text{ord}_{p}(a)$ and, $\\text{ord}_{p}(a) \\mid p$.\n‚ñ†\nCode Below is the code written in R language to compute the order. Prime factorization code was used.\nprime = read.table(\u0026#34;../attachment\r/cfile8.uf@25411C3C5968BBE322F0D4.txt\u0026#34;); prime = prime[,1]\rfactorize\u0026lt;-function(p)\r{\rq=p\rfactors\u0026lt;-numeric(0)\ri=1; j=1\rwhile(q!=1)\r{\rif(q%%prime[i]) {i=i+1}\relse\r{\rq\u0026lt;-q/prime[i]\rfactors[j]\u0026lt;-prime[i]\ri=1\rj=j+1\r}\r}\rreturn(factors)\r}\rorder\u0026lt;-function(g,p,h=1) #Calculate a order of g in modulo p\r{\rqe\u0026lt;-table(factorize(p-1))\rqe\u0026lt;-rbind(as.numeric(names(qe)),qe)\rdivisor\u0026lt;-qe[1,1]^(0:qe[2,1])\rif((length(qe)/2)==1) {return(qe[1,1]^qe[2,1])}\rfor(i in 2:(length(qe)/2)) {divisor=c(divisor%*%t(qe[1,i]^(0:qe[2,i])))}\rfor(i in divisor) {if((FPM(g,i,p))%%p==1) break;}\rreturn(i)\r}\rorder(1,7)\rorder(2,7)\rorder(3,7)\rorder(4,7)\rorder(5,7)\rorder(6,7) Below is the result of executing the above code.\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p211. Let us define $\\gcd (a, p) = 1$. The smallest natural number $e$ that satisfies $a^{e} \\equiv 1 \\pmod{p}$ is denoted as $\\text{ord}_{p} (a)$, and is defined as the order of $a$ modulo $p$.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":798,"permalink":"https://freshrimpsushi.github.io/en/posts/798/","tags":null,"title":"Orders in Number Theory"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition of Extension Field 1 For a field $F$, if there exists $E$ such that $F \\le E$, then $E$ is called the Extension Field of $F$.\nKronecker\u0026rsquo;s Theorem Assuming $f(x) \\in F [ x ]$ is not a constant, there exists an extension field $E$ of $F$ and $\\alpha \\in E$ such that $f ( \\alpha ) = 0$.\nDescription An example of an extension field is that $\\mathbb{C}$ is an extension field of $\\mathbb{R}$. Kronecker\u0026rsquo;s Theorem implies that even if a polynomial does not have roots in $F$ immediately, expanding the domain to $E$ enables the existence of roots. The statement that blindly expanding the field would magically yield roots, without even knowing what $F$ looks like, is very much a mathematical theorem in spirit.\nProof Part 1. Since $f(x)$ is not a constant function, it is uniquely factorized into irreducible elements over $F$, let one of these irreducible elements be $p(x)$. Then, the principal ideal $\\left\u0026lt; p(x) \\right\u0026gt;$ is a maximal ideal of $F [ x ]$, and $F [ x ] / \\left\u0026lt; p(x) \\right\u0026gt;$ becomes a field.\nPart 2. Existence of the Extension Field $E$\nDefining the mapping $\\psi : F \\to F [ x ] / \\left\u0026lt; p(x) \\right\u0026gt;$ as follows makes $\\psi$ naturally a homomorphism. $$ \\psi (a) := a + \\left\u0026lt; p(x) \\right\u0026gt; $$\nIf for some $a,b \\in F$, $\\psi (a) = \\psi (b)$ then $$ a + \\left\u0026lt; p(x) \\right\u0026gt; = b + \\left\u0026lt; p(x) \\right\u0026gt; $$ it implies $(b-a) \\in \\left\u0026lt; p(x) \\right\u0026gt;$, which means that $(b-a)$ is a constant multiple of $p(x)$. But since $a, b \\in F$ initially, $(b-a) \\in F$ and, for $(b-a)$ to be a constant multiple of $p(x)$, it must be that $(b-a) = 0$. Therefore $\\psi$ is injective, and $\\psi$ becomes an isomorphism that sends every element of $F$ to a subfield of $F [ x ] / \\left\u0026lt; p(x) \\right\u0026gt;$. Defining specifically $E := F [ x ] / \\left\u0026lt; p(x) \\right\u0026gt;$ then makes $E$ an extension field of $F$.\nPart 3. Existence of the Root $\\alpha \\in E$\nIf we set $\\alpha : = x + \\left\u0026lt; p(x) \\right\u0026gt;$ then initially $\\alpha$ $\\in E$. Define the substitution function $\\phi_{\\alpha} : F [ x ] \\to E$ for this $\\alpha$. If we explicitly present the chosen irreducible element as $p(x) := a_{0} + a_{1} x + \\cdots + a_{n} x^{n}$\n$$ \\begin{align*} p ( \\alpha) =\u0026amp; \\phi_{\\alpha} ( p(x) ) \\\\ =\u0026amp; a_{0} + a_{1} ( x + \\left\u0026lt; p(x) \\right\u0026gt; ) + \\cdots + a_{n} ( x + \\left\u0026lt; p(x) \\right\u0026gt; )^n \\\\ =\u0026amp; a_{0} + a_{1} ( x + \\left\u0026lt; p(x) \\right\u0026gt; ) + \\cdots + a_{n} ( x^n + \\left\u0026lt; p(x) \\right\u0026gt; ) \\\\ =\u0026amp; \\left( a_{0} + a_{1} x + \\cdots + a_{n} x^n \\right) + \\left\u0026lt; p(x) \\right\u0026gt; \\\\ =\u0026amp; p(x) + \\left\u0026lt; p(x) \\right\u0026gt; \\\\ =\u0026amp; 0 + \\left\u0026lt; p(x) \\right\u0026gt; \\end{align*} $$\nTherefore, in $F [ x ] / \\left\u0026lt; p(x) \\right\u0026gt;$, $p( \\alpha ) = 0$ and $\\alpha$ satisfies $f ( \\alpha ) = 0$. ‚ñ†\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p265.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":797,"permalink":"https://freshrimpsushi.github.io/en/posts/797/","tags":null,"title":"Definition and Proof of Kronecker's Theorem for Extension Bodies"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Partition1 Let\u0026rsquo;s assume the interval $[a,b]$ is given. The partition $P$ of $[a,b]$ is defined as follows.\n$$ P := \\left\\{ x_{0},\\ x_{1},\\ \\cdots, x_{n}\\right\\},\\quad a=x_{0} \u0026lt;x_{1}\u0026lt;\\cdots \u0026lt; x_{n} =b $$\nAnd $\\Delta x_{i}$ is defined as follows.\n$$ \\Delta x_{i} :=x_{i}-x_{i-1},\\quad i=1,2,\\cdots,n $$\nExplanation Simply put, a partition is a set that contains all points at the ends of an interval and all boundary points within the interval when the interval is divided. An important point is that to talk about a partition, it is necessary to specify which interval it pertains to. That is, one cannot merely speak of a partition; one must refer to the partition of a certain interval.\nRiemann Sum Let $f$ be a bounded function defined on $[a,b]$, and let $P$ be a partition of $[a,b]$. Also, let\u0026rsquo;s assume $M_{i}$ and $m_{i}$ are as follows.\n$$ \\begin{align*} M_{i} \u0026amp;=\\sup f(x),\u0026amp;(x_{i-1} \\le x \\le x_{i}) \\\\ m_{i}\u0026amp;=\\inf f(x), \u0026amp;(x_{i-1} \\le x \\le x_{i}) \\end{align*} $$\nThen, $U(P,f), L(P,f)$ is defined as follows, and they are called the $P$-related upper and lower Riemann sum of $f$, respectively.\n$$ \\begin{align*} U(P,f) \u0026amp;:=\\sum \\limits _{i=1} ^n M_{i} \\Delta x_{i} \\\\ L(P,f) \u0026amp;:= \\sum \\limits _{i=1} ^{n} m_{i}\\Delta x_{i} \\end{align*} $$\nExplanation The Riemann sum approximates the area under a function by dividing the interval. For a given partition $P$, the upper sum refers to the largest value, and the lower sum refers to the smallest value. If the approximation is so close that there is no difference between upper and lower sums, it can be considered as the area under the graph of $f$.\nRiemann Integral The upper Riemann integral of $f$ over $[a,b]$ consists of taking $\\inf$ over all partitions $P$ of the interval $[a,b]$.\nThis is defined as the supremum of the upper sums regarding each partition $P$ and is represented as follows.\n$$ \\begin{equation} \\overline{\\int _{a}^{b}} f dx := \\inf \\limits_{P} U(P,f) \\label{eq1} \\end{equation} $$\nSimilarly, the lower Riemann integral of $f$ over $[a,b]$ consists of taking $\\sup$ over all partitions $P$ of interval $[a,b]$.\n$$ \\begin{equation} \\underline {\\int _{a}^b } f dx := \\sup \\limits_{P} L(P,f) \\label{eq2} \\end{equation} $$\nWhen the upper and lower Riemann integrals of $f$ are equal, $f$ is considered Riemann integrable over $[a,b]$ and is denoted as follows.\n$$ f \\in \\mathscr{R}= \\left\\{ f : f \\text{ is Riemann integrable} \\right\\} $$\n$\\mathscr R$ is the set of Riemann integrable functions. Moreover, the common value of $(1)$ and $(2)$ is denoted as follows, and this is referred to as the Riemann integral of $f$ over $[a,b]$.\n$$ \\underline {\\int _{a}^b } f dx = \\int _{a} ^b f dx = \\overline {\\int _{a}^b} f dx $$\nOr\n$$ \\int _{a} ^b f(x) dx $$\nExplanation The upper integral approximates the area of $f$ slightly larger (upper sum) among the smallest ones, and the lower integral approximates the area slightly smaller (lower sum) among the largest ones. Thus, when these two are identical, it can be stated that the area under the graph of $f$ has been accurately approximated.\nFurthermore, as $f$ is bounded, there exist two constants $M$ and $m$ that satisfy the following.\n$$ m \\le f(x) \\le M \\ \\ \\ (a\\le x\\le b) $$\nTherefore, the following holds for all partitions $P$.\n$$ m(b-a) \\le L(P,f) \\le U(P,f) \\le M(b-a) $$\nWalter Rudin, Principles of Mathematical Analysis (3rd Edition, 1976), p120-121\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":828,"permalink":"https://freshrimpsushi.github.io/en/posts/828/","tags":null,"title":"Partition, Riemann Sum, Riemann Integral"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 An integer $n$ is called a Carmichael number if for all $1 \\le a \\le n$, it satisfies $a^{n} \\equiv a \\pmod{n}$.\nTheorem Every Carmichael number is a product of distinct primes, except for $2$.\nDescription Carmichael numbers are composite numbers that pass the Fermat\u0026rsquo;s Little Theorem, meaning they appear to be prime. For example, $561=3 \\cdot 11 \\cdot 17$ is a composite number, but $a^{561} \\equiv a \\pmod{561}$ always holds.\nMeanwhile, the Miller-Rabin primality test is available to catch such Carmichael numbers.\nProof Let\u0026rsquo;s say $n$ is a Carmichael number.\nPart 1. If we set $a = n-1$, then because of $n-1 \\equiv -1 \\pmod{n}$, we have $$ (n-1)^{n} \\equiv (-1)^{n} \\equiv -1 \\pmod{n} $$ The above congruence holds only when $n$ is odd.\nPart 2. Suppose $n$ is represented by $n = p_{1}^{r_{1} + 1} \\cdots p_{m}^{r_{m} + 1}$ for primes $p_{1}, \\cdots , p_{m}$ excluding $2$. Let\u0026rsquo;s set $\\displaystyle r : = \\max \\left\\{ r_{1}, \\cdots , r_{m} \\right\\}$ and show that $r=0$. Let\u0026rsquo;s denote the prime corresponding to $r$ as $p$.\nSince $n$ is a Carmichael number, we have $p^{rn} \\equiv p^{r} \\pmod{n}$, and $n$ must divide $\\left( p^{rn} - p^{r} \\right)$. Also, since one of the divisors of $n$ was $p^{r+1}$, $p^{r+1}$ must divide $\\left( p^{rn} - p^{r} \\right)$. Thus, $$ {{ p^{rn} - p^{r} } \\over { p^{r+1} }} = {{ p^{rn - r} - 1 } \\over { p }} $$ This implies that it is an integer, which is only possible when $0$ in the numerator makes $r=0$.\n‚ñ†\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p133.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":794,"permalink":"https://freshrimpsushi.github.io/en/posts/794/","tags":null,"title":"Carmichael Numbers"},{"categories":"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ","contents":"Theorem[^1] Let $\\left( H, \\left\\langle \\cdot,\\cdot \\right\\rangle \\right)$ be a Hilbert space. For linear functionals $f \\in H^{ \\ast }$ and $\\mathbf{x} \\in H$ satisfying $f ( \\mathbf{x} ) = \\left\\langle \\mathbf{x} , \\mathbf{w} \\right\\rangle$ and $\\| f \\|_{H^{\\ast}} = \\| \\mathbf{w} \\|_{H}$, there exists a unique $\\mathbf{w} \\in H$.\n","id":786,"permalink":"https://freshrimpsushi.github.io/en/posts/786/","tags":null,"title":"Proof of Liouville's Theorem"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Definition $$U_{n} (x) := {{1} \\over {n+1} } T_{n+1} \u0026rsquo; (x) = {{\\sin \\left( ( n +1 ) \\theta \\right)} \\over { \\sin \\theta }} $$ is called the second kind Chebyshev polynomial.\nBasic Properties Recursive Formula [0]: $$U_{n+1} (x) = 2x U_{n} (x) - U_{n-1} (X)$$ Orthogonal Set [1] Inner product of functions: Given the weight $w$ for $\\displaystyle \\left\u0026lt;f, g\\right\u0026gt;:=\\int_a^b f(x) g(x) w(x) dx$ as $\\displaystyle w(x) := \\sqrt{1 - x^2}$, then $\\left\\{ U_{0} , U_{1}, U_{2}, \\cdots \\right\\}$ forms an orthogonal set. Chebyshev Nodes [2]: The roots of $\\displaystyle U_{n} (X)$ are as follows for $k=1, \\cdots , n$. $$x_{k} = \\cos \\left( {{k} \\over {n+1}} \\pi \\right)$$ Even and Odd Functions [3]: $$U_{n} (-x) = (-1)^{n} U_{n} (x)$$ Normally, for $0 \\le \\theta \\le \\pi$, it is assumed that $\\theta := \\cos^{-1} x $. See Also First kind Chebyshev polynomial Second kind Chebyshev polynomial Relationship between the first and second kind Chebyshev polynomials Chebyshev polynomials as solutions to the Chebyshev differential equation Explanation The second kind Chebyshev polynomial for $n = 0, \\cdots , 3$ is represented as follows.\n$$ \\begin{align*} U_{0} (x) =\u0026amp; 1 \\\\ U_{1} (x) =\u0026amp; 2x \\\\ U_{2} (x) =\u0026amp; 4x^{2} - 1 \\\\ U_{3} (x) =\u0026amp; 8x^{3} - 4x \\end{align*} $$\n$T_{n} (X)$ is the first kind Chebyshev polynomial.\nShowing that $\\displaystyle {{1} \\over {n+1} } T_{n+1} \u0026rsquo; (x) = {{\\sin \\left( ( n +1 ) \\theta \\right)} \\over { \\sin \\theta }}$ can be done using the differentiation of inverse trigonometric functions as follows. $$ \\begin{align*} \\displaystyle U_{n} (x) =\u0026amp; {{1} \\over {n+1} } \\left[ \\cos \\left( ( n +1 ) \\cos^{-1} x \\right) \\right]\u0026rsquo; \\\\ \u0026amp;= {{n+1} \\over {n+1} } {{ - 1} \\over { \\sqrt{ 1 - x^{2} } }} \\left[ - \\sin \\left( ( n +1 ) \\cos^{-1} x \\right) \\right] \\\\ =\u0026amp; {{\\sin \\left( ( n +1 ) \\cos^{-1} x \\right)} \\over { \\sqrt{ 1 - x^{2} } }} \\\\ =\u0026amp; {{ \\sin \\left( (n+1) \\theta \\right) } \\over {\\sin \\theta }} \\end{align*} $$ The second kind Chebyshev polynomial is very useful not only in numerical analysis but also in applied mathematics as a whole, boasting interesting properties along with the first kind Chebyshev polynomial.\nMeanwhile, the second kind Chebyshev polynomial can also be defined in reverse using $U_{0} (x) = 1$, $U_{1} (x) = 2x$, and the recursive formula [0]. This is also true for the first kind Chebyshev polynomial, and the reason for naming the first and second kinds is considered to be due to $T_{1} (x) = 1 \\cdot x$ and $U_{1} (x) = 2 \\cdot x$.\nProof [0] By differentiating both sides of the recursive formula $T_{n+1} (x) = 2x T_{n} (x) - T_{n-1} (X)$ of the first kind Chebyshev polynomial $$ T_{n+1} ' (x) = 2 T_{n} (x) + 2x T_{n} ' (x) - T_{n-1} ' (x) $$ since $T_{n+1} ' (x) = ( n+1 ) U_{n} (x) $, $$ (n+1) U_{n} (x) = 2 T_{n} (x) + 2x n U_{n-1} (x) - (n-1) U_{n-2} (x) $$ and combining as $n$, $$ n \\left[ U_{n} (x) - 2x U_{n-1} (x) + U_{n-2} (x) \\right] = 2 T_{n} (x) + U_{n-2} (x) - U_{n} (x) $$\nRelationship between the first and second kind Chebyshev polynomials:\n[1]: $$U_{n} (x) - U_{n-2} (x) = 2 T_{n} (X)$$ $$ n \\left[ U_{n} (x) - 2x U_{n-1} (x) + U_{n-2} (x) \\right] = 0 $$ Dividing both sides by $n$ and rearranging yields $$ U_{n+1} (x) = 2x U_{n} (x) - U_{n-1} (x) $$\n‚ñ†\n[1] Since $dx = - \\sin \\theta d \\theta = - \\sqrt{1 - x^2} d \\theta$ and $\\sin \\theta = \\sqrt{1 - x^2}$, $$ \\begin{align*} \\displaystyle \\left\u0026lt; U_{n}, U_{m} \\right\u0026gt; =\u0026amp; \\int_{-1}^{1} U_{n} (x) U_{m} (x) \\sqrt{1 - x^2} d x \\\\ =\u0026amp; - \\int_{\\pi}^{0} {{ \\sin \\left( (n + 1 ) \\theta \\right) \\sin \\left( (m + 1 ) \\theta \\right) \\sin^2 \\theta } \\over { \\sin^2 \\theta}} d \\theta \\\\ =\u0026amp; \\int_{0}^{\\pi} \\sin \\left( (n + 1 ) \\theta \\right) \\sin \\left( (m + 1 ) \\theta \\right) d \\theta \\\\ =\u0026amp; \\begin{cases} \\pi/2 \u0026amp;, n=m \\\\ 0 \u0026amp;, n \\ne m \\end{cases} \\end{align*} $$ thus $\\left\\{ U_{0} , U_{1}, U_{2}, \\cdots \\right\\}$ forms an orthogonal set.\n‚ñ†\n[2] It is self-evident by definition.\n‚ñ†\n[3] Case 1. $n=0,1$\n$$ \\begin{align*} U_{0} (-x) =\u0026amp; 1 = U_{0} (x) \\\\ U_{1} (-x) =\u0026amp; 2(-x) = -2x = - U_{1} (x) \\end{align*} $$\nCase 2. $n \\ge 2$ is even\nSince the degree of all terms that are not $0$ in $U_{n}(x)$ is even, $U_{n}(-x) = U_{n}(x)$\nCase 3. $n \\ge 2$ is odd\nSince the degree of all terms that are not $0$ in $U_{n}(x)$ is odd, $U_{n}(-x) = - U_{n}(x)$\n‚ñ†\nImplementation Below is the code for the Chebyshev polynomial written in R.\nSince it returns the polynomial itself, it can be directly used for calculations. n is the degree, and by setting kind and turning the print option to true, it will print the coefficients.\nThe printed coefficients are from the constant term to the higher-order terms in sequence, and since the second kind Chebyshev polynomial is $U_{3} (x) = 8x^{3} - 4x$, it is correct. The value of the function is also accurately calculated as $U_{3} (3) = 8 \\cdot 3^{3} - 4 \\cdot 3 = 216-12 = 204$.\nChebyshev\u0026lt;-function(n,kind=1,print=F)\r{\rp\u0026lt;-NA\rif((round(n)-n)!=0 | n\u0026lt;0) {stop(\u0026#34;Wrong Degree!!\u0026#34;)} #degree must be nonnegative integer\rif(!kind%in%(1:2)) {stop(\u0026#34;Wrong Kind!!\u0026#34;)} #kind must be 1 or 2\rif(n==0)\r{\rif(print) {print(1)}\rp\u0026lt;-function(x) {return(1)}\rreturn(p)\r}\rif(n==1)\r{\rif(print) {print(c(0,kind))}\rp\u0026lt;-function(x) {return(kind*x)}\rreturn(p)\r}\rcoef0\u0026lt;-c(1)\rcoef1\u0026lt;-c(0,kind)\rfor(i in 1:(n-1))\r{\rcoef2\u0026lt;- ( c(0,2*coef1) - c(coef0,0,0) )\rcoef0\u0026lt;-coef1\rcoef1\u0026lt;-coef2\r}\rif(print) {print(coef2)}\rp\u0026lt;-function(x) {return(sum(coef2*x^(0:n)))}\rreturn(p)\r}\rp\u0026lt;-Chebyshev(1,2); p(2)\rp\u0026lt;-Chebyshev(3,2,T); p(3) ","id":779,"permalink":"https://freshrimpsushi.github.io/en/posts/779/","tags":null,"title":"Second Kind Chebyshev Polynomials"},{"categories":"ÏàòÏπòÌï¥ÏÑù","contents":"Definition 1 $T_{n} (x) = \\cos \\left( n \\cos^{-1} x \\right)$ is called the first kind Chebyshev polynomial.\nBasic Properties Recurrence Formula [0]: $$T_{n+1} (x) = 2x T_{n} (x) - T_{n-1} (X)$$ Orthogonal Set [1] Inner product of functions: Given the weight $w$ as $\\displaystyle w(x) := {{1} \\over { \\sqrt{1 - x^2} }}$, $\\left\\{ T_{0} , T_{1}, T_{2}, \\cdots \\right\\}$ forms an orthogonal set. Chebyshev Nodes [2]: The roots of $T_{n} (x)$ are the Chebyshev nodes for $k=1, \\cdots , n$. $$x_{k} = \\cos \\left( {{2k-1} \\over {2n}} \\pi \\right)$$ Even and Odd Functions [3]: $$T_{n} (-x) = (-1)^{n} T_{n} (x)$$\nTypically, $0 \\le \\theta \\le \\pi$ is defined as $\\theta := \\cos^{-1} x $. See Also First kind Chebyshev polynomial Second kind Chebyshev polynomial Relationship between first and second kind Chebyshev polynomials Chebyshev polynomials as solutions to Chebyshev\u0026rsquo;s differential equation Description The first kind Chebyshev polynomial for $n = 0, \\cdots , 3$ is expressed as follows:\n$$ \\begin{align*} T_{0} (x) =\u0026amp; 1 \\\\ T_{1} (x) =\u0026amp; x \\\\ T_{2} (x) =\u0026amp; 2x^{2} - 1 \\\\ T_{3} (x) =\u0026amp; 4x^{3} - 3x \\end{align*} $$\nThe first kind Chebyshev polynomial is very useful not only in numerical analysis but also in applied mathematics in general, and together with the second kind Chebyshev polynomial, it has a wide range of interesting properties.\nMeanwhile, the first kind Chebyshev polynomial can also be defined using the inverse $T_{0} (x) = 1$, $T_{1} (x) = x$, and the recurrence formula [0]. This is also true for the second kind Chebyshev polynomial, so it is reasonable to refer to the first and second kinds for reasons $T_{1} (x) = 1 \\cdot x$ and $U_{1} (x) = 2 \\cdot x$.\nProof [0] Since $T_{n} (x) = \\cos \\left( n \\theta \\right)$, by the addition theorem of trigonometric functions $$ T_{n \\pm 1} (x) = \\cos (n \\pm 1) \\theta = \\cos (n \\theta ) \\cos \\theta \\mp \\sin ( n \\theta ) \\sin \\theta $$ Adding both sides $$ T_{n+1} (x) + T_{n-1} (x) = 2 \\cos (n \\theta ) \\cos \\theta = 2 T_{n} (x) x $$ Rearranging $T_{n-1} (x)$ gives $$ T_{n+1} (x) = 2x T_{n} (x) - T_{n-1} (x) $$\n‚ñ†\n[1] Since $dx = - \\sin \\theta d \\theta = - \\sqrt{1 - x^2} d \\theta$, $$ \\begin{align*} \\displaystyle \\left\u0026lt; T_{n}, T_{m} \\right\u0026gt; =\u0026amp; \\int_{-1}^{1} T_{n} (x) T_{m} (x) {{1} \\over { \\sqrt{1 - x^2} }} dx \\\\ =\u0026amp; - \\int_{\\pi}^{0} \\cos n \\theta \\cos m \\theta d \\theta \\\\ =\u0026amp; \\int_{0}^{\\pi} \\cos n \\theta \\cos m \\theta d \\theta \\\\ =\u0026amp; \\begin{cases} \\pi/2 \u0026amp;, n=m \\\\ 0 \u0026amp;, n \\ne m \\end{cases} \\end{align*} $$ Therefore, $\\left\\{ T_{0} , T_{1}, T_{2}, \\cdots \\right\\}$ forms an orthogonal set.\n‚ñ†\n[2] Trivial by definition.\n‚ñ†\n[3] Case 1. $n=0,1$\n$$ T_{0} (-x) = 1 = T_{0} (x) $$\n$$ T_{1} (-x) = (-x) = -x = - T_{1} (x) $$\nCase 2. $n \\ge 2$ is even\nSince all terms of $T_{n}(x)$ have even degrees except the coefficient $0$, $T_{n}(-x) = T_{n}(x)$\nCase 3. $n \\ge 2$ is odd\nSince all terms of $T_{n}(x)$ have odd degrees except the coefficient $0$, $T_{n}(-x) = - T_{n}(x)$\n‚ñ†\nImplementation Below is the code for the Chebyshev polynomial written in R.\nSince the polynomial itself is returned, it can be directly used for calculations. n is the degree, kind specifies the type, and if the print option is true, it outputs the coefficients.\nThe coefficients are output from the constant term to the high-order term, and since the first kind Chebyshev polynomial is $T_{3} (x) = 4x^{3} - 3x$, it is correctly obtained. The function value is also accurately calculated as $T_{3} (3) = 4 \\cdot 3^{3} - 3 \\cdot 3 = 108-9 = 99$.\nChebyshev\u0026lt;-function(n,kind=1,print=F)\r{\rp\u0026lt;-NA\rif((round(n)-n)!=0 | n\u0026lt;0) {stop(\u0026#34;Wrong Degree!!\u0026#34;)} #degree must be nonnegative integer\rif(!kind%in%(1:2)) {stop(\u0026#34;Wrong Kind!!\u0026#34;)} #kind must be 1 or 2\rif(n==0)\r{\rif(print) {print(1)}\rp\u0026lt;-function(x) {return(1)}\rreturn(p)\r}\rif(n==1)\r{\rif(print) {print(c(0,kind))}\rp\u0026lt;-function(x) {return(kind*x)}\rreturn(p)\r}\rcoef0\u0026lt;-c(1)\rcoef1\u0026lt;-c(0,kind)\rfor(i in 1:(n-1))\r{\rcoef2\u0026lt;- ( c(0,2*coef1) - c(coef0,0,0) )\rcoef0\u0026lt;-coef1\rcoef1\u0026lt;-coef2\r}\rif(print) {print(coef2)}\rp\u0026lt;-function(x) {return(sum(coef2*x^(0:n)))}\rreturn(p)\r}\rp\u0026lt;-Chebyshev(1,1); p(2)\rp\u0026lt;-Chebyshev(3,1,T); p(3) Atkinson. (1989). An Introduction to Numerical Analysis(2nd Edition): p211.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":777,"permalink":"https://freshrimpsushi.github.io/en/posts/777/","tags":null,"title":"First kind Chebyshev polynomials"},{"categories":"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ","contents":"Definition1 A Hilbert space is a complete inner product space. It is commonly denoted by $H$ and named after Hilbert.\nDescription A complete space is a space in which every Cauchy sequence converges. Since Banach spaces are also complete spaces, Hilbert spaces can be described as Banach spaces with an inner product. Examples include:\nLebesgue spaces $L^{2}$ $\\ell^{2}$ spaces Real number space $\\mathbb{R}^{n}$ Complex number space $\\mathbb{C}^{n}$ Properties Hilbert spaces are uniformly convex Shortest vector theorem Orthogonal decomposition theorem Riesz representation theorem Ole Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p65\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":776,"permalink":"https://freshrimpsushi.github.io/en/posts/776/","tags":null,"title":"Hilbert Spaces in Functional Analysis"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Definitions Given two metric spaces $(X,\\ d_X), (Y,\\ d_Y)$, if there exists a mapping $f : X \\to Y$ that satisfies the conditions below, then $X$ and $Y$ are said to be isometric, denoted by $X \\approx Y$. Furthermore, the mapping $f$ is called an isometric map or isometry.\n$$ d_X(x_1,\\ x_2) =d_Y\\big( f(x_1),\\ f(x_2) \\big),\\quad \\forall\\ x_1,x_2\\in X $$\nExplanation As the name suggests, an isometric map is a mapping that preserves distance. Therefore, two spaces that have an isometric map between them can be considered \u0026rsquo;essentially\u0026rsquo; the same. Moreover, an isometry naturally becomes a one-to-one function from its definition.\nIn Normed Spaces If $X$ and $Y$ are normed spaces, since the distance is defined below, an isometric map becomes a mapping that preserves the norm.\n$$ d_X(x_1,x_2) = \\|x_1-x_2\\|_X $$\nDefinition1 Let $(X, \\left\\| \\cdot \\right\\|_{X}), (Y, \\left\\| \\cdot \\right\\|_{Y})$ be a normed space. If there exists a linear operator $L\\ : X \\to Y$ that satisfies the conditions below for $X$ and $Y$, then $L$ is called an isometric isomorphism. Moreover, $X$ and $Y$ are said to be isometrically isomorphic.\n$$ \\|x\\|_X = \\|L(x)\\|_Y, \\quad \\forall\\ x\\in X $$\nProperties The following facts hold for isometric maps:\nIsometric maps are one-to-one functions. Isometric maps are homeomorphisms. $\\approx$ is an equivalence relation. An isometric map is an embedding. Proof Let $x_1,x_2\\in X$ and $f(x_1)=f(x_2)$. Then, by the definition of distance, $d_Y\\big( f(x_1),\\ f(x_2) \\big)=0$ holds. Since $f$ preserves distance, $d_X(x_1,\\ x_2)=0$ holds and similarly by the definition of distance, $x_1=x_2$ holds. If $f(x_1)=f(x_2)$, then $x_1=x_2$ holds, hence $f$ is a one-to-one function.\n‚ñ†\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p5\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":756,"permalink":"https://freshrimpsushi.github.io/en/posts/756/","tags":null,"title":"Isometric Mapping"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Dual Spaces Definition 11 The set of all continuous linear functionals of a vector space $X$ is denoted by $X^{ \\ast }$ and is called the dual space of $X$, simply referred to as the dual of $X$, as denoted below.\n$$ X^{ \\ast }:=\\left\\{ x^{ \\ast }:X\\to \\mathbb{C}\\ |\\ x^{ \\ast } \\text{ is continuous and linear} \\right\\} $$\n$$ X^{ \\ast }:=B(X,\\mathbb{C}) $$\n$B \\left( X, \\mathbb{C} \\right)$ is the set of bounded linear operators whose domain is $X$ and codomain is $\\mathbb{C}$.\nDefinition 22 For a vector space $X$ over the field $F$, the set of linear functionals on $X$ is called the dual space of $X$ and is denoted by $X^{\\ast}$.\n$$ X^{\\ast} = L(X, F) $$\n$L(X, F)$ is the set of all linear transformations from $X$ to $F$.\nExplanation By the properties of linear operators, the condition of continuity is equivalent to the condition of boundedness. Instead of the symbol $\\ast$, $^{\\prime}$ is also used to denote the dual space. It is also possible to talk about the dual space of the dual space. In this case, it is denoted as $X^{\\ast \\ast}=\\left( X^{ \\ast } \\right)^{ \\ast }$ and called as bidual, double dual, or second dual.\nRegarding the operator norm $\\displaystyle \\| f \\| = \\sup_{\\substack{x \\in X \\\\ \\| x \\| =1}} | f(x) |$, $(X^{ \\ast } , \\| \\cdot \\| )$ becomes a Banach space. The following theorem holds.\nTheorem If $X$ is a finite-dimensional vector space, then the following holds.\n$$ \\dim X^{ \\ast } = \\dim X $$\nProof Method 11 Strategy: Use the basis of $\\dim X$ to create a basis that makes $\\dim X^{ \\ast }$ finite-dimensional.\nIf we let $\\dim X = n$, since $X$ is finite-dimensional, it has a basis $\\left\\{ \\tilde{ e_{1} } , \\cdots , \\tilde{ e_{n} } \\right\\}$.If we then let $\\displaystyle e_{j} : = {{ \\tilde{e_{j} } } \\over { \\| \\tilde{ e_{j} } \\| }} \\in X$, $\\| e_{j} \\| = 1$ and $\\left\\{ e_{1} , \\cdots , e_{n} \\right\\}$ is still a basis of $X$. Now, let\u0026rsquo;s define $e_{j}^{ \\ast } : (X , \\| \\cdot \\| ) \\to ( \\mathbb{C} , | \\cdot | )$ as follows.\n$$ e_{j}^{ \\ast } (e_{i}) := \\delta_{ij} $$\nProperties of Linear Operators\nLet $T : (X , \\| \\cdot \\|_{X}) \\to ( Y , \\| \\cdot \\|_{Y} )$ be a linear operator. If $X$ is a finite-dimensional space, then $T$ is continuous.\nSince we assumed $\\dim X = n$, $e_{j}^{ \\ast }$ is a continuous linear functional.\nNecessary and Sufficient Conditions for Linear Functionals to be Expressed as Linear Combinations\nLet $f_{1} , \\cdots , f_{n}$ be a linear functional with domain $X$.\nThere exists $x_{1} , \\cdots , x_{n}$ that satisfies $\\iff$ $f_{j} (x_{i} ) = \\delta_{ij}$ if $f_{1} , \\cdots , f_{n}$ is linearly independent\nAccording to the above theorem, $\\beta^{\\ast} = \\left\\{ e_{1}^{\\ast}, \\dots, e_{n}^{\\ast} \\right\\}$ is linearly independent. Applying $f \\in X^{ \\ast }$ to any $\\displaystyle x = \\sum_{i=1}^{n} t_{i} e_{i} \\in X$ results in\n$$ f(x) = f\\left( \\sum_{i=1}^{n} t_{i} e_{i} \\right) = \\sum_{i=1}^{n} t_{i} f(e_{i} ) = \\sum_{i=1}^{n} f(e_{i} ) t_{i} $$\nSince $\\displaystyle t_{i} = e_{i}^{ \\ast } \\left( \\sum_{k=1}^{n} t_{k} e_{k} \\right) = e_{i}^{ \\ast } (x)$,\n$$ f(x) = \\sum_{i=1}^{n} f(e_{i} ) e_{i}^{ \\ast } (x) = \\left[ \\sum_{i=1}^{n} f(e_{i} ) e_{i}^{ \\ast } \\right] (x) $$\nTherefore,\n$$ f = \\sum_{i=1}^{n} f(e_{i} ) e_{i}^{ \\ast } \\in \\text{span} \\left\\{ e_{1}^{ \\ast } , \\cdots , e_{n}^{ \\ast } \\right\\} $$\nIn other words, $\\beta^{\\ast} = \\left\\{ e_{1}^{ \\ast } , \\cdots , e_{n}^{ \\ast } \\right\\}$ is linearly independent and generates $X^{\\ast}$, so it is a basis of $X^{ \\ast }$.\n$$ \\dim X^{ \\ast } = n $$\n‚ñ†\nMethod 22 Since $\\dim(L(X,F)) = \\dim(X)\\dim(F)$,\n$$ \\dim(X^{\\ast}) = \\dim(L(X,F)) = \\dim(X)\\dim(F) = \\dim(X) $$\n‚ñ†\nAlthough this concludes the proof of the theorem itself, let\u0026rsquo;s concretely find the basis of $X^{\\ast}$. Let $\\beta = \\left\\{ x_{1}, \\dots, x_{n} \\right\\}$ be the ordered basis of $X$. Also, let\u0026rsquo;s refer to $f_{i}$ as the $i$th coordinate function.\n$$ f_{i}(x_{j}) = \\delta_{ij} $$\nThus, $f_{i}$ is a linear functional defined on $X$. Now, let\u0026rsquo;s assume $\\beta^{\\ast} = \\left\\{ f_{i}, \\dots, f_{n} \\right\\}$.\nClaim: $\\beta^{\\ast}$ is an (ordered) basis of $X^{\\ast}$\nWe already know $\\dim (X^{\\ast}) = n$, so all we have to show is $\\span(\\beta^{\\ast}) = X^{\\ast}$. That is, we have to demonstrate that any $f \\in X^{\\ast}$ can be represented as a linear combination of $f_{i}$s. Given $f$, let\u0026rsquo;s assume $g = \\sum_{i=1}^{n}f(x_{i})f_{i}$. Then, in fact, this $g$ is precisely $f$, and we can see that $f$ is represented as a linear combination of $f_{i}$s. Regarding $1 \\le j \\le n$,\n$$ g(x_{j}) = \\left( \\sum_{i=1}^{n}f(x_{i})f_{i} \\right) (x_{j}) = \\sum_{i=1}^{n}f(x_{i})f_{i}(x_{j}) = \\sum_{i=1}^{n}f(x_{i})\\delta_{ij} = f(x_{j}) $$\nTherefore, $g=f$ and $f = \\sum_{i=1}^{n}f(x_{i})f_{i}$. Thus, $\\beta^{\\ast}$ generates $X^{\\ast}$.\nDual Basis Following the notation, the ordered basis $\\beta^{\\ast} = \\left\\{ f_{1}, \\dots, f_{n} \\right\\}$ of $X^{\\ast}$ is called the dual basis or reciprocal basis of $\\beta$.\n$$ f_{i} : X \\to \\mathbb{F} \\quad \\text{ by } \\quad f_{i}(x_{j}) = \\delta_{ij} $$\nHere, $\\delta_{ij}$ is the Kronecker delta.\nKreyszig. (1989). Introductory Functional Analysis with Applications: p106.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nStephen H. Friedberg, Linear Algebra (4th Edition, 2002), p119-120\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":753,"permalink":"https://freshrimpsushi.github.io/en/posts/753/","tags":null,"title":"Dual Space"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Diagnostics To determine if regression analysis was performed correctly, you can check using the standardized residual plot.\nNormality is better assessed using histograms rather than looking at the scatter of residuals, or by conducting a normality test.\nThe left side shows a density that decreases towards the top and bottom from the center, whereas the right side is evenly distributed regardless of the direction.\nHowever, cases where the residuals actually follow a known distribution other than normal distribution are almost never found in actual analysis. Issues with normality in analysis are mostly due to outliers.\nNormality problems occur when there are considerably more outliers than in the sample or when an absurd number like 6 or 7 appears. Such outliers should not be blindly removed; instead, the analyst must carefully review the data.\nSee also Linearity Independence Homoscedasticity ","id":683,"permalink":"https://freshrimpsushi.github.io/en/posts/683/","tags":null,"title":"Checking the Normality of Residuals through Model Diagnostics"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Diagnostic Methods Intuitive Pattern Recognition Using standardized residual plots, we can check if the regression analysis was performed correctly. To confirm independence, there should be no distinct patterns appearing in the residual plots. Unfortunately, diagnosing independence can be very subjective compared to other assumptions of regression analysis.\nA common example of lacking independence is seeing an unidentified straight line as shown above. It could be by chance, but usually, it indicates a misunderstanding of the data or missing crucial data.\nAt first glance, the case above may seem problem-free, but on closer inspection, the same pattern repeats every $9$ periods. If such an explicit regularity is observed, one can confidently say that independence is compromised. In such cases, the residuals exhibit Autocorrelation, and it is advisable to consider analysis including time series.\nStatistical Testing Such issues could easily be detected if the analyst thought they were not good at observing data and used the Durbin-Watson test. However, one should not entirely rely on the Durbin-Watson test because it only identifies autocorrelation and does not guarantee independence. The image below is deliberately created for easier understanding, but there are plenty of examples where independence is compromised even after passing the Durbin-Watson test.\nIn the figure, the residuals almost precisely fall on $0$ for the first time, and the next two times as well, but it is impossible to predict when the first $0$ will occur. In such cases, though there\u0026rsquo;s a serious issue with the independence of residuals, it\u0026rsquo;s too irregular to claim autocorrelation. While it might be a coincidence, the judgment is entirely up to the analyst.\nSee Also Linearity Homoscedasticity Normality ","id":679,"permalink":"https://freshrimpsushi.github.io/en/posts/679/","tags":null,"title":"Residual Independence Verified through Model Diagnosis"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 A subring $(I, +)$ that satisfies $a I \\subset I$ and $I b \\subset I$ for all $a,b \\in R$ in a ring $(R , + , \\cdot )$ is called an Ideal.\nExplanation As a simple example, $n \\mathbb{Z}$ is an Ideal of $\\mathbb{Z}$. The name Ideal literally comes from the word Ideal, as it is the perfect subring to deal with in abstract algebra.\nEspecially if $R$ is a commutative ring, $I$ being a normal subgroup of $R$, it\u0026rsquo;s also commonly referred to just as $I \\triangleleft R$. Just like how normal subgroups are important in group theory, ideals will play a significant role in various theorems of ring theory. The reason it\u0026rsquo;s specifically called ring theory is because Ideal is essentially a concept unique to rings.\nThe Ideal $I$ is a subring of $R$.\nAlthough the definition emphasizes the comparison with groups by mentioning a \u0026lsquo;subgroup\u0026rsquo; that meets certain conditions, it naturally also becomes a subring. No proof will be provided here, but if it\u0026rsquo;s hard to understand, think thoroughly about the conditions $a I \\subset I$ and $I b \\subset I$. Seemingly, $I$ is a collection of elements that \u0026lsquo;survive under multiplication\u0026rsquo; by any element of $R$, maintaining its structure as an algebraic structure. Logically, such a construction like $(I , \\cdot )$ should at least form a semigroup with respect to $(R , + , \\cdot)$. This explanation is not mathematical, so if you\u0026rsquo;re still doubtful, verify it directly using the subring test. In fact, some textbooks might even start with defining it as a subring from the beginning.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p241.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":739,"permalink":"https://freshrimpsushi.github.io/en/posts/739/","tags":null,"title":"Ideals in Abstract Algebra"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Ï†ïÎ¶¨ A square matrix $A_{n \\times n} = (a_{ij})$ is given.\n[1]: For the selected $i$ row $$ \\det A = \\sum_{j=1}^{n} a_{ij} C_{ij} $$ [2]: For the selected $j$ column $$ \\det A = \\sum_{i=1}^{n} a_{ij} C_{ij} $$ The determinant $M_{ij}$ of the matrix obtained by removing the $i$th row and $j$th column from the square matrix $A_{n \\times n} = (a_{ij})$ is called a minor, and $C_{ij} := (-1)^{i + j} M_{ij}$ is called a cofactor. ÏÑ§Î™Ö Laplace expansion is also known as cofactor expansion, and its usefulness is beyond words. It is much easier than calculating the determinant with just the definition. When finding the determinant of a matrix under specific conditions, its advantages increase even more, so it is absolutely essential to know this fact.\nÏòàÏãú Let\u0026rsquo;s look at the following Laplace expansion as an example that can be used to determine whether a matrix is invertible or not.\n$$ \\begin{align*} \\displaystyle \\det \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\ 7 \u0026amp; 8 \u0026amp; 9 \\end{bmatrix} =\u0026amp; 1 \\cdot \\begin{vmatrix} 5 \u0026amp; 6 \\\\ 8 \u0026amp; 9 \\end{vmatrix} - 2 \\cdot \\begin{vmatrix} 4 \u0026amp; 6 \\\\ 7 \u0026amp; 9 \\end{vmatrix} + 3 \\cdot \\begin{vmatrix} 4 \u0026amp; 5 \\\\ 7 \u0026amp; 8 \\end{vmatrix} \\\\ =\u0026amp; 1 \\cdot (-3) - 2 \\cdot (-6) + 3 \\cdot (-3) \\\\ =\u0026amp; 0 \\end{align*} $$\nTherefore, it is easy to confirm that $\\displaystyle \\det \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\ 7 \u0026amp; 8 \u0026amp; 9 \\end{bmatrix}$ does not have an inverse.\nÏΩîÎìú The following is the code for implementing and verifying the Laplace expansion in Julia. It is practically a direct translation of the equations, and in reality, it is implemented very inefficiently. For this, it would be good to refer to the following post:\nWhat to be careful of when using recursive functions ","id":781,"permalink":"https://freshrimpsushi.github.io/en/posts/781/","tags":null,"title":"Laplace Expansion"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Theorem 1 $T : (X , \\left\\| \\cdot \\right\\|_{X}) \\to ( Y , \\left\\| \\cdot \\right\\|_{Y} )$ is called a linear operator.\n(a) If $T$ is bounded, for all $x \\in X$, $\\left\\| T(x) \\right\\|_{Y} \\le \\left\\| T \\right\\| \\left\\| x \\right\\|_{X}$\n(b) $T$ is continuous $\\iff$ $T$ is bounded\n(c) If $X$ is a finite-dimensional space, then $T$ is continuous.\n(d) If $Y$ is a Banach space, then $( B(X,Y) , \\| \\cdot \\| )$ is a Banach space.\nExplanation $B(X,Y)$ is the space of bounded linear operators, so by (b), it is known that all operators in this space are continuous. Being linear is useful, but if it is not only continuous but also complete, it is definitely a very good space.\n(a) is widely used, and if there are no major problems, it is usually just written as $\\| Tx \\| \\le \\| T \\| \\| x \\| $.\n(d) In norm $\\| \\cdot \\|$ is the operator norm.\nProof (a) Strategy: Use the fact that $\\| x \\|_{X}$ is a scalar to go in and out of $T$.\nSince $T$ is bounded, there exists some $c\u0026gt; 0$ such that\n$$ {{ \\| T(x) \\|_{Y} } \\over { \\| x \\|_{X} }} \\le c $$\nSince $\\| x \\|_{X}$ is a scalar and $T$ is linear,\n$$ {{ \\| T(x) \\|_{Y} } \\over { \\| x \\|_{X} }} =\\left\\| {{1} \\over {\\| x \\|_{X} }} T \\left( x \\right) \\right\\|_{Y} = \\left\\| T \\left( {{x} \\over {\\| x \\|_{X} }} \\right) \\right\\|_{Y} $$\nFrom the definition of operator norm, since $\\left\\| T \\right\\| = \\sup \\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\left\\| T(x) \\right\\|_{Y}$,\n$$ {{ \\| T(x) \\|_{Y} } \\over { \\| x \\|_{X} }} = \\left\\| T \\left( {{x} \\over {\\| x \\|_{X} }} \\right) \\right\\|_{Y} \\le \\sup \\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\left\\| T(x) \\right\\|_{Y} = \\| T \\| $$\nMultiplying both sides by the scalar $\\| x \\|_{X}$ gives\n$$ \\| T(x) \\|_{Y} \\le \\| T \\| \\| x \\|_{X} $$\n‚ñ†\n(b) Strategy: Direct deduction using epsilon-delta argument. $(\\implies)$ employs reductio ad absurdum, and according to continuity, it constructs a sequence that would be a contradiction to the assumption.\n$(\\impliedby)$\nIf $T = 0$, it\u0026rsquo;s naturally continuous, so consider the case when $T \\ne 0$. For any $x_{0} \\in X$, let\u0026rsquo;s say $\\| x - x_{0} \\| \u0026lt; \\delta$.\nSince $T$ is a bounded linear operator, by (a)\n$$ \\| Tx - Tx_{0} \\| = \\| T ( x - x_{0} ) \\| \\le \\| T \\| \\| x - x_{0} \\| \u0026lt; \\| T \\| \\delta $$\nFor any $\\varepsilon \u0026gt; 0$, if we set $\\displaystyle \\delta = {{ \\varepsilon } \\over { \\| T \\| }}$, then $\\| Tx - Tx_{0} \\| \u0026lt; \\varepsilon$, so $T$ is continuous.\n$(\\implies)$\nIf we assume that $\\| T \\| = \\infty$,\n$$ \\| x_{n} \\| = 1 $$\n$$ \\lim_{n \\to \\infty} \\| T x_{n} \\| = \\infty $$\nThere exists a sequence of $X$, $\\left\\{ x_{n} \\right\\}_{ n \\in \\mathbb{N} }$, such that defining $\\displaystyle z_{n} := {{x_{n}} \\over { \\sqrt{ \\| Tx_{n} \\| } }}$,\n$$ \\lim_{n \\to \\infty} z_{n} = 0 $$\nSince $T$ is continuous,\n$$ 0 = \\lim_{n \\to \\infty} \\| T( 0 ) \\| = \\left\\| T \\left( \\lim_{n \\to \\infty} z_{n} \\right) \\right\\| = \\lim_{n \\to \\infty} \\| T( z_{n} ) \\| = \\lim_{n \\to \\infty} \\left\\| T \\left( {{x_{n}} \\over { \\sqrt{ \\| Tx_{n} \\| } }} \\right) \\right\\|= \\lim_{n \\to \\infty} \\sqrt{ \\| T(x_{n} ) \\| } = \\infty $$\nThis is a contradiction to the assumption, so $T$ is bounded.\n‚ñ†\n(c) Strategy: To show continuity according to (b), it is sufficient to demonstrate boundedness. Using the properties of finite-dimensional spaces, showing that $T$ is bounded is relatively straightforward.\nIf we say $\\dim X = n$, then $X$ has a basis $\\left\\{ e_{1} , \\cdots , e_{n} \\right\\}$ and any $x \\in X$ for $t_{i} \\in \\mathbb{C}$ is\n$$ x = \\sum_{i=1}^{n} t_{i} e_{i} $$\nSince $T$ is a linear operator,\n$$ Tx = T \\left( \\sum_{i=1}^{n} t_{i} e_{i} \\right) = \\sum_{i=1}^{n} | t_{i} | T \\left( e_{i} \\right) $$\nTaking the norm $\\| \\cdot \\|_{Y}$ on both sides gives\n$$ \\begin{equation} \\| Tx \\|_{Y} = \\left\\| \\sum_{i=1}^{n} t_{i} T \\left( e_{i} \\right) \\right\\|_{Y} \\le \\sum_{i=1}^{n} | t_{i} | \\| T ( e_{i} ) \\|_{Y} \\le \\max_{1 \\le i \\le n} \\| T ( e_{i} ) \\|_{Y} \\sum_{i=1}^{n} | t_{ i} | \\end{equation} $$\nNow let\u0026rsquo;s define a new norm $\\displaystyle \\left\\| \\sum_{i=1}^{n} t_{i} e_{i} \\right\\|_{1} := \\sum_{i=1}^{n} | t_{ i} |$. Since all norms defined in a finite-dimensional vector space are equivalent,\n$$ C \\left\\| \\sum_{i=1}^{n} t_{i} e_{i} \\right\\|_{1} \\le \\left\\| \\sum_{i=1}^{n} t_{i} e_{i} \\right\\|_{X} $$\nThere exists some $C\u0026gt;0$ that satisfies. Therefore,\n$$ \\sum_{i=1}^{n} | t_{ i} | = \\left\\| \\sum_{i=1}^{n} t_{i} e_{i} \\right\\|_{1} \\le {{1} \\over {C}} \\left\\| \\sum_{i=1}^{n} t_{i} e_{i} \\right\\|_{X} = {{1} \\over {C}} \\| x \\|_{X} $$\nApplying to $(1)$ gives\n$$ \\| T x \\|_{Y} \\le {{1} \\over {C}} \\max_{1 \\le i \\le n} \\| T(e_{i} ) \\|_{Y} \\cdot \\| x \\|_{X} $$\nTherefore, $\\displaystyle \\| T \\| \\le {{1} \\over {C}} \\max_{1 \\le i \\le n} \\| T(e_{i} ) \\|_{Y} \u0026lt; \\infty$ but since $T$ is a bounded linear operator, by (b), it is continuous.\n‚ñ†\n(d) Strategy: Convert the discussion to $T(x) \\in T(X) \\subset Y$ by drawing out completeness in Banach space $Y$.\nPart 1. For the normed space $( B(X,Y) , \\| \\cdot \\| )$, $\\| \\cdot \\|$ satisfies the following conditions for $T \\in B(X,Y)$,\n(i): $$ \\| T \\| = \\sup\\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\| T(x) \\| \\ge 0 $$\n(ii): $$ \\| T \\| = \\sup\\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\| T(x) \\| = 0 \\iff T = 0 $$\n(iii): $$ \\| \\lambda T \\| = \\sup\\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\| \\lambda T(x) \\| =\\sup\\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\lambda \\| T(x) \\| = \\lambda \\sup\\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\| T(x) \\| $$\n(iv): $$ \\begin{align*} \\| T_{1} + T_{2} \\| =\u0026amp; \\sup\\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\| (T_{1} + T_{2})(x) \\| \\\\ \\le \u0026amp; \\sup\\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\left( \\| T_{1} (x) \\| + \\| T_{2}(x) \\| \\right) \\\\ \\le \u0026amp; \\sup\\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\| T_{1}(x) \\| + \\sup\\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\| T_{2}(x) \\| \\end{align*} $$\nPart 2. Completeness\nDefining a Cauchy sequence of $B(X,Y)$, $\\left\\{ T_{n} \\right\\}_{n \\in \\mathbb{N}}$, for any $\\varepsilon \u0026gt; 0$,\n$$ \\| T_{n} - T_{m} \\| \u0026lt; \\varepsilon $$\nAccording to (a), for all $x \\in X$,\n$$ \\| T_{n} x - T_{m} x \\| = \\| ( T_{n} - T_{m} ) x \\| \\le \\| T_{n} - T_{m} \\| \\| x \\| \u0026lt; \\varepsilon \\| x \\| $$\nTherefore, $\\left\\{ T_{n}x \\right\\}$ is a Cauchy sequence in $Y$. Since $Y$ is assumed to be complete, for some $Tx \\in Y$\n$$ \\lim_{m \\to \\infty } T_{m}x = Tx $$\nAgain, according to (a), for all $x \\in X$,\n$$ \\| T_{n} x - T x \\| = \\left\\| T_{n} x - \\lim_{m \\to \\infty} T_{m} x \\right\\| = \\lim_{m \\to \\infty} \\left\\| T_{n} x - T_{m} x \\right\\| \u0026lt; \\varepsilon \\| x \\| $$\nFor all $x \\in X$, since $\\displaystyle {{ \\| ( T_{n} - T ) x \\| } \\over { \\| x \\| }} \u0026lt; \\epsilon$,\n$$ ( T_{n} - T ) \\in B(X,Y) $$\nMeanwhile, Part 1 showed that $B(X,Y)$ is a vector space,\n$$ T = T_{n} - ( T_{n} - T ) \\in B(X,Y) $$\nNow, considering $\\| x \\| = 1$, for all $x \\in X$, since $\\displaystyle {{ \\| ( T_{n} - T ) x \\| } \\over { \\| x \\| }} \u0026lt; \\epsilon$,\n$$ \\| T_{n} - T \\| = \\sup\\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} {{ \\| ( T_{n} - T ) x \\| } \\over { \\| x \\| }} \u0026lt; \\varepsilon $$\nEvery Cauchy sequence $\\left\\{ T_{n} \\right\\}_{n \\in \\mathbb{N}} $, when $n \\to \\infty$, converges to some $T \\in B(X,Y)$, so $B(X,Y)$ is complete.\nPart 3.\n$B(X,Y)$ is a complete normed space, hence a Banach space.\n‚ñ†\nKreyszig. (1989). Introductory Functional Analysis with Applications: p92~97, 118~119.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":730,"permalink":"https://freshrimpsushi.github.io/en/posts/730/","tags":null,"title":"Properties of Linear Operators"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 $$ f(x) : = \\sum_{i=0}^{n} a_{i} x^{i} = a_{0} + a_{1} x + \\cdots + a_{k} x^{k} $$ Let us define the evaluation function $\\phi_{\\alpha} : F [ x ] \\to E$ in $\\alpha \\in E$ for a polynomial function $f \\in F [x]$ and a field $F \\le E$ as follows. $$ \\phi_{\\alpha} ( f(x) ) : = a_{0} + a_{1} \\alpha + \\cdots + a_{n} \\alpha^n = f (\\alpha) $$ $f( \\alpha ) = 0$ satisfying in $\\alpha \\in E$ is called the zero $f(x)$ of $f(x)$.\nExplanation Evaluation Function As a fact, $\\phi_{\\alpha}$ becomes a homomorphism.\nIf the definition feels too vague, consider the simple example of $\\phi_{i} : \\mathbb{R} [ x ] \\to \\mathbb{C}$. For instance, if we have $\\phi_{i} ( x^2 - 3 x + 2)$, it simply becomes $$ f(x) = x^2 - 3 x + 2 $$ by substituting $i$ into $$ i^2 - 3 i + 2= 1 -i2 \\in \\mathbb{C} $$ Of course, it does not matter if $\\mathbb{R} \\le \\mathbb{C}$.\nMotive of Zero Thinking of kernel, $\\ker ( \\phi_{\\alpha} )$ would be a set of functions satisfying $f(\\alpha) = 0$. Continuing with the above example, elements of $\\ker ( \\phi_{i} ) \\subset \\mathbb{R} [ x ]$ would be polynomial functions that have $(x-i)$ as a factor.\nThus, it is undoubtedly natural to call $\\alpha$ the zero of $f(x)$ when satisfying $f( \\alpha ) = 0$. Equivalently, if $\\phi_{\\alpha} ( f(x) ) = 0$ then $\\alpha$ is said to be the zero of $f(x)$.\nThe reason for explaining the concepts of substitution and roots by involving functions is precisely to define the concept of \u0026lsquo;solution of equation\u0026rsquo; rigorously. $$ f(x) = g(x) $$ Consider the equation above, for instance. There‚Äôs no reason not to think of a set of such equations, but it‚Äôs much more straightforward to consider $f(x)$ and $g(x)$ separately rather than collecting relations. If a set of equations $X$ is a collection of such equations, it should be able to be expressed as $$ \\left( f(x) = g(x) \\right) \\in X $$ But after all, since reducing it comes down to $$ f(x) = g(x) \\iff f(x) - g(x) = 0 $$ there‚Äôs no need to keep the right side messy and free. Having the set $X$ follow a structure that holds functions rather than equations, and having interest in when they hold, is no different than collecting equations with $0$ on the right side.\nThis expansion of thought will lead to facts such as \u0026lsquo;polynomial functions with real coefficients can have imaginary roots\u0026rsquo; being abstracted and generalized.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p201, 204.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":723,"permalink":"https://freshrimpsushi.github.io/en/posts/723/","tags":null,"title":"Zeros of a Polynomial Function"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Definitions1 Let\u0026rsquo;s call $(X, \\left\\| \\cdot \\right\\|_{X}), (Y, \\left\\| \\cdot \\right\\|_{Y})$ a normed space.\nA mapping from a normed space to another normed space is called an operator.\nFor $x,x_{1},x_{2}\\in X$, if $T : X \\to Y$ satisfies $$ T( x_{1} + x_{2} ) = T( x_{1} ) + T( x_{2} ) \\quad \\text{and} \\quad T( a x ) = a T( x ) $$, it is called a linear operator.\nIf for all $x \\in X$ there exists a $\\left\\| T(x) \\right\\|_{Y} \\le C \\left\\| x \\right\\|_{X}$ that satisfies $C \\ge 0$, then $T$ is said to be bounded.\nAmong the $C$s that satisfy 3., the smallest $C$ is defined as the operator norm of $T$ and denoted as follows: $$ \\left\\| T \\right\\| :=\\min \\left\\{ C : \\left\\| T(x) \\right\\|_{Y} \\le C \\left\\| x \\right\\|_{X} \\right\\} $$\nThe set that collects all bounded linear operators $T : X \\to Y$ is denoted as $B(X,Y)$.\nExplanation Just as a mapping from a vector space to another vector space is specially called a transformation, a function from a normed space to another normed space is specially called an operator.\nFor convenience in various textbooks, any function $X \\to Y$ between vector spaces is called a transformation, and transformations like $X \\to X$ are called operators.\nFrom the definition of 4., we get the following:\n$$ \\left\\| T \\right\\| = \\sup \\limits_{\\substack{x\\in X \\\\ \\left\\| x \\right\\|=1 }} \\left\\| T(x) \\right\\|_{Y} $$\nThis is also defined as the norm of $T$. If you don\u0026rsquo;t understand why the condition $\\left\\| x \\right\\|_{X}=1$ exists, think about 3.\nAn operator is algebraically a homomorphism that preserves operations, and naturally, all theorems regarding this can be used as well.\nChoosing to use the term operator instead of operator is because rather than focusing on \u0026lsquo;operations\u0026rsquo; like in the past, we are interested in the \u0026lsquo;action\u0026rsquo; in some space, abstracting, and dealing with it mathematically. If you think about something like a rotational transformation, you can see it as moving a point by rotating it in space. Of course, it is also correct to explain that we obtain the result by taking coordinates as vectors and multiplying matrices, but if you think of it as the behavior of \u0026lsquo;moving\u0026rsquo; the position of a point, the expression operator is also quite appropriate.\nThus, we can now use expressions like applying some \u0026lsquo;action $T$\u0026rsquo; to mathematical objects represented as vectors in a given space. Among these, what we particularly focus on are linear operators, with examples including:\nIdentity operator $I : X \\to X, Ix = x$ As the name suggests, it is an action that does not change or is virtually the same as not taking any action. It is also denoted as $1$ or ${\\rm id}$.\nZero operator $\\mathbb{0} (x) : = 0$\nAn action that turns any element into $0$, playing the role of a zero vector in the vector space of operators.\nDifferentiation operator $D : C^{1} \\to C^{1}, Df = \\dfrac{d f}{d x}=f^{\\prime}$\nAn operator that takes the derivative, a fact that everyone has been using knowingly or unknowingly since high school.\nIntegration operator $T : C[0, 1] \\to C[0, 1]$, $\\displaystyle y(t) = Tx(t) = \\int_{0}^{1}K(t, s)x(s) ds$ Integration is also an operator, and here $K$ is called the kernel. It is also known as integral transform.\nMatrix $T_{A} ( \\mathbb{x} ) := A \\mathbb{x}$ A $m \\times n$ matrix $A$ can be thought of as a function that goes from $\\mathbb{C}^{n}$ to $\\mathbb{C}^{m}$.\nOle Christensen, Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering (2010), p37\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":728,"permalink":"https://freshrimpsushi.github.io/en/posts/728/","tags":null,"title":"Operators in Functional Analysis"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 $$ f(x) : = \\sum_{i=0}^{n} a_{i} x^{i} = a_{0} + a_{1} x + \\cdots + a_{k} x^{k} $$ A polynomial $f(x)$ over a ring $R$ is defined as above.\n$a_{i} \\in R$ are called the coefficients of $f(x)$. If $n \u0026lt; \\infty$, then $n$ is called the degree of $f(x)$. $R[x]$ is the set of all polynomials with coefficients in $R$. $$ R[x] := \\left\\{ a_{0} + a_{1} x + \\cdots + a_{n} x^{n} \\ | \\ a_{0}, \\cdots , a_{n} \\in R \\right\\} $$ $R[[x]]$ is the set of all formal power series with coefficients in $R$. $$ R[[x]] := \\left\\{ a_{0} + a_{1} x + \\cdots + a_{n} x^{n} + \\cdots \\ | \\ a_{0}, \\cdots , a_{n} , \\cdots \\in R \\right\\} $$ Explanation After a long detour, we are back to the \u0026lsquo;algebra\u0026rsquo; learned in middle and high school. The reason for redefining polynomials is to treat polynomial \u0026rsquo;equations\u0026rsquo; as elements of groups, rings, and fields.\nIt is essential to know the following important theorems. They may not seem like much but they guarantee that the ring of polynomials preserves the useful properties of the original ring.\nTheorems [1]: If $R$ is a ring, then $R[x]$ is also a ring with respect to the addition and multiplication of polynomials. [2]: If $R$ is a commutative ring, then $R[x]$ is also commutative. [3]: If $R$ has a multiplicative identity $1 \\ne 0$, then $R[x]$ also has a multiplicative identity $1 \\ne 0$. These theorems hold for $R[x]$ also apply to $R[[x]]$.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p199.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":721,"permalink":"https://freshrimpsushi.github.io/en/posts/721/","tags":null,"title":"Polynomial Rings"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definitions 1 In a ring $R$, a $a,b \\in R$ that is not $0$ and satisfies $ab = 0$ is called a Zero Divisor. A $D$ with a unit $1 \\ne 0$ and without zero divisors is called an Integral Domain. Description Zero Divisors Examples of non-$0$ elements whose product is $0$ include $$ \\begin{bmatrix} 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \\end{bmatrix} \\begin{bmatrix} 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{bmatrix} = \\begin{bmatrix} 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \\end{bmatrix} $$ and $2 \\cdot 3 \\equiv 0 \\pmod{6}$. Hence, it is essential to be cautious as not everything in a ring behaves conveniently. This implies that if $xy = 0$ and $x \\ne 0$, we cannot assert that $y = 0$.\nIntegral Domains ID is a common abbreviation for Integral Domains.\nAn example of an integral domain is simple to illustrate with the set of integers $\\mathbb{Z}$. Naturally, the term \u0026ldquo;Integral\u0026rdquo; originates from the word \u0026ldquo;Integer\u0026rdquo;. A significant advantage of an integral domain is that there is no need to worry about division by anything other than $0$. In an integral domain, if $x y = 0$, it assures that either $x = 0$ or $y = 0$, making it highly useful as an algebraic structure.\nThat $R$ is an integral domain guarantees that the Cancellation law applies to multiplication in $R$, indicating that it is a ring without zero divisors, closely related to a field. Let\u0026rsquo;s explore the following useful theorems.\nTheorems [1]: A field is an integral domain. [2]: A finite integral domain is a field. [3] If $p$ is prime, then $\\mathbb{Z}_{p}$ is a field. [4]: A field has only two idempotents, $0$ and $1$. Proofs [1] For a field $F$, if $a \\ne 0$ and $ab = 0$, then $$ \\left( {{1} \\over {a}} \\right) (ab) = \\left( {{1} \\over {a}} \\right) 0 = 0 $$ and concurrently, $$ \\left[ \\left( {{1} \\over {a}} \\right) a \\right] b =1 b = b $$ holds. This means that if $ab= 0$, one of them must be $0$, so elements of a field cannot be zero divisors, and $F$ is an integral domain.\n‚ñ†\n[2] Let\u0026rsquo;s name the elements of a finite integral domain $D$, excluding $0$, as $1, a_{1} , \\cdots , a_{n}$. Considering them multiplied by $a \\ne 0$, $$ a, aa_{1} , \\cdots , aa_{n} $$ since $D$ is an integral domain, none of these are $0$.\nSince the cancellation law holds in an integral domain, if $aa_{i} = aa_{j}$, then $a_{i} = a_{j}$. This implies $$ a_{i} \\ne a_{j} \\implies aa_{i} \\ne aa_{j} $$, leading to $$ \\left\\{ 1, a_{1} , \\cdots , a_{n} \\right\\} = \\left\\{ a, aa_{1} , \\cdots , aa_{n} \\right\\} $$. Therefore, there always exists a $b \\in \\left\\{ 1, a_{1} , \\cdots , a_{n} \\right\\}$ satisfying $ab=1$ for $a \\ne 0$. Since $b$ is the multiplicative inverse of $a$, $D$ is a field.\n‚ñ†\n[3] Obviously, $\\mathbb{Z}_{p} = \\left\\{ 0 , 1, \\cdots , p-1 \\right\\}$ is a finite set. Given $p$ is prime, there exist no non-$0$ $a,b \\in \\mathbb{Z}_{p}$ satisfying $$ ab \\equiv 0 \\pmod{p} $$, so $\\mathbb{Z}_{p}$ is an integral domain and, by theorem [2], a field.\n‚ñ†\n[4] For a field $F$, if $0^2 = 0$ and $1^2 = 1$, then $0$ and $1$ are idempotents of $F$. Assuming the existence of an idempotent $a \\in F$ that is neither $0$ nor $1$ leads to $a^2 = a$, hence $a( a-1) = 0$. However, given theorem [1], since $F$ is an integral domain and does not have zero divisors, this assumption is contradictory.\n‚ñ†\nSee Also Euclidean Domain $\\implies$ Principal Ideal Domain $\\implies$ Unique Factorization Domain $\\implies$ Integral Domain Fraleigh. (2003). A first course in abstract algebra(7th Edition): p178~179.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":719,"permalink":"https://freshrimpsushi.github.io/en/posts/719/","tags":null,"title":"Reflection and Refraction"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Formula1 Assuming the Laplace transform $F(s)=\\mathcal{L} \\left\\{ f(t) \\right\\}$ of the function $f(t)$ exists as $s\u0026gt;a$. Then, the following holds for constant $c$.\n$$ \\begin{align*} \\mathcal{L} \\left\\{ e^{ct}f(t) \\right\\}\u0026amp;=F(s-c), \u0026amp;s\u0026gt;a+c \\\\ \\mathcal{L^{-1}} \\left\\{ F(s-c) \\right\\}\u0026amp;=e^{ct}f(t) \u0026amp; \\end{align*} $$\nExplanation This means that multiplying an exponential function to $f$ is equivalent to translating $F$.\nDerivation $$ \\begin{align*} \\mathcal{L} \\left\\{ e^{ct}f(t) \\right\\} \u0026amp;=\\int_{0}^\\infty e^{-st}e^{ct}f(t)dt \\\\ \u0026amp;= \\int_{0}^\\infty e^{-(s-c)t}f(t)dt \\\\ \u0026amp;= F(s-c) \\end{align*} $$\n‚ñ†\nCorollary $$ \\begin{align*} \\mathcal{L} \\left\\{ e^{ct} t^p \\right\\} \u0026amp;=\\dfrac{\\Gamma (p+1)}{(s-c)^{p+1}} \\\\ \\mathcal{L} \\left\\{ e^{ct} \\sin (at) \\right\\} \u0026amp;=\\dfrac{a}{(s-c)^2+a^2} \\\\ \\mathcal{L} \\left\\{ e^{ct} \\cos (at) \\right\\} \u0026amp;= \\dfrac{s-c}{(s-c)^2+a^2} \\\\ \\mathcal{L} \\left\\{ e^{ct} \\sinh (at) \\right\\} \u0026amp;= \\dfrac{a}{(s-c)^2-a^2} \\\\ \\mathcal{L} \\left\\{ e^{ct} \\cosh (at) \\right\\} \u0026amp;= \\dfrac{s-c}{(s-c)^2-a^2} \\end{align*} $$\nSee Also Table of Laplace Transforms William E. Boyce, Boyce\u0026rsquo;s Elementary Differential Equations and Boundary Value Problems (11th Edition, 2017), p262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":764,"permalink":"https://freshrimpsushi.github.io/en/posts/764/","tags":null,"title":"Laplace Transform Translation"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 Let\u0026rsquo;s call $R$ a ring.\nIf $r \\in R$ satisfies $r^2 = r$, then $r$ is called an Idempotent Element. If all elements of $R$ are idempotent, $R$ is called a Boolean Ring. Explanation Although \u0026lsquo;Boolean ring\u0026rsquo; could be translated phonetically in Korean, the term sounds awkward, hence the English pronunciation was used directly.\nThe property of projection in linear algebra is known to be very useful, needless to say in generalized abstract algebra.\nThe most famous example of a Boolean ring is, of course, what is also referred to as \u0026lsquo;Boolean algebra\u0026rsquo; $$ (\\left\\{ \\text{True}, \\text{False} \\right\\} , \\text{OR}, \\text{AND} ) $$ As well-known $$ \\text{True AND True} = \\text{True} \\\\ \\text{Flase AND Flase} = \\text{Flase} $$ thus, this ring becomes a Boolean ring. A more familiar example for mathematicians is $\\mathbb{Z}_{2}$, which, of course, is isomorphic to the Boolean ring.\nMeanwhile, the following property of the Boolean ring is known.\nTheorem The Boolean ring is a commutative ring.\nProof For the Boolean ring $R$, if $a, b \\in R$ then $(a+b) \\in R$ and $$ (a + b)^2 = (a+b) $$ by the distributive law $$ (a + b)^2 = (a+b)a + (a+b)b = a^2 + ba + ab + b^2 = (a+b) $$ $a^2 = a$ and $b^2 = b$ hence $$ a+ ba + ab + b = a+ b $$ $a$ and $b$ exist as additive inverses, thus summarizing $$ ba +ab = 0 $$ Adding the inverse $(-ba)$ of $ba$ to both sides gives $ab = -ba$ hence $$ ab = (ab)^2 = (-ba)^2 = (ba)^2 = ba $$\n‚ñ†\nSee Also Projection in Linear Algebra Fraleigh. (2003). A first course in abstract algebra(7th Edition): p176.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":717,"permalink":"https://freshrimpsushi.github.io/en/posts/717/","tags":null,"title":"Boolean Ring"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition[^1] The Laplace transform of a function $f$ is defined as follows.\n$$ \\mathcal{L} \\left\\{ f(t) \\right\\} := \\int _{0}^\\infty e^{-st}f(t) dt =F(s) $$\n","id":761,"permalink":"https://freshrimpsushi.github.io/en/posts/761/","tags":null,"title":"Definition and Existence Proof of the Laplace Transform"},{"categories":"Ìï®Ïàò","contents":"Definition A function that is a piecewise constant function is called a step function.\nDescription As shown in the figure above, it looks like a staircase, hence the name step function. It is also known as the Heaviside function, named after Heaviside, who is known to be the first to propose it. Heaviside was the person who created a method for solving differential equations in electrical circuits, which is the Laplace transform. A typical example of a step function is the Gaussian function.\nIt is commonly denoted by $H, h$, following Heaviside\u0026rsquo;s name. Unless specifically mentioned, referring to a step function usually means the unit step function described below.\nUnit Step Function The following $H$ is called the unit step function.\n$$ H(x) = \\begin{cases} 1 \u0026amp; x \\gt 0 \\\\ 0 \u0026amp; x \\le 0\\end{cases} $$\nSee Also Dirac Delta Function Ramp Function ReLU ","id":757,"permalink":"https://freshrimpsushi.github.io/en/posts/757/","tags":null,"title":"Staircase Function"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 If a ring $(R , + , \\cdot)$ has an identity element $1 \\in R$ for multiplication $\\cdot$, $1$ is called a unity. In a ring $R$ with a unity, the element $r \\ne 0$ that has a multiplicative inverse is called a unit. If every element other than $0$ is a unit in a ring $R$ with a unity, it is called a division ring. A division ring $R$ that is commutative with respect to multiplication is called a field. Explanation In short, a field $(F , + , \\cdot )$ is a commutative ring where every element except the additive identity $0 \\in F$ has an inverse. Although it might seem complex when thought of in terms of abstract algebra, if you consider $\\mathbb{R}$, which you learned in analysis, it can actually be seen as very fitting for \u0026lsquo;algebraic structures\u0026rsquo;.\nWhy are elements with inverses called units? While the English term Unity for the identity element can be easily understood, many might find it hard to accept why elements with an inverse are called Units. The term unit is commonly translated as \u0026lsquo;unit\u0026rsquo; and often used in the sense of \u0026lsquo;a standard measure for quantifying\u0026rsquo;. It seems unrelated to having an inverse, so why exactly define it as a \u0026lsquo;unit\u0026rsquo;? Here, I\u0026rsquo;d like to propose an interesting brain teaser.\nIn the early days of the development of algebra, research on integers was naturally quite active. The reason we refer to the set of integers as $\\mathbb{Z}$ is because of the German Zahlring, with \u0026lsquo;Zahl-\u0026rsquo; meaning \u0026rsquo;number\u0026rsquo;, and \u0026lsquo;-ring\u0026rsquo; translating to ring, as is well-known. Accepting that many concepts used in algebra originated from the field of number theory isn\u0026rsquo;t too difficult.\nNow, consider the integer field $\\mathbb{Z}$.\n$\\mathbb{Z}$ has infinitely many integers as elements. Among these, only $1$ serves as the multiplicative identity, and the elements that have an inverse are only $-1$ and $1$. For those familiar enough with mathematics to study abstract algebra, calling $-1$ and $1$ \u0026lsquo;units\u0026rsquo; wouldn\u0026rsquo;t feel awkward. With this background, as one explores various algebraic structures beyond integers, it might have seemed appropriate to refer to these as units.\nComing up to $\\mathbb{R}$, excluding $0$, every element $r \\in \\mathbb{R}$ has a multiplicative inverse $\\displaystyle {{1} \\over {r}} \\in \\mathbb{R}$, so every element except for $0$ is a unit. Thinking about it, you can multiply some number $a$ to $r$ to get the number you want $x$, so there\u0026rsquo;s no reason $r \\ne 1$ can\u0026rsquo;t serve as a unit too. And this certain number $a$ is obviously $a = r^{-1}x$, as you couldn\u0026rsquo;t be certain without the existence of $r^{-1}$.\nSee also Axioms of fields in analysis Fraleigh. (2003). A first course in abstract algebra(7th Edition): p173.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":715,"permalink":"https://freshrimpsushi.github.io/en/posts/715/","tags":null,"title":"Field Theory in Abstract Algebra"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Formula1 This is table of Laplace transform.\n$f(t)=\\mathcal{L^{-1}}$ $F(s)=\\mathcal{L} \\left\\{ f(t) \\right\\}$ Derivation $1$ $\\dfrac{1}{s}$ link $e^{at}$ $\\dfrac{1}{s-a}$ link $t^n$ $\\dfrac{n!}{s^{n+1}}$ link $t^{p}$ $\\dfrac{ \\Gamma (p+1) }{ s^{p+1}}$ link $t^{p}e^{at}$ $\\dfrac{ \\Gamma (p+1) }{ (s-a)^{p+1}}$ link $\\sin (at)$ $\\dfrac{a}{s^2+a^2}$ link $\\cos (at)$ $\\dfrac{s}{s^2+a^2}$ link $e^{at}\\sin(bt)$ $\\dfrac{b}{(s-a)^2 +b^2}$ link $e^{at}\\cos(bt)$ $\\dfrac{s-a}{(s-a)^2+b^2}$ link $\\sinh (at)$ $\\dfrac{a}{s^2-a^2}$ link $\\cosh (at)$ $\\dfrac{s}{s^2-a^2}$ link $e^{at} \\sinh (bt)$ $\\dfrac{b}{(s-a)^2-b^2}$ link $e^{at} \\cosh (bt)$ $\\dfrac{s-a}{(s-a)^2-b^2}$ link $u_{c}(t)= \\begin{cases} 0 \u0026amp; t\u0026lt;c \\\\ 1 \u0026amp; t\\ge c\\end{cases}$ $\\dfrac{e^{-cs}}{s}$ link $u_{c}(t)f(t-c)$ $e^{-cs}F(s)$ link $f^{\\prime}(t)$ $s\\mathcal{L} \\left\\{ f(t) \\right\\} -f(0)$ link $f^{(n)}$ ${s^n\\mathcal {L}\\left\\{ f(t) \\right\\} -s^{n-1}f(0) - \\cdots -f^{(n-1)}(0) }$ link $f(t)=f(t+T)$ $\\dfrac{\\displaystyle \\int_{0}^T e^{-st}f(t)dt}{1-e^{-st}}$ link $\\delta (t-t_{0})$ $e^{-st_{0}}$ link $f(ct)$ $\\frac{1}{c}F \\left( \\frac{s}{c} \\right)$ link $\\frac{1}{k}f (\\frac{t}{k} )$ $F(ks)$ link $\\frac{1}{a} e^{-\\frac{b} {a}t}f\\left(\\frac{t}{a}\\right)$ $F(as+b)$ link $t^{n}f(t)$ $(-1)^{n}F^{(n)}(s)$ link William E. Boyce , Boyce\u0026rsquo;s Elementary Differential Equations and Boundary Value Problems (11th Edition, 2017), Chapter6 The Laplace Transform\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":743,"permalink":"https://freshrimpsushi.github.io/en/posts/743/","tags":null,"title":"Laplace Transform Table"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Theorem 1 Every finite-dimensional norm space has a basis.\nDescription It might be unfamiliar to announce the existence of a basis not under specific conditions, but actually, the definition of a basis never stated that every vector space has a basis. Depending on how one defines finite dimensionality, it can also be a fact so obvious that it requires no separate proof.\nProof Strategy: Use the fact that the space is finite-dimensional to explicitly construct a basis.\n$(X, | \\cdot | )$ is finite-dimensional, so there exists $\\text{span} \\left\\{ x_{1} , \\dots , x_{n} \\right\\} = X$ that satisfies $\\left\\{x_{1} , \\dots , x_{n} \\right\\}$. Let\u0026rsquo;s say $y_{1} : = x_{1}$. If $x_{2} \\in \\text{span} \\left\\{ y_{1} \\right\\}$ then consider $x_{3}$. If $x_{2} \\notin \\text{span} \\left\\{ y_{1} \\right\\}$, let $y_{2} := x_{2}$. If $x_{3} \\in \\text{span} \\left\\{ y_{1}, y_{2} \\right\\}$, then consider $x_{4}$. If $x_{3} \\notin \\text{span} \\left\\{ y_{1}, y_{2} \\right\\}$, let $y_{3} := x_{3}$. In this way, by defining $M = \\left\\{ y_{1} , \\dots , y_{k} \\right\\}$, for $1 \\le j \\le k$\n$$ y_{j} \\notin \\text{span} \\left\\{ y_{1} , \\dots , y_{j-1} \\right\\} $$\nIf we assume that $M$ is not linearly independent, for some $\\lambda_{j} \\ne 0$s\n$$ \\lambda_{1} y_{1} + \\dots + \\lambda_{k} y_{k} = 0 $$\nAmong such $j$s, let the largest $j$ be $j_{0}$.\n$$ y_{j_{0}} = - {{1} \\over { \\lambda_{j_{0}} }} \\sum_{j \u0026lt; j_{0}} \\lambda_{j} y_{j} - {{1} \\over { \\lambda_{j_{0}} }} \\sum_{j \u0026gt; j_{0}} \\lambda_{j} y_{j} = - {{1} \\over { \\lambda_{j_{0}} }} \\sum_{j \u0026lt; j_{0}} \\lambda_{j} y_{j} $$\nTherefore, $\\displaystyle y_{j_{0}} = - {{1} \\over { \\lambda_{j_{0}} }} \\sum_{j \u0026lt; j_{0}} \\lambda_{j} y_{j} \\in \\text{span} \\left\\{ y_{1} , \\dots , y_{j_{0}-1} \\right\\}$, which is a contradiction. Since $M \\subset \\left\\{ x_{1} , \\dots , x_{n} \\right\\}$ is linearly independent and satisfies $\\text{span} M = X$, $M$ becomes a basis of $X$.\n‚ñ†\nBy examining the proof process, it can be seen that $\\left\\{ x_{1} , \\dots , x_{n} \\right\\}$ comfortably generates $X$. By discarding what hinders being linearly independent and taking only $M$, it explicitly shows that it is a basis.\nKreyszig. (1989). Introductory Functional Analysis with Applications: p55.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":707,"permalink":"https://freshrimpsushi.github.io/en/posts/707/","tags":null,"title":"Every Finite-Dimensional Normed Space Has a Basis"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Definition 1 Given a vector space $X$.\nFor vectors $x_{1} , \\dots , x_{n}$ and scalar $\\alpha_{1} , \\dots , \\alpha_{n}$ in $X$, $\\alpha_{1} x_{1} + \\cdots + \\alpha_{n} x_{n}$ is called the linear combination of vectors $x_{1} , \\dots , x_{n}$.\nWhen it is $M =\\left\\{ x_{1} , \\dots , x_{n} \\right\\}$, the set of all linear combinations of vectors of $M$ is called $\\text{span} M$, which is a subspace of $X$ generated by $M$.\n$M$ is said to be linearly independent if the only case satisfying $\\alpha_{1} x_{1} + \\cdots + \\alpha_{n} x_{n} = 0$ is $\\alpha_{1} = \\cdots = \\alpha_{n} = 0$.\nIf the finite set $K \\subset X$ satisfies $\\text{span} K = X$, then $X$ is said to be finite-dimensional.\nWhen the linearly independent set $M$ satisfies $\\text{span} M = X$, $M$ is called a basis of $X$.\nThe cardinality $\\dim X := | M|$ of the basis is called the dimension of $X$.\nDescription In vector spaces, the basis is especially referred to as the Hamel basis when discussing \u0026lsquo;finite\u0026rsquo; linear combinations. A finite-dimensional normed space might sound complex, but it\u0026rsquo;s a familiar concept from the beginning of linear algebra studies. Usually, the interesting properties of these spaces are taken for granted without much serious contemplation.\nA finite-dimensional normed space has a basis. All norms defined on a finite-dimensional vector space are equivalent. A finite-dimensional normed space is complete. Although these facts are taken as given when considering Euclidean spaces, the same cannot be said for general spaces. Each statement requires proof, and the process is not always straightforward.\nSee Also Linear independence, basis, and dimension in linear algebra Basis of infinite-dimensional vector spaces: Schauder basis Kreyszig. (1989). Introductory Functional Analysis with Applications: p54~55.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":705,"permalink":"https://freshrimpsushi.github.io/en/posts/705/","tags":null,"title":"Hamel Basis of Finite-Dimensional Vector Spaces"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Definition1 A Banach space is a complete normed space.\nExplanation A complete space refers to a space in which every Cauchy sequence converges.\nBanach space is a space that satisfies all of the following conditions, making it an extremely useful space as it is defined with a distance function and possesses completeness:\nIt is a vector space. It is a normed space. $\\implies$ It is a metric space. It is a complete space. Moreover, as an example of Banach spaces, one can think of the set of continuous functions defined on a closed interval. This serves as a very simple example while also underpinning various important theorems, making it a very important fact. Examples of Banach spaces include:\n$C[a,b]$ $\\R^{n}$ $\\mathbb{C}^{n}$ An introduction to the proof for $C[a,b]$ is as follows.\nProof 1 Part 1. Vector Space\nContinuous functions defined on a closed interval have a constant function $f(x) = 0$ as an identity element and $f(x) = - f(x)$ as an inverse element. Besides, $C[a,b]$ well satisfies the conditions of a vector space over the scalar field $\\mathbb{R}$.\nPart 2. Normed Space\nDefining $\\| \\cdot \\|$ for $f \\in C [a,b]$ as $\\displaystyle \\| f \\| := \\sup_{ a \\le t \\le b } | f (t) |$ satisfies the conditions for a norm.\nPart 3. Completeness\nLet\u0026rsquo;s consider $\\left\\{ f_{n} \\right\\}_{n \\in \\mathbb{N}}$ as a Cauchy sequence under $C [a,b]$. In other words, for all $\\varepsilon / 3 \u0026gt; 0$, there exists $N_{1} \\in \\mathbb{N}$ that satisfies $\\| f_{n} (t) - f_{m} (t) \\| \u0026lt; \\varepsilon / 3$ whenever $n,m \u0026gt; N_{1}$.\nSince $\\mathbb{R}$ is a complete space, for any fixed $t_{0} \\in [a,b]$, $\\displaystyle \\lim_{n \\to \\infty} f_{n} (t_{0})$ can be expressed with respect to some $f : [a,b] \\to \\mathbb{R}$ as\n$$ \\lim_{n \\to \\infty} f_{n} ( t_{0} ) = f ( t_{0} ) $$\nThen, since $f_{n}$ is a Cauchy sequence, for any $t \\in [a,b]$, there exists $N_{2}$ that satisfies\n$$ \\begin{align*} | f(t) - f_{m} (t) | =\u0026amp; \\left| \\lim_{n \\to \\infty} f_{n} (t) - f_{m} (t) \\right| \\\\ =\u0026amp; \\lim_{n \\to \\infty} | f_{n} (t) - f_{m} (t) | \\\\ \\le \u0026amp; \\lim_{n \\to \\infty} \\sup_{t \\in [a,b] } | f_{n} (t) - f_{m} (t) | \\\\ =\u0026amp; \\lim_{n \\to \\infty} \\| f_{n} - f_{m} \\| \\\\ \u0026lt;\u0026amp; \\varepsilon / 3 \\end{align*} $$\nwhen $m \\ge N_{2}$. Of course, there is still no guarantee that the function $f$ is continuous, but merely that it is defined to have a value converging eventually for all $t \\in [a,b]$ as the function value. However, from this definition, it can be guaranteed that $f_{n}$ uniformly converges to $f$, meaning that for all $x,y \\in [a,b]$ and $\\varepsilon / 3 \u0026gt; 0$, there exists $N_{3} \\in \\mathbb{N}$ satisfying both simultaneously when $n \\ge N_{3}$.\n$$ \\left| f_{n} (x) - f(x) \\right| \u0026lt; \\varepsilon / 3 \\\\ \\left| f_{n} (y) - f(y) \\right| \u0026lt; \\varepsilon / 3 $$\nNow, it remains to show that $f$ is a continuous function.\nLet\u0026rsquo;s consider $E \\subset \\mathbb{R}$ as not an empty set.\nCompact Metric Space\nIf $f$ is continuous and $E$ is a bounded closed interval, then $f$ is uniformly continuous.\nSince $f_{n} : [a,b] \\to \\mathbb{R}$ is continuous and $[a,b] \\subset \\mathbb{R}$ is compact, $f_{n}$ is uniformly continuous in $[a,b]$. That is, for all $x,y \\in [a,b]$ and $\\varepsilon / 3 \u0026gt; 0$, there exists $\\delta \u0026gt; 0$ satisfying\n$$ \\left| f_{n}(x) - f_{n}(y) \\right| \u0026lt; \\varepsilon / 3 $$\nwhen $|x-y| \u0026lt; \\delta$.\nCombining the above results, since there exists $\\delta \u0026gt; 0$ and $N_{3} \\in \\mathbb{N}$ satisfying both\n$$ \\begin{align*} |f(x) - f(y)| \\le \u0026amp; \\left| f (x) - f_{n} (x) \\right| + \\left| f_{n}(x) - f_{n}(y) \\right| + \\left| f_{n} (y) - f(y) \\right| \\\\ =\u0026amp; \\varepsilon / 3 + \\varepsilon / 3 + \\varepsilon / 3 \\\\ =\u0026amp; \\varepsilon \\end{align*} $$\nwhen $|x-y| \u0026lt; \\delta$ and $n \\ge N_{3}$, $f$ is uniformly continuous in $[a,b]$ and converges to $f \\in C[a,b]$. Hence, any Cauchy sequence of continuous functions $\\left\\{ f_{n} \\right\\}_{n \\in \\mathbb{N}}$ uniformly converges to some $f \\in C[a,b]$, proving that $C[a,b]$ possesses completeness.\n‚ñ†\nKreyszig. (1989). Introductory Functional Analysis with Applications: p36.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":703,"permalink":"https://freshrimpsushi.github.io/en/posts/703/","tags":null,"title":"Banach Space"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Buildup Statistics can be defined as the study of methods to understand parameters. Just like measuring a physical quantity using formulas or laws, it would be ideal if parameters can be precisely estimated. However, due to the impractical nature of such precision, assumptions and samples are used to find \u0026lsquo;what is expected to be the parameter\u0026rsquo;. If interested in the average height of men in our country $X$, one might assume $X \\sim N ( \\theta , \\sigma^2 )$ and find $\\displaystyle \\hat{\\theta} = \\overline{x} = {{1} \\over {n}} \\sum_{k = 1}^{ n } x_{k}$ to determine it as $\\theta = \\hat{\\theta}$. This method of estimation is based on a rather simple and easy concept.\nFrequentist The samples we have are randomly obtained from the population, and as long as the method of obtaining these samples is fair, no special distinction is made among samples of the same size. Of course, they are practically different samples, but since the problem of whether a sample represents the population well entirely depends on luck, the only certainty is that larger samples are better than smaller ones. Naturally, it is not thought that the observations we have not obtained would be significantly different from the current sample. If they were, statistical analysis would be meaningless. This inference starts with the expectation that the sample and the population are not significantly different, and the more samples there are, the more this expectation approaches certainty. This kind of inference, which considers not only the data obtained so far but also the data that will be obtained in the future or has not been obtained yet, is called Frequentist Inference. From the view that accuracy increases with the size (Frequency) of the sample, this naming can be considered justified.\nBayesian On the other hand, Bayesian Inference considers only the samples obtained so far. Through the Bayes\u0026rsquo; theorem, the prior distribution merely changes to the posterior distribution. It is assumed that parameters have a distribution, but it is not strictly believed to be accurate. Before the analysis begins, it is okay to hypothesize any prior distribution based on expert opinions or subjective experiences. No concern is given even if the distribution changes upon obtaining new samples. The only certainty is that the posterior distribution after the analysis is the result obtained by reflecting the sample on the prior distribution.\nWhat is the Bayesian Paradigm? 1 The components of the Bayesian Paradigm are as follows:\n(1): Determining the prior distribution of parameters (2): Calculation through Bayes\u0026rsquo; theorem (3): Estimation of parameters using the posterior distribution If the prior distribution of the parameter $\\theta$ is $\\pi (\\theta)$ and the observation is $y$, then according to the Bayes\u0026rsquo; theorem, $$ p ( \\theta | y ) = {{ p(y | \\theta ) \\pi (\\theta ) } \\over { p(y) }} $$ This probability distribution of the parameter reflected by the data $p ( \\theta | y )$ is called the posterior distribution.\nExample Let\u0026rsquo;s consider a simple example. Suppose we have a friend named Adam who often arrives late for appointments.\nIf Adam\u0026rsquo;s lateness for appointments follows a normal distribution with an average of 10 minutes and a standard deviation of 5 minutes $N ( 10 , 5^2 )$, both the Frequentist and Bayesian would say the following when Adam is late for an appointment:\nFrequentist: \u0026ldquo;Adam is inherently someone who arrives 10 minutes late.\u0026rdquo; Bayesian: \u0026ldquo;Looking at it, Adam tends to be about 10 minutes late.\u0026rdquo; The Frequentist infers that Adam is on average 10 minutes late, and since that\u0026rsquo;s Adam\u0026rsquo;s nature, he has been and will continue to be about 10 minutes late for appointments. The Bayesian supposes that, based on what has been observed so far, the probability that Adam is 10 minutes late is the highest, thus expecting Adam to be about 10 minutes late this time as well.\nAt first glance, their statements seem similar. That\u0026rsquo;s because, despite their different perspectives, both Frequentists and Bayesians are making statistical inferences. The difference emerges when, for example, Adam arrives on time for the next appointment:\nFrequentist: \u0026ldquo;It\u0026rsquo;s rare for Adam to be on time, with a probability of only about 3%.\u0026rdquo; Bayesian: \u0026ldquo;Oh, Adam can be early sometimes. Will he be early next time too?\u0026rdquo; And if asked whether Adam could arrive on time for the next appointment, their answers would definitely differ:\nFrequentist: \u0026ldquo;It\u0026rsquo;s hard to say Adam has changed. Him arriving early this time was definitely a possibility.\u0026rdquo; Bayesian: \u0026ldquo;While the probability of Adam being late is still high, it\u0026rsquo;s also true that the probability of him being on time has increased.\u0026rdquo; While the Frequentist only checks whether the newly obtained observation matches the conclusion already drawn, the Bayesian immediately updates the existing conclusion, thereby obtaining a new posterior distribution. Thus, the ease of Sequential Analysis is not only a distinguishing feature from the Frequentist but also an inherent advantage of Bayesian inference.\nÍπÄÎã¨Ìò∏. (2013). RÍ≥º WinBUGSÎ•º Ïù¥Ïö©Ìïú Î≤†Ïù¥ÏßÄÏïà ÌÜµÍ≥ÑÌïô: p89.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":702,"permalink":"https://freshrimpsushi.github.io/en/posts/702/","tags":null,"title":"Bayesian Paradigm"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition Let us define a vector space over $V$ as $\\mathbb{F}$.\n$\\left\\| \\cdot \\right\\| : V \\to \\mathbb{F}$ is defined as a norm on $V$ if it satisfies the following three conditions with respect to $\\mathbf{u}, \\mathbf{v} \\in V$ and $k \\in \\mathbb{F}$:\n(i) Positive definiteness: $\\left\\| \\mathbf{u} \\right\\| \\ge 0$ and $\\mathbf{u} = \\mathbb{0} \\iff \\left\\| \\mathbf{u} \\right\\| = 0$ (ii) Homogeneity: $\\left\\|k \\mathbf{u} \\right\\| = | k | \\left\\| \\mathbf{u} \\right\\| $ (iii) Triangle inequality: $\\left\\| \\mathbf{u} + \\mathbf{v}\\right\\| \\le \\left\\|\\mathbf{v} \\right\\| + \\left\\| \\mathbf{u} \\right\\|$ Explanation The norm is a concept that starts from the absolute value and abstracts it. In Korean, there isn‚Äôt a direct translation, so it‚Äôs read as it is pronounced. Personally, I think it was awkwardly translated, so I try to pronounce it as close to [n…î:m] as possible.\nIn linear algebra, the definition of a norm is as above. (In other words, a norm might be defined differently in other fields.) As can be seen, the essential conditions for defining a norm are those that make \u0026ldquo;measurement\u0026rdquo; or \u0026ldquo;comparison\u0026rdquo; possible. Although these concepts are intuitively defined when thinking about three-dimensional space $\\mathbb{R}^3$, abstraction becomes necessary when considering complex numbers, for example. There are many types of norms in the world, and a norm in a vector space does not necessarily have to be unique. As long as these definitions are satisfied, there can be an infinite number of ways to think about norms.\nIntroducing the following norms for the vector space $\\mathbb{C}^n$ and its vector $\\mathbf{u} = ( u_1 , u_2 , \\cdots , u_n ) \\in \\mathbb{C}^n$:\nManhattan Norm $$ \\left\\| \\mathbf{u} \\right\\|_1 = \\sum_{k=1}^{n} |u_k| $$\nAlso called the $\\mathcal{l}^1$ norm, the Manhattan norm is used to define distances in taxicab geometry. The name \u0026ldquo;Manhattan\u0026rdquo; comes from the actual Manhattan city, designed to represent the actual travel distance rather than the simple straight-line distance. Though not exactly the same concept, the illustration helps understand why this norm was named after Manhattan. In the image, it corresponds to the blue line, and if one side of the green square is taken as $1$, the distance between A and B becomes $6+2 = 8$.\nEuclidean Norm $$ \\left\\| \\mathbf{u} \\right\\|_2 = \\sqrt{\\sum_{k=1}^{n} |u_k|^2} $$\nThe Euclidean norm is the concept of distance and magnitude that we are familiar with, obtained regardless of dimension as the square root of the sum of the squares of absolute values. In the image, it corresponds to the red line, and as is well known, the distance between A and B is $\\sqrt{6^2 + 2^2} =6.32\u0026hellip;$.\n$\\infty$-Norm, Maximum Norm $$ \\left\\| \\mathbf{u} \\right\\|_\\infty = \\max_{1\\le k \\le n} |u_k| $$\nAlso known as the Supremum Norm, it simply takes the maximum value.\n$p$-Norm $$ \\left\\| \\mathbf{u} \\right\\|_p = \\left( \\sum_{k=1}^{n} |u_k|^p \\right) ^ {{1} \\over {p} } $$\n$p$ can be equal to or greater than $1$ and does not necessarily have to be a natural number. The Manhattan norm and the Euclidean norm are special examples of the $p$-norm, corresponding to the $1$-norm and $2$-norm respectively. Especially, if $p = \\infty$, it becomes the Maximum Norm, covering all the notations mentioned above.\nIt may or may not be noteworthy, but one interesting point is that the shape of the $p$-norm is similar to that of the $p$-moment in statistics. While there are differences such as the presence of absolute values or fixing the median at 0, just by looking at the shape, the $1$-norm reminds one of the mean, and the $2$-norm suggests variance.\n","id":257,"permalink":"https://freshrimpsushi.github.io/en/posts/257/","tags":null,"title":"In Linear Algebra, What is a Norm?"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 A set $R$ satisfying the following rules for two binary operations, addition$+$ and multiplication$\\cdot$, is defined as a Ring.\nWhen $a$, $b$, $c$ are elements of $R$,\nCommutative law holds for addition. $$a+b=b+a$$ Associative law holds for addition. $$(a+b)+c=a+(b+c)$$ There exists an identity element for addition. $$\\forall a \\ \\exists 0\\ \\ \\mathrm{s.t} \\ a+0=a$$ There exists an additive inverse for every element. $$\\forall a \\ \\exists -a\\ \\ \\mathrm{s.t}\\ a+(-a)=0$$ Associative law holds for multiplication. $$(ab)c=a(bc)$$ Distributive law holds for addition and multiplication. $$a(b+c)=ab+ac\\ \\mathrm{and} \\ (b+c)a=ba+ca$$ Description In summary, a set $R$ is called a ring when it is an abelian group under addition and a semigroup under multiplication, and the distributive law is applicable for both operations.\nSpecifically, if the commutative law also holds for multiplication, it is called a commutative ring or abelian ring. Moreover, according to the definition of a ring, there‚Äôs no need for the existence of an identity or an inverse for multiplication. Even if an identity exists, an inverse is not necessary. A set is considered a ring if it satisfies the six conditions mentioned above.\nWhen dealing with groups, we denote the identity element for an operation as $e$. Since there are two operations in a ring, different symbols are used to easily identify the identity for each operation. The identity for addition is denoted as $0$ and called the identity. If an identity for multiplication exists, it is denoted as $1$ and called unity. An element $a$ with an existing multiplicative inverse in the ring $R$ is referred to as a unit.\nSimilar to groups, the existence of a multiplicative identity in a ring, if it exists, is unique. Likewise, if an element‚Äôs inverse exists, it is also unique. The proof of this is identical to that used for groups, so it will not be reiterated here. Please refer to this link for more details.\nExample Consider the set of integers $\\mathbb{Z}$. It satisfies the six conditions mentioned, making it a ring under addition and multiplication. It is also a commutative ring since the commutative law is satisfied for multiplication. The unity $1$ exists, and its element is the integer 1, with units being 1 and -1 (each having 1 and -1 as their inverses, respectively).\nNote In a ring, the existence of a multiplicative identity and inverse is not \u0026rsquo;necessary\u0026rsquo;. Hence, one cannot indiscriminately cancel like in a group. What this means is when $a,\\ b,\\ c$ is an element of the ring $R$, just because $ab=ac$, one cannot hastily conclude that $b=c$. This is because the inverse for $a$ does not necessarily exist.\nLikewise, $a^2=a$ does not warrant hastily drawing the conclusions that $a=0$ or $a=1$. This is an important consideration when dealing with rings.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p167.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":587,"permalink":"https://freshrimpsushi.github.io/en/posts/587/","tags":null,"title":"Rings in Abstract Algebra"},{"categories":"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ","contents":"Definition 1 For $1 \\le p \u0026lt; \\infty$, distance space $( \\ell^{p} , d^{p} )$ is defined as follows:\n(i) Set of converging sequences:\n$$ \\ell^{p} := \\left\\{ \\left\\{ x_{n} \\right\\}_{n \\in \\mathbb{N}} \\subset \\mathbb{C} \\left| \\left( \\sum_{i=1}^{\\infty} | x_{i} |^{p} \\right)^{{1} \\over {p}} \u0026lt; \\infty \\right. \\right\\} $$\n(ii) Distance function:\n$$ d^{p} ( x_{n} , y_{n} ) := \\left( \\sum_{i = 1}^{\\infty} | x_{i} - y_{i} |^{p} \\right)^{ {{1} \\over {p}} },\\quad \\left\\{ x_{n} \\right\\} , \\left\\{ y_{n} \\right\\} \\in \\ell^{p} $$\nFor $p = \\infty$, distance space $( \\ell^{\\infty} , d^{\\infty} )$ is defined as follows:\n(i)\u0026rsquo; Set of bounded sequences:\n$$ \\ell^{\\infty} := \\left\\{ \\left\\{ x_{n} \\right\\}_{n \\in \\mathbb{N}} \\ \\left| \\ \\sup_{i \\in \\mathbb{N}} | x_{i} | \u0026lt; \\infty \\right. \\right\\} $$\n(ii)\u0026rsquo; Distance function:\n$$d^{\\infty} ( x_{n} , y_{n} ) := \\sup_{i \\in \\mathbb{N}} | x_{i} - y_{i} |,\\quad \\left\\{ x_{n} \\right\\} , \\left\\{ y_{n} \\right\\} \\in \\ell^{\\infty} $$\nExplanation $\\ell^{p}$ is called a sequence space, and $\\ell^{p}$ is pronounced as [ell_p]. The TeX code for $\\ell$ is \\ell.\nThe difference between space $\\ell^{p}$ and $L^{p}$ space is merely whether it\u0026rsquo;s about sequences or functions, series or integrals. This includes Young\u0026rsquo;s inequality, Cauchy-Schwarz inequality, H√∂lder\u0026rsquo;s inequality, Minkowski\u0026rsquo;s inequality, as well as completeness. Since the facts themselves are similar, the methods of proof are also largely the same, so if one is thoroughly studied, there is no real need to study the other.\nOn the other hand, $\\ell^{\\infty}$ is, in reality, the same as when $p \\to \\infty$, proven to be unnecessary to define separately. Most properties of $\\ell^{p}$ and $\\ell^{\\infty}$ are almost the same, so there\u0026rsquo;s no need to think of them separately.\nHowever, a notable exception is divisibility.\nTheorem 1 Let\u0026rsquo;s say $1 \\le p_{0} \u0026lt; \\infty$.\n(a): $\\ell^{p_{0}}$ is a divisible space. (b): $\\ell^{\\infty}$ is an indivisible space. This difference occurs because $\\ell^{p_{0}}$ has convergence as a condition, whereas $\\ell^{\\infty}$ only has boundedness as a condition.\nProof (a) Strategy: A converging sequence always allows to select $i_{0}$ so that $\\displaystyle \\left| \\sum_{i = i_{0}}^{\\infty} a_{i} \\right|$ becomes sufficiently small. Based on this $i_{0}$, it divides into finite and infinite parts, and then explicitly finds a subset that makes $l^{p_{0}}$ a divisible space by utilizing the fact that any finite sequence must converge to a point.\nClaim: A countable set $M \\subset \\ell^{p_{0}}$ that satisfies $\\overline{M} = \\ell^{p_{0}}$ exists.\nConsider a set of complex sequences that repeat only $0$ from a certain $j_{0}$\n$$ M : = \\left\\{ \\left\\{ m_{j} \\right\\} \\in \\ell^{p_{0}} \\ | \\ m_{j} \\in \\mathbb{Q} + i \\mathbb{Q} , m_{j} = 0 , \\ j\u0026gt;j_{0} , \\ j_{0} \\in \\mathbb{N} \\right\\} $$\nSince $M$ is a countable set and $\\overline{M} \\subset \\ell^{p_{0}}$ obviously holds, it is sufficient to show $\\ell^{p_{0}} \\subset \\overline{M}$. According to the definition of $l^{p_{0}}$, every sequence $x : = ( x_{1} , x_{2} , \\cdots ) \\in \\ell^{p_{0}}$ must have\n$$ \\left( \\sum_{j \u0026gt; N} | x_{j} |^{p_{0}} \\right)^{ {{1} \\over {p_{0}}} } \u0026lt; {{ \\varepsilon } \\over {2}} $$\nthat satisfies for any $\\varepsilon \u0026gt; 0$. Then, for each $x$\n$$ \\left( |x_{1} - m_{1}|^{p_{0}} + \\cdots + |x_{N} - m_{N}|^{p_{0}} \\right)^{ {{1} \\over {p_{0}}} } \u0026lt; {{\\varepsilon} \\over {2}} $$\nthat satisfies also exists\n$$ d^{p_{0}} ( x, m) = \\left( \\sum_{j \\le N} |x_{j} - m_{j}|^{p_{0}} + \\sum_{j \u0026gt; N} |x_{j}|^{p_{0}} \\right)^{{1} \\over {p_{0}}} \u0026lt; {{ \\varepsilon} \\over {2}} + {{ \\varepsilon} \\over {2}} = \\varepsilon $$\nfor all $\\varepsilon \u0026gt;0$, $B^{d^{p_{0}}} (x ; \\varepsilon ) \\cap M \\ne \\emptyset$, so $x \\in \\overline{M}$\n‚ñ†\n(b) Strategy: Define manageable bounded function $e_{I} \\in \\ell^{\\infty}$ and functions $\\psi$ on them, and use their injectiveness to calculate cardinality.\nClaim: No countable set $M \\subset \\ell^{p_{0}}$ satisfying $\\overline{M} = \\ell^{\\infty}$ exists.\nIt is sufficient to show that all $M \\subset \\ell^{\\infty}$ satisfying $\\overline{ M} = \\ell^{\\infty}$ are uncountable.\nPart 1.\nLet\u0026rsquo;s define function $e_{I} : I \\to \\left\\{ 0, 1 \\right\\}$ with domain $I \\subset \\mathbb{N}$ as\n$$ e_{I} (j) := \\begin{cases} 1 \u0026amp; , j \\in I \\\\ 0 \u0026amp; , j \\in ( \\mathbb{N} \\setminus I ) \\end{cases} $$\nFor example, if $I = 2 \\mathbb{N} = \\left\\{ 2, 4, 6 , \\cdots \\right\\} $, then the function value appears as $e_{2 \\mathbb{N}} (1) = 0$, $e_{2 \\mathbb{N}} (2) = 1$, $e_{2 \\mathbb{N}} (3) = 0$, $e_{2 \\mathbb{N}} (4) = 1 $.\nConsidering the set of these functions $A: = \\left\\{ e_{I} \\ | \\ I \\subset \\mathbb{N} \\right\\}$, since the function value cannot exceed $[0,1]$, $A \\subset \\ell^{\\infty}$ holds.\nPart 2.\nDefine function $\\phi : \\mathscr{P} ( \\mathbb{N} ) \\to A$ as $\\phi (I) : =e_{I}$. Then, if $I , I\u0026rsquo; \\subset \\mathbb{N}$ is $I \\ne i '$, $\\phi (I) = e_{I} \\ne e_{I\u0026rsquo;} = \\phi (I\u0026rsquo;)$ holds, so $\\phi$ is injective, and therefore\n$$ |A| \\ge | \\mathscr{P} ( \\mathbb{ N} ) | = 2^{\\aleph_{0}} = \\aleph_{1} $$\nFor any $x \\in \\ell^{\\infty} = \\overline{M}$ and $\\varepsilon \u0026gt;0$, $B_{d^{\\infty}} (x ; \\varepsilon ) \\cap M \\ne \\emptyset$ holds\n$$ B_{d^{\\infty}} \\left( e_{I} ; {{1} \\over {3}} \\right) \\cap M \\ne \\emptyset $$\nPart 3.\nSince $\\displaystyle B_{d^{\\infty}} \\left( e_{I} ; {{1} \\over {3}} \\right) \\cap M \\ne \\emptyset$ holds\n$$ \\psi ( e_{I} ) \\in \\left( B_{d^{\\infty}} \\left[ e_{I} ; {{1} \\over {3}} \\right] \\cap M \\right) $$\nwe can define function $\\psi : A \\to M$ that satisfies. Assuming $\\psi$ is not injective, for $\\psi ( e_{I}) = \\psi ( e_{I\u0026rsquo; })$, we have\n$$ \\psi ( e_{I}) = \\psi ( e_{I\u0026rsquo; }) \\in \\left[ B_{d^{\\infty}} \\left( e_{I} ; {{1} \\over {3}} \\right) \\cap B_{d^{\\infty}} \\left( e_{I\u0026rsquo;} ; {{1} \\over {3}} \\right) \\right] $$\nAccording to the triangle inequality\n$$ 1 = d^{\\infty} ( e_{I} , e_{I\u0026rsquo;} ) \\le d^{\\infty} ( e_{I} , \\psi (e_{I}) ) + d^{\\infty} ( \\psi (e_{I}) , e_{I\u0026rsquo;} ) \\le {{1} \\over {3}} + {{1} \\over {3}} = {{2} \\over {3}} $$\nIt concludes $\\displaystyle 1 \\le {{2} \\over {3}}$, which is a contradiction, hence $\\psi$ is injective. Also, since $\\psi : A \\to M$ is injective, $|M| \\ge |A| = \\aleph_{1}$, and $M$ cannot be countable.\n‚ñ†\nKreyszig. (1989). Introductory Functional Analysis with Applications: p11.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":695,"permalink":"https://freshrimpsushi.github.io/en/posts/695/","tags":null,"title":"Sequence Spaces (‚Ñìp spaces)"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 A topological space $X$ is called a $n$-dimensional manifold when it satisfies the following three conditions:\n(i): It is second-countable. (ii): It is Hausdorff. (iii): Every point of $X$ has a neighborhood homeomorphic to an open set in $\\mathbb{R}^{n}$. A $n$-dimensional manifold $X$ is said to have a boundary when it has the following two types of points:\n(1) Interior points: Every neighborhood of $x \\in X^{\\circ}$ is homeomorphic to $\\mathbb{R}^{n}$. (2) Boundary points: Every neighborhood of $x \\in \\partial X$ is homeomorphic to $U^{n} := \\left\\{ \\mathbb{x} \\ | \\ \\mathbb{x} \\in (\\mathbb{R}^{+})^{n} \\right\\}$. Description Condition (iii) and being locally Euclidean are equivalent. That is, a manifold is a topological space that locally resembles Euclidean space. In particular, a $1$-dimensional manifold is called a Curve, and a $2$-dimensional manifold is called a Surface.\nIn the example above, the first and second are $1$-dimensional manifolds, but the third is not a $1$-dimensional manifold because it has a twisted part.\nIn particular, the following holds true for a $n$-dimensional manifold $X$ with a boundary and a $m$-dimensional manifold $Y$ without a boundary. $$ \\partial (X \\times Y) = X \\times \\partial Y $$\nMunkres. (2000). Topology(2nd Edition): p225.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":673,"permalink":"https://freshrimpsushi.github.io/en/posts/673/","tags":null,"title":"What is a Manifold?"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Diagnostic Methods 1 Standardized residual plots can be used to check if a regression analysis was conducted properly. To verify homoscedasticity, one should check if the scatter of the residuals is uniformly distributed overall. Common examples of lack of homoscedasticity include the following two cases.\nThe variance increases towards the end, a situation that often requires a transformation or the introduction of weights to resolve. Regardless of how easy it is to solve, it‚Äôs often the most straightforward and simple solution among the issues discovered during model diagnostics.\nOnly the middle part has an unbelievably small variance, which could suggest a problem right from the data collection stage. It‚Äôs likely that there are other variables that can precisely explain the extreme variance, so it‚Äôs recommended to review the dataset once more.\nSee Also Linearity Independence Normality Hadi. (2006). Regression Analysis by Example(4th Edition): p98.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":681,"permalink":"https://freshrimpsushi.github.io/en/posts/681/","tags":null,"title":"Homoscedasticity of Residuals Verified through Model Diagnostics"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Diagnostic Techniques 1 Standardized residual plots can be used to check if the regression analysis was performed correctly.\nTo check for linearity, see if the residuals are symmetrically distributed around $0$.\nLooking at the figure on the right, it is evident that there is a lack of linearity.\nIf it were a simple regression analysis, it would result in an inability to explain the trend of the data at all.\nLet\u0026rsquo;s look at some shapes to be wary of.\nThe left side shows that the green residuals violate various assumptions of regression analysis but satisfy linearity itself.\nThe right side shows residuals that are distributed around $0$ on average, but there are issues calling it symmetric. If the residual plot turns out like this, it can be almost certainly inferred that some important condition or data is missing.\nIf it were a simple regression analysis, the trend of the data would roughly be correct, but there would always be large errors on an all-or-nothing level.\nSee Also Homoscedasticity Independence Normality Hadi. (2006). Regression Analysis by Example(4th Edition): p91.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":677,"permalink":"https://freshrimpsushi.github.io/en/posts/677/","tags":null,"title":"Residual Linearity Verified through Model Diagnostics"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Necessity In the case of simple regression analysis, since it involves only one independent variable and one dependent variable, making it a $2$ dimensional analysis, it is easy to visually confirm if the analysis was conducted properly. However, for multiple regression analyses that exceed $3$ dimensions, it becomes difficult to represent the data graphically, making it hard to verify the accuracy of the analysis. There are instances where the analysis passes hypothesis testing even though it does not satisfy the assumptions of regression analysis, in which case the analysis is essentially incorrect.\nErrors in analysis are mainly due to (1) the data not fitting the linear model, or (2) a significant discrepancy between the analysis results and the actual understanding of the data. Model diagnostics are conducted to check whether the data fits the linear model.\nDiagnostic Methods 1 Data not fitting the linear model simply means that the data is not aligned in a straight line. Whether the data fits the linear model or not is determined by looking at standardized residual plots and conducting model diagnostics. This method of residual analysis is quite ingenious, as it is designed to overcome the challenge of drawing lines in higher dimensions. It is fair to say that the very reason for calculating residuals in the first place is because of this.\nIf the following four conditions are met in the residual plots, the model diagnostic is considered to have passed:\n(i) Linearity: The residuals should be symmetrically distributed around $0$. This assumption is intrinsic to the nature of regression analysis, which aims to find a straight line. If linearity is not met, the exercise becomes pointless. Typically, linearity is easily satisfied in actual analysis since the use of regression analysis is predicated on the presumption of its presence. (ii) Homoscedasticity: The distribution of residuals should be uniform. If the variance suddenly decreases or increases in specific intervals, it implies that the data might not have been obtained through the same process. Issues such as differences in data collectors or errors need to be considered. If there are issues like increasing or decreasing variance towards the end, partial remedies can be sought through variable transformation. (iii) Independency: There should be no pattern in the residuals. A pattern in the residuals suggests that the errors are not completely random, contradicting the assumption of regression analysis. Lack of independency implies that there might be an unknown rule, such as autocorrelation. In such cases, it is better to look for more appropriate tools like time series analysis rather than attempting convoluted solutions. If the issue is severe, it becomes apparent at first glance but if not, it might not be a significant concern. Caution should be taken not to misuse the Durbin-Watson test for checking independency, as it is designed to detect autocorrelation in residuals at fixed intervals and not to confirm independency. One should not blindly trust in independency just because it passed the Durbin-Watson test when there is an apparent trend. (iv) Normality: The residuals should appear to follow a standard normal distribution. Unlike other assumptions, normality can be objectively diagnosed through tests like the Shapiro-Wilk test or Jarque-Bera test. However, the issue is not always straightforward, mainly because outliers often significantly impact normality. If the analyst can directly observe and explain the phenomena represented by the outliers, it‚Äôs not a major issue. It‚Äôs important not to hastily remove outliers. For instance, if there are $300$ samples and approximately $3$ outliers deviating beyond six sigma ($\\pm 3 \\sigma$), it‚Äôs considered normal. Having too many outliers is problematic, but having too few can also indicate that the data does not truly follow a normal distribution. These four conditions are not randomly ordered but are laid out in order of importance, and understanding this order can be gleaned from the theoretical derivation of hypothesis testing for regression coefficients.2 In actual statistical analysis, not all data presents itself neatly, requiring compromise on certain conditions at times. In such instances, some degree of deviation from normality, due to a high number of outliers or slight bias, can be tolerated.\nA significant part of model diagnostics relies on visual inspection, requiring a thorough understanding of the data. Identifying the incorrect parts is the first issue; how to address them is the second. The best way to develop this skill is to engage in as many real analyses as possible, exposing oneself to a variety of cases.\nCode Below is the R code that outputs the residual plots.\nout\u0026lt;-lm(rating~.,data=attitude); summary(out)\rwin.graph(5,5); plot(rstudent(out),main=\u0026#34;ÌëúÏ§ÄÌôîÎêú ÏûîÏ∞®\u0026#34;) Hadi. (2006). Regression Analysis by Example(4th Edition): p86~88.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nUnfortunately, it can be quite challenging to grasp at the undergraduate level.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":675,"permalink":"https://freshrimpsushi.github.io/en/posts/675/","tags":null,"title":"Regression Model Diagnostics"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÍ≤ÄÏ†ï","contents":"Hypothesis Testing Assuming in the model diagnostics of the linear multiple regression model, the residuals satisfy linearity, homoscedasticity, independence, and normality. The hypothesis testing for the multiple regression analysis with $n$ observations and $p$ independent variables is as follows:\n$H_{0}$: $\\beta_{1} = \\beta_{2} = \\cdots = \\beta_{p} = 0$ i.e., all independent variables do not have a correlation with the dependent variable. $H_{1}$: At least one among $\\beta_{1} , \\beta_{2} , \\cdots , \\beta_{p}$ is not $ 0$. Meaning, at least one independent variable has a significant correlation with the dependent variable. Derivation SST, SSR, SSE: 6. TSS(Total Sum of Squares) or SST(Sum of Squares Total): $$ \\text{TSS} =\\text{SST} := \\sum_{i=1}^{n} ( y_{i} - \\overline{y} )^2 $$ 7. ESS(Explained Sum of Squares) or SSR(Sum of Squares due to Regression): $$ \\text{ESS} = \\text{SSR} := \\sum_{i=1}^{n} ( \\hat{y}_{i} - \\overline{y} )^2 $$ 8. RSS(Residual Sum of Squares) or SSE(Sum of squared Error): $$ \\text{RSS} = \\text{SSE} := \\sum_{i=1}^{n} ( y_{i} - \\hat{y}_{i} )^2 $$\nSST, since it uses a single mean, has a degrees of freedom of $(n-1)$ while SSE, computed based on $p$ independent variables, uses $(p+1)$ regression coefficients including the constant term thus having a degrees of freedom of $\\left( n-(p-1) \\right)$. These follow a Chi-square distribution with their respective degrees of freedom based on the homoscedasticity and independence, and normality of residuals as divided by $\\sigma^{2}$. Meanwhile, $$ SST = SSR + SSE \\iff SSR = SST - SSE $$ thus, it has a degrees of freedom of $SSR$ and follows a Chi-square distribution $\\chi^{2} (p)$.\nDerivation of the F-distribution: If two random variables $U,V$ are independent and $U \\sim \\chi^{2} ( r_{1})$, $V \\sim \\chi^{2} ( r_{2})$, then $$ {{ U / r_{1} } \\over { V / r_{2} }} \\sim F \\left( r_{1} , r_{2} \\right) $$\nThe test statistic $F$ is $$ F := {{ \\text{SSR} / p } \\over { \\text{SSE} / (n-p-1 ) }} $$ defined as above follows an F-distribution with $(p , n-p-1)$ degrees of freedom.\nRepresenting in equations again, it is $\\displaystyle F = {{ \\text{SSR} / p } \\over { \\text{SSE} / (n-p-1 ) }} \\sim F(p, n-p-1)$, which is used for hypothesis testing.\n‚ñ†\nAlthough this F-test is meaningless if we can see each t-test of regression coefficient, the real essence lies in comparing models. It is about shedding the \u0026lsquo;subjectivity\u0026rsquo; or \u0026lsquo;ambiguousness\u0026rsquo; that inevitably follows statistics to produce statistically meaningful results. (Of course, in actual analyses, more convenient and easier statistics are used to compare models.)\nHypothesis Testing for Reduced Model For the multiple regression analysis with $n$ observations and $p$ independent variables, let\u0026rsquo;s say it is $i=0,1,\\cdots,p$. This regression model is called the Full Model, and the model that removes $k$ independent variables from FM is called the Reduced Model.\n$H_{0}$: RM is sufficient. Meaning, there is no need to use the FM with many variables. $H_{1}$: RM is insufficient. Meaning, it\u0026rsquo;s better to use the FM by increasing the variables. $$ F = {{ [ \\text{SSR} (RM) - \\text{SSR} (FM) ] / (p +1 - k) } \\over { \\text{SSE} ( FM ) / (n-p-1 ) }} $$ follows an F-distribution with $(p + 1 - k , n-p-1)$ degrees of freedom. If at the significance level $\\alpha$, $F \\le F_{ ( p+1-k , n-p-1 ; \\alpha ) }$ is achieved, $H_{0}$ is adopted, allowing for the use of the reduced RM.\nSee Also Multiple Regression Analysis Results of Multiple Regression Analysis in R ","id":672,"permalink":"https://freshrimpsushi.github.io/en/posts/672/","tags":null,"title":"F-test for Regression Coefficients"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Data Exploration tail(attitude) In R, let\u0026rsquo;s load the built-in data attitude and check it using the tail() function. We are interested in performing multiple regression analysis on this data.\nWe are interested in how the other independent variables affect the rating, which is our dependent variable. It\u0026rsquo;s difficult to see if there is a linear relationship between rating and the other variables just by looking at the data, so let\u0026rsquo;s draw a graph to check.\nwin.graph()\rplot(attitude) Simply putting the data into the plot() function and running it will output scatter plots comparing each variable.\nAt first glance, rating seems to have a clear linear relationship with complaints. For others like learning, and raises, they seem to form a linear relationship, but they are more scattered compared to complaints. Just like in simple regression analysis, we can input a linear model into the lm() function and see the results using the summary() function.\nResults Interpretation In the code below, columns 1~2 and 3 are exactly the same expression. The dot(.) input when entering the linear model means \u0026lsquo;all other variables\u0026rsquo;. [ NOTE: On the other hand, it\u0026rsquo;s also possible to input rating~.-privileges to exclude only privileges. ]\nout\u0026lt;-lm(rating~complaints+privileges+learning\r+raises+critical+advance,data=attitude)\rout\u0026lt;-lm(rating~.,data=attitude)\rsummary(out) The mentioning \u0026lsquo;it\u0026rsquo;s okay not to know\u0026rsquo; doesn\u0026rsquo;t mean you really don\u0026rsquo;t need to know; it means that these aren‚Äôt the indicators to focus on immediately when hurriedly studying and reading results. (1) Residuals It\u0026rsquo;s fine to just look at whether other percentiles appear symmetrically around the median(median). Since a model diagnosis cannot be completed with percentiles alone, it\u0026rsquo;s not very meaningful after all.\n(2) Estimate These are regression coefficients for each variable, where (Intercept) represents $y$ the intercept of the regression line, and the rest represents the rate of unit change per variable. Different from simple regression analysis, because there are various independent variables, the results change according to the significance level. At significance level $5 \\%$, the regression coefficient of learning doesn\u0026rsquo;t reject the null hypothesis $0$, $$ \\text{(rating)} = 0.61319 \\cdot \\text{(complaints)} + \\varepsilon $$ whereas at significance level $10 %$, the model can be reduced as follows: $$ \\text{(rating)} = 0.61319 \\cdot \\text{(complaints)} + 0.32033 \\cdot \\text{(learning)} + \\varepsilon $$\n(3) Std. Error It\u0026rsquo;s okay not to know. It\u0026rsquo;s the Standard Error of the estimate, which can be used to find the confidence interval of the regression coefficient.\n(4) t-value It\u0026rsquo;s okay not to know. This is the value obtained by dividing the estimate by its Standard Error, becoming a test statistic that follows the t-distribution with degrees of freedom $n-p-1$. It\u0026rsquo;s used to conduct a hypothesis test to see if the regression coefficients are statistically significant.\n(5) p-value pr(\u0026gt;|t|) If this is small, it means the regression coefficient is significant, and it\u0026rsquo;s better the smaller it is if you want to show there\u0026rsquo;s a correlation. Depending on how small this value is, the Signif. codes below will be marked accordingly. Typically, the significance level is set at 5%, so having even one dot marked can be considered as having a correlation. If this value is large and shows no regression relationship, it means that how the regression coefficient was determined is statistically meaningless. Since this p-value comes from the t-distribution, it\u0026rsquo;s appropriate to use the expression pr(\u0026gt;|t|).\n(6) Adjusted R-squared This measure indicates how well the analysis explains the data relative to the number of variables, with a higher value being better. As the number of variables in regression analysis increases, it means that more data can be used, and accordingly, the explanatory power $R^{2}$ always increases. The difference between adjusted explanatory power and explanatory power is that, unlike $\\displaystyle R^2 = 1 - {{ \\text{ SSE } } \\over { \\text{ SST} }}$, $$ \\displaystyle R^{2}_{a} = 1 - {{ \\text{ SSE } / (n - p - 1) } \\over { \\text{ SST} / (n - 1) }} $$ it\u0026rsquo;s calculated to reflect the number of variables. In actual applied mathematics, increasing the number of variables means increasing costs, and naturally, a way to reduce this must be found. The adjusted explanatory power $R^{2}_{a}$ applies a penalty in terms of the number of variables, thereby correcting the explanatory power and being used to compare models. If increasing the number of variables doesn\u0026rsquo;t significantly increase the adjusted explanatory power, it\u0026rsquo;s considered a waste.\n(7) F-Statistic If the p-value of this is small, it indicates significant regression coefficients, and it\u0026rsquo;s better the smaller it is if you want to show there is a correlation. While the t-test for regression coefficients is a test for each regression coefficient, the F-test is a test for the regression analysis itself. Leaving aside the p-value and talking about the F-statistic itself, it\u0026rsquo;s handy for comparing models.\nIt\u0026rsquo;s important to note that just being able to view these results does not mean the end. Multiple regression analysis is much more difficult than simple regression analysis because the introduction of more independent variables brings problems that were not present in simple regression analysis. There are various verification procedures that remain, which are difficult to explain with numerical calculations alone, and being good at these is essentially what constitutes proficiency at the undergraduate level of regression analysis.\nCode Below is the full example code written in R.\ntail(attitude)\rwin.graph()\rplot(attitude)\rout\u0026lt;-lm(rating~complaints+privileges+learning\r+raises+critical+advance,data=attitude)\rout\u0026lt;-lm(rating~.,data=attitude)\rsummary(out) See Also Multiple regression analysis F-test for regression coefficients How to do regression analysis in Julia ","id":670,"permalink":"https://freshrimpsushi.github.io/en/posts/670/","tags":["R"],"title":"How to Interpret Multiple Regression Analysis Results in R"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Overview Regression analysis is a method used to discover the relationships between variables, particularly useful for identifying linear relationships. Multiple Linear Regression refers to the regression analysis that determines the effects of multiple independent variables (explanatory variables) on a single dependent variable (response variable).\nModel 1 $$Y = \\beta_{0} + \\beta_{1} X_{1} + \\cdots + \\beta_{p} X_{p} + \\varepsilon $$\nWe are interested in whether variables have a linear relationship as shown above. It is assumed that each variable is independent of the others, and similarly, the regression coefficient represents the rate of unit change of a variable when other variables are held constant. Represented by a design matrix, it looks like $$ \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; x_{11} \u0026amp; \\cdots \u0026amp; x_{p1} \\\\ 1 \u0026amp; x_{12} \u0026amp; \\cdots \u0026amp; x_{p2} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 1 \u0026amp; x_{1n} \u0026amp; \\cdots \u0026amp; x_{pn} \\end{bmatrix} \\begin{bmatrix} \\beta_{0} \\\\ \\beta_{1} \\\\ \\vdots \\\\ \\beta_{p} \\end{bmatrix} + \\begin{bmatrix} \\varepsilon_{1} \\\\ \\varepsilon_{2} \\\\ \\vdots \\\\ \\varepsilon_{n} \\end{bmatrix} $$ and summarized, it is $Y = X \\beta + \\varepsilon$.\nThe computation itself uses the least squares method, just like simple regression analysis, which fortunately does not pay much attention to the dimensions $p$. However, unlike simple regression analysis, as $p$ is generalized for dimensions, it is also difficult to verify with a graph in $p \\ge 3$.\nJust looking at it is not enough to know if the analysis was done properly, therefore the analyst must justify the results through various diagnostics. Even if it passes these diagnostics, there are still issues like interaction and multicollinearity left, and choosing which variable to use is also an important issue.\nSee also Results of multiple regression analysis in R F-test of regression coefficients Derivation of the estimation of multiple regression coefficient vectors Hadi. (2006). Regression Analysis by Example(4th Edition): p53.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":666,"permalink":"https://freshrimpsushi.github.io/en/posts/666/","tags":null,"title":"Multiple Regression Analysis"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÍ≤ÄÏ†ï","contents":"Hypothesis Testing $$ \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; x_{11} \u0026amp; \\cdots \u0026amp; x_{p1} \\\\ 1 \u0026amp; x_{12} \u0026amp; \\cdots \u0026amp; x_{p2} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 1 \u0026amp; x_{1n} \u0026amp; \\cdots \u0026amp; x_{pn} \\end{bmatrix} \\begin{bmatrix} \\beta_{0} \\\\ \\beta_{1} \\\\ \\vdots \\\\ \\beta_{p} \\end{bmatrix} + \\begin{bmatrix} \\varepsilon_{1} \\\\ \\varepsilon_{2} \\\\ \\vdots \\\\ \\varepsilon_{n} \\end{bmatrix} $$ When independent variables of $p$ and $n$ data are given, the linear multiple regression model can be represented using the design matrix as shown above, and let\u0026rsquo;s denote it simply as $Y = X \\beta + \\varepsilon$. Assuming that the residuals satisfy linearity, homoscedasticity, independence, and normality in the model diagnostics, the hypothesis testing for each regression coefficient in multiple regression analysis is as follows:\n$H_{0}$: $\\beta_{j} = 0$, that is, the $j$th independent variable has no correlation with the dependent variable. $H_{1}$: $\\beta_{j} \\ne 0$, that is, the regression coefficient for the $j$th independent variable is significant. Derivation 1 Normality of Regression Coefficients: $$ \\hat{\\beta} \\sim N_{1+p} \\left( \\beta , \\sigma^{2} \\left( X^{T} X \\right)^{-1} \\right) $$ Unbiased Estimator of Residual Sum of Squares and Standard Error of Regression Coefficients: $$ E \\widehat{\\sigma^{2}} = E \\left[ {{ 1 } \\over { n-p-1 }} \\sum_{i=1}^{n} \\left( y_{i} - \\hat{y}_{i} \\right)^{2} \\right] = \\sigma^{2} $$ $$ \\text{s.e.} \\left( \\hat{\\beta}_{k} \\right) = \\hat{\\sigma} \\sqrt{ \\left[ \\left( X^{T} X \\right)^{-1} \\right]_{kk} } $$ Let\u0026rsquo;s define $t_{j}$ for the estimate of regression coefficient $\\hat{ \\beta_{j} }$ and standard error $\\text{se} \\left( \\hat{ \\beta_{j} } \\right)$ as follows: $$ t_{j} := {{\\hat{ \\beta_{j} }} \\over {\\text{se} \\left( \\hat{ \\beta_{j} } \\right)}} $$\nSum of Random Variables following Chi-Squared Distribution: Let\u0026rsquo;s assume that the random variables $X_{1} , \\cdots , X_{n}$ are mutually independent. If $X_i \\sim \\chi^2 ( r_{i} )$, then $$ \\sum_{i=1}^{n} X_{i} \\sim \\chi ^2 \\left( \\sum_{i=1}^{n} r_{i} \\right) $$ The residual sum of squares $\\sum_{i=1}^{n} \\left( y_{i} - \\hat{y}_{i} \\right)^{2} / \\sigma^{2}$ uses the sample mean for $n$ data points, $p$ independent variables, and $1$ constant terms‚Äîthus, since only $(n-p-1)$ independent random variables are used, it follows a chi-squared distribution with degrees of freedom $(n-p-1)$ under the null hypothesis‚Äîassuming the null hypothesis is true, then $\\beta_{j} = 0$ results in $\\hat{\\beta}_{j} \\sim N \\left( 0 , \\sigma^{2} \\left( X^{T} X \\right)^{-1}_{jj} \\right)$, thus obtaining: $$ \\begin{align*} t_{j} =\u0026amp; {{\\hat{ \\beta_{j} }} \\over {\\text{se} \\left( \\hat{ \\beta_{j} } \\right)}} \\\\ =\u0026amp; {{\\hat{ \\beta_{j}} - 0 } \\over { \\hat{\\sigma} \\sqrt{ \\left[ \\left( X^{T} X \\right)^{-1} \\right]_{kk} } }} \\\\ =\u0026amp; {{\\hat{ \\beta_{j}} - 0 } \\over { \\sqrt{ {{ \\sum_{i=1}^{n} \\left( y_{i} - \\hat{y}_{i} \\right)^{2} } \\over { n-p-1 }} \\left[ \\left( X^{T} X \\right)^{-1} \\right]_{kk} } }} \\\\ =\u0026amp; {{ {{ \\hat{ \\beta_{j}} - 0 } \\over { \\sqrt{ \\left[ \\left( X^{T} X \\right)^{-1} \\right]_{kk} } }} } \\over { \\sqrt{ {{ \\sum_{i=1}^{n} \\left( y_{i} - \\hat{y}_{i} \\right)^{2} } \\over { n-p-1 }} } }} \\\\ =\u0026amp; {{ {{ \\hat{ \\beta_{j} } - 0 } \\over { \\sigma \\sqrt{ \\left[ \\left( X^{T} X \\right)^{-1} \\right]_{kk} } }} } \\over { \\sqrt{ {{ \\sum_{i=1}^{n} \\left( y_{i} - \\hat{y}_{i} \\right)^{2} } \\over { \\sigma^{2} }} / (n-p-1) } }} \\\\ \\sim \u0026amp; {{ N (0,1) } \\over { \\sqrt{\\chi^{2} (n-p-1) / n-p-1} }} \\end{align*} $$\nDerivation of t-Distribution: If two random variables $W,V$ are independent and $W \\sim N(0,1)$, $V \\sim \\chi^{2} (r)$, then $$ T = { {W} \\over {\\sqrt{V/r} } } \\sim t(r) $$ In conclusion, $t_{j}$ follows a t-distribution with degrees of freedom $(n-p-1)$. Representing it in a formula again gives: $$ t_{j} = {{\\hat{ \\beta_{j} }} \\over {\\text{se} \\left( \\hat{ \\beta_{j} } \\right)}} \\sim t(n-p-1) $$ which is used for hypothesis testing. If $$ \\left| t_j \\right| \\ge t_{(n-p-1 , {{\\alpha} \\over {2}})} $$ then the null hypothesis is rejected. That $\\left| t_j \\right|$ is of such magnitude means $\\hat{ \\beta_{j} }$ is too large to believe that the null hypothesis is true.\n‚ñ†\nExplanation $j$th variable and significance level $\\alpha$ can also calculate the confidence interval $\\hat{ \\beta_{j} } \\pm t_{(n-p-1 , {{\\alpha} \\over {2}})} \\text{se} ( \\hat{ \\beta_{j}} )$.\nWhile the derivation process is written calmly, it could be quite difficult for undergraduates learning regression analysis to understand it. Following $t_{j}$ to a t-distribution is not very challenging, but it requires understanding the distribution of regression coefficients as a corollary, and having a firm grasp on the concepts of model diagnostics.\nSee Also Simple Regression Analysis Multiple Regression Analysis Simple Regression Analysis Results in R Hadi. (2006). Regression Analysis by Example(4th Edition): p0.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":654,"permalink":"https://freshrimpsushi.github.io/en/posts/654/","tags":null,"title":"Regression Coefficient's t-test"},{"categories":"Ïó¥Î¨ºÎ¶¨Ìïô","contents":"Definition The quantity $S$ is defined as entropy if it satisfies the following equation.\n$$ dS = {{ \\delta Q_{\\text{rev} } } \\over { T }} $$\nExplanation Entropy is a physical quantity representing \u0026lsquo;disorder,\u0026rsquo; and it\u0026rsquo;s challenging to understand why it indicates disorder just by looking at its mathematical definition. Explanations for non-specialists like \u0026lsquo;messing up a room\u0026rsquo; or \u0026lsquo;dropping ink into a glass of water\u0026rsquo; can only explain \u0026lsquo;disorder,\u0026rsquo; not $dS = \\dfrac{\\delta Q_{\\text{rev}} }{ T }$.\nTo grasp the concept, it\u0026rsquo;s essential to think of entropy not as something derived but as a \u0026lsquo;definition.\u0026rsquo; If you\u0026rsquo;ve ever wondered, \u0026lsquo;Why define it this way?\u0026rsquo; a brief visual explanation might help. Consider the following two situations:\nCase 1. When the system\u0026rsquo;s temperature is low\nImagine inputting thermal energy $Q$ into a cooled space. This is giving a change in thermal energy $\\delta Q$ at a low temperature $T_{1}$. Let\u0026rsquo;s say the change in entropy is $d S_{1}$.\nCase 2. When the system\u0026rsquo;s temperature is high\nNow, imagine adding the same thermal energy $Q$ to an already hot space as in Case 1. This is giving a change in thermal energy $\\delta Q$ at a high temperature $T_{2}$. Let\u0026rsquo;s say the change in entropy is $d S_{2}$ in this case.\nThe inputted energy will diffuse to a colder area according to the Second Law of Thermodynamics. The space in Case 1. turns into a murky color that is hard to describe, compared to its original blue color, while the space in Case 2. barely becomes redder than before. This difference in color change signifies how much the space has changed due to the inputted energy, meaning $d S_{1} \u0026gt; d S_{2}$. Mathematically, since $T_{1} \u0026lt; T_{2}$, it follows that:\n$$ {{1} \\over {T_{1} }} \u0026gt; {{1} \\over {T_{2}}} $$\nThus, according to the definition of entropy, the following equation is a natural conclusion.\n$$ d S_{1} = {{\\delta Q_{\\text{rev} }} \\over {T_{1} }} \u0026gt; {{\\delta Q_{\\text{rev} }} \\over {T_{2}}} = d S_{2} $$\nIn thermodynamic terms, this means the increase in entropy in Case 1. is greater than in Case 2.. If explained by messing up a room, it means \u0026rsquo;the same mischief causes a tidy room to become messier easier than a messy room.\u0026rsquo; If explained by dropping ink, \u0026rsquo;the same amount makes clear water dirtier easier than murky water.\u0026rsquo;\n","id":651,"permalink":"https://freshrimpsushi.github.io/en/posts/651/","tags":null,"title":"In Thermodynamics, What is Entropy?"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Overview Regression Analysis is a method for identifying relationships between variables, especially useful for elucidating linear relationships. Simple Linear Regression is the simplest among them, referring to regression analysis on one dependent (response) variable and one independent (explanatory) variable.\nModel 1 The statement that independent variable $x_{i}$ and dependent variable $y_{i}$ have a linear relationship means that for some $a,b$, it can be expressed as $y_{i} = ax_{i} + b$. Of course, there will inevitably be errors concerning the actual data, so more precisely, it includes an error term, becoming $y_{i} = ax_{i} + b + \\varepsilon_{i}$. Converting this expression into a form more commonly used in regression analysis $$ y_{i} = \\beta_{0} + \\beta_{1} x_{i} + \\varepsilon_{i} $$ When represented as a design matrix, $$ \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; x_{1} \\\\ 1 \u0026amp; x_{2} \\\\ \\vdots \u0026amp; \\vdots \\\\ 1 \u0026amp; x_{n} \\end{bmatrix} \\begin{bmatrix} \\beta_{0} \\\\ \\beta_{1} \\end{bmatrix} + \\begin{bmatrix} \\varepsilon_{1} \\\\ \\varepsilon_{2} \\\\ \\vdots \\\\ \\varepsilon_{n} \\end{bmatrix} $$ and by arranging, we get $Y = X \\beta + \\varepsilon$.\nOptimization This boils down to finding $\\beta = \\begin{bmatrix} \\beta_{0} \\\\ \\beta_{1} \\end{bmatrix}$ that minimizes $\\| \\varepsilon \\|_{2} = \\| Y - X \\beta \\|_{2}$ through the method of least squares. Since $\\beta$ represents the intercept and slope of the line, finding $\\beta$ is about finding the line that explains the data in linear terms with the least error. Of course, since we can\u0026rsquo;t know exactly what relationship the two variables have, we need to find the estimates of regression coefficients, $\\hat{ \\beta_{0}}$ and $\\hat{ \\beta_{1} }$. In simple terms, draw the line that looks the most like the data.\nThese problems are typically solved using tools from numerical linear algebra, but simple regression analysis can also be solved with simple calculus. Rearranging the matrix and representing it again, $$ \\begin{align} \\varepsilon^2 = \\sum_{i=1}^{n} ( y_{i} - \\beta_{0} - \\beta_{1} x_{i} )^2 \\end{align} $$ is about finding $\\beta_{0} = \\hat{ \\beta_{0} }$ and $\\beta_{1} = \\hat {\\beta_{1}}$ that minimize it. Taking the partial derivative of equation $(1)$ with respect to $\\beta_{0}$, $$ {{ \\partial \\varepsilon^2 } \\over { \\partial \\beta_{0}}} = -2 \\sum_{i=1}^{n} (y_{i} - \\beta_{0} - \\beta_{1} x_{i} ) $$ For $\\varepsilon^2$ to be minimized, $$ n \\beta_{0} = \\sum_{i=1}^{n} y_{i} - \\beta_{1} \\sum_{i=1}^{n} x_{i} $$ Thus, $\\varepsilon^2$ is minimized when it is $\\beta_{0} = \\overline{y} - \\beta_{1} \\overline{x}$. Taking the partial derivative of equation $(1)$ with respect to $\\beta_{1}$, $$ {{ \\partial \\varepsilon^2 } \\over { \\partial \\beta_{1}}} = -2 \\sum_{i=1}^{n} x_{i} (y_{i} - \\beta_{0} - \\beta_{1} x_{i} ) $$ Since $\\varepsilon^2$ is minimized when it is $\\beta_{0} = \\overline{y} - \\beta_{1} \\overline{x}$, $$ \\sum_{i=1}^{n} x_{i} (y_{i} - \\overline{y} + \\beta_{1} \\overline{x} - \\beta_{1} x_{i} ) = 0 $$ In other words, $$ \\beta_{1} \\sum_{i=1}^{n} ( x_{i}^2 - \\overline{x} x_{i} ) = \\sum_{i=1}^{n} x_{i} y_{i} - \\sum_{i=1}^{n} x_{i} \\overline{y} $$ Summarizing, $$ \\begin{align*} \\beta_{1} =\u0026amp; {{\\sum_{i=1}^{n} x_{i} y_{i} - \\sum_{i=1}^{n} x_{i} \\overline{y} } \\over {\\sum_{i=1}^{n} ( x_{i}^2 - \\overline{x} x_{i} ) }} \\\\ =\u0026amp; {{ \\sum_{i=1}^n ( x_{i} - \\overline{x} ) ( y_{i} - \\overline{y} ) } \\over { \\sum_{i=1}^{n} (x_{i}^2 - \\overline{x}^2 )}} \\\\ =\u0026amp; {{ \\text{Cov} (X,Y) } \\over { \\text{Var} ( X ) }} \\\\ =\u0026amp; \\text{Cor} (X,Y) {{s_{y}} \\over {s_{x}}} \\end{align*} $$ For the actual calculation, one should find $\\hat{\\beta_{0}}$ before $\\hat{\\beta_{1}}$.\nSee Also Simple Regression Analysis Results in R T-test of Regression Coefficients Multiple Regression Analysis: Extending the model to multiple independent variables, unlike simple regression analysis. Derivation of the Estimate of Multiple Regression Coefficients Vector Hadi. (2006). Regression Analysis by Example(4th Edition): p24.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":648,"permalink":"https://freshrimpsushi.github.io/en/posts/648/","tags":null,"title":"Simple Regression Analysis"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Definition 1 The regression equation obtained through regression analysis $Y \\gets X_{1} + X_{2} + \\cdots + X_{n}$ is denoted as $y = \\beta_{0} + \\beta_{1} x_{1} + \\beta_{2} x_{2} + \\cdots + \\beta_{n} x_{n}$, and let\u0026rsquo;s indicate the n-th data as $(y_{i} , x_{i1} , x_{i2} , \\cdots , x_{in})$.\nMean: $$ \\displaystyle \\overline{y} := {{1} \\over {n}} \\sum_{i=1}^{n} y_{i} $$ Fitted Value: For the n-th data $y_{i}$ $$ \\hat{y}_{i} := \\beta_{0} + \\beta_{1} x_{i1} + \\beta_{2} x_{i2} + \\cdots + \\beta_{n} x_{in} $$ Predicted Value: For new data $y_{0}$ $$ \\hat{y}_{0} := \\beta_{0} + \\beta_{1} x_{01} + \\beta_{2} x_{02} + \\cdots + \\beta_{n} x_{0n} $$ Deviation due to Fit: $$ \\hat{y}_{i} - \\overline{y} $$ Residual: $$ y_{i} - \\hat{y}_{i} $$ TSS(Total Sum of Squares) or SST(Sum of Squares Total): $$ \\text{TSS} =\\text{SST} := \\sum_{i=1}^{n} ( y_{i} - \\overline{y} )^2 $$ ESS(Explained Sum of Squares) or SSR(Sum of Squares due to Regression): $$ \\text{ESS} = \\text{SSR} := \\sum_{i=1}^{n} ( \\hat{y}_{i} - \\overline{y} )^2 $$ RSS(Residual Sum of Squares) or SSE(Sum of squared Error): $$ \\text{RSS} = \\text{SSE} := \\sum_{i=1}^{n} ( y_{i} - \\hat{y}_{i} )^2 $$ R-squared or Coefficient of Determination: $$ R^2 := {{ \\text{ SSR } } \\over { \\text{ SST} }} $$ Description Fitted values and predicted values are mathematically the same; however, the difference lies in whether the data inserted into the regression equation is actual data or not. Thus, obtaining $\\hat{y_{i}}$ means calculating a value reflecting the given information. In this context, the 5th item, residual, is an error that naturally exists out of our control‚Äîerrors that should naturally be present. Regression analysis minimizes the sum of squared errors, constructs a regression line, and then examines the residuals to verify if the regression analysis\u0026rsquo;s assumptions are met, in a process called model diagnostics. The term \u0026ldquo;ESS\u0026rdquo; is merely a contrastive expression to \u0026ldquo;RSS,\u0026rdquo; the unexplainable sum of squares. The annoying part is that E and R stand confusingly close to Explained and Regression, Error and Residual respectively. $$ \\text{TSS} = \\text{SST} \\\\ \\text{ESS} = \\text{SSR} \\\\ \\text{RSS} = \\text{SSE} $$ It is not recommended to memorize which terms are switched by whether they come first or last. Just choose one notation that is comfortable for yourself to remember mathematically, and memorize as a fact that if it is written opposite to what you know, the abbreviations could be reversed as well. The R-squared value, also called the coefficient of determination, indicates how well the analysis explains the data. On the other hand, it can be easily shown that $\\text{SST} = \\text{SSR} + \\text{SSE}$; according to this, as $\\text{ESS}$ increases, $\\text{RSS}$ decreases, and $0 \\le R^{2} \\le 1$ is true. Therefore, when viewed intuitively, $$ R^2 = {{ \\text{ SSR } } \\over { \\text{ SST} }} = {{ \\text{ ESS } } \\over { \\text{ TSS } }} = {{\\text{ÏÑ§Î™ÖÌï† Ïàò ÏûàÎäî ÏóêÎü¨}} \\over {\\text{Ï†ÑÏ≤¥ ÏóêÎü¨}}} $$ hence, it can be understood as the ratio of the explanation of data in the analysis. Hadi. (2006). Regression Analysis by Example(4th Edition): p40~42.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":650,"permalink":"https://freshrimpsushi.github.io/en/posts/650/","tags":null,"title":"Fitted Values, Predicted Values, Residuals, Errors"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 A function space is defined as the product space $Y^{X}$ for topological spaces $X$ and $Y$. $$ Y^{X} : = \\prod_{x \\in X} Y = \\left\\{ f \\ | \\ f : X \\to Y \\text{ is a function} \\right\\} $$\nThe topology for the function space can be:\nFor an open set $U$ in $x \\in X$ and $Y$, let $$ S (x , U) = \\left\\{ f \\in Y^{X} \\ | \\ f(x) \\in U \\right\\} $$ The topology generated by the subbasis $\\left\\{ S(x,U) \\ | \\ x \\in X , U \\subset Y \\right\\}$ for $Y^{X}$ is called the Point-Open Topology. For a compact set $K \\subset X$ and an open set $U$ in $Y$, let $$ S (K , U) = \\left\\{ f \\in Y^{X} \\ | \\ f(K) \\subset U \\right\\} $$ The topology generated by the subbasis $\\left\\{ S(K,U) \\ | \\ K \\subset X , U \\subset Y \\right\\}$ for $Y^{X}$ is called the Compact-Open Topology. Let‚Äôs say $(Y,d)$ is a metric space.\nFor a compact set $K \\subset X$ and $\\varepsilon \u0026gt; 0$, let $$ B_{K} (f, \\epsilon) = \\left\\{ g \\in Y^{X} \\ \\left| \\ \\sup_{x \\in K} \\left\\{ d(f(x),g(x)) \\right\\} \u0026lt; \\varepsilon \\right. \\right\\} $$ The topology generated by the basis $\\left\\{ B_{K} (f, \\varepsilon ) \\ | \\ K \\subset X , \\varepsilon \u0026gt; 0 \\right\\}$ for $Y^{X}$ is called the Topology of Compact Convergence. The uniform metric $$ \\overline{ \\rho } (f,g) : = \\sup_{x \\in X} \\left\\{ \\min \\left\\{ d(f(x) , g(x) ) , 1 \\right\\} \\right\\} $$ generates the topology for the metric space $(Y^{X} , \\overline{ \\rho } )$ called the Uniform Topology. Theorem [1]: The Compact-Open Topology is larger than the Point-Open Topology. [2]: The Topology of Compact Convergence is larger than the Point-Open Topology. [3]: The Uniform Topology is larger than the Compact-Open Topology. [4]: The Uniform Topology is larger than the Topology of Compact Convergence. [5]: If $X$ is a discrete space, the Topology of Compact Convergence for $Y^{X}$ is the same as the Point-Open Topology. [6]: If $X$ is a compact space, the Topology of Compact Convergence for $Y^{X}$ is the same as the Tychonoff Topology. Let $\\left\\{ f_{n} : X \\to Y \\right\\}$ be a sequence in $Y^{X}$, and let the function restricted to the domain $K \\subset X$ be denoted as $f_{n} |_{K} : K \\to Y$.\n[7]: If $\\left\\{ f_{n} \\right\\}$ converges to $f$ in the Point-Open Topology of $Y^{X}$, then for every $x \\in X$, $ f_{n} (x) $ converges to $f(x)$. [8]: If $\\left\\{ f_{n} \\right\\}$ converges to $f$ in the Topology of Compact Convergence of $Y^{X}$, then for every compact $K \\subset X$, $f_{n} |_{K}$ uniformly converges to $f |_{K}$. For a set of continuous functions whose domain is the topological space $X$ and codomain is the metric space $Y$, $$ C(X,Y) := \\left\\{ f \\in Y^{X} \\ | \\ f \\text{ is continuous} \\right\\} $$ and let $C(X,Y)$ be a subspace of $Y^{X}$.\n[9]: The Compact-Open Topology and the Topology of Compact Convergence for $C(X,Y)$ are the same. [10]: The Topology of Compact Convergence for $C(X,Y)$ does not depend on the distance function of $Y$. [11]: If the sequence $\\left\\{ f_{n} \\right\\}$ of $C(X,Y)$ converges to $f \\in Y^{X}$, then $f : X \\to Y$ is a continuous function. Explanation In particular, $C(X, \\mathbb{R})$ is represented as $C(X)$, and especially when $X$ is an interval, that is, when $X=(a,b)$, $X=[a,b]$, they are represented as $C(a,b)$, $C[a,b]$, respectively.\n[1]~[4] To summarize, one can say the Point-Open Topology is smaller, and the Uniform Topology is larger.\n[7], [8] It can be useful in demonstrating uniform continuity of functions.\n[10], [11] As a generalization of analysis to general topology, this is very important as a fact.\nMunkres. (2000). Topology(2nd Edition): p267.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":646,"permalink":"https://freshrimpsushi.github.io/en/posts/646/","tags":null,"title":"Functional Spaces in Topology"},{"categories":"Ïó¥Î¨ºÎ¶¨Ìïô","contents":"Laws Clausius: There is no process that transfers heat from a colder body to a hotter body by itself.\nKelvin: A process that converts all heat into work is impossible.\nExplanation The statements by German physicist Clausius and British physicist Kelvin on the Second Law of Thermodynamics are equivalent to each other. The most famous version is by the Greek mathematician Carath√©odory, stating that \u0026rsquo;the entropy of a closed system does not decrease\u0026rsquo;. This is popular especially among laypeople because it affirms eschatology without using terms like \u0026lsquo;hot\u0026rsquo; or \u0026lsquo;work,\u0026rsquo; thus sounding sophisticated. It\u0026rsquo;s a concept often cherry-picked by those who, without serious consideration, prefer pseudoscience, like \u0026lsquo;Schrodinger\u0026rsquo;s cat\u0026rsquo;. Let\u0026rsquo;s define the terms mentioned in the laws more precisely for a better explanation.\nColder means having a relatively lower [temperature].\nHotter means having a relatively higher temperature.\nThe conversion of [heat] into work is referred to as a process.\nA closed system that receives heat from outside to perform a process is called a heat engine.\nLet\u0026rsquo;s say a heat engine receives heat $Q_{h}$ and does work $W$. Then, $\\eta : = \\dfrac{W}{Q_{h}}$ is referred to as efficiency.\nSteam engines and hot air balloons are examples of heat engines. Efficiency is logically defined as the \u0026lsquo;ratio of energy converted into desired work out of the total energy provided to the engine\u0026rsquo;.\nUsing blue for colder with $l$ and red for hotter with $h$, we can illustrate it as above, showing the energy received at a higher temperature and the remaining energy after some of it is used for work.\nClausius: There is no process that transfers heat from a colder body to a hotter body by itself\nThe diagram above schematically represents Clausius\u0026rsquo;s Second Law of Thermodynamics. Simply put, Clausius\u0026rsquo;s statement implies \u0026lsquo;heat always flows from a higher place to a lower one\u0026rsquo;. If this law were incorrect, water could flow uphill, and suddenly heat could appear out of nowhere, warming things up.\nOf course, if a machine receives work from the outside as shown above, the story changes. Since it\u0026rsquo;s not a process where heat is \u0026lsquo;spontaneously\u0026rsquo; transferred from a colder to a hotter body, heat has been transferred from cold to hot. This does not violate the Second Law of Thermodynamics because the assumption of a \u0026lsquo;closed system\u0026rsquo; was not met, making it possible.\nKelvin: A process that converts all heat into work is impossible\nThe diagram above schematically represents Kelvin\u0026rsquo;s Second Law of Thermodynamics. Simply put, Kelvin\u0026rsquo;s statement means \u0026lsquo;it\u0026rsquo;s impossible to have no loss\u0026rsquo;. If this law were incorrect, Galileo\u0026rsquo;s thought experiment would have been a real experiment, and perpetual motion machines would exist.\nSee Also Zeroth Law of Thermodynamics First Law of Thermodynamics ","id":643,"permalink":"https://freshrimpsushi.github.io/en/posts/643/","tags":null,"title":"The Second Law of Thermodynamics"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Theorems 1 Let $G,G'$ be a group.\nFirst Isomorphism Theorem: If there exists a homomorphism $\\phi : G \\to G'$, then $$ G / \\ker ( \\phi ) \\simeq \\phi (G) $$ Second Isomorphism Theorem: If $H \\le G$ and $N \\triangleleft G$, then $$ (HN) / N \\simeq H / (H \\cap N) $$ Third Isomorphism Theorem: If $H , K \\triangleleft G$ and $K \\leq H$, then $$ G/H \\simeq (G/K) / (H/K) $$ The Isomorphism Theorem refers to three independent theorems proved by the algebraist Emmy Noether.\n$\\ker$ is the kernel. $N \\triangleleft G$ means that $N$ is a normal subgroup of $G$. Explanation The First Isomorphism Theorem suggests that there exists an isomorphism $\\color{red} {\\mu}$ corresponding to the red part in the diagram. This implies that, in a group, by discarding unnecessary parts for $\\phi$, only structures treating the kernel as a kind of \u0026lsquo;unit\u0026rsquo; can be left.\nProof Let $K : = \\ker ( \\phi )$. Define $\\mu : G / K \\to \\phi (G)$ as $\\mu (xK) = \\phi ( x)$. Now, we need to show that $\\mu$ is an isomorphism.\nPart 1. $\\mu$ is a function.\nFor the identity elements $x,y \\in G$ and $G'$, $e'$,\n$$ \\begin{align*} \u0026amp; xK = yK \\\\ \\iff \u0026amp; x^{-1} y \\in K \\\\ \\iff \u0026amp; \\phi ( x^{-1} y ) = e' \\\\ \\iff \u0026amp; \\phi ( x^{-1} ) \\phi ( y ) = e' \\\\ \\iff \u0026amp; \\phi ( x ) ^{-1} \\phi ( y ) = e' \\\\ \\iff \u0026amp; \\phi ( x ) = \\phi ( y ) \\end{align*} $$ Hence, $xK = yK \\implies \\phi ( x ) = \\phi ( y )$, so $\\mu$ is a function.\nPart 2. $\\mu$ is injective.\nBy reversing the process from Part 1, since $\\phi ( x ) = \\phi ( y ) \\implies xK = yK$, $\\mu$ is injective.\nPart 3. $\\mu$ is surjective.\n$\\mu ( G / K ) = \\left\\{ \\mu (xK) \\ | \\ x \\in G \\right\\} = \\left\\{ \\phi (x) \\ | \\ x \\in G \\right\\} = \\phi (G)$, thus, $\\mu$ is surjective.\nPart 4. $\\mu$ is a homomorphism.\nFor $x,y \\in G$, $$ \\mu (xKyK) = \\mu (xyK) = \\phi (xy) = \\phi (x) \\phi (y) = \\mu (xK) \\mu (yK) $$ therefore, $\\mu$ is a homomorphism.\n‚ñ†\nGeneralization Meanwhile, a theorem extending the First Isomorphism Theorem to rings is known. The method of proof is almost the same, except that unlike groups, both addition and multiplication operations are considered.\nFundamental Theorem of Homomorphism: For rings $R$, $r '$, if there exists a homomorphism $\\phi : R \\to r '$, then $R / \\ker ( \\phi ) \\simeq \\phi (R)$\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p307~309.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":637,"permalink":"https://freshrimpsushi.github.io/en/posts/637/","tags":null,"title":"Proof of the First Isomorphism Theorem"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 An action of a group $G$ with identity element $e$ on a set $X$ is a binary operation $\\ast : G \\times X \\to X$ that satisfies the following two conditions:\n(i): For all $x \\in X$, there is $ex = x$ (ii): For all $x \\in X$ and $g_{1} , g_{2} \\in G$, there is $( g_{1} g_{2} ) (x) = g_{1} (g_{2} x)$ We refer to $X$ as a $G$-set under these circumstances.\nExplanation In simple terms, the action of a group is \u0026lsquo;adding $g \\in G$ to $x \\in X$\u0026rsquo;. To intuitively understand this, consider the following illustration:\n$$ X : = \\left\\{ C, 1,2,3,4 , p_{1}, p_{2} , p_{3} , p_{4} , s_{1}, s_{2} , s_{3} , s_{4} , d_{1}, d_{2} , m_{1} , m_{2} \\right\\} $$ Regarding the set $X$, consider the tetrahedral group $D_{4}$. The set of lines and points that can be thought of in a square, $X$, can change its position through flipping and rotating by $D_{4}$, making it a $D_{4}$-set. Calling such manipulations that induce changes in $X$ an action is very reasonable and justifiable.\nNote that $X$ doesn\u0026rsquo;t necessarily have to be a group nor related to $G$. For instance, considering $\\mathbb{Z}$ and $$ X:= \\left\\{ \\cdots , - {{3} \\over {2}} , - {{1} \\over {2}}, {{1} \\over {2}} , {{3} \\over {2}} , \\cdots \\right\\} $$ $\\left\u0026lt; X , + \\right\u0026gt;$ doesn‚Äôt form a group and is not yet related to $G = \\mathbb{Z}$. However, if $\\ast : \\mathbb{Z} \\times X \\to X$ is defined as $ z * x = z + x$ for $z \\in \\mathbb{Z}$ and $x \\in X$, then\n(i): $0 + x = x$ holds, (ii): $(z_{1} + z_{2}) + x = z_{1} + (z_{2} + x)$ holds, hence the operation $\\ast$ becomes an action on $X$, making $X$ a $\\mathbb{Z}$-set. Fraleigh. (2003). A first course in abstract algebra(7th Edition): p154.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":630,"permalink":"https://freshrimpsushi.github.io/en/posts/630/","tags":null,"title":"Group Actions"},{"categories":"Ïó¥Î¨ºÎ¶¨Ìïô","contents":"Laws When work $W$ is applied to a system with thermal energy $Q$, the following equation holds for the internal energy $U$:\n$$ d U = \\delta Q + \\delta W $$\n$\\delta$ indicates an inexact differential.\nExplanation Since they do not have a primitive function in a clean form, it is necessary to calculate through line integration. It means that it is impossible to know exactly how much the thermal energy has changed or how much work has changed just by the change in internal energy. It might be helpful to think that whether it is $10 = 2 + 8$ or $10 = -5 + 15$, the left side is the same, which is $10$.\nHowever, this is merely the limitation of the First Law of Thermodynamics, not the main point I want to make. On the contrary, it means that the change in internal energy can be calculated cleanly regardless of how thermal energy and work turn out. The following formulas are derived from the First Law of Thermodynamics.\nFormula 1 For the distance $dx$ that the piston has pushed and the force $F$, $\\delta W = F dx$\nIn fact, this form is hardly ever used in thermodynamics. Since the pressure $p$ and the force $F$ can be expressed as $F = pA$ for the area of the piston $A$, it is $A dx = - dV$.\nFormula 2 For pressure $p$ and volume $V$, $\\delta W = - p d V$\nUnlike above, this form is used quite frequently, so pay special attention to the sign and memorize it.\nSee Also Zeroth Law of Thermodynamics Second Law of Thermodynamics ","id":629,"permalink":"https://freshrimpsushi.github.io/en/posts/629/","tags":null,"title":"First Law of Thermodynamics"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 Let\u0026rsquo;s call the set of all cosets of $H \\subset G$ as $G / H$. If there exists a well-defined binary operation $\\ast$ like $(aH) \\ast\\ (bH) = (ab) H$, then $\\left\u0026lt; G / H , * \\right\u0026gt;$ is called a Factor Group.\nTheorem Let\u0026rsquo;s assume $H \\leqslant G$. That $H \\triangleleft G$ and $G / H$ being a group are equivalent.\nDescription That $H \\triangleleft G$ means that $H$ is a normal subgroup of $G$.\nThe binary operation $\\ast$ is a binary operation that calculates only with the representative elements of cosets, which makes the set $G / H$ form a factor group. If it\u0026rsquo;s not intuitively understandable why $G / H$ forms a group, it\u0026rsquo;s highly likely that the concept of cosets is misunderstood.\nProof It suffices to show that $( \\implies )$ $(aH) (bH) = (ab) H$.\nSince $H$ is a normal subgroup, if $h_{1} b \\in H b$, then there exists some $h_{3} \\in H$ such that $b h_{3} \\in bH$. For $ah_{1} \\in aH$ and $bh_{2} \\in H$ $$ (ah_{1}) (b h_{2}) = a(h_{1} b)h_{2} = a b h_{3} h_{2} = ab (h_{3} h_{2}) \\in (ab) H $$ Therefore, $(aH) (bH) \\subset (ab) H$, and reversing the process, $(ab) H \\subset (aH) (bH)$ thus $$ (aH) (bH) = (ab) H $$\nIt suffices to show that $( \\impliedby )$ $gH = Hg$.\nIf we have $x \\in gH$ and $g^{-1} \\in g^{-1} H$, then $$ (xH) (g^{-1} H) = (x g^{-1}) H $$ thus, $h := x g^{-1} \\in H$ must be the case. Meanwhile, since $x = hg$, $$ x \\in Hg $$ Therefore, $gH \\subset Hg$, and reversing the process, $Hg \\subset gH$ thus $$ gH = Hg $$\n‚ñ†\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p139.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":628,"permalink":"https://freshrimpsushi.github.io/en/posts/628/","tags":null,"title":"Quotient Groups in Abstract Algebra"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition The kernel of $G, G'$ with respect to the identity element $e, e'$ and the homomorphism $\\phi : G \\to G'$ is the preimage $ \\phi^{-1} [ \\left\\{ e' \\right\\} ]$ of $\\left\\{ e' \\right\\}$ and is denoted as $\\ker \\phi $.\nDefinition [1]: For $g \\in G$, $g ( \\ker \\phi ) = ( \\ker \\phi ) g$ [2]: $\\ker \\phi \\triangleleft G$ [3]: $\\ker \\phi = \\left\\{ e \\right\\}$ $\\iff$ $\\phi$ is injective. [4]: If $\\phi$ is surjective and $\\ker \\phi = \\left\\{ e \\right\\}$, then $\\phi$ is an isomorphism. Description Theorem [3] is a necessary and sufficient condition, but is particularly useful in proving that a homomorphism is injective. In linear algebra, the null space is strongly identified as the solution set for a given equation.\nMeanwhile, in abstract algebra, at least in group theory, $G$ is strongly characterized as \u0026lsquo;holding the center\u0026rsquo;, regardless of what it is, by becoming a normal subgroup. Interestingly, in theorem [1], it doesn\u0026rsquo;t even bother with how $\\phi$ is actually defined or what group $G'$ is. The theorem only views $G'$ as receiving $\\phi$ from $G$, meaningless otherwise.\nProof [3] If $( \\implies )$ $\\ker \\phi = \\left\\{ e \\right\\}$, then for every $g \\in G$, $\\phi ( \\left\\{ g \\right\\} )$ corresponds precisely only to $\\left\\{ g \\right\\} = g \\left\\{ e \\right\\}$, therefore $\\phi$ is injective.\nSince $( \\impliedby )$ $\\phi$ is injective and due to $\\phi (e) = e'$, $\\ker \\phi = \\left\\{ e \\right\\}$ must be followed.\n‚ñ†\nSee Also Null space in linear algebra ","id":622,"permalink":"https://freshrimpsushi.github.io/en/posts/622/","tags":null,"title":"Nucleus, Kernel in Abstract Algebra"},{"categories":"Ï†ïÏàòÎ°†","contents":"Algorithm Given a natural number $a,k,m$, $b \\equiv a^{k} \\pmod{m}$ can be computed as follows.\nStep 1. Binary Expansion of $k$\nRepresent $u_{i} = 0$ or $u_{i} = 1$ as follows. $$ k = \\sum_{i=0}^{r} u_{i} 2^{i} = u_{0} + 2 u_{1} + \\cdots + 2^r u_{r} $$\nStep 2.\nCalculate $a^{2^{r}} \\equiv ( a^{2^{r-1}} )^2 \\equiv A_{r-1}^2 \\equiv A_{r} \\pmod{m}$ as follows: $$ \\begin{align*} a \u0026amp; \u0026amp; \u0026amp; \\equiv A_{0} \\pmod{m} \\\\ a^{2} \u0026amp; \\equiv ( a^1 )^2 \u0026amp; \\equiv A_{0}^2 \u0026amp; \\equiv A_{1} \\pmod{m} \\\\ a^{4} \u0026amp; \\equiv ( a^2 )^2 \u0026amp; \\equiv A_{1}^2 \u0026amp; \\equiv A_{2} \\pmod{m} \\\\ a^{8} \u0026amp; \\equiv ( a^4 )^2 \u0026amp; \\equiv A_{2}^2 \u0026amp; \\equiv A_{3} \\pmod{m} \\\\ \u0026amp; \u0026amp; \u0026amp; \\vdots \\end{align*} $$\nStep 3.\nCalculating $A_{0}^{u_{0}} \\cdot A_{1}^{u_{1}} \\cdot \\cdots A_{r}^{u_{r}}$ yields: $$ a^{k} \\equiv A_{0}^{u_{0}} \\cdot A_{1}^{u_{1}} \\cdot \\cdots A_{r}^{u_{r}} \\pmod{m} $$\nExplanation Although the advancement of computers has made it possible to compute powers quickly, humans are never satisfied. The method of repeated squaring is a way to get the answer without directly computing immensely large numbers in modular operations. By dividing by $\\pmod{m}$ after each square, the number falls below $m$, thus reducing the amount of computation.\nExample For instance, let\u0026rsquo;s calculate $7^{327} \\pmod{853}$. Taking the common logarithm of $7^{327}$ gives $327 \\log 7 \\approx 327 \\cdot 0.8450 = 276.315$, which is a large number with a digit count of $277$. It\u0026rsquo;s too big to multiply honestly and then divide, so let\u0026rsquo;s use the above algorithm. If you do the binary expansion of $327$ as described in the algorithm, it looks like this: $$ 327 = 256 + 64 + 4 +2 +1 = 2^{8} + 2^{6} + 2^2 + 2^1 + 2^0 $$ If you calculate according to Step 2, $$ \\begin{align*} 7 \u0026amp; \u0026amp; \\equiv 7 \u0026amp; \\equiv 7 \\pmod{853} \\\\ 7^{2} \u0026amp; \\equiv ( 7^1 )^2 \u0026amp; \\equiv 7^2 \u0026amp; \\equiv 49 \\pmod{853} \\\\ 7^{4} \u0026amp; \\equiv ( 7^2 )^2 \u0026amp; \\equiv 49^2 \u0026amp; \\equiv 2401 \\equiv 695 \\pmod{853} \\\\ 7^{8} \u0026amp; \\equiv ( 7^4 )^2 \u0026amp; \\equiv 695^2 \u0026amp; \\equiv 227 \\pmod{853} \\\\ 7^{16} \u0026amp; \\equiv ( 7^8 )^2 \u0026amp; \\equiv 227^2 \u0026amp; \\equiv 349 \\pmod{853} \\\\ 7^{32} \u0026amp; \\equiv ( 7^{16} )^2 \u0026amp; \\equiv 349^2 \u0026amp; \\equiv 675 \\pmod{853} \\\\ 7^{64} \u0026amp; \\equiv ( 7^{32} )^2 \u0026amp; \\equiv 675^2 \u0026amp; \\equiv 123 \\pmod{853} \\\\ 7^{128} \u0026amp; \\equiv ( 7^{64} )^2 \u0026amp; \\equiv 123^2 \u0026amp; \\equiv 628 \\pmod{853} \\\\ 7^{256} \u0026amp; \\equiv ( 7^{128} )^2 \u0026amp; \\equiv 628^2 \u0026amp; \\equiv 298 \\pmod{853} \\end{align*} $$ Thus, $$ 7^{327} = 7^{256} \\cdot 7^{64} \\cdot 7^{4} \\cdot 7^{2} \\cdot 7^{1} = 298 \\cdot 123 \\cdot 695 \\cdot 49 \\cdot 7 \\equiv 286 \\pmod{853} $$ This method might still feel hard, but the amount of computation is quite reasonable compared to multiplying $327$ times individually.\nProof $$ \\begin{align*} a^{k} =\u0026amp; a^{u_{0} + 2u_{1} + \\cdots + 2^r u_{r} } \\\\ =\u0026amp; a^{u_{0}} a^{ 2u_{1} } \\cdots a^{ 2^r u_{r} } \\\\ \\equiv \u0026amp; A_{0}^{u_{0}} A_{1}^{u_{1}} \\cdots A_{r}^{u_{r}} \\pmod{m} \\end{align*} $$\n‚ñ†\nCode Below is an example code for calculating $7^{327} \\pmod{853}$ using the repeated squaring method, written in R language. Note that the power option accommodates negative integers, and if mod is a prime number, entering power=-1 allows you to find the multiplicative inverse of the given base.\nFPM\u0026lt;-function(base,power,mod) #It is equal to (base^power)%%mod\r{\ri\u0026lt;-0\rif (power\u0026lt;0) {\rwhile((base*i)%%mod != 1) {i=i+1}\rbase\u0026lt;-i\rpower\u0026lt;-(-power)}\rif (power==0) {return(1)}\rif (power==1) {return(base%%mod)}\rn\u0026lt;-0\rwhile(power\u0026gt;=2^n) {n=n+1}\rA\u0026lt;-rep(1,n)\rA[1]=base\rfor(i in 1:(n-1)) {A[i+1]=(A[i]^2)%%mod}\rfor(i in n:1) {\rif(power\u0026gt;=2^(i-1)) {power=power-2^(i-1)}\relse {A[i]=1} }\rfor(i in 2:n) {A[1]=(A[1]*A[i])%%mod}\rreturn(A[1])\r}\rFPM(7,327,853)\rFPM(7,-1,11) ","id":621,"permalink":"https://freshrimpsushi.github.io/en/posts/621/","tags":null,"title":"Square-and-Multiply Algorithm Proof"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 For an index set $\\mathscr{A}$, let $\\left\\{ X_{\\alpha} \\ | \\ \\alpha \\in \\mathscr{A} \\right\\}$ be a set of topological spaces, and let $O_{\\alpha}$ be an open set in $X_{\\alpha}$.\nFor the Cartesian product $\\displaystyle X := \\prod_{\\alpha \\in \\mathscr{A}} X_{ \\alpha}$, $p_{\\alpha} : X \\to X_{\\alpha}$ is called the projection. The topology generated by a subbasis $\\mathscr{S} : = \\left\\{ p_{\\alpha}^{-1} ( O_{\\alpha} ) \\ | \\ O_{\\alpha} \\subset X_{\\alpha} , \\alpha \\in \\mathscr{A} \\right\\}$ for $X$ is called the product topology. The topology generated by a basis $\\displaystyle \\mathscr{B} : = \\left\\{ \\prod_{\\alpha \\in \\mathscr{A}} O_{\\alpha} \\left. \\ \\right| \\ O_{\\alpha} \\subset X_{\\alpha} , \\alpha \\in \\mathscr{A} \\right\\}$ for $X$ is called the box topology. Theorem [1]: $p_{\\alpha}$ is a continuous function. [2]: If $\\left\\{ X_{\\alpha} \\ | \\ \\alpha \\in \\mathscr{A} \\right\\}$ is a set of Hausdorff spaces, then $X$ is Hausdorff. [3]: If $\\left\\{ X_{\\alpha} \\ | \\ \\alpha \\in \\mathscr{A} \\right\\}$ is a set of connected spaces, then $X$ is connected. [4]: If $\\left\\{ X_{\\alpha} \\ | \\ \\alpha \\in \\mathscr{A} \\right\\}$ is a set of compact spaces, then $X$ is compact. Let $\\mathscr{A} = \\mathbb{N}$.\n[5]: If $\\left\\{ X_{\\alpha} \\ | \\ \\alpha \\in \\mathscr{A} \\right\\}$ is a set of separable spaces, then $X$ is separable. [6]: If $\\left\\{ X_{\\alpha} \\ | \\ \\alpha \\in \\mathscr{A} \\right\\}$ is a set of first-countable spaces, then $X$ is first-countable. [7]: If $\\left\\{ X_{\\alpha} \\ | \\ \\alpha \\in \\mathscr{A} \\right\\}$ is a set of second-countable spaces, then $X$ is second-countable. [8]: If $\\mathscr{A}$ is a finite set, then the product topology and box topology of $X$ are the same. Explanation The reason why a complicated subbasis appears in the definition is mainly for the use of intersections, as the definition of basis does not allow anything other than unions.\nAccording to the definition of subbasis, the basis that is generated for the product topology by the subbasis $\\mathscr{S}$ is $$ \\left\\{ \\left. \\bigcap_{i=1}^{n} p_{\\alpha_{i} }^{-1} ( O_{ \\alpha_{i} } ) \\ \\right| \\ p_{\\alpha_{i} }^{-1} ( O_{ \\alpha_{i} } ) \\in \\mathscr{S} \\right\\} $$. Naturally, for the basis of the box topology $\\mathscr{B}$, $$ \\left\\{ \\left. \\bigcap_{i=1}^{n} p_{\\alpha_{i} }^{-1} ( O_{ \\alpha_{i} } ) \\ \\right| \\ p_{\\alpha_{i} }^{-1} ( O_{ \\alpha_{i} } ) \\in \\mathscr{S} \\right\\} \\subset \\mathscr{B} $$ holds. The fact that the elements of the box topology include those generated from the subbasis of the product topology means that the box topology has the same or more elements than the product topology, and thus the product topology is referred to as being smaller, coarser, or weaker.\nThe fact that theorem [8] holds is surprisingly rare. Remembering the fact \u0026rsquo;the box contains the product\u0026rsquo; helps in avoiding confusion. The fact that it touches upon dimensions not just finite or countably infinite, but arbitrary dimensions, is somewhat shocking.\nTopology for Non-Majors However, considering Cartesian products in topology is more interesting than any other field, whether it\u0026rsquo;s due to generalization over dimensions or multivariate analysis. But now, it feels closer to the popularly known topology.\nConsider the following spaces for $I := [0,1]$ and $S^{1} = \\left\\{ (x,y) \\in \\mathbb{R}^2 \\ | \\ x^2 + y^2 =1 \\right\\}$.\nFrom left to right, a square $I \\times I$, a cylinder $I \\times S^{1}$, and a torus $S^{1} \\times S^{1}$.\nStarting from one-point compactification, it has now become a kind of mathematics that gives a feeling of spaces being twisted and folded.\nSee Also Cartesian product of sets Cartesian product of groups Cartesian product of topological spaces Munkres. (2000). Topology(2nd Edition): p113~114.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":620,"permalink":"https://freshrimpsushi.github.io/en/posts/620/","tags":null,"title":"Cartesian Product of Topological Spaces"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 2 For groups $G_{1} , \\cdots , G_{n}$ and elements $\\displaystyle (a_{1},\\cdots , a_{n}), (b_{1} , \\cdots , b_{n} ) \\in \\prod_{i=1}^{n} G_{i}$ of their Cartesian product, $$ (a_{1},\\cdots , a_{n}) (b_{1} , \\cdots , b_{n} ) = (a_{1} b_{1},\\cdots , a_{n} b_{n}) $$ then $\\displaystyle \\prod_{i=1}^{n} G_{i}$ is called the Direct Product of $G_{1} , \\cdots , G_{n}$ groups. Especially, if $G_{1}, \\cdots , G_{n}$ is an abelian group, it is denoted by $\\displaystyle \\bigoplus_{i=1}^{n} G_{i}$ and also referred to as a Direct Sum. When $G_{1}$ is a subgroup of $G$, if there exists another subgroup $G_{2}$ of $G$ satisfying the following, $G_{1}$ is called a Direct Summand. $$ G = G_{1} \\oplus G_{2} $$ Properties Let\u0026rsquo;s state $G = G_{1} \\oplus G_{2}$. If $H_{1}$ is a subgroup of $G_{1}$, and $H_{2}$ is a subgroup of $G_{2}$, then $H_{1}$ and $H_{2}$ can also be represented as a direct sum, and in particular, the following holds: $$ {{ G } \\over { H_{1} \\oplus H_{2} }} \\simeq {{ G_{1} } \\over { H_{1} }} \\oplus {{ G_{2} } \\over { H_{2} }} $$\n[1]: If $H_{1} \\simeq G_{1}$ and $H_{2} \\simeq \\left\\{ 0 \\right\\}$ are set, $$ G / G_{1} \\simeq G_{2} $$ [2]: If $H_{1} \\simeq \\left\\{ 0 \\right\\}$ is set, $$ {{ G } \\over { H_{2} }} \\simeq G_{1} \\oplus {{ G_{2} } \\over { H_{2} }} $$ Explanation While vector spaces are groups with respect to addition, groups are not vector spaces, thus the direct sum in linear algebra does not exactly match. However, for comparison to have any meaning, it should at least be a ring.\nFor example, the Klein four-group satisfies $V \\simeq \\mathbb{Z}_{2} \\times \\mathbb{Z}_{2}$, and if $\\gcd (m , n) = 1$, then $\\mathbb{Z}_{m} \\times \\mathbb{Z}_{n} \\simeq \\mathbb{Z}_{mn}$ being a cyclic group is a known theorem.\nFree Group In terms of notation, for a free abelian group, it is convenient to express that it is isomorphic to the direct sum of the integer ring $\\mathbb{Z}$. For example, if $G$ is a free abelian group of rank $3$, $G$ could be represented as follows: $$ G \\simeq \\mathbb{Z} \\oplus \\mathbb{Z} \\oplus \\mathbb{Z} $$\nSee Also Direct Sum in Linear Algebra Cartesian Product of Sets Cartesian Product of Groups Cartesian Product of Topological Spaces Fraleigh. (2003). A first course in abstract algebra(7th Edition): p104~105.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMunkres. (1984). Elements of Algebraic Topology: p23~24.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":619,"permalink":"https://freshrimpsushi.github.io/en/posts/619/","tags":null,"title":"The Cartesian Product of Groups"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Summary[^1] Let\u0026rsquo;s call $\\Omega \\subset \\mathbb{R}^{n}$ an open set. If $1 \\le p \u0026lt; \\infty$ and $u, v \\in L^{p}(\\Omega)$, then\n$$ \\left\\| u + v \\right\\|_{p} \\le \\left\\| u \\right\\|_{p}+\\left\\| v \\right\\|_{p} $$\nThis is called the Minkowski inequality.\n","id":614,"permalink":"https://freshrimpsushi.github.io/en/posts/614/","tags":null,"title":"Proof of Minkowski's Inequality in Lebesgue Spaces"},{"categories":"Ïó¥Î¨ºÎ¶¨Ìïô","contents":"Definition1 2 Let\u0026rsquo;s assume there is a system with energy $E$. When the number of microstates for $E$ is denoted as $\\Omega (E) = \\Omega$, then\n$$ \\dfrac{1}{k_{B} T} := \\dfrac{d \\ln ( \\Omega )}{d E } $$\ndefines the temperature of the system as $T$, where $k_{B}$ is the Boltzmann constant.\nMicrostates and Macrostates In statistical mechanics, the concepts of a system\u0026rsquo;s Macrostate and Microstate could be similar to the following example. Suppose there are four coins inside a box. After shaking the box vigorously and opening it, the heads and tails will be determined randomly. When representing heads with white and tails with dark grey, their states can be depicted as follows:\nLooking only at the number of heads, there are a total of $5$ ways, from $0$ to $4$, and this is called the number of macrostates $S$. Meanwhile, if counting whether each coin is heads or tails, as known, there are $2^4=16$ ways, which is called the number of microstates $\\Omega$.\nNaturally, if the number of microstates $\\Omega$ is large, the corresponding macrostate is more likely to be observed. In the situation above, if designating the number of heads among $n$ coins as $\\Omega (k, n-k)$, the microstate number is largest when $\\Omega (2,2) = 6$, hence, the state with two heads and two tails is more likely to be observed.\nDerivation The definition of temperature naturally arises through finding the macrostate of two interacting systems. Consider a closed system $X$ as below.\n$X$ is divided into $A$ and $B$. Let\u0026rsquo;s call the internal energy of $A$ and $B$ as $E_{A}$ and $E_{B}$ respectively. Similar to the coin example above, imagine $A$ and $B$ as groups of specific coins, and $E_{A}$ and $E_{B}$ as the number of heads.\nAssuming that all microstates have equal probability and that $A$ and $B$ have interacted enough (or sufficient time has passed) to consider the two systems in thermal equilibrium. The total energy of the system is as $E_{X} = E_{A} + E_{B}$. The number of microstates of the total system $X$ is represented by the product of the possible microstates of $A$ $\\Omega (E_{A})$ and of $B$ $\\Omega (E_{B})$.\n$$ \\begin{equation} \\Omega_{X} (E_{X}) = \\Omega_{A} (E_{A}) \\Omega_{B} (E_{B}) \\end{equation} $$\nThen, it can naturally be accepted that the macrostate in thermal equilibrium is when the value of the above equation is at its largest. Actually, it is said that the number of possible microstates in a macrostate during thermal equilibrium overwhelmingly exceeds other cases. If considering the number of microstates $\\Omega$ as a normal distribution, naturally, the point where taking the derivative of $(1)$ becomes $0$ signifies the maximum value.\nHowever, in reality, the energy of particles is not continuous but quantumized. Therefore, the total energy of the system $E_{X}$ also has discrete values. But in the case of thermophysics, since the number of particles in the system being examined is extremely high, the possible values of $E_{X}$ are also enormously numerous. Hence, consider $E_{X}$, $E_{A}$, and $E_{B}$ as variables with continuous values.\nReturning to finding the macrostate, let\u0026rsquo;s designate the macrostate (energy) in thermal equilibrium as $\\overline{E} = \\overline{E}_{A} + \\overline{E}_{B}$. By taking the derivative of $(1)$ with respect to $E_{A}$ and substituting $E_{A}=\\overline{E}_{A}$, it results in $0$.\n$$ \\left. \\dfrac{d( \\Omega_{A} (E_{A} ) \\Omega_{B} (E_{B}) )}{dE_{A}} \\right|_{E_{A}=\\overline{E}_{A}} = 0 $$\nCalculating the above equation yields as follows by the product rule of differentiation.\n$$ \\Omega_{B} (E_{B}) \\left. \\dfrac{d \\Omega_{A} (E_{A} )}{d E_{A}} \\right|_{E_{A}=\\overline{E}_{A}} + \\Omega_{A} (E_{A}) \\left. \\dfrac{d \\Omega_{B} (E_{B} )}{d E_{B}} {{d E_{B} } \\over {d E_{A} }} \\right|_{E_{A}=\\overline{E}_{A}} = 0 $$\nHere, since the total energy $E_{X} = E_{A} + E_{B}$ remains a constant regardless of how energy transfers between $A$ and $B$, the following is established.\n$$ d E_{A} = - d E_{B} \\implies \\dfrac{d E_{B}}{d E_{A} } = -1 $$\nSubstituting into the above equation yields the following expression.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\Omega_{B} \\left. \\dfrac{ d \\Omega_{A} }{d E_{A}}\\right|_{E_{A}=\\overline{E}_{A}} - \\left. \\Omega_{A} \\dfrac{ d \\Omega_{B} }{d E_{B}}\\right|_{E_{B}=\\overline{E}_{B}} =\u0026amp; 0 \\\\ \\implies \u0026amp;\u0026amp; \\dfrac{1}{ \\Omega_{A} } \\left. \\dfrac{ d \\Omega_{A} }{d E_{A}}\\right|_{E_{A}=\\overline{E}_{A}} - \\dfrac{1}{\\Omega_{B} } \\left. \\dfrac{ d \\Omega_{B} }{d E_{B}} \\right|_{E_{B}=\\overline{E}_{B}} =\u0026amp; 0 \\\\ \\implies \u0026amp;\u0026amp; \\dfrac{1}{ \\Omega_{A} } \\left. \\dfrac{ d \\Omega_{A} }{d E_{A}} \\right|_{E_{A}=\\overline{E}_{A}} =\u0026amp; \\dfrac{1}{\\Omega_{B} } \\left. \\dfrac{ d \\Omega_{B} }{d E_{B}} \\right|_{E_{B}=\\overline{E}_{B}} \\\\ \\implies \u0026amp;\u0026amp; \\dfrac{ d \\ln \\Omega_{A} }{d E_{A}} \\left(\\overline{E}_{A}\\right) =\u0026amp; \\dfrac{ d \\ln \\Omega_{B} }{d E_{B}}\\left(\\overline{E}_{B}\\right) \\end{align*} $$\nThe last line is valid in accordance with logarithmic differentiation and the chain rule. Here, the above equation is a condition for thermal equilibrium, where the left-hand side is expressed solely in terms of the variables for system $A$, and the right-hand side in terms of the variables for system $B$. Since both sides of the equation in thermal equilibrium state represent the same value with each respective system\u0026rsquo;s state, defining temperature by this value would be appropriate. Hence, the temperature of $A$ and $B$ can be defined as $T_{A}$ and $T_{B}$, respectively.\n$$ \\begin{align*} \\dfrac{1}{k_{B} T_{A} } \u0026amp;:= \\dfrac{ d \\ln \\Omega _{A} }{d E_{A}} \\left(\\overline{E}_{A}\\right) \\\\ \\dfrac{1}{k_{B} T_{B} } \u0026amp;:= \\dfrac{ d \\ln \\Omega _{B} }{d E_{B}} \\left(\\overline{E}_{B}\\right) \\end{align*} $$\n‚ñ†\nStephen J. Blundell and Katherine M. Blundell, Concepts in Thermal Physics, translated by Ïù¥Ïû¨Ïö∞ (2nd Edition, 2014), p45-49\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nR. K. Pathria and Paul D. Beale, Statistical Mechanics (3rd Edition, 2011), p1-5\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":613,"permalink":"https://freshrimpsushi.github.io/en/posts/613/","tags":null,"title":"Definition of temperature in physicss"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Theorem1 Let us consider $\\Omega \\subset \\mathbb{R}^{n}$ as an open set. Suppose we\u0026rsquo;re given two constants $1 \\lt p \\lt \\infty, 1 \\lt p^{\\prime} \\lt \\infty$ satisfying the following equation.\n$$ \\dfrac{1}{p}+\\dfrac{1}{p^{\\prime}} = 1 \\left(\\text{or } p^{\\prime} = \\frac{p}{p-1} \\right) $$\nIf $u \\in L^p(\\Omega)$ and $v\\in L^{p^{\\prime}}(\\Omega)$, then $uv \\in L^1(\\Omega)$, and the inequality below holds.\n$$ \\| uv \\|_{1} = \\int_{\\Omega} |u(x)v(x)| dx \\le \\| u \\|_{p} \\| v \\|_{p^{\\prime}} $$\nThis inequality is known as H√∂lder\u0026rsquo;s inequality.\nExplanation $p^{\\prime}$ is known as the H√∂lder conjugate or conjugate exponent of $p$. It is often denoted as $q$.\nIf $| u(x) |^{p}$ and $| v(x) |^{p^{\\prime}}$ are proportional almost everywhere in $\\Omega$, equality holds.\nIt is essentially the same as H√∂lder\u0026rsquo;s inequality in Euclidean spaces, and it also becomes the Cauchy-Schwarz inequality when $p=p^{\\prime}=2$. The proof is no different than that of the Cauchy-Schwarz inequality, with the addition of Young\u0026rsquo;s inequality.\nIt can also be generalized in the following form.\n$$ \\| uv \\|_{r} = \\left( \\int_{\\Omega} |u(x)v(x)|^{r} dx \\right)^{1/r} \\le \\| u \\|_{p} \\| v\\|_{p^{\\prime}} $$\n$$ \\| u \\|_{r} = \\left( \\int_{\\Omega} |u(x)|^{r} dx \\right)^{1/r} \\le \\prod_{j=1}^{N} \\| u_{j} \\|_{{p}_j} = \\| u_{1} \\|_{{p}_1} \\cdots \\| u_{N} \\|_{p_{N}} $$\nProof Young\u0026rsquo;s Inequality\nGiven $\\dfrac{1}{p} + \\dfrac{1}{p^{\\prime}} = 1$ satisfies and for two constants greater than 1, $p, p^{\\prime}$, and two positive numbers $a,b$,\n$$ ab \\le { {a^{p}} \\over {p} } + {{b^{p^{\\prime}}} \\over {p^{\\prime}}} $$\nCase 1. $\\| u \\|_{p} = 0$ or $\\| v \\|_{p^{\\prime}} = 0$\nSince almost everywhere in $\\Omega$ is $u(x) = 0$ or almost everywhere in $\\Omega$ is $v(x) = 0$, almost everywhere in $\\Omega$ is $u(x)v(x) = 0$. Therefore,\n$$ \\left| \\int_{\\Omega} u(x) v(x) dx \\right| = \\| uv \\|_{1} = 0 $$\nand\n$$ \\| u \\|_{p} \\| v \\|_{p^{\\prime}} = 0 $$\nhence the inequality is satisfied.\nCase 2. Other cases\nBy substituting $a = \\dfrac{\\left| u(x) \\right|}{\\| u \\|_{p}}$ and $b = \\dfrac{\\left| v(x) \\right|}{\\| v \\|_{p^{\\prime}}}$ in Young\u0026rsquo;s inequality, we have\n$$ \\dfrac{\\left| u(x) \\right|}{\\| u \\|_{p}} \\dfrac{\\left| v(x) \\right|}{\\| v \\|_{p^{\\prime}}} \\le \\dfrac{ \\left| u(x) \\right|^{p}}{ p \\| u \\|_{p}^{p}} + \\dfrac{\\left| v(x) \\right|^{p^{\\prime}}}{ p^{\\prime} \\| v \\|_{p^{\\prime}}^{p^{\\prime}}} $$\nIntegrating both sides yields\n$$ \\begin{align*} \\dfrac{1}{\\| u \\|_{p} \\| v \\|_{p^{\\prime}}} \\int_{\\Omega}\\left| u(x)v(x) \\right| dx \\le \u0026amp; \\dfrac{1}{p \\| u \\|_{p}^{p}} \\int_{\\Omega} \\left| u(x) \\right|^{p} dx + \\dfrac{1}{ p^{\\prime} \\| v \\|_{p^{\\prime}}^{p^{\\prime}}} \\int_{\\Omega} \\left| v(x) \\right|^{p^{\\prime}} dx \\\\ \\le \u0026amp; \\dfrac{1}{p \\| u \\|_{p}^{p}} \\| u \\|_{p}^{p} + \\dfrac{1}{ p^{\\prime} \\| v \\|_{p^{\\prime}}^{p^{\\prime}}} \\| v \\|_{p^{\\prime}}^{p^{\\prime}} \\\\ \\le \u0026amp; \\dfrac{1}{p} + \\dfrac{1}{ p^{\\prime} } \\\\ =\u0026amp; 1 \\end{align*} $$\nMoving the constant to the left side gives\n$$ \\| uv \\|_{1} = \\int_{\\Omega} |u(x)v(x)| dx \\le \\| u \\|_{p} \\| v \\|_{p^{\\prime}} $$\nThus, $uv \\in L^{1}(\\Omega)$ holds, and the inequality is satisfied.\n‚ñ†\nSee also H√∂lder\u0026rsquo;s inequality in Euclidean spaces Generalized H√∂lder\u0026rsquo;s inequality Robert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p24-25\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":609,"permalink":"https://freshrimpsushi.github.io/en/posts/609/","tags":null,"title":"Proof of H√∂lder's Inequality in Lebesgue Spaces"},{"categories":"Ïó¥Î¨ºÎ¶¨Ìïô","contents":"Formulas The following equation is referred to as Stirling\u0026rsquo;s formula.\n$$ \\lim_{n \\to \\infty} {{n!} \\over {e^{n \\ln n - n} \\sqrt{ 2 \\pi n} }} = 1 $$\nDescription1 This approximation is useful in the aspect of calculating factorials for large numbers. In fields like thermodynamics and statistical mechanics, it\u0026rsquo;s essential to assume a large number of molecules,\n$$ \\begin{align*} n! \u0026amp;\\approx \\sqrt{2\\pi n}\\left( \\dfrac{n}{e} \\right)^{n} \\\\[0.6em] \\log_{2} n! \u0026amp;\\approx n \\log_{2} n - n \\log_{2}e \\\\[0.6em] \\ln n! \u0026amp;\\approx n \\ln n - n \\end{align*} $$\nand a more simplified expression like the one above is also used. The proof below is somewhat less rigorous analytically but is sufficient if one only emphasizes the facts for application.\nSee Also Mathematical Statistical Proof Rigorous Proof Derivation 2 Let\u0026rsquo;s start from the Gamma function $\\displaystyle n! = \\int_{0}^{\\infty} x^{n} e^{-x} dx$. If we set it as $f(x) = n \\ln x - x$, then the following formula holds.\n$$ e^{f(x)} = x^{n} e^{-x} $$\nGiven $\\displaystyle {{df(x)} \\over {dx}} = {{n } \\over {x }} - 1$ and $\\displaystyle {{d^2 f(x)} \\over {dx^2 }} = - {{n } \\over {x^2 }}$, and also $\\displaystyle {{d^3 f(x)} \\over {dx^3 }} = {{ 2n } \\over {x^3 }}$, the Taylor expansion of $f$ is as follows.\n$$ \\begin{align*} f(x) =\u0026amp; f(n) + f '(n) (x-n) + {{1} \\over {2!}} f ''(n) (x-n)^2 + {{1} \\over {3!}} f^{(3)} (n) (x-n)^3 + \\cdots \\\\ =\u0026amp; n \\ln n - n + 0 \\cdot (x-n) - {{1} \\over {2}} {{n} \\over{ n^2}} (x-n)^2 + {{1} \\over {6}} {{2n} \\over{ n^3}} (x-n)^3 + \\cdots \\\\ =\u0026amp; n \\ln n - n - {{ (x-n)^2 } \\over{ 2n }} + {{ (x-n)^3 } \\over{ 3 n^2 }} + \\cdots \\end{align*} $$\nWhen $n$ is sufficiently large, the terms following $\\displaystyle {{ (x-n)^2 } \\over{ 2 n }}$ can be ignored as the denominator increases too rapidly. Thus, the result below is obtained.\n$$ f(x) \\approx n \\ln n - n - {{ (x-n)^2 } \\over{ 2n }} $$\nFurthermore, if $n$ is significantly large, the integration of the Gaussian curve from $0$ to $\\infty$, and one from $-\\infty$ to $\\infty$, have no significant difference. Consequently, for a sufficiently large $n$, $$ n! = e^{n \\ln n - n} \\int_{0}^{\\infty} e^{-(x-n)^2 / 2n + \\cdots } dx \\approx e^{n \\ln n - n} \\int_{-\\infty}^{\\infty} e^{-(x-n)^2 / 2n } dx $$ by Gaussian integration, $\\displaystyle \\int_{-\\infty}^{\\infty} e^{-(x-n)^2 / 2n } dx = \\sqrt{ 2 \\pi n}$ holds, leading to the following formula.\n$$ n! \\approx e^{n \\ln n - n} \\sqrt{ 2 \\pi n} $$\nTaking the logarithm of both sides yields the formula below.\n$$ \\ln n! \\approx n \\ln n - n + \\dfrac{1}{2}\\ln 2\\pi n $$\nIf $n$ is very large, then the following approximation holds.\n$$ \\ln n! \\approx n \\ln n - n $$\n‚ñ†\nStephen J. Blundell and Katherine M. Blundell, Ïó¥ Î¨ºÎ¶¨Ìïô(Concepts in Thermal Physics, Ïù¥Ïû¨Ïö∞ Ïó≠) (2nd Edition, 2014), p12\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nStephen J. Blundell and Katherine M. Blundell, Ïó¥ Î¨ºÎ¶¨Ìïô(Concepts in Thermal Physics, Ïù¥Ïû¨Ïö∞ Ïó≠) (2nd Edition, 2014), p591-593\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":608,"permalink":"https://freshrimpsushi.github.io/en/posts/608/","tags":null,"title":"A Simple Derivation of the Stirling Formula"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Definition1 2 3 Let $\\Omega \\subset \\mathbb{R}^{n}$ be an open set, and $p$ be a positive real number.\nFor all measurable functions $f$ defined on $\\Omega$, define set $L^{p}(\\Omega)$ as follows.\n$$ L^{p}(\\Omega) := \\left\\{ f : \\int_{\\Omega} \\left| f(x) \\right|^{p} dx \u0026lt; \\infty \\right\\} $$\nThis is called the Lp space or Lebesgue space and is briefly denoted as $L^{p}$. Typically, textbooks on functional analysis describe it as above, while measure theory and real analysis textbooks describe it as follows.\nGiven a measure space $(X, \\mathcal{E}, \\mu)$, for measurable functions $f$ defined on $X$, define set $L^{p}(X, \\mathcal{E},\\mu)$ as follows.\n$$ L^{p}(X, \\mathcal{E}, \\mu) := \\left\\{ f : \\int \\left| f \\right|^{p} d \\mu \u0026lt; \\infty \\right\\} $$\nHere, $\\mu$ is the measure. It is simply denoted as $L^{p}(\\mu), L^{p}(X)$ and so on.\nProperties $L^{p}$ is a vector space. For $1 \\le p \\le \\infty$, $L^{p}$ is a normed space. $L^{p}$ is a complete space. For $E\\subset X$, if $1 \\le p \\le q \\le \\infty$ and $\\mu (E) \u0026lt; \\infty \\implies L^{q} (E) \\subset L^{p} (E)$ Explanation 2. If $p \\lt 1$, then $\\left\\| \\cdot \\right\\|_{p}$ does not satisfy the triangle inequality and is not a norm. However, if $p = \\infty$, then $L^{p}$ space becomes a normed space.\nA complete normed vector space is specifically called a Banach space. Therefore, $L^{p}$ space is a Banach space. $L^{p}$ is especially important as a space where the H√∂lder inequality and the Minkowski inequality hold.\nA vector space on which an inner product is defined is called an inner product space. A complete inner product space is specifically called a Hilbert space. For $L^{2}$ space, an inner product can be defined as follows.\n$$ \\left( \\int |f(x)|^2 dx\\right)^{\\frac{1}{2}} = \\left( \\int f(x)\\overline{f(x)}dx \\right) ^{\\frac{1}{2}} = \\langle f,f \\rangle ^{\\frac{1}{2}} $$\nTherefore, $L^{2}$ space is a Hilbert space.\n4. Let\u0026rsquo;s focus on the condition $\\mu (E) \u0026lt; \\infty$. If the integration range is not bounded, then $L^{1} (E)$ and $L^{2} (E)$ do not have any inclusion relation. For certain conditions that $1 \\le p \\lt q \\lt r$ meets, ${u \\in L^{p} \\cap L^{r} \\implies u \\in L^{q}}$ can also be satisfied.\nProof 2. For $1\\le p \u0026lt;\\infty$, define $\\| \\cdot \\|_{p}$ as follows.\n$$ \\left\\| f \\right\\|_{p} := \\left( \\int_{\\Omega} \\left| f(x) \\right|^{p} dx \\right)^{1/p},\\quad f\\in L^{p}(\\Omega) $$\nThen $\\| \\cdot \\|_{p}$ becomes the norm of $L^{p}$ space. (When $0\u0026lt;p\u0026lt;1$, it does not become a norm.) It is obvious that $\\| f \\|_{p} \\ge 0$, and it is also obvious that $\\| f \\|_{p}=0 \\iff f=0$. It can also be shown that for $c \\in \\mathbb{C}$, $\\| cf \\|_{p} = \\left| c \\right| \\left\\| f \\right\\|_{p}$ holds as follows.\n$$ \\begin{align*} \\left\\| cf \\right\\|_{p} =\u0026amp; \\left( \\int_{\\Omega} \\left| cf(x) \\right|^{p} dx \\right)^{1/p} \\\\ =\u0026amp; \\left( \\left| c \\right|^{p} \\int_{\\Omega} \\left| f(x) \\right|^{p} dx \\right)^{1/p} \\\\ =\u0026amp; \\left| c \\right| \\left( \\int_{\\Omega} \\left| f(x) \\right|^{p} dx \\right)^{1/p} \\\\ =\u0026amp; \\left| c \\right| \\left\\| f \\right\\|_{p} \\end{align*} $$\nFor $f,g \\in L^{p}$, $\\left\\| f + g \\right\\|_{p} \\le \\| f \\|_{p} + \\| g \\|_{p}$ also holds, and this is known as the Minkowski inequality.\n‚ñ†\n3. Strategy: Almost everything is solved by Fatou\u0026rsquo;s lemma.\nGiven a Cauchy sequence $f_{n}$, a subsequence $f_{n_{k}}$ that satisfies $\\left\\| f_{n} - f_{n_{k}} \\right\\|_{p} \u0026lt; \\dfrac{1}{2^{k}}$ can be found. For all $k \\in \\mathbb{N}$,\n$$ \\begin{align*} g_{k} :=\u0026amp; \\sum_{i=1}^{k} \\left| f_{n_{i+1}} - f_{n_{i}} \\right| \\\\ g :=\u0026amp; \\lim_{k \\to \\infty} g_{k} = \\sum_{i=1}^{\\infty} \\left| f_{n_{i+1}} - f_{n_{i}} \\right| \\end{align*} $$\nby defining it, the triangle inequality provides\n$$ \\left\\| g_{k} \\right\\|_{p} \\le \\sum_{i}^{k} \\dfrac{1}{2^{i}} \u0026lt; 1 $$\nFatou\u0026rsquo;s Lemma\nFor a sequence of non-negative measurable functions $\\left\\{ f_{n} \\right\\}$,\n$$ \\int \\left( \\liminf_{n \\to \\infty} f_{n} \\right) d \\mu \\le \\liminf_{n \\to \\infty} \\int f_{n} d \\mu $$\nAccording to Fatou\u0026rsquo;s lemma,\n$$ \\left\\| g \\right\\|_{p}^{p} \\le \\int \\lim_{n \\to \\infty} g_{k}^{p} d \\mu \\le \\liminf_{k \\to \\infty} \\int g_{k}^{p} d \\mu \\le 1 $$\nSince $g$ is finite almost everywhere,\n$$ f_{n_{k}} = f_{n_{1}}(x) + \\sum_{i=1}^{ k } \\left[ f_{n_{i}} (x) - f_{n_{i-1}} (x) \\right] $$\nconverges almost everywhere. If we define $f := \\lim\\limits_{k \\to \\infty} f_{n_{k}}$, then by Fatou\u0026rsquo;s lemma,\n$$ \\left\\| f - f_{m} \\right\\|_{p} = \\int |f - f_{m}|^{p} d \\mu \\le \\liminf_{k \\to \\infty} \\int | f_{n_{k}} - f_{m}|^{p} d \\mu \\le \\varepsilon^{p} $$\nTherefore, $f - f_{m} \\in L^{p}$ and $f = f_{m} + (f - f_{m} ) \\in L^{p}$. Since every Cauchy sequence in $L^{p}$ converges to an element in $L^{p}$, $L^{p}$ is a complete space.\n‚ñ†\n4. Strategy: Showing the inequality $|f(x)|^{p} \\le 1 + |f(x)|^{q}$ is sufficient; the rest follows from the properties of Lebesgue integration.\nLet\u0026rsquo;s assume $f \\in L^{q}$. Then the following equation holds.\n$$ \\begin{align*} | f(x) | \\le 1 \\implies\u0026amp; |f(x) |^{p} \\le 1 \\\\ 1 \\le |f(x)| \\implies\u0026amp; |f(x)|^{p} \\le |f(x)|^{q} \\end{align*} $$\nHence, whether $| f(x) |$ is larger or smaller than $1$, the following holds.\n$$ |f(x)|^{p} \\le 1 + |f(x)|^{q} $$\nTaking the Lebesgue integral $\\displaystyle \\int_{E} d \\mu$ results in\n$$ \\int_{E} |f|^{p} d \\mu \\le \\int_{E} 1 d \\mu + \\int_{E} |f|^{q} d \\mu = m(E) + \\int_{E} |f|^{q} d \\mu \u0026lt; \\infty $$\nSince $m(E) \u0026lt; \\infty$ and $\\displaystyle \\int_{E} |f|^{q} d \\mu \u0026lt; \\infty$, the following holds.\n$$ \\int_{E} |f|^{p} d \\mu \u0026lt; \\infty $$\nIn other words, since $f \\in L^{q} \\implies f \\in L^{p}$,\n$$ L^{q} (E) \\subset L^{p} (E) $$\n‚ñ†\nSee Also $L^{1}$ space $L^{2}$ space Hilbert space Capinski, Measure, Integral and Probability (1999), p140\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRobert A. Adams and John J. F. Foutnier, Sobolev Space (2nd Edition, 2003), p23\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGerald B. Folland, Real Analysis: Modern Techniques and Their Applications (2nd Edition, 1999), p181\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":605,"permalink":"https://freshrimpsushi.github.io/en/posts/605/","tags":null,"title":"Lp Spaces, Lebesgue Spaces"},{"categories":"Ïó¥Î¨ºÎ¶¨Ìïô","contents":"Formulas1 Let\u0026rsquo;s denote the number of molecules of a gas as $N$, volume as $V$, pressure as $p$, and absolute temperature as $T$. Then, the following equation holds, and this is called the ideal gas equation.\n$$ pV = N k_{B} T $$\nHere, $k_{B} = 1.3807 \\times 10^{-23} J / K$ is called the Boltzmann constant.\nDescription Historically, it was derived from experimental laws and later derived mathematically from kinetic theory of gases. It is called the \u0026lsquo;ideal gas\u0026rsquo; equation because the following assumptions were made in the process of deriving the equation.\nThere are no forces acting between each molecule. In other words, they do not attract each other. Each molecule is a point particle with no size. In reality, molecules interact with each other and have size, but for the sake of simplicity of the theory, these assumptions are made. Just as Newtonian mechanics can explain many phenomena well without considering relativity on the surface of the earth, the ideal gas equation also well describes actual gases. An actual gas becomes closer to an ideal gas as the molecular weight of the system decreases, the temperature increases, and the pressure decreases.\nThe ideal gas equation does not explain all gas phenomena. When relativistic effects need to be considered, a relativistic gas model should be used, and when quantum effects need to be considered, a quantum gas model should be used.\nThe constant in the ideal gas equation can be expressed in the form of $pV = nRT$ with respect to the amount of substance $n$. Here, $R$ is called the gas constant, which is almost equally used in thermodynamics in the form.\nDerivation $$ p \\propto \\dfrac{1}{V} $$\nAt a constant temperature, the relationship between the pressure and volume of a gas is established, and this is called Boyle\u0026rsquo;s law. Later, independently of Boyle, Edme Mariotte also discovered the same fact, which is also called Boyle-Mariotte\u0026rsquo;s law.\n$$ V \\propto T $$\nAt a constant pressure, the relationship between the volume and temperature of a gas is established, and this is called Charles\u0026rsquo; law.\n$$ p \\propto T $$\nWhen the volume of a gas is constant, the relationship between temperature and pressure is established, and this is called Gay-Lussac\u0026rsquo;s law. From the three proportionalities above, the next equation is obtained.\n$$ p^{2}V \\propto T^{2}/V \\implies p^{2}V^{2} \\propto T^{2} \\implies pV \\propto T $$\nIf the proportionality constant is denoted as $Nk_{B}$, the following result is obtained.\n$$ pV = Nk_{B}T $$\nStephen J. Blundell and Katherine M. Blundell, Concepts in Thermal Physics(Concepts in Thermal Physics, translated by Jae-woo Lee) (2nd Edition, 2014), p8-10\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":602,"permalink":"https://freshrimpsushi.github.io/en/posts/602/","tags":null,"title":"Ideal Gas Equation"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Buildup The general definition of the inner product is as follows:\nLet $H$ be a vector space. For $x,y,z \\in H$ and $\\alpha, \\beta \\in \\mathbb{C}$, a function that satisfies the following conditions\n$$ \\langle \\cdot , \\cdot \\rangle \\ : \\ H \\times H \\to \\mathbb{C} $$\nis defined as an inner product, and $\\left( H, \\langle \\cdot ,\\cdot \\rangle \\right)$ is called an inner product space.\nLinearity: $\\langle \\alpha x + \\beta y ,z \\rangle =\\alpha \\langle x,z\\rangle + \\beta \\langle y,z\\rangle$ Conjugate Symmetry: $\\langle x,y \\rangle = \\overline{ \\langle y,x \\rangle}$ Positive-definiteness: $\\langle x,x \\rangle \\ge 0 \\quad \\text{and} \\quad \\langle x,x \\rangle = 0\\iff x=0$ Especially, the inner product in the function space is defined using a definite integral as follows:\n$$ \\langle f, g \\rangle := \\int_{a}^{b} f(x) g(x) dx $$\nIt is easy to show that $\\langle , \\rangle$ becomes an inner product by this definition, but why it is defined in this way might be hard to understand. It feels quite detached from the definition of the inner product in Euclidean space, which is the sum of the products of corresponding elements, and it also doesn\u0026rsquo;t seem practical at all. However, these definitions are not only natural but also beautifully fit together as one learns more about functional analysis.\nExample Let\u0026rsquo;s understand through an example:\nConsider two vectors $\\mathbf{f} = ( {\\color{blue} 1} , {\\color{orange} 5} , 0 , {\\color{purple} 4} , {\\color{red} 2} , {\\color{Green} 1} )$ and $\\mathbf{g} = ( {\\color{blue} 9} , {\\color{orange} 6} , 0 , {\\color{purple} 1} , {\\color{red} 2} , {\\color{Green} 5} )$. Calculating the inner product gives\n$$ \\mathbf{f} \\cdot \\mathbf{g} = {\\color{blue} 1 \\cdot 9 } + {\\color{orange} 5 \\cdot 6} + 0 \\cdot 0+ {\\color{purple} 4 \\cdot 1 } + {\\color{red} 2 \\cdot 2 } + {\\color{Green} 1 \\cdot 5} = 52 $$\nIf we represent the size of each component of the vector with a bar graph, it looks like this.\nConsidering two functions defined to make the shapes in the bar graph above from $[-3,3]$\n$$ f(x) := \\begin{cases} 1 \u0026amp; , -3 \\le x \\le -2 \\\\ 5 \u0026amp; , -2 \\le x \u0026lt; -1 \\\\ 0 \u0026amp; , -1 \\le x \\le 0 \\\\ 4 \u0026amp; , 0 \\le x \u0026lt; 1 \\\\ 2 \u0026amp; , 1 \\le x \u0026lt; 2 \\\\ 1 \u0026amp; , 2 \\le x \\le 3 \\end{cases} $$\n$$ g(x) := \\begin{cases} 9 \u0026amp; , -3 \\le x \\le -2 \\\\ 6 \u0026amp; , -2 \\le x \u0026lt; -1 \\\\ 0 \u0026amp; , -1 \\le x \\le 0 \\\\ 1 \u0026amp; , 0 \\le x \u0026lt; 1 \\\\ 2 \u0026amp; , 1 \\le x \u0026lt; 2 \\\\ 5 \u0026amp; , 2 \\le x \\le 3 \\end{cases} $$\nThen,\n$$ f(x) g(x) = \\begin{cases} 9 \u0026amp; , -3 \\le x \\le -2 \\\\ 30 \u0026amp; , -2 \\le x \u0026lt; -1 \\\\ 0 \u0026amp; , -1 \\le x \\le 0 \\\\ 4 \u0026amp; , 0 \\le x \u0026lt; 1 \\\\ 4 \u0026amp; , 1 \\le x \u0026lt; 2 \\\\ 5 \u0026amp; , 2 \\le x \\le 3 \\end{cases} $$\ntherefore, it is $\\displaystyle \\int_{-3}^{3} f(x) g(x) dx = 52$ and amazingly matches with $\\mathbf{f} \\cdot \\mathbf{g}$.\nOf course, not all functions are conveniently like this, but if it\u0026rsquo;s an integrable function, the idea of Riemann sums can be applied. Since the definite integral itself includes dividing, multiplying, and adding, there is nothing lacking in calling it an \u0026lsquo;inner product\u0026rsquo;. The inner product of functions can be seen as a generalization of the inner product of finite-dimensional vectors to infinite dimensions, emphatically covered by the conventional concept of inner product.\n","id":599,"permalink":"https://freshrimpsushi.github.io/en/posts/599/","tags":null,"title":"Reason for Defining the Inner Product of Functions via Definite Integration"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Definition 1 A function space $L^{2}$ is defined as follows.\n$$ L^{2} (E) := \\left\\{ f : \\left( \\int_{E} | f |^2 dm \\right)^{{1} \\over {2}} \u0026lt; \\infty \\right\\} $$\nProperties $L^{2}$ is a metric space. The metric is defined as following. $$ d(f,g) := \\left( \\int \\left| f(x) - g(x) \\right|^{2}dx \\right)^{\\frac{1}{2}} = \\left\\| f-g \\right\\|_{2} = \\sqrt{\\braket{f-g, f-g}} $$ $L^{2}$ is a vector space. $L^{2}$ is a normed space. The norm is defined as following. $$ \\left\\| f \\right\\|_{2} := \\left( \\int \\left| f(x) \\right|^{2}dx \\right)^{\\frac{1}{2}} = \\sqrt{\\braket{f,f}} $$ $L^{2}$ is a complete space. $L^{2}$ is an inner product space. The inner product is defined as following. $$ \\braket{f, g} := \\int \\overline{f(x)}g(x)dx $$ Description The space $L^{2}$ is a special case when it is $p=2$ of the $L^{p}$ space, and it is the only space among $L^{p}$ spaces where an inner product is defined. A complete inner product space is specifically called a Hilbert space. Therefore, $L^{2}$ is a Hilbert space. Hilbert spaces are important spaces that appear in various fields including partial differential equations and quantum mechanics.\nFor a generalized proof about $L^{p}$ space, refer here.\nProof 3. Definition of Norm\nLet\u0026rsquo;s call $V$ a vector space on $\\mathbb{F}$. If a function $\\left\\| \\cdot \\right\\| : V \\to \\mathbb{F}$ satisfies the following three conditions for $\\mathbf{u}, \\mathbf{v} \\in V$ and $k \\in \\mathbb{F}$, then it is defined as the norm on $V$.\nPositivity: $\\left\\| \\mathbf{u} \\right\\| \\ge 0$ and $\\mathbf{u} = \\mathbb{0} \\iff \\left\\| \\mathbf{u} \\right\\| = 0$ Homogeneity: $\\left\\|k \\mathbf{u} \\right\\| = | k | \\left\\| \\mathbf{u} \\right\\| $ Triangle inequality: $\\left\\| \\mathbf{u} + \\mathbf{v}\\right\\| \\le \\left\\|\\mathbf{v} \\right\\| + \\left\\| \\mathbf{u} \\right\\|$ Let\u0026rsquo;s define the norm of $L ^{2}$ as follows $\\displaystyle \\left\\| f \\right\\|_{2} := \\left( \\int_{E} | f |^2 dm \\right)^{{1} \\over {2}}$.\nPart 1. Positivity\nSince $| f | \\ge 0$, if $\\left\\| f \\right\\|_{2} \\ge 0$ almost everywhere, then $\\left\\| f \\right\\|_{2} = 0$. Conversely, if $\\left\\| f \\right\\|_{2} = 0$, then almost everywhere, it must be $f = 0$.\nPart 2. Homogeneity\n$$ \\left\\| c f \\right\\|_{2} = \\left( \\int_{E} | c f |^2 dm \\right)^{{1}\\over {2}} =\\left( |c|^2 \\int_{E} | f |^2 dm \\right)^{{1}\\over {2}} = |c| \\left( \\int_{E} | f |^2 dm \\right)^{{1}\\over {2}} = |c| \\left\\| f\\right\\|_{2} $$\nPart 3. Triangle inequality\n$$ \\begin{align*} \\left\\| f + g \\right\\|_{2}^{2} =\u0026amp; \\int_{E} | f + g |^2 dm \\\\ =\u0026amp; \\int_{E} ( f + g ) \\overline{( f + g )} dm \\\\ =\u0026amp; \\int_{E} | f |^2 dm + \\int_{E} ( f \\overline{g} + \\overline{f} g ) dm +\\int_{E} | g |^2 dm \\end{align*} $$\nBy the Cauchy-Schwarz inequality, we get the following.\n$$ \\begin{align*} \\int_{E} ( f \\overline{g} + \\overline{f} g ) dm \\le \u0026amp; 2 \\int_{E} | fg | dm \\le 2 | f |_{2} | g |_{2} \\\\ =\u0026amp; | f + g | _{2}^{2} \\le | f | _{2} + 2 | f | _{2} | g | _{2} + | g | _{2} \\\\ =\u0026amp; \\left( | f |_{2} + | g |_{2} \\right)^{2} \\end{align*} $$\nTo summarize\n$$ \\left\\| f + g \\right\\|_{2} \\le \\left\\| f \\right\\|_{2} + | g |_{2} $$\n‚ñ†\n5. Definition of Inner Product\nLet us call $H$ a vector space. A function that satisfies the following conditions for $x,y,z \\in H$ and $\\alpha, \\beta \\in \\mathbb{C}$\n$$ \\langle \\cdot , \\cdot \\rangle : H \\times H \\to \\mathbb{C} $$\nis defined as inner product, and $\\left( H, \\langle \\cdot ,\\cdot \\rangle \\right)$ is called an inner product space.\nLinearity: $\\langle \\alpha x + \\beta y ,z \\rangle =\\alpha \\langle x,z\\rangle + \\beta \\langle y,z\\rangle$ Conjugate Symmetry: $\\langle x,y \\rangle = \\overline{ \\langle y,x \\rangle}$ Positive-definiteness: $\\langle x,x \\rangle \\ge 0 \\quad \\text{and} \\quad \\langle x,x \\rangle = 0\\iff x=0$ Let\u0026rsquo;s define the inner product of $L ^{2}$ as follows $\\displaystyle \\langle f , g \\rangle := \\int_{E} f \\overline{g} dm$.\nPart 1. Linearity\n$$ \\langle f + g , h \\rangle = \\int_{E} ( f + g ) \\overline{g} dm = \\int_{E} f \\overline{g} dm + \\int_{E} g \\overline{g} dm = \\langle f , h \\rangle + \\langle g , h \\rangle $$\nAnd\n$$ \\langle c f , g \\rangle = \\int_{E} c f \\overline{g} dm = c \\int_{E} f \\overline{g} dm = c \\langle f , g \\rangle $$\nPart 2. Conjugate Symmetry\n$$ \\langle f , g \\rangle = \\int_{E} f \\overline{g} dm = \\overline{ \\int_{E} \\overline{f} g dm} = \\overline{ \\int_{E} g \\overline{f} dm} = \\overline{ \\langle f , g \\rangle } $$\nPart 3. Positive-definiteness\n$$ \\langle f, f \\rangle = \\int_{E} f \\overline{f} dm = \\int_{E} | f |^2 dm = \\sqrt{ | f |_{2} } $$\nThe proof concludes with Part 1 of Property 3..\n‚ñ†\nSee Also $L^{p}$ space $L^{1}$ space Hilbert space Capinski. (1999). Measure, Integral and Probability: p131.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":594,"permalink":"https://freshrimpsushi.github.io/en/posts/594/","tags":null,"title":"L2 Space"},{"categories":"Î•¥Î≤°Í≥µÍ∞Ñ","contents":"Definition1 A function space $L^{1}$ is defined as follows.\n$$ L^{1} (E) := \\left\\{ f : E \\to \\mathbb{R} \\Big \\vert \\int_{E} | f | dm \\lt \\infty \\right\\} $$\nProperties $L^{1}$ is a vector space. $L^{1}$ is a normed space. The norm is defined as follows: $$ \\left\\| f \\right\\|_{1} := \\int \\left| f(x) \\right| dx $$ $L^{1}$ is a complete space. Explanation Space $L^{1}$ is a special case when it is the $p=1$ of the $L^{p}$ space, and has been defined as a collection of integrable functions when talking about Lebesgue integrability.\nGeneralized proofs for the $L^{p}$ space can be found here.\nProof 2. Definition of Norm\nLet\u0026rsquo;s say $V$ in $\\mathbb{F}$ is a vector space. If a function $\\left\\| \\cdot \\right\\| : V \\to \\mathbb{F}$ satisfies the following three conditions for $\\mathbf{u}, \\mathbf{v} \\in V$ and $k \\in \\mathbb{F}$, then $\\left\\| \\cdot \\right\\|$ is defined as the norm on $V$.\nPositive definiteness: $\\left\\| \\mathbf{u} \\right\\| \\ge 0$ and $\\mathbf{u} = \\mathbb{0} \\iff \\left\\| \\mathbf{u} \\right\\| = 0$ Homogeneity: $\\left\\|k \\mathbf{u} \\right\\| = | k | \\left\\| \\mathbf{u} \\right\\| $ Triangle inequality: $\\left\\| \\mathbf{u} + \\mathbf{v}\\right\\| \\le \\left\\|\\mathbf{v} \\right\\| + \\left\\| \\mathbf{u} \\right\\|$ Let\u0026rsquo;s define the norm of $L ^{1}$ as $\\displaystyle \\left\\| f \\right\\|_{1} := \\int_{E} |f| dm$.\nPart 1. Positive Definiteness\nSince $| f | \\ge 0$, if $f = 0$ almost everywhere then $\\left\\| f \\right\\|_{1} = 0$. Conversely, if $\\left\\| f \\right\\|_{1} = 0$ then almost everywhere must be $f = 0$.\nPart 2. Homogeneity\n$$\\left\\| c f \\right\\| _{1} = \\int_{E} | c f | dm = |c| \\int_{E} | f | dm = |c| \\left\\| f \\right\\| _{1}$$\nPart 3. Triangle Inequality\n$$ \\left\\| f + g \\right\\|_{1} = \\int_{E} | f + g | dm \\le \\int_{E} | f | dm + \\int_{E} | g | dm = \\left\\| f\\right\\|_{1} + \\left\\| g\\right\\|_{1} $$\n‚ñ†\n3. Completeness\nLet\u0026rsquo;s assume that the norm $\\left\\| \\cdot \\right\\|_{X}$ is defined in the vector space $X$. If for every $\\varepsilon \u0026gt; 0$ $$n, m \\ge N \\implies \\left\\| f_{n} - f_{m} \\right\\|_{X} \\lt \\varepsilon$$ If there exists a $N \\in \\mathbb{N}$ satisfying this, then the sequence $f_{n} \\in X$ is called a Cauchy sequence. If every Cauchy sequence converges to an element of $X$, then $X$ is called complete.\nIf $f_{n} \\in L^{1}$ is a Cauchy sequence,\n$$ \\left\\| f_{n} - f_{N_{1}} \\right\\|_{1} \\lt {{1} \\over {2}} $$\n$N_{1}$ can be found that satisfies this, and similarly,\n$$ \\left\\| f_{n} - f_{N_{2}} \\right\\|_{1} \\lt {{1} \\over {2^2}} $$\n$N_{2} \u0026gt; N_{1}$ can be found that satisfies this. In this way, $$ \\left\\| f_{n} - f_{N_{n}} \\right\\|_{1} \\lt {{1} \\over {2^n}} $$ $N_{n} \u0026gt; N_{n-1}$ can be found that satisfies this. By the triangle inequality, $$ \\left\\| f_{N_{n}} - f_{N_{n-1}} \\right\\|_{1} \\lt \\left\\| f_{N_{n}} - f_{n} \\right\\|_{1} + \\left\\| f_{n} - f_{N_{n-1}} \\right\\|_{1} \\lt {{1} \\over {2^n}} + {{1} \\over {2^{n-1}}} \\lt {{3} \\over {2^{n}}} $$\nLevi\u0026rsquo;s Theorem\nIf $\\displaystyle \\sum_{k=1}^{\\infty} \\int |f_{k}| dm \\lt \\infty$ then $\\displaystyle \\sum_{k=1}^{\\infty} f_{k} (x)$ converges almost everywhere and the following holds:\n$$ \\int \\sum_{k=1}^{\\infty} f_{k} dm = \\sum_{k=1}^{\\infty} \\int f_{k} dm $$\nBy Levi\u0026rsquo;s Theorem, $\\displaystyle \\sum_{n=1}^{\\infty} | f_{N_{n}} - f_{N_{n-1}} |_{1}$ converges. Therefore, the following converges almost everywhere.\n$$ f_{N_{1}}(x) + \\sum_{n=2}^{ k } \\left[ f_{N_{n}} (x) - f_{N_{n-1}} (x) \\right] = f_{N_{k}} $$\nIf the right side converges to $f(x)$, then the right side\u0026rsquo;s $f_{N_{k}} (x)$ also converges to $f(x)$.\nFatou\u0026rsquo;s Lemma\nFor a sequence of non-negative measurable functions $\\left\\{ f_{n} \\right\\}$,\n$$ \\displaystyle \\int_{E} \\left( \\liminf_{n \\to \\infty} f_{n} \\right) dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm $$\nBy Fatou\u0026rsquo;s Lemma,\n$$ \\begin{align*} \\left\\| f - f_{n} \\right\\|_{1} =\u0026amp; \\int |f - f_{n}| dm \\\\ \\le \u0026amp; \\liminf_{k \\to \\infty} \\int | f_{N_{k}} - f_{n}| dm \\\\ =\u0026amp; \\liminf_{k \\to \\infty} \\left\\| f_{N_{k}} - f_{n} \\right\\| \\\\ \\lt\u0026amp; \\varepsilon \\end{align*} $$\nSince $f_{n}$ is a Cauchy sequence, the above inequality holds for any $\\varepsilon \u0026gt; 0$, hence $\\left\\| f_{n} - f \\right\\|_{1} \\to 0$ is obtained. In short, since $f_{n}$ is Cauchy and a subsequence converges to $f$, $f_{n}$ converges to $f$. Here, since $f - f_{n} \\in L^{1}$ and $L^{1}$ is a vector space,\n$$ ( f - f_{n} ) + f_{n} = f \\in L^{1} $$\nAll Cauchy sequences in $L^{1}$ converge to an element of $L^{1}$, hence $L^{1}$ is a complete space.\n‚ñ†\nSee Also $L^{p}$ space $L^{2}$ space Capinski. (1999). Measure, Integral and Probability: p127.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":592,"permalink":"https://freshrimpsushi.github.io/en/posts/592/","tags":null,"title":"L1 Space"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 A subset $H$ of a group $G$ is called a subgroup of $G$ if $H$ itself is a group under the operation of $G$.\nTheorem Subgroup Test: For a non-empty subset $H$ of a group $G$, if for every element $a,\\ b$ in $H$, $ab^{-1}$ is also an element of $H$, then $H$ is a subgroup of $G$. In other words, if whenever $a,\\ b$ is in $H$, $a-b$ is also in $H$, then $H$ is a subgroup.\nProof Assume that whenever $a,\\ b$ is an element of $H$, $ab^{-1}$ is also an element of $H$. We need to verify whether $H$ satisfies the three conditions to be a group.\nThe operation of $H$ being the same as that of $G$, associativity is trivially satisfied. Let\u0026rsquo;s assume $a=x,\\ b=x$. Then $ab^{-1}=xx^{-1}=e$ and by assumption, it\u0026rsquo;s an element of $H$, which means $H$ has an identity element. Assume $a=e,\\ b=x$. Then $ex^{-1}=x^{-1}$ and by assumption, it becomes an element of $H$, which means any element $b$ in $H$ has an inverse. By 3, having verified that every element has an inverse, assume $a=x,\\ b=-y$. Then $x(y^{-1})^{-1}=xy$ and by assumption, it becomes an element of $H$, which means $H$ is closed under the operation. By points 1-4, since $H$ is closed under the operation of $G$, satisfies associativity, has an identity element, and every element has an inverse, it is a group. Therefore, the subset $H$ is a subgroup of the group $G$.\n‚ñ†\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p50.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":589,"permalink":"https://freshrimpsushi.github.io/en/posts/589/","tags":null,"title":"Definition and Test Method of Subgroups"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 If every infinite subset of a topological space $X$ has its limit point in $X$, then $X$ is said to have the Bolzano-Weierstrass property or to be compactly accumulating points.\nTheorem [1]: Every compact space is a compactly accumulating points space. [2]: If $X$ is a metric space, then $X$ being compact is equivalent to being compactly accumulating points. $X$ is a metric space, then it being compact is equivalent to it being compactly accumulating points. Description For example, $[a,b]$ is compactly accumulating points, but $(a,b)$ is not. Also, if we consider an infinite subset like with $$ P = \\left\\{ 3 , 3.1 , 3.14 , 3.141, 3.1415, \\cdots \\right\\} $$, because of $\\pi \\notin P$, it is not compactly accumulating points. $\\mathbb{R}$, having such subsets, is naturally not compactly accumulating points.\nInterestingly, despite the name, the definition doesn‚Äôt mention compactness at all. Just from the name, one might think it\u0026rsquo;s a special case of compact spaces, but in fact, only the opposite theorem [1] holds true.\nAnother significance of compactly accumulating points is theorem [2], which can be useful in proving some metric space is compact. Proving a metric space is compact ensures the uniform continuity of continuous functions, which goes without saying is beneficial.\nMunkres. (2000). Topology(2nd Edition): p178.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":576,"permalink":"https://freshrimpsushi.github.io/en/posts/576/","tags":null,"title":"Bolzano-Weierstrass Property and Compactness of Accumulation Points"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Definition Let\u0026rsquo;s assume we have a model for distinguishing between positive $P$ and negative $N$ in a classification problem. We define the number of positives correctly predicted as true positives $TP$, the number of negatives correctly predicted as true negatives $TN$, the number of positives incorrectly predicted as negatives as false negatives $FN$, and the number of negatives incorrectly predicted as positives as false positives $FP$.\nConfusion Matrix In classification problems, the Confusion Matrix is used as a metric to evaluate the model as shown above.\nAccuracy $$ \\text{Accuracy} = {{TP + TN} \\over { P + N }} $$ In the table above, P represents positive, and N represents negative. TP is the case predicted positive and actually positive, TN is the case predicted negative and actually negative. It is common sense and reasonable to assess models with relatively high TP and TN as good models. On the other hand, where there is \u0026lsquo;correct\u0026rsquo;, there must also be \u0026lsquo;incorrect\u0026rsquo;. The Error Rate is defined as follows. $$ \\text{Error Rate} = 1 - \\text{Accuracy} = {{FP + FN} \\over {N + P}} $$\nPrecision $$ \\text{Precision} = {{TP } \\over {TP + FP}} $$ Precision is the ratio of those actually true among those predicted as true. Be careful not to confuse it with Accuracy.\nSensitivity $$ \\text{Sensitivity} = \\text{True Positive Rate} = \\text{Recall} = {{TP } \\over { P }} $$ Sensitivity is the ratio of those predicted as true among the positives, also known as Recall or True Positive Rate.\nSpecificity $$ \\text{Specificity} = 1 - \\text{False Positive Rate} = 1- {{FP } \\over { N }} = {{TN } \\over {N }} $$ Specificity is the ratio of those predicted as false among the negatives.\nHere, a graph with False Positive Rate and True Positive Rate as axes is referred to as the ROC curve.\nSee Also Confusion Matrix, Sensitivity, and Specificity $F_{1}$ Score Situations Where Accuracy is Overrated in Data Science Precision Recall ","id":571,"permalink":"https://freshrimpsushi.github.io/en/posts/571/","tags":null,"title":"Confusion Matrix, Sensitivity, and Specificity"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Theorem 1 For a compact space $X$, if a function $f : X \\to \\mathbb{R}$ is continuous, then for every $x \\in X$, there exists a $c,d \\in X$ that satisfies $f(c) \\le f(x) \\le f(d)$.\nExplanation In $\\mathbb{R}$, being compact is equivalent to being a closed interval $[a,b]$, so ultimately this generalizes the theorem we learned in high school and analysis. As much as it uses the difficult theories of topology, the proof is relatively simple and easy.\nProof Auxiliary lemma for compact spaces: Let $f : X \\to Y$ be such that $X$ is compact and $f$ is continuous.\n[1]: If $f$ is surjective, then $Y$ is compact. Even if $f$ is not surjective, $f(X)$ is compact. [2]: If $Y$ is Hausdorff, then $f$ is a closed function. For a closed set $C \\subset X$, $f(C) \\subset Y$ is a closed set. Since $f(X)$ is compact, for an open cover $\\mathcal{O} := \\left\\{ (-n,n) \\ | \\ n \\in \\mathbb{N} \\right\\}$, $$ f(X) \\subset \\bigcup_{n=1}^{m} (-n , n) \\subset \\mathcal{O} $$ there exists a $m$ that satisfies this. By auxiliary lemma [1], since $f(X)$ is bounded, and $\\mathbb{R}$ is a Hausdorff space, by auxiliary lemma [2] the image of the whole set $X \\subset X$ in $f(X)$ is a closed set in $\\mathbb{R}$. Since $f(X)$ is bounded, by the completeness axiom, $$ u := \\sup f(X) \\\\ l : = \\inf f(X) $$ exists. Since $f(X)$ is a closed set, $$ u, l \\in f(X) \\\\ f(c) = l \\\\ f(d) = u $$ there must exist some $c,d \\in X$ that satisfies this. This $c,d$ satisfies $f(c) \\le f(x) \\le f(d)$ for all $x \\in X$.\n‚ñ†\nSee also Extreme value theorem in metric spaces Munkres. (2000). Topology(2nd Edition): p174.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":563,"permalink":"https://freshrimpsushi.github.io/en/posts/563/","tags":null,"title":"Proof of the Maximum and Minimum Value Theorem in Topological Spaces"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Theorems Let us assume that $f : X \\to Y$, with $X$ being compact, and $f$ being continuous.\n[1]: If $f$ is surjective, $Y$ is compact. Even if $f$ is not surjective, $f(X)$ is still compact. [2]: If $Y$ is Hausdorff, then $f$ is a closed function. For a closed set $C \\subset X$, $f(C) \\subset Y$ is also a closed set. [3]: If $f$ is bijective and $Y$ is Hausdorff, then $f$ is a homeomorphism. [4]: If $X$ is a metric space, then $f$ is uniformly continuous. Descriptions You might think these properties are trivial, but they are often used, including in the proof of the extreme value theorem.\n[1] This states that the property of being compact is preserved when applying a continuous function.\n[2] While it talks about being closed, because it\u0026rsquo;s about Hausdorff, it\u0026rsquo;s widely applicable. Since every metric space is a $T_{2}$ space, it generally holds true.\n[3] Though the conditions are numerous, the key point is that the definition of a homeomorphism implies that the inverse function is also continuous. If it\u0026rsquo;s easier to understand the topological properties of the domain and codomain than checking the continuity of the inverse function directly, it will be highly useful.\n[4] Uniform continuity is typically discussed only in metric spaces, but if $X$ is a compact space, it guarantees that $f$ has not just continuity but also uniform continuity. Compactness and continuity start from very different concepts, but as shown, they are intertwined in many ways and inseparable.\n","id":561,"permalink":"https://freshrimpsushi.github.io/en/posts/561/","tags":null,"title":"Useful Properties of Compact Spaces and Continuous Functions"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Theorem 1 Given measurable sets $E \\in \\mathcal{M}$ and $g \\in \\mathcal{L}^{1} (E)$, let the sequence of measurable functions $\\left\\{ f_{n} \\right\\}$ satisfy $|f_{n}| \\le g$ almost everywhere in $E$. If, almost everywhere in $E$, $\\displaystyle f = \\lim_{n \\to \\infty} f_{n}$ then $f \\in \\mathcal{L}^{1}(E)$. $$ \\lim_{ n \\to \\infty} \\int_{E} f_{n} (x) dm = \\int_{E} f dm $$\n$f,g \\in \\mathcal{L}^{1} (E)$ means that $f$ and $g$ are Lebesgue integrable functions. Explanation Compared to the Monotone Convergence Theorem, the condition $f_{n} \\nearrow f$ is missing, and there\u0026rsquo;s no need for $f_{n} \\ge 0$ either.\nInterestingly though, a $g$ that can \u0026ldquo;dominate\u0026rdquo; $\\left\\{ f_{n} \\right\\}$ is required, but eventually, $g$ does not appear in the result.\nProof Part 1.\nLet\u0026rsquo;s prove $f \\in \\mathcal{L}^{1}(E) $.\nSince in $E$ we have $|f_{n}| \\le g$, for all $x \\in E$, $-g(x) \\le f_{n} \\le g(x)$ holds. Summarizing gives $$0 \\le f_{n} (x) + g(x) \\le 2 g(x)$$, and when $n \\to \\infty $, $$0 \\le f (x) + g(x) \\le 2 g(x)$$ thus $$(f+g) \\in \\mathcal{L}^{1}(E)$$ Meanwhile, $f = (f + g ) + ( -g)$ and since $\\mathcal{L}^{1}(E)$ is a vector space, $f \\in \\mathcal{L}^{1}(E)$ holds.\nPart 2.\nAssume $f_{n} \\ge 0$.\nFatou\u0026rsquo;s Lemma: For a sequence of non-negative measurable functions $\\left\\{ f_{n} \\right\\}$, $$\\displaystyle \\int_{E} f dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm $$\nBy assumption and Fatou\u0026rsquo;s Lemma, $$\\displaystyle \\int_{E} f dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm $$ and it suffices to show $\\displaystyle \\limsup_{n \\to \\infty} \\int_{E} f_{n} dm \\le \\int_{E} f dm $.\nApplying Fatou\u0026rsquo;s Lemma again to $g-f_{n}$ gives $$\\displaystyle \\int_{E} \\lim_{n \\to \\infty} (g - f_{n}) dm \\le \\liminf_{n \\to \\infty} \\int_{E} (g - f_{n} ) dm $$. Here, since $f, g \\ge 0$, the left side is $$\\displaystyle \\int_{E} \\lim_{n \\to \\infty} (g - f_{n}) dm =\\int_{E} g dm - \\int_{E} f dm$$ and the right side is $$ \\begin{align*} \u0026amp; \\liminf_{n \\to \\infty} \\int_{E} (g - f_{n} ) dm \\\\ =\u0026amp; \\liminf_{n \\to \\infty} \\left( \\int_{E} g dm - \\int_{E} f_{n} dm \\right) \\\\ =\u0026amp; \\int_{E} g dm - \\limsup_{n \\to \\infty} \\int_{E} f_{n} dm \\end{align*} $$. Summarizing, $$ \\int_{E} g dm - \\int_{E} f dm \\le \\int_{E} g dm - \\limsup_{n \\to \\infty} \\int_{E} f_{n} dm $$ Since $g \\in \\mathcal{L}^{1} (E)$, $\\displaystyle \\int_{E} g dm \u0026lt; \\infty$ holds, allowing for cancellation on both sides, and rearranging signs yields: $$\\limsup_{n \\to \\infty} \\int_{E} f_{n} dm \\le \\int_{E} f dm$$\nPart 3.\nTo generalize for cases where $f_{n} \\ge 0$ is not true, define $h_{n} := f_{n} + g$. Since $h_{n} \\ge 0$, we can repeat the process in Part 2.\n‚ñ†\nCapinski. (1999). Measure, Integral and Probability: p92.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":557,"permalink":"https://freshrimpsushi.github.io/en/posts/557/","tags":null,"title":"Proof of the Dominated Convergence Theorem"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Buildup Let\u0026rsquo;s load the built-in data faithful in R and check it with the head() function.\nThough only six, at a glance, eruptions and waiting seem to have a positive correlation. It would be nice if their relationship could be represented by some two constants $\\beta_{0}, \\beta_{1}$ such that $$\\text{(eruptions)} = \\beta_{0} + \\beta_{1} \\cdot \\text{(waiting) }$$ The above equation represents the linear relationship between the two variables as the equation of a line, where $\\beta_{0}$ is the constant term, and $\\beta_{1}$ represents the slope.\nHowever, in reality, due to differences from theory, some error term $\\varepsilon$ is necessary. For simplification, if we denote this as $y:=\\text{(eruptions)}$ and $x:=\\text{(waiting) }$, we get the following. $$y = \\beta_{0} + \\beta_{1} x + \\varepsilon$$\nThe screenshot above shows a total of $6$ ordered pairs, representing them as a system of equations yields the following.\n$$ \\begin{cases} 3.600 = \\beta_{0} + \\beta_{1} 79 + \\varepsilon_{1} \\\\ 1.800 = \\beta_{0} + \\beta_{1} 54 + \\varepsilon_{2} \\\\ 3.333 = \\beta_{0} + \\beta_{1} 74 + \\varepsilon_{3} \\\\ 2.283 = \\beta_{0} + \\beta_{1} 62 + \\varepsilon_{4} \\\\ 4.533 = \\beta_{0} + \\beta_{1} 85 + \\varepsilon_{5} \\\\ 2.883 = \\beta_{0} + \\beta_{1} 55 + \\varepsilon_{6} \\end{cases} $$\nActually, faithful contains as many as 272 ordered pairs, thus representing all of them in this manner is impractical, let\u0026rsquo;s represent them using symbols again.\n$$ \\begin{cases} y_{1} \u0026amp;= \\beta_{0} + \\beta_{1} x_{1} + \\varepsilon_{1} \\\\ y_{2} \u0026amp;= \\beta_{0} + \\beta_{1} x_{2} + \\varepsilon_{2} \\\\ \u0026amp;\\vdots\u0026amp; \\\\ y_{272} \u0026amp;= \\beta_{0} + \\beta_{1} x_{272} + \\varepsilon_{272} \\end{cases} $$\nMeanwhile, such a system of equations can be more simply represented as a matrix equation. $$ \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{272} \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; x_{1} \\\\ 1 \u0026amp; x_{2} \\\\ \\vdots \u0026amp; \\vdots \\\\ 1 \u0026amp; x_{272} \\end{bmatrix} \\begin{bmatrix} \\beta_{0} \\\\ \\beta_{1} \\end{bmatrix} + \\begin{bmatrix} \\varepsilon_{1} \\\\ \\varepsilon_{2} \\\\ \\vdots \\\\ \\varepsilon_{272} \\end{bmatrix} $$ As usual, if even the matrix is represented with uppercase, you finally get $Y = X \\beta + \\varepsilon$.\nDefinition Here, the matrix grouping together the independent variables, as indicated by $X$, is called the Design Matrix.\nPrerequisites Thus, being able to represent data as a matrix means that various tools from linear algebra can be applied to statistics. Finding $\\beta$ here is precisely what regression analysis is about, and understanding it accurately requires knowledge of linear algebra.\nMany learners approaching statistics do not feel the need for linear algebra and neglect it, only to feel challenged when matrices are introduced. To avoid following in the footsteps of your predecessors, it\u0026rsquo;s crucial to thoroughly grind and polish lower-year subjects like analysis and linear algebra.\n","id":550,"permalink":"https://freshrimpsushi.github.io/en/posts/550/","tags":null,"title":"Design Matrix"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Theorem1 The following holds for a 3-dimensional vector function $\\mathbf{F}$:\n$$ \\begin{equation} \\int_{\\mathcal{V}} \\nabla \\cdot \\mathbf{F} dV = \\oint_{\\mathcal{S}} \\mathbf{F} \\cdot d \\mathbf{S} \\label{1} \\end{equation} $$\nHere, $\\nabla \\cdot \\mathbf{F}$ is divergence, $\\int_{\\mathcal{V}}$ is volume integration, and $\\oint_{\\mathcal{S}}$ is closed surface integration.\nDescription This is called Gauss\u0026rsquo;s theorem, Green\u0026rsquo;s theorem, or divergence theorem. The divergence theorem is especially used in electromagnetics.\nMathematical Meaning Mathematically, it means that a surface integral can be expressed as a volume integral, and a volume integral can be expressed as a surface integral. In other words, it\u0026rsquo;s possible to convert triple integrals and double integrals to each other.\nPhysical Meaning Physically, the total sum of amounts coming in and out at each point (small volume) on the left side of $\\big( \\eqref{1}$ is the same as the total sum of amounts coming in and out on the entire surface of the volume on the right side of $\\big( \\eqref{1}$.\nAs a simple example, imagine there are people in a room. People enter and leave the room through the door. Suppose there are two observers, one looking inside the room and the other at the door. Let\u0026rsquo;s say 2 people enter the room and 3 people leave. Then, the change of people as seen by the observer inside the room2 is $|2-3|=1$, and the change of people as seen by the doorkeeper3 is $|3-2|=1$. (Count as $+1$ when $1$ people open the door and leave) These two are always the same.\nProof Let\u0026rsquo;s check if the volume integral of divergence for each face adds up to the same.\nAdding up the surface integral for all faces results in:\n$$ \\int _{S_{1}} \\mathbf{F} \\cdot d \\mathbf{S}_{1} + \\int_ {S_2} \\mathbf{F} \\cdot d \\mathbf{S}_2 + \\int_ {S_{3}} \\mathbf{F} \\cdot d \\mathbf{S}_ + \\int_ {S_{4}} \\mathbf{F} \\cdot d\\mathbf{S}_{4} + \\int _{S_{5}} \\mathbf{F} \\cdot d\\mathbf{S}_{5}+\\int _{S_{6}} \\mathbf{F} \\cdot d\\mathbf{S}_{6} $$\nFirst, let\u0026rsquo;s calculate for faces $S_{1}$ and $S_2$, which are perpendicular to the $x$ axis. It\u0026rsquo;s $\\mathbf{F}= F_{x} \\hat{\\mathbf{x}} + F_{y} \\hat{\\mathbf{y}} + F_{z} \\hat{\\mathbf{z}}$, and each surface\u0026rsquo;s direction is outward. Assume the direction of $\\mathbf{F}$ is the same as $S_{1}$. Then, the two surface integrals are as follows:\n$$ \\begin{align*} \\int _{S_{1}} \\mathbf{F} \\cdot d \\mathbf{S}_{1} + \\int _{S_2} \\mathbf{F} \\cdot d \\mathbf{S}_2 \u0026amp;= \\int_ {S_{1}} F_{x} dS_{1} - \\int _{S_2} F_{x} dS_2 \\\\ \u0026amp;= \\int_{z}^{z+\\Delta z} \\int_{y}^{y+\\Delta y} F_{x} (x+\\Delta x,y,z) dydz - \\int_{z}^{z+\\Delta z} \\int_{y}^{y+\\Delta y} F_{x} (x,y,z) dydz \\\\ \u0026amp;= \\int_{z}^{z+\\Delta z} \\int_{y}^{y+\\Delta y} \\bigg[ F_{x} (x+\\Delta x,y,z) - F_{x} (x,y,z) \\bigg] dydz \\end{align*} $$\nAt this point, by the Fundamental Theorem of Calculus, since $\\displaystyle \\int _{a} ^b \\dfrac{ dF(x)}{dx}dx=F(b) - F(a)$, it can be summarized as follows:\n$$ \\begin{align*} \u0026amp; \\int_{z}^{z+\\Delta z} \\int_{y}^{y+\\Delta y} \\left[ F_{x} (x+\\Delta x,y,z) - F_{x} (x,y,z) \\right] dydz \\\\ =\u0026amp;\\ \\int_{z}^{z+\\Delta z} \\int_{y}^{y+\\Delta y} \\left[ \\int_{x} ^{x +\\Delta x} \\dfrac{ \\partial F_{x}(x,y,z) }{\\partial x} dx \\right] dydz \\\\ =\u0026amp;\\ \\int_{z}^{z+\\Delta z} \\int_{y}^{y+\\Delta y} \\int_{x} ^{x +\\Delta x} \\dfrac{ \\partial F_{x}(x,y,z) }{\\partial x} dx dydz \\\\ =\u0026amp;\\ \\iiint \\dfrac{ \\partial F_{x} }{\\partial x} dV \\end{align*} $$\nThus, the following result is obtained:\n$$ \\int_ {S_{1}} \\mathbf{F} \\cdot d \\mathbf{S}_{1} + \\int_ {S_2} \\mathbf{F} \\cdot d \\mathbf{S}_2 =\\iiint \\dfrac{ \\partial F_{x} }{\\partial x} dV $$\nSimilarly, if we calculate the surface integrals for $S_{3}$ and $S_{4}$, and the surface integrals for $S_{5}$ and $S_{6}$, we get:\n$$ \\int _{S_{3}} \\mathbf{F} \\cdot d \\mathbf{S}_{1} + \\int _{S_{4}} \\mathbf{F} \\cdot d \\mathbf{S}_2 =\\iiint \\dfrac{ \\partial F_{y} }{\\partial y} dV $$\n$$ \\int_ {S_{5}} \\mathbf{F} \\cdot d \\mathbf{S}_{5} + \\int_ {S_{6}} \\mathbf{F} \\cdot d \\mathbf{S}_2 =\\iiint \\dfrac{ \\partial F_{z} }{\\partial z} dV $$\nFinally, adding all the surface integrals for the 6 faces gives:\n$$ \\begin{align*} \\oint _\\mathcal{S} \\mathbf{F} \\cdot d \\mathbf{S} \u0026amp;= \\iiint \\dfrac{ \\partial F_{x} }{\\partial x} dV + \\iiint \\dfrac{ \\partial F_{y} }{\\partial y} dV +\\iiint \\dfrac{ \\partial F_{z} }{\\partial z} dV \\\\ \u0026amp;= \\iiint \\left[ \\dfrac{ \\partial F_{x} }{\\partial x} + \\dfrac{ \\partial F_{y} }{\\partial y} + \\dfrac{ \\partial F_{z} }{\\partial z} \\right] dV \\\\ \u0026amp;= \\iiint \\nabla \\cdot \\mathbf{F} dV \\\\ \u0026amp;= \\int_\\mathcal{V} \\nabla \\cdot \\mathbf{F} dV \\end{align*} $$\n‚ñ†\nDavid J. Griffiths, Introduction to Electrodynamics (translated by Jin-Seung Kim) (4th Edition, 2014), p35\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe change inside, i.e., the change in volume.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe change at the entrance, i.e., the change on the surface.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":565,"permalink":"https://freshrimpsushi.github.io/en/posts/565/","tags":null,"title":"Gauss's Theorem, Divergence Theorem"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition 1 Basic Properties [1]: An integrable function is a measurable function. [2]: If $f \\in \\mathcal{L}^{1} (E)$ then $\\displaystyle \\left| \\int_{E} f dm \\right| \\le \\int_{E} | f | dm$ [3]: If $f \\in \\mathcal{L}^{1} (E) $ and $c \\in \\mathbb{R}$ then $\\displaystyle \\int_{E} (c f) dm = c \\int_{E} f dm$ [4]: If $f,g \\in \\mathcal{L}^{1} (E) $ then $\\displaystyle \\int_{E} ( f + g ) dm = \\int_{E} f dm + \\int_{E} g dm$ [5]: If $f,g \\in \\mathcal{L}^{1} (E)$ and $f \\le g$ then $\\displaystyle \\int_{E} f dm \\le \\int_{E} g dm$ [6]: For all $E \\in \\mathcal{M}$, if $\\displaystyle \\int_{E} f dm = \\int_{E} g dm$ then almost everywhere $f= g$. Explanation It might seem easy that Property [1] is directly under the definition, but it can get confusing after a while so make sure to memorize it well.\nMeanwhile, from properties [3]~[5], it can be seen that $\\mathcal{L}^{1}(E)$ is a vector space.\nCapinski. (1999). Measure, Integral and Probability: p86. When we say $E \\in \\mathcal{M}$, for a measurable function $f$, let\u0026rsquo;s denote it as $$f^{+} := \\max \\left\\{ f , 0 \\right\\} \\\\ f^{-} := \\max \\left\\{ -f , 0 \\right\\}$$ Then, it can be represented as $$ f = f^{+} - f^{-} \\\\ | f | = f^{+} + f^{-} $$ If $\\displaystyle \\int_{E} | f | dm \u0026lt; \\infty$, that is, $$ \\int_{E} f^{+} dm \u0026lt; \\infty \\\\ \\int_{E} f^{-} dm \u0026lt; \\infty $$ then $f$ is called Lesbegue Integrable. The set of integrable functions from $E$ is denoted as follows. $$ \\mathcal{L}^{1}(E) : = \\left\\{ f \\ \\left| \\ \\int_{E} | f | dm \u0026lt; \\infty \\right. \\right\\} $$\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":549,"permalink":"https://freshrimpsushi.github.io/en/posts/549/","tags":null,"title":"Lebesgue Integrable"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Description Regression analysis is so ubiquitous a foundation of nearly all statistical techniques that it is often described either too generally or too specifically. If one were to explain what regression analysis is in a sentence for someone curious, it could be described as a method for discovering the relationships between variables.\nThis useful and astonishing method of analysis was born from the ideas of Francis Galton, the father of eugenics.\nGalton, while studying genetics, came across data on the heights of fathers and their sons and noticed that generally, if the father was tall, the son was also likely to be tall and vice versa. While this relationship was known to everyone before, Galton focused on the phenomenon where, over generations, it regresses to the mean.\nSons of taller fathers were indeed tall but tended to be shorter than their fathers, and sons of shorter fathers were also short but tended to be taller than their fathers. Logically, this makes sense; otherwise, over generations, height would diverge infinitely or converge to $0$.\nMeanwhile, it\u0026rsquo;s not always regressing to the mean because there are unavoidable errors, such as environmental factors or mutations. Nevertheless, the evident linear relationship must have persuaded Galton that \u0026lsquo;height is inherited.\u0026rsquo;\nSo, even if it\u0026rsquo;s not exactly accurate, isn\u0026rsquo;t it possible, albeit with some error, to roughly predict a son\u0026rsquo;s height by just looking at the father\u0026rsquo;s height? If the height of the parents $x$ and the height of the son $y$ have a relationship like $y = a + b x$, then by substituting the father\u0026rsquo;s height for $x$, one could guess the height of the son. Of course, it might not match perfectly, but on average, it would fall reasonably close.\nThis is how regression analysis came about. Now, of course, regression analysis is applied in an incredibly broad range of fields, and there\u0026rsquo;s no need to talk about generational change, so the term \u0026lsquo;regression\u0026rsquo; has lost its original meaning. It\u0026rsquo;s okay to just understand its etymology and move on.\n","id":548,"permalink":"https://freshrimpsushi.github.io/en/posts/548/","tags":null,"title":"What is Regression Analysis?"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Theorem 1 Let us assume that a sequence $\\left\\{ f_{n} \\right\\}$ of measurable functions with non-negative values satisfies $f_{n} \\nearrow f$. Then $$ \\lim_{n \\to \\infty} \\int_{E} f_{n} dm = \\int_{E} f dm $$\nExplanation $f_{n} \\nearrow f$ means that for all $x$, if $f_{n}(x) \\le f_{n+1} (x)$ while $\\displaystyle \\lim_{n \\to \\infty} f_{n} = f$. The formula is too simple, so knowing this theorem means precisely understanding the \u0026lsquo;condition\u0026rsquo;. In terms of usefulness, it implies that limits can freely cross integrals, which is unequivocally beneficial.\nProof Since $f_{n} \\le f$, $$ \\limsup_{n \\to \\infty} \\int_{E} f_{n} dm \\le \\int_{E} f dm $$\nFatou\u0026rsquo;s Lemma: For a sequence $\\left\\{ f_{n} \\right\\}$ of measurable functions with non-negative values $$\\displaystyle \\int_{E} \\left( \\liminf_{n \\to \\infty} f_{n} \\right) dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm $$\nBy Fatou\u0026rsquo;s Lemma and the properties of limit infimum, $\\displaystyle \\int_{E} f dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm$ holds, and summarizing, $$\\displaystyle \\limsup_{n \\to \\infty} \\int_{E} f_{n} dm \\le \\int_{E} f dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm $$ However, obviously $\\displaystyle \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm \\le \\limsup_{n \\to \\infty} \\int_{E} f_{n} dm$, therefore $$\\displaystyle \\limsup_{n \\to \\infty} \\int_{E} f_{n} dm = \\int_{E} f dm = \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm$$ must hold.\n‚ñ†\nCorollary Let us assume that a sequence $\\left\\{ f_{n} \\right\\}$ of measurable functions with non-negative values satisfies $f_{n} \\nearrow f$ almost everywhere. Then $$\\lim_{n \\to \\infty} \\int_{E} f_{n} dm = \\int_{E} f dm$$ and, in particular $$ \\int \\sum_{n=1}^{\\infty} f_{n} dm = \\sum_{n=1}^{\\infty} \\int f_{n} dm$$\nCapinski. (1999). Measure, Integral and Probability: p84.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":535,"permalink":"https://freshrimpsushi.github.io/en/posts/535/","tags":null,"title":"Monotone Convergence Theorem Proof"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Summary 1 For a sequence $\\left\\{ f_{n} \\right\\}$ of non-negative measurable functions, $$ \\int_{E} \\left( \\liminf_{n \\to \\infty} f_{n} \\right) dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm $$\n$\\liminf$ is the limit inferior. Explanation A lemma necessary for proving the Monotone Convergence Theorem and the Dominated Convergence Theorem in real analysis. The version of Fatou\u0026rsquo;s lemma for series without the condition of being measurable functions is as follows.\nSeries Version: For a sequence $\\left\\{ f_{k} : \\mathbb{N} \\to [0, \\infty) \\right\\}_{k \\in \\mathbb{N}}$ of functions with non-negative values $$ \\sum_{j=1}^{\\infty} \\liminf_{k \\to \\infty} f_{k} (j) \\le \\liminf_{k \\to \\infty} \\sum_{j=1}^{\\infty} f_{k} (j) \\qquad , \\forall j \\in \\mathbb{N} $$\nProof Strategy: It helps to have an intuition for simple functions. As with all lemmas, they are useful but the proof is quite long and complex, so it is best read when in a clear and healthy state of mind. The proof for the series case is essentially the same.\nPart 1.\nIf we have $$ f : = \\liminf_{n \\to \\infty} f_{n} \\\\ \\displaystyle g_{n} : = \\inf_{k \\ge n } f_{k} $$ then $\\displaystyle f = \\lim_{n \\to \\infty} g_{n}$. $$ \\int_{E} f dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm $$ To show this, it\u0026rsquo;s sufficient to prove for all simple functions $\\phi \\le f$ that $$ \\int_{E} \\phi dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm $$\nNow, let\u0026rsquo;s define a new simple function for a very small positive number $\\varepsilon \u0026gt; 0$. Then for a sufficiently large natural number $n$, $\\phi_{\\varepsilon} \\le g_{n} \\le f$ will hold. Lastly, if we define $A_{k} : = \\left\\{ x \\ | \\ g_{k} \\ge \\phi_{\\varepsilon} \\right\\}$, $$ A_{k} \\subset A_{k+1} \\\\ \\displaystyle \\bigcup_{k=1}^{\\infty} A_{k} = \\mathbb{R} $$\nPart 2.\nSince $A_{n}$ and $\\phi_{\\varepsilon} \\le g_{n}$, $$ \\int_{A_{n} \\cap E} \\phi_{\\varepsilon} dm \\le \\int_{A_{n} \\cap E} g_{n} dm $$ and since $\\displaystyle g_{n} = \\inf_{k \\ge n } f_{k}$, from $k \\ge n$, we have $$ \\int_{A_{n} \\cap E} g_{n} dm \\le \\int_{A_{n} \\cap E} f_{k} dm $$ Meanwhile, since $A_{n} \\cap E \\subset E$, $$ \\int_{A_{n} \\cap E} f_{k} dm \\le \\int_{E} f_{k} dm $$ Hence, we obtain the following: $$ \\int_{A_{n} \\cap E} \\phi_{\\varepsilon} dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm $$\nPart 3.\nSince $\\phi_{\\epsilon}$ was a simple function, its image can be represented as a finite set $\\left\\{ c_{1} , c_{2} , \\cdots , c_{r} \\right\\}$. If we assume $B_{i} := \\phi_{\\epsilon}^{-1} ( \\left\\{ c_{i} \\right\\} )$, $$ \\int_{A_{n} \\cap E} \\phi_{\\varepsilon} dm = \\sum_{i = 1}^{r} c_{i} m (A_{n} \\cap E \\cap B_{i}) $$\n[7]: $A_{n} \\in \\mathcal{M}$, $\\displaystyle A_{n} \\subset A_{n+1} \\implies m \\left( \\bigcup_{n=1}^{\\infty} A_{n} \\right) = \\lim_{n \\to \\infty} m (A_{n})$\nFrom Part 1, since $A_{n} \\subset A_{n+1}$ and $\\displaystyle \\bigcup_{n=1}^{\\infty} A_{n} = \\mathbb{R}$, $$ \\lim_{n \\to \\infty} \\sum_{i = 1}^{r} c_{i} m (A_{n} \\cap E \\cap B_{i}) = \\lim_{n \\to \\infty} \\int_{A_{n} \\cap E} \\phi_{\\varepsilon} dm = \\int_{E} \\phi_{\\varepsilon} dm $$ Combining with results obtained in Part 2, $$ \\int_{E} \\phi_{\\varepsilon} dm \\le \\liminf_{k \\to \\infty} \\int_{E} f_{k} dm $$\nPart 4.\nCase 1. $m( \\left\\{ x \\ | \\ \\phi (x) \u0026gt;0 \\right\\} ) \u0026lt; \\infty$\n$$\\displaystyle \\int_{E} \\phi_{\\varepsilon} dm = \\int_{E} \\phi dm - \\varepsilon m( \\left\\{ x \\ | \\ \\phi (x) \u0026gt;0 \\right\\} ) $$ Taking the limit as $\\varepsilon \\to 0$, yields the following: $$ \\displaystyle \\int_{E} \\phi_{\\varepsilon} dm = \\int_{E} \\phi dm $$\nCase 2. $m( \\left\\{ x \\ | \\ \\phi (x) \u0026gt;0 \\right\\} ) = \\infty$ $$\\displaystyle D_{n} : = \\left\\{ x \\ \\left| \\ g(x) \\ge {{1} \\over {2}} \\min \\left\\{ c_{i} \\right\\}_{i=1}^{n} \\right. \\right\\} $$ Then, $$ D_{n} \\subset D_{n+1} \\\\ \\displaystyle \\bigcup_{n=1}^{\\infty} D_{n} = \\mathbb{R} $$ Since $\\displaystyle \\int_{D_{n} \\cap E} g_{n} dm \\to \\infty$, and from the definition of $g_{n}$, we obtain the following: $$ \\displaystyle \\int_{D_{n} \\cap E} g_{n} dm \\le \\int_{D_{n} \\cap E} f_{k} dm \\le \\int_{E} f_{k} dm $$\nTherefore, in any case, for all simple functions $\\phi \\le f$, the following holds: $$ \\int_{E} \\phi dm \\le \\liminf_{n \\to \\infty} \\int_{E} f_{n} dm $$\n‚ñ†\nCapinski. (1999). Measure, Integral and Probability: p82.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":534,"permalink":"https://freshrimpsushi.github.io/en/posts/534/","tags":null,"title":"Proof of Fatou's Lemma"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition The following quasilinear partial differential equation is called the Burgers\u0026rsquo; equation.\n$$ \\begin{cases} u_{t} + u u_{x} = 0 \u0026amp; , t\u0026gt;0 \\\\ u(t,x) = f(x) \u0026amp; , t=0 \\end{cases} $$\nHere, $t$ represents time, $x$ represents position, and $u(t,x)$ represents the waveform at position $x$ at time $t$. $f$ represents the initial condition, specifically the waveform at $t=0$.\nExplanation Burgers\u0026rsquo; equation represents the case where the diffusion coefficient $\\nu$ is $0$ in $\\displaystyle u_{t} + u u_{x} = \\nu u_{xx}$.\nIf $f ' (x)\u0026gt;0$, it means that the speed increases with increasing $x$, hence the characteristic curves form a rarefaction wave as shown above. The slope at $(t,x)$ represents the speed of the wave, implying that in a rarefaction, the speed either consistently increases or decreases. In such cases, the characteristic curves never intersect.\nDrawing the waveform shows that as time progresses, the fast points move faster and the slow points move slower, resulting in an increasing difference.\nOn the other hand, in cases where the speed decreases with increasing $x$, characteristic curves intersect as shown.\nIn this case, as shown in the figure, points at the back overtake the points in front. This is particularly noticeable from the time $t=1$, where $u$ starts to have multiple values for a given $x$. A natural phenomenon that could be imagined to exemplify this is the formation of a wave; the water at the bottom slows down due to friction with the sand or gravel, while the top moves over it. This is called a blow-up, which mathematically means the function ceases to exist, and physically, it signifies the superposition of several states at the same time.\nThe case where characteristic curves form a rarefaction is too straightforward, hence the main interest lies elsewhere. Although finding the solution is not complicated, converting it into an explicit function form is challenging, and often impossible. In solving Burgers\u0026rsquo; equation, determining the blow-up time and blow-up location is also a crucial problem. The solution to the inviscid Burgers\u0026rsquo; equation, if it exists, is as follows.\nSolution Step 1. Let $\\xi = x - tu$.\nStep 2. Let $u = f(x - tu)$.\nThen, since $\\xi = x - t f( x - tu) = x - t f (\\xi )$, the characteristic lines become $x = f(\\xi) t + \\xi$. If $f ' (x) \u0026gt; 0$ for all $x \\in \\mathbb{R}$, the characteristic lines form a rarefaction and do not meet. If there exists a $x$ such that $f ' (x) \u0026lt; 0$, the characteristic lines will meet at some point and blow-up at that point.\nStep 3. Convert the initial condition to the form of $f(x-tu) = f(\\xi)$.\nIf possible, convert $u = f(\\xi) = f(x - tu)$ into an explicit function form.\n‚ñ†\nIf the solution to the inviscid Burgers\u0026rsquo; equation blows up within a finite time, the time and location are as follows:\nStep 1. If $u$ has been found in the form of an explicit function, find $t = t_{\\ast}$ where $u$ diverges.\nThat $t_{\\ast}$ is the blow-up time.\nStep 2. If it has not been possible to find the explicit function form, find $f ' (x)$.\n$$ t_{\\ast} : = \\inf \\left\\{ \\left. - {{1} \\over {f ' (x) }} \\ \\right| \\ f '(x) \u0026lt; 0 \\right\\} $$\nThat is the blow-up time.\nStep 3. Find the point $x_{0}$ where the characteristic line $x = f(\\xi) t + \\xi$ intersects with the $x$ axis.\n$x_{*} = x_{0} + f(x_{0}) t_{\\ast}$, obtained by substituting $\\xi=x_{0}$ and $t = t_{\\ast}$ into $x = f(\\xi) t + \\xi$, is the blow-up location.\n‚ñ†\nExamples 1 Find the blow-up time of $\\displaystyle \\begin{cases} u_{t} + u u_{x} = 0 \u0026amp; , t\u0026gt;0 \\\\ u(t,x) = \\alpha (x - tu) + \\beta \u0026amp; , t=0 \\end{cases}$. This is the type where $u$ is neatly represented as an explicit function.\nOrganizing $u = \\alpha ( x - tu ) + \\beta$ in terms of $u$ yields $\\displaystyle u(t,x) = {{\\alpha x + \\beta} \\over {1 + \\alpha t}}$ and the blow-up time is $\\displaystyle t_{\\ast} = - {{1} \\over {\\alpha}} $.\n‚ñ†\n2 Find the blow-up time of $\\displaystyle \\begin{cases} u_{t} + u u_{x} = 0 \u0026amp; , t\u0026gt;0 \\\\ u(t,x) = {{1} \\over {2}} \\pi - \\tan^{-1} x \u0026amp; , t=0 \\end{cases}$. This is the type where representing $u$ as an explicit function is cumbersome.\n$$ f ' (x) = \\left( {{1} \\over {2}} \\pi - \\tan^{-1} x \\right) = - {{1} \\over {1 + x^2}} $$\nand for $x \\in \\mathbb{R}$, $f ' (x) \u0026lt; 0$ holds. Therefore,\n$$ t_{\\ast} = \\inf \\left\\{ \\left. - {{1} \\over {f ' (x) }} \\ \\right| \\ f '(x) \u0026lt; 0 \\right\\} = \\inf \\left\\{ \\left. (1+ x^2) \\ \\right| \\ f '(x) \u0026lt; 0 \\right\\} = 1 $$\n‚ñ†\n","id":532,"permalink":"https://freshrimpsushi.github.io/en/posts/532/","tags":null,"title":"Solution to the Inviscid Burgers' Equation"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Summary1 $$ ay^{\\prime \\prime} + by^\\prime + cy=0 $$\nLet\u0026rsquo;s say the solutions to the characteristic equation $ar^2+br+c=0$ given above are $r_{1}$ and $r_2$. Then,\n$\\text{1.}$ If $r_{1}$ and $r_2$ are two distinct real numbers$(b^2-4ac\u0026gt;0)$, the general solution is as follows: $$ y(t)=c_{1}e^{r_{1}t}+c_2e^{r_2t} $$\n$\\text{2.}$ If $r_{1}$ and $r_2$ are complex conjugates $\\lambda \\pm i \\mu$$(b^2-4ac\u0026lt;0)$, the general solution is as follows: $$ \\begin{align*} y(t) \u0026amp;= c_{1}e^{(\\lambda + i\\mu)t} + c_2e^{(\\lambda ‚Äì i\\mu)t} \\\\ \u0026amp;= c_{3}e^{\\lambda t} \\cos \\mu t + c_{4} e^{\\lambda t} \\sin \\mu t \\end{align*} $$\n$\\text{3.}$ In the case of $r_{1}=r_2=r$$(b^2-4ac=0)$, the general solution is as follows: $$ y(t)=c_{1}e^{rt}+c_2te^{rt} $$\nSolution 1. If $r_{1} \\ne r_2$ and $r_{1}, r_2\\in \\mathbb{R}$ The general solution is as follows:\n$$ y(t)=c_{1}e^{r_{1}t}+c_2e^{r_2t} $$\nHere, $c_{1}, c_2$ is a constant, and if we know the two initial values $y(0)=y_{0}$ and $y^\\prime (0) =y^\\prime_{0}$, we can determine it exactly.\n‚ñ†\n2. If $r_{1} \\ne r_2$ and $r_{1}, r_2 \\in \\mathbb{C}$ In the case where the discriminant of the characteristic equation is $b^2-4ac\u0026lt;0$. Since $r_{1}$ and $r_2$ become complex conjugates, it can be expressed as follows:\n$$ r_{1}=\\lambda + i\\mu,\\quad r_2=\\lambda ‚Äì i\\mu $$\nThen, the two solutions of the differential equation are as follows:\n$$ y_{1}=e^{r_{1}t}=e^{(\\lambda + i\\mu)t}, y_{2}=e^{(\\lambda ‚Äì i\\mu)t} $$\nTherefore, the general solution is as follows:\n$$ y(t)=c_{1}e^{(\\lambda + i\\mu)t} + c_2e^{(\\lambda ‚Äì i\\mu)t} $$\nUp to here, it is not particularly different from 1. If we represent the general solution using the Euler\u0026rsquo;s formula, then\n$$ \\begin{align*} \u0026amp;\\ c_{1}e^{(\\lambda + i\\mu)t} + c_2e^{(\\lambda ‚Äì i\\mu)t} \\\\ =\u0026amp;\\ c_{1} e^{\\lambda t} (\\cos \\mu t + i\\sin \\mu t) + c_2 e^{\\lambda t} ( \\cos \\mu t ‚Äì i \\sin \\mu t) \\\\ =\u0026amp;\\ c_{3}e^\\lambda \\cos \\mu t + c_{4} e^\\lambda \\sin \\mu t \\end{align*} $$\nTherefore,\n$$ y(t)=c_{3}e^{\\lambda t} \\cos \\mu t + c_{4} e^{\\lambda t} \\sin \\mu t $$\nAt this time, $c_{4}$ is a complex constant including $i$. If we know the initial values, we can determine $c_{3}$ and $c_{4}$ exactly.\n‚ñ†\n3. If $r_{1}=r_2=r=-\\dfrac{b}{2a}$ In the case where the discriminant of the characteristic equation is $b^2-4ac=0$. $y_{1}$ can be found by $y_{1}=e^{\\frac{-b}{2a}t}$, but $y_{2}$ cannot be found. Assume $y_{2}$ as $y(t)=\\nu (t) y_{1}(t)$, then\n$$ \\begin{align*} y^\\prime \u0026amp;= \\nu ^\\prime y_{1} + \\nu y_{1}^\\prime \\\\ y^{\\prime \\prime}\u0026amp;=\\nu^{\\prime \\prime}y_{1} +\\nu ^\\prime y_{1}^\\prime + \\nu^\\prime y_{1}^\\prime + \\nu y_{1}^{\\prime \\prime}=\\nu^{\\prime \\prime}y_{1}+2\\nu ^\\prime y_{1}^\\prime+ \\nu y_{1}^{\\prime \\prime} \\end{align*} $$\nSubstituting $y^\\prime$ and $y^{\\prime \\prime}$ into the given differential equation gives\n$$ a \\left( \\nu^{\\prime \\prime}y_{1}+2\\nu ^\\prime y_{1}^\\prime+ \\nu y_{1}^{\\prime \\prime} \\right) + b \\left( \\nu ^\\prime y_{1} + \\nu y_{1}^\\prime \\right) + c\\nu y_{1}=0 $$\nOrganizing it according to $\\nu$ turns out as follows:\n$$ \\nu \\left( ay_{1}^{\\prime \\prime} + b y_{1}^{\\prime} + cy_{1}\\right) + \\nu^\\prime \\left( 2ay_{1}^\\prime+by_{1} \\right) + ay_{1} \\nu ^{\\prime \\prime}=0 $$\nHere, since $y_{1}$ is a solution to the given differential equation, the first parenthesis is $0$. Also, since $y_{1}=e^{(-b/{2a})t}$ and $y_{1}^\\prime = \\frac{-b}{2a}e^{({-b}/{2a})t}$,\n$$ \\begin{align*} \u0026amp;\u0026amp;\\nu^\\prime \\left( 2a \\dfrac{-b}{2a}e^{\\frac{-b}{2a}t} + b e^{\\frac{-b}{2a}t} \\right) + ae^{\\frac{-b}{2a}t} \\nu ^{\\prime \\prime}\u0026amp;=0 \\\\ \\implies\u0026amp;\u0026amp; \\nu^\\prime(-b+b)+a\\nu^{\\prime \\prime}\u0026amp;=0 \\\\ \\implies \u0026amp;\u0026amp; \\nu^{\\prime \\prime} \u0026amp;=0 \\end{align*} $$\nTherefore, it turns out that $\\nu (t)=c_{1}+c_2t$. Ultimately, the general solution to the given differential equation is\n$$ y(t)=\\nu (t) y_{1}(t)=c_{1}y_{1}(t)+c_2ty_{1}(t)=c_{1}e^{rt}+c_2te^{rt} $$\nIn other words, it turns out to be $y_{2}=ty_{1}$.\n‚ñ†\nExamples 1. $$ y^{\\prime \\prime}+ 5y^\\prime + 6y=0 \\\\ y(0)=2 \\\\ y^\\prime (0)=3 $$\nThe characteristic equation is $r^2+5r+6=0$. That is $(r+2)(r+3)=0$, so $r_{1}=-2$, $r_2=-3$. Therefore, the general solution is\n$$ y(t)=c_{1}e^{-2t}+c_2e^{-3t} $$\nDifferentiating the general solution gives\n$$ y^\\prime(t)=-2c_{1}e^{-2t} -3c_2e^{-3t} $$\nSubstituting the initial values gives\n$$ \\begin{cases} c_{1}+c_2=2 \\\\ -2c_{1}-3c_2=3 \\end{cases} $$\nSolving them together gives\n$$ c_{1}=9,\\quad c_2=7 $$\nTherefore, the solution for the given initial values is\n$$ y(t)=9e^{-2t}+7e^{-3t} $$\n‚ñ†\n2. $$ y^{\\prime \\prime}+4y^\\prime + 8y=0 $$\nThe characteristic equation is\n$$ r^2+4r+8=0 $$\nThe solutions of the characteristic equation are\n$$ r_{1,2}= \\dfrac{-4\\pm \\sqrt{16-32}}{2}=-2 \\pm 2i $$\nSo $\\lambda=-2$, $\\mu=2$. Therefore, the general solution for the given differential equation is\n$$ y(t)=c_{1}e^{-2t}\\cos 2t + c_2 e^{-2t} \\sin 2t $$\n‚ñ†\n3. $$ y^{\\prime \\prime} + 4y^\\prime + 4y=0 $$\nThe characteristic equation is\n$$ r^2+4r+4=(r+2)^2=0 $$\nThe solutions of the characteristic equation are\n$$ r=-2 $$\nTherefore, it turns out $y_{1}(t)=e^{-2t}$ and the general solution is\n$$ y(t)=c_{1}e^{-2t} + c_2te^{-2t} $$\n‚ñ†\nWilliam E. Boyce, Boyce\u0026rsquo;s Elementary Differential Equations and Boundary Value Problems (11th Edition, 2017), p120-133\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":544,"permalink":"https://freshrimpsushi.github.io/en/posts/544/","tags":null,"title":"Solution to Second Order Homogeneous Differential Equations"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Buildup Before considering the generalization of Riemann integration, it is necessary to define what a simple function is.\nLet\u0026rsquo;s say the range $\\phi : \\mathbb{R} \\to \\mathbb{R}$ of the function values, which are non-negative, is a finite set $\\left\\{ a_{1} , a_{2}, \\cdots , a_{n} \\right\\}$. If it satisfies $A_{i} = \\phi^{-1} \\left( \\left\\{ a_{i} \\right\\} \\right) \\in \\mathcal{M}$, then $\\phi$ is called a simple function. Simple functions have the following properties:\n(i): If $i \\ne j$, then $A_{i } \\cap A_{j} = \\emptyset$ (ii): $\\displaystyle \\bigsqcup_{k=1}^{n} A_{k} = \\mathbb{R}$ (iii): $\\displaystyle \\phi (x) = \\sum_{k=1}^{n} a_{k} \\mathbb{1}_{A_{k}}(x)$ is a measurable function. Simple functions are, by their very definition, composed of three elements that are too easy to handle. Firstly, since the function values are non-negative, there is no need to consider signs; secondly, being finite makes addition and subtraction flexible; and thirdly, they are measurable. The word simple is used in various ways in different fields of mathematics, but at least in real analysis, it can be considered the opposite of \u0026lsquo;complex\u0026rsquo;. Having defined simple functions that are easy and convenient to handle, it is immediately possible to think of a new integration that covers Riemann integration.\nLebesgue Integration of Simple Functions When $\\phi$ is a simple function and $E \\in \\mathcal{M}$, $\\displaystyle \\int_{E} \\phi dm := \\sum_{k=1}^{n} a_{k} m (A_{k} \\cap E)$ is called the Lebesgue Integral of the simple function $\\phi$. The Lebesgue integral has the following properties:\n[1]: For all $r\u0026gt;0$, $\\displaystyle \\int_{E} a \\phi dm = a \\int_{E} \\phi dm $ [2]: For two simple functions $\\phi , \\psi$, if $\\phi \\le \\psi$, then $\\displaystyle \\int_{E} \\phi dm \\le \\int_{E} \\psi dm$ [3]: If $A, B \\in \\mathcal{M}$ for $A \\cap B = \\emptyset$, then $\\displaystyle \\int_{A \\cup B} \\phi dm = \\int_{A} \\phi dm + \\int_{B} \\phi dm$ $m$ is a Lebesgue measure. However, the condition of being a simple function is too strong and specific to be widely applicable. Adding an idea like the method of exhaustion roughly completes a satisfactory \u0026lsquo;Lebesgue Integral\u0026rsquo;.\nDefinition 1 When $\\phi$ is a simple function, for a non-negative measurable function $f$ and $E \\in \\mathcal{M}$, $$\\displaystyle \\int_{E} f dm := \\sup \\left\\{ \\left. \\int_{E} \\phi dm \\ \\right| \\ 0 \\le \\phi \\le f \\right\\}$$ is called the Lebesgue Integral of the measurable function $f$.\nFundamental Properties The Lebesgue integral has the following properties:\n[1]\u0026rsquo;: For all $r \\ge 0$, $\\displaystyle \\int_{E} r f dm = r \\int_{E} f dm $ [2]\u0026rsquo;: For two simple functions $f, g$, if $f \\le g$, then $\\displaystyle \\int_{E} f dm \\le \\int_{E} g dm$ [3]\u0026rsquo;: If $A, B \\in \\mathcal{M}$ for $A \\cap B = \\emptyset$, then $\\displaystyle \\int_{A \\cup B} f dm = \\int_{A} f dm + \\int_{B} f dm$ [4]\u0026rsquo;: If $A, B \\in \\mathcal{M}$ for $A \\subset B$, then $\\displaystyle \\int_{A} f dm \\le \\int_{B} f dm$ [5]\u0026rsquo;: If $N \\in \\mathcal{N}$, then $\\displaystyle \\int_{N} f dm = 0$ [6]\u0026rsquo;: $\\displaystyle m(E) \\inf_{E} f \\le \\int_{E} f dm \\le m(E) \\sup_{E} f $ Explanation In addition to these basic properties, the following theorem can be considered. Using this theorem, calculations as novel as $\\displaystyle \\int_{\\mathbb{R}} \\mathbb{1}_{\\mathbb{Q}} dm = 0$ can be completed in a single cut. Though not as simple to prove as it appears, it\u0026rsquo;s certainly worth a look at least once.\nTheorem For measurable functions $f \\ge 0$ in a measurable space $( X , \\mathcal{E} )$ and all measurable sets $A \\in \\mathcal{E}$, $$ \\int_{A} f dm = 0 \\iff f = 0 \\text{ a.e.} $$\n$\\text{a.e.}$ means almost everywhere. Proof $( \\implies )$\nIf $E := f^{-1} ( 0 , \\infty)$ for $m(E) = 0$, then $f$ is almost everywhere $f=0$. Assuming $\\displaystyle E_{n} := f^{-1} \\left[ {{1} \\over {n}} , \\infty \\right)$, if $\\displaystyle E = \\bigcup_{n=1}^{\\infty} E_{n}$ while $\\displaystyle \\lim_{n \\to \\infty} E_{n} = E$ holds true. Considering the simple function $\\displaystyle \\phi_{n} := {{1}\\over {n}} \\mathbb{1}_{E_{n}} \\le f$, we have $$ {{1}\\over {n}} m( E_{n} ) = \\int_{A} \\phi_{n} dm \\le \\int_{A} f dm = 0 $$ Therefore, $$ {{1} \\over {n}} m(E_{n}) \\le 0 $$ meaning, for all $n \\in \\mathbb{N}$, $m(E_{n}) = 0$.\n[7]: $E_{n} \\in \\mathcal{M}$, $\\displaystyle E_{n} \\subset E_{n+1} \\implies m \\left( \\bigcup_{n=1}^{\\infty} E_{n} \\right) = \\lim_{n \\to \\infty} m (E_{n})$\nMeanwhile, since $E_{n} \\subset E_{n+1}$, the following holds true: $$ m \\left( \\bigcup_{n=1}^{\\infty} E_{n} \\right) = \\lim_{n \\to \\infty} m (E_{n}) = m(E) = 0 $$\n$( \\impliedby )$\nSince $f$ is almost everywhere $f=0$ and the simple function $\\phi$ satisfies $0 \\le \\phi \\le f$, $\\phi$ is also almost everywhere $\\phi = 0$. Thus, $\\displaystyle \\int_{A} f dm = 0$ is true.\n‚ñ†\nCapinski. (1999). Measure, Integral and Probability: p77.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":527,"permalink":"https://freshrimpsushi.github.io/en/posts/527/","tags":null,"title":"Lebesgue Integration"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Simple Harmonic Motion1 Let\u0026rsquo;s consider the motion of an object hanging on a spring. It oscillates back and forth due to the restoring force of the spring. Such motion is called a harmonic oscillation. The functions representing harmonic oscillation, $\\sin$ and $\\cos$, were called harmonic functions a long time ago, which is why the motion is designated as such. Among harmonic oscillations, those with no friction or other external forces, moving solely by the spring\u0026rsquo;s restoring force, are called simple harmonic oscillations. Let\u0026rsquo;s first find out how the restoring force by the spring is expressed. Let $V(x)$ be the potential energy of a 1-dimensional simple harmonic oscillator. And let\u0026rsquo;s assume it is expressed as an infinite sum of polynomials, a series. Then it can be expressed as follows.\n$$ V(x)=a_{0} + a_{1}x + a_2x^2+ a_{3}x^3 + \\cdots $$\nHowever, since only the difference between two potentials has physical meaning, it is irrelevant to consider the constant term as $0$. It\u0026rsquo;s akin to setting the equilibrium point at $0$. Furthermore, since $-\\dfrac{dV}{dx}=F(x)$ and the restoring force is $F(0)=0$, $V^\\prime(0)=0$ results. That is, the coefficient of the first order term must be $0$. Therefore, the potential of the restoring force is as follows.\n$$ V(x)=a_2x^2+a_{3}x^3+\\cdots $$\nWhen $x$ is sufficiently small, terms of third order and above can be neglected. Ultimately, the restoring force can be determined as follows.\n$$ F(x)=-\\dfrac{dV}{dx}=-2a_2x=-kx \\ \\ (k=2a_2) $$\nAt this time, $k$ is called the modulus of elasticity or the spring constant. And $F(x)=-kx$ is called Hooke\u0026rsquo;s law2. Now let\u0026rsquo;s solve the equation of motion related to the restoring force. $F=ma=m\\ddot{x}$ and the restoring force is $F=-kx$, so the following equation is obtained.\n$$ \\begin{align*} \u0026amp;\u0026amp; m \\ddot{x} \u0026amp; =-kx \\\\ \\implies \u0026amp;\u0026amp; m \\ddot{x} + kx \u0026amp;= 0 \\\\ \\implies \u0026amp;\u0026amp; \\ddot{x} + \\dfrac{k}{m}x \u0026amp;= 0 \\end{align*} $$\nHere, let\u0026rsquo;s substitute ${\\omega_{0}}^2 \\equiv \\dfrac{k}{m}$. The reason for squaring is to simplify the form of the final equation. $\\omega_{0}$ is referred to as the angular frequency of the system. It is also called the natural angular frequency or natural frequency to distinguish from systems in damped and forced oscillation. Now the equation of motion is as follows.\n$$ \\ddot{x} + {\\omega_{0}}^2x=0 $$\nSolving a 2nd Order Differential Equation with Negative Coefficients\nThe solution to a 2nd order differential equation $$ \\dfrac{d^{2}X}{dx^{2}} = -\\alpha^{2}X $$ is as follows.\n$$ X(x) = Ae^{i\\alpha x} + B e^{-i \\alpha x} $$\nThus, the following solution is obtained.\n$$ \\begin{align*} x(t) \u0026amp;=A_{1}e^{i\\omega_{0} t}+A_2e^{-i\\omega_{0} t} \\\\ \u0026amp;=A_{3}\\cos \\omega_{0} t+ A_{4}\\sin \\omega_{0} t \\\\ \u0026amp;=A \\cos (\\omega_{0} t + \\phi) \\end{align*} $$\nHere, $A_{1}$, $A_{2}$, $A_{3}$, $A_{4}$, $A$ are arbitrary complex or real constants, respectively. Usually, it is often represented in the form of cosine or sine functions, like the third equation.\nSee Also Damped Oscillation Forced Oscillation Multi-spring Oscillation Coupled Oscillation Grant R. Fowles and George L. Cassiday, Analytical Mechanics (7th Edition, 2005), p84-86\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAlso known as Hooke\u0026rsquo;s law.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":543,"permalink":"https://freshrimpsushi.github.io/en/posts/543/","tags":null,"title":"Restoring Force and One-Dimensional Simple Harmonic Oscillator"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition 1 If a function $f : E \\to \\overline{\\mathbb{R}}$, excluding a set $E_{0} \\subset E$ where $m(E_{0}) = 0$, has some property $P$, then $f$ is said to have property $P$ almost everywhere within $E$.\nNotation When talking about probability, almost everywhere is expressed as almost surely, and for conciseness, the abbreviation $$ f = g \\text{ a.e.} \\\\ P(E) = 0 \\text{ a.s.} $$ can be used.\nExplanation Simply put, viewing all points except for the null set as \u0026lsquo;almost everywhere.\u0026rsquo; This concept might seem new only because it\u0026rsquo;s formally defined, but it\u0026rsquo;s something already known when learning about definite integrals in high school. Hence, if the upper and lower limits are the same, that integral was inevitably $0$, and whether endpoints were included or not was disregarded when calculating probabilities.\nBasic Properties [1]: If $f : E \\to \\mathbb{R}$ is measurable and almost everywhere within $E$ $f = g$, then $g$ is measurable within $E$. [2]: If $f,g$ is measurable within $E$ and almost everywhere within $E$ $|f| , |g| \u0026lt; \\infty$, then $\\alpha f + \\beta g$ is measurable within $E$. [3]: If $f,g$ is measurable within $E$ and almost everywhere within $E$ $|f| , |g| \u0026lt; \\infty$, then $f g$ is measurable. Proof It\u0026rsquo;s beneficial to try proving these properties by hand at least once, though except for [3], they might not seem very interesting.\n[1] Let\u0026rsquo;s say $E_{0} = \\left\\{ x \\in E \\ | \\ f(x) \\ne g(x) \\right\\}$, then $E_{0} \\subset E$ and $m(E_{0}) = 0$. For any given $c$, $$ \\left\\{ x \\in E \\ | \\ g(x) \u0026gt; c \\right\\} = \\left\\{ x \\in E_{0} \\ | \\ g(x) \u0026gt; c \\right\\} \\cup \\left[ \\left\\{ x \\in E \\ | \\ f(x) \u0026gt; c \\right\\} \\cap ( E \\setminus E_{0} ) \\right] $$, looking at each term on the right, since $\\left\\{ x \\in E_{0} \\ | \\ g(x) \u0026gt; c \\right\\} \\subset E_{0}$, $$ \\left\\{ x \\in E_{0} \\ | \\ g(x) \u0026gt; c \\right\\} \\in \\mathcal{M} $$, since $f$ is measurable within $E$, $$ \\left\\{ x \\in E \\ | \\ f(x) \u0026gt; c \\right\\} \\in \\mathcal{M} $$, and finally, $$ E \\cap (\\mathbb{R} \\setminus E_{0}) = ( E \\setminus E_{0} ) \\in \\mathcal{M} $$, thus $\\left\\{ x \\in E \\ | \\ g(x) \u0026gt; c \\right\\} \\in \\mathcal{M}$ and $g$ is measurable within $E$.\n‚ñ†\n[2] If $\\alpha = 0$, then $\\alpha f$ is measurable and if $\\beta = 0$, then $\\beta g $ is measurable.\nIf $\\alpha \\ne 0$, as $f$ is measurable, for any given $\\displaystyle {{c} \\over {\\alpha}}$, $$ \\left\\{ x \\in E \\ \\left| \\ f(x) \u0026gt; {{c} \\over {\\alpha}} \\right. \\right\\} \\in \\mathcal{M} $$, if $\\alpha\u0026gt; 0$, $$ \\left\\{ x \\in E \\ | \\ \\alpha f(x) \u0026gt; c \\right\\} \\in \\mathcal{M} $$, and if $\\alpha \u0026lt;0$, $$ \\left\\{ x \\in E \\ | \\ \\alpha f(x) \u0026lt; c \\right\\} \\in \\mathcal{M} $$, hence, $\\alpha f$ is measurable and, in the same way, it can be shown that when $\\beta \\ne 0$, $\\beta g$ is measurable.\nNow if $(f + g)$ is measurable, i.e., $\\left\\{ x \\in E \\ | \\ f(x) + g(x) \u0026lt; c \\right\\} \\in \\mathcal{M}$, the proof concludes. Since both functions have finite values, for all $x \\in E$, there exists a $c \\in \\mathbb{R}$ that satisfies $f(x) + g(x) \u0026lt; c$. Rewriting, $f(x) \u0026lt; c - g(x)$ and due to the density of rational numbers, there exists a $q \\in \\mathbb{Q}$ that satisfies $f(x) \u0026lt; q \u0026lt; c - g(x)$. Thus, $$ \\bigcup_{q \\in \\mathbb{Q}} \\left\\{ x \\in E \\ | \\ g(x) \u0026lt; c - q \\right\\} \\cap \\left\\{ x \\in \\ | \\ E f(x) \u0026lt; q \\right\\} = \\left\\{ x \\in E \\ | \\ f(x) + g(x) \u0026lt; c \\right\\} \\in \\mathcal{M} $$\n‚ñ†\nStrategy[3]**: The idea to show that $fg$ is measurable is summarized by one equation $\\displaystyle fg = {{1} \\over {2}} \\left[ (f+ g)^2 - f^2 - g^2\\right]$.\n[3] Since [2] already proved that the sum of measurable functions not diverging in value is measurable, it suffices to demonstrate that $f^2$ is measurable. Since $f$ is measurable, for all $c$, $$ \\left\\{ x \\in E \\ | \\ f(x) \u0026gt; \\sqrt{c} \\right\\} \\in \\mathcal{M} \\\\ \\left\\{ x \\in E \\ | \\ f(x) \u0026lt; - \\sqrt{c} \\right\\} \\in \\mathcal{M} $$, thus, $$ \\left\\{ x \\in E \\ | \\ f(x) \u0026gt; \\sqrt{c} \\right\\} \\cup \\left\\{ x \\in E \\ | \\ f(x) \u0026lt; - \\sqrt{c} \\right\\} = \\left\\{ x \\in E \\ | \\ f^2 (x) \u0026gt; c \\right\\} \\in \\mathcal{M} $$\n‚ñ†\nSee Also Almost everywhere convergence $\\implies$ Convergence in measure Almost sure convergence $\\implies$ Convergence in probability Capinski. (1999). Measure, Integral and Probability: p55.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":524,"permalink":"https://freshrimpsushi.github.io/en/posts/524/","tags":null,"title":"In Measure Theory: Almost Everywhere and Almost Surely"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Summary1 The general solution of a second-order linear homogeneous differential equation with constant coefficients $a y^{\\prime \\prime} + by^\\prime +cy=0$ is as follows.\n$$ y(x)=A e^{r_{1} x}+Be^{r_2 x} $$\nAt this time, $r_{1,2}=\\dfrac{-b \\pm \\sqrt{b^2-4ac}} {2a}$\nCorollary The solution of $a y^{\\prime \\prime} + cy = 0$ is as follows.\n$$ y(x) = A e^{i\\sqrt{\\frac{c}{a}} x}+Be^{-i\\sqrt{\\frac{c}{a}} x} = C\\cos{\\textstyle (\\sqrt{\\frac{c}{a}}x)} + D\\sin{\\textstyle (\\sqrt{\\frac{c}{a}}x)} $$\nSolution $$ \\begin{equation} a\\dfrac{d^2}{dx^2}y+b\\dfrac{d}{dx}y+cy = 0 \\label{eq1} \\end{equation} $$\nFirst, let\u0026rsquo;s define the differential operator $D$ as follows.\n$$ D:=\\dfrac{d}{dx} \\\\ Df = D(f) = \\dfrac{df}{dx} $$\nThen, since $D$ satisfies $D(ay_{1}+y_{2}) = a\\dfrac{dy_{1}}{dx} + \\dfrac{dy_{2}}{dx} = aDy_{1}+Dy_{2}$, it is a linear operator. Using $D$ to express Equation $\\eqref{eq1}$ gives the following.\n$$ \\begin{align} \u0026amp;\u0026amp;aD^2y+bDy+cy\u0026amp;=0 \\\\ \\implies\u0026amp;\u0026amp; (aD^2+bD+c)y\u0026amp;=0 \\end{align} $$\nIf there is a constant $r$ that satisfies $Dy=ry$, then we obtain the following equation from the above equation.\n$$ (aD^2+bD+c) y = (ar^2+br+c) y = 0 $$\nSince we are looking for solutions that satisfy $y \\ne 0$, we obtain the following condition\n$$ aD^{2} + bD + c = ar^{2}+br+c = 0 $$\nThis quadratic equation is called the characteristic equation.\n$$ \\begin{align*} r_{1} \u0026amp;= \\dfrac{-b + \\sqrt{b^2-4ac}} {2a} \\\\ r_2 \u0026amp;=\\dfrac{-b - \\sqrt{b^2-4ac}} {2a} \\end{align*} $$\nLet\u0026rsquo;s say $r_{1}, r_{2}$ are two different real numbers. Then, from the above equations, we obtain the following.\n$$ (aD^2 + bD+c)y=0 \\implies \\ a(D-r_{1})(D-r_2)y=0 $$\nCase 1. $(D-r_{1})y=0$\nIf $\\dfrac{dy}{dx}=r_{1}y$ and we find $y$ through the method of separation of variables, then\n$$ y_{1}(x)=Ae^{r_{1}t} $$\nCase 2. $(D-r_2)y=0$\nSimilarly, if we find $y$, then\n$$ y_{2}(x)=Be^{r_2t} $$\nIf $y_{1}$ and $y_{2}$ are solutions to the given differential equation, then $y_{1}+y_{2}$ is also a solution, so the general solution of the given differential equation is\n$$ y(x)=y_{1}+y_{2}=Ae^{r_{1}t} + Be^{r_2t} $$\n‚ñ†\nWilliam E. Boyce, Boyce\u0026rsquo;s Elementary Differential Equations and Boundary Value Problems (11th Edition, 2017), p103-109\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":540,"permalink":"https://freshrimpsushi.github.io/en/posts/540/","tags":null,"title":"Second-Order Linear Homogeneous Differential Equations with Constant Coefficients and Characteristic Equation"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition 1 A function $f: E \\in \\overline{ \\mathbb{R} }$ is said to be (Lebesgue) measurable if for every interval $I \\subset \\overline{ \\mathbb{R} }$, $$ f^{-1} (I) = \\left\\{ x \\in \\mathbb{R} \\ | \\ f(x) \\in I \\right\\} \\in \\mathcal{M} $$ holds.\n$\\overline{ \\mathbb{R} } = \\mathbb{R} \\cup \\left\\{ - \\infty , + \\infty \\right\\}$ refers to the extended real number space, which includes positive and negative infinity, in the $1$-dimensional Euclidean space. Equivalent Conditions The following propositions are equivalent to each other:\n(1): $f$ is a Lebesgue measurable function. (2): For all $r \\in \\mathbb{R}$, $f^{-1} ( - \\infty , r ] \\in \\mathcal{M}$ holds. (3): For all $r \\in \\mathbb{R}$, $f^{-1} (r, \\infty ) \\in \\mathcal{M}$ holds. (4): For all $r \\in \\mathbb{R}$, $f^{-1} ( - \\infty , r ) \\in \\mathcal{M}$ holds. (5): For all $r \\in \\mathbb{R}$, $f^{-1} [r, \\infty ) \\in \\mathcal{M}$ holds. Theorem [1]: A necessary and sufficient condition for $f$ to be measurable is that for every open set $O$, $f^{-1} ( O ) \\in \\mathcal{M}$ holds. [2]: A necessary and sufficient condition for $f |_{E}$ to be measurable, given $D \\subset E$ and $D \\in \\mathcal{M}$, is that $f |_{D}$ and $f |_{E \\setminus D}$ are measurable. [3]: Continuous functions are measurable. [4]: Indicator functions are measurable. [5]: Monotonic functions are measurable. $f |_{X}$ denotes a contraction mapping that restricts the domain to $X$ and satisfies $f = f |_{X}$. An Indicator Function refers to a function that is $1$ if it belongs to a certain set, and $0$ otherwise. $$\\displaystyle \\mathbb{1}_{E} (x) = \\chi _{E} (x) = \\begin{cases} 1 \u0026amp; , x \\in E \\\\ 0 \u0026amp; , x \\notin E \\end{cases}$$ Note that this definition omits the condition $E \\in \\mathcal{M}$, so care should be taken. Explanation For easier manipulation, it\u0026rsquo;s convenient to use the original definition of pre-image, $f^{-1} (-\\infty , r) = \\left\\{ x \\in E \\ | \\ f(x) \u0026lt; r \\right\\}$.\nIf all intervals $I \\subset \\mathbb{R}$ satisfy $f^{-1} (I) = \\left\\{ x \\in \\mathbb{R} \\ | \\ f(x) \\in I \\right\\} \\in \\mathcal{B}$ under the conditions for a Lebesgue measurable function, it is called Borel measurable and referred to as a Borel function.\nExtended real numbers $\\overline{\\mathbb{R}} : = [ - \\infty, \\infty]$ include infinity as a point along with the entire set of real numbers. Although infinity has been a daunting and difficult concept in analysis, it is now just another entity to conquer. Don\u0026rsquo;t be too afraid, and try to regain the flexible thinking of your high school days.\nConsidering a general measurable space, [1] can also become the definition of a measurable function.\nProof [1] Considering closed intervals, it is sufficient to only consider open intervals since adding two points at each end of a closed interval suffices.\n$(\\Rightarrow)$\nDefining open intervals $A_{k} := (a_{k}, \\infty)$, $B_{k} := (b_{k}, \\infty)$, since $f$ is a measurable function, $$f^{-1} (A_{k}), f^{-1} (B_{k}) \\in \\mathcal{M}$$ any open set $O \\subset \\overline{ \\mathbb{R} }$ can be represented as $\\displaystyle O = \\bigcup_{k=1}^{\\infty} A_{k} \\cap B_{k}$, hence, $$\\displaystyle f^{-1} ( O ) = f^{-1} \\left[ \\bigcup_{k=1}^{\\infty} A_{k} \\cap B_{k} \\right] = \\bigcup_{k=1}^{\\infty} \\left[ f^{-1} (B_{k}) \\cap f^{-1} (B_{k}) \\right]$$ by the properties of the œÉ-field, it follows that $f^{-1} ( O ) \\in \\mathcal{M}$.\n$(\\Leftarrow)$ Since $f^{-1} ( O ) \\in \\mathcal{M}$ holds for all open sets $O \\subset \\overline{ \\mathbb{R} }$, it also holds for all open intervals $(a,b) \\subset \\overline{ \\mathbb{R} }$.\nBy the definition of a measurable function, $f$ is a measurable function.\n‚ñ†\nCapinski. (1999). Measure, Integral and Probability: p57.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":518,"permalink":"https://freshrimpsushi.github.io/en/posts/518/","tags":null,"title":"Lebesgue Measurable Functions"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition 1 Let\u0026rsquo;s assume a probability space $(\\Omega , \\mathcal{F} , P)$ is given.\nFor $P(B)\u0026gt;0$, $\\displaystyle P (A | B) = {{P(A \\cap B)} \\over {P(B)}}$ is called the conditional probability of $A$ given $B$. If $P(A | B) = P(A)$, that is $P( A \\cap B) = P(A) \\cdot P(B)$, then $A, B$ are considered independent. If you haven\u0026rsquo;t yet encountered measure theory, you can ignore the term probability space. Explanation As long as the probability space is well defined, concepts such as conditional probability and independence of events can directly use the definitions from high school level. It\u0026rsquo;s quite natural because the definitions of conditional probability and independence are very intuitive. The reason for mentioning this is to point out \u0026rsquo;nothing changes by introducing measure theory\u0026rsquo;, and to emphasize the contrast when discussing independent variables, conditional expectation.\nAs transformations of conditional probability, the following two laws are obtained. These can be directly applied to Bayes\u0026rsquo; theorem.\nTheorems [1] Multiplication rule of probability: $$ P(A \\cap B) = P(B) P(A | B) $$ [2] Law of total probability: $$ P(C) = \\sum_{i=1}^{k} P(C_{i}) P (C|C_{i}) $$ Capinski. (1999). Measure, Integral and Probability: p47~49.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":521,"permalink":"https://freshrimpsushi.github.io/en/posts/521/","tags":null,"title":"Independence of Events and Conditional Probability"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition The given differential equation\n$\\psi=\\psi (x,y)$\nis said to be an exact differential equation if there exists $\\psi=\\psi (x,y)$ that satisfies\n$\\psi (x,y)$.\nExplanation If the given differential equation is exact, it can be represented as a total differential with respect to $\\psi (x,y)$.\n$d\\psi (x,y)=\\dfrac{\\partial \\psi }{\\partial x}dx + \\dfrac{\\partial \\psi }{\\partial y}dy$\nSince $d\\psi (x,y)=\\dfrac{\\partial \\psi }{\\partial x}dx + \\dfrac{\\partial \\psi }{\\partial y}dy$, it follows that $d\\psi (x,y)=0$ is also true. Hence,\n$d\\psi (x,y)=0$\nThat is, the solution of the differential equation is not represented as a function in the form of $y=y(x)$, but instead as an implicit function in the form of $\\psi (x,y)=C$. Meanwhile, whether the given differential equation is exact or not can be determined according to the following theorem.\nTheorem Let function $M,\\ N,\\ M_{y},\\ N_{x}$ be continuous. The subscript denotes partial differentiation with respect to the indicated variable. Then, the differential equation\n$y=y(x)$\nis exact if and only if\n$\\psi (x,y)=C$.\n$M,\\ N,\\ M_{y},\\ N_{x}$\nProof $(\\implies)$ If $M(x,y)dx+N(x,y)dy=0$ is exact, by definition, there exists $\\psi$ satisfying:\n$(\\implies)$\nTaking partial derivatives with respect to $y, x$ yields: $M(x,y)dx+N(x,y)dy=0$\nBy the assumption of continuity, it follows that:\n$\\psi$\nTherefore,\n$y, x$\nThat is,\n$(\\impliedby)$\n‚ñ†\n$(\\impliedby)$ Assume $M_{y}=N_{x}$. Assume there exists $\\psi (x,y)$ satisfying:\n$M_{y}=N_{x}$\nThen, proving that $\\psi (x,y)$ satisfies $\\psi_{y}=N$ completes the proof. Integrating both sides of $\\eqref{eq1}$ with respect to $x$,\n$\\psi (x,y)$\nSince $\\psi$ is a function of two variables with respect to $x,y$, note that the constant of integration is a function of $y$, denoted as $h(y)$, not just $C$. Differentiating $h(y)$ with respect to $x$ gives $0$. Now, differentiating both sides of $\\eqref{eq2}$ with respect to $y$ again,\n$\\psi (x,y)$\nUpon arranging the equation with respect to $h^{\\prime}(y)$,\n$\\psi_{y}=N$\nObserving this equation reveals that the left side is a function solely of $y$. Hence, the right side must also be, which implies that differentiating the right side with respect to $x$ yields $0$. Differentiating the right side with respect to $x$,\n$\\eqref{eq1}$\nThe third equality is valid under the assumption of $M_{y}=N_{x}$. Since it must hold that $N=N(x,y)$ and it is independent of $N$, the expression inside the parenthesis equals $0$. Therefore,\n$x$\nThus, if $M_{y}=N_{x}$, there exists $\\psi (x,y)$ satisfying $\\psi_{x}=M \\ \\mathrm{and}\\ \\psi_{y}=N$, and the given differential equation is exact.\n‚ñ†\nSee Also Solving Exact Differential Equations ","id":516,"permalink":"https://freshrimpsushi.github.io/en/posts/516/","tags":null,"title":"Definition and Discrimination Method of an Exact Differential Equation"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÍ≤ÄÏ†ï","contents":"Definition 1 The error of rejecting the null hypothesis when it is actually true is called a Type I error. The error of failing to reject the null hypothesis when the alternative hypothesis is true is called a Type II error. The maximum probability of committing a Type I error is called the Significance Level. The statistic used for hypothesis testing is called the Test Statistic. The region of the test statistic\u0026rsquo;s observed values that leads to the rejection of the null hypothesis is called the Rejection Region. Description No matter how much data is accumulated and how sophisticated mathematical techniques are applied, it all means nothing if it can\u0026rsquo;t be used. Here, \u0026rsquo;to use\u0026rsquo; means to derive statistics from some data and make a \u0026lsquo;claim\u0026rsquo; based on those statistics. Naturally, those statistics must be reliable, and the answer to the question of who and by what standard will judge them is hypothesis testing.\nExample Let\u0026rsquo;s consider the data above as the average midterm scores of classes 1 through 15 of the Science Department, Gangbuk High School, Grade 3. At a glance, the average of class 15 is exceptionally high, and standardization makes this even clearer. However, while ranking or comparing whether scores are above or below the overall average is easy, it\u0026rsquo;s difficult to judge \u0026lsquo;how much\u0026rsquo; better or worse someone is. Just a small difference in averages isn\u0026rsquo;t enough to conclusively say who is better; it\u0026rsquo;s like measuring acorns. There must be a certain extent from which one can say \u0026lsquo;it\u0026rsquo;s a different level,\u0026rsquo; but where that line is can be vague.\nConsider that the Z-score follows a t-distribution with degrees of freedom $14$.\nIf we display the probability density function of $t_{14}$ and the distribution of means together, it appears as shown in the image above. The mean of the Z-score is $0$, and a Z-score close to $0$ means that the original data is \u0026rsquo;not far from the mean.\u0026rsquo; On the other hand, original data with a Z-score far from $0$, whether high or low, is difficult to say is similar to the average.\nThe area colored in yellow, combining both sides, is $\\color{red}{0.05}$, indicating the probability of data falling within that range is $\\color{red}{0.05}$. Data belonging here is theoretically a very rare case with a probability of $\\color{red}{5 \\%}$, and the disparity is too significant to be attributed merely to chance. Therefore, if the average score is higher while being different from the mean, maybe it\u0026rsquo;s not just by chance but because of superior skill.\nReturning to our example, it\u0026rsquo;s abnormal for the entire class 15 to have merely \u0026lsquo;happened\u0026rsquo; to score well on the test. If the null hypothesis $H_{0}$ is \u0026lsquo;The average of class 15 does not significantly differ from the overall grade 3 average\u0026rsquo;, we can reject this null hypothesis. The yellow-colored area being the \u0026lsquo;rejection region\u0026rsquo; is hence called the Rejection Region. Furthermore, the area\u0026rsquo;s size when deciding this region is \u0026rsquo;to what extent it is meaningful,\u0026rsquo; hence called the Significance Probability. In short, hypothesis testing supports the statement \u0026lsquo;It\u0026rsquo;s hard to attribute it to just coincidence\u0026rsquo; with statistics. The judgment comes down to whether it falls within the rejection region, and the criterion for this is the significance level.\nUnderstanding the rejection region and significance level as concepts is more important than their exact definitions. Ignoring them because they seem barely relevant or unnecessary can lead to forgetting these fundamental concepts when they\u0026rsquo;re most needed.\nR Code Below is the R code used in this post.\nset.seed(150421);\ravg\u0026lt;-signif(6*rnorm(15)+60,3); names(avg)\u0026lt;-paste0(\u0026#39;(\u0026#39;,(1:15),\u0026#39;)\u0026#39;); avg\rZ = scale(avg)[,1]; Z\rwin.graph()\rplot(0,0,type=\u0026#39;n\u0026#39;,xlim=c(-4,4),ylim=c(-0.08,0.4),xlab=\u0026#39;Z-score\\\u0026#39;,ylab=\u0026#39;t\u0026#39;,main=\u0026#39;Ï§ëÍ∞ÑÍ≥†ÏÇ¨ Í≤∞Í≥º\u0026#39;)\rabline(h=0)\rlines(seq(-5,5,0.01),dt(seq(-5,5,0.01),df=14))\rpoints(x=Z,y=rep(0,15),pch=16)\rtext(x=Z,-0.05,labels=paste0(\u0026#39;(\u0026#39;,(1:15),\u0026#39;)\u0026#39;))\rarrows(Z,-0.04,Z,-0.005,length=0.1)\rwin.graph()\rplot(0,0,type=\u0026#39;n\u0026#39;,xlim=c(-4,4),ylim=c(-0.08,0.4),xlab=\u0026#39;Z-score\\\u0026#39;,ylab=\u0026#39;t\u0026#39;,main=\u0026#39;Ï§ëÍ∞ÑÍ≥†ÏÇ¨ Í≤∞Í≥º\u0026#39;)\rpolygon(c(seq(qt(0.975,14),5,0.01),qt(0.975,14)),\rc(dt(seq(qt(0.975,14),5,0.01),df=14),0),\rcol=\u0026#39;yellow\u0026#39;,lty=0)\rpolygon(c(seq(-5,qt(0.025,14),0.01),qt(0.025,14)),\rc(dt(seq(-5,qt(0.025,14),0.01),df=14),0),\rcol=\u0026#39;yellow\u0026#39;,lty=0)\rabline(h=0)\rlines(seq(-5,5,0.01),dt(seq(-5,5,0.01),df=14))\rwin.graph()\rplot(0,0,type=\u0026#39;n\u0026#39;,xlim=c(-4,4),ylim=c(-0.08,0.4),xlab=\u0026#39;Z-score\\\u0026#39;,ylab=\u0026#39;t\u0026#39;,main=\u0026#39;Ï§ëÍ∞ÑÍ≥†ÏÇ¨ Í≤∞Í≥º\u0026#39;)\rpolygon(c(seq(qt(0.975,14),5,0.01),qt(0.975,14)),\rc(dt(seq(qt(0.975,14),5,0.01),df=14),0),\rcol=\u0026#39;yellow\u0026#39;,lty=0)\rpolygon(c(seq(-5,qt(0.025,14),0.01),qt(0.025,14)),\rc(dt(seq(-5,qt(0.025,14),0.01),df=14),0),\rcol=\u0026#39;yellow\u0026#39;,lty=0)\rabline(h=0)\rlines(seq(-5,5,0.01),dt(seq(-5,5,0.01),df=14))\rpoints(x=Z,y=rep(0,15),pch=16)\rtext(x=Z,-0.05,labels=paste0(\u0026#39;(\u0026#39;,(1:15),\u0026#39;)\u0026#39;))\rarrows(Z,-0.04,Z,-0.005,length=0.1) See Also The complicated definition of the rejection region The difference between Type I and Type II errors Department of Statistics, Kyungpook National University. (2008). Statistics with Excel: p200~201.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":509,"permalink":"https://freshrimpsushi.github.io/en/posts/509/","tags":null,"title":"Rejection Region and Significance Level"},{"categories":"ÌôïÎ•†Î°†","contents":"Definition 1 Let\u0026rsquo;s say $\\mathcal{F}$ is a sigma field of set $\\Omega$.\nMeasurable set $E \\in \\mathcal{F}$ is called an Event. On $\\mathcal{F}$, if measure $P : \\mathcal{F} \\to \\mathbb{R}$ satisfies $P(\\Omega) = 1$, then $P$ is called Probability. $( \\Omega, \\mathcal{F} , P )$ is called the Probability Space. Explanation Borrowing the strength of measure theory, we can provide a mathematical foundation for various concepts of probability theory and remove ambiguity.\nIn high school curriculum or in probability and mathematical statistics, an event was a case that could occur in any experiment. Unlike in mathematical statistics where probability was defined as a function with all events as its domain, now, elements of $\\mathcal{F}$ are considered events and the term sample space is no longer used. The sigma field $\\mathcal{F}$ is defined only as a formal algebraic system with the entire set $\\Omega$, without worrying about exactly what kind of experiment is being conducted. Thus, there can be no ambiguity that might arise from who says what and how. Probability used to be defined as a function with the sample space as its domain and $[0,1]$ as its codomain, satisfying the laws of addition of probabilities. The concept of probability redefined in measure theory does not even allow words like \u0026lsquo;random experiment\u0026rsquo; or \u0026rsquo;number of cases\u0026rsquo;. Considering the definition of measure, this definition of probability completely covers the concept of probability we have been familiar with and rigorously generalizes it. The reason a new term \u0026lsquo;Probability Space\u0026rsquo; is purposely defined is to regard the space $\\Omega$ itself as $P$. As in basic mathematical statistics, if $\\Omega = \\mathbb{R}$, then $\\mathcal{F}$ becomes the Borel sigma field $\\mathcal{B}$, making it meaningless to discuss $(\\Omega , \\mathcal{F})$. It\u0026rsquo;s too simple, meaning that its applicability is limited. With the introduction of measure theory, the world of probability enters a vast phase of generalization that can be overwhelming. If you\u0026rsquo;re planning to study properly, you\u0026rsquo;ll need to be alert to how incredibly set $\\Omega$ can be presented. See Also Probability defined in mathematical statistics Capinski. (1999). Measure, Integral and Probability: p46.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":498,"permalink":"https://freshrimpsushi.github.io/en/posts/498/","tags":null,"title":"Probability Defined by Measure Theory"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Formulas Let\u0026rsquo;s say $\\mathbf{A} = A_{x}\\hat{\\mathbf{x}} + A_{y}\\hat{\\mathbf{y}} + A_{z}\\hat{\\mathbf{z}}, \\mathbf{B} = B_{x}\\hat{\\mathbf{x}} + B_{y}\\hat{\\mathbf{y}} + B_{z}\\hat{\\mathbf{z}}$ is a vector in a 3-dimensional Cartesian coordinate system. Let $n$ be any scalar. Then, the following equations hold:\n(a) $\\dfrac{ d \\left( n \\mathbf{A} \\right) }{dt} = \\dfrac{ dn }{dt} \\mathbf{A} + n\\dfrac{ d\\mathbf{A}}{dt}$\n(b) $\\dfrac{ d ( \\mathbf{A} \\cdot \\mathbf{B} )}{dt} = \\dfrac{ \\mathbf{A} }{dt} \\cdot \\mathbf{B} + \\mathbf{A} \\cdot \\dfrac{ d\\mathbf{B}}{dt}$\n(c) $\\dfrac{ d ( \\mathbf{A} \\times \\mathbf{B}) }{dt} = \\dfrac{ d \\mathbf{A} } {dt} \\times \\mathbf{B} + \\mathbf{A} \\times \\dfrac{ d \\mathbf{B} } {dt}$\nExplanation One can naturally accept the results by recalling the product rule of differentiation that is learned since high school. First, let\u0026rsquo;s calculate the derivative of $\\mathbf{A}$.\n$$ \\begin{align*} \\dfrac{ d \\mathbf{A} } { dt } =\u0026amp; \\dfrac{d}{dt} \\left(A_{x}\\hat{\\mathbf{x}} + A_{y}\\hat{\\mathbf{y}} + A_{z}\\hat{\\mathbf{z}} \\right) \\\\ =\u0026amp; \\dfrac{ d A_{x} }{dt} \\hat{\\mathbf{x}} + A_{x} \\dfrac{d \\hat{\\mathbf{x}}}{dt} + \\dfrac{ d A_{y} }{dt} \\hat{\\mathbf{y}} + A_{y} \\dfrac{d \\hat{\\mathbf{y}}}{dt} + \\dfrac{ d A_{z} }{dt} \\hat{\\mathbf{z}} + A_{z} \\dfrac{d \\hat{\\mathbf{z}}}{dt} \\\\ =\u0026amp; \\dfrac{ d A_{x} }{dt} \\hat{\\mathbf{x}} + \\dfrac{ d A_{y} }{dt} \\hat{\\mathbf{y}} + \\dfrac{ d A_{z} }{dt} \\hat{\\mathbf{z}} \\\\ =\u0026amp; \\left( \\dfrac{ d A_{x} }{dt}, \\dfrac{ d A_{y} }{dt}, \\dfrac{ d A_{z} }{dt} \\right) \\end{align*} $$\nSince the unit vectors in each direction do not change over time, their derivatives are $\\mathbf{0}$. From this result, we can see that the derivative of a vector function is still a vector function. Moreover, it can be seen that the following equation also holds.\n$$ \\left( \\dfrac{ d \\mathbf{A} } {dt} \\right)_{x}=\\dfrac{ d A_{x}}{ dt} $$\nHowever, this equation is not generally valid but only holds in a Cartesian coordinate system, so it must be observed with caution. The equation does not hold when unit vectors change over time. For example, in polar coordinates, velocity and acceleration are as follows.\n$$ \\begin{align*} \\mathbf{v}=\u0026amp;\\dot{r} \\hat{\\mathbf{r}} + r \\dot{\\theta} \\hat{\\boldsymbol{\\theta}} \\\\ \\mathbf{a}=\u0026amp; (\\ddot r -r\\dot{\\theta} ^2)\\hat{\\mathbf{r}} + (2\\dot{r} \\dot{\\theta} + r\\ddot{\\theta})\\hat{\\boldsymbol{\\theta}} \\end{align*} $$\nThen, one can see that the following equality does not hold.\n$$ \\left( \\dfrac{d \\mathbf{v}}{dt} \\right)_{\\theta} = a_{\\theta} = 2\\dot{r} \\dot{\\theta} + r\\ddot{\\theta} \\ne \\dot{r}\\dot{\\theta} + r\\ddot{\\theta} = \\dfrac{d v_{\\theta}}{dt} $$\nProof (a) $$ \\begin{align*} \\dfrac{ d (n\\mathbf{A}) }{ dt} =\u0026amp; \\dfrac{ d}{dt} (nA_{x}\\hat{\\mathbf{x}} + nA_{y}\\hat{\\mathbf{y}} + nA_{z} \\hat{\\mathbf{z}}) \\\\ =\u0026amp; \\left( \\dfrac{dn}{dt}A_{x} + n\\dfrac{dA_{x}}{dt} \\right) \\hat{\\mathbf{x}} +\\left( \\dfrac{dn}{dt}A_{y} + n \\dfrac{dA_{y}}{dt} \\right) \\hat{\\mathbf{y}} + \\left( \\dfrac{ dn }{ dt } A_{z} + n \\dfrac{ d A_{z} }{dt } \\right) \\hat{\\mathbf{z}} \\\\ =\u0026amp; \\dfrac{dn}{dt} \\left( A_{x} \\hat{\\mathbf{x}} + A_{y} \\hat{\\mathbf{y}} + A_{z} \\hat{\\mathbf{z}}\\right) + n \\left( \\dfrac{ dA_{x}}{dt}\\hat{\\mathbf{x}} + \\dfrac{dA_{y}}{dt}\\hat{\\mathbf{y}} + \\dfrac{dA_{z}}{dt} \\hat{\\mathbf{z}} \\right) \\\\ =\u0026amp; \\dfrac{ dn } {dt } \\mathbf{A} + n\\dfrac{ d \\mathbf{A} }{ dt } \\end{align*} $$\n‚ñ†\n(b) $$ \\begin{align*} \\dfrac{ d (\\mathbf{A} \\cdot \\mathbf{B})} {dt} =\u0026amp; \\dfrac{d}{dt}\\left( A_{x}B_{x} + A_{y}B_{y} + A_{z}B_{z} \\right) \\\\ =\u0026amp; \\left( {\\color{blue}\\dfrac{ d A_{x}}{dt}B_{x}} + A_{x}\\dfrac{ d B_{x}}{dt} \\right) + \\left( {\\color{blue}\\dfrac{ dA_{y}}{dt}B_{y} } + A_{y}\\dfrac{d B_{y}}{dt} \\right) + \\left( {\\color{blue} \\dfrac{ d A_{z}}{dt}B_{z} }+ A_{z}\\dfrac{dB_{z}}{dt}\\right) \\\\ =\u0026amp; \\left( {\\color{blue}\\dfrac{ d A_{x}}{dt}B_{x} + \\dfrac{ dA_{y}}{dt}B_{y} + \\dfrac{ d A_{z}}{dt}B_{z} } \\right) + \\left( A_{x}\\dfrac{ d B_{x}}{dt} + A_{y}\\dfrac{d B_{y}}{dt} + A_{z}\\dfrac{dB_{z}}{dt} \\right) \\\\ =\u0026amp; \\left[ \\left( \\dfrac{ d \\mathbf{A}}{dt}\\right)_{x}B_{x} + \\left(\\dfrac{ d\\mathbf{A}}{dt}\\right)_{y}B_{y} + \\left( \\dfrac{ d \\mathbf{A}}{dt}\\right)_{z}B_{z} \\right] + \\left[ A_{x} \\left( \\dfrac{ d \\mathbf{B}}{dt} \\right)_{x} + A_{y} \\left( \\dfrac{d \\mathbf{B}}{dt}\\right)_{y} + A_{z} \\left( \\dfrac{d \\mathbf{B} }{dt} \\right)_{z}\\right] \\\\ =\u0026amp;\\dfrac{d\\mathbf{A}}{dt}\\cdot \\mathbf{B} + \\mathbf{A}\\cdot \\dfrac{d\\mathbf{B}}{dt} \\end{align*} $$\n‚ñ†\n(c) $$ \\begin{align*} \\dfrac{d( \\mathbf{A} \\times \\mathbf{B}) }{ dt } =\u0026amp; \\dfrac{ d}{dt} \\left[ \\hat{\\mathbf{x}} (A_{y}B_{z}-A_{z}B_{y})+ \\hat{\\mathbf{y}} (A_{z}B_{x}-A_{x}B_{z}) + \\hat{\\mathbf{z}} (A_{x}B_{y}-A_{y}B_{x}) \\right] \\\\ =\u0026amp; \\hat{\\mathbf{x}} \\left( {\\color{blue} \\dfrac{ dA_{y}}{dt}B_{z} } +A_{y}\\dfrac{d B_{z}}{dt} {\\color{blue} -\\dfrac{d A_{z}}{dt}B_{y} } ‚ÄìA_{z}\\dfrac{B_{y}}{dt} \\right) + \\hat{\\mathbf{y}} \\left( {\\color{blue} \\dfrac{ dA_{z}}{dt}B_{x} } +A_{z}\\dfrac{d B_{x}}{dt} {\\color{blue} -\\dfrac{d A_{x}}{dt}B_{z} } ‚ÄìA_{x}\\dfrac{B_{z}}{dt} \\right) \\\\ \u0026amp;\\quad + \\hat{\\mathbf{z}} \\left( {\\color{blue} \\dfrac{ dA_{x}}{dt}B_{y} } +A_{x}\\dfrac{d B_{y}}{dt} {\\color{blue} -\\dfrac{d A_{y}}{dt}B_{x} } ‚ÄìA_{y}\\dfrac{B_{x}}{dt} \\right) \\\\ =\u0026amp; {\\color{blue} \\left[ {\\color{black} \\hat{\\mathbf{x}} \\left( \\dfrac{ dA_{y}}{dt}B_{z}-\\dfrac{d A_{z}}{dt}B_{y}\\right) + \\hat{\\mathbf{y}} \\left( \\dfrac{ dA_{z}}{dt}B_{x}-\\dfrac{d A_{x}}{dt}B_{z} \\right) + \\hat{\\mathbf{z}} \\left( \\dfrac{ dA_{x}}{dt}B_{y}-\\dfrac{d A_{y}}{dt}B_{x} \\right)} \\right] } \\\\ \u0026amp;\\quad + \\left[ \\hat{\\mathbf{x}} \\left( A_{y}\\dfrac{d B_{z}}{dt}-A_{z}\\dfrac{d B_{y}}{dt} \\right) + \\hat{\\mathbf{y}} \\left( A_{z}\\dfrac{d B_{x}}{dt}-A_{x}\\dfrac{d B_{z}}{dt} \\right) + \\hat{\\mathbf{z}} \\left( A_{x}\\dfrac{d B_{y}}{dt}-A_{y}\\dfrac{d B_{x}}{dt} \\right) \\right] \\\\ =\u0026amp; \\dfrac{d\\mathbf{A}}{dt} \\times \\mathbf{B} + \\mathbf{A} \\times \\dfrac{d \\mathbf{B}}{dt} \\end{align*} $$\n‚ñ†\n","id":506,"permalink":"https://freshrimpsushi.github.io/en/posts/506/","tags":null,"title":"Differentiation of Vectors, Dot Product, and Cross Product in Cartesian Coordinates"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Kinetic Energy1 When the force depends only on the position, i.e., it is independent of the velocity or time, the equation of motion (differential equation) for the straight-line motion of a particle is as follows.\n$$ \\begin{equation} F(x)=m\\ddot{x} \\label{force1} \\end{equation} $$\nIn this case, acceleration $\\ddot{x}$ can be expressed in terms of velocity as follows.\n$$ \\begin{align*} \\ddot{x} \u0026amp;= \\dfrac{d \\dot{x}}{dt} \\\\ \u0026amp;=\\dfrac{dv}{dt} \\\\ \u0026amp;=\\dfrac{dv}{dx} \\dfrac{dx}{dt} \\\\ \u0026amp;=v\\dfrac{dv}{dx} \\\\ \u0026amp;= \\frac{1}{2}\\frac{ d (v^{2})}{ dx } \\end{align*} $$\nSubstituting this into $\\eqref{force1}$,\n$$ F(x)=m\\ddot{x}= m\\frac{1}{2}\\frac{d(v^{2})}{dx}=\\frac{ d }{ dx }\\left( \\frac{1}{2}mv^{2} \\right) $$\nThe physical quantity inside the parentheses in the above equation is defined as the particle\u0026rsquo;s kinetic energy and is denoted by $T$.\n$$ T=\\dfrac{1}{2}mv^2 $$\nThen, the equation of motion $\\eqref{force1}$ can be expressed as follows.\n$$ F(x)=\\dfrac{dT}{dx} $$\nThe symbol for kinetic energy is often written as $K$ or $E_{K}$, following the first letter of kinetic.\nPotential Energy Now, let\u0026rsquo;s define a function $V(x)$ as follows.\n$$ -\\dfrac{dV(x)}{dx}=F(x) $$\nThe function $V(x)$ defined as above is called potential energy2. Then, it can be written as follows, like the kinetic energy.\n$$ -\\frac{ d V(x)}{ d x}=F(x)=\\frac{ d T}{ d x} $$\nIntegrating the above equation from the initial position $x_{0}$ to the later position $x_{1}$ results in the following.\n$$ -V(x_{1}) +V(x_{0}) =T_{1}-T_{0} $$\nWhat this equation means is that during an object\u0026rsquo;s motion, the change in potential energy is the same in magnitude but opposite in sign to the change in kinetic energy. That is, if one increases, the other decreases by an equal amount. This implies that their sum is always constant. Therefore, let\u0026rsquo;s denote the sum of the two as the particle\u0026rsquo;s total energy or mechanical energy and mark it as $E$.\n$$ E=T_{0}+V(x_{0})=T_{1}+V_{x_{1}} $$\nThis equation is called the energy equation. As seen above, if the force can be obtained from a position-dependent function, the potential energy $V(x)$, the mechanical energy of the particle is conserved; therefore, that force is called a conservative force. In cases where the force is not a conservative force, i.e., when there is no position-dependent potential energy, it is called a nonconservative force. When a nonconservative force acts on an object, the mechanical energy of the object is not conserved.\nGrant R. Fowles and George L. Cassiday, Analytical Mechanics (7th Edition, 2005), p63-64\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nÎùºÎñºÎäî ÏúÑÏπò ÏóêÎÑàÏßÄÎùºÍ≥† Î∂àÎ†ÄÎã§. Ï†ïÌôïÌïòÍ≤å ÎßêÌïòÏûêÎ©¥ \u0026lsquo;ÏúÑÏπò ÏóêÎÑàÏßÄ=Ï§ëÎ†•Ïùò ÌçºÌÖêÏÖú ÏóêÎÑàÏßÄ\u0026rsquo;Ïù¥Îã§.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":507,"permalink":"https://freshrimpsushi.github.io/en/posts/507/","tags":null,"title":"Kinetic and Potential Energy Definitions in Physics"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition1 A first-order differential equation is said to be separable if it satisfies the following condition:\n$$ f(x)+g(y)\\dfrac{dy}{dx}=0 \\quad \\text{or} \\quad f(x)dx = -g(y)dy $$\nExplanation It can be expressed in various forms, but the important point is that the variables on each side must be separated. The method of finding solutions by separating these two variables is called the method of separation of variables.\nThe separability is a very good condition; if a given differential equation is separable, its solution can be easily obtained. On the other hand, if it is not separable, various methods are used to make it into a separable form. In other words, there are various ways to solve a first-order differential equation, but essentially, it all comes down to separation of variables.\nSolution $$ \\begin{align*} \u0026amp;\u0026amp; g(y)\\dfrac{dy}{dx} + f(x)\u0026amp;=0 \\\\ \\implies \u0026amp;\u0026amp; g(y)\\dfrac{dy}{dx} \u0026amp;=-f(x) \\\\ \\implies \u0026amp;\u0026amp; g(y)dy \u0026amp;=-f(x)dx \\\\ \\implies \u0026amp;\u0026amp; \\int g(y)dy\u0026amp; =-\\int f(x)dx+C \\end{align*} $$\nHere, $C$ is the integration constant. After integration, the left-hand side should be arranged with respect to $y$.\n‚ñ†\nExample Find the general solution of $\\dfrac{dy}{dx}+y=0$.\n$$ \\begin{align*} \u0026amp;\u0026amp;\\dfrac{dy}{dx}\u0026amp; =-y \\\\ \\implies \u0026amp;\u0026amp; \\dfrac{1}{y}dy\u0026amp;=-dx \\\\ \\implies \u0026amp;\u0026amp; \\int \\dfrac{1}{y} dy \u0026amp;=-\\int dx \\\\ \\implies \u0026amp;\u0026amp;\\ln y \u0026amp;=-x+C \\\\ \\implies \u0026amp;\u0026amp; y\u0026amp;=e^{-x+C}=e^{-x}e^C=Ce^{-x} \\end{align*} $$ If the initial value is $y(0)=y_{0}$, then because of $y(0)=C=y_{0}$, we have\n$$ y(x)=y_{0}e^{-x} $$\n‚ñ†\nRadioactive Decay of Nuclei The number of radioactive nuclei decaying per unit time is proportional to the number of nuclei $N$.\n$$ \\dfrac{dN}{dt}=-\\lambda N $$\nHere, $\\lambda$ is the decay constant.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\dfrac{dN}{dt} \u0026amp;=-\\lambda N \\\\ \\implies \u0026amp;\u0026amp; \\dfrac{1}{N}dN\u0026amp;=-\\lambda dt \\\\ \\implies \u0026amp;\u0026amp; \\int \\dfrac{1}{N}dN \u0026amp;=-\\int \\lambda dt \\\\ \\implies \u0026amp;\u0026amp; \\ln N \u0026amp;=-\\lambda t+C \\\\ \\implies \u0026amp;\u0026amp; N\u0026amp;=Ce^{-\\lambda t} \\end{align*} $$\nIf the initial value is $N(0)=N_{0}$, then because of $N(0)=C=N_{0}$, we have\n$$ N(t)=N_{0}e^{-\\lambda t} $$\n‚ñ†\nWilliam E. Boyce, Boyce\u0026rsquo;s Elementary Differential Equations and Boundary Value Problems (11th Edition, 2017), p33-37\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":503,"permalink":"https://freshrimpsushi.github.io/en/posts/503/","tags":null,"title":"Separable First-Order Differential Equations"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let us consider a set of functions that are differentiable up to n times, denoted by $S=\\left\\{ f_{1}, f_{2}, \\dots, f_{n} \\right\\}$. The Wronskian $W$ of this set is defined by the following determinant.\n$$ W(x) = W(f_{1}, f_{2}, \\dots, f_{n}) := \\begin{vmatrix} f_{1} \u0026amp; f_{2} \u0026amp; \\cdots \u0026amp; f_{n} \\\\ f_{1}^{\\prime} \u0026amp; f_2^{\\prime} \u0026amp; \\cdots \u0026amp; f_{n}^{\\prime} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ f_{1}^{(n-1)} \u0026amp; f_{2}^{(n-1)} \u0026amp; \\cdots \u0026amp; f_{n}^{(n-1)} \\end{vmatrix} $$\nExplanation The set of differentiable functions constitutes a vector space, known as the function space. While there is no general method to determine the linear independence/dependence of a set of functions, the Wronskian can be used to ascertain linear independence for differentiable functions.\nIt is crucial to understand that the theorem introduced below is not bidirectional. It is essential to realize that the converse does not hold. If $W(x) \\ne 0$, it signifies linear independence, but if $W(x)=0$, it does not determine whether the set is independent or dependent.\nTheorem Let $S$ be the set as defined here. If the Wronskian of $S$ is not $0$, then $S$ is linearly independent.\nProof The proof is by contrapositive. In other words, if $S$ is linearly dependent, then the Wronskian $W$ is always $0$.\nAssume $S=\\left\\{ f_{1},\\ f_{2},\\ \\cdots,\\ f_{n} \\right\\}$ to be linearly dependent. Then, by definition, there exists a non-$0$ $k_{i}(i=1,2,\\dots,n)$ satisfying the equation below.\n$$ \\begin{equation} k_{1} f_{1} + k_{2} f_{2} + \\cdots + k_{n} f_{n} = 0 \\label{eq1} \\end{equation} $$\nDifferentiating the above equation yields:\n$$ \\begin{align*} k_{1} f_{1}^{\\prime} + k_{2} f_{2}^{\\prime} + \\cdots + k_{n} f_{n}\u0026rsquo;\u0026amp;=0 \\\\ k_{1} f_{1}^{(2)} + k_{2} f_{2}^{(2)} + \\cdots + k_{n} f_{n}^{(2)}\u0026amp;=0 \\\\ \\vdots\u0026amp; \\\\ k_{1} f_{1}^{(n-1)} + k_{2} f_{2}^{(n-1)} + \\cdots + k_{n} f_{n}^{(n-1)} \u0026amp;=0 \\end{align*} $$\nConverting this system of equations into matrix representation results in:\n$$ \\begin{align*} \\begin{pmatrix} f_{1} \u0026amp; f_{2} \u0026amp; \\cdots \u0026amp; f_{n} \\\\ f_{1}^{\\prime} \u0026amp; f_2^{\\prime} \u0026amp; \\cdots \u0026amp; f_{n}^{\\prime} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ f_{1}^{(n-1)} \u0026amp; f_{2}^{(n-1)} \u0026amp; \\cdots \u0026amp; f_{n}^{(n-1)} \\end{pmatrix} \\begin{pmatrix} k_{1} \\\\ k_{2} \\\\ \\vdots \\\\ k_{n} \\end{pmatrix} \u0026amp;= \\begin{pmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix} \\\\ \\mathbf{F} \\mathbf{k} \u0026amp;= \\mathbf{0} \\end{align*} $$\nIn this case, the above equation has a nontrivial solution $\\mathbf{k} \\ne \\mathbf{0}$. Therefore, by equivalence, $\\mathbf{F}$ is not an invertible matrix, and its determinant is $0$. Since the determinant of $\\mathbf{F}$ is the Wronskian,\n$$ W(x) = 0,\\quad \\forall x \\in \\mathbb{R}. $$\nHence, if $S$ is linearly dependent, the Wronskian $W$ is always $0$.\n‚ñ†\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p234-235\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":501,"permalink":"https://freshrimpsushi.github.io/en/posts/501/","tags":null,"title":"Wronskian Definition and Determination of Linear Independence"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definition 1 Let us define the function $m : \\mathcal{M} \\to [0,\\infty]$ with respect to $E \\in \\mathcal{M}$ as follows $m(E) := m^{ \\ast } (E)$. $m$ is called the (Lebesgue) measure.\n$\\mathcal{M}$ is a sigma-algebra, the set of measurable sets of $X = \\mathbb{R}$. $m^{\\ast}$ is an outer measure. Description The outer measure was neatly defined by $m^{ \\ast } : \\mathscr{P}( \\mathbb{R} ) \\to [0, \\infty]$, but it left something to be desired as a generalization of length. Limiting its domain to the real numbers\u0026rsquo; sigma-field completed the ideal \u0026lsquo;generalization of length.\u0026rsquo; This can be seen as a step back conditionally to meet the Carath√©odory condition.\nOf course, this is a special case in $X = \\mathbb{R}$ when compared to general measures.\nBasic Properties Assuming $A, B, E \\in \\mathcal{M}$ and for all $n \\in \\mathbb{N}$, let\u0026rsquo;s say $A_{n}, B_{n}, \\in \\mathcal{M}$. The measure has the following properties:\n[1]: $$A \\subset B \\implies m(A) \\le m(B)$$ [2]: If $A \\subset B$ then, $$m(A) \u0026lt; \\infty \\implies m(B \\setminus A) = m(B) - m(A)$$ [3]: $$t \\in \\mathbb{R} \\implies m(E) = m(E + t)$$ [4]: $$m(A \\triangle B) = 0 \\implies B \\in \\mathcal{M} \\\\ m(A) = m(B)$$ [5]: For all $\\varepsilon \u0026gt; 0, A \\subset \\mathbb{R}$, there exists an open $O$ that satisfies the following. $$ A \\subset O \\\\ m(O) \\le m^{ \\ast }(A) + \\varepsilon $$ [6]: For all $A \\subset \\mathbb{R}$, there exists a sequence of open sets $\\left\\{ O_{n} \\right\\}$ that satisfies the following. $$ A \\subset \\bigcap_{n} O_{n} \\\\ m \\left( \\bigcap_{n} O_{n} \\right) = m^{ \\ast }(A) $$ [7]: $$\\displaystyle A_{n} \\subset A_{n+1} \\implies m \\left( \\bigcup_{n=1}^{\\infty} A_{n} \\right) = \\lim_{n \\to \\infty} m (A_{n})$$ [8]: If $A_{n+1} \\subset A_{n}$ then, $$\\displaystyle m(A_{1}) \u0026lt; \\infty \\implies m \\left( \\bigcap_{n=1}^{\\infty} A_{n} \\right) = \\lim_{n \\to \\infty} m (A_{n})$$ [9]: $$\\displaystyle m \\left( \\bigsqcup_{i=1}^{n} A_{i} \\right) = \\sum_{i = 1}^{n} m (A_{i})$$ [10]: $m$ is continuous in $\\emptyset$. [11]: $$B_{n} \\to \\emptyset \\implies m(B_{n}) \\to 0$$ $A \\triangle B = ( A \\setminus B ) \\cup ( B \\setminus A )$ is true. Proof [1] Since $m = m^{ \\ast } |_{\\mathcal{M}}$, it naturally follows from the properties of outer measure.\n‚ñ†\n[2] First, it\u0026rsquo;s necessary to prove $(B \\setminus A) \\in \\mathcal{M}$. Given $(B \\setminus A) = B \\cap (\\mathbb{R} \\setminus A) = B \\cap A^{c}$ since $A \\in \\mathcal{M}$, thus $A^{c} \\in \\mathcal{M}$. Therefore, $(B \\setminus A) \\in \\mathcal{M}$ and $(B \\setminus A ) \\cap A = \\emptyset$ and $(B \\setminus A ) \\cup A = B$, thus $m(B \\setminus A ) + m(A) = m(B)$ is true. Assuming $m(A) \u0026lt; \\infty$, rearranging gives $m(B \\setminus A) = m(B) - m(A)$.\n‚ñ†\n[3] Since $m = m^{ \\ast } |_{\\mathcal{M}}$, it naturally follows from the properties of outer measure.\n‚ñ†\n[4] Since $B = (A \\cap B) \\cup (B \\setminus A) = A \\setminus (A \\setminus B) \\cup (B \\setminus A)$, $B \\in \\mathcal{M}$ is true. Meanwhile, since $m(A \\triangle B) = 0$, $m(A \\setminus B) = 0$ and $m(B \\setminus A) = 0$. Therefore, $$ m(B) = m( B \\setminus A) + m(B \\cap A) = m( A \\setminus B) + m(A \\cap B) = m(A) $$\n‚ñ†\n[7] If we assume $B_{n} :=A_{n} \\setminus A_{n-1}$, for $i \\ne j$, $B_{i} \\cap B_{j} = \\emptyset$ and $\\displaystyle \\bigcup_{n=1}^{\\infty} A_{n} = \\bigsqcup_{n=1}^{\\infty} B_{n}$ are true. Therefore, $$ m \\left( \\bigcup_{n=1}^{\\infty} A_{n} \\right) = m \\left( \\bigsqcup_{n=1}^{\\infty} B_{n} \\right) = \\sum_{n=1}^{\\infty} m(B_{n}) = \\lim_{n \\to \\infty} \\sum_{k=1}^{n} m(B_{k}) = \\lim_{n \\to \\infty} m \\left( \\bigsqcup_{k=1}^{n} B_{k} \\right) = \\lim_{n \\to \\infty} m \\left( A_{n} \\right) $$\n‚ñ†\n[8] Since $(A_{1} \\setminus A_{n} ) \\subset (A_{1} \\setminus A_{n+1} )$, by [7] $$ m \\left( \\bigcup_{n=1}^{\\infty} ( A_{1} \\setminus A_{n} ) \\right) = \\lim_{ n \\to \\infty} m (A_{1} \\setminus A_{n}) $$ And since $m(A_{n}) \u0026lt; \\infty$, by [3] $$ m (A_{1} \\setminus A_{n}) = m(A_{1}) - m(A_{n}) $$ Meanwhile, since $\\displaystyle \\bigcup_{n=1}^{\\infty} (A_{1} \\setminus A_{n}) = A_{1} \\setminus \\bigcap_{n=1}^{\\infty} A_{n}$ $$ m \\left( \\bigcup_{n=1}^{\\infty} (A_{1} \\setminus A_{n}) \\right) = m \\left( A_{1} \\right) - m \\left( \\bigcap_{n=1}^{\\infty} A_{n} \\right) $$ Summarizing, $$ m \\left( \\bigcup_{n=1}^{\\infty} (A_{1} \\setminus A_{n}) \\right) = m(A_{1}) - \\lim_{n \\to \\infty} m(A_{n}) = m \\left( A_{1} \\right) - m \\left( \\bigcap_{n=1}^{\\infty} A_{n} \\right) $$ Therefore, $\\displaystyle \\lim_{n \\to \\infty} m(A_{n}) = m \\left( \\bigcap_{n=1}^{\\infty} A_{n} \\right)$\n‚ñ†\nGeneralization Generalization of measures Capinski. (1999). Measure, Integral and Probability: p35.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":494,"permalink":"https://freshrimpsushi.github.io/en/posts/494/","tags":null,"title":"Lebesgue Measure"},{"categories":"Ï∏°ÎèÑÎ°†","contents":"Definitions For a set $X \\ne \\emptyset$, $\\mathcal{E} \\subset \\mathscr{P} (X)$ is called a Sigma Algebra or Sigma Field on $X$ if it satisfies the conditions below. The ordered pair $(X , \\mathcal{E})$ of the set $X$ and the sigma field $\\mathcal{E}$ is called a Measurable Space.\n(i): $\\emptyset \\in \\mathcal{E}$ (ii): $E \\in \\mathcal{E} \\implies E^{c} \\in \\mathcal{E}$ (iii): $\\displaystyle \\left\\{ E_{n} \\right\\}_{n \\in \\mathbb{N}} \\subset \\mathcal{E} \\implies \\bigcup_{n=1}^{\\infty} E_{n} \\in \\mathcal{E}$ (iv): $\\displaystyle \\left\\{ E_{n} \\right\\}_{n \\in \\mathbb{N}} \\subset \\mathcal{E} \\implies \\bigcap_{n=1}^{\\infty} E_{n} \\in \\mathcal{E}$ Description Given a space $X$ and a sigma field $\\mathcal{E}$, $(X , \\mathcal{E})$ is called a Measurable Space. If a measure $\\mu$ is provided, it is called a measure space, and specifically, if the measure $\\mu$ is a probability, it is referred to as a probability space.\nThe same concept is called Sigma Algebra in mathematics and Sigma Field in statistics.\nCarath√©odory\u0026rsquo;s condition: If $E \\subset \\mathbb{R}$ satisfies $m^{ \\ast }(A) = m^{ \\ast } ( A \\cap E ) + m^{ \\ast } ( A \\cap E^{c} )$ for $A \\subset \\mathbb{R}$, $E$ is called a Measurable Set and is denoted as $E \\in \\mathcal{M}$.\nA \u0026lsquo;Measurable Set\u0026rsquo; simply means a set that can be measured. From the monotonicity of the outer measure, $$m^{ \\ast }(A) \\le m^{ \\ast } ( A \\cap E ) + m^{ \\ast } ( A \\cap E^{c} )$$ is trivial, so verifying whether a set is measurable boils down to checking if $$m^{ \\ast }(A) \\ge m^{ \\ast } ( A \\cap E ) + m^{ \\ast } ( A \\cap E^{c} )$$ is true.\nThe Sigma Algebra of Measurable Sets With the definitions provided above, the collection $\\mathcal{M}$ of measurable sets of $X = \\mathbb{R}$ turns into a sigma algebra with the following properties.\n$\\mathcal{M}$ is a sigma algebra with the properties below.\n[1]: $$ \\emptyset \\in \\mathcal{M} $$ [2]: $$ E \\in \\mathcal{M} \\implies E^{c} \\in \\mathcal{M} $$ [3]: $$ \\left\\{ E_{n} \\right\\}_{n \\in \\mathbb{N}} \\subset \\mathcal{M} \\implies \\bigcup_{n=1}^{\\infty} E_{n} \\in \\mathcal{M} $$ [4]: $$ \\left\\{ E_{n} \\right\\}_{n \\in \\mathbb{N}} \\subset \\mathcal{M} \\implies \\bigcap_{n=1}^{\\infty} E_{n} \\in \\mathcal{M} $$ [5]: $$ \\mathcal{N} \\subset \\mathcal{M} $$ [6]: $$ \\mathcal{I} \\subset \\mathcal{M} $$ [7]: If we denote it as $E_{i} , E_{j} \\in \\mathcal{M}$, the following is true. $$ E_{i} \\cap E_{j} = \\emptyset , \\forall i \\ne j \\implies m^{ \\ast } \\left( \\bigcup_{n=1}^{\\infty} E_{n} \\right) = \\sum_{n = 1} ^{\\infty} m^{ \\ast } ( E_{n}) $$ $\\mathcal{I}$ is the set of all intervals, $\\mathcal{N}$ is the set of all null sets. Especially, note that [7] is a property absolutely necessary for the \u0026lsquo;generalization of length\u0026rsquo;, which Lebesgue could only dream of.\n","id":490,"permalink":"https://freshrimpsushi.github.io/en/posts/490/","tags":null,"title":"Sigma Algebra and Measurable Spaces"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 Let\u0026rsquo;s say we have a topological space $\\left( X, \\mathscr{T} \\right)$.\nA set $\\mathscr{O} \\subset \\mathscr{T}$ consisting of open sets of $X$ is called an open covering of $A$ if it satisfies the following: $$ A \\subset \\bigcup_{O \\in \\mathscr{O}} O $$ A subset $\\mathscr{O} ' $ of $\\mathscr{O}$ is called a subcover of $\\mathscr{O}$. If the cardinality of $\\mathscr{O} ' $ is a natural number, it is called a finite subcover. $X$ is said to be compact if every open cover of $X$ has a finite subcover. In other words, for every open cover $\\mathscr{O}$, if there exists a finite set $\\mathscr{O} ' = \\left\\{ O_{1} , \\cdots , O_{n} \\right\\} \\subset \\mathscr{O}$ satisfying the following, then $X$ is compact: $$ X = \\bigcup_{i=1}^{n} O_{i} $$ If a subspace $A$ of $X$ is compact as a subspace, then $A$ is said to be compact. Let\u0026rsquo;s consider $X$ as a topological space. A subset $K$ is said to be precompact or relatively compact if the closure $\\overline{K}$ of $K$ is compact. Explanation Compactness Considering how useful the condition of compactness was in introductory analysis, it\u0026rsquo;s natural to seek its generalization. While the generalization might have made the terminology more complex, the essence hasn\u0026rsquo;t changed.\nIn fact, compactness is crucially applied in various theories. Being compact implies that a set can be considered in finite pieces, making it an excellent condition for rigorous proofs. Conversely, demonstrating that a certain set $A$ appearing in a proof is indeed compact often becomes a key part of the argument.\nPrecompactness Precompactness suggests that even if $K$ itself is not compact, taking the closure of $K$ results in a compact set, indicating the potential for $K$ to become compact. In metric spaces, this is also known as a totally bounded space. The alternative term relatively compact comes from the relative nature of closure; if $K$ is considered not as a subspace but as the entire space itself, then $K$ is closed in $K$, making $\\overline{K}$ compact, which essentially means $K$ is (relatively) compact.\nPrecompactness can also be defined in terms of sequences:\n$K \\subset X$ is precompact if, for every sequence $\\left\\{ x_{n} \\right\\} \\subset K$ defined in $K$, there exists a subsequence $\\left\\{ x_{n '} \\right\\} \\subset \\left\\{ x_{n} \\right\\}$ that converges to $x \\in X$.\nExpressed mathematically as:\n$$ K : \\text{precompact} \\iff \\forall \\left\\{ x_{n} \\right\\} \\subset K, \\exists \\left\\{ x_{n '} \\right\\} \\subset \\left\\{ x_{n} \\right\\} : x_{n '} \\to x \\in X \\text{ as } n \\to \\infty $$\nEspecially, when the condition involves $x \\in K$ instead of $x \\in X$, $K$ is termed sequentially compact.\nTheorem [1]: $A$ being compact is equivalent to every open cover of $A$ having a finite subcover. [2]: If a subset $F$ of a compact set $K$ is closed, then $F$ is compact. [3]: $X$ being compact is equivalent to every family of closed sets in $X$ having the finite intersection property (f.i.p.), meaning taking intersections over any collection of these sets results in a non-empty set. Proof [1] $\\Gamma$ represents an index set.\n$( \\implies )$\nAssume $A \\subset X$ is compact and $\\mathscr{U} := \\left\\{ U_{\\alpha} : \\alpha \\in \\Gamma \\right\\}$ is an open cover of $A$. Then, $U_{\\alpha} \\cap A$ is an open set in the subspace $A$ of $X$, and $\\mathscr{O} := \\left\\{ U_{\\alpha} \\cap A : U_{\\alpha} \\in \\mathscr{U} \\right\\}$ becomes an open cover of $A$. Since $A$ is compact, there exists $\\alpha_{1} , \\cdots , \\alpha_{n} \\in \\Gamma$ satisfying $\\displaystyle A \\subset \\bigcup_{i=1}^{n} \\left( U_{\\alpha_{i}} \\cap A \\right)$. Hence, $\\left\\{ U_{\\alpha_{1}} , \\cdots , U_{\\alpha_{n}} \\right\\}$ exists as a finite subcover of $\\mathscr{U}$.\n$( \\impliedby )$\nConsider an open cover $\\mathscr{O} := \\left\\{ O_{\\alpha} : O_{\\alpha} \\text{ is open in } A, \\alpha \\in \\Gamma \\right\\}$ of $A$ consisting of open sets. For each $\\alpha \\in \\Gamma$, there exists an open set $U_{\\alpha}$ satisfying $U_{\\alpha} \\cap A = O_{\\alpha}$. The set of these $U_{\\alpha}$, denoted as $\\mathscr{U} := \\left\\{ U_{\\alpha} : \\alpha \\in \\Gamma \\right\\}$, forms an open cover of $A$. Since every open cover has a finite subcover $\\left\\{ U_{\\alpha_{1}} , \\cdots , U_{\\alpha_{n}} \\right\\}$, $\\left\\{ O_{\\alpha_{1}} , \\cdots , O_{\\alpha_{n}} \\right\\}$ becomes a finite subcover of $\\mathscr{O}$.\n‚ñ†\n[2] $$ F \\subset K \\subset X $$ Assume $F$ is a closed set in $X$ and $K$ is compact. Consider an open cover $\\left\\{ U_{\\alpha} \\right\\}$ of $F$. Since $F$ is closed, $F^{c}$ is an open set in $X$ and hence $F^{c} \\cup \\left\\{ U_{\\alpha} \\right\\}$ becomes one of the open covers of $K$. Since $K$ is compact, there exists a finite subcover $\\Phi$ satisfying $F \\subset K \\subset \\Phi$.\nIf $F^{c}\\notin \\Phi$, then $\\Phi$ becomes a finite subcover of $\\left\\{ U_{\\alpha} \\right\\}$, making $F$ compact. If $F^{c}\\in \\Phi$, then $\\Phi \\setminus \\left\\{ F^{c} \\right\\}$ becomes a finite subcover of $\\left\\{ U_{\\alpha} \\right\\}$, making $F$ compact. In both possible cases, $F$ is compact.\n‚ñ†\n[3] Strategy: The terminology here is quite complex, so understanding the terms is crucial. Having the finite intersection property (f.i.p.) for $\\mathscr{C}$ does not guarantee $\\displaystyle \\bigcap_{C \\in \\mathscr{C}} C \\ne \\emptyset$; the compact condition is necessary. The definition of compactness involves unions of open sets, while this theorem involves intersections of closed sets, highlighting the relationship between finite intersection properties and compactness.\n$\\Gamma$ is an index set.\nFinite Intersection Property: For a family $\\mathscr{A} \\subset \\mathscr{P}(X)$ of subsets of $X$, having the finite intersection property (f.i.p) means that for every finite subfamily $A \\subset \\mathscr{A}$, the intersection of its members is non-empty. This is expressed mathematically as: $$ \\forall A \\subset \\mathscr{A}, \\bigcap_{a \\in A} a \\ne \\emptyset $$\n$( \\implies )$\nAssuming $X$ is compact and $\\mathscr{C} := \\left\\{ C_{\\alpha} : C_{\\alpha} \\text{ is closed in } X, \\alpha \\in \\Gamma \\right\\}$ has the f.i.p., suppose $\\displaystyle \\bigcap_{\\alpha \\in \\Gamma} C_{\\alpha} = \\emptyset$ and choose $\\mathscr{O} := \\left\\{ X \\setminus C_{\\alpha} : C_{\\alpha} \\in \\mathscr{C} \\right\\}$. Then, $$ \\begin{align*} \\bigcup_{\\alpha \\in \\Gamma} ( X \\setminus C_{\\alpha}) =\u0026amp; X \\setminus \\bigcap_{\\alpha \\in \\Gamma} C_{\\alpha} \\\\ =\u0026amp; X \\setminus \\emptyset \\\\ =\u0026amp; X \\end{align*} $$ making $\\mathscr{O}$ an open cover of $X$. Since $X$ is compact, $\\mathscr{O}$ has a finite subcover $\\displaystyle \\left\\{ (X \\setminus C_{\\alpha_{1}}) , \\cdots ,(X \\setminus C_{\\alpha_{n}}) \\right\\}$, which implies $$ X = \\bigcup_{i=1}^{n} ( X \\setminus C_{\\alpha_{i}}) = X \\setminus \\bigcap_{i=1}^{n} C_{\\alpha_{i}} $$, leading to $\\displaystyle \\bigcap_{i=1}^{n} C_{\\alpha_{i}} = \\emptyset$. This contradicts the assumption that $\\mathscr{C}$ has the f.i.p., thus $\\displaystyle \\bigcap_{C \\in \\mathscr{C}} C \\ne \\emptyset$ must hold.\n$( \\impliedby )$\nConsider the open cover $\\mathscr{O} := \\left\\{ O_{\\alpha} : O_{\\alpha} \\text{ is open in } A, \\alpha \\in \\Gamma \\right\\}$ of $X$ and $\\mathscr{C} := \\left\\{ X \\setminus O_{\\alpha} : O_{\\alpha} \\in \\mathscr{O} \\right\\}$. Since $$ \\begin{align*} \\bigcap_{\\alpha \\in \\Gamma} C_{\\alpha} \u0026amp;= \\bigcap_{\\alpha \\in \\Gamma} ( X \\setminus O_{\\alpha}) \\\\ =\u0026amp; X \\setminus \\bigcup_{\\alpha \\in \\Gamma} O_{\\alpha} \\\\ =\u0026amp; X \\setminus X \\\\ =\u0026amp; \\emptyset \\end{align*} $$, by contraposition, $\\mathscr{C}$ lacks the f.i.p., meaning there exists $C_{\\alpha_{1}} , \\cdots , C_{\\alpha_{n}} \\in \\mathscr{C}$ satisfying $\\displaystyle \\bigcap_{i=1}^{n} C_{\\alpha_{i}} = \\emptyset$. Then, $$ \\begin{align*} X \\setminus \\bigcup_{i=1}^{n} O_{i} =\u0026amp; X \\setminus \\bigcup_{i=1}^{n} (X \\setminus C_{i}) \\\\ =\u0026amp; X \\setminus \\left( X \\setminus \\bigcap_{i=1}^{n} C_{i} \\right) \\\\ =\u0026amp; \\bigcap_{i=1}^{n} C_{i} \\\\ =\u0026amp; \\emptyset \\end{align*} $$, making $\\displaystyle X = \\bigcup_{i=1}^{n} O_{i}$. Hence, having a finite subcover for every open cover implies compactness.\n‚ñ†\nSee Also Compactness in Metric Spaces Munkres. (2000). Topology (2nd Edition): p164.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":489,"permalink":"https://freshrimpsushi.github.io/en/posts/489/","tags":null,"title":"What are Compact and Precompact in Topological Spaces?"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Description Differential equations can be classified by various criteria. They are broadly divided into ordinary differential equations and partial differential equations. Further classification can be made based on coefficients and order, and whether they are linear or nonlinear. The reason for classifying differential equations is obviously to solve them. The method of solving a differential equation varies depending on its classification.\nOrdinary Differential Equations and Partial Differential Equations Ordinary differential equations refer to differential equations that involve derivatives of one or more dependent variables with respect to a single independent variable only. They are commonly abbreviated as ODEs.\n$$ \\begin{align*} \\dfrac{dy}{dx}\u0026amp;=2y-1 \\\\ \\dfrac{d^2y}{dx^2}+3\\dfrac{dy}{dx}-2y \u0026amp;=0 \\\\ \\dfrac{dy}{dt}+\\dfrac{dx}{dt}\u0026amp;=2c \\end{align*} $$\nPartial differential equations involve derivatives of one or more dependent variables with respect to two or more independent variables. Simply put, they are differential equations that include partial derivatives. They are abbreviated as PDEs. When referred to as $u=u(x,t)$,\n$$ \\begin{align*} \\dfrac{\\partial u}{\\partial x}-\\dfrac{\\partial u }{\\partial t} =0 \\\\ \\dfrac{\\partial^2 u }{\\partial x^2}=\\dfrac{1}{c^2} \\dfrac{\\partial^2 u}{\\partial t^2} \\end{align*} $$\nCoefficients and Order While the terms order and degree are often used interchangeably, they actually refer to different things. It is important to use the terminology correctly as their meanings differ significantly. Remember that a second-order derivative is not referred to as a second-degree derivative. Speaking in English is the most accurate, and the term order is frequently used.\nIn differential equations, the order refers to the highest number of differentiations. The term highlighted in red determines the order of the differential equation.\n$$ \\begin{align} x^2 {\\color{red} \\dfrac{dy}{dx} }+y\u0026amp;=0 \\label{eq1} \\\\ {\\color{red}\\dfrac{d^2u}{dx^2}}+2 \\left( \\dfrac{dy}{dx} \\right) ^3\u0026amp;=5x \\label{eq2} \\end{align} $$\n$(1)$ is a first-order differential equation, and $(2)$ is a second-order differential equation. In differential equations, the degree refers to the power of the highest order derivative term. The term highlighted in red determines the degree of the differential equation.\n$$ \\begin{align} x^2 \\left(\\dfrac{d^{\\color{blue}1}y}{dx^{\\color{blue}1}} \\right)^{\\color{red}1} + y \u0026amp; =0 \\label{eq3} \\\\ \\left( \\dfrac{d^{\\color{blue}3}y}{dx^{\\color{blue}3}} \\right)^{\\color{red}2} + x^2\\dfrac{dy}{dx}\u0026amp;=0 \\label{eq4} \\\\ \\left( \\dfrac{d^{\\color{blue}2}y}{dx^{\\color{blue}2}} \\right)^{\\color{red}3} + \\left( \\dfrac{dy}{dx} \\right)^5+x^2y\u0026amp;=0 \\label{eq5} \\end{align} $$\n$(3)$ is a $\\color{blue}1$th order, $\\color{red}1$ degree, $(4)$ is a $\\color{blue}3$th order, $\\color{red}2$ degree, and $(5)$ is a $\\color{blue}2$th order, $\\color{red}3$ degree differential equation.\nLinear and Nonlinear A differential equation is said to be a $\\mathrm{n}$th order linear differential equation when it is in the following form.\n$$ a_{n}(x)\\dfrac{d^ny}{dx^n}+a_{n-1}(x)\\dfrac{d^{n-1}y}{dx^{n-1}}+ \\cdots + a_{1}(x)\\dfrac{dy}{dx}+a_{0}(x)y=f(x) $$\nIt is linear if the coefficients of each term depend only on the independent variable $x$. That is, if the differential equation can be expressed as a function $L(y)$ such that $L$ is a linear function, then the differential equation represented by $L$ is considered linear.\n$$ x \\dfrac{dy}{dx} $$\nIf any coefficient depends on the dependent variable $y$, then it is nonlinear.\n$$ L(y) = y\\dfrac{dy}{dx}\\\\ \\implies L(y+Y) = (y+Y)\\left( \\dfrac{dy}{dx} + \\dfrac{dY}{dx} \\right) \\ne y\\dfrac{dy}{dx} + Y\\dfrac{dY}{dx}=L(y) + L(Y) $$\nHomogeneous and Nonhomogeneous Though the terms homogeneous and nonhomogeneous are more commonly used, one might also hear the terms homogenous and nonhomogenous. Consider the following differential equation: $$ a_{n}(x)\\dfrac{d^ny}{dx^n}+a_{n-1}(x)\\dfrac{d^{n-1}y}{dx^{n-1}}+ \\cdots + a_{1}(x)\\dfrac{dy}{dx}+a_{0}(x)y=f(x) $$\nIf it is $f(x)=0$, it is called homogeneous, and if it is $f(x) \\ne 0$, it is called nonhomogeneous. Naturally, homogeneous differential equations are much easier to solve.\n","id":483,"permalink":"https://freshrimpsushi.github.io/en/posts/483/","tags":null,"title":"Classification of Differential Equations"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definitions 1 Let\u0026rsquo;s call $X$ a topological space and let $C \\subset \\mathbb{R}^{n}$.\nA continuous function $p : [0,1] \\to X$ from initial point $p(0)$ to terminal point $p(1)$ is called a path. $\\overline{p}(t) = p(1-t)$ is called the reverse path of $p$. If for every $a,b \\in X$ there exists a path $p$ satisfying both $p(0) = a$ and $p(1) = b$, then $X$ is called a path-connected space. For all $a,b \\in C$ and $t \\in [0,1]$, if $(1-t) a + t b \\in C$ then it\u0026rsquo;s called convex. If $p(0) = p(1)$ then it\u0026rsquo;s called a closed path. Explanation Simply put, if there is always a path connecting any two points of a space, it is called path-connected.\n$X$ is a disconnected space since there exists a continuous function $f : X \\to \\left\\{ a, b \\right\\}$. $X$ is a path-connected space since there exists a continuous function $p : [0,1] \\to X$. Thinking in terms of whether there is a continuous function satisfying certain conditions makes it easier to distinguish between disconnected and path-connected spaces. However, it is important to note that many details are omitted in the above statements, so they should not be taken as is.\nConvexity The concept of convexity doesn\u0026rsquo;t necessarily need to be defined only in subsets of Euclidean spaces, but can also be defined in subspaces of vector spaces. Geometrically speaking, a set is convex if a straight line connecting any two points always exists within the set.\nFor example, looking at the two shapes above, the blue circle is convex because any two points can be connected by a straight line. The orange shape is not convex because there is no straight line that can connect points $a$ and $b$ inside it.\nConnectivity Upon closer inspection of the definition of a path-connected space, it almost seems identical to a connected space. Indeed, the following theorem is not difficult to prove, and distinguishing between the two might seem meaningless. However, connectivity and path connectivity are distinctly different concepts because there exist counterexamples where the inverse of the theorem does not hold. Convex subspaces or open connected subspaces are examples where the inverse does hold.\nTheorem: If a space is path-connected, it is connected. Proof For a path-connected space $X$, if $X = \\emptyset$ then $X$ is a connected space. If $X \\ne \\emptyset$, then we can choose some point $a \\in X$. Then, for any $x \\in X$, there exists a continuous function $p_{x} : [0,1] \\to X$ satisfying $p_{x} (0) = a$,$p_{x} (1) = x$.\nThe continuous image of a connected space is connected For a connected space $X$, if $f : X \\to Y$ is a continuous function, then $f(X)$ is a connected space.\nSince $[0,1]$ is connected, $p_{x} ( [0,1] )$ is connected, and since $\\displaystyle a \\in \\bigcap_{x \\in X} p_{x} ( [0, 1] )$, therefore $\\displaystyle \\bigcap_{x \\in X} p_{x} ( [0, 1] ) \\ne \\emptyset$\n(3) The set of connected subsets of $X$ $\\left\\{ A_{\\alpha} \\ | \\ \\alpha \\in \\forall \\right\\}$, if $\\displaystyle \\bigcap_{\\alpha \\in \\forall} A_{\\alpha} \\ne \\emptyset$ then $\\displaystyle \\bigcup_{\\alpha \\in \\forall} A_{\\alpha}$ is a connected space.\nTherefore, $\\displaystyle X = \\bigcup_{x \\in X} p_{x} ( [0, 1] )$ is a connected space.\n‚ñ†\nSee also Convex sets defined in vector spaces Munkres. (2000). Topology(2nd Edition): p155.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":478,"permalink":"https://freshrimpsushi.github.io/en/posts/478/","tags":null,"title":"Path-Connectedness in Topology"},{"categories":"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Definition A differential equation is an equation that includes derivatives of one or more dependent variables with respect to one or more independent variables.\n$$ \\dfrac{dy}{dx}=y $$\n$$ \\dfrac{d^2y}{dx^2} = y $$\nExplanation Most physical situations can be described by first-order or second-order differential equations.\nFalling Body $$ F=ma=mg $$\n$$ v=\\dfrac{dy}{dt} $$\n$$ a=\\dfrac{dv}{dt}=\\dfrac{d}{dt} \\left( \\dfrac{dy}{dt} \\right)=\\dfrac{d^2y}{dt^2} $$\n$$ \\dfrac{d^2y}{dt^2}=g $$\nSpring Mass System $$ F=ma=-ky $$\n$$ a= -\\dfrac{k}{m}y $$\n$$ \\dfrac{d^2y}{dt^2}=-\\dfrac{k}{m}y $$\n$$ \\dfrac{d^2y}{dt^2}+\\dfrac{k}{m}y=0 $$\nWhen this is referred to as $ w^2=\\dfrac{k}{m}$, then,\n$$ \\dfrac{d^2y}{dt^2}+w^2y=0 $$\nRLC Circuit $$ L\\dfrac{d^2q}{dt^2}+R\\dfrac{dq}{dt}+\\dfrac{1}{c}q=V(t) $$\nSchroedinger Equation $$ i\\hbar \\dfrac{\\partial \\psi}{\\partial t}=-\\dfrac{\\hbar^2 }{2m} \\dfrac{\\partial^2 \\psi}{\\partial x^2} + u(x)\\psi $$\n","id":479,"permalink":"https://freshrimpsushi.github.io/en/posts/479/","tags":null,"title":"Definition and Examples of Differential Equations"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 If $f : [a,b] \\to \\mathbb{R}$ is continuous, then there exists a $c \\in (a,b)$ between $f(a)$ and $f(b)$ such that $y_{0} = f(c)$ is satisfied for $y_{0}$.\nExplanation Using the contrapositive, it can be shown that there is no curve connecting two specific shapes under condition $\\mathbb{R}^2$.\nCorollary Meanwhile, the intermediate value theorem has several useful corollaries as follows:\nExistence judgment method for the solution of equation $f(x)=0$: For a continuous function $f:[a,b] \\to \\mathbb{R}$, if $f(a) f(b) \u0026lt; 0$ then $f(x) = 0$ has a solution $x_{0} \\in [a,b]$.\nThis fact is very important as it is used in entrance examination mathematics and also in methods like bisection in numerical analysis.\nFixed-point theorem form of the intermediate value theorem: If $[a,b]$ and $f[a,b]$ have an inclusion relationship, the continuous function $f$ has a fixed point in $[a,b]$. The intermediate value theorem allows for an easy application of the fixed-point theorem. If the conditions are expressed mathematically, they are either $[a,b] \\subset f[a,b]$ or $f[a,b] \\subset [a,b]$, and naturally, it also holds when both $f[a,b] = [a,b]$ are satisfied simultaneously. Although it may seem unusual that it holds for $[a,b] \\subset f[a,b]$ because the condition often mentioned in the fixed-point theorem is $f[a,b] \\subset [a,b]$, from the perspective of corollaries of the intermediate value theorem, there is no need to consider overly general conditions, so it can be accepted as a natural fact.\nProof Strategy: Employ topological auxiliary lemmas. It\u0026rsquo;s a really important theorem, but it\u0026rsquo;s accepted without proof in high school and is too difficult to prove during calculus. While proofs that do not use higher theory are meaningful in their own right, the topological proof of the intermediate value theorem is too easy to resist its temptations.\nConnectedness is a topological property, and since $f$ is continuous, $f[a,b]$ is also a connected space.\nFor all $V \\subset Y$ that satisfy $f(a) \\in V^{\\circ}$, there exists a $c \\in (a,b)$ that satisfies $f(c) = y_{0}$\nDue to the properties of continuous functions, there exists a $c \\in (a,b)$ that satisfies $f(c) = y_{0}$.\n‚ñ†\nMunkres. (2000). Topology(2nd Edition): p476.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":476,"permalink":"https://freshrimpsushi.github.io/en/posts/476/","tags":null,"title":"Proof of the Intermediate Value Theorem"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 The set $G$ and its subgroup $H$ such that $aH = \\left\\{ ah \\ | \\ h \\in H \\right\\}$ is called the Left Coset and $Ha = \\left\\{ ha \\ | \\ h \\in H \\right\\}$ is called the Right Coset. Here, $a \\in G$ and $aH, Ha \\subset G$. The number of left (right) cosets of $H \\leqslant G$ is denoted as $(G : H)$ and called the Index of $H$ in $G$. If $H$ is a subgroup of $G$ and for all $g \\in G$, $gH = Hg$ holds, then $H$ is called a Normal Subgroup of $G$, denoted as $H \\triangleleft G$. $G$ is called Simple if it doesn\u0026rsquo;t have a $H \\triangleleft G$ other than $H = \\left\\{ e \\right\\}$ or $H = G$. In other words, $G$ is simple if it only has $\\left\\{ e \\right\\}$ and itself as normal subgroups. Explanation Cosets The idea of cosets inevitably leads algebra to a higher level.\nFor example, the set $3 \\mathbb{Z} = \\left\\{ \\cdots, -6, -3, 0 , 3, 6 , \\cdots\\right\\}$ of multiples of $3$ forms a group, and especially since $\\mathbb{Z}$ is an abelian group, $3 \\mathbb{Z} \\triangleleft \\mathbb{Z}$ holds.\nIf we think about adding integers here, $$ \\begin{align*} 1 + 3 \\mathbb{Z} =\u0026amp; \\left\\{ \\cdots, -5, -2, 1 , 4, 7 , \\cdots\\right\\} \\\\ 2 + 3 \\mathbb{Z} =\u0026amp; \\left\\{ \\cdots, -4, -1, 2 , 5, 8 , \\cdots\\right\\} \\\\ 3 + 3 \\mathbb{Z} =\u0026amp; \\left\\{ \\cdots, -3, 0 , 3, 6 , 9 , \\cdots\\right\\} = 3 \\mathbb{Z} \\\\ 4 + 3 \\mathbb{Z} =\u0026amp; \\left\\{ \\cdots, -2, 1 , 4, 7 , 10 , \\cdots\\right\\} = 1 + 3 \\mathbb{Z} \\\\ 5 + 3 \\mathbb{Z} =\u0026amp; \\left\\{ \\cdots, -1, 2 , 5, 8 , 11 , \\cdots\\right\\} = 2 + 3 \\mathbb{Z} \\end{align*} $$ it resembles adding integers in $\\pmod{3}$.\nThis means we can think of a new group consisting of sets as elements, like $\\mathbb{Z}_{3} : = \\left\\{ 3 \\mathbb{Z} , 1 + 3 \\mathbb{Z} , 2 + 3 \\mathbb{Z}\\right\\}$. Such a newly formed group is called a Quotient Group. It\u0026rsquo;s a concept that\u0026rsquo;s quite difficult to understand at first, usually due to a misunderstanding of cosets. Don\u0026rsquo;t underestimate it as if it\u0026rsquo;s trivial and unused; it\u0026rsquo;s crucial to master cosets by writing them down to ease understanding of later topics.\nIndex It says left and right without distinguishing because there\u0026rsquo;s no particular need to. Originally, an index is defined by the number of left cosets, but in fact, since there exists a one-to-one correspondence with right cosets, it can also be defined by the number of right cosets.2\nNormality Checking whether $gH$ and $Hg$ form a group and whether $gH = Hg$ holds reminds one of the definition of continuity learned in courses. Given the term Normal, it suggests a very strong condition and many useful properties can be inferred.\nImmediately known from the definition is that for the identity element $e$ of $G$, $\\left\\{ e \\right\\} \\triangleleft G$ exists. A bit of thought reveals that for an abelian group $G$, if $H \\leqslant G$, then approximately $H \\triangleleft G$ exists.\nSimplicity For example, for a prime number $p$, $\\mathbb{Z}_{p}$ doesn\u0026rsquo;t have any subgroups other than the trivial group or itself, thus it forms a simple group.\nSee Also Properties of Cosets Fraleigh. (2003). A first course in abstract algebra(7th Edition): p97, 101, 132, 149.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p103\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":469,"permalink":"https://freshrimpsushi.github.io/en/posts/469/","tags":null,"title":"Cosets and Normal Subgroups in Abstract Algebra"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definitions 1 The equivalence classes of $\\sim$ are called the Orbits of $\\sigma$. A permutation that has at most one orbit with more than one element is called a Cycle. Among the orbits a cycle has, the orbit with the largest cardinality is called the Length of the cycle. A cycle with length $2$ is called a Transposition. Orbits corresponding to a cycle that do not share elements are called Disjoint. Explanation It\u0026rsquo;s normal to not understand just by definitions, let‚Äôs look into some actual examples.\nOrbit Considering the permutation $$ \\sigma = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 4 \u0026amp; 5 \u0026amp; 6 \u0026amp; 7 \u0026amp; 8 \\\\ 3 \u0026amp; 8 \u0026amp; 6 \u0026amp; 7 \u0026amp; 4 \u0026amp; 1 \u0026amp; 5 \u0026amp; 2 \\end{bmatrix} $$ from $S_{8}$. This expression represents $$ 1 \\to 3 \\to 6 \\to 1 \\\\ 2 \\to 8 \\to 2 \\\\ 4 \\to 7 \\to 5 \\to 4 $$ . Therefore, the equivalence relation $\\sim$ determines the following three equivalence classes. $$ \\left\\{ 1, 3, 6 \\right\\} \\\\ \\left\\{ 2, 8 \\right\\} \\\\ \\left\\{ 4 , 5 , 7 \\right\\} $$\nCycle Considering the permutation $$ \\mu_{1} = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 4 \u0026amp; 5 \\\\ 3 \u0026amp; 2 \u0026amp; 5 \u0026amp; 1 \u0026amp; 4 \\end{bmatrix} $$ from $S_{5}$. This permutation is represented as $1 \\to 3 \\to 5 \\to 4 \\to 1$, excluding the unchanged $2$, it can also be represented simply as $(1,3,5,4)$. It is important to note that while using this representation, order matters so that $(1,3,5,4) = (3,5,4,1)$ but not $(1,3,5,4) \\ne (1,5,3,4)$. Also, considering $$ \\mu_{2} = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 1 \u0026amp; 3 \\end{bmatrix} $$ , since $(1,2)$ does not even represent the presence of $3$, it should be clearly stated in $S_{3}$ that it is $(1,2)$.\nLength There are only two orbits of the cycle $$ \\mu_{1} = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 4 \u0026amp; 5 \\\\ 3 \u0026amp; 2 \u0026amp; 5 \u0026amp; 1 \u0026amp; 4 \\end{bmatrix} $$ , which are $$ \\left\\{ 1,3,4,5 \\right\\} \\\\ \\left\\{ 2 \\right\\} $$ . Therefore, since $ | \\left\\{ 1,3,4,5 \\right\\} | = 4$ and $| \\left\\{ 2 \\right\\} | =1 $, the length of $\\mu_{1}$ becomes $4$.\nTransposition The cycle $$ \\mu_{2} = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 1 \u0026amp; 3 \\end{bmatrix} = (1,2) $$ has a length of $2$, so it\u0026rsquo;s a transposition. In simple terms, it‚Äôs a cycle that just swaps two elements. Generally, $$ (1,2, \\cdots , n) = (1, n) (1, n-1 ) \\cdots (1,3) (1,2) $$ can be represented. If one wishes to base it on $3$, $$ (1,2, \\cdots , n) = (3, 4, \\cdots , n , 1, 2 ) = (3 , 2) (3, 1) \\cdots (3,4) $$ can be changed accordingly. This is a very useful property to know.\nDisjoint Considering $$ \\sigma = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 4 \u0026amp; 5 \u0026amp; 6 \u0026amp; 7 \u0026amp; 8 \\\\ 3 \u0026amp; 8 \u0026amp; 6 \u0026amp; 7 \u0026amp; 4 \u0026amp; 1 \u0026amp; 5 \u0026amp; 2 \\end{bmatrix} = (1,3,6) (2,8) (4,7,5) $$ , the three cycles $(1,3,6)$, $(2,8)$, and $(4,7,5)$ have corresponding orbits that do not share elements, making them disjoint. What can be understood from this representation is that it‚Äôs perfectly fine to be represented as $$ (1,3,6) (2,8) (4,7,5) = (4,7,5) (2,8) (1,3,6) $$ . Permutations can be represented as the product of cycles, and if such products are considered the same, then the orbits are uniquely determined.\nSummary [1]: Every permutation of a finite symmetric group with more than one element can be represented as the product of transpositions. [2]: Every permutation of a finite symmetric group can be represented as the product of disjoint cycles. Fraleigh. (2003). A first course in abstract algebra(7th Edition): p87~90. If $\\sigma$ is defined as a permutation of a group $G$, then an equivalence relation $\\sim$ on $a, b \\in G$ is defined when there exists an integer $n \\in \\mathbb{Z}$ that satisfies $b=\\sigma^n (a)$ as $a \\sim b$.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":460,"permalink":"https://freshrimpsushi.github.io/en/posts/460/","tags":null,"title":"Orbits, Cycles, and Permutations in Abstract Algebra"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definitions 1 In a topological space $X$, if there exist open sets $A \\ne \\emptyset$, $B \\ne \\emptyset$ that satisfy $A \\cap B = \\emptyset$ and $A \\cup B = X$, then $X$ is called a Disconnected space. If it is not disconnected, it is called a Connected space.\nTheorems [1]: Connectedness is a topological property. [2]: Every trivial space is a connected space. [3]: Every discrete space is a disconnected space. [4]: Every singleton set is connected. Description The definition of being not connected is quite intuitive, and its negation, being connected, is also easily acceptable. Graph theory defines connectedness in a similar manner.\nFor example, if we consider the Euclidean space $( \\mathbb{R} , d )$, it is a connected space as it does not satisfy the conditions for being disconnected, regardless of which open interval is considered. On the other hand, if we consider its subspace $( \\mathbb{Q}, d )$, since $( \\mathbb{Q} , d ) = ( \\mathbb{Q} , \\mathscr{P} ( \\mathbb{Q} ) )$ is a discrete space, it can easily be shown to be a disconnected space.\nProofs [1] Let there exist a homeomorphic mapping $f : X \\to Y$, and let $X$ be a connected space. To prove that $Y$ is a connected space, it is sufficient.\nAssuming $Y$ is a disconnected space, then there exist open sets $A, B \\subset Y$ that satisfy $$ A \\cap B = \\emptyset \\\\ A \\cup B = Y $$\nIf $f$ is a continuous function, for every open set $V \\subset Y$, $f^{-1} (V)$ is an open set in $X$.\nSince $Y$ is continuous, $f^{-1} (A)$ and $f^{-1} (B)$ are open sets in $X$. However, $$ f^{-1} (A) \\cap f^{-1} (B) = f^{-1} (A \\cap B) = f^{-1} ( \\emptyset ) = \\emptyset \\\\ f^{-1} (A) \\cup f^{-1} (B) = f^{-1} (A \\cup B) = f^{-1} ( Y ) = X $$ This is a contradiction to the assumption that $X$ is a disconnected space.\n‚ñ†\n[2] In the topology $\\mathscr{T} = \\left\\{ \\emptyset , X \\right\\}$ of the trivial space $X$, there do not exist two non-empty open sets, so $X$ is a connected space.\n‚ñ†\n[3] If $X$ has only one element, it is a trivial space rather than a discrete space, so we must assume that $X$ has more than one element. In the discrete space $X$, every non-empty open set $U$ such that $V = X \\setminus U$ is an open set in $X$, so it is a disconnected space.\n‚ñ†\n[4] For $A , B \\subset \\left\\{ x \\right\\}$ to satisfy $A \\cap B = \\emptyset$, either $A$ or $B$ must necessarily be empty, so it cannot be a disconnected space.\n‚ñ†\nMunkres. (2000). Topology(2nd Edition): p148.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":457,"permalink":"https://freshrimpsushi.github.io/en/posts/457/","tags":null,"title":"Connectivity in Topology"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 Let\u0026rsquo;s consider $X$ as a topological space. For $a,b \\in X$, if $a \\ne b$ and $U, V \\subset X$ are open sets in $X$, then:\n$T_{0}$: If there exists $U$ that contains only one of $a$ and $b$, then $X$ is called a Kolmogorov space. $T_{1}$: For any $a,b$, if there exists $U,V$ satisfying $$ a \\in U, b \\notin U \\\\ a \\notin V, b \\in V $$, then $X$ is called a Frechet space. $T_{2}$: For any $a,b$, if there exists $U,V$ satisfying $$ a \\in U, b \\in V \\\\ U \\cap V = \\emptyset $$, then $X$ is called a Hausdorff space. $T_{3}$: If $X$ is a $T_{1}$-space, and for every closed set $C \\subset X$ that does not contain $a$, if there exists $U,V$ satisfying $$ a \\in U , C \\subset V \\\\ U \\cap V = \\emptyset $$, then $X$ is called a Regular space. $T_{4}$: If $X$ is a $T_{1}$-space, and for two closed sets $A, B \\subset X$ with $A \\cap B = \\emptyset$, if there exists $U,V$ satisfying $$ A \\subset U , B \\subset V \\\\ U \\cap V = \\emptyset $$, then $X$ is called a Normal space. Explanation These properties, also known as Separation Axioms, focus exactly on dividing the space into parts. The classification shown as $T_{i}$ is called Kolmogorov classification. Just by looking at the definitions, you might feel like it\u0026rsquo;s $$ T_{4} \\implies T_{3} \\implies T_{2} \\implies T_{1} \\implies T_{0} $$, and indeed it is, making it a nice classification method.\nEspecially, $T_{2}$, the Hausdorff space, often becomes a central subject of interest, as its conditions are neither too many nor too few, making it an appropriately usable level. Various bizarre spaces that are commonly used as counterexamples often fail to satisfy $T_{2}$. Examples of non-Hausdorff spaces include Sierpi≈Ñski space and Indiscrete space.\nFollowing are some useful properties of Hausdorff spaces. It goes without saying that there are many applications since every metric space is a Hausdorff space.\nTheorems [2-1]: $T_{2}$ is a topological property. [2-2]: $T_{2}$ is a hereditary property. [2-3]: [In a $T_{2}$-space, a sequence $\\left\\{ x_{n} \\right\\}$ converges to at most one point.](../456) Proof [2-1] Assume there exists a homeomorphism $f : X \\to Y$ and $X$ is a Hausdorff space. To prove that $Y$ is also a Hausdorff space, it is sufficient to show the following.\n$f$ is a bijection, so for two distinct $y_{1}, y_{2} \\in Y$, there are two distinct $x_{1}, x_{2} \\in X$ satisfying $$ a = f(x_{1}) \\\\ b = f(x_{2}) $$. By assumption, since $X$ is a Hausdorff space, there exists open sets $U, V \\subset X$ satisfying $$ x_{1} \\in U \\\\ x_{2} \\in V \\\\ U \\cap V = \\emptyset $$. Since $f$ is an open function due to continuity, $f(U)$ and $f(V)$ are open sets in $Y$, and $$ a \\in f(U) \\\\ b \\in f(V) \\\\ f(U) \\cap f(V) = \\emptyset $$ follows. Therefore, $Y$ is a Hausdorff space.\n‚ñ†\nMunkres. (2000). Topology(2nd Edition): p195.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":454,"permalink":"https://freshrimpsushi.github.io/en/posts/454/","tags":null,"title":"Separation Properties in Topology"},{"categories":"Ìï®Ïàò","contents":"Theorem: Binomial Coefficients Expressed Through the Beta Function $0 \\le k\\le n$ is satisfied for two natural numbers $k,n$, the following equation holds. $$ \\binom{n}{k}={}_{n}C_{k}=C(n,k)=\\frac{1}{(n+1)B(n-k+1,k+1)} $$ For two natural numbers $m,n$, the following equation holds. $$ B(m,n)=\\left[ \\frac{mn}{m+n} \\begin{pmatrix} m+n \\\\ n \\end{pmatrix}\\right]^{-1} $$\nDescription The beta function, defined by $B(p,q):=\\displaystyle \\int_{0}^{1}t^{p-1}(1-t)^{q-1}dt$, can also be seen as a generalization of binomial coefficients. The proof is not difficult, but a lemma has to be proved first.\nProof Lemma 1 $$ B(p,q)=B(p+1,q) +B(p,q+1) $$\nProof of Lemma 1 $$ \\begin{align*} B(p+1,q) + B(p,q+1) =\u0026amp; \\int_{0}^{1} t^{p-1} (1-t)^{q-1}dt + \\int_{0}^{1}t^{p-1}(1-t)^{p-1}dt \\\\ =\u0026amp; \\int_{0}^{1}t^{p-1}(1-t)^{q-1}\\big[t+(1-t) \\big]dt \\\\ =\u0026amp; \\int_{0}^{1}t^{p-1}(1-t)^{q-1}dt \\\\ =\u0026amp; B(p,q) \\end{align*} $$\n‚ñ†\nLemma 2 (a): $B(p+1,q)=\\dfrac{p}{p+q}B(p,q)$ (b): $B(p,q+1)=\\dfrac{q}{p+q}B(p,q)$ Proof of Lemma 2 $$ \\begin{align*} B(p+1,q) =\u0026amp; \\int_{0}^{1}t^{p}(1-t)^{q-1}dt \\\\ =\u0026amp; \\left[ -\\frac{1}{q}t^{p}(1-t)^{q}\\right]_{0}^{1} + \\int_{0}^{1} \\frac{p}{q}t^{p-1}(1-t)^{q}dt \\\\ =\u0026amp; 0 + \\frac{p}{q}\\int_{0}^{1} t^{p-1}(1-t)^{q}dt \\\\ =\u0026amp; \\frac{p}{q} B(p,q+1) \\end{align*} $$ Integration by parts was used for the second equality. Since by Lemma 1, $(a)$, substituting this into the equation yields: $$ B(p+1,q)=\\frac{p}{q}B(p,q) -\\frac{p}{q}B(p+1,q) \\\\ \\Rightarrow \\frac{q+p}{q}B(p+1,q)=\\frac{p}{q}B(p,q) \\\\ \\Rightarrow B(p+1,q)=\\frac{p}{p+q}B(p,q) $$ Since by Lemma 1, $(b)$, substituting this into the equation yields: $$ B(p,q)-B(p,q+1)=\\frac{p}{q}B(p,q+1) \\\\ \\Rightarrow B(p,q)=\\frac{p+q}{q}B(p,q+1) \\\\ \\Rightarrow B(p,q+1)=\\frac{q}{p+q}B(p,q) $$\n‚ñ†\nMain Proof First, let\u0026rsquo;s show that $B(1,1)=1$. This can be directly seen from the definition. $$ B(1,1)=\\int_{0}^{1}t^{0}(1-t)^{0}dt=1-0=1 $$ Let\u0026rsquo;s say $m,n \\in \\mathbb{N}$. Applying Lemma 2\u0026rsquo;s $(a)$ repeatedly to $B(m,n)$ yields: $$ \\begin{align*} B(m,n) =\u0026amp; \\frac{m-1}{m+n-1}B(m-1,n) \\\\ =\u0026amp; \\frac{m-1}{m+n-1}\\cdot \\frac{m-2}{m+n-2}B(m-2,n) \\\\ =\u0026amp; \\frac{m-1}{m+n-1} \\cdot \\frac{ m-2 }{m+n-2}\\cdot \\cdots \\frac{ 1 }{m+n-(m-1) }B(1,n) \\\\ =\u0026amp; \\frac{ (m-1)! }{ (m+n-1)(m+n-2)\\cdots(n+1) }B(1,n) \\end{align*} $$ Applying Lemma 2\u0026rsquo;s $(b)$ repeatedly results in: $$ \\begin{align*} B(m,n) =\u0026amp; \\frac{ (m-1)! }{ (m+n-1)(m+n-2)\\cdots(n+1) }B(1,n) \\\\ =\u0026amp; \\frac{ (m-1)! }{ (m+n-1)(m+n-2)\\cdots(n+1) } \\frac{ n-1 }{ n }B(1,n-1) \\\\ =\u0026amp; \\frac{ (m-1)! }{ (m+n-1)(m+n-2)\\cdots(n+1) } \\frac{ n-1 }{ n }\\cdot \\frac{ n-2 }{ n-1 }B(1,n-2) \\\\ =\u0026amp; \\frac{ (m-1)! }{ (m+n-1)(m+n-2)\\cdots(n+1) } \\frac{ n-1 }{ n }\\cdot \\frac{ n-2 }{ n-1 }\\cdots \\frac{ 1 }{ n+1-(n-1) }B(1,1) \\\\ =\u0026amp; \\frac{ (m-1)!(n-1)! }{ (m+n-1)(m+n-2)\\cdots(n+1)n(n-1)\\cdots2 } B(1,1) \\\\ =\u0026amp; \\frac{ (m-1)!(n-1)! }{ (m+n-1)! } \\\\ =\u0026amp; \\frac{ m+n }{ mn }\\frac{ m!n! }{ (m+n)! } \\\\ =\u0026amp; \\left[ \\frac{ mn }{ m+n } \\begin{pmatrix} m+n \\\\ n \\end{pmatrix} \\right]^{-1} \\end{align*} $$ Substituting $m=n-k+1$, $n=k+1$ into the third equation from the bottom of the above sequence gives: $$ B(n-k+1,k+1)=\\frac{(n-k)!k!}{ (n+1)! }=\\frac{ (n-k)!k! }{(n+1)n! } $$ Therefore: $$ \\frac{ n! }{(n-k)!k! }=\\begin{pmatrix} n \\\\ k \\end{pmatrix}=\\frac{ 1 }{ (n+1)B(n-k+1,k+1) } $$\n‚ñ†\nSee Also Euler Integration ","id":450,"permalink":"https://freshrimpsushi.github.io/en/posts/450/","tags":null,"title":"Generalization of Binomial Coefficients: Beta Function"},{"categories":"ÌôïÎ•†Î∂ÑÌè¨Î°†","contents":"Definition 1 Continuous For $[a,b] \\subset \\mathbb{R}$, a continuous probability distribution $U(a,b)$ with the following probability density function is called the Uniform Distribution. $$ f(x) = {{ 1 } \\over { b - a }} \\qquad , x \\in [a,b] $$\nDiscrete For a finite set $\\left\\{ x_{k} \\right\\}_{k=1}^{n}$, a discrete probability distribution with the following probability mass function is called the Uniform Distribution. $$ p \\left( x_{k} \\right) = P \\left( X = x_{k} \\right) = {{ 1 } \\over { n }} \\qquad , k = 1, \\cdots , n $$\nDescription The uniform distribution is commonly referred to as the uniform distribution. A typical example of a discrete uniform distribution is $x_{k} = k$, such as dice, in which case the mathematical properties are often of little concern. Unless otherwise mentioned, the uniform distribution refers to the continuous discrete distribution.\nThe importance of the uniform distribution is not so much for a particular reason but because it is the simplest distribution we can think of. It might seem too simplistic for students familiar with distribution theory, but it is still widely used in fields such as mathematics and artificial intelligence.\nInformation Theory From the perspective of information theory, it is a very important distribution because, whether discrete or continuous, Shannon entropy is maximized. Given that other distributions have highs and lows in probability functions, it\u0026rsquo;s natural that uniform distribution does not give any hint of what the sample might be like.\nMaximizing entropy in the discrete uniform distribution is also a good example of the Lagrange multiplier method.\nBasic Properties Moment Generating Function [1]: $$m(t) = {{ e^{tb} - e^{ta} } \\over { t(b-a) }}$$ Mean and Variance [2]: If $X \\sim U(a,b)$ then $$ E(X) = {{ a+b } \\over { 2 }} \\\\ \\text{Var}(X) = {{ (b-a)^{2} } \\over { 12 }} $$ Sufficient Statistic and Maximum Likelihood Estimate [3]: Suppose we are given a random sample $\\mathbf{X} := \\left( X_{1} , \\cdots , X_{n} \\right) \\sim U \\left( 0 , \\theta \\right)$. The sufficient statistic $T$ and maximum likelihood estimate $\\hat{\\theta}$ for $\\theta$ are as follows. $$ \\begin{align*} T =\u0026amp; \\max_{k=1 , \\cdots , n} X_{k} \\\\ \\hat{\\theta} =\u0026amp; \\max_{k=1 , \\cdots , n} X_{k} \\end{align*} $$\nProof [1] $$ \\begin{align*} m(t) = \\int_{a}^{b} e^{tx} {{ 1 } \\over { b-a }} dx =\u0026amp; {{ 1 } \\over { b-a }} \\left[ {{ 1 } \\over { t }} e^{tx} \\right]_{a}^{b} \\\\ =\u0026amp; {{ e^{tb} - e^{ta} } \\over { t(b-a) }} \\end{align*} $$\n‚ñ†\n[2] Deduced directly.\n‚ñ†\n[3] Deduced directly.\n‚ñ†\nHogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p45.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":443,"permalink":"https://freshrimpsushi.github.io/en/posts/443/","tags":null,"title":"Binomial Distribution"},{"categories":"Ï†ïÏàòÎ°†","contents":"See Also Totient Function in Analytic Number Theory Definition 1 The function defined as follows, $\\phi$, is called the Euler\u0026rsquo;s totient function.\n$$ \\phi ( m ) := \\left| \\left\\{ a \\ | \\ 1 \\le a \\le m \\land \\gcd (a,m) = 1 \\right\\} \\right| = m \\prod_{p \\mid m} \\left( 1 - {{1} \\over {p}} \\right) $$\nExplanation The term totient comes from the Tot- in Total meaning the whole and -tient from Quo-tient meaning the quotient. It can be understood in this way though it\u0026rsquo;s not used outside of mathematics, more specifically number theory, where it\u0026rsquo;s often referred to as the Phi function.\nStart by manually calculating from $1$ to about $10$ to get the hang of it. $$ \\begin{align*} \\phi ( 1 ) = \u0026amp; \\left| \\left\\{ 1 \\right\\} \\right| = 1 =1 \\\\ \\phi ( 2 ) = \u0026amp; \\left| \\left\\{ 1 \\right\\} \\right| = 2 {{1} \\over {2}} = 1 \\\\ \\phi ( 3 ) = \u0026amp; \\left| \\left\\{ 1 , 2 \\right\\} \\right| = 3 {{2} \\over {3}} = 2 \\\\ \\phi ( 4 ) = \u0026amp; \\left| \\left\\{ 1 , 3 \\right\\} \\right| = 4 {{1} \\over {2}} = 2 \\\\ \\phi ( 5 ) = \u0026amp; \\left| \\left\\{ 1 , 2 , 3 , 4 \\right\\} \\right| = 5 {{4} \\over {5}} = 4 \\\\ \\phi ( 6 ) = \u0026amp; \\left| \\left\\{ 1 , 5 \\right\\} \\right| = 6 {{1} \\over {2}} {{2} \\over {3}} = 2 \\\\ \\phi ( 7 ) = \u0026amp; \\left| \\left\\{ 1 , 2 , 3 , 4 , 5 , 6 \\right\\} \\right| = 7 {{6} \\over {7}} = 6 \\\\ \\phi ( 8 ) = \u0026amp; \\left| \\left\\{ 1 , 3 , 5 , 7 \\right\\} \\right| = 8 {{1} \\over {2}} = 4 \\\\ \\phi ( 9 ) = \u0026amp; \\left| \\left\\{ 1 , 2, 4 , 5 , 7, 8, \\right\\} \\right| = 9 {{2} \\over {3}} = 6 \\\\ \\phi ( 10 ) = \u0026amp; \\left| \\left\\{ 1 , 3 , 7 , 9 \\right\\} \\right| = 10 {{1} \\over {2}} {{4} \\over {5}} = 4 \\end{align*} $$\nAt first glance, it may be wondered why such a seemingly difficult and irregular function is necessary. It turns out that it has many beautiful properties and serves as a foundation for various theories.\nTheorem For a prime number $p$, then $\\phi (p^{k}) = p^{k} - p^{k-1}$\nProof Strategy: The function value for the power of a prime can easily be counted.\nSince $p$ is a prime, for any $n \\in \\mathbb{N}$, $\\gcd (p, np) \\ne 1$ namely $$ p , 2p , \\cdots (p^{k-1} - 2 ) p , (p^{k-1} - 1 ) p , p^{k} \\notin \\left\\{ a \\ | \\ 1 \\le a \\le p^{k} \\land \\gcd (a,p^{k}) = 1 \\right\\} $$ There are exactly $p^{k-1}$ such, therefore, $\\phi (p^{k}) = p^{k} - p^{k-1}$\n‚ñ†\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p72.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":445,"permalink":"https://freshrimpsushi.github.io/en/posts/445/","tags":null,"title":"Torsion Function"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definitions Let\u0026rsquo;s talk about a group $\\left\u0026lt; G , \\ast\\ \\right\u0026gt; , \\left\u0026lt; G' , *' \\right\u0026gt;$ and refer to it as $\\phi : G \\to G'$.\nIf $\\forall x ,y \\in G $, $\\phi (x \\ast\\ y) = \\phi (x ) *' \\phi ( y)$ then we call $\\phi$ a Homomorphism. If a homomorphism $\\phi$ is injective, then we call $\\phi$ a Monomorphism and denote it $G \\hookrightarrow G'$. If a homomorphism $\\phi$ is surjective, then we call $\\phi$ an Epimorphism and denote it $G \\twoheadrightarrow G'$. If a homomorphism $\\phi$ is bijective, then we call $\\phi$ an Isomorphism and denote it $G \\simeq G'$. For a homomorphism $\\phi$, if $G = G'$ then we call $\\phi$ an Endomorphism. For an isomorphism $\\phi$, if $G = G'$ then we call $\\phi$ an Automorphism. Description Although you might get overwhelmed by these sudden definitions, you\u0026rsquo;ll get used to them soon. Don\u0026rsquo;t be intimidated and face them confidently.\nMonomorphisms and epimorphisms are arbitrarily termed, and in Japanese mathematics, they simply use „É¢„ÉéÂ∞Ñ and „Ç®„ÉîÂ∞Ñ respectively. Outside of abstract algebra, these terms are basically used as injective and surjective functions, but in abstract algebra, they usually include homomorphisms.\nThe isomorphism is immediately useful for its properties, although the conditions required for it are a drawback. It would be better if those conditions could be reduced, meaning if it were enough to just have a monomorphism or an epimorphism.\n","id":439,"permalink":"https://freshrimpsushi.github.io/en/posts/439/","tags":null,"title":"In English: Various Mappings in Abstract Algebra"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 For two topological spaces $X,Y$, if a bijection $f : X \\to Y$ exists such that both $f$ and its inverse function $f^{-1}$ are continuous functions, then $f$ is called a Homeomorphism, and the two topological spaces are said to be Homeomorphic.\nTheorem The following propositions are equivalent.\n(1): $f : X \\to Y$ is a homeomorphism. (2): $f^{-1} : Y \\to X$ is a homeomorphism. (3): $f : X \\to Y$ is a continuous bijection that is a closed function. (4): $f : X \\to Y$ is a continuous bijection that is an open function. Explanation Just as with the concept defined in the metric space, the concept of homeomorphism can also be easily extended. It is also reasonable to see it as the very reason to study continuous functions.\nThe particularly good reason for (3) and especially (4) is because it eliminates the need for checking the inverse function. It\u0026rsquo;s easily deduced from the properties of open and closed functions, satisfying the condition that the inverse function must be continuous in their stead.\nEspecially, if $f,f^{-1}$ is differentiable, it is called a Diffeomorphism.\nSee also Topological equivalence in graph theory Munkres. (2000). Topology(2nd Edition): p105.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":438,"permalink":"https://freshrimpsushi.github.io/en/posts/438/","tags":null,"title":"Homotopy in Topological Spaces"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition Let\u0026rsquo;s say for a topological space $X,Y$ that $f : X \\to Y$.\nFor every open set $O \\subset X$, if $f (O)$ is an open set in $Y$, then $f$ is called an open function. For every closed set $C \\subset X$, if $f (C)$ is a closed set in $Y$, then $f$ is called a closed function. Theorem In particular, a continuous function has the following property:\n[1]: If a continuous function $f : \\mathbb{R} \\to \\mathbb{R}$ is a bijection, it is both an open and a closed function. The above property briefly summarizes a very special case of the theorem below:\nIf $f : X \\to Y$ is a bijection, the following propositions are equivalent:\n(1): $f^{-1} : Y \\to X$ is a continuous function. (2): $f : X \\to Y$ is an open function. (3): $f : X \\to Y$ is a closed function. Explanation Note that, as in the definition in sets, open and closed are not mutually exclusive concepts.\nThe equivalence condition (1) implies $f^{-1}$ being a continuous function can be conveniently used in discussions about topological equivalence.\nAn example showing that the concepts of openness and closedness are not necessarily related to continuity is the floor function $\\lfloor \\cdot \\rfloor : \\mathbb{R} \\to \\mathbb{R}$ which is not a continuous function, but a closed function:\nIt is self-evident that $\\lfloor \\cdot \\rfloor$ is not a continuous function. For any closed interval $[a,b]$, since $\\lfloor [a,b] \\rfloor \\subset \\mathbb{Z}$, $\\lfloor \\cdot \\rfloor$ is a closed function. Proof [1] For any open interval $(a,b)$, since $f(a,b) = (c ,d)$, $f$ is an open function.\nFor any closed interval $[a,b]$, since $f[a,b] = [c,d]$, $f$ is a closed function.\n‚ñ†\n","id":435,"permalink":"https://freshrimpsushi.github.io/en/posts/435/","tags":null,"title":"Open Functions and Closed Functions"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition For a topological space $(X, \\mathscr{T}_{X} )$ and $(Y, \\mathscr{T}_{Y} )$, let\u0026rsquo;s denote by $f: X \\to Y$. A function $f$ is said to be continuous at $a$ if, for every neighborhood $V \\in \\mathscr{T}_{Y}$ containing $f(a)$, there exists a neighborhood $U \\in \\mathscr{T}_{X}$ containing $a$ such that $f(U) \\subset V$ is satisfied. If $f$ is continuous at every point of $X$, it is called a continuous function and can be represented as $f \\in C(X,Y)$.\nExplanation At first glance, this definition might seem difficult to grasp, but upon closer examination, it is essentially the same concept as defining continuity in analysis, where for every given $\\epsilon \u0026gt; 0$, there exists an $\\delta$ satisfying $\\left| x - a \\right| \\lt \\delta \\implies \\left| f(x) - f(a) \\right| \\lt \\epsilon$. Noting that $\\left\\{ x : \\left| x - a \\right| \\lt \\delta \\right\\}$ and $\\left\\{ f(x) : \\left| f(x) - f(a) \\right| \\lt \\epsilon \\right\\}$ are open sets, the idea that for every given $\\epsilon$, an $\\delta$ can be found translates to being able to find an open set satisfying the condition in $X$ for every open set given in $Y$.\nIt\u0026rsquo;s worth noting that $C(X,Y)$ represents the set of continuous functions with domain $X$ and codomain $Y$. For those studying topology, the epsilon-delta argument is probably well-tread territory, making formulas and symbols more comfortable than text.\nContinuity has been generalized from the Euclidean space to metric spaces, and now beyond metric spaces to topological spaces. If the discussion of continuity in analysis is primarily for the sake of differentiation, in topology, the concept of continuity is necessary to discuss homeomorphisms.\nBelow are various equivalent conditions for continuous points and continuous functions. Since these are equivalent conditions, they can sometimes be used as definitions depending on the textbook.\nEquivalent Conditions for Continuous Points If we denote by $a \\in X$, the following propositions are equivalent:\n(1): $f : X \\to Y$ is continuous at $a$. (2): For every neighborhood $V \\in \\mathscr{T}_{Y}$ containing $f(a)$, there exists a neighborhood $ U \\in \\mathscr{T}_{X}$ satisfying $a \\in U \\subset f^{-1} (V)$. (3): For every $\\mathcal{N} ( f(a) )$, $f^{-1} ( \\mathcal{N} ( f(a) ) )$ is a neighborhood of $a$. (4): For all $V \\subset Y$ satisfying $f(a) \\in V^{\\circ}$, $a \\in (f^{-1} (V))^{\\circ} $ holds. It\u0026rsquo;s worth mentioning that $\\mathcal{N} (a)$ is an open set in $X$ containing $a$, known as the neighborhood of $a$.\nEquivalent Conditions for Continuous Functions The following propositions are equivalent:\n[1]: $f : X \\to Y$ is a continuous function. [2]: For every neighborhood $V \\in \\mathscr{T}_{Y}$ containing $f(a)$ and every point $a \\in f^{-1} (V)$, there exists a neighborhood $ U_{a} \\in \\mathscr{T}_{X}$ satisfying $a \\in U_{a} \\subset f^{-1} (V)$. [3]: For every open set $V \\subset Y$, $f^{-1} (V)$ is an open set in $X$1. [4]: For every closed set $C \\subset Y$, $f^{-1} (C)$ is a closed set in $X$. [5]: For every $A \\subset X$, $f( \\overline{A} ) \\subset \\overline{ f(A) } $ holds. [6]: For every $B \\in \\mathscr{B}$, there exists a basis $\\mathscr{B}$ of $\\mathscr{T}_{Y}$ satisfying $f^{-1} (B) \\in \\mathscr{T}_{X}$. [7]: For every $S \\in \\mathscr{S}$, there exists a sub-basis $\\mathscr{S}$ of $\\mathscr{T}_{Y}$ satisfying $f^{-1} (S) \\in \\mathscr{T}_{X}$. [8]: Composition of continuous functions: If $f : X \\to Y$ and $g : Y \\to Z$ are continuous functions, then the composite function $g \\circ f : X \\to Z$ is also continuous. Another Definition of Continuous Functions Especially, \u0026lsquo;Theorem [3]: For every open set $V \\subset Y$, $f^{-1} (V)$ is an open set in $X$\u0026rsquo; is frequently used and often serves as the definition of continuous functions. While it\u0026rsquo;s not necessary to memorize all listed conditions, it\u0026rsquo;s crucial to remember [3] and be able to apply it readily.\nMunkres. (2000). Topology(2nd Edition): p102.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":432,"permalink":"https://freshrimpsushi.github.io/en/posts/432/","tags":null,"title":"Continuous in Topology"},{"categories":"Ï†ïÏàòÎ°†","contents":"Theorem 1 Prime numbers $p$ and integers $a$ that are coprime to each other, $a^{p-1} \\equiv 1 \\pmod{p}$\nExplanation Fermat\u0026rsquo;s little theorem is a straightforward yet highly influential theorem used in a variety of fields. Although there is a generalized theorem by Euler, Fermat\u0026rsquo;s little theorem is often sufficient. It is particularly essential in fields like cryptography that extensively deal with exponentiation in finite fields.\nProof Strategy: The proof is brutishly simple yet not trivial. If $$ a \\cdot 2a \\cdot \\cdots \\cdot (p-1)a \\equiv (p-1)! \\pmod{p} $$ is established, then eliminating $(p-1)!$ from both sides would prove Fermat\u0026rsquo;s little theorem. That is, it suffices to show that two sets $\\left\\{ a,2a,\\cdots , (p-1)a \\right\\}$ and $\\left\\{1,2,\\cdots ,(p-1) \\right\\}$ are identical in $\\pmod{p}$.\nThe set $\\left\\{ a,2a,\\cdots , (p-1)a \\right\\}$ has exactly $(p-1)$ elements as a finite set. Since $a$ is coprime to $p$, the remainders when these elements are divided by $p$ will be integers between $1$ and $(p-1)$. If there are no duplicates among those remainders, then $$ \\left\\{ a,2a,\\cdots , (p-1)a \\right\\} = \\left\\{1,2,\\cdots ,(p-1) \\right\\} $$ will hold. Consider two distinct elements $ia$ and $ja$ from $\\left\\{ a,2a,\\cdots , (p-1)a \\right\\}$. Assuming the remainders of dividing both by $p$ are the same implies that $ia \\equiv ja \\pmod{p}$ holds. Since $a$ is coprime to $p$, canceling out $a$ from both sides also makes $i \\equiv j \\pmod{p}$ valid. However, within the set, $i$ and $j$ were integers greater than $0$ and less than $p$, thus $ia$ and $ja$ are also the same. This contradicts the assumption, indicating that the remainders when different elements are divided by $p$ are always distinct. With no duplicates among the remainders, in $\\pmod{p}$, $$ \\left\\{ a,2a,\\cdots , (p-1)a \\right\\} = \\left\\{1,2,\\cdots ,(p-1) \\right\\} $$ holds. Moreover, since $p$ is a prime, it is coprime to $(p-1)!$. $$ (p-1)! a^{p-1} \\equiv (p-1)! \\pmod{p} $$ Upon eliminating $(p-1)!$ from both sides, the congruence $a^{p-1} \\equiv 1 \\pmod{p}$ is obtained.\n‚ñ†\nKeep in mind the following corollaries as well.\nCorollaries [1] Inverse: In $\\pmod{p}$, the multiplicative inverse of $a$ is necessarily given as $$ a^{-1} \\equiv a^{p-2} \\pmod{p} $$ [2] Fermat\u0026rsquo;s test: If $a^n \\equiv a \\pmod{n}$ does not hold, then $n$ is a composite number. Determining whether a number is prime can be challenging, but identifying a composite number is relatively easier. Note that the converse of Fermat\u0026rsquo;s test is not true. A counterexample that demonstrates the failure of the converse is Carmichael numbers. For instance, although $561=3 \\cdot 11 \\cdot 17$ is a composite, $a^{561} \\equiv a \\pmod{561}$ always holds.\nCode The following is an implementation of Fermat\u0026rsquo;s test in R, utilizing the method of exponentiation by squaring.\nFPM\u0026lt;-function(base,power,mod) #It is equal to (base^power)%%mod\r{\ri\u0026lt;-0\rif (power\u0026lt;0) {\rwhile((base*i)%%mod != 1) {i=i+1}\rbase\u0026lt;-i\rpower\u0026lt;-(-power)}\rif (power==0) {return(1)}\rif (power==1) {return(base%%mod)}\rn\u0026lt;-0\rwhile(power\u0026gt;=2^n) {n=n+1}\rA\u0026lt;-rep(1,n)\rA[1]=base\rfor(i in 1:(n-1)) {A[i+1]=(A[i]^2)%%mod}\rfor(i in n:1) {\rif(power\u0026gt;=2^(i-1)) {power=power-2^(i-1)}\relse {A[i]=1} }\rfor(i in 2:n) {A[1]=(A[1]*A[i])%%mod}\rreturn(A[1])\r}\rfermat.test\u0026lt;-function(n)\r{\rfor(i in 2:(n-1)) {if( i!=FPM(i,n,n) ) {return(paste(i,\u0026#34;is a Fermat witness!\u0026#34;))}}\rpaste(n,\u0026#34;passes the Fermat test!\u0026#34;)\r}\rfermat.test(121)\rfermat.test(341) #Almost composite yields fermat witness 2, but 341=11*31 doesn\u0026#39;t.\rfermat.test(561) #Carmicheal number 561 = 3*11*17\rfermat.test(1031) #1031 is a prime\rfermat.test(1105) #Carmicheal number 1105 = 5*13*17\rfermat.test(1729) #Carmicheal number 1729 = 7*13*19\rfermat.test(41041) #Carmicheal number 41041 = 7*11*13*41 Below is the result of executing the code.\nFermat\u0026rsquo;s test was able to definitively catch composites such as $121$ or $341$ and correctly passed prime numbers like $1031$. However, it failed to catch Carmichael numbers such as $561$, $1105$, $1729$, and $41041$. To detect Carmichael numbers, one would need to use a method like the Miller-Rabin test.\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p66.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":121,"permalink":"https://freshrimpsushi.github.io/en/posts/121/","tags":null,"title":"Proof of Fermat's Little Theorem"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 Let\u0026rsquo;s say there is a topological space $\\left( X , \\mathscr{T} \\right)$ and consider $\\mathscr{S} \\subset \\mathscr{T}$.\nWhen $\\displaystyle \\mathscr{B} = \\left\\{ \\left. B = \\bigcap_{ i = 1}^{n} S_{i} \\ \\right| \\ S_{i} \\in \\mathscr{S} \\right\\}$ becomes the basis for $\\mathscr{T}$, then $\\mathscr{S}$ is called a Subbasis for $\\mathscr{T}$.\nExplanation The reason why accepting the concept of subbasis can be difficult is because the term \u0026lsquo;sub\u0026rsquo; in mathematics usually implies a subset while maintaining the original properties. For example, a subgroup means a subset that satisfies the conditions of a group, and a subspace means a subset that satisfies the conditions of the space. In this sense, the term subbasis can be more confusing than the concept itself.\nBy definition, if $\\mathscr{S}$ has become a subbasis then being a subset, that is $\\mathscr{S} \\subset \\mathscr{B}$, of the basis $\\mathscr{B}$ is trivial. However, since $\\mathscr{S}$ must constitute $\\mathscr{B}$ as a set of all finite intersections to become a basis, it can also be described as still immature as a basis.\nRather, considering mathematics thus far, it seems more natural to say that subbasis is the basis of a basis. The problem lies in the fact that despite understanding the term \u0026lsquo;sub\u0026rsquo;, the definition of subbasis itself remains complex and bizarre. It is easier to accept this for the study of the product of topological spaces later on. After studying it to some extent, one would also understand why it is specifically finite intersections that are considered.\nNow let\u0026rsquo;s grasp the concept a bit more through an example.\nExample Show that $\\mathscr{S} = \\left\\{ (- \\infty , b ), ( a , \\infty ) \\ | \\ a,b \\in \\mathbb{R} \\right\\}$ is a subbasis for the metric space $\\mathbb{R}$.\nSolution Since all open intervals $(a,b)$ can be formed as the intersection of two open intervals $( - \\infty , b )$ and $( a , \\infty )$, $\\mathscr{S}$ becomes a subbasis.\n‚ñ†\nMunkres. (2000). Topology(2nd Edition): p82.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":427,"permalink":"https://freshrimpsushi.github.io/en/posts/427/","tags":null,"title":"Subbasis in Topology"},{"categories":"Ï†ïÏàòÎ°†","contents":"Theorem 1 Every natural number $n \u0026gt;2$ has a unique prime factorization $n = p_{1} p_{2} \\cdots p_{r}$. The order of the primes $p_{1} , p_{2} , \\cdots , p_{r}$ is ignored.\nExplanation It may seem strange that a property we\u0026rsquo;ve naturally used since elementary school requires proof, but it is extremely important. The fact that this is so simple perhaps serves as evidence that it merits the name theorem.\nProof Elementary Proof Part 1. Existence\nGiven $2=2$ and $3= 3$, and $4 = 2^2$, there exists a unique prime factorization. For all possible $n$, let\u0026rsquo;s find the prime factorization, and say the last number is $N$. Here, $N+1$ could be a prime or a composite number, so let\u0026rsquo;s check both cases.\nCase 1. If $N+1$ is Prime\nIf $N+1$ is a prime, then it is its own prime factorization. Case 2. If $N+1$ is Composite\nIf $N+1$ is composite, it can be represented as the product of two natural numbers $N+1 = n_{1} n_{2}$. Since we\u0026rsquo;ve found the prime factorization for all natural numbers up to $N$, $$ n_{1} = p_{1} p_{2} \\cdots p_{m} \\\\ n_{2} = q_{m+1} q_{m+2} \\cdots q_{r} $$, by simply multiplying, we obtain $N+1 = p_{1} p_{2} \\cdots p_{r}$, thus we can determine the prime factorization of $N+1$. Since we can find the prime factorization for $N+1$ in both cases, all natural numbers greater than $2$ have a prime factorization.\nPart 2. Uniqueness\nNow we need to show that $n = p_{1} p_{2} \\cdots p_{r}$ is unique.\nAssuming that $n$ has a non-unique prime factorization, so that $n = p_{1} p_{2} \\cdots p_{r} = q_{1} q_{2} \\cdots q_{s}$ holds. The order does not affect uniqueness, so for convenience, let\u0026rsquo;s say $p_{1} \\le p_{2} \\le \\cdots \\le p_{r}$.\nPrime Factorization Principle: If a prime $p$ divides a natural number $ n : = d_{1} d_{2} \\cdots d_{r}$ such that $p \\mid n$, then $p$ must divide at least one of $d_{1} , d_{2} , \\cdots , d_{r}$.\nSince a prime dividing some number must divide at least one of its factors, $p_{1}$ must divide one of $q_{1} , q_{2} , \\cdots , q_{s}$. The order is free, so a divisible $q_{i}$ by $p_{1}$ can be considered as $q_{1}$, and $q_{1}$ could substitute for $q_{i}$.\nHowever, since $q_{1}$ is also a prime like $p_{1}$, $p_{1} = q_{1}$ holds and $$ p_{1} p_{2} \\cdots p_{r} = q_{1} q_{2} \\cdots q_{s} $$, eliminating both from each side gives $$ p_{2} \\cdots p_{r} = q_{2} \\cdots q_{s} $$. The same method continues until one side becomes $1$. If the other side is not $1$, the product of primes must be greater than $1$, making the equation invalid. Therefore, $$ p_{1} =q_{1} \\\\ p_{2} = q_{2} \\\\ \\vdots \\\\ p_{i} = q_{i} \\\\ \\vdots $$ must hold, and finally, $p_{r} = q_{s}$ must be true.\n‚ñ†\nAlgebraic Proof Algebraic Proof of the Fundamental Theorem of Arithmetic: The ring of integers $\\mathbb{Z}$](../587) is a PID, thus a UFD.\n‚ñ†\nCode Below is the implementation of prime factorization in R. It\u0026rsquo;s fast because it doesn\u0026rsquo;t need to check for primes, using a list of primes instead. As an algorithm, it\u0026rsquo;s virtually useless. It returns the factorization in list form, which might be less readable. If you want it in exponential form, simply use the built-in function table() on the returned vector.\nprime = read.table(\u0026#34;../attachment /cfile8.uf@25411C3C5968BBE322F0D4.txt\u0026#34;); prime = prime[,1] factorize\u0026lt;-function(p) { q=p factors\u0026lt;-numeric(0) i=1; j=1 while(q!=1) { if(q%%prime[i]) {i=i+1} else { q\u0026lt;-q/prime[i] factors[j]\u0026lt;-prime[i] i=1 j=j+1 } } return(factors) } factorize(54) factorize(101) factorize(256) factorize(420) table(factorize(420)) Here is the result of running the code.\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p49.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":419,"permalink":"https://freshrimpsushi.github.io/en/posts/419/","tags":null,"title":"Fundamental Theorem of Arithmetic Proof"},{"categories":"Ï†ïÏàòÎ°†","contents":"Theorem 1 For two integers $a,b$, there always exists an integer solution for $ax + by = \\gcd (a,b)$.\nDescription This theorem is also known as the Linear Congruence Theorem as it implies that $\\gcd (a,b)$ can be expressed as a linear equation involving $a$ and $b$.\nAlthough its appearance seems somewhat complex and it only discusses existence, it is surprisingly widely used. It might not provide a specific solution $(x,y)$, but the fact that we can start from the relationship between $a$ and $b$ is a significant gain. It is incredibly useful especially when we don‚Äôt know what $x$ and $y$ are.\nProof Elementary Proof Strategy: As the name suggests, the Extended Euclidean Theorem repeats the Euclidean algorithm. Hence, it is also referred to as the Extended Euclidean Algorithm.\nEuclidean algorithm: For $ r_i\u0026lt;r_{i+1}$, let\u0026rsquo;s define $a: = r_{-1}$ and $b:=r_{0}$ that satisfy the recurrence relation $r_{i-1} = q_{i+1} \\cdot r_{i} + r_{i+1}$. For $n$ that satisfies $r_{n+1} = 0$, $r_{n} = \\gcd (a,b)$\nAccording to the Euclidean algorithm, $r_{1}$ is $$ r_{1} = a - q_{1} b $$ In other words, it can be represented as a linear combination of $a$ and $b$. Meanwhile, $$ r_{2} = b - q_{2} r_{1} $$ and substituting the above $r_{1} = a - q_{1} b$ yields $$ \\begin{align*} r_{2} =\u0026amp; b - q_{2} r_{1} \\\\ =\u0026amp; b - q_{2} ( a - q_{1} b ) \\\\ =\u0026amp; -q_{2} a + ( 1 + q_{1} q_{2} ) b \\end{align*} $$ meaning $r_{2}$ can also be represented as a linear combination of $a$ and $b$. Repeating this $n$ times, $r_{n}$ can be expressed for some $x,y \\in \\mathbb{Z}$ as $$ r_{n} = x a + y b $$ Since the Euclidean algorithm ensures $r_{n} = \\gcd (a,b)$, $(x,y)$ exists as a solution for $ax + by = \\gcd (a,b)$.\n‚ñ†\nAlgebraic Proof The ring of integers $\\mathbb{Z}$ is a PID, hence a Bezout domain.\n‚ñ†\nSee Also Generalization: Bezout Domain As pointed out in the algebraic proof, if a domain is a Bezout domain, then the Extended Euclidean Theorem applies no matter where that domain is.\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p42.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":417,"permalink":"https://freshrimpsushi.github.io/en/posts/417/","tags":null,"title":"Proof of the Extended Euclidean Theorem"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 A permutation is a bijection $\\phi : A \\to A$ for a set $A$. $S_{A}$ is the set of all permutations of $A$, which forms a group $\\left\u0026lt; S_{A} , \\circ \\right\u0026gt;$ with respect to function composition $\\circ$, and is called the symmetric group.\nExplanation The fact that symmetric groups indeed satisfy the conditions of a group can be easily ascertained, given that a permutation is defined as a bijection. The main interest lies in when $A$ is a finite set, namely when it is $|A| = n$, which is commonly denoted as $S_{A} = S_{n}$.\nSymmetry of a Triangle The concept of permutation is not essentially different from what is learned in high school. Consider $A = \\left\\{ 1,2,3 \\right\\}$. Since the number of elements is $3$, the order of the symmetric group $S_{3}$ is $3! = 6$. Since it is not a large number, let\u0026rsquo;s list them all. The representation is similar to a matrix, where the element in row $1$ is mapped to the element in row $2$. $$ \\rho_{0} = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 2 \u0026amp; 3 \\end{bmatrix} \\qquad \\rho_{1} = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 3 \u0026amp; 1 \\end{bmatrix} \\qquad \\rho_{2} = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 1 \u0026amp; 2 \\end{bmatrix} \\\\ \\mu_{1} = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 3 \u0026amp; 2 \\end{bmatrix} \\qquad \\mu_{2} = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 2 \u0026amp; 1 \\end{bmatrix} \\qquad \\mu_{3} = \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 1 \u0026amp; 3 \\end{bmatrix} $$\nRepresented graphically, it appears as follows:\n$\\rho_{k}$ is rotating the triangle in a counterclockwise direction by $\\displaystyle {{2 k \\pi} \\over {n}}$ with respect to $|A| = n$. Here, $\\rho_{0}$ represents a rotation that has no effect on the shape, serving as the identity element in the symmetric group. The reason for using $\\rho$ is that it stems from Rotation. $\\mu_{k}$ is swapping the two points while fixing $k$, or it could be described as flipping over a symmetry line that bisects $1$, just like a mirror image. The reason for using $\\mu$ is that it originates from Mirror Image. Not Commutative Concerning $n \\ge 3$, $S_{n}$ is not a commutative group.\nOne interesting property of a symmetric group is that it is not a commutative group.\nThe table above shows all the operations in $S_{3}$, for example, $\\rho_{1} \\circ \\mu_{1} = \\mu_{3}$ while $\\mu_{1} \\circ \\rho_{1} = \\mu_{2}$. Thus, $$ \\rho_{1} \\circ \\mu_{1} \\ne \\mu_{1} \\circ \\rho_{1} $$ hence, $S_{3}$ is not a commutative group. A true proof is sufficient by showing through mathematical induction that all $S_{n}$ have such exceptions.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p76~79.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":421,"permalink":"https://freshrimpsushi.github.io/en/posts/421/","tags":null,"title":"Symmetry Groups in Abstract Algebra"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition Let\u0026rsquo;s say topological space $\\left( X , \\mathscr{T} \\right)$ with respect to $\\mathscr{B} , \\mathscr{B}_{x} \\subset \\mathscr{T}$.\nWhen we say $B_{\\lambda} \\in \\mathscr{B}$, if for every $U \\in \\mathscr{T}$ there exists a neighbourhood $\\Lambda$ that satisfies $$ U = \\bigcup_{\\lambda \\in \\Lambda} B_{ \\lambda } $$ then $\\mathscr{B}$ is called a basis for $\\mathscr{T}$. In this case, the topology $\\mathscr{T}$ is said to be generated by $\\mathscr{B}$. When we say $x \\in X$, if for every $B \\in \\mathscr{B}_{x}$ there exists $x \\in B$ and for all $U \\in \\mathscr{T}$ that include $x$, $$ x \\in B \\subset U $$ there exists $B \\in \\mathscr{B}_{x}$ that satisfies this, then $\\mathscr{B}_{x}$ is called a local basis at $x$. Explanation Since the definition is quite confusingly written, it will be much more comfortable to conceptually grasp it before trying to solve exercises. Don\u0026rsquo;t try too hard to find the relevance with the basis in linear algebra; the definition isn\u0026rsquo;t much similar besides the feel.\nIn a word, a basis is a set that can be made by the union of the given topology. Since there\u0026rsquo;s no need to think about the intersection, just gather \u0026lsquo;small\u0026rsquo; open sets in the topology and compose them.\nFor example, in a metric space, the set of all open balls becomes a basis for the metric space.\nNecessity From the perspective of studying from books, it feels difficult and puzzling to think about finding a basis $\\mathscr{B}$ in the topology $\\mathscr{T}$ like in linear algebra. On the contrary, if you adopt the standpoint of generating, that is, making a topology from a basis, the concept of basis cannot be handier.\nFor instance, if you wanted to create a topological space using sequences of natural numbers, to base the topology on the first term, $B_{1}$ would be the set of sequences with first term $1$, $B_{2}$ would be the set of sequences with first term $2$, $B_{k}$ would be the set of sequences with first term $k$\u0026hellip; And you could approach this by considering them as open sets. The problem is that there\u0026rsquo;s no union $B_{1} \\cup B_{2}$ in $\\mathscr{T}$. Because there are no sequences whose first term is either $1$ or $2$, but if you just assume every possible union in $\\mathscr{B} = \\left\\{ B_{k} \\right\\}_{k \\in \\mathbb{N}}$ exists, the task becomes much easier. This is truly making good use of the topology generated by a basis.\nCriterion 1 Criterion for a basis: For the entire set $X$, $\\mathscr{B} \\subset \\mathscr{P} (X)$ is the basis of $X$ when the following two conditions are met:\n(i): $\\displaystyle X = \\bigcup_{B \\in \\mathscr{B}} B$ (ii): For all $ B_{1} , B_{2} \\in \\mathscr{B}$ such that $x \\in B_{1} \\cap B_{2}$, there exists $B_{x} \\in \\mathscr{B}$ satisfying: $$ x \\in B_{x} \\subset B_{1} \\cap B_{2} $$ This criterion is a useful theorem that can be effectively used in actual problem solving, so make sure to remember it. Depending on the textbook, this criterion could rather be the definition.\nA local basis, unlike the general concept of a basis which is for the entire topology, is a concept only dealing with a given point. Although it\u0026rsquo;s a lengthy and complicated explanation, in summary, it only needs to collect the \u0026lsquo;smallest\u0026rsquo; among all open spaces that include $x$ to satisfy the conditions for a local basis.\nFor example, in a metric space, the set of all open balls centered at $x$ becomes the local basis at $x$.\nRelation between Basis and Local Basis Let\u0026rsquo;s say $X$ is a topological space.\nIf $\\mathscr{B}$ is a basis for $X$, then $\\mathscr{B}_{x} := \\left\\{ B \\in \\mathscr{B} \\ | \\ x \\in B \\right\\}$ is a local basis at $x \\in X$. Conversely, if for every $x \\in X$, $\\mathscr{B}_{x}$ is a local basis, then $\\displaystyle \\mathscr{B} := \\bigcup_{x \\in X} \\mathscr{B}_{x}$ is a basis for $X$.\nPrecautions Note that it\u0026rsquo;s not a necessary and sufficient condition, so for the converse to hold, it\u0026rsquo;s important to consider local bases at all points.\nMunkres. (2000). Topology(2nd Edition): p78.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":412,"permalink":"https://freshrimpsushi.github.io/en/posts/412/","tags":null,"title":"Bases and Local Bases in Topology"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 Let\u0026rsquo;s suppose that a topological space $X$ is given.\nIf every point $x \\in X$ has a countable local base, it is called a first-countable space. If $X$ has a countable base, it is called a second-countable space. Explanation Through the concepts of base and local base, a new branch of countability has been created.\nExamples of spaces not being first-countable Discrete spaces $\\left( \\mathbb{R} , \\mathscr{T}_{f} \\right)$ are not first-countable, and needless to say, they are not second-countable either.\nIntuitive Understanding Although not an accurate explanation, one can understand the first-countability as the feeling that at every point, there exists a countable number of open sets. On the other hand, the second-countability conveys a sense that a countable set encompasses the whole, closely related to the concept of separability. First-countability and second-countability are not mutually exclusive contrary to first-category \u0026amp; second-category and have an inclusion relationship. This can be readily verified by considering the relationship between a base and a local base. Moreover, as previously mentioned, second-countability not only resembles the concept of separability but in fact, it can also be shown to embody true separability.\nSummary [1]: Every second-countable space is a first-countable space. [2]: Every second-countable space is separable. Proof Every second-countable space is first-countable If $X$ is a second-countable space, then $X$ will have a countable base $\\mathscr{B}$.\nRelationship between base and local base: If $\\mathscr{B}$ is a base for $X$, then $\\mathscr{B}_{x} := \\left\\{ B \\in \\mathscr{B} \\ | \\ x \\in B \\right\\}$ is a local base for $x \\in X$.\nSince $\\mathscr{B}_{x} = \\left\\{ B \\in \\mathscr{B} \\ | \\ x \\in B \\right\\}$ is countable for all $x \\in X$, $X$ is first-countable.\n‚ñ†\nEvery second-countable space is separable Suppose $X$ is a second-countable space that has a countable base $\\mathscr{B}$. For every non-empty set $B \\in \\mathscr{B}$, let\u0026rsquo;s choose $x_{B} \\in B$ and define $D : = \\left\\{ x_{B} \\in B \\ | \\ \\emptyset \\ne B \\in \\mathscr{B} \\right\\}$. Since $D$ is constructed by selecting elements from the countable base $\\mathscr{B}$, $D$ is also countable, and proving $\\overline{D} = X$ concludes the proof.\nLet\u0026rsquo;s say $U$ is an open set that contains $x \\in X \\setminus D$.\nSince $\\mathscr{B}$ is a base for $X$, there exists $B \\in \\mathscr{B}$ satisfying $x \\in B \\subset U$. Since $x_{B} \\in B \\cap D$ and $x \\notin D$, we have $$ D \\cap (B \\setminus \\left\\{ x \\right\\} ) \\ne \\emptyset $$. As mentioned earlier, since $B \\subset U$, $$ D \\cap (U \\setminus \\left\\{ x \\right\\} ) \\ne \\emptyset $$ still holds. By the definition of a limit point, $x$ is a limit point of $D$, and since $x \\in \\overline{D}$, $X \\setminus D \\subset \\overline{D}$ holds. Of course, since $D \\subset \\overline{D}$, to satisfy both conditions, it must be that $X = \\overline{D}$.\n‚ñ†\nMunkres. (2000). Topology(2nd Edition): p190.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":413,"permalink":"https://freshrimpsushi.github.io/en/posts/413/","tags":null,"title":"The First Countable and the Second Countable"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Definition 1 A function $f: A \\subset \\mathbb{C} \\to \\mathbb{C}$ that is analytic at $\\mathscr{R} \\subset A$ and for all $z \\in \\mathscr{R}$ satisfies $f ' (z) \\ne 0$ is called a Conformal Mapping if $f$. Meanwhile, if there exists a point $\\alpha$ that satisfies $f ' (\\alpha) = 0$, then $\\alpha$ is referred to as the Critical Point of $f$.\nDescription As the Chinese characters for conformal (Á≠âËßí) directly imply, angles between figures are preserved under a conformal transformation.\nIt\u0026rsquo;s essential to know that the composition of conformal mappings is still a conformal mapping. Proof of this can be sufficiently demonstrated by verifying the following contrapositive. $$ (f \\circ g) \u0026rsquo; = f '(g) g' = 0 \\iff g' = 0 \\lor f ' = 0 $$\nSuch conformal transformations are very important in complex analysis, which often deals with simple closed paths, as they are helpful when handling integration paths. Geometrically, critical points can be considered points where the direction changes completely, i.e., where it pivots. On the other hand, analytic functions that are injective have the following two crucial properties.\nFundamental Properties 1 [1]: If a function $f$ is analytic and injective in $\\mathscr{R}$, then for all $z \\in \\mathscr{R}$, $f ' (z) \\ne 0$ is satisfied. In other words, $f$ is a conformal mapping. [2]: If a function $f$ is analytic and injective in $\\mathscr{R}$ and maps a simple closed path $\\mathscr{C}$ to $\\mathscr{C} ' $, then $f$ maps points inside $\\mathscr{C}$ to either the inside or outside of $\\mathscr{C} ' $ only. Note that the condition in [1] is not sufficient and necessary. [2] Is particularly important because, by checking just one point inside $\\mathscr{C}$, one can determine whether the rest of the points are mapped to the inside or outside of $\\mathscr{C} ' $. Osborne (1999). Complex variables and their applications: p193, 196.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":409,"permalink":"https://freshrimpsushi.github.io/en/posts/409/","tags":null,"title":"What is a Conformal Mapping in Complex Analysis?"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Theorem In general, in a topological space, the limit of a sequence is not unique.\nExplanation This might sound surprising, but it is indeed true. Until now, we have been accustomed to the image of intervals containing sequences in analysis narrowing down to converge to a point. However, according to the concept of convergence defined in topology, there is no reason for sequences to converge to a single point depending on the topological space.\nTo ensure the uniqueness of a limit, Hausdorff spaces are commonly assumed.\nCounterexample It is sufficient to present a counterexample where multiple limits exist.\nConsider a sequence $\\left\\{ x_{n} \\right\\}$ consisting of distinct points in an ample space $\\left( \\mathbb{R} , \\mathscr{T}_{f} \\right)$. Let us arbitrarily set a point of convergence for $\\left\\{ x_{n} \\right\\}$ as $x \\in \\mathbb{R}$. There exists an open set $U \\in \\mathscr{T}_{f}$ containing $x$, and $\\mathbb{R} \\setminus U$ is a finite set. Since $\\left\\{ x_{n} \\right\\}$ consists of distinct points, for all $n \u0026gt; n_{0}$, there cannot be $n_{0} \\in \\mathbb{N}$ satisfying $x_{n} \\notin \\mathbb{R} \\setminus U$. However, since $\\left\\{ x_{n} \\right\\}$ does converge, for all $n \u0026gt; n_{0}$, there must exist $n_{0} \\in \\mathbb{N}$ satisfying $x_{n} \\in U$. By the definition of convergence, $\\left\\{ x_{n} \\right\\}$ converges to $x$, but it doesn\u0026rsquo;t particularly matter what $x$ is.\n‚ñ†\nIf this is confusing, it\u0026rsquo;s helpful to think about how the definition of convergence has changed and what an open set in an ample space means.\nIn the traditional metric space, an open set referred to a collection of points within a given distance from a central point. Therefore, although it is said to be \u0026ldquo;all open sets,\u0026rdquo; the key was to satisfy the condition in the vicinity of the point. If the condition continues to be satisfied no matter how small the set is chosen, it\u0026rsquo;s as if the check for \u0026ldquo;all open sets\u0026rdquo; is complete.\nHowever, in an ample space, if we consider $U$ and another open space, something like $U \\setminus \\left\\{ a \\right\\}$ also becomes an open set. Whether the entire space is real numbers or anything else, removing each point one by one still results in an open set, making it meaningless to consider \u0026ldquo;distance\u0026rdquo; here. Therefore, even if we check all open sets, there\u0026rsquo;s no reason for them to gradually diminish, and the limit is not specified.\n","id":407,"permalink":"https://freshrimpsushi.github.io/en/posts/407/","tags":null,"title":"Limits of sequence are not unique in general Space"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 For a topological space $X$, let\u0026rsquo;s say $A \\subset X$.\nWhen an open set $O$ exists that satisfies $x \\in O \\subset A$, $x$ is called the interior point of $A$. The set of interior points of $A$, $A^{\\circ}$, is called the interior of $A$. The union of $A$ and its codomain $\\overline{A} : = A \\cup a '$ is called the closure of $A$. When $x \\in \\overline{A}$ and also $x \\in \\overline{X \\setminus A}$, $x$ is called the boundary point of $A$. $\\partial A : = \\overline{A} \\cap \\overline{X \\setminus A}$ is called the boundary of $A$. When $\\overline{A} = X$, $A$ is said to be dense in $X$. When $\\left( \\overline{A} \\right) ^{\\circ} = \\emptyset$, $A$ is said to be nowhere dense in $X$. If $X$ has a dense countable subset, then $X$ is said to be separable. $\\overline{A}$ and $A^{\\circ}$ are the closure and interior of $A$, respectively. Explanation Let‚Äôs confirm that various definitions previously defined in metric spaces can also be brought over without any problems.\nA typical example of a separable space is $\\overline{ \\mathbb{Q} } = \\mathbb{R}$.\nIf the notion of a countable subset is difficult, one might first think of segmenting the real space $\\mathbb{R}$ with the set of integers $\\mathbb{Z}$. Although this imagery is easy to imagine, dividing any set into its subsets is easy and thus meaningless. Conversely, dividing it into uncountable subsets would be too chaotic to manage and ultimately meaningless. On the other hand, if there is a concept that satisfies both density and countability, as defined, it could be considered neither too simple nor too difficult. In such a case, the subset $A$, though referred to as a subset, must feel like a large \u0026lsquo;skeleton\u0026rsquo; that supports the entire set.\nTaking the metaphor of a skeleton a step further, saying that a space is a separable space essentially guarantees the existence of sequences $\\left\\{ x_{n} \\right\\}_{n \\in \\mathbb{N} }$ converging to $x$, for any given $x \\in X$. For example, if $x \\in \\mathbb{R}$ is given, it means that we can find a sequence of rationals $\\left\\{ q_{n} \\right\\}_{n \\in \\mathbb{N}}$ that converge to $x$ no matter what $x$ is.\nThe importance of separability lies in it enabling us to create sequences (countable) that converge (dense) to the elements we desire. From a practical standpoint, the usefulness of this property becomes even more apparent. In applied mathematics, approximating some complex functions with well-known, simpler functions is undoubtedly crucial.\nFor instance, the space of continuous functions $C[a,b]$ is a separable space, which means we can find a sequence of continuous functions $\\left\\{ f_{n} \\right\\}_{n \\in \\mathbb{N}}$ that converge to any given $f$. Uncovering what exactly these $\\left\\{ f_{n} \\right\\}_{n \\in \\mathbb{N}}$ are is the responsibility of applied mathematics, such as numerical analysis, but proving their existence is the purview of pure mathematics.\nSummary Methods to Determine Density As a way to determine density, remember the following useful equivalence condition:\nFor $A$ to be dense in $X$ is equivalent to every open subset $U$ of $X$ having an intersection with $U \\cap A \\ne \\emptyset$.\nBasic Properties: Boundary of a Subspace [1]: $\\partial A \\subset A \\iff A = \\overline{A}$ [2]: $\\partial A \\subset X \\setminus A \\iff A = A^{\\circ}$ [3]: $\\partial A = \\emptyset \\iff A = A^{\\circ}= \\overline{A}$ It\u0026rsquo;s unrelated to countability, but now that these concepts are newly defined, make sure to be aware of these properties.\nUsing the boundary to determine whether space is open or closed can be a useful property. As one becomes more accustomed to topology, realizing that spaces can become increasingly abstract, it\u0026rsquo;s important to be thankful that one can infer definitions and contemplate just from the words.\nMunkres. (2000). Topology(2nd Edition): p95, 97.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":405,"permalink":"https://freshrimpsushi.github.io/en/posts/405/","tags":null,"title":"Topological Spaces: Separability and Closure"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 For two binary operation structures $\\left\u0026lt; S , * \\right\u0026gt;$ and $\\left\u0026lt; S' , *' \\right\u0026gt;$, if there exists a bijective function $\\phi : S \\to S'$ such that for all $x , y \\in S$, $$ \\phi (x \\ast\\ y) = \\phi ( x ) *' \\phi ( y ) $$ is satisfied, then $\\phi$ is called an isomorphism, and $S$ and $S'$ are said to be isomorphic, denoted as $S \\simeq S'$.\nDescription To summarize the definition, if there is a bijection that preserves operations, they are essentially considered the same. Not only in abstract algebra, this mapping, known as isomorphism, is very important throughout mathematics.\nIf $\\phi$ preserves the operation but is not a bijection, it is called a homomorphism. Like this, there are many important mappings that are not isomorphisms, and there is extensive research on them.\nThe following theorem signifies that the identity of the identity element is also preserved by an isomorphism.\nTheorem If there is an isomorphism $\\phi$ such that $S \\simeq S'$, and if $e$ is the identity element of $S$, then $\\phi (e)$ is the identity element of $S'$.\nProof Since $e$ is the identity element of $S$, for $s \\in S$, $$ e \\ast\\ s = s \\ast\\ e = s $$\n$$ \\phi ( e \\ast\\ s ) = \\phi ( s \\ast\\ e ) = \\phi ( s ) $$ Since $\\phi$ is an isomorphism, for $s' : = \\phi (s) \\in S'$, $$ \\phi ( e ) *' \\phi ( s ) = \\phi ( s ) *' \\phi ( e ) = \\phi ( s ) $$ Therefore, $\\phi (e)$ is the identity element of $S'$.\n‚ñ†\nSee Also Isomorphism in Graph Theory Fraleigh. (2003). A first course in abstract algebra(7th Edition): p29.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":403,"permalink":"https://freshrimpsushi.github.io/en/posts/403/","tags":null,"title":"Isomorphism in Abstract Algebra"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition 1 Let\u0026rsquo;s assume a topological space $\\left( X , \\mathscr{T} \\right)$ is given.\nIf for $A \\subset X$ any open set $O$ containing $x$ satisfies $O \\cap ( A \\setminus \\left\\{ x \\right\\} ) \\ne \\emptyset$, then $x$ is called a limit point of $A$, and the set of all limit points of $A$ is called the derived set of $A$. A sequence $\\left\\{ x_{n} \\right\\}$ in $X$ converges to $x$ if for any open set $O$ containing $x$, there exists $n_{0} \\in \\mathbb{N}$ that satisfies the following: $$ n \\ge n_{0} \\implies x_{n} \\in O $$ Explanation Note that we do not specifically define divergence for sequences that do not converge.\nEven in a topological space, limit points can still be defined, and there seems to be little difference in words. Nothing has changed from the definition in a metric space, but the conceptual difference is significant because although \u0026lsquo;all open sets\u0026rsquo; were considered in a metric space, it felt like narrowing down the interval, whereas in a topological space, supposedly, all kinds of open sets must be considered.\nThat $A$ is a closed set in $X$ is equivalent to $ A ' \\subset A$, which can be easily proved from the definitions of closed sets and limit points. More cleanly, it can be represented by $A = \\overline{A}$ as well because of $\\overline{A} = A \\cup a '$. Especially, in metric spaces, it is expressed as the following theorem.\nTheorem In a metric space $(X,d)$, let\u0026rsquo;s say $K \\subset X$.\n[1]: There exists a sequence of distinct points of $K$ that converges to $x \\in X$, which is a limit point of $K$. [2]: If $K$ is a closed set in $X$, then all converging sequences of $K$ converge to a point of $K$. Munkres. (2000). Topology(2nd Edition): p97.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":400,"permalink":"https://freshrimpsushi.github.io/en/posts/400/","tags":null,"title":"Limit Points and Convergence in Topological Spaces, Image Sets"},{"categories":"ÏúÑÏÉÅÏàòÌïô","contents":"Definition Topological Space 1 Given a set $X$, if $\\mathscr{T} \\subset \\mathscr{P} (X)$ satisfies the following three conditions for $T \\in \\mathscr{T}$, then $\\mathscr{T}$ is called the topology of $X$, and $\\left( X , \\mathscr{T} \\right)$ is called a Topological Space.\n(i): $$\\emptyset , X \\in \\mathscr{T}$$ (ii): $$\\displaystyle \\bigcup_{ \\alpha \\in \\forall } T_{\\alpha} \\in \\mathscr{T}$$ (iii): $$\\displaystyle \\bigcap_{ i= 1}^{n} T_{i} \\in \\mathscr{T}$$ Explained in words, conditions (i)~(iii) are as follows:\n(i): $\\mathscr{T}$ includes the empty set $\\emptyset$ and the entire set $X$. (ii): The union of elements of $\\mathscr{T}$ belongs to $\\mathscr{T}$. (iii): The finite intersection of elements of $\\mathscr{T}$ belongs to $\\mathscr{T}$. Open and Closed Sets 2 $O \\in \\mathscr{T}$ is defined as an Open Set. For $C \\subset X$, if $ X \\setminus C \\in \\mathscr{T}$ is true, then $C$ is defined as a Closed Set. If a set is both an open set and a closed set, it is called a Clopen Set. Explanation Topological Spaces The definition suggests that $\\mathscr{T}$ is closed under $\\cup$ and $\\cap$, evoking thoughts of algebra, but this definition alone makes it hard to find algebraic properties.\nJust as a vector in a vector space becomes a vector not just by having force and direction as learned in high school but by satisfying certain conditions, the topology of topological space is generalized as the set of subsets that satisfy certain conditions.\nOpen and Closed Sets With the definition of topology, the concepts of openness and closure are redefined. In conventional metric spaces, these concepts were defined intuitively, following from intervals open and closed. However, general topology uses sets, which can create abstract and bizarre spaces.\nThe definition reveals that while openness is completely redefined via the concept of topology, closure remains almost the same as in metric spaces.\nBased on the definitions of topology, openness, and closure, the following properties can be easily verified.\nTheorems [1-1]: $\\displaystyle \\bigcup_{ \\alpha \\in \\forall } O_{\\alpha} \\in \\mathscr{T}$ is an open set. [1-2]: $\\displaystyle \\bigcap_{ i= 1}^{n} O_{i} \\in \\mathscr{T}$ is an open set. [2-1]: $\\displaystyle \\bigcap_{ \\alpha \\in \\forall } C_{\\alpha} \\in \\mathscr{T}$ is a closed set. [2-2]: $\\displaystyle \\bigcup_{ i= 1}^{n} C_{i} \\in \\mathscr{T}$ is a closed set. [3]: $\\emptyset$ and $X$ are both open and closed sets. Examples Let\u0026rsquo;s get a feel for topology with the following example.\nShow that for $X:=\\left\\{ a,b,c,d \\right\\}$, $\\mathscr{T} : = \\left\\{ \\emptyset , \\left\\{ b \\right\\} , \\left\\{ a, b \\right\\} , \\left\\{ b,c \\right\\} , \\left\\{ a,b,c \\right\\} , \\left\\{ a,b,c,d \\right\\} \\right\\}$ is the topology of $X$.\n(i): $\\emptyset \\in \\mathscr{T}$ and $\\left\\{ a,b,c,d \\right\\} =X \\in \\mathscr{T}$. (ii): Except for the entire set $X$, $d$ is not used and $\\left\\{ a,b,c \\right\\} \\in \\mathscr{T}$. (iii): Except for the empty set $\\emptyset$, all share $b$ and $\\left\\{ b \\right\\} \\in \\mathscr{T}$. ‚ñ†\nMunkres. (2000). Topological(2nd Edition): p76.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMunkres. (2000). Topology(2nd Edition): p93.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":398,"permalink":"https://freshrimpsushi.github.io/en/posts/398/","tags":null,"title":"What is a Topological Space?"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definition 1 Let\u0026rsquo;s say for a metric space $\\left( X , d \\right)$.\nIf for every sequence $\\left\\{ x_{n} \\right\\}$ in $X$ there exists a natural number $n_{0}$ that satisfies $d(x_{n} , x_{m}) \u0026lt; \\varepsilon$ whenever $\\varepsilon \u0026gt; 0$ for all $n,m \u0026gt; n_{0}$, it is called a Cauchy sequence. If the limiting points of Cauchy sequences in $\\left( X , d \\right)$ belong to $X$, then $\\left( X , d \\right)$ is called complete; otherwise, it is incomplete. When $\\overline{A} = X$, $A$ is said to be dense in $X$. When $\\left( \\overline{A} \\right) ^{\\circ} = \\emptyset$, $A$ is said to be nowhere dense in $X$. If $X$ can be represented as the union of countably many nowhere dense subsets of $X$, $\\left( X , d \\right)$ is called first category; if not, it is referred to as second category. $\\overline{A}$ and $A^{\\circ}$ are the closure, interior of $A$, respectively. Description Completeness The concept of completeness appears to be very similar to that of being closed, often confusing those unfamiliar with topology into thinking of it as being closed. The noticeable difference is that completeness does not require the concept of the entire space, whereas being closed requires the entire space to be defined.\nFor example, if the entire space for $[a,b)$ is given as $[a,b)$, then it becomes a closed set because it is the entire space. However, since there exists a Cauchy sequence converging to $b$ in $[a,b)$, $[a,b)$ is incomplete regardless of what the entire space is.\nHowever, completeness encompasses a more crucial concept than this intuitive understanding. It guarantees that the sequences of interest in the space of interest converge to elements of interest. The lack of completeness in a space could be likened to finding a solution to an equation in complex numbers when the answer should be real. Regardless of what the answer is, if it\u0026rsquo;s not in the form we desire, it\u0026rsquo;s useless, and completeness guarantees that it is.\nWhen first encountering the completeness axiom in analysis, it was difficult to understand why it was called Completeness. In daily life, the English word Complete is not commonly used as \u0026lsquo;fully equipped,\u0026rsquo; but rather used alongside \u0026lsquo;completion\u0026rsquo; or \u0026lsquo;conclusion,\u0026rsquo; denoting the end of something ongoing. Viewing the generalized definition of completeness, the term is apt because it guarantees the existence of the limit point (within that space).\nDensity Density is not so much a new concept to learn as it is a way of refining an intuitively understood concept in the manner of topology. Such statements are neat, but sometimes it\u0026rsquo;s better to explain them in a more elaborate manner. Another way to express it is that for every open set $O \\subset X$, if $A \\cap O \\ne \\emptyset$, then $A$ is dense in $X$. The concept of density leads to the notion of a separable space, which is a crucial issue concerning what sequences can or cannot be chosen.\nThe study of metric spaces is not only of mathematical importance but also conceptually the most intuitive to us humans. Naturally, there\u0026rsquo;s extensive research on metric spaces and numerous properties regarding completeness.\nCategory Baire\u0026rsquo;s category theorem: All complete metric spaces are second category when considered as a whole set.\nUnderstanding the concept of category can be challenging before actually seeing the theory in action, so for now, it\u0026rsquo;s best to learn as you go. In the context of Baire\u0026rsquo;s category theorem, focus more on \u0026lsquo;completeness\u0026rsquo; rather than whether it considers itself a whole set or a subset.\nCroom. (1989). Principles of Topology: p87~89.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":396,"permalink":"https://freshrimpsushi.github.io/en/posts/396/","tags":null,"title":"Completeness and Density in Metric Spaces"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 A group $G$, having an element $a$ and for any $x \\in G$ there exists an integer $n \\in \\mathbb{Z}$ satisfying $x = a^{n}$, is called a Cyclic Group, and $a$ is called a Generator.\nExplanation Simply put, if all elements of a group can be expressed as the power of a generator, then it is a cyclic group. The term \u0026lsquo;cyclic\u0026rsquo; is quite apt since it involves continuously expressing all elements as powers of the generator.\nNot immediately apparent from the definition is that all cyclic groups are abelian groups, and the generator is not necessarily unique. Theorem [1] is an example of this.\nFurthermore, according to the definition, cyclic groups do not have to be finite groups. What is important to note is that $n$ exists but is an integer, not a natural number, which means that adding the inverse of the generator is also fine. Theorem [2] is an example of this.\nTheorems [1]: The generators of $\\mathbb{Z}_{4} = \\left\\{ 0,1,2,3 \\right\\}$ are not unique. [2]: $\\mathbb{Z}$ is a cyclic group. Proof [1] Even though $1$ alone can represent all the elements, since $3 \\equiv -1 \\pmod{4}$, $3$ can also represent all elements.\nTherefore, $\\left\u0026lt; 1 \\right\u0026gt; = \\left\u0026lt; 3 \\right\u0026gt; = \\mathbb{Z}_{4}$, and it can be understood that a generator does not have to be unique.\n‚ñ†\n[2] Since all elements of $\\left\u0026lt; \\mathbb{Z} , + \\right\u0026gt;$ can be represented as $1 \\cdot n = (-1) \\cdot (-n) = n$, thus $\\mathbb{Z} = \\left\u0026lt; 1 \\right\u0026gt; = \\left\u0026lt; -1 \\right\u0026gt;$\n‚ñ†\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p59.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":392,"permalink":"https://freshrimpsushi.github.io/en/posts/392/","tags":null,"title":"Cyclic Groups in Abstract Algebra"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definition Given a metric space where $\\left( X, d \\right)$, let $a \\in X$ and $r \u0026gt; 0$.\nAn open ball with center $a$ and radius $r$ is denoted by $B_{d} (a,r) = \\left\\{ x \\in X \\ | \\ d(a,x) \u0026lt; r \\right\\}$. A closed ball with center $a$ and radius $r$ is denoted by $B_{d} [a,r] = \\left\\{ x \\in X \\ | \\ d(a,x) \\le r \\right\\}$. If $O \\subset X$ is a union of open balls, then $O$ is called an open set in $X$. If $X \\setminus C$ is an open set for $C \\subset X$, then $C$ is called a closed set in $X$. Explanation Open and closed sets can be defined differently, but essentially, they are similar concepts.\nThe term \u0026ldquo;ball\u0026rdquo; generalizes the concepts of intervals, open intervals, and closed intervals. Considering that an interval can also be thought of as a $1$-dimensional ball, this is an intuitive link. Moreover, this generalization doesn\u0026rsquo;t just stop with dimensions in Euclidean spaces denoted by $\\mathbb{R}$; as long as distance is properly defined, it is well established anywhere.\nOpen and closed sets generally satisfy the following properties:\nProperties Let us denote the open sets in the entire space $X$ as $O_{\\alpha}$, and the closed sets as $C_{\\alpha}$.\n[1]: $X$ and $\\emptyset$ are both open and closed. [2]: The union of open sets $\\displaystyle \\bigcup_{\\alpha \\in \\forall} O_{\\alpha}$ is an open set in $X$. [3]: The finite intersection of open sets $\\displaystyle \\bigcap_{i = 1}^{n} O_{i} $ is an open set in $X$. [4]: The intersection of closed sets $\\displaystyle \\bigcap_{\\alpha \\in \\forall} C_{\\alpha}$ is a closed set in $X$. [5]: The finite union of closed sets $\\displaystyle \\bigcup_{i = 1}^{n} C_{i}$ is a closed set in $X$. Without the condition of being finite in [3], $\\displaystyle \\bigcap_{n = 1}^{ \\infty } \\left( -{{1} \\over {n}} , {{1} \\over {n}} \\right) = \\left\\{ 0 \\right\\}$ could be given as a counterexample. Without the condition of being finite in [5], $\\displaystyle \\bigcup_{n = 1}^{ \\infty } \\left[ 0 , 1-{{1} \\over {n}} \\right] = [ 0 , 1 )$ could be given as a counterexample.\nProof [1] Introduced in this post.\n[2]~[5] Introduced in this post.\n","id":382,"permalink":"https://freshrimpsushi.github.io/en/posts/382/","tags":null,"title":"Balls and Open Sets, Closed Sets in Metric Spaces"},{"categories":"Í±∞Î¶¨Í≥µÍ∞Ñ","contents":"Definition A function $d : X \\times X \\to [0, \\infty)$ on a set set $X$ is called a distance and $\\left( X, d\\right)$ is called a metric space if it satisfies the following conditions with respect to $x,y,z \\in X$. If the distance is trivial, the metric space is also simply denoted by $X$.\n$d(x,y)=0 \\iff x = y$\n$d(x,y) = d(y,x)$\n$d(x,y) + d(y,z) \\ge d(x,z)$\nExplanation As one might know from the concept of norms in linear algebra, the size or distance does not necessarily have to be defined intuitively. The three examples below are defined specifically on $\\mathbb{R}^{n}$, and as mentioned, are not much different from the norms seen in linear algebra. This is because a distance $d ( \\mathbf{x} , \\mathbf{y} ) := \\left\\| \\mathbf{x} - \\mathbf{y} \\right\\|$ can always be defined regardless of how a norm $\\left\\| \\cdot \\right\\|$ is defined, therefore, if there is any kind of norm, there necessarily exists a corresponding distance.\nExamples Let\u0026rsquo;s consider $\\mathbf{x} = (x_{1} , x_{2} , \\cdots , x_{n} )$ and $\\mathbf{y} = (y_{1} , y_{2} , \\cdots , y_{n} ) $.\nEuclidean distance: $d(\\mathbf{x} , \\mathbf{y}) = \\sqrt{ \\sum \\limits_{i = 1}^{n} (x_{i} - y_{i} )^2 }$\nTaxicab distance: $d^{\\prime}(\\mathbf{x} , \\mathbf{y}) = \\sum \\limits_{i = 1}^{n} | x_{i} - y_{i} |$\nMaximum distance: $d^{\\prime \\prime}(\\mathbf{x} , \\mathbf{y}) = \\max \\left\\{ | x_{i} - y_{i} | \\right\\}_{i=1}^{n}$\nIn basic analysis, $\\mathbb{R}^{1}$ is mainly dealt with, and it is safe to say that the Euclidean distance is mostly used. Specifically for analysis, there might not be a need to study metric spaces in detail, and it‚Äôs sufficient to accept the real number set $\\mathbb{R}$ as a metric space $\\left( \\mathbb{R} , d \\right)$. The two examples below are concepts of distance beyond Euclidean spaces.\nDiscrete distance:\n$$ d_{0} (x,y) = \\delta_{xy} = \\begin{cases}1, \u0026amp; \\ x \\ne y \\\\ 0, \u0026amp; \\ x = y \\end{cases} $$\nThe discrete distance uses the Kronecker delta, which only considers whether two elements are the same. That it satisfies the triangle inequality can be easily proven by dividing into cases.\nIntegral distance:\n$$ \\rho (f,g) = \\int_{a}^{b} | f(x) - g(x) | dx $$\nThe integral distance is a distance that can be defined in a set of continuous functions $C[a,b]$. If the graphs of two functions are completely the same, then the value is $0$.\nThe enclosed area by the solid line in the illustration represents $\\rho (f,g)$.\nFrom these definitions, it can be understood that metric is more appropriately understood as a \u0026lsquo;disparity\u0026rsquo; rather than the traditional sense of \u0026lsquo;distance\u0026rsquo;. Since everything identical necessarily is $0$, what matters isn\u0026rsquo;t \u0026lsquo;how close to infinity\u0026rsquo; but \u0026lsquo;how far from $0$\u0026rsquo;. For more abstract thinking, let\u0026rsquo;s move away from the intuitive notion that a larger distance means \u0026lsquo;farther away\u0026rsquo; in terms of \u0026rsquo;location\u0026rsquo;.\n","id":381,"permalink":"https://freshrimpsushi.github.io/en/posts/381/","tags":null,"title":"Definition of a Metric Space"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 Let\u0026rsquo;s say that a linear system $A\\mathbf{x} = \\mathbf{b}$ with a matrix $A \\in \\mathbb{C}^{m \\times n}$ and a vector $\\mathbf{b} \\in \\mathbb{C}^{m}$ is either overdetermined or underdetermined. In this case, the system either does not have a solution or has infinitely many. Here, consider the problem of minimizing the value of\n$$ \\left\\| A \\mathbf{x} - \\mathbf{b} \\right\\|_{2} $$\nThis is called the Least Squares Problem (LSP). The solution $\\mathbf{x}_{\\ast}$ to this problem is referred to as the least square solution.\n$$ \\mathbf{x}_{\\ast} = \\argmin \\left\\| A \\mathbf{x} - \\mathbf{b} \\right\\|_{2} $$\n$A \\mathbf{x} - \\mathbf{b}$ is called the least square error vector, and $\\left\\| A \\mathbf{x} - \\mathbf{b} \\right\\|$ is called the least square error.\nExplanation It\u0026rsquo;s unfortunate when a system of equations has no solution, but that doesn\u0026rsquo;t mean we can abandon the search for a solution altogether. In fact, equations that are tough to solve, waiting for solutions from mathematicians at the forefront of academic research, are typically of this nature. Researching methods to solve these problems, even if only approximately, is undeniably valuable and practical. Among these methods, the Least Squares Method is one of the most prominent. It is actively used across various applied sciences, especially in statistics where it is fundamental to the theory supporting regression analysis. The minimization of $\\left\\| \\mathbf{b} - A \\mathbf{x} \\right\\|_{2}$ implies that the distance, or the error, between $A \\mathbf{x}$ and $\\mathbf{b}$ is minimized. Regarding the orthogonal projection $P : \\mathbb{C}^{m} \\to \\mathcal{C} (A)$,\n$$ \\mathbf{b} = P \\mathbf{b} + (I -P) \\mathbf{b} $$\n$$ P \\mathbf{b} \\in \\mathcal{C} (A) $$\nthus, for any vector $\\mathbf{x}_{\\ast}$, $A \\mathbf{x}_{\\ast} = P \\mathbf{b}$ holds. Representing this as\n$$ \\left\\| A \\mathbf{x} - \\mathbf{b} \\right\\|_{2} = \\left\\| A \\mathbf{x} - P \\mathbf{b} + P \\mathbf{b} - \\mathbf{b} \\right\\|_{2} $$\nwe can understand that $( A \\mathbf{x} - P \\mathbf{b} ) \\in \\mathcal{C} (A)$ and $(I -P )\\mathbf{b} \\in \\mathcal{N}(A)$ are orthogonal to each other. According to Pythagoras\u0026rsquo; theorem,\n$$ \\left\\| \\mathbf{b} - A \\mathbf{x} \\right\\|_{2}^{2} = \\left\\| A \\mathbf{x} - P \\mathbf{b} \\right\\|_{2}^{2} + \\left\\| (I -P )\\mathbf{b} \\right\\|_{2}^{2} $$\nand the smallest possible value of $\\left\\| \\mathbf{b} - A \\mathbf{x} \\right\\|_{2}$ occurs when $\\mathbf{x} = \\mathbf{x}_{\\ast}$ is true.\nFurthermore, due to the properties of projections, $A \\in \\mathcal{C} (A)$ and thus $(I - P) \\mathbf{b} \\in \\mathcal{C} (A)^{\\perp}$,\n$$ A^{\\ast} (I - P) \\mathbf{b} = A^{\\ast} ( \\mathbf{b} - A \\mathbf{x}_{\\ast} ) = 0 $$\nIn summary, $A^{\\ast} A \\mathbf{x}_{\\ast} = A^{\\ast} \\mathbf{b}$, so the Least Squares Method essentially consists of finding the solution $\\mathbf{x}_{\\ast}$ that satisfies the normal equation $A^{\\ast} A \\mathbf{x}_{\\ast} = A^{\\ast} \\mathbf{b}$.\nFor an intuitive understanding not through formulas but through figures, the following example might be helpful.\nConsider the problem of finding a line that goes through all the points laid out on a plane as shown above. Naturally, there is no line (solution) that exactly does this, but we can look for an approximate solution that does it as closely as possible.\nComparing the green and red lines, one can easily see that the one on the left is more accurate than the one on the right. The lengths of the blue lines represent the distances the points fall from the line when projected onto it. In this problem, the least square solution is a certain line for which the sum of the squares of these distances is minimized.\nHoward Anton, Elementary Linear Algebra: Aplications Version (12th Edition, 2019), p417-418\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":356,"permalink":"https://freshrimpsushi.github.io/en/posts/356/","tags":null,"title":"Least Squares Method"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition A square matrix $P \\in \\mathbb{C}^{m \\times m}$ is a projector if $P^2 = P$.\nExplanation In algebraic terms, this is referred to as an idempotent, which similarly refers to an element like $a^2 = a$.\nIf $P$ is a projection, then $(I-P)^2 = I - 2P + P^2 = I - 2P + P = (I-P)$, so it can be known that $(I-P)$ is also a projection.\nSuch a projector $(I - P)$ is called the complementary projector of $P$.\nThinking of projection as a linear transformation geometrically, it\u0026rsquo;s like casting light on a geometric figure and obtaining its shadow. For example, a function like $f(x,y,z) := (x,y,0)$ shoots light towards the direction of the $z$ axis and represents the shadow that forms on the $xy$ plane. Projecting the shadow again yields the same result, hence the definition of $P^2 = P$ as a projector is sensible.\nProperties Projection $P \\in \\mathbb{C}^{m \\times m}$ and its complementary projection $I-P$ satisfy the following properties:\n(a) $\\mathcal{C} (I-P) = \\mathcal{N} (P)$\n(b) $\\mathcal{N} (1-P) = \\mathcal{C} (P)$\n(c) $\\mathcal{N} (1-P) \\cap \\mathcal{N} (P) = \\left\\{ 0 \\right\\}$\n(d) $\\mathcal{C} (P) \\cap \\mathcal{N} (P) = \\left\\{ 0 \\right\\}$\n(e) $\\mathcal{C} (P) \\oplus \\mathcal{N} (P) = \\mathbb{C}^{m}$\nProof (a)(b) It suffices to show that $\\mathcal{C} ( I - P)$ and $\\mathcal{N}(P)$ are inclusive of each other. For any vector $\\mathbb{v} \\in \\mathbb{C}^{m}$,\n$$ (I - P) \\mathbb{v} = \\mathbb{v} - P \\mathbb{v} $$\nIf $\\mathbb{v} \\in \\mathcal{N} (P)$, then $P \\mathbb{v} = \\mathbb{0}$, hence $(I - P) \\mathbb{v} = \\mathbb{v}$, i.e., $\\mathbb{v} \\in \\mathcal{C} (I - P)$, thus\n$$ \\mathcal{N} (P) \\subset \\mathcal{C} (I - P) $$\nIf we let $\\mathbb{w} \\in \\mathcal{C} (I-P)$, then any $\\mathbb{v}$ satisfying $\\mathbb{w} = (I - P) \\mathbb{v}$ is also in $\\mathcal{C} (I-P)$. Taking the projection $P$ on $\\mathbb{w} = (I - P) \\mathbb{v}$,\n$$ P \\mathbb{w} = P \\mathbb{v} - P^2 \\mathbb{v} = P \\mathbb{v} - P \\mathbb{v} = \\mathbb{0} $$\nThus $\\mathbb{w} \\in \\mathcal{N} (P)$, and therefore\n$$ \\mathcal{C} (I - P) \\subset \\mathcal{N} (P) $$\nHence (1) is proven, and since $P = I - (I- P)$, by regarding the complementary projection $(I - P)$ of projection $P$, (2) is immediately proven.\n‚ñ†\n(c)(d) Assume that $\\mathbb{v} \\in \\mathcal{N} (I - P) \\cap \\mathcal{N} (P)$ is not the zero vector. However, since $\\mathbb{v} \\in \\mathcal{N} (I - P)$, $(I-P) \\mathbb{v} = \\mathbb{0}$, and $\\mathbb{v} \\in \\mathcal{N} (P)$,\n$$ P \\mathbb{v} = \\mathbb{0} $$\nAdding both sides yields $(I-P) \\mathbb{v} + P \\mathbb{v} = \\mathbb{v} = \\mathbb{0}$, which is a contradiction to the assumption.\nThus, (3) is proven, and (4) is immediately proven by (1) and (2).\n‚ñ†\n(e) By the definition of direct sum, it suffices to show existence, exclusivity, and uniqueness.\n(i) Existence\nBy (a), $\\mathcal{N} (P) = \\mathcal{C} (I - P)$, and for any vector $\\mathbb{s} \\in \\mathbb{C}^{m}$, $P \\mathbb{s} \\in \\mathcal{C}(P)$, and $(I - P)\\mathbb{s} \\in \\mathcal{C} (I - P)$.\nHowever, since $P \\mathbb{s} + (I - P) \\mathbb{s} = P \\mathbb{s} + \\mathbb{s} - P \\mathbb{s} = s \\in \\mathbb{C}^{m}$, $\\mathbb{s}$ can always be represented as the sum of $\\mathcal{C}(P)$ and $\\mathcal{C} (I - P)$.\n(ii) Exclusivity\nAlready proven in (d).\n(iii) Uniqueness\nFrom the above (ii), for $s \\in \\mathbb{C}^{m}$,\n$$ \\mathbb{s} = \\mathbb{c}_{1} + \\mathbb{n}_{1} = \\mathbb{c}_{2} + \\mathbb{n}_{2} $$\nThere exist $\\mathbb{c}_{1} , \\mathbb{c}_{2} \\in \\mathcal{C}(P)$ and $\\mathbb{n}_{1}, \\mathbb{n}_{2} \\in \\mathcal{N}(P)$ satisfying it.\nLet\u0026rsquo;s assume $\\mathbb{c}_{1} \\ne \\mathbb{c}_{2} $ and $\\mathbb{n}_{1} \\ne \\mathbb{n}_{2}$.\nMultiplying both sides of $\\mathbb{c}_{1} + \\mathbb{n}_{1} = \\mathbb{c}_{2} + \\mathbb{n}_{2}$ by $P$,\n$$ P\\mathbb{c}_{1} + P\\mathbb{n}_{1} = P\\mathbb{c}_{2} + P\\mathbb{n}_{2} $$\nMeanwhile, since $\\mathbb{n}_{1}, \\mathbb{n}_{2} \\in \\mathcal{N} (P)$,\n$$ P\\mathbb{c}_{1} = P\\mathbb{c}_{2} $$\nThus $P( \\mathbb{c}_{1} - \\mathbb{c}_{2} ) = \\mathbb{0}$. By the definition of the null space, $( \\mathbb{c}_{1} - \\mathbb{c}_{2}) \\in \\mathcal{N}(P)$, and by the property of vector spaces, $( \\mathbb{c}_{1} - \\mathbb{c}_{2}) \\in \\mathcal{C}(P)$, which by (exclusivity) must mean $\\mathbb{c}_{1} - \\mathbb{c}_{2} = \\mathbb{0}$.\nThis contradicts the assumption $\\mathbb{c}_{1} \\ne \\mathbb{c}_{2}$, and similarly, $\\mathbb{n}_{1} = \\mathbb{n}_{2}$ being true can be shown.\n‚ñ†\nSee also Idempotents in abstract algebra ","id":352,"permalink":"https://freshrimpsushi.github.io/en/posts/352/","tags":null,"title":"Matrix Projection in Linear Algebra"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition A vector space $V$ is said to be the direct sum of its two subspaces $W_{1}$ and $W_{2}$ if it satisfies the following, denoted by $V = W_{1} \\oplus W_{2}$.\n(i) Existence: For any $\\mathbf{v} \\in V$, there exist $\\mathbf{v}_{1} \\in W_{1}$ and $\\mathbf{v}_{2} \\in W_{2}$ satisfying $\\mathbf{v} = \\mathbf{v}_{1} + \\mathbf{v}_{2}$.\n(ii) Exclusivity: $W_{1} \\cap W_{2} = \\left\\{ \\mathbf{0} \\right\\}$\n(iii) Uniqueness: For a given $\\mathbf{v}$, there exists a unique $\\mathbf{v}_{1} \\in W_{1}$ and $\\mathbf{v}_{2} \\in W_{2}$ satisfying $\\mathbf{v} = \\mathbf{v}_{1} + \\mathbf{v}_{2}$.\nGeneralization1 Let $W_{1}, W_{2}, \\dots, W_{k}$ be subspaces of the vector space $V$. When these subspaces meet the following conditions, $V$ is called the direct sum of $W_{1}, \\dots, W_{k}$, denoted by $V = W_{1} \\oplus \\cdots \\oplus W_{k}$.\n$\\displaystyle V = \\sum\\limits_{i=1}^{k}W_{i}$\n$\\displaystyle W_{j} \\bigcap \\sum\\limits_{i \\ne j}W_{i} = \\left\\{ \\mathbf{0} \\right\\} \\text{ for each } j(1\\le j \\le k)$\nHere, $\\sum\\limits_{i=1}^{k}W_{i}$ is the sum of the $W_{i}$.\nExplanation (i) Existence: This condition can be rewritten as $V = W_{1} + W_{2}$, meaning \u0026quot;$V$ is the sum of $W_{1}$ and $W_{2}$\u0026quot;.\n(iii) Uniqueness: In fact, this condition is not necessary. Due to condition (ii), if $\\mathbf{v}_{1} \\in W_{1}$, then $\\pm \\mathbf{v}_{1} \\notin W_{2}$ exists, and only one representation exists for the zero vector $W$.\n$$ \\mathbf{0} = \\mathbf{0} + \\mathbf{0},\\quad \\mathbf{0}\\in W_{1}, W_{2} $$\nTherefore, if two expressions $\\mathbf{v}_{1} + \\mathbf{v}_{2}$ and $\\mathbf{v}_{1}^{\\prime} + \\mathbf{v}_{2}^{\\prime}$ exist for $\\mathbf{v}$,\n$$ \\mathbf{0} = \\mathbf{v} - \\mathbf{v} = (\\mathbf{v}_{1} - \\mathbf{v}_{1}^{\\prime}) + (\\mathbf{v}_{2} - \\mathbf{v}_{2}^{\\prime}) = \\mathbf{0} + \\mathbf{0} \\implies \\mathbf{v}_{1}=\\mathbf{v}_{1}^{\\prime},\\ \\mathbf{v}_{2}=\\mathbf{v}_{2}^{\\prime} $$\nFurther, (i), (ii) $\\iff$ (iii) is validated.\nAt first glance, the definition might seem complex, but looking at examples in Euclidean space makes it clear that this is a very logical and convenient concept. For example, considering $\\mathbb{R}^{3} = \\mathbb{R} \\times \\mathbb{R} \\times \\mathbb{R}$, elements of $\\mathbb{R}^{3}$ are n-dimensional vectors $(x,y,z)$, which can be divided into $(x,y)$ and $(z)$.\nOn the other hand, thinking about the process of recombining them gives $(x,y) \\in \\mathbb{R}^2$ and, in turn, $(z) \\in \\mathbb{R}$. Therefore, their mere union $\\mathbb{R}^2 \\cup \\mathbb{R}$ would include scalars and n-dimensional vectors as elements. From just these symbols, it‚Äôs evident how difficult it is to express the expansion and separation of the spaces we desire. When the concept of direct sum is introduced, however, it will be much easier to explain when subspaces neatly divide a vector space.\nSee Also Direct sum in abstract algebra Sum of vector spaces $+$ Stephen H. Friedberg, Linear Algebra (4th Edition, 2002), p275\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":353,"permalink":"https://freshrimpsushi.github.io/en/posts/353/","tags":null,"title":"Direct Sum in Vector Spaces"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Overview While it would be great if every matrix could be decomposed through eigenvalue diagonalization, unfortunately, this method is limited by the requirement that the given matrix must be a square matrix. We aim to extend decomposability to matrices that are not square.\nBuildup Let us consider two natural numbers $m \u0026gt; n$ for a matrix $A \\in \\mathbb{C}^{ m \\times n}$ whose coefficients are given by $\\text{rank} A = n$. Then, it is possible to think about $\\dim C(A) = \\dim C(A^{T}) = n $, its orthonormal vectors $\\mathbb{v}_{1} , \\cdots , \\mathbb{v}_{n} \\in C(A)$ and $\\mathbb{u}_{1} , \\cdots , \\mathbb{u}_{n} \\in C(A^{T})$.\nSimilar to when contemplating the geometric meaning of eigenvalues, $$ A \\mathbb{v}_{i} = \\sigma_{i} \\mathbb{u}_{i} $$ let us assume that a $\\sigma_{i}\u0026gt;0$ exists that satisfies this. Then, $A$ is a linear transformation that aligns the direction of $\\mathbb{v}_{i}$ with $\\mathbb{u}_{i}$, and $\\sigma_{i}\u0026gt;0$ adjusts its magnitude. This $\\sigma_{i}$ is defined not as an eigenvalue but as the singular value of $A$, although, regrettably, its meaning has nothing to do with singular value decomposition (SVD). The difference from the discussion on eigenvalues here is $A \\in \\mathbb{C}^{ m \\times n}$, that is $\\mathbb{v}_{i} \\in \\mathbb{C}^{n}$, and $\\mathbb{u}_{i} \\in \\mathbb{C}^{m}$, which means $A$ changes the dimension of vectors too. For matrix $A$, we have $A = \\sigma_{i} \\mathbb{u}_{i} \\mathbb{v}_{i}^{\\ast}$ and can confirm that both sides have the dimension $m \\times n = ( m \\times 1 ) \\times (1 \\times n )$. Note that, unlike eigenvectors, there is a distinction between left and right, so $\\mathbb{u}_{i}$ is defined as the left singular vector, and $\\mathbb{v}_{i}$ is the right singular vector. If we now rewrite $A \\mathbb{v}_{i} = \\sigma_{i} \\mathbb{u}_{i}$ for $1 \\le i \\le n$, it becomes $$ A \\begin{bmatrix} \\mathbb{v}_{1} \u0026amp; \\mathbb{v}_{2} \u0026amp; \\cdots \u0026amp; \\mathbb{v}_{n} \\end{bmatrix} = \\begin{bmatrix} \\mathbb{u}_{1} \u0026amp; \\mathbb{u}_{2} \u0026amp; \\cdots \u0026amp; \\mathbb{u}_{n} \\end{bmatrix} \\begin{bmatrix} \\sigma_{1} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\sigma_2 \u0026amp; \\ddots \u0026amp; \\vdots \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\ddots \u0026amp; 0 \\\\ 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; \\sigma_{m} \\end{bmatrix} $$ For simplicity, let\u0026rsquo;s express it as below. $$ V := \\begin{bmatrix} \\mathbb{v}_{1} \u0026amp; \\mathbb{v}_{2} \u0026amp; \\cdots \u0026amp; \\mathbb{v}_{n} \\end{bmatrix} \\in \\mathbb{C}^{n \\times n} \\\\ \\widehat{U} := \\begin{bmatrix} \\mathbb{u}_{1} \u0026amp; \\mathbb{u}_{2} \u0026amp; \\cdots \u0026amp; \\mathbb{u}_{n} \\end{bmatrix} \\in \\mathbb{C}^{m \\times n} \\\\ \\widehat{\\Sigma} := \\text{diag} ( \\sigma_1 , \\sigma_2 , \\cdots , \\sigma_n) $$ For convenience, let\u0026rsquo;s say $\\sigma_{i} \\ge \\sigma_{j} \u0026gt; 0$. Summarizing, $$ AV = \\widehat{U} \\widehat{\\Sigma} $$ since $V V^{\\ast} = V^{\\ast} V = I$, we have $$ A = \\widehat{U} \\widehat{\\Sigma} V^{\\ast} $$ Of course, since $\\widehat{U} \\in \\ \\mathbb{C}^{m \\times n}$, although $\\widehat{U}$ is not a unitary matrix, it has orthonormality, so $\\widehat{U}^{\\ast} \\widehat{U} = I_{n}$, $$ \\begin{align*} A^{\\ast}A =\u0026amp; (\\widehat{U} \\widehat{\\Sigma} V^{\\ast})^{\\ast} (\\widehat{U} \\widehat{\\Sigma} V^{\\ast}) \\\\ =\u0026amp; V \\widehat{\\Sigma} \\widehat{U}^{\\ast} \\widehat{U} \\widehat{\\Sigma} V^{\\ast} \\\\ =\u0026amp; V \\widehat{\\Sigma}^{2} V^{\\ast} \\\\ =\u0026amp; V \\widehat{\\Sigma}^{2} V^{-1} \\end{align*} $$\n$$ A = S \\begin{bmatrix} \\lambda_{1} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\lambda_2 \u0026amp; \\ddots \u0026amp; \\vdots \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\ddots \u0026amp; 0 \\\\ 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; \\lambda_{m} \\end{bmatrix} S^{-1} $$\nThis can be seen as the result of completing eigenvalue diagonalization for the square matrix $A^{\\ast} A \\in \\mathbb{C}^{m \\times m}$. $\\sigma^{2}_{i}$ is the eigenvalue of $A^{\\ast}A$, and $\\mathbb{v}_{i}$ becomes the eigenvector corresponding to $\\sigma^{2}_{i}$. Now, for numerical calculations, let\u0026rsquo;s trace back through the process in reverse.\nAlgorithm For the matrix $A \\in \\mathbb{C}^{m \\times n} (m \\ge n)$, it is given that $\\text{rank} A = n$.\nStep 1.\nFind the eigenvalues $\\sigma_{1} \\ge \\sigma_{2} \\ge \\cdots \\ge \\sigma_{n}\u0026gt;0$ of $A^{\\ast} A$. For any $\\mathbb{x} \\ne \\mathbb{0}$, $$ \\mathbb{x}^{\\ast} A^{\\ast} A \\mathbb{x} = || A \\mathbb{x} ||^2 \u0026gt; 0 $$ meaning, since $A^{\\ast} A$ is positive definite, $\\sigma_{i} \u0026gt;0$ is guaranteed.\nStep 2.\nFind orthonormal vectors $V = \\begin{bmatrix} v_{1} \u0026amp; v_{2} \u0026amp; \\cdots \u0026amp; v_{n} \\end{bmatrix}$ corresponding to the found eigenvalues.\nStep 3.\nThrough $\\displaystyle \\mathbb{u}_{i} = {{1} \\over { \\sigma_{i} }} A \\mathbb{v}_{i}$, find $\\widehat{U} = \\begin{bmatrix} u_{1} \u0026amp; u_{2} \u0026amp; \\cdots \u0026amp; u_{n} \\end{bmatrix}$.\nReduced Singular Value Decomposition and Full Singular Value Decomposition Decomposing $A$ into three matrices satisfying $A = \\widehat{U} \\widehat{\\Sigma} V^{\\ast}$ is known as reduced singular value decomposition (rSVD).\nIn order to distinguish this from full singular value decomposition (fSVD), notations like $\\widehat{U}$ and $\\widehat{\\Sigma}$ were used. The concept behind full SVD is merely an expanded version of the reduced SVD. It involves finding $\\mathbb{u}_{n+1} , \\cdots , \\mathbb{u}_{m}$ that turns matrix $$ U := \\begin{bmatrix} \\widehat{U} \u0026amp; \\mathbb{u}_{n+1} \u0026amp; \\cdots \u0026amp; \\mathbb{u}_{m} \\end{bmatrix} \\in \\mathbb{C}^{m \\times m} $$ into a unitary matrix and then appending $0$ to the bottom of $\\widehat{\\Sigma}$ to construct the matrix $\\Sigma := \\begin{bmatrix} \\widehat{\\Sigma} \\\\ O \\end{bmatrix}$ which is decomposed into form $A = U \\Sigma V^{\\ast}$.\nfSVD is theoretically more robust, and rSVD is more advantageous for actual computations. Whether it is fSVD or rSVD, being told to perform SVD essentially means to find $U$ or $\\widehat{U}$, $\\Sigma$ or $\\widehat{\\Sigma}$, $V$.\nSee also Extending Ellipses in Euclidean Space, Ellipsoids ","id":340,"permalink":"https://freshrimpsushi.github.io/en/posts/340/","tags":null,"title":"Singular Value Decomposition of a Matrix"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition If there exists a unitary matrix $Q$ and a diagonal matrix $\\Lambda$ that satisfy $A = Q^{ \\ast } \\Lambda Q$ for $A \\in \\mathbb{C}^{ m \\times m }$, then the matrix $A$ is said to be unitarily diagonalizable.\n","id":339,"permalink":"https://freshrimpsushi.github.io/en/posts/339/","tags":null,"title":"Eigenvalue Diagonalization of Invertible Matrices"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":" üöß Ïù¥ Ìè¨Ïä§Ìä∏Îäî ÏïÑÏßÅ Ïù¥Í¥Ä ÏûëÏóÖÏù¥ ÏôÑÎ£åÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§ üöß\nÏ°∞ÌôîÏßÑÎèôÏûê Î¨∏Ï†úÎ•º Ïó∞ÏÇ∞Ïûê Î∞©Î≤ïÏúºÎ°ú ÌíÄ Îïå ÏïÑÏ£º Ïú†Ïö©Ìïú Ïó∞ÏÇ∞ÏûêÍ∞Ä ÏûàÎã§.Î∞îÎ°ú Ï°∞ÌôîÏßÑÎèôÏûêÏùò ÏÇ¨Îã§Î¶¨Ïó∞ÏÇ∞Ïûê$\\mathrm{Ladder\\ Operator}$Ïù¥Îã§.ÏóêÎÑàÏßÄ Ïó∞ÏÇ∞ÏûêÏù∏ Ìï¥Î∞ÄÌÜ†ÎãàÏïà$H$Í≥ºÎèÑ ÏπòÌôòÏù¥ Í∞ÄÎä•ÌïòÍ≥†,ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞ÏûêÏùò ÌäπÏßïÏùÑ Ïù¥Ïö©Ìï¥ Î∞îÎã•ÏÉÅÌÉúÎ∂ÄÌÑ∞Ïùò Í≥†Ïú†Ìï®ÏàòÎèÑ Íµ¨Ìï† Ïàò ÏûàÎã§.Ï°∞Ìôî ÏßÑÎèôÏûêÏùò Í≥†Ï†ÑÏ†ÅÏù∏ Ìï¥Î∞ÄÌÜ†ÎãàÏïà$H$ÏùÑ Ïù∏ÏàòÎ∂ÑÌï¥ ÌïòÎäî Í≤ÉÏóêÏÑú ÏÉà Ïó∞ÏÇ∞ÏûêÎ•º Ï†ïÏùòÌïòÎäî ÌûåÌä∏Î•º ÏñªÏùÑ Ïàò ÏûàÎã§.$\\begin{align*} H =\u0026amp;\\ \\frac{1}{2m}p^2+\\frac{1}{2m}mw^2x^2 \\\\ =\u0026amp;\\ \\frac{1}{2m} \\left(p^2+m^2w^2x^2 \\right) \\\\ =\u0026amp;\\ \\frac{1}{2m} (ip+mwx)(-ip+mwx) \\end{align*}$Ïó¨Í∏∞ÏÑú ÌûåÌä∏Î•º ÏñªÏñ¥ Ï°∞Ìôî ÏßÑÎèôÏûêÏùò Îëê ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞ÏûêÎ•º Îã§ÏùåÍ≥º Í∞ôÏù¥ Ï†ïÏùòÌï† Ïàò ÏûàÎã§.ÌïòÌïÑ $i$Í∞Ä $x$Ìï≠Ïù¥ ÏïÑÎãå $p$Ìï≠Ïóê Î∂ôÎäî Ïù¥Ïú†ÎÇò ÏïûÏùò ÏÉÅÏàòÍ∞Ä $ \\dfrac{1}{\\sqrt{2\\hbar mw}}$Ïù∏ Ïù¥Ïú†Îäî ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú ÎÇòÏò¨ ÏãùÏùò ÌòïÌÉúÎ•º ÏÉùÍ∞ÅÌï¥ÏÑú Í≥ÑÏÇ∞ÏùÑ ÏâΩÍ≤å Ìï† Ïàò ÏûàÍ≤å Ìïú Í≤ÉÏù¥Îã§.$\\displaystyle a_+=\\frac{1}{\\sqrt{2\\hbar mw}}(ip+mwx) $$ a_-=\\frac{1}{\\sqrt{2\\hbar mw}}(-ip+mwx)=(a_+)^{\\ast}$Ïù¥Ï†ú Îëê Ïó∞ÏÇ∞ÏûêÏùò Í≥±ÏúºÎ°ú Ìï¥Î∞ÄÌÜ†ÎãàÏïà$H$ÏùÑ ÌëúÌòÑÌï¥Î≥¥Ïûê.Ïó∞ÏÇ∞ÏûêÏù¥ÎØÄÎ°ú Í≥±ÏÖàÏùò ÏàúÏÑúÏóê Îî∞Îùº Í≤∞Í≥ºÍ∞Ä Îã¨ÎùºÏßà Ïàò ÏûàÏùåÏùÑ Ïú†ÏùòÌï¥Ïïº ÌïúÎã§.ÎòêÌïú ÌëúÏ§ÄÍµêÌôòÍ¥ÄÍ≥ÑÏãù$\\mathrm{canonical\\ commutation\\ relation}$ $([x,p]=i\\hbar)$ÏùÑ ÏÇ¨Ïö©ÌïúÎã§.$\\begin{align*} a_-a_+ =\u0026amp;\\ \\frac{1}{2\\hbar mw} (p^2 + m^2w^2x^2+mwipx-mwixp) \\\\ =\u0026amp;\\ \\frac{1}{2\\hbar mw} (p^2 + m^2w^2x^2-mwi[x,p]) \\\\ =\u0026amp;\\ \\frac{1}{2\\hbar mw} (p^2 + ^2w^2x^2+mw\\hbar) \\\\ =\u0026amp;\\ \\frac{1}{2\\hbar mw} (p^2 + m^2w^2x^2) + \\frac{1}{2\\hbar mw}(mw\\hbar) \\\\ =\u0026amp;\\ \\frac{1}{\\hbar w}\\frac{1}{2m} (p^2 + m^2w^2x^2) + \\frac{1}{2} \\\\ =\u0026amp;\\ \\frac{1}{\\hbar w}H+\\frac{1}{2} \\end{align*} $$ \\therefore H=\\hbar w(a_-a_+ - \\dfrac{1}{2})$Í≥±Ïùò ÏàúÏÑúÎ•º Î∞îÍæ∏Í≥† Í∞ôÏùÄ Í≥ºÏ†ïÏúºÎ°ú Í≥ÑÏÇ∞ÌïòÎ©¥$a_+a_-=\\dfrac{1}{\\hbar w}H-\\dfrac{1}{2} $$ \\implies H=\\hbar w(a_+a_- + \\dfrac{1}{2})$Ïù¥Î°úÎ∂ÄÌÑ∞ Îëê Ïó∞ÏÇ∞ÏûêÏùò ÍµêÌôòÏûêÎèÑ Í≥ÑÏÇ∞Ìï† Ïàò ÏûàÎã§.$[a_-,a_+]=1$Ïù¥Ï†ú Îëê Ïó∞ÏÇ∞Ïûê$a_\\pm$Î•º Ïù¥Ïö©ÌïòÏó¨ Ï°∞ÌôîÏßÑÎèôÏûêÏùò ÏäàÎ¢∞Îî©Í±∞ Î∞©Ï†ïÏãùÏùÑ ÏÉàÎ°≠Í≤å ÌëúÌòÑÌï† Ïàò ÏûàÎã§.$H\\psi=E\\psi $$ \\implies \\hbar w (a_\\pm a_\\mp \\pm \\dfrac{1}{2})\\psi=E\\psi$Ïù¥ Îëê Ïó∞ÏÇ∞Ïûê $a_+$, $a_-$Ïùò Ïù¥Î¶ÑÏùÄ Í∞ÅÍ∞Å Ïò¨Î¶º Ïó∞ÏÇ∞Ïûê$\\mathrm{rasing\\ operator}$, ÎÇ¥Î¶º Ïó∞ÏÇ∞Ïûê$\\mathrm{lowering\\ operator}$Ïù¥Îã§.Ïù¥Îü∞ Ïù¥Î¶ÑÏùÑ Í∞ÄÏßÄÎäî Ïù¥Ïú†Îäî Î∞îÎ°ú Í≥†Ïú†Ìï®ÏàòÏóê Ï†ÅÏö©ÏãúÏº∞ÏùÑ Îïå ÏóêÎÑàÏßÄ(Í≥†Ïú†Í∞í)Í∞Ä Ï¶ùÍ∞ÄÌïòÍ±∞ÎÇò Í∞êÏÜåÌïòÍ∏∞ ÎïåÎ¨∏Ïù¥Îã§.Ï¶â, ÏóêÎÑàÏßÄÎ•º Ïò¨Î†§Ï£ºÍ±∞ÎÇò ÎÇ¥Î†§Ï£ºÎäî Ïó∞ÏÇ∞ÏûêÎùºÎäî ÎúªÏù¥Îã§.Ïôú Í∑∏Î†áÍ≤å ÎêòÎäîÏßÄÎäî Îã§Ïùå Í∏ÄÏùÑ Ï∞∏Í≥†ÌïòÏûêÎã§Ïùå Í∏Ä : Ïó∞ÏÇ∞Ïûê Î∞©Î≤ïÏúºÎ°ú Ï°∞ÌôîÏßÑÎèôÏûê Î¨∏Ï†ú Ìï¥Í≤∞ÌïòÍ∏∞ : ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞Ïûê Ï†ÅÏö©\nüöß Ïù¥ Ìè¨Ïä§Ìä∏Îäî ÏïÑÏßÅ Ïù¥Í¥Ä ÏûëÏóÖÏù¥ ÏôÑÎ£åÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§ üöß\nÏù¥Ï†Ñ Í∏Ä : Ïó∞ÏÇ∞Ïûê Î∞©Î≤ïÏúºÎ°ú Ï°∞ÌôîÏßÑÎèôÏûê Î¨∏Ï†ú ÌíÄÍ∏∞ : ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞ÏûêÏùò Ï†ïÏùòÏù¥Ï†ú ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞ÏûêÍ∞Ä Ï°∞ÌôîÏßÑÎèôÏûêÏùò Í≥†Ïú†Ìï®ÏàòÏóê Ïñ¥ÎñªÍ≤å ÏûëÏö©ÌïòÎäîÏßÄ ÏïåÏïÑÎ≥¥Ïûê.Ï∞∏Í≥†Î°ú ÏûÑÏùòÏùò ÏÉÅÏàòÏôÄ ÏûÑÏùòÏùò Ïó∞ÏÇ∞ÏûêÍ∞ÑÏùò ÍµêÌôòÏûêÎäî Ìï≠ÏÉÅ $0$Ïù¥Îã§.ÏïÑÎûòÏùò ÏàòÏãù Ï†ÑÍ∞úÏóêÏÑú ÏÇ¨Ïö©Ìïú Í¥ÄÍ≥ÑÏãù $( [AB,C]=A[B,C]+[A,C]B,\\ \\ [a_-,a_+]=1 ) $$ H=(a_+a_-+\\dfrac{1}{2})\\hbar w$Ïù¥ÎØÄÎ°ú, $ \\begin{align*} [H,a_+] =\u0026amp;\\ [(a_+a_-+\\dfrac{1}{2})\\hbar w,a_+] \\\\ =\u0026amp;\\ [a_+a_-\\hbar w,a_+]+[\\dfrac{1}{2}\\hbar w, a_+] \\\\ =\u0026amp;\\ \\hbar w[a_+a_-,a_+] \\\\ =\u0026amp;\\ \\hbar w(a_+[a_-,a_+] + [a_+,a_+]a_-) \\\\ =\u0026amp;\\ \\hbar w a_+ \\\\ =\u0026amp;\\ Ha_+ - a_+H \\end{align*} $Í∞ôÏùÄ Î∞©Î≤ïÏúºÎ°ú $[H,a_-]$Î•º Íµ¨ÌïòÎ©¥$[H,a_-]=-\\hbar w a_-=Ha_- - a_-H$Ïù¥Ï†ú ÏúÑÏóêÏÑú Íµ¨Ìïú Í¥ÄÍ≥ÑÏãùÏùÑ Ïç®ÏÑú Ï°∞ÌôîÏßÑÎèôÏûêÏùò Í≥†Ïú†Ìï®ÏàòÏóê Ï†ÅÏö©ÏãúÏºúÎ≥¥Ïûê.$a_\\pm$Îäî Í≥†Ïú†Ìï®Ïàò$|\\psi\u0026gt;$Ïóê ÎåÄÌï¥ÏÑú Í≥†Ïú†Í∞í Î∞©Ï†ïÏãùÏùÑ ÎßåÏ°±ÏãúÌÇ§Îäî Ïó∞ÏÇ∞ÏûêÍ∞Ä ÏïÑÎãàÎØÄÎ°ú$a_\\pm$ÎåÄÏã† $H$Í∞Ä Í≥†Ïú†Ìï®ÏàòÏóê Ï†ÅÏö©Îê† Ïàò ÏûàÎèÑÎ°ù Î™®ÏñëÏùÑ Î∞îÍøîÏ§ÄÎã§.ÏäàÎ¢∞Îî©Í±∞ Î∞©Ï†ïÏãùÏùÄ $H|\\psi\u0026gt;=E|\\psi\u0026gt; $$ \\begin{align*} Ha_+|\\psi\u0026gt; =\u0026amp;\\ (\\hbar wa_+ + a_+H)|\\psi\u0026gt; \\\\ =\u0026amp;\\ (\\hbar wa_+ + a_+E)|\\psi\u0026gt; \\\\ =\u0026amp;\\ (E+\\hbar w)a_+|\\psi\u0026gt; \\end{align*}$Îî∞ÎùºÏÑú $|\\psi\u0026gt;$Í∞Ä $H$Ïóê ÎåÄÌïú Í≥†Ïú†Ìï®ÏàòÏùº Îïå $a_+|\\psi\u0026gt;$Ïó≠Ïãú Í≥†Ïú†Í∞í Î∞© Ï†ïÏãùÏùÑ ÎßåÏ°±ÌïòÎäî Í≥†Ïú†Ìï®ÏàòÏù¥Îã§.Ïù¥ Îïå $a_+|\\psi\u0026gt;$Ïùò Í≥†Ïú†Í∞íÏùÄ $(E+\\hbar w)$Ïù¥Îã§.ÏùºÎ∞òÏãùÏùÑ Íµ¨ÌïòÍ∏∞ ÏúÑÌï¥ Îëê Î≤à Ï†ÅÏö©ÏãúÏºúÎ≥¥Ïûê.Ìïú Î≤à Ï†ÅÏö©ÌñàÏùÑ ÎïåÏùò Í≤∞Í≥ºÎ•º Ïó¨Í∏∞ÏÑú ÏÇ¨Ïö©ÌïúÎã§.$\\begin{align*} H(a_+)^2|\\psi\u0026gt; =\u0026amp;\\ Ha_+a_+|\\psi\u0026gt; \\\\ =\u0026amp;\\ (a_+H+\\hbar w a_+)a_+|\\psi\u0026gt; \\\\ =\u0026amp;\\ a_+H+a_+|\\psi\u0026gt; + \\hbar w a_+a_+|\\psi\u0026gt; \\\\ =\u0026amp;\\ a_+(E+\\hbar w)a_+|\\psi\u0026gt; + \\hbar w a_+a_+|\\psi\u0026gt; \\\\ =\u0026amp;\\ (E+\\hbar w)(a_+)^2|\\psi\u0026gt; + \\hbar w (a_+)^2|\\psi\u0026gt; \\\\ =\u0026amp;\\ (E+2\\hbar w)(a_+)^2|\\psi\u0026gt; \\end{align*}$Îî∞ÎùºÏÑú Í≥†Ïú†Ìï®Ïàò $|\\psi\u0026gt;$Ïóê $a_+$Î•º $n$Î≤à Ï†ÅÏö©ÌïòÎ©¥ Îã§ÏùåÍ≥º Í∞ôÏùÄ Í≤∞Í≥ºÎ•º ÏñªÎäîÎã§.$\\implies H(a_+)^n|\\psi\u0026gt;=(E+n\\hbar w)(a_+)^n|\\psi\u0026gt;$ÎßàÏ∞¨Í∞ÄÏßÄÎ°ú Í∞ôÏùÄ Î∞©Î≤ïÏúºÎ°ú Í≥†Ïú†Ìï®ÏàòÏóê $a_-$Î•º Ï†ÅÏö©ÏãúÌÇ§Î©¥$Ha_-|\\psi\u0026gt;=(a_-H - \\hbar w a_-)|\\psi\u0026gt;=(E-\\hbar w)a_-|\\psi\u0026gt; $$ \\implies H(a_-)^n|\\psi\u0026gt;=(E-n\\hbar w)(a_-)^n|\\psi\u0026gt;$Îî∞ÎùºÏÑú Í≥†Ïú†Ìï®ÏàòÏóê Ï†ÅÏö©ÏãúÌÇ¨ÏàòÎ°ù ÏóêÎÑàÏßÄÍ∞Ä Ïª§ÏßÄÎäî $a_+$Î•º Ïò¨Î¶ºÏó∞ÏÇ∞Ïûê$\\mathrm{rasing\\ operator}$Îùº ÌïúÎã§.Í≥†Ïú†Ìï®ÏàòÏóê Ï†ÅÏö©ÏãúÌÇ¨ÏàòÎ°ù ÏóêÎÑàÏßÄÍ∞Ä ÏûëÏïÑÏßÄÎäî $a_-$Î•º ÎÇ¥Î¶ºÏó∞ÏÇ∞Ïûê$\\mathrm{lowering\\ operator}$Îùº ÌïúÎã§.Îã§ÏùåÍ∏Ä : Ïó∞ÏÇ∞Ïûê Î∞©Î≤ïÏúºÎ°ú Ï°∞ÌôîÏßÑÎèôÏûê Î¨∏Ï†ú ÌíÄÍ∏∞ : ÏóêÎÑàÏßÄ Ï§ÄÏúÑÏôÄ Î∞îÎã•ÏÉÅÌÉú üöß Ïù¥ Ìè¨Ïä§Ìä∏Îäî ÏïÑÏßÅ Ïù¥Í¥Ä ÏûëÏóÖÏù¥ ÏôÑÎ£åÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§ üöß\nÏù¥Ï†Ñ Í∏Ä : Ïó∞ÏÇ∞Ïûê Î∞©Î≤ïÏúºÎ°ú Ï°∞ÌôîÏßÑÎèôÏûê Î¨∏Ï†ú ÌíÄÍ∏∞ : ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞Ïûê Ï†ÅÏö©Í≥ÑÏÜçÌï¥ÏÑú Ï°∞ÌôîÏßÑÎèôÏûêÏùò ÏóêÎÑàÏßÄÏôÄ Î∞îÎã•ÏÉÅÌÉúÏùò Í≥†Ïú†Ìï®ÏàòÎ•º Íµ¨Ìï¥Î≥¥Ïûê.$E=\u0026lt;\\psi|H|\\psi\u0026gt;=\u0026lt;\\psi|(a_+a_-+\\dfrac{1}{2})\\hbar w|\\psi\u0026gt;$Ïù¥ Îïå Í≥†Ïú†Ìï®ÏàòÏóê Ìïú ÏóÜÏù¥ $a_-$Î•º Ï†ÅÏö©ÏãúÌÇ¨ Ïàú ÏóÜÎã§.ÏóêÎÑàÏßÄÍ∞Ä $0$Î≥¥Îã§ ÏûëÏïÑÏßà ÏàòÎäî ÏóÜÎã§Îäî ÎßêÏù¥Îã§.ÏóêÎÑàÏßÄÍ∞Ä Ìè¨ÌÖêÏÖú Î≥¥Îã§ ÏûëÏùÑ ÎïåÎäî Ìï¥Í∞Ä ÏóÜÍ∏∞ ÎïåÎ¨∏Ïóê $E\u0026gt;U$Ïù¥Ïñ¥Ïïº ÌïòÍ∏∞ ÎïåÎ¨∏Ïù¥Îã§.Ï¶â, Îçî Ïù¥ÏÉÅ ÏóêÎÑàÏßÄÏ§ÄÏúÑÍ∞Ä ÎÇ¥Î†§Í∞ÄÏßÄ ÏïäÎäî Î∞îÎã•ÏÉÅÌÉú$\\mathrm{ground\\ state}$Í∞Ä ÏûàÍ≥†Î∞îÎã• ÏÉÅÌÉúÏóê ÎÇ¥Î¶ºÏó∞ÏÇ∞Ïûê$\\mathrm{lowering\\ operator}$Î•º Ï†ÅÏö©ÏãúÌÇ§Î©¥ $0$Ïù¥Îã§.Ï¶â, Î∞îÎã•ÏÉÅÌÉúÎ•º $|\\psi_{0}\u0026gt;$ÎùºÍ≥† ÌïòÎ©¥$a_-|\\psi_{0}\u0026gt;=0$Ïù¥Ï†ú Ïù¥ ÏÇ¨Ïã§ÏùÑ Ïù¥Ïö©Ìï¥ÏÑú Î∞îÎã•ÏÉÅÌÉúÏùò ÏóêÎÑàÏßÄÎ•º Íµ¨Ìï¥Î≥¥Ïûê.$\\begin{align*} H|\\psi_{0}\u0026gt; =\u0026amp;\\ (a_+a_- + \\frac{1}{2})\\hbar w|\\psi_{0}\u0026gt; \\\\ =\u0026amp;\\ \\hbar w a_+a_-|\\psi_{0}\u0026gt;+\\frac{1}{2}\\hbar w|\\psi_{0}\u0026gt; \\\\ =\u0026amp;\\ \\frac{1}{2}\\hbar w |\\psi_{0}\u0026gt; \\end{align*} $$ \\therefore H|\\psi_{0}\u0026gt;=\\dfrac{1}{2}\\hbar w |\\psi_{0}\u0026gt;$Î∞îÎã•ÏÉÅÌÉúÏùò ÏóêÎÑàÏßÄÎäî $E_{0}=\\dfrac{1}{2}\\hbar w$Ïù¥Îã§.$0$Ïù¥ ÏïÑÎãàÎã§!Ïù¥Ï†Ñ Í∏ÄÏóêÏÑú ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞ÏûêÎäî Í≥†Ïú†Ìï®ÏàòÏùò ÏóêÎÑàÏßÄÎ•º $\\pm \\hbar w$ÎßåÌÅº Î≥ÄÌôîÏãúÌÇ§Îäî Í≤ÉÏùÑ ÏïåÏïòÎã§.Ï¶â, Ï≤´ Î≤àÏß∏ Îì§Îú¨ ÏÉÅÌÉúÏùò ÏóêÎÑàÏßÄÎäî$E_{1}=\\dfrac{1}{2}\\hbar w +\\hbar w$Îëê Î≤àÏß∏ Îì§Îú¨ ÏÉÅÌÉúÏùò ÏóêÎÑàÏßÄÎäî$E_2=\\dfrac{1}{2}\\hbar w+2\\hbar w$Îî∞ÎùºÏÑú $n$Î≤àÏß∏ ÏóêÎÑàÏßÄÏóê ÎåÄÌï¥ÏÑú ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÌëúÌòÑÌï† Ïàò ÏûàÎã§.$E_{n}=(n+\\dfrac{1}{2})\\hbar w,\\ \\ (n=0,\\ 1,\\ 2,\\ \\cdot)$ÏóêÎÑàÏßÄ Ï§ÄÏúÑÍ∞Ä Îì±Í∞ÑÍ≤©($\\hbar w $)ÏúºÎ°ú Ïù¥Î£®Ïñ¥Ï†∏ÏûàÏùåÏùÑ Ïïå Ïàò ÏûàÎã§.Ïù¥Ï†ú Î∞îÎã•ÏÉÅÌÉúÏùò Í≥†Ïú†Ìï®Ïàò $\\psi_{0}$Î•º Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú Íµ¨Ìï¥Î≥¥Ïûê.Ï∞∏Í≥†Î°ú Ïö¥ÎèôÎüâ Ïó∞ÏÇ∞Ïûê $p$Îäî $p={\\hbar \\over i}{\\partial \\over \\partial x}$$a_-\\psi_{0}=0 $$ \\implies {1 \\over {\\sqrt{2\\hbar mw}} }(-ip+mwx) \\psi_{0}=0 $$ \\implies (-ip+mwx) \\psi_{0}=0 $$ \\implies (\\hbar\\frac{\\partial}{\\partial x} +mwx) \\psi_{0}=0 $$ \\implies \\frac{\\partial}{\\partial x}\\psi_{0}=-\\frac{mwx}{\\hbar}\\psi_{0}$Ïó¨Í∏∞ÏÑú Î≥ÄÏàòÎ∂ÑÎ¶¨Î•º Ìï¥Ï£ºÎ©¥$\\displaystyle \\frac{1}{\\psi_{0}} d\\psi_{0}=-\\frac{mwx}{\\hbar} dx $$ \\implies \\ln (\\psi_{0}) = -\\frac{mwx^2}{2\\hbar}+C $$ \\implies \\psi_{0}(x)=Ce^{-\\frac{mwx^2}{2\\hbar}}$Ïù¥Ï†ú Í∑úÍ≤©ÌôîÏÉÅÏàò $C$Îßå Íµ¨ÌïòÎ©¥ Î∞îÎã•ÏÉÅÌÉúÏùò Í≥†Ïú†Ìï®ÏàòÎ•º Ï†ïÌôïÌïòÍ≤å Ïïå Ïàò ÏûàÎã§.Í∑úÍ≤©Ìôî Ï°∞Í±¥Ïóê ÏùòÌï¥$\\displaystyle \\int_{-\\infty}^{\\infty} (\\psi_{0})^{\\ast}\\psi_{0}dx=1 $$ \\implies |C|^2\\int_{-\\infty}^{\\infty}e^{-\\frac{mwx^2}{\\hbar}} dx=1$Ïù¥ Ï†ÅÎ∂ÑÏùÑ Í≥ÑÏÇ∞ÌïòÍ∏∞ ÏúÑÌï¥ Í∞ÄÏö∞Ïä§ Ï†ÅÎ∂Ñ : $e^{-x^2}$Íº¥Ïùò Ï†ïÏ†ÅÎ∂ÑÏùÑ Ï∞∏Í≥†ÌïòÏûê.Ï†ÅÎ∂ÑÌïòÍ∏∞ Ìé∏ÌïòÍ≤å ÏπòÌôòÏùÑ Ìï¥Ï£ºÎ©¥ $\\sqrt{\\frac{mw}{\\hbar}}x \\equiv y $$ dx=\\sqrt{\\frac{\\hbar}{mw}}dy$, Ï†ÅÎ∂Ñ Î≤îÏúÑÎäî Î≥ÄÌï® ÏóÜÎã§.Ïù¥Ï†ú ÏõêÎûòÏùò ÏãùÏóê ÎåÄÏûÖÌï¥Ï£ºÎ©¥$\\displaystyle \\implies |C|^2\\sqrt{\\dfrac{\\hbar}{mw}}\\int_{-\\infty}^{\\infty}e^{-^y2} dy=1 $$ \\implies |C|^2\\sqrt{\\dfrac{\\hbar}{mw}}\\sqrt{\\pi}=1 $$ \\implies |C|^2\\sqrt{\\dfrac{\\hbar \\pi}{mw}}=1 $$ \\therefore |C|^2=\\sqrt{\\frac{mw}{\\hbar \\pi}},\\ \\ C=(\\frac{mw}{\\hbar \\pi})^{\\frac{1}{4}}$Îî∞ÎùºÏÑú ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú Î∞îÎã•ÏÉÅÌÉúÏùò Í≥†Ïú†Ìï®ÏàòÎäî$\\psi_{0} (x)=(\\frac{mw}{\\hbar \\pi})^{\\frac{1}{4}} e^{-\\frac{mwx^2}{2\\hbar}}$Îã§Ïùå Í∏ÄÏóêÏÑúÎäî $n$Ïóê ÎåÄÌï¥ÏÑú ÏùºÎ∞òÌôîÎêú Í≥†Ïú†Ìï®ÏàòÎ•º Íµ¨Ìï¥Î≥¥Í≤†Îã§.Îã§Ïùå Í∏Ä : Ïó∞ÏÇ∞Ïûê Î∞©Î≤ïÏúºÎ°ú Ï°∞ÌôîÏßÑÎèôÏûê Î¨∏Ï†ú ÌíÄÍ∏∞ : ÏùºÎ∞òÌôîÎêú Í≥†Ïú†Ìï®Ïàò\nüöß Ïù¥ Ìè¨Ïä§Ìä∏Îäî ÏïÑÏßÅ Ïù¥Í¥Ä ÏûëÏóÖÏù¥ ÏôÑÎ£åÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§ üöß\nÏù¥Ï†Ñ Í∏Ä : Ïó∞ÏÇ∞Ïûê Î∞©Î≤ïÏúºÎ°ú Ï°∞ÌôîÏßÑÎèôÏûê Î¨∏Ï†ú ÌíÄÍ∏∞ : ÏóêÎÑàÏßÄ Ï§ÄÏúÑÏôÄ Î∞îÎã•ÏÉÅÌÉúÏùò Í≥†Ïú†Ìï®Ïàò Ïù¥Ï†ú Ï°∞ÌôîÏßÑÎèôÏûêÏùò ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞ÏûêÏôÄ Î∞îÎã•ÏÉÅÌÉúÏùò Í≥†Ïú†Ìï®ÏàòÎ°úÎ∂ÄÌÑ∞ ÏùºÎ∞òÌôîÎêú Í≥†Ïú†Ìï®ÏàòÎ•º Íµ¨Ìï¥Î≥¥Ïûê.ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞Ïûê $a_\\pm$Îäî Í≥†Ïú†Ìï®Ïàò $\\psi_{n}$Ïùò ÏÉÅÌÉúÎ•º Ìïú Îã®Í≥Ñ Ïò¨Î†§Ï£ºÍ±∞ÎÇò ÎÇ¥Î†§Ï§ÄÎã§.Îî∞ÎùºÏÑú Îã§ÏùåÍ≥º Í∞ôÏùÄ ÏãùÏùÑ ÏÑ∏Ïö∏ Ïàò ÏûàÎã§.$a_+|\\psi_{n}\u0026gt;=C_+|\\psi_{n+1}\u0026gt; $$ a_-|\\psi_{n}\u0026gt;=C_-|\\psi_{n-1}\u0026gt; $$ C_\\pm$Îäî Í∞ÅÍ∞Å $n$Î≤àÏß∏ÏôÄ $(n+1)$Î≤àÏß∏, $n$Î≤àÏß∏ÏôÄ $(n-1)$Î≤àÏß∏ ÏÉÅÌÉú ÏÇ¨Ïù¥Ïùò ÎπÑÎ°ÄÍ≥ÑÏàòÏù¥Îã§. Ïù¥ ÎπÑÎ°ÄÍ≥ÑÏàòÎ•º Ï†ïÌôïÌïòÍ≤å Íµ¨Ìï¥Î≥¥Ïûê.Í∞Å Í≥†Ïú†Ìï®ÏàòÎì§Ïù¥ Í∑úÍ≤©ÌôîÎêú Í≥†Ïú†Ìï®ÏàòÎùºÍ≥† Í∞ÄÏ†ïÌïòÍ≥† Í∑úÍ≤©ÌôîÏ°∞Í±¥ÏùÑ ÏÇ¨Ïö©ÌïòÏûê.Í∑úÍ≤©ÌôîÎêú Í≥†Ïú† Ìï®ÏàòÎäî ÏûêÏã†Í≥º ÎÇ¥Ï†ÅÌïòÎ©¥ Í∞íÏù¥ $1$Ïù¥Îã§.ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞ÏûêÏôÄ Ìï¥Î∞ÄÌÜ†ÎãàÏïà ÏÇ¨Ïù¥Ïùò Í¥ÄÍ≥ÑÏãùÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥.$\\begin{align*} (a_+|\\psi_{n}\u0026gt;)^{\\ast}(a_+|\\psi_{n}\u0026gt;) =\u0026amp;\\ \u0026lt;\\psi_{n}|a_-a_+|\\psi_{n}\u0026gt; \\\\ =\u0026amp;\\ \u0026lt;\\psi_{n}| \\frac{1}{\\hbar w}H + \\frac{1}{2} |\\psi_{n}\u0026gt; \\\\ =\u0026amp;\\ \\frac{1}{\\hbar w} E_{n} \u0026lt;\\psi_{n}|\\psi_{n}\u0026gt; + \\frac{1}{2} \u0026lt;\\psi_{n}|\\psi_{n}\u0026gt; \\\\ =\u0026amp;\\ \\frac{1}{\\hbar w}(n+\\frac{1}{2})\\hbar w +\\frac{1}{2} \\\\ =\u0026amp;\\ n+1 \\end{align*}$ Î∞òÎ©¥ ÏúÑÏùò ÎπÑÎ°ÄÏãùÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥$\\begin{align*} (a_+|\\psi_{n}\u0026gt;)^{\\ast}(a_+|\\psi_{n}\u0026gt;) =\u0026amp;\\ (C_+|\\psi_{n+1}\u0026gt;)^{\\ast}(C_+|\\psi_{n+1}\u0026gt;) \\\\ =\u0026amp;\\ |C_+|^2\u0026lt;\\psi_{n+1}|\\psi_{n+1}\u0026gt; \\\\ =\u0026amp;\\ |C_+|^2 \\end{align*}$ Îî∞ÎùºÏÑú ÏúÑÏùò Îëê Í≤∞Í≥ºÎ•º Ï¢ÖÌï©ÌïòÎ©¥ $C_+$Í∞íÏùÑ ÏñªÏùÑ Ïàò ÏûàÎã§.$|C_+|^2=n+1 $$ \\implies C_+=\\sqrt{n+1} $$ \\therefore a_+|\\psi_{n}\u0026gt;=\\sqrt{n+1}|\\psi_{n+1}\u0026gt;$ Í∞ôÏùÄ Î∞©Î≤ïÏúºÎ°ú $C_-$ÎèÑ Íµ¨Ìï† Ïàò ÏûàÎã§.Í≥ºÏ†ïÏùÄ ÏÉùÎûµÌïòÍ≥† Í≤∞Í≥ºÎßå Ï†ÅÏùÑ ÌÖåÎãà ÏßÅÏ†ë Ìï¥Î≥¥Í∏∏ Î∞îÎûÄÎã§.$|C_-|^2=n $$ \\implies C_-=\\sqrt n $$ \\implies a_-|\\psi_{n}\u0026gt;=\\sqrt n |\\psi_{n-1}\u0026gt;$ Ïù¥Ï†ú Ïù¥ Í≤∞Í≥ºÏôÄ Î∞îÎã•ÏÉÅÌÉú $|\\psi_{0}\u0026gt;$Î•º Ïù¥Ïö©Ìï¥ÏÑú ÏùºÎ∞òÌôîÎêú $n$Î≤àÏß∏ ÏÉÅÌÉúÎ•º Íµ¨Ìï¥Î≥¥Ïûê.$ a_+|\\psi_{n}\u0026gt;=\\sqrt{n+1}|\\psi_{n+1}\u0026gt;$Ïù¥ÎØÄÎ°ú $ |\\psi_{n+1}\u0026gt;=\\frac{1}{\\sqrt{n+1}}a_+|\\psi_{n}\u0026gt;$Ïù¥Îã§. 1Î≤àÏß∏ Îì§Îú¨ ÏÉÅÌÉú$|\\psi_{1}\u0026gt;=a_+|\\psi_{0}\u0026gt;$2Î≤àÏß∏ Îì§Îú¨ ÏÉÅÌÉú$\\begin{align*} |\\psi_2\u0026gt; =\u0026amp;\\ \\frac{1}{\\sqrt{2}}a_+|\\psi_{1}\u0026gt; \\\\ =\u0026amp;\\ \\frac{1}{\\sqrt{2}}a_+a_+|\\psi_{0}\u0026gt; \\\\ =\u0026amp;\\ \\frac{1}{\\sqrt{2}}(a_+)^2|\\psi_{0}\u0026gt; \\end{align*}$3Î≤àÏß∏ Îì§Îú¨ ÏÉÅÌÉú$\\begin{align*} |\\psi_{3}\u0026gt; =\u0026amp;\\ \\frac{1}{\\sqrt{3}}a_+|\\psi_2\u0026gt; \\\\ =\u0026amp;\\ \\frac{1}{\\sqrt{3}}a_+\\frac{1}{\\sqrt{2}}(a_+)^2|\\psi_{0}\u0026gt; \\\\ =\u0026amp;\\ \\frac{1}{\\sqrt{3!}}(a_+)^3|\\psi_{0}\u0026gt; \\end{align*}$4Î≤àÏß∏ Îì§Îú¨ ÏÉÅÌÉú$\\begin{align*} |\\psi_{4}\u0026gt; =\u0026amp;\\ \\frac{1}{\\sqrt{4}}a_+|\\psi_{3}\u0026gt; \\\\ =\u0026amp;\\ \\frac{1}{\\sqrt{4}}a_+\\frac{1}{\\sqrt{3!}}(a_+)^3|\\psi_{0}\u0026gt; \\\\ =\u0026amp;\\ \\frac{1}{\\sqrt{4!}}(a_+)^4|\\psi_{0}\u0026gt; \\end{align*}$ Îî∞ÎùºÏÑú $|\\psi_{n}\u0026gt;=\\frac{1}{\\sqrt{n!}}(a_+)^n|\\psi_{0}\u0026gt; $ Ïó¨Í∏∞Ïóê Ïù¥Ï†ÑÏóê Íµ¨Ìïú Î∞îÎã•ÏÉÅÌÉúÏùò Í≥†Ïú†Ìï®Ïàò $\\psi_{0}(x)=(\\frac{mw}{\\hbar \\pi})^{\\frac{1}{4}} e^{-\\frac{mwx^2}{2\\hbar}}$ÏôÄÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞Ïûê $a_+=\\frac{1}{\\sqrt{2\\hbar mw }}(mwx+ip)=\\sqrt{\\frac{mw}{2\\hbar}}x-\\sqrt{\\frac{\\hbar}{2mw}}\\frac{d}{dx}$Î•º ÎåÄÏûÖÌïòÎ©¥ $\\psi_{n} (x) =\\frac{1}{\\sqrt{n!}} \\left( \\sqrt{\\frac{mw}{2\\hbar}}x-\\sqrt{\\frac{\\hbar}{2mw}}\\frac{d}{dx} \\right)^n (\\frac{mw}{\\hbar \\pi})^{\\frac{1}{4}} e^{-\\frac{mwx^2}{2\\hbar}}$Ïù¥Í≤ÉÏù¥ Î∞îÎ°ú Ïó∞ÏÇ∞ÏûêÎ•º Ïù¥Ïö©Ìï¥ÏÑú Íµ¨Ìïú Ï°∞ÌôîÏßÑÎèôÏûêÏùò ÏùºÎ∞òÌôîÎêú $n$Î≤àÏß∏ ÏÉÅÌÉú($n$Î≤àÏß∏ Í≥†Ïú†Ìï®Ïàò)Ïù¥Îã§.\n","id":362,"permalink":"https://freshrimpsushi.github.io/en/posts/362/","tags":null,"title":"Ïó∞ÏÇ∞Ïûê Î∞©Î≤ïÏúºÎ°ú Ï°∞ÌôîÏßÑÎèôÏûê Î¨∏Ï†ú ÌíÄÍ∏∞  ÏÇ¨Îã§Î¶¨ Ïó∞ÏÇ∞ÏûêÏùò Ï†ïÏùò"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":"Definition Raising Operator: $L_+ \\equiv L_{x} + iL_{y}$ Lowering Operator: $L_- \\equiv L_{x} - iL_{y}$, i.e., $(L_-)^{\\ast}=L_+$ Explanation Why are these two operators named \u0026lsquo;raising\u0026rsquo; and \u0026rsquo;lowering\u0026rsquo;? It\u0026rsquo;s because when applied to the simultaneous eigenfunction of the square of the angular momentum magnitude and an angular momentum component, it raises or lowers the state of the eigenfunction. This can be seen in Finding the Eigenvalues of the Square of Angular Momentum and Its Components\u0026rsquo; Simultaneous Eigenfunction.\nIn this article, various relationships and commutators for calculation purposes will be established. Also, such operators that change the eigenvalue of another operator\u0026rsquo;s eigenvector (eigenfunction) are called ladder operators$\\mathrm{Ladder\\ Operator}$. Operators that increase eigenvalues are called raising operators, and those that decrease are called lowering operators. ‚ÄªNote: The order of operations is very important for operators, so they should not be handled as casually as one might with numbers. This is because two arbitrary operators generally do not commute. For instance, when expanding $(A+B)^2$, $A^2+2AB+B^2$ is incorrect. It should be expanded as $(A+B)^2=(A+B)(A+B)=A^2+AB+BA+B^2$.\n$$ \\begin{align*} 1)\\ L_+L_-= (L_{x} + iL_{y})(L_{x}-iL_{y}) =\u0026amp;\\ {L_{x}}^2 + iL_{y}L_{x} - iL_{x}L_{y} + {L_{y}}^2 \\\\ =\u0026amp;\\ {L_{x}}^2+{L_{y}}^2 -i[L_{x},L_{y}] \\\\ =\u0026amp;\\ {\\vec L}^2 -{L_{z}}^2 +\\hbar L_{z} \\end{align*} $$\n$$ \\begin{align*} 2)\\ L_-L_+= (L_{x} - iL_{y})(L_{x} + iL_{y}) =\u0026amp;\\ {L_{x}}^2 - iL_{y}L_{x} + iL_{x}L_{y} + {L_{y}}^2 \\\\ =\u0026amp;\\ {L_{x}}^2+{L_{y}}^2 +i[L_{x},L_{y}] \\\\ =\u0026amp;\\ {\\vec L}^2 -{L_{z}}^2 -\\hbar L_{z} \\end{align*} $$ 1)$Í≥º $2)$Ïùò Í≤∞Í≥ºÎ•º Ï¢ÖÌï©ÌïòÎ©¥\n$$ \\begin{align*} 3)\\ {\\vec L}^2 =\u0026amp;\\ L_+L_- + {L_{z}}^2 -\\hbar L_{z} \\\\ =\u0026amp;\\ L_-L_+ + {L_{z}}^2 +\\hbar L_{z} \\\\ =\u0026amp;\\ L_\\pm L_\\mp + {L_{z}}^2 \\mp \\hbar L_{z} \\end{align*} $$\n$$ \\begin{align*} 4)\\ [L_{z},L_\\pm] =\u0026amp;\\ [L_{z},L_{x} \\pm iL_{y}] \\\\ =\u0026amp;\\ [L_{z},L_{x}] \\pm i [L_{z},L_{y}] \\\\ =\u0026amp;\\ i\\hbar L_{y} \\pm i (-i\\hbar L_{x}) \\\\ =\u0026amp;\\ \\pm \\hbar(L_{x} \\pm iL_{y}) \\\\ =\u0026amp;\\ \\pm \\hbar L_\\pm \\end{align*} $$\n$$ \\begin{align*} 5)\\ [{\\vec L}^2, L_\\pm] =\u0026amp;\\ [\\vec L^2, L_{x} \\pm iL_{y}] \\\\ =\u0026amp;\\ [{\\vec L}^2,L_{x}] \\pm i [{\\vec L}^2 , L_{y}] \\\\ =\u0026amp;\\ 0 \\end{align*} $$ ( \\because [${\\vec L}^2, L_{i}]=0$ Ï∞∏Í≥† $)\nWhen $L_+$ and $L_-$ are combined:\n$$ \\begin{align*} 6)\\ L_{x}=\u0026amp;\\ \\dfrac{1}{2} (L_+ + L_-) \\\\ L_{y} =\u0026amp;\\ \\dfrac{-i}{2}(L_{x} - L_-) \\end{align*} $$\n","id":344,"permalink":"https://freshrimpsushi.github.io/en/posts/344/","tags":null,"title":"Ladder Operators for Angular Momentum: Raising and Lowering Operators"},{"categories":"R","contents":"Overview R is a representative statistical programming language that not only provides useful methods but also offers data sets that are good as examples. Without such data sets, one would have to download and load new data every time when giving lectures.\nGuide The method to load a data set is very simple. All you need to do is assign the name of the data set you want to load to the variable we will use. Let\u0026rsquo;s take a look at the Iris (flower) data, which you will see worn out as an example while studying statistics.\nEach column represents the length and width of the sepal, the length and width of the petal, and the species, respectively. Although each column has a name, if it is difficult to understand the data with just this, enter ?iris to read the help.\nOf course, the Iris is not the only data set available. Entering library(help=datasets) in the console window will show a list of available data sets and brief descriptions as shown below.\nBroad Classification Regression Analysis attitude LifeCycleSavings Loblolly attenu faithful iris quakes wiss trees Time Series AirPassengers BJsales EuStockMarkets WorldPhones JohnsonJohnson LakeHuron Nile UKDriverDeaths UKgas USAccDeaths USPersonalExpenditure WWWusage airmiles airquality austres co2 discoveries freeny lh longley lynx nhtemp nottem presidents sunspot.month sunspot.year sunspots treering uspop Multivariate Harman23.cor Harman74.cor USJudgeRatings Categorical HairEyeColor Titanic UCBAdmissions ability.cov Experimental CO2 ChickWeight DNase Indometh InsectSprays Orange OrchardSprays PlantGrowth Puromycin Theoph cars chickwts morley mtcars npk pressure warpbreaks Small Samples BOD Formaldehyde VADeaths anscombe euro sleep stackloss women Others crimtab esoph eurodist islands occupationalStatus precip randu rivers rock volcano ","id":331,"permalink":"https://freshrimpsushi.github.io/en/posts/331/","tags":null,"title":"How to import built-in datasets in R"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 A group $\\left\u0026lt; G, \\ast\\ \\right\u0026gt;$ is defined to be an Abelian Group if for any two elements $a, b$ in $a \\ast\\ b = b \\ast\\ a$, $\\left\u0026lt; G, \\ast\\ \\right\u0026gt;$ satisfies the commutative property.\nExplanation The term \u0026ldquo;commutative\u0026rdquo; implies that the commutative law is applicable. In English, instead of Commutative, the term Abelian is used, named after the genius mathematician Abel. It is perfectly fine to refer to it as an Abel group in Korean for the sake of conveying the meaning.\nBy the time a group is an Abelian group, it has satisfied quite a complex structure, meaning it is not an unimaginable structure. Let\u0026rsquo;s look at an example where a group can be a group but not an Abelian group.\nFor a set of invertible square matrices $\\text{GL}_{n} (\\mathbb{R}) = \\left\\{ A \\in \\mathbb{R}^{n \\times n} \\ | \\ \\det A \\ne 0 \\right\\}$, the group $\\left\u0026lt; \\text{GL}_{n} (\\mathbb{R}) , \\cdot \\right\u0026gt;$ is not an Abelian group.\nThe multiplication of matrices does not satisfy the commutative law. The fact that the commutative law is not applicable in the multiplication of matrices is often taken as crucial when one first encounters operations with matrices. This emphasizes that the commutative law is a natural property in the numbers we deal with daily. Conversely, there are many examples where the commutative law is satisfied, and these examples are usually familiar to us.\nThe group $\\left\u0026lt; \\mathbb{R} , + \\right\u0026gt;$ is an Abelian group.\nThe addition of real numbers satisfies the commutative law. Considering only the most familiar real numbers, the same also applies to complex numbers, rational numbers, and integers. It is often much more challenging to find an example of a group that is not an Abelian group.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p39.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":309,"permalink":"https://freshrimpsushi.github.io/en/posts/309/","tags":null,"title":"Commutative Groups in Abstract Algebra"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Theorem 1 Let the analytic function $f: A \\subset \\mathbb{C} \\to \\mathbb{C}$ have a finite number of singularities $z_{1} , z_{2} , \\cdots , z_{m}$ inside a simple closed path $\\mathscr{C}$. Then, $$ \\int_{\\mathscr{C}} f(z) dz = 2 \\pi i \\sum_{k=1}^{m} \\text{Res}_{z_{k}} f(z) $$\nExplanation At first glance, the theorem might seem quite confusing. One has to calculate the integral, but instead of calculus-like computations, there\u0026rsquo;s talk about singularities and residues; it might well be perplexing. The theorem suggests that one could find the integral value simply by adding up residues. But could it really be that straightforward? Surprisingly, the answer is \u0026lsquo;yes\u0026rsquo;, thanks to the residue theorem.\nThis approach not only replaces integral calculations with other calculations but also makes many integrals that were impossible to solve feasible. Some integrals that couldn\u0026rsquo;t be handled with real numbers become relatively straightforward with the application of the residue theorem. Complex analysis hosts many important theorems, but the residue theorem, in particular, provides especially useful results and is thus essential to understand.\nProof First, let\u0026rsquo;s break $\\mathscr{C}$ into $m$ parts.\nGeneralized contraction sublemma for partitions: Assuming $f: A \\subseteq \\mathbb{C} \\to \\mathbb{C}$ is analytic at all points inside a simple closed path $\\mathscr{C}$, excluding a finite number of points $z_{1} , z_{2}, \\cdots z_{m}$ within a simply connected region that contains $\\mathscr{C}$. Then, for a circle $\\mathscr{C_k}$ centered at $z_{k}$ inside $\\mathscr{C}$, $$ \\int_{\\mathscr{C}} f(z) dz = \\sum_{k=1}^{m} \\int_{\\mathscr{C}_{k}} f(z) dz $$\nIf we expand each $\\mathscr{C}_{k}$ using a Laurent series, $$ \\int_{\\mathscr{C}_{k}} f(z) dz = \\int_{\\mathscr{C}_{k}} \\sum_{n = 0 }^{\\infty} a_{nk} (z-z_{k}) ^{n} dz + \\int_{\\mathscr{C}_{k}} \\sum_{n = 1 }^{\\infty} { {b_{nk} } \\over{ (z-z_{k}) ^{n} } } dz $$ by the Cauchy\u0026rsquo;s theorem, $$ \\int_{\\mathscr{C}_{k}} f(z) dz = \\int_{\\mathscr{C}_{k}} \\sum_{n = 1 }^{\\infty} { {b_{nk} } \\over{ (z-z_{k}) ^{n} } } dz $$ meanwhile, since $\\int_{\\mathscr{C}_{k}} {{1} \\over {(z - z_{k})^n}} dz = \\begin{cases} 2 \\pi i \u0026amp; n = 1 \\\\ 0 \u0026amp; n \\ge 2 \\end{cases}$ by Cauchy\u0026rsquo;s integral formula, $$ \\int_{\\mathscr{C}_{k}} f(z) dz = 2 \\pi i b_{1k} = 2 \\pi i \\text{Res}_{z_{k}} f(z) $$ Therefore, $$ \\int_{\\mathscr{C}} f(z) dz = 2 \\pi i \\sum_{k=1}^{m} \\text{Res}_{z_{k}} f(z) $$\n‚ñ†\nNotes Especially in the proof, it is important to note that when $n=1$, all coefficients except for the residue $b_1k$, that is, $\\displaystyle {{1} \\over {z - z_{k}}}$, become $0$ and vanish. The residue theorem can be so beneficial that if one only studies its applications, it might be easy to forget why such results occur. Reminding oneself of the form of Cauchy\u0026rsquo;s integral formula and the Laurent series could signify a thorough understanding.\nOsborne (1999). Complex variables and their applications: p153.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":308,"permalink":"https://freshrimpsushi.github.io/en/posts/308/","tags":null,"title":"Proof of the Residue Theorem"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":"Definition For an operator $A$, we denote its conjugate transpose as $A^{\\dagger}$.\nAn operator $A$ that satisfies $A = A^{\\dagger}$ is called a Hermitian operator.\n","id":304,"permalink":"https://freshrimpsushi.github.io/en/posts/304/","tags":null,"title":"Hermite Operators"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 The number of elements (vectors) of a basis for a vector space $V$ is defined as the dimension of $V$ and is denoted as follows.\n$$ \\dim (V) $$\nExplanation Such a generalization of dimensions goes beyond merely exploring vector spaces and is being applied to various technologies that support this society. It might seem pointless to consider dimensions higher than the $3$ dimensions of our world and the $4$ dimensions we can\u0026rsquo;t even draw, but this is because Euclidean space is not the only kind of vector space. For example, consider a dataset used in statistics, which can be viewed as a vector. For instance, if a person named \u0026lsquo;Adam\u0026rsquo; has a height of 175, weight of 62, age of 22, IQ of 103, and vision of 1.2, it can be represented as \u0026lsquo;Adam=(175, 62, 22, 103, 1.2)\u0026rsquo;. Even such straightforward data involves the use of $5$ dimensions, which would be ineffective with even minor limitations.\nOn the other hand, considering that the basis of a vector space is not unique, for the above definition to be considered valid it is necessary that all bases have the same number of elements. From the following two theorems, it can be known that all bases of a finite-dimensional vector space must have the same number of vectors.\nTheorems Let $S = \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots \\mathbf{v}_{n} \\right\\}$ be any basis of the vector space $V$.\n(a) A subset of $V$ that has more vectors than the basis is linearly dependent.\n(b) A subset of $V$ that has fewer vectors than the basis cannot span $V$.\nProof2 (a) Let\u0026rsquo;s consider $W=\\left\\{ \\mathbf{w}_{1},\\ \\mathbf{w}_{2},\\ \\cdots ,\\ \\mathbf{w}_{m} \\right\\} \\subset V$. In this case, $m \u0026gt; n$. Since $S$ is a basis of $V$, the elements of $W$ can be expressed as linear combinations of the vectors of $S$.\n$$ \\begin{equation} \\begin{aligned} \\mathbf{w}_{1} \u0026amp;= a_{11}\\mathbf{v}_{1}+a_{21}\\mathbf{v}_{2} + \\cdots + a_{n1}\\mathbf{v}_{n}=\\sum \\limits _{i}^{n} a_{i1}\\mathbf{v}_{i} \\\\ \\mathbf{w}_{2} \u0026amp;= a_{12}\\mathbf{v}_{1}+a_{22}\\mathbf{v}_{2} + \\cdots + a_{n2}\\mathbf{v}_{n}=\\sum \\limits _{i}^{n} a_{i2}\\mathbf{v}_{i} \\\\ \u0026amp; \\vdots \\\\ \\mathbf{w}_{m} \u0026amp;= a_{1m}\\mathbf{v}_{1}+a_{2m}\\mathbf{v}_{2} + \\cdots + a_{nm}\\mathbf{v}_{n}=\\sum \\limits _{i}^{n} a_{im}\\mathbf{v}_{i} \\end{aligned} \\label{wlincom1} \\end{equation} $$\nTo show that $W$ is linearly dependent,\n$$ \\begin{equation} k_{1}\\mathbf{w}_{1} + k_2\\mathbf{w}_{2} + \\cdots + k_{m}\\mathbf{w}_{m}= \\mathbf{0} \\label{wlincom2} \\end{equation} $$\nit suffices to show that there exists $(k_{1},k_{2},\\dots,k_{m}) \\ne (0,0,\\dots,0)$ that satisfies the equation. By substituting $(1)$ into $(2)$, we get the following.\n$$ \\begin{align*} \u0026amp;k_{1}(a_{11}\\mathbf{v}_{1} + a_{21}\\mathbf{v}_{2} + \\cdots + a_{n1}\\mathbf{v}_{n}) \\\\ + \u0026amp;k_2(a_{12}\\mathbf{v}_{1} + a_{22}\\mathbf{v}_{2} + \\cdots + a_{n2}\\mathbf{v}_{n}) \\\\ + \u0026amp;\\cdots \\\\ + \u0026amp;k_{m}(a_{1m}\\mathbf{v}_{1} + a_{2m}\\mathbf{v}_{2} + \\cdots + a_{nm}\\mathbf{v}_{n}) = \\mathbf{0} \\end{align*} $$\nArranging this for $\\mathbf{v}_{i}$ gives the following.\n$$ \\left( \\sum \\limits _{j} ^{m} k_{j}a_{1j} \\right)\\mathbf{v}_{1} + \\left( \\sum \\limits _{j} ^{m} k_{j}a_{2j} \\right)\\mathbf{v}_{2} + \\cdots + \\left( \\sum \\limits _{j} ^{m} k_{j}a_{nj} \\right)\\mathbf{v}_{n} = \\mathbf{0} $$\nSince $S$ is a basis of $V$ and is linearly independent, the only solution that satisfies the above equation is when all coefficients are $0$. Hence, the following equation holds.\n$$ \\begin{align*} a_{11}k_{1} + a_{12}k_{2} + \\cdots + a_{1m}k_{m} = 0 \\\\ a_{21}k_{1} + a_{22}k_{2} + \\cdots + a_{2m}k_{m} = 0 \\\\ \\vdots \\\\ a_{n1}k_{1} + a_{n2}k_{2} + \\cdots + a_{nm}k_{m} = 0 \\end{align*} $$\nLooking at the system of equations, there are $n$ equations, and the number of unknowns $k$ is $m$. Since there are more unknowns than equations, the system of equations has infinitely many nontrivial solutions. Therefore, not all solutions are $0$, and a $k_{1},\\dots,k_{m}$ exists. Hence, $W$ is linearly dependent. Moreover, this proof applies to any set that has more elements than the basis.\n‚ñ†\n(b) The proof is by contradiction.\nAssume $W=\\left\\{ \\mathbf{w}_{1},\\ \\mathbf{w}_{2},\\ \\cdots ,\\ \\mathbf{w}_{m} \\right\\} \\subset V$. Then, $m \u0026lt; n$. Suppose that $W$ spans $V$. Then, all vectors of $V$ can be expressed as linear combinations of $W$.\n$$ \\begin{equation} \\begin{aligned} \\mathbf{v}_{1} \u0026amp;= a_{11}\\mathbf{w}_{1}+a_{21}\\mathbf{w}_{2} + \\cdots + a_{m1}\\mathbf{w}_{m} \\\\ \\mathbf{v}_{2} \u0026amp;= a_{12}\\mathbf{w}_{1}+a_{22}\\mathbf{w}_{2} + \\cdots + a_{m2}\\mathbf{w}_{m} \\\\ \u0026amp; \\vdots \\\\ \\mathbf{v}_{n} \u0026amp;= a_{1n}\\mathbf{w}_{1}+a_{2n}\\mathbf{w}_{2} + \\cdots + a_{mn}\\mathbf{w}_{m} \\end{aligned} \\label{vlincom1} \\end{equation} $$\nThis leads to a contradiction that the $\\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots \\mathbf{v}_{n} \\right\\}$ are linearly dependent. Consider the following homogeneous equation.\n$$ k_{1}\\mathbf{v}_{1} + k_2\\mathbf{v}_{2} + \\cdots + k_{n}\\mathbf{v}_{n}= \\mathbf{0} $$\nSubstituting $(1)$ into it, we get the following.\n$$ \\begin{align*} \u0026amp;k_{1}(a_{11}\\mathbf{w}_{1} + a_{21}\\mathbf{w}_{2} + \\cdots + a_{m1}\\mathbf{w}_{m}) \\\\ + \u0026amp;k_2(a_{12}\\mathbf{w}_{1} + a_{22}\\mathbf{w}_{2} + \\cdots + a_{m2}\\mathbf{w}_{m}) \\\\ + \u0026amp;\\cdots \\\\ + \u0026amp;k_{n}(a_{1n}\\mathbf{w}_{1} + a_{2n}\\mathbf{w}_{2} + \\cdots + a_{mn}\\mathbf{w}_{m}) = \\mathbf{0} \\end{align*} $$\nArranging this for $\\mathbf{w}_{i}$ gives the following.\n$$ \\left( \\sum \\limits _{j} ^{n} k_{j}a_{1j} \\right)\\mathbf{w}_{1} + \\left( \\sum \\limits _{j} ^{n} k_{j}a_{2j} \\right)\\mathbf{w}_{2} + \\cdots + \\left( \\sum \\limits _{j} ^{n} k_{j}a_{mj} \\right)\\mathbf{w}_{m} = \\mathbf{0} $$\nThen we obtain the following homogeneous linear system for the unknowns $k$.\n$$ \\begin{align*} a_{11}k_{1} + a_{12}k_{2} + \\cdots + a_{1n}k_{n} = 0 \\\\ a_{21}k_{1} + a_{22}k_{2} + \\cdots + a_{2n}k_{n} = 0 \\\\ \\vdots \\\\ a_{m1}k_{1} + a_{m2}k_{2} + \\cdots + a_{mn}k_{n} = 0 \\end{align*} $$\nSince the number of unknowns is $n$ and the number of equations is $m$, and since $m \u0026lt; n$, the linear system has infinitely many nontrivial solutions. Hence, we conclude that $S = \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots \\mathbf{v}_{n} \\right\\}$ is linearly dependent, which contradicts the fact that $S$ is linearly independent, thereby disproving the assumption. Thus, $W$ cannot span $V$.\n‚ñ†\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p248\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p252-253\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3018,"permalink":"https://freshrimpsushi.github.io/en/posts/3018/","tags":null,"title":"Dimension of the Vector Space"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":"Definition In quantum mechanics, a wave function is a vector and is fundamentally treated as a column vector. Column vectors are denoted by a right single arrow bracket, and this is called a ket vector.\n$$ \\psi = \\ket{\\psi} = \\begin{pmatrix} \\psi_{1} \\\\ \\psi_{2} \\\\ \\vdots \\\\ \\psi_{n} \\end{pmatrix} $$\nThe conjugate transpose matrix of $\\ket{\\psi}$ is denoted by a left single arrow bracket and is called a bra vector.\n$$ \\psi^{\\ast} = \\ket{\\psi}^{\\ast} = \\bra{\\psi} = \\begin{pmatrix} \\psi_{1}^{\\ast} \u0026amp; \\psi_{2}^{\\ast} \u0026amp; \\cdots \u0026amp; \\psi_{n}^{\\ast} \\end{pmatrix} $$\n$^{\\ast}$ means conjugate transpose.\nExplanation Conjugate Transpose In physics, $^{\\ast}$ is commonly explained as a complex conjugate, but in mathematics, $^{\\ast}$ carries both meanings of complex conjugate and transpose matrix. However, from the above definition, we can see that even in physics, the notation has the meaning of transpose. That is, in physics, the notation is used redundantly, where $\\ast$ attached to a scalar means complex conjugate, and when attached to a vector or matrix, it means conjugate transpose. If $^{\\ast}$ is seen merely as the meaning of a complex conjugate, it is confusing why if $\\psi$ is a column vector, then $\\psi^{\\ast}$ is a row vector, so be careful.\nOrigin of the Name The origin of the name comes from the English word bracket, which means parentheses. Since the parenthesis is split in half, the word was also split in half and used as the name. To colloquially translate it into Korean, it could be thought of as Í¥Ñ-Î≤°ÌÑ∞(bra-vector) and Ìò∏-Î≤°ÌÑ∞(ket-vector).\nRelation with Inner Product It is one notation used in quantum mechanics to conveniently operate on operators and wave functions (eigenvectors). The reason for using the single arrow brackets is due to its relation to the inner product. Mathematically, the notation of a generalized inner product is written as $\\left\\langle \\quad \\right\\rangle$. Therefore, when denoting row vectors and column vectors as above, the multiplication of two vectors itself becomes an inner product, making the notation quite fitting.\n$$ \\braket{ \\psi \\vert \\phi } = \\begin{pmatrix} \\psi_{1}^{\\ast} \u0026amp; \\psi_{2}^{\\ast} \u0026amp; \\cdots \u0026amp; \\psi_{n}^{\\ast} \\end{pmatrix}\\begin{pmatrix} \\phi_{1} \\\\ \\phi_{2} \\\\ \\vdots \\\\ \\phi_{n} \\end{pmatrix} = \\psi_{1}^{\\ast}\\phi_{1} + \\psi_{2}^{\\ast}\\phi_{2} + \\cdots + \\psi_{n}^{\\ast}\\phi_{n} $$\nThe expectation value of any operator $Q$ is as follows.\n$$ \\braket{Q}= \\int \\psi^{\\ast} Q \\psi dx $$\nThis can be seen as the inner product between $\\psi$ and $Q\\psi$, and therefore can be denoted as follows.\n$$ \\braket{\\psi \\vert Q\\psi} $$\nOr it can be thought of as the inner product between $Q^{\\ast}\\psi$ and $\\psi$.\n$$ \\int \\psi^{\\ast} Q \\psi dx = \\int (Q^{\\ast}\\psi)^{\\ast} \\psi dx = \\braket{Q^{\\ast}\\psi \\vert \\psi} $$\nThe notations below all mean the same expression.\n$$ \\braket{Q} = \\braket{\\psi \\vert Q \\vert \\psi} = \\braket{\\psi \\vert Q \\psi} = \\braket{Q^{\\ast}\\psi \\vert \\psi} = \\int \\psi^{\\ast} Q \\psi dx $$\n","id":303,"permalink":"https://freshrimpsushi.github.io/en/posts/303/","tags":null,"title":"What is Dirac Notation?"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":"Buildup In mathematics, what is called a function is a relationship that maps exactly one element of some set $X$ to an element of another set $Y$, and it is commonly denoted by $f$, following the first letter of the word function. If we consider a function that maps an element $x$ of the set $X$ to an element $y$ of the set $Y$, we denote it as follows.\n$$ y = f(x) $$\nIf the relationship is specifically given for $x$, it is expressed as in the following examples.\n$$ y = 3x^{3} -2 x^{2} + x + 1 \\quad \\text{and} \\quad y = e^{3x} \\quad \\text{and} \\quad y = 5 \\cos x $$\nMany students in science and engineering probably think of a function as a relationship between some number $x$ and some number $y$, as most of the functions they encounter do this. However, as the definition above shows, there is no necessity for functions to essentially link numbers with numbers. Meaning, sets $X$ and $Y$ don\u0026rsquo;t necessarily have to be composed of numbers. For instance, functions connecting functions with numbers can be considered, and this is encountered as the concept known as action when learning Hamilton\u0026rsquo;s principle in classical mechanics.\nDefinition of a Functional\nWhen a function is substituted into another function and in return, a certain number comes out, that function is referred to as a functional. For example, the function $F$ defined below is a functional.\n$$ {\\color{blue}F\\big( {\\color{orange}f(x)} \\big)} := {\\color{red} \\int_{1}^{2} f(x) dx} $$\nNamely, the function $F$ has a function value that is the definite integral from $1$ to $2$ of some function. Performing the actual calculation yields\n$$ {\\color{blue}F( {\\color{orange} e^{x} })} = \\int_{1}^2 e^x dx = {\\color{red}e^2-e},\\quad {\\color{blue}F({\\color{orange}x^2})}=\\int_{1}^2 x^{2} dx = {\\color{red}\\frac{7}{3} } $$\nNow, let\u0026rsquo;s go further and consider sets $X$ and $Y$ as sets of functions. Even in this case, we can think of a function that maps $X$ to $Y$. A specific example of such a function is differentiation. Let\u0026rsquo;s say the function $f$ is differentiation. Then, $f$ becomes a function that maps the quadratic polynomial $x^{2} + 3x + 1$ to the linear polynomial $2x + 3$.\n$$ f\\left( x^{2} + 3x + 1 \\right) = 2x + 3 $$\nNext, let\u0026rsquo;s consider the function $g$ as indefinite integration. Then, $g$ becomes a function that maps $\\cos x$ to $\\sin x$. (Let\u0026rsquo;s omit the constant of integration)\n$$ g(\\cos x) = \\sin x $$\nHowever, talking about a function that maps a function to another function can be confusing due to the repeated use of the word \u0026ldquo;function,\u0026rdquo; and it\u0026rsquo;s not a good expression. Therefore, in quantum mechanics, such functions are referred to by a special name.\nDefinition In quantum mechanics, a function that maps a (wave) function to another (wave) function is specially called an operator.\nExplanation Operators appear in a field of mathematics called functional analysis, where they are translated as operators in this context. Although the above definition is not strictly the definition of an operator, it is sufficient for physics students who have not studied advanced mathematics.\nThe reason why the del operator is called an operator is also related to the above definition. For example, the gradient $\\nabla$ is an operator that maps the scalar function $f$ to the vector function $\\left( \\dfrac{\\partial f}{\\partial x}, \\dfrac{\\partial f}{\\partial y}, \\dfrac{\\partial f}{\\partial z} \\right)$. This is why we continuously say not to think of the del operator as a vector at the shrimp sushi restaurant.\nOperators discussed in quantum mechanics include the momentum operator $p_{\\text{op}}$, and the energy operator Hamiltonian $H$, among others.\nExample In quantum mechanics, a wave function is a function that describes the motion state of a particle according to time and position. Let\u0026rsquo;s say a particle\u0026rsquo;s wave function is $\\psi = \\psi (x,t) = A e ^{i(kx+\\omega t) }$. To avoid confusion with momentum $p$, the momentum operator is denoted as $p_{\\text{op}}$. This operator, when given the wave function $\\psi$, maps it to the function obtained by multiplying the wave function and the momentum $p$ of this particle. It is expressed in the following formula.\n$$ p_{\\text{op}} (\\psi) = p_{\\text{op}} \\psi = p \\psi $$\nIn this case, it is common to omit the brackets as shown above. This is because inserting the wave function $\\psi$ into the operator $p_{\\text{op}}$ can be treated akin to multiplying two matrices. If we view the above equation as a matrix multiplication, it becomes an eigenvalue equation, and the wave function $\\psi$ and momentum $p$ become the eigenfunction and eigenvalue of the momentum operator $p_{\\text{op}}$, respectively. The momentum operator is specifically given as follows.\n$$ p_{\\text{op}}=\\displaystyle \\frac{\\hbar}{i}\\frac{\\partial}{\\partial x} $$\nInserting the wave function $\\psi$ into the above operator yields the momentum $p=\\hbar k$ as confirmed by the following.\n$$ p_{\\text{op}}(\\psi) = p_{\\text{op}}\\psi = \\frac{\\hbar}{i}\\frac{\\partial }{\\partial x} \\left( \\psi \\right) = \\frac{\\hbar}{i}\\frac{\\partial \\psi}{\\partial x} = (ik)\\frac{\\hbar}{i}\\psi = p \\psi $$\n","id":301,"permalink":"https://freshrimpsushi.github.io/en/posts/301/","tags":null,"title":"In Physics (Quantum Mechanics), an Operator Refers to"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Buildup Taylor\u0026rsquo;s theorem generalizes the mean value theorem regarding the number of differentiations. It expands from dealing with something differentiated $1$ times to $n \\in \\mathbb{N}$ times. But if it was possible to generalize it to natural numbers, could it not be generalized to all integers? Of course, it\u0026rsquo;s not possible to differentiate $-n$ times, but what about considering integration, which is the inverse operation of differentiation? Here we introduce the Laurent\u0026rsquo;s Theorem without proof.\nAssuming $f$ is analytic on two concentric circles $\\mathscr{C}_{1}: |z-\\alpha| = r_{1}$ and $\\mathscr{C}_{2}: |z-\\alpha| = r_{2}$ $(r_{2} \u0026lt; r_{1})$ centered at the singularity $\\alpha$ of $f: A \\subset \\mathbb{C} \\to \\mathbb{C}$. Then, for all points between the two concentric circles, $f$ can be represented by $\\displaystyle f(z) = \\sum_{n = 0 }^{\\infty} a_{n} (z-\\alpha) ^{n} + \\sum_{n = 1 }^{\\infty} { {b_{n} } \\over{ (z-\\alpha) ^{n} } }$.\n$\\displaystyle a_{n} = {{1} \\over {2 \\pi i}} \\int_{\\mathscr{C}_{1}} {{f(z)} \\over {(z - \\alpha)^{ 1 + n} }} dz \\qquad , n = 0,1,2, \\cdots$ $\\displaystyle b_{n} = {{1} \\over {2 \\pi i}} \\int_{\\mathscr{C}_{2}} {{f(z)} \\over {(z - \\alpha)^{ 1 - n} }} dz \\qquad , n=1,2,3,\\cdots$ Definition The following series is called the Laurent series. $$ f(z) = \\sum_{n = 0 }^{\\infty} a_{n} (z-\\alpha) ^{n} + \\sum_{n = 1 }^{\\infty} { {b_{n} } \\over{ (z-\\alpha) ^{n} } } $$\nExplanation A Generalization of Cauchy\u0026rsquo;s Integral Formula for Differentiation: Let $f: A \\subseteq \\mathbb{C} \\to \\mathbb{C}$ be analytic in a simply connected region $\\mathscr{R}$.\nIf a simple closed path $\\mathscr{C}$ in $\\mathscr{R}$ encloses a point $\\alpha$, then for a natural number $n$:\n$$ {{f^{(n)} (\\alpha) } \\over {n!}} = {{1} \\over {2 \\pi i }} \\int_{\\mathscr{C}} {{f(z)} \\over { (z - \\alpha)^{1+n} }} dz $$\nUsing Cauchy\u0026rsquo;s Integral Formula will make it more evident that it is a generalization of Taylor\u0026rsquo;s theorem.\n$$ f(z) = \\sum_{n = 0 }^{\\infty} {{f^{(n)} (\\alpha) } \\over {n!}} (z-\\alpha) ^{n} + \\sum_{n = 1 }^{\\infty} { {b_{n} } \\over{ (z-\\alpha) ^{n} } } $$ In such a series form, $\\displaystyle \\sum_{n = 1 }^{\\infty} { {b_{n} } \\over{ (z-\\alpha) ^{n} } }$ is referred to as the Principal Part. Notably, the coefficient of $\\displaystyle {{1} \\over {z-\\alpha}}$, i.e., $b_{1}$, is defined as the Residue of $f$ at $\\alpha$ and is expressed as $b_{1} = \\text{Res}_{\\alpha} f(z)$1.\nOsborne (1999). Complex variables and their applications: p144.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":290,"permalink":"https://freshrimpsushi.github.io/en/posts/290/","tags":null,"title":"What is the Laurent Series?"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Explanation In physics, the four operations involving the del operator $\\nabla$, Gradient, Divergence, Curl, Laplacian, are very important. Therefore, one must know the operations in three coordinate systems. Of course, this does not mean that you have to memorize them. Since physics study is not about memorizing formulas, they will naturally be memorized as you study, so do not try to memorize them intentionally but instead keep a printout of the formulas with you, or bookmark this page and pull it up when needed.\nFormulas Let $f$ be a scalar function, vector function$\\mathbf A$ be $\\mathbf A= A_{1}\\mathbf{\\hat e_{1}}+A_2\\mathbf{\\hat e_2}+A_{3}\\mathbf{\\hat e_{3}}$.\nGradient:\n$$ \\begin{align*} \\nabla f \u0026amp;= \\mathbf{\\hat e_{1}}\\frac{1}{h_{1}}\\frac{\\partial f}{\\partial e_{1}}+ \\mathbf{\\hat e_2}\\frac{1}{h_2}\\frac{\\partial f}{\\partial e_2}+\\mathbf{\\hat e_{3}}\\frac{1}{h_{3}}\\frac{\\partial f}{\\partial e_{3}} \\\\ \u0026amp;= \\sum \\limits_{i=1}^3 \\mathbf{\\hat e_{i}}\\frac{1}{h_{i}}\\frac{\\partial f}{\\partial e_{i}} \\end{align*} $$\nDivergence:\n$$ \\nabla \\cdot \\mathbf A=\\frac{1}{h_{1}h_2h_{3}} \\left[ \\frac{\\partial}{\\partial e_{1}} (h_2h_{3}A_{1}) + \\frac{\\partial}{\\partial e_2} (h_{1}h_{3}A_2) + \\frac{\\partial}{\\partial e_{3}} (h_{1}h_2A_{3}) \\right] $$\nCurl:\n$$ \\nabla \\times \\mathbf A =\\frac{1}{h_{1}h_2h_{3}} \\begin{vmatrix} h_{1} \\mathbf{\\hat e_{1}} \u0026amp; h_2 \\mathbf{\\hat e_2} \u0026amp; h_{3} \\mathbf{\\hat e_{3}} \\\\[0.5em] \\dfrac{\\partial}{\\partial e_{1}} \u0026amp; \\dfrac{\\partial }{\\partial e_2} \u0026amp; \\dfrac{\\partial}{\\partial e_{3}} \\\\[1em] h_{1}A_{1} \u0026amp; h_2A_2 \u0026amp; h_{3}A_{3} \\end{vmatrix} $$\nLaplacian:\n$$ \\begin{align*} \u0026amp; \\nabla \\cdot (\\nabla f) \\\\ =\u0026amp;\\ \\nabla ^2 f \\\\ =\u0026amp;\\ \\frac{1}{h_{1}h_2h_{3}} \\left[ \\frac{\\partial }{\\partial e_{1}} \\left( \\frac{h_2h_{3}}{h_{1}} \\frac{\\partial f}{\\partial e_{1}} \\right) +\\frac{\\partial }{\\partial e_2} \\left( \\frac{h_{1}h_{3}}{h_2} \\frac{\\partial f}{\\partial e_2} \\right) + \\frac{\\partial }{\\partial e_{3}} \\left( \\frac{h_{1}h_2}{h_{3}} \\frac{\\partial f}{\\partial e_{3}} \\right) \\right] \\end{align*} $$\nThe unit vectors and scale factors for each coordinate system are as follows.\nCartesian Coordinates:\n$$ \\mathbf{\\hat{e_{1}}}=\\mathbf{\\hat{\\mathbf{x}}},\\quad\\mathbf{\\hat{e_{2}}}=\\mathbf{\\hat{\\mathbf{y}}},\\quad\\mathbf{\\hat{e_{3}}}=\\mathbf{\\hat{\\mathbf{z}}},\\quad h_{1}=1,\\quad h_{2}=1,\\quad h_{3}=1 $$\nCylindrical Coordinates:\n$$ \\mathbf{\\hat{e_{1}}}=\\boldsymbol{\\hat \\rho},\\quad\\mathbf{\\hat{e_{2}}}=\\boldsymbol{\\hat \\phi},\\quad\\mathbf{\\hat{e_{3}}}=\\mathbf{\\hat{\\mathbf{z}}},\\quad h_{1}=1,\\quad h_{2}=\\rho,\\quad h_{3}=1 $$\nSpherical Coordinates\n$$ \\mathbf{\\hat{e_{1}}}=\\mathbf{\\hat r},\\quad\\mathbf{\\hat{e_{2}}}=\\boldsymbol{\\hat \\theta},\\quad\\mathbf{\\hat{e_{3}}}=\\boldsymbol{\\hat \\phi},\\quad h_{1}=1,\\quad h_{2}=r,\\quad h_{3}=r\\sin\\theta $$\nCartesian Coordinates Gradient $$ \\nabla f = \\frac{\\partial f}{\\partial x}\\mathbf{\\hat{\\mathbf{x}} }+ \\frac{\\partial f}{\\partial y}\\mathbf{\\hat{\\mathbf{y}}} + \\frac{\\partial f}{\\partial z}\\mathbf{\\hat{\\mathbf{z}}} $$\nDivergence $$ \\nabla \\cdot \\mathbf A=\\frac{\\partial A_{x}}{\\partial x}+\\frac{\\partial A_{y}}{\\partial y}+\\frac{\\partial A_{z}}{\\partial z} $$\nCurl $$ \\begin{align*} \\nabla \\times \\mathbf A\u0026amp;=\\left(\\frac{\\partial A_{z}}{\\partial y}-\\frac{\\partial A_{y}}{\\partial z} \\right) \\mathbf{\\hat{\\mathbf{x}}}+\\left(\\frac{\\partial A_{x}}{\\partial z}-\\frac{\\partial A_{z}}{\\partial x} \\right) \\mathbf{\\hat{\\mathbf{y}}}+\\left(\\frac{\\partial A_{y}}{\\partial x}-\\frac{\\partial A_{x}}{\\partial y} \\right) \\mathbf{\\hat{\\mathbf{z}}} \\\\ \u0026amp;= \\begin{vmatrix} \\mathbf{\\hat{\\mathbf{x}}} \u0026amp; \\mathbf{\\hat{\\mathbf{y}}} \u0026amp; \\mathbf{\\hat{\\mathbf{z}}} \\\\ \\dfrac{\\partial}{\\partial x} \u0026amp; \\dfrac{\\partial }{\\partial y} \u0026amp; \\dfrac{\\partial}{\\partial z} \\\\ A_{x} \u0026amp; A_{y} \u0026amp; A_{z} \\end{vmatrix} \\end{align*} $$\nLaplacian $$ \\begin{align*} \\nabla \\cdot (\\nabla f) = \\nabla ^2 f \u0026amp;= \\left( \\frac{\\partial}{\\partial x}\\mathbf{\\hat{\\mathbf{x}}}+\\frac{\\partial}{\\partial y}\\mathbf{\\hat{\\mathbf{y}}}+\\frac{\\partial}{\\partial z}\\mathbf{\\hat{\\mathbf{z}}} \\right) \\cdot \\left( \\frac{\\partial f}{\\partial x}\\mathbf{\\hat{\\mathbf{x}}}+\\frac{\\partial f}{\\partial y}\\mathbf{\\hat{\\mathbf{y}}}+\\frac{\\partial f}{\\partial z}\\mathbf{\\hat{\\mathbf{z}}} \\right) \\\\ \u0026amp;= \\frac{\\partial^2 f}{\\partial x^2}+\\frac{\\partial^2 f}{\\partial y^2}+\\frac{\\partial^2 f}{\\partial z^2} \\end{align*} $$\nCylindrical Coordinates Gradient $$ \\nabla f = \\frac{\\partial f}{\\partial \\rho}\\boldsymbol{\\hat \\rho} + \\frac{1}{\\rho}\\frac{\\partial f}{\\partial \\phi}\\boldsymbol{\\hat \\phi} + \\frac{\\partial f}{\\partial z}\\mathbf{\\hat{\\mathbf{z}}} $$\nDivergence $$ \\nabla \\cdot \\mathbf A=\\frac{1}{\\rho}\\frac{\\partial (\\rho A_\\rho)}{\\partial \\rho}+\\frac{1}{\\rho}\\frac{\\partial A_\\phi}{\\partial \\phi}+\\frac{\\partial A_{z}}{\\partial z} $$\nCurl $$ \\begin{align*} \\nabla \\times \\mathbf A\u0026amp;=\\left[\\frac{1}{\\rho}\\frac{\\partial A_{z}}{\\partial \\phi}-\\frac{\\partial A_\\phi}{\\partial z} \\right] \\boldsymbol{\\hat \\rho}+\\left[\\frac{\\partial A_\\rho}{\\partial z}-\\frac{\\partial A_{z}}{\\partial \\rho} \\right] \\boldsymbol{\\hat \\phi}+\\frac{1}{\\rho}\\left[\\frac{\\partial (\\rho A_\\phi)}{\\partial \\rho}-\\frac{\\partial A_\\rho}{\\partial \\phi} \\right] \\mathrm{\\hat{\\mathbf{z}}} \\\\ \u0026amp;= \\frac{1}{\\rho}\\begin{vmatrix} \\boldsymbol{\\hat \\rho} \u0026amp; \\rho\\boldsymbol{ \\hat \\phi} \u0026amp; \\mathbf{\\hat{\\mathbf{z}}} \\\\ \\dfrac{\\partial}{\\partial \\rho} \u0026amp; \\dfrac{\\partial }{\\partial \\phi} \u0026amp; \\dfrac{\\partial}{\\partial z} \\\\ A_\\rho \u0026amp; \\rho A_\\phi \u0026amp; A_{z} \\end{vmatrix} \\end{align*} $$\nLaplacian $$ \\nabla \\cdot (\\nabla f) = \\nabla ^2 f = \\frac{1}{\\rho}\\frac{\\partial}{\\partial \\rho}\\left( \\rho \\frac{\\partial f}{\\partial \\rho} \\right) + \\frac{1}{\\rho^2}\\frac{\\partial^2 f}{\\partial \\phi^2} + \\frac{\\partial^2 f}{\\partial z^2} $$\nSpherical Coordinates Gradient $$ \\nabla f = \\frac{\\partial f}{\\partial r} \\mathbf{\\hat{\\mathbf{r}}} + \\frac{1}{r}\\frac{\\partial f}{\\partial \\theta} \\boldsymbol{\\hat{\\boldsymbol{\\theta}}} + \\frac{1}{r\\sin\\theta}\\frac{\\partial f}{\\partial \\phi}\\boldsymbol{\\hat \\phi} $$\nDivergence $$ \\nabla \\cdot \\mathbf A=\\frac{1}{r^2}\\frac{\\partial (r^2 A_{r})}{\\partial r}+\\frac{1}{r\\sin\\theta}\\frac{\\partial (\\sin\\theta A_\\theta)}{\\partial \\theta}+\\frac{1}{r\\sin\\theta}\\frac{\\partial A_\\phi}{\\partial \\phi} $$\nCurl $$ \\begin{align*} \\nabla \\times \\mathbf A \u0026amp;=\\frac{1}{r\\sin\\theta} \\left[\\frac{\\partial (\\sin\\theta A_\\phi)}{\\partial \\theta}-\\frac{\\partial A_\\theta}{\\partial \\phi} \\right]\\mathbf{\\hat{\\mathbf{r}}}+\\frac{1}{r}\\left[\\frac{1}{\\sin\\theta} \\frac{\\partial A_{r}}{\\partial \\phi}-\\frac{\\partial (rA_\\phi)}{\\partial r} \\right] \\boldsymbol{\\hat{\\boldsymbol{\\theta}}} \\\\ \u0026amp; \\quad+ \\frac{1}{r} \\left[\\frac{\\partial (rA_\\theta)}{\\partial r}-\\frac{\\partial A_{r}}{\\partial \\theta} \\right]\\boldsymbol{\\hat \\phi} \\\\ \u0026amp;= \\frac{1}{r^2\\sin\\theta}\\begin{vmatrix} \\mathbf{\\hat{\\mathbf{r}}} \u0026amp; r\\boldsymbol{\\hat{\\boldsymbol{\\theta}}} \u0026amp; r\\sin\\theta\\boldsymbol{\\hat \\phi} \\\\ \\dfrac{\\partial}{\\partial r} \u0026amp; \\dfrac{\\partial }{\\partial \\theta} \u0026amp; \\dfrac{\\partial}{\\partial \\phi} \\\\ A_{r} \u0026amp; r A_\\theta \u0026amp; r\\sin\\theta A_\\phi \\end{vmatrix} \\end{align*} $$\nLaplacian $$ \\nabla \\cdot (\\nabla f) = \\nabla ^2 f = \\frac{1}{r^2}\\frac{\\partial}{\\partial r} \\left( r^2\\frac{\\partial f}{\\partial r} \\right) + \\frac{1}{r^2\\sin\\theta}\\frac{\\partial}{\\partial\\theta}\\left( \\sin\\theta \\frac{\\partial f}{\\partial \\theta} \\right) + \\frac{1}{r^2\\sin^2\\theta}\\frac{\\partial^2 f}{\\partial^2 \\phi} $$\n","id":299,"permalink":"https://freshrimpsushi.github.io/en/posts/299/","tags":null,"title":"Gradient, Divergence, Curl, and Laplacian in Curvilinear Coordinates"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Definitions Singularity 1 If the function $f$ is differentiable at all points of $\\mathcal{N}(\\alpha)$ in $\\alpha$, it is said to be analytic at $\\alpha$. If the function $f$ is not analytic in $\\alpha \\in \\mathbb{C}$ but is analytic at some points of $\\mathcal{N}(\\alpha)$, $\\alpha$ is called a Singular Point of $f$. If there exists $\\mathcal{N}(\\alpha)$ that is analytic at all points except for $\\alpha$, then $\\alpha$ is said to be isolated. $\\mathcal{N}$ denotes a neighborhood, meaning an open set that includes $\\alpha$. Types Let\u0026rsquo;s say $\\alpha \\in \\mathbb{C}$ is a singular point of $f$.\n$\\displaystyle \\exists \\lim_{z \\to \\alpha} f(z) \\iff$ $\\alpha$ is a removable singularity. $\\displaystyle \\lim_{z \\to \\alpha} (z - \\alpha)^n f(z) = k \\ne 0 \\iff$ $\\alpha$ is a Pole of Order $n$. If $\\alpha$ is not a pole or is associated with a branch, $\\iff$ $\\alpha$ is an essential singular point. Description Particularly, a pole is a Simple Pole if it is $n=1$.\nIn fact, unless it is a very perverted case, the points where $f$ is undefined usually become singularities.\nFor example, if it were said that $\\displaystyle f(z) = {{z - i} \\over {(z^2+1)(z+i)}}$, then the singularity would be $z= \\pm i$. It\u0026rsquo;s not necessarily finite, as in the case of $\\csc z$ where $z = n \\pi ( n \\in \\mathbb{Z} )$ are all singularities. On the other hand, $\\text{Log} z$ has a singularity at $z= 0$, which might feel a bit different from the examples mentioned above.\nIn $\\displaystyle f(z) = {{z - i} \\over {(z^2+1)(z+i)}}$, $z = i$ is removable, and $z = -i$ is a pole of order $2$.\nSince $\\displaystyle \\lim_{z \\to n \\pi} {{ z - n \\pi } \\over {\\sin z }} = 1$, the singularities of $\\csc z$ are all poles of order $1$, namely simple poles.\nLastly, in $\\text{Log} z$, $z = 0$ is a branch point, thus, an essential singularity.\nThe classification of such singularities might seem at first glance like a meaningless play on definitions, but it becomes a very important concept in the subsequent discussions on integrals.\nOsborne (1999). Complex variables and their applications: p63.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":281,"permalink":"https://freshrimpsushi.github.io/en/posts/281/","tags":null,"title":"Types of Singularities in Complex Analysis"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let\u0026rsquo;s denote a non-empty subset of vector space $V$ as $S = \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{r} \\right\\}$. For constants $k_{1}, k_{2}, \\dots, k_{r}$, the following equation\n$$ k_{1} \\mathbf{v}_{1} + k_{2} \\mathbf{v}_{2} + \\dots + k_{r} \\mathbf{v}_{r} = \\mathbf{0} $$\nhas at least one solution\n$$ k_{1} = 0,\\ k_{2} = 0,\\ \\dots,\\ k_{r} = 0 $$\nThis is called a trivial solution. If the trivial solution is the only solution, then vectors $\\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{r}$ are called linearly independent. If there is at least one solution that is not trivial, it is called linearly dependent.\nExplanation A trivial solution is a solution that is immediately obvious and hence, considered of little value. This is because, as mentioned in the definition, the case of $0$ is a frequent occurrence.\nFrom the above definition, the following theorem can be immediately derived.\nLet\u0026rsquo;s denote a non-empty subset of vector space $V$ as $S = \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{r} \\right\\}$. If no vector in $S$ can be represented as a linear combination of other vectors, it is considered linearly independent. Conversely, if at least one vector can be represented as a linear combination of others, it is considered linearly dependent.\nThinking with the theorem in mind, the naming of \u0026ldquo;independent\u0026rdquo; and \u0026ldquo;dependent\u0026rdquo; makes sense. Some textbooks have the definition and theorem in reverse order.\nInterestingly, the reference in the footnote, \u0026lsquo;Elementary Linear Algebra\u0026rsquo;, defines it as this text for the translated version, but the original version has it defined in the opposite way. Personally, I think defining it as this text is cleaner. This is because defining it in the opposite way requires separate definitions for independence/dependence for sets with only one element. The proof of the theorem is introduced later.\nIn simpler terms, if there are two distinct vectors such that one cannot be made identical to the other by scaling up or down, they are considered independent. For example, $(1,0)$ and $(0,1)$ cannot become equal to each other no matter how they are scaled, i.e., enlarged or reduced. To rewrite according to the definition,\n$$ k_{1} (1,0) + k_{2} (0,1) = \\mathbf{0} $$\nRearranging the second term gives\n$$ k_{1}(1,0) = - k_{2}(0,1) $$\nRearranging again gives\n$$ (k_{1}, 0) = ( 0 , - k_{2}) $$\nAs the only solution satisfying the above equation is $k_{1} = k_{2} = 0$, $(1,0)$ and $(0,1)$ are linearly independent. This can be proven as a theorem.\nTheorem (a) A finite set that includes the zero vector is linearly dependent.\n(b) The necessary and sufficient condition for a single vector $\\mathbf{v}$ to be linearly independent is $\\mathbf{v} \\ne \\mathbf{0}$.\n(c) The necessary and sufficient condition for two distinct vectors to be linearly independent is that one vector cannot be represented as a multiple of the other.\n(d) Let\u0026rsquo;s denote a set containing more than two vectors as $S=\\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{r} \\right\\}$. The necessary and sufficient condition for $S$ to be linearly independent is that no vector in $S$ can be represented as a linear combination of other vectors.\n(e) Let\u0026rsquo;s say $T \\subset S$. If $S$ is linearly independent, then $T$ is also linearly independent.\n(e') Let\u0026rsquo;s say $T \\subset S$. If $T$ is linearly dependent, then $S$ is also linearly dependent.\nProof (a) Let\u0026rsquo;s say $S=\\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{r}, \\mathbf{0} \\right\\}$. Then, the following equation holds true.\n$$ 0 \\mathbf{v}_{1} + 0 \\mathbf{v}_{2} + \\dots + 0 \\mathbf{v}_{r} + 1 \\mathbf{0} = \\mathbf{0} $$\nTherefore, by definition, $S$ is linearly dependent.\n‚ñ†\n(b) Applying (a) to a set with a single element proves its validity.\n‚ñ†\n(c) $(\\Longrightarrow)$\nAssume $\\mathbf{v}_{1}, \\mathbf{v}_{2}$ is linearly independent. Then,\n$$ k_{1} \\mathbf{v}_{1} + k_{2} \\mathbf{v}_{2} = \\mathbf{0} $$\nThe only solution satisfying this equation is $k_{1}=k_{2}=0$, so there does not exist a constant $k$ satisfying $\\mathbf{v}_{1} = -\\frac{k_{2}}{k_{1}}\\mathbf{v}_{2} = -k\\mathbf{v}_{2}$.\n$(\\Longleftarrow)$\nAssume $\\mathbf{v}_{1}$ cannot be represented as a constant multiple of $\\mathbf{v}_{2}$. That is, assume the following equation\n$$ \\mathbf{v}_{1} = k_{2}\\mathbf{v} $$\ndoes not have a solution for $k_{2}$. Then,\n$$ k_{1} \\mathbf{v}_{1} + k_{2} \\mathbf{v}_{2} = \\mathbf{0} $$\nSince the only solution satisfying this equation is the trivial solution, $\\mathbf{v}_{1}, \\mathbf{v}_{2}$ is linearly independent.\n‚ñ†\n(d) $(\\Longrightarrow)$\nAssume $S$ is linearly independent.\n$$ k_{1} \\mathbf{v}_{1} + k_{2} \\mathbf{v}_{2} + \\dots + k_{r} \\mathbf{v}_{r} = \\mathbf{0} $$\nSince the only solution is $k_{1}=k_{2}=\\cdots=k_{r}=0$,\n$$ \\mathbf{v}_{1} = -\\frac{k_{2}}{k_{1}}\\mathbf{v}_{2} - \\cdots - \\frac{k_{r}}{k_{1}}\\mathbf{v}_{r} $$\nno constants $\\frac{k_{2}}{k_{1}}, \\dots, \\frac{k_{r}}{k_{1}}$ exist satisfying this. This applies to all $\\mathbf{v}_{i}$, meaning no vector can be represented as a linear combination of others.\n$(\\Longleftarrow)$\nAssuming no vector can be represented as a linear combination of others,\n$$ \\mathbf{v}_{1} = k_{2}\\mathbf{v}_{2} + \\cdots + k_{r}\\mathbf{v}_{r} $$\nAssuming no solution exists for $k_{2}, \\dots, k_{r}$,\n$$ k_{1}\\mathbf{v}_{1} + k_{2}\\mathbf{v}_{2} + \\cdots + k_{r}\\mathbf{v}_{r} = \\mathbf{0} $$\nSince the only solution satisfying this equation is the trivial solution, $S$ is linearly independent.\n‚ñ†\n(e) Let\u0026rsquo;s consider the two sets $T$ and $S$ as follows.\n$$ T = \\left\\{ \\mathbf{v}_{1},\\ \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{r} \\right\\},\\quad S = \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{r}, \\mathbf{v}_{r+1}, \\dots, \\mathbf{v}_{n} \\right\\} $$\n$T$ is a subset of $S$. Now, assuming $S$ is linearly independent,\n$$ c_{1}\\mathbf{v}_{1} + c_{2}\\mathbf{v}_{2} + \\cdots +c_{r} \\mathbf{v}_{r} + c_{r+1} \\mathbf{v}_{r+1} + \\cdots + c_{n} \\mathbf{v}_{n} = \\mathbf{0} $$\nThe only solution satisfying this is the trivial solution $c_{1}=c_{2} = \\cdots = c_{r} = c_{r+1} = \\cdots = c_{n} = 0$. Therefore, since $c_{r+1} = \\cdots = c_{n} = 0$, the following equation holds true.\n$$ \\begin{align*} \u0026amp;\u0026amp; c_{1}\\mathbf{v}_{1} + c_{2}\\mathbf{v}_{2} + \\cdots +c_{r} \\mathbf{v}_{r} + c_{r+1} \\mathbf{v}_{r+1} + \\cdots + c_{n} \\mathbf{v}_{n} =\u0026amp;\\ \\mathbf{0} \\\\ \\implies \u0026amp;\u0026amp; c_{1}\\mathbf{v}_{1} + c_{2}\\mathbf{v}_{2} + \\cdots +c_{r} \\mathbf{v}_{r} + \\left( 0\\mathbf{v}_{r+1} + \\cdots + 0 \\mathbf{v}_{n} \\right) =\u0026amp;\\ \\mathbf{0} \\\\ \\implies \u0026amp;\u0026amp; c_{1}\\mathbf{v}_{1} + c_{2}\\mathbf{v}_{2} + \\cdots +c_{r} \\mathbf{v}_{r} + \\mathbf{0} =\u0026amp;\\ \\mathbf{0} \\\\ \\implies \u0026amp;\u0026amp; c_{1}\\mathbf{v}_{1} + c_{2}\\mathbf{v}_{2} + \\cdots +c_{r} \\mathbf{v}_{r} =\u0026amp;\\ \\mathbf{0} \\end{align*} $$\nHowever, this equation only holds true when $c_{1} = c_{2} = \\cdots = c_{r} = 0$, so $T$ is linearly independent.\n‚ñ†\n(e') This is a contrapositive of (e).\n‚ñ†\nHoward Anton, Chris Rorres, Anton Kaul, Elementary Linear Algebra: Applications Version(12th Edition). 2019, p228-229\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":253,"permalink":"https://freshrimpsushi.github.io/en/posts/253/","tags":null,"title":"Linear Independence and Linear Dependence"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 For elements $a$ and the identity element $e$ of a monoid $\\left\u0026lt; G, \\ast\\ \\right\u0026gt;$, if there exists $a '$ satisfying $a \\ast\\ a\u0026rsquo; = a\u0026rsquo; \\ast\\ a = e$, then $\\left\u0026lt; G, \\ast\\ \\right\u0026gt;$ is defined as a Group. That is, a group is a binary operation structure that satisfies the following properties:\n(i): The operation is associative. (ii): An identity element exists for all elements. (iii): An inverse element exists for all elements. Explanation Starting from magma and moving through semigroup, monoid, we finally arrive at group. It may not seem like much, but compared to magma, the conditions have significantly expanded. It must be closed under the operation, associative, and have both an identity and inverse elements, so not just anything can be called a group.\nThe reason for studying groups is that they are much simpler and easier than other algebraic structures. If the conditions are less than that of a group, useful properties decrease, and if the conditions are more, the applications narrow.\nMost of the algebraic structures of interest in algebra fundamentally rely on groups, and algebra is applied not only in pure mathematics like number theory but also in applied mathematics that meld into daily life, such as in cryptography. Surprisingly, group theory is also used in physics outside of mathematics.\nLet\u0026rsquo;s look at an example where it becomes a monoid but not a group.\nFor the set of regular matrices $\\mathbb{R}^{n \\times n}$, the monoid $\\left\u0026lt; \\mathbb{R}^{n \\times n} , \\cdot \\right\u0026gt;$ is not a group.\nFor the matrix $A \\in \\mathbb{R}^{n \\times n}$, if $\\det A = 0$, then $A^{-1}$ does not exist. Of course, with certain restrictions on the set, it can become a group.\nFor the set of regular matrices with inverses $\\text{GL}_{n} (\\mathbb{R}) = \\left\\{ A \\in \\mathbb{R}^{n \\times n} \\ | \\ \\det A \\ne 0 \\right\\}$, the monoid $\\left\u0026lt; \\text{GL}_{n} (\\mathbb{R}) , \\cdot \\right\u0026gt;$ is a group.\nThe sub-monoid $\\left\u0026lt; \\text{GL}_{n} (\\mathbb{R}) , \\cdot \\right\u0026gt;$ of $\\left\u0026lt; \\mathbb{R}^{n \\times n} , \\cdot \\right\u0026gt;$ has an inverse for multiplication by definition $\\text{GL}_{n} (\\mathbb{R})$, therefore it is a group. Symmetry? When grasping the concept of a group, the discussion often starts with symmetry or is entirely constructed upon mathematical definitions.\nAs an example of symmetry, actions such as rotating or leaving a Rubik\u0026rsquo;s Cube as is (identity), or reversing (inverse), are often mentioned. However, these explanations make it easy to understand that structures with symmetry have the structure of a group but difficult to comprehend that the structure of a group possesses symmetry. It\u0026rsquo;s good to think of the concept of symmetry as relating to the concept of inverses in groups.\nIf $a$ exists, then by the definition of a group, the corresponding $a '$ must exist.\nOn the other hand, as $a '$ also has a corresponding $a\u0026rsquo;\u0026rsquo;=a$, it is natural to think of this relationship as symmetry. The difference between a monoid and a group is solely the inverse, so the concept and definition are more validly matched.\nNow that we\u0026rsquo;re talking about symmetry, let\u0026rsquo;s look at a perfect example of a group with symmetry.\nThe monoid $\\left\u0026lt; \\mathbb{Z} , + \\right\u0026gt;$ is a group.\nFor integers $a$, $-a$ always has an inverse satisfying $a + (-a) = 0$. If $1$ exists, then symmetrical $-1$ exists around the identity element $0$, for $-2$, $2$ exists, for\u0026hellip; $n$, $-n$ exists. Thinking in terms of symmetry, this is quite a natural example.\nGenerally, when dealing with groups alone, group $\\left\u0026lt; G, \\ast\\ \\right\u0026gt;$ is simply represented as $G$, and operations are written as $\\cdot$ unless otherwise mentioned. However, in contexts like $\\left\u0026lt; \\mathbb{Z} , + \\right\u0026gt;$ where addition is clear, $+$ is used, adapting the appropriate operation as needed.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p37.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":278,"permalink":"https://freshrimpsushi.github.io/en/posts/278/","tags":null,"title":"In Group Theory in Abstract Algebra"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Definition 1 A semigroup $\\left\u0026lt; M , \\ast\\ \\right\u0026gt;$ is defined to be a monoid if there exists an element $e$ such that for all elements $a$ of $\\left\u0026lt; M , \\ast\\ \\right\u0026gt;$, $a \\ast\\ e = e \\ast\\ a = a$ is satisfied.\nExplanation A monoid is a semigroup with an identity element. Introducing the concept of an identity element considerably broadens the scope of discussion. Let\u0026rsquo;s look at a typical example that is a semigroup but not a monoid.\nThe semigroup $\\left\u0026lt; \\mathbb{N} , +\\right\u0026gt;$ is not a monoid.\nLet\u0026rsquo;s assume that there exists an identity element $ e$ for any natural number $a$ that satisfies $a + e = a$. Since $e$ is a natural number greater than or equal to $1$, $a + e \\ge a + 1$ holds. Meanwhile, since $a + 1 \u0026gt; a$, it follows that $a + e \u0026gt; a$, which contradicts the assumption.\nThis naturally-occurring counterexample suggests that the existence of an identity element might not be as obvious as it seems.\nFor the set of all square matrices $\\mathbb{R}^{n \\times n}$, $\\left\u0026lt; \\mathbb{R}^{n \\times n} , \\cdot \\right\u0026gt;$ is a monoid.\nBy definition of matrix multiplication, it is straightforward to show that $\\left\u0026lt; \\mathbb{R}^{n \\times n} , + \\right\u0026gt;$ is a semigroup. Meanwhile, considering the unit matrix $I_{n}$ and any matrix $( a_{ij} )$, $a_{ij} \\cdot 1 = a_{ij}$ and $a_{ij} \\cdot 0 = 0$ hence $(a_{ij}) I = I (a_{ij}) = (a_{ij})$ follows. Therefore, $I$ is the identity element of $\\left\u0026lt; \\mathbb{R}^{n \\times n} , \\cdot \\right\u0026gt;$. ‚ñ†\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p42.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":277,"permalink":"https://freshrimpsushi.github.io/en/posts/277/","tags":null,"title":"Monoids in Abstract Algebra"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition: Linear Combination1 Let $\\mathbf{w}$ be a vector in the vector space $V$. If $\\mathbf{w}$ can be expressed as follows for vectors $\\mathbf{v}_{1},\\mathbf{v}_{2},\\cdots ,\\mathbf{v}_{r}$ in $V$ and arbitrary constants $k_{1}, k_{2}, \\cdots, k_{r}$, then $\\mathbf{w}$ is called a linear combination of $\\mathbf{v}_{1},\\mathbf{v}_{2},\\cdots ,\\mathbf{v}_{r}$.\n$$ \\mathbf{w} = k_{1}\\mathbf{v}_{1} + k_{2}\\mathbf{v}_{2} + \\cdots + k_{r}\\mathbf{v}_{r} $$\nAdditionally, in this case, the constants $k_{1}, k_{2}, \\cdots, k_{r}$ are referred to as the coefficients of the linear combination $\\mathbf{w}$.\nExplanation Though it might seem unfamiliar presented in a formulaic manner, it‚Äôs not a complex concept. The representation of vectors in a two-dimensional Cartesian coordinate system is precisely the linear combination of two unit vectors $\\hat{\\mathbf{x}} = (0,1)$ and $\\hat{\\mathbf{y}} = (0,1)$.\n$$ \\mathbf{v} = (v_{1}, v_{2}) = (v_{1},0)+(0,v_{2}) = v_{1}(1,0) + v_{2}(0,1) = v_{1}\\hat{\\mathbf{x}} + v_{2} \\hat{\\mathbf{y}} $$\nTheorem Let $S = \\left\\{ \\mathbf{w}_{1}, \\mathbf{w}_{2}, \\dots, \\mathbf{w}_{r} \\right\\}$ be a non-empty subset of the vector space $V$. Then the following hold.\n(a) Let $W$ be the set of all possible linear combinations of elements of $S$. $W$ is a subspace of $V$.\n(b) The $W$ from (a) is the smallest subspace of $V$ that includes $S$. That is, if $W^{\\prime}$ is a subspace of $V$ that includes $S$, then the following equation holds.\n$$ S \\subset W \\le W^{\\prime} $$\nProof (a) To demonstrate that $W$ is closed under addition and scalar multiplication, one can apply the subspace test as follows.\n$$ \\mathbf{u} = c_{1} \\mathbf{w}_{1} + c_{2} \\mathbf{w}_{2} + \\cdots + c_{r} \\mathbf{w}_{r}, \\quad \\mathbf{v} = k_{1} \\mathbf{w}_{1} + k_{2} \\mathbf{w}_{2} + \\cdots + k_{r} \\mathbf{w}_{r} $$\n(A1)\n$\\mathbf{u}+\\mathbf{v}$ is as follows.\n$$ \\mathbf{u} +\\mathbf{v} = ( c_{1} + k_{1} ) \\mathbf{w}_{1} + ( c_{2} + k_{2} ) \\mathbf{w}_{2} + \\cdots + ( c_{r} + k_{r} ) \\mathbf{w}_{r} $$\nSince this is a linear combination of $\\mathbf{w}_{1}, \\mathbf{w}_{2}, \\dots, \\mathbf{w}_{r}$, $\\mathbf{u} + \\mathbf{v} \\in W$ is true.\n(M1)\nFor any constant $k$, $k\\mathbf{u}$ is as follows.\n$$ k\\mathbf{u} = ( k c_{1} ) \\mathbf{w}_{1} + ( k c_{2} ) \\mathbf{w}_{2} + \\cdots + ( k c_{r} ) \\mathbf{w}_{r} $$\nSince this is a linear combination of $\\mathbf{w}_{1}, \\mathbf{w}_{2}, \\dots, \\mathbf{w}_{r}$, $k\\mathbf{u} \\in W$ is true.\nConclusion\nSince $W$ is closed under addition and scalar multiplication, by the subspace test, $W$ is a subspace of $V$.\n$$ W \\le V $$\n‚ñ†\n(b) Assuming $W^{\\prime}$ is a subspace of $V$ that includes $S$, since $W^{\\prime}$ is closed under addition and scalar multiplication, all linear combinations of elements of $S$ are elements of $W^{\\prime}$. Therefore,\n$$ W \\le W^{\\prime} $$\n‚ñ†\nDefinition: Span The $W$ in the theorem is referred to as the subspace of $V$ spanned by $S$. Furthermore, it is said that the vectors $\\mathbf{w}_{1}, \\mathbf{w}_{2}, \\dots, \\mathbf{w}_{r}$ span $W$, which is denoted as follows.\n$$ W = \\text{span}\\left\\{ \\mathbf{w}_{1}, \\mathbf{w}_{2}, \\dots, \\mathbf{w}_{r} \\right\\} \\quad \\text{or} \\quad W = \\text{span}(S) $$\nExplanation The concept of spanning is necessary to contemplate the smallest set that contains certain elements. Indeed, the above theorem highlights this point. Additionally, eliminating all redundant elements from $S$ itself would make it the basis of a vector space.\nTheorem Let $S = \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{r} \\right\\}$ and $S^{\\prime} = \\left\\{ \\mathbf{w}_{1}, \\mathbf{w}_{2}, \\dots, \\mathbf{w}_{r} \\right\\}$ be non-empty subsets of the vector space $V$. Then,\n$$ \\text{span} \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{r} \\right\\} = \\text{span} \\left\\{ \\mathbf{w}_{1}, \\mathbf{w}_{2}, \\dots, \\mathbf{w}_{r} \\right\\} $$\nThe necessary and sufficient condition for this to hold is that all vectors of $S$ can be expressed as linear combinations of vectors of $S^{\\prime}$, and all vectors of $S^{\\prime}$ can be expressed as linear combinations of vectors of $S$.\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p220-222\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":512,"permalink":"https://freshrimpsushi.github.io/en/posts/512/","tags":null,"title":"Linear Combination, Span"},{"categories":"Ï∂îÏÉÅÎåÄÏàò","contents":"Buildup Mathematics can be broadly divided into three categories: geometry, analysis, and algebra. Among these, algebra was a branch of mathematics dealing with binomials, reduction, etc., in the curriculum. Algebra essentially aimed to solve any equation using letters instead of numbers. It sought after a general and powerful method of solution, not limited to specific numbers, thus could be considered cutting-edge technology of the time. However, these mathematical techniques have become common knowledge to everyone in the modern era of developed education.\nMeanwhile, the mathematical community started to develop these concepts further, moving beyond \u0026rsquo;numbers\u0026rsquo; to focus on abstract \u0026lsquo;structures\u0026rsquo;. What we previously called \u0026rsquo;numbers\u0026rsquo; and \u0026lsquo;calculations\u0026rsquo; has been abstracted to \u0026rsquo;elements\u0026rsquo; and \u0026lsquo;operations\u0026rsquo;. Therefore, modern algebra has become a discipline that studies the conditions under which algebraic techniques can be used or the structures themselves. As can be guessed from the above explanation, modern algebra is especially abstract, often referred to as \u0026lsquo;abstract algebra\u0026rsquo;.\nAbstract algebra primarily focuses on the properties of certain sets and the operations defined on those sets. Given a set $S$ and an operation $\\ast$, it studies whether $S$ is closed under $\\ast$, whether there is an identity element, whether there are inverses, etc. Among these, the operations of interest in abstract algebra are binary operations, where two elements correspond to one element like $a \\ast\\ b = c$.\nDefinition 1 Binary operation can be considered as a function defined as $\\ast : S \\times S \\to S$, and the set on which such a binary operation is defined is called a binary operation structure. For an element $a,b$ in a set $M \\ne \\emptyset$ and a binary operation $\\ast$, if $a * b \\in M$ then $\\left\u0026lt; M , \\ast\\ \\right\u0026gt;$ is defined as a magma. Description A magma is the simplest concept among the binary operation structures of interest in abstract algebra. It just needs to be closed.\nExamples of not being a magma The set of odd numbers $O$ and the set of irrational numbers $I$ are not magmas.\nExamples that cannot be magmas include the set of odd numbers and the set of irrational numbers. These are not closed under operations like multiplication or addition, and so they cannot be magmas despite being binary operation structures.\nConsidering the addition for the set of odd numbers $O$, the sum of two odd numbers is always even, so $O$ is not closed and cannot be a magma. Considering multiplication for the set of irrational numbers $I$, $\\sqrt{2} , 2\\sqrt{2} \\in I$ and $\\sqrt{2} \\cdot 2 \\sqrt{2 } = 4 $, but since $ 4 \\notin I$, $I$ is not a magma. Examples of being a magma The power set $\\mathscr{P}(S)$ of any set $S$ and the difference $\\setminus$ are magmas.\nFor subsets $A$ and $B$ of $S$, $( A \\setminus B ) \\subset S$, thus $( A \\setminus B ) \\in \\mathscr{P}(S)$, and $\\left\u0026lt; \\mathscr{P}(S) , \\setminus \\right\u0026gt;$ is a magma. Operations Matter One important thing is that when exploring algebraic structures, not only the set itself but also the operations need to be considered. Let\u0026rsquo;s revisit the examples that are not magmas.\nThe set of odd numbers $O$, and the set of irrational numbers $I$, $\\left\u0026lt; O , \\cdot \\right\u0026gt;$ is a magma but $\\left\u0026lt; I , + \\right\u0026gt;$ is not.\nConsidering multiplication for the set of odd numbers $O$, the product of two odd numbers is always odd, so $O$ is closed and is a magma. Considering addition for the set of irrational numbers $I$, $\\sqrt{2} , -\\sqrt{2} \\in I$ and $\\sqrt{2} + ( - \\sqrt{2 } ) = 0$, but since $ 0 \\notin I$, $I$ is not a magma. Although the set of odd numbers became a magma with a different operation, the set of irrational numbers still could not be a magma. In essence, even sets that seem meaningless at the moment can have the potential to hold meaningful algebraic structures, depending on the operation given.\nOn the other hand, since the definition of magma is so simple and general, magma itself does not provide useful properties. The term magma, sharing the same root as the \u0026rsquo;lava\u0026rsquo; we know, means \u0026lsquo;mixed bag\u0026rsquo; in French. It signifies that many algebraic structures start as magmas, but the concept itself is not critically important.\nFraleigh. (2003). A first course in abstract algebra(7th Edition): p20, 29.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":275,"permalink":"https://freshrimpsushi.github.io/en/posts/275/","tags":null,"title":"Binary Operations in Abstract Algebra"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 Let $W$ be a non-empty subset of the vector space $V$. If $W$ satisfies the definition of a vector space with respect to the addition and scalar multiplication defined in $V$, then $W$ is called a subspacesubspace of the vector space $V$, and is denoted as follows:\n$$ W \\le V $$\nExplanation To determine whether a subset $W$ of a vector space $V$ is a subspace of $V$, it must satisfy all 10 rules required for being a vector space. It would be quite cumbersome and difficult to check all 10 rules every time we consider a subset of a vector space. Fortunately, due to being a subset of some vector space, some rules are trivially satisfied.\nFor instance, if $\\mathbf{u},\\mathbf{v}$ is an element of $W$, it is also an element of $V$, hence (A2), (A3), (M2)-(M5) are naturally satisfied. Therefore, it is enough to verify the closure under addition (A1), the existence of the zero vector (A4), the existence of additive inverses (A5), and the closure under scalar multiplication (M1) to conclude that $W$ is a subspace. However, in practice, it\u0026rsquo;s even simpler. Satisfying conditions (A1) and (M1) is a necessary and sufficient condition for being a subspace.\nExamples Examples of subspaces of the vector space $V$ include:\nItself $V$ Cosets $v + W$ For a linear transformation $T : V \\to W$,\nThe null space of $T$ $N(T) \\le V$ The range of $T$ $R(T) \\le W$ For a linear transformation $T : V \\to V$,\nEigenspace $E_{\\lambda}$ $T$-Invariant space $T$-Cyclic space Theorem: Subspace Test Let $W$ be a non-empty subset of the vector space $V$. It is a necessary and sufficient condition for $W$ to be a subspace of $V$ if $W$ satisfies the following two conditions:\n(A1) The subset $W$ is closed under addition as defined in $V$.\n(M1) The subset $W$ is closed under scalar multiplication as defined in $V$.\nProof $(\\implies)$\nAssume that $W$ is a subspace of $V$. If $W$ is a subspace, it is trivial that $W$ satisfies (A1) and (M1) by the definition of a vector space.\n$(\\impliedby)$\nAssume that $W$ satisfies $(A1)$ and $(M1)$. Let $\\mathbf{u} \\in W$. Then, $W$ is closed under scalar multiplication, and since $0\\mathbf{u}=\\mathbf{0}$, the following is true:\n$$ 0 \\mathbf{u} = \\mathbf{0} \\in W $$\nFor the same reason, the following is true by $(-1)\\mathbf{u}=-\\mathbf{u}$:\n$$ (-1)\\mathbf{u} = -\\mathbf{u} \\in W $$\nTherefore, $W$ satisfies (A1)-(M5), thus it is a subspace of $V$.\n‚ñ†\nTheorem: The Intersection of Subspaces is a Subspace2 Let $W_{1}, W_2$ be subspaces of the vector space $V$. Then, $W_{1} \\cap W_2$ is also a subspace of $V$.\nProof By the Subspace Test, we need to check if $W_{1} \\cap W_2$ satisfies (A1) and (M1). Let $W= W_{1} \\cap W_2$.\n(A1)\nSince $W = W_{1} \\cap W_2$, any two vectors $\\mathbf u,\\mathbf v$ inside $W$ are also contained in $W_{1}$ and $W_2$. Since $W_{1}, W_2$ is a subspace, it is closed under addition. Therefore, the following is true:\n$$ \\mathbf u + \\mathbf v \\in W_{1}, \\quad \\mathbf u + \\mathbf v \\in W_2 $$\nHence, by the definition of intersection, the following is true:\n$$ \\mathbf u + \\mathbf v \\in W $$\nAny two vectors $\\mathbf u,\\ \\mathbf v$ inside $W$ implies that $\\mathbf u + \\mathbf v$ is also an element of $W$, so $W$ is closed under addition and satisfies (A1).\n(M1)\nThe proof follows similarly to the above case.\nSince $W = W_{1} \\cap W_2$, any vector $\\mathbf u$ inside $W$ is also contained in $W_{1}$ and $W_2$. Since $W_{1},\\ W_2$ is a subspace, it is closed under scalar multiplication. Hence, for any scalar $k$, the following is true:\n$$ k\\mathbf{u} \\in W_{1} \\quad k \\mathbf{u} \\in W_2 $$\nHence, by the definition of intersection, the following is true:\n$$ k\\mathbf u \\in W $$\nAny vector $\\mathbf u$ inside $W$ implies that $k\\mathbf u$ is also an element of $W$, so $W$ is closed under scalar multiplication and satisfies (M1).\nConclusion\nIf $W_{1}, W_{2}$ is a subspace, then $W = W_{1} \\cap W_2$ satisfies (A1) and (M1), thus $W$ is also a subspace.\n‚ñ†\nCorollary If $W_{1}, W_{2}, \\dots W_{n}$ are subspaces of the vector space $V$, then $W = W_{1} \\cap \\cdots \\cap \\dots W_{n}$ is also a subspace of $V$.\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p211-212\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p216\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":285,"permalink":"https://freshrimpsushi.github.io/en/posts/285/","tags":null,"title":"Subspace of Vector Space"},{"categories":"ÏÑ†ÌòïÎåÄÏàò","contents":"Definition1 When the elements of a non-empty set $V$ satisfy the following ten rules for two operations, additionaddition and scalar multiplicationscalar multiplication, $V$ is called a vector spacevector space over field2 $\\mathbb{F}$, and the elements of $V$ are called vectorsvector.\nFor $\\mathbf{u}, \\mathbf{v}, \\mathbf{w} \\in V$ and $k, l \\in \\mathbb{F}$,\n(A1) If $\\mathbf{u}, \\mathbf{v}$ is an element of $V$, then $\\mathbf{u}+\\mathbf{v}$ is also an element of $V$.\n(A2) $\\mathbf{u} + \\mathbf{v} = \\mathbf{v} + \\mathbf{u}$\n(A3) $(\\mathbf{u}+\\mathbf{v})+\\mathbf{w}=\\mathbf{u}+(\\mathbf{v}+\\mathbf{w})$\n(A4) For all $\\mathbf{u}$ in $V$, there exists $\\mathbf{0}$ in $V$ that satisfies $\\mathbf{u} + \\mathbf{0} = \\mathbf{0} + \\mathbf{u} = \\mathbf{u}$. This $\\mathbf{0}$ is called the zero vectorzero vector.\n(A5) For all $\\mathbf{u}$ in $V$, there exists $\\mathbf{v}$ in $V$ that satisfies $\\mathbf{u} + \\mathbf{v} = \\mathbf{v} + \\mathbf{u} = \\mathbf{0}$. This $\\mathbf{v}$ is called the negative of $\\mathbf{u}$negative of $\\mathbf{u}$ and is denoted by $\\mathbf{v} = -\\mathbf{u}$.\n(M1) If $\\mathbf{u}$ is an element of $V$, then $k \\mathbf{u}$ is also an element of $V$.\n(M2) $k(\\mathbf{u} + \\mathbf{v})=k\\mathbf{u} + k\\mathbf{v}$\n(M3) $(k+l)\\mathbf{u}=k\\mathbf{u}+ l\\mathbf{u}$\n(M4) $k(l\\mathbf{u})=(kl)(\\mathbf{u})$\n(M5) For $1\\in \\mathbb{F}$, $1\\mathbf{u} = \\mathbf{u}$\nExplanation The term linear spacelinear space is also used. Naturally, the scalar (field) does not need to be real numbers. Specifically, when $\\mathbb{F} = \\mathbb{R}$, it is called a real vector spacereal vector space, and when $\\mathbb{F} = \\mathbb{C}$, it is called a complex vector spacecomplex vector space.\nIn undergraduate linear algebra, mainly $\\mathbb{R}^{n}$ or $\\mathbb{C}^{n}$ are discussed. $\\mathbb{R}^{n}$ refers to the vector space containing ordered pairs of real numbers $n$. In other words, it signifies the $n$-dimensional Euclidean space, specifically $\\mathbb{R}^{3}$ refers to the three-dimensional space extensively covered in high school mathematics and calculus.\nThere are various sets that can become vector spaces. A set of functions can also be a vector space, which is called a function space.\nIn physics, something with magnitude and direction is called a vector. This concept is generalized in linear algebra. For example, consider a set $M_{m\\times n}(\\mathbb{R})$ that collects real number matrices of size $m\\times n$. Then, it can be seen that $M_{m\\times n}(\\mathbb{R})$ satisfies all ten rules mentioned above. Therefore, a set of matrices of the same size becomes a vector space, and each matrix within it becomes a vector. If you are encountering this abstract vector space for the first time, the fact that matrices can be vectors might be surprising, but it makes sense when thinking about how vectors in coordinate spaces have been denoted.\nTo determine whether a set is a vector space, one must examine whether it satisfies the definition above. It might seem intuitively to be a vector space when it is not, and vice versa. Since there can be cases entirely different from intuition, it is advisable to carefully examine each one when solving problems. Also, the zero vector $\\mathbf{0}$ and the scalar $0$ are entirely different entities and should be distinguished. Typically, vectors are expressed in bold type in textbooks.\nTheorem 1 Let $V$ be a vector space and $\\mathbf{u}$ be an element of $V$.\n(1a) The zero vector of $V$ is unique.\n(1b) The negative of $\\mathbf{u}$ is unique.\nProof This is a proof using the definition of vector spaces.\n(1a) Let\u0026rsquo;s say $\\mathbf{0},\\mathbf{0}^{\\prime}$ is the zero vector of $V$. Then, by the definition of vector spaces, the following holds.\n$$ \\begin{align*} \\mathbf{0} \u0026amp;= \\mathbf{0} + \\mathbf{0}^{\\prime} \u0026amp;\u0026amp; \\text{by (A4)} \\\\ \u0026amp;= \\mathbf{0}^{\\prime} + \\mathbf{0} \u0026amp;\u0026amp; \\text{by (A2)} \\\\ \u0026amp;= \\mathbf{0}^{\\prime} \u0026amp;\u0026amp; \\text{by (A4)} \\end{align*} $$\nTherefore, the two zero vectors are the same.\n‚ñ†\n(1b) Let\u0026rsquo;s say $\\mathbf{v}, \\mathbf{v}^{\\prime}$ is the negative of $\\mathbf{u}$. Then, by the definition of vector spaces, the following holds.\n$$ \\begin{align*} \\mathbf{v} \u0026amp;= \\mathbf{v} + \\mathbf{0} \u0026amp;\u0026amp; \\text{by (A4)} \\\\ \u0026amp;= \\mathbf{v} + \\left( \\mathbf{u} + \\mathbf{v}^{\\prime} \\right) \u0026amp;\u0026amp; \\text{by (A5)} \\\\ \u0026amp;= \\left( \\mathbf{v} + \\mathbf{u} \\right) + \\mathbf{v}^{\\prime} \u0026amp;\u0026amp; \\text{by (A3)} \\\\ \u0026amp;= \\mathbf{0} + \\mathbf{v}^{\\prime} \u0026amp;\u0026amp; \\text{by (A5)} \\\\ \u0026amp;= \\mathbf{v}^{\\prime} \u0026amp;\u0026amp; \\text{by (A4)} \\end{align*} $$\nTherefore, the two negatives of $\\mathbf{u}$ are the same.\n‚ñ†\nTheorem 2 Let $V$ be a vector space, $\\mathbf{u}$ be an element of $V$, and $k$ be a scalar.\n(2a) $0 \\mathbf{u} = \\mathbf{0}$\n(2b) $k \\mathbf{0} = \\mathbf{0}$\n(2c) $(-1) \\mathbf{u} = -\\mathbf{u}$\n(2d) If $k \\mathbf{u} = \\mathbf{0}$, then $k = 0$ or $\\mathbf{u} = \\mathbf{0}$.\nProof This is a proof using the definition of vector spaces.\n(2a) $$ \\begin{align*} \u0026amp;\u0026amp; 0\\mathbf{u} \u0026amp;= (0 + 0)\\mathbf{u} \\\\ \u0026amp;\u0026amp; \u0026amp;= 0\\mathbf{u} + 0\\mathbf{u} \u0026amp;\u0026amp;\\text{by (M3)} \\\\ \u0026amp; \u0026amp; \\\\ \\implies \u0026amp;\u0026amp; 0\\mathbf{u}+(-0\\mathbf{u}) \u0026amp;= 0\\mathbf{u} + 0\\mathbf{u} +(-0\\mathbf{u}) \\\\ \\implies \u0026amp;\u0026amp; \\mathbf{0} \u0026amp;= 0\\mathbf{u} \u0026amp;\u0026amp;\\text{by (A5)} \\end{align*} $$\n‚ñ†\n(2b) $$ \\begin{align*} \u0026amp;\u0026amp; k\\mathbf{0} \u0026amp;= k(\\mathbf{0} + \\mathbf{0}) \u0026amp;\u0026amp;\\text{by (A4)} \\\\ \u0026amp;\u0026amp; \u0026amp;= k\\mathbf{0} + k\\mathbf{0} \u0026amp;\u0026amp;\\text{by (M2)} \\\\ \u0026amp; \u0026amp; \\\\ \\implies \u0026amp;\u0026amp; k\\mathbf{0}+(-k\\mathbf{0}) \u0026amp;= k\\mathbf{0} + k\\mathbf{0} +(-k\\mathbf{0}) \\\\ \\implies \u0026amp;\u0026amp; \\mathbf{0} \u0026amp;= k\\mathbf{0} \u0026amp;\u0026amp;\\text{by (A5)} \\end{align*} $$\n‚ñ†\n(2c) $$ \\begin{align*} \\mathbf{u} + (-1)\\mathbf{u} \u0026amp;= 1 \\mathbf{u} + (-1)\\mathbf{u} \u0026amp;\u0026amp;\\text{by (M5)} \\\\ \u0026amp;= \\big( 1 + (-1) \\big) \\mathbf{u} \u0026amp;\u0026amp;\\text{by (M3)} \\\\ \u0026amp;= 0 \\mathbf{u} \\\\ \u0026amp;= \\mathbf{0} \u0026amp;\u0026amp;\\text{by (a2)} \\end{align*} $$\nThus, by (A5), $(-1)\\mathbf{u}$ is the negative of $\\mathbf{u}$, and since the negative of $\\mathbf{u}$ is unique by (1b),\n$$ (-1)\\mathbf{u} = -\\mathbf{u} $$\n‚ñ†\n(2d) $k$ must either be $0$ or not $0$, so let\u0026rsquo;s consider both scenarios.\nIf $k=0$\nThis satisfies the conclusion.\nIf $k\\ne 0$\nSince $k$ is not $0$, it can be divided by $k$, hence\n$$ \\begin{align*} \u0026amp;\u0026amp; k \\mathbf{u} \u0026amp;= \\mathbf{0} \\\\ \\implies \u0026amp;\u0026amp; \\mathbf{u} \u0026amp;= \\frac{1}{k}\\mathbf{0} \\\\ \u0026amp;\u0026amp; \u0026amp;= \\mathbf{0} \u0026amp;\u0026amp; \\text{by (2b)} \\end{align*} $$\n‚ñ†\nSee Also A simple definition of vectors Abstract Algebra Vector spaces in linear algebra Vector spaces in abstract algebra The $F$-vector spaces discussed in the documents below are essentially no different from the vector spaces mentioned above, albeit from a slightly different perspective. Vector spaces in linear algebra are abstractions of intuitive Euclidean spaces, whereas in abstract\nalgebra, vector spaces are brought into the realm of \u0026lsquo;algebra\u0026rsquo; in the true sense.\nConversely, $R$-modules generalize the scalar field $F$ of $F$-vector spaces into scalar rings $R$, thereby revealing their identity in a naming that is indifferent to the history and meaning of $F$-vector fields. From the perspective of group $G$, it\u0026rsquo;s about adding a new operation $\\mu$ to ring $R$, thus also being a moduleÂä†Áæ§.\nR-modules in abstract algebra $F$-vector spaces in abstract algebra Howard Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p202-203\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIf you are unfamiliar with fields, you can simply think of them as $\\mathbb{F}=\\mathbb{R}$ or $\\mathbb{F}=\\mathbb{C}$.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":282,"permalink":"https://freshrimpsushi.github.io/en/posts/282/","tags":null,"title":"Definition of Vector Space"},{"categories":"Ìï®Ïàò","contents":"Definition Given an interval $I \\subset \\mathbb{R}$, two elements $x_{1} , x_{2}$ and functions $f : I \\to \\mathbb{R}$ and $0 \\le t \\le 1$,\nWhen $f( t x_{1} + (1-t) x_{2}) \\le t f(x_{1}) + (1-t) f(x_{2})$, $f$ is defined as a convex function on $I$. When $f( t x_{1} + (1-t) x_{2}) \\ge t f(x_{1}) + (1-t) f(x_{2})$, $f$ is defined as a concave function on $I$. Explanation Since there are too many confusing terms for convex or concave, whether it\u0026rsquo;s upwards convex or downwards concave, it\u0026rsquo;s strongly recommended to remember the graph shapes and correspond them with convex and concave, just as they are expressed in English. Although at first glance, the definition may seem unfamiliar just by looking at the formulas, thinking about the concept of internal division can make it a very intuitive definition to accept. It\u0026rsquo;s an intuitively simple concept, so there\u0026rsquo;s no need to memorize the definition if there\u0026rsquo;s no need for formulaic elaboration or explanation. Typically, starting from the quadratic functions in junior high school, constant exposure to the properties of second derivatives and their signs makes their properties familiar as well.\nTo be honest To be honest, just assume that concave isn\u0026rsquo;t used much and it\u0026rsquo;s mostly convex.\nSecond Derivative Second derivative of a convex function: Let\u0026rsquo;s say $f$ is twice differentiable on $I$. That $f$ is convex on $I$ and $f '' (x) \\ge 0$ are necessary and sufficient conditions.\nNote the added condition of being twice differentiable here. Usually, curves like $y = x^2$ or $y = \\ln {x}$ are used as examples, making it easy to overlook, but as we have redefined the convex function, \u0026lsquo;continuous\u0026rsquo; wasn\u0026rsquo;t even mentioned.\nSee Also General Convex Vector Functions Convexity of Sets Various Properties of Convex Functions ","id":262,"permalink":"https://freshrimpsushi.github.io/en/posts/262/","tags":null,"title":"Convex Functions, Concave Functions"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition The cross product of $\\mathbf{x}$ and $\\mathbf{y}$ is defined in terms of $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^3$.\n$$ \\begin{align*} \\mathbf{x} \\times \\mathbf{y} =\u0026amp; (x_{2}y_{3} - x_{3}y_{2}, x_{3}y_{1} - x_{1}y_{3}, x_{1}y_{2} - x_{2}y_{1}) \\\\ =\u0026amp; \\det \\begin{bmatrix} \\mathbf{i} \u0026amp; \\mathbf{j} \u0026amp; \\mathbf{k} \\\\ x_{1} \u0026amp; x_{2} \u0026amp; x_{3} \\\\ y_{1} \u0026amp; y_{2} \u0026amp; y_{3} \\end{bmatrix} \\\\ =\u0026amp; \\begin{bmatrix} 0 \u0026amp; -x_{3} \u0026amp; x_{2} \\\\ x_{3} \u0026amp; 0 \u0026amp; -x_{1} \\\\ -x_{2} \u0026amp; x_{1} \u0026amp; 0 \\end{bmatrix} \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ y_{3} \\end{bmatrix} \\end{align*} $$\nExplanation Note that $\\mathbf{i} = (1,0,0)$, $ \\mathbf{j} = (0,1,0)$, and $\\mathbf{k} = (0,0,1)$. Like the dot product, the cross product can also be defined in a more general sense, but in practice, it is typically considered only in three dimensions. This specific definition in three-dimensional space is also known as a vector product, although this term is usually used only when making a strict distinction. The most common application is in physics, where it frequently appears in expressions for torque and the Lorentz force, among others. Its geometric shape can be easily envisioned by recalling the right-hand rule. Here, we introduce several properties of the cross product without proof.\nProperties For $\\mathbf{x}, \\mathbf{y}, \\mathbb{z} \\in \\mathbb{R}^3$ and $k \\in \\mathbb{R}$, the following holds:\n(1) $\\mathbf{x} \\times \\mathbf{x} = 0$\n(2) Anti commutativity: $\\mathbf{x} \\times \\mathbf{y} = -\\mathbf{y} \\times \\mathbf{x} $\n(3) $(k \\mathbf{x}) \\times \\mathbf{y} = k (\\mathbf{x} \\times \\mathbf{y}) = \\mathbf{x} \\times (k \\mathbf{y})$\n(4) $\\mathbf{x} \\times ( \\mathbf{y}+ \\mathbb{z} )= (\\mathbf{x} \\times \\mathbf{y}) + (\\mathbf{x} \\times \\mathbb{z})$\n(5) Scalar triple product: $(\\mathbf{x} \\times \\mathbf{y}) \\cdot \\mathbb{z} = \\mathbf{x} \\cdot ( \\mathbf{y} \\times \\mathbb{z})$\n(6) Vector triple product (bac-cab rule): $\\mathbf{x} \\times ( \\mathbf{y} \\times \\mathbb{z} ) = (\\mathbf{x} \\cdot \\mathbb{z}) \\mathbf{y} - (\\mathbf{x} \\cdot \\mathbf{y}) \\mathbb{z} $\n(7) $|| \\mathbf{x} \\cdot \\mathbf{y} ||^2 = (\\mathbf{x} \\cdot \\mathbf{x} ) ( \\mathbf{y} \\cdot \\mathbf{y} ) - ( \\mathbf{x} \\cdot \\mathbf{y} )^2$\n(8) $|| \\mathbf{x} \\times \\mathbf{y} || = || \\mathbf{x} || || \\mathbf{y} || \\sin{\\theta} $\n(9) If $\\mathbf{x} \\times \\mathbf{y} \\ne \\mathbb{0}$, then $\\mathbf{x} \\times \\mathbf{y} $ is perpendicular to both $\\mathbf{x}$ and $\\mathbf{y}$.\nMany properties are counterintuitive because the commutative law does not hold. Work through problems and write them out on paper to become accustomed to them.\n","id":256,"permalink":"https://freshrimpsushi.github.io/en/posts/256/","tags":null,"title":"Cross Product in Three-Dimensional Euclidean Space"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Definition Let\u0026rsquo;s say $V = \\mathbb{R}^n$ for a vector space, and also $\\mathbb{x}, \\mathbb{y}, \\mathbb{z} \\in V$ and $k \\in \\mathbb{R}$.\n$\\left\u0026lt; \\cdot , \\cdot \\right\u0026gt; : V^2 \\to \\mathbb{R}$ is defined as the inner product on $V$ when it satisfies the following four conditions:\n(1) Symmetry: $\\left\u0026lt; \\mathbb{x} , \\mathbb{y} \\right\u0026gt; = \\left\u0026lt; \\mathbb{y}, \\mathbb{x} \\right\u0026gt;$\n(2) Additivity: $\\left\u0026lt; \\mathbb{x} + \\mathbb{y} , \\mathbb{z} \\right\u0026gt; = \\left\u0026lt; \\mathbb{x}, \\mathbb{z} \\right\u0026gt; + \\left\u0026lt; \\mathbb{y}, \\mathbb{z} \\right\u0026gt;$\n(3) Homogeneity: $\\left\u0026lt; k \\mathbb{x} , \\mathbb{y} \\right\u0026gt; = k \\left\u0026lt; \\mathbb{x}, \\mathbb{y} \\right\u0026gt;$\n(4) Positive-definiteness: $\\left\u0026lt; \\mathbb{x} , \\mathbb{x} \\right\u0026gt; \\ge 0$ and $\\left\u0026lt; \\mathbb{x} , \\mathbb{x} \\right\u0026gt; =0 \\iff \\mathbb{x}=\\mathbb{0}$\nIn particular, when $\\mathbb{x} = (x_{1}, x_{2}, \\cdots , x_{n})$ and $\\mathbb{y} = (y_{1}, y_{2}, \\cdots , y_{n})$,\n$$ \\left\u0026lt; \\mathbb{x} , \\mathbb{y}\\right\u0026gt; = \\mathbb{x} \\cdot \\mathbb{y} = x_{1} y_{1} + x_{2} y_{2} + \\cdots + x_{n} y_{n} = \\mathbb{x}^T \\mathbb{y} $$\nis defined as the dot product or Euclidean inner product.\nExplanation The concept of vector spaces itself can be generalized for any field $\\mathbb{F}$. Naturally, the inner product can also be generalized, but in the basic level of linear algebra, it is common to deal only with Euclidean spaces.\nHowever, the reason why inner product is confusing when learned in university is that it is sufficiently generalized compared to high school level. When considering the inner product by itself, if there exists a mapping that satisfies the conditions, there\u0026rsquo;s no particular reason to multiply components. The difference starts from \u0026rsquo;the inner product we knew\u0026rsquo; becoming \u0026lsquo;one of the inner products we learn in university\u0026rsquo;, which is the dot product. Not only that, it is generalized for $n$ dimensions, and loses its geometric properties, which can bring great confusion to the definitions of size or angle between vectors.\n[1]: $\\left\\| \\mathbb{x} \\right\\| = \\sqrt{ \\mathbb{x} \\cdot \\mathbb{x} }$ is defined as the size or length of $\\mathbb{x}$. [2] $d(\\mathbb{x}, \\mathbb{y} ) = \\left\\| \\mathbb{x} - \\mathbb{y} \\right\\|$ is defined as the distance between $\\mathbb{x}$ and $\\mathbb{y}$.\n[3] For $\\theta \\in [0 , \\pi]$, $\\displaystyle \\cos \\theta = {{ \\mathbb{x} \\cdot \\mathbb{y} } \\over { \\left\\| \\mathbb{x} \\right\\| \\left\\| \\mathbb{y} \\right\\|}}$ is defined as the angle between $\\mathbb{x}$ and $\\mathbb{y}$.\n[4] When $\\mathbb{x} \\cdot \\mathbb{y} = 0$, $\\mathbb{x}$ and $\\mathbb{y}$ are perpendicular is defined.\nWhile up to 3 dimensions, it\u0026rsquo;s possible to manually calculate and visualize to see these definitions align with intuition, from 4 dimensions it becomes impossible. However, this kind of transcendental generalization is exactly the charm and strength of mathematics, and these definitions alone make it easy to generalize several theorems. See the two examples below.\nGeneralized Cauchy-Schwarz Inequality $$ \\left\\| \\mathbf{x} \\right\\| \\left\\| \\mathbf{y} \\right\\| \\ge \\left\u0026lt; \\mathbf{x} , \\mathbf{y} \\right\u0026gt; $$\nThe Cauchy-Schwarz Inequality originally holds for four unknowns but can be easily generalized using the inner product.\nProof For an arbitrary scalar $t \\in \\mathbb{R}$,\n$$ ( t \\mathbb{x} + \\mathbb{y} ) ^2 = t^2 (\\mathbb{x} \\cdot \\mathbb{x}) + 2t (\\mathbb{x} \\cdot \\mathbb{y} )+ ( \\mathbb{y} \\cdot \\mathbb{y} ) $$\nSince $t$ is a real number, by the quadratic formula it must be $(\\mathbb{x} \\cdot \\mathbb{y})^2 - ( \\mathbb{x} \\cdot \\mathbb{x} )( \\mathbb{y} \\cdot \\mathbb{y} ) \\le 0$.\n‚ñ†\nGeneralized Pythagorean Theorem Suppose two vectors $\\mathbb{x}$ and $\\mathbb{y}$ are perpendicular, then $\\left\\| \\mathbb{x} \\right\\|^2 + \\left\\| \\mathbb{y} \\right\\|^2 = \\left\\| \\mathbb{x} +\\mathbb{y} \\right\\|^2$\nThe Pythagorean Theorem also was originally valid for triangles on the plane. To generalize it, one needs to use the Pythagorean Theorem of a lower dimension step by step as we go higher in dimension, but using inner product makes it much easier and concise.\nProof $$ \\begin{align*} \\left\\| \\mathbb{x} +\\mathbb{y} \\right\\|^2 =\u0026amp; ( \\mathbb{x} + \\mathbb{y} ) ^2 \\\\ =\u0026amp; (\\mathbb{x} \\cdot \\mathbb{x}) + 2 (\\mathbb{x} \\cdot \\mathbb{y} )+ ( \\mathbb{y} \\cdot \\mathbb{y} ) \\\\ \u0026amp;= \\left\\| \\mathbb{x} \\right\\|^2 + 2 (\\mathbb{x} \\cdot \\mathbb{y} ) + \\left\\| \\mathbb{y} \\right\\|^2 \\end{align*} $$\nBy the definition of the inner angle, $(\\mathbb{x} \\cdot \\mathbb{y} ) = \\cos{\\theta} \\left\\| \\mathbb{x} \\right\\|^2 \\left\\| \\mathbb{y} \\right\\|^2$ and since $\\mathbb{x}$ and $\\mathbb{y}$ are perpendicular to each other $\\cos{\\theta} = 0$\n‚ñ†\nA More Generalized Pythagorean Theorem Let\u0026rsquo;s assume $\\mathbf{a}_1,\\ \\mathbf{a}_2,\\ \\cdots,\\ \\mathbf{a}_n$ are vectors perpendicular to each other. Then, the following formula holds:\n$$ \\left\\| \\mathbf{a}_1+\\mathbf{a}_2+\\cdots+\\mathbf{a}_n \\right\\|^2 = \\left\\| \\mathbf{a}_1 \\right\\|^2 + \\left\\| \\mathbf{a}_2 \\right\\|^2 +\\cdots+ \\left\\| \\mathbf{a}_n \\right\\|^2 $$\nThis theorem is a generalization of the above for $n$ vectors.\nProof According to the above definition, the following holds:\n$$ \\left\\| \\mathbf{a}_1+\\mathbf{a}_2+\\cdots+\\mathbf{a}_n \\right\\| ^2=\\left\u0026lt; \\mathbf{a}_1 + \\mathbf{a}_2 + \\cdots + \\mathbf{a}_n,\\ \\mathbf{a}_1 + \\mathbf{a}_2+\\cdots+\\mathbf{a}_n \\right\u0026gt; $$\nBy the additivity of the inner product, breaking down the above inner products results in:\n$$ \\begin{array} {l} \\left\u0026lt; \\mathbf{a}_1,\\ \\mathbf{a}_1 \\right\u0026gt;+\\left\u0026lt; \\mathbf{a}_1,\\ \\mathbf{a}_2 \\right\u0026gt;+\\cdots+\\left\u0026lt; \\mathbf{a}_1,\\ \\mathbf{a}_n \\right\u0026gt; \\\\ + \\left\u0026lt; \\mathbf{a}_2,\\ \\mathbf{a}_1 \\right\u0026gt; + \\left\u0026lt; \\mathbf{a}_2,\\ \\mathbf{a}_2 \\right\u0026gt;+\\cdots+\\left\u0026lt; \\mathbf{a}_2,\\ \\mathbf{a}_n \\right\u0026gt; \\\\ +\\cdots \\\\ + \\left\u0026lt; \\mathbf{a}_n,\\ \\mathbf{a}_1 \\right\u0026gt;+\\left\u0026lt; \\mathbf{a}_n,\\ \\mathbf{a}_2 \\right\u0026gt;+\\cdots +\\left\u0026lt; \\mathbf{a}_n,\\ \\mathbf{a}_n \\right\u0026gt; \\end{array} $$\nBecause of the assumption, $\\left\u0026lt; \\mathbf{a}_i,\\ \\mathbf{a}_j \\right\u0026gt;=\\delta_{ij}$, so only the inner products of the same vectors remain, and the rest are $0$. Therefore,\n$$ \\begin{align*} \\left\\| \\mathbf{a}_1+\\mathbf{a}_2+\\cdots+\\mathbf{a}_n \\right\\|^2 =\u0026amp; \\left\u0026lt; \\mathbf{a}_1,\\ \\mathbf{a}_1 \\right\u0026gt; + \\left\u0026lt; \\mathbf{a}_2,\\ \\mathbf{a}_2 \\right\u0026gt;+\\cdots+\\left\u0026lt; \\mathbf{a}_n,\\ \\mathbf{a}_n \\right\u0026gt; \\\\ =\u0026amp; \\left\\| \\mathbf{a}_1 \\right\\|^2 + \\left\\| \\mathbf{a}_2 \\right\\|^2 +\\cdots+\\left\\| \\mathbf{a}_n \\right\\|^2 \\end{align*} $$\n‚ñ†\n","id":255,"permalink":"https://freshrimpsushi.github.io/en/posts/255/","tags":null,"title":"Inner product in Euclidean space"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Theorem1 The dimensions of the row space and column space of matrix $A$ are the same.\nProof Let $R$ be the row echelon form matrix of $A$. Since basic row operations do not change the dimensions of the row space and column space of $A$, the following equation holds:\n$$ \\begin{align*} \\dim \\big( \\mathcal{R}(A) \\big) \u0026amp;= \\dim \\big( \\mathcal{R}(R) \\big) \\\\ \\dim \\big( \\mathcal{C}(A) \\big) \u0026amp;= \\dim \\big( \\mathcal{C}(R) \\big) \\end{align*} $$\nTherefore, it suffices to show that the dimensions of the row space and column space of $R$ are the same. But since the row space of $R$ is generated by the rows with leading 1, and the column space of $R$ is generated by the columns with leading 1, the dimensions of the row space and column space of $R$ are the same.\n‚ñ†\nDefinition The dimension of the row space (column space) of matrix $A$ is called rank and is denoted as follows:\n$$ \\text{rank}(A) = \\dim \\mathcal{R}(A) = \\dim \\mathcal{C}(A) $$\nThe dimension of the null space of matrix $A$ is called nullity and is denoted as follows:\n$$ \\text{nullity}(A) = \\dim \\mathcal{N}(A) $$\nExplanation Rank is sometimes translated as coefficient, and nullity as degeneracy.\nOn the other hand, $\\text{rank}(A)$ can also be defined as the number of pivots when $A$ is turned into a row echelon form.\nConsider the non-square matrix $m \\times n$, matrix $A$. Then, the row space can be at most $n$ dimensions, and the column space can be at most $m$ dimensions. But since these two values are the same and that is the rank, the following holds:\n$$ \\rank(A) \\le \\min(m,n) $$\nIn the case of $\\rank(A) = \\min(m,n)$, $A$ is said to have full rank. If it does not have full rank, it is called rank deficient.\nIf it is difficult to intuitively understand, think of it as a concept derived from counting the unknowns in a system of linear equations. Although the definition itself is not difficult, concepts such as null space, coefficient, and degeneracy especially complicate understanding for those who study from the original texts, making it difficult to grasp the meaning. The reason for studying these concepts is to make it easier to express the applications of linear algebra in the language of mathematics later on. When complex theories unfold, definitions like column space or null space greatly save space and cover more complex phenomena.\nAlso, the column space is called image as $\\text{Im} (A)$. If matrix $A$ is considered in terms of a function concept, then $A \\in \\mathbb{R}^{m \\times n}$ corresponds to function $T_{A}$, which can also be seen as $T_{A} : \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$.\nThe following Rank-Nullity Theorem is also easier to understand when thought of in terms of a function concept. Don\u0026rsquo;t forget that it is $\\text{rank} A = \\text{rank} A^{T}$.\nRank-Nullity Theorem For matrix $A \\in M_{ m \\times n }(\\mathbb{R})$, the following equation holds:\n$$ \\begin{align*} \\text{rank} (A) + \\text{nullity} (A) \u0026amp;= \\dim \\mathbb{R}^{n} = n \\\\ \\text{rank} (A^{T}) + \\text{nullity} (A^{T}) \u0026amp;= \\dim \\mathbb{R}^{m} = m \\end{align*} $$\nAlso known as the Dimension Theorem for matrices. When generalized for linear transformations, the following holds:\nFor vector space $V, W$ and linear transformation $T : V \\to W$, the following equation holds:\n$$ \\text{rank} (T) + \\text{nullity} (T) = \\dim (V) $$\nProof Let\u0026rsquo;s say $A$ is a $m \\times n$ matrix. Then, since there are $n$ columns in $A$, the homogeneous linear system $A \\mathbf{x} = \\mathbf{0}$ has $n$ unknowns. Therefore, \u0026rsquo;the number of leading variables + the number of free variables = $n$\u0026rsquo; holds. The number of leading variables is the same as the number of leading 1s, which is the same as the dimension of the row space. Moreover, the number of free variables is the same as the number of parameters, which is the same as the dimension of the null space. Therefore, the theorem holds.\n‚ñ†\nSee Also Kernel in Abstract Algebra The null space is denoted as $\\ker A$ and is also called Kernel. This is a specialized expression in linear algebra of the general concept of kernel dealt with in abstract algebra, and it is also seen as $A$ being viewed as a function.\nHoward Anton, Elementary Linear Algebra: Applications Version (12th Edition, 2019), p278\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3021,"permalink":"https://freshrimpsushi.github.io/en/posts/3021/","tags":null,"title":"Matrix Rank, Nullity"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition1 $$ A = \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\end{bmatrix} $$\nFor a matrix $A$, the $m$ number of $\\mathbb{R}^{n}$ vectors made from the rows of $A$\n$$ \\begin{align*} \\mathbf{r}_{1} =\u0026amp; \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\end{bmatrix} \\\\ \\mathbf{r}_{2} =\u0026amp; \\begin{bmatrix} a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\end{bmatrix} \\\\ \u0026amp;\\vdots \\\\ \\mathbf{r}_{m} =\u0026amp; \\begin{bmatrix} a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\end{bmatrix} \\end{align*} $$\nare called the row vectors of $A$. The $n$ number of $\\mathbb{R}^{m}$ vectors made from the columns of $A$\n$$ \\mathbf{c}_{1} = \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ \\vdots \\\\ a_{m1} \\end{bmatrix},\\quad \\mathbf{c}_{2} = \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ \\vdots \\\\ a_{m2} \\end{bmatrix},\\quad \\dots,\\quad \\mathbf{c}_{n} = \\begin{bmatrix} a_{1n} \\\\ a_{2n} \\\\ \\vdots \\\\ a_{mn} \\end{bmatrix} $$\nare called the column vectors of $A$.\n$$ \\begin{align*} A =\u0026amp; \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\cdots \u0026amp; a_{mn} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{r}_{1} \\\\ \\mathbf{r}_{2} \\\\ \\vdots \\\\ \\mathbf{r}_{m} \\end{bmatrix} \\\\ =\u0026amp; \\begin{bmatrix} \\mathbf{c}_{1} \u0026amp; \\mathbf{c}_{2} \u0026amp; \\cdots \u0026amp; \\mathbf{c}_{n} \\end{bmatrix} \\end{align*} $$\nThe $\\mathbb{R}^{n}$ subspace generated by the row vectors $\\mathbf{r}_{1}, \\mathbf{r}_{2},\\dots,\\mathbf{r}_{m}$ of $A$ is called the row space of $A$ and is denoted as follows.\n$$ \\mathcal{R} (A) \\quad \\text{or} \\quad \\text{row}(A) $$\nThe $\\mathbb{R}^{m}$ subspace generated by the column vectors $\\mathbf{c}_{1}, \\mathbf{c}_{2},\\dots,\\mathbf{c}_{n}$ of $A$ is called the column space of $A$ and is denoted as follows.\n$$ \\mathcal{C} (A) \\quad \\text{or} \\quad \\text{col}(A) $$\nThe set of solutions to the homogeneous system of linear equations $A \\mathbf{x} =\\mathbf{0}$ is called the null space of $A$ and is denoted as follows.\n$$ \\mathcal{N}(A) \\quad \\text{or} \\quad \\text{null}(A) $$\nExplanation Such concepts were devised to solve\n$$ \\begin{equation} A\\mathbf{x} = \\mathbf{b} \\end{equation} $$\nsystems of linear equations. That is, in linear algebra, there is interest in the relationship between the solutions of $(1)$ and the row space, column space, and null space of $A$. In particular, finding the basis of the row space is related to solving linear systems. Specifically, the dimension of the row space and column space is called the rank, and the dimension of the null space is called the nullity.\nNote that the column space is also called the image. If one considers the matrix $A$ as a concept of a function, then the function corresponding to $A \\in \\mathbb{R}^{m \\times n}$ can also be seen as $T_{A} : \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$.\nTheorem 1 A necessary and sufficient condition for the linear system $A \\mathbf{x} = \\mathbf{b}$ to have a solution is $\\mathbf{b} \\in \\mathcal{C}(A)$.\nTheorem 2 Let $\\mathbf{x}_{0}$ be some solution to $A\\mathbf{x} = \\mathbf{b}$. Let us call $S= \\left\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{k} \\right\\}$ a basis for $\\mathcal{N}(A)$. Then, all solutions of $A\\mathbf{x} = \\mathbf{b}$ can be expressed as follows.\n$$ \\begin{equation} \\mathbf{x} = \\mathbf{x}_{0} + c_{1}\\mathbf{v}_{1} + c_{2}\\mathbf{v}_{2} + \\cdots + c_{k}\\mathbf{v}_{k} \\end{equation} $$\nConversely, for all constants $c_{1}, c_{2}, \\dots, c_{k}$, the above $\\mathbf{x}$ is a solution to $A\\mathbf{x} = \\mathbf{b}$.\n$(2)$ is called the general solution of $A \\mathbf{x} = \\mathbf{b}$. $\\mathbf{x}_{0}$ is called the particular solution of $A \\mathbf{x} = \\mathbf{b}$. Furthermore, $c_{1}\\mathbf{v}_{1} + c_{2}\\mathbf{v}_{2} + \\cdots + c_{k}\\mathbf{v}_{k}$ is called the general solution of $A \\mathbf{x} = \\mathbf{0}$.\nFrom these theorems, it can be understood that the general solution of a nonhomogeneous linear system can be represented as the sum of a particular solution and the general solution of the homogeneous linear system.\nSee Also Kernel in Abstract Algebra The null space is written as $\\ker A$ and also called the kernel. This is because it is a specialization of the general concept of kernel discussed in abstract algebra, seeing $A$ as a function.\nHoward Anton, Chris Rorres, Anton Kaul, Elementary Linear Algebra: Applications Version(12th Edition). 2019, p263-267\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":254,"permalink":"https://freshrimpsushi.github.io/en/posts/254/","tags":null,"title":"Row Space, Column Space, Null Space"},{"categories":"Î¨ºÎ¶¨Ìïô","contents":"Definition The line that represents the track of a particle in space and time is called a world line.\nDescription Let\u0026rsquo;s think only about a coordinate system moving at a constant speed in one direction. In the $A$ coordinate system, there is a particle at rest at the origin. The world line of this particle is as follows.\nAnd there is a $A^{\\prime}$ coordinate system moving at a speed of $v_{0}$ in the $+x$ direction relative to the $A$ coordinate system.\nWhen observing the motion of the same particle from the $A^{\\prime}$ coordinate system, the world line is as follows.\nSince the $A^{\\prime}$ system moves only in the $x$ direction, the value of $y, z$ does not change. That is, it is as follows.\n$$ \\begin{align*} t^{\\prime}\u0026amp;= t \\\\ x^{\\prime} \u0026amp;= -v_{0}t \\\\ y^{\\prime} \u0026amp;= 0 \\\\ z^{\\prime} \u0026amp;= 0 \\end{align*} $$\nIf one considers the particle to be stationary at an arbitrary point $P(x,y,z,)$, it is as follows.\n$$ \\begin{align*} t^{\\prime} \u0026amp;= t \\\\ x^{\\prime} \u0026amp;= x-v_{0}t \\\\ y^{\\prime} \u0026amp;= y \\\\ z^{\\prime} \u0026amp;= z \\end{align*} $$\nThen, the following equation holds true between the two coordinate systems in space-time, which is called the Galilean transformation.\n$$ \\begin{pmatrix} t^{\\prime} \\\\ x^{\\prime} \\\\ y^{\\prime} \\\\ z^{\\prime} \\end{pmatrix} = \\begin{pmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ -v_{0} \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix} \\begin{pmatrix} t \\\\ x \\\\ y \\\\ z \\end{pmatrix} = \\begin{pmatrix} t \\\\ x-v_{0}t \\\\ y \\\\ z \\end{pmatrix} $$\nOne can observe the following characteristics of the Galilean transformation:\nTime is absolute and unchanging between the two coordinate systems. The speed of the particle differs by the speed difference between the two coordinate systems. Furthermore, there is no difference in speed in the direction that the coordinate system does not move. Mathematically, it is expressed as follows. $$ \\begin{align*} t^{\\prime} \u0026amp;= t \\\\ v_{x}^{\\prime} \u0026amp;= v_{x}-v_{0} \\\\ v_{y}^{\\prime} \u0026amp;= v_{y} \\\\ v_{z}^{\\prime}\u0026amp;= v_{z} \\end{align*} $$ See Also [Lorentz Transformation] Galilean transformation is a transformation equation that does not consider the effects of relativity. When the speed is not close to the speed of light, this approximation matches reality quite well. However, as it approaches the speed of light, one must consider the effects of relativity, and the expression reflecting this is the Lorentz transformation.\n","id":250,"permalink":"https://freshrimpsushi.github.io/en/posts/250/","tags":null,"title":"World Line and Galilean Transformation"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Definition Let\u0026rsquo;s define a complex number as $z$ with $z=a+ib(a,b\\in \\mathbb{R})$.\n$\\overline{z}$ is defined as follows and is called the Complex Conjugate of $z$. $$ \\overline{z}:=\\overline{a+ib}=a-ib $$\nExplanation It can be explained as substituting $-i$ for $i$ in the original complex number, and as a reflection across the real axis on the complex plane. The term conjugate seems to be named because it forms a pair that produces a real number when added together. Conjugate complex numbers are one of the first concepts encountered when studying complex analysis, but they often neglect to study it as there seems to be no immediate use for it. However, it is important to master these properties through repetition rather than just learning them. Usually, since these are not mentioned in books after [5], it\u0026rsquo;s a good idea to learn them at the shrimp sushi place and take advantage of them.\nProperties Let\u0026rsquo;s define as $z_{1}$, $z_{2}$, $z \\in \\mathbb{C}$. Then, the following equations hold.\n[1]: $(z+\\overline{z}) = 2 \\Re(z) \\in \\mathbb{R}$ [2]: $\\overline{z_{1} + z_{2}} = \\overline{z_{1}} + \\overline{z_{2}}$ [3]: $\\overline{z_{1} z_{2}} = \\overline{z_{1}} \\cdot \\overline{z_{2}}$ [4]: $\\overline{ \\overline{z} } = z$ [5]: $z \\overline{z} = |z|^2$ [6]: $\\overline{ \\left( { \\dfrac{1}{z} } \\right) } = \\dfrac{1}{\\overline{z}}$ [7]: $\\overline{ \\left( \\dfrac{z_{1}}{z_{2}} \\right) } = \\dfrac{\\overline{z_{1}}}{\\overline{z_{2}}}$ [8]: $\\overline{ \\sin{ z } } = \\sin{\\overline{z}}$ [9]: $\\overline{ \\cos{ z } } = \\cos{\\overline{z}}$ [10]: $\\overline{ e^{ z } } = e^{\\overline{z}}$ [11]: $\\overline{ \\cosh{z} } = e^{\\overline{z}}$ [12]: $\\overline{ \\tan{ z } } = \\tan{\\overline{z}}$ Proof Before proving, let\u0026rsquo;s define variables as $z_{1} = x_{1} + i y_{1}$, $z_{2} = x_{2} + i y_{2}$, $z = x + i y$.\n[1] Because of $$ z +\\overline{z} = (x+iy)+(x-iy) = 2x $$,\n$(z+\\overline{z})=2x\\in \\mathbb{R}$ is true.\n‚ñ†\n[2] Because of $$ \\begin{align*} \\overline{z_{1} + z_{2}} =\u0026amp; \\overline{ ( x_{1} + i y_{2} ) + ( x_{2} + i y_{2} ) } \\\\ =\u0026amp; \\overline{ ( x_{1} + x_{2} ) + i ( y_{1} + y_{2} ) } \\\\ =\u0026amp; ( x_{1} + x_{2} ) - i ( y_{1} + y_{2} ) \\\\ \u0026amp;=(x_{1} - i y_{1}) + (x_{2} - i y_{2}) \\\\ =\u0026amp; \\overline{z_{1}} + \\overline{z_{2}} \\end{align*} $$,\n‚ñ†\n[3] Because of $$ \\begin{align*} \\overline{z_{1} z_{2}} =\u0026amp; \\overline{ ( x_{1} + i y_{1} ) ( x_{2} + i y_{2} ) } \\\\ =\u0026amp; \\overline{( x_{1} x_{2} - y_{1} y_{2} ) + i ( x_{1} y_{2} + y_{1} x_{2} )} \\\\ =\u0026amp; ( x_{1} x_{2} - y_{1} y_{2} ) - i ( x_{1} y_{2} + y_{1} x_{2} ) \\\\ =\u0026amp; ( x_{1} - i y_{1} ) ( x_{2} - i y_{2} ) \\\\ =\u0026amp; \\overline{( x_{1} + i y_{1} )} \\ \\overline{( x_{2} + i y_{2} )} \\\\ =\u0026amp; \\overline{z_{1}} \\cdot \\overline{z_{2}} \\end{align*} $$,\n‚ñ†\n[4] Because of $$ \\overline{ \\overline{ z } } = \\overline{ x - i y } = x + i y =z $$,\n‚ñ†\n[5] Because of $$ z \\overline{z} = (x + iy ) ( x - i y )= x^2 + y^2 =|z|^2 $$,\n‚ñ†\n[6] Because of $$ \\overline{ \\left( { {1} \\over {z} } \\right) } = \\overline{ \\left( {1} \\over { x + iy } \\right) } = \\overline{{x - i y} \\over {x ^ 2 + y^2 }} = {{x + i y} \\over {x ^ 2 + y^2 }} = {{1} \\over {x - i y }} = {{1} \\over { \\overline{z} }} $$,\n‚ñ†\n[7] Because of [3], [6], $$ \\overline{ \\left( { {z_{1}} \\over { z_{2} } } \\right) } = \\overline{ z_{1} { {1} \\over { z_{2} } }}=\\overline{z_{1}}\\cdot \\overline{ \\left( {1} \\over { z_{2} } \\right) } = \\overline{z_{1}}\\cdot { 1 \\over \\overline{z_{2}} } = {{\\overline{z_{1}}} \\over { \\overline{z_{2}} }} $$ ‚ñ†\n[8] [9] The proofs for [8] and [9] are essentially the same, so the proof for [9] is omitted.\n$$ \\begin{align*} \\overline{ \\sin{ z } } =\u0026amp; \\overline{\\sin{(x+ i y)}} \\\\ =\u0026amp; \\overline{ \\sin{x} \\cosh{y} - i \\cos{x} \\sinh{y} } \\\\ =\u0026amp; { \\sin{x} \\cosh{y} + i \\cos{x} \\sinh{y} } \\\\ =\u0026amp; \\sin{(x-iy)} \\\\ =\u0026amp; \\sin{ \\overline{z} } \\end{align*} $$\n‚ñ†\n[10] By the Euler‚Äôs formula, the following holds.\n$$ \\overline{e^z} = \\overline{\\cos{x} + i \\sin{y}} = \\cos{x} - i \\sin{y} =e^{\\overline{z}} $$\n‚ñ†\n[11] Because of [7], [10],\n$$ \\overline{\\cosh{z}} = \\overline{\\left( \\dfrac{e^{z} + e^{-z}}{2} \\right)} = \\dfrac{ e^{\\overline{z}} + e^{-\\overline{z}} } {2} = \\cosh\\overline{z} $$\n‚ñ†\n[12] Because of [7], [8], [9],\n$$ \\overline{ \\tan{z} } = \\overline{ \\left( { \\sin{z} } \\over { \\cos{z} }\\right) } = {{ \\overline{\\sin{z}} } \\over { \\overline{\\cos{z}} }} = {{ \\sin{ \\overline{z} } } \\over { \\cos { \\overline{z} } }} = \\tan{ \\overline{z} } $$\n‚ñ†\nSupplementary As you can see from the proof process, [11] can also be applied to other hyperbolic functions. It\u0026rsquo;s not that only those functions are important enough to warrant their proof separately, but to just show that such good properties can easily be derived. The same goes for trigonometric functions, so try it out for yourself.\n[13]: $\\dfrac{1 + i}{1 - i } = i$ [14]: $\\dfrac{1 - i}{1 + i } = -i$ [15]: $\\dfrac{1}{i } = -i$ [16]: $i \\cdot (- i ) = 1$ Though not exactly a formula, these calculations with imaginary numbers are used very frequently and mastering them can drastically reduce the amount of calculation required. Especially, [15] is very useful in situations where reducing or multiplying both sides by an imaginary number is involved.\n","id":245,"permalink":"https://freshrimpsushi.github.io/en/posts/245/","tags":null,"title":"Conjugate Complex Number"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Moment of Inertia $$ \\begin{align*} I \u0026amp;= \\sum_{i} m_{i} {r_{i}}^2 \\\\ I \u0026amp;= \\int r^2 dm \\end{align*} $$\nThe moment of inertia is defined as the (mass of a particle)$\\times$(distance from the rotation axis to the particle) and represents the physical quantity that indicates the characteristic of a body to continue rotating. Its symbol is $I$, which seems to be derived from the initial letter of the English word Inertia. The unit is $[kg \\cdot m^2]$. It can be considered to play a similar role to mass in translational motion. That is, when the angular momentum $L=I \\omega $ is constant, the greater the moment of inertia, the smaller the angular velocity becomes. When there are multiple particles, the moment of inertia of the particle system is calculated by adding up the moments of inertia of each particle. For a body with continuously distributed mass points, it is calculated using integration.\nRadius of Gyration When the moment of inertia is divided by the total mass, the average value of the squared distance from the rotation axis is obtained. This is referred to as the radius of gyration and is denoted by $k$.\n$$ k=\\sqrt{\\frac{I}{m}} $$\n","id":234,"permalink":"https://freshrimpsushi.github.io/en/posts/234/","tags":null,"title":"Inertia Moment and Turning Radius"},{"categories":"Ìï®Ïàò","contents":"Definition A function $g$, represented in the form such as $$ g(x) =\\sum \\limits _{n=0}^{\\infty}a_{n}x^{n}= a_{0} + a_{1} x + a_{2} x^2 + \\cdots $$ for a given sequence $\\left\\{ a_{n} \\right\\}$, is called the generating function of the sequence $\\left\\{ a_{n}\\right\\}$ or simply generating function. When the sequence is $a_{n}=a_{n}(x)$, it is also denoted as follows: $$ G(x,t)=\\sum \\limits _{n=0}^{\\infty}a_{n}(x)t^{n} $$\nExplanation As sharp readers may have noticed, the Taylor series also takes a similar form. Even those who are not as sharp may have encountered a similar form called \u0026lsquo;power series\u0026rsquo; during their high school years. This is because it is very suitable for exam questions to check if one has a mathematical understanding of the process of finding the sum of arithmetic and geometric sequences.\nHistorically, the term \u0026lsquo;generating function\u0026rsquo; is known to have been named by Laplace. After differentiating both sides by $n$ times and substituting $x=0$, it results in $g^{(n)} (x) = a_{n} n!$, hence $\\displaystyle a_{n} = {{g^{(n)} (x) } \\over {n!}}$ can be determined. In that sense, a generating function can be thought of as a function that can restore or \u0026lsquo;generate\u0026rsquo; the original given sequence.\nA special case is the Maclaurin series $\\displaystyle f(x) = \\sum_{n=0}^{\\infty} {{f^{(n)} (0)}\\over{n!}} {x}^n$ as mentioned earlier. The Maclaurin series explicitly takes the sequence $a_{n}$ as the $n$ th derivative of the given function.\nIn the case of $1 = a_{0} = a_{1} = a_{2} = \\cdots$, where all the coefficients of the terms are 1, this happily becomes the infinite geometric series $$ g(x) = 1 + x + x^2 + \\cdots = {{1} \\over {1-x}} $$ On the other hand, in the case of $a_{n} = n+1$, which is the sequence of natural numbers, it is the same as differentiating both sides of $\\displaystyle g(x) = {{1} \\over {1-x}}$ by $x$. The result is, of course, as follows: $$ g ' (x) = 1 + 2 x + 3 x^2 + \\cdots = {{1} \\over {(1-x)^2 }} $$ Research on generating functions may seem utterly useless at first glance, but it is widely used in various applied mathematics, including statistics, as it is generalized to power functions. (Surprisingly, Euler had been using it to solve problems in analysis and number theory even before this term was coined.)\n","id":232,"permalink":"https://freshrimpsushi.github.io/en/posts/232/","tags":null,"title":"What is a Generating Function?"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Theorem 1 $n$th degree polynomial $P(x) = a_{0} + a_{1} x + a_{2} x^2 + \\cdots + a_{n} x^{n}$ has exactly $n$ roots, including multiple roots.\nExplanation In fact, when we solve a polynomial, we usually assume that there exists a solution, but there\u0026rsquo;s no guarantee that this is always the case. For example, the quadratic polynomial $x^2+1 = 0$ does not have real roots. However, if complex numbers are allowed, then there are two solutions, which are $\\pm i$.\nTo state a fact, if complex roots are allowed when solving a polynomial, then there will always be a solution, and exactly as many as its degree. The importance of all fundamental theorems is evident without further ado. The core idea is Liouville\u0026rsquo;s theorem, and mathematical induction is used to generalize it for natural numbers $n$.\nProof Let\u0026rsquo;s assume first that there is no solution satisfying $P(z) = 0$, then $\\displaystyle {{1} \\over {P(z)}}$ is an entire function and since $\\displaystyle \\lim_{|z| \\to \\infty} \\left| {{1} \\over {P(z)}} \\right| = 0$, it is bounded.\nLiouville\u0026rsquo;s Theorem: If $f$ is an entire function and bounded, then $f$ is a constant function.\nBy Liouville\u0026rsquo;s theorem, $P$ must be a constant function, which contradicts our assumption; therefore, $P(z) = 0$ has at least one root.\nNow, let\u0026rsquo;s generalize for the natural numbers. Assuming that $P(z) = 0$ has at least one root, let\u0026rsquo;s say $z = \\alpha$, then $$ P(z) = (z-\\alpha) Q(z) $$ where $Q(z) = b_{0} + b_{1} x + b_{2} x^2 + \\cdots + b_{n-1} x^{n-1} = 0$ also has at least one root. Repeating this process, by mathematical induction, $n$th degree polynomial $P(z) = 0$ has exactly $n$ roots.\n‚ñ†\nSee Also Fundamental Theorem of Algebra expressed in terms of Abstract Algebra Osborne (1999). Complex variables and their applications: p94.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":223,"permalink":"https://freshrimpsushi.github.io/en/posts/223/","tags":null,"title":"Proof of the Fundamental Theorem of Algebra"},{"categories":"ÍµêÍ≥ºÍ≥ºÏ†ï","contents":"Theorem $$ (x+y)^{n} = \\sum_{r=0}^{n} {_n C _r} x^{r} y^{n-r} $$ Here, ${_n C _r}$ is defined as the Binomial Coefficient. $$ {_n C _r} = \\binom{n}{r} = {{ n! } \\over { r ! (n-r)! }} $$\nDescription It‚Äôs surprisingly useful right after you learn it in high school. Because of its versatility, it allows for the derivation of many formulas quickly and is widely used across various fields.\nProof When expanding $(x+y)^{n}$, the coefficient of $x^{r} y^{n-r}$ is $$ (x+y)^{n} = (x+y)(x+y)(x+y) \\cdots (x+y) $$ equivalent to selecting $x$ of $(x+y)$ $n$ times and $y$ $n-r$ times respectively. Therefore, the combination $_n C _r$ becomes the coefficient of $x^{r} y^{n-r}$, $$ (x+y)^{n} = \\sum_{r=0}^{n} {_n C _r} x^{r} y^{n-r} $$\n‚ñ†\n","id":218,"permalink":"https://freshrimpsushi.github.io/en/posts/218/","tags":null,"title":"Binomial Theorem Proof"},{"categories":"Î≥¥Ï°∞Ï†ïÎ¶¨","contents":"Theorem The Gaussian function $f(x) := e^{-x^2}$\u0026rsquo;s integral over the entire domain is as follows.\n$$ \\int_{-\\infty}^{\\infty} e^{-x^2} dx= \\sqrt{\\pi} $$\nDescription Physicist Kelvin is said to have left the remark that \u0026ldquo;one who finds this integral obvious is a mathematician\u0026rdquo;. It is also known by other names such as Gaussian integral, or Euler-Poisson integral.\nIt\u0026rsquo;s a shocking integration for high school students and especially crucial for statistics. That\u0026rsquo;s because, while you can\u0026rsquo;t find a primitive function within the high school curriculum rendering the calculation impossible, the probability of normal distribution is tacitly used in the statistics part.\nProof Strategy: Create $x$ and $y$ independent of each other, then convert to polar coordinates to turn it into an integral over a closed interval. There is a method said to be understandable at a high school level, through the Pappus-Guldin theorem, to prove by calculating the volume of solids of revolution, but essentially, this proof is the same and includes improper integrals, making it difficult to be deemed as high school level.\nIf we denote by $\\displaystyle I = \\int_{-\\infty}^{\\infty} e^{-x^2} dx$ then it can also be represented by $\\displaystyle I = \\int_{-\\infty}^{\\infty} e^{-y^2} dy$. Since $x$ and $y$ are independent,\n$$ \\begin{align*} I^2 =\u0026amp; \\int_{-\\infty}^{\\infty} e^{-x^2} dx \\int_{-\\infty}^{\\infty} e^{-y^2} dy \\\\ =\u0026amp; \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} e^{-( x^2 + y^2 ) } dxdy \\end{align*} $$\nConverting to polar coordinates,\n$$ \\begin{align*} I^2 =\u0026amp; \\int_{0}^{2 \\pi} \\int_{0}^{\\infty} e^{-r^2 } r dr d\\theta \\\\ =\u0026amp; \\int_{0}^{2 \\pi} \\left[ {{-e^{-r^2}} \\over {2}}\\right]_{0}^{\\infty} d\\theta \\\\ =\u0026amp; \\int_{0}^{2 \\pi} {{1} \\over {2}} d\\theta \\\\ =\u0026amp; \\pi \\end{align*} $$\nTherefore,\n$$ I =\\sqrt{\\pi} $$\n‚ñ†\nCorollary Improper integral over a half-line $$ \\int_{0}^{\\infty} e^{-x^2} dx= {{\\sqrt{\\pi}} \\over {2}} $$\nIf the integration range is from $0$ to $\\infty$, polar coordinates can\u0026rsquo;t be used. However, looking at the shape of the Gaussian function, one can guess without calculating that it would be halved for $x=0$ since it is an even function, but since it\u0026rsquo;s an improper integral over an infinitely long range, let\u0026rsquo;s verify it accurately.\nProof $$ \\int_{0}^{\\infty} e^{-x^2} dx $$\nBy substituting like $x :=-y$,\n$$ x \\rightarrow 0,\\ y \\rightarrow 0 \\\\ x \\rightarrow \\infty,\\ y \\rightarrow -\\infty \\\\ x^2=y^2 $$\nSince $dx=-dy$,\n$$ \\int_{0}^{\\infty} e^{-x^2} dx = -\\int_{0}^{-\\infty} e^{-y^2} dy=\\int_{-\\infty}^{0} e^{-y^2} dy $$\nThe integration variable does not affect the definite integral, so it can be written as $\\displaystyle \\int_{-\\infty}^{0} e^{-y^2} dy=\\int_{-\\infty}^{0} e^{-x^2} dx$, and therefore,\n$$ \\int_{0}^{\\infty} e^{-x^2} dx + \\int_{-\\infty}^{0} e^{-x^2} dx= 2\\int_{0}^{\\infty} e^{-x^2} dx=\\int_{-\\infty}^{\\infty} e^{-x^2} dx $$\nUsing the above results,\n$$ \\int_{0}^{\\infty} e^{-x^2} dx=\\frac{1}{2}\\int_{-\\infty}^{\\infty} e^{-x^2} dx=\\frac{1}{2}\\sqrt{\\pi} $$\nGeneralization The following generalized formula is widely used.\n$$ \\int_{-\\infty}^{\\infty} e^{-\\alpha x^2} dx= \\sqrt{\\dfrac{\\pi}{\\alpha}} $$\nSee Also Generalization of Gaussian integral ‚ñ†\n","id":219,"permalink":"https://freshrimpsushi.github.io/en/posts/219/","tags":null,"title":"Definite Integration of the form e^-x^2, Gaussian Integral, Euler-Poisson Integral"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Theorem 1 Let the complex function $f: A \\subseteq \\mathbb{C} \\to \\mathbb{C}$ be analytic in a simply connected region $\\mathscr{R}$.\nIf a simple closed path $\\mathscr{C} \\subset \\mathscr{R}$ contained in $\\mathscr{R}$ surrounds a point $\\alpha$, then the following holds: $$ f(\\alpha) = {{1} \\over {2 \\pi i }} \\int_{\\mathscr{C}} {{f(z)} \\over { z - \\alpha }} dz $$\nDerivation First, let\u0026rsquo;s show that $\\displaystyle 2 \\pi i = \\int_{\\mathscr{C} '} {{1} \\over { z - \\alpha }} dz$.\nContraction auxiliary lemma of complex path integrals: For a circle $\\mathscr{C} '$ centered at $\\alpha$ inside $\\mathscr{C}$, $$\\int_{\\mathscr{C}} f(z) dz = \\int_{\\mathscr{C} '} f(z) dz$$\nContracting the integration interval of $\\displaystyle \\int_{\\mathscr{C}} {{1} \\over { z - \\alpha }} dz$ to the circle $\\mathscr{C} ': | z - \\alpha | = \\rho$ results in $z(\\theta) = \\rho e^{i \\theta} + \\alpha, -\\pi \\le \\theta \\le \\pi$, so $$ \\int_{\\mathscr{C} '} {{1} \\over { z - \\alpha }} dz = \\int_{-\\pi}^{\\pi} {{ i \\rho e^{i \\theta}} \\over { \\rho e^{i \\theta} }} d\\theta = 2 \\pi i $$ Now, setting $\\displaystyle I = \\int_{\\mathscr{C}} {{f(z)} \\over { z - \\alpha }} dz$ and calculating $I$ gives $$ \\begin{align*} \\int_{\\mathscr{C}} {{f(z)} \\over { z - \\alpha }} dz =\u0026amp; \\int_{\\mathscr{C} '} {{f(\\alpha)} \\over { z - \\alpha }} dz + \\int_{\\mathscr{C} '} {{f(z) - f(\\alpha)} \\over { z - \\alpha }} dz \\\\ =\u0026amp; f(\\alpha) \\int_{\\mathscr{C} '} {{1} \\over { z - \\alpha }} dz + \\int_{\\mathscr{C} '} {{f(z) - f(\\alpha)} \\over { z - \\alpha }} dz \\\\ =\u0026amp; f(\\alpha) 2 \\pi i + \\int_{\\mathscr{C} '} {{f(z) - f(\\alpha)} \\over { z - \\alpha }} dz \\end{align*} $$ Demonstrating that $\\displaystyle \\int_{\\mathscr{C} '} {{f(z) - f(\\alpha)} \\over { z - \\alpha }} dz = 0$ completes the proof.\n$f(z)$ being differentiable in $z = \\alpha$ means that for some $M\u0026gt;0$, $$ \\left| {{f(z) - f(\\alpha)} \\over { z - \\alpha }} \\right| \\le M $$ Since $\\mathscr{C} ' : | z - \\alpha | = \\rho$, the length of $\\mathscr{C} '$ is $2 \\pi \\rho$.\nML auxiliary lemma: For a positive number $M$ that satisfies $|f(z)| \\le M$ and the length of $\\mathscr{C}$, $L$, $$ \\left| \\int_{\\mathscr{C}} f(z) dz \\right| \\le ML $$\nAccording to the ML auxiliary lemma, $$ \\left| \\int_{\\mathscr{C} '} {{f(z) - f(\\alpha)} \\over { z - \\alpha }} dz \\right| \\le 2 \\pi \\rho M $$ Now, if we continuously use the contraction auxiliary lemma of complex path integrals around $z = \\alpha$, think $$\\mathscr{C}_n : | z - \\alpha | = \\rho_n \\\\ \\mathscr{C}_{n+1} : | z - \\alpha | = \\rho_{n+1} \\\\ \\rho_{n} \u0026gt; \\rho_{n+1} $$ then, when $n \\to \\infty$, it is $\\rho_{n} \\to 0$. For all $\\rho_{n} \u0026gt;0$, $$ \\left| \\int_{\\mathscr{C}_{n}} {{f(z) - f(\\alpha)} \\over { z - \\alpha }} dz \\right| \\le 2 \\pi \\rho_{n} M $$ thus, $$ \\left| \\int_{\\mathscr{C} '} {{f(z) - f(\\alpha)} \\over { z - \\alpha }} dz \\right| = 0 $$ Finally, we obtain the following: $$ \\int_{\\mathscr{C}} {{f(z)} \\over { z - \\alpha }} dz = f(\\alpha) 2 \\pi i $$\n‚ñ†\nDescription It\u0026rsquo;s the formula that makes the blind see and the lame walk. The mathematical beauty is indescribable, and its usefulness is so profound that its impact is almost beyond measure. Especially regarding integration, it is often called the flower of complex analysis because of the incessant outpouring of rich mathematical results.\nCorollary Meanwhile, the Cauchy integral formula can be generalized for the $n$th derivative. Except for using mathematical induction for the generalization, the proof fundamentally does not differ from that of the Cauchy integral formula. This formula is useful in itself but harbors even more significant implications.\nGeneralization of Cauchy Integral Formula for Derivatives Let the function $f: A \\subseteq \\mathbb{C} \\to \\mathbb{C}$ be analytic in a simply connected region $\\mathscr{R}$.\nIf a simple closed path $\\mathscr{C} \\subset \\mathscr{R}$ contained in $\\mathscr{R}$ surrounds a point $\\alpha$, then for a natural number $n$, the following holds: $$ f^{(n)} (\\alpha) = {{n!} \\over {2 \\pi i }} \\int_{\\mathscr{C}} {{f(z)} \\over { (z - \\alpha)^{n+1} }} dz $$\nHowever, while reading the conditions, there\u0026rsquo;s no mentioning that $f$ needs to be differentiable multiple times, yet it uses the $n$th derivative. This means, in complex analysis, a function that is differentiable once is infinitely differentiable. This is guaranteed during the proof process and is a very powerful advantage, which cannot be easily assured in real functions. Thus, complex analysis enables the derivation of incredible mathematical results, as it dismantles various limitations, whether in differentiation or integration.\nInfinite Differentiability 2 The derivative of an analytic complex function is analytic. In other words, if $f$ is analytic in $z \\in \\mathbb{C}$, then for all $n \\in \\mathbb{N}$, the $n$th order derivative $f^{(n)}$ is also analytic in $z$.\nOsborne (1999). Complex variables and their applications: p87~89.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOsborne (1999). Complex variables and their applications: p91.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":215,"permalink":"https://freshrimpsushi.github.io/en/posts/215/","tags":null,"title":"Cauchy's Integral Formula Derivation"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem If a function $f$ is continuous on a closed interval $[a,b]$, there exists at least one $c$ in $(a,b)$ that satisfies $\\displaystyle f(c) = {{1}\\over {b-a} } \\int_{a}^{b} f(x) dx$.\nDescription Similar to the Mean Value Theorem but as it is used for integration, it is named as such. The usage is very similar, and its utility is by no means inferior to the Mean Value Theorem. On the other hand, considering defining the average value of a function as on the right side makes this theorem more likely to be the mean value theorem, and the widely known Mean Value Theorem might be more appropriately called the \u0026lsquo;mean value theorem for derivatives\u0026rsquo;.\nProof Strategy: The continuity of $f$ is assumed, thus we use both the Extreme Value Theorem and the Intermediate Value Theorem.\nSince $f$ is continuous on $[a,b]$, and by the Extreme Value Theorem, the minimum value $m$ and maximum value $M$ exist, then\n$$ \\int_{a}^{b} m dx \\le \\int_{a}^{b} f(x) dx \\le \\int_{a}^{b} M dx $$\n$$ \\implies m \\le {{1}\\over {b-a} } \\int_{a}^{b} f(x) dx \\le M $$\nOnce again, as $f$ is continuous on $[a,b]$, by the Intermediate Value Theorem, for $m$ and $M$, there exists at least one $c$ between $a$ and $b$ that satisfies $f(c) = \\displaystyle {{1}\\over {b-a} } \\int_{a}^{b} f(x) dx$ for $\\displaystyle {{1}\\over {b-a} } \\int_{a}^{b} f(x) dx$.\n‚ñ†\nLikewise, the same method can generalize to weighted $w$. The form introduced above is for $w(x) = 1$, and it is well covered by the theorem below as $\\displaystyle \\int_{a}^{b} dx = b - a$.\nCorollary If a function $f$ is continuous on a closed interval $[a,b]$ and $w(x) \\ge 0$ is integrable, then there exists at least one $\\xi$ in $(a,b)$ that satisfies $\\displaystyle \\int_{a}^{b} f(x) w(x) dx = f( \\xi ) \\int_{a}^{b} w(x) dx$.\nSee Also Mean Value Theorem Cauchy\u0026rsquo;s Mean Value Theorem Gauss\u0026rsquo;s Mean Value Theorem ","id":212,"permalink":"https://freshrimpsushi.github.io/en/posts/212/","tags":null,"title":"Mean Value Theorem for Integrals"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 Assume that the function $f$ is continuous on the closed interval $[a,b]$.\n(1) The function $\\displaystyle F(x) = \\int_{a}^{x} f(t) dt$ is continuous on $[a,b]$, differentiable on $(a,b)$, and satisfies $\\displaystyle {{dF(x)} \\over {dx}} = f(x)$.\n(2) For any antiderivative $F$ of $f$, $\\displaystyle \\int_{a}^{b} f(x) dx = F(b) - F(a)$\nExplanation Of course, we use the words differentiation and integration so we can easily guess the relationship between them. However, in English, they are called differential and integral, which seem totally unrelated, and even the concepts don\u0026rsquo;t really resemble each other.\nThe Fundamental Theorem of Calculus shows that differentiation and integration are, indeed, inverse operations of each other.\nProof (1) By the Mean Value Theorem of Integration, there exists $c$ between $x, x+h$ that satisfies $\\displaystyle f(c) = {{1} \\over {h}} \\int_{x}^{x+h} f(t) dt$.\nWhen $h \\to 0$, it becomes $c \\to x$, thus\n$$ \\lim_{h \\to 0} {{1} \\over {h}} \\int_{x}^{x+h} f(t) dt = \\lim_{h \\to 0} f(c) = f(x) $$\nMeanwhile, because of $\\displaystyle F(x+h) - F(x) = \\int_{a}^{x+h} f(t) dt - \\int_{a}^{x} f(t) dt = \\int_{x}^{x+h} f(t) dt$, it is also\n$$ {{1} \\over {h}} \\int_{x}^{x+h} f(t) dt = { {F(x+h) - F(x)} \\over {h} } $$\nTherefore,\n$$ \\lim_{h \\to 0} { {F(x+h) - F(x)} \\over {h} } = F ' (x) = f(x) $$\n‚ñ†\n(2) Since $F$ is an antiderivative of $f$, it follows $\\displaystyle \\int_{a}^{b} f(t) dt = F(b) + C$, thus\n$$ \\int_{a}^{a} f(t) dt = F(a) + C $$\nSubtracting the two sides from each other results in\n$$ \\int_{a}^{b} f(x) dx = F(b) - F(a) $$\n‚ñ†\nSee Also The Fundamental Theorem of Calculus in Analysis (1) The Fundamental Theorem of Calculus in Analysis (2) Basic Education College of Kyungpook National University, Mathematics for Engineers (2012), pp. 108-109\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":213,"permalink":"https://freshrimpsushi.github.io/en/posts/213/","tags":null,"title":"Proof of the Fundamental Theorem of Calculus"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Theorem 1 Let\u0026rsquo;s assume that $\\mathscr{C}$ is a simple closed path and $f: A \\subseteq \\mathbb{C} \\to \\mathbb{C}$ is analytic in its interior and $f '$ is continuous. Then, $$ \\int_{\\mathscr{C}} f(z) dz = 0 $$\nProof For $a \\le t \\le b$, $$ z(t) = x(t) + i y(t) \\\\ f(z) = u(x,y) + i v(x,y) $$ then since $\\displaystyle {{dz} \\over {dt}} = x ' + i y '$, $$ \\begin{align*} f(z)dz =\u0026amp; f(z) ( x ' + i y ' ) dt \\\\ =\u0026amp; (u + i v ) ( x ' + i y ' ) dt \\\\ =\u0026amp; (u x ' - v y ' ) + i (v x ' + u y ' ) dt \\end{align*} $$ and $\\displaystyle x ' = {{dx} \\over {dt}}$ and also because $\\displaystyle y ' = {{dy} \\over {dt}}$, $$ \\begin{align*} \\int_{\\mathscr{C}} f(z) dz =\u0026amp; \\int_{a}^{b} (u x ' - v y ' ) dt + i \\int_{a}^{b} (v x ' + u y ' ) dt \\\\ =\u0026amp; \\int_{\\mathscr{C}} (u dx - v dy ) + i \\int_{\\mathscr{C}} (v dx + u dy) \\end{align*} $$ here the condition that the derivative is continuous is used.\nGreen\u0026rsquo;s theorem: If $P,Q$ is continuous and its derivative is also continuous, then $$\\int_{\\mathscr{C}} (Pdx + Qdy) = \\iint_{S} (Q_{x} - P_{y}) dx dy$$\nAccording to Green\u0026rsquo;s theorem, $$ \\int_{\\mathscr{C}} f(z) dz = - \\iint_{S} (v_x + u_y) dxdy + i \\iint_{S} (u_x - v_y) dxdy $$ Meanwhile, $u,v$ are solutions satisfying the Cauchy-Riemann equations, so $u_y = -v_x$ and $u_x = v_y$. Hence, $$ \\int_{\\mathscr{C}} f(z) dz = 0 $$\n‚ñ†\nDescription This means that under certain conditions, it\u0026rsquo;s not necessary to calculate the definite integral at all. Cauchy is known as the \u0026lsquo;father of analysis\u0026rsquo;, and this theorem is extremely important, just as his name alone indicates. As you can see, fulfilling the conditions of function $f$ is not that difficult, so it can be utilized in many places.\nIt\u0026rsquo;s not only practical but also remarkably simple, so you can even appreciate the mathematical beauty.\nWhile dealing with derivatives and integrals, a rough interpretation of analysis was used. It\u0026rsquo;s synonymous in result, but rigorously it\u0026rsquo;s an incorrect process, so caution is needed.\nI introduce another useful theorem without proof.\nGeneralization The Cauchy-Goursat Theorem In a simply connected region $\\mathscr{R}$, if $f$ is analytic, for a simple closed path $\\mathscr{C}$ in the $\\mathscr{R}$ interior, $$ \\int_{\\mathscr{C}} f(z) dz = 0 $$\nThe French mathematician Goursat generalized this by eliminating the condition on the derivative of $f$. It\u0026rsquo;s a fact that it is more useful than Cauchy\u0026rsquo;s theorem, so make sure to remember it.\nSee also Cauchy\u0026rsquo;s Theorem in group theory Osborne (1999). Complex variables and their applications: p82.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":210,"permalink":"https://freshrimpsushi.github.io/en/posts/210/","tags":null,"title":"Proof of Cauchy's Theorem in Complex Analysis"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Theorem Let\u0026rsquo;s say the random variables $X_{1} , \\cdots , X_{n}$ are mutually independent.\n[1] Binomial distribution: If $X_i \\sim \\text{Bin} ( n_{i}, p)$, then $$ \\sum_{i=1}^{m} X_{i} \\sim \\text{Bin} \\left( \\sum_{i=1}^{m} n_{i} , p \\right) $$ [2] Poisson distribution: If $X_i \\sim \\text{Poi}( m_{i} )$, then $$ \\sum_{i=1}^{n} X_{i} \\sim \\text{Poi} \\left( \\sum_{i=1}^{n} m_{i} \\right) $$ [3] Gamma distribution: If $X_i \\sim \\Gamma ( k_{i}, \\theta)$, then $$ \\sum_{i=1}^{n} X_{i} \\sim \\Gamma \\left( \\sum_{i=1}^{n} k_{i} , \\theta \\right) $$ [4] Chi-squared distribution: If $X_i \\sim \\chi^2 ( r_{i} )$, then $$ \\sum_{i=1}^{n} X_{i} \\sim \\chi ^2 \\left( \\sum_{i=1}^{n} r_{i} \\right) $$ [5] Normal distribution: If $X_i \\sim N( \\mu_{i}, \\sigma_{i}^{2} )$, then for the given vector $(a_{1} , \\cdots , a_{n}) \\in \\mathbb{R}^{n}$, $$ \\sum_{i=1}^{n} a_{i} X_{i} \\sim N \\left( \\sum_{i=1}^{n} a_{i } \\mu_{i} , \\sum_{i=1}^{n} a_{i }^2 \\sigma_{i}^2 \\right) $$ Proof Strategy: Derive using the moment generating function. The condition that the variables are mutually independent is essential for applying the following theorem.\nIf $X_{1} , \\cdots , X_{n}$ are mutually independent and each has moment generating function of $M_{i}(t) \\qquad , -h_{i} \u0026lt; t \u0026lt; h_{i}$, then the moment generating function of their linear combination $\\displaystyle T := \\sum_{i=1}^{n} a_{i} X_{i}$ is $$ M_{T} (t) = \\prod_{i=1}^{n} M_{i} \\left( a_{i} t \\right) \\qquad , -\\text{min}_{i=1, \\cdots, n}^{n} h_{i} \u0026lt; t \u0026lt; \\text{min}_{i=1, \\cdots, n} h_{i} $$\n[1]1 Moment generating function of the binomial distribution: $$ m(t) = \\left[ (1-p) + pe^{t} \\right]^{n} \\qquad , t \\in \\mathbb{R} $$\nLet\u0026rsquo;s denote $\\displaystyle Y := \\sum_{i=1}^{m} X_{i}$, given that $X_{1} , \\cdots , X_{m}$ are mutually independent, $$ \\begin{align*} M_{Y} (t) =\u0026amp; M_{1} (t) \\cdots M_{m} (t) \\\\ =\u0026amp; \\left[ (1-p) + pe^{t} \\right]^{n_{1}} \\cdots \\left[ (1-p) + pe^{t} \\right]^{n_{m}} \\\\ =\u0026amp; \\left[ (1-p) + pe^{t} \\right]^{\\sum_{i=1}^{m} n_{i}} \\end{align*} $$ Therefore, $$ Y \\sim \\text{Bin} \\left( \\sum_{i=1}^{m} n_{i} , p \\right) $$\n‚ñ†\n[2]2 Moment generating function of the Poisson distribution: $$ m(t) = \\exp \\left[ \\lambda \\left( e^{t} - 1 \\right) \\right] \\qquad , t \\in \\mathbb{R} $$\nLet\u0026rsquo;s denote $\\displaystyle Y := \\sum_{i=1}^{n} X_{i}$, given that $X_{1} , \\cdots , X_{n}$ are mutually independent, $$ \\begin{align*} M_{Y} (t) =\u0026amp; M_{1} (t) \\cdots M_{n} (t) \\\\ =\u0026amp; \\exp \\left[ m_{1} \\left( e^{t} - 1 \\right) \\right] \\cdots \\exp \\left[ m_{n} \\left( e^{t} - 1 \\right) \\right] \\\\ =\u0026amp; \\exp \\left[ \\sum_{i=1}^{n} m_{i} \\left( e^{t} - 1 \\right) \\right] \\end{align*} $$ Therefore, $$ Y \\sim \\text{Poi} \\left( \\sum_{i=1}^{m} m_{i} \\right) $$\n‚ñ†\n[3]3 Moment generating function of the gamma distribution: $$ m(t) = \\left( 1 - \\theta t\\right)^{-k} \\qquad , t \u0026lt; {{ 1 } \\over { \\theta }} $$\nLet\u0026rsquo;s denote $\\displaystyle Y := \\sum_{i=1}^{n} X_{i}$, given that $X_{1} , \\cdots , X_{n}$ are mutually independent, $$ \\begin{align*} M_{Y} (t) =\u0026amp; M_{1} (t) \\cdots M_{n} (t) \\\\ =\u0026amp; \\left( 1 - \\theta t\\right)^{-k_{1}} \\cdots \\left( 1 - \\theta t\\right)^{-k_{n}} \\\\ =\u0026amp; \\left( 1 - \\theta t\\right)^{-\\sum_{i=1}^{n} k_{i}} \\end{align*} $$ Therefore, $$ Y \\sim \\Gamma \\left( \\sum_{i=1}^{n} k_{i} , \\theta \\right) $$\n‚ñ†\n[4]4 Relationship between gamma distribution and chi-squared distribution: $$ \\Gamma \\left( { r \\over 2 } , 2 \\right) \\iff \\chi ^2 (r) $$\nWith $\\displaystyle Y := \\sum_{i=1}^{n} X_{i}$ and if we denote $\\displaystyle \\sum_{i=1}^{n} k_{i} := {{ r_{i} } \\over { 2 }}$ and $\\theta := 2$, according to Theorem [3] $$ Y \\sim \\Gamma \\left( \\sum_{i=1}^{n} {{ r_{i} } \\over { 2 }} , 2 \\right) $$\n‚ñ†\n[5]5 Moment generating function of the normal distribution: $$ m(t) = \\exp \\left( \\mu t + {{ \\sigma^{2} t^{2} } \\over { 2 }} \\right) \\qquad , t \\in \\mathbb{R} $$\nLet\u0026rsquo;s denote $\\displaystyle Y := \\sum_{i=1}^{n} a_{i} X_{i}$, given that $X_{1} , \\cdots , X_{n}$ are mutually independent, $$ \\begin{align*} M_{Y} =\u0026amp; M_{1} (t) \\cdots M_{n} (t) \\\\ =\u0026amp; \\prod_{i=1}^{n} \\exp \\left[ t a_{i} \\mu_{i} + {{ t^{2} a_{i}^{2} \\sigma_{i}^{2} } \\over { 2 }} \\right] \\\\ =\u0026amp; \\exp \\left[ t \\sum_{i=1}^{n} a_{i} \\mu_{i} + {{ t^{2} \\sum_{i=1}^{n} a_{i}^{2} \\sigma_{i}^{2} } \\over { 2 }} \\right] \\end{align*} $$ Therefore, $$ Y \\sim N \\left( \\sum_{i=1}^{n} a_{i } \\mu_{i} , \\sum_{i=1}^{n} a_{i }^2 \\sigma_{i}^2 \\right) $$\n‚ñ†\nNote It\u0026rsquo;s important to note that technically, there\u0026rsquo;s no term for the addition of random variables. More precisely, it refers to a special case among linear combinations of random variables. Obviously, a stronger condition like iid makes it easier to identify their distribution.\nHogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p145.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p155.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p163.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p163.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHogg et al. (2013). Introduction to Mathematical Statistics (7th Edition): p176.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":202,"permalink":"https://freshrimpsushi.github.io/en/posts/202/","tags":null,"title":"Summation Summary of Random Variables Following a Specific Distribution"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition For a natural number $n \\in \\mathbb{N}$, the Cartesian product $\\mathbb{R}$ of the set of real numbers is called the Euclidean space.\n$$ \\mathbb{R}^{n} = \\mathbb{R} \\times \\cdots \\times \\mathbb{R} $$\n$\\mathbb{R}^{1}$ is referred to as real space or number line. $\\mathbb{R}^{2}$ is called a plane. $\\mathbb{R}^{3}$ is called a $3$-dimensional space. Here, $\\mathbb{N} := \\left\\{ 1, 2, 3, \\cdots \\right\\}$ means the set that includes all natural numbers. $\\mathbb{R}$ represents the set that includes all real numbers.\nExplanation The Euclidean space, named after Euclid, the author of Elements, is a space that describes not only our living $3$-dimensional space, including planes and number lines but also spaces of higher dimensions.\nBeing closely related to our lives, it is often assumed as the entire space in many theories. However, the Euclidean space alone cannot explain all the deep and profound theories of science and engineering and sometimes becomes a toy for pseudo-mathematicians and pseudo-scientists prolific on YouTube.\nThe extension to higher dimensions is necessary not necessarily for fancy purposes like being because of spacetime $\\mathbb{R}^{1+3}$ or string theory where $\\mathbb{R}^{11}$. For example, there are applications in statistics, and even if the space itself is $3$-dimensional, introducing speed and acceleration may require $9$ dimensions. If the reader is primarily interested in engineering or practical physics only, they might never need to venture beyond classical Euclidean space. Dreaming romantic notions from pop-science books without formulas and proofs can\u0026rsquo;t be helped. However, if one is interested in the worlds beyond math and physics, it\u0026rsquo;s pivotal to get familiar with Euclidean spaces sooner rather than later.\n","id":205,"permalink":"https://freshrimpsushi.github.io/en/posts/205/","tags":null,"title":"Euclidean Space"},{"categories":"Ìï®Ïàò","contents":"Formulas For non-integer $p$, $$ {\\Gamma (1-p) \\Gamma ( p )} = { {\\pi} \\over {\\sin \\pi p } } $$\nDescription It is the most famous formula among the formulas using the Gamma function.\nA useful result that can be obtained from the reflection formula is $ \\Gamma ( { 1 \\over 2} ) = \\sqrt{\\pi}$. Perhaps that‚Äôs why? The name \u0026ldquo;reflection formula\u0026rdquo; is said to have been derived from reflecting on $\\frac{1}{2}$.\nDerivation Weierstrass\u0026rsquo;s infinite product: $$ {1 \\over \\Gamma (p)} = p e^{\\gamma p } \\prod_{n=1}^{\\infty} \\left( 1 + {p \\over n} \\right) e^{- {p \\over n} } $$\n$$ \\begin{align*} {{1} \\over {\\Gamma (p)}} \\cdot { 1 \\over { \\Gamma ( -p )}} =\u0026amp; p e^{\\gamma p } \\prod_{n=1}^{\\infty} \\left( 1 + {p \\over n} \\right) e^{- {p \\over n} } \\cdot (-p) e^{- \\gamma p } \\prod_{n=1}^{\\infty} \\left( 1 - {p \\over n} \\right) e^{ {p \\over n} } \\\\ =\u0026amp; -p^2 \\prod_{n=1}^{\\infty} \\left( 1 - {p^2 \\over n^2} \\right) \\end{align*} $$ Meanwhile, since ${ \\Gamma ( 1-p )} = -p \\Gamma (-p)$, $$ { 1 \\over {\\Gamma (1-p) \\Gamma ( p )} } = p \\prod_{n=1}^{\\infty} \\left( 1 - {p^2 \\over n^2} \\right) $$\nEuler\u0026rsquo;s representation of the sinc function: $$ {{\\sin \\pi x} \\over {\\pi x}} = \\prod_{n=1}^{\\infty} \\left( 1 - {{x^2} \\over { n^2}} \\right) $$\nBy fine-tuning the Euler representation of the sinc function, the desired formula is obtained.\n‚ñ†\n","id":192,"permalink":"https://freshrimpsushi.github.io/en/posts/192/","tags":null,"title":"Euler's Reflection Formula Derivation"},{"categories":"Ìï®Ïàò","contents":"Theorem Definition of Sinc Function The following function $\\text{sinc} : \\mathbb{R} \\to \\mathbb{R}$ is called the Sinc Function.\n$$ \\text{sinc} x := \\begin{cases} \\displaystyle {{\\sin x} \\over {x}} \u0026amp; , \\text{if } x \\ne 0 \\\\ 1 \u0026amp; , \\text{if } x = 0 \\end{cases} $$\nEuler Representation $$ \\text{sinc} x = \\prod_{n=1}^{\\infty} \\left( 1 - {{x^2} \\over { \\pi^2 n^2}} \\right) $$\nExplanation The Sinc function is the function obtained by dividing $\\sin x$ by $x$, and as its separate name suggests, it is quite useful. It often appears in limitations and continuity parts of the curriculum, even if its name is not known.\nOn the other hand, the Normalized Sinc Function is defined as follows: $$ \\text{sinc} x = {{\\sin \\pi x} \\over {\\pi x}} = \\prod_{n=1}^{\\infty} \\left( 1 - {{x^2} \\over { n^2}} \\right) $$ In this case, $\\displaystyle \\text{Sa}(x) := {{\\sin x} \\over {x}}$ is sometimes called the Unnormalized Sinc Function, but essentially, the two are just the same function and are not strictly distinguished, usually redefined as needed for each case.\nIncidentally, the ideal integral of the Sinc function is found to be $\\displaystyle \\int_{- \\infty}^{\\infty} {{\\sin x} \\over {x} } dx = \\pi$.\nProof Strategy: The proof to be introduced is not intuitive and has many technical aspects which make it quite difficult to understand. However, it is relatively easier among them and has the advantage of not using complex analysis.\nLet\u0026rsquo;s define $$ I_{n} (c) := \\int_{0}^{ { {\\pi} \\over {2} } } \\cos ^{n} t \\cos ct dt $$. Then $$ I_{0} (0) = \\int_{0}^{ { {\\pi} \\over {2} } } \\cos 0 dt = { {\\pi} \\over {2} } \\\\ I_{0} (2x) = \\int_{0}^{ { {\\pi} \\over {2} } } \\cos 2xt dt = \\left[ {{\\sin 2xt} \\over {2x}} \\right]_{0}^{{ {\\pi} \\over {2} }} = {{\\sin \\pi x} \\over {2 x}} $$ Therefore $$ {{I_{0} (2x)} \\over {I_{0} (0)}}= {{\\sin \\pi x} \\over {\\pi x}} = \\text{sinc} x $$ Hence $$ {{I_{0} (2x)} \\over {I_{0} (0)}}= \\prod_{n=1}^{\\infty} \\left( 1 - {{x^2} \\over { n^2}} \\right) $$ is what needs to be shown. First, let\u0026rsquo;s represent $ I_{n} (c)$ as a recurrence formula. $$ \\begin{align*} I_{n} (c) =\u0026amp; \\int_{0}^{ { {\\pi} \\over {2} } } \\cos ^{n} t \\cos ct dt \\\\ =\u0026amp; \\left[ {1 \\over c} \\cos^{n} t \\sin c t \\right]_{0}^{{ {\\pi} \\over {2} }} - \\int_{0}^{ { {\\pi} \\over {2} } } {1 \\over c} n \\cos ^{n-1} t (-\\sin t) \\sin ct dt \\\\ =\u0026amp; {n \\over c} \\int_{0}^{ { {\\pi} \\over {2} } } \\cos ^{n-1} t \\sin t \\sin ct dt \\\\ =\u0026amp; {n \\over c} \\left[ {1 \\over c} \\cos^{n-1} t \\sin t (-\\cos c t ) \\right]_{0}^{{ {\\pi} \\over {2} }} \\\\ \u0026amp; - {n \\over c} \\int_{0}^{ { {\\pi} \\over {2} } } {1 \\over c} \\left\\{ (n-1) \\cos ^{n-2} t (-\\sin^2 t) + \\cos ^{n} t \\right\\} (-\\cos ct) dt \\\\ =\u0026amp; {n \\over {c^2} } \\int_{0}^{ { {\\pi} \\over {2} } } \\left\\{ (n-1) \\cos ^{n-2} t (\\cos^2 t - 1) + \\cos ^{n} t \\right\\} \\cos ct dt \\\\ =\u0026amp; {n \\over {c^2} } \\int_{0}^{ { {\\pi} \\over {2} } } \\left\\{ n \\cos ^{n} t - (n-1) \\cos^{n-2} t \\right\\} \\cos ct dt \\\\ =\u0026amp; {n \\over {c^2} } \\left\\{ n I_{n}(c) - (n-1) I_{n-2}(c) \\right\\} \\end{align*} $$ If well organized $$ (n^2 - c^2) I_{n} (c) = ( n^{2} - n) I_{n-2} (c) $$ By substituting $c=0$ into the obtained formula and dividing each side, a new recurrent formula $$ { {(n^2 - c^2)} \\over {n^2} } {{I_{n} (c)} \\over {I_{n} (0)}} = { {I_{n-2} (c)} \\over {I_{n-2} (0)} } $$ is obtained. If we repeat until the RHS becomes $\\displaystyle { {I_{0} (c)} \\over {I_{0} (0)} }$ in the new recurrence formula $$ \\prod_{k=1}^{m} { {(2k)^2 - c^2} \\over {(2k)^2} } {{I_{2m} (c)} \\over {I_{2m} (0)}} = { {I_{0} (c)} \\over {I_{0} (0)} } $$ By substituting $c=2x$ here $$ \\prod_{k=1}^{m} { {(2k)^2 - (2x)^2} \\over {(2k)^2} } {{I_{2m} (2x)} \\over {I_{2m} (0)}} = {{I_{2m} (2x)} \\over {I_{2m} (0)}} \\prod_{k=1}^{m} { {k^2 - x^2} \\over {k^2} } = {{I_{0} (2x)} \\over {I_{0} (0)}} $$ Since $\\displaystyle {{I_{0} (2x)} \\over {I_{0} (0)}}= \\prod_{n=1}^{\\infty} \\left( 1 - {{x^2} \\over { n^2}} \\right)$, $\\displaystyle \\lim_{m \\to \\infty} {{I_{m} (2x)} \\over {I_{m} (0)}}=1$ is proven. Now $$ I_{m} (2x) = \\int_{0}^{ { {\\pi} \\over {2} } } \\cos ^{m} t \\cos 2xt dt $$ Consider this sequence. If this sequence is seen as a function of $x$, its period is $1$, and since it\u0026rsquo;s an odd function, considering only $\\displaystyle 0\u0026lt;x \\le {1 \\over 2}$ is sufficient. Since $\\cos 0 \u0026gt;\\cos 2x t$ $$ I_{m} (0)\u0026gt; I_{m} (2x) \\\\ \\cos 2xt \u0026gt;\\cos^{2} t $$ And, $ I_{m} (2x)\u0026gt; I_{m+2} (0)$. Therefore $$ I_{m} (0)\u0026gt; I_{m} (2x)\u0026gt; I_{m+2} (0) $$ In which, dividing each side by $ I_{m} (0)$ yields $$ 1 \u0026gt; {{I_{m} (2x)} \\over {I_{m} (0)} }\u0026gt; {{I_{m+2} (0)} \\over {I_{m} (0)}} $$ Here, $$ (m+2)^2 I_{m+2}(0) = (m^2 + 3m + 2) I_{m}(0) $$ Thus, $$ \\lim_{m \\to \\infty} {{I_{m+2} (0)} \\over {I_{m} (0)}} = \\lim_{m \\to \\infty} { {m+1} \\over {m+2} } = 1 $$ Therefore $$ {{\\sin \\pi x} \\over {\\pi x}} = \\prod_{n=1}^{\\infty} \\left( 1 - {{x^2} \\over { n^2}} \\right) $$\n‚ñ†\nAlthough the actual result is quite useful, the proof itself is not something that can be memorized and applied elsewhere. It\u0026rsquo;s recommended to acknowledge that such proof exists rather than thoroughly understanding and memorizing it.\nCorollary Euler\u0026rsquo;s Proof: Using Sinc Function to Determine the Sum of the Reciprocals of Squares ","id":187,"permalink":"https://freshrimpsushi.github.io/en/posts/187/","tags":null,"title":"Proof of the Euler Representation of the Sinc Function"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Overview This post will introduce several series convergence tests without diving into their proofs. It is often more valuable to utilize these tests as facts, especially since the proofs can be quite tedious.\nIn this post, we use the following notations:\n$\\mathbb{N}$ is the set containing all natural numbers. $\\mathbb{R}$ is the set containing all real numbers, and $\\overline{\\mathbb{R}}$ is the extended real number set that includes $\\pm \\infty$. $\\left\\{ a_{k} \\right\\}_{k \\in \\mathbb{N}}, \\left\\{ b_{k} \\right\\}_{k \\in \\mathbb{N}} \\subset \\mathbb{R}$ is a sequence of real numbers. $\\exists \\lim_{k \\to \\infty} x_{k}$ means that the limit of $x_{k}$ exists in $\\mathbb{R}$, meaning it converges. Conversely, $\\not\\exists \\lim_{k \\to \\infty} x_{k}$ means that the limit of $x_{k}$ does not exist in $\\mathbb{R}$, meaning it diverges. For sufficiently large $k$, when $\\displaystyle \\lim_{k \\to \\infty} { {a_k} \\over {b_k} } = 1$ then it is expressed as $a_k \\approx b_k$. $b_k \\downarrow 0$ means that $b_{k}$ is a decreasing sequence and converges to $0$ while always taking a value greater than or equal to $0$. Real Sequences 1 Divergence Test If $\\lim _{ k \\to \\infty }{ { a }_{ k }} \\ne 0$ then $\\sum _{ k =1 }^{ \\infty }{ { a }_{ k }}$ diverges: $$ \\lim _{ k \\to \\infty }{ { a }_{ k }} \\ne 0 \\implies \\not\\exists \\sum _{ k =1 }^{ \\infty }{ { a }_{ k }} $$\nThe Divergence Test is the only method you might encounter in high school. It\u0026rsquo;s a pity that it cannot determine convergence itself, but it\u0026rsquo;s the easiest and fastest when showing divergence. Cauchy\u0026rsquo;s Criterion The convergence of $\\sum _{ n=1 }^{ \\infty }{ { a }_{ n }}$ is equivalent to $\\lim_{n \\to \\infty} \\sum _{ k=n }^{ n+m }{ { a }_{ k }}=0$: $$ \\exists \\sum_{k=1}^{\\infty} a_{k} \\iff \\left( \\forall \\varepsilon \u0026gt; 0 , \\exists N \\in \\mathbb{N} : m \\ge n \\ge N \\implies \\left| \\sum_{k=n}^{m} a_{k} \\right| \u0026lt; \\varepsilon \\right) $$\nThis is called the Cauchy Criterion because the theorem utilizes the fact that, in the space of real numbers $\\mathbb{R}$, a converging sequence being a Cauchy sequence is equivalent. Nonnegative Sequences 2 This section deals with sequences where each term is greater than or equal to $0$, denoted $a_{k} \\ge 0$.\nIntegral Test Let\u0026rsquo;s assume the decreasing function $f: [1,\\infty) \\to \\mathbb{R}$ is always greater than $0$. The convergence of $\\sum _{ k =1 }^{ \\infty }{ { f }( k )}$ is equivalent to $\\int_{1}^{\\infty} f(x) dx \u0026lt; \\infty$: $$ \\exists \\sum_{k=1}^{\\infty} f(k) \\iff \\int_{1}^{\\infty} f(x) dx \u0026lt; \\infty $$\nThe Integral Test is proven using the fact that $f(n+1) \\le \\int_{n}^{n+1} f(x) dx \\le f(n)$. It\u0026rsquo;s one of those rare criteria where the proof itself is interesting. $p$-Series Test The convergence of $\\sum _{ k=1 }^{ \\infty } k^{-p}$ is equivalent to $p\u0026gt;1$: $$ \\exists \\sum_{k=1}^{\\infty} {{ 1 } \\over { k^{p} }} \\iff p \u0026gt; 1 $$\nThe $p$-Series Test essentially means that if you increase the exponent even slightly in a harmonic series, it converges; otherwise, it diverges. It\u0026rsquo;s a corollary derived by inserting a geometric series into the integral test, but because it\u0026rsquo;s so simple and useful, it\u0026rsquo;s used even more often than the integral test. Comparison Test For sufficiently large $k$, let\u0026rsquo;s say $0 \\le a_k \\le b_k$. If $\\sum _{ k=1 }^{ \\infty }{ { b }_{ k }}$ converges, then $\\sum _{ k=1 }^{ \\infty }{ { a }_{ k }}$ also converges: $$ \\begin{align*} \\sum_{k=1}^{\\infty} b_{k} \u0026lt; \\infty \\implies \u0026amp; \\sum_{k=1}^{\\infty} a_{k} \u0026lt; \\infty \\\\ \\sum_{k=1}^{\\infty} a_{k} = \\infty \\implies \u0026amp; \\sum_{k=1}^{\\infty} b_{k} = \\infty \\end{align*} $$\nThe Comparison Test compares another series known to converge to determine the convergence as its name suggests. Using the contrapositive, you can similarly check if a series diverges. Limit Comparison Test For sufficiently large $k$, let\u0026rsquo;s say $a_k \\ge 0$ and $b_k\u0026gt;0$. $L := \\lim_{k \\to \\infty} { {a_k} \\over {b_k} } \\in \\overline{\\mathbb{R}}$ is some extended real number. (1) If $0\u0026lt;L\u0026lt;\\infty$ then both $\\sum _{ n=1 }^{ \\infty }{ { a }_{ n }}$ and $\\sum _{ n=1 }^{ \\infty }{ { b }_{ n }}$ either converge or diverge together. (2) If $L=0$ and $\\sum _{ n=1 }^{ \\infty }{ { b }_{ n }}$ converges, then $\\sum _{ n=1 }^{ \\infty }{ { a }_{ n }}$ also converges. (3) If $L=\\infty$ and $\\sum _{ n=1 }^{ \\infty }{ { b }_{ n }}$ diverges, then $\\sum _{ n=1 }^{ \\infty }{ { a }_{ n }}$ also diverges: $$ \\begin{align*} 0 \u0026lt; L \u0026lt; \\infty \\implies \u0026amp; \\left( \\exists \\sum_{k=1}^{n} a_{k} \\iff \\exists \\sum_{k=1}^{n} b_{k} \\right) \\\\ L = 0 \\implies \u0026amp; \\left( \\exists \\sum_{k=1}^{n} b_{k} \\implies \\exists \\sum_{k=1}^{n} a_{k} \\right) \\\\ L = \\infty \\implies \u0026amp; \\left( \\not\\exists \\sum_{k=1}^{n} b_{k} \\implies \\not\\exists \\sum_{k=1}^{n} a_{k} \\right) \\end{align*} $$\nThe Limit Comparison Test is like the comparison test but for when it\u0026rsquo;s difficult to show the original series converges by comparing it with another converging series. Though the conditions might seem strenuous, they\u0026rsquo;re often easy to satisfy when simply proving convergence, making this very useful. Absolute Convergence 3 For an infinite series $S = \\sum_{k=1}^{\\infty} a_{k}$, if $\\sum_{k=1}^{\\infty} \\left| a_{k} \\right|$ converges, $S$ is defined to converge absolutely. Accordingly, a series that doesn\u0026rsquo;t converge absolutely but does converge on its own is said to converge conditionally.\nRoot Test For the limit supremum $r = \\limsup_{k \\to \\infty} {{|a_k|} ^ {1 / k}}$ of $\\left\\{ \\left| a_{k} \\right|^{1/k} \\right\\}$, if $r\u0026lt;1$ then $\\sum _{ n=1 }^{ \\infty }{ { a }_{ k }}$ absolutely converges, if $r\u0026gt;1$ then $\\sum _{ n=1 }^{ \\infty }{ { a }_{ k }}$ diverges: $$ \\begin{align*} r \u0026lt; 1 \\implies \u0026amp; \\exists \\sum_{k=1}^{\\infty} \\left| a_{k} \\right| \\\\ r \u0026gt; 1 \\implies \u0026amp; \\not\\exists \\sum_{k=1}^{\\infty} a_{k} \\end{align*} $$\nRatio Test Assuming $a_{k} \\ne 0$, and $r = \\lim_{k \\to \\infty} { {|a_{k+1}|} \\over {|a_{k}|} } \\in \\overline{\\mathbb{R}}$ is an extended real number. If $r\u0026lt;1$ then $\\sum _{ k=1 }^{ \\infty }{ { a }_{ k }}$ absolutely converges, if $r\u0026gt;1$ then $\\sum _{ k=1 }^{ \\infty }{ { a }_{ k }}$ diverges: $$ \\begin{align*} r \u0026lt; 1 \\implies \u0026amp; \\exists \\sum_{k=1}^{\\infty} \\left| a_{k} \\right| \\\\ r \u0026gt; 1 \\implies \u0026amp; \\not\\exists \\sum_{k=1}^{\\infty} a_{k} \\end{align*} $$\nThe Root Test and Ratio Test have slightly stringent conditions but can outright prove absolute convergence, hence their popularity. Meanwhile, if $r=1$, methods like Dirichlet\u0026rsquo;s Test or Alternating Series Test can be used. The alternating series test can be directly derived from Dirichlet\u0026rsquo;s test, and if you\u0026rsquo;re only looking to establish convergence, considering an alternating harmonic series as an example is helpful. Dirichlet\u0026rsquo;s Test If the partial sum $s_n = \\sum_{k=1}^{n} a_k$ is bounded and $k \\to \\infty$ when $b_k \\downarrow 0$, then $\\sum _{ k=1 }^{ \\infty }{ { a }_{ k } {b}_{k}}$ converges: $$ \\left| s_n \\right| \u0026lt; \\infty , b_k \\downarrow 0 \\implies \\exists \\sum _{ k=1 }^{ \\infty }{ { a }_{ k } {b}_{k}} $$\nAlternating Series Test If $k \\to \\infty$ when $b_k \\downarrow 0$, then $\\sum _{ n=1 }^{ \\infty }{ (-1)^{k} {b}_{k}}$ converges. $$ b_k \\downarrow 0 \\implies \\exists \\sum _{ k=1 }^{ \\infty }{ (-1)^{-k} {b}_{k}} $$\nWade. (2013). An Introduction to Analysis(4th Edition): p186, 188.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWade. (2013). An Introduction to Analysis(4th Edition): p193, 194, 196.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWade. (2013). An Introduction to Analysis(4th Edition): p198, 201, 210.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":186,"permalink":"https://freshrimpsushi.github.io/en/posts/186/","tags":null,"title":"A Comprehensive Summary of Various Series Tests in Analysis"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem For two real numbers $a\u0026lt;b$, there exists a $r \\in \\mathbb{R}$ that satisfies $a\u0026lt;r\u0026lt;b$.\nExplanation In the real number space, no matter what interval you consider, there is always another real number in between. No matter how much you split it, there is a point that can be further divided. Although it seems obvious, keep in mind that this is not only non-obvious but also highly abstract. As an example, even the matter and energy dealt with in physics have their limits when split into smaller and smaller pieces.\nProof Strategy: The proof is divided for rational and irrational numbers respectively. If there exist both a rational number and an irrational number between two real numbers, then the proof is complete. The phrase \u0026ldquo;without loss of generality\u0026rdquo; is mentioned because the positive numbers that appear in the proof can always be represented by the difference between real numbers, so there is no need to specifically consider numbers below $0$. For example, even if the proof starts from two negative numbers $c \u0026lt; d \u0026lt; 0$, as long as inequality holds, a positive number can be formed as in $d - c \u0026gt; 0$.\nThe necessary foundational premises are as follows:\nField Axioms:\n(A1) Closure under addition: $a+b \\in \\mathbb{R}$ (A5) Additive inverse: There exists a $(-a)$ that satisfies $a + (-a) = (-a) + a = 0$ (M1) Closure under multiplication: $a\\cdot b \\in \\mathbb{R}$ (M5) Multiplicative inverse: There exists a ${a^{-1}}$ that satisfies $a \\cdot a^{-1} = a^{-1} \\cdot a = 1$ (D) Distributive law: $a \\cdot (b + c) = a \\cdot b + a \\cdot c$ Order Axioms:\nAdditivity: If $a\u0026lt;b$ and $c\\in \\mathbb{R}$, then $a+ c\u0026lt; b + c$ Multiplicativity: If $a\u0026lt;b$ and $c\u0026gt;0$, then $ac\u0026lt; bc$, or if $c\u0026lt;0$, then $ac\u0026gt; bc$ Archimedean Principle: For a positive number $a$ and a real number $b$, there exists a natural number $n$ that satisfies $an\u0026gt;b$.\nPart 1. Density of Rational Numbers 1\nLet\u0026rsquo;s show that there always exists a $q \\in \\mathbb{Q}$ that satisfies $a\u0026lt;q\u0026lt;b$. Without loss of generality, considering a positive number $(b-a) \u0026gt; 0$ and a real number $1 \\in \\mathbb{R}$ that satisfy $0 \u0026lt; a \u0026lt; b$, there exists a set of natural numbers $\\left\\{ n \\in \\mathbb{N} : (b-a) n \u0026gt; 1 \\right\\}$ that satisfies the inequality of Archimedes\u0026rsquo; principle, and by the existence of an additive inverse, closure, and distributive law, and additivity $$ bn-an \u0026gt; 1 \\implies an + 1 \u0026lt; bn \\implies an \u0026lt; an + 1 \u0026lt; bn $$ is known. $an$ and $an + 1$ have a difference greater than $1$, so there is at least one integer between them, let\u0026rsquo;s denote it as $m$, then $$ an \u0026lt; m \u0026lt; an + 1 \u0026lt; bn $$ If each side is multiplied by the multiplicative inverse of $n$ $n^{-1}$, we get the following: $$ a \u0026lt; {{ m } \\over { n }} \u0026lt; b $$ Here, if we set $\\displaystyle q := {{ m } \\over { n }}$, then $q$ is a \u0026lsquo;ratio of natural numbers\u0026rsquo;, a rational number, and we obtain the following inequality: $$ a \u0026lt; q \u0026lt; b $$\nPart 2. Density of Irrational Numbers\nLet\u0026rsquo;s show that there always exists a $\\xi \\in \\mathbb{Q^{c}}$ that satisfies $a\u0026lt;\\xi\u0026lt;b$. Without loss of generality, considering real numbers and irrational numbers $c\u0026gt;0$ that satisfy $0 \u0026lt; a \u0026lt; b$, if $a\u0026lt;b$ then $ac\u0026lt;bc$ by multiplicativity. Since real numbers are closed under multiplication, $ac$ and $bc$ are also real numbers, and by the density of rational numbers, there exists a rational number $q \\ne 0$ that satisfies $ac\u0026lt;q\u0026lt;bc$. If each side of $ac\u0026lt;q\u0026lt;bc$ is multiplied by the multiplicative inverse of $c$ $\\displaystyle {1 \\over c}$, it\u0026rsquo;s as follows:\n$$ a\u0026lt;{q \\over c}\u0026lt;b $$\nHere, if we set $\\displaystyle \\xi := {q \\over c}$, then $\\xi$ is the product of a non-$0$ rational number and an irrational number, thus an irrational number, and we obtain the following inequality:\n$$ a\u0026lt;\\xi\u0026lt;b $$\n‚ñ†\nhttps://www.math.ucdavis.edu/~hunter/m127a_19/rat_dense.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":185,"permalink":"https://freshrimpsushi.github.io/en/posts/185/","tags":null,"title":"Proof of the Density of Real Numbers"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Axioms1 A set $E \\subset \\mathbb{R}$ is not empty and if $E$ is bounded above, then a supremum $\\sup(E) \u0026lt; \\infty$ exists.\nExplanation The axioms of fields and orders might seem like complicating the known, but the completeness axiom does not seem so at a glance. Definitions for the terminology used here appear to be necessary first.\nDefinitions For every element $a$ of $E$ if $a \\le M$ is satisfied, then $E$ is called bounded above. All such $M$ satisfying these conditions are called the upper bounds of $E$. $\\sup(E)$ is the smallest upper bound of $E$, for all upper bounds $M$ of $E$, satisfying $\\sup (E) \\le M$. This is called the supremum or least upper bound of $E$.\nConversely, for the case with the opposite inequality,\nFor every element $a$ of $E$ if $a \\ge m$ is satisfied, then $E$ is called bounded below. All such $m$ satisfying these conditions are called the lower bounds of $E$. $\\inf(E)$ is the largest lower bound of $E$, for all lower bounds $m$ of $E$, satisfying $\\inf (E) \\ge m$. This is called the infimum or greatest lower bound of $E$.\nDefinitions might suddenly overflow and confuse, but essentially, it doesn\u0026rsquo;t challenge our concept. It merely defines when a set has limits and what those limits are called.\nSwitching back to the completeness axiom, it feels like repeating the introduced definitions. The difference is simple. Definitions only talk about when to call something if it exists, not whether it really exists. The completeness axiom discusses this \u0026rsquo;existence'.\nHowever, it might prompt the question: should this really be an axiom? Is it such a fundamental fact that it needs to be axiomatized, cannot it be proven? At first glance, it seems these upper bounds definitely exist by definition, but that\u0026rsquo;s not the case.\nCounterexample If $E$ is bounded above, then there would be upper bounds $M$ satisfying the condition, and among these upper bounds $M$, there exists the smallest value as the supremum $\\sup(E)$. But, think reversely, $\\sup(E)$ is the largest value among $-M$, i.e., the supremum. The claim that the smallest value exists itself bases on the existence of a supremum. Thus, inevitably leading to a circular argument.\n‚ñ†\nWhether it\u0026rsquo;s an upper or lower bound, magnitude large or small, the direction of the argument roundabouts. Ultimately, we cannot ascertain the existence of these bounds. Hence, there was no choice but to introduce a new axiom, the completeness axiom.\nTheorem If a subset $E$ of the set of integers $\\mathbb{Z}$ has a supremum, then $\\sup(E) \\in E$\nWithout the completeness axiom, we wouldn\u0026rsquo;t even trust such an obvious fact because its assumption is doubtful.\nComplete? The term complete, a mild version of completenessÂÆåÂÇô, when generalized in a metric space beyond the real number space $\\mathbb{R}$ includes spaces that contain converging points of Cauchy sequences as complete spaces. However, in everyday context, the English word Complete is not typically used in the sense of being fully equipped (ÂÆåÂÇô), instead, it is often used with \u0026lsquo;completion\u0026rsquo; or \u0026lsquo;conclusion,\u0026rsquo; denoting the end of something ongoing. This, as mentioned, since it guarantees the existence of a convergence point (within that space), the term complete is suitable.\nOf course, capturing a Cauchy sequence is different from capturing $E \\subset \\mathbb{R}$, though explanations such as $\\mathbb{R}$ having separability are too early right now. It\u0026rsquo;s okay to think you\u0026rsquo;ll learn about such later and move on.\nWilliam R. Wade, An Introduction to Analysis (4th Edition, 2010), p16-18\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":180,"permalink":"https://freshrimpsushi.github.io/en/posts/180/","tags":null,"title":"Three Axioms of Analysis: The Axiom of Completeness"},{"categories":"ÏñëÏûêÏó≠Ìïô","contents":"Definition In quantum mechanics, the momentum operator is as follows.\n$$ p_{\\text{op}} = \\frac{\\hbar}{i}\\frac{\\partial}{\\partial x} = -i\\hbar \\dfrac{\\partial }{\\partial x} $$\n","id":100,"permalink":"https://freshrimpsushi.github.io/en/posts/100/","tags":null,"title":"Momentum Operators in Quantum Mechanics"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Axioms1 Let\u0026rsquo;s accept the following properties for real numbers $a,b,c \\in \\mathbb{R}$ and operations $+,\\cdot$.\n(A1) Closure under addition: $a+b \\in \\mathbb{R}$\n(A2) Associative law for addition: $(a+b) + c = a + (b+c)$\n(A3) Commutative law for addition: $ a+ b= b + a$\n(A4) Identity element for addition: For every real number $a$, there exists a unique $0$ satisfying $a+0=0+a=a$.\n(A5) Inverse element for addition: For every real number $a$, there exists a unique $(-a)$ satisfying $a + (-a) = (-a) + a = 0$.\n(M1) Closure under multiplication: $a\\cdot b \\in \\mathbb{R}$\n(M2) Associative law for multiplication: $(a\\cdot b) \\cdot c = a \\cdot (b\\cdot c)$\n(M3) Commutative law for multiplication: $a\\cdot b= b \\cdot a$\n(M4) Identity element for multiplication: For every real number $a$, there exists a unique $1$ satisfying $a\\cdot 1=1\\cdot a=a$.\n(M5) Inverse element for multiplication: For every real number $a$, excluding $0$, there exists a unique ${a^{-1}}$ satisfying $a \\cdot a^{-1} = a^{-1} \\cdot a = 1$.\n(D) Distributive law: $a \\cdot (b + c) = a \\cdot b + a \\cdot c$\nExplanation Introduction to analysis fundamentally deals with the functions in the set of real numbers $\\mathbb{R}$. And one of the most perplexing processes in this study of analysis is studying such seemingly obvious facts. Until now, what was considered obvious is delved into with \u0026lsquo;rigor\u0026rsquo;, or as students might feel, unnecessary depth. Students who have always been thirsty for rigor will find it interesting, whereas others may find it challenging.\nReal numbers have been gradually expanded in the compulsory education system, naturally and intuitively accepted as a concept. Thus, it becomes quite tedious to argue if they are closed under operations like addition and multiplication, especially when these 11 properties are taken for granted so much that we hardly pay attention to them until we hurriedly memorize them before an exam, which might add to a mathematician\u0026rsquo;s sense of doubt.\nHowever, overcoming all this is part of the trial for learning greater subjects. There\u0026rsquo;s no need to memorize them thoroughly either. After a while, when you learn abstract algebra, you\u0026rsquo;ll find yourself talking fluently about these 11 properties without needing to memorize them. And further on, you\u0026rsquo;ll understand how these properties are not so obvious yet very useful. For instance, the following obvious fact surprisingly requires proof.\nTheorem Multiplying any real number by $0$ results in $0$.\nProof Let\u0026rsquo;s say $a \\in \\mathbb{R}$. Since $0 \\in \\mathbb{R}$, then $0 + 0= 0$,\n$$ a \\cdot 0 = a \\cdot [ 0 + 0 ] $$\nBy the (D) Distributive Law,\n$$ a \\cdot 0 = a \\cdot 0 + a \\cdot 0 $$\nSince $a \\cdot 0 \\in \\mathbb{R}$, the (A5) Inverse element for addition exists,\n$$ a \\cdot 0 + \\left[ -(a \\cdot 0) \\right] = a \\cdot 0 + a \\cdot 0 + \\left[ -(a \\cdot 0) \\right] $$\nThen $a \\cdot 0 + \\left[ -(a \\cdot 0) \\right] = 0$,\n$$ 0 = a \\cdot 0 $$\n‚ñ†\nSee Also Fields in Abstract Algebra William R. Wade, An Introduction to Analysis (4th Edition, 2010), p5-6\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":178,"permalink":"https://freshrimpsushi.github.io/en/posts/178/","tags":null,"title":"Three Axioms of Analysis: 1 Field Axioms"},{"categories":"ÍµêÍ≥ºÍ≥ºÏ†ï","contents":"Formula Given a geometric sequence $a_{n} = a r^{n-1}$ with the first term $a$ and common ratio $r$, $$ \\sum_{k=1}^{n} a_{k}= {{a (1- r^{n} ) } \\over {1-r}} $$\nProof Let\u0026rsquo;s denote it as $\\displaystyle S= \\sum_{k=1}^{n} a_{k}$. Then, $$ S= a + ar + \\cdots + ar^{n-2} + ar^{n-1} $$ Multiplying both sides by $r$ gives $$ rS= ar + a r^2 + \\cdots + ar^{n-1} + ar^{n} $$ Subtracting the two equations from each other, $$ S - rS = (1-r)S = a- a r^n $$ Dividing both sides of the resulting equation by $1-r$, $$ S=\\sum_{k=1}^{n} a_{k}= {{a (1- r^{n} ) } \\over {1-r}} $$\n‚ñ†\nExplanation Unlike the sum of an arithmetic sequence, this formula itself is very commonly used. The proof method is slightly different but it\u0026rsquo;s not so complicated that it requires additional study.\nGeometric series are also called Geometric Series. When people often say something has \u0026ldquo;increased geometrically,\u0026rdquo; that\u0026rsquo;s what they\u0026rsquo;re referring to. Thus, most people who are not familiar with mathematics are using the term \u0026ldquo;geometrically\u0026rdquo; incorrectly.\nWhat happens if the term $n$ in a geometric series grows infinitely? If $|r|\u0026lt;1$, it will converge, and if $|r|\u0026gt;1$, it will diverge. This consideration of $n \\to \\infty$ in a geometric series is referred to as an \u0026ldquo;infinite geometric series.\u0026rdquo;\nInfinite Geometric Series When $|r|\u0026lt;1$, $$ \\sum_{n=1}^{\\infty} a r^{n-1} = { a \\over {1-r}} $$\nSince $n \\to \\infty$ leads to $ar^n \\to 0$, it naturally derives from the geometric series.\n","id":170,"permalink":"https://freshrimpsushi.github.io/en/posts/170/","tags":null,"title":"Finding the Sum of a Geometric Sequence"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 2 Let\u0026rsquo;s define the function $f : R \\to \\mathbb{R}$ on the 2-dimensional domain $R : [a,b] \\times [c,d]$. If $f(x,\\cdot)$ is integrable over $[c,d]$, and $f(\\cdot,y)$ is integrable over $[a,b]$, and $f$ is integrable over $R$, then\n$$ \\iint _{R} f dA = \\int_{a}^{b} \\int_{c}^{d} f(x,y) dy dx = \\int_{c}^{d} \\int_{a}^{b} f(x,y) dx dy $$\nExplanation The integration domain $R$ obviously comes from a Rectangle. As it is always the case in analysis, to summarize for those of you who dislike reading long explanations, if it is integrable in each of the two orthogonal directions, then it does not matter in which order we integrate $f$. This might seem trivial for those in other fields who mostly deal with functions that satisfy these conditions, but it is an extremely important theorem. The fact that it is not just a property of double integrals but a theorem named after a person indicates its significance.\nProof $$ \\begin{align*} (L) \\iint _{R} f dA \\le \u0026amp; (L) \\int_{a}^{b} \\left( \\int_{c}^{d} f(x,y) dy \\right) dx \\\\ \\le \u0026amp; (U) \\int_{a}^{b} \\left( \\int_{c}^{d} f(x,y) dy \\right) dx \\\\ \\le \u0026amp; (U) \\iint _{R} f dA \\end{align*} $$\nLet\u0026rsquo;s define the function $g : [a,b] \\to \\mathbb{R}$ as $\\displaystyle g(x) := \\int_{c}^{d} f(x,y) dy$. Since $f$ is integrable over $R$, i.e., $\\displaystyle (L) \\iint _{R} f dA = (U) \\iint _{R} f dA$,\n$$ \\iint _{R} f dA = (U) \\int_{a}^{b} g(x) dx = (L) \\int_{a}^{b} g(x) dx $$\nSince $\\displaystyle (U) \\int_{a}^{b} g(x) dx = (L) \\int_{a}^{b} g(x) dx$, $g$ is integrable over $[a,b]$. Expressing it again,\n$$ \\begin{align*} \\iint _{R} f dA =\u0026amp; (U) \\int_{a}^{b} g(x) dx \\\\ =\u0026amp; (L) \\int_{a}^{b} g(x) dx \\\\ =\u0026amp; \\int_{a}^{b} \\int_{c}^{d} f(x,y) dy dx \\end{align*} $$\nBy swapping $x$ and $y$ and repeating the same process,\n$$ \\iint _{R} f dA = \\int_{c}^{d} \\int_{a}^{b} f(x,y) dx dy $$\nTherefore,\n$$ \\iint _{R} f dA = \\int_{a}^{b} \\int_{c}^{d} f(x,y) dy dx = \\int_{c}^{d} \\int_{a}^{b} f(x,y) dx dy $$\n‚ñ†\nWilliam R. Wade, An Introduction to Analysis (4th Edition, 2010), p477-478\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nÍ≤ΩÎ∂ÅÎåÄÌïôÍµê Í∏∞Ï¥àÍµêÏú°Ïõê, Ïù¥Í≥µÌïôÎèÑÎ•º ÏúÑÌïú ÎåÄÌïôÏàòÌïô (2012), p317-318\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":165,"permalink":"https://freshrimpsushi.github.io/en/posts/165/","tags":null,"title":"Proof of Fubini's Theorem"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 Let the curve $\\mathcal{C}$ be a simple, smooth, closed path in the plane $S = [a,b] \\times [c,d]$, moving counterclockwise. If the function $P,Q : \\mathbb{R}^2 \\to \\mathbb{R}$ is continuous on $\\mathcal{C}$ and its derivative is also continuous,\n$$ \\int_{\\mathcal{C}} (Pdx + Qdy) = \\iint_{S} (Q_{x} - P_{y}) dx dy $$\nExplanation This can be thought of as a theorem that converts line integrals into surface integrals. It\u0026rsquo;s widely known as a corollary derived from the Kelvin-Stokes theorem specifically limited to the plane. Despite there being more generalized theorems, it retains its significance in numerous fields due to its namesake.\nProof Suppose $$ I_{1} := \\int_{\\mathcal{C}} P dx \\\\ \\displaystyle I_{2} := \\int_{\\mathcal{C}} Q dy $$ then $$ \\int_{\\mathcal{C}} (Pdx + Qdy) = I_{1} + I_{2} $$ Let\u0026rsquo;s first find $I_{1}$.\nThe region for calculating $I_{1}$ is depicted above. The region encased by $\\mathcal{C}$ is $$ S = \\left\\{ (x,y) \\in \\mathbb{R} \\ | \\ a \\le x \\le b, y_{1}(x) \\le y \\le y_{2}(x) \\right\\} $$ thus, $$ \\begin{align*} I_{1} =\u0026amp; \\int_{\\mathcal{C}} Pdx \\\\ =\u0026amp; \\int_{a}^{b} P(x,y_{1} (x))dx + \\int_{b}^{a} P(x,y_{2} (x)) dx \\\\ =\u0026amp; - \\int_{a}^{b} \\left\\{ P(x,y_{2} (x))-P(x,y_{1} (x)) \\right\\} dx \\\\ =\u0026amp; - \\int_{a}^{b} \\int_{y_{1}(x)}^{y_{2}(x)} {{\\partial P(x,y)} \\over {\\partial y}} dy dx \\\\ =\u0026amp; - \\iint_{S} P_{y} dy dx \\end{align*} $$ Next, let\u0026rsquo;s calculate $I_{2}$. Usually, such proofs might conclude with \u0026rsquo;the same method can be applied\u0026rsquo;, but Green\u0026rsquo;s theorem requires a direct computation. The approach is similar, but it\u0026rsquo;s important to verify since the resulting signs are in opposite directions.\nThe region for calculating $I_{2}$ is depicted above. The region encased by $\\mathcal{C}$ is $$ S = \\left\\{ (x,y) \\in \\mathbb{R}^{2} \\ | \\ c \\le y \\le d, x_{1}(y) \\le x \\le x_{2}(y) \\right\\} $$ thus, $$ \\begin{align*} I_{2} =\u0026amp; \\int_{\\mathcal{C}} Qdy \\\\ =\u0026amp; \\int_{d}^{c} Q(x_{1}(y),y) dy + \\int_{c}^{d} Q(x_{2}(y),y) dy \\\\ =\u0026amp; \\int_{c}^{d} Q(x_{2}(y),y) dy - \\int_{c}^{d} Q(x_{1}(y),y) dy \\\\ =\u0026amp; \\int_{c}^{d} \\left\\{ Q(x_{2}(y),y) dy - Q(x_{1}(y),y) \\right\\} dy \\\\ =\u0026amp; \\int_{c}^{d} \\int_{x_{1}(x)}^{x_{2}(x)} {{\\partial Q(x,y)} \\over {\\partial x}} dx dy \\\\ =\u0026amp; \\iint_{S} Q_{x} dx dy \\end{align*} $$ Adding the results of $I_{2}$ and $I_{1}$ gives $$ \\int_{\\mathcal{C}} (Pdx + Qdy) = I_{2} + I_{1} = \\iint_{S} Q_{x} dx dy - \\iint_{S} P_{y} dy dx $$\nFubini\u0026rsquo;s Theorem: Suppose $R : [a,b] \\times [c,d]$. If $f(x,\\cdot)$ is integrable over $[c,d]$, $f(\\cdot,y)$ is integrable over $[a,b]$, and $f$ is integrable over $R$, then $$ \\iint _{R} f dA = \\int_{a}^{b} \\int_{c}^{d} f(x,y) dy dx = \\int_{c}^{d} \\int_{a}^{b} f(x,y) dx dy $$\nGiven that the derivative $P$ of the premise is also continuous, thereby integrable, Fubini\u0026rsquo;s theorem can be applied. By changing the order of integration as follows, $$ \\iint_{S} P_{y} dy dx = \\iint_{S} P_{y} dx dy $$ and standardizing the integration order to $dx dy$ results in $$ \\int_{\\mathcal{C}} (Pdx + Qdy) = \\iint_{S} ( Q_{x} - P_{y} ) dx dy $$\n‚ñ†\nWhile demonstrated with the rectangle $S$, this can be specialized for a small square $[\\alpha, \\alpha + \\varepsilon] \\times [\\beta, \\beta + \\varepsilon]$ and further generalized by dividing a bounded region $\\mathcal{R}$ into small squares with side length $\\varepsilon$, then taking the limit as $\\varepsilon \\to 0$ to obtain the generalized theorem simply.\nAlthough conditions and expressions may vary, the essence is largely the same. Rather than focusing on the generalization, it\u0026rsquo;s sufficient to acknowledge and move on as different textbooks might vary in detail.\nGeneralization 1 If the two functions $P,Q$ defined in $\\mathcal{R}$ are differentiable over $\\mathcal{R}$, $$ \\int_{\\mathcal{C}} (Pdx + Qdy) = \\iint_{\\mathcal{R}} (Q_{x} - P_{y}) dx dy $$\nThe curve $C^{2}$ is twice differentiable, and its derivatives are all differentiable. See Also Generalization of Green\u0026rsquo;s theorem Millman. (1977). Elements of Differential Geometry: p51. Supposing that the plane, simple, counterclockwise, closed curve $C^{2}$ $\\mathcal{C}$ encloses the bounded region $\\mathcal{R}$,\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":166,"permalink":"https://freshrimpsushi.github.io/en/posts/166/","tags":null,"title":"Proof of Green's Theorem"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Summary 1 Let\u0026rsquo;s say the function $f$ is piecewise continuous on the integration path $\\mathscr{C}: z = z(t), t \\in [a,b]$. If the positive number $\\displaystyle L = \\int_{a}^{b} |z\u0026rsquo;(t)| dt$ is the length of $\\mathscr{C}$, and for all points on $\\mathscr{C}$ there exists a positive number $M$ satisfying $|f(z)| \\le M$, then $$ \\left| \\int_{\\mathscr{C}} f(z) dz \\right| \\le ML $$\nProof For the function $z\u0026rsquo;: [a,b] \\to \\mathbb{C}$ let\u0026rsquo;s say $\\displaystyle \\left| \\int_{a}^{b} z\u0026rsquo;(t) dt \\right| = r$.\nIf $r \\ne 0$ then it can be represented as $\\displaystyle \\int_{a}^{b} z\u0026rsquo;(t) dt = r e^{i \\theta}$. Then $\\theta$ is a constant, therefore $$ r = \\int_{a}^{b} e^{- i \\theta} z\u0026rsquo;(t) dt \\le \\int_{a}^{b} \\left| e^{- i \\theta} z\u0026rsquo;(t) \\right| dt = \\int_{a}^{b} \\left| e^{- i \\theta} \\right| \\left| z\u0026rsquo;(t) \\right| dt $$ Here, because the magnitude of a complex number\u0026rsquo;s real root is always 1, $\\left| e^{ - i \\theta} \\right| = 1$. Thus, $$ \\left| \\int_{a}^{b} z\u0026rsquo;(t) dt \\right| = r \\le \\int_{a}^{b} \\left| z\u0026rsquo;(t) \\right| dt $$ This demonstrates that the properties of definite integrals which hold for real functions are also valid for complex functions. Using the inequality derived above, we get $$ \\begin{align*} \\left| \\int_{\\mathscr{C}} f(z) dz \\right| =\u0026amp; \\left| \\int_{a}^{b} f(z(t)) z\u0026rsquo;(t) dt \\right| \\\\ \\le \u0026amp; \\int_{a}^{b} \\left| f(z(t)) \\right| \\left| z\u0026rsquo;(t) \\right| dt \\\\ =\u0026amp; \\int_{a}^{b} M \\left| z\u0026rsquo;(t) \\right| dt \\\\ =\u0026amp; ML \\end{align*} $$\n‚ñ†\nExplanation In the ML Lemma, M stands for Maximum, and L stands for Length.\nWhat can be confusing when using the ML Lemma is how to choose $L$. Often in the original integral, $\\mathscr{C}$ is given as a circle with radius $r$, and when substituting, the integration interval becomes $[0,2\\pi]$. After substituting and applying the ML Lemma, one should use $2 \\pi$, the length of the new integration interval, not $2\\pi r$, the original circle\u0026rsquo;s circumference. In other words, it\u0026rsquo;s important to remember that you must apply the ML Lemma to the new curve (segment), $\\mathscr{C} ' $, that emerges through substitution.\nOsborne (1999). Complex variables and their applications: p76.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":162,"permalink":"https://freshrimpsushi.github.io/en/posts/162/","tags":null,"title":"Proof of ML Auxiliary Lemma"},{"categories":"ÍµêÍ≥ºÍ≥ºÏ†ï","contents":"Theorem Given a right-angled triangle, if we call the length of the hypotenuse $c$, and the lengths of the other two sides $a,b$, then the following equation holds. $$ a^2 + b^2 = c^2 $$\nExplanation Apart from its wide applications, this theorem is very practical in itself. It\u0026rsquo;s named after Pythagoras for leaving behind the oldest \u0026lsquo;proof\u0026rsquo;, but it is speculated that most ancient civilizations, which could be considered to have formed true societies, were aware of the fact itself.\nThere are known to be over 400 different proofs of Pythagoras\u0026rsquo; theorem. Among them, let\u0026rsquo;s learn about the oldest theorem, that is, the proof left by Pythagoras himself.\nProof The length of one side of the outer square is $(a+b)$, and that of the inner square is $c$. The area of the outer square is $(a+b)^2 = a^2 + 2ab + b^2$. The area of the right-angled triangle at each vertex is $\\displaystyle {ab \\over 2}$. Therefore, we can say that the area of the inner square is $$ (a+b)^2 - 4{ab \\over 2} = a^2 + 2ab + b^2 - 2ab $$. Meanwhile, the area of the inner square is also $c^2$, hence $$ a^2 + b^2 = c^2 $$.\n‚ñ†\nSome have summarized this proof as \u0026ldquo;just look\u0026rdquo;. It‚Äôs that intuitive and easy, so make sure to see it properly and not forget.\n","id":161,"permalink":"https://freshrimpsushi.github.io/en/posts/161/","tags":null,"title":"Pythagorean Theorem Proof"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Definition 1 Let\u0026rsquo;s define the hyperbolic function as a complex function $\\sinh, \\cosh : \\mathbb{C} \\to \\mathbb{C}$ as follows. $$ \\sinh z := { {e^{z} - e^{-z}} \\over 2 } \\\\ \\cosh z := { {e^{z} + e^{-z}} \\over 2 } $$\nTheorem 2 $$ \\begin{align*} \\sinh (iz) =\u0026amp; i \\sin z \\\\ \\sin (iz) =\u0026amp; i \\sinh z \\\\ \\cosh (iz) =\u0026amp; \\cos z \\\\ \\cos (iz) =\u0026amp; \\cosh z \\end{align*} $$\nDescription The most confusing part when first encountering the hyperbolic function is \u0026lsquo;why such a definition is used\u0026rsquo;. In the realm of real numbers, trigonometric functions are defined as ratios in a unit circle, while hyperbolic functions are represented as a linear combination of exponential functions. Just by definitions, it\u0026rsquo;s hard to accept why hyperbolic functions are called a kind of trigonometric function. Only by observing these functions over complex numbers can one understand how well-structured and intuitive this system is.\nThese properties are somewhat aligned with the original properties used in trigonometric functions.\nSine function is an odd function, Cosine function is an even function $$ \\sin (-\\theta) = - \\sin \\theta \\\\ \\cos (-\\theta) = \\cos \\theta $$\nJust as $-1$ freely moves in and out of $\\sin$ without affecting $\\cos$, $i$ moves freely in and out of $\\sin$ and $\\sinh$ without affecting $\\cos$ and $\\cosh$. The difference is whether it\u0026rsquo;s $\\sin$ or $\\cos$, the presence of $\\text{h}$ toggles. Thinking of complex numbers creating a world not of just negative or positive but of $i$ and $-i$, one might realize the necessity of moving beyond merely $\\sin$ or $\\cos$ to include $\\sinh$ and $\\cosh$.\nPeriodicity of Hyperbolic Functions $$ \\sinh (ix) = i \\sin x \\\\ \\cosh (ix) = \\cos x $$\nMoreover, the relationship between trigonometric and hyperbolic functions easily reveals the periodicity of hyperbolic functions in pure imaginary numbers. It\u0026rsquo;s straightforward once considered, but such a property might be elusive when not familiar.\nProof In complex analysis of trigonometric functions: $$ \\sin z = { {e^{iz} - e^{-iz}} \\over 2 i } \\\\ \\cos z = { {e^{iz} + e^{-iz}} \\over 2 } $$\n$$ \\sinh (iz) = { { e^{iz} - e^{-iz} } \\over 2 } = i { { e^{iz} - e^{-iz} } \\over {2 i} } = i \\sin z $$\n$$ \\sin (iz) = { {e^{iiz} - e^{-iiz}} \\over 2 i } = - i { {e^{-z} - e^{z}} \\over 2 } = i \\sinh z $$\n$$ \\cosh (iz) = { { e^{iz} + e^{-iz} } \\over 2 } = \\cos z $$\n$$ \\cos (iz) = { { e^{iiz} + e^{-iiz} } \\over 2 } = { { e^{-z} + e^{z} } \\over 2 } = \\cosh z $$\n‚ñ†\nOsborne (1999). Complex variables and their applications: p27.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOsborne (1999). Complex variables and their applications: p29.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":157,"permalink":"https://freshrimpsushi.github.io/en/posts/157/","tags":null,"title":"The Relationship between Trigonometric and Hyperbolic Functions in Complex Analysis"},{"categories":"Í≥†Ï†ÑÏó≠Ìïô","contents":"Velocity and Acceleration in Polar Coordinates $$ \\begin{align*} \\mathbf{v}\u0026amp;=\\dot{r} \\hat{\\mathbf{r}} + r \\dot{\\theta} \\hat{\\boldsymbol{\\theta}} \\\\ \\mathbf{a}\u0026amp;= (\\ddot r -r\\dot{\\theta} ^2)\\hat{\\mathbf{r}} + (2\\dot{r} \\dot{\\theta} + r\\ddot{\\theta})\\hat{\\boldsymbol{\\theta}} \\end{align*} $$\nDerivation In the polar coordinate system, unit vectors can be described as follows.\n$$ \\begin{align*} \u0026amp;\u0026amp; \\mathbf{r}\u0026amp;=r\\hat{\\mathbf{r}}=x\\hat{\\mathbf{x}} + y \\hat{\\mathbf{y}} \\\\ \\implies \u0026amp;\u0026amp; \\hat{\\mathbf{r}} \u0026amp;= \\frac{x}{r}\\hat{\\mathbf{x}} +\\frac{y}{r} \\hat{\\mathbf{y}}=\\cos\\theta \\hat{\\mathbf{x}} + \\sin\\theta \\hat{\\mathbf{y}} = \\hat{\\mathbf{r}} (\\theta) \\\\ {} \\\\ \u0026amp;\u0026amp; \\hat \\theta \u0026amp;= \\hat{\\mathbf{r}}(\\theta+\\pi/2)= -\\sin\\theta \\hat{\\mathbf{x}} + \\cos\\theta \\hat{\\mathbf{y}} \\end{align*} $$\nVelocity is obtained by differentiating position with respect to time, and acceleration is obtained by differentiating velocity with respect to time. Note that $\\dot{r}$ is pronounced \u0026ldquo;dot\u0026rdquo;. In physics, a dot above a letter means differentiation with respect to time.\n$$ \\dot{r}=\\frac{dr}{dt} $$\nVelocity Differentiating $\\mathbf{r}$ with respect to $t$ gives the following.\n$$ \\mathbf{v}=\\frac{d \\mathbf{r}}{dt}=\\frac{d}{dt}(r \\hat{\\mathbf{r}})=\\frac{d r}{dt}\\hat{\\mathbf{r}} + r\\frac{d \\hat{\\mathbf{r}}}{dt} =\\dot{r} \\hat{\\mathbf{r}} +r \\dot{\\hat{\\mathbf{r}}} $$\nCalculating $\\dot{\\hat{\\mathbf{r}}}$, since $\\hat{\\mathbf{x}}$ and $\\hat{\\mathbf{y}}$ do not change over time, $\\dfrac{d \\hat{\\mathbf{x}}}{dt}=0$ is true. Hence, it can be given as follows.\n$$ \\begin{align*} \\dot{\\hat{\\mathbf{r}}} = \\frac{d}{dt}(\\hat{\\mathbf{r}}) \u0026amp;= \\frac{d}{dt}(\\cos\\theta \\hat{\\mathbf{x}}) + \\frac{d}{dt}(\\sin\\theta \\hat{\\mathbf{y}}) \\\\ \u0026amp;= \\frac{\\cos\\theta}{dt}\\hat{\\mathbf{x}} + \\frac{\\sin\\theta}{dt}\\hat{\\mathbf{y}} \\\\ \u0026amp;= \\frac{\\cos\\theta}{d \\theta}\\frac{d \\theta}{dt}\\hat{\\mathbf{x}}+\\frac{\\sin\\theta}{d \\theta}\\frac{d \\theta}{dt}\\hat{\\mathbf{y}} \\\\ \u0026amp;= -\\sin\\theta \\frac{d \\theta}{dt}\\hat{\\mathbf{x}}+\\cos\\theta \\frac{d \\theta}{dt}\\hat{\\mathbf{y}} \\\\ \u0026amp;= \\frac{d \\theta }{dt}(-\\sin\\theta \\hat{\\mathbf{x}}+\\cos\\theta \\hat{\\mathbf{y}}) \\\\ \u0026amp;= \\dot{\\theta} \\hat{\\boldsymbol{\\theta}} \\end{align*} $$ Therefore, the velocity in polar coordinates is as follows.\n$$ \\mathbf{v}=\\dot{r} \\hat{\\mathbf{r}} + r \\dot{\\theta} \\hat{\\boldsymbol{\\theta}} $$\n‚ñ†\nAcceleration Differentiating $\\mathbf{v}$ with respect to $t$ gives the following.\n$$ \\mathbf{a} = \\dfrac{d\\mathbf{v}}{dt} = \\dfrac{d(\\dot{r} \\hat{\\mathbf{r}} + r \\dot{\\theta} \\hat{\\boldsymbol{\\theta}})}{dt} = \\ddot{r} \\hat{\\mathbf{r}} + \\dot{r} \\dot{\\hat{\\mathbf{r}}} + \\dot{r} \\dot{\\theta} \\hat{\\boldsymbol{\\theta}} + r \\ddot{\\theta} \\hat{\\boldsymbol{\\theta}} + r \\dot{\\theta} \\dot{\\hat{\\boldsymbol{\\theta}}} $$\nCalculating $\\dot{ \\hat{\\boldsymbol{\\theta}}}$ gives the following result.\n$$ \\begin{align*} \\dot{ \\hat{\\boldsymbol{\\theta}}} = \\frac{d}{dt}(\\hat{\\boldsymbol{\\theta}}) \u0026amp;= \\frac{d}{dt}(-\\sin\\theta \\hat{\\mathbf{x}})+\\frac{d}{dt}(\\cos\\theta \\hat{\\mathbf{y}}) \\\\ \u0026amp;= -\\frac{d \\sin\\theta}{dt}\\hat{\\mathbf{x}} +\\frac{d\\cos\\theta}{dt}\\hat{\\mathbf{y}} \\\\ \u0026amp;= -\\frac{d\\sin\\theta}{d \\theta}\\frac{d \\theta}{dt}\\hat{\\mathbf{x}}+\\frac{d\\cos\\theta}{d \\theta}\\frac{d \\theta}{dt}\\hat{\\mathbf{y}} \\\\ \u0026amp;= \\dfrac{d\\theta}{dt} (-\\cos\\theta \\hat{\\mathbf{x}}-\\sin\\theta \\hat{\\mathbf{y}}) \\\\ \u0026amp;= - \\dot{\\theta} \\hat{\\mathbf{r}} \\end{align*} $$\nSince $\\dot{\\hat{\\mathbf{r}}}$ was calculated when deriving velocity, substituting and organizing gives the following result.\n$$ \\begin{align*} \\mathbf{a} \u0026amp;= \\ddot r \\hat{\\mathbf{r}} +\\dot{r} \\dot{ \\hat{\\mathbf{r}}} + \\dot{r} \\dot{\\theta} \\hat{\\boldsymbol{\\theta}} + r \\ddot{\\theta} \\hat{\\boldsymbol{\\theta}} + r \\dot{\\theta} \\dot{ \\hat{\\boldsymbol{\\theta}}} \\\\ \u0026amp;= \\ddot r \\hat{\\mathbf{r}} +\\dot{r} \\dot{\\theta} \\hat{\\theta} + \\dot{r} \\dot{\\theta} \\hat{\\boldsymbol{\\theta}} + r \\ddot{\\theta} \\hat{\\boldsymbol{\\theta}} -r \\dot{\\theta} \\dot{\\theta} \\hat{\\mathbf{r}} \\\\ \u0026amp;= (\\ddot r -r\\dot{\\theta} ^2)\\hat{\\mathbf{r}} + (2\\dot{r} \\dot{\\theta} + r\\ddot{\\theta})\\hat{\\boldsymbol{\\theta}} \\end{align*} $$\n‚ñ†\nSee Also Velocity and Acceleration in Cartesian Coordinates Velocity and Acceleration in Cylindrical Coordinates Velocity and Acceleration in Spherical Coordinates ","id":158,"permalink":"https://freshrimpsushi.github.io/en/posts/158/","tags":null,"title":"Velocity and Acceleration in Polar Coordinates"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Spherical Coordinate System\u0026rsquo;s Unit Vectors $$ \\begin{align*} \\hat{\\mathbf{r}} \u0026amp;= \\cos\\phi \\sin\\theta\\hat{\\mathbf{x}} + \\sin\\phi \\sin\\theta\\hat{\\mathbf{y}} + \\cos\\theta\\hat{\\mathbf{z}} \\\\ \\hat{\\boldsymbol{\\theta}} \u0026amp;= \\cos\\phi \\cos\\theta \\hat{\\mathbf{x}} + \\sin\\phi \\cos\\theta \\hat{\\mathbf{y}} - \\sin\\theta\\hat{\\mathbf{z}} \\\\ \\hat{\\boldsymbol{\\phi}} \u0026amp;= -\\sin\\phi \\hat{\\mathbf{x}} + \\cos\\phi \\hat{\\mathbf{y}} \\end{align*} $$\nDerivation First, calculate $\\hat{\\mathbf{r}}$ and then use it to derive the other two.\nRadial Direction Unit Vector $\\hat{\\mathbf{r}}$ $$ \\hat{\\mathbf{r}}=r\\hat{\\mathbf{r}}=x\\hat{\\mathbf{x}}+y\\hat{\\mathbf{y}}+z\\hat{\\mathbf{z}} $$\nTherefore, dividing both sides by $r$ gives:\n$$ \\begin{align*} \\hat{\\mathbf{r}}\u0026amp;=\\frac{x}{r}\\hat{\\mathbf{x}}+\\frac{y}{r}\\hat{\\mathbf{y}}+\\frac{z}{r}\\hat{\\mathbf{z}} \\\\ \u0026amp;= \\frac{x}{r \\sin\\theta}\\sin\\theta\\hat{\\mathbf{x}}+\\frac{y}{r \\sin\\theta}\\sin\\theta\\hat{\\mathbf{y}}+\\cos\\theta\\hat{\\mathbf{z}} \\\\ \u0026amp;= \\cos\\phi \\sin\\theta \\hat{\\mathbf{x}} + \\sin\\phi \\sin\\theta\\hat{\\mathbf{y}} + \\cos\\theta\\hat{\\mathbf{z}} =\\hat{\\mathbf{r}}(\\theta,\\phi) \\end{align*} $$\nPolar Angle Direction Unit Vector $\\hat{\\boldsymbol{\\theta}}$ $\\hat{\\boldsymbol{\\theta}}$ is obtained from the $\\hat{\\mathbf{r}}$ direction, where $\\phi$ remains the same, and only $\\theta$ increases by $\\dfrac{\\pi}{2}$, as follows:\n$$ \\begin{align*} \\hat{\\boldsymbol{\\theta}} \u0026amp;= \\hat{\\mathbf{r}} \\left(\\theta+\\dfrac{\\pi}{2}, \\phi \\right) \\\\ \u0026amp;= \\cos\\phi \\sin\\left(\\theta+\\dfrac{\\pi}{2}\\right) \\hat{\\mathbf{x}} + \\sin\\phi \\sin\\left(\\theta+\\dfrac{\\pi}{2}\\right)\\hat{\\mathbf{y}} + \\cos\\left(\\theta+\\dfrac{\\pi}{2}\\right)\\hat{\\mathbf{z}} \\\\ \u0026amp;= \\cos\\phi \\cos\\theta \\hat{\\mathbf{x}} + \\sin\\phi \\cos\\theta\\hat{\\mathbf{y}} - \\sin\\theta\\hat{\\mathbf{z}} \\end{align*} $$\nAzimuthal Angle Direction Unit Vector $\\hat{\\boldsymbol{\\phi}}$ Given $\\hat{\\boldsymbol{\\phi}}=\\hat{\\mathbf{r}} \\times \\hat{\\boldsymbol{\\theta}}$, it follows that:\n$$ \\begin{align*} \\hat{\\boldsymbol{\\phi}} \u0026amp;= \\begin{vmatrix} \\hat{\\mathbf{x}} \u0026amp; \\hat{\\mathbf{y}} \u0026amp; \\hat{\\mathbf{z}} \\\\ \\cos\\phi \\sin\\theta \u0026amp; \\sin\\phi \\sin\\theta\\ \u0026amp; \\cos\\theta \\\\ \\cos\\phi \\cos\\theta \u0026amp; \\sin\\phi \\cos\\theta \u0026amp; -\\sin\\theta \\end{vmatrix} \\\\ \u0026amp;= (-\\sin\\phi \\sin^2\\theta-\\sin\\phi \\cos^2\\theta)\\hat{\\mathbf{x}}+ (\\cos\\phi \\cos^2\\theta + \\cos\\phi \\sin^2\\theta)\\hat{\\mathbf{y}} \\\\ \u0026amp;\\quad +(\\cos\\phi \\sin\\theta \\sin\\phi \\cos\\theta -\\cos\\phi \\sin\\theta \\sin\\phi \\cos\\theta)\\hat{\\mathbf{z}} \\\\ \u0026amp;= -\\sin\\phi (\\sin^2\\theta + \\cos^2\\theta) \\hat{\\mathbf{x}} + \\cos\\phi (\\cos^2 \\theta + \\sin^2\\theta) \\hat{\\mathbf{y}} \\\\ \u0026amp;= -\\sin\\phi \\hat{\\mathbf{x}} + \\cos\\phi \\hat{\\mathbf{y}} \\end{align*} $$\nOr, one can consider it in this way: When determining the direction of $\\hat{\\boldsymbol{\\phi}}$, $\\theta$ does not influence. The direction is solely determined by the values of $r$ and $\\phi$, regardless of the value of $\\theta$. Moreover, the direction of $\\hat{\\boldsymbol{\\phi}}$ is that in which $\\phi$ has increased by $\\dfrac{\\pi}{2}$ from the $\\hat{\\mathbf{r}}$ direction. Therefore, the term $\\theta$ disappears from $\\hat{\\mathbf{r}}$, and instead of $\\phi$, $\\phi + \\dfrac{\\pi}{2}$ is substituted.\n$$ \\begin{align*} \\hat{\\boldsymbol{\\phi}} \u0026amp;= \\cos{(\\phi+\\dfrac{\\pi}{2} )}\\hat{\\mathbf{x}} + \\sin{(\\phi + \\dfrac{\\pi}{2})}\\hat{\\mathbf{y}} \\\\ \u0026amp;= -\\sin \\phi \\hat{\\mathbf{x}}+ \\cos \\phi \\hat{\\mathbf{y}} \\end{align*} $$\n‚ñ†\n","id":152,"permalink":"https://freshrimpsushi.github.io/en/posts/152/","tags":null,"title":"Unit Vectors of the Spherical Coordinate System Expressed in Terms of Unit Vectors of the Cartesian Coordinate System"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition The following expression is called the scalar triple product.\n$$ \\mathbf{A}\\cdot (\\mathbf{B} \\times \\mathbf{C} ) $$\nExplanation A scalar triple product is an operation involving the product of three vectors, where the result is a scalar. The operation resulting in a vector is called vector triple product. To get a scalar result, one must first cross multiply two vectors to produce another vector and then dot multiply it with a different vector.\nBy the commutative property below, the following notation is also used, known as the Grassmann symbol1.\n$$ \\mathbf{A} \\cdot (\\mathbf{B} \\times \\mathbf{C} ) = [\\mathbf{A}, \\mathbf{B}, \\mathbf{C}] = [\\mathbf{A} \\mathbf{B} \\mathbf{C}] $$\nParallelepiped The magnitude of the scalar triple product equals the volume of the parallelepiped formed by the three vectors.\n$$ \\mathbf{A}\\cdot (\\mathbf{B} \\times \\mathbf{C} )=|\\mathbf{A}||\\mathbf{B}\\times \\mathbf{C}| \\cos\\theta $$\n$ |\\mathbf{B} \\times \\mathbf{C}|$ is the area of the base of the parallelepiped, and $|\\mathbf{A} \\cos\\theta|$ is the height. Hence, the scalar triple product, being the product of the area of the base and the height, represents the volume of the parallelepiped.\nA closer examination of this feature reveals that whatever the order of operation, the same value should result. This is because the parallelepiped formed by the three vectors is unique. Therefore, the following equation is valid.\nCommutability The value of the scalar triple product can be cyclically commuted.\n$$ \\mathbf{A}\\cdot (\\mathbf{B} \\times \\mathbf{C} ) = \\mathbf{B}\\cdot (\\mathbf{C} \\times \\mathbf{A} ) =\\mathbf{C}\\cdot (\\mathbf{A} \\times \\mathbf{B} ) $$\nIt can be proven simply using the Levi-Civita symbol.\n$$ \\mathbf{A} \\cdot (\\mathbf{B} \\times \\mathbf{C} ) = A_{i} (B \\times C)_{i} =A_{i} \\epsilon_{ijk} B_{j}C_{k} =\\epsilon_{ijk}A_{i}B_{j}C_{k} $$\n$$ \\mathbf{B} \\cdot (\\mathbf{C} \\times \\mathbf{A} ) = B_{i} (C \\times A)_{i} =B_{i} \\epsilon_{ijk} C_{j}A_{k} =\\epsilon_{ijk}B_{i}C_{j}A_{k} $$\n$$ \\mathbf{C} \\cdot (\\mathbf{A} \\times \\mathbf{B} ) = C_{i} (A \\times B)_{i} =C_{i} \\epsilon_{ijk} A_{j}B_{k} =\\epsilon_{ijk}C_{i}A_{j}B_{k} $$\nDue to the properties of the Levi-Civita symbol, it is understood that the above three expressions yield the same value. Whether it\u0026rsquo;s ABC, BCA, or CAB, as long as the order is correct, the calculation will yield the same result. Conversely, if the order is different, the result will differ because the direction is crucial as the result of the cross product involved in the operation is a vector.\n$$ \\mathbf{A}\\cdot (\\mathbf{B} \\times \\mathbf{C} ) \\neq \\mathbf{A}\\cdot (\\mathbf{C} \\times \\mathbf{B} ) $$\n$$ \\mathbf{A}\\cdot (\\mathbf{B} \\times \\mathbf{C} ) \\neq \\mathbf{B}\\cdot (\\mathbf{A} \\times \\mathbf{C} ) $$\nThe scalar triple product can also be represented in the form of a determinant. In an orthogonal coordinate system, it looks as follows.\n$$ \\mathbf{A}\\cdot (\\mathbf{B} \\times \\mathbf{C} ) = \\epsilon_{ijk}A_{i}B_{j}C_{k}=\\begin{vmatrix} A_{i} \u0026amp; A_{j} \u0026amp; A_{k} \\\\ B_{i}\u0026amp;B_{j}\u0026amp;B_{k} \\\\ C_{i}\u0026amp;C_{j}\u0026amp;C_{k} \\end{vmatrix}=\\begin{vmatrix} A_{x} \u0026amp; A_{y} \u0026amp; A_{z} \\\\ B_{x}\u0026amp;B_{y}\u0026amp;B_{z} \\\\ C_{x}\u0026amp;C_{y}\u0026amp;C_{z} \\end{vmatrix} $$\nTriple product -Wikipedia\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":144,"permalink":"https://freshrimpsushi.github.io/en/posts/144/","tags":null,"title":"Scalar Triple Product"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Formulas The square of the magnitude of the separation vector $\\bcR$ and the gradient of $\\cR ^{n}$ are as follows.\n$$ \\nabla (\\cR^n)=n\\cR^{n-1}\\crH $$\nExplanation It is calculated in the same way as the derivative of a polynomial function, and then just attach the unit vector $\\crH$.\nSince the separation vector is $\\bcR=\\mathbf{r}-\\mathbf{r}^{\\prime}$, it has variables $(x,y,z)$ and $(x^{\\prime},y^{\\prime},z^{\\prime})$. Therefore, attention must be paid when differentiating. Gradients for coordinates with and without superscripts are represented as follows.\n$$ \\begin{align*} \\nabla f\u0026amp;= \\dfrac{\\partial f}{\\partial x}\\hat {\\mathbf{x}} + \\dfrac{\\partial f}{\\partial y} \\hat{\\mathbf{y}} + \\dfrac{\\partial f} {\\partial z} \\hat{\\mathbf{z}} \\\\ \\nabla^{\\prime} f\u0026amp;= \\dfrac{\\partial f}{\\partial x^{\\prime}}\\hat {\\mathbf{x}} + \\dfrac{\\partial f}{\\partial y^{\\prime}} \\hat{\\mathbf{y}} + \\dfrac{\\partial f} {\\partial z^{\\prime}} \\hat{\\mathbf{z}} \\end{align*} $$\nIn Cartesian coordinates, the separation vector is as follows.\n$$ \\begin{align*} \\bcR \u0026amp;= (x-x^{\\prime})\\hat {\\mathbf{x}} + (y-y^{\\prime})\\hat{\\mathbf{y}} + (z-z^{\\prime})\\hat{\\mathbf{z}} \\\\ \\cR \u0026amp;= \\sqrt{ (x-x^{\\prime})^{2} + (y-y^{\\prime})^{2} + (z-z^{\\prime})^{2} } \\\\ \\crH \u0026amp;= \\dfrac{ (x-x^{\\prime})\\hat {\\mathbf{x}} + (y-y^{\\prime})\\hat{\\mathbf{y}} + (z-z^{\\prime})\\hat{\\mathbf{z}}}{\\sqrt{ (x-x^{\\prime})^{2} + (y-y^{\\prime})^{2} + (z-z^{\\prime})^{2} }} \\end{align*} $$\nLet\u0026rsquo;s first examine the results for the case of $n=2$, $n=-1$ and then prove the general case. If the equation is too long, the same part is marked with red brackets ${\\color{red}[ \\ \\ ]}$ for omission.\nProof $\\nabla \\cR^{2} = 2\\bcR=2\\cR\\crH$ $$ \\begin{align*} \\nabla(\\cR ^{2}) =\u0026amp;\\ \\frac{\\partial }{\\partial x} {\\color{red} \\left[ (x-x^{\\prime})^{2}+(y-y^{\\prime})^{2}+(z-z^{\\prime})^{2} \\right]} \\hat{\\mathbf{x}} +\\frac{\\partial }{\\partial y}{\\color{red}[ \\ \\ ]}\\hat{\\mathbf{y}} +\\frac{\\partial }{\\partial z}{\\color{red}[ \\ \\ ]}\\hat{\\mathbf{z}} \\\\ =\u0026amp;\\ 2(x-x^{\\prime})\\hat{\\mathbf{x}}+2(y-y^{\\prime})\\hat{\\mathbf{y}}+2(z-z^{\\prime})\\hat{\\mathbf{z}} \\\\ =\u0026amp;\\ 2 \\left( (x-x^{\\prime})\\hat {\\mathbf{x}} + (y-y^{\\prime})\\hat{\\mathbf{y}} + (z-z^{\\prime})\\hat{\\mathbf{z}} \\right) \\\\ =\u0026amp;\\ 2\\bcR \\\\ =\u0026amp;\\ 2\\cR\\crH \\end{align*} $$\n‚ñ†\n$\\nabla \\dfrac{1}{\\cR} = -\\dfrac{1}{\\cR^{2}}\\crH$ $$ \\begin{align*} \\nabla \\dfrac{1}{\\cR} \u0026amp;= \\dfrac{\\partial }{\\partial x} {\\color{red} \\left[ (x-x^{\\prime})^{2}+(y-y^{\\prime})^{2}+(z-z^{\\prime})^{2} \\right]}^{-\\frac{1}{2}} \\hat{\\mathbf{x}} +\\dfrac{\\partial }{\\partial y}{\\color{red}[ \\ \\ ]}^{-\\frac{1}{2}} \\hat{\\mathbf{y}} +\\dfrac{\\partial }{\\partial z}{\\color{red}[ \\ \\ ]}^{-\\frac{1}{2}} \\hat{\\mathbf{z}} \\\\ \u0026amp;= -\\frac{1}{2}\\dfrac{2(x-x^{\\prime})}{ {\\color{red} \\left[(x-x^{\\prime})^{2}+(y-y^{\\prime})^{2}+(z-z^{\\prime})^{2} \\right]}^{\\frac{3}{2}} }\\hat{\\mathbf{x}} - \\frac{1}{2}\\dfrac{2(y-y^{\\prime})}{ {\\color{red}[ \\ \\ ]}^{\\frac{3}{2}} } \\hat{\\mathbf{y}} -\\frac{1}{2}\\dfrac{2(z-z^{\\prime})}{ {\\color{red}[ \\ \\ ]}^{\\frac{3}{2}} } \\\\ \u0026amp;= -\\dfrac{1}{ {\\color{red} \\left[(x-x^{\\prime})^{2}+(y-y^{\\prime})^{2}+(z-z^{\\prime})^{2} \\right]} } \\left[ \\dfrac{(x-x^{\\prime})}{ {\\color{red}[ \\ \\ ]}^{\\frac{1}{2}} } \\hat{\\mathbf{x}} + \\dfrac{(y-y^{\\prime})}{ {\\color{red}[ \\ \\ ]}^{\\frac{1}{2}} } \\hat{\\mathbf{y}} + \\dfrac{(z-z^{\\prime})}{ {\\color{red}[ \\ \\ ]}^{\\frac{1}{2}} } \\right] \\\\ \u0026amp;= -\\dfrac{1}{ {\\color{red}\\cR^{2}} } \\left[ \\dfrac{(x-x^{\\prime})}{ {\\color{red} \\left[ (x-x^{\\prime})^{2}+(y-y^{\\prime})^{2}+(z-z^{\\prime})^{2} \\right]} ^{\\frac{1}{2}}} \\hat{\\mathbf{x}} + \\dfrac{(y-y^{\\prime})}{ {\\color{red}[ \\ \\ ]}^{\\frac{1}{2}}} \\hat{\\mathbf{y}} +\\dfrac{(z-z^{\\prime})}{ {\\color{red}[ \\ \\ ]}^{\\frac{1}{2}}} \\hat{\\mathbf{z}} \\right] \\\\ \u0026amp;= -\\dfrac{1}{\\cR^{2}} \\dfrac{ (x-x^{\\prime})\\hat{\\mathbf{x}} + (y-y^{\\prime})\\hat{\\mathbf{y}} +(z-z^{\\prime})\\hat{\\mathbf{z}}}{\\sqrt{(x-x^{\\prime})^{2}+(y-y^{\\prime})^{2}+(z-z^{\\prime})^{2}}} \\\\ \u0026amp;= -\\dfrac{1}{\\cR^{2}}\\crH \\end{align*} $$ ‚ñ†\n$\\nabla (\\cR^n)=n\\cR^{n-1}\\crH $ $$ \\begin{align*} \\nabla (\\cR^n) \u0026amp;= \\frac{\\partial}{\\partial x}(\\cR^n)\\hat{\\mathbf{x}}+ \\frac{\\partial}{\\partial y}(\\cR^n)\\hat{\\mathbf{y}}+\\frac{\\partial}{\\partial z}(\\cR^n)\\hat{\\mathbf{z}} \\\\ \u0026amp;= \\frac{\\partial}{\\partial \\cR}(\\cR^n)\\frac{\\partial \\cR}{\\partial x}\\hat{\\mathbf{x}}+ \\frac{\\partial}{\\partial \\cR}(\\cR^n)\\frac{\\partial \\cR}{\\partial y}\\hat{\\mathbf{y}}+\\frac{\\partial}{\\partial \\cR}(\\cR^n)\\frac{\\partial \\cR}{\\partial z}\\hat{\\mathbf{z}} \\end{align*} $$\nThe second equality holds by the chain rule. At this time, the following equation holds.\n$$ \\begin{align*} \\frac{\\partial \\cR}{\\partial x} \u0026amp;=\\frac{\\partial }{\\partial x}[(x-x^{\\prime})^{2} + (y-y^{\\prime})^{2} +(z-z^{\\prime})^{2})]^{\\frac{1}{2}} \\\\ \u0026amp;= \\frac{1}{2}[2(x-x^{\\prime})][(x-x^{\\prime})^{2}+(y-y^{\\prime})^{2}+(z-z^{\\prime})^{2}]^{-\\frac{1}{2}} \\\\ \u0026amp;= \\frac{x-x^{\\prime}}{\\cR} \\end{align*} $$\nSimilarly, $\\dfrac{\\partial \\cR}{\\partial y}= \\dfrac {y-y^{\\prime}}{\\cR}$, $\\dfrac{\\partial \\cR}{\\partial z} = \\dfrac {z-z^{\\prime}}{\\cR}$. Therefore, summarizing gives the following.\n$$ \\begin{align*} \\nabla (\\cR^n) \u0026amp;= \\frac{\\partial}{\\partial \\cR}(\\cR^n)\\frac{x-x^{\\prime}}{\\cR}\\hat{\\mathbf{x}}+ \\frac{\\partial}{\\partial \\cR}(\\cR^n)\\frac{y-y^{\\prime}}{\\cR}\\hat{\\mathbf{y}}+\\frac{\\partial}{\\partial \\cR}(\\cR^n)\\frac{z-z^{\\prime}}{\\cR}\\hat{\\mathbf{z}} \\\\ \u0026amp;= \\frac{\\partial}{\\partial \\cR}(\\cR^n) \\left( \\frac{x-x^{\\prime}}{\\cR}\\hat{\\mathbf{x}}+ \\frac{y-y^{\\prime}}{\\cR}\\hat{\\mathbf{y}}+\\frac{z-z^{\\prime}}{\\cR}\\hat{\\mathbf{z}} \\right) \\\\ \u0026amp;= n\\cR^{n-1}\\crH \\end{align*} $$\n‚ñ†\n","id":142,"permalink":"https://freshrimpsushi.github.io/en/posts/142/","tags":null,"title":"Gradient of the Magnitude of Separation Vectors"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition1 The vector from the source point to the observation point is called the separation vector.\n$$ \\bcR = \\mathbf{r} - \\mathbf{r}^{\\prime} $$\nDescription Source vector $\\mathbf{r}^{\\prime}$: The place where there is a charge or current. That is, it represents the coordinates of the origin of the electromagnetic field. Position vector $\\mathbf{r}$: Represents the coordinates of where the electric field $\\mathbf{E}$ or magnetic field $\\mathbf{B}$ is measured. Separation vector $\\bcR$: The difference between the position vector and the source vector (origin vector). There is no standard notation for the separation vector, and it differs widely. Some people do not designate a symbol and just write $\\mathbf{r} - \\mathbf{r}^{\\prime}$. At the shrimp sushi restaurant, like in Griffiths\u0026rsquo; electrodynamics, it\u0026rsquo;s denoted by the cursive $r$(Kaufmann font) $\\bcR$. Other characters used include the Greek letter eta $\\eta$. The magnitude and unit vector of the separation vector are as follows.\n$$ \\left| \\bcR \\right| = \\cR = \\left| \\mathbf{r} - \\mathbf{r}^{\\prime} \\right| $$\n$$ \\crH = \\dfrac{\\bcR}{\\cR} = \\dfrac{\\mathbf{r} - \\mathbf{r}^{\\prime}}{ \\left| \\mathbf{r} - \\mathbf{r}^{\\prime} \\right|} $$\nIn the Cartesian coordinate system, it looks as follows.\n$$ \\bcR = (x-x^{\\prime})\\hat {\\mathbf{x}} + (y-y^{\\prime})\\hat{\\mathbf{y}} + (z-z^{\\prime})\\hat{\\mathbf{z}} $$ $$ \\cR = \\sqrt{ (x-x^{\\prime})^2 + (y-y^{\\prime})^2 + (z-z^{\\prime})^2 } $$ $$ \\crH = \\dfrac{ (x-x^{\\prime})\\hat {\\mathbf{x}} + (y-y^{\\prime})\\hat{\\mathbf{y}} + (z-z^{\\prime})\\hat{\\mathbf{z}}}{\\sqrt{ (x-x^{\\prime})^2 + (y-y^{\\prime})^2 + (z-z^{\\prime})^2 }} $$\nExample Find the separation vector $\\bcR$ from the source point (2,8,7) to the observation point (4,6,8). Also, calculate its magnitude and unit vector.\n$$ \\bcR=(4,6,8)-(2,8,7)=(2,-2,1)=2\\hat{\\mathbf{x}} -2\\hat{\\mathbf{y}}+\\hat{\\mathbf{z}} $$\n$$ \\cR=\\sqrt{ 2^2+ (-2)^2+1^2}=\\sqrt{4+4+1}=\\sqrt{9}=3 $$\n$$ \\crH=\\left( \\dfrac{2}{3}, - \\dfrac{2}{3},\\dfrac{1}{3} \\right) = \\dfrac{2}{3}\\hat{\\mathbf{x}} -\\dfrac{2}{3}\\hat{\\mathbf{y}}+\\dfrac{1}{3}\\hat{\\mathbf{z}} $$\nDavid J. Griffiths, Introduction to Electrodynamics (Translated by Jin-Seung Kim)(4th Edition). 2014, p9-10\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":141,"permalink":"https://freshrimpsushi.github.io/en/posts/141/","tags":null,"title":"Separation Vector"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem Euler\u0026rsquo;s Formula: $$ { e }^{ ix }= \\cos x + i \\sin x $$\nEuler\u0026rsquo;s Identity: $$ { e }^{ i\\pi }+1=0 $$\nExplanation Euler\u0026rsquo;s Formula is in itself so peculiar that even Euler did not know where it might be used, but nowadays, it is utilized in so many fields that it is difficult to summarize its usefulness. It is even more astonishing when considering it was discovered at a time when imaginary numbers were still not well accepted in academia. Its derivation can be simply done through the Taylor series expansions of the exponential function, sine function, and cosine function.\n$$ { { e ^ x } }=\\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ n } }{ n! } } $$\n$$ \\sin x=\\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ 2n+1 } }{ (2n+1)! }{ { (-1) }^{ n } } } $$\n$$ \\cos x=\\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ 2n } }{ (2n)! }{ { (-1) }^{ n } } } $$\nDerivation (Euler\u0026rsquo;s Formula) $$ \\begin{align*} { e }^{ ix } =\u0026amp; \\sum _{ n=0 }^{ \\infty }{ \\frac { { (ix) } ^{ n } }{ n! } } \\\\ =\u0026amp;\\frac { { (ix) } ^{ 0 } }{ 0! }+\\frac { { (ix) } ^{ 1 } }{ 1! }+\\frac { { (ix) } ^{ 2 } }{ 2! }+\\frac { { (ix) } ^{ 3 } }{ 3! }+\\frac { { (ix) } ^{ 4 } }{ 4! }+ \\cdots \\\\ =\u0026amp;\\frac { 1 }{ 0! }+\\frac { ix }{ 1! }-\\frac { { x }^{ 2 } }{ 2! }-\\frac { i { x }^{ 3 } }{ 3! }+\\frac { { x } ^{ 4 } }{ 4! }+ \\cdots \\\\ =\u0026amp; \\left( \\frac { 1 }{ 0! } - \\frac { { x } ^{ 2 } }{ 2! }+\\frac { { x } ^{ 4 } }{ 4! }-\\frac { { x } ^{ 6 } }{ 6! }+\\cdots \\right) + i\\left( \\frac { x }{ 1! } - \\frac { { x } ^{ 3 } }{ 3! }+\\frac { { x } ^{ 5 } }{ 5! }-\\frac { { x } ^{ 7 } }{ 7! }+\\cdots \\right) \\\\ =\u0026amp; \\cos x + i \\sin x \\end{align*} $$\nTherefore,\n$$ { e }^{ ix }= \\cos x + i \\sin x $$\n‚ñ†\nEspecially, by substituting $x=\\pi$, we get what is called \u0026rsquo;the most beautiful equation in the world,\u0026rsquo; the Euler\u0026rsquo;s identity. Moreover, by manipulating the Euler\u0026rsquo;s identity, we can also find the value of the power of the imaginary unit $i$, that is, ‚ñ∑eq4‚óÄ. Surprisingly, this value is a real number, and the proof goes as follows.\nProof $$ \\begin{align*} \u0026amp;\u0026amp; { e }^{ i\\pi }+1 =\u0026amp; 0 \\\\ \\implies \u0026amp;\u0026amp; { e }^{ i\\pi }=\u0026amp;-1 \\\\ \\implies \u0026amp;\u0026amp; { e }^{ \\frac { i\\pi }{ 2 } } =\u0026amp; \\sqrt { -1 } \\\\ \\implies \u0026amp;\u0026amp; { \\left( { e } ^{ \\frac { i\\pi }{ 2 } } \\right) }^{ i } =\u0026amp; { \\sqrt { -1 } }^{ i } \\\\ \\implies \u0026amp;\u0026amp; { e }^{ \\frac { i\\pi }{ 2 }i } =\u0026amp; { i } ^{ i } \\\\ \\implies \u0026amp;\u0026amp; { i }^{ i } =\u0026amp; { e }^{ -\\frac { \\pi }{ 2 } } \\\\ \\implies \u0026amp;\u0026amp; { i }^{ i } =\u0026amp; \\frac { 1 }{ \\sqrt { { e }^{ \\pi } } } \\end{align*} $$\n‚ñ†\n","id":112,"permalink":"https://freshrimpsushi.github.io/en/posts/112/","tags":null,"title":"Calculus and the Euler Formula"},{"categories":"Ï†ïÏàòÎ°†","contents":"Definition 1 Given integers $a \\equiv b \\pmod{m}$, $\\iff$, $a$, $b$, $m$, there exists an integer $k$ that satisfies $a = b + mk$.\nTheorem Assuming $a_{1} \\equiv b_{1} \\pmod{m}$ and $a_{2} \\equiv b_{2} \\pmod{m}$ are true:\n[1] Addition: $a_{1} + a_{2} \\equiv b_{1} + b_{2} \\pmod{m}$ [2] Subtraction: $a_{1} - a_{2} \\equiv b_{1} - b_{2} \\pmod{m}$ [3] Multiplication: $a_{1} a_{2} \\equiv b_{1} b_{2} \\pmod{m}$ [4] Division: if $\\gcd ( c , m ) = 1$, then $$ ac \\equiv bc \\pmod{m} \\implies a \\equiv b \\pmod{m} $$ [5] Product of Modulos: if $\\gcd ( m_{1} , m_{2} ) = 1$, then $$ \\begin{cases} a \\equiv b \\pmod{ m_{1} } \\\\ a = b \\pmod{ m_{2} } \\end{cases} \\implies a \\equiv b \\pmod{ m_{1} m_{2} } $$ [6] Power of Modulo: if $a \\equiv b \\pmod{m^n}$, then $a \\equiv b \\pmod{m}$ [7] Reduction including modulo: $ax \\equiv ay \\pmod{am} \\iff x \\equiv y \\pmod{m}$ Explanation The equation $a \\equiv b \\pmod{m}$ is called a congruence, and within the Modulo $m$, $a$ is said to be congruent to $b$. The modulo is often simply pronounced as modulo $m$, as $\\pmod{}$ is used as is in the formula.\nIn theorem [4], without the condition $\\gcd(c,m) = 1$, it is not possible to divide both sides by $c$. For example, $ 8 \\equiv 20 \\pmod{12}$ holds, but $ 2 \\equiv 5 \\pmod{12}$, which is divided by $4$ on both sides, does not hold.\nIn dealing with simple number theory problems, $m$ is often set to be a prime number, but as things become complicated, $m$ is set to be a composite number. Therefore, it\u0026rsquo;s necessary to understand the overall properties of congruence equations.\nProof [5] Because of $a \\equiv b \\pmod{m_{1}}$, there exists an integer $n_{1}$ satisfying: $$ a = b + n_{1} m_{1} $$ Because of $a \\equiv b \\pmod{m_{2}}$, there exists an integer $n_{2}$ satisfying: $$ a = b + n_{2} m_{2} $$ Since $m_{1}$ and $m_{2}$ are coprime, for both equations to be satisfied simultaneously, $n_{1}$ must be a multiple of $m_{2}$, and $n_{2}$ must be a multiple of $m_{1}$. Thus, there exists an integer $n_{3}$ satisfying: $$ a = b + n_{3} m_{1} m_{2} $$ Then, by the definition of congruence: $$ a \\equiv b \\pmod{ m_{1} m_{2} } $$\n‚ñ†\n[6] If $a \\equiv b \\pmod{m^n}$, then there exists an integer $k$ satisfying: $$ a = b + m^n k $$ Detaching $m^{n-1}$ gives: $$ a = b + m^{n} k \\cdot n = b + m \\cdot (m^{n-1} k) $$ Thus, there exists an integer $m^{n-1} k$ satisfying: $$ a \\equiv b \\pmod{m} $$\n‚ñ†\n[7] For some integer $k$, $$ \\begin{align*} ax \\equiv ay \\pmod{am} \u0026amp; \\iff ax = ay + amk \\\\ \u0026amp; \\iff x = y + mk \\\\ \u0026amp; \\iff x \\equiv y \\pmod{m} \\end{align*} $$\n‚ñ†\nSilverman. (2012). A Friendly Introduction to Number Theory (4th Edition): p55.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":106,"permalink":"https://freshrimpsushi.github.io/en/posts/106/","tags":null,"title":"Congruences in Number Theory"},{"categories":"Ìï®Ïàò","contents":"Definition A function that satisfies the following two conditions is called the Dirac delta function.\n$$ \\delta (x) = \\begin{cases} 0, \u0026amp; x\\neq 0 \\\\ \\infty , \u0026amp; x=0 \\end{cases} $$\n$$ \\int_{-\\infty}^{\\infty}{\\delta (x) dx}=1 $$\nDescription ‚ÄªBe careful not to confuse it with the Kronecker delta.\nIn engineering, it is called the unit impulse function. Strictly speaking, mathematically, the Dirac delta function is not a function because it diverges to infinity at 0. Griffiths\u0026rsquo; textbook explains it as follows: \u0026ldquo;Since the value of the delta function becomes infinitely large at $x=0$, technically it is not a function. In mathematical literature, it is called a generalized function or distribution.\u0026rdquo; It might be difficult to understand what the delta function is just by looking at the formula above. The picture below will help understand its geometric meaning. To explain it more intuitively, it\u0026rsquo;s like the following. A series of functions whose height is $n$ and width is $\\displaystyle \\frac{1}{n}$, a rectangle $R_{n}(x)$, or whose height is $n$ and base is $\\displaystyle \\frac{2}{n}$, an isosceles triangle $T_{n}(x)$, and the limit of such function series\nIf you have understood what the delta function is, let\u0026rsquo;s look at its characteristics. If the function $f(x)$ is not a delta function but a general function, the value of $f(x)\\delta (x)$ is $0$ everywhere except at $x=0$. (Since $\\because$ $\\delta (x)$ is $0$ everywhere except at $x=0$) That is, the value exists only at $x=0$. Hence, the following equation holds.\n$$ f(x)\\delta (x) = f(0) \\delta (x) $$\nIn integral form\n$$ \\displaystyle{ \\int_{-\\infty}^{\\infty} f(x) \\delta (x) dx = f(0) \\int_{-\\infty}^{\\infty} \\delta (x) dx = f(0)} $$\nTo represent a general case, if we move the peak of the delta function from $x=0$ to $x=a$, it is as follows.\n$$ \\delta (x-a) = \\begin{cases} 0, \u0026amp; x\\neq a \\\\ \\infty , \u0026amp; x=a \\end{cases} $$\n$$ \\displaystyle{ \\int_{-\\infty}^{\\infty}{\\delta (x-a) dx}=1 } $$\n$$ f(x)\\delta (x-a) = f(a) \\delta (x-a) $$\n$$ \\displaystyle{ \\int_{-\\infty}^{\\infty} f(x) \\delta (x-a) dx = f(a)} $$\nIn 3D, the delta function is as follows.\n$$ \\int f( \\mathbf{r} ) \\delta ^3 (\\mathbf{r}-\\mathbf{a}) d\\tau = f(\\mathbf{a}) $$\nIn this case,\n$$ \\int \\delta ^3 (\\mathbf{r} ) d\\tau =1 $$\n$$ \\delta ^3 (\\mathbf{r})=\\delta (\\mathbf{x}) \\delta (\\mathbf{y}) \\delta (\\mathbf{z}) $$\n","id":103,"permalink":"https://freshrimpsushi.github.io/en/posts/103/","tags":null,"title":"Dirac Delta Function"},{"categories":"Ìï®Ïàò","contents":"Definition The function defined as follows $\\Gamma : (0, \\infty) \\to \\mathbb{R}$ is called the Gamma function. $$ \\Gamma (x) := \\int_{0}^{\\infty} t^{x-1} e^{-t} dt $$\nDescription Focusing on the integral in the equation above, it is also referred to as Euler\u0026rsquo;s integral. The Gamma function is famous as an exceedingly important function not just in pure mathematics but also in physics, statistics, etc. It possesses a plethora of interesting properties, but the most representative one is the concept of generalizing factorials to real numbers.\nTheorem The Gamma function as a generalization of factorials For a natural number $n \\in \\mathbb{N}$, $\\Gamma (n) = (n-1)!$ holds.\nProof Strategy: It is sufficient to show that the Gamma function appears in the form of a factorial to address its generalization.\nBy the definition of the Gamma function $$ \\Gamma (n) = \\int_{0}^{\\infty} t^{n-1} e^{-t} dt $$\nCase 1. $n=1$ $$ \\Gamma (1) = \\int_{0}^{\\infty} e^{-t} dt = 1 $$ This can be understood as the same meaning as $0! = 1$.\nCase 2. $n\u0026gt;1$\nBy partial integration $$ \\begin{align*} \\Gamma (n) =\u0026amp; \\int_{0}^{\\infty} t^{n-1} e^{-t} dt \\\\ =\u0026amp; \\left[ -t^{n-1} e^{-t} \\right] _{0} ^{\\infty} - \\int_{0}^{\\infty} -(n-1)t^{n-2} e^{-t} dt \\\\ =\u0026amp; (n-1) \\int_{0}^{\\infty} t^{n-2} e^{-t} dt \\\\ =\u0026amp; (n-1) \\Gamma (n-1) \\end{align*} $$\nSummarizing for both cases $$ \\begin{align*} \\Gamma (n) =\u0026amp; (n-1) \\cdot (n-2) \\cdots 2\\cdot\\Gamma (2) \\\\ =\u0026amp; (n-1) \\cdot (n-2) \\cdots 2\\cdot 1\\cdot \\Gamma (1) \\\\ =\u0026amp; (n-1)! \\end{align*} $$\n‚ñ†\nSee Also Gamma function derivation Gamma function in physics Gamma function as a result of the Laplace transform of a polynomial Euler\u0026rsquo;s reflection formula for the Gamma function Weierstrass infinite product for the Gamma function ","id":95,"permalink":"https://freshrimpsushi.github.io/en/posts/95/","tags":null,"title":"Gamma Function"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Notation The summation sign $\\sum$ is omitted when a subscript is repeated two or more times.\nDescription Also referred to as the Einstein summation convention. It\u0026rsquo;s not really a formula but rather a rule. When doing vector calculations, there are often cases where one needs to write the summation sign $\\sum$ multiple times in a single formula, which can make the equation look cluttered and is very annoying to write by hand. Hence, it is a convention to omit the summation sign when a subscript is repeated more than twice. Of course, care must be taken to avoid confusion in its meaning.\nIf confused, check the left side for what indices are present. If index $i$ is clearly not on the left side, then on the right side, $\\sum \\limits_{i}$ is omitted due to the Einstein notation. Conversely, if the index $j$ is on the left side, then on the right side, the summation over $j$ is not just omitted; it is not there at all.\nExamples Let\u0026rsquo;s say $1,2,3$ each represent $x,y,z$. Suppose vectors $\\mathbf{A} = (A_{1}, A_{2}, A_{3})$ and $\\mathbf{B} = (B_{1}, B_{2}, B_{3})$ are given.\nVector $$ \\begin{align*} \\mathbf{A} \u0026amp;= \\hat{\\mathbf{e}}_{1}A_{1} + \\hat{\\mathbf{e}}_{2}A_{2} + \\hat{\\mathbf{e}}_{3}A_{3} \\\\ \u0026amp;= \\sum \\limits_{i=1}^{3} \\hat{\\mathbf{e}}_{i}A_{i} \\\\ \u0026amp;= \\hat{\\mathbf{e}}_{i}A_{i} \\end{align*} $$\nInner Product of Two Vectors $$ \\begin{align*} \\mathbf{A} \\cdot \\mathbf{B} \u0026amp;= A_{1}B_{1} + A_{2}B_{2} + A_{3}B_{3} \\\\ \u0026amp;= \\sum \\limits_{i=1}^{3} A_{i}B_{i} \\\\ \u0026amp;= A_{i}B_{i} \\end{align*} $$\nIt can be expressed using the Kronecker delta as follows.\n$$ \\mathbf{A} \\cdot \\mathbf{B} = A_{i}B_{i} = \\delta_{ij}A_{i}B_{j} $$\nDivergence of a Vector Function Let\u0026rsquo;s say $\\dfrac{\\partial }{\\partial x_{i}} = \\nabla_{i}$. Then, a similar result to the inner product of two vectors is obtained.\n$$ \\begin{align*} \\nabla \\cdot \\mathbf{A} \u0026amp;= \\dfrac{\\partial A_{1}}{\\partial x_{1}} + \\dfrac{\\partial A_{2}}{\\partial x_{2}} + \\dfrac{\\partial A_{3}}{\\partial x_{3}} \\\\ \u0026amp;= \\nabla_{1} A_{1} + \\nabla_{2} A_{2} + \\nabla_{3} A_{3} \\\\ \u0026amp;= \\sum \\limits_{i=1}^{3} \\nabla_{i} A_{i} \\\\ \u0026amp;= \\nabla_{i}A_{i} \\\\ \u0026amp;= \\delta_{ij}\\nabla_{i}A_{j} \\end{align*} $$\nCross Product of Two Vectors $$ \\begin{align*} \u0026amp; \\mathbf{A} \\times \\mathbf{B} \\\\ =\u0026amp;\\ \\hat{\\mathbf{e}}_{1} \\left( A_{2} B_{3} - A_{3} B_{2} \\right) + \\hat{\\mathbf{e}}_{2} \\left( A_{3} BA_{1} - A_{1} B_{3} \\right) + \\hat{\\mathbf{e}}_{3} \\left( A_{1} B_{2} - A_{2} B_{1} \\right) \\\\ =\u0026amp;\\ \\hat{\\mathbf{e}}_{1} A_{2} B_{3} - \\hat{\\mathbf{e}}_{1} A_{3} B_{2} + \\hat{\\mathbf{e}}_{2} A_{3} B_{1} - \\hat{\\mathbf{e}}_{2} A_{1} B_{3} + \\hat{\\mathbf{e}}_{3} A_{1} B_{2} - \\hat{\\mathbf{e}}_{1} A_{2} B_{1} \\\\ =\u0026amp;\\ \\epsilon_{123} \\hat{\\mathbf{e}}_{1} A_{2} B_{3} + \\epsilon_{132} \\hat{\\mathbf{e}}_{1} A_{3} B_{2} + \\epsilon_{231} \\hat{\\mathbf{e}}_{2} A_{3} B_{1} + \\epsilon_{213} \\hat{\\mathbf{e}}_{2} A_{1} B_{3} + \\epsilon_{312} \\hat{\\mathbf{e}}_{3} A_{1} B_{2} + \\epsilon_{321} \\hat{\\mathbf{e}}_{3} A_{2} B_{1} \\\\ =\u0026amp;\\ \\sum\\limits_{i=1}^{3} \\sum\\limits_{j=1}^{3} \\sum\\limits_{k=1}^{3} \\epsilon_{ijk} \\hat{\\mathbf{e}}_{i} A_{j} B_{k} \\\\ =\u0026amp;\\ \\epsilon_{ijk} \\hat{\\mathbf{e}}_{i} A_{j}B_{k} \\end{align*} $$\nHere, $\\epsilon_{ijk}$ is the Levi-Civita symbol. By the above result, the following equation holds.\n$$ (\\mathbf{A} \\times \\mathbf{B} )_{i} = \\epsilon_{ijk} A_{j}B_{k} $$\nCurl of a Vector Function Let\u0026rsquo;s say $\\dfrac{\\partial }{\\partial x_{i}} = \\nabla_{i}$ again. Then, a similar result to the cross product of two vectors is obtained.\n$$ \\begin{align*} \u0026amp; \\nabla \\times \\mathbf{A} \\\\ =\u0026amp;\\ \\hat{\\mathbf{e}}_{1} \\left( \\nabla_{2} A_{3} - \\nabla_{3} A_{2} \\right) + \\hat{\\mathbf{e}}_{2} \\left( \\nabla_{3} A_{1} - \\nabla_{1} A_{3} \\right) + \\hat{\\mathbf{e}}_{3} \\left( \\nabla_{1} A_{2} - \\nabla_{2} A_{1} \\right) \\\\ =\u0026amp;\\ \\hat{\\mathbf{e}}_{1} \\nabla_{2} A_{3} - \\hat{\\mathbf{e}}_{1} \\nabla_{3} A_{2} + \\hat{\\mathbf{e}}_{2} \\nabla_{3} A_{1} - \\hat{\\mathbf{e}}_{2} \\nabla_{1} A_{3} + \\hat{\\mathbf{e}}_{3} \\nabla_{1} A_{2} - \\hat{\\mathbf{e}}_{1} \\nabla_{2} A_{1} \\\\ =\u0026amp;\\ \\epsilon_{123} \\hat{\\mathbf{e}}_{1} \\nabla_{2} A_{3} + \\epsilon_{132} \\hat{\\mathbf{e}}_{1} \\nabla_{3} A_{2} + \\epsilon_{231} \\hat{\\mathbf{e}}_{2} \\nabla_{3} A_{1} + \\epsilon_{213} \\hat{\\mathbf{e}}_{2} \\nabla_{1} A_{3} + \\epsilon_{312} \\hat{\\mathbf{e}}_{3} \\nabla_{1} A_{2} + \\epsilon_{321} \\hat{\\mathbf{e}}_{3} \\nabla_{2} A_{1} \\\\ =\u0026amp;\\ \\sum\\limits_{i=1}^{3} \\sum\\limits_{j=1}^{3} \\sum\\limits_{k=1}^{3} \\epsilon_{ijk} \\hat{\\mathbf{e}}_{i} \\nabla_{j} A_{k} \\\\ =\u0026amp;\\ \\epsilon_{ijk} \\hat{\\mathbf{e}}_{i} \\nabla_{j} A_{k} \\end{align*} $$\nHere, it\u0026rsquo;s important always to remember that $\\nabla_{i}$ represents differentiation. Normally, swapping the order of vector components doesn‚Äôt cause any problems.\n$$ A_{1}A_{2}A_{3} = A_{2}A_{1}A_{3} $$\nHowever, since $\\nabla_{i}$ is a differentiation, you must never swap the order of vector components with it.\n$$ A_{1}\\nabla_{2}A_{3} \\ne \\nabla_{2}A_{1}A_{3} $$\nFor example, if $\\mathbf{A} = (y,xy,xyz)$, the following result is obtained.\n$$ A_{1}\\nabla_{2}A_{3} = y \\dfrac{\\partial (xyz)}{\\partial y} = xyz \\ne 2xyz = \\dfrac{\\partial (xy^{2}z)}{\\partial y} = \\nabla_{2}A_{1}A_{3} $$\nOf course, since $\\dfrac{\\partial^{2} }{\\partial x\\partial y} = \\dfrac{\\partial^{2} }{\\partial y\\partial x}$, $\\nabla_{1}\\nabla_{2}=\\nabla_{2}\\nabla_{1}$ holds true.\n","id":90,"permalink":"https://freshrimpsushi.github.io/en/posts/90/","tags":null,"title":"Einstein Notation"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Theorem The $\\epsilon_{ijk}$, defined as follows, is referred to as the Levi-Civita symbol.\n$$ \\epsilon_{ijk} = \\begin{cases} +1 \u0026amp; \\text{if} \\ \\epsilon_{123}, \\epsilon_{231}, \\epsilon_{312} \\\\ -1 \u0026amp; \\text{if} \\ \\epsilon_{132}, \\epsilon_{213}, \\epsilon_{321} \\\\ 0 \u0026amp; \\text{if} \\ i=j \\ \\text{or} \\ j=k \\ \\text{or} \\ k=i \\end{cases} $$\nThe $\\delta_{ij}$, defined as follows, is referred to as the Kronecker delta.\n$$ \\delta_{ij} := \\begin{cases} 1,\u0026amp;i=j \\\\ 0, \u0026amp; i\\ne j \\end{cases} $$\nBetween the product of two Levi-Civita symbols and the Kronecker delta, the following relationships hold:\n(a) When one index is the same: $\\epsilon_{ijk}\\epsilon_{ilm} = \\delta_{jl}\\delta_{km} - \\delta_{jm}\\delta_{kl}$\n(b) When two indices are the same: $\\epsilon_{ijk}\\epsilon_{ijm}=2\\delta_{km}$\n(c) When all three indices are the same: $\\epsilon_{ijk}\\epsilon_{ijk}=6$\nExplanation Note that the summation symbol $\\sum$ is omitted throughout this text, adhering to the Einstein notation. This applies to the formulas above as well. Memorizing (a) can be very useful as it\u0026rsquo;s frequently used. A simple way to remember it is as follows.\nProof (a) Let $\\mathbf{e}_{i}$ $(i=1,2,3)$ be the standard unit vectors in 3-dimensional space.\n$$ \\mathbf{e}_{1} = (1, 0, 0),\\quad \\mathbf{e}_{2} = (0, 1, 0),\\quad \\mathbf{e}_{3} = (0, 0, 1) $$\nLet $P_{ijk}$ be a $3 \\times 3$ matrix whose 1st, 2nd, and 3rd rows are $\\mathbf{e}_{i}$, $\\mathbf{e}_{j}$, and $\\mathbf{e}_{k}$, respectively.\n$$ P_{ijk} = \\begin{bmatrix} \\text{\u0026mdash; } \\mathbf{e}_{i} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{j} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{k} \\text{ \u0026mdash;} \\end{bmatrix} $$\nThen, by the properties of determinants, it\u0026rsquo;s easy to see that $\\det P_{ijk} = \\epsilon_{ijk}$. Initially, $P_{123}$ is the identity matrix, hence its determinant is $1$. Moreover, the value of the determinant remains unchanged when swapping different rows an even number of times, hence,\n$$ \\det P_{123} = \\det P_{231} = \\det P_{312} = 1 $$\nWhen different rows are swapped an odd number of times, the sign of the determinant changes, hence,\n$$ \\det P_{132} = \\det P_{213} = \\det P_{321} = -1 $$\nThe determinant of a matrix with two or more identical rows is $0$, hence the rest of the cases are all $0$. Therefore, $\\det P_{ijk} = \\epsilon_{ijk}$ holds true. The product of two Levi-Civita symbols with one identical index can be expressed as follows, using the properties of determinants.\n$$ \\begin{align*} \\epsilon_{ijk}\\epsilon_{ilm} \u0026amp;= \\det \\begin{bmatrix} \\text{\u0026mdash; } \\mathbf{e}_{i} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{j} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{k} \\text{ \u0026mdash;} \\end{bmatrix} \\det \\begin{bmatrix} \\text{\u0026mdash; } \\mathbf{e}_{i} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{l} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{m} \\text{ \u0026mdash;} \\end{bmatrix} \\\\ \u0026amp;= \\det \\begin{bmatrix} \\text{\u0026mdash; } \\mathbf{e}_{i} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{j} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{k} \\text{ \u0026mdash;} \\end{bmatrix} \\det \\begin{bmatrix} \\vert \u0026amp; \\vert \u0026amp; \\vert \\\\ \\mathbf{e}_{i} \u0026amp; \\mathbf{e}_{l} \u0026amp; \\mathbf{e}_{m} \\\\ \\vert \u0026amp; \\vert \u0026amp; \\vert \\end{bmatrix} \u0026amp; (\\because \\det A = \\det A^{T}) \\\\ \u0026amp;= \\det \\left( \\begin{bmatrix} \\text{\u0026mdash; } \\mathbf{e}_{i} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{j} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{k} \\text{ \u0026mdash;} \\end{bmatrix} \\begin{bmatrix} \\vert \u0026amp; \\vert \u0026amp; \\vert \\\\ \\mathbf{e}_{i} \u0026amp; \\mathbf{e}_{l} \u0026amp; \\mathbf{e}_{m} \\\\ \\vert \u0026amp; \\vert \u0026amp; \\vert \\end{bmatrix} \\right) \u0026amp; \\Big(\\because (\\det A) (\\det B) = \\det (AB) \\Big) \\\\ \u0026amp;= \\det \\begin{bmatrix} \\mathbf{e}_{i} \\cdot \\mathbf{e}_{i} \u0026amp; \\mathbf{e}_{i} \\cdot \\mathbf{e}_{l} \u0026amp; \\mathbf{e}_{i} \\cdot \\mathbf{e}_{m} \\\\ \\mathbf{e}_{j} \\cdot \\mathbf{e}_{i} \u0026amp; \\mathbf{e}_{j} \\cdot \\mathbf{e}_{l} \u0026amp; \\mathbf{e}_{j} \\cdot \\mathbf{e}_{m} \\\\ \\mathbf{e}_{k} \\cdot \\mathbf{e}_{i} \u0026amp; \\mathbf{e}_{k} \\cdot \\mathbf{e}_{l} \u0026amp; \\mathbf{e}_{k} \\cdot \\mathbf{e}_{m} \\end{bmatrix} \\end{align*} $$\nSince $\\mathbf{e}_{i}$ are standard unit vectors, $\\mathbf{e}_{i} \\cdot \\mathbf{e}_{j} = \\delta_{ij}$ holds true.\n$$ \\epsilon_{ijk}\\epsilon_{ilm} = \\det \\begin{bmatrix} \\delta_{ii} \u0026amp; \\delta_{il} \u0026amp; \\delta_{im} \\\\ \\delta_{ji} \u0026amp; \\delta_{jl} \u0026amp; \\delta_{jm} \\\\ \\delta_{ki} \u0026amp; \\delta_{kl} \u0026amp; \\delta_{km} \\end{bmatrix} $$\nNote that we are only considering cases where $i$ is different from $j, k, l, m$. This is because if $j, k, l, m$ includes $i$, then $\\epsilon_{ijk}\\epsilon_{ilm} = 0$, rendering the result meaningless. Therefore, the result is\n$$ \\epsilon_{ijk}\\epsilon_{ilm} = \\det \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; \\delta_{jl} \u0026amp; \\delta_{jm} \\\\ 0 \u0026amp; \\delta_{kl} \u0026amp; \\delta_{km} \\end{bmatrix} = \\delta_{jl}\\delta_{km} - \\delta_{jm}\\delta_{kl} $$\n‚ñ†\n(b) This is the case where $l=j$ in (a). Thus, it can be expressed as follows.\n$$ \\epsilon_{ijk}\\epsilon_{ijm} = \\delta_{jj}\\delta_{km} - \\delta_{jm}\\delta_{kj} $$\nHere, $\\delta_{jj}=3$ and $\\delta_{jm}\\delta_{kj}=\\delta_{mk}$ hold, leading to the following.\n$$ \\epsilon_{ijk}\\epsilon_{ijm} = \\delta_{jj}\\delta_{km} - \\delta_{jm}\\delta_{kj} = 3\\delta_{km} - \\delta_{mk} = 2\\delta_{km} $$\n‚ñ†\n(c) This is the case where $m=k$ in (b), hence,\n$$ \\epsilon_{ijk}\\epsilon_{ijk} = \\sum_{k=1}^{3}2\\delta_{kk} = 2\\delta_{11} + 2\\delta_{22} + 2\\delta_{33} = 2 + 2 + 2 = 6 $$\nAlternatively, by explicitly writing out all non-zero terms, the following can be obtained.\n$$ \\begin{align*} \\epsilon_{ijk}\\epsilon_{ijk} \u0026amp;=\\sum \\limits _{i=1} ^{3}\\sum \\limits _{j=1} ^{3}\\sum \\limits _{k=1} ^{1} \\epsilon_{ijk}\\epsilon_{ijk} \\\\ \u0026amp;=\\epsilon_{123}\\epsilon_{123}+\\epsilon_{231}\\epsilon_{231}+\\epsilon_{312}\\epsilon_{312}+\\epsilon_{132}\\epsilon_{132}+\\epsilon_{213}\\epsilon_{213}+\\epsilon_{321}\\epsilon_{321} \\\\ \u0026amp;=6 \\end{align*} $$\n‚ñ†\n","id":88,"permalink":"https://freshrimpsushi.github.io/en/posts/88/","tags":null,"title":"Product of Two Levi-Civita Symbols"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition The $\\delta_{ij}$, defined as follows, is called the Kronecker delta.\n$$ \\delta_{ij} := \\begin{cases} 1,\u0026amp;i=j \\\\ 0, \u0026amp; i\\ne j \\end{cases} $$\nDescription The Kronecker delta is used in many places, and its main role is to indicate only what one wants among all components (elements, possibilities, etc.). For students of physics, it is mainly encountered in the expression for the inner product. This might not be immediately clear, so let\u0026rsquo;s understand it through the example below.\nExample First, let\u0026rsquo;s assume that two vectors $\\mathbf{A}=(A_{1}, A_{2}, A_{3})$, $\\mathbf{B}=(B_{1}, B_{2}, B_{3})$ are given. Then, the inner product of the two vectors is as follows.\n$$ \\mathbf{A} \\cdot \\mathbf{B} = A_{1}B_{1} + A_{2}B_{2} + A_{3}B_{3} $$\nUsing the summation symbol $\\sum$ to express it, it looks like this.\n$$ \\mathbf{A} \\cdot \\mathbf{B} = A_{1}B_{1} + A_{2}B_{2} + A_{3}B_{3} = \\sum \\limits_{i=1}^{3}A_{i}B_{i} $$\nThen, through the following, we can see that the above equation and $\\sum \\limits_{i=1}^{3}\\sum \\limits_{j=1}^{3}\\delta_{ij}A_{i}B_{j}$ are the same.\n$$ \\begin{align*} \\sum _{i=1}^{3}\\sum _{j=1}^{3}\\delta_{ij}A_{i}B_{j} \u0026amp;= \\delta_{11}A_{1}B_{1} + \\delta_{12}A_{1}B_{2} + \\delta_{13}A_{1}B_{3} \\\\ \u0026amp; \\quad+ \\delta_{21}A_{2}B_{1} + \\delta_{22}A_{2}B_{2} + \\delta_{23}A_{2}B_{3} \\\\ \u0026amp; \\quad+ \\delta_{31}A_{3}B_{1} + \\delta_{32}A_{3}B_{2} + \\delta_{33}A_{3}B_{3} \\\\ \u0026amp;= 1\\cdot A_{1}B_{1} + 0 \\cdot A_{1}B_{2} + 0\\cdot A_{1}B_{3} \\\\ \u0026amp; \\quad+ 0\\cdot A_{2}B_{1} + 1\\cdot A_{2}B_{2} + 0\\cdot A_{2}B_{3} \\\\ \u0026amp; \\quad+ 0\\cdot A_{3}B_{1} + 0\\cdot A_{3}B_{2} + 1\\cdot A_{3}B_{3} \\\\ \u0026amp;= A_{1}B_{1} + A_{2}B_{2} + A_{3}B_{3} \\\\ \u0026amp;= \\sum \\limits_{i=1}^{3}A_{i}B_{i} \\\\ \u0026amp;= \\mathbf{A} \\cdot \\mathbf{B} \\end{align*} $$\nApplying the Einstein notation, which omits $\\sum$ when an index appears more than once on one side, results in the following.\n$$ \\delta_{ij}A_{i}B_{j} = \\mathbf{A} \\cdot \\mathbf{B} $$\nSo $\\delta_{ij}A_{i}B_{j}$ and $\\mathbf{A} \\cdot \\mathbf{B}$ are the same, but it may not be clear why such an expression is used. The example above is a very simple formula, so its usefulness may not stand out. However, calculating the inner product of numerous vectors and operations like cross product, gradient, divergence, curl, Laplacian, etc., in electromagnetism will reveal its convenience. If you\u0026rsquo;re a sophomore, you\u0026rsquo;ll naturally come to understand its convenience, so there\u0026rsquo;s no need to force yourself to understand it right now.\nAlso, since there is a value only when both subscripts are the same, if two or more Kronecker deltas are multiplied together, there is a value only when all the indices are the same.\n$$ \\delta_{ij}\\delta_{jk} $$\nIn such a case, a non-$0$ value exists only in the case of $i=j=k$. Also, the Kronecker delta is an example of a $2$th tensor.\nFormulae (a) $\\delta_{ii} = 3$\n(b) $\\delta_{ij}\\delta_{jl} = \\delta_{il}$\n(c) $\\delta_{ii}\\delta_{jj} = 9$\n(d) $\\delta_{ii}\\delta_{jj} = 6 \\quad (i \\ne j)$\nRemember that $\\sum$ is omitted when the same index appears more than once in a term.\nProof (a) By the Einstein notation, the following holds.\n$$ \\delta_{ii} = \\sum \\limits_{i=1}^{3} \\delta_{ii} = \\delta_{11}+\\delta_{22}+\\delta_{33}=3 $$\n‚ñ†\n(b) By the Einstein notation, the following holds.\n$$ \\delta_{ij}\\delta_{jl}=\\sum\\limits_{j=1}^{3}\\delta_{ij}\\delta_{jl}=\\delta_{i1}\\delta_{1l}+\\delta_{i2}\\delta_{2l}+\\delta_{i3}\\delta_{3l} $$\nNow, let\u0026rsquo;s consider the cases where the above value is not $0$.\n$$ i=l=1 \\quad \\text{and} \\quad i=l=2 \\quad \\text{and} \\quad i=l=3 $$\nIf it\u0026rsquo;s the first case, the following holds.\n$$ \\delta_{i1}\\delta_{1l} = 1 \\quad \\text{and} \\quad \\delta_{i2}\\delta_{2l}=\\delta_{i3}\\delta_{3l} = 0 \\\\ \\implies \\delta_{ij}\\delta_{jl} = \\delta_{i1}\\delta_{1l}+\\delta_{i2}\\delta_{2l}+\\delta_{i3}\\delta_{3l} = 1 $$\nIf it\u0026rsquo;s the second case, the following holds.\n$$ \\delta_{i2}\\delta_{2l} = 1 \\quad \\text{and} \\quad \\delta_{i1}\\delta_{1l}=\\delta_{i3}\\delta_{3l} = 0 \\\\ \\implies \\delta_{ij}\\delta_{jl} = \\delta_{i1}\\delta_{1l}+\\delta_{i2}\\delta_{2l}+\\delta_{i3}\\delta_{3l} = 1 $$\nIf it\u0026rsquo;s the third case, the following holds.\n$$ \\delta_{i3}\\delta_{3l} = 1 \\quad \\text{and} \\quad \\delta_{i1}\\delta_{1l}=\\delta_{i2}\\delta_{2l} = 0 \\\\ \\implies \\delta_{ij}\\delta_{jl} = \\delta_{i1}\\delta_{1l}+\\delta_{i2}\\delta_{2l}+\\delta_{i3}\\delta_{3l} = 1 $$\nTherefore, since $\\delta_{ij}\\delta_{jl}$ has a value of $1$ only when it is $i=l$ and otherwise is $0$, the following result is obtained.\n$$ \\delta_{ij}\\delta_{jl} = \\delta_{il} $$\n‚ñ†\n(c) As $\\sum$ is omitted due to the Einstein notation, it is as follows.\n$$ \\begin{align*} \\delta_{ii}\\delta_{jj} \u0026amp;= \\sum\\limits_{i=1}^{3}\\sum\\limits_{j=1}^3{\\delta_{ii}\\delta_{jj}} \\\\ \u0026amp;= \\sum\\limits_{i=1}^{3}{\\delta_{ii} \\sum\\limits_{j=1}^3\\delta_{jj}} \\\\ \u0026amp;= 3\\cdot 3 \\\\ \u0026amp;= 9 \\end{align*} $$\nThe third equality holds because of (a).\n‚ñ†\n(d) As $\\sum$ is omitted due to the Einstein notation, it is as follows.\n$$ \\begin{align*} \\delta_{ii}\\delta_{jj} \u0026amp;= \\sum\\limits_{i=1}^{3}\\sum\\limits_{\\substack{j=1 \\\\ j\\ne i}}^{3}{\\delta_{ii}\\delta_{jj}} \\\\ \u0026amp;= \\delta_{11}\\delta_{22} +\\delta_{11}\\delta_{33} +\\delta_{22}\\delta_{11} +\\delta_{22}\\delta_{33}+\\delta_{33}\\delta_{11}+\\delta_{33}\\delta_{22} \\\\ \u0026amp;= 6 \\end{align*} $$\n‚ñ†\n","id":84,"permalink":"https://freshrimpsushi.github.io/en/posts/84/","tags":null,"title":"Kronecker Delta"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Definition The $\\epsilon_{ijk}$ defined as follows is called the Levi-Civita symbol.\n$$ \\epsilon_{ijk} = \\begin{cases} +1 \u0026amp; \\text{if} \\ \\epsilon_{123}, \\epsilon_{231}, \\epsilon_{312} \\\\ -1 \u0026amp; \\text{if} \\ \\epsilon_{132}, \\epsilon_{213}, \\epsilon_{321} \\\\ 0 \u0026amp; \\text{if} \\ i=j \\ \\text{or} \\ j=k \\ \\text{or} \\ k=i \\end{cases} $$\nDescription While the Kronecker delta only considers whether the indices are equal, the Levi-Civita symbol, as shown in its definition, is also affected by the order of the indices. $\\epsilon_{ijk}$ results in $+1$ if $i$, $j$, $k$ are in ascending order without duplicates$(1\\to 2\\to 3\\to 1)$, $-1$ if in descending order without duplicates$(3\\to 2\\to 1\\to 3)$, and $0$ if there‚Äôs any duplication. Simply put, that\u0026rsquo;s the summary, and if you list all values, there are a total of $3\\times 3\\times 3=27$, out of which $6$ are not $0$.\n$$ \\begin{array}{|c|c|c|c|}\\hline i=1 \u0026amp; k=1 \u0026amp; k=2 \u0026amp; k=3 \\\\ \\hline j=1 \u0026amp; \\epsilon_{111}=0 \u0026amp; \\epsilon_{112}=0 \u0026amp; \\epsilon_{113}=0 \\\\ j=2 \u0026amp; \\epsilon_{121}=0 \u0026amp; \\epsilon_{122}=0 \u0026amp; \\epsilon_{123}=1 \\\\ j=3 \u0026amp; \\epsilon_{131}=0 \u0026amp; \\epsilon_{132}=-1 \u0026amp; \\epsilon_{133}=0 \\\\ \\hline \\end{array}\\quad \\begin{array}{|c|c|c|c|}\\hline i=2 \u0026amp; k=1 \u0026amp; k=2 \u0026amp; k=3 \\\\ \\hline j=1 \u0026amp; \\epsilon_{211}=0 \u0026amp; \\epsilon_{212}=0 \u0026amp; \\epsilon_{213}=-1 \\\\ j=2 \u0026amp; \\epsilon_{221}=0 \u0026amp; \\epsilon_{222}=0 \u0026amp; \\epsilon_{223}=0 \\\\ j=3 \u0026amp; \\epsilon_{231}=1 \u0026amp; \\epsilon_{232}=0 \u0026amp; \\epsilon_{233}=0 \\\\ \\hline \\end{array} \\\\ {} \\\\ \\begin{array}{|c|c|c|c|}\\hline i=3 \u0026amp; k=1 \u0026amp; k=2 \u0026amp; k=3 \\\\ \\hline j=1 \u0026amp; \\epsilon_{311}=0 \u0026amp; \\epsilon_{312}=1 \u0026amp; \\epsilon_{313}=0 \\\\ j=2 \u0026amp; \\epsilon_{321}=-1 \u0026amp; \\epsilon_{322}=0 \u0026amp; \\epsilon_{323}=0 \\\\ j=3 \u0026amp; \\epsilon_{331}=0 \u0026amp; \\epsilon_{332}=0 \u0026amp; \\epsilon_{333}=0 \\\\ \\hline \\end{array} $$\nIt is an example of a $3$th order tensor.\nExamples Cross Product Using the Levi-Civita symbol, the cross product of two vectors can be expressed very simply. In a 3-dimensional orthogonal coordinate system, the cross product of two vectors is as follows.\n$$ \\begin{align*} \\mathbf{A} \\times \\mathbf{B} =\u0026amp;\\ \\hat{\\mathbf{e}}_{x} (A_{y}B_{z}-A_{z}B_{y}) + \\hat{\\mathbf{e}}_{y} (A_{z}B_{x}-A_{x}B_{z}) + \\hat{\\mathbf{e}}_{z} (A_{x}B_{y}-A_{y}B_{x}) \\\\ =\u0026amp;\\ \\begin{vmatrix} \\hat{\\mathbf{e}}_{x} \\quad \\hat{\\mathbf{e}}_{y} \\quad \\hat{\\mathbf{e}}_{z} \\\\ A_{x} \\quad A_{y} \\quad A_{z} \\\\ B_{x} \\quad B_{y} \\quad B_{z} \\end{vmatrix} \\end{align*} $$\nHere, if we set $x=1$, $y=2$, $z=3$, then the cross product of two vectors can be expressed using the Levi-Civita symbol as below.\n$$ \\sum\\limits_{i=1}^{3} \\sum\\limits_{j=1}^{3} \\sum\\limits_{k=1}^{3} {\\epsilon_{ijk} \\hat{\\mathbf{e}}_{i} A_{j}B_{k}} $$\nIf we expand only the terms that are not $0$, it can be written as follows.\n$$ \\begin{align*} \u0026amp; \\sum\\limits_{i=1}^{3} \\sum\\limits_{j=1}^{3} \\sum\\limits_{k=1}^{3} {\\epsilon_{ijk} \\hat{\\mathbf{e}}_{i} A_{j}B_{k}} \\\\ =\u0026amp;\\ \\epsilon_{123} \\hat{\\mathbf{e}}_{1}A_{2}B_{3} + \\epsilon_{132} \\hat{\\mathbf{e}}_{1}A_{3}B_{2} + \\epsilon_{ 231 }\\hat{\\mathbf{e}}_{2}A_{3}B_{1} + \\epsilon_{213}\\hat{\\mathbf{e}}_{2}A_{1}B_{3} + \\epsilon_{312}\\hat{\\mathbf{e}}_{3}A_{1}B_{2} + \\epsilon_{321}\\hat{\\mathbf{e}}_{3}A_{2}B_{1} \\end{align*} $$\nBy substituting $\\epsilon_{123}=\\epsilon_{231}=\\epsilon_{312}=1$, $\\epsilon_{132}=\\epsilon_{213}=\\epsilon_{321}=-1$ and rearranging, we obtain the following.\n$$ \\begin{align*} \u0026amp; \\sum\\limits_{i=1}^{3} \\sum\\limits_{j=1}^{3} \\sum\\limits_{k=1}^{3} {\\epsilon_{ijk} A_{i}B_{j}}\\hat{\\mathbf{e}}_{k} \\\\ =\u0026amp;\\ \\hat{\\mathbf{e}}_{1}\\left( A_{2}B_{3} - A_{3}B_{2} \\right) + \\hat{\\mathbf{e}}_{2}\\left( A_{3}B_{1} - A_{1}B_{3} \\right) + \\hat{\\mathbf{e}}_{3}\\left( A_{1}B_{2} - A_{2}B_{1} \\right) \\end{align*} $$\nFinally, by substituting $1$, $2$, $3$ with $x$, $y$, $z$ respectively, we get the following.\n$$ \\hat{\\mathbf{e}}_{x}\\left( A_{y}B_{z} - A_{z}B_{y} \\right) + \\hat{\\mathbf{e}}_{y}\\left( A_{z}B_{x} - A_{x}B_{z} \\right) + \\hat{\\mathbf{e}}_{z}\\left( A_{x}B_{y} - A_{y}B_{x} \\right) $$\nTherefore, we obtain the below result.\n$$ \\mathbf{A} \\times \\mathbf{ B } = \\sum \\limits_{i=1}^{3} \\sum \\limits_{j=1}^{3} \\sum \\limits_{k=1}^{3} \\epsilon_{ijk}\\hat{\\mathbf{e}}_{i}A_{j}B_{k} $$\nUsing Einstein notation, it can be expressed as follows.\n$$ \\mathbf{A} \\times \\mathbf{ B } = \\epsilon_{ijk}\\hat{\\mathbf{e}}_{i}A_{j}B_{k} $$\nEach component of the cross product can be easily expressed as shown in the above equation, where the $i$ component of $(\\mathbf{A} \\times \\mathbf{B})$ is as follows.\n$$ (\\mathbf{A} \\times \\mathbf {B})_{i}=\\epsilon_{ijk}A_{j}B_{k} $$\nDeterminant The determinant of matrix $3 \\times 3$, $A = [a_{ij}]$ is expressed as follows.\n$$ \\begin{vmatrix} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\\\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \\\\ \\end{vmatrix} = \\sum\\limits_{i,j,k=1}^{3} \\epsilon_{ijk}a_{1i}a_{2j}a_{3k} $$\nThe demonstration is simple. By expanding the determinant and carefully observing the second index of each matrix component, one can see that the index\u0026rsquo;s Levi-Civita symbol corresponds to the sign of each term.\n$$ \\begin{align*} \u0026amp; \\det A \\\\ \u0026amp;= a_{11}(a_{22}a_{33} - a_{23}a_{32}) + a_{12}(a_{23}a_{31} - a_{21}a_{33}) + a_{13}(a_{21}a_{32} - a_{22}a_{31}) \\\\ \u0026amp;= a_{11}a_{22}a_{33} - a_{11}a_{23}a_{32} + a_{12}a_{23}a_{31} - a_{12}a_{21}a_{33} + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31} \\\\ \u0026amp;= a_{1\\textcolor{red}{1}}a_{2\\textcolor{red}{2}}a_{3\\textcolor{red}{3}} - a_{1\\textcolor{red}{1}}a_{2\\textcolor{red}{3}}a_{3\\textcolor{red}{2}} + a_{1\\textcolor{red}{2}}a_{2\\textcolor{red}{3}}a_{3\\textcolor{red}{1}} - a_{1\\textcolor{red}{2}}a_{2\\textcolor{red}{1}}a_{3\\textcolor{red}{3}} + a_{1\\textcolor{red}{3}}a_{2\\textcolor{red}{1}}a_{3\\textcolor{red}{2}} - a_{1\\textcolor{red}{3}}a_{2\\textcolor{red}{2}}a_{3\\textcolor{red}{1}} \\\\ \u0026amp;= \\epsilon_{\\textcolor{red}{123}}a_{1\\textcolor{red}{1}}a_{2\\textcolor{red}{2}}a_{3\\textcolor{red}{3}} + \\epsilon_{\\textcolor{red}{132}}a_{1\\textcolor{red}{1}}a_{2\\textcolor{red}{3}}a_{3\\textcolor{red}{2}} + \\epsilon_{\\textcolor{red}{231}}a_{1\\textcolor{red}{2}}a_{2\\textcolor{red}{3}}a_{3\\textcolor{red}{1}} + \\epsilon_{\\textcolor{red}{213}}a_{1\\textcolor{red}{2}}a_{2\\textcolor{red}{1}}a_{3\\textcolor{red}{3}} + \\epsilon_{\\textcolor{red}{312}}a_{1\\textcolor{red}{3}}a_{2\\textcolor{red}{1}}a_{3\\textcolor{red}{2}} + \\epsilon_{\\textcolor{red}{321}}a_{1\\textcolor{red}{3}}a_{2\\textcolor{red}{2}}a_{3\\textcolor{red}{1}} \\\\ \u0026amp;= \\sum\\limits_{i,j,k=1}^{3} \\epsilon_{ijk}a_{1i}a_{2j}a_{3k} \\end{align*} $$\nFormula (a) When one index is the same: $\\epsilon_{ijk}\\epsilon_{lmk}=\\delta_{il}\\delta_{jm}-\\delta_{im}\\delta_{jl}$\n(b) When two indices are the same: $\\epsilon_{ijk}\\epsilon_{ljk}=2\\delta_{il}$\n(c) When three indices are the same: $\\epsilon_{ijk}\\epsilon_{ijk}=6$\n","id":83,"permalink":"https://freshrimpsushi.github.io/en/posts/83/","tags":null,"title":"Levi-Civita Symbol"},{"categories":"ÏàòÎ¶¨Î¨ºÎ¶¨","contents":"Formulas $$ \\mathbf{A} \\times (\\mathbf{B} \\times \\mathbf{C} ) = \\mathbf{B}(\\mathbf{A} \\cdot \\mathbf{C} )-\\mathbf{C}(\\mathbf{A} \\cdot \\mathbf{B}) $$\n","id":71,"permalink":"https://freshrimpsushi.github.io/en/posts/71/","tags":null,"title":"Vector Triple Product, BAC-CAB Rule"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 $$ \\begin{equation} { { e ^ x } }=\\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ n } }{ n! } } \\end{equation} $$\n$$ \\begin{equation} \\sin x=\\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ 2n+1 } }{ (2n+1)! }{ { (-1) }^{ n } } } \\end{equation} $$\n$$ \\begin{equation} \\cos x=\\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ 2n } }{ (2n)! }{ { (-1) }^{ n } } } \\end{equation} $$\nExplanation The Maclaurin series for the exponential function, sine function, and cosine function can be easily obtained without the use of difficult techniques. Combining these three results in the famous Euler\u0026rsquo;s formula. One tip is to remember that sine contains only odd-degree terms while cosine contains only even-degree terms.\nProof $(1)$ Since\n${ \\left( { { e ^ x } } \\right) ^{ (n) } }={ { e ^ x } }$\n$$ { { e ^ x } }=\\frac { { x } ^{ 0 } }{ 0! } { e }^{ 0 } +\\frac { { x } ^{ 1 } }{ 1! } { e }^{ 0 } +\\frac { { x } ^{ 2 } }{ 2! } { e }^{ 0 } + \\cdots =\\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ n } }{ n! } } $$\n‚ñ†\n$(2)$ Regarding\n$k=0,1,2, \\cdots$\n$$ { (\\sin x) } ^{ (n) }= \\begin{cases} \\cos x \u0026amp; , n=4k+1 \\\\ \\pm \\sin x \u0026amp; , n=2k \\\\ -\\cos x \u0026amp; , n=4k+3 \\end{cases} $$\nTherefore\n$$ { (\\sin 0) } ^{ (n) }=\\begin{cases} 1 \u0026amp; , n=4k+1 \\\\ 0 \u0026amp; , n=2k \\\\ -1 \u0026amp; , n=4k+3 \\end{cases} $$\nAnd when represented as a series\n$$ \\begin{align*} \\sin x =\u0026amp; \\frac { { x } ^{ 0 } }{ 0! }0+\\left( \\frac { { x } ^{ 1 } }{ 1! }1+\\frac { { x } ^{ 2 } }{ 2! }0+\\frac { { x } ^{ 3 } }{ 3! }(-1)+\\frac { { x } ^{ 4 } }{ 4! }0 \\right) + \\cdots \\\\ =\u0026amp; \\frac { x }{ 1! }-\\frac { { x } ^{ 3 } }{ 3! }+\\frac { { x } ^{ 5 } }{ 5! }-\\frac { { x } ^{ 7 } }{ 7! }+ \\cdots \\\\ =\u0026amp; \\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ 2n+1 } }{ (2n+1)! }{ { (-1) }^{ n } } } \\end{align*} $$\nTo summarize, we obtain $\\displaystyle \\sin x=\\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ 2n+1 } }{ (2n+1)! }{ { (-1) }^{ n } } }$.\n‚ñ†\n$(3)$ Regarding\n$k=0,1,2, \\cdots$\n$$ { (\\cos x) }^{ (n) } = \\begin{cases} \\cos x \u0026amp; , n=4k \\\\ \\pm \\sin x \u0026amp; , n\\neq 2k \\\\ -\\cos x \u0026amp; , n=4k+2 \\end{cases} $$\nTherefore\n$$ { (\\cos 0) } ^{ (n) } = \\begin{cases} 1 \u0026amp; , n=4k \\\\ 0 \u0026amp; , n\\neq 2k \\\\ -1 \u0026amp; , n=4k+2 \\end{cases} $$\nAnd when represented as a series\n$$ \\begin{align*} \\cos x =\u0026amp; \\left( \\frac { { x } ^{ 0 } }{ 0! }1+\\frac { { x } ^{ 1 } }{ 1! }0+\\frac { { x } ^{ 2 } }{ 2! }(-1)+\\frac { { x } ^{ 3 } }{ 3! }0 \\right) +\\frac { { x } ^{ 4 } }{ 4! }1+ \\cdots \\\\ =\u0026amp; \\frac { 1 }{ 0! }-\\frac { { x } ^{ 2 } }{ 2! }+\\frac { { x } ^{ 4 } }{ 4! }-\\frac { { x } ^{ 6 } }{ 6! }+ \\cdots \\\\ =\u0026amp; \\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ 2n } }{ (2n)! }{ { (-1) }^{ n } } } \\end{align*} $$\nTo summarize, we obtain $\\displaystyle \\cos x=\\sum _{ n=0 }^{ \\infty }{ \\frac { { x } ^{ 2n } }{ (2n)! }{ { (-1) }^{ n } } }$.\n‚ñ†\nBasic Education Department of Kyungpook National University, Mathematics for Engineers (2012), p221-222\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":59,"permalink":"https://freshrimpsushi.github.io/en/posts/59/","tags":null,"title":"Exponential, Sine, and Cosine Functions' Taylor Series Expansion"},{"categories":"ÍµêÍ≥ºÍ≥ºÏ†ï","contents":"Formulas For the quadratic equation $ax^{2}+bx+c=0$ (where $a\\neq 0$): $$ x=\\dfrac{ -b\\pm \\sqrt { b^{2}-4ac } }{2a} $$\nExplanation Given a quadratic equation, its roots can be easily found through the formula.\nDerivation Strategy: The key to deriving the formula is to convert it into a complete square form. This is explained in great detail for children who are not familiar with math. Simply follow along without questioning, and try to replicate it multiple times.\n$$ \\begin{align*} \u0026amp;\u0026amp; ax^{2} + bx + c =\u0026amp; 0 \\\\ \\implies \u0026amp;\u0026amp; \\ ax^{2} + bx =\u0026amp; -c \\\\ \\implies \u0026amp;\u0026amp; x^{2} + \\dfrac{b}{a}x =\u0026amp; -\\dfrac{c}{a} \\\\ \\implies \u0026amp;\u0026amp; x^{2} + \\dfrac{b}{a}x + \\left( \\dfrac{ b^{2} }{ 4a^{2} }-\\dfrac{ b^{2} }{ 4a^{2} } \\right) =\u0026amp; -\\dfrac{c}{a} \\text{(ÏôÑÏ†ÑÏ†úÍ≥±Íº¥ÏùÑ ÎßåÎì§Í∏∞ ÏúÑÌïú Ìä∏Î¶≠)} \\\\ \\implies \u0026amp;\u0026amp; \\left( x^{2}+\\dfrac{b}{a}x+\\dfrac{ b^{2} }{ 4a^{2} } \\right) -\\dfrac{ b^{2} }{ 4a^{2} } =\u0026amp; -\\dfrac{c}{a} \\\\ \\implies \u0026amp;\u0026amp; \\left( x^{2}+\\dfrac{b}{a}x+\\dfrac{ b^{2} }{ 4a^{2} } \\right) =\u0026amp; \\dfrac{ b^{2} }{ 4a^{2} }-\\dfrac{c}{a} \\\\ \\implies \u0026amp;\u0026amp; \\left( x^{2}+\\dfrac{b}{a}x+\\dfrac{ b^{2} }{ 4a^{2} } \\right) =\u0026amp; \\dfrac{ b^{2} }{ 4a^{2} }-\\dfrac{ 4ac }{ 4a^{2} } \\\\ \\implies \u0026amp;\u0026amp; \\left( x^{2}+\\dfrac{b}{a}x+\\dfrac{ b^{2} }{ 4a^{2} } \\right) =\u0026amp; \\dfrac{ b^{2}-4ac }{ 4a^{2} } \\\\ \\implies \u0026amp;\u0026amp; \\left( x+\\dfrac{b}{2a} \\right) \\left( x+\\dfrac{b}{2a} \\right) =\u0026amp; \\dfrac{ b^{2}-4ac }{ 4a^{2} } \\\\ \\implies \u0026amp;\u0026amp; { \\left( x+\\dfrac{b}{2a} \\right) }^{ 2 } =\u0026amp; \\dfrac{ b^{2}-4ac }{ 4a^{2} } \\\\ \\implies \u0026amp;\u0026amp; \\left( x+\\dfrac{b}{2a} \\right) =\u0026amp; \\pm \\sqrt { \\dfrac{ b^{2}-4ac }{ 4a^{2} } } \\text{(ÏñëÎ≥ÄÏóê Î£®Ìä∏Î•º Ï∑®Ìï®)} \\\\ \\implies \u0026amp;\u0026amp; x+\\dfrac{b}{2a} =\u0026amp; \\pm \\sqrt { \\dfrac{ b^{2}-4ac }{ 4a^{2} } } \\\\ \\implies \u0026amp;\u0026amp; x+\\dfrac{b}{2a} =\u0026amp; \\pm \\dfrac{ \\sqrt { b^{2}-4ac } }{2a} \\\\ \\implies \u0026amp;\u0026amp; x =\u0026amp; -\\dfrac{b}{2a}\\pm \\dfrac{ \\sqrt { b^{2}-4ac } }{2a} \\\\ \\implies \u0026amp;\u0026amp; x =\u0026amp; \\dfrac{ -b\\pm \\sqrt { b^{2}-4ac } }{2a} \\end{align*} $$\n‚ñ†\n","id":56,"permalink":"https://freshrimpsushi.github.io/en/posts/56/","tags":null,"title":"Derivation of the Quadratic Formula Step by Step"},{"categories":"Î≥¥Ï°∞Ï†ïÎ¶¨","contents":"Theorem $$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\\ge { (ax+by) }^{ 2 } $$\nProof $$ \\begin{align*} \u0026amp; ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})-{ (ax+by) }^{ 2 } \\\\ =\u0026amp; {a}^{2}{x}^{2}+{b}^{2}{x}^{2}+{a}^{2}{y}^{2}+{b}^{2}{y}^{2}-{ (ax+by) }^{ 2 } \\\\ =\u0026amp; {b}^{2}{x}^{2}+{a}^{2}{y}^{2}-2axby \\\\ =\u0026amp; { (ay-bx) }^{ 2 } \\\\ \\ge\u0026amp; 0 \\end{align*} $$ Thus, we can summarize as follows. $$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\\ge { (ax+by) }^{ 2 } $$\n‚ñ†\nExplanation This inequality, which can be encountered as early as high school, is used widely across various fields. Its algebraic proof is very straightforward.\nAs can be seen in the proof process, equality holds only in the case of $ay-bx=0$. The Cauchy-Schwarz inequality can also be expressed in the form of an equation, including the terms that appear in the proof.\n$$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})={ (ax+by) }^{ 2 }+{ (ay-bx) }^{ 2 } $$\nThis implies that a sum of some squares can be represented as the product of sums of other squares.\nGeneralization Generalized proof ","id":51,"permalink":"https://freshrimpsushi.github.io/en/posts/51/","tags":null,"title":"Cauchy-Schwarz Inequality Proof"},{"categories":"ÍµêÍ≥ºÍ≥ºÏ†ï","contents":"Theorem $$ \\sin\\left( \\alpha +\\beta \\right) =\\sin\\alpha \\cos\\beta +\\cos\\alpha \\sin\\beta \\\\ \\sin\\left( \\alpha -\\beta \\right) =\\sin\\alpha \\cos\\beta -\\cos\\alpha \\sin\\beta \\\\ \\cos\\left( \\alpha +\\beta \\right) =\\cos\\alpha \\cos\\beta -\\sin\\alpha \\sin\\beta \\\\ \\cos\\left( \\alpha -\\beta \\right) =\\cos\\alpha \\cos\\beta +\\sin\\alpha \\sin\\beta \\\\ \\tan\\left( \\alpha +\\beta \\right) =\\frac { \\tan\\alpha +\\tan\\beta }{ 1-\\tan\\alpha \\tan\\beta } \\\\ \\tan\\left( \\alpha -\\beta \\right) =\\frac { \\tan\\alpha -\\tan\\beta }{ 1+\\tan\\alpha \\tan\\beta } $$\nProof Proof using the Law of Cosines By Pythagoras\u0026rsquo; theorem $$ \\begin{align*} {\\overline { AB } } ^{ 2 } =\u0026amp; {( \\cos \\alpha -\\cos \\beta )}^{ 2 }+{(\\sin\\alpha -\\sin\\beta )}^{ 2 } \\\\ =\u0026amp; 2-2 \\cos \\alpha \\cos \\beta ‚Äì2 \\sin \\alpha \\sin \\beta \\end{align*} $$\nBy the Second Law of Cosines\n$$ \\begin{align*} { \\overline { AB } } ^{ 2 } =\u0026amp; 1^{ 2 }+1^{ 2 }-2\\cos(\\beta -\\alpha ) \\\\ =\u0026amp; 2-2\\cos(\\beta -\\alpha ) \\end{align*} $$\nSince the right-hand sides of both equations are equal\n$$ \\cos(\\beta -\\alpha )=\\cos\\alpha \\cos\\beta +\\sin\\alpha \\sin\\beta $$\n‚ñ†\nThis is the most basic method of proof, and although there are various methods, this is usually the first one encountered.\nProof using the Dot Product of Vectors $$ \\begin{align*} \\cos(\\beta -\\alpha ) =\u0026amp; \\frac { \\vec { OA }\\cdot \\vec { OB } }{ \\left| \\vec { OA } \\right| \\left| \\vec { OB } \\right| } \\\\ =\u0026amp; \\cos\\alpha \\cos\\beta +\\sin\\alpha \\sin\\beta \\end{align*} $$\n‚ñ†\nWriting the dot product of vectors on paper is practically the same as writing a single line. The idea is simple and it\u0026rsquo;s the easiest method.\nProof using Triangles (1) Let the area of the triangle be $S$\n$$ S=\\frac { 1 }{ 2 }ab\\sin(\\alpha +\\beta ) $$\n(2) Adding the areas of the two triangles bounded by the perpendicular\n$$ S=\\frac { 1 }{ 2 }bh\\sin\\alpha +\\frac { 1 }{ 2 }ah\\sin\\beta $$\nSince $h=b\\cos\\alpha =a\\cos\\beta$\n$$ S=\\frac { 1 }{ 2 }ab\\cos\\beta \\sin\\alpha +\\frac { 1 }{ 2 }ab\\cos\\alpha \\sin\\beta $$\nWhat is obtained in (1) and (2) are both $S$, thus canceling $\\frac { 1 }{ 2 }ab$ on both sides gives\n$$ \\sin(\\alpha +\\beta )=\\cos\\beta \\sin\\alpha +\\cos\\alpha \\sin\\beta $$\n‚ñ†\nThe proof using the area of a triangle is simple in idea, and dealing with $h$ is key.\nProof using Rotational Transformation Rotating point $A$ around the origin by $\\beta$\n$$ \\begin{bmatrix} \\cos(\\alpha +\\beta ) \\\\ \\sin(\\alpha +\\beta ) \\end{bmatrix} = \\begin{bmatrix} { \\cos\\beta }\u0026amp;{ -\\sin\\beta } \\\\ { \\sin\\beta }\u0026amp;{ \\cos\\beta } \\end{bmatrix} \\begin{bmatrix} { \\cos\\alpha } \\\\ { \\sin\\alpha } \\end{bmatrix} \\\\ \\implies \\begin{cases} \\cos(\\alpha +\\beta )=\\cos\\beta \\cos\\alpha -\\sin\\beta \\sin\\alpha \\\\ { \\sin(\\alpha +\\beta )=\\sin\\beta \\cos\\alpha +\\cos\\beta \\sin\\alpha } \\end{cases} $$\n‚ñ†\nThis is a proof using rotational transformation. It requires setting the angle slightly differently but it\u0026rsquo;s great since it allows obtaining the cosines and sines at the same time.\nCorollaries These cases are used more often than one might think, so it\u0026rsquo;s convenient to remember them.\n$$ \\begin{align*} \\sin(\\frac { \\pi }{ 4 }+\\frac { \\pi }{ 6 })=\\cos(\\frac { \\pi }{ 4 }-\\frac { \\pi }{ 6 })=\\frac { \\sqrt { 3 }+1 }{ 2\\sqrt { 2 } } \\\\ \\sin(\\frac { \\pi }{ 4 }-\\frac { \\pi }{ 6 })=\\cos(\\frac { \\pi }{ 4 }+\\frac { \\pi }{ 6 })=\\frac { \\sqrt { 3 }-1 }{ 2\\sqrt { 2 } } \\end{align*} $$ Addition formula for tangent: $$ \\tan ( \\theta_1 \\pm \\theta_2) = \\dfrac{\\tan\\theta_1 \\pm \\tan\\theta_2}{1 \\mp \\tan\\theta_1\\tan\\theta_2} $$ Proof of the Addition Formula for Tangent $$ \\tan (\\theta_1 \\pm \\theta2)=\\dfrac{\\sin ( \\theta_1 \\pm \\theta_2)}{\\cos ( \\theta_1 \\pm \\theta_2)} =\\dfrac{ \\sin \\theta_1 \\cos \\theta_2 \\pm \\sin \\theta_2 \\cos \\theta_2}{\\cos \\theta_1 \\cos\\theta_2 \\mp \\sin\\theta_1 \\sin\\theta_2} $$ When dividing both the numerator and the denominator by $\\cos\\theta_1\\cos\\theta_2$ $$ \\dfrac{ \\dfrac{\\sin \\theta_1}{ \\cos \\theta_1} \\pm \\dfrac{\\sin \\theta_2}{ \\cos \\theta_1} } { 1 \\mp \\dfrac{\\sin\\theta_1 \\sin\\theta_2}{\\cos\\theta_1\\cos\\theta_2 }} = \\dfrac{ \\tan\\theta_1 \\pm \\tan\\theta_2}{1 \\mp \\tan\\theta_1\\tan\\theta_2} $$\n‚ñ†\n","id":44,"permalink":"https://freshrimpsushi.github.io/en/posts/44/","tags":null,"title":"Addition Formula for Trigonometric Functions: Various Proofs"},{"categories":"Ìï®Ïàò","contents":"Definitions A function $f(x)$ that satisfies $f(-x) = f(x)$ is called an Even function. A function $f(x)$ that satisfies $f(-x) = -f(x)$ is called an Odd function. Description Even functions are symmetric about the $y$ axis in the coordinate plane, while Odd functions are symmetric about the origin $O$.\nFor example, among the trigonometric functions, $\\sin$ is Odd and $\\cos$ is Even. Differentiating $\\sin$ yields $\\cos$, and differentiating $\\cos$ yields $\\sin$. It might seem unnecessary, but it\u0026rsquo;s useful in situations where you need not know the function exactly.\nDerivatives If $f$ is differentiable over all real numbers, the following holds:\n[1] The derivative of an Even function is an Odd function. [2] The derivative of an Odd function is an Even function. Derivation Let $f(x)$ be any Odd function, and $g(x)$ be any Even function.\nBecause of $f(x)=-f(-x)$, we have $$ f ' (x)=f ' (-x) $$ Because of $g(x)=g(-x)$, we have $$ g ' (x)=-g ' (-x) $$\n‚ñ†\nCorollary Another good thing to know is that the derivative of an Even function $g(x)$, $g ' (x)$, is always $g ' (0)=0$.\nProof $$ \\begin{align*} \u0026amp; g ' (x)=-g ' (-x) \\\\ \\implies\u0026amp; g ' (0)=-g ' (-0) \\\\ \\implies\u0026amp; 2g ' (0)=0 \\\\ \\implies\u0026amp; g ' (0)=0 \\end{align*} $$\n‚ñ†\n","id":40,"permalink":"https://freshrimpsushi.github.io/en/posts/40/","tags":null,"title":"Odd Functions and Even Functions"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Summary1 If the function $f(x)$ is continuous at $[a,b]$ and differentiable at $(a,b)$ and if $f(a)=f(b)$, then there exists at least one $c$ in $(a,b)$ that satisfies $f ' (c)=0$.\nDescription In high school courses, it is introduced only as an auxiliary lemma to prove the mean value theorem and is not used at all otherwise. However, beyond the high school level, it is sometimes used as an auxiliary lemma. Although the mean value theorem is more general, when there is no need to use complex forms like $\\displaystyle f '(c) = {{f(b) - f(a)} \\over {b - a}}$, it makes the proof more concise.\nProof Strategy: Apply Fermat\u0026rsquo;s theorem by dividing it into two cases: when $f(x)$ is a constant function and when it is not.\nCase 1. $f(x)$ is a constant function\nSince $f ' (x)=0$, there exists at least one $c$ in $(a,b)$ that satisfies $f ' (c)=0$.\nCase 2. When $f(x)$ is not a constant function\nSince $f(x)$ has a maximum or minimum and is differentiable in $(a,b)$, there exists a critical point $c$ satsifying $f ' (c)$.\nFermat\u0026rsquo;s Theorem\nIf function $f(x)$ has a maximum or minimum at $x=c$ and $f ' (c)$ exists, then $f ' (c) = 0$\nThe critical point $c$ must satisfy $f ' (c) = 0$ by Fermat\u0026rsquo;s theorem.\nTherefore, whether $f(x)$ is a constant function or not, there exists at least one $c$ in $(a,b)$ that satisfies $f ' (c)=0$.\n‚ñ†\nÍ≤ΩÎ∂ÅÎåÄÌïôÍµê Í∏∞Ï¥àÍµêÏú°Ïõê, Ïù¥Í≥µÌïôÎèÑÎ•º ÏúÑÌïú ÎåÄÌïôÏàòÌïô (2012), p65\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":36,"permalink":"https://freshrimpsushi.github.io/en/posts/36/","tags":null,"title":"Proof of Rolle's Theorem in Calculus"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 If a function $f(x)$ is continuous at $[a,b]$ and differentiable up to $n$ times at $(a,b)$, then there exists $\\xi \\in (a,b)$ that satisfies\n$$ \\begin{align*} f(b) =\u0026amp; \\sum_{k=0}^{n-1} {{(b-a)^{k}\\over{k!}}{f^{(k)}( a )}} + {(b-a)^{n}\\over{n!}}{f^{(n)}(\\xi)} \\\\ =\u0026amp; {f(a)} + {(b-a)f ' (a)} + \\cdots + {(b-a)^{n-1}\\over{(n-1)!}}{f^{(n-1)}(a)} + {(b-a)^{n}\\over{(n)!}}{f^{(n)}(\\xi)} \\end{align*} $$\nExplanation This theorem, which is widely used throughout mathematics, has lent its name to the Taylor series. In terms of being differentiated $n$ times, it can be considered a generalization of the mean value theorem.\nCustomarily, when using the Taylor theorem, $c$ is not used, but $\\xi$ is used instead.\nProof Let\u0026rsquo;s consider\n$$ \\begin{align*} f(b) :=\u0026amp; {(b-a)^0\\over{0!}}{f(a)} + {(b-a)^1\\over{1!}}{f ' (a)} + {(b-a)^2\\over{2!}}{f '' (a)} \\\\ \u0026amp;+ \\cdots + {(b-a)^{n-1}\\over{(n-1)!}}{f^{(n-1)}(a)} + {(b-a)^{n}\\over{(n)!}}c \\end{align*} $$\nShowing $c={f^{(n)}(\\xi)}$ concludes the proof. Let\u0026rsquo;s define function $g$ as follows.\n$$ \\begin{align*} g(x):=\u0026amp; -f(b) + f(x) + {(b-x)^1\\over{1!}}{f ' (x)} + {(b-x)^2\\over{2!}}{f '' (x)} \\\\ \u0026amp; + \\cdots + {(b-x)^{n-1}\\over{(n-1)!}}{f^{(n-1)}(x)} + {(b-x)^{n}\\over{(n)!}}c \\\\ =\u0026amp; -f(b) + \\sum_{k=0}^{n-1}{(b-x)^{k}\\over{(k)!}}{f^{(k)}(x)} + {(b-x)^{n}\\over{(n)!}}c \\end{align*} $$\n$g$ is continuous at $[a,b]$, differentiable at $(a,b)$, and by definition of $c$, it is $g(b)=g(a)=0$.\nRolle\u0026rsquo;s Theorem: If function $f(x)$ is continuous at $[a,b]$, differentiable at $(a,b)$, and $f(a)=f(b)$, then there exists at least one $\\xi$ in $(a,b)$ that satisfies $f ' (\\xi)=0$.\nIf $h(x)$ is set as\n$$ \\begin{align*} h(x):=\u0026amp; \\left[ \\sum_{k=0}^{n-1}{(b-x)^{k}\\over{(k)!}}{f^{(k)}(x)} \\right] ' \\\\ =\u0026amp; \\left[ {(b-x)^{0}\\over{(0)!}}{f^{(0)}(x)} + {(b-x)^{1}\\over{(1)!}}{f^{(1)}(x)} + \\cdots + {(b-x)^{n-1}\\over{(n-1)!}}{f^{(n-1)}(x)} \\right] ' \\\\ =\u0026amp; \\left[ f (x) + {(b-x)^{1}\\over{(1)!}}{f^{(1)}(x)} + \\cdots + {(b-x)^{n-1}\\over{(n-1)!}}{f^{(n-1)}(x)} \\right] ' \\\\ =\u0026amp; f^{(1)} (x) - \\left[ f^{(1)} (x) + {(b-x)^{1}\\over{(1)!}}{f^{(2)}(x)} \\right] \\\\ \u0026amp; + \\left[ - {(b-x)^{1}\\over{(1)!}} f^{(2)} (x) + {(b-x)^{2}\\over{(2)!}}{f^{(3)}(x)} \\right] \\\\ \u0026amp; \\vdots \\\\ \u0026amp; + \\left[ - {(b-x)^{n-3}\\over{(n-3)!}} f^{(n-2)} (x) + {(b-x)^{n-2}\\over{(n-2)!}}{f^{(n-1)}(x)} \\right] \\\\ \u0026amp; + \\left[ - {(b-x)^{n-2}\\over{(n-2)!}} f^{(n-1)} (x) + {(b-x)^{n-1}\\over{(n-1)!}}{f^{(n)}(x)} \\right] \\\\ =\u0026amp; {(b-x)^{n-1}\\over{(n-1)!}}{f^{(n)}(x)} \\end{align*} $$\nand since $\\displaystyle g ' (x) = 0 + h(x) + {(b-x)^{n-1}\\over{(n-1)!}}c$, by Rolle\u0026rsquo;s theorem,\n$$ \\begin{align*} g ' (\\xi) =\u0026amp; h(\\xi) - {(b-\\xi)^{n-1}\\over{(n-1)!}}c \\\\ =\u0026amp; {(b-\\xi)^{n-1}\\over{(n-1)!}}{f^{(n)}(\\xi)} - {(b-\\xi)^{n-1}\\over{(n-1)!}}c \\\\ =\u0026amp; 0 \\end{align*} $$\nthere exists at least one $\\xi$ in $(a,b)$ that satisfies it. Thus,\n$$ \\begin{align*} \u0026amp;\u0026amp; {(b-\\xi)^{n-1}\\over{(n-1)!}}{f^{(n)}(\\xi)} - {(b-\\xi)^{n-1}\\over{(n-1)!}}c =\u0026amp; 0 \\\\ \\implies \u0026amp;\u0026amp; {(b-\\xi)^{n-1}\\over{(n-1)!}}{f^{(n)}(\\xi)} =\u0026amp; {(b-\\xi)^{n-1}\\over{(n-1)!}}c \\\\ \\implies \u0026amp;\u0026amp; {f^{(n)}(\\xi)} =\u0026amp; c \\end{align*} $$\nSince $c={f^{(n)}(\\xi)}$ is shown, the proof is concluded.\n‚ñ†\nThe proof is as shown above; however, a more commonly used form is as follows. Of course, as $x \\in [a,b]$ and set as $x_{0} \\in (a,b)$, it essentially becomes $[x_{0} , x] \\subset [a,b]$.\nTaylor\u0026rsquo;s Theorem\nIf a function $f(x)$ is continuous at $[a,b]$ and differentiable up to $n$ times at $(a,b)$, then for $x_{0} \\in (a,b)$,\n$$ f(x) = \\sum_{k=0}^{n-1} {{( x - x_{0} )^{k}\\over{ k! }}{f^{(k)}( x_{0} )}} + {(x - x_{0} )^{n}\\over{ n! }}{f^{(n)}(\\xi)} $$\nthere exists $\\xi \\in (a,b)$ that satisfies it.\nSee Also Taylor\u0026rsquo;s theorem for multivariable functions Kyungpook National University Basic Education Center, Mathematics for Engineering Students (2012), p67-68\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":41,"permalink":"https://freshrimpsushi.github.io/en/posts/41/","tags":null,"title":"Proof of Taylor's Theorem"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 If the function $f(x)$ is continuous at $[a,b]$ and differentiable at $(a,b)$, then there exists at least one $c$ in $(a,b)$ that satisfies $\\displaystyle f '(c)={{f(b)-f(a)}\\over{b-a}}$.\nDescription It\u0026rsquo;s not just commonly used; it\u0026rsquo;s so famous that it\u0026rsquo;s abbreviated as MVT. The term \u0026lsquo;mean value\u0026rsquo; comes from the idea that there is a point where the derivative equals the average rate of change over the entire interval. The concept of the average is so useful that there are various modified forms of it for application in many fields.\nProof Let $\\displaystyle m:= {{f(b)-f(a)}\\over{b-a}}$ and define $g(x):=f(x)-mx$, then $g(b)=g(a)$ and $g(x)$ is differentiable.\nRolle\u0026rsquo;s Theorem\nIf the function $f(x)$ is continuous at $[a,b]$ and differentiable at $(a,b)$, and if $f(a)=f(b)$, then there exists at least one $c$ in $(a,b)$ that satisfies $f ' (c)=0$.\nBy Rolle\u0026rsquo;s Theorem, there exists at least one $c$ in $(a,b)$ that satisfies $g ' (c)=0$, and since $g ' (x)=f ' (x) - m$, it follows that $g ' (c) = f '(c) - m = 0$. By rearranging $f ' (c) -m = 0$ into $(-m)$, we can find that there exists at least one $c$ in $(a,b)$ satisfying $\\displaystyle f '(c) = m = {{f(b)-f(a)}\\over{b-a}}$.\n‚ñ†\nSee Also Cauchy\u0026rsquo;s Mean Value Theorem The Mean Value Theorem for Integrals Gauss\u0026rsquo;s Mean Value Theorem College of Basic Education, Kyungpook National University, College Mathematics for Engineers (2012), p65-66\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":37,"permalink":"https://freshrimpsushi.github.io/en/posts/37/","tags":null,"title":"Proof of the Mean Value Theorem in Calculus"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem1 A function $f$ that is infinitely differentiable around point $a$, a necessary and sufficient condition for $\\displaystyle f(x) = \\sum_{n=0}^{\\infty} {{f^{(n)} (a)}\\over{n!}} {(x-a)}^n$ is that for some $\\xi \\in \\mathscr{H} \\left\\{ x , a \\right\\}$\n$$ \\lim_{n \\to \\infty} {{f^{(n)} (\\xi)}\\over{n!}} {(x-a)}^n = 0 $$\nwhere $\\xi \\in \\mathscr{H} \\left\\{ x , a \\right\\}$ means that $\\xi$ is in either $(x,a)$ or $(a,x)$.\nExplanation The Taylor theorem often represents a function that can be infinitely differentiated as an infinite series. This is called a Taylor series, and specifically, when $a=0$, it is called a Maclaurin series. The Taylor series is also commonly referred to as Taylor Formula, Taylor Expansion.\nProof Taylor theorem\nIf a function $f(x)$ is continuous at $[a,b]$ and differentiable $n$ times at $(a,b)$, then for $x_{0} \\in (a,b)$\n$$ f(x) = \\sum_{k=0}^{n-1} {{( x - x_{0} )^{k}\\over{ k! }}{f^{(k)}( x_{0} )}} + {(x - x_{0} )^{n}\\over{ n! }}{f^{(n)}(\\xi)} $$\nthere exists a $\\xi \\in (a,b)$ that satisfies the above.\nBy the Taylor theorem,\n$$ f(x) = \\sum_{k=0}^{n-1} {{( x - a )^{k}\\over{ k! }}{f^{(k)}( a )}} + {(x - a )^{n}\\over{ n! }}{f^{(n)}(\\xi)} $$\nthere exists at least one $\\xi$ between $x$ and $a$ that satisfies the above. Since the function $f$ is infinitely differentiable,\n$$ f(x) =\\lim_{n \\to \\infty} \\left[ \\sum_{k=0}^{n-1} {{f^{(k)} (a)}\\over{k!}} {(x-a)}^k + {{f^{(n)} (a)}\\over{n!}} {(x-a)}^n \\right] $$\nIf $\\displaystyle \\lim_{n \\to \\infty} {{f^{(n)} (a)}\\over{n!}} {(x-a)}^n = 0$ then,\n$$ f(x) =\\lim_{n \\to \\infty} \\sum_{k=0}^{n-1} {{f^{(k)} (a)}\\over{k!}} {(x-a)}^k = \\sum_{n=0}^{\\infty} {{f^{(n)} (a)}\\over{n!}} {(x-a)}^n $$\n‚ñ†\nKyungpook National University Basic Education Center, College Mathematics for Engineers (2012), p220-221\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":42,"permalink":"https://freshrimpsushi.github.io/en/posts/42/","tags":null,"title":"Taylor Series and Maclaurin Series"},{"categories":"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô","contents":"Theorem 1 Sample Space $S$ and Event $A$, Probability $P$ If $\\left\\{ S_1, S_2, \\cdots ,S_n \\right\\}$ is a partition of $S$, then the following holds. $$ P(S_k|A)=\\frac { P(S_k)P(A|S_k) }{ \\sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$\nDefinition The right-hand side of Bayes\u0026rsquo; theorem, $P \\left( S_{k} \\right)$, is called the Prior Probability, and the left-hand side, $P \\left( S_{k} | A \\right)$, is called the Posterior Probability. The probability distributions formed by these probabilities are called Prior Distribution and Posterior Distribution, respectively.\nExplanation Also called Bayes\u0026rsquo; Rule, this theorem can be proven quite easily using only two laws, but its applications are extensive. The so-called Bayesian Paradigm divides the field of statistics into two schools of thought, emphasizing its importance cannot be overstated.\nWhat we want to know is the left-hand side of the above equation. What we already know are the probabilities of event $A$ and the partitions $S_k$ of sample space $S$ occurring, and the probability of $A$ occurring when each of these partitions occurs. In short, we start with everything we know about $S_k$ and its impact on $A$. Bayes\u0026rsquo; theorem reverses this, allowing us to understand the impact of $A$ on each of these partitions. If this sounds complicated, it\u0026rsquo;s enough to focus on wanting to find out the left-hand side.\nProof By the Law of Total Probability and the Multiplication Rule of Probability, we obtain the following equation. $$ \\begin{align*} P(A)=\u0026amp;P(A\\cap S_1)+P(A\\cap S_2)+\u0026hellip;+P(A\\cap S_n) \\\\ =\u0026amp;P(S_1)P(A|S_1)+P(S_2)P(A|S_2)+\u0026hellip;+P(S_n)P(A|S_n) \\\\ =\u0026amp; \\sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } \\end{align*} $$ Taking the reciprocal of both sides gives us $$ \\begin{align*} \u0026amp; \\frac { 1 }{ \\sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } }=\\frac { 1 }{ P(A) } \\\\ \\implies\u0026amp; \\frac { P(A\\cap S_k) }{ \\sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } }=\\frac { P(A\\cap S_k) }{ P(A) } \\\\ \\implies\u0026amp; \\frac { P(S_k)P(A|S_k) }{ \\sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } }=P(S_k|A) \\end{align*} $$\n‚ñ†\nHogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p23.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":29,"permalink":"https://freshrimpsushi.github.io/en/posts/29/","tags":null,"title":"Proof of Bayes' Theorem and Prior, Posterior Distributions"},{"categories":"ÍµêÍ≥ºÍ≥ºÏ†ï","contents":"Formulas $$ d=\\frac { |2k| }{ \\sqrt { m^{ 2 }+1 } } $$\nExplanation When solving problems involving the tangent to a conic section, one often needs to calculate the distance between two tangents. While it\u0026rsquo;s not particularly challenging, thanks to the formula for the distance from a given point to a line, having an easy and quick formula for this distance can help to reduce calculation time.\nDerivation Let\u0026rsquo;s assume two parallel lines have the equation $y=mx\\pm k$. The distance from any point $(x,y)$ to the line $y=mx+k$ is $$ \\frac { |mx-y+k| }{ \\sqrt { m^{ 2 }+1 } } $$ For a point $(x_1,y_1)$ on the line $y=mx-k$, we have $$ k=mx_1-y_1 $$ Substituting $mx_1-y_1=k$ into the distance formula, we get $$ {{ |mx_{1}-y_{1}+k| }\\over{ \\sqrt { m^{ 2 }+1 } }} = {{ |k+k| }\\over{\\sqrt { m^{ 2 }+1 }}} $$ Therefore, the distance between the two parallel lines $y=mx\\pm k$ is $$ \\frac { |2k| }{ \\sqrt { m^{ 2 }+1 } } $$\n‚ñ†\n","id":4,"permalink":"https://freshrimpsushi.github.io/en/posts/4/","tags":null,"title":"Derivation of the Formula to Calculate the Distance Between Two Parallel Lines"},{"categories":"Î≥µÏÜåÌï¥ÏÑù","contents":"Theorem 1 Let $\\left\\{ a_{i} \\right\\}_{i=0}^{n} \\subset \\mathbb{R}$ such that $a_0 \u0026gt; a_1 \u0026gt; \\cdots \u0026gt; a_n \u0026gt; 0$. Then for the polynomial function $$ P(z) := a_0 + a_1 z + \\cdots + a_{n-1} z^{n-1} + a_n z^n $$ all roots $z \\in \\mathbb{C}$ satisfy $|z| \\ge 1$.\nProof If there is a root of $P(z) = 0$ at $z=1$, then we have $\\displaystyle 0 = P(1) = \\sum_{i=0}^{n} a_{i} \u0026gt; 0$, so the root must be $z \\ne 1$. Multiply both sides of the equation $P(z) = 0$ by $z$ and subtract from the original equation to express $a_0$ as $$ a_0 = (1-z)P(z) + (a_0 - a_1) z + \\cdots + (a_{n-1} - a_n) z^n + a_n z^{n+1} $$ If we assume that a root $z \\ne 1$ of $P(z) = 0$ satisfies $|z| \u0026lt; 1$ given that $a_0 \u0026gt; a_1 \u0026gt; \\cdots \u0026gt; a_n \u0026gt; 0$, then we have $$ \\begin{align*} \u0026amp; |a_0| \u0026lt; |(1-z)P(z)| + (a_0 - a_1) + \\cdots + (a_{n-1} - a_n) + a_n \\\\ \\implies\u0026amp; |a_0| \u0026lt; |(1-z)P(z)| + a_0 + (- a_1 + a_1) + \\cdots + (- a_{n-1} + a_{n-1} )+ (- a_n + a_n ) \\\\ \\implies\u0026amp; a_0 = |a_0| \u0026lt; |(1-z)P(z)| + a_0 \\\\ \\implies\u0026amp; 0 \u0026lt; |(1-z)P(z)| \\end{align*} $$ Yet, since we assumed $z \\ne 1$ is a root of $P(z) = 0$, we find a contradiction $$ 0 \u0026lt; |(1-z)P(z)| = 0 $$ This indicates the wrongness of the assumption that $| z | \u0026lt; 1$, hence we must have $|z | \\ge 1$.\n‚ñ†\nOsborne. (1999). Complex variables and their applications: p. 6.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":5,"permalink":"https://freshrimpsushi.github.io/en/posts/5/","tags":null,"title":"Ernestrom-Kakeya Theorem Proof"},{"categories":"Ìï¥ÏÑùÍ∞úÎ°†","contents":"Theorem The harmonic series diverges.\n$$ \\sum _{ n=1 }^{ \\infty }{ \\frac { 1 }{ n } }=\\infty $$\nDescription At first glance, the harmonic series appears as if it would converge since its terms continue to decrease in value. However, Oresme elegantly and simply proved that it diverges. This fact is often used as an example to explain the concept of absolute convergence, where the alternating harmonic series converges as shown in $\\displaystyle \\sum_{n=1}^{\\infty} {{(-1)^{n-1}} \\over {n}} = 1- {1 \\over 2} + { 1 \\over 3} - { 1 \\over 4 }+ \\cdots = \\ln 2 \u0026lt; \\infty$, whereas the series of their absolute values, the harmonic series, holds true for $\\displaystyle \\sum_{n=1}^{\\infty} \\left| {{(-1)^{n-1}} \\over {n}} \\right| = \\sum _{ n=1 }^{ \\infty }{ \\frac { 1 }{ n } }=\\infty$. Therefore, it serves as the simplest example to demonstrate that convergence does not necessarily imply absolute convergence. It also provides a counterexample to show that the inverse of the proposition \u0026ldquo;If an infinite series converges, then its sequence converges to 0\u0026rdquo; does not hold.\nProof The essence of the proof lies in the fact that the sum of infinitely many $1/2$ diverges, and yet, the harmonic series is greater than this sum. The proof is straightforward and neat.\n$$ \\begin{align*} \u0026amp; \\frac { 1 }{ 1 }+\\frac { 1 }{ 2 }+\\frac { 1 }{ 3 }+\\frac { 1 }{ 4 }+\\frac { 1 }{ 5 }+\\frac { 1 }{ 6 }+\\frac { 1 }{ 7 }+\\frac { 1 }{ 8 }+\\frac { 1 }{ 9 }+\\cdots \\\\ =\u0026amp; \\frac { 1 }{ 1 }+\\frac { 1 }{ 2 }+\\left( \\frac { 1 }{ 3 }+\\frac { 1 }{ 4 } \\right) +\\left( \\frac { 1 }{ 5 }+\\frac { 1 }{ 6 }+\\frac { 1 }{ 7 }+\\frac { 1 }{ 8 } \\right) +\\frac { 1 }{ 9 }+\\cdots \\\\ \u0026gt;\u0026amp; 1+\\frac { 1 }{ 2 }+\\left( \\frac { 1 }{ 4 }+\\frac { 1 }{ 4 } \\right) +\\left( \\frac { 1 }{ 8 }+\\frac { 1 }{ 8 }+\\frac { 1 }{ 8 }+\\frac { 1 }{ 8 } \\right) +\\cdots \\\\ =\u0026amp; 1+\\frac { 1 }{ 2 }+\\frac { 1 }{ 2 }+\\frac { 1 }{ 2 }+\\cdots \\end{align*} $$\n‚ñ†\nSee Also Convergence of the Alternating Harmonic Series ","id":17,"permalink":"https://freshrimpsushi.github.io/en/posts/17/","tags":null,"title":"Euler's Proof of the Divergence of the Harmonic Series"},{"categories":"Î≥¥Ï°∞Ï†ïÎ¶¨","contents":"Definitions For $n$ positive numbers ${x}_1,{x}_2,\\cdots,{x}_n$, the arithmetic mean, geometric mean, and harmonic mean are defined as:\nArithmetic Mean : $$ \\sum_{ k=1 }^{ n }{ \\frac { {x}_k }{ n } }=\\frac { {x}_1+{x}_2+\\cdots+{x}_n }{ n } $$ Geometric Mean : $$ \\prod_{ k=1 }^{ n }{ { {x}_k }^{ \\frac { 1 }{ n } } }=\\sqrt [ n ]{ {x}_1{x}_2\\cdots{x}_n } $$ Harmonic Mean : $$ \\left( \\frac { \\sum_{ k=1 }^{ n }{ \\frac { 1 }{ {x}_k } } }{ n } \\right)^{-1}=\\frac { n }{ \\frac { 1 }{ {x}_1 }+\\frac { 1 }{ {x}_2 }+\\cdots+\\frac { 1 }{ {x}_n } } $$ Theorem The following inequality holds for these means:\n$$ \\frac { {x}_1+{x}_2+\\cdots+{x}_n }{ n }\\ge \\sqrt [ n ]{ {x}_1{x}_2\\cdots{x}_n }\\ge \\frac { n }{ \\frac { 1 }{ {x}_1 }+\\frac { 1 }{ {x}_2 }+\\cdots+\\frac { 1 }{ {x}_n } } $$\nExplanation High school students might have heard about the arithmetic-geometric mean at some point. It is not typically defined by a specific name but is commonly passed down colloquially as \u0026ldquo;Arith-Geo.\u0026rdquo; For the case when $n=2$, its proof is simple and useful even for high school level problem solving. A general proof at the high school level requires the intervention of messy expressions using mathematical induction, but instead, a more sophisticated but challenging proof is introduced.\nProof Strategy: Utilizing the following lemma:\nJensen\u0026rsquo;s Inequality: If $f$ is a convex function and $E(X) \u0026lt; \\infty$, then the following inequality holds: $$ E{f(X)}\\ge f{E(X)} $$\nArithmetic-Geometric Let $f(x)=-\\ln x$, then $f$ is convex on the interval $(0,\\infty )$. Assume that a random variable $X$ has the probability mass function\n$$ p(X=x)=\\begin{cases}{1 \\over n} \u0026amp; , x={x}_1,{x}_2, \\cdots ,{x}_n \\\\ 0 \u0026amp; , \\text{otherwise}\\end{cases} $$\nThen $E(X)$ is\n$$ \\frac { {x}_1+{x}_2+\u0026hellip;+{x}_n }{ n }\u0026lt;\\infty $$\nhence finite. This satisfies all necessary conditions for Jensen\u0026rsquo;s inequality, yielding:\n$$ E(-\\ln X)\\ge ‚Äì\\ln E(X) $$\nThe left-hand side is\n$$ \\begin{align*} E(-\\ln X)\u0026amp;=-E(\\ln X) \\\\ \u0026amp;=-\\frac { 1 }{ n } \\sum_{ k=1 }^{ n }{ \\ln{x}_k } \\\\ \u0026amp;=-\\frac { 1 }{ n }\\ln \\prod_{ k=1 }^{ n }{ {x}_k } \\\\ \u0026amp;=-\\ln { \\left( \\prod_{ k=1 }^{ n }{ {x}_k } \\right) }^{ \\frac { 1 }{ n } } \\\\ \u0026amp;=-\\ln\\prod_{ k=1 }^{ n }{ { {x}_k }^{ \\frac { 1 }{ n } } } \\end{align*} $$\nThe right-hand side is\n$$ \\begin{align*} -\\ln E(X)=-\\ln\\frac { 1 }{ n }\\sum_{ k=1 }^{ n }{ {x}_k } \\end{align*} $$\nUpon rearranging, we get\n$$ \\begin{align*} -\\ln\\prod_{ k=1 }^{ n }{ { {x}_k }^{ \\frac { 1 }{ n } } } \\ge\u0026amp; -\\ln\\frac { 1 }{ n }\\sum_{ k=1 }^{ n }{ {x}_k } \\\\ \\implies \\ln\\frac { 1 }{ n }\\sum_{ k=1 }^{ n }{ {x}_k } \\ge\u0026amp; \\ln\\prod_{ k=1 }^{ n }{ { {x}_k }^{ \\frac { 1 }{ n } } } \\\\ \\implies \\frac { 1 }{ n }\\sum_{ k=1 }^{ n }{ {x}_k } \\ge\u0026amp; \\prod_{ k=1 }^{ n }{ { {x}_k }^{ \\frac { 1 }{ n } } } \\\\ \\implies \\frac { {x}_1+{x}_2+\u0026hellip;+{x}_n }{ n } \\ge\u0026amp; \\sqrt [ n ]{ {x}_1{x}_2\u0026hellip;{x}_n } \\end{align*} $$\n‚ñ†\nThis proves the inequality between the arithmetic and geometric means. Using this, let\u0026rsquo;s prove the inequality between the geometric and harmonic means.\nGeometric-Harmonic $$ \\frac { {x}_1+{x}_2+\u0026hellip;+{x}_n }{ n }\\ge \\sqrt [ n ]{ {x}_1{x}_2\u0026hellip;{x}_n } $$\nBy setting $\\displaystyle {x}_k=\\frac { 1 }{ {y}_k }$, we get\n$$ \\begin{align*} \\frac { \\frac { 1 }{ {y}_1 }+\\frac { 1 }{ {y}_2 }+\u0026hellip;+\\frac { 1 }{ {y}_n } }{ n }\\ge \\sqrt [ n ]{ \\frac { 1 }{ {y}_1 }\\frac { 1 }{ {y}_2 }\u0026hellip;\\frac { 1 }{ {y}_n } } \\\\ \\implies \\frac { 1 }{ \\sqrt [ n ]{ \\frac { 1 }{ {y}_1 }\\frac { 1 }{ {y}_2 }\u0026hellip;\\frac { 1 }{ {y}_n } } }\\ge \\frac { n }{ \\frac { 1 }{ {y}_1 }+\\frac { 1 }{ {y}_2 }+\u0026hellip;+\\frac { 1 }{ n{y}_n } } \\\\ \\implies \\sqrt [ n ]{ {y}_1{y}_2\u0026hellip;{y}_n }\\ge \\frac { n }{ \\frac { 1 }{ n{y}_1 }+\\frac { 1 }{ n{y}_2 }+\u0026hellip;+\\frac { 1 }{ n{y}_n } } \\end{align*} $$ ‚ñ†\n","id":3,"permalink":"https://freshrimpsushi.github.io/en/posts/3/","tags":null,"title":"Arithmetic, Geometric, and Harmonic Means Inequality"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Description PyTorch contains many functions related to neural networks, which are included under the same names in torch.nn and torch.nn.functional. The functions in nn return a neural network as a function, while those in nn.functional are the neural network itself.\nFor instance, nn.MaxPool2d takes the kernel size as input and returns a pooling layer.\nimport torch import torch.nn as nn pool = nn.MaxPool2d(kernel_size = 2) # MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) A = torch.arange(16.).reshape(1, 4, 4) # tensor([[[ 0., 1., 2., 3.], # [ 4., 5., 6., 7.], # [ 8., 9., 10., 11.], # [12., 13., 14., 15.]]]) pool(A) # tensor([[[ 5., 7.], # [13., 15.]]]) On the other hand, nn.functional.MaxPool2d is itself a 2-dimensional max pooling layer. Therefore, this function takes both the tensor to apply pooling to and the conditions for pooling as inputs, and actually returns the result of pooling the input tensor.\nimport torch import torch.nn.functional as F A = torch.arange(16.).reshape(1, 4, 4) F.max_pool2d(A, kernel_size=2) #tensor([[[ 5., 7.], # [13., 15.]]]) In other words, the forward function returned by nn.MaxPool2d(kernel_size=(n,m)) is defined as max_pool2d( ,kernel_size(n,m)). If you look into the code, it is actually as follows.\nclass MaxPool2d(_MaxPoolNd): kernel_size: _size_2_t stride: _size_2_t padding: _size_2_t dilation: _size_2_t def forward(self, input: Tensor): return F.max_pool2d(input, self.kernel_size, self.stride, self.padding, self.dilation, ceil_mode=self.ceil_mode, return_indices=self.return_indices) For layers that include parameters, such as a linear layer, the parameters are also taken as inputs, for example, F.linear(input, weight, bias).\nEnvironment OS: Windows11 Version: Python 3.11.5, torch==2.0.1+cu118 ","id":3626,"permalink":"https://freshrimpsushi.github.io/en/posts/3626/","tags":null,"title":"Difference Between torch.nn and torch.nn.functional in PyTorch"},{"categories":"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù","contents":"Tidy up Let\u0026rsquo;s say that we have the following wave equation. where $\\Delta_{\\mathbf{x}}$ is Laplacian for the variable $\\mathbf{x}$.\n$$ \\begin{align} \\partial_{t}^{2} p(\\mathbf{x}, t) \u0026amp;= \\Delta_{\\mathbf{x}} p(\\mathbf{x}, t) \u0026amp;\\text{on } \\mathbb{R} \\times [0, \\infty) \\\\ p(\\mathbf{x}, 0) \u0026amp;= f(\\mathbf{x}) \u0026amp;\\text{on } \\mathbb{R} \\\\ \\partial_{t} p(\\mathbf{x}, 0) \u0026amp;= 0 \u0026amp;\\text{on } \\mathbb{R} \\end{align} $$\nThe solution of the above partial differential equation is as follows.\n$$ \\begin{equation} p(\\mathbf{x}, t) = \\dfrac{1}{(2\\pi)^{n}} \\int\\limits_{\\mathbb{R}^{n}} \\hat{f} (\\boldsymbol{\\xi}) \\cos (t \\left| \\boldsymbol{\\xi} \\right|) e^{\\mathrm{i} \\mathbf{x} \\cdot \\boldsymbol{\\xi}} \\mathrm{d} \\boldsymbol{\\xi} \\end{equation} $$\nHere, $\\hat{f}$ is the Fourier transform of $f$(\u0026hellip;/1086). Now let\u0026rsquo;s consider the wave equation with the initial conditions as follows.\n$$ \\begin{align*} \\partial_{t}^{2} p(\\mathbf{x}, t) \u0026amp;= \\Delta_{\\mathbf{x}} p(\\mathbf{x}, t) \u0026amp;\\text{on } \\mathbb{R} \\times [0, \\infty) \\\\ p(\\mathbf{x}, 0) \u0026amp;= 0 \u0026amp;\\text{on } \\mathbb{R} \\\\ \\partial_{t} p(\\mathbf{x}, 0) \u0026amp;= g(\\mathbf{x}) \u0026amp;\\text{on } \\mathbb{R} \\end{align*} $$\nThe solution of the above partial differential equation is as follows.\n$$ p(\\mathbf{x}, t) = \\dfrac{1}{(2\\pi)^{n}} \\int\\limits_{\\mathbb{R}^{n}} \\hat{g} (\\boldsymbol{\\xi}) \\dfrac{\\sin (t \\left| \\boldsymbol{\\xi} \\right|)}{\\left| \\boldsymbol{\\xi} \\right|} e^{\\mathrm{i} \\mathbf{x} \\cdot \\boldsymbol{\\xi}} \\mathrm{d} \\boldsymbol{\\xi} $$\nDescription Let\u0026rsquo;s put the definitions of Fourier transform and it\u0026rsquo;s Inverse transform as below.\n$$ \\hat{f}(\\boldsymbol{\\xi}) = \\int\\limits_{\\mathbb{R}^{n}} f(\\mathbf{x}) e^{\\mathrm{i} \\boldsymbol{\\xi} \\cdot \\mathbf{x}} \\mathrm{d} \\mathbf{x}, \\qquad f(\\mathbf{x}) = \\dfrac{1}{(2\\pi)^{n}}\\int\\limits_{\\mathbb{R}^{n}} f(\\mathbf{x}) e^{\\mathrm{i} \\mathbf{x} \\cdot \\boldsymbol{\\xi}} \\mathrm{d} \\boldsymbol{\\xi} $$\nThe latter method of proof is the same as the former, so it is omitted.\nProof of proof Just check that $(4)$ satisfies $(1)$, $(2)$, and $(3)$. Let\u0026rsquo;s first calculate the second derivative of time,\n$$ \\partial_{t}^{2} p(\\mathbf{x}, t) = -\\left| \\boldsymbol{\\xi} \\right|^{2} \\dfrac{1}{(2\\pi)^{n}} \\int\\limits_{\\mathbb{R}^{n}} \\hat{f} (\\boldsymbol{\\xi}) \\cos (t \\left| \\boldsymbol{\\xi} \\right|) e^{\\mathrm{i} \\mathbf{x} \\cdot \\boldsymbol{\\xi}} \\mathrm{d} \\boldsymbol{\\xi} $$\nThe Laplacian is calculated as follows.\n$$ \\begin{align*} \\Delta_{\\mathbf{x}} p(\\mathbf{x}, t) \u0026amp;= \\dfrac{1}{(2\\pi)^{n}} \\int\\limits_{\\mathbb{R}^{n}} \\hat{f} (\\boldsymbol{\\xi}) \\cos (t \\left| \\boldsymbol{\\xi} \\right|) (\\Delta_{\\mathbf{x}} e^{\\mathrm{i} \\mathbf{x} \\cdot \\boldsymbol{\\xi}}) \\mathrm{d} \\boldsymbol{\\xi} \\\\ \u0026amp;= (- \\left| \\boldsymbol{\\xi} \\right|^{2}) \\dfrac{1}{(2\\pi)^{n}} \\int\\limits_{\\mathbb{R}^{n}} \\hat{f} (\\boldsymbol{\\xi}) \\cos (t \\left| \\boldsymbol{\\xi} \\right|) e^{\\mathrm{i} \\mathbf{x} \\cdot \\boldsymbol{\\xi}} \\mathrm{d} \\boldsymbol{\\xi} \\\\ \\end{align*} $$\nThus, $(1)$ is established. When $p(\\mathbf{x}, 0)$ is calculated, $(2)$ is established because it is as follows.\n$$ \\begin{align*} p(\\mathbf{x}, 0) \u0026amp;= \\dfrac{1}{(2\\pi)^{n}} \\int\\limits_{\\mathbb{R}^{n}} \\hat{f} (\\boldsymbol{\\xi}) \\cos ( 0 \\left| \\boldsymbol{\\xi} \\right|) e^{\\mathrm{i} \\mathbf{x} \\cdot \\boldsymbol{\\xi}} \\mathrm{d} \\boldsymbol{\\xi} \\\\ \u0026amp;= \\dfrac{1}{(2\\pi)^{n}} \\int\\limits_{\\mathbb{R}^{n}} \\hat{f} (\\boldsymbol{\\xi}) e^{\\mathrm{i} \\mathbf{x} \\cdot \\boldsymbol{\\xi}} \\mathrm{d} \\boldsymbol{\\xi} \\\\ \u0026amp;= f(\\mathbf{x}) \\end{align*} $$\nIt is also easy to see that $(3)$ is established.\n$$ \\begin{align*} \\partial_{t}p(\\mathbf{x}, 0) \u0026amp;= - \\left| \\boldsymbol{\\xi} \\right| \\int\\limits_{\\mathbb{R}^{n}} \\hat{f} (\\boldsymbol{\\xi}) \\sin ( 0 \\left| \\boldsymbol{\\xi} \\right|) e^{\\mathrm{i} \\mathbf{x} \\cdot \\boldsymbol{\\xi}} \\mathrm{d} \\boldsymbol{\\xi} \\\\ \u0026amp;= 0 \\end{align*} $$\n‚ñ†\n","id":3623,"permalink":"https://freshrimpsushi.github.io/en/posts/3623/","tags":null,"title":"Solution of Wave Equation with Zero Initial Condition"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Description AdaBelief, introduced by J. Zhuang et al. in 2020, is one of the variations of Adam1. Since PyTorch does not natively provide this optimizer, it must be installed separately.\nCode2 Installation The following command can be used to install it via cmd.\npip install adabelief-pytorch==0.2.0 Usage The code below can be used to import and utilize it.\nfrom adabelief_pytorch import AdaBelief\roptimizer = AdaBelief(model.parameters(), lr=1e-3, eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = False) Environment OS: Windows11 Version: Python 3.11.5, torch==2.0.1+cu118, adabelief-pytorch==0.2.0 https://arxiv.org/abs/2010.07468\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/juntang-zhuang/Adabelief-Optimizer?tab=readme-ov-file#installation-and-usage\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3620,"permalink":"https://freshrimpsushi.github.io/en/posts/3620/","tags":null,"title":"ÌååÏù¥ÌÜ†ÏπòÏóêÏÑú AdaBelief ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÇ¨Ïö©ÌïòÎäî Î∞©Î≤ï"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Description A color gradient is one of the two color schemes supported by Julia\u0026rsquo;s visualization package Plots.jl (the other is palette), which is what we commonly refer to as gradation. Simply put, a type that implements gradation is ColorGradient.\nGradients are used to draw charts such as heatmap(), surface(), contour(). If you want to differentiate the colors of various graphs, use a palette instead of a gradient.\nCode Symbol It can be used with cgrad(symbol). The default gradient is cgrad(:inferno), and the colors are as follows.\nusing Plots\rcgrad(:inferno) heatmap(reshape(1:25, (5, 5))) Pre-defined palettes and gradients in Plots.jl can be found in the official documentation (More diverse palettes and gradients can be found in the official documentation of the package ColorSchemes.jl here).\nIn Python\u0026rsquo;s matplotlib, the default colormap for imshow that resembles a gradient is :viridis.\nheatmap(reshape(1:25, (5, 5)), fillcolor = cgrad(:viridis)) Custom Definition A palette can be defined directly with cgrad([start color, end color]). To set the points of color transformation, input a vector containing values between $0$ and $1$ as an optional argument.\ncgrad([:blue, :orange]) cgrad([:blue, :orange], [0.1, 0.9]) cgrad([:blue, :orange], [0.5, 0.50001]) Keywords rev Entering the keyword argument rev = true will reverse the order.\ncgrad(:darktest) cgrad(:darktest, rev = true) scale The keyword scale specifies the scale of the gradient. You can input :log or :exp.\ncgrad(:rainbow) cgrad(:rainbow, scale = :log) cgrad(:rainbow, scale = :exp) Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0 See Also How to use Color How to use palettes How to use Color Gradient (Gradation) Package for Color Processing Colors.jl Using RGB code RGB(1, 0, 0) Using HEX code \u0026quot;#000000\u0026quot; How to specify the color of graph elements Specifying the color of graphs for each subplot How to specify the color of axes, axis names, ticks, and tick values How to specify background color ","id":3608,"permalink":"https://freshrimpsushi.github.io/en/posts/3608/","tags":null,"title":"How to Use Color Gradients in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Explanation A palette refers to a board where paints are squeezed out in advance. Mathematically, it can be explained as a \u0026lsquo;set of colors\u0026rsquo; or a \u0026lsquo;sequence of colors\u0026rsquo;. When drawing multiple graphs in one picture, the most common way is to distinguish them by using different colors. For this purpose, Julia has implemented a type called ColorPalette that collects various colors. It can be comfortably understood as a vector of colors. Indeed, if we load the default palette :default, it may look incredibly complicated, but if we look inside, it\u0026rsquo;s just a vector of colors.\nWhen drawing heatmaps, gradients are used instead of palettes.\njulia\u0026gt; using Plots\rjulia\u0026gt; palette(:default)\rColorPalette(ColorSchemes.ColorScheme{Vector{RGB{Float64}}, String, String}(RGB{Float64}[RG\rB{Float64}(0.0,0.6056031611752245,0.9786801175696073), RGB{Float64}(0.8888735002725198,0.43\r564919034818994,0.2781229361419438), RGB{Float64}(0.2422242978521988,0.6432750931576305,0.3\r044486515341153), RGB{Float64}(0.7644401754934356,0.4441117794687767,0.8242975359232758), R\rGB{Float64}(0.6755439572114057,0.5556623322045815,0.09423433626639477), RGB{Float64}(4.8211\r81644776295e-7,0.6657589812923561,0.6809969518707945), RGB{Float64}(0.930767491919665,0.367\r4771896571412,0.5757699667547829), RGB{Float64}(0.7769816661712932,0.5097431319944513,0.146\r4252569555497), RGB{Float64}(3.8077343661790943e-7,0.6642678029460116,0.5529508754522481), RGB{Float64}(0.558464964115081,0.5934846564332882,0.11748125233232104), RGB{Float64}(5.9476\r23898072685e-7,0.6608785231434254,0.7981787608414297), RGB{Float64}(0.6096707676128648,0.49\r918492100827777,0.9117812665042642), RGB{Float64}(0.3800016049820351,0.5510532724353506,0.9\r665056985227146), RGB{Float64}(0.942181647954218,0.37516423354097583,0.4518168202944593), R\rGB{Float64}(0.8684020893043971,0.3959893639954845,0.7135147524811879), RGB{Float64}(0.42314\r674364630817,0.6224954944199981,0.19877060252130468)], \u0026#34;\u0026#34;, \u0026#34;\u0026#34;))\rjulia\u0026gt; palette(:default).colors.colors\r16-element Array{RGB{Float64},1} with eltype RGB{Float64}:\rRGB{Float64}(0.0,0.6056031611752245,0.9786801175696073)\rRGB{Float64}(0.8888735002725198,0.43564919034818994,0.2781229361419438)\rRGB{Float64}(0.2422242978521988,0.6432750931576305,0.3044486515341153)\rRGB{Float64}(0.7644401754934356,0.4441117794687767,0.8242975359232758)\rRGB{Float64}(0.6755439572114057,0.5556623322045815,0.09423433626639477)\rRGB{Float64}(4.821181644776295e-7,0.6657589812923561,0.6809969518707945)\rRGB{Float64}(0.930767491919665,0.3674771896571412,0.5757699667547829)\rRGB{Float64}(0.7769816661712932,0.5097431319944513,0.1464252569555497)\rRGB{Float64}(3.8077343661790943e-7,0.6642678029460116,0.5529508754522481)\rRGB{Float64}(0.558464964115081,0.5934846564332882,0.11748125233232104)\rRGB{Float64}(5.947623898072685e-7,0.6608785231434254,0.7981787608414297)\rRGB{Float64}(0.6096707676128648,0.49918492100827777,0.9117812665042642)\rRGB{Float64}(0.3800016049820351,0.5510532724353506,0.9665056985227146)\rRGB{Float64}(0.942181647954218,0.37516423354097583,0.4518168202944593)\rRGB{Float64}(0.8684020893043971,0.3959893639954845,0.7135147524811879)\rRGB{Float64}(0.42314674364630817,0.6224954944199981,0.19877060252130468) You can load or create a palette by entering the symbol of an already defined palette or by entering the color and length into the function palette(). When drawing a chart, you just need to assign it to the palette keyword of the plot() function.\nCode Symbols Use it like palette(symbol). The symbol for the default palette is :default, and its colors are as follows.\nWhen drawing multiple graphs in one picture, the above colors are applied in order. After using all the colors, it cycles back to the beginning.\nusing Plots x = 0:0.01:2œÄ plot([x -\u0026gt; sin(x - a) for a in range(0, œÄ, length = 5)], 0, 2œÄ) Palettes and gradients predefined in Plots.jl can be checked in the official documentation. (More diverse palettes and gradients can be found in the official documentation of the package ColorSchemes.jl.)\nIf drawn with :rainbow,\npalette(:rainbow) plot([x -\u0026gt; sin(x - a) for a in range(0, œÄ, length = 5)], 0, 2œÄ,\rpalette = palette(:rainbow)) Custom Definition You can define your palette directly with palette([start color, end color], length). Alternatively, you can interpolate colors using range().\npalette([:blue, :orange], 10) palette([RGB(0.5, 0.6, 0.2), RGB(1.0, 0.2, 0.9)], 10) Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0 See Also How to Use Colors How to Use Palettes How to Use Color Gradients Package for Color Processing Colors.jl How to Use RGB Code RGB(1, 0, 0) How to Use HEX Code \u0026quot;#000000\u0026quot; How to Specify Colors of Graph Elements [How to Specify Colors for Each Subplot] (../3602) How to Specify Colors of Axes, Axis Names, Ticks, and Tick Values How to Specify Background Color ","id":3607,"permalink":"https://freshrimpsushi.github.io/en/posts/3607/","tags":null,"title":"How to Use Palettes in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"ÏΩîÎìú When plotting two data sets that have a large scale difference on the same plot, the one with the smaller scale gets completely ignored as shown in the figure below.\nusing Plots\rx = 0:0.01:2œÄ\rplot(x, sin.(x))\rplot!(x, exp.(x)) When plotting the second data set, if you input twinx() as the first argument, it shares the $x$ axis and the graph is drawn on the new $y$ axis.\nplot(x, sin.(x), ylabel = \u0026#34;sin x\u0026#34;)\rplot!(twinx(), x, exp.(x), ylabel = \u0026#34;exp x\u0026#34;) Conversely, to share the $y$ axis and plot, you can input twiny() as the first argument.\nEnvironment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0 ","id":3606,"permalink":"https://freshrimpsushi.github.io/en/posts/3606/","tags":null,"title":"How to Plot Two Data Axes of Different Scales in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Description In Julia\u0026rsquo;s Plots.jl, a plot is also an object. If you draw an empty plot to check its type, it looks like this.\njulia\u0026gt; using Plots\rjulia\u0026gt; p = plot()\rjulia\u0026gt; p |\u0026gt; typeof\rPlots.Plot{Plots.GRBackend} Removing Plots., it becomes Plot{GRBackend}, meaning the plot\u0026rsquo;s backend is GR, similar to how a vector with elements of type Float64 is denoted as Vector{Float64}. Checking the properties of Plot, we find the following.\njulia\u0026gt; p |\u0026gt; propertynames\r(:backend, :n, :attr, :series_list, :o, :subplots, :spmap, :layout, :inset_subplots, :init) Each property includes vectors or dictionaries containing attributes of the picture.\np.backend This is the plot\u0026rsquo;s backend.\njulia\u0026gt; p.backend\rPlots.GRBackend() p.attr This is a dictionary about the attributes of the picture. It contains 30 key-value pairs as follows.\njulia\u0026gt; plot(rand(10, 4), layout = 4).attr\rRecipesPipeline.DefaultsDict with 30 entries:\r:dpi =\u0026gt; 100\r:background_color_outside =\u0026gt; :match\r:plot_titlefontvalign =\u0026gt; :vcenter\r:warn_on_unsupported =\u0026gt; true\r:background_color =\u0026gt; RGBA{Float64}(1.0,1.0,1.0,1.0)\r:inset_subplots =\u0026gt; nothing\r:size =\u0026gt; (600, 400)\r:display_type =\u0026gt; :auto\r:overwrite_figure =\u0026gt; true\r:html_output_format =\u0026gt; :auto\r:plot_titlefontfamily =\u0026gt; :match\r:plot_titleindex =\u0026gt; 0\r:foreground_color =\u0026gt; RGB{N0f8}(0.0,0.0,0.0)\r:window_title =\u0026gt; \u0026#34;Plots.jl\u0026#34;\r:plot_titlefontrotation =\u0026gt; 0.0\r:extra_plot_kwargs =\u0026gt; Dict{Any, Any}()\r:pos =\u0026gt; (0, 0)\r:plot_titlefonthalign =\u0026gt; :hcenter\r:tex_output_standalone =\u0026gt; false\r:extra_kwargs =\u0026gt; :series\r:thickness_scaling =\u0026gt; 1\r:layout =\u0026gt; 4\r:plot_titlelocation =\u0026gt; :center\r:plot_titlefontsize =\u0026gt; 16\r:plot_title =\u0026gt; \u0026#34;\u0026#34;\r:show =\u0026gt; false\r:link =\u0026gt; :none\r:plot_titlefontcolor =\u0026gt; :match\r:plot_titlevspan =\u0026gt; 0.05\r:fontfamily =\u0026gt; \u0026#34;sans-serif\u0026#34;\rjulia\u0026gt; plot(rand(10, 4), layout = 4).attr[:size]\r(600, 400) p.series_list It is a vector whose elements are dictionaries of attributes for each data graph.\njulia\u0026gt; plot(rand(10,5)).series_list\r5-element Vector{Plots.Series}:\rjulia\u0026gt; plot(plot(rand(10, 4)), plot(rand(10, 3))).series_list\r7-element Vector{Plots.Series}: The included key-value pairs in each dictionary are as follows.\njulia\u0026gt; plot(rand(10, 2)).series_list[1].plotattributes\rRecipesPipeline.DefaultsDict with 62 entries:\r:plot_object =\u0026gt; Plot{Plots.GRBackend() n=2}\r:subplot =\u0026gt; Subplot{1}\r:label =\u0026gt; \u0026#34;y1\u0026#34;\r:fillalpha =\u0026gt; nothing\r:linealpha =\u0026gt; nothing\r:linecolor =\u0026gt; RGBA{Float64}(0.0,0.605603,0.97868,1.0)\r:x_extrema =\u0026gt; (NaN, NaN)\r:series_index =\u0026gt; 1\r:markerstrokealpha =\u0026gt; nothing\r:markeralpha =\u0026gt; nothing\r:seriestype =\u0026gt; :path\r:z_extrema =\u0026gt; (NaN, NaN)\r:x =\u0026gt; Base.OneTo(10)\r:markerstrokecolor =\u0026gt; RGBA{Float64}(0.0,0.0,0.0,1.0)\r:fillcolor =\u0026gt; RGBA{Float64}(0.0,0.605603,0.97868,1.0)\r:clims_calculated =\u0026gt; (NaN, NaN)\r:seriescolor =\u0026gt; RGBA{Float64}(0.0,0.605603,0.97868,1.0)\r:extra_kwargs =\u0026gt; Dict{Symbol, Any}()\r:z =\u0026gt; nothing\r:series_plotindex =\u0026gt; 1\r:y =\u0026gt; [0.477103, 0.00362131, 0.864524, 0.391488, 0.663659, 0.89787, 0.157973, 0.964416, 0.806635, 0.243531]\r:markercolor =\u0026gt; RGBA{Float64}(0.0,0.605603,0.97868,1.0)\r:y_extrema =\u0026gt; (0.00362131, 0.964416)\r:linewidth =\u0026gt; 1\r:group =\u0026gt; nothing\r:stride =\u0026gt; (1, 1)\r:permute =\u0026gt; :none\r:marker_z =\u0026gt; nothing\r:show_empty_bins =\u0026gt; false\r:seriesalpha =\u0026gt; nothing\r:smooth =\u0026gt; false\r:zerror =\u0026gt; nothing\r:arrow =\u0026gt; nothing\r:normalize =\u0026gt; false\r:linestyle =\u0026gt; :solid\r:contours =\u0026gt; false\r:bar_width =\u0026gt; nothing\r:bins =\u0026gt; :auto\r:markerstrokestyle =\u0026gt; :solid\r:weights =\u0026gt; nothing\r:z_order =\u0026gt; :front\r:fill_z =\u0026gt; nothing\r:markershape =\u0026gt; :none\r:markerstrokewidth =\u0026gt; 1\r:xerror =\u0026gt; nothing\r:bar_position =\u0026gt; :overlay\r:contour_labels =\u0026gt; false\r:hover =\u0026gt; nothing\r:primary =\u0026gt; true\r:yerror =\u0026gt; nothing\r:ribbon =\u0026gt; nothing\r:fillstyle =\u0026gt; nothing\r:line_z =\u0026gt; nothing\r:orientation =\u0026gt; :vertical\r:markersize =\u0026gt; 4\r:bar_edges =\u0026gt; false\r:quiver =\u0026gt; nothing\r:fillrange =\u0026gt; nothing\r:colorbar_entry =\u0026gt; true\r:series_annotations =\u0026gt; nothing\r:levels =\u0026gt; 15\r:connections =\u0026gt; nothing\rjulia\u0026gt; plot(rand(10, 2)).series_list[1][:label]\r\u0026#34;y1\u0026#34; Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0 ","id":3605,"permalink":"https://freshrimpsushi.github.io/en/posts/3605/","tags":null,"title":"List of Plot Properties in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Theorem Keywords related to the grid background in Plots.jl are as follows:\nKeyword Name Function grid Display grid gridalpha, ga, gŒ± Specify grid transparency foreground_color_grid, fgcolor_grid Specify grid color gridlinewidth, grid_lw Specify grid thickness gridstyle, grid_ls Specify grid line style minorgrid Display minor grid minorgridalpha Specify minor grid transparency foreground_color_minor_grid, fgcolor_minorgrid Specify minor grid color minorgridlinewidth, minorgrid_lw Specify minor grid thickness minorgridstyle, minorgrid_ls Specify minor grid line style Code Display Grid The keyword for displaying the grid is grid. Inputting :x or :y displays only the lines assisting the $x$ axis or the $y$ axis ticks, respectively. Inputting false does not display the grid.\nplot(plot(rand(10)), plot(rand(10), grid = :x), plot(rand(10), grid = :y), plot(rand(10), grid = false)) Transparency The grid in the background is drawn with a transparency of 0.1 by default. The keyword for adjusting the grid‚Äôs transparency is gridalpha(=ga)(=gŒ±).\nplot(rand(10, 3), layout = (3, 1), gridalpha = [0.1 0.5 1]) Color The default grid color is black, and it can be changed with the keyword foreground_color_grid(=fgcolor_grid).\nplot(rand(10, 3), layout = (3, 1), gridalpha = 1, fgcolor_grid = [:red :green :orange]) Thickness The keyword for specifying the grid thickness is gridlinewidth(=grid_lw), with a default value of 0.5.\nplot(rand(10, 3), layout = (3, 1), grid_lw = [0.5 5 10]) Grid Style The grid line style can be specified with the keyword gridstyle(=grid_ls). Possible symbols are :auto, :solid, :dash, :dot, :dashdot, :dashdotdot.\nplot(rand(10, 2), layout = 2, ga = 1, gridstyle = [:solid :dash]) Minor Grid Inputting the keyword argument minorgrid = true draws the minor grid. Keywords for specifying the minor grid‚Äôs transparency, color, thickness, and line style are minorgridalpha, foreground_color_minor_grid minorgrid_lw, minorgrid_ls, respectively.\nplot(plot(rand(10)), plot(rand(10), minorgrid = true), gridalpha = 0.8, minorgridalpha = 0.2) Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0 ","id":3604,"permalink":"https://freshrimpsushi.github.io/en/posts/3604/","tags":null,"title":"Decorating the Background Grid in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Theorem The keywords related to the background color of figures in Plots.jl are as follows.\nKeyword Name Function background_color, bg_color Specify the color of the overall background background_color_outside, bg_color_outside Specify the color of the area outside where the graph is drawn background_subplot, bg_subplot Specify the color of the area where the graph is drawn background_inside, bg_inside Specify the color of the area where the graph is drawn, excluding the legend Code The keyword to specify the background color is background_color(=bg_color). It sets the color of the legend, the area where the graph is drawn, and all the background to the entered value.\nplot(rand(10), bg_color = :tomato) The keyword to specify the color outside the area where the graph is drawn is background_color_outside(=bg_color_outside).\nplot(rand(10), bg_color_outside = :palegreen) The keyword to specify the color of the area where the graph is drawn is background_subplot(=bg_subplot).\nplot(rand(10), bg_subplot = :violet) The keyword to specify the color of the area where the graph is drawn, excluding the legend, is background_inside(=bg_inside).\nplot(rand(10), bg_inside = :brown4) Sub Plots When there are multiple sub plots, it is necessary to set the color using bg_subplot or bg_inside to maintain each background color when combined into an overall plot.\np‚ÇÅ = plot(rand(10), bg_subplot = :tomato) p‚ÇÇ = scatter(rand(10), bg_inside = :yellow) p = plot(p‚ÇÅ, p‚ÇÇ) Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0 See Also How to Use Colors How to Use Palettes How to Use Color Gradients Package for Color Processing Colors.jl How to Use RGB Codes RGB(1, 0, 0) How to Use HEX Codes \u0026quot;#000000\u0026quot; How to Specify the Color of Graph Elements How to Specify Graph Colors for Each Sub Plot How to Specify the Color of Axes, Axis Names, Ticks, and Tick Values How to Specify Background Color ","id":3603,"permalink":"https://freshrimpsushi.github.io/en/posts/3603/","tags":null,"title":"Specifying Background Color in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview This section introduces three methods for specifying graph colors for each subplot. To learn how to specify colors for graph elements, refer here.\nMethod 1 The first way to specify the graph color for a subplot is to predefine the color when defining each subplot. In Julia, since a picture is an object itself, you can define multiple pictures with different attributes and then combine them into one plot.\np‚ÇÅ = plot(rand(10), lc = :red)\rp‚ÇÇ = scatter(rand(10), mc = :blue)\rp‚ÇÉ = bar(rand(10), fc = :green)\rplot(p‚ÇÅ, p‚ÇÇ, p‚ÇÉ,\rlayout = (3, 1),\rtitle = [\u0026#34;p‚ÇÅ\u0026#34; \u0026#34;p‚ÇÇ\u0026#34; \u0026#34;p‚ÇÉ\u0026#34;],\r) Method 2 The second method involves entering the colors as a row vector when defining the subplots in the overall plot through keyword arguments. Note that it must be a row vector, not a column vector.\np‚ÇÑ = plot(rand(10))\rp‚ÇÖ = plot(rand(10))\rp‚ÇÜ = plot(rand(10))\rplot(p‚ÇÑ, p‚ÇÖ, p‚ÇÜ,\rlayout = (3, 1),\rlinecolor = [:brown :purple :orange],\rtitle = [\u0026#34;p‚ÇÑ\u0026#34; \u0026#34;p‚ÇÖ\u0026#34; \u0026#34;p‚ÇÜ\u0026#34;],\r) Method 3 The third method changes the property value of each subplot after defining the overall plot. The property .series_list is a vector of dictionaries containing series attributes information of each subplot. That is, p.series_list[1] returns the series attributes dictionary of the first subplot. By entering the :linecolor key and changing its value in this dictionary, the line color of the first subplot changes.\np‚Çá = plot(rand(10))\rp‚Çà = scatter(rand(10))\rp‚Çâ = bar(rand(10))\rp = plot(p‚Çá, p‚Çà, p‚Çâ,\rlayout = (3, 1),\rtitle = [\u0026#34;p‚Çá\u0026#34; \u0026#34;p‚Çà\u0026#34; \u0026#34;p‚Çâ\u0026#34;],\r)\rp.series_list[1][:linecolor] = :goldenrod1\rp.series_list[2][:markercolor] = :olivedrab3\rp.series_list[3][:fillcolor] = :hotpink3 Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0 See Also How to Use Colors How to Use Palettes How to Use Color Gradients Package for Color Handling Colors.jl How to Use RGB Codes RGB(1, 0, 0) How to Use HEX Codes \u0026quot;#000000\u0026quot; How to Specify Colors for Graph Elements How to Specify Graph Colors for Each Subplot How to Specify Colors for Axes, Axis Names, Ticks, and Tick Labels How to Specify Background Color ","id":3602,"permalink":"https://freshrimpsushi.github.io/en/posts/3602/","tags":null,"title":"How to Specify Graph Colors for Each Subplot in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Theorem In Plots.jl, the keywords for specifying the color of each graph component are as follows.\nKeyword Function markercolor, mc Specify the marker\u0026rsquo;s inside color markerstrokecolor, msc Specify the marker\u0026rsquo;s border color linecolor, lc Specify the line color fillcolor, fc Specify the fill color seriescolor, c Specify the color of all components Keyword Function markeralpha, ma, mŒ± Specify the marker\u0026rsquo;s inside transparency markerstrokealpha, msa, msŒ± Specify the marker\u0026rsquo;s border transparency linealpha, la, lŒ± Specify the line transparency fillalpha, fa, fŒ± Specify the fill transparency seriesalpha, a, Œ± Specify the transparency of all components Colors In Plots.jl, the targets whose color can be changed are dots, lines, and areas. The keyword arguments for specifying each color are markercolor(=mc), linecolor(=lc), and fillcolor(=fc). The property specified by these keywords does not affect each other; hence, even if you input mc = :red after plotting a line graph, the line color will not apply as red. Indeed, checking the property of p = plot(rand(10), mc = :red) shows the following.\njulia\u0026gt; p = plot(rand(10), mc = :red) julia\u0026gt; p.series_list[1][:linecolor] RGBA{Float64}(0.0,0.6056031611752245,0.9786801175696073,1.0) julia\u0026gt; p.series_list[1][:markercolor] RGBA{Float64}(1.0,0.0,0.0,1.0) The color of the plotted line graph is still the default color, not red.\nThus, if you plot multiple subplots and specify colors with the three keywords above, each will be applied accordingly. If you color the dots (markers) in purple :purple, the line in dark green :darkgreen, and the area in sky blue :skyblue, it will look as follows.\nst = [:line :scatter :barhist :steppre :scatterhist :bar] x = rand(20) y = repeat(x, outer = (1, length(st))) plot(y, seriestype = st, layout = 6, mc = :purple, lc = :darkgreen, fc = :skyblue ) Transparency The keyword for determining the transparency of a color is created by replacing color with alpha in the color specifying keyword name. It is also acceptable to use the Greek letter Œ± directly.\nAlternatively, you can input a color code that includes transparency, such as RGBA, into the color specifying keyword.\nplot(rand(20, 3), layout = (3,1), seriestype = [:scatter :line :bar], mc = :red, lc = :green, fc = :blue ) plot(rand(20, 3), layout = (3,1), seriestype = [:scatter :line :bar], markeralpha = 0.5, mc = :red, la = 0.5, lc = :green, fŒ± = 0.5, fc = :blue ) Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0 See Also How to Use Colors How to Use Palettes How to Use Color Gradient (Gradation) Package for Color Processing Colors.jl How to Use RGB Codes RGB(1, 0, 0) How to Use HEX Codes \u0026quot;#000000\u0026quot; How to Specify Colors of Graph Components How to Specify Colors of Subplots How to Specify Colors of Axes, Axis Labels, Ticks, and Tick Values How to Specify Background Color ","id":3601,"permalink":"https://freshrimpsushi.github.io/en/posts/3601/","tags":null,"title":"Specifying the Color of Graph Elements in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code The package provided in Julia for dealing with colors is Colors.jl. By importing the visualization package Plots.jl, the features within Colors.jl can also be used. The color codes representing the RGB space include RGB, BGR, RGB24, RGBX, XRGB, which are subtypes of AbstractRGB. RGBA adds transparency to RGB.\njulia\u0026gt; using Plots\rjulia\u0026gt; subtypes(AbstractRGB)\r5-element Vector{Any}:\rBGR\rRGB\rRGB24\rRGBX\rXRGB\rjulia\u0026gt; subtypes(AbstractRGBA)\r2-element Vector{Any}:\rBGRA\rRGBA Strings For the function plot(), entering a string like \u0026quot;rgb(255, 0, 0)\u0026quot; as a color specifying keyword allows the use of the color with RGB code (255, 0, 0). As seen below, the reason why entering a string also works is apparently because plot() parses it automatically. For named colors, they can be used as either strings or symbols like \u0026quot;red\u0026quot; or :red.\nusing Plots\rr = \u0026#34;rgb(255, 0, 0)\u0026#34; # Ï†ïÏàòÎ°ú ÌëúÌòÑÎêú RGB Îπ®Í∞ÑÏÉâ\rg = \u0026#34;rgba(0, 255, 0, 0.2)\u0026#34; # Ìà¨Î™ÖÎèÑÍ∞Ä 0.2Ïù∏ RGB Ï¥àÎ°ùÏÉâ\rp = \u0026#34;rgb(50%, 0%, 100%)\u0026#34; # ÌçºÏÑºÌÖåÏù¥ÏßÄÎ°ú ÌëúÌòÑÎêú RGB Î≥¥ÎùºÏÉâ\rplot(\rplot(rand(15), lc = r),\rbar(rand(15), fc = g),\rscatter(rand(15), mc = p),\rlayout = (3, 1)\r) Parsing RGB color codes can be parsed like colorant\u0026quot;rgb(0, 0, 0)\u0026quot;.\njulia\u0026gt; r = colorant\u0026#34;rgb(255, 0, 0)\u0026#34; # Ï†ïÏàòÎ°ú ÌëúÌòÑÎêú RGB Îπ®Í∞ÑÏÉâ\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; g = colorant\u0026#34;rgba(0, 255, 0, 0.2)\u0026#34; # Ìà¨Î™ÖÎèÑÍ∞Ä 0.2Ïù∏ Ï¥àÎ°ùÏÉâ\rRGBA{N0f8}(0.0,1.0,0.0,0.502)\rjulia\u0026gt; p = colorant\u0026#34;rgb(50%, 0%, 100%)\u0026#34; # ÌçºÏÑºÌÖåÏù¥ÏßÄÎ°ú ÌëúÌòÑÎêú RGB Î≥¥ÎùºÏÉâ\rRGB{N0f8}(0.502,0.0,1.0)\rjulia\u0026gt; plot(\rplot(rand(15), lc = r),\rbar(rand(15), fc = g),\rscatter(rand(15), mc = p),\rlayout = (3, 1)) It is also possible to parse using parse(RGB, \u0026quot;rgb(0, 255, 255)\u0026quot;).\njulia\u0026gt; parse(RGB, \u0026#34;rgb(0, 255, 255)\u0026#34;)\rRGB{N0f8}(0.0,1.0,1.0)\rjulia\u0026gt; parse(RGBA, \u0026#34;rgba(0, 255, 0, 0.5)\u0026#34;)\rRGBA{N0f8}(0.0,1.0,0.0,0.502) Custom Definition Colors can be defined directly using functions like RGB(), RGBA().\njulia\u0026gt; RGB(1, 0, 0)\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; RGB(1.0, 0.0, 0.0)\rRGB{Float64}(1.0,0.0,0.0)\rjulia\u0026gt; RGBA(1, 0, 0.5, 0.5)\rRGBA{Float64}(1.0,0.0,0.5,0.5) To get exactly the same type of color as parsed by colorant, input of numbers in N0f8 type is needed. To use this, FixedPointNumbers.jl is required. Or, directly defining it as 1.0N0f8 is also an option. Below is the code returning the same color as colorant\u0026quot;rgb(255, 0, 0)\u0026quot;, which is red.\njulia\u0026gt; using FixedPointNumbers\r# RGB Îπ®Í∞ÑÏÉâ RGB\rjulia\u0026gt; colorant\u0026#34;rgb(255, 0, 0)\u0026#34;\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; RGB(1.0, 0.0, 0.0)\rRGB{Float64}(1.0,0.0,0.0)\rjulia\u0026gt; RGB(1.0N0f8, 0N0f8, 0N0f8)\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; RGB(reinterpret(N0f8, UInt8(255)), reinterpret(N0f8, UInt8(0)), reinterpret(N0f8, UInt8(0)))\rRGB{N0f8}(1.0,0.0,0.0) Conversion from Other Color Spaces The function convert() converts color codes from other color spaces to RGB code.\njulia\u0026gt; using Colors\rjulia\u0026gt; convert(RGB{N0f8}, HSL(270, 0.5, 0.5))\rERROR: UndefVarError: `N0f8` not defined\rjulia\u0026gt; using FixedPointNumbers\rjulia\u0026gt; convert(RGB{N0f8}, HSL(270, 0.5, 0.5))\rRGB{N0f8}(0.502,0.251,0.749) Getting Color Names Functions rgb_string() and rgba_string() return the RGB, RGBA codes of colors as strings, respectively.\njulia\u0026gt; rgb_string(colorant\u0026#34;rgba(255, 0, 0, 0.5)\u0026#34;)\r\u0026#34;rgb(255, 0, 0)\u0026#34;\rjulia\u0026gt; rgba_string(colorant\u0026#34;rgba(255, 0, 0, 0.5)\u0026#34;)\r\u0026#34;rgba(255, 0, 0, 0.502)\u0026#34;\rjulia\u0026gt; rgb_string(colorant\u0026#34;red\u0026#34;)\r\u0026#34;rgb(255, 0, 0)\u0026#34;\rjulia\u0026gt; rgb_string(parse(RGB, :blue))\r\u0026#34;rgb(0, 0, 255)\u0026#34;\rjulia\u0026gt; rgb_string(colorant\u0026#34;#00FF00\u0026#34;)\r\u0026#34;rgb(0, 255, 0)\u0026#34; See Also Using colors in Plots Using RGB color codes Using HEX color codes Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0, Colors v0.12.10, FixedPointNumbers v0.8.4 See Also How to use colors Using palettes Using color gradients Package for color processing Colors.jl Using RGB codes RGB(1, 0, 0) Using HEX codes \u0026quot;#000000\u0026quot; Determining the color of graph elements Specifying graph colors for each subplot Designating colors for axes, axis labels, ticks, and tick values Setting background colors ","id":3600,"permalink":"https://freshrimpsushi.github.io/en/posts/3600/","tags":null,"title":"How to Use RGB Color Codes in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Introduction1 Introducing the capabilities of Colors.jl, a package for color processing in Julia. When using the visualization package Plots.jl, there\u0026rsquo;s no need to load Colors.jl separately. It provides the following functionalities:\nColor parsing and conversion Color maps Color scales Parsing and Conversion Assuming str is a string representing color information, you can parse the string into a color code of a specific color space using @colorant_str or parse(Colorant, str). Note that colorant means a dye or pigment.\nHow to use RGB codes How to use HEX codes julia\u0026gt; using Colors\rjulia\u0026gt; colorant\u0026#34;red\u0026#34;\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; colorant\u0026#34;rgb(255, 0, 0)\u0026#34;\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; parse(Colorant, \u0026#34;rgba(0, 255, 0, 0.5)\u0026#34;)\rRGBA{N0f8}(0.0,1.0,0.0,0.502)\rjulia\u0026gt; parse(Colorant, \u0026#34;#FF0000\u0026#34;)\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; parse(Colorant, \u0026#34;hsl(120, 100%, 25%)\u0026#34;)\rHSL{Float32}(120.0f0,1.0f0,0.25f0) The convert() function can be used to convert to a color code of a different color space.\njulia\u0026gt; convert(RGB, HSL(270, 0.5, 0.5))\rRGB{Float64}(0.5,0.25,0.75) Color Interpolation Using the range() function, colors can be interpolated. This operation is quite logical and intuitive. For example, consider the RGB codes. Red is represented by $(255, 0, 0)$ or $(1, 0, 0)$, which is essentially a 3D vector. Therefore, there\u0026rsquo;s no reason not to use the color code as an argument for the range() function which interpolates between two vectors.\njulia\u0026gt; v1 = [1.0, 0.0, 0.0];\rjulia\u0026gt; v2 = [0.0, 0.5, 0.0];\rjulia\u0026gt; collect(range(v1, v2, length = 15))\r15-element Vector{Vector{Float64}}:\r[1.0, 0.0, 0.0]\r[0.9285714285714286, 0.03571428571428571, 0.0]\r[0.8571428571428572, 0.07142857142857142, 0.0]\r[0.7857142857142857, 0.10714285714285714, 0.0]\r[0.7142857142857143, 0.14285714285714285, 0.0]\r[0.6428571428571428, 0.17857142857142858, 0.0]\r[0.5714285714285714, 0.21428571428571427, 0.0]\r[0.5, 0.25, 0.0]\r[0.4285714285714286, 0.2857142857142857, 0.0]\r[0.3571428571428571, 0.32142857142857145, 0.0]\r[0.2857142857142857, 0.35714285714285715, 0.0]\r[0.2142857142857143, 0.39285714285714285, 0.0]\r[0.1428571428571429, 0.42857142857142855, 0.0]\r[0.0714285714285714, 0.4642857142857143, 0.0]\r[0.0, 0.5, 0.0]\rjulia\u0026gt; c1 = colorant\u0026#34;rgb(255, 0, 0)\u0026#34;\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; c2 = colorant\u0026#34;rgb(0, 128, 0)\u0026#34;\rRGB{N0f8}(0.0,0.502,0.0)\rjulia\u0026gt; range(colorant\u0026#34;rgb(255,0,0)\u0026#34;, colorant\u0026#34;rgb(0,128,0)\u0026#34;, length=15)\r15-element Array{RGB{N0f8},1} with eltype RGB{FixedPointNumbers.N0f8}:\rRGB{N0f8}(1.0,0.0,0.0)\rRGB{N0f8}(0.929,0.035,0.0)\rRGB{N0f8}(0.859,0.071,0.0)\rRGB{N0f8}(0.784,0.11,0.0)\rRGB{N0f8}(0.714,0.145,0.0)\rRGB{N0f8}(0.643,0.18,0.0)\rRGB{N0f8}(0.573,0.216,0.0)\rRGB{N0f8}(0.502,0.251,0.0)\rRGB{N0f8}(0.427,0.286,0.0)\rRGB{N0f8}(0.357,0.322,0.0)\rRGB{N0f8}(0.286,0.357,0.0)\rRGB{N0f8}(0.216,0.392,0.0)\rRGB{N0f8}(0.141,0.431,0.0)\rRGB{N0f8}(0.071,0.467,0.0)\rRGB{N0f8}(0.0,0.502,0.0) Visualization of the above color range can be obtained in VS Code by installing and running the Julia extension as follows.\nAlso, the return of range() can be used as a palette.\nmy_palette = range(colorant\u0026#34;rgb(255,0,0)\u0026#34;, colorant\u0026#34;rgb(0,128,0)\u0026#34;, length=15)\rplot(rand(10, 15), palette = my_palette) Environment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0, Colors v0.12.10 See Also How to Use Colors How to Use Palettes How to Use Color Gradients Package for Color Processing Colors.jl How to Use RGB Codes RGB(1, 0, 0) How to Use HEX Codes \u0026quot;#000000\u0026quot; How to Specify Colors for Graph Elements How to Specify Graph Colors for Each Subplot How to Specify Colors for Axes, Axis Labels, Ticks, and Tick Labels How to Set Background Color https://juliagraphics.github.io/Colors.jl/stable/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3599,"permalink":"https://freshrimpsushi.github.io/en/posts/3599/","tags":null,"title":"Package for Color Processing in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview The package that facilitates the convenient use of colors in Julia is Colors.jl. It can be used together just by importing the visualization package Plots.jl.\nSymbols and Strings The way to check the list of named colors is by entering Colors.color_names in the console window or checking the official documentation.\njulia\u0026gt; using Plots\rjulia\u0026gt; Colors.color_names\rDict{String, Tuple{Int64, Int64, Int64}} with 666 entries:\r\u0026#34;darkorchid\u0026#34; =\u0026gt; (153, 50, 204)\r\u0026#34;chocolate\u0026#34; =\u0026gt; (210, 105, 30)\r\u0026#34;chocolate2\u0026#34; =\u0026gt; (238, 118, 33)\r\u0026#34;grey69\u0026#34; =\u0026gt; (176, 176, 176)\r\u0026#34;grey97\u0026#34; =\u0026gt; (247, 247, 247)\r\u0026#34;olivedrab3\u0026#34; =\u0026gt; (154, 205, 50)\r\u0026#34;deeppink2\u0026#34; =\u0026gt; (238, 18, 137)\r\u0026#34;mediumpurple2\u0026#34; =\u0026gt; (159, 121, 238)\r\u0026#34;ivory1\u0026#34; =\u0026gt; (255, 255, 240)\r‚ãÆ =\u0026gt; ‚ãÆ Keywords that can designate colors basically allow the use of symbols and strings. Whether you enter the color name as a symbol or a string, the respective color is applied. It doesn‚Äôt matter what is entered as it is passed to Colors.parse(Colorant, color name), so the result is the same whether a symbol or string.\njulia\u0026gt; Colors.parse(Colorant, :red)\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; Colors.parse(Colorant, \u0026#34;red\u0026#34;)\rRGB{N0f8}(1.0,0.0,0.0) The results of designating colors in various graphs are as follows.\nplot(randn(50, 6),\rseriescolor = [:red :hotpink1 :purple3 \u0026#34;blue\u0026#34; \u0026#34;lime\u0026#34; \u0026#34;brown4\u0026#34;],\rseriestype = [:line :scatter :histogram :shape :sticks :steppre],\rlayout = (3,2)\r) RGB RGB color codes can be used like colorant\u0026quot;rgb(255, 0, 0)\u0026quot;. Only integers in $[0, 255]$ can be entered in rgb().\njulia\u0026gt; colorant\u0026#34;rgb(255, 0, 0)\u0026#34; # rgb() notation with integers in [0, 255]\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; colorant\u0026#34;rgba(0, 0, 255, 0.5)\u0026#34; # with alpha in [0, 1]\rRGBA{N0f8}(0.0,0.0,1.0,0.502)\rplot(rand(20, 2),\rseriescolor = [colorant\u0026#34;rgb(255, 0, 0)\u0026#34; colorant\u0026#34;rgba(0, 0, 255, 0.5)\u0026#34;],\rlayout = 2\r) For more details on handling RGB color codes, refer to here.\nHEX 6-digit HEX codes can be used like colorant\u0026quot;#FF0000\u0026quot;, and 3-digit HEX codes like colorant\u0026quot;#00f\u0026quot;.\njulia\u0026gt; colorant\u0026#34;#FF0000\u0026#34; # 6-digit hex notation\rRGB{N0f8}(1.0,0.0,0.0)\rjulia\u0026gt; colorant\u0026#34;#00f\u0026#34; # 3-digit hex notation\rRGB{N0f8}(0.0,0.0,1.0)\rjulia\u0026gt; plot(rand(20, 2),\rseriescolor = [colorant\u0026#34;#FF0000\u0026#34; colorant\u0026#34;#00f\u0026#34;],\rlayout = 2\r) For more details on handling HEX color codes, refer to here.\nEnvironment OS: Windows11 Version: Julia 1.9.4, Plots v1.39.0, Colors v0.12.10 See Also How to use colors How to use palettes How to use color gradients Package for color processing Colors.jl How to use RGB codes RGB(1, 0, 0) How to use HEX codes \u0026quot;#000000\u0026quot; How to designate colors for graph elements How to designate colors for each subplot How to designate colors for axes, axis names, ticks, and tick values How to designate background colors ","id":3598,"permalink":"https://freshrimpsushi.github.io/en/posts/3598/","tags":null,"title":"How to Use Colors in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Using the function printstyled(string; color = color) allows you to decorate the outputted function. As input for the keyword argument color, symbols and integers $(0 \\le n \\le 255)$ are possible. Note that strings are not allowed.\nThe available symbols include not only colors but also options like :blink, :reverse, etc. These can also be applied by entering them as keyword arguments like blink = true, bold = true.\n:normal :default :blink :bold :hidden :nothing :reverse :underline :white :light_white :black :light_black :blue :light_blue :cyan :light_cyan :green :light_green :magenta :light_magenta :red :light_red :yellow :light_yellow symbols = [:normal :default :blink :bold :hidden :nothing :reverse :underline :white :light_white :black :light_black :blue :light_blue :cyan :light_cyan :green :light_green :magenta :light_magena :red :light_red :yellow :light_yellow]\rfor i ‚àà 1:length(symbols)\rprintstyled(\u0026#34;Hello ($(symbols[i]))\\n\u0026#34;, color = symbols[i])\rend Entering Base.text_colors returns all possible values for the keyword argument (including symbols).\njulia\u0026gt; Base.text_colors\rDict{Union{Int64, Symbol}, String} with 280 entries:\r56 =\u0026gt; \u0026#34;\\e[38;5;56m\u0026#34;\r35 =\u0026gt; \u0026#34;\\e[38;5;35m\u0026#34;\r60 =\u0026gt; \u0026#34;\\e[38;5;60m\u0026#34;\r220 =\u0026gt; \u0026#34;\\e[38;5;220m\u0026#34;\r:blink =\u0026gt; \u0026#34;\\e[5m\u0026#34;\r67 =\u0026gt; \u0026#34;\\e[38;5;67m\u0026#34;\r215 =\u0026gt; \u0026#34;\\e[38;5;215m\u0026#34;\r73 =\u0026gt; \u0026#34;\\e[38;5;73m\u0026#34;\r251 =\u0026gt; \u0026#34;\\e[38;5;251m\u0026#34;\r115 =\u0026gt; \u0026#34;\\e[38;5;115m\u0026#34;\r‚ãÆ =\u0026gt; ‚ãÆ See Also The package Crayons.jl can also be used.\nEnvironment OS: Windows11 Version: Julia 1.9.4 ","id":3597,"permalink":"https://freshrimpsushi.github.io/en/posts/3597/","tags":null,"title":"Decorating Text Output with Built-in Functions in Julia"},{"categories":"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô","contents":"Definition Let\u0026rsquo;s assume a data set $X \\subset \\mathbb{R}^{n}$ is given. The following mapping for $m \\lt n$ is called dimension reductiondimension reduction.\n$$ r : X \\to \\mathbb{R}^{m} $$\nOr more commonly in machine learning, any method that reduces the number of input variables in a way that retains as much of the performance as possible is called a dimension reduction technique.\nExplanation Dimension reduction, as the name suggests, refers to reducing the dimensionality of vectors. It is often used to make data easier and more intuitive to understand. The method of reduction varies by algorithm. It might involve outright deleting certain components or creating new, lower-dimensional data from the existing data according to predefined rules. The following are some of the techniques:\nPrincipal Component AnalysisPCA Principal Component Analysis in Mathematical Statistics Purpose Visualization It is practically impossible to efficiently visualize data with more than four dimensions. Even with three-dimensional data, depending on its form, there can be difficulties in visualization. Difficulties in visualization mean that it is challenging to draw pictures that well represent the features of the data. For three-dimensional data, the shape may appear differently depending on the viewpoint. In such cases, reducing the dimensionality for drawing can make it easier to grasp the features of the data. The picture below shows an example where the same data looks significantly different depending on the viewing direction. The right picture is a projection of the left data onto the $xy$-plane.\nThe Iris dataset, which is four-dimensional data, is often introduced in many data science textbooks as being visualized by splitting it into several two-dimensional figures like the following.\nFocus and Selection Dimension reduction can be used to discard less important information to focus more on the important information. \u0026ldquo;Less important information\u0026rdquo; here refers to noise or redundant information. For example, looking at the left table below, one can see that the first column has the same value for all data. Also, the second and third columns have different values but are essentially the same. Thus, dimension reduction can be done by discarding the first column and either the second or third column. Furthermore, the right table summarizes weather information for Daegu. At first glance, it might seem like there is no unnecessary information, but since \u0026ldquo;daily temperature range = maximum temperature - minimum temperature,\u0026rdquo; these three are not linearly independent, and actually, errors can occur in regression analysis. Therefore, in this case, deleting the fourth column to remove multicollinearity is an example of dimension reduction.\nSchool\rGrade\rGroup\rName\rHive High School\r3rd grade\rfromis_9\rLEE NA GYUNG\rHive High School\r3rd grade\rfromis_9\rBAEK JI HEON\rHive High School\r2nd grade\rLE SSERAFIM\rKIM CHAEWON\rHive High School\r2nd grade\rLE SSERAFIM\rHUH YUNJIN\rHive High School\r1st grade\rNewJeans\rHAERIN\rHive High School\r1st grade\rNewJeans\rMINJI\rDate\rHigh Temp\rLow Temp\rDaily\nTemp Range\rPrecipitation\nProbability\r19th\r32¬∫\r24¬∫\r8¬∫\r60%\r20th\r33¬∫\r22¬∫\r11¬∫\r0%\r21st\r32¬∫\r23¬∫\r9¬∫\r30%\r22nd\r30¬∫\r21¬∫\r9¬∫\r60%\r23rd\r31¬∫\r24¬∫\r7¬∫\r60%\r24th\r33¬∫\r25¬∫\r8¬∫\r60%\rLightweighting Reducing the dimensions of data means there are fewer numbers to store, thereby reducing the data\u0026rsquo;s storage size. In the case of artificial neural networks, MLPs consist of linear layers where the dimension of input data influences the number of model parameters. Dimension reduction can be used here to reduce the number of model parameters. Even in models like CNNs, where the input data\u0026rsquo;s dimensions do not affect the number of model parameters, reducing dimensions can still offer computational speed advantages.\nPreventing Overfitting Appropriate dimension reduction is known to be able to prevent overfitting to some extent.\n","id":3563,"permalink":"https://freshrimpsushi.github.io/en/posts/3563/","tags":null,"title":"Dimensionality Reduction in Data Science"},{"categories":"Î®∏Ïã†Îü¨Îãù","contents":"Overview In TensorFlow, neural networks can be easily defined using Keras. Below, we introduce how to define and train a simple MLP using Sequential() and the functional API. However, Sequential() is only easy for defining models and can be challenging to use for designing complex structures. Similarly, if you plan to design complex structures using the functional API, it‚Äôs better to use the keras.Model class, and for even more complex and customizable designs, implementing at a lower level without Keras might be preferable. Depending on the deep learning task, these methods might not be the primary choice, especially for researchers in STEM fields looking to integrate deep learning into their domain. These methods are more about getting a feel for \u0026rsquo;this is how it\u0026rsquo;s used\u0026rsquo; when first learning and practicing deep learning.\nSequential Model Model Definition Let‚Äôs define an MLP with input and output dimensions of 1 to approximate the sine function $\\sin : \\mathbb{R} \\to \\mathbb{R}$ as follows.\nimport tensorflow as tf\rfrom tensorflow.keras import Sequential\rfrom tensorflow.keras.layers import Dense\r# model define\rmodel = Sequential([Dense(10, input_dim = 1, activation = \u0026#34;relu\u0026#34;),\rDense(10, input_dim = 10, activation = \u0026#34;relu\u0026#34;),\rDense(1, input_dim = 10)])\rmodel.summary() # output‚Üì\r# Model: \u0026#34;sequential_3\u0026#34;\r# _________________________________________________________________\r# Layer (type) Output Shape Param # # =================================================================\r# dense_9 (Dense) (None, 10) 20 # # dense_10 (Dense) (None, 10) 110 # # dense_11 (Dense) (None, 1) 11 # # =================================================================\r# Total params: 141\r# Trainable params: 141\r# Non-trainable params: 0\r# _________________________________________________________________ One feature of keras.layers.Dense() is that it\u0026rsquo;s not necessary to specify the input dimensions. The reason for this allowance is unclear, but for readability (especially in code that others might see), it\u0026rsquo;s better to explicitly state the input dimensions. This results in a characteristic where the output dimensions are on the left and input dimensions on the right. To read the structure of the model, one must read from right to left, which is not the standard in most languages. If we consider a linear layer as a matrix in terms of linear transformation, then it\u0026rsquo;s natural for the input to be on the right and the output on the left as in $\\mathbf{y} = A\\mathbf{x}$. However, TensorFlow wasn‚Äôt necessarily designed with such mathematical precision in mind. Even in Julia, known for its mathematical rigor, linear layers are implemented as Dense(in, out), which is naturally read from left to right. After all, it‚Äôs more comfortable and easier to understand. Moreover, the notation of a function $f$ from $X$ to $Y$ is $f : X \\to Y$, and there‚Äôs no function anywhere (apart from Keras) that is described as mapping from right to left.\nData Generation Since we are training a sine function, if we take the function values as data and compare the graph of the sine function with the model\u0026rsquo;s output, it will look like this:\n# generating data\rfrom math import pi\rx = tf.linspace(0., 2*pi, num=1000) # ÂÖ•Âäõ„Éá„Éº„Çø\ry = tf.sin(x) # Âá∫Âäõ„Éá„Éº„Çø(label)\r# check output of model\rimport matplotlib.pyplot as plt\rplt.plot(x, model(x), label=\u0026#34;model\u0026#34;)\rplt.plot(x, y, label=\u0026#34;sin\u0026#34;)\rplt.legend()\rplt.show() Training and Results from tensorflow.keras.optimizers import Adam\rmodel.compile(optimizer=Adam(learning_rate=0.001), loss=\u0026#39;mse\u0026#39;) model.compile(optimizer, loss, metric) The .compile() method specifies the optimizer and loss function. Another key option is metric, which is a function for evaluating the model. It can be the same as or different from the loss. For example, if training an MLP on the MNIST dataset, the loss might be the MSE between the output and the label, while the metric could be the ratio of correctly predicted data out of the total.\n\u0026gt; model.fit(x, y, epochs=10000, batch_size=1000, verbose=\u0026#39;auto\u0026#39;)\r.\r.\r.\rEpoch 9998/10000\r1/1 [==============================] - 0s 8ms/step - loss: 6.2260e-06\rEpoch 9999/10000\r1/1 [==============================] - 0s 4ms/step - loss: 6.2394e-06\rEpoch 10000/10000\r1/1 [==============================] - 0s 3ms/step - loss: 6.2385e-06 The .fit() method takes inputs, labels, epochs, batch sizes, etc., and executes the training. verbose determines how the training progress is output. There are options 0, 1, 2, where 0 outputs nothing. The others output in the following format: # verbose=1\rEpoch (current epoch)/(total epochs)\r(current batch)/(total batchs) [==============================] - 0s 8ms/step - loss: 0.7884\r# verbose=2\rEpoch (current epoch)/(total epochs)\r(current batch)/(total batchs) - 0s - loss: 0.7335 - 16ms/epoch - 8ms/step After training, comparing the sine function with the model\u0026rsquo;s function values shows that the training was successful.\nFunctional API This method directly connects layers using the Input() and Model() functions. For simple models like MLPs, defining them using the Sequential model above is much more convenient. The method to define the same structure as the neural network defined in the Sequential model above is as follows:\nfrom tensorflow.keras import Model\rfrom tensorflow.keras.layers import Input, Dense\rinput = Input(shape=(10)) # \u0026#34;dim of output = dim of input in 1st layer\u0026#34;\rdense1 = Dense(10, activation = \u0026#34;relu\u0026#34;)(input)\rdense2 = Dense(10, activation = \u0026#34;relu\u0026#34;)(dense1)\routput = Dense(1)(dense2)\rmodel = Model(inputs=input, outputs=output)\rmodel.summary() # output‚Üì\r# Model: \u0026#34;model_10\u0026#34;\r# _________________________________________________________________\r# Layer (type) Output Shape Param #\r# =================================================================\r# input_13 (InputLayer) [(None, 1)] 0\r# # dense_19 (Dense) (None, 10) 20\r# # dense_20 (Dense) (None, 10) 110\r# # dense_21 (Dense) (None, 1) 11\r# # =================================================================\r# Total params: 141\r# Trainable params: 141\r# Non-trainable params: 0\r# _________________________________________________________________ Input is a function for defining the input layer. Strictly speaking, it‚Äôs not a layer but a tensor, but this is a minor detail. A confusing point is that the output dimension should be input as a variable. In other words, the input dimension of the first layer should be input. After defining this, connect each layer directly and explicitly as input to the Dense function. Finally, input the input and output as arguments to the Model function to define the model.\nThe subsequent process of compiling the model with the .compile() method and training it with the .fit() method is the same as introduced above.\nEnvironment OS: Windows11 Version: Python 3.9.13, tensorflow==2.12.0, keras==2.12.0 ","id":3562,"permalink":"https://freshrimpsushi.github.io/en/posts/3562/","tags":null,"title":"How to Define and Train MLP with the Sequence Model and Functional API in TensorFlow and Keras"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code Size plot(x, y, size=(600,400)) In Julia, the size of a plot is set using the size option. It must be input as a Tuple{Integer, Integer}, where each integer represents the width and height in pixels, respectively. The default value is (600,400).\nusing Plots\rx = rand(10)\rplot(x)\rsavefig(\u0026#34;size_default.png\u0026#34;)\rplot(x, size=(1200,800))\rsavefig(\u0026#34;size_(1200,800).png\u0026#34;) 1800x1200 image (left), 600x400 image (right) Resolution plot(x, y, dpi=100) The resolution of an image is set using the dpi option, with the default value being 100. It‚Äôs advisable to use about 300 for documents to be included in papers, reports, PowerPoint presentations, etc.\nusing Plots\rx = rand(10)\rplot(x)\rsavefig(\u0026#34;dpi_default.png\u0026#34;)\rplot(x, dpi=300) savefig(\u0026#34;dpi_300.png\u0026#34;) dpi=100 image (top), dpi=300 image (bottom) Also, when increasing the size, it‚Äôs necessary to increase the resolution as well to maintain the attractiveness of the image. If you save with the dpi set to 300 and the size increases to 1800x1200, but keep the dpi at the default value of 100 while increasing just the size, the image will become unattractive, so pay attention.\ndpi=300, size=1800x1200 image (left), dpi=100, size=1800x1200 image (right) Environment OS: Windows11 Version: Julia 1.9.0, Plots v1.38.12 ","id":3559,"permalink":"https://freshrimpsushi.github.io/en/posts/3559/","tags":null,"title":"How to Adjust the Size and Resolution of an Image in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code plot!([x1, x2], [y1, y2], arrow=:true) This code plots an arrow from point $(x1, y1)$ to point $(x2, y2)$ on the plot. Naturally, the tip of the arrow is at the terminal point $(x2, y2)$. The maximum value of the sine function can be shown as follows.\nusing Plots\rx = range(0, 2œÄ, 100)\rplot(x, sin.(x), label=\u0026#34;\u0026#34;, ylims=(-1.3,1.3))\rplot!([œÄ/2, 3], [1, 1.1], arrow=:true, color=:black, label=\u0026#34;\u0026#34;)\rannotate!(3.7, 1.1, \u0026#34;maximum\u0026#34;) Arrow tip The style of the tip can be chosen as :open or :closed.\nNot specified or :true: a polyline $\\to$ plot!([3œÄ/2, 3], [-1, -1.1], arrow=:open, color=:red, label=\u0026#34;\u0026#34;)\rannotate!(2.3, -1.1, \u0026#34;minimum\u0026#34;) Arrow direction The direction of the tip can be set to :head, :tail, :both, with :head being the default.\nplot!([œÄ/2, œÄ/2], [0, 1], arrow=(:closed, :both), color=:purple, label=\u0026#34;\u0026#34;)\rannotate!(0.75œÄ, 0.5, \u0026#34;amplitude\u0026#34;) In the official documentation1, there are explanations about the headlength and headwidth options, but trying to use them only leads to errors and it is unclear how to use them.\nEnvironment OS: Windows11 Version: Julia 1.9.0, Plots v1.38.12 https://docs.juliaplots.org/v1.38/api/#Plots.arrow-Tuple\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3558,"permalink":"https://freshrimpsushi.github.io/en/posts/3558/","tags":null,"title":"Drawing Arrows in Graphics with Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Explanation1 In Julia, the random seed can be fixed as follows:\nseed!([rng=default_rng()], seed) -\u0026gt; rng seed!([rng=default_rng()]) -\u0026gt; rng The input variable rng stands for Random Number Generator, which refers to the algorithm used for drawing random numbers. The Random package offers the following options:\nTaskLocalRNG: This is the default setting. Xoshiro RandomDevice MersenneTwister Code By fixing the seed to 0, drawing three times, and then fixing it again to 0 and drawing three times, it can be verified that the same values are obtained.\njulia\u0026gt; using Random\rjulia\u0026gt; Random.seed!(0)\rTaskLocalRNG()\rjulia\u0026gt; rand(1)\r1-element Vector{Float64}:\r0.4056994708920292\rjulia\u0026gt; rand(1)\r1-element Vector{Float64}:\r0.06854582438651502\rjulia\u0026gt; rand(1)\r1-element Vector{Float64}:\r0.8621408571954849\rjulia\u0026gt; Random.seed!(0)\rTaskLocalRNG()\rjulia\u0026gt; rand(3)\r3-element Vector{Float64}:\r0.4056994708920292\r0.06854582438651502\r0.8621408571954849 https://docs.julialang.org/en/v1/stdlib/Random/index.html#Random.seed!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3555,"permalink":"https://freshrimpsushi.github.io/en/posts/3555/","tags":null,"title":"How to Fix the Random Seed in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"English Translation Description To draw a box plot, the statistical visualization package StatsPlots.jl must be used.\nboxplot([data], labels=[label]) Code using StatsPlots\rx = rand(0:100, 100)\ry = rand(50:100, 100)\rz = cat(x,y, dims=1)\rboxplot(x, label=\u0026#34;x\u0026#34;)\rboxplot!(y, label=\u0026#34;y\u0026#34;)\rboxplot!(z, label=\u0026#34;z\u0026#34;) Or boxplot([x,y,z], label=[\u0026quot;x\u0026quot; \u0026quot;y\u0026quot; \u0026quot;z\u0026quot;]) will draw the same figure. Note that there should be no commas in lable. That is, it needs to be an array, not an $3 \\times 1$ vector as in $1 \\times 3$.\nx-axis tick If you want to represent the x-axis ticks with strings,\nboxplot([x, y, z], xticks=(1:3, [\u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;, \u0026#34;z\u0026#34;]), label=[\u0026#34;x\u0026#34; \u0026#34;y\u0026#34; \u0026#34;z\u0026#34;]) Or the code below will also draw the same figure. The difference is how the actual coordinates are. In the code above, the actual x-coordinates where each box is drawn are 1, 2, 3, but it just appears with the tick values as x, y, z. The code below actually draws boxes on the \u0026ldquo;x\u0026rdquo;, \u0026ldquo;y\u0026rdquo;, \u0026ldquo;z\u0026rdquo; coordinates.\nDrawing with a 2D array a = rand(100, 3)\rboxplot(a, xticks=(1:3, [\u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;, \u0026#34;z\u0026#34;]), label=[\u0026#34;x\u0026#34; \u0026#34;y\u0026#34; \u0026#34;z\u0026#34;]) Drawing with a data frame Data frames cannot be drawn on their own and need to be converted to an array.\nusing MLDatasets\rusing DataFrames\rdf = Iris().features\rboxplot(Array(df), xticks=(1:4, names(df)), label=reshape(names(df), (1,4))) Average There is no separate option to display the average. Use scatter to plot it.\nusing Statistics\rboxplot(fill(\u0026#34;x\u0026#34;, length(x)), x, labels=\u0026#34;x\u0026#34;)\rboxplot!(fill(\u0026#34;y\u0026#34;, length(y)), y, labels=\u0026#34;y\u0026#34;)\rboxplot!(fill(\u0026#34;z\u0026#34;, length(z)), z, labels=\u0026#34;z\u0026#34;)\rscatter!([\u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;, \u0026#34;z\u0026#34;], [mean(x), mean(y), mean(z)], color=palette(:default)[1:3], label=\u0026#34;\u0026#34;) Or the following code also draws the same picture.\nboxplot([x, y, z], xticks=(1:3, [\u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;, \u0026#34;z\u0026#34;]), label=[\u0026#34;x\u0026#34; \u0026#34;y\u0026#34; \u0026#34;z\u0026#34;])\rscatter!([1, 2, 3], [mean(x), mean(y), mean(z)], color=palette(:default)[1:3], label=\u0026#34;\u0026#34;) Environment OS: Windows11 Version: Julia 1.9.0, Plots v1.38.12, StatsPlots v0.15.5, DataFrames v1.5.0, MLDatasets v0.7.11 See Also How to draw with Python matplotlib ","id":3553,"permalink":"https://freshrimpsushi.github.io/en/posts/3553/","tags":null,"title":"How to Draw a Box Plot in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Introducing the DecisionTree.jl package, which implements Decision Trees in Julia1.\nCode As an example, we use the iris dataset, a classic built-in dataset in R. Our goal is to create a decision tree that uses four variables SepalLength, SepalWidth, PetalLength, PetalWidth to predict Species and evaluate its performance.\njulia\u0026gt; iris = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;iris\u0026#34;)\r150√ó5 DataFrame\rRow ‚îÇ SepalLength SepalWidth PetalLength PetalWidth Speci ‚ãØ\r‚îÇ Float64 Float64 Float64 Float64 Cat‚Ä¶ ‚ãØ\r‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\r1 ‚îÇ 5.1 3.5 1.4 0.2 setos ‚ãØ\r2 ‚îÇ 4.9 3.0 1.4 0.2 setos 3 ‚îÇ 4.7 3.2 1.3 0.2 setos 4 ‚îÇ 4.6 3.1 1.5 0.2 setos 5 ‚îÇ 5.0 3.6 1.4 0.2 setos ‚ãØ\r6 ‚îÇ 5.4 3.9 1.7 0.4 setos 7 ‚îÇ 4.6 3.4 1.4 0.3 setos 8 ‚îÇ 5.0 3.4 1.5 0.2 setos 9 ‚îÇ 4.4 2.9 1.4 0.2 setos ‚ãØ\r10 ‚îÇ 4.9 3.1 1.5 0.1 setos 11 ‚îÇ 5.4 3.7 1.5 0.2 setos 12 ‚îÇ 4.8 3.4 1.6 0.2 setos 13 ‚îÇ 4.8 3.0 1.4 0.1 setos ‚ãØ\r14 ‚îÇ 4.3 3.0 1.1 0.1 setos 15 ‚îÇ 5.8 4.0 1.2 0.2 setos ‚ãÆ ‚îÇ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ãÆ ‚ã±\r136 ‚îÇ 7.7 3.0 6.1 2.3 virgi 137 ‚îÇ 6.3 3.4 5.6 2.4 virgi ‚ãØ\r138 ‚îÇ 6.4 3.1 5.5 1.8 virgi 139 ‚îÇ 6.0 3.0 4.8 1.8 virgi 140 ‚îÇ 6.9 3.1 5.4 2.1 virgi 141 ‚îÇ 6.7 3.1 5.6 2.4 virgi ‚ãØ\r142 ‚îÇ 6.9 3.1 5.1 2.3 virgi 143 ‚îÇ 5.8 2.7 5.1 1.9 virgi 144 ‚îÇ 6.8 3.2 5.9 2.3 virgi 145 ‚îÇ 6.7 3.3 5.7 2.5 virgi ‚ãØ\r146 ‚îÇ 6.7 3.0 5.2 2.3 virgi 147 ‚îÇ 6.3 2.5 5.0 1.9 virgi 148 ‚îÇ 6.5 3.0 5.2 2.0 virgi 149 ‚îÇ 6.2 3.4 5.4 2.3 virgi ‚ãØ\r150 ‚îÇ 5.9 3.0 5.1 1.8 virgi 1 column and 120 rows omitted Model Creation julia\u0026gt; using DecisionTree\rjulia\u0026gt; model = DecisionTreeClassifier(max_depth=2)\rDecisionTreeClassifier\rmax_depth: 2\rmin_samples_leaf: 1\rmin_samples_split: 2\rmin_purity_increase: 0.0\rpruning_purity_threshold: 1.0\rn_subfeatures: 0\rclasses: nothing\rroot: nothing Create the model. Parameters for the decision tree can be given through DecisionTreeClassifier().\nModel Fitting julia\u0026gt; features = Matrix(iris[:, Not(:Species)]);\rjulia\u0026gt; labels = iris.Species;\rjulia\u0026gt; fit!(model, features, labels) DecisionTreeClassifier\rmax_depth: 2\rmin_samples_leaf: 1\rmin_samples_split: 2\rmin_purity_increase: 0.0\rpruning_purity_threshold: 1.0\rn_subfeatures: 0\rclasses: [\u0026#34;setosa\u0026#34;, \u0026#34;versicolor\u0026#34;, \u0026#34;virginica\u0026#34;]\rroot: Decision Tree Leaves: 3\rDepth: 2 Divide the data into independent and dependent variables and train the model using the fit!() function.\nPerformance Check julia\u0026gt; print_tree(model)\rFeature 3 \u0026lt; 2.45 ?\r‚îú‚îÄ setosa : 50/50\r‚îî‚îÄ Feature 4 \u0026lt; 1.75 ?\r‚îú‚îÄ versicolor : 49/54\r‚îî‚îÄ virginica : 45/46 After training, the structure of the model can be checked with the print_tree() function.\njulia\u0026gt; sum(labels .== predict(model, features)) / length(labels)\r0.96 A quick check of the accuracy rate showed it was around 96%, which is quite decent.\nFull Code using RDatasets\riris = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;iris\u0026#34;)\rusing DecisionTree\rmodel = DecisionTreeClassifier(max_depth=2)\rfeatures = Matrix(iris[:, Not(:Species)]);\rlabels = iris.Species;\rfit!(model, features, labels)\rprint_tree(model)\rsum(labels .== predict(model, features)) / length(labels) Environment OS: Windows julia: v1.9.0 https://github.com/JuliaAI/DecisionTree.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2618,"permalink":"https://freshrimpsushi.github.io/en/posts/2618/","tags":null,"title":"How to Use Decision Trees in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview This section introduces how to remove and check for duplicates in collections in Julia. The unique() function, which eliminates duplicates, is algorithmically straightforward, but can be bothersome to implement on your own, and may not be efficient. The allunique() function, which checks for the absence of duplicate elements, is easy enough to implement that one might not have sought it out, so it‚Äôs worth getting familiar with.\nCode unique() julia\u0026gt; x = [3, 1, 4, 1, 5, 9, 2, 6, 5];\rjulia\u0026gt; y = unique(x)\r7-element Vector{Int64}:\r3\r1\r4\r5\r9\r2\r6 allunique() 1 In fact, the purpose of this post is to introduce allunique(). One common sense way to check if a collection has duplicate elements is to see if length(unique(x)) == length(x) by applying unique() to see if the number of elements has decreased.\nThis method might seem too easy to be overconfident about its efficiency; however, the unique() function has to look at every element of an array of length $n$ at least once, which means its time complexity is $O (n)$. This could certainly be a noticeable burden when frequently checking for duplicates in code, and allunique() offers a clear advantage in performance as it may vary its implementation based on the array\u0026rsquo;s length and can stop its calculation upon finding a duplicate, thereby efficiently determining success.\njulia\u0026gt; allunique(x)\rfalse\rjulia\u0026gt; allunique(y)\rtrue Complete Code x = [3, 1, 4, 1, 5, 9, 2, 6, 5];\ry = unique(x)\rallunique(x)\rallunique(y) Environment OS: Windows julia: v1.9.0 https://docs.julialang.org/en/v1/base/collections/#Base.allunique\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2616,"permalink":"https://freshrimpsushi.github.io/en/posts/2616/","tags":null,"title":"How to Remove Duplicates from a Collection in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, the package for clustering offered is Clustering.jl1. The algorithms implemented include:\nK-means K-medoids Affinity Propagation Density-based spatial clustering of applications with noise (DBSCAN) Markov Clustering Algorithm (MCL) Fuzzy C-Means Clustering Hierarchical Clustering Single Linkage Average Linkage Complete Linkage Ward\u0026rsquo;s Linkage Code DBSCAN DBSCAN (Density-based spatial clustering of applications with noise) is implemented with the dbscan() function. If there are $n$ pieces of data in $p$ dimensions, a matrix of size $p \\times n$ and a radius should be given as arguments.\njulia\u0026gt; points = [iris.PetalLength iris.PetalWidth]\u0026#39;\r2√ó150 adjoint(::Matrix{Float64}) with eltype Float64:\r1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 ‚Ä¶ 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8 julia\u0026gt; dbscaned = dbscan(points, 0.5)\rDbscanResult(DbscanCluster[DbscanCluster(50, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ‚Ä¶ 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], Int64[]), DbscanCluster(100, [51, 52, 53, 54, 55, 56, 57, 58, 59, 60 ‚Ä¶ 141, 142, 143, 144, 145, 146, 147, 148, 149, 150], Int64[])], [1, 51], [50, 100], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ‚Ä¶ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\rjulia\u0026gt; dbscaned |\u0026gt; propertynames\r(:clusters, :seeds, :counts, :assignments) The result of DBSCAN is returned as a structure called DbscanResult. .assignments and .cluster are important for us.\nHow each data point belongs to each cluster can be obtained through the getproperty() function as follows.\njulia\u0026gt; getproperty.(dbscaned.clusters, :core_indices)\r2-element Vector{Vector{Int64}}:\r[1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ‚Ä¶ 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\r[51, 52, 53, 54, 55, 56, 57, 58, 59, 60 ‚Ä¶ 141, 142, 143, 144, 145, 146, 147, 148, 149, 150] Which cluster each data point belongs to can be known through the .assignments property as follows.\njulia\u0026gt; dbscaned.assignments\r150-element Vector{Int64}:\r1\r1\r1\r1\r1\r1\r1\r1\r1\r1\r1\r1\r1\r1\r1\r‚ãÆ\r2\r2\r2\r2\r2\r2\r2\r2\r2\r2\r2\r2\r2\r2 As a tip for visualization, since clusters are assigned arbitrary integers, putting *.assignments directly into the color option when drawing a scatter plot assigns colors corresponding to each cluster as follows.\nscatter(iris.PetalLength, iris.PetalWidth,\rxlabel = \u0026#34;PetalLength\u0026#34;, ylabel = \u0026#34;PetalWidth\u0026#34;,\rcolor = dbscaned.assignments) It can be confirmed that the clustering has been performed well.\nFull Code using Clustering\rusing RDatasets\riris = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;iris\u0026#34;)\rscatter(iris.PetalLength, iris.PetalWidth, xlabel = \u0026#34;PetalLength\u0026#34;, ylabel = \u0026#34;PetalWidth\u0026#34;)\rpng(\u0026#34;iris\u0026#34;)\rpoints = [iris.PetalLength iris.PetalWidth]\u0026#39;\rdbscaned = dbscan(points, 0.5)\rdbscaned |\u0026gt; propertynames\rgetproperty.(dbscaned.clusters, :core_indices)\rdbscaned.assignments\rscatter(iris.PetalLength, iris.PetalWidth,\rxlabel = \u0026#34;PetalLength\u0026#34;, ylabel = \u0026#34;PetalWidth\u0026#34;,\rcolor = dbscaned.assignments) Environment OS: Windows julia: v1.9.0 Clustering v0.15.4 https://github.com/JuliaStats/Clustering.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2613,"permalink":"https://freshrimpsushi.github.io/en/posts/2613/","tags":null,"title":"How to Use Clustering Packages in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, the Zygote.jl package is used for automatic differentiation, especially in the field of machine learning, and particularly for deep learning. The developers promote this package as the next-generation automatic differentiation system that enables differentiable programming in Julia, and indeed, using it can be surprisingly intuitive.\nIf you are curious about packages related to the derivative itself, not automatic differentiation, check out the Calculus.jl package.\nCode Univariate Functions It\u0026rsquo;s incredibly simple. Just like when we differentiate normally, appending a prime ' to the function name computes the derivative as if we are working with an actual derivative.\njulia\u0026gt; using Zygote\rjulia\u0026gt; p(x) = 2x^2 + 3x + 1\rp (generic function with 1 method)\rjulia\u0026gt; p(2)\r15\rjulia\u0026gt; p\u0026#39;(2)\r11.0\rjulia\u0026gt; p\u0026#39;\u0026#39;(2)\r4.0 Multivariate Functions Use the gradient() function.\njulia\u0026gt; g(x,y) = 3x^2 + 2y + x*y\rg (generic function with 1 method)\rjulia\u0026gt; gradient(g, 2,-1)\r(11.0, 4.0) If you want to write code a bit more intuitively, you can redefine the function using \\nabla, or ‚àá, like below.\njulia\u0026gt; ‚àá(f, v...) = gradient(f, v...)\r‚àá (generic function with 1 method)\rjulia\u0026gt; ‚àá(g, 2, -1)\r(11.0, 4.0) Full Code using Zygote\rp(x) = 2x^2 + 3x + 1\rp(2)\rp\u0026#39;(2)\rp\u0026#39;\u0026#39;(2)\rg(x,y) = 3x^2 + 2y + x*y\rgradient(g, 2,-1)\r‚àá(f, v...) = gradient(f, v...)\r‚àá(g, 2, -1) Environment OS: Windows julia: v1.9.0 Zygote: v0.6.62 ","id":2609,"permalink":"https://freshrimpsushi.github.io/en/posts/2609/","tags":null,"title":"Julia's Automatic Differentiation Package Zygote.jl"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, there are mainly two ways to reference the properties of a structure. They should be used appropriately according to grammatical convenience or actual use.\nCode For example, in Julia, the // operator creates a Rational type of number as follows. The names of the properties that a rational number has include :num meaning numerator and :den meaning denominator.\njulia\u0026gt; q = 7 // 12\r7//12\rjulia\u0026gt; q |\u0026gt; typeof\rRational{Int64}\rjulia\u0026gt; q |\u0026gt; propertynames\r(:num, :den) getproperty(x, :y) and x.y julia\u0026gt; getproperty(q, :den)\r12\rjulia\u0026gt; q.den\r12 Essentially, you just need to provide the name of the property as a symbol in the second argument of the getproperty() function. Or, as in many common programming languages, you can access the property by appending a dot after the object variable name.\nReference to Properties of Arrays Meanwhile, the above method can be used when needed just once, but if you need to access several elements in an array, you should use broadcasting as follows. Or, if performance is not important and quick coding is needed, using list comprehension like Python is also an option.\njulia\u0026gt; Q = [k // 12 for k in 1:12]\r12-element Vector{Rational{Int64}}:\r1//12\r1//6\r1//4\r1//3\r5//12\r1//2\r7//12\r2//3\r3//4\r5//6\r11//12\r1//1\rjulia\u0026gt; getproperty.(Q, :num)\r12-element Vector{Int64}:\r1\r1\r1\r1\r5\r1\r7\r2\r3\r5\r11\r1\rjulia\u0026gt; [q.num for q in Q]\r12-element Vector{Int64}:\r1\r1\r1\r1\r5\r1\r7\r2\r3\r5\r11\r1 Full Code q = 7 // 12 q |\u0026gt; typeof q |\u0026gt; propertynames getproperty(q, :den) q.den Q = [k // 12 for k in 1:12] getproperty.(Q, :num) [q.num for q in Q] Environment OS: Windows julia: v1.9.0 ","id":2607,"permalink":"https://freshrimpsushi.github.io/en/posts/2607/","tags":null,"title":"Referencing Struct Properties as Functions in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code quiver(, quiver=) In Julia, the quiver() function can be used to visualize a vector field.\nŒ∏ = 0:0.2:2œÄ\rquiver(cos.(Œ∏),sin.(Œ∏), quiver = (-sin.(Œ∏), cos.(Œ∏)), size = (600,600), lims = (-2,2)); png(\u0026#34;1\u0026#34;) Changing the Length of Arrows There might be a better way to change the size of the arrows, but essentially, you can draw a better picture by increasing or decreasing the length of vectors provided by the quiver= option.\nquiver(cos.(Œ∏),sin.(Œ∏), quiver = (-sin.(Œ∏), cos.(Œ∏)) ./ 2, size = (600,600), lims = (-2,2)); png(\u0026#34;2\u0026#34;) Environment OS: Windows julia: v1.9.0 ","id":2605,"permalink":"https://freshrimpsushi.github.io/en/posts/2605/","tags":null,"title":"How to Draw Vector Fields in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview When multiple arrays are given, there are often situations where one wants to access a specific element of these arrays, for example, the third element in each array. In Julia, this can be implemented through broadcasting the getindex() function.\nCode getindex.() julia\u0026gt; seq_ = [collect(1:k:100) for k in 1:10]\r10-element Vector{Vector{Int64}}:\r[1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ‚Ä¶ 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\r[1, 3, 5, 7, 9, 11, 13, 15, 17, 19 ‚Ä¶ 81, 83, 85, 87, 89, 91, 93, 95, 97, 99]\r[1, 4, 7, 10, 13, 16, 19, 22, 25, 28 ‚Ä¶ 73, 76, 79, 82, 85, 88, 91, 94, 97, 100]\r[1, 5, 9, 13, 17, 21, 25, 29, 33, 37 ‚Ä¶ 61, 65, 69, 73, 77, 81, 85, 89, 93, 97]\r[1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96]\r[1, 7, 13, 19, 25, 31, 37, 43, 49, 55, 61, 67, 73, 79, 85, 91, 97]\r[1, 8, 15, 22, 29, 36, 43, 50, 57, 64, 71, 78, 85, 92, 99]\r[1, 9, 17, 25, 33, 41, 49, 57, 65, 73, 81, 89, 97]\r[1, 10, 19, 28, 37, 46, 55, 64, 73, 82, 91, 100]\r[1, 11, 21, 31, 41, 51, 61, 71, 81, 91]\rjulia\u0026gt; getindex.(seq_, 3)\r10-element Vector{Int64}:\r3\r5\r7\r9\r11\r13\r15\r17\r19\r21 first(), last() first() is the same as getindex(, 1), but last() is special because there is no equivalent expression like getindex(, end). It\u0026rsquo;s often necessary to get the last result as the program iterates, and the index of that last element can vary greatly, so it\u0026rsquo;s good to know the last() function.\njulia\u0026gt; first.(seq_)\r10-element Vector{Int64}:\r1\r1\r1\r1\r1\r1\r1\r1\r1\r1\rjulia\u0026gt; last.(seq_)\r10-element Vector{Int64}:\r100\r99\r100\r97\r96\r97\r99\r97\r100\r91 Environment OS: Windows julia: v1.9.0 ","id":2603,"permalink":"https://freshrimpsushi.github.io/en/posts/2603/","tags":null,"title":"Referencing Specific Positions in an Array with Functions in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview The way to load a package in Julia is to use using, but as the program grows, it becomes a task to individually write them each time. This introduces a method to load packages through a loop1.\nCode Metaprogramming packages = [:CSV, :DataFrames, :LinearAlgebra, :Plots]\rfor package in packages\r@eval using ‚ñ∑eq1‚óÅ(package)\rend In actual use, it is better to load only the progress bar separately and visually check the loading of other packages.\nEnvironment OS: Windows julia: v1.9.0 https://discourse.julialang.org/t/programmatically-load-packages/52435/2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2601,"permalink":"https://freshrimpsushi.github.io/en/posts/2601/","tags":null,"title":"How to Import Packages from Julia to R"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview This document introduces a tip for easily normalizing matrices in Julia 1. At its core, it‚Äôs just mixing the method of scalar multiplying matrices by rows and columns, the eachcol() function, and the norm() function from the LinearAlgebra module, but it‚Äôs concise, ending in one line, and proving to be quite useful to memorize for frequent use.\nCode julia\u0026gt; using LinearAlgebra\rjulia\u0026gt; X = reshape(1:15, 5, :)\r5√ó3 reshape(::UnitRange{Int64}, 5, 3) with eltype Int64:\r1 6 11\r2 7 12\r3 8 13\r4 9 14\r5 10 15 Given a matrix X, normalizing it by columns can be succinctly done with just one line: X ./ norm.(eachcol(X))'. The execution and the results confirming that it was indeed properly normalized are as follows.\njulia\u0026gt; Z = X ./ norm.(eachcol(X))\u0026#39;\r5√ó3 Matrix{Float64}:\r0.13484 0.330289 0.376192\r0.26968 0.385337 0.410391\r0.40452 0.440386 0.444591\r0.53936 0.495434 0.47879\r0.6742 0.550482 0.512989\rjulia\u0026gt; norm.(eachcol(Z))\r3-element Vector{Float64}:\r1.0\r1.0\r1.0 Complete Code using LinearAlgebra\rX = reshape(1:15, 5, :)\rZ = X ./ norm.(eachcol(X))\u0026#39;\rnorm.(eachcol(Z)) Environment OS: Windows julia: v1.9.0 https://stackoverflow.com/a/72627341/12285249\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2599,"permalink":"https://freshrimpsushi.github.io/en/posts/2599/","tags":null,"title":"How to Normalize Matrices Column-wise in Julia"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definitions 1 2 For a permutation matrix $P^{T}$ and an invertible matrix $A \\in \\mathbb{R}^{n \\times n}$, the matrix multiplication $P^{T} A$ gives us the product $LU$. This decomposition is referred to as the PLU decompositionPermutation LU Decomposition of $A$. Since $P$ is a permutation matrix, it is also an orthogonal matrix, that is $P^{-1} = P^{T}$, hence it can be written like this: $$ P^{T} A = LU \\iff A = PLU $$\nExplanation Algorithm for LU Decomposition: Suppose $(a_{ij}) \\in \\mathbb{R}^{n \\times n}$ is an invertible matrix.\nStep 1. $k = 1$\nInsert $u_{1j} = a_{1j}$ and compute $\\displaystyle l_{i1} = {{1} \\over {u_{11}}} a_{i1}$.\nStep 2. $k = 2, 3, \\cdots , n-1$\nStep 2-1. Compute the following: $$ u_{kk} = a_{kk} - \\sum_{s = 1}^{k-1} l_{ks} u_{sk} $$ Step 2-2. For $j = k+1, k+2, \\cdots , n-1$, compute the following: $$ u_{kj} = a_{kj} - \\sum_{s = 1}^{k-1} l_{ks} u_{sj} $$ Step 2-3. For $i = k+1, k+2, \\cdots , n-1$, compute the following: $$ l_{ik} = {{1} \\over {u_{kk}}} \\left{ a_{ik} - \\sum_{s = 1}^{k-1} l_{is} u_{sk} \\right} $$ Step 3. For $k = n$, compute the following: $$ u_{nn} = a_{nn} - \\sum_{s = 1}^{n-1} l_{ns} u_{sn} $$\nIn order to perform an LU decomposition of a matrix, one would need $u_{11} = a_{11}$ or to be able to take the reciprocal of $u_{kk}$. However, even simple matrices like $$ A = \\begin{bmatrix} 0 \u0026amp; 3\\\\ 2 \u0026amp; 1 \\end{bmatrix} $$ cannot be decomposed using this algorithm. To perform LU decomposition on such matrices, one multiplies by some permutation matrix $P^{T}$, expressing $A$ as $PLU$; this process is called PLU decomposition. Since it doesn\u0026rsquo;t really matter if it\u0026rsquo;s left or right, rows or columns, we can also write $$ A P^{T} = LU \\iff A = LUP $$ and refer to it as LUP decomposition.\nhttps://www.cfm.brown.edu/people/dobrush/cs52/Mathematica/Part2/PLU.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://math.unm.edu/~loring/links/linear_s08/LU\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2,"permalink":"https://freshrimpsushi.github.io/en/posts/2/","tags":null,"title":"PLU Decomposition"},{"categories":"ÌñâÎ†¨ÎåÄÏàò","contents":"Definition 1 $P \\in \\mathbb{R}^{n \\times n}$ in which only one component in each row is $1$ and the rest are $0$ is called a Permutation Matrix.\nBasic Properties Orthogonality All permutation matrices are orthogonal matrices: $$P^{-1} = P^{T}$$\nSparseness For sufficiently large $n$, $P \\in \\mathbb{R}^{n \\times n}$ is a sparse matrix.\nExplanation The Permutation Matrix gives a permutation of rows and columns through matrix multiplication. The following example shows that if it is multiplied on the left, it gives a row permutation, and if it is multiplied on the right, it gives a column permutation. $$ \\begin{align*} \\begin{bmatrix} 0 \u0026amp; 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\\\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \\end{bmatrix} = \u0026amp; \\begin{bmatrix} a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\\\ a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\\\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \\end{bmatrix} \\\\ \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\\\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \\end{bmatrix} \\begin{bmatrix} 0 \u0026amp; 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} = \u0026amp; \\begin{bmatrix} a_{12} \u0026amp; a_{11} \u0026amp; a_{13} \\\\ a_{22} \u0026amp; a_{21} \u0026amp; a_{23} \\\\ a_{32} \u0026amp; a_{31} \u0026amp; a_{33} \\end{bmatrix} \\end{align*} $$\nhttps://www.cfm.brown.edu/people/dobrush/cs52/Mathematica/Part2/PLU.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1,"permalink":"https://freshrimpsushi.github.io/en/posts/1/","tags":null,"title":"Permutation Matrix"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Error When using data frames in Julia, string data sometimes get read as String7, String15, String31, etc., causing various errors. Rather than specific errors occurring, the usual functions don\u0026rsquo;t work with these, causing all sorts of problems.\nCause For performance reasons, String was changed to faster versions like String7, etc. It\u0026rsquo;s designed this way on purpose, so nothing much can be done about it.\nSolution Passing the option stringtype = String to CSV.read() works.\nIt\u0026rsquo;s actually quite inconvenient, but you\u0026rsquo;ll have to deal with it.\nEnvironment OS: Windows julia: v1.8.5 ","id":2574,"permalink":"https://freshrimpsushi.github.io/en/posts/2574/","tags":null,"title":"How to Call a DataFrame without String7, String15 in Julia"},{"categories":"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù","contents":"Question In partial derivatives, unlike the usual derivatives, expressions like $\\displaystyle {{ \\partial f } \\over { \\partial t }}$ are used instead of $\\displaystyle {{ d f } \\over { d t }}$. $\\partial$ is read as \u0026ldquo;Round Dee\u0026rdquo; or \u0026ldquo;Partial,\u0026rdquo; and historically, it originated from \u0026ldquo;Curly Dee,\u0026rdquo; which is a cursive form of $d$1. In code, it\u0026rsquo;s \\partial, and in Korea, some people even shorten it to just \u0026ldquo;Round,\u0026rdquo; considering \u0026ldquo;Round Dee\u0026rdquo; too long.\nWhy is $d$ written as $\\partial$? The problem is that it\u0026rsquo;s hard to understand why a different symbol is used for partial differentiation, which is just differentiating with respect to another variable. At the undergraduate level, this question inevitably arises whenever partial differentiation is introduced, but the answer could be, if you\u0026rsquo;re not in a math department, \u0026ldquo;That\u0026rsquo;s something for mathematicians to worry about,\u0026rdquo; or even if you are, \u0026ldquo;It\u0026rsquo;s okay to accept it as just a notational difference.\u0026rdquo; This isn\u0026rsquo;t necessarily wrong, as whether it\u0026rsquo;s written as $d$ or $\\partial$, if you\u0026rsquo;re not in a math department, it\u0026rsquo;s not particularly important, and even if you are, it doesn\u0026rsquo;t change the meaning of the equation itself. For example, in the context of studying heat equations, $$ {{ \\partial u } \\over { \\partial t }} = {{ \\partial u } \\over { \\partial x^{2} }} $$ changing $\\partial$ to an ordinary differential expression $d$ and writing it as $$ {{ d u } \\over { d t }} = {{ d u } \\over { d x^{2} }} $$ could raise the question of whether these two equations are the same. Confusingly, the answer would be \u0026rsquo;they are indeed the same,\u0026rsquo; leading many students to feel that there\u0026rsquo;s no difference between $d$ and $\\partial$, or to just accept the definition and move on.\nAnswer Newton and Leibniz Before diving into partial differentiation, let\u0026rsquo;s start with an interesting read about the two fathers of differentiation, Newton and Leibniz. Nowadays, both are recognized for independently inventing the concept and notation of differentiation, with function $y = f(x)$ and its derivative, where Newton used notation like $$ y ' = f ' (x) $$ and Leibniz used $$ {{ dy } \\over { dx }} = {{ d f(x) } \\over { dx }} $$ The reason for the difference in expression, despite being the same differentiation, is due to their different thought processes and perspectives on calculus. It\u0026rsquo;s fortunate that there were two people independently inventing differentiation at the same time, as it could have been beneficial if there had been another person as well. Newton, as a master of [classical mechanics](../../categories/Classical Mechanics), often discussed \u0026lsquo;differentiating position once gives velocity, and twice gives acceleration,\u0026rsquo; making expressions like $$ \\begin{align*} v =\u0026amp; x ' \\\\ a =\u0026amp; v ' = x '' \\end{align*} $$ very neat and efficient. Leibniz, on the other hand, had a more logical approach from a geometric perspective, where the slope of a line is defined as the ratio of changes in horizontal and vertical directions, so for a curve, one could naturally approach the slope of the tangent by giving very small units as $$ {{ \\Delta y } \\over { \\Delta x }} \\approx {{ d y } \\over { d x }} $$ Interestingly, despite being about ordinary differentiation, the field allows for such divergence in notation, where Newton\u0026rsquo;s and Leibniz\u0026rsquo;s notations can coexist.\nIn differential geometry, the notation for differentiation with respect to $s$ and $t$: $$ {{ df } \\over { ds }} = f^{\\prime} \\quad \\text{and} \\quad {{ df } \\over { dt }} = \\dot{f} $$ Dot $\\dot{}$ or prime $'$, although both denote differentiation, can be distinguished in the context of differential geometry. Typically, $s$ represents the parameter of a unit speed curve, and $t = t(s)$ represents the parameter of the curve reparameterized by arc length.\nThis notation didn\u0026rsquo;t arise because the concept of differentiation was transformed. In differential geometry, differentiation is often performed with both $s$ and $t$, but Newton\u0026rsquo;s notation doesn\u0026rsquo;t allow distinguishing what is being differentiated, and Leibniz\u0026rsquo;s notation makes the expression too complicated, leading to the creation of an additional notation to take advantage of both.\nWhat\u0026rsquo;s fascinating is that, despite $s$ and $t$ being just variables used as parameters, in the context of ordinary differential equations involving time, the derivative with respect to $t$ began to be written not as $v '$ but as $\\dot{v}$, borrowing the first letter. As a result, in almost all systems describing changes over time, dynamics prefer to use expressions like $$ \\dot{v} = f(v) $$ instead of $v '$. The point is that the concern to clearly and neatly represent \u0026lsquo;what is being differentiated\u0026rsquo; can naturally arise even outside the context of partial differentiation.\nImplication of Multivariable Functions In the previous section, it was noted that $f '$ and $\\dot{f}$ could be distinguished just by their expressions, and especially in dynamical systems, even without the appearance of time $t$ in the expression, it could be implied as differentiation with respect to time due to universal conventions and context. Let\u0026rsquo;s discuss a bit more about the implicit information conveyed by expressions.\nReturning to partial differentiation, the reason why the notation $d$ and $\\partial$ doesn\u0026rsquo;t seem different is that there\u0026rsquo;s no difference in the partial derivatives they represent. For instance, if the derivative of $f$ with respect to $t$ is $g$, then that $g$ could be represented as $$ g = {{ d f } \\over { d t }} = {{ \\partial f } \\over { \\partial t }} $$ either way as $d$ or $\\partial$, and it wouldn\u0026rsquo;t matter much. Regardless of the notation, it\u0026rsquo;s differentiated with respect to $t$, and the \u0026lsquo;result\u0026rsquo; $g$ is the same. In fact, the implicit information given by $\\partial$ is not about $g$ but about $f$. When a function $h$ is said to be differentiated with respect to $H$ giving $x$, consider the following two expressions:\nWithout $\\partial$: It seems $\\displaystyle h = {{ d H } \\over { d x }} \\implies$ $H$ is differentiated to $h$.\rWith $\\partial$: Why is it only this one? There must be some $y$, so it should be $H = H (x , y)$.\rIn other words, the notation $\\partial$ itself implies that the given function is a multivariable function. Often, the first serious encounter with partial differentiation is usually through partial differential equations, and in equations like $$ {{ \\partial u } \\over { \\partial t }} = {{ \\partial u } \\over { \\partial x^{2} }} $$ we are not interested in the first-order partial derivative $u_{t}$ of $u$ with respect to $t$, nor the second-order partial derivative $u_{xx}$ of $u$ with respect to $x$, but what function $u = u (t,x)$ of $t$ and $x$ satisfies them being equal. From this perspective, using $\\partial$ in partial differential equations is justifiable and natural.\nOn the other hand, such conventions being widely accepted also changes the meaning of $d$ itself. If a function isn\u0026rsquo;t multivariable, it\u0026rsquo;s pointless to differentiate it with $\\partial$, so if the derivative expression uses $d$, it implies that it\u0026rsquo;s not a multivariable function. For instance, if we fix the location of a bivariate function $u = u (t,x)$ to a point and set $u = u \\left( t , x_{0} \\right)$, then $$ \\left. {{ \\partial u } \\over { \\partial t }} \\right|_{x = x_{0} } = {{ d u } \\over { d t }} = \\dot{u} $$ such an expression makes excellent use of the implicit information transmission of $\\partial$ and $d$. This goes beyond just a difference in expression and influences the way we handle equations, leading to ideas like transforming partial differential equation problems into relatively simple ordinary differential equations to solve them.\n‚úÖ To Avoid Confusion in Total Differentiation $$ df = \\frac{ \\partial f}{ \\partial x_{1} }dx_{1} + \\frac{ \\partial f}{ \\partial x_{2} }dx_{2} + \\cdots + \\frac{ \\partial f}{ \\partial x_{n} }dx_{n} $$ For a multivariable function $f : \\mathbb{R}^{n} \\to \\mathbb{R}$, the total differentiation used in fields like mathematical physics is often represented as above, and to write it more intuitively when $n = 3$, we only write $t,x,y,z$ like this, assuming $x,y,z$ are independent. $$ df = {{ \\partial f } \\over { \\partial x }} dx + {{ \\partial f } \\over { \\partial y }} dy + {{ \\partial f } \\over { \\partial z }} dz $$ At first glance, this expression might seem complicated with a mix of $d$ and $\\partial$, but by applying Leibniz\u0026rsquo;s legacy of \u0026lsquo;dividing both sides by $dt$ or $dx$,\u0026rsquo; we can see $$ \\begin{align*} df =\u0026amp; {{ \\partial f } \\over { \\partial x }} dx + {{ \\partial f } \\over { \\partial y }} dy + {{ \\partial f } \\over { \\partial z }} dz \\\\ {{ d f } \\over { d t }} =\u0026amp; {{ \\partial f } \\over { \\partial x }} {{ d x } \\over { d t }} + {{ \\partial f } \\over { \\partial y }} {{ d y } \\over { d t }} + {{ \\partial f } \\over { \\partial z }} {{ d z } \\over { d t }} \\\\ {{ d f } \\over { d x }} =\u0026amp; {{ \\partial f } \\over { \\partial x }} {{ d x } \\over { d x }} + {{ \\partial f } \\over { \\partial y }} {{ d y } \\over { d x }} + {{ \\partial f } \\over { \\partial z }} {{ d z } \\over { d x }} = {{ \\partial f } \\over { \\partial x }} \\end{align*} $$ that it clearly represents both the meaning of differentiating $f$ with respect to $t$ and partial differentiating with respect to $x$. This shows how useful the form of total differentiation can be in handling equations, and if we eliminate $\\partial$ altogether and unify it with $d$ to rewrite it, we get $$ df = {{ d f } \\over { d x }} dx + {{ d f } \\over { d y }} dy + {{ d f } \\over { d z }} dz $$ Of course, Leibniz\u0026rsquo;s differential notation is incredibly intuitive when dealing with numerator and denominator like fractions, but if you\u0026rsquo;re reading this, you should know not to treat $dx$, $dy$, or $dz$ so carelessly. Despite this, your inner instincts will scream to simplify it like this. $$ \\begin{align*} df =\u0026amp; {{ d f } \\over { dx }} dx + {{ d f } \\over { dy }} dy + {{ d f } \\over { dz }} dz \\\\ \\overset{?}{=} \u0026amp; {{ d f } \\over { \\cancel{dx} }} \\cancel{dx} + {{ d f } \\over { \\cancel{dy} }} \\cancel{dy} + {{ d f } \\over { \\cancel{dz} }} \\cancel{dz} \\\\ =\u0026amp; df + df + df \\\\ \\overset{???}{=}\u0026amp; 3 df \\end{align*} $$ This disaster can be seen as a circular argument caused by overlooking what conditions make $d$ equal to $\\partial$. The progression that casually assumes \u0026rsquo;eliminate $\\partial$ and unify with $d$ to rewrite\u0026rsquo; is too bold, especially since the very thought of replacing $\\partial$ with $d$ came from $$ df = {{ \\partial f } \\over { \\partial x }} dx + {{ \\partial f } \\over { \\partial y }} dy + {{ \\partial f } \\over { \\partial z }} dz \\implies {{ d f } \\over { d x }} = {{ \\partial f } \\over { \\partial x }} \\implies d \\equiv \\partial $$ assuming $x,y,z$ are independent. While tampering with $df = {{ \\partial f } \\over { \\partial x }} dx + {{ \\partial f } \\over { \\partial y }} dy + {{ \\partial f } \\over { \\partial z }} dz$, which forms the basis for $d \\equiv \\partial$, it\u0026rsquo;s natural that some form of error would occur. For $d$ and $\\partial$ to be equal, as assumed in the example, either the variables of a multivariable function must be independent, or some special condition or remarkable theorem must truly equate $d$ and $\\partial$.\nFrom the considerations so far, we can summarize that the reason for using $d$ instead of $\\partial$ for partial differentiation is because they are indeed different. All the examples we\u0026rsquo;ve seen where $d$ and $\\partial$ were the same always implicitly assume certain conditions. Within those good assumptions, $\\partial$ might essentially be the same as $d$, but that doesn\u0026rsquo;t mean we necessarily have to rewrite $\\partial$ as $d$.\n‚ùå Treating Variables Other Than the Differentiated One as Constants? To put it bluntly, this is a wrong answer.\nMore precisely, the causal relationship explaining the phenomenon is reversed. For example, if $f(t,x) = \\left( t^{2} + x^{2} \\right)$, then $\\partial t$ is not formally treating variables other than $t$ as constants because of $$ {{ \\partial f } \\over { \\partial t }} = 2t + 0 = 2t = {{ d f } \\over { d t }} $$ but, as seen in the previous section, it\u0026rsquo;s because of the assumption $\\displaystyle {{ dx } \\over { dt }} = 0$ that $$ \\begin{align*} \u0026amp; df = {{ \\partial f } \\over { \\partial t }} dt + {{ \\partial f } \\over { \\partial x }} dx \\\\ \\implies \u0026amp; {{ d f } \\over { d t }} = {{ \\partial f } \\over { \\partial t }} {{ dt } \\over { dt }} + {{ \\partial f } \\over { \\partial x }} {{ dx } \\over { dt }} \\\\ \\implies \u0026amp; {{ d f } \\over { d t }} = {{ \\partial f } \\over { \\partial t }} \\cdot 1 + {{ \\partial f } \\over { \\partial x }} \\cdot 0 \\\\ \\implies \u0026amp; {{ d f } \\over { d t }} = {{ \\partial f } \\over { \\partial t }} \\end{align*} $$ holds. Partial differentiation $\\partial$ itself didn\u0026rsquo;t produce the result $\\displaystyle {{ dx } \\over { dt }} = 0$; it\u0026rsquo;s the cause $\\displaystyle {{ dx } \\over { dt }} = 0$ that led to the result $\\partial \\equiv d$. Thus, the explanation that \u0026lsquo;partial differentiation treats variables other than the differentiated one as constants\u0026rsquo; gives a misleading impression and misconception that partial differentiation $\\partial$ is somehow a more powerful operator than ordinary differentiation $d$. Moreover, if $x$ were treated as a constant, it should disappear after differentiation with respect to $t$, but as can be simply seen with $f(t,x) = t^{2} + x^{2} + 2tx$, $\\dfrac{\\partial f}{\\partial t}$ remains a bivariate function with variable $(t,x)$.\nThe persistence of this fallacy is due to its plausibility. Practically, when assuming relationships between variables like $x = x(t)$, there\u0026rsquo;s no need to use the expression \u0026lsquo;differentiate with respect to $t$\u0026rsquo; in the first place, as according to the chain rule, $$ \\begin{align*} {{ d f } \\over { d t }} =\u0026amp; {{ d } \\over { d t }} \\left( t^{2} + x^{2} \\right) \\\\ =\u0026amp; 2t + {{ d x^{2} } \\over { d x }} {{ dx } \\over { dt }} \\\\ =\u0026amp; 2t + 2x \\dot{x} \\end{align*} $$ the equation can be unfolded without ambiguity right from the start. At least in this example, $f = f(t,x)$ is essentially the same as a univariate function like $f = f(t)$, or it\u0026rsquo;s unnecessarily complex, and eventually, textbooks only include cases that are clean, independent, and yet still multivariable. Typically, people study with clean examples, time passes, familiarity with partial differentiation grows, incorrect intuitions settle, and everyone else does the same. However, what\u0026rsquo;s wrong is wrong. Merely changing the notation of differentiation can\u0026rsquo;t arbitrarily alter the dependencies of the given function.\nhttps://math.stackexchange.com/a/2000353/459895\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2573,"permalink":"https://freshrimpsushi.github.io/en/posts/2573/","tags":null,"title":"Why Notation of Partial Differential is Different?"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview When drawing figures in Julia, to apply a title to all subplots, one should use plot_title instead of title1. This is because the arguments of the outermost plot() function, in the case of a plot with subplots like\nplot(\rplot1, plot2, ...\r) inherit properties to the inner subplots. To clearly distinguish between them, title and plot_title are used separately.\nCode plot(p1, p2, title = \u0026#34;Two Plots\u0026#34;) As you can see, using title = \u0026quot;Two Plots\u0026quot; applies the title to all subplots.\nplot(p1, p2, plot_title = \u0026#34;Two Plots\u0026#34;) plot_title = \u0026quot;Two Plots\u0026quot; applies just one title to the entire figure, as can be seen.\nEntire code using Plots\rp1 = scatter(rand(100))\rp2 = histogram(rand(100))\rplot(p1, p2, title = \u0026#34;Two Plots\u0026#34;)\rplot(p1, p2, plot_title = \u0026#34;Two Plots\u0026#34;) Environment OS: Windows julia: v1.8.5 https://stackoverflow.com/a/69713616/12285249\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2572,"permalink":"https://freshrimpsushi.github.io/en/posts/2572/","tags":null,"title":"How to Add a Main Title in Julia Subplots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, there are ways to remove color bars, axes, ticks, grids, etc., but these involve graphic elements, so it\u0026rsquo;s not possible to cleanly remove numbers alone. You must use an option called formatter.\nformatter = (_...) -\u0026gt; \u0026quot;\u0026quot; By giving the option formatter = (_...) -\u0026gt; \u0026quot;\u0026quot; to the plot() function, it\u0026rsquo;s done.\nusing Plots\rx = rand(10)\ry = rand(10)\rplot(\rplot(x,y)\r,plot(x,y, formatter = (_...) -\u0026gt; \u0026#34;\u0026#34;)\r) In the image above, the left is a plain picture, and the right is a picture with all values removed. Originally, formatter is not just used this way; it has much more functionality. Briefly explained, it applies a given function to the values that should have been displayed in the original image. In the example above, a lambda expression (_...) -\u0026gt; \u0026quot;\u0026quot; is received, and returns an empty string for whatever numerical value comes in, thus removing the axis values1.\nxformatter, yformatter Of course, there are xformatter and yformatter which can be specified for each axis. If you want to remove only the x-axis, pass (_...) -\u0026gt; \u0026quot;\u0026quot; to yformatter, and vice versa for the y-axis.\nEnvironment OS: Windows julia: v1.8.5 foreground_color_text = false By inputting foreground_color_text = false as a keyword for the plot() function, it\u0026rsquo;s done. Although it\u0026rsquo;s a keyword for specifying the color of the tick values (names), entering false results in the values not being output at all.\nx_foreground_color_text and y_foreground_color_text can be specified for each axis respectively.\nusing Plots\rplot(\rplot(rand(10)),\rplot(rand(10), foreground_color_text = false)\r) Environment OS: Windows11 Version: Julia 1.9.3, Plots v1.39.0 https://stackoverflow.com/questions/74842089/remove-only-axis-values-in-plot-julia\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2570,"permalink":"https://freshrimpsushi.github.io/en/posts/2570/","tags":null,"title":"How to Remove Axis Values in Julia Plots"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview To use Finite Differences in Julia, more specifically to calculate the coefficients of finite differences, it is advisable to use FiniteDifferences.jl1. In cases where there is susceptibility to noise, it‚Äôs possible to use Total Variation Regularized Numerical Differentiation, known as TVDiff, implemented in NoiseRobustDifferentiation.jl.\nCode FiniteDifferenceMethod() julia\u0026gt; f‚Ä≤ = FiniteDifferenceMethod([-2, 0, 5], 1)\rFiniteDifferenceMethod:\rorder of method: 3\rorder of derivative: 1\rgrid: [-2, 0, 5]\rcoefficients: [-0.35714285714285715, 0.3, 0.05714285714285714]\rjulia\u0026gt; typeof(f‚Ä≤)\rFiniteDifferences.UnadaptedFiniteDifferenceMethod{3, 1} The example above calculates the first-order derivative using the middle point of the function, the second point from the left, and the fifth point from the right, providing the weights of these three points. The basic thing that FiniteDifferenceMethod() provides is these coefficients.\njulia\u0026gt; propertynames(f‚Ä≤)\r(:grid, :coefs, :coefs_neighbourhood, :condition, :factor, :max_range, :‚àáf_magnitude_mult, :f_error_mult)\rjulia\u0026gt; f‚Ä≤.grid\r3-element StaticArraysCore.SVector{3, Int64} with indices SOneTo(3):\r-2\r0\r5\rjulia\u0026gt; f‚Ä≤.coefs\r3-element StaticArraysCore.SVector{3, Float64} with indices SOneTo(3):\r-0.35714285714285715\r0.3\r0.05714285714285714 The properties to be used in the structure primarily include .grid and .coefs.\njulia\u0026gt; f‚Ä≤(sin, œÄ/2)\r-1.2376571459669071e-11\rjulia\u0026gt; f‚Ä≤(cos, œÄ/2)\r-1.0000000000076525 When the function itself is given instead of data, it\u0026rsquo;s perfectly fine to write it directly as a function form as seen above.\n_fdm() central_fdm(2, 1)\rcentral_fdm(3, 2)\rbackward_fdm(4, 1)\rforward_fdm(5, 1) If you need a well-known FDM without customizations, it\u0026rsquo;s more convenient to use the function already provided as seen above. The first argument depends on how many points will be used according to the type of the function, and the second argument $n$ determines that it will calculate the $n$ derivative. Obviously, when the first argument of central_fdm() is given as an odd number, the coefficient of the central point is definitely 0.\nFull Code using FiniteDifferences\rf‚Ä≤ = FiniteDifferenceMethod([-2, 0, 5], 1)\rtypeof(f‚Ä≤)\rpropertynames(f‚Ä≤)\rf‚Ä≤.grid\rf‚Ä≤.coefs\rf‚Ä≤(sin, œÄ/2)\rf‚Ä≤(cos, œÄ/2)\rcentral_fdm(2, 1)\rcentral_fdm(3, 2)\rbackward_fdm(4, 1)\rforward_fdm(5, 1) Environment OS: Windows julia: v1.8.5 https://github.com/JuliaDiff/FiniteDifferences.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2568,"permalink":"https://freshrimpsushi.github.io/en/posts/2568/","tags":null,"title":"How to Use Finite Difference in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, the Interpolations.jl package is used for numerical interpolation1. Be cautious not to confuse it with the interpolation method used when printing the value of a variable in Julia[../2041].\nCode Interpolate() julia\u0026gt; y = rand(10)\r10-element Vector{Float64}:\r0.8993801321974316\r0.12988982511901515\r0.49781160399025925\r0.22555299914088356\r0.4848674643768577\r0.6089318286915111\r0.10444895196527337\r0.5921775799940143\r0.2149546302906653\r0.32749334953170317\rjulia\u0026gt; f = interpolate(y, BSpline(Linear()));\rjulia\u0026gt; f(1.2)\r0.7454820707817483\rjulia\u0026gt; f(0.1)\rERROR: BoundsError: attempt to access 10-element interpolate(::Vector{Float64}, BSpline(Linear())) with element type Float64 at index [0.1] Basically, as shown above, you can receive the interpolation function f=$f$ itself by giving data and use it. The example shows how a value (0.745) around 1.2 between the 1st (0.899) and 2nd (0.129) given points is interpolated. Refer to the API section of the official documentation to determine the specific method to use2.\nlinear_interpolation() x = 1:10\rf_lin = linear_interpolation(x, y);\rscatter(x, y, label = \u0026#34;Data\u0026#34;); plot!(1:0.01:10, f_lin.(1:0.01:10), label = \u0026#34;Linear\u0026#34;) cubic_spline_interpolation() f_cub = cubic_spline_interpolation(x, y);\rscatter(x, y, label = \u0026#34;Data\u0026#34;); plot!(1:0.01:10, f_cub.(1:0.01:10), label = \u0026#34;Cubic\u0026#34;) constant_interpolation() f_con = constant_interpolation(x, y);\rscatter(x, y, label = \u0026#34;Data\u0026#34;); plot!(1:0.01:10, f_con.(1:0.01:10), label = \u0026#34;Constant\u0026#34;) Full Code using Interpolations, Plots\ry = rand(10)\rf = interpolate(y, BSpline(Linear()));\rf(1.2)\rf(0.1)\rx = 1:10\rf_lin = linear_interpolation(x, y);\rscatter(x, y, label = \u0026#34;Data\u0026#34;); plot!(1:0.01:10, f_lin.(1:0.01:10), label = \u0026#34;Linear\u0026#34;)\rf_cub = cubic_spline_interpolation(x, y);\rscatter(x, y, label = \u0026#34;Data\u0026#34;); plot!(1:0.01:10, f_cub.(1:0.01:10), label = \u0026#34;Cubic\u0026#34;)\rf_con = constant_interpolation(x, y);\rscatter(x, y, label = \u0026#34;Data\u0026#34;); plot!(1:0.01:10, f_con.(1:0.01:10), label = \u0026#34;Constant\u0026#34;) Environment OS: Windows julia: v1.8.5 https://github.com/JuliaMath/Interpolations.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttp://juliamath.github.io/Interpolations.jl/stable/api/#Public-API\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2566,"permalink":"https://freshrimpsushi.github.io/en/posts/2566/","tags":null,"title":"Numerical Interpolation in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, the diff() function is provided to calculate differences1. It\u0026rsquo;s also possible to use the circshift() function to easily create a similar effect, but dealing with end points and such can be somewhat inconvenient, so knowing how to use diff() can be much more comfortable. It can be used almost in the same way as the diff() functions in R and MATLAB, however, unlike these, Julia does not specifically implement second-order differences (calculating the difference twice).\nCode Basic Usage julia\u0026gt; x = rand(0:9, 12)\r12-element Vector{Int64}:\r3\r1\r9\r7\r1\r0\r6\r5\r3\r2\r9\r9 For example, with an array like the one above, simply applying diff() calculates the difference between preceding and following elements, resulting in the output below. Notice that the size of the array has decreased by exactly 1.\njulia\u0026gt; diff(x)\r11-element Vector{Int64}:\r-2\r8\r-2\r-6\r-1\r6\r-1\r-2\r-1\r7\r0 Multidimensional Arrays julia\u0026gt; X = reshape(x, 3, :)\r3√ó4 Matrix{Int64}:\r3 7 6 2\r1 1 5 9\r9 0 3 9\rjulia\u0026gt; diff(X)\rERROR: UndefKeywordError: keyword argument dims not assigned\rStacktrace:\r[1] diff(a::Matrix{Int64})\r@ Base .\\multidimensional.jl:997\r[2] top-level scope\r@ c:\\Users\\rmsms\\OneDrive\\lab\\DataDrivenModel\\REPL.jl:7 For instance, if you have a multidimensional array like the one above, applying diff() directly will result in an error. This is because the direction in which to compute the difference is not specified. As in the one-dimensional case, you must specify the dims argument to determine in which dimension to calculate the difference. Pay attention to the fact that the length decreases by one in the direction in which the difference was taken.\njulia\u0026gt; diff(X, dims = 1)\r2√ó4 Matrix{Int64}:\r-2 -6 -1 7\r8 -1 -2 0\rjulia\u0026gt; diff(X, dims = 2)\r3√ó3 Matrix{Int64}:\r4 -1 -4\r0 4 4\r-9 3 6 Complete Code x = rand(0:9, 12)\rdiff(x)\rX = reshape(x, 3, :)\rdiff(X)\rdiff(X, dims = 1)\rdiff(X, dims = 2) Environment OS: Windows julia: v1.8.5 https://docs.julialang.org/en/v1/base/arrays/#Base.diff\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2564,"permalink":"https://freshrimpsushi.github.io/en/posts/2564/","tags":null,"title":"Calculating the Difference of Arrays in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Though Julia does not natively support Circular Arrays, it essentially allows for such functionality by providing the circshift() function, which pushes or pulls elements circularly1. It\u0026rsquo;s not particularly difficult to write this function yourself, but knowing it obviates the need. This function can be used almost exactly like the circshift() in MATLAB.\nCode This function has been introduced in the post about how to translate arrays in parallel as well.\nBasic Usage julia\u0026gt; circshift(1:4, 1)\r4-element Vector{Int64}:\r4\r1\r2\r3\rjulia\u0026gt; circshift(1:4, -1)\r4-element Vector{Int64}:\r2\r3\r4\r1 circshift() basically takes an integer as the second argument to push or pull elements. In the example above, positive integers cause a backward (downward) shift, while negative integers cause a forward (upward) shift.\nMultidimensional Arrays julia\u0026gt; ca = reshape(1:20, 5, :)\r5√ó4 reshape(::UnitRange{Int64}, 5, 4) with eltype Int64:\r1 6 11 16\r2 7 12 17\r3 8 13 18\r4 9 14 19\r5 10 15 20 Given a multidimensional array like the one above, you specify a tuple of the same dimension to determine how much to push or pull each dimension.\njulia\u0026gt; circshift(ca, (0,1))\r5√ó4 Matrix{Int64}:\r16 1 6 11\r17 2 7 12\r18 3 8 13\r19 4 9 14\r20 5 10 15\rjulia\u0026gt; circshift(ca, (-1,0))\r5√ó4 Matrix{Int64}:\r2 7 12 17\r3 8 13 18\r4 9 14 19\r5 10 15 20\r1 6 11 16\rjulia\u0026gt; circshift(ca, (-1,1))\r5√ó4 Matrix{Int64}:\r17 2 7 12\r18 3 8 13\r19 4 9 14\r20 5 10 15\r16 1 6 11 Complete Code circshift(1:4, 1)\rcircshift(1:4, -1)\rca = reshape(1:20, 5, :)\rcircshift(ca, (0,1))\rcircshift(ca, (-1,0))\rcircshift(ca, (-1,1)) Environment OS: Windows julia: v1.8.5 https://docs.julialang.org/en/v1/base/arrays/#Base.circshift\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2562,"permalink":"https://freshrimpsushi.github.io/en/posts/2562/","tags":null,"title":"How to Use Circular Arrangements in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code 1 No need for a lengthy description, it literally shows what the marker and line styles look like in reality.\nlinesytle Choose one from [:auto, :solid, :dash, :dot, :dashdot, :dashdotdot].\nshape Choose one from [:none, :auto, :circle, :rect, :star5, :diamond, :hexagon, :cross, :xcross, :utriangle, :dtriangle, :rtriangle, :ltriangle, :pentagon, :heptagon, :octagon, :star4, :star6, :star7, :star8, :vline, :hline, :+, :x].\nFull Code ‚ñ∑code1‚óÅ\nEnvironment OS: Windows julia: v1.8.5 Plots v1.38.5 https://docs.juliaplots.org/latest/generated/attributes_series/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2560,"permalink":"https://freshrimpsushi.github.io/en/posts/2560/","tags":null,"title":"List of Markers and Line Styles in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code To insert a regression line in the scatter plot of Julia, simply use the option smooth = true.\nusing Plots\rx = rand(100)\rscatter(x, 2x .+ 0.1randn(100), smooth = true)\rsavefig(\u0026#34;plot.svg\u0026#34;) Environment OS: Windows julia: v1.8.3 Plots v1.38.5 ","id":2558,"permalink":"https://freshrimpsushi.github.io/en/posts/2558/","tags":null,"title":"Drawing a Regression Line on a Julia Plot"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, the most frequently used purpose of the ... splat is explained as the method of passing optional arguments. Basically, it uses the method of applying the splat operator to the tuple after determining in advance what options to put into which arguments, in the form of a named tuple.\nCode Passing to Multiple Functions args1 = (; dims = 1)\nThe named tuple args1 above can be commonly used for all functions having an optional argument called dims. In the following example, sum() and minimum() are completely different functions, but they were applied regardless of the type of function as they both have dims.\njulia\u0026gt; sum(rand(100,100); args1...)\r1√ó100 Matrix{Float64}:\r47.0704 45.7637 44.4513 48.2325 50.5745 51.9176 ‚Ä¶ 49.9548 47.6825 50.7284 50.0861 50.0168 50.5116\rjulia\u0026gt; minimum(rand(100,100); args1...)\r1√ó100 Matrix{Float64}:\r0.00702003 0.0163299 0.00665818 0.0174564 0.00589048 ‚Ä¶ 0.002967 0.00460205 0.0116248 0.0114521 0.0698425 Passing Multiple Arguments args2 = (; dims = 2, rev = true)\nThe named tuple args2 above includes the optional argument rev in addition to dims. In the following example, the sort() function reflected both options well and returned the computation result regardless of the input data.\njulia\u0026gt; sort(rand(0:9, 3,3); args2...)\r3√ó3 Matrix{Int64}:\r9 4 4\r6 5 2\r8 0 0\rjulia\u0026gt; sort(rand(3,3); args2...)\r3√ó3 Matrix{Float64}:\r0.438682 0.211154 0.108741\r0.72113 0.445214 0.00910109\r0.971441 0.666732 0.0227372 Entire Code args1 = (; dims = 1)\rsum(rand(100,100); args1...)\rminimum(rand(100,100); args1...)\rargs2 = (; dims = 2, rev = true)\rsort(rand(0:9, 3,3); args2...)\rsort(rand(3,3); args2...) Environment OS: Windows julia: v1.8.3 ","id":2554,"permalink":"https://freshrimpsushi.github.io/en/posts/2554/","tags":null,"title":"Tips for Passing Optional Arguments through the Julia Splatt Operator"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In Julia, ... is called the splat operator. It is usefully employed when using functions or defining arrays1. This operator isn\u0026rsquo;t exclusive to Julia, but it\u0026rsquo;s defined in a more intuitive way compared to other languages, making it exceptionally easy to learn and understand. From personal experience, using ... seems to bring some sort of enlightenment regarding Julia programming.\nCode Function Input Primarily, ... is appended after an array or generator and unfolds every element from the preceding container/iterator as it appears.\njulia\u0026gt; min([1,2,3,4,5,6,7,8,9,10])\rERROR: MethodError: no method matching min(::Vector{Int64})\rjulia\u0026gt; min(1,2,3,4,5,6,7,8,9,10)\r1 For instance, Julia‚Äôs min() function acts as a reducer, so you cannot pass an array as a whole; instead, you must directly provide multiple numbers as arguments. Naturally, as arrays grow larger, it becomes cumbersome to manually unfold and list each element, and using ... allows for these elements to be conveniently incorporated.\njulia\u0026gt; min(1:10)\rERROR: MethodError: no method matching min(::UnitRange{Int64})\rjulia\u0026gt; min((1:10)...)\r1 Of course, there actually exists a minimum() function that can be used on arrays, making this approach somewhat unnecessary.\nArray Definition julia\u0026gt; [(1:10)]\r1-element Vector{UnitRange{Int64}}:\r1:10 The array defined above is an array of unit ranges, which makes directly accessing elements somewhat tedious. If time permits, one could manually insert numbers from 1 to 10, but employing the splat operator allows for an easy definition like so:\njulia\u0026gt; [(1:10)...]\r10-element Vector{Int64}:\r1\r2\r3\r4\r5\r6\r7\r8\r9\r10 There are alternatives such as the collect() function, but this method is appealing for its neat and ingenious representation. However, it‚Äôs not highly recommended in terms of speed, so avoid overusing ....\njulia\u0026gt; [eachrow(rand(3,3))...]\r3-element Vector{SubArray{Float64, 1, Matrix{Float64}, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}}, true}}:\r[0.6695368164913422, 0.69695509795356, 0.12084083239135612]\r[0.6833475867141307, 0.5368141950494666, 0.7877252857572066]\r[0.2810163716135018, 0.04317485597011517, 0.44214186775440534] ... becomes interesting when used with generators as seen above. eachrow() returns a generator of vectors, each corresponding to a row in the matrix. Through the splat operator, these vectors are inserted into array notation [], creating a vector of vectors.\nFull code min([1,2,3,4,5,6,7,8,9,10])\rmin(1,2,3,4,5,6,7,8,9,10)\rmin(1:10)\rmin((1:10)...)\r[(1:10)]\r[(1:10)...]\r[eachrow(rand(3,3))...] Environment OS: Windows julia: v1.8.3 https://docs.julialang.org/en/v1/base/base/#\u0026hellip;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2552,"permalink":"https://freshrimpsushi.github.io/en/posts/2552/","tags":null,"title":"Julia's Splat Operator"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview As with many programming languages, in Julia, English is written in ASCII code and characters like Chinese and Korean are written in Unicode. The trouble, unlike with other languages, is that dealing with these strings is quite tricky, which is intended for performance reasons1, so one has no choice but to bear with it and use them as they are.\nCode julia\u0026gt; str1 = \u0026#34;English\u0026#34;\r\u0026#34;English\u0026#34;\rjulia\u0026gt; str2 = \u0026#34;Êó•Êú¨Ë™û\u0026#34;\r\u0026#34;Êó•Êú¨Ë™û\u0026#34;\rjulia\u0026gt; str3 = \u0026#34;ÌïúÍµ≠Ïñ¥\u0026#34;\r\u0026#34;ÌïúÍµ≠Ïñ¥\u0026#34; For example, let\u0026rsquo;s say the strings are given as above.\njulia\u0026gt; str1[2:end]\r\u0026#34;nglish\u0026#34; str1 is a simple English string and, because it\u0026rsquo;s ASCII code, it can be sliced like accessing a regular array as above.\njulia\u0026gt; str2[2:end]\rERROR: StringIndexError: invalid index [2], valid nearby indices [1]=\u0026gt;\u0026#39;Êó•\u0026#39;, [4]=\u0026gt;\u0026#39;Êú¨\u0026#39;\rStacktrace:\r[1] string_index_err(s::String, i::Int64)\r@ Base .\\strings\\string.jl:12\r[2] getindex(s::String, r::UnitRange{Int64})\r@ Base .\\strings\\string.jl:266\r[3] top-level scope\r@ c:\\Users\\rmsms\\OneDrive\\lab\\population_dynamics\\REPL.jl:6 However, str2 is written in Unicode because of the Chinese characters, and as shown, raises an index error. Judging by the error message, one can guess that the index for the second character is not 2 but 4, and indeed, starting indexing at 4 slices it as originally intended.\njulia\u0026gt; str2[4:end]\r\u0026#34;Êú¨Ë™û\u0026#34; This applies to Korean as well in the same way. There\u0026rsquo;s no reason for it to be different because it\u0026rsquo;s also Unicode.\njulia\u0026gt; str3[4:end]\r\u0026#34;Íµ≠Ïñ¥\u0026#34;\rjulia\u0026gt; str3[6]\rERROR: StringIndexError: invalid index [6], valid nearby indices [4]=\u0026gt;\u0026#39;Íµ≠\u0026#39;, [7]=\u0026gt;\u0026#39;Ïñ¥\u0026#39;\rStacktrace:\r[1] string_index_err(s::String, i::Int64)\r@ Base .\\strings\\string.jl:12\r[2] getindex_continued(s::String, i::Int64, u::UInt32)\r@ Base .\\strings\\string.jl:237\r[3] getindex(s::String, i::Int64)\r@ Base .\\strings\\string.jl:230\r[4] top-level scope\r@ c:\\Users\\rmsms\\OneDrive\\lab\\population_dynamics\\REPL.jl:9\rjulia\u0026gt; str3[7]\r\u0026#39;Ïñ¥\u0026#39;: Unicode U+C5B4 (category Lo: Letter, other) Trick julia\u0026gt; String(collect(str3)[2:3])\r\u0026#34;Íµ≠Ïñ¥\u0026#34; A somewhat convenient way to use it is to unravel the string into an array of characters using collect(), slice it, and then reassemble it into a string like above.\nEnvironment OS: Windows julia: v1.8.3 https://discourse.julialang.org/t/weird-string-slicing-in-korean/92252/2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2550,"permalink":"https://freshrimpsushi.github.io/en/posts/2550/","tags":null,"title":"Slicing Only a Part of Unicode Strings in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview In the StatsPlots package of Julia, the @df macro allows omitting the repeatedly mentioned dataframe name when plotting1. The syntax for using the macro, when using column a of dataframe X, is to specify which dataframe to use with @df X, followed immediately by passing the argument a as a symbol :a in the scope that follows, writing it as plot (:a). In summary, the code is written as @df X plot(:a).\nCode Below is a scatter plot using SepalLength and SepalWidth from the Iris data.\nThe following code scatter(iris.SepalLength, iris.SepalWidth) and @df iris scatter(:SepalLength, :SepalWidth) are equivalent.\nusing RDatasets\riris = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;iris\u0026#34;)\rusing StatsPlots\rscatter(iris.SepalLength, iris.SepalWidth)\r@df iris scatter(:SepalLength, :SepalWidth) Environment OS: Windows julia: v1.8.3 StatsPlots v0.15.4 https://github.com/JuliaPlots/StatsPlots.jl#original-author-thomas-breloff-tbreloff-maintained-by-the-juliaplots-members\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2548,"permalink":"https://freshrimpsushi.github.io/en/posts/2548/","tags":null,"title":"Omitting DataFrame Names in Julia StatsPlots with Macro @df"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Overview Introducing the function include() which executes Julia code itself to use functions from another file. In MATLAB, if it\u0026rsquo;s in the same directory, it tends to automatically find the function, so some people think this process is hard. There is a way to properly modularize and export, but1 it is not recommended for beginners who urgently need functionality because it is difficult and complicated. It\u0026rsquo;s not too late to learn about modularization after making a package yourself or when the scale of the program has become unmanageable.\nGuide Let\u0026rsquo;s say you want to run the baz() function in the foo/bar.jl file from main.jl as shown above. As you can see in the screenshot, you just write Julia code normally without using anything like modules.\nNow, the result of the execution by giving the path with include() is as follows.\nThe reason why 23 is printed as a result of the include() execution is that there was a value assignment like y = 23 at the bottom of the bar.jl file. As you can see, not only functions can be transferred, but also variables, and it\u0026rsquo;s possible to load data and print logs since it executes the file itself.\nEnvironment OS: Windows julia: v1.8.3 https://docs.julialang.org/en/v1/manual/modules/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2544,"permalink":"https://freshrimpsushi.github.io/en/posts/2544/","tags":null,"title":"How to Use Functions Defined in Other Files in Julia"},{"categories":"Ï§ÑÎ¶¨ÏïÑ","contents":"Code using Plots\rx, y = rand(100), rand(100) Given the data above, depending on whether the data is continuous or categorical, the shape of the plot and the method of plotting differ.\nContinuous scatter(marker_z=) z = x + y\rscatter(x, y, marker_z = z) Categorical scatter(group=) 1 team = rand(\u0026#39;A\u0026#39;:\u0026#39;C\u0026#39;, 100)\rscatter(x, y, group = team) Environment OS: Windows julia: v1.8.3 https://stackoverflow.com/a/60846501/12285249\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2537,"permalink":"https://freshrimpsushi.github.io/en/posts/2537/","tags":null,"title":"How to Color Markers in a Julia Fractal"},{"categories":"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù","contents":"Model Ordinary Kriging In Spatial Data Analysis, for a Random Field $\\mathbf{Y} = \\left( Y \\left( s_{1} \\right) , \\cdots , Y \\left( s_{n} \\right) \\right)$ following a Multivariate Normal Distribution with Mean $\\mu \\in \\mathbb{R}$ and Covariance Matrix $\\Sigma \\in \\mathbb{R}^{n \\times n}$, the value estimated for a new site $s_{0}$ using the model $$ \\mathbf{Y} = \\mu \\mathbf{1} + \\varepsilon $$ is called the Ordinary Kriging Estimate. The act of estimating using this model is also referred to as Kriging.\n$\\mathbf{1} = (1 , \\cdots , 1)$ is a 1-vector with all elements being $1$. $N_{n} \\left( \\mathbf{0} , \\Sigma \\right)$ denotes the Multivariate Normal Distribution. Explanation Etymology Kriging is named after the pioneer Daine G. Krige, and the term has become a general verb. In statistics, terms like prediction, forecasting, fitting, estimation, and the concept of filling in \u0026rsquo;empty spaces\u0026rsquo; similar to Interpolation are often used to describe it, summing up all these concepts into the verb \u0026ldquo;to Krig.\u0026rdquo;\nA distinguishing feature of Kriging, as opposed to applied mathematics, computer algorithms, and machine learning techniques, is its statistical approach of considering not just the mean (point estimate) but also the variance. For example, the Kriging estimate\u0026rsquo;s variance would be high in areas where each point has high variance, and low between points of low variance. This can be applied in choosing locations for data observation sites; for instance, in measuring concentrations of particulate matter, the interest may not be in how to measure but where to measure, focusing on where the variance of measurements is highest.\nDependence The formula $$ \\mathbf{Y} = \\mu \\mathbf{1} + \\varepsilon \\qquad , \\text{where } \\varepsilon \\sim N_{n} \\left( 0, \\Sigma \\right) $$ reveals that in the model, our main interest is in $\\varepsilon$, unlike in regression or time series analysis. If $\\Sigma$ is a Diagonal Matrix, implying no dependence between observations, it essentially means there\u0026rsquo;s no spatial structure to analyze, negating the need for Kriging. In practice, $\\Sigma$ is determined through the Semivariogram Model as follows. $$ \\Sigma = \\sigma^{2} H \\left( \\phi \\right) + \\tau^{2} I $$ Here, $\\tau^{2}$ represents the \u0026ldquo;Nugget Effect Variance\u0026rdquo; (the covariance seen regardless of distance in actual Data), and $I$ is the Identity Matrix.\nGeneralization The use of a generalized model for other independent variables in Kriging is called Universal Kriging. $$ \\mathbf{Y} = \\mathbf{X} \\beta + \\varepsilon $$\nFormula Given a Random Field $\\left\\{ Y (s_{k}) \\right\\}_{k=1}^{n}$ assumed to be an Intrinsic Stationary Spatial Process, and a new point to predict $s_{0}$, define the Matrix $\\Gamma \\in \\mathbb{R}^{n \\times n}$ with respect to the Variogram $2 \\gamma$ as $\\left( \\Gamma \\right)_{ij} := \\gamma \\left( s_{i} - s_{j} \\right)$, and the Vector $\\gamma_{0} \\in \\mathbb{R}^{n}$ as $\\left( \\gamma_{0} \\right)_{i} := \\left( \\gamma \\left( s_{0} - s_{i} \\right) \\right)$. The Best Linear Unbiased Predictor (BLUP) of $Y \\left( s_{0} \\right)$ is the Inner Product of $l$ and $\\mathbf{Y}$, given by $$ l^{T} \\mathbf{Y} = \\begin{bmatrix} l_{1} \u0026amp; \\cdots \u0026amp; l_{n} \\end{bmatrix} \\begin{bmatrix} Y \\left( s_{1} \\right)\\\\ Y \\left( s_{2} \\right)\\\\ \\vdots\\\\ Y \\left( s_{n} \\right) \\end{bmatrix} = \\sum_{k=1}^{n} l_{k} Y \\left( s_{k} \\right) $$ where the vector $l$ is specifically determined as follows. $$ l = \\Gamma^{-1} \\left( \\gamma_{0} + {{ 1 - \\mathbf{1}^T \\Gamma^{-1} \\gamma_{0} } \\over { \\mathbf{1}^T \\Gamma^{-1} \\mathbf{1} }} \\mathbf{1} \\right) $$\nDerivation 1 This section elaborates on the mathematical process of Kriging. Adding the assumption of a Gaussian Process to these formulas results in Ordinary Kriging.\nPart 1. Optimization Problem\nFor some constants $l_{1} , \\cdots , l_{n} , \\delta_{0} \\in \\mathbb{R}$, we aim to predict a new $Y \\left( s_{0} \\right)$ as a Linear Combination of existing data $$ \\hat{y} \\left( s_{0} \\right) = l_{1} y_{1} + \\cdots + l_{n} y_{n} + \\delta_{0} $$ which means finding the Optimal Solution $l_{1} , \\cdots , l_{n} , \\delta_{0}$ that Minimizes the Objective Function $$ E \\left[ Y \\left( s_{0} \\right) - \\left( \\sum_{k} l_{k} Y \\left( s_{k} \\right) + \\delta_{0} \\right) \\right]^{2} $$\nDefinition of Intrinsic Stationarity: Consider a Spatial Process $\\left\\{ Y(s) \\right\\}_{s \\in D}$ in a fixed subset $D \\subset \\mathbb{R}^{r}$ of the Euclidean Space, comprising a set of Random Variables $Y(s) : \\Omega \\to \\mathbb{R}^{1}$. Specifically, let\u0026rsquo;s denote $n \\in \\mathbb{N}$ Sites as $\\left\\{ s_{1} , \\cdots , s_{n} \\right\\} \\subset D$, assuming that $Y(s)$ has a Variance for all $s \\in D$. If $\\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right]$\u0026rsquo;s mean is $0$ and its variance depends only on $\\mathbf{h}$, then $\\left\\{ Y \\left( s_{k} \\right) \\right\\}$ is said to possess Intrinsic Stationarity. $$ \\begin{align*} E \\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right] =\u0026amp; 0 \\\\ \\text{Var} \\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right] =\u0026amp; 2 \\gamma ( \\mathbf{h} ) \\end{align*} $$\nBy imposing the constraint $\\sum_{k} l_{k} = 1$, if $\\left\\{ Y \\left( s_{k} \\right) \\right\\}_{k=1}^{n}$ is intrinsically stationary, $$ \\begin{align*} \u0026amp; E \\left[ Y \\left( s_{0} \\right) - \\left( \\sum_{k} l_{k} Y \\left( s_{k} \\right) \\right) \\right] \\\\ =\u0026amp; E \\left[ \\sum_{k} l_{k} Y \\left( s_{0} \\right) - \\left( \\sum_{k} l_{k} Y \\left( s_{k} \\right) \\right) \\right] \\\\ =\u0026amp; \\sum_{k} l_{k} E \\left[ Y \\left( s_{0} \\right) - Y \\left( s_{k} \\right) \\right] \\\\ =\u0026amp; 0 \\end{align*} $$ we can ensure that. The Objective Function to be minimized becomes $$ E \\left[ Y \\left( s_{0} \\right) - \\sum_{k} l_{k} Y \\left( s_{k} \\right) \\right]^{2} + \\delta_{0}^{2} $$ where $\\delta_{0}^{2}$ is irrelevant to the prediction. If the model is $\\mathbf{Y} = \\mu \\mathbf{1} + \\varepsilon$, $\\delta_{0}$ corresponds to $\\mu$, and it\u0026rsquo;s reasonable to set $\\delta_{0} = 0$ as $$ E \\left[ Y \\left( s_{0} \\right) - \\sum_{k} l_{k} Y \\left( s_{k} \\right) \\right]^{2} $$ Setting $a_{0} = 1$ and $a_{k} = - l_{k}$, $$ E \\left[ Y \\left( s_{0} \\right) - \\sum_{k=1}^{n} l_{k} Y \\left( s_{k} \\right) \\right]^{2} = E \\left[ \\sum_{k=0}^{n} a_{k} Y \\left( s_{k} \\right) \\right]^{2} $$ leads to solving the following optimization problem using the Lagrange Multiplier Method. $$ \\begin{matrix} \\text{Minimize} \u0026amp; \\displaystyle E \\left[ \\sum_{k=0}^{n} a_{k} Y \\left( s_{k} \\right) \\right]^{2} \\\\ \\text{subject to} \u0026amp; \\displaystyle \\sum_{k=0}^{n} a_{k} = 0 \\end{matrix} $$\nPart 2. Semivariogram $\\gamma$\nLet\u0026rsquo;s express $E \\left[ \\sum_{k=0}^{n} a_{k} Y \\left( s_{k} \\right) \\right]^{2}$ in terms of a semivariogram assumed to be computable from the data.\nDefinition of Semivariogram: Consider a Spatial Process $\\left\\{ Y(s) \\right\\}_{s \\in D}$ in a fixed subset $D \\subset \\mathbb{R}^{r}$ of the Euclidean Space, comprising a set of Random Variables $Y(s) : \\Omega \\to \\mathbb{R}^{1}$. Specifically, let\u0026rsquo;s denote $n \\in \\mathbb{N}$ sites as $\\left\\{ s_{1} , \\cdots , s_{n} \\right\\} \\subset D$, assuming that $Y(s)$ has a Variance for all $s \\in D$. The function defined as $2 \\gamma ( \\mathbf{h} )$ is called the Variogram. $$ 2 \\gamma ( \\mathbf{h} ) := E \\left[ Y \\left( s + \\mathbf{h} \\right) - Y(s) \\right]^{2} $$ Specifically, half of the Variogram $\\gamma ( \\mathbf{h} )$ is known as the Semivariogram.\nAssuming $\\gamma \\left( s_{i} - s_{j} \\right)$ as the semivariogram between two sites $s_{i}, s_{j}$, for any set $\\left\\{ a_{k} : k = 1 , \\cdots , n \\right\\} \\subset \\mathbb{R}$ satisfying $\\sum_{0=1}^{n} a_{k} = 0$, the following holds true. $$ \\sum_{i} \\sum_{j} a_{i} a_{j} \\gamma \\left( s_{i} - s_{j} \\right) = - E \\left[ \\sum_{i} a_{i} Y \\left( s_{i} \\right) \\right]^{2} $$ This is evident from the following derivation: $$ \\begin{align*} \u0026amp; \\sum_{i} \\sum_{j} a_{i} a_{j} \\gamma \\left( s_{i} - s_{j} \\right) \\\\ =\u0026amp; {{ 1 } \\over { 2 }} \\sum_{i} \\sum_{j} a_{i} a_{j} \\text{Var} \\left[ Y \\left( s_{i} \\right) - Y \\left( s_{j} \\right) \\right] \\\\ =\u0026amp; {{ 1 } \\over { 2 }} \\sum_{i} \\sum_{j} a_{i} a_{j} E \\left[ Y \\left( s_{i} \\right) - Y \\left( s_{j} \\right) \\right]^{2} \\\\ =\u0026amp; {{ 1 } \\over { 2 }} \\sum_{i} \\sum_{j} a_{i} a_{j} E \\left( \\left[ Y \\left( s_{i} \\right) \\right]^{2} - 2 Y \\left( s_{i} \\right) Y \\left( s_{j} \\right) + \\left[ Y \\left( s_{j} \\right) \\right]^{2} \\right) \\\\ =\u0026amp; - \\sum_{i} \\sum_{j} a_{i} a_{j} E \\left( Y \\left( s_{i} \\right) Y \\left( s_{j} \\right) \\right) \u0026amp; \\because \\text{cases of } i = j \\\\ =\u0026amp; - E \\sum_{i} \\sum_{j} a_{i} a_{j} Y \\left( s_{i} \\right) Y \\left( s_{j} \\right) \\\\ =\u0026amp; - E \\sum_{i} a_{i} Y \\left( s_{i} \\right) \\sum_{j} a_{j} Y \\left( s_{j} \\right) \\\\ =\u0026amp; - E \\left[ \\sum_{i} a_{i} Y \\left( s_{i} \\right) \\right]^{2} \\end{align*} $$ Setting $\\gamma_{ij} = \\gamma \\left( s_{i} - s_{j} \\right)$ and $\\gamma_{0j} = \\gamma \\left( s_{0} - s_{j} \\right)$, our objective function becomes $$ \\begin{align*} \u0026amp; E \\left[ \\sum_{i} a_{i} Y \\left( s_{i} \\right) \\right]^{2} \\\\ =\u0026amp; - \\sum_{i} \\sum_{j} a_{i} a_{j} \\gamma \\left( s_{i} - s_{j} \\right) \\\\ =\u0026amp; - \\sum_{i} \\sum_{j} l_{i} l_{j} \\gamma_{ij} + 2 \\sum_{i} l_{i} \\gamma_{0i} \\end{align*} $$ Applying the Lagrange Multiplier Method with the constraint $\\sum_{i} l_{i} = 1$ leads to $$ \\ - \\sum_{i} \\sum_{j} l_{i} l_{j} \\gamma_{ij} + 2 \\sum_{i} l_{i} \\gamma_{0i} - \\lambda \\sum_{i} l_{i} $$ Hence, differentiating with respect to $l_{i}$ yields $$ \\ - \\sum_{j} l_{j} \\gamma_{ij} + \\gamma_{0i} - \\lambda = 0 $$ which minimizes the objective function.\nPart 3. Optimal Solution\nNow, we derive the specific form of the optimal solution. Denote the element of matrix $\\Gamma \\in \\mathbb{R}^{n \\times n}$ as $\\gamma_{ij}$, meaning $\\left( \\Gamma \\right)_{ij} := \\gamma_{ij}$, and define vector $\\gamma_{0} \\in \\mathbb{R}^{n}$ as $\\left( \\gamma_{0} \\right)_{i} := \\gamma_{0i}$. If we set the vector of coefficients as $l := \\left( l_{1} , \\cdots , l_{n} \\right) \\in \\mathbb{R}^{n}$, then from Part 2, the derived equation can be expressed in the following matrix/vector form: $$ \\begin{align*} \u0026amp; - \\sum_{j} l_{j} \\gamma_{ij} + \\gamma_{0i} - \\lambda = 0 \\\\ \\implies \u0026amp; - \\Gamma l + \\gamma_{0} - \\lambda \\mathbf{1} = 0 \\\\ \\implies \u0026amp; \\Gamma l + \\lambda \\mathbf{1} = \\gamma_{0} \\end{align*} $$ Meanwhile, from the constraint, we have $$ \\sum_{i} l_{i} = 1 \\iff \\begin{bmatrix} 1 \u0026amp; \\cdots \u0026amp; 1 \\end{bmatrix} \\begin{bmatrix} l_{1} \\\\ \\vdots \\\\ l_{n} \\end{bmatrix} = 1 \\iff \\mathbf{1}^{T} l = 1 $$ which also gives us $\\mathbf{1}^{T} l = 1$. Here, $\\mathbf{x}^{T}$ represents the Transpose of $\\mathbf{x}$. First, considering $\\lambda$ alone, we have $$ \\begin{align*} 1 =\u0026amp; \\mathbf{1}^T l \\\\ =\u0026amp; \\mathbf{1}^T \\Gamma^{-1} \\Gamma l \\\\ =\u0026amp; \\mathbf{1}^T \\Gamma^{-1} \\left( \\gamma_{0} - \\lambda \\mathbf{1} \\right) \\\\ =\u0026amp; \\mathbf{1}^T \\Gamma^{-1} \\gamma_{0} - \\lambda \\mathbf{1}^T \\Gamma^{-1} \\mathbf{1} \\end{align*} $$ which simplifies to $$ \\ - \\lambda = {{ 1 - \\mathbf{1}^T \\Gamma^{-1} \\gamma_{0} } \\over { \\mathbf{1}^T \\Gamma^{-1} \\mathbf{1} }} $$ At this point, $l$ is essentially determined. $$ \\begin{align*} \u0026amp; \\Gamma l + \\lambda \\mathbf{1} = \\gamma_{0} \\\\ \\implies \u0026amp; \\Gamma l = \\gamma_{0} - \\lambda \\mathbf{1} \\\\ \\implies \u0026amp; \\Gamma l = \\gamma_{0} + {{ 1 - \\mathbf{1}^T \\Gamma^{-1} \\gamma_{0} } \\over { \\mathbf{1}^T \\Gamma^{-1} \\mathbf{1} }} \\mathbf{1} \\\\ \\implies \u0026amp; l = \\Gamma^{-1} \\left( \\gamma_{0} + {{ 1 - \\mathbf{1}^T \\Gamma^{-1} \\gamma_{0} } \\over { \\mathbf{1}^T \\Gamma^{-1} \\mathbf{1} }} \\mathbf{1} \\right) \\end{align*} $$\nThis concludes the derivation process for the optimal solution in Kriging, detailing how the estimates are calculated through the optimization of the objective function under given constraints, and how the semivariogram plays a central role in this estimation process.\n‚ñ†\nBanerjee. (2015). Hierarchical Modeling and Analysis for Spatial Data(2nd Edition): p25, 40~41.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2521,"permalink":"https://freshrimpsushi.github.io/en/posts/2521/","tags":null,"title":"Kringing in Spatial Data Analysis"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","id":null,"permalink":"https://freshrimpsushi.github.io/en/search/","tags":null,"title":"Search Results"}]