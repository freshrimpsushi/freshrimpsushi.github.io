[{"categories":"머신러닝","contents":"Overview1 2 Describe the adaptive learning rate used in gradient descent and the models that apply it: AdaGrad, RMSProp, and Adam.\nExplanation In gradient descent, the learning rate learning rate is an important parameter that determines how fast the parameter converges, how successful the method is, and so on. It is often written as $\\alpha$, $\\eta$, and determines how much of the gradient is taken into account when updating the parameter.\nOptimization Patterns with Learning Rate: Large Learning Rate (Left), Small Learning Rate (Right)\"\r$$ \\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\alpha \\nabla L (\\boldsymbol{\\theta}_{i}) $$\nIn basic gradient descent, $\\alpha$ is described as a constant, and in this case, gradient is a vector, so the same learning rate applies to all variables (parameters) as follows\n$$ \\alpha \\nabla L (\\boldsymbol{\\theta}) = \\alpha \\begin{bmatrix} \\dfrac{\\partial L}{\\partial \\theta_{1}} \u0026amp; \\dfrac{\\partial L}{\\partial \\theta_{2}} \u0026amp; \\cdots \u0026amp; \\dfrac{\\partial L}{\\partial \\theta_{k}} \\end{bmatrix} = \\begin{bmatrix} \\alpha\\dfrac{\\partial L}{\\partial \\theta_{1}} \u0026amp; \\alpha\\dfrac{\\partial L}{\\partial \\theta_{2}} \u0026amp; \\cdots \u0026amp; \\alpha\\dfrac{\\partial L}{\\partial \\theta_{k}} \\end{bmatrix} $$\nSo, by thinking of the learning rate as a vector like $\\boldsymbol{\\alpha} = (\\alpha_{1}, \\alpha_{2}, \\dots, \\alpha_{k})$, we can generalize the gradient term to the expression below.\n$$ \\boldsymbol{\\alpha} \\odot \\nabla L (\\boldsymbol{\\theta}) = \\begin{bmatrix} \\alpha_{1}\\dfrac{\\partial L}{\\partial \\theta_{1}} \u0026amp; \\alpha_{2}\\dfrac{\\partial L}{\\partial \\theta_{2}} \u0026amp; \\cdots \u0026amp; \\alpha_{k}\\dfrac{\\partial L}{\\partial \\theta_{k}} \\end{bmatrix} $$\nwhere $\\odot$ is the matrix\u0026rsquo;s [Adamar product (componentwise product)] (../3436). The learning rate $\\boldsymbol{\\alpha}$, which varies from parameter to parameter in this way, is called the adaptive learning rateadaptive learning rate. Since the following techniques rely on the gradient to determine the adaptive learning rate, $\\boldsymbol{\\alpha}$ can be viewed as a function of $\\boldsymbol{\\alpha}$.\n$$ \\boldsymbol{\\alpha} (\\nabla L(\\boldsymbol{\\theta})) = \\begin{bmatrix} \\alpha_{1}(\\nabla L(\\boldsymbol{\\theta})) \u0026amp; \\alpha_{2}(\\nabla L(\\boldsymbol{\\theta})) \u0026amp; \\dots \u0026amp; \\alpha_{k}(\\nabla L(\\boldsymbol{\\theta})) \\end{bmatrix} $$\nBelow we introduce AdaGrad, RMSProp, and Adam. It is important to note that there is no absolute winner among these optimizers, including the [momentum] (../3528) technique. Different fields and different tasks require different optimizers, so it\u0026rsquo;s not a good idea to make a judgment or question about \u0026ldquo;what\u0026rsquo;s best\u0026rdquo;. It\u0026rsquo;s helpful to find out what\u0026rsquo;s commonly used in your field, and if you don\u0026rsquo;t have that or aren\u0026rsquo;t sure, you can try SGD+Momentum or Adam.\nAdaGrad AdaGrad is an adaptive learning rate technique introduced in the paper \u0026ldquo;Adaptive subgradient methods for online learning and stochastic optimization\u0026rdquo; by Duchi et al. (2011). The name is short for adaptive gradient and is pronounced as [AY-duh-grad] or [AH-duh-grad]. In AdaGrad, the learning rate for each parameter is set inversely proportional to the gradient. Consider the vector $\\mathbf{r}$ as follows.\n$$ \\mathbf{r} = (\\nabla L) \\odot (\\nabla L) = \\begin{bmatrix} \\left( \\dfrac{\\partial L}{\\partial \\theta_{1}} \\right)^{2} \u0026amp; \\left( \\dfrac{\\partial L}{\\partial \\theta_{2}} \\right)^{2} \u0026amp; \\cdots \u0026amp; \\left( \\dfrac{\\partial L}{\\partial \\theta_{k}} \\right)^{2} \\end{bmatrix} $$\nFor a global learning rate global learning rate $\\epsilon$, an arbitrary small number $\\delta$, the adaptive learning rate $\\boldsymbol{\\alpha}$ is given by\n$$ \\boldsymbol{\\alpha} = \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}}} $$\nAs you can see from the formula, we apply a smaller learning rate for variables with larger components of the gradient and a larger learning rate for variables with smaller components of the gradient. The $\\delta$, as you might guess, prevents the denominator from being $0$ or too small a number, and is often used between $10^{-5} \\sim 10^{-7}$, and is often used for values between $10^{-5} and $10^{-7}. Also, the learning rate is cumulative from iteration to iteration. The gradient at the $i$th iteration is called $\\nabla L _{i} = \\nabla L (\\boldsymbol{\\theta}_{i})$,\n$$ \\begin{align} \\mathbf{r}_{i} \u0026amp;= (\\nabla L_{i}) \\odot (\\nabla L_{i}) \\nonumber \\\\ \\boldsymbol{\\alpha}_{i} \u0026amp;= \\boldsymbol{\\alpha}_{i-1} + \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}_{i}}} = \\sum_{j=1}^{i} \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}_{j}}} \\\\ \\boldsymbol{\\theta}_{i+1} \u0026amp;= \\boldsymbol{\\theta}_{i} - \\boldsymbol{\\alpha}_{i} \\odot \\nabla L_{i} \\nonumber \\end{align} $$\nAlgorithm: AdaGrad Input Global learning rate $\\epsilon$, small positive value $\\delta$, epochs $N$ 1. Initialize parameters $\\boldsymbol{\\theta}$ with random values. 2. Initialize learning rates $\\boldsymbol{\\alpha} = \\mathbf{0}$. 3. for $i = 1, \\cdots, N$ do 4. $\\mathbf{r} \\leftarrow \\nabla L(\\boldsymbol{\\theta}) \\odot \\nabla L(\\boldsymbol{\\theta})$ # Compute gradients and square each component 5. $\\boldsymbol{\\alpha} \\leftarrow \\boldsymbol{\\alpha} + \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}}}$ # Update adaptive learning rates 6. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\boldsymbol{\\alpha} \\odot \\nabla L(\\boldsymbol{\\theta})$ # Update parameters 7. end for RMSProp RMSProp, short for Root Mean Square Propagation, is an adaptive learning rate technique proposed in Geoffrey Hinton\u0026rsquo;s lecture Neural networks for machine learning. It is basically a variant of AdaGrad, only with the addition of $(1)$ replaced by a [weighted sum] (../2470/#exponentially weighted average) so that the added term decreases exponentially. For $\\rho \\in (0,1)$,\n$$ \\boldsymbol{\\alpha}_{i} = \\rho \\boldsymbol{\\alpha}_{i-1} + (1-\\rho) \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}_{i}}} = (1-\\rho) \\sum_{j=1}^{i} \\rho^{i-j} \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}_{j}}} $$\nLarge values such as $\\rho = 0.9, 0.99$ are commonly used.\nAlgorithm: RMSProp Input Global learning rate $\\epsilon$, small positive value $\\delta$, decay rate $\\rho$, epochs $N$ 1. Initialize parameters $\\boldsymbol{\\theta}$ with random values. 2. Initialize learning rates $\\boldsymbol{\\alpha} = \\mathbf{0}$. 3. for $i = 1, \\dots, N$ do 4. $\\mathbf{r} \\leftarrow \\nabla L(\\boldsymbol{\\theta}) \\odot \\nabla L(\\boldsymbol{\\theta})$ # Compute gradients and square each component 5. $\\boldsymbol{\\alpha} \\leftarrow \\rho \\boldsymbol{\\alpha} + (1-\\rho) \\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}}}$ # Update adaptive learning rates 6. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\boldsymbol{\\alpha} \\odot \\nabla L(\\boldsymbol{\\theta})$ # Update parameters 7. end for Adam Adamderives from \u0026quot;apative moments\u0026quot; is an optimizer introduced in the paper \u0026quot;Adam: A method for stochastic optimization\u0026quot; (Kingma and Ba, 2014). It combines the adaptive learning rate and the momentum technique and can be thought of as RMSProp + momentum. Once you understand RMSProp and momentum, it\u0026rsquo;s not hard to understand Adam. Here\u0026rsquo;s how RMSProp, momentum, and Adam compare to each other If $\\nabla L_{i} = \\nabla L(\\boldsymbol{\\theta}_{i})$,\nMomentum\r$\\mathbf{p}_{i} = \\beta_{1}\\mathbf{p}_{i-1} + \\nabla L_{i} \\quad (\\mathbf{p}_{0}=\\mathbf{0}) \\\\\r\\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\alpha \\mathbf{p}_{i}$\rRMSProp\r$\\mathbf{r}_{i} = \\nabla L_{i} \\odot \\nabla L_{i} \\\\\r\\boldsymbol{\\alpha}_{i} = \\beta_{2} \\boldsymbol{\\alpha}_{i-1} + (1-\\beta_{2})\\dfrac{\\epsilon}{\\delta + \\sqrt{\\mathbf{r}_{i}}} \\quad (\\boldsymbol{\\alpha}_{0}=\\mathbf{0})\\\\\r\\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\boldsymbol{\\alpha}_{i} \\odot \\nabla L_{i}$\rAdam\r$\\mathbf{p}_{i} = \\beta_{1}\\mathbf{p}_{i-1} + (1-\\beta_{1}) \\nabla L_{i-1} \\quad (\\mathbf{p}_{0}=\\mathbf{0}) \\\\\\\\[0.5em]\r\\hat{\\mathbf{p}}_{i} = \\dfrac{\\mathbf{p}_{i}}{1-(\\beta_{1})^{i}} \\\\\\\\[0.5em]\r\\mathbf{r}_{i} = \\beta_{2} \\mathbf{r}_{i-1} + (1-\\beta_{2}) \\nabla L_{i} \\odot \\nabla L_{i} \\\\\\\\[0.5em]\r\\hat{\\mathbf{r}}_{i} = \\dfrac{\\mathbf{r}}{1-(\\beta_{2})^{i}} \\\\\\\\[0.5em]\r\\hat{\\boldsymbol{\\alpha}}_{i} = \\dfrac{\\epsilon}{\\delta + \\sqrt{\\hat{\\mathbf{r}}_{i}}} \\\\\\\\[0.5em]\r\\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\hat{\\boldsymbol{\\alpha}_{i}} \\odot \\hat{\\mathbf{p}_{i}}\r$\rThe reason we divide $1 - \\beta^{i}$ when calculating $\\hat{\\mathbf{p}}_{i}$ and $\\hat{\\mathbf{r}}_{i}$ is to make them weighted averages since $\\mathbf{p}_{i}$ and $\\mathbf{r}_{i}$ are weighted sums.\nAlgorithm: Adam\rInput Global learning rate $\\epsilon$ (recommended value is $0.001$), epochs $N$ Small constant $\\delta$ (recommended value is $10^{-8}$) Decay rates $\\beta_{1}, \\beta_{2}$ (recommended values are $0.9$ and $0.999$ respectively) 1. Initialize parameters $\\boldsymbol{\\theta}$ with random values. 2. Initialize learning rates $\\boldsymbol{\\alpha} = \\mathbf{0}$. 3. Initialize momentum $\\mathbf{p} = \\mathbf{0}$. 4. for $i = 1, \\dots, N$ do 5. $\\mathbf{p} \\leftarrow \\beta_{1}\\mathbf{p} + (1-\\beta_{1}) \\nabla L$ # Update momentum using weighted sum 6. $\\hat{\\mathbf{p}} \\leftarrow \\dfrac{\\mathbf{p}}{1-(\\beta_{1})^{i}}$ # Correct with weighted average 7. $\\mathbf{r} \\leftarrow \\beta_{2} \\mathbf{r} + (1-\\beta_{2}) \\nabla L \\odot \\nabla L$ # Update gradient square vector with weighted sum 8. $\\hat{\\mathbf{r}} \\leftarrow \\dfrac{\\mathbf{r}}{1-(\\beta_{2})^{i}}$ # Correct with weighted average 9. $\\hat{\\boldsymbol{\\alpha}} \\leftarrow \\dfrac{\\epsilon}{\\delta + \\sqrt{\\hat{\\mathbf{r}}}}$ # Update adaptive learning rates 10. $\\boldsymbol{\\theta} = \\boldsymbol{\\theta} - \\hat{\\boldsymbol{\\alpha}} \\odot \\hat{\\mathbf{p}}$ # Update parameters 11. end for Ian Goodfellow, Deep Learning, 8.5 Algorithms with Adaptive Learning Rates\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n오일석, 기계 학습(MACHINE LEARNING) (2017), ch 5.4 적응적 학습률\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3529,"permalink":"https://freshrimpsushi.github.io/en/posts/3529/","tags":null,"title":"Adaptive Learning Rates: AdaGrad, RMSProp, Adam"},{"categories":"머신러닝","contents":"Overview1 2 In gradient descent, the momentum technique involves using all previous gradients when updating parameters. This is its essence and the end of the explanation. However, explanations involving strange update equations, the motivation from physics\u0026rsquo; momentum, setting the mass to $1$ and the initial velocity to $0$, only complicate understanding. This article explains the momentum technique as plainly as possible.\nBuild-Up Let\u0026rsquo;s denote the parameters as $\\boldsymbol{\\theta}$ and the loss function as $L$. The standard gradient descent method updates the parameters iteratively as follows:\n$$ \\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\alpha \\nabla L_{i} $$\nHere, $L_{i} = L(\\boldsymbol{\\theta}_{i})$ represents the loss function calculated in the $i$th iteration. The momentum technique simply adds $\\nabla L_{i-1}$, the gradient of the loss function calculated in the previous iteration.\n$$ \\boldsymbol{\\theta}_{i+1} = \\boldsymbol{\\theta}_{i} - \\alpha \\nabla L_{i} - \\alpha \\nabla L_{i-1} - \\cdots - \\alpha \\nabla L_{0} $$\nAs iterations progress, to reduce the impact of the gradient and prevent the sum of gradients from diverging, a coefficient $\\beta \\in (0,1)$ is added as follows:\n$$ \\begin{align} \\boldsymbol{\\theta}_{i+1} \u0026amp;= \\boldsymbol{\\theta}_{i} - \\alpha \\nabla L_{i} - \\beta \\alpha \\nabla L_{i-1} - \\cdots - \\beta^{i}\\alpha \\nabla L_{0} \\nonumber \\\\ \u0026amp;= \\boldsymbol{\\theta}_{i} - \\alpha\\sum_{j=0}^{i} \\beta^{j} \\nabla L_{i-j} \\end{align} $$\nDefinition Updating the parameters as in $(1)$ is called the momentum method, and the added term $\\alpha\\sum\\limits_{j=0}^{i} \\beta^{j} \\nabla L_{i-j}$ is referred to as momentum.\nExplanation According to the definition, the momentum method is a generalized form of gradient descent. In fact, gradient descent can be seen as a special case of the momentum method where $\\beta = 0$. The closer $\\beta$ is to $1$, the more it reflects previous gradients, and vice versa when it\u0026rsquo;s closer to $0$.\nGradient descent updates parameters in the direction of the steepest current gradient and is thus a greedy algorithm. The momentum method mitigates this greediness, enabling choices that may not be the best in the short term but are more beneficial in the long run. It also helps prevent sudden and excessive changes in gradient direction.\nObviously, since the magnitude of the gradient used to update parameters is larger compared to standard gradient descent, the momentum method has the advantage of faster convergence. Empirically, it is also known to escape local minima more effectively, similar to how a ball rolling down a hill can overcome small bumps if it has enough speed.\nIt is important to note that there is no absolute superiority among these optimizers, including adaptive learning rate techniques. The optimal optimizer varies by field and task, so it\u0026rsquo;s unwise to ask or judge which is the best. It\u0026rsquo;s helpful to learn what is commonly used in your field, or if unsure, to try SGD+momentum or Adam.\nNesterov Momentum To summarize the momentum method: to obtain the next parameter $\\boldsymbol{\\theta}_{i+1}$, the current gradient $\\alpha \\nabla L(\\boldsymbol{\\theta}_{i})$ is cumulatively added to the current parameter $\\boldsymbol{\\theta}_{i}$.\nNesterov momentum, or Nesterov accelerated gradient (NAG), computes the gradient at \u0026ldquo;the current parameter plus the previous gradient\u0026rdquo; and adds this to the current parameter to obtain the next one. This might sound complicated, but if you understand the momentum method, the following algorithm may make Nesterov momentum easier to grasp.\nAlgorithm Let\u0026rsquo;s denote the momentum term as $\\mathbf{p}$.\nAlgorithm: Momentum Method Input Learning rate $\\alpha$, momentum parameter $\\beta$, epochs $N$ 1. Initialize parameters $\\boldsymbol{\\theta}$ to random values. 2. Initialize momentum $\\mathbf{p} = \\mathbf{0}$. 3. for $k = 1, \\cdots, N$ do 4. $\\mathbf{p} \\leftarrow \\beta \\mathbf{p} - \\alpha \\nabla L(\\boldsymbol{\\theta})$ # Update momentum with calculated gradient 5. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\mathbf{p}$ # Update parameters 6. end for Algorithm: Nesterov Momentum Input Learning rate $\\alpha$, momentum parameter $\\beta$, epochs $N$ 1. Initialize parameters $\\boldsymbol{\\theta}$ to random values. 2. Initialize momentum $\\mathbf{p} = \\mathbf{0}$. 3. for $k = 1, \\cdots, N$ do 4. $\\mathbf{p} \\leftarrow \\beta \\mathbf{p} - \\alpha \\nabla L(\\boldsymbol{\\theta} + \\beta \\mathbf{p})$ # Update momentum with calculated gradient 5. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\mathbf{p}$ # Update parameters 6. end for Looking at the first few calculations of both methods, we can represent it as follows. If we simply denote $\\mathbf{p}_{i} = \\alpha \\nabla L_{i}$, and $\\mathbf{p}^{i} = \\alpha \\nabla L(\\boldsymbol{\\theta}_{i} - \\beta^{1}\\mathbf{p}^{i-1} - \\beta^{2}\\mathbf{p}^{i-2} - \\cdots - \\beta^{i}\\mathbf{p}^{0})$ (here $\\mathbf{p}^{0} = \\mathbf{p}_{0}$), then\nMomentum Nesterov Momentum $\\boldsymbol{\\theta}\\_{0} =$ initial\r$\\boldsymbol{\\theta}\\_{0} =$ initial\r$\\boldsymbol{\\theta}\\_{1} = \\boldsymbol{\\theta}\\_{0} - \\alpha \\nabla L\\_{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{0} - \\mathbf{p}\\_{0}$\r$\\boldsymbol{\\theta}\\_{1} = \\boldsymbol{\\theta}\\_{0} - \\alpha \\nabla L\\_{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{0} - \\mathbf{p}^{0}$\r$\\boldsymbol{\\theta}\\_{2} = \\boldsymbol{\\theta}\\_{1} - \\alpha\\nabla L\\_{1} - \\beta \\mathbf{p}\\_{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{1} - \\mathbf{p}\\_{1} - \\beta \\mathbf{p}\\_{0}$\r$\\boldsymbol{\\theta}\\_{2} = \\boldsymbol{\\theta}\\_{1} - \\alpha \\nabla L(\\boldsymbol{\\theta}\\_{1} - \\beta \\mathbf{p}^{0}) - \\beta \\mathbf{p}^{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{1} - \\mathbf{p}^{1} - \\beta \\mathbf{p}^{0}$\r$\\boldsymbol{\\theta}\\_{3} = \\boldsymbol{\\theta}\\_{2} - \\mathbf{p}\\_{2} - \\beta \\mathbf{p}\\_{1} - \\beta^{2} \\mathbf{p}\\_{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{2} - \\sum\\limits\\_{j=0}^{2}\\beta^{j}\\mathbf{p}\\_{2-j}$\r$\\boldsymbol{\\theta}\\_{3} = \\boldsymbol{\\theta}\\_{2} - \\alpha \\nabla L(\\boldsymbol{\\theta}\\_{2} - \\beta \\mathbf{p}^{1} - \\beta^{2}\\mathbf{p}^{0}) - \\beta \\mathbf{p}^{1} - \\beta^{2}\\mathbf{p}^{0} \\\\ \\quad\\ = \\boldsymbol{\\theta}\\_{2} - \\mathbf{p}^{2} - \\beta \\mathbf{p}^{1} - \\beta^{2} \\mathbf{p}^{0}$\r$$\\vdots$$\r$$\\vdots$$\r$\\boldsymbol{\\theta}\\_{i+1} = \\boldsymbol{\\theta}\\_{i} - \\sum\\limits\\_{j=0}^{i}\\beta^{j}\\mathbf{p}\\_{i-j}$\r$\\boldsymbol{\\theta}\\_{i+1} = \\boldsymbol{\\theta}\\_{i} - \\sum\\limits\\_{j=0}^{i}\\beta^{j}\\mathbf{p}^{i-j}$\rIan Goodfellow, Deep Learning, Ch 8.3.2 Momentum, 8.3.3 Nesterov Momentum\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nO Ilseok, Machine Learning (2017), Ch 5.3 Momentum\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3528,"permalink":"https://freshrimpsushi.github.io/en/posts/3528/","tags":null,"title":"Momentum Method in Gradient Descent"},{"categories":"줄리아","contents":"Overview In Julia, you can easily use a progress bar to indicate the progress of a program.\nCode ProgressMeter.jl By placing the @showprogress macro from the ProgressMeter.jl package in a for loop, you can display the progress1.\nusing ProgressMeter chi2 = [] @showprogress for n in 1:20000 push!(chi2, sum(randn(n) .^ 2)) end Compared to ProgressBars.jl below, the use of a macro makes the code more concise.\nProgressBars.jl You can wrap the iterator of a for loop with the ProgressBar() function from the ProgressBars.jl package2.\nusing ProgressBars chi2 = [] for n in ProgressBar(1:20000) push!(chi2, sum(randn(n) .^ 2)) end Regardless of the actual task, the progress of the program is beautifully displayed. Naturally, since it only indicates which iteration the for loop is currently on, it can only provide the average execution time per iteration, not an accurate prediction of the total time required.\nEnvironment OS: Windows julia: v1.7.3 https://github.com/timholy/ProgressMeter.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/cloud-oak/ProgressBars.jl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2497,"permalink":"https://freshrimpsushi.github.io/en/posts/2497/","tags":null,"title":"How to use progress bars in Julia"},{"categories":"머신러닝","contents":"Overview Monte Carlo integration is a numerical approximation method used when calculating the integral of a given function is difficult. Consider the following scenario: For an integrable function $f$ in the given $[0, 1]$or generally $[0, 1]^{n}$, we know the formula of $f(x)$ but calculating its integral is not straightforward. However, we want to calculate the integral $I[f]$ of $f$.\n$$ \\begin{equation} I[f] = \\int_{[0,1]} f(x) dx \\end{equation} $$\nDefinition Monte Carlo integrationMonte Carlo integration is a method to estimate the integral of $f$ by drawing samples $\\left\\{ x_{i} \\right\\}$ from a distribution on $[0, 1]$ as follows:\n$$ I[f] \\approx I_{n}[f] := \\dfrac{1}{n}\\sum_{i=1}^{n} f(x_{i}) $$\nDifference from Riemann Sum The idea of Riemann Sum is to divide the interval $[0,1]$ into $n$ equal parts and get points $\\left\\{ x_{i} = \\frac{i-1}{n} \\right\\}_{i=1}^{n}$, then sum up the function values at these points.\n$$ \\text{mensuration by parts}[f] = \\dfrac{1}{n}\\sum_{i=1}^{n} f(x_{i}) $$\nAt first glance, Monte Carlo integration and Riemann Sum may seem similar, but their meanings are completely different. In Riemann Sum, $\\left\\{ x_{i} \\right\\}$ are points obtained by dividing the interval $[0, 1]$ into $n$ equal parts, whereas in Monte Carlo integration, $x$ represents $n$ samples drawn from the distribution $p(x)$. Thus, the value obtained by Riemann Sum simply represents the area under the graph drawn by $f$, while the value obtained by Monte Carlo integration represents the expectation of $f$.\nProperties The statistical meaning of equation $(1)$ is that \u0026rsquo;the $I[f]$ is equal to the expectation of $f(X)$ when $X$ follows a uniform distribution'.\n$$ X \\sim U(0,1) \\implies I[f] = \\int_{[0,1]} f(x) dx = E\\left[ f(X) \\right] $$\nExpectation Let the random variable $X$ follow a uniform distribution. $I_{n}[f]$ is an unbiased estimator of $I[f]$.\n$$ E\\left[ I_{n}[f] \\right] = I[f] $$\nProof $$ \\begin{align*} E\\left[ I_{n}[f] \\right] \u0026amp;= E\\left[ \\dfrac{1}{n} \\sum\\limits_{i=1}^{n} f(X_{i}) \\right] \\\\ \u0026amp;= \\dfrac{1}{n} \\sum\\limits_{i=1}^{n} E\\left[ f(X_{i}) \\right] \\qquad \\text{by linearity of $E$} \\\\ \u0026amp;= \\dfrac{1}{n} \\sum\\limits_{i=1}^{n} I\\left[ f \\right] \\\\ \u0026amp;= I\\left[ f \\right] \\end{align*} $$\n■\nVariance Proof Properties of Variance\n[a] $\\Var (aX) = a^{2} \\Var (X)$\n[b] If $X, Y$ are independent, $\\Var (X + Y) = \\Var(X) + \\Var(Y)$\nLet\u0026rsquo;s denote the variance of $f(X)$ as $\\sigma^{2}$. Then, by the properties of variance:\n$$ \\begin{align*} \\Var \\left[ I_{n}[f] \\right] \u0026amp;= \\Var \\left[ \\dfrac{1}{n} \\sum\\limits_{i=1}^{n} f(X_{i}) \\right] \\\\ \u0026amp;= \\dfrac{1}{n^{2}} \\Var \\left[ \\sum\\limits_{i=1}^{n} f(X_{i}) \\right] \\\\ \u0026amp;= \\dfrac{1}{n^{2}} \\sum\\limits_{i=1}^{n} \\Var \\left[ f(X_{i}) \\right] \\\\ \u0026amp;= \\dfrac{1}{n^{2}} \\sum\\limits_{i=1}^{n} \\sigma^{2} \\\\ \u0026amp;= \\dfrac{\\sigma^{2}}{n} \\end{align*} $$\n■\nGeneralization Now consider a function $p(x) \\ge 0$ and $\\int_{[0,1]} p = 1$. Think about the integral $I[fp]$.\n$$ I[fp] = \\int_{[0, 1]}f(x)p(x) dx $$\nThis is the same as the expectation of $f(X)$ for a random variable $X$ with a probability density function $p$. To approximate this value, we can consider the following two methods:\nDraw samples $\\left\\{ x_{i} \\right\\}_{i=1}^{n}$ uniformly and approximate $I[fp]$ as follows: $$ X_{i} \\sim U(0,1) \\qquad I[fp] \\approx \\dfrac{1}{n}\\sum\\limits_{i}f(x_{i})p(x_{i}) $$\nDraw samples $\\left\\{ x_{i} \\right\\}_{i=1}^{n}$ from $p(x)$ and approximate $I[fp]$ as follows: $$ X_{i} \\sim p(x) \\qquad I[fp] = I_{p}[f] \\approx \\dfrac{1}{n}\\sum\\limits_{i}f(x_{i}) $$\nIn other words, 1. is averaging $f(x)p(x)$ by uniform sampling, and 2. is averaging $f(x)$ by sampling from $p(x)$. Among these, the one with smaller variance is 1. Let\u0026rsquo;s simplify the notation as $I = I[fp] = I[fp]$.\nIn case of 1. $$ \\begin{align*} \\sigma_{1}^{2} = \\Var [fp] \u0026amp;= E \\left[ (fp - I)^{2} \\right] \\\\ \u0026amp;= \\int (fp - I)^{2} dx \\\\ \u0026amp;= \\int (fp)^{2} dx - 2I\\int fp dx + I^{2}\\int dx\\\\ \u0026amp;= \\int (fp)^{2} dx - 2I^{2} + I^{2}\\\\ \u0026amp;= \\int (fp)^{2} dx - I^{2}\\\\ \\end{align*} $$\nIn case of 2. $$ \\begin{align*} \\sigma_{2}^{2} = \\Var [f] \u0026amp;= E_{p} \\left[ (f - I)^{2} \\right] \\\\ \u0026amp;= \\int (f - I)^{2}p dx \\\\ \u0026amp;= \\int f^{2}p dx - 2I\\int fp dx + I^{2}\\int pdx\\\\ \u0026amp;= \\int f^{2}p dx - 2I^{2} + I^{2}\\\\ \u0026amp;= \\int f^{2}p dx - I^{2}\\\\ \\end{align*} $$\nHowever, since $0 \\le p \\le 1$, it follows that $f^{2}p \\ge f^{2}p^{2}$. Therefore,\n$$ \\sigma_{1}^{2} \\le \\sigma_{2}^{2} $$\n","id":3515,"permalink":"https://freshrimpsushi.github.io/en/posts/3515/","tags":null,"title":"Monte Carlo Integration"},{"categories":"푸리에해석","contents":"Overview1 The Discrete Fourier Transform (DFT), when computed naively following its mathematical definition, has a time complexity of $\\mathcal{O}(N^{2})$. However, by using the algorithm described below, the time complexity can be reduced to $\\mathcal{O}(N\\log_{2}N)$. This efficient computation method of the Discrete Fourier Transform is known as the Fast Fourier Transform (FFT).\nBuildup Let\u0026rsquo;s define multiplying two numbers and then adding them to another number as one operation. To compute the value of $\\sum\\limits_{i=0}^{n-1}a_{n}b_{n}$, $n$ operations are needed.\n$$ \\begin{align*} \\sum\\limits_{n=0}^{0} a_{n}b_{b} \u0026amp;= a_{0}b_{0} = \\overbrace{0 {\\color{red} +} a_{0} {\\color{red} \\times} b_{0}}^{\\color{red} 1 \\text{ operation}} \\\\ \\sum\\limits_{n=0}^{1} a_{n}b_{b} \u0026amp;= a_{0}b_{0} + a_{1}b_{1} = \\overbrace{\\big( \\overbrace{0 {\\color{red} +} a_{0} {\\color{red} \\times} b_{0}}^{\\color{red} 1 \\text{ operation}} \\big) {\\color{#5882FA} + } a_{1} {\\color{#5882FA} \\times} b_{1}}^{\\color{#5882FA}2 \\text{ operations}} \\\\ \\sum\\limits_{n=0}^{2} a_{n}b_{b} \u0026amp;= a_{0}b_{0} + a_{1}b_{1} + a_{2}b_{2} = \\overbrace{\\bigg( \\overbrace{\\big( \\overbrace{0 {\\color{red} +} a_{0} {\\color{red} \\times} b_{0}}^{\\color{red} 1 \\text{ operation}} \\big) {\\color{#5882FA} + } a_{1} {\\color{#5882FA} \\times} b_{1}}^{\\color{#5882FA}2 \\text{ operations}} \\bigg) {\\color{#FE9A2E} + } a_{2} {\\color{#FE9A2E} \\times} b_{2}}^{\\color{#FE9A2E}3 \\text{ operations}} \\\\ \\end{align*} $$\nNow, recall the definition of the Discrete Fourier Transform.\nThe linear transformation $\\mathcal{F}_{N} : \\mathbb{C}^{N} \\to \\mathbb{C}^{N}$ is called the Discrete Fourier Transform.\n$$ \\mathcal{F}_{N}(\\mathbf{a}) = \\hat{\\mathbf{a}} = \\begin{bmatrix} \\hat{a}_{0} \\\\ \\hat{a}_{1} \\\\ \\dots \\\\ \\hat{a}_{N-1} \\end{bmatrix} ,\\quad \\hat{a}_{m} = \\sum_{n=0}^{N-1}e^{-i2\\pi mn /N} a_{n}\\quad (0\\le m \u0026lt; N) \\tag{1} $$\nWhere $\\mathbf{a} = \\begin{bmatrix} a_{0}\u0026amp; a_{1}\u0026amp; \\dots\u0026amp; a_{N-1} \\end{bmatrix}^{T}$.\nTo compute $\\hat{a}_{m}$, $N$ operations are needed, and to compute $\\hat{\\mathbf{a}}$, this must be performed $N$ times. Therefore, the total number of operations needed for the Discrete Fourier Transform is $N^{2}$, which means it has a time complexity of $\\mathcal{O}(N^{2})$. This implies a significant computational cost for Fourier Transforms from a computer calculation perspective.\nAlgorithm Let\u0026rsquo;s assume the length of the data, $N$, is a composite number $N = N_{1}N_{2}$. Now, define the indices $m, n$ as follows.\n$$ m = m^{\\prime}N_{1} + m^{\\prime \\prime},\\quad n = n^{\\prime}N_{2} + n^{\\prime \\prime} $$\nThen, $0 \\le m^{\\prime}, n^{\\prime \\prime} \\le N_{2}-1$, and $0 \\le m^{\\prime \\prime}, n^{\\prime} \\le N_{1}-1$. Let\u0026rsquo;s express the exponent part of $(1)$ as follows.\n$$ \\begin{align*} e^{-i2\\pi mn /N} \u0026amp;= e^{-i2\\pi (m^{\\prime}N_{1} + m^{\\prime \\prime})(n^{\\prime}N_{2} + n^{\\prime \\prime})/(N_{1}N_{2})} \\\\ \u0026amp;= e^{-i2\\pi (m^{\\prime}n^{\\prime}N_{1}N_{2} + m^{\\prime}n^{\\prime \\prime}N_{1} + m^{\\prime \\prime}n^{\\prime}N_{2} + m^{\\prime \\prime}n^{\\prime \\prime})/(N_{1}N_{2})} \\\\ \u0026amp;= e^{-i2\\pi m^{\\prime}n^{\\prime}} e^{-i2\\pi \\big( (m^{\\prime}n^{\\prime \\prime}/N_{2}) + (m^{\\prime \\prime}n^{\\prime}/N_{1}) + (m^{\\prime \\prime}n^{\\prime \\prime}/N) \\big)} \\\\ \u0026amp;= e^{-i2\\pi \\big( (m^{\\prime}n^{\\prime \\prime}/N_{2}) + (m^{\\prime \\prime}n^{\\prime}/N_{1}) + (m^{\\prime \\prime}n^{\\prime \\prime}/N) \\big)} \\\\ \\end{align*} $$\nSubstituting this into $(1)$ gives,\n$$ \\begin{align*} \\hat{a}_{m} \u0026amp;= \\sum_{n=0}^{N-1}e^{-i2\\pi mn /N} a_{n} \\\\ \u0026amp;= \\sum_{n^{\\prime \\prime}=0}^{N_{2}-1} \\sum_{n^{\\prime}=0}^{N_{1}-1} e^{-i2\\pi \\big( (m^{\\prime}n^{\\prime \\prime}/N_{2}) + (m^{\\prime \\prime}n^{\\prime}/N_{1}) + (m^{\\prime \\prime}n^{\\prime \\prime}/N) \\big)}a_{n^{\\prime}N_{2}+n^{\\prime \\prime}} \\\\ \u0026amp;= \\sum_{n^{\\prime \\prime}=0}^{N_{2}-1} \\left[ \\sum_{n^{\\prime}=0}^{N_{1}-1} e^{-i2\\pi m^{\\prime \\prime}n^{\\prime}/N_{1}}a_{n^{\\prime}N_{2}+n^{\\prime \\prime}} \\right] e^{-i2\\pi [ (m^{\\prime}n^{\\prime \\prime}/N_{2}) + (m^{\\prime \\prime}n^{\\prime \\prime}/N) ] } \\end{align*} $$\nAccording to the equation above, calculating $\\left[ \\sum_{n^{\\prime}=0}^{N_{1}-1} \\right]$ inside each bracket requires $N_{1}$ operations, and computing $\\sum_{n^{\\prime \\prime}=0}^{N_{2}-1}$ outside each bracket requires $N_{2}$ operations. Therefore, to calculate $\\hat{a}_{m}$, a total of $(N_{1} + N_{2})$ operations are needed. To obtain $\\hat{\\mathbf{a}}$, this must be repeated $N$ times, resulting in a total cost of $N(N_{1} + N_{2})$, which is a reduction from $N^{2}$.\nUpon closer inspection of the brackets, it is apparent that if $N_{1}$ is again a composite number, the same logic can be applied. Generally, when the length of the data is a composite number $N = N_{1} N_{2} \\cdots N_{k}$, the time complexity is reduced as follows.\n$$ \\mathcal{O}(N^{2}) \\searrow \\mathcal{O}\\big( N(N_{1} + N_{2} + \\cdots + N_{k}) \\big) $$\nNow, let\u0026rsquo;s assume $N$ is a power of $2$, $N = 2^{k}$. Then $\\log_{2}N = k$, and from $N^{2} = 2^{k}$, it is reduced to $2^{k}(2k)$, hence the time complexity is reduced as follows.\n$$ \\mathcal{O}(N^{2}) \\searrow \\mathcal{O}(2N \\log_{2}N) $$\nAside This method was proposed in 1965 by Cooley and Tukey2, hence it is also called the Cooley-Tukey algorithm. However, they were not the first to invent it. Gauss also researched a similar algorithm but did not publish it properly, so this fact became known later3.\nGerald B. Folland, Fourier Analysis and Its Applications (1992), p252-253\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. W. Cooley and J. W. Tukey, An algorithm for the machine calculation of complex Fourier series, Mathematics of Computation 19 (1965), 297-301.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. T. Heideman, D. H. Johnson, and C. S. Burms, Gauss and the history of the fast Fourier transform, Archive for the History of the Exact Sciences 34 (1985), 264-277.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3492,"permalink":"https://freshrimpsushi.github.io/en/posts/3492/","tags":null,"title":"The Fast Fourier Transform Algorithm"},{"categories":"확률론","contents":"Overview This is a summary of definitions and concepts for those who have already studied measure theory and probability. It is intended to be viewed when definitions are confusing or unrecognizable, and when a general review is needed.\nMeasure Theory Algebras An algebra of sets on nonempty set $X$ is a nonempty collection $\\mathcal{A}$ of subsets of $X$ is colsed under finite unions ans complements.\n$\\sigma$-algebra is an algebra that is closed under countable unions.\nNote:\n$\\mathcal{A}$ is also closed under intersections, because $E_{1} \\cap E_{2} = \\left( E_{1} \\cup E_{2} \\right)^{c} \\in \\mathcal{A}$ for $E_{1}, E_{2} \\in \\mathcal{A}$. $\\varnothing$, $X$ $\\in \\mathcal{A}$, since if $E \\in \\mathcal{A}$ we have $\\varnothing = E \\cap E^{c} \\in \\mathcal{A}$ and $X = E \\cup E^{c} \\in \\mathcal{A}$. If $X$ any topological space, the $\\sigma$-algebra generated by the family of open sets in $X$ is called the Borel $\\sigma$-algebra on $X$ and is denoted by $\\mathcal{B}_{X}$.\nBorel $\\sigma$-algebra is unique smallest $\\sigma$-algebra containing all open sets. Let $\\mathcal{E}$ be a $\\sigma$-algebra on $X$, then $(X, \\mathcal{E})$ is called a measurable space and $E \\in \\mathcal{E}$ is called ($\\mathcal{E}$-)measurable set.\nIn the following, we shall consider a fixed measurable space $(X, \\mathcal{E})$.\nMeasurable Functions A function $f : X \\to \\mathbb{R}$ is said to be ($\\mathcal{E}$-)measurable, if for every real number $\\alpha \\in \\mathbb{R}$ the set $\\left\\{ x \\in X : f(x) \\gt \\alpha \\right\\}$ belongs to $\\mathcal{E}$.\nGeneralization Let $(X, \\mathcal{E})$ and $(Y, \\mathcal{F})$ be a measurable spaces. A function $f : X \\to Y$ is called $(\\mathcal{E}, \\mathcal{F})$-measurable, if $f^{-1}(F) = \\left\\{ x \\in X : f(x) \\in F \\right\\}$ belongs to $\\mathcal{E}$ for all $F \\in \\mathcal{F}$.\nNote: A $\\mathcal{E}$-measurable function is equivalent to this definition in the case $(Y, \\mathcal{F}) = (\\mathbb{R}, \\mathcal{B}_{\\mathbb{R}})$.\nMeasures A measure on $\\mathcal{E}$ (or on $(X, \\mathcal{E})$, or simply on $X$ if $\\mathcal{E}$ is understood) is a function $\\mu : \\mathcal{E} \\to [0, \\infty]$ such that\nNull empty set: $\\mu (\\varnothing) = 0$. Countable additivity: If $\\left\\{ E_{j} \\right\\}$ is a sequence of disjoint sets in $\\mathcal{E}$, then $\\displaystyle \\mu \\left( \\bigcup\\limits_{j} E_{j} \\right) = \\sum\\limits_{j} \\mu (E_{j})$. A triple $(X, \\mathcal{E}, \\mu)$ is called a measure space and we shall be working on a fixed measure space $(X, \\mathcal{E}, \\mu)$.\nA Borel measure on $\\mathbb{R}$ is a measure whose domain is the Borel $\\sigma$-algebra $\\mathcal{B}_{\\mathbb{R}}$: $$ \\mu : \\mathcal{B}_{\\mathbb{R}} \\to [0, \\infty] $$\nFor two measures $\\mu$ and $\\nu$ on each $(X, \\mathcal{E})$ and $(Y, \\mathcal{F})$, measure $\\mu \\times \\nu$ is the product of $\\mu$ and $\\nu$ which is the unique measure on $\\mathcal{E} \\times \\mathcal{F}$ such that $\\mu \\times \\nu (E \\times F) = \\mu(E) \\nu(F)$ for all rectangles $E \\times F$.\nThe Integral A real-valued function $f$ is simple if it has only a finite number of values.\nA simple measurable function $\\varphi$ can be represented in the form $$ \\begin{equation} \\varphi = \\sum\\limits_{j=1}^{n} a_{j}\\chi_{E_{j}}, \\text{ where } E_{j} = \\varphi^{-1}(\\left\\{ a_{j} \\right\\}) \\text{ and } \\operatorname{range} (\\varphi) = \\left\\{ a_{1}, \\dots, a_{n} \\right\\}. \\end{equation} $$ where $\\chi_{E_{j}}$ is the characteristic function of $E_{j}$. We call this standard representation of $\\varphi$.\nIf $\\varphi$ simple measurable function with standard representation $(1)$, we define the integral of $\\varphi$ with respect to measure $\\mu$ by $$ \\int \\varphi d\\mu := \\sum\\limits_{j=1}^{n} a_{j}\\mu(E_{j}). $$ Notation: $$ \\int \\varphi d\\mu = \\int \\varphi = \\int \\varphi(x) d\\mu(x), \\qquad \\int = \\int_{X}. $$\nIf $f$ is measurable function on $(X, \\mathcal{E})$, we define the integral of $f$ with respect to $\\mu$ by $$ \\int f d\\mu := \\sup \\left\\{ \\int \\varphi d\\mu : 0 \\le \\varphi \\le f, \\varphi \\text{ is simple and measurable} \\right\\}. $$\nThe positive and negative parts of $f : X \\to \\mathbb{R}$ are defined repectively as $$ f^{+}(x) := \\max \\left( f(x), 0 \\right)),\\qquad f^{-1}(x) := \\min \\left(-f(x), 0 \\right)). $$ If $\\displaystyle \\int f^{+}$ and $\\displaystyle \\int f^{-}$ are both finite, then we say that $f$ is integrable. Also $\\left| f \\right| = f^{+} - f^{-}$.\nThe set of real-valued integrable functions is a vector space and the integral is a linear functional on it. This vector space is denoted as: $$ L = L(X, \\mathcal{E}, \\mu) = L(X, \\mu) = L(X) = L(\\mu), \\qquad L = L^{1} $$\n$L^{p}$ space For measure space $(X, \\mathcal{E}, \\mu)$ and $0 \\lt p \\lt \\infty$, we define $$ L^{p}(X, \\mathcal{E}, \\mu) := \\left\\{ f : X \\to \\mathbb{R} \\left| f \\text{ is measurable and } \\left( \\int \\left| f \\right|^{p} d\\mu \\right)^{1/p} \\lt \\infty \\right. \\right\\}. $$ $$ {} \\\\ {} \\\\ {} \\\\ $$\nProbability Theory Notation and Terminology $$ \\begin{array}{lll} \\text{Analysts\u0026rsquo; Term} \u0026amp;\u0026amp; \\text{Probabilists\u0026rsquo; Term} \\\\ \\hline \\text{Measure space } (X, \\mathcal{E}, \\mu) \\text{ such that } \\mu(X) = 1 \u0026amp;\u0026amp; \\text{Probability space } (\\Omega, \\mathcal{F}, P) \\\\ \\text{Measure } \\mu : \\mathcal{E} \\to \\mathbb{R} \\text{ such that } \\mu(X) = 1 \u0026amp;\u0026amp; \\text{Probability } P : \\mathcal{F} \\to \\mathbb{R} \\\\ (\\sigma\\text{-)algebra $\\mathcal{E}$ on $X$} \u0026amp;\u0026amp; (\\sigma\\text{-)field $\\mathcal{F}$ on $\\Omega$} \\\\ \\text{Mesurable set } E \\in \\mathcal{E} \u0026amp;\u0026amp; \\text{Event } E \\in \\mathcal{F} \\\\ \\text{Measurable real-valued function } f : X \\to \\mathbb{R} \u0026amp;\u0026amp; \\text{Random variable } X : \\Omega \\to \\mathbb{R} \\\\ \\text{Integral of } f, {\\displaystyle \\int f d\\mu} \u0026amp;\u0026amp; \\text{Expextation of } f, E(X) \\\\ f \\text{ is } L^{p} \u0026amp;\u0026amp; X \\text{ has finite $p$th moment} \\\\ \\text{Almost everywhere, a.e.} \u0026amp;\u0026amp; \\text{Almost surely, a.s.} \\end{array} $$\n$$ \\begin{align*} \\left\\{ X \\gt a \\right\\} \u0026amp;:= \\left\\{ w : X(w) \\gt a \\right\\} \\\\ P\\left( X \\gt a \\right) \u0026amp;:= P\\left( \\left\\{ w : X(w) \\gt a \\right\\} \\right) \\end{align*} $$\nBasic Definitions For measurable spacse $(\\Omega, \\mathcal{F})$ and $(\\mathbb{R}, \\mathcal{B}_{\\mathbb{R}})$, $(\\mathcal{F}, \\mathcal{B}_{\\mathbb{R}})$-mearsuable function $X : \\Omega \\to \\mathbb{R}$ is called random variable. Namely, $$ X^{-1}(B) \\in \\mathcal{F}\\qquad \\forall B \\in \\mathcal{B}_{\\mathbb{R}}. $$\nA probability (or probability measure) on $(\\Omega, \\mathcal{F})$ is measure $P : \\mathcal{F} \\to \\mathbb{R}$ such that $P(\\Omega) = 1$.\nIf $X$ is a random variable,\nexpectation: $\\displaystyle E(X) := \\int X dP$ variance: $\\sigma^{2}(X) := E\\left[ (X - E(X))^{2} \\right] = E(X^{2}) - E(X)^{2}$ The (probability) distribution of $X$ is a probability on $\\mathbb{R}$, $P_{X} : \\mathcal{B}_{\\mathbb{R}} \\to \\mathbb{R}$ such that $$ P_{X}(B) := P(X^{-1}(B)). $$\nThe distribution fuction of $X$ is defined as $$ F_{X}(a) := P_{X}\\left( (-\\infty, a] \\right) = P(X \\le a). $$\nFor any finite sequence of random variables $\\left\\{ X_{i} \\right\\}_{i=1}^{n}$, random vector $(X_{1}, \\dots, X_{n})$ is defined as a map from $\\Omega \\to \\mathbb{R}^{n}$: $$ (X_{1}, \\dots, X_{n})(x) := (X_{1}(x), \\dots, X_{n}(x)). $$ Note: $(X_{1}, \\dots, X_{n})^{-1}(B_{1} \\times \\cdots \\times B_{n})= X_{1}^{-1}(B_{1}) \\cap \\cdots \\cap X_{n}^{-1}(B_{n})$.\nFor $(X, Y) : \\Omega \\to \\mathbb{R}^{2}$, $$ (X, Y)^{-1} (a, b) = \\left\\{ x \\in \\Omega : X(x) = a \\right\\} \\cap \\left\\{ x \\in \\Omega : Y(x) = b \\right\\}. $$ Thus, for all Borel sets $B_{1}$ and $B_{2} \\in \\mathcal{B}_{\\mathbb{R}}$ we have $$ (X, Y)^{-1}(B_{1} \\times B_{2}) = (X, Y)^{-1}(B_{1}, B_{2}) = X^{-1}(B_{1}) \\cap Y^{-1}(B_{2}) $$ and extending to $\\mathbb{R}^{n}$ we obtain $$ \\begin{equation} \\begin{aligned} (X_{1}, \\dots, X_{n})^{-1}(B_{1} \\times \\cdots \\times B_{n}) \u0026amp;= (X_{1}, \\dots, X_{n})^{-1}(B_{1}, \\dots, B_{n}) \\\\ \u0026amp;= X_{1}^{-1}(B_{1}) \\cap \\cdots \\cap X_{n}^{-1}(B_{n}). \\end{aligned} \\end{equation} $$\nThe joint distribution of $X_{1}, \\dots, X_{n}$ is a probability distribution of $(X_{1}, \\dots, X_{n})$: $$ P_{(X_{1}, \\dots, X_{n})} : \\mathcal{B}_{\\mathbb{R}^{n}} \\to \\mathbb{R}, $$ $$ P_{(X_{1}, \\dots, X_{n})}(B_{1} \\times \\cdots \\times B_{n}) := P\\left( (X_{1}, \\dots, X_{n})^{-1}(B_{1} \\times \\cdots \\times B_{n}) \\right). $$\nIndependency For an event $E$ such that $P(E) \\gt 0$, a probability on $\\Omega$ $$ P_{E}(F) = P(E|F) := P(E \\cap F)/P(E) $$ is called conditional probability on $E$.\nIf $P_{E}(F) = P(F)$, then $F$ is said to be independent of $E$: $$ \\text{$F$ is independent of $E$} \\iff P(E \\cap F) = P(E)P(F). $$ A collection $\\left\\{ E_{j} \\right\\}$ of events in $\\Omega$ is indepencent if $$ P(E_{1} \\cap \\cdots \\cap E_{n}) = P(E_{1}) P(E_{2}) \\cdots P(E_{n}) = \\prod \\limits_{i=1}^{n} P(E_{j}) $$\nA collection $\\left\\{ X_{j} \\right\\}$ of random variables on $\\Omega$ is independent if the events $\\left\\{ X_{j}^{-1}(B_{j}) \\right\\}$ are independent for all Borel sets $B_{j} \\in \\mathcal{B}_{\\mathbb{R}}$, namely $$ P\\left(X_{1}^{-1}(B_{1}) \\cap \\cdots \\cap X_{n}^{-1}(B_{n})\\right) = \\prod \\limits_{j=1}^{n} P(X_{j}^{-1}(B_{j})). $$\nWe have from LHS by definition of distribution and $(2)$ $$ \\begin{align*} P\\left(X_{1}^{-1}(B_{1}) \\cap \\cdots \\cap X_{n}^{-1}(B_{n})\\right) \u0026amp;= P\\left( (X_{1}, \\dots, X_{n})^{-1}(B_{1} \\times \\cdots \\times B_{n}) \\right) \\\\ \u0026amp;= P_{(X_{1}, \\dots, X_{n})} \\left( B_{1} \\times \\cdots \\times B_{n} \\right). \\end{align*} $$ By the way, we have from RHS by definition of product measure and distribution $$ \\prod \\limits_{j=1}^{n} P(X_{j}^{-1}(B_{j})) = \\prod \\limits_{j=1}^{n} P_{X_{j}}(B_{j}) = \\left( \\prod \\limits_{j=1}^{n} P_{X_{j}} \\right) \\left( B_{1} \\times \\cdots \\times B_{n} \\right). $$ Therefore, if $\\left\\{ X_{j} \\right\\}$ are independent, then $$ P_{(X_{1}, \\dots, X_{n})} = \\prod\\limits_{j=1}^{n}P_{X_{j}}. $$\n$\\left\\{ X_{j} \\right\\}$ is an independent set of random variables if and only if the joint distribution of $\\left\\{ X_{j} \\right\\}$ is the product of their individual distributions.\nReferences Robert G. Bartle, The Elements of Integration and Lebesgue Measure (1995) Gerald B. Folland, Real Analysis: Modern Techniques and Their Applications (1999) ","id":3473,"permalink":"https://freshrimpsushi.github.io/en/posts/3473/","tags":null,"title":"Summary of Measure Theory and Probability Theory"},{"categories":"프로그래밍","contents":"Overview1 140+ CSS color palettes with names.\nCode ","id":3459,"permalink":"https://freshrimpsushi.github.io/en/posts/3459/","tags":null,"title":"CSS color name tags"},{"categories":"머신러닝","contents":"Overview1 $$ \\includegraphics[height=20em]{https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png} $$\nThe MNISTmodified national institute of standards and technology database refers to a dataset of digit handwriting from American high school students and Census Bureau employees. It is commonly known as [MNIST].\nOfficial Website Description This dataset is frequently used as an example for beginners in machine learning/deep learning. NIST originally collected handwritten data in the following format for the evaluation of character recognition technology for automated sorting of handwritten postal codes. Yann LeCun took this handwritten data from high school students and Census Bureau employees, processed it, and created the MNIST. The image size is 28 x 28, and it consists of 60,000 training sets and 10,000 test sets.\n$$ \\includegraphics[height=30em]{https://www.nist.gov/sites/default/files/styles/960_x_960_limit/public/images/2019/04/27/sd19.jpg?itok=oETq77cZ} $$\nHow to Use Julia In Julia, the MNIST dataset can be used with the machine learning dataset package MLDatasets.jl. By default, it loads the training set in Float32 type. There are options to change this. The available methods are as follows:\ndataset[i]: Returns a tuple of the i-th features and target. dataset[:]: Returns a tuple of all features and target. length(dataset): Returns the number of data. convert2image(dataset, i): Converts the i-th data into a grayscale image. The ImageShow.jl package is required. julia\u0026gt; using MLDatasets\rjulia\u0026gt; train = MNIST()\rdataset MNIST:\rmetadata =\u0026gt; Dict{String, Any} with 3 entries\rsplit =\u0026gt; :train\rfeatures =\u0026gt; 28×28×60000 Array{Float32, 3}\rtargets =\u0026gt; 60000-element Vector{Int64}\rjulia\u0026gt; test = MNIST(Float64, :test)\rdataset MNIST:\rmetadata =\u0026gt; Dict{String, Any} with 3 entries\rsplit =\u0026gt; :test\rfeatures =\u0026gt; 28×28×10000 Array{Float64, 3}\rtargets =\u0026gt; 10000-element Vector{Int64}\rjulia\u0026gt; length(train), length(test)\r(60000, 10000)\rjulia\u0026gt; using Plots\rjulia\u0026gt; using ImageShow\rjulia\u0026gt; train.targets[1]\r5\rjulia\u0026gt; heatmap(convert2image(train, 1)) Since the labels are given as integers, one-hot encoding needs to be done separately.\njulia\u0026gt; train.targets[1:5]\r5-element Vector{Int64}:\r5\r0\r4\r1\r9\rjulia\u0026gt; using Flux\rjulia\u0026gt; Flux.onehotbatch(train.targets[1:5], 0:9)\r10×5 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\r⋅ 1 ⋅ ⋅ ⋅\r⋅ ⋅ ⋅ 1 ⋅\r⋅ ⋅ ⋅ ⋅ ⋅\r⋅ ⋅ ⋅ ⋅ ⋅\r⋅ ⋅ 1 ⋅ ⋅\r1 ⋅ ⋅ ⋅ ⋅\r⋅ ⋅ ⋅ ⋅ ⋅\r⋅ ⋅ ⋅ ⋅ ⋅\r⋅ ⋅ ⋅ ⋅ ⋅\r⋅ ⋅ ⋅ ⋅ 1 How to do one-hot encoding in Julia Flux How to implement MLP and train MNIST in Julia Flux Environment OS: Windows11 Version: Julia v1.8.2, MLDatasets v0.7.6, Plots v1.36.1, ImageShow v0.3.6, Flux v0.13.7 Gun-Woo Kwon and Ryeong Heo, Learning AI through Night History and Comics 2, p68\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3444,"permalink":"https://freshrimpsushi.github.io/en/posts/3444/","tags":null,"title":"MNIST Database"},{"categories":"머신러닝","contents":"Definition 1 2 Input Space $X \\ne \\emptyset$ is the domain and the codomain is the set of complex numbers $\\mathbb{C}$, and let\u0026rsquo;s denote the space of functions $\\left( H , \\left\u0026lt; \\cdot , \\cdot \\right\u0026gt; \\right) \\subset \\mathbb{C}^{X}$ composed of mappings $f: X \\to \\mathbb{C}$ as a Hilbert space.\nReproducing Kernel Hilbert Space For a fixed datum $x \\in X$, the functional $\\delta_{x} : H \\to \\mathbb{C}$, which takes a function $f \\in H$ and returns its value at $x$, is called the (Dirac) Evaluation Functional at $x$. $$ \\delta_{x} (f) := f (x) $$ If the evaluation functional $\\delta_{x}$ is continuous for all $x \\in X$, then $H$ is called a Reproducing Kernel Hilbert Space (RKHS) and is sometimes denoted as $H_{k}$. A function $k : X \\times X \\to \\mathbb{C}$ is called the reproducing kernel of $H$ if it satisfies the following two conditions: (i) Representer: For all $x \\in X$, $$ k \\left( \\cdot , x \\right) \\in H $$ (ii) Reproducing Property: For all $x \\in X$ and all $f \\ in H$, $$ \\left\u0026lt; f , k \\left( \\cdot , x \\right) \\right\u0026gt; = f(x) = \\delta_{x} (f) $$ Especially, for all $x_{1} , x_{2} \\in X$, the following holds: $$ k \\left( x_{1} , x_{2} \\right) = \\left\u0026lt; k \\left( \\cdot , x_{2} \\right), k \\left( \\cdot , x_{1} \\right) \\right\u0026gt; $$ Positive Definite Kernel Let\u0026rsquo;s call a mapping $\\phi : X \\to H$ from the input space $X \\ne \\emptyset$ to the Hilbert space $\\left( H , \\left\u0026lt; \\cdot , \\cdot \\right\u0026gt; \\right)$ a feature map. In this context, $H$ is also referred to as the feature space. A function $k : X \\times X \\to \\mathbb{C}$ defined by the inner product $\\left\u0026lt; \\cdot , \\cdot \\right\u0026gt; : H \\times H \\to \\mathbb{C}$ in $\\left( H , \\left\u0026lt; \\cdot , \\cdot \\right\u0026gt; \\right)$ is called a kernel. $$ k \\left( x_{1} , x_{2} \\right) := \\left\u0026lt; \\phi \\left( x_{1} \\right) , \\phi \\left( x_{2} \\right) \\right\u0026gt; $$ For $m$ data points $\\left\\{ x_{1} , \\cdots , x_{m} \\right\\} \\subset X$, the matrix $K \\in \\mathbb{C}^{m \\times m}$ formed as follows is called the Gram Matrix of the kernel $k$. $$ K := \\left( k \\left( x_{i} , x_{j} \\right) \\right)_{ij} $$ If the Gram Matrix of $k$ is a positive definite matrix, then $k$ is called a positive definite kernel. In other words, a kernel $k$ whose Gram Matrix satisfies the following for all $\\left\\{ c_{1} , \\cdots , c_{m} \\right\\} \\subset \\mathbb{C}$ is a positive definite kernel. $$ \\sum_{i=1}^{m} \\sum_{j=1}^{m} c_{i} \\bar{c_{j}} K_{ij} \\ge 0 $$ Explanation Although the content is complex, let\u0026rsquo;s read it carefully as it\u0026rsquo;s been simplified as much as possible.\nThe Meaning of Hilbert Space in Data Science A Hilbert space is a complete space where an inner product is defined. In mathematics, an inner product is simply a bi-variable scalar function that satisfies certain conditions, but in machine learning, it can be thought of as a measure of similarity. In fact, the cosine similarity used to compare word frequencies between two documents also uses an inner product, and another naive example is when we have three vectors $$ A := \\left( 3, 0, 1 \\right) \\\\ B := \\left( 4, 1, 0 \\right) \\\\ C := \\left( 0, 2, 5 \\right) $$ it\u0026rsquo;s evident that $A$ and $B$ are similar, and both are different from $C$. Although this is still an intuitive inference, quantifying it through inner product yields: $$ A \\cdot B = 12 + 0 + 0 = 12 \\\\ A \\cdot C = 0 + 0 + 5 = 5 \\\\ B \\cdot C = 0 + 2 + 0 = 2 $$ This simple comparison of the absolute values of inner products explains the data better than just \u0026lsquo;it\u0026rsquo;s obvious\u0026rsquo;.\nNote that there are no specific assumptions about the input space $X$. In real applications, we cannot guarantee what kind of bad data we will handle. For example, if $X$ represents photos or document data, it does not make sense to take inner products of photos or documents.\nQ. If $X$ is a set of black and white photos, can\u0026rsquo;t we just consider the photos as matrices and take inner products based on pixel values? A. That would work, and that\u0026rsquo;s exactly what a feature map $\\phi : X \\to H$ does. In this case, $H$ becomes a space of functions defined on a rectangle $[a,b] \\times [c,d]$. Thinking in this way, the existence of a kernel itself is almost like bringing \u0026lsquo;difficult to handle data\u0026rsquo; into a space we are familiar with. Even if the meaning of inner products mentioned above doesn\u0026rsquo;t make sense, since an inner product space is a norm space and a metric space, most assumptions we consider necessary logically hold. An inner product $\\left\u0026lt; \\cdot , \\cdot \\right\u0026gt;$ induces a norm $$ \\left\\| f \\right\\| := \\sqrt{ \\left\u0026lt; f , f \\right\u0026gt; } $$ and a norm $\\left\\| f \\right\\|$ induces a metric $$ d (f,g) = \\left\\| f -g \\right\\| $$\nFrom a data science perspective, a norm itself quantifies data. For example, if we define the norm of a black and white photo as the sum of all pixel values, this alone can roughly evaluate how bright or dark the photo is. From a data science perspective, a distance tells us how different two data points are. Distinguishing between right and wrong, similar and different, is undoubtedly important. Apart from these reasons, sometimes in mathematical derivations, inner products become necessary. This post won\u0026rsquo;t cover all related examples as it would become too cluttered. Refer to the \u0026lsquo;Kernel Trick\u0026rsquo; section of the \u0026lsquo;Support Vector Machine\u0026rsquo; post.\nWhy a Function Space? Does it Have to be This Complicated? Most applications of mathematics involve finding \u0026rsquo;the function we want\u0026rsquo;.\nInterpolation finds a polynomial function that fills in between given data points. Statistical regression analysis is a technique for finding a line that best explains the data, which is a linear function. Deep learning approximates non-linear functions by incorporating activation functions because linear functions alone are insufficient. Fourier transform represents a function as a linear combination of trigonometric functions. There are countless examples like these. Returning to machine learning, the reason we consider function spaces is that ultimately, what we are looking for is a function. Even if it\u0026rsquo;s not explicitly stated, we want a function that returns the desired result for a given input. For example, a function that returns the number on a photo of a digit, or one that calculates the probability of loan repayment based on personal information. Such useful functions are unlikely to be simple, and we hope they can be represented as a sum of finitely many $\\phi_{k} (x) (\\cdot)$, which serve as bases. In particular, for $\\phi (x) = k (\\cdot , x)$, the proposition that some function $f$ can be found is precisely the Representer Theorem.\nRepresenter Theorem: In a Reproducing Kernel Hilbert Space, any function fitted to the training data can be represented as a finite linear combination of representers.\nIn summary, in machine learning (especially in the context of Support Vector Machines), what we seek is ultimately a function, so exploring the function space where they reside is inevitable.\nWhy is Dirac\u0026rsquo;s Name in Front of the Evaluation Functional? $$ \\delta_{x_{0}} (x) = \\begin{cases} 1 \u0026amp; , \\text{if } x = x_{0} \\\\ 0 \u0026amp; , \\text{if } x \\ne x_{0} \\end{cases} $$ Originally, the Dirac delta function is known as a function that only has a value at one point. Regardless of its precise definition and usage, its variations are typically named after Dirac if they have a non-zero value at only one point. To aid understanding, imagine two functions $f : \\mathbb{R} \\to \\mathbb{R}$, $\\delta_{x_{0}} : \\mathbb{R} \\to \\mathbb{R}$, and their inner product as $$ \\left\u0026lt; f, \\delta_{x_{0}} \\right\u0026gt; = \\sum_{x \\in \\mathbb{R}} f (x) \\delta_{x_{0}} (x) = f \\left( x_{0} \\right) $$ Though we normally use integration instead of summation for the inner product of functions, and summing over all $x \\in \\mathbb{R}$ is risky, the concept aligns with the idea.\nIn this sense, $\\delta_{x_{0}} (f)$ straightforwardly yields $f \\left( x_{0} \\right)$, \u0026lsquo;obtaining a single point\u0026rsquo; at $x_{0}$, hiding the aforementioned discussion.\nWhy it\u0026rsquo;s Called Reproducing Property The definition of RKHS is quite interesting. Usually, when we say \u0026lsquo;some space\u0026rsquo; in mathematics, we define it as the space where \u0026lsquo;some\u0026rsquo; exists, but RKHS is defined as a Hilbert space where \u0026rsquo;the evaluation functional is continuous at every point\u0026rsquo;, which seems out of the blue.\nRiesz Representation Theorem: Let $\\left( H, \\left\\langle \\cdot,\\cdot \\right\\rangle \\right)$ be a Hilbert space. For a linear functional $f \\in H^{ \\ast }$ and $\\mathbf{x} \\in H$, there exists a unique $\\mathbf{w} \\in H$ such that $f ( \\mathbf{x} ) = \\left\\langle \\mathbf{x} , \\mathbf{w} \\right\\rangle$ and $\\| f \\|_{H^{\\ast}} = \\| \\mathbf{w} \\|_{H}$.\nMoore-Aronszajn Theorem: If a positive definite kernel exists, then a unique RKHS corresponding to it also exists.\nAccording to this definition, the existence of a reproducing kernel in RKHS is not self-evident and requires proof. In fact, the Riesz Representation Theorem guarantees the unique existence of a reproducing kernel in RKHS. Interestingly, conversely, an RKHS corresponding to a reproducing kernel also uniquely exists.\nLet\u0026rsquo;s delve into the formulas in the definition.\nOriginally, the function $k : X \\times X \\to \\mathbb{C}$ could take $x_{1}, x_{2} \\in X$, but if we fix $x$ like in the definition, $k$ essentially becomes $k : y \\mapsto k (y,x)$, a function $k : X \\to \\mathbb{C}$. By blocking one input, it\u0026rsquo;s like $$ \\left\u0026lt; f , k \\left( \\cdot , x \\right) \\right\u0026gt; = f(x) $$ This expression is simply the inner product of two functions $f (\\cdot) : X \\to \\mathbb{C}$ and $k \\left( \\cdot , x \\right): X \\to \\mathbb{C}$. There\u0026rsquo;s no need to overcomplicate thinking, \u0026ldquo;How does $f$ come out and how does the inner product with $x$\u0026hellip;\u0026rdquo; It\u0026rsquo;s unnecessary. Since $f(x) \\in \\mathbb{C}$ is also just a result of the inner product, it\u0026rsquo;s just some complex number, the codomain being the set of complex numbers.\nHere, let\u0026rsquo;s discuss the naming of the reproducing property. The word Reproduction inherently carries the meaning of Re-(again, 再) -produce (create, 生), with its first translation being reproduction/generation, second being copying/duplication, and third being reproduction. Reproduction in the sense of breeding doesn\u0026rsquo;t fit, and copying doesn\u0026rsquo;t seem right as there\u0026rsquo;s no original to speak of.\nHowever, if we consider that inner-producting $f(\\cdot)$ and $k (\\cdot, x)$ to get $f(x)$ is \u0026lsquo;reproducing\u0026rsquo; the information contained in $f$ through the kernel, then wouldn\u0026rsquo;t it make sense? Imagine we have a function $y(t)$ dependent on time $t$, representing a YouTube video. We don\u0026rsquo;t see $y$ itself but the reproduction of $\\left\\{ y(t) : t \\in [0,T] \\right\\}$. In this analogy, the kernel $k$ \u0026lsquo;reproduces\u0026rsquo; the function values from $f$, not as the function itself but as its values, justifying the term \u0026lsquo;reproducing kernel\u0026rsquo;.\nFeature Map and Uncomfortable Notation Looking closely at the definitions of kernel and reproducing kernel, we notice that they don\u0026rsquo;t necessarily need each other for their definitions. A kernel is a kernel, and a reproducing kernel is a reproducing kernel, and they become the same when the feature map is also the representer, i.e., $$ \\phi (x) = k \\left( \\cdot , x \\right) $$ A feature map transforms original data into a form that\u0026rsquo;s easier for us to handle,\nand saying that a function is represented by such functions means it\u0026rsquo;s explained by certain features derived from the data. One issue is that even if one intuitively understands up to this point, the notation like $k \\left( \\cdot , x \\right)$ remains uncomfortable, and it\u0026rsquo;s hard to empathize with the motive behind defining kernels separately from their inner products and feature maps.\nSince a feature map is $\\phi : X \\to H$, its function value for $x \\in X$ is some function $\\lambda : X \\to \\mathbb{C}$, which usually isn\u0026rsquo;t confusing. More precisely, $\\phi(x)$ can be written as $$ \\left( \\phi (x) \\right) (\\cdot) = k \\left( \\cdot , x \\right) $$ Then why use such inconvenient notation with the dot $\\cdot$? Most people find it easier to understand with examples where not using such notation would cause more trouble. As mentioned earlier, whether it\u0026rsquo;s a kernel or a reproducing kernel, the space we consistently care about is the function space $H$, and the inner product in $H$ is between functions. First, let\u0026rsquo;s assume a function $f$ is represented by a linear combination of data representers $\\phi \\left( x_{i} \\right)$: $$ f (y) = \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) (y) = \\sum_{i=1}^{m} \\alpha_{i} \\left( \\phi \\left( x_{i} \\right) \\right) (y) $$ This already looks messy. Considering another function $g$ and different data $\\left\\{ x'_{j} \\right\\}_{j=1}^{n}$, we get $$ g (y) = \\sum_{j=1}^{n} \\beta_{j} \\left( \\phi \\left( x'_{j} \\right) \\right) (y) $$ Moreover, if we\u0026rsquo;re not using inner products, there\u0026rsquo;s no point in considering an inner product space. Writing down $\\left\u0026lt; f,g \\right\u0026gt;$ gives us $$ \\left\u0026lt; f,g \\right\u0026gt; = \\sum_{i=1}^{m} \\sum_{j=1}^{n} \\bar{\\alpha_{i}} \\beta_{j} \\left\u0026lt; \\phi \\left( x_{i} \\right) , \\phi \\left( x'_{j} \\right) \\right\u0026gt; $$ This is unnecessarily complicated. Before taking the inner product, we hardly need to deal with actual $y \\in X$ in the function space, and after taking the inner product, there\u0026rsquo;s no need to keep writing $\\phi$ and the inner product. Seeing this, the notation $$ f (\\cdot) = \\sum_{i=1}^{m} \\alpha_{i} k \\left( \\cdot , x_{i} \\right) \\\\ g (\\cdot) = \\sum_{j=1}^{n} \\beta_{j} k \\left( \\cdot , x'_{j} \\right) \\\\ \\left\u0026lt; f,g \\right\u0026gt; = \\sum_{i=1}^{m} \\sum_{j=1}^{n} \\bar{\\alpha_{i}} \\beta_{j} k \\left( x_{i} , x'_{j} \\right) $$ might not seem as cumbersome.\nReproducing Kernels are Positive Definite Given data $\\left\\{ x_{k} \\right\\}_{k=1}^{m}$, if $k$ is a kernel, then the following holds: $$ \\begin{align*} \u0026amp; \\sum_{i=1}^{m} \\sum_{j=1}^{m} \\bar{\\alpha_{i}} \\alpha_{j} k \\left( x_{i} , x_{j} \\right) \\\\ =\u0026amp; \\sum_{i=1}^{m} \\sum_{j=1}^{m} \\left\u0026lt; \\alpha_{i} \\phi \\left( x_{i} \\right) , \\alpha_{j} \\phi \\left( x_{j} \\right) \\right\u0026gt; \\\\ =\u0026amp; \\left\u0026lt; \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) , \\sum_{j=1}^{m} \\alpha_{j} \\phi \\left( x_{j} \\right) \\right\u0026gt; \\\\ =\u0026amp; \\left\\| \\sum_{i=1}^{m} \\alpha_{i} \\phi \\left( x_{i} \\right) \\right\\|^{2} \\\\ \\ge \u0026amp; 0 \\end{align*} $$ As mentioned earlier, if we consider $\\phi : x \\mapsto k (\\cdot , x)$, the reproducing kernel $k$ is also a kernel and thus positive definite. This positive definiteness of kernels naturally appears in various properties related to kernels.\nKernels Outside of Functional Analysis (1) In general mathematics, a kernel often refers to the abstract algebra kernel $\\ker$. For a structure $Y$ where $0$ is defined, the kernel $\\ker f$ of a function $f : X \\to Y$ is defined as $\\ker f := f^{-1} \\left( \\left\\{ 0 \\right\\} \\right)$. (2) This concept is specialized in linear algebra as the kernel of a linear transformation. If you ask someone who isn\u0026rsquo;t specialized in functional analysis about kernels, nine out of ten times, they\u0026rsquo;ll think of meaning (1). If your background is in mathematics, you should at least know about (1), and even if not, you should be familiar with (2).\nNamed Kernels In the context of machine learning, the following kernels are known. 3 These might not seem like kernels at first glance, but they can be derived from the fact that the sum and product of kernels remain kernels.\nLinear Kernel: $$ k \\left( x_{1} , x_{2} \\right) = \\left\u0026lt; x_{1} , x_{2} \\right\u0026gt; $$ Polynomial Kernel: For $c \\ge 0$ and $d \\in \\mathbb{N}$, $$ k \\left( x_{1} , x_{2} \\right) = \\left( \\left\u0026lt; x_{1} , x_{2} \\right\u0026gt; + c \\right) ^{d} $$ Gaussian Kernel: For $\\sigma^{2} \u0026gt; 0$, $$ k \\left( x_{1} , x_{2} \\right) = \\exp \\left( - {{ \\left\\| x_{1} - x_{2} \\right\\| } \\over { 2 \\sigma^{2} }} \\right) $$ Sigmoid Kernel: For $w, b \\in \\mathbb{C}$, $$ k \\left( x_{1} , x_{2} \\right) = \\tanh \\left( w \\left\u0026lt; x_{1} , x_{2} \\right\u0026gt; + b \\right) $$ Sejdinovic, Gretton. (2014). What is an RKHS?: p7~11. http://www.stats.ox.ac.uk/~sejdinov/teaching/atml14/Theory_2014.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSchölkopf. (2001). A Generalized Representer Theorem. https://link.springer.com/chapter/10.1007/3-540-44581-1_27\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJakkula. (2006). Tutorial on Support Vector Machine (SVM). https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2406,"permalink":"https://freshrimpsushi.github.io/en/posts/2406/","tags":null,"title":"Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning"},{"categories":"위상데이터분석","contents":"Overview Without considering the geometric meaning, if we just define it plainly, in Algebraic Topology, the Betti Number is merely the rank of the homology group in a chain complex. The problem is that such an explanation does not help those curious about the meaning of Betti numbers, and it\u0026rsquo;s also difficult to learn through examples because the specific calculation is daunting.\nIn this post, we introduce a theorem that answers at least the second question—how to calculate Betti numbers—with its detailed proof. According to the theorem introduced below, a certain matrix can be found according to the given chain complex, and through a series of calculations, the following explicit formula can be derived. $$ \\beta_{p} = \\rank ?_{1} - \\rank ?_{2} $$\nAlthough the best explanation for mathematical content is to convey it without using mathematics, in the case of Betti numbers, one can realize its fundamental principles through the process of deriving the formula. The proof may be quite difficult for undergraduates to follow, but it is written in detail without omissions, so it is recommended to at least give it a try.\nTheorem Definition of Homology Group:\nLet\u0026rsquo;s say $n \\in \\mathbb{N}_{0}$. Chain $$ \\cdots \\longrightarrow C_{n+1} \\overset{\\partial_{n+1}}{\\longrightarrow} C_{n} \\overset{\\partial_{n}}{\\longrightarrow} C_{n-1} \\longrightarrow \\cdots \\longrightarrow C_{1} \\overset{\\partial_{1}}{\\longrightarrow} C_{0} \\overset{\\partial_{0}}{\\longrightarrow} 0 $$ If it satisfies $$ \\partial_{n} \\circ \\partial_{n+1} = 0 $$ for all $n$, then $\\mathcal{C} := \\left\\{ \\left( C_{n}, \\partial_{n} \\right) \\right\\}_{n=0}^{\\infty}$ is called a Chain Complex. The Quotient Group $H_{n} := \\ker \\partial_{n} / \\text{Im} \\partial_{n+1}$ is called the $n$-th Homology Group of $\\mathcal{C}$. Homomorphism $\\partial_{n} : C_{n} \\longrightarrow C_{n-1}$ is called a Boundary or Differential Operator. Elements of $Z_{n} := \\ker \\partial_{n}$ are called $n$-Cycles, and elements of $B_{n} := \\text{Im} \\partial_{n+1}$ are called $n$-Boundaries. Standard Basis Decomposition of Free Chain Complexes Assuming that all $C_{p}$ of the Chain Complex $\\mathcal{C} := \\left\\{ \\left( C_{p}, \\partial_{p} \\right) \\right\\}$ are Free Groups with Finite Rank, there exist Subgroups $U_{p}, V_{p}, W_{p} \\subset C_{p}$ and for all $p$ and $Z_{p} := \\ker \\partial_{p}$ that satisfy the following. $$ \\begin{align*} C_{p} =\u0026amp; U_{p} \\oplus V_{p} \\oplus W_{p} \\\\ =\u0026amp; U_{p} \\oplus Z_{p} \\end{align*} $$ $$ \\begin{align*} \\partial_{p} \\left( U_{p} \\right) \\subset \u0026amp; W_{p} \\\\ Z_{p} =\u0026amp; V_{p} \\oplus W_{p} \\end{align*} $$ Of course, $Z_{p}$ is the Kernel of $\\partial_{p}$, so $\\partial_{p} \\left( V_{p} \\right) = 0$ and $\\partial_{p} \\left( W_{p} \\right) = 0$. Furthermore, the Restriction Function ${\\partial_{p}}_{| U_{p}} : U_{p} \\to W_{p-1}$ from $U_{p}$ to $\\partial_{p}$ has the following Smith Normal Form. $$ \\begin{bmatrix} b_{1} \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; \\cdots \u0026amp; b_{l} \\end{bmatrix} $$ Here, $b_{i} \\in \\mathbb{N}$ and $b_{1} \\mid \\cdots \\mid b_{l}$.\nEfficient Computability of Homology Groups 1 The Betti Number of $H_{p} \\left( \\mathcal{C} \\right)$ is called the $p$-th Betti Number of $\\mathcal{C}$. The $\\beta_{p}$ of a finite Complex $K$ is as follows. $$ \\beta_{p} = \\rank Z_{p} - \\rank B_{p} $$ Its specific values can be calculated by the Smith Normal Form of $\\partial_{p}$ as follows. In the diagram, the blue dotted line represents the diagonal components where $1$, the orange solid line represents the diagonal components where $1$ is not $0$, and all other components are $0$. 2\nWhat is important here is the number $\\rank B_{p-1}$ of $1$ in the Smith Normal Form, and the number of zero columns $\\rank Z_{p}$.\nProof 3 Part 1. $B_{p} \\subset W_{p} \\subset Z_{p} \\subset C_{p}$\nLet\u0026rsquo;s say $$ \\begin{align*} Z_{p} :=\u0026amp; \\ker \\partial_{p} \\\\ B_{p} :=\u0026amp; \\text{Im} \\partial_{p+1} \\\\ W_{p} :=\u0026amp; \\left\\{ c_{p} \\in C_{p} : \\lambda c_{p} \\in B_{p} , \\forall m \\ne 0 \\right\\} \\end{align*} $$. In particular, $W_{p}$ becomes a Subgroup of $C_{p}$, and considering only $\\lambda = 1$, it weakens the condition of the Boundary $B_{p}$, so it is called a Weak Boundary.\nFrom the definition of $W_{p}$, if we consider $\\lambda \\ne 1$ $$ B_{p} \\subset W_{p} $$ From the definition of $Z_{p}$, since $\\forall z_{p} \\in Z_{p}$ is $\\partial_{p} z_{p} = 0$ and $Z_{p} = \\ker \\partial_{p}$ is $\\partial_{p} : C_{p} \\to C_{p-1}$ $$ Z_{p} \\subset C_{p} $$ Since $C_{p}$ is assumed to be a Free Group, it is Torsion-Free, meaning there does not exist $\\lambda \\ne 0$ that satisfies $\\lambda z_{p} = 0$ for any $\\forall z_{p} \\in Z_{p} \\subset C_{p}$. Meanwhile, for all $c_{p+1} \\in C_{p+1}$ $$ \\partial_{p+1} c_{p+1} = \\lambda z_{p} \\in W_{p} $$ If we apply $\\partial_{p}$ to both sides, $$ 0 = \\partial_{p} \\partial_{p+1} c_{p+1} = \\partial_{p} \\lambda z_{p} = \\lambda \\partial_{p} z_{p} $$ so $\\partial_{p} z_{p} = 0$ must hold. This means if $\\lambda z_{p} \\in W_{p}$ then $\\lambda z_{p} \\in Z_{p}$, $$ W_{p} \\subset Z_{p} $$ From such considerations, we obtain the following inclusion relationships. $$ B_{p} \\subset W_{p} \\subset Z_{p} \\subset C_{p} $$\nPart 2. $W_{p} \\subset Z_{p}$ is a Direct Summand of $Z_{p}$\nFrom the definition of the $p$-th Homology Group $H_{p} \\left( \\mathcal{C} \\right) = Z_{p} / B_{p}$ $$ \\text{proj}_{1} : Z_{p} \\to H_{p} \\left( \\mathcal{C} \\right) $$ is a Projection with a rank reduced by as much as the Coset $B_{p}$, and For the Torsion Subgroup $T_{p} \\left( \\mathcal{C} \\right) \\subset H_{p} \\left( \\mathcal{C} \\right)$ of $H_{p} \\left( \\mathcal{C} \\right)$ $$ \\text{proj}_{2} : H_{p} \\left( \\mathcal{C} \\right) \\to H_{p} \\left( \\mathcal{C} \\right) / T_{p} \\left( \\mathcal{C} \\right) $$ is also a projection. First Isomorphism Theorem: If a Homomorphism $\\phi : G \\to G'$ exists, then $$G / \\ker ( \\phi ) \\simeq \\phi (G)$$\nTherefore, defined as $\\text{proj} := \\text{proj}_{1} \\circ \\text{proj}_{2}$ $$ \\text{proj} : Z_{p} \\to H_{p} \\left( \\mathcal{C} \\right) / T_{p} \\left( \\mathcal{C} \\right) $$ is also a projection. Elements of $W_{p}$ are expressed as $\\partial_{p+1} d_{p+1}$, so the kernel of this projection $\\text{proj}$ is $W_{p}$, and since every projection is a Surjection, according to the First Isomorphism Theorem, $$ Z_{p} / W_{p} \\simeq H_{p} / T_{p} $$ holds. Here, regardless of how the right side of $H_{p}$ is formed, it\u0026rsquo;s reduced by the Torsion Subgroup $T_{p}$, so it\u0026rsquo;s torsion-free, thereby ensuring that the left side $Z_{p} / W_{p}$ is also torsion-free. Therefore, if $\\alpha_{1} , \\cdots , \\alpha_{k}$ is the basis of $Z_{p} / W_{p}$, and $\\alpha'_{1} , \\cdots , \\alpha'_{l} \\in W_{p}$ is the basis of $W_{p}$, then $\\alpha_{1} , \\cdots , \\alpha_{k}, \\alpha'_{1} , \\cdots , \\alpha'_{l}$ becomes the basis of $Z_{p}$. Thus, $Z_{p}$ can be expressed as a direct sum of the Subgroup $V_{p}$ with the basis $\\alpha_{1} , \\cdots , \\alpha_{k}$ and $W_{p}$.\nPart 3. Basis of $Z_{p}, B_{p-1}, W_{p-1}$\nHomomorphism\u0026rsquo;s Smith Normal Form: If the ranks of free Abelian groups $G$ and $G'$ are $n,m$ and $f : G \\to G'$, respectively, and $g$ is a homomorphism, then there exists a homomorphism $g$ with the following matrix. $$ \\begin{bmatrix} d_{1} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\ddots \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; d_{r} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\end{bmatrix} \\in \\mathbb{Z}^{m \\times n} $$ Here, $d_{1} , \\cdots, d_{r} \\in \\mathbb{N}$ and $d_{1} \\mid \\cdots \\mid d_{r}$, meaning $d_{k}$ must be a divisor of $d_{k+1}$.\n$\\partial_{p} : C_{p} \\to C_{p-1}$ has the following Smith Normal Form of the matrix $m \\times n$.\n$$ \\begin{matrix} \u0026amp; \\begin{matrix} e_{1} \u0026amp; \\cdots \u0026amp; e_{l} \u0026amp; e_{l} \u0026amp; \\cdots \u0026amp; e_{n} \\end{matrix} \\\\ \\begin{matrix} e'_{1} \\\\ \\vdots \\\\ e'_{l} \\\\ e'_{l} \\\\ \\vdots \\\\ e'_{m} \\end{matrix} \u0026amp; \\begin{bmatrix} d_{1} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\ddots \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; d_{r} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\end{bmatrix} \\end{matrix} $$\nHere, we will directly show the following three things:\n(1): $e_{l+1} , \\cdots , e_{n}$ is the basis of $Z_{p}$. (2): $b_{1} e'_{1} , \\cdots , b_{l} e'_{l}$ is the basis of $B_{p-1}$. (3): $e'_{1} , \\cdots , e'_{l}$ is the basis of $W_{p-1}$. Sub-proof\nAccording to the definition of $\\partial_{p}$, for a general $c_{p} \\in C_{p}$, the following holds. $$ c_{p} = \\sum_{i=1}^{n} a_{i} e_{i} \\implies \\partial_{p} c_{p} = \\sum_{i=1}^{l} a_{i} b_{i} e'_{i} $$ (1): Since $b_{i} \\ne 0$, the necessary and sufficient condition for $Z_{p} = \\ker \\partial_{p}$ is for $a_{i} = 0$ for any $i = 1 \\cdots , l$. Therefore, $e_{l+1} , \\cdots , e_{n}$ is the basis of $Z_{p}$. (2): Every $\\partial_{p} c_{p} \\in B_{p-1}$ can be expressed as a Linear Combination of $b_{1} e'_{1} , \\cdots , b_{l} e'_{l}$, and since $b_{i} \\ne 0$, $b_{1} e'_{1} , \\cdots , b_{l} e'_{l}$ is the basis of $B_{p-1}$. (3): Since $b_{i} e'_{i} = \\partial e_{i}$, first of all, $e'_{1}, \\cdots, e'_{l} \\in W_{p-1}$. Conversely, if we set $c_{p-1} \\in C_{p-1}$ as $$ c_{p-1} = \\sum_{i=1}^{m} d_{i} e'_{i} $$ and assume $c_{p-1} \\in W_{p-1}$, then since $W_{p-1}$ was defined as $W_{p-1} = \\left\\{ c_{p} \\in C_{p} : \\lambda c_{p} \\in B_{p} , \\forall m \\ne 0 \\right\\}$, $c_{p-1}$ can be expressed in the form of $$ \\lambda c_{p-1} = \\partial c_{p} = \\sum_{i=1}^{l} a_{i} b_{i} e'_{i} $$ for some $\\lambda \\ne 0$. Comparing coefficients, for $i \u0026gt; l$, we obtain $$ \\lambda d_{i} = 0 \\implies d_{i} = 0 $$ Therefore, $e'_{1} , \\cdots , e'_{l}$ is the basis of $W_{p-1}$. Part 4. Proof of \u0026lsquo;Standard Basis Decomposition of Free Chain Complexes\u0026rsquo;\nFor $C_{p}$ and $C_{p-1}$, if we consider the Free Group generated by $e_{1} , \\cdots , e_{l}$ appearing in the discussion so far as $U_{p}$, then since $Z_{p} = V_{p} \\oplus W_{p}$, we obtain $$ \\begin{align*} C_{p} =\u0026amp; U_{p} \\oplus Z_{p} \\\\ =\u0026amp; U_{p} \\oplus \\left( V_{p} \\oplus W_{p} \\right) \\end{align*} $$ as $\\partial V_{p} = \\partial W_{p} = 0$. Here, note that $W_{p}$ and $Z_{p}$ are unique according to $C_{p}$, but $U_{p}$ and $V_{p}$ do not necessarily have to be unique.\nPart 5. Proof of \u0026lsquo;Efficient Computability of Homology Groups\u0026rsquo;\nAccording to Part 4, for the Complex $K$, the following decomposition is guaranteed to exist. $$ \\begin{align*} C_{p} \\left( K \\right) =\u0026amp; U_{p} \\oplus V_{p} \\oplus W_{p} \\\\ Z_{p} =\u0026amp; V_{p} \\oplus W_{p} \\end{align*} $$\nProperties of Direct Sum: Let\u0026rsquo;s say $G = G_{1} \\oplus G_{2}$. If $H_{1}$ is a subgroup of $G_{1}$ and $H_{2}$ is a subgroup of $G_{2}$, then $H_{1}$ and $H_{2}$ can also be expressed as a direct sum, especially the following holds. $${{ G } \\over { H_{1} \\oplus H_{2} }} \\simeq {{ G_{1} } \\over { H_{1} }} \\oplus {{ G_{2} } \\over { H_{2} }}$$\n[1]: If we say $H_{1} \\simeq G_{1}$ and $H_{2} \\simeq \\left\\{ 0 \\right\\}$, then $$ G / G_{1} \\simeq G_{2} $$ [2]: If we say $H_{1} \\simeq \\left\\{ 0 \\right\\}$, then $$ {{ G } \\over { H_{2} }} \\simeq G_{1} \\oplus {{ G_{2} } \\over { H_{2} }}$$ Since it was $B_{p} \\subset W_{p} \\subset Z_{p} \\subset C_{p}$ in Part 1, according to the properties of the Direct Sum, $$ \\begin{align*} H_{p} \\left( K \\right) =\u0026amp; Z_{p} / B_{p} \\\\ =\u0026amp; \\left( {{ V_{p} \\oplus W_{p} } \\over { B_{p} }} \\right) \\\\ =\u0026amp; V_{p} \\oplus \\left( {{ W_{p} } \\over { B_{p} }} \\right) \u0026amp; \\because [2] \\\\ =\u0026amp; \\left( {{ Z_{p} } \\over { W_{p} }} \\right) \\oplus \\left( {{ W_{p} } \\over { B_{p} }} \\right) \u0026amp; \\because [1] \\end{align*} $$ is obtained. Here, in $H_{p} \\left( K \\right) = \\left( Z_{p} / W_{p} \\right) \\oplus \\left( W_{p} / B_{p} \\right)$,\n$Z_{p} / W_{p}$ is the Free part, and $W_{p} / B_{p}$ is the Torsion part. Therefore, the $p$-th Betti Number $\\beta_{p}$ of $K$ is calculated as follows. $$ \\begin{align*} \\beta_{p} =\u0026amp; \\rank H_{p} \\left( K \\right) \\\\ =\u0026amp; \\rank \\left[ \\left( Z_{p} / W_{p} \\right) \\oplus \\left( W_{p} / B_{p} \\right) \\right] \\\\ =\u0026amp; \\rank \\left( Z_{p} / W_{p} \\right) + \\rank \\left( W_{p} / B_{p} \\right) \\\\ =\u0026amp; \\left[ \\rank Z_{p} - \\rank W_{p} \\right] + \\left[ \\rank W_{p} - \\rank B_{p} \\right] \\\\ =\u0026amp; \\rank Z_{p} - \\rank B_{p} \\end{align*} $$\nMeanwhile, for the torsion part of $H_{p-1}(K)$ and $b_{1} | \\cdots | b_{l} \\in \\mathbb{N}$, the following Isomorphism can be known to exist. $$ W_{p-1} / B_{p-1} \\simeq \\left( {{ \\mathbb{Z} } \\over { b_{1} \\mathbb{Z} }} \\right) \\oplus \\cdots \\oplus \\left( {{ \\mathbb{Z} } \\over { b_{l} \\mathbb{Z} }} \\right) $$ Here, the fact that $b_{i} = 1$ for $i \\le l$, in other words, the rank of $B_{p-1}$ is $l$, is because $$ \\mathbb{Z} / b_{i} \\mathbb{Z} = \\mathbb{Z} / \\mathbb{Z} = \\left\\{ 0 \\right\\} $$ so the rank of $W_{p-1}$ is reduced by $l$.\n■\nExample Torus $$ \\begin{align*} \\beta_{0} =\u0026amp; 1 \\\\ \\beta_{1} =\u0026amp; 2 \\\\ \\beta_{2} =\u0026amp; 1 \\end{align*} $$\nThe Betti numbers of a torus are known as above. Assuming the chain complex of this torus is defined as in the above figure, let\u0026rsquo;s just calculate $\\beta_{1} = 2$ as an example. There is also a way to calculate it by just mathematically pondering without using the formula derived above, but as you can read, it\u0026rsquo;s headache-inducingly difficult. In contrast, let\u0026rsquo;s see how convenient it is to \u0026rsquo;efficiently calculate homology\u0026rsquo;.\nHomomorphism\u0026rsquo;s Smith Normal Form: For Free Abelian Groups $G$ and $G'$, if $a_{1} , \\cdots , a_{n}$ is the basis of $G$, and $a_{1}' , \\cdots , a_{m}'$ is the basis of $G'$, and if the function $f : G \\to G'$ is a Homomorphism, then there exists a unique set of integers $\\left\\{ \\lambda_{ij} \\right\\} \\subset \\mathbb{Z}$ that satisfies the following. $$ f \\left( a_{j} \\right) = \\sum_{i=1}^{m} \\lambda_{ij} a_{i}' $$ Here, the matrix $\\left( \\lambda_{ij} \\right) \\in \\mathbb{Z}^{m \\times n}$ is called the Matrix of $f$ with respect to the bases of $G$ and $G'$.\nSince $\\beta_{1} = \\rank Z_{1} - \\rank B_{1}$, at least the Boundary Matrices $\\left( \\partial_{1} \\right)$ and $\\left( \\partial_{2} \\right)$ need to be found. For all $a , b, c \\in C_{1} (T)$, $$ \\begin{align*} \\partial_{1} (a) =\u0026amp; v - v = 0 = 0v \\\\ \\partial_{1} (b) =\u0026amp; v - v = 0 = 0v \\\\ \\partial_{1} (c) =\u0026amp; v - v = 0 = 0v \\end{align*} $$ is obtained. $Z_{p}$ is the number of zero vectors on the right side of the matrix, and $B_{p-1}$ is the number of $1$ in the matrix. Considering $\\partial_{2}$ next, $$ \\begin{align*} \\partial_{2} (U) =\u0026amp; -a -b +c \\\\ \\partial_{2} (L) =\u0026amp; a + b - c \\end{align*} $$ is obtained. Combining these, the $1$-th Betti Number $\\beta_{1}$ of the torus is calculated as follows. $$ \\beta_{1} = \\rank Z_{1} - \\rank B_{1} = 3 - 1 = 2 $$ Of course, this result is guaranteed to match the value obtained by using all sorts of mathematical knowledge, discussing what the Free Group is, what an Isomorphism is, and so on, according to the theorems introduced in this post. To speak a bit recklessly, one can \u0026lsquo;calculate\u0026rsquo; Betti numbers, that is, \u0026lsquo;homology\u0026rsquo;, just by following instructions without using the brain. On the other hand, to put it more positively, it opens the way to studying topology through computers.\nMunkres. (1984). Elements of Algebraic Topology: p58.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEdelsbrunner, Harer. (2010). Computational Topology An Introduction: p104.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMunkres. (1984). Elements of Algebraic Topology: p58~61.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2399,"permalink":"https://freshrimpsushi.github.io/en/posts/2399/","tags":null,"title":"Betti Number of Homology Group"},{"categories":"양자정보이론","contents":"\r양자정보이론\r[ 펼치기 · 접기 ]\r양자계산\r논리게이트\r비트\r· 부울함수(AND\r· OR\r· NOT\r· XOR\r· NAND\r· NOR\r· CNOT\r· CCNOT\r· CSWAP)\r· 범용 게이트\r· 복제 함수\r· 사영\r· 주입\r양자게이트\r큐비트\r· 양자 얽힘\r· 양자 회로\r· 양자 게이트(파울리 게이트\r· 위상 게이트\r· 아다마르 게이트\r· 양자 CNOT\r· 교환 게이트\r· 양자 CSWAP\r· 양자 CSWAP)\r· 솔베이-키타예프 정리\r· 복제 불가 정리\r정보이론\r고전정보이론\r정보량\r· 엔트로피(결합 엔트로피\r· 조건부 엔트로피\r· 상대적 엔트로피\r· 상호 정보\r)\r· 부호화\r· 복호화\r양자정보이론\rTBD\r· TBD\r· TBD\r관련 분야\r선형대수\r· 양자역학\r정의1 $2$큐비트 $\\ket{a, b} = \\ket{a} \\otimes \\ket{b}$에 대해서 교환 게이트exchage gate $\\text{ex}$를 다음과 같이 정의한다.\n$$ \\begin{align*} \\text{ex} : (\\mathbb{C}^{2})^{\\otimes 2} \u0026amp;\\to (\\mathbb{C}^{2})^{\\otimes 2} \\\\ \\ket{a, b} \u0026amp;\\mapsto \\ket{b, a},\\quad \\forall a,b \\in \\left\\{ 0, 1 \\right\\} \\end{align*} $$\n$$ \\text{ex} (\\ket{a} \\otimes \\ket{b}) = \\ket{b} \\otimes \\ket{a} $$\n설명 교환 게이트는 두 큐비트의 상태를 서로 바꾼다. 구체적인 입출력은 다음과 같다.\n$$ \\text{ex} (\\ket{00}) = \\ket{00} \\\\[0.5em] \\text{ex} (\\ket{01}) = \\ket{10} \\\\[0.5em] \\text{ex} (\\ket{10}) = \\ket{01} \\\\[0.5em] \\text{ex} (\\ket{11}) = \\ket{11} $$\n행렬표현은 다음과 같다.\n$$ \\text{ex} = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} $$\n김영훈·허재성, 양자 정보 이론 (2020), p97\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3429,"permalink":"https://freshrimpsushi.github.io/en/posts/3429/","tags":null,"title":"교환 게이트"},{"categories":"위상데이터분석","contents":"Buildup Despite the complexity of the content, I made sure to leave detailed calculations and explanations to make it as understandable as possible. If you\u0026rsquo;re interested in homology, I highly recommend reading this.\nConsider a topological space $X$ of interest, represented through a $\\Delta$-complex structure according to a specific simplicial complex. As a small example, in the image on the right, the torus represents $X$, and the left side corresponds to the simplicial complex.\nDefinition of a simplex:\nThe convex hull of $v_{0}, v_{1} , \\cdots , v_{n} \\in \\mathbb{R}^{n+1}$, which are affinely independent, is called an $n$-simplex $\\Delta^{n}$, and the vectors $v_{k}$ are called vertices. Mathematically, it is expressed as follows. $$ \\Delta^{n} := \\left\\{ \\sum_{k} t_{k} v_{k} : v_{k} \\in \\mathbb{R}^{n+1} , t_{k} \\ge 0 , \\sum_{k} t_{k} = 1 \\right\\} $$ An $n-1$-simplex $\\Delta^{n-1}$ created by removing a vertex from $\\Delta^{n}$ is called a face of $\\Delta^{n}$. The union of all faces of $\\Delta^{n}$ is called the boundary of $\\Delta^{n}$ and is denoted as $\\partial \\Delta^{n}$. The interior of a simplex $\\left( \\Delta^{n} \\right)^{\\circ} := \\Delta^{n} \\setminus \\partial \\Delta^{n}$ is called an open simplex. Let\u0026rsquo;s say a simplicial complex is a complex made up of simplices, specifically forming a CW complex as follows:\nThe definition of $n$:\n$D^{n} \\subset \\mathbb{R}^{n}$ defined as follows is called an $n$-unit disk. $$ D^{n} := \\left\\{ \\mathbf{x} \\in \\mathbb{R}^{n} : \\left\\| \\mathbf{x} \\right\\| \\le 1 \\right\\} $$ A subset $e^{n}$ that is homeomorphic to $D^{n} \\setminus \\partial D^{n}$ is called an $n$-cell. Definition of CW Complex:\nA discrete set $X^{0} \\ne \\emptyset$ is considered as 0-cells. An $n$-skeleton $X^{n}$ is made by attaching $n$-cells $e_{\\alpha}^{n}$ to $X^{n-1}$ using the maps $\\phi_{\\alpha} : S^{n-1} \\to X^{n-1}$. $X := \\bigcup_{n \\in \\mathbb{N}} X^{n}$ becomes a topological space with a weak topology, then $X$ is called a cell complex. Definition Consider a topological space $X$ with a $\\Delta$-complex structure.\nLet\u0026rsquo;s denote the free abelian group with a basis of open $n$-simplices, or $n$-cells $e_{\\alpha}^{n}$ in $X$, as $\\Delta_{n} (X)$. Elements of $\\Delta_{n} (X)$ are called $n$-chains and are represented as formal sums with coefficients $k_{\\alpha} \\in \\mathbb{Z}$ as follows. $$ \\sum_{\\alpha} k_{\\alpha} e_{\\alpha}^{n} $$ Each $n$-cell $e_{\\alpha}^{n}$ corresponds to a characteristic map $\\sigma_{\\alpha} : \\Delta^{n} \\to X$, allowing representation as follows. $$ \\sum_{\\alpha} k_{\\alpha} \\sigma_{\\alpha} $$ The boundary homomorphism $\\partial_{n} : \\Delta_{n} (X) \\to \\Delta_{n-1} (X)$ is defined as follows, where $\\sigma_{\\alpha} | \\left[ v_{1} , \\cdots , \\hat{v}_{i} , \\cdots , v_{n} \\right]$ indicates the restriction of $\\sigma_{\\alpha}$ to an $n-1$-simplex in $X$. $$ \\partial _{n} \\left( \\sigma_{\\alpha} \\right) := \\sum_{i=0}^{n} \\left( -1 \\right)^{i} \\sigma_{\\alpha} | \\left[ v_{1} , \\cdots , \\hat{v}_{i} \\cdots , v_{n} \\right] $$ The quotient group $\\ker \\partial_{n} / \\text{Im} \\partial_{n+1}$ is denoted as $H_{n}^{\\Delta}$, and since $H_{n}^{\\Delta}$ is a homology group, it is called the $n$th simplicial homology group of $X$. The group $0$ is a magma defined on ${ 0 }$, essentially an empty algebraic structure. The homomorphism $\\partial^{2} = 0$ is a zero morphism. $\\text{Im}$ refers to the image. $\\ker$ refers to the kernel. In a set, the notation $\\hat{v}_{i}$ means excluding $v_{i}$, as follows: $$ { v_{1} , \\cdots , \\hat{v}_{i} , \\cdots , v_{n} } := { v_{1} , \\cdots , v_{n} } \\setminus { v_{i} } $$ Explanation The definition section might be overwhelming with its dense text. It\u0026rsquo;s normal if it\u0026rsquo;s not immediately clear. The explanation aims to be thorough and accessible, addressing points that were confusing during my study.\nWhy are elements of $\\Delta_{n} (X)$ called chains? Considering the notation $\\sigma_{\\alpha} : \\Delta^{n} \\to X$, we can abstract away whether $e_{\\alpha}^{n}$ is an element of $\\Delta^{n}$ or $X$. For $n=2$ and all coefficients $k_{\\alpha} = 1$, the geometric representation can be imagined as the figure on the right, denoted as $\\sum_{i=1}^{7} \\sigma_{i}$.\nThe term \u0026ldquo;chain\u0026rdquo; might make sense now, but it\u0026rsquo;s not crucial for understanding. What\u0026rsquo;s important is that the collection of $n$-chains in $\\Delta_{n} (X)$ forms a chain complex.\nIs $\\Delta_{n} (X)$ really a group? It\u0026rsquo;s crucial to note that the \u0026ldquo;formal sum\u0026rdquo; used to describe chains is not an algebraic operation within $\\Delta_{n} (X)$. This notation is merely symbolic. For example, the expression\n2😀 + 💎 - 3🍌\rhas no mathematical meaning as it's unclear what \"twice 😀 plus 💎 minus three 🍌\" would entail. This confusion is similar to the uncertainty in $\\sum\\_{\\alpha} k\\_{\\alpha} e\\_{\\alpha} \\simeq \\sum\\_{\\alpha} k\\_{\\alpha} \\sigma\\_{\\alpha}$ regarding\r- The addition of open simplices $e\\_{\\alpha}^{n}$, which is undefined\r- The interpretation of $\\sigma\\_{\\alpha}$, which is a function\r- The meaning of operations like $-3 e\\_{1}^{n} + 7 e\\_{2}^{n} \\simeq -3 \\sigma\\_{1} + 7 \\sigma\\_{2}$\rThankfully, these concerns are irrelevant to $\\Delta_{n} (X)$. If we define\n$\\sigma=$2😀 + 💎 - 3🍌\ras an $n$-chain in $\\Delta\\_{n} (X)$, its inverse can be defined using the inverses of coefficients $k\\_{\\alpha} \\in (\\mathbb{Z}, +)$, resulting in\r$-\\sigma=$ (-2)😀 + (-1)💎 + 3🍌\rThis definition is sufficient regardless of the specific structure of $\\Delta_{n} (X)$. The identity element of $\\Delta_{n} (X)$ can be defined as $0 := \\sigma + (-\\sigma)$, and since $\\mathbb{Z}$ is an abelian group, so is $\\Delta_{n} (X)$. The operation $+$ in $(\\Delta_{n} (X), +)$ is induced from $(\\mathbb{Z}, +)$ but is distinct, and $\\Delta_{n} (X)$ is a free abelian group, with $\\sum_{\\alpha} k_{\\alpha} \\sigma_{\\alpha}$ now being an algebraic sum.\nIn summary:\nThe initial definition\u0026rsquo;s appearance of addition in $\\sum_{\\alpha} k_{\\alpha} \\sigma_{\\alpha}$ was merely notational, not an operation. The $+$ in $(\\Delta_{n} (X), +)$ is derived from $(\\mathbb{Z}, +)$ but is not the same. $(\\Delta_{n} (X), +)$ is a free abelian group, and $\\sum_{\\alpha} k_{\\alpha} \\sigma_{\\alpha}$ is now an algebraic sum. Why is $\\partial$ called the boundary? The definition of $\\partial_{n}$ may seem abstract, but the following illustration clarifies its meaning.\nFor example, for $\\partial_{2}$, we can perform the following calculation. $$ \\begin{align*} \u0026amp; \\partial _{2} \\left[ v_{0} ,v_{1}, v_{2} \\right] \\\\ =\u0026amp; \\sum_{i=0}^{2} (-1)^{i} \\left[ v_{0} ,v_{1}, v_{2} \\right] \\setminus \\left[ v_{i} \\right] \\\\ =\u0026amp; (-1)^{0} \\left[ v_{1}, v_{2} \\right] + (-1)^{1} \\left[ v_{0}, v_{2} \\right] + (-1)^{2} \\left[ v_{0}, v_{1} \\right] \\\\ =\u0026amp; \\left[ v_{1}, v_{2} \\right] - \\left[ v_{0}, v_{2} \\right] + \\left[ v_{0}, v_{1} \\right] \\end{align*} $$\nIf you\u0026rsquo;re studying homology, it\u0026rsquo;s generally accepted that the boundary of a triangle $\\left[ v_{0} ,v_{1}, v_{2} \\right]$ consists of the segments $\\left[ v_{1}, v_{2} \\right], \\left[ v_{0}, v_{2} \\right], \\left[ v_{0} , v_{1} \\right]$. The real challenge is understanding what $\\left[ v_{1}, v_{2} \\right] - \\left[ v_{0}, v_{2} \\right]$ means. How can segments be subtracted? And how about operations on 2-simplices like triangles?\nThese questions miss the point. Refocusing, $\\partial_{2} \\left[ v_{0} ,v_{1}, v_{2} \\right] \\in \\Delta_{1} (X)$ is simply a formal sum of the three elements $\\left[ v_{1}, v_{2} \\right], \\left[ v_{0}, v_{2} \\right], \\left[ v_{0} , v_{1} \\right]$. $$ (+1) \\left[ v_{1}, v_{2} \\right] + (-1) \\left[ v_{0}, v_{2} \\right] + (+1) \\left[ v_{0}, v_{1} \\right] $$\nDenoting these as $$ \\begin{align*} a := \\left[ v_{1}, v_{2} \\right] \\ b:= \\left[ v_{0}, v_{2} \\right] \\ c:= \\left[ v_{0} , v_{1} \\right] \\end{align*} $$ reveals the nature of $\\Delta_{1} (X)$. For example, a $1$-chain $x \\in \\Delta_{1} (X)$ can be represented with coefficients $k_{a} , k_{b} , k_{c} \\in \\mathbb{Z}$ as $$ x = k_{a} a + k_{b} b + k_{c} c $$\nViewing from the perspective of $a,b,c$, the free group $\\Delta_{1} (X) := F[{ a,b,c }]$ is constructed, essentially equivalent to $\\mathbb{Z}^{3} \\simeq \\mathbb{Z} \\oplus \\mathbb{Z} \\oplus \\mathbb{Z}$.\nThis shift in perspective is crucial for understanding subsequent examples. We must think algebraically rather than geometrically.\nExamples Consider the following scenario: $$ \\begin{align*} \\\\ \\partial_{n} :\u0026amp; \\Delta_{n} (X) \\to \\Delta_{n-1} (X) \\\\ H_{n}^{\\Delta} (X) =\u0026amp; \\ker \\partial_{n} / \\text{Im} \\partial_{n+1} \\end{align*} $$\nFor $n = 0$, $\\partial_{0} : \\Delta_{0} (X) \\to 0$ implies $\\ker \\partial_{0} = \\Delta_{0} (X)$.\nCircle $S^{1}$ For a circle $X = S^{1}$, there\u0026rsquo;s one 0-simplex (vertex $v$), one 1-simplex (edge $e$), and no $n$-simplices for $n \\ge 2$. The chain complex is structured as follows: $$ \\cdots \\longrightarrow 0 \\longrightarrow \\Delta_{1}\\left( S^{1} \\right) \\overset{\\partial_{1}}{\\longrightarrow} \\Delta_{0}\\left( S^{1} \\right) \\overset{\\partial_{0}}{\\longrightarrow} 0 $$\n$\\Delta_{1}(S^{1})$, being generated solely by $e$, is isomorphic to $\\mathbb{Z}$, and similarly, $\\Delta_{0}(S^{1})$ is isomorphic to $\\mathbb{Z}$ due to being generated by $v$ alone. Since $\\partial_{1}$ is a zero morphism: $$ \\partial e = v - v = 0 $$\nFor $n = 0$, $\\ker \\partial_{0} = \\Delta_{0} (S^{1})$, and since $\\partial_{1}$ is a zero morphism, its image is ${ 0 }$, leading to: $$ \\begin{align*} H_{0}^{\\Delta} \\left( S^{1} \\right) =\u0026amp; \\ker \\partial_{0} / \\text{Im} \\partial_{1} \\\\ \\simeq\u0026amp; \\Delta_{0} \\left( S^{1} \\right) / \\left\\{ 0 \\right\\} \\\\ \\simeq\u0026amp; \\mathbb{Z} \\end{align*} $$\nFor $n = 1$, $\\text{Im} \\partial_{2} = { 0 }$ since $\\partial_{1}$ is a zero morphism, and $\\ker \\partial_{1} = \\Delta_{1} (S^{1})$, resulting in: $$ \\begin{align*} H_{1}^{\\Delta} \\left( S^{1} \\right) =\u0026amp; \\ker \\partial_{1} / \\text{Im} \\partial_{2} \\\\ \\simeq\u0026amp; \\Delta_{1} \\left( S^{1} \\right) / \\left\\{ 0 \\right\\} \\\\ \\simeq\u0026amp; \\mathbb{Z} \\end{align*} $$\nFor $n \\ge 2$, $H_{n}^{\\Delta} (S_{1}) \\simeq 0$, summarizing as: $$ H_{n}^{\\Delta} \\left( S_{1} \\right) \\simeq \\begin{cases} \\mathbb{Z} \u0026amp; , \\text{if } n = 0, 1 \\\\ 0 \u0026amp; , \\text{if } n \\ge 2 \\end{cases} $$\nTorus $T^{2}$ Considering a torus $T^{2}$ as in the image, there\u0026rsquo;s one 0-simplex (vertex $v$), three 1-simplices (edges $a$, $b$, $c$), two 2-simplices ($U$, $L$), and no $n$-simplices for $n \\ge 3$. The chain complex is organized as follows: $$ \\cdots \\longrightarrow 0 \\longrightarrow \\Delta_{2}\\left( T \\right) \\overset{\\partial_{2}}{\\longrightarrow} \\Delta_{1}\\left( T \\right) \\overset{\\partial_{1}}{\\longrightarrow} \\Delta_{0}\\left( T \\right) \\overset{\\partial_{0}}{\\longrightarrow} 0 $$\nHence, the free groups $\\Delta_{n} (T)$ are: $$ \\Delta_{n} \\left( T \\right) \\simeq \\begin{cases} \\mathbb{Z}^{1} \u0026amp; , \\text{if } n = 0 \\\\ \\mathbb{Z}^{3} \u0026amp; , \\text{if } n = 1 \\\\ \\mathbb{Z}^{2} \u0026amp; , \\text{if } n = 2 \\\\ 0 \u0026amp; , \\text{if } n \\ge 3 \\end{cases} $$\nSince the edges $a$, $b$, $c$ connect to vertex $v$ at both ends: $$ \\begin{align*} \\partial a =\u0026amp; v - v = 0 \\\\ \\partial b =\u0026amp; v - v = 0 \\\\ \\partial c =\u0026amp; v - v = 0 \\end{align*} $$ and $\\partial_{1}$ is a zero morphism, similar to the circle case.\nFor $n = 0$, the situation mirrors that of the circle: $$ \\begin{align*} H_{0}^{\\Delta} \\left( T \\right) =\u0026amp; \\ker \\partial_{0} / \\text{Im} \\partial_{1} \\\\ \\simeq\u0026amp; \\Delta_{0} \\left( T \\right) / \\left\\{ 0 \\right\\} \\\\ \\simeq\u0026amp; \\mathbb{Z} \\end{align*} $$\nFor $n = 1$, since $\\partial_{1}$ is a zero morphism, $\\ker \\partial_{1} = \\Delta_{1} (T)$. The boundary homomorphism $\\partial_{2} : \\Delta_{2}(T) \\to \\Delta_{1}(T)$ yields: $$ \\partial_{2} U = a + b - c = \\partial_{2} L $$ and since ${ a, b, a + b - c }$ is a basis for $\\Delta_{1}(T)$, $H_{1}^{\\Delta}$ is isomorphic to the free group generated by $a$ and $b$, resulting in: $$ H_{1}^{\\Delta} \\left( T \\right) \\simeq \\mathbb{Z} \\oplus \\mathbb{Z} $$\nFor $n = 2$, $\\text{Im} \\partial_{3} = { 0 }$ and considering the dimensions of $\\Delta_{2}(T)$ and $\\Delta_{1}(T)$, we get: $$ \\begin{align*} H_{2}^{\\Delta} \\left( T \\right) =\u0026amp; \\ker \\partial_{2} / \\text{Im} \\partial_{3} \\\\ \\simeq\u0026amp; \\mathbb{Z}^{3-2} / \\left\\{ 0 \\right\\} \\\\ \\simeq\u0026amp; \\mathbb{Z} \\end{align*} $$\nFor $n \\ge 3$, $H_{n}^{\\Delta} (T) \\simeq 0$, summarizing as: $$ H_{n}^{\\Delta} \\left( T \\right) \\simeq \\begin{cases} \\mathbb{Z} \u0026amp; , \\text{if } n = 0 \\\\ \\mathbb{Z} \\oplus \\mathbb{Z} \u0026amp; , \\text{if } n = 1 \\\\ \\mathbb{Z} \u0026amp; , \\text{if } n = 2 \\\\ 0 \u0026amp; , \\text{if } n \\ge 3 \\end{cases} $$\nTheorem $H_{n}^{\\Delta}$ is a homology group Definition of a homology group:\nLet $n \\in \\mathbb{N}_{0}$. A sequence of abelian groups $C_{n}$ and homomorphisms $\\partial_{n} : C_{n} \\longrightarrow C_{n-1}$ forming a chain $$ \\cdots \\longrightarrow C_{n+1} \\overset{\\partial_{n+1}}{\\longrightarrow} C_{n} \\overset{\\partial_{n}}{\\longrightarrow} C_{n-1} \\longrightarrow \\cdots \\longrightarrow C_{1} \\overset{\\partial_{1}}{\\longrightarrow} C_{0} \\overset{\\partial_{0}}{\\longrightarrow} 0 $$ that satisfies $$ \\partial_{n} \\circ \\partial_{n+1} = 0 $$ for all $n$ is called a chain complex. The quotient group $H_{n} := \\ker \\partial_{n} / \\text{Im} \\partial_{n+1}$ is called the $n$th homology group of the complex. The homomorphism $\\partial_{n} : C_{n} \\longrightarrow C_{n-1}$ is called the boundary or differential operator. For the chain complex ${ (\\Delta_{n} (X), \\partial_{n}) }_{n=0}^{\\infty}$, $H_{n}^{\\Delta} := \\ker \\partial_{n} / \\text{Im} \\partial_{n+1}$ is a homology group. That is, $\\partial_{n} \\circ \\partial_{n+1}$ is a zero morphism for all $n \\in \\mathbb{N}$.\nProof Applying $\\partial_{n-1} \\circ \\partial_{n}$ to $\\sigma \\in \\Delta_{n}$ yields: $$ \\begin{align*} \u0026amp; \\left( \\partial_{n-1} \\circ \\partial_{n} \\right) \\left( \\sigma \\right) \\\\ =\u0026amp; \\partial_{n-1} \\left( \\partial_{n} \\left( \\sigma \\right) \\right) \\\\ =\u0026amp; \\partial_{n-1} \\left( \\sum_{i=0}^{n} \\left( -1 \\right)^{i} \\sigma_{\\alpha} | \\left[ v_{1} , \\cdots , \\hat{v}_{i} , \\cdots , v_{n} \\right] \\right) \\\\ =\u0026amp; \\sum_{j \u0026lt; i} \\left( -1 \\right)^{i} \\left( -1 \\right)^{j} \\sigma_{\\alpha} | \\left[ v_{1} , \\cdots , \\hat{v}_{i} , \\cdots , \\hat{v}_{j} , \\cdots , v_{n} \\right] \\\\ \u0026amp; + \\left( -1 \\right) \\sum_{j \u0026gt;i} \\left( -1 \\right)^{i} \\left( -1 \\right)^{j} \\sigma_{\\alpha} | \\left[ v_{1} , \\cdots , \\hat{v}_{i} , \\cdots , \\hat{v}_{j} , \\cdots , v_{n} \\right] \\\\ =\u0026amp; 0 \\end{align*} $$\nSuch proofs are often more illuminating with specific examples rather than generalizations. $$ \\begin{align*} \u0026amp; \\partial_{1} \\left( \\partial_{2} \\left[ v_{0}, v_{1} , v_{2} \\right] \\right) \\\\ =\u0026amp; \\partial_{1} \\left( \\left[ v_{1} , v_{2} \\right] - \\left[ v_{0}, v_{2} \\right] + \\left[ v_{0}, v_{1} \\right] \\right) \\\\ =\u0026amp; \\partial_{1} \\left[ v_{1} , v_{2} \\right] - \\partial_{1} \\left[ v_{0}, v_{2} \\right] + \\partial_{1} \\left[ v_{0}, v_{1} \\right] \\\\ =\u0026amp; \\left[ v_{2} \\right] - \\left[ v_{1} \\right] - \\left( \\left[ v_{2} \\right] - \\left[ v_{0} \\right] \\right) + \\left[ v_{1} \\right] - \\left[ v_{0} \\right] \\\\ =\u0026amp; 0 \\end{align*} $$\n■\n","id":2383,"permalink":"https://freshrimpsushi.github.io/en/posts/2383/","tags":null,"title":"Definition of Simplicial Homology Group"},{"categories":"머신러닝","contents":"Overview The notation and numbering of references and formulas follow the conventions of the original paper. Physics-informed neural networks (referred to as PINN[pronounced \u0026lsquo;pin\u0026rsquo;]) are artificial neural networks designed to numerically solve differential equations, introduced in the 2018 Journal of Computational Physics paper Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. The authors of the paper are M. Raissi, P. Perdikaris, and G.E. Karniadakis from the departments of Applied Mathematics and Mechanical Engineering.\nThe physics information mentioned in this paper, although it may sound grandiose, simply refers to the given differential equations themselves. In other words, using the given differential equations when solving them with artificial neural networks is essentially the same as saying \u0026lsquo;using physics information\u0026rsquo; in this context. When reading machine learning papers, one should be cautious not to be swayed by such seemingly impressive terminology.\nThe reason PINN is receiving significant attention in the numerical solution of differential equations is likely due to the simplicity and ease of understanding of the idea behind the loss function, as well as its straightforward implementation. In fact, the paper introduces a very simple DNN as an example.\nCommonly, the model introduced in Section 3.1 is referred to as PINN.\n0. Abstract The authors describe PINN as \u0026lsquo;an artificial neural network trained to solve supervised learning problems while satisfying a given nonlinear partial differential equation\u0026rsquo;. The two main issues addressed in this paper are the \u0026lsquo;data-driven solution and data-driven discovery of partial differential equations\u0026rsquo;. To evaluate performance, problems in fluid mechanics, quantum mechanics, and diffusion equations were solved.\n1. Introduction Although recent advances in machine learning and data analysis have led to innovative results in scientific fields such as image recognition, cognitive science, and genomics, there is a challenge in complex physical, biological, and engineering systems to yield desired results with limited information (due to the high cost of data collection). In such a small data regime, the convergence of advanced technologies like DNNs, CNNs, and RNNs is not guaranteed.\nStudies on methods to learn physics information efficiently (i.e., solve differential equations with minimal data) were conducted in [4-6]. The extension to nonlinear problems was proposed in subsequent studies by Raissi, one of the authors of this paper, in [8,9].\n2. Problem setup The function represented by an artificial neural network is determined by its input values (coordinates $x, t$ of the solution $u$ in a partial differential equation) and parameters. Automatic differentiation is utilized to differentiate these two types of variables.\nSuch neural networks are constrained to respect any symmetries, invariances, or conservation principles originating from the physical laws that govern the observed data, as modeled by general time-dependent and nonlinear partial differential equations.\nThis sentence from the paper might seem complex, but simply put, it means that the proposed artificial neural network, PINN, must satisfy the given differential equations. This is because the condition of satisfying the differential equations is used as a loss function, as will be discussed later.\nThe aim of this paper is to present a new modeling and computational paradigm to advance deep learning in mathematical physics. To this end, as mentioned earlier, this paper mainly addresses two issues. One is the data-driven solution of partial differential equations, and the other is the data-driven discovery of partial differential equations. All the codes and datasets used can be found at https://github.com/maziarraissi/PINNs. In this paper, a simple MLP using hyperbolic tangent as the activation function is used without any regularization such as $L1$, $L2$, or dropout, as introduced in the regularization section. The structure of the neural network, optimizer, learning rate, etc., are specifically introduced in each example.\nThis paper deals with the general form of parameterized and nonlinear partial differential equations as follows:\n$$ \\begin{equation} u_{t} + \\mathcal{N}[u; \\lambda] = 0,\\quad x \\in \\Omega,\\quad t \\in [0,T] \\end{equation} $$\nHere, $u=u(t,x)$ is the hidden (i.e., not given or unknown) function, the solution of $(1)$ that we seek, and $\\mathcal{N}[\\cdot; \\lambda]$ is a nonlinear operator parameterized by $\\lambda$, with $\\Omega \\subset \\mathbb{R}^{D}$. Many problems in mathematical physics can be represented in this form. For instance, consider the one-dimensional viscous Burgers\u0026rsquo; equation:\n$$ u_{t} + uu_{x} = \\nu u_{xx} $$\nThis corresponds to the case in $(1)$ where $\\mathcal{N}[u; \\lambda] = \\lambda_{1} uu_{x} - \\lambda_{2}u_{xx}$ and $\\lambda = (\\lambda_{1}, \\lambda_{2})$. The two problems addressed for the given equation $(1)$ are as follows:\ndata-driven solution of PDEs: For a fixed $\\lambda$, what is the solution $u(t,x)$ of the system? data-driven discovery of PDEs: What are the parameters $\\lambda$ that best describe the observed data? 3. Data-driven solutions of partial differential equations Section 3 discusses the problem of finding data-driven solutions for partial differential equations of the following form:\n$$ \\begin{equation} u_{t} + \\mathcal{N}[u] = 0,\\quad x \\in \\Omega,\\quad t \\in [0,T] \\end{equation} $$\nThis corresponds to the situation in $(1)$ where the parameter $\\lambda$ is fixed. Section 3.1 and Section 3.2 will cover continuous time models and discrete time models respectively. The problem of finding the equations will be addressed in Section 4. The meaning of \u0026lsquo;data\u0026rsquo; mentioned here will be explained in detail below.\n3.1. Continuous time models Assuming $(t,x) \\in \\mathbb{R} \\times \\mathbb{R}$, then $u : \\mathbb{R}^{2} \\to \\mathbb{R}$. This will be approximated using an artificial neural network, employing a simple MLP implemented as follows. In Julia, it would be:\nusing Flux u = Chain( Dense(2, 10, relu), Dense(10, 10, relu), Dense(10, 1) ) In PyTorch, it would be:\nimport torch import torch.nn as nn import torch.nn.functional as F layers = [2, 10, 10, 1] class network(nn.Module): def __init__(self): super(network, self).__init__() layer_list = [nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)] self.linears = nn.ModuleList(layer_list) def forward(self, tx): u = tx for i in range(len(layers)-2): u = self.linears[i](u) u = F.relu(u) u = self.linears[-1](u) return u u = network() Now, $u$ represents the artificial neural network we\u0026rsquo;ve defined, with $2$ input nodes and $1$ output node. Let\u0026rsquo;s define the left-hand side of $(2)$ as a function $f = f(t,x; u)$ as follows:\n$$ \\begin{equation} f := u_{t} + \\mathcal{N}[u] \\end{equation} $$\nSince $u$ is an artificial neural network, $f$ also becomes a sort of artificial neural network with hidden layer parameters. The $f$ defined in this way is called a physics-informed neural network (PINN), which is, in essence, the given partial differential equation itself. The differentiation included in $f$ is implemented through automatic differentiation and shares the same parameters as $u$. If the artificial neural network $u$ accurately approximates the solution to $(2)$, the function values of $f$ should be zero everywhere. We can infer that we will train the artificial neural network in a direction where $ f \\to 0$.\nLet\u0026rsquo;s say $(t_{u}^{i}, x_{u}^{i})$ are points in the domain where the initial and boundary conditions are defined: $$ (t_{u}^{i}, x_{u}^{i}) \\in( \\Omega \\times \\left\\{ 0 \\right\\}) \\cup (\\partial \\Omega \\times [0, T]) $$ If $u_{\\ast}$ is the actual solution, having initial and boundary conditions means that the following values are given:\n$$ \\left\\{ t_{u}^{i}, x_{u}^{i}, u^{i} \\right\\}_{i=1}^{N_{u}},\\quad u^{i} = u_{\\ast} (t_{u}^{i}, x_{u}^{i}) $$\nTheoretically, we would have an infinite number of such values, but in numerical problems, we can only handle a finite number of points, so let\u0026rsquo;s say we have $N_{u}$ points. The artificial neural network $u$ should output $u^{i}$ when given $(t_{u}^{i}, x_{u}^{i})$ as input, making these pairs the inputs and corresponding labels:\n$$ \\text{input} = (t_{u}^{i}, x_{u}^{i}),\\qquad \\text{label} = u^{i} $$\nThis is precisely the \u0026lsquo;data\u0026rsquo; to be learned in PINN. We can now consider the following as the loss function:\n$$ MSE_{u} = \\dfrac{1}{N_{u}} \\sum\\limits_{i=1}^{N_{u}} \\left| u(t_{u}^{i},x_{u}^{i}) - u^{i} \\right|^{2} $$\nAdditionally, $f$ should satisfy $(2)$ at appropriate points (ideally at all points where the solution $u_{\\ast}$ is defined, but numerically we can only handle a finite number of points) $\\left\\{ t_{f}^{i}, x_{f}^{i} \\right\\}_{i=1}^{N_{f}}$. In the paper, these points are referred to as collocation points. We set the following as the loss function for the collocation points:\n$$ MSE_{f} = \\dfrac{1}{N_{f}}\\sum\\limits_{i=1}^{N_{f}} \\left| f(t_{f}^{i}, x_{f}^{i}) \\right|^{2} $$\nIn other words, $MSE_{f}$ getting closer to $0$ means satisfying the physical information (the partial differential equation). Therefore, the final loss function for training the artificial neural network $u$ is as follows:\n$$ MSE = MSE_{u} + MSE_{f} $$\nThe paper explains that using $MSE_{f}$ as a constraint for physical information, as done here, was first researched in [15, 16]. However, in the PINN paper, it was reviewed using modern computational tools and applied to more challenging dynamic systems.\nThe term physics-informed machine learning was first used in Wang\u0026rsquo;s study [17] on turbulence modeling. However, prior to PINN, studies simply employed machine learning algorithms like support vector machines, random forests, and FNNs. PINN is distinguished from these previous approaches by considering not only the derivatives with respect to the parameters commonly used in machine learning\nbut also the derivatives with respect to the coordinates $x, t$ of the solution. That is, if the solution approximated by an artificial neural network with parameter $w$ is denoted as $u(t,x; w)$, while previously proposed methods only utilized the partial derivatives $u_{w}$, PINN also uses $u_{t}$, $u_{x}$, etc., to find the solution. It explains that this approach allows for finding the solution well even with a small amount of data.\nDespite the fact that there is no theoretical guarantee that this procedure converges to a global minimum, our empirical evidence indicates that, if the given partial differential equation is well-posed and its solution is unique, our method is capable of achieving good prediction accuracy given a sufficiently expressive neural network architecture and a sufficient number of collocation points $N_{f}$.\nThe paper notes that although there is no theoretical guarantee for the convergence of the proposed method, empirical evidence suggests that if the given partial differential equation is well-posed and has a unique solution, and if there are a sufficient number of points, then high prediction accuracy can be achieved.\n3.1.1. Example (Schrodinger Equation) This example focuses on verifying the effectiveness of the proposed method for solutions with periodic boundary conditions and complex values. As an example, the Schrodinger Equation with the following initial and boundary conditions is considered:\n$$ \\begin{align*} ih_{t} + 0.5h_{xx} + \\left| h \\right|^{2}h \u0026amp;= 0,\\quad x\\in [-5, 5], t\\in[0, \\pi/2], \\\\ h(0,x) \u0026amp;= 2\\operatorname{sech} (x), \\\\ h(t,-5) \u0026amp;= h(t,5), \\\\ h_{x}(t,-5) \u0026amp;= h_{x}(t,5) \\end{align*} $$\nThe solution to the problem, $h_{\\ast}(t,x)$, is a function with complex-valued function outputs, namely $h_{\\ast} : [0, \\pi/2] \\times [-5, 5] \\to \\mathbb{C}$. However, instead of defining an artificial neural network that outputs complex numbers, we define it to output a 2-dimensional vector consisting of $u(t,x)$ representing the real part and $v(t,x)$ representing the imaginary part. In simple terms, it is defined as an MLP with 2 input nodes and 2 output nodes:\n$$ h(t,x) = \\begin{bmatrix} u(t,x) \\\\[0.5em] v(t,x) \\end{bmatrix} $$\nIn this problem, the PINN $f$ is defined as:\n$$ f := ih_{t} + 0.5h_{xx} + \\left| h \\right|^{2} h $$\nThe parameters of $h(t,x)$ and $f(t,x)$ are trained to minimize the loss for initial values $MSE_{0}$, the loss for boundary values $MSE_{b}$, and the loss for physical information $MSE_{f}$.\n$$ MSE = MSE_{0} + MSE_{b} + MSE_{f} $$\n$$ \\begin{align*} \\text{where } MSE_{0} \u0026amp;= \\dfrac{1}{N_{0}}\\sum_{i=1}^{N_{0}} \\left| h(0, x_{0}^{i}) - h_{0}^{i} \\right|^{2} \\qquad (h_{0}^{i} = 2\\operatorname{sech} (x_{0}^{i})) \\\\ MSE_{b} \u0026amp;= \\dfrac{1}{N_{b}}\\sum_{i=1}^{N_{b}} \\left( \\left| h(t_{b}^{i}, -5) - h(t_{b}^{i}, 5) \\right|^{2} + \\left| h_{x}(t_{b}^{i},-5) - h_{x}(t_{b}^{i},5) \\right|^{2} \\right) \\\\ MSE_{f} \u0026amp;= \\dfrac{1}{N_{f}} \\sum\\limits_{i=1}^{N_{f}} \\left| f(t_{f}^{i}, x_{f}^{i}) \\right|^{2} \\end{align*} $$\nBe aware that there is a typo in the formula for $MSE_{b}$ in the paper. Here, $\\left\\{ x_{0}^{i}, h_{0}^{i} \\right\\}_{i=1}^{N_{0}}$ are the initial value data, $\\left\\{ t_{b}^{i} \\right\\}_{i=1}^{N_{b}}$ are the collocation points at the boundary, and $\\left\\{ t_{f}^{i}, x_{f}^{i} \\right\\}_{i=1}^{N_{f}}$ are the collocation points for $f$.\nFor data generation, traditional spectral methods were used. The number of initial value data $N_{0} = 50$ and the number of boundary value data $N_{b} = 50$ were chosen randomly. Additionally, the number of collocation points for $f$ is $N_{f} = 20,000$. The artificial neural network was constructed by stacking\n5 linear layers each with 100 nodes, and hyperbolic tangent $\\tanh$ was used as the activation function between layers.\nFigure 1.\nIn Figure 1, the upper image shows the heatmap of the predicted solution $\\left| h(t, x) \\right|$. The lower images show how well the predicted solution matches the actual solution at times $t = 0.59, 0.79, 0.98$, respectively. The relative $L_{2}$-norm is $0.00197 = 1.97 \\cdot 10^{-3}$, which means the predicted solution differs by about $0.02\\%$ when compared to the accurate solution. Therefore, PINN can accurately capture the nonlinear behavior of the Schrodinger equation even with a small amount of initial data.\nThe continuous time model being discussed works well even with a few initial values but has a potential limitation in that a large number of collocation points $N_{f}$ are needed. This is not a significant issue when the spatial dimension is 2 or less, but in higher dimensions, the required number of collocation points can increase exponentially, which can be problematic. Therefore, in the next section, a more structured neural network that does not require many collocation points is presented, utilizing the classical Runge–Kutta time-stepping schemes.\n3.2. Discrete time models In Section 3.1, we approximated the solution over continuous time. In that case, the artificial neural network is trained simultaneously over the entire domain, providing an output for any arbitrary point $(x,t)$. In this section, unlike Section 3.1, we deal with discrete time. In other words, we will describe how to approximate the value at $t_{n+1}$ using an artificial neural network, given the value at $t_{n}$. Applying a $q$-stage Runge-Kutta method to $(2)$ yields the following: $$ u(t_{n+1}, x) = u(t_{n}, x) - \\Delta t \\sum_{j=1}^{q} b_{j}\\mathcal{N}\\left[ u(t_{n}+c_{j} \\Delta t, x) \\right] $$\nIf we denote $u^{n}(x) = u(t_{n}, x)$ and $u^{n+c_{j}} = u(t_{n} + c_{j}\\Delta t, x)$, then:\n$$ \\begin{equation} \\begin{aligned} u^{n+1} \u0026amp;= u^{n} - \\Delta t \\sum_{j=1}^{q} b_{j}\\mathcal{N}\\left[ u^{n+c_{j}}\\right] \\\\ \\text{where } u^{n+c_{j}} \u0026amp;= u^{n} - \\Delta t \\sum_{i=1}^{q} a_{j,i}\\mathcal{N}\\left[ u^{n+c_{i}}\\right] \\quad j=1,\\dots,q \\end{aligned}\\tag{7} \\end{equation} $$\nIn the $q+1$ equations above, let\u0026rsquo;s move all the $\\sum$ terms on the right-hand side to the left-hand side. Then, denote the left-hand side as $u_{i}^{n}$.\n$$ \\begin{equation} \\begin{aligned} u_{q+1}^{n} \u0026amp;:= u^{n+1} + \\Delta t \\sum_{j=1}^{q} b_{j}\\mathcal{N}\\left[ u^{n+c_{j}}\\right] = u^{n} \\\\ \\\\ u_{1}^{n} \u0026amp;:= u^{n+c_{1}} + \\Delta t \\sum_{i=1}^{q} a_{1,i}\\mathcal{N}\\left[ u^{n+c_{i}}\\right] = u^{n} \\\\ u_{2}^{n} \u0026amp;:= u^{n+c_{2}} + \\Delta t \\sum_{i=1}^{q} a_{2,i}\\mathcal{N}\\left[ u^{n+c_{i}}\\right] = u^{n} \\\\ \u0026amp;\\vdots \\\\ u_{q}^{n} \u0026amp;:= u^{n+c_{q}} + \\Delta t \\sum_{i=1}^{q} a_{q,i}\\mathcal{N}\\left[ u^{n+c_{i}}\\right] = u^{n} \\end{aligned}\\tag{9} \\end{equation} $$\nFrom this, we can see that all these values should be equal to $u^{n}$.\n$$ u^{n} = u_{1}^{n} = u_{2}^{n} = \\cdots = u_{q+1}^{n} \\tag{8} $$\nTherefore, the physics information mentioned in Section 3.2 refers to the given initial \u0026amp; boundary conditions and $(8)$. Now, to compute $u(t_{n+1}, x)$, we define two artificial neural networks. The artificial neural network used in Section 3.1 was $u$ which is expected to converge to the exact solution $u_{\\ast}$ and the differential equation $f$ that $u$ must satisfy, but here it\u0026rsquo;s slightly different. First, let\u0026rsquo;s define the artificial neural network $U$ as the following function:\n$$ U : \\mathbb{R} \\to \\mathbb{R}^{q+1} $$\nThat is, it\u0026rsquo;s a neural network with $1$ input node and $q+1$ output nodes. Let\u0026rsquo;s assume the output of this network is as follows:\n$$ U(x) = \\begin{bmatrix} u^{n+c_{1}}(x) \\\\[0.5em] u^{n+c_{2}}(x) \\\\ \\vdots \\\\[0.5em] u^{n+c_{q}}(x) \\\\[0.5em] u^{n+1}(x) \\end{bmatrix} \\tag{10} $$\nThis network corresponds to the neural_net defined within the PhysicsInformedNN class in the attached code.\nIn the learning process below, the last component of the output of $U$ is expected to converge to $u(t_{n+1}, x)$. The second neural network is defined using the output of $U$ and the definition in $(7)$ as follows.\n3.2.1. Example (Allen–Cahn equation) The example for the discrete time model deals with the Allen-Cahn equation, given the following initial condition and periodic boundary conditions:\n$$ \\begin{equation} \\begin{aligned} \u0026amp;u_{t} - 0.0001u_{xx} + 5 u^{3} - 5u = 0,\\qquad x\\in [-1, 1], t\\in[0, 1], \\\\ \u0026amp;u(0,x) = x^{2} \\cos (\\pi x), \\\\ \u0026amp;u(t,-1) = u(t,1), \\\\ \u0026amp;u_{x}(t,-1) = u_{x}(t,1) \\end{aligned}\\tag{12} \\end{equation} $$\nIn this example, the nonlinear operator included in $(9)$ is as follows:\n$$ \\mathcal{N}[u^{n+c_{j}}] = -0.0001u_{xx}^{n+c_{j}} + 5(u^{n+c_{j}})^{3} - 5u^{n+c_{j}} $$\nLet\u0026rsquo;s denote the value of $u$ at time step $t^{n}$ as $u^{n,i}$:\n$$ u^{n,i} = u^{n}(x^{n,i}) = u(t^{n}, x^{n,i}),\\qquad i=1,\\dots,N_{n} $$\nSince our problem is to compute $u^{n+1}$ given $u^{n}$, $\\left\\{ x^{n,i}, u^{n,i} \\right\\}_{i=1}^{N_{n}}$ is our given dataset. According to $(8)$, the following must hold for this dataset:\n$$ u^{n,i} = u_{1}^{n}(x^{n,i}) = \\cdots = u_{q+1}^{n}(x^{n,i}) $$\nSo, let\u0026rsquo;s set the following loss function, the sum of squared error (SSE), for this:\nIt\u0026rsquo;s unclear why $MSE$ is not used here, but $SSE$ is used for the discrete time model. The paper uses $MSE$ for continuous time models and $SSE$ for discrete time models, which suggests there might be a reason (even if experimental). $$ SSE_{n} = \\sum\\limits_{j=1}^{q+1} \\sum\\limits_{i=1}^{N_{n}} \\left| u_{j}^{n} (x^{n,i}) - u^{n,i} \\right|^{2} $$\nEach $u_{j}^{n}$ is computed according to $(9)$, with the calculations involving $u^{n+1}$ and $u^{n+c_{j}}$ being the output of the neural network $U$. This loss corresponds to net_U0 defined within the PhysicsInformedNN class in the attached code. Since the output of $U$ must satisfy the boundary conditions of $(12)$, we set the following loss function:\n$$ \\begin{align*} SSE_{b} \u0026amp;= \\sum\\limits_{i=1}^{q} \\left| u^{n+c_{i}}(-1) - u^{n+c_{i}}(1) \\right|^{2} + \\left| u^{n+1}(-1) - u^{n+1}(1) \\right|^{2} \\\\ \u0026amp;\\quad+ \\sum\\limits_{i=1}^{q} \\left| u_{x}^{n+c_{i}}(-1) - u_{x}^{n+c_{i}}(1) \\right|^{2} + \\left| u_{x}^{n+1}(-1) - u_{x}^{n+1}(1) \\right|^{2} \\\\ \\end{align*} $$\nThe final loss is the sum of these two:\n$$ SSE = SSE_{n} + SSE_{b} $$\nFigure 2.\nIn Fig. 2, the upper image shows the heatmap of the exact solution. The lower image shows the predicted values at $t=0.9$, given the $u$ at $t=0.1$. In the lower left image, the blue line represents the exact solution, and $\\color{red}\\mathsf{X\n}$ marks the points used as data. In the lower right image, the blue line is the exact solution, and the red line is the predicted solution.\nIn Implicit Runge-Kutta methods (IRK), solving simultaneous equations for all $j$ is required to compute $u^{n+c_{j}}$, meaning that the computational cost increases significantly as $q$ increases. However, the paper explains that the proposed method does not incur much additional cost even if $q$ increases. It also explains that while IRK may not be able to make accurate predictions with large time steps $\\Delta t$ when $q$ is small, PINN can still make accurate predictions even with large $\\Delta t$.\n4. Data-driven discovery of partial differential equations This chapter deals with the problem of finding the parameters $\\lambda$ of the partial differential equation $(1)$ when observational data is available. The details are explained below with examples.\n4.1. Continuous time models Let\u0026rsquo;s define $f$ as the left-hand side of $(1)$:\n$$ f = u_{t} + \\mathcal{N}[u; \\lambda] $$\nThe difference from $(3)$ in Section 3 is that $\\lambda$ is no longer a fixed constant but an unknown parameter that needs to be learned.\n4.1.1. Example (Navier–Stokes equation) Section 4.1.1 introduces an example related to real data of an incompressible fluid described by the Navier-Stokes equation. Consider the following 2-dimensional Navier-Stokes equation:\n$$ \\begin{equation} \\begin{aligned} u_{t} + \\lambda_{1}(uu_{x} + vu_{y}) \u0026amp;= -p_{x} + \\lambda_{2}(u_{xx} + u_{yy}) \\\\ v_{t} + \\lambda_{1}(uv_{x} + vv_{y}) \u0026amp;= -p_{y} + \\lambda_{2}(v_{xx} + v_{yy}) \\end{aligned} \\tag{15} \\end{equation} $$\nHere, $u(t,x,y)$ is the $x$ component of the fluid\u0026rsquo;s velocity vector, $v(t,x,y)$ is the $y$ component. And $p(t,x,y)$ is the pressure, $\\lambda = (\\lambda_{1}, \\lambda_{2})$ are unknown parameters. The solution to the Navier-Stokes equation satisfies the condition that the divergence is $0$, hence the following holds:\n$$ \\begin{equation} u_{x} + v_{y} = 0 \\tag{17} \\end{equation} $$\nLet\u0026rsquo;s assume some latent function $\\psi(t, x, y)$ such that:\n$$ u = \\psi_{y},\\quad v = -\\psi_{x} $$\nIn other words, the fluid\u0026rsquo;s velocity vector is set as $\\begin{bmatrix} \\psi_{y} \u0026amp; -\\psi_{x}\\end{bmatrix}$. This naturally satisfies $(17)$ since $u_{x} + v_{y} = \\psi_{yx} - \\psi_{xy} = 0$. Instead of obtaining $u$ and $v$ individually, we approximate $\\psi$ with an artificial neural network and derive $u, v$ as its partial derivatives. Let\u0026rsquo;s assume that the following measured information is available for the actual velocity vector field:\n$$ \\left\\{ t^{i}, x^{i}, y^{i}, u^{i}, v^{i} \\right\\}_{i=1}^{N} $$\nFrom this, we set the loss function as follows, remembering that $u = \\psi_{y}$ and $v = -\\psi_{x}$:\n$$ \\dfrac{1}{N} \\sum\\limits_{i=1}^{N} \\left( \\left| u(t^{i}, x^{i}, y^{i}) - u^{i} \\right|^{2} + \\left| v(t^{i}, x^{i}, y^{i}) - v^{i} \\right|^{2} \\right) $$\nAnd let\u0026rsquo;s rearrange the right-hand side of $(15)$ to the left-hand side and define them as $f$ and $g$, respectively.\n$$ \\begin{equation} \\begin{aligned} f \u0026amp;:= u_{t} + \\lambda_{1}(uu_{x} + vu_{y}) + p_{x} - \\lambda_{2}(u_{xx} + u_{yy}) \\\\ g \u0026amp;:= v_{t} + \\lambda_{1}(uv_{x} + vv_{y}) + p_{y} - \\lambda_{2}(v_{xx} + v_{yy}) \\end{aligned}\\tag{18} \\end{equation} $$\nThen the values of $f, g$ are expressed with $\\psi$ as follows. (Note that $p$ will also be approximated by a neural network)\n$$ \\begin{align*} f \u0026amp;= \\psi_{yt} + \\lambda_{1}(\\psi_{y} \\psi_{yx} - \\psi_{x}\\psi_{yy}) + p_{x} -\\lambda_{2}(\\psi_{yxx} + \\psi_{yyy}) \\\\ g \u0026amp;= -\\psi_{xt} + \\lambda_{1}(-\\psi_{y} \\psi_{xx} + \\psi_{x}\\psi_{xy}) + p_{y} + \\lambda_{2}(\\psi_{xxx} + \\psi_{xyy}) \\\\ \\end{align*} $$\nAdd the information that $f(t^{i}, x^{i}, y^{i}) = 0 = g(t^{i}, x^{i}, y^{i})$ to the loss function, and finally set it as follows:\n$$ \\begin{aligned} MSE \u0026amp;:= \\dfrac{1}{N} \\sum\\limits_{i=1}^{N} \\left( \\left| u(t^{i}, x^{i}, y^{i}) - u^{i} \\right|^{2} + \\left| v(t^{i}, x^{i}, y^{i}) - v^{i} \\right|^{2} \\right) \\\\ \u0026amp;\\qquad + \\dfrac{1}{N} \\sum\\limits_{i=1}^{N} \\left( \\left| f(t^{i}, x^{i}, y^{i}) \\right|^{2} + \\left| g(t^{i}, x^{i}, y^{i}) \\right|^{2} \\right) \\end{aligned} \\tag{19} $$\nNow let\u0026rsquo;s define an artificial neural network with $3$ input nodes and $2$ output nodes. Let\u0026rsquo;s assume its output to be $\\begin{bmatrix} \\psi(t, x, y) \u0026amp; p(t, x, y) \\end{bmatrix}$. Then, the above loss function can be computed.\nExperiments were conducted for cases with and without noise in the data, and in both cases, it was reported that $\\lambda_{1}, \\lambda_{2}$ could be predicted with high accuracy. It was also demonstrated that even if data for the pressure $p$ was not provided, the neural network could accurately approximate the parameters and $p$. The specific experimental settings, results, and how the reference solutions were obtained are detailed in the paper.\n5. Conclusions In this paper, we introduced the physics-informed neural network, a new structure of neural networks that is capable of encoding the physical laws satisfied by given data and can be described by partial differential equations. This result has revealed that deep learning can learn about physical models, which could be applied to various physical simulations.\nHowever, the authors note that the proposed method should not be considered as a replacement for traditional methods of solving partial differential equations, such as the finite element method or spectral methods. In fact, Runge-Kutta methods were utilized in conjunction with PINN in Section 3.2..\nThe authors also attempted to address questions about the hyperparameters required to implement PINN, such as how deep the neural network should be and how much data is needed. However, they observed that what is effective for one equation might not be effective for another.\n","id":3313,"permalink":"https://freshrimpsushi.github.io/en/posts/3313/","tags":null,"title":"Paper Review: Physics-Informed Neural Networks"},{"categories":"기하학","contents":"Overview We define the pullback on a differential manifold. If differential manifolds are complex, one can think of $M = \\mathbb{R}^{m}$ and $N = \\mathbb{R}^{n}$.\nDefinition1 Given two differential manifolds $M, N$ and a differentiable function $f : M \\to N$, we can consider a function $f^{\\ast}$ that maps $N$\u0026rsquo;s $k$-forms to $M$\u0026rsquo;s $k$-forms. Let $\\omega$ be a $k$-form on the manifold $N$, then a $k$-form $f^{\\ast}\\omega$ on the manifold $M$ is defined as the pullback of $\\omega$ as follows.\n$$ \\begin{equation} (f^{\\ast}\\omega)(p) (v_{1}, \\dots, v_{k}) := \\omega(f(p))\\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right),\\quad v_{i} \\in T_{p}M \\end{equation} $$\nExplanation The name pullback implies that, contrary to $f$ mapping from $M$ to $N$, $f^{\\ast}$ maps from $N$ to $M$. The definition and notation are quite complex, so let\u0026rsquo;s understand them step by step.\n$f^{\\ast}$ $f^{\\ast}$ is a map that sends $k$-forms of $N$ to $k$-forms of $M. Therefore, if $\\omega$ is a $k$-form of $N$, then $f^{\\ast}\\omega = f^{\\ast}(\\omega)$ is a $k$-form of $M.\n$f^{\\ast}\\omega(p)$ A $k$-form on the manifold $M$ maps $p \\in M$ to an element of $\\Lambda^{k}(T_{p}^{\\ast}M)$.\n$$ f^{\\ast}\\omega : M \\to \\Lambda^{k}(T_{p}^{\\ast}M) $$\n$$ \\Lambda^{k} (T_{p}^{\\ast}M) := \\left\\{ \\varphi : \\underbrace{T_{p}M \\times \\cdots \\times T_{p}M}_{k \\text{ times}} \\to \\mathbb{R}\\ | \\ \\varphi \\text{ is k-linear alternating map} \\right\\} $$\nIn other words, $f^{\\ast}\\omega(p) \\in \\Lambda^{k} (T_{p}^{\\ast}M)$ is also a function. By the definition of $\\Lambda^{k} (T_{p}^{\\ast}M)$, $f^{\\ast}\\omega(p)$ takes \u0026ldquo;$k$ tangent vectors at $p$\u0026rdquo; as variables. Thus, $(1)$ is the expression that specifically defines this function\u0026rsquo;s value. To emphasize that $f^{\\ast}(p)$ itself is a function, let\u0026rsquo;s use the following notation.\n$$ (f^{\\ast}\\omega)_{p} = f^{\\ast}\\omega(p) $$\n$\\omega(f(p))$ Since $\\omega$ is a $k$-form of $N$, it maps the point $f(p)$ of $N$ to an element of $\\Lambda^{k}(T_{f(p)}^{\\ast}N)$.\n$$ \\Lambda^{k} (T_{f(p)}^{\\ast}N) := \\left\\{ \\varphi : \\underbrace{T_{f(p)}N \\times \\cdots \\times T_{f(p)}N}_{k \\text{ times}} \\to \\mathbb{R}\\ | \\ \\varphi \\text{ is k-linear alternating map} \\right\\} $$\nBy the definition of $\\Lambda^{k} (T_{f(p)}^{\\ast}N)$, $\\omega(f(p))$ is also a function. $\\omega(f(p))$ takes \u0026ldquo;$k$ tangent vectors at $f(p)$\u0026rdquo; as variables. Here too, to emphasize that $\\omega(f(p))$ itself is a function, let\u0026rsquo;s use the following notation.\n$$ \\omega_{f(p)} = \\omega(f(p)) $$\n$df_{p}v_{i}$ $$ df_{p} : T_{p}M \\to T_{f(p)}N $$\nFor $f : M \\to N$, the differential $df_{p}$ of $f$ is defined as above. Therefore, if $v_{i} \\in T_{p}M$, then $df_{p}v_{i} = df_{p}(v_{i})$ is an element of $T_{f(p)}N$.\nNow, combining these, we obtain $(1)$.\n$$ (f^{\\ast}\\omega)_{p} (v_{1}, \\dots, v_{k}) := \\omega_{f(p)}\\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right),\\quad v_{i} \\in T_{p}M $$\nThe domains of these two functions show the following difference.\n$$ \\begin{align*} (f^{\\ast}\\omega)_{p} : \u0026amp;\u0026amp; \\underbrace{T_{p}M \\times \\cdots \\times T_{p}M}_{k \\text{ times}} \u0026amp;\\to \\mathbb{R} \\\\ \\omega_{f(p)} : \u0026amp;\u0026amp; \\underbrace{T_{f(p)}N \\times \\cdots \\times T_{f(p)}N}_{k \\text{ times}} \u0026amp;\\to \\mathbb{R} \\end{align*} $$\nThink of the differential $df_{p} : T_{p}M \\to T_{f(p)}N$ as bridging this difference. Hence, $df_{p}$ is also called push forward. For a $1$-form $\\varphi$, the following holds true.\n$$ \\begin{equation} \\varphi( dfv) = f^{\\ast}\\varphi(v) \\end{equation} $$\nPullback of $0$-forms Let\u0026rsquo;s consider $f : M \\to N$ as a function defined between two differential manifolds. Let $g : N \\to \\mathbb{R}$ be a function (a $0$-form of $N$). The pullback $f^{\\ast}g : M \\to \\mathbb{R}$ is defined as the following function (a $0$-form of $M$).\n$$ f^{\\ast}g := g \\circ f $$\nCoordinate Transformation Let\u0026rsquo;s assume a function $f : \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$ is given. Let $\\mathbf{x} = (x_{1}, \\dots ,x_{n}) \\in \\mathbb{R}^{n}$, and $\\mathbf{y} = (y_{1}, \\dots ,y_{m}) \\in \\mathbb{R}^{m}$.\n$$ f(x_{1}, \\dots, x_{n}) = (f_{1}(\\mathbf{x}), \\dots, f_{m}(\\mathbf{x}) )= (y_{1}, \\dots ,y_{m}) $$\nAnd let $\\omega = \\sum\\limits_{I} a_{I} dy_{I}$ be a $k$-form on $\\mathbb{R}^{m}$. Then the pullback $f^{\\ast}\\omega$ is as follows, based on these properties.\n$$ \\begin{align*} f^{\\ast} \\omega \u0026amp;= f^{\\ast} \\left( \\sum a_{I}dy_{I} \\right) \\\\ \u0026amp;= \\sum f^{\\ast} \\left( a_{I}dy_{I} \\right) \\\\ \u0026amp;= \\sum f^{\\ast}a_{I} f^{\\ast}dy_{I} \\\\ \u0026amp;= \\sum f^{\\ast}a_{I} f^{\\ast}(dy_{i1} \\wedge \\cdots \\wedge dy_{ik}) \\\\ \u0026amp;= \\sum f^{\\ast}a_{I} (f^{\\ast}dy_{i1} \\wedge \\cdots \\wedge f^{\\ast}dy_{ik}) \\end{align*} $$\nHere, due to $(2)$, $f^{\\ast}dy_{i1}(v) = dy_{i1}(df(v)) = d(y_{i1}\\circ f)(v) = df_{i1}(v)$, and $f^{\\ast}a_{I} = a_{I} \\circ f$, so,\n$$ \\begin{equation} f^{\\ast} \\omega = \\sum a_{I}(f_{1}, \\dots f_{m}) df_{i1} \\wedge \\cdots \\wedge df_{ik} \\end{equation} $$\nThis formula signifies coordinate transformation. Let\u0026rsquo;s see how it specifically works in the following example.\nExample Let\u0026rsquo;s assume a $1$-form $\\omega$ on $\\mathbb{R}^{2} \\setminus \\left\\{ 0, 0 \\right\\}$ is as follows.\n$$ \\omega = - \\dfrac{y}{x^{2} + y^{2}}dx + \\dfrac{x}{x^{2} + y^{2}}dy = a_{1}dx + a_{2}dy $$\nLet\u0026rsquo;s transform this $1$-form in Cartesian coordinates to polar coordinates. Let $U = \\left\\{ (r,\\theta) : 0 \\lt r, 0 \\le \\theta \\lt 2\\pi \\right\\}$. And let $f : U \\to \\mathbb{R}^{2}$ be as follows.\n$$ f(r,\\theta) = (r\\cos\\theta, r\\sin\\theta) = (f_{1}, f_{2}) $$\nNow, let\u0026rsquo;s calculate $df_{1}, df_{2}$. Since $f_{1} = r\\cos\\theta, f_{2}=r\\sin\\theta$,\n$$ \\begin{align*} df_{1} \u0026amp;= \\dfrac{\\partial f_{1}}{\\partial r}dr + \\dfrac{\\partial f_{1}}{\\partial \\theta}d\\theta = \\cos\\theta dr - r \\sin \\theta d\\theta \\\\ df_{2} \u0026amp;= \\dfrac{\\partial f_{2}}{\\partial r}dr + \\dfrac{\\partial f_{2}}{\\partial \\theta}d\\theta = \\sin\\theta dr + r \\cos \\theta d\\theta \\\\ \\end{align*} $$\nThen, by $(3)$,\n$$ \\begin{align*} f^{\\ast} \\omega \u0026amp;= a_{1}(f_{1}, f_{2})df_{1} + a_{2}(f_{1}, f_{2})df_{2} \\\\ \u0026amp;= - \\dfrac{f_{2}}{f_{1}^{2} + f_{2}^{2}}(\\cos\\theta dr - r \\sin \\theta d\\theta) + \\dfrac{f_{1}}{f_{1}^{2} + f_{2}^{2}}df_{2}(\\sin\\theta dr + r \\cos \\theta d\\theta) \\\\ \u0026amp;= - \\dfrac{r\\sin\\theta}{r^{2}\\cos^{2}\\theta + r^{2}\\sin^{2}\\theta}(\\cos\\theta dr - r \\sin \\theta d\\theta) \\\\ \u0026amp;\\quad + \\dfrac{r\\cos\\theta}{r^{2}\\cos^{2}\\theta + r^{2}\\sin^{2}\\theta}(\\sin\\theta dr + r \\cos \\theta d\\theta) \\\\ \u0026amp;= -\\dfrac{\\sin\\theta \\cos\\theta}{r}dr + \\sin^{2}\\theta d\\theta + \\dfrac{\\cos\\theta \\sin\\theta}{r}dr + \\cos^{2}\\theta d\\theta \\\\ \u0026amp;= d\\theta \\end{align*} $$\nTherefore,\n$$ \\int - \\dfrac{y}{x^{2} + y^{2}}dx + \\dfrac{x}{x^{2} + y^{2}}dy = \\int d\\theta $$\n■\nProperties Let $M, N$ be differential manifolds of dimensions $m, n$ respectively, and let $f : M \\to N$. Let $\\omega, \\varphi$ be $k$-forms on $N$. Let $g$ be a $0$-form on $N$. Let $\\varphi_{i}$s be $1$-forms on $N. Then, the following hold true.\n$$ \\begin{align} f^{\\ast} (\\omega + \\varphi) =\u0026amp;\\ f^{\\ast}\\omega + f^{\\ast}\\varphi \\tag{a} \\\\ f^{\\ast} (g \\omega) =\u0026amp;\\ (f^{\\ast}g) (f^{\\ast}\\omega) \\tag{b} \\\\ f^{\\ast} (\\varphi_{1} \\wedge \\cdots \\wedge \\varphi_{k}) =\u0026amp;\\ f^{\\ast}(\\varphi_{1}) \\wedge \\cdots \\wedge f^{\\ast}(\\varphi_{k}) \\tag{c} \\end{align} $$\nHere, $+$ and $\\wedge$ represent the sum and wedge product of $k$-forms, respectively.\nLet $\\omega, \\varphi$ be arbitrary forms on $N. Let $L$ be a $l$-dimensional differential manifold, and let $g : L \\to N$.\n$$ \\begin{align*} f^{\\ast}(\\omega \\wedge \\varphi) \u0026amp;= (f^{\\ast}\\omega) \\wedge (f^{\\ast}\\varphi) \\tag{d} \\\\ (f \\circ g)^{\\ast} \\omega \u0026amp;= g^{\\ast}(f^{\\ast}\\omega) \\tag{e} \\end{align*} $$\nProof Proof $(a)$ $$ \\begin{align*} (f^{\\ast}(\\omega + \\varphi))_{p} (v_{1}, \\dots, v_{k}) =\u0026amp;\\ (\\omega + \\varphi)_{f(p)} \\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right) \\\\ =\u0026amp;\\ \\omega_{f(p)} \\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right) + \\varphi_{f(p)} \\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right) \\\\ =\u0026amp;\\ (f^{\\ast} \\omega)_{p}(v_{1}, \\dots, v_{k}) + (f^{\\ast} \\varphi)_{p}(v_{1}, \\dots, v_{k}) \\\\ =\u0026amp;\\ \\left( f^{\\ast}\\omega + f^{\\ast}\\varphi \\right)_{p}(v_{1}, \\dots, v_{k}) \\end{align*} $$\n■\nProof $(b)$ Let\u0026rsquo;s define the product of a $0$-form $g$ and a $k$-form $\\omega$ as follows.\n$$ (g\\omega)(p) = g(p) \\omega(p) $$\nNote that $g(p) = g_{p}$ is a scalar, and $\\omega(p) = \\omega_{p}$ is a function. Then,\n$$ \\begin{align*} (f^{\\ast} (g\\omega))_{p} (v_{1}, \\dots, v_{k}) =\u0026amp;\\ g\\omega_{f(p)} \\left( df_{p}v_{1}, \\dots, df_{p}v_{k} \\right) \\\\ =\u0026amp;\\ g_{f(p)} \\omega_{f(p)} (df_{p}v_{1}, \\dots, df_{p}v_{k}) \\\\ =\u0026amp;\\ g\\circ f(p) \\omega_{f(p)} (df_{p}v_{1}, \\dots, df_{p}v_{k}) \\\\ =\u0026amp;\\ (f^{\\ast}g)_{p} (f^{\\ast}\\omega)_{p} (v_{1}, \\dots, v_{k}) \\end{align*} $$\n■\nProof $(c)$ $$ \\begin{align*} (f^{\\ast}\\left( \\varphi_{1} \\wedge \\cdots \\wedge \\varphi_{k} \\right))_{p} (v_{1}, \\dots, v_{k}) =\u0026amp;\\ (\\varphi_{1} \\wedge \\dots \\wedge \\varphi_{k})_{f(p)} \\left( df_{1}, \\dots, df_{k} \\right) \\\\ =\u0026amp;\\ \\det [\\varphi_{i}df(v_{j})] \\\\ =\u0026amp;\\ \\det [ f^{\\ast} \\varphi_{i}(v_{j})] \\\\ \\end{align*} $$\n■\nManfredo P. Do Carmo, Differential Forms and Applications, p6-8\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3262,"permalink":"https://freshrimpsushi.github.io/en/posts/3262/","tags":null,"title":"Pull Back in Differential Geometry"},{"categories":"확률미분방정식","contents":"Model 1 At time point $t$, let\u0026rsquo;s say the price of $S_{t}$ units of the underlying asset $1$, and assume that $S_{t}$ undergoes Geometric Brownian Motion. That is, for Standard Brownian Motion $W_{t}$, drift $\\mu \\in \\mathbb{R}$, and diffusion $\\sigma^{2} \u0026gt; 0$, $S_{t}$ is the solution to the following Stochastic Differential Equation. $$ d S_{t} = S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right) $$ When a risk-free rate $r \\in \\mathbb{R}$ is given, the price $F = F \\left( t, S_{t} \\right)$ of $1$ units of the derivative at time $t$ follows the following [Partial Differential Equation](../../categories/Partial Differential Equations). $$ r F = {{ \\partial F } \\over { \\partial t }} + r S_{t} {{ \\partial F } \\over { \\partial S_{t} }} + {{ 1 } \\over { 2 }} \\sigma^{2} S_{t}^{2} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} $$\nVariables $F \\left( t, S_{t} \\right)$: Derivatives refer to financial instruments such as futures and options. $S_{t}$: Underlying Assets are the commodities traded in derivatives, such as currency, bonds, and stocks. Parameters $r \\in \\mathbb{R}$: Represents the interest rate of Risk-free Assets. A typical example of a risk-free asset is a deposit. $\\sigma^{2} \u0026gt; 0$: Represents the market\u0026rsquo;s Volatility. Explanation Contrary to common misconceptions about derivatives, futures and options were created as means of hedging against uncertain futures. It was a way to reduce risk by paying a certain premium, even if it cost a bit. The problem was the lack of an appropriate method to price them, and traders traded derivatives based on experience. The Black-Scholes model is an equation that made it possible to mathematically explain the price of such derivatives.\nCommonly, the contributors to the Black-Scholes model (1973) are cited as Fischer Black, Myron Scholes, and Robert K. Merton, who introduced the \u0026lsquo;hedge-based derivation\u0026rsquo; in this post. Unfortunately, Black passed away in 1995, and Scholes and Merton were awarded the Nobel Prize in Economics in 1997. After the discovery of the Black-Scholes-Merton equation, the options market developed dazzlingly, and a new sub-discipline called financial engineering emerged in academia.\nThe Comedy of Black According to Wikipedia2, Black frequently changed majors during his PhD studies and had trouble settling down in one field. He switched from physics to mathematics, to computer science, and to artificial intelligence, but eventually made a significant contribution in economics.\nAlthough no reliable reference was found, it is said that Black, during his physics major, realized he couldn\u0026rsquo;t survive among the surrounding geniuses and became a pioneer in economics/finance, where there were no pioneers actively using mathematics, thus making a name for himself in a wasteland without science monsters.\nThe Tragedy of Scholes According to Namuwiki3, Scholes caused a sensation at the 1997 Nobel Economics Prize press conference by saying he would invest the prize money in stocks. The hedge fund Scholes was managing went bankrupt in 1998 due to overconfidence and excessive leverage, following Russia\u0026rsquo;s default. After the crisis, Scholes managed to return profits to investors and continued as a fund manager until retiring just before the subprime mortgage crisis erupted.\nAssumptions Before delving into the derivation, let\u0026rsquo;s check some assumptions.\nFactors such as commissions, taxes, and dividends are not considered Think of it as not considering resistance, temperature, or atmospheric pressure in a physics model, which are not the focus of the study. Additionally, it\u0026rsquo;s assumed that the trend $\\mu$ and $\\sigma$ are simply constants.\nDerivatives depend on the underlying assets and timing If the price of a derivative is independent of the underlying asset, there\u0026rsquo;s no need to use the terms \u0026lsquo;derivative\u0026rsquo; and \u0026lsquo;underlying\u0026rsquo;. It\u0026rsquo;s reasonable for the price of a derivative to change as the price of the underlying asset changes. If it doesn\u0026rsquo;t change over time (if it\u0026rsquo;s constant), then there\u0026rsquo;s no point in pondering the price of a derivative. Thus, it\u0026rsquo;s assumed that $F$ is a function of at least two factors $t$ and $S_{t}$, even if we can\u0026rsquo;t specify the exact form. $$ F = F \\left( t, S_{t} \\right) $$\nThe underlying asset undergoes Geometric Brownian Motion The primary application of Geometric Brownian Motion GBM is to explain the price fluctuations of underlying assets like stock prices. It assumes that the change in asset prices is proportional to the asset\u0026rsquo;s price, and that the price cannot become negative unless the asset is delisted, among other favorable assumptions. $$ d S_{t} = S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right) $$\nLet\u0026rsquo;s assume the price $p_{t}$ of some stock follows GBM. The return, defined as taking the log of dividing the closing price on day $t$ by the closing price on day $t-1$, $$ r_{t} = \\nabla \\log p_{t} = \\log {{ p_{t} } \\over { p_{t-1} }} $$ aligns with our intuition that the return should be positive if the price increases and negative if it decreases, regardless of the stock\u0026rsquo;s size. As explained in the \u0026ldquo;Log-normal Distribution\u0026rdquo; section, this return follows a normal distribution, focusing on the essence of growth and decay rather than simple fluctuations.\nRisk-free assets grow according to Malthusian growth The Malthusian growth model is the simplest model describing the growth of a population without any limitations or interventions and can be used as an assumption to explain the proliferation of risk-free assets in economics/finance. The risk-free rate is assumed to be a constant $r$, and the financial income is proportional to the size of asset $N_{t}$, so it can be expressed by the following [Ordinary Differential Equation](../../categories/Ordinary Differential Equations). $$ {{ d V_{t} } \\over { d t }} = r V_{t} $$\nArbitrage-free pricing: There\u0026rsquo;s no value difference between portfolios A mathematical explanation of the portfolio will be further detailed in this proof. The assumption of arbitrage-free pricing means that all portfolios we consider are balanced at the same value. For instance, if the value of portfolio $A$ is higher than $B$, a rational market participant would increase the proportion of the more valuable $A$ to make a profit, so there\u0026rsquo;s no reason to consider $B$. Therefore, it\u0026rsquo;s assumed that the portfolios we consider are already in a state where no further profits can be made through such arbitrage.\nFrictionless market: There are no restrictions on division and short selling Anyone who has traded stocks knows that there are minimum bidding units, so you can\u0026rsquo;t trade exactly the amount you want, and there are restrictions on short selling in the Korean stock market, where borrowed short selling (borrowing stocks) is the principle. Being able to divide trading units as desired and short sell without any restrictions can be considered as having no friction opposing actions.\nDerivation Part 1. Portfolio Composition\nLet\u0026rsquo;s assume we can only hold three types of assets:\nUnderlying Asset: Let\u0026rsquo;s say we hold $s$ units. Derivative: Let\u0026rsquo;s say we hold $f$ units. Risk-free Asset: An asset that is neither an underlying asset nor a derivative, which can be considered as cash. If we denote the value of all assets we hold at time $t$ as $V_{t}$, and if $S_{t}$ was the price of $1$ units of the underlying asset and $F \\left( t , S_{t} \\right)$ was the price of $1$ units of the derivative, it can be represented as follows. $$ V_{t} = f F \\left( t, S_{t} \\right) + s S_{t} $$ Composing a portfolio means adjusting the amounts of $f$ and $s$, in other words, strategizing on how to invest. Assuming that the trading volume generated by such portfolio composition significantly affects the market is irrational, so the prices of the underlying asset and derivative are independent of the choices of $f$ and $s$. In other words, the mathematical discussions that follow do not change regardless of how $f$ and $s$ are determined.\nIt\u0026rsquo;s important to note that $V_{t}$ is not the sum of the total assets. It\u0026rsquo;s easier to understand if you think of it as looking only at the stock balance, not the cash account. Let\u0026rsquo;s think about what portfolios could be:\nSavings $V_{t} = 0$: Clear the stock account and put everything into savings to receive interest. It might seem trivial to a scholar who knows nothing but mathematics, but it\u0026rsquo;s a legitimate strategy for dealing with market crashes or recessions. Individual Investor $V_{t} = 5 S_{t}$: Individuals should not touch derivatives. Most individual investors in countries where short selling is banned have this type of portfolio. For example, if $S_{t} = 81,200$ is the stock price of Samsung Electronics, this portfolio is my friend \u0026lsquo;Kim Soo-hyung\u0026rsquo;s account holding $5$ shares of Samsung Electronics. Hedge $\\displaystyle V_{t} = 1 \\cdot F- {{ \\partial F } \\over { \\partial S_{t} }} \\cdot S_{t}$: Consider buying a call option $1$ and short selling the underlying asset ${{ \\partial F } \\over { \\partial S_{t} }}$. If the price of the underlying asset increases significantly on the expiration date of the option, the call option will bring in a large profit, and if the price of the underlying asset falls, profit will have been made from the short sale early on. The options mentioned in the explanation of hedging and to be covered later are European Options, which are usually known as \u0026lsquo;options that can only be exercised on the expiration date\u0026rsquo;. American Options can be exercised at any time before maturity, but that\u0026rsquo;s not our concern here, so don\u0026rsquo;t be intimidated by the terms European and American.\nWe will derive the Black-Scholes equation from the last example, a portfolio that hedges a derivative with a spot short sale $$ V_{t} = 1 \\cdot F \\left( t, S_{t} \\right) - {{ \\partial F } \\over { \\partial S_{t} }} \\cdot S_{t} $$ Since it\u0026rsquo;s perfectly hedged, this portfolio is a risk-free asset, and the increment over time $t$ is $$ d V_{t} = d F - {{ \\partial F } \\over { \\partial S_{t} }} d S_{t} $$ Here, since $S_{t}$ is assumed to follow Geometric Brownian Motion, substituting $d S_{t}$ for $\\displaystyle S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right)$ yields $$ d V_{t} = d F - {{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right) $$ Considering the assumption of arbitrage-free pricing, the increment of this portfolio should be the same as that of a risk-free asset portfolio. If we assume there\u0026rsquo;s a price difference between the portfolios, profit could be made by liquidating one portfolio and investing in the other. Since we assumed risk-free assets grow according to Malthusian growth, the risk-free rate $r$ can be expressed by the following [Ordinary Differential Equation](../../categories/Ordinary Differential Equations). $$ {{ d V_{t} } \\over { d t }} = r V_{t} $$ Organizing these, we get $$ \\begin{align*} d V_{t} =\u0026amp; d F - {{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right) \\\\ d V_{t} =\u0026amp; r V_{t} dt \\end{align*} $$ thus, $$ \\begin{equation} r V_{t} dt = d F - {{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\left( \\mu dt + \\sigma d W_{t} \\right) \\label{1} \\end{equation} $$ is obtained. Now, let\u0026rsquo;s use Itô calculus to find $dF$.\nPart 2. Itô Calculus\nItô\u0026rsquo;s Lemma: Given an Itô Process $\\left\\{ X_{t} \\right\\}_{t \\ge 0}$, $$ d X_{t} = u dt + v d W_{t} $$ for function $V \\left( t, X_{t} \\right) = V \\in C^{2} \\left( [0,\\infty) \\times \\mathbb{R} \\right)$, if we set $Y_{t} := V \\left( t, X_{t} \\right)$, then $\\left\\{ Y_{t} \\right\\}$ is also an Itô Process, and the following holds. $$ \\begin{align*} d Y_{t} =\u0026amp; V_{t} dt + V_{x} d X_{t} + {{ 1 } \\over { 2 }} V_{xx} \\left( d X_{t} \\right)^{2} \\\\ =\u0026amp; \\left( V_{t} + V_{x} u + {{ 1 } \\over { 2 }} V_{xx} v^{2} \\right) dt + V_{x} v d W_{t} \\end{align*} $$\nIn Geometric Brownian Motion, distributing $S_{t}$ according to the distributive law gives $$ d S_{t} = \\mu S_{t} dt + \\sigma S_{t} d W_{t} $$ and, from Itô\u0026rsquo;s Lemma, since $u = \\mu S_{t}$ and $v = \\sigma S_{t}$, we obtain $$ d F = \\left( {{ \\partial F } \\over { \\partial t }} + {{ \\partial F } \\over { \\partial S_{t} }} \\mu S_{t} + {{ 1 } \\over { 2 }} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} \\sigma^{2} S_{t}^{2} \\right) dt + {{ \\partial F } \\over { \\partial S_{t} }} \\sigma S_{t} d W_{t} $$ Substituting this into $\\eqref{1}$ for $d F$ gives $$ \\begin{align*} r V_{t} dt =\u0026amp; d F - {{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\mu dt - {{ \\partial F } \\over { \\partial S_{t} }} \\sigma S_{t} d W_{t} \\\\ =\u0026amp; \\left( {{ \\partial F } \\over { \\partial t }} + {\\color{Red}{{ \\partial F } \\over { \\partial S_{t} }} \\mu S_{t}} + {{ 1 } \\over { 2 }} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} \\sigma^{2} S_{t}^{2} \\right) dt + {\\color{Blue}{{ \\partial F } \\over { \\partial S_{t} }} \\sigma S_{t} d W_{t}} \\\\ \u0026amp; - {\\color{Red}{{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\mu dt} - {\\color{Blue}{{ \\partial F } \\over { \\partial S_{t} }} \\sigma S_{t} d W_{t}} \\\\ =\u0026amp; {{ \\partial F } \\over { \\partial t }} dt + {{ 1 } \\over { 2 }} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} \\sigma^{2} S_{t}^{2} dt \\end{align*} $$ Since the portfolio\u0026rsquo;s value $V_{t}$ was defined as $\\displaystyle V_{t} = F- {{ \\partial F } \\over { \\partial S_{t} }} S_{t}$, substituting this yields $$ r \\left( F- {{ \\partial F } \\over { \\partial S_{t} }} S_{t} \\right) dt = {{ \\partial F } \\over { \\partial t }} dt + {{ 1 } \\over { 2 }} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} \\sigma^{2} S_{t}^{2} dt $$ Rearranging the equation for $rF$, we obtain the desired equation. $$ r F = {{ \\partial F } \\over { \\partial t }} + r S_{t} {{ \\partial F } \\over { \\partial S_{t} }} + {{ 1 } \\over { 2 }} \\sigma^{2} S_{t}^{2} {{ \\partial^{2} F } \\over { \\partial S_{t}^{2} }} $$\n■\nByung-Seon Choi. (2012). Various Derivations of the Black-Scholes Formula\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/Fischer_Black\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://namu.wiki/w/Black-Scholes%20model#s-5\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2156,"permalink":"https://freshrimpsushi.github.io/en/posts/2156/","tags":null,"title":"Derivation of Black-Scholes Model"},{"categories":"머신러닝","contents":"This article is written for math majors to understand the principles of the backpropagation algorithm.\nNotation Given an artificial neural network like the one shown above. Let $\\mathbf{x} = (x_{1}, x_{2}, \\dots, x_{n_{0}})$ be the inputinput, $y_{j}^{l}$ be the $j$th node of the $l$th layer, $\\hat{\\mathbf{y}} = (\\hat{y}_{1}, \\hat{y}_{2}, \\dots, \\hat{y}_{\\hat{n}})$ is the output output.\nLet $L \\in \\mathbb{N}$ be the number of hidden layers, and the components of $\\mathbf{n}=(n_{0}, n_{1}, \\dots, n_{L}, \\hat{n}) \\in \\mathbb{N}^{L+2}$ be the number of nodes in the input layer, $L$ hidden layers, and output layer, in that order. Also, for convenience, let the $0$th hidden layer be the input layer and the $L+1$th hidden layer be the output layer.\nLet $w_{ji}^{l}$ denote the weight connecting the $i$th node in the $l$th layer to the $j$th node in the next layer. Propagation from each layer to the next then occurs as shown in the image below.\nwhere $\\phi$ is an arbitrary activation function. Let us denote by $v_{i}^{l}$ the linear combination passed from the $l$th layer to the $j$th node of the next layer.\n$$ \\begin{align*} v_{j}^{l} \u0026amp;= \\sum _{i=1}^{n_{l}} w_{ji}^{l}y_{i}^{l} \\\\ y_{j}^{l+1} \u0026amp;= \\phi ( v_{j}^{l} ) = \\phi \\left( \\sum \\nolimits_{i=1}^{n_{l}} w_{ji}^{l}y_{i}^{l} \\right) \\end{align*} $$\nTo summarize, this looks like this\nSymbols Meaning $\\mathbf{x}=(x_{1}, x_{2}, \\dots, x_{n_{0}})$ input $y^{l}_{j}$ The $j$th node in the $l$th layer $\\hat{\\mathbf{y}} = (\\hat{y}_{1}, \\hat{y}_{2}, \\dots, \\hat{y}_{\\hat{n}} )$ output $n_{l}$ Number of nodes in the $l$th layer $w_{ji}^{l}$ The weight connecting the $i$th node in the $l$th layer to the $j$th node in the next layer. $\\phi$ Activation Functions $v_{j}^{l} = \\sum \\limits _{i=1} ^{n_{l}} w_{ji}^{l}y_{i}^{l}$ Linear Combination $y^{l+1}_{j} = \\phi (v_{j}^{l})$ Propagation from $l$th layer to next layer Theorem Let $E = E(\\hat{\\mathbf{y}})$ be a proper differentiable loss function, then the way to optimize $E$ is to update the weights $w_{ji}^{l}$ at each layer as follows. $$ \\begin{equation} w_{ji}^{l} \\leftarrow w_{ji}^{l} + \\alpha \\delta^{l}_{j} y_{i}^{l} \\label{thm} \\end{equation} $$\nWhere $\\alpha$ is the learning rate and $\\delta_{j}^{l}$ is as follows when $l=L$,\n$$ -\\delta_{j}^{L} = \\phi ^{\\prime} (v_{j}^{L}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{j}} $$\nFor $l \\in \\left\\{ 0,\\dots, L-1 \\right\\}$,\n$$ \\delta_{j}^{l} = \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i=1}^{n_{l}} \\delta_{i}^{l+1} w_{i j}^{l+1} $$\nExplanation Let\u0026rsquo;s look at $(1)$. It says that we rely on the $l$th nodes $y_{j}^{l}$ to update the weights between the $l$th and $l+1$th layers, which makes sense since the output of each layer ultimately determines the output $\\hat{\\mathbf{y}}$. Also, $y_{j}^{l}$ can be viewed as inputs as they propagate from the $l$th to the $l+1$th layer, which is similar to how a linear regression model is trained with LMSLeast Mean Squares.\n$$ \\mathbf{w} \\leftarrow \\mathbf{w} - \\alpha (\\mathbf{w}^{T}\\mathbf{x} - \\mathbf{y}) \\mathbf{x} $$\nThis optimization technique is called a back propagation algorithm because the outputs $y_{j}^{l}$ at each layer are computed from the input layer to the output layer, while the $\\delta_{j}^{l}$ for optimization are computed backwards from the output layer to the input layer as follows.\n$$ \\begin{align*} \\delta_{j}^{L} \u0026amp;= - \\phi ^{\\prime} (v_{j}^{L}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{j}} \\\\ \\delta_{j}^{L-1} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i} \\delta_{j}^{L} w_{ij}^{L} \\\\ \\delta_{j}^{L-2} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\delta_{i}^{L-1} w_{ij}^{L-1} \\\\ \\delta_{j}^{L-3} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-3}) \\sum _{i} \\delta_{i}^{L-2} w_{ij}^{L-2} \\\\ \u0026amp;\\vdots \\\\ \\delta_{j}^{1} \u0026amp;= \\phi ^{\\prime} (v_{j}^{1}) \\sum _{i} \\delta_{i}^{2} w_{ij}^{2} \\\\ \\delta_{j}^{0} \u0026amp;= \\phi ^{\\prime} (v_{j}^{0}) \\sum _{i} \\delta_{i}^{1} w_{ij}^{1} \\end{align*} $$\nProof Let\u0026rsquo;s say we\u0026rsquo;re done computing from the input layer to the output layer. We can modify the weights in such a way that the loss function $E$ decreases, using the gradient descent method.\n$$ \\begin{equation} w_{ji}^{l} \\leftarrow w_{ji}^{l} - \\alpha \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial w_{ji}^{l} } \\label{gradesent} \\end{equation} $$\nSince each $y_{i}^{l}$ is a given value, we can solve for the partial derivative in a computable form. The partial differential on the right hand side is given by the chain rule.\n$$ \\begin{equation} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial w_{ji}^{l}} = \\dfrac{\\partial E(\\hat{\\mathbf{y}}) }{\\partial v_{j}^{l}} \\dfrac{\\partial v_{j}^{l}}{\\partial w_{ji}^{l}} = \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial v_{j}^{l}} y_{i}^{l} \\label{chainrule} \\end{equation} $$\nLetting $-\\delta_{j}^{l}$ be the partial derivative of the right-hand side of $(3)$, we obtain $(1)$ from $(2)$.\n$$ w_{ji}^{l} \\leftarrow w_{ji}^{l} + \\alpha \\delta^{l}_{j} y_{i}^{l} $$\nFind $\\delta_{j}^{l}$ at each floor as follows.\nCase $l = L$\nFor $j \\in \\left\\{ 1, \\dots, \\hat{n} \\right\\}$, the following holds.\n$$ \\begin{equation} -\\delta_{j}^{L} = \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial v_{j}^{L}} = \\dfrac{\\partial E ( \\hat{\\mathbf{y}} ) } {\\partial \\hat{y}_{j}} \\dfrac{d \\hat{y}_{j}}{d v_{j}^{L}} \\label{deltamL} \\end{equation} $$\nSince $\\hat{y}_{j} =\\phi (v_{j}^{L})$, we get\n$$ -\\delta_{j}^{L} (t) =\\phi ^{\\prime} (v_{j}^{L}(t)) \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{j}} $$\n■\nCase $l = L-1$\nFor $j \\in \\left\\{ 1, \\dots, n_{L-1} \\right\\}$, we have\n$$ -\\delta_{j}^{L-1} = \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial v_{j}^{L-1}} = \\dfrac{\\partial E ( \\hat{\\mathbf{y}} ) } {\\partial y_{j}^{L}} \\dfrac{d y_{j}^{L}}{d v_{j}^{L-1}} $$\nSince $y_{j}^{L} =\\phi (v_{j}^{L-1})$, we get\n$$ -\\delta_{j}^{L-1} = \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial y_{j}^{L}} \\dfrac{\\partial y_{j}^{L}}{\\partial v_{j}^{L-1}} = \\phi ^{\\prime} (v_{j}^{L-1}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{L}} $$\nThe partial derivative on the right-hand side is computed by the chain rule as follows.\n$$ \\begin{align*} -\\delta_{j}^{L-1} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{L}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{\\partial \\hat{y}_{i}}{\\partial y_{j}^{L}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{d \\hat{y}_{i}}{d v_{i}^{L}} \\dfrac{\\partial v_{i}^{L}}{\\partial y_{j}^{L}} \\end{align*} $$\nHere, by $(4)$ and ${\\color{green}v_{i}^{L}=\\sum_{j}w_{ij}^{L}y_{j}^{L}}$, we get the following.\n$$ \\begin{align} \u0026amp;\u0026amp; -\\delta_{j}^{L-1} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i=1} {\\color{blue}\\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{\\partial \\hat{y}_{i}}{\\partial v_{i}^{L}}} {\\color{green} \\dfrac{d v_{i}^{L}}{d y_{j^{L}}} } \\nonumber \\\\ \u0026amp;\u0026amp; \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i} {\\color{blue} -\\delta_{i}^{L}} {\\color{green} w_{ij}^{L} }\\nonumber \\\\ {}\\nonumber \\\\ \\implies \u0026amp;\u0026amp; \\delta_{j}^{L-1} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-1}) \\sum _{i} \\delta_{i}^{L} w_{ij}^{L} \\label{deltajL-1} \\end{align} $$\n■\nCase $l = L-2$\nFor $j \\in \\left\\{ 1, \\dots, n_{L-2} \\right\\}$\n$$ -\\delta_{j}^{L-2} = \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial v_{j}^{L-2}} = \\dfrac{\\partial E ( \\hat{\\mathbf{y}} ) } {\\partial y_{j}^{L-1}} \\dfrac{d y_{j}^{L-1}}{d v_{j}^{L-2}} $$\nSince $y_{j}^{L-1} =\\phi (v_{j}^{L-2})$, we get\n$$ -\\delta_{j}^{L-2} = \\dfrac{\\partial E (\\hat{\\mathbf{y}})}{\\partial y_{j}^{L-1}} \\dfrac{d y_{j}^{L-1}}{d v_{j}^{L-2}} = \\phi ^{\\prime} (v_{j}^{L-2}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{L-1}} $$\nThe partial derivative on the right-hand side is computed by the chain rule as follows.\n$$ \\begin{align*} -\\delta_{j}^{L-2} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{L-1}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{\\partial \\hat{y}_{i}}{\\partial y_{j}^{L-1}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{d \\hat{y}_{i}}{d v_{i}^{L}} \\dfrac{\\partial v_{i}^{L}}{\\partial y_{j}^{L-1}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{d \\hat{y}_{i}}{d v_{i}^{L}} \\sum _{k} \\dfrac{\\partial v_{i}^{L}}{\\partial y_{k}^{L}} \\dfrac{\\partial y_{k}^{L}}{\\partial y_{j}^{L-1}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{d \\hat{y}_{i}}{d v_{i}^{L}} \\sum _{k} \\dfrac{\\partial v_{i}^{L}}{\\partial y_{k}^{L}} \\dfrac{d y_{k}^{L}}{d v_{k}^{L-1}} \\dfrac{\\partial v_{k}^{L-1}}{\\partial y_{j}^{L-1}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{k} \\sum _{i} {\\color{blue}\\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i}} \\dfrac{d \\hat{y}_{i}}{d v_{i}^{L}}} {\\color{red}\\dfrac{\\partial v_{i}^{L}}{\\partial y_{k}^{L}} } {\\color{green}\\dfrac{d y_{k}^{L}}{d v_{k}^{L-1}}} {\\color{purple}\\dfrac{d v_{k}^{L-1}}{\\partial y_{j}^{L-1}}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{k} \\sum _{i} {\\color{blue} -\\delta_{i}^{L}} {\\color{red} w_{ik}^{L}} {\\color{green} \\phi^{\\prime}(v_{k}^{L-1})} {\\color{purple} w_{kj}^{L-1}} \\end{align*} $$\nSo we get the following\n$$ \\delta_{j}^{L-2} = -\\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{k} \\sum _{i} \\delta_{i}^{L} w_{ik}^{L} \\phi^{\\prime}(v_{k}^{L-1}) w_{kj}^{L-1} $$\nThen, by $(5)$, the following holds.\n$$ \\sum _{i} \\delta_{i}^{L} w_{ik}^{L} \\phi^{\\prime}(v_{k}^{L-1}) = \\phi^{\\prime}(v_{k}^{L-1}) \\sum _{i} \\delta_{i}^{L} w_{ik}^{L} = \\delta_{k}^{L-1} $$\nTHerefore we get the following\n$$ \\begin{align*} \\delta_{j}^{L-2} \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{k} \\delta_{k}^{L-1} w_{kj}^{L-1} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{L-2}) \\sum _{i} \\delta_{i}^{L-1} w_{ij}^{L-1} \\end{align*} $$\n■\nGeneralization: $l \\in \\left\\{ 1, \\dots, L-1 \\right\\}$\nBased on the above results, we can generalize as follows for $j \\in \\left\\{ 1, \\dots, n_{l} \\right\\}$,\n$$ -\\delta_{j}^{l} = \\phi ^{\\prime} (v_{j}^{l}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{l}} $$\nSolving the partial derivative on the right-hand side by the chain rule is as follows.\n$$ \\begin{align*} \u0026amp;\\quad \\delta_{j}^{l} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\dfrac{\\partial E(\\hat{\\mathbf{y}})}{\\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{\\partial \\hat{y}_{i_{(1)}}}{\\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(2)}} \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{i_{(2)}}^{L}} \\frac{\\partial y_{i_{(2)}}^{L}}{\\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(2)}} \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{i_{(2)}}^{L}} \\frac{d y_{i_{(2)}}^{L}}{d v_{i_{(2)}}^{L-1}} \\frac{\\partial v_{i_{(2)}}^{L-1}}{\\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(3)}} \\sum_{i_{(2)}} \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{i_{(2)}}^{L}} \\frac{d y_{i_{(2)}}^{L}}{d v_{i_{(2)}}^{L-1}} \\frac{\\partial v_{i_{(2)}}^{L-1}}{\\partial y_{i_{(3)}}^{L-1} } \\frac{\\partial y_{i_{(3)}}^{L-1} }{ \\partial y_{j}^{l}} \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(3)}} \\sum_{i_{(2)}} \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{i_{(2)}}^{L}} \\frac{d y_{i_{(2)}}^{L}}{d v_{i_{(2)}}^{L-1}} \\frac{\\partial v_{i_{(2)}}^{L-1}}{\\partial y_{i_{(3)}}^{L-1} } \\frac{d y_{i_{(3)}}^{L-1} }{d v_{i_{(3)}}^{L-2} } \\frac{\\partial v_{i_{(3)}}^{L-2} }{ \\partial y_{j}^{l}} \\\\ \u0026amp; \\quad \\vdots \\\\ \u0026amp;= -\\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(L-l)}} \\cdots \\sum_{i_{(3)}} \\sum_{i_{(2)}} \\sum_{i_{(1)}} \\frac{\\partial E(\\hat{\\mathbf{y}})}{\\partial \\hat{y}_{i_{(1)}}} \\frac{d \\hat{y}_{i_{(1)}}}{d v_{i_{(1)}}^{L}} \\frac{\\partial v_{i_{(1)}}^{L}}{\\partial y_{i_{(2)}}^{L}} \\frac{d y_{i_{(2)}}^{L}}{d v_{i_{(2)}}^{L-1}} \\frac{\\partial v_{i_{(2)}}^{L-1}}{\\partial y_{i_{(3)}}^{L-1} } \\frac{d y_{i_{(3)}}^{L-1} }{d v_{i_{(3)}}^{L-2} } \\frac{\\partial v_{i_{(3)}}^{L-2} }{ \\partial y_{i_{(4)}}^{L-2}} \\cdots \\frac{d y_{i_{(L-l+1)}}^{l+1} }{d v_{i_{(L-l+1)}}^{l} } \\frac{\\partial v_{i_{(L-l+1)}}^{l} }{ \\partial y_{j}^{l}} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(L-l)}} \\cdots \\sum_{i_{(3)}} \\sum_{i_{(2)}} \\sum_{i_{(1)}} -\\delta_{i_{(1)}}^{L} w_{i_{(1)}i_{(2)}}^{L} \\phi^{\\prime}(v_{i_{(2)}}^{L-1}) w_{i_{(2)} i_{(3)}}^{L-1} \\phi^{\\prime}( v_{i_{(3)}}^{L-2} ) w_{i_{(3)} i_{(4)}}^{L-2} \\cdots \\phi^{\\prime}(v_{L-l+1}^{l})w_{i_{(L-l+1)} j}^{L} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(L-l)}} \\cdots \\sum_{i_{(3)}} \\sum_{i_{(2)}} \\delta_{i_{(2)}}^{L-1}w_{i_{(2)} i_{(3)}}^{L-1} \\phi^{\\prime}( v_{i_{(3)}}^{L-2} ) w_{i_{(3)} i_{(4)}}^{L-2} \\cdots \\phi^{\\prime}(v_{L-l+1}^{l})w_{i_{(L-l+1)} j}^{L} \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(L-l)}} \\cdots \\sum_{i_{(3)}} \\delta_{i_{(3)}}^{L-2} w_{i_{(3)} i_{(4)}}^{L-2} \\cdots w_{i_{(L-l)} j}^{L} \\\\ \u0026amp;\\quad \\vdots \\\\ \u0026amp;= \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i_{(L-l)}} \\delta_{i_{(L-l)}}^{l+1} w_{i_{(l-l)} j}^{l} \\end{align*} $$\nTherefore to summarize\n$$ \\delta_{j}^{l} = \\phi ^{\\prime} (v_{j}^{l}) \\sum_{i} \\delta_{i}^{l+1} w_{ij}^{l+1} $$\n■\n","id":3077,"permalink":"https://freshrimpsushi.github.io/en/posts/3077/","tags":null,"title":"Back Propagation Algorithm"},{"categories":"프로그래밍","contents":"Overview A commonly used RGB color palette.\nCode ","id":2013,"permalink":"https://freshrimpsushi.github.io/en/posts/2013/","tags":null,"title":"RGB Color Cheat Sheet"},{"categories":"머신러닝","contents":"Definition Reinforcement learning is the process where an agent interacts with the environment to find a policy that maximizes the cumulative reward.\nDescription1 The elements comprising reinforcement learning are as follows:\nAgentagent: Decides actions based on a policy, given a state. Statestate: Refers to the situation in which the agent is placed. Actionaction: Refers to the choices available to the agent in a given state. Policypolicy: Refers to the strategy according to which the agent decides its actions in a given state. Rewardreward: Refers to the score the agent receives based on the actions it chooses in a given state. It can be considered the goal the agent aims to achieve. Environmentenvironment: When the agent decides an action in a given state, according to the MDP (Markov Decision Process), the next state and the corresponding reward are determined. Episodeepisode: Refers to the period from when the interaction between the agent and the environment begins to when it ends. This can be analogized in various scenarios as follows:\nReinforcement Learning Studying for Exams Go Game Agent Student Go Player State Days Left Until Exam Go Board Action Study, Drinking, Gaming, etc. Placing a Stone Policy Study Plan per Day Strategy Reward Exam Score Win/Loss Episode Exam Period One Game Problem of Reinforcement Learning: Grid Model A typical example to explain reinforcement learning is the grid world. Let\u0026rsquo;s consider a robot that can move one square at a time in four directions: up, down, left, and right, in the following $4 \\times 4$ grid. The starting square is randomly chosen from $\\boxed{\\ 2\\ }$ to $\\boxed{15}$, and the goal is to reach $\\fcolorbox{black}{darkgray}{\\ 1\\ }$ or $\\fcolorbox{black}{darkgray}{16}$ in the shortest distance possible.\nAgent In reinforcement learning, the agent is the subject of learning, although it does not exist in reality. Unlike other concepts defined later, such as random variables, the agent does not have a clear mathematical definition. Therefore, it\u0026rsquo;s possible to study the theory of reinforcement learning without the concept of an agent, and indeed, this is often the case. Essentially, in the theory of reinforcement learning, the policy is what represents the agent. However, for convenience, it\u0026rsquo;s common to think of the learning subject as an entity and express it as 'the agent acts', 'the state of the agent has changed', etc. The agent is merely something that appears to be learning in computer simulations (especially games). For instance, the movement of an agent in the grid model can be expressed simply as a sequence of states. $$ \\boxed{\\ 3\\ } \\to \\boxed{\\ 2\\ } \\to \\fcolorbox{black}{darkgray}{\\ 1\\ } $$ You only need to print the sequence $3, 2, 1$. Ultimately, what we want to obtain from reinforcement learning is essentially a policy, so learning can occur even without defining an agent. In short, an agent can be considered the visualization (materialization) of a policy.\nOf course, the above is true in theory and computer simulations. In actual applications such as autonomous driving, there is a need for drones or cars that move according to policies. In this case, robots or machines like drones and cars become agents, and without them, learning the policy would be impossible.\nState The statestate is a random variable, denoted by $S$. As the episode progresses sequentially over time, we use the index $t$ for time. Hence, the state function at time $t$ is denoted as $S_t$. The initial state is usually represented as $t=0$. Summarizing, $S_t$ is a function that gives function values for each of the squares at time $t$.\n$$ S_{t} \\left( \\boxed{ N } \\right) = n,\\quad 1\\le n \\le 16 $$\nIn this case, the set of all possible state values (the function values of the state function) is denoted as $\\mathcal{S}\\subset \\mathbb{R}$, and its elements are denoted as $s$.\n$$ \\mathcal{S} = \\left\\{ s_{1}, s_{2},\\dots \\right\\} $$\nTherefore, the state function for the above grid model is as follows.\n$$ S_{t} : \\left\\{ \\fcolorbox{black}{darkgray}{\\ 1\\ } , \\boxed{\\ 2\\ }, \\dots, \\boxed{15}, \\fcolorbox{black}{darkgray}{16} \\right\\} \\to \\mathcal{S} \\\\ S_{t} \\left( \\boxed{\\ n\\ } \\right) = s_{n} = n,\\quad 1\\le n \\le 16 $$\nThen, the probability that the state value at time $t$ was $s_6$ and changes to $s_{10}$ in the next time step is as follows.\n$$ P \\left( S_{t+1} = s_{10} | S_{t} = s_{6} \\right) $$\nA state where the episode ends once reached is called a terminal state. In the above grid model, the terminal states are $\\fcolorbox{black}{darkgray}{1}, \\fcolorbox{black}{darkgray}{16}$.\nAction The actionaction refers to the choices the agent can make in the current state, and it is also a random variable. Denoted as $A_{t}$, it represents the action at time $t$. In the grid model example above, one can choose up, down, left, or right in each of the squares from $\\boxed{2}$ to $\\boxed{15}$. The set of all possible action values (the function values of the action function) is denoted as $\\mathcal{A}\\subset \\mathbb{R}$, and its elements are denoted as $a$.\n$$ \\mathcal{A} = \\left\\{ a_{1}, a_{2}, \\dots \\right\\} $$\nThen, the action function at time $t$ is as follows.\n$$ A_{t} : \\left\\{ \\uparrow, \\rightarrow, \\downarrow, \\leftarrow \\right\\} \\to \\mathcal{A} \\\\ \\begin{cases} A_{t}(\\uparrow) = a_{1} \\\\ A_{t}(\\rightarrow) = a_{2} \\\\ A_{t}(\\downarrow) = a_{3} \\\\ A_{t}(\\leftarrow) = a_{4} \\end{cases} $$\nThe agent decides its actions based on probabilities given the current state. For example, the probability of choosing action $a_1$ in state $s_6$ at time $t$ is as follows.\n$$ P(A_{t} = a_{1} | S_{t} = s_{6}) $$\nPolicy The policypolicy specifies the probability of deciding action $a$ in state $s$ for all $s$ and $a$, denoted as $\\pi$. It\u0026rsquo;s analogous to a strategy in a game or war. In the grid model example, if the probability of deciding each action is $\\dfrac{1}{4}$, the policy $\\pi$ is as follows.\n$$ \\pi \\begin{cases} P(a_{1} | s_{2}) = \\dfrac{1}{4} \\\\ P(a_{2} | s_{2}) = \\dfrac{1}{4} \\\\ P(a_{3} | s_{2}) = \\dfrac{1}{4} \\\\ \\vdots \\\\ P(a_{2} | s_{15}) = \\dfrac{1}{4} \\\\ P(a_{3} | s_{15}) = \\dfrac{1}{4} \\\\ P(a_{4} | s_{15}) = \\dfrac{1}{4} \\end{cases} \\quad \\text{or} \\quad \\pi : \\mathcal{S} \\times \\mathcal{A} \\to [0,1] $$\nOf course, this is not an optimized policy. Considering just the case of $\\boxed{2}$, it\u0026rsquo;s better not to have any probability of going upwards as it would go out of the grid. Therefore, $\\pi_2$ can be said to be a better policy than $\\pi_1$ as shown in the illustration below.\nThe goal of reinforcement learning algorithms is to find the optimal policy. The question then arises, how do we find the optimal policy? It can be found through the value functionvalue function, which evaluates the quality of a policy.\nReward The rewardreward is a function that maps a real number based on the action chosen by the agent in a given state, denoted as $R_t$. The set of all reward values (the function values of the reward function) is denoted as $\\mathcal{R} \\subset \\mathbb{R}$, and its elements are denoted as $r$.\n$$ \\mathcal{R} = \\left\\{ r_{1}, r_{2}, \\dots \\right\\} \\\\ R_{t} = \\mathcal{S} \\times \\mathcal{A} \\to \\mathcal{R} $$\nA reward is received once at each time step, and the ultimate goal of reinforcement learning is to find a policy that maximizes the cumulative reward, the total reward received in an episode.\nOne might wonder why we focus on maximizing cumulative rewards rather than rewards at each time step. This can be easily understood through the analogy of studying for exams. During the exam period, spending every evening drinking and partying or playing games might be more enjoyable than studying. However, the cumulative reward, i.e., the exam score, would be terrible. Hence, even if studying is tiring and challenging in the moment, it\u0026rsquo;s considered better for the sake of future greater rewards.\nThe reward is a hyperparameter set by a person and should be appropriately decided based on the task the agent must perform. For instance, in the grid model example, if the grid is a maze and the agent is a robot escaping the maze, a reward of $-1$ for moving one square and a reward of $+10$ for reaching a terminal state can be set. If the grid is a park and the agent is a robot walking a pet, a reward of $0$ for moving one square and a reward of $+10$ for reaching a terminal state can be set.\nEnvironment The environmentenvironment is a function that decides the next state and reward based on the action chosen by the agent in a given state, i.e., $f : (s,a) \\mapsto (s^{\\prime},r)$. Therefore, it\u0026rsquo;s always challenging to find a perfect analogy in reality.\nLet\u0026rsquo;s say the state at time $t$ is $s_t$, and the action chosen at $s_t$ is $a_t$. Then, the next state\ndecided by the environment is $s_{t+1}$, and the reward is $r_{t+1}$. It can be represented as follows.\n$$ f(s_{t}, a_{t}) = (s_{t+1}, r_{t+1}) $$\nIf in the grid model example, the agent chose $\\uparrow$ at $\\boxed{7}$ and the environment decided the next state to be $\\boxed{3}$ and the reward to be $-1$, it can be expressed with the following formula.\n$$ f(s_{7}, a_{1}) = (s_{3}, -1) $$\nIf the strategy by which the agent decides actions is called a policy, the environment\u0026rsquo;s decision of the next state and reward is called the MDPmarkov decision process. The interaction between the agent and the environment can be illustrated as follows.\nEpisode The sequence of states, actions, and rewards determined by the interaction between the agent and the environment is called a trajectory or history. When the trajectory is finite, it\u0026rsquo;s referred to as an episode task. The exam period, Go game, and grid model examples mentioned earlier fall into this category.\n$$ s_{0}, a_{0}, s_{1}, r_{1}, a_{1}, s_{2}, r_{2}, \\dots, a_{T-1}, s_{T}, r_{T} \\\\ \\text{or} \\\\ (s_{0},) \\overset{a_{0}}{\\to} (s_{1}, r_{1}) \\overset{a_{1}}{\\to} (s_{2}, r_{2}) \\overset{a_{2}}{\\to} \\cdots \\overset{a_{T-1}}{\\to} (s_{T}, r_{T}) $$\nWhen the trajectory is infinite, it\u0026rsquo;s referred to as a continuing task. However, very long episodes are sometimes considered infinite.\n$$ s_{0}, a_{0}, s_{1}, r_{1}, a_{1}, s_{2}, r_{2}, \\dots, a_{t-1}, s_{t}, r_{t}, a_{t}, s_{t+1}, r_{t+1},\\dots \\\\ \\text{or} \\\\ (s_{0},) \\overset{a_{0}}{\\to} (s_{1}, r_{1}) \\overset{a_{1}}{\\to} (s_{2}, r_{2}) \\overset{a_{2}}{\\to} \\cdots \\overset{a_{t-1}}{\\to} (s_{t}, r_{t}) \\overset{a_{t}}{\\to} (s_{t+1}, r_{t+1}) \\overset{a_{t+1}}{\\to} \\cdots $$\nO Il-Seok, Machine Learning (MACHINE LEARNING). 2017, p466-480\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3029,"permalink":"https://freshrimpsushi.github.io/en/posts/3029/","tags":null,"title":"What is Reinforcement Learning in Machine Learning"},{"categories":"수리물리","contents":"Definition For a scalar function $f=f(x,y,z)$, the following vector function is defined as the gradient of $f$, denoted by $\\nabla f$:\n$$ \\nabla f := \\frac{ \\partial f}{ \\partial x }\\hat{\\mathbf{x}}+\\frac{ \\partial f}{ \\partial y}\\hat{\\mathbf{y}}+\\frac{ \\partial f}{ \\partial z}\\hat{\\mathbf{z}} = \\left( \\dfrac{\\partial f}{\\partial x}, \\dfrac{\\partial f}{\\partial y}, \\dfrac{\\partial f}{\\partial z} \\right) $$\nExplanation The gradient is translated into English as gradient, slope, or incline. The terms \u0026lsquo;slope\u0026rsquo; and \u0026lsquo;incline\u0026rsquo; are old translations of the gradient and are not commonly used nowadays. Also, \u0026lsquo;slope\u0026rsquo; is a Sino-Korean word for gradient, so it\u0026rsquo;s essentially the same. The gradient is actually a vector, so the term \u0026lsquo;slope\u0026rsquo; seems insufficient to fully capture the meaning of the gradient. Here at Sashimi Sushi, we prefer to use the term \u0026lsquo;gradient\u0026rsquo; consistently.\nGeometrically, $\\nabla f$ represents the direction in which $f$ changes most rapidly. In other words, the direction in which the rate of increase of $f$ is highest at the point $(x,y,z)$ is the vector $\\left( \\dfrac{\\partial f(x,y,z)}{\\partial x}, \\dfrac{\\partial f(x,y,z)}{\\partial y}, \\dfrac{\\partial f(x,y,z)}{\\partial z} \\right)$. This is just an extension of the concept of differential coefficients to multiple dimensions. If $f$ is increasing, the differential coefficient is positive; if $f$ is decreasing, the coefficient is negative.\nMeanwhile, it\u0026rsquo;s important to note that $\\left( \\dfrac{\\partial f}{\\partial x}, \\dfrac{\\partial f}{\\partial y}, \\dfrac{\\partial f}{\\partial z} \\right)$ is denoted as $\\nabla f$ in the definition. While $\\nabla$ is called the del operator, thinking of it as having its own meaning can lead to misunderstandings, such as misinterpreting $\\nabla \\cdot \\mathbf{F}$ or $\\nabla \\times \\mathbf{F}$ as dot products or cross products. Thus, $\\nabla$ should be understood merely as a convenient notation, and it\u0026rsquo;s better to think of the gradient, divergence, and curl collectively as del operators, or even to consider the del operator as equivalent to the gradient. More details will follow below.\nPoints of Attention $\\nabla f$ is not the product of $\\nabla$ and $f$ An important aspect of understanding the gradient is recognizing that $\\nabla f$ is not the product of the vector $\\nabla = \\left( \\frac{\\partial }{\\partial x}, \\frac{\\partial }{\\partial y}, \\frac{\\partial }{\\partial z} \\right)$ and the scalar $f$. It may seem intuitive and appealing to interpret it this way, but it\u0026rsquo;s actually the opposite. $\\nabla$ is presented as a vector like $\\left( \\frac{\\partial }{\\partial x}, \\frac{\\partial }{\\partial y}, \\frac{\\partial }{\\partial z} \\right)$ to make it appear like a product of a vector and a scalar. If $\\nabla f$ were really the product of the vector $\\nabla$ and the scalar $f$, then, since the product of a vector and a scalar is commutative, the following strange equation would hold:\n$$ \\nabla f = \\left( \\dfrac{\\partial f}{\\partial x}, \\dfrac{\\partial f}{\\partial y}, \\dfrac{\\partial f}{\\partial z} \\right) \\overset{?}{=} \\left( f\\dfrac{\\partial }{\\partial x}, f\\dfrac{\\partial }{\\partial y}, f\\dfrac{\\partial }{\\partial z} \\right) = f\\nabla $$\nThis odd result arises because $\\nabla$ is not actually a vector, and $\\nabla f$ is not a product of a vector and a scalar. $\\nabla$ is an operator that maps the scalar function $f(x,y,z)$ to the vector function $\\left( \\frac{\\partial f(x,y,z)}{\\partial x}, \\frac{\\partial f(x,y,z)}{\\partial y}, \\frac{\\partial f(x,y,z)}{\\partial z} \\right)$. Let\u0026rsquo;s define a function $\\operatorname{grad}$ that takes $f$ as a variable like this:\n$$ \\begin{equation} \\operatorname{grad} (f) = \\left( \\dfrac{\\partial f}{\\partial x}, \\dfrac{\\partial f}{\\partial y}, \\dfrac{\\partial f}{\\partial z} \\right), \\quad f=f(x,y,z) \\end{equation} $$\nIn this definition, there is no need for explanations about the product of a vector and a scalar. $\\operatorname{grad}$ is just a function (operator) that, when given the variable $f$, follows the rule in $(1)$ to determine its function value. However, $\\operatorname{grad} (f)$\u0026rsquo;s function value, when denoted as $\\operatorname{grad} = \\nabla$, becomes a convenient and intuitive notation, and it\u0026rsquo;s helpful to explain it as a vector $\\nabla = \\left( \\frac{\\partial }{\\partial x}, \\frac{\\partial }{\\partial y}, \\frac{\\partial }{\\partial z} \\right)$.\nSimilarly to how Leibniz\u0026rsquo;s notation for differentiation isn\u0026rsquo;t an exact explanation of the underlying principle but is used for convenience and ease of understanding, $\\nabla f$ also appears as a product of a vector and a scalar for computational convenience, though that\u0026rsquo;s not its true nature.\nWhat about $f\\nabla$? Following the explanation above, since $\\nabla$ is a function, $\\nabla f = \\nabla(f)$ represents the function value obtained when the variable $f$ is substituted into the function $\\nabla$. On the other hand, $f \\nabla$ is a function in itself, which when another function $g$ is substituted as a variable, maps to a function value as follows:\n$$ (f\\nabla) (g) = f\\left( \\dfrac{\\partial g}{\\partial x}, \\dfrac{\\partial g}{\\partial y}, \\dfrac{\\partial g}{\\partial z} \\right) = \\left( f\\dfrac{\\partial g}{\\partial x}, f\\dfrac{\\partial g}{\\partial y}, f\\dfrac{\\partial g}{\\partial z} \\right) $$\nOf course, when looking at the function value $f \\nabla g$, it can be seen as substituting $g$ into $f \\nabla$, or as the product of the scalar function $f$ and the vector function $\\nabla g$.\nDerivation 1-Dimension Look at the above picture. The differential coefficient of $f_{1}$ at point $x=2$ is $4$. This value not only tells how much the function $f_{1}$ is inclined at $x=2$, but also indicates that the graph of $f_{1}$ increases in the direction where $x$ increases, as suggested by the $+$ sign in front of $4$. Therefore, the differential coefficient $4$ should be understood not merely as a scalar, but as a 1-dimensional vector $4\\hat{\\mathbf{x}}$.\nSimilarly, the differential coefficient of $f_{2}$ at $x=2$ is $-3$. This includes the meaning that the inclination is $3$ and also implies that as $x$ increases, the graph of $f_{2}$ decreases. In other words, if we think of the sign as indicating direction, the direction of the differential coefficient points towards where the graph of the function increases. Put differently, following the direction indicated by the differential coefficient leads to the peak of the graph.\nBefore extending to 3 dimensions, recall that the differential coefficient of $y$ at $x$, $\\dfrac{ d y}{ d x}=a$, can be written as if it were a fraction. Although this is not a mathematically rigorous way to handle differentiation, it helps understand the geometric meaning and has its advantages. Leibniz thought of $dy$ and $dx$ as very small changes in $y$ and $x$, respectively, and called the ratio between these changes the differential coefficient.\n$$ dy=adx $$\nAs an aside, this helps understand why $a$ is called a differential \u0026lsquo;coefficient\u0026rsquo;.\n3D Now, let\u0026rsquo;s assume a 3D scalar function $f=f(x,y,z)$ and a position vector $\\mathbf{r}=x\\hat{\\mathbf{x}}+y\\hat{\\mathbf{y}}+z\\hat{\\mathbf{z}}$ are given. The change in $f$ is expressed through total differentiation.\n$$ \\begin{equation} df=\\frac{ \\partial f}{ \\partial x }dx + \\frac{ \\partial f}{ \\partial y}dy+\\frac{ \\partial f}{ \\partial z}dz \\end{equation} $$\nThe change in $\\mathbf{r}$ is as follows:\n$$ d\\mathbf{r}=dx\\hat{\\mathbf{x}}+dy\\hat{\\mathbf{y}}+dz\\hat{\\mathbf{z}} $$\nNow, as in the 1D case, let\u0026rsquo;s find something that represents the ratio between $df$ and $d\\mathbf{r}$. Since $df$ is a scalar and $d\\mathbf{r}$ is a vector, that \u0026lsquo;something\u0026rsquo; must be a vector, and $df$ can be imagined as the dot product of that \u0026lsquo;something\u0026rsquo; with $d\\mathbf{r}$. Therefore, let\u0026rsquo;s denote that \u0026lsquo;something\u0026rsquo; as $\\mathbf{a}=a_{1}\\hat{\\mathbf{x}}+a_{2}\\hat{\\mathbf{y}}+a_{3}\\hat{\\mathbf{z}}$ and express it as follows:\n$$ \\begin{align*} df=\\mathbf{a}\\cdot d\\mathbf{r}\u0026amp;=(a_{1}\\hat{\\mathbf{x}}+a_{2}\\hat{\\mathbf{y}}+a_{3}\\hat{\\mathbf{z}})\\cdot(dx\\hat{\\mathbf{x}}+dy\\hat{\\mathbf{y}}+dz\\hat{\\mathbf{z}}) \\\\ \u0026amp;= a_{1}dx+a_{2}dy+a_{3}dz \\end{align*} $$\nComparing this with $(2)$ yields the following result:\n$$ \\mathbf{a}=\\frac{ \\partial f}{ \\partial x}\\hat{\\mathbf{x}}+\\frac{ \\partial f}{ \\partial y}\\hat{\\mathbf{y}}+\\frac{ \\partial f}{ \\partial z}\\hat{\\mathbf{z}} $$\nFrom now on, let\u0026rsquo;s denote this vector $\\mathbf{a}$ as $\\nabla f$ and call it the gradient of $f$. The direction of the gradient points to where the function $f$ increases most significantly, and its magnitude represents the extent of this increase.\nRelated Formulas Linearity:\n$$ \\nabla (f + g) = \\nabla f + \\nabla g $$\nProduct Rule:\n$$ \\nabla{(fg)}=f\\nabla{g}+g\\nabla{f} $$ $$ \\nabla(\\mathbf{A} \\cdot \\mathbf{B}) = \\mathbf{A} \\times (\\nabla \\times \\mathbf{B}) + \\mathbf{B} \\times (\\nabla \\times \\mathbf{A})+(\\mathbf{A} \\cdot \\nabla)\\mathbf{B}+(\\mathbf{B} \\cdot \\nabla) \\mathbf{A} $$\nSecond Derivative:\n$$ \\nabla \\cdot (\\nabla T) = \\dfrac{\\partial^{2} T}{\\partial x^{2}} + \\dfrac{\\partial ^{2} T} {\\partial y^{2}} + \\dfrac{\\partial ^{2} T}{\\partial z^{2}} $$ $$ \\nabla \\times (\\nabla T)= \\mathbf{0} $$ $$\\nabla (\\nabla \\cdot \\mathbf{A} ) $$\nFundamental Theorem of Gradient\n$$ T(b)-T(a) = \\int _{a}^{b} (\\nabla T) \\cdot d\\mathbf{l} $$\nIntegration Formulas\n$$ \\int_{\\mathcal{V}} (\\nabla T) d \\tau = \\oint_{\\mathcal{S}} T d \\mathbf{a} $$ $$ \\int_{\\mathcal{V}} \\left[ T \\nabla^{2} U + (\\nabla T) \\cdot (\\nabla U) \\right] d \\tau = \\oint_{\\mathcal{S}} (T \\nabla U) \\cdot d \\mathbf{a} $$ $$ \\int_{\\mathcal{V}} \\left( T \\nabla^{2} U - U \\nabla^{2} T \\right) d \\tau = \\oint_{\\mathcal{S}} \\left( T \\nabla U - U \\nabla T \\right) \\cdot d \\mathbf{a} $$ $$ \\int_{\\mathcal{S}} \\nabla T \\times d \\mathbf{a} = - \\oint_{\\mathcal{P}} T d \\mathbf{l} $$\nPartial Integration\n$$ \\int_{\\mathcal{V}}\\mathbf{A} \\cdot (\\nabla f)d\\tau = \\oint_{\\mathcal{S}}f\\mathbf{A} \\cdot d \\mathbf{a}-\\int_{\\mathcal{V}}f(\\nabla \\cdot \\mathbf{A})d\\tau $$ $$ \\int_{\\mathcal{S}} f \\left( \\nabla \\times \\mathbf{A} \\right)\\mathbf{A} \\cdot d \\mathbf{a} = \\int_{\\mathcal{S}} \\left[ \\mathbf{A} \\times \\left( \\nabla f \\right) \\right] \\cdot d\\mathbf{a} + \\oint_{\\mathcal{P}} f\\mathbf{A} \\cdot d\\mathbf{l} $$\nSee Also Del Operator $\\nabla$ Gradient $\\nabla f$ Divergence $\\nabla \\cdot \\mathbf{F}$ Curl $\\nabla \\times \\mathbf{F}$ Laplacian $\\nabla^{2} f$ ","id":1778,"permalink":"https://freshrimpsushi.github.io/en/posts/1778/","tags":null,"title":"Gradient of Scalar Function in Cartesian Coordinate System"},{"categories":"수리물리","contents":"Definition For a vector function $\\mathbf{F}(x,y,z)=(F_{x},F_{y},F_{z})=F_{x}\\hat{\\mathbf{x}} + F_{y}\\hat{\\mathbf{y}} + F_{z}\\hat{\\mathbf{z}}$, the following vector is defined as the curl of $\\mathbf{F}$, denoted as $\\nabla \\times \\mathbf{F}$.\n$$ \\begin{align} \\nabla \\times \\mathbf{F} \u0026amp;= \\left( \\dfrac{ \\partial F_{z}}{ \\partial y }-\\dfrac{ \\partial F_{y}}{ \\partial z} \\right)\\hat{\\mathbf{x}}+ \\left( \\dfrac{ \\partial F_{x}}{ \\partial z }-\\dfrac{ \\partial F_{z}}{ \\partial x} \\right)\\hat{\\mathbf{y}}+ \\left( \\dfrac{ \\partial F_{y}}{ \\partial x }-\\dfrac{ \\partial F_{x}}{ \\partial y} \\right)\\hat{\\mathbf{z}} \\label{def1} \\\\ \u0026amp;=\\begin{vmatrix} \\hat{\\mathbf{x}} \u0026amp; \\hat{\\mathbf{y}} \u0026amp; \\hat{\\mathbf{z}} \\\\ \\dfrac{ \\partial }{ \\partial x} \u0026amp; \\dfrac{ \\partial }{ \\partial y } \u0026amp; \\dfrac{ \\partial }{ \\partial z} \\\\ F_{x} \u0026amp; F_{y} \u0026amp;F_{z}\\end{vmatrix} \\label{def2} \\end{align} $$\n$(2)$ serves as an easy-to-remember formula for the curl of $\\mathbf{F}$. Think of it as a determinant and expand accordingly. Explanation Curl translates to rotation. However, since the term \u0026lsquo;rotation\u0026rsquo; is too common and may lead to confusion with rotation instead of curl, the term \u0026lsquo;curl\u0026rsquo; is preferred at the Fresh Shrimp Sushi Restaurant.\n$\\nabla \\times \\mathbf{F}$ is a vector that indicates in which direction the physical quantity $\\mathbf{F}$ is rotating. If you place the direction of $\\nabla \\times \\mathbf{F}$ as the axis (thumb) and apply the right-hand rule, the direction in which your right hand wraps around corresponds to the direction of rotation of $\\mathbf{F}$. The magnitude of the vector $\\nabla \\times \\mathbf{F}$ represents the extent of the rotation.\nUsing Einstein notation and Levi-Civita symbol, it can be expressed as follows. If $\\nabla_{j} = \\dfrac{\\partial }{\\partial x_{j}}$ is denoted,\n$$ \\nabla \\times \\mathbf{F} = \\epsilon_{ijk}\\hat{\\mathbf{e}}_{i}\\nabla_{j}F_{k} $$\nMeanwhile, note that the value denoted as $(1)$ in the definition is expressed as $\\nabla \\times \\mathbf{F}$. Although $\\nabla$ is referred to as the del operator, thinking of it as having a meaning on its own could easily lead to confusion, mistaking $\\nabla \\cdot \\mathbf{F}$ or $\\nabla \\times \\mathbf{F}$ as the dot product and cross product, respectively. Hence, it\u0026rsquo;s best to understand $\\nabla$ merely as a convenient notation, and it might be even better to think of the del operator as synonymous with the gradient. The del operators, encompassing the gradient, divergence, and curl, will be discussed in more detail below.\nPoints to Note $\\nabla \\times \\mathbf{F}$ is not the cross product of $\\nabla$ and $\\mathbf{F}$ $\\nabla \\times \\mathbf{F}$ is definitely not the cross product of $\\nabla$ and $\\mathbf{F}$.\r$\\nabla \\times \\mathbf{F}$ is merely a vector containing some information about $\\mathbf{F}$. We think of $\\nabla$ as a vector like $\\nabla = \\dfrac{ \\partial }{ \\partial x}\\hat{\\mathbf{x}} + \\dfrac{ \\partial }{ \\partial y}\\hat{\\mathbf{y}} + \\dfrac{ \\partial }{ \\partial z}\\hat{\\mathbf{z}}$, and the result matches perfectly with $(1)$, so it\u0026rsquo;s denoted as $\\nabla \\times \\mathbf{F}$ for convenience. Assuming $\\nabla$ is an actual vector would lead to strange results.\nThe following equation holds for two vectors $\\mathbf{A}, \\mathbf{B}$:\n$$ \\nabla \\times (\\mathbf{A} \\times \\mathbf{B}) = (\\mathbf{B} \\cdot \\nabla)\\mathbf{A} - (\\mathbf{A} \\cdot \\nabla)\\mathbf{B} + \\mathbf{A} (\\nabla \\cdot \\mathbf{B}) - \\mathbf{B} (\\nabla \\cdot \\mathbf{A}) $$\nIf $\\nabla$ were truly a vector, we could substitute it into the above formula and obtain the following results.\n$$ \\nabla \\times (\\nabla \\times \\mathbf{F})=(\\mathbf{F} \\cdot \\nabla)\\nabla - (\\nabla \\cdot \\nabla)\\mathbf{F} + \\nabla (\\nabla \\cdot \\mathbf{F}) - \\mathbf{F} (\\nabla \\cdot \\nabla) $$\nHowever, the correct result is as follows.\n$$ \\nabla \\times (\\nabla \\times \\mathbf{F})=\\nabla(\\nabla \\cdot \\mathbf{F})-\\nabla ^{2} \\mathbf{F} $$\nAnother example exists. Since the cross product of vectors has the property of anticommutativity, if $\\nabla \\times \\mathbf{F}$ were a cross product, the following equation should hold:\n$$ \\nabla \\times \\mathbf{F} \\overset{?}{=} - \\mathbf{F} \\times \\nabla $$\nTherefore, $\\nabla$ is not a vector, and it can be understood that $\\nabla \\times \\mathbf{F}$ is not the cross product of $\\nabla$ and $\\mathbf{F}$. Instead of being a vector, $\\nabla \\times$ should be considered as a function in itself. In physics, functions that take other functions as variables are called operators.\nSo, what\u0026rsquo;s the difference between $\\nabla \\times \\mathbf{F}$ and $\\mathbf{F} \\times \\nabla$? $\\nabla \\times$ is an operator defined as follows, taking a vector function as its variable:\n$$ \\nabla \\times (\\mathbf{F}) = \\left( \\dfrac{ \\partial F_{z}}{ \\partial y }-\\dfrac{ \\partial F_{y}}{ \\partial z} \\right)\\hat{\\mathbf{x}}+ \\left( \\dfrac{ \\partial F_{x}}{ \\partial z }-\\dfrac{ \\partial F_{z}}{ \\partial x} \\right)\\hat{\\mathbf{y}}+ \\left( \\dfrac{ \\partial F_{y}}{ \\partial x }-\\dfrac{ \\partial F_{x}}{ \\partial y} \\right)\\hat{\\mathbf{z}} $$\nIn other words, $\\nabla \\times \\mathbf{F}$ is the function value when the variable $\\mathbf{F}$ is substituted into the operator (function) $\\nabla \\times$. Of course, this in turn is a vector function of the variables $(x,y,z)$. While $\\nabla \\times \\mathbf{F}$ is the function value of $\\nabla \\times$, $\\mathbf{F} \\times \\nabla$ is an operator in itself. Although it\u0026rsquo;s not a commonly used expression, it can be defined as the following differential operator if we were to define it.\n$$ \\begin{align*} \\mathbf{F} \\times \\nabla \u0026amp;= \\begin{vmatrix} \\hat{\\mathbf{x}} \u0026amp; \\hat{\\mathbf{y}} \u0026amp; \\hat{\\mathbf{z}} \\\\ F_{x} \u0026amp; F_{y} \u0026amp;F_{z} \\\\ \\dfrac{ \\partial }{ \\partial x} \u0026amp; \\dfrac{ \\partial }{ \\partial y } \u0026amp; \\dfrac{ \\partial }{ \\partial z} \\end{vmatrix} \\\\ \u0026amp;= \\left( F_{y}\\dfrac{ \\partial }{ \\partial z} - F_{z}\\dfrac{ \\partial }{ \\partial y} \\right)\\hat{\\mathbf{x}} + \\left( F_{z}\\dfrac{ \\partial }{ \\partial x} - F_{x}\\dfrac{ \\partial }{ \\partial z} \\right)\\hat{\\mathbf{y}} + \\left( F_{x}\\dfrac{ \\partial }{ \\partial y} - F_{y}\\dfrac{ \\partial }{ \\partial x} \\right)\\hat{\\mathbf{z}} \\end{align*} $$\nDerivation Now, let\u0026rsquo;s consider a function that indicates the direction of rotation (clockwise or counterclockwise) of a rotating vector function. It\u0026rsquo;s important to note that no direction within the plane of rotation can specify the direction of rotation. Look at the diagram below.\nVector $-\\hat{\\mathbf{x}}$ can explain the movement at point $A$, but not at point $B$. Vector $\\hat{\\mathbf{y}}$ can explain the movement at point $C$, but not at point $D$. Vector $\\hat{\\mathbf{x}} + \\hat{\\mathbf{y}}$ can explain the path $F$, but not $G$. This is also true for clockwise rotation. Now, you should sense the need to move out of the plane of rotation to specify the direction of rotation. In fact, there\u0026rsquo;s already a good method to determine this: using the right-hand rule, which determines the axis of rotation in the direction of the thumb when the right hand wraps around. Therefore, in the $xy$-plane, the axis (direction) of counterclockwise rotation is $\\hat{\\mathbf{z}}$, and the axis (direction) of clockwise rotation is $-\\hat{\\mathbf{z}}$.\nNow, let\u0026rsquo;s find a value that indicates the $\\hat{\\mathbf{z}}$ direction when $\\mathbf{F}$ is rotating counterclockwise in the $xy$-plane, in other words, a positive value. Let\u0026rsquo;s represent the rotation simply with a rectangle as below.\nPath ① moves from point $a$ to point $b$, and let\u0026rsquo;s say $\\mathbf{F}(a) = (1,0,0)$ and $\\mathbf{F}(b) = (0,1,0)$. Then, as $x$ changes by +1 from point $a$ to $b$, and $F_{y}$ also changes by +1, we obtain the following.\n$$ \\dfrac{\\partial F_{y}}{\\partial x} \\gt 0 $$\nIn the same manner, on the path where the point moves from $b$ to $c$, $y$ changes by +1, and $F_{x}$ changes by -1. Checking all four paths, we find that:\n$$ \\dfrac{\\partial F_{y}}{\\partial x} \\gt 0 \\quad \\text{in path $\\textcircled{1}$, $\\textcircled{3}$} $$\n$$ \\dfrac{\\partial F_{x}}{\\partial y} \\lt 0 \\quad \\text{in path $\\textcircled{2}$, $\\textcircled{4}$} $$\nTherefore, for a vector $\\mathbf{F}$ that rotates counterclockwise as above, the value below is always positive:\n$$ \\dfrac{\\partial F_{y}}{\\partial x} - \\dfrac{\\partial F_{x}}{\\partial y} \\gt 0 $$\nConversely, if $\\mathbf{F}$ is rotating clockwise, the above value is always negative. Now, we can define the operator $\\operatorname{curl}_{xy}$, which indicates the direction and magnitude of rotation in the $xy$-plane when the vector function $\\mathbf{F}$ is substituted:\n$$ \\operatorname{curl}_{xy} (\\mathbf{F}) = \\left( \\dfrac{\\partial F_{y}}{\\partial x} - \\dfrac{\\partial F_{x}}{\\partial y} \\right) \\hat{\\mathbf{z}} $$\nThe sign of the $\\hat{\\mathbf{z}}$ component of this function indicates the direction of rotation of $\\mathbf{F}$ in the $xy$-plane: If it\u0026rsquo;s positive (+), $\\mathbf{F}$ rotates counterclockwise in the $xy$-plane. If it\u0026rsquo;s negative (-), $\\mathbf{F}$ rotates clockwise in the $xy$-plane. If it\u0026rsquo;s zero (0), there is no rotation. The magnitude of the $\\hat{\\mathbf{z}}$ component of this function indicates how rapidly $\\mathbf{F}$ is rotating in the $xy$-plane. Applying this discussion similarly to the $yz$-plane and the $zx$-plane, we can define the vector $\\nabla \\times \\mathbf{F}$, which indicates the direction and magnitude of rotation of $\\mathbf{F}$ in 3-dimensional space, as follows.\n$$ \\nabla \\times \\mathbf{F} := \\left( \\dfrac{\\partial F_{z}}{\\partial y} - \\dfrac{\\partial F_{y}}{\\partial z} \\right)\\hat{\\mathbf{x}} + \\left( \\dfrac{\\partial F_{x}}{\\partial z} - \\dfrac{\\partial F_{z}}{\\partial x} \\right)\\hat{\\mathbf{y}} + \\left( \\dfrac{\\partial F_{y}}{\\partial x} - \\dfrac{\\partial F_{x}}{\\partial y} \\right)\\hat{\\mathbf{z}} $$\n■\nRelated formulas Linearity: $$ \\nabla \\times (\\mathbf{A} + \\mathbf{B}) = \\nabla \\times \\mathbf{A} + \\nabla \\times \\mathbf{B} $$\nMultiplication rule:\n$$ \\nabla \\times (f\\mathbf{A}) = f(\\nabla \\times \\mathbf{A}) - \\mathbf{A} \\times (\\nabla f) $$\n$$ \\nabla \\times (\\mathbf{A} \\times \\mathbf{B}) = (\\mathbf{B} \\cdot \\nabla)\\mathbf{A} - (\\mathbf{A} \\cdot \\nabla)\\mathbf{B} + \\mathbf{A} (\\nabla \\cdot \\mathbf{B}) - \\mathbf{B} (\\nabla \\cdot \\mathbf{A}) $$\n2nd derivative:\n$$ \\nabla \\times (\\nabla f) = \\mathbf{0} $$\n$$ \\nabla \\times (\\nabla \\times \\mathbf{F}) = \\nabla (\\nabla \\cdot \\mathbf{F}) - \\nabla^{2} \\mathbf{F} $$\nStokes\u0026rsquo; theorem $$ \\int_{\\mathcal{S}} (\\nabla \\times \\mathbf{v} )\\cdot d\\mathbf{a} = \\oint_{\\mathcal{P}} \\mathbf{v} \\cdot d\\mathbf{l} $$\nIntegral formulas $$ \\int_{\\mathcal{V}} (\\nabla \\times \\mathbf{v}) d \\tau = - \\oint_{\\mathcal{S}} \\mathbf{v} \\times d \\mathbf{a} $$\n$$ \\int_{\\mathcal{S}} \\nabla T \\times d \\mathbf{a} = - \\oint_{\\mathcal{P}} T d \\mathbf{l} $$\nIntegration by parts $$ \\int_{\\mathcal{S}} f \\left( \\nabla \\times \\mathbf{A} \\right)\\mathbf{A} \\cdot d \\mathbf{a} = \\int_{\\mathcal{S}} \\left[ \\mathbf{A} \\times \\left( \\nabla f \\right) \\right] \\cdot d\\mathbf{a} + \\oint_{\\mathcal{P}} f\\mathbf{A} \\cdot d\\mathbf{l} $$\n$$ \\int_{\\mathcal{V}} \\mathbf{B} \\cdot \\left( \\nabla \\times \\mathbf{A} \\right) d\\tau = \\int_{\\mathcal{V}} \\mathbf{A} \\cdot \\left( \\nabla \\times \\mathbf{B} \\right) d\\tau + \\oint_{\\mathcal{S}} \\left( \\mathbf{A} \\times \\mathbf{B} \\right) \\cdot d \\mathbf{a} $$\nProof Linearity Using Einstein notation and Levi-Civita symbol, if we denote $\\nabla_{j} = \\dfrac{\\partial }{\\partial x_{j}}$, then:\n$$ \\begin{align*} \\left[ \\nabla \\times (\\mathbf{A} + \\mathbf{B}) \\right]_{i} \u0026amp;= \\epsilon_{ijk} \\nabla_{j} (\\mathbf{A} + \\mathbf{B})_{k} \\\\ \u0026amp;= \\epsilon_{ijk} \\nabla_{j} (A_{k} + B_{k}) \\\\ \u0026amp;= \\epsilon_{ijk} \\nabla_{j}A_{k} + \\epsilon_{ijk} \\nabla_{j}B_{k} \\\\ \u0026amp;= [\\nabla \\times \\mathbf{A}]_{i} + [\\nabla \\times \\mathbf{B}]_{i} \\\\ \\end{align*} $$\nThe third equality holds because $\\dfrac{\\partial (A_{k} + B_{k})}{\\partial x_{j}} = \\dfrac{\\partial A_{k}}{\\partial x_{j}} + \\dfrac{\\partial B_{k}}{\\partial x_{j}}$. ■\nFurther reading Del Operator $\\nabla$ Gradient $\\nabla f$ Divergence $\\nabla \\cdot \\mathbf{F}$ Curl $\\nabla \\times \\mathbf{F}$ Laplacian $\\nabla^{2} f$ ","id":1752,"permalink":"https://freshrimpsushi.github.io/en/posts/1752/","tags":null,"title":"Curl of Vector Functions in 3D Cartesian Coordinates"},{"categories":"거리공간","contents":"Definition For $a_i,b_i \\in \\mathbb{R} (1\\le i \\le k)$, the set $I=[a_{1},b_{1}] \\times [a_{2},b_{2}]\\times \\cdots \\times [a_{k},b_{k}]$ is called a $k$-cellk-cell. Here, $\\times$ represents the Cartesian product of sets.\nTheorem 1 Let\u0026rsquo;s assume a sequence of closed intervals on $\\mathbb{R}$, $\\left\\{ I_{n} \\right\\}$, satisfies $I_{n}\\supset I_{n+1}\\ (n=1,2,\\cdots)$. Then, the following holds true.\n$$ \\bigcap_{i=1}^{\\infty}I_{n}\\ne \\varnothing $$\nProof Let\u0026rsquo;s denote $I_{n}=[a_{n},b_{n}]$. Also, let $E=\\left\\{ a_{n} : n=1,2,\\cdots \\right\\}$. Then, $E\\ne \\varnothing$ and is upper bounded by $b_{1}$1. Now, let\u0026rsquo;s define $x=\\sup E$. For any two positive numbers $m$ and $n$,\n$$ a_{n} \\le a_{m+n} \\le b_{m+n} \\le b_{m} $$\nholds true, thus for all $n$, $x\\le b_{n}$. Moreover, since $x$ is the upper bound of $E$, it\u0026rsquo;s trivial that for all $n$, $a_{n} \\le x$. Therefore, for all $n$, $a_{n}\\le x \\le b_{n}$, which implies $x\\in I_{n}\\ \\forall n$. Thus,\n$$ x\\in \\bigcap _{i=1}^{n}I_{n} $$\n■\nTheorem 2 Let $\\left\\{ I_{n} \\right\\}$ be a sequence of $k$-cells satisfying $I_{n}\\supset I_{n+1}(n=1,2,\\cdots)$. Then, $\\bigcap _{i=1}^{n}I_{n}\\ne\\varnothing$.\nTheorem 2 is an extension of Theorem 1 to $\\mathbb{R}^{k}$.\nProof Let\u0026rsquo;s represent $I_{n}$ as follows.\n$$ I_{n}=\\left\\{ \\mathbf{x}=(x_{1},\\cdots,x_{k}) : a_{n,j} \\le x_{j} \\le b_{nj},\\quad(1\\le j \\le k;\\ n=1,2,\\cdots) \\right\\} $$\nThat is, $I_{n}=I_{n,1}\\times \\cdots\\times I_{n,k}\\ (I_{n,j}=[a_{n,j},b_{n,j}])$. By Theorem 1, for each $I_{n,j}$, there exists $x_{j}^{\\ast}\\in I_{n,j} \\ (a_{n,j} \\le x_{j}^{\\ast} \\le b_{n,j})$. Therefore,\n$$ \\mathbf{x^{\\ast}} =(x_{1}^{\\ast},\\cdots ,x_{k}^{\\ast})\\in I_{n} ,\\quad (n=1,2,\\cdots) $$\n■\nTheorem 3 Every $k$-cell is compact.\nProof Let\u0026rsquo;s consider an arbitrary $k$-cell $I$ as follows.\n$$ I=I^{1}\\times \\cdots \\times I^{k}=[a_{1},b_{1}]\\times \\cdots \\times [a_{k},b_{k}] $$\nAnd let\u0026rsquo;s define as follows.\n$$ \\mathbf{x}=(x_{1},\\cdots,x_{k}) \\quad \\text{and} \\quad a_{j} \\le x_{j} \\le b_{j}(1\\le j \\le k) $$\nNow, let\u0026rsquo;s consider $\\delta$ as follows.\n$$ \\delta =\\left( \\sum \\limits_{j=1}^{k}(b_{j})-a_{j})^{2} \\right)^{{\\textstyle \\frac{1}{2}}}=|\\mathbf{b}-\\mathbf{a}| $$\nHere, $\\mathbf{a}=(a_{1},\\cdots,a_{n})$, $\\mathbf{b}=(b_{1},\\cdots,b_{n})$. Then, $\\delta$ is the same as the distance between $\\mathbf{b}$ and $\\mathbf{a}$. Therefore,\n$$ |\\mathbf{x}-\\mathbf{y}| \\le \\delta \\quad \\forall \\mathbf{x},\\mathbf{y}\\in I $$\nis valid. Now the proof begins in earnest, using a proof by contradiction. That is, assume that a $k$-cell is not compact. Then, by the definition of compactness, it\u0026rsquo;s the same as assuming that some open cover $\\left\\{ O_{\\alpha} \\right\\}$ of $I$ does not have a finite subcover. Let\u0026rsquo;s denote $c_{j}=(a_{j}+b_{j})/2$. Then, each $I^{j}$ can be divided into $[a_{j},c_{j}]$, $[c_{j},b_{j}]$ using $c_{j}$, creating $2^{k}$ 1-cells. Their union is naturally $I$, and by assumption, at least one of them cannot be covered by any finite subcover of $\\left\\{ O_{\\alpha} \\right\\}$. Let\u0026rsquo;s call this cell $I_{1}$. Then, by choosing intervals in the same way as $I_{1}$ was chosen from $I$, we can obtain a sequence $\\left\\{ I_{n} \\right\\}$ satisfying the following three rules.\n$(\\mathrm{i})$ $I\\supset I_{1} \\supset I_{2}\\supset \\cdots$\n$(\\mathrm{ii})$ Each $I_{n}$ cannot be covered by any finite subcover of $\\left\\{ O_{\\alpha} \\right\\}$.\n$(\\mathrm{iii})$ $|\\mathbf{x}-\\mathbf{y}|\\le 2^{-n}\\delta,\\quad \\forall \\mathbf{x},\\mathbf{y}\\in I_{n}$\nThen, by $(\\mathrm{i})$ and Theorem 2, there exists $\\mathbf{x}^{\\ast}\\in I_{n}$ for all $n$. Since $\\left\\{ O_{\\alpha} \\right\\}$ is an open cover of $I$, there is some $\\alpha$ for which $\\mathbf{x}^{\\ast}\\in O_{\\alpha}$. As $O_{\\alpha}$ is an open set, there exists $r\u0026gt;0$ such that $|\\mathbf{x}^{\\ast}-\\mathbf{y}|\u0026lt;r \\implies \\mathbf{y}\\in O_{\\alpha}$. On the other hand, $n$ can be sufficiently large so that $2^{-n}\\delta\u0026lt;r$. Then, by $(\\mathrm{iii})$, $I_{n}\\subset O_{\\alpha}$. However, this contradicts $(\\mathrm{ii})$, so the assumption is wrong. Therefore, every $k$-cell is compact.\n■\nFrom the above facts, we can prove the following useful theorems.\nEquivalent Conditions for Compactness in Euclidean Space For a subset $E\\subset \\mathbb{R}^{k}(\\mathrm{or}\\ \\mathbb{C}^{k})$ of the real (or complex) space, the following three propositions are equivalent.\n(a) $E$ is closed and bounded.\n(b) $E$ is compact.\n(c) Every infinite subset\nof $E$ has an accumulation point $p \\in E$.\nHere, the equivalence of (a) and (b) is known as the Heine-Borel theorem. An $E$ satisfying (c) is said to be \u0026lsquo;compact with respect to accumulation points\u0026rsquo; or \u0026lsquo;having the Bolzano-Weierstrass property\u0026rsquo;. The equivalence of (b) and (c) holds in metric spaces but is not generally true in topological spaces.\nProof (a) $\\implies$ (b)\nAssuming (a), there exists a $k$-cell $I$ such that $E \\subset I$. Since $I$ is compact, and a closed subset of a compact set is compact, $E$ is compact.\n(b) $\\implies$ (c)\nThis is proved by contradiction.\nLet $S$ be an infinite subset of a compact set $E$. Assume that $S$ has no accumulation point. Then, every $p\\in E$ has at most one point of $S$ in its neighborhood $N_{p}$. When $p \\in S$, that one point is $p$ itself. And this implies that the open cover $\\left\\{ N_{p} \\right\\}$ does not have a finite subcover for $S$. Since $S \\subset E$, similarly, there\u0026rsquo;s no finite subcover for $E$ either, contradicting the assumption that $E$ is compact. Hence, $S$ has an accumulation point $p \\in E$.\n(c) $\\implies$ (a)\nThis is proved by contradiction.\npart 1. $E$ is bounded\nLet\u0026rsquo;s assume $E$ is not bounded. Then, $E$ contains points $\\mathbf{x}_{n}$ satisfying the following inequality.\n$$ |\\mathbf{x}_{n}| \u0026gt;n\\quad (n=1,2,\\cdots) $$\nLet\u0026rsquo;s denote $S=\\left\\{ \\mathbf{x}_{n} :n=1,2,\\cdots\\right\\}$. $S$ is infinite and obviously does not have an accumulation point in $\\mathbb{R}^{k}, contradicting (c). Thus, $E$ is bounded.\npart 2. $E$ is closed\nLet\u0026rsquo;s assume $E$ is not closed. Then, by definition, there exists an accumulation point $\\mathbf{x}_{0}$ of $E$ that is not included in $E. Now, for $n=1,2,\\cdots$, let\u0026rsquo;s consider $\\mathbf{x}_{n} \\in E$ satisfying the following conditions.\n$$ \\left|\\mathbf{x}_{n}-\\mathbf{x}_{0} \\right| \u0026lt; {\\textstyle \\frac{1}{n}} $$\nLet\u0026rsquo;s denote the set of such $\\mathbf{x}_{n}$ as $S$. $S$ is infinite and has $\\mathbf{x}_{0}$ as an accumulation point. If $\\mathbf{x}_{0}$ is the only accumulation point of $S$, then $\\mathbf{x}_{0}\\notin E$ contradicts (c), proving $E$ is closed. Now, consider $\\mathbf{y} \\ne\\mathbf{x}_{0}$ in $\\mathbb{R}^{k}$. Then,\n$$ \\begin{align*} \\left| \\mathbf{x}_{n} - \\mathbf{y} \\right| \u0026amp; \\ge \\left|\\mathbf{x}_{0} - \\mathbf{y} \\right| - \\left|\\mathbf{x}_{n}-\\mathbf{x}_{0} \\right| \\\\ \u0026amp; \\ge \\left| \\mathbf{x}_{0} - \\mathbf{y} \\right| -\\frac{1}{n} \\end{align*} $$\nFor sufficiently large $n$, the following holds true.\n$$ \\begin{equation} \\left| \\mathbf{x}_{n} - \\mathbf{y} \\right| \\ge \\left| \\mathbf{x}_{0}- \\mathbf{y} \\right|-\\frac{1}{n} \\ge \\frac{1}{2}\\left|\\mathbf{x}_{0}-\\mathbf{y} \\right| \\label{eq1} \\end{equation} $$\nFurthermore, as $n$ increases, $\\mathbf{x}_{n}$ gets closer to $\\mathbf{x}_{0}$. This fact, along with $\\eqref{eq1}$, implies that we can find a neighborhood of $\\mathbf{y}$ that contains no point other than $\\mathbf{y}$ as $n$ increases. Thus, $\\mathbf{y}$ is not an accumulation point of $S$, proving $\\mathbf{x}_{0}$ is the only accumulation point of $S. This contradicts (c), proving $E$ is closed.\n■\nBolzano-Weierstrass Theorem Every bounded infinite subset of $\\mathbb{R}^{k}$ has an accumulation point $p \\in \\mathbb{R}^{k}$.\nProof Let $E$ be a bounded infinite subset of $\\mathbb{R}^{k}$. Since $E$ is bounded, there exists a $k$-cell $I$ such that $E \\subset I. As $k$-cells are compact, $I$ is compact. Then, by the equivalent condition for compactness in $\\mathbb{R}^{k}$ $(b)\\implies (c)$, $E$ has an accumulation point $p \\in I \\subset \\mathbb{R}^{k}$.\n■\nSee Also Specialization of Riesz\u0026rsquo;s Theorem Riesz\u0026rsquo;s Theorem in normed spaces indicates the compactness of the closed unit ball $\\overline{B (0;1)}$ as an equivalent condition of finite dimension. The $k$-cell $[0,1]^{k}$ in Euclidean space is compact, and since there is a homeomorphism with the closed unit ball, Riesz\u0026rsquo;s theorem can be seen as a generalization of the compactness of the $k$-cell.\nAny $b_{n}$ will suffice.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1711,"permalink":"https://freshrimpsushi.github.io/en/posts/1711/","tags":null,"title":"Every k Cell is Compact"},{"categories":"정수론","contents":"Prime numbers A list of primes up to the 10,000th.\nDownload\r2 3 5 7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97 101 103 107 109 113 127 131 137 139 149 151 157 163 167 173 179 181 191 193 197 199 211 223 227 229 233 239 241 251 257 263 269 271 277 281 283 293 307 311 313 317 331 337 347 349 353 359 367 373 379 383 389 397 401 409 419 421 431 433 439 443 449 457 461 463 467 479 487 491 499 503 509 521 523 541 547 557 563 569 571 577 587 593 599 601 607 613 617 619 631 641 643 647 653 659 661 673 677 683 691 701 709 719 727 733 739 743 751 757 761 769 773 787 797 809 811 821 823 827 829 839 853 857 859 863 877 881 883 887 907 911 919 929 937 941 947 953 967 971 977 983 991 997 1009 1013 1019 1021 1031 1033 1039 1049 1051 1061 1063 1069 1087 1091 1093 1097 1103 1109 1117 1123 1129 1151 1153 1163 1171 1181 1187 1193 1201 1213 1217 1223 1229 1231 1237 1249 1259 1277 1279 1283 1289 1291 1297 1301 1303 1307 1319 1321 1327 1361 1367 1373 1381 1399 1409 1423 1427 1429 1433 1439 1447 1451 1453 1459 1471 1481 1483 1487 1489 1493 1499 1511 1523 1531 1543 1549 1553 1559 1567 1571 1579 1583 1597 1601 1607 1609 1613 1619 1621 1627 1637 1657 1663 1667 1669 1693 1697 1699 1709 1721 1723 1733 1741 1747 1753 1759 1777 1783 1787 1789 1801 1811 1823 1831 1847 1861 1867 1871 1873 1877 1879 1889 1901 1907 1913 1931 1933 1949 1951 1973 1979 1987 1993 1997 1999 2003 2011 2017 2027 2029 2039 2053 2063 2069 2081 2083 2087 2089 2099 2111 2113 2129 2131 2137 2141 2143 2153 2161 2179 2203 2207 2213 2221 2237 2239 2243 2251 2267 2269 2273 2281 2287 2293 2297 2309 2311 2333 2339 2341 2347 2351 2357 2371 2377 2381 2383 2389 2393 2399 2411 2417 2423 2437 2441 2447 2459 2467 2473 2477 2503 2521 2531 2539 2543 2549 2551 2557 2579 2591 2593 2609 2617 2621 2633 2647 2657 2659 2663 2671 2677 2683 2687 2689 2693 2699 2707 2711 2713 2719 2729 2731 2741 2749 2753 2767 2777 2789 2791 2797 2801 2803 2819 2833 2837 2843 2851 2857 2861 2879 2887 2897 2903 2909 2917 2927 2939 2953 2957 2963 2969 2971 2999 3001 3011 3019 3023 3037 3041 3049 3061 3067 3079 3083 3089 3109 3119 3121 3137 3163 3167 3169 3181 3187 3191 3203 3209 3217 3221 3229 3251 3253 3257 3259 3271 3299 3301 3307 3313 3319 3323 3329 3331 3343 3347 3359 3361 3371 3373 3389 3391 3407 3413 3433 3449 3457 3461 3463 3467 3469 3491 3499 3511 3517 3527 3529 3533 3539 3541 3547 3557 3559 3571 3581 3583 3593 3607 3613 3617 3623 3631 3637 3643 3659 3671 3673 3677 3691 3697 3701 3709 3719 3727 3733 3739 3761 3767 3769 3779 3793 3797 3803 3821 3823 3833 3847 3851 3853 3863 3877 3881 3889 3907 3911 3917 3919 3923 3929 3931 3943 3947 3967 3989 4001 4003 4007 4013 4019 4021 4027 4049 4051 4057 4073 4079 4091 4093 4099 4111 4127 4129 4133 4139 4153 4157 4159 4177 4201 4211 4217 4219 4229 4231 4241 4243 4253 4259 4261 4271 4273 4283 4289 4297 4327 4337 4339 4349 4357 4363 4373 4391 4397 4409 4421 4423 4441 4447 4451 4457 4463 4481 4483 4493 4507 4513 4517 4519 4523 4547 4549 4561 4567 4583 4591 4597 4603 4621 4637 4639 4643 4649 4651 4657 4663 4673 4679 4691 4703 4721 4723 4729 4733 4751 4759 4783 4787 4789 4793 4799 4801 4813 4817 4831 4861 4871 4877 4889 4903 4909 4919 4931 4933 4937 4943 4951 4957 4967 4969 4973 4987 4993 4999 5003 5009 5011 5021 5023 5039 5051 5059 5077 5081 5087 5099 5101 5107 5113 5119 5147 5153 5167 5171 5179 5189 5197 5209 5227 5231 5233 5237 5261 5273 5279 5281 5297 5303 5309 5323 5333 5347 5351 5381 5387 5393 5399 5407 5413 5417 5419 5431 5437 5441 5443 5449 5471 5477 5479 5483 5501 5503 5507 5519 5521 5527 5531 5557 5563 5569 5573 5581 5591 5623 5639 5641 5647 5651 5653 5657 5659 5669 5683 5689 5693 5701 5711 5717 5737 5741 5743 5749 5779 5783 5791 5801 5807 5813 5821 5827 5839 5843 5849 5851 5857 5861 5867 5869 5879 5881 5897 5903 5923 5927 5939 5953 5981 5987 6007 6011 6029 6037 6043 6047 6053 6067 6073 6079 6089 6091 6101 6113 6121 6131 6133 6143 6151 6163 6173 6197 6199 6203 6211 6217 6221 6229 6247 6257 6263 6269 6271 6277 6287 6299 6301 6311 6317 6323 6329 6337 6343 6353 6359 6361 6367 6373 6379 6389 6397 6421 6427 6449 6451 6469 6473 6481 6491 6521 6529 6547 6551 6553 6563 6569 6571 6577 6581 6599 6607 6619 6637 6653 6659 6661 6673 6679 6689 6691 6701 6703 6709 6719 6733 6737 6761 6763 6779 6781 6791 6793 6803 6823 6827 6829 6833 6841 6857 6863 6869 6871 6883 6899 6907 6911 6917 6947 6949 6959 6961 6967 6971 6977 6983 6991 6997 7001 7013 7019 7027 7039 7043 7057 7069 7079 7103 7109 7121 7127 7129 7151 7159 7177 7187 7193 7207 7211 7213 7219 7229 7237 7243 7247 7253 7283 7297 7307 7309 7321 7331 7333 7349 7351 7369 7393 7411 7417 7433 7451 7457 7459 7477 7481 7487 7489 7499 7507 7517 7523 7529 7537 7541 7547 7549 7559 7561 7573 7577 7583 7589 7591 7603 7607 7621 7639 7643 7649 7669 7673 7681 7687 7691 7699 7703 7717 7723 7727 7741 7753 7757 7759 7789 7793 7817 7823 7829 7841 7853 7867 7873 7877 7879 7883 7901 7907 7919 7927 7933 7937 7949 7951 7963 7993 8009 8011 8017 8039 8053 8059 8069 8081 8087 8089 8093 8101 8111 8117 8123 8147 8161 8167 8171 8179 8191 8209 8219 8221 8231 8233 8237 8243 8263 8269 8273 8287 8291 8293 8297 8311 8317 8329 8353 8363 8369 8377 8387 8389 8419 8423 8429 8431 8443 8447 8461 8467 8501 8513 8521 8527 8537 8539 8543 8563 8573 8581 8597 8599 8609 8623 8627 8629 8641 8647 8663 8669 8677 8681 8689 8693 8699 8707 8713 8719 8731 8737 8741 8747 8753 8761 8779 8783 8803 8807 8819 8821 8831 8837 8839 8849 8861 8863 8867 8887 8893 8923 8929 8933 8941 8951 8963 8969 8971 8999 9001 9007 9011 9013 9029 9041 9043 9049 9059 9067 9091 9103 9109 9127 9133 9137 9151 9157 9161 9173 9181 9187 9199 9203 9209 9221 9227 9239 9241 9257 9277 9281 9283 9293 9311 9319 9323 9337 9341 9343 9349 9371 9377 9391 9397 9403 9413 9419 9421 9431 9433 9437 9439 9461 9463 9467 9473 9479 9491 9497 9511 9521 9533 9539 9547 9551 9587 9601 9613 9619 9623 9629 9631 9643 9649 9661 9677 9679 9689 9697 9719 9721 9733 9739 9743 9749 9767 9769 9781 9787 9791 9803 9811 9817 9829 9833 9839 9851 9857 9859 9871 9883 9887 9901 9907 9923 9929 9931 9941 9949 9967 9973 10007 10009 10037 10039 10061 10067 10069 10079 10091 10093 10099 10103 10111 10133 10139 10141 10151 10159 10163 10169 10177 10181 10193 10211 10223 10243 10247 10253 10259 10267 10271 10273 10289 10301 10303 10313 10321 10331 10333 10337 10343 10357 10369 10391 10399 10427 10429 10433 10453 10457 10459 10463 10477 10487 10499 10501 10513 10529 10531 10559 10567 10589 10597 10601 10607 10613 10627 10631 10639 10651 10657 10663 10667 10687 10691 10709 10711 10723 10729 10733 10739 10753 10771 10781 10789 10799 10831 10837 10847 10853 10859 10861 10867 10883 10889 10891 10903 10909 10937 10939 10949 10957 10973 10979 10987 10993 11003 11027 11047 11057 11059 11069 11071 11083 11087 11093 11113 11117 11119 11131 11149 11159 11161 11171 11173 11177 11197 11213 11239 11243 11251 11257 11261 11273 11279 11287 11299 11311 11317 11321 11329 11351 11353 11369 11383 11393 11399 11411 11423 11437 11443 11447 11467 11471 11483 11489 11491 11497 11503 11519 11527 11549 11551 11579 11587 11593 11597 11617 11621 11633 11657 11677 11681 11689 11699 11701 11717 11719 11731 11743 11777 11779 11783 11789 11801 11807 11813 11821 11827 11831 11833 11839 11863 11867 11887 11897 11903 11909 11923 11927 11933 11939 11941 11953 11959 11969 11971 11981 11987 12007 12011 12037 12041 12043 12049 12071 12073 12097 12101 12107 12109 12113 12119 12143 12149 12157 12161 12163 12197 12203 12211 12227 12239 12241 12251 12253 12263 12269 12277 12281 12289 12301 12323 12329 12343 12347 12373 12377 12379 12391 12401 12409 12413 12421 12433 12437 12451 12457 12473 12479 12487 12491 12497 12503 12511 12517 12527 12539 12541 12547 12553 12569 12577 12583 12589 12601 12611 12613 12619 12637 12641 12647 12653 12659 12671 12689 12697 12703 12713 12721 12739 12743 12757 12763 12781 12791 12799 12809 12821 12823 12829 12841 12853 12889 12893 12899 12907 12911 12917 12919 12923 12941 12953 12959 12967 12973 12979 12983 13001 13003 13007 13009 13033 13037 13043 13049 13063 13093 13099 13103 13109 13121 13127 13147 13151 13159 13163 13171 13177 13183 13187 13217 13219 13229 13241 13249 13259 13267 13291 13297 13309 13313 13327 13331 13337 13339 13367 13381 13397 13399 13411 13417 13421 13441 13451 13457 13463 13469 13477 13487 13499 13513 13523 13537 13553 13567 13577 13591 13597 13613 13619 13627 13633 13649 13669 13679 13681 13687 13691 13693 13697 13709 13711 13721 13723 13729 13751 13757 13759 13763 13781 13789 13799 13807 13829 13831 13841 13859 13873 13877 13879 13883 13901 13903 13907 13913 13921 13931 13933 13963 13967 13997 13999 14009 14011 14029 14033 14051 14057 14071 14081 14083 14087 14107 14143 14149 14153 14159 14173 14177 14197 14207 14221 14243 14249 14251 14281 14293 14303 14321 14323 14327 14341 14347 14369 14387 14389 14401 14407 14411 14419 14423 14431 14437 14447 14449 14461 14479 14489 14503 14519 14533 14537 14543 14549 14551 14557 14561 14563 14591 14593 14621 14627 14629 14633 14639 14653 14657 14669 14683 14699 14713 14717 14723 14731 14737 14741 14747 14753 14759 14767 14771 14779 14783 14797 14813 14821 14827 14831 14843 14851 14867 14869 14879 14887 14891 14897 14923 14929 14939 14947 14951 14957 14969 14983 15013 15017 15031 15053 15061 15073 15077 15083 15091 15101 15107 15121 15131 15137 15139 15149 15161 15173 15187 15193 15199 15217 15227 15233 15241 15259 15263 15269 15271 15277 15287 15289 15299 15307 15313 15319 15329 15331 15349 15359 15361 15373 15377 15383 15391 15401 15413 15427 15439 15443 15451 15461 15467 15473 15493 15497 15511 15527 15541 15551 15559 15569 15581 15583 15601 15607 15619 15629 15641 15643 15647 15649 15661 15667 15671 15679 15683 15727 15731 15733 15737 15739 15749 15761 15767 15773 15787 15791 15797 15803 15809 15817 15823 15859 15877 15881 15887 15889 15901 15907 15913 15919 15923 15937 15959 15971 15973 15991 16001 16007 16033 16057 16061 16063 16067 16069 16073 16087 16091 16097 16103 16111 16127 16139 16141 16183 16187 16189 16193 16217 16223 16229 16231 16249 16253 16267 16273 16301 16319 16333 16339 16349 16361 16363 16369 16381 16411 16417 16421 16427 16433 16447 16451 16453 16477 16481 16487 16493 16519 16529 16547 16553 16561 16567 16573 16603 16607 16619 16631 16633 16649 16651 16657 16661 16673 16691 16693 16699 16703 16729 16741 16747 16759 16763 16787 16811 16823 16829 16831 16843 16871 16879 16883 16889 16901 16903 16921 16927 16931 16937 16943 16963 16979 16981 16987 16993 17011 17021 17027 17029 17033 17041 17047 17053 17077 17093 17099 17107 17117 17123 17137 17159 17167 17183 17189 17191 17203 17207 17209 17231 17239 17257 17291 17293 17299 17317 17321 17327 17333 17341 17351 17359 17377 17383 17387 17389 17393 17401 17417 17419 17431 17443 17449 17467 17471 17477 17483 17489 17491 17497 17509 17519 17539 17551 17569 17573 17579 17581 17597 17599 17609 17623 17627 17657 17659 17669 17681 17683 17707 17713 17729 17737 17747 17749 17761 17783 17789 17791 17807 17827 17837 17839 17851 17863 17881 17891 17903 17909 17911 17921 17923 17929 17939 17957 17959 17971 17977 17981 17987 17989 18013 18041 18043 18047 18049 18059 18061 18077 18089 18097 18119 18121 18127 18131 18133 18143 18149 18169 18181 18191 18199 18211 18217 18223 18229 18233 18251 18253 18257 18269 18287 18289 18301 18307 18311 18313 18329 18341 18353 18367 18371 18379 18397 18401 18413 18427 18433 18439 18443 18451 18457 18461 18481 18493 18503 18517 18521 18523 18539 18541 18553 18583 18587 18593 18617 18637 18661 18671 18679 18691 18701 18713 18719 18731 18743 18749 18757 18773 18787 18793 18797 18803 18839 18859 18869 18899 18911 18913 18917 18919 18947 18959 18973 18979 19001 19009 19013 19031 19037 19051 19069 19073 19079 19081 19087 19121 19139 19141 19157 19163 19181 19183 19207 19211 19213 19219 19231 19237 19249 19259 19267 19273 19289 19301 19309 19319 19333 19373 19379 19381 19387 19391 19403 19417 19421 19423 19427 19429 19433 19441 19447 19457 19463 19469 19471 19477 19483 19489 19501 19507 19531 19541 19543 19553 19559 19571 19577 19583 19597 19603 19609 19661 19681 19687 19697 19699 19709 19717 19727 19739 19751 19753 19759 19763 19777 19793 19801 19813 19819 19841 19843 19853 19861 19867 19889 19891 19913 19919 19927 19937 19949 19961 19963 19973 19979 19991 19993 19997 20011 20021 20023 20029 20047 20051 20063 20071 20089 20101 20107 20113 20117 20123 20129 20143 20147 20149 20161 20173 20177 20183 20201 20219 20231 20233 20249 20261 20269 20287 20297 20323 20327 20333 20341 20347 20353 20357 20359 20369 20389 20393 20399 20407 20411 20431 20441 20443 20477 20479 20483 20507 20509 20521 20533 20543 20549 20551 20563 20593 20599 20611 20627 20639 20641 20663 20681 20693 20707 20717 20719 20731 20743 20747 20749 20753 20759 20771 20773 20789 20807 20809 20849 20857 20873 20879 20887 20897 20899 20903 20921 20929 20939 20947 20959 20963 20981 20983 21001 21011 21013 21017 21019 21023 21031 21059 21061 21067 21089 21101 21107 21121 21139 21143 21149 21157 21163 21169 21179 21187 21191 21193 21211 21221 21227 21247 21269 21277 21283 21313 21317 21319 21323 21341 21347 21377 21379 21383 21391 21397 21401 21407 21419 21433 21467 21481 21487 21491 21493 21499 21503 21517 21521 21523 21529 21557 21559 21563 21569 21577 21587 21589 21599 21601 21611 21613 21617 21647 21649 21661 21673 21683 21701 21713 21727 21737 21739 21751 21757 21767 21773 21787 21799 21803 21817 21821 21839 21841 21851 21859 21863 21871 21881 21893 21911 21929 21937 21943 21961 21977 21991 21997 22003 22013 22027 22031 22037 22039 22051 22063 22067 22073 22079 22091 22093 22109 22111 22123 22129 22133 22147 22153 22157 22159 22171 22189 22193 22229 22247 22259 22271 22273 22277 22279 22283 22291 22303 22307 22343 22349 22367 22369 22381 22391 22397 22409 22433 22441 22447 22453 22469 22481 22483 22501 22511 22531 22541 22543 22549 22567 22571 22573 22613 22619 22621 22637 22639 22643 22651 22669 22679 22691 22697 22699 22709 22717 22721 22727 22739 22741 22751 22769 22777 22783 22787 22807 22811 22817 22853 22859 22861 22871 22877 22901 22907 22921 22937 22943 22961 22963 22973 22993 23003 23011 23017 23021 23027 23029 23039 23041 23053 23057 23059 23063 23071 23081 23087 23099 23117 23131 23143 23159 23167 23173 23189 23197 23201 23203 23209 23227 23251 23269 23279 23291 23293 23297 23311 23321 23327 23333 23339 23357 23369 23371 23399 23417 23431 23447 23459 23473 23497 23509 23531 23537 23539 23549 23557 23561 23563 23567 23581 23593 23599 23603 23609 23623 23627 23629 23633 23663 23669 23671 23677 23687 23689 23719 23741 23743 23747 23753 23761 23767 23773 23789 23801 23813 23819 23827 23831 23833 23857 23869 23873 23879 23887 23893 23899 23909 23911 23917 23929 23957 23971 23977 23981 23993 24001 24007 24019 24023 24029 24043 24049 24061 24071 24077 24083 24091 24097 24103 24107 24109 24113 24121 24133 24137 24151 24169 24179 24181 24197 24203 24223 24229 24239 24247 24251 24281 24317 24329 24337 24359 24371 24373 24379 24391 24407 24413 24419 24421 24439 24443 24469 24473 24481 24499 24509 24517 24527 24533 24547 24551 24571 24593 24611 24623 24631 24659 24671 24677 24683 24691 24697 24709 24733 24749 24763 24767 24781 24793 24799 24809 24821 24841 24847 24851 24859 24877 24889 24907 24917 24919 24923 24943 24953 24967 24971 24977 24979 24989 25013 25031 25033 25037 25057 25073 25087 25097 25111 25117 25121 25127 25147 25153 25163 25169 25171 25183 25189 25219 25229 25237 25243 25247 25253 25261 25301 25303 25307 25309 25321 25339 25343 25349 25357 25367 25373 25391 25409 25411 25423 25439 25447 25453 25457 25463 25469 25471 25523 25537 25541 25561 25577 25579 25583 25589 25601 25603 25609 25621 25633 25639 25643 25657 25667 25673 25679 25693 25703 25717 25733 25741 25747 25759 25763 25771 25793 25799 25801 25819 25841 25847 25849 25867 25873 25889 25903 25913 25919 25931 25933 25939 25943 25951 25969 25981 25997 25999 26003 26017 26021 26029 26041 26053 26083 26099 26107 26111 26113 26119 26141 26153 26161 26171 26177 26183 26189 26203 26209 26227 26237 26249 26251 26261 26263 26267 26293 26297 26309 26317 26321 26339 26347 26357 26371 26387 26393 26399 26407 26417 26423 26431 26437 26449 26459 26479 26489 26497 26501 26513 26539 26557 26561 26573 26591 26597 26627 26633 26641 26647 26669 26681 26683 26687 26693 26699 26701 26711 26713 26717 26723 26729 26731 26737 26759 26777 26783 26801 26813 26821 26833 26839 26849 26861 26863 26879 26881 26891 26893 26903 26921 26927 26947 26951 26953 26959 26981 26987 26993 27011 27017 27031 27043 27059 27061 27067 27073 27077 27091 27103 27107 27109 27127 27143 27179 27191 27197 27211 27239 27241 27253 27259 27271 27277 27281 27283 27299 27329 27337 27361 27367 27397 27407 27409 27427 27431 27437 27449 27457 27479 27481 27487 27509 27527 27529 27539 27541 27551 27581 27583 27611 27617 27631 27647 27653 27673 27689 27691 27697 27701 27733 27737 27739 27743 27749 27751 27763 27767 27773 27779 27791 27793 27799 27803 27809 27817 27823 27827 27847 27851 27883 27893 27901 27917 27919 27941 27943 27947 27953 27961 27967 27983 27997 28001 28019 28027 28031 28051 28057 28069 28081 28087 28097 28099 28109 28111 28123 28151 28163 28181 28183 28201 28211 28219 28229 28277 28279 28283 28289 28297 28307 28309 28319 28349 28351 28387 28393 28403 28409 28411 28429 28433 28439 28447 28463 28477 28493 28499 28513 28517 28537 28541 28547 28549 28559 28571 28573 28579 28591 28597 28603 28607 28619 28621 28627 28631 28643 28649 28657 28661 28663 28669 28687 28697 28703 28711 28723 28729 28751 28753 28759 28771 28789 28793 28807 28813 28817 28837 28843 28859 28867 28871 28879 28901 28909 28921 28927 28933 28949 28961 28979 29009 29017 29021 29023 29027 29033 29059 29063 29077 29101 29123 29129 29131 29137 29147 29153 29167 29173 29179 29191 29201 29207 29209 29221 29231 29243 29251 29269 29287 29297 29303 29311 29327 29333 29339 29347 29363 29383 29387 29389 29399 29401 29411 29423 29429 29437 29443 29453 29473 29483 29501 29527 29531 29537 29567 29569 29573 29581 29587 29599 29611 29629 29633 29641 29663 29669 29671 29683 29717 29723 29741 29753 29759 29761 29789 29803 29819 29833 29837 29851 29863 29867 29873 29879 29881 29917 29921 29927 29947 29959 29983 29989 30011 30013 30029 30047 30059 30071 30089 30091 30097 30103 30109 30113 30119 30133 30137 30139 30161 30169 30181 30187 30197 30203 30211 30223 30241 30253 30259 30269 30271 30293 30307 30313 30319 30323 30341 30347 30367 30389 30391 30403 30427 30431 30449 30467 30469 30491 30493 30497 30509 30517 30529 30539 30553 30557 30559 30577 30593 30631 30637 30643 30649 30661 30671 30677 30689 30697 30703 30707 30713 30727 30757 30763 30773 30781 30803 30809 30817 30829 30839 30841 30851 30853 30859 30869 30871 30881 30893 30911 30931 30937 30941 30949 30971 30977 30983 31013 31019 31033 31039 31051 31063 31069 31079 31081 31091 31121 31123 31139 31147 31151 31153 31159 31177 31181 31183 31189 31193 31219 31223 31231 31237 31247 31249 31253 31259 31267 31271 31277 31307 31319 31321 31327 31333 31337 31357 31379 31387 31391 31393 31397 31469 31477 31481 31489 31511 31513 31517 31531 31541 31543 31547 31567 31573 31583 31601 31607 31627 31643 31649 31657 31663 31667 31687 31699 31721 31723 31727 31729 31741 31751 31769 31771 31793 31799 31817 31847 31849 31859 31873 31883 31891 31907 31957 31963 31973 31981 31991 32003 32009 32027 32029 32051 32057 32059 32063 32069 32077 32083 32089 32099 32117 32119 32141 32143 32159 32173 32183 32189 32191 32203 32213 32233 32237 32251 32257 32261 32297 32299 32303 32309 32321 32323 32327 32341 32353 32359 32363 32369 32371 32377 32381 32401 32411 32413 32423 32429 32441 32443 32467 32479 32491 32497 32503 32507 32531 32533 32537 32561 32563 32569 32573 32579 32587 32603 32609 32611 32621 32633 32647 32653 32687 32693 32707 32713 32717 32719 32749 32771 32779 32783 32789 32797 32801 32803 32831 32833 32839 32843 32869 32887 32909 32911 32917 32933 32939 32941 32957 32969 32971 32983 32987 32993 32999 33013 33023 33029 33037 33049 33053 33071 33073 33083 33091 33107 33113 33119 33149 33151 33161 33179 33181 33191 33199 33203 33211 33223 33247 33287 33289 33301 33311 33317 33329 33331 33343 33347 33349 33353 33359 33377 33391 33403 33409 33413 33427 33457 33461 33469 33479 33487 33493 33503 33521 33529 33533 33547 33563 33569 33577 33581 33587 33589 33599 33601 33613 33617 33619 33623 33629 33637 33641 33647 33679 33703 33713 33721 33739 33749 33751 33757 33767 33769 33773 33791 33797 33809 33811 33827 33829 33851 33857 33863 33871 33889 33893 33911 33923 33931 33937 33941 33961 33967 33997 34019 34031 34033 34039 34057 34061 34123 34127 34129 34141 34147 34157 34159 34171 34183 34211 34213 34217 34231 34253 34259 34261 34267 34273 34283 34297 34301 34303 34313 34319 34327 34337 34351 34361 34367 34369 34381 34403 34421 34429 34439 34457 34469 34471 34483 34487 34499 34501 34511 34513 34519 34537 34543 34549 34583 34589 34591 34603 34607 34613 34631 34649 34651 34667 34673 34679 34687 34693 34703 34721 34729 34739 34747 34757 34759 34763 34781 34807 34819 34841 34843 34847 34849 34871 34877 34883 34897 34913 34919 34939 34949 34961 34963 34981 35023 35027 35051 35053 35059 35069 35081 35083 35089 35099 35107 35111 35117 35129 35141 35149 35153 35159 35171 35201 35221 35227 35251 35257 35267 35279 35281 35291 35311 35317 35323 35327 35339 35353 35363 35381 35393 35401 35407 35419 35423 35437 35447 35449 35461 35491 35507 35509 35521 35527 35531 35533 35537 35543 35569 35573 35591 35593 35597 35603 35617 35671 35677 35729 35731 35747 35753 35759 35771 35797 35801 35803 35809 35831 35837 35839 35851 35863 35869 35879 35897 35899 35911 35923 35933 35951 35963 35969 35977 35983 35993 35999 36007 36011 36013 36017 36037 36061 36067 36073 36083 36097 36107 36109 36131 36137 36151 36161 36187 36191 36209 36217 36229 36241 36251 36263 36269 36277 36293 36299 36307 36313 36319 36341 36343 36353 36373 36383 36389 36433 36451 36457 36467 36469 36473 36479 36493 36497 36523 36527 36529 36541 36551 36559 36563 36571 36583 36587 36599 36607 36629 36637 36643 36653 36671 36677 36683 36691 36697 36709 36713 36721 36739 36749 36761 36767 36779 36781 36787 36791 36793 36809 36821 36833 36847 36857 36871 36877 36887 36899 36901 36913 36919 36923 36929 36931 36943 36947 36973 36979 36997 37003 37013 37019 37021 37039 37049 37057 37061 37087 37097 37117 37123 37139 37159 37171 37181 37189 37199 37201 37217 37223 37243 37253 37273 37277 37307 37309 37313 37321 37337 37339 37357 37361 37363 37369 37379 37397 37409 37423 37441 37447 37463 37483 37489 37493 37501 37507 37511 37517 37529 37537 37547 37549 37561 37567 37571 37573 37579 37589 37591 37607 37619 37633 37643 37649 37657 37663 37691 37693 37699 37717 37747 37781 37783 37799 37811 37813 37831 37847 37853 37861 37871 37879 37889 37897 37907 37951 37957 37963 37967 37987 37991 37993 37997 38011 38039 38047 38053 38069 38083 38113 38119 38149 38153 38167 38177 38183 38189 38197 38201 38219 38231 38237 38239 38261 38273 38281 38287 38299 38303 38317 38321 38327 38329 38333 38351 38371 38377 38393 38431 38447 38449 38453 38459 38461 38501 38543 38557 38561 38567 38569 38593 38603 38609 38611 38629 38639 38651 38653 38669 38671 38677 38693 38699 38707 38711 38713 38723 38729 38737 38747 38749 38767 38783 38791 38803 38821 38833 38839 38851 38861 38867 38873 38891 38903 38917 38921 38923 38933 38953 38959 38971 38977 38993 39019 39023 39041 39043 39047 39079 39089 39097 39103 39107 39113 39119 39133 39139 39157 39161 39163 39181 39191 39199 39209 39217 39227 39229 39233 39239 39241 39251 39293 39301 39313 39317 39323 39341 39343 39359 39367 39371 39373 39383 39397 39409 39419 39439 39443 39451 39461 39499 39503 39509 39511 39521 39541 39551 39563 39569 39581 39607 39619 39623 39631 39659 39667 39671 39679 39703 39709 39719 39727 39733 39749 39761 39769 39779 39791 39799 39821 39827 39829 39839 39841 39847 39857 39863 39869 39877 39883 39887 39901 39929 39937 39953 39971 39979 39983 39989 40009 40013 40031 40037 40039 40063 40087 40093 40099 40111 40123 40127 40129 40151 40153 40163 40169 40177 40189 40193 40213 40231 40237 40241 40253 40277 40283 40289 40343 40351 40357 40361 40387 40423 40427 40429 40433 40459 40471 40483 40487 40493 40499 40507 40519 40529 40531 40543 40559 40577 40583 40591 40597 40609 40627 40637 40639 40693 40697 40699 40709 40739 40751 40759 40763 40771 40787 40801 40813 40819 40823 40829 40841 40847 40849 40853 40867 40879 40883 40897 40903 40927 40933 40939 40949 40961 40973 40993 41011 41017 41023 41039 41047 41051 41057 41077 41081 41113 41117 41131 41141 41143 41149 41161 41177 41179 41183 41189 41201 41203 41213 41221 41227 41231 41233 41243 41257 41263 41269 41281 41299 41333 41341 41351 41357 41381 41387 41389 41399 41411 41413 41443 41453 41467 41479 41491 41507 41513 41519 41521 41539 41543 41549 41579 41593 41597 41603 41609 41611 41617 41621 41627 41641 41647 41651 41659 41669 41681 41687 41719 41729 41737 41759 41761 41771 41777 41801 41809 41813 41843 41849 41851 41863 41879 41887 41893 41897 41903 41911 41927 41941 41947 41953 41957 41959 41969 41981 41983 41999 42013 42017 42019 42023 42043 42061 42071 42073 42083 42089 42101 42131 42139 42157 42169 42179 42181 42187 42193 42197 42209 42221 42223 42227 42239 42257 42281 42283 42293 42299 42307 42323 42331 42337 42349 42359 42373 42379 42391 42397 42403 42407 42409 42433 42437 42443 42451 42457 42461 42463 42467 42473 42487 42491 42499 42509 42533 42557 42569 42571 42577 42589 42611 42641 42643 42649 42667 42677 42683 42689 42697 42701 42703 42709 42719 42727 42737 42743 42751 42767 42773 42787 42793 42797 42821 42829 42839 42841 42853 42859 42863 42899 42901 42923 42929 42937 42943 42953 42961 42967 42979 42989 43003 43013 43019 43037 43049 43051 43063 43067 43093 43103 43117 43133 43151 43159 43177 43189 43201 43207 43223 43237 43261 43271 43283 43291 43313 43319 43321 43331 43391 43397 43399 43403 43411 43427 43441 43451 43457 43481 43487 43499 43517 43541 43543 43573 43577 43579 43591 43597 43607 43609 43613 43627 43633 43649 43651 43661 43669 43691 43711 43717 43721 43753 43759 43777 43781 43783 43787 43789 43793 43801 43853 43867 43889 43891 43913 43933 43943 43951 43961 43963 43969 43973 43987 43991 43997 44017 44021 44027 44029 44041 44053 44059 44071 44087 44089 44101 44111 44119 44123 44129 44131 44159 44171 44179 44189 44201 44203 44207 44221 44249 44257 44263 44267 44269 44273 44279 44281 44293 44351 44357 44371 44381 44383 44389 44417 44449 44453 44483 44491 44497 44501 44507 44519 44531 44533 44537 44543 44549 44563 44579 44587 44617 44621 44623 44633 44641 44647 44651 44657 44683 44687 44699 44701 44711 44729 44741 44753 44771 44773 44777 44789 44797 44809 44819 44839 44843 44851 44867 44879 44887 44893 44909 44917 44927 44939 44953 44959 44963 44971 44983 44987 45007 45013 45053 45061 45077 45083 45119 45121 45127 45131 45137 45139 45161 45179 45181 45191 45197 45233 45247 45259 45263 45281 45289 45293 45307 45317 45319 45329 45337 45341 45343 45361 45377 45389 45403 45413 45427 45433 45439 45481 45491 45497 45503 45523 45533 45541 45553 45557 45569 45587 45589 45599 45613 45631 45641 45659 45667 45673 45677 45691 45697 45707 45737 45751 45757 45763 45767 45779 45817 45821 45823 45827 45833 45841 45853 45863 45869 45887 45893 45943 45949 45953 45959 45971 45979 45989 46021 46027 46049 46051 46061 46073 46091 46093 46099 46103 46133 46141 46147 46153 46171 46181 46183 46187 46199 46219 46229 46237 46261 46271 46273 46279 46301 46307 46309 46327 46337 46349 46351 46381 46399 46411 46439 46441 46447 46451 46457 46471 46477 46489 46499 46507 46511 46523 46549 46559 46567 46573 46589 46591 46601 46619 46633 46639 46643 46649 46663 46679 46681 46687 46691 46703 46723 46727 46747 46751 46757 46769 46771 46807 46811 46817 46819 46829 46831 46853 46861 46867 46877 46889 46901 46919 46933 46957 46993 46997 47017 47041 47051 47057 47059 47087 47093 47111 47119 47123 47129 47137 47143 47147 47149 47161 47189 47207 47221 47237 47251 47269 47279 47287 47293 47297 47303 47309 47317 47339 47351 47353 47363 47381 47387 47389 47407 47417 47419 47431 47441 47459 47491 47497 47501 47507 47513 47521 47527 47533 47543 47563 47569 47581 47591 47599 47609 47623 47629 47639 47653 47657 47659 47681 47699 47701 47711 47713 47717 47737 47741 47743 47777 47779 47791 47797 47807 47809 47819 47837 47843 47857 47869 47881 47903 47911 47917 47933 47939 47947 47951 47963 47969 47977 47981 48017 48023 48029 48049 48073 48079 48091 48109 48119 48121 48131 48157 48163 48179 48187 48193 48197 48221 48239 48247 48259 48271 48281 48299 48311 48313 48337 48341 48353 48371 48383 48397 48407 48409 48413 48437 48449 48463 48473 48479 48481 48487 48491 48497 48523 48527 48533 48539 48541 48563 48571 48589 48593 48611 48619 48623 48647 48649 48661 48673 48677 48679 48731 48733 48751 48757 48761 48767 48779 48781 48787 48799 48809 48817 48821 48823 48847 48857 48859 48869 48871 48883 48889 48907 48947 48953 48973 48989 48991 49003 49009 49019 49031 49033 49037 49043 49057 49069 49081 49103 49109 49117 49121 49123 49139 49157 49169 49171 49177 49193 49199 49201 49207 49211 49223 49253 49261 49277 49279 49297 49307 49331 49333 49339 49363 49367 49369 49391 49393 49409 49411 49417 49429 49433 49451 49459 49463 49477 49481 49499 49523 49529 49531 49537 49547 49549 49559 49597 49603 49613 49627 49633 49639 49663 49667 49669 49681 49697 49711 49727 49739 49741 49747 49757 49783 49787 49789 49801 49807 49811 49823 49831 49843 49853 49871 49877 49891 49919 49921 49927 49937 49939 49943 49957 49991 49993 49999 50021 50023 50033 50047 50051 50053 50069 50077 50087 50093 50101 50111 50119 50123 50129 50131 50147 50153 50159 50177 50207 50221 50227 50231 50261 50263 50273 50287 50291 50311 50321 50329 50333 50341 50359 50363 50377 50383 50387 50411 50417 50423 50441 50459 50461 50497 50503 50513 50527 50539 50543 50549 50551 50581 50587 50591 50593 50599 50627 50647 50651 50671 50683 50707 50723 50741 50753 50767 50773 50777 50789 50821 50833 50839 50849 50857 50867 50873 50891 50893 50909 50923 50929 50951 50957 50969 50971 50989 50993 51001 51031 51043 51047 51059 51061 51071 51109 51131 51133 51137 51151 51157 51169 51193 51197 51199 51203 51217 51229 51239 51241 51257 51263 51283 51287 51307 51329 51341 51343 51347 51349 51361 51383 51407 51413 51419 51421 51427 51431 51437 51439 51449 51461 51473 51479 51481 51487 51503 51511 51517 51521 51539 51551 51563 51577 51581 51593 51599 51607 51613 51631 51637 51647 51659 51673 51679 51683 51691 51713 51719 51721 51749 51767 51769 51787 51797 51803 51817 51827 51829 51839 51853 51859 51869 51871 51893 51899 51907 51913 51929 51941 51949 51971 51973 51977 51991 52009 52021 52027 52051 52057 52067 52069 52081 52103 52121 52127 52147 52153 52163 52177 52181 52183 52189 52201 52223 52237 52249 52253 52259 52267 52289 52291 52301 52313 52321 52361 52363 52369 52379 52387 52391 52433 52453 52457 52489 52501 52511 52517 52529 52541 52543 52553 52561 52567 52571 52579 52583 52609 52627 52631 52639 52667 52673 52691 52697 52709 52711 52721 52727 52733 52747 52757 52769 52783 52807 52813 52817 52837 52859 52861 52879 52883 52889 52901 52903 52919 52937 52951 52957 52963 52967 52973 52981 52999 53003 53017 53047 53051 53069 53077 53087 53089 53093 53101 53113 53117 53129 53147 53149 53161 53171 53173 53189 53197 53201 53231 53233 53239 53267 53269 53279 53281 53299 53309 53323 53327 53353 53359 53377 53381 53401 53407 53411 53419 53437 53441 53453 53479 53503 53507 53527 53549 53551 53569 53591 53593 53597 53609 53611 53617 53623 53629 53633 53639 53653 53657 53681 53693 53699 53717 53719 53731 53759 53773 53777 53783 53791 53813 53819 53831 53849 53857 53861 53881 53887 53891 53897 53899 53917 53923 53927 53939 53951 53959 53987 53993 54001 54011 54013 54037 54049 54059 54083 54091 54101 54121 54133 54139 54151 54163 54167 54181 54193 54217 54251 54269 54277 54287 54293 54311 54319 54323 54331 54347 54361 54367 54371 54377 54401 54403 54409 54413 54419 54421 54437 54443 54449 54469 54493 54497 54499 54503 54517 54521 54539 54541 54547 54559 54563 54577 54581 54583 54601 54617 54623 54629 54631 54647 54667 54673 54679 54709 54713 54721 54727 54751 54767 54773 54779 54787 54799 54829 54833 54851 54869 54877 54881 54907 54917 54919 54941 54949 54959 54973 54979 54983 55001 55009 55021 55049 55051 55057 55061 55073 55079 55103 55109 55117 55127 55147 55163 55171 55201 55207 55213 55217 55219 55229 55243 55249 55259 55291 55313 55331 55333 55337 55339 55343 55351 55373 55381 55399 55411 55439 55441 55457 55469 55487 55501 55511 55529 55541 55547 55579 55589 55603 55609 55619 55621 55631 55633 55639 55661 55663 55667 55673 55681 55691 55697 55711 55717 55721 55733 55763 55787 55793 55799 55807 55813 55817 55819 55823 55829 55837 55843 55849 55871 55889 55897 55901 55903 55921 55927 55931 55933 55949 55967 55987 55997 56003 56009 56039 56041 56053 56081 56087 56093 56099 56101 56113 56123 56131 56149 56167 56171 56179 56197 56207 56209 56237 56239 56249 56263 56267 56269 56299 56311 56333 56359 56369 56377 56383 56393 56401 56417 56431 56437 56443 56453 56467 56473 56477 56479 56489 56501 56503 56509 56519 56527 56531 56533 56543 56569 56591 56597 56599 56611 56629 56633 56659 56663 56671 56681 56687 56701 56711 56713 56731 56737 56747 56767 56773 56779 56783 56807 56809 56813 56821 56827 56843 56857 56873 56891 56893 56897 56909 56911 56921 56923 56929 56941 56951 56957 56963 56983 56989 56993 56999 57037 57041 57047 57059 57073 57077 57089 57097 57107 57119 57131 57139 57143 57149 57163 57173 57179 57191 57193 57203 57221 57223 57241 57251 57259 57269 57271 57283 57287 57301 57329 57331 57347 57349 57367 57373 57383 57389 57397 57413 57427 57457 57467 57487 57493 57503 57527 57529 57557 57559 57571 57587 57593 57601 57637 57641 57649 57653 57667 57679 57689 57697 57709 57713 57719 57727 57731 57737 57751 57773 57781 57787 57791 57793 57803 57809 57829 57839 57847 57853 57859 57881 57899 57901 57917 57923 57943 57947 57973 57977 57991 58013 58027 58031 58043 58049 58057 58061 58067 58073 58099 58109 58111 58129 58147 58151 58153 58169 58171 58189 58193 58199 58207 58211 58217 58229 58231 58237 58243 58271 58309 58313 58321 58337 58363 58367 58369 58379 58391 58393 58403 58411 58417 58427 58439 58441 58451 58453 58477 58481 58511 58537 58543 58549 58567 58573 58579 58601 58603 58613 58631 58657 58661 58679 58687 58693 58699 58711 58727 58733 58741 58757 58763 58771 58787 58789 58831 58889 58897 58901 58907 58909 58913 58921 58937 58943 58963 58967 58979 58991 58997 59009 59011 59021 59023 59029 59051 59053 59063 59069 59077 59083 59093 59107 59113 59119 59123 59141 59149 59159 59167 59183 59197 59207 59209 59219 59221 59233 59239 59243 59263 59273 59281 59333 59341 59351 59357 59359 59369 59377 59387 59393 59399 59407 59417 59419 59441 59443 59447 59453 59467 59471 59473 59497 59509 59513 59539 59557 59561 59567 59581 59611 59617 59621 59627 59629 59651 59659 59663 59669 59671 59693 59699 59707 59723 59729 59743 59747 59753 59771 59779 59791 59797 59809 59833 59863 59879 59887 59921 59929 59951 59957 59971 59981 59999 60013 60017 60029 60037 60041 60077 60083 60089 60091 60101 60103 60107 60127 60133 60139 60149 60161 60167 60169 60209 60217 60223 60251 60257 60259 60271 60289 60293 60317 60331 60337 60343 60353 60373 60383 60397 60413 60427 60443 60449 60457 60493 60497 60509 60521 60527 60539 60589 60601 60607 60611 60617 60623 60631 60637 60647 60649 60659 60661 60679 60689 60703 60719 60727 60733 60737 60757 60761 60763 60773 60779 60793 60811 60821 60859 60869 60887 60889 60899 60901 60913 60917 60919 60923 60937 60943 60953 60961 61001 61007 61027 61031 61043 61051 61057 61091 61099 61121 61129 61141 61151 61153 61169 61211 61223 61231 61253 61261 61283 61291 61297 61331 61333 61339 61343 61357 61363 61379 61381 61403 61409 61417 61441 61463 61469 61471 61483 61487 61493 61507 61511 61519 61543 61547 61553 61559 61561 61583 61603 61609 61613 61627 61631 61637 61643 61651 61657 61667 61673 61681 61687 61703 61717 61723 61729 61751 61757 61781 61813 61819 61837 61843 61861 61871 61879 61909 61927 61933 61949 61961 61967 61979 61981 61987 61991 62003 62011 62017 62039 62047 62053 62057 62071 62081 62099 62119 62129 62131 62137 62141 62143 62171 62189 62191 62201 62207 62213 62219 62233 62273 62297 62299 62303 62311 62323 62327 62347 62351 62383 62401 62417 62423 62459 62467 62473 62477 62483 62497 62501 62507 62533 62539 62549 62563 62581 62591 62597 62603 62617 62627 62633 62639 62653 62659 62683 62687 62701 62723 62731 62743 62753 62761 62773 62791 62801 62819 62827 62851 62861 62869 62873 62897 62903 62921 62927 62929 62939 62969 62971 62981 62983 62987 62989 63029 63031 63059 63067 63073 63079 63097 63103 63113 63127 63131 63149 63179 63197 63199 63211 63241 63247 63277 63281 63299 63311 63313 63317 63331 63337 63347 63353 63361 63367 63377 63389 63391 63397 63409 63419 63421 63439 63443 63463 63467 63473 63487 63493 63499 63521 63527 63533 63541 63559 63577 63587 63589 63599 63601 63607 63611 63617 63629 63647 63649 63659 63667 63671 63689 63691 63697 63703 63709 63719 63727 63737 63743 63761 63773 63781 63793 63799 63803 63809 63823 63839 63841 63853 63857 63863 63901 63907 63913 63929 63949 63977 63997 64007 64013 64019 64033 64037 64063 64067 64081 64091 64109 64123 64151 64153 64157 64171 64187 64189 64217 64223 64231 64237 64271 64279 64283 64301 64303 64319 64327 64333 64373 64381 64399 64403 64433 64439 64451 64453 64483 64489 64499 64513 64553 64567 64577 64579 64591 64601 64609 64613 64621 64627 64633 64661 64663 64667 64679 64693 64709 64717 64747 64763 64781 64783 64793 64811 64817 64849 64853 64871 64877 64879 64891 64901 64919 64921 64927 64937 64951 64969 64997 65003 65011 65027 65029 65033 65053 65063 65071 65089 65099 65101 65111 65119 65123 65129 65141 65147 65167 65171 65173 65179 65183 65203 65213 65239 65257 65267 65269 65287 65293 65309 65323 65327 65353 65357 65371 65381 65393 65407 65413 65419 65423 65437 65447 65449 65479 65497 65519 65521 65537 65539 65543 65551 65557 65563 65579 65581 65587 65599 65609 65617 65629 65633 65647 65651 65657 65677 65687 65699 65701 65707 65713 65717 65719 65729 65731 65761 65777 65789 65809 65827 65831 65837 65839 65843 65851 65867 65881 65899 65921 65927 65929 65951 65957 65963 65981 65983 65993 66029 66037 66041 66047 66067 66071 66083 66089 66103 66107 66109 66137 66161 66169 66173 66179 66191 66221 66239 66271 66293 66301 66337 66343 66347 66359 66361 66373 66377 66383 66403 66413 66431 66449 66457 66463 66467 66491 66499 66509 66523 66529 66533 66541 66553 66569 66571 66587 66593 66601 66617 66629 66643 66653 66683 66697 66701 66713 66721 66733 66739 66749 66751 66763 66791 66797 66809 66821 66841 66851 66853 66863 66877 66883 66889 66919 66923 66931 66943 66947 66949 66959 66973 66977 67003 67021 67033 67043 67049 67057 67061 67073 67079 67103 67121 67129 67139 67141 67153 67157 67169 67181 67187 67189 67211 67213 67217 67219 67231 67247 67261 67271 67273 67289 67307 67339 67343 67349 67369 67391 67399 67409 67411 67421 67427 67429 67433 67447 67453 67477 67481 67489 67493 67499 67511 67523 67531 67537 67547 67559 67567 67577 67579 67589 67601 67607 67619 67631 67651 67679 67699 67709 67723 67733 67741 67751 67757 67759 67763 67777 67783 67789 67801 67807 67819 67829 67843 67853 67867 67883 67891 67901 67927 67931 67933 67939 67943 67957 67961 67967 67979 67987 67993 68023 68041 68053 68059 68071 68087 68099 68111 68113 68141 68147 68161 68171 68207 68209 68213 68219 68227 68239 68261 68279 68281 68311 68329 68351 68371 68389 68399 68437 68443 68447 68449 68473 68477 68483 68489 68491 68501 68507 68521 68531 68539 68543 68567 68581 68597 68611 68633 68639 68659 68669 68683 68687 68699 68711 68713 68729 68737 68743 68749 68767 68771 68777 68791 68813 68819 68821 68863 68879 68881 68891 68897 68899 68903 68909 68917 68927 68947 68963 68993 69001 69011 69019 69029 69031 69061 69067 69073 69109 69119 69127 69143 69149 69151 69163 69191 69193 69197 69203 69221 69233 69239 69247 69257 69259 69263 69313 69317 69337 69341 69371 69379 69383 69389 69401 69403 69427 69431 69439 69457 69463 69467 69473 69481 69491 69493 69497 69499 69539 69557 69593 69623 69653 69661 69677 69691 69697 69709 69737 69739 69761 69763 69767 69779 69809 69821 69827 69829 69833 69847 69857 69859 69877 69899 69911 69929 69931 69941 69959 69991 69997 70001 70003 70009 70019 70039 70051 70061 70067 70079 70099 70111 70117 70121 70123 70139 70141 70157 70163 70177 70181 70183 70199 70201 70207 70223 70229 70237 70241 70249 70271 70289 70297 70309 70313 70321 70327 70351 70373 70379 70381 70393 70423 70429 70439 70451 70457 70459 70481 70487 70489 70501 70507 70529 70537 70549 70571 70573 70583 70589 70607 70619 70621 70627 70639 70657 70663 70667 70687 70709 70717 70729 70753 70769 70783 70793 70823 70841 70843 70849 70853 70867 70877 70879 70891 70901 70913 70919 70921 70937 70949 70951 70957 70969 70979 70981 70991 70997 70999 71011 71023 71039 71059 71069 71081 71089 71119 71129 71143 71147 71153 71161 71167 71171 71191 71209 71233 71237 71249 71257 71261 71263 71287 71293 71317 71327 71329 71333 71339 71341 71347 71353 71359 71363 71387 71389 71399 71411 71413 71419 71429 71437 71443 71453 71471 71473 71479 71483 71503 71527 71537 71549 71551 71563 71569 71593 71597 71633 71647 71663 71671 71693 71699 71707 71711 71713 71719 71741 71761 71777 71789 71807 71809 71821 71837 71843 71849 71861 71867 71879 71881 71887 71899 71909 71917 71933 71941 71947 71963 71971 71983 71987 71993 71999 72019 72031 72043 72047 72053 72073 72077 72089 72091 72101 72103 72109 72139 72161 72167 72169 72173 72211 72221 72223 72227 72229 72251 72253 72269 72271 72277 72287 72307 72313 72337 72341 72353 72367 72379 72383 72421 72431 72461 72467 72469 72481 72493 72497 72503 72533 72547 72551 72559 72577 72613 72617 72623 72643 72647 72649 72661 72671 72673 72679 72689 72701 72707 72719 72727 72733 72739 72763 72767 72797 72817 72823 72859 72869 72871 72883 72889 72893 72901 72907 72911 72923 72931 72937 72949 72953 72959 72973 72977 72997 73009 73013 73019 73037 73039 73043 73061 73063 73079 73091 73121 73127 73133 73141 73181 73189 73237 73243 73259 73277 73291 73303 73309 73327 73331 73351 73361 73363 73369 73379 73387 73417 73421 73433 73453 73459 73471 73477 73483 73517 73523 73529 73547 73553 73561 73571 73583 73589 73597 73607 73609 73613 73637 73643 73651 73673 73679 73681 73693 73699 73709 73721 73727 73751 73757 73771 73783 73819 73823 73847 73849 73859 73867 73877 73883 73897 73907 73939 73943 73951 73961 73973 73999 74017 74021 74027 74047 74051 74071 74077 74093 74099 74101 74131 74143 74149 74159 74161 74167 74177 74189 74197 74201 74203 74209 74219 74231 74257 74279 74287 74293 74297 74311 74317 74323 74353 74357 74363 74377 74381 74383 74411 74413 74419 74441 74449 74453 74471 74489 74507 74509 74521 74527 74531 74551 74561 74567 74573 74587 74597 74609 74611 74623 74653 74687 74699 74707 74713 74717 74719 74729 74731 74747 74759 74761 74771 74779 74797 74821 74827 74831 74843 74857 74861 74869 74873 74887 74891 74897 74903 74923 74929 74933 74941 74959 75011 75013 75017 75029 75037 75041 75079 75083 75109 75133 75149 75161 75167 75169 75181 75193 75209 75211 75217 75223 75227 75239 75253 75269 75277 75289 75307 75323 75329 75337 75347 75353 75367 75377 75389 75391 75401 75403 75407 75431 75437 75479 75503 75511 75521 75527 75533 75539 75541 75553 75557 75571 75577 75583 75611 75617 75619 75629 75641 75653 75659 75679 75683 75689 75703 75707 75709 75721 75731 75743 75767 75773 75781 75787 75793 75797 75821 75833 75853 75869 75883 75913 75931 75937 75941 75967 75979 75983 75989 75991 75997 76001 76003 76031 76039 76079 76081 76091 76099 76103 76123 76129 76147 76157 76159 76163 76207 76213 76231 76243 76249 76253 76259 76261 76283 76289 76303 76333 76343 76367 76369 76379 76387 76403 76421 76423 76441 76463 76471 76481 76487 76493 76507 76511 76519 76537 76541 76543 76561 76579 76597 76603 76607 76631 76649 76651 76667 76673 76679 76697 76717 76733 76753 76757 76771 76777 76781 76801 76819 76829 76831 76837 76847 76871 76873 76883 76907 76913 76919 76943 76949 76961 76963 76991 77003 77017 77023 77029 77041 77047 77069 77081 77093 77101 77137 77141 77153 77167 77171 77191 77201 77213 77237 77239 77243 77249 77261 77263 77267 77269 77279 77291 77317 77323 77339 77347 77351 77359 77369 77377 77383 77417 77419 77431 77447 77471 77477 77479 77489 77491 77509 77513 77521 77527 77543 77549 77551 77557 77563 77569 77573 77587 77591 77611 77617 77621 77641 77647 77659 77681 77687 77689 77699 77711 77713 77719 77723 77731 77743 77747 77761 77773 77783 77797 77801 77813 77839 77849 77863 77867 77893 77899 77929 77933 77951 77969 77977 77983 77999 78007 78017 78031 78041 78049 78059 78079 78101 78121 78137 78139 78157 78163 78167 78173 78179 78191 78193 78203 78229 78233 78241 78259 78277 78283 78301 78307 78311 78317 78341 78347 78367 78401 78427 78437 78439 78467 78479 78487 78497 78509 78511 78517 78539 78541 78553 78569 78571 78577 78583 78593 78607 78623 78643 78649 78653 78691 78697 78707 78713 78721 78737 78779 78781 78787 78791 78797 78803 78809 78823 78839 78853 78857 78877 78887 78889 78893 78901 78919 78929 78941 78977 78979 78989 79031 79039 79043 79063 79087 79103 79111 79133 79139 79147 79151 79153 79159 79181 79187 79193 79201 79229 79231 79241 79259 79273 79279 79283 79301 79309 79319 79333 79337 79349 79357 79367 79379 79393 79397 79399 79411 79423 79427 79433 79451 79481 79493 79531 79537 79549 79559 79561 79579 79589 79601 79609 79613 79621 79627 79631 79633 79657 79669 79687 79691 79693 79697 79699 79757 79769 79777 79801 79811 79813 79817 79823 79829 79841 79843 79847 79861 79867 79873 79889 79901 79903 79907 79939 79943 79967 79973 79979 79987 79997 79999 80021 80039 80051 80071 80077 80107 80111 80141 80147 80149 80153 80167 80173 80177 80191 80207 80209 80221 80231 80233 80239 80251 80263 80273 80279 80287 80309 80317 80329 80341 80347 80363 80369 80387 80407 80429 80447 80449 80471 80473 80489 80491 80513 80527 80537 80557 80567 80599 80603 80611 80621 80627 80629 80651 80657 80669 80671 80677 80681 80683 80687 80701 80713 80737 80747 80749 80761 80777 80779 80783 80789 80803 80809 80819 80831 80833 80849 80863 80897 80909 80911 80917 80923 80929 80933 80953 80963 80989 81001 81013 81017 81019 81023 81031 81041 81043 81047 81049 81071 81077 81083 81097 81101 81119 81131 81157 81163 81173 81181 81197 81199 81203 81223 81233 81239 81281 81283 81293 81299 81307 81331 81343 81349 81353 81359 81371 81373 81401 81409 81421 81439 81457 81463 81509 81517 81527 81533 81547 81551 81553 81559 81563 81569 81611 81619 81629 81637 81647 81649 81667 81671 81677 81689 81701 81703 81707 81727 81737 81749 81761 81769 81773 81799 81817 81839 81847 81853 81869 81883 81899 81901 81919 81929 81931 81937 81943 81953 81967 81971 81973 82003 82007 82009 82013 82021 82031 82037 82039 82051 82067 82073 82129 82139 82141 82153 82163 82171 82183 82189 82193 82207 82217 82219 82223 82231 82237 82241 82261 82267 82279 82301 82307 82339 82349 82351 82361 82373 82387 82393 82421 82457 82463 82469 82471 82483 82487 82493 82499 82507 82529 82531 82549 82559 82561 82567 82571 82591 82601 82609 82613 82619 82633 82651 82657 82699 82721 82723 82727 82729 82757 82759 82763 82781 82787 82793 82799 82811 82813 82837 82847 82883 82889 82891 82903 82913 82939 82963 82981 82997 83003 83009 83023 83047 83059 83063 83071 83077 83089 83093 83101 83117 83137 83177 83203 83207 83219 83221 83227 83231 83233 83243 83257 83267 83269 83273 83299 83311 83339 83341 83357 83383 83389 83399 83401 83407 83417 83423 83431 83437 83443 83449 83459 83471 83477 83497 83537 83557 83561 83563 83579 83591 83597 83609 83617 83621 83639 83641 83653 83663 83689 83701 83717 83719 83737 83761 83773 83777 83791 83813 83833 83843 83857 83869 83873 83891 83903 83911 83921 83933 83939 83969 83983 83987 84011 84017 84047 84053 84059 84061 84067 84089 84121 84127 84131 84137 84143 84163 84179 84181 84191 84199 84211 84221 84223 84229 84239 84247 84263 84299 84307 84313 84317 84319 84347 84349 84377 84389 84391 84401 84407 84421 84431 84437 84443 84449 84457 84463 84467 84481 84499 84503 84509 84521 84523 84533 84551 84559 84589 84629 84631 84649 84653 84659 84673 84691 84697 84701 84713 84719 84731 84737 84751 84761 84787 84793 84809 84811 84827 84857 84859 84869 84871 84913 84919 84947 84961 84967 84977 84979 84991 85009 85021 85027 85037 85049 85061 85081 85087 85091 85093 85103 85109 85121 85133 85147 85159 85193 85199 85201 85213 85223 85229 85237 85243 85247 85259 85297 85303 85313 85331 85333 85361 85363 85369 85381 85411 85427 85429 85439 85447 85451 85453 85469 85487 85513 85517 85523 85531 85549 85571 85577 85597 85601 85607 85619 85621 85627 85639 85643 85661 85667 85669 85691 85703 85711 85717 85733 85751 85781 85793 85817 85819 85829 85831 85837 85843 85847 85853 85889 85903 85909 85931 85933 85991 85999 86011 86017 86027 86029 86069 86077 86083 86111 86113 86117 86131 86137 86143 86161 86171 86179 86183 86197 86201 86209 86239 86243 86249 86257 86263 86269 86287 86291 86293 86297 86311 86323 86341 86351 86353 86357 86369 86371 86381 86389 86399 86413 86423 86441 86453 86461 86467 86477 86491 86501 86509 86531 86533 86539 86561 86573 86579 86587 86599 86627 86629 86677 86689 86693 86711 86719 86729 86743 86753 86767 86771 86783 86813 86837 86843 86851 86857 86861 86869 86923 86927 86929 86939 86951 86959 86969 86981 86993 87011 87013 87037 87041 87049 87071 87083 87103 87107 87119 87121 87133 87149 87151 87179 87181 87187 87211 87221 87223 87251 87253 87257 87277 87281 87293 87299 87313 87317 87323 87337 87359 87383 87403 87407 87421 87427 87433 87443 87473 87481 87491 87509 87511 87517 87523 87539 87541 87547 87553 87557 87559 87583 87587 87589 87613 87623 87629 87631 87641 87643 87649 87671 87679 87683 87691 87697 87701 87719 87721 87739 87743 87751 87767 87793 87797 87803 87811 87833 87853 87869 87877 87881 87887 87911 87917 87931 87943 87959 87961 87973 87977 87991 88001 88003 88007 88019 88037 88069 88079 88093 88117 88129 88169 88177 88211 88223 88237 88241 88259 88261 88289 88301 88321 88327 88337 88339 88379 88397 88411 88423 88427 88463 88469 88471 88493 88499 88513 88523 88547 88589 88591 88607 88609 88643 88651 88657 88661 88663 88667 88681 88721 88729 88741 88747 88771 88789 88793 88799 88801 88807 88811 88813 88817 88819 88843 88853 88861 88867 88873 88883 88897 88903 88919 88937 88951 88969 88993 88997 89003 89009 89017 89021 89041 89051 89057 89069 89071 89083 89087 89101 89107 89113 89119 89123 89137 89153 89189 89203 89209 89213 89227 89231 89237 89261 89269 89273 89293 89303 89317 89329 89363 89371 89381 89387 89393 89399 89413 89417 89431 89443 89449 89459 89477 89491 89501 89513 89519 89521 89527 89533 89561 89563 89567 89591 89597 89599 89603 89611 89627 89633 89653 89657 89659 89669 89671 89681 89689 89753 89759 89767 89779 89783 89797 89809 89819 89821 89833 89839 89849 89867 89891 89897 89899 89909 89917 89923 89939 89959 89963 89977 89983 89989 90001 90007 90011 90017 90019 90023 90031 90053 90059 90067 90071 90073 90089 90107 90121 90127 90149 90163 90173 90187 90191 90197 90199 90203 90217 90227 90239 90247 90263 90271 90281 90289 90313 90353 90359 90371 90373 90379 90397 90401 90403 90407 90437 90439 90469 90473 90481 90499 90511 90523 90527 90529 90533 90547 90583 90599 90617 90619 90631 90641 90647 90659 90677 90679 90697 90703 90709 90731 90749 90787 90793 90803 90821 90823 90833 90841 90847 90863 90887 90901 90907 90911 90917 90931 90947 90971 90977 90989 90997 91009 91019 91033 91079 91081 91097 91099 91121 91127 91129 91139 91141 91151 91153 91159 91163 91183 91193 91199 91229 91237 91243 91249 91253 91283 91291 91297 91303 91309 91331 91367 91369 91373 91381 91387 91393 91397 91411 91423 91433 91453 91457 91459 91463 91493 91499 91513 91529 91541 91571 91573 91577 91583 91591 91621 91631 91639 91673 91691 91703 91711 91733 91753 91757 91771 91781 91801 91807 91811 91813 91823 91837 91841 91867 91873 91909 91921 91939 91943 91951 91957 91961 91967 91969 91997 92003 92009 92033 92041 92051 92077 92083 92107 92111 92119 92143 92153 92173 92177 92179 92189 92203 92219 92221 92227 92233 92237 92243 92251 92269 92297 92311 92317 92333 92347 92353 92357 92363 92369 92377 92381 92383 92387 92399 92401 92413 92419 92431 92459 92461 92467 92479 92489 92503 92507 92551 92557 92567 92569 92581 92593 92623 92627 92639 92641 92647 92657 92669 92671 92681 92683 92693 92699 92707 92717 92723 92737 92753 92761 92767 92779 92789 92791 92801 92809 92821 92831 92849 92857 92861 92863 92867 92893 92899 92921 92927 92941 92951 92957 92959 92987 92993 93001 93047 93053 93059 93077 93083 93089 93097 93103 93113 93131 93133 93139 93151 93169 93179 93187 93199 93229 93239 93241 93251 93253 93257 93263 93281 93283 93287 93307 93319 93323 93329 93337 93371 93377 93383 93407 93419 93427 93463 93479 93481 93487 93491 93493 93497 93503 93523 93529 93553 93557 93559 93563 93581 93601 93607 93629 93637 93683 93701 93703 93719 93739 93761 93763 93787 93809 93811 93827 93851 93871 93887 93889 93893 93901 93911 93913 93923 93937 93941 93949 93967 93971 93979 93983 93997 94007 94009 94033 94049 94057 94063 94079 94099 94109 94111 94117 94121 94151 94153 94169 94201 94207 94219 94229 94253 94261 94273 94291 94307 94309 94321 94327 94331 94343 94349 94351 94379 94397 94399 94421 94427 94433 94439 94441 94447 94463 94477 94483 94513 94529 94531 94541 94543 94547 94559 94561 94573 94583 94597 94603 94613 94621 94649 94651 94687 94693 94709 94723 94727 94747 94771 94777 94781 94789 94793 94811 94819 94823 94837 94841 94847 94849 94873 94889 94903 94907 94933 94949 94951 94961 94993 94999 95003 95009 95021 95027 95063 95071 95083 95087 95089 95093 95101 95107 95111 95131 95143 95153 95177 95189 95191 95203 95213 95219 95231 95233 95239 95257 95261 95267 95273 95279 95287 95311 95317 95327 95339 95369 95383 95393 95401 95413 95419 95429 95441 95443 95461 95467 95471 95479 95483 95507 95527 95531 95539 95549 95561 95569 95581 95597 95603 95617 95621 95629 95633 95651 95701 95707 95713 95717 95723 95731 95737 95747 95773 95783 95789 95791 95801 95803 95813 95819 95857 95869 95873 95881 95891 95911 95917 95923 95929 95947 95957 95959 95971 95987 95989 96001 96013 96017 96043 96053 96059 96079 96097 96137 96149 96157 96167 96179 96181 96199 96211 96221 96223 96233 96259 96263 96269 96281 96289 96293 96323 96329 96331 96337 96353 96377 96401 96419 96431 96443 96451 96457 96461 96469 96479 96487 96493 96497 96517 96527 96553 96557 96581 96587 96589 96601 96643 96661 96667 96671 96697 96703 96731 96737 96739 96749 96757 96763 96769 96779 96787 96797 96799 96821 96823 96827 96847 96851 96857 96893 96907 96911 96931 96953 96959 96973 96979 96989 96997 97001 97003 97007 97021 97039 97073 97081 97103 97117 97127 97151 97157 97159 97169 97171 97177 97187 97213 97231 97241 97259 97283 97301 97303 97327 97367 97369 97373 97379 97381 97387 97397 97423 97429 97441 97453 97459 97463 97499 97501 97511 97523 97547 97549 97553 97561 97571 97577 97579 97583 97607 97609 97613 97649 97651 97673 97687 97711 97729 97771 97777 97787 97789 97813 97829 97841 97843 97847 97849 97859 97861 97871 97879 97883 97919 97927 97931 97943 97961 97967 97973 97987 98009 98011 98017 98041 98047 98057 98081 98101 98123 98129 98143 98179 98207 98213 98221 98227 98251 98257 98269 98297 98299 98317 98321 98323 98327 98347 98369 98377 98387 98389 98407 98411 98419 98429 98443 98453 98459 98467 98473 98479 98491 98507 98519 98533 98543 98561 98563 98573 98597 98621 98627 98639 98641 98663 98669 98689 98711 98713 98717 98729 98731 98737 98773 98779 98801 98807 98809 98837 98849 98867 98869 98873 98887 98893 98897 98899 98909 98911 98927 98929 98939 98947 98953 98963 98981 98993 98999 99013 99017 99023 99041 99053 99079 99083 99089 99103 99109 99119 99131 99133 99137 99139 99149 99173 99181 99191 99223 99233 99241 99251 99257 99259 99277 99289 99317 99347 99349 99367 99371 99377 99391 99397 99401 99409 99431 99439 99469 99487 99497 99523 99527 99529 99551 99559 99563 99571 99577 99581 99607 99611 99623 99643 99661 99667 99679 99689 99707 99709 99713 99719 99721 99733 99761 99767 99787 99793 99809 99817 99823 99829 99833 99839 99859 99871 99877 99881 99901 99907 99923 99929 99961 99971 99989 99991 100003 100019 100043 100049 100057 100069 100103 100109 100129 100151 100153 100169 100183 100189 100193 100207 100213 100237 100267 100271 100279 100291 100297 100313 100333 100343 100357 100361 100363 100379 100391 100393 100403 100411 100417 100447 100459 100469 100483 100493 100501 100511 100517 100519 100523 100537 100547 100549 100559 100591 100609 100613 100621 100649 100669 100673 100693 100699 100703 100733 100741 100747 100769 100787 100799 100801 100811 100823 100829 100847 100853 100907 100913 100927 100931 100937 100943 100957 100981 100987 100999 101009 101021 101027 101051 101063 101081 101089 101107 101111 101113 101117 101119 101141 101149 101159 101161 101173 101183 101197 101203 101207 101209 101221 101267 101273 101279 101281 101287 101293 101323 101333 101341 101347 101359 101363 101377 101383 101399 101411 101419 101429 101449 101467 101477 101483 101489 101501 101503 101513 101527 101531 101533 101537 101561 101573 101581 101599 101603 101611 101627 101641 101653 101663 101681 101693 101701 101719 101723 101737 101741 101747 101749 101771 101789 101797 101807 101833 101837 101839 101863 101869 101873 101879 101891 101917 101921 101929 101939 101957 101963 101977 101987 101999 102001 102013 102019 102023 102031 102043 102059 102061 102071 102077 102079 102101 102103 102107 102121 102139 102149 102161 102181 102191 102197 102199 102203 102217 102229 102233 102241 102251 102253 102259 102293 102299 102301 102317 102329 102337 102359 102367 102397 102407 102409 102433 102437 102451 102461 102481 102497 102499 102503 102523 102533 102539 102547 102551 102559 102563 102587 102593 102607 102611 102643 102647 102653 102667 102673 102677 102679 102701 102761 102763 102769 102793 102797 102811 102829 102841 102859 102871 102877 102881 102911 102913 102929 102931 102953 102967 102983 103001 103007 103043 103049 103067 103069 103079 103087 103091 103093 103099 103123 103141 103171 103177 103183 103217 103231 103237 103289 103291 103307 103319 103333 103349 103357 103387 103391 103393 103399 103409 103421 103423 103451 103457 103471 103483 103511 103529 103549 103553 103561 103567 103573 103577 103583 103591 103613 103619 103643 103651 103657 103669 103681 103687 103699 103703 103723 103769 103787 103801 103811 103813 103837 103841 103843 103867 103889 103903 103913 103919 103951 103963 103967 103969 103979 103981 103991 103993 103997 104003 104009 104021 104033 104047 104053 104059 104087 104089 104107 104113 104119 104123 104147 104149 104161 104173 104179 104183 104207 104231 104233 104239 104243 104281 104287 104297 104309 104311 104323 104327 104347 104369 104381 104383 104393 104399 104417 104459 104471 104473 104479 104491 104513 104527 104537 104543 104549 104551 104561 104579 104593 104597 104623 104639 104651 104659 104677 104681 104683 104693 104701 104707 104711 104717 104723 104729\n","id":2339,"permalink":"https://freshrimpsushi.github.io/en/posts/2339/","tags":null,"title":"List of decimals to the 10,000th"},{"categories":"양자역학","contents":"Generalization of Vectors Linear Algebra might be a new concept for science students who haven\u0026rsquo;t studied it yet. To them, a vector refers to a physical quantity with magnitude and direction, representing a point in 3-dimensional space, often denoted as $\\vec{x} = (x_{1}, x_{2}, x_{3})$. This definition is sufficient for studying classical mechanics and electromagnetism. However, in quantum mechanics, concepts like Fourier Analysis, Inner Product of Functions emerge, making it essential to understand the generalized definition of vectors to avoid significant difficulties in studying.\nIn linear algebra, a vector is an abstraction of the intuitive concept of vectors. Entities that have the same properties as 3-dimensional space vectors are collectively referred to as vectors, and the set of these vectors is called a vector space. These properties are the ones that we naturally associate with points in 3-dimensional space. For instance:\nThe sum of two vectors is also a vector. A vector multiplied by a scalar is also a vector. Therefore, a point in 3-dimensional space qualifies as a vector, and the 3-dimensional space itself becomes a vector space. Below are two critical examples in quantum mechanics. Both matrices and functions can be vectors.\nExamples Matrices Consider a set of matrices of size $m \\times n$. Adding two such matrices still results in an $m \\times n$ matrix, and multiplying a matrix by any scalar yields an $m \\times n$ matrix. Hence, this set forms a vector space, and each matrix is considered a vector.\nRealizing that there\u0026rsquo;s essentially no difference between representing a vector as an ordered pair $\\mathbf{x} = (x_{1}, x_{2}, x_{3})$ and representing it as a $1 \\times 3$ matrix $\\mathbf{x} = \\begin{bmatrix} x_{1} \u0026amp; x_{2} \u0026amp; x_{3} \\end{bmatrix}$ might make the concept of matrices being vectors more intuitive.\nFunctions Consider the set of continuous functions. If $f$ and $g$ are continuous functions, their sum $f+g$ is also a continuous function. Similarly, multiplying any continuous function by a scalar, $cf$, results in another continuous function. Therefore, the set of continuous functions forms a vector space, and each continuous function within is a vector.\nIn fact, recalling the notation for vector functions, where the function values are 3-dimensional vectors, can help in understanding this concept.\n$$ f(x,y,z) = (xy, yz, z^{2}) $$\nGeneralization of Inner Product The inner product is an operation that is extremely useful when dealing with vectors. Just as we generalized the concept of vectors, let\u0026rsquo;s generalize the concept of inner products. Instead of using the dot $\\cdot$ for traditional inner products, we use angle brackets $\\left\\langle \\ ,\\ \\right\\rangle$. If $\\mathbf{x} = \\left( x_{1}, x_{2}, x_{3} \\right)$ and $\\mathbf{y}=\\left( y_{1}, y_{2}, y_{3} \\right)$, we represent the inner product as follows:\n$$ \\mathbf{x} \\cdot \\mathbf{y} = x_{1}y_{1} + x_{2}y_{2} + x_{3}y_{3} = \\left\\langle \\mathbf{x}, \\mathbf{y} \\right\\rangle $$\nIn quantum mechanics, instead of a comma, a bar $|$ is used in the middle.\n$$ \\mathbf{x} \\cdot \\mathbf{y} = \\braket{\\mathbf{x} \\vert \\mathbf{y} } $$\nThis is referred to as Dirac Notation. The essence of generalizing vectors lies in the concept that anything satisfying the \u0026lsquo;properties we attribute to vectors\u0026rsquo; can be called a vector, regardless of what it is. The same applies to the generalization of inner products; the concept of \u0026lsquo;adding up the product of each corresponding component\u0026rsquo; is maintained. Depending on the vector space being dealt with, the definition of inner product can vary as follows:\nExamples Matrices Consider two matrices $A = \\begin{pmatrix} a_{11} \u0026amp; a_{12} \\ a_{21} \u0026amp; a_{22} \\end{pmatrix}, B = \\begin{pmatrix} b_{11} \u0026amp; b_{12} \\ b_{21} \u0026amp; b_{22} \\end{pmatrix}$. Their inner product is defined as the \u0026lsquo;sum of the products of corresponding components\u0026rsquo;, just like the inner product of 3-dimensional vectors.\n$$ \\braket{ A \\vert B } = a_{11}b_{11} + a_{12}b_{12} + a_{21}b_{21} + a_{22}b_{22} $$\nFunctions Since we have established that functions are also vectors, we can define the inner product of two functions. The inner product of functions is defined as follows, using definite integration:\n$$ \\braket{\\psi \\vert \\phi} = \\int \\psi^{\\ast}(x) \\phi(x) dx $$\nHere, $\\psi^{\\ast}$ represents the complex conjugate of $\\psi. Be mindful of the notation ambiguity. The reasons for defining the inner product of functions this way are well explained in 'Why the Inner Product of Functions is Defined Using Definite Integration'.\nWave Functions in Quantum Mechanics In quantum mechanics, a wave function represents the state of a particle with respect to position and time and is typically expressed using exponential functions.\n$$ \\psi (x,t) = e^{i(kx + \\omega t)} $$\nThey are commonly denoted by $\\psi$ and $\\phi$, pronounced as [psi] and [phi], respectively. $k$ is the wave number, satisfying the relationship with momentum, $p = \\hbar k$. Here, $\\hbar$ is a constant, so $k$ can be considered equivalent to momentum in quantum mechanics. $\\omega$ is the angular frequency, satisfying the energy relationship, $E = \\hbar \\omega$.\nHilbert Space The rigorous definition of a Hilbert Space is a 'complete inner product space'. While understanding its mathematical significance is beneficial, it\u0026rsquo;s not essential for undergraduate physics students studying quantum mechanics. The important thing to note is that a collection with very favorable properties is named Hilbert Space and that the set of wave functions constitutes a Hilbert Space. This means various excellent mathematical tools can be utilized to handle wave functions.\n","id":1509,"permalink":"https://freshrimpsushi.github.io/en/posts/1509/","tags":null,"title":"Vector, Inner Product, Wave Function, Hilbert Space in Quantum Mechanics"},{"categories":"집합론","contents":"Definition 1 Set: A collection of distinct objects that serves as the subject of our intuition or thought is called a set. Element: An object belonging to a set is called an element. Propositional Function: For an element $x$ in the set $U$, a proposition $p(x)$ that is either true or false is referred to as a propositional function on $U$. Explanation In mathematics, the concept of sets is nearly as fundamental as a native language. Perhaps what makes it even better than natural language is its ability to eliminate inherent ambiguity and allow logical reasoning based solely on its definition and form. Typically, elements are represented in lowercase, and sets in uppercase. If $a$ belongs to $A$, it is written as $a \\in A$, and we say \u0026ldquo;$a$ is an element of $A$.\u0026rdquo; Of course, there is no strict requirement to represent elements and sets with alphabetic uppercase and lowercase, and it is common to denote the set of all natural numbers as $\\mathbb{N}$, where $N \\in \\mathbb{N}$ would also be acceptable. Enumeration: The set of natural numbers $\\mathbb{N}$ can be expressed as $\\left\\{1, 2, 3, \\cdots \\right\\}$. This representation, where the elements of the set are explicitly listed, is called enumeration. Set-Builder Notation: In contrast to enumeration, a set can also be represented as the collection of elements that satisfy certain conditions. For example, if we want to represent the set of natural numbers greater than $5$, we can express it as $\\left\\{ x \\in \\mathbb{N} : x \u0026gt; 5 \\right\\}$. This notation is known as set-builder notation or conditional specification. It is important to note that a propositional function is defined by the proposition function itself. Although it conforms to the definition of a function in set theory, it is crucial to recognize that it can be defined solely in terms of propositions, without depending on set theory. This clarity is essential to avoid difficulties in freely using set-builder notation, as circular definitions of functions could arise if this aspect is unclear. Additionally, propositional functions are also referred to as logical expressions. Heung-Chun Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach, p.47, 73, 81, 85.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1316,"permalink":"https://freshrimpsushi.github.io/en/posts/1316/","tags":null,"title":"The Definitions of Sets and Propositional Functions"},{"categories":"집합론","contents":"Definition 1 A statement that is either true or false is called a proposition. Propositions have a single truth value – either true or false. If the truth values of two propositions $p$ and $q$ are the same, then $p$ and $q$ are said to be logically equivalent, denoted as $p \\equiv q$. The following symbols are used as connectives to form compound propositions:\nNegation: $\\lnot$ Conjunction: $\\land$ Disjunction: $\\lor$ Conditional: $\\to$ Biconditional: $\\leftrightarrow$ Truth Table Usually, true is represented by $T$, and false by $F$. The truth values of propositions formed by applying the connectives can be conveniently verified using a truth table:\nNegation If $p$ is true, then $\\lnot p$ is false, and if $p$ is false, then $\\lnot p$ is true.\n$\\text{NOT}$ gate Conjunction If both $p$ and $q$ are true, then $p \\land q$ is true; otherwise, it is false. In fields like computer engineering, $0$ is often considered false, and any non-zero number is considered true. Considering two non-zero numbers $a$ and $b$, $a \\times b = ab \\ne 0$ is true, but if either $a$ or $b$ is $0$, then $a \\times b = 0$ is false. In this sense, $\\land$ is called logical \u0026lsquo;AND\u0026rsquo;.\n$\\text{AND}$ gate Disjunction If at least one of $p$ and $q$ is true, then $p \\lor q$ is true; it is false only when both are false. Similar to conjunction, $\\lor$ is called logical \u0026lsquo;OR\u0026rsquo;. Of course, if $b = -a \\ne 0$, then $a$ and $b$ are both true, but $a+b = 0$ is false. Let\u0026rsquo;s not dwell on this exception; it\u0026rsquo;s why it\u0026rsquo;s called \u0026rsquo;logical OR\u0026rsquo; and not just \u0026lsquo;OR\u0026rsquo;.\n$\\text{OR}$ gate Conditional If $p$ is true and $q$ is true, then $p \\to q$ is true. It\u0026rsquo;s important to note that, contrary to natural language, if $p$ is false, $p \\to q$ is true regardless of the truth value of $q$. Additionally, $p \\to q \\equiv \\lnot p \\lor q$, which can be easily proven through a truth table. Refer to the bottom of the main text.\nBiconditional If both $p \\to q$ and $q \\to p$ are true, then $p \\leftrightarrow q$ is true. In mathematical notation, $(p \\to q) \\land (q \\to p) \\equiv p \\leftrightarrow q$. In terms of a truth table, $p \\leftrightarrow q$ is true only when $p$ and $q$ have the same truth value.\nProof of Conditional Based on the definitions of negation and disjunction:\n■\nHeung-Chun Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach, pp. 3-21.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1299,"permalink":"https://freshrimpsushi.github.io/en/posts/1299/","tags":null,"title":"Propositions and Connectives, Truth Tables"},{"categories":"측도론","contents":"Theorem1 (a) Let $\\nu$ be a signed measure defined on a measurable space $(X, \\mathcal{E})$. Then there exist a positive set $P$ and a negative set $N$ for $\\nu$, satisfying the following:\n$$ P \\cup N=X \\quad \\text{and} \\quad P \\cap N =\\varnothing $$\nSuch a $X=P \\cup N$ is called a Hahn decomposition for $\\nu$.\n(b) Let $P^{\\prime}, N^{\\prime}$ be another pair of sets satisfying (a). Then the following sets are null sets for $\\nu$:\n$$ (P-P^{\\prime}) \\cup (P^{\\prime}-P)=(N-N^{\\prime}) \\cup (N^{\\prime}-N) $$\nThis can be denoted using the symmetric difference symbol as follows:\n$$ P\\Delta P^{\\prime}=N\\Delta N^{\\prime} $$\nExplanation (a) For any given measurable space, it is possible to separate the set $X$ into positive and negative sets with respect to $\\nu$ defined on the measurable space.\n(b) As stated above, even if there are multiple ways to divide the set $X$, essentially, there is no difference. $P$ and $P^{\\prime}$, $N$ and $N^{\\prime}$ always differ by only a null set, so they may be different from the set perspective but are the same from the measure perspective.\nProof Strategies: The** proof of this theorem itself is not very difficult, but the flow of the proof is not trivial, so I will explain it concretely before starting. First, define some positive set $P$. Then define $N$ as $N:=X-P$. If $N$ is a negative set, then the proof for (a) is complete. Before proving that $N$ is a negative set, we will verify that $N$ has two properties as defined above. Finally, we will use proof by contradiction. Assuming $N$ is not a negative set, we will complete the proof by showing that a contradiction arises using the two properties.\nWithout loss of generality, assume that $\\nu$ does not take the value $+\\infty$. For the other case, the same proof applies by considering $-\\nu$. Let $C$ be the collection of all positive sets in $\\mathcal{E}$. Then, by assumption, $\\nu$ does not take the value $+\\infty$, so there exists $M$ defined as below:\n$$ M:=\\sup \\limits_{P \\in C } \\nu(P) \u0026lt; \\infty $$\nNow, we can show that there exists a maximizer $P$ satisfying $\\nu(P)=M$. Consider the following maximizing sequence $\\left\\{ P_j \\right\\}$:\n$$ \\lim \\limits_{j \\rightarrow \\infty} \\nu (P_j)=M $$\nSince there is no containment relationship between $P_j$\u0026rsquo;s, consider the following $\\tilde{P_j}$:\n$$ \\tilde{P_j} :=\\bigcup \\limits_{k=1}^j P_k $$\nThen, $\\nu(P_j) \\le \\nu (\\tilde{P_j}) \\le M$, so $\\left\\{ \\tilde{P_j} \\right\\}$ is a maximizing sequence. Also, it is obvious that $\\tilde{P_1} \\subset \\tilde{P_2}\\subset \\cdots $ by definition. Now, define $P$ as follows:\n$$ P := \\bigcup \\limits_{j=1}^\\infty \\tilde{P_j} $$\nThen, the following holds:\n$$ \\nu(P)=\\lim \\limits_{j\\rightarrow \\infty} \\nu(\\tilde{P_j})=M $$\nThus, we have shown the existence of a maximizer satisfying $\\nu(P)=M$. Moreover, since $P$ is the countable sum of positive sets, it is a positive set. In fact, such $P$ and $N:=X-P$ are the decomposition mentioned in the theorem. The process of proving that $N$ is such a negative set remains. Let\u0026rsquo;s now consider $N:=X \\setminus P$. As explained above, the proof ends if we show that $N$ is a negative set. First, let\u0026rsquo;s prove that such $N$ has the following two properties:\nClaim 1 $N$ does not contain any positive set with a measure value greater than $0$. In other words, it does not contain any non-null positive set. That is, if $\\nu(E)\u0026gt;0$ and $E$ is a positive set, then $E \\not \\subset N$.\nNote that it is possible for a set $E \\subset N$ to exist that is neither a positive nor a negative set. In other words, a subset of $N$ can be 1. a null set, 2. a negative set, or 3. a set that is neither positive nor negative.\nProof\nSuppose $E\\subset N$ is a positive set and $\\nu(E) \u0026gt;0$. Then, by the definition of $N$, $E$ and $P$ are disjoint sets. Therefore, the following holds:\n$$ \\nu(P \\cup E)=\\nu(P)+\\nu(E) $$\nHowever, since $\\nu(P)=M$, the following holds:\n$$ \\nu(P \\cup E)=\\nu(P)+\\nu(E)\u0026gt;M $$\nBut this contradicts the assumption that $M=\\sup \\nu (F)\\ \\forall F\\in \\mathcal{E}$. Therefore, there does not exist $E \\subset N$ such that $E$ is a positive set and $\\nu(E)\u0026gt;0$.\nClaim 2 If $A \\subset N$ and $\\nu(A)\u0026gt;0$, then there exists $B \\subset A$ such that $\\nu(B) \u0026gt; \\nu(A)$.\nProof\nLet\u0026rsquo;s say $A \\subset N$ and $\\nu(A)\u0026gt;0$. Then, by Claim 1, $A$ is not a positive set. Therefore, it is neither a null set nor a positive set. Hence, there exists $C$ satisfying the following conditions2:\n$$ C \\subset A,\\ \\nu(C) \u0026lt;0 $$\nNow, let\u0026rsquo;s define $B:=A-C$. Then, the following holds:\n$$ \\nu(A)=\\nu(B)+\\nu(C) \u0026lt; \\nu(B) $$\nNow, let\u0026rsquo;s assume $N$ is not a negative set. By showing that a contradiction arises using the above two properties, we prove that $N$ is a negative set.\nPart 1.\nLet $\\left\\{ A_j \\right\\}$ be a sequence of subsets of $N$. Let $\\left\\{ n_j \\right\\}$ be a sequence of natural numbers. Assuming $N$ is not a negative set, there exists some $B \\subset N$ with $\\nu (B) \u0026gt;0$. Let\u0026rsquo;s say the smallest $n_j$ satisfying $\\nu (B) \u0026gt; \\frac{1}{n_j}$ is $n_1$, and let\u0026rsquo;s call such $B$ as $A_1$. Since $\\nu (B)=\\nu (A_1)\u0026gt;0$, the process done for $N$ can be applied to $A_1$ equally.\nPart 2\nAgain, there exists some $B\\subset A_1$ with $\\nu(B)\u0026gt;0$, and by Claim 2, $\\nu(B) \u0026gt; \\nu (A_1)$. Therefore, there exists a natural number $n$ such that $\\nu(B) \u0026gt; \\nu (A_1)+\\frac{1}{n}$. Let\u0026rsquo;s call the smallest such natural number $n_2$, and such $B$ as $A_2$.\nPart 3\nRepeating the same process, $n_j$ is the smallest natural number for which there exists some $B \\subset A_{j-1}$ satisfying $\\nu(B)\u0026gt;\\nu (A_{j-1}) + \\dfrac{1}{n_j}$, and such $B$ is called $A_j$. Now, let\u0026rsquo;s define $A=\\bigcap \\nolimits_1^\\infty A_j$. Since $\\nu$ is assumed not to take the value $+\\infty$ and by the property of signed measure $(B)$, the following holds:\n$$ \\begin{align*} +\\infty \\gt \\nu(A) \u0026amp;= \\nu \\left(\\bigcap \\nolimits_1^\\infty A_j \\right) \\\\ \u0026amp;= \\lim \\limits_{j \\rightarrow \\infty} \\nu (A_j) \\\\ \u0026amp;\\ge \\lim \\limits_{j\\rightarrow \\infty} \\left( \\nu(A_{j-1}) +\\frac{1}{n_j} \\right) \\\\ \u0026amp;\\ge \\lim \\limits_{j\\rightarrow \\infty} \\left( \\nu (A_{j-2}) + \\frac{1}{n_{j-1}} +\\frac{1}{n_j} \\right) \\\\ \u0026amp;\\vdots \\\\ \u0026amp;\\ge \\lim \\limits_{j\\rightarrow \\infty} \\left( \\nu (A_{1}) + \\frac{1}{n_{2}}+\\cdots +\\frac{1}{n_j} \\right) \\\\ \u0026amp;\\ge \\lim \\limits_{j\\rightarrow \\infty} \\left( \\frac{1}{n_1}+ \\frac{1}{n_{2}}+\\cdots +\\frac{1}{n_j} \\right) \\\\ \u0026amp;= \\sum \\limits_{j=1}^\\infty \\frac{1}{n_j} \\end{align*} $$\nSince the series is finite, the limit is $0$.\n$$ \\lim \\limits_{j\\rightarrow \\infty} \\frac{1}{n_j} =0 $$\nTherefore, we obtain the following:\n$$ \\begin{equation} \\lim \\limits_{j\\rightarrow \\infty} n_j =\\infty \\label{eq1} \\end{equation} $$\nHowever, as seen in Part 1, by Claim 2, there exists some natural number $n$ for which there exists $B \\subset A$ satisfying $\\nu(B) \u0026gt; \\nu(A) +\\dfrac{1}{n}$. Then, by the definition of $A$, $A \\subset A_{j-1}$, and by Claim 2, the sequence $\\left\\{ \\nu (A_j) \\right\\}$ is increasing. Therefore, since $\\nu (A) =\\lim \\limits_{j \\rightarrow \\infty} \\nu(A_j)$, $\\nu(A) \u0026gt; \\nu(A_{j-1})$.\nAdditionally, by $(1)$, for sufficiently large $j$, $n_j \u0026gt;n$. Therefore, the following holds:\n$$ \\nu (B) \u0026gt; \\nu (A) +\\frac{1}{n}\u0026gt;\\nu (A_{j-1}) +\\frac{1}{n} \u0026gt; \\nu(A_{j-1}) +\\frac{1}{n_j} $$\nBut this contradicts the definition of $n_j$ and $A_j$. Therefore, the assumption that $N$ is not a negative set is wrong. Hence, $N$ is a negative set.\nLet\u0026rsquo;s consider $P^{\\prime}$, $N^{\\prime}$ as another decomposition satisfying the theorem. Then, the following holds:\n$$ P^{\\prime} \\cup N^{\\prime} =X \\quad \\text{and} \\quad P^{\\prime}\\cap N^{\\prime} =\\varnothing $$\nTherefore, we can see that $P-P^{\\prime} \\subset P$, $P-P^{\\prime}\\subset N^{\\prime}$. Then, $P-P^{\\prime}$ is both a positive set and a negative set, which is only possible if it\u0026rsquo;s a null set, so $P-P^{\\prime}$ is $\\nu-\\mathrm{null}$. Similarly, $\\nu -\\mathrm{null}$ can be shown for $P^{\\prime}-P$, $N-N^{\\prime}$, and $N^{\\prime}-N$.\n■\nGerald B. Folland, Real Analysis: Modern Techniques and Their Applications (2nd Edition, 1999), p86-87\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIf not, A must be either a null set or a positive set by definition.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1308,"permalink":"https://freshrimpsushi.github.io/en/posts/1308/","tags":null,"title":"Hahn Decomposition Theorem"},{"categories":"편미분방정식","contents":"Explanation1 When emphasizing that x and p are variables of a partial differential equation, they are denoted in normal font as $x,p \\in \\mathbb{R}^{n}$, and when emphasizing them as functions of $s$, they are denoted in bold font as $\\mathbf{x}, \\mathbf{p} \\in \\mathbb{R}^{n}$. Characteristic Equations\n$$ \\begin{cases} \\dot{\\mathbf{p}} (s) = -D_{x}F\\big(\\mathbf{p}(s),\\ z(s),\\ \\mathbf{x}(s) \\big)-D_{z}F\\big(\\mathbf{p}(s),\\ z(s),\\ \\mathbf{x}(s) \\big)\\mathbf{p}(s) \\\\ \\dot{z}(s) = D_pF\\big(\\mathbf{p}(s),\\ z(s),\\ \\mathbf{x}(s) \\big) \\cdot \\mathbf{p}(s) \\\\ \\dot{\\mathbf{x}}(s) = D_pF\\big(\\mathbf{p}(s),\\ z(s),\\ \\mathbf{x}(s) \\big) \\end{cases} $$\nThe solution of nonlinear first-order partial differential equations using characteristic equations varies slightly depending on how the differential equation is given. This is distinguished by the linearity of the given differential equation and differs for cases of linear, quasi-linear, and fully nonlinear. The stronger the nonlinearity, the more challenging it is.\nSolution Homogeneous Linear If the given partial differential equation is completely linear, it can be solved most easily. The condition for $\\mathbf{p}(s)$ in the characteristic equation is so simple that it is unnecessary. Consider the following linear and homogeneous differential equation.\n$$ \\begin{equation} F(Du, u, x) = \\mathbf{b}(x)\\cdot Du(x)+c(x)u(x)=0 \\quad (x\\in \\Omega \\subset \\mathbb{R}^{n}) \\label{eq1} \\end{equation} $$\nHere, if we set the variables of $F$ as $p, z, x$, it would be as follows.\n$$ \\begin{equation} F(p,\\ z,\\ x)=\\mathbf{b}(x)\\cdot p +c(x)z=b_{1}p_{1}+\\cdots +b_{n}p_{n}+cz = 0 \\label{eq2} \\end{equation} $$\nIf we calculate $D_{p}F$, it would be as follows.\n$$ D_{p}F=(F_{p_{1}}, \\dots, F_{p_{n}})=(b_{1}, \\dots, b_{n})=\\mathbf{b}(x) $$\nThen, the characteristic equation is as follows.\n$$ \\begin{align*} \\dot{\\mathbf{x}}(s) \u0026amp;= \\mathbf{b}(x) \\\\ \\dot{z}(s) \u0026amp;= \\mathbf{b}(\\mathbf{x}(s))\\cdot \\mathbf{p}(s) \\end{align*} $$\nBy $(2)$, $\\dot{z}(s)$ is as follows.\n$$ \\dot{z}(s) = -c(\\mathbf{x}(s))z $$\nTherefore, the characteristic equation for a homogeneous linear first-order partial differential equation is as follows.\n$$ \\left\\{ \\begin{align*} \\dot{\\mathbf{x}}(s)\u0026amp;=\\mathbf{b}(x) \\\\ \\dot{z}(s) \u0026amp;= -c(\\mathbf{x}(s))z \\end{align*} \\right. $$\nHere, it can be seen through an example that the characteristic equation for $\\mathbf{p}(s)$ is not necessary to solve the problem.\nExample Suppose the following differential equation is given.\n$$ \\left\\{ \\begin{align*} x_{1} u_{x_{2}} - x_{2} u_{x_{1}} \u0026amp;= u \u0026amp;\u0026amp; \\text{in } \\Omega \\\\ u\u0026amp;=g \u0026amp;\u0026amp; \\text{on } \\Gamma \\end{align*} \\right. $$\n$\\Omega=\\left\\{ x_{1}\u0026gt;0,\\ x_{2}\u0026gt;0 \\right\\}$ $\\Gamma=\\left\\{ x_{1}\u0026gt;0,\\ x_{2}=0 \\right\\}$ Then in $(1)$, $\\mathbf{b}=(-x_{2},\\ x_{1}), c=-1$. Thus, the characteristic equation is as follows.\n$$ \\left\\{ \\begin{align*} \\dot{x}^{1} \u0026amp;= -x^{2} \\\\ \\dot{x}^{2} \u0026amp;=x^{1} \\\\ \\dot{z}\u0026amp;=z \\end{align*} \\right. $$\nSince this is a simple ordinary differential equation, it can be easily solved as follows.\n$$ \\left\\{ \\begin{align*} x^{1}(s) \u0026amp;=x^{0}\\cos s \\\\ x^{2}(s)\u0026amp;=x^{0} \\sin s \\\\ z(s)\u0026amp;=z^{0}e^s=g(x^{0})e^s \\end{align*} \\right. $$\nHere, $x^{0}$ is a constant set to pass through the $x_{1}-$axis $(\\Gamma)$ when $s=0$. Then, by the boundary condition $z=u=g\\ \\mathrm{on}\\ \\Gamma$, when $s=0$, $z(0)=z^{0}=g(x^{0})$. Now, fix the point $(x_{1},\\ x_{2}) \\in \\Omega$.\n$$ (x_{1},\\ x_{2})=(x^{1}(s),\\ x^{2}(s)) = (x^{0} \\cos (s),\\ x^{0} \\sin (s)) $$\nThen, for $s\u0026gt;0, x^{0}\u0026gt;0$, we obtain the following.\n$$ x_{1}^{2} + x_{2}^{2} = (x^{0})^{2}\\cos^{2}(s) + (x^{0})^{2}\\sin^{2}(s) = (x^{0})^{2} \\implies x^{0}=({x_{1}}^{2}+{x_{2}}^{2})^{1/2} \\\\ \\dfrac{x_{2}}{x_{1}} = \\dfrac{x^{0}\\sin (s)}{x^{0} \\cos (s)} = \\tan (s) \\implies s=\\arctan \\left( \\frac{x_{2}}{x_{1}} \\right) $$\nTherefore, the solution of the equation is as follows.\n$$ \\begin{align*} u(x)\u0026amp;=u(x^{1}(s),\\ x^{2}(s)) \\\\ \u0026amp;= z(s) \\\\ \u0026amp;=g(x^{0})e^s \\\\ \u0026amp;= g(({x_{1}}^{2}+{x_{2}}^{2})^{1/2})e^{\\arctan \\left(\\frac{x_{2}}{x_{1}}\\right)} \\end{align*} $$\n■\nQuasi-Linear The following describes cases where the given differential equation is linear with respect to the highest order of differentiation. As we are dealing with first-order differential equations, it refers to cases where they are linear with respect to first-order derivatives.\n$$ F(Du,\\ u,\\ x)=\\mathbf{b}(x,\\ u(x))\\cdot Du(x)+c(x,\\ u(x))=0 $$\nHere, if we set the variables of $F$ as $p, z, x$, it would be as follows.\n$$ \\begin{equation} F(p, z, x)=\\mathbf{b}(x, z)\\cdot p + c(x, z)=b_{1}p_{1} + \\cdots + b_{n} p_{n} +c=0 \\label{eq3} \\end{equation} $$\nIf we calculate $D_{p}F$, it would be as follows.\n$$ D_pF=(F_{p_{1}},\\ \\cdots,\\ F_{p_{n}})=(b_{1},\\ \\cdots,\\ b_{n})=\\mathbf{b}(x,\\ z) $$\nThen, the characteristic equation is as follows.\n$$ \\begin{align*} \\dot{\\mathbf{x}}(s) \u0026amp;= \\mathbf{b}(\\mathbf{x}(s),\\ z(s)) \\\\ \\dot{z}(s) \u0026amp;= \\mathbf{b}(\\mathbf{x}(s),\\ z(s))\\mathbf{p}(s)=-c(\\mathbf{x}(s),\\ z(s)) \\end{align*} $$\nThe second equality for $\\dot{z}$ is valid due to $(3)$. Even in this case, the condition for $\\mathbf{p}(s)$ is not necessary to solve the problem.\nExample Suppose the following differential equation is given.\n$$ \\left\\{ \\begin{align*} u_{x_{1}} + u_{x_{2}} \u0026amp;= u^{2} \u0026amp;\u0026amp; \\text{in } \\Omega \\\\ u\u0026amp;=g \u0026amp;\u0026amp; \\text{on } \\Gamma \\end{align*} \\right. $$\n$\\Omega=\\left\\{ x_{2}\u0026gt;0 \\right\\}$ $\\Gamma=\\left\\{x_{2}=0 \\right\\}$ Then in $(3)$, $\\mathbf{b}=(1,\\ 1)$, $c=-z^{2}$. Thus, the characteristic equation is as follows.\n$$ \\left\\{ \\begin{align*} \\dot{x}^{1} \u0026amp;=1, \\dot{x}^{2}=1 \\\\ \\dot{z} \u0026amp;= z^{2} \\end{align*} \\right. $$\nSince these are simple ordinary differential equations, they can be solved as follows.\n$$ \\left\\{ \\begin{align*} x^{1}(s) \u0026amp;= x^{0}+s, x^{2}(s)=s \\\\ z(s)\u0026amp;=\\frac{z^{0}}{1-sz^{0}}=\\frac{g(x^{0})}{1-sg(x^{0})} \\end{align*} \\right. $$ $x^{0}$ is a constant set to pass through the $x_{2}-$axis $(\\Gamma)$ when $s=0$. Now, fix the point $(x_{1},\\ x_{2}) \\in \\Omega$.\n$$ (x_{1}, x_{2})=(x^{1}(s), x^{2}(s))=(x^{0}+s, s) $$\nThen, for $s\u0026gt;0, x^{0} \\in \\mathbb{R}$, we obtain the following. $$ s=x_{2}, \\quad x^{0}=x_{1}-x_{2} $$\nTherefore, the solution of the equation is as follows.\n$$ \\begin{align*} u(x) \u0026amp;= u(x^{1}(s),\\ x^{2}(s)) \\\\ \u0026amp;= z(s) \\\\ \u0026amp;= \\frac{g(x^{0})}{1-sg(x^{0})} \\\\ \u0026amp;= \\frac{g(x_{1}-x_{2})}{1-x_{2}g(x_{1}-x_{2})} \\end{align*} $$\nOf course, this is only valid when $1-x^{2}g(x_{1}-x_{2})\\ne 0$.\n■\nFully Nonlinear Suppose the following differential equation is given.\n$$ \\begin{align*} u_{x_{1}}u_{x_{2}} \u0026amp;= u \u0026amp;\u0026amp; \\text{in } \\Omega \\\\ u \u0026amp;= x_{2}^{2} \u0026amp;\u0026amp; \\text{on } \\Gamma \\end{align*} $$\n$\\Omega=\\left\\{ x_{1}\u0026gt;0 \\right\\}$ $\\Gamma=\\left\\{x_{1}=0 \\right\\}$ If we set the variables of $F$ as $P, z, x$, it would be as follows.\n$$ F(p, z, x)=p_{1}p_{2}-z $$\nThus, the characteristic equation is as follows.\n$$ \\begin{align*} \\dot{p}^{1} \u0026amp;= p^{1},\\quad \\dot{p}^{2}=p^{2} \\\\ \\dot{z} \u0026amp;= 2p^{1}p^{2} \\\\ \\dot{x}^{1} \u0026amp;= p^{2},\\quad \\dot{x}^{2}=p^{1} \\end{align*} $$\nFirst, if we solve the differential equation for $p$, it would be as follows.\n$$ p^{1}(s)=p_{1}^{0}e^s,\\ \\ p^{2}(s)=p_{2}^{0}e^s $$\nHere, $p_{1}^{0}=p(0)$, $p_{2}^{0}=p(0)$. Then, since $\\dot{z}(s)=2p_{1}^{0}p_{2}^{0}e^{2s}$, $z$ is as follows.\n$$ z(s)=p_{1}^{0}p_{2}^{0}e^{2s}+C $$\nSince $z(0)=z^{0}=p_{1}^{0}p_{2}^{0}+C$, $C=z^{0}-p_{1}^{0}p_{2}^{0}$. Therefore, it is as follows.\n$$ z(s)=z^{0}+p_{1}^{0}p_{2}^{0}(e^{2s}-1) $$\nSimilarly, if we calculate $x^{1}$ and $x^{2}$, it would be as follows.\n$$ \\begin{equation} \\left\\{ \\begin{aligned} p^{1}(s) \u0026amp;= p_{1}^{0}e^s \\\\ p^{2}(s) \u0026amp;= p_{2}^{0}e^s \\\\ z(s) \u0026amp;= z^{0}+p_{1}^{0}p_{2}^{0}(e^{2s}-1) \\\\ x^{1}(s) \u0026amp;= p_{2}^{0}(e^s-1) \\\\ x^{2}(s) \u0026amp;= x^{0}+p_{1}^{0}(e^s-1) \\end{aligned} \\right. \\label{eq4} \\end{equation} $$\nHere, $x^{0}$ is a constant set to pass through the $x_{1}-$axis $(\\Gamma)$ when $s=0$. Since $u_{x_{2}}=p^{2}$ and by the boundary condition $u=x_{2}^{2}$ when $x_{1}=0$ ($s=0$), $p_{2}^{0}=u(0,\\ x^{0})=2x^{0}$. Also, as the given differential equation is $u_{x_{1}}u_{x_{2}}=u$, $p_{1}^{0}p_{2}^{0}=z^{0}=(x^{0})^{2}$ and $p_{1}^{0}=\\frac{x^{0}}{2}$. If we substitute all these into $(4)$, we obtain the following.\n$$ \\left\\{ \\begin{align*} p^{1}(s) \u0026amp;= \\frac{x^{0}}{2}e^s \\\\ p^{2}(s) \u0026amp;= 2x^{0}e^s \\\\ z(s) \u0026amp;= (x^{0})^{2}e^{2s} \\\\ x^{1}(s) \u0026amp;= 2x^{0}(e^s-1) \\\\ x^{2}(s) \u0026amp;= x^{0}+\\frac{x^{0}}{2}(e^s-1) \\end{align*} \\right. $$\nNow, fix the point $(x_{1}, x_{2})\\in \\Omega$.\n$$ (x_{1}, x_{2})=(x^{1}(s), x^{2}(s))=\\left( 2x^{0}(e^s -1), \\frac{x^{0}}{2}(e^s+1) \\right) $$\nThen, for $s,\\ x^{0}$, we obtain the following.\n$$ x^{0}=\\frac{4x_{2}-x_{1}}{4},\\ \\ e^s=\\frac{x_{1}+4x_{2}}{4x_{2}-x_{1}} $$\nTherefore, the solution of the equation is as follows.\n$$ u(x)=u(x^{1}(s),\\ x^{2}(s))=z(s)=(x^{0})^{2}e^{2s}=\\dfrac{(x_{1}+4x_{2})^{2}}{16} $$\n■\nLawrence C. Evans, Partial Differential Equations (2nd Edition, 2010), p99-102\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1074,"permalink":"https://freshrimpsushi.github.io/en/posts/1074/","tags":null,"title":"Solution of Nonlinear First Order PDE Using Characteristic Equations"},{"categories":"푸리에해석","contents":"Definition The series for $2L$-periodic function $f$ is defined as the Fourier series of $f$ as follows:\n$$ \\begin{align*} \\lim \\limits_{N \\rightarrow \\infty} S^{f}_{N}(t) \u0026amp;= \\lim \\limits_{N \\to \\infty}\\left[ \\dfrac{a_0}{2}+\\sum \\limits_{n=1}^{N} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L} + b_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right] \\\\ \u0026amp;= \\dfrac{a_0}{2}+\\sum \\limits_{n=1}^{\\infty} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L} + b_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\end{align*} $$\nHere, each coefficient $a_{0}, a_{n}, b_{n}$ is called the Fourier coefficient, and its value is as follows:\n$$ \\begin{align*} \\\\ a_0 \u0026amp;=\\dfrac{1}{L}\\int_{-L}^{L}f(t)dt \\\\ a_{n} \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{n\\pi t}{L} dt \\\\ b_{n} \u0026amp;=\\dfrac{1}{L}\\int_{-L}^{L}f(t)\\sin \\dfrac{n\\pi t}{L}dt \\end{align*} $$\nDescription The Fourier series represents any function as a series expansion of trigonometric functions, famously developed by the French mathematician Joseph Fourier for solving heat equations. The term \u0026ldquo;any function\u0026rdquo; is used because if there is a function defined on a certain interval $(a,b)$, it can be replicated (Ctrl+C, Ctrl+V) to produce a $(b-a)$-periodic function.\nThe core principle is to express it as a linear combination of orthogonal trigonometric functions, analogous to decomposing $(4,-1,7)$ as follows in three-dimensional vectors:\n$$ (4,-1,7) = a_{1}\\hat{\\mathbf{e}}_{1} + a_{2}\\hat{\\mathbf{e}}_{1} + a_{3}\\hat{\\mathbf{e}}_{1} $$\nIndeed, the Fourier series of $f$ not only has minimal error with $f$ but also converges pointwise under well-defined conditions to $f$.\n$$ f(t) = \\dfrac{a_{0}}{2}+\\sum \\limits_{n=1}^{\\infty} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L}t + b_{n}\\sin\\dfrac{n\\pi t}{L} \\right) $$\nDerivation Regression Analysis1 Part 1\nThe goal is to express the function $f(t)$ as a linear combination of $1, \\cos \\dfrac{\\pi t}{L}, \\cos\\dfrac{2\\pi t}{L}, \\cdots, \\sin \\dfrac{\\pi t}{L}, \\sin \\dfrac{2\\pi t}{L}, \\cdots $s. Thus, assuming $S^{f}_{N}(t)=\\dfrac{1}{2}{\\alpha_0}+\\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right)$, $f(t)$ can be represented as follows:\n$$ f(t)=S^{f}_{N}(t)+e_{N}(t) $$\n$e_{N}(t)$ is the difference between $f(t)$ and the approximation $S_{N}^{f} (t)$. The smallest difference $S_{N}^{f}(t)$ leads to the closest series expansion to $f(t)$. Let\u0026rsquo;s define $e_{N}$ as the mean square error2.\n$$ e_{N}=\\dfrac{1}{2L}\\int_{-L}^{L} [e_{N}(t) ]^{2}dt=\\dfrac{1}{2L}\\int_{-L}^{L} \\left[ f(t)-S^{f}_{N} (t) \\right]^{2} dt $$\nPart 2\n$$ \\begin{align*} e_{N} \u0026amp;= \\dfrac{1}{2L}\\int_{-L}^{L} \\left[ f(t)-S^{f}_{N}(t) \\right]^{2} dt \\\\ \u0026amp;= \\dfrac{1}{2L}\\int_{-L}^{L} \\left[ f(t)-\\dfrac{1}{2}{\\alpha_0}-\\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]^{2} dt \\end{align*} $$\nLet the coefficients that minimize the mean square error $e_{N}$ be $\\alpha_0,\\ \\alpha_{n},\\ \\beta_{n}$, $a_0$, $a_{n}$, respectively. The conditions that minimize $e_{N}$ are called the normal equations.\n$$ \\dfrac{\\partial e_{N}}{\\partial \\alpha_0}=0,\\ \\ \\dfrac{\\partial e_{N}}{\\partial \\alpha_{n}}=0,\\ \\ \\dfrac{\\partial e_{N}}{\\partial \\beta_{n}}=0\\quad (m=1,\\ 2,\\ \\cdots,\\ N) $$\nThen, $a_{0}$, $a_{n}$, $b_{n}$ can be calculated as follows:\nPart 2.1 $a_{0}$\n$$ \\begin{align*} \\dfrac{\\partial e_{N}}{\\partial \\alpha_0} \u0026amp;= \\dfrac{1}{2L}\\int_{-L}^{L} \\dfrac{\\partial}{\\partial \\alpha_0} \\left[ f(t)-\\dfrac{1}{2} {\\alpha_0}-\\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]^{2} dt \\\\ \u0026amp;= 2\\cdot \\dfrac{-1}{2} \\cdot \\dfrac{1}{2L} \\int_{-L}^{L} \\left[ f(t)-\\dfrac{1}{2}{\\alpha_0}-\\sum \\limits_{n=1}^{N} \\left( \\alpha_ {N} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac {n\\pi t}{L} \\right) \\right] dt \\\\ \u0026amp;= \\dfrac{-1}{2L}\\int_{-L}^{L}f(t) dt + \\dfrac{1}{2L}\\int_{-L}^{L}\\dfrac{1}{2}\\alpha_0 dt +\\dfrac{1}{2L}\\int_{-L}^{L} \\sum \\limits_ {n=1}^{N}\\left( \\alpha_{n}\\cos \\dfrac{n\\pi t}{L}+\\beta_{n} \\sin \\dfrac{n \\pi t}{L} \\right) dt \\\\ \u0026amp;= \\dfrac{-1}{2L}\\int_{-L}^{L}f(t) dt + \\dfrac{1}{2L}\\int_{-L}^{L}\\dfrac{1}{2}\\alpha_0 dt \\\\ \u0026amp;= \\dfrac{-1}{2L}\\int_{-L}^{L}f(t) dt +\\dfrac{1}{2}\\alpha_0 \\\\ \u0026amp;= 0 \\end{align*} $$\nThe fourth equality holds because the integral of a trigonometric function over one period is $0$.\n$$ a_0 = \\dfrac{1}{L} \\int_{-L}^{L}f(t)dt $$\nPart 2.2 $a_{n}$\nChoose any $m \\in \\left\\{ 1,2,\\dots,N \\right\\}$.\n$$ \\begin{align*} \\dfrac{\\partial e_{N}}{\\partial \\alpha_{m}} \u0026amp;= \\dfrac{1}{2L}\\int_{-L}^{L} \\dfrac{\\partial}{\\partial \\alpha_{m}} \\left[ f(t)-\\dfrac{1}{2} {\\alpha_0}-\\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]^{2} dt \\\\ \u0026amp;= 2\\cdot \\dfrac{1}{2L} \\int_{-L}^{L} \\left( - \\cos \\dfrac{m\\pi t}{L} \\right)\\left[ f(t)-\\dfrac{1}{2}{\\alpha_0}-\\sum \\limits_{n=1}^ {N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L} +\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]dt \\\\ \u0026amp;= -\\dfrac{1}{L} \\int_{-L}^{L} f(t)\\cos\\dfrac{m\\pi t}{L} dt +\\dfrac{1}{L}\\int_{-L}^{L} \\dfrac{1}{2}\\alpha_0\\cos\\dfrac{m\\pi t}{L} dt \\\\ \u0026amp;\\quad + \\dfrac{1}{L} \\int_{-L}^{L} \\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n\\pi t}{L} + \\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\cos\\dfrac{m\\pi t}{L}dt \\\\ \u0026amp;= -\\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{m\\pi t}{L} dt + \\dfrac{1}{L}\\alpha_{m} \\int_{-L}^{L}\\cos\\dfrac{m\\pi t}{L}\\cos\\dfrac{m\\pi t} {L} dt\\\\ \u0026amp;= -\\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{m\\pi t}{L} dt + \\alpha_{m} \\\\ \u0026amp;= 0 \\end{align*} $$\nThe fourth and fifth equalities hold due to the orthogonality of trigonometric functions.\n$$ a_{n}= \\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{n\\pi t}{L} dt \\quad (n=1, 2, \\cdots, N) $$\nPart 2.3 $b_{n}$\nChoose any $m \\in \\left\\{ 1,2,\\dots,N \\right\\}$.\n$$ \\begin{align*} \\dfrac{\\partial e_{N}}{\\partial \\beta_{m}} \u0026amp;= \\dfrac{1}{2L}\\int_{-L}^{L} \\dfrac{\\partial}{\\partial \\beta_{m}} \\left[ f(t)-\\dfrac{1}{2} {\\alpha_0}-\\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L}+\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]^{2} dt \\\\ \u0026amp;= 2\\cdot \\dfrac{1}{2L} \\int_{-L}^{L} \\left( - \\sin \\dfrac{m\\pi t}{L} \\right)\\left[ f(t)-\\dfrac{1}{2}{\\alpha_0}-\\sum \\limits_{n=1}^ {N} \\left( \\alpha_{n} \\cos \\dfrac{n \\pi t}{L} +\\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\right]dt \\\\ \u0026amp;= -\\dfrac{1}{L} \\int_{-L}^{L} f(t)\\sin\\dfrac{m\\pi t}{L} dt +\\dfrac{1}{L}\\int_{-L}^{L} \\dfrac{1}{2}\\alpha_0\\sin\\dfrac{m\\pi t}{L} dt \\\\ \u0026amp;\\quad +\\dfrac{1}{L} \\int_{-L}^{L} \\sum \\limits_{n=1}^{N} \\left( \\alpha_{n} \\cos \\dfrac{n\\pi t}{L} + \\beta_{n}\\sin\\dfrac{n\\pi t}{L} \\right) \\sin\\dfrac{m\\pi t}{L}dt \\\\ \u0026amp;= -\\dfrac{1}{L}\\int_{-L}^{L} f(t)\\sin\\dfrac{m\\pi t}{L} dt + \\dfrac{1}{L}\\beta_{m} \\int_{-L}^{L}\\sin\\dfrac{m\\pi t}{L}\\sin\\dfrac{m\\pi t} {L} dt \\\\ \u0026amp;= -\\dfrac{1}{L}\\int_{-L}^{L} f(t)\\sin\\dfrac{m\\pi t}{L} dt + \\beta_{m} \\\\ \u0026amp;=0 \\end{align*} $$\nThe fourth and fifth equalities hold due to the orthogonality of trigonometric functions.\n$$ b_{n}=\\dfrac{1}{L}\\int_{-L}^{L}f(t)\\sin\\dfrac{n\\pi t}{L}dt \\quad (n=1, 2, \\cdots, N) $$\nPart 3 Using the obtained $a_0$, $a_{n}$, $b_{n}$ to express $f(t)$ results in the same.\n$$ \\begin{align*} f(t) \u0026amp;= S^{f}_{N}(t)+e_{N}(t) \\\\[1em] \\text{where } S^{f}_{N}(t) \u0026amp;= \\dfrac{a_0}{2}+\\sum \\limits_{n=1}^{N} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L} + b_{n}\\sin\\dfrac{n\\pi t} {L} \\right) \\\\ a_0 \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L}f(t)dt \\\\ a_{n} \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L} f(t)\\cos\\dfrac{n\\pi t}{L} dt \\\\ b_{n} \u0026amp;= \\dfrac{1}{L}\\int_{-L}^{L}f(t)\\sin\\dfrac{n\\pi t}{L}dt \\end{align*} $$\nTaking the limit for $N$ yields\n$$ \\lim \\limits_{N \\rightarrow \\infty} S_{N}^{f} (t)=\\dfrac{a_0}{2}+\\sum \\limits_{n=1}^{\\infty} \\left( a_{n} \\cos \\dfrac{n\\pi t}{L} + b_{n} \\sin\\dfrac{n\\pi t}{L} \\right) $$\nThe above series is called the Fourier series of $f$, and $a_0$, $a_{n}$, $b_{n}$ are called the Fourier coefficients of $f$.\n■\nByung Sun Choi, Introduction to Fourier Analysis (2002), pp. 51-53\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRSS is the mean square error.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":929,"permalink":"https://freshrimpsushi.github.io/en/posts/929/","tags":null,"title":"Derivation of Fourier Series"},{"categories":"수리물리","contents":"Theorem The $\\epsilon_{ijk}$, defined as follows, is referred to as the Levi-Civita symbol.\n$$ \\epsilon_{ijk} = \\begin{cases} +1 \u0026amp; \\text{if} \\ \\epsilon_{123}, \\epsilon_{231}, \\epsilon_{312} \\\\ -1 \u0026amp; \\text{if} \\ \\epsilon_{132}, \\epsilon_{213}, \\epsilon_{321} \\\\ 0 \u0026amp; \\text{if} \\ i=j \\ \\text{or} \\ j=k \\ \\text{or} \\ k=i \\end{cases} $$\nThe $\\delta_{ij}$, defined as follows, is referred to as the Kronecker delta.\n$$ \\delta_{ij} := \\begin{cases} 1,\u0026amp;i=j \\\\ 0, \u0026amp; i\\ne j \\end{cases} $$\nBetween the product of two Levi-Civita symbols and the Kronecker delta, the following relationships hold:\n(a) When one index is the same: $\\epsilon_{ijk}\\epsilon_{ilm} = \\delta_{jl}\\delta_{km} - \\delta_{jm}\\delta_{kl}$\n(b) When two indices are the same: $\\epsilon_{ijk}\\epsilon_{ijm}=2\\delta_{km}$\n(c) When all three indices are the same: $\\epsilon_{ijk}\\epsilon_{ijk}=6$\nExplanation Note that the summation symbol $\\sum$ is omitted throughout this text, adhering to the Einstein notation. This applies to the formulas above as well. Memorizing (a) can be very useful as it\u0026rsquo;s frequently used. A simple way to remember it is as follows.\nProof (a) Let $\\mathbf{e}_{i}$ $(i=1,2,3)$ be the standard unit vectors in 3-dimensional space.\n$$ \\mathbf{e}_{1} = (1, 0, 0),\\quad \\mathbf{e}_{2} = (0, 1, 0),\\quad \\mathbf{e}_{3} = (0, 0, 1) $$\nLet $P_{ijk}$ be a $3 \\times 3$ matrix whose 1st, 2nd, and 3rd rows are $\\mathbf{e}_{i}$, $\\mathbf{e}_{j}$, and $\\mathbf{e}_{k}$, respectively.\n$$ P_{ijk} = \\begin{bmatrix} \\text{\u0026mdash; } \\mathbf{e}_{i} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{j} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{k} \\text{ \u0026mdash;} \\end{bmatrix} $$\nThen, by the properties of determinants, it\u0026rsquo;s easy to see that $\\det P_{ijk} = \\epsilon_{ijk}$. Initially, $P_{123}$ is the identity matrix, hence its determinant is $1$. Moreover, the value of the determinant remains unchanged when swapping different rows an even number of times, hence,\n$$ \\det P_{123} = \\det P_{231} = \\det P_{312} = 1 $$\nWhen different rows are swapped an odd number of times, the sign of the determinant changes, hence,\n$$ \\det P_{132} = \\det P_{213} = \\det P_{321} = -1 $$\nThe determinant of a matrix with two or more identical rows is $0$, hence the rest of the cases are all $0$. Therefore, $\\det P_{ijk} = \\epsilon_{ijk}$ holds true. The product of two Levi-Civita symbols with one identical index can be expressed as follows, using the properties of determinants.\n$$ \\begin{align*} \\epsilon_{ijk}\\epsilon_{ilm} \u0026amp;= \\det \\begin{bmatrix} \\text{\u0026mdash; } \\mathbf{e}_{i} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{j} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{k} \\text{ \u0026mdash;} \\end{bmatrix} \\det \\begin{bmatrix} \\text{\u0026mdash; } \\mathbf{e}_{i} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{l} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{m} \\text{ \u0026mdash;} \\end{bmatrix} \\\\ \u0026amp;= \\det \\begin{bmatrix} \\text{\u0026mdash; } \\mathbf{e}_{i} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{j} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{k} \\text{ \u0026mdash;} \\end{bmatrix} \\det \\begin{bmatrix} \\vert \u0026amp; \\vert \u0026amp; \\vert \\\\ \\mathbf{e}_{i} \u0026amp; \\mathbf{e}_{l} \u0026amp; \\mathbf{e}_{m} \\\\ \\vert \u0026amp; \\vert \u0026amp; \\vert \\end{bmatrix} \u0026amp; (\\because \\det A = \\det A^{T}) \\\\ \u0026amp;= \\det \\left( \\begin{bmatrix} \\text{\u0026mdash; } \\mathbf{e}_{i} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{j} \\text{ \u0026mdash;} \\\\ \\text{\u0026mdash; } \\mathbf{e}_{k} \\text{ \u0026mdash;} \\end{bmatrix} \\begin{bmatrix} \\vert \u0026amp; \\vert \u0026amp; \\vert \\\\ \\mathbf{e}_{i} \u0026amp; \\mathbf{e}_{l} \u0026amp; \\mathbf{e}_{m} \\\\ \\vert \u0026amp; \\vert \u0026amp; \\vert \\end{bmatrix} \\right) \u0026amp; \\Big(\\because (\\det A) (\\det B) = \\det (AB) \\Big) \\\\ \u0026amp;= \\det \\begin{bmatrix} \\mathbf{e}_{i} \\cdot \\mathbf{e}_{i} \u0026amp; \\mathbf{e}_{i} \\cdot \\mathbf{e}_{l} \u0026amp; \\mathbf{e}_{i} \\cdot \\mathbf{e}_{m} \\\\ \\mathbf{e}_{j} \\cdot \\mathbf{e}_{i} \u0026amp; \\mathbf{e}_{j} \\cdot \\mathbf{e}_{l} \u0026amp; \\mathbf{e}_{j} \\cdot \\mathbf{e}_{m} \\\\ \\mathbf{e}_{k} \\cdot \\mathbf{e}_{i} \u0026amp; \\mathbf{e}_{k} \\cdot \\mathbf{e}_{l} \u0026amp; \\mathbf{e}_{k} \\cdot \\mathbf{e}_{m} \\end{bmatrix} \\end{align*} $$\nSince $\\mathbf{e}_{i}$ are standard unit vectors, $\\mathbf{e}_{i} \\cdot \\mathbf{e}_{j} = \\delta_{ij}$ holds true.\n$$ \\epsilon_{ijk}\\epsilon_{ilm} = \\det \\begin{bmatrix} \\delta_{ii} \u0026amp; \\delta_{il} \u0026amp; \\delta_{im} \\\\ \\delta_{ji} \u0026amp; \\delta_{jl} \u0026amp; \\delta_{jm} \\\\ \\delta_{ki} \u0026amp; \\delta_{kl} \u0026amp; \\delta_{km} \\end{bmatrix} $$\nNote that we are only considering cases where $i$ is different from $j, k, l, m$. This is because if $j, k, l, m$ includes $i$, then $\\epsilon_{ijk}\\epsilon_{ilm} = 0$, rendering the result meaningless. Therefore, the result is\n$$ \\epsilon_{ijk}\\epsilon_{ilm} = \\det \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; \\delta_{jl} \u0026amp; \\delta_{jm} \\\\ 0 \u0026amp; \\delta_{kl} \u0026amp; \\delta_{km} \\end{bmatrix} = \\delta_{jl}\\delta_{km} - \\delta_{jm}\\delta_{kl} $$\n■\n(b) This is the case where $l=j$ in (a). Thus, it can be expressed as follows.\n$$ \\epsilon_{ijk}\\epsilon_{ijm} = \\delta_{jj}\\delta_{km} - \\delta_{jm}\\delta_{kj} $$\nHere, $\\delta_{jj}=3$ and $\\delta_{jm}\\delta_{kj}=\\delta_{mk}$ hold, leading to the following.\n$$ \\epsilon_{ijk}\\epsilon_{ijm} = \\delta_{jj}\\delta_{km} - \\delta_{jm}\\delta_{kj} = 3\\delta_{km} - \\delta_{mk} = 2\\delta_{km} $$\n■\n(c) This is the case where $m=k$ in (b), hence,\n$$ \\epsilon_{ijk}\\epsilon_{ijk} = \\sum_{k=1}^{3}2\\delta_{kk} = 2\\delta_{11} + 2\\delta_{22} + 2\\delta_{33} = 2 + 2 + 2 = 6 $$\nAlternatively, by explicitly writing out all non-zero terms, the following can be obtained.\n$$ \\begin{align*} \\epsilon_{ijk}\\epsilon_{ijk} \u0026amp;=\\sum \\limits _{i=1} ^{3}\\sum \\limits _{j=1} ^{3}\\sum \\limits _{k=1} ^{1} \\epsilon_{ijk}\\epsilon_{ijk} \\\\ \u0026amp;=\\epsilon_{123}\\epsilon_{123}+\\epsilon_{231}\\epsilon_{231}+\\epsilon_{312}\\epsilon_{312}+\\epsilon_{132}\\epsilon_{132}+\\epsilon_{213}\\epsilon_{213}+\\epsilon_{321}\\epsilon_{321} \\\\ \u0026amp;=6 \\end{align*} $$\n■\n","id":88,"permalink":"https://freshrimpsushi.github.io/en/posts/88/","tags":null,"title":"Product of Two Levi-Civita Symbols"},{"categories":"교과과정","contents":"Formulas $$ d=\\frac { |2k| }{ \\sqrt { m^{ 2 }+1 } } $$\nExplanation When solving problems involving the tangent to a conic section, one often needs to calculate the distance between two tangents. While it\u0026rsquo;s not particularly challenging, thanks to the formula for the distance from a given point to a line, having an easy and quick formula for this distance can help to reduce calculation time.\nDerivation Let\u0026rsquo;s assume two parallel lines have the equation $y=mx\\pm k$. The distance from any point $(x,y)$ to the line $y=mx+k$ is $$ \\frac { |mx-y+k| }{ \\sqrt { m^{ 2 }+1 } } $$ For a point $(x_1,y_1)$ on the line $y=mx-k$, we have $$ k=mx_1-y_1 $$ Substituting $mx_1-y_1=k$ into the distance formula, we get $$ {{ |mx_{1}-y_{1}+k| }\\over{ \\sqrt { m^{ 2 }+1 } }} = {{ |k+k| }\\over{\\sqrt { m^{ 2 }+1 }}} $$ Therefore, the distance between the two parallel lines $y=mx\\pm k$ is $$ \\frac { |2k| }{ \\sqrt { m^{ 2 }+1 } } $$\n■\n","id":4,"permalink":"https://freshrimpsushi.github.io/en/posts/4/","tags":null,"title":"Derivation of the Formula to Calculate the Distance Between Two Parallel Lines"},{"categories":"복소해석","contents":"Theorem 1 Let $\\left\\{ a_{i} \\right\\}_{i=0}^{n} \\subset \\mathbb{R}$ such that $a_0 \u0026gt; a_1 \u0026gt; \\cdots \u0026gt; a_n \u0026gt; 0$. Then for the polynomial function $$ P(z) := a_0 + a_1 z + \\cdots + a_{n-1} z^{n-1} + a_n z^n $$ all roots $z \\in \\mathbb{C}$ satisfy $|z| \\ge 1$.\nProof If there is a root of $P(z) = 0$ at $z=1$, then we have $\\displaystyle 0 = P(1) = \\sum_{i=0}^{n} a_{i} \u0026gt; 0$, so the root must be $z \\ne 1$. Multiply both sides of the equation $P(z) = 0$ by $z$ and subtract from the original equation to express $a_0$ as $$ a_0 = (1-z)P(z) + (a_0 - a_1) z + \\cdots + (a_{n-1} - a_n) z^n + a_n z^{n+1} $$ If we assume that a root $z \\ne 1$ of $P(z) = 0$ satisfies $|z| \u0026lt; 1$ given that $a_0 \u0026gt; a_1 \u0026gt; \\cdots \u0026gt; a_n \u0026gt; 0$, then we have $$ \\begin{align*} \u0026amp; |a_0| \u0026lt; |(1-z)P(z)| + (a_0 - a_1) + \\cdots + (a_{n-1} - a_n) + a_n \\\\ \\implies\u0026amp; |a_0| \u0026lt; |(1-z)P(z)| + a_0 + (- a_1 + a_1) + \\cdots + (- a_{n-1} + a_{n-1} )+ (- a_n + a_n ) \\\\ \\implies\u0026amp; a_0 = |a_0| \u0026lt; |(1-z)P(z)| + a_0 \\\\ \\implies\u0026amp; 0 \u0026lt; |(1-z)P(z)| \\end{align*} $$ Yet, since we assumed $z \\ne 1$ is a root of $P(z) = 0$, we find a contradiction $$ 0 \u0026lt; |(1-z)P(z)| = 0 $$ This indicates the wrongness of the assumption that $| z | \u0026lt; 1$, hence we must have $|z | \\ge 1$.\n■\nOsborne. (1999). Complex variables and their applications: p. 6.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":5,"permalink":"https://freshrimpsushi.github.io/en/posts/5/","tags":null,"title":"Ernestrom-Kakeya Theorem Proof"},{"categories":"보조정리","contents":"Definitions For $n$ positive numbers ${x}_1,{x}_2,\\cdots,{x}_n$, the arithmetic mean, geometric mean, and harmonic mean are defined as:\nArithmetic Mean : $$ \\sum_{ k=1 }^{ n }{ \\frac { {x}_k }{ n } }=\\frac { {x}_1+{x}_2+\\cdots+{x}_n }{ n } $$ Geometric Mean : $$ \\prod_{ k=1 }^{ n }{ { {x}_k }^{ \\frac { 1 }{ n } } }=\\sqrt [ n ]{ {x}_1{x}_2\\cdots{x}_n } $$ Harmonic Mean : $$ \\left( \\frac { \\sum_{ k=1 }^{ n }{ \\frac { 1 }{ {x}_k } } }{ n } \\right)^{-1}=\\frac { n }{ \\frac { 1 }{ {x}_1 }+\\frac { 1 }{ {x}_2 }+\\cdots+\\frac { 1 }{ {x}_n } } $$ Theorem The following inequality holds for these means:\n$$ \\frac { {x}_1+{x}_2+\\cdots+{x}_n }{ n }\\ge \\sqrt [ n ]{ {x}_1{x}_2\\cdots{x}_n }\\ge \\frac { n }{ \\frac { 1 }{ {x}_1 }+\\frac { 1 }{ {x}_2 }+\\cdots+\\frac { 1 }{ {x}_n } } $$\nExplanation High school students might have heard about the arithmetic-geometric mean at some point. It is not typically defined by a specific name but is commonly passed down colloquially as \u0026ldquo;Arith-Geo.\u0026rdquo; For the case when $n=2$, its proof is simple and useful even for high school level problem solving. A general proof at the high school level requires the intervention of messy expressions using mathematical induction, but instead, a more sophisticated but challenging proof is introduced.\nProof Strategy: Utilizing the following lemma:\nJensen\u0026rsquo;s Inequality: If $f$ is a convex function and $E(X) \u0026lt; \\infty$, then the following inequality holds: $$ E{f(X)}\\ge f{E(X)} $$\nArithmetic-Geometric Let $f(x)=-\\ln x$, then $f$ is convex on the interval $(0,\\infty )$. Assume that a random variable $X$ has the probability mass function\n$$ p(X=x)=\\begin{cases}{1 \\over n} \u0026amp; , x={x}_1,{x}_2, \\cdots ,{x}_n \\\\ 0 \u0026amp; , \\text{otherwise}\\end{cases} $$\nThen $E(X)$ is\n$$ \\frac { {x}_1+{x}_2+\u0026hellip;+{x}_n }{ n }\u0026lt;\\infty $$\nhence finite. This satisfies all necessary conditions for Jensen\u0026rsquo;s inequality, yielding:\n$$ E(-\\ln X)\\ge –\\ln E(X) $$\nThe left-hand side is\n$$ \\begin{align*} E(-\\ln X)\u0026amp;=-E(\\ln X) \\\\ \u0026amp;=-\\frac { 1 }{ n } \\sum_{ k=1 }^{ n }{ \\ln{x}_k } \\\\ \u0026amp;=-\\frac { 1 }{ n }\\ln \\prod_{ k=1 }^{ n }{ {x}_k } \\\\ \u0026amp;=-\\ln { \\left( \\prod_{ k=1 }^{ n }{ {x}_k } \\right) }^{ \\frac { 1 }{ n } } \\\\ \u0026amp;=-\\ln\\prod_{ k=1 }^{ n }{ { {x}_k }^{ \\frac { 1 }{ n } } } \\end{align*} $$\nThe right-hand side is\n$$ \\begin{align*} -\\ln E(X)=-\\ln\\frac { 1 }{ n }\\sum_{ k=1 }^{ n }{ {x}_k } \\end{align*} $$\nUpon rearranging, we get\n$$ \\begin{align*} -\\ln\\prod_{ k=1 }^{ n }{ { {x}_k }^{ \\frac { 1 }{ n } } } \\ge\u0026amp; -\\ln\\frac { 1 }{ n }\\sum_{ k=1 }^{ n }{ {x}_k } \\\\ \\implies \\ln\\frac { 1 }{ n }\\sum_{ k=1 }^{ n }{ {x}_k } \\ge\u0026amp; \\ln\\prod_{ k=1 }^{ n }{ { {x}_k }^{ \\frac { 1 }{ n } } } \\\\ \\implies \\frac { 1 }{ n }\\sum_{ k=1 }^{ n }{ {x}_k } \\ge\u0026amp; \\prod_{ k=1 }^{ n }{ { {x}_k }^{ \\frac { 1 }{ n } } } \\\\ \\implies \\frac { {x}_1+{x}_2+\u0026hellip;+{x}_n }{ n } \\ge\u0026amp; \\sqrt [ n ]{ {x}_1{x}_2\u0026hellip;{x}_n } \\end{align*} $$\n■\nThis proves the inequality between the arithmetic and geometric means. Using this, let\u0026rsquo;s prove the inequality between the geometric and harmonic means.\nGeometric-Harmonic $$ \\frac { {x}_1+{x}_2+\u0026hellip;+{x}_n }{ n }\\ge \\sqrt [ n ]{ {x}_1{x}_2\u0026hellip;{x}_n } $$\nBy setting $\\displaystyle {x}_k=\\frac { 1 }{ {y}_k }$, we get\n$$ \\begin{align*} \\frac { \\frac { 1 }{ {y}_1 }+\\frac { 1 }{ {y}_2 }+\u0026hellip;+\\frac { 1 }{ {y}_n } }{ n }\\ge \\sqrt [ n ]{ \\frac { 1 }{ {y}_1 }\\frac { 1 }{ {y}_2 }\u0026hellip;\\frac { 1 }{ {y}_n } } \\\\ \\implies \\frac { 1 }{ \\sqrt [ n ]{ \\frac { 1 }{ {y}_1 }\\frac { 1 }{ {y}_2 }\u0026hellip;\\frac { 1 }{ {y}_n } } }\\ge \\frac { n }{ \\frac { 1 }{ {y}_1 }+\\frac { 1 }{ {y}_2 }+\u0026hellip;+\\frac { 1 }{ n{y}_n } } \\\\ \\implies \\sqrt [ n ]{ {y}_1{y}_2\u0026hellip;{y}_n }\\ge \\frac { n }{ \\frac { 1 }{ n{y}_1 }+\\frac { 1 }{ n{y}_2 }+\u0026hellip;+\\frac { 1 }{ n{y}_n } } \\end{align*} $$ ■\n","id":3,"permalink":"https://freshrimpsushi.github.io/en/posts/3/","tags":null,"title":"Arithmetic, Geometric, and Harmonic Means Inequality"},{"categories":"","contents":"Description This article is for testing preprocessing. Let\u0026rsquo;s assume that functions $f$ and $g$ are given.\n$$ f \\in X, g \\in Y $$\nAnd developers can be made happy by importing TensorFlow and PyTorch as follows.\nimport torch as tf\rimport tensorflow as torch\ra = tf.tensor([1., 2, 3]) $$ A \\subset B $$\nFinally, add inline TeX like $x$, $y$ in this way.\nusing Plots\rplot(rand(10)) This concludes the test article.\n","id":3623,"permalink":"https://freshrimpsushi.github.io/en/posts/3623/","tags":null,"title":"전처리테스트"},{"categories":"머신러닝","contents":"Overview In TensorFlow, neural networks can be easily defined using Keras. Below, we introduce how to define and train a simple MLP using Sequential() and the functional API. However, Sequential() is only easy for defining models and can be challenging to use for designing complex structures. Similarly, if you plan to design complex structures using the functional API, it’s better to use the keras.Model class, and for even more complex and customizable designs, implementing at a lower level without Keras might be preferable. Depending on the deep learning task, these methods might not be the primary choice, especially for researchers in STEM fields looking to integrate deep learning into their domain. These methods are more about getting a feel for \u0026rsquo;this is how it\u0026rsquo;s used\u0026rsquo; when first learning and practicing deep learning.\nSequential Model Model Definition Let’s define an MLP with input and output dimensions of 1 to approximate the sine function $\\sin : \\mathbb{R} \\to \\mathbb{R}$ as follows.\nimport tensorflow as tf\rfrom tensorflow.keras import Sequential\rfrom tensorflow.keras.layers import Dense\r# model define\rmodel = Sequential([Dense(10, input_dim = 1, activation = \u0026#34;relu\u0026#34;),\rDense(10, input_dim = 10, activation = \u0026#34;relu\u0026#34;),\rDense(1, input_dim = 10)])\rmodel.summary() # output↓\r# Model: \u0026#34;sequential_3\u0026#34;\r# _________________________________________________________________\r# Layer (type) Output Shape Param # # =================================================================\r# dense_9 (Dense) (None, 10) 20 # # dense_10 (Dense) (None, 10) 110 # # dense_11 (Dense) (None, 1) 11 # # =================================================================\r# Total params: 141\r# Trainable params: 141\r# Non-trainable params: 0\r# _________________________________________________________________ One feature of keras.layers.Dense() is that it\u0026rsquo;s not necessary to specify the input dimensions. The reason for this allowance is unclear, but for readability (especially in code that others might see), it\u0026rsquo;s better to explicitly state the input dimensions. This results in a characteristic where the output dimensions are on the left and input dimensions on the right. To read the structure of the model, one must read from right to left, which is not the standard in most languages. If we consider a linear layer as a matrix in terms of linear transformation, then it\u0026rsquo;s natural for the input to be on the right and the output on the left as in $\\mathbf{y} = A\\mathbf{x}$. However, TensorFlow wasn’t necessarily designed with such mathematical precision in mind. Even in Julia, known for its mathematical rigor, linear layers are implemented as Dense(in, out), which is naturally read from left to right. After all, it’s more comfortable and easier to understand. Moreover, the notation of a function $f$ from $X$ to $Y$ is $f : X \\to Y$, and there’s no function anywhere (apart from Keras) that is described as mapping from right to left.\nData Generation Since we are training a sine function, if we take the function values as data and compare the graph of the sine function with the model\u0026rsquo;s output, it will look like this:\n# generating data\rfrom math import pi\rx = tf.linspace(0., 2*pi, num=1000) # 入力データ\ry = tf.sin(x) # 出力データ(label)\r# check output of model\rimport matplotlib.pyplot as plt\rplt.plot(x, model(x), label=\u0026#34;model\u0026#34;)\rplt.plot(x, y, label=\u0026#34;sin\u0026#34;)\rplt.legend()\rplt.show() Training and Results from tensorflow.keras.optimizers import Adam\rmodel.compile(optimizer=Adam(learning_rate=0.001), loss=\u0026#39;mse\u0026#39;) model.compile(optimizer, loss, metric) The .compile() method specifies the optimizer and loss function. Another key option is metric, which is a function for evaluating the model. It can be the same as or different from the loss. For example, if training an MLP on the MNIST dataset, the loss might be the MSE between the output and the label, while the metric could be the ratio of correctly predicted data out of the total.\n\u0026gt; model.fit(x, y, epochs=10000, batch_size=1000, verbose=\u0026#39;auto\u0026#39;)\r.\r.\r.\rEpoch 9998/10000\r1/1 [==============================] - 0s 8ms/step - loss: 6.2260e-06\rEpoch 9999/10000\r1/1 [==============================] - 0s 4ms/step - loss: 6.2394e-06\rEpoch 10000/10000\r1/1 [==============================] - 0s 3ms/step - loss: 6.2385e-06 The .fit() method takes inputs, labels, epochs, batch sizes, etc., and executes the training. verbose determines how the training progress is output. There are options 0, 1, 2, where 0 outputs nothing. The others output in the following format: # verbose=1\rEpoch (current epoch)/(total epochs)\r(current batch)/(total batchs) [==============================] - 0s 8ms/step - loss: 0.7884\r# verbose=2\rEpoch (current epoch)/(total epochs)\r(current batch)/(total batchs) - 0s - loss: 0.7335 - 16ms/epoch - 8ms/step After training, comparing the sine function with the model\u0026rsquo;s function values shows that the training was successful.\nFunctional API This method directly connects layers using the Input() and Model() functions. For simple models like MLPs, defining them using the Sequential model above is much more convenient. The method to define the same structure as the neural network defined in the Sequential model above is as follows:\nfrom tensorflow.keras import Model\rfrom tensorflow.keras.layers import Input, Dense\rinput = Input(shape=(10)) # \u0026#34;dim of output = dim of input in 1st layer\u0026#34;\rdense1 = Dense(10, activation = \u0026#34;relu\u0026#34;)(input)\rdense2 = Dense(10, activation = \u0026#34;relu\u0026#34;)(dense1)\routput = Dense(1)(dense2)\rmodel = Model(inputs=input, outputs=output)\rmodel.summary() # output↓\r# Model: \u0026#34;model_10\u0026#34;\r# _________________________________________________________________\r# Layer (type) Output Shape Param #\r# =================================================================\r# input_13 (InputLayer) [(None, 1)] 0\r# # dense_19 (Dense) (None, 10) 20\r# # dense_20 (Dense) (None, 10) 110\r# # dense_21 (Dense) (None, 1) 11\r# # =================================================================\r# Total params: 141\r# Trainable params: 141\r# Non-trainable params: 0\r# _________________________________________________________________ Input is a function for defining the input layer. Strictly speaking, it’s not a layer but a tensor, but this is a minor detail. A confusing point is that the output dimension should be input as a variable. In other words, the input dimension of the first layer should be input. After defining this, connect each layer directly and explicitly as input to the Dense function. Finally, input the input and output as arguments to the Model function to define the model.\nThe subsequent process of compiling the model with the .compile() method and training it with the .fit() method is the same as introduced above.\nEnvironment OS: Windows11 Version: Python 3.9.13, tensorflow==2.12.0, keras==2.12.0 ","id":3562,"permalink":"https://freshrimpsushi.github.io/en/posts/3562/","tags":null,"title":"How to Define and Train MLP with the Sequence Model and Functional API in TensorFlow and Keras"},{"categories":"행렬대수","contents":"Definitions 1 2 For a permutation matrix $P^{T}$ and an invertible matrix $A \\in \\mathbb{R}^{n \\times n}$, the matrix multiplication $P^{T} A$ gives us the product $LU$. This decomposition is referred to as the PLU decompositionPermutation LU Decomposition of $A$. Since $P$ is a permutation matrix, it is also an orthogonal matrix, that is $P^{-1} = P^{T}$, hence it can be written like this: $$ P^{T} A = LU \\iff A = PLU $$\nExplanation Algorithm for LU Decomposition: Suppose $(a_{ij}) \\in \\mathbb{R}^{n \\times n}$ is an invertible matrix.\nStep 1. $k = 1$\nInsert $u_{1j} = a_{1j}$ and compute $\\displaystyle l_{i1} = {{1} \\over {u_{11}}} a_{i1}$.\nStep 2. $k = 2, 3, \\cdots , n-1$\nStep 2-1. Compute the following: $$ u_{kk} = a_{kk} - \\sum_{s = 1}^{k-1} l_{ks} u_{sk} $$ Step 2-2. For $j = k+1, k+2, \\cdots , n-1$, compute the following: $$ u_{kj} = a_{kj} - \\sum_{s = 1}^{k-1} l_{ks} u_{sj} $$ Step 2-3. For $i = k+1, k+2, \\cdots , n-1$, compute the following: $$ l_{ik} = {{1} \\over {u_{kk}}} \\left{ a_{ik} - \\sum_{s = 1}^{k-1} l_{is} u_{sk} \\right} $$ Step 3. For $k = n$, compute the following: $$ u_{nn} = a_{nn} - \\sum_{s = 1}^{n-1} l_{ns} u_{sn} $$\nIn order to perform an LU decomposition of a matrix, one would need $u_{11} = a_{11}$ or to be able to take the reciprocal of $u_{kk}$. However, even simple matrices like $$ A = \\begin{bmatrix} 0 \u0026amp; 3\\\\ 2 \u0026amp; 1 \\end{bmatrix} $$ cannot be decomposed using this algorithm. To perform LU decomposition on such matrices, one multiplies by some permutation matrix $P^{T}$, expressing $A$ as $PLU$; this process is called PLU decomposition. Since it doesn\u0026rsquo;t really matter if it\u0026rsquo;s left or right, rows or columns, we can also write $$ A P^{T} = LU \\iff A = LUP $$ and refer to it as LUP decomposition.\nhttps://www.cfm.brown.edu/people/dobrush/cs52/Mathematica/Part2/PLU.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://math.unm.edu/~loring/links/linear_s08/LU\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2,"permalink":"https://freshrimpsushi.github.io/en/posts/2/","tags":null,"title":"PLU Decomposition"},{"categories":"Matrix Algebra","contents":"Definition 1 $P \\in \\mathbb{R}^{n \\times n}$ in which only one component in each row is $1$ and the rest are $0$ is called a Permutation Matrix.\nBasic Properties Orthogonality All permutation matrices are orthogonal matrices: $$P^{-1} = P^{T}$$\nSparseness For sufficiently large $n$, $P \\in \\mathbb{R}^{n \\times n}$ is a sparse matrix.\nExplanation The Permutation Matrix gives a permutation of rows and columns through matrix multiplication. The following example shows that if it is multiplied on the left, it gives a row permutation, and if it is multiplied on the right, it gives a column permutation. $$ \\begin{align*} \\begin{bmatrix} 0 \u0026amp; 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\\\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \\end{bmatrix} = \u0026amp; \\begin{bmatrix} a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\\\ a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\\\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \\end{bmatrix} \\\\ \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\\\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \\end{bmatrix} \\begin{bmatrix} 0 \u0026amp; 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} = \u0026amp; \\begin{bmatrix} a_{12} \u0026amp; a_{11} \u0026amp; a_{13} \\\\ a_{22} \u0026amp; a_{21} \u0026amp; a_{23} \\\\ a_{32} \u0026amp; a_{31} \u0026amp; a_{33} \\end{bmatrix} \\end{align*} $$\nhttps://www.cfm.brown.edu/people/dobrush/cs52/Mathematica/Part2/PLU.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1,"permalink":"https://freshrimpsushi.github.io/en/posts/1/","tags":null,"title":"Permutation Matrix"}]