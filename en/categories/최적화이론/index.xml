<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>최적화이론 on FreshrimpRestaurant</title>
    <link>https://freshrimpsushi.github.io/en/categories/%EC%B5%9C%EC%A0%81%ED%99%94%EC%9D%B4%EB%A1%A0/</link>
    <description>Recent content in 최적화이론 on FreshrimpRestaurant</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 01 Mar 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://freshrimpsushi.github.io/en/categories/%EC%B5%9C%EC%A0%81%ED%99%94%EC%9D%B4%EB%A1%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Linear Programming Duality</title>
      <link>https://freshrimpsushi.github.io/en/posts/2348/</link>
      <pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2348/</guid>
      <description>Buildup For $x_{1} , x_{2} \ge 0$, let&amp;rsquo;s say we have the following linear programming problem. $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; 2x_{1} &amp;amp; + &amp;amp; 3x_{2} \\ \text{subject to} &amp;amp; &amp;amp; 4x_{1} &amp;amp; + &amp;amp; 8x_{2} &amp;amp; \le &amp;amp; 12 \\ &amp;amp; &amp;amp; 2x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; \le &amp;amp; 3 \\ &amp;amp; &amp;amp; 3x_{1} &amp;amp; + &amp;amp; 2x_{2} &amp;amp; \le &amp;amp; 4 \end{matrix} $$ Our goal is to</description>
    </item>
    <item>
      <title>Simplex Method&#39;s Bland&#39;s Rule</title>
      <link>https://freshrimpsushi.github.io/en/posts/2344/</link>
      <pubDate>Tue, 21 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2344/</guid>
      <description>Theorem A system of equations of the following form for Dictionary: $i = 1 , \cdots , m$ is called a Dictionary. $$ \begin{align*} \zeta &amp;amp;=&amp;amp; &amp;amp; &amp;amp; \sum_{j=1}^{n} c_{j} x_{j} \\ x_{n+i} &amp;amp;=&amp;amp; b_{i} &amp;amp;-&amp;amp; \sum_{j=1}^{n} a_{ij} x_{j} \end{align*} $$ Variables on the left side of $\zeta$, excluding the one variable, are called basic variables, and variables on the right side are called nonbasic variables. Their indices are denoted</description>
    </item>
    <item>
      <title>Linear Programming: The Simplex Method</title>
      <link>https://freshrimpsushi.github.io/en/posts/2336/</link>
      <pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2336/</guid>
      <description>Buildup 1 Consider the following Linear Programming Problem for $x_{1} , x_{2} \ge 0$. $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} \\ \text{subject to} &amp;amp;-&amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; \le &amp;amp; 1 \\ &amp;amp; &amp;amp; x_{1} &amp;amp; &amp;amp; &amp;amp; \le &amp;amp; 3 \\ &amp;amp; &amp;amp; &amp;amp; &amp;amp; x_{2} &amp;amp; \le &amp;amp; 2 \end{matrix} $$ In other words, we want to maximize $x_{1} + x_{2}$ while</description>
    </item>
    <item>
      <title>Linear Programming: Dictionaries and Tableau</title>
      <link>https://freshrimpsushi.github.io/en/posts/2334/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2334/</guid>
      <description>Notation $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ For the matrix $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$, it is said that the linear programming problem is represented in the form of equation form as above, and let&amp;rsquo;s denote its components as follows. $$ \begin{align*} A =&amp;amp; \left( a_{ij}</description>
    </item>
    <item>
      <title>Linear Programming Problem Basis Solution</title>
      <link>https://freshrimpsushi.github.io/en/posts/2223/</link>
      <pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2223/</guid>
      <description>Definition 1 $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ Given matrices $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$ for a Linear Programming Problem represented in the equation form, a set $B \subseteq [n]$ with cardinality $m$ exists for the feasible solution $\mathbf{x} \in \mathbb{R}^{n}$, satisfying the following two conditions,</description>
    </item>
    <item>
      <title>Linear Programming Problem in Equation Form</title>
      <link>https://freshrimpsushi.github.io/en/posts/2221/</link>
      <pubDate>Mon, 20 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2221/</guid>
      <description>Definition 1 For matrices $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$, the following linear programming problem is called in standard form or equational form. $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ $\mathbf{c}^{T}$ means transpose. Optimization refers to maximization or minimization. Description Conversion to Standard Form In principle, any linear</description>
    </item>
    <item>
      <title>Definition of Linear Programming Problem</title>
      <link>https://freshrimpsushi.github.io/en/posts/2207/</link>
      <pubDate>Mon, 23 May 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2207/</guid>
      <description>Definition 1 A linear programming problem, shortly referred to as LP, is an optimization problem that is linear in both its objective function and constraints. Simply put, a linear problem looks to find $\mathbf{x} \in \mathbb{R}^{n}$ for which the objective function $f: \mathbb{R}^{n} \to \mathbb{R}$, given vectors $\mathbf{c} \in \mathbb{R}^{n}$, is $$ f \left( \mathbf{x} \right) := \mathbf{c}^{T} \mathbf{x} $$ and for given matrices $A \in \mathbb{R}^{m \times n}$ and</description>
    </item>
    <item>
      <title>Optimal Value: Maximum and Minimum</title>
      <link>https://freshrimpsushi.github.io/en/posts/2027/</link>
      <pubDate>Fri, 28 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2027/</guid>
      <description>Simple Definitions Maximum and Minimum collectively are called the Optimum. In the set $X$, the largest element is denoted as the maximum $\max X$, and the smallest element as the minimum $\min X$. For the function $f : X \to \mathbb{R}$, the largest function value is denoted as $\max_{X} f$, and the smallest function value as $\min_{X} f$. $\mathbb{R}$ denotes the entire set of real numbers. Maximum and Minimum are</description>
    </item>
    <item>
      <title>Optimization Techniques in Mathematics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1463/</link>
      <pubDate>Sat, 25 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1463/</guid>
      <description>Definition The problem of finding $x^{ \ast } = \argmin_{x} f(x)$ that makes the function value of function $f : \mathbb{R}^{n} \to \mathbb{R}$ minimum is known as the Optimization Problem, and the algorithm to solve this problem is called an Optimization Technique. The given function $f$ in the optimization problem is specifically referred to as the Objective Function. $x^{ \ast }$ is called the Global Optimizer if for all $x$,</description>
    </item>
    <item>
      <title>Gradient Descent in Mathematics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1012/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1012/</guid>
      <description>Definition 1 A scalar function $\varphi : \mathbb{R}^{n} \to \mathbb{R}$ is called a Cost Function. An algorithm that finds $\mathbb{x}_{n+1}$ that satisfies $\varphi ( \mathbb{x}_{n+1} ) &amp;lt; \varphi ( \mathbb{x}_{n} )$ in $\mathbb{x} = \mathbb{x}_{n}$ to minimize the cost function $ \varphi ( \mathbb{x} )$ is called the Descent Method. Explanation Let’s consider building a house as an example for a cost function, $\varphi$. The resources</description>
    </item>
  </channel>
</rss>
