<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Optimization on FreshrimpRestaurant</title><link>https://freshrimpsushi.github.io/en/categories/%EC%B5%9C%EC%A0%81%ED%99%94%EC%9D%B4%EB%A1%A0/</link><description>Recent content in Optimization on FreshrimpRestaurant</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 29 Apr 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/en/categories/%EC%B5%9C%EC%A0%81%ED%99%94%EC%9D%B4%EB%A1%A0/index.xml" rel="self" type="application/rss+xml"/><item><title>Proximal Operator</title><link>https://freshrimpsushi.github.io/en/posts/3590/</link><pubDate>Mon, 29 Apr 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3590/</guid><description>Definition1 Let $\left\| \cdot \right\|_{X}$ be the norm of the vector space $X$. The proximal operator $\operatorname{prox}_{\lambda f} : X \to 2^{X}$ for a function $f : X \to \mathbb{R}$ is defined as follows, for $\lambda &amp;gt; 0$, $$ \begin{align} \operatorname{prox}_{\lambda f} (\mathbf{x}) &amp;amp;:= \argmin\limits_{\mathbf{v}} \left\{ \lambda f(\mathbf{v}) + \dfrac{1}{2}\left\| \mathbf{v} - \mathbf{x} \right\|_{X}^{2} : \mathbf{v} \in X \right\} \\ &amp;amp;= \argmin\limits_{\mathbf{v}} \left\{ f(\mathbf{v}) + \dfrac{1}{2\lambda}\left\| \mathbf{v} - \mathbf{x} \right\|_{X}^{2}</description></item><item><title>First-Order Necessary Conditions for Extrema of Multivariable Functions</title><link>https://freshrimpsushi.github.io/en/posts/3534/</link><pubDate>Mon, 08 Jan 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3534/</guid><description>Theorem1 Let&amp;rsquo;s assume the function $f : \mathbb{R}^{n} \to \mathbb{R}$ is given. If $x^{\ast}$ is a local optimizer and $f \in C^{1}$ in the vicinity of $x^{\ast}$, then, $$ \nabla f(x^{\ast}) = 0 $$ $\nabla f$ is the gradient of $f$. Note here that $0$ is not the numeric zero, but a zero vector. Explanation The first-order necessary condition tells us about the property of the gradient, which is the</description></item><item><title>Second Order Necessary/Sufficient Conditions for the Extreme Values of Multivariable Functions</title><link>https://freshrimpsushi.github.io/en/posts/3533/</link><pubDate>Sat, 06 Jan 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3533/</guid><description>Theorem1 Let&amp;rsquo;s say the function $f : \mathbb{R}^{n} \to \mathbb{R}$ is given. $\nabla f$, $\nabla^{2}f$ are the gradient and Hessian of $f$, respectively. Second-order necessary conditions If $x^{\ast}$ is a local optimizer and $\nabla^{2}f$ exists and is continuous in the neighborhood of $x^{\ast}$, $$ \nabla f(x^{\ast}) = 0 $$ and $\nabla^{2} f(x^{\ast})$ is positive semidefinite. Note that $0$ is not the number zero, but the zero vector. Second-order sufficient conditions</description></item><item><title>Secant Method: Newton's Method</title><link>https://freshrimpsushi.github.io/en/posts/3530/</link><pubDate>Sun, 31 Dec 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3530/</guid><description>Definition1 2 In the problem of optimizing the objective function $J : \mathbb{R}^{n} \to \mathbb{R}$, the following iterative algorithm is called Newton&amp;rsquo;s method. $$ \begin{equation} \mathbf{x}_{n+1} = \mathbf{x}_{n} - H^{-1}(\mathbf{x}_{n}) \nabla J(\mathbf{x}_{n}) \end{equation} $$ $\nabla J$ is the gradient, and $H$ is the Hessian of $J$. Derivation By approximating $J$ with up to the second derivative term using the Taylor expansion, it looks like this: $$ J(\mathbf{x}) \approx J(\mathbf{x}_{0}) +</description></item><item><title>Optimization Theory: Method of Lagrange Multipliers</title><link>https://freshrimpsushi.github.io/en/posts/2404/</link><pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2404/</guid><description>⚡ 이 포스트는 패스트 트랙Fast Track으로 작성되었습니다. Description In nonlinear optimization problems that have a nonlinear objective function, a method called Lagrangian Multiplier Method involves multiplying constraints by something called Lagrangian Multipliers and integrating them into the objective function. $$ \begin{matrix} \text{Maximize} &amp;amp; f(x) \\ \text{subject to}</description></item><item><title>Solving Linear Programming Problems with R</title><link>https://freshrimpsushi.github.io/en/posts/2362/</link><pubDate>Wed, 29 Mar 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2362/</guid><description>Outline You can use the lpSolve package1. It allows you to put a linear programming problem, represented in matrix form, $A, \mathbf{b}, \mathbf{c}$. Code $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} \\ \text{subject to} &amp;amp;-&amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; \le &amp;amp; 1 \\ &amp;amp; &amp;amp; x_{1} &amp;amp; &amp;amp; &amp;amp; \le &amp;amp; 3 \\ &amp;amp; &amp;amp; &amp;amp; &amp;amp; x_{2} &amp;amp; \le &amp;amp; 2 \end{matrix} $$ As</description></item><item><title>Solving Linear Programming Problems with MATLAB</title><link>https://freshrimpsushi.github.io/en/posts/2360/</link><pubDate>Sat, 25 Mar 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2360/</guid><description>Overview You can use the Optimization Toolbox1. Insert the $A, \mathbf{b}, \mathbf{c}$ in matrix form for the linear programming problem. Code $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} \\ \text{subject to} &amp;amp;-&amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; \le &amp;amp; 1 \\ &amp;amp; &amp;amp; x_{1} &amp;amp; &amp;amp; &amp;amp; \le &amp;amp; 3 \\ &amp;amp; &amp;amp; &amp;amp; &amp;amp; x_{2} &amp;amp; \le &amp;amp; 2 \end{matrix} $$ As a simple example,</description></item><item><title>Solving Linear Programming Problems with Python</title><link>https://freshrimpsushi.github.io/en/posts/2358/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2358/</guid><description>Overview You can use the scipy package1. Input the linear programming problem expressed in matrix form, as in $A, \mathbf{b}, \mathbf{c}$. Code $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} \\ \text{subject to} &amp;amp;-&amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; \le &amp;amp; 1 \\ &amp;amp; &amp;amp; x_{1} &amp;amp; &amp;amp; &amp;amp; \le &amp;amp; 3 \\ &amp;amp; &amp;amp; &amp;amp; &amp;amp; x_{2} &amp;amp; \le &amp;amp; 2 \end{matrix} $$ As a simple</description></item><item><title>Solving Linear Programming Problems with Julia</title><link>https://freshrimpsushi.github.io/en/posts/2356/</link><pubDate>Fri, 17 Mar 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2356/</guid><description>Overview To solve optimization problems, one can use the JuMP package[^1]. JuMP stands for Julia Mathematical Programming. Compared to other languages, coding in Julia is almost like directly transcribing mathematical formulas, which is very intuitive. Code $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} \\ \text{subject to} &amp;amp;-&amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; \le &amp;amp; 1 \\ &amp;amp; &amp;amp; x_{1} &amp;amp; &amp;amp; &amp;amp; \le &amp;amp; 3 \\</description></item><item><title>Solving Linear Programming Problems with Excel</title><link>https://freshrimpsushi.github.io/en/posts/2354/</link><pubDate>Mon, 13 Mar 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2354/</guid><description>Guide Step 1. Activate the Solver Add-in In the File/Options/Add-ins tab, click the Go(G) button next to Excel Add-ins in Manage(A). A window named Add-ins will pop up like below. Check the Solver Add-in and click OK. The Solver feature has been activated under the Data tab in Analysis. Step 2. Transcribe the Linear Programming Problem $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} \\ \text{subject to} &amp;amp;-&amp;amp;</description></item><item><title>Proof of Strong Duality Theorem in Linear Programming</title><link>https://freshrimpsushi.github.io/en/posts/2352/</link><pubDate>Thu, 09 Mar 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2352/</guid><description>Theorem $$ \begin{align*} \text{Maximize} &amp;amp; \sum_{j=1}^{n} c_{j} x_{j} &amp;amp; \text{(Primal)} \\ \text{subject to} &amp;amp; \sum_{j=1}^{n} a_{ij} x_{j} \le b_{i} &amp;amp; i = 1 ,\cdots , m \\ &amp;amp; x_{j} \ge 0 &amp;amp; j = 1, \cdots , n \end{align*} $$ $$ \begin{align*} \text{Minimize} &amp;amp; \sum_{i=1}^{m} b_{i} y_{i} &amp;amp; \text{(Dual)} \\ \text{subject to} &amp;amp; \sum_{i=1}^{m} y_{i} a_{ij} \ge c_{j} &amp;amp; j = 1 ,\cdots , n \\ &amp;amp; y_{i} \ge 0</description></item><item><title>Proof of Weak Duality Theorem in Linear Programming</title><link>https://freshrimpsushi.github.io/en/posts/2350/</link><pubDate>Sun, 05 Mar 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2350/</guid><description>Theorem $$ \begin{align*} \text{Maximize} &amp;amp; \sum_{j=1}^{n} c_{j} x_{j} &amp;amp; \text{(Primal)} \\ \text{subject to} &amp;amp; \sum_{j=1}^{n} a_{ij} x_{j} \le b_{i} &amp;amp; i = 1 ,\cdots , m \\ &amp;amp; x_{j} \ge 0 &amp;amp; j = 1, \cdots , n \end{align*} $$ $$ \begin{align*} \text{Minimize} &amp;amp; \sum_{i=1}^{m} b_{i} y_{i} &amp;amp; \text{(Dual)} \\ \text{subject to} &amp;amp; \sum_{i=1}^{m} y_{i} a_{ij} \ge c_{j} &amp;amp; j = 1 ,\cdots , n \\ &amp;amp; y_{i} \ge 0</description></item><item><title>Linear Programming Duality</title><link>https://freshrimpsushi.github.io/en/posts/2348/</link><pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2348/</guid><description>Buildup For $x_{1} , x_{2} \ge 0$, let&amp;rsquo;s say we have the following linear programming problem. $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; 2x_{1} &amp;amp; + &amp;amp; 3x_{2} \\ \text{subject to} &amp;amp; &amp;amp; 4x_{1} &amp;amp; + &amp;amp; 8x_{2} &amp;amp; \le &amp;amp; 12 \\ &amp;amp; &amp;amp; 2x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; \le &amp;amp; 3 \\ &amp;amp; &amp;amp; 3x_{1} &amp;amp; + &amp;amp; 2x_{2} &amp;amp; \le &amp;amp; 4 \end{matrix} $$ Our goal is to</description></item><item><title>Linear Programming: Proof of the Fundamental Theorem</title><link>https://freshrimpsushi.github.io/en/posts/2346/</link><pubDate>Sat, 25 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2346/</guid><description>Theorem For a linear programming problem in the form of equation form, one of the following three is true: (1): If an optimal solution does not exist, then the problem is inherently infeasible or unbounded. (2): If a feasible solution exists, then a feasible basic solution also exists. (3): If an optimal solution exists, then an optimal basic solution also exists. Proof Strategy: Given that it&amp;rsquo;s named the Fundamental Theorem,</description></item><item><title>Simplex Method's Bland's Rule</title><link>https://freshrimpsushi.github.io/en/posts/2344/</link><pubDate>Tue, 21 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2344/</guid><description>Theorem A system of equations of the following form for Dictionary: $i = 1 , \cdots , m$ is called a Dictionary. $$ \begin{align*} \zeta &amp;amp;=&amp;amp; &amp;amp; &amp;amp; \sum_{j=1}^{n} c_{j} x_{j} \\ x_{n+i} &amp;amp;=&amp;amp; b_{i} &amp;amp;-&amp;amp; \sum_{j=1}^{n} a_{ij} x_{j} \end{align*} $$ Variables on the left side of $\zeta$, excluding the one variable, are called basic variables, and variables on the right side are called nonbasic variables. Their indices are denoted</description></item><item><title>Simplex Method Cycling</title><link>https://freshrimpsushi.github.io/en/posts/2342/</link><pubDate>Fri, 17 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2342/</guid><description>Definition $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ For the matrix $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$, let us say the linear programming problem is expressed in the equation form as above, and for $i = 1 , \cdots , m$, let us represent its dictionary as follows.</description></item><item><title>Infinity of the Objective Function in Linear Programming</title><link>https://freshrimpsushi.github.io/en/posts/2340/</link><pubDate>Mon, 13 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2340/</guid><description>Description $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ Given matrix $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$, let&amp;rsquo;s say a linear programming problem is represented in an equation form as above. Despite following the constraints, the objective function can become unbounded. A picture is worth a thousand words1. Geometrically</description></item><item><title>Initialization and Auxiliary Problem in Simplex Method</title><link>https://freshrimpsushi.github.io/en/posts/2338/</link><pubDate>Thu, 09 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2338/</guid><description>Buildup $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ Let&amp;rsquo;s say the linear programming problem is represented in the equation form as above with respect to matrices $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$. And for all $j = 1 , \cdots , n+m$, $x_{k} \ge 0$ holds, and for</description></item><item><title>Linear Programming: The Simplex Method</title><link>https://freshrimpsushi.github.io/en/posts/2336/</link><pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2336/</guid><description>Buildup 1 Consider the following Linear Programming Problem for $x_{1} , x_{2} \ge 0$. $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} \\ \text{subject to} &amp;amp;-&amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; \le &amp;amp; 1 \\ &amp;amp; &amp;amp; x_{1} &amp;amp; &amp;amp; &amp;amp; \le &amp;amp; 3 \\ &amp;amp; &amp;amp; &amp;amp; &amp;amp; x_{2} &amp;amp; \le &amp;amp; 2 \end{matrix} $$ In other words, we want to maximize $x_{1} + x_{2}$ while</description></item><item><title>Linear Programming: Dictionaries and Tableau</title><link>https://freshrimpsushi.github.io/en/posts/2334/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2334/</guid><description>Notation $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ For the matrix $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$, it is said that the linear programming problem is represented in the form of equation form as above, and let&amp;rsquo;s denote its components as follows. $$ \begin{align*} A =&amp;amp; \left( a_{ij}</description></item><item><title>If an Optimal Solution Exists in Linear Programming Problems, One of Them is a Basic Feasible Solution</title><link>https://freshrimpsushi.github.io/en/posts/2229/</link><pubDate>Wed, 06 Jul 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2229/</guid><description>Theorem 1 $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ Given matrices $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$, let&amp;rsquo;s assume a linear programming problem is represented in the form of an equation as above. If an optimal solution exists, then an optimal basic feasible solution also exists. $\mathbf{c}^{T}$ represents</description></item><item><title>Proof of the Existence of an Optimal Solution in the Equation Form of Linear Programming Problems</title><link>https://freshrimpsushi.github.io/en/posts/2227/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2227/</guid><description>Theorem 1 $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ Let&amp;rsquo;s say the linear programming problem is represented in the form of equation form for matrices $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$. If there exists at least one feasible solution, and the set of feasible solutions is Bounded Above</description></item><item><title>Proof of the Uniqueness of Base Solubility</title><link>https://freshrimpsushi.github.io/en/posts/2225/</link><pubDate>Tue, 28 Jun 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2225/</guid><description>Theorem 1 $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ Given a matrix $A \in \mathbb{R}^{m \times n}$ and $\mathbf{b} \in \mathbb{R}^{m \times 1}$ and $\mathbf{c} \in \mathbb{R}^{n}$, if the linear programming problem is expressed in the form of equations as above, the basic feasible solution is uniquely determined by the basis $B$. $\mathbf{c}^{T}$ means the transpose.</description></item><item><title>Linear Programming Problem Basis Solution</title><link>https://freshrimpsushi.github.io/en/posts/2223/</link><pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2223/</guid><description>Definition 1 $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ Given matrices $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$ for a Linear Programming Problem represented in the equation form, a set $B \subseteq [n]$ with cardinality $m$ exists for the feasible solution $\mathbf{x} \in \mathbb{R}^{n}$, satisfying the following two conditions,</description></item><item><title>Linear Programming Problem in Equation Form</title><link>https://freshrimpsushi.github.io/en/posts/2221/</link><pubDate>Mon, 20 Jun 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2221/</guid><description>Definition 1 For matrices $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$, the following linear programming problem is called in standard form or equational form. $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ $\mathbf{c}^{T}$ means transpose. Optimization refers to maximization or minimization. Description Conversion to Standard Form In principle, any linear</description></item><item><title>Definition of Linear Programming Problem</title><link>https://freshrimpsushi.github.io/en/posts/2207/</link><pubDate>Mon, 23 May 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2207/</guid><description>Definition 1 A linear programming problem, shortly referred to as LP, is an optimization problem that is linear in both its objective function and constraints. Simply put, a linear problem looks to find $\mathbf{x} \in \mathbb{R}^{n}$ for which the objective function $f: \mathbb{R}^{n} \to \mathbb{R}$, given vectors $\mathbf{c} \in \mathbb{R}^{n}$, is $$ f \left( \mathbf{x} \right) := \mathbf{c}^{T} \mathbf{x} $$ and for given matrices $A \in \mathbb{R}^{m \times n}$ and</description></item><item><title>Optimal Solution: Maximum and Minimum Factors</title><link>https://freshrimpsushi.github.io/en/posts/2031/</link><pubDate>Sat, 05 Jun 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2031/</guid><description>Difficult Definitions Let&amp;rsquo;s assume an arbitrary set $X$ and a totally ordered set $\left( Y, \le \right)$ are given. For a subset $S \subset X$ of $X$, the argument of maxima $\argmax_{S} : Y^{X} \to 2^{X}$ and argument of minima $\argmin_{S} : Y^{X} \to 2^{X}$ of the function $f : X \to Y$ are defined as follows. $$ \argmax_{S} f := \left\{ x_{\ast} \in S : f \left( x_{\ast} \right)</description></item><item><title>Optimal Value: Maximum and Minimum</title><link>https://freshrimpsushi.github.io/en/posts/2027/</link><pubDate>Fri, 28 May 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2027/</guid><description>Simple Definitions Maximum and Minimum collectively are called the Optimum. In the set $X$, the largest element is denoted as the maximum $\max X$, and the smallest element as the minimum $\min X$. For the function $f : X \to \mathbb{R}$, the largest function value is denoted as $\max_{X} f$, and the smallest function value as $\min_{X} f$. $\mathbb{R}$ denotes the entire set of real numbers. Maximum and Minimum are</description></item><item><title>Stochastic Gradient Descent</title><link>https://freshrimpsushi.github.io/en/posts/1464/</link><pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1464/</guid><description>Definition The method known as Stochastic Gradient Descent refers to, given the objective function $Q$, learning rate $\alpha &amp;gt; 0$, batch size $m$, and for the $i$th data, $$ \omega_{n+1} := \omega_{n} - \alpha {{ 1 } \over { n }} \sum_{i=1}^{m} \nabla Q_{i} ( \omega_{n} ) $$. Explanation Machine Learning Stochastic Gradient Descent is inevitably deeply related to machine learning as it deals with data. Even if some terms</description></item><item><title>Optimization Techniques in Mathematics</title><link>https://freshrimpsushi.github.io/en/posts/1463/</link><pubDate>Sat, 25 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1463/</guid><description>Definition The problem of finding $x^{ \ast } = \argmin_{x} f(x)$ that makes the function value of function $f : \mathbb{R}^{n} \to \mathbb{R}$ minimum is known as the Optimization Problem, and the algorithm to solve this problem is called an Optimization Technique. The given function $f$ in the optimization problem is specifically referred to as the Objective Function. $x^{ \ast }$ is called the Global Optimizer if for all $x$,</description></item><item><title>Gradient Descent in Mathematics</title><link>https://freshrimpsushi.github.io/en/posts/1012/</link><pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1012/</guid><description>Definition 1 A scalar function $\varphi : \mathbb{R}^{n} \to \mathbb{R}$ is called a Cost Function. An algorithm that finds $\mathbb{x}_{n+1}$ that satisfies $\varphi ( \mathbb{x}_{n+1} ) &amp;lt; \varphi ( \mathbb{x}_{n} )$ in $\mathbb{x} = \mathbb{x}_{n}$ to minimize the cost function $ \varphi ( \mathbb{x} )$ is called the Descent Method. Explanation Let’s consider building a house as an example for a cost function, $\varphi$. The resources</description></item><item><title>Proximal Alternating Linearized Minimization Algorithm (PALM)</title><link>https://freshrimpsushi.github.io/en/posts/3596/</link><pubDate>Sun, 11 May 2014 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3596/</guid><description>Overview Jérôme Bolte, Shoham Sabach, and Marc Teboulle introduced an optimization technique called Proximal Alternating Linearized Minimization (PALM) algorithm in their paper Proximal alternating linearized minimization for nonconvex and nonsmooth problems. Algorithm The method to solve optimization problems like $(1)$ is called the Proximal Alternating Linearized Minimization (PALM) algorithm. This, in simple terms, means performing alternating optimization for two variables using the proximal gradient method.</description></item><item><title>Proximal Gradient Method</title><link>https://freshrimpsushi.github.io/en/posts/3595/</link><pubDate>Fri, 09 May 2014 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3595/</guid><description>Definition 1 Let&amp;rsquo;s say the non-differentiable objective function $H(\mathbf{x}) : \mathbb{R}^{n} \to \mathbb{R}$ is decomposed into a differentiable function $f$ and a non-differentiable function $g$. $$ H(\mathbf{x}) = f(\mathbf{x}) + g(\mathbf{x}) $$ The method of solving the optimization problem for $H$ using the following iterative algorithm is called the proximal gradient method. $$ \mathbf{x}^{(k+1)} = \operatorname{prox}_{\lambda g}(\mathbf{x}^{(k)} - \lambda \nabla f(\mathbf{x}^{(k)})) $$ Explanation It is called the proximal gradient method</description></item><item><title>Subgradient Method</title><link>https://freshrimpsushi.github.io/en/posts/3594/</link><pubDate>Wed, 07 May 2014 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3594/</guid><description>Definition1 Let&amp;rsquo;s say the objective function $f : \mathbb{R}^{n} \to \mathbb{R}$ is a convex function. Let&amp;rsquo;s denote the subgradient of $f$ at point $\mathbf{x}^{(k)}$ as $\mathbf{g}^{(k)}$. The method of updating $\mathbf{x}^{(k)}$ in the following way to solve the optimization problem for $f$ is called the subgradient method. $$ \mathbf{x}^{(k+1)} = \mathbf{x}^{(k)} - \alpha \mathbf{g}^{(k)} $$ Description2 It&amp;rsquo;s a form where the gradient in the Gradient Descent is replaced with a</description></item><item><title>Subgradient</title><link>https://freshrimpsushi.github.io/en/posts/3593/</link><pubDate>Mon, 05 May 2014 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3593/</guid><description>Definition 1 2 For a function $f : \mathbb{R}^{n} \to \mathbb{R}$, the $\mathbf{g} \in \mathbb{R}^{n}$ that satisfies the following is called a subgradient of $f$ at point $\mathbf{x}$. $$ f(\mathbf{y}) \ge f(\mathbf{x}) + \mathbf{g}^{T}(\mathbf{y} - \mathbf{x}) \qquad \forall \mathbf{y} \in \mathbb{R}^{n} $$ Explanation If the convex function $f$ is differentiable at $\mathbf{x}$, then $\mathbf{g} =$ $\nabla f(\mathbf{x})$ is unique. Conversely, if $\partial f(\mathbf{x}) = \left\{ \mathbf{g} \right\}$, then $f$ is</description></item><item><title>Alternating Optimization</title><link>https://freshrimpsushi.github.io/en/posts/3592/</link><pubDate>Sat, 03 May 2014 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3592/</guid><description>Definition When optimizing a multivariate objective function, the practice of optimizing over one variable at a time, alternating between variables, is known as alternating optimization. Description Consider the following optimization problem where the objective function is $H(x,y)$. $$ \argmin\limits_{x,y} H(x,y) $$ This can be divided into two subproblems by fixing one variable and optimizing over the other. $$ \begin{cases} \argmin\limits_{x} H(x,y) \\ \argmin\limits_{y} H(x,y) \end{cases} $$ Alternating optimization is the</description></item><item><title>Proximal Minimization Algorithm</title><link>https://freshrimpsushi.github.io/en/posts/3591/</link><pubDate>Thu, 01 May 2014 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3591/</guid><description>Definition1 When solving the optimization problem for the objective function $f : \mathbb{R}^{n} \to \mathbb{R}^{n}$, the method of updating the optimal solution $\mathbf{x}^{(k)}$ by repeatedly applying the proximal operator is called the proximal minimization algorithm. $$ \mathbf{x}^{(k+1)} = \operatorname{prox}_{\lambda f}(\mathbf{x}^{(k)}) = \argmin\limits_{\mathbf{v}} \left\{ \lambda f(\mathbf{v}) + \dfrac{1}{2}\left\| \mathbf{v} - \mathbf{x}^{(k)} \right\|_{2}^{2} : \mathbf{v} \in \mathbb{R}^{n} \right\} $$ Description It is also known as the proximal point algorithm or proximal iteration.</description></item></channel></rss>