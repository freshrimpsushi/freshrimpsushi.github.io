<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>통계적검정 on FreshrimpRestaurant</title>
    <link>https://freshrimpsushi.github.io/en/categories/%ED%86%B5%EA%B3%84%EC%A0%81%EA%B2%80%EC%A0%95/</link>
    <description>Recent content in 통계적검정 on FreshrimpRestaurant</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 05 Sep 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://freshrimpsushi.github.io/en/categories/%ED%86%B5%EA%B3%84%EC%A0%81%EA%B2%80%EC%A0%95/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Simplified Definition of Hypothesis Testing</title>
      <link>https://freshrimpsushi.github.io/en/posts/2442/</link>
      <pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2442/</guid>
      <description>Definition 1 2 In science, a statistical hypothesis refers to an assumption about a population, and the statistical decision-making process of accepting or rejecting this hypothesis is called statistical hypothesis testing. This process involves two competing hypotheses, where the hypothesis that the researcher wishes to support is called the alternative hypothesis $H_{1}$, and the hypothesis accepted when there is no substantial evidence to claim that the alternative hypothesis is true</description>
    </item>
    <item>
      <title>Harke-Bera Test</title>
      <link>https://freshrimpsushi.github.io/en/posts/949/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/949/</guid>
      <description>Hypothesis Testing Given that we have quantitative data $\left\{ x_{i} \right\}_{i = 1}^{n}$. $H_{0}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ follows a normal distribution. $H_{1}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ does not follow a normal distribution. Explanation The Jarque-Bera test is used to test for normality as a hypothesis test, typically to demonstrate the presence of normality. This is one of the rare cases where the acceptance of the</description>
    </item>
    <item>
      <title>Shapiro-Wilk Test</title>
      <link>https://freshrimpsushi.github.io/en/posts/939/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/939/</guid>
      <description>Hypothesis Testing Given quantitative data $\left\{ x_{i} \right\}_{i = 1}^{n}$. $H_{0}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ follows a normal distribution. $H_{1}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ does not follow a normal distribution. Description The Shapiro-Wilk test is a hypothesis test used to assess the normality of data, usually to demonstrate that normality is present. It&amp;rsquo;s one of the rare occasions where having the null hypothesis accepted matches &amp;rsquo;the</description>
    </item>
    <item>
      <title>Hosmer-Lemeshow Goodness of Fit Test</title>
      <link>https://freshrimpsushi.github.io/en/posts/852/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/852/</guid>
      <description>Hypothesis Testing Let&amp;rsquo;s refer to the model obtained through logistic regression as $M$. $H_{0}$: $M$ is appropriate. $H_{1}$: $M$ is not appropriate. Description The Hosmer-Lemeshow goodness of fit test is a representative hypothesis test used to determine the adequacy of logistic regression models. Although it&amp;rsquo;s a very simple test, the null hypothesis and the alternative hypothesis can be confusing. While it’s true that there is no good</description>
    </item>
    <item>
      <title>F-test for Regression Coefficients</title>
      <link>https://freshrimpsushi.github.io/en/posts/672/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/672/</guid>
      <description>Hypothesis Testing Assuming in the model diagnostics of the linear multiple regression model, the residuals satisfy linearity, homoscedasticity, independence, and normality. The hypothesis testing for the multiple regression analysis with $n$ observations and $p$ independent variables is as follows: $H_{0}$: $\beta_{1} = \beta_{2} = \cdots = \beta_{p} = 0$ i.e., all independent variables do not have a correlation with the dependent variable. $H_{1}$: At least one among $\beta_{1} , \beta_{2}</description>
    </item>
    <item>
      <title>Regression Coefficient&#39;s t-test</title>
      <link>https://freshrimpsushi.github.io/en/posts/654/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/654/</guid>
      <description>Hypothesis Testing $$ \begin{bmatrix} y_{1} \\ y_{2} \\ \vdots \\ y_{n} \end{bmatrix} = \begin{bmatrix} 1 &amp;amp; x_{11} &amp;amp; \cdots &amp;amp; x_{p1} \\ 1 &amp;amp; x_{12} &amp;amp; \cdots &amp;amp; x_{p2} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 1 &amp;amp; x_{1n} &amp;amp; \cdots &amp;amp; x_{pn} \end{bmatrix} \begin{bmatrix} \beta_{0} \\ \beta_{1} \\ \vdots \\ \beta_{p} \end{bmatrix} + \begin{bmatrix} \varepsilon_{1} \\ \varepsilon_{2} \\ \vdots \\ \varepsilon_{n} \end{bmatrix} $$ When independent variables of</description>
    </item>
    <item>
      <title>Rejection Region and Significance Level</title>
      <link>https://freshrimpsushi.github.io/en/posts/509/</link>
      <pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/509/</guid>
      <description>Definition 1 The error of rejecting the null hypothesis when it is actually true is called a Type I error. The error of failing to reject the null hypothesis when the alternative hypothesis is true is called a Type II error. The maximum probability of committing a Type I error is called the Significance Level. The statistic used for hypothesis testing is called the Test Statistic. The region of the</description>
    </item>
  </channel>
</rss>
