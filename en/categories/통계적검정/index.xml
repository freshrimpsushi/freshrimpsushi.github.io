<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Statistical Test on FreshrimpRestaurant</title><link>https://freshrimpsushi.github.io/en/categories/%ED%86%B5%EA%B3%84%EC%A0%81%EA%B2%80%EC%A0%95/</link><description>Recent content in Statistical Test on FreshrimpRestaurant</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 10 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/en/categories/%ED%86%B5%EA%B3%84%EC%A0%81%EA%B2%80%EC%A0%95/index.xml" rel="self" type="application/rss+xml"/><item><title>Rank in Statistics</title><link>https://freshrimpsushi.github.io/en/posts/2677/</link><pubDate>Thu, 10 Jul 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2677/</guid><description>Definition In statistics, the rank $R : \mathbb{R} \to \mathbb{N}$ is commonly used as a function to indicate the order of data when sorted in ascending order. Explanation $$ x_{3} &amp;lt; x_{1} &amp;lt; x_{2} \implies x_{(1)} = x_{3}, x_{(2)} = x_{1}, x_{(3)} = x_{2} $$ In statistics, the method of placing parentheses in the subscript of data is used when the order of data is required. The rank introduced in</description></item><item><title>What is Non-parametric Statistics?</title><link>https://freshrimpsushi.github.io/en/posts/2675/</link><pubDate>Sun, 06 Jul 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2675/</guid><description>Definition 1 In statistics, nonparametric statistics refers to statistical methodologies that generally do not assume a specific distribution for the population. They are particularly known for having minimal conditions for hypothesis testing. Description As an example, let&amp;rsquo;s see how hypothesis testing is conducted in analysis of variance. One-way ANOVA: Consider that there are $k$ treatments in an experimental design, and $n_{j}$ samples are drawn from each treatment, with a total</description></item><item><title>Two-way ANOVA</title><link>https://freshrimpsushi.github.io/en/posts/2669/</link><pubDate>Tue, 24 Jun 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2669/</guid><description>Hypothesis Testing 1 Suppose there are $k$ treatments and $b$ blocks in an experimental design, from which $n = bk$ samples are obtained. Assume that the samples of the $j = 1 , \cdots , k$th treatment are independently and randomly distributed following a normal distribution $N \left( \mu_{j} , \sigma_{j}^{2} \right)$, with the population variance of each normal distribution being equal, i.e., $\sigma^{2} = \sigma_{1}^{2} = \cdots = \sigma_{k}^{2}$.</description></item><item><title>One-way Analysis of Variance</title><link>https://freshrimpsushi.github.io/en/posts/2667/</link><pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2667/</guid><description>Hypothesis Testing 1 In the experimental design where there are $k$ treatments, suppose that we obtain $n_{j}$ samples from each treatment for a total of $n = n_{1} + \cdots + n_{k}$ samples. Assume that the samples from the $j = 1 , \cdots , k$-th treatment are independent and randomly follow a normal distribution with $N \left( \mu_{j} , \sigma_{j}^{2} \right)$, and that the population variance of each normal</description></item><item><title>F-test in Analysis of Variance</title><link>https://freshrimpsushi.github.io/en/posts/2665/</link><pubDate>Mon, 16 Jun 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2665/</guid><description>Hypothesis Testing 1 Assume that there are $k$ treatments in experimental design, and that in each treatment there are $n_{j}$ samples, totaling $n = n_{1} + \cdots + n_{k}$ samples. Assume that each sample in the $j = 1 , \cdots , k$th treatment is independently and randomly drawn from a normal distribution $N \left( \mu_{j} , \sigma_{j}^{2} \right)$, and their population variance is equal such that $\sigma^{2} = \sigma_{1}^{2}</description></item><item><title>ANOVA Table</title><link>https://freshrimpsushi.github.io/en/posts/2663/</link><pubDate>Thu, 12 Jun 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2663/</guid><description>Definition 1 A table summarizing the results from analysis of variance (ANOVA) is called an ANOVA table. The format of the ANOVA table may vary slightly depending on the experimental design. Completely Randomized Design Source df SS MS F Treatments $k-1$ SST MST MST/MSE Error $n-k$ SSE MSE Total $n-1$ TSS Randomized Block Design Source df SS MS F Treatments $k-1$ SST MST MST/MSE Blocks $b-1$ SSB MSB Error $(k-1)(b-1)$</description></item><item><title>What is Analysis of Variance or ANOVA in Statistics?</title><link>https://freshrimpsushi.github.io/en/posts/2661/</link><pubDate>Sun, 08 Jun 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2661/</guid><description>Definition 1 2 Analyzing variance to compare the population means of two or more groups is called analysis of variance, and it&amp;rsquo;s often abbreviated as ANOVA. Explanation Intuitively, one might think that comparing the sample means would suffice to compare population means, but in the realm of statistics, simply comparing numerical values has little significance. Mean of A Mean of B 0.0142 0.0271 For example, consider the histograms of samples</description></item><item><title>Experimental Design in Statistics</title><link>https://freshrimpsushi.github.io/en/posts/2659/</link><pubDate>Wed, 04 Jun 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2659/</guid><description>Definition 1 The subject on which measurement or observation is performed is known as an experimental unit. The independent variable manipulated and varied by the experimenter is referred to as a factor. The intensity at which a factor is set is called a level. The combination of levels of factors is termed as a treatment. The dependent variable measured by the experimenter is called a response. Completely Randomized Design 2</description></item><item><title>Estimation of Population Variance for Normally Distributed Groups</title><link>https://freshrimpsushi.github.io/en/posts/2657/</link><pubDate>Sat, 31 May 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2657/</guid><description>Hypothesis Testing 1 Assume the distribution of a population with a sample size of $n$ follows a normal distribution $N \left( \mu , \sigma^{2} \right)$. The hypothesis test for the candidate $\sigma_{0}$ of the population variance is as follows. $H_{0}$: $\sigma^{2} = \sigma_{0}^{2}$ $H_{1}$: $\sigma^{2} \neq \sigma_{0}^{2}$ Test Statistic The test statistic for the sample variance $S^{2}$ is as follows. $$ \mathcal{X}^{2} = \frac{ \left( n - 1 \right) S^{2}</description></item><item><title>Test of Homogeneity of Population</title><link>https://freshrimpsushi.github.io/en/posts/894/</link><pubDate>Thu, 03 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/894/</guid><description>Hypothesis Testing 1 Assume that the categories in multinomial experiments are obtained from $R$ populations, each with $C$ categorical data. When the probability that an element in the $i = 1 , \cdots , R$-th population falls into the $j = 1 , \cdots , C$-th category is $p_{ij}$, denote the proportion vector of the $i$-th population as $\mathbf{p}_{i} = \left( p_{i1} , \cdots , p_{iC} \right)$. The following hypothesis</description></item><item><title>Test of Independence</title><link>https://freshrimpsushi.github.io/en/posts/882/</link><pubDate>Sun, 30 Mar 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/882/</guid><description>Hypothesis Testing 1 In a multinomial experiment, assume we have categorical data with two characteristics $X$ and $Y$, where $X$ has $R$ categories and $Y$ has $C$ categories obtained from $n$ independent trials. The following hypothesis test using the Pearson chi-square test statistic is called the test of independence. $H_{0}$: The two categories are independent. $H_{1}$: The two categories are dependent. Test Statistic The test statistic is the Pearson chi-square</description></item><item><title>Fitness Test of a group</title><link>https://freshrimpsushi.github.io/en/posts/2491/</link><pubDate>Tue, 12 Dec 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2491/</guid><description>Hypothesis Testing 1 Given categorical data obtained from $n$ independent trials in a multinomial experiment where $k$ categories are each theoretically drawn with a probability of $p_{j} &amp;gt; 0$, the following hypothesis test using the Pearson&amp;rsquo;s chi-square test statistic is known as a goodness of fit test. $H_{0}$: The given data has been sampled to conform to the theoretical probabilities. $H_{1}$: The given data has not been sampled to conform</description></item><item><title>Polynomial Experiments and Contingency Tables</title><link>https://freshrimpsushi.github.io/en/posts/2489/</link><pubDate>Fri, 08 Dec 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2489/</guid><description>Definition 1 Multinomial Experiment An experiment that has the following characteristics and has three or more possible outcomes or categories is called a Multinomial Experiment. It consists of $n$ identical trials. Each trial&amp;rsquo;s outcome is one of $k&amp;gt;2$ possible outcomes or categories. Each trial is independent. The probabilities of various outcomes remain constant throughout the trials. Contingency Table When there is information about more than one variable for an element,</description></item><item><title>Pearson Chi-Square test statistic</title><link>https://freshrimpsushi.github.io/en/posts/2487/</link><pubDate>Mon, 04 Dec 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2487/</guid><description>Definition 1 Consider a multinomial experiment where $k$ categories are drawn each with a probability of $p_{j} &amp;gt; 0$, and we obtain categorical data from $n$ independent trials. The frequency of data belonging to the $j$-th category $O_{j}$ is termed the observed cell count, while the expected value under the null hypothesis of hypothesis testing $E_{j}$ is called the expected cell count. The test statistic $$ \mathcal{X}^{2} := \sum_{j=1}^{k} {{</description></item><item><title>Small-Sample Hypothesis Testing for the Difference Between Two Population Means</title><link>https://freshrimpsushi.github.io/en/posts/2476/</link><pubDate>Sun, 12 Nov 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2476/</guid><description>Hypothesis Testing 1 Assume that two independent populations, each following a normal distribution $N \left( \mu_{1} , \sigma_{1}^{2} \right)$ and $N \left( \mu_{2} , \sigma_{2}^{2} \right)$ with $\sigma_{1}^{2} = \sigma^{2} = \sigma_{2}^{2}$, i.e., the population variances are unknown but assumed to be equal. When the samples are small, meaning the number of samples is $n_{1} , n_{2} &amp;lt; 30$, the hypothesis testing for the difference between two population means $D_{0}$</description></item><item><title>Hypothesis Testing for the Population Mean with a Small Sample</title><link>https://freshrimpsushi.github.io/en/posts/2474/</link><pubDate>Wed, 08 Nov 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2474/</guid><description>Hypothesis Testing 1 Assuming the population distribution follows a normal distribution $N \left( \mu , \sigma^{2} \right)$ but the population variance $\sigma^{2}$ is unknown. When the sample size is $n &amp;lt; 30$, a small sample, the hypothesis test about the candidate $\mu_{0}$ for the population mean proceeds as follows. $H_{0}$: $\mu = \mu_{0}$. That is, the population mean is $\mu_{0}$. $H_{1}$: $\mu \ne \mu_{0}$. That is, the population mean is</description></item><item><title>Large Sample Hypothesis Testing for the Difference Between Two Population Means</title><link>https://freshrimpsushi.github.io/en/posts/2468/</link><pubDate>Fri, 27 Oct 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2468/</guid><description>Hypothesis Testing 1 Let&amp;rsquo;s say two independent populations follow distributions $\left( \mu_{1} , \sigma_{1}^{2} \right)$ and $\left( \mu_{2} , \sigma_{2}^{2} \right)$, respectively. In the case of a large sample, meaning the sample size is $n_{1} , n_{2} &amp;gt; 30$, the hypothesis test about the difference between the two population means against candidate $D_{0}$ is as follows: $H_{0}$: $\mu_{1} - \mu_{2} = D_{0}$. That is, the difference in population means is</description></item><item><title>Hypothesis Testing for Population Mean</title><link>https://freshrimpsushi.github.io/en/posts/2466/</link><pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2466/</guid><description>Hypothesis Testing 1 Suppose the population distribution follows $\left( \mu , \sigma^{2} \right)$. When the sample is a large sample, i.e., when the number of samples is $n &amp;gt; 30$, the hypothesis testing for the candidate of population mean $\mu_{0}$ is as follows: $H_{0}$: $\mu = \mu_{0}$. That is, the population mean is $\mu_{0}$. $H_{1}$: $\mu \ne \mu_{0}$. That is, the population mean is not $\mu_{0}$. test statistic The test</description></item><item><title>Simplified Definition of Hypothesis Testing</title><link>https://freshrimpsushi.github.io/en/posts/2442/</link><pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2442/</guid><description>Definition 1 2 In science, a statistical hypothesis refers to an assumption about a population, and the statistical decision-making process of accepting or rejecting this hypothesis is called statistical hypothesis testing. This process involves two competing hypotheses, where the hypothesis that the researcher wishes to support is called the alternative hypothesis $H_{1}$, and the hypothesis accepted when there is no substantial evidence to claim that the alternative hypothesis is true</description></item><item><title>McLeod-Li Test</title><link>https://freshrimpsushi.github.io/en/posts/1279/</link><pubDate>Sat, 07 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1279/</guid><description>Hypothesis Testing Given the time series data returns $\left\{ r_{t} \right\}$, let&amp;rsquo;s assume: $H_{0}$: The data does not exhibit autoregressive conditional heteroscedasticity (ARCH) effect at lag $k$. $H_{1}$: The data exhibits ARCH effect at lag $k$. Explanation McLeod-Li Test is used to check for ARCH effects in the given returns. Code Practice Fortunately, in R, the TSA package’s McLeod.Li.test() function allows for</description></item><item><title>Run-Test</title><link>https://freshrimpsushi.github.io/en/posts/1219/</link><pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1219/</guid><description>Hypothesis Testing Let us denote the ARMA model obtained from time series analysis as $ARMA(p,q)$ to be $M$. $H_{0}$: $M$ is fit. $H_{1}$: $M$ is not fit. Explanation The Ljung-Box Test, also abbreviated as LBQ, is a test for determining the goodness-of-fit of an ARIMA model. In 1970, Box and Pierce proposed the following test statistic $Q$, through the sACF $\hat{r}_{1} , \cdots , \widehat{r}_{k}$ of residuals obtained from ARIMA</description></item><item><title>Durbin-Watson Test</title><link>https://freshrimpsushi.github.io/en/posts/1217/</link><pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1217/</guid><description>Hypothesis Testing After performing a regression analysis, let&amp;rsquo;s assume we are given a residual $\left\{ e_{t} \right\}_{t=1}^{n}$ and express it as $e_{t} := \rho e_{t-1} + \nu_{t}$. $H_{0}$: $\rho = 0$ i.e., the residuals do not exhibit autocorrelation. $H_{1}$: $\rho \ne 0$ i.e., the residuals exhibit autocorrelation. Explanation Empirical Interpretation The Durbin-Watson test is used to check the independence of residuals after regression analysis, determining whether or not the residuals</description></item><item><title>Box-Cox Transformation</title><link>https://freshrimpsushi.github.io/en/posts/1065/</link><pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1065/</guid><description>Buildup $x &amp;gt; 0$ is referred to as a Box-Cox transformation on $g(x) := \begin{cases} \displaystyle {{ x^{\lambda} - 1 } \over { \lambda }} &amp;amp; , \lambda \ne 0 \\ \log x &amp;amp; , \lambda = 0 \end{cases}$. $g$, originally known as Power Transformation, was introduced by Box and Cox, hence it is also called the Box-Cox transformation. The main uses of the Box-Cox transformation are to make data</description></item><item><title>Dickey-Fuller Test</title><link>https://freshrimpsushi.github.io/en/posts/921/</link><pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/921/</guid><description>Hypothesis Testing Given that we have time series data eq1. eq2: The data eq1 does not have stationarity. eq4: The data eq1 has stationarity. Explanation The Dickey-Fuller test is a hypothesis test used to determine whether time series data has stationarity or not. If it does not have stationarity, differencing must be used to make the mean constant. It is important to note that this diagnosis only occurs for the</description></item><item><title>Jarque–Bera test Test</title><link>https://freshrimpsushi.github.io/en/posts/949/</link><pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/949/</guid><description>Hypothesis Testing Given that we have quantitative data $\left\{ x_{i} \right\}_{i = 1}^{n}$. $H_{0}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ follows a normal distribution. $H_{1}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ does not follow a normal distribution. Explanation The Jarque-Bera test is used to test for normality as a hypothesis test, typically to demonstrate the presence of normality. This is one of the rare cases where the acceptance of the</description></item><item><title>Shapiro-Wilk Test</title><link>https://freshrimpsushi.github.io/en/posts/939/</link><pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/939/</guid><description>Hypothesis Testing Given quantitative data $\left\{ x_{i} \right\}_{i = 1}^{n}$. $H_{0}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ follows a normal distribution. $H_{1}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ does not follow a normal distribution. Description The Shapiro-Wilk test is a hypothesis test used to assess the normality of data, usually to demonstrate that normality is present. It&amp;rsquo;s one of the rare occasions where having the null hypothesis accepted matches &amp;rsquo;the</description></item><item><title>Hosmer-Lemeshow Goodness of Fit Test</title><link>https://freshrimpsushi.github.io/en/posts/852/</link><pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/852/</guid><description>Hypothesis Testing Let&amp;rsquo;s refer to the model obtained through logistic regression as $M$. $H_{0}$: $M$ is appropriate. $H_{1}$: $M$ is not appropriate. Description The Hosmer-Lemeshow goodness of fit test is a representative hypothesis test used to determine the adequacy of logistic regression models. Although it&amp;rsquo;s a very simple test, the null hypothesis and the alternative hypothesis can be confusing. While it’s true that there is no good</description></item><item><title>F-test for Regression Coefficients</title><link>https://freshrimpsushi.github.io/en/posts/672/</link><pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/672/</guid><description>Hypothesis Testing Assuming in the model diagnostics of the linear multiple regression model, the residuals satisfy linearity, homoscedasticity, independence, and normality. The hypothesis testing for the multiple regression analysis with $n$ observations and $p$ independent variables is as follows: $H_{0}$: $\beta_{1} = \beta_{2} = \cdots = \beta_{p} = 0$ i.e., all independent variables do not have a correlation with the dependent variable. $H_{1}$: At least one among $\beta_{1} , \beta_{2}</description></item><item><title>Regression Coefficient's t-test</title><link>https://freshrimpsushi.github.io/en/posts/654/</link><pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/654/</guid><description>Hypothesis Testing $$ \begin{bmatrix} y_{1} \\ y_{2} \\ \vdots \\ y_{n} \end{bmatrix} = \begin{bmatrix} 1 &amp;amp; x_{11} &amp;amp; \cdots &amp;amp; x_{p1} \\ 1 &amp;amp; x_{12} &amp;amp; \cdots &amp;amp; x_{p2} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 1 &amp;amp; x_{1n} &amp;amp; \cdots &amp;amp; x_{pn} \end{bmatrix} \begin{bmatrix} \beta_{0} \\ \beta_{1} \\ \vdots \\ \beta_{p} \end{bmatrix} + \begin{bmatrix} \varepsilon_{1} \\ \varepsilon_{2} \\ \vdots \\ \varepsilon_{n} \end{bmatrix} $$ When independent variables of</description></item><item><title>Easy Definition of P-Value or Significance Probability</title><link>https://freshrimpsushi.github.io/en/posts/537/</link><pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/537/</guid><description>Definition 1 The probability of rejecting the null hypothesis in hypothesis testing is called the p-value. Explanation If the p-value is lower than the significance level, it is considered that the null hypothesis has been rejected. A small p-value under the null hypothesis can be understood as &amp;rsquo;the evidence against the null hypothesis is too strong to be attributed to chance.' When terms like power curve or rejection region are</description></item><item><title>Rejection Region and Significance Level</title><link>https://freshrimpsushi.github.io/en/posts/509/</link><pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/509/</guid><description>Definition 1 The error of rejecting the null hypothesis when it is actually true is called a Type I error. The error of failing to reject the null hypothesis when the alternative hypothesis is true is called a Type II error. The maximum probability of committing a Type I error is called the Significance Level. The statistic used for hypothesis testing is called the test statistic. The region of the</description></item><item><title>Type I and Type II Errors Difference</title><link>https://freshrimpsushi.github.io/en/posts/508/</link><pubDate>Sat, 07 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/508/</guid><description>Definition In hypothesis testing, an error of not accepting $H_{0}$ when $H_{0}$ is true is called a Type 1 Error, and an error of accepting $H_{0}$ when $H_{0}$ is false is called a Type 2 Error. Explanation We use the term &amp;lsquo;accept&amp;rsquo; for the null hypothesis and &amp;lsquo;reject&amp;rsquo; for the alternative hypothesis. If there is sufficient evidence supporting the null hypothesis, it means &amp;lsquo;rejecting the alternative hypothesis and accepting the</description></item><item><title>How to Set the Null Hypothesis and Alternative Hypothesis</title><link>https://freshrimpsushi.github.io/en/posts/500/</link><pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/500/</guid><description>Description Hypothesis Testing: Null Hypothesis $H_{0}$ vs Alternative Hypothesis $H_{1}$ As of April 2018, some textbooks and Wikipedia describe the null hypothesis as &amp;rsquo;the hypothesis that is initially assumed to be rejected in statistics&amp;rsquo;, and the alternative hypothesis as &amp;rsquo;the hypothesis that one hopes or expects to prove through research&amp;rsquo;. However, if you only study the necessary parts of statistics or lightly know about it, that might be fine, but</description></item></channel></rss>