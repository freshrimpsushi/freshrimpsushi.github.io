<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Odinary Differential Equations on FreshrimpRestaurant</title><link>https://freshrimpsushi.github.io/en/categories/%EC%83%81%EB%AF%B8%EB%B6%84%EB%B0%A9%EC%A0%95%EC%8B%9D/</link><description>Recent content in Odinary Differential Equations on FreshrimpRestaurant</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 21 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/en/categories/%EC%83%81%EB%AF%B8%EB%B6%84%EB%B0%A9%EC%A0%95%EC%8B%9D/index.xml" rel="self" type="application/rss+xml"/><item><title>Picard's Theorem</title><link>https://freshrimpsushi.github.io/en/posts/3057/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3057/</guid><description>Buildup1 Consider the following ODE system. $$ \begin{equation} \begin{aligned} x_{1}^{\prime}(t) =&amp;amp;\ F_{1}(t,x_{1},x_{2},\cdots,x_{n}) \\ x_{2}^{\prime}(t) =&amp;amp;\ F_{2}(t,x_{1},x_{2},\cdots,x_{n}) \\ \vdots &amp;amp; \\ x_{n}^{\prime}(t) =&amp;amp;\ F_{n}(t,x_{1},x_{2},\cdots,x_{n}) \end{aligned} \end{equation} $$ Assume the values of $x_{i}$ are as follows when $t=t_{0}$. $$ \begin{equation} x_{1}(t_{0}) = x_{1}^{0}, x_{2}(t_{0}) = x_{2}^{0}, \dots, x_{n}(t_{0}) = x_{n}^{0} \end{equation} $$ Combining $(1)$ and $(2)$ into an initial value problem of a system of first-order differential equations, and finding the solution</description></item><item><title>Solution of Differential Equations Using Series Solutions</title><link>https://freshrimpsushi.github.io/en/posts/888/</link><pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/888/</guid><description>Description Differential equations with constant coefficients can be relatively easily solved using methods such as separation of variables or integrating factor method. However, differential equations with coefficients that include the independent variable, as shown below, cannot be easily solved. $$ \begin{equation} P(x)\dfrac{d^2 y}{dx^2} + Q(x)\dfrac{dy}{dx}+R(x)y=0 \label{1}\end{equation} $$ Here, $P$, $Q$, and $R$ are assumed to be polynomials without common factors. Equations of the above form include Bessel&amp;rsquo;s equation $$ x^2</description></item><item><title>First-Order Linear Differential Equation System</title><link>https://freshrimpsushi.github.io/en/posts/1659/</link><pubDate>Thu, 11 Jun 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1659/</guid><description>Buildup1 When the mass is $m$, the damping factor is $\gamma$, and the spring constant is $k$, the equation of motion representing the vibration of an object hung on a spring is as follows. $$ m x^{\prime \prime} + \gamma x^{\prime} + kx = F $$ Letting $x_{1}=x$, $x_{2}=x_{1}^{\prime}$, the above equation of motion can be expressed as the following system. $$ \begin{align*} x_{1}^{\prime}(t) =&amp;amp;\ x_{2}(t) \\ x_{2}^{\prime} (t) =&amp;amp;\</description></item><item><title>Series Solution of Laguerre Differential Equation</title><link>https://freshrimpsushi.github.io/en/posts/1651/</link><pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1651/</guid><description>Definition The following differential equation is referred to as the Laguerre differential equation. $$ xy^{\prime \prime}+(1-x)y^{\prime}+ny=0,\quad n=0,1,2,\cdots $$ Description The solution to the Laguerre differential equation is called Laguerre polynomials, and the first few Laguerre polynomials are as follows. $$ \begin{align*} L_{0}(x) &amp;amp;= 1 \\ L_{1}(x) &amp;amp;= -x+1 \\ L_{2}(x) &amp;amp;= \frac{1}{2}\left( x^{2}-4x+2 \right) \\ L_{3}(x) &amp;amp;= \frac{1}{6}\left( -x^{3}+9x^{2}-18x+6 \right) \\ \vdots &amp;amp; \end{align*} $$ Examining the equation to solve</description></item><item><title>Hermite Differential Equations and Series Solutions</title><link>https://freshrimpsushi.github.io/en/posts/1650/</link><pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1650/</guid><description>Definition The differential equation given below is referred to as the Hermite Differential Equation. $$ y^{\prime \prime}-2xy^{\prime}+2ny=0,\quad n=0,1,2,\cdots $$ The solution to the Hermite Differential Equation is called the Hermite Polynomial, and it is commonly denoted as $H_{n}(x)$. $$ \begin{align*} H_{0}(x) &amp;amp;= 1 \\ H_{1}(x) &amp;amp;= 2x \\ H_{2}(x) &amp;amp;= 4x^{2} - 2 \\ H_{3}(x) &amp;amp;= 8x^{3} - 12x \\ H_{4}(x) &amp;amp;= 16x^{4} - 48x^{2} + 12 \\ H_{5}(x) &amp;amp;=</description></item><item><title>Series Solutions to the Airy Differential Equation</title><link>https://freshrimpsushi.github.io/en/posts/1625/</link><pubDate>Thu, 21 May 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1625/</guid><description>Definition The following differential equation is called the Airy differential equation. $$ y^{\prime \prime}-xy=0,\quad -\infty&amp;lt;x&amp;lt;\infty $$ Explanation The name originates from the British astronomer George Biddell Airy. It is also called the Stokes equation. Solution Since the coefficient of $y^{\prime \prime}$ is $1$, all points are ordinary points. Among them, let&amp;rsquo;s find the power series solution around $x=0$. Assume that the solution of the Airy equation is as follows and</description></item><item><title>Bessel Functions as Solutions to Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/1620/</link><pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1620/</guid><description>Theorem1 Theorem 1 Given a differential equation slightly different from the Bessel equation as follows: $$ \begin{equation} \begin{aligned} &amp;amp;&amp;amp; y^{\prime \prime}+\frac{1-2a}{x}y^{\prime}+\left[ (bcx^{c-1})^{2}+\frac{a^{2}-\nu^{2}c^{2}}{x^{2}} \right]y =&amp;amp;\ 0 \\ \text{or} &amp;amp;&amp;amp; x^{2}y^{\prime \prime}+(1-2a)xy^{\prime}+\left[ b^{2}c^{2}x^{2c}+(a^{2}-\nu^{2}c^{2}) \right]y =&amp;amp;\ 0 \end{aligned} \label{1} \end{equation} $$ And let $Z_{\nu}(x)$ be any linear combination of $J_{\nu}(x)$ and $N_{\nu}(x)$. Then, the solution to the given differential equation is as follows: $$ y=x^{a}Z_{\nu}(bx^{c})=x^{a}[AJ_{\nu}(bx^{c})+BN_{\nu}(bx^{c})] $$ $\nu$, $a$, $b$, $c$, $A$, $B$ are</description></item><item><title>Associated Legendre Differential Equations and Polynomials</title><link>https://freshrimpsushi.github.io/en/posts/1605/</link><pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1605/</guid><description>Definition1 The differential equation given below is called the associated Legendre differential equation. $$ \begin{equation} \begin{aligned} &amp;amp;&amp;amp;(1-x^{2})\frac{ d^{2}y }{ dx^{2} }-2x \frac{dy}{dx}+\left[ +l(l+1)-\frac{m^{2}}{1-x^{2}} \right]y =&amp;amp;\ 0 \\ \mathrm{or} &amp;amp;&amp;amp; \frac{ d }{ dx } \left[ (1-x^{2})y^{\prime} \right] +\left[ l(l+1)-\frac{m^{2}}{1-x^{2}} \right]y =&amp;amp;\ 0 \end{aligned} \label{1} \end{equation} $$ The solution to the associated Legendre differential equation is denoted as $P_{l}^{m}(x)$, and this is called the associated Legendre polynomial or the generalized Legendre</description></item><item><title>Solutions to Euler's Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/1599/</link><pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1599/</guid><description>Definition The differential equation of the following form is called the Euler differential equation or Euler-Cauchy equation. $$ \begin{equation} a_{2}x^{2}\frac{ d ^{2 }y}{ dx^{2} }+a_{1}x\frac{ d y}{ d x }+a_{0}y=0 \end{equation} $$ Explanation For a non-homogeneous equation where the right side is not $0$, it can be solved by substituting it with $x=e^{z}$. Solution For convenience of calculation, both sides of $(1)$ are divided by $a_{2}$, and let&amp;rsquo;s call the</description></item><item><title>Trigonometric Form of the Legendre Differential Equation</title><link>https://freshrimpsushi.github.io/en/posts/1537/</link><pubDate>Fri, 21 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1537/</guid><description>Definition The associated Legendre differential equation in the form of a trigonometric function is as follows. $$ \begin{align} \frac{ d^{2} y}{ d \theta^{2} }+\cot \theta \frac{ d y}{ d \theta}+ \left( l(l+1) -\frac{m^{2}}{\sin ^{2 }\theta} \right)y=0 \\ \mathrm{or} \quad\frac{1}{\sin \theta}\left(\sin \theta \frac{dy}{d\theta} \right)+ \left(l(l+1) -\frac{ m^{2}}{\sin ^{2} \theta} \right)y=0 \end{align} $$ Explanation Useful for solving spherical coordinate Laplace&amp;rsquo;s equation in electromagnetics, quantum mechanics, etc. The solutions are as follows. $$</description></item><item><title>Frobenius Method</title><link>https://freshrimpsushi.github.io/en/posts/1508/</link><pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1508/</guid><description>Explanation1 There are various methods to solve differential equations. One of them involves assuming the solution as a power series, as follows. $$ y=\sum \limits_{n=0}^{\infty} a_{n}x^{n} $$ However, some series cannot be represented in the form above. For example, as follows. $$ \frac{\cos x}{x^{2}}=\frac{1}{x^{2}}-\frac{1}{2!}+\frac{ x^{2}}{4!}-\cdots $$ $$ \sqrt{x} \sin x = x^{\frac{1}{2}}\left( x - \frac{x^{3}}{3!}+\cdots \right) $$ In such cases, the solution is assumed to be in the following form.</description></item><item><title>Series Solution of the Bessel Equation: Bessel Functions of the First Kind</title><link>https://freshrimpsushi.github.io/en/posts/1503/</link><pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1503/</guid><description>Definition1 For $\nu \in \mathbb{R}$, a differential equation of the following form is called a $\nu$ order Bessel equation. $$ \begin{align*} &amp;amp;&amp;amp; x^{2} y^{\prime \prime} +xy^{\prime}+(x^{2}-\nu^{2})y &amp;amp;= 0 \\ \text{or} &amp;amp;&amp;amp; y^{\prime \prime}+\frac{1}{x} y^{\prime} + \left( 1-\frac{\nu^{2}}{x^{2}} \right)y &amp;amp;= 0 \end{align*} $$ Explanation The Bessel equation emerges when solving the wave equation in spherical coordinates. The coefficients are not constant but depend on the independent variable $x$. Since, at $x=0$,</description></item><item><title>Ordinary Differential Equation</title><link>https://freshrimpsushi.github.io/en/posts/1097/</link><pubDate>Fri, 24 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1097/</guid><description>Definition1 For the univariate function $u(t)$, the following form is called an ordinary differential equation (ODE). $$ F(t, u(t), u^{\prime}(t), \dots, u^{(n)}(t)) = 0 \tag{1} $$ Here, $u^{\prime}$ is the derivative of $u$, and $u^{(n)}$ is the $n$-th order derivative of $u$, or simply referred to as $y = u(t)$, $$ F(t, y, y^{\prime}, \dots, y^{(n)}) = 0 $$ Explanation In $(1)$, $n$ is referred to as the order of</description></item><item><title>Laplace Transform Convolution</title><link>https://freshrimpsushi.github.io/en/posts/1170/</link><pubDate>Thu, 04 Jul 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1170/</guid><description>Definitions1 Let&amp;rsquo;s call $\mathcal{L}$ the Laplace transform. The function $f*g$ that satisfies the following expression is called the convolution with respect to the Laplace transforms of $f$ and $g$. $$ \mathcal{L}(f*g) = \mathcal{L}(f) \cdot \mathcal{L}(g) $$ Theorem The convolution of $f$ and $g$ with respect to their Laplace transforms $h=f*g$ is as follows. $$ h(t) = f*g(t) = \int_{0}^t f(t-\tau)g(\tau)d\tau = \int_{0}^t f(\tau) g(t-\tau)d\tau $$ Proof $$ \begin{align*} \mathcal{L} \left\{</description></item><item><title>Wronskian of Two Solutions of a Second Order Linear Differential Equation</title><link>https://freshrimpsushi.github.io/en/posts/965/</link><pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/965/</guid><description>Theorem 1 Suppose $y_{1}$ and $y_{2}$ are solutions to the second-order linear differential equation $y^{\prime \prime}+p(t)y^{\prime}+q(t)y=0$. Then, The Wronskian of $y_{1}$ and $y_{2}$ is expressed in the form of an exponential function. $$ W [y_{1}, y_{2}] (t)=c e^{-\int p(t) dt} $$ Where $c$ is a constant that depends on $y_{1},\ y_{2}$. $W[y_{1},y_{2}] (t)$ is either always $0$ or never $0$ at all points. Explanation Also known as Abel&amp;rsquo;s theorem. Although</description></item><item><title>Chebyshev Differential Equations and Chebyshev Polynomials</title><link>https://freshrimpsushi.github.io/en/posts/956/</link><pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/956/</guid><description>Definition The following differential equation is referred to as the Chebyshev Differential Equation. $$ \begin{equation} (1-x^2)\dfrac{d^2 y}{dx^2} -x\dfrac{dy}{dx}+n^2 y=0 \label{def1} \end{equation} $$ The solution to the Chebyshev differential equation is known as Chebyshev polynomials, commonly denoted by $T_{n}(x)$. The general term of $T_{n}(x)$ is as follows: When $n$ is even $$ 1-\dfrac{\lambda^2}{2!}x^2+\dfrac{\lambda^2(\lambda^2-2^2)}{4!}x^4+\sum \limits_{m=3}^\infty (-1)^m \dfrac{\lambda^2(\lambda^2-2^2)\cdots(\lambda^2-(2m-2)^2)}{(2m)!} x^{2m} $$ When $n$ is odd $$ x-\dfrac{\lambda^2-1^2}{3!}x^3+\dfrac{(\lambda^2-1^2)(\lambda^2-3^2)}{5!}x^5+\sum \limits_{m=3}^\infty (-1)^m\dfrac{(\lambda^2-1^2)(\lambda^2-3^2) \cdots (\lambda^2-(2m-1)^2)}{(2m+1)!} x^{2m+1} $$ Especially,</description></item><item><title>Series Solution of Chebyshev Differential Equation</title><link>https://freshrimpsushi.github.io/en/posts/955/</link><pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/955/</guid><description>Definition The following differential equation is referred to as the Chebyshev Differential Equation: $$ (1-x^2)\dfrac{d^2 y}{dx^2} -x\dfrac{dy}{dx}+n^2 y=0 $$ Description It&amp;rsquo;s a form that includes the independent variable $x$ in the coefficient, and assuming that the solution is in the form of a power series, it can be solved. The solution to the Chebyshev equation is called the Chebyshev polynomial, often denoted as $T_{n}(x)$. Solution $$ \begin{equation} (1-x^2)y^{\prime \prime} -xy^{\prime}+\lambda^2</description></item><item><title>Existence and Uniqueness of Solutions for Initial Value Problems of First-Order Ordinary Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/892/</link><pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/892/</guid><description>Theorem1 Let $E$ be open in $\mathbb{R}^{n}$ and given the following initial value problem concerning $f \in C^{1} (E)$ and $\phi_{0} \in E$. $$ \begin{cases} \dot{ \phi } = \mathbf{f} ( \phi ) \\ \phi (0) = \phi_{0} \end{cases} $$ Then, there exists a unique solution $\phi (t)$ to the given initial value problem in some interval $[-h,h] \subset \mathbb{R}$. $C^{1}$ is a set of functions with continuous derivatives. Proof</description></item><item><title>Picard Method</title><link>https://freshrimpsushi.github.io/en/posts/881/</link><pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/881/</guid><description>Theorem1 If $E$ is open in $\mathbb{R}^{n}$ and the following initial value problem is given for $f \in C^{1} (E)$, $$ \begin{cases} \dot{ \phi } = f ( \phi ) \\ \phi (0) = \phi_{0} \end{cases} $$ let&amp;rsquo;s define the sequence of functions $\left\{ u_{k} (t) \right\} _{ k =0}^{ \infty }$ as follows. $$ \begin{cases} u_{0} (t) = \phi_{0} \\ u_{k+1} (t) = \phi_{0} + \int_{0}^{t} f \left( u_{k}</description></item><item><title>Series Solution of Legendre Differential Equation: Legendre Polynomial</title><link>https://freshrimpsushi.github.io/en/posts/889/</link><pubDate>Mon, 11 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/889/</guid><description>Definition1 The following differential equation is called the Legendre differential equation. $$ (1-x^2)\dfrac{d^2 y}{dx^2} -2x\dfrac{dy}{dx}+l(l+1) y=0 $$ The solution to the Legendre differential equation is called the Legendre polynomial, commonly denoted as $P_{l}(x)$. The first few Legendre polynomials according to $l$ are as follows. $$ \begin{align*} P_{0}(x) =&amp;amp;\ 1 \\ P_{1}(x) =&amp;amp;\ x \\ P_2(x) =&amp;amp;\ \dfrac{1}{2}(3x^2-1) \\ P_{3}(x) =&amp;amp;\ \dfrac{1}{2}(5x^3-3x) \\ P_{4}(x) =&amp;amp;\ \dfrac{1}{8}(35x^4-30x^2+3) \\ P_{5}(x) =&amp;amp;\ \dfrac{1}{8}(63x^5-70x^3+15x) \\</description></item><item><title>Solving Nonhomogeneous Euler Differential Equations Using Substitution</title><link>https://freshrimpsushi.github.io/en/posts/871/</link><pubDate>Wed, 30 Jan 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/871/</guid><description>Definition The differential equation given as follows is called the Euler differential equation. $$ \begin{align} &amp;amp;&amp;amp; a_2 x^2 \dfrac{d^2 y}{d x^2} + a_{1} x \dfrac{dy}{dx} + a_{0} y &amp;amp;= f(x) \label{eq1} \\ \mathrm{or}&amp;amp;&amp;amp; a_2 x^2 y^{\prime \prime} + a_{1} x y^{\prime} +a_{0} y &amp;amp;= f(x) \nonumber \\ \mathrm{or}&amp;amp;&amp;amp; x^2 y^{\prime \prime} + \alpha x y^{\prime} + \beta y &amp;amp;= f(x) \nonumber \end{align} $$ Explanation It is also referred to as</description></item><item><title>Laplace Transform of Periodic Functions</title><link>https://freshrimpsushi.github.io/en/posts/773/</link><pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/773/</guid><description>Formulas Let $f$ be a periodic function with period $T$. Then $f(t+T)=f(t)$ and the Laplace transform of $f(t)$ is as follows. $$ \mathcal{L} \left\{ f(t) \right\} = \int_{0}^\infty e^{-st}f(t)dt = \frac{\displaystyle \int_{0}^T e^{-st}f(t)dt}{1-e^{-st}} $$ Derivation From the definition of Laplace transform, split the integral like this. $$ \int_{0}^\infty e^{-st}f(t)dt = \int_{0}^T e^{-st}f(t)dt + \int_{T}^{2T} e^{-st}f(t)dt + \int_{2T}^{3T}e^{-st}f(t)dt + \cdots $$ At this point, to make the integration range of the</description></item><item><title>Laplace Transform of the Dirac Delta Function</title><link>https://freshrimpsushi.github.io/en/posts/772/</link><pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/772/</guid><description>Theorem1 The Laplace Transform of the Dirac Delta Function is as follows. $$ \mathcal{L} \left\{ \delta (t-t_{0}) \right\} = e^{-st_{0}} $$ Proof Let&amp;rsquo;s define as shown in the picture above $d_\tau (t) = \dfrac{1}{2\tau}$ $-\tau \le t \le \tau$. Then, the limit below is the same as the Dirac Delta Function. $$ \lim \limits_{\tau \to 0^+}d_\tau (t)=\delta (t) \\ \lim \limits_{\tau \to 0^+}d_\tau (t-t_{0})=\delta (t-t_{0}) $$ Thus $\mathcal{L} \left\{ \delta</description></item><item><title>Laplace Transform of t^{n}f(t)</title><link>https://freshrimpsushi.github.io/en/posts/771/</link><pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/771/</guid><description>Formulas Let&amp;rsquo;s say the Laplace transform of the function $f(t)$ is $\mathcal{L} \left\{ f(t) \right\} = \displaystyle \int _{0} ^\infty e^{-st}f(t)dt = F(s)$. Then, the Laplace transform of $t^{n}f(t)$ is as follows. $$ \mathcal{L} \left\{ t^n f(t) \right\} = (-1)^nF^{(n)}(s) $$ Derivation First, the Laplace transform of $t^nf(t)$, by definition, is as follows. $$ \int _{0} ^\infty e^{-st}tf(t) dt $$ If we look closely at the integral, it can be</description></item><item><title>Inverse Laplace Transform of F(as+b)</title><link>https://freshrimpsushi.github.io/en/posts/767/</link><pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/767/</guid><description>공식1 Assuming that the Laplace transform $\mathcal{L} \left\{ f(t) \right\}= \displaystyle \int _{0} ^\infty e^{-st}f(t)dt =F(s)$ of function $f(t)$ exists as $s&amp;gt;\alpha \ge 0$, the inverse Laplace transform of $F(as+b)$ for constant $a&amp;gt;0 , b$ is as follows. $$ \mathcal{L^{-1}} \left\{ F(as+b) \right\} =\frac{1}{a}e^{-\frac{b}{a}t}f\left(\frac{t}{a}\right) $$ Derivation 1 Inverse Laplace transform of $F(ks)$: $$ \mathcal{L^{-1}} \left\{ F(ks) \right\} =\dfrac{1}{k}f\left(\frac{t}{k}\right) $$ Translation of Laplace transform: $$ \mathcal{L^{-1}} \left\{ F(s-c) \right\}=e^{ct}f(t)</description></item><item><title>Inverse Laplace Transform of F(ks)</title><link>https://freshrimpsushi.github.io/en/posts/766/</link><pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/766/</guid><description>Formulas1 Assuming that the Laplace transform $\mathcal{L} \left\{ f(t) \right\} = \displaystyle \int _{0} ^\infty e^{-st}f(t)dt = F(s)$ of the function $f(t)$ exists and is $s&amp;gt;a \ge 0$ for a positive number $k&amp;gt; 0$ then the inverse Laplace transform of $F(ks)$ is as follows. $$ \mathcal{L^{-1}} \left\{ F(ks) \right\} =\dfrac{1}{k}f\left(\frac{t}{k}\right),\quad s&amp;gt;\frac{a}{k} $$ Derivation 1 The Laplace transform of $f(ct)$ $$ \mathcal{L} \left\{ f(ct) \right\} =\dfrac{1}{c}F\left(\dfrac{s}{c}\right), \quad s&amp;gt;ca $$ By substituting</description></item><item><title>Laplace Transform of f(ct)</title><link>https://freshrimpsushi.github.io/en/posts/765/</link><pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/765/</guid><description>Formulas1 Let&amp;rsquo;s assume that the Laplace transform $\mathcal{L} \left\{ f(t) \right\} = \displaystyle \int _{0} ^\infty e^{-st}f(t)dt = F(s)$ of the function $f(t)$ exists and is $s&amp;gt;a \ge 0$. Then, for $c &amp;gt;0$, the Laplace transform of $f(ct)$ is as follows. $$ \mathcal{L} \left\{ f(ct) \right\} =\dfrac{1}{c}F\left(\dfrac{s}{c}\right), \quad s&amp;gt;ca $$ Derivation $$ \mathcal{L} \left\{ f(ct) \right\} = \int _{0} ^\infty e^{-st}f(ct)dt $$ Let&amp;rsquo;s substitute $ct=\tau$. Then, since $st=\dfrac{s}{c}\tau$ and $dt=\dfrac{1}{c}d\tau$,</description></item><item><title>Laplace Transform of the First Order Derivative</title><link>https://freshrimpsushi.github.io/en/posts/760/</link><pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/760/</guid><description>Theorem1 Let&amp;rsquo;s assume the following two conditions. Let function $f(t)$ be continuous on interval $0 \le t \le A$, and let its first derivative $f^{\prime}(t)$ be piecewise continuous. There exists real numbers $a$ and positive numbers $K$, $M$ such that when $t \ge M$, it satisfies $|f(t)| \le Ke^{at}$. Then, the first derivative of $f$&amp;rsquo;s Laplace transform $\mathcal{L} \left\{ f^{\prime}(t) \right\}$ exists when $s&amp;gt;a$ and its value is as follows.</description></item><item><title>Laplace Transform Translation</title><link>https://freshrimpsushi.github.io/en/posts/764/</link><pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/764/</guid><description>Formula1 Assuming the Laplace transform $F(s)=\mathcal{L} \left\{ f(t) \right\}$ of the function $f(t)$ exists as $s&amp;gt;a$. Then, the following holds for constant $c$. $$ \begin{align*} \mathcal{L} \left\{ e^{ct}f(t) \right\}&amp;amp;=F(s-c), &amp;amp;s&amp;gt;a+c \\ \mathcal{L^{-1}} \left\{ F(s-c) \right\}&amp;amp;=e^{ct}f(t) &amp;amp; \end{align*} $$ Explanation This means that multiplying an exponential function to $f$ is equivalent to translating $F$. Derivation $$ \begin{align*} \mathcal{L} \left\{ e^{ct}f(t) \right\} &amp;amp;=\int_{0}^\infty e^{-st}e^{ct}f(t)dt \\ &amp;amp;= \int_{0}^\infty e^{-(s-c)t}f(t)dt \\ &amp;amp;= F(s-c) \end{align*}</description></item><item><title>Solving Second-Order Linear Nonhomogeneous Differential Equations Using Laplace Transforms</title><link>https://freshrimpsushi.github.io/en/posts/763/</link><pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/763/</guid><description>Theorem1 $$ ay^{\prime \prime} + by^{\prime} + cy = g(t) $$ Let us assume that the above second-order linear inhomogeneous differential equation is given. And let&amp;rsquo;s say $\mathcal{L} \left\{ y \right\} =Y(s)$, $\mathcal{L} \left\{ g(t) \right\}=G(s)$. Then, $$ Y(s) = \dfrac{ (as + b)y(0) + ay^{\prime}(0) } {as^2+bs+c} + \dfrac{G(s) }{as^2+bs+c} $$ Explanation The above formula is easy to memorize if you remember the rules well. If you memorize according</description></item><item><title>The Laplace Transform of the n-th Order Derivative</title><link>https://freshrimpsushi.github.io/en/posts/762/</link><pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/762/</guid><description>Theorem1 Assuming the following two conditions: For any interval $0 \le t \le A$, let functions $f$, $f^{\prime}$, $\cdots$, $f^{(n-1)}$ be continuous and let the n-th derivative $f^{(n)}(t)$ be piecewise continuous. When $t \ge M$, there exist real numbers $a$ and positives $K$, $M$ satisfying $|f(t)| \le Ke^{at}$, $|f^{\prime}(t)| \le Ke^{at}$, $\cdots$, and $|f^{(n-1)}(t)| \le Ke^{at}$. Then, the Laplace transform of the n-th derivative of $f$, $\mathcal{L} \left\{ f^{(n)}(t) \right\}$,</description></item><item><title>Definition and Existence Proof of the Laplace Transform</title><link>https://freshrimpsushi.github.io/en/posts/761/</link><pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/761/</guid><description>Definition[^1] The Laplace transform of a function $f$ is defined as follows. $$ \mathcal{L} \left\{ f(t) \right\} := \int _{0}^\infty e^{-st}f(t) dt =F(s) $$</description></item><item><title>Laplace Transform of the Step Function</title><link>https://freshrimpsushi.github.io/en/posts/758/</link><pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/758/</guid><description>Definition1 Let&amp;rsquo;s denote the unit step function unit step function shifted by $c$ as follows: $$ u_{c}(t)=\begin{cases} 0 &amp;amp; t&amp;lt;c \\ 1 &amp;amp; t \ge c \end{cases} $$ Formula The Laplace transform of the step function $u_{c}(t)$ is as follows. $$ \begin{equation} \mathcal{L} \left\{ u_{c}(t) \right\} = \dfrac{e^{-cs}}{s},\quad s&amp;gt;0 \label{eq1} \end{equation} $$ Let&amp;rsquo;s assume that $c$ is an arbitrary constant, and when $s &amp;gt; a \ge 0$, the Laplace transform</description></item><item><title>Laplace Transform of Constant Functions</title><link>https://freshrimpsushi.github.io/en/posts/745/</link><pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/745/</guid><description>Formulas1 $$ \mathcal{L} \left\{ 1 \right\} = \dfrac{1}{s},\quad s&amp;gt;0 $$ Derivation $$ \begin{align*} \mathcal{L}\left\{ 1 \right\} &amp;amp;= \int _{0}^\infty e^{-st} \cdot 1 dt \\ &amp;amp;= \lim \limits_{A \to \infty} \left[ -\dfrac{e^{-st}}{s} \right]_{0}^A \\ &amp;amp;= \lim \limits_{A \to \infty} \left[ -\dfrac{e^{-sA}}{s} +\dfrac{e^{-0t}}{s} \right] \\ &amp;amp;= \dfrac{1}{s} \end{align*} $$ Since it must follow $\lim \limits_{A \to \infty}\dfrac{e^{-sA}}{s}=0$,2 the condition that $s&amp;gt;0$ is added. ■ See Also Table of Laplace Transforms William E.</description></item><item><title>Laplace Transform of Exponential Functions</title><link>https://freshrimpsushi.github.io/en/posts/750/</link><pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/750/</guid><description>Formulas1 $$ \mathcal {L} \left\{ e^{at} \right\} = \dfrac{1}{s-a},\quad s&amp;gt;a $$ Description Let&amp;rsquo;s compare this with the result of the Laplace transform of a constant function (../745). $$ \mathcal{L} \left\{ 1 \right\} =\dfrac{1}{s} $$ The Laplace transform result of $e^{at}$ is the same as when $F(s)$ is shifted by $a$, when $f(t)=1$. This is inevitable because when $e^{at}$ is multiplied by the original function, $\displaystyle \int e^{-st}f(t) dt$ becomes $\displaystyle</description></item><item><title>Laplace Transform of Hyperbolic Functions</title><link>https://freshrimpsushi.github.io/en/posts/751/</link><pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/751/</guid><description>Formulas1 The Laplace transforms of hyperbolic sine and hyperbolic cosine functions are as follows. $$ \mathcal{L} \left\{ \sinh (at) \right\} = \dfrac{a}{s^2-a^2},\quad s&amp;gt;|a| \\ \mathcal{L} \left\{ \cosh (at) \right\} = \dfrac{s}{s^2-a^2},\quad s&amp;gt;|a| $$ Description The definition of hyperbolic functions is as follows. $$ \sinh (ax) = \dfrac{ e^{ax} - e^{-ax} }{ 2 } \\ \cosh (ax) = \dfrac{ e^{ax} + e^{-ax} }{ 2 } $$ Derivation Use the results of</description></item><item><title>Laplace Transform of Polynomial Functions</title><link>https://freshrimpsushi.github.io/en/posts/747/</link><pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/747/</guid><description>Formulas1 $$ \mathcal{L} \left\{ t^p \right\} = \dfrac{ \Gamma (p+1) } {s^{p+1}},\quad s&amp;gt;0 $$ Explanation The Laplace transform of a polynomial is represented by the Gamma function. If we use $x^p$ instead of $t^p$, it would be easier to recognize at a glance. Usually, in differential equations, variables represent time, so $x$ is replaced with $t$. Derivation $$ \begin{align*} \mathcal{L} \left\{ t^p \right\} &amp;amp;= \int_{0}^\infty e^{-st}t^p dt \\ &amp;amp;= \lim</description></item><item><title>Laplace Transform of Trigonometric Functions</title><link>https://freshrimpsushi.github.io/en/posts/746/</link><pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/746/</guid><description>Formulas1 The Laplace transforms of sine and cosine are as follows. $$ \mathcal{L} \left\{ \sin (at) \right\} = \dfrac{a}{s^2+a^2},\quad s&amp;gt;0 $$ $$ \mathcal{L} \left\{ \cos (at) \right\} = \dfrac{s}{s^2+a^2},\quad s&amp;gt;0 $$ Derivation $\sin (at)$ $$ \begin{align*} \mathcal{L} \left\{ \sin (at) \right\}&amp;amp; =\displaystyle \int_{0}^\infty e^{-st}\sin(at)dt \\ &amp;amp;= \lim \limits_{A \to \infty} \left[-\dfrac{1}{a}e^{-st}\cos (at) \right]_{0}^A+ \lim \limits_{A \to \infty} \int _{0}^\infty -\dfrac{s}{a}e^{-st} \cos (at)dt \\ &amp;amp;= \dfrac{1}{a} - \lim \limits_{A \to \infty}</description></item><item><title>Laplace Transform Table</title><link>https://freshrimpsushi.github.io/en/posts/743/</link><pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/743/</guid><description>Formula1 This is table of Laplace transform. $f(t)=\mathcal{L^{-1}}$ $F(s)=\mathcal{L} \left\{ f(t) \right\}$ Derivation $1$ $\dfrac{1}{s}$ link $e^{at}$ $\dfrac{1}{s-a}$ link $t^n$ $\dfrac{n!}{s^{n+1}}$ link $t^{p}$ $\dfrac{ \Gamma (p+1) }{ s^{p+1}}$ link $t^{p}e^{at}$ $\dfrac{ \Gamma (p+1) }{ (s-a)^{p+1}}$ link $\sin (at)$ $\dfrac{a}{s^2+a^2}$ link $\cos (at)$ $\dfrac{s}{s^2+a^2}$ link $e^{at}\sin(bt)$ $\dfrac{b}{(s-a)^2 +b^2}$ link $e^{at}\cos(bt)$ $\dfrac{s-a}{(s-a)^2+b^2}$ link $\sinh (at)$ $\dfrac{a}{s^2-a^2}$ link $\cosh (at)$ $\dfrac{s}{s^2-a^2}$ link $e^{at} \sinh (bt)$ $\dfrac{b}{(s-a)^2-b^2}$ link $e^{at} \cosh (bt)$ $\dfrac{s-a}{(s-a)^2-b^2}$ link $u_{c}(t)=</description></item><item><title>Linearity of Laplace Transform</title><link>https://freshrimpsushi.github.io/en/posts/749/</link><pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/749/</guid><description>Theorem1 Let $f_{1}$ and $f_2$ be functions for which the Laplace transform exists. Also, let $c_{1}, c_2$ be an arbitrary constant. Then $$ \mathcal{L} \left\{ c_{1}f_{1} + c_2f_2 \right\} = c_{1}\mathcal{L} \left\{f_{1} \right\} + c_2\mathcal{L} \left\{f_2 \right\} $$ Explanation It is obvious that the Laplace transform is an integral transform. Proof $$ \begin{align*} \mathcal{L} \left\{ c_{1}f_{1}+c_2f_2 \right\} &amp;amp;= \int_{0}^\infty e^{-st} \left( c_{1}f_{1}+c_2f_2 \right) dt \\ &amp;amp;= \int_{0}^\infty e^{-st}c_{1}f_{1} dt +</description></item><item><title>Solution to Clairaut's Differential Equation</title><link>https://freshrimpsushi.github.io/en/posts/556/</link><pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/556/</guid><description>Definition The 1st order nonlinear differential equation below is called Clairaut&amp;rsquo;s equation. $$ y=xy^\prime+f(y^\prime ) $$ Explanation The Clairaut differential equation is comparatively easier to solve than other nonlinear differential equations such as the Bernoulli differential equation or the Riccati differential equation. Solution Differentiate both sides of the given differential equation $y=xy^\prime+f(y^\prime )$ and then organize. $$ \begin{align*} &amp;amp;&amp;amp; y^\prime = y^\prime+xy^{\prime \prime} + y^{\prime \prime}f^\prime(y^\prime ) \\ \implies &amp;amp;&amp;amp;</description></item><item><title>Riccati Differential Equation Solutions</title><link>https://freshrimpsushi.github.io/en/posts/555/</link><pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/555/</guid><description>Definition The first-order nonlinear differential equation below is called the Riccati equation. $$ y^\prime = P(x)y+Q(x)y^2+R(x) $$ Explanation If $y_{1}$ is known as a particular solution, the general solution is represented in the form of $y=y_{1}+u(x)$. Here, $u(x)$ is an arbitrary constant, and it can be obtained by solving the Bernoulli differential equation when $n=2$. Solution The Riccati equation looks too complicated at first glance to solve. Hence, we need</description></item><item><title>Solution to the Bernoulli Differential Equation</title><link>https://freshrimpsushi.github.io/en/posts/554/</link><pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/554/</guid><description>Definition The following first-order nonlinear differential equation is called the Bernoulli equation. $$ y^\prime + p(x)y = q(x)y^n $$ Here, $n$ is an integer greater than or equal to $2$, and when $n=0,\ 1$, it is a linear equation. Description It’s worth noting that the Bernoulli of the Bernoulli differential equation and the Bernoulli of the widely known Bernoulli&amp;rsquo;s principle in fluid dynamics are different people. The</description></item><item><title>Methods for Finding the Second Solution of Second Order Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/553/</link><pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/553/</guid><description>Description1 $$ \begin{equation} y^{\prime \prime }+p(t)y^{\prime} + q(t)y=0 \end{equation} $$ Given the differential equation above, assume we know one solution $y_{1}$. Let&amp;rsquo;s assume the general solution is $y(t)=\nu (t) y_{1}(t)$. If we calculate the 1st and 2nd derivatives of $y$, we get the following. $$ \begin{align*} y^{\prime} &amp;amp;= \nu^{\prime} y_{1} + \nu y_{1}^{\prime} \\ y^{\prime \prime} &amp;amp;= \nu ^{\prime \prime}y_{1} + \nu^{\prime} y_{1}^{\prime} + \nu^ \prime y_{1}^{\prime} + \nu y_{1}^{\prime</description></item><item><title>General Solution to Second-Order Linear Nonhomogeneous Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/547/</link><pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/547/</guid><description>Auxiliary Lemma1 Consider the following nonhomogeneous/homogeneous second-order linear differential equation: $$ \begin{align} y^{\prime \prime}+p(t)y^\prime + q(t)y &amp;amp;=g(t) \label{eq1} \\ y^{\prime \prime}+p(t)y^\prime + q(t)y &amp;amp;=0 \label{eq2} \end{align} $$ Assume that $y_{1} (t)$ and $y_{2} (t)$ are solutions to the nonhomogeneous differential equation $\eqref{eq1}$, and that $y_{1}(t)$ and $y_{2}(t)$ are the fundamental set of solutions to the homogeneous differential equation $\eqref{eq2}$. Then, the following equation holds: $$ y_{1} (t) – y_{2} (t)=</description></item><item><title>Solutions to the Homogeneous Second-Order Linear Differential Equation and the Wronskian</title><link>https://freshrimpsushi.github.io/en/posts/546/</link><pubDate>Thu, 03 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/546/</guid><description>Definition[^1] $$ ay^{\prime \prime}+ by^\prime +cy=0 $$ Let&amp;rsquo;s consider the second-order linear homogeneous differential equation given above. Let&amp;rsquo;s call $W$ the Wronskian. If $W (y_{1}, y_{2}) \ne 0$, then we call $\left\{ y_{1}, y_{2} \right\}$ the fundamental set of solution for the given differential equation.</description></item><item><title>Homogeneous Meaning in Homogeneous Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/545/</link><pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/545/</guid><description>Description $$ a_{n}(x)\dfrac{d^ny}{dx^n}+a_{n-1}(x)\dfrac{d^{n-1}y}{dx^{n-1}}+ \cdots + a_{1}(x)\dfrac{dy}{dx}+a_{0}(x)y=f(x) $$ When a differential equation is as above, if $f(x)=0$, it is called homogeneous $f(x) \ne 0$ if not, it is called non-homogeneous or inhomogeneous. Consider the following simple example of a 2nd order linear differential equation. $$ ay^{\prime \prime}+by^\prime +cy=g(t) $$ Here, if $g(t)$ equals $0$, it is homogeneous; if $0$ is not met, it is non-homogeneous. To elaborate on the term homogeneous,</description></item><item><title>Solution to Second Order Homogeneous Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/544/</link><pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/544/</guid><description>Theorem1 $$ ay^{\prime \prime} + by^\prime + cy=0 $$ Let&amp;rsquo;s say the solutions to the characteristic equation $ar^2+br+c=0$ given above are $r_{1}$ and $r_2$. Then, $\text{1.}$ If $r_{1}$ and $r_2$ are two distinct real numbers$(b^2-4ac&amp;gt;0)$, the general solution is as follows: $$ y(t)=c_{1}e^{r_{1}t}+c_2e^{r_2t} $$ $\text{2.}$ If $r_{1}$ and $r_2$ are complex conjugates $\lambda \pm i \mu$$(b^2-4ac&amp;lt;0)$, the general solution is as follows: $$ \begin{align*} y(t) &amp;amp;= c_{1}e^{(\lambda + i\mu)t} +</description></item><item><title>Second-Order Linear Homogeneous Differential Equations with Constant Coefficients and Characteristic Equation</title><link>https://freshrimpsushi.github.io/en/posts/540/</link><pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/540/</guid><description>Theorem1 The general solution of a second-order linear homogeneous differential equation with constant coefficients $a y^{\prime \prime} + by^\prime +cy=0$ is as follows. $$ y(x)=A e^{r_{1} x}+Be^{r_2 x} $$ At this time, $r_{1,2}=\dfrac{-b \pm \sqrt{b^2-4ac}} {2a}$ Corollary The solution of $a y^{\prime \prime} + cy = 0$ is as follows. $$ y(x) = A e^{i\sqrt{\frac{c}{a}} x}+Be^{-i\sqrt{\frac{c}{a}} x} = C\cos{\textstyle (\sqrt{\frac{c}{a}}x)} + D\sin{\textstyle (\sqrt{\frac{c}{a}}x)} $$ Solution $$ \begin{equation} a\dfrac{d^2}{dx^2}y+b\dfrac{d}{dx}y+cy = 0</description></item><item><title>Linear Combination of Solutions to Homogeneous Linear Differential Equations is Also a Solution</title><link>https://freshrimpsushi.github.io/en/posts/542/</link><pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/542/</guid><description>Theorem1 If $y_{1}, y_{2}$ is a solution to $ay^{\prime \prime}+by^\prime +cy=0$, then $d_{1}y_{1} + d_{2}y_{2}$ is also a solution. Here, $d_{1}, d_{2}$ is any constant. Description As can be seen in the proof, it also holds for any $n$ order linear homogeneous differential equation. Proof Assume that $y_{1}, y_{2}$ is a solution to $ay^{\prime \prime}+by^\prime +cy=0$. Then the following two equations are satisfied. $$ \begin{align*} d_{1} (ay_{1}^{\prime \prime}+by_{1}^\prime + cy_{1}</description></item><item><title>Definition and Discrimination Method of an Exact Differential Equation</title><link>https://freshrimpsushi.github.io/en/posts/516/</link><pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/516/</guid><description>Definition The given differential equation $\psi=\psi (x,y)$ is said to be an exact differential equation if there exists $\psi=\psi (x,y)$ that satisfies $\psi (x,y)$. Explanation If the given differential equation is exact, it can be represented as a total differential with respect to $\psi (x,y)$. $d\psi (x,y)=\dfrac{\partial \psi }{\partial x}dx + \dfrac{\partial \psi }{\partial y}dy$ Since $d\psi (x,y)=\dfrac{\partial \psi }{\partial x}dx + \dfrac{\partial \psi }{\partial y}dy$, it follows that $d\psi</description></item><item><title>Integrating Factor Method for First Order Linear Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/515/</link><pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/515/</guid><description>Theorem1 The solution to the first order linear differential equation $\dfrac{dy}{dx}+p(x)y=q(x)$ is given as follows. $$ \begin{align*} y(x)&amp;amp;=\dfrac{1}{e^{\int p(x) dx}} \left[ \int e^{\int p(x) dx} q(x) dx +C \right] \\ &amp;amp;=e^{-\int p(x) dx}\int e^{\int p(x) dx} q(x) dx + e^{-\int p(x) dx}C \end{align*} $$ Description A differential equation of form $y^\prime+p(x)y=q(x)$ is called a first order linear differential equation. Here, if $q(x)=0$, we can directly apply variable separation and solve</description></item><item><title>Solution to the Exact Differential Equation</title><link>https://freshrimpsushi.github.io/en/posts/517/</link><pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/517/</guid><description>Solution The solution to the given exact differential equation $M(x,y)+N(x,y)\dfrac{dy}{dx}=0$ is as follows. Step 0. Since the differential equation given is exact, an $\psi$ exists such that $\psi_{x}=M,\ \ \psi_{y}=N, \ \ \psi=c$. Step 1. Integrate $\psi_{x}$. Then, differentiate the obtained $\psi$ with respect to $y$ to find $h^\prime(y)$. The entire process including Step 1 can be done the opposite way with respect to $x$ and $y$ as well. $$</description></item><item><title>Homogeneous Functions and First-Order Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/505/</link><pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/505/</guid><description>Definition When a function $f(x,y)$ satisfies $f(tx,ty)=t^nf(x,y)$ for any positive integer $n$, $f$ is called a $n$th degree homogeneous function.</description></item><item><title>Separable First-Order Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/503/</link><pubDate>Sat, 31 Mar 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/503/</guid><description>Definition1 A first-order differential equation is said to be separable if it satisfies the following condition: $$ f(x)+g(y)\dfrac{dy}{dx}=0 \quad \text{or} \quad f(x)dx = -g(y)dy $$ Explanation It can be expressed in various forms, but the important point is that the variables on each side must be separated. The method of finding solutions by separating these two variables is called the method of separation of variables. The separability is a very</description></item><item><title>Classification of Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/483/</link><pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/483/</guid><description>Description Differential equations can be classified by various criteria. They are broadly divided into ordinary differential equations and partial differential equations. Further classification can be made based on coefficients and order, and whether they are linear or nonlinear. The reason for classifying differential equations is obviously to solve them. The method of solving a differential equation varies depending on its classification. Ordinary Differential Equations and Partial Differential Equations Ordinary differential</description></item><item><title>Definition and Examples of Differential Equations</title><link>https://freshrimpsushi.github.io/en/posts/479/</link><pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/479/</guid><description>Definition A differential equation is an equation that includes derivatives of one or more dependent variables with respect to one or more independent variables. $$ \dfrac{dy}{dx}=y $$ $$ \dfrac{d^2y}{dx^2} = y $$ Explanation Most physical situations can be described by first-order or second-order differential equations. Falling Body $$ F=ma=mg $$ $$ v=\dfrac{dy}{dt} $$ $$ a=\dfrac{dv}{dt}=\dfrac{d}{dt} \left( \dfrac{dy}{dt} \right)=\dfrac{d^2y}{dt^2} $$ $$ \dfrac{d^2y}{dt^2}=g $$ Spring Mass System $$ F=ma=-ky $$ $$ a=</description></item></channel></rss>