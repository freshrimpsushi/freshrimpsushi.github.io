<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>수리물리 on FreshrimpRestaurant</title>
    <link>https://freshrimpsushi.github.io/en/categories/%EC%88%98%EB%A6%AC%EB%AC%BC%EB%A6%AC/</link>
    <description>Recent content in 수리물리 on FreshrimpRestaurant</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 07 Jan 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://freshrimpsushi.github.io/en/categories/%EC%88%98%EB%A6%AC%EB%AC%BC%EB%A6%AC/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Product Rule Involving the Del Operator</title>
      <link>https://freshrimpsushi.github.io/en/posts/93/</link>
      <pubDate>Thu, 07 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/93/</guid>
      <description>Formulas Let&amp;rsquo;s call $f=f(x,y,z)$ a scalar function. Let&amp;rsquo;s call $\mathbf{A} = A_{x}\hat{\mathbf{x}} + A_{y}\hat{\mathbf{y}} + A_{z}\hat{\mathbf{z}}, \mathbf{B} = B_{x}\hat{\mathbf{x}} + B_{y}\hat{\mathbf{y}} + B_{z}\hat{\mathbf{z}}$ a vector function. Then, the following equations hold. Gradient (a) $\nabla{(fg)}=f\nabla{g}+g\nabla{f}$ (b) $\nabla(\mathbf{A} \cdot \mathbf{B}) = \mathbf{A} \times (\nabla \times \mathbf{B}) + \mathbf{B} \times (\nabla \times \mathbf{A})+(\mathbf{A} \cdot \nabla)\mathbf{B}+(\mathbf{B} \cdot \nabla) \mathbf{A}$ Divergence (c) $\nabla \cdot (f\mathbf{A}) = f(\nabla \cdot \mathbf{A}) + \mathbf{A} \cdot (\nabla f)$ (d)</description>
    </item>
    <item>
      <title>Laplacian of a Scalar Function in the Three-Dimensional Cartesian Coordinate System</title>
      <link>https://freshrimpsushi.github.io/en/posts/1879/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1879/</guid>
      <description>Definition The Laplacian of a 3D scalar function $f=f(x,y,z)$ is the divergence of its gradient $f$ and is denoted by $\nabla^{2}$. $$ \nabla ^{2} f := \nabla \cdot(\nabla f)= \frac{ \partial^{2} f}{ \partial x^{2} }+\frac{ \partial^{2} f}{ \partial y^{2}}+\frac{ \partial^{2} f}{ \partial z^{2}} $$ Explanation The name Laplacian comes from the French mathematician Laplace. The notation $\nabla^{2}$ is used for convenience. In mathematics (theory of partial differential equations), the notation</description>
    </item>
    <item>
      <title>Total Differentiation, Exact Differentiation</title>
      <link>https://freshrimpsushi.github.io/en/posts/1773/</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1773/</guid>
      <description>Definition Let&amp;rsquo;s assume that a multivariable function $f : \mathbb{R}^{n} \to \mathbb{R}$ is given. The change of $f(\mathbf{x})$ according to the change of variable $\mathbf{x} = (x_{1}, x_{2}, \dots, x_{n})$ is denoted as $df$, and this is called the total differential or exact differential of $f$. $$ \begin{equation} df = \frac{ \partial f}{ \partial x_{1} }dx_{1} + \frac{ \partial f}{ \partial x_{2} }dx_{2} + \cdots + \frac{ \partial f}{ \partial</description>
    </item>
    <item>
      <title>Divergence of Vector Function in Cartesian Cooridenates System</title>
      <link>https://freshrimpsushi.github.io/en/posts/1796/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1796/</guid>
      <description>Definition For a vector function $\mathbf{F}(x,y,z)=F_{x}\hat{\mathbf{x}}+F_{y}\hat{\mathbf{y}} + F_{z}\hat{\mathbf{z}}$, the following scalar function is defined as the divergence $\mathbf{F}$ of $\mathbf{F}(x,y,z)=F_{x}\hat{\mathbf{x}}+F_{y}\hat{\mathbf{y}} + F_{z}\hat{\mathbf{z}}$ and is denoted by $\nabla \cdot \mathbf{F}$. $$ \begin{equation} \nabla \cdot \mathbf{F} := \frac{ \partial F_{x}}{ \partial x} + \frac{ \partial F_{y}}{ \partial y }+ \frac{ \partial F_{z}}{ \partial z} \label{divergence} \end{equation} $$ Explanation Geometrically, if $\nabla \cdot \mathbf{F}&amp;gt;0$, it means that $\mathbf{F}$ is spreading out or diverging.</description>
    </item>
    <item>
      <title>Gradient of Scalar Function in Cartesian Coordinate System</title>
      <link>https://freshrimpsushi.github.io/en/posts/1778/</link>
      <pubDate>Sat, 12 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1778/</guid>
      <description>Definition For a scalar function $f=f(x,y,z)$, the following vector function is defined as the gradient of $f$, denoted by $\nabla f$: $$ \nabla f := \frac{ \partial f}{ \partial x }\hat{\mathbf{x}}+\frac{ \partial f}{ \partial y}\hat{\mathbf{y}}+\frac{ \partial f}{ \partial z}\hat{\mathbf{z}} = \left( \dfrac{\partial f}{\partial x}, \dfrac{\partial f}{\partial y}, \dfrac{\partial f}{\partial z} \right) $$ Explanation The gradient is translated into English as gradient, slope, or incline. The terms &amp;lsquo;slope&amp;rsquo; and &amp;lsquo;incline&amp;rsquo; are</description>
    </item>
    <item>
      <title>Curl of Vector Functions in 3D Cartesian Coordinates</title>
      <link>https://freshrimpsushi.github.io/en/posts/1752/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1752/</guid>
      <description>Definition For a vector function $\mathbf{F}(x,y,z)=(F_{x},F_{y},F_{z})=F_{x}\hat{\mathbf{x}} + F_{y}\hat{\mathbf{y}} + F_{z}\hat{\mathbf{z}}$, the following vector is defined as the curl of $\mathbf{F}$, denoted as $\nabla \times \mathbf{F}$. $$ \begin{align} \nabla \times \mathbf{F} &amp;amp;= \left( \dfrac{ \partial F_{z}}{ \partial y }-\dfrac{ \partial F_{y}}{ \partial z} \right)\hat{\mathbf{x}}+ \left( \dfrac{ \partial F_{x}}{ \partial z }-\dfrac{ \partial F_{z}}{ \partial x} \right)\hat{\mathbf{y}}+ \left( \dfrac{ \partial F_{y}}{ \partial x }-\dfrac{ \partial F_{x}}{ \partial y} \right)\hat{\mathbf{z}} \label{def1} \\ &amp;amp;=\begin{vmatrix}</description>
    </item>
    <item>
      <title>Gauss&#39;s Theorem, Divergence Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/565/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/565/</guid>
      <description>Summary1 The following holds for a 3-dimensional vector function $\mathbf{F}$: $$ \begin{equation} \int_{\mathcal{V}} \nabla \cdot \mathbf{F} dV = \oint_{\mathcal{S}} \mathbf{F} \cdot d \mathbf{S} \label{1} \end{equation} $$ Here, $\nabla \cdot \mathbf{F}$ is divergence, $\int_{\mathcal{V}}$ is volume integration, and $\oint_{\mathcal{S}}$ is closed surface integration. Description This is called Gauss&amp;rsquo;s theorem, Green&amp;rsquo;s theorem, or divergence theorem. The divergence theorem is especially used in electromagnetics. Mathematical Meaning Mathematically, it means that a surface integral</description>
    </item>
    <item>
      <title>Gradient, Divergence, Curl, and Laplacian in Curvilinear Coordinates</title>
      <link>https://freshrimpsushi.github.io/en/posts/299/</link>
      <pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/299/</guid>
      <description>Explanation In physics, the four operations involving the del operator $\nabla$, Gradient, Divergence, Curl, Laplacian, are very important. Therefore, one must know the operations in three coordinate systems. Of course, this does not mean that you have to memorize them. Since physics study is not about memorizing formulas, they will naturally be memorized as you study, so do not try to memorize them intentionally but instead keep a printout of</description>
    </item>
    <item>
      <title>Cross Product in Three-Dimensional Euclidean Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/256/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/256/</guid>
      <description>Definition The cross product of $\mathbf{x}$ and $\mathbf{y}$ is defined in terms of $\mathbf{x}, \mathbf{y} \in \mathbb{R}^3$. $$ \begin{align*} \mathbf{x} \times \mathbf{y} =&amp;amp; (x_{2}y_{3} - x_{3}y_{2}, x_{3}y_{1} - x_{1}y_{3}, x_{1}y_{2} - x_{2}y_{1}) \\ =&amp;amp; \det \begin{bmatrix} \mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} \\ x_{1} &amp;amp; x_{2} &amp;amp; x_{3} \\ y_{1} &amp;amp; y_{2} &amp;amp; y_{3} \end{bmatrix} \\ =&amp;amp; \begin{bmatrix} 0 &amp;amp; -x_{3} &amp;amp; x_{2} \\ x_{3} &amp;amp; 0 &amp;amp; -x_{1} \\ -x_{2}</description>
    </item>
    <item>
      <title>Euclidean Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/205/</link>
      <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/205/</guid>
      <description>Definition For a natural number $n \in \mathbb{N}$, the Cartesian product $\mathbb{R}$ of the set of real numbers is called the Euclidean space. $$ \mathbb{R}^{n} = \mathbb{R} \times \cdots \times \mathbb{R} $$ $\mathbb{R}^{1}$ is referred to as real space or number line. $\mathbb{R}^{2}$ is called a plane. $\mathbb{R}^{3}$ is called a $3$-dimensional space. Here, $\mathbb{N} := \left\{ 1, 2, 3, \cdots \right\}$ means the set that includes all natural numbers.</description>
    </item>
    <item>
      <title>Separation Vector</title>
      <link>https://freshrimpsushi.github.io/en/posts/141/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/141/</guid>
      <description>Definition1 The vector from the source point to the observation point is called the separation vector. $$ \bcR = \mathbf{r} - \mathbf{r}^{\prime} $$ Description Source vector $\mathbf{r}^{\prime}$: The place where there is a charge or current. That is, it represents the coordinates of the origin of the electromagnetic field. Position vector $\mathbf{r}$: Represents the coordinates of where the electric field $\mathbf{E}$ or magnetic field $\mathbf{B}$ is measured. Separation vector $\bcR$:</description>
    </item>
    <item>
      <title>Einstein Notation</title>
      <link>https://freshrimpsushi.github.io/en/posts/90/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/90/</guid>
      <description>Notation The summation sign $\sum$ is omitted when a subscript is repeated two or more times. Description Also referred to as the Einstein summation convention. It&amp;rsquo;s not really a formula but rather a rule. When doing vector calculations, there are often cases where one needs to write the summation sign $\sum$ multiple times in a single formula, which can make the equation look cluttered and is very annoying to write</description>
    </item>
    <item>
      <title>Product of Two Levi-Civita Symbols</title>
      <link>https://freshrimpsushi.github.io/en/posts/88/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/88/</guid>
      <description>Theorem The $\epsilon_{ijk}$, defined as follows, is referred to as the Levi-Civita symbol. $$ \epsilon_{ijk} = \begin{cases} +1 &amp;amp; \text{if} \ \epsilon_{123}, \epsilon_{231}, \epsilon_{312} \\ -1 &amp;amp; \text{if} \ \epsilon_{132}, \epsilon_{213}, \epsilon_{321} \\ 0 &amp;amp; \text{if} \ i=j \ \text{or} \ j=k \ \text{or} \ k=i \end{cases} $$ The $\delta_{ij}$, defined as follows, is referred to as the Kronecker delta. $$ \delta_{ij} := \begin{cases} 1,&amp;amp;i=j \\ 0, &amp;amp; i\ne j</description>
    </item>
    <item>
      <title>Kronecker Delta</title>
      <link>https://freshrimpsushi.github.io/en/posts/84/</link>
      <pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/84/</guid>
      <description>Definition The $\delta_{ij}$, defined as follows, is called the Kronecker delta. $$ \delta_{ij} := \begin{cases} 1,&amp;amp;i=j \\ 0, &amp;amp; i\ne j \end{cases} $$ Description The Kronecker delta is used in many places, and its main role is to indicate only what one wants among all components (elements, possibilities, etc.). For students of physics, it is mainly encountered in the expression for the inner product. This might not be immediately clear,</description>
    </item>
    <item>
      <title>Levi-Civita Symbol</title>
      <link>https://freshrimpsushi.github.io/en/posts/83/</link>
      <pubDate>Tue, 25 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/83/</guid>
      <description>Definition The $\epsilon_{ijk}$ defined as follows is called the Levi-Civita symbol. $$ \epsilon_{ijk} = \begin{cases} +1 &amp;amp; \text{if} \ \epsilon_{123}, \epsilon_{231}, \epsilon_{312} \\ -1 &amp;amp; \text{if} \ \epsilon_{132}, \epsilon_{213}, \epsilon_{321} \\ 0 &amp;amp; \text{if} \ i=j \ \text{or} \ j=k \ \text{or} \ k=i \end{cases} $$ Description While the Kronecker delta only considers whether the indices are equal, the Levi-Civita symbol, as shown in its definition, is also affected by</description>
    </item>
  </channel>
</rss>
