<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Mathematical Statistics on FreshrimpRestaurant</title><link>https://freshrimpsushi.github.io/en/categories/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99/</link><description>Recent content in Mathematical Statistics on FreshrimpRestaurant</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 01 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/en/categories/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99/index.xml" rel="self" type="application/rss+xml"/><item><title>Probability Vector</title><link>https://freshrimpsushi.github.io/en/posts/3665/</link><pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3665/</guid><description>Definition A vector that satisfies the following condition $\mathbf{p} = \begin{bmatrix}p_{1} &amp;amp; \cdots &amp;amp; p_{n} \end{bmatrix}^{\mathsf{T}}$ is called a probability vector. $$ 0 \le p_{i} \le 1 \quad (1 \le i \le n)\quad \text{and} \quad \sum_{i=1}^{n} p_{i} = 1 $$ Explanation A probability vector is a vector that represents the probabilities of each state when there are $n$ states. Conceptually, it is analogous to a probability mass function. If the</description></item><item><title>Proof of Cochran's Theorem</title><link>https://freshrimpsushi.github.io/en/posts/2655/</link><pubDate>Tue, 27 May 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2655/</guid><description>Theorem Let Sample $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ be iid and follow a Normal distribution like $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} N \left( 0, \sigma^{2} \right)$. For a symmetric matrix $A_{1} , \cdots , A_{k} \in \mathbb{R}^{n \times n}$ with rank $r_{j}$, suppose the random variable $Q_{1} , \cdots , Q_{k}$ is expressed as a random vector quadratic form $Q_{i} := \mathbf{X}^{T} A_{i} \mathbf{X}$, and</description></item><item><title>Proof of the Hogg-Craig Theorem</title><link>https://freshrimpsushi.github.io/en/posts/2651/</link><pubDate>Mon, 19 May 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2651/</guid><description>Theorem Let sample $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ follow iid Normal distribution like $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} N \left( 0, \sigma^{2} \right)$. Consider a symmetric matrix $A_{1} , \cdots , A_{k} \in \mathbb{R}^{n \times n}$ and a random variable $Q_{1} , \cdots , Q_{k}$ represented as a random vector quadratic form $Q_{i} := \mathbf{X}^{T} A_{i} \mathbf{X}$. Define symmetric matrix $A$ and random variable $Q$</description></item><item><title>Proof of Craig's Theorem</title><link>https://freshrimpsushi.github.io/en/posts/2647/</link><pubDate>Sun, 11 May 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2647/</guid><description>Theorem Let the sample $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ be iid and follow a normal distribution like $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} N \left( 0, \sigma^{2} \right)$. For a symmetric matrix $A, B \in \mathbb{R}^{n \times n}$, with respect to the random variables $Q_{1}$ and $Q_{2}$, which are defined as quadratic forms in random vectors like $Q_{1} := \sigma^{-2} \mathbf{X}^{T} A \mathbf{X}$ and $Q_{2} :=</description></item><item><title>Mixture Distributions</title><link>https://freshrimpsushi.github.io/en/posts/3639/</link><pubDate>Tue, 06 May 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3639/</guid><description>Build-up1 Suppose we want to approximate a probability distribution with the probability density function as shown in the image below. One of the basic methods to approximate a probability distribution is to find a normal distribution that closely resembles the distribution we aim to approximate. However, as the following figures show, the distribution we want to approximate has three peaks, making it challenging to approximate using a normal distribution. Here,</description></item><item><title>Conditions for Equivalence of Chi-Squared Nature in Quadratic Forms of Normal Distribution Random Vectors</title><link>https://freshrimpsushi.github.io/en/posts/2639/</link><pubDate>Fri, 25 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2639/</guid><description>Theorem Let sample $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ follow a normal distribution as iid as $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} N \left( 0, \sigma^{2} \right)$. For a symmetric matrix $A \in \mathbb{R}^{n \times n}$ with rank $r \le n$, define the quadratic form of a random vector as $Q = \sigma^{-2} \mathbf{X}^{T} A \mathbf{X}$, then the following holds. $$ Q \sim \chi^{2} (r) \iff A^{2}</description></item><item><title>The Moment Generating Function of a Quadratic Form of a Normally Distributed Random Vector</title><link>https://freshrimpsushi.github.io/en/posts/2637/</link><pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2637/</guid><description>Theorem Let Sample $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ be iid following a Normal Distribution such as $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} N \left( 0, \sigma^{2} \right)$. Consider a Symmetric Matrix $A \in \mathbb{R}^{n \times n}$ with Rank $r \le n$. The Moment Generating Function of the Quadratic Form of a Random Vector $Q = \sigma^{-2} \mathbf{X}^{T} A \mathbf{X}$ is expressed as follows: $$ M_{Q} (t)</description></item><item><title>Sum of Squares Decomposition Represented by Quadratic Form of a Random Vector</title><link>https://freshrimpsushi.github.io/en/posts/2635/</link><pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2635/</guid><description>Formula For a random vector $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$, an identity matrix $I_{n} \in \mathbb{R}^{n \times n}$, and an all-ones matrix $J_{n} \in \mathbb{R}^{n \times n}$ whose elements are all $1$, the following holds: $$ \mathbf{X}^{T} \left( I_{n} - {\frac{ 1 }{ n }} J_{n} \right) \mathbf{X} = ( n - 1 ) S^{2} $$ Here, $S^{2}$ is the sample variance. Derivation $$ \begin{align*} \overline{X}</description></item><item><title>Expected Value of the Quadratic Form of a Random Vector</title><link>https://freshrimpsushi.github.io/en/posts/2633/</link><pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2633/</guid><description>Formula Let the population mean vector $\mu \in \mathbb{R}^{n}$ and the covariance matrix $\Sigma \in \mathbb{R}^{n \times n}$ be given such that the random vector $\mathbf{X}$ is $\mathbf{X} \sim \left( \mu , \Sigma \right)$. For a symmetric matrix $A$, the expected value of the quadratic form of a random vector is as follows. $$ E (Q) = \operatorname{tr} A \Sigma + \mu^{T} A \mu $$ Here, $\mu^{T}$ is the transpose</description></item><item><title>Quadratic Form of Random Vector</title><link>https://freshrimpsushi.github.io/en/posts/2631/</link><pubDate>Wed, 09 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2631/</guid><description>Definition 1 For a random vector $\mathbf{X} = \left( X_{1} , \cdots , X_{n} \right)$ and a symmetric matrix $A \in \mathbb{R}^{n \times n}$, $Q = \mathbf{X}^{T} A \mathbf{X}$ is called a quadratic form. Explanation Since the quadratic form $A = \left( a_{ij} \right)$ is a symmetric matrix, it can be expressed in several ways, as shown below, and is useful in many applications. $$ \begin{align*} &amp;amp; Q \\ =&amp;amp;</description></item><item><title>Principal Component Analysis (PCA) in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/2606/</link><pubDate>Fri, 02 Aug 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2606/</guid><description>Overview Principal Component Analysis (PCA) has many uses in statistics, such as avoiding multicollinearity in regression analysis and summarizing data, and holds significant importance in machine learning as a way of dimensionality reduction. This post focuses on the theoretical foundations of deriving principal components rather than on practical usage. Definition 1 Principal Component Analysis Let&amp;rsquo;s assume a random vector $\mathbf{X} = \left( X_{1} , \cdots , X_{p} \right)$ is given.</description></item><item><title>Expectation of Random Vectors</title><link>https://freshrimpsushi.github.io/en/posts/2555/</link><pubDate>Thu, 18 Apr 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2555/</guid><description>Definition 1 $$ E \left( X \right) := \begin{bmatrix} E \left( X_{1} \right) \\ \vdots \\ E \left( X_{n} \right) \end{bmatrix} $$ The expectation of a random vector $X = \left( X_{1} , \cdots , X_{n} \right)$ is defined as a vector of the expectations of its components, as shown above. Similarly, the matrix $\mathbf{X} = \left[ X_{ij} \right]$ of a random variable of size $m \times n$ is also</description></item><item><title>Conditional Expectation Minimizes the Sum of Squared Deviations</title><link>https://freshrimpsushi.github.io/en/posts/3514/</link><pubDate>Wed, 29 Nov 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3514/</guid><description>Summary The following holds true: $$ \begin{equation} E\left[ Y | X \right] = \argmin_{f(X)} E\left[ (Y - f(X))^{2} | X \right] \end{equation} $$ $$ \begin{equation} E\left[ Y | X \right] = \argmin_{f(X)} E\left[ (Y - f(X))^{2} \right] \end{equation} $$ Proof (1) $$ \begin{align*} &amp;amp; \argmin_{f(X)} E\left[ (Y - f(X))^{2} | X \right] \\ &amp;amp;= \argmin_{f(X)} E\left[ Y^{2} - 2Yf(X) + f(X)^{2} | X \right] \\ &amp;amp;= \argmin_{f(X)} \left( E\left[ Y^{2}</description></item><item><title>Definition of Congruent Covariance</title><link>https://freshrimpsushi.github.io/en/posts/2472/</link><pubDate>Sat, 04 Nov 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2472/</guid><description>Buildup Let&amp;rsquo;s say we have samples drawn independently from a population with distribution $X \sim \left( \mu , \sigma^{2} \right)$, but these samples are actually composed of $m$ different populations, $\left( \mu_{1} , \sigma_{1}^{2} \right), \cdots , \left( \mu_{m} , \sigma_{m}^{2} \right)$, with $n_{1} , \cdots , n_{m}$ samples drawn from each, creating a collection of random samples. $$ \begin{align*} \left\{ X_{1} \right\}_{n_{1}} \overset{\text{iid}}{\sim} &amp;amp; \left( \mu_{1} , \sigma_{1}^{2} \right)</description></item><item><title>Definition of Weighted Average</title><link>https://freshrimpsushi.github.io/en/posts/2470/</link><pubDate>Tue, 31 Oct 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2470/</guid><description>Definition The following is called the Weighted Mean for data $\mathbf{x} = \left\{ x_{1} , \cdots , x_{n} \right\}$ and vector $\mathbf{w} = \left( w_{1} , \cdots , w_{n} \right) \in \mathbb{R}^{n}$. $$ {{ \sum_{k=1}^{n} w_{k} x_{k} } \over { \sum_{k=1}^{n} w_{k} }} = {{ w_{1} x_{1} + \cdots + w_{n} x_{n} } \over { w_{1} + \cdots + w_{n} }} $$ Meanwhile, $\mathbf{w}$ is also called a weighted vector</description></item><item><title>Standard Definition of Standard Error</title><link>https://freshrimpsushi.github.io/en/posts/2462/</link><pubDate>Sun, 15 Oct 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2462/</guid><description>Definition 1 For a given estimator $T$, the estimated standard deviation of $T$ is called the standard error. $$ \text{s.e.} \left( T \right) := \sqrt{ \widehat{ \Var \left( T \right) } } $$ Explanation The reason why it is precisely defined as an estimator in the definition, not a statistic, is because the standard error becomes meaningless unless we are discussing whether it &amp;lsquo;matches or not&amp;rsquo; with the parameter $\theta$</description></item><item><title>Unimodal Distribution's Shortest Confidence Interval</title><link>https://freshrimpsushi.github.io/en/posts/2337/</link><pubDate>Tue, 07 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2337/</guid><description>Theorem Definition of Unimodal Functions If there exists a mode $x^{\ast}$ such that the function $f : \mathbb{R} \to \mathbb{R}$ does not decrease in $x \le x^{\ast}$ and does not increase in $x \ge x^{\ast}$, then $f$ is called unimodal. Especially, if the probability density function of $f$ is unimodal, we call that probability distribution a unimodal distribution. Shortest Confidence Interval Let&amp;rsquo;s consider $f(x)$ to be a unimodal probability density</description></item><item><title>Stochastic Increment and Decrement Functions and Confidence Intervals</title><link>https://freshrimpsushi.github.io/en/posts/2335/</link><pubDate>Fri, 03 Feb 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2335/</guid><description>Theorem 1 Definition of Stochastic Monotone Functions If the cumulative distribution function $F \left( t ; \theta \right)$ is a monotone (increasing or decreasing) function for $\theta$, it is called a Stochastic Increasing(Decreasing) Function. Pivoting a Continuous Cumulative Distribution Function Let&amp;rsquo;s say a statistic $T$ has a continuous cumulative distribution function $F_{T} \left( t ; \theta \right)$. For a fixed $\alpha \in (0,1)$, let $\alpha_{1} + \alpha_{2} = \alpha$, and</description></item><item><title>Most Accurate Confidence Set</title><link>https://freshrimpsushi.github.io/en/posts/2333/</link><pubDate>Mon, 30 Jan 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2333/</guid><description>Definition 1 For the hypothesis test for $\theta$, the confidence set of $1 - \alpha$ is called $C \left( \mathbf{x} \right)$, and let the acceptance region be $A \left( \theta \right) = C \left( \mathbf{x} \right)^{c}$. The probability of False Coverage for $P_{\theta} \left( \theta ' \in C \left( \mathbf{X} \right) \right)$ against $\theta ' \ne \theta$ is called. The original coverage probability of $P_{\theta} \left( \theta \in C \left(</description></item><item><title>Hypothesis Testing and the One-to-One Correspondence of Confidence Sets</title><link>https://freshrimpsushi.github.io/en/posts/2332/</link><pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2332/</guid><description>Theorem Let&amp;rsquo;s assume we have parameter space $\Theta$ and space $\mathcal{X}$ given. For each $\theta_{0} \in \Theta$, let $A \left( \theta_{0} \right)$ be the rejection region $\alpha$ of the hypothesis test $H_{0} : \theta = \theta_{0}$. For each $\mathbf{x} \in \mathcal{X}$, let&amp;rsquo;s define the set $C \left( \mathbf{x} \right) \subset \Theta$ as follows: $$ C \left( \mathbf{x} \right) := \left\{ \theta_{0} : \mathbf{x} \in A \left( \theta_{0} \right) \right\} $$</description></item><item><title>Definition of a Pivot in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/2331/</link><pubDate>Thu, 26 Jan 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2331/</guid><description>Definition 1 A random variable $Q \left( \mathbf{X} ; \theta \right) := Q \left( X_{1} , \cdots , X_{n} ; \theta \right)$ whose probability distribution is independent of all parameters $\theta$ is called a pivot or pivotal quantity. Description Naturally, $Q$ is a statistic. The statement that the probability distribution is independent of all parameters $\theta$ means that the cumulative distribution function $F \left( \mathbf{x} ; \theta \right)$ of $Q</description></item><item><title>Definition of a Mathematical-Statistical Confidence Set</title><link>https://freshrimpsushi.github.io/en/posts/2329/</link><pubDate>Sun, 22 Jan 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2329/</guid><description>Definition 1 The following is referred to as the coverage probability for the interval estimator $\left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right]$ of parameter $\theta$. $$ P_{\theta} \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] \right) = P \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] | \theta \right) $$ The infimum of the coverage probability is</description></item><item><title>Interval Estimator</title><link>https://freshrimpsushi.github.io/en/posts/2327/</link><pubDate>Wed, 18 Jan 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2327/</guid><description>Definition 1 For a parameter $\theta \in \mathbb{R}$, the ordered pair $\left( L \left( x_{1} , \cdots , x_{n} \right), U \left( x_{1} , \cdots , x_{n} \right) \right)$ is called an Interval Estimate if it satisfies $L \left( \mathbf{x} \right) \le U \left( \mathbf{x} \right)$ for all $\mathbf{x} \in \mathcal{X}$. The random interval $\left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right]$ is referred to as an Interval</description></item><item><title>Mathematical Definition of Statistical Significance</title><link>https://freshrimpsushi.github.io/en/posts/2304/</link><pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2304/</guid><description>Definition 1 Let&amp;rsquo;s assume that there is a given hypothesis test $H_{0} \text{ vs } H_{1}$. For all realizations $\mathbf{x} \in \Omega$, a test statistic $p \left( \mathbf{X} \right)$ that satisfies $0 \le p \left( \mathbf{x} \right) \le 1$ is called the significance probability or p-value. If $p \left( \mathbf{X} \right)$ satisfies the following for all $\theta \in \Theta_{0}$ and all $\alpha \in [0,1]$, it is said to be valid.</description></item><item><title>Most Powerful Test Containing Sufficient Statistics</title><link>https://freshrimpsushi.github.io/en/posts/2301/</link><pubDate>Sun, 27 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2301/</guid><description>Theorem Hypothesis Testing: $$ \begin{align*} H_{0} :&amp;amp; \theta = \theta_{0} \\ H_{1} :&amp;amp; \theta = \theta_{1} \end{align*} $$ In such hypothesis testing, let us call the probability density function or probability mass function for $\theta_{0}, \theta_{1}$ of sufficient statistic $T$ considering $\theta$ as $g \left( t | \theta_{0} \right), g \left( t | \theta_{1} \right)$. Then, given a rejection region $S$ and a certain constant $k \ge 0$, all hypothesis</description></item><item><title>Calin-Rubin Theorem Proof</title><link>https://freshrimpsushi.github.io/en/posts/2299/</link><pubDate>Wed, 23 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2299/</guid><description>Theorem Hypothesis Testing: $$ \begin{align*} H_{0} :&amp;amp; \theta \le \theta_{0} \\ H_{1} :&amp;amp; \theta &amp;gt; \theta_{0} \end{align*} $$ In such a hypothesis test, $T$ is called a sufficient statistic for $\theta$, and the family $\left\{ g(t | \theta) : \theta \in \Theta \right\}$ of the probability density function or probability mass function of $t$ possesses a Monotone Likelihood Ratio (MLR). Then, for $\forall t_{0}$, $$ H_{0} \text{ is rejected if</description></item><item><title>Definition of Monotonic Probability</title><link>https://freshrimpsushi.github.io/en/posts/2297/</link><pubDate>Sat, 19 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2297/</guid><description>Definition Let&amp;rsquo;s define a family of probability mass functions or probability density functions for a parameter $\theta \in \mathbb{R}$ and a univariate random variable $T$ as $G := \left\{ g ( t | \theta) : \theta \in \Theta \right\}$. If for all $\theta_{2} &amp;gt; \theta_{1}$, $$ {{ g \left( t | \theta_{2} \right) } \over { g \left( t | \theta_{1} \right) }} $$ is a monotonic function in $\left\{</description></item><item><title>Proof of the Neyman-Pearson Lemma</title><link>https://freshrimpsushi.github.io/en/posts/2295/</link><pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2295/</guid><description>Theorem Hypothesis Testing: $$ \begin{align*} H_{0} :&amp;amp; \theta = \theta_{0} \\ H_{1} :&amp;amp; \theta = \theta_{1} \end{align*} $$ In the hypothesis testing above, let $\theta_{0}, \theta_{1}$ have a probability density function or probability mass function denoted by $f \left( \mathbf{x} | \theta_{0} \right), f \left( \mathbf{x} | \theta_{1} \right)$, and let the rejection region be $R$, and some constant $k \ge 0$, then if (i): $f \left( \mathbf{x} | \theta_{1}</description></item><item><title>How to Sample Univariate Probability Variables</title><link>https://freshrimpsushi.github.io/en/posts/2294/</link><pubDate>Sun, 13 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2294/</guid><description>Overview A method for obtaining a specific realization of a random variable. Theorem Let the cumulative distribution function $F = F_{T}$ of a univariate random variable $T$ be an increasing function. Then, for a probability variable $U \sim U \left( 0,1 \right)$ that follows a uniform distribution, the following holds: $$ T = F^{-1} \left( U \right) $$ Explanation Considering that the range of the cumulative distribution function is always</description></item><item><title>Power of a Nuisance Test and the Most Powerful Test</title><link>https://freshrimpsushi.github.io/en/posts/2293/</link><pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2293/</guid><description>Definition 1 Hypothesis Testing: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ A power function $\beta (\theta)$ is said to be unbiased if it satisfies the following for all $\theta_{0} \in \Theta_{0}$ and $\theta_{1} \in \Theta_{0}^{c}$: $$ \beta \left( \theta_{0} \right) \le \beta \left( \theta_{1} \right) $$ Let $\mathcal{C}$ be a set comprising such hypothesis tests. A hypothesis test $A$ that has a</description></item><item><title>Power Function of Hypothesis Testing</title><link>https://freshrimpsushi.github.io/en/posts/2291/</link><pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2291/</guid><description>Definition 1 Hypothesis Testing: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ Given the hypothesis testing above, let&amp;rsquo;s denote it as $\alpha \in [0,1]$. For the parameter $\theta$, the function $\beta (\theta) := P_{\theta} \left( \mathbf{X} \in \mathbb{R} \right)$ with the rejection region $R$ is called the Power Function. If $\sup_{\theta \in \Theta_{0}} \beta (\theta) = \alpha$, then the given hypothesis test is</description></item><item><title>Likelihood Ratio Test Including Sufficient Statistic</title><link>https://freshrimpsushi.github.io/en/posts/2289/</link><pubDate>Thu, 03 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2289/</guid><description>Theorem Hypothesis Testing: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ Likelihood Ratio test statistic: $$ \lambda \left( \mathbf{x} \right) := {{ \sup_{\Theta_{0}} L \left( \theta \mid \mathbf{x} \right) } \over { \sup_{\Theta} L \left( \theta \mid \mathbf{x} \right) }} $$ If $T \left( \mathbf{X} \right)$ is a sufficient statistic for the parameter $\theta$, and $\lambda^{\ast} (t)$ is a likelihood ratio test statistic</description></item><item><title>Definition of Likelihood Ratio Test in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/2287/</link><pubDate>Sun, 30 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2287/</guid><description>Definition 1 $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ For the hypothesis test described above, the statistic $\lambda$ is called the Likelihood Ratio test statistic. $$ \lambda \left( \mathbf{x} \right) := {{ \sup_{\Theta_{0}} L \left( \theta \mid \mathbf{x} \right) } \over { \sup_{\Theta} L \left( \theta \mid \mathbf{x} \right) }} $$ A hypothesis test that has a rejection region $\left\{ \mathbf{x} :</description></item><item><title>Sufficient Statistics and Maximum Likelihood Estimates of the Location Family</title><link>https://freshrimpsushi.github.io/en/posts/2285/</link><pubDate>Wed, 26 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2285/</guid><description>Theorem Given a random sample $X_{1} , \cdots , X_{n} \sim X$ obtained from a location family with the probability density function $f_{X} \left( x ; \theta \right) = f_{X} \left( x - \theta \right)$, the sufficient statistic and maximum likelihood estimator depend on if the support of $X$ is upper bounded, then $\max X_{k}$ if the support of $X$ is lower bounded, then $\min X_{k}$. The support of a</description></item><item><title>Mathematical Statistical Hypothesis Testing Definition</title><link>https://freshrimpsushi.github.io/en/posts/2283/</link><pubDate>Sat, 22 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2283/</guid><description>Definition A proposition about a parameter is called a Hypothesis. The problem of accepting hypothesis $H_{0}$ as true based on a given sample, or rejecting hypothesis $H_{0}$ and adopting hypothesis $H_{1}$ is called a Hypothesis Test. In hypothesis testing, the complementary hypotheses $H_{0}$, $H_{1}$ are called the Null Hypothesis and the Alternative Hypothesis, respectively. The subset $R \subset \Omega$ of the sample space $\Omega$ that leads to the rejection of</description></item><item><title>Random Sample's Sample Mean Average and Variance</title><link>https://freshrimpsushi.github.io/en/posts/2281/</link><pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2281/</guid><description>Formulas Given a random sample $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} X$, the mean and variance of its sample mean $\bar{X}$ are as follows. $$ \begin{align*} E \bar{X} =&amp;amp; E X \\ \Var \bar{X} =&amp;amp; {{ 1 } \over { n }} \Var X \end{align*} $$</description></item><item><title>The Unique Maximum Likelihood Estimator Depends on the Sufficient Statistic</title><link>https://freshrimpsushi.github.io/en/posts/2279/</link><pubDate>Fri, 14 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2279/</guid><description>Theorem If a sufficient statistic $T$ exists for a parameter $\theta$ and a unique maximum likelihood estimator $\hat{\theta}$ for $\theta$ exists, then $\hat{\theta}$ can be represented as a function of $T$. Proof 1 Consider a random sample $X_{1} , \cdots , X_{n}$ with a probability density function $f \left( x ; \theta \right)$ and its sufficient statistic $T := T \left( X_{1} , \cdots , X_{n} \right)$ and probability density</description></item><item><title>Lemmas-Schep Theorem Proof</title><link>https://freshrimpsushi.github.io/en/posts/2277/</link><pubDate>Mon, 10 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2277/</guid><description>Theorem 1 2 A unique unbiased estimator dependent on a complete sufficient statistic exists. That is, for the complete sufficient statistic $T$, if $E \left[ \phi (T) \right] = \tau (\theta)$, then $\phi (T)$ is the unique unbiased estimator for $\tau (\theta)$, namely the best unbiased estimator. Explanation The Lehmann-Scheffé theorem is a powerful theorem that</description></item><item><title>Minimum Variance Unbiased Estimator Uniqueness</title><link>https://freshrimpsushi.github.io/en/posts/2275/</link><pubDate>Thu, 06 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2275/</guid><description>Theorem 1 If $W$ is the Best Unbiased Estimator for $\tau (\theta)$, then $W$ is unique. Proof Cauchy-Schwarz Inequality: For the Random Variable $X, Y$, the following holds: $$ \operatorname{Cov} (X,Y) \le \Var X \Var Y $$ The necessary and sufficient condition for equality to hold is as follows: $$ \exist a \ne 0 , b \in \mathbb{R} : a X + b = Y $$ Assuming $w '$ is</description></item><item><title>Best Unbiased Estimator, Minimum Variance Unbiased Estimator UMVUE</title><link>https://freshrimpsushi.github.io/en/posts/2273/</link><pubDate>Sun, 02 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2273/</guid><description>Definition 1 Let us assume that parameter $\theta$ is given. If an unbiased estimator $W^{\ast}$ satisfies the following condition over all other unbiased estimators $W$, it is called the Best Unbiased Estimator or the Uniform Minimum Variance Unbiased Estimator (UMVUE). $$ \Var_{\theta} W^{\ast} \le \Var_{\theta} W \qquad , \forall \theta $$ Explanation UMVUE is sometimes simply referred to as MVUE, dropping the initial Uniform part. The term UMVUE might be</description></item><item><title>Unbiased Estimators and the Cramér-Rao Bound</title><link>https://freshrimpsushi.github.io/en/posts/2271/</link><pubDate>Wed, 28 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2271/</guid><description>Theorem Regularity Conditions: (R0): The probability density function $f$ is injective with respect to $\theta$. It satisfies the following equation. $$ \theta \ne \theta ' \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta ' \right) $$ (R1): The probability density function $f$ has the same support for all $\theta$. (R2): The true value $\theta_{0}$ is an interior point of $\Omega$. (R3): The probability density function</description></item><item><title>Proof of the Invariance Property of the Maximum Likelihood Estimator</title><link>https://freshrimpsushi.github.io/en/posts/2269/</link><pubDate>Sat, 24 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2269/</guid><description>Theorem The Maximum Likelihood Estimator (MLE) is invariant with respect to transformation of function. In other words, if $\hat{\theta}$ is the MLE of the parameter $\theta$, then for any function $\tau$, $\tau \left( \hat{\theta} \right)$ is also the MLE of $\tau \left( \theta \right)$. Proof 1 Let $\eta := \tau \left( \theta \right)$ and define a new function $L^{\ast}$ for the likelihood function $L = L \left( \theta | \mathbf{x}</description></item><item><title>Satterthwaite Approximation</title><link>https://freshrimpsushi.github.io/en/posts/2267/</link><pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2267/</guid><description>Buildup Let&amp;rsquo;s assume that we have $n$ independent random variables $Y_{k} \sim \chi_{r_{k}}^{2}$, each following a chi-squared distribution with degrees of freedom $r_{k}$. As is well-known, the sum of these, $\sum_{k=1}^{n} Y_{k}$, follows a chi-squared distribution with degrees of freedom $\sum_{k=1}^{n} r_{k}$. This insight can be particularly useful when looking at the denominator of $\displaystyle {{W} \over {\sqrt{V / r}}}$, which follows a t-distribution. Unfortunately, there&amp;rsquo;s an issue when this</description></item><item><title>Location-Scale Family Auxiliary Statistics</title><link>https://freshrimpsushi.github.io/en/posts/2265/</link><pubDate>Fri, 16 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2265/</guid><description>Theorem 1 Let $X_{1} , \cdots , X_{n}$ be a random sample from both a location family and a scale family. If the two statistics $T_{1} \left( X_{1} , \cdots, X_{n} \right)$ and $T_{2} \left( X_{1} , \cdots , X_{n} \right)$ satisfy $$ T_{i} \left( a x_{1} + b , \cdots , a x_{n} + b \right) = a T_{i} \left( x_{1} , \cdots , x_{n} \right) $$ for all</description></item><item><title>The Variance of an Unbiased Estimator Given a Sufficient Statistic is Minimized</title><link>https://freshrimpsushi.github.io/en/posts/2263/</link><pubDate>Mon, 12 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2263/</guid><description>Theorem 1 Let&amp;rsquo;s say we have a parameter $\theta$. $U$ is an unbiased estimator, $T_{1}$ is a sufficient statistic, and $T_{2}$ is a minimal sufficient statistic, defined as follows: $$ \begin{align*} U_{1} :=&amp;amp; E \left( U | T_{1} \right) \\ U_{2} :=&amp;amp; E \left( U | T_{2} \right) \end{align*} $$ it holds that: $$ \Var U_{2} \le \Var U_{1} $$ Explanation Whether $T_{1}$ or $T_{2}$ is given, $U$ being an</description></item><item><title>Complete Statistics of the Exponential Family of Probability Distributions</title><link>https://freshrimpsushi.github.io/en/posts/2261/</link><pubDate>Thu, 08 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2261/</guid><description>Theorem 1 Given a parameter $\mathbf{\theta} = \left( \theta_{1} , \cdots , \theta_{k} \right)$ and the probability density function or probability mass function of a random sample $X_{1} , \cdots , X_{n}$ follows an exponential family distribution as shown below. $$ f(x; \mathbf{\theta}) = h(x) c (\mathbf{\theta}) \exp \left( \sum_{i=1}^{k} w_{i} \left( \theta_{j} \right) t_{i} (x) \right) $$ Then the following statistic $T$ is a complete statistic. $$ T \left(</description></item><item><title>Moment Method</title><link>https://freshrimpsushi.github.io/en/posts/2259/</link><pubDate>Sun, 04 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2259/</guid><description>Definition 1 When the parameters of a given distribution are unknown, the method of forming simultaneous equations for the parameters using moments and considering the solution to these equations as estimates of the parameters is known as the Moment Method. Description The moment method has been a point estimation technique used for a long time since the 1800s by Karl Pearson and others. Although it has not always produced very</description></item><item><title>Proof of Bézout's Theorem</title><link>https://freshrimpsushi.github.io/en/posts/2257/</link><pubDate>Wed, 31 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2257/</guid><description>Theorem If $T \left( \mathbf{X} \right)$ is a complete statistic as well as a minimal sufficient statistic, then $T \left( \mathbf{X} \right)$ is independent of all ancillary statistics. Description Basu&amp;rsquo;s theorem is one of the most important results, among those related to sufficient statistics, allowing for a very strong conclusion that certain statistics are independent. Intuitively, a sufficient statistic contains all the information about a parameter $\theta$, and since ancillary</description></item><item><title>Sufficient Statistic</title><link>https://freshrimpsushi.github.io/en/posts/2255/</link><pubDate>Sat, 27 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2255/</guid><description>Definition 1 Let us define the set of parameters as $\Omega$. The family $\left\{ f \left( t ; \theta \right) : \theta \in \Theta \right\}$ that collects all probability density functions or probability mass functions $f \left( t ; \theta \right)$ of the statistic $T := T \left( \mathbf{X} \right)$ from the sample $\mathbf{X}$, $$ \forall \theta, E_{\theta} g (T) = 0 \implies \forall \theta, P_{\theta} \left( g(T) = 0</description></item><item><title>Scale Families</title><link>https://freshrimpsushi.github.io/en/posts/2253/</link><pubDate>Tue, 23 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2253/</guid><description>Definition The cumulative distribution function $F$ is said to satisfy $F_{\sigma}$ for all $x$ if $F_{\sigma} (x) = F \left( x / \sigma \right)$ holds. $\left\{ F_{\sigma} : \sigma &amp;gt; 0 \right\}$ is called a Scale Family. Example 1 Consider a random sample $X_{1} , \cdots , X_{n}$ with parameter $\sigma$ having a cumulative distribution function $F_{1} (x) = F ( x / 1) = F(x)$, then for the random</description></item><item><title>Location Family</title><link>https://freshrimpsushi.github.io/en/posts/2251/</link><pubDate>Fri, 19 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2251/</guid><description>Definition For a given cumulative distribution function $F$, suppose $F_{\theta}$ satisfies $F_{\theta} (x) = F \left( x - \theta \right)$ for all $x$. $\left\{ F_{\theta} : \theta \in \mathbb{R} \right\}$ is referred to as a Location Family. Example 1 Considering a random sample $X_{1} , \cdots , X_{n}$ with parameter $\theta$ that possesses a cumulative distribution function $F_{0} (x) = F (x - 0) = F(x)$, the sample $Z_{1} ,</description></item><item><title>Auxiliary Statistics</title><link>https://freshrimpsushi.github.io/en/posts/2249/</link><pubDate>Mon, 15 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2249/</guid><description>Definition 1 Let $S$ be a statistic of sample $\mathbf{X}$. If the distribution of $S \left( \mathbf{X} \right)$ does not depend on the parameter $\theta$, it is called an Ancillary Statistic. Description Actually, nobody says ancillary statistic in conversation, they pronounce it as [ancillary statistic]. If a sufficient statistic has all the information about $\theta$, then an ancillary statistic can be thought of as a statistic that has no information</description></item><item><title>Minimum Sufficient Statistic</title><link>https://freshrimpsushi.github.io/en/posts/2247/</link><pubDate>Thu, 11 Aug 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2247/</guid><description>Definition 1 Let $T \left( \mathbf{X} \right)$ be a sufficient statistic. If for every other sufficient statistic $T ' \left( \mathbf{X} \right)$, $T \left( \mathbf{x} \right)$ can be expressed as a function of $T ' \left( \mathbf{x} \right)$, then $T \left( \mathbf{X} \right)$ is called a Minimal Sufficient Statistic. Theorem Let $f \left( \mathbf{x} ; \theta \right)$ be the probability density function or probability mass function of a sample $\mathbf{X}$.</description></item><item><title>Definition of Likelihood Function</title><link>https://freshrimpsushi.github.io/en/posts/2239/</link><pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2239/</guid><description>Definition 1 Let&amp;rsquo;s denote the joint probability density function or probability mass function of a sample $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right)$ as $f(\mathbf{x}|\theta)$. When a realization $\mathbf{x}$ is given, regarding $f(\mathbf{x}|\theta)$ as a function of $\theta$ $$ L \left( \theta | \mathbf{x} \right) := f \left( \mathbf{x} | \theta \right) $$ is called the Likelihood Function. Explanation In the context of discussing maximum likelihood estimators, it</description></item><item><title>Delta Method in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/2237/</link><pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2237/</guid><description>Theorem Let&amp;rsquo;s assume that the constant $\theta \in \mathbb{R}$ and the sequence of random variables $\left\{ Y_{n} \right\}_{n \in \mathbb{N}}$ converge in distribution to a normal distribution $\sqrt{n} \left( Y_{n} - \theta \right)$ following $N \left(0, \sigma^{2} \right)$. $1$-Order Delta Method 1 If $g ' (\theta) \ne 0$ exists, $$ \sqrt{n} \left[ g \left( Y_{n} \right) - g(\theta) \right] \overset{D}{\to} N \left( 0, \sigma^{2} \left[ g ' (\theta) \right]^{2} \right)</description></item><item><title>Statistical Proof of Stirling's Formula</title><link>https://freshrimpsushi.github.io/en/posts/2235/</link><pubDate>Mon, 18 Jul 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2235/</guid><description>정리 $$ \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ 설명 The Stirling approximation, or Stirling&amp;rsquo;s formula, is usefully applied in various fields, including statistics and physics. If one is well-versed in probability theory, the mathematical statistical proof can be more intuitive and easier to understand compared to other proofs. 같이보기 Proof using Gaussian integral</description></item><item><title>Exponential Family of Probability Distributions</title><link>https://freshrimpsushi.github.io/en/posts/2213/</link><pubDate>Sat, 04 Jun 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2213/</guid><description>Definition 1 2 If the probability mass function or probability density function of a probability distribution with parameter $\theta$ can be expressed in terms of some functions $p,K,H,q,h,c,w_{i},t_{i}$ as follows, it is said to belong to the Exponential Family or Exponential Class. $$ \begin{align*} f \left( x ; \theta \right) =&amp;amp; \exp \left( p (\theta) K (x) + H(x) + q(\theta) \right) \\ =&amp;amp; h(x) c (\theta) \exp \left( \sum_{i=1}^{k}</description></item><item><title>Convolution Formula of Probability Density Functions</title><link>https://freshrimpsushi.github.io/en/posts/2211/</link><pubDate>Tue, 31 May 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2211/</guid><description>Formula 1 Given two independent continuous random variables $X, Y$, their probability density functions are given by $f_{X}, f_{Y}$. Then the probability density function of $Z := X + Y$ is the convolution of the two probability density functions $f_{Z} = f_{X} \ast f_{Y}$. $$ f_{Z} (z) = \left( f_{X} \ast f_{Y} \right) (z) = \int_{-\infty}^{\infty} f_{X} (w) f_{Y} (z-w) dw $$ Derivation If we let $W := X$, the</description></item><item><title>Expectation of the Sum of Random Variables in the Form of Functions</title><link>https://freshrimpsushi.github.io/en/posts/2209/</link><pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2209/</guid><description>Theorem 1 Given that $X_{1} , \cdots , X_{n}$ is a random sample, and there exist functions $E g \left( X_{1} \right)$ and $\Var g \left( X_{1} \right)$ such that $g : \mathbb{R} \to \mathbb{R}$ is given, then the following hold: [1] Mean: $$ E \left( \sum_{k = 1}^{n} g \left( X_{k} \right) \right) = n E g \left( X_{1} \right) $$ [2] Variance: $$ \Var \left( \sum_{k = 1}^{n}</description></item><item><title>Rao-Blackwell Theorem Proof</title><link>https://freshrimpsushi.github.io/en/posts/2107/</link><pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2107/</guid><description>Theorem 1 2 Description To put the Rao-Blackwell Theorem into simple terms, it could be summarized as a theorem that &amp;rsquo;tells why sufficient statistics are useful.&amp;rsquo; An unbiased estimator becomes more effective, as in having a reduced variance, when information about the sufficient statistic is provided. Especially if $T$ is the minimum sufficient statistic, then $\phi \left( T \right)$ becomes the best unbiased estimator, as proven by the theorem. Proof</description></item><item><title>Neumann Factorization Theorem Proof</title><link>https://freshrimpsushi.github.io/en/posts/2084/</link><pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2084/</guid><description>Theorem Let&amp;rsquo;s say a random sample $X_{1} , \cdots , X_{n}$ has the same probability mass/density function $f \left( x ; \theta \right)$ for a parameter $\theta \in \Theta$. Statistic $Y = u_{1} \left( X_{1} , \cdots , X_{n} \right)$ is a sufficient statistic for $\theta$ if there exist two non-negative functions $k_{1} , k_{2} \ge 0$ that satisfy the following. $$ f \left( x_{1} ; \theta \right) \cdots f</description></item><item><title>Sufficient Statistic</title><link>https://freshrimpsushi.github.io/en/posts/2061/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2061/</guid><description>Definitions Mathematical Definition 1 Let the probability mass/density function of a random sample $X_{1} , \cdots , X_{n}$ for parameter $\theta \in \Theta$ be $f(x;\theta)$, and let the probability mass/density function for statistic $Y_{1} := u_{1} \left( X_{1} , \cdots , X_{n} \right)$ be $f_{Y_{1}} \left( y_{1}; \theta \right)$. For $H \left( x_{1} , \cdots , x_{n} \right)$, which does not depend on $\theta \in \Theta$, $$ {{ f \left(</description></item><item><title>Efficient Estimator</title><link>https://freshrimpsushi.github.io/en/posts/2059/</link><pubDate>Sat, 31 Jul 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2059/</guid><description>Definition 1 Let&amp;rsquo;s say $Y$ is an unbiased estimator for the parameter $\theta$. The efficiency of estimator $Y$ with respect to the Cramér-Rao lower bound $\text{RC}$ is defined as: $$ {{ \text{RC} } \over { \Var (Y) }} $$ An estimator with efficiency $1$ is called an Efficient Estimator. Description Cramér-Rao Inequality:</description></item><item><title>Rao-Blackwell-Kolmogorov Theorem</title><link>https://freshrimpsushi.github.io/en/posts/2057/</link><pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2057/</guid><description>Theorem 1 Regular Conditions: (R0): The probability density function $f$ is injective with respect to $\theta$. In formula, it satisfies: $$ \theta \ne \theta ' \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta ' \right) $$ (R1): The probability density function $f$ has the same support for all $\theta$. (R2): The true value $\theta_{0}$ is an interior point of $\Omega$. (R3): The probability density function</description></item><item><title>Bartlett's Identity</title><link>https://freshrimpsushi.github.io/en/posts/2055/</link><pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2055/</guid><description>Theorem Regular Conditions: (R0): The probability density function $f$ is injective with respect to $\theta$. Mathematically, it satisfies the following. $$ \theta \ne \theta ' \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta ' \right) $$ (R1): The probability density function $f$ has the same support for all $\theta$. (R2): The true value $\theta_{0}$ is an interior point of $\Omega$. (R3): The probability density function</description></item><item><title>Fisher Information</title><link>https://freshrimpsushi.github.io/en/posts/2034/</link><pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2034/</guid><description>Buildup Score Function Consider a random variable $X$ whose probability density function is $f \left( x ; \theta \right)$ for a parameter $\theta \in \Theta$. The estimator that maximizes the log-likelihood function, known as the maximum likelihood estimator, can be found as $\widehat{\theta}$, which satisfies the following partial differential equation. $$ \sum_{k=1}^{n} {{ \partial \log f \left( x_{k} ; \theta \right) } \over { \partial \theta }} = 0 $$</description></item><item><title>Regularity Conditions in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/2029/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2029/</guid><description>Overview In subjects that utilize mathematics, the term Regularity Conditions usually refers to conditions that allow for a wide range of applications and make theoretical developments more comfortable. In mathematical statistics, they are as follows. Assumptions 1 Consider a random variable $X$ with probability density function $f \left( x ; \theta \right)$ for a parameter $\theta \in \Theta$. The random sample $X_{1} , \cdots , X_{n}$ drawn iid from the</description></item><item><title>Maximum Likelihood Estimator</title><link>https://freshrimpsushi.github.io/en/posts/2026/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2026/</guid><description>Buildup Consider a random variable $X$ with a probability density function (pdf) $f \left( x ; \theta \right)$ for parameter $\theta \in \Theta$. A random sample $X_{1} , \cdots , X_{n}$ drawn identically and independently (iid) from the same distribution as $X$ has the same pdf $f(x ; \theta)$ and realization $\mathbf{x} := \left( x_{1} , \cdots , x_{n} \right)$. The function $L$ defined for this is called the Likelihood</description></item><item><title>Consistent Estimator</title><link>https://freshrimpsushi.github.io/en/posts/2021/</link><pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2021/</guid><description>Definition 1 Let the random variable $X$ have a cumulative distribution function $F ( x ; \theta), \theta \in \Theta$. When $X_{1} , \cdots , X_{n}$ is drawn from $X$, the statistic $T_{n}$ satisfies the following for the parameter $\theta$, it is said to be a Consistent Estimator. $$ T_{n} \overset{P}{\to} \theta \quad \text{as } n \to \infty $$ $\overset{P}{\to}$ is probabilistic convergence. Explanation If the unbiased estimator discusses the</description></item><item><title>Student's t-test Proof</title><link>https://freshrimpsushi.github.io/en/posts/203/</link><pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/203/</guid><description>Theorem 1 If random variables $X_{1} , \cdots , X_{n}$ are iid and follow a normal distribution $N\left( \mu,\sigma^{2} \right)$, then (a): $$ \overline{X} \sim N\left( \mu , { {\sigma^2} \over {n} } \right) $$ (b): $$ \overline{X} \perp S^2 $$ (c): $$ (n-1) { {S^2} \over {\sigma^2} } \sim \chi^2 (n-1) $$ (d): $$ T = { {\overline{X} - \mu } \over {S / \sqrt{n}} } \sim t(n-1) $$</description></item><item><title>Distribution Convergence of Multivariate Random Variables</title><link>https://freshrimpsushi.github.io/en/posts/2009/</link><pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2009/</guid><description>Definition1 When a $p$-dimensional random vector $\mathbf{X}$ and the sequence of random vectors $\left\{ \mathbf{X}_{n} \right\}$ satisfies the following condition for $n \to \infty$, it is said that $\mathbf{X}_{n}$ converges in distribution to $\mathbf{X}$, denoted as $\mathbf{X}_{n} \overset{D}{\to} \mathbf{X}$. $$\lim_{n \to \infty} F_{\mathbf{X}_{n}} (x) = F_{\mathbf{X}} (x) \qquad, \forall x \in C_{F_{\mathbf{X}}}$$ $F_{X}$ is the cumulative distribution function of the random variable $X$. $C_{F_{\mathbf{X}}}$ represents the set of points where</description></item><item><title>Multivariate Random Variables Probability Convergence</title><link>https://freshrimpsushi.github.io/en/posts/1952/</link><pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1952/</guid><description>Definition 1 $p$-dimensional random vector $\mathbf{X}$ and a sequence of random vectors $\left\{ \mathbf{X}_{n} \right\}$ are said to converge in probability to $n \to \infty$ as $\mathbf{X}_{n}$ if they satisfy the following. It is denoted by $\mathbf{X} _ {n} \overset{P}{\to} \mathbf{X}$. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left\| \mathbf{X}_{n} - \mathbf{X} \right\| &amp;lt; \varepsilon \right] = 1 $$ $\| \cdot \|$ is defined as the</description></item><item><title>Covariance Matrix</title><link>https://freshrimpsushi.github.io/en/posts/1950/</link><pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1950/</guid><description>Definition1 $p$ For a dimensional random vector $\mathbf{X} = \left( X_{1}, \cdots , X_{p} \right)$, the following defined ▶eq03◀ is called the covariance matrix. $$ \left( \operatorname{Cov} \left( \mathbf{X} \right) \right)_{ij} := \operatorname{Cov} \left( X_{i} , X_{j} \right) $$ $\operatorname{Cov}$ is covariance. Explanation To put the definition more simply, it can be stated as follows: $$ \operatorname{Cov} \left( \mathbf{X} \right) := \begin{pmatrix} \Var \left( X_{1}</description></item><item><title>Central Limit Theorem Proof</title><link>https://freshrimpsushi.github.io/en/posts/43/</link><pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/43/</guid><description>Theorem 1 If $\left\{ X_{k} \right\}_{k=1}^{n}$ are iid random variables following the probability distribution $\left( \mu, \sigma^2 \right) $, then when $n \to \infty$ $$ \sqrt{n} {{ \overline{X}_n - \mu } \over {\sigma}} \overset{D}{\to} N (0,1) $$ $\overset{D}{\to}$ means convergence in distribution. Explanation This theorem is widely acclaimed in statistics, along with the Law of Large Numbers. Despite being frequently discussed and applied, many encounter its proof only upon studying</description></item><item><title>Proof of the Weak Law of Large Numbers</title><link>https://freshrimpsushi.github.io/en/posts/32/</link><pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/32/</guid><description>Law Given $\left\{ X_{k} \right\}_{k=1}^{n}$ are iid random variables with distribution $\left( \mu, \sigma^2 \right) $, then when $n \to \infty$ $$ \overline{X}_n \overset{P}{\to} \mu $$ $\overset{P}{\to}$ means convergence in probability. Explanation Ranked among the most important theorems in statistics, alongside the Central Limit Theorem. This theorem implies that no matter the distribution, &amp;rsquo;the sample mean converges to the population mean&amp;rsquo;. While this might seem obvious, in natural sciences, the</description></item><item><title>Convergence in Distribution Implies Probability Bound</title><link>https://freshrimpsushi.github.io/en/posts/176/</link><pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/176/</guid><description>Theorem A sequence of random variables $\left\{ X_{n} \right\}$ is probabilistically bounded if it converges in distribution. $\overset{D}{\to}$ means convergence in distribution. Explanation Since we have shown that convergence almost surely implies convergence in distribution, by considering the contrapositive proposition, we can also obtain the common-sense corollary that &amp;lsquo;if it is not probabilistically bounded, it does not converge almost surely&amp;rsquo;. Proof Given $\epsilon&amp;gt;0$ and assuming that $X_{n}$ converges in distribution</description></item><item><title>Convergence in Probability Implies Convergence in Distribution</title><link>https://freshrimpsushi.github.io/en/posts/175/</link><pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/175/</guid><description>Theorem1 Given a random variable $X$ and its sequence $\left\{ X_{n} \right\}$, $$ X_{n} \overset{P}{\to} X \implies X_{n} \overset{D}{\to} X $$ $\overset{P}{\to}$ denotes convergence in probability. $\overset{D}{\to}$ denotes convergence in distribution. Explanation In simpler terms, it’s much easier to have convergence in distribution than exact convergence. Understanding a random variable as a function in its own right should make this concept not too difficult to grasp. Proof</description></item><item><title>Probability Bounds in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1922/</link><pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1922/</guid><description>Definition 1 Let&amp;rsquo;s assume that a sequence of random variables $\left\{ X_{n} \right\}$ is given. If for all $\varepsilon &amp;gt; 0$, there exists a $N_{\varepsilon} \in \mathbb{N}$ and a constant $B_{\varepsilon} &amp;gt; 0$ such that the following is satisfied, then $\left\{ X_{n} \right\}$ is said to be Bounded in Probability. $$ n \ge N_{\varepsilon} \implies P \left[ \left| X_{n} \right| \le B_{\varepsilon} \right] \ge 1 - \varepsilon $$ Explanation If</description></item><item><title>Convergence of Distributions in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1888/</link><pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1888/</guid><description>Definition 1 Given a random variable $X$ and a sequence of random variables $\left\{ X_{n} \right\}$, if the following condition is satisfied when $n \to \infty$, we say that $X$ converges in distribution to $X_{n}$ and represent it as $X_{n} \overset{D}{\to} X$. $$ \lim_{n \to \infty} F_{X_{n}} (x) = F_{X} (x) \qquad, \forall x \in C_{F_{X}} $$ $F_{X}$ is the cumulative distribution function of the random variable $X$. $C_{F_{X}}$ represents</description></item><item><title>Probability Convergence in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1789/</link><pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1789/</guid><description>Definition 1 A random variable $X$ and a sequence of random variables $\left\{ X_{n} \right\}$ are said to converge in probability to $X$ as $n \to \infty$ if they satisfy the following, and it is denoted by $X_{n} \overset{P}{\to} X$. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left| X_{n} - X \right| &amp;lt; \varepsilon \right] = 1 $$ Explanation The condition for convergence in probability is</description></item><item><title>Order Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1757/</link><pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1757/</guid><description>Theorem1 Let&amp;rsquo;s say that a random sample $X_{1} , \cdots , X_{n}$ has a probability density function $f(x)$ with support $\mathcal{S} =(a,b)$, following a continuous probability distribution. If we arrange these according to their size as $Y_{1} &amp;lt; \cdots &amp;lt; Y_{n}$, then their joint and marginal probability density functions are as follows: [1] Joint: $$ g \left( y_{1} , \cdots , y_{n} \right) = \begin{cases} n! f (y_{1}) \cdots f</description></item><item><title>Reason for Dividing the Sample Variance by n-1</title><link>https://freshrimpsushi.github.io/en/posts/1747/</link><pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1747/</guid><description>Why divide by n-1? If we denote it as $X_{i} \sim \left( \mu , \sigma^{2} \right)$, the sample variance $S^{2}$ can be represented as follows. $$ S^{2} := {{1} \over {n-1}} \sum_{i=1}^{n} \left( X_{i} - \overline{X} \right)^{2} $$ As is well known, unlike the sample mean, the sample variance sums up the squares of the deviations and then divides not by the sample size $n$, but by $n-1$. While I</description></item><item><title>Unbiased Estimator</title><link>https://freshrimpsushi.github.io/en/posts/1745/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1745/</guid><description>Definition 1 If the estimator $T$ of $\theta$ satisfies the following, then $T$ is called the unbiased estimator of $\theta$. $$ E T = \theta $$ Explanation Especially, among the unbiased estimators for $\theta$, the one with the smallest variance is called the minimum variance unbiased estimator. Unbiasedness refers to the property of not having any bias. For example, when we assume $X_{i} \sim \left( \mu , \sigma^{2} \right)$, if</description></item><item><title>Convenience-Variance Trade-off</title><link>https://freshrimpsushi.github.io/en/posts/1739/</link><pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1739/</guid><description>Definition $$ \text{MSE} \left( \widehat{\theta} \right) = \Var \widehat{\theta} + \left( \text{Bias} \widehat{\theta} \right)^{2} $$ Description Mean Squared Error (MSE) $\text{MSE}$ is frequently used as a measure for evaluating statistical models or as a loss function in machine learning, represented especially in terms of trade-offs between bias and variance. Handling bias may seem somewhat uncomfortable for a statistician. While dealing with variance feels almost tangible, based on the assumption of</description></item><item><title>Convenience in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1735/</link><pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1735/</guid><description>Definition A bias $\text{Bias}$ is defined as follows for an estimator $\widehat{\theta}$ of a parameter $\theta$. $$ \text{Bias} ( \theta ) = E(\widehat{\theta}) - \theta $$ Description While the term Bias can be purified into bias or tendency, the most commonly used term is Bias, pronounced as it is. In Korean, &amp;ldquo;편의(Convenien</description></item><item><title>Easy Definition of Confidence Intervals</title><link>https://freshrimpsushi.github.io/en/posts/1732/</link><pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1732/</guid><description>Definition 1 Let the probability density function $f (x; \theta)$ of the random variable $X$ and the samples $X_{1} , \cdots , X_{n}$ with a Confidence Coefficient $\alpha \in (0,1)$ be given. $$ L := L \left( X_{1} , \cdots , X_{n} \right) \\ U := U \left( X_{1} , \cdots , X_{n} \right) $$ It is said that the statistic $L &amp;lt; U$ is defined as above, then the</description></item><item><title>Statistical Measures and Estimators in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1730/</link><pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1730/</guid><description>Definition 1 2 A function $T$ of a sample $X_{1} , \cdots , X_{n}$ from a random variable $X$ is called a Statistic. $$ T := T \left( X_{1} , \cdots , X_{n} \right) $$ When the distribution function of $X$ is expressed as $f(x; \theta)$ or $p(x; \theta)$, if $T$ serves to capture $\theta$, then $T$ is referred to as an Estimator of $\theta$. The probability distribution of a</description></item><item><title>Random Sampling in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1715/</link><pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1715/</guid><description>Definitions 1 The actual outcome of a random variable $X$ is called its realization and is usually represented by the lowercase letter $x$. A set of random variables from the same probability distribution as $X$, with a sample size of $n$, is called a sample, represented as follows: $$ X_{1} , X_{2} , \cdots , X_{n} $$ If the random variable $X_{1} , \cdots , X_{n}$ is iid, then a</description></item><item><title>Linear Combinations of Random Variables</title><link>https://freshrimpsushi.github.io/en/posts/1479/</link><pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1479/</guid><description>Definition 1 Let $X_{1} , \cdots , X_{n}$ be given as a random variable. For some $(a_{1}, \cdots , a_{n}) \in \mathbb{R}^{n}$, $\displaystyle T := \sum_{i=1}^{n} a_{i} X_{i}$ is referred to as Linear Combinations. Hogg et al. (2013). Introduction to Mathematical Statistcs(7th Edition): p136.&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>The Equivalence Between Two Normally Distributed Random Variables Being Independent and Having a Covariance of Zero</title><link>https://freshrimpsushi.github.io/en/posts/591/</link><pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/591/</guid><description>Theorem $$ X_{1} \sim N ( \mu_{1} , \sigma_{1} ) \\ X_{2} \sim N ( \mu_{2} , \sigma_{2} ) $$ Surface $$ X_{1} \perp X_{2} \iff \text{cov} (X_{1} , X_{2} ) = 0 $$ Description Generally, being uncorrelated does not imply independence. However, if there is an assumption that the distributions follow a normal distribution, then having a covariance of $0$ guarantees independence. Proof $( \implies )$ $$ M_{X_{1}} (t_{1}</description></item><item><title>Bernstein Distributions: Pairwise Independence Does Not Imply Mutual Independence</title><link>https://freshrimpsushi.github.io/en/posts/206/</link><pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/206/</guid><description>Definition For $(x,y,z) \in \left\{ (1,0,0), (0,1,0), (0,0,1), (1,1,1) \right\}$, the distribution with the following probability mass function is called the Bernstein Distribution. $$ p(x,y,z) = {{1} \over {4} } $$ Explanation Although the Bernstein Distribution satisfies all the conditions for a distribution, it is hard to consider it as a distribution that actually exists in nature. It is presented as a counterexample to the proposition that &amp;lsquo;if pairs are</description></item><item><title>Independence and iid of Random Variables</title><link>https://freshrimpsushi.github.io/en/posts/1469/</link><pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1469/</guid><description>Definition 1 A random variable $X_{1} , \cdots , X_{n}$ is said to be pairwise independent if it satisfies the following. $$ i \ne j \implies X_{i} \perp X_{j} $$ A continuous random variable $X_{1} , \cdots , X_{n}$ whose joint probability density function $f$ satisfies the condition with respect to each of its probability density functions $f_{1} , \cdots , f_{n}$ is said to be mutually independent. $$ f(x_{1}</description></item><item><title>Probability Variables Independence in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1461/</link><pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1461/</guid><description>Definition 1 If for two random variables $X_{1}, X_{2}$, the joint probability density function $f$ or the probability mass function $p$ satisfies the following conditions for the probability density functions $f_{1}, f_{2}$ or the probability mass functions $p_{1}, p_{2}$ of $X_{1}, X_{2}$, then $X_{1}, X_{2}$ are said to be independent, and is denoted as $X_{1} \perp X_{2}$. $$ f(x_{1} , x_{2} ) \equiv f_{1}(x_{1})f_{2}(x_{2}) \\ p(x_{1} , x_{2} ) \equiv</description></item><item><title>Probability Distributions under Conditional Probability in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1458/</link><pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1458/</guid><description>Definition1 For a discrete random vector $(X, Y)$, let $p_{X, Y}$ be the joint probability mass function of $(X, Y)$. Let $p_{X}$ be the marginal probability mass function of $X$. In this case, the following $p_{Y | X}$, given $Y = y$, is called the conditional probability mass function of $X$. $$ p_{Y | X} (y | x) = \dfrac{p_{X, Y}(x, y)}{p_{X}(x)} $$ For a continuous random vector $(X, Y)$,</description></item><item><title>Transformation of Multivariate Random Variables</title><link>https://freshrimpsushi.github.io/en/posts/1455/</link><pubDate>Fri, 17 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1455/</guid><description>Formulas The joint probability density function of a multivariate random variable $X = ( X_{1} , \cdots , X_{n} )$, given by $f$, is assumed to be as follows: $$ y_{1} = u_{1} (x_{1} , \cdots , x_{n}) \\ \vdots \\ y_{n} = u_{n} (x_{1} , \cdots , x_{n}) $$ Consider the following transformation $u_{1} , \cdots , u_{n}$, which might not be injective. Thus, the support $X$ of $S_{X}$</description></item><item><title>Multivariate Probability Distributions in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1449/</link><pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1449/</guid><description>Definition 1 A Random Vector is defined as $X = (X_{1} , \cdots , X_{n})$ for $n$ number of probability variables $X_{i}$ defined in sample space $\Omega$. The range $X(\Omega)$ of $X$ is also called a space. A function that satisfies the following $F_{X} : \mathbb{R}^{n} \to [0,1]$ is called the Joint Cumulative Distribution Function of $X$. $$ F_{X}\left( x_{1}, \cdots , x_{n} \right) := P \left[ X_{1} \le x_{1}</description></item><item><title>If an nth Moment Exists, Moments of Lower Orders than n Also Exist</title><link>https://freshrimpsushi.github.io/en/posts/247/</link><pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/247/</guid><description>Theorem If there exists $E( X^n )$ for a random variable $X$ and a natural number $n$, then $E( X^m ), m=1,2,3,\cdots, n$ also exists. Description Regardless of the degree, if a certain moment exists, moments of lower degrees always exist, although naturally the converse is not true. Of course, in practice, it is rare for higher-order moments to be given first, but this theorem does save a significant amount</description></item><item><title>What is the Moment Generating Function?</title><link>https://freshrimpsushi.github.io/en/posts/248/</link><pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/248/</guid><description>Definition 1 For a random variable $X$ and some positive number $h&amp;gt;0$, if $E(e^{tX})$ exists in $-h&amp;lt; t &amp;lt; h$, then $M(t) = E( e^{tX} )$ is defined as the Moment Generating Function of $X$. Explanation The moment generating function (mgf) is a concept often encountered relatively early in mathematical statistics, yet its unfamiliar definition and seemingly contextless introduction can make it a source of dislike for the subject. The</description></item><item><title>Kurtosis in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1271/</link><pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1271/</guid><description>Kurtosis Given a random variable $X$ with mean $\mu$ and variance $\sigma^2$, the kurtosis of $X$ is defined as follows: $$ \gamma_{2} := {{ E \left( X - \mu \right)^4 } \over { \sigma^4 }} $$ For data $\left\{ X_{i} \right\}_{i}^{n}$, with sample mean $\overline{X}$ and sample variance $\widehat{\sigma}^2$, sample kurtosis $g_{2}$ is obtained as follows: $$ g_{2} := \sum_{i=1}^{n} {{ \left( X - \overline{X} \right)^4 } \over { n</description></item><item><title>Skewness in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1268/</link><pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1268/</guid><description>Definition When the mean of a random variable $X$ is $\mu$, and its variance is $\sigma^2$, the following defined $\gamma_{1}$ is called the Skewness of $X$. $$ \gamma_{1} := {{ E \left( X - \mu \right)^3 } \over { \sigma^3 }} $$ When the sample mean of data $\left\{ X_{i} \right\}_{i}^{n}$ is $\overline{X}$, and the sample variance is $\widehat{\sigma}^2$, the sample skewness $g_{1}$ is calculated as follows. $$ g_{1} :=</description></item><item><title>Pearson Correlation Coefficient</title><link>https://freshrimpsushi.github.io/en/posts/57/</link><pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/57/</guid><description>Definition 1 For two random variables $X, Y$, the term $\rho = \rho (X,Y)$ defined as follows is called the Pearson correlation coefficient. $$ \rho = { {\operatorname{Cov} (X,Y)} \over {\sigma_X \sigma_Y} } $$ $\sigma_{X}$ and $\sigma_{Y}$ are the standard deviations of $X$ and $Y$, respectively. Explanation The (Pearson) Correlation coefficient is a measure used to determine whether two variables have a (linear) correlation. If it is close to $1$</description></item><item><title>Various Properties of Covariance</title><link>https://freshrimpsushi.github.io/en/posts/425/</link><pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/425/</guid><description>Definitions and Properties The covariance of probability variables $X$ and $Y$, whose means are $\mu_{X}$ and $\mu_{Y}$ respectively, is defined as $\operatorname{Cov} (X ,Y) : = E \left[ ( X - \mu_{X} ) ( Y - \mu_{Y} ) \right]$. Covariance has the following properties: [1]: $\Var (X) = \operatorname{Cov} (X,X)$ [2]: $\operatorname{Cov} (X,Y) = \operatorname{Cov} (Y, X)$ [3]: $\Var (X + Y) = \Var (X) + \Var (Y) + 2</description></item><item><title>Properties of Mean and Variance</title><link>https://freshrimpsushi.github.io/en/posts/424/</link><pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/424/</guid><description>Theorem The mean $E ( X ) = \mu_{X}$ and variance $\Var (X) = E [ ( X - \mu_{X} )^2 ]$ have the following properties: [1]: $E(X + Y) = E(X) + E(Y)$ [2]: $E(aX + b) = a E(X) + b$ [3]: $\Var (X) \ge 0$ [4]: $\Var ( X ) = E(X^2) - \mu_{X}^2$ [5]: $\Var (aX + b) = a^2 \Var (X)$ Explanation As they relate</description></item><item><title>Mathematical Proof of the Properties of Representative Values</title><link>https://freshrimpsushi.github.io/en/posts/49/</link><pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/49/</guid><description>Theorem Let&amp;rsquo;s assume that we have given data $X = \left\{ x_{1} , \cdots , x_{n} \right\}$. [0]: The $\theta$ that minimizes $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{0}$ is $$ \argmin_{\theta} h \left( \theta \right) = \text{mode}(X) $$ [1]: The $\theta$ that minimizes $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{1}$ is $$ \argmin_{\theta} h \left( \theta \right) = \text{median}(X) $$ [2]: The $\theta$ that minimizes $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{2}$ is $$ \argmin_{\theta}</description></item><item><title>Expectation, Mean, Variance, and Moments in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/246/</link><pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/246/</guid><description>Definition: Expectation, Mean, and Variance Let&amp;rsquo;s assume that we have a given random variable $X$. If the probability density function $f(x)$ of a continuous random variable $X$ satisfies $\displaystyle \int_{-\infty}^{\infty} |x| f(x) dx &amp;lt; \infty$, then $E(X)$, defined as follows, is called the Expectation of $X$. $$ E(X) := \int_{-\infty}^{\infty} x f(x) dx $$ If the probability mass function $p(x)$ of a discrete random variable $X$ satisfies $\displaystyle \sum_{x} |x|</description></item><item><title>Probability Variables and Probability Distribution in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1433/</link><pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1433/</guid><description>Definition 1 Let us assume that probability $P$ is defined in the sample space $\Omega$. A function $X : \Omega \to \mathbb{R}$ whose domain is the sample space is called a Random Variable. The range $X(\Omega)$ of a random variable is also called its Space. A function $F_{X} : \mathbb{R} \to [0,1]$ that satisfies the following is called the Cumulative Distribution Function (cdf) of $X$. $$ F_{X}(x) = P_{X}\left( (-\infty,x]</description></item><item><title>Probability and the Addition Law of Probability in Mathematical Statistics</title><link>https://freshrimpsushi.github.io/en/posts/1431/</link><pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1431/</guid><description>Definition 1 An experiment that can be repeated under the same conditions is referred to as a Random Experiment. The set $\Omega$ of all possible outcomes that can be obtained from a random experiment is called the Sample Space. The set of outcomes in the sample space that we are interested in, i.e., $B \subset \Omega$ is called an Event, and these sets are represented as $\mathcal{B}$. A function $P</description></item><item><title>Hypothesis Testing Through Bayesian Factors</title><link>https://freshrimpsushi.github.io/en/posts/782/</link><pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/782/</guid><description>Buildup To be able to use classical hypothesis testing, one must have a mathematical understanding of concepts such as rejection region, p-value, and even a statistical sense intuitive enough to understand them. It is no surprise that many students, even at the freshman college level, spend hours being taught and still fail to properly understand hypothesis testing. It is similar to how many students learn statistics in high school, find</description></item><item><title>Highest Posterior Density Credible Interval</title><link>https://freshrimpsushi.github.io/en/posts/769/</link><pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/769/</guid><description>Definition 1 A subset $C \subset \Theta$ of the parameter space $\Theta$ is called the Highest Posterior Density (HPD) Credible Interval for $100(1 - \alpha) % $ given the data $y$ at the significance level $\alpha$ if it satisfies $C : = \left\{ \theta \in \Theta \ | \ p ( \theta | y ) \ge k (\alpha) \right\}$. Here $k(\alpha)$ is the largest constant that satisfies $p(\theta \in C</description></item><item><title>Differences between Credit Intervals and Confidence Intervals</title><link>https://freshrimpsushi.github.io/en/posts/752/</link><pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/752/</guid><description>Theorem The difference between a credence interval and a confidence interval can indeed be considered the difference between Bayesian and frequentist approaches. Confidence Interval (Frequentist): The parameter is a fixed constant and the confidence interval is randomly determined. Credence Interval (Bayesian): The parameter is a variable with a distribution, and the credence interval is also determined from the posterior distribution. Confidence Interval In classical statistics, what a confidence interval $[a</description></item><item><title>Confidence Intervals</title><link>https://freshrimpsushi.github.io/en/posts/741/</link><pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/741/</guid><description>Definition 1 When a subset $C \subset \Theta$ of the parameter space $\Theta$ satisfies $P ( \theta \in C | y ) \ge 1 - \alpha$ for a significance level $\alpha$, $C$ is called the Credible Interval for $\theta$ given data $y$. Explanation Interval estimation in Bayesian statistics is about finding intervals that are highly probable to contain the parameter $\theta$. The &amp;lsquo;Credible Interval&amp;rsquo; found in this manner corresponds to</description></item><item><title>Three Representative Values of Statistics: Mode, Median, Average</title><link>https://freshrimpsushi.github.io/en/posts/740/</link><pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/740/</guid><description>Overview Measures of central tendency are statistics that summarize the data by identifying the central position within a data set. Even when dealing with thousands or millions of data points, it&amp;rsquo;s often not practical or necessary to examine each one individually. Instead, what&amp;rsquo;s important is understanding what the data represents, and measures of central tendency effectively condense this information. The three most commonly used measures of central tendency are mode,</description></item><item><title>Jeffreys Prior Distribution</title><link>https://freshrimpsushi.github.io/en/posts/716/</link><pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/716/</guid><description>Definitions 1 The distribution $p( y | \theta)$ is called the Jeffreys prior for $\pi ( \theta ) \propto I^{1/2} ( \theta )$. $I$ refers to the Fisher information. $$ I ( \theta ) = E \left[ \left( \left. {{\partial \ln p (y | \theta) } \over {\partial \theta}} \right)^2 \right| \theta \right] = E \left[ \left. - {{\partial^2 \ln p (y | \theta) } \over { (\partial \theta )^2</description></item><item><title>Laplace Prior Distribution</title><link>https://freshrimpsushi.github.io/en/posts/714/</link><pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/714/</guid><description>Buildup If there&amp;rsquo;s almost no information about the parameter, there&amp;rsquo;s no reason to consider a complex prior distribution: Example 1: If someone with a fair understanding of statistics is asked to guess the gender ratio of incoming freshmen for a certain university&amp;rsquo;s statistics department next year, they might make a reasonable guess based on the gender ratios in previous years. However, if someone with no relation or interest in the</description></item><item><title>Conjugate Prior Distribution</title><link>https://freshrimpsushi.github.io/en/posts/712/</link><pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/712/</guid><description>Definition 1 If the prior and posterior distributions belong to the same family of distributions, the prior distribution is referred to as a Conjugate Prior. Explanation Even though Bayesian analysis is essentially about finding the parameters through updates regardless of the initial prior, using an appropriate prior can greatly simplify the mathematical computations and make the results easier to understand if there is some knowledge about the model. (1) The</description></item><item><title>Laplace's Succession Rule</title><link>https://freshrimpsushi.github.io/en/posts/710/</link><pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/710/</guid><description>Theorem 1 Let&amp;rsquo;s say the prior distribution of the binomial model $\displaystyle p(y | \theta) = \binom{ n }{ y} \theta^{y} (1- \theta)^{n-y}$ follows a uniform distribution $U (0,1)$ and the posterior distribution follows a beta distribution $\beta (y+1 , n-y+1)$, hence $p( \theta | y ) \sim \theta^{y} (1- \theta)^{n-y}$. Then, for the data obtained so far $y$, the probability of observing a new $\tilde{y}$ being $1$ is $$</description></item><item><title>Bayesian Paradigm</title><link>https://freshrimpsushi.github.io/en/posts/702/</link><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/702/</guid><description>Buildup Statistics can be defined as the study of methods to understand parameters. Just like measuring a physical quantity using formulas or laws, it would be ideal if parameters can be precisely estimated. However, due to the impractical nature of such precision, assumptions and samples are used to find &amp;lsquo;what is expected to be the parameter&amp;rsquo;. If interested in the average height of men in our country $X$, one might</description></item><item><title>Viewing the Monty Hall Dilemma through Bayes' Theorem</title><link>https://freshrimpsushi.github.io/en/posts/697/</link><pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/697/</guid><description>Explanation As is well known, in the Monty Hall problem it is advantageous to switch regardless of where the prize actually is. Setting aside whether one accepts this as a fact, there are people who do not grasp the Monty Hall game intuitively or who are uncomfortable with algebraic expressions. For convenience, imagine you are the player and you have chosen door 1. At this point we have no information</description></item><item><title>Differences between the Monte Carlo Method and Bootstrapping</title><link>https://freshrimpsushi.github.io/en/posts/551/</link><pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/551/</guid><description>Overview Monte Carlo methods involve repeating simulations with arbitrary data to test new techniques, while bootstrapping involves resampling from actual data to solve problems more cost-effectively. Definitions Monte Carlo Method is a method of finding point estimates for a target by drawing random samples. Bootstrap is a method that involves resampling from a sample to understand the distribution of a target. Explanation The primary confusion may come from the fact</description></item><item><title>Sample Standard Deviation and Standard Error Distinguished</title><link>https://freshrimpsushi.github.io/en/posts/541/</link><pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/541/</guid><description>Definition Let&amp;rsquo;s call the data obtained from $X$ as $\mathbf{x} = ( x_{1}, x_{2}, \cdots , x_{n} )$. Sample Mean: $$ \overline{x} = {{1} \over {n}} \sum_{i=1}^{n} x_{i} $$ Sample Standard Deviation: $$ s_{x} = \sqrt { {{1} \over {n-1}} \sum_{i=1}^{n} ( x_{i} - \overline{x} )^2 } $$ Standard Error: $$ \text{s.e.} \left( \overline{X} \right) = {{ s_{x} } \over { \sqrt{n} }} $$ Explanation Because the terms sound similar,</description></item><item><title>Independence Does Not Imply No Correlation</title><link>https://freshrimpsushi.github.io/en/posts/536/</link><pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/536/</guid><description>Description If variables are independent, it means there is no correlation, but lack of correlation does not necessarily imply independence. The case when variables are independent if there is no correlation, that is when it is a necessary and sufficient condition, is when the random variables follow a normal distribution. In the case on the left, there is positive correlation, and in the case on the right, there is negative</description></item><item><title>Summation Summary of Random Variables Following a Specific Distribution</title><link>https://freshrimpsushi.github.io/en/posts/202/</link><pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/202/</guid><description>Theorem Let&amp;rsquo;s say the random variables $X_{1} , \cdots , X_{n}$ are mutually independent. [1] Binomial distribution: If $X_i \sim \text{Bin} ( n_{i}, p)$, then $$ \sum_{i=1}^{m} X_{i} \sim \text{Bin} \left( \sum_{i=1}^{m} n_{i} , p \right) $$ [2] Poisson distribution: If $X_i \sim \text{Poi}( m_{i} )$, then $$ \sum_{i=1}^{n} X_{i} \sim \text{Poi} \left( \sum_{i=1}^{n} m_{i} \right) $$ [3] Gamma distribution: If $X_i \sim \Gamma ( k_{i}, \theta)$, then $$ \sum_{i=1}^{n}</description></item><item><title>Proof of Bayes' Theorem and Prior, Posterior Distributions</title><link>https://freshrimpsushi.github.io/en/posts/29/</link><pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/29/</guid><description>Theorem 1 Sample Space $S$ and Event $A$, Probability $P$ If $\left\{ S_1, S_2, \cdots ,S_n \right\}$ is a partition of $S$, then the following holds. $$ P(S_k|A)=\frac { P(S_k)P(A|S_k) }{ \sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$ Definition The right-hand side of Bayes&amp;rsquo; theorem, $P \left( S_{k} \right)$, is called the Prior Probability, and the left-hand side, $P \left( S_{k} | A \right)$, is called the</description></item></channel></rss>