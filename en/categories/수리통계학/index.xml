<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>수리통계학 on FreshrimpRestaurant</title>
    <link>https://freshrimpsushi.github.io/en/categories/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99/</link>
    <description>Recent content in 수리통계학 on FreshrimpRestaurant</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 31 Oct 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://freshrimpsushi.github.io/en/categories/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Definition of Weighted Average</title>
      <link>https://freshrimpsushi.github.io/en/posts/2470/</link>
      <pubDate>Tue, 31 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2470/</guid>
      <description>Definition The following is called the Weighted Mean for data $\mathbf{x} = \left\{ x_{1} , \cdots , x_{n} \right\}$ and vector $\mathbf{w} = \left( w_{1} , \cdots , w_{n} \right) \in \mathbb{R}^{n}$. $$ {{ \sum_{k=1}^{n} w_{k} x_{k} } \over { \sum_{k=1}^{n} w_{k} }} = {{ w_{1} x_{1} + \cdots + w_{n} x_{n} } \over { w_{1} + \cdots + w_{n} }} $$ Meanwhile, $\mathbf{w}$ is also called a weighted vector</description>
    </item>
    <item>
      <title>Standard Definition of Standard Error</title>
      <link>https://freshrimpsushi.github.io/en/posts/2462/</link>
      <pubDate>Sun, 15 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2462/</guid>
      <description>Definition 1 For a given estimator $T$, the estimated standard deviation of $T$ is called the standard error. $$ \text{s.e.} \left( T \right) := \sqrt{ \widehat{ \text{Var} \left( T \right) } } $$ Explanation The reason why it is precisely defined as an estimator in the definition, not a statistic, is because the standard error becomes meaningless unless we are discussing whether it &amp;lsquo;matches or not&amp;rsquo; with the parameter $\theta$</description>
    </item>
    <item>
      <title>Definition of a Mathematical-Statistical Confidence Set</title>
      <link>https://freshrimpsushi.github.io/en/posts/2329/</link>
      <pubDate>Sun, 22 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2329/</guid>
      <description>Definition 1 The following is referred to as the coverage probability for the interval estimator $\left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right]$ of parameter $\theta$. $$ P_{\theta} \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] \right) = P \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] | \theta \right) $$ The infimum of the coverage probability is</description>
    </item>
    <item>
      <title>Power of a Nuisance Test and the Most Powerful Test</title>
      <link>https://freshrimpsushi.github.io/en/posts/2293/</link>
      <pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2293/</guid>
      <description>Definition 1 Hypothesis Testing: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ A power function $\beta (\theta)$ is said to be unbiased if it satisfies the following for all $\theta_{0} \in \Theta_{0}$ and $\theta_{1} \in \Theta_{0}^{c}$: $$ \beta \left( \theta_{0} \right) \le \beta \left( \theta_{1} \right) $$ Let $\mathcal{C}$ be a set comprising such hypothesis tests. A hypothesis test $A$ that has a</description>
    </item>
    <item>
      <title>Power Function of Hypothesis Testing</title>
      <link>https://freshrimpsushi.github.io/en/posts/2291/</link>
      <pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2291/</guid>
      <description>Definition 1 Hypothesis Testing: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ Given the hypothesis testing above, let&amp;rsquo;s denote it as $\alpha \in [0,1]$. For the parameter $\theta$, the function $\beta (\theta) := P_{\theta} \left( \mathbf{X} \in \mathbb{R} \right)$ with the rejection region $R$ is called the Power Function. If $\sup_{\theta \in \Theta_{0}} \beta (\theta) = \alpha$, then the given hypothesis test is</description>
    </item>
    <item>
      <title>Mathematical Statistical Hypothesis Testing Definition</title>
      <link>https://freshrimpsushi.github.io/en/posts/2283/</link>
      <pubDate>Sat, 22 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2283/</guid>
      <description>Definition A proposition about a parameter is called a Hypothesis. The problem of accepting hypothesis $H_{0}$ as true based on a given sample, or rejecting hypothesis $H_{0}$ and adopting hypothesis $H_{1}$ is called a Hypothesis Test. In hypothesis testing, the complementary hypotheses $H_{0}$, $H_{1}$ are called the Null Hypothesis and the Alternative Hypothesis, respectively. The subset $R \subset \Omega$ of the sample space $\Omega$ that leads to the rejection of</description>
    </item>
    <item>
      <title>Best Unbiased Estimator, Minimum Variance Unbiased Estimator UMVUE</title>
      <link>https://freshrimpsushi.github.io/en/posts/2273/</link>
      <pubDate>Sun, 02 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2273/</guid>
      <description>Definition 1 Let us assume that parameter $\theta$ is given. If an unbiased estimator $W^{\ast}$ satisfies the following condition over all other unbiased estimators $W$, it is called the Best Unbiased Estimator or the Uniform Minimum Variance Unbiased Estimator (UMVUE). $$ \text{Var}_{\theta} W^{\ast} \le \text{Var}_{\theta} W \qquad , \forall \theta $$ Explanation UMVUE is sometimes simply referred to as MVUE, dropping the initial Uniform part. The term UMVUE might be</description>
    </item>
    <item>
      <title>Location Family</title>
      <link>https://freshrimpsushi.github.io/en/posts/2251/</link>
      <pubDate>Fri, 19 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2251/</guid>
      <description>Definition For a given cumulative distribution function $F$, suppose $F_{\theta}$ satisfies $F_{\theta} (x) = F \left( x - \theta \right)$ for all $x$. $\left\{ F_{\theta} : \theta \in \mathbb{R} \right\}$ is referred to as a Location Family. Example 1 Considering a random sample $X_{1} , \cdots , X_{n}$ with parameter $\theta$ that possesses a cumulative distribution function $F_{0} (x) = F (x - 0) = F(x)$, the sample $Z_{1} ,</description>
    </item>
    <item>
      <title>Auxiliary Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2249/</link>
      <pubDate>Mon, 15 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2249/</guid>
      <description>Definition 1 Let $S$ be a statistic of sample $\mathbf{X}$. If the distribution of $S \left( \mathbf{X} \right)$ does not depend on the parameter $\theta$, it is called an Ancillary Statistic. Description Actually, nobody says ancillary statistic in conversation, they pronounce it as [ancillary statistic]. If a sufficient statistic has all the information about $\theta$, then an ancillary statistic can be thought of as a statistic that has no information</description>
    </item>
    <item>
      <title>Definition of Likelihood Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/2239/</link>
      <pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2239/</guid>
      <description>Definition 1 Let&amp;rsquo;s denote the joint probability density function or probability mass function of a sample $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right)$ as $f(\mathbf{x}|\theta)$. When a realization $\mathbf{x}$ is given, regarding $f(\mathbf{x}|\theta)$ as a function of $\theta$ $$ L \left( \theta | \mathbf{x} \right) := f \left( \mathbf{x} | \theta \right) $$ is called the Likelihood Function. Explanation In the context of discussing maximum likelihood estimators, it</description>
    </item>
    <item>
      <title>Neumann Factorization Theorem Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/2084/</link>
      <pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2084/</guid>
      <description>Theorem Let&amp;rsquo;s say a random sample $X_{1} , \cdots , X_{n}$ has the same probability mass/density function $f \left( x ; \theta \right)$ for a parameter $\theta \in \Theta$. Statistic $Y = u_{1} \left( X_{1} , \cdots , X_{n} \right)$ is a sufficient statistic for $\theta$ if there exist two non-negative functions $k_{1} , k_{2} \ge 0$ that satisfy the following. $$ f \left( x_{1} ; \theta \right) \cdots f</description>
    </item>
    <item>
      <title>Sufficient Statistic</title>
      <link>https://freshrimpsushi.github.io/en/posts/2061/</link>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2061/</guid>
      <description>Definitions Mathematical Definition 1 Let the probability mass/density function of a random sample $X_{1} , \cdots , X_{n}$ for parameter $\theta \in \Theta$ be $f(x;\theta)$, and let the probability mass/density function for statistic $Y_{1} := u_{1} \left( X_{1} , \cdots , X_{n} \right)$ be $f_{Y_{1}} \left( y_{1}; \theta \right)$. For $H \left( x_{1} , \cdots , x_{n} \right)$, which does not depend on $\theta \in \Theta$, $$ {{ f \left(</description>
    </item>
    <item>
      <title>Regularity Conditions in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2029/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2029/</guid>
      <description>Overview In subjects that utilize mathematics, the term Regularity Conditions usually refers to conditions that allow for a wide range of applications and make theoretical developments more comfortable. In mathematical statistics, they are as follows. Assumptions 1 Consider a random variable $X$ with probability density function $f \left( x ; \theta \right)$ for a parameter $\theta \in \Theta$. The random sample $X_{1} , \cdots , X_{n}$ drawn iid from the</description>
    </item>
    <item>
      <title>Maximum Likelihood Estimator</title>
      <link>https://freshrimpsushi.github.io/en/posts/2026/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2026/</guid>
      <description>Buildup Consider a random variable $X$ with a probability density function (pdf) $f \left( x ; \theta \right)$ for parameter $\theta \in \Theta$. A random sample $X_{1} , \cdots , X_{n}$ drawn identically and independently (iid) from the same distribution as $X$ has the same pdf $f(x ; \theta)$ and realization $\mathbf{x} := \left( x_{1} , \cdots , x_{n} \right)$. The function $L$ defined for this is called the Likelihood</description>
    </item>
    <item>
      <title>Student&#39;s t-test Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/203/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/203/</guid>
      <description>Summary 1 If random variables $X_{1} , \cdots , X_{n}$ are iid and follow a normal distribution $N\left( \mu,\sigma^{2} \right)$, then (a): $$ \overline{X} \sim N\left( \mu , { {\sigma^2} \over {n} } \right) $$ (b): $$ \overline{X} \perp S^2 $$ (c): $$ (n-1) { {S^2} \over {\sigma^2} } \sim \chi^2 (n-1) $$ (d): $$ T = { {\overline{X} - \mu } \over {S / \sqrt{n}} } \sim t(n-1) $$</description>
    </item>
    <item>
      <title>Covariance Matrix</title>
      <link>https://freshrimpsushi.github.io/en/posts/1950/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1950/</guid>
      <description>Definition1 $p$-dimensional random vector $\mathbf{X} = \left( X_{1}, \cdots , X_{p} \right)$ is defined as follows for $\text{Cov} (\mathbf{X})$, which is called a Covariance Matrix. $$ \left( \text{Cov} \left( \mathbf{X} \right) \right)_{ij} := \text{Cov} \left( X_{i} , X_{j} \right) $$ $\text{Cov}$ is covariance. Explanation To put the definition in simpler words, it is as follows. $$ \text{Cov} \left( \mathbf{X} \right) := \begin{pmatrix} \text{Var} \left( X_{1} \right) &amp;amp; \text{Cov} \left( X_{1}</description>
    </item>
    <item>
      <title>Central Limit Theorem Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/43/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/43/</guid>
      <description>Theorem 1 If $\left\{ X_{k} \right\}_{k=1}^{n}$ are iid random variables following the probability distribution $\left( \mu, \sigma^2 \right) $, then when $n \to \infty$ $$ \sqrt{n} {{ \overline{X}_n - \mu } \over {\sigma}} \overset{D}{\to} N (0,1) $$ $\overset{D}{\to}$ means convergence in distribution. Explanation This theorem is widely acclaimed in statistics, along with the Law of Large Numbers. Despite being frequently discussed and applied, many encounter its proof only upon studying</description>
    </item>
    <item>
      <title>Convergence of Distributions in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1888/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1888/</guid>
      <description>Definition 1 Given a random variable $X$ and a sequence of random variables $\left\{ X_{n} \right\}$, if the following condition is satisfied when $n \to \infty$, we say that $X$ converges in distribution to $X_{n}$ and represent it as $X_{n} \overset{D}{\to} X$. $$ \lim_{n \to \infty} F_{X_{n}} (x) = F_{X} (x) \qquad, \forall x \in C_{F_{X}} $$ $F_{X}$ is the cumulative distribution function of the random variable $X$. $C_{F_{X}}$ represents</description>
    </item>
    <item>
      <title>Probability Convergence in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1789/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1789/</guid>
      <description>Definition 1 A random variable $X$ and a sequence of random variables $\left\{ X_{n} \right\}$ are said to converge in probability to $X$ as $n \to \infty$ if they satisfy the following, and it is denoted by $X_{n} \overset{P}{\to} X$. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left| X_{n} - X \right| &amp;lt; \varepsilon \right] = 1 $$ Explanation The condition for convergence in probability is</description>
    </item>
    <item>
      <title>Unbiased Estimator</title>
      <link>https://freshrimpsushi.github.io/en/posts/1745/</link>
      <pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1745/</guid>
      <description>Definition 1 If the estimator $T$ of $\theta$ satisfies the following, then $T$ is called the unbiased estimator of $\theta$. $$ E T = \theta $$ Explanation Especially, among the unbiased estimators for $\theta$, the one with the smallest variance is called the minimum variance unbiased estimator. Unbiasedness refers to the property of not having any bias. For example, when we assume $X_{i} \sim \left( \mu , \sigma^{2} \right)$, if</description>
    </item>
    <item>
      <title>Easy Definition of Confidence Intervals</title>
      <link>https://freshrimpsushi.github.io/en/posts/1732/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1732/</guid>
      <description>Definition 1 Let the probability density function $f (x; \theta)$ of the random variable $X$ and the samples $X_{1} , \cdots , X_{n}$ with a Confidence Coefficient $\alpha \in (0,1)$ be given. $$ L := L \left( X_{1} , \cdots , X_{n} \right) \\ U := U \left( X_{1} , \cdots , X_{n} \right) $$ It is said that the statistic $L &amp;lt; U$ is defined as above, then the</description>
    </item>
    <item>
      <title>Statistical Measures and Estimators in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1730/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1730/</guid>
      <description>Definition 12 A function $T$ of a sample $X_{1} , \cdots , X_{n}$ from a random variable $X$ is called a Statistic. $$ T := T \left( X_{1} , \cdots , X_{n} \right) $$ When the distribution function of $X$ is expressed as $f(x; \theta)$ or $p(x; \theta)$, if $T$ serves to capture $\theta$, then $T$ is referred to as an Estimator of $\theta$. The probability distribution of a statistic</description>
    </item>
    <item>
      <title>Random Sampling in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1715/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1715/</guid>
      <description>Definitions 1 The actual outcome of a random variable $X$ is called its realization and is usually represented by the lowercase letter $x$. A set of random variables from the same probability distribution as $X$, with a sample size of $n$, is called a sample, represented as follows: $$ X_{1} , X_{2} , \cdots , X_{n} $$ If the random variable $X_{1} , \cdots , X_{n}$ is iid, then a</description>
    </item>
    <item>
      <title>Independence and iid of Random Variables</title>
      <link>https://freshrimpsushi.github.io/en/posts/1469/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1469/</guid>
      <description>Definition 1 A random variable $X_{1} , \cdots , X_{n}$ is said to be pairwise independent if it satisfies the following. $$ i \ne j \implies X_{i} \perp X_{j} $$ A continuous random variable $X_{1} , \cdots , X_{n}$ whose joint probability density function $f$ satisfies the condition with respect to each of its probability density functions $f_{1} , \cdots , f_{n}$ is said to be mutually independent. $$ f(x_{1}</description>
    </item>
    <item>
      <title>Probability Variables Independence in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1461/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1461/</guid>
      <description>Definition 1 If for two random variables $X_{1}, X_{2}$, the joint probability density function $f$ or the probability mass function $p$ satisfies the following conditions for the probability density functions $f_{1}, f_{2}$ or the probability mass functions $p_{1}, p_{2}$ of $X_{1}, X_{2}$, then $X_{1}, X_{2}$ are said to be independent, and is denoted as $X_{1} \perp X_{2}$. $$ f(x_{1} , x_{2} ) \equiv f_{1}(x_{1})f_{2}(x_{2}) \\ p(x_{1} , x_{2} ) \equiv</description>
    </item>
    <item>
      <title>Probability Distributions under Conditional Probability in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1458/</link>
      <pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1458/</guid>
      <description>Definition For a discrete random variable $X_{1}, X_{2}, \cdots , X_{n}$, the following $p_{2, \cdots , n \mid 1}$, given $X_{1} = x_{1}$, is called the joint conditional probability mass function of $ X_{2}, \cdots , X_{n}$: $$ p_{2, \cdots , n \mid 1} ( x_{2} , \cdots ,x_{n} \mid X_{1} = x_{1} ) = {{ p_{1, \cdots , n}(x_{1} , x_{2} , \cdots , x_{n}) } \over { p_{1}(</description>
    </item>
    <item>
      <title>Multivariate Probability Distributions in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1449/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1449/</guid>
      <description>Definition 1 A Random Vector is defined as $X = (X_{1} , \cdots , X_{n})$ for $n$ number of probability variables $X_{i}$ defined in sample space $\Omega$. The range $X(\Omega)$ of $X$ is also called a space. A function that satisfies the following $F_{X} : \mathbb{R}^{n} \to [0,1]$ is called the Joint Cumulative Distribution Function of $X$. $$ F_{X}\left( x_{1}, \cdots , x_{n} \right) := P \left[ X_{1} \le x_{1}</description>
    </item>
    <item>
      <title>What is the Moment Generating Function?</title>
      <link>https://freshrimpsushi.github.io/en/posts/248/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/248/</guid>
      <description>Definition 1 For a random variable $X$ and some positive number $h&amp;gt;0$, if $E(e^{tX})$ exists in $-h&amp;lt; t &amp;lt; h$, then $M(t) = E( e^{tX} )$ is defined as the Moment Generating Function of $X$. Explanation The moment generating function (mgf) is a concept often encountered relatively early in mathematical statistics, yet its unfamiliar definition and seemingly contextless introduction can make it a source of dislike for the subject. The</description>
    </item>
    <item>
      <title>Pearson Correlation Coefficient</title>
      <link>https://freshrimpsushi.github.io/en/posts/57/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/57/</guid>
      <description>Definition 1 For two random variables $X, Y$, the following $\rho = \rho (X,Y)$, defined as the Pearson Correlation Coefficient, is: $$ \rho = { {\text{Cov} (X,Y)} \over {\sigma_X \sigma_Y} } $$ $\sigma_{X}$, $\sigma_{Y}$ are the standard deviations of $X$, $Y$ respectively. Explanation The Pearson Correlation Coefficient is a measure of whether two variables have a (linear) correlation. If close to $1$ or $–1$, it is</description>
    </item>
    <item>
      <title>Various Properties of Covariance</title>
      <link>https://freshrimpsushi.github.io/en/posts/425/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/425/</guid>
      <description>Definitions and Properties The covariance of probability variables $X$ and $Y$, whose means are $\mu_{X}$ and $\mu_{Y}$ respectively, is defined as $\text{Cov} (X ,Y) : = E \left[ ( X - \mu_{X} ) ( Y - \mu_{Y} ) \right]$. Covariance has the following properties: [1]: $\text{Var} (X) = \text{Cov} (X,X)$ [2]: $\text{Cov} (X,Y) = \text{Cov} (Y, X)$ [3]: $\text{Var} (X + Y) = \text{Var} (X) + \text{Var} (Y) + 2</description>
    </item>
    <item>
      <title>Properties of Mean and Variance</title>
      <link>https://freshrimpsushi.github.io/en/posts/424/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/424/</guid>
      <description>Theorem The mean $E ( X ) = \mu_{X}$ and variance $\text{Var} (X) = E [ ( X - \mu_{X} )^2 ]$ have the following properties: [1]: $E(X + Y) = E(X) + E(Y)$ [2]: $E(aX + b) = a E(X) + b$ [3]: $\text{Var} (X) \ge 0$ [4]: $\text{Var} ( X ) = E(X^2) - \mu_{X}^2$ [5]: $\text{Var} (aX + b) = a^2 \text{Var} (X)$ Explanation As they relate</description>
    </item>
    <item>
      <title>Mathematical Proof of the Properties of Representative Values</title>
      <link>https://freshrimpsushi.github.io/en/posts/49/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/49/</guid>
      <description>Summary Let&amp;rsquo;s assume that we have given data $X = \left\{ x_{1} , \cdots , x_{n} \right\}$. [0]: The $\theta$ that minimizes $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{0}$ is $$ \argmin_{\theta} h \left( \theta \right) = \text{mode}(X) $$ [1]: The $\theta$ that minimizes $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{1}$ is $$ \argmin_{\theta} h \left( \theta \right) = \text{median}(X) $$ [2]: The $\theta$ that minimizes $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{2}$ is $$ \argmin_{\theta}</description>
    </item>
    <item>
      <title>Expectation, Mean, Variance, and Moments in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/246/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/246/</guid>
      <description>Definition: Expectation, Mean, and Variance Let&amp;rsquo;s assume that we have a given random variable $X$. If the probability density function $f(x)$ of a continuous random variable $X$ satisfies $\displaystyle \int_{-\infty}^{\infty} |x| f(x) dx &amp;lt; \infty$, then $E(X)$, defined as follows, is called the Expectation of $X$. $$ E(X) := \int_{-\infty}^{\infty} x f(x) dx $$ If the probability mass function $p(x)$ of a discrete random variable $X$ satisfies $\displaystyle \sum_{x} |x|</description>
    </item>
    <item>
      <title>Probability Variables and Probability Distribution in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1433/</link>
      <pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1433/</guid>
      <description>Definition 1 Let us assume that probability $P$ is defined in the sample space $\Omega$. A function $X : \Omega \to \mathbb{R}$ whose domain is the sample space is called a Random Variable. The range $X(\Omega)$ of a random variable is also called its Space. A function $F_{X} : \mathbb{R} \to [0,1]$ that satisfies the following is called the Cumulative Distribution Function (cdf) of $X$. $$ F_{X}(x) = P_{X}\left( (-\infty,x]</description>
    </item>
    <item>
      <title>Probability and the Addition Law of Probability in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1431/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1431/</guid>
      <description>Definition 1 An experiment that can be repeated under the same conditions is referred to as a Random Experiment. The set $\Omega$ of all possible outcomes that can be obtained from a random experiment is called the Sample Space. The set of outcomes in the sample space that we are interested in, i.e., $B \subset \Omega$ is called an Event, and these sets are represented as $\mathcal{B}$. A function $P</description>
    </item>
    <item>
      <title>Bayesian Paradigm</title>
      <link>https://freshrimpsushi.github.io/en/posts/702/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/702/</guid>
      <description>Buildup Statistics can be defined as the study of methods to understand parameters. Just like measuring a physical quantity using formulas or laws, it would be ideal if parameters can be precisely estimated. However, due to the impractical nature of such precision, assumptions and samples are used to find &amp;lsquo;what is expected to be the parameter&amp;rsquo;. If interested in the average height of men in our country $X$, one might</description>
    </item>
    <item>
      <title>Summation Summary of Random Variables Following a Specific Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/202/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/202/</guid>
      <description>Theorem Let&amp;rsquo;s say the random variables $X_{1} , \cdots , X_{n}$ are mutually independent. [1] Binomial distribution: If $X_i \sim \text{Bin} ( n_{i}, p)$, then $$ \sum_{i=1}^{m} X_{i} \sim \text{Bin} \left( \sum_{i=1}^{m} n_{i} , p \right) $$ [2] Poisson distribution: If $X_i \sim \text{Poi}( m_{i} )$, then $$ \sum_{i=1}^{n} X_{i} \sim \text{Poi} \left( \sum_{i=1}^{n} m_{i} \right) $$ [3] Gamma distribution: If $X_i \sim \Gamma ( k_{i}, \theta)$, then $$ \sum_{i=1}^{n}</description>
    </item>
    <item>
      <title>Proof of Bayes&#39; Theorem and Prior, Posterior Distributions</title>
      <link>https://freshrimpsushi.github.io/en/posts/29/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/29/</guid>
      <description>Theorem 1 Sample Space $S$ and Event $A$, Probability $P$ If $\left\{ S_1, S_2, \cdots ,S_n \right\}$ is a partition of $S$, then the following holds. $$ P(S_k|A)=\frac { P(S_k)P(A|S_k) }{ \sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$ Definition The right-hand side of Bayes&amp;rsquo; theorem, $P \left( S_{k} \right)$, is called the Prior Probability, and the left-hand side, $P \left( S_{k} | A \right)$, is called the</description>
    </item>
  </channel>
</rss>
