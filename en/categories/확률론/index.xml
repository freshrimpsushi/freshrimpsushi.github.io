<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Probability Theory on FreshrimpRestaurant</title><link>https://freshrimpsushi.github.io/en/categories/%ED%99%95%EB%A5%A0%EB%A1%A0/</link><description>Recent content in Probability Theory on FreshrimpRestaurant</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 11 Mar 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/en/categories/%ED%99%95%EB%A5%A0%EB%A1%A0/index.xml" rel="self" type="application/rss+xml"/><item><title>Brook's Auxiliary Lemma Proof</title><link>https://freshrimpsushi.github.io/en/posts/2536/</link><pubDate>Mon, 11 Mar 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2536/</guid><description>Theorem 1 Let&amp;rsquo;s represent the support of the probability mass function $p : \mathbb{R}^{n} \to \mathbb{R}$ of the random vector $Z : \Omega \to \mathbb{R}^{n}$ as follows. $$ S_{Z} = \left\{ \left( z_{1} , \cdots , z_{n} \right) \in \mathbb{R}^{n} : p \left( z_{1} , \cdots , z_{n} \right) &amp;gt; 0 \right\} \subset \Omega $$ For all $\mathbf{x} := \left( x_{1} , \cdots , x_{n} \right) \in S_{Z}$ and $\mathbf{y}</description></item><item><title>Levy's Continuity Theorem in Probability Theory</title><link>https://freshrimpsushi.github.io/en/posts/2482/</link><pubDate>Fri, 24 Nov 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2482/</guid><description>Theorem 1 Let a measurable space $\left( \mathbb{R}^{d} , \mathcal{B} \left( \mathbb{R}^{d} \right) \right)$ be given. Denote by $n \in \overline{\mathbb{N}}$ a probability measure with $\mu_{n}$, and the corresponding characteristic function by $\varphi_{n}$. The following are equivalent: (a): $\mu_{n}$ weakly converges to $\mu_{\infty}$. (b): For all $t \in \mathbb{R}^{d}$, $$\lim_{n \to \infty} \varphi_{n} (t) = \varphi_{\infty} (t)$$ $\overline{\mathbb{N}} = \mathbb{N} \cup \left\{ \infty \right\}$ is a set that includes natural</description></item><item><title>Summary of Measure Theory and Probability Theory</title><link>https://freshrimpsushi.github.io/en/posts/3473/</link><pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/3473/</guid><description>Overview This is a summary of definitions and concepts for those who have already studied measure theory and probability. It is intended to be viewed when definitions are confusing or unrecognizable, and when a general review is needed. Measure Theory Algebras An algebra of sets on nonempty set $X$ is a nonempty collection $\mathcal{A}$ of subsets of $X$ is colsed under finite unions ans complements. $\sigma$-algebra is an algebra that</description></item><item><title>Definition of Poisson Processes through Differential Operator Matrices</title><link>https://freshrimpsushi.github.io/en/posts/2302/</link><pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2302/</guid><description>Definition Let us assume that $\lambda &amp;gt; 0$ is given. If it satisfies $X(0) = 0$ and has infinitesimal probabilities like $\left\{ X(t) : t \in [0,\infty) \right\}$, then it is called a Poisson Process. $$ \begin{align*} p_{ij} \left( \Delta t \right) := &amp;amp; P \left( X \left( t + \Delta t = j | X(t) = i \right) \right) \\ =&amp;amp; \begin{cases} \lambda \Delta + o \left( \Delta t</description></item><item><title>Gillespie Stochastic Simulation Algorithm</title><link>https://freshrimpsushi.github.io/en/posts/2290/</link><pubDate>Sat, 05 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2290/</guid><description>Algorithm 1 For $\mathbf{x}_{t} = i$, $$ P \left( \mathbf{X}_{t + \tau} = j | \mathbf{x}_{t} = i \right) = a_{j} \left( \mathbf{x}_{t} \right) \qquad , j = 1, \cdots , n $$ the method for simulating the realization of a continuous Markov chain $\left\{ \mathbf{X}_{t} \right\}$ is called the Gillespie Stochastic Simulation Algorithm, or simply SSA. Input Receives initial values $t=0$ and $\mathbf{X}_{0} = \mathbf{x}$. Step 1. Calculate $\sum_{j}</description></item><item><title>Kolmogorov Differential Equation Derivation</title><link>https://freshrimpsushi.github.io/en/posts/2288/</link><pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2288/</guid><description>Theorem A differential equation holds for the transition probability matrix $P(t)$ and the differential matrix $Q$. $$ {{ d P(t) } \over { dt }} = Q P(t) = P(t) Q $$ Explanation If one were to make a distinction, $dP/dt = P(t) Q$ is referred to as the backward Kolmogorov differential equation, and $dP/dt = Q P(t)$ as the forward Kolmogorov differential equation or Stochastic governing equation. Derivation According</description></item><item><title>Continuous Markov Chain</title><link>https://freshrimpsushi.github.io/en/posts/2286/</link><pubDate>Fri, 28 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2286/</guid><description>Definition A Continuous-Time Markov Chain (CTMC) refers to a continuous stochastic process $\left\{ X_{t} \right\}$ that satisfies the following conditions for all finite sequences of time points $0 \le t_{0} \le \cdots \le t_{n} \le t_{n+1}$, where the state space is a countable set: $$ P \left( X_{t_{n+1}} = j \mid X_{t_{n}} = i , X_{t_{n-1}} = k , \cdots , X_{t_{0}} = l \right) = P \left( X_{t_{n+1}} =</description></item><item><title>Transition Probabilities of Stochastic Processes</title><link>https://freshrimpsushi.github.io/en/posts/2284/</link><pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2284/</guid><description>Definition Let us assume there is a stochastic process $\left\{ X_{t} \right\}$ with a countable set as its state space. For two points in time $t_{1} &amp;lt; t_{2}$, the transition probability $p_{ij} \left( t_{1} , t_{2} \right)$ is defined as follows: $$ p_{ij} \left( t_{1} , t_{2} \right) := P \left( X_{t_{2}} = j \mid X_{t_{1}} = i \right) $$ Here, the (current) state represented by $i$ is referred to</description></item><item><title>Galton-Watson Process</title><link>https://freshrimpsushi.github.io/en/posts/2272/</link><pubDate>Fri, 30 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2272/</guid><description>Definition 1 The Basic Reproductive Rate $m = EX &amp;lt; \infty$ of a random variable $X$ is given. If we denote the $X_{n,i}$th offspring of the $i$th particle in the $n$rd generation of a branching process by $X_{n,i}$, then the stochastic process represented by a random sample $\left\{ X_{n,i} : (n,i) \in \mathbb{N}^{2} \right\} \overset{\text{iid}}{\sim} X$ is called the Galton-Watson Process. $$ Z_{n+1} = \sum_{i=1}^{Z_{n}} X_{n,i} $$ If the mean</description></item><item><title>Branching Process</title><link>https://freshrimpsushi.github.io/en/posts/2270/</link><pubDate>Mon, 26 Sep 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2270/</guid><description>Definition 1 A branching process refers to a stochastic process where entities such as individuals, cells, molecules, or other types of particles have characteristics like lifespan or basic reproductive rate that are considered random variables. Kimmel, Axelrod. (2006). Branching Processes in Biology: p1.&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Fractal Brownian Motion</title><link>https://freshrimpsushi.github.io/en/posts/2167/</link><pubDate>Fri, 04 Mar 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2167/</guid><description>Definition $E \left( X_{t} \right) = 0$ given $X_{t}$ is a Gaussian process and let&amp;rsquo;s denote it by $H \in (0, 1)$. The Fractional Brownian motion can be defined in the following two ways. Definition through Covariance 1 The covariance at time point $t, s$ of $X_{t}$, if it follows the expression below, is referred to as Fractional Brownian Motion. $$ \operatorname{Cov} \left( X_{t}, X_{s} \right) = {{ 1 }</description></item><item><title>Self-similarity and the Hurst Index of Stochastic Processes</title><link>https://freshrimpsushi.github.io/en/posts/2161/</link><pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2161/</guid><description>Definition 1 2 A stochastic process $\left\{ X_{t} \right\}$ is said to be $H$-self-similar if for all $a &amp;gt; 0$, it satisfies the following equation. $$ X_{at} \overset{D}{=} a^{H} X_{t} $$ Here, $\overset{D}{=}$ denotes equality in distribution, and the parameter $H&amp;gt;0$ is referred to as the Hurst Index. Example Considering the Brownian motion $W_{t}$, where $W_{t} \sim N(0,t)$ applies. For instance, regarding a random variable $Z$ that follows a normal</description></item><item><title>Gaussian Processes</title><link>https://freshrimpsushi.github.io/en/posts/2159/</link><pubDate>Wed, 16 Feb 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2159/</guid><description>Definition 1 For all finite subsets $S = \left\{ X_{t_{k}} \right\}_{k=1}^{n} \subset \left\{ X_{t} \right\}$ of a stochastic process $\left\{ X_{t} \right\}$, if the linear combination $$ \sum_{k=1}^{n} a_{k} X_{t_{k}} \qquad , \left\{ a_{k} \right\}_{k=1}^{n} \subset \mathbb{R} $$ of elements of $S$ follows a multivariate normal distribution, then $\left\{ X_{t} \right\}$ is called a Gaussian Process. Explanation To non-experts, the definition might seem overly mathematical, but intuitively, it is not</description></item><item><title>Geometric Brownian Motion</title><link>https://freshrimpsushi.github.io/en/posts/2154/</link><pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2154/</guid><description>Definition 1 Let&amp;rsquo;s say the following Stochastic Differential Equation (SDE) is given by $\mu \in \mathbb{R}$ and $\sigma^{2} &amp;gt; 0$. $$ d X_{t} = X_{t} \left( \mu dt + \sigma d B_{t} \right) $$ The solution of this SDE is found as a Stochastic Process for the initial value $X_{0}$, which is referred to as Geometric Brownian Motion. $$ X_{t} = X_{0} \exp \left[ \left( \mu - {{ \sigma^{2} }</description></item><item><title>Gibbs' Inequality</title><link>https://freshrimpsushi.github.io/en/posts/2049/</link><pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2049/</guid><description>Theorem Gibbs Inequality describes the relationship between Shannon Entropy and Cross Entropy, ensuring the lower bound of Kullback-Leibler Divergence. Theorem $$ H(P) \le H(P,Q) $$ Proof 1 The proof is provided only for the discrete case, assuming for all $k$ that $p_{k} &amp;gt; 0$. The equation of the tangent line at $x=1$ on the curve $y = \ln x$ is $y = x - 1$. Since the logarithm is a</description></item><item><title>Relative Entropy, Kullback-Leibler Divergence</title><link>https://freshrimpsushi.github.io/en/posts/2047/</link><pubDate>Wed, 07 Jul 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2047/</guid><description>Buildup When there are two probability distributions $P$ and $Q$, it&amp;rsquo;s easy to imagine situations where one might wonder how different these two are. For instance, consider the situation of guessing exactly what number is captured by a camera. The numbers 6 and 9 can be quite confusing without clear indication of their top and bottom, and since there are people who draw a line below 9 and those who</description></item><item><title>Cross Entropy</title><link>https://freshrimpsushi.github.io/en/posts/2045/</link><pubDate>Sat, 03 Jul 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2045/</guid><description>Overview Cross Entropy is the average number of bits required to distinguish between two probability distributions, commonly defined between the assumed true (reference) probability distribution $p$ and the estimated (expected) probability distribution $q$. Definition 1 Discrete Given the probability mass functions $p,q$ of two discrete probability distributions. The cross entropy $H (p,q)$ of the two distributions is defined as follows: $$ H (p,q) := - \sum p(x) \log_{2} q(x) $$</description></item><item><title>Conditional Entropy</title><link>https://freshrimpsushi.github.io/en/posts/2043/</link><pubDate>Tue, 29 Jun 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2043/</guid><description>Definition 1 A joint probability mass function $p$ or a joint probability density function $f$ is given for the random variable $X_{1}, \cdots , X_{n}$. The conditional entropy of $X_{1}, \cdots , X_{n}$ given that $X_{k}$ is given can be stated as $H \left( X_{1}, \cdots , X_{n} | X_{k} \right)$. Discrete $$ H \left( X_{1}, \cdots , X_{n} | X_{k} \right) := - \sum_{x_{1}} \cdots \sum_{x_{n}} p \left( x_{1}</description></item><item><title>Joint Entropy</title><link>https://freshrimpsushi.github.io/en/posts/2037/</link><pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2037/</guid><description>Definition Let us assume we have the joint probability mass function $X_{1}, \cdots , X_{n}$ or joint probability density function $f$ given for random variables. Discrete $$ H \left( X_{1}, \cdots , X_{n} \right) := - \sum_{x_{1}} \cdots \sum_{x_{n}} p \left( x_{1} , \cdots , x_{n} \right) \log_{2} p \left( x_{1} , \cdots , x_{n} \right) $$ Continuous $$ H \left( X_{1}, \cdots , X_{n} \right) := - \int_{\mathbb{R}} \cdots</description></item><item><title>Shannon Entropy: Entropy Defined by Random Variables</title><link>https://freshrimpsushi.github.io/en/posts/2035/</link><pubDate>Sun, 13 Jun 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2035/</guid><description>Overview Shannon Entropy or Information Entropy is a measure of disorder defined by a probability variable, and can be viewed as a quantification of how uncertain it is in a probability distribution. Easy and Complex Definitions Discrete Entropy 1 When the probability mass function of a discrete random variable $X$ is $p(x)$, the entropy of $X$ is represented as follows. $$ H(X) := - \sum p(x) \log_{2} p(x) $$ Continuous</description></item><item><title>Shannon Information: Information Defined by Probability Theory</title><link>https://freshrimpsushi.github.io/en/posts/2033/</link><pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/2033/</guid><description>Buildup Card Matching Game Imagine Alice and Bob are betting on which one of the 52 cards in a deck (excluding Jokers) they have drawn facedown. Alice: The card I drew is not a Joker. Bob frowns immediately upon hearing this. While it&amp;rsquo;s technically true, it&amp;rsquo;s such an obvious statement that it holds no meaningful insight for the bet. A discussion on the stakes seems necessary before proceeding with the</description></item><item><title>Proof of the Continuity Mapping Theorem</title><link>https://freshrimpsushi.github.io/en/posts/1787/</link><pubDate>Wed, 11 Nov 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1787/</guid><description>Theorem 1 The following is a measure-theoretic description of the continuous mapping theorem. For metric spaces $\left( S , d \right)$ and $\left( S' , d&amp;rsquo; \right)$, let us say $g : S \to S'$ is continuous from $C_{g} \subset S$. For a random element $X$ in $S$, concerning a sequence of random elements converging to $X$ in $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$, the following holds if $P \left( X</description></item><item><title>Don'sker's Theorem</title><link>https://freshrimpsushi.github.io/en/posts/1447/</link><pubDate>Sun, 05 Jan 2020 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1447/</guid><description>Theorem Let&amp;rsquo;s say $\left\{ \xi_i \right\}_{i \in \mathbb{N}}$ is a probability process defined in $(0,1)$. Suppose in the function space $C[0,1]$, the probability function $X_{n}$ is defined as follows: $$ X_{n}:= {{ 1 } \over { \sqrt{n} }} \sum_{i=1}^{\lfloor nt \rfloor} \xi_{i} + \left( nt - \lfloor nt \rfloor \right) {{ 1 } \over { \sqrt{n} }} \xi_{\lfloor nt \rfloor + 1} $$ $X_{n}$ converges in distribution to the Wiener</description></item><item><title>Tight Probability Processes</title><link>https://freshrimpsushi.github.io/en/posts/1443/</link><pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1443/</guid><description>Definition Let us say in a probability space $( \Omega , \mathcal{F} , P)$, a stochastic process $\left\{ X_n \right\}_{n \in \mathbb{N}}$ is defined. If for every $\varepsilon &amp;gt; 0$, there exists a compact set $K \subset \Omega$ such that $$\displaystyle \inf_{n \in \mathbb{N}} P\left( X_{n} \in K \right) &amp;gt; 1 - \varepsilon$$ is satisfied, then $\left\{ X_{n} \right\}$ is said to be tight. Explanation In mathematical statistics, it corresponds</description></item><item><title>Precompact Stochastic Process</title><link>https://freshrimpsushi.github.io/en/posts/1436/</link><pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1436/</guid><description>Theorem Let&amp;rsquo;s define a function space consisting of continuous functions going from measurable space $(S, \mathcal{S})$ to $(S ', \mathcal{S} ')$ as $\mathscr{H}:= C \left( S,S&amp;rsquo; \right)$, and say that $\left\{ h^{-1}(A&amp;rsquo;): h \in \mathscr{H} , A ' \in \mathcal{S} ' \right\}$ is a separating class of $(S , \mathcal{S})$. Here, $X$ is a probability element defined in $S$, and $\left\{ X_n \right\}_{n \in \mathbb{N}}$ is a stochastic process defined</description></item><item><title>Convergence of Distributions Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/1432/</link><pubDate>Sat, 21 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1432/</guid><description>Definition Let&amp;rsquo;s define a measurable space $(S,\mathcal{S})$ with respect to the Borel sigma field $\mathcal{S}:= \mathcal{B}(S)$ of a metric space $S$. When random variables $X$ and stochastic processes $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ defined in a probability space $(\Omega, \mathcal{F}, P)$ are $n \to \infty$, for all $f \in C_{b}(S)$, if the following is satisfied, then it is said to Converge in Distribution $X$ and is denoted as $X_{n} \overset{D}{\to}</description></item><item><title>Proof of the Mixing Theorem in Probability Theory</title><link>https://freshrimpsushi.github.io/en/posts/1430/</link><pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1430/</guid><description>Theorem Let the space $S$ be both a metric space $( S , \rho)$ and a measurable space $(S,\mathcal{B}(S))$. The following are all equivalent: (1): $P_{n} \overset{W}{\to} P$ (2): For every bounded, uniformly continuous function $f$, there exists $\displaystyle \int_{S} f dP_{n} \to \int_{S}f d P$ (3): For every closed set $F$, there exists $\displaystyle \limsup_{n\to\infty} P_{n}(F) \le P(F)$ (4): For every open set $G$, there exists $\displaystyle P(G) \le</description></item><item><title>Projection Mapping in Stochastic Processes</title><link>https://freshrimpsushi.github.io/en/posts/1429/</link><pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1429/</guid><description>Definition Let $S$ be a space that is both a metric space $( S , \rho)$ and a measurable space $(S,\mathcal{B}(S))$, and consider $k \in \mathbb{N}$. Discrete Projection Mapping: For (discrete time) $N = \left\{ n \in \mathbb{N}: n \le \xi, \xi \in [0,\infty] \right\}\subset \mathbb{N}$ and an element $x:= (x_{1} , x_{2} , \cdots )$ of $\displaystyle S^{\sup N}:= \prod_{n \in N} S$ in $S$, the following defined $\pi_{k}:</description></item><item><title>Probability Measures Defined on Polish Spaces are Tight</title><link>https://freshrimpsushi.github.io/en/posts/1428/</link><pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1428/</guid><description>Theorem Let&amp;rsquo;s say that a metric space $(S,\rho)$ is a Polish space. Then, all probability measures defined in $S$ are tight. Explanation A Polish space refers to a separable complete metric space. The reason we discuss the tightness of probability measures is precisely that, under these conditions, most probabilities are tight. This, conversely, implies the need to study probabilities defined in non-Polish spaces. Proof Strategy: We need to bring in</description></item><item><title>Tight Probability Measures</title><link>https://freshrimpsushi.github.io/en/posts/1417/</link><pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1417/</guid><description>Definition Let the space $S$ be a metric space $( S , \rho)$ and a measurable space $(S,\mathcal{B}(S))$. Let $P$ be a probability measure defined on $S$. It is said to be tight if for all $\varepsilon &amp;gt; 0$, there exists a compact set $K$ such that $P(K) &amp;gt; 1 - \varepsilon$ is satisfied. Explanation Generally, in undergraduate level probability, one rarely encounters a probability measure that is not tight.</description></item><item><title>Conditions for Two Probability Measures to Coincide</title><link>https://freshrimpsushi.github.io/en/posts/1415/</link><pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1415/</guid><description>Theorem Let space $S$ be a metric space $( S , \rho)$ and a measurable space $(S,\mathcal{B}(S))$. $\mathcal{O}$ is the set of all open sets, $\mathcal{C}$ is the set of all closed sets, and $P$ and $Q$ are probability measures defined in $(S,\mathcal{B}(S))$. [1]: For every open set $O \in \mathcal{O} \subset S$, if $P(O) = Q(O)$ then $P=Q$. In other words, $\mathcal{O}$ is a separating class. [2]: For every</description></item><item><title>In Probability Theory: Separating Classes</title><link>https://freshrimpsushi.github.io/en/posts/1413/</link><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1413/</guid><description>Theorem A Separating Class in a measurable space $(S, \mathcal{B}(S))$ defined for two probabilities $P$, $Q$ is said to satisfy the following $\mathcal{C}$. $$ P(A) = Q(A), \forall A \in \mathcal{C} \implies P(A) = Q(A), \forall A \in \mathcal{B}(S) $$ Explanation The existence of a separating class implies that to check if two measures are the same, one does not need to examine the entire measurable space but only a</description></item><item><title>Proof of Lévy's Theorem in Probability Theory</title><link>https://freshrimpsushi.github.io/en/posts/1406/</link><pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1406/</guid><description>Theorem Let&amp;rsquo;s assume that a probability space $( \Omega , \mathcal{F} , P)$ is given. If $\eta$ is an integrable random variable and $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$ is a sequence of sigma fields where $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$ is $\mathcal{F}_{n} \subset \mathcal{F}_{n+1}$, then $n \to \infty$ when $$ E \left( \eta | \mathcal{F}_{n} \right) \to E \left( \eta | \mathcal{F}_{\infty} \right) $$ $\displaystyle \mathcal{F}_{\infty} = \bigotimes_{n=1}^{\infty} \mathcal{F}_{n}$ does</description></item><item><title>If L1 Convergent, Then Martingale is Closable</title><link>https://freshrimpsushi.github.io/en/posts/1401/</link><pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1401/</guid><description>Theorem Given a probability space $( \Omega , \mathcal{F} , P)$ and a martingale $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$, if a stochastic process $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ converges to a random variable $Y$ through $\mathcal{L}_{1}$, then $\left\{ ( X_{n} , \mathcal{F}_{n} ): n = 1 , \cdots , \infty \right\}$ is a closable martingale. Description Even if $X_{n}$ converges to $Y$ through $\mathcal{L}_{1}$ and almost</description></item><item><title>Uniformly Integrable Martingales are L1 Convergent Martingales</title><link>https://freshrimpsushi.github.io/en/posts/1399/</link><pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1399/</guid><description>Definition Let&amp;rsquo;s assume we have a probability space $( \Omega , \mathcal{F} , P)$. A stochastic process $\left\{ X_{n} \right\}$ is said to converge to a random variable $X_{\infty}$ in the sense of $\mathcal{L}_{p}$, if it satisfies the following. $$ \lim_{n \to \infty} \| X_{n} - X_{\infty} \|_{p} = 0 $$ If a stochastic process $\left\{ X_{n} \right\}$ converges in the sense of $\mathcal{L}_{p}$, then the martingale $\left\{ ( X_{n}</description></item><item><title>Convergence of Probabilities Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/1397/</link><pubDate>Sat, 23 Nov 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1397/</guid><description>Probability Convergence Defined Rigorously Given a probability space $( \Omega , \mathcal{F} , P)$. A sequence of random variables $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ is said to converge in probability to a random variable $X$ if it converges in measure to $X$, denoted as $X_{n} \overset{P}{\to} X$. If you&amp;rsquo;re not yet familiar with measure theory, the term probability space can be disregarded. Explanation The convergence of $\left\{ X_{n} \right\}_{n \in</description></item><item><title>If It Is a Regular Martingale, It Is a Uniformly Integrable Martingale</title><link>https://freshrimpsushi.github.io/en/posts/1393/</link><pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1393/</guid><description>Definition Let there be a given probability space $( \Omega , \mathcal{F} , P)$. When a set of random variables $\Phi$ is given, if for all $\varepsilon&amp;gt;0$ there exists a $k \in \mathbb{N}$ that satisfies $$ \sup_{ X \in \Phi } \int_{ \left( \left| X \right| \ge k \right) } \left| X \right| dP &amp;lt; \varepsilon $$, then $\Phi$ is said to be uniformly integrable. If a stochastic process $\left\{</description></item><item><title>Regular Martingales and Closable Martingales</title><link>https://freshrimpsushi.github.io/en/posts/1384/</link><pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1384/</guid><description>Definition Let us assume a probability space $( \Omega , \mathcal{F} , P)$ and a martingale $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ are given. If for some integrable random variable $\eta$, $X_{n} = E ( \eta | \mathcal{F}_{n} )$ holds, then $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ is called a regular martingale. If there exists some integrable random variable $X_{\infty}$ that makes $\left\{ ( X_{n} , \mathcal{F}_{n} ):</description></item><item><title>Proof of the Submartingale Convergence Theorem</title><link>https://freshrimpsushi.github.io/en/posts/1382/</link><pubDate>Sat, 16 Nov 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1382/</guid><description>Theorem Given a probability space $( \Omega , \mathcal{F} , P)$ and a submartingale $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$, if we assume $\displaystyle \sup_{n \in \mathbb{N}} E X_{n}^{+} &amp;lt; \infty$, then $X_{n}$ converges almost surely to some random variable $X_{\infty}: \Omega \to \mathbb{R}$. $$E X_{\infty} &amp;lt; E X_{\infty}^{+} &amp;lt; \infty$$ Proof Strategy: Use the properties of limit supremum and limit infimum. $$ X^{\ast}:= \limsup_{n \in \mathbb{N}} X_{n} \\</description></item><item><title>Crossings in Stochastic Processes</title><link>https://freshrimpsushi.github.io/en/posts/1380/</link><pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1380/</guid><description>Definition Let&amp;rsquo;s assume that we have a probability space $( \Omega , \mathcal{F} , P)$ and a submartingale $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$. An upcrossing occurs when, over a closed interval $[a,b]$, the value changes from being $X_{t_{1}} \le a$ to $X_{t_{2}} \ge b$. The number of upcrossings observed up to time $N \in \mathbb{N}$ is represented as follows: $$ \beta_{N} (a,b): = \text{A number of upcrossing of</description></item><item><title>Dob's Inequality Proof</title><link>https://freshrimpsushi.github.io/en/posts/1375/</link><pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1375/</guid><description>Theorem Given a probability space $( \Omega , \mathcal{F} , P)$ and a submartingale $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$. If for some $N \in \mathbb{N}$ and $p&amp;gt;1$, $X_{n} \ge 0 (n \le N)$, $E X_{N}^{p} &amp;lt; \infty$ then $$ E \left( \max_{n \le N} X_{n}^{p} \right) \le \left( {{ p } \over { p-1 }} \right)^{p} E X_{N}^{p} \text{ a.s.} $$ Explanation The form of the equation can</description></item><item><title>Inequalities of Martingales</title><link>https://freshrimpsushi.github.io/en/posts/1370/</link><pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1370/</guid><description>Theorem Let $\left\{ (X_{n} , \mathcal{F}_{n}) \right\}$ be a supermartingale. [1]: For all $\lambda &amp;gt; 0$, $$ \begin{align*} \lambda P \left( \max_{n \le N} X_{n} \ge \lambda \right) \le &amp;amp; E X_{1} - \int_{(\max_{n \le N} X_{n} &amp;lt; \lambda)} X_{N} dP \\ \le &amp;amp; E X_{1} + E X_{N}^{-} \text{ a.s.} \end{align*} $$ [2]: For all $\lambda &amp;gt; 0$, $$ \begin{align*} \lambda P \left( \min_{n \le N} X_{n} \le -</description></item><item><title>Selective Sampling Theorem Proof</title><link>https://freshrimpsushi.github.io/en/posts/1355/</link><pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1355/</guid><description>Theorem Let&amp;rsquo;s assume there is a probability space $( \Omega , \mathcal{F} , P)$ and a supermartingale $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$. If $\tau$ and $\sigma$ are bounded stopping times with respect to $\sigma \le \tau$ and $\mathcal{F}_{n}$ then $$ E \left( X_{\tau} | \mathcal{F}_{\sigma} \right) \le X_{\sigma} \text{ a.s.} $$ Being bounded with respect to $\mathcal{F}_{n}$ for $\tau$ means, quite literally, that there exists a $N \in</description></item><item><title>Properties of Stopping Times</title><link>https://freshrimpsushi.github.io/en/posts/1353/</link><pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1353/</guid><description>Theorem Let&amp;rsquo;s assume we have a probability space $( \Omega , \mathcal{F} , P)$ and a martingale $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$. For a given stopping time $\tau$, $\mathcal{F}_{\tau}:= \left\{ A \in \mathcal{F}: A \cap ( \tau = n ) \in \mathcal{F}_{n} \right\}$ is referred to as the sigma field induced by $\tau$. [1]: $\mathcal{F}_{\tau}$ is a sigma field. [2]: $\tau$ is a $\mathcal{F}_{\tau}$-measurable function. [3]: For a</description></item><item><title>Stopping Times in Stochastic Processes</title><link>https://freshrimpsushi.github.io/en/posts/1351/</link><pubDate>Sat, 26 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1351/</guid><description>Definitions Let&amp;rsquo;s assume a probability space $( \Omega , \mathcal{F} , P)$ is given. A random variable $\tau$ with an integer value greater than or equal to $0$ for all $n \in \mathbb{N}_{0}$ that satisfies $(\tau = n) \in \mathcal{F}_{n}$ with respect to the filtration $\left\{ \mathcal{F}_{n} \right\}$ is called a Stopping Time. For a Borel set $B \in \mathcal{B}(\mathbb{R})$, $(\tau \in B) = \tau^{-1} (B)$ is, therefore, the same</description></item><item><title>The Definition of Martingale</title><link>https://freshrimpsushi.github.io/en/posts/1349/</link><pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1349/</guid><description>Definition Let&amp;rsquo;s assume that a probability space $( \Omega , \mathcal{F} , P)$ is given. A sequence $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$ of sub-σ-fields of $\mathcal{F}$ is called a filtration if it satisfies the following: $$ \forall n \in \mathbb{N}, \mathcal{F}_{n} \subset \mathcal{F}_{n+1} $$ Given a filtration $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$, a sequence $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$</description></item><item><title>Proof of Conditional Jensen's Inequality</title><link>https://freshrimpsushi.github.io/en/posts/1347/</link><pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1347/</guid><description>Theorem Given a probability space $( \Omega , \mathcal{F} , P)$ and a sub-sigma field $\mathcal{G} \subset \mathcal{F}$, let&amp;rsquo;s assume $X$ is a random variable. Regarding the convex function $\phi : \mathbb{R} \to \mathbb{R}$ and $\phi (X) \in \mathcal{L}^{1} ( \Omega ) $, $$ \phi \left( E \left( X | \mathcal{G} \right) \right) \le E \left( \phi (X) | \mathcal{G} \right) $$ A function is said to be convex if,</description></item><item><title>Conditional Variance Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/1343/</link><pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1343/</guid><description>Definition Given a probability space $( \Omega , \mathcal{F} , P)$ and a sub sigma field $\mathcal{G} \subset \mathcal{F}$, let $X$ and $Y$ be random variables. The following defined $\operatorname{Var}$ is called the variance of $X$ given $\mathcal{G}$. $$ \operatorname{Var} ( X | \mathcal{G}) := E \left[ (X - E(X | \mathcal{G}))^2 | \mathcal{G} \right] $$ That $\mathcal{G}$ is a sub sigma field of $\mathcal{F}$ means both are sigma fields</description></item><item><title>Smoothing Properties of Conditional Expectation</title><link>https://freshrimpsushi.github.io/en/posts/1340/</link><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1340/</guid><description>Theorem Given a probability space $( \Omega , \mathcal{F} , P)$ and a sub-sigma field $\mathcal{G}, \mathcal{G} ' \subset \mathcal{F}$, assume $X$ and $Y$ are random variables. [1]: If $X$ is $\mathcal{G}$-measurable $$ E(XY | \mathcal{G}) = X E (Y | \mathcal{G}) \text{ a.s.} $$ [2]: If $\mathcal{G} ' \subset \mathcal{G}$ then $$ \begin{align*} E (X | \mathcal{G} ') =&amp;amp; E \left( E ( X | \mathcal{G}) | \mathcal{G} '</description></item><item><title>Conditional Properties of Probability</title><link>https://freshrimpsushi.github.io/en/posts/1338/</link><pubDate>Mon, 14 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1338/</guid><description>Theorem Let&amp;rsquo;s say we have a probability space $( \Omega , \mathcal{F} , P)$ and a sub-sigma field $\mathcal{G} \subset \mathcal{F}$. [1] For all $B \in \mathcal{G}$, there is $0 \le P(B | \mathcal{G}) \le 1$. [2] Continuity of probability: For a nested sequence $\left\{ B_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{G}$, $$ \lim_{n \to \infty} B_{n} = B \implies P ( B_{n} | \mathcal{G} ) \to P ( B |</description></item><item><title>Proof of the Dominated Convergence Theorem</title><link>https://freshrimpsushi.github.io/en/posts/1336/</link><pubDate>Sat, 12 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1336/</guid><description>Theorem Given a probability space $( \Omega , \mathcal{F} , P)$. If a sequence of random variables $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ satisfies $n \in \mathbb{N}$ for all $Y \in \mathcal{L}^{1} (\Omega)$ and some $Y \in \mathcal{L}^{1} (\Omega)$, then $$ X_{n} \to X \text{ a.s.} \implies E( X_{n} | \mathcal{G} ) \to \mathcal{G} ) \text{ a.s.} $$ $\text{a.s.}$ means almost surely. Description The Dominated Convergence Theorem for conditional expectations, also</description></item><item><title>Proof of the Monotone Convergence Theorem for Conditional Cases</title><link>https://freshrimpsushi.github.io/en/posts/1331/</link><pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1331/</guid><description>Theorem Let&amp;rsquo;s assume that a probability space $( \Omega , \mathcal{F} , P)$ is given. Considering the sequence of random variables $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ and $X \in \mathcal{L}^{1} (\Omega)$, we have $$ X_{1} \le X_{2} \le \cdots \le X \\ X_{n} \to X \text{ a.s.} $$ then $$ \lim_{n \to \infty} E( X_{n} | \mathcal{G} ) = E( \lim_{n \to \infty} X_{n} | \mathcal{G} ) \text{ a.s.} $$</description></item><item><title>Properties of Conditional Expectation</title><link>https://freshrimpsushi.github.io/en/posts/1322/</link><pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1322/</guid><description>Theorem Given a probability space $( \Omega , \mathcal{F} , P)$: [1] From measure theory: If measurable functions $f$, $g$ are $\mathcal{F}$-measurable, then there exists a Borel function $h : \mathbb{R} \to \mathbb{R}$ satisfying $g = h (f)$. [2] Application in probability theory: If random variables $X$, $Y$ are $\sigma (X)$-measurable, then there exists a Borel function $h : \mathbb{R} \to \mathbb{R}$ satisfying $E(Y | X) = h(X)$. [3]: If</description></item><item><title>Conditional Probability of Random Variables Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/1320/</link><pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1320/</guid><description>Definition Given a probability space $( \Omega , \mathcal{F} , P)$. When $\mathcal{G}$ is a sub sigma field of $\mathcal{F}$, the conditional probability of an event $F \in \mathcal{F}$ with respect to $\mathcal{G}$ is defined as $$ P(F | \mathcal{G}) := E ( \mathbb{1}_{F} | \mathcal{G}) $$. The conditional density of $Y$ when $f_{Y | X =x}$ is defined as follows and given $X=x$ is $$ f_{Y | X =</description></item><item><title>Conditional Expectation of Random Variables Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/1315/</link><pubDate>Thu, 03 Oct 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1315/</guid><description>Definition Let&amp;rsquo;s assume a probability space $( \Omega , \mathcal{F} , P)$ is given. If $\mathcal{G}$ is a sub sigma-field of $\mathcal{F}$ and the random variable $X \in \mathcal{L}^{1} ( \Omega )$ is integrable, for all $A \in \mathcal{G}$, $$ \int_{A} Y d P = \int_{A} X d P $$ a $\mathcal{G}$-measurable random variable $Y$ uniquely exists satisfying the above, then $Y := E ( X | \mathcal{G} )$ is</description></item><item><title>Joint and Marginal Distributions Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/1305/</link><pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1305/</guid><description>Definition 1 Let&amp;rsquo;s assume that a probability space $( \Omega , \mathcal{F} , P)$ is given. Joint Distribution: If there are two random variables $X$ and $Y$ defined in $( \Omega , \mathcal{F} , P)$, the distribution of the random vector $(X,Y) : \Omega \to \mathbb{R}^2$ for a Borel set $B \subset \mathcal{B} \left( \mathbb{R}^2 \right)$ is defined as $$ \begin{align*} P_{(X,Y)} (B) :=&amp;amp; P \left( (X,Y) \in B \right)</description></item><item><title/><link>https://freshrimpsushi.github.io/en/posts/1300/</link><pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1300/</guid><description>Definition 1 Probability Space $( \Omega , \mathcal{F} , P)$ is given. For Random Variables $X$ and $t \in \mathbb{R}$, the function defined as follows $\varphi_{X} (t)$ is called the characteristic function of $X$. $$ \varphi_{X} (t) := E \left( e^{i t X} \right) = \int_{\mathbb{R}} e^{it x} f_{X} (x) dx $$ If you haven&amp;rsquo;t encountered measure theory yet, you can ignore the term &amp;ldquo;probability space.&amp;rdquo; Explanation The random variable</description></item><item><title>Expected Value Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/1294/</link><pubDate>Sat, 21 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1294/</guid><description>Definition 1 Let us assume that a probability space $( \Omega , \mathcal{F} , P)$ is given. The $E(X)$, defined as follows for a random variable $X$, is referred to as the (mathematical) expected value of $X$. $$ E(X) := \int_{\Omega} X d P $$ If you haven&amp;rsquo;t encountered measure theory yet, you can disregard the term probability space. Explanation The definition of expected value, however complex it might seem</description></item><item><title>Dirac Measure and Discrete Probability Distribution Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/879/</link><pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/879/</guid><description>Overview In basic probability theory, a probability distribution was either discrete or continuous, and its explanation had to rely somewhat on intuition. However, with the introduction of measure theory, discrete probability distributions can be defined cleanly without any mathematical ambiguity. Discrete Probability Distribution 1 Assume that a probability space $( \Omega , \mathcal{F} , P)$ is given. Step 1. When the random variable $X$ takes only one value When considering</description></item><item><title>Density and Cumulative Distribution Functions of Random Variables Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/1292/</link><pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1292/</guid><description>Definition 1 A probability space $( \Omega , \mathcal{F} , P)$ is given, and let&amp;rsquo;s say $m$ is a measure. For an integrable $f \ge 0$, if measure $P : \mathcal{F} \to \mathbb{R}$ has the form of $$ A \mapsto P(A) = \int_{A} f dm $$ then $P$ is said to be absolutely continuous. In particular, such $f$ is called the density of $P$ with respect to measure $m$. The</description></item><item><title>Random Variables Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/1290/</link><pubDate>Mon, 16 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1290/</guid><description>Definition 1 Let there be a given probability space $( \Omega , \mathcal{F} , P)$. Probability variables $X$, $Y$ are said to be independent if for all Borel sets $B_{1} , B_{2} \in \mathcal{B} ( \mathbb{R} )$ the following holds true: $$ P \left( X^{-1} (B_{1} ) \cap Y^{-1} (B_{2} ) \right) = P \left( X^{-1} (B_{1}) \right) P \left( Y^{-1} (B_{2}) \right) $$ If you have not yet encountered</description></item><item><title>Probability Variables and Probability Distributions Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/1288/</link><pubDate>Sat, 14 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/1288/</guid><description>Definition 1 Let&amp;rsquo;s assume a Probability Space $( \Omega , \mathcal{F} , P)$ is given. A function $X : \Omega \to \mathbb{R}$ that satisfies $X^{-1} (B) \in \mathcal{F}$ for every Borel Set $B \in \mathcal{B} (\mathbb{R})$ is called a Random Variable. $\mathcal{F}_{X}$ defined as follows is called the Sigma Field generated by $X$. $$ \mathcal{F}_{X} := X^{-1} ( \mathcal{B} ) = \sigma (X) = \left\{ X^{-1} (B) \in \Omega :</description></item><item><title>Wiener Process</title><link>https://freshrimpsushi.github.io/en/posts/957/</link><pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/957/</guid><description>Definition When $s&amp;lt; t &amp;lt; t+u$, a stochastic process $\left\{ W_{t} \right\}$ that satisfies the following conditions is called a Wiener Process: (i): $W_{0} = 0$ (ii): $\left( W_{t+u} - W_{t} \right) \perp W_{s}$ (iii): $\left( W_{t+u} - W_{t} \right) \sim N ( 0, u )$ (iv): The sample paths of $W_{t}$ are almost surely continuous. Basic Properties [1]: $\displaystyle W_{t} \sim N ( 0 , t )$ [2]: $\displaystyle</description></item><item><title>Increment of Stochastic Processes</title><link>https://freshrimpsushi.github.io/en/posts/943/</link><pubDate>Wed, 27 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/943/</guid><description>Definition A stochastic process $\xi (t)$ is defined at time $T$ and let’s denote it by $t_{0} &amp;lt; t_{1} &amp;lt; \cdots &amp;lt; t_{n} \in T$. $\xi ( t ) - \xi ( s )$ is called an increment. If for all $i=1, \cdots , n$, $\xi ( t_{i} ) - \xi ( t_{i-1} )$ are mutually independent, $\xi (t)$ is said to have independent increments. If</description></item><item><title>Definition of Poisson Process Through Exponential Distribution</title><link>https://freshrimpsushi.github.io/en/posts/903/</link><pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/903/</guid><description>Definition Let&amp;rsquo;s define $\tau_{1} , \tau_{2} , \cdots \sim \text{exp} ( \lambda )$. $\lambda$ is referred to as Intensity. $\displaystyle s_{n}:= \sum_{k=1}^{n} \tau_{k}$ is called the Arrival Time. A stochastic process defined as $N_{t}:= \begin{cases} 0 , &amp;amp; 0 \le t &amp;lt; s_{1} \\ k , &amp;amp; s_{k} \le t &amp;lt; s_{k+1} \end{cases}$, $\left\{ N_{t} \right\}_{t = 0}^{\infty}$ is called a Poisson Process. Basic Properties [1]: $\displaystyle p (N_{t} =</description></item><item><title>Hidden Markov Chain</title><link>https://freshrimpsushi.github.io/en/posts/901/</link><pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/901/</guid><description>Buildup Imagine a machine that produces certain items at fixed intervals as shown in the figure above. If green represents the normal quality goods $1$ and red represents defective goods that need to be discarded $0$, then the record so far would be $\left( 1, 0 , 1 \right)$. The actual visible results like this are referred to as Signal. However, the probability of producing a defective item varies depending</description></item><item><title>The Gambler's Ruin Problem</title><link>https://freshrimpsushi.github.io/en/posts/893/</link><pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/893/</guid><description>Problem The gambler&amp;rsquo;s ruin problem is a type of random walk where two players bet a finite amount of money and the game is repeated until one of them goes bankrupt. If you are one of the players, then according to the diagram above, the probability of you winning is $p$ and the probability of losing is $(1-p)$. State $0$ is when you go bankrupt, and state $N$ is when</description></item><item><title>Generalized Random Walk</title><link>https://freshrimpsushi.github.io/en/posts/870/</link><pubDate>Thu, 21 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/870/</guid><description>Definition A stochastic process $\left\{ X_{n} \right\}$ whose state space is the set of integers $\left\{ \cdots , -2 , -1, 0 , 1 , 2 , \cdots \right\}$ and starts from state $0$ is referred to as a generalized random walk if the probability of decreasing by $1$ in the next step is $p$, and the probability of increasing by $1$ is $(1-p)$. Explanation A random walk, which is</description></item><item><title>Limit of Transition Probabilities</title><link>https://freshrimpsushi.github.io/en/posts/863/</link><pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/863/</guid><description>Definition When the current state is $i$, after going through $k$ steps to reach $j$, the transition probability is denoted as $p_{ij}^{(k)}$. The transition probability after an infinite number of steps is represented as follows: $$ \pi_{j}:= \lim_{n \to \infty} p_{ij}^{ ( n ) } $$ Description Whether it&amp;rsquo;s statistics or applied mathematics, the main interest usually lies in predicting the future. What&amp;rsquo;s intriguing in the theory of stochastic processes</description></item><item><title>Types of States in Stochastic Processes</title><link>https://freshrimpsushi.github.io/en/posts/861/</link><pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/861/</guid><description>Definition State space is a countable set of stochastic processes $\left\{ X_{t} \right\}$. Let $i,j$ be the states and let $p_{ij}$ be the transition probabilities. If there exists $p_{ij}^{ ( n ) } &amp;gt; 0$ that satisfies $n \ge 0$, then $j$ is said to be accessible from $i$. If $i$ and $j$ are mutually accessible, they are said to communicate. The largest set of states that communicate with each</description></item><item><title>Derivation of the Chapman-Kolmogorov Equation</title><link>https://freshrimpsushi.github.io/en/posts/47/</link><pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/47/</guid><description>Theorem Probability process establishes the following equations for transition probabilities $p_{ij}^{(n)}$, $p_{ij}(t)$ and transition probability matrices $P^{(n)}$, $P(t)$. Discrete Probability Process $$ \begin{align*} p_{ ij }^{ (n+m) } =&amp;amp; \sum _{ k } p_{ ik }^{ (n) } p _{ kj }^{ (m) } \\ P^{(n+m)} =&amp;amp; P^{(n)} P^{(m)} \end{align*} $$ Continuous Probability Process $$ \begin{align*} p_{ij} (t + s) =&amp;amp; \sum _{ k } p_{ ik } \left( t</description></item><item><title>Discrete Markov Chains</title><link>https://freshrimpsushi.github.io/en/posts/859/</link><pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/859/</guid><description>Definition A discrete-time Markov chain (DTMC), or simply a Markov Chain, is a discrete stochastic process $\left\{ X_{n} \right\}$ satisfying the following, provided the state space is a countable set: $$ p \left( X_{n+1} = j \mid X_{n} = i , X_{n-1} = k , \cdots , X_{0} = l \right) = p \left( X_{n+1} = j \mid X_{n} = i \right) $$ See Also Continuous Markov Chain Description $p_{ij}:=</description></item><item><title>What is a Stochastic Process?</title><link>https://freshrimpsushi.github.io/en/posts/857/</link><pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/857/</guid><description>Definition The range of the random variable $X: \Omega \to E$ is called the state space. The set of random variables $\left\{ X_{t} \mid t \in [ 0 , \infty ) \right\}$ is called a continuous stochastic process. The sequence of random variables $\left\{ X_{n} \mid n = 0, 1, 2, \cdots \right\}$ is called a discrete stochastic process. Explanation The term &amp;lsquo;process&amp;rsquo; in stochastic process often makes the concept</description></item><item><title>Independence of Events and Conditional Probability</title><link>https://freshrimpsushi.github.io/en/posts/521/</link><pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/521/</guid><description>Definition 1 Let&amp;rsquo;s assume a probability space $(\Omega , \mathcal{F} , P)$ is given. For $P(B)&amp;gt;0$, $\displaystyle P (A | B) = {{P(A \cap B)} \over {P(B)}}$ is called the conditional probability of $A$ given $B$. If $P(A | B) = P(A)$, that is $P( A \cap B) = P(A) \cdot P(B)$, then $A, B$ are considered independent. If you haven&amp;rsquo;t yet encountered measure theory, you can ignore the term</description></item><item><title>Probability Defined by Measure Theory</title><link>https://freshrimpsushi.github.io/en/posts/498/</link><pubDate>Tue, 03 Apr 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/498/</guid><description>Definition 1 Let&amp;rsquo;s say $\mathcal{F}$ is a sigma field of set $\Omega$. Measurable set $E \in \mathcal{F}$ is called an Event. On $\mathcal{F}$, if measure $P : \mathcal{F} \to \mathbb{R}$ satisfies $P(\Omega) = 1$, then $P$ is called Probability. $( \Omega, \mathcal{F} , P )$ is called the Probability Space. Explanation Borrowing the strength of measure theory, we can provide a mathematical foundation for various concepts of probability theory and</description></item><item><title>Proof that if Two Events are Mutually Exclusive, They are Dependent</title><link>https://freshrimpsushi.github.io/en/posts/27/</link><pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/27/</guid><description>Theorem For two events $A,B$, if $B=A^c$ then $P(A\cap B) \neq P(A)P(B)$ Explanation Even without a formal proof through equations, it is common sense that if events are mutually exclusive, they cannot be independent. If one event occurring means the other cannot, this already implies an influence. However, knowing or not knowing this makes a big difference when solving problems regarding true or false judgments. Proof Let&amp;rsquo;s say for two</description></item><item><title>Two Events Being Independent Proves that Their Complements Are Also Independent</title><link>https://freshrimpsushi.github.io/en/posts/28/</link><pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/en/posts/28/</guid><description>Theorem The following are equivalent. $$ P(A \cap B) = P(A)P(B) \\ P(A \cap B^c)=P(A)P(B^c) \\ P(A^c \cap B)=P(A^c)P(B) \\ P(A^c \cap B^c)=P(A^c)P(B^c) $$ Explanation Not only is this fact highly beneficial to know, but it is also useful as a formula. Proof Let&amp;rsquo;s assume $P(A \cap B) = P(A)P(B)$. In other words, events $A$ and $B$ are independent. According to the property of the complement, $$ P(A)=1-P(A^{ c })</description></item></channel></rss>