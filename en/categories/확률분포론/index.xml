<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>확률분포론 on FreshrimpRestaurant</title>
    <link>https://freshrimpsushi.github.io/en/categories/%ED%99%95%EB%A5%A0%EB%B6%84%ED%8F%AC%EB%A1%A0/</link>
    <description>Recent content in 확률분포론 on FreshrimpRestaurant</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 20 Nov 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://freshrimpsushi.github.io/en/categories/%ED%99%95%EB%A5%A0%EB%B6%84%ED%8F%AC%EB%A1%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Polynomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/2480/</link>
      <pubDate>Mon, 20 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2480/</guid>
      <description>Definition Let a random vector composed of $n \in \mathbb{N}$ and $k \in \mathbb{N}$ counts of random variables be denoted as $\left( X_{1} , \cdots , X_{k} \right)$. $$ \sum_{i=1}^{k} X_{i} = n \qquad \&amp;amp; \qquad \sum_{i=1}^{k} p_{i} = 1 $$ For $\mathbf{p} = \left( p_{1} , \cdots , p_{k} \right) \in [0,1]^{k}$ that satisfies this, a multivariate probability distribution $M_{k} \left( n, \mathbf{p} \right)$ with the following probability mass</description>
    </item>
    <item>
      <title>Reasons Why the Modified Bessel Function of the First Kind Appears in Directional Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2478/</link>
      <pubDate>Thu, 16 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2478/</guid>
      <description>Buildup Modified Bessel Functions $$ J_{\nu}(x) = \sum \limits_{n=0}^{\infty} \frac{(-1)^{n} }{\Gamma (n+1) \Gamma (n+\nu+1)} \left(\frac{x}{2} \right)^{2n+\nu} $$ The $I_{\nu}$ defined as follows for the Bessel function of the first kind $J_{\nu}$ is called the modified Bessel function of the first kind1. $$ \begin{align*} I_{\nu} (z) :=&amp;amp; i^{-\nu} J_{\nu} \left( iz \right) \\ =&amp;amp; \left( {{ z } \over { 2 }} \right)^{\nu} \sum_{k=0}^{\infty} {{ {{ z } \over { 2</description>
    </item>
    <item>
      <title>Weibull Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/2219/</link>
      <pubDate>Thu, 16 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2219/</guid>
      <description>Definition A Weibull Distribution is a probability distribution with the following probability density function, given scale parameter $\lambda &amp;gt; 0$ and shape parameter $k &amp;gt; 0$. $$ f(x) = {{ k } \over { \lambda }} \left( {{ x } \over { \lambda }} \right)^{k-1} e^{-(x/\lambda)^{k}} \qquad , x \ge 0 $$ Theorems [1] A Generalization of the Exponential Distribution: The Weibull Distribution becomes the Exponential Distribution when $k=1$. [2]</description>
    </item>
    <item>
      <title>Pareto Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/2181/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2181/</guid>
      <description>Definition 1 For the scale parameter $x_{0} &amp;gt; 0$ and the shape parameter $\alpha &amp;gt; 0$, the following probability function is referred to as the Pareto Distribution, Power Law, or Scale-free Distribution: Continuous: For a constant $C$ that satisfies constant $\displaystyle \int_{x_{0}}^{\infty} p(x) dx = 1$ $$ p(x) = C x^{-\alpha} \qquad , x &amp;gt; x_{0} $$ Discrete: For the Riemann zeta function $\zeta$ $$ p_{k} = {{ 1 }</description>
    </item>
    <item>
      <title>Multivariate Normal Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1954/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1954/</guid>
      <description>Definition The multivariate normal distribution $N_{p} \left( \mu , \Sigma \right)$ has a probability density function based on the mean vector $\mathbf{\mu} \in \mathbb{R}^{p}$ and the covariance matrix $\Sigma \in \mathbb{R}^{p \times p}$ as follows: $$ f (\textbf{x}) = \left( (2\pi)^{p} \det \Sigma \right)^{-1/2} \exp \left[ - {{ 1 } \over { 2 }} \left( \textbf{x} - \mathbf{\mu} \right)^{T} \Sigma^{-1} \left( \textbf{x} - \mathbf{\mu} \right) \right] \qquad , \textbf{x} \in</description>
    </item>
    <item>
      <title>Deriving Standard Normal Distribution as a Limiting Distribution of Student&#39;s t-Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/195/</link>
      <pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/195/</guid>
      <description>Theorem If $T_n \sim t(n)$ then $$ T_n \ \overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ is a normal distribution with mean $\mu$ and variance $\sigma^{2}$. $t(r)$ is a t-distribution with degrees of freedom $r$. $\overset{D}{\to}$ respectively imply distribution convergence. Originally, the Student t-distribution was created for statistical analysis when the sample size is small. As the sample size increases, it becomes similar to the standard normal distribution,</description>
    </item>
    <item>
      <title>Derivation of the Standard Normal Distribution as the Limiting Distribution of the Poisson Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/197/</link>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/197/</guid>
      <description>Theorem If $X_{n} \sim \text{Poi} \left( n \right)$ and $\displaystyle Y_{n} := {{ X_{n} - n } \over { \sqrt{n} }}$ are given $$ Y_{n} \overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ is a normal distribution with a mean of $\mu$ and a variance of $\sigma^{2}$. $\text{Poi} (\lambda)$ is a Poisson distribution with mean and variance of $\lambda$. Explanation Considering the approximation of the binomial distribution to the</description>
    </item>
    <item>
      <title>Derivation of the Standard Normal Distribution as a Limiting Distribution of the Binomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/196/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/196/</guid>
      <description>Theorem De Moivre-Laplace Theorem If $X_i \sim B(1,p)$ and $Y_n = X_1 + X_2 + \cdots + X_n$, then $Y_n \sim B(n,p)$ and $$ { { Y_n - np } \over {\sqrt{ np(1-p) } } }\overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ is a normal distribution with mean $\mu$ and variance $\sigma^{2}$. $B(n,p)$ is a binomial distribution with $n$ trials and probability $p$. $\overset{D}{\to}$ denotes convergence in distribution.</description>
    </item>
    <item>
      <title>The Poisson Distribution as a Limiting Distribution of the Binomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/198/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/198/</guid>
      <description>Theorem Let&amp;rsquo;s say $X_{n} \sim B(n,p)$. If $\mu \approx np$ then $$ X_{n} \overset{D}{\to} \text{Poi} (\mu) $$ $B(n,p)$ is a binomial distribution with trials $n$ and probability $p$. $\text{Poi} (\lambda)$ is a Poisson distribution with mean and variance $\lambda$. $\overset{D}{\to}$ means distribution convergence. Description Note that the condition $\mu \approx np$ is necessary here. Since $ np \approx npq$, it implies $q = (1-p) \approx 1$, i.e., $p \approx 0$.</description>
    </item>
    <item>
      <title>Cauchy Distribution: A Distribution Without a Mean</title>
      <link>https://freshrimpsushi.github.io/en/posts/147/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/147/</guid>
      <description>Definition The continuous probability distribution with the following probability density function is called a Cauchy distribution. $C$ $$ f(x) = {1 \over \pi} {1 \over {x^2 + 1}} \qquad , x \in \mathbb{R} $$ Explanation It may seem like all probability distributions would have a mean and variance, but in reality, that&amp;rsquo;s not always the case. A prime example of this is the Cauchy distribution, which at a glance resembles</description>
    </item>
    <item>
      <title>t-Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1667/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1667/</guid>
      <description>Definition 1 A continuous probability distribution $t \left( \nu \right)$, known as the t-distribution, is defined for degrees of freedom $\nu &amp;gt; 0$ as having the following probability density function: $$ f(x) = {{ \Gamma \left( {{ \nu + 1 } \over { 2 }} \right) } \over { \sqrt{\nu \pi} \Gamma \left( {{ \nu } \over { 2 }} \right) }} \left( 1 + {{ x^{2} } \over {</description>
    </item>
    <item>
      <title>Derivation of the Student&#39;s t-Distribution from Independent Normal Distributions and the Chi-Squared Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/204/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/204/</guid>
      <description>Theorem Two independent random variables $W,V$ where $W \sim N(0,1)$ and $V \sim \chi^{2} (r)$, then $$ T = { {W} \over {\sqrt{V/r} } } \sim t(r) $$ $N \left( \mu , \sigma^{2} \right)$ is a normal distribution with mean $\mu$ and variance $\sigma^{2}$. $\chi^{2} \left( r \right)$ is a chi-squared distribution with degrees of freedom $r$. $t(r)$ is a t-distribution with degrees of freedom $r$. Description If this theorem</description>
    </item>
    <item>
      <title>The Square of a Standard Normal Distribution Follows a Chi-Square Distribution with One Degree of Freedom</title>
      <link>https://freshrimpsushi.github.io/en/posts/148/</link>
      <pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/148/</guid>
      <description>Summary If $X \sim N(\mu,\sigma ^2)$ then $$ V=\left( { X - \mu \over \sigma} \right) ^2 \sim \chi ^2 (1) $$ $N \left( \mu , \sigma^{2} \right)$ is a normal distribution with mean $\mu$ and variance $\sigma^{2}$. $\chi^{2} \left( 1 \right)$ is a chi-squared distribution with degrees of freedom $1$. Description In general, Student&amp;rsquo;s theorem is widely used to generalize this. Anyone studying statistics must always know as a</description>
    </item>
    <item>
      <title>Normal Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1645/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1645/</guid>
      <description>Definition A continuous probability distribution $N \left( \mu,\sigma^{2} \right)$ with a probability density function as follows, given mean $\mu \in \mathbb{R}$ and variance $\sigma^{2} &amp;gt; 0$, is called Normal Distribution. $$ f(x) = {{ 1 } \over { \sqrt{2 \pi} \sigma }} \exp \left[ - {{ 1 } \over { 2 }} \left( {{ x - \mu } \over { \sigma }} \right)^{2} \right] \qquad, x \in \mathbb{R} $$ In</description>
    </item>
    <item>
      <title>Derivation of F-distribution from Two Independent Chi-squared Distributions</title>
      <link>https://freshrimpsushi.github.io/en/posts/1643/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1643/</guid>
      <description>Summary If two random variables $U,V$ are independent and it is assumed that $U \sim \chi^{2} ( r_{1})$, $V \sim \chi^{2} ( r_{2})$ then $$ {{ U / r_{1} } \over { V / r_{2} }} \sim F \left( r_{1} , r_{2} \right) $$ Explanation If two data follow the Chi-squared distribution and are independent, it might be possible to explain their ratio using distribution theory. In statistics in general,</description>
    </item>
    <item>
      <title>F-distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1606/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1606/</guid>
      <description>Definition 1 The continuous probability distribution $F \left( r_{1} , r_{2} \right)$, which has the following probability density function for degrees of freedom $r_{1}, r_{2} &amp;gt; 0$, is called the F-distribution. $$ f(x) = {{ 1 } \over { B \left( r_{1}/2 , r_{2} / 2 \right) }} \left( {{ r_{1} } \over { r_{2} }} \right)^{r_{1} / 2} x^{r_{1} / 2 - 1} \left( 1 + {{ r_{1} }</description>
    </item>
    <item>
      <title>Chi-Squared Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1600/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1600/</guid>
      <description>Definition 1 The chi-square distribution refers to a continuous probability distribution $\chi^{2} (r)$ with the following probability density function, defined over the degrees of freedom $r &amp;gt; 0$. $$ f(x) = {{ 1 } \over { \Gamma (r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} \qquad , x \in (0, \infty) $$ $\Gamma$ represents the gamma function. Basic Properties Moment Generating Function [1]: $$m(t) = (1-2t)^{-r/2} \qquad , t &amp;lt; {{ 1 }</description>
    </item>
    <item>
      <title>Beta Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1540/</link>
      <pubDate>Sat, 02 May 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1540/</guid>
      <description>Definition 1 For $\alpha , \beta &amp;gt; 0$, the continuous probability distribution $\text{Beta}(\alpha,\beta)$, called the beta Distribution, has the following probability density function: $$ f(x) = {{ 1 } \over { B(\alpha,\beta) }} x^{\alpha - 1} (1-x)^{\beta - 1} \qquad , x \in [0,1] $$ $B$ represents the beta function. Basic Properties Moment Generating Function [1]: $$m(t) = 1 + \sum_{k=1}^{\infty} \left( \prod_{r=0}^{k-1} {{ \alpha + r } \over {</description>
    </item>
    <item>
      <title>The Relationship Between the Gamma Distribution and the Chi-Squared Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/135/</link>
      <pubDate>Tue, 07 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/135/</guid>
      <description>Theorem $$ \Gamma \left( { r \over 2 } , 2 \right) \iff \chi ^2 (r) $$ Description The gamma distribution and the chi-square distribution have the following properties. Proof Strategy: It is shown that the moment-generating functions of the two distributions can be represented in the same form. The moment-generating function of the chi-square distribution $\chi ^2 (r)$ is $\displaystyle m_{1}(t) = (1- 2t)^{- {r \over 2} }$, and</description>
    </item>
    <item>
      <title>Relationship between Gamma Distribution and Exponential Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/133/</link>
      <pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/133/</guid>
      <description>Theorem $$ \Gamma \left(1, { 1 \over \lambda } \right) \iff \text{exp} (\lambda) $$ Description If we think about the intuitive definition of the exponential distribution, it&amp;rsquo;s about the interest in the amount of time it takes for a certain event to occur. If we were to relate this to a discrete probability distribution, the geometric distribution would correspond to this. In this sense, the generalization of the geometric distribution</description>
    </item>
    <item>
      <title>Gamma Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1517/</link>
      <pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1517/</guid>
      <description>Definition 1 For $k, \theta &amp;gt; 0$, it is called the Gamma Distribution which has the following probability density function $\Gamma ( k , \theta )$. $$ f(x) = {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x^{k - 1} e^{ - x / \theta} \qquad , x &amp;gt; 0 $$ $\Gamma$ represents the Gamma function. The probability density function of the Gamma distribution can also be</description>
    </item>
    <item>
      <title>The Relationship between Exponential Distribution and Poisson Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/296/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/296/</guid>
      <description>Summary When the time it takes for an event to occur is given by $X_{k}$, and if $X_{k} \sim \exp (\lambda)$, then the number of occurrences of an event per unit time is given by $N$, and $\displaystyle N \sim \text{Poi} (\lambda)$</description>
    </item>
    <item>
      <title>Exponential Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1510/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1510/</guid>
      <description>Definition 1 The continuous probability distribution $\exp ( \lambda)$ with the following probability density function, for $\lambda &amp;gt; 0$, is called an Exponential Distribution. $$ f(x) = \lambda e^{-\lambda x} \qquad , x \ge 0 $$ Depending on the book, the parameter might be its reciprocal, $\displaystyle \theta = {{ 1 } \over { \lambda }}$. Basic Properties Moment Generating Function [1]: $$m(t) = {{ \lambda } \over { \lambda</description>
    </item>
    <item>
      <title>Mean and Variance of the Poisson Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/61/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/61/</guid>
      <description>Formulas $X \sim \text{Poi}(\lambda)$ Surface $$ E(X) = \lambda \\ \text{Var}(X) = \lambda $$ Derivation Strategy: Directly deduce from the definition of the Poisson distribution. The trick of splitting factorials and series is important. Definition of Poisson Distribution: For $\lambda &amp;gt; 0$, an discrete probability distribution that has the following probability mass function $\text{Poi} ( \lambda )$ is called a Poisson distribution. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over</description>
    </item>
    <item>
      <title>Poisson Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1491/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1491/</guid>
      <description>Definitions 1 For $\lambda &amp;gt; 0$, we refer to the following probability mass function as the Poisson Distribution that has a discrete probability distribution $\text{Poi} ( \lambda )$. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over { x! }} \qquad , x = 0 , 1 , 2, \cdots $$ Basic Properties Moment Generating Function [1]: $$m(t) = \exp \left[ \lambda \left( e^{t} - 1 \right) \right] \qquad , t</description>
    </item>
    <item>
      <title>Negative Binomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1489/</link>
      <pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1489/</guid>
      <description>Definition 1 Given $r \in \mathbb{N}$ and $p \in (0,1]$, a discrete probability distribution $\text{NB}(r,p)$ with the following probability mass function is called the Negative Binomial Distribution. $$ p(x) = \binom{r+x-1}{x-1} p^{r}(1-p)^{x} \qquad, x = 0,1,2,\cdots $$ Basic Properties Moment Generating Function [1]: $$m(t) = \left[ {{ p } \over { 1 - (1-p) e^{t} }} \right]^{r} \qquad , t &amp;lt; -\log (1-P)$$ Mean and Variance [2]: If $X \sim</description>
    </item>
    <item>
      <title>Geometric Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1486/</link>
      <pubDate>Sun, 16 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1486/</guid>
      <description>Definition 1 For $p \in (0,1]$, the discrete probability distribution $\text{Geo}(p)$ that follows the probability mass function as shown above, is called the Geometric Distribution. $$ p(x) = p (1 - p)^{x-1} \qquad , x = 1 , 2, 3, \cdots $$ Take special care with the domain and the formula as there are two definitions used. Basic Properties Moment Generating Function [1]: $$m(t) = {{ p e^{t} } \over</description>
    </item>
    <item>
      <title>Binomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1480/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1480/</guid>
      <description>Definition 1 The discrete probability distribution $\text{Bin}(n,p)$ with the following probability mass function for $n \in \mathbb{N}$ and $p \in [0,1]$ is called the Binomial Distribution. $$ p(x) = \binom{n}{x} p^{x} (1-p)^{n-x} \qquad , x = 0 , 1, \cdots n $$ Basic Properties Moment Generating Function [1]: $$m(t) = \left[ (1-p) + pe^{t} \right]^{n} \qquad , t \in \mathbb{R}$$ Mean and Variance [2]: If $X \sim \text{Bin}(n,p)$ then $$</description>
    </item>
    <item>
      <title>Binomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/443/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/443/</guid>
      <description>Definition 1 Continuous For $[a,b] \subset \mathbb{R}$, a continuous probability distribution $U(a,b)$ with the following probability density function is called the Uniform Distribution. $$ f(x) = {{ 1 } \over { b - a }} \qquad , x \in [a,b] $$ Discrete For a finite set $\left\{ x_{k} \right\}_{k=1}^{n}$, a discrete probability distribution with the following probability mass function is called the Uniform Distribution. $$ p \left( x_{k} \right) =</description>
    </item>
  </channel>
</rss>
