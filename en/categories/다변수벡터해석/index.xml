<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>다변수벡터해석 on FreshrimpRestaurant</title>
    <link>https://freshrimpsushi.github.io/en/categories/%EB%8B%A4%EB%B3%80%EC%88%98%EB%B2%A1%ED%84%B0%ED%95%B4%EC%84%9D/</link>
    <description>Recent content in 다변수벡터해석 on FreshrimpRestaurant</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 23 Dec 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://freshrimpsushi.github.io/en/categories/%EB%8B%A4%EB%B3%80%EC%88%98%EB%B2%A1%ED%84%B0%ED%95%B4%EC%84%9D/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Taylor&#39;s Theorem for Multivariable Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/3163/</link>
      <pubDate>Thu, 23 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/3163/</guid>
      <description>Theorem1 Let $f : \mathbb{R}^{n} \to \mathbb{R}$ be $C^{k}$ function, and call it $\mathbf{a} = (a_{1}, \dots, a_{n}) \in \mathbb{R}^{n}$. Then, there exists $C^{k-2}$ function $h_{ij}$ that satisfies the following. $$ f(\mathbf{x}) = f(\mathbf{a}) + \sum_{i} (x_{i} - a_{i})\dfrac{\partial f}{\partial x_{i}}(\mathbf{a}) + \sum_{i,j}h_{ij}(\mathbf{x})(x_{i} - a_{i}) (x_{j} - a_{j}) $$ Description It generalizes the Taylor theorem to functions of several variables. second-order $$ \begin{align*} f(\mathbf{x}) &amp;amp;= f(\mathbf{a}) + \sum\limits_{i=1}^{n} (x_{i} -</description>
    </item>
    <item>
      <title>Chain Rule for Multivariable Vector Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/3134/</link>
      <pubDate>Tue, 26 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/3134/</guid>
      <description>Theorem Let&amp;rsquo;s assume that two functions $\mathbf{g} : D \subset \mathbb{R}^{m} \to \mathbb{R}^{k}$, $\mathbf{f} : \mathbf{g}(\mathbb{R}^{k}) \subset \mathbb{R}^{k} \to \mathbb{R}^{n}$ are differentiable. Then, the composition of these two functions $\mathbf{F} = \mathbf{f} \circ \mathbf{g} : \mathbb{R}^{m} \to \mathbb{R}^{n}$ is also differentiable, and the (total) derivative of $\mathbf{F}$ satisfies the following. $$ \mathbf{F}^{\prime}(\mathbf{x}) = \mathbf{f}^{\prime}\left( \mathbf{g}(\mathbf{x}) \right) \mathbf{g}^{\prime}(\mathbf{x}) $$ Explanation This is called the chain rule. If we denote $\mathbf{x} =</description>
    </item>
    <item>
      <title>Definition of Directional Derivative</title>
      <link>https://freshrimpsushi.github.io/en/posts/3109/</link>
      <pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/3109/</guid>
      <description>Buildup Let&amp;rsquo;s say a multivariable function $f = \mathbb{R}^{n} \to \mathbb{R}$ is given. When trying to calculate the derivative of $f$, unlike the case with a univariable function, one must consider the rate of change in &amp;lsquo;which direction&amp;rsquo;. A familiar example is the partial derivative. The partial derivative considers the rate of change with respect to only one variable. For instance, the partial derivative $\dfrac{\partial f}{\partial y}$ of $f=f(x,y,z)$ with</description>
    </item>
    <item>
      <title>Partial Derivatives: Derivatives of Multivariable Vector Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/3082/</link>
      <pubDate>Wed, 14 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/3082/</guid>
      <description>Buildup[^1] Recall the definition of the derivative of a univariate function. $$ \lim \limits_{h\to 0} \dfrac{f(x+h) - f(x)}{h} = f^{\prime}(x) $$ By approximating the numerator on the left-hand side as a linear function of $h$, we get the following. $$ \begin{equation} f(x+h) - f(x) = a h + r(h) \label{1} \end{equation} $$ Let&amp;rsquo;s call $r(h)$ the remainder, satisfying the condition below. $$ \lim \limits_{h \to 0} \dfrac{r(h)}{h}=0 $$ Then, dividing</description>
    </item>
    <item>
      <title>Laplacian of a Scalar Field</title>
      <link>https://freshrimpsushi.github.io/en/posts/3081/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/3081/</guid>
      <description>Definition The divergence of the gradient of the scalar function $u : \mathbb{R}^{n} \to \mathbb{R}$ is called the Laplacian and is denoted as follows. $$ \begin{align*} \Delta u :&amp;amp;= \mathrm{div}(\nabla (u)) \\ &amp;amp;= \mathrm{div} \left( \left( u_{x_{1}}, u_{x_{2}}, \dots, u_{x_{n}} \right) \right) \\ &amp;amp;= u_{x_{1}x_{1}} + u_{x_{2}x_{2}} + \cdots + u_{x_{n}x_{n}} \\ &amp;amp;= \sum _{i=1}^{n} u_{x_{i}x_{i}} \end{align*} $$ Here, $u_{x_{i}}=\dfrac{\partial u}{\partial x_{i}}$ is. Explanation In mathematics, the divergence is often</description>
    </item>
    <item>
      <title>Partial Derivatives</title>
      <link>https://freshrimpsushi.github.io/en/posts/3036/</link>
      <pubDate>Mon, 08 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/3036/</guid>
      <description>Definitions1 Let us define $E\subset \mathbb{R}^{n}$ as an open set, and $\mathbf{x}\in E$, and $\mathbf{f} : E \to \mathbb{R}^{m}$. Let $\left\{ \mathbf{e}_{1}, \mathbf{e}_{2}, \dots, \mathbf{e}_{n} \right\}$, and $\left\{ \mathbf{u}_{1}, \mathbf{u}_{2}, \dots, \mathbf{u}_{m} \right\}$ be the standard basis of $\mathbb{R}^{n}$ and $\mathbb{R}^{m}$, respectively. Then, the components $f_{i} : \mathbb{R}^{n} \to \mathbb{R}$ of $\mathbf{f}$ are defined as follows. $$ \mathbf{f} (\mathbf{x}) = \sum_{i=1}^{m} f_{i}(\mathbf{x})\mathbf{u}_{i}, \quad \mathbf{x} \in E $$ or $$ f_{i}</description>
    </item>
    <item>
      <title>Gradient of Scalar Field</title>
      <link>https://freshrimpsushi.github.io/en/posts/1010/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1010/</guid>
      <description>Definition A gradient, specifically referred to as the total derivative of a scalar field $f : \mathbb{R}^{n} \to \mathbb{R}$, is denoted by $\nabla f$. $$ \begin{align*} \nabla f := f^{\prime} =&amp;amp; \begin{bmatrix} D_{1}f &amp;amp; D_{2}f &amp;amp; \cdots &amp;amp; D_{n}f\end{bmatrix} \\ =&amp;amp; \begin{bmatrix} \dfrac{\partial f}{\partial x_{1}} &amp;amp; \dfrac{\partial f}{\partial x_{2}} &amp;amp; \cdots &amp;amp; \dfrac{\partial f}{\partial x_{n}} \end{bmatrix} \\ =&amp;amp; \dfrac{\partial f}{\partial x_{1}}\hat{x}_{1} + \dfrac{\partial f}{\partial x_{2}}\hat{x}_{2} + \dots + \dfrac{\partial f}{\partial</description>
    </item>
    <item>
      <title>What is a Hessian Matrix?</title>
      <link>https://freshrimpsushi.github.io/en/posts/992/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/992/</guid>
      <description>Definition $D \subset \mathbb{R}^{n}$ is defined as the matrix $H \in \mathbb{R}^{n \times n}$ for a multivariate scalar function $f : D \to \mathbb{R}$ is called the Hessian matrix of $f$. $$ H := \begin{bmatrix} {{\partial^2 f } \over {\partial x_{1}^2 }} &amp;amp; \cdots &amp;amp; {{\partial^2 f } \over { \partial x_{1} \partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial^2 f } \over {\partial x_{n} \partial x_{1}</description>
    </item>
    <item>
      <title>Jacobian Matrix or Jacobi Matrix</title>
      <link>https://freshrimpsushi.github.io/en/posts/989/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/989/</guid>
      <description>Definition Let a multivariable vector function $\mathbb{f} : D \to \mathbb{R}^{m}$ defined by $D \subset \mathbb{R}^{n}$ be defined for each scalar function $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ as follows: $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ It is called the</description>
    </item>
    <item>
      <title>Scalar Functions and Vector-valued Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/970/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/970/</guid>
      <description>Definition Let $D$ be a subset $D\subset \mathbb{R}^{n}$ of the $n$-dimensional Euclidean space. Functions having $D$ as their domain are called function of several variables. $f : D \to \mathbb{R}$ is called a scalar function. For a scalar function $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$, $\mathbb{f} : D \to \mathbb{R}^{m}$ defined as follows is called a vector-valued function. $$ \mathbb{f} ( x_{1} , \cdots , x_{n} )</description>
    </item>
    <item>
      <title>Inner product in Euclidean space</title>
      <link>https://freshrimpsushi.github.io/en/posts/255/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/255/</guid>
      <description>Definition Let&amp;rsquo;s say $V = \mathbb{R}^n$ for a vector space, and also $\mathbb{x}, \mathbb{y}, \mathbb{z} \in V$ and $k \in \mathbb{R}$. $\left&amp;lt; \cdot , \cdot \right&amp;gt; : V^2 \to \mathbb{R}$ is defined as the inner product on $V$ when it satisfies the following four conditions: (1) Symmetry: $\left&amp;lt; \mathbb{x} , \mathbb{y} \right&amp;gt; = \left&amp;lt; \mathbb{y}, \mathbb{x} \right&amp;gt;$ (2) Additivity: $\left&amp;lt; \mathbb{x} + \mathbb{y} , \mathbb{z} \right&amp;gt; = \left&amp;lt; \mathbb{x}, \mathbb{z}</description>
    </item>
    <item>
      <title>Why Notation of Partial Differential is Different?</title>
      <link>https://freshrimpsushi.github.io/en/posts/2573/</link>
      <pubDate>Sat, 24 May 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2573/</guid>
      <description>Question In partial derivatives, unlike the usual derivatives, expressions like $\displaystyle {{ \partial f } \over { \partial t }}$ are used instead of $\displaystyle {{ d f } \over { d t }}$. $\partial$ is read as &amp;ldquo;Round Dee&amp;rdquo; or &amp;ldquo;Partial,&amp;rdquo; and historically, it originated from &amp;ldquo;Curly Dee,&amp;rdquo; which is a cursive form of $d$1. In code, it&amp;rsquo;s \partial, and in Korea, some people even shorten it to just</description>
    </item>
  </channel>
</rss>
