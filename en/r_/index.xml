<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R_s on FreshrimpRestaurant</title>
    <link>https://freshrimpsushi.github.io/en/r_/</link>
    <description>Recent content in R_s on FreshrimpRestaurant</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 12 Feb 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://freshrimpsushi.github.io/en/r_/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Stress Centrality in Network Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/2522/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2522/</guid>
      <description>Definition 1 In a network $\left( V, E \right)$, the number of shortest paths connecting two nodes $s,t \in V$ is denoted by $\sigma_{st} = \sigma_{ts}$, and specifically, the number of paths among those that include another node $v \in V$ is denoted by $\sigma_{st} (v)$. The following defined $C_{S} : V \to \mathbb{Z}$ is referred to as the Stress Centrality of node $v$. $$ C_{S} (v) := \sum_{s \ne</description>
    </item>
    <item>
      <title>Sparse Matrices</title>
      <link>https://freshrimpsushi.github.io/en/posts/2513/</link>
      <pubDate>Thu, 25 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2513/</guid>
      <description>Definition In natural language, sparse refers to being thin or scarce in a way that a value is considered virtually non-existent if it is $0$. Sparsity indicates the degree to which something is made up of such $0$ values. Sparse Matrix A matrix whose elements are mostly $0$ is referred to as a Sparse Matrix. $S$-Sparse 1 Even if there are many values, when there are only $S \ll d$</description>
    </item>
    <item>
      <title>How to Use Infinite Arrays in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2511/</link>
      <pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2511/</guid>
      <description>Overview InfiniteArrays.jl is a package that enables the use of arrays of infinite size1, and is, in fact, closely related to Lazy Arrays. Lazy Evaluation refers to the method where the computer knows what needs to be computed but postpones the calculation until it is absolutely necessary. Obviously, computers cannot understand infinity, but this method allows for the implementation of infinite arrays on computers. Code ∞ julia&amp;gt; using InfiniteArrays julia&amp;gt;</description>
    </item>
    <item>
      <title>Reading and Writing mat Files in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2509/</link>
      <pubDate>Wed, 17 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2509/</guid>
      <description>Overview MAT.jl is a library for reading and writing *.mat files, which are the data storage format used in MATLAB1. As is typical of Julia, this package does not force users to abandon their existing programming languages and habits; instead, it aims to secure users by providing an environment that is as familiar as possible. While the speed and convenience of Julia are significant advantages, MATLAB offers unique benefits for</description>
    </item>
    <item>
      <title>How to Output Simple Graphics in the Julia Console</title>
      <link>https://freshrimpsushi.github.io/en/posts/2507/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2507/</guid>
      <description>Overview UnicodePlots.jl is a library that uses Unicode characters to print graphics in the Julia REPL1, enabling lightweight yet high-quality visualization as the program runs. Code using UnicodePlots p1 = lineplot(100 |&amp;gt; randn |&amp;gt; cumsum) p1 = lineplot!(p1, 100 |&amp;gt; randn |&amp;gt; cumsum); p1 UnicodePlots.heatmap(cumsum(abs.(randn(100,100)), dims=2)) The result of running the above example code is as follows. Environment OS: Windows julia: v1.7.3 UnicodePlots v3.0.4 https://github.com/JuliaPlots/UnicodePlots.jl&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    <item>
      <title>How to Initialize the Console in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2505/</link>
      <pubDate>Tue, 09 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2505/</guid>
      <description>Method In the console, pressing Ctrl + L appears to clear the console completely, but in some environments, it does not actually reset but rather scrolls the window as if it were pushed up. To cleanly remove or not rely on keyboard input, printing ASCII character \033c can be used12. print(&amp;#34;\033c&amp;#34;) Also, printing \007 will play a notification sound. 3 It&amp;rsquo;s surprisingly useful when you want to hear the end</description>
    </item>
    <item>
      <title>Removing Missing Values in DataFrames in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2503/</link>
      <pubDate>Fri, 05 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2503/</guid>
      <description>Overview 1 In Julia, you can easily remove missing values using the dropmissing() function. Code julia&amp;gt; df = DataFrame(x = [&amp;#34;i&amp;#34;, missing, &amp;#34;k&amp;#34;, &amp;#34;j&amp;#34;], y = [1, 2, 3, missing]) 4×2 DataFrame Row │ x y │ String? Int64? ─────┼────────────────── 1 │ i 1 2</description>
    </item>
    <item>
      <title>Models of Semivariograms</title>
      <link>https://freshrimpsushi.github.io/en/posts/2502/</link>
      <pubDate>Wed, 03 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2502/</guid>
      <description>Overview In Spatial Statistics Analysis, if a Spatial Process is Isotropic and the Semivariogram satisfies $\gamma \left( \left\| \mathbf{h} \right\| \right) = \gamma (d)$, then $\gamma$ can be expressed not as a complex matrix form but as a one-dimensional scalar function, that is, $\gamma : \mathbb{R} \to \mathbb{R}$. This means that the correlation between point reference data $Y(s), Y(s + d)$ can be plotted as a line graph. Models 1</description>
    </item>
    <item>
      <title>How to Reference Environment Variables in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2499/</link>
      <pubDate>Thu, 28 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2499/</guid>
      <description>Overview This document explains how to reference environment variables in Julia1. Code Base.ENV Base.ENV[&amp;#34;JULIA_NUM_THREADS&amp;#34;] As you can see, accessing environment variables does not require loading any separate package; you can directly access them through Base.ENV. Since they are read as a dictionary, using the name of the desired environment variable as a key will return the environment variable as a string. The results of executing the above two lines of</description>
    </item>
    <item>
      <title>Definition of Variogram</title>
      <link>https://freshrimpsushi.github.io/en/posts/2498/</link>
      <pubDate>Tue, 26 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2498/</guid>
      <description>Definition 1 In a fixed subset $D \subset \mathbb{R}^{r}$ of Euclidean space , consider a space process $\left\{ Y(s) \right\}_{s \in D}$ which is a set of random variables $Y(s) : \Omega \to \mathbb{R}^{1}$ and a direction vector $\mathbf{h} \in \mathbb{R}^{r}$. Specifically, represent $n \in \mathbb{N}$ sites as $\left\{ s_{1} , \cdots , s_{n} \right\} \subset D$, and assume that $Y(s)$ has variance existing for all $s \in D$. The</description>
    </item>
    <item>
      <title>How to use progress bars in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2497/</link>
      <pubDate>Sun, 24 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2497/</guid>
      <description>Overview In Julia, you can easily use a progress bar to indicate the progress of a program. Code ProgressMeter.jl By placing the @showprogress macro from the ProgressMeter.jl package in a for loop, you can display the progress1. using ProgressMeter chi2 = [] @showprogress for n in 1:20000 push!(chi2, sum(randn(n) .^ 2)) end Compared to ProgressBars.jl below, the use of a macro makes the code more concise. ProgressBars.jl You can wrap</description>
    </item>
    <item>
      <title>Stationarity of Spatial Processes</title>
      <link>https://freshrimpsushi.github.io/en/posts/2496/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2496/</guid>
      <description>Definitions 1 Consider a spatial process $\left\{ Y(s) \right\}_{s \in D}$ and direction vector $\mathbf{h} \in \mathbb{R}^{r}$, which is a set of random variables $Y(s) : \Omega \to \mathbb{R}^{1}$ in a fixed subset $D \subset \mathbb{R}^{r}$ of Euclidean space. Specifically, represent $n \in \mathbb{N}$ number of sites as $\left\{ s_{1} , \cdots , s_{n} \right\} \subset D$, and assume that $Y(s)$ has a variance for all $s \in D$. $\left\{</description>
    </item>
    <item>
      <title>Calculating the Mean Excluding 0 or Missing Values in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2495/</link>
      <pubDate>Wed, 20 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2495/</guid>
      <description>Overview R language has options within functions like sum() or mean() to ignore missing values directly, whereas Julia lacks such options but actively employs Functional Programming approaches instead. Code julia&amp;gt; data = [0,1,2,3,0] 5-element Vector{Int64}: 0 1 2 3 0 julia&amp;gt; sum(data) / length(data) 1.2 julia&amp;gt; sum(data) / sum(!iszero, data) 2.0 The top portion results in 1.2, dividing by the total number of samples including up to $0$, while the</description>
    </item>
    <item>
      <title>Spatial Processes</title>
      <link>https://freshrimpsushi.github.io/en/posts/2494/</link>
      <pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2494/</guid>
      <description>Definition 1 Especially when it is $r &amp;gt; 1$, for a fixed subset $D \in \mathbb{R}^{r}$ of the Euclidean space, the following set of $p$-variate random vectors $Y(s) : \Omega \to \mathbb{R}^{p}$ is also referred to as a Spatial Process. $$ \left\{ Y(s) : s \in D \right\} $$ Especially when the spatial process is a finite set and represented as a vector like the following, it is also referred</description>
    </item>
    <item>
      <title>How to Perform Regression Analysis in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2493/</link>
      <pubDate>Sat, 16 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2493/</guid>
      <description>Overview This brief introduction presents the GLM.jl package for conducting regression analysis in Julia, emphasizing its similarity to the interface in R and thus, skipping detailed explanations1. Code Julia using GLM, RDatasets faithful = dataset(&amp;#34;datasets&amp;#34;, &amp;#34;faithful&amp;#34;) out1 = lm(@formula(Waiting ~ Eruptions), faithful) The result of running the above code is as follows: julia&amp;gt; out1 = lm(@formula(Waiting ~ Eruptions), faithful) StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}} Waiting ~ 1 + Eruptions Coefficients:</description>
    </item>
    <item>
      <title>What is Spatial Data Analysis?</title>
      <link>https://freshrimpsushi.github.io/en/posts/2492/</link>
      <pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2492/</guid>
      <description>Explanation 1 Spatial Data refers to data that includes information about space, and Spatial Statistics is a branch of statistics that analyzes Euclidean space $\mathbb{R}^{r}$ as &amp;lsquo;space&amp;rsquo; in the true dictionary sense. While time series analysis analyses data that changes over the time axis $t$, spatial data analysis analyses data that changes depending on the given $D \subset \mathbb{R}^{r}$, (usually when $r = 2$) location. Even at first thought, the</description>
    </item>
    <item>
      <title>Polynomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/2480/</link>
      <pubDate>Mon, 20 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2480/</guid>
      <description>Definition Let a random vector composed of $n \in \mathbb{N}$ and $k \in \mathbb{N}$ counts of random variables be denoted as $\left( X_{1} , \cdots , X_{k} \right)$. $$ \sum_{i=1}^{k} X_{i} = n \qquad \&amp;amp; \qquad \sum_{i=1}^{k} p_{i} = 1 $$ For $\mathbf{p} = \left( p_{1} , \cdots , p_{k} \right) \in [0,1]^{k}$ that satisfies this, a multivariate probability distribution $M_{k} \left( n, \mathbf{p} \right)$ with the following probability mass</description>
    </item>
    <item>
      <title>Reasons Why the Modified Bessel Function of the First Kind Appears in Directional Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2478/</link>
      <pubDate>Thu, 16 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2478/</guid>
      <description>Buildup Modified Bessel Functions $$ J_{\nu}(x) = \sum \limits_{n=0}^{\infty} \frac{(-1)^{n} }{\Gamma (n+1) \Gamma (n+\nu+1)} \left(\frac{x}{2} \right)^{2n+\nu} $$ The $I_{\nu}$ defined as follows for the Bessel function of the first kind $J_{\nu}$ is called the modified Bessel function of the first kind1. $$ \begin{align*} I_{\nu} (z) :=&amp;amp; i^{-\nu} J_{\nu} \left( iz \right) \\ =&amp;amp; \left( {{ z } \over { 2 }} \right)^{\nu} \sum_{k=0}^{\infty} {{ {{ z } \over { 2</description>
    </item>
    <item>
      <title>Definition of a Complex Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/2473/</link>
      <pubDate>Mon, 06 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2473/</guid>
      <description>Definition 1 For a non-empty subset $A,B \subset \mathbb{C}$ of the set of complex numbers $\mathbb{C}$, $f : A \to B$ is called a Complex Valued Function. On the other hand, when $A, B \subset \mathbb{R}$, $f : A \to B$ is also referred to as a Real Valued Function to distinguish it from complex functions. Explanation The above definition actually means nothing. You might wonder what all this is</description>
    </item>
    <item>
      <title>Definition of Weighted Average</title>
      <link>https://freshrimpsushi.github.io/en/posts/2470/</link>
      <pubDate>Tue, 31 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2470/</guid>
      <description>Definition The following is called the Weighted Mean for data $\mathbf{x} = \left\{ x_{1} , \cdots , x_{n} \right\}$ and vector $\mathbf{w} = \left( w_{1} , \cdots , w_{n} \right) \in \mathbb{R}^{n}$. $$ {{ \sum_{k=1}^{n} w_{k} x_{k} } \over { \sum_{k=1}^{n} w_{k} }} = {{ w_{1} x_{1} + \cdots + w_{n} x_{n} } \over { w_{1} + \cdots + w_{n} }} $$ Meanwhile, $\mathbf{w}$ is also called a weighted vector</description>
    </item>
    <item>
      <title>Topology of Complex Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/2467/</link>
      <pubDate>Wed, 25 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2467/</guid>
      <description>Overview We introduce definitions for dealing with the set of complex numbers $\mathbb{C}$ as a topological space. Although it is referred to as a topological space, most of the definitions are specializations of the definitions in a metric space for complex sets. If you have studied introductory analysis diligently, you will be able to understand these without much difficulty. Definitions 1 Let&amp;rsquo;s assume $\alpha \in \mathbb{C}$, $\delta &amp;gt; 0$ and</description>
    </item>
    <item>
      <title>Definition of a Constant Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/2465/</link>
      <pubDate>Sat, 21 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2465/</guid>
      <description>Definition A function $c : X \to Y$ is called a Constant Function if it satisfies the following for all $x_{1} , x_{2} \in X$. $$ c \left( x_{1} \right) = c \left( x_{2} \right) $$ Explanation Typically, the starting point where one first &amp;lsquo;recognizes&amp;rsquo; a constant function as a function is when learning about the differentiation of constant functions. $$ \lim_{h \to 0} {{ c \left( x + h</description>
    </item>
    <item>
      <title>Definition of a Rational Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/2463/</link>
      <pubDate>Tue, 17 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2463/</guid>
      <description>Definition 1 For any two polynomial functions $P_{1}(z), P_{2}(z) : \mathbb{C} \to \mathbb{C}$, the following function $Q$ that maps every $z \in \mathbb{C}$ for which $P_{2} (z) \ne 0$ into $\left( P_{1} / P_{2} \right) (z)$ is called a Rational Function or an Algebraic Fraction. $$ Q (z) := {{ P_{1} (z) } \over { P_{2} (z) }} \qquad \text{where } P_{2} (z) \ne 0 $$ Osborne (1999). Complex variables</description>
    </item>
    <item>
      <title>Standard Definition of Standard Error</title>
      <link>https://freshrimpsushi.github.io/en/posts/2462/</link>
      <pubDate>Sun, 15 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2462/</guid>
      <description>Definition 1 For a given estimator $T$, the estimated standard deviation of $T$ is called the standard error. $$ \text{s.e.} \left( T \right) := \sqrt{ \widehat{ \text{Var} \left( T \right) } } $$ Explanation The reason why it is precisely defined as an estimator in the definition, not a statistic, is because the standard error becomes meaningless unless we are discussing whether it &amp;lsquo;matches or not&amp;rsquo; with the parameter $\theta$</description>
    </item>
    <item>
      <title>How to Calculate the Difference Between Two Times in Seconds in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2461/</link>
      <pubDate>Fri, 13 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2461/</guid>
      <description>Overview To achieve this, one can use the canonicalize() function of the Dates module1. Code using Dates tic = DateTime(2022,3,7,7,1,11) toc = now() Dates.canonicalize(toc-tic) The result of executing the above code is as follows. julia&amp;gt; using Dates julia&amp;gt; tic = DateTime(2022,3,7,7,1,11) 2022-03-07T07:01:11 julia&amp;gt; toc = now() 2022-07-19T22:26:22.070 julia&amp;gt; Dates.canonicalize(toc-tic) 19 weeks, 1 day, 15 hours, 25 minutes, 11 seconds, 70 milliseconds It automatically calculates and outputs up to weeks, precisely</description>
    </item>
    <item>
      <title>How to Convert between 2D Arrays and Matrices in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2459/</link>
      <pubDate>Mon, 09 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2459/</guid>
      <description>Overview Introducing tips for switching between 2D arrays and matrices in Julia, which may be the simplest, fastest, and most beautiful way to do it, especially in environments of Julia 1.7 or lower1. Code There are countless ways to switch between matrices and 2D arrays, not just the method introduced here. Since the goal itself is not difficult whether you code haphazardly or not, it&amp;rsquo;s better to consider not only</description>
    </item>
    <item>
      <title>The Definition of Regression Coefficients and Derivation of Estimator Formulas</title>
      <link>https://freshrimpsushi.github.io/en/posts/2458/</link>
      <pubDate>Sat, 07 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2458/</guid>
      <description>Definition 1 $$ Y = \beta_{0} + \beta_{1} X_{1} + \cdots + \beta_{p} X_{p} + \varepsilon $$ In multiple regression analysis, for the given $p$ independent variables $X_{1} , \cdots , X_{p}$, when setting up a linear model as above, $\beta_{0} , \beta_{1} , \cdots , \beta_{p}$ is called the regression coefficient. $Y$ represents the dependent variable, and $\varepsilon$ represents the randomly distributed error. Formula $$ \begin{bmatrix} y_{1} \\ y_{2}</description>
    </item>
    <item>
      <title>How to Send an Email via Naver in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2457/</link>
      <pubDate>Thu, 05 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2457/</guid>
      <description>Overview This document introduces how to send emails from Naver using the SMTPClient.jl package with SMTP 1. I use it to send reports to Kakao Mail when long-running simulations are finished, which helps to speed up my research. This way, knowing when simulations are finished without having to check the server myself, as Jordy notifies me via personal chat. Code Regardless of the programming language, the first thing to do</description>
    </item>
    <item>
      <title>Degrees of Freedom in Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2456/</link>
      <pubDate>Tue, 03 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2456/</guid>
      <description>용어 The number of independent data that can change the value when calculating a certain statistic is called the Degree of Freedom1. 설명 Why It&amp;rsquo;s Hard to Explain Degrees of Freedom When you become a freshman and study statistics, this thing called &amp;lsquo;degrees of freedom&amp;rsquo; really gets annoying. Aside from being difficult and frequently mentioned, it&amp;rsquo;s because you can hardly see its definition clearly stated in any textbook.</description>
    </item>
    <item>
      <title>Definition of Intervals in Mathematics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2453/</link>
      <pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2453/</guid>
      <description>Definition $$ [a,b] := \left\{ x \in \mathbb{R} : a \le x \le b \right\} \subset \mathbb{R} $$ For two real numbers $a \le b$, the set as described above is called an Interval. In particular, if both endpoints $a,b$ are included, it is notated as $\left[ a,b \right]$ using square brackets [] and is said to be Closed. If both endpoints $a,b$ are not included, it is notated as</description>
    </item>
    <item>
      <title>Percentiles and Outliers</title>
      <link>https://freshrimpsushi.github.io/en/posts/2452/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2452/</guid>
      <description>Definitions 1 Given quantitative data, A value that is greater than $p \%$ but less than $(100-p) \%$ is called the $p$-percentile. The $100$-percentile and $0$-percentile (the largest and smallest values in the data) are referred to as the maximum, minimum values, respectively. The difference between the maximum and minimum values is called the data&amp;rsquo;s range $R$. The $25$-percentile is called the first quartile $Q_{1}$, and the $75$-percentile is called</description>
    </item>
    <item>
      <title>Definition of Pi</title>
      <link>https://freshrimpsushi.github.io/en/posts/2451/</link>
      <pubDate>Sat, 23 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2451/</guid>
      <description>Definitions Geometric Definition A circle is defined as the set of points in a plane that are at a given distance $r &amp;gt; 0$ from a given point. The ratio of a circle&amp;rsquo;s circumference $l$ to its diameter $2r$ is defined as the Pi $\pi$. $$ \pi := {{ l } \over { 2r }} $$ Analytical Definition 1 $$ E (z) := \sum_{k=0}^{\infty} {{ z^{k} } \over { k!</description>
    </item>
    <item>
      <title>Implementation of Zomorodian&#39;s Algorithm</title>
      <link>https://freshrimpsushi.github.io/en/posts/2449/</link>
      <pubDate>Tue, 19 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2449/</guid>
      <description>Overview This section explains and implements the pseudocode of an algorithm introduced in the paper &amp;ldquo;Computing Persistent Homology&amp;rdquo; by Zomorodian and Carlsson1. It takes a filtered complex constructed from an abstract simplicial complex and returns $\mathcal{P}$-intervals, omitting the construction of computationally challenging persistent modules and calculating persistent homology through matrix reduction. Furthermore, the actual implementation does not even use matrix operations. Derivation Derivation of Zomorodian&amp;rsquo;s algorithm: It&amp;rsquo;s certain that without</description>
    </item>
    <item>
      <title>Definition of Variance in Basic Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2448/</link>
      <pubDate>Sun, 17 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2448/</guid>
      <description>Definition 1 Let&amp;rsquo;s assume we are given $n$ quantitative data. The difference $\left( \overline{x} - x_{i} \right)$ between the sample mean $\overline{x}$ and the data is called the deviation. The value $s^{2}$, which is the sum of the squares of deviations divided by $n-1$, is known as the variance of a sample. $$ s^{2} := {{ \sum \left( x_{i} - \overline{x} \right)^{2} } \over { n-1 }} $$ Taking the</description>
    </item>
    <item>
      <title>Derivation of Zomorodian&#39;s Algorithm</title>
      <link>https://freshrimpsushi.github.io/en/posts/2447/</link>
      <pubDate>Fri, 15 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2447/</guid>
      <description>Overview The paper &amp;ldquo;Computing Persistent Homology&amp;rdquo; by Zomorodian and Carlsson introduces an algorithm for deriving $\mathcal{P}$-intervals from a Filtered Complex created by an Abstract Simplicial Complex, bypassing the construction of Persistent Modules that are challenging to handle computationally, and computing persistent homology through matrix reduction1. Derivation Part 0. Preliminary Investigation The derivation of the algorithm starts by examining the form of a Persistence Complex depicted as above, crucial for understanding</description>
    </item>
    <item>
      <title>Definition of the Mode in Basic Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2446/</link>
      <pubDate>Wed, 13 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2446/</guid>
      <description>Definitions1 When given qualitative data, the category with the highest frequency is called the Mode. In the case of quantitative data, the class with the highest frequency is called the Modal Class. Description Literally meaning &amp;rsquo;the most frequent value&amp;rsquo;, the mode disregards all information except for that singular value. Unless dealing with qualitative data, its significance greatly diminishes, making it not so important when handling real data. When viewed through</description>
    </item>
    <item>
      <title>Definition of Median in Basic Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2444/</link>
      <pubDate>Sat, 09 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2444/</guid>
      <description>Definition 1 Given $n$ quantitative data in ascending order, the value located in the middle of all the data is called the median $m$. If $n$ is odd, $m := x_{(n+1)/2}$ is used, and if $n$ is even, any values that satisfy the following are considered the median. $$ x_{1} \le \cdots \le x_{ \lceil {{ n+1 } \over { 2 }} \rceil } \le m \le x_{ \lceil {{</description>
    </item>
    <item>
      <title>Simplified Definition of Hypothesis Testing</title>
      <link>https://freshrimpsushi.github.io/en/posts/2442/</link>
      <pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2442/</guid>
      <description>Definition 1 2 In science, a statistical hypothesis refers to an assumption about a population, and the statistical decision-making process of accepting or rejecting this hypothesis is called statistical hypothesis testing. This process involves two competing hypotheses, where the hypothesis that the researcher wishes to support is called the alternative hypothesis $H_{1}$, and the hypothesis accepted when there is no substantial evidence to claim that the alternative hypothesis is true</description>
    </item>
    <item>
      <title>Filtration of Complexes</title>
      <link>https://freshrimpsushi.github.io/en/posts/2441/</link>
      <pubDate>Sun, 03 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2441/</guid>
      <description>Definition 1 Let $K$ be a simplicial complex. A subset $L \subset K$ is a Subcomplex of $K$ if it is a simplicial complex itself. $$ \emptyset = K^{0} \subset K^{1} \subset \cdots \subset K^{m} = K $$ A Nested Sequence of subcomplexes of $K$ is called the Filtration of $K$. Generally, for all $i \ge m$, it is presumed that $K^{i} = K^{m}$. When such a filtration exists, $K$</description>
    </item>
    <item>
      <title>Parameter and Statistic in Basic Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2440/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2440/</guid>
      <description>Definition 1 A Parameter is a numerical descriptive measure associated with a population, while something computed from a sample is referred to as a Statistic. Explanation Although there can be various definitions of statistics, fundamentally, it is considered a field of study which primarily focuses on &amp;lsquo;what is a Parameter&amp;rsquo; especially in inferential statistics, a field slightly more abstract from general understanding and favored by majors, including Mathematical Statistics. From</description>
    </item>
    <item>
      <title>Definition of Mean in Basic Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2438/</link>
      <pubDate>Mon, 28 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2438/</guid>
      <description>Definition 1 $$ \overline{x} := {{ 1 } \over { n }} \sum_{k=1}^{n} x_{k} $$ When $n$ quantitative data are given, the value obtained by adding all those values and dividing by $n$, denoted as $\overline{x}$, is called the sample mean, arithmetic mean, or average. Description There&amp;rsquo;s no need to explicitly explain how averages can efficiently summarize data. Anyone studying statistics beyond the undergraduate level should be able to address</description>
    </item>
    <item>
      <title>Histograms of Quantitative Data</title>
      <link>https://freshrimpsushi.github.io/en/posts/2432/</link>
      <pubDate>Wed, 16 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2432/</guid>
      <description>Definitions 1 2 Complex Definition A bar chart made from the frequency distribution of quantitative data is called a histogram. Simple Definition A histogram is a bar chart where numerical data is divided into intervals, and the frequency of data within those intervals is counted, with the sizes represented as the heights of the bars. Explanation Histograms are an indispensable visualization technique in scientific literature, especially used to represent probability</description>
    </item>
    <item>
      <title>Qualitative Data Frequency</title>
      <link>https://freshrimpsushi.github.io/en/posts/2426/</link>
      <pubDate>Fri, 04 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2426/</guid>
      <description>Definition 1 The frequency at which each observation of qualitative data appears is referred to as Frequency. Dividing the frequency by the total number of data and multiplying the relative frequency by 100 is called Relative Frequency and Percentage, respectively. How each frequency or relative frequency is distributed across several categories is known as Frequency Distribution. Explanation Frequency, often translated as frequency in the context of physics, in the context</description>
    </item>
    <item>
      <title>Definition of Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2424/</link>
      <pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2424/</guid>
      <description>Definition 1 Statistics is a collection of methods for collecting, analyzing, representing, interpreting, and making decisions about data. Descriptive statistics consist of methods that use charts or graphs and summary measures to organize, present, and describe data. Inferential statistics consist of methods for making decisions or predictions about a population from a sample. Commentary Below is a story beyond the textbook. I personally would like to define statistics as &amp;ldquo;a</description>
    </item>
    <item>
      <title>Qualitative Variable and Quantitative Variable</title>
      <link>https://freshrimpsushi.github.io/en/posts/2420/</link>
      <pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2420/</guid>
      <description>Definition 1 Qualitative Variables Variables that measure qualitative characteristics are called qualitative variables. The food is&amp;hellip; delicious / so-so / tasteless The color is&amp;hellip; red / blue / yellow The major is&amp;hellip; mathematics / statistics / physics Such qualitative variables are often referred to as categorical data. Quantitative Variables Variables that measure quantitative characteristics are called quantitative variables. Age is&amp;hellip; 20 years old / 31 years old / 11 years</description>
    </item>
    <item>
      <title>Proof of the Lifting Theorem in Algebraic Topology</title>
      <link>https://freshrimpsushi.github.io/en/posts/2419/</link>
      <pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2419/</guid>
      <description>Theorem 1 2 Definitions of Covering and Lifting: Let&amp;rsquo;s denote the unit interval as $I = [0,1]$. An open set $U \subset X$ of $X$ is evenly covered by $p$ if for every $\alpha \in \forall$, all corresponding restricted functions $p |_{\widetilde{U}_{\alpha}}$ are homeomorphisms, and $$ \alpha_{1} \ne \alpha_{2} \implies \widetilde{U}_{\alpha_{1}} \cap \widetilde{U}_{\alpha_{2}} = \emptyset $$ holds, meaning there exist disjoint open sets $\widetilde{U}_{\alpha} \subset \widetilde{X}$ in $\widetilde{X}$ such that</description>
    </item>
    <item>
      <title>Definition and Etymology of Data</title>
      <link>https://freshrimpsushi.github.io/en/posts/2418/</link>
      <pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2418/</guid>
      <description>Overview In modern society, there is no intellectual who knows absolutely nothing about data. Even non-specialists with no interest can easily think of synonyms such as &amp;lsquo;knowledge about something&amp;rsquo; or &amp;lsquo;resources for communication&amp;rsquo; like data or information, to the extent that the concept of data has become universal and popularized. The following descriptions are merely attempts to define data a little more strictly from the perspective of data science. Definition</description>
    </item>
    <item>
      <title>Covering and Lifting in Algebraic Topology</title>
      <link>https://freshrimpsushi.github.io/en/posts/2417/</link>
      <pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2417/</guid>
      <description>Definitions 1 2 Let $p : \widetilde{X} \to X$ be a continuous function between two topological spaces $\widetilde{X}, X$. Denote any index set as $\forall$, and let&amp;rsquo;s write the restriction function from $\widetilde{U}_{\alpha} \subset \widetilde{X}$ to $p$ simply as $p |_{\widetilde{U}_{\alpha}} : \widetilde{U}_{\alpha} \to U$. $I = [0,1]$ is the unit interval from $0$ to $1$. $\bigsqcup$ represents the union of disjoint sets. Covering An open set $U \subset X$</description>
    </item>
    <item>
      <title>How to Print Without Omitting Data in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2416/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2416/</guid>
      <description>Overview Originally, Julia formats the data output to fit the size of the REPL beautifully, but sometimes we want to see the entire data comfortably. If the data is foo, you can print the entire data using show(stdout, &amp;quot;text/plain&amp;quot;, foo)1. Code julia&amp;gt; foo = rand(100,2) 100×2 Matrix{Float64}: 0.956438 0.663427 0.790117 0.472821 0.976134 0.198475 0.727601 0.472336 0.0469046 0.991999 0.625807 0.26634 0.490773 0.588481 0.352966 0.426474 0.585632 0.00185974 ⋮</description>
    </item>
    <item>
      <title>Fundamental Group in Algebraic Topology</title>
      <link>https://freshrimpsushi.github.io/en/posts/2415/</link>
      <pubDate>Thu, 13 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2415/</guid>
      <description>Definition 1 Given a topological space $X$ and a unit interval $I = [0,1]$, For paths $f, g : I \to X$ in $X$, when $f (1) = g(0)$, the product or composition $f \cdot g$ of two paths is defined as: $$ f \cdot g (s) := \begin{cases} f \left( 2s \right) &amp;amp; , \text{if } s \in [0, 1/2] \\ g \left( 2s - 1 \right) &amp;amp; ,</description>
    </item>
    <item>
      <title>Homotopy Classes</title>
      <link>https://freshrimpsushi.github.io/en/posts/2413/</link>
      <pubDate>Sun, 09 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2413/</guid>
      <description>Theorem Brief Description In any topological space, the relation of a homotopy defined between any two fixed points is an equivalence relation. Detailed Description Given a topological space $X$ and two points $x_{0}, x_{1} \in X$, if the paths $f, g : I \to X$ between two points are homotopic, as expressed by $f \simeq g$, then this binary relation $\simeq$ is an equivalence relation. Moreover, the equivalence classes created</description>
    </item>
    <item>
      <title>How to Use the Linear Algebra Package in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2412/</link>
      <pubDate>Fri, 07 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2412/</guid>
      <description>Overview Julia supports [linear algebra](../../categories/Linear Algebra) as well as MATLAB does, if not better. The intuitive and elegant syntax of Julia gives a feeling that it has been well-designed since its inception1. Code julia&amp;gt; A = [ 1 0 3 0 5 1 3 1 9 ] 3×3 Matrix{Int64}: 1 0 3 0 5 1 3 1 9 As you can see, defining matrices is intuitive and easy</description>
    </item>
    <item>
      <title>Definition of Homotopy</title>
      <link>https://freshrimpsushi.github.io/en/posts/2411/</link>
      <pubDate>Wed, 05 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2411/</guid>
      <description>Definitions 1 Let&amp;rsquo;s assume that the closed unit interval $I := [0,1]$ and the topological space $X$ are given. A continuous function $p : I \to X$ from $x_{0}$ to $x_{1}$ satisfying the following for fixed points $x_{0} , x_{1} \in X$ is called a path or path. $$ \begin{align*} p(0) =&amp;amp; x_{0} \\ p(1) =&amp;amp; x_{1} \end{align*} $$ For two paths $f \equiv h_{0}$ and $g \equiv h_{1}$, the</description>
    </item>
    <item>
      <title>Using Date and Time Functions in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2410/</link>
      <pubDate>Mon, 03 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2410/</guid>
      <description>Overview 1 Dates is a module that collects functions related to dates and times. It is inevitably useful not only for general programming but also for handling a lot of data, whether it&amp;rsquo;s related to time series or not1. Code Full Code using Dates 오늘 = DateTime(2022,3,10) typeof(오늘) propertyname</description>
    </item>
    <item>
      <title>Abstract Simplicial Complexes: Definitions</title>
      <link>https://freshrimpsushi.github.io/en/posts/2409/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2409/</guid>
      <description>Definition 1 Let&amp;rsquo;s say an arbitrary set $X$ is given. A (Abstract Simplicial) Complex $A \subset 2^{X}$ that satisfies the following among the finite subsets of the power set $2^{X}$ of $X$ is defined as: $$ \alpha \in A \land \beta \subset \alpha \implies \beta \in A $$ The elements $\alpha \in A$ of the complex $A$ are called Simplices. The Dimension of a Simplex $\alpha$ $\dim$ is defined as</description>
    </item>
    <item>
      <title>Proof of the Representation Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/2408/</link>
      <pubDate>Thu, 29 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2408/</guid>
      <description>Theorem Let&amp;rsquo;s assume we are given an input set $X \ne \emptyset$ and a positive definite kernel $k: X \times X \to \mathbb{R}$. Define the Training Dataset as $$ D := \left\{ \left( x_{i} , y_{i} \right) \right\}_{i=1}^{m} \subset X \times \mathbb{R} $$ and a class in the Reproducing Kernel Hilbert Space $H_{k}$ as $$ \mathcal{F} := \left\{ f \in \mathbb{R}^{X} : f \left( \cdot \right) = \sum_{i=1}^{\infty} \beta_{i} k</description>
    </item>
    <item>
      <title>Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning</title>
      <link>https://freshrimpsushi.github.io/en/posts/2406/</link>
      <pubDate>Sun, 25 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2406/</guid>
      <description>Definition 1 2 Input Space $X \ne \emptyset$ is the domain and the codomain is the set of complex numbers $\mathbb{C}$, and let&amp;rsquo;s denote the space of functions $\left( H , \left&amp;lt; \cdot , \cdot \right&amp;gt; \right) \subset \mathbb{C}^{X}$ composed of mappings $f: X \to \mathbb{C}$ as a Hilbert space. Reproducing Kernel Hilbert Space For a fixed datum $x \in X$, the functional $\delta_{x} : H \to \mathbb{C}$, which takes</description>
    </item>
    <item>
      <title>Support Vector Machine</title>
      <link>https://freshrimpsushi.github.io/en/posts/2402/</link>
      <pubDate>Sat, 17 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2402/</guid>
      <description>Model 1 Simple Definition The method of finding a Support Vector Machine is to find a line or plane that best separates binary classifiable data. Complex Definition For an inner product space $X = \mathbb{R}^{p}$ and labeling $Y = \left\{ -1, +1 \right\}$, let&amp;rsquo;s denote the Training Dataset composed of $n$ pieces of data as $D = \left\{ \left( \mathbf{x}_{k} , y_{k} \right) \right\}_{k=1}^{n} \subset X \times Y$, and $$</description>
    </item>
    <item>
      <title>Definition of Vietoris-Rips Complex</title>
      <link>https://freshrimpsushi.github.io/en/posts/2401/</link>
      <pubDate>Thu, 15 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2401/</guid>
      <description>Definition 1 2 Simple Definition Let us assume a Euclidean space $\left( \mathbb{R}^{d} , \left\| \cdot \right\|_{2} \right)$ and a positive number $\varepsilon &amp;gt; 0$ are given. For a finite set $S \subset \mathbb{R}^{d}$, a simplicial complex $\text{VR}_{\varepsilon} (S)$ that satisfies the following two conditions is called a Vietoris-Rips Complex. (i): It has $S$ as the set of vertices. (ii): A simplex $\left[ v_{0} , v_{1} , \cdots, v_{k} \right]$</description>
    </item>
    <item>
      <title>Betti Number of Homology Group</title>
      <link>https://freshrimpsushi.github.io/en/posts/2399/</link>
      <pubDate>Sun, 11 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2399/</guid>
      <description>Overview Without considering the geometric meaning, if we just define it plainly, in Algebraic Topology, the Betti Number is merely the rank of the homology group in a chain complex. The problem is that such an explanation does not help those curious about the meaning of Betti numbers, and it&amp;rsquo;s also difficult to learn through examples because the specific calculation is daunting. In this post, we introduce a theorem that</description>
    </item>
    <item>
      <title>Distributed Computing in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2398/</link>
      <pubDate>Fri, 09 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2398/</guid>
      <description>Overview In Julia, this introduces how to schedule computations across multiple devices1. Honestly, I&amp;rsquo;m not quite sure myself. Code using Distributed ip_ = [] for last in [160,161,162,163,164,32,33,34,35,36,43,44,45,46,47] push!(ip_, join([155,230,211,last],&amp;#39;.&amp;#39;)) end sort!(ip_) for ip in ip_ addprocs([(&amp;#34;chaos@&amp;#34; * ip, 8)]; dir =&amp;#34;/home/chaos&amp;#34;, exename = &amp;#34;julia&amp;#34;) #add slave node\&amp;#39;s workers println(&amp;#34;ip $ip&amp;#34; * &amp;#34; passed&amp;#34;) end nworkers() @everywhere function f(n) return n^2 - n end A = pmap(f,1:20000) X = []</description>
    </item>
    <item>
      <title>Julia&#39;s Multidimensional Indices</title>
      <link>https://freshrimpsushi.github.io/en/posts/2394/</link>
      <pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2394/</guid>
      <description>Overview Julia provides a type of index that can reference multi-dimensional arrays, known as CatesianIndex1. Naturally, the naming Catesian comes from the Cartesian product, which is the product of sets. Code julia&amp;gt; M = rand(0:9, 4,4) 4×4 Matrix{Int64}: 9 3 7 0 8 6 2 1 3 8 4 9 5 6 8 2 For example, let&amp;rsquo;s assume you want to access the element 9, which is in</description>
    </item>
    <item>
      <title>Julia&#39;s Short Circuit</title>
      <link>https://freshrimpsushi.github.io/en/posts/2392/</link>
      <pubDate>Sun, 28 May 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2392/</guid>
      <description>Overview In Julia, &amp;amp;&amp;amp; and || not only perform logical AND and OR operations but also execute short-circuit evaluation1. For instance, A &amp;amp;&amp;amp; B returns true only if both A and B are true, but in reality, if A is false, there is no need to check whether B is true or false; A &amp;amp;&amp;amp; B is false. Short-circuit evaluation essentially skips checking B. Skipping the calculation for B can</description>
    </item>
    <item>
      <title>Julia&#39;s find functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/2390/</link>
      <pubDate>Wed, 24 May 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2390/</guid>
      <description>Overview Julia&amp;rsquo;s basic built-in functions are increasingly useful the more you know them. Without further ado, let&amp;rsquo;s learn through examples. Code x = [3, 7, 4, 5, 10, 3, 12, 3, 2, 4] argmin(x) argmax(x) findmin(x) findmax(x) extrema(x) findfirst(x .== 3) findlast(x .== 3) findall(x .== 3) findnext(x .== 3, 5) findprev(x .== 3, 5) Optimal solutions argmin(),argmax(),findmin(),findmax(),extrema() Finding the optimal solutions. x = [3, 7, 4, 5, 10, 3,</description>
    </item>
    <item>
      <title>Proof of the Existence of Smith Normal Form</title>
      <link>https://freshrimpsushi.github.io/en/posts/2389/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2389/</guid>
      <description>Algorithm $R$ is a principal ideal domain, for every matrix $A \in R^{m \times n}$, there exists a unique Smith normal form. In other words, for the matrix $A \in R^{m \times n}$, there exists $d_{1} , \cdots , d_{r} \in R$ and invertible matrices $P \in R^{m \times m}$, $Q \in R^{n \times n}$ that satisfy $$ PAQ = \begin{bmatrix} d_{1} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \cdots</description>
    </item>
    <item>
      <title>Julia&#39;s Exclamation Point Convention</title>
      <link>https://freshrimpsushi.github.io/en/posts/2388/</link>
      <pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2388/</guid>
      <description>Overview 1 In Julia, appending an exclamation mark ! at the very end of a function name is referred to as the bang convention. Such functions are characterized by modifying the arguments they are given. Code function add_1!(x) x .+= 1 return x end foo = [2,5,-1] add_1!(foo) foo For example, executing the code above yields the following result. julia&amp;gt; foo = [2,5,-1] 3-element Vector{Int64}: 2 5 -1 julia&amp;gt; add_1!(foo)</description>
    </item>
    <item>
      <title>Welzl Algorithm: Solution to Smallest Enclosing Disk Problem</title>
      <link>https://freshrimpsushi.github.io/en/posts/2385/</link>
      <pubDate>Sun, 14 May 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2385/</guid>
      <description>Problem Smallest Enclosing Disk Let&amp;rsquo;s denote it as $n &amp;gt; d$. In a $d$-dimensional Euclidean space, given a finite set $P = \left\{ p_{k} \right\}_{k=1}^{n} \subset \mathbb{R}^{d}$, the following optimization problem is referred to as the Smallest Enclosing Disk Problem: $$ \begin{matrix} \text{Minimize} &amp;amp; r \ge 0 \\ \text{subject to} &amp;amp; \left\| c - p_{k} \right\|_{2} \le r \end{matrix} \\ c \in \mathbb{R}^{d} , k = 1, \cdots , n</description>
    </item>
    <item>
      <title>How to Quickly Reference Subarrays in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2384/</link>
      <pubDate>Fri, 12 May 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2384/</guid>
      <description>Overview In Julia, view is a data structure that quickly refers to a subarray of an array, making it seem cumbersome from a user&amp;rsquo;s perspective, although there might seem to be no difference. However, it returns a lighter array as it is lazily referenced. Therefore, in Julia code that is optimized even at a very basic level, it is easy to find the macro @views. Code Let&amp;rsquo;s refer to a</description>
    </item>
    <item>
      <title>Definition of Simplicial Homology Group</title>
      <link>https://freshrimpsushi.github.io/en/posts/2383/</link>
      <pubDate>Wed, 10 May 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2383/</guid>
      <description>Buildup Despite the complexity of the content, I made sure to leave detailed calculations and explanations to make it as understandable as possible. If you&amp;rsquo;re interested in homology, I highly recommend reading this. Consider a topological space $X$ of interest, represented through a $\Delta$-complex structure according to a specific simplicial complex. As a small example, in the image on the right, the torus represents $X$, and the left side corresponds</description>
    </item>
    <item>
      <title>Julia&#39;s Broadcasting Syntax</title>
      <link>https://freshrimpsushi.github.io/en/posts/2382/</link>
      <pubDate>Mon, 08 May 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2382/</guid>
      <description>Overview Broadcasting is one of the most important concepts in Julia, offering a convenient syntax for writing vectorized code1. It is used by placing a dot . before a binary operation or after a function. This represents the application of a function in a pointwise manner, which is a perfect expression of its purpose. From a programming perspective, broadcasting can be viewed as a simplification of using Map in Map</description>
    </item>
    <item>
      <title>Definition of Simplicial Complexes</title>
      <link>https://freshrimpsushi.github.io/en/posts/2379/</link>
      <pubDate>Tue, 02 May 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2379/</guid>
      <description>Definition Difficult Definition 1 $$ \Delta^{k} \in K $$ A complex is called a Simplicial Complex if a finite set of simplices $K$ satisfies the following two conditions: (i): If $\sigma \in K$ and $\tau$ is a face of $\sigma$, then $\tau \in K$. $$ \sigma \in K \land \tau \le \sigma \implies \tau \in K $$ (ii): If $\sigma_{1}, \sigma_{2} \in K$, then $\sigma_{1} \cap \sigma_{2}$ is either an</description>
    </item>
    <item>
      <title>What is a Torus in Mathematics?</title>
      <link>https://freshrimpsushi.github.io/en/posts/2377/</link>
      <pubDate>Fri, 28 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2377/</guid>
      <description>Definition The square of the sphere $1$, denoted as $S^{1} \times S^{1} = [0,1] \times [0,1]$, and the quotient space $T$ that is homeomorphic to it according to the map shown above, is called a Torus. In the figure, the donut shape on the far right is an example of a torus. Description The torus is a space - more specifically, a figure - that is treated very preciously throughout</description>
    </item>
    <item>
      <title>Creating Dictionaries from Arrays in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2375/</link>
      <pubDate>Mon, 24 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2375/</guid>
      <description>Code 1 julia&amp;gt; Dict([&amp;#34;a&amp;#34;, &amp;#34;bc&amp;#34;] .=&amp;gt; [2,8]) Dict{String, Int64} with 2 entries: &amp;#34;a&amp;#34; =&amp;gt; 2 &amp;#34;bc&amp;#34; =&amp;gt; 8 Given two arrays you want to use as keys and values, you can create a dictionary using Dict(Key .=&amp;gt; Value). Essentially, it&amp;rsquo;s nothing more than broadcasting the =&amp;gt; operator to create pairs. Environment OS: Windows julia: v1.7.0 https://discourse.julialang.org/t/create-a-dictionary-from-arrays-of-keys-and-values/13908/3&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    <item>
      <title>What is a Complex in Topology?</title>
      <link>https://freshrimpsushi.github.io/en/posts/2374/</link>
      <pubDate>Sat, 22 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2374/</guid>
      <description>Overview In mathematics, the term &amp;ldquo;Complex&amp;rdquo; usually refers to complex numbers, but in geometry or topology, &amp;ldquo;Complex&amp;rdquo; signifies something like the following terms. Terminology A Complex is made up of topologically simple $S$s, whose intersections are of a lower dimension but of the same kind as $S$. Description As this ambiguous expression suggests, there isn&amp;rsquo;t exactly a &amp;lsquo;definition&amp;rsquo;. Whether we call the simple things a Simplex or refer to Complex</description>
    </item>
    <item>
      <title>How to Use Complex Numbers in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2373/</link>
      <pubDate>Thu, 20 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2373/</guid>
      <description>Overview In Julia, complex numbers are natively supported, similar to R. Code Imaginary unit im julia&amp;gt; z = 3 + 4im 3 + 4im im represents the pure imaginary unit $i = \sqrt{-1}$. All the common arithmetic operations that we are familiar with can be used. julia&amp;gt; typeof(z) Complex{Int64} julia&amp;gt; typeof(3.0 + 4.0im) ComplexF64 (alias for Complex{Float64}) When checking the type, even though it&amp;rsquo;s the same complex number, the type</description>
    </item>
    <item>
      <title>Topology in Mathematics: Discs and Spheres</title>
      <link>https://freshrimpsushi.github.io/en/posts/2372/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2372/</guid>
      <description>Definition 1 In the Euclidean space $\left( \mathbb{R}^{n} , \left\| \cdot \right\| \right)$, the following shapes are defined. Defined as $D^{n} \subset \mathbb{R}^{n}$, this is called $n$-Unit Disk. $$ D^{n} := \left\{ \mathbf{x} \in \mathbb{R}^{n} : \left\| \mathbf{x} \right\| \le 1 \right\} $$ Defined as $S^{n} \subset \mathbb{R}^{n+1}$, this is called $n$-Unit Sphere. $$ S^{n} := \left\{ \mathbf{x} \in \mathbb{R}^{n+1} : \left\| \mathbf{x} \right\| = 1 \right\} $$ An open</description>
    </item>
    <item>
      <title>Linear Programming Duality</title>
      <link>https://freshrimpsushi.github.io/en/posts/2348/</link>
      <pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2348/</guid>
      <description>Buildup For $x_{1} , x_{2} \ge 0$, let&amp;rsquo;s say we have the following linear programming problem. $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; 2x_{1} &amp;amp; + &amp;amp; 3x_{2} \\ \text{subject to} &amp;amp; &amp;amp; 4x_{1} &amp;amp; + &amp;amp; 8x_{2} &amp;amp; \le &amp;amp; 12 \\ &amp;amp; &amp;amp; 2x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; \le &amp;amp; 3 \\ &amp;amp; &amp;amp; 3x_{1} &amp;amp; + &amp;amp; 2x_{2} &amp;amp; \le &amp;amp; 4 \end{matrix} $$ Our goal is to</description>
    </item>
    <item>
      <title>Simplex Method&#39;s Bland&#39;s Rule</title>
      <link>https://freshrimpsushi.github.io/en/posts/2344/</link>
      <pubDate>Tue, 21 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2344/</guid>
      <description>Theorem A system of equations of the following form for Dictionary: $i = 1 , \cdots , m$ is called a Dictionary. $$ \begin{align*} \zeta &amp;amp;=&amp;amp; &amp;amp; &amp;amp; \sum_{j=1}^{n} c_{j} x_{j} \\ x_{n+i} &amp;amp;=&amp;amp; b_{i} &amp;amp;-&amp;amp; \sum_{j=1}^{n} a_{ij} x_{j} \end{align*} $$ Variables on the left side of $\zeta$, excluding the one variable, are called basic variables, and variables on the right side are called nonbasic variables. Their indices are denoted</description>
    </item>
    <item>
      <title>How to Write Conditional Statements Concisely in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2341/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2341/</guid>
      <description>Overview In Julia, &amp;lt;condition&amp;gt; &amp;amp;&amp;amp; &amp;lt;statement&amp;gt; executes &amp;lt;statement&amp;gt; when &amp;lt;condition&amp;gt; is true. As a function, it returns the result of &amp;lt;statement&amp;gt; if true, and if false, &amp;lt;statement&amp;gt; is not even evaluated. While it allows writing code efficiently and concisely, it may reduce readability. Moreover, even if you don&amp;rsquo;t use it frequently, you should understand it to read the code written by others. Without any context, encountering such syntax can be</description>
    </item>
    <item>
      <title>Linear Programming: The Simplex Method</title>
      <link>https://freshrimpsushi.github.io/en/posts/2336/</link>
      <pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2336/</guid>
      <description>Buildup 1 Consider the following Linear Programming Problem for $x_{1} , x_{2} \ge 0$. $$ \begin{matrix} \text{Maximize} &amp;amp; &amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} \\ \text{subject to} &amp;amp;-&amp;amp; x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; \le &amp;amp; 1 \\ &amp;amp; &amp;amp; x_{1} &amp;amp; &amp;amp; &amp;amp; \le &amp;amp; 3 \\ &amp;amp; &amp;amp; &amp;amp; &amp;amp; x_{2} &amp;amp; \le &amp;amp; 2 \end{matrix} $$ In other words, we want to maximize $x_{1} + x_{2}$ while</description>
    </item>
    <item>
      <title>Linear Programming: Dictionaries and Tableau</title>
      <link>https://freshrimpsushi.github.io/en/posts/2334/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2334/</guid>
      <description>Notation $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ For the matrix $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$, it is said that the linear programming problem is represented in the form of equation form as above, and let&amp;rsquo;s denote its components as follows. $$ \begin{align*} A =&amp;amp; \left( a_{ij}</description>
    </item>
    <item>
      <title>How to Replace NaN with 0 in Julia DataFrames</title>
      <link>https://freshrimpsushi.github.io/en/posts/2330/</link>
      <pubDate>Tue, 24 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2330/</guid>
      <description>Overview The method of replacing with a specific value is inconvenient because it changes one column at a time, and when dealing with NaN throughout the dataframe, it seems more practical to use a better trick. Code julia&amp;gt; df = DataFrame(rand(1:9,3,3), :auto) ./ DataFrame(rand(0:1,3,3), :auto) 3×3 DataFrame Row │ x1 x2 x3 │ Float64 Float64 Float64 ─────┼──────</description>
    </item>
    <item>
      <title>Definition of a Mathematical-Statistical Confidence Set</title>
      <link>https://freshrimpsushi.github.io/en/posts/2329/</link>
      <pubDate>Sun, 22 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2329/</guid>
      <description>Definition 1 The following is referred to as the coverage probability for the interval estimator $\left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right]$ of parameter $\theta$. $$ P_{\theta} \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] \right) = P \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] | \theta \right) $$ The infimum of the coverage probability is</description>
    </item>
    <item>
      <title>Julia&#39;s Ternary Operator ? :</title>
      <link>https://freshrimpsushi.github.io/en/posts/2328/</link>
      <pubDate>Fri, 20 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2328/</guid>
      <description>Overview In Julia, A ? B : C is known as the Ternary Operator, which returns B if A is true and C otherwise. Just like binary operations are defined as functions in mathematics, the ternary operation is also a function. It&amp;rsquo;s similar to an if statement but has this fundamental difference, making it very useful once you&amp;rsquo;re accustomed to it. However, it can make the code less readable, so</description>
    </item>
    <item>
      <title>How to Change a Specific Value in a DataFrame in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2326/</link>
      <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2326/</guid>
      <description>Overview To make replacements, use the replace!() method1. The first argument should be the column of the dataframe you want to change, and the second argument takes a pair A =&amp;gt; B. It&amp;rsquo;s important that it&amp;rsquo;s the dataframe&amp;rsquo;s column being specified here. Code julia&amp;gt; WJSN 10×4 DataFrame Row │ member birth height unit │ String Int64 Int64 String ─────┼───</description>
    </item>
    <item>
      <title>How to Calculate Frequency in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2324/</link>
      <pubDate>Thu, 12 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2324/</guid>
      <description>Overview 1 Use the freqtable() function from the FreqTables.jl package. It provides a similar functionality to the freq() function in R. Code Arrays julia&amp;gt; compartment = rand([&amp;#39;S&amp;#39;,&amp;#39;I&amp;#39;,&amp;#39;R&amp;#39;], 1000); julia&amp;gt; freqtable(compartment) 3-element Named Vector{Int64} Dim1 │ ──────┼──── &amp;#39;I&amp;#39; │ 316 &amp;#39;R&amp;#39; │ 342 &amp;#39;S&amp;#39; │ 342 By inserting an array like shown above, it will count the frequency for each class.</description>
    </item>
    <item>
      <title>Reading Only Columns from a CSV File in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2322/</link>
      <pubDate>Sun, 08 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2322/</guid>
      <description>Guide Let&amp;rsquo;s say we have an example.csv file like the one above. When loading it into a dataframe, sometimes we want to create an entirely empty dataframe that only retains the column names, without importing all the data. This is necessary in cases where an empty dataframe is needed. using CSV # Loading the dataframe with no rows df_empty = CSV.read(&amp;#34;example.csv&amp;#34;, DataFrame; limit = 0) In the resulting dataframe created</description>
    </item>
    <item>
      <title>How to View Data Frame Summaries in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2320/</link>
      <pubDate>Wed, 04 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2320/</guid>
      <description>Guide 1 using RDatasets iris = dataset(&amp;#34;datasets&amp;#34;, &amp;#34;iris&amp;#34;) describe(iris) describe() function can be used. Let&amp;rsquo;s summarize the iris data. julia&amp;gt; describe(iris) 5×7 DataFrame Row │ variable mean min median max nmissing eltype │ Symbol Union… Any Union… Any Int64 DataType ─────┼────────────</description>
    </item>
    <item>
      <title>Julia&#39;s Categorical Array</title>
      <link>https://freshrimpsushi.github.io/en/posts/2318/</link>
      <pubDate>Sat, 31 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2318/</guid>
      <description>Overview The CategoricalArrays.jl package in Julia serves a similar function to factor in R. Code julia&amp;gt; A = [&amp;#34;red&amp;#34;, &amp;#34;blue&amp;#34;, &amp;#34;red&amp;#34;, &amp;#34;green&amp;#34;] 4-element Vector{String}: &amp;#34;red&amp;#34; &amp;#34;blue&amp;#34; &amp;#34;red&amp;#34; &amp;#34;green&amp;#34; julia&amp;gt; B = categorical(A) 4-element CategoricalArray{String,1,UInt32}: &amp;#34;red&amp;#34; &amp;#34;blue&amp;#34; &amp;#34;red&amp;#34; &amp;#34;green&amp;#34; julia&amp;gt; levels(B) 3-element Vector{String}: &amp;#34;blue&amp;#34; &amp;#34;green&amp;#34; &amp;#34;red&amp;#34; categorical() The categorical() function allows for casting a regular array to a categorical array. levels() With the levels() function, one can view the categories. Naturally,</description>
    </item>
    <item>
      <title>Definition of Simplex</title>
      <link>https://freshrimpsushi.github.io/en/posts/2317/</link>
      <pubDate>Thu, 29 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2317/</guid>
      <description>Definition 1 A $n$-simplex $\Delta^{n}$, whose convex hull consists of affinely independent $v_{0}, v_{1} , \cdots , v_{n} \in \mathbb{R}^{n+1}$, has vertices $v_{k}$. Formally, it is defined as follows: $$ \Delta^{n} := \left\{ \sum_{k} t_{k} v_{k} : v_{k} \in \mathbb{R}^{n+1} , t_{k} \ge 0 , \sum_{k} t_{k} = 1 \right\} $$ The faces of a $\Delta^{n}$ are the $n-1$-simplices $\Delta^{n-1}$ formed by removing a single vertex from $\Delta^{n}$. The boundary</description>
    </item>
    <item>
      <title>How to Load a Built-in Dataset in R Used in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2316/</link>
      <pubDate>Tue, 27 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2316/</guid>
      <description>Guide Using the RDatasets.jl package should do the trick. The following is an example of how to load the simplest iris dataset. It includes a variety of datasets beyond the basic built-in ones, so make sure to check out GitHub1. julia&amp;gt; using RDatasets julia&amp;gt; iris = dataset(&amp;#34;datasets&amp;#34;, &amp;#34;iris&amp;#34;) 150×5 DataFrame Row │ SepalLength SepalWidth PetalLength PetalWidth Species │ Float64 Float64 Float64 Float64 Cat…</description>
    </item>
    <item>
      <title>Definition of Affine Independence</title>
      <link>https://freshrimpsushi.github.io/en/posts/2315/</link>
      <pubDate>Sun, 25 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2315/</guid>
      <description>Definition 1 A set of vectors $S := \left\{ v_{0} , v_{1}, \cdots , v_{n} \right\} \subset V$ is said to be Affinely Independent if the vectors in $S$ or $S$ itself are linearly independent. $$ v_{1} - v_{0} , v_{2} - v_{0} , \cdots , v_{n} - v_{0} $$ https://glossary.informs.org/ver2/mpgwiki/index.php?title=Affine_independence&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    <item>
      <title>How to Check Package Versions in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2313/</link>
      <pubDate>Wed, 21 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2313/</guid>
      <description>## Guide For example, let&amp;#39;s check the version of the `Plots.jl` package. Press the `]` key in the REPL to enter the package mode. Here, if you type `status foo`, you can check the version of the `foo` package as follows. ![20211204_193048.png](20211204_193048.png#center) ## Environment - OS: Windows - julia: v1.6.3</description>
    </item>
    <item>
      <title>How to Check if an Array is Empty in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2311/</link>
      <pubDate>Sat, 17 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2311/</guid>
      <description>Overview Use the isempty() function. Code julia&amp;gt; isempty([]) true julia&amp;gt; isempty(Set()) true julia&amp;gt; isempty(&amp;#34;&amp;#34;) true Though it&amp;rsquo;s mentioned as an array in the title, it actually could be a set or a string. Optimization Of course, checking if an array is empty by seeing if length() is $0$ might be fine too. julia&amp;gt; @time for t in 1:10^6 isempty([]) end 0.039721 seconds (1000.00 k allocations: 76.294 MiB, 27.85% gc time)</description>
    </item>
    <item>
      <title>Definition of Homology Groups</title>
      <link>https://freshrimpsushi.github.io/en/posts/2310/</link>
      <pubDate>Thu, 15 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2310/</guid>
      <description>Definitions 1 2 Let&amp;rsquo;s denote by $n \in \mathbb{N}_{0}$. A chain of abelian groups $C_{n}$ and homomorphisms $\partial_{n} : C_{n} \longrightarrow C_{n-1}$ $$ \cdots \longrightarrow C_{n+1} \overset{\partial_{n+1}}{\longrightarrow} C_{n} \overset{\partial_{n}}{\longrightarrow} C_{n-1} \longrightarrow \cdots \longrightarrow C_{1} \overset{\partial_{1}}{\longrightarrow} C_{0} \overset{\partial_{0}}{\longrightarrow} 0 $$ that satisfies $$ \partial_{n} \circ \partial_{n+1} = 0 $$ for all $n$ is called a Chain Complex. The quotient group $H_{n} := \ker \partial_{n} / \text{Im} \partial_{n+1}$ is called the $n$-th</description>
    </item>
    <item>
      <title>How to Handle Exceptions in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2309/</link>
      <pubDate>Tue, 13 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2309/</guid>
      <description>Overview People who have struggled with severe loneliness know, oh they know Anyone who has struggled with unknown errors while coding understands the critical importance of errors in programming&amp;hellip; In Julia, errors can be thrown using the error() function or the @error macro. As of Julia v1.63, 25 types of built-in exceptions are defined1. Code julia&amp;gt; log(1 + 2im) 0.8047189562170501 + 1.1071487177940904im Consider, for instance, when using the logarithmic function</description>
    </item>
    <item>
      <title>How to Check DataFrame Size in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2307/</link>
      <pubDate>Fri, 09 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2307/</guid>
      <description>Overview nrow(), ncol(), and size() can be used. Unlike with R, length() results in an error. Code julia&amp;gt; df = DataFrame(rand(100000,5), :auto) 100000×5 DataFrame Row │ x1 x2 x3 x4 x5 │ Float64 Float64 Float64 Float64 Float64 ────────┼─────────────────</description>
    </item>
    <item>
      <title>Free Groups in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/2306/</link>
      <pubDate>Wed, 07 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2306/</guid>
      <description>Definition 1 Given an index set $I \ne \emptyset$, let&amp;rsquo;s refer to the set $A := \left\{ a_{i} : i \in I \right\}$ as the alphabet, and its elements $a_{i} \in A$ as letters. For an integer $n \in \mathbb{Z}$, expressions like $a_{i}^{n}$ are referred to as syllables. A finite juxtaposition of these, $w$, is called a word. A syllable $a_{i}^{n} a_{i}^{m}$ can be represented as $a_{i}^{n+m}$, this is called</description>
    </item>
    <item>
      <title>How to Create a DataFrame with Variable Names as Column Names in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2305/</link>
      <pubDate>Mon, 05 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2305/</guid>
      <description>Overview Named tuples can be used. The way to create a named tuple is by attaching a semicolon ; right after the left parenthesis. For example, if you say DataFrame(; x, y), a DataFrame is created with column names :x and :y, and the contents are x and y respectively. Code julia&amp;gt; MyCol7 = rand(5); B = 1:5; julia&amp;gt; DataFrame(; MyCol7, B) 5×2 DataFrame Row │ MyCol7 B</description>
    </item>
    <item>
      <title>Julia&#39;s Named Tuples</title>
      <link>https://freshrimpsushi.github.io/en/posts/2303/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2303/</guid>
      <description>Overview Named tuples are tuples that, unlike regular tuples, can be used like dictionaries or structures. They have an array of symbols as keys and allow access to values via those keys, all the while retaining their tuple-like usage. Code x = rand(Bool, 5); y = rand(Bool, 5); z = (; x, y) typeof(z) z.x Let&amp;rsquo;s run the above code to see how named tuples are used. julia&amp;gt; z =</description>
    </item>
    <item>
      <title>F-Vector Spaces in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/2300/</link>
      <pubDate>Fri, 25 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2300/</guid>
      <description>Definition A vector space is a module that is a field for a given ring $R = F$.</description>
    </item>
    <item>
      <title>Abstract Algebra in R-modules</title>
      <link>https://freshrimpsushi.github.io/en/posts/2298/</link>
      <pubDate>Mon, 21 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2298/</guid>
      <description>Definitions 1 An Abelian group $(G,+)$ with the identity element for multiplication $1 \ne 0$, and a ring $(R,+,\cdot)$ satisfy the following three conditions for the binary operation $$ \mu : R \times G \to G $$, then $\left( G, +, R, \cdot ; \mu \right)$ is called an $R$-module: (M1) Bi-additivity: For $\forall \alpha, \beta \in R$ and $\forall x,y \in G$, $$ \begin{align*} \mu \left( \alpha + \beta</description>
    </item>
    <item>
      <title>Power of a Nuisance Test and the Most Powerful Test</title>
      <link>https://freshrimpsushi.github.io/en/posts/2293/</link>
      <pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2293/</guid>
      <description>Definition 1 Hypothesis Testing: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ A power function $\beta (\theta)$ is said to be unbiased if it satisfies the following for all $\theta_{0} \in \Theta_{0}$ and $\theta_{1} \in \Theta_{0}^{c}$: $$ \beta \left( \theta_{0} \right) \le \beta \left( \theta_{1} \right) $$ Let $\mathcal{C}$ be a set comprising such hypothesis tests. A hypothesis test $A$ that has a</description>
    </item>
    <item>
      <title>Power Function of Hypothesis Testing</title>
      <link>https://freshrimpsushi.github.io/en/posts/2291/</link>
      <pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2291/</guid>
      <description>Definition 1 Hypothesis Testing: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ Given the hypothesis testing above, let&amp;rsquo;s denote it as $\alpha \in [0,1]$. For the parameter $\theta$, the function $\beta (\theta) := P_{\theta} \left( \mathbf{X} \in \mathbb{R} \right)$ with the rejection region $R$ is called the Power Function. If $\sup_{\theta \in \Theta_{0}} \beta (\theta) = \alpha$, then the given hypothesis test is</description>
    </item>
    <item>
      <title>Transition Probabilities of Stochastic Processes</title>
      <link>https://freshrimpsushi.github.io/en/posts/2284/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2284/</guid>
      <description>Definition Let us assume there is a stochastic process $\left\{ X_{t} \right\}$ with a countable set as its state space. For two points in time $t_{1} &amp;lt; t_{2}$, the transition probability $p_{ij} \left( t_{1} , t_{2} \right)$ is defined as follows: $$ p_{ij} \left( t_{1} , t_{2} \right) := P \left( X_{t_{2}} = j \mid X_{t_{1}} = i \right) $$ Here, the (current) state represented by $i$ is referred to</description>
    </item>
    <item>
      <title>Mathematical Statistical Hypothesis Testing Definition</title>
      <link>https://freshrimpsushi.github.io/en/posts/2283/</link>
      <pubDate>Sat, 22 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2283/</guid>
      <description>Definition A proposition about a parameter is called a Hypothesis. The problem of accepting hypothesis $H_{0}$ as true based on a given sample, or rejecting hypothesis $H_{0}$ and adopting hypothesis $H_{1}$ is called a Hypothesis Test. In hypothesis testing, the complementary hypotheses $H_{0}$, $H_{1}$ are called the Null Hypothesis and the Alternative Hypothesis, respectively. The subset $R \subset \Omega$ of the sample space $\Omega$ that leads to the rejection of</description>
    </item>
    <item>
      <title>How to Insert Command Line Arguments in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2280/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2280/</guid>
      <description>English Translation Code println(ARGS[1] * &amp;#34; + &amp;#34; * ARGS[2] * &amp;#34; = &amp;#34; * string(parse(Float64, ARGS[1]) + parse(Float64, ARGS[2]))) Let&amp;rsquo;s say we have a file named example.jl that consists of a single line as shown above. In Julia, we can receive command line arguments as an array through ARGS, similar to how sys.argv works with command line arguments in Python. The code written is a program that takes two</description>
    </item>
    <item>
      <title>Executing External Programs in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2278/</link>
      <pubDate>Wed, 12 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2278/</guid>
      <description>Code In Julia, the run() function is used to execute a string wrapped in backticks `. This is similar to using the os.system() from the os module in Python. julia&amp;gt; txt = &amp;#34;helloworld&amp;#34; &amp;#34;helloworld&amp;#34; julia&amp;gt; typeof(`echo $txt`) Cmd 위와 같이 백틱으로 감싸진 문자열은 Cmd라는 타입을 가지고, run() 함수로써</description>
    </item>
    <item>
      <title>Converting String to Number in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2276/</link>
      <pubDate>Sat, 08 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2276/</guid>
      <description>Code To convert a string str to a number of type type, use parse(type, str). julia&amp;gt; parse(Int, &amp;#34;21&amp;#34;) 21 julia&amp;gt; parse(Float64, &amp;#34;3.14&amp;#34;) 3.14 You might wonder why we can&amp;rsquo;t do something like Int64(&amp;quot;21&amp;quot;) as in Python&amp;hellip; That&amp;rsquo;s because changing &amp;lsquo;&amp;ldquo;21&amp;rdquo;&amp;rsquo; into 21 is not about changing types but interpreting the string &amp;quot;21&amp;quot; as a number, which justifies the use of parse1. Environment OS: Windows julia: v1.6.3 https://discourse.julialang.org/t/why-are-there-all-these-strange-stumbling-blocks-in-julia/92644/2&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    <item>
      <title>Best Unbiased Estimator, Minimum Variance Unbiased Estimator UMVUE</title>
      <link>https://freshrimpsushi.github.io/en/posts/2273/</link>
      <pubDate>Sun, 02 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2273/</guid>
      <description>Definition 1 Let us assume that parameter $\theta$ is given. If an unbiased estimator $W^{\ast}$ satisfies the following condition over all other unbiased estimators $W$, it is called the Best Unbiased Estimator or the Uniform Minimum Variance Unbiased Estimator (UMVUE). $$ \text{Var}_{\theta} W^{\ast} \le \text{Var}_{\theta} W \qquad , \forall \theta $$ Explanation UMVUE is sometimes simply referred to as MVUE, dropping the initial Uniform part. The term UMVUE might be</description>
    </item>
    <item>
      <title>How to Define Variadic Functions in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2266/</link>
      <pubDate>Sun, 18 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2266/</guid>
      <description>Overview 1 A Varargs Function, commonly mentioned in programming, is a function that can receive an unlimited number of arguments. In Julia, you can simply set a variable to accept variadic arguments by appending ... after it. Let&amp;rsquo;s understand this with an example code. Additionally, this ... is called splat operator.2 Code Isaac Newton famously discovered that adding the reciprocals of factorials simply converges to $e$ with the following theorem.</description>
    </item>
    <item>
      <title>How to Check the Element Type Inside a Julia Container</title>
      <link>https://freshrimpsushi.github.io/en/posts/2264/</link>
      <pubDate>Wed, 14 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2264/</guid>
      <description>Overview To achieve this, use the eltype() function. It likely gets its name from element type. Code julia&amp;gt; set_primes = Set([2,3,5,7,11,13]) Set{Int64} with 6 elements: 5 13 7 2 11 3 julia&amp;gt; arr_primes = Array([2,3,5,7,11,13]) 6-element Vector{Int64}: 2 3 5 7 11 13 Consider two types of containers that hold prime numbers up to $13$. Honestly, they contain the same data, but one is a set while the other is</description>
    </item>
    <item>
      <title>How to Change the Basic Settings of a Julia Plot</title>
      <link>https://freshrimpsushi.github.io/en/posts/2262/</link>
      <pubDate>Sat, 10 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2262/</guid>
      <description>Code You can use the default() function. using Plots default(size = (400,400), color = :red) default(:size, (400,400)) for key in [:size, :color], value in [(400,400), :red] default(key, value) end There is a way to set it up like the ordinary plot() function, and there is a way to change them one by one by giving key and value. Usually, the former is more convenient, but in the case of very</description>
    </item>
    <item>
      <title>How to Remove Specific Rows from a DataFrame in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2260/</link>
      <pubDate>Tue, 06 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2260/</guid>
      <description>Overview When indexing, you can use the Not() function1. If you input the symbol of the column name as is, or an array of symbols, those columns are excluded from the indexing. Code using DataFrames WJSN = DataFrame( member = [&amp;#34;다영&amp;#34;,&amp;#34;다원&amp;#34;,&amp;#3</description>
    </item>
    <item>
      <title>How to Insert Vertical and Horizontal Lines in Figures in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2258/</link>
      <pubDate>Fri, 02 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2258/</guid>
      <description>Overview To draw vertical and horizontal lines, use the vline!() and hline!() functions respectively. Code @time using Plots plot(rand(100)) hline!([0.5], linewidth = 2) vline!([25, 75], linewidth = 2) png(&amp;#34;result&amp;#34;) The positions where lines are drawn should be passed as an array. If the array contains multiple elements, multiple lines will be drawn at once. Environment OS: Windows julia: v1.6.3</description>
    </item>
    <item>
      <title>How to Create Art Styles in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2256/</link>
      <pubDate>Mon, 29 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2256/</guid>
      <description>Overview RecipesBase.jl is a package that allows users to create their own styles for new plots, similar to how ggplot works in the R programming language, with its own unique syntax1 separate from the base Julia. Let&amp;rsquo;s learn through examples. Code using Plots using DataFrames df = DataFrame(x = 1:10, y = rand(10)) plot(df) @userplot TimeEvolution @recipe function f(te::TimeEvolution) df = te.args[1] linealpha --&amp;gt; 0.5 column_names = names(df) for (column_index,</description>
    </item>
    <item>
      <title>Grouping and Calculating DataFrames in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2254/</link>
      <pubDate>Thu, 25 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2254/</guid>
      <description>Overview Using groupby() to divide by group and combine() for calculation is the way to go1. groupby(df, :colname) Returns a GroupedDataFrame based on :colname. combine(gdf, :colname =&amp;gt; fun) gdf is a GroupedDataFrame divided by groups. :colname =&amp;gt; fun represents a pair of the symbol :colname, which is the name of the column containing the values to be calculated, and the calculation function fun. Code using DataFrames using StatsBase WJSN =</description>
    </item>
    <item>
      <title>How to Delete Duplicate Rows in DataFrames in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2252/</link>
      <pubDate>Sun, 21 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2252/</guid>
      <description>Overview To achieve this, we can use unique(). More precisely, it leaves only one of the duplicates rather than deleting duplicated rows. Code using DataFrames WJSN = DataFrame( member = [&amp;#34;다영&amp;#34;,&amp;#34;다원&amp;#34;,&amp;#34;루다&amp;#34;,</description>
    </item>
    <item>
      <title>Location Family</title>
      <link>https://freshrimpsushi.github.io/en/posts/2251/</link>
      <pubDate>Fri, 19 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2251/</guid>
      <description>Definition For a given cumulative distribution function $F$, suppose $F_{\theta}$ satisfies $F_{\theta} (x) = F \left( x - \theta \right)$ for all $x$. $\left\{ F_{\theta} : \theta \in \mathbb{R} \right\}$ is referred to as a Location Family. Example 1 Considering a random sample $X_{1} , \cdots , X_{n}$ with parameter $\theta$ that possesses a cumulative distribution function $F_{0} (x) = F (x - 0) = F(x)$, the sample $Z_{1} ,</description>
    </item>
    <item>
      <title>Drawing Subplots with a Layout in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2250/</link>
      <pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2250/</guid>
      <description>Overview In Julia, options related to subplots can be controlled through the layout option. Entering an integer automatically creates a grid of that many plots. Entering a 2-tuple of integers creates a grid exactly as specified. The @layout macro is used to create complex layouts of the Plots.GridLayout type. Code using Plots left = plot(randn(100), color = :red) right = plot(randn(100), color = :blue) plot(left, right) png(&amp;#34;easyone&amp;#34;) data = rand(10,</description>
    </item>
    <item>
      <title>Auxiliary Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2249/</link>
      <pubDate>Mon, 15 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2249/</guid>
      <description>Definition 1 Let $S$ be a statistic of sample $\mathbf{X}$. If the distribution of $S \left( \mathbf{X} \right)$ does not depend on the parameter $\theta$, it is called an Ancillary Statistic. Description Actually, nobody says ancillary statistic in conversation, they pronounce it as [ancillary statistic]. If a sufficient statistic has all the information about $\theta$, then an ancillary statistic can be thought of as a statistic that has no information</description>
    </item>
    <item>
      <title>Adjusting the Position of the Legend in Julia Plots</title>
      <link>https://freshrimpsushi.github.io/en/posts/2248/</link>
      <pubDate>Sat, 13 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2248/</guid>
      <description>Overview 1 The position of the legend can be freely adjusted with the legend option of the plot() function. Giving a 2-tuple comprised of values between $0$ and $1$ will exactly place it at that location, otherwise, it can be controlled by symbols. Symbols combine top/bottom and left/right in order. Adding an outer at the very beginning places the legend outside of the plot. Examples of symbols that can be</description>
    </item>
    <item>
      <title>How to Adjust the Aspect Ratio of a Julia Set Picture</title>
      <link>https://freshrimpsushi.github.io/en/posts/2246/</link>
      <pubDate>Tue, 09 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2246/</guid>
      <description>Overview 1 To adjust the width and height of the figure, you can include the ratio option. Other recommended aliases include aspect_ratios, axis_ratio. ratio = :none: The default value, where the figure&amp;rsquo;s size is adjusted to fit the ratio. ratio = :equal: Regardless of the figure&amp;rsquo;s size, the x and y axes are adjusted to a one-to-one ratio. ratio = Number: The ratio is adjusted according to Number. Number is</description>
    </item>
    <item>
      <title>Solving Broken Characters when Exporting CSV in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2244/</link>
      <pubDate>Fri, 05 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2244/</guid>
      <description>Error using DataFrames, CSV example = DataFrame(x = 1:10, 가 = &amp;#34;나다&amp;#34;) CSV.write(&amp;#34;example.csv&amp;#34;, example) When outputting to a CSV file in Julia, you can see a phenomenon where the Korean text becomes garbled, as shown above. Cause The garbling isn&amp;rsquo;t actually due to the Korean text itself but a Unicode encoding issue, especially due to the UTF-8 encoding&amp;rsquo;s</description>
    </item>
    <item>
      <title>- Text Formatting Package in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2242/</link>
      <pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2242/</guid>
      <description>Overview The Crayons.jl package is known for decorating text output in Julia1. If you want to decorate using only built-in functions, you can use printstyled(). Code using Crayons print(Crayon(background = :red), &amp;#34;빨강&amp;#34;) print(Crayon(foreground = :blue), &amp;#34;파랑&amp;#34;) print(Crayon(bold = true), &amp;#34;볼드</description>
    </item>
    <item>
      <title>Inserting a Line into a Julia Set Image</title>
      <link>https://freshrimpsushi.github.io/en/posts/2240/</link>
      <pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2240/</guid>
      <description>Code using Plots scatter(rand(100), randn(100)) plot!([0,1],[0,1]) png(&amp;#34;example1&amp;#34;) plot!([.00,.25,.50],[-2,0,-2]) png(&amp;#34;example2&amp;#34;) θ = 0:0.01:2π plot!(.5 .+ cos.(θ)/3, 1.5sin.(θ)) png(&amp;#34;example3&amp;#34;) Let&amp;rsquo;s learn how to insert line segments into the diagram by executing the code above. Line Segment plot!([0,1],[0,1]) Whether you draw just one line segment or</description>
    </item>
    <item>
      <title>Definition of Likelihood Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/2239/</link>
      <pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2239/</guid>
      <description>Definition 1 Let&amp;rsquo;s denote the joint probability density function or probability mass function of a sample $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right)$ as $f(\mathbf{x}|\theta)$. When a realization $\mathbf{x}$ is given, regarding $f(\mathbf{x}|\theta)$ as a function of $\theta$ $$ L \left( \theta | \mathbf{x} \right) := f \left( \mathbf{x} | \theta \right) $$ is called the Likelihood Function. Explanation In the context of discussing maximum likelihood estimators, it</description>
    </item>
    <item>
      <title>How to Sort Dataframe in julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2238/</link>
      <pubDate>Sun, 24 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2238/</guid>
      <description>Code using DataFrames Unit1 = DataFrame( member = [&amp;#34;다영&amp;#34;,&amp;#34;루다&amp;#34;,&amp;#34;수빈&amp;#34;,&amp;#34;진숙&amp;#34;], birth = [99,97,96,99], height = [161,157,159,162] ) Unit2</description>
    </item>
    <item>
      <title>Inserting a New Row into a DataFrame in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2236/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2236/</guid>
      <description>Code using DataFrames Unit1 = DataFrame( member = [&amp;#34;다영&amp;#34;,&amp;#34;루다&amp;#34;,&amp;#34;수빈&amp;#34;,&amp;#34;진숙&amp;#34;], birth = [99,97,96,99], height = [161,157,159,162] ) Unit2</description>
    </item>
    <item>
      <title>Using Infinity in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2234/</link>
      <pubDate>Sat, 16 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2234/</guid>
      <description>Overview Infinities.jl is a package that aids in using infinity symbols in Julia1. Surprisingly, infinity is quite useful in scientific computing coding. Code julia&amp;gt; 8 &amp;lt; Inf true The reason it&amp;rsquo;s mentioned that it helps in using infinity symbols, not just infinity, in the introduction is that you can actually use them without the package. julia&amp;gt; using Infinities julia&amp;gt; 8 &amp;lt; ∞ true julia&amp;gt; -∞ &amp;lt; 8 true julia&amp;gt;</description>
    </item>
    <item>
      <title>How to Install a Specific Version of a Package in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2232/</link>
      <pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2232/</guid>
      <description>Guide 1 (@v1.6) pkg&amp;gt; status JuMP Status `C:\Users\rmsms\.julia\environments\v1.6\Project.toml` [4076af6c] JuMP v0.20.0 By pressing the ] key in the REPL, you enter the package mode. For example, if you want to upgrade a package version from v0.20.0 to v0.21, you can do so by appending @x.yy to the package as follows. (@v1.6) pkg&amp;gt; add JuMP@0.21 Resolving package versions... ... (@v1.6) pkg&amp;gt; status JuMP Status `C:\Users\rmsms\.julia\environments\v1.6\Project.toml` [4076af6c] JuMP v0.21.4 If you check</description>
    </item>
    <item>
      <title>How to Make Empty DataFrame in julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2230/</link>
      <pubDate>Fri, 08 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2230/</guid>
      <description>Overview Despite many languages supporting dataframes, surprisingly, creating empty arrays can be a new and annoying task each time. Code Type Specification julia&amp;gt; using DataFrames julia&amp;gt; df1 = DataFrame(x = Int64[], y = String[]) 0×2 DataFrame You actually just need to insert an empty array as data. At this point, a type is specified, but when there&amp;rsquo;s absolutely no data, neither column names nor types are visible. julia&amp;gt;</description>
    </item>
    <item>
      <title>Definition of Convex Hull</title>
      <link>https://freshrimpsushi.github.io/en/posts/2228/</link>
      <pubDate>Mon, 04 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2228/</guid>
      <description>Definition 1 The convex hull $C$ of a subset $X$ of a vector space $V$ refers to the intersection of all convex sets that contain $X$, and is mathematically defined as follows. $$ C = \left\{ \sum_{k} t_{k} \mathbf{x}_{k} : \mathbf{x}_{k} \in X, t_{k} \ge 0 , \sum_{k} t_{k} = 1 \right\} $$ Explanation The equation mentioned in the definition isn&amp;rsquo;t exactly a definition per se. The expression $$ \sum_{k}</description>
    </item>
    <item>
      <title>How to Find a Specific Pattern Location in Julia Strings</title>
      <link>https://freshrimpsushi.github.io/en/posts/2226/</link>
      <pubDate>Thu, 30 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2226/</guid>
      <description>Code julia&amp;gt; findfirst(&amp;#34;li&amp;#34;, &amp;#34;multicolinearlity&amp;#34;) 8:9 julia&amp;gt; findlast(&amp;#34;li&amp;#34;, &amp;#34;multicolinearlity&amp;#34;) 14:15 julia&amp;gt; findnext(&amp;#34;l&amp;#34;, &amp;#34;multicolinearlity&amp;#34;, 1) 3:3 julia&amp;gt; findnext(&amp;#34;l&amp;#34;, &amp;#34;multicolinearlity&amp;#34;, 4) 8:8 julia&amp;gt; findnext(&amp;#34;l&amp;#34;, &amp;#34;multicolinearlity&amp;#34;, 9) 14:14 julia&amp;gt; findfirst(r&amp;#34;t.+t&amp;#34;, &amp;#34;multicolinearlity&amp;#34;) 4:16 findfirst(pattern, A) Returns a Range representing the interval matching pattern in the string A. The pattern can include regular expressions. In the last example, it finds and returns the interval from the first t to the last t.</description>
    </item>
    <item>
      <title>How to Check if a Specific String is Contained in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2224/</link>
      <pubDate>Sun, 26 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2224/</guid>
      <description>Code julia&amp;gt; contains(&amp;#34;qwerty&amp;#34;, &amp;#34;er&amp;#34;) true julia&amp;gt; contains(&amp;#34;qwerty&amp;#34;, &amp;#34;et&amp;#34;) false julia&amp;gt; contains(&amp;#34;qwerty&amp;#34;, r&amp;#34;q?&amp;#34;) true contains(haystack::AbstractString, needle) Returns a boolean indicating whether needle is contained in haystack. needle can include regular expressions, such as r&amp;quot;...&amp;quot;. Note that &amp;lsquo;haystack&amp;rsquo; means a hay pile, referring to the idiom &amp;ldquo;a needle in a haystack&amp;rdquo;. Environment OS: Windows julia: v1.6.2</description>
    </item>
    <item>
      <title>Linear Programming Problem Basis Solution</title>
      <link>https://freshrimpsushi.github.io/en/posts/2223/</link>
      <pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2223/</guid>
      <description>Definition 1 $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ Given matrices $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$ for a Linear Programming Problem represented in the equation form, a set $B \subseteq [n]$ with cardinality $m$ exists for the feasible solution $\mathbf{x} \in \mathbb{R}^{n}$, satisfying the following two conditions,</description>
    </item>
    <item>
      <title>How to Use Factorization and Prime Number Functions in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2222/</link>
      <pubDate>Wed, 22 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2222/</guid>
      <description>Overview Primes.jl is a package that deals with functions related to primes and prime factorization. The implementation of functions related to analytic number theory is still lacking. This is not a comprehensive list of all the features of the package, but rather a selection of the useful ones. For more details, check the repository1. Types Prime Factorization Primes.Factorization julia&amp;gt; factor(12) 2^2 * 3 julia&amp;gt; factor(12)[1] 0 julia&amp;gt; factor(12)[2] 2 julia&amp;gt;</description>
    </item>
    <item>
      <title>Linear Programming Problem in Equation Form</title>
      <link>https://freshrimpsushi.github.io/en/posts/2221/</link>
      <pubDate>Mon, 20 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2221/</guid>
      <description>Definition 1 For matrices $A \in \mathbb{R}^{m \times n}$, $\mathbf{b} \in \mathbb{R}^{m \times 1}$, and $\mathbf{c} \in \mathbb{R}^{n}$, the following linear programming problem is called in standard form or equational form. $$ \begin{matrix} \text{Maximize} &amp;amp; \mathbf{c}^{T} \mathbf{x} \\ \text{subject to} &amp;amp; A \mathbf{x} = \mathbf{b} \\ &amp;amp; \mathbf{x} \ge \mathbf{0} \end{matrix} $$ $\mathbf{c}^{T}$ means transpose. Optimization refers to maximization or minimization. Description Conversion to Standard Form In principle, any linear</description>
    </item>
    <item>
      <title>How to Use Polynomials in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2220/</link>
      <pubDate>Sat, 18 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2220/</guid>
      <description>Overview Polynomials.jl is a package that includes the representation and computation of polynomial functions. Since polynomials are mathematically simple, there&amp;rsquo;s a tendency to think their coding should be straightforward, too. However, once you start implementing the necessary features, it can become quite cumbersome. Of course, it&amp;rsquo;s not extremely difficult, but it&amp;rsquo;s generally better to use a package whenever possible. This is not an exhaustive list of all features of the</description>
    </item>
    <item>
      <title>Weibull Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/2219/</link>
      <pubDate>Thu, 16 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2219/</guid>
      <description>Definition A Weibull Distribution is a probability distribution with the following probability density function, given scale parameter $\lambda &amp;gt; 0$ and shape parameter $k &amp;gt; 0$. $$ f(x) = {{ k } \over { \lambda }} \left( {{ x } \over { \lambda }} \right)^{k-1} e^{-(x/\lambda)^{k}} \qquad , x \ge 0 $$ Theorems [1] A Generalization of the Exponential Distribution: The Weibull Distribution becomes the Exponential Distribution when $k=1$. [2]</description>
    </item>
    <item>
      <title>Concatenating Strings in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2218/</link>
      <pubDate>Tue, 14 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2218/</guid>
      <description>Code Concatenate Strings * julia&amp;gt; &amp;#34;oh&amp;#34; * &amp;#34;my&amp;#34; * &amp;#34;girl&amp;#34; &amp;#34;ohmygirl&amp;#34; Corresponds to the + in Python. Concatenate Multiple Strings string() julia&amp;gt; string(&amp;#34;oh&amp;#34;,&amp;#34;my&amp;#34;, &amp;#34;girl&amp;#34;) &amp;#34;ohmygirl&amp;#34; Corresponds to paste0() in R. Joining Items of a List of Strings join() julia&amp;gt; OMG = [&amp;#34;oh&amp;#34;,&amp;#34;my&amp;#34;, &amp;#34;girl&amp;#34;] 3-element Vector{String}: &amp;#34;oh&amp;#34; &amp;#34;my&amp;#34; &amp;#34;girl&amp;#34; julia&amp;gt; join(OMG) &amp;#34;ohmygirl&amp;#34; Corresponds to join() in Python. Repeat the Same String ^ julia&amp;gt; &amp;#34;=-&amp;#34; ^ 10 &amp;#34;=-=-=-=-=-=-=-=-=-=-&amp;#34; Corresponds to * in</description>
    </item>
    <item>
      <title>Hiding Specific Data Labels in Julia Plots</title>
      <link>https://freshrimpsushi.github.io/en/posts/2216/</link>
      <pubDate>Fri, 10 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2216/</guid>
      <description>Code 1 using Plots x = rand(30) y = rand(30) z = rand(30) plot(x) plot!(y) plot!(z) png(&amp;#34;result1&amp;#34;) In some cases, you might want to make only certain data labels appear in the legend, as shown above. label = &amp;quot;&amp;quot; plot(x, label = &amp;#34;&amp;#34;) plot!(y) png(&amp;#34;result2&amp;#34;) In such cases, you can set the option label = &amp;quot;&amp;quot;. As you can see, the first data is displayed in the figure, but it</description>
    </item>
    <item>
      <title>How to Insert Text into a Julia Plot</title>
      <link>https://freshrimpsushi.github.io/en/posts/2214/</link>
      <pubDate>Mon, 06 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2214/</guid>
      <description>Code 1 You can use annotate!(). The following code is for drawing a picture that marks the maximum and minimum points in Brownian motion. using Plots cd(@__DIR__) data = cumsum(randn(100)) plot(data, color = :black, legend = :none) annotate!(argmax(data), maximum(data), &amp;#34;max\n&amp;#34;) annotate!(argmin(data), minimum(data), &amp;#34;\nmin&amp;#34;) png(&amp;#34;result&amp;#34;) Environment OS: Windows julia: v1.7.0 https://discourse.julialang.org/t/plots-annotate/37784&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    <item>
      <title>Inserting Korean Text into Julia Plots</title>
      <link>https://freshrimpsushi.github.io/en/posts/2212/</link>
      <pubDate>Thu, 02 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2212/</guid>
      <description>Environment OS: Windows julia: v1.6.2 Error julia&amp;gt; plot(data, color = :black, label = &amp;#34;값&amp;#34;, title = &amp;#34;브라운모션&amp;#34;) GKS: glyph missing from current font: 48652 GKS: glyph missing from current font: 46972 GKS: glyph missing from current font: 50868 GKS: glyph missing from current font:</description>
    </item>
    <item>
      <title>Definition of Linear Programming Problem</title>
      <link>https://freshrimpsushi.github.io/en/posts/2207/</link>
      <pubDate>Mon, 23 May 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2207/</guid>
      <description>Definition 1 A linear programming problem, shortly referred to as LP, is an optimization problem that is linear in both its objective function and constraints. Simply put, a linear problem looks to find $\mathbf{x} \in \mathbb{R}^{n}$ for which the objective function $f: \mathbb{R}^{n} \to \mathbb{R}$, given vectors $\mathbf{c} \in \mathbb{R}^{n}$, is $$ f \left( \mathbf{x} \right) := \mathbf{c}^{T} \mathbf{x} $$ and for given matrices $A \in \mathbb{R}^{m \times n}$ and</description>
    </item>
    <item>
      <title>Handling Strings in Julia like in Python</title>
      <link>https://freshrimpsushi.github.io/en/posts/2205/</link>
      <pubDate>Thu, 19 May 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2205/</guid>
      <description>Code 1 2 3 julia&amp;gt; replace(&amp;#34;qwerty&amp;#34;, &amp;#34;q&amp;#34;=&amp;gt;&amp;#34;Q&amp;#34;) &amp;#34;Qwerty&amp;#34; julia&amp;gt; join(&amp;#34;qwerty&amp;#34;, &amp;#34;,&amp;#34;) &amp;#34;q,w,e,r,t,y&amp;#34; julia&amp;gt; split(&amp;#34;qwerty&amp;#34;, &amp;#34;&amp;#34;) 6-element Vector{SubString{String}}: &amp;#34;q&amp;#34; &amp;#34;w&amp;#34; &amp;#34;e&amp;#34; &amp;#34;r&amp;#34; &amp;#34;t&amp;#34; &amp;#34;y&amp;#34; Julia is not particularly outstanding in string processing, but maybe because of that, it has followed Python closely making it easy and quick to learn. Most of the already known functionalities are implemented, so apart from whether it&amp;rsquo;s a module or not, the usage is almost similar.</description>
    </item>
    <item>
      <title>How to Check Approximate Values in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2203/</link>
      <pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2203/</guid>
      <description>Code Using the comparison operator $\approx$, it only returns true when two values are sufficiently similar. ≈ can be used by entering \approx and then pressing Tab, just as in $\TeX$. julia&amp;gt; π ≈ 3.141592653 true julia&amp;gt; π ≈ 3.14159265 true julia&amp;gt; π ≈ 3.1415926 false julia&amp;gt; π ≈ 3.141592 false Environment OS: Windows julia: v1.7.0</description>
    </item>
    <item>
      <title>From Julia: Dictionaries and Pairs</title>
      <link>https://freshrimpsushi.github.io/en/posts/2201/</link>
      <pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2201/</guid>
      <description>Code 1 julia&amp;gt; d = Dict(&amp;#34;A&amp;#34;=&amp;gt;1, &amp;#34;B&amp;#34;=&amp;gt;2) Dict{String, Int64} with 2 entries: &amp;#34;B&amp;#34; =&amp;gt; 2 &amp;#34;A&amp;#34; =&amp;gt; 1 julia&amp;gt; push!(d,(&amp;#34;C&amp;#34;,3)) ERROR: MethodError: no method matching push!(::Dict{String, Int64}, ::Tuple{String, Int64}) julia&amp;gt; push!(d,&amp;#34;C&amp;#34; =&amp;gt; 3) Dict{String, Int64} with 3 entries: &amp;#34;B&amp;#34; =&amp;gt; 2 &amp;#34;A&amp;#34; =&amp;gt; 1 &amp;#34;C&amp;#34; =&amp;gt; 3 julia&amp;gt; typeof(&amp;#34;C&amp;#34; =&amp;gt; 3) Pair{String, Int64} Dictionaries in Julia are data types that pair Keys and Values, much like in other programming languages.</description>
    </item>
    <item>
      <title>How to Store Data like .mat in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2199/</link>
      <pubDate>Sat, 07 May 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2199/</guid>
      <description>Overview JLD.jl is a package that allows the storage of temporary data created while using Julia1. It is useful for managing the input and output of data in pure Julia projects. On the other hand, JLD2.jl, which further improves the intuitiveness of the JLD.jl interface, is also available. 2 The content introduced in this post should be taken as a rough understanding of these functionalities, and it is recommended to</description>
    </item>
    <item>
      <title>How to Refer to Both Index and Value in Julia&#39;s Loops</title>
      <link>https://freshrimpsushi.github.io/en/posts/2197/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2197/</guid>
      <description>Code 1 Base.Iterators.enumerate() returns an iterator that allows referencing both the index and value of an array, similar to Python. julia&amp;gt; x = [3,5,4,1,2] 5-element Vector{Int64}: 3 5 4 1 2 julia&amp;gt; for (idx, value) in enumerate(x) println(&amp;#34;x[▷eq1◁value&amp;#34;) end x[1]:</description>
    </item>
    <item>
      <title>Symbols in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2195/</link>
      <pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2195/</guid>
      <description>Overview When first encountering Julia, one might be perplexed by the symbol data type. Symbols are used with a preceding :, functioning simply by their name without any internal data. They are commonly used as names, labels, or dictionary keys1. Explanation In other programming languages, when giving options to a function, they are often provided as numbers or strings to clarify the meaning. For example, the following two functions illustrate</description>
    </item>
    <item>
      <title>Definition of a Hit in Baseball</title>
      <link>https://freshrimpsushi.github.io/en/posts/2194/</link>
      <pubDate>Wed, 27 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2194/</guid>
      <description>Definition 1 The number of balls hit by the batter that land in the valid area, excluding fielder&amp;rsquo;s choices and errors, is called a hit, abbreviated as H. Hits are classified into four types: singles, doubles, triples, and home runs. Summary [1]: For Plate Appearances PA, At Bats AB, and Hits H, the following inequality is established: $$ \begin{align*} H \le AB \le PA \\ 안타 \le 타수</description>
    </item>
    <item>
      <title>How to Check if Elements of an Array Belong to a List in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2193/</link>
      <pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2193/</guid>
      <description>Guide 1 julia&amp;gt; x = rand(&amp;#39;a&amp;#39;:&amp;#39;c&amp;#39;, 10) 10-element Vector{Char}: &amp;#39;a&amp;#39;: ASCII/Unicode U+0061 (category Ll: Letter, lowercase) &amp;#39;a&amp;#39;: ASCII/Unicode U+0061 (category Ll: Letter, lowercase) &amp;#39;b&amp;#39;: ASCII/Unicode U+0062 (category Ll: Letter, lowercase) &amp;#39;c&amp;#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase) &amp;#39;b&amp;#39;: ASCII/Unicode U+0062 (category Ll: Letter, lowercase) &amp;#39;c&amp;#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase) &amp;#39;c&amp;#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase) &amp;#39;c&amp;#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase) &amp;#39;b&amp;#39;: ASCII/Unicode U+0062 (category Ll:</description>
    </item>
    <item>
      <title>Definition of At-bats in Baseball</title>
      <link>https://freshrimpsushi.github.io/en/posts/2192/</link>
      <pubDate>Sat, 23 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2192/</guid>
      <description>Definition 1 The term At Bat, abbreviated as AB, refers to the number of times a batter hits a ball, reaches base on a fielder&amp;rsquo;s choice, reaches base on an error, or gets out (excluding sacrifice hits). Theorem [1]: The equation for a batter&amp;rsquo;s plate appearances (PA), at-bats (AB), walks (BB), hit by pitch (HBP), sacrifice bunts (SH), sacrifice fly (SF), and reaching base due to batter or runner interference</description>
    </item>
    <item>
      <title>How to Use Elegant Loops in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2191/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2191/</guid>
      <description>Guide while The while loop is no different from other languages. julia&amp;gt; while x &amp;lt; 10 x += 1 print(&amp;#34;▷eq1◁i - &amp;#34;) end 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - julia&amp;gt; for i = 1:10 print(</description>
    </item>
    <item>
      <title>Scale-Free Network</title>
      <link>https://freshrimpsushi.github.io/en/posts/2183/</link>
      <pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2183/</guid>
      <description>Definition 1 A random network whose degree distribution follows a Pareto distribution is known as a Scale-free Network. Description The term Scale-free (SF) network comes from the scale-invariance of the Pareto distribution. Being defined by its degree distribution, it strongly inherits the properties of that distribution. Mathematically, the degree $v \in V(G)$ of nodes in a scale-free network $G$ can be described by some parameter $\gamma &amp;gt; 0$ as follows.</description>
    </item>
    <item>
      <title>Pareto Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/2181/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2181/</guid>
      <description>Definition 1 For the scale parameter $x_{0} &amp;gt; 0$ and the shape parameter $\alpha &amp;gt; 0$, the following probability function is referred to as the Pareto Distribution, Power Law, or Scale-free Distribution: Continuous: For a constant $C$ that satisfies constant $\displaystyle \int_{x_{0}}^{\infty} p(x) dx = 1$ $$ p(x) = C x^{-\alpha} \qquad , x &amp;gt; x_{0} $$ Discrete: For the Riemann zeta function $\zeta$ $$ p_{k} = {{ 1 }</description>
    </item>
    <item>
      <title>Using TeX in Plots in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2180/</link>
      <pubDate>Wed, 30 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2180/</guid>
      <description>Code 1 To use the LaTeXStrings library, prefix strings with L, like so L&amp;quot;...&amp;quot;. @time using Plots @time using LaTeXStrings plot(0:0.1:2π, sin.(0:0.1:2π), xlabel = L&amp;#34;x&amp;#34;, ylabel = L&amp;#34;y&amp;#34;) title!(L&amp;#34;\mathrm{TeX\,representation:\,} y = \sin x , x \in [0, 2 \pi]&amp;#34;) Note that the package</description>
    </item>
    <item>
      <title>How to Make a Transparent Background in Graphics with Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2173/</link>
      <pubDate>Wed, 16 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2173/</guid>
      <description>Code 1 If the browser is in dark mode, you can clearly see that the background has been rendered transparent. You just need to insert the :transparent symbol into the background_color option. It saves well as *.png, but it is said that it doesn&amp;rsquo;t save well as *.pdf. using Plots plot(rand(10), background_color = :transparent) png(&amp;#34;example&amp;#34;) As you can guess from the option name, if you put in a color symbol,</description>
    </item>
    <item>
      <title>Prime and Composite Numbers</title>
      <link>https://freshrimpsushi.github.io/en/posts/2163/</link>
      <pubDate>Thu, 24 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2163/</guid>
      <description>Definition 1 A prime number is a natural number $p \ge 2$ that has only $1$ and $p$ as its divisors. A natural number $m \ge 2$ that is not a prime number is called a composite number. Explanation According to the definition, $2$ is naturally a prime number. The scope of numbers dealt with in Number Theory is quite broad, extending to rational numbers, but the actual subject of</description>
    </item>
    <item>
      <title>The Difference Between == and === in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2157/</link>
      <pubDate>Sat, 12 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2157/</guid>
      <description>Code 1 == compares whether values are the same, and === operates differently depending on whether the values to be compared are Mutable or not. Mutable: Checks if both terms refer to the same object, in other words, it returns whether the two variables can be programmatically distinguished or not. Immutable: Checks if both terms are of the same type, Checks if both terms have the same structure, And recursively</description>
    </item>
    <item>
      <title>Derivation of Black-Scholes Model</title>
      <link>https://freshrimpsushi.github.io/en/posts/2156/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2156/</guid>
      <description>Model 1 At time point $t$, let&amp;rsquo;s say the price of $S_{t}$ units of the underlying asset $1$, and assume that $S_{t}$ undergoes Geometric Brownian Motion. That is, for Standard Brownian Motion $W_{t}$, drift $\mu \in \mathbb{R}$, and diffusion $\sigma^{2} &amp;gt; 0$, $S_{t}$ is the solution to the following Stochastic Differential Equation. $$ d S_{t} = S_{t} \left( \mu dt + \sigma d W_{t} \right) $$ When a risk-free rate</description>
    </item>
    <item>
      <title>Geometric Brownian Motion</title>
      <link>https://freshrimpsushi.github.io/en/posts/2154/</link>
      <pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2154/</guid>
      <description>Definition 1 Let&amp;rsquo;s say the following Stochastic Differential Equation (SDE) is given by $\mu \in \mathbb{R}$ and $\sigma^{2} &amp;gt; 0$. $$ d X_{t} = X_{t} \left( \mu dt + \sigma d B_{t} \right) $$ The solution of this SDE is found as a Stochastic Process for the initial value $X_{0}$, which is referred to as Geometric Brownian Motion. $$ X_{t} = X_{0} \exp \left[ \left( \mu - {{ \sigma^{2} }</description>
    </item>
    <item>
      <title>How to Invert a Bit Array in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2149/</link>
      <pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2149/</guid>
      <description>Code 1 It&amp;rsquo;s quite simple, but a common mistake is to treat the negation operators ! and ~ not as unary operators but as functions, and use !. or ~.. They should be written as .! or .~ instead. julia&amp;gt; a = rand(1,10) .&amp;lt; 0.5 1×10 BitMatrix: 1 1 0 0 1 0 1 0 0 0 julia&amp;gt; .!(a) 1×10 BitMatrix: 0 0 1</description>
    </item>
    <item>
      <title>How to Open a Dialog Box and Select a File Like file.choose() in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2143/</link>
      <pubDate>Sat, 15 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2143/</guid>
      <description>Code 1 using Gtk file_name = open_dialog(&amp;#34;파일 열기&amp;#34;) The string given as the first argument is the title of the dialog. When executed, you can see a &amp;lsquo;Open File&amp;rsquo; dialog popping up like this. Environment OS: Windows julia: v1.6.0 https://discourse.julialang.org/t/choose-a-file-interactively/10910/3&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    <item>
      <title>Greatest Common Divisor and Coprime</title>
      <link>https://freshrimpsushi.github.io/en/posts/2137/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2137/</guid>
      <description>Definition 1 For two integers $n$ and $m \ne 0$, if there exists an integer $k$ that satisfies the following, $n$ is divisible by $m$. $$ n = mk $$ In this case, $n$ is called a Multiple of $m$, and $m$ is called a Divisor of $n$, as indicated below. $$ m \mid n $$ If $m$ cannot divide $n$, it is denoted by striking through as $m \nmid</description>
    </item>
    <item>
      <title>How to Round to a Specific Decimal Place in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2133/</link>
      <pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2133/</guid>
      <description>Code In fact, Julia is not a very convenient language for things like string formatting. While there are methods that utilize the intrinsic capabilities of strings for printing to the console, often it&amp;rsquo;s more convenient to use the round() function&amp;rsquo;s default option, digits. julia&amp;gt; for k in 0:8 println(round(π, digits = k)) end 3.0 3.1</description>
    </item>
    <item>
      <title>How to Specify Heatmap Color Ranges in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2126/</link>
      <pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2126/</guid>
      <description>Code 1 When drawing a heatmap, sometimes it&amp;rsquo;s essential to fix the scale of values, so they don&amp;rsquo;t adjust with the numerical values. You can fix the color range using the clim option in the basic heatmap function. using Plots cd(@__DIR__) heatmap(rand(4,4)); png(&amp;#34;1.png&amp;#34;) heatmap(rand(4,4), clim = (0,1)); png(&amp;#34;2.png&amp;#34;) The results are as follows. The first heatmap has no fixed range, but the second heatmap&amp;rsquo;s range is fixed between 0 and</description>
    </item>
    <item>
      <title>What is a Stochastic Differential Equation?</title>
      <link>https://freshrimpsushi.github.io/en/posts/2125/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2125/</guid>
      <description>Definition 1 $$ d X(t) = f \left( t, X(t) \right) dt + g \left( t, X(t) \right) d W_{t} \qquad , t \in \left[ t_{0} , T \right], T &amp;gt; 0 $$ Equations of the form above are called Stochastic Differential Equations, abbreviated as SDEs. Here, $f$ and $g$ are called the drift and diffusion coefficient functions, respectively. For the initial condition $X_{0} := X \left( t_{0} \right)$, the</description>
    </item>
    <item>
      <title>How to Use zfill() in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2124/</link>
      <pubDate>Wed, 08 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2124/</guid>
      <description>Overview 1 In Python, zfill() actually serves as a method of the string class, filling the left side with zeros. Julia, on the other hand, offers the lpad() as a more versatile and widely applicable built-in function. While zfill() means to fill with zeros, lpad() signifies padding to the left. Code julia&amp;gt; lpad(&amp;#34;12&amp;#34;, 4, &amp;#34;0&amp;#34;) &amp;#34;0012&amp;#34; julia&amp;gt; lpad(12, 4, &amp;#34;0&amp;#34;) &amp;#34;0012&amp;#34; Continuing from the overview, lpad() in Julia is more</description>
    </item>
    <item>
      <title>Ito&#39;s Formula</title>
      <link>https://freshrimpsushi.github.io/en/posts/2121/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2121/</guid>
      <description>Theorem 1 Given an Itô process $\left\{ X_{t} \right\}_{t \ge 0}$, $$ d X_{t} = u dt + v d W_{t} $$ for a function $V \left( t, X_{t} \right) = V \in C^{2} \left( [0,\infty) \times \mathbb{R} \right)$, let $Y_{t} := V \left( t, X_{t} \right)$, then $\left\{ Y_{t} \right\}$ is also an Itô process and the following holds: $$ \begin{align*} d Y_{t} =&amp;amp; V_{t}</description>
    </item>
    <item>
      <title>Checking Struct Properties in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2120/</link>
      <pubDate>Tue, 30 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2120/</guid>
      <description>Code propertynames() You can check with the propertynames() function1. Since Julia has no classes, only structs2, all symbols returned by this function are precisely the names of properties only. The following is code for creating an Erdős–Rényi network in the Graphs package, checking the number of nodes, and each node&amp;rsquo;s neighborhood. The propertynames() function was used on this network, and</description>
    </item>
    <item>
      <title>Ito Process</title>
      <link>https://freshrimpsushi.github.io/en/posts/2119/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2119/</guid>
      <description>Definition 1 Given a probability space $( \Omega , \mathcal{F} , P)$ and a filtration $\left\{ \mathcal{F}_{t} \right\}_{t \ge 0}$, suppose that a Wiener process $\left\{ W_{t} \right\}_{t \ge 0}$ is $\mathcal{F}_{t}$-adapted, and for $f \in \mathcal{L}^{1} [0 , \infty)$ and $g \in \mathcal{L}^{2} [0 , \infty)$, we define a $1$-dimensional continuous $\mathcal{F}_{t}$-adapted stochastic process $\left\{ X_{t} \right\}_{t \ge 0}$ as a $1$-dimensional Itô Process. $$ X (t)</description>
    </item>
    <item>
      <title>Gilbert Model</title>
      <link>https://freshrimpsushi.github.io/en/posts/2118/</link>
      <pubDate>Fri, 26 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2118/</guid>
      <description>Definition 1 2 Simple Definition A random network where links of a simple network are connected independently according to probability $p \in [0,1]$ is called the Gilbert Model $\mathbb{G}_{n,p}$. Complicated Definition Given a probability space $( \Omega , \mathcal{F} , P)$, and a network&amp;rsquo;s properties $2^{\binom{n}{2}} \subseteq 2^{\binom{n}{2}}$ with $n$ labeled nodes. A function that is measurable with respect to $\mathcal{F}$ and has the following probability mass function for the</description>
    </item>
    <item>
      <title>Random Graphs</title>
      <link>https://freshrimpsushi.github.io/en/posts/2114/</link>
      <pubDate>Thu, 18 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2114/</guid>
      <description>Definitions Simple Definition A graph that is created by a nondeterministic procedure or expressed according to some probability distribution is called a Random Graph. Complex Definition Given a probability space $( \Omega , \mathcal{F} , P)$, let $2^{\binom{n}{2}}$ represent the collection of all labeled graphs with $n$ vertices, known as a graph family. A function $\mathbb{G} : \Omega \to 2^{\binom{n}{2}}$, which is $\mathcal{F}$-measurable, is called a Random Graph. In other</description>
    </item>
    <item>
      <title>Ito Calculus</title>
      <link>https://freshrimpsushi.github.io/en/posts/2111/</link>
      <pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2111/</guid>
      <description>Buildup Before discussing stochastic integrals, it is crucial to define an essential probabilistic process called the Elementary Process. Elementary processes play a similar role to simple functions, which were necessary for defining the Lebesgue integral in [Measure Theory](../../categories/Measure Theory). $$ a = t_{0} &amp;lt; t_{1} &amp;lt; \cdots &amp;lt; t_{k} = b $$ Considering such a partition in the Natural Domain $[a,b]$, an Elementary Process is defined as follows for indicator</description>
    </item>
    <item>
      <title>Intersection of a Plane and a Normal Vector</title>
      <link>https://freshrimpsushi.github.io/en/posts/2110/</link>
      <pubDate>Wed, 10 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2110/</guid>
      <description>Definition 1 Let a subset of the Euclidean space $2$ have coordinates $U \subset \mathbb{R}^{2}$ and $u_{1}$, then the directional derivatives $\mathbf{x}_{1}$ and $\mathbf{x}_{2}$ can be referred to as follows on a simple surface $\mathbf{x} : U \to \mathbb{R}^{3}$. $$ \begin{align*} \mathbf{x}_{1} := {{ \partial \mathbf{x} } \over { \partial u_{1} }} &amp;amp; , &amp;amp; \mathbf{x}_{2} := {{ \partial \mathbf{x} } \over { \partial u_{2} }} \end{align*} $$ The plane</description>
    </item>
    <item>
      <title>m2 Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/2109/</link>
      <pubDate>Mon, 08 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2109/</guid>
      <description>Definition 1 2 Given that there is a probability space $( \Omega , \mathcal{F} , P)$, A sequence of sub sigma fields $\left\{ \mathcal{F}_{t} \right\}_{t \ge 0}$ of $\mathcal{F}$ is called a Filtration if it satisfies the following: $$ \forall s &amp;lt; t, \mathcal{F}_{s} \subset \mathcal{F}_{t} $$ A stochastic process $g(t,\omega) : [0,\infty) \times \Omega \to \mathbb{R}^{n}$ is said to be $\mathcal{F}_{t}$-Adapted if for all $t \ge 0$, $\omega \mapsto</description>
    </item>
    <item>
      <title>Simple Surfaces, Coordinate Mapping</title>
      <link>https://freshrimpsushi.github.io/en/posts/2106/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2106/</guid>
      <description>Definition 1 1 Let&amp;rsquo;s consider subsets $U \subset \mathbb{R}^{2}$ of a $2$-dimensional Euclidean space with coordinates $u_{1}$, $u_{2}$ to be open sets. If there exists a $C^{k}$ injective function $\mathbf{x} : U \to \mathbb{R}^{3}$ that satisfies the following for all $p \in U$, it is called a Simple Surface. $$ {{ \partial \mathbf{x} } \over { \partial u_{1} }} (p) \times {{ \partial \mathbf{x} } \over { \partial u_{2} }}</description>
    </item>
    <item>
      <title>How to Create an Array Filled with a Specific Value in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2101/</link>
      <pubDate>Sat, 23 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2101/</guid>
      <description>Code fill() function can be used. It serves a similar purpose to the rep() function in R.</description>
    </item>
    <item>
      <title>How to Read SHP Files in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2097/</link>
      <pubDate>Fri, 15 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2097/</guid>
      <description>Code The code to read a shp file named XsDB_주거인구_100M_TM.shp is as follows. using Shapefile cd(@__DIR__) path = &amp;#34;XsDB_주거인구_100M_TM.shp&amp;#34; table</description>
    </item>
    <item>
      <title>How to truncate decimal points and convert to an integer in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2095/</link>
      <pubDate>Mon, 11 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2095/</guid>
      <description>## Summary To use the `trunc` function, simply pass `Int` as the first argument. ## Code julia&amp;gt; @time for t in 1:10^8 Int64(ceil(t/1000)) end 0.189653 seconds julia&amp;gt; @time for t in 1:10^8 trunc(Int64, ceil(t/1000)) end 0.128472 seconds The two loops perform the identical task but with about a 1.5 times speed difference. The former drops the decimal points using `ceil` and type casts to `Int64`, whereas the latter returns an</description>
    </item>
    <item>
      <title>Definition of a Simple Curve</title>
      <link>https://freshrimpsushi.github.io/en/posts/2094/</link>
      <pubDate>Sat, 09 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2094/</guid>
      <description>Definition 1 A regular curve $\beta (t)$ is said to be simple if $\beta$ is an injective function or it is a closed curve with period $a &amp;gt; 0$ that satisfies the following for some integer $n \in \mathbb{Z}$: $$ \beta \left( t_{1} \right) = \beta \left( t_{2} \right) \iff t_{1} - t_{2} = na $$ Example Cases like the above, which cannot be represented as an injective function but</description>
    </item>
    <item>
      <title>Renaming Column Names of a DataFrame in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2093/</link>
      <pubDate>Thu, 07 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2093/</guid>
      <description>Overview To rename columns, you can use the rename!() function1. You can rename them all at once by providing a list of strings, or individually. Code using DataFrames df = DataFrame(rand(1:9, 10, 3), :auto) rename!(df, [&amp;#34;X&amp;#34;, &amp;#34;Y&amp;#34;, &amp;#34;Z&amp;#34;]) rename!(df, :X =&amp;gt; :A) When executed, it first creates the following dataframe: julia&amp;gt; df = DataFrame(rand(1:9, 10, 3), :auto) 10×3 DataFrame Row │ x1 x2 x3 │ Int64 Int64</description>
    </item>
    <item>
      <title>Definition of a Closed Curve</title>
      <link>https://freshrimpsushi.github.io/en/posts/2092/</link>
      <pubDate>Tue, 05 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2092/</guid>
      <description>Definition 1 A regular curve $\beta (t)$ being a closed curve is equivalent to being a periodic function $\beta$. Formula: Length of a Closed Curve If $\alpha (s)$ is the arc length parameterization of a closed curve $\beta (t)$ with period $a&amp;gt;0$, then $\alpha$ is a closed curve with period $L = \int_{0}^{a} |d \beta / dt| dt$. In other words, the length of the closed curve $\beta$ is $L$.</description>
    </item>
    <item>
      <title>How to Calculate Distance using NearstNeibors.jl in julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2088/</link>
      <pubDate>Mon, 27 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2088/</guid>
      <description>Overview To calculate the distance between $n$ points, if there&amp;rsquo;s no need to create a matrix but just to compute the distance, using a k-d tree1, a data structure advantageous for multi-dimensional search, can enhance speed. All related algorithms are implemented in NearestNeighbors.jl, so refer to the official GitHub page. Speed Comparison Let&amp;rsquo;s compare with the technique optimized for calculating distance matrices using the pairwise() function. using Distances using StatsBase</description>
    </item>
    <item>
      <title>Neumann Factorization Theorem Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/2084/</link>
      <pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2084/</guid>
      <description>Theorem Let&amp;rsquo;s say a random sample $X_{1} , \cdots , X_{n}$ has the same probability mass/density function $f \left( x ; \theta \right)$ for a parameter $\theta \in \Theta$. Statistic $Y = u_{1} \left( X_{1} , \cdots , X_{n} \right)$ is a sufficient statistic for $\theta$ if there exist two non-negative functions $k_{1} , k_{2} \ge 0$ that satisfy the following. $$ f \left( x_{1} ; \theta \right) \cdots f</description>
    </item>
    <item>
      <title>Integration of Complex Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/2082/</link>
      <pubDate>Wed, 15 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2082/</guid>
      <description>Definition 1 $$ g(t) := p(t) + i q(t) \qquad , t \in [a,b] $$ Let&amp;rsquo;s assume for a real function $p, q : [a,b] \to \mathbb{R}$, a complex function $g : [a,b] \to \mathbb{C}$ is expressed as above. The definite integral from $[a,b]$ to $g$ is defined as follows. $$ \int_{a}^{b} g(t) dt = \int_{a}^{b} p(t) dt + i \int_{a}^{b} q(t) dt $$ For $t \in [a,b]$, the complex</description>
    </item>
    <item>
      <title>Zeros in Complex Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/2080/</link>
      <pubDate>Sat, 11 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2080/</guid>
      <description>Definition 1 $\alpha \in \mathbb{C}$ being a zero of order $n$ of the function $f : \mathbb{C} \to \mathbb{C}$ means that for some function $g$, where $\displaystyle \lim_{z \to \alpha} g(z) \ne 0$, it can be expressed as follows: $$ f(z) = (z-\alpha)^{n} g(z) $$ Theorem Zeros are isolated: For a zero $f$, we can take a radius such that no other zeros exist around it. For the zero $\alpha$</description>
    </item>
    <item>
      <title>Harmonic Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/2078/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2078/</guid>
      <description>Definition 1 If a function $\phi (x,y)$ has a continuous second derivative in the region $\mathscr{R}$ and is a solution to the Laplace&amp;rsquo;s equation, it is said to be harmonic. In other words, a harmonic function satisfies the following. $$ \Delta \phi = \nabla^{2} \phi = \phi_{xx} + \phi_{yy} = 0 $$ Especially, if a function $u(x,y), v(x,y)$ is harmonic and $u,v$ satisfies the Cauchy-Riemann equations, then $v(x,y)$ is referred</description>
    </item>
    <item>
      <title>How to Output a 2D Array to a CSV File in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2073/</link>
      <pubDate>Sat, 28 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2073/</guid>
      <description>Code using CSV, DataFrames A = rand(1:10, 10) B = zeros(10) AB = DataFrame(hcat(A,B), [&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;]) CSV.write(&amp;#34;AB.csv&amp;#34;, AB) The write function of the CSV package allows you to easily output a two-dimensional array. A, B are one-dimensional arrays, which are combined using the hcat function to transform into a dataframe. Execution Result julia&amp;gt; using CSV, DataFrames julia&amp;gt; A = rand(1:10, 10) 10-element Array{Int64,1}: 8 5 4 3 6 4 10</description>
    </item>
    <item>
      <title>Frenet-Serret Formulas</title>
      <link>https://freshrimpsushi.github.io/en/posts/2072/</link>
      <pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2072/</guid>
      <description>Formulas 1 If $\alpha$ is a unit speed curve with $\kappa (s) \ne 0$ then $$ \begin{align*} T^{\prime}(s) =&amp;amp; \kappa (s) N(s) \\ N^{\prime}(s) =&amp;amp; - \kappa (s) T(s) + \tau (s) B(s) \\ B^{\prime}(s) =&amp;amp; - \tau (s) N(s) \end{align*} $$ Description In matrix form, it can be expressed as follows. $$ \begin{bmatrix} T \\ N \\ B \end{bmatrix} ^{\prime} = \begin{bmatrix} 0 &amp;amp; \kappa &amp;amp; 0 \\ -</description>
    </item>
    <item>
      <title>Rigorous Definition of Dynamical Systems</title>
      <link>https://freshrimpsushi.github.io/en/posts/2071/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2071/</guid>
      <description>Definition 1 For a space $X$ and a moment $t \in T$, an operator $\varphi^{t}$ is called a Flow. If the set of flows $F := \left\{ \varphi^{t} \right\}_{t \in T}$ satisfies $\left( F , \circ \right)$ with respect to the function composition operation $\circ$, then the triple $\left( T, X, \varphi^{t} \right)$ is called a Dynamic System. $$ \begin{align*} \varphi^{0} =&amp;amp; \text{id} \\ \varphi^{t+s} =&amp;amp; \varphi^{t} \circ \varphi^{s} \end{align*}</description>
    </item>
    <item>
      <title>Frenet-Serret Formulas: Curvature, Tangent, Normal, Binormal, Torsion</title>
      <link>https://freshrimpsushi.github.io/en/posts/2070/</link>
      <pubDate>Sun, 22 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2070/</guid>
      <description>Definition 1 Let&amp;rsquo;s say $\alpha$ is a unit speed curve. The speed $\kappa (s) := \left| T^{\prime}(s) \right|$ of the tangent $T(s) = \alpha^{\prime} (s)$ is called the curvature $\alpha (s)$. The function obtained by dividing the velocity $T^{\prime}(s)$ of the tangent of $\alpha$ by the curvature $\kappa (s)$, namely, defined as $N$, is referred to as the Normal vector field. $$ N(s) := {{ T^{\prime}(s) } \over { \left|</description>
    </item>
    <item>
      <title>Tangent Lines and Tangent Vector Fields</title>
      <link>https://freshrimpsushi.github.io/en/posts/2066/</link>
      <pubDate>Sat, 14 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2066/</guid>
      <description>Definition Let there be a given regular curve $\alpha (t)$. The vector field $\displaystyle T(t) := {{ d \alpha / d t } \over { \left| d \alpha / d t \right| }}$ is called the Tangent Vector Field. The line $l$ defined as follows in $t = t_{0}$ to $\alpha$ is called the Tangent Line. $$ l := \left\{ \mathbf{w} \in \mathbb{R}^{3} : \mathbf{w} = \alpha \left( t_{0} \right)</description>
    </item>
    <item>
      <title>Writing Greek Characters and Subscripts in Julia Variable Names</title>
      <link>https://freshrimpsushi.github.io/en/posts/2065/</link>
      <pubDate>Thu, 12 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2065/</guid>
      <description>Overview In Julia, Unicode (UTF-8) is allowed for variable names. Therefore, you can use not only Greek letters but also superscripts, subscripts, and even Korean or emojis. There&amp;rsquo;s no particular need to use them, but odd codes like the following work fine. julia&amp;gt; α₁ = 2 2 julia&amp;gt; α₂ = 1 1 julia&amp;gt; println(α₁ \ast\ α₂) 2</description>
    </item>
    <item>
      <title>Definition of Logarithmic Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/2063/</link>
      <pubDate>Sun, 08 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2063/</guid>
      <description>Definition The inverse function of an exponential function is defined as the logarithmic function $\log : (0,\infty) \to \mathbb{R}$. If for all $x \in (0,\infty)$, $x = e^y$ then the logarithmic function is represented as: $$ \log x := y(x) $$</description>
    </item>
    <item>
      <title>Definition of a Curve</title>
      <link>https://freshrimpsushi.github.io/en/posts/2062/</link>
      <pubDate>Fri, 06 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2062/</guid>
      <description>Definitions 1 The mapping $\alpha : (a,b) \to \mathbb{R}^{3}$ is referred to as a Curve. A point $t = t_{0}$ at the curve where $\alpha^{\prime} = \dfrac{d \alpha}{d t} = \mathbf{0}$ is called a Singular Point. A curve $\alpha \in C^{k}$ for some $k \in \mathbb{N}$ where at all $t \in (a,b)$, $\displaystyle {{ d \alpha } \over { d t }} \ne \mathbf{0}$ is known as a Regular Curve.</description>
    </item>
    <item>
      <title>Sufficient Statistic</title>
      <link>https://freshrimpsushi.github.io/en/posts/2061/</link>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2061/</guid>
      <description>Definitions Mathematical Definition 1 Let the probability mass/density function of a random sample $X_{1} , \cdots , X_{n}$ for parameter $\theta \in \Theta$ be $f(x;\theta)$, and let the probability mass/density function for statistic $Y_{1} := u_{1} \left( X_{1} , \cdots , X_{n} \right)$ be $f_{Y_{1}} \left( y_{1}; \theta \right)$. For $H \left( x_{1} , \cdots , x_{n} \right)$, which does not depend on $\theta \in \Theta$, $$ {{ f \left(</description>
    </item>
    <item>
      <title>Exponential Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/2060/</link>
      <pubDate>Mon, 02 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2060/</guid>
      <description>Overview The Exponential Function is a generalization of exponentiation that appears universally across all branches of mathematics. Although in original exponentiations the base $a &amp;gt; 0$ does not necessarily have to be $a = e$, the existence of the base change formula means that essentially, it doesn’t matter which base is used. For convenience, when referring to an exponential function, its base is commonly</description>
    </item>
    <item>
      <title>Polynomial Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/2058/</link>
      <pubDate>Thu, 29 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2058/</guid>
      <description>Definition 1 A Polynomial of degree $n$ is defined for $n \in \mathbb{N}_{0}$ and $\left\{ a_{k} \right\}_{k=0}^{n} \subset \mathbb{C}$ as follows: $$ P(z) := a_{0} + a_{1} z + \cdots a_{n} z^{n} \qquad , a_{n} \ne 0 $$ Explanation A polynomial function is one of the most basic functions that can be considered in all of mathematics, and it has been proven by the Fundamental Theorem of Algebra that there</description>
    </item>
    <item>
      <title>Definition of Trigonometric Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/2056/</link>
      <pubDate>Sun, 25 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2056/</guid>
      <description>Overview Trigonometric functions are functions that associate the angles of a right triangle with their trigonometric ratios. Definition The trigonometric functions sine and cosine $\sin, \cos : \mathbb{R} \to \mathbb{R}$ are defined as follows. $$ \sin \theta := {{ y } \over { \sqrt{x^{2} + y^{2}} }} \\ \cos \theta := {{ x } \over { \sqrt{x^{2} + y^{2}} }} $$ Consequently, secant, cosecant, tangent, and cotangent are defined as</description>
    </item>
    <item>
      <title>Periodic Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/2050/</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2050/</guid>
      <description>Definition A function $f : \mathbb{R} \to \mathbb{R}$ is said to be a $T$-periodic function if it satisfies the following for some constant $T \ne 0$ and all $t \in \mathbb{R}$: ▶e</description>
    </item>
    <item>
      <title>Definition of Complex Numbers</title>
      <link>https://freshrimpsushi.github.io/en/posts/2046/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2046/</guid>
      <description>Definition 1 The solution $x = \sqrt{-1}$ of the quadratic equation $x^{2} +1 = 0$ is called an Imaginary Number. A number in the form of $z = x + iy$ for two real numbers $x,y \in \mathbb{R}$ is called a Complex Number, and is also denoted as $(x,y)$. Here, $\text{Re} (z) = x$ and $\text{Im} (z) = y$ are called the Real Part and Imaginary Part of $z$, respectively.</description>
    </item>
    <item>
      <title>General Definitions of Lines, Planes, and Spheres</title>
      <link>https://freshrimpsushi.github.io/en/posts/2042/</link>
      <pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2042/</guid>
      <description>Definition 1 Let&amp;rsquo;s assume that a vector space $X$ is given. The set of points satisfying the following equation $L \subset X$ or $\alpha (t)$ itself is defined as a Line that passes through point $\mathbf{x}_{0} \in X$ and is parallel to vector $\mathbf{v} \ne 0$. $$ \alpha (t) = \mathbf{x}_{0} + t \mathbf{v} \qquad , t \in \mathbb{R} $$ The set of points satisfying the following equation $P \subset</description>
    </item>
    <item>
      <title>How to Conveniently Print Variable Values in Julia, Interpolation</title>
      <link>https://freshrimpsushi.github.io/en/posts/2041/</link>
      <pubDate>Fri, 25 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2041/</guid>
      <description>Overview This section explains the interpolation convenience feature in Julia. Interpolation can be very handy as it allows for writing output statements in an easy and clean manner. Although it is not directly related to numerical analysis interpolation, the term intersects in meaning. For functionalities related to numerical analysis interpolation, refer to the usage of Interpolations.jl. Code The usage is quite straightforward. Simply write the variable inside the string with</description>
    </item>
    <item>
      <title>Definition of General Angles and Perpendicularity</title>
      <link>https://freshrimpsushi.github.io/en/posts/2038/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2038/</guid>
      <description>Definition 1 Let&amp;rsquo;s say $V$ is a vector space. For two vectors $\mathbb{u}, \mathbb{v} \in V$, $\theta$ is defined as the angle between two vectors if it satisfies the following. $$ \cos \theta = {{ \left&amp;lt; \mathbb{u}, \mathbb{v} \right&amp;gt; } \over { \left| \mathbb{u} \right| \left| \mathbb{v} \right| }} $$ If two vectors $\mathbb{u}, \mathbb{v}$ satisfy $\left&amp;lt; \mathbb{u}, \mathbb{v} \right&amp;gt; = 0$, then $\mathbb{u}$ is said to be orthogonal or</description>
    </item>
    <item>
      <title>Using Julia in Windows CMD and PowerShell</title>
      <link>https://freshrimpsushi.github.io/en/posts/2036/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2036/</guid>
      <description>Guide Step 0. Install julia 1.6 or higher From version 1.6, you can add it to the environment variables during the installation process. Just check the indicated option and install. If using an older version, either install version 1.6 or higher, or follow the instructions below. Step 1. Check the Julia installation path Check the installation path of Julia. If you haven&amp;rsquo;t altered anything, it should be stored in the</description>
    </item>
    <item>
      <title>Shannon Entropy: Entropy Defined by Random Variables</title>
      <link>https://freshrimpsushi.github.io/en/posts/2035/</link>
      <pubDate>Sun, 13 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2035/</guid>
      <description>Overview Shannon Entropy or Information Entropy is a measure of disorder defined by a probability variable, and can be viewed as a quantification of how uncertain it is in a probability distribution. Easy and Complex Definitions Discrete Entropy 1 When the probability mass function of a discrete random variable $X$ is $p(x)$, the entropy of $X$ is represented as follows. $$ H(X) := - \sum p(x) \log_{2} p(x) $$ Continuous</description>
    </item>
    <item>
      <title>Regularity Conditions in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/2029/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2029/</guid>
      <description>Overview In subjects that utilize mathematics, the term Regularity Conditions usually refers to conditions that allow for a wide range of applications and make theoretical developments more comfortable. In mathematical statistics, they are as follows. Assumptions 1 Consider a random variable $X$ with probability density function $f \left( x ; \theta \right)$ for a parameter $\theta \in \Theta$. The random sample $X_{1} , \cdots , X_{n}$ drawn iid from the</description>
    </item>
    <item>
      <title>Optimal Value: Maximum and Minimum</title>
      <link>https://freshrimpsushi.github.io/en/posts/2027/</link>
      <pubDate>Fri, 28 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2027/</guid>
      <description>Simple Definitions Maximum and Minimum collectively are called the Optimum. In the set $X$, the largest element is denoted as the maximum $\max X$, and the smallest element as the minimum $\min X$. For the function $f : X \to \mathbb{R}$, the largest function value is denoted as $\max_{X} f$, and the smallest function value as $\min_{X} f$. $\mathbb{R}$ denotes the entire set of real numbers. Maximum and Minimum are</description>
    </item>
    <item>
      <title>Maximum Likelihood Estimator</title>
      <link>https://freshrimpsushi.github.io/en/posts/2026/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2026/</guid>
      <description>Buildup Consider a random variable $X$ with a probability density function (pdf) $f \left( x ; \theta \right)$ for parameter $\theta \in \Theta$. A random sample $X_{1} , \cdots , X_{n}$ drawn identically and independently (iid) from the same distribution as $X$ has the same pdf $f(x ; \theta)$ and realization $\mathbf{x} := \left( x_{1} , \cdots , x_{n} \right)$. The function $L$ defined for this is called the Likelihood</description>
    </item>
    <item>
      <title>SIR Model: The Most Basic Diffusion Model</title>
      <link>https://freshrimpsushi.github.io/en/posts/2025/</link>
      <pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2025/</guid>
      <description>Overview The SIR model is one of the simplest and most widely varied compartmental models in epidemiology, offering a straightforward and intuitive explanation of the spread of diseases or information. Model 1 $$ \begin{align*} {{d S} \over {d t}} =&amp;amp; - {{ \beta } \over { N }} I S \\ {{d I} \over {d t}} =&amp;amp; {{ \beta } \over { N }} S I - \mu I \\</description>
    </item>
    <item>
      <title>Metaprogramming in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2024/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2024/</guid>
      <description>## Code [^1] [^1]: https://docs.julialang.org/en/v1/manual/metaprogramming/ Julia supports [metaprogramming](../1457) at the language level. Here is the result of reading and executing a string as code itself. julia&amp;gt; text = &amp;ldquo;f(x) = 2x + 1; f(2)&amp;rdquo; &amp;ldquo;f(x) = 2x + 1; f(2)&amp;rdquo; julia&amp;gt; code = Meta.parse(text) :($(Expr(:toplevel, :(f(x) = begin #= none:1 =# 2x + 1 end), :(f(2))))) julia&amp;gt; eval(code) 5 - `Meta.Parse()`: 이 함수를 통해 입력된</description>
    </item>
    <item>
      <title>How to Flatten an Array in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2022/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2022/</guid>
      <description>Code Use the vec() function. julia&amp;gt; A = rand(0:9, 3,4) 3×4 Array{Int64,2}: 6 8 7 3 2 9 3 2 5 0 6 7 julia&amp;gt; vec(A) 12-element Array{Int64,1}: 6 2 5 8 9 0 7 3 6 3 2 7 To the human eye, it appears the same as a 1-dimensional array, but it&amp;rsquo;s actually a 2-dimensional array by type, which can cause errors. This method can solve</description>
    </item>
    <item>
      <title>Optimizing Distance Matrix Calculations in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2020/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2020/</guid>
      <description>Conclusion Let&amp;rsquo;s calculate the distance between $n$ coordinates. If it&amp;rsquo;s not necessary to calculate the distance between all coordinates, divide them into groups and create a rectangular distance matrix. The rectangular distance matrix can be calculated quickly and easily with the pairwise() function. Speed Comparison Let&amp;rsquo;s imagine doing a moving agent-based simulation for the SIR model. The original time complexity is $O \left( n^{2} \right)$, but if you divide it</description>
    </item>
    <item>
      <title>Dynamics Compartment Model</title>
      <link>https://freshrimpsushi.github.io/en/posts/2019/</link>
      <pubDate>Wed, 12 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2019/</guid>
      <description>Overview 1 Compartmental models in epidemiology serve as models for epidemic outbreaks, incorporating infectious diseases into population dynamics and dividing the &amp;lsquo;population&amp;rsquo; into several compartments. Epidemiology is the study of epidemics, unrelated to the mechanics discussed at shrimp sushi restaurants. Description Ever since Kermack and McKendrick devised what&amp;rsquo;s known as the SIR model, there have been numerous modifications and developments. All models that originate from this idea are essentially considered</description>
    </item>
    <item>
      <title>How to Weight and Random Sample in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2018/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2018/</guid>
      <description>Overview The usage of the function sample() which serves a similar role to R&amp;rsquo;s sample() or Python package numpy&amp;rsquo;s random.choice(), and the Weights function in Julia. Code 1 using StatsBase items = 0:5 weights = 0:5 sample(items, Weights(weights)) # With replacement my_samps = sample(items, Weights(weights), 10) # Without replacement my_samps = sample(items, Weights(weights), 2, replace=false) Execution Result julia&amp;gt; using StatsBase julia&amp;gt; items = 0:5 0:5 julia&amp;gt; weights = 0:5 0:5</description>
    </item>
    <item>
      <title>Comparison of the Speed of the Equality Operator == for Characters and Integers in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2016/</link>
      <pubDate>Thu, 06 May 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2016/</guid>
      <description>Conclusion Comparing each element in an array using the Equal Operator == shows that Char is faster than integers. Speed Comparison julia&amp;gt; integer = rand(1:5, N); print(typeof(integer)) Array{Int64,1} julia&amp;gt; character = rand([&amp;#39;S&amp;#39;,&amp;#39;E&amp;#39;,&amp;#39;I&amp;#39;,&amp;#39;R&amp;#39;,&amp;#39;D&amp;#39;], N); print(typeof(character)) Array{Char,1} julia&amp;gt; @time integer .== 1; 0.009222 seconds (6 allocations: 1.196 MiB) julia&amp;gt; @time character .== &amp;#39;S&amp;#39;; 0.005266 seconds (7 allocations: 1.196 MiB) The above code identifies where 1 and S are located in an array</description>
    </item>
    <item>
      <title>Student&#39;s t-test Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/203/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/203/</guid>
      <description>Summary 1 If random variables $X_{1} , \cdots , X_{n}$ are iid and follow a normal distribution $N\left( \mu,\sigma^{2} \right)$, then (a): $$ \overline{X} \sim N\left( \mu , { {\sigma^2} \over {n} } \right) $$ (b): $$ \overline{X} \perp S^2 $$ (c): $$ (n-1) { {S^2} \over {\sigma^2} } \sim \chi^2 (n-1) $$ (d): $$ T = { {\overline{X} - \mu } \over {S / \sqrt{n}} } \sim t(n-1) $$</description>
    </item>
    <item>
      <title>RGB Color Cheat Sheet</title>
      <link>https://freshrimpsushi.github.io/en/posts/2013/</link>
      <pubDate>Wed, 28 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2013/</guid>
      <description>Overview A commonly used RGB color palette. Code</description>
    </item>
    <item>
      <title>Solving \General\Registry.toml: No such file or directory when Installing Julia Packages</title>
      <link>https://freshrimpsushi.github.io/en/posts/2069/</link>
      <pubDate>Sat, 20 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2069/</guid>
      <description>Error ERROR: SystemError: opening file &amp;quot;C:\\Users\\rmsms\\.julia\\registries\\General\\Registry.toml&amp;quot;: No such file or directory Cause It&amp;rsquo;s a really frustrating error, which, as the message indicates, occurs because the Registry.toml file does not exist at the specified path. Solution Delete the C:\Users\사용자이름\.julia\registries\</description>
    </item>
    <item>
      <title>How to Install the Latest Version of Julia on Windows</title>
      <link>https://freshrimpsushi.github.io/en/posts/2067/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2067/</guid>
      <description>Guide Step 1. Install Julia Download the installation file from the Julia download page and run it. Step 2. Install VS Code Download the installation file from the Visual Studio Code download page and run it. Step 3. Install Julia Extension Open Extensions by clicking on the fifth icon from the left or pressing Ctrl + Shift + X. Search for &amp;lsquo;julia&amp;rsquo; and Julia Language Support will appear at the</description>
    </item>
    <item>
      <title>Definite matrix</title>
      <link>https://freshrimpsushi.github.io/en/posts/336/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/336/</guid>
      <description>Definition1 Positive Definite Matrix A quadratic form $\mathbf{x}^{\ast} A \mathbf{x}$ is called a positive definite matrix or quadratic form if it satisfies $\mathbf{x}^{\ast} A \mathbf{x} &amp;gt; 0$ for all $\mathbf{x} \ne \mathbf{0}$. called a negative definite matrix or quadratic form if it satisfies $\mathbf{x}^{\ast} A \mathbf{x} &amp;lt; 0$ for all $\mathbf{x} \ne \mathbf{0}$. called indefinite if it sometimes satisfies $\mathbf{x}$ for the same quadratic form or matrix $A$. For real</description>
    </item>
    <item>
      <title>The eigenvalues of a Hermitian matrix are always real</title>
      <link>https://freshrimpsushi.github.io/en/posts/310/</link>
      <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/310/</guid>
      <description>Summary Let $A$ be a Hermitian matrix of size $n \times n$. Then, the eigenvalues of $A$ are all real. Explanation In general, there is no guarantee that the eigenvalues of a matrix are real, but for Hermitian matrices, this can be verified through proof. It may not be intuitively obvious, but the proof itself is relatively simple, and it is quite useful as a fact. It yields various good</description>
    </item>
    <item>
      <title>Multivariate Normal Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1954/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1954/</guid>
      <description>Definition The multivariate normal distribution $N_{p} \left( \mu , \Sigma \right)$ has a probability density function based on the mean vector $\mathbf{\mu} \in \mathbb{R}^{p}$ and the covariance matrix $\Sigma \in \mathbb{R}^{p \times p}$ as follows: $$ f (\textbf{x}) = \left( (2\pi)^{p} \det \Sigma \right)^{-1/2} \exp \left[ - {{ 1 } \over { 2 }} \left( \textbf{x} - \mathbf{\mu} \right)^{T} \Sigma^{-1} \left( \textbf{x} - \mathbf{\mu} \right) \right] \qquad , \textbf{x} \in</description>
    </item>
    <item>
      <title>Covariance Matrix</title>
      <link>https://freshrimpsushi.github.io/en/posts/1950/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1950/</guid>
      <description>Definition1 $p$-dimensional random vector $\mathbf{X} = \left( X_{1}, \cdots , X_{p} \right)$ is defined as follows for $\text{Cov} (\mathbf{X})$, which is called a Covariance Matrix. $$ \left( \text{Cov} \left( \mathbf{X} \right) \right)_{ij} := \text{Cov} \left( X_{i} , X_{j} \right) $$ $\text{Cov}$ is covariance. Explanation To put the definition in simpler words, it is as follows. $$ \text{Cov} \left( \mathbf{X} \right) := \begin{pmatrix} \text{Var} \left( X_{1} \right) &amp;amp; \text{Cov} \left( X_{1}</description>
    </item>
    <item>
      <title>Central Limit Theorem Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/43/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/43/</guid>
      <description>Theorem 1 If $\left\{ X_{k} \right\}_{k=1}^{n}$ are iid random variables following the probability distribution $\left( \mu, \sigma^2 \right) $, then when $n \to \infty$ $$ \sqrt{n} {{ \overline{X}_n - \mu } \over {\sigma}} \overset{D}{\to} N (0,1) $$ $\overset{D}{\to}$ means convergence in distribution. Explanation This theorem is widely acclaimed in statistics, along with the Law of Large Numbers. Despite being frequently discussed and applied, many encounter its proof only upon studying</description>
    </item>
    <item>
      <title>Analytic Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/1929/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1929/</guid>
      <description>Definition Given open sets $A \subset \mathbb{C}$ and $f: A \to \mathbb{C}$, let us assume $\alpha \in A$. If $\displaystyle \lim_{z \to \alpha } f(z) = f (\alpha)$, then $f$ is said to be continuous at $\alpha$, and if $f$ is continuous at every point in the complex domain $\mathscr{R}$, then $f$ is said to be continuous on $\mathscr{R}$. Especially, if $f$ is continuous throughout its domain, it is called</description>
    </item>
    <item>
      <title>Deriving Standard Normal Distribution as a Limiting Distribution of Student&#39;s t-Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/195/</link>
      <pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/195/</guid>
      <description>Theorem If $T_n \sim t(n)$ then $$ T_n \ \overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ is a normal distribution with mean $\mu$ and variance $\sigma^{2}$. $t(r)$ is a t-distribution with degrees of freedom $r$. $\overset{D}{\to}$ respectively imply distribution convergence. Originally, the Student t-distribution was created for statistical analysis when the sample size is small. As the sample size increases, it becomes similar to the standard normal distribution,</description>
    </item>
    <item>
      <title>How to Use Hexadecimal RGB Codes (HEX) in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1921/</link>
      <pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1921/</guid>
      <description>Code The package provided for handling colors in Julia is Colors.jl. By loading the visualization package Plots.jl, one can also use the functionality within Colors.jl. Color codes representing the RGB space, such as RGB, BGR, RGB24, RGBX, XRGB, are supported and are subtypes of AbstractRGB. RGBA is RGB with added transparency. julia&amp;gt; using Plots julia&amp;gt; subtypes(AbstractRGB) 5-element Vector{Any}: BGR RGB RGB24 RGBX XRGB julia&amp;gt; subtypes(AbstractRGBA) 2-element Vector{Any}: BGRA RGBA Strings</description>
    </item>
    <item>
      <title>Converting Between DataFrames and 2D Arrays in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1930/</link>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1930/</guid>
      <description>Code Matrix(df) or Array(df) functions can be used to convert a DataFrame into an array of the same size. To create a DataFrame from an array, use DataFrame(array, :auto). In the past, the convert function was used, but it&amp;rsquo;s not applicable anymore, so be careful. using DataFrames julia&amp;gt; A = rand(5,3) 5×3 Matrix{Float64}: 0.678876 0.10431 0.827079 0.621647 0.372007 0.29346 0.756844 0.171237 0.0732631 0.922519 0.0535938 0.121689 0.164058 0.0684278 0.68446</description>
    </item>
    <item>
      <title>Derivation of the Standard Normal Distribution as the Limiting Distribution of the Poisson Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/197/</link>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/197/</guid>
      <description>Theorem If $X_{n} \sim \text{Poi} \left( n \right)$ and $\displaystyle Y_{n} := {{ X_{n} - n } \over { \sqrt{n} }}$ are given $$ Y_{n} \overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ is a normal distribution with a mean of $\mu$ and a variance of $\sigma^{2}$. $\text{Poi} (\lambda)$ is a Poisson distribution with mean and variance of $\lambda$. Explanation Considering the approximation of the binomial distribution to the</description>
    </item>
    <item>
      <title>How to Read *.csv Files in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1923/</link>
      <pubDate>Sun, 24 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1923/</guid>
      <description>Guide Old Version In julia v1.5.0, *.csv files were read as follows: In fact, Julia is not yet a language notably convenient for data input. However, if one desires speed, there may come a time when Julia should be chosen over Python, R, or Matlab. For instance, if one wants to load a *.csv file located just under the E drive, it can be entered as follows. using CSV data</description>
    </item>
    <item>
      <title>Changing the Number of Threads for Parallel Computing in Julia on Windows</title>
      <link>https://freshrimpsushi.github.io/en/posts/1933/</link>
      <pubDate>Sat, 23 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1933/</guid>
      <description>Guide In Julia, parallel computing is commonly used, so it may be necessary to focus all of a computer&amp;rsquo;s resources on computation depending on the situation. Although there are various ways to change the number of threads, the most static and convenient method is to edit environmental variables. Step 1. Edit System Environmental Variables Press the Windows key or Windows+S to search for &amp;lsquo;Edit system environment variables&amp;rsquo;. When the System</description>
    </item>
    <item>
      <title>Logistic Growth Model: The Limits of Population Growth</title>
      <link>https://freshrimpsushi.github.io/en/posts/1915/</link>
      <pubDate>Sat, 23 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1915/</guid>
      <description>Model $$ \dot{N} = {{ r } \over { K }} N ( K - N) $$ Variables $N(t)$: Represents the population size of a group at time $t$. Parameters $r \in \mathbb{R}$ : Intrinsic Rate of Increase, growth occurs if it is greater than $0$, and decline occurs if it is less than $0$. It can also be defined by the difference $r:=b-d$ between the Birth Rate $b$ and</description>
    </item>
    <item>
      <title>Derivation of the Standard Normal Distribution as a Limiting Distribution of the Binomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/196/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/196/</guid>
      <description>Theorem De Moivre-Laplace Theorem If $X_i \sim B(1,p)$ and $Y_n = X_1 + X_2 + \cdots + X_n$, then $Y_n \sim B(n,p)$ and $$ { { Y_n - np } \over {\sqrt{ np(1-p) } } }\overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ is a normal distribution with mean $\mu$ and variance $\sigma^{2}$. $B(n,p)$ is a binomial distribution with $n$ trials and probability $p$. $\overset{D}{\to}$ denotes convergence in distribution.</description>
    </item>
    <item>
      <title>How to Determine the Location of Code Files Executed in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1935/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1935/</guid>
      <description>Guide If you are someone who uses Julia, it&amp;rsquo;s likely that you&amp;rsquo;re comfortable with using multiple operating systems or computers, including servers. If there is file input/output involved, having to adjust the path each time the development environment changes can be quite bothersome. This is where the @__DIR__ macro comes in handy. Suppose you have a Julia code file like the following. Typically, when executed from the terminal, pwd() and</description>
    </item>
    <item>
      <title>Changing the Number of Threads for Parallel Computing in Julia on Linux</title>
      <link>https://freshrimpsushi.github.io/en/posts/1937/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1937/</guid>
      <description>Guide In Julia, parallel computing is routinely used, so sometimes it&amp;rsquo;s necessary to focus all of a computer&amp;rsquo;s resources on the computation. There are several ways to change the number of threads, but the most static and convenient method is to edit the environment variables. Step 1. Edit System Environment Variables Press Ctrl + Alt + T to open the terminal and type gedit ~/.bashrc. A window for editing environment</description>
    </item>
    <item>
      <title>The Poisson Distribution as a Limiting Distribution of the Binomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/198/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/198/</guid>
      <description>Theorem Let&amp;rsquo;s say $X_{n} \sim B(n,p)$. If $\mu \approx np$ then $$ X_{n} \overset{D}{\to} \text{Poi} (\mu) $$ $B(n,p)$ is a binomial distribution with trials $n$ and probability $p$. $\text{Poi} (\lambda)$ is a Poisson distribution with mean and variance $\lambda$. $\overset{D}{\to}$ means distribution convergence. Description Note that the condition $\mu \approx np$ is necessary here. Since $ np \approx npq$, it implies $q = (1-p) \approx 1$, i.e., $p \approx 0$.</description>
    </item>
    <item>
      <title>How to Use Composite Functions in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1942/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1942/</guid>
      <description>Code julia&amp;gt; f(x) = 2x + 1 f (generic function with 1 method) julia&amp;gt; g(x) = x^2 g (generic function with 1 method) julia&amp;gt; (g ∘ f)(3) 49 Description In Julia, function composition is similar to the pipe operator in programming. The main advantage of this composition is that it makes it easier for mathematicians to express formulas as code. The example above is simply a translation of the following</description>
    </item>
    <item>
      <title>Convergence of Distributions in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1888/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1888/</guid>
      <description>Definition 1 Given a random variable $X$ and a sequence of random variables $\left\{ X_{n} \right\}$, if the following condition is satisfied when $n \to \infty$, we say that $X$ converges in distribution to $X_{n}$ and represent it as $X_{n} \overset{D}{\to} X$. $$ \lim_{n \to \infty} F_{X_{n}} (x) = F_{X} (x) \qquad, \forall x \in C_{F_{X}} $$ $F_{X}$ is the cumulative distribution function of the random variable $X$. $C_{F_{X}}$ represents</description>
    </item>
    <item>
      <title>Definition of Vectors</title>
      <link>https://freshrimpsushi.github.io/en/posts/1947/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1947/</guid>
      <description>Definition A sequence of numbers is called a vector. Description In the general curriculum, a vector is learned as a &amp;lsquo;geometric object with magnitude and direction&amp;rsquo;. Since it&amp;rsquo;s the concept you first come across in physics, you inevitably become familiar with vectors of $3$ dimensions or less. $$ (3,4) = \begin{bmatrix} 3 \\ 4 \end{bmatrix} $$ $$ (x,y,z) = \begin{bmatrix} x \\ y \\ z \end{bmatrix} $$ However, vectors can</description>
    </item>
    <item>
      <title>Malthus Growth Model: Ideal Population Growth</title>
      <link>https://freshrimpsushi.github.io/en/posts/1871/</link>
      <pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1871/</guid>
      <description>Model $$ \dot{N} = rN $$ Variables $N(t)$: Represents the population size of a group at time $t$. Parameters $r \in \mathbb{R}$ : The Intrinsic Rate of Increase, if greater than $0$, the population grows, if less than $0$, it declines. It can also be defined by the difference $r:=b-d$ between Birth Rate $b$ and Death Rate $d$. Description Population Dynamics is the first pathway through which dynamics leads to</description>
    </item>
    <item>
      <title>Making GIFs in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1863/</link>
      <pubDate>Sun, 27 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1863/</guid>
      <description>Code Although the original Sakura Sushi restaurant tends to add much more detailed explanations, to emphasize how easy it is to create animated GIFs in Julia, we will keep this explanation as brief as possible. Even setting aside simulating a random walk, creating an animated GIF like the one above can be very difficult and demanding, depending on the language. However, Julia makes this incredibly easy with the @animate macro</description>
    </item>
    <item>
      <title>Key Bases and Base Pairs in Bioinformatics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1832/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1832/</guid>
      <description>Definition The following five bases are referred to as the Canonical Bases: Purine bases: Adenine $A$, Guanine $G$ Pyrimidine bases: Cytosine $C$, Thymine $T$, Uracil $U$ Description Thymine is only used in DNA, while Uracil is used in RNA. Therefore, by checking whether $T$ or $U$ is used in the data, one can tell whether it is a DNA or RNA base sequence. A Base Pair is formed by two</description>
    </item>
    <item>
      <title>Bioinformatics: DNA Sequencing</title>
      <link>https://freshrimpsushi.github.io/en/posts/1828/</link>
      <pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1828/</guid>
      <description>Build-up A polymer is a large molecule composed of repeating monomeric units linked by chemical synthesis. Phosphoric Acid is a type of inorganic oxyacid, with the chemical formula $H_{3}PO_{4}$. A monosaccharide with five carbon atoms is called Pentose. The molecule that functions as the basic unit of genetic information is known as a Nitrogenous base or simply Base. A nucleotide is a molecule that consists of phosphate-pentose-base and becomes the</description>
    </item>
    <item>
      <title>Biomedical Informatics: DNA, RNA, Chromosomes</title>
      <link>https://freshrimpsushi.github.io/en/posts/1827/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1827/</guid>
      <description>Buildup Polymers are high molecular compounds formed by the repeating connection of monomers through chemical synthesis. Phosphoric Acid is a type of inorganic oxyacid, with the chemical formula $H_{3}PO_{4}$. Monosaccharides with five carbon atoms are called Pentoses. Molecules that function as the basic unit of genetic information are called Nitrogenous bases, or simply Bases. A molecule composed of phosphate, pentose, and a base, serving as the building block of nucleic</description>
    </item>
    <item>
      <title>How to Compute Distance Matrices in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1799/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1799/</guid>
      <description>Overview The Distance Matrix is commonly used in simulations based on Particle Dynamics and Moving Agents, but it is often difficult to find a ready-made function for this purpose, and coding it from scratch can be daunting. In Julia, you can easily calculate a distance matrix using the pairwise() function and the Euclidean() function from the Distances package1. The dims option allows you to specify the direction of rows and</description>
    </item>
    <item>
      <title>How to Create an Empty Array in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1797/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1797/</guid>
      <description>Code Size Specification julia&amp;gt; empty = Array{Float64, 2}(undef, 3, 4) 3×4 Array{Float64,2}: 3.39519e-313 3.18299e-313 4.66839e-313 1.061e-313 4.03179e-313 5.51719e-313 1.6976e-313 4.24399e-314 2.97079e-313 4.66839e-313 7.00259e-313 5.0e-324 Executing the code above results in an empty array being created. Occasionally, it may seem like a strange value such as 1.76297e-315 is entered, but this is a value very close to 0, so it&amp;rsquo;s not a major issue for initialization. Array{X, Y}(undef, ...)</description>
    </item>
    <item>
      <title>Probability Convergence in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1789/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1789/</guid>
      <description>Definition 1 A random variable $X$ and a sequence of random variables $\left\{ X_{n} \right\}$ are said to converge in probability to $X$ as $n \to \infty$ if they satisfy the following, and it is denoted by $X_{n} \overset{P}{\to} X$. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left| X_{n} - X \right| &amp;lt; \varepsilon \right] = 1 $$ Explanation The condition for convergence in probability is</description>
    </item>
    <item>
      <title>Proof of the Continuity Mapping Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/1787/</link>
      <pubDate>Wed, 11 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1787/</guid>
      <description>Theorem 1 The following is a measure-theoretic description of the continuous mapping theorem. For metric spaces $\left( S , d \right)$ and $\left( S&#39; , d&amp;rsquo; \right)$, let us say $g : S \to S&#39;$ is continuous from $C_{g} \subset S$. For a random element $X$ in $S$, concerning a sequence of random elements converging to $X$ in $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$, the following holds if $P \left( X</description>
    </item>
    <item>
      <title>What is a Logistic Function?</title>
      <link>https://freshrimpsushi.github.io/en/posts/1775/</link>
      <pubDate>Sat, 07 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1775/</guid>
      <description>Definition [^1] The logistic function is derived as $y &#39; = y(1-y)$, which is a solution to the differential equation. $$ y(t) = {{ 1 } \over { 1 + e^{-t} }} $$ Explanation In a more general form, it can also be expressed as $\displaystyle f(x) := {{ L } \over { 1 + e^{-k(x-x_{0})} }}$. The logistic function, which is a sigmoid function, is widely mentioned in various</description>
    </item>
    <item>
      <title>Proof of Poincaré bendixson Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/1788/</link>
      <pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1788/</guid>
      <description>Theorem $2$ Consider a manifold $\mathcal{P}$ and a function $f,g \in C^{r} \left( \mathcal{P} \right)$ such that the following vector field is given as a differential equation: $$ \dot{x} = f(x,y) \\ \dot{y} = g(x,y) $$ If $\mathcal{M}$ represents an invariant set with a finite number of fixed points, then the omega limit set $\omega (p)$ of $p \in \mathcal{M}$ satisfies one of the following three conditions: (1): $\omega (p)$</description>
    </item>
    <item>
      <title>Unbiased Estimator</title>
      <link>https://freshrimpsushi.github.io/en/posts/1745/</link>
      <pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1745/</guid>
      <description>Definition 1 If the estimator $T$ of $\theta$ satisfies the following, then $T$ is called the unbiased estimator of $\theta$. $$ E T = \theta $$ Explanation Especially, among the unbiased estimators for $\theta$, the one with the smallest variance is called the minimum variance unbiased estimator. Unbiasedness refers to the property of not having any bias. For example, when we assume $X_{i} \sim \left( \mu , \sigma^{2} \right)$, if</description>
    </item>
    <item>
      <title>Invariant Sets in Dynamics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1079/</link>
      <pubDate>Sun, 18 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1079/</guid>
      <description>Definition1 Consider a space $X$ and a function $f,g : X \to X$, the vector field, and map are expressed as follows. $$ \dot{x} = f(x) \\ x \mapsto g(x) $$ Let $S \subset X$. (V): $\forall x_{0} \in S$ is called an invariant set under the vector field $\dot{x}=f(x)$ if for all $t \in \mathbb{R}$ it satisfies: $$ x(t,x_{0}) \in S $$ (M): $\forall x_{0} \in S$ is called</description>
    </item>
    <item>
      <title>Classification of Fixed Points in Autonomous Systems</title>
      <link>https://freshrimpsushi.github.io/en/posts/1733/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1733/</guid>
      <description>Definition Given a space $X$ and a function $f \in C^{1}(X,X)$, consider the following vector field given as a differential equation: $$ \dot{x} = f(x) $$ Let $\overline{x}$ be a fixed point of this autonomous system and the eigenvalues of $D f \left( \overline{x} \right)$ be described as $\lambda_{1} , \cdots , \lambda_{m}$. Hyperbolic: Hyperbolic Fixed Points1 Hyperbolic: If the real parts of all eigenvalues of $D f \left( \overline{x}</description>
    </item>
    <item>
      <title>Easy Definition of Confidence Intervals</title>
      <link>https://freshrimpsushi.github.io/en/posts/1732/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1732/</guid>
      <description>Definition 1 Let the probability density function $f (x; \theta)$ of the random variable $X$ and the samples $X_{1} , \cdots , X_{n}$ with a Confidence Coefficient $\alpha \in (0,1)$ be given. $$ L := L \left( X_{1} , \cdots , X_{n} \right) \\ U := U \left( X_{1} , \cdots , X_{n} \right) $$ It is said that the statistic $L &amp;lt; U$ is defined as above, then the</description>
    </item>
    <item>
      <title>Statistical Measures and Estimators in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1730/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1730/</guid>
      <description>Definition 12 A function $T$ of a sample $X_{1} , \cdots , X_{n}$ from a random variable $X$ is called a Statistic. $$ T := T \left( X_{1} , \cdots , X_{n} \right) $$ When the distribution function of $X$ is expressed as $f(x; \theta)$ or $p(x; \theta)$, if $T$ serves to capture $\theta$, then $T$ is referred to as an Estimator of $\theta$. The probability distribution of a statistic</description>
    </item>
    <item>
      <title>Random Sampling in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1715/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1715/</guid>
      <description>Definitions 1 The actual outcome of a random variable $X$ is called its realization and is usually represented by the lowercase letter $x$. A set of random variables from the same probability distribution as $X$, with a sample size of $n$, is called a sample, represented as follows: $$ X_{1} , X_{2} , \cdots , X_{n} $$ If the random variable $X_{1} , \cdots , X_{n}$ is iid, then a</description>
    </item>
    <item>
      <title>Cauchy Distribution: A Distribution Without a Mean</title>
      <link>https://freshrimpsushi.github.io/en/posts/147/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/147/</guid>
      <description>Definition The continuous probability distribution with the following probability density function is called a Cauchy distribution. $C$ $$ f(x) = {1 \over \pi} {1 \over {x^2 + 1}} \qquad , x \in \mathbb{R} $$ Explanation It may seem like all probability distributions would have a mean and variance, but in reality, that&amp;rsquo;s not always the case. A prime example of this is the Cauchy distribution, which at a glance resembles</description>
    </item>
    <item>
      <title>t-Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1667/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1667/</guid>
      <description>Definition 1 A continuous probability distribution $t \left( \nu \right)$, known as the t-distribution, is defined for degrees of freedom $\nu &amp;gt; 0$ as having the following probability density function: $$ f(x) = {{ \Gamma \left( {{ \nu + 1 } \over { 2 }} \right) } \over { \sqrt{\nu \pi} \Gamma \left( {{ \nu } \over { 2 }} \right) }} \left( 1 + {{ x^{2} } \over {</description>
    </item>
    <item>
      <title>Derivation of the Student&#39;s t-Distribution from Independent Normal Distributions and the Chi-Squared Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/204/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/204/</guid>
      <description>Theorem Two independent random variables $W,V$ where $W \sim N(0,1)$ and $V \sim \chi^{2} (r)$, then $$ T = { {W} \over {\sqrt{V/r} } } \sim t(r) $$ $N \left( \mu , \sigma^{2} \right)$ is a normal distribution with mean $\mu$ and variance $\sigma^{2}$. $\chi^{2} \left( r \right)$ is a chi-squared distribution with degrees of freedom $r$. $t(r)$ is a t-distribution with degrees of freedom $r$. Description If this theorem</description>
    </item>
    <item>
      <title>The Square of a Standard Normal Distribution Follows a Chi-Square Distribution with One Degree of Freedom</title>
      <link>https://freshrimpsushi.github.io/en/posts/148/</link>
      <pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/148/</guid>
      <description>Summary If $X \sim N(\mu,\sigma ^2)$ then $$ V=\left( { X - \mu \over \sigma} \right) ^2 \sim \chi ^2 (1) $$ $N \left( \mu , \sigma^{2} \right)$ is a normal distribution with mean $\mu$ and variance $\sigma^{2}$. $\chi^{2} \left( 1 \right)$ is a chi-squared distribution with degrees of freedom $1$. Description In general, Student&amp;rsquo;s theorem is widely used to generalize this. Anyone studying statistics must always know as a</description>
    </item>
    <item>
      <title>Normal Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1645/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1645/</guid>
      <description>Definition A continuous probability distribution $N \left( \mu,\sigma^{2} \right)$ with a probability density function as follows, given mean $\mu \in \mathbb{R}$ and variance $\sigma^{2} &amp;gt; 0$, is called Normal Distribution. $$ f(x) = {{ 1 } \over { \sqrt{2 \pi} \sigma }} \exp \left[ - {{ 1 } \over { 2 }} \left( {{ x - \mu } \over { \sigma }} \right)^{2} \right] \qquad, x \in \mathbb{R} $$ In</description>
    </item>
    <item>
      <title>Derivation of F-distribution from Two Independent Chi-squared Distributions</title>
      <link>https://freshrimpsushi.github.io/en/posts/1643/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1643/</guid>
      <description>Summary If two random variables $U,V$ are independent and it is assumed that $U \sim \chi^{2} ( r_{1})$, $V \sim \chi^{2} ( r_{2})$ then $$ {{ U / r_{1} } \over { V / r_{2} }} \sim F \left( r_{1} , r_{2} \right) $$ Explanation If two data follow the Chi-squared distribution and are independent, it might be possible to explain their ratio using distribution theory. In statistics in general,</description>
    </item>
    <item>
      <title>Operators as Fourier Transforms</title>
      <link>https://freshrimpsushi.github.io/en/posts/1640/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1640/</guid>
      <description>Definition1 The Fourier Transform of the function $f$ $$ \widehat{f} (\gamma ) := \int_{\mathbb{R}} f(x) e^{-2 \pi i x \gamma} dx, \quad \gamma \in \mathbb{R} $$ can also be represented as the following operator $\mathcal{F}$. $$ (\mathcal{F} f) (\gamma ) := \widehat{f} ( \gamma ) $$ Description Fourier Transform is widely used throughout analysis and the two expressions $\widehat{f}$ and $\mathcal{F} f$ essentially do not differ, but there is a</description>
    </item>
    <item>
      <title>Continuous and Uniformly Continuous in Metric Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/384/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/384/</guid>
      <description>Definitions Let&amp;rsquo;s define a function $f : E \to Y$ for two metric spaces $\left( X , d_{X} \right)$, $\left( Y , d_{Y} \right)$ and a subset $E\subset X$. Let&amp;rsquo;s say $p \in E$. For any $\varepsilon &amp;gt; 0$, if there exists $\delta&amp;gt;0$ such that $$ x \in E \quad \text{and} \quad d_{X}(p, x ) &amp;lt; \delta \implies d_{Y}(f(p) , f(x) ) &amp;lt; \varepsilon $$ is satisfied, then $f$ is</description>
    </item>
    <item>
      <title>Riemann Zeta Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/1626/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1626/</guid>
      <description>Definition The function defined as $\zeta : \mathbb{C} \setminus \left\{ 1 \right\} \to \mathbb{C}$ is called the Riemann Zeta Function. $$ \zeta (s) := \sum_{n \in \mathbb{N}} n^{-s} = \prod_{p : \text{prime}} \left( 1- {p^{-s}} \right)^{-1} $$ Related Theorems [0] Ramanujan Sum: If $\displaystyle \sum_{n \in \mathbb{N}} x^{n-1} = {{ 1 } \over { 1-x }}$ is accepted to hold even at $|x| = 1$, $$ \zeta (0) = 1</description>
    </item>
    <item>
      <title>Translation in L2 Spaces: Translations, Modulations, Dilations</title>
      <link>https://freshrimpsushi.github.io/en/posts/1616/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1616/</guid>
      <description>Definition1 Translation is defined as $T_{a} : L^{2} \to L^{2}$ for $a \in \mathbb{R}$ as follows. $$ \left( T_{a} f \right) (x) := f(x-a) $$ Modulation is defined as $E_{b} : L^{2} \to L^{2}$ for $b \in \mathbb{R}$ as follows. $$ \left( E_{b} f \right) (x) := e^{2 \pi i b x} f(x) $$ Dilation is defined as $D_{c} : L^{2} \to L^{2}$ for $c &amp;gt; 0$ as follows. $$</description>
    </item>
    <item>
      <title>F-distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1606/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1606/</guid>
      <description>Definition 1 The continuous probability distribution $F \left( r_{1} , r_{2} \right)$, which has the following probability density function for degrees of freedom $r_{1}, r_{2} &amp;gt; 0$, is called the F-distribution. $$ f(x) = {{ 1 } \over { B \left( r_{1}/2 , r_{2} / 2 \right) }} \left( {{ r_{1} } \over { r_{2} }} \right)^{r_{1} / 2} x^{r_{1} / 2 - 1} \left( 1 + {{ r_{1} }</description>
    </item>
    <item>
      <title>Chi-Squared Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1600/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1600/</guid>
      <description>Definition 1 The chi-square distribution refers to a continuous probability distribution $\chi^{2} (r)$ with the following probability density function, defined over the degrees of freedom $r &amp;gt; 0$. $$ f(x) = {{ 1 } \over { \Gamma (r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} \qquad , x \in (0, \infty) $$ $\Gamma$ represents the gamma function. Basic Properties Moment Generating Function [1]: $$m(t) = (1-2t)^{-r/2} \qquad , t &amp;lt; {{ 1 }</description>
    </item>
    <item>
      <title>The Support of Functions and the Class of Continuous Function Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/1594/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1594/</guid>
      <description>Definitions Let&amp;rsquo;s consider a function $f : \mathbb{R} \to \mathbb{C}$ in the function space $\mathbb{C}^{\mathbb{R}}$. The support of a function $f$ is defined as the closed set obtained by taking the closure of the set of points where the function value is not $0$. $$ \text{supp} f = \overline{\left\{ x \in \mathbb{R} : f(x) \ne 0 \right\}} $$ If $\text{supp} f$ is bounded, then $f$ is said to have a</description>
    </item>
    <item>
      <title>Hilbert Space&#39;s Orthonormal Basis and Unitary Operator</title>
      <link>https://freshrimpsushi.github.io/en/posts/1593/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1593/</guid>
      <description>Definition If a Schauder basis $\left\{ \mathbf{e}_{k} \right\}_{k \in \mathbb{N}}$ of a Hilbert space $H$ is a normal orthogonal system, then $\left\{ \mathbf{e}_{k} \right\}_{k \in \mathbb{N}}$ is called the Orthonormal Basis of $H$. Theorem1 Equivalent Conditions for Orthonormal Basis [1]: Assuming $H$ is a Hilbert space. For the normal orthogonal system $\left\{ \mathbf{e}_{k} \right\}_{k \in \mathbb{N}} \subset H$ of $H$, the following are all equivalent. (i): $\left\{ \mathbf{e}_{k} \right\}_{k \in</description>
    </item>
    <item>
      <title>Infinite-Dimensional Vector Spaces and Schauder Bases</title>
      <link>https://freshrimpsushi.github.io/en/posts/1583/</link>
      <pubDate>Mon, 06 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1583/</guid>
      <description>Definition1 Let&amp;rsquo;s call $(X, \left\| \cdot \right\|)$ a normed space. If there exists a unique sequence of scalars $\left\{ a_{k} \right\}_{k \in \mathbb{N}}$ that satisfies the following for every element $\mathbf{x}\in X$ in $X$, then $\left\{ \mathbf{e}_{k} \right\}_{k \in \mathbb{N}} \subset X$ is called the Schauder basis of $X$. $$ \mathbf{x}= \sum_{k \in \mathbb{N}} a_{k} \mathbf{e}_{k} $$ Description The basis of a vector space is called the Schauder basis, especially</description>
    </item>
    <item>
      <title>Planar Graphs and Kuratowski&#39;s Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/1565/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1565/</guid>
      <description>Definition Planar Graph A planar graph is a graph that can be drawn on a plane without any edges crossing each other. Explanation When a planar graph is drawn, the regions that are demarcated on the plane are called faces. The following planar graph $K_{4}$ has four faces $f_{1}, f_{2}, f_{3}, f_{4}$, and among them, the one that is not bounded $f_{4}$ is called an infinite face. Planar Graphs, as</description>
    </item>
    <item>
      <title>Hilbert Space Adjoint Operators</title>
      <link>https://freshrimpsushi.github.io/en/posts/1562/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1562/</guid>
      <description>Buildup1 Let us assume that we are given bounded linear operators $T : K \to H$ in Hilbert spaces $\left( H, \left\langle \cdot , \cdot \right\rangle_{H} \right)$ and $\left( K, \left\langle \cdot , \cdot \right\rangle_{K} \right)$. Then, for any fixed element $\mathbf{w} \in H$, the following defined $\Phi : K \to \mathbb{C}$ becomes a linear functional $\Phi \in K^{ \ast }$. $$ \Phi \mathbf{v} := \left\langle T \mathbf{v} , \mathbf{w}</description>
    </item>
    <item>
      <title>In Analytic Number Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/1547/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1547/</guid>
      <description>Definition 1 The arithmetic function defined as follows $u$ is called the unit function. $$ u(n) := 1 $$ Basic Properties [1] Unit series: Equals the number of divisors $\sigma_{0}$. In other words, $$ \sum_{d \mid n} u(d) = \sigma_{0} (n) $$ [2] Completely multiplicative: For all $m,n \in \mathbb{N}$, $u(mn) = u(m) u(n)$ Explanation $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6</description>
    </item>
    <item>
      <title>Beta Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1540/</link>
      <pubDate>Sat, 02 May 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1540/</guid>
      <description>Definition 1 For $\alpha , \beta &amp;gt; 0$, the continuous probability distribution $\text{Beta}(\alpha,\beta)$, called the beta Distribution, has the following probability density function: $$ f(x) = {{ 1 } \over { B(\alpha,\beta) }} x^{\alpha - 1} (1-x)^{\beta - 1} \qquad , x \in [0,1] $$ $B$ represents the beta function. Basic Properties Moment Generating Function [1]: $$m(t) = 1 + \sum_{k=1}^{\infty} \left( \prod_{r=0}^{k-1} {{ \alpha + r } \over {</description>
    </item>
    <item>
      <title>The Moebius Function in Analytic Number Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/1531/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1531/</guid>
      <description>Definition 1 For a prime number $p_{1} , \cdots , p_{k}$, let&amp;rsquo;s express a natural number $n$ as follows. The arithmetic function $\mu$ defined as such is called the Möbius function. $$ \mu (n) := \begin{cases} 1 &amp;amp;, n=1 \\ (-1)^{k} &amp;amp;, a_{1} = \cdots = a_{k} = 1 \\ 0 &amp;amp; , \text{otherwise} \end{cases} $$ Basic Properties [1] Möbius</description>
    </item>
    <item>
      <title>Distance, Neighborhood, Diameter, Perimeter in a Graph</title>
      <link>https://freshrimpsushi.github.io/en/posts/1530/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1530/</guid>
      <description>Definition In the graph $G$, the set of paths whose origin is $v \in V(G)$ and destination is $w \in V(G)$ is represented as $P(v,w)$, and let&amp;rsquo;s denote the set of cycles that include $v \in V(G)$ as $C(v)$. Also, let&amp;rsquo;s present the length of a walk $x$ as $l(x)$. The distance $d$ between two vertices $v,w \in V(G)$ is defined as the smallest value among the lengths of paths</description>
    </item>
    <item>
      <title>Walks, Trails, Paths, and Cycles in Graph Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/1528/</link>
      <pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1528/</guid>
      <description>Definition 1 Let there be a given graph $G$. A finite sequence of edges is called a walk and is denoted as follows: $$ v_{0} v_{1} , v_{1} v_{2} , \cdots , v_{m-1} v_{m} \\ v_{0} \rightarrow v_{1} \rightarrow v_{2} \rightarrow \cdots \rightarrow v_{m-1} \rightarrow v_{m} $$ Here, $v_{0}$ is called the initial vertex, $v_{m}$ is called the final vertex, and $m$ is called the length. If all edges in</description>
    </item>
    <item>
      <title>Divisor Function in Analytic Number Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/1527/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1527/</guid>
      <description>Definition 1 For $\alpha \in \mathbb{C}$, the following $\sigma_{\alpha} : \mathbb{N} \to \mathbb{C}$ is defined as a divisor function. $$ \sigma_{\alpha} (n) := \sum_{d \mid n} d^{\alpha} $$ Basic Properties [1] Multiplicativity: For all $m, n \in \mathbb{N}$ that satisfy $\gcd (m,n) = 1$, $\sigma_{\alpha} (mn) = \sigma_{\alpha} (m) \sigma_{\alpha} (n)$ [2]: For a prime $p$ and natural number $a$, $$ \sigma_{\alpha} \left( p^{a} \right) = \begin{cases} a +1 &amp;amp;</description>
    </item>
    <item>
      <title>The Relationship Between the Gamma Distribution and the Chi-Squared Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/135/</link>
      <pubDate>Tue, 07 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/135/</guid>
      <description>Theorem $$ \Gamma \left( { r \over 2 } , 2 \right) \iff \chi ^2 (r) $$ Description The gamma distribution and the chi-square distribution have the following properties. Proof Strategy: It is shown that the moment-generating functions of the two distributions can be represented in the same form. The moment-generating function of the chi-square distribution $\chi ^2 (r)$ is $\displaystyle m_{1}(t) = (1- 2t)^{- {r \over 2} }$, and</description>
    </item>
    <item>
      <title>Regular Graph</title>
      <link>https://freshrimpsushi.github.io/en/posts/1522/</link>
      <pubDate>Mon, 06 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1522/</guid>
      <description>Definition 1 A graph is called a Regular Graph if all vertices have the same degree. Specifically, if all vertices have a degree of $r$, it is called a $r$-Regular Graph. In other words, a graph $G$ that satisfies the following is referred to as a $r$-Regular Graph. $$ \deg (v) = r \qquad , \forall v \in V(G) $$ A $2$-Regular connected graph is called a Cycle. Examples Regular</description>
    </item>
    <item>
      <title>Relationship between Gamma Distribution and Exponential Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/133/</link>
      <pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/133/</guid>
      <description>Theorem $$ \Gamma \left(1, { 1 \over \lambda } \right) \iff \text{exp} (\lambda) $$ Description If we think about the intuitive definition of the exponential distribution, it&amp;rsquo;s about the interest in the amount of time it takes for a certain event to occur. If we were to relate this to a discrete probability distribution, the geometric distribution would correspond to this. In this sense, the generalization of the geometric distribution</description>
    </item>
    <item>
      <title>Arithmetic Functions&#39; Multiplicative Properties</title>
      <link>https://freshrimpsushi.github.io/en/posts/1521/</link>
      <pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1521/</guid>
      <description>Definition 1 For $\forall n \in \mathbb{N}$, if an arithmetic function $f$ that is not $f(n) = 0$ satisfies the following, it is called a multiplicative function. $$ f(mn) = f(m) f(n) \qquad,\gcd(m,n)=1 $$ If a multiplicative function satisfies the following condition, it is called a completely multiplicative function. $$ f(mn) = f(m) f(n) \qquad,m,n \in \mathbb{N} $$ Basic Properties [1]: If $f$ is multiplicative, then $f(1) = 1$. [2]:</description>
    </item>
    <item>
      <title>Null Graphs and Complete Graphs</title>
      <link>https://freshrimpsushi.github.io/en/posts/1520/</link>
      <pubDate>Thu, 02 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1520/</guid>
      <description>Definition 1 Given a simple graph $G$. If $E(G) = \emptyset$, then $G$ is called a null graph. If $E \left( \overline{G} \right) = \emptyset$, then $G$ is called a complete graph. Description A null graph is literally an empty graph. The reason why we use the term Null instead of Empty is that even if $G \ne \emptyset$, it has no meaning as a graph. For example, if there</description>
    </item>
    <item>
      <title>Gamma Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1517/</link>
      <pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1517/</guid>
      <description>Definition 1 For $k, \theta &amp;gt; 0$, it is called the Gamma Distribution which has the following probability density function $\Gamma ( k , \theta )$. $$ f(x) = {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x^{k - 1} e^{ - x / \theta} \qquad , x &amp;gt; 0 $$ $\Gamma$ represents the Gamma function. The probability density function of the Gamma distribution can also be</description>
    </item>
    <item>
      <title>Subgraph</title>
      <link>https://freshrimpsushi.github.io/en/posts/1513/</link>
      <pubDate>Wed, 25 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1513/</guid>
      <description>Definition 1 For a given graph $G$, graph $H$ is said to be a subgraph of $G$ if it satisfies $V(H) \subset V(G)$ and $ E(H) \subset E(G)$. Explanation It is important not to denote $H$ being a subgraph of $G$ as $H \subset G$. The concept of a subgraph serves not so much as a focus of interest in graph theory itself but rather as a natural and common</description>
    </item>
    <item>
      <title>Graphical Set Notation</title>
      <link>https://freshrimpsushi.github.io/en/posts/1512/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1512/</guid>
      <description>Definition 1 Let&amp;rsquo;s consider two graphs $G_{1}$ and $G_{2}$ and let $V(G_{1}) \cap V(G_{2}) = \emptyset$. The union $G = G_{1} \cup G_{2}$ of two graphs is a graph that has a vertex set $V(G_{1}) \cup V(G_{2})$ and an edge set $E (G_{1}) \cup E ( G_{2} )$. If graph $H$ cannot be represented as the union of other graphs, then $H$ is said to be connected; otherwise, it is</description>
    </item>
    <item>
      <title>The Relationship between Exponential Distribution and Poisson Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/296/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/296/</guid>
      <description>Summary When the time it takes for an event to occur is given by $X_{k}$, and if $X_{k} \sim \exp (\lambda)$, then the number of occurrences of an event per unit time is given by $N$, and $\displaystyle N \sim \text{Poi} (\lambda)$</description>
    </item>
    <item>
      <title>Exponential Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1510/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1510/</guid>
      <description>Definition 1 The continuous probability distribution $\exp ( \lambda)$ with the following probability density function, for $\lambda &amp;gt; 0$, is called an Exponential Distribution. $$ f(x) = \lambda e^{-\lambda x} \qquad , x \ge 0 $$ Depending on the book, the parameter might be its reciprocal, $\displaystyle \theta = {{ 1 } \over { \lambda }}$. Basic Properties Moment Generating Function [1]: $$m(t) = {{ \lambda } \over { \lambda</description>
    </item>
    <item>
      <title>Autonomous Systems: Flow and Time-T Maps</title>
      <link>https://freshrimpsushi.github.io/en/posts/1507/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1507/</guid>
      <description>Definition 1 Flow Given a space $X$ and a function $f : X \to X$, suppose we have the following vector field presented as a differential equation. $$ \dot{x} = f(x) $$ For a time variable $t$ and an initial value $x_{0}$, the solution to the autonomous differential equation is called a flow, which is denoted as $F(t, x_{0})$. For a fixed unit time $t = T$, $F_{T}(x) := F(T,x)$</description>
    </item>
    <item>
      <title>Dynamical Systems Described by Differential Equations and Equilibrium Points</title>
      <link>https://freshrimpsushi.github.io/en/posts/1505/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1505/</guid>
      <description>Definition 1 Given a space $V$ and function $f : V \to V$, assume the following vector field is given as a differential equation: $$ \dot{v} = f(v) $$ If variable $t$ is included in the differential equation and $t$ is not explicitly shown, it is referred to as an Autonomous Differential Equation. If a constant function $f_{0} (v)$ is a solution to the autonomous differential equation $\dot{v} = f(v)$,</description>
    </item>
    <item>
      <title>Graph Theory: Degree</title>
      <link>https://freshrimpsushi.github.io/en/posts/1496/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1496/</guid>
      <description>Definition 1 Let&amp;rsquo;s assume a directed graph $G$ is given. If an edge $vw$ exists, we say that the edge leaves from $v$ and enters into $w$. The number of edges entering vertex $v$ is called the Indegree and is denoted as $\deg^{-} (v)$. The number of edges leaving vertex $v$ is called the Outdegree and is denoted as $\deg^{+}(v)$. A vertex that is $\deg^{-} (v) = 0$ is called</description>
    </item>
    <item>
      <title>Inverse of Dirichlet Products</title>
      <link>https://freshrimpsushi.github.io/en/posts/1494/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1494/</guid>
      <description>Definition 1 An arithmetic function $f^{-1}$ is said to be the (Dirichlet) inverse of another arithmetic function $f$ if there exists a unique arithmetic function $f^{-1}$ satisfying the following equation $f$. $$ f \ast\ f^{-1} = f^{-1} \ast\ f = I $$ Here, $I$ is the identity function with respect to convolution. Theorem [1]: If an arithmetic function $f$ is $f(1) \ne 0$, then its inverse $f^{-1}$ uniquely exists and</description>
    </item>
    <item>
      <title>Mean and Variance of the Poisson Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/61/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/61/</guid>
      <description>Formulas $X \sim \text{Poi}(\lambda)$ Surface $$ E(X) = \lambda \\ \text{Var}(X) = \lambda $$ Derivation Strategy: Directly deduce from the definition of the Poisson distribution. The trick of splitting factorials and series is important. Definition of Poisson Distribution: For $\lambda &amp;gt; 0$, an discrete probability distribution that has the following probability mass function $\text{Poi} ( \lambda )$ is called a Poisson distribution. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over</description>
    </item>
    <item>
      <title>Poisson Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1491/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1491/</guid>
      <description>Definitions 1 For $\lambda &amp;gt; 0$, we refer to the following probability mass function as the Poisson Distribution that has a discrete probability distribution $\text{Poi} ( \lambda )$. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over { x! }} \qquad , x = 0 , 1 , 2, \cdots $$ Basic Properties Moment Generating Function [1]: $$m(t) = \exp \left[ \lambda \left( e^{t} - 1 \right) \right] \qquad , t</description>
    </item>
    <item>
      <title>Identity for Dirichlet Products</title>
      <link>https://freshrimpsushi.github.io/en/posts/1490/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1490/</guid>
      <description>Definition 1 A arithmetic function defined as follows $I$ is called the identity function. $$ I(n) := \left[ {{ 1 } \over { n }} \right] $$ [1] Identity series: This is the unit function $u$. In other words, $$ \sum_{d \mid n}I(d) = u(n) = 1 $$ [2] Completely multiplicative: For all $n , m \in \mathbb{N}$, $I (mn) = I(m) I(n)$ [a] Identity element for convolution: For all</description>
    </item>
    <item>
      <title>Negative Binomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1489/</link>
      <pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1489/</guid>
      <description>Definition 1 Given $r \in \mathbb{N}$ and $p \in (0,1]$, a discrete probability distribution $\text{NB}(r,p)$ with the following probability mass function is called the Negative Binomial Distribution. $$ p(x) = \binom{r+x-1}{x-1} p^{r}(1-p)^{x} \qquad, x = 0,1,2,\cdots $$ Basic Properties Moment Generating Function [1]: $$m(t) = \left[ {{ p } \over { 1 - (1-p) e^{t} }} \right]^{r} \qquad , t &amp;lt; -\log (1-P)$$ Mean and Variance [2]: If $X \sim</description>
    </item>
    <item>
      <title>Arithmetic Functions&#39; Dirichlet Convolution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1488/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1488/</guid>
      <description>Definition 1 For two arithmetic functions $f$, $g$, the arithmetic function $h$ satisfying the following is called the Dirichlet product of $f$ and $g$. $$ h(n) = \sum_{d \mid n} f(d) g \left( {{ n } \over { d }} \right) $$ The Dirichlet product can be represented as either $h (n) = \left( f \ast g \right) (n) $ or $h = f \ast g$. Explanation The Dirichlet product,</description>
    </item>
    <item>
      <title>Arithmetic Functions in Analytic Number Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/1487/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1487/</guid>
      <description>Definition 1 A function whose domain is the set of natural numbers $\mathbb{N}$ and whose range is the set of real numbers $\mathbb{R}$ or the set of complex numbers $\mathbb{C}$ is called an arithmetic function. Description In analytic number theory, there is interest in the properties and relationships of various arithmetic functions, including examples such as: Identity function $I$ Divisor function $\sigma_{\alpha}$ Norm $N$ Divisor function $\sigma_{\alpha}$ Möb</description>
    </item>
    <item>
      <title>Installing the Latest Version of Julia on Linux</title>
      <link>https://freshrimpsushi.github.io/en/posts/1511/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1511/</guid>
      <description>Julia&amp;rsquo;s latest version as of this post is v1.3.1. Guide Step 1. Download Julia Download the file that matches your CPU&amp;rsquo;s bit from Generic Linux Binaries for x86. Step 2. Unzip and Move Unzip it. Move the folder to where Julia is to be stored. This can be any location of your preference, but this post has moved it to /home/[username]/julia-1.3.1. Step 3. Symbolic Link Use the following command to</description>
    </item>
    <item>
      <title>Geometric Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1486/</link>
      <pubDate>Sun, 16 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1486/</guid>
      <description>Definition 1 For $p \in (0,1]$, the discrete probability distribution $\text{Geo}(p)$ that follows the probability mass function as shown above, is called the Geometric Distribution. $$ p(x) = p (1 - p)^{x-1} \qquad , x = 1 , 2, 3, \cdots $$ Take special care with the domain and the formula as there are two definitions used. Basic Properties Moment Generating Function [1]: $$m(t) = {{ p e^{t} } \over</description>
    </item>
    <item>
      <title>Binomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/1480/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1480/</guid>
      <description>Definition 1 The discrete probability distribution $\text{Bin}(n,p)$ with the following probability mass function for $n \in \mathbb{N}$ and $p \in [0,1]$ is called the Binomial Distribution. $$ p(x) = \binom{n}{x} p^{x} (1-p)^{n-x} \qquad , x = 0 , 1, \cdots n $$ Basic Properties Moment Generating Function [1]: $$m(t) = \left[ (1-p) + pe^{t} \right]^{n} \qquad , t \in \mathbb{R}$$ Mean and Variance [2]: If $X \sim \text{Bin}(n,p)$ then $$</description>
    </item>
    <item>
      <title>List of decimals to the 10,000th</title>
      <link>https://freshrimpsushi.github.io/en/posts/2339/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2339/</guid>
      <description>Prime numbers A list of primes up to the 10,000th. Download 2 3 5 7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97 101 103 107 109 113 127 131 137 139 149 151 157 163 167 173 179 181 191 193 197 199 211 223 227 229 233 239 241 251 257 263 269 271 277</description>
    </item>
    <item>
      <title>How to Parallel Process in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1474/</link>
      <pubDate>Sat, 08 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1474/</guid>
      <description>Code While the original sushi restaurant with fresh shrimp includes detailed explanations, Julia wants to omit explanations on purpose to emphasize how easy it is to do parallel processing. using Base.Threads for i in 1:10 println(i^2) end If you want to parallelize the above loop, you just need to prepend @threads to the for loop. @threads for i in 1:10 println(i^2) end However, if I must add one piece of</description>
    </item>
    <item>
      <title>Generalization of the Ellipse: Ellipsoid</title>
      <link>https://freshrimpsushi.github.io/en/posts/1471/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1471/</guid>
      <description>Definition For a linear transformation $A \in \mathbb{R}^{m \times m}$, the image $AN$ of a $m$-dimensional unit sphere $N := \left\{ \mathbb{x} \in \mathbb{R}^{m} : \left\| \mathbb{x} \right\|_{2} = 1 \right\}$ is called an ellipsoid. The eigenvalues $\sigma_{1}^{2} &amp;gt; \cdots \ge \sigma_{m}^{2} \ge 0$ of $A$ and the corresponding unit eigenvectors $u_{1} , \cdots , u_{m}$ are referred to as the axes of the ellipsoid for $\sigma_{i} u_{i}$. Explanation A</description>
    </item>
    <item>
      <title>Independence and iid of Random Variables</title>
      <link>https://freshrimpsushi.github.io/en/posts/1469/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1469/</guid>
      <description>Definition 1 A random variable $X_{1} , \cdots , X_{n}$ is said to be pairwise independent if it satisfies the following. $$ i \ne j \implies X_{i} \perp X_{j} $$ A continuous random variable $X_{1} , \cdots , X_{n}$ whose joint probability density function $f$ satisfies the condition with respect to each of its probability density functions $f_{1} , \cdots , f_{n}$ is said to be mutually independent. $$ f(x_{1}</description>
    </item>
    <item>
      <title>Probability Variables Independence in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1461/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1461/</guid>
      <description>Definition 1 If for two random variables $X_{1}, X_{2}$, the joint probability density function $f$ or the probability mass function $p$ satisfies the following conditions for the probability density functions $f_{1}, f_{2}$ or the probability mass functions $p_{1}, p_{2}$ of $X_{1}, X_{2}$, then $X_{1}, X_{2}$ are said to be independent, and is denoted as $X_{1} \perp X_{2}$. $$ f(x_{1} , x_{2} ) \equiv f_{1}(x_{1})f_{2}(x_{2}) \\ p(x_{1} , x_{2} ) \equiv</description>
    </item>
    <item>
      <title>Optimization Techniques in Mathematics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1463/</link>
      <pubDate>Sat, 25 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1463/</guid>
      <description>Definition The problem of finding $x^{ \ast } = \argmin_{x} f(x)$ that makes the function value of function $f : \mathbb{R}^{n} \to \mathbb{R}$ minimum is known as the Optimization Problem, and the algorithm to solve this problem is called an Optimization Technique. The given function $f$ in the optimization problem is specifically referred to as the Objective Function. $x^{ \ast }$ is called the Global Optimizer if for all $x$,</description>
    </item>
    <item>
      <title>Probability Distributions under Conditional Probability in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1458/</link>
      <pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1458/</guid>
      <description>Definition For a discrete random variable $X_{1}, X_{2}, \cdots , X_{n}$, the following $p_{2, \cdots , n \mid 1}$, given $X_{1} = x_{1}$, is called the joint conditional probability mass function of $ X_{2}, \cdots , X_{n}$: $$ p_{2, \cdots , n \mid 1} ( x_{2} , \cdots ,x_{n} \mid X_{1} = x_{1} ) = {{ p_{1, \cdots , n}(x_{1} , x_{2} , \cdots , x_{n}) } \over { p_{1}(</description>
    </item>
    <item>
      <title>Julia&#39;s Powerful Convenience Features, Macros</title>
      <link>https://freshrimpsushi.github.io/en/posts/1454/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1454/</guid>
      <description>Overview Macros in Julia provide convenience features when coding, being executed in front of a scope. For example, if you want to know how much time your program is consuming, you can write it as follows. @time for t in 1:10 foo() bar() end Examples There are many types, but the following macros are especially widely used: @time: Measures the execution time of the function or scope that follows. When</description>
    </item>
    <item>
      <title>How to Use Pipe Operators in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1450/</link>
      <pubDate>Sat, 11 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1450/</guid>
      <description>Overview Julia supports the pipeline operator, highlighting its strength in handling data. Code julia&amp;gt; (1:5) .|&amp;gt; (x -&amp;gt; sqrt(x+2)) .|&amp;gt; sin |&amp;gt; minimum 0.4757718381527513 julia&amp;gt; minimum(sin.((x -&amp;gt; sqrt(x+2)).(1:5))) 0.4757718381527513 The example code above puts the array $[1,2,3,4,5]$ into $\sqrt{x + 2}$, and then puts the result into $\sin$ to obtain the smallest value. The code above and below produces exactly the same results. It goes without saying how useful the</description>
    </item>
    <item>
      <title>Multivariate Probability Distributions in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1449/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1449/</guid>
      <description>Definition 1 A Random Vector is defined as $X = (X_{1} , \cdots , X_{n})$ for $n$ number of probability variables $X_{i}$ defined in sample space $\Omega$. The range $X(\Omega)$ of $X$ is also called a space. A function that satisfies the following $F_{X} : \mathbb{R}^{n} \to [0,1]$ is called the Joint Cumulative Distribution Function of $X$. $$ F_{X}\left( x_{1}, \cdots , x_{n} \right) := P \left[ X_{1} \le x_{1}</description>
    </item>
    <item>
      <title>Lambda Expressions in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1448/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1448/</guid>
      <description>Overview In Julia, lambdas are defined as follows: (x -&amp;gt; 3x^2 - 2x + 3)(1) This corresponds to defining the anonymous function $\lambda : \mathbb{Z} \to \mathbb{Z}$, substituting $1$ into it, and obtaining the function value $4$. $$ \lambda : x \mapsto ( 3 x^{2} - 2 x + 3 ) \\ \lambda (1) = 4 $$ Indeed, lambda expressions themselves are not a Julia-specific feature but almost naturally supported,</description>
    </item>
    <item>
      <title>How to Load Images in Julia and Save Them as Matrices</title>
      <link>https://freshrimpsushi.github.io/en/posts/1446/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1446/</guid>
      <description>Code using Images cd(&amp;#34;C:/Users/rmsms/OneDrive/examples&amp;#34;) pwd() example = load(&amp;#34;example.jpg&amp;#34;) typeof(example) size(example) gray1 = Gray.(example) typeof(gray1) size(gray1) M = convert(Array{Float64},gray1) typeof(M) size(M) colorview(Gray, M.^(1/2)) save(&amp;#34;rgb.png&amp;#34;, colorview(RGB, example)) save(&amp;#34;gray1.png&amp;#34;, colorview(Gray, gray1)) save(&amp;#34;gray2.png&amp;#34;, colorview(Gray, transpose(gray1))) save(&amp;#34;gray3.png&amp;#34;, colorview(Gray, M.^(1/2))) Let&amp;rsquo;s briefly understand the example code from top to bottom: cd() : Change Directory, changes the working directory to the desired location. pwd() : Print Working Directory, prints the working directory. If you want to follow</description>
    </item>
    <item>
      <title>Sets and Operators in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1442/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1442/</guid>
      <description>Overview Julia, like Python, supports the set data type. As with any set data type, it is incredibly useful for those who use it and utterly ignored by those who don&amp;rsquo;t. Given that Julia&amp;rsquo;s design is closely aligned with mathematics, its implementation of set concepts and operations is robust, making it an important feature to understand. Perhaps the most distinct difference from other languages, especially Python, is the ability to</description>
    </item>
    <item>
      <title>What is the Moment Generating Function?</title>
      <link>https://freshrimpsushi.github.io/en/posts/248/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/248/</guid>
      <description>Definition 1 For a random variable $X$ and some positive number $h&amp;gt;0$, if $E(e^{tX})$ exists in $-h&amp;lt; t &amp;lt; h$, then $M(t) = E( e^{tX} )$ is defined as the Moment Generating Function of $X$. Explanation The moment generating function (mgf) is a concept often encountered relatively early in mathematical statistics, yet its unfamiliar definition and seemingly contextless introduction can make it a source of dislike for the subject. The</description>
    </item>
    <item>
      <title>Pearson Correlation Coefficient</title>
      <link>https://freshrimpsushi.github.io/en/posts/57/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/57/</guid>
      <description>Definition 1 For two random variables $X, Y$, the following $\rho = \rho (X,Y)$, defined as the Pearson Correlation Coefficient, is: $$ \rho = { {\text{Cov} (X,Y)} \over {\sigma_X \sigma_Y} } $$ $\sigma_{X}$, $\sigma_{Y}$ are the standard deviations of $X$, $Y$ respectively. Explanation The Pearson Correlation Coefficient is a measure of whether two variables have a (linear) correlation. If close to $1$ or $–1$, it is</description>
    </item>
    <item>
      <title>Slicing and Indexing of Arrays in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1437/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1437/</guid>
      <description>Overview Julia is a language that mixes the advantages of R, Python, and Matlab. Arrays are fundamental to programming, and their usage reveals traces of these languages. Code Matrix julia&amp;gt; M = [1. 2. ; 3. 4.] 2×2 Array{Float64,2}: 1.0 2.0 3.0 4.0 julia&amp;gt; size(M) (2, 2) julia&amp;gt; length(M) 4 For matrices, the syntax is defined and used almost exactly like Matlab. The size() function is used just</description>
    </item>
    <item>
      <title>Various Properties of Covariance</title>
      <link>https://freshrimpsushi.github.io/en/posts/425/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/425/</guid>
      <description>Definitions and Properties The covariance of probability variables $X$ and $Y$, whose means are $\mu_{X}$ and $\mu_{Y}$ respectively, is defined as $\text{Cov} (X ,Y) : = E \left[ ( X - \mu_{X} ) ( Y - \mu_{Y} ) \right]$. Covariance has the following properties: [1]: $\text{Var} (X) = \text{Cov} (X,X)$ [2]: $\text{Cov} (X,Y) = \text{Cov} (Y, X)$ [3]: $\text{Var} (X + Y) = \text{Var} (X) + \text{Var} (Y) + 2</description>
    </item>
    <item>
      <title>Properties of Mean and Variance</title>
      <link>https://freshrimpsushi.github.io/en/posts/424/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/424/</guid>
      <description>Theorem The mean $E ( X ) = \mu_{X}$ and variance $\text{Var} (X) = E [ ( X - \mu_{X} )^2 ]$ have the following properties: [1]: $E(X + Y) = E(X) + E(Y)$ [2]: $E(aX + b) = a E(X) + b$ [3]: $\text{Var} (X) \ge 0$ [4]: $\text{Var} ( X ) = E(X^2) - \mu_{X}^2$ [5]: $\text{Var} (aX + b) = a^2 \text{Var} (X)$ Explanation As they relate</description>
    </item>
    <item>
      <title>Mathematical Proof of the Properties of Representative Values</title>
      <link>https://freshrimpsushi.github.io/en/posts/49/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/49/</guid>
      <description>Summary Let&amp;rsquo;s assume that we have given data $X = \left\{ x_{1} , \cdots , x_{n} \right\}$. [0]: The $\theta$ that minimizes $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{0}$ is $$ \argmin_{\theta} h \left( \theta \right) = \text{mode}(X) $$ [1]: The $\theta$ that minimizes $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{1}$ is $$ \argmin_{\theta} h \left( \theta \right) = \text{median}(X) $$ [2]: The $\theta$ that minimizes $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{2}$ is $$ \argmin_{\theta}</description>
    </item>
    <item>
      <title>Expectation, Mean, Variance, and Moments in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/246/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/246/</guid>
      <description>Definition: Expectation, Mean, and Variance Let&amp;rsquo;s assume that we have a given random variable $X$. If the probability density function $f(x)$ of a continuous random variable $X$ satisfies $\displaystyle \int_{-\infty}^{\infty} |x| f(x) dx &amp;lt; \infty$, then $E(X)$, defined as follows, is called the Expectation of $X$. $$ E(X) := \int_{-\infty}^{\infty} x f(x) dx $$ If the probability mass function $p(x)$ of a discrete random variable $X$ satisfies $\displaystyle \sum_{x} |x|</description>
    </item>
    <item>
      <title>Greedy Algorithm</title>
      <link>https://freshrimpsushi.github.io/en/posts/1434/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1434/</guid>
      <description>Definition Greedy algorithm is a method of making choices that only considers the current moment and selects the best possible option. Description As its name suggests, the greedy algorithm focuses on the immediate without taking a long-term perspective. Speaking positively, it&amp;rsquo;s always trying to do its best, but this may not always be wise when looking at the bigger picture. Consider the following example: Let&amp;rsquo;s say there&amp;rsquo;s a problem of</description>
    </item>
    <item>
      <title>Probability Variables and Probability Distribution in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1433/</link>
      <pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1433/</guid>
      <description>Definition 1 Let us assume that probability $P$ is defined in the sample space $\Omega$. A function $X : \Omega \to \mathbb{R}$ whose domain is the sample space is called a Random Variable. The range $X(\Omega)$ of a random variable is also called its Space. A function $F_{X} : \mathbb{R} \to [0,1]$ that satisfies the following is called the Cumulative Distribution Function (cdf) of $X$. $$ F_{X}(x) = P_{X}\left( (-\infty,x]</description>
    </item>
    <item>
      <title>Convergence of Distributions Defined by Measure Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/1432/</link>
      <pubDate>Sat, 21 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1432/</guid>
      <description>Definition Let&amp;rsquo;s define a measurable space $(S,\mathcal{S})$ with respect to the Borel sigma field $\mathcal{S}:= \mathcal{B}(S)$ of a metric space $S$. When random variables $X$ and stochastic processes $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ defined in a probability space $(\Omega, \mathcal{F}, P)$ are $n \to \infty$, for all $f \in C_{b}(S)$, if the following is satisfied, then it is said to Converge in Distribution $X$ and is denoted as $X_{n} \overset{D}{\to}</description>
    </item>
    <item>
      <title>Probability and the Addition Law of Probability in Mathematical Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1431/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1431/</guid>
      <description>Definition 1 An experiment that can be repeated under the same conditions is referred to as a Random Experiment. The set $\Omega$ of all possible outcomes that can be obtained from a random experiment is called the Sample Space. The set of outcomes in the sample space that we are interested in, i.e., $B \subset \Omega$ is called an Event, and these sets are represented as $\mathcal{B}$. A function $P</description>
    </item>
    <item>
      <title>Partially Ordered Set</title>
      <link>https://freshrimpsushi.github.io/en/posts/1421/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1421/</guid>
      <description>Definitions 1 A relation $\le$ in a set $A$ that is reflexive, transitive, and antisymmetric is called a Partial Order, and $(A,\le)$ is referred to as a partially ordered set. Saying that $A$ is a partially ordered set means that it satisfies the following for all elements $a,b \in A$. $$ a \le b \land b \le a \implies a = b $$ Given a partially ordered set $(A, \le)$,</description>
    </item>
    <item>
      <title>Completely Bounded Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/1420/</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1420/</guid>
      <description>Definition 1 Given a metric space $(X,d)$ and $\varepsilon&amp;gt;0$, A finite set $A_{\varepsilon} \subset X$ that satisfies $B_{d}(x,\varepsilon) \cap A_{\varepsilon} \ne \emptyset$ for all $x \in X$ is called a $\varepsilon$-net for $X$. If for all $\varepsilon &amp;gt; 0$, there exists a $\varepsilon$-net $A_{\varepsilon}$ for $X$, then $X$ is said to be Totally Bounded. Explanation Totally bounded spaces are often also called precompact spaces. $\varepsilon$-Net Calling $A_{\varepsilon}$ a net is</description>
    </item>
    <item>
      <title>Installing and Using Packages in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/1416/</link>
      <pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1416/</guid>
      <description>Method 1 using LinearAlgebra using Pkg Pkg.add(&amp;#34;Plots&amp;#34;) Pkg.add(&amp;#34;Distributions&amp;#34;) using Plots The above code demonstrates importing the LinearAlgebra and Pkg packages and installing the Plots, Distribution packages using the .add() function. The keyword using to import packages is somewhat reminiscent of the language used in mathematics when applying a theorem or argument. Installing packages is more akin to R than Python, and its usage closely resembles that of Python. Similar to</description>
    </item>
    <item>
      <title>Convergence in Measure</title>
      <link>https://freshrimpsushi.github.io/en/posts/1410/</link>
      <pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1410/</guid>
      <description>Definition Let space $S$ be both a metric space $( S , \rho)$ and a measurable space $(S,\mathcal{B}(S))$. Measure Theory When a measure $\mu$ defined on $S$ and a sequence of measures $\left\{ \mu_n \right\}_{n \in \mathbb{N}}$ is $n \to \infty$, it is said to converge weakly to measure $\mu$ if it satisfies the following for all $f \in C_{b}(S)$: $$ \int_{S} f d\mu_{n} \to \int_{S} f d\mu $$ It</description>
    </item>
    <item>
      <title>Dinkin&#39;s Pi-Lambda Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/1405/</link>
      <pubDate>Sat, 30 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1405/</guid>
      <description>Theorem If the pi system $\mathcal{P}$ is a subset of the lambda system $\mathcal{L}$, then there exists a sigma field $\sigma ( \mathcal{P} )$ that satisfies $\mathcal{P} \subset \sigma ( \mathcal{P} ) \subset \mathcal{L}$. $\sigma ( \mathcal{P} )$ represents the smallest sigma field that contains all elements of $\mathcal{P}$. Explanation At first glance, the statement might look rather simple, but as with such theorems, its proof is quite long and</description>
    </item>
    <item>
      <title>Convergence of Probabilities Defined by Measure Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/1397/</link>
      <pubDate>Sat, 23 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1397/</guid>
      <description>Probability Convergence Defined Rigorously Given a probability space $( \Omega , \mathcal{F} , P)$. A sequence of random variables $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ is said to converge in probability to a random variable $X$ if it converges in measure to $X$, denoted as $X_{n} \overset{P}{\to} X$. If you&amp;rsquo;re not yet familiar with measure theory, the term probability space can be disregarded. Explanation The convergence of $\left\{ X_{n} \right\}_{n \in</description>
    </item>
    <item>
      <title>Cardinality of a Set</title>
      <link>https://freshrimpsushi.github.io/en/posts/1395/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1395/</guid>
      <description>Definition 1 For any given set $X$, $\text{card} X$ that satisfies the following properties is defined as the Cardinality of $X$. (i): $X = \emptyset \iff \text{card} X = 0$ (ii): $A \sim B \iff \text{card} A = \text{card} B$ (iii): For some natural number $k$, if $X \sim \left\{ 1 , 2, \cdots , k \right\}$ then $\text{card} X = k$ Specifically, the cardinality of a finite set is</description>
    </item>
    <item>
      <title>Uniform Integrability</title>
      <link>https://freshrimpsushi.github.io/en/posts/1392/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1392/</guid>
      <description>Definition Let&amp;rsquo;s assume that a measure space $( X , \mathcal{E} , \mu)$ is given. Given a set of Lebesgue integrable functions $\Phi \subset \mathcal{L}^{1}$, if for every $\varepsilon&amp;gt;0$, there exists $\delta &amp;gt; 0$ that satisfies $$ \mu (E) &amp;lt; \delta \implies \sup_{f \in \Phi} \int_{ E } \left| f \right| d \mu &amp;lt; \varepsilon $$ then $\Phi$ is said to be uniformly integrable. Explanation The concept of uniform integrability</description>
    </item>
    <item>
      <title>Cantor&#39;s Diagonal Argument</title>
      <link>https://freshrimpsushi.github.io/en/posts/109/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/109/</guid>
      <description>Theorem 1 The open interval $(0,1)$ is an uncountable set. Proof The set of real numbers $\mathbb{R}$ is not a countable set, which is shown by the absence of a &amp;lsquo;one-to-one correspondence&amp;rsquo; between the set of real numbers and any countable set. This demonstrates that there is no one-to-one correspondence between the set of natural numbers and the open interval $(0,1)$, which can be obtained as a corollary. Cantor proved</description>
    </item>
    <item>
      <title>Countable and Uncountable Sets</title>
      <link>https://freshrimpsushi.github.io/en/posts/1383/</link>
      <pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1383/</guid>
      <description>Definitions 1 A set $X$ is called a countable set if it is either a finite set or $X \sim \mathbb{N}$. A set that is not countable is called an uncountable set. $\mathbb{N}$ is the set of natural numbers. $X \sim Y$&amp;rsquo;s $\sim$ denotes the equivalence of sets. Explanation The concept of countable sets might not be intuitively accepted by Easterners, including Koreans. This comes from a fundamental difference in</description>
    </item>
    <item>
      <title>Finite Sets and Infinite Sets Strictly Defined by Set Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/1381/</link>
      <pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1381/</guid>
      <description>## Definition [^1] [^1]: Translated by Heungcheon Lee, You-Feng Lin. (2011). Set Theory: An Intuitive Approach: p205, 215. 1. If there exists a [bijection](../471) $f : X \to Y$ between two [sets](../1316) $X,Y$, then $X$ and $Y$ are said to be **equipotent** and denoted as $X \sim Y$. 2. If for some non-[empty set](../1337) $X$, any [proper subset](../1329) $Y \subsetneq X$ satisfies $X \sim Y$, then $X$ is called an</description>
    </item>
    <item>
      <title>Julia&#39;s Types and Annotations</title>
      <link>https://freshrimpsushi.github.io/en/posts/1379/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1379/</guid>
      <description>Code julia&amp;gt; typeof(0) Int64 julia&amp;gt; typeof(0.0) Float64 julia&amp;gt; typeof(0 == 0.0) Bool julia&amp;gt; typeof(Bool) DataType julia&amp;gt; typeof(NaN) Float64 julia&amp;gt; typeof(Inf) Float64 julia&amp;gt; typeof(&amp;#39;O&amp;#39;) Char julia&amp;gt; typeof(&amp;#34;Ohmygirl&amp;#34;) String julia&amp;gt; typeof(&amp;#34;O&amp;#34;) String Julia includes all sorts of types. $0$ and $0.0$ are the same $0$, but have different types, and as you can see, even a type like Bool has a type named DataType. Like in C, String is an array of</description>
    </item>
    <item>
      <title>Injection, Surjection, Bijection, Inverse Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/471/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/471/</guid>
      <description>Definition 1 Let&amp;rsquo;s say $x \in X$, $y \in Y$, and $f: X \to Y$ are functions. For every $x_{1}, x_{2} \in X$, if $x_{1} \ne x_{2} \implies f(x_{1}) \ne f(x_{2})$ then $f$ is called injective. If $f(X) = Y$, then $f$ is called surjective. If $f$ is both injective and surjective, it is called bijective. $I : X \to X$ that satisfies $I(x) = x$ is called an Identity</description>
    </item>
    <item>
      <title>Julia Programming Language</title>
      <link>https://freshrimpsushi.github.io/en/posts/1374/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1374/</guid>
      <description>Overview Julia has been developed at MIT and publicly released in 2012, aiming for a language that is both highly productive and fast. It achieves speeds comparable to C or Fortran while also providing a high-level syntax similar to Python or R, among absorbing benefits from various other languages. As of November 2019, it&amp;rsquo;s true that Julia is somewhat lagging due to the rapid advancement of GPUs and the prevalence</description>
    </item>
    <item>
      <title>The Original Image of a Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/472/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/472/</guid>
      <description>Definition 1 For functions $f: X \to Y$ and $B \subset Y$, $f^{-1}(B): = \left\{ x \in X \ | \ f(x) \in B \right\}$ is called the preimage or inverse image according to $f$ of $B$. Explanation Though the notation is similar, one cannot say that the inverse image and the inverse function are related just by the definitions alone, and one should not confuse them. Some people might</description>
    </item>
    <item>
      <title>Functions and Mappings Rigorously Defined by Set Theory, Sequences</title>
      <link>https://freshrimpsushi.github.io/en/posts/470/</link>
      <pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/470/</guid>
      <description>Definitions 1 Let&amp;rsquo;s assume two sets $X$, $Y$ that are not empty sets are given. A binary relation $f \subset (X,Y)$ is called a function if it satisfies the following and is denoted as $f : X \to Y$. $$ (x ,y_{1}) \in f \land (x,y_{2}) \in f \implies y_{1} = y_{2} $$ For the function $f : X \to Y$, $\text{Dom} (f) = X$ is called the domain of</description>
    </item>
    <item>
      <title>Homotopy Type</title>
      <link>https://freshrimpsushi.github.io/en/posts/1050/</link>
      <pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1050/</guid>
      <description>Definition 1 Let&amp;rsquo;s say a equivalence relation $R$ is defined on a set $X$. For $x \in X$, $x / R := \left\{ y \in X : y R x \right\}$ is called the equivalence class of $x$. The set of all equivalence classes given by $X$ is represented as $X / R := \left\{ x / R : x \in X \right\}$. Explanation Though the expression might look a</description>
    </item>
    <item>
      <title>Partition of a Set</title>
      <link>https://freshrimpsushi.github.io/en/posts/1049/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1049/</guid>
      <description>Definition 1 A partition of a set $X$ consists of all subsets $A,B,C$ of $X$ that satisfy the following conditions: (i): $$A,B \in \mathscr{P} \land A \ne B \implies A \cap B = \emptyset$$ (ii): $$\bigcup_{C \in \mathscr{P} } C = X$$ Explanation Although the mathematical expression might seem complex, simply put, it&amp;rsquo;s just about dividing the entire set into several parts without omission. If there&amp;rsquo;s leeway to delve into</description>
    </item>
    <item>
      <title>Equivalence Relations in Mathematics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1033/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1033/</guid>
      <description>Definition 1 A binary relation that is reflexive, symmetric, and transitive is called an equivalence relation. Explanation To put the concept of an equivalence relation in non-mathematical terms, it&amp;rsquo;s like saying &amp;ldquo;it&amp;rsquo;s all the same.&amp;rdquo; While it&amp;rsquo;s not always necessary to have a reason when studying mathematics, if there were to be a practical reason for studying mathematics, it could be said to &amp;ldquo;simplify complex concepts into easier, more manageable</description>
    </item>
    <item>
      <title>Mathematical Binary Relations</title>
      <link>https://freshrimpsushi.github.io/en/posts/960/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/960/</guid>
      <description>Definition 1 For two sets $X,Y$, $$ R := \left\{ (x,y): x \in X , y \in Y \right\} \subset X \times Y $$ is defined as a (binary) relation and is represented as follows: $$ (x,y) \in R \iff x R y $$ $x R y \iff y R^{-1} x$ satisfying $$ R^{-1} : \left\{ (y,x): (a,b) \in R \right\} $$ is called the inverse relation of $R$. For</description>
    </item>
    <item>
      <title>Cartesian Product of Sets</title>
      <link>https://freshrimpsushi.github.io/en/posts/1360/</link>
      <pubDate>Mon, 04 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1360/</guid>
      <description>Definition 1 For any two objects $a$, $b$, $(a,b)$ is called an Ordered Pair. For any two sets $A$, $B$, the set of ordered pairs $(a,b)$ of $a \in A$, $b \in B$ is called the Cartesian Product of $A$ and $B$ and is represented as follows. $$ A \times B := \left\{ (a,b): a \in A \land b \in B \right\} $$ Explanation The reason why the term &amp;lsquo;product&amp;rsquo;</description>
    </item>
    <item>
      <title>Sets and Indices</title>
      <link>https://freshrimpsushi.github.io/en/posts/1358/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1358/</guid>
      <description>Definitions A set whose elements are sets themselves is called a Family. The elements of a family are called Members. When each element of a set $\Gamma$ corresponds to a set $A_{\gamma}$ with $\gamma$ as the index, $\Gamma$ as the index set, and $\left\{ A_{\gamma} : \gamma \in \Gamma \right\}$ as the indexed family. Explanation Though the term &amp;lsquo;Family&amp;rsquo; was originally introduced as a refined term for &amp;lsquo;set of sets&amp;rsquo;,</description>
    </item>
    <item>
      <title>Stopping Times in Stochastic Processes</title>
      <link>https://freshrimpsushi.github.io/en/posts/1351/</link>
      <pubDate>Sat, 26 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1351/</guid>
      <description>Definitions Let&amp;rsquo;s assume a probability space $( \Omega , \mathcal{F} , P)$ is given. A random variable $\tau$ with an integer value greater than or equal to $0$ for all $n \in \mathbb{N}_{0}$ that satisfies $(\tau = n) \in \mathcal{F}_{n}$ with respect to the filtration $\left\{ \mathcal{F}_{n} \right\}$ is called a Stopping Time. For a Borel set $B \in \mathcal{B}(\mathbb{R})$, $(\tau \in B) = \tau^{-1} (B)$ is, therefore, the same</description>
    </item>
    <item>
      <title>Lp Convergence</title>
      <link>https://freshrimpsushi.github.io/en/posts/1394/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1394/</guid>
      <description>Definition 1 If a sequence of functions $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ satisfies the following for some function $f$, then $\left\{ f_{n} \right\}$ is said to converge to $f$ in $L^{p}$. $$ \lim_{n \to \infty} \left\| f_{n} - f \right\|_{p} = 0 $$ The sequence $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ is said to be Cauchy in $L^{p}$ if it satisfies the following. $$ \lim_{n, m \to \infty} \left\| f_{n} -</description>
    </item>
    <item>
      <title>The Definition of Martingale</title>
      <link>https://freshrimpsushi.github.io/en/posts/1349/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1349/</guid>
      <description>Definition Let&amp;rsquo;s assume that a probability space $( \Omega , \mathcal{F} , P)$ is given. A sequence $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$ of sub-σ-fields of $\mathcal{F}$ is called a filtration if it satisfies the following: $$ \forall n \in \mathbb{N}, \mathcal{F}_{n} \subset \mathcal{F}_{n+1} $$ Given a filtration $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$, a sequence $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$</description>
    </item>
    <item>
      <title>Axiom of Infinity</title>
      <link>https://freshrimpsushi.github.io/en/posts/1348/</link>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1348/</guid>
      <description>Axioms $$ \exists U \left( \emptyset \in U \land \forall X ( X \in U \implies S(X) \in U) \right) $$ There exists a set $U$ that contains the empty set and $X$ as elements, and also contains $S(X)$ as an element. For a set $X$, $S(X)$ is defined as a set that is equivalent to $S(X):= X \cup \left\{ X \right\}$. Explanation Rather than tediously explaining why this is</description>
    </item>
    <item>
      <title>Power Set Axiom</title>
      <link>https://freshrimpsushi.github.io/en/posts/1346/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1346/</guid>
      <description>Axioms 1 $$ \forall X \exists P \forall A ( A \subset X \implies A \in P) $$ For any set $X$, there exists a set $P$ that contains every subset of $X$ as an element. Explanation The power set of $X$ is generally denoted by $\mathcal{P} (X)$ or $2^{X}$, the reason being if the number of elements of a finite set $X$ is denoted by $|X|$, then $\left| \mathcal{P}</description>
    </item>
    <item>
      <title>Union axiom</title>
      <link>https://freshrimpsushi.github.io/en/posts/1344/</link>
      <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1344/</guid>
      <description>Axiom $$ \forall X \left( \exists U \left( \forall a \left( a \in x \land x \in X \implies a \in U \right) \right) \right) $$ For any set $X$, there exists a set $U$ that contains all the elements of the elements of $X$. Definition of Union 1 The axiom of union guarantees the existence of the union defined as follows: $$ x \in A \lor x \in B</description>
    </item>
    <item>
      <title>Classification Axiomatic Form</title>
      <link>https://freshrimpsushi.github.io/en/posts/1341/</link>
      <pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1341/</guid>
      <description>Axioms 1 $$ \forall X \exists A \forall a \left( a \in A \iff ( a \in X \land p(a)) \right) $$ For any set $X$, there exists a subset $A$ composed of elements that have property $p$. $p(x)$ is a propositional function in $X$. Explanation The reason why $A$ is limited to a subset of $X$ is to prevent problems like Russell&amp;rsquo;s paradox. The reason it is not called</description>
    </item>
    <item>
      <title>Empty Set Axiom</title>
      <link>https://freshrimpsushi.github.io/en/posts/1337/</link>
      <pubDate>Sun, 13 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1337/</guid>
      <description>Axioms 1 $$ \exists X \forall x \left( \lnot \left( x \in X \right) \right) $$ A set $X$ that does not contain any elements exists, and this set $X$ is defined as the empty set. Explanation The empty set is typically denoted as $\emptyset$. Meanwhile, the empty set can also be viewed as a set with $0$ elements, and sets that can be defined in terms of the number</description>
    </item>
    <item>
      <title>Set Inclusion</title>
      <link>https://freshrimpsushi.github.io/en/posts/1329/</link>
      <pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1329/</guid>
      <description>Definition 1 $$ A \subset B \iff \forall x (x\in A \implies x \in B) $$ For any set $A$, $B$, if all elements of $A$ are also elements of $B$, then $A$ is a Subset of $B$, and $B$ is a Superset of $A$, denoted as $A \subset B$. Explanation If it&amp;rsquo;s $A \subset B$ and $B \not\subset A$, then $A$ is called a Proper Subset of $B$, and</description>
    </item>
    <item>
      <title>Properties of Conditional Expectation</title>
      <link>https://freshrimpsushi.github.io/en/posts/1322/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1322/</guid>
      <description>Theorem Given a probability space $( \Omega , \mathcal{F} , P)$: [1] From measure theory: If measurable functions $f$, $g$ are $\mathcal{F}$-measurable, then there exists a Borel function $h : \mathbb{R} \to \mathbb{R}$ satisfying $g = h (f)$. [2] Application in probability theory: If random variables $X$, $Y$ are $\sigma (X)$-measurable, then there exists a Borel function $h : \mathbb{R} \to \mathbb{R}$ satisfying $E(Y | X) = h(X)$. [3]: If</description>
    </item>
    <item>
      <title>Dynamic Programming</title>
      <link>https://freshrimpsushi.github.io/en/posts/1262/</link>
      <pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1262/</guid>
      <description>Buildup When solving a problem, if the solution to a larger problem includes the solution to a smaller problem, it is said to have an Optimal Substructure. An easy example of a problem with an optimal substructure is calculating the Fibonacci numbers. The $n$-th Fibonacci number is calculated as $a_{n} = a_{n-1} + a_{n-2}$, thus, the larger problem $a_{n}$ includes the smaller problems $a_{n-1}$ and $a_{n-2}$. A simple way to</description>
    </item>
    <item>
      <title>Definition of Sets and Propositional Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/1316/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1316/</guid>
      <description>Definitions 1 Set: A collection of distinct objects that are the subjects of our intuition or thought is called a set. Element: An object that belongs to a set is called an element. Propositional Function: For an element $x$ of the set $U$, a proposition $p(x)$ that is either true or false is called a propositional function in $U$. Explanation In mathematics, the concept of a set is as important</description>
    </item>
    <item>
      <title>Conditional Expectation of Random Variables Defined by Measure Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/1315/</link>
      <pubDate>Thu, 03 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1315/</guid>
      <description>Definition Let&amp;rsquo;s assume a probability space $( \Omega , \mathcal{F} , P)$ is given. If $\mathcal{G}$ is a sub sigma-field of $\mathcal{F}$ and the random variable $X \in \mathcal{L}^{1} ( \Omega )$ is integrable, for all $A \in \mathcal{G}$, $$ \int_{A} Y d P = \int_{A} X d P $$ a $\mathcal{G}$-measurable random variable $Y$ uniquely exists satisfying the above, then $Y := E ( X | \mathcal{G} )$ is</description>
    </item>
    <item>
      <title>Finite Sigma Measures</title>
      <link>https://freshrimpsushi.github.io/en/posts/1314/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1314/</guid>
      <description>Definitions 1 Let a measurable space $( X , \mathcal{E} )$ be given. If $\mu (X) &amp;lt; \infty$, then $\mu$ is called a finite measure. When $$\displaystyle X = \bigcup_{i=1}^{\infty} E_{i} \qquad , E_{i} \in \mathcal{E}$$ for all $i \in \mathbb{N}$ such that $\mu ( E_{i} ) &amp;lt; \infty$, it is called a sigma-finite measure. Also, the ordered pair $(X, \mathcal{E}, \mu)$ is called a sigma-finite measure space. If for</description>
    </item>
    <item>
      <title>Mathematical Induction</title>
      <link>https://freshrimpsushi.github.io/en/posts/118/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/118/</guid>
      <description>Law 1 $$ \left[ p(1) \land \left( p(n) \implies p(n+1) \right) \right] \implies \forall n \in \mathbb{N} : p(n) $$ Regarding the proposition $p(n) (n=1,2,3, \cdots )$, if $p(1)$ is true and assuming $p(n)$, then if $p(n+1)$ holds, $p(n)$ is true. Explanation When a formula holds for natural numbers, a powerful proof method called Peano&amp;rsquo;s Fifth Axiom is especially potent, or simply called induction without the &amp;lsquo;mathematical&amp;rsquo; prefix. Originally, induction</description>
    </item>
    <item>
      <title>Absolute Continuity of Measures</title>
      <link>https://freshrimpsushi.github.io/en/posts/1309/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1309/</guid>
      <description>Definition 1 Let&amp;rsquo;s assume given a measurable space $( \Omega , \mathcal{F} )$. If measures $\nu$, $\mu$ satisfy $$ \mu (A) = 0 \implies \nu (A) = 0 $$ for all $A \in \mathcal{F}$, then $\nu$ is said to be absolutely continuous with respect to $\mu$ and is denoted by $\nu \ll \mu$. Explanation As the notation $\nu \ll \mu$ suggests, $\mu$ has a strong sense of &amp;lsquo;dominating&amp;rsquo; over $\nu$.</description>
    </item>
    <item>
      <title>Mathematical Logic Proof by Contradiction</title>
      <link>https://freshrimpsushi.github.io/en/posts/117/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/117/</guid>
      <description>Law 1 $$ (p \land \lnot q) \to c \iff p \to q $$ $c$ implies a contradiction. Explanation Reductio ad absurdum or proof by contradiction is a proof technique that is widely used throughout mathematics. However, those who encounter this method for the first time may find the term unfamiliar and may resist it. Or there might be people who, although they have become accustomed to it, do not</description>
    </item>
    <item>
      <title>Mathematical Proof of the Counterfactual</title>
      <link>https://freshrimpsushi.github.io/en/posts/116/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/116/</guid>
      <description>Law 1 $$ p \to q \iff \lnot q \to \lnot p $$ Explanation If a proposition is true, then its contrapositive is also true; if a proposition is false, then its contrapositive is also false. Of course, if the converse holds, then the inverse of the original proposition also holds through contraposition. These expressions might be too difficult for those not familiar with mathematics. Let&amp;rsquo;s understand it through an</description>
    </item>
    <item>
      <title>Proof of De Morgan&#39;s Laws</title>
      <link>https://freshrimpsushi.github.io/en/posts/1306/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1306/</guid>
      <description>Theorem 1 [1] De Morgan&amp;rsquo;s Laws: $$ \lnot (p \land q) \iff \lnot p \lor \lnot q \\ \lnot(p \lor q) \iff \lnot p \land \lnot q $$ [2] De Morgan&amp;rsquo;s Theorem: $$ (A \cup B)^{c} = A^{c} \cap B^{c} \\ (A \cap B)^{c} = A^{c} \cup B^{c} $$ Description De Morgan&amp;rsquo;s Laws and De Morgan&amp;rsquo;s Theorems refer to propositions and sets, respectively, but in everyday language, they are often</description>
    </item>
    <item>
      <title>Contrapositive and Converse Propositions</title>
      <link>https://freshrimpsushi.github.io/en/posts/1304/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1304/</guid>
      <description>Definition 1 A proposition that is true for all logical possibilities is called a Tautology. A proposition that is false for all logical possibilities is called a Contradiction. For $p$, $q$, if the conditional statement $p \to q$ is a tautology, it is called an Implication and represented as follows: $$ p \implies q $$ For $p$, $q$, if the biconditional statement $p \to q$ is a tautology, it is</description>
    </item>
    <item>
      <title>Eisenstein Integer</title>
      <link>https://freshrimpsushi.github.io/en/posts/1289/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1289/</guid>
      <description>Definition Equation $\mathbb{Z} [ \omega ] := \left\{ a + \omega b : a, b \in \mathbb{Z} \right\}$ is called the Eisenstein Ring, and its elements are referred to as Eisenstein Integers. Theorem [1]: $\overline{ \omega } = \omega^{2} = - (1 + \omega)$ [2]: $( a \pm \omega b ) + ( c \pm \omega d) = (a \pm c) + \omega (b \pm d)$ [3]: $( a +</description>
    </item>
    <item>
      <title>Probability Variables and Probability Distributions Defined by Measure Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/1288/</link>
      <pubDate>Sat, 14 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1288/</guid>
      <description>Definition 1 Let&amp;rsquo;s assume a Probability Space $( \Omega , \mathcal{F} , P)$ is given. A function $X : \Omega \to \mathbb{R}$ that satisfies $X^{-1} (B) \in \mathcal{F}$ for every Borel Set $B \in \mathcal{B} (\mathbb{R})$ is called a Random Variable. $\mathcal{F}_{X}$ defined as follows is called the Sigma Field generated by $X$. $$ \mathcal{F}_{X} := X^{-1} ( \mathcal{B} ) = \sigma (X) = \left\{ X^{-1} (B) \in \Omega :</description>
    </item>
    <item>
      <title>Time Complexity and Space Complexity</title>
      <link>https://freshrimpsushi.github.io/en/posts/1283/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1283/</guid>
      <description>Definition The time it takes to solve a given problem is called time complexity, and the memory requirements are referred to as space complexity. Example Asymptotic notation is a very useful means for expressing these. Let&amp;rsquo;s take a look at an example of time complexity. Constant Time $O(1)$ Algorithms that can finish regardless of $n$, essentially taking no time. For example, finding the third element in $\mathbb{x} = [4,3,8,-1,-9,0,5,7,2,6]$ just</description>
    </item>
    <item>
      <title>Heteroskedasticity and Volatility Clustering in Time Series Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/1272/</link>
      <pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1272/</guid>
      <description>Definition 1 Given a time series data $\left\{ p_{t} \right\}$. When the variance of $\left\{ p_{t} \right\}$ depends on $t$, $\left\{ p_{t} \right\}$ is said to have Heteroscedasticity. The phenomenon of the variance of $\left\{ p_{t} \right\}$, which has Heteroscedasticity, increasing and decreasing repeatedly is referred to as Volatility Clustering. The following defined $r_{t}$ is referred to as (Log) Return in $t$. $$ r_{t} := \nabla \log p_{t} = \log</description>
    </item>
    <item>
      <title>Gaussian Integers</title>
      <link>https://freshrimpsushi.github.io/en/posts/1267/</link>
      <pubDate>Sat, 31 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1267/</guid>
      <description>Definition 1 $\mathbb{Z} [i] := \left\{ a + i b : a, b \in \mathbb{Z} \right\}$ is called a Gaussian Ring, and its elements are called Gaussian Integers. Theorems [1]: $\overline{i} = i^{3}$ [2]: $( a \pm ib ) + ( c \pm id) = (a \pm c) + i (b \pm d)$ [3]: $( a + ib )( c + id) = (ac - bd) + i (ad +</description>
    </item>
    <item>
      <title>Integral Domain Norm</title>
      <link>https://freshrimpsushi.github.io/en/posts/1259/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1259/</guid>
      <description>Definition 1 An multiplicative norm $N : D \to \mathbb{Z}$ on an integral domain $D$ with respect to all $\alpha , \beta \in D$ is defined by the following conditions: (i): $N (\alpha) = 0 \iff \alpha = 0$ (ii): $N ( \alpha \beta ) = N ( \alpha ) N ( \beta )$ Theorem Let $p \in \mathbb{Z}$ be a prime. [1]: If a multiplicative norm $N$ is defined</description>
    </item>
    <item>
      <title>Fourth-order Runge-Kutta method</title>
      <link>https://freshrimpsushi.github.io/en/posts/796/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/796/</guid>
      <description>Method 1 Explanation The Runge-Kutta method, like the Adams method, comes in various forms and determines $\gamma_{j}$ and $V_{j}$ through complex algebraic operations. Among them, the 4th-order Runge-Kutta method, often abbreviated as RK4, is the most popularly used. 4th-order Runge-Kutta method: $$ \begin{align*} y_{n+1} =&amp;amp; y_{n} + {{h} \over {6}} \left[ V_{1} + 2 V_{2} + 2 V_{3} + V_{4} \right] \\ V_{1} =&amp;amp; f(x_{n} , y_{n}) \\ V_{2} =&amp;amp;</description>
    </item>
    <item>
      <title>Cross-Correlation Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/1227/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1227/</guid>
      <description>Definition 1 Let&amp;rsquo;s say $\left\{ X_{t} \right\}_{t=1}^{n}$, $\left\{ Y_{t} \right\}_{t=1}^{n}$ are stochastic processes. The following defined $\rho_{k}$ is called the cross-correlation function at lag $k$. $$ \rho_{k} (X,Y) := \text{cor} \left( X_{t} , Y_{t-k} \right) = \text{cor} \left( X_{t+k} , Y_{t} \right) $$ The following defined $r_{k}$ is called the sample cross-correlation function at lag $k$. $$ r_{k} := {{ \sum \left( X_{t} - \overline{X} \right) \left( Y_{t-k} - \overline{Y}</description>
    </item>
    <item>
      <title>Extended Autocorrelation Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/1213/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1213/</guid>
      <description>Buildup PACF helps in determining the order of $AR(p)$, while ACF is helpful in setting the order for $MA(q)$. However, when applying to $ARMA(p,q)$ model, due to the invertibility of ARMA models, $AR(p)$ may appear as $MA(\infty)$, and $MA(q)$ may appear as $AR(\infty)$. Therefore, various methods have been devised to circumvent these issues and find the ARMA model. Definition The Extended Autocorrelation Function is one such method, defined as EACF</description>
    </item>
    <item>
      <title>Autocorrelation Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/1211/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1211/</guid>
      <description>Definition 1 Let $\left\{ Y_{t} \right\}_{t=1}^{n}$ be a stochastic process, and for lag $k$, let the residuals obtained by regressing $Y_{t}$ on $Y_{t-1}, \cdots , Y_{t-(k-1)}$ be $\widehat{e_{t}}$, and the residuals obtained by regressing $Y_{t-k}$ on $Y_{t-1}, \cdots , Y_{t-(k-1)}$ be $\widehat{e_{t-k}}$. The following defined $\phi_{kk}$ is referred to as the partial autocovariance function at lag $k$. $$ \phi_{kk} := \text{cor} ( \widehat{e_{t}} , \widehat{e_{t-k}} ) $$ The following defined</description>
    </item>
    <item>
      <title>Differentiation of Functions Defined in Real Number Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/1210/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1210/</guid>
      <description>Definition1 If in some $E$ containing $a$, $f$ is defined and the limit $$ f^{\prime} (a) := \lim_{h \to 0} {{ f (a + h ) - f(a) } \over { h }}=\lim \limits_{x\rightarrow a}\frac{f(x)-f(a)}{x-a} $$ exists, then $f$ is said to be differentiable at $a$, and $f^{\prime} (a)$ is called the derivative of $f$ at $a$. If $f$ is differentiable at every point $a \in E$, then $f$ is</description>
    </item>
    <item>
      <title>Autocorrelation Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/1209/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1209/</guid>
      <description>Definition 1 Let&amp;rsquo;s say $\left\{ Y_{t} \right\}_{t=1}^{n}$ is a stochastic process. $\mu_{t} := E ( Y_{t} )$ is called the mean function. The following defined $\gamma_{ t , s }$ is called the autocovariance function. $$ \gamma_{t , s} : = \text{cov} ( Y_{t} , Y_{s} ) = E ( Y_{t} - \mu_{t} ) E ( Y_{s} - \mu_{s} ) $$ The following defined $\rho_{ t , s }$ is</description>
    </item>
    <item>
      <title>Uniform Continuity of Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/1207/</link>
      <pubDate>Sat, 03 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1207/</guid>
      <description>Definition1 Let us assume $E \subset \mathbb{R}$ is a non-empty set and define $f : E \to \mathbb{R}$. If for every $\varepsilon &amp;gt; 0$, $$ | x_{1} - x_{2} | &amp;lt; \delta \land x_{1} , x_{2} \in E \implies | f(x_{1}) - f(x_{2}) | &amp;lt; \varepsilon $$ there exists a $\delta&amp;gt;0$ satisfying the above equation, then $f$ is said to be uniformly continuous on $E$. $\land$ represents the logical &amp;lsquo;and&amp;rsquo;</description>
    </item>
    <item>
      <title>Newly Defined Continuous Functions in University Mathematics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1206/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1206/</guid>
      <description>Definition Let&amp;rsquo;s say a set that is not an empty set is called $E \subset \mathbb{R}$, and $f : E \to \mathbb{R}$. If there exists $\delta&amp;gt;0$ for every $\varepsilon &amp;gt; 0$ such that $$ | x - a | &amp;lt; \delta \implies | f(x) - f(a) | &amp;lt; \varepsilon $$ is satisfied, $f$ is said to be continuous at $a \in E$, and if it is continuous at every point</description>
    </item>
    <item>
      <title>Epsilon-Delta Argument</title>
      <link>https://freshrimpsushi.github.io/en/posts/1204/</link>
      <pubDate>Tue, 30 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1204/</guid>
      <description>Definition1 Let $I$ be an interval containing $a \in \mathbb{R}$, and suppose that $f$ is a function defined at $I \setminus \left\{ a \right\}$. If for every $\epsilon &amp;gt; 0$, there exists a $\delta&amp;gt;0$ such that $$ 0 &amp;lt; | x - a | &amp;lt; \delta \implies | f(x) - L | &amp;lt; \varepsilon $$ is satisfied, then we say that $f(x)$ converges to $L \in \mathbb{R}$ as $x \to</description>
    </item>
    <item>
      <title>Limits Supremum and Limits Infimum</title>
      <link>https://freshrimpsushi.github.io/en/posts/1198/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1198/</guid>
      <description>Definition Let $\left\{ x_{n} \right\}_{n \in \mathbb{N}}$, $\left\{ y_{n} \right\}_{n \in \mathbb{N}}$ be sequences of real numbers. $\displaystyle \limsup_{n \to \infty} x_{n} := \lim_{n \to \infty} \left( \sup_{k \ge n} x_{k} \right)$ is called the limit supremum of $\left\{ x_{n} \right\}$. $\displaystyle \liminf_{n \to \infty} y_{n} := \lim_{n \to \infty} \left( \inf_{k \ge n} y_{k} \right)$ is called the limit infimum of $\left\{ y_{n} \right\}$. Where $\displaystyle \sup_{k \ge n}</description>
    </item>
    <item>
      <title>Multistep Methods</title>
      <link>https://freshrimpsushi.github.io/en/posts/693/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/693/</guid>
      <description>Definition 1 Given a continuous function defined in $D \subset \mathbb{R}^2$ for the initial value problem given in $\begin{cases} y &#39; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) ) = (Y_{0}, \cdots , Y_{p} ) \end{cases}$, let&amp;rsquo;s say we have broken down interval $(a,b)$ into nodes like $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$. Especially for a sufficiently small</description>
    </item>
    <item>
      <title>Strong Lipschitz Condition and Error of the Euler Method</title>
      <link>https://freshrimpsushi.github.io/en/posts/689/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/689/</guid>
      <description>Summary Let&amp;rsquo;s assume that the solution $Y(x)$ to the initial value problem $\begin{cases} y &#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$, defined in $[x_{0} , b] \times \mathbb{R}$ for $f$, is twice differentiable in $[x_{0} , b]$. If $f$ satisfies strong Lipschitz condition $$ |f(x,y_{1} ) - f(x,y_{2}) | \le K | y_{1} - y_{2} | $$ for all $x_{0} \le x \le b$, $ y_{1} ,</description>
    </item>
    <item>
      <title>Euler Method in Numerical Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/687/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/687/</guid>
      <description>Method 1 $D \subset \mathbb{R}^2$ defines a continuous function $f$ for the initial value problem given by $\begin{cases} y &#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$. Suppose the interval $(a,b)$ is divided into nodes like $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$. Particularly for a sufficiently small $h &amp;gt; 0$, if it is assumed that $x_{j} = x_{0} + j</description>
    </item>
    <item>
      <title>Proof of the Pollard p-1 Factoring Algorithm</title>
      <link>https://freshrimpsushi.github.io/en/posts/1187/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1187/</guid>
      <description>Algorithm 1 Given a semiprime $N$, if $p$ is a smooth prime, then the factorization $N = pq$ of $N$ can be found as follows: Step 1. $a := 2$ and $L := 1$ are set. Step 2. $d := \gcd ( a^{L} - 1 , N )$ is calculated. Step 3. If $1&amp;lt; d &amp;lt; N$, then $d = p$, a divisor of $N$, is found and we are</description>
    </item>
    <item>
      <title>Redefining the Limits of Sequences in University Mathematics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1184/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1184/</guid>
      <description>Definitions1 2 $\mathbb{N}$ represents the set of natural numbers, and $\mathbb{R}$ represents the set of real numbers. A function with a domain of $\mathbb{N}$ is called a sequence. For a sequence of natural numbers $\left\{ n_{k} \right\}_{ k \in \mathbb{N}}$, $\left\{ x_{n_{k}} \right\}_{ k \in \mathbb{N}}$ is called a subsequence of $\left\{ x_{n} \right\}_{ n \in \mathbb{N}}$. If for every $x \in \left\{ x_{n} \right\}_{ n \in \mathbb{N}}$ there exists</description>
    </item>
    <item>
      <title>Proof of the RSA Public Key Cryptosystem</title>
      <link>https://freshrimpsushi.github.io/en/posts/1173/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1173/</guid>
      <description>Buildup Let&amp;rsquo;s call them Alice, Bob, and Eve from left to right. Alice and Bob are the parties exchanging messages, and Eve is a passive attacker interested in the message. The orange box represents information only known by Alice, the sky blue box is information only known by Bob, and the black box represents information that is public (also known by Eve). Alice has a message $m \in \mathbb{N}$ she</description>
    </item>
    <item>
      <title>Prime Factorization</title>
      <link>https://freshrimpsushi.github.io/en/posts/775/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/775/</guid>
      <description>Definition For a given natural number $N$, finding prime numbers $p_{1} , \cdots , p_{n}$ and natural numbers $r_{1} , \cdots , r_{n}$ that satisfy $N = p_{1}^{r_{1}} \cdots p_{n}^{r_{n}}$ is called prime factorization.</description>
    </item>
    <item>
      <title>Lipschitz Condition</title>
      <link>https://freshrimpsushi.github.io/en/posts/684/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/684/</guid>
      <description>Definition We can find the Lipschitz condition in the statement of Existence-Uniqueness Theorem for First Order Differential Equations. For a continuous function defined in $D \subset \mathbb{R}^2$ with an initial value problem given by $\begin{cases} y &#39; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$, if $f$ satisfies the Lipschitz condition for all $(x,y_{1}) , (x , y_{2} ) \in D$ and $K &amp;gt; 0$, $$ |f(x,y_{1} ) -</description>
    </item>
    <item>
      <title>Inner Enclosure Boundary in Metric Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/383/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/383/</guid>
      <description>Definition Let&amp;rsquo;s say $\left( X, d \right)$ for a metric space. When there exists an open set $O$ that satisfies $x \in O \subset A$, $x$ is called an Interior Point of $A$. The set of interior points of $A$, $A^{\circ}$, is called the Interior of $A$. The union $\overline{A} : = A \cup a &#39;$ of $A$ and its codomain is called the Closure of $A$. When it</description>
    </item>
    <item>
      <title>The Accumulation Point in the Set of Real Numbers</title>
      <link>https://freshrimpsushi.github.io/en/posts/379/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/379/</guid>
      <description>Definition Given a point $x \in \mathbb{R}$ on the real line and a subset $A \subset \mathbb{R}$, if for any open set $O$ containing $x$, $ O \cap ( A \setminus \left\{ x \right\} ) \ne \emptyset $ holds, then $x$ is defined as a Limit Point. The set of limit points of $A$ is called the Derived set of $A$, and is denoted by $a &#39;$. Explanation In the</description>
    </item>
    <item>
      <title>Uniform Convergence of Function Series</title>
      <link>https://freshrimpsushi.github.io/en/posts/1154/</link>
      <pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1154/</guid>
      <description>Definition Let&amp;rsquo;s define a subset $E \ne \emptyset$ of $\mathbb{R}$, function $f : E \to \mathbb{R}$, and sequence of functions $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$. If there exists $N \in \mathbb{N}$ for every $\varepsilon &amp;gt; 0$ satisfying $n \ge N \implies | f_{n} (x) - f(x) | &amp;lt; \varepsilon$, then sequence $f_{n}$ converges uniformly to $f$ in $E$, denoted by: $$ f_n \rightrightarrows f $$ or $$ f_{n}</description>
    </item>
    <item>
      <title>Pointwise Convergence of Function Sequences</title>
      <link>https://freshrimpsushi.github.io/en/posts/1148/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1148/</guid>
      <description>Definition Let us define a function $f : E \to \mathbb{R}$ for the subset $E \ne \emptyset$ of $\mathbb{R}$. If the sequence of functions $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ satisfies $f(x) = \lim \limits_{n \to \infty} f_{n} (X)$ for each $x \in E$, then it is said to converge pointwise to $f_{n}$ in $E$, denoted by: $$ f_{n} \to f $$ Explanation Rewriting the above definition using the</description>
    </item>
    <item>
      <title>Trapezoidal Rule</title>
      <link>https://freshrimpsushi.github.io/en/posts/1130/</link>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1130/</guid>
      <description>Definition Let&amp;rsquo;s assume $f : [a,b] \to \mathbb{R}$ is integrable over $[a,b]$ and $[a,b]$ is divided into nodes at intervals of $\displaystyle h:= {{b-a} \over {n}}$, like $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$. The numerical integration operator $I_{n}^{1}$, defined as follows, is called the trapezoidal rule. $$ I_{n}^{1} (f) := \displaystyle \sum_{k=1}^{n} {{h} \over {2}} \left( f(x_{k-1}) + f(x_{k} ) \right) $$ Theorem Let&amp;rsquo;s say $f \in</description>
    </item>
    <item>
      <title>Numerical Integration</title>
      <link>https://freshrimpsushi.github.io/en/posts/1128/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1128/</guid>
      <description>Definition 1 Let&amp;rsquo;s assume that $f : [a,b] \to \mathbb{R}$ is integrable over $[a,b]$, and $[a,b]$ is divided into nodes like $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$. The integral operator $I$ is defined as $\displaystyle I(f) := \int_{a}^{b} f(x) dx$. The integral operator $I_{n}$ is defined as $\displaystyle I_{n} (f) := \sum_{k=1}^{n} \int_{x_{k-1}}^{x_{k}} f(x) dx$. The error $E_{n}$ is defined as $E_{n} (f) := I (f) -</description>
    </item>
    <item>
      <title>Proof of the Stone-Weierstrass Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/1117/</link>
      <pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1117/</guid>
      <description>Theorem1 Auxiliary Definitions Let&amp;rsquo;s say $A \subset C(X)$ for $X$. If for any distinct $x_{1}, x_{2} \in X$, there always exists $f \in A$ that satisfies $f(x_{1}) \ne f(x_{2})$, then we say $A$ separates the points of $X$. If $X$ is a metric space and for all $\varepsilon &amp;gt; 0$ and $f \in C(X)$ there exists $g \in A$ that satisfies $| g - f | &amp;lt; \varepsilon$, then $A$</description>
    </item>
    <item>
      <title>Function Approximation in Numerical Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/1107/</link>
      <pubDate>Mon, 10 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1107/</guid>
      <description>Buildup Although it is true that computers are overwhelmingly faster at numerical calculations than humans, it isn&amp;rsquo;t because they understand transcendental functions or irrational numbers. For instance, when asked to calculate $\displaystyle \sin {{ \pi } \over {6}} = {{1} \over { 2 }}$, instead of drawing a right triangle and finding the ratio of the hypotenuse to the height using the geometric definition of trigonometric functions, it uses polynomial</description>
    </item>
    <item>
      <title>Power Series</title>
      <link>https://freshrimpsushi.github.io/en/posts/1090/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1090/</guid>
      <description>Definition A power series is denoted by $S(x) : = \sum \limits_{k=0}^{\infty} a_{k} ( x - x_{0} )^{k}$, and the Center of $S(x)$ is denoted by $x_{0}$. When $S(x)$ converges absolutely for $|x - x_{0}| &amp;lt; R$ and diverges for $|x - x_{0}| &amp;gt; R$, $R$ is called the Radius of Convergence of $S(x)$. The largest interval on which $S(x)$ converges is called the Interval of Convergence. If there exists</description>
    </item>
    <item>
      <title>Seasonal ARIMA Model</title>
      <link>https://freshrimpsushi.github.io/en/posts/1067/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1067/</guid>
      <description>Model 1 An operator defined as $\nabla_{s} Y_{t} := Y_{t} - Y_{t-s}$ is called the Seasonal Difference. If $W_{t} := \nabla^{d} \nabla_{s}^{D} Y_{t}$ is defined as $\left\{ W_{t} \right\}_{t \in \mathbb{N}}$, and if $ARMA(P,Q)$ and $\left\{ Y_{t} \right\}_{t \in \mathbb{N}}$ is $ARMA(p,q)$, then $\left\{ Y_{t} \right\}_{t \in \mathbb{N}}$ is called a Seasonal ARIMA process $ARIMA(p,d,q)\times(P,D,Q)_{s}$. This form is called the Seasonal ARIMA model. Explanation Today&amp;rsquo;s temperature is, of course, mostly</description>
    </item>
    <item>
      <title>Derivation of Newton&#39;s Forward Difference Formula</title>
      <link>https://freshrimpsushi.github.io/en/posts/1025/</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1025/</guid>
      <description>Formulas For different data $x_{0} , \cdots , x_{n}$ of $(x_{0}, f(x_{0} )) , \cdots , (x_{n} , f( x_{n} ) )$, $$ p_{n} (x) =\sum_{i=0}^{n} f [ x_{0} , \cdots , x_{i} ] \prod_{j=0}^{i-1} (x - x_{j} ) $$ Description Though it seems complicated, when actually expanding for $n=0,1,2$, it simplifies as follows. $$ \begin{align*} p_{0} (x) =&amp;amp; f(x_{0}) \\ p_{1} (x) =&amp;amp; f( x_{0} ) + (x -</description>
    </item>
    <item>
      <title>Lagrange&#39;s Formula Derivation</title>
      <link>https://freshrimpsushi.github.io/en/posts/1023/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1023/</guid>
      <description>Formula 1 Given different $x_{0} , \cdots , x_{n}$ data $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$, let&amp;rsquo;s say $\displaystyle l_{i} (x) := \prod_{i \ne j} \left( {{ x - x_{j} } \over { x_{i} - x_{j} }} \right)$, then $$ p_{n} (x) = \sum_{i=0}^{n} y_{i} l_{i} (X) $$ Description Lagrange&amp;rsquo;s formula is the simplest method among those to find polynomial interpolation. Derivation Strategy: Prove that $l_{i}$ is the</description>
    </item>
    <item>
      <title>Polynomial Interpolation</title>
      <link>https://freshrimpsushi.github.io/en/posts/1021/</link>
      <pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1021/</guid>
      <description>Definition 1 For different $x_{0} , \cdots , x_{n}$ data $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$, a polynomial function $p$ that satisfies $p (x_{i} ) = y_{i}$ and $\deg p \le n$ is called Polynomial Interpolation. Theorem Existence and Uniqueness [1]: For the given data, there exists a unique $p$. Lagrange&amp;rsquo;s Formula [2]: $$p_{n} (x) = \sum_{i=0}^{n} y_{i} l_{i} (X)$$ Newton&amp;rsquo;s Divided Difference Formula [3]: $$p_{n} (x) =</description>
    </item>
    <item>
      <title>Interpolation in Numerical Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/1016/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1016/</guid>
      <description>Definition 1 For a given pair of data $(n+1)$ and $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$, the method or the function itself that satisfies $f (x_{i} ) = y_{i}$ while possessing some specific property is called interpolation. Description For example, consider the situation where there&amp;rsquo;s data available as shown above, but the middle part is missing. Of course, it&amp;rsquo;s best to have actual data, but if not, there</description>
    </item>
    <item>
      <title>Gradient Descent in Mathematics</title>
      <link>https://freshrimpsushi.github.io/en/posts/1012/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1012/</guid>
      <description>Definition 1 A scalar function $\varphi : \mathbb{R}^{n} \to \mathbb{R}$ is called a Cost Function. An algorithm that finds $\mathbb{x}_{n+1}$ that satisfies $\varphi ( \mathbb{x}_{n+1} ) &amp;lt; \varphi ( \mathbb{x}_{n} )$ in $\mathbb{x} = \mathbb{x}_{n}$ to minimize the cost function $ \varphi ( \mathbb{x} )$ is called the Descent Method. Explanation Let’s consider building a house as an example for a cost function, $\varphi$. The resources</description>
    </item>
    <item>
      <title>Gradient of Scalar Field</title>
      <link>https://freshrimpsushi.github.io/en/posts/1010/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1010/</guid>
      <description>Definition A gradient, specifically referred to as the total derivative of a scalar field $f : \mathbb{R}^{n} \to \mathbb{R}$, is denoted by $\nabla f$. $$ \begin{align*} \nabla f := f^{\prime} =&amp;amp; \begin{bmatrix} D_{1}f &amp;amp; D_{2}f &amp;amp; \cdots &amp;amp; D_{n}f\end{bmatrix} \\ =&amp;amp; \begin{bmatrix} \dfrac{\partial f}{\partial x_{1}} &amp;amp; \dfrac{\partial f}{\partial x_{2}} &amp;amp; \cdots &amp;amp; \dfrac{\partial f}{\partial x_{n}} \end{bmatrix} \\ =&amp;amp; \dfrac{\partial f}{\partial x_{1}}\hat{x}_{1} + \dfrac{\partial f}{\partial x_{2}}\hat{x}_{2} + \dots + \dfrac{\partial f}{\partial</description>
    </item>
    <item>
      <title>What is a Hessian Matrix?</title>
      <link>https://freshrimpsushi.github.io/en/posts/992/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/992/</guid>
      <description>Definition $D \subset \mathbb{R}^{n}$ is defined as the matrix $H \in \mathbb{R}^{n \times n}$ for a multivariate scalar function $f : D \to \mathbb{R}$ is called the Hessian matrix of $f$. $$ H := \begin{bmatrix} {{\partial^2 f } \over {\partial x_{1}^2 }} &amp;amp; \cdots &amp;amp; {{\partial^2 f } \over { \partial x_{1} \partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial^2 f } \over {\partial x_{n} \partial x_{1}</description>
    </item>
    <item>
      <title>Activation Functions in Deep Learning</title>
      <link>https://freshrimpsushi.github.io/en/posts/991/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/991/</guid>
      <description>Definition An non-linear function that mimics the threshold of real-life organisms is known as an activation function. Mathematical Definition In deep learning, a non-linear scalar function $\sigma : \mathbb{R}^{n} \to \mathbb{R}$ is referred to as an activation function. Of course, there are exceptions like the softmax which don&amp;rsquo;t fit into this definition. Explanation On the other hand, a vector function is called a layer. If there is an expression or</description>
    </item>
    <item>
      <title>Jacobian Matrix or Jacobi Matrix</title>
      <link>https://freshrimpsushi.github.io/en/posts/989/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/989/</guid>
      <description>Definition Let a multivariable vector function $\mathbb{f} : D \to \mathbb{R}^{m}$ defined by $D \subset \mathbb{R}^{n}$ be defined for each scalar function $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ as follows: $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ It is called the</description>
    </item>
    <item>
      <title>What is Deep Learning?</title>
      <link>https://freshrimpsushi.github.io/en/posts/996/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/996/</guid>
      <description>Definition Deep learning is a type of machine learning that uses artificial neural networks, especially employing multiple layers when constructing these networks. Motivation Just like the human brain is composed of a complex network of neurons, deep learning also enhances performance by making the connections in artificial neural networks more complex. Similar to how the stimuli received by sensory cells are transmitted to the brain through the spinal cord, artificial</description>
    </item>
    <item>
      <title>Gradient Descent and Stochastic Gradient Descent in Machine Learning</title>
      <link>https://freshrimpsushi.github.io/en/posts/987/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/987/</guid>
      <description>Overview The Gradient Descent Algorithm is the simplest method among algorithms that find the local minimum of the loss function by using the gradient of the loss function. Description Here, the loss function $L$ is considered a function of weights and biases with the dataset $X$ being fixed. If the input data looks like $\mathbb{x} \in \mathbb{R}^{m}$, then $L$ becomes a function of $(w_{1} , w_{2} , \cdots , w_{m}</description>
    </item>
    <item>
      <title>Scalar Functions and Vector-valued Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/970/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/970/</guid>
      <description>Definition Let $D$ be a subset $D\subset \mathbb{R}^{n}$ of the $n$-dimensional Euclidean space. Functions having $D$ as their domain are called function of several variables. $f : D \to \mathbb{R}$ is called a scalar function. For a scalar function $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$, $\mathbb{f} : D \to \mathbb{R}^{m}$ defined as follows is called a vector-valued function. $$ \mathbb{f} ( x_{1} , \cdots , x_{n} )</description>
    </item>
    <item>
      <title>Loss Functions in Machine Learning</title>
      <link>https://freshrimpsushi.github.io/en/posts/967/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/967/</guid>
      <description>Definition When an estimate for the data $Y = \begin{bmatrix} y_{1} \\ \vdots \\ y_{n} \end{bmatrix}$ is given as $\widehat{Y} = \begin{bmatrix} \widehat{ y_{1} } \\ \vdots \\ \widehat{y_{n}} \end{bmatrix}$, the scalar function $L : \mathbb{R}^{n} \to [ 0 , \infty )$ that represents the discrepancy between the data and its estimate is called a loss function. Alternate Names The loss function is used as an indicator to evaluate how</description>
    </item>
    <item>
      <title>Graphs and Networks in Mathematics</title>
      <link>https://freshrimpsushi.github.io/en/posts/966/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/966/</guid>
      <description>Definitions 1 A set comprising vertices and lines connecting vertices is called a graph or a network. Let&amp;rsquo;s denote the set of vertices as $V$ and the set of lines as $E$. Elements of $V(G) := V$ are called vertices or nodes of $G$. Elements of $E(G) := E$ are called edges or links of $G$. An edge that connects to the same vertex is called a loop. If two</description>
    </item>
    <item>
      <title>What is an Artificial Neural Network?</title>
      <link>https://freshrimpsushi.github.io/en/posts/962/</link>
      <pubDate>Sat, 06 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/962/</guid>
      <description>Definition An artificial neural network (ANN) is a network mimicking the nervous system of actual organisms. Mathematical Definition In deep learning, a vector function $W : \mathbb{R}^{n} \to \mathbb{R}^{m}$ is referred to as a layer. In deep learning, a nonlinear scalar function $\sigma : \mathbb{R} \to \mathbb{R}$ is referred to as an activation function. The composition $\sigma \circ W$ of layers and activation functions is called an artificial neural network.</description>
    </item>
    <item>
      <title>Chaos in One-Dimensional Maps</title>
      <link>https://freshrimpsushi.github.io/en/posts/864/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/864/</guid>
      <description>Definition Chaotic Orbit1 An orbit of map $f : \mathbb{R} \to \mathbb{R}$ is said to be chaotic if it satisfies the following conditions: (i) It is not asymptotically periodic. (ii): $h (x_{1} ) &amp;gt; 0$ A bounded orbit is an $M \in \mathbb{R}$ for which there exists a $|x_{n} | &amp;lt; M$ that satisfies all $n \in \mathbb{N}$. $h(x_{1} )$ refers to the Lyapunov exponent. Chaotic Map A map $f$</description>
    </item>
    <item>
      <title>Wiener Process</title>
      <link>https://freshrimpsushi.github.io/en/posts/957/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/957/</guid>
      <description>Definition When $s&amp;lt; t &amp;lt; t+u$, a stochastic process $\left\{ W_{t} \right\}$ that satisfies the following conditions is called a Wiener Process: (i): $W_{0} = 0$ (ii): $\left( W_{t+u} - W_{t} \right) \perp W_{s}$ (iii): $\left( W_{t+u} - W_{t} \right) \sim N ( 0, u )$ (iv): The sample paths of $W_{t}$ are almost surely continuous. Basic Properties [1]: $\displaystyle W_{t} \sim N ( 0 , t )$ [2]: $\displaystyle</description>
    </item>
    <item>
      <title>Map System&#39;s Orbit</title>
      <link>https://freshrimpsushi.github.io/en/posts/858/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/858/</guid>
      <description>Definition1 Let the smallest natural number satisfying $f^{k} (p) = p$ for maps $f : X \to X$ and $p \in X$ be $k \in \mathbb{N}$. For map $f : X \to X$ and point $x \in X$, the set $\left\{ x , f(x) , f^{2} , \cdots \right\}$ under $f$ is called the orbit of $x$. Here, $x$ is called the initial value of the orbit. An orbit $\left\{</description>
    </item>
    <item>
      <title>Harke-Bera Test</title>
      <link>https://freshrimpsushi.github.io/en/posts/949/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/949/</guid>
      <description>Hypothesis Testing Given that we have quantitative data $\left\{ x_{i} \right\}_{i = 1}^{n}$. $H_{0}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ follows a normal distribution. $H_{1}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ does not follow a normal distribution. Explanation The Jarque-Bera test is used to test for normality as a hypothesis test, typically to demonstrate the presence of normality. This is one of the rare cases where the acceptance of the</description>
    </item>
    <item>
      <title>Discrete Logarithm Problems Solved Easily Under Certain Conditions</title>
      <link>https://freshrimpsushi.github.io/en/posts/942/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/942/</guid>
      <description>Review 1 Assume element $g$ of group $G = F_{p}$ has an order of $N$. Then, the Discrete Logarithm problem $g^{x} = h$ becomes relatively easy to solve under the following conditions: (i): $p$ is a smooth prime number. (ii): $p \equiv 3 \pmod{4}$ and $a$ are quadratic residues modulo $p$. Proof (i) If $p$ is a smooth prime, the Pohlig-Hellman algorithm can be used, so the Discrete Logarithm problem</description>
    </item>
    <item>
      <title>Arima Model</title>
      <link>https://freshrimpsushi.github.io/en/posts/941/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/941/</guid>
      <description>Model 1 For the given white noise $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$, it is defined as $$ \nabla^{d} Y_{t} := \sum_{i = 1}^{p} \phi_{i} \nabla^{d} Y_{t-i} + e_{t} - \sum_{i = 1}^{q} \theta_{i} e_{t-i} $$ and this form is referred to as the $(p,d,q)$th ARIMA process $ARIMA (p,d,q)$. Such a form of time series analysis model is called ARIMA model. Explanation $ARI(p,d) \iff ARIMA(p,d,0)$ is referred to as AR model,</description>
    </item>
    <item>
      <title>Differential Stages in Numerical Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/969/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/969/</guid>
      <description>Definition A Divided Difference of a function $f : \mathbb{R} \to \mathbb{R}$ for distinct $x_{1} , \cdots , x_{n}$ is defined as follows: $$ \begin{align*} f[x_{0}] :=&amp;amp; f( x_{0} ) \\ f [ x_{0} , x_{1} ] :=&amp;amp; {{ f ( x_{1} ) - f ( x_{0} ) } \over { x_{1} - x_{0} }} \\ f [ x_{0} , x_{1} , x_{2} ] :=&amp;amp; {{ f [ x_{1} ,</description>
    </item>
    <item>
      <title>Proof of Pollard&#39;s Rho Algorithm</title>
      <link>https://freshrimpsushi.github.io/en/posts/940/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/940/</guid>
      <description>Algorithm Let&amp;rsquo;s say that an element $g$ of a group $G$ has order $N = q_{1}^{r_{1}} q_{2}^{r_{2}} \cdots q_{t}^{r_{t}}$. Then, the discrete logarithm problem $g^{x} = h$ can be solved in no more than $\displaystyle O \left( \sum_{i=1}^{t} S_{q_{i}^{r_{i}}} + \log N \right)$ steps according to the following algorithm. Step 1. Compute $\displaystyle g_{i} : = g^{N / q_{i}^{r_{i}}}$ and $\displaystyle h_{i} := h^{N / q_{i}^{r_{i}}}$. Step 2. Find the</description>
    </item>
    <item>
      <title>Shapiro-Wilk Test</title>
      <link>https://freshrimpsushi.github.io/en/posts/939/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/939/</guid>
      <description>Hypothesis Testing Given quantitative data $\left\{ x_{i} \right\}_{i = 1}^{n}$. $H_{0}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ follows a normal distribution. $H_{1}$: Data $\left\{ x_{i} \right\}_{i = 1}^{n}$ does not follow a normal distribution. Description The Shapiro-Wilk test is a hypothesis test used to assess the normality of data, usually to demonstrate that normality is present. It&amp;rsquo;s one of the rare occasions where having the null hypothesis accepted matches &amp;rsquo;the</description>
    </item>
    <item>
      <title>Transformation in Time Series Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/938/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/938/</guid>
      <description>Buildup The reason why transformations are necessary in time series is to give a &amp;ldquo;penalty&amp;rdquo; for increasing variance over time, to keep the variance constant, and to achieve stationarity. The square root $\sqrt{}$ and log $\log$ are often used because the amount reduced is greater for larger values. Of course, when variance decreases, it means that the trend of data converges to some point, thus no time series analysis is</description>
    </item>
    <item>
      <title>Smooth Primes</title>
      <link>https://freshrimpsushi.github.io/en/posts/927/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/927/</guid>
      <description>Definitions A prime number $p$ that has many divisors is called a smooth prime if $(p-1)$. A number that can be represented as a product of prime numbers less than or equal to $B$ is called a $B$-smooth number. $\psi ( X , B )$ represents the number of $B$-smooth numbers less than or equal to $X$. Description As an example of a smooth prime, consider $p=37$ where $(p-1)$ is</description>
    </item>
    <item>
      <title>Shor&#39;s Algorithm Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/917/</link>
      <pubDate>Tue, 19 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/917/</guid>
      <description>Algorithm 1 Let us say the element $g$ of the group $G$, with an identity element of $e$, has an order of $N$. Then, the discrete logarithm problem $g^{x} = h$ can be solved in at most $O \left( \sqrt{N} \log N \right)$ steps according to the following algorithm. Step 1. $n: = 1 + \lfloor \sqrt{N} \rfloor $ Step 2. Create two lists $A := \left\{ e , g</description>
    </item>
    <item>
      <title>Differencing in Time Series Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/916/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/916/</guid>
      <description>Definition 1 Define operator $B$ as $B Y_{t} = Y_{t-1}$, referred to as Backshift. Define operator $\nabla$ as $\nabla := 1 - B$ and $\nabla^{r+1} = \nabla \left( \nabla^{r} Y_{t} \right)$, referred to as Differencing. Explanation According to the definition of differencing, the $1$th difference is calculated as $$ \nabla Y_{t} = Y_{t} - Y_{t-1} $$, and the $2$th difference is calculated as $$ \begin{align*} \nabla^2 Y_{t} =&amp;amp; \nabla \left(</description>
    </item>
    <item>
      <title>ElGamal Public Key Cryptosystem Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/915/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/915/</guid>
      <description>Buildup From left to right, let&amp;rsquo;s name them Alice, Bob, and Eve. Alice and Bob are the parties exchanging messages, and Eve is a passive attacker interested in the message. The orange box represents information known only to Alice, the sky-blue box represents information known only to Bob, and the black box represents public information (also known to Eve). Alice has a message $m \in \mathbb{N}$ to receive from Bob.</description>
    </item>
    <item>
      <title>Autoregressive Moving Average Model</title>
      <link>https://freshrimpsushi.github.io/en/posts/914/</link>
      <pubDate>Sat, 16 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/914/</guid>
      <description>Model 1 White noise $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ is defined as $$ Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} +e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q} $$ such a process is called a $(p,q)$th order autoregressive moving average process $ARMA(p,q)$. Explanation The ARMA model is simply a combination of the Moving Average Process and the Autoregressive Process. For instance,</description>
    </item>
    <item>
      <title>Autoregressive Process</title>
      <link>https://freshrimpsushi.github.io/en/posts/910/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/910/</guid>
      <description>Model 1 White noise $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ is defined as in $Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} + e_{t}$ and is called an $p$th order autoregressive process $AR(p)$. (1): $AR(1) : Y_{t} = \phi Y_{t-1} + e_{t}$ (2): $AR(2) : Y_{t} = \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + e_{t}$ (p): $AR(p) : Y_{t} = \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots +</description>
    </item>
    <item>
      <title>Discrete Logarithms</title>
      <link>https://freshrimpsushi.github.io/en/posts/911/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/911/</guid>
      <description>Definition 1 Let&amp;rsquo;s say that for a prime number $p$, the identity element in the Galois Field $\mathbb{F}_{p} := \mathbb{Z} / p \mathbb{Z}$ is $0$. Then, for a primitive root $g \ne 0$ of $\mathbb{F}_{p}$, a function $\log_{g} : \mathbb{F}_{p}^{ \ast } \to \mathbb{Z} / (p-1) \mathbb{Z}$ defined on a cyclic group $\mathbb{F}_{p} ^{ \ast } := \mathbb{F}_{p} \setminus \left\{ 0 \right\} = \left&amp;lt; g \right&amp;gt;$ that satisfies the following</description>
    </item>
    <item>
      <title>Moving Average Process</title>
      <link>https://freshrimpsushi.github.io/en/posts/909/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/909/</guid>
      <description>Model 1 The process defined as follows for white noise $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ and according to $Y_{t} := e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q}$, is called the $q$th order moving average process $MA(q)$. (1): $MA(1) : Y_{t} = e_{t} - \theta e_{t-1}$ (2): $MA(2) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2}$ (q): $MA(q) : Y_{t} = e_{t} - \theta_{1}</description>
    </item>
    <item>
      <title>Encryption and Decryption in Cryptography</title>
      <link>https://freshrimpsushi.github.io/en/posts/908/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/908/</guid>
      <description>Buildup Let&amp;rsquo;s imagine that Alice wants to convey a message to Bob. If there were only two people in the world, this message would be shared exclusively between them, with no reason to hide it. [ NOTE: In cryptography, Alice and Bob are names commonly used to represent $A$ and $B$, respectively. ] However, suppose there is a third person, Eve. Eve might not necessarily have bad intentions, but she</description>
    </item>
    <item>
      <title>Stability in Time Series Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/907/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/907/</guid>
      <description>Definition 1 Time series data is said to have stationarity when its mean and variance are constant over time. Description It&amp;rsquo;s not normal正常 as in standard, but stationarity定常. The fact that data is stationary means that its mean and variance are stabilized, making it easier to analyze. If the</description>
    </item>
    <item>
      <title>Time Series Analysis: White Noise</title>
      <link>https://freshrimpsushi.github.io/en/posts/904/</link>
      <pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/904/</guid>
      <description>Definition 1 A sequence $\left\{ e_{t} \right\}_{t = 1}^{\infty}$ of independent identically distributed (iid) random variables $e_{t}$ is called White Noise. iid stands for independent identically distributed, meaning that they are independent from each other and share the same distribution. Description Following the definition of a sequence of random variables, it is naturally a stochastic process. Particularly, if $E ( e_{t} ) = 0$, then the stochastic process $\left\{ Y_{t}</description>
    </item>
    <item>
      <title>Time Series Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/900/</link>
      <pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/900/</guid>
      <description>Description Time Series can be simply seen as a stochastic process obtained from real data. The stock index is a good example of a time series as its value changes with uncertainty over time. Time series analysis aims to understand and predict the movement of a dependent variable over time. The biggest difference between time series analysis and regression analysis is that, while regression analysis assumes that the independent variables</description>
    </item>
    <item>
      <title>Generalized Random Walk</title>
      <link>https://freshrimpsushi.github.io/en/posts/870/</link>
      <pubDate>Thu, 21 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/870/</guid>
      <description>Definition A stochastic process $\left\{ X_{n} \right\}$ whose state space is the set of integers $\left\{ \cdots , -2 , -1, 0 , 1 , 2 , \cdots \right\}$ and starts from state $0$ is referred to as a generalized random walk if the probability of decreasing by $1$ in the next step is $p$, and the probability of increasing by $1$ is $(1-p)$. Explanation A random walk, which is</description>
    </item>
    <item>
      <title>Galois Field</title>
      <link>https://freshrimpsushi.github.io/en/posts/820/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/820/</guid>
      <description>Theorem 1 For a prime number $p$ and a natural number $n$, a finite field with cardinality $p^{n}$ is defined as the Galois Field of order $p^{n}$, denoted as $\text{GF} \left( p^{n} \right)$. Finite fields are exclusively Galois Fields, and for a given $p$ and $n$, the Galois Field is uniquely determined. The uniqueness implies that even if there are different fields, an isomorphism exists, making them essentially the same</description>
    </item>
    <item>
      <title>Discrete Markov Chains</title>
      <link>https://freshrimpsushi.github.io/en/posts/859/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/859/</guid>
      <description>Definition A discrete-time Markov chain (DTMC), or simply a Markov Chain, is a discrete stochastic process $\left\{ X_{n} \right\}$ satisfying the following, provided the state space is a countable set: $$ p \left( X_{n+1} = j \mid X_{n} = i , X_{n-1} = k , \cdots , X_{0} = l \right) = p \left( X_{n+1} = j \mid X_{n} = i \right) $$ See Also Continuous Markov Chain Description $p_{ij}:=</description>
    </item>
    <item>
      <title>What is a Stochastic Process?</title>
      <link>https://freshrimpsushi.github.io/en/posts/857/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/857/</guid>
      <description>Definition The range of the random variable $X: \Omega \to E$ is called the state space. The set of random variables $\left\{ X_{t} \mid t \in [ 0 , \infty ) \right\}$ is called a continuous stochastic process. The sequence of random variables $\left\{ X_{n} \mid n = 0, 1, 2, \cdots \right\}$ is called a discrete stochastic process. Explanation The term &amp;lsquo;process&amp;rsquo; in stochastic process often makes the concept</description>
    </item>
    <item>
      <title>Representing Dynamical Systems and Fixed Points with Maps</title>
      <link>https://freshrimpsushi.github.io/en/posts/856/</link>
      <pubDate>Sat, 09 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/856/</guid>
      <description>Definitions1 A function $f : X \to X$ whose domain and codomain are the same is called a Map. A map that is the composition of $f$ $k$ times is denoted as $f^{k}$. $p \in X$ that satisfies $f(p) = p$ is called a Fixed Point. If there exists a $\epsilon &amp;gt; 0$ that satisfies $\displaystyle \lim_{k \to \infty} f^{k} (x) = p$ for all $x \in N_{ \epsilon }</description>
    </item>
    <item>
      <title>Hosmer-Lemeshow Goodness of Fit Test</title>
      <link>https://freshrimpsushi.github.io/en/posts/852/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/852/</guid>
      <description>Hypothesis Testing Let&amp;rsquo;s refer to the model obtained through logistic regression as $M$. $H_{0}$: $M$ is appropriate. $H_{1}$: $M$ is not appropriate. Description The Hosmer-Lemeshow goodness of fit test is a representative hypothesis test used to determine the adequacy of logistic regression models. Although it&amp;rsquo;s a very simple test, the null hypothesis and the alternative hypothesis can be confusing. While it’s true that there is no good</description>
    </item>
    <item>
      <title>Euclidean Geometry</title>
      <link>https://freshrimpsushi.github.io/en/posts/838/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/838/</guid>
      <description>Definitions 1 In an integral domain $D$, if there exists a Euclidean norm $\nu : D \setminus \left\{ 0 \right\} \to \mathbb{N}_{0}$ that satisfies the following two conditions, then $D$ is called a Euclidean domain: (i): For all $a,b \in D (b \ne 0 )$, there exists $q$ and $r$ such that $$ a = bq + r $$ is satisfied. In this case, either $r = 0$ or $\nu</description>
    </item>
    <item>
      <title>Logistic Regression</title>
      <link>https://freshrimpsushi.github.io/en/posts/832/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/832/</guid>
      <description>Buildup Let&amp;rsquo;s think about performing $Y \gets X_{1} , \cdots, X_{p}$. Here, $Y$ can be a categorical variable, particularly one with only two classes, such as male and female, success and failure, positive and negative, $0$ and $1$, etc. For convenience, let&amp;rsquo;s just call it $Y=0$ or $Y=1$. In cases where the dependent variable is binary, the interest is &amp;lsquo;what is $Y$ when we look at independent variables $ X_{1}</description>
    </item>
    <item>
      <title>Unique Factorization Domain</title>
      <link>https://freshrimpsushi.github.io/en/posts/827/</link>
      <pubDate>Wed, 30 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/827/</guid>
      <description>Definitions 1 A domain $D$, that is neither $0$ nor a field, in which every element (except for 0 and units) has a unique factorization into irreducible elements is said to be a Unique Factorization Domain. In a Unique Factorization Domain $D$, for $a_{1} , \cdots , a_{n}$ if $d \mid a_{i}$ and every divisor of $a_{i}$ divides $d$, then $d$ is called the Greatest Common Divisor of $a_{1} ,</description>
    </item>
    <item>
      <title>Variable Selection Criteria in Statistical Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/826/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/826/</guid>
      <description>Overview The problem of variable selection inevitably involves the subjectivity of the analyst, but a numerical indicator that helps draw as objective a conclusion as possible was needed. If such values could be calculated, it would provide a clear answer to when to stop the variable selection procedure. However, there are various types of criteria, and applying different criteria can lead to different results. Indicators [^1] Explained Variance $R^2$ The</description>
    </item>
    <item>
      <title>Principal Ideal Domain</title>
      <link>https://freshrimpsushi.github.io/en/posts/825/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/825/</guid>
      <description>Definition 1 Let&amp;rsquo;s assume that the $p \ne 0$ of the integral domain $D$ is not a field. PID An integral domain $D$ is called a Principal Ideal Domain (PID) if every ideal in $D$ is a principal ideal. Consequent Definitions Let&amp;rsquo;s say a commutative ring $R$ has a unity $1$. If for $a,b \in R$ there exists $c \in R$ that satisfies $b=ac$, then $a$ divides $b$ or $a$</description>
    </item>
    <item>
      <title>Brain Ventricular Enlargement</title>
      <link>https://freshrimpsushi.github.io/en/posts/823/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/823/</guid>
      <description>Definition $N$ is referred to as a ring. When the ideals of $N$ satisfy $S_{1} \le S_{2} \le \cdots$, it is called an Ascending Chain. For the ascending chain $\left\{ S_{i} \right\}_{i \in \mathbb{N} }$, if there exists $n \in \mathbb{n}$ that satisfies $S_{n} = S_{n+1} = \cdots$, it is said to be Stationary. In other words, in a stationary ascending chain, the ideal does not increase any further from</description>
    </item>
    <item>
      <title>Principal Component Analysis in Statistics</title>
      <link>https://freshrimpsushi.github.io/en/posts/812/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/812/</guid>
      <description>Overview Think about performing Multiple Regression Analysis $Y \gets X_{1} , \cdots, X_{p}$. Principal Component Analysis, abbreviated as PCA in English, is, in simple terms, a method of &amp;lsquo;restructuring&amp;rsquo; quantitative variables so that they are properly independent for analysis. From the perspective of multivariate data analysis, it has the significance of &amp;lsquo;dimension reduction&amp;rsquo; as a means to explain phenomena with fewer variables. To properly understand the theoretical derivation of principal</description>
    </item>
    <item>
      <title>Multicollinearity</title>
      <link>https://freshrimpsushi.github.io/en/posts/808/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/808/</guid>
      <description>Definition 1 Consider performing multiple regression analysis $Y \gets X_{1} , \cdots, X_{p}$. If among the independent variables $ X_{1} , \cdots, X_{p}$ there is a strong correlation between the independent variables, then it is said that there is multicollinearity. Practice Initially, the very idea that independent variables are dependent violates the assumptions of regression analysis and indeed leads to numerical problems that make the analysis results unreliable. It can</description>
    </item>
    <item>
      <title>Vector Spaces in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/806/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/806/</guid>
      <description>Definition 1 A field $F$ and an abelian group $V$ are said to form a vector space over $F$ if all elements $\alpha , \beta \in F$ and $x, y \in V$ satisfy the following conditions. Elements of $F$ are called scalars, and elements of $V$ are called vectors. (i): $\alpha x \in V$ (ii): $\alpha ( \beta x) = ( \alpha \beta ) x$ (iii): $\alpha (x + y)</description>
    </item>
    <item>
      <title>Quadratic Residues and Non-Quadratic Residues</title>
      <link>https://freshrimpsushi.github.io/en/posts/137/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/137/</guid>
      <description>Definition 1 For primes $p \ne 2$ and $a &amp;lt; p$, if there exists a solution to the congruence equation $x^{2} \equiv a \pmod{p}$, then $a$ is called a Quadratic Residue QR modulo $p$. If $a$ is not a quadratic residue, it is called a Non-Quadratic Residue NR. Explanation Simply put, a quadratic residue is a number for which a square root exists in $\pmod{p}$. For example, consider the prime</description>
    </item>
    <item>
      <title>Algebraic Numbers and Transcendental Numbers</title>
      <link>https://freshrimpsushi.github.io/en/posts/799/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/799/</guid>
      <description>Definition 1 Let&amp;rsquo;s call the field extension of field $F$ as $E$. For a non-constant function $f(x) \in F [ x ]$, if it satisfies $f( \alpha ) = 0$ for $\alpha \in E$, it is called algebraic over $F$, and if not, it is called transcendental. When $F = \mathbb{Q}$, $E = \mathbb{C}$, if $\alpha \in \mathbb{C}$ is algebraic, it is called an algebraic number, and if transcendental, a</description>
    </item>
    <item>
      <title>Orders in Number Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/798/</link>
      <pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/798/</guid>
      <description>Definition 1 Theorem If $a^{n} \equiv 1 \pmod{p}$, then $\text{ord}_{p} (a) \mid n$. Explanation For example, consider $p=7$. $$ \begin{align*} 1^{1} \equiv &amp;amp; 1 \pmod{ 7 } \\ 2^{3} \equiv &amp;amp; 1 \pmod{ 7 } \\ 3^{6} \equiv &amp;amp; 1 \pmod{ 7 } \\ 4^{3} \equiv &amp;amp; 1 \pmod{ 7 } \\ 5^{6} \equiv &amp;amp; 1 \pmod{ 7 } \\ 6^{2} \equiv &amp;amp; 1 \pmod{ 7 } \end{align*} $$ Here,</description>
    </item>
    <item>
      <title>Definition and Proof of Kronecker&#39;s Theorem for Extension Bodies</title>
      <link>https://freshrimpsushi.github.io/en/posts/797/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/797/</guid>
      <description>Definition of Extension Field 1 For a field $F$, if there exists $E$ such that $F \le E$, then $E$ is called the Extension Field of $F$. Kronecker&amp;rsquo;s Theorem Assuming $f(x) \in F [ x ]$ is not a constant, there exists an extension field $E$ of $F$ and $\alpha \in E$ such that $f ( \alpha ) = 0$. Description An example of an extension field is that $\mathbb{C}$</description>
    </item>
    <item>
      <title>Carmichael Numbers</title>
      <link>https://freshrimpsushi.github.io/en/posts/794/</link>
      <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/794/</guid>
      <description>Definition 1 An integer $n$ is called a Carmichael number if for all $1 \le a \le n$, it satisfies $a^{n} \equiv a \pmod{n}$. Theorem Every Carmichael number is a product of distinct primes, except for $2$. Description Carmichael numbers are composite numbers that pass the Fermat&amp;rsquo;s Little Theorem, meaning they appear to be prime. For example, $561=3 \cdot 11 \cdot 17$ is a composite number, but $a^{561} \equiv a</description>
    </item>
    <item>
      <title>Proof of Liouville&#39;s Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/786/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/786/</guid>
      <description>Theorem[^1] Let $\left( H, \left\langle \cdot,\cdot \right\rangle \right)$ be a Hilbert space. For linear functionals $f \in H^{ \ast }$ and $\mathbf{x} \in H$ satisfying $f ( \mathbf{x} ) = \left\langle \mathbf{x} , \mathbf{w} \right\rangle$ and $\| f \|_{H^{\ast}} = \| \mathbf{w} \|_{H}$, there exists a unique $\mathbf{w} \in H$.</description>
    </item>
    <item>
      <title>Second Kind Chebyshev Polynomials</title>
      <link>https://freshrimpsushi.github.io/en/posts/779/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/779/</guid>
      <description>Definition $$U_{n} (x) := {{1} \over {n+1} } T_{n+1} &amp;rsquo; (x) = {{\sin \left( ( n +1 ) \theta \right)} \over { \sin \theta }} $$ is called the second kind Chebyshev polynomial. Basic Properties Recursive Formula [0]: $$U_{n+1} (x) = 2x U_{n} (x) - U_{n-1} (X)$$ Orthogonal Set [1] Inner product of functions: Given the weight $w$ for $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx$ as $\displaystyle w(x) :=</description>
    </item>
    <item>
      <title>First kind Chebyshev polynomials</title>
      <link>https://freshrimpsushi.github.io/en/posts/777/</link>
      <pubDate>Sun, 16 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/777/</guid>
      <description>Definition 1 $T_{n} (x) = \cos \left( n \cos^{-1} x \right)$ is called the first kind Chebyshev polynomial. Basic Properties Recurrence Formula [0]: $$T_{n+1} (x) = 2x T_{n} (x) - T_{n-1} (X)$$ Orthogonal Set [1] Inner product of functions: Given the weight $w$ as $\displaystyle w(x) := {{1} \over { \sqrt{1 - x^2} }}$, $\left\{ T_{0} , T_{1}, T_{2}, \cdots \right\}$ forms an orthogonal set. Chebyshev Nodes [2]: The roots</description>
    </item>
    <item>
      <title>Hilbert Spaces in Functional Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/776/</link>
      <pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/776/</guid>
      <description>Definition1 A Hilbert space is a complete inner product space. It is commonly denoted by $H$ and named after Hilbert. Description A complete space is a space in which every Cauchy sequence converges. Since Banach spaces are also complete spaces, Hilbert spaces can be described as Banach spaces with an inner product. Examples include: Lebesgue spaces $L^{2}$ $\ell^{2}$ spaces Real number space $\mathbb{R}^{n}$ Complex number space $\mathbb{C}^{n}$ Properties Hilbert spaces</description>
    </item>
    <item>
      <title>Isometric Mapping</title>
      <link>https://freshrimpsushi.github.io/en/posts/756/</link>
      <pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/756/</guid>
      <description>Definitions Given two metric spaces $(X,\ d_X), (Y,\ d_Y)$, if there exists a mapping $f : X \to Y$ that satisfies the conditions below, then $X$ and $Y$ are said to be isometric, denoted by $X \approx Y$. Furthermore, the mapping $f$ is called an isometric map or isometry. $$ d_X(x_1,\ x_2) =d_Y\big( f(x_1),\ f(x_2) \big),\quad \forall\ x_1,x_2\in X $$ Explanation As the name suggests, an isometric map is a</description>
    </item>
    <item>
      <title>Dual Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/753/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/753/</guid>
      <description>Dual Spaces Definition 11 The set of all continuous linear functionals of a vector space $X$ is denoted by $X^{ \ast }$ and is called the dual space of $X$, simply referred to as the dual of $X$, as denoted below. $$ X^{ \ast }:=\left\{ x^{ \ast }:X\to \mathbb{C}\ |\ x^{ \ast } \text{ is continuous and linear} \right\} $$ $$ X^{ \ast }:=B(X,\mathbb{C}) $$ $B \left( X, \mathbb{C} \right)$</description>
    </item>
    <item>
      <title>Checking the Normality of Residuals through Model Diagnostics</title>
      <link>https://freshrimpsushi.github.io/en/posts/683/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/683/</guid>
      <description>Diagnostics To determine if regression analysis was performed correctly, you can check using the standardized residual plot. Normality is better assessed using histograms rather than looking at the scatter of residuals, or by conducting a normality test. The left side shows a density that decreases towards the top and bottom from the center, whereas the right side is evenly distributed regardless of the direction. However, cases where the residuals actually</description>
    </item>
    <item>
      <title>Residual Independence Verified through Model Diagnosis</title>
      <link>https://freshrimpsushi.github.io/en/posts/679/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/679/</guid>
      <description>Diagnostic Methods Intuitive Pattern Recognition Using standardized residual plots, we can check if the regression analysis was performed correctly. To confirm independence, there should be no distinct patterns appearing in the residual plots. Unfortunately, diagnosing independence can be very subjective compared to other assumptions of regression analysis. A common example of lacking independence is seeing an unidentified straight line as shown above. It could be by chance, but usually, it</description>
    </item>
    <item>
      <title>Ideals in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/739/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/739/</guid>
      <description>Definition 1 A subring $(I, +)$ that satisfies $a I \subset I$ and $I b \subset I$ for all $a,b \in R$ in a ring $(R , + , \cdot )$ is called an Ideal. Explanation As a simple example, $n \mathbb{Z}$ is an Ideal of $\mathbb{Z}$. The name Ideal literally comes from the word Ideal, as it is the perfect subring to deal with in abstract algebra. Especially if</description>
    </item>
    <item>
      <title>Laplace Expansion</title>
      <link>https://freshrimpsushi.github.io/en/posts/781/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/781/</guid>
      <description>정리 A square matrix $A_{n \times n} = (a_{ij})$ is given. [1]: For the selected $i$ row $$ \det A = \sum_{j=1}^{n} a_{ij} C_{ij} $$ [2]: For the selected $j$ column $$ \det A = \sum_{i=1}^{n} a_{ij} C_{ij} $$ The determinant $M_{ij}$ of the matrix obtained by removing the $i$th row and $j$th column from the square matrix $A_{n \times n} = (a_{ij})$ is called a minor, and $C_{ij}</description>
    </item>
    <item>
      <title>Properties of Linear Operators</title>
      <link>https://freshrimpsushi.github.io/en/posts/730/</link>
      <pubDate>Thu, 22 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/730/</guid>
      <description>Theorem 1 $T : (X , \left\| \cdot \right\|_{X}) \to ( Y , \left\| \cdot \right\|_{Y} )$ is called a linear operator. (a) If $T$ is bounded, for all $x \in X$, $\left\| T(x) \right\|_{Y} \le \left\| T \right\| \left\| x \right\|_{X}$ (b) $T$ is continuous $\iff$ $T$ is bounded (c) If $X$ is a finite-dimensional space, then $T$ is continuous. (d) If $Y$ is a Banach space, then $(</description>
    </item>
    <item>
      <title>Zeros of a Polynomial Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/723/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/723/</guid>
      <description>Definition 1 $$ f(x) : = \sum_{i=0}^{n} a_{i} x^{i} = a_{0} + a_{1} x + \cdots + a_{k} x^{k} $$ Let us define the evaluation function $\phi_{\alpha} : F [ x ] \to E$ in $\alpha \in E$ for a polynomial function $f \in F [x]$ and a field $F \le E$ as follows. $$ \phi_{\alpha} ( f(x) ) : = a_{0} + a_{1} \alpha + \cdots + a_{n} \alpha^n</description>
    </item>
    <item>
      <title>Operators in Functional Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/728/</link>
      <pubDate>Tue, 20 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/728/</guid>
      <description>Definitions1 Let&amp;rsquo;s call $(X, \left\| \cdot \right\|_{X}), (Y, \left\| \cdot \right\|_{Y})$ a normed space. A mapping from a normed space to another normed space is called an operator. For $x,x_{1},x_{2}\in X$, if $T : X \to Y$ satisfies $$ T( x_{1} + x_{2} ) = T( x_{1} ) + T( x_{2} ) \quad \text{and} \quad T( a x ) = a T( x ) $$, it is called a linear</description>
    </item>
    <item>
      <title>Polynomial Rings</title>
      <link>https://freshrimpsushi.github.io/en/posts/721/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/721/</guid>
      <description>Definition 1 $$ f(x) : = \sum_{i=0}^{n} a_{i} x^{i} = a_{0} + a_{1} x + \cdots + a_{k} x^{k} $$ A polynomial $f(x)$ over a ring $R$ is defined as above. $a_{i} \in R$ are called the coefficients of $f(x)$. If $n &amp;lt; \infty$, then $n$ is called the degree of $f(x)$. $R[x]$ is the set of all polynomials with coefficients in $R$. $$ R[x] := \left\{ a_{0} + a_{1}</description>
    </item>
    <item>
      <title>Reflection and Refraction</title>
      <link>https://freshrimpsushi.github.io/en/posts/719/</link>
      <pubDate>Sun, 11 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/719/</guid>
      <description>Definitions 1 In a ring $R$, a $a,b \in R$ that is not $0$ and satisfies $ab = 0$ is called a Zero Divisor. A $D$ with a unit $1 \ne 0$ and without zero divisors is called an Integral Domain. Description Zero Divisors Examples of non-$0$ elements whose product is $0$ include $$ \begin{bmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} 0 &amp;amp; 0 \\ 0 &amp;amp;</description>
    </item>
    <item>
      <title>Boolean Ring</title>
      <link>https://freshrimpsushi.github.io/en/posts/717/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/717/</guid>
      <description>Definition 1 Let&amp;rsquo;s call $R$ a ring. If $r \in R$ satisfies $r^2 = r$, then $r$ is called an Idempotent Element. If all elements of $R$ are idempotent, $R$ is called a Boolean Ring. Explanation Although &amp;lsquo;Boolean ring&amp;rsquo; could be translated phonetically in Korean, the term sounds awkward, hence the English pronunciation was used directly. The property of projection in linear algebra is known to be very useful, needless</description>
    </item>
    <item>
      <title>Field Theory in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/715/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/715/</guid>
      <description>Definition 1 If a ring $(R , + , \cdot)$ has an identity element $1 \in R$ for multiplication $\cdot$, $1$ is called a unity. In a ring $R$ with a unity, the element $r \ne 0$ that has a multiplicative inverse is called a unit. If every element other than $0$ is a unit in a ring $R$ with a unity, it is called a division ring. A division</description>
    </item>
    <item>
      <title>Every Finite-Dimensional Normed Space Has a Basis</title>
      <link>https://freshrimpsushi.github.io/en/posts/707/</link>
      <pubDate>Mon, 29 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/707/</guid>
      <description>Theorem 1 Every finite-dimensional norm space has a basis. Description It might be unfamiliar to announce the existence of a basis not under specific conditions, but actually, the definition of a basis never stated that every vector space has a basis. Depending on how one defines finite dimensionality, it can also be a fact so obvious that it requires no separate proof. Proof Strategy: Use the fact that the space</description>
    </item>
    <item>
      <title>Hamel Basis of Finite-Dimensional Vector Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/705/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/705/</guid>
      <description>Definition 1 Given a vector space $X$. For vectors $x_{1} , \dots , x_{n}$ and scalar $\alpha_{1} , \dots , \alpha_{n}$ in $X$, $\alpha_{1} x_{1} + \cdots + \alpha_{n} x_{n}$ is called the linear combination of vectors $x_{1} , \dots , x_{n}$. When it is $M =\left\{ x_{1} , \dots , x_{n} \right\}$, the set of all linear combinations of vectors of $M$ is called $\text{span} M$, which is a</description>
    </item>
    <item>
      <title>Banach Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/703/</link>
      <pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/703/</guid>
      <description>Definition1 A Banach space is a complete normed space. Explanation A complete space refers to a space in which every Cauchy sequence converges. Banach space is a space that satisfies all of the following conditions, making it an extremely useful space as it is defined with a distance function and possesses completeness: It is a vector space. It is a normed space. $\implies$ It is a metric space. It is</description>
    </item>
    <item>
      <title>Bayesian Paradigm</title>
      <link>https://freshrimpsushi.github.io/en/posts/702/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/702/</guid>
      <description>Buildup Statistics can be defined as the study of methods to understand parameters. Just like measuring a physical quantity using formulas or laws, it would be ideal if parameters can be precisely estimated. However, due to the impractical nature of such precision, assumptions and samples are used to find &amp;lsquo;what is expected to be the parameter&amp;rsquo;. If interested in the average height of men in our country $X$, one might</description>
    </item>
    <item>
      <title>In Linear Algebra, What is a Norm?</title>
      <link>https://freshrimpsushi.github.io/en/posts/257/</link>
      <pubDate>Sat, 06 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/257/</guid>
      <description>Definition Let us define a vector space over $V$ as $\mathbb{F}$. $\left\| \cdot \right\| : V \to \mathbb{F}$ is defined as a norm on $V$ if it satisfies the following three conditions with respect to $\mathbf{u}, \mathbf{v} \in V$ and $k \in \mathbb{F}$: (i) Positive definiteness: $\left\| \mathbf{u} \right\| \ge 0$ and $\mathbf{u} = \mathbb{0} \iff \left\| \mathbf{u} \right\| = 0$ (ii) Homogeneity: $\left\|k \mathbf{u} \right\| = | k |</description>
    </item>
    <item>
      <title>Sequence Spaces (ℓp spaces)</title>
      <link>https://freshrimpsushi.github.io/en/posts/695/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/695/</guid>
      <description>Definition 1 For $1 \le p &amp;lt; \infty$, distance space $( \ell^{p} , d^{p} )$ is defined as follows: (i) Set of converging sequences: $$ \ell^{p} := \left\{ \left\{ x_{n} \right\}_{n \in \mathbb{N}} \subset \mathbb{C} \left| \left( \sum_{i=1}^{\infty} | x_{i} |^{p} \right)^{{1} \over {p}} &amp;lt; \infty \right. \right\} $$ (ii) Distance function: $$ d^{p} ( x_{n} , y_{n} ) := \left( \sum_{i = 1}^{\infty} | x_{i} - y_{i} |^{p} \right)^{</description>
    </item>
    <item>
      <title>What is a Manifold?</title>
      <link>https://freshrimpsushi.github.io/en/posts/673/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/673/</guid>
      <description>Definition 1 A topological space $X$ is called a $n$-dimensional manifold when it satisfies the following three conditions: (i): It is second-countable. (ii): It is Hausdorff. (iii): Every point of $X$ has a neighborhood homeomorphic to an open set in $\mathbb{R}^{n}$. A $n$-dimensional manifold $X$ is said to have a boundary when it has the following two types of points: (1) Interior points: Every neighborhood of $x \in X^{\circ}$ is</description>
    </item>
    <item>
      <title>Homoscedasticity of Residuals Verified through Model Diagnostics</title>
      <link>https://freshrimpsushi.github.io/en/posts/681/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/681/</guid>
      <description>Diagnostic Methods 1 Standardized residual plots can be used to check if a regression analysis was conducted properly. To verify homoscedasticity, one should check if the scatter of the residuals is uniformly distributed overall. Common examples of lack of homoscedasticity include the following two cases. The variance increases towards the end, a situation that often requires a transformation or the introduction of weights to resolve. Regardless of how easy it</description>
    </item>
    <item>
      <title>Residual Linearity Verified through Model Diagnostics</title>
      <link>https://freshrimpsushi.github.io/en/posts/677/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/677/</guid>
      <description>Diagnostic Techniques 1 Standardized residual plots can be used to check if the regression analysis was performed correctly. To check for linearity, see if the residuals are symmetrically distributed around $0$. Looking at the figure on the right, it is evident that there is a lack of linearity. If it were a simple regression analysis, it would result in an inability to explain the trend of the data at all.</description>
    </item>
    <item>
      <title>Regression Model Diagnostics</title>
      <link>https://freshrimpsushi.github.io/en/posts/675/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/675/</guid>
      <description>Necessity In the case of simple regression analysis, since it involves only one independent variable and one dependent variable, making it a $2$ dimensional analysis, it is easy to visually confirm if the analysis was conducted properly. However, for multiple regression analyses that exceed $3$ dimensions, it becomes difficult to represent the data graphically, making it hard to verify the accuracy of the analysis. There are instances where the analysis</description>
    </item>
    <item>
      <title>F-test for Regression Coefficients</title>
      <link>https://freshrimpsushi.github.io/en/posts/672/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/672/</guid>
      <description>Hypothesis Testing Assuming in the model diagnostics of the linear multiple regression model, the residuals satisfy linearity, homoscedasticity, independence, and normality. The hypothesis testing for the multiple regression analysis with $n$ observations and $p$ independent variables is as follows: $H_{0}$: $\beta_{1} = \beta_{2} = \cdots = \beta_{p} = 0$ i.e., all independent variables do not have a correlation with the dependent variable. $H_{1}$: At least one among $\beta_{1} , \beta_{2}</description>
    </item>
    <item>
      <title>How to Interpret Multiple Regression Analysis Results in R</title>
      <link>https://freshrimpsushi.github.io/en/posts/670/</link>
      <pubDate>Wed, 05 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/670/</guid>
      <description>Data Exploration tail(attitude) In R, let&amp;rsquo;s load the built-in data attitude and check it using the tail() function. We are interested in performing multiple regression analysis on this data. We are interested in how the other independent variables affect the rating, which is our dependent variable. It&amp;rsquo;s difficult to see if there is a linear relationship between rating and the other variables just by looking at the data, so let&amp;rsquo;s</description>
    </item>
    <item>
      <title>Multiple Regression Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/666/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/666/</guid>
      <description>Overview Regression analysis is a method used to discover the relationships between variables, particularly useful for identifying linear relationships. Multiple Linear Regression refers to the regression analysis that determines the effects of multiple independent variables (explanatory variables) on a single dependent variable (response variable). Model 1 $$Y = \beta_{0} + \beta_{1} X_{1} + \cdots + \beta_{p} X_{p} + \varepsilon $$ We are interested in whether variables have a linear relationship</description>
    </item>
    <item>
      <title>Regression Coefficient&#39;s t-test</title>
      <link>https://freshrimpsushi.github.io/en/posts/654/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/654/</guid>
      <description>Hypothesis Testing $$ \begin{bmatrix} y_{1} \\ y_{2} \\ \vdots \\ y_{n} \end{bmatrix} = \begin{bmatrix} 1 &amp;amp; x_{11} &amp;amp; \cdots &amp;amp; x_{p1} \\ 1 &amp;amp; x_{12} &amp;amp; \cdots &amp;amp; x_{p2} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 1 &amp;amp; x_{1n} &amp;amp; \cdots &amp;amp; x_{pn} \end{bmatrix} \begin{bmatrix} \beta_{0} \\ \beta_{1} \\ \vdots \\ \beta_{p} \end{bmatrix} + \begin{bmatrix} \varepsilon_{1} \\ \varepsilon_{2} \\ \vdots \\ \varepsilon_{n} \end{bmatrix} $$ When independent variables of</description>
    </item>
    <item>
      <title>In Thermodynamics, What is Entropy?</title>
      <link>https://freshrimpsushi.github.io/en/posts/651/</link>
      <pubDate>Sat, 18 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/651/</guid>
      <description>Definition The quantity $S$ is defined as entropy if it satisfies the following equation. $$ dS = {{ \delta Q_{\text{rev} } } \over { T }} $$ Explanation Entropy is a physical quantity representing &amp;lsquo;disorder,&amp;rsquo; and it&amp;rsquo;s challenging to understand why it indicates disorder just by looking at its mathematical definition. Explanations for non-specialists like &amp;lsquo;messing up a room&amp;rsquo; or &amp;lsquo;dropping ink into a glass of water&amp;rsquo; can only explain</description>
    </item>
    <item>
      <title>Simple Regression Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/648/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/648/</guid>
      <description>Overview Regression Analysis is a method for identifying relationships between variables, especially useful for elucidating linear relationships. Simple Linear Regression is the simplest among them, referring to regression analysis on one dependent (response) variable and one independent (explanatory) variable. Model 1 The statement that independent variable $x_{i}$ and dependent variable $y_{i}$ have a linear relationship means that for some $a,b$, it can be expressed as $y_{i} = ax_{i} + b$.</description>
    </item>
    <item>
      <title>Fitted Values, Predicted Values, Residuals, Errors</title>
      <link>https://freshrimpsushi.github.io/en/posts/650/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/650/</guid>
      <description>Definition 1 The regression equation obtained through regression analysis $Y \gets X_{1} + X_{2} + \cdots + X_{n}$ is denoted as $y = \beta_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} + \cdots + \beta_{n} x_{n}$, and let&amp;rsquo;s indicate the n-th data as $(y_{i} , x_{i1} , x_{i2} , \cdots , x_{in})$. Mean: $$ \displaystyle \overline{y} := {{1} \over {n}} \sum_{i=1}^{n} y_{i} $$ Fitted Value: For the n-th data $y_{i}$ $$</description>
    </item>
    <item>
      <title>Functional Spaces in Topology</title>
      <link>https://freshrimpsushi.github.io/en/posts/646/</link>
      <pubDate>Mon, 13 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/646/</guid>
      <description>Definition 1 A function space is defined as the product space $Y^{X}$ for topological spaces $X$ and $Y$. $$ Y^{X} : = \prod_{x \in X} Y = \left\{ f \ | \ f : X \to Y \text{ is a function} \right\} $$ The topology for the function space can be: For an open set $U$ in $x \in X$ and $Y$, let $$ S (x , U) = \left\{</description>
    </item>
    <item>
      <title>The Second Law of Thermodynamics</title>
      <link>https://freshrimpsushi.github.io/en/posts/643/</link>
      <pubDate>Fri, 10 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/643/</guid>
      <description>Laws Clausius: There is no process that transfers heat from a colder body to a hotter body by itself. Kelvin: A process that converts all heat into work is impossible. Explanation The statements by German physicist Clausius and British physicist Kelvin on the Second Law of Thermodynamics are equivalent to each other. The most famous version is by the Greek mathematician Carathéod</description>
    </item>
    <item>
      <title>Proof of the First Isomorphism Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/637/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/637/</guid>
      <description>Theorems 1 Let $G,G&#39;$ be a group. First Isomorphism Theorem: If there exists a homomorphism $\phi : G \to G&#39;$, then $$ G / \ker ( \phi ) \simeq \phi (G) $$ Second Isomorphism Theorem: If $H \le G$ and $N \triangleleft G$, then $$ (HN) / N \simeq H / (H \cap N) $$ Third Isomorphism Theorem: If $H , K \triangleleft G$ and $K \leq H$, then $$</description>
    </item>
    <item>
      <title>Group Actions</title>
      <link>https://freshrimpsushi.github.io/en/posts/630/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/630/</guid>
      <description>Definition 1 An action of a group $G$ with identity element $e$ on a set $X$ is a binary operation $\ast : G \times X \to X$ that satisfies the following two conditions: (i): For all $x \in X$, there is $ex = x$ (ii): For all $x \in X$ and $g_{1} , g_{2} \in G$, there is $( g_{1} g_{2} ) (x) = g_{1} (g_{2} x)$ We refer to</description>
    </item>
    <item>
      <title>First Law of Thermodynamics</title>
      <link>https://freshrimpsushi.github.io/en/posts/629/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/629/</guid>
      <description>Laws When work $W$ is applied to a system with thermal energy $Q$, the following equation holds for the internal energy $U$: $$ d U = \delta Q + \delta W $$ $\delta$ indicates an inexact differential. Explanation Since they do not have a primitive function in a clean form, it is necessary to calculate through line integration. It means that it is impossible to know exactly how much the</description>
    </item>
    <item>
      <title>Quotient Groups in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/628/</link>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/628/</guid>
      <description>Definition 1 Let&amp;rsquo;s call the set of all cosets of $H \subset G$ as $G / H$. If there exists a well-defined binary operation $\ast$ like $(aH) \ast\ (bH) = (ab) H$, then $\left&amp;lt; G / H , * \right&amp;gt;$ is called a Factor Group. Theorem Let&amp;rsquo;s assume $H \leqslant G$. That $H \triangleleft G$ and $G / H$ being a group are equivalent. Description That $H \triangleleft G$ means</description>
    </item>
    <item>
      <title>Nucleus, Kernel in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/622/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/622/</guid>
      <description>Definition The kernel of $G, G&#39;$ with respect to the identity element $e, e&#39;$ and the homomorphism $\phi : G \to G&#39;$ is the preimage $ \phi^{-1} [ \left\{ e&#39; \right\} ]$ of $\left\{ e&#39; \right\}$ and is denoted as $\ker \phi $. Definition [1]: For $g \in G$, $g ( \ker \phi ) = ( \ker \phi ) g$ [2]: $\ker \phi \triangleleft G$ [3]: $\ker \phi = \left\{</description>
    </item>
    <item>
      <title>Square-and-Multiply Algorithm Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/621/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/621/</guid>
      <description>Algorithm Given a natural number $a,k,m$, $b \equiv a^{k} \pmod{m}$ can be computed as follows. Step 1. Binary Expansion of $k$ Represent $u_{i} = 0$ or $u_{i} = 1$ as follows. $$ k = \sum_{i=0}^{r} u_{i} 2^{i} = u_{0} + 2 u_{1} + \cdots + 2^r u_{r} $$ Step 2. Calculate $a^{2^{r}} \equiv ( a^{2^{r-1}} )^2 \equiv A_{r-1}^2 \equiv A_{r} \pmod{m}$ as follows: $$ \begin{align*} a &amp;amp; &amp;amp; &amp;amp; \equiv</description>
    </item>
    <item>
      <title>Cartesian Product of Topological Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/620/</link>
      <pubDate>Sun, 22 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/620/</guid>
      <description>Definition 1 For an index set $\mathscr{A}$, let $\left\{ X_{\alpha} \ | \ \alpha \in \mathscr{A} \right\}$ be a set of topological spaces, and let $O_{\alpha}$ be an open set in $X_{\alpha}$. For the Cartesian product $\displaystyle X := \prod_{\alpha \in \mathscr{A}} X_{ \alpha}$, $p_{\alpha} : X \to X_{\alpha}$ is called the projection. The topology generated by a subbasis $\mathscr{S} : = \left\{ p_{\alpha}^{-1} ( O_{\alpha} ) \ | \</description>
    </item>
    <item>
      <title>The Cartesian Product of Groups</title>
      <link>https://freshrimpsushi.github.io/en/posts/619/</link>
      <pubDate>Sat, 21 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/619/</guid>
      <description>Definition 1 2 For groups $G_{1} , \cdots , G_{n}$ and elements $\displaystyle (a_{1},\cdots , a_{n}), (b_{1} , \cdots , b_{n} ) \in \prod_{i=1}^{n} G_{i}$ of their Cartesian product, $$ (a_{1},\cdots , a_{n}) (b_{1} , \cdots , b_{n} ) = (a_{1} b_{1},\cdots , a_{n} b_{n}) $$ then $\displaystyle \prod_{i=1}^{n} G_{i}$ is called the Direct Product of $G_{1} , \cdots , G_{n}$ groups. Especially, if $G_{1}, \cdots , G_{n}$ is an</description>
    </item>
    <item>
      <title>Proof of Minkowski&#39;s Inequality in Lebesgue Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/614/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/614/</guid>
      <description>Summary[^1] Let&amp;rsquo;s call $\Omega \subset \mathbb{R}^{n}$ an open set. If $1 \le p &amp;lt; \infty$ and $u, v \in L^{p}(\Omega)$, then $$ \left\| u + v \right\|_{p} \le \left\| u \right\|_{p}+\left\| v \right\|_{p} $$ This is called the Minkowski inequality.</description>
    </item>
    <item>
      <title>Definition of temperature in physicss</title>
      <link>https://freshrimpsushi.github.io/en/posts/613/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/613/</guid>
      <description>Definition1 2 Let&amp;rsquo;s assume there is a system with energy $E$. When the number of microstates for $E$ is denoted as $\Omega (E) = \Omega$, then $$ \dfrac{1}{k_{B} T} := \dfrac{d \ln ( \Omega )}{d E } $$ defines the temperature of the system as $T$, where $k_{B}$ is the Boltzmann constant. Microstates and Macrostates In statistical mechanics, the concepts of a system&amp;rsquo;s Macrostate and Microstate could be similar to</description>
    </item>
    <item>
      <title>Proof of Hölder&#39;s Inequality in Lebesgue Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/609/</link>
      <pubDate>Thu, 12 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/609/</guid>
      <description>Theorem1 Let us consider $\Omega \subset \mathbb{R}^{n}$ as an open set. Suppose we&amp;rsquo;re given two constants $1 \lt p \lt \infty, 1 \lt p^{\prime} \lt \infty$ satisfying the following equation. $$ \dfrac{1}{p}+\dfrac{1}{p^{\prime}} = 1 \left(\text{or } p^{\prime} = \frac{p}{p-1} \right) $$ If $u \in L^p(\Omega)$ and $v\in L^{p^{\prime}}(\Omega)$, then $uv \in L^1(\Omega)$, and the inequality below holds. $$ \| uv \|_{1} = \int_{\Omega} |u(x)v(x)| dx \le \| u \|_{p} \|</description>
    </item>
    <item>
      <title>A Simple Derivation of the Stirling Formula</title>
      <link>https://freshrimpsushi.github.io/en/posts/608/</link>
      <pubDate>Wed, 11 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/608/</guid>
      <description>Formulas The following equation is referred to as Stirling&amp;rsquo;s formula. $$ \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ Description1 This approximation is useful in the aspect of calculating factorials for large numbers. In fields like thermodynamics and statistical mechanics, it&amp;rsquo;s essential to assume a large number of molecules, $$ \begin{align*} n! &amp;amp;\approx \sqrt{2\pi n}\left( \dfrac{n}{e} \right)^{n} \\[0.6em] \log_{2} n!</description>
    </item>
    <item>
      <title>Lp Spaces, Lebesgue Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/605/</link>
      <pubDate>Sun, 08 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/605/</guid>
      <description>Definition1 2 3 Let $\Omega \subset \mathbb{R}^{n}$ be an open set, and $p$ be a positive real number. For all measurable functions $f$ defined on $\Omega$, define set $L^{p}(\Omega)$ as follows. $$ L^{p}(\Omega) := \left\{ f : \int_{\Omega} \left| f(x) \right|^{p} dx &amp;lt; \infty \right\} $$ This is called the Lp space or Lebesgue space and is briefly denoted as $L^{p}$. Typically, textbooks on functional analysis describe it as above,</description>
    </item>
    <item>
      <title>Ideal Gas Equation</title>
      <link>https://freshrimpsushi.github.io/en/posts/602/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/602/</guid>
      <description>Formulas1 Let&amp;rsquo;s denote the number of molecules of a gas as $N$, volume as $V$, pressure as $p$, and absolute temperature as $T$. Then, the following equation holds, and this is called the ideal gas equation. $$ pV = N k_{B} T $$ Here, $k_{B} = 1.3807 \times 10^{-23} J / K$ is called the Boltzmann constant. Description Historically, it was derived from experimental laws and later derived mathematically from</description>
    </item>
    <item>
      <title>Reason for Defining the Inner Product of Functions via Definite Integration</title>
      <link>https://freshrimpsushi.github.io/en/posts/599/</link>
      <pubDate>Mon, 02 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/599/</guid>
      <description>Buildup The general definition of the inner product is as follows: Let $H$ be a vector space. For $x,y,z \in H$ and $\alpha, \beta \in \mathbb{C}$, a function that satisfies the following conditions $$ \langle \cdot , \cdot \rangle \ : \ H \times H \to \mathbb{C} $$ is defined as an inner product, and $\left( H, \langle \cdot ,\cdot \rangle \right)$ is called an inner product space. Linearity: $\langle</description>
    </item>
    <item>
      <title>L2 Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/594/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/594/</guid>
      <description>Definition 1 A function space $L^{2}$ is defined as follows. $$ L^{2} (E) := \left\{ f : \left( \int_{E} | f |^2 dm \right)^{{1} \over {2}} &amp;lt; \infty \right\} $$ Properties $L^{2}$ is a metric space. The metric is defined as following. $$ d(f,g) := \left( \int \left| f(x) - g(x) \right|^{2}dx \right)^{\frac{1}{2}} = \left\| f-g \right\|_{2} = \sqrt{\braket{f-g, f-g}} $$ $L^{2}$ is a vector space. $L^{2}$ is a normed</description>
    </item>
    <item>
      <title>L1 Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/592/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/592/</guid>
      <description>Definition1 A function space $L^{1}$ is defined as follows. $$ L^{1} (E) := \left\{ f : E \to \mathbb{R} \Big \vert \int_{E} | f | dm \lt \infty \right\} $$ Properties $L^{1}$ is a vector space. $L^{1}$ is a normed space. The norm is defined as follows: $$ \left\| f \right\|_{1} := \int \left| f(x) \right| dx $$ $L^{1}$ is a complete space. Explanation Space $L^{1}$ is a special case</description>
    </item>
    <item>
      <title>Bolzano-Weierstrass Property and Compactness of Accumulation Points</title>
      <link>https://freshrimpsushi.github.io/en/posts/576/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/576/</guid>
      <description>Definition 1 If every infinite subset of a topological space $X$ has its limit point in $X$, then $X$ is said to have the Bolzano-Weierstrass property or to be compactly accumulating points. Theorem [1]: Every compact space is a compactly accumulating points space. [2]: If $X$ is a metric space, then $X$ being compact is equivalent to being compactly accumulating points. $X$ is a metric space, then it being compact</description>
    </item>
    <item>
      <title>Confusion Matrix, Sensitivity, and Specificity</title>
      <link>https://freshrimpsushi.github.io/en/posts/571/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/571/</guid>
      <description>Definition Let&amp;rsquo;s assume we have a model for distinguishing between positive $P$ and negative $N$ in a classification problem. We define the number of positives correctly predicted as true positives $TP$, the number of negatives correctly predicted as true negatives $TN$, the number of positives incorrectly predicted as negatives as false negatives $FN$, and the number of negatives incorrectly predicted as positives as false positives $FP$. Confusion Matrix In classification</description>
    </item>
    <item>
      <title>Proof of the Maximum and Minimum Value Theorem in Topological Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/563/</link>
      <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/563/</guid>
      <description>Theorem 1 For a compact space $X$, if a function $f : X \to \mathbb{R}$ is continuous, then for every $x \in X$, there exists a $c,d \in X$ that satisfies $f(c) \le f(x) \le f(d)$. Explanation In $\mathbb{R}$, being compact is equivalent to being a closed interval $[a,b]$, so ultimately this generalizes the theorem we learned in high school and analysis. As much as it uses the difficult theories</description>
    </item>
    <item>
      <title>Useful Properties of Compact Spaces and Continuous Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/561/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/561/</guid>
      <description>Theorems Let us assume that $f : X \to Y$, with $X$ being compact, and $f$ being continuous. [1]: If $f$ is surjective, $Y$ is compact. Even if $f$ is not surjective, $f(X)$ is still compact. [2]: If $Y$ is Hausdorff, then $f$ is a closed function. For a closed set $C \subset X$, $f(C) \subset Y$ is also a closed set. [3]: If $f$ is bijective and $Y$ is</description>
    </item>
    <item>
      <title>Proof of the Dominated Convergence Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/557/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/557/</guid>
      <description>Theorem 1 Given measurable sets $E \in \mathcal{M}$ and $g \in \mathcal{L}^{1} (E)$, let the sequence of measurable functions $\left\{ f_{n} \right\}$ satisfy $|f_{n}| \le g$ almost everywhere in $E$. If, almost everywhere in $E$, $\displaystyle f = \lim_{n \to \infty} f_{n}$ then $f \in \mathcal{L}^{1}(E)$. $$ \lim_{ n \to \infty} \int_{E} f_{n} (x) dm = \int_{E} f dm $$ $f,g \in \mathcal{L}^{1} (E)$ means that $f$ and $g$ are</description>
    </item>
    <item>
      <title>Design Matrix</title>
      <link>https://freshrimpsushi.github.io/en/posts/550/</link>
      <pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/550/</guid>
      <description>Buildup Let&amp;rsquo;s load the built-in data faithful in R and check it with the head() function. Though only six, at a glance, eruptions and waiting seem to have a positive correlation. It would be nice if their relationship could be represented by some two constants $\beta_{0}, \beta_{1}$ such that $$\text{(eruptions)} = \beta_{0} + \beta_{1} \cdot \text{(waiting) }$$ The above equation represents the linear relationship between the two variables as the</description>
    </item>
    <item>
      <title>Lebesgue Integrable</title>
      <link>https://freshrimpsushi.github.io/en/posts/549/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/549/</guid>
      <description>Definition 1 Basic Properties [1]: An integrable function is a measurable function. [2]: If $f \in \mathcal{L}^{1} (E)$ then $\displaystyle \left| \int_{E} f dm \right| \le \int_{E} | f | dm$ [3]: If $f \in \mathcal{L}^{1} (E) $ and $c \in \mathbb{R}$ then $\displaystyle \int_{E} (c f) dm = c \int_{E} f dm$ [4]: If $f,g \in \mathcal{L}^{1} (E) $ then $\displaystyle \int_{E} ( f + g ) dm =</description>
    </item>
    <item>
      <title>What is Regression Analysis?</title>
      <link>https://freshrimpsushi.github.io/en/posts/548/</link>
      <pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/548/</guid>
      <description>Description Regression analysis is so ubiquitous a foundation of nearly all statistical techniques that it is often described either too generally or too specifically. If one were to explain what regression analysis is in a sentence for someone curious, it could be described as a method for discovering the relationships between variables. This useful and astonishing method of analysis was born from the ideas of Francis Galton, the father of</description>
    </item>
    <item>
      <title>Monotone Convergence Theorem Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/535/</link>
      <pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/535/</guid>
      <description>Theorem 1 Let us assume that a sequence $\left\{ f_{n} \right\}$ of measurable functions with non-negative values satisfies $f_{n} \nearrow f$. Then $$ \lim_{n \to \infty} \int_{E} f_{n} dm = \int_{E} f dm $$ Explanation $f_{n} \nearrow f$ means that for all $x$, if $f_{n}(x) \le f_{n+1} (x)$ while $\displaystyle \lim_{n \to \infty} f_{n} = f$. The formula is too simple, so knowing this theorem means precisely understanding the &amp;lsquo;condition&amp;rsquo;.</description>
    </item>
    <item>
      <title>Proof of Fatou&#39;s Lemma</title>
      <link>https://freshrimpsushi.github.io/en/posts/534/</link>
      <pubDate>Sat, 05 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/534/</guid>
      <description>Summary 1 For a sequence $\left\{ f_{n} \right\}$ of non-negative measurable functions, $$ \int_{E} \left( \liminf_{n \to \infty} f_{n} \right) dm \le \liminf_{n \to \infty} \int_{E} f_{n} dm $$ $\liminf$ is the limit inferior. Explanation A lemma necessary for proving the Monotone Convergence Theorem and the Dominated Convergence Theorem in real analysis. The version of Fatou&amp;rsquo;s lemma for series without the condition of being measurable functions is as follows. Series</description>
    </item>
    <item>
      <title>Solution to the Inviscid Burgers&#39; Equation</title>
      <link>https://freshrimpsushi.github.io/en/posts/532/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/532/</guid>
      <description>Definition The following quasilinear partial differential equation is called the Burgers&amp;rsquo; equation. $$ \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ Here, $t$ represents time, $x$ represents position, and $u(t,x)$ represents the waveform at position $x$ at time $t$. $f$ represents the initial condition, specifically the waveform at $t=0$. Explanation Burgers&amp;rsquo; equation represents the case where the diffusion coefficient</description>
    </item>
    <item>
      <title>Lebesgue Integration</title>
      <link>https://freshrimpsushi.github.io/en/posts/527/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/527/</guid>
      <description>Buildup Before considering the generalization of Riemann integration, it is necessary to define what a simple function is. Let&amp;rsquo;s say the range $\phi : \mathbb{R} \to \mathbb{R}$ of the function values, which are non-negative, is a finite set $\left\{ a_{1} , a_{2}, \cdots , a_{n} \right\}$. If it satisfies $A_{i} = \phi^{-1} \left( \left\{ a_{i} \right\} \right) \in \mathcal{M}$, then $\phi$ is called a simple function. Simple functions have the</description>
    </item>
    <item>
      <title>In Measure Theory: Almost Everywhere and Almost Surely</title>
      <link>https://freshrimpsushi.github.io/en/posts/524/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/524/</guid>
      <description>Definition 1 If a function $f : E \to \overline{\mathbb{R}}$, excluding a set $E_{0} \subset E$ where $m(E_{0}) = 0$, has some property $P$, then $f$ is said to have property $P$ almost everywhere within $E$. Notation When talking about probability, almost everywhere is expressed as almost surely, and for conciseness, the abbreviation $$ f = g \text{ a.e.} \\ P(E) = 0 \text{ a.s.} $$ can be used. Explanation</description>
    </item>
    <item>
      <title>Lebesgue Measurable Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/518/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/518/</guid>
      <description>Definition 1 A function $f: E \in \overline{ \mathbb{R} }$ is said to be (Lebesgue) measurable if for every interval $I \subset \overline{ \mathbb{R} }$, $$ f^{-1} (I) = \left\{ x \in \mathbb{R} \ | \ f(x) \in I \right\} \in \mathcal{M} $$ holds. $\overline{ \mathbb{R} } = \mathbb{R} \cup \left\{ - \infty , + \infty \right\}$ refers to the extended real number space, which includes positive and negative infinity,</description>
    </item>
    <item>
      <title>Independence of Events and Conditional Probability</title>
      <link>https://freshrimpsushi.github.io/en/posts/521/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/521/</guid>
      <description>Definition 1 Let&amp;rsquo;s assume a probability space $(\Omega , \mathcal{F} , P)$ is given. For $P(B)&amp;gt;0$, $\displaystyle P (A | B) = {{P(A \cap B)} \over {P(B)}}$ is called the conditional probability of $A$ given $B$. If $P(A | B) = P(A)$, that is $P( A \cap B) = P(A) \cdot P(B)$, then $A, B$ are considered independent. If you haven&amp;rsquo;t yet encountered measure theory, you can ignore the term</description>
    </item>
    <item>
      <title>Rejection Region and Significance Level</title>
      <link>https://freshrimpsushi.github.io/en/posts/509/</link>
      <pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/509/</guid>
      <description>Definition 1 The error of rejecting the null hypothesis when it is actually true is called a Type I error. The error of failing to reject the null hypothesis when the alternative hypothesis is true is called a Type II error. The maximum probability of committing a Type I error is called the Significance Level. The statistic used for hypothesis testing is called the Test Statistic. The region of the</description>
    </item>
    <item>
      <title>Probability Defined by Measure Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/498/</link>
      <pubDate>Tue, 03 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/498/</guid>
      <description>Definition 1 Let&amp;rsquo;s say $\mathcal{F}$ is a sigma field of set $\Omega$. Measurable set $E \in \mathcal{F}$ is called an Event. On $\mathcal{F}$, if measure $P : \mathcal{F} \to \mathbb{R}$ satisfies $P(\Omega) = 1$, then $P$ is called Probability. $( \Omega, \mathcal{F} , P )$ is called the Probability Space. Explanation Borrowing the strength of measure theory, we can provide a mathematical foundation for various concepts of probability theory and</description>
    </item>
    <item>
      <title>Lebesgue Measure</title>
      <link>https://freshrimpsushi.github.io/en/posts/494/</link>
      <pubDate>Thu, 29 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/494/</guid>
      <description>Definition 1 Let us define the function $m : \mathcal{M} \to [0,\infty]$ with respect to $E \in \mathcal{M}$ as follows $m(E) := m^{ \ast } (E)$. $m$ is called the (Lebesgue) measure. $\mathcal{M}$ is a sigma-algebra, the set of measurable sets of $X = \mathbb{R}$. $m^{\ast}$ is an outer measure. Description The outer measure was neatly defined by $m^{ \ast } : \mathscr{P}( \mathbb{R} ) \to [0, \infty]$, but it</description>
    </item>
    <item>
      <title>Sigma Algebra and Measurable Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/490/</link>
      <pubDate>Sun, 25 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/490/</guid>
      <description>Definitions For a set $X \ne \emptyset$, $\mathcal{E} \subset \mathscr{P} (X)$ is called a Sigma Algebra or Sigma Field on $X$ if it satisfies the conditions below. The ordered pair $(X , \mathcal{E})$ of the set $X$ and the sigma field $\mathcal{E}$ is called a Measurable Space. (i): $\emptyset \in \mathcal{E}$ (ii): $E \in \mathcal{E} \implies E^{c} \in \mathcal{E}$ (iii): $\displaystyle \left\{ E_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{E} \implies \bigcup_{n=1}^{\infty}</description>
    </item>
    <item>
      <title>What are Compact and Precompact in Topological Spaces?</title>
      <link>https://freshrimpsushi.github.io/en/posts/489/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/489/</guid>
      <description>Definition 1 Let&amp;rsquo;s say we have a topological space $\left( X, \mathscr{T} \right)$. A set $\mathscr{O} \subset \mathscr{T}$ consisting of open sets of $X$ is called an open covering of $A$ if it satisfies the following: $$ A \subset \bigcup_{O \in \mathscr{O}} O $$ A subset $\mathscr{O} &#39; $ of $\mathscr{O}$ is called a subcover of $\mathscr{O}$. If the cardinality of $\mathscr{O} &#39; $ is a natural number, it is</description>
    </item>
    <item>
      <title>Path-Connectedness in Topology</title>
      <link>https://freshrimpsushi.github.io/en/posts/478/</link>
      <pubDate>Sun, 18 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/478/</guid>
      <description>Definitions 1 Let&amp;rsquo;s call $X$ a topological space and let $C \subset \mathbb{R}^{n}$. A continuous function $p : [0,1] \to X$ from initial point $p(0)$ to terminal point $p(1)$ is called a path. $\overline{p}(t) = p(1-t)$ is called the reverse path of $p$. If for every $a,b \in X$ there exists a path $p$ satisfying both $p(0) = a$ and $p(1) = b$, then $X$ is called a path-connected space.</description>
    </item>
    <item>
      <title>Proof of the Intermediate Value Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/476/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/476/</guid>
      <description>Definition 1 If $f : [a,b] \to \mathbb{R}$ is continuous, then there exists a $c \in (a,b)$ between $f(a)$ and $f(b)$ such that $y_{0} = f(c)$ is satisfied for $y_{0}$. Explanation Using the contrapositive, it can be shown that there is no curve connecting two specific shapes under condition $\mathbb{R}^2$. Corollary Meanwhile, the intermediate value theorem has several useful corollaries as follows: Existence judgment method for the solution of equation</description>
    </item>
    <item>
      <title>Cosets and Normal Subgroups in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/469/</link>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/469/</guid>
      <description>Definition 1 The set $G$ and its subgroup $H$ such that $aH = \left\{ ah \ | \ h \in H \right\}$ is called the Left Coset and $Ha = \left\{ ha \ | \ h \in H \right\}$ is called the Right Coset. Here, $a \in G$ and $aH, Ha \subset G$. The number of left (right) cosets of $H \leqslant G$ is denoted as $(G : H)$ and</description>
    </item>
    <item>
      <title>Orbits, Cycles, and Permutations in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/460/</link>
      <pubDate>Sun, 04 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/460/</guid>
      <description>Definitions 1 The equivalence classes of $\sim$ are called the Orbits of $\sigma$. A permutation that has at most one orbit with more than one element is called a Cycle. Among the orbits a cycle has, the orbit with the largest cardinality is called the Length of the cycle. A cycle with length $2$ is called a Transposition. Orbits corresponding to a cycle that do not share elements are called</description>
    </item>
    <item>
      <title>Connectivity in Topology</title>
      <link>https://freshrimpsushi.github.io/en/posts/457/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/457/</guid>
      <description>Definitions 1 In a topological space $X$, if there exist open sets $A \ne \emptyset$, $B \ne \emptyset$ that satisfy $A \cap B = \emptyset$ and $A \cup B = X$, then $X$ is called a Disconnected space. If it is not disconnected, it is called a Connected space. Theorems [1]: Connectedness is a topological property. [2]: Every trivial space is a connected space. [3]: Every discrete space is a</description>
    </item>
    <item>
      <title>Separation Properties in Topology</title>
      <link>https://freshrimpsushi.github.io/en/posts/454/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/454/</guid>
      <description>Definition 1 Let&amp;rsquo;s consider $X$ as a topological space. For $a,b \in X$, if $a \ne b$ and $U, V \subset X$ are open sets in $X$, then: $T_{0}$: If there exists $U$ that contains only one of $a$ and $b$, then $X$ is called a Kolmogorov space. $T_{1}$: For any $a,b$, if there exists $U,V$ satisfying $$ a \in U, b \notin U \\ a \notin V, b \in</description>
    </item>
    <item>
      <title>Generalization of Binomial Coefficients: Beta Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/450/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/450/</guid>
      <description>Theorem: Binomial Coefficients Expressed Through the Beta Function $0 \le k\le n$ is satisfied for two natural numbers $k,n$, the following equation holds. $$ \binom{n}{k}={}_{n}C_{k}=C(n,k)=\frac{1}{(n+1)B(n-k+1,k+1)} $$ For two natural numbers $m,n$, the following equation holds. $$ B(m,n)=\left[ \frac{mn}{m+n} \begin{pmatrix} m+n \\ n \end{pmatrix}\right]^{-1} $$ Description The beta function, defined by $B(p,q):=\displaystyle \int_{0}^{1}t^{p-1}(1-t)^{q-1}dt$, can also be seen as a generalization of binomial coefficients. The proof is not difficult, but a lemma</description>
    </item>
    <item>
      <title>Binomial Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/443/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/443/</guid>
      <description>Definition 1 Continuous For $[a,b] \subset \mathbb{R}$, a continuous probability distribution $U(a,b)$ with the following probability density function is called the Uniform Distribution. $$ f(x) = {{ 1 } \over { b - a }} \qquad , x \in [a,b] $$ Discrete For a finite set $\left\{ x_{k} \right\}_{k=1}^{n}$, a discrete probability distribution with the following probability mass function is called the Uniform Distribution. $$ p \left( x_{k} \right) =</description>
    </item>
    <item>
      <title>Torsion Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/445/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/445/</guid>
      <description>See Also Totient Function in Analytic Number Theory Definition 1 The function defined as follows, $\phi$, is called the Euler&amp;rsquo;s totient function. $$ \phi ( m ) := \left| \left\{ a \ | \ 1 \le a \le m \land \gcd (a,m) = 1 \right\} \right| = m \prod_{p \mid m} \left( 1 - {{1} \over {p}} \right) $$ Explanation The term totient comes from the Tot- in Total meaning</description>
    </item>
    <item>
      <title>In English: Various Mappings in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/439/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/439/</guid>
      <description>Definitions Let&amp;rsquo;s talk about a group $\left&amp;lt; G , \ast\ \right&amp;gt; , \left&amp;lt; G&#39; , *&#39; \right&amp;gt;$ and refer to it as $\phi : G \to G&#39;$. If $\forall x ,y \in G $, $\phi (x \ast\ y) = \phi (x ) *&#39; \phi ( y)$ then we call $\phi$ a Homomorphism. If a homomorphism $\phi$ is injective, then we call $\phi$ a Monomorphism and denote it $G \hookrightarrow G&#39;$.</description>
    </item>
    <item>
      <title>Homotopy in Topological Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/438/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/438/</guid>
      <description>Definition 1 For two topological spaces $X,Y$, if a bijection $f : X \to Y$ exists such that both $f$ and its inverse function $f^{-1}$ are continuous functions, then $f$ is called a Homeomorphism, and the two topological spaces are said to be Homeomorphic. Theorem The following propositions are equivalent. (1): $f : X \to Y$ is a homeomorphism. (2): $f^{-1} : Y \to X$ is a homeomorphism. (3): $f</description>
    </item>
    <item>
      <title>Open Functions and Closed Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/435/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/435/</guid>
      <description>Definition Let&amp;rsquo;s say for a topological space $X,Y$ that $f : X \to Y$. For every open set $O \subset X$, if $f (O)$ is an open set in $Y$, then $f$ is called an open function. For every closed set $C \subset X$, if $f (C)$ is a closed set in $Y$, then $f$ is called a closed function. Theorem In particular, a continuous function has the following property:</description>
    </item>
    <item>
      <title>Continuous in Topology</title>
      <link>https://freshrimpsushi.github.io/en/posts/432/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/432/</guid>
      <description>Definition For a topological space $(X, \mathscr{T}_{X} )$ and $(Y, \mathscr{T}_{Y} )$, let&amp;rsquo;s denote by $f: X \to Y$. A function $f$ is said to be continuous at $a$ if, for every neighborhood $V \in \mathscr{T}_{Y}$ containing $f(a)$, there exists a neighborhood $U \in \mathscr{T}_{X}$ containing $a$ such that $f(U) \subset V$ is satisfied. If $f$ is continuous at every point of $X$, it is called a continuous function and</description>
    </item>
    <item>
      <title>Proof of Fermat&#39;s Little Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/121/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/121/</guid>
      <description>Theorem 1 Prime numbers $p$ and integers $a$ that are coprime to each other, $a^{p-1} \equiv 1 \pmod{p}$ Explanation Fermat&amp;rsquo;s little theorem is a straightforward yet highly influential theorem used in a variety of fields. Although there is a generalized theorem by Euler, Fermat&amp;rsquo;s little theorem is often sufficient. It is particularly essential in fields like cryptography that extensively deal with exponentiation in finite fields. Proof Strategy: The proof is</description>
    </item>
    <item>
      <title>Subbasis in Topology</title>
      <link>https://freshrimpsushi.github.io/en/posts/427/</link>
      <pubDate>Fri, 09 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/427/</guid>
      <description>Definition 1 Let&amp;rsquo;s say there is a topological space $\left( X , \mathscr{T} \right)$ and consider $\mathscr{S} \subset \mathscr{T}$. When $\displaystyle \mathscr{B} = \left\{ \left. B = \bigcap_{ i = 1}^{n} S_{i} \ \right| \ S_{i} \in \mathscr{S} \right\}$ becomes the basis for $\mathscr{T}$, then $\mathscr{S}$ is called a Subbasis for $\mathscr{T}$. Explanation The reason why accepting the concept of subbasis can be difficult is because the term &amp;lsquo;sub&amp;rsquo; in</description>
    </item>
    <item>
      <title>Fundamental Theorem of Arithmetic Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/419/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/419/</guid>
      <description>Theorem 1 Every natural number $n &amp;gt;2$ has a unique prime factorization $n = p_{1} p_{2} \cdots p_{r}$. The order of the primes $p_{1} , p_{2} , \cdots , p_{r}$ is ignored. Explanation It may seem strange that a property we&amp;rsquo;ve naturally used since elementary school requires proof, but it is extremely important. The fact that this is so simple perhaps serves as evidence that it merits the name theorem.</description>
    </item>
    <item>
      <title>Proof of the Extended Euclidean Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/417/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/417/</guid>
      <description>Theorem 1 For two integers $a,b$, there always exists an integer solution for $ax + by = \gcd (a,b)$. Description This theorem is also known as the Linear Congruence Theorem as it implies that $\gcd (a,b)$ can be expressed as a linear equation involving $a$ and $b$. Although its appearance seems somewhat complex and it only discusses existence, it is surprisingly widely used. It might not provide a specific solution</description>
    </item>
    <item>
      <title>Symmetry Groups in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/421/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/421/</guid>
      <description>Definition 1 A permutation is a bijection $\phi : A \to A$ for a set $A$. $S_{A}$ is the set of all permutations of $A$, which forms a group $\left&amp;lt; S_{A} , \circ \right&amp;gt;$ with respect to function composition $\circ$, and is called the symmetric group. Explanation The fact that symmetric groups indeed satisfy the conditions of a group can be easily ascertained, given that a permutation is defined as</description>
    </item>
    <item>
      <title>Bases and Local Bases in Topology</title>
      <link>https://freshrimpsushi.github.io/en/posts/412/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/412/</guid>
      <description>Definition Let&amp;rsquo;s say topological space $\left( X , \mathscr{T} \right)$ with respect to $\mathscr{B} , \mathscr{B}_{x} \subset \mathscr{T}$. When we say $B_{\lambda} \in \mathscr{B}$, if for every $U \in \mathscr{T}$ there exists a neighbourhood $\Lambda$ that satisfies $$ U = \bigcup_{\lambda \in \Lambda} B_{ \lambda } $$ then $\mathscr{B}$ is called a basis for $\mathscr{T}$. In this case, the topology $\mathscr{T}$ is said to be generated by $\mathscr{B}$. When we</description>
    </item>
    <item>
      <title>The First Countable and the Second Countable</title>
      <link>https://freshrimpsushi.github.io/en/posts/413/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/413/</guid>
      <description>Definition 1 Let&amp;rsquo;s suppose that a topological space $X$ is given. If every point $x \in X$ has a countable local base, it is called a first-countable space. If $X$ has a countable base, it is called a second-countable space. Explanation Through the concepts of base and local base, a new branch of countability has been created. Examples of spaces not being first-countable Discrete spaces $\left( \mathbb{R} , \mathscr{T}_{f} \right)$</description>
    </item>
    <item>
      <title>What is a Conformal Mapping in Complex Analysis?</title>
      <link>https://freshrimpsushi.github.io/en/posts/409/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/409/</guid>
      <description>Definition 1 A function $f: A \subset \mathbb{C} \to \mathbb{C}$ that is analytic at $\mathscr{R} \subset A$ and for all $z \in \mathscr{R}$ satisfies $f &#39; (z) \ne 0$ is called a Conformal Mapping if $f$. Meanwhile, if there exists a point $\alpha$ that satisfies $f &#39; (\alpha) = 0$, then $\alpha$ is referred to as the Critical Point of $f$. Description As the Chinese characters for conformal (等</description>
    </item>
    <item>
      <title>Limits of sequence are not unique in general Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/407/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/407/</guid>
      <description>Theorem In general, in a topological space, the limit of a sequence is not unique. Explanation This might sound surprising, but it is indeed true. Until now, we have been accustomed to the image of intervals containing sequences in analysis narrowing down to converge to a point. However, according to the concept of convergence defined in topology, there is no reason for sequences to converge to a single point depending</description>
    </item>
    <item>
      <title>Topological Spaces: Separability and Closure</title>
      <link>https://freshrimpsushi.github.io/en/posts/405/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/405/</guid>
      <description>Definition 1 For a topological space $X$, let&amp;rsquo;s say $A \subset X$. When an open set $O$ exists that satisfies $x \in O \subset A$, $x$ is called the interior point of $A$. The set of interior points of $A$, $A^{\circ}$, is called the interior of $A$. The union of $A$ and its codomain $\overline{A} : = A \cup a &#39;$ is called the closure of $A$. When $x \in</description>
    </item>
    <item>
      <title>Isomorphism in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/403/</link>
      <pubDate>Sun, 28 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/403/</guid>
      <description>Definition 1 For two binary operation structures $\left&amp;lt; S , * \right&amp;gt;$ and $\left&amp;lt; S&#39; , *&#39; \right&amp;gt;$, if there exists a bijective function $\phi : S \to S&#39;$ such that for all $x , y \in S$, $$ \phi (x \ast\ y) = \phi ( x ) *&#39; \phi ( y ) $$ is satisfied, then $\phi$ is called an isomorphism, and $S$ and $S&#39;$ are said to be</description>
    </item>
    <item>
      <title>Limit Points and Convergence in Topological Spaces, Image Sets</title>
      <link>https://freshrimpsushi.github.io/en/posts/400/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/400/</guid>
      <description>Definition 1 Let&amp;rsquo;s assume a topological space $\left( X , \mathscr{T} \right)$ is given. If for $A \subset X$ any open set $O$ containing $x$ satisfies $O \cap ( A \setminus \left\{ x \right\} ) \ne \emptyset$, then $x$ is called a limit point of $A$, and the set of all limit points of $A$ is called the derived set of $A$. A sequence $\left\{ x_{n} \right\}$ in $X$ converges</description>
    </item>
    <item>
      <title>What is a Topological Space?</title>
      <link>https://freshrimpsushi.github.io/en/posts/398/</link>
      <pubDate>Fri, 26 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/398/</guid>
      <description>Definition Topological Space 1 Given a set $X$, if $\mathscr{T} \subset \mathscr{P} (X)$ satisfies the following three conditions for $T \in \mathscr{T}$, then $\mathscr{T}$ is called the topology of $X$, and $\left( X , \mathscr{T} \right)$ is called a Topological Space. (i): $$\emptyset , X \in \mathscr{T}$$ (ii): $$\displaystyle \bigcup_{ \alpha \in \forall } T_{\alpha} \in \mathscr{T}$$ (iii): $$\displaystyle \bigcap_{ i= 1}^{n} T_{i} \in \mathscr{T}$$ Explained in words, conditions (i)~(iii)</description>
    </item>
    <item>
      <title>Completeness and Density in Metric Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/396/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/396/</guid>
      <description>Definition 1 Let&amp;rsquo;s say for a metric space $\left( X , d \right)$. If for every sequence $\left\{ x_{n} \right\}$ in $X$ there exists a natural number $n_{0}$ that satisfies $d(x_{n} , x_{m}) &amp;lt; \varepsilon$ whenever $\varepsilon &amp;gt; 0$ for all $n,m &amp;gt; n_{0}$, it is called a Cauchy sequence. If the limiting points of Cauchy sequences in $\left( X , d \right)$ belong to $X$, then $\left( X ,</description>
    </item>
    <item>
      <title>Cyclic Groups in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/392/</link>
      <pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/392/</guid>
      <description>Definition 1 A group $G$, having an element $a$ and for any $x \in G$ there exists an integer $n \in \mathbb{Z}$ satisfying $x = a^{n}$, is called a Cyclic Group, and $a$ is called a Generator. Explanation Simply put, if all elements of a group can be expressed as the power of a generator, then it is a cyclic group. The term &amp;lsquo;cyclic&amp;rsquo; is quite apt since it involves</description>
    </item>
    <item>
      <title>Balls and Open Sets, Closed Sets in Metric Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/382/</link>
      <pubDate>Thu, 18 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/382/</guid>
      <description>Definition Given a metric space where $\left( X, d \right)$, let $a \in X$ and $r &amp;gt; 0$. An open ball with center $a$ and radius $r$ is denoted by $B_{d} (a,r) = \left\{ x \in X \ | \ d(a,x) &amp;lt; r \right\}$. A closed ball with center $a$ and radius $r$ is denoted by $B_{d} [a,r] = \left\{ x \in X \ | \ d(a,x) \le r \right\}$.</description>
    </item>
    <item>
      <title>Definition of a Metric Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/381/</link>
      <pubDate>Wed, 17 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/381/</guid>
      <description>Definition A function $d : X \times X \to [0, \infty)$ on a set set $X$ is called a distance and $\left( X, d\right)$ is called a metric space if it satisfies the following conditions with respect to $x,y,z \in X$. If the distance is trivial, the metric space is also simply denoted by $X$. $d(x,y)=0 \iff x = y$ $d(x,y) = d(y,x)$ $d(x,y) + d(y,z) \ge d(x,z)$ Explanation As</description>
    </item>
    <item>
      <title>Least Squares Method</title>
      <link>https://freshrimpsushi.github.io/en/posts/356/</link>
      <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/356/</guid>
      <description>Definition1 Let&amp;rsquo;s say that a linear system $A\mathbf{x} = \mathbf{b}$ with a matrix $A \in \mathbb{C}^{m \times n}$ and a vector $\mathbf{b} \in \mathbb{C}^{m}$ is either overdetermined or underdetermined. In this case, the system either does not have a solution or has infinitely many. Here, consider the problem of minimizing the value of $$ \left\| A \mathbf{x} - \mathbf{b} \right\|_{2} $$ This is called the Least Squares Problem (LSP). The</description>
    </item>
    <item>
      <title>Matrix Projection in Linear Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/352/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/352/</guid>
      <description>Definition A square matrix $P \in \mathbb{C}^{m \times m}$ is a projector if $P^2 = P$. Explanation In algebraic terms, this is referred to as an idempotent, which similarly refers to an element like $a^2 = a$. If $P$ is a projection, then $(I-P)^2 = I - 2P + P^2 = I - 2P + P = (I-P)$, so it can be known that $(I-P)$ is also a projection. Such</description>
    </item>
    <item>
      <title>Direct Sum in Vector Spaces</title>
      <link>https://freshrimpsushi.github.io/en/posts/353/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/353/</guid>
      <description>Definition A vector space $V$ is said to be the direct sum of its two subspaces $W_{1}$ and $W_{2}$ if it satisfies the following, denoted by $V = W_{1} \oplus W_{2}$. (i) Existence: For any $\mathbf{v} \in V$, there exist $\mathbf{v}_{1} \in W_{1}$ and $\mathbf{v}_{2} \in W_{2}$ satisfying $\mathbf{v} = \mathbf{v}_{1} + \mathbf{v}_{2}$. (ii) Exclusivity: $W_{1} \cap W_{2} = \left\{ \mathbf{0} \right\}$ (iii) Uniqueness: For a given $\mathbf{v}$, there exists</description>
    </item>
    <item>
      <title>Singular Value Decomposition of a Matrix</title>
      <link>https://freshrimpsushi.github.io/en/posts/340/</link>
      <pubDate>Sat, 23 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/340/</guid>
      <description>Overview While it would be great if every matrix could be decomposed through eigenvalue diagonalization, unfortunately, this method is limited by the requirement that the given matrix must be a square matrix. We aim to extend decomposability to matrices that are not square. Buildup Let us consider two natural numbers $m &amp;gt; n$ for a matrix $A \in \mathbb{C}^{ m \times n}$ whose coefficients are given by $\text{rank} A =</description>
    </item>
    <item>
      <title>Eigenvalue Diagonalization of Invertible Matrices</title>
      <link>https://freshrimpsushi.github.io/en/posts/339/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/339/</guid>
      <description>Definition If there exists a unitary matrix $Q$ and a diagonal matrix $\Lambda$ that satisfy $A = Q^{ \ast } \Lambda Q$ for $A \in \mathbb{C}^{ m \times m }$, then the matrix $A$ is said to be unitarily diagonalizable.</description>
    </item>
    <item>
      <title>How to import built-in datasets in R</title>
      <link>https://freshrimpsushi.github.io/en/posts/331/</link>
      <pubDate>Fri, 24 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/331/</guid>
      <description>Overview R is a representative statistical programming language that not only provides useful methods but also offers data sets that are good as examples. Without such data sets, one would have to download and load new data every time when giving lectures. Guide The method to load a data set is very simple. All you need to do is assign the name of the data set you want to load</description>
    </item>
    <item>
      <title>Commutative Groups in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/309/</link>
      <pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/309/</guid>
      <description>Definition 1 A group $\left&amp;lt; G, \ast\ \right&amp;gt;$ is defined to be an Abelian Group if for any two elements $a, b$ in $a \ast\ b = b \ast\ a$, $\left&amp;lt; G, \ast\ \right&amp;gt;$ satisfies the commutative property. Explanation The term &amp;ldquo;commutative&amp;rdquo; implies that the commutative law is applicable. In English, instead of Commutative, the term Abelian is used, named after the genius mathematician Abel. It is perfectly fine to</description>
    </item>
    <item>
      <title>Proof of the Residue Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/308/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/308/</guid>
      <description>Theorem 1 Let the analytic function $f: A \subset \mathbb{C} \to \mathbb{C}$ have a finite number of singularities $z_{1} , z_{2} , \cdots , z_{m}$ inside a simple closed path $\mathscr{C}$. Then, $$ \int_{\mathscr{C}} f(z) dz = 2 \pi i \sum_{k=1}^{m} \text{Res}_{z_{k}} f(z) $$ Explanation At first glance, the theorem might seem quite confusing. One has to calculate the integral, but instead of calculus-like computations, there&amp;rsquo;s talk about singularities and</description>
    </item>
    <item>
      <title>What is the Laurent Series?</title>
      <link>https://freshrimpsushi.github.io/en/posts/290/</link>
      <pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/290/</guid>
      <description>Buildup Taylor&amp;rsquo;s theorem generalizes the mean value theorem regarding the number of differentiations. It expands from dealing with something differentiated $1$ times to $n \in \mathbb{N}$ times. But if it was possible to generalize it to natural numbers, could it not be generalized to all integers? Of course, it&amp;rsquo;s not possible to differentiate $-n$ times, but what about considering integration, which is the inverse operation of differentiation? Here we introduce</description>
    </item>
    <item>
      <title>Types of Singularities in Complex Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/281/</link>
      <pubDate>Sat, 04 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/281/</guid>
      <description>Definitions Singularity 1 If the function $f$ is differentiable at all points of $\mathcal{N}(\alpha)$ in $\alpha$, it is said to be analytic at $\alpha$. If the function $f$ is not analytic in $\alpha \in \mathbb{C}$ but is analytic at some points of $\mathcal{N}(\alpha)$, $\alpha$ is called a Singular Point of $f$. If there exists $\mathcal{N}(\alpha)$ that is analytic at all points except for $\alpha$, then $\alpha$ is said to be</description>
    </item>
    <item>
      <title>Linear Independence and Linear Dependence</title>
      <link>https://freshrimpsushi.github.io/en/posts/253/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/253/</guid>
      <description>Definition1 Let&amp;rsquo;s denote a non-empty subset of vector space $V$ as $S = \left\{ \mathbf{v}_{1}, \mathbf{v}_{2}, \dots, \mathbf{v}_{r} \right\}$. For constants $k_{1}, k_{2}, \dots, k_{r}$, the following equation $$ k_{1} \mathbf{v}_{1} + k_{2} \mathbf{v}_{2} + \dots + k_{r} \mathbf{v}_{r} = \mathbf{0} $$ has at least one solution $$ k_{1} = 0,\ k_{2} = 0,\ \dots,\ k_{r} = 0 $$ This is called a trivial solution. If the trivial solution is</description>
    </item>
    <item>
      <title>In Group Theory in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/278/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/278/</guid>
      <description>Definition 1 For elements $a$ and the identity element $e$ of a monoid $\left&amp;lt; G, \ast\ \right&amp;gt;$, if there exists $a &#39;$ satisfying $a \ast\ a&amp;rsquo; = a&amp;rsquo; \ast\ a = e$, then $\left&amp;lt; G, \ast\ \right&amp;gt;$ is defined as a Group. That is, a group is a binary operation structure that satisfies the following properties: (i): The operation is associative. (ii): An identity element exists for all elements. (iii):</description>
    </item>
    <item>
      <title>Monoids in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/277/</link>
      <pubDate>Tue, 31 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/277/</guid>
      <description>Definition 1 A semigroup $\left&amp;lt; M , \ast\ \right&amp;gt;$ is defined to be a monoid if there exists an element $e$ such that for all elements $a$ of $\left&amp;lt; M , \ast\ \right&amp;gt;$, $a \ast\ e = e \ast\ a = a$ is satisfied. Explanation A monoid is a semigroup with an identity element. Introducing the concept of an identity element considerably broadens the scope of discussion. Let&amp;rsquo;s look at</description>
    </item>
    <item>
      <title>Binary Operations in Abstract Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/275/</link>
      <pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/275/</guid>
      <description>Buildup Mathematics can be broadly divided into three categories: geometry, analysis, and algebra. Among these, algebra was a branch of mathematics dealing with binomials, reduction, etc., in the curriculum. Algebra essentially aimed to solve any equation using letters instead of numbers. It sought after a general and powerful method of solution, not limited to specific numbers, thus could be considered cutting-edge technology of the time. However, these mathematical techniques have</description>
    </item>
    <item>
      <title>Convex Functions, Concave Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/262/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/262/</guid>
      <description>Definition Given an interval $I \subset \mathbb{R}$, two elements $x_{1} , x_{2}$ and functions $f : I \to \mathbb{R}$ and $0 \le t \le 1$, When $f( t x_{1} + (1-t) x_{2}) \le t f(x_{1}) + (1-t) f(x_{2})$, $f$ is defined as a convex function on $I$. When $f( t x_{1} + (1-t) x_{2}) \ge t f(x_{1}) + (1-t) f(x_{2})$, $f$ is defined as a concave function on $I$. Explanation</description>
    </item>
    <item>
      <title>Cross Product in Three-Dimensional Euclidean Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/256/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/256/</guid>
      <description>Definition The cross product of $\mathbf{x}$ and $\mathbf{y}$ is defined in terms of $\mathbf{x}, \mathbf{y} \in \mathbb{R}^3$. $$ \begin{align*} \mathbf{x} \times \mathbf{y} =&amp;amp; (x_{2}y_{3} - x_{3}y_{2}, x_{3}y_{1} - x_{1}y_{3}, x_{1}y_{2} - x_{2}y_{1}) \\ =&amp;amp; \det \begin{bmatrix} \mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} \\ x_{1} &amp;amp; x_{2} &amp;amp; x_{3} \\ y_{1} &amp;amp; y_{2} &amp;amp; y_{3} \end{bmatrix} \\ =&amp;amp; \begin{bmatrix} 0 &amp;amp; -x_{3} &amp;amp; x_{2} \\ x_{3} &amp;amp; 0 &amp;amp; -x_{1} \\ -x_{2}</description>
    </item>
    <item>
      <title>Inner product in Euclidean space</title>
      <link>https://freshrimpsushi.github.io/en/posts/255/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/255/</guid>
      <description>Definition Let&amp;rsquo;s say $V = \mathbb{R}^n$ for a vector space, and also $\mathbb{x}, \mathbb{y}, \mathbb{z} \in V$ and $k \in \mathbb{R}$. $\left&amp;lt; \cdot , \cdot \right&amp;gt; : V^2 \to \mathbb{R}$ is defined as the inner product on $V$ when it satisfies the following four conditions: (1) Symmetry: $\left&amp;lt; \mathbb{x} , \mathbb{y} \right&amp;gt; = \left&amp;lt; \mathbb{y}, \mathbb{x} \right&amp;gt;$ (2) Additivity: $\left&amp;lt; \mathbb{x} + \mathbb{y} , \mathbb{z} \right&amp;gt; = \left&amp;lt; \mathbb{x}, \mathbb{z}</description>
    </item>
    <item>
      <title>Row Space, Column Space, Null Space</title>
      <link>https://freshrimpsushi.github.io/en/posts/254/</link>
      <pubDate>Tue, 03 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/254/</guid>
      <description>Definition1 $$ A = \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn} \end{bmatrix} $$ For a matrix $A$, the $m$ number of $\mathbb{R}^{n}$ vectors made from the rows of $A$ $$ \begin{align*} \mathbf{r}_{1} =&amp;amp; \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \end{bmatrix} \\ \mathbf{r}_{2} =&amp;amp;</description>
    </item>
    <item>
      <title>Conjugate Complex Number</title>
      <link>https://freshrimpsushi.github.io/en/posts/245/</link>
      <pubDate>Sat, 23 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/245/</guid>
      <description>Definition Let&amp;rsquo;s define a complex number as $z$ with $z=a+ib(a,b\in \mathbb{R})$. $\overline{z}$ is defined as follows and is called the Complex Conjugate of $z$. $$ \overline{z}:=\overline{a+ib}=a-ib $$ Explanation It can be explained as substituting $-i$ for $i$ in the original complex number, and as a reflection across the real axis on the complex plane. The term conjugate seems to be named because it forms a pair that produces a real</description>
    </item>
    <item>
      <title>What is a Generating Function?</title>
      <link>https://freshrimpsushi.github.io/en/posts/232/</link>
      <pubDate>Wed, 30 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/232/</guid>
      <description>Definition A function $g$, represented in the form such as $$ g(x) =\sum \limits _{n=0}^{\infty}a_{n}x^{n}= a_{0} + a_{1} x + a_{2} x^2 + \cdots $$ for a given sequence $\left\{ a_{n} \right\}$, is called the generating function of the sequence $\left\{ a_{n}\right\}$ or simply generating function. When the sequence is $a_{n}=a_{n}(x)$, it is also denoted as follows: $$ G(x,t)=\sum \limits _{n=0}^{\infty}a_{n}(x)t^{n} $$ Explanation As sharp readers may have noticed, the</description>
    </item>
    <item>
      <title>Proof of the Fundamental Theorem of Algebra</title>
      <link>https://freshrimpsushi.github.io/en/posts/223/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/223/</guid>
      <description>Theorem 1 $n$th degree polynomial $P(x) = a_{0} + a_{1} x + a_{2} x^2 + \cdots + a_{n} x^{n}$ has exactly $n$ roots, including multiple roots. Explanation In fact, when we solve a polynomial, we usually assume that there exists a solution, but there&amp;rsquo;s no guarantee that this is always the case. For example, the quadratic polynomial $x^2+1 = 0$ does not have real roots. However, if complex numbers are</description>
    </item>
    <item>
      <title>Binomial Theorem Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/218/</link>
      <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/218/</guid>
      <description>Theorem $$ (x+y)^{n} = \sum_{r=0}^{n} {_n C _r} x^{r} y^{n-r} $$ Here, ${_n C _r}$ is defined as the Binomial Coefficient. $$ {_n C _r} = \binom{n}{r} = {{ n! } \over { r ! (n-r)! }} $$ Description It’s surprisingly useful right after you learn it in high school. Because of its versatility, it allows for the derivation of many formulas quickly and is widely used</description>
    </item>
    <item>
      <title>Definite Integration of the form e^-x^2, Gaussian Integral, Euler-Poisson Integral</title>
      <link>https://freshrimpsushi.github.io/en/posts/219/</link>
      <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/219/</guid>
      <description>Theorem The Gaussian function $f(x) := e^{-x^2}$&amp;rsquo;s integral over the entire domain is as follows. $$ \int_{-\infty}^{\infty} e^{-x^2} dx= \sqrt{\pi} $$ Description Physicist Kelvin is said to have left the remark that &amp;ldquo;one who finds this integral obvious is a mathematician&amp;rdquo;. It is also known by other names such as Gaussian integral, or Euler-Poisson integral. It&amp;rsquo;s a shocking integration for high school students and especially crucial for statistics. That&amp;rsquo;s because,</description>
    </item>
    <item>
      <title>Cauchy&#39;s Integral Formula Derivation</title>
      <link>https://freshrimpsushi.github.io/en/posts/215/</link>
      <pubDate>Wed, 09 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/215/</guid>
      <description>Theorem 1 Let the complex function $f: A \subseteq \mathbb{C} \to \mathbb{C}$ be analytic in a simply connected region $\mathscr{R}$. If a simple closed path $\mathscr{C} \subset \mathscr{R}$ contained in $\mathscr{R}$ surrounds a point $\alpha$, then the following holds: $$ f(\alpha) = {{1} \over {2 \pi i }} \int_{\mathscr{C}} {{f(z)} \over { z - \alpha }} dz $$ Derivation First, let&amp;rsquo;s show that $\displaystyle 2 \pi i = \int_{\mathscr{C} &#39;}</description>
    </item>
    <item>
      <title>Mean Value Theorem for Integrals</title>
      <link>https://freshrimpsushi.github.io/en/posts/212/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/212/</guid>
      <description>Theorem If a function $f$ is continuous on a closed interval $[a,b]$, there exists at least one $c$ in $(a,b)$ that satisfies $\displaystyle f(c) = {{1}\over {b-a} } \int_{a}^{b} f(x) dx$. Description Similar to the Mean Value Theorem but as it is used for integration, it is named as such. The usage is very similar, and its utility is by no means inferior to the Mean Value Theorem. On the</description>
    </item>
    <item>
      <title>Proof of the Fundamental Theorem of Calculus</title>
      <link>https://freshrimpsushi.github.io/en/posts/213/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/213/</guid>
      <description>Theorem1 Assume that the function $f$ is continuous on the closed interval $[a,b]$. (1) The function $\displaystyle F(x) = \int_{a}^{x} f(t) dt$ is continuous on $[a,b]$, differentiable on $(a,b)$, and satisfies $\displaystyle {{dF(x)} \over {dx}} = f(x)$. (2) For any antiderivative $F$ of $f$, $\displaystyle \int_{a}^{b} f(x) dx = F(b) - F(a)$ Explanation Of course, we use the words differentiation and integration so we can easily guess the relationship between</description>
    </item>
    <item>
      <title>Proof of Cauchy&#39;s Theorem in Complex Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/210/</link>
      <pubDate>Mon, 07 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/210/</guid>
      <description>Theorem 1 Let&amp;rsquo;s assume that $\mathscr{C}$ is a simple closed path and $f: A \subseteq \mathbb{C} \to \mathbb{C}$ is analytic in its interior and $f &#39;$ is continuous. Then, $$ \int_{\mathscr{C}} f(z) dz = 0 $$ Proof For $a \le t \le b$, $$ z(t) = x(t) + i y(t) \\ f(z) = u(x,y) + i v(x,y) $$ then since $\displaystyle {{dz} \over {dt}} = x &#39; + i y</description>
    </item>
    <item>
      <title>Summation Summary of Random Variables Following a Specific Distribution</title>
      <link>https://freshrimpsushi.github.io/en/posts/202/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/202/</guid>
      <description>Theorem Let&amp;rsquo;s say the random variables $X_{1} , \cdots , X_{n}$ are mutually independent. [1] Binomial distribution: If $X_i \sim \text{Bin} ( n_{i}, p)$, then $$ \sum_{i=1}^{m} X_{i} \sim \text{Bin} \left( \sum_{i=1}^{m} n_{i} , p \right) $$ [2] Poisson distribution: If $X_i \sim \text{Poi}( m_{i} )$, then $$ \sum_{i=1}^{n} X_{i} \sim \text{Poi} \left( \sum_{i=1}^{n} m_{i} \right) $$ [3] Gamma distribution: If $X_i \sim \Gamma ( k_{i}, \theta)$, then $$ \sum_{i=1}^{n}</description>
    </item>
    <item>
      <title>Euler&#39;s Reflection Formula Derivation</title>
      <link>https://freshrimpsushi.github.io/en/posts/192/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/192/</guid>
      <description>Formulas For non-integer $p$, $$ {\Gamma (1-p) \Gamma ( p )} = { {\pi} \over {\sin \pi p } } $$ Description It is the most famous formula among the formulas using the Gamma function. A useful result that can be obtained from the reflection formula is $ \Gamma ( { 1 \over 2} ) = \sqrt{\pi}$. Perhaps that’s why? The name &amp;ldquo;reflection formula&amp;rdquo; is</description>
    </item>
    <item>
      <title>Proof of the Euler Representation of the Sinc Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/187/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/187/</guid>
      <description>Theorem Definition of Sinc Function The following function $\text{sinc} : \mathbb{R} \to \mathbb{R}$ is called the Sinc Function. $$ \text{sinc} x := \begin{cases} \displaystyle {{\sin x} \over {x}} &amp;amp; , \text{if } x \ne 0 \\ 1 &amp;amp; , \text{if } x = 0 \end{cases} $$ Euler Representation $$ \text{sinc} x = \prod_{n=1}^{\infty} \left( 1 - {{x^2} \over { \pi^2 n^2}} \right) $$ Explanation The Sinc function is the function</description>
    </item>
    <item>
      <title>A Comprehensive Summary of Various Series Tests in Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/186/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/186/</guid>
      <description>Overview This post will introduce several series convergence tests without diving into their proofs. It is often more valuable to utilize these tests as facts, especially since the proofs can be quite tedious. In this post, we use the following notations: $\mathbb{N}$ is the set containing all natural numbers. $\mathbb{R}$ is the set containing all real numbers, and $\overline{\mathbb{R}}$ is the extended real number set that includes $\pm \infty$. $\left\{</description>
    </item>
    <item>
      <title>Proof of the Density of Real Numbers</title>
      <link>https://freshrimpsushi.github.io/en/posts/185/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/185/</guid>
      <description>Theorem For two real numbers $a&amp;lt;b$, there exists a $r \in \mathbb{R}$ that satisfies $a&amp;lt;r&amp;lt;b$. Explanation In the real number space, no matter what interval you consider, there is always another real number in between. No matter how much you split it, there is a point that can be further divided. Although it seems obvious, keep in mind that this is not only non-obvious but also highly abstract. As an</description>
    </item>
    <item>
      <title>Three Axioms of Analysis: The Axiom of Completeness</title>
      <link>https://freshrimpsushi.github.io/en/posts/180/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/180/</guid>
      <description>Axioms1 A set $E \subset \mathbb{R}$ is not empty and if $E$ is bounded above, then a supremum $\sup(E) &amp;lt; \infty$ exists. Explanation The axioms of fields and orders might seem like complicating the known, but the completeness axiom does not seem so at a glance. Definitions for the terminology used here appear to be necessary first. Definitions For every element $a$ of $E$ if $a \le M$ is satisfied,</description>
    </item>
    <item>
      <title>Three Axioms of Analysis: 1 Field Axioms</title>
      <link>https://freshrimpsushi.github.io/en/posts/178/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/178/</guid>
      <description>Axioms1 Let&amp;rsquo;s accept the following properties for real numbers $a,b,c \in \mathbb{R}$ and operations $+,\cdot$. (A1) Closure under addition: $a+b \in \mathbb{R}$ (A2) Associative law for addition: $(a+b) + c = a + (b+c)$ (A3) Commutative law for addition: $ a+ b= b + a$ (A4) Identity element for addition: For every real number $a$, there exists a unique $0$ satisfying $a+0=0+a=a$. (A5) Inverse element for addition: For every real</description>
    </item>
    <item>
      <title>Finding the Sum of a Geometric Sequence</title>
      <link>https://freshrimpsushi.github.io/en/posts/170/</link>
      <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/170/</guid>
      <description>Formula Given a geometric sequence $a_{n} = a r^{n-1}$ with the first term $a$ and common ratio $r$, $$ \sum_{k=1}^{n} a_{k}= {{a (1- r^{n} ) } \over {1-r}} $$ Proof Let&amp;rsquo;s denote it as $\displaystyle S= \sum_{k=1}^{n} a_{k}$. Then, $$ S= a + ar + \cdots + ar^{n-2} + ar^{n-1} $$ Multiplying both sides by $r$ gives $$ rS= ar + a r^2 + \cdots + ar^{n-1} + ar^{n} $$</description>
    </item>
    <item>
      <title>Proof of Fubini&#39;s Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/165/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/165/</guid>
      <description>Theorem1 2 Let&amp;rsquo;s define the function $f : R \to \mathbb{R}$ on the 2-dimensional domain $R : [a,b] \times [c,d]$. If $f(x,\cdot)$ is integrable over $[c,d]$, and $f(\cdot,y)$ is integrable over $[a,b]$, and $f$ is integrable over $R$, then $$ \iint _{R} f dA = \int_{a}^{b} \int_{c}^{d} f(x,y) dy dx = \int_{c}^{d} \int_{a}^{b} f(x,y) dx dy $$ Explanation The integration domain $R$ obviously comes from a Rectangle. As it is</description>
    </item>
    <item>
      <title>Proof of Green&#39;s Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/166/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/166/</guid>
      <description>Theorem1 Let the curve $\mathcal{C}$ be a simple, smooth, closed path in the plane $S = [a,b] \times [c,d]$, moving counterclockwise. If the function $P,Q : \mathbb{R}^2 \to \mathbb{R}$ is continuous on $\mathcal{C}$ and its derivative is also continuous, $$ \int_{\mathcal{C}} (Pdx + Qdy) = \iint_{S} (Q_{x} - P_{y}) dx dy $$ Explanation This can be thought of as a theorem that converts line integrals into surface integrals. It&amp;rsquo;s widely</description>
    </item>
    <item>
      <title>Proof of ML Auxiliary Lemma</title>
      <link>https://freshrimpsushi.github.io/en/posts/162/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/162/</guid>
      <description>Summary 1 Let&amp;rsquo;s say the function $f$ is piecewise continuous on the integration path $\mathscr{C}: z = z(t), t \in [a,b]$. If the positive number $\displaystyle L = \int_{a}^{b} |z&amp;rsquo;(t)| dt$ is the length of $\mathscr{C}$, and for all points on $\mathscr{C}$ there exists a positive number $M$ satisfying $|f(z)| \le M$, then $$ \left| \int_{\mathscr{C}} f(z) dz \right| \le ML $$ Proof For the function $z&amp;rsquo;: [a,b] \to \mathbb{C}$</description>
    </item>
    <item>
      <title>Pythagorean Theorem Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/161/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/161/</guid>
      <description>Theorem Given a right-angled triangle, if we call the length of the hypotenuse $c$, and the lengths of the other two sides $a,b$, then the following equation holds. $$ a^2 + b^2 = c^2 $$ Explanation Apart from its wide applications, this theorem is very practical in itself. It&amp;rsquo;s named after Pythagoras for leaving behind the oldest &amp;lsquo;proof&amp;rsquo;, but it is speculated that most ancient civilizations, which could be considered</description>
    </item>
    <item>
      <title>The Relationship between Trigonometric and Hyperbolic Functions in Complex Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/157/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/157/</guid>
      <description>Definition 1 Let&amp;rsquo;s define the hyperbolic function as a complex function $\sinh, \cosh : \mathbb{C} \to \mathbb{C}$ as follows. $$ \sinh z := { {e^{z} - e^{-z}} \over 2 } \\ \cosh z := { {e^{z} + e^{-z}} \over 2 } $$ Theorem 2 $$ \begin{align*} \sinh (iz) =&amp;amp; i \sin z \\ \sin (iz) =&amp;amp; i \sinh z \\ \cosh (iz) =&amp;amp; \cos z \\ \cos (iz) =&amp;amp; \cosh</description>
    </item>
    <item>
      <title>Calculus and the Euler Formula</title>
      <link>https://freshrimpsushi.github.io/en/posts/112/</link>
      <pubDate>Tue, 23 May 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/112/</guid>
      <description>Theorem Euler&amp;rsquo;s Formula: $$ { e }^{ ix }= \cos x + i \sin x $$ Euler&amp;rsquo;s Identity: $$ { e }^{ i\pi }+1=0 $$ Explanation Euler&amp;rsquo;s Formula is in itself so peculiar that even Euler did not know where it might be used, but nowadays, it is utilized in so many fields that it is difficult to summarize its usefulness. It is even more astonishing when considering it was</description>
    </item>
    <item>
      <title>Congruences in Number Theory</title>
      <link>https://freshrimpsushi.github.io/en/posts/106/</link>
      <pubDate>Thu, 11 May 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/106/</guid>
      <description>Definition 1 Given integers $a \equiv b \pmod{m}$, $\iff$, $a$, $b$, $m$, there exists an integer $k$ that satisfies $a = b + mk$. Theorem Assuming $a_{1} \equiv b_{1} \pmod{m}$ and $a_{2} \equiv b_{2} \pmod{m}$ are true: [1] Addition: $a_{1} + a_{2} \equiv b_{1} + b_{2} \pmod{m}$ [2] Subtraction: $a_{1} - a_{2} \equiv b_{1} - b_{2} \pmod{m}$ [3] Multiplication: $a_{1} a_{2} \equiv b_{1} b_{2} \pmod{m}$ [4] Division: if $\gcd (</description>
    </item>
    <item>
      <title>Gamma Function</title>
      <link>https://freshrimpsushi.github.io/en/posts/95/</link>
      <pubDate>Sun, 30 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/95/</guid>
      <description>Definition The function defined as follows $\Gamma : (0, \infty) \to \mathbb{R}$ is called the Gamma function. $$ \Gamma (x) := \int_{0}^{\infty} t^{x-1} e^{-t} dt $$ Description Focusing on the integral in the equation above, it is also referred to as Euler&amp;rsquo;s integral. The Gamma function is famous as an exceedingly important function not just in pure mathematics but also in physics, statistics, etc. It possesses a plethora of interesting</description>
    </item>
    <item>
      <title>Exponential, Sine, and Cosine Functions&#39; Taylor Series Expansion</title>
      <link>https://freshrimpsushi.github.io/en/posts/59/</link>
      <pubDate>Tue, 11 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/59/</guid>
      <description>Theorem1 $$ \begin{equation} { { e ^ x } }=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ n } }{ n! } } \end{equation} $$ $$ \begin{equation} \sin x=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ 2n+1 } }{ (2n+1)! }{ { (-1) }^{ n } } } \end{equation} $$ $$ \begin{equation} \cos x=\sum _{ n=0 }^{ \infty }{ \frac { {</description>
    </item>
    <item>
      <title>Derivation of the Quadratic Formula Step by Step</title>
      <link>https://freshrimpsushi.github.io/en/posts/56/</link>
      <pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/56/</guid>
      <description>Formulas For the quadratic equation $ax^{2}+bx+c=0$ (where $a\neq 0$): $$ x=\dfrac{ -b\pm \sqrt { b^{2}-4ac } }{2a} $$ Explanation Given a quadratic equation, its roots can be easily found through the formula. Derivation Strategy: The key to deriving the formula is to convert it into a complete square form. This is explained in great detail for children who are not familiar with math. Simply follow along without questioning, and try</description>
    </item>
    <item>
      <title>Cauchy-Schwarz Inequality Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/51/</link>
      <pubDate>Mon, 03 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/51/</guid>
      <description>Theorem $$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\ge { (ax+by) }^{ 2 } $$ Proof $$ \begin{align*} &amp;amp; ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})-{ (ax+by) }^{ 2 } \\ =&amp;amp; {a}^{2}{x}^{2}+{b}^{2}{x}^{2}+{a}^{2}{y}^{2}+{b}^{2}{y}^{2}-{ (ax+by) }^{ 2 } \\ =&amp;amp; {b}^{2}{x}^{2}+{a}^{2}{y}^{2}-2axby \\ =&amp;amp; { (ay-bx) }^{ 2 } \\ \ge&amp;amp; 0 \end{align*} $$ Thus, we can summarize as follows. $$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\ge { (ax+by) }^{ 2 } $$ ■ Explanation This inequality, which can be encountered as early as high school, is used widely</description>
    </item>
    <item>
      <title>Addition Formula for Trigonometric Functions: Various Proofs</title>
      <link>https://freshrimpsushi.github.io/en/posts/44/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/44/</guid>
      <description>Theorem $$ \sin\left( \alpha +\beta \right) =\sin\alpha \cos\beta +\cos\alpha \sin\beta \\ \sin\left( \alpha -\beta \right) =\sin\alpha \cos\beta -\cos\alpha \sin\beta \\ \cos\left( \alpha +\beta \right) =\cos\alpha \cos\beta -\sin\alpha \sin\beta \\ \cos\left( \alpha -\beta \right) =\cos\alpha \cos\beta +\sin\alpha \sin\beta \\ \tan\left( \alpha +\beta \right) =\frac { \tan\alpha +\tan\beta }{ 1-\tan\alpha \tan\beta } \\ \tan\left( \alpha -\beta \right) =\frac { \tan\alpha -\tan\beta }{ 1+\tan\alpha \tan\beta } $$ Proof Proof using the Law of</description>
    </item>
    <item>
      <title>Odd Functions and Even Functions</title>
      <link>https://freshrimpsushi.github.io/en/posts/40/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/40/</guid>
      <description>Definitions A function $f(x)$ that satisfies $f(-x) = f(x)$ is called an Even function. A function $f(x)$ that satisfies $f(-x) = -f(x)$ is called an Odd function. Description Even functions are symmetric about the $y$ axis in the coordinate plane, while Odd functions are symmetric about the origin $O$. For example, among the trigonometric functions, $\sin$ is Odd and $\cos$ is Even. Differentiating $\sin$ yields $\cos$, and differentiating $\cos$ yields</description>
    </item>
    <item>
      <title>Proof of Rolle&#39;s Theorem in Calculus</title>
      <link>https://freshrimpsushi.github.io/en/posts/36/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/36/</guid>
      <description>Summary1 If the function $f(x)$ is continuous at $[a,b]$ and differentiable at $(a,b)$ and if $f(a)=f(b)$, then there exists at least one $c$ in $(a,b)$ that satisfies $f &#39; (c)=0$. Description In high school courses, it is introduced only as an auxiliary lemma to prove the mean value theorem and is not used at all otherwise. However, beyond the high school level, it is sometimes used as an auxiliary lemma.</description>
    </item>
    <item>
      <title>Proof of Taylor&#39;s Theorem</title>
      <link>https://freshrimpsushi.github.io/en/posts/41/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/41/</guid>
      <description>Theorem1 If a function $f(x)$ is continuous at $[a,b]$ and differentiable up to $n$ times at $(a,b)$, then there exists $\xi \in (a,b)$ that satisfies $$ \begin{align*} f(b) =&amp;amp; \sum_{k=0}^{n-1} {{(b-a)^{k}\over{k!}}{f^{(k)}( a )}} + {(b-a)^{n}\over{n!}}{f^{(n)}(\xi)} \\ =&amp;amp; {f(a)} + {(b-a)f &#39; (a)} + \cdots + {(b-a)^{n-1}\over{(n-1)!}}{f^{(n-1)}(a)} + {(b-a)^{n}\over{(n)!}}{f^{(n)}(\xi)} \end{align*} $$ Explanation This theorem, which is widely used throughout mathematics, has lent its name to the Taylor series. In terms of</description>
    </item>
    <item>
      <title>Proof of the Mean Value Theorem in Calculus</title>
      <link>https://freshrimpsushi.github.io/en/posts/37/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/37/</guid>
      <description>Theorem1 If the function $f(x)$ is continuous at $[a,b]$ and differentiable at $(a,b)$, then there exists at least one $c$ in $(a,b)$ that satisfies $\displaystyle f &#39;(c)={{f(b)-f(a)}\over{b-a}}$. Description It&amp;rsquo;s not just commonly used; it&amp;rsquo;s so famous that it&amp;rsquo;s abbreviated as MVT. The term &amp;lsquo;mean value&amp;rsquo; comes from the idea that there is a point where the derivative equals the average rate of change over the entire interval. The concept of</description>
    </item>
    <item>
      <title>Taylor Series and Maclaurin Series</title>
      <link>https://freshrimpsushi.github.io/en/posts/42/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/42/</guid>
      <description>Theorem1 A function $f$ that is infinitely differentiable around point $a$, a necessary and sufficient condition for $\displaystyle f(x) = \sum_{n=0}^{\infty} {{f^{(n)} (a)}\over{n!}} {(x-a)}^n$ is that for some $\xi \in \mathscr{H} \left\{ x , a \right\}$ $$ \lim_{n \to \infty} {{f^{(n)} (\xi)}\over{n!}} {(x-a)}^n = 0 $$ where $\xi \in \mathscr{H} \left\{ x , a \right\}$ means that $\xi$ is in either $(x,a)$ or $(a,x)$. Explanation The Taylor theorem often represents</description>
    </item>
    <item>
      <title>Proof of Bayes&#39; Theorem and Prior, Posterior Distributions</title>
      <link>https://freshrimpsushi.github.io/en/posts/29/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/29/</guid>
      <description>Theorem 1 Sample Space $S$ and Event $A$, Probability $P$ If $\left\{ S_1, S_2, \cdots ,S_n \right\}$ is a partition of $S$, then the following holds. $$ P(S_k|A)=\frac { P(S_k)P(A|S_k) }{ \sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$ Definition The right-hand side of Bayes&amp;rsquo; theorem, $P \left( S_{k} \right)$, is called the Prior Probability, and the left-hand side, $P \left( S_{k} | A \right)$, is called the</description>
    </item>
    <item>
      <title>Derivation of the Formula to Calculate the Distance Between Two Parallel Lines</title>
      <link>https://freshrimpsushi.github.io/en/posts/4/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/4/</guid>
      <description>Formulas $$ d=\frac { |2k| }{ \sqrt { m^{ 2 }+1 } } $$ Explanation When solving problems involving the tangent to a conic section, one often needs to calculate the distance between two tangents. While it&amp;rsquo;s not particularly challenging, thanks to the formula for the distance from a given point to a line, having an easy and quick formula for this distance can help to reduce calculation time. Derivation</description>
    </item>
    <item>
      <title>Ernestrom-Kakeya Theorem Proof</title>
      <link>https://freshrimpsushi.github.io/en/posts/5/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/5/</guid>
      <description>Theorem 1 Let $\left\{ a_{i} \right\}_{i=0}^{n} \subset \mathbb{R}$ such that $a_0 &amp;gt; a_1 &amp;gt; \cdots &amp;gt; a_n &amp;gt; 0$. Then for the polynomial function $$ P(z) := a_0 + a_1 z + \cdots + a_{n-1} z^{n-1} + a_n z^n $$ all roots $z \in \mathbb{C}$ satisfy $|z| \ge 1$. Proof If there is a root of $P(z) = 0$ at $z=1$, then we have $\displaystyle 0 = P(1) = \sum_{i=0}^{n}</description>
    </item>
    <item>
      <title>Euler&#39;s Proof of the Divergence of the Harmonic Series</title>
      <link>https://freshrimpsushi.github.io/en/posts/17/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/17/</guid>
      <description>Theorem The harmonic series diverges. $$ \sum _{ n=1 }^{ \infty }{ \frac { 1 }{ n } }=\infty $$ Description At first glance, the harmonic series appears as if it would converge since its terms continue to decrease in value. However, Oresme elegantly and simply proved that it diverges. This fact is often used as an example to explain the concept of absolute convergence, where the alternating harmonic series</description>
    </item>
    <item>
      <title>Arithmetic, Geometric, and Harmonic Means Inequality</title>
      <link>https://freshrimpsushi.github.io/en/posts/3/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/3/</guid>
      <description>Definitions For $n$ positive numbers ${x}_1,{x}_2,\cdots,{x}_n$, the arithmetic mean, geometric mean, and harmonic mean are defined as: Arithmetic Mean : $$ \sum_{ k=1 }^{ n }{ \frac { {x}_k }{ n } }=\frac { {x}_1+{x}_2+\cdots+{x}_n }{ n } $$ Geometric Mean : $$ \prod_{ k=1 }^{ n }{ { {x}_k }^{ \frac { 1 }{ n } } }=\sqrt [ n ]{ {x}_1{x}_2\cdots{x}_n } $$ Harmonic Mean : $$ \left(</description>
    </item>
    <item>
      <title>How to Use Decision Trees in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2618/</link>
      <pubDate>Tue, 26 Aug 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2618/</guid>
      <description>Overview Introducing the DecisionTree.jl package, which implements Decision Trees in Julia1. Code As an example, we use the iris dataset, a classic built-in dataset in R. Our goal is to create a decision tree that uses four variables SepalLength, SepalWidth, PetalLength, PetalWidth to predict Species and evaluate its performance. julia&amp;gt; iris = dataset(&amp;#34;datasets&amp;#34;, &amp;#34;iris&amp;#34;) 150×5 DataFrame Row │ SepalLength SepalWidth PetalLength PetalWidth Speci ⋯ │ Float64</description>
    </item>
    <item>
      <title>How to Remove Duplicates from a Collection in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2616/</link>
      <pubDate>Fri, 22 Aug 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2616/</guid>
      <description>Overview This section introduces how to remove and check for duplicates in collections in Julia. The unique() function, which eliminates duplicates, is algorithmically straightforward, but can be bothersome to implement on your own, and may not be efficient. The allunique() function, which checks for the absence of duplicate elements, is easy enough to implement that one might not have sought it out, so it’s worth getting familiar</description>
    </item>
    <item>
      <title>How to Use Clustering Packages in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2613/</link>
      <pubDate>Sat, 16 Aug 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2613/</guid>
      <description>Overview In Julia, the package for clustering offered is Clustering.jl1. The algorithms implemented include: K-means K-medoids Affinity Propagation Density-based spatial clustering of applications with noise (DBSCAN) Markov Clustering Algorithm (MCL) Fuzzy C-Means Clustering Hierarchical Clustering Single Linkage Average Linkage Complete Linkage Ward&amp;rsquo;s Linkage Code DBSCAN DBSCAN (Density-based spatial clustering of applications with noise) is implemented with the dbscan() function. If there are $n$ pieces of data in $p$ dimensions, a</description>
    </item>
    <item>
      <title>Julia&#39;s Automatic Differentiation Package Zygote.jl</title>
      <link>https://freshrimpsushi.github.io/en/posts/2609/</link>
      <pubDate>Fri, 08 Aug 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2609/</guid>
      <description>Overview In Julia, the Zygote.jl package is used for automatic differentiation, especially in the field of machine learning, and particularly for deep learning. The developers promote this package as the next-generation automatic differentiation system that enables differentiable programming in Julia, and indeed, using it can be surprisingly intuitive. If you are curious about packages related to the derivative itself, not automatic differentiation, check out the Calculus.jl package. Code Univariate Functions</description>
    </item>
    <item>
      <title>Referencing Struct Properties as Functions in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2607/</link>
      <pubDate>Mon, 04 Aug 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2607/</guid>
      <description>Overview In Julia, there are mainly two ways to reference the properties of a structure. They should be used appropriately according to grammatical convenience or actual use. Code For example, in Julia, the // operator creates a Rational type of number as follows. The names of the properties that a rational number has include :num meaning numerator and :den meaning denominator. julia&amp;gt; q = 7 // 12 7//12 julia&amp;gt; q</description>
    </item>
    <item>
      <title>How to Draw Vector Fields in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2605/</link>
      <pubDate>Thu, 31 Jul 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2605/</guid>
      <description>Code quiver(, quiver=) In Julia, the quiver() function can be used to visualize a vector field. θ = 0:0.2:2π quiver(cos.(θ),sin.(θ), quiver = (-sin.(θ), cos.(θ)),</description>
    </item>
    <item>
      <title>Referencing Specific Positions in an Array with Functions in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2603/</link>
      <pubDate>Sun, 27 Jul 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2603/</guid>
      <description>Overview When multiple arrays are given, there are often situations where one wants to access a specific element of these arrays, for example, the third element in each array. In Julia, this can be implemented through broadcasting the getindex() function. Code getindex.() julia&amp;gt; seq_ = [collect(1:k:100) for k in 1:10] 10-element Vector{Vector{Int64}}: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 … 91, 92, 93, 94, 95, 96, 97,</description>
    </item>
    <item>
      <title>How to Import Packages from Julia to R</title>
      <link>https://freshrimpsushi.github.io/en/posts/2601/</link>
      <pubDate>Wed, 23 Jul 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2601/</guid>
      <description>Overview The way to load a package in Julia is to use using, but as the program grows, it becomes a task to individually write them each time. This introduces a method to load packages through a loop1. Code Metaprogramming packages = [:CSV, :DataFrames, :LinearAlgebra, :Plots] for package in packages @eval using ▷eq1◁(package) end In actual use,</description>
    </item>
    <item>
      <title>How to Normalize Matrices Column-wise in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2599/</link>
      <pubDate>Sat, 19 Jul 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2599/</guid>
      <description>Overview This document introduces a tip for easily normalizing matrices in Julia 1. At its core, it’s just mixing the method of scalar multiplying matrices by rows and columns, the eachcol() function, and the norm() function from the LinearAlgebra module, but it’s concise, ending in one line, and proving to be quite useful to memorize for frequent use. Code julia&amp;gt; using LinearAlgebra julia&amp;gt; X</description>
    </item>
    <item>
      <title>PLU Decomposition</title>
      <link>https://freshrimpsushi.github.io/en/posts/2/</link>
      <pubDate>Fri, 11 Jul 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2/</guid>
      <description>Definitions 1 2 For a permutation matrix $P^{T}$ and an invertible matrix $A \in \mathbb{R}^{n \times n}$, the matrix multiplication $P^{T} A$ gives us the product $LU$. This decomposition is referred to as the PLU decompositionPermutation LU Decomposition of $A$. Since $P$ is a permutation matrix, it is also an orthogonal matrix, that is $P^{-1} = P^{T}$, hence it can be written like this: $$ P^{T} A = LU \iff</description>
    </item>
    <item>
      <title>Permutation Matrix</title>
      <link>https://freshrimpsushi.github.io/en/posts/1/</link>
      <pubDate>Wed, 09 Jul 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/1/</guid>
      <description>Definition 1 $P \in \mathbb{R}^{n \times n}$ in which only one component in each row is $1$ and the rest are $0$ is called a Permutation Matrix. Basic Properties Orthogonality All permutation matrices are orthogonal matrices: $$P^{-1} = P^{T}$$ Sparseness For sufficiently large $n$, $P \in \mathbb{R}^{n \times n}$ is a sparse matrix. Explanation The Permutation Matrix gives a permutation of rows and columns through matrix multiplication. The following example</description>
    </item>
    <item>
      <title>How to Call a DataFrame without String7, String15 in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2574/</link>
      <pubDate>Mon, 26 May 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2574/</guid>
      <description>Error When using data frames in Julia, string data sometimes get read as String7, String15, String31, etc., causing various errors. Rather than specific errors occurring, the usual functions don&amp;rsquo;t work with these, causing all sorts of problems. Cause For performance reasons, String was changed to faster versions like String7, etc. It&amp;rsquo;s designed this way on purpose, so nothing much can be done about it. Solution Passing the option stringtype =</description>
    </item>
    <item>
      <title>Why Notation of Partial Differential is Different?</title>
      <link>https://freshrimpsushi.github.io/en/posts/2573/</link>
      <pubDate>Sat, 24 May 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2573/</guid>
      <description>Question In partial derivatives, unlike the usual derivatives, expressions like $\displaystyle {{ \partial f } \over { \partial t }}$ are used instead of $\displaystyle {{ d f } \over { d t }}$. $\partial$ is read as &amp;ldquo;Round Dee&amp;rdquo; or &amp;ldquo;Partial,&amp;rdquo; and historically, it originated from &amp;ldquo;Curly Dee,&amp;rdquo; which is a cursive form of $d$1. In code, it&amp;rsquo;s \partial, and in Korea, some people even shorten it to just</description>
    </item>
    <item>
      <title>How to Add a Main Title in Julia Subplots</title>
      <link>https://freshrimpsushi.github.io/en/posts/2572/</link>
      <pubDate>Thu, 22 May 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2572/</guid>
      <description>Overview When drawing figures in Julia, to apply a title to all subplots, one should use plot_title instead of title1. This is because the arguments of the outermost plot() function, in the case of a plot with subplots like plot( plot1, plot2, ... ) inherit properties to the inner subplots. To clearly distinguish between them, title and plot_title are used separately. Code plot(p1, p2, title = &amp;#34;Two Plots&amp;#34;) As you</description>
    </item>
    <item>
      <title>How to Remove Axis Values in Julia Plots</title>
      <link>https://freshrimpsushi.github.io/en/posts/2570/</link>
      <pubDate>Sun, 18 May 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2570/</guid>
      <description>Overview In Julia, there are ways to remove color bars, axes, ticks, grids, etc., but these involve graphic elements, so it&amp;rsquo;s not possible to cleanly remove numbers alone. You must use an option called formatter. formatter = (_...) -&amp;gt; &amp;quot;&amp;quot; By giving the option formatter = (_...) -&amp;gt; &amp;quot;&amp;quot; to the plot() function, it&amp;rsquo;s done. using Plots x = rand(10) y = rand(10) plot( plot(x,y) ,plot(x,y, formatter = (_...) -&amp;gt;</description>
    </item>
    <item>
      <title>How to Use Finite Difference in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2568/</link>
      <pubDate>Wed, 14 May 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2568/</guid>
      <description>Overview To use Finite Differences in Julia, more specifically to calculate the coefficients of finite differences, it is advisable to use FiniteDifferences.jl1. In cases where there is susceptibility to noise, it’s possible to use Total Variation Regularized Numerical Differentiation, known as TVDiff, implemented in NoiseRobustDifferentiation.jl. Code FiniteDifferenceMethod() julia&amp;gt; f′ = FiniteDifferenceMethod([-2, 0, 5], 1) FiniteDifferenceMethod: order of method: 3 order of derivative: 1 grid: [-2, 0,</description>
    </item>
    <item>
      <title>Numerical Interpolation in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2566/</link>
      <pubDate>Sat, 10 May 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2566/</guid>
      <description>Overview In Julia, the Interpolations.jl package is used for numerical interpolation1. Be cautious not to confuse it with the interpolation method used when printing the value of a variable in Julia[../2041]. Code Interpolate() julia&amp;gt; y = rand(10) 10-element Vector{Float64}: 0.8993801321974316 0.12988982511901515 0.49781160399025925 0.22555299914088356 0.4848674643768577 0.6089318286915111 0.10444895196527337 0.5921775799940143 0.2149546302906653 0.32749334953170317 julia&amp;gt; f = interpolate(y, BSpline(Linear())); julia&amp;gt; f(1.2) 0.7454820707817483 julia&amp;gt; f(0.1) ERROR: BoundsError: attempt to access 10-element interpolate(::Vector{Float64}, BSpline(Linear())) with element type</description>
    </item>
    <item>
      <title>Calculating the Difference of Arrays in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2564/</link>
      <pubDate>Tue, 06 May 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2564/</guid>
      <description>Overview In Julia, the diff() function is provided to calculate differences1. It&amp;rsquo;s also possible to use the circshift() function to easily create a similar effect, but dealing with end points and such can be somewhat inconvenient, so knowing how to use diff() can be much more comfortable. It can be used almost in the same way as the diff() functions in R and MATLAB, however, unlike these, Julia does not</description>
    </item>
    <item>
      <title>How to Use Circular Arrangements in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2562/</link>
      <pubDate>Fri, 02 May 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2562/</guid>
      <description>Overview Though Julia does not natively support Circular Arrays, it essentially allows for such functionality by providing the circshift() function, which pushes or pulls elements circularly1. It&amp;rsquo;s not particularly difficult to write this function yourself, but knowing it obviates the need. This function can be used almost exactly like the circshift() in MATLAB. Code This function has been introduced in the post about how to translate arrays in parallel as</description>
    </item>
    <item>
      <title>List of Markers and Line Styles in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2560/</link>
      <pubDate>Mon, 28 Apr 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2560/</guid>
      <description>Code 1 No need for a lengthy description, it literally shows what the marker and line styles look like in reality. linesytle Choose one from [:auto, :solid, :dash, :dot, :dashdot, :dashdotdot]. shape Choose one from [:none, :auto, :circle, :rect, :star5, :diamond, :hexagon, :cross, :xcross, :utriangle, :dtriangle, :rtriangle, :ltriangle, :pentagon, :heptagon, :octagon, :star4, :star6, :star7, :star8, :vline, :hline, :+, :x]. Full Code ▷code1◁ Environment OS:</description>
    </item>
    <item>
      <title>Drawing a Regression Line on a Julia Plot</title>
      <link>https://freshrimpsushi.github.io/en/posts/2558/</link>
      <pubDate>Thu, 24 Apr 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2558/</guid>
      <description>Code To insert a regression line in the scatter plot of Julia, simply use the option smooth = true. using Plots x = rand(100) scatter(x, 2x .+ 0.1randn(100), smooth = true) savefig(&amp;#34;plot.svg&amp;#34;) Environment OS: Windows julia: v1.8.3 Plots v1.38.5</description>
    </item>
    <item>
      <title>Tips for Passing Optional Arguments through the Julia Splatt Operator</title>
      <link>https://freshrimpsushi.github.io/en/posts/2554/</link>
      <pubDate>Wed, 16 Apr 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2554/</guid>
      <description>Overview In Julia, the most frequently used purpose of the ... splat is explained as the method of passing optional arguments. Basically, it uses the method of applying the splat operator to the tuple after determining in advance what options to put into which arguments, in the form of a named tuple. Code Passing to Multiple Functions args1 = (; dims = 1) The named tuple args1 above can be</description>
    </item>
    <item>
      <title>Julia&#39;s Splat Operator</title>
      <link>https://freshrimpsushi.github.io/en/posts/2552/</link>
      <pubDate>Sat, 12 Apr 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2552/</guid>
      <description>Overview In Julia, ... is called the splat operator. It is usefully employed when using functions or defining arrays1. This operator isn&amp;rsquo;t exclusive to Julia, but it&amp;rsquo;s defined in a more intuitive way compared to other languages, making it exceptionally easy to learn and understand. From personal experience, using ... seems to bring some sort of enlightenment regarding Julia programming. Code Function Input Primarily, ... is appended after an array</description>
    </item>
    <item>
      <title>Slicing Only a Part of Unicode Strings in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2550/</link>
      <pubDate>Tue, 08 Apr 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2550/</guid>
      <description>Overview As with many programming languages, in Julia, English is written in ASCII code and characters like Chinese and Korean are written in Unicode. The trouble, unlike with other languages, is that dealing with these strings is quite tricky, which is intended for performance reasons1, so one has no choice but to bear with it and use them as they are. Code julia&amp;gt; str1 = &amp;#34;English&amp;#34; &amp;#34;English&amp;#34; julia&amp;gt; str2 =</description>
    </item>
    <item>
      <title>Omitting DataFrame Names in Julia StatsPlots with Macro @df</title>
      <link>https://freshrimpsushi.github.io/en/posts/2548/</link>
      <pubDate>Fri, 04 Apr 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2548/</guid>
      <description>Overview In the StatsPlots package of Julia, the @df macro allows omitting the repeatedly mentioned dataframe name when plotting1. The syntax for using the macro, when using column a of dataframe X, is to specify which dataframe to use with @df X, followed immediately by passing the argument a as a symbol :a in the scope that follows, writing it as plot (:a). In summary, the code is written as</description>
    </item>
    <item>
      <title>How to Use Functions Defined in Other Files in Julia</title>
      <link>https://freshrimpsushi.github.io/en/posts/2544/</link>
      <pubDate>Thu, 27 Mar 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2544/</guid>
      <description>Overview Introducing the function include() which executes Julia code itself to use functions from another file. In MATLAB, if it&amp;rsquo;s in the same directory, it tends to automatically find the function, so some people think this process is hard. There is a way to properly modularize and export, but1 it is not recommended for beginners who urgently need functionality because it is difficult and complicated. It&amp;rsquo;s not too late to</description>
    </item>
    <item>
      <title>How to Color Markers in a Julia Fractal</title>
      <link>https://freshrimpsushi.github.io/en/posts/2537/</link>
      <pubDate>Thu, 13 Mar 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2537/</guid>
      <description>Code using Plots x, y = rand(100), rand(100) Given the data above, depending on whether the data is continuous or categorical, the shape of the plot and the method of plotting differ. Continuous scatter(marker_z=) z = x + y scatter(x, y, marker_z = z) Categorical scatter(group=) 1 team = rand(&amp;#39;A&amp;#39;:&amp;#39;C&amp;#39;, 100) scatter(x, y, group = team) Environment OS: Windows julia: v1.8.3 https://stackoverflow.com/a/60846501/12285249&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    <item>
      <title>Kringing in Spatial Data Analysis</title>
      <link>https://freshrimpsushi.github.io/en/posts/2521/</link>
      <pubDate>Sun, 10 Feb 1924 00:00:00 +0000</pubDate>
      <guid>https://freshrimpsushi.github.io/en/posts/2521/</guid>
      <description>Model Ordinary Kriging In Spatial Data Analysis, for a Random Field $\mathbf{Y} = \left( Y \left( s_{1} \right) , \cdots , Y \left( s_{n} \right) \right)$ following a Multivariate Normal Distribution with Mean $\mu \in \mathbb{R}$ and Covariance Matrix $\Sigma \in \mathbb{R}^{n \times n}$, the value estimated for a new site $s_{0}$ using the model $$ \mathbf{Y} = \mu \mathbf{1} + \varepsilon $$ is called the Ordinary Kriging Estimate. The</description>
    </item>
  </channel>
</rss>
