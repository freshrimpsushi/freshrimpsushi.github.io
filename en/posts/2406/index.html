<!doctype html><html class=blog lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link rel=preload href=https://freshrimpsushi.github.io/en/css/style.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=preload href=https://freshrimpsushi.github.io/en/css/comment.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=icon href=https://freshrimpsushi.github.io/ko/logo/favicon.ico><meta name=msapplication-TileColor content="#FFFFFF"><meta name=msapplication-TileImage content="logo/basic.png"><meta name=NaverBot content="All"><meta name=NaverBot content="index,follow"><meta name=Yeti content="All"><meta name=Yeti content="index,follow"><meta name=google-site-verification content="KYAokS7-6C5YuXOjatJQsiK1T0O8x4YncYFIF4tneYI"><meta name=naver-site-verification content="e5651d6f97899061897203413efc84994f04bbba"><link rel=alternate type=application/rss+xml title=FreshrimpRestaurant href=https://freshrimpsushi.github.io/en/index.xml><title>Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning</title></head><meta name=title content="Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning"><meta name=description content="Íµ≠ÎÇ¥ ÏµúÎåÄÏùò ÏàòÌïô, Î¨ºÎ¶¨Ìïô, ÌÜµÍ≥ÑÌïô Î∏îÎ°úÍ∑∏"><meta property="og:title" content="Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning"><meta property="og:description" content><meta property="og:image" content="https://freshrimpsushi.github.io/en/logo/basic.png/"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"r_","name":"Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning","headline":"Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning","alternativeHeadline":"","description":"Definition 1 2 Input Space $X \\ne \\emptyset$ is the domain and the codomain is the set of complex numbers $\\mathbb{C}$, and let\u0026rsquo;s denote the space of functions $\\left( H , \\left\u0026lt; \\cdot , \\cdot \\right\u0026gt; \\right) \\subset \\mathbb{C}^{X}$ composed of mappings $f: X \\to \\mathbb{C}$ as a Hilbert space. Reproducing Kernel Hilbert Space For a fixed datum $x \\in X$, the functional $\\delta_{x} : H \\to \\mathbb{C}$, which takes","inLanguage":"en","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/freshrimpsushi.github.io\/en\/posts\/2406\/"},"author":{"@type":"Person","name":"Î•òÎåÄÏãù","url":"https://math.stackexchange.com/users/459895/ryu-dae-sick"},"creator":{"@type":"Person","name":"Î•òÎåÄÏãù"},"accountablePerson":{"@type":"Person","name":"Î•òÎåÄÏãù"},"copyrightHolder":"FreshrimpRestaurant","copyrightYear":"2023","dateCreated":"2023-06-25T00:00:00.00Z","datePublished":"2023-06-25T00:00:00.00Z","dateModified":"2023-06-25T00:00:00.00Z","publisher":{"@type":"Organization","name":"FreshrimpRestaurant","url":"https://freshrimpsushi.github.io/en/","logo":{"@type":"ImageObject","url":"https:\/\/freshrimpsushi.github.io\/en\/logo\/basic.png","width":"32","height":"32"}},"image":"https://freshrimpsushi.github.io/en/logo/basic.png","url":"https:\/\/freshrimpsushi.github.io\/en\/posts\/2406\/","wordCount":"2695","genre":[],"keywords":[]}</script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/mhchem.min.js integrity=sha384-F2ptQFZqNJuqfGGl28mIXyQ5kXH48spn7rcoS0Y9psqIKAcZPLd1NzwFlm/bl1mH crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>function renderKaTex(e){renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],trust:!0,trust:e=>["\\htmlId","\\href","\\includegraphics"].includes(e.command),macros:{"\\eqref":"(\\text{#1})","\\ref":"\\href{###1}{\\text{#1}}","\\label":"\\htmlId{#1}{}","\\sech":"\\operatorname{sech}","\\csch":"\\operatorname{csch}","\\sgn":"\\operatorname{sgn}","\\sign":"\\operatorname{sign}","\\sinc":"\\operatorname{sinc}","\\diag":"\\operatorname{diag}","\\diam":"\\operatorname{diam}","\\Tr":"\\operatorname{Tr}","\\tr":"\\operatorname{tr}","\\re":"\\operatorname{Re}","\\im":"\\operatorname{Im}","\\Var":"\\operatorname{Var}","\\Poi":"\\operatorname{Poi}","\\Cov":"\\operatorname{Cov}","\\span":"\\operatorname{span}","\\supp":"\\operatorname{supp}","\\rank":"\\operatorname{rank}","\\nullity":"\\operatorname{nullity}","\\Ric":"\\operatorname{Ric}","\\i":"\\mathrm{i}","\\d":"\\mathrm{d}","\\cR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5863.png}","\\acR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.4371.png}","\\bcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5899.png}","\\abcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.0596.png}","\\crH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\smallcrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\acrH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}","\\smallacrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}"},throwOnError:!1})}</script><body class=main><header><a href=https://freshrimpsushi.github.io/en/ rel=home><p style=text-align:center;font-size:1rem;color:#000><img src=https://freshrimpsushi.github.io/en/logo/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.png style=height:80px alt=logo></p></a></header><form method=get action=/en/search style=border:1px;text-align:center><div class=field><input type=text id=searchtext placeholder=üîçÔ∏é class=input_text name=s style=background-color:#eee;text-align:center;width:200px;font-size:1.5rem;border:1px;border-radius:5px;padding-top:5px;padding-bottom:5px;margin-bottom:1.5rem></div></form><aside style=text-align:center;margin-bottom:1rem><a href=https://freshrimpsushi.github.io/ko//posts/2406/>ÌïúÍµ≠Ïñ¥</a> |
<a href=https://freshrimpsushi.github.io/en//posts/2406/>English</a> |
<a href=https://freshrimpsushi.github.io/jp//posts/2406/>Êó•Êú¨Ë™û</a></aside><div class=wrapper><div class=content><div class=content-box><title>Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning</title>
<a href=https://freshrimpsushi.github.io/en/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/ style=background-color:rgba(0,0,0,.8);color:orange;border-radius:10px;padding:5px>üìÇMachine Learning</a><h1>Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning</h1><aside><div class=innerheader><div class=innertoc><b>Table of Contents</b><nav id=TableOfContents><ul><li><a href=#definition-1-2>Definition</a><ul><li><a href=#reproducing-kernel-hilbert-space>Reproducing Kernel Hilbert Space</a></li><li><a href=#positive-definite-kernel>Positive Definite Kernel</a></li></ul></li><li><a href=#explanation>Explanation</a><ul><li><a href=#the-meaning-of-hilbert-space-in-data-science>The Meaning of Hilbert Space in Data Science</a></li><li><a href=#why-a-function-space-does-it-have-to-be-this-complicated>Why a Function Space? Does it Have to be This Complicated?</a></li><li><a href=#why-is-diracs-name-in-front-of-the-evaluation-functional>Why is Dirac&rsquo;s Name in Front of the Evaluation Functional?</a></li><li><a href=#why-its-called-reproducing-property>Why it&rsquo;s Called Reproducing Property</a></li><li><a href=#feature-map-and-uncomfortable-notation>Feature Map and Uncomfortable Notation</a></li><li><a href=#reproducing-kernels-are-positive-definite>Reproducing Kernels are Positive Definite</a></li><li><a href=#kernels-outside-of-functional-analysis>Kernels Outside of Functional Analysis</a></li><li><a href=#named-kernels>Named Kernels</a></li></ul></li></ul></nav></div></div></aside><h2 id=definition-1-2>Definition <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></h2><p><strong>Input Space</strong> $X \ne \emptyset$ is the <a href=../471>domain and the codomain</a> is the <a href=../1316>set</a> of <a href=../2046>complex numbers</a> $\mathbb{C}$, and let&rsquo;s denote the <a href=../646>space of functions</a> $\left( H , \left&lt; \cdot , \cdot \right> \right) \subset \mathbb{C}^{X}$ composed of mappings $f: X \to \mathbb{C}$ as a <a href=../776>Hilbert space</a>.</p><h3 id=reproducing-kernel-hilbert-space>Reproducing Kernel Hilbert Space</h3><ol><li>For a fixed <strong>datum</strong> $x \in X$, the <a href=../3281>functional</a> $\delta_{x} : H \to \mathbb{C}$, which takes a function $f \in H$ and returns its value at $x$, is called the <strong>(Dirac) Evaluation Functional at $x$</strong>.
$$
\delta_{x} (f) := f (x)
$$</li><li>If the evaluation functional $\delta_{x}$ is <a href=../432>continuous</a> for all $x \in X$, then $H$ is called a <strong>Reproducing Kernel Hilbert Space (RKHS)</strong> and is sometimes denoted as $H_{k}$.</li><li>A function $k : X \times X \to \mathbb{C}$ is called the <strong>reproducing kernel</strong> of $H$ if it satisfies the following two conditions:<ul><li>(i) <strong>Representer</strong>: For all $x \in X$,
$$
k \left( \cdot , x \right) \in H
$$</li><li>(ii) <strong>Reproducing Property</strong>: For all $x \in X$ and all $f \ in H$,
$$
\left&lt; f , k \left( \cdot , x \right) \right> = f(x) = \delta_{x} (f)
$$
Especially, for all $x_{1} , x_{2} \in X$, the following holds:
$$
k \left( x_{1} , x_{2} \right) = \left&lt; k \left( \cdot , x_{2} \right), k \left( \cdot , x_{1} \right) \right>
$$</li></ul></li></ol><h3 id=positive-definite-kernel>Positive Definite Kernel</h3><ol start=4><li>Let&rsquo;s call a mapping $\phi : X \to H$ from the <strong>input space</strong> $X \ne \emptyset$ to the Hilbert space $\left( H , \left&lt; \cdot , \cdot \right> \right)$ a <strong>feature map</strong>. In this context, $H$ is also referred to as the <strong>feature space</strong>.</li><li>A function $k : X \times X \to \mathbb{C}$ defined by the inner product $\left&lt; \cdot , \cdot \right> : H \times H \to \mathbb{C}$ in $\left( H , \left&lt; \cdot , \cdot \right> \right)$ is called a <strong>kernel</strong>.
$$
k \left( x_{1} , x_{2} \right) := \left&lt; \phi \left( x_{1} \right) , \phi \left( x_{2} \right) \right>
$$</li><li>For $m$ <strong>data points</strong> $\left\{ x_{1} , \cdots , x_{m} \right\} \subset X$, the matrix $K \in \mathbb{C}^{m \times m}$ formed as follows is called the <strong>Gram Matrix</strong> of the kernel $k$.
$$
K := \left( k \left( x_{i} , x_{j} \right) \right)_{ij}
$$</li><li>If the Gram Matrix of $k$ is a <a href=../336>positive definite matrix</a>, then $k$ is called a <strong>positive definite kernel</strong>. In other words, a kernel $k$ whose Gram Matrix satisfies the following for all $\left\{ c_{1} , \cdots , c_{m} \right\} \subset \mathbb{C}$ is a positive definite kernel.
$$
\sum_{i=1}^{m} \sum_{j=1}^{m} c_{i} \bar{c_{j}} K_{ij} \ge 0
$$</li></ol><h2 id=explanation>Explanation</h2><p>Although the content is complex, let&rsquo;s read it carefully as it&rsquo;s been simplified as much as possible.</p><h3 id=the-meaning-of-hilbert-space-in-data-science>The Meaning of Hilbert Space in Data Science</h3><ul><li><p>A <a href=../776>Hilbert space</a> is a <a href=../1718>complete space</a> where an <a href=../1842>inner product</a> is defined. In mathematics, an inner product is simply a bi-variable scalar function that satisfies certain conditions, but in machine learning, it can be thought of as a <strong>measure of similarity</strong>. In fact, the <a href=../2038>cosine similarity</a> used to compare word frequencies between two documents also uses an inner product, and another naive example is when we have three vectors
$$
A := \left( 3, 0, 1 \right)
\\ B := \left( 4, 1, 0 \right)
\\ C := \left( 0, 2, 5 \right)
$$
it&rsquo;s evident that $A$ and $B$ are similar, and both are different from $C$. Although this is still an intuitive inference, quantifying it through inner product yields:
$$
A \cdot B = 12 + 0 + 0 = 12
\\ A \cdot C = 0 + 0 + 5 = 5
\\ B \cdot C = 0 + 2 + 0 = 2
$$
This simple comparison of the absolute values of inner products explains the data better than just &lsquo;it&rsquo;s obvious&rsquo;.</p></li><li><p>Note that there are no specific assumptions about the input space $X$. In real applications, we cannot guarantee what kind of bad data we will handle. For example, if $X$ represents photos or document data, it does not make sense to take inner products of photos or documents.</p><ul><li>Q. If $X$ is a set of black and white photos, can&rsquo;t we just consider the photos as matrices and take inner products based on pixel values?</li><li>A. That would work, and that&rsquo;s exactly what a feature map $\phi : X \to H$ does. In this case, $H$ becomes a space of functions defined on a rectangle $[a,b] \times [c,d]$.</li><li>Thinking in this way, the existence of a kernel itself is almost like bringing &lsquo;difficult to handle data&rsquo; into a space we are familiar with.</li></ul></li><li><p>Even if the meaning of inner products mentioned above doesn&rsquo;t make sense, since an inner product space is a norm space and a metric space, most assumptions we consider necessary logically hold. An inner product $\left&lt; \cdot , \cdot \right>$ induces a norm
$$
\left\| f \right\| := \sqrt{ \left&lt; f , f \right> }
$$
and a norm $\left\| f \right\|$ induces a metric
$$
d (f,g) = \left\| f -g \right\|
$$</p><ul><li>From a data science perspective, a <a href=../1225>norm</a> itself quantifies data. For example, if we define the norm of a black and white photo as the sum of all pixel values, this alone can roughly evaluate how bright or dark the photo is.</li><li>From a data science perspective, a <a href=../381>distance</a> tells us how different two data points are. Distinguishing between right and wrong, similar and different, is undoubtedly important.</li></ul></li><li><p>Apart from these reasons, sometimes in mathematical derivations, inner products become necessary. This post won&rsquo;t cover all related examples as it would become too cluttered. Refer to the &lsquo;Kernel Trick&rsquo; section of the <a href=../2402#Kernel-Trick>&lsquo;Support Vector Machine&rsquo; post</a>.</p></li></ul><h3 id=why-a-function-space-does-it-have-to-be-this-complicated>Why a Function Space? Does it Have to be This Complicated?</h3><p>Most applications of mathematics involve finding &rsquo;the function we want&rsquo;.</p><ul><li><a href=../1016>Interpolation</a> finds a <a href=../2058>polynomial function</a> that fills in between given data points.</li><li><a href=../548>Statistical regression analysis</a> is a technique for finding a line that best explains the <a href=../2418>data</a>, which is a <a href=../3037>linear function</a>.</li><li><a href=../1853>Deep learning</a> approximates non-linear functions by incorporating <a href=../991>activation functions</a> because linear functions alone are insufficient.</li><li><a href=../1086>Fourier transform</a> represents a function as a linear combination of <a href=../2056>trigonometric functions</a>.</li></ul><p>There are countless examples like these. Returning to machine learning, the reason we consider function spaces is that ultimately, what we are looking for is a function. Even if it&rsquo;s not explicitly stated, we want a function that returns the desired result for a given input. For example, a function that returns the number on a photo of a digit, or one that calculates the probability of loan repayment based on personal information. Such useful functions are unlikely to be simple, and we hope they can be represented as a sum of finitely many $\phi_{k} (x) (\cdot)$, which serve as <a href=../3017>bases</a>. In particular, for $\phi (x) = k (\cdot , x)$, the proposition that some function $f$ can be found is precisely the <a href=../2406>Representer Theorem</a>.</p><blockquote><p><a href=../2406>Representer Theorem</a>: In a Reproducing Kernel Hilbert Space, any function fitted to the training data can be represented as a finite linear combination of representers.</p></blockquote><p>In summary, in machine learning (especially in the context of Support Vector Machines), what we seek is ultimately a function, so exploring the function space where they reside is inevitable.</p><h3 id=why-is-diracs-name-in-front-of-the-evaluation-functional>Why is Dirac&rsquo;s Name in Front of the Evaluation Functional?</h3><p>$$
\delta_{x_{0}} (x) = \begin{cases}
1 & , \text{if } x = x_{0}
\\ 0 & , \text{if } x \ne x_{0}
\end{cases}
$$
Originally, the <a href=../103>Dirac delta function</a> is known as a function that only has a value at one point. Regardless of its precise definition and usage, its variations are typically named after Dirac if they have a non-zero value at only one point. To aid understanding, imagine two functions $f : \mathbb{R} \to \mathbb{R}$, $\delta_{x_{0}} : \mathbb{R} \to \mathbb{R}$, and their inner product as
$$
\left&lt; f, \delta_{x_{0}} \right> = \sum_{x \in \mathbb{R}} f (x) \delta_{x_{0}} (x) = f \left( x_{0} \right)
$$
Though we normally use integration instead of summation for the inner product of functions, and summing over all $x \in \mathbb{R}$ is risky, the concept aligns with the idea.</p><p>In this sense, $\delta_{x_{0}} (f)$ straightforwardly yields $f \left( x_{0} \right)$, &lsquo;obtaining a single point&rsquo; at $x_{0}$, hiding the aforementioned discussion.</p><h3 id=why-its-called-reproducing-property>Why it&rsquo;s Called Reproducing Property</h3><p>The definition of RKHS is quite interesting. Usually, when we say &lsquo;some space&rsquo; in mathematics, we define it as the space where &lsquo;some&rsquo; exists, but RKHS is defined as a Hilbert space where &rsquo;the evaluation functional is continuous at every point&rsquo;, which seems out of the blue.</p><blockquote><p><a href=../786>Riesz Representation Theorem</a>: Let $\left( H, \left\langle \cdot,\cdot \right\rangle \right)$ be a Hilbert space. For a linear functional $f \in H^{ \ast }$ and $\mathbf{x} \in H$, there exists a unique $\mathbf{w} \in H$ such that $f ( \mathbf{x} ) = \left\langle \mathbf{x} , \mathbf{w} \right\rangle$ and $\| f \|_{H^{\ast}} = \| \mathbf{w} \|_{H}$.</p></blockquote><blockquote><p><strong>Moore-Aronszajn Theorem</strong>: If a positive definite kernel exists, then a unique RKHS corresponding to it also exists.</p></blockquote><p>According to this definition, the existence of a reproducing kernel in RKHS is not self-evident and requires proof. In fact, the Riesz Representation Theorem guarantees the unique existence of a reproducing kernel in RKHS. Interestingly, conversely, an RKHS corresponding to a reproducing kernel also uniquely exists.</p><p>Let&rsquo;s delve into the formulas in the definition.</p><p>Originally, the function $k : X \times X \to \mathbb{C}$ could take $x_{1}, x_{2} \in X$, but if we fix $x$ like in the definition, $k$ essentially becomes $k : y \mapsto k (y,x)$, a function $k : X \to \mathbb{C}$. By blocking one input, it&rsquo;s like
$$
\left&lt; f , k \left( \cdot , x \right) \right> = f(x)
$$
This expression is simply the inner product of two functions $f (\cdot) : X \to \mathbb{C}$ and $k \left( \cdot , x \right): X \to \mathbb{C}$. There&rsquo;s no need to overcomplicate thinking, &ldquo;How does $f$ come out and how does the inner product with $x$&mldr;&rdquo; It&rsquo;s unnecessary. Since $f(x) \in \mathbb{C}$ is also just a result of the inner product, it&rsquo;s just some complex number, the codomain being the set of complex numbers.</p><p>Here, let&rsquo;s discuss the naming of the <strong>reproducing</strong> property. The word Reproduction inherently carries the meaning of Re-(again, ÂÜç) -produce (create, Áîü), with its first translation being reproduction/generation, second being copying/duplication, and third being reproduction. Reproduction in the sense of breeding doesn&rsquo;t fit, and copying doesn&rsquo;t seem right as there&rsquo;s no original to speak of.</p><p>However, if we consider that inner-producting $f(\cdot)$ and $k (\cdot, x)$ to get $f(x)$ is &lsquo;reproducing&rsquo; the information contained in $f$ through the kernel, then wouldn&rsquo;t it make sense? Imagine we have a function $y(t)$ dependent on time $t$, representing a YouTube video. We don&rsquo;t see $y$ itself but the reproduction of $\left\{ y(t) : t \in [0,T] \right\}$. In this analogy, the kernel $k$ &lsquo;reproduces&rsquo; the function values from $f$, not as the function itself but as its values, justifying the term &lsquo;reproducing kernel&rsquo;.</p><h3 id=feature-map-and-uncomfortable-notation>Feature Map and Uncomfortable Notation</h3><p>Looking closely at the definitions of kernel and reproducing kernel, we notice that they don&rsquo;t necessarily need each other for their definitions. A kernel is a kernel, and a reproducing kernel is a reproducing kernel, and they become the same when the <strong>feature map</strong> is also the <strong>representer</strong>, i.e.,
$$
\phi (x) = k \left( \cdot , x \right)
$$
A feature map transforms original data into a form that&rsquo;s easier for us to handle,</p><p>and saying that a function is represented by such functions means it&rsquo;s explained by certain features derived from the data. One issue is that even if one intuitively understands up to this point, the notation like $k \left( \cdot , x \right)$ remains uncomfortable, and it&rsquo;s hard to empathize with the motive behind defining kernels separately from their inner products and feature maps.</p><p>Since a feature map is $\phi : X \to H$, its function value for $x \in X$ is some function $\lambda : X \to \mathbb{C}$, which usually isn&rsquo;t confusing. More precisely, $\phi (x)$ can be written as
$$
\left( \phi (x) \right) (\cdot) = k \left( \cdot , x \right)
$$
Then why use such inconvenient notation with the dot $\cdot$? Most people find it easier to understand with examples where not using such notation would cause more trouble. As mentioned earlier, whether it&rsquo;s a kernel or a reproducing kernel, the space we consistently care about is the function space $H$, and the inner product in $H$ is between functions. First, let&rsquo;s assume a <a href=../470>function</a> $f$ is represented by a linear combination of data representers $\phi \left( x_{i} \right)$:
$$
f (y) = \sum_{i=1}^{m} \alpha_{i} \phi \left( x_{i} \right) (y) = \sum_{i=1}^{m} \alpha_{i} \left( \phi \left( x_{i} \right) \right) (y)
$$
This already looks messy. Considering another function $g$ and different data $\left\{ x'_{j} \right\}_{j=1}^{n}$, we get
$$
g (y) = \sum_{j=1}^{n} \beta_{j} \left( \phi \left( x'_{j} \right) \right) (y)
$$
Moreover, if we&rsquo;re not using inner products, there&rsquo;s no point in considering an inner product space. Writing down $\left&lt; f,g \right>$ gives us
$$
\left&lt; f,g \right> = \sum_{i=1}^{m} \sum_{j=1}^{n} \bar{\alpha_{i}} \beta_{j} \left&lt; \phi \left( x_{i} \right) , \phi \left( x'_{j} \right) \right>
$$
This is unnecessarily complicated. Before taking the inner product, we hardly need to deal with actual $y \in X$ in the function space, and after taking the inner product, there&rsquo;s no need to keep writing $\phi$ and the inner product. Seeing this, the notation
$$
f (\cdot) = \sum_{i=1}^{m} \alpha_{i} k \left( \cdot , x_{i} \right)
\\ g (\cdot) = \sum_{j=1}^{n} \beta_{j} k \left( \cdot , x'_{j} \right)
\\ \left&lt; f,g \right> = \sum_{i=1}^{m} \sum_{j=1}^{n} \bar{\alpha_{i}} \beta_{j} k \left( x_{i} , x'_{j} \right)
$$
might not seem as cumbersome.</p><h3 id=reproducing-kernels-are-positive-definite>Reproducing Kernels are Positive Definite</h3><p>Given data $\left\{ x_{k} \right\}_{k=1}^{m}$, if $k$ is a kernel, then the following holds:
$$
\begin{align*}
& \sum_{i=1}^{m} \sum_{j=1}^{m} \bar{\alpha_{i}} \alpha_{j} k \left( x_{i} , x_{j} \right)
\\ =& \sum_{i=1}^{m} \sum_{j=1}^{m} \left&lt; \alpha_{i} \phi \left( x_{i} \right) , \alpha_{j} \phi \left( x_{j} \right) \right>
\\ =& \left&lt; \sum_{i=1}^{m} \alpha_{i} \phi \left( x_{i} \right) , \sum_{j=1}^{m} \alpha_{j} \phi \left( x_{j} \right) \right>
\\ =& \left\| \sum_{i=1}^{m} \alpha_{i} \phi \left( x_{i} \right) \right\|^{2}
\\ \ge & 0
\end{align*}
$$
As mentioned earlier, if we consider $\phi : x \mapsto k (\cdot , x)$, the reproducing kernel $k$ is also a kernel and thus positive definite. This positive definiteness of kernels naturally appears in various properties related to kernels.</p><h3 id=kernels-outside-of-functional-analysis>Kernels Outside of Functional Analysis</h3><ul><li>(1) In general mathematics, a kernel often refers to the <a href=../622>abstract algebra kernel $\ker$</a>. For a structure $Y$ where $0$ is defined, the kernel $\ker f$ of a function $f : X \to Y$ is defined as $\ker f := f^{-1} \left( \left\{ 0 \right\} \right)$.</li><li>(2) This concept is specialized in <a href=../../categories/%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98>linear algebra</a> as the <a href=../3071>kernel of a linear transformation</a>.</li></ul><p>If you ask someone who isn&rsquo;t specialized in functional analysis about kernels, nine out of ten times, they&rsquo;ll think of meaning (1). If your background is in mathematics, you should at least know about (1), and even if not, you should be familiar with (2).</p><h3 id=named-kernels>Named Kernels</h3><p>In the context of <a href=../../categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D>machine learning</a>, the following kernels are known<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>. These might not seem like kernels at first glance, but they can be derived from the fact that the sum and product of kernels remain kernels.</p><ol start=8><li>Linear Kernel:
$$
k \left( x_{1} , x_{2} \right) = \left&lt; x_{1} , x_{2} \right>
$$</li><li>Polynomial Kernel: For $c \ge 0$ and $d \in \mathbb{N}$,
$$
k \left( x_{1} , x_{2} \right) = \left( \left&lt; x_{1} , x_{2} \right> + c \right) ^{d}
$$</li><li>Gaussian Kernel: For $\sigma^{2} > 0$,
$$
k \left( x_{1} , x_{2} \right) = \exp \left( - {{ \left\| x_{1} - x_{2} \right\| } \over { 2 \sigma^{2} }} \right)
$$</li><li>Sigmoid Kernel: For $w, b \in \mathbb{C}$,
$$
k \left( x_{1} , x_{2} \right) = \tanh \left( w \left&lt; x_{1} , x_{2} \right> + b \right)
$$</li></ol><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Sejdinovic, Gretton. (2014). What is an RKHS?: p7~11. <a href=http://www.stats.ox.ac.uk/~sejdinov/teaching/atml14/Theory_2014.pdf>http://www.stats.ox.ac.uk/~sejdinov/teaching/atml14/Theory_2014.pdf</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Sch√∂lkopf. (2001). A Generalized Representer Theorem. <a href=https://link.springer.com/chapter/10.1007/3-540-44581-1_27>https://link.springer.com/chapter/10.1007/3-540-44581-1_27</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Jakkula. (2006). Tutorial on Support Vector Machine (SVM). <a href=https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf>https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div><aside style=text-align:right>2023-06-25&emsp;
Î•òÎåÄÏãù&emsp;
<a href=../2050>üé≤ 2406</a></aside><script>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning",c="https://freshrimpsushi.github.io/en/posts/2406/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script></div><aside><h2>Comment</h2><div class=area-reply><div class=list-reply></div></div><div class=write-box><div class="write-author-info box-account"><input type=hidden name=cmt_idx>
<input class=ai-author type=text placeholder=Name>
<input class=ai-password type=password maxlength=20 placeholder=Password></div><div class=write-content><textarea class=ai-content value placeholder='Feel free to ask in english' style=ime-mode:active></textarea></div><button class=write-button onclick=write_comment() aria-label=send><i class='fa-solid fa-paper-plane'></i></button><aside class=tex>$\TeX$ is also applied to comments.</aside></div></aside><script>let commentRows=[];const listReply=document.querySelector(".list-reply");document.addEventListener("DOMContentLoaded",()=>{get_all_comment()});function get_all_comment(){fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=getAllComment";return postFetch(t,{board_idx:"2406",user_ip:e})}).then(e=>e.json()).then(e=>{e.ok&&(commentRows=e.rows,render_comment(commentRows))}).catch(e=>console.error(e))}function render_comment(e){const n=["Î•òÎåÄÏãù","Ï†ÑÍ∏∞ÌòÑ","„Öá„Öá","ÏßàÎ¨∏"],s=["Î•òÎåÄÏãù","Ï†ÑÍ∏∞ÌòÑ"];render_blank();let t="";e.map(e=>{t+=`<div id="comment${e.cmt_idx}" class="parents">`,t+=`<div class="content-info">`;let o="";e.cmt_cnt>125?o="ü•á":e.cmt_cnt>25?o="ü•à":e.cmt_cnt>5&&(o="ü•â"),n.includes(e.author)&&(o="");let i="";e.ip_address==null?i="(-)":(ipParts=e.ip_address.split("."),i=`(${ipParts[0]}.${ipParts[1]})`),s.includes(e.author)&&(i=""),t+=`<div class="list-author">${o} ${e.author} ${i}</div>`,t+=`<sup class="list-date">${e.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,e.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> Waiting for approvement</div>`);let a=e.content;a=a.replace(/\n/g,"<br />"),t+=`<div class="content-text">${a} <span class="re-comment-button" onclick="re_comment('${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`,e.child.map(o=>{let c="child";e.ip_address&&o.ip_address===e.ip_address&&(c="parentself"),t+=`<div id="comment${o.cmt_idx}" class="${c}">`,t+=`<div class="content-info">`;let i="";o.cmt_cnt>5?i="ü•â":o.cmt_cnt>25?i="ü•à":o.cmt_cnt>125&&(i="ü•á"),n.includes(o.author)&&(i="");let a="";o.ip_address==null?a="(-)":a=`(${o.ip_address})`,s.includes(o.author)&&(a=""),t+=`<div class="list-author">${i} ${o.author} ${a}</div>`,t+=`<sup class="list-date">${o.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,o.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> Waiting for approvement</div>`);let r=o.content;r=r.replace(/\n/g,"<br />"),t+=`<div class="content-text">${r} <span class="re-comment-button" onclick="re_comment('${o.cmt_idx}', '${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`})}),listReply.innerHTML=t,renderKaTex(listReply),location.href.indexOf("#")!=-1&&(location.href=location.href.substr(location.href.indexOf("#")))}function render_blank(){listReply.innerHTML=""}function write_comment(){const e=document.querySelector(".ai-author"),t=document.querySelector(".ai-password"),n=document.querySelector(".ai-content"),s=e.value,o=t.value,i=n.value;if(s===""||o===""||i===""){alert("ÎπàÏπ∏ÏùÑ Ï±ÑÏõåÏ£ºÏÑ∏Ïöî");return}const a="2406",r="",c="Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeComment";return postFetch(t,{board_idx:a,board_slug:r,board_title:c,author:s.replace(/\+/g,"%2B"),password:o,content:i.replace(/\+/g,"%2B"),user_ip:e})}).then(e=>e.json()).then(s=>{s.ok?(commentRows.push(s.row),render_comment(commentRows),e.value="",t.value="",n.value=""):s.status===606?(Swal.fire(`Warning!
ÏßÄÏÜçÏ†ÅÏù∏ ÎèÑÎ∞∞ ÏãúÎèÑÏãú
IPÍ∞Ä Ï∞®Îã®Îê† Ïàò ÏûàÏäµÎãàÎã§.`),e.value="",t.value="",n.value=""):s.status===607&&(alert(`ÏßÄÎÇòÏπú ÎåìÍ∏Ä ÎèÑÎ∞∞Î•º ÌôïÏù∏ÌïòÏó¨
Ï†ëÍ∑ºÏùÑ Ï∞®Îã®Ìï©ÎãàÎã§.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}async function update_comment(e,t){const{value:n}=await Swal.fire({title:"ÎåìÍ∏Ä ÏàòÏ†ï",input:"password",inputPlaceholder:"Í∏Ä ÏûëÏÑ± Ïãú ÏûÖÎ†•ÌñàÎçò Ìå®Ïä§ÏõåÎìúÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(s=>{if(s.ok){const s=document.querySelector(`#comment${e}`),o="https://freshrimpsushi.com/blog/ajax/comment.php?action=getComment";postFetch(o,{cmt_idx:e}).then(e=>e.json()).then(o=>{if(o.ok){const a=o.row,r=a.author,c=a.content;let i="";i+=`<div class="update-author-info">`,i+=`<input class="update-author" type="text" value="${r}" placeholder="Ïù¥Î¶Ñ" />`,i+=`<input class="update-password" type="password" value="${n}" placeholder="ÎπÑÎ∞ÄÎ≤àÌò∏" disabled />`,i+="</div>",i+=`<textarea class="update-content" value="" style="IME-MODE:active;">${c}</textarea>`,i+=`<input class="update_comment-button" type="submit" value="ÏàòÏ†ï" onclick="update_comment_click(${e}, '${t}')" />`,i+=`<input class="update_comment-button" type="submit" value="Ï∑®ÏÜå" onclick="cancel_click(${e})" />`,s.innerHTML=i}}).catch(e=>console.error(e))}else Swal.fire("Ìå®Ïä§ÏõåÎìú ÏùºÏπò Ïò§Î•ò")}).catch(e=>console.error(e))}}async function delete_comment(e,t){const{value:n}=await Swal.fire({title:"ÎåìÍ∏Ä ÏÇ≠Ï†ú",text:"ÏÇ≠Ï†úÌïòÎ©¥ ÎêòÎèåÎ¶¥ Ïàò ÏóÜÏäµÎãàÎã§.",input:"password",icon:"warning",showCancelButton:!0,confirmButtonColor:"#3085d6",cancelButtonColor:"#d33",inputPlaceholder:"Í∏Ä ÏûëÏÑ± Ïãú ÏûÖÎ†•ÌñàÎçò Ìå®Ïä§ÏõåÎìúÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(n=>{if(n.ok){const n="https://freshrimpsushi.com/blog/ajax/comment.php?action=deleteComment";postFetch(n,{cmt_idx:e}).then(e=>e.json()).then(n=>{Swal.fire("ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§."),t==="parents"?commentRows=commentRows.filter(t=>t.cmt_idx!==e):t==="child"&&commentRows.map(t=>{t.child=t.child.filter(t=>t.cmt_idx!==e),t.child_cnt=t.child.length}),render_comment(commentRows)}).catch(e=>console.error(e))}else Swal.fire("Ìå®Ïä§ÏõåÎìú ÏùºÏπò Ïò§Î•ò")}).catch(e=>console.error(e))}}function update_comment_click(e,t){const i=document.querySelector(`#comment${e} .update-author`),a=document.querySelector(`#comment${e} .update-password`),r=document.querySelector(`#comment${e} .update-content`),n=i.value,s=a.value,o=r.value;(n===""||s===""||o==="")&&alert("ÎπàÏπ∏ÏùÑ Ï±ÑÏõåÏ£ºÏÑ∏Ïöî");const c="https://freshrimpsushi.com/blog/ajax/comment.php?action=updateComment";postFetch(c,{cmt_idx:e,author:n.replace(/\+/g,"%2B"),password:s,content:o.replace(/\+/g,"%2B")}).then(e=>e.json()).then(n=>{n.ok&&(Swal.fire("ÏàòÏ†ïÎêòÏóàÏäµÎãàÎã§."),t==="parents"?commentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}):t==="child"&&commentRows.map(t=>{t.cmt_idx==n.parent_cmt_idx&&t.child.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)})}),render_comment(commentRows),recentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}),render_recent_comment(recentRows))}).catch(e=>console.error(e))}function cancel_click(){render_comment(commentRows)}function re_comment(e,t){const s=document.querySelector(`#comment${e} .re-comment`);let n="";n+='<div class="re-comment-box">',n+='<div class="re-comment-author-info">',n+='<input class="re-comment-author" type="text" value="" placeholder="Ïù¥Î¶Ñ" />',n+='<input class="re-comment-password" type="password" value="" placeholder="ÎπÑÎ∞ÄÎ≤àÌò∏" />',n+="</div>",n+='<textarea class="re-comment-content" placeholder="ÎÇ¥Ïö©" value="" style="IME-MODE:active;"></textarea>',t===void 0?n+=`<button class="write-button" onclick="re_comment_click(${e})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`:n+=`<button class="write-button" onclick="re_comment_click(${e}, ${t})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`,n+=`<button class="write-button" onclick="cancel_click(${e})" value="close"><i class='fa-solid fa-solid fa-ban'></i></button>`,n+="</div>",s.innerHTML=n}function re_comment_click(e,t){const n=document.querySelector(`#comment${e} .re-comment-author`),s=document.querySelector(`#comment${e} .re-comment-password`),o=document.querySelector(`#comment${e} .re-comment-content`),i=n.value,a=s.value,r=o.value;if(i===""||a===""||r===""){alert("ÎπàÏπ∏ÏùÑ Ï±ÑÏõåÏ£ºÏÑ∏Ïöî");return}const c="2406",l="",d="Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(n=>{const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeReComment";return postFetch(s,{board_idx:c,board_slug:l,board_title:d,cmt_idx:t===void 0?e:t,author:i.replace(/\+/g,"%2B"),password:a,content:r.replace(/\+/g,"%2B"),user_ip:n})}).then(e=>e.json()).then(i=>{i.ok?(commentRows.map(n=>{t===void 0?n.cmt_idx==e&&n.child.push(i.row):n.cmt_idx==t&&n.child.push(i.row)}),render_comment(commentRows)):i.status==606?(Swal.fire(`Warning!
ÏßÄÏÜçÏ†ÅÏù∏ ÎèÑÎ∞∞ ÏãúÎèÑÏãú
IPÍ∞Ä Ï∞®Îã®Îê† Ïàò ÏûàÏäµÎãàÎã§.`),n.value="",s.value="",o.value=""):i.status===607&&(alert(`ÏßÄÎÇòÏπú ÎåìÍ∏Ä ÎèÑÎ∞∞Î•º ÌôïÏù∏ÌïòÏó¨
Ï†ëÍ∑ºÏùÑ Ï∞®Îã®Ìï©ÎãàÎã§.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}</script></div><aside class=sidebar><aside><style>.reddot a:link{color:#67d10f;text-shadow:0 0 10px #d3d3d3;font-weight:700}.reddot a:visited{color:#f5f5f5}</style><p class=reddot style=text-align:center;margin:0><a href=https://freshrimpsushi.github.io/en/posts/2707/>Summer Special Omakase<br>„ÄåImaginary Numbers„Äç</a></p></aside><br><div class=category></div><div style=display:flex>Click ‚óè to highlight only you interested.<div class=resetmute><button class="sb-btn btnReset" style=border-radius:5px;border:0>reset</button>
<button class="sb-btn btnMute" style=border-radius:5px;border:0>mute</button></div></div><script defer>const color={green:"#33cc33",yellow:"#ffcc00",red:"#ff3333",black:"#000000"},categoryRows=[[{idx:1,name:"Ìï®Ïàò",color:color.green,show:"Functions",size:"146"},{idx:2,name:"Î≥¥Ï°∞Ï†ïÎ¶¨",color:color.green,show:"Lemmas",size:"55"},{idx:3,name:"ÎØ∏Î∂ÑÏ†ÅÎ∂ÑÌïô",color:color.green,show:"Calculus",size:"45"},{idx:4,name:"ÌñâÎ†¨ÎåÄÏàò",color:color.green,show:"Matrix Algebra",size:"117"}],[{idx:1,name:"Ï†ïÏàòÎ°†",color:color.green,show:"Number Theory",size:"90"},{idx:2,name:"ÏßëÌï©Î°†",color:color.green,show:"Set Theory",size:"49"},{idx:3,name:"Í∑∏ÎûòÌîÑÏù¥Î°†",color:color.green,show:"Graph Theory",size:"65"},{idx:4,name:"ÏÑ†ÌòïÎåÄÏàò",color:color.green,show:"Linear Algebra",size:"97"},{idx:5,name:"Ìï¥ÏÑùÍ∞úÎ°†",color:color.green,show:"Analysis",size:"84"},{idx:6,name:"Ï∂îÏÉÅÎåÄÏàò",color:color.green,show:"Abstract Algebra",size:"105"},{idx:7,name:"ÏúÑÏÉÅÏàòÌïô",color:color.green,show:"Topology",size:"64"},{idx:8,name:"Í∏∞ÌïòÌïô",color:color.green,show:"Geometry",size:"167"}],[{idx:1,name:"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù",color:color.green,show:"Vector Analysis",size:"37"},{idx:2,name:"Î≥µÏÜåÌï¥ÏÑù",color:color.green,show:"Complex Anaylsis",size:"71"},{idx:3,name:"Ï∏°ÎèÑÎ°†",color:color.green,show:"Measure Theory",size:"53"},{idx:4,name:"Ìë∏Î¶¨ÏóêÌï¥ÏÑù",color:color.green,show:"Fourier Analysis",size:"54"},{idx:5,name:"Ï¥àÌï®ÏàòÎ°†",color:color.green,show:"Distribution Theory",size:"22"},{idx:6,name:"Îã®Ï∏µÏ¥¨ÏòÅ",color:color.green,show:"Tomography",size:"20"}],[{idx:1,name:"Í±∞Î¶¨Í≥µÍ∞Ñ",color:color.green,show:"Metric Space",size:"38"},{idx:2,name:"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ",color:color.green,show:"Banach Space",size:"38"},{idx:3,name:"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ",color:color.green,show:"Hilbert Space",size:"31"},{idx:4,name:"Î•¥Î≤°Í≥µÍ∞Ñ",color:color.green,show:"Lebesgue Space",size:"33"}],[{idx:1,name:"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù",color:color.green,show:"ODE",size:"58"},{idx:2,name:"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù",color:color.green,show:"PDE",size:"60"},{idx:3,name:"ÌôïÎ•†ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù",color:color.green,show:"SDE",size:"26"}],[{idx:1,name:"Ï§ÑÎ¶¨ÏïÑ",color:color.green,show:"Julia",size:"229"},{idx:2,name:"ÏïåÍ≥†Î¶¨Ï¶ò",color:color.green,show:"Algorithm",size:"28"},{idx:3,name:"ÏàòÏπòÌï¥ÏÑù",color:color.green,show:"Numerical Analysis",size:"63"},{idx:4,name:"ÏµúÏ†ÅÌôîÏù¥Î°†",color:color.green,show:"Optimization Theory",size:"37"},{idx:5,name:"Î®∏Ïã†Îü¨Îãù",color:color.green,show:"Machine Learning",size:"114"},{idx:6,name:"ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç",color:color.yellow,show:"Programming",size:"114"},{idx:7,name:"ÏÑ∏Ïù¥Î≤ÑÎ©îÌä∏Î¶≠Ïä§",color:color.green,show:"Sabermetrics",size:"229",size:"13"}],[{idx:1,name:"Î¨ºÎ¶¨Ìïô",color:color.green,show:"Physics",size:"27"},{idx:2,name:"ÏàòÎ¶¨Î¨ºÎ¶¨",color:color.green,show:"Mathematical Physics",size:"77"},{idx:3,name:"Í≥†Ï†ÑÏó≠Ìïô",color:color.green,show:"Classical Mechanics",size:"48"},{idx:4,name:"Ï†ÑÏûêÍ∏∞Ìïô",color:color.green,show:"Electrodynamics",size:"51"},{idx:5,name:"ÏñëÏûêÏó≠Ìïô",color:color.green,show:"Quantum Mechanics",size:"57"},{idx:6,name:"Ïó¥Î¨ºÎ¶¨Ìïô",color:color.green,show:"Thermal Physics",size:"29"}],[{idx:1,name:"R",color:color.green,show:"R",size:"54"},{idx:2,name:"Îç∞Ïù¥ÌÑ∞ÌôïÎ≥¥",color:color.green,show:"Data Sets",size:"29"},{idx:3,name:"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô",color:color.green,show:"Data Science",size:"41"},{idx:4,name:"ÌÜµÍ≥ÑÏ†ÅÍ≤ÄÏ†ï",color:color.green,show:"Statistical Test",size:"33"},{idx:5,name:"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù",color:color.green,show:"Statistical Analysis",size:"76"},{idx:6,name:"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô",color:color.green,show:"Mathematical Statistics",size:"123"},{idx:7,name:"ÌôïÎ•†Î∂ÑÌè¨Î°†",color:color.green,show:"Probability Distribution",size:"84"},{idx:8,name:"ÌôïÎ•†Î°†",color:color.green,show:"Probability Theory",size:"80"},{idx:9,name:"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù",color:color.green,show:"TDA",size:"40"}],[{idx:1,name:"ÎÖºÎ¨∏ÏûëÏÑ±",color:color.red,show:"Writing",size:"63"},{idx:2,name:"ÏÉùÏÉàÏö∞Ï¥àÎ∞•ÏßÄ",color:color.black,show:"JOF",size:"7"}]];document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("blindList"));(e==""||e==null||e==null||e==0||e==NaN)&&localStorage.setItem("blindList",null),render_category(categoryRows),blind_category(e);const t=document.querySelector(".btnReset");t.addEventListener("click",()=>{let e=new Array;localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)});const n=document.querySelector(".btnMute");n.addEventListener("click",()=>{let e=new Array;for(let t=0;t<categoryRows.length;t++)categoryRows[t].map(n=>{const s={mainIdx:t,subIdx:n.idx};e.push(s)});localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)})});function render_category(e){const n=document.querySelector(".category");let t="";for(let n=0;n<e.length;n++)e[n].map(e=>{t+=`<span id="cate${n}-${e.idx}" class="cate etewsert">`,t+=`<span onclick="check_blind(${n}, ${e.idx});" style="cursor: pointer; color: ${e.color}">‚óè</span>`,t+=`<a href="https://freshrimpsushi.github.io/en/categories/${e.name.toLowerCase()}/">`,t+=` ${e.show} (${e.size})</a>`,t+="</span>",screen.width>954?t+="<br>":t+=" "}),t+="<hr>";n.innerHTML=t}function check_blind(e,t){const o=document.querySelector(`#cate${e}-${t}`);let n=new Array;const i={mainIdx:e,subIdx:t};let s=JSON.parse(localStorage.getItem("blindList"));if(s==""||s==null||s==null||s==0||s==NaN)n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind";else{n=s;let a=null;for(let s=0;s<n.length;s++)if(n[s].mainIdx==e&&n[s].subIdx==t){a=n.filter(n=>n.mainIdx!=e||n.subIdx!=t);break}a===null?(n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind"):(localStorage.setItem("blindList",JSON.stringify(a)),o.className="cate")}}function blind_category(e){const t=document.querySelectorAll(".cate");t.forEach(e=>{e.className="cate"}),e!==null&&e.map(e=>{const t=document.querySelector(`#cate${e.mainIdx}-${e.subIdx}`);t.className+=" blind"})}</script><br><br><b>Viewed posts</b><div class=lately-viewed-list style=padding-left:4px></div><script defer>document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("latelyViewPostList")),n=document.querySelector(".lately-viewed-list");let t="";if(e==""||e==null||e==null||e==0||e==NaN)localStorage.setItem("latelyViewPostList",null),t+='<div class="lv-list">',t+=" ¬∑ Ïó¥ÎûåÌïú Ìè¨Ïä§Ìä∏Í∞Ä ÏóÜÏäµÎãàÎã§.",t+="</div>",n.innerHTML=t;else{for(let n=e.length-1;n>=0;n--)t+='<div class="lv-list">',t+=`<a href="${e[n].link}"> ¬∑ ${e[n].title}</a>`,t+="</div>";n.innerHTML=t}})</script><script defer>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="Definite Kernel and Reproducing Kernel Hilbert Space in Machine Learning",c="https://freshrimpsushi.github.io/en/posts/2406/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script><br><b>Recent comment</b><div class=current-reply></div><script defer>const url="https://freshrimpsushi.com/blog/ajax/recent_comment.php?action=getCurrentComment";let recentRows=[];fetch(url).then(e=>e.json()).then(e=>{e.ok&&(recentRows=e.rows,render_recent_comment(recentRows))}).catch(e=>console.error(e));function render_recent_comment(e){const n=document.querySelector(".current-reply");let t="";e.map(e=>{let n="https://freshrimpsushi.github.io/en/";e.board_idx>-1?n+=`posts/${e.board_idx}#comment${e.cmt_idx}`:e.board_idx==-1?n+=`#comment${e.cmt_idx}`:n+=`categories/${e.board_title}#comment${e.cmt_idx}`,t+='<div class="current-reply-list">',t+=`<a href="${n}">`,t+=`<b> - ${e.author}</b>: `,t+=`${e.content}`,t+=`</a>`,t+=`</div>`}),n.innerHTML=t,renderKaTex(n)}</script><br></aside></div><footer><aside><div><p id=mirror-link style=text-align:center><a style=cursor:text href=http://localhost:1313//en/posts/2406/>¬© FreshrimpRestaurant / Powered by Î•òÎåÄÏãù, Ï†ÑÍ∏∞ÌòÑ</a><br>Contact:
<img src=https://freshrimpsushi.github.io/en/logo/gmail.png width=12px alt=mail> freshrimpsushi@gmail.com
<a href=https://freshrimpsushi.github.io/en/index.xml><img src=https://freshrimpsushi.github.io/en/logo/RSS.png width=12px alt=RSS> RSS</a></p></div><script type=text/javascript>var goIndex=function(){var e=document.getElementsByName("idx")[0].value,t="https://freshrimpsushi.github.io/en/posts/"+e;location.replace(t)};document.addEventListener("keydown",function(e){const n=document.getElementById("navigator");if(e.altKey&&e.ctrlKey&&e.key==="l"){e.preventDefault();var t=document.querySelector("#mirror-link a");t?t.click():console.log("Í±∞Ïö∏ ÎßÅÌÅ¨Î•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§.")}})</script></aside></footer></body><script async src="https://www.googletagmanager.com/gtag/js?id=G-NLV8Y9PRK1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NLV8Y9PRK1")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4751085325232621" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/sweetalert2@11></script><script src=https://freshrimpsushi.github.io/en/js/fontawsome.min.js></script><script src=https://freshrimpsushi.github.io/en/js/common.js></script><script>document.addEventListener("DOMContentLoaded",()=>{fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/ip_checker.php";return postFetch(t,{user_ip:e})}).then(e=>e.json()).then(e=>{e.ok||(alert(`Ï∞®Îã®Îêú IPÏûÖÎãàÎã§.
Contact:
freshrimpsushi@gmail.com`),window.location.href="https://google.com")}).catch(e=>console.error(e))})</script></html>