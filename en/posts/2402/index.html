<!doctype html><html class=blog lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link rel=preload href=https://freshrimpsushi.github.io/en/css/style.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=preload href=https://freshrimpsushi.github.io/en/css/comment.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=icon href=https://freshrimpsushi.github.io/ko/logo/favicon.ico><meta name=msapplication-TileColor content="#FFFFFF"><meta name=msapplication-TileImage content="logo/basic.png"><meta name=NaverBot content="All"><meta name=NaverBot content="index,follow"><meta name=Yeti content="All"><meta name=Yeti content="index,follow"><meta name=google-site-verification content="KYAokS7-6C5YuXOjatJQsiK1T0O8x4YncYFIF4tneYI"><meta name=naver-site-verification content="e5651d6f97899061897203413efc84994f04bbba"><link rel=alternate type=application/rss+xml title=FreshrimpRestaurant href=https://freshrimpsushi.github.io/en/index.xml><title>Support Vector Machine</title></head><meta name=title content="Support Vector Machine"><meta name=description content="Íµ≠ÎÇ¥ ÏµúÎåÄÏùò ÏàòÌïô, Î¨ºÎ¶¨Ìïô, ÌÜµÍ≥ÑÌïô Î∏îÎ°úÍ∑∏"><meta property="og:title" content="Support Vector Machine"><meta property="og:description" content><meta property="og:image" content="https://freshrimpsushi.github.io/en/logo/basic.png/"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"r_","name":"Support Vector Machine","headline":"Support Vector Machine","alternativeHeadline":"","description":"Model 1 Simple Definition The method of finding a Support Vector Machine is to find a line or plane that best separates binary classifiable data. Complex Definition For an inner product space $X = \\mathbb{R}^{p}$ and labeling $Y = \\left\\{ -1, \u002b1 \\right\\}$, let\u0026rsquo;s denote the Training Dataset composed of $n$ pieces of data as $D = \\left\\{ \\left( \\mathbf{x}_{k} , y_{k} \\right) \\right\\}_{k=1}^{n} \\subset X \\times Y$, and $$","inLanguage":"en","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/freshrimpsushi.github.io\/en\/posts\/2402\/"},"author":{"@type":"Person","name":"Î•òÎåÄÏãù","url":"https://math.stackexchange.com/users/459895/ryu-dae-sick"},"creator":{"@type":"Person","name":"Î•òÎåÄÏãù"},"accountablePerson":{"@type":"Person","name":"Î•òÎåÄÏãù"},"copyrightHolder":"FreshrimpRestaurant","copyrightYear":"2023","dateCreated":"2023-06-17T00:00:00.00Z","datePublished":"2023-06-17T00:00:00.00Z","dateModified":"2023-06-17T00:00:00.00Z","publisher":{"@type":"Organization","name":"FreshrimpRestaurant","url":"https://freshrimpsushi.github.io/en/","logo":{"@type":"ImageObject","url":"https:\/\/freshrimpsushi.github.io\/en\/logo\/basic.png","width":"32","height":"32"}},"image":"https://freshrimpsushi.github.io/en/logo/basic.png","url":"https:\/\/freshrimpsushi.github.io\/en\/posts\/2402\/","wordCount":"2394","genre":[],"keywords":[]}</script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/mhchem.min.js integrity=sha384-F2ptQFZqNJuqfGGl28mIXyQ5kXH48spn7rcoS0Y9psqIKAcZPLd1NzwFlm/bl1mH crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>function renderKaTex(e){renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],trust:!0,trust:e=>["\\htmlId","\\href","\\includegraphics"].includes(e.command),macros:{"\\eqref":"(\\text{#1})","\\ref":"\\href{###1}{\\text{#1}}","\\label":"\\htmlId{#1}{}","\\sech":"\\operatorname{sech}","\\csch":"\\operatorname{csch}","\\sgn":"\\operatorname{sgn}","\\sign":"\\operatorname{sign}","\\sinc":"\\operatorname{sinc}","\\diag":"\\operatorname{diag}","\\diam":"\\operatorname{diam}","\\Tr":"\\operatorname{Tr}","\\tr":"\\operatorname{tr}","\\re":"\\operatorname{Re}","\\im":"\\operatorname{Im}","\\Var":"\\operatorname{Var}","\\Poi":"\\operatorname{Poi}","\\Cov":"\\operatorname{Cov}","\\span":"\\operatorname{span}","\\supp":"\\operatorname{supp}","\\rank":"\\operatorname{rank}","\\nullity":"\\operatorname{nullity}","\\Ric":"\\operatorname{Ric}","\\i":"\\mathrm{i}","\\d":"\\mathrm{d}","\\cR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5863.png}","\\acR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.4371.png}","\\bcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5899.png}","\\abcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.0596.png}","\\crH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\smallcrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\acrH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}","\\smallacrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}"},throwOnError:!1})}</script><body class=main><header><a href=https://freshrimpsushi.github.io/en/ rel=home><p style=text-align:center;font-size:1rem;color:#000><img src=https://freshrimpsushi.github.io/en/logo/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.png style=height:80px alt=logo></p></a></header><form method=get action=/en/search style=border:1px;text-align:center><div class=field><input type=text id=searchtext placeholder=üîçÔ∏é class=input_text name=s style=background-color:#eee;text-align:center;width:200px;font-size:1.5rem;border:1px;border-radius:5px;padding-top:5px;padding-bottom:5px;margin-bottom:1.5rem></div></form><aside style=text-align:center;margin-bottom:1rem><a href=https://freshrimpsushi.github.io/ko//posts/2402/>ÌïúÍµ≠Ïñ¥</a> |
<a href=https://freshrimpsushi.github.io/en//posts/2402/>English</a> |
<a href=https://freshrimpsushi.github.io/jp//posts/2402/>Êó•Êú¨Ë™û</a></aside><div class=wrapper><div class=content><div class=content-box><title>Support Vector Machine</title>
<a href=https://freshrimpsushi.github.io/en/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/ style=background-color:rgba(0,0,0,.8);color:orange;border-radius:10px;padding:5px>üìÇMachine Learning</a><h1>Support Vector Machine</h1><aside><div class=innerheader><div class=innertoc><b>Table of Contents</b><nav id=TableOfContents><ul><li><a href=#model-1>Model</a><ul><li><a href=#simple-definition>Simple Definition</a></li><li><a href=#complex-definition>Complex Definition</a></li></ul></li><li><a href=#explanation>Explanation</a><ul><li><a href=#inner-product-space>Inner Product Space</a></li><li><a href=#support-vectors>Support Vectors</a></li><li><a href=#maximizing-the-margin>Maximizing the Margin</a></li></ul></li><li><a href=#derived-models>Derived Models</a><ul><li><a href=#soft-margin-svm>Soft Margin SVM</a></li><li><a href=#kernel-trick>Kernel Trick</a></li></ul></li><li><a href=#see-also>See Also</a></li><li><a href=#code>Code</a></li></ul></nav></div></div></aside><h2 id=model-1>Model <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></h2><h3 id=simple-definition>Simple Definition</h3><p>The method of finding a <strong>Support Vector Machine</strong> is to find a <a href=../2042>line or plane</a> that best separates <a href=../2540>binary classifiable</a> <a href=../2418>data</a>.</p><h3 id=complex-definition>Complex Definition</h3><p>For an <a href=../1842>inner product space</a> $X = \mathbb{R}^{p}$ and labeling $Y = \left\{ -1, +1 \right\}$, let&rsquo;s denote the <strong>Training Dataset</strong> composed of $n$ pieces of data as $D = \left\{ \left( \mathbf{x}_{k} , y_{k} \right) \right\}_{k=1}^{n} \subset X \times Y$, and
$$
\begin{align*}
X^{+} :=& \left\{ \mathbf{x}_{k} \in X : y_{k} = +1 \right\}
\\ X^{-} :=& \left\{ \mathbf{x}_{k} \in X : y_{k} = -1 \right\}
\end{align*}
$$</p><p>Suppose a <a href=../2042>hyperplane</a> created by a <a href=../3037>linear function</a> $f \left( \mathbf{x} \right) = \mathbf{w}^{T} \mathbf{x} + b$ with some weight $\mathbf{w} \in \mathbb{R}^{p}$ and bias $b \in \mathbb{R}$ is $H : \mathbf{w}^{T} \mathbf{x} + b = 0$. The $\mathbf{x}^{+} \in X^{+}$s and $\mathbf{x}^{-} \in X^{-}$s closest to $H$ are called <strong>Support Vectors</strong>, and the distance $\delta$ between them is called the <strong>Margin</strong>. The [machine learning](../../categories/Machine Learning) technique that finds $\mathbf{w} , b$ that maximizes the margin while satisfying
$$
\begin{align*}
f \left( \mathbf{x}^{+} \right) =& +1
\\ f \left( \mathbf{x}^{-} \right) =& -1
\end{align*}
$$</p><p>is called <strong>Support Vector Machine (SVM)</strong>.</p><hr><ul><li>$\mathbb{R}$ is a set of real numbers, and $\mathbb{R}^{p}$ is the <a href=../205>$p$-dimensional Euclidean space</a>.</li><li>$X \times Y$ denotes the <a href=../1360>Cartesian product of two sets</a>.</li><li>$\mathbf{w}^{T}$ is the <a href=../3002>transpose matrix</a> of $\mathbf{w}$, and $\mathbf{w}^{T} \mathbf{x}$ is the <a href=../3011>inner product</a> $\left&lt; \mathbf{w} , \mathbf{x} \right>$ of two vectors $\mathbf{w}, \mathbf{x}$.</li></ul><h2 id=explanation>Explanation</h2><p>Simply put, it&rsquo;s like finding a line or plane that divides orange and sky-blue data as shown in the next picture. The red arrows in the picture correspond to the support vectors.</p><p><img src=20220225_015438.png#center alt=20220225_015438.png></p><p>In the picture, we found a line for $2$ dimensions and a plane for $3$ dimensions, but for larger $p$ dimensions, we need to find a hyperplane, which becomes harder to represent in a picture. However, the concept of dividing the space into two remains the same. Once binary classification is done with the training dataset, new data can be classified using $f$ as a linear classifier.</p><p><img src=20220225_014703.png#center alt=20220225_014703.png></p><p>Obviously, even with the same binary classification data, the left side is better than the right, as the margin for the sky-blue data on the right is excessive. Specifically, how this is calculated is not necessary to know since packages handle it.</p><p>For undergraduate students, just understanding up to the simple definition and grasping the concept through pictures is sufficient for future use or comprehension of the terminology. For slightly more complex content, practical summary points, and Python example codes, there are plenty of well-organized documents available on domestic web platforms. <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup></p><h3 id=inner-product-space>Inner Product Space</h3><p>As evident, SVM itself is not particularly complex conceptually, but the reason for introducing mathematical definitions and equations is due to the extensive theoretical discussions to follow.</p><p>The <a href=../205>Euclidean space</a> $\mathbb{R}^{p}$ is naturally a <a href=../282>vector space</a>, an <a href=../1842>inner product space</a>, and since an inner product space is a <a href=../1840>metric space</a>, it is also a metric space. Emphasizing this is important because in the real world of data, assuming an inner product space is quite a good assumption. For example, images, documents, or molecular structures immediately raise concerns about whether they can be directly input into SVM. The definition implicitly uses terms like &lsquo;close in distance&rsquo; and linear functions $f$ involving inner products of vectors, which should not be taken for granted as theory approaches reality.</p><h3 id=support-vectors>Support Vectors</h3><p>In geometric problems, those on the edge (Boundary) are typically called supports. For example, in the <a href=../2385>Minimum Enclosing Disk problem</a>, the points on the circumference of the circle determining the circle are called supports. Similarly, the support vectors in SVM are also on the boundary, positioned $\delta/2$ away from the sets $X^{+}, X^{-}$ and $\mathbf{x}^{+}, \mathbf{x}^{-}$.</p><p>There&rsquo;s no guarantee that support vectors are unique for each $X^{+}, X^{-}$, but uniqueness is not important for the upcoming discussions, so let&rsquo;s assume they are unique without losing generality. No data exists on the margin $H$, and
$$
f \left( \mathbf{x} \right)
\begin{cases}
\ge +1 & , \text{if } \mathbf{x} \in X^{+}
\\ \le -1 & , \text{if } \mathbf{x} \in X^{-}
\end{cases}
$$
thus, for all $\left\{ \mathbf{x}_{k} \right\}_{k=1}^{n}$s, $\left| f \left( \mathbf{x}_{k} \right) \right| \ge 1$ must hold.</p><h3 id=maximizing-the-margin>Maximizing the Margin</h3><p>Since support vectors are the closest points to $H$, the distance $\delta/2$ to $H$ will be the distance when the support vectors fall in the direction $\mathbf{w}$ perpendicular to $H$. This margin is the same whether for $\mathbf{x}^{+}$ or $\mathbf{x}^{-}$, and both being at a distance $\delta/2$ from the hyperplane $H$ means the distance between the two support vectors is
$$
\delta \mathbf{w} = \mathbf{x}^{+} - \mathbf{x}^{-}
$$
where operations like $\mathbf{x}^{+} - \mathbf{x}^{-}$ are permitted under the assumption that $X$ is a vector space. Taking the inner product of both sides of $\delta \mathbf{w} = \mathbf{x}^{+} - \mathbf{x}^{-}$ with $\mathbf{w}$, in other words, multiplying $\mathbf{w}^{T}$ on the left side, gives
$$
\begin{align*}
& \delta \mathbf{w} = \mathbf{x}^{+} - \mathbf{x}^{-}
\\ \implies & \delta \mathbf{w}^{T} \mathbf{w} = \mathbf{w}^{T} \mathbf{x}^{+} - \mathbf{w}^{T} \mathbf{x}^{-}
\\ \implies & \delta \left\| \mathbf{w} \right\|_{2}^{2} = \left( \mathbf{w}^{T} \mathbf{x}^{+} + b \right) - \left( \mathbf{w}^{T} \mathbf{x}^{-} + b \right)
\\ \implies & \delta \left\| \mathbf{w} \right\|_{2}^{2} = +1 - (-1)
\\ \implies & \delta \left\| \mathbf{w} \right\|_{2}^{2} = 2
\\ \implies & \delta = {{ 2 } \over { \left\| \mathbf{w} \right\|_{2}^{2} }}
\end{align*}
$$
by definition of $f$. Therefore, maximizing the margin is equivalent to minimizing the objective function $\left\| \mathbf{w} \right\|_{2}^{2} / 2$, and in summary, SVM is an optimizer that solves the following optimization problem.
$$
\begin{matrix}
\text{Minimize} & {{ 1 } \over { 2 }} \left\| \mathbf{w} \right\|_{2}^{2}
\\ \text{subject to} & \left| f \left( \mathbf{x}_{k} \right) \right| \ge 1
\end{matrix}
\\ k = 1, \cdots , n
$$</p><h2 id=derived-models>Derived Models</h2><p>As per the complex definition, SVM finds a linear function, whether it&rsquo;s a line or hyperplane, and naturally, that wouldn&rsquo;t be satisfactory.</p><h3 id=soft-margin-svm>Soft Margin SVM</h3><p>Consider data like the following. SVM cannot perfectly binary classify it due to the mixed data in the middle.</p><p><img src=20220225_030646.png#center alt=20220225_030646.png></p><p>Note that we had to satisfy the condition $\left| f \left( \mathbf{x}_{k} \right) \right| \ge 1$ under the constraint that data couldn&rsquo;t exist in the margin of support vectors. If we allow this inequality to be smaller than $1$, it would yield better results than giving up on binary classification altogether, even if it&rsquo;s not perfect. If we denote this allowance for each data as $\xi_{k} \ge 0$, we get a new constraint $\left| f \left( \mathbf{x}_{k} \right) \right| \ge 1 - \xi_{k}$. This weakened margin is called a <strong>Soft Margin</strong>.</p><p>Although the constraint has been relaxed, completely loosening it to $\xi_{l} = \cdots = \xi_{n} = 1$ would negate SVM altogether. To prevent this, a term like $\sum_{k} \xi_{k}$ can be added to the objective function as a penalty for making impossible binary classification possible. Of course, such a simple penalty could be meaningless or too sensitive depending on the data scale, so instead of using $0 \le \sum_{k} \xi_{k} \le n$ as is, it&rsquo;s better to multiply it by a suitable positive number $\lambda > 0$ and add it.
$$
\begin{matrix}
\text{Minimize} & {{ 1 } \over { 2 }} \left\| \mathbf{w} \right\|_{2}^{2} + \lambda \sum_{k=1}^{n} \xi_{k}
\\ \text{subject to} & \left| f \left( \mathbf{x}_{k} \right) \right| \ge 1 - \xi_{k}
\\ & \xi_{k} \ge 0
\end{matrix}
\\ k = 1, \cdots , n
$$</p><h3 id=kernel-trick>Kernel Trick</h3><p><img src=raw.png#center alt=raw.png></p><p>Given data like the above, it seems impossible to binary classify it with SVM, whether with a soft margin or not. However, it&rsquo;s clear that sky-blue points are clustered closer to $0$, and orange points appear on the outside. To utilize this information, let&rsquo;s create a new $z$-axis as follows.
$$
\phi (x,y) := (x,y, x^{2} + y^{2})
$$</p><p><img src=20220225_140243.png#center alt=20220225_140243.png>
The above picture is a capture of the one below. The below is a 3D space interactive with the mouse, so take a look around.</p><p align=middle><iframe width=640 height=425 frameborder=0 src=kernel.html></iframe></p><p>While it was difficult to find a line that separates data in the original $\mathbb{R}^{2}$, in the expanded $\mathbb{R}^{3}$, we can now use SVM to classify data with a suitable plane. Naturally, one might ask, &lsquo;So, is this good transformation $\phi$ called a Kernel, and is using a kernel called the Kernel Trick?&rsquo; The answer is half right and half wrong. $\phi$ with an extra step, including the inner product, is what constitutes a kernel.</p><p>Returning to <a href=#Maximizing-the-Margin>Maximizing the Margin</a>, let&rsquo;s revisit the optimization problem given to us.
$$
\begin{matrix}
\text{Minimize} & {{ 1 } \over { 2 }} \left\| \mathbf{w} \right\|_{2}^{2}
\\ \text{subject to} & \left| f \left( \mathbf{x}_{k} \right) \right| \ge 1
\end{matrix}
\\ k = 1, \cdots , n
$$</p><p>Although constraint $\left| f \left( \mathbf{x}_{k} \right) \right| \ge 1$ looks neat, it doesn&rsquo;t help much when solving this problem. If we revert to the form in the original training dataset, for $k = 1 , \cdots , n$,
$$
\begin{cases}
f \left( \mathbf{x}_{k} \right) \ge 1 & , \text{if } y_{k} = 1
\\ f \left( \mathbf{x}_{k} \right) \le -1 & , \text{if } y_{k} = -1
\end{cases}
\\ \implies
\begin{cases}
y_{k} \left( \mathbf{w}^{T} \mathbf{x}_{k} + b \right) \ge 1 & , \text{if } y_{k} = 1
\\ y_{k} \left( \mathbf{w}^{T} \mathbf{x}_{k} + b \right) \ge 1 & , \text{if } y_{k} = -1
\end{cases}
\\ \implies y_{k} \left( \mathbf{w}^{T} \mathbf{x}_{k} + b \right) \ge 1
$$
must hold. The method of incorporating this constraint directly into the objective function, treating it as if there were no constraints, is the <a href=../2404>Lagrange Multiplier Method</a>. For the objective function minus the terms multiplied by $y_{k} \left( \mathbf{w}^{T} \mathbf{x}_{k} + b \right) - 1 \ge 0$ with $\alpha_{k} \ge 0$, we get the following optimization problem for $L(\mathbf{w}, b)$:
$$
\begin{matrix}
\text{Minimize} & {{ 1 } \over { 2 }} \left\| \mathbf{w} \right\|_{2}^{2} - \sum_{k=1}^{n} \alpha_{k} \left[ y_{k} \left( \mathbf{w}^{T} \mathbf{x}_{k} + b \right) - 1 \right]
\\ \text{subject to} & \alpha_{k} \ge 0
\end{matrix}
\\ k = 1, \cdots , n
$$</p><p>To reiterate, our goal was to find $\mathbf{w}, b$ that minimizes this objective function. The condition that makes the partial derivative of the objective function with respect to $\mathbf{w}, b$ equal to $0$ is as follows:
$$
\begin{align*}
{{ \partial L } \over { \partial \mathbf{w} }} = 0 \implies & \mathbf{w} = \sum_{k=1}^{n} \alpha_{k} y_{k} \mathbf{x}_{k}
\\ {{ \partial L } \over { \partial b }} = 0 \implies & 0 = \sum_{k=1}^{n} \alpha_{k} y_{k}
\end{align*}
$$</p><p>Substituting this directly into $L$ yields
$$
\begin{align*}
& L(\mathbf{w},b)
\\ =& {{ 1 } \over { 2 }} \left\| \mathbf{w} \right\|_{2}^{2} - \sum_{k=1}^{n} \alpha_{k} \left[ y_{k} \left( \mathbf{w}^{T} \mathbf{x}_{k} + b \right) - 1 \right]
\\ =& {{ 1 } \over { 2 }} \mathbf{w}^{T} \mathbf{w} - \sum_{k=1}^{n} \alpha_{k} y_{k} \left( \mathbf{w}^{T} \mathbf{x}_{k} + b \right) + \sum_{k=1}^{n} \alpha_{k}
\\ =& {{ 1 } \over { 2 }} \mathbf{w}^{T} \sum_{k=1}^{n} \alpha_{k} y_{k} \mathbf{x}_{k} - \sum_{k=1}^{n} \alpha_{k} y_{k}\mathbf{w}^{T} \mathbf{x}_{k} - b \sum_{k=1}^{n} \alpha_{k} y_{k} - \sum_{k=1}^{n} \alpha_{k}
\\ =& - {{ 1 } \over { 2 }} \sum_{k=1}^{n} \alpha_{k} y_{k} \mathbf{w}^{T} \mathbf{x}_{k} - b \cdot 0 + \sum_{k=1}^{n} \alpha_{k}
\\ =& \sum_{k=1}^{n} \alpha_{k} - {{ 1 } \over { 2 }} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_{i} y_{i} a_{j} y_{j} \mathbf{x}_{i}^{T} \mathbf{x}_{j}
\\ =& \sum_{k=1}^{n} \alpha_{k} - {{ 1 } \over { 2 }} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_{i} a_{j} y_{i} y_{j} \mathbf{x}_{i}^{T} \mathbf{x}_{j}
\\ =& L \left( \alpha_{1} , \cdots , \alpha_{n} \right)
\end{align*}
$$</p><p>As expected, to specifically calculate $\mathbf{w}$ and $b$, the training data $\left\{ \left( \mathbf{x}_{k}, y_{k} \right) \right\}_{k=1}^{n}$ is required.</p><p>The point to note here is that the inner product of $\mathbf{x}_{i}$ and $\mathbf{x}_{j}$ was used in the equation. Ultimately, we must perform an inner product, and if $X$ is not an <a href=../1842>inner product space</a>, there&rsquo;s no guarantee we can take this smooth path. Conversely, even if $X$ isn&rsquo;t an inner product space, if the transformation $\phi$ can send $X$ to an inner product space, considering SVM with the objective function
$$
\sum_{k=1}^{n} \alpha_{k} - {{ 1 } \over { 2 }} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_{i} a_{j} y_{i} y_{j} \phi \left( \mathbf{x}_{i} \right) ^{T} \phi \left( \mathbf{x}_{j} \right)
$$
becomes plausible. In [Machine Learning](../../categories/Machine Learning), functions involving a transformation and inner product of two vectors
$$
K \left( \mathbf{x}_{i}, \mathbf{x}_{j} \right) := \left&lt; \phi \left( \mathbf{x}_{i} \right) , \phi \left( \mathbf{x}_{j} \right) \right>
$$
are sometimes referred to as a <a href=../2406>Kernel</a>. [ <strong>NOTE</strong>: Even within data science, there are other kernels that could be confused with this. The original mathematical <a href=../622>kernel</a> is a function with the same name but entirely different functionality. ]</p><p>If you can accept the content up to this point mathematically, you should understand why introducing a transformation $\phi$, not even a kernel, is called the <strong>Kernel Trick</strong>, and why it&rsquo;s important that it guarantees an <a href=../1842>inner product space</a> afterwards.</p><p>Several kernels that satisfy certain conditions can be considered, especially the original SVM can also be seen as using a Linear Kernel
$$
K \left( \mathbf{x}_{i}, \mathbf{x}_{j} \right) = \left&lt; \mathbf{x}_{i}, \mathbf{x}_{j} \right>^{1} = \mathbf{x}_{i}^{T} \mathbf{x}_{j}
$$</p><h2 id=see-also>See Also</h2><p>The <a href=#Kernel-Trick>Kernel Trick section</a> dealt with mathematically simple content, but if you&rsquo;re interested in deeper theories, go beyond SVM and study the following topics:</p><ul><li><a href=../2406>Kernels in Machine Learning and Reproducing Kernel Hilbert Spaces</a></li><li><a href=../2408>Proof of the Representation Theorem</a></li></ul><h2 id=code>Code</h2><p>The following is Julia code implementing the kernel trick.</p><pre tabindex=0><code>struct Sphere
    d::Int64
end
Sphere(d) = Sphere(d)

import Base.rand
function rand(Topology::Sphere, n::Int64)
    direction = randn(Topology.d, n)
    boundary = direction ./ sqrt.(sum(abs2, direction, dims = 1))
    return boundary
end

using Plots
A = 0.3rand(Sphere(2), 200) + 0.1randn(2, 200)
B = rand(Sphere(2), 200) + 0.1randn(2, 200)

scatter(A[1,:],A[2,:], ratio = :equal, label = &#34;+1&#34;)
scatter!(B[1,:],B[2,:], ratio = :equal, label = &#34;-1&#34;)
png(&#34;raw.png&#34;)

Plots.plotly()
œï(z) = z[1]^2 + z[2]^2
scatter(A[1,:],A[2,:],œï.(eachcol(A)), ms = 1, label = &#34;+1&#34;)
scatter!(B[1,:],B[2,:],œï.(eachcol(B)), ms = 1, label = &#34;-1&#34;)
savefig(&#34;kernel.html&#34;)
</code></pre><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Jakkula. (2006). Tutorial on Support Vector Machine (SVM). <a href=https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf>https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/>https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href=https://bkshin.tistory.com/entry/Machine-Learning-2-Support-Vector-Machine-SVM>https://bkshin.tistory.com/entry/Machine-Learning-2-Support-Vector-Machine-SVM</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p><a href=https://hleecaster.com/ml-svm-concept/>https://hleecaster.com/ml-svm-concept/</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div><aside style=text-align:right>2023-06-17&emsp;
Î•òÎåÄÏãù&emsp;
<a href=../1192>üé≤ 2402</a></aside><script>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="Support Vector Machine",c="https://freshrimpsushi.github.io/en/posts/2402/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script></div><aside><h2>Comment</h2><div class=area-reply><div class=list-reply></div></div><div class=write-box><div class="write-author-info box-account"><input type=hidden name=cmt_idx>
<input class=ai-author type=text placeholder=Name>
<input class=ai-password type=password maxlength=20 placeholder=Password></div><div class=write-content><textarea class=ai-content value placeholder='Feel free to ask in english' style=ime-mode:active></textarea></div><button class=write-button onclick=write_comment() aria-label=send><i class='fa-solid fa-paper-plane'></i></button><aside class=tex>$\TeX$ is also applied to comments.</aside></div></aside><script>let commentRows=[];const listReply=document.querySelector(".list-reply");document.addEventListener("DOMContentLoaded",()=>{get_all_comment()});function get_all_comment(){fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=getAllComment";return postFetch(t,{board_idx:"2402",user_ip:e})}).then(e=>e.json()).then(e=>{e.ok&&(commentRows=e.rows,render_comment(commentRows))}).catch(e=>console.error(e))}function render_comment(e){const n=["Î•òÎåÄÏãù","Ï†ÑÍ∏∞ÌòÑ","„Öá„Öá","ÏßàÎ¨∏"],s=["Î•òÎåÄÏãù","Ï†ÑÍ∏∞ÌòÑ"];render_blank();let t="";e.map(e=>{t+=`<div id="comment${e.cmt_idx}" class="parents">`,t+=`<div class="content-info">`;let o="";e.cmt_cnt>125?o="ü•á":e.cmt_cnt>25?o="ü•à":e.cmt_cnt>5&&(o="ü•â"),n.includes(e.author)&&(o="");let i="";e.ip_address==null?i="(-)":(ipParts=e.ip_address.split("."),i=`(${ipParts[0]}.${ipParts[1]})`),s.includes(e.author)&&(i=""),t+=`<div class="list-author">${o} ${e.author} ${i}</div>`,t+=`<sup class="list-date">${e.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,e.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> Waiting for approvement</div>`);let a=e.content;a=a.replace(/\n/g,"<br />"),t+=`<div class="content-text">${a} <span class="re-comment-button" onclick="re_comment('${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`,e.child.map(o=>{let c="child";e.ip_address&&o.ip_address===e.ip_address&&(c="parentself"),t+=`<div id="comment${o.cmt_idx}" class="${c}">`,t+=`<div class="content-info">`;let i="";o.cmt_cnt>5?i="ü•â":o.cmt_cnt>25?i="ü•à":o.cmt_cnt>125&&(i="ü•á"),n.includes(o.author)&&(i="");let a="";o.ip_address==null?a="(-)":a=`(${o.ip_address})`,s.includes(o.author)&&(a=""),t+=`<div class="list-author">${i} ${o.author} ${a}</div>`,t+=`<sup class="list-date">${o.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,o.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> Waiting for approvement</div>`);let r=o.content;r=r.replace(/\n/g,"<br />"),t+=`<div class="content-text">${r} <span class="re-comment-button" onclick="re_comment('${o.cmt_idx}', '${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`})}),listReply.innerHTML=t,renderKaTex(listReply),location.href.indexOf("#")!=-1&&(location.href=location.href.substr(location.href.indexOf("#")))}function render_blank(){listReply.innerHTML=""}function write_comment(){const e=document.querySelector(".ai-author"),t=document.querySelector(".ai-password"),n=document.querySelector(".ai-content"),s=e.value,o=t.value,i=n.value;if(s===""||o===""||i===""){alert("ÎπàÏπ∏ÏùÑ Ï±ÑÏõåÏ£ºÏÑ∏Ïöî");return}const a="2402",r="",c="Support Vector Machine";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeComment";return postFetch(t,{board_idx:a,board_slug:r,board_title:c,author:s.replace(/\+/g,"%2B"),password:o,content:i.replace(/\+/g,"%2B"),user_ip:e})}).then(e=>e.json()).then(s=>{s.ok?(commentRows.push(s.row),render_comment(commentRows),e.value="",t.value="",n.value=""):s.status===606?(Swal.fire(`Warning!
ÏßÄÏÜçÏ†ÅÏù∏ ÎèÑÎ∞∞ ÏãúÎèÑÏãú
IPÍ∞Ä Ï∞®Îã®Îê† Ïàò ÏûàÏäµÎãàÎã§.`),e.value="",t.value="",n.value=""):s.status===607&&(alert(`ÏßÄÎÇòÏπú ÎåìÍ∏Ä ÎèÑÎ∞∞Î•º ÌôïÏù∏ÌïòÏó¨
Ï†ëÍ∑ºÏùÑ Ï∞®Îã®Ìï©ÎãàÎã§.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}async function update_comment(e,t){const{value:n}=await Swal.fire({title:"ÎåìÍ∏Ä ÏàòÏ†ï",input:"password",inputPlaceholder:"Í∏Ä ÏûëÏÑ± Ïãú ÏûÖÎ†•ÌñàÎçò Ìå®Ïä§ÏõåÎìúÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(s=>{if(s.ok){const s=document.querySelector(`#comment${e}`),o="https://freshrimpsushi.com/blog/ajax/comment.php?action=getComment";postFetch(o,{cmt_idx:e}).then(e=>e.json()).then(o=>{if(o.ok){const a=o.row,r=a.author,c=a.content;let i="";i+=`<div class="update-author-info">`,i+=`<input class="update-author" type="text" value="${r}" placeholder="Ïù¥Î¶Ñ" />`,i+=`<input class="update-password" type="password" value="${n}" placeholder="ÎπÑÎ∞ÄÎ≤àÌò∏" disabled />`,i+="</div>",i+=`<textarea class="update-content" value="" style="IME-MODE:active;">${c}</textarea>`,i+=`<input class="update_comment-button" type="submit" value="ÏàòÏ†ï" onclick="update_comment_click(${e}, '${t}')" />`,i+=`<input class="update_comment-button" type="submit" value="Ï∑®ÏÜå" onclick="cancel_click(${e})" />`,s.innerHTML=i}}).catch(e=>console.error(e))}else Swal.fire("Ìå®Ïä§ÏõåÎìú ÏùºÏπò Ïò§Î•ò")}).catch(e=>console.error(e))}}async function delete_comment(e,t){const{value:n}=await Swal.fire({title:"ÎåìÍ∏Ä ÏÇ≠Ï†ú",text:"ÏÇ≠Ï†úÌïòÎ©¥ ÎêòÎèåÎ¶¥ Ïàò ÏóÜÏäµÎãàÎã§.",input:"password",icon:"warning",showCancelButton:!0,confirmButtonColor:"#3085d6",cancelButtonColor:"#d33",inputPlaceholder:"Í∏Ä ÏûëÏÑ± Ïãú ÏûÖÎ†•ÌñàÎçò Ìå®Ïä§ÏõåÎìúÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(n=>{if(n.ok){const n="https://freshrimpsushi.com/blog/ajax/comment.php?action=deleteComment";postFetch(n,{cmt_idx:e}).then(e=>e.json()).then(n=>{Swal.fire("ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§."),t==="parents"?commentRows=commentRows.filter(t=>t.cmt_idx!==e):t==="child"&&commentRows.map(t=>{t.child=t.child.filter(t=>t.cmt_idx!==e),t.child_cnt=t.child.length}),render_comment(commentRows)}).catch(e=>console.error(e))}else Swal.fire("Ìå®Ïä§ÏõåÎìú ÏùºÏπò Ïò§Î•ò")}).catch(e=>console.error(e))}}function update_comment_click(e,t){const i=document.querySelector(`#comment${e} .update-author`),a=document.querySelector(`#comment${e} .update-password`),r=document.querySelector(`#comment${e} .update-content`),n=i.value,s=a.value,o=r.value;(n===""||s===""||o==="")&&alert("ÎπàÏπ∏ÏùÑ Ï±ÑÏõåÏ£ºÏÑ∏Ïöî");const c="https://freshrimpsushi.com/blog/ajax/comment.php?action=updateComment";postFetch(c,{cmt_idx:e,author:n.replace(/\+/g,"%2B"),password:s,content:o.replace(/\+/g,"%2B")}).then(e=>e.json()).then(n=>{n.ok&&(Swal.fire("ÏàòÏ†ïÎêòÏóàÏäµÎãàÎã§."),t==="parents"?commentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}):t==="child"&&commentRows.map(t=>{t.cmt_idx==n.parent_cmt_idx&&t.child.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)})}),render_comment(commentRows),recentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}),render_recent_comment(recentRows))}).catch(e=>console.error(e))}function cancel_click(){render_comment(commentRows)}function re_comment(e,t){const s=document.querySelector(`#comment${e} .re-comment`);let n="";n+='<div class="re-comment-box">',n+='<div class="re-comment-author-info">',n+='<input class="re-comment-author" type="text" value="" placeholder="Ïù¥Î¶Ñ" />',n+='<input class="re-comment-password" type="password" value="" placeholder="ÎπÑÎ∞ÄÎ≤àÌò∏" />',n+="</div>",n+='<textarea class="re-comment-content" placeholder="ÎÇ¥Ïö©" value="" style="IME-MODE:active;"></textarea>',t===void 0?n+=`<button class="write-button" onclick="re_comment_click(${e})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`:n+=`<button class="write-button" onclick="re_comment_click(${e}, ${t})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`,n+=`<button class="write-button" onclick="cancel_click(${e})" value="close"><i class='fa-solid fa-solid fa-ban'></i></button>`,n+="</div>",s.innerHTML=n}function re_comment_click(e,t){const n=document.querySelector(`#comment${e} .re-comment-author`),s=document.querySelector(`#comment${e} .re-comment-password`),o=document.querySelector(`#comment${e} .re-comment-content`),i=n.value,a=s.value,r=o.value;if(i===""||a===""||r===""){alert("ÎπàÏπ∏ÏùÑ Ï±ÑÏõåÏ£ºÏÑ∏Ïöî");return}const c="2402",l="",d="Support Vector Machine";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(n=>{const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeReComment";return postFetch(s,{board_idx:c,board_slug:l,board_title:d,cmt_idx:t===void 0?e:t,author:i.replace(/\+/g,"%2B"),password:a,content:r.replace(/\+/g,"%2B"),user_ip:n})}).then(e=>e.json()).then(i=>{i.ok?(commentRows.map(n=>{t===void 0?n.cmt_idx==e&&n.child.push(i.row):n.cmt_idx==t&&n.child.push(i.row)}),render_comment(commentRows)):i.status==606?(Swal.fire(`Warning!
ÏßÄÏÜçÏ†ÅÏù∏ ÎèÑÎ∞∞ ÏãúÎèÑÏãú
IPÍ∞Ä Ï∞®Îã®Îê† Ïàò ÏûàÏäµÎãàÎã§.`),n.value="",s.value="",o.value=""):i.status===607&&(alert(`ÏßÄÎÇòÏπú ÎåìÍ∏Ä ÎèÑÎ∞∞Î•º ÌôïÏù∏ÌïòÏó¨
Ï†ëÍ∑ºÏùÑ Ï∞®Îã®Ìï©ÎãàÎã§.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}</script></div><aside class=sidebar><aside><style>.reddot a:link{color:#67d10f;text-shadow:0 0 10px #d3d3d3;font-weight:700}.reddot a:visited{color:#f5f5f5}</style><p class=reddot style=text-align:center;margin:0><a href=https://freshrimpsushi.github.io/en/posts/2707/>Summer Special Omakase<br>„ÄåImaginary Numbers„Äç</a></p></aside><br><div class=category></div><div style=display:flex>Click ‚óè to highlight only you interested.<div class=resetmute><button class="sb-btn btnReset" style=border-radius:5px;border:0>reset</button>
<button class="sb-btn btnMute" style=border-radius:5px;border:0>mute</button></div></div><script defer>const color={green:"#33cc33",yellow:"#ffcc00",red:"#ff3333",black:"#000000"},categoryRows=[[{idx:1,name:"Ìï®Ïàò",color:color.green,show:"Functions",size:"146"},{idx:2,name:"Î≥¥Ï°∞Ï†ïÎ¶¨",color:color.green,show:"Lemmas",size:"55"},{idx:3,name:"ÎØ∏Î∂ÑÏ†ÅÎ∂ÑÌïô",color:color.green,show:"Calculus",size:"45"},{idx:4,name:"ÌñâÎ†¨ÎåÄÏàò",color:color.green,show:"Matrix Algebra",size:"117"}],[{idx:1,name:"Ï†ïÏàòÎ°†",color:color.green,show:"Number Theory",size:"90"},{idx:2,name:"ÏßëÌï©Î°†",color:color.green,show:"Set Theory",size:"49"},{idx:3,name:"Í∑∏ÎûòÌîÑÏù¥Î°†",color:color.green,show:"Graph Theory",size:"65"},{idx:4,name:"ÏÑ†ÌòïÎåÄÏàò",color:color.green,show:"Linear Algebra",size:"97"},{idx:5,name:"Ìï¥ÏÑùÍ∞úÎ°†",color:color.green,show:"Analysis",size:"84"},{idx:6,name:"Ï∂îÏÉÅÎåÄÏàò",color:color.green,show:"Abstract Algebra",size:"105"},{idx:7,name:"ÏúÑÏÉÅÏàòÌïô",color:color.green,show:"Topology",size:"64"},{idx:8,name:"Í∏∞ÌïòÌïô",color:color.green,show:"Geometry",size:"167"}],[{idx:1,name:"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù",color:color.green,show:"Vector Analysis",size:"37"},{idx:2,name:"Î≥µÏÜåÌï¥ÏÑù",color:color.green,show:"Complex Anaylsis",size:"71"},{idx:3,name:"Ï∏°ÎèÑÎ°†",color:color.green,show:"Measure Theory",size:"53"},{idx:4,name:"Ìë∏Î¶¨ÏóêÌï¥ÏÑù",color:color.green,show:"Fourier Analysis",size:"54"},{idx:5,name:"Ï¥àÌï®ÏàòÎ°†",color:color.green,show:"Distribution Theory",size:"22"},{idx:6,name:"Îã®Ï∏µÏ¥¨ÏòÅ",color:color.green,show:"Tomography",size:"20"}],[{idx:1,name:"Í±∞Î¶¨Í≥µÍ∞Ñ",color:color.green,show:"Metric Space",size:"38"},{idx:2,name:"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ",color:color.green,show:"Banach Space",size:"38"},{idx:3,name:"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ",color:color.green,show:"Hilbert Space",size:"31"},{idx:4,name:"Î•¥Î≤°Í≥µÍ∞Ñ",color:color.green,show:"Lebesgue Space",size:"33"}],[{idx:1,name:"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù",color:color.green,show:"ODE",size:"58"},{idx:2,name:"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù",color:color.green,show:"PDE",size:"60"},{idx:3,name:"ÌôïÎ•†ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù",color:color.green,show:"SDE",size:"26"}],[{idx:1,name:"Ï§ÑÎ¶¨ÏïÑ",color:color.green,show:"Julia",size:"229"},{idx:2,name:"ÏïåÍ≥†Î¶¨Ï¶ò",color:color.green,show:"Algorithm",size:"28"},{idx:3,name:"ÏàòÏπòÌï¥ÏÑù",color:color.green,show:"Numerical Analysis",size:"63"},{idx:4,name:"ÏµúÏ†ÅÌôîÏù¥Î°†",color:color.green,show:"Optimization Theory",size:"37"},{idx:5,name:"Î®∏Ïã†Îü¨Îãù",color:color.green,show:"Machine Learning",size:"114"},{idx:6,name:"ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç",color:color.yellow,show:"Programming",size:"112"},{idx:7,name:"ÏÑ∏Ïù¥Î≤ÑÎ©îÌä∏Î¶≠Ïä§",color:color.green,show:"Sabermetrics",size:"229",size:"13"}],[{idx:1,name:"Î¨ºÎ¶¨Ìïô",color:color.green,show:"Physics",size:"27"},{idx:2,name:"ÏàòÎ¶¨Î¨ºÎ¶¨",color:color.green,show:"Mathematical Physics",size:"77"},{idx:3,name:"Í≥†Ï†ÑÏó≠Ìïô",color:color.green,show:"Classical Mechanics",size:"48"},{idx:4,name:"Ï†ÑÏûêÍ∏∞Ìïô",color:color.green,show:"Electrodynamics",size:"51"},{idx:5,name:"ÏñëÏûêÏó≠Ìïô",color:color.green,show:"Quantum Mechanics",size:"57"},{idx:6,name:"Ïó¥Î¨ºÎ¶¨Ìïô",color:color.green,show:"Thermal Physics",size:"29"}],[{idx:1,name:"R",color:color.green,show:"R",size:"54"},{idx:2,name:"Îç∞Ïù¥ÌÑ∞ÌôïÎ≥¥",color:color.green,show:"Data Sets",size:"29"},{idx:3,name:"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô",color:color.green,show:"Data Science",size:"41"},{idx:4,name:"ÌÜµÍ≥ÑÏ†ÅÍ≤ÄÏ†ï",color:color.green,show:"Statistical Test",size:"33"},{idx:5,name:"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù",color:color.green,show:"Statistical Analysis",size:"76"},{idx:6,name:"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô",color:color.green,show:"Mathematical Statistics",size:"123"},{idx:7,name:"ÌôïÎ•†Î∂ÑÌè¨Î°†",color:color.green,show:"Probability Distribution",size:"84"},{idx:8,name:"ÌôïÎ•†Î°†",color:color.green,show:"Probability Theory",size:"80"},{idx:9,name:"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù",color:color.green,show:"TDA",size:"40"}],[{idx:1,name:"ÎÖºÎ¨∏ÏûëÏÑ±",color:color.red,show:"Writing",size:"63"},{idx:2,name:"ÏÉùÏÉàÏö∞Ï¥àÎ∞•ÏßÄ",color:color.black,show:"JOF",size:"7"}]];document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("blindList"));(e==""||e==null||e==null||e==0||e==NaN)&&localStorage.setItem("blindList",null),render_category(categoryRows),blind_category(e);const t=document.querySelector(".btnReset");t.addEventListener("click",()=>{let e=new Array;localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)});const n=document.querySelector(".btnMute");n.addEventListener("click",()=>{let e=new Array;for(let t=0;t<categoryRows.length;t++)categoryRows[t].map(n=>{const s={mainIdx:t,subIdx:n.idx};e.push(s)});localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)})});function render_category(e){const n=document.querySelector(".category");let t="";for(let n=0;n<e.length;n++)e[n].map(e=>{t+=`<span id="cate${n}-${e.idx}" class="cate etewsert">`,t+=`<span onclick="check_blind(${n}, ${e.idx});" style="cursor: pointer; color: ${e.color}">‚óè</span>`,t+=`<a href="https://freshrimpsushi.github.io/en/categories/${e.name.toLowerCase()}/">`,t+=` ${e.show} (${e.size})</a>`,t+="</span>",screen.width>954?t+="<br>":t+=" "}),t+="<hr>";n.innerHTML=t}function check_blind(e,t){const o=document.querySelector(`#cate${e}-${t}`);let n=new Array;const i={mainIdx:e,subIdx:t};let s=JSON.parse(localStorage.getItem("blindList"));if(s==""||s==null||s==null||s==0||s==NaN)n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind";else{n=s;let a=null;for(let s=0;s<n.length;s++)if(n[s].mainIdx==e&&n[s].subIdx==t){a=n.filter(n=>n.mainIdx!=e||n.subIdx!=t);break}a===null?(n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind"):(localStorage.setItem("blindList",JSON.stringify(a)),o.className="cate")}}function blind_category(e){const t=document.querySelectorAll(".cate");t.forEach(e=>{e.className="cate"}),e!==null&&e.map(e=>{const t=document.querySelector(`#cate${e.mainIdx}-${e.subIdx}`);t.className+=" blind"})}</script><br><br><b>Viewed posts</b><div class=lately-viewed-list style=padding-left:4px></div><script defer>document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("latelyViewPostList")),n=document.querySelector(".lately-viewed-list");let t="";if(e==""||e==null||e==null||e==0||e==NaN)localStorage.setItem("latelyViewPostList",null),t+='<div class="lv-list">',t+=" ¬∑ Ïó¥ÎûåÌïú Ìè¨Ïä§Ìä∏Í∞Ä ÏóÜÏäµÎãàÎã§.",t+="</div>",n.innerHTML=t;else{for(let n=e.length-1;n>=0;n--)t+='<div class="lv-list">',t+=`<a href="${e[n].link}"> ¬∑ ${e[n].title}</a>`,t+="</div>";n.innerHTML=t}})</script><script defer>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="Support Vector Machine",c="https://freshrimpsushi.github.io/en/posts/2402/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script><br><b>Recent comment</b><div class=current-reply></div><script defer>const url="https://freshrimpsushi.com/blog/ajax/recent_comment.php?action=getCurrentComment";let recentRows=[];fetch(url).then(e=>e.json()).then(e=>{e.ok&&(recentRows=e.rows,render_recent_comment(recentRows))}).catch(e=>console.error(e));function render_recent_comment(e){const n=document.querySelector(".current-reply");let t="";e.map(e=>{let n="https://freshrimpsushi.github.io/en/";e.board_idx>-1?n+=`posts/${e.board_idx}#comment${e.cmt_idx}`:e.board_idx==-1?n+=`#comment${e.cmt_idx}`:n+=`categories/${e.board_title}#comment${e.cmt_idx}`,t+='<div class="current-reply-list">',t+=`<a href="${n}">`,t+=`<b> - ${e.author}</b>: `,t+=`${e.content}`,t+=`</a>`,t+=`</div>`}),n.innerHTML=t,renderKaTex(n)}</script><br></aside></div><footer><aside><div><p id=mirror-link style=text-align:center><a style=cursor:text href=http://localhost:1313//en/posts/2402/>¬© FreshrimpRestaurant / Powered by Î•òÎåÄÏãù, Ï†ÑÍ∏∞ÌòÑ</a><br>Contact:
<img src=https://freshrimpsushi.github.io/en/logo/gmail.png width=12px alt=mail> freshrimpsushi@gmail.com
<a href=https://freshrimpsushi.github.io/en/index.xml><img src=https://freshrimpsushi.github.io/en/logo/RSS.png width=12px alt=RSS> RSS</a></p></div><script type=text/javascript>var goIndex=function(){var e=document.getElementsByName("idx")[0].value,t="https://freshrimpsushi.github.io/en/posts/"+e;location.replace(t)};document.addEventListener("keydown",function(e){const n=document.getElementById("navigator");if(e.altKey&&e.ctrlKey&&e.key==="l"){e.preventDefault();var t=document.querySelector("#mirror-link a");t?t.click():console.log("Í±∞Ïö∏ ÎßÅÌÅ¨Î•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§.")}})</script><link rel=stylesheet href=https://freshrimpsushi.github.io/en/css/codefence.css><script src=https://freshrimpsushi.github.io/en/js/highlight.min.js></script><script>hljs.highlightAll()</script></aside></footer></body><script async src="https://www.googletagmanager.com/gtag/js?id=G-NLV8Y9PRK1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NLV8Y9PRK1")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4751085325232621" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/sweetalert2@11></script><script src=https://freshrimpsushi.github.io/en/js/fontawsome.min.js></script><script src=https://freshrimpsushi.github.io/en/js/common.js></script><script>document.addEventListener("DOMContentLoaded",()=>{fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/ip_checker.php";return postFetch(t,{user_ip:e})}).then(e=>e.json()).then(e=>{e.ok||(alert(`Ï∞®Îã®Îêú IPÏûÖÎãàÎã§.
Contact:
freshrimpsushi@gmail.com`),window.location.href="https://google.com")}).catch(e=>console.error(e))})</script></html>