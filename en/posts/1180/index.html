<!doctype html><html class=blog lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link rel=preload href=https://freshrimpsushi.github.io/en/css/style.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=preload href=https://freshrimpsushi.github.io/en/css/comment.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=icon href=https://freshrimpsushi.github.io/ko/logo/favicon.ico><meta name=msapplication-TileColor content="#FFFFFF"><meta name=msapplication-TileImage content="logo/basic.png"><meta name=NaverBot content="All"><meta name=NaverBot content="index,follow"><meta name=Yeti content="All"><meta name=Yeti content="index,follow"><meta name=google-site-verification content="KYAokS7-6C5YuXOjatJQsiK1T0O8x4YncYFIF4tneYI"><meta name=naver-site-verification content="e5651d6f97899061897203413efc84994f04bbba"><link rel=alternate type=application/rss+xml title=FreshrimpRestaurant href=https://freshrimpsushi.github.io/en/index.xml><title>Paper Review: DeepONet</title></head><meta name=title content="Paper Review: DeepONet"><meta name=description content="국내 최대의 수학, 물리학, 통계학 블로그"><meta property="og:title" content="Paper Review: DeepONet"><meta property="og:description" content><meta property="og:image" content="https://freshrimpsushi.github.io/en/logo/basic.png/"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"j_","name":"Paper Review: DeepONet","headline":"Paper Review: DeepONet","alternativeHeadline":"","description":"Overview and Summary Follow the references, equation numbers, and notation in the paper as closely as possible. For accessibility, this review is based on the version available on arXiv rather than the journal published version. Although the problems covered in the experimental section differ slightly, the core focus is not on the experimental results and performance but on the explanation of the DeepONet method itself. DeepONet is a deep learning","inLanguage":"en","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/freshrimpsushi.github.io\/en\/posts\/1180\/"},"author":{"@type":"Person","name":"전기현","url":"https://math.stackexchange.com/users/459895/ryu-dae-sick"},"creator":{"@type":"Person","name":"전기현"},"accountablePerson":{"@type":"Person","name":"전기현"},"copyrightHolder":"FreshrimpRestaurant","copyrightYear":"2024","dateCreated":"2024-08-11T00:00:00.00Z","datePublished":"2024-08-11T00:00:00.00Z","dateModified":"2024-08-11T00:00:00.00Z","publisher":{"@type":"Organization","name":"FreshrimpRestaurant","url":"https://freshrimpsushi.github.io/en/","logo":{"@type":"ImageObject","url":"https:\/\/freshrimpsushi.github.io\/en\/logo\/basic.png","width":"32","height":"32"}},"image":"https://freshrimpsushi.github.io/en/logo/basic.png","url":"https:\/\/freshrimpsushi.github.io\/en\/posts\/1180\/","wordCount":"2139","genre":[],"keywords":[]}</script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/mhchem.min.js integrity=sha384-F2ptQFZqNJuqfGGl28mIXyQ5kXH48spn7rcoS0Y9psqIKAcZPLd1NzwFlm/bl1mH crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>function renderKaTex(e){renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],trust:!0,trust:e=>["\\htmlId","\\href","\\includegraphics"].includes(e.command),macros:{"\\eqref":"(\\text{#1})","\\ref":"\\href{###1}{\\text{#1}}","\\label":"\\htmlId{#1}{}","\\sech":"\\operatorname{sech}","\\csch":"\\operatorname{csch}","\\sgn":"\\operatorname{sgn}","\\sign":"\\operatorname{sign}","\\sinc":"\\operatorname{sinc}","\\diag":"\\operatorname{diag}","\\diam":"\\operatorname{diam}","\\trace":"\\operatorname{trace}","\\Tr":"\\operatorname{Tr}","\\tr":"\\operatorname{tr}","\\re":"\\operatorname{Re}","\\im":"\\operatorname{Im}","\\Var":"\\operatorname{Var}","\\Poi":"\\operatorname{Poi}","\\Cov":"\\operatorname{Cov}","\\span":"\\operatorname{span}","\\supp":"\\operatorname{supp}","\\rank":"\\operatorname{rank}","\\nullity":"\\operatorname{nullity}","\\ad":"\\operatorname{ad}","\\Ric":"\\operatorname{Ric}","\\i":"\\mathrm{i}","\\d":"\\mathrm{d}","\\cR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5863.png}","\\acR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.4371.png}","\\bcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5899.png}","\\abcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.0596.png}","\\crH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\smallcrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\acrH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}","\\smallacrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}"},throwOnError:!1})}</script><body class=main><header><a href=https://freshrimpsushi.github.io/en/ rel=home><p style=text-align:center;font-size:1rem;color:#000><img src=https://freshrimpsushi.github.io/en/logo/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.png style=height:80px alt=logo></p></a></header><form method=get action=/en/search style=border:1px;text-align:center><div class=field><input type=text id=searchtext placeholder=🔍︎ class=input_text name=s style=background-color:#eee;text-align:center;width:200px;font-size:1.5rem;border:1px;border-radius:5px;padding-top:5px;padding-bottom:5px;margin-bottom:1.5rem></div></form><aside style=text-align:center;margin-bottom:1rem><a href=https://freshrimpsushi.github.io/ko//posts/1180/>한국어</a> |
<a href=https://freshrimpsushi.github.io/en//posts/1180/>English</a> |
<a href=https://freshrimpsushi.github.io/jp//posts/1180/>日本語</a></aside><div class=wrapper><div class=content><div class=content-box><title>Paper Review: DeepONet</title>
<a href=https://freshrimpsushi.github.io/en/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/ style=background-color:rgba(0,0,0,.8);color:orange;border-radius:10px;padding:5px>📂Machine Learning</a><h1>Paper Review: DeepONet</h1><aside><div class=innerheader><div class=innertoc><b>Table of Contents</b><nav id=TableOfContents><ul><li><a href=#overview-and-summary>Overview and Summary</a><ul><li><a href=#implementation>Implementation</a></li></ul></li><li><a href=#1-introduction>1 Introduction</a></li><li><a href=#2-methodology>2 Methodology</a><ul><li><a href=#21-deep-operator-networks-deeponets>2.1 Deep operator networks (DeepONets)</a></li><li><a href=#22-data-generation>2.2 Data generation</a></li></ul></li><li><a href=#3-number-of-sensors-for-identifying-nonlinear-dynamic-systems>3 Number of sensors for identifying nonlinear dynamic systems</a></li><li><a href=#4-simulation-results>4 Simulation results</a><ul><li><a href=#41-a-simple-1d-dynamic-system>4.1 A simple 1D dynamic system</a></li><li><a href=#42-gravity-pendulum-with-an-external-force>4.2 Gravity pendulum with an external force</a></li><li><a href=#43-diffusion-reaction-system-with-a-source-term>4.3 Diffusion-reaction system with a source term</a></li></ul></li><li><a href=#5-conclusion>5 Conclusion</a></li></ul></nav></div></div></aside><h2 id=overview-and-summary>Overview and Summary</h2><ul><li>Follow the references, equation numbers, and notation in the paper as closely as possible.</li></ul><p>For accessibility, this review is based on the <a href=https://arxiv.org/pdf/1910.03193>version available on arXiv</a> rather than the <a href=https://www.nature.com/articles/s42256-021-00302-5>journal published version</a>. Although the problems covered in the experimental section differ slightly, the core focus is not on the experimental results and performance but on the explanation of the DeepONet method itself.</p><p>DeepONet is a deep learning technique proposed for learning operators. An operator is a function that maps functions to functions (explained in detail in the main text). Specifically, for a function $u$, an operator $G$ is defined as follows.</p><p>$$
G : u \mapsto G(u)
$$</p><p>Here, $u$ is also a function and $Gu = G(u)$ is a function as well. The first key point is that &ldquo;DeepONet learns operators,&rdquo; and the second point is that it &ldquo;approximates $Gu$ as a series.&rdquo; Given an appropriate function space $X$, let&rsquo;s call its basis $\left\{ \phi_{k} \right\}$. Then $Gu \in X$ can be expressed as follows.</p><p>$$
Gu = \sum_{k=1}^{\infty} c_{k}\phi_{k}
$$</p><p>DeepONet learns $c_{k}$ and $\phi_{k}$, where the part learning the coefficients $c_{k}$ is called the branch network and the part learning the basis $\left\{ \phi_{k} \right\}$ is called the trunk network.</p><h3 id=implementation>Implementation</h3><ul><li><a href=../1153>Implementing with PyTorch</a></li><li>Implementing with Julia</li></ul><h2 id=1-introduction>1 Introduction</h2><p>The <a href=../1853>universal approximation theorem</a> guarantees that neural networks can approximate arbitrary <strong>continuous functions</strong>. This provides a theoretical basis for the effective functioning of artificial neural networks and deep learning techniques, which have been successful across various fields. Even more surprisingly, artificial neural networks can approximate all nonlinear <a href=../3281>functionals</a> and (nonlinear) <a href=../728>operators</a>.</p><blockquote><p>For readers unfamiliar with mathematics, let&rsquo;s briefly explain functions, functionals, and operators. These are fundamentally functions (which map a single element in the <a href=../470>domain</a> to exactly one element in the <a href=../470>codomain</a>). However, in contexts where the terms functional and operator are used, they have a slightly special meaning. Typically, a function means mapping numbers (or vectors) to numbers (or vectors). Polynomial functions, trigonometric functions, and other commonly dealt functions fall under this context.</p><p>$$
\text{function}: \mathbb{R}^{n} \to \mathbb{R}^{m}
$$</p><p>A function that maps functions to numbers (scalars) is specifically called a functional. A concrete example is the <a href=../828>definite integral</a>. If we define a functional $I_{[a,b]}$ as $\displaystyle I_{[a,b]}(f) = \int_{a}^{b} f(x)dx$, for each $f$ given, this functional maps the area under the curve of $f$ over the interval $[a, b]$. If we consider $X$ as an appropriate <a href=../3032>function space</a>, a functional can be expressed as follows.</p><p>$$
\text{functional}: X \to \mathbb{R}
$$</p><p>Operators map functions to functions. Examples include indefinite integrals and derivatives.</p><p>$$
\text{operator}: X \to X
$$
For a function $f$, defining an operator $D$ as $D(f) = \dfrac{df}{dx}$ makes it a <a href=../1638>differential operator</a> that maps a given function to its derivative. Defining an operator $I$ as $\displaystyle I(f) = \int f(x) dx$ maps a given function to its <a href=../1177>indefinite integral</a>.</p></blockquote><p>Now, the terms function, functional, and operator used below have the meanings given in the explanation above. Before delving into our main discussion, let&rsquo;s introduce the notation used throughout the paper. $G$ represents an operator where the variable is the function $u$.</p><p>$$
G : u \mapsto G(u)
$$</p><p>Since $G$ is an operator, its function value $G(u)$ is also a function, and its variable is denoted as $y$.</p><p>$$
G(u) : y \mapsto G(u)(y)
$$</p><p>Therefore, both $y$ and $G(u)(y)$ are real numbers.</p><p>$$
y, G(u)(y) \in \mathbb{R}
$$</p><p>The goal of this paper is to learn operators, and for that, we consider a neural network that takes both $u$ and $y$ as inputs and outputs $G(u)(y)$.</p><p>$$
\text{network} : (u, y) \mapsto G(u)(y)
$$</p><p>Theoretically, operator $G$ takes the function $u$ itself as a variable, but for computer simulations, discretization is necessary, and a finite number of function values $u(x_{1})$, $u(x_{2})$, $\dots$, and $u(x_{m})$ are used as inputs to the neural network. These are referred to as sensors in the paper. Thus, the proposed neural network has the following structure (Fig. 1A).</p><p><img src=1180_1.png#center alt></p><p align=center>Figure 1A</p><blockquote><p><strong>Theorem 1 (Universal Approximation Theorem for Operator)</strong> Let $\sigma$ be a <a href=../1206>non-polynomial function</a>. Let $X$ be a <a href=../703>Banach space</a>, and $K_{1} \subset X$, $K_{2} \subset X$ be <a href=../1705>compact</a> sets. Let $V \subset C(K_{1})$ be a compact set, and $G : V \to C(K_{2})$ be a nonlinear continuous operator.</p><p>Then, for any $\epsilon > 0$, there exist positive integers $n$, $p$, $m$, and constants $c_{i}^{k}$, $\xi_{ij}^{k}$, $\theta_{i}^{k}$, $\zeta_{k} \in \mathbb{R}$, $w_{k} \in \mathbb{R}^{d}$, $x_{j} \in K_{1}$ ($i = 1,\dots,n$, $k = 1,\dots,p$, $j = 1,\dots,m$) such that the following holds.</p><p>$$
\left| G(u)(y) - \sum\limits_{k=1}^{p} \underbrace{\sum\limits_{i=1}^{n} c_{i}^{k}\sigma\left( \sum\limits_{j=1}^{m} \xi_{ij}^{k}u(x_{j}) + \theta_{i}^{k} \right)}_{branch} \underbrace{\sigma(w_{k} \cdot y + \zeta_{k})}_{trunk} \right| &lt; \epsilon \quad \text{for all } u \in V, y \in K_{2} \tag{1}
$$</p></blockquote><p>In this paper, the above approximation is divided into two parts, called <strong>branch</strong> and <strong>trunk</strong>.</p><p>Although the approximation theorem suggests that neural networks could learn nonlinear operators, it does not suggest how to effectively train them. Even though the <a href=../1853>universal approximation theorem</a> implies that any [MLP] should be able to approximate any continuous function, CNNs or other neural network architectures perform better on image-related tasks. A useful network should be easy to train and have good <a href=../1807>generalization performance</a>. The authors aim to propose a new methodology that makes this possible.</p><p>To demonstrate that the proposed method is suitable for learning nonlinear operators, they impose very weak constraints on the data. Specifically, the input data $u_{i}$ must share the same sensors. However, these sensors don&rsquo;t necessarily need to be on a uniform grid, and there are no constraints on variable $y$. This condition is well illustrated in Fig. 1B.</p><p><img src=1180_2.png#center alt></p><p align=center>Figure 1B</p><p>The authors name the proposed architecture <strong>DeepONet</strong> (Deep Operator Network), which is composed of a <strong>branch net</strong> for the input function ($u(x_{1}), \dots, u(x_{m})$) and a <strong>trunk net</strong> for the output function variable ($y$). Details are elaborated in Section 2.</p><p>The paper considers two types of operators represented by <a href=../1505>ordinary differential equations (ODE)</a> and <a href=../1818>partial differential equations (PDE)</a>.</p><h2 id=2-methodology>2 Methodology</h2><h3 id=21-deep-operator-networks-deeponets>2.1 Deep operator networks (DeepONets)</h3><p>The authors focus on operator learning in general situations and impose the constraint that input functions ($u$) must share the same sensors. The inputs to the proposed neural network are divided into two parts, as seen in Fig. 1A: $[u(x_{1}), \dots, u(x_{m})]$ and $y$. There are no restrictions on the network architecture; the paper uses basic [fully-connected neural networks] (FNNs) to showcase performance capabilities. It is noted that [CNN], RNN architectures, or attention mechanisms could be integrated if desired.</p><p>Initially, the trunk network takes $y$ as input and outputs $[t_{1}, t_{2}, \dots, t_{p}]^{T} \in \mathbb{R}^{p}$. Each of the $p$ branch networks takes $[u(x_{1}), \dots, u(x_{m})]$ as input and outputs $b_{k} \in \mathbb{R}$ each ($k = 1,2,\dots,p$). These are combined as in Equation $(1)$ as follows.</p><p>$$
G(u)(y) \approx \sum_{k=1}^{p} b_{k}t_{k} = \sum_{k=1}^{p} b_{k}([u(x_{1}), u(x_{2}), \cdots, u(x_{m})]) t_{k}(y)
$$</p><p>It is notable to mention that the activation function is applied even in the last layer of the trunk net. Although not explicitly evident in these equations, this approach can be viewed as approximating the function $Gu = G(u)$ as a series. Given an appropriate <a href=../3032>function space</a> $X$ with <a href=../1583>basis</a> $\left\{ \phi_{k} \right\}$, it can be expressed as follows.</p><p>$$
Gu = \sum_{k=1}^{\infty} b_{k}\phi_{k}
$$</p><p>In other words, interpreting $t_{k} = \phi_{k}(y)$ as $t_{k}$ being the basis and $b_{k}$ the coefficient part of the series, DeepONet approximates $Gu$ by decomposing it into a series instead of approximating it directly. Although Theorem 1 does not require this, adding a bias (constant term) as shown improves generalization performance.</p><p>$$
G(u)(y) \approx \sum_{k=1}^{p} b_{k}t_{k} + b_{0}
$$</p><p>In practice, $p$ should be at least 10 or more; a larger $p$ increases computational cost. Therefore, the paper introduces Stacked DeepONet, which employs separate branch networks for each $b_{k}$ (Fig. 1C), and Unstacked DeepONet, where a single network learns all $b_{k}$ (Fig. 1D). All codes related to DeepONet can be found at <a href=https://github.com/lululxvi/deepxde>https://github.com/lululxvi/deepxde</a>, although it can be challenging to locate specific components among the author&rsquo;s other works featured there.</p><p><img src=1180_3.png#center alt></p><p align=center>Figure 1C and 1D</p><h3 id=22-data-generation>2.2 Data generation</h3><p>The paper discusses two function spaces: Gaussian random field (GRF) and [orthogonal polynomial space]. The authors used a GRF with a mean of $0$.</p><p>$$
u \sim \cal{G}(0, k_{l}(x_{1}, x_{2}))
$$</p><p>Here, $k_{l}(x_{1}, x_{2}) = \exp (- \| x_{1} - x_{2} \|^{2} / 2l^{2})$ is the covariance kernel. As an orthogonal polynomial space, the <a href=../1545>Chebyshev polynomials</a> are chosen. Let $M > 0$ be and $T_{i}$ be the first kind of Chebyshev polynomial.</p><p>$$
V_{\text{poly}} = \left\{ \sum\limits_{i=0}^{N-1} a_{i} T_{i}(x): |a_{i}| \le M \right \}
$$</p><p>The dataset was generated by random sampling of $a_{i} \in [-M, M]$. For each generated dataset, the <a href=../3317>Runge-Kutta method</a> solved the ODE systems and the <a href=../3494>finite difference method</a> was used to find reference solutions for second-order PDEs.</p><h2 id=3-number-of-sensors-for-identifying-nonlinear-dynamic-systems>3 Number of sensors for identifying nonlinear dynamic systems</h2><p>In this section, the need to discuss the number of sensors required to achieve arbitrary accuracy $\varepsilon$ in solving nonlinear dynamic systems using DeepONet is highlighted.</p><h2 id=4-simulation-results>4 Simulation results</h2><p>In this section, it is first confirmed that DeepONet provides better performance than FNN even for the simplest linear problems, followed by results for three nonlinear ODE and PDE problems. For all problems, the optimizer used is <a href=../3529>Adam</a> with a learning rate $0.001$, and unless explicitly mentioned, the network sizes are as shown in the table below.</p><p><img src=1180_4.png#center alt></p><p align=center>Table 1 and 2</p><h3 id=41-a-simple-1d-dynamic-system>4.1 A simple 1D dynamic system</h3><p>The one-dimensional dynamic system is expressed as follows.</p><p>$$
\begin{align*}
\dfrac{ds(x)}{dx} &= g(s(x), u(x), x), \qquad x\in[0, 1] \\
s(0) &= 0
\end{align*}
$$</p><p>The goal is to find the solution $s(x) \text{ on } [0,1]$ for any given $u$.</p><h4 id=411-linear-case-gsx-ux-x--ux>4.1.1 Linear case: $g(s(x), u(x), x) = u(x)$</h4><p>First, let&rsquo;s consider a very simple case.</p><p>$$
\begin{align*}
\dfrac{ds(x)}{dx} &= u(x), \qquad x\in[0, 1] \\
s(0) &= 0
\end{align*}
$$</p><p>In this case, the operator $G : u \mapsto s$ is the following <a href=../1177>indefinite integral</a> operator.</p><p>$$
G : u(x) \mapsto s(x) = \int_{0}^{x} u(\tau)d\tau
$$</p><p>To compare, FNN was trained to learn $G$ by adjusting depth and width. Increasing the depth doesn&rsquo;t significantly affect performance, but increasing the width reduces training error; however, generalization performance (test error) doesn&rsquo;t improve (Fig. 2).</p><p><img src=1180_5.png#center alt></p><p align=center>Figure 2</p><p>In contrast, DeepONet shows little difference between training and test errors (Fig. 3A). Performance slightly improves by adding a bias $b_{0}$. Moreover, Unstacked DeepONet, though having larger training errors, has lower test errors, which are more important. Unstacked DeepONet is also faster and uses considerably less memory due to fewer parameters.</p><p><img src=1180_6.png#center alt></p><p align=center>Figure 3</p><h4 id=412-nonlinear-case-gsx-ux-x--s2x--ux>4.1.2 Nonlinear case: $g(s(x), u(x), x) = −s^{2}(x) + u(x)$</h4><p>In this case, the focus moves more to comparing Unstacked DeepONet and Stacked DeepONet. By observing the correlation between training and test errors, it&rsquo;s clear that Unstacked DeepONet is stronger (Fig. 4A). It displayed even stronger correlations when tested with different learning rates and initial values (Fig. 4B).</p><p><img src=1180_7.png#center alt></p><p align=center>Figure 4</p><h3 id=42-gravity-pendulum-with-an-external-force>4.2 Gravity pendulum with an external force</h3><p>This subsection addresses the <a href=../1742>pendulum motion with an external force</a> as follows.</p><p>$$
\begin{align*}
\dfrac{ds_{1}}{dt} &= s_{2} \\
\dfrac{ds_{2}}{dt} &= -k \sin s_{1} + u(t) \\
s_{1}(0) &= 0, \quad s_{2}(0) = 0
\end{align*}
$$</p><p>The following content demonstrates how well DeepONet works for this problem, discussing the number of sensors, error convergence, etc.</p><h3 id=43-diffusion-reaction-system-with-a-source-term>4.3 Diffusion-reaction system with a source term</h3><p>The following diffusion-reaction equation is addressed.</p><p>$$
\dfrac{\partial s}{\partial t} = D \dfrac{\partial^{2} s}{\partial^{x}} + ks^{2} + u(x),\qquad x\in [0,1], t\in [0,1]
$$
$$
\text{with zero initial/boundary conditions}
$$</p><p>Unlike previous examples, $u(x)$ has a 1D variable, whereas $s(x, t)$ has a 2D variable. It is shown that DeepONet also works well here. The training data for one $u$ is as follows.</p><p>$$
\begin{align*}
\big( (u, (x_{1}, t_{1})), s(x_{1}, t_{1}) \big) \\
\big( (u, (x_{2}, t_{2})), s(x_{2}, t_{2}) \big) \\
\vdots \\
\big( (u, (x_{p}, t_{p})), s(x_{p}, t_{p}) \big)
\end{align*}
$$</p><p>$(u, (x_{i}, t_{i}))$ is the input for DeepONet, and $s(x_{i}, t_{i})$ is the final output. Concretely, $u$ is the input for the branch, and $(x_{i}, t_{i})$ is for the trunk. Such structured data is generated and used for training for each different $u$.</p><h2 id=5-conclusion>5 Conclusion</h2><p>This paper proposes DeepONet, a method for learning nonlinear operators. DeepONet is composed of branches, which learn coefficients, and trunks, which learn the basis. The body of the paper analyzes various factors affecting test errors (e.g., number of sensors, maximum prediction time, complexity of the input function space, size of the training dataset, and network size). It theoretically derives how the approximation error is impacted by various factors and shows that results align with calculations.</p><p>However, there is still much to research regarding a theoretical analysis of DeepONet itself. While the paper only uses FNN, potential explorations could involve connections with CNNs or attention mechanisms, as well as other neural network architectures and techniques.</p><aside style=text-align:right>2024-08-11&emsp;
전기현&emsp;
<a href=../1211>🎲 1180</a></aside><script>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="Paper Review: DeepONet",c="https://freshrimpsushi.github.io/en/posts/1180/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script></div><aside><h2>Comment</h2><div class=area-reply><div class=list-reply></div></div><div class=write-box><div class="write-author-info box-account"><input type=hidden name=cmt_idx>
<input class=ai-author type=text placeholder=Name>
<input class=ai-password type=password maxlength=20 placeholder=Password></div><div class=write-content><textarea class=ai-content value placeholder='Feel free to ask in english' style=ime-mode:active></textarea></div><button class=write-button onclick=write_comment() aria-label=send><i class='fa-solid fa-paper-plane'></i></button><aside class=tex>$\TeX$ is also applied to comments.</aside></div></aside><script>let commentRows=[];const listReply=document.querySelector(".list-reply");document.addEventListener("DOMContentLoaded",()=>{get_all_comment()});function get_all_comment(){fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=getAllComment";return postFetch(t,{board_idx:"1180",user_ip:e})}).then(e=>e.json()).then(e=>{e.ok&&(commentRows=e.rows,render_comment(commentRows))}).catch(e=>console.error(e))}function render_comment(e){const n=["류대식","전기현","ㅇㅇ","질문"],s=["류대식","전기현"];render_blank();let t="";e.map(e=>{t+=`<div id="comment${e.cmt_idx}" class="parents">`,t+=`<div class="content-info">`;let o="";e.cmt_cnt>125?o="🥇":e.cmt_cnt>25?o="🥈":e.cmt_cnt>5&&(o="🥉"),n.includes(e.author)&&(o="");let i="";e.ip_address==null?i="(-)":(ipParts=e.ip_address.split("."),i=`(${ipParts[0]}.${ipParts[1]})`),s.includes(e.author)&&(i=""),t+=`<div class="list-author">${o} ${e.author} ${i}</div>`,t+=`<sup class="list-date">${e.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,e.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> Waiting for approvement</div>`);let a=e.content;a=a.replace(/\n/g,"<br />"),t+=`<div class="content-text">${a} <span class="re-comment-button" onclick="re_comment('${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`,e.child.map(o=>{let c="child";e.ip_address&&o.ip_address===e.ip_address&&(c="parentself"),t+=`<div id="comment${o.cmt_idx}" class="${c}">`,t+=`<div class="content-info">`;let i="";o.cmt_cnt>5?i="🥉":o.cmt_cnt>25?i="🥈":o.cmt_cnt>125&&(i="🥇"),n.includes(o.author)&&(i="");let a="";o.ip_address==null?a="(-)":a=`(${o.ip_address})`,s.includes(o.author)&&(a=""),t+=`<div class="list-author">${i} ${o.author} ${a}</div>`,t+=`<sup class="list-date">${o.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,o.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> Waiting for approvement</div>`);let r=o.content;r=r.replace(/\n/g,"<br />"),t+=`<div class="content-text">${r} <span class="re-comment-button" onclick="re_comment('${o.cmt_idx}', '${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`})}),listReply.innerHTML=t,renderKaTex(listReply),location.href.indexOf("#")!=-1&&(location.href=location.href.substr(location.href.indexOf("#")))}function render_blank(){listReply.innerHTML=""}function write_comment(){const e=document.querySelector(".ai-author"),t=document.querySelector(".ai-password"),n=document.querySelector(".ai-content"),s=e.value,o=t.value,i=n.value;if(s===""||o===""||i===""){alert("빈칸을 채워주세요");return}const a="1180",r="",c="Paper Review: DeepONet";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeComment";return postFetch(t,{board_idx:a,board_slug:r,board_title:c,author:s.replace(/\+/g,"%2B"),password:o,content:i.replace(/\+/g,"%2B"),user_ip:e})}).then(e=>e.json()).then(s=>{s.ok?(commentRows.push(s.row),render_comment(commentRows),e.value="",t.value="",n.value=""):s.status===606?(Swal.fire(`Warning!
지속적인 도배 시도시
IP가 차단될 수 있습니다.`),e.value="",t.value="",n.value=""):s.status===607&&(alert(`지나친 댓글 도배를 확인하여
접근을 차단합니다.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}async function update_comment(e,t){const{value:n}=await Swal.fire({title:"댓글 수정",input:"password",inputPlaceholder:"글 작성 시 입력했던 패스워드를 입력하세요",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(s=>{if(s.ok){const s=document.querySelector(`#comment${e}`),o="https://freshrimpsushi.com/blog/ajax/comment.php?action=getComment";postFetch(o,{cmt_idx:e}).then(e=>e.json()).then(o=>{if(o.ok){const a=o.row,r=a.author,c=a.content;let i="";i+=`<div class="update-author-info">`,i+=`<input class="update-author" type="text" value="${r}" placeholder="이름" />`,i+=`<input class="update-password" type="password" value="${n}" placeholder="비밀번호" disabled />`,i+="</div>",i+=`<textarea class="update-content" value="" style="IME-MODE:active;">${c}</textarea>`,i+=`<input class="update_comment-button" type="submit" value="수정" onclick="update_comment_click(${e}, '${t}')" />`,i+=`<input class="update_comment-button" type="submit" value="취소" onclick="cancel_click(${e})" />`,s.innerHTML=i}}).catch(e=>console.error(e))}else Swal.fire("패스워드 일치 오류")}).catch(e=>console.error(e))}}async function delete_comment(e,t){const{value:n}=await Swal.fire({title:"댓글 삭제",text:"삭제하면 되돌릴 수 없습니다.",input:"password",icon:"warning",showCancelButton:!0,confirmButtonColor:"#3085d6",cancelButtonColor:"#d33",inputPlaceholder:"글 작성 시 입력했던 패스워드를 입력하세요",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(n=>{if(n.ok){const n="https://freshrimpsushi.com/blog/ajax/comment.php?action=deleteComment";postFetch(n,{cmt_idx:e}).then(e=>e.json()).then(n=>{Swal.fire("삭제되었습니다."),t==="parents"?commentRows=commentRows.filter(t=>t.cmt_idx!==e):t==="child"&&commentRows.map(t=>{t.child=t.child.filter(t=>t.cmt_idx!==e),t.child_cnt=t.child.length}),render_comment(commentRows)}).catch(e=>console.error(e))}else Swal.fire("패스워드 일치 오류")}).catch(e=>console.error(e))}}function update_comment_click(e,t){const i=document.querySelector(`#comment${e} .update-author`),a=document.querySelector(`#comment${e} .update-password`),r=document.querySelector(`#comment${e} .update-content`),n=i.value,s=a.value,o=r.value;(n===""||s===""||o==="")&&alert("빈칸을 채워주세요");const c="https://freshrimpsushi.com/blog/ajax/comment.php?action=updateComment";postFetch(c,{cmt_idx:e,author:n.replace(/\+/g,"%2B"),password:s,content:o.replace(/\+/g,"%2B")}).then(e=>e.json()).then(n=>{n.ok&&(Swal.fire("수정되었습니다."),t==="parents"?commentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}):t==="child"&&commentRows.map(t=>{t.cmt_idx==n.parent_cmt_idx&&t.child.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)})}),render_comment(commentRows),recentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}),render_recent_comment(recentRows))}).catch(e=>console.error(e))}function cancel_click(){render_comment(commentRows)}function re_comment(e,t){const s=document.querySelector(`#comment${e} .re-comment`);let n="";n+='<div class="re-comment-box">',n+='<div class="re-comment-author-info">',n+='<input class="re-comment-author" type="text" value="" placeholder="이름" />',n+='<input class="re-comment-password" type="password" value="" placeholder="비밀번호" />',n+="</div>",n+='<textarea class="re-comment-content" placeholder="내용" value="" style="IME-MODE:active;"></textarea>',t===void 0?n+=`<button class="write-button" onclick="re_comment_click(${e})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`:n+=`<button class="write-button" onclick="re_comment_click(${e}, ${t})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`,n+=`<button class="write-button" onclick="cancel_click(${e})" value="close"><i class='fa-solid fa-solid fa-ban'></i></button>`,n+="</div>",s.innerHTML=n}function re_comment_click(e,t){const n=document.querySelector(`#comment${e} .re-comment-author`),s=document.querySelector(`#comment${e} .re-comment-password`),o=document.querySelector(`#comment${e} .re-comment-content`),i=n.value,a=s.value,r=o.value;if(i===""||a===""||r===""){alert("빈칸을 채워주세요");return}const c="1180",l="",d="Paper Review: DeepONet";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(n=>{const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeReComment";return postFetch(s,{board_idx:c,board_slug:l,board_title:d,cmt_idx:t===void 0?e:t,author:i.replace(/\+/g,"%2B"),password:a,content:r.replace(/\+/g,"%2B"),user_ip:n})}).then(e=>e.json()).then(i=>{i.ok?(commentRows.map(n=>{t===void 0?n.cmt_idx==e&&n.child.push(i.row):n.cmt_idx==t&&n.child.push(i.row)}),render_comment(commentRows)):i.status==606?(Swal.fire(`Warning!
지속적인 도배 시도시
IP가 차단될 수 있습니다.`),n.value="",s.value="",o.value=""):i.status===607&&(alert(`지나친 댓글 도배를 확인하여
접근을 차단합니다.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}</script></div><aside class=sidebar><aside><style>.reddot a:link{color:#67d10f;text-shadow:0 0 10px #d3d3d3;font-weight:700}.reddot a:visited{color:#f5f5f5}</style><p class=reddot style=text-align:center;margin:0><a href=https://freshrimpsushi.github.io/en/posts/2707/>Summer Special Omakase<br>「Imaginary Numbers」</a></p></aside><br><div class=category></div><div style=display:flex>Click ● to highlight only you interested.<div class=resetmute><button class="sb-btn btnReset" style=border-radius:5px;border:0>reset</button>
<button class="sb-btn btnMute" style=border-radius:5px;border:0>mute</button></div></div><script defer>const color={green:"#33cc33",yellow:"#ffcc00",red:"#ff3333",black:"#000000"},categoryRows=[[{idx:1,name:"함수",color:color.green,show:"Functions",size:"146"},{idx:2,name:"보조정리",color:color.green,show:"Lemmas",size:"55"},{idx:3,name:"미분적분학",color:color.green,show:"Calculus",size:"45"},{idx:4,name:"행렬대수",color:color.green,show:"Matrix Algebra",size:"117"}],[{idx:1,name:"정수론",color:color.green,show:"Number Theory",size:"90"},{idx:2,name:"집합론",color:color.green,show:"Set Theory",size:"49"},{idx:3,name:"그래프이론",color:color.green,show:"Graph Theory",size:"65"},{idx:4,name:"선형대수",color:color.green,show:"Linear Algebra",size:"97"},{idx:5,name:"해석개론",color:color.green,show:"Analysis",size:"84"},{idx:6,name:"추상대수",color:color.green,show:"Abstract Algebra",size:"98"},{idx:7,name:"위상수학",color:color.green,show:"Topology",size:"64"},{idx:8,name:"기하학",color:color.green,show:"Geometry",size:"167"}],[{idx:1,name:"다변수벡터해석",color:color.green,show:"Vector Analysis",size:"37"},{idx:2,name:"복소해석",color:color.green,show:"Complex Anaylsis",size:"71"},{idx:3,name:"측도론",color:color.green,show:"Measure Theory",size:"53"},{idx:4,name:"푸리에해석",color:color.green,show:"Fourier Analysis",size:"54"},{idx:5,name:"표현론",color:color.red,show:"Representation Theory",size:"7"},{idx:6,name:"초함수론",color:color.green,show:"Distribution Theory",size:"22"},{idx:7,name:"단층촬영",color:color.green,show:"Tomography",size:"20"}],[{idx:1,name:"거리공간",color:color.green,show:"Metric Space",size:"38"},{idx:2,name:"바나흐공간",color:color.green,show:"Banach Space",size:"38"},{idx:3,name:"힐베르트공간",color:color.green,show:"Hilbert Space",size:"31"},{idx:4,name:"르벡공간",color:color.green,show:"Lebesgue Space",size:"33"}],[{idx:1,name:"상미분방정식",color:color.green,show:"ODE",size:"58"},{idx:2,name:"편미분방정식",color:color.green,show:"PDE",size:"60"},{idx:3,name:"확률미분방정식",color:color.green,show:"SDE",size:"26"}],[{idx:1,name:"줄리아",color:color.green,show:"Julia",size:"232"},{idx:2,name:"알고리즘",color:color.green,show:"Algorithm",size:"28"},{idx:3,name:"수치해석",color:color.green,show:"Numerical Analysis",size:"63"},{idx:4,name:"최적화이론",color:color.green,show:"Optimization Theory",size:"37"},{idx:5,name:"머신러닝",color:color.green,show:"Machine Learning",size:"114"},{idx:6,name:"프로그래밍",color:color.yellow,show:"Programming",size:"120"},{idx:7,name:"세이버메트릭스",color:color.green,show:"Sabermetrics",size:"232",size:"13"}],[{idx:1,name:"물리학",color:color.green,show:"Physics",size:"30"},{idx:2,name:"수리물리",color:color.green,show:"Mathematical Physics",size:"77"},{idx:3,name:"고전역학",color:color.green,show:"Classical Mechanics",size:"48"},{idx:4,name:"전자기학",color:color.green,show:"Electrodynamics",size:"51"},{idx:5,name:"양자역학",color:color.green,show:"Quantum Mechanics",size:"57"},{idx:6,name:"열물리학",color:color.green,show:"Thermal Physics",size:"29"}],[{idx:1,name:"R",color:color.green,show:"R",size:"54"},{idx:2,name:"데이터확보",color:color.green,show:"Data Sets",size:"29"},{idx:3,name:"데이터과학",color:color.green,show:"Data Science",size:"41"},{idx:4,name:"통계적검정",color:color.green,show:"Statistical Test",size:"33"},{idx:5,name:"통계적분석",color:color.green,show:"Statistical Analysis",size:"76"},{idx:6,name:"수리통계학",color:color.green,show:"Mathematical Statistics",size:"123"},{idx:7,name:"확률분포론",color:color.green,show:"Probability Distribution",size:"84"},{idx:8,name:"확률론",color:color.green,show:"Probability Theory",size:"80"},{idx:9,name:"위상데이터분석",color:color.green,show:"TDA",size:"40"}],[{idx:1,name:"논문작성",color:color.red,show:"Writing",size:"63"},{idx:2,name:"생새우초밥지",color:color.black,show:"JOF",size:"7"}]];document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("blindList"));(e==""||e==null||e==null||e==0||e==NaN)&&localStorage.setItem("blindList",null),render_category(categoryRows),blind_category(e);const t=document.querySelector(".btnReset");t.addEventListener("click",()=>{let e=new Array;localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)});const n=document.querySelector(".btnMute");n.addEventListener("click",()=>{let e=new Array;for(let t=0;t<categoryRows.length;t++)categoryRows[t].map(n=>{const s={mainIdx:t,subIdx:n.idx};e.push(s)});localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)})});function render_category(e){const n=document.querySelector(".category");let t="";for(let n=0;n<e.length;n++)e[n].map(e=>{t+=`<span id="cate${n}-${e.idx}" class="cate etewsert">`,t+=`<span onclick="check_blind(${n}, ${e.idx});" style="cursor: pointer; color: ${e.color}">●</span>`,t+=`<a href="https://freshrimpsushi.github.io/en/categories/${e.name.toLowerCase()}/">`,t+=` ${e.show} (${e.size})</a>`,t+="</span>",screen.width>954?t+="<br>":t+=" "}),t+="<hr>";n.innerHTML=t}function check_blind(e,t){const o=document.querySelector(`#cate${e}-${t}`);let n=new Array;const i={mainIdx:e,subIdx:t};let s=JSON.parse(localStorage.getItem("blindList"));if(s==""||s==null||s==null||s==0||s==NaN)n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind";else{n=s;let a=null;for(let s=0;s<n.length;s++)if(n[s].mainIdx==e&&n[s].subIdx==t){a=n.filter(n=>n.mainIdx!=e||n.subIdx!=t);break}a===null?(n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind"):(localStorage.setItem("blindList",JSON.stringify(a)),o.className="cate")}}function blind_category(e){const t=document.querySelectorAll(".cate");t.forEach(e=>{e.className="cate"}),e!==null&&e.map(e=>{const t=document.querySelector(`#cate${e.mainIdx}-${e.subIdx}`);t.className+=" blind"})}</script><br><br><b>Viewed posts</b><div class=lately-viewed-list style=padding-left:4px></div><script defer>document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("latelyViewPostList")),n=document.querySelector(".lately-viewed-list");let t="";if(e==""||e==null||e==null||e==0||e==NaN)localStorage.setItem("latelyViewPostList",null),t+='<div class="lv-list">',t+=" · 열람한 포스트가 없습니다.",t+="</div>",n.innerHTML=t;else{for(let n=e.length-1;n>=0;n--)t+='<div class="lv-list">',t+=`<a href="${e[n].link}"> · ${e[n].title}</a>`,t+="</div>";n.innerHTML=t}})</script><script defer>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="Paper Review: DeepONet",c="https://freshrimpsushi.github.io/en/posts/1180/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script><br><b>Recent comment</b><div class=current-reply></div><script defer>const url="https://freshrimpsushi.com/blog/ajax/recent_comment.php?action=getCurrentComment";let recentRows=[];fetch(url).then(e=>e.json()).then(e=>{e.ok&&(recentRows=e.rows,render_recent_comment(recentRows))}).catch(e=>console.error(e));function render_recent_comment(e){const n=document.querySelector(".current-reply");let t="";e.map(e=>{let n="https://freshrimpsushi.github.io/en/";e.board_idx>-1?n+=`posts/${e.board_idx}#comment${e.cmt_idx}`:e.board_idx==-1?n+=`#comment${e.cmt_idx}`:n+=`categories/${e.board_title}#comment${e.cmt_idx}`,t+='<div class="current-reply-list">',t+=`<a href="${n}">`,t+=`<b> - ${e.author}</b>: `,t+=`${e.content}`,t+=`</a>`,t+=`</div>`}),n.innerHTML=t,renderKaTex(n)}</script><br></aside></div><footer><aside><div><p id=mirror-link style=text-align:center><a style=cursor:text href=http://localhost:1313//en/posts/1180/>© FreshrimpRestaurant / Powered by 류대식, 전기현</a><br>Contact:
<img src=https://freshrimpsushi.github.io/en/logo/gmail.png width=12px alt=mail> freshrimpsushi@gmail.com
<a href=https://freshrimpsushi.github.io/en/index.xml><img src=https://freshrimpsushi.github.io/en/logo/RSS.png width=12px alt=RSS> RSS</a></p></div><script type=text/javascript>var goIndex=function(){var e=document.getElementsByName("idx")[0].value,t="https://freshrimpsushi.github.io/en/posts/"+e;location.replace(t)};document.addEventListener("keydown",function(e){const n=document.getElementById("navigator");if(e.altKey&&e.ctrlKey&&e.key==="l"){e.preventDefault();var t=document.querySelector("#mirror-link a");t?t.click():console.log("거울 링크를 찾지 못했습니다.")}})</script></aside></footer></body><script async src="https://www.googletagmanager.com/gtag/js?id=G-NLV8Y9PRK1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NLV8Y9PRK1")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4751085325232621" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/sweetalert2@11></script><script src=https://freshrimpsushi.github.io/en/js/fontawsome.min.js></script><script src=https://freshrimpsushi.github.io/en/js/common.js></script><script>document.addEventListener("DOMContentLoaded",()=>{fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/ip_checker.php";return postFetch(t,{user_ip:e})}).then(e=>e.json()).then(e=>{e.ok||(alert(`차단된 IP입니다.
Contact:
freshrimpsushi@gmail.com`),window.location.href="https://google.com")}).catch(e=>console.error(e))})</script></html>