<!doctype html><html class=blog lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link rel=preload href=https://freshrimpsushi.github.io/en/css/style.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=preload href=https://freshrimpsushi.github.io/en/css/comment.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=icon href=https://freshrimpsushi.github.io/ko/logo/favicon.ico><meta name=msapplication-TileColor content="#FFFFFF"><meta name=msapplication-TileImage content="logo/basic.png"><meta name=NaverBot content="All"><meta name=NaverBot content="index,follow"><meta name=Yeti content="All"><meta name=Yeti content="index,follow"><meta name=google-site-verification content="KYAokS7-6C5YuXOjatJQsiK1T0O8x4YncYFIF4tneYI"><meta name=naver-site-verification content="e5651d6f97899061897203413efc84994f04bbba"><link rel=alternate type=application/rss+xml title=FreshrimpRestaurant href=https://freshrimpsushi.github.io/en/index.xml><title>What is LASSO Regression?</title></head><meta name=title content="What is LASSO Regression?"><meta name=description content="Íµ≠ÎÇ¥ ÏµúÎåÄÏùò ÏàòÌïô, Î¨ºÎ¶¨Ìïô, ÌÜµÍ≥ÑÌïô Î∏îÎ°úÍ∑∏"><meta property="og:title" content="What is LASSO Regression?"><meta property="og:description" content><meta property="og:image" content="https://freshrimpsushi.github.io/en/logo/basic.png/"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"r_","name":"What is LASSO Regression?","headline":"What is LASSO Regression?","alternativeHeadline":"","description":"Definition $$ \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; x_{11} \u0026amp; \\cdots \u0026amp; x_{p1} \\\\ 1 \u0026amp; x_{12} \u0026amp; \\cdots \u0026amp; x_{p2} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 1 \u0026amp; x_{1n} \u0026amp; \\cdots \u0026amp; x_{pn} \\end{bmatrix} \\begin{bmatrix} \\beta_{0} \\\\ \\beta_{1} \\\\ \\vdots \\\\ \\beta_{p} \\end{bmatrix} \u002b \\begin{bmatrix} \\varepsilon_{1} \\\\ \\varepsilon_{2} \\\\ \\vdots \\\\ \\varepsilon_{n} \\end{bmatrix} $$ Given $n$ data points and","inLanguage":"en","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/freshrimpsushi.github.io\/en\/posts\/2571\/"},"author":{"@type":"Person","name":"Î•òÎåÄÏãù","url":"https://math.stackexchange.com/users/459895/ryu-dae-sick"},"creator":{"@type":"Person","name":"Î•òÎåÄÏãù"},"accountablePerson":{"@type":"Person","name":"Î•òÎåÄÏãù"},"copyrightHolder":"FreshrimpRestaurant","copyrightYear":"2024","dateCreated":"2024-05-20T00:00:00.00Z","datePublished":"2024-05-20T00:00:00.00Z","dateModified":"2024-05-20T00:00:00.00Z","publisher":{"@type":"Organization","name":"FreshrimpRestaurant","url":"https://freshrimpsushi.github.io/en/","logo":{"@type":"ImageObject","url":"https:\/\/freshrimpsushi.github.io\/en\/logo\/basic.png","width":"32","height":"32"}},"image":"https://freshrimpsushi.github.io/en/logo/basic.png","url":"https:\/\/freshrimpsushi.github.io\/en\/posts\/2571\/","wordCount":"2603","genre":[],"keywords":[]}</script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/mhchem.min.js integrity=sha384-F2ptQFZqNJuqfGGl28mIXyQ5kXH48spn7rcoS0Y9psqIKAcZPLd1NzwFlm/bl1mH crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>function renderKaTex(e){renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],trust:!0,trust:e=>["\\htmlId","\\href","\\includegraphics"].includes(e.command),macros:{"\\eqref":"(\\text{#1})","\\ref":"\\href{###1}{\\text{#1}}","\\label":"\\htmlId{#1}{}","\\sech":"\\operatorname{sech}","\\csch":"\\operatorname{csch}","\\sgn":"\\operatorname{sgn}","\\sign":"\\operatorname{sign}","\\sinc":"\\operatorname{sinc}","\\diag":"\\operatorname{diag}","\\diam":"\\operatorname{diam}","\\Tr":"\\operatorname{Tr}","\\tr":"\\operatorname{tr}","\\re":"\\operatorname{Re}","\\im":"\\operatorname{Im}","\\Var":"\\operatorname{Var}","\\Poi":"\\operatorname{Poi}","\\Cov":"\\operatorname{Cov}","\\span":"\\operatorname{span}","\\supp":"\\operatorname{supp}","\\rank":"\\operatorname{rank}","\\nullity":"\\operatorname{nullity}","\\Ric":"\\operatorname{Ric}","\\i":"\\mathrm{i}","\\d":"\\mathrm{d}","\\cR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5863.png}","\\acR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.4371.png}","\\bcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5899.png}","\\abcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.0596.png}","\\crH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\smallcrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\acrH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}","\\smallacrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}"},throwOnError:!1})}</script><body class=main><header><a href=https://freshrimpsushi.github.io/en/ rel=home><p style=text-align:center;font-size:1rem;color:#000><img src=https://freshrimpsushi.github.io/en/logo/%ED%86%B5%EA%B3%84%EC%A0%81%EB%B6%84%EC%84%9D.png style=height:80px alt=logo></p></a></header><form method=get action=/en/search style=border:1px;text-align:center><div class=field><input type=text id=searchtext placeholder=üîçÔ∏é class=input_text name=s style=background-color:#eee;text-align:center;width:200px;font-size:1.5rem;border:1px;border-radius:5px;padding-top:5px;padding-bottom:5px;margin-bottom:1.5rem></div></form><aside style=text-align:center;margin-bottom:1rem><a href=https://freshrimpsushi.github.io/ko//posts/2571/>ÌïúÍµ≠Ïñ¥</a> |
<a href=https://freshrimpsushi.github.io/en//posts/2571/>English</a> |
<a href=https://freshrimpsushi.github.io/jp//posts/2571/>Êó•Êú¨Ë™û</a></aside><div class=wrapper><div class=content><div class=content-box><title>What is LASSO Regression?</title>
<a href=https://freshrimpsushi.github.io/en/categories/%ED%86%B5%EA%B3%84%EC%A0%81%EB%B6%84%EC%84%9D/ style=background-color:rgba(0,0,0,.8);color:orange;border-radius:10px;padding:5px>üìÇStatistical Analysis</a><h1>What is LASSO Regression?</h1><aside><div class=innerheader><div class=innertoc><b>Table of Contents</b><nav id=TableOfContents><ul><li><a href=#definition>Definition</a></li><li><a href=#explanation>Explanation</a><ul><li><a href=#why-use-it>Why Use It?</a></li><li><a href=#tuning-parameter-lambda>Tuning Parameter $\lambda$</a></li><li><a href=#differences-from-ridge-regression>Differences from Ridge Regression</a></li></ul></li><li><a href=#formulas>Formulas</a><ul><li><a href=#optimal-solution-6>Optimal Solution</a></li><li><a href=#derivation-7>Derivation</a></li><li><a href=#algorithm>Algorithm</a></li></ul></li><li><a href=#see-also>See Also</a></li></ul></nav></div></div></aside><h2 id=definition>Definition</h2><p>$$
\begin{bmatrix}
y_{1}
\\ y_{2}
\\ \vdots
\\ y_{n}
\end{bmatrix} = \begin{bmatrix}
1 & x_{11} & \cdots & x_{p1}
\\ 1 & x_{12} & \cdots & x_{p2}
\\ \vdots & \vdots & \ddots & \vdots
\\ 1 & x_{1n} & \cdots & x_{pn}
\end{bmatrix} \begin{bmatrix}
\beta_{0}
\\ \beta_{1}
\\ \vdots
\\ \beta_{p}
\end{bmatrix} + \begin{bmatrix}
\varepsilon_{1}
\\ \varepsilon_{2}
\\ \vdots
\\ \varepsilon_{n}
\end{bmatrix}
$$
Given $n$ <a href=../2418>data</a> points and $p &lt; n$, a <a href=../666>linear multiple regression model</a> can be represented by a <a href=../550>design matrix</a> as shown above, and succinctly expressed as $Y = X \beta + \varepsilon$. Here, the following <a href=../1463>optimization problem</a> is called <strong>BPDN</strong>, and solving BPDN is referred to as <strong>LASSO</strong> or <strong>LASSO Regression</strong>.
$$
\argmin_{\beta} \left( {{ 1 } \over { 2 }} \left\| Y - X \beta \right\|_{2}^{2} + \lambda \left\| \beta \right\|_{1} \right)
$$
In this context, $\lambda \ge 0$ is known as the <strong>Tuning Parameter</strong>.</p><hr><ul><li>$\left\| \cdot \right\|_{2}$ represents the <a href=../1225>Euclidean norm</a>, and $\left\| \cdot \right\|_{1}$ denotes the sum of <a href=../3083>absolute values</a>.</li></ul><h2 id=explanation>Explanation</h2><p>LASSO, as the name suggests, shrinks the <a href=../3083>absolute values</a> of the <a href=../2458>regression coefficients</a> in a <a href=../2540>regression problem</a> to the minimum necessary for selection.</p><p>In <a href=../../categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D>machine learning</a>, BPDN can also be seen as an <a href=../1807>$l_{1}$ regularization</a> that adds $\lambda \left\| \beta \right\|_{1}$ to the general <a href=../356>least squares problem</a>.</p><h3 id=why-use-it>Why Use It?</h3><p>It&rsquo;s beneficial to read the <a href=../2563>sparse regression</a> document first:</p><ul><li><strong>From a statistical perspective</strong>: It&rsquo;s used to find models that are easy to interpret. Fundamentally, if the size of the <a href=../2458>regression coefficients</a> is not significantly large compared to the scale of the data, they are considered statistically insignificant. In other words, if they are almost $0$, they might not be necessary to explain the data. This interpretation may not be exactly the same in LASSO regression, but the ultimate goal is to identify and address &lsquo;small-sized regression coefficients&rsquo;.</li><li><strong>From a machine learning perspective</strong>: It&rsquo;s used to prevent overfitting. A model might be created to cover even the most special cases by adding very complex terms or acquiring additional data to describe the given data well. However, meticulously fitting the model might result in excellent performance on training data but poor performance in practical tests. Therefore, despite the penalty reducing the explanatory power of the data, it&rsquo;s a way to avoid the risk of overfitting associated with finding minor regression coefficients for countless variables.</li></ul><p>This is just a difference in perspective, but if read carefully, it&rsquo;s essentially the same statement.</p><h3 id=tuning-parameter-lambda>Tuning Parameter $\lambda$</h3><ul><li>This explanation is about <a href=../2567>ridge regression</a>, but the context of handling the tuning parameter applies to LASSO regression as well.</li></ul><p>The tuning parameter $\lambda$ introduced in the definition increases the penalty $\left\| \lambda \right\|$ as it increases. If it&rsquo;s too small, it&rsquo;s no different from regular regression analysis, and if it&rsquo;s too large, $\beta = \mathbf{0}$ becomes the best choice regardless of whether it explains the data or not. As an extreme and intuitive example, if the scale of the data values is around 0~10 but a large weight $\lambda = 10^{6}$ is given to the penalty, the focus on minimizing $\left\| \beta \right\|$ prevents the model from performing its primary function‚Äîcreating a model that explains the data well. The point is that an appropriate $\lambda$ must be chosen, and there&rsquo;s no inherent good or bad about $\lambda$ being large or small just by looking at the formula.</p><p><img src=2023-04-27-11-34-04.png#center alt></p><p>Therefore, without any specific intuition or criteria for the given data, one method is to vary $\lambda$ and select the one that minimizes the objective function. The above figure illustrates the error after cross-validation in an analysis by changing $\lambda$, plotted as a function of $\lambda$<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. The graph shows the <a href=../2027>minimum value</a> around $5 \times 10^{-1}$, marked with a vertical dotted line, and without a particular reason, it&rsquo;s reasonable to use $\lambda$ at that value.</p><h3 id=differences-from-ridge-regression>Differences from Ridge Regression</h3><p>Historically, Ridge was introduced in 1970 as a method to increase the <a href=../2059>efficiency</a> of <a href=../2440>parameter</a> <a href=../1730>estimation</a> by sacrificing a bit of <a href=../1745>unbiasedness</a> to gain a bit of bias in the <a href=../1739>bias-variance trade-off</a> relationship<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, and LASSO was first introduced in 1986 in Geophysics and then reintroduced in 1996, when it was named LASSO.<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></p><blockquote><ul><li>Objective function of ridge regression:
$$\argmin_{\beta} \left( \left\| Y - X \beta \right\|_{2}^{2} + \lambda \left\| \beta \right\|_{2}^{2} \right)$$</li><li>Objective function of LASSO regression:
$$\argmin_{\beta} \left( \left\| Y - X \beta \right\|_{2}^{2} + \lambda \left\| \beta \right\|_{1} \right)$$</li></ul></blockquote><p>As seen, the objective functions of <a href=../2567>ridge regression</a> and <a href=../2571>LASSO regression</a> are very similar, leading to frequent comparisons, but frankly, the only similarity is the formal appearance of the objective functions, and comparing their pros and cons might be an oversimplification. Commonly, the differences between ridge and LASSO are explained in terms of whether the penalty term is $l_{1}$ or $l_{2}$, whether the optimal solution is differentiable and can be easily represented in a <a href=../2576>closed form</a>, or whether it can actually reduce certain coefficients to $0$. If more detailed, Python example codes are included, and empirically, it&rsquo;s often mentioned what is generally superior and under what circumstances the other may be better.</p><p>&mldr; However, such explanations are abundantly available in various books, Wikipedia, blogs, etc. Posts that neatly summarize these well-known points can be easily found by searching &lsquo;Ridge vs LASSO&rsquo; on Google. In this post, we aim to delve a bit deeper, just a little bit more, than them.</p><hr><ul><li>The following content explains how LASSO regression differs from ridge regression from the perspective of LASSO regression. To see how ridge regression views LASSO regression, check the <a href=../2567>relevant post</a>.</li></ul><p>Generally, it&rsquo;s often explained that LASSO regression is more expensive or computationally complex than ridge regression. While not entirely incorrect, if the goal is <a href=../2563>sparse regression</a>, the additional cost might not be an issue.</p><p><img src=2023-05-04-12-41-40.png#center alt></p><p>In the above figure, $\hat{\beta}$ is the optimal solution for the original least squares problem, the left side represents the solution space of LASSO regression ($l_{1}$), and the right side represents ridge regression ($l_{2}$).<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> This geometric explanation is so prevalent that searching &lsquo;Ridge vs LASSO&rsquo; on Google yields countless images, making it an effective explanation.</p><ul><li><strong>(Left) LASSO</strong>: The statement that the absolute values of regression coefficients $\beta_{1}$ and $\beta_{2}$ are equal to some value $r$ means that it&rsquo;s a point on the square $\left| \beta_{1} \right| + \left| \beta_{2} \right| = r$ with side length $\sqrt{r}$. The optimal solution in BPDN must be a point where the contour of $\left\| Y - X \beta \right\|_{2}$ is lowest while also intersecting the square, and as shown in the figure, it can be precisely on an axis. Having a solution on an axis means that at least one dimension among others is $0$, indicating that LASSO can make certain regression coefficients exactly $0$.</li><li><strong>(Right) Ridge</strong>: The statement that the square of regression coefficients $\beta_{1}$ and $\beta_{2}$ equals some value $r$ means it&rsquo;s a point on the circle $\beta_{1}^{2} + \beta_{2}^{2} = r$ with radius $r$. Similar to LASSO, at a certain level of $r$, the intersection of the contour created by $\hat{\beta}$ and the circle is <a href=../524>almost certainly</a> not on an axis.</li></ul><p><img src=2023-05-04-13-18-51.png#center alt></p><p>Of course, ridge regression has its merits, but in the context of <a href=../2563>sparse regression</a>, comparing it to a method that cannot make certain coefficients $0$ is odd. <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> Under certain types of data, depending on how $\lambda$ is given, in terms of overfitting, computational speed, and simplicity&mldr; all those assumptions might be irrelevant. Ridge regression cannot do what LASSO regression can, and there&rsquo;s fundamentally no way to bridge this difference. The comparison between LASSO and ridge should not be based on minor differences or pros and cons.</p><ul><li>If only considering the outcome, $\beta_{k} = 0$ and $\beta_{k} \approx 0$ might not seem very different, but considering the process, the fact that the <a href=../2538>independent variable</a> $X_{k}$ can be <strong>excluded from the start</strong> if $\beta_{k} = 0$ makes a significant difference. If, for instance, in ridge regression $\beta_{k} \approx 0$ but in LASSO regression it&rsquo;s definitively $\beta_{k} = 0$ for about 1 million variables, even if the model performance is similar, ridge regression would require 1 million more multiplications per data point fitting.</li></ul><p>Meanwhile, LASSO actually has a known closed form for the optimal solution under specific conditions, and <a href=../2569>soft thresholding</a> is used in that optimal solution. In other words, the formula itself includes a part that makes $\beta_{k}$ $0$, and to grasp LASSO regression without relying on visuals or intuition, one must understand the following mathematical discussions.</p><h2 id=formulas>Formulas</h2><h3 id=optimal-solution-6>Optimal Solution <sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup></h3><p>$$
L \left( \beta \right) = {{ 1 } \over { 2 }} \left\| Y - X \beta \right\|_{2}^{2} + \lambda \left\| \beta \right\|_{1}
$$
When $\lambda$ is given as a <a href=../2465>constant</a>, let&rsquo;s express the objective function $L$ of LASSO regression as shown above. Generally, LASSO regression does not have a closed form for the optimal solution, but assuming all columns of $X$ are <a href=../3045>orthogonal</a> to each other, the $k$-th component $\left( \hat{\beta} \right)_{k}$ of $\hat{\beta} = \argmin_{\beta} L \left( \beta \right)$ is as follows.
$$
\begin{align*}
\left( \hat{\beta} \right)_{k} =& {{ 1 } \over { \left( X^{T} X \right)_{kk} }} \eta_{\lambda} \left( X^{T} Y \right)_{k}
\\ = & {{ 1 } \over { \left( X^{T} X \right)_{kk} }} \begin{cases}
\left( X^{T} Y \right)_{k} + \lambda & , \text{if } \left( X^{T} Y \right)_{k} &lt; - \lambda
\\ 0 & , \text{if } \left( X^{T} Y \right)_{k} \in [-\lambda, \lambda]
\\ \left( X^{T} Y \right)_{k} - \lambda & , \text{if } \left( X^{T} Y \right)_{k} > \lambda
\end{cases}
\end{align*}
$$
Here, $A^{T}$ is the <a href=../3002>transpose matrix</a> of $A$, $A^{-1}$ is the <a href=../3003>inverse matrix</a> of $A$, and $\eta_{\lambda}$ is <a href=../2569>soft thresholding</a>.</p><h3 id=derivation-7>Derivation <sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup></h3><blockquote><p><a href=../1926>Gradient of Vectors and Matrices</a>:
$$
\frac{ \partial }{ \partial \mathbf{w} }\left( \mathbf{w}^{T}\mathbf{R}\mathbf{w} \right)= \left( \mathbf{R} + \mathbf{R}^{T} \right) \mathbf{w}
$$</p></blockquote><blockquote><p><a href=../2565>Gradient of Residual Sum of Squares</a>:
$$
f \left( \mathbf{s} \right) := \left( \mathbf{y} - X \mathbf{s} \right)^{T} R \left( \mathbf{y} - X \mathbf{s} \right)
$$
For a vector $\mathbf{y} \in \mathbb{R}^{n}$ and matrices $X \in \mathbb{R}^{n \times p}$, $R \in \mathbb{R}^{n \times n}$ that are not dependent on $\mathbf{s}$, the following holds true.
$$
{{ \partial f \left( \mathbf{s} \right) } \over { \partial \mathbf{s} }} = - X^{T} \left( R + R^{T} \right) \left( \mathbf{y} - X \mathbf{s} \right)
$$</p></blockquote><p>Applying the above formulas when $R = I$ gives
$$
\begin{align*}
{{ \partial } \over { \partial \beta }} L \left( \beta \right) =& {{ \partial } \over { \partial \beta }} {{ 1 } \over { 2 }} \left\| Y - X \beta \right\|_{2}^{2} + {{ \partial } \over { \partial \beta }} \lambda \left\| \beta \right\|
\\ =& {{ \partial } \over { \partial \beta }} {{ 1 } \over { 2 }} \left( Y - X \beta \right)^{T} \left( Y - X \beta \right) + \lambda {{ \partial } \over { \partial \beta }} \left\| \beta \right\|
\\ =& - {{ 1 } \over { 2 }} X^{T} \left( I + I^{T} \right) \left( Y - X \beta \right) + \lambda {{ \partial } \over { \partial \beta }} \left\| \beta \right\|
\\ =& - X^{T} \left( Y - X \beta \right) + \lambda {{ \partial } \over { \partial \beta }} \left\| \beta \right\|
\\ =& - X^{T} Y + X^{T} X \beta + \lambda {{ \partial } \over { \partial \beta }} \left\| \beta \right\|
\end{align*}
$$
And, since $\beta = \hat{\beta}$ must satisfy ${{ \partial } \over { \partial \beta }} L = 0$, we obtain the following.
$$
X^{T} X \hat{\beta} = X^{T} Y - \lambda {{ \partial } \over { \partial \beta }} \left\| \beta \right\|
$$
Now, consider $\hat{\beta}_{k} := \left( \beta \right)_{k}$ for $k = 0, 1, \cdots, p$. If we denote the $i$-th row of matrix $A$ as $\left( A \right)_{i \cdot}$, we get the following equation.
$$
\begin{align*}
& X^{T} X \hat{\beta} = X^{T} Y - \lambda {{ \partial } \over { \partial \beta }} \left\| \beta \right\|
\\ \implies & \left( X^{T} X \right)_{i \cdot} \hat{\beta} = \left( X^{T} Y \right)_{i} - \lambda {{ \partial } \over { \partial \hat{\beta}_{i} }} \sum_{j=0}^{p} \left| \beta_{j} \right|
\\ \implies & \sum_{j=0}^{p} \left( X^{T} X \right)_{i j} \hat{\beta}_{j} = \left( X^{T} Y \right)_{i} - \lambda {{ \partial } \over { \partial \hat{\beta}_{i} }} \left| \hat{\beta}_{i} \right|
\\ \implies & \hat{\beta}_{i} = {{ 1 } \over { \left( X^{T} X \right)_{ii} }} \left[ \left( X^{T} Y \right)_{i} - \lambda {{ \partial } \over { \partial \hat{\beta}_{i} }} \left| \hat{\beta}_{i} \right| - \sum_{j \ne i} \left( X^{T} X \right)_{i j} \hat{\beta}_{j} \right]
\end{align*}
$$
Since $\hat{\beta}_{i}$ depends on other $\hat{\beta}_{j}$s, we can&rsquo;t call this solution a closed form, and we can ignore $\hat{\beta}_{j}$ when $\left( X^{T} X \right)_{i j} = 0$. Adding the assumption that the columns of $X$ are orthogonal implies that $X^{T} X$ is a <a href=../1958>diagonal matrix</a>.</p><p>$\hat{\beta}_{k}$ can be greater than, less than, or equal to $0$. If $\hat{\beta}_{k} > 0$, then
$$
\begin{align*}
& \hat{\beta}_{k} > 0
\\ \implies & \hat{\beta}_{k} = {{ 1 } \over { \left( X^{T} X \right)_{kk} }} \left[ \left( X^{T} Y \right)_{k} - \lambda {{ \partial } \over { \partial \hat{\beta}_{k} }} \left| \hat{\beta}_{k} \right| \right] > 0
\\ \implies & \hat{\beta}_{k} = {{ 1 } \over { \left( X^{T} X \right)_{kk} }} \left[ \left( X^{T} Y \right)_{k} - \lambda \right] > 0
\end{align*}
$$
implies not only that $\hat{\beta}_{k} > 0$ but also that $\left( X^{T} Y \right)_{k} > \lambda$. Similarly, if $\hat{\beta}_{k} &lt; 0$, then
$$
\begin{align*}
& \hat{\beta}_{k} &lt; 0
\\ \implies & \hat{\beta}_{k} = {{ 1 } \over { \left( X^{T} X \right)_{kk} }} \left[ \left( X^{T} Y \right)_{k} - \lambda (-1) \right] > 0
\\ \implies & \hat{\beta}_{k} = {{ 1 } \over { \left( X^{T} X \right)_{kk} }} \left[ \left( X^{T} Y \right)_{k} + \lambda \right] &lt; 0
\end{align*}
$$
implies that $\left( X^{T} Y \right)_{k} &lt; - \lambda$. Otherwise, $\hat{\beta}_{k} = 0$, and this can be summarized with soft thresholding as follows.
$$
\begin{align*}
\hat{\beta}_{k} =& {{ 1 } \over { \left( X^{T} X \right)_{kk} }} \begin{cases}
\left( X^{T} Y \right)_{k} + \lambda & , \text{if } \left( X^{T} Y \right)_{k} &lt; - \lambda
\\ 0 & , \text{if } \left( X^{T} Y \right)_{k} \in [-\lambda, \lambda]
\\ \left( X^{T} Y \right)_{k} - \lambda & , \text{if } \left( X^{T} Y \right)_{k} > \lambda
\end{cases}
\\ = & {{ 1 } \over { \left( X^{T} X \right)_{kk} }} \eta_{\lambda} \left( X^{T} Y \right)_{k}
\end{align*}
$$</p><p style=text-align:right;margin:0;margin-top:-2em>‚ñ†</p><h3 id=algorithm>Algorithm</h3><p>$$
\hat{\beta}_{i} = {{ 1 } \over { \left( X^{T} X \right)_{ii} }} \left[ \left( X^{T} Y \right)_{i} - \lambda {{ \partial } \over { \partial \hat{\beta}_{i} }} \left| \hat{\beta}_{i} \right| - \sum_{j \ne i} \left( X^{T} X \right)_{i j} \hat{\beta}_{j} \right]
$$
As already seen in the derivation process, just having implicit equations doesn&rsquo;t mean we can&rsquo;t find $\hat{\beta}_{j}$, and it&rsquo;s stated that an approximate solution can be found using an iterative algorithm like <a href=../987>gradient descent</a>.<sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup> With BPDN, unlike typical optimization problems, we at least have equations to verify our solution, making the situation somewhat favorable. On the other hand, even if gradient descent is used eventually, if the columns of $X$ are reasonably orthogonal, the optimal solution obtained from the above formula can be used as a starting point. It&rsquo;s difficult to attribute issues with variable independence to a flaw in LASSO.</p><h2 id=see-also>See Also</h2><ul><li><a href=../2563>Sparse Regression</a><ul><li><a href=../2567>Ridge Regression</a></li><li><a href=../2571>LASSO Regression</a></li></ul></li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>James. (2013). An Introduction to Statistical Learning with Applications in R: p228.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://en.wikipedia.org/wiki/Ridge_regression>https://en.wikipedia.org/wiki/Ridge_regression</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href=https://en.wikipedia.org/wiki/Lasso_(statistics)>https://en.wikipedia.org/wiki/Lasso_(statistics)</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>James. (2013). An Introduction to Statistical Learning with Applications in R: p222.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>Muneyuki Kaneshiro, Yusuke Nomura. (2018). Blue Rock: Volume 1&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p><a href=https://stats.stackexchange.com/q/174003/172321>https://stats.stackexchange.com/q/174003/172321</a>&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><p><a href=https://stats.stackexchange.com/a/246169/172321>https://stats.stackexchange.com/a/246169/172321</a>&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8><p><a href=https://machinelearningcompass.com/machine_learning_models/lasso_regression/>https://machinelearningcompass.com/machine_learning_models/lasso_regression/</a>&#160;<a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div><aside style=text-align:right>2024-05-20&emsp;
Î•òÎåÄÏãù&emsp;
<a href=../1725>üé≤ 2571</a></aside><script>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="What is LASSO Regression?",c="https://freshrimpsushi.github.io/en/posts/2571/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script></div><aside><h2>Comment</h2><div class=area-reply><div class=list-reply></div></div><div class=write-box><div class="write-author-info box-account"><input type=hidden name=cmt_idx>
<input class=ai-author type=text placeholder=Name>
<input class=ai-password type=password maxlength=20 placeholder=Password></div><div class=write-content><textarea class=ai-content value placeholder='Feel free to ask in english' style=ime-mode:active></textarea></div><button class=write-button onclick=write_comment() aria-label=send><i class='fa-solid fa-paper-plane'></i></button><aside class=tex>$\TeX$ is also applied to comments.</aside></div></aside><script>let commentRows=[];const listReply=document.querySelector(".list-reply");document.addEventListener("DOMContentLoaded",()=>{get_all_comment()});function get_all_comment(){fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=getAllComment";return postFetch(t,{board_idx:"2571",user_ip:e})}).then(e=>e.json()).then(e=>{e.ok&&(commentRows=e.rows,render_comment(commentRows))}).catch(e=>console.error(e))}function render_comment(e){const n=["Î•òÎåÄÏãù","Ï†ÑÍ∏∞ÌòÑ","„Öá„Öá","ÏßàÎ¨∏"],s=["Î•òÎåÄÏãù","Ï†ÑÍ∏∞ÌòÑ"];render_blank();let t="";e.map(e=>{t+=`<div id="comment${e.cmt_idx}" class="parents">`,t+=`<div class="content-info">`;let o="";e.cmt_cnt>125?o="ü•á":e.cmt_cnt>25?o="ü•à":e.cmt_cnt>5&&(o="ü•â"),n.includes(e.author)&&(o="");let i="";e.ip_address==null?i="(-)":(ipParts=e.ip_address.split("."),i=`(${ipParts[0]}.${ipParts[1]})`),s.includes(e.author)&&(i=""),t+=`<div class="list-author">${o} ${e.author} ${i}</div>`,t+=`<sup class="list-date">${e.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,e.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> Waiting for approvement</div>`);let a=e.content;a=a.replace(/\n/g,"<br />"),t+=`<div class="content-text">${a} <span class="re-comment-button" onclick="re_comment('${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`,e.child.map(o=>{let c="child";e.ip_address&&o.ip_address===e.ip_address&&(c="parentself"),t+=`<div id="comment${o.cmt_idx}" class="${c}">`,t+=`<div class="content-info">`;let i="";o.cmt_cnt>5?i="ü•â":o.cmt_cnt>25?i="ü•à":o.cmt_cnt>125&&(i="ü•á"),n.includes(o.author)&&(i="");let a="";o.ip_address==null?a="(-)":a=`(${o.ip_address})`,s.includes(o.author)&&(a=""),t+=`<div class="list-author">${i} ${o.author} ${a}</div>`,t+=`<sup class="list-date">${o.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,o.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> Waiting for approvement</div>`);let r=o.content;r=r.replace(/\n/g,"<br />"),t+=`<div class="content-text">${r} <span class="re-comment-button" onclick="re_comment('${o.cmt_idx}', '${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`})}),listReply.innerHTML=t,renderKaTex(listReply),location.href.indexOf("#")!=-1&&(location.href=location.href.substr(location.href.indexOf("#")))}function render_blank(){listReply.innerHTML=""}function write_comment(){const e=document.querySelector(".ai-author"),t=document.querySelector(".ai-password"),n=document.querySelector(".ai-content"),s=e.value,o=t.value,i=n.value;if(s===""||o===""||i===""){alert("ÎπàÏπ∏ÏùÑ Ï±ÑÏõåÏ£ºÏÑ∏Ïöî");return}const a="2571",r="",c="What is LASSO Regression?";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeComment";return postFetch(t,{board_idx:a,board_slug:r,board_title:c,author:s.replace(/\+/g,"%2B"),password:o,content:i.replace(/\+/g,"%2B"),user_ip:e})}).then(e=>e.json()).then(s=>{s.ok?(commentRows.push(s.row),render_comment(commentRows),e.value="",t.value="",n.value=""):s.status===606?(Swal.fire(`Warning!
ÏßÄÏÜçÏ†ÅÏù∏ ÎèÑÎ∞∞ ÏãúÎèÑÏãú
IPÍ∞Ä Ï∞®Îã®Îê† Ïàò ÏûàÏäµÎãàÎã§.`),e.value="",t.value="",n.value=""):s.status===607&&(alert(`ÏßÄÎÇòÏπú ÎåìÍ∏Ä ÎèÑÎ∞∞Î•º ÌôïÏù∏ÌïòÏó¨
Ï†ëÍ∑ºÏùÑ Ï∞®Îã®Ìï©ÎãàÎã§.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}async function update_comment(e,t){const{value:n}=await Swal.fire({title:"ÎåìÍ∏Ä ÏàòÏ†ï",input:"password",inputPlaceholder:"Í∏Ä ÏûëÏÑ± Ïãú ÏûÖÎ†•ÌñàÎçò Ìå®Ïä§ÏõåÎìúÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(s=>{if(s.ok){const s=document.querySelector(`#comment${e}`),o="https://freshrimpsushi.com/blog/ajax/comment.php?action=getComment";postFetch(o,{cmt_idx:e}).then(e=>e.json()).then(o=>{if(o.ok){const a=o.row,r=a.author,c=a.content;let i="";i+=`<div class="update-author-info">`,i+=`<input class="update-author" type="text" value="${r}" placeholder="Ïù¥Î¶Ñ" />`,i+=`<input class="update-password" type="password" value="${n}" placeholder="ÎπÑÎ∞ÄÎ≤àÌò∏" disabled />`,i+="</div>",i+=`<textarea class="update-content" value="" style="IME-MODE:active;">${c}</textarea>`,i+=`<input class="update_comment-button" type="submit" value="ÏàòÏ†ï" onclick="update_comment_click(${e}, '${t}')" />`,i+=`<input class="update_comment-button" type="submit" value="Ï∑®ÏÜå" onclick="cancel_click(${e})" />`,s.innerHTML=i}}).catch(e=>console.error(e))}else Swal.fire("Ìå®Ïä§ÏõåÎìú ÏùºÏπò Ïò§Î•ò")}).catch(e=>console.error(e))}}async function delete_comment(e,t){const{value:n}=await Swal.fire({title:"ÎåìÍ∏Ä ÏÇ≠Ï†ú",text:"ÏÇ≠Ï†úÌïòÎ©¥ ÎêòÎèåÎ¶¥ Ïàò ÏóÜÏäµÎãàÎã§.",input:"password",icon:"warning",showCancelButton:!0,confirmButtonColor:"#3085d6",cancelButtonColor:"#d33",inputPlaceholder:"Í∏Ä ÏûëÏÑ± Ïãú ÏûÖÎ†•ÌñàÎçò Ìå®Ïä§ÏõåÎìúÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(n=>{if(n.ok){const n="https://freshrimpsushi.com/blog/ajax/comment.php?action=deleteComment";postFetch(n,{cmt_idx:e}).then(e=>e.json()).then(n=>{Swal.fire("ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§."),t==="parents"?commentRows=commentRows.filter(t=>t.cmt_idx!==e):t==="child"&&commentRows.map(t=>{t.child=t.child.filter(t=>t.cmt_idx!==e),t.child_cnt=t.child.length}),render_comment(commentRows)}).catch(e=>console.error(e))}else Swal.fire("Ìå®Ïä§ÏõåÎìú ÏùºÏπò Ïò§Î•ò")}).catch(e=>console.error(e))}}function update_comment_click(e,t){const i=document.querySelector(`#comment${e} .update-author`),a=document.querySelector(`#comment${e} .update-password`),r=document.querySelector(`#comment${e} .update-content`),n=i.value,s=a.value,o=r.value;(n===""||s===""||o==="")&&alert("ÎπàÏπ∏ÏùÑ Ï±ÑÏõåÏ£ºÏÑ∏Ïöî");const c="https://freshrimpsushi.com/blog/ajax/comment.php?action=updateComment";postFetch(c,{cmt_idx:e,author:n.replace(/\+/g,"%2B"),password:s,content:o.replace(/\+/g,"%2B")}).then(e=>e.json()).then(n=>{n.ok&&(Swal.fire("ÏàòÏ†ïÎêòÏóàÏäµÎãàÎã§."),t==="parents"?commentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}):t==="child"&&commentRows.map(t=>{t.cmt_idx==n.parent_cmt_idx&&t.child.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)})}),render_comment(commentRows),recentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}),render_recent_comment(recentRows))}).catch(e=>console.error(e))}function cancel_click(){render_comment(commentRows)}function re_comment(e,t){const s=document.querySelector(`#comment${e} .re-comment`);let n="";n+='<div class="re-comment-box">',n+='<div class="re-comment-author-info">',n+='<input class="re-comment-author" type="text" value="" placeholder="Ïù¥Î¶Ñ" />',n+='<input class="re-comment-password" type="password" value="" placeholder="ÎπÑÎ∞ÄÎ≤àÌò∏" />',n+="</div>",n+='<textarea class="re-comment-content" placeholder="ÎÇ¥Ïö©" value="" style="IME-MODE:active;"></textarea>',t===void 0?n+=`<button class="write-button" onclick="re_comment_click(${e})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`:n+=`<button class="write-button" onclick="re_comment_click(${e}, ${t})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`,n+=`<button class="write-button" onclick="cancel_click(${e})" value="close"><i class='fa-solid fa-solid fa-ban'></i></button>`,n+="</div>",s.innerHTML=n}function re_comment_click(e,t){const n=document.querySelector(`#comment${e} .re-comment-author`),s=document.querySelector(`#comment${e} .re-comment-password`),o=document.querySelector(`#comment${e} .re-comment-content`),i=n.value,a=s.value,r=o.value;if(i===""||a===""||r===""){alert("ÎπàÏπ∏ÏùÑ Ï±ÑÏõåÏ£ºÏÑ∏Ïöî");return}const c="2571",l="",d="What is LASSO Regression?";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(n=>{const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeReComment";return postFetch(s,{board_idx:c,board_slug:l,board_title:d,cmt_idx:t===void 0?e:t,author:i.replace(/\+/g,"%2B"),password:a,content:r.replace(/\+/g,"%2B"),user_ip:n})}).then(e=>e.json()).then(i=>{i.ok?(commentRows.map(n=>{t===void 0?n.cmt_idx==e&&n.child.push(i.row):n.cmt_idx==t&&n.child.push(i.row)}),render_comment(commentRows)):i.status==606?(Swal.fire(`Warning!
ÏßÄÏÜçÏ†ÅÏù∏ ÎèÑÎ∞∞ ÏãúÎèÑÏãú
IPÍ∞Ä Ï∞®Îã®Îê† Ïàò ÏûàÏäµÎãàÎã§.`),n.value="",s.value="",o.value=""):i.status===607&&(alert(`ÏßÄÎÇòÏπú ÎåìÍ∏Ä ÎèÑÎ∞∞Î•º ÌôïÏù∏ÌïòÏó¨
Ï†ëÍ∑ºÏùÑ Ï∞®Îã®Ìï©ÎãàÎã§.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}</script></div><aside class=sidebar><aside><style>.reddot a:link{color:#67d10f;text-shadow:0 0 10px #d3d3d3;font-weight:700}.reddot a:visited{color:#f5f5f5}</style><p class=reddot style=text-align:center;margin:0><a href=https://freshrimpsushi.github.io/en/posts/2707/>Summer Special Omakase<br>„ÄåImaginary Numbers„Äç</a></p></aside><br><div class=category></div><div style=display:flex>Click ‚óè to highlight only you interested.<div class=resetmute><button class="sb-btn btnReset" style=border-radius:5px;border:0>reset</button>
<button class="sb-btn btnMute" style=border-radius:5px;border:0>mute</button></div></div><script defer>const color={green:"#33cc33",yellow:"#ffcc00",red:"#ff3333",black:"#000000"},categoryRows=[[{idx:1,name:"Ìï®Ïàò",color:color.green,show:"Functions",size:"146"},{idx:2,name:"Î≥¥Ï°∞Ï†ïÎ¶¨",color:color.green,show:"Lemmas",size:"55"},{idx:3,name:"ÎØ∏Î∂ÑÏ†ÅÎ∂ÑÌïô",color:color.green,show:"Calculus",size:"45"},{idx:4,name:"ÌñâÎ†¨ÎåÄÏàò",color:color.green,show:"Matrix Algebra",size:"117"}],[{idx:1,name:"Ï†ïÏàòÎ°†",color:color.green,show:"Number Theory",size:"90"},{idx:2,name:"ÏßëÌï©Î°†",color:color.green,show:"Set Theory",size:"49"},{idx:3,name:"Í∑∏ÎûòÌîÑÏù¥Î°†",color:color.green,show:"Graph Theory",size:"65"},{idx:4,name:"ÏÑ†ÌòïÎåÄÏàò",color:color.green,show:"Linear Algebra",size:"97"},{idx:5,name:"Ìï¥ÏÑùÍ∞úÎ°†",color:color.green,show:"Analysis",size:"84"},{idx:6,name:"Ï∂îÏÉÅÎåÄÏàò",color:color.green,show:"Abstract Algebra",size:"105"},{idx:7,name:"ÏúÑÏÉÅÏàòÌïô",color:color.green,show:"Topology",size:"64"},{idx:8,name:"Í∏∞ÌïòÌïô",color:color.green,show:"Geometry",size:"167"}],[{idx:1,name:"Îã§Î≥ÄÏàòÎ≤°ÌÑ∞Ìï¥ÏÑù",color:color.green,show:"Vector Analysis",size:"37"},{idx:2,name:"Î≥µÏÜåÌï¥ÏÑù",color:color.green,show:"Complex Anaylsis",size:"71"},{idx:3,name:"Ï∏°ÎèÑÎ°†",color:color.green,show:"Measure Theory",size:"53"},{idx:4,name:"Ìë∏Î¶¨ÏóêÌï¥ÏÑù",color:color.green,show:"Fourier Analysis",size:"54"},{idx:5,name:"Ï¥àÌï®ÏàòÎ°†",color:color.green,show:"Distribution Theory",size:"22"},{idx:6,name:"Îã®Ï∏µÏ¥¨ÏòÅ",color:color.green,show:"Tomography",size:"20"}],[{idx:1,name:"Í±∞Î¶¨Í≥µÍ∞Ñ",color:color.green,show:"Metric Space",size:"38"},{idx:2,name:"Î∞îÎÇòÌùêÍ≥µÍ∞Ñ",color:color.green,show:"Banach Space",size:"38"},{idx:3,name:"ÌûêÎ≤†Î•¥Ìä∏Í≥µÍ∞Ñ",color:color.green,show:"Hilbert Space",size:"31"},{idx:4,name:"Î•¥Î≤°Í≥µÍ∞Ñ",color:color.green,show:"Lebesgue Space",size:"33"}],[{idx:1,name:"ÏÉÅÎØ∏Î∂ÑÎ∞©Ï†ïÏãù",color:color.green,show:"ODE",size:"58"},{idx:2,name:"Ìé∏ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù",color:color.green,show:"PDE",size:"60"},{idx:3,name:"ÌôïÎ•†ÎØ∏Î∂ÑÎ∞©Ï†ïÏãù",color:color.green,show:"SDE",size:"26"}],[{idx:1,name:"Ï§ÑÎ¶¨ÏïÑ",color:color.green,show:"Julia",size:"229"},{idx:2,name:"ÏïåÍ≥†Î¶¨Ï¶ò",color:color.green,show:"Algorithm",size:"28"},{idx:3,name:"ÏàòÏπòÌï¥ÏÑù",color:color.green,show:"Numerical Analysis",size:"63"},{idx:4,name:"ÏµúÏ†ÅÌôîÏù¥Î°†",color:color.green,show:"Optimization Theory",size:"37"},{idx:5,name:"Î®∏Ïã†Îü¨Îãù",color:color.green,show:"Machine Learning",size:"114"},{idx:6,name:"ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç",color:color.yellow,show:"Programming",size:"113"},{idx:7,name:"ÏÑ∏Ïù¥Î≤ÑÎ©îÌä∏Î¶≠Ïä§",color:color.green,show:"Sabermetrics",size:"229",size:"13"}],[{idx:1,name:"Î¨ºÎ¶¨Ìïô",color:color.green,show:"Physics",size:"27"},{idx:2,name:"ÏàòÎ¶¨Î¨ºÎ¶¨",color:color.green,show:"Mathematical Physics",size:"77"},{idx:3,name:"Í≥†Ï†ÑÏó≠Ìïô",color:color.green,show:"Classical Mechanics",size:"48"},{idx:4,name:"Ï†ÑÏûêÍ∏∞Ìïô",color:color.green,show:"Electrodynamics",size:"51"},{idx:5,name:"ÏñëÏûêÏó≠Ìïô",color:color.green,show:"Quantum Mechanics",size:"57"},{idx:6,name:"Ïó¥Î¨ºÎ¶¨Ìïô",color:color.green,show:"Thermal Physics",size:"29"}],[{idx:1,name:"R",color:color.green,show:"R",size:"54"},{idx:2,name:"Îç∞Ïù¥ÌÑ∞ÌôïÎ≥¥",color:color.green,show:"Data Sets",size:"29"},{idx:3,name:"Îç∞Ïù¥ÌÑ∞Í≥ºÌïô",color:color.green,show:"Data Science",size:"41"},{idx:4,name:"ÌÜµÍ≥ÑÏ†ÅÍ≤ÄÏ†ï",color:color.green,show:"Statistical Test",size:"33"},{idx:5,name:"ÌÜµÍ≥ÑÏ†ÅÎ∂ÑÏÑù",color:color.green,show:"Statistical Analysis",size:"76"},{idx:6,name:"ÏàòÎ¶¨ÌÜµÍ≥ÑÌïô",color:color.green,show:"Mathematical Statistics",size:"123"},{idx:7,name:"ÌôïÎ•†Î∂ÑÌè¨Î°†",color:color.green,show:"Probability Distribution",size:"84"},{idx:8,name:"ÌôïÎ•†Î°†",color:color.green,show:"Probability Theory",size:"80"},{idx:9,name:"ÏúÑÏÉÅÎç∞Ïù¥ÌÑ∞Î∂ÑÏÑù",color:color.green,show:"TDA",size:"40"}],[{idx:1,name:"ÎÖºÎ¨∏ÏûëÏÑ±",color:color.red,show:"Writing",size:"63"},{idx:2,name:"ÏÉùÏÉàÏö∞Ï¥àÎ∞•ÏßÄ",color:color.black,show:"JOF",size:"7"}]];document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("blindList"));(e==""||e==null||e==null||e==0||e==NaN)&&localStorage.setItem("blindList",null),render_category(categoryRows),blind_category(e);const t=document.querySelector(".btnReset");t.addEventListener("click",()=>{let e=new Array;localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)});const n=document.querySelector(".btnMute");n.addEventListener("click",()=>{let e=new Array;for(let t=0;t<categoryRows.length;t++)categoryRows[t].map(n=>{const s={mainIdx:t,subIdx:n.idx};e.push(s)});localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)})});function render_category(e){const n=document.querySelector(".category");let t="";for(let n=0;n<e.length;n++)e[n].map(e=>{t+=`<span id="cate${n}-${e.idx}" class="cate etewsert">`,t+=`<span onclick="check_blind(${n}, ${e.idx});" style="cursor: pointer; color: ${e.color}">‚óè</span>`,t+=`<a href="https://freshrimpsushi.github.io/en/categories/${e.name.toLowerCase()}/">`,t+=` ${e.show} (${e.size})</a>`,t+="</span>",screen.width>954?t+="<br>":t+=" "}),t+="<hr>";n.innerHTML=t}function check_blind(e,t){const o=document.querySelector(`#cate${e}-${t}`);let n=new Array;const i={mainIdx:e,subIdx:t};let s=JSON.parse(localStorage.getItem("blindList"));if(s==""||s==null||s==null||s==0||s==NaN)n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind";else{n=s;let a=null;for(let s=0;s<n.length;s++)if(n[s].mainIdx==e&&n[s].subIdx==t){a=n.filter(n=>n.mainIdx!=e||n.subIdx!=t);break}a===null?(n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind"):(localStorage.setItem("blindList",JSON.stringify(a)),o.className="cate")}}function blind_category(e){const t=document.querySelectorAll(".cate");t.forEach(e=>{e.className="cate"}),e!==null&&e.map(e=>{const t=document.querySelector(`#cate${e.mainIdx}-${e.subIdx}`);t.className+=" blind"})}</script><br><br><b>Viewed posts</b><div class=lately-viewed-list style=padding-left:4px></div><script defer>document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("latelyViewPostList")),n=document.querySelector(".lately-viewed-list");let t="";if(e==""||e==null||e==null||e==0||e==NaN)localStorage.setItem("latelyViewPostList",null),t+='<div class="lv-list">',t+=" ¬∑ Ïó¥ÎûåÌïú Ìè¨Ïä§Ìä∏Í∞Ä ÏóÜÏäµÎãàÎã§.",t+="</div>",n.innerHTML=t;else{for(let n=e.length-1;n>=0;n--)t+='<div class="lv-list">',t+=`<a href="${e[n].link}"> ¬∑ ${e[n].title}</a>`,t+="</div>";n.innerHTML=t}})</script><script defer>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="What is LASSO Regression?",c="https://freshrimpsushi.github.io/en/posts/2571/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script><br><b>Recent comment</b><div class=current-reply></div><script defer>const url="https://freshrimpsushi.com/blog/ajax/recent_comment.php?action=getCurrentComment";let recentRows=[];fetch(url).then(e=>e.json()).then(e=>{e.ok&&(recentRows=e.rows,render_recent_comment(recentRows))}).catch(e=>console.error(e));function render_recent_comment(e){const n=document.querySelector(".current-reply");let t="";e.map(e=>{let n="https://freshrimpsushi.github.io/en/";e.board_idx>-1?n+=`posts/${e.board_idx}#comment${e.cmt_idx}`:e.board_idx==-1?n+=`#comment${e.cmt_idx}`:n+=`categories/${e.board_title}#comment${e.cmt_idx}`,t+='<div class="current-reply-list">',t+=`<a href="${n}">`,t+=`<b> - ${e.author}</b>: `,t+=`${e.content}`,t+=`</a>`,t+=`</div>`}),n.innerHTML=t,renderKaTex(n)}</script><br></aside></div><footer><aside><div><p id=mirror-link style=text-align:center><a style=cursor:text href=http://localhost:1313//en/posts/2571/>¬© FreshrimpRestaurant / Powered by Î•òÎåÄÏãù, Ï†ÑÍ∏∞ÌòÑ</a><br>Contact:
<img src=https://freshrimpsushi.github.io/en/logo/gmail.png width=12px alt=mail> freshrimpsushi@gmail.com
<a href=https://freshrimpsushi.github.io/en/index.xml><img src=https://freshrimpsushi.github.io/en/logo/RSS.png width=12px alt=RSS> RSS</a></p></div><script type=text/javascript>var goIndex=function(){var e=document.getElementsByName("idx")[0].value,t="https://freshrimpsushi.github.io/en/posts/"+e;location.replace(t)};document.addEventListener("keydown",function(e){const n=document.getElementById("navigator");if(e.altKey&&e.ctrlKey&&e.key==="l"){e.preventDefault();var t=document.querySelector("#mirror-link a");t?t.click():console.log("Í±∞Ïö∏ ÎßÅÌÅ¨Î•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§.")}})</script></aside></footer></body><script async src="https://www.googletagmanager.com/gtag/js?id=G-NLV8Y9PRK1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NLV8Y9PRK1")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4751085325232621" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/sweetalert2@11></script><script src=https://freshrimpsushi.github.io/en/js/fontawsome.min.js></script><script src=https://freshrimpsushi.github.io/en/js/common.js></script><script>document.addEventListener("DOMContentLoaded",()=>{fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/ip_checker.php";return postFetch(t,{user_ip:e})}).then(e=>e.json()).then(e=>{e.ok||(alert(`Ï∞®Îã®Îêú IPÏûÖÎãàÎã§.
Contact:
freshrimpsushi@gmail.com`),window.location.href="https://google.com")}).catch(e=>console.error(e))})</script></html>