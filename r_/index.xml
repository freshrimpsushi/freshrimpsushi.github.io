<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R_s on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/r_/</link>
    <description>Recent content in R_s on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Sun, 17 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/r_/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>네트워크 이론에서의 허브 노드</title>
      <link>https://freshrimpsushi.github.io/posts/hub-in-network-theory/</link>
      <pubDate>Sun, 17 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hub-in-network-theory/</guid>
      <description>정의 1 네트워크에서 다른 많은 노드와 연결된 노드를 허브Hub라 한다. 설명 네트워크 이론에서의 구심성이란 그 중에서 &amp;lsquo;중요한 노드가 무엇인가&amp;rsquo;에 대한 대답이다. 이러한 목적에서 차수 $\deg v$ 가 높은 노드 $v$, 즉 다른 노드와 연결이 많이 된 노드가 중요할 것이라는 직관은 상식적이라 할 수 있을 것이다. 위 그림은 바라바시-알버트</description>
    </item>
    
    <item>
      <title>KDX 한국데이터거래소 소개</title>
      <link>https://freshrimpsushi.github.io/posts/itroduction-to-kdx/</link>
      <pubDate>Fri, 15 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/itroduction-to-kdx/</guid>
      <description>소개 일반적인 데이터 허브와 달리 유료로 데이터를 판매하는 기업이다. 유료인만큼 한국 실정에 맞는 데이터의 양과 질로는 최고 수준이며, 무료 데이터도 적지않게 판매되고 있다. 요구사항 돈이 든다. 가령 대구 지역 부동산 매물 시세 데이터는 천만원, 21년 7월 종합 이커머스 상품별 구매 및 관심사 데이터는 50만원이다. 링크 메인 페이지: https://kdx.kr/main</description>
    </item>
    
    <item>
      <title>바라바시-알버트 모델</title>
      <link>https://freshrimpsushi.github.io/posts/barab%C3%A1si-albert-model/</link>
      <pubDate>Wed, 13 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/barab%C3%A1si-albert-model/</guid>
      <description>알고리즘 1 Input 링크 파라메터 $m \in \mathbb{N}$ 과 네트워크 사이즈 $N$ 이 주어져 있다고 하자. Step 1. 초기화 노드가 $m$ 개인 최초의 네트워크를 구성한다. 별 다른 이유가 없다면 그 네트워크는 컴플리트 그래프로 주어진다. Step 2. 노드 추가 현재 노드의 수가 $n$ 개라고 하자. 여기에 새로운 노드를 추가하는데, 이 노드는 기존에 있던 각 $m$ 개의 노드와 링크가 이어진다. 이 때 각각의</description>
    </item>
    
    <item>
      <title>ITS 국가교통정보센터 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-national-transport-imformation-center/</link>
      <pubDate>Mon, 11 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-national-transport-imformation-center/</guid>
      <description>소개 국가교통정보센터는 국내의 교통소통, 공사사고, CCTV, 교통예측, 차량검지기, VMS, 교통안전도우미, 가변속도표지, 취약구간정보 및 전국표준노드링크를 제공한다. 특히 전국표준노드링크는 국내의 모든 도로망을 네트워크로 표현한 최고의 데이터로, 대부분의 데이터 과학자에게 아주 유용하게 쓰일 수 있다. 요구사항 어떤 요구 사항도 없이 무제한적</description>
    </item>
    
    <item>
      <title>청-루 피트니스 모델</title>
      <link>https://freshrimpsushi.github.io/posts/chung-lu-fitness-model/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chung-lu-fitness-model/</guid>
      <description>정의 각 노드 별로 가중치Weight를 주고 그에 따라 링크가 연결되는 확률을 다르게 주는 랜덤 네트워크를 피트니스 모델Fitness Model이라 한다. 알고리즘 Input $n \in \mathbb{N}$ 개의 노드를 가진 널 그래프 $G$ 가 주어져 있다고 하자. 청-루 모델 1 Step 1. $\displaystyle \max w_{k}^{2} &amp;lt; \sum_{k=1}^{n} w_{k}$ 을 만족하게끔 하는 디그리 시퀀스 $\displaystyle \mathbf{w} := \left( w_{1} , \cdots , w_{n} \right)$ 를 만든다. 여기서 각 노드 $k \in V(G)$</description>
    </item>
    
    <item>
      <title>기상자료개방포털 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-data.kma.go.kr/</link>
      <pubDate>Thu, 07 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-data.kma.go.kr/</guid>
      <description>소개 기상자료개방포털은 종관기상관측, 기후, 지진화산 등의 다양한 데이터셋과 오픈 API를 제공하고 있다. 기온, 강수량, 미세먼지, 풍속, 습도, 일조량 등 기상 데이터라면 갖추어야할 모든 것을 갖추었다. 요구사항 생활기상정보와 해구별 예측자료는 비회원도 다운로드 할 수 있고, 비회원의 경우 일별 자료는 하루 최대 31건, 시간별 자료 최대 2</description>
    </item>
    
    <item>
      <title>스케일 프리 네트워크</title>
      <link>https://freshrimpsushi.github.io/posts/scale-free-network/</link>
      <pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scale-free-network/</guid>
      <description>정의 1 차수분포가 파레토 분포인 랜덤 네트워크를 무척도 네트워크Scale-free Network라고 한다. 설명 스케일-프리(SF) 네트워크라는 명명은 파레토 분포가 가지는 무척도성에서 온 말이다. 차수분포로 정의되는 네트워크인만큼 그 분포의 성질을 진하게 물려받은 것이 특징이다. 수식으로 나타내보자면 스케일-프리 네트워크 $G$ 의</description>
    </item>
    
    <item>
      <title>환경 빅데이터 플랫폼 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-envdigdata/</link>
      <pubDate>Sun, 03 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-envdigdata/</guid>
      <description>소개 환경 빅데이터 플랫폼은 환경 데이터 마켓과 시각화, 교육 서비스, 공모전 등을 제공하고 있다. 마켓이라고 하나 무료 데이터도 많고 UI, 데이터 설명도 깔끔해 사용하기 좋다. 환경에 관해서는 독보적으로 깊이 있고 다양한 데이터를 보유하고 있다. 요구사항 로그인이 필요하며 데이터를 받을 때마다 어떤 목적인지 응답해야한다. 어쨌든 데이터 허브가 아닌 마</description>
    </item>
    
    <item>
      <title>Let 뒤에는 무조건 동사원형이 온다</title>
      <link>https://freshrimpsushi.github.io/posts/usage-of-let/</link>
      <pubDate>Mon, 28 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/usage-of-let/</guid>
      <description>문법 주어 S 와 동사 V 에 대해 &amp;ldquo;Let S V ~&amp;rdquo; 절의 V는 동사원형으로 쓰여야한다. 예문 &amp;ldquo;자아! 살육을 시작하자.&amp;rdquo; &amp;ldquo;Let the killing begin.&amp;rdquo; - 복한규, 전 LOL 프로게이머 &amp;ldquo;감염 접촉률이 $b=0.2 (&amp;gt;k)$ 이라고 가정해보자.&amp;rdquo; &amp;ldquo;Let us further assume that the infectious contact rate is $b=0.2 (&amp;gt;k)$.&amp;rdquo; 1 설명 사실 굳이 논문에서 예문을 찾지 않더라도 &amp;ldquo;Let X be Y.&amp;rdquo; 와 같은 문형은 수학</description>
    </item>
    
    <item>
      <title>investing.com 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-investing.com/</link>
      <pubDate>Sat, 26 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-investing.com/</guid>
      <description>소개 인베스팅닷컴은 세계적인 금융정보 사이트로써 코스피, 코스닥 등 종목의 차트 정보를 무료로 간편하게 제공한다. 다만 실시간 데이터라든가 더욱 다양한 데이터가 필요하다면 CYBOS Plus와 같은 증권사 API를 사용하는 것을 고려해봐야한다. 간단한 테스트용 데이터셋 정도만 필요하다면 인베스팅닷컴이 압도적으로 편리하다. 요구사항 로그인 정보를</description>
    </item>
    
    <item>
      <title>a의 확률로 V하다</title>
      <link>https://freshrimpsushi.github.io/posts/it-v-at-the-rate-a/</link>
      <pubDate>Thu, 24 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/it-v-at-the-rate-a/</guid>
      <description>a의 확률로 V하다 문형 동사 V와 확률Rate $a \in [0,1]$ 가 주어져있다고 하자. &amp;ldquo;It V at the rate $a$.&amp;rdquo; $\iff$ &amp;ldquo;$a$의 확률로 V하다.&amp;rdquo; 예문 &amp;ldquo;질병이 확산되는 동안, 감염된 노드는 이웃한 감병가능 노드에 감염률 $\beta$ 로 질병을 전달하고, 회복률 $\mu$ 로 감염가능상태로 돌아간다.&amp;rdquo; &amp;ldquo;During the spreading, each infected node transmits the disease to its susceptible neighbors</description>
    </item>
    
    <item>
      <title>창원시 빅데이터 포털 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-changwon-bigdata-portal/</link>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-changwon-bigdata-portal/</guid>
      <description>소개 창원 빅데이터 포털은 창원시를 중심으로 한 공공데이터 포털로써 9억건 이상의 데이터와 빅데이터 스튜디오, 상권분석 등의 서비스를 제공하고 분석대회 공모전을 여는 등 데이터 과학을 적극적으로 장려하고 있다. 다만 주의해야하는 게, 유선으로 확인해본 결과 사실 이것은 데이터의 셀을 하나하나 카운트 한 것이기 때문에 기대하던 것과는 달리 딱히 빅데이</description>
    </item>
    
    <item>
      <title>커플드 다이내믹 시스템</title>
      <link>https://freshrimpsushi.github.io/posts/coupled-dynamical-system/</link>
      <pubDate>Sun, 20 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coupled-dynamical-system/</guid>
      <description>정의 1 상태공간 $X$ 가 주어져 있다고 하자. $N$ 개의 노드를 가지는 네트워크 $\Gamma$ 의 인접 행렬을 $A$, 노드 $i \in V \left( \Gamma \right)$ 의 상태를 $x_{i} \in X$ 와 같이 나타낼 때, 다음의 미분방정식으로 표현되는 동역학계를 커플드 다이내믹 시스템Coupled Dynamical System이라 한다. $$ x_{i}&amp;rsquo; = f_{i} \left( x_{i} \right) + \sum_{i=1}^{N} A_{ji} c_{ji} \left( x_{j} , x_{i} \right) \qquad i = 1, \cdots, N $$ $f_{i}$ 를 각 노드 $i$ 의 에볼루션Evolut</description>
    </item>
    
    <item>
      <title>CYBOS Plus로 공매도 추이 불러오는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-call-short-selling-using-cybos-plus/</link>
      <pubDate>Fri, 18 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-call-short-selling-using-cybos-plus/</guid>
      <description>코드 CpSysDib.CpSvr7238 는 종목별 공매도 추이를 요청하고 수신한다. 주식회사 씨젠의 공매도 데이터를 불러우는 파이썬 예제로 사용법을 익혀보자. 만약 CYBOS API에 익숙하지 않다면 다음의 가이드를 먼저 참고하자. CYBOS Plus로 종목 주가 불러오는 법 &amp;gt;&amp;gt;&amp;gt; import win32com.client &amp;gt;&amp;gt;&amp;gt; instCpStockCode = win32com.client.Dispatch(&amp;#34;CpUtil.CpStockCode&amp;#34;) &amp;gt;&amp;gt;&amp;gt; item = instCpStockCode.NameToCode(&amp;#34;씨젠&amp;#34;) &amp;gt;&amp;gt;&amp;gt; short</description>
    </item>
    
    <item>
      <title>CYBOS Plus로 기관, 외국인 매매량 불러오는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-call-firm-and-foreigner-using-cybos-plus/</link>
      <pubDate>Mon, 14 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-call-firm-and-foreigner-using-cybos-plus/</guid>
      <description>가이드1 CpSysDib.CpSvr7254는 투자주체별현황을 일별/기간별,순매수/매매비중, 수량/금액을 일자별로 확인한다. 주식회사 씨젠의 투자주체별 데이터를 불러우는 파이썬 예제로 사용법을 익혀보자. 만약 CYBOS API에 익숙하지 않다면 다음의 가이드를 먼저 참고하자. CYBOS Plus로 종목 주가 불러오는 법 하이라이트 &amp;gt;&amp;gt;&amp;gt; data7254 종가 등</description>
    </item>
    
    <item>
      <title>All 뒤에는 가산명사 복수형이나 비가산명사 단수형이 온다</title>
      <link>https://freshrimpsushi.github.io/posts/usage-of-all/</link>
      <pubDate>Sat, 12 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/usage-of-all/</guid>
      <description>문법 All 뒤에 올 명사를 N이라 하자. All 뒤에 오는 N은 가산명사 복수형이나 비가산명사 단수형이어야하고, &amp;ldquo;All N&amp;rdquo; 의 수는 N의 수와 일치해야한다. 예문 복수형 &amp;ldquo;모든 빨간 타일들은 키메라 상태가 양쪽 레이어에서 일어났음을 나타낸다.&amp;rdquo; &amp;ldquo;All red tiles indicate chimera states that emerge in both layers.&amp;rdquo; 1 tile는 가산명사이므로 All 뒤에 복수형 tiles로 들어왔</description>
    </item>
    
    <item>
      <title>CYBOS Plus로 종목 주가 불러오는 법 CpSysDib.StockChart</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-call-stock-price-using-cybos-plus/</link>
      <pubDate>Thu, 10 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-call-stock-price-using-cybos-plus/</guid>
      <description>가이드 1 CpSysDib.StockChart는 주식, 업종, ELW의 차트데이터를 수신한다. API를 사용하는 것에 익숙하지 않다면 이 체계를 이해하기가 대단히 어려울 수 있다. 주식회사 씨젠의 주가를 불러오는 파이썬 예제를 실행해보고 그 작동방식을 파악해보자. SetInputValue(): 어떤 데이터를 원하는지를 구체적으로 지정한다. BlockRequest(): 지정된 데이터 수신을</description>
    </item>
    
    <item>
      <title>Every와 Each 뒤에는 반드시 단수명사가 온다</title>
      <link>https://freshrimpsushi.github.io/posts/usage-of-every-and-each/</link>
      <pubDate>Tue, 08 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/usage-of-every-and-each/</guid>
      <description>문법 E가 Every 혹은 Each이라 하고, E 뒤에 올 명사를 N이라 하자. E 뒤에 오는 N 은 단수여야하고, &amp;ldquo;E N&amp;rdquo; 은 통째로 단수 취급된다. 예문 Every &amp;ldquo;결론적으로, 유향 그래프에서 모든 커플링 함수는 첫번째 인자 $x_i$ 와 두번째 인자 $x_j$ 로 한 번, 반대로 한 번 해서 두 번씩 호출된다.&amp;rdquo; &amp;ldquo;In consequence, every coupling function in an undirected graph has to be called twice, once with $x_i$ as its first and $x_j$ as its</description>
    </item>
    
    <item>
      <title>CYBOS Plus로 종목 코드 불러오는 법 CpUtil.CpStockCode</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-call-code-using-cybos-plus/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-call-code-using-cybos-plus/</guid>
      <description>가이드 1 CpUtil.CpStockCode는 종목 코드에 관련된 메소드를 제공한다. NameToCode(): 종목 이름을 문자열로 받아 코드를 문자열로 리턴한다. CodeToName(): 코드를 문자열로 받아 종목 이름을 문자열로 리턴한다. 씨젠(096530)을 예로써 다음의 파이썬 코드를 실행해보자. &amp;gt;&amp;gt;&amp;gt; import win32com.client &amp;gt;&amp;gt;&amp;gt; instCpStockCode = win32com.client.Dispatch(&amp;#34;CpUtil.CpStockCode&amp;#34;) &amp;gt;&amp;gt;&amp;gt; instCpStockCode.NameToCod</description>
    </item>
    
    <item>
      <title>프랙탈 브라운 운동</title>
      <link>https://freshrimpsushi.github.io/posts/fractional-brownian-motion/</link>
      <pubDate>Fri, 04 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fractional-brownian-motion/</guid>
      <description>정의 $E \left( X_{t} \right) = 0$ 인 $X_{t}$ 가 가우시안 프로세스고 $H \in (0, 1)$ 이라 하자. 프랙셔널 브라우니안 모션Fractional Brownian motion은 다음과 같이 두가지 방법으로 정의될 수 있다. 공분산을 통한 정의 1 $X_{t}$ 의 $t, s$ 시점에서의 공분산이 다음과 같으면 프랙탈 브라운 운동이라 한다. $$ \text{Cov} \left( X_{t}, X_{s} \right) = {{ 1 } \over { 2 }} \left( t^{2H} + s^{2H} - \left| t-s \right|^{2H} \right) $$ 조건을 통한 정의 2</description>
    </item>
    
    <item>
      <title>CYBOS Plus 설치 튜토리얼</title>
      <link>https://freshrimpsushi.github.io/posts/cybos-plus-install-tutorial/</link>
      <pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cybos-plus-install-tutorial/</guid>
      <description>환경 OS: Windows IDE: VS code 가이드 윈도에서 CYBOS Plus를 설치하고 파이썬으로 연결상태를 확인하는 튜토리얼이다. 파이썬의 객체지향성이나 IDE를 다루는 부분에서는 어느정도 익숙한 사용자라고 가정하겠다. Step 1. CYBOS Plus 설치 대신증권 다운로드 센터에서 CYBOS Plus를 다운로드 받자. 사실 따로 받을 수 있는 건 아니고, CYBOS 프로그램 안에 Plus가 내장된 형태라 C</description>
    </item>
    
    <item>
      <title>TeX에서 큰 괄호를 한 쪽에만 치는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-handle-the-size-of-parentheses/</link>
      <pubDate>Mon, 28 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-handle-the-size-of-parentheses/</guid>
      <description>코드 $$ \left. \int {{ 1 } \over { g (u) }} du \right|\_{u = X\_{t}} $$ $$ \left. \int {{ 1 } \over { g (u) }} du \right|_{u = X_{t}} $$ 큰 괄호에서 좌우 중 한 쪽이 필요 없으면 \left., \right. 로 크기만 유지하면서 렌더링을 생략할 수 있다.</description>
    </item>
    
    <item>
      <title>투자 정보 Open API CYBOS Plus 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-cybos-plus/</link>
      <pubDate>Sat, 26 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-cybos-plus/</guid>
      <description>소개 CYBOS는 대신증권에서 개발한 트레이딩 시스템으로, CYBOS Plus라는 Open APIApplication Programming Interface로써 증권 데이터를 제공하고 있다. 요구사항 대신증권 계좌와 ID가 필요하며, 공동인증서를 포함해 서비스에 로그인 된 상태에서 데이터를 요청할 수 있다. 대우증권 계좌는 앱 스토어에서 CYBOS Touch를 통해 비대면으로 개설할 수 있다. 신분증과</description>
    </item>
    
    <item>
      <title>소수와 합성수</title>
      <link>https://freshrimpsushi.github.io/posts/prime-number-and-composite-number/</link>
      <pubDate>Thu, 24 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prime-number-and-composite-number/</guid>
      <description>정의 1 자연수 $p \ge 2$ 의 약수가 $1$ 과 $p$ 뿐이면 소수Prime NUmber라 한다. 자연수 $m \ge 2$ 가 소수가 아니면 합성수Composite Number라 한다. 설명 정의에 따라 $2$ 는 당연히 소수다. 수론Number Theory에서 다루는 수는 아주 넓게 잡아 유리수까지인데, 실제 그 연구대상은 &amp;lsquo;소수론&amp;rsquo;이라 불</description>
    </item>
    
    <item>
      <title>Kaggle 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-kaggle/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-kaggle/</guid>
      <description>소개 캐글Kaggle은 전 세계적으로 가장 유명한 오픈 데이터 허브로, 셀 수 없을만큼 다양한 데이터를 공개하고 작은 대회도 많이 열고 있다. 모든 데이터가 캐글에 있다고 할 순 없지만, 캐글에 없는 데이터 유형은 없다. 통계과목이나 머신러닝에서 자유주제 과제를 한다면 가장 먼저 체크해봐야할 사이트다. 요구사항 회원가입이 필요하지만 구글 연동이 되므</description>
    </item>
    
    <item>
      <title>확률과정의 자기유사성과 허스트 인덱스</title>
      <link>https://freshrimpsushi.github.io/posts/self-similarity-and-hurst-index/</link>
      <pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/self-similarity-and-hurst-index/</guid>
      <description>정의 1 2 확률과정 $\left\{ X_{t} \right\}$ 이 모든 $a &amp;gt; 0$ 에 대해 다음을 만족하면 $H$-자기유사$H$-self-similar하다고 한다. $$ X_{at} \overset{D}{=} a^{H} X_{t} $$ 여기서 $\overset{D}{=}$ 은 분포가 같음을 의미하며, 파라메터 $H&amp;gt;0$ 을 허스트 인덱스Hurst Index라 부른다. 예시 브라운 모션 $W_{t}$ 을 생각해보면 $W_{t} \sim N(0,t)$ 이다. 예로써 정규분포 $N(0,1)$ 를 따르는 확률변수 $Z$ 에 대해 $a Z \sim N</description>
    </item>
    
    <item>
      <title>kaggle API로 데이터 받는 법, OSError: Could not find kaggle.json. 해결</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-fix-oserror-could-not-find-kaggle.json/</link>
      <pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-fix-oserror-could-not-find-kaggle.json/</guid>
      <description>개요 예시 데이터 링크 캐글에 있는 데이터는 그 용량이 만만치 않기 때문에 웹브라우저의 다운로드 기능에만 맡기기엔 조금 불안한 감이 있다. 그래서 고용량 데이터를 안정적으로 받을 수 있는 API를 제공하는데, 위 스크린샷에서 제일 상단에 있는 코드가 거기에 해당한다. 터미널에서 pip install kaggle을 입력래 kaggle을 설치하고 kaggle competitions download -c rsna-miccai-brain-tumor-radiogenomic-classification 를 입력하</description>
    </item>
    
    <item>
      <title>가우스 과정</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-gaussian-process/</link>
      <pubDate>Wed, 16 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-gaussian-process/</guid>
      <description>정의 1 확률과정 $\left\{ X_{t} \right\}$ 의 모든 유한 부분집합 $S = \left\{ X_{t_{k}} \right\}_{k=1}^{n} \subset \left\{ X_{t} \right\}$ 에 대해 $S$ 의 원소들의 모든 선형결합 $$ \sum_{k=1}^{n} a_{k} X_{t_{k}} \qquad , \left\{ a_{k} \right\}_{k=1}^{n} \subset \mathbb{R} $$ 가 다변량 정규분포를 따르면 $\left\{ X_{t} \right\}$ 가 가우시안 프로세스Gaussian Process라고 한다. 설명 비전공자가 보기에는 정의가 조금 지나치게 수학적으로 보일 수 있는데, 직관적으로 보았을 땐 위너 프로세스와 크게 다</description>
    </item>
    
    <item>
      <title>AI Hub 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-ai-hub/</link>
      <pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-ai-hub/</guid>
      <description>소개 음성/자연어, 비전, 헬스케어, 자율주행, 안전, 농축수산, 국토환경, 교육 등의 분야에서 이미지, 비디오, 텍스트, 오디오, 3D, 센서 데이터와 같이 다양한 포맷을 다룬다. 대구광역시 동구 소재의 한국지능정보사회진흥원에서 제공하는 듯하다. 데이터의 형태, 구조, 활용분야 등 설명이 아주 상세하며, 그 외에도 AI 컴퓨팅, 바우처, S/W</description>
    </item>
    
    <item>
      <title>블랙-숄즈 모델 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-black-scholes-model/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-black-scholes-model/</guid>
      <description>모델 1 $t$ 시점에서 $S_{t}$ 를 기초자산 $1$단위의 가격이라 하고 $S_{t}$ 가 기하 브라운 운동을 한다고 가정하자. 즉, 표준 브라운 운동 $W_{t}$ 와 추세Drift $\mu \in \mathbb{R}$ 와 확산Diffusion $\sigma^{2} &amp;gt; 0$ 에 대해 $S_{t}$ 는 다음의 확률미분방정식의 솔루션이다. $$ d S_{t} = S_{t} \left( \mu dt + \sigma d W_{t} \right) $$ 무위험이자율 $r \in \mathbb{R}$ 이 주어져 있을 때, $t$ 시점에서 파생상품 $1$단위의 가격</description>
    </item>
    
    <item>
      <title>파이썬 패키지, 라이브러리, 모듈 버전 체크하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-version-of-module-in-python/</link>
      <pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-version-of-module-in-python/</guid>
      <description>가이드 콘솔에서 다음과 같은 명령을 통해 버전을 확인할 수 있다. 전체적으로 보기에는 list가 더 깔끔하지만 특정 패키지의 버전을 확인할 땐 freeze가 더 읽기 쉽다. pip3 list pip3 freeze</description>
    </item>
    
    <item>
      <title>기하 브라운 운동</title>
      <link>https://freshrimpsushi.github.io/posts/geometric-brownian-motion/</link>
      <pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/geometric-brownian-motion/</guid>
      <description>정의 1 $\mu \in \mathbb{R}$ 과 $\sigma^{2} &amp;gt; 0$ 에 대해 다음과 같은 확률미분방정식이 주어져 있다고 하자. $$ d X_{t} = X_{t} \left( \mu dt + \sigma d B_{t} \right) $$ 이 SDE의 솔루션은 초기값 $X_{0}$ 에 대해 다음과 같은 확률과정으로 구해지며, 이를 기하 브라운 운동Geometric Brownian Motion이라 한다. $$ X_{t} = X_{0} \exp \left[ \left( \mu - {{ \sigma^{2} } \over { 2 }} \right) t + \sigma B_{t} \right] $$ 설명 지오메트릭 브라우니안 모션GB</description>
    </item>
    
    <item>
      <title>쇼지-오자키 국소 선형화 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/shoji-ozaki-local-linearization-method/</link>
      <pubDate>Wed, 02 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shoji-ozaki-local-linearization-method/</guid>
      <description>빌드업 1 $$ d X_{t} = f \left( t, X_{t} \right) dt + g \left( X_{t} \right) d W_{t} $$ 디퓨전 $g$ 가 $X_{t}$ 에만 종속이고 시간 $t$ 에 독립인 확률미분방정식이 위와 같이 주어져 있다고 하자. $Y_{t}$ 가 어떤 상수 $\sigma$ 에 대해 $\phi &amp;rsquo; \left( X_{t} \right) g \left( X_{t} \right) = \sigma$ 인 $\phi \in C^{2}$ 에 의해 $Y_{t} := \phi \left( X_{t} \right)$ 와 같이 나타난다고 하면, 이토 공식에 따라 어떤 함수 $b$ 에 대해 $$ \begin{align*} d Y_{t} =&amp;amp; \left( f \phi&amp;rsquo; + {{ 1 } \over { 2 }} g^{2} \phi&amp;rsquo;&amp;rsquo; \right) dt + g \phi&amp;rsquo; d W_{t} \\ =&amp;amp; b</description>
    </item>
    
    <item>
      <title>파이썬 shutil 모듈 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/cheetsheet-shutil-module-in-python/</link>
      <pubDate>Mon, 31 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cheetsheet-shutil-module-in-python/</guid>
      <description>파이썬 shutil 모듈 총정리 Cheetsheet os Module in python 개요 1 shutil 은 파일이나 디렉터리 등에 대한 고수준 명령을 모아놓은 기본 모듈이다. 파이썬을 사용하는 이유 중 하나가 빠르고 간편하게 프로그램을 작성하기 용이하다는 것인데, 상식적으로 있어야할 기능들이 os 모듈과 혼재되어 있어 무척 불편하다. 파일 시스템을 다룰 땐 두 모듈을 고르게 사용해야한다. 총정리지만 단순히 공식</description>
    </item>
    
    <item>
      <title>람페르티 변환</title>
      <link>https://freshrimpsushi.github.io/posts/lamperti-transformation/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lamperti-transformation/</guid>
      <description>정의 1 $$ d X_{t} = f \left( t , X_{t} \right) dt + g \left( X_{t} \right) d W_{t} $$ 디퓨전 $g$ 가 $X_{t}$ 에만 종속이고 시간 $t$ 에 독립인 확률미분방정식이 위와 같이 주어져 있다고 하자. 다음과 같은 변환 $F : X_{t} \mapsto Y_{t}$ 를 람페르티 변환Lamperti Transformation 이라고 한다. $$ Y_{t} := F \left( X_{t} \right) = \left. \int {{ 1 } \over { g (u) }} du \right|_{u = X_{t}} $$ 이렇게 얻어진 $\left\{ Y_{t} \right\}$ 는 다음과 같이 유닛 디퓨전을 가진 변환된 SDE의 솔</description>
    </item>
    
    <item>
      <title>밀슈타인 메소드 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-milstein-method/</link>
      <pubDate>Tue, 25 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-milstein-method/</guid>
      <description>메소드 1 $$ d X(t) = f \left( X_{t} \right) dt + g \left( X_{t} \right) d W_{t} \qquad , t \in [t_{0}, T] $$ 이토 프로세스가 위와 같은 자율 확률미분방정식의 솔루션으로써 주어져 있다고 하자. 간격이 $h$ 으로 일정한 등간격시점 $\left\{ t_{i} \le T : t_{i+1} = t_{i} + h \right\}_{i=0}^{N}$ 에 대해서 다음과 같이 계산되는 $Y_{i} := Y \left( t_{i} \right)$ 는 주어진 미분방정식의 수치적 해다. $$ Y_{i+1} = Y_{i} + f \left( Y_{i} \right) h + g \left( Y_{i} \right) \sqrt{h} Z + {{ 1 } \over { 2 }} g \left(</description>
    </item>
    
    <item>
      <title>파이썬 os 모듈 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/cheetsheet-os-module-in-python/</link>
      <pubDate>Sun, 23 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cheetsheet-os-module-in-python/</guid>
      <description>개요 1 os 은 운영체제 종속 기능에 대한 간단한 명령을 모아놓은 기본 모듈이다. 파이썬을 사용하는 이유 중 하나가 빠르고 간편하게 프로그램을 작성하기 용이하다는 것인데, 상식적으로 있어야할 기능들이 shutil 모듈과 혼재되어 있어 무척 불편하다. 파일 시스템을 다룰 땐 두 모듈을 고르게 사용해야한다. 총정리지만 단순히 공식 다큐먼트를 긁어온 게 아니라 가능하</description>
    </item>
    
    <item>
      <title>오일러-마루야마 메소드 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-euler-maruyama-method/</link>
      <pubDate>Fri, 21 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-euler-maruyama-method/</guid>
      <description>메소드 1 $$ d X(t) = f \left( X_{t} \right) dt + g \left( X_{t} \right) d W_{t} \qquad , t \in [t_{0}, T] $$ 이토 프로세스가 위와 같은 자율 확률미분방정식의 솔루션으로써 주어져 있다고 하자. 간격이 $h$ 으로 일정한 등간격시점 $\left\{ t_{i} \le T : t_{i+1} = t_{i} + h \right\}_{i=0}^{N}$ 에 대해서 다음과 같이 계산되는 $Y_{i} := Y \left( t_{i} \right)$ 는 주어진 미분방정식의 수치적 해다. $$ Y_{i+1} = Y_{i} + f \left( Y_{i} \right) h + g \left( Y_{i} \right) \sqrt{h} Z $$ 여기서 $Z$ 는 표준 정규</description>
    </item>
    
    <item>
      <title>파이썬에서 프로그램 일시중지하는 세가지 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-pause-in-python/</link>
      <pubDate>Wed, 19 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-pause-in-python/</guid>
      <description>코드 1 input() input() 모듈을 불러올 필요가 없고 아무런 메세지를 출력하지 않아 간편하게 가장 많이 사용하는 방법이다. 입력을 기다리는 동안 프로그램은 정지되며, 입력받은 값은 따로 저장되지 않아도 일시정지로써의 기능에는 문제가 없다. time.sleep() import time time_duration = 3.5 time.sleep(time_duration) 입력한 시간만큼 대기시킨다. 웹 크롤러와 같이 시간 지연을 고려해야하는 프로그램을 작성할 때 사용하게 된다</description>
    </item>
    
    <item>
      <title>이토-테일러 전개 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-it%C3%B4-taylor-expansion/</link>
      <pubDate>Mon, 17 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-it%C3%B4-taylor-expansion/</guid>
      <description>정리 1 $$ d X(t) = f \left( X_{t} \right) dt + g \left( X_{t} \right) d W_{t} \qquad , t \in [0, T] $$ 이토 프로세스가 위와 같은 자율 확률미분방정식의 솔루션으로써 주어져 있다고 하자. $f,g : \mathbb{R} \to \mathbb{R}$ 가 리니어 성장 조건을 만족하면, 즉 어떤 상수 $K$ 에 대해 $\begin{cases} \left| f \left( X_{t} \right) \right| \le K \left( 1 + \left| X_{t} \right|^{2} \right) \\ \left| g \left( X_{t} \right) \right| \le K \left( 1 + \left| X_{t} \right|^{2} \right) \end{cases}$ 이고 충분히 여러번 미분가능하면 다음이 성립한다. $$ X_{t} = X_{0} +</description>
    </item>
    
    <item>
      <title>줄리아에서 file.choose()처럼 대화창 열어서 파일 선택하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-choose-a-file-interactively-in-julia/</link>
      <pubDate>Sat, 15 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-choose-a-file-interactively-in-julia/</guid>
      <description>코드 1 using Gtk file_name = open_dialog(&amp;#34;파일 열기&amp;#34;) 첫번째 인수로 주어지는 문자열은 대화창의 타이틀이다. 실행하면 다음과 같이 &amp;lsquo;파일 열기&amp;rsquo;라는 대화창이 뜨는 것을 확인할 수 있다. 환경 OS: Windows julia: v1.6.0 https://discourse.julialang.org/t/choose-a-file-interactively/10910/3&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>SDE 수치적 해의 강한 수렴과 약한 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/strong-and-weak-convergence-of-sde-solver/</link>
      <pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/strong-and-weak-convergence-of-sde-solver/</guid>
      <description>빌드업 $$ d X_{t} = f \left( t, X_{t} \right) dt + g \left( t , X_{t} \right) d W_{t} \qquad , t \in \left[ t_{0} , T \right] $$ 확률미분방정식이 위와 같이 주어져 있고, 시간은 $t_{0} &amp;lt; t_{1} &amp;lt; \cdots &amp;lt; t_{N}$ 와 같이 이산화Discretization 되어있다고 하자. 충분히 큰 $N \in \mathbb{N}$ 을 선택해서 $\Delta = \left( T - t_{0} \right) / N \in (0,1)$ 이라 두면 이는 시간을 등간격Equidistant으로 자른 것이다. SDE의 해를 $X(t)$ 라</description>
    </item>
    
    <item>
      <title>짝수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-even-number/</link>
      <pubDate>Tue, 11 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-even-number/</guid>
      <description>정의 쉬운 정의 $2$ 로 나눈 나머지가 $0$ 인 정수를 짝수라 한다. 어려운 정의 $$ a = 2 \cdot k $$ 정수 $a$ 에 대해 위를 만족하는 정수 $k$ 가 존재하면 $a$ 가 짝수Even라 한다. 짝수가 아닌 정수를 홀수Odd라 한다. 설명 쿨타임이 돌때마다 인터넷 커뮤니티를 뜨겁게 달구는 질문이 있다. &amp;ldquo;$0$ 은 짝수인가?&amp;rdquo; 전국민이 초등학교 때 다 배웠는데도 매번 논쟁이</description>
    </item>
    
    <item>
      <title>CKLS 평균 복귀 감마 확률미분방정식</title>
      <link>https://freshrimpsushi.github.io/posts/ckls-sde/</link>
      <pubDate>Sun, 09 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ckls-sde/</guid>
      <description>모델 1 $$ d X_{t} = \left( \alpha - \beta X_{t} \right) dt + \sigma X_{t}^{\gamma} d W_{t} \qquad , X_{0} &amp;gt; 0 $$ $\alpha, \beta, \sigma, \gamma &amp;gt; 0$ 라고 하자. 위 확률미분방정식을 CKLS 평균 복귀 감마 확률미분방정식이라고 한다. 변수 $X_{t}$: 이자율Interesting Rate 혹은 유전자 빈도Gene frequency를 나타낸다. 파라메터 $\alpha / \beta$: 복귀 평균으로, $X_{t}$ 는 장기적으로 보았을 때 이 값으로 돌아가려고 한다. $\alpha &amp;gt; 0$: 조</description>
    </item>
    
    <item>
      <title>몫과 나머지</title>
      <link>https://freshrimpsushi.github.io/posts/quotient-and-remainder/</link>
      <pubDate>Fri, 07 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quotient-and-remainder/</guid>
      <description>정의 1 두 정수 $A$ 와 $B \ne 0$ 에 대해 $B &amp;gt; R \ge 0$ 과 $$ A = Q \cdot B + R $$ 을 만족하는 정수 $Q$, $R$ 이 있다고 하자. 이 때 $Q$ 를 몫Quotient, $R$ 을 나머지Remainder라 한다. 설명 요즘 초등학교에서 몫과 나머지를 어떻게 정의하는지는 모르겠으나, 엄밀한 이산수학과 정수론 수준과는 차이가 있을 것이다. 정의에서 주목할만한 점은 몫과 나머지를 나</description>
    </item>
    
    <item>
      <title>칵스-잉거솔-로스 모델, CIR Model</title>
      <link>https://freshrimpsushi.github.io/posts/cox-ingersol-ross-model/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cox-ingersol-ross-model/</guid>
      <description>모델 1 $$ d X_{t} = \left( \alpha - \beta X_{t} \right) dt + \sigma \sqrt{X_{t}} d W_{t} \qquad , X_{0} &amp;gt; 0 $$ $\alpha, \beta, \sigma &amp;gt; 0$ 가 $2 \alpha &amp;gt; \sigma^{2}$ 을 만족시킨다고 하자. 위 확률미분방정식을 CIR 모델이라고 한다. $$ X_{t} = {{ \alpha } \over { \beta }} + e^{-\beta t} \left( X_{0} - {{ \alpha } \over { \beta }} \right) + \sigma e^{-\beta t} \int_{0}^{t} e^{\beta u} \sqrt{X_{u}} d W_{u} $$ 변수 $X_{t}$: 이자율Interesting Rate 혹은 유전자 빈도Gene frequency를 나타낸다. 파라메터 $\alpha / \beta$: 복</description>
    </item>
    
    <item>
      <title>최대공약수와 서로소</title>
      <link>https://freshrimpsushi.github.io/posts/greatest-common-divisor-and-relatively-prime/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/greatest-common-divisor-and-relatively-prime/</guid>
      <description>정의 1 두 정수 $n$ 과 $m \ne 0$ 에 대해 다음을 만족하는 정수 $k$ 가 존재하면 $n$ 을 $m$ 이 나눈다고 한다. $$ n = mk $$ 이 때 $n$ 을 $m$ 의 배수Multiple, $m$ 을 $n$ 의 약수Divisor라 하며 다음과 같이 표기한다. $$ m \mid n $$ $m$ 이 $n$ 을 나눌 수 없으면 삭선을 그어 $m \nmid n$ 로 나타낸다. $0$ 이 아닌 두 정수 $a$, $b$ 가 주어져 있다고 하자. 둘 모두를 나누는 약수 중 가장 큰 수</description>
    </item>
    
    <item>
      <title>온스테인-울렌벡 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/ornstein-uhlenbeck-equation/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ornstein-uhlenbeck-equation/</guid>
      <description>정의 1 $$ d X_{t} = a X_{t} dt + \sigma d W_{t} $$ $a , \sigma \in \mathbb{R}$ 이라고 하자. 위 확률미분방정식을 온스테인-울렌벡 방정식Ornstein-Uhlenbeck Equation이라 하고, 그 솔루션인 확률과정 $X_{t}$ 를 온스테인-울렌벡 프로세스라고 한다. $$ X_{t} = X_{0} e^{a t} + \sigma \int_{0}^{t} e^{a (t-s)} d W_{s} $$ 설명 2 온스테인-울렌벡 방정식은 랑주뱅 방정식Langevin Eq</description>
    </item>
    
    <item>
      <title>거리공간이 컴팩트인 것과 완비이면서 완전 유계인 것은 동치다</title>
      <link>https://freshrimpsushi.github.io/posts/metric-space-is-compact-iff-it-is-complete-and-totally-bounded/</link>
      <pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/metric-space-is-compact-iff-it-is-complete-and-totally-bounded/</guid>
      <description>정리 1 거리공간이 컴팩트인 것과 완비이면서 완전 유계인 것은 동치다. 증명 $(\Rightarrow)$ 거리 공간 $X$ 가 컴팩트라 하자. 완비 거리 공간의 성질들: $(X,d)$ 가 거리 공간이고 $K \subset X$ 라 하자. [1]: $K$ 는 완비 부분 공간이다. $\iff$ $X$ 에서 $K$가 닫힌 집합이다. [2]: $K$ 는 완전 유계 공간 $\iff$ $X$에서 닫힌 집합 $K$ 는 컴팩트이다. $X \subset X$ 는 $X$ 에서 폐집합이므로 완비 공간이다. 폐집합 $X</description>
    </item>
    
    <item>
      <title>2021년 독자 전공 조사 결과</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-your-major-2021/</link>
      <pubDate>Tue, 28 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-your-major-2021/</guid>
      <description>독자전공조사 결과 생새우초밥집은 국내 최대의 형식과학 블로그를 지향하며, 22년에는 커뮤니티와 연계해서 작은 공모전과 같은 이벤트를 준비하고 있습니다. 20년 12월 29일부터 21년 11월 28일까지, 약 11개월동안 저희는 방문자 여러분들의 전공에 대한 간단한 설문조사를 요청한 바 있습니다. 간단한 요약을 함께 봅시다. 설문조사에는 총</description>
    </item>
    
    <item>
      <title>브라운의 다리</title>
      <link>https://freshrimpsushi.github.io/posts/brownian-bridge/</link>
      <pubDate>Tue, 28 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/brownian-bridge/</guid>
      <description>정의 1 2 $$ d Y_{t} = {{ b - Y_{t} } \over { 1 - t }} dt + d W_{t} \qquad, t \in [0,1), Y_{0} = a $$ $a, b \in \mathbb{R}$ 이라고 하자. 위의 $1$차원 확률미분방정식의 솔루션인 확률과정 $Y_{t}$ 를 ($a$ 에서 $b$ 로의) 브라우니안 브릿지Brownian Bridge라고 한다. $$ Y_{t} = a (1-t) + bt + (1-t) \int_{0}^{t} {{ 1 } \over { 1 - s }} d W_{s} $$ 설명 브라운의 다리는 $a$ 에서 시작해서 중간에 아무리 방황하더라도</description>
    </item>
    
    <item>
      <title>줄리아에서 소수점 아래 특정 자리에서 반올림하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-round-function-in-julia/</link>
      <pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-round-function-in-julia/</guid>
      <description>코드 사실 줄리아는 문자열 포맷 등이 아주 편리한 언어는 아니다. 콘솔에 출력할 때 문자열 자체 기능을 사용하는 방법도 있지만 round() 함수의 기본 옵션인 digits를 사용하는 게 편한 경우가 많을 것이다. julia&amp;gt; for k in 0:8 println(round(π, digits = k)) end 3.0 3.1 3.14 3.142 3.1416 3.14159 3.141593 3.1415927 3.14159265 환경 OS: Windows julia: v1.6.0</description>
    </item>
    
    <item>
      <title>전형적인 확률미분방정식들의 해</title>
      <link>https://freshrimpsushi.github.io/posts/solution-to-typical-sdes/</link>
      <pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-to-typical-sdes/</guid>
      <description>방정식 1 (G) General Form: $$ d X_{t} = f \left( t , X_{t} \right) dt + g \left( t , X_{t} \right) d W_{t} $$ (L) Linear: $\begin{cases} f \left( t , X_{t} \right) = a_{t} + b_{t} X_{t} \\ g \left( t , X_{t} \right) = c_{t} + e_{t} X_{t} \end{cases}$ $$ d X_{t} = \left( a_{t} + b_{t} X_{t} \right) dt + \left( c_{t} + e_{t} X_{t} \right) d W_{t} $$ (LH) Homogeneous: $a_{t} = c_{t} = 0$ $$ d X_{t} = b_{t} X_{t} dt + e_{t} X_{t} d W_{t} $$ (LNS) in Narrow Sense: $e_{t} = 0$ $$ d X_{t} = \left( a_{t} + b_{t} X_{t} \right) dt + c_{t} d W_{t} $$ (A) Autonomous: $\begin{cases} f \left( t , X_{t} \right) = f \left( X_{t} \right) \\ g \left( t , X_{t} \right) = g \left( X_{t} \right) \end{cases}$ $$ d X_{t} =</description>
    </item>
    
    <item>
      <title>그뢴발 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gr%C3%B6nwalls-inequality/</link>
      <pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gr%C3%B6nwalls-inequality/</guid>
      <description>정리 최소값 $a \in \mathbb{R}$ 를 가지는 구간 $I \subset \mathbb{R}$ 에서 두 연속함수 $f,w : I \to \mathbb{R}$ 가 정의되어 있다고 하자. $w$ 가 $\forall t \in I$ 에서 $w(t) \ge 0$ 이고 어떤 상수 $C \in \mathbb{R}$ 에 대해 $$ f(t) \le C + \int_{a}^{t} w(s) f(s) ds \qquad , \forall t \in I $$ 이면 다음이 성립한다. $$ f(t) \le C \exp \left( \int_{a}^{t} w(s) ds \right) \qquad , \forall t \in I $$ 설명 구간 $I$ 가 최소값 $a$ 를 가진다는 것은 $I$ 가 $a &amp;lt; b$ 에 대해 다음과 같이 생겼다는 의미다. $$ [a,b] \text{ or } [a,b)</description>
    </item>
    
    <item>
      <title>선형, 동차, 자율 확률미분방정식</title>
      <link>https://freshrimpsushi.github.io/posts/linear-homogeneous-autonomous-sde/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-homogeneous-autonomous-sde/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 필트레이션 $\left\{ \mathcal{F}_{t} \right\}_{t \ge 0}$ 이 주어져 있다고 하자. 두 함수 $f$, $g$ 와 $\mathcal{F}_{t}$-어댑티드인 $m$차원 위너 프로세스 $W_{t}$ 에 대해 다음과 같은 $n$차원 확률미분방정식을 생각해보자. $$ \begin{align*} d X_{t} =&amp;amp; f \left( t, X_{t} \right) dt + g \left( t, X_{t} \right) d W_{t} \\ f =&amp;amp; a(t) + A(t) X_{t} \\ g =&amp;amp; b(t) + B(t) X_{t} \\ a, b &amp;amp;: [0,T] \to \mathbb{R}^{n} \\ A, B &amp;amp;: [0,T] \to \mathbb{R}^{n \times</description>
    </item>
    
    <item>
      <title>프로베니우스 놈</title>
      <link>https://freshrimpsushi.github.io/posts/frobenius-norm/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/frobenius-norm/</guid>
      <description>정의 1 행렬 $A = \left( a_{ij} \right) \in \mathbb{C}^{m \times n}$ 에 대해 행렬의 놈 $\left\| \cdot \right\|_{F}$ 을 다음과 같이 정의하고 프로베니우스 놈Frobenius Norm이라 부른다. $$ \left\| A \right\|_{F} = \sqrt{ \sum_{ij} \left| a_{ij} \right|^{2} } = \sqrt{ \text{Tr} \left( A A^{\ast} \right) } $$ 설명 프로베니우스 놈은 힐베르트-슈미트 놈이라 불리기도 한다. $n = 1$, 즉 $m$차원 벡터들의 공간에선 유클리드 놈이 되므로 유클리드 놈의 자연스러운 일반화로 볼</description>
    </item>
    
    <item>
      <title>확률미분방정식의 해의 존재성과 유일성, 강한 해와 약한 해</title>
      <link>https://freshrimpsushi.github.io/posts/existence-and-uniqueness-of-solution-to-sde/</link>
      <pubDate>Thu, 16 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/existence-and-uniqueness-of-solution-to-sde/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 필트레이션 $\left\{ \mathcal{F}_{t} \right\}_{t \ge 0}$ 이 주어져 있다고 하자. $$ \begin{align*} f &amp;amp;: [0,T] \times \mathbb{R}^{n} \to \mathbb{R}^{n} \\ g &amp;amp;: [0,T] \times \mathbb{R}^{n} \to \mathbb{R}^{n \times m} \end{align*} $$ 두 함수 $f$, $g$ 와 $\mathcal{F}_{t}$-어댑티드인 $m$차원 위너 프로세스 $W_{t}$ 에 대해 다음과 같은 $n$차원 확률미분방정식을 생각해보자. $$ d X_{t} = f \left( t, X_{t} \right) dt + g \left( t, X_{t} \right) d W_{t} $$ 연속이고 $F_{</description>
    </item>
    
    <item>
      <title>D-데이터 허브 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-d-data-hub/</link>
      <pubDate>Tue, 14 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-d-data-hub/</guid>
      <description>소개 D-데이터허브는 대구광역시를 중심으로 한 공공데이터 포털로써 4,000가지 이상의 데이터셋과 13,000개 이상의 서비스를 제공하고 있다. 지역데이터답게 구/군별로 상세하고 다양한 데이터를 얻을 수 있다. 요구사항 어떤 요구 사항도 없이 무제한적으로 다운로드 받을 수 있다. 데이터 예시 대구광역시_기초지자체별 일일 코로나19 확진</description>
    </item>
    
    <item>
      <title>줄리아에서 히트맵 색 범위 지정하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-set-min-max-values-in-a-heatmap/</link>
      <pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-set-min-max-values-in-a-heatmap/</guid>
      <description>코드 1 히트맵을 그릴 때 수치에 따라 값의 스케일이 고정되지 않으면 곤란할 때가 있다. 기본 히트맵 함수에서 clim 옵션을 통해 색의 범위를 고정할 수 있다. using Plots cd(@__DIR__) heatmap(rand(4,4)); png(&amp;#34;1.png&amp;#34;) heatmap(rand(4,4), clim = (0,1)); png(&amp;#34;2.png&amp;#34;) 결과는 다음과 같다. 첫번째 히트맵은 범위가 없지만 두번째 히트맵은 0과 1로 범위가 고정되어있음을 확인할 수 있다. 한쪽만 제한 heatmap(rand(4,4), clim = (0,Inf)) heatmap(rand(4,4), clim = (-Inf,1)) 상한만 두거나 하한만 두고 싶으면</description>
    </item>
    
    <item>
      <title>확률미분방정식이란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-stochastic-differential-equation/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-stochastic-differential-equation/</guid>
      <description>정의 1 $$ d X(t) = f \left( t, X(t) \right) dt + g \left( t, X(t) \right) d W_{t} \qquad , t \in \left[ t_{0} , T \right], T &amp;gt; 0 $$ 위와 같은 꼴의 방정식을 확률미분방정식, 줄여서 SDE(Stochastic Differential Equation)라 한다. 이 때 $f$, $g$ 를 각각 드리프트Drift, 디퓨젼Diffusion 계수 함수라 부른다. 초기조건 $X_{0} := X \left( t_{0} \right)$ 에 대해 적분꼴은 다음과 같이 나타난다. $$ X(t) = X_{0} + \int_{t_{0}}^{t} f \left( s, X (s) \right) ds + \int_{t_{0}}^{t}</description>
    </item>
    
    <item>
      <title>줄리아에서 zfill() 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-zfill-in-julia/</link>
      <pubDate>Wed, 08 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-zfill-in-julia/</guid>
      <description>개요 1 파이썬에서 zfill()은 사실 문자열 클래스의 메소드로써, 좌측을 0으로 채워주는 기능을 가지고 있다. 줄리아에서는 이보다 범용적이고 쓰임새가 많은 내장 함수로써 lpad()를 제공한다. zfill()은 제로zero를 채운다fill는 의미고, lpad()는 왼쪽left의 패딩padding을 의미한다. 코드 julia&amp;gt; lpad(&amp;#34;12&amp;#34;, 4, &amp;#34;0&amp;#34;)</description>
    </item>
    
    <item>
      <title>이토 표현 정리와 마틴게일 표현 정리</title>
      <link>https://freshrimpsushi.github.io/posts/it%C3%B4-representation-and-martingale-representation-theorem/</link>
      <pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/it%C3%B4-representation-and-martingale-representation-theorem/</guid>
      <description>정리 1 2 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 필트레이션 $\left\{ \mathcal{F}_{t} \right\}_{t \ge 0}$ 이 주어져 있다고 위너 프로세스 $\left\{ W_{t} \right\}_{t \ge 0}$ 가 $\mathcal{F}_{t}$-어댑티드라고 하자. 이토 표현 정리 $f \in \mathcal{L}^{2} (P)$ 면 다음을 만족하는 확률과정 $X (t,\omega) \in m^{2}(0,T)$ 가 유일하게 존재한다. $$ f (\omega) = E (f) + \int_{0}^{T} X(s, \omega) d W_{s} $$ 마틴게일 표현 정리 모든 $t \ge 0$ 에 대해 $f_{t} \in \mathcal{L}^{2} (P)$ 이고 $f_{t}$ 가 확률 $P$ 에 대해</description>
    </item>
    
    <item>
      <title>네트워크에서 차수의 분포</title>
      <link>https://freshrimpsushi.github.io/posts/distribution-of-degree-of-nodes/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distribution-of-degree-of-nodes/</guid>
      <description>빌드업 랜덤 네트워크는 그 함수값이 네트워크인 랜덤 엘러먼트이므로, 샘플링을 할 때마다 다른 네트워크를 얻는다. 네트워크를 구축하는 방법에 따라, 즉 모델에 따라 어떠한 일관된 성질을 가지긴 하겠지만 그렇게 얻어진 실현은 제각각이다. 이에 따르면 각 노드의 차수 $\deg$ 역시 매번의 샘플링때마다 바뀌는데, 네트워크 이론에서 차수는 대단히 중요한 요소기 때</description>
    </item>
    
    <item>
      <title>이토 공식</title>
      <link>https://freshrimpsushi.github.io/posts/it%C3%B4-formula/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/it%C3%B4-formula/</guid>
      <description>정리 1 이토 프로세스 $\left\{ X_{t} \right\}_{t \ge 0}$ 가 주어져 있다고 하자. $$ d X_{t} = u dt + v d W_{t} $$ 함수 $V \left( t, X_{t} \right) = V \in C^{2} \left( [0,\infty) \times \mathbb{R} \right)$ 에 대해 $Y_{t} := V \left( t, X_{t} \right)$ 라 두면 $\left\{ Y_{t} \right\}$ 역시 이토 프로세스고, 다음이 성립한다. $$ \begin{align*} d Y_{t} =&amp;amp; V_{t} dt + V_{x} d X_{t} + {{ 1 } \over { 2 }} V_{xx} \left( d X_{t} \right)^{2} \\ =&amp;amp; \left( V_{t} + V_{x} u + {{ 1 } \over { 2 }} V_{xx} v^{2} \right) dt + V_{x} v d W_{t} \end{align*} $$ $C^{2}$ 는 두 번 미분가능하고 그 도함수가</description>
    </item>
    
    <item>
      <title>줄리아에서 구조체 속성 확인하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-properties-of-structure-in-julia/</link>
      <pubDate>Tue, 30 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-properties-of-structure-in-julia/</guid>
      <description>코드 propertynames() 함수로 확인하면 된다.1 줄리아에는 클래스가 없고 구조체만 있으니2 이 함수로 리턴되는 모든 심볼들은 정확히 프로퍼티들만의 이름들이다. 다음은 Graphs 패키지에서 에르되시-레니 네트워크를 생성하고 노드의 수와 각 노드의 네이버후드를 확인하는 코드다. propertynames() 함수에 해당 네트워크를 집어넣어서 :ne와 fadjlist라는 프로퍼티가 심볼로써</description>
    </item>
    
    <item>
      <title>이토 프로세스</title>
      <link>https://freshrimpsushi.github.io/posts/it%C3%B4-process/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/it%C3%B4-process/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 필트레이션 $\left\{ \mathcal{F}_{t} \right\}_{t \ge 0}$ 이 주어져 있다고 하자. 위너 프로세스 $\left\{ W_{t} \right\}_{t \ge 0}$ 가 $\mathcal{F}_{t}$-어댑티드고, $f \in \mathcal{L}^{1} [0 , \infty)$ 과 $g \in \mathcal{L}^{2} [0 , \infty)$ 에 대해 다음과 같은 $1$차원 연속 $\mathcal{F}_{t}$-어댑티드 확률과정 $\left\{ X_{t} \right\}_{t \ge 0}$ 를 $1$차원 이토 프로세스Itô Proces</description>
    </item>
    
    <item>
      <title>길버트 모델</title>
      <link>https://freshrimpsushi.github.io/posts/gilbert-model/</link>
      <pubDate>Fri, 26 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gilbert-model/</guid>
      <description>정의 1 2 쉬운 정의 심플 네트워크의 링크가 각각 독립적으로 확률 $p \in [0,1]$ 에 따라 연결되는 랜덤 네트워크를 길버트 모델Gilbert Model $\mathbb{G}_{n,p}$ 라 한다. 어려운 정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있고, $n$ 개의 라벨링 된Labeled 노드를 가진 네트워크의 프로퍼티 $2^{\binom{n}{2}} \subseteq 2^{\binom{n}{2}}$ 가 주어져 있다고 하자. 링크의 수 $0 \le m \le \binom{n}{2}$ 에 대해 다음의 확률질량함수를 가지는</description>
    </item>
    
    <item>
      <title>이토 부분 적분</title>
      <link>https://freshrimpsushi.github.io/posts/it%C3%B4-integration-by-parts/</link>
      <pubDate>Wed, 24 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/it%C3%B4-integration-by-parts/</guid>
      <description>정리 1 $[0,t]$ 에서 바운드 된 연속함수 $f(s,\omega) = f(s)$ 가 $s$ 에만 종속되어있다고 하면 $$ \int_{0}^{t} f(s) d W_{s} = f (t) W_{t} - \int_{0}^{t} W_{s} d f (s) $$ $W_{t}$ 는 위너 프로세스다. 설명 이토 적분에 대한 정리일 뿐 흔히 우리가 아는 부분적분법과 크게 다르지 않다. 적분자가 바뀐 것에 주의해야한다. 유도 역시 일반적인 부분적분법과 같다. $$ \begin{align*} &amp;amp; {{ d } \over { ds }} f(s) W_{s} = {{ d } \over { ds }} f(s) \cdot W_{s} + f(s) {{ d }</description>
    </item>
    
    <item>
      <title>에르되시-레니 모델</title>
      <link>https://freshrimpsushi.github.io/posts/erd%C5%91s-r%C3%A9nyi-model/</link>
      <pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/erd%C5%91s-r%C3%A9nyi-model/</guid>
      <description>빌드업 $n$ 개의 라벨링 된Labeled 버텍스와 $m$ 개의 에지를 가진 심플 그래프라는 프로퍼티 $\mathscr{G}_{n,m} \subset 2^{\binom{n}{2}}$ 를 생각해보자. 정확히 $m$ 개의 링크를 가진 랜덤 그래프는 $\mathbb{G}_{n, m} : \Omega \to \mathscr{G}_{n,m}$ 과 같이 나타낼 수 있다. 이렇게 만들어지는 그래프는 $n$ 개의 노드와 $m$ 개의 링크만 가지면 누가 어떤 확률로 만들어지든 아무래도 상관 없다. 다시 말해, 아직까지는 확률 분포가 주어지지</description>
    </item>
    
    <item>
      <title>이토 곱셈 테이블</title>
      <link>https://freshrimpsushi.github.io/posts/it%C3%B4-multiplication-table/</link>
      <pubDate>Sat, 20 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/it%C3%B4-multiplication-table/</guid>
      <description>빌드업 $s&amp;lt; t &amp;lt; t+u$ 라고 할 때, 다음의 조건들을 만족하는 확률과정 $\left\{ W_{t} \right\}$ 를 위너 프로세스라 한다. (i): $W_{0} = 0$ (ii): $\left( W_{t+u} - W_{t} \right) \perp W_{s}$ (iii): $\left( W_{t+u} - W_{t} \right) \sim N ( 0, u )$ (iv): $W_{t}$ 의 샘플 패스는 거의 어디서나 연속이다. 위너 프로세스는 다음과 같은 성질들을 가진다. [1]: $\displaystyle W_{t} \sim N ( 0 , t ) $ [2]: $\displaystyle E ( W_{t} ) = 0$ [3]: $\displaystyle \text{Var} ( W_{t} ) = t$ [4]: $\displaystyle \text{cov} ( W_{t} , W_{s} ) = {{1} \over {2}} (|t| + |s| - |t-s|) = \min</description>
    </item>
    
    <item>
      <title>랜덤 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/random-graph/</link>
      <pubDate>Thu, 18 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-graph/</guid>
      <description>정의 쉬운 정의 비결정론적인 절차로 만들어지거나 어떤 확률 분포에 따라 표현되는 그래프를 랜덤 그래프Random Graph라 한다. 어려운 정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있고, $2^{\binom{n}{2}}$ 는 버텍스가 $n$ 개인 라벨링 된 그래프를 모두 모은 그래프 패밀리를 나타낸다고 하자. $\mathcal{F}$-가측인 함수 $\mathbb{G} : \Omega \to 2^{\binom{n}{2}}$ 를 랜덤 그래프Rand</description>
    </item>
    
    <item>
      <title>이토 등거리 등식</title>
      <link>https://freshrimpsushi.github.io/posts/it%C3%B4-isometry/</link>
      <pubDate>Tue, 16 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/it%C3%B4-isometry/</guid>
      <description>정리 1 모든 $f \in m^{2}[a,b]$ 에 대해 다음 등식이 성립한다. $$ E \left[ \left( \int_{a}^{b} f d W_{t} \right)^{2} \right] = E \left[ \int_{a}^{b} f^{2} dt \right] $$ 설명 적분기호 밖의 제곱 $^{2}$ 이 넘나드는 것도 맞지만, 적분자 $d W_{t}$ 와 $dt$ 역시 바뀌는 것에도 주목해야한다. 증명 1 전략: 초등 과정의 시퀀스 $\left\{ \phi_{n} \right\}_{n \in \mathbb{N}}$ 에 대해서만 보이면 이토 적분의 정의에 따라 자연스럽게 $\phi_{n} \to f \in m^{2}$ 에 대해 일반화되므로, 초등 과정 $\phi_{n}$ 만 생각해도</description>
    </item>
    
    <item>
      <title>그래프의 패밀리와 프로퍼티</title>
      <link>https://freshrimpsushi.github.io/posts/family-and-property-of-graph/</link>
      <pubDate>Sun, 14 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/family-and-property-of-graph/</guid>
      <description>빌드업 $n$ 개의 라벨링 된Labeled 버텍스의 집합 $V = [n] = \left\{ 1 ,\cdots , n \right\}$ 를 가진 심플 그래프를 생각해보자. 이 그래프의 에지는 서로 다른 두 버텍스를 고르는 경우의 수만큼 존재할 수 있고, 따라서 그 종류는 정확히 $\binom{n}{2}$ 다. 이것을 각각의 에지가 아닌 그래프 전체로 생각해보자면 $n$ 개의 버텍스가 픽스된 상황에서 $\binom{n}{2}$ 가지 각각의 에지가 존재하느냐(1) 존재</description>
    </item>
    
    <item>
      <title>이토 적분</title>
      <link>https://freshrimpsushi.github.io/posts/it%C3%B4-integral/</link>
      <pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/it%C3%B4-integral/</guid>
      <description>빌드업 확률적 적분을 생각하기 이전에 아주 중요한 확률 프로세스인 초등 프로세스Elementary Process을 정의하려고 한다. 초등 프로세스란 측도론에서 르벡 적분을 정의하기 위해 필요했던 단순 함수와 비슷한 역할을 한다. $$ a = t_{0} &amp;lt; t_{1} &amp;lt; \cdots &amp;lt; t_{k} = b $$ 네츄럴 도메인 $[a,b]$ 에서 위와 같은 분할을 생각해보자. 지시함수 $\chi$ 와 $\mathca</description>
    </item>
    
    <item>
      <title>접평면과 노멀 벡터</title>
      <link>https://freshrimpsushi.github.io/posts/tangent-plane/</link>
      <pubDate>Wed, 10 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tangent-plane/</guid>
      <description>정의 1 $2$차원 유클리드 공간의 개집합 $U \subset \mathbb{R}^{2}$ 이 두 좌표 $u_{1}$, $u_{2}$ 를 가졌다고 할 때, $\mathbf{x}_{1}$, $\mathbf{x}_{2}$를 다음과 같이 단순곡면 $\mathbf{x} : U \to \mathbb{R}^{3}$의 방향 편미분들이라고 하자. $$ \begin{align*} \mathbf{x}_{1} := {{ \partial \mathbf{x} } \over { \partial u_{1} }} &amp;amp; , &amp;amp; \mathbf{x}_{2} := {{ \partial \mathbf{x} } \over { \partial u_{2} }} \end{align*} $$ 점 $P = \mathbf{x} (a,b)$ 에서 $\mathbf{x}_{1} \times \mathbf{x}_{2}$ 와 수직인 평면을 $P$ 에서 $\mathbf{x}$ 의 접평면Ta</description>
    </item>
    
    <item>
      <title>m2 공간</title>
      <link>https://freshrimpsushi.github.io/posts/m2-space/</link>
      <pubDate>Mon, 08 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/m2-space/</guid>
      <description>정의 1 2 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. $\mathcal{F}$ 의 서브 시그마 필드의 시퀀스 $\left\{ \mathcal{F}_{t} \right\}_{t \ge 0}$ 이 다음을 만족하면 필트레이션Filtration이라 부른다. $$ \forall s &amp;lt; t, \mathcal{F}_{s} \subset \mathcal{F}_{t} $$ 확률과정 $g(t,\omega) : [0,\infty) \times \Omega \to \mathbb{R}^{n}$ 가 모든 $t \ge 0$ 에 에서 $\omega \mapsto g (t,\omega)$ 가 $\mathcal{F}_{t}$-가측이면 $\mathcal{F}_{t}$-어댑티드$</description>
    </item>
    
    <item>
      <title>곡면 이론에서의 좌표 변환</title>
      <link>https://freshrimpsushi.github.io/posts/coordinate-transformation/</link>
      <pubDate>Sat, 06 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/coordinate-transformation/</guid>
      <description>정의 1 $2$차원 유클리드 공간의 $U \subset \mathbb{R}^{2}$ 이 개집합이라고 하자. $k \in \mathbb{N}$ 에 대해 전단사 함수 $f : U \to \mathbb{R}^{3}$ 와 그 역함수 $f^{-1}$ 가 모두 $C^{k}$ 함수면 좌표 변환Coordinate Transformation이라고 한다. 설명 좌표변환의 정의는 일반 위상 수학에서 말하는 호메오멀피즘, 디피오멀피즘을 떠올리게 한다. 단지 기하학의 맥락에서 $3$차원 공간</description>
    </item>
    
    <item>
      <title>라오-블랙웰 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rao-blackwell-theorem/</link>
      <pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rao-blackwell-theorem/</guid>
      <description>정리 1 2 모수 $\theta$ 가 주어져 있다고 하자. $T$ 가 $\theta$ 의 충분통계량이고 $W$ 가 $\tau \left( \theta \right)$ 의 불편추정량이라고 할 때 $\phi \left( T \right) := E \left( W | T \right)$ 를 정의하면 모든 $\theta$ 에 대해 다음이 성립한다. $$ \begin{align*} E_{\theta} \phi (T) =&amp;amp; \tau (\theta) \\ \text{Var}_{\theta} \phi (T) \le&amp;amp; \text{Var}_{\theta} W \end{align*} $$ 다시 말해, $\phi (T)$ 는 $\tau (\theta)$ 에 대해 $W$ 보다 더 나은 불편추정량Uniformly Better Unbiased Estimator이다. 설명 라오-블랙웰 정리를</description>
    </item>
    
    <item>
      <title>단순 곡면, 좌표 패치</title>
      <link>https://freshrimpsushi.github.io/posts/simple-surface/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simple-surface/</guid>
      <description>정의1 1 두 좌표 $u_{1}$, $u_{2}$ 를 가진 $2$차원 유클리드 공간의 부분집합 $U \subset \mathbb{R}^{2}$가 개집합이라고 하자. $k \in \mathbb{N}$ 에 대해 $C^{k}$ 단사 함수 $\mathbf{x} : U \to \mathbb{R}^{3}$ 가 모든 $p \in U$ 에 대해 다음을 만족하면 단순 곡면Simple Surface이라 부른다. $$ {{ \partial \mathbf{x} } \over { \partial u_{1} }} (p) \times {{ \partial \mathbf{x} } \over { \partial u_{2} }} (p) \ne \mathbf{0} $$ 설명 정의에서 개집합 $U$ 은 $2$차</description>
    </item>
    
    <item>
      <title>동역학계 간 위상적 동치</title>
      <link>https://freshrimpsushi.github.io/posts/topologically-equivalence-between-two-dynamical-systems/</link>
      <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/topologically-equivalence-between-two-dynamical-systems/</guid>
      <description>정의 1 $$ \left\{ T , \mathbb{R}^{n} , \varphi^{t} \right\} \\ \left\{ T , \mathbb{R}^{n} , \psi^{t} \right\} $$ 두 동역학계가 위와 같이 주어져 있다고 하자. 시간의 방향을 유지하면서 첫번째 시스템의 각 오빗을 두번째 시스템의 모든 오빗으로 대응시키는 위상동형사상Homeomorphism $h : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 이 존재하면 두 시스템이 위상적 동치Topologically Equivalent라고 한다. 설명 정의</description>
    </item>
    
    <item>
      <title>등주 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-isoperimetric-inequaltity/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-isoperimetric-inequaltity/</guid>
      <description>정리 1 길이가 $L$ 인 평면 정칙 단순 폐곡선 $\alpha$ 가 있다고 하자. $\alpha$ 로 둘러싸인 내부의 면적을 $A$ 라 하면 $$ L^{2} \ge 4 \pi A $$ 이다. 특히, $L^{2} = 4 \pi A$ 가 되는 조건은 $\alpha$ 가 원인 것이다. 설명 사실 이 정리가 말하는 팩트 자체는 직관적으로든 어떻든 많은 사람들에게 알려져있다. 물방울이 굳이 각지지 않고 둥글게 맺히는 물리적인 이유는 모르더라도, 수많은 자연현상 속에</description>
    </item>
    
    <item>
      <title>확률미분방정식에서의 백색소음</title>
      <link>https://freshrimpsushi.github.io/posts/white-noise-in-sde/</link>
      <pubDate>Wed, 27 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/white-noise-in-sde/</guid>
      <description>모티브 $$ \xi (t) \overset{?}{:=} \dot{W}(t) = {{d W (t)} \over {dt}} $$ 위와 같이 위너 프로세스의 도함수로써 정의된 $\xi$ 를 상상해보자. 브라운 모션을 생각해봤을 때 이 $\xi(t)$ 는 시점 $t$ 에 무작위적인 등락을 표현하는 노이즈가 될 것이다. 겉보기에는 아주 직관적이고 전혀 어색하지 않으나, 안타깝게도 보편적인 센스에서 $\dot{W}(t)$ 의 존재성에 문제가 있다. 위너 프로세스의 미분불가능성 1 $$ Y_{h} := {{W (t + h)</description>
    </item>
    
    <item>
      <title>평면 단순 폐곡선으로 둘러싸인 영역의 넓이 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/volume-formula-for-plane-simple-closed-curve/</link>
      <pubDate>Mon, 25 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/volume-formula-for-plane-simple-closed-curve/</guid>
      <description>공식 1 영역 $R$ 을 둘러싼 평면 단순 폐곡선 $\alpha$ 가 반시계방향으로 돈다고 하면 $$ V (R) = \int_{\alpha} x dy = - \int_{\alpha} y dx $$ $V(R)$ 은 영역 $R$ 의 볼륨, 다시 말해 $R$ 의 면적을 의미한다. 증명 그린의 정리: 반시계방향을 가지고 조각마다 스무스한 단순 평면 $C^{2}$ 닫힌 곡선 $\mathcal{C}$ 가 유계 영역 $\mathcal{R}$ 을 감싸고 있다고 하자. $\mathcal{R}$ 에서 정의된 두 함수 $P,Q$ 가 $\mathcal{R}$ 에서 미분가능하면 $$ \int_{\mathcal{C}} (Pdx + Qdy) = \iint_{\mathcal{R}} (Q_{x} - P_{y}) dx dy</description>
    </item>
    
    <item>
      <title>줄리아에서 특정 값으로 채운 배열 만드는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-array-with-some-value-in-julia/</link>
      <pubDate>Sat, 23 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-array-with-some-value-in-julia/</guid>
      <description>코드 fill() 함수를 사용하면 된다. R에서의 rep() 함수와 비슷한 기능을 한다. julia&amp;gt; fill(1, 4) 4-element Vector{Int64}: 1 1 1 1 julia&amp;gt; fill(false, 2, 3) 2×3 Matrix{Bool}: 0 0 0 0 0 0 julia&amp;gt; fill(3.14, 2, 3, 2) 2×3×2 Array{Float64, 3}: [:, :, 1] = 3.14 3.14 3.14 3.14 3.14 3.14 [:, :, 2] = 3.14 3.14 3.14 3.14 3.14 3.14</description>
    </item>
    
    <item>
      <title>회전수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rotation-index-theorem/</link>
      <pubDate>Thu, 21 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rotation-index-theorem/</guid>
      <description>정리 1 평면 단순 폐곡선의 회전수는 $i_{\alpha} = \pm 1$ 이다. 설명 짧지만 아주 직관적이고 중요한 정리다. 증명은 다소 독특하다. 증명 $\alpha(s)$ 가 정리의 조건을 만족하면서 길이 $L$ 인 곡선이라고 하자. $$ 0 \le u &amp;lt; v \le L $$ 곡선에서 호의 길이 재매개변수화에 따라 나타나는 두 점 $u, v$ 을 위와 같이 정의하자. 여기서 이변수 함수 $a (u, v)$ 를 시점이 $\alpha(u)$ 이고 종점이 $\alpha(v)$ 인 벡터와 같은</description>
    </item>
    
    <item>
      <title>윈도에서 파이썬 텐서플로 GPU 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-tensorflow-gpu-in-windows/</link>
      <pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-tensorflow-gpu-in-windows/</guid>
      <description>가이드 텐서플로 GPU는 보통 프로그램처럼 그냥 설치파일 하나로 쉽게 설치하기 어렵다. 이런 저런 문제가 있다면 컴퓨터 자체를 밀고 처음부터 설치하는 게 편하고, 처음 시도한다면 열 번은 밀 각오를 하는 편이 좋다. Step 1. NVIDIA GPU 드라이버 설치 NVIDIA 제어판에서 그래픽사양을 확인하고 알맞는 드라이버를 선택한다. 언어 설정은 한국어로 해도 상관 없을테지만, 이런</description>
    </item>
    
    <item>
      <title>평면곡선의 회전수</title>
      <link>https://freshrimpsushi.github.io/posts/rotation-index-of-plane-curve/</link>
      <pubDate>Sun, 17 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rotation-index-of-plane-curve/</guid>
      <description>빌드업 평면 곡선의 탄젠트가 얼마나 도는지를 논하기 이전에, 알맞는 각도 함수같은 것을 먼저 생각해 보려 한다. 평면에서 수평선(x축)과 점 $p$ 에서 탄젠트 $t$ 로 만들어지는 각의 크기를 $\overline{\theta} (p)$ 와 같이 나타내도록 하자. 문제는 그 값이 $0 \le \overline{\theta} \le 2\pi$ 이므로 $0$ 에서 $\overline{\theta}$ 가 연속이 아니라는 것이다. 이를 극복하기 위해 우리가 고려할 각도 $\theta$ 는 위와 같이 사분면들의 연결</description>
    </item>
    
    <item>
      <title>줄리아에서 shp 파일 읽는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-shp-file-in-julia/</link>
      <pubDate>Fri, 15 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-shp-file-in-julia/</guid>
      <description>코드 위와 같이 XsDB_주거인구_100M_TM.shp라는 shp 파일을 읽어들이는 코드는 다음과 같다. using Shapefile cd(@__DIR__) path = &amp;#34;XsDB_주거인구_100M_TM.shp&amp;#34; table = Shapefile.Table(path) using DataFrames df = DataFrame(table) 물론 파일을 읽어들이는 것만으로는 할 수 있는 것이 제한적이고, 데이터를 살펴보기 위해 데이터프레임으로 변환해줄 필요가 있다. 실행결과</description>
    </item>
    
    <item>
      <title>폐곡선의 회전수</title>
      <link>https://freshrimpsushi.github.io/posts/rotation-index-of-closed-curve/</link>
      <pubDate>Wed, 13 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rotation-index-of-closed-curve/</guid>
      <description>빌드업 평면 곡선의 탄젠트가 얼마나 도는지를 논하기 이전에, 알맞는 각도 함수같은 것을 먼저 생각해 보려 한다. 평면에서 수평선(x축)과 점 $p$ 에서 탄젠트 $t$ 로 만들어지는 각의 크기를 $\overline{\theta} (p)$ 와 같이 나타내도록 하자. 문제는 그 값이 $0 \le \overline{\theta} \le 2\pi$ 이므로 $0$ 에서 $\overline{\theta}$ 가 연속이 아니라는 것이다. 이를 극복하기 위해 우리가 고려할 각도 $\theta$ 는 위와 같이 사분면들의 연결</description>
    </item>
    
    <item>
      <title>줄리아에서 소수점 아래 버리고 정수형으로 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-cast-float-to-int-in-julia/</link>
      <pubDate>Mon, 11 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-cast-float-to-int-in-julia/</guid>
      <description>요약 trunc 함수의 첫번째 인수로써 Int 를 넣으면 된다. 코드 julia&amp;gt; @time for t in 1:10^8 Int64(ceil(t/1000)) end 0.189653 seconds julia&amp;gt; @time for t in 1:10^8 trunc(Int64, ceil(t/1000)) end 0.128472 seconds 두 반복문은 정확히 같은 기능을 하지만 1.5배 정도의 속도차이를 보인다. 위는 ceil로 소수점 아래를 버리고 Int64로 타입 캐스트를 했고, 아래는 trunc 함수의 자체 기능으로써 네이티브하게 정수를 리턴했기 때문에 더 빠르다. 다른 언어를 쓰던 사</description>
    </item>
    
    <item>
      <title>단순 곡선의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-simple-curve/</link>
      <pubDate>Sat, 09 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-simple-curve/</guid>
      <description>정의 1 정칙 곡선 $\beta(t)$ 가 단순Simple하다는 것은 $\beta$ 가 단사 함수거나 어떤 정수 $n \in \mathbb{Z}$ 에 대해 다음을 만족하는 주기 $a &amp;gt; 0$ 의 폐곡선인 것이다. $$ \beta \left( t_{1} \right) = \beta \left( t_{2} \right) \iff t_{1} - t_{2} = na $$ 예시 위와 같이 단사함수로 표현할 수 있는 경우가 아닌데 단순곡선이라는 것은 와 같이 폐곡선이며 꼬인 부분이 없어야만 한다. 꼬인 부분이 있으면 그 점에서 수식 조건을 만족시</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터프레임의 열 이름 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-column-name-of-dataframe-in-julia/</link>
      <pubDate>Thu, 07 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-column-name-of-dataframe-in-julia/</guid>
      <description>개요 rename!() 함수로 바꾸면 된다. 1 문자열의 리스트를 줘서 한번에 바꾸는 방법도 있고, 개별적으로 바꾸는 방법도 있다. 코드 using DataFrames df = DataFrame(rand(1:9, 10, 3), :auto) rename!(df, [&amp;#34;X&amp;#34;, &amp;#34;Y&amp;#34;, &amp;#34;Z&amp;#34;]) rename!(df, :X =&amp;gt; :A) 실행 시키면 가장 먼저 다음과 같은 데이터 프레임이 생성된다. julia&amp;gt; df = DataFrame(rand(1:9, 10, 3), :auto) 10×3 DataFrame Row │ x1 x2 x3 │ Int64 Int64 Int64 ─────┼───────────────────── 1 │ 2 3 6 2 │ 9 2</description>
    </item>
    
    <item>
      <title>폐곡선의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-closed-curve/</link>
      <pubDate>Tue, 05 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-closed-curve/</guid>
      <description>정의 1 정칙 곡선 $\beta(t)$ 가 폐곡선Closed Curve이라는 것은 $\beta$ 주기 함수인 것과 동치다. 공식: 폐곡선의 길이 $\alpha(s)$ 가 주기 $a&amp;gt;0$ 인 폐곡선 $\beta(t)$ 에 대한 현의 길이 재매개변수화라고 하면, $\alpha$ 는 주기 $L = \int_{0}^{a} |d \beta / dt| dt$ 를 가지는 페곡선이다. 다시 말해, 폐곡선 $\beta$ 의 길이는 $L$ 이다. 유도 $$ \begin{align*} s(t+a) =&amp;amp; \int_{0}^{t+a}\left|\frac{d \beta}{d t}\right| d t \\ =&amp;amp; \int_{0}^{a}\left|\frac{d \beta}{d t}\right| d t+\int_{a}^{t+a}\left|\frac{d \beta}{d t}\right| d t \\ =&amp;amp; L+\int_{0}^{t}\left|\frac{d \beta}{d t}\right| d t \\ =&amp;amp; L+s(t) \end{align*} $$</description>
    </item>
    
    <item>
      <title>역삼각함수</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-trigonometric-functions/</link>
      <pubDate>Sun, 03 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-trigonometric-functions/</guid>
      <description>정의 삼각함수의 역함수를 역삼각함수라 한다. $$ \begin{align*} \arcsin \theta =&amp;amp; \sin^{-1} \theta \\ \arccos \theta =&amp;amp; \cos^{-1} \theta \\ \arctan \theta =&amp;amp; \tan^{-1} \theta \\ \text{arccot} \theta =&amp;amp; \cot^{-1} \theta \end{align*} $$ 설명 물론 삼각함수 자체가 전단사가 아닌만큼, 이들의 정의역은 보통 $\displaystyle \left[ -\pi , \pi \right]$ 이나 $\displaystyle \left[ -{{\pi}\over{2}} , {{\pi}\over{2}} \right]$ 로 제한되고, 시컨트 $\sec$ 와 코시컨트 $\csc$ 은 따로 역삼각함수를 생각하지 않는다. 프로그래밍에서는 굳이 arc-를 쓰지 않고 아크탄젠트 함수를</description>
    </item>
    
    <item>
      <title>평면곡선의 탄젠트, 노멀, 곡률</title>
      <link>https://freshrimpsushi.github.io/posts/tangent-normal-curvature-of-plane-curve/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tangent-normal-curvature-of-plane-curve/</guid>
      <description>정의 1 단위 스피드 평면 곡선 $\alpha : (a,b) \to \mathbb{R}^{2}$ 가 주어져 있다고 하자. 탄젠트 (벡터 필드)를 $t (s) := \alpha^{\prime} (s)$ 와 같이 정의한다. $\left\{ t(s), n(s) \right\}$ 가 $\mathbb{R}^{2}$ 의 시계반대방향 기저가 되게끔 하는 유일한 벡터 필드 $n(s)$ 를 노멀 (벡터 필드)라 정의한다. 평면 곡률을 $k(s) := \left&amp;lt; t^{\prime}(s) , n (s) \right&amp;gt;$ 와 같이 정의한다. 기초 성질 [1] $$ \begin{align*} \alpha(s) =&amp;amp; \left( x(s) , y(s) \right) \\ t(s) =&amp;amp; \left( x^{\prime}(s) , y^{\prime}(s) \right) \\ n(s) =&amp;amp; \left( -y^{\prime}(s) , x^{\prime}(s) \right) \end{align*} $$ [2] $t(s)$ 가</description>
    </item>
    
    <item>
      <title>QGIS로 shp 파일 열어보는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-open-shp-file-using-qgis/</link>
      <pubDate>Wed, 29 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-open-shp-file-using-qgis/</guid>
      <description>개요 shp 확장자는 Shapefile을 나타낸다. 많은 지리정보 데이터들이 *.shp 파일과 동봉된 *.dbf, *.sbn, *.sbx, *.shx 등의 포맷으로 관리된다. 데이터를 받았을 때 가장 황당한 것은 도대체 이걸 어떻게 보는지 모르기 때문이다. 가이드 Step 1. QGIS 설치 https://qgis.org/ko/site/forusers/download.html QGIS는 GIS(Geographic Information System) 데이터를 조회하고 편집하는 기능을 갖춘 응용소프트웨어다. 위 링크에서 각자 환경에 맞는 인스톨러를 받</description>
    </item>
    
    <item>
      <title>줄리아에서 NearstNeighbors.jl로 빠르게 거리 계산하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-calculate-distance-using-nearstneibors.jl-in-julia/</link>
      <pubDate>Mon, 27 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-calculate-distance-using-nearstneibors.jl-in-julia/</guid>
      <description>개요 $n$ 개의 좌표끼리 거리를 계산하는데, 행렬을 만들 필요까지는 없고 단순히 거리만 계산하면 되는 경우 다차원 탐색에 유리한 자료구조인 k-d 트리1를 사용해 속도를 높일 수 있다. NearestNeighbors.jl에 관련 알고리즘이 모두 구현되어 있으니 공식 깃허브 페이지를 참고하도록 하자. 속도 비교 pairwise() 함수로 거리행렬 계산에 최적화된 기법과</description>
    </item>
    
    <item>
      <title>곡선의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-curve/</link>
      <pubDate>Sat, 25 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-curve/</guid>
      <description>정리 1 $a,b$ 가 $0$ 을 포함하는 구간이라고 하자. 그리고 다음이 성립한다고 하자. (i): $\overline{\kappa}(s) &amp;gt; 0$ 이 $(a,b)$ 에서 $C^{1}$ (ii): $\overline{\tau}(s)$ 가 $(a,b)$ 에서 연속 (iii): $\mathbf{x}_{0}$ 가 $\mathbb{R}^{3}$ 의 고정된 한 점 (iV): $\left\{ D,E,F \right\}$ 가 $\mathbb{R}^{3}$ 의 오른손 방향 정규직교기저 그러면 매개변수가 $\alpha(0)$로부터의 현의 길이이고, 다음을 만족하는 $C^{3}$ 정칙 곡선 $\alpha : (a,b) \to \mathbb{R}^{3}$ 이 유일하게 존재한다: $$ \begin{align*} \alpha (0) =&amp;amp; \left( \mathbf{x}_{0} \right) \\ T(0) =&amp;amp; D \\ N(0) =&amp;amp;</description>
    </item>
    
    <item>
      <title>리눅스에서 스왑 메모리 초기화하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-initialize-swap-memory-in-linux/</link>
      <pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-initialize-swap-memory-in-linux/</guid>
      <description>가이드 sudo swapoff -a sudo swapon -a 메모리가 부족한 문제를 스왑 메모리로 당장은 넘어갈 수 있지만, 관련된 작업이 끝났을 때 스왑 메모리를 비워주지 않으면 매우 버벅이는 현상이 있다. 스왑 메모리를 끌 때는 엔터 한 번에 사라지지 않고 조금씩 줄어드는 게 정상이니 시간이 걸려도 기다리도록 하자. 환경 Ubuntu 20.04 LTS</description>
    </item>
    
    <item>
      <title>재매개변수화와 프레네-세레의 도구</title>
      <link>https://freshrimpsushi.github.io/posts/reparameterization-and-frenet-serret-apparatus/</link>
      <pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reparameterization-and-frenet-serret-apparatus/</guid>
      <description>정의 $\beta : [a,b] \to \mathbb{R}^{3}$ 를 정칙 곡선이라고 하자. 현의 길이 재매개변수화 $t = t(s)$ 는 $s(t) = \int_{a}^{t} \left| \beta^{\prime}(t) \right| dt$ 을 만족하고, 단위 스피드 커브 $\alpha(s) := \beta \left( t (s) \right)$ 의 프레네-세레 도구 $$ \left\{ \kappa_{\alpha} \left( s(t) \right), \tau_{\alpha} \left( s(t) \right) , T_{\alpha} \left( s(t) \right) , N_{\alpha} \left( s(t) \right), B_{\alpha} \left( s(t) \right) \right\} $$ 를 $\beta$ 의 프레네-세레 도구라 정의한다. 설명 프레네-세레 도구의 정의를 정칙 곡선에 대해 일반화했다. 이는 수학 전반에서 흔히 쓰는</description>
    </item>
    
    <item>
      <title>네이만 인수분해 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-neyman-factorization-theorem/</link>
      <pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-neyman-factorization-theorem/</guid>
      <description>정리 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 이 모수 $\theta \in \Theta$ 에 대해 같은 확률질량/밀도함수 $f \left( x ; \theta \right)$ 를 가진다고 하자. 통계량 $Y = u_{1} \left( X_{1} , \cdots , X_{n} \right)$ 이 $\theta$ 의 충분통계량인 것은 다음을 만족하는 음이 아닌 두 함수 $k_{1} , k_{2} \ge 0$ 이 존재하는 것이다. $$ f \left( x_{1} ; \theta \right) \cdots f \left( x_{n} ; \theta \right) = k_{1} \left[ u_{1} \left( x_{1} , \cdots , x_{n} \right) ; \theta \right] k_{2} \left( x_{1} , \cdots , x_{n} \right) $$ 단, $k_{2}$ 는 $\theta$ 에 종속되지 않아야한다.</description>
    </item>
    
    <item>
      <title>구면에 놓이는 곡선에 대한 공식</title>
      <link>https://freshrimpsushi.github.io/posts/formula-for-curve-lies-on-sphere/</link>
      <pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/formula-for-curve-lies-on-sphere/</guid>
      <description>공식 1 단위 스피드 커브 $\alpha : I \to \mathbb{R}^{3}$ 이 중심 $m$ 에 반지름 $r$ 인 구면 위에 놓인다고 하자. 즉 $$ \alpha(I) \subset S_{r,m} = \left\{ x \in \mathbb{R}^{3} : \left&amp;lt; x - m , x - m \right&amp;gt; = r^{2} \right\} $$ 이라고 하면 $\kappa \ne 0$ 이다. 만약 $\tau \ne 0$ 면 $\rho = 1/\kappa$ 와 $\sigma = 1 / \tau$ 에 대해 $$ \alpha - m = - \rho N - \rho^{\prime} \sigma B $$ 이고, 반지름에 대해 정리하면 $$ r^{2} = \rho^{2} + \left( \rho^{\prime} \sigma \right)^{2} $$ 유도 보조정리: $n$차원 내적공간 $V$ 에서 $E = \left\{ e_{1} , \cdots</description>
    </item>
    
    <item>
      <title>복소함수의 적분</title>
      <link>https://freshrimpsushi.github.io/posts/integral-of-complex-function/</link>
      <pubDate>Wed, 15 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integral-of-complex-function/</guid>
      <description>정의 1 $$ g(t) := p(t) + i q(t) \qquad , t \in [a,b] $$ 실함수 $p, q : [a,b] \to \mathbb{R}$ 에 대해 복소함수 $g : [a,b] \to \mathbb{C}$ 가 위와 같이 나타난다고 하자. 구간 $[a,b]$ 에서 $g$ 의 정적분은 다음과 같이 정의된다. $$ \int_{a}^{b} g(t) dt = \int_{a}^{b} p(t) dt + i \int_{a}^{b} q(t) dt $$ $t \in [a,b]$ 에 대해 경로 $\mathscr{C} : z(t) = x(t) + i y(t)$ 을 따르는 복소경로적분을 다음과 같이 정의한다. $$ \int_{\mathscr{C}} f(z) dz = \int_{a}^{b} f \left( z(t) \right) z&amp;rsquo;(t) dt $$ 설명 호Arc 혹은 커브Curve</description>
    </item>
    
    <item>
      <title>접평면과 법평면</title>
      <link>https://freshrimpsushi.github.io/posts/osculating-plane-and-normal-plane/</link>
      <pubDate>Mon, 13 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/osculating-plane-and-normal-plane/</guid>
      <description>정의 1 곡선 $\alpha$ 가 주어져 있다고 하자. $B$ 에 수직인 평면 $\text{span} \left\{ T, N \right\}$ 을 접평면Osculating Plane이라 한다. $T$ 에 수직인 평면 $\text{span} \left\{ N, B \right\}$ 을 법평면Normal Plane이라 한다. $N$ 에 수직인 평면 $\text{span} \left\{ B, T \right\}$ 을 전직평면Rectifying Plane이라 한다. $T,N,B$ 은 각각 탄젠트, 노멀, 바이노멀을 나타낸다. $\text{span}$ 은 벡터로 생성되</description>
    </item>
    
    <item>
      <title>복소해석에서의 영점</title>
      <link>https://freshrimpsushi.github.io/posts/zero-in-complex-analysis/</link>
      <pubDate>Sat, 11 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zero-in-complex-analysis/</guid>
      <description>정의 1 $\alpha$ 가 함수 $f$ 의 $n$차 영점Zero of Order $n$이라는 것은 $\displaystyle \lim_{z \to \alpha} g(z) \ne 0$ 인 어떤 함수 $g$ 에 대해 $f$ 가 다음과 같이 나타날 수 있다는 것과 동치다. $$ f(z) = (z-\alpha)^{n} g(z) $$ 정리 영점은 고립점이다. 증명 일반성을 잃지 않고, $g$ 가 $f$ 의 영점 $\alpha$ 에서 해석적이라고 가정하고 $g(\alpha) = 2 \beta \ne 0$ 라 적자. $g$ 가 $\alpha$ 에서 연속이므로 모든 $\beta$ 에 대해 다음을 만족하는 $\delta &amp;gt; 0$ 가 존</description>
    </item>
    
    <item>
      <title>랑크레 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lancret-theorem/</link>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lancret-theorem/</guid>
      <description>정리 1 $\kappa \ne 0$ 인 단위 스피드 커브 $\alpha$ 가 나선인 것은 어떤 상수 $c \in \mathbb{R}$ 에 대해 $\tau = c \kappa$ 인 것과 동치다. $\tau, \kappa$ 는 토션, 곡률이다. 증명 나선의 정의: 정칙 곡선 $\alpha$ 가 어떤 픽스된 단위 벡터 $\mathbf{u}$ 에 대해 $\left&amp;lt; T, \mathbf{u} \right&amp;gt;$ 가 상수면 나선Helix이라 하고, $\mathbf{u}$ 를 축Axis라 부른다. 보조정리: $n$차원 내적공간 $V$ 에서 $E = \left\{ e_{1} , \cdots , e_{n} \right\}$ 이 직교 집합이라고 하면 $E$ 는</description>
    </item>
    
    <item>
      <title>조화 함수</title>
      <link>https://freshrimpsushi.github.io/posts/harmonic-function/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/harmonic-function/</guid>
      <description>정의 1 함수 $\phi(x,y)$ 가 영역 $\mathscr{R}$ 에서 연속이계도함수를 가지며 라플라스 방정식의 솔루션이면 하모닉Harmonic하다고 말한다. 다시 말해, 하모닉 함수는 다음을 만족하는 함수다. $$ \Delta \phi = \nabla^{2} \phi = \phi_{xx} + \phi_{yy} = 0 $$ 특히 함수 $u(x,y), v(x,y)$ 가 하모닉하면서 $u,v$ 가 코시-리만 방정식을 만족시키면 $v(x,y)$ 가 $u(x,y)$ 의 하모닉 컨쥬게이트Conjugate라고 한다. $$ \begin{cases} u_{x} (x,y) = v_{y}</description>
    </item>
    
    <item>
      <title>일반적인 나선의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-helix/</link>
      <pubDate>Sun, 05 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-helix/</guid>
      <description>정의 1 정칙 곡선 $\alpha$ 가 어떤 픽스된 단위 벡터 $\mathbf{u}$ 에 대해 $\left&amp;lt; T, \mathbf{u} \right&amp;gt;$ 가 상수면 나선Helix이라 하고, $\mathbf{u}$ 를 축Axis라 부른다. $T$ 는 탄젠트다. $\left&amp;lt; \cdot , \cdot \right&amp;gt;$ 는 내적이다. 설명 정의에 따르면 $\mathbb{R}^{3}$ 에서 $\mathbf{u} = B$ 일 때 항상 $\left&amp;lt; T, \mathbf{u} \right&amp;gt; = 0$ 이므로 평면에 놓이는 모든 정칙 곡선들은 나선이지만, 이는 어디까지나 정의에 불과하고 실제로 이들을 의미 그대로의 &amp;lsqu</description>
    </item>
    
    <item>
      <title>복소함수의 극한</title>
      <link>https://freshrimpsushi.github.io/posts/limit-of-complex-valued-function/</link>
      <pubDate>Fri, 03 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-of-complex-valued-function/</guid>
      <description>정의 1 $f$ 가 오픈셋 $A \subset \mathbb{C}$ 에서 정의된 복소함수 $f : A \to \mathbb{C}$ 이고 $\alpha \in \overline{A}$ 라 하자. $f(z)$ 가 $z \to \alpha$ 일 때 극한Limit $l$ 로 수렴한다는 것은 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ 0 &amp;lt; \left| z - \alpha \right| &amp;lt; \delta \implies \left| f(z) - l \right| &amp;lt; \varepsilon $$ 를 만족시키는 $\delta &amp;gt; 0$ 가 존재한다는 것과 동치고, 다음과 같이 나타낸다. $$ \lim_{z \to \alpha} f(z) = l $$ 성질 $\lim_{z \to \alpha} f(z)$ 와 $\lim_{z \to \alpha} g(z)$ 가 존재한다고 하자. 유일성: $\displaystyle \lim_{z \to</description>
    </item>
    
    <item>
      <title>3차원 유클리드 공간에서 곡선이 평면 속에 놓이는 동치조건</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-conditions-for-curve-lying-on-plane/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-conditions-for-curve-lying-on-plane/</guid>
      <description>정리 1 $\kappa \ne 0$ 인 단위 스피드 커브 $\alpha : I \to \mathbb{R}^{3}$ 에 대해 다음 세가지는 동치다. (a): $\alpha$ 는 평면에 놓이는 커브다. (b): $B$ 는 상수다. (c): $\tau = 0$ 이다. 설명 이는 프레네-세레 공식의 따름 정리로써, 토션이 왜 $\tau := \left&amp;lt; B^{\prime}, N \right&amp;gt;$ 과 같이 기괴하게 정의되었는지 알 수 있다. 증명 프레네-세레 공식: $\alpha$ 가 $\kappa(s) \ne 0$ 인 단위 스피드 커브라고 하면 $$ \begin{align*} T^{\prime}(s) =&amp;amp; \kappa(s) N(s) \\ N^{\prime}(s) =&amp;amp; - \kappa (s) T(s) + \tau</description>
    </item>
    
    <item>
      <title>페이즈 포트레이트</title>
      <link>https://freshrimpsushi.github.io/posts/phase-portrait/</link>
      <pubDate>Mon, 30 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/phase-portrait/</guid>
      <description>정의 1 $$ O \left( x_{0} \right) := \left\{ x \in X : x = \varphi^{t} x_{0} , \forall t \in T \right\} $$ 동역학계 $\left( T, X, \varphi^{t} \right)$ 에서 $x_{0} \in X$ 의 오빗Orbit을 위와 같이 나타낸다고 하자. 오빗들로 이루어진 $X$ 의 분할을 동역학계의 페이즈 포트레이트Phase Portrait라 한다. 설명 Phase Portrait를 어거지로 번역하면 위상 초상 정도가 될 수 있겠으나 의미전달이 안 되고 용례가 없어도</description>
    </item>
    
    <item>
      <title>줄리아에서 2차원 배열 csv 파일로 출력하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-export-2d-array-as-csv-file-in-julia/</link>
      <pubDate>Sat, 28 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-export-2d-array-as-csv-file-in-julia/</guid>
      <description>코드 using CSV, DataFrames A = rand(1:10, 10) B = zeros(10) AB = DataFrame(hcat(A,B), [&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;]) CSV.write(&amp;#34;AB.csv&amp;#34;, AB) CSV 패키지의 write 함수를 통해 간단하게 2차원 배열을 출력할 수 있다. A, B는 1차원 배열로, hcat 함수로 묶어 데이터프레임으로 변환시켰다. 실행결과 julia&amp;gt; using CSV, DataFrames julia&amp;gt; A = rand(1:10, 10) 10-element Array{Int64,1}: 8 5 4 3 6 4 10 6 2 9 julia&amp;gt; B = zeros(10) 10-element Array{Float64,1}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 julia&amp;gt; AB = DataFrame(hcat(A,B), [&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;]) 10×2 DataFrame Row │ A B │ Float64 Float64 ─────┼────────</description>
    </item>
    
    <item>
      <title>프레네-세레 공식</title>
      <link>https://freshrimpsushi.github.io/posts/frenet-serret-formula/</link>
      <pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/frenet-serret-formula/</guid>
      <description>공식 1 $\alpha$ 가 $\kappa(s) \ne 0$ 인 단위 스피드 커브라고 하면 $$ \begin{align*} T^{\prime}(s) =&amp;amp; \kappa(s) N(s) \\ N^{\prime}(s) =&amp;amp; - \kappa (s) T(s) + \tau (s) B(s) \\ B^{\prime}(s) =&amp;amp; - \tau(s) N(s) \end{align*} $$ 설명 행렬 폼으로 나타내면 다음과 같다. $$ \begin{bmatrix} T \\ N \\ B \end{bmatrix} ^{\prime} = \begin{bmatrix} 0 &amp;amp; \kappa &amp;amp; 0 \\ - \kappa &amp;amp; 0 &amp;amp; \tau \\ 0 &amp;amp; - \tau &amp;amp; 0 \end{bmatrix} \begin{bmatrix} T \\ N \\ B \end{bmatrix} $$ 유도 보조정리: $n$차원 내적공간 $V$ 에서 $E = \left\{ e_{1} , \cdots , e_{n} \right\}$ 이 직교 집합이라고 하면 $E$ 는 $V$ 의 기저고, 모든 $v</description>
    </item>
    
    <item>
      <title>동역학계의 엄밀한 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-dynamic-system/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-dynamic-system/</guid>
      <description>정의 1 (상태) 공간 $X$ 와 시점 $t \in T$ 에 대해 오퍼레이터 $\varphi^{t}$ 를 플로우Flow라 한다. 플로우의 집합 $F := \left\{ \varphi^{t} \right\}_{t \in T}$ 이 함수합성 연산 $\circ$ 에 대해 $\left( F , \circ \right)$ 가 다음을 만족시키는 그룹이면 트리플 $\left( T, X, \varphi^{t} \right)$ 를 동역학계Dynamic System라 한다. $$ \begin{align*} \varphi^{0} =&amp;amp; \text{id} \\ \varphi^{t+s} =&amp;amp; \varphi^{t} \circ \varphi^{s} \end{align*} $$ 설명 주로 $T = \mathbb{Z}$ 일 때는 맵, $T = \mathbb{R}$ 일 때는 미분방정식으로 표현될</description>
    </item>
    
    <item>
      <title>프레네-세레의 도구: 곡률, 접선, 법선, 종법선, 비틀림</title>
      <link>https://freshrimpsushi.github.io/posts/frenet-serret-apparatus/</link>
      <pubDate>Sun, 22 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/frenet-serret-apparatus/</guid>
      <description>정의 1 $\alpha$ 가 단위 스피드 커브라고 하자. 탄젠트 $T(s) = \alpha^{\prime} (s)$ 의 스피드speed, 속력 $\kappa (s) := \left| T^{\prime}(s) \right|$ 를 $\alpha (s)$ 의 곡률Curvature이라 한다. $\alpha$ 의 탄젠트의 속도velocity $T^{\prime}(s)$ 를 곡률 $\kappa (s)$ 로 나눈 함수, 즉 다음과 같이 정의된 $N$ 을 노멀Normal 벡터 필드라고 한다. $$ N(s) := {{ T^{\prime}(s) } \over { \left| T^{\prime}(s) \right| }} = {{ T^{\prime}(s) } \over { \kappa (s) }} \qquad , \kappa(s) \ne 0 $$ 다음과 같이</description>
    </item>
    
    <item>
      <title>현의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-chord/</link>
      <pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-chord/</guid>
      <description>정의 1 곡선 $\alpha : (c,d) \to \mathbb{R}^{3}$ 가 주어져 있다고 하자. $c &amp;lt; a &amp;lt; b &amp;lt; d$ 일 때, 모든 $t \in [a,b]$ 에 대해 $\alpha(t) = \gamma(t)$ 를 만족하는 $\gamma : [a,b] \to \mathbb{R}^{3}$ 를 현Chord 혹은 곡선분Curve Segment라 한다. 현 $\gamma : [a,b] \to \mathbb{R}^{3}$ 의 길이 $l_{[a,b]}(\gamma)$ 를 다음과 같이 정의한다. $$ l_{[a,b]}(\gamma) := \int_{a}^{b} \left| {{ d \gamma } \over { d t }} \right| dt $$ 다음과 같이 정의된 $s = h(t)$ 를 $\alpha$ 에 따른 호의 길이Length of Arc라고 한</description>
    </item>
    
    <item>
      <title>접선과 탄젠트 벡터 필드</title>
      <link>https://freshrimpsushi.github.io/posts/tangent-line-and-tangent-vector-field/</link>
      <pubDate>Sat, 14 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tangent-line-and-tangent-vector-field/</guid>
      <description>정의 정칙 곡선 $\alpha(t)$ 이 주어져 있다고 하자. 벡터 필드 $\displaystyle T(t) := {{ d \alpha / d t } \over { \left| d \alpha / d t \right| }}$ 를 탄젠트 벡터 필드Tangent Vector Field라 한다. 다음과 같이 정의된 직선 $l$ 을 $t = t_{0}$ 에서 $\alpha$ 의 접선Tangent Line이라 한다. $$ l := \left\{ \mathbf{w} \in \mathbb{R}^{3} : \mathbf{w} = \alpha \left( t_{0} \right) + \lambda T \left( t_{0} \right) , \lambda \in \mathbb{R} \right\} $$ 설명 탄젠트 벡터 필드는 미분기하학에서 대단히 중</description>
    </item>
    
    <item>
      <title>줄리아 변수 이름에 그리스 문자, 첨자 쓰는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-greek-alphabet-and-subscript-in-julia-variable/</link>
      <pubDate>Thu, 12 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-greek-alphabet-and-subscript-in-julia-variable/</guid>
      <description>개요 줄리아에서는 변수 이름으로 유니코드(UTF-8)을 허용한다. 따라서 그리스 문자는 물론 윗첨자, 아랫첨자, 심지어는 한글이나 이모지까지 쓸 수 있다. 굳이 쓸 필요는 없지만 다음과 같이 기괴한 코드도 잘 돌아간다. julia&amp;gt; α₁ = 2 2 julia&amp;gt; α₂ = 1 1 julia&amp;gt; println(α₁ \ast\ α₂) 2 julia&amp;gt; 사인(t) = sin(t) 사인 (generic function with 1 method) julia&amp;gt; 😂 = 1:20 1:20 julia&amp;gt; 사인.(😂)</description>
    </item>
    
    <item>
      <title>재매개변수화</title>
      <link>https://freshrimpsushi.github.io/posts/reparametrization/</link>
      <pubDate>Tue, 10 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reparametrization/</guid>
      <description>정의 1 곡선 $\alpha : (a,b) \to \mathbb{R}^{3}$ 가 주어져 있다고 하자. 전단사 $g: (c,d) \to (a,b)$ 가 $g , g^{-1} \in C^{k}$ 를 만족하면 $g$ 를 $\alpha$ 의 재매개변수화Reparametrization라고 한다. $C^{k}$ 는 $k$ 번 미분가능하고 그 도함수가 연속함수인 함수들의 집합이다. 설명 곡선 $\alpha$ 를 $\alpha(t)$ 와 같이 매개변수로 나타낸 것처럼 $\beta (t) = \alpha \left( g (t) \right)$ 를 생각하는 것 자체가 재매개변수화다. 수학적으로</description>
    </item>
    
    <item>
      <title>로그 함수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-log-function/</link>
      <pubDate>Sun, 08 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-log-function/</guid>
      <description>정의 지수 함수의 역함수 를 로그 함수 $\log : (0,\infty) \to \mathbb{R}$ 라 정의한다. 만약 모든 $x \in (0,\infty)$ 에 대해 $x = e^y$ 면 로그 함수는 다음과 같이 나타난다. $$ \log x := y(x) $$ 설명 로그는 간단한 정의와 달리 수학 전반에서 무척 많은 의미를 지닌다. 밑Base은 양수라면 무엇이든 상관 없지만, 보통은 위의 정의와 같이 오일러 상수 $e$ 로 두는 편이다. 교과과정 및 공학에서는 밑이 $10$</description>
    </item>
    
    <item>
      <title>곡선의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-curve/</link>
      <pubDate>Fri, 06 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-curve/</guid>
      <description>정의 1 사상 $\alpha : (a,b) \to \mathbb{R}^{3}$ 을 곡선Curve이라고 한다. 곡선에서 $\alpha^{\prime} = \dfrac{d \alpha}{d t} = \mathbf{0}$ 인 점 $t = t_{0}$ 을 특이점Singular Point라 한다. 어떤 $k \in \mathbb{N}$ 에 대해 모든 $t \in (a,b)$ 에서 $\displaystyle {{ d \alpha } \over { d t }} \ne \mathbf{0}$ 인 곡선 $\alpha \in C^{k}$ 을 정칙 곡선Regular Curve이라 한다. 다시 말해, 정칙 곡선은 특이점이 없는 곡선이다. 곡선 $\alpha$의 $t</description>
    </item>
    
    <item>
      <title>충분통계량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistiic/</link>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistiic/</guid>
      <description>정의 수식적인 정의 1 모수 $\theta \in \Theta$ 에 대해 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 의 확률질량/밀도함수를 $f(x;\theta)$, 통계량 $Y_{1} := u_{1} \left( X_{1} , \cdots , X_{n} \right)$ 의 확률질량/밀도함수를 $f_{Y_{1}} \left( y_{1}; \theta \right)$ 이라 하자. $\theta \in \Theta$ 에 종속되지 않은 $H \left( x_{1} , \cdots , x_{n} \right)$ 에 대해 $$ {{ f \left( x_{1} ; \theta \right) \cdots f \left( x_{n} ; \theta \right) } \over { f_{Y_{1}} \left( u_{1} \left( x_{1} , \cdots, x_{n} \right) ; \theta \right) }} = H \left( x_{1} , \cdots , x_{n} \right) $$ 이면 $Y_{1}$ 을 $\theta$ 에 대한 충분통계량Suf</description>
    </item>
    
    <item>
      <title>지수 함수</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-exponential-function/</link>
      <pubDate>Mon, 02 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-exponential-function/</guid>
      <description>개요 지수 함수Exponential Function는 거듭 제곱의 일반화로써, 수학 전반에서 분과를 가리지 않고 등장한다. 원래 거듭제곱에서 밑 $a &amp;gt; 0$ 은 반드시 $a = e$ 일 필요는 없으나, 밑변환 공식이 있어 어떤게 두든지도 본질적으로 상관 없다. 편의상 지수 함수라 하면 그 밑은 다음과 같이 $e$ 로 본다. 정의 1 $x, y \in \mathbb{R}$ 이라고 할 때, 복소수 $z \in \mathbb{C}$</description>
    </item>
    
    <item>
      <title>효율적추정량</title>
      <link>https://freshrimpsushi.github.io/posts/efficient-estimator/</link>
      <pubDate>Sat, 31 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/efficient-estimator/</guid>
      <description>정의 1 $Y$ 가 모수 $\theta$ 에 대한 불편추정량이라고 하자. 라오-크래머 하한 $\text{RC}$ 에 대해 다음을 추정량 $Y$ 의 효율성Efficiency이라고 한다. $$ {{ \text{RC} } \over { \text{Var} (Y) }} $$ 효율성이 $1$ 인 추정량을 효율적추정량Efficient Estimator이라고 한다. 설명 라오-크래머 부등식: $$ \text{Var} (Y) \ge {{ \left[ k&amp;rsquo;(\theta) \right]^{2} } \over { n I (\theta) }} = \text{RC} $$ 위 부등식에 따라 효율</description>
    </item>
    
    <item>
      <title>다항 함수</title>
      <link>https://freshrimpsushi.github.io/posts/polynomial-function/</link>
      <pubDate>Thu, 29 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/polynomial-function/</guid>
      <description>정의 1 $n \in \mathbb{N}_{0}$ 과 $\left\{ a_{k} \right\}_{k=0}^{n} \subset \mathbb{C}$ 에 대해 다음과 같이 정의된 $P: \mathbb{C} \to \mathbb{C}$ 를 $n$차 다항 함수Polynomial of degree $n$라 한다. $$ P(z) := a_{0} + a_{1} z + \cdots a_{n} z^{n} \qquad , a_{n} \ne 0 $$ 설명 다항 함수는 수학 전반에서 가장 쉽게 생각할 수 있는 함수로써, 대수학의 기본정리에 의해 근이 정확히 $n$ 개 존재함이 밝혀져있다. 정의에서 상수함수 역시 다항함수다. 다항함수는 무</description>
    </item>
    
    <item>
      <title>라오-크래머 하한</title>
      <link>https://freshrimpsushi.github.io/posts/rao-cramer-lower-bound/</link>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rao-cramer-lower-bound/</guid>
      <description>정리 1 정칙조건: (R0): 확률밀도함수 $f$ 는 $\theta$ 에 대해 단사다. 수식으로는 다음을 만족시킨다. $$ \theta \ne \theta&amp;rsquo; \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta&amp;rsquo; \right) $$ (R1): 확률밀도함수 $f$ 는 모든 $\theta$ 에 대해 같은 서포트를 가진다. (R2): 참값 $\theta_{0}$ 는 $\Omega$ 의 내점Interior Point이다. (R3): 확률밀도함수 $f$ 는 $\theta$ 에 대해 두 번 미분가능하다. (R4): 적분 $\int f (x; \theta) dx$ 은 적분 기호를 넘나들며 $\theta$ 에</description>
    </item>
    
    <item>
      <title>삼각함수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-trigonometric-functions/</link>
      <pubDate>Sun, 25 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-trigonometric-functions/</guid>
      <description>개요 삼각함수는 직각삼각형의 밑각에 삼각비를 대응시킨 함수다. 정의 삼각함수 사인, 코사인 $\sin, \cos : \mathbb{R} \to \mathbb{R}$ 는 다음과 같이 정의된다. $$ \sin \theta := {{ y } \over { \sqrt{x^{2} + y^{2}} }} \\ \cos \theta := {{ y } \over { \sqrt{x^{2} + y^{2}} }} $$ 이에 따라 시컨트, 코시컨트, 탄젠트, 코탄젠트를 다음과 같이 정의한다. $$ \begin{align*} \tan \theta &amp;amp;:= {{ \sin \theta } \over { \cos \theta }} \qquad, \cos \theta \ne 0 \\ \cot \theta &amp;amp;:= {{ \cos \theta } \over { \sin \theta }} \qquad, \sin</description>
    </item>
    
    <item>
      <title>바틀렛 항등식</title>
      <link>https://freshrimpsushi.github.io/posts/bartlett-identity/</link>
      <pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bartlett-identity/</guid>
      <description>정리 정칙조건: (R0): 확률밀도함수 $f$ 는 $\theta$ 에 대해 단사다. 수식으로는 다음을 만족시킨다. $$ \theta \ne \theta&amp;rsquo; \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta&amp;rsquo; \right) $$ (R1): 확률밀도함수 $f$ 는 모든 $\theta$ 에 대해 같은 서포트를 가진다. (R2): 참값 $\theta_{0}$ 는 $\Omega$ 의 내점Interior Point이다. (R3): 확률밀도함수 $f$ 는 $\theta$ 에 대해 두 번 미분가능하다. (R4): 적분 $\int f (x; \theta) dx$ 은 적분 기호를 넘나들며 $\theta$ 에 대</description>
    </item>
    
    <item>
      <title>수학에서의 질량 작용 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/law-of-mass-action/</link>
      <pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/law-of-mass-action/</guid>
      <description>법칙 1 화학반응의 정도는 반응에 관여하는 각종 분자수에 같은 힘을 야기하는 물질의 농도에 비례한다. 설명 2 수리적 모델링에서 질량 작용 법칙Law of Mass Action은 법칙이라는 이름이 무색하지 않을만큼 일상적으로 사용된다. 가령 두가지 물질 $A$, $B$ 가 만나 $k$ 만큼의 반응속도로 작용해 $C$ 가 생겨난다고 생각해보자. $$ A + B \overset{k}{\to} C $$ 질량 작용 법칙에 따</description>
    </item>
    
    <item>
      <title>생존 함수</title>
      <link>https://freshrimpsushi.github.io/posts/survival-function/</link>
      <pubDate>Mon, 19 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/survival-function/</guid>
      <description>정의 1 $S(0)=1$ 이면서 증가하지 않는 함수 $S : [0,\infty) \to [0,1]$ 를 생존 함수Survival Function라 정의한다. 설명 생존 함수란 쉽게 말해 시간 $t$ 에 생존해있을 확률 $S(t) \in [0,1]$ 을 매핑하는 함수다. 수학에서 생존이란 딱히 &amp;lsquo;살아있다&amp;rsquo;는 의미에 집착할 필요 없이 어떠한 사건이 일어날 때까지의 기간으로 추상화되며, 확률에 대한 맵핑</description>
    </item>
    
    <item>
      <title>에이즈 전염 모델</title>
      <link>https://freshrimpsushi.github.io/posts/aids-infection-model/</link>
      <pubDate>Sat, 17 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/aids-infection-model/</guid>
      <description>개요 에이즈AIDS, 후천면역결핍증후군은 바이러스인 HIV에 의해 발병하며 수십년간 인류를 괴롭혀오고 있는 전염병이다. 에이즈의 전파 경로는 동성애, 이성애, 약물 사용 등으로 다양하며 그에 대한 수학적 모델링은 전체 인구의 구조를 포함하지 않을 수가 없다. 그러나 우선은 가장 단순하게 카스티요Castillo, 카베즈Chavez 등에 의</description>
    </item>
    
    <item>
      <title>복소수의 극좌표 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/polar-representation-of-complex-number/</link>
      <pubDate>Thu, 15 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/polar-representation-of-complex-number/</guid>
      <description>정의 1 복소수 $z \ne 0$ 는 복소평면 상의 점 $P(x,y)$ 에 대응되며, 선분 $\overline{OP}$ 의 길이 $r := |z|$ 와 $x$ 축과 $\overline{OP}$ 가 만드는 시계반대방향의 각 $\theta$ 을 통해 다음과 같이 극좌표 표기Polar Representation를 할 수 있다. $$ z = r \left( \cos \theta + i \sin \theta \right) $$ 이 때 $\theta$ 를 편각Argument이라 부르며 $\theta = \arg z$ 와 같이 나타낸다. 하나의 복소수에는 무수히 많은 편각 $\theta +</description>
    </item>
    
    <item>
      <title>주기 함수</title>
      <link>https://freshrimpsushi.github.io/posts/periodic-function/</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/periodic-function/</guid>
      <description>정의 함수 $f : \mathbb{R} \to \mathbb{R}$ 이 어떤 상수 $T \ne 0$ 와 모든 $t \in \mathbb{R}$ 에 대해 다음을 만족하면 $T$-주기 함수$T$-periodic function라 한다. $$ f(t + T) = f(t) $$ 예시 사인 $\sin$ 과 코사인 $\cos$ 은 대표적인 주기 함수로써, 위 정의에 따라 $2\pi$-주기 함수다.</description>
    </item>
    
    <item>
      <title>깁스 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/gibbs-inequality/</link>
      <pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gibbs-inequality/</guid>
      <description>개요 깁스 부등식Gibbs Inequality은 샤넌 엔트로피와 크로스 엔트로피 사이의 관계를 말해주며, 쿨백-라이블러 발산의 하한을 보장해주는 부등식이다. 정리 $$ H(P) \le H(P,Q) $$ 증명 1 이산형에 대한 경우만 증명하고, 모든 $k$ 에 대해 $p_{k} &amp;gt; 0$ 이라 가정한다. 곡선 $y = \ln x$ 의 $x=1$ 에서의 접선의 방정식은 $y = x - 1$ 이다. 로그함수는 위로 볼록한 함수</description>
    </item>
    
    <item>
      <title>함수로써의 대각행렬, 대각성분</title>
      <link>https://freshrimpsushi.github.io/posts/diagonal-as-function/</link>
      <pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diagonal-as-function/</guid>
      <description>정의 대각성분 행렬에 대한 $\text{diag} : \mathbb{R}^{n \times n} \to \mathbb{R}^{n}$ 는 다음과 같이 행렬의 대각 성분으로 이루어진 벡터를 의미한다. $$ \text{diag} A = \begin{bmatrix} A_{11} \\ A_{22} \\ \vdots \\ A_{nn} \end{bmatrix} $$ 대각행렬 벡터에 대한 $\text{diag} : \mathbb{R}^{n} \to \mathbb{R}^{n \times n}$ 는 다음과 같이 벡터를 대각성분으로 갖는 행렬을 의미한다. $$ \text{diag} \begin{bmatrix} x_{1} \\ x_{2} \\ \vdots \\ x_{n} \end{bmatrix} = \begin{bmatrix} x_{1} &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; x_{2} &amp;amp; \cdots &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; x_{n} \end{bmatrix} $$ 설명 대각</description>
    </item>
    
    <item>
      <title>상대적 엔트로피, 쿨백-라이블러 발산</title>
      <link>https://freshrimpsushi.github.io/posts/relative-entropy-kullback-leibler-divergence/</link>
      <pubDate>Wed, 07 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relative-entropy-kullback-leibler-divergence/</guid>
      <description>빌드업 두 확률분포 $P$ 와 $Q$ 가 있을 때, 이 둘이 얼마나 다른지 궁금할 상황은 얼마든지 쉽게 상상해볼 수 있다. 가령 카메라에 찍힌 숫자가 정확히 어떤 숫자인지에 대해 맞추는 상황을 생각해보자. 숫자 6과 9는 위아래를 정확히 표시하지 않으면 사람도 충분히 헷갈릴만한데, 9에서 아래로 획을 긋는 사람이 있고 아닌 사람이 있으니 수많은 사람들의 필체 데이터를 모</description>
    </item>
    
    <item>
      <title>복소수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-complex-number/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-complex-number/</guid>
      <description>정의 1 이차방정식 $x^{2} +1 = 0$ 의 해 $x = \sqrt{-1}$ 을 허수Imaginary Number라 한다. 두 실수 $x,y \in \mathbb{R}$ 에 대해 $z = x + iy$ 꼴의 수를 복소수Complex Number라 하고 $(x,y)$ 와 같이 나타내기도 한다. 이 때 $\text{Re} (z) = x$ 와 $\text{Im} (z) = y$ 를 각각 $z$ 의 실수부Real Part와 허수부Imaginary Part라 한다. 모든 복소수의 집합을 $\mathbb{C}$ 로 표기한</description>
    </item>
    
    <item>
      <title>크로스 엔트로피</title>
      <link>https://freshrimpsushi.github.io/posts/cross-entropy/</link>
      <pubDate>Sat, 03 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cross-entropy/</guid>
      <description>개요 크로스 엔트로피Cross Entropy는 두 확률분포를 구분하기 위해 필요한 평균 비트수로써, 보통 참으로 가정되는 (레퍼런스) 확률분포 $p$ 와 이를 추정하기 위한 (예상) 확률분포 $q$ 사이에서 정의된다. 정의 1 이산 두 이산확률분포의 확률질량함수 $p,q$ 가 주어져있다고 하자. 두 확률분포의 크로스 엔트로피 $H (p,q)$ 는 다음과 같이 정의된다. $$ H</description>
    </item>
    
    <item>
      <title>푸앙카레 맵</title>
      <link>https://freshrimpsushi.github.io/posts/poincare-map/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poincare-map/</guid>
      <description>정의 1 유클리드 공간 $\mathbb{R}^{n}$ 와 오픈 셋 $U \subset \mathbb{R}^{n}$ 에서 $r$번 미분가능한 함수 $f : U \to \mathbb{R}^{n}$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 그 플로우를 $\phi_t \left( \cdot \right)$ 와 같이 나타내고 벡터 필드를 가로지르는 $n-1$차원 곡면 $\Sigma$ 를 생각해보자. 오픈 셋 $V \subset \Sigma$ 에 대해 다음과 같은 맵 $P$ 를 푸앙카레 맵Poincaré Map이라 한다.</description>
    </item>
    
    <item>
      <title>조건부 엔트로피</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-entropy/</link>
      <pubDate>Tue, 29 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-entropy/</guid>
      <description>정의 1 확률변수 $X_{1}, \cdots , X_{n}$ 의 결합확률질량함수 $p$ 혹은 결합확률밀도함수 $f$ 가 주어져 있다고 하자. $H \left( X_{1}, \cdots , X_{n} | X_{k} \right)$ 을 $X_{k}$ 가 주어져 있을 때 $X_{1}, \cdots , X_{n}$ 의 조건부 엔트로피Conditional Entropy라 한다. 이산 $$ H \left( X_{1}, \cdots , X_{n} | X_{k} \right) := - \sum_{x_{1}} \cdots \sum_{x_{n}} p \left( x_{1} , \cdots , x_{n} \right) \log_{2} {{ p \left( x_{1} , \cdots , x_{n} \right) } \over { p(x_{k}) }} $$ 연속 $$ H \left( X_{1}, \cdots , X_{n} | X_{k} \right) := - \int_{\mathbb{R}}</description>
    </item>
    
    <item>
      <title>일반적인 직선, 평면, 구의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/general-definition-of-line-plane-sphere/</link>
      <pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-definition-of-line-plane-sphere/</guid>
      <description>정의 1 벡터공간 $X$ 가 주어져 있다고 하자. 다음의 방정식을 만족시키는 점들의 집합 $L \subset X$ 혹은 $\alpha (t)$ 그 자체를 점 $\mathbf{x}_{0} \in X$ 를 지나고 벡터 $\mathbf{v} \ne 0$ 와 평행한 직선Line이라 정의한다. $$ \alpha(t) = \mathbf{x}_{0} + t \mathbf{v} \qquad , t \in \mathbb{R} $$ 다음의 방정식을 만족시키는 점들의 집합 $P \subset X$ 를 점 $\mathbf{x}_{0} \in X$ 를 지나고 벡터 $\mathbf{n} \ne 0$ 에 수직인 평면Plane이라 정의한다. $$ \left&amp;lt; \mathbf{x} - \mathbf{x}_{0} , \mathbf{n} \right&amp;gt; =</description>
    </item>
    
    <item>
      <title>줄리아에서 변수의 값을 편리하게 출력하는 법, 보간법</title>
      <link>https://freshrimpsushi.github.io/posts/interpolation-in-julia/</link>
      <pubDate>Fri, 25 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interpolation-in-julia/</guid>
      <description>개요 줄리아의 편의 기능인 보간법Interpolation에 대해 설명한다. 인터폴레이션을 잘 이용하면 출력문을 쉽고 깔끔하게 쓸 수 있어 아주 편리하다. 수치해석학의 보간법과 관계는 없으나 단어의 의미는 상통한다. 코드 사용법은 아주 간단하다. 다음과 같이 문자열 안에서 변수 앞에 달러 기호 $를 붙이면 변수가 알아서 문자열처럼 읽힌다. 변수 그</description>
    </item>
    
    <item>
      <title>벡터공간에서 정의되는 기저의 방향</title>
      <link>https://freshrimpsushi.github.io/posts/orientation-of-bases-of-vector-space/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orientation-of-bases-of-vector-space/</guid>
      <description>정의 1 $$ U = \left\{ \mathbf{u}_{1}, \cdots, \mathbf{u}_{n} \right\} \\ V = \left\{ \mathbf{v}_{1}, \cdots, \mathbf{v}_{n} \right\} $$ 위의 두 순서 있는 집합 $U,V$ 가 벡터공간 $X$ 의 기저라고 하고 행렬 $\left( a_{ij} \right) \in \mathbb{C}^{n \times n}$ 을 다음 식이 만족되도록 정의하자. $$ \mathbf{v}_{j} = \sum_{i=1}^{n} a_{ij} \mathbf{u}_{i} $$ 이때 $\det \left( a_{ij} \right) &amp;gt; 0$ 이면 $U,V$ 가 같은 방향Orientation이라하고 $\det \left( a_{ij} \right) &amp;lt; 0$ 이면 다른 방향이라 한다. 특히 유클리드 공간 $X = \mathbb{R}^{n}$ 에서는 방향의 이름이 있다. $\mathbb{R}^{2}$ 에서 기저</description>
    </item>
    
    <item>
      <title>천장 함수와 바닥 함수</title>
      <link>https://freshrimpsushi.github.io/posts/ceil-and-floor-function/</link>
      <pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ceil-and-floor-function/</guid>
      <description>정의 1 천장 함수Ceil $\lceil \cdot \rceil : \mathbb{R} \to \mathbb{Z}$ 와 바닥 함수Floor $\lfloor \cdot \rfloor : \mathbb{R} \to \mathbb{Z}$ 는 다음과 같이 정의된다. $$ \lceil x \rceil := \min \left\{ n \in \mathbb{Z} : x \le n \right\} \\ \lfloor x \rfloor := \max \left\{ n \in \mathbb{Z} : n \le x \right\} $$ 설명 국내에서는 바닥 함수 $\lfloor \cdot \rfloor$ 가 이른바 가우스 함수 $[ \cdot ]$ 로도 많이 알려져있다. 10진법으로 보았을 때 자릿수 버림에 해당하기 때문에 직관적이고, 그래서 쓴다고 하면</description>
    </item>
    
    <item>
      <title>일반적인 각도와 수직의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/general-definition-of-angle/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/general-definition-of-angle/</guid>
      <description>정의 1 $V$ 가 벡터공간이라고 하자. 두 벡터 $\mathbb{u}, \mathbb{v} \in V$ 에 대해 다음을 만족하는 $\theta$ 를 두 벡터 사이의 각도Angle라 정의한다. $$ \cos \theta = {{ \left&amp;lt; \mathbb{u}, \mathbb{v} \right&amp;gt; } \over { \left| \mathbb{u} \right| \left| \mathbb{v} \right| }} $$ 만약 두 벡터 $\mathbb{u}, \mathbb{v}$ 가 $\left&amp;lt; \mathbb{u}, \mathbb{v} \right&amp;gt; = 0$ 을 만족하면 $\mathbb{u}$ 가 $\mathbb{v}$ 에 직교Orthogonal 혹은 수직Perpendicular하다고 말하고 $\mathbb{u} \perp \mathbb{v}$ 와 같이 나타낸다. $\left&amp;lt; \cdot, \cdot \right&amp;gt;$ 는 내적이</description>
    </item>
    
    <item>
      <title>조인트 엔트로피</title>
      <link>https://freshrimpsushi.github.io/posts/joint-entropy/</link>
      <pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/joint-entropy/</guid>
      <description>정의 확률변수 $X_{1}, \cdots , X_{n}$ 의 결합확률질량함수 $p$ 혹은 결합확률밀도함수 $f$ 가 주어져 있다고 하자. 이산 $$ H \left( X_{1}, \cdots , X_{n} \right) := - \sum_{x_{1}} \cdots \sum_{x_{n}} p \left( x_{1} , \cdots , x_{n} \right) \log_{2} p \left( x_{1} , \cdots , x_{n} \right) $$ 연속 $$ H \left( X_{1}, \cdots , X_{n} \right) := - \int_{\mathbb{R}} \cdots \int_{\mathbb{R}} f \left( x_{1} , \cdots , x_{n} \right) \log_{2} f \left( x_{1} , \cdots , x_{n} \right) d x_{1} \cdots d x_{n} $$ 정리 조인트 엔트로피는 다음과 같은 성질들을 가진다. [1] 부등식: $$ 0 \le \max_{k=1 \cdots n} \left\{ H \left( {X_{k}}</description>
    </item>
    
    <item>
      <title>윈도 cmd, powershell에서 줄리아 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-julia-in-windows-cmd-or-powershell/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-julia-in-windows-cmd-or-powershell/</guid>
      <description>가이드 Step 0. julia 1.6 이상 버전 설치 1.6 버전 이상부터는 인스톨 과정에서 환경변수에 넣을 수 있다. 표시된 옵션을 체크하고 설치하면 된다. 구버전을 사용하고 있다면 1.6 이상 버전을 설치하거나 아래의 지시를 따르면 된다. Step 1. 줄리아 설치 경로 확인 줄리아의 설치 경로를 확인한다. 별달리 건드린 게 없다면 다음 경로에 저장되어 있을 것이다. C:\Users\사</description>
    </item>
    
    <item>
      <title>샤넌 엔트로피: 확률변수로 정의되는 엔트로피</title>
      <link>https://freshrimpsushi.github.io/posts/shannon-entropy/</link>
      <pubDate>Sun, 13 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shannon-entropy/</guid>
      <description>개요 샤넌 엔트로피Shannon Entropy 혹은 정보 엔트로피는 확률변수로 정의되는 무질서에 대한 척도로써, 확률분포 상 얼마나 불확실한지에 대한 계량화로 볼 수 있다. 쉽고 복잡한 정의 이산형 엔트로피 1 이산확률변수 $X$ 의 확률질량함수가 $p(x)$ 일 때, $X$ 의 엔트로피를 다음과 같이 나타낸다. $$ H(X) := - \sum p(x) \log_{2} p(x) $$ 연속형 엔트로피 2 연속확률변수 $X$ 의 값이 확률</description>
    </item>
    
    <item>
      <title>피셔 정보</title>
      <link>https://freshrimpsushi.github.io/posts/fisher-information/</link>
      <pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fisher-information/</guid>
      <description>빌드업 스코어 함수 모수 $\theta \in \Theta$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. 로그우도함수가 가장 커지는 추정량인 최대우도추정량은 다음과 같은 편미분방정식을 만족하는 $\widehat{\theta}$ 으로 구할 수 있었다. $$ \sum_{k=1}^{n} {{ \partial \log f \left( x_{k} ; \theta \right) } \over { \partial \theta }} $$ 여기서 $\displaystyle {{ \partial \log f ( x ; \theta ) } \over { \partial \theta }}$ 를 스코어 함수Score Function이라</description>
    </item>
    
    <item>
      <title>샤넌 정보: 확률론으로 정의되는 정보</title>
      <link>https://freshrimpsushi.github.io/posts/information-contents-in-probability-theory/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/information-contents-in-probability-theory/</guid>
      <description>빌드업 카드 맞추기 게임 앨리스와 밥이 조커 없는 트럼프 카드 덱 52장 중 하나를 뒷면으로 뽑고 어떤 카드인지 맞추는 내기를 한다고 상상해보자. 앨리스: 뽑은 카드는 조커가 아니다. 듣자마자 밥이 표정을 찌푸린다. 말이야 맞는 말인데, 너무 당연히 맞는 말이라서 아무런 의미가 없기 때문이다. 내기에 앞서 배당에 대한 합의가 필요해보인다. 두 사람은 우선 막</description>
    </item>
    
    <item>
      <title>종간 전염 모델: 3개 집단 간의 질병 전파</title>
      <link>https://freshrimpsushi.github.io/posts/host-vector-host-model/</link>
      <pubDate>Mon, 07 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/host-vector-host-model/</guid>
      <description>개요 종간 장벽Species Barrier이란 감염원이 종래의 숙주에서 다른 종에 전염되기 어려운 현상을 말한다. 이러한 종간 장벽을 뛰어넘어 병이 전염되는 것을 종간 전염Cross-species Transmission이라 부르는데, 이를 수학적으로 모델링한 호스트-벡터-호스트 모델Host-vector-host mode</description>
    </item>
    
    <item>
      <title>최적해: 최대인수와 최소인수</title>
      <link>https://freshrimpsushi.github.io/posts/optimizer-argmax-and-argmin/</link>
      <pubDate>Sat, 05 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/optimizer-argmax-and-argmin/</guid>
      <description>어려운 정의 임의의 집합 $X$ 과 전순서집합 $\left( Y, \le \right)$ 가 주어져 있다고 하자. $X$ 의 부분집합 $S \subset X$ 에 대해 함수 $f : X \to Y$ 의 최대인수Argument of Maxima $\argmax_{S} : Y^{X} \to 2^{X}$ 와 최소인수Argument of Minima $\argmin_{S} : Y^{X} \to 2^{X}$ 는 다음과 같이 정의된다. $$ \argmax_{S} f := \left\{ x_{\ast} \in S : f \left( x_{\ast} \right) \ge f(x) , \forall x \in X \right\} \\ \argmin_{S} f := \left\{ x_{\ast} \in S : f \left( x_{\ast} \right) \le f(x) , \forall x \in X \right\} $$ $2^{X}$ 은 $X$ 의 멱집</description>
    </item>
    
    <item>
      <title>성병 모델: 2개 집단 간의 질병 전파</title>
      <link>https://freshrimpsushi.github.io/posts/venereal-disease-model/</link>
      <pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/venereal-disease-model/</guid>
      <description>개요 쿡Cooke과 요크Yorke에 의해 제안된 성병 전파의 수학적 모델에 대해 알아본다. 레퍼런스에서는 성병의 구체적인 예로써 임질Gonorrhea을 고려했다. 모델 1 $$ \begin{align*} {{d S_{1}} \over {d t}} =&amp;amp; - \beta_{12} S_{1} I_{2} + \gamma_{1} I_{1} \\ {{d I_{1}} \over {d t}} =&amp;amp; \beta_{12} S_{1} I_{2} - \gamma_{1} I_{1} \\ {{d S_{2}} \over {d t}} =&amp;amp; - \beta_{21} S_{2} I_{1} + \gamma_{2} I_{2} \\ {{d I_{2}} \over {d t}} =&amp;amp; \beta_{21} S_{2} I_{1} - \gamma_{2} I_{2} \end{align*} $$ 변수 $S_{k}(t)$: $t$ 시점에서 병에 걸릴 수 있는S</description>
    </item>
    
    <item>
      <title>수리통계학에서의 정칙성 조건</title>
      <link>https://freshrimpsushi.github.io/posts/regularity-conditions-in-mathematical-statistiics/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regularity-conditions-in-mathematical-statistiics/</guid>
      <description>개요 수학을 사용하는 과목에서 대개 정칙성Regularity Conditions이란 대개 응용될 구석이 많으면서 이론적인 전개가 편해지는 조건들을 말하며, 수리통계학에서는 다음과 같다. 가정 1 모수 $\theta \in \Theta$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. $X$ 와 같은 분포로 iid하게 뽑은 랜덤샘플 $X_{1} , \cdots , X_{n}$ 는 같은 확률</description>
    </item>
    
    <item>
      <title>SIS 모델: 재감염과 고질병</title>
      <link>https://freshrimpsushi.github.io/posts/sis-model-reinfection-and-endemic/</link>
      <pubDate>Sun, 30 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sis-model-reinfection-and-endemic/</guid>
      <description>개요 SIS 모델은 전염이나 정보의 확산에서 면역, 무관심 등을 고려하지 않는 모델이다. 주로 유행병Epidemic이 아닌 풍토병Endemic, 예를 들어 감기, 독감, 성병, 말라리아 등이 SIS 로 모델링될 수 있다. 모델 1 $$ \begin{align*} {{d S} \over {d t}} =&amp;amp; - {{ \beta } \over { N }} I S + \gamma I \\ {{d I} \over {d t}} =&amp;amp; {{ \beta } \over { N }} S I - \gamma I \end{align*} $$ 변수 $S(t)$: $t$ 시점에서 병에 걸릴 수</description>
    </item>
    
    <item>
      <title>최적값: 최대값과 최소값</title>
      <link>https://freshrimpsushi.github.io/posts/optimum-maximum-minimum/</link>
      <pubDate>Fri, 28 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/optimum-maximum-minimum/</guid>
      <description>쉬운 정의 최대값Maximum과 최소값Minimum을 통틀어 최적값Optimum이라 한다. 집합 $X$ 에서 가장 큰 원소를 최대값 $\max X$, 가장 작은 원소를 최소값 $\min X$ 과 같이 나타낸다. 함수 $f : X \to \mathbb{R}$ 의 가장 큰 함수값을 $\max_{X} f$, 가장 작은 함수값을 $\min_{X} f$ 와 같이 나타낸다. $\mathbb{R}$ 은 실수 전체의 집합을 나타낸다. 최대, 최소는 한자어고 값은 순우리말이므로 사</description>
    </item>
    
    <item>
      <title>최대우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/maximum-likelihood-estimator/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maximum-likelihood-estimator/</guid>
      <description>빌드업 모수 $\theta \in \Theta$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. $X$ 와 같은 분포로 iid하게 뽑은 랜덤샘플 $X_{1} , \cdots , X_{n}$ 는 같은 확률밀도함수 $f(x ; \theta)$ 와 실현 $\mathbf{x} := \left( x_{1} , \cdots , x_{n} \right)$ 을 가진다. 이에 대해 다음과 같은 함수 $L$ 을 우도함수Likelihood Function라 한다. $$ L ( \theta ; \mathbf{x} ) := \prod_{k=1}^{n} f \left( x_{k} ; \theta \right) $$ 아래에서 나오</description>
    </item>
    
    <item>
      <title>SIR 모델: 가장 기본적인 확산 모델</title>
      <link>https://freshrimpsushi.github.io/posts/sir-model-most-basic-epdemic-spreading-model/</link>
      <pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sir-model-most-basic-epdemic-spreading-model/</guid>
      <description>개요 SIR 모델은 가장 간단하고 수많은 변형이 있는 역학 구획 모델로써, 질병이나 정보 등의 확산 자체를 간단하면서도 직관적으로 잘 설명한다. 모델 1 $$ \begin{align*} {{d S} \over {d t}} =&amp;amp; - {{ \beta } \over { N }} I S \\ {{d I} \over {d t}} =&amp;amp; {{ \beta } \over { N }} S I - \mu I \\ {{d R} \over {d t}} =&amp;amp; \mu I \end{align*} $$ 변수 $S(t)$: $t$ 시점에서 병에 걸릴 수 있는Susceptible 집단의 개체수를 나타낸다. $I(t)$: $t$</description>
    </item>
    
    <item>
      <title>줄리아에서의 메타 프로그래밍</title>
      <link>https://freshrimpsushi.github.io/posts/meta-programming-in-julia/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/meta-programming-in-julia/</guid>
      <description>코드 1 줄리아에서는 메타 프로그래밍을 언어 차원에서 지원한다. 다음은 문자열을 코드 그 자체로 읽고 실행한 결과다. julia&amp;gt; text = &amp;#34;f(x) = 2x + 1; f(2)&amp;#34; &amp;#34;f(x) = 2x + 1; f(2)&amp;#34; julia&amp;gt; code = Meta.parse(text) :($(Expr(:toplevel, :(f(x) = begin #= none:1 =# 2x + 1 end), :(f(2))))) julia&amp;gt; eval(code) 5 Meta.Parse(): 이 함수를 통해 입력된 문자열을 표현식Expression으로 바꿔 반환한다. eval(): 표현식을 평가Evaluate한다. 위 예제코드에서는 $f(2)$ 가 실제</description>
    </item>
    
    <item>
      <title>전염병 확산 모델에서 기초감염재생산수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-basic-reproduction-number-in-epidemic-spreading-model/</link>
      <pubDate>Thu, 20 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-basic-reproduction-number-in-epidemic-spreading-model/</guid>
      <description>정의 기초감염재생산수Basic Reproduction Number $\mathcal{R}_{0}$ 는 전염병이 확산되는 속도를 나타낸 값으로써, 기본적으로 한 명의 감염자가 다른 이를 얼마나 감염시킬지에 대한 기대값로 표현된다. 역학 구획 모델 1 미분방정식으로 표현된 동역학계에서는 자코비안 행렬의 실수부가 가장 큰 고유값을 $\mathcal{R}_{0}$ 이라 한다. 설명 정의만 읽어보면 무슨 소린지 이해하기 어렵지만 구체적인 값으</description>
    </item>
    
    <item>
      <title>줄리아에서 배열 Flatten 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-flatten-array-in-julia/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-flatten-array-in-julia/</guid>
      <description>코드 vec() 함수를 쓰면 된다. julia&amp;gt; A = rand(0:9, 3,4) 3×4 Array{Int64,2}: 6 8 7 3 2 9 3 2 5 0 6 7 julia&amp;gt; vec(A) 12-element Array{Int64,1}: 6 2 5 8 9 0 7 3 6 3 2 7 사람이 생각하기로, 사람에게 보이기로는 똑같이 1차원 배열인데 타입상 2차원 배열이라 에러를 내는 경우도 이 방법으로 해결하면 된다. 다음 두 명령은 정확히 같은 배열로 보이지만 $\mathbb{N}^{10 \times 1}$ 행렬이냐 $\mathbb{N}^{10 }$ 벡터냐의 차이가 있다. julia&amp;gt; b = rand(0:9, 10,1) 10</description>
    </item>
    
    <item>
      <title>일치추정량</title>
      <link>https://freshrimpsushi.github.io/posts/consistent-estimator/</link>
      <pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/consistent-estimator/</guid>
      <description>정의 1 확률변수 $X$ 가 누적분포함수 $F ( x ; \theta), \theta \in \Theta$ 를 가진다고 하자. $X_{1} , \cdots , X_{n}$ 을 $X$ 에서 뽑은 샘플이라고 할 때, 통계량 $T_{n}$ 이 다음을 만족하면 모수 $\theta$ 에 대한 일치추정량Consistent Estimator이라 한다. $$ T_{n} \overset{P}{\to} \theta $$ $\overset{P}{\to}$ 는 확률수렴이다. 예시 $X_{1} , \cdots , X_{n}$ 가 확률분포 $\left( \mu, \sigma^{2} \right)$ 를 따르는 랜덤 샘플, 즉 $X_{1} , \cdots , X_{n} \sim \left( \mu, \sigma^{2} \right)$ 이고 첨</description>
    </item>
    
    <item>
      <title>줄리아에서 거리 행렬 계산 최적화하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-optimize-calculating-distance-matrix/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-optimize-calculating-distance-matrix/</guid>
      <description>결론 $n$ 개의 좌표끼리 거리를 계산한다고 하자. 모든 좌표끼리 계산할 필요가 없다면 그룹을 나누어 직사각 거리 행렬을 만들면 된다. 직사각 거리행렬은 pairwise() 함수로 쉽고 빠르게 계산할 수 있다. 속도 비교 가령 SIR 모델에 대해 무빙 에이전트 기반 시뮬레이션을 한다고 생각해보자. 원래의 시간복잡도는 $O \left( n^{2} \right)$ 이지만, $S$ 와 $I$ 그룹으로 나누어 계산하면 시간 복잡도</description>
    </item>
    
    <item>
      <title>역학 구획 모델</title>
      <link>https://freshrimpsushi.github.io/posts/compartmental-model-in-epidemiology/</link>
      <pubDate>Wed, 12 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compartmental-model-in-epidemiology/</guid>
      <description>개요 1 역학 구획 모델은 전염병의 창궐에 대한 모델로써, 인구 동역학에 전염병을 가미하고 &amp;lsquo;인구&amp;rsquo;을 몇가지 구획Compartmental으로 나눈다. 역학疫學, Epidemiology이란 전염병을 다루는 학문으로써, 생새우초밥집에서 다루는 역학力學, Mechanics과는 관계가 없다. 설명 커맥Ke</description>
    </item>
    
    <item>
      <title>줄리아에서 가중치를 주고 랜덤 샘플링 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-random-sampling-with-weight-in-julia/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-random-sampling-with-weight-in-julia/</guid>
      <description>개요 줄리아에서 R에서의 sample()이나 파이썬 패키지 numpy의 random.choice()와 같은 역할을 하는 함수인 sample()과 Weights 함수의 사용법이다. 코드 1 using StatsBase items = 0:5 weights = 0:5 sample(items, Weights(weights)) # With replacement my_samps = sample(items, Weights(weights), 10) # Without replacement my_samps = sample(items, Weights(weights), 2, replace=false) 실행 결과 julia&amp;gt; using StatsBase julia&amp;gt; items = 0:5 0:5 julia&amp;gt; weights = 0:5 0:5 julia&amp;gt; sample(items, Weights(weights)) 5 julia&amp;gt; # With replacement julia&amp;gt; my_samps = sample(items, Weights(weights), 10) 10-element Array{Int64,1}: 4 3 2 1 3 3 5 5 2</description>
    </item>
    
    <item>
      <title>스미스-워터맨 정렬: 국소 서열 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/smith-waterman-alignment/</link>
      <pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/smith-waterman-alignment/</guid>
      <description>개요 두 염기서열에서 가장 비슷한 부분의 정렬을 찾는 것을 국소 정렬Local Alignment이라 하는데, 그 방법으로 가장 널리 쓰이는 스미스-워터맨 알고리즘Smith-Waterman Algorithm을 소개한다. 서열정렬에는 너무나 많은 경우의 수가 있기 때문에 다이내믹 프로그래밍 을 통해 효율적이고 빠르게 계산할 필요가 있다.</description>
    </item>
    
    <item>
      <title>줄리아에서 문자와 정수의 이퀄 오퍼레이터 == 속도 비교</title>
      <link>https://freshrimpsushi.github.io/posts/speed-of-equal-operator-for-character-or-integer-in-julia/</link>
      <pubDate>Thu, 06 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/speed-of-equal-operator-for-character-or-integer-in-julia/</guid>
      <description>결론 배열의 각 원소를 Equal Operator ==를 통해 비교하면 정수보다 Char가 빠르다. 속도 비교 julia&amp;gt; integer = rand(1:5, N); print(typeof(integer)) Array{Int64,1} julia&amp;gt; character = rand([&amp;#39;S&amp;#39;,&amp;#39;E&amp;#39;,&amp;#39;I&amp;#39;,&amp;#39;R&amp;#39;,&amp;#39;D&amp;#39;], N); print(typeof(character)) Array{Char,1} julia&amp;gt; @time integer .== 1; 0.009222 seconds (6 allocations: 1.196 MiB) julia&amp;gt; @time character .== &amp;#39;S&amp;#39;; 0.005266 seconds (7 allocations: 1.196 MiB) 위의 코드는 정수와 문자로 이루어진 배열에서 각각 1과 S가 어디에 있는지 파악하는 프로그램이다. 정수냐 문자열이냐의 차이 빼고는 정확히 같으나, 시간 소요는 두배에 육박할만큼 큰</description>
    </item>
    
    <item>
      <title>이항분포에서 근사시킨 정규분포의 분산 안정화</title>
      <link>https://freshrimpsushi.github.io/posts/parameter-free-transform-of-binomial-distribution/</link>
      <pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/parameter-free-transform-of-binomial-distribution/</guid>
      <description>예시 1 $Y = Y_{n}$ 가 이항분포 $\text{Bin} (n,p)$ 를 따른다고 하면 $$ \arcsin \sqrt{ {{ Y } \over { n }} } \overset{D}{\to} N \left( \arcsin \sqrt{p} , n/4 \right) $$ $N \left( \mu , \sigma^{2} \right)$ 는 정규분포를 의미한다. $\overset{D}{\to}$ 는 분포수렴을 의미한다. 설명 이항분포 $\text{Bin} (n, p )$ 는 $n \to \infty$ 일 때 정규분포 $N \left( np, np(1-p) \right)$ 로 수렴하므로 정규분포 자체는 신기할 게 없지만, 위와 같은 변환을 취함으로써 분산이 모수 $p$ 에 관계 없이 일정한 극한 분포를 얻을 수도</description>
    </item>
    
    <item>
      <title>2차원 배열의 행우선과 열우선</title>
      <link>https://freshrimpsushi.github.io/posts/row-major-and-column-major/</link>
      <pubDate>Sun, 02 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/row-major-and-column-major/</guid>
      <description>개요 1 행렬 혹은 2차원 배열의 행우선row-major, 열우선column-major에 대해 설명한다. 행우선이냐 열우선이냐는 쉽게 말해 배열을 참조하면서 어떤 반향으로 읽느냐를 선호하는지를 말한다. 차이점 위키피디아에 따르면 어떤 프로그래밍 언어와 라이브러리들은 다음과 같이 네이티브Native한 행/렬우선이 정해져있다고 한</description>
    </item>
    
    <item>
      <title>스튜던트의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-students-theorem/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-students-theorem/</guid>
      <description>정리 1 확률 변수 $X_{1} , \cdots , X_{n}$ 들이 iid로 정규분포 $N\left( \mu,\sigma^{2} \right)$ 를 따른다고 하면 (a): $$ \overline{X} \sim N\left( \mu , { {\sigma^2} \over {n} } \right) $$ (b): $$ \overline{X} \perp S^2 $$ (c): $$ (n-1) { {S^2} \over {\sigma^2} } \sim \chi^2 (n-1) $$ (d): $$ T = { {\overline{X} - \mu } \over {S / \sqrt{n}} } \sim t(n-1) $$ 표뵨 평균 $\overline{X}$ 과 표본 분산 $S^{2}$ 는 다음과 같이 정의된 확률 변수다. $$ \overline{X} := {{ 1 } \over { n }} \sum_{k=1}^{n} X_{k} \\ S^{2} := {{ 1 } \over { n-1 }} \sum_{k=1}^{n} \left( X_{k} - \overline{X} \right)^{2} $$ 설명 통계학을 하는 사람들은 당연</description>
    </item>
    
    <item>
      <title>RGB 색상 치트 시트</title>
      <link>https://freshrimpsushi.github.io/posts/rgb-color-cheat-sheet/</link>
      <pubDate>Wed, 28 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rgb-color-cheat-sheet/</guid>
      <description>개요 자주 사용되는 RGB색상표다. 코드 000000 R - 000 G - 000 B - 000 333333 R - 051 G - 051 B - 051 666666 R - 102 G - 102 B - 102 999999 R - 153 G - 153 B - 153 CCCCCC R - 204 G - 204 B - 204 FFFFFF R - 255 G - 255 B - 255 000033 R - 000 G - 000 B - 051 333300 R - 051 G - 051 B - 000 666600 R - 102 G - 102 B - 000 999900 R - 153 G - 153 B - 000 CCCC00 R - 204 G - 204 B - 000 FFFF00 R - 255 G - 255 B - 000 000066 R - 000 G - 000 B - 102 333366 R</description>
    </item>
    
    <item>
      <title>니들맨-분쉬 알고리즘: 전역 서열 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/needleman-wunsch-algorithm/</link>
      <pubDate>Mon, 26 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/needleman-wunsch-algorithm/</guid>
      <description>개요 두 염기서열의 공통 부분이 가장 많아지는 정렬을 찾는 것을 전역 정렬Global Alignment이라 하는데, 그 방법으로 가장 널리 쓰이는 니들맨-분쉬 알고리즘Needleman-Wunsch Algorithm을 소개한다. 서열정렬에는 너무나 많은 경우의 수가 있기 때문에 다이내믹 프로그래밍 을 통해 효율적이고 빠르게 계산할 필요</description>
    </item>
    
    <item>
      <title>유사 역행렬</title>
      <link>https://freshrimpsushi.github.io/posts/pseudoinvers-matrix/</link>
      <pubDate>Sat, 24 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pseudoinvers-matrix/</guid>
      <description>개요 유사역행렬Pseudoinvers Matrix은 역행렬의 일반화로써, 행과 열의 크기가 같지 않아서 정방행렬이 아닌 행렬 $A \in \mathbb{R}^{m \times n}$ 에 대해 &amp;lsquo;사실상&amp;rsquo; 역행렬이 되는 행렬을 말한다. 행렬변환 $T_{A} : \mathcal{N} (A) \to \mathcal{C} (A)$ 이 모든 $\mathbf{x} \in \mathcal{N} (A)^{\perp}$ 에 대해 $$ T_{A} \mathbf{x} = A \mathbf{x} $$ 을 만족한다면 $T_{A}$ 는 전단사가 된다. 이는 $T_{A}$ 의 공역을 좁혀서 강제</description>
    </item>
    
    <item>
      <title>일제사격 전투 모델</title>
      <link>https://freshrimpsushi.github.io/posts/salvo-combat-model/</link>
      <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/salvo-combat-model/</guid>
      <description>개요 란체스터 법칙이 근대전과 현대전의 양상을 묘사하는 모델이라면, 일제사격 전투 모델은 현대전 중에서도 특히 스케일이 큰 함대전을 묘사한다. 함대전에서 공격의 수단은 미사일과 같이 크고 강력한 것들이 많으며, 반대로 이런 미사일을 요격하는 미사일도 있다는 점이 다르다. 모델1 $$ \begin{align*} \Delta A =&amp;amp; - { { 1 } \over { H_{A} } } \left( O_{B} B - D_{A} A \right) \\ \Delta B =&amp;amp; - { { 1</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution-of-random-vector/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution-of-random-vector/</guid>
      <description>정의1 $p$차원 랜덤 벡터 $\mathbf{X}$ 와 랜덤 벡터의 시퀀스 $\left\{ \mathbf{X}_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $\mathbf{X}_{n}$ 이 $\mathbf{X}$ 로 분포 수렴한다고 말하고, $\mathbf{X}_{n} \overset{D}{\to} \mathbf{X}$ 와 같이 나타낸다. $$\lim_{n \to \infty} F_{\mathbf{X}_{n}} (x) = F_{\mathbf{X}} (x) \qquad, \forall x \in C_{F_{\mathbf{X}}}$$ $F_{X}$ 는 확률변수 $X$ 의 누적분포함수다. $C_{F_{\mathbf{X}}}$ 는 함수 $F_{\mathbf{X}}$ 가 연속인 점들의 집합을 나타낸다. 다변량 중심 극한 정리 $\left\{ \mathbf{X}_{n} \right\}$ 가 평균 벡터 $\mathbf{\mu} \in \mathbb{R}^{p}$ 와 공분산 행렬 $\Sigma \in \mathbb{R}^{p \times p}$ 를 가지고 ii</description>
    </item>
    
    <item>
      <title>란체스터 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/lanchester-laws/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lanchester-laws/</guid>
      <description>법칙 제1법칙 근대전 혹은 근접전투에서 전투력은 부대 규모에 비례한다. 제2법칙 현대전 혹은 원거리전투에서는 전투력은 부대 규모의 제곱에 비례한다. 설명 란체스터 법칙Lanchester&amp;rsquo;s Laws은 두 집단의 전투에서 사상자의 수에 대한 법칙으로, 제1법칙(선형 법칙)과 제2법칙(제곱 법칙)으로 서술된다. 선형 법칙:</description>
    </item>
    
    <item>
      <title>git warning: LF will be replaced by LF in … 해결법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-fix-warning-lf-will-be-replaced-by-lf-in/</link>
      <pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-fix-warning-lf-will-be-replaced-by-lf-in/</guid>
      <description>명령 git config --global core.safecrlf false 리눅스랑 윈도우 차이 때문에 나오는 경고인데 무시하면 된다. 위와 같이 입력하면 된다.</description>
    </item>
    
    <item>
      <title>메이-레너드 경쟁 모델</title>
      <link>https://freshrimpsushi.github.io/posts/may-leonard-competition-model/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/may-leonard-competition-model/</guid>
      <description>개요 메이-레너드 경쟁 모델은 세 가지 집단이 포함된 경쟁 상태에서의 인구 동역학 모델로, 세 집단이 서로 먹고 먹히는 삼각 관계를 묘사한다. 세 개의 당이나 기업, 혹은 실제로 상성이 있는 경쟁이 될 수도 있다. 모델1 $$ \begin{align*} x_{1}&amp;rsquo; =&amp;amp; x_{1} \left( 1 - x_{1} - b x_{2} - a x_{3} \right) \\ x_{2}&amp;rsquo; =&amp;amp; x_{2} \left( 1 - a x_{1} - x_{2} - b x_{3} \right) \\ x_{3}&amp;rsquo; =&amp;amp; x_{3} \left( 1 - b x_{1} - a x_{2} - x_{3} \right) \end{align*} $$ 변수 $x_{1}(t)$: $t$ 시점에서 집단 $x_{1}$ 의</description>
    </item>
    
    <item>
      <title>1&#43;2&#43;3&#43;4&#43;5&#43;⋯=-1/12 의 해석적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/analytic-proof-of-zeta--1/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/analytic-proof-of-zeta--1/</guid>
      <description>정리 $$ \begin{align*} &amp;amp; 1 + 2 + 3 + 4 + 5 + \cdots \\ =&amp;amp; \sum_{n \in \mathbb{N}} {{ 1 } \over { n^{-1} }} \\ =&amp;amp; \zeta(-1) \\ =&amp;amp; -{{ 1 } \over { 12 }} \end{align*} $$ 설명 양수를 계속 더했는데 어떻게 음수가 나오는가에만 집중한다면 이 포스트를 절대 이해할 수 없을 것이다. 핵심은 $\sum_{n \in \mathbb{N}} n$ 이 디리클레 급수 $\displaystyle \sum_{n \in \mathbb{N}} {{ 1 } \over { n^{-1} }}$ 으로 표현된다는 것이고, 그 해석적 연속인 리만 제타 함수 $\zeta$ 의 함숫값 $\zeta(-1)$ 으로써 계산한다는</description>
    </item>
    
    <item>
      <title>롯카-볼테라 경쟁 모델</title>
      <link>https://freshrimpsushi.github.io/posts/competitive-lotka-volterra-equations/</link>
      <pubDate>Sun, 04 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/competitive-lotka-volterra-equations/</guid>
      <description>개요 롯카-볼테라 경쟁 모델은 두 집단 사이의 경쟁적 배제 원리Principle of Competitive Exclusion을 설명할 수 있는 모델로써, 특히 두 집단이 서로를 견제하는 상황을 묘사한다. 이를테면 같은 목초지를 공유하는 토끼와 양의 관계나 두 라이벌 부족의 살육전 등에 대해 적용될 수 있다. 모델1 $$ \begin{align*} x_{1}&amp;rsquo; =&amp;amp; r_{1} x_{1} {{ K_{1} - x_{1} - \beta_{12} x_{2} } \over { K_{1} }} \\ x_{2}&amp;rsquo; =&amp;amp; r_{2} x_{2} {{ K_{2}</description>
    </item>
    
    <item>
      <title>다변량 t-분포</title>
      <link>https://freshrimpsushi.github.io/posts/multivariate-t-distribution/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multivariate-t-distribution/</guid>
      <description>정의 로케이션 벡터 $\mathbf{\mu} \in \mathbb{R}^{p}$ 와 양의 정부호인 스케일 행렬 $\Sigma \in \mathbb{R}^{p \times p}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 다변량 분포 $t_{p} \left(\nu; \mu , \Sigma \right)$ 를 다변량 t-분포Multivariate t-distribution라고 한다. $$ f (\textbf{x}) = {{ \Gamma \left[ (\nu + p) / 2 \right] } \over { \Gamma ( \nu / 2) \sqrt{ \nu^{p} \pi^{p} \det \Sigma } }} \left[ 1 + {{ 1 } \over { \nu }} \left( \textbf{x} - \mathbf{\mu} \right)^{T} \Sigma^{-1} \left( \textbf{x} - \mathbf{\mu} \right) \right] \qquad , \textbf{x} \in</description>
    </item>
    
    <item>
      <title>롯카-볼테라 포식자-피식자 모델</title>
      <link>https://freshrimpsushi.github.io/posts/lotka-volterra-predator-prey-model/</link>
      <pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lotka-volterra-predator-prey-model/</guid>
      <description>개요 롯카-볼테라 포식자-피식자 모델은 종간의 상호작용을 시스템으로써 모델링하며, 특히 포식자-피식자 모델은 두 종의 포식관계를 나타낸다. 두 종에 대해서만 다루면 그 확장은 끝이 없기 때문에 먹이사슬을 표현하기엔 충분하다. 모델1 $$ \begin{align*} x&amp;rsquo; =&amp;amp; a x - b y \cdot x \\ y&amp;rsquo; =&amp;amp; c x \cdot y - d y \end{align*} $$ 변수 $x(t)$: $t$ 시점에서 피식자 집단 $x$ 의 개체수를 나타낸다. $y(t)$:</description>
    </item>
    
    <item>
      <title>git 비밀번호 저장하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-save-git-password/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-save-git-password/</guid>
      <description>명령 git config credential.helper store 위와 같이 입력하면 된다.</description>
    </item>
    
    <item>
      <title>줄리아 패키지 설치 시 \General\Registry.toml: No such file or directory 해결</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-fix-registry.toml-no-such-file-or-directory/</link>
      <pubDate>Sat, 20 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-fix-registry.toml-no-such-file-or-directory/</guid>
      <description>에러 ERROR: SystemError: opening file &amp;quot;C:\\Users\\rmsms\\.julia\\registries\\General\\Registry.toml&amp;quot;: No such file or directory 원인 사람 정말 열 받게 하는 에러인데, 말 그대로 해당 경로에 Registry.toml 파일이 없어서 일어나는 에러다. 해결법 C:\Users\사용자이름\.julia\registries\General 폴더를 삭제하고 다시 시도해본다. 그러면 위와 같이 Registry.toml 파일도 생기고 설치도 정상적으로 진행되는 것을 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>윈도에서 줄리아 최신 버전 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-julia-in-windows/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-julia-in-windows/</guid>
      <description>가이드 Step 1. 줄리아 설치 줄리아 다운로드 페이지에서 설치 파일을 받고 실행한다. Step 2. vs code 설치 비주얼 스튜디오 코드 다운로드 페이지에서 설치파일을 받고 실행한다. Step 3. 줄리아 확장 설치 좌측 다섯번째 아이콘 혹은 Ctrl + Shift + X으로 Extensions을 연다. &amp;lsquo;julia&amp;rsquo;를 검색하면 최상단에 Julia Language Support가 뜬</description>
    </item>
    
    <item>
      <title>정부호 행렬</title>
      <link>https://freshrimpsushi.github.io/posts/definite-matrix/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definite-matrix/</guid>
      <description>정의: 정부호 행렬1 이차 형식 $\mathbf{x}^{\ast} A \mathbf{x}$가 모든 $\mathbf{x} \ne \mathbf{0}$ 에 대해서 $\mathbf{x}^{\ast} A \mathbf{x} &amp;gt; 0$ 을 만족하면 이차 형식 혹은 행렬 $A$를 양의 정부호positive definite라고 한다. 모든 $\mathbf{x} \ne \mathbf{0}$ 에 대해서 $\mathbf{x}^{\ast} A \mathbf{x} &amp;lt; 0$ 을 만족하면 이차 형식 혹은 행렬 $A$를 음의 정부호negative definite라고 한다. $\mathbf{x}$ 에 따라서 양수이기</description>
    </item>
    
    <item>
      <title>에르미트 행렬의 서로 다른 고유값의 고유벡터는 서로 수직이다</title>
      <link>https://freshrimpsushi.github.io/posts/the-eigenvectors-for-two-different-eigenvalues-of-the-hermitian-matrix-are-perpendicular-to-each-other/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-eigenvectors-for-two-different-eigenvalues-of-the-hermitian-matrix-are-perpendicular-to-each-other/</guid>
      <description>정리 $A$를 크기가 $n \times n$인 에르미트 행렬이라고 하자. $A$ 의 서로 다른 두 고유값 $\lambda , \mu$ 에 대한 고유 벡터를 $\mathbf{x}$, $\mathbf{y}$라고 하자. 즉 $$ \begin{align*} A \mathbf{x} =&amp;amp; \lambda \mathbf{x} \quad \\ A \mathbf{y} =&amp;amp; \mu \mathbf{y} \end{align*} $$ 그러면 두 고유 벡터는 서로 직교한다. $$ \mathbf{x} \perp \mathbf{y} $$ 설명 에르미트 행렬은 고유값이 모두 실수라는 성질뿐만 아니라 그들에 대응하는 고유벡터가 서로 직교한다는 성질</description>
    </item>
    
    <item>
      <title>에르미트 행렬의 고유값은 항상 실수이다</title>
      <link>https://freshrimpsushi.github.io/posts/eigenvalue-of-hermitian-is-real-number/</link>
      <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eigenvalue-of-hermitian-is-real-number/</guid>
      <description>정리 $A$를 크기가 $n \times n$인 에르미트 행렬이라고 하자. 그러면 $A$ 의 고유값은 모두 실수다. 설명 일반적인 행렬에서 고유값이 실수라는 보장은 없고, 에르미트 행렬에 대해서는 증명을 통해 실수임을 확인할 수 있다. 직관적으로는 떠올리기 쉽지 않지만 증명 자체는 간단한 편이고, 팩트로써도 상당히 유용하다.후에 이어지는 양의 정부호 등의 개념과 결합</description>
    </item>
    
    <item>
      <title>다변량 정규 분포</title>
      <link>https://freshrimpsushi.github.io/posts/multivariate-normal-distribution/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multivariate-normal-distribution/</guid>
      <description>정의 모평균 벡터 $\mathbf{\mu} \in \mathbb{R}^{p}$ 와 공분산 행렬 $\Sigma \in \mathbb{R}^{p \times p}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 다변량 분포 $N_{p} \left( \mu , \Sigma \right)$ 를 다변량 정규 분포Multivariate Normal Distribution라고 한다. $$ f (\textbf{x}) = \left( (2\pi)^{p} \det \Sigma \right)^{-1/2} \exp \left[ - {{ 1 } \over { 2 }} \left( \textbf{x} - \mathbf{\mu} \right)^{T} \Sigma^{-1} \left( \textbf{x} - \mathbf{\mu} \right) \right] \qquad , \textbf{x} \in \mathbb{R}^{p} $$ 같이보기 일변량 정규 분포: $p = 1$ 이어서 $\mu \in \mathbb{R}^{1}$ 이고 $\Sigma \in</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability-of-random-vector/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability-of-random-vector/</guid>
      <description>정의 1 $p$차원 랜덤 벡터 $\mathbf{X}$ 와 랜덤 벡터의 시퀀스 $\left\{ \mathbf{X}_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $\mathbf{X}_{n}$ 이 $\mathbf{X}$ 로 확률 수렴Convergence in Probability한다고 말하고, $\mathbf{X} _ {n} \overset{P}{\to} \mathbf{X}$ 와 같이 나타낸다. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left\| \mathbf{X}_{n} - \mathbf{X} \right\| &amp;lt; \varepsilon \right] = 1 $$ $\| \cdot \|$ 는 유클리드 놈으로써, $\left\| \left( x_{1} , \cdots , x_{n} \right) \right\| = \sqrt{ x_{1}^{2} + \cdots + x_{n}^{2}}$ 와 같이 정의된다. 정리</description>
    </item>
    
    <item>
      <title>1&#43;1&#43;1&#43;1&#43;1&#43;⋯=-12 의 해석적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/analytic-proof-of-zeta-zero/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/analytic-proof-of-zeta-zero/</guid>
      <description>정리 $$ \begin{align*} &amp;amp; 1 + 1 + 1 + 1 + 1 + \cdots \\ =&amp;amp; \sum_{n \in \mathbb{N}} {{ 1 } \over { n^{0} }} \\ =&amp;amp; \zeta(0) \\ =&amp;amp; -{{ 1 } \over { 2 }} \end{align*} $$ 설명 양수를 계속 더했는데 어떻게 음수가 나오는가에만 집중한다면 이 포스트를 절대 이해할 수 없을 것이다. 핵심은 $\sum_{n \in \mathbb{N}} 1$ 이 디리클레 급수 $\displaystyle \sum_{n \in \mathbb{N}} {{ 1 } \over { n^{0} }}$ 으로 표현된다는 것이고, 그 해석적 연속인 리만 제타 함수 $\zeta$ 의 함숫값 $\zeta(0)$ 으로써 계산한다는</description>
    </item>
    
    <item>
      <title>공분산 행렬</title>
      <link>https://freshrimpsushi.github.io/posts/covariance-matrix/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/covariance-matrix/</guid>
      <description>정의1 $p$차원 랜덤 벡터 $\mathbf{X} = \left( X_{1}, \cdots , X_{p} \right)$ 에 대해 다음과 같이 정의된 $\text{Cov} (\mathbf{X})$ 를 공분산 행렬Covariance Matrix이라 한다. $$ \left( \text{Cov} \left( \mathbf{X} \right) \right)_{ij} := \text{Cov} \left( X_{i} , X_{j} \right) $$ $\text{Cov}$ 는 공분산이다. 설명 정의를 더 쉽게 풀어 적어보면 다음과 같다. $$ \text{Cov} \left( \mathbf{X} \right) := \begin{pmatrix} \text{Var} \left( X_{1} \right) &amp;amp; \text{Cov} \left( X_{1} , X_{2} \right) &amp;amp; \cdots &amp;amp; \text{Cov} \left( X_{1} , X_{p} \right) \\ \text{Cov} \left( X_{2} , X_{1} \right) &amp;amp; \text{Var} \left( X_{2} \right) &amp;amp; \cdots &amp;amp; \text{Cov} \left( X_{2} , X_{p}</description>
    </item>
    
    <item>
      <title>바스 확산 모델: 혁신과 모방</title>
      <link>https://freshrimpsushi.github.io/posts/bass-diffusion-model/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bass-diffusion-model/</guid>
      <description>모델 12 $$ N&amp;rsquo; = \left( p + q {{ N } \over { K }} \right) \left( 1 - {{ N } \over { K }} \right) $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 파라메터 $K$: 환경 용량Carrying Capacity으로, 집단을 수용할 수 있는 환경의 크기를 묘사한다. 개체수는 환경 용량을 넘어서 성장할 수 없다. $p$: 혁신 계수Coefficient of Innovation 혹은 전역 성장률Global Growth R</description>
    </item>
    
    <item>
      <title>곰페르츠 성장 모델: 시간에 따른 성장 지연</title>
      <link>https://freshrimpsushi.github.io/posts/gompertz-growth-mode/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gompertz-growth-mode/</guid>
      <description>모델 1 $$ {{ d N } \over { dt }} = r e^{ - \alpha t} N \qquad, \alpha 0 $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 파라메터 $r \in \mathbb{R}$ : 고유 성장률Intrinsic Rate of Increase로써, $0$ 보다 크면 성장하고 $0$ 보다 작으면 쇠퇴한다. 번식률Birth Rate $b$ 와 사망률Death Rate $d$ 의 차 $r:=b-d$ 로 정의되기도 한다. $\alpha&amp;gt;0$: 일종의 감쇠율 을 나타내는 상수로, 클수록</description>
    </item>
    
    <item>
      <title>수리생물학에서의 알리 효과</title>
      <link>https://freshrimpsushi.github.io/posts/allee-efect-in-mathematical-biology/</link>
      <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/allee-efect-in-mathematical-biology/</guid>
      <description>알리 효과란? 1 개체군의 밀도가 낮을 때 인구수가 감소하는 효과를 알리 효과Allee Efect라 한다. 수식적으로는 다음과 같이 모델에서 $N$ 에 대한 함수 $a: \mathbb{R} \to \mathbb{R}$ 를 위로 볼록한 컨벡스 함수로 두어 표현한다. $$ N&amp;rsquo; = a(N) N $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 예시 알리 이펙트는 예로써 함수 $a$ 를 다음과 같은 이차함수로 두어서 가정할 수 있다</description>
    </item>
    
    <item>
      <title>격자 모델 시뮬레이션에서의 확산</title>
      <link>https://freshrimpsushi.github.io/posts/diffusion-in-lattice-model-simulation/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diffusion-in-lattice-model-simulation/</guid>
      <description>시뮬레이션 이 포스트에서는 격자 공간에서 어떤 성분(Ingredient)의 확산 현상을 모방하려고 한다. 이는 그 동시에 SI 질병 확산 모델의 시뮬레이션이기도 하며, 공간이 제한되어 있다는 점에서 SIR 모델로도 볼 수 있다. 변수 $t$: 현재 턴을 의미한다. $I(t) \in \mathbb{N}$: $t$ 턴에서 확산되고 있는 성분(Ingredient)의 양을 나타낸다. $S(t) \in \mathbb{N}$: $t$ 턴에서</description>
    </item>
    
    <item>
      <title>라마누잔 합</title>
      <link>https://freshrimpsushi.github.io/posts/ramanujan-summation/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ramanujan-summation/</guid>
      <description>정의 발산하는 급수에 값을 매기는 것을 라마누잔 합이라 하고, 심볼 $\Re$ 을 통해 나타낸다. 정리 [1] 그란디 급수Grandi Series** 1: $$ 1-1+1-1+ \cdots = {{ 1 } \over { 2 }} \qquad ( \text{Re} ) $$ [2] $$ 1-2+3-4+ \cdots = {{ 1 } \over { 4 }} \qquad ( \text{Re} ) $$ [2]&amp;rsquo; $$ 1+2+3+4+ \cdots = - {{ 1 } \over { 12 }} \qquad ( \text{Re} ) $$ 설명 값이 존재하지 않으니 발산하지 거기다 값을 매긴다는 게 무슨 말인가 싶을 것이다. 우선은 수렴하지 않지만</description>
    </item>
    
    <item>
      <title>중심극한 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-central-limit-theorem/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-central-limit-theorem/</guid>
      <description>정리 1 ${X_n}$가 iid 확률 변수들이고 확률분포 $\left( \mu, \sigma^2 \right) $를 따른다고 하면 $n \to \infty$ 일 때 $$ \displaystyle \sqrt{n} {{ \overline{X}_n - \mu } \over {\sigma}} \overset{D}{\to} \text{N} (0,1) $$ $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 통계학에선 대수의 법칙과 더불어 정말 그 명성이 자자한 정리로 꼽힌다. 수없이 듣고 쓰는 정리지만 막상 증명은 수리통계학을 배우면서 한번 해볼까말까다. 하지만 실제로는 활용도를 떠나 증명 자체</description>
    </item>
    
    <item>
      <title>격자 모델 시뮬레이션 첫걸음: 히트맵으로 나타내기</title>
      <link>https://freshrimpsushi.github.io/posts/tutorial-on-lattice-model-simulation/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tutorial-on-lattice-model-simulation/</guid>
      <description>시뮬레이션 코드 리뷰 Step 1. 격자 공간 생성 julia&amp;gt; colormap\_SI = [colorant&amp;#34;#EEEEEE&amp;#34;, colorant&amp;#34;#111111&amp;#34;] julia&amp;gt; row\_size = 5 5 julia&amp;gt; column\_size = 5 5 julia&amp;gt; Random.seed!(3); julia&amp;gt; stage\_lattice = rand([&amp;#39;S&amp;#39;], row\_size, column\_size) 5×5 Array{Char,2}: &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; &amp;#39;S&amp;#39; 위의 코드는 $5 \times 5$ 크기의 빈 격자 공간을 만들고 랜덤한 위치 두 곳을 채운 것이다. 빈 공간은 문자 &#39;S&#39;, 채운 공간은 &#39;I&#39;로 표시되어있다. Step 2. 히트맵으로 플로팅 stage\_lattice[rand(1:row\_size), rand(1:column\_size)] = &amp;#39;I&amp;#39;; stage\_lattice figure = heatmap(reverse(stage\_lattice,dims=1), color=colormap\_SI, xaxis=false,yaxis=false,axis=nothing, size = [400,400], legend</description>
    </item>
    
    <item>
      <title>리만 제타 함수의 로랑 전개 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-laurent-expansion-of-riemann-zeta-function/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-laurent-expansion-of-riemann-zeta-function/</guid>
      <description>정리 리만 제타 함수 $\zeta$ 의 로랑 전개는 다음과 같다. $$ \zeta (s) = {{ 1 } \over { s-1 }} + \sum_{n=0}^{\infty} \gamma_{n} {{ (1-s)^{n} } \over { n! }} \qquad , s &amp;gt; 1 $$ 여기서 $\gamma_{n}$ 은 $n$번째 스틸체스 상수Stieltjes constants 로, 다음과 같이 정의된다. $$ \gamma_{n} := \lim_{m \to \infty} \sum_{k=1}^{m} \left( {{ \left( \log k \right)^{n} } \over { k }} - {{ \left( \log m \right)^{n} } \over { n+1 }} \right) $$ 설명 스틸체스 상수는 특히 $n=0$ 일 때 $\gamma_{0} = \gamma$ 로써 오일러-마스케로니 상수다. 이</description>
    </item>
    
    <item>
      <title>약한 대수의 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-weak-law-of-large-numbers/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-weak-law-of-large-numbers/</guid>
      <description>법칙 ${X_n}$가 iid 확률 변수들이고 확률분포 $\left( \mu, \sigma^2 \right) $를 따른다고 하면 $n \to \infty$ 일 때 $$ \overline{X}_n \overset{P}{\to} \mu $$ $\overset{P}{\to}$ 는확률 수렴을 의미한다. 설명 이 정리는 그 어떤 분포든 &amp;lsquo;표본평균은 모평균으로 수렴한다&amp;rsquo;는 팩트를 함의한다. 생각해보면 당연할 수도 있지만, 자연과학에서 &amp;lsquo;당연하다&amp;rsquo;는 말만큼 중요한</description>
    </item>
    
    <item>
      <title>해석적 연속</title>
      <link>https://freshrimpsushi.github.io/posts/analytic-continuation/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/analytic-continuation/</guid>
      <description>정의 1 해석적 함수 $f_{1}: \mathscr{R}_{1} \to \mathbb{C}$ 에 대해 $$ \mathscr{S} := \mathscr{R}_{1} \cap \mathscr{R}_{2} \ne \emptyset \\ f_{1} (z) = f_{2} (z) \qquad , z \in \mathscr{S} $$ 를 만족하면서 $\mathscr{R}_{2} \subset \mathbb{C}$ 에서 해석적 함수 $f_{2}: \mathscr{R}_{2} \to \mathbb{C}$ 가 존재하면 $f_{2}$ 가 $\mathscr{R}_{2}$ 에서 $f_{1}$ 의 해석적 연속Analytic Continuation이라고 부른다. 설명 글은 굉장히 어렵게 적혀있지만 정의를 잘 읽어보면 결국 특정 영역 $\mathscr{S}$ 에서 $f_{2}$ 가 $f_{1}$ 을 완벽하게 대신할 수 있는 해석적 함수</description>
    </item>
    
    <item>
      <title>분포수렴하면 확률유계다</title>
      <link>https://freshrimpsushi.github.io/posts/if-convergence-in-distribution-then-bounded-in-probability/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-convergence-in-distribution-then-bounded-in-probability/</guid>
      <description>정리 확률변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 분포수렴하면 확률유계다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 앞서 확률수렴하면 분포수렴함을 보였으므로, 이 대우 명제를 생각해보면 &amp;lsquo;확률유계가 아니면 확률수렴하지 않는다&amp;rsquo;는 상식적인 따름정리도 얻을 수 있다. 증명 $\epsilon&amp;gt;0$ 가 주어져 있고 $X_{n}$ 이 확률변수 $X$ 로 분포수렴하며 그 누적분포함수가 $F_{X}$</description>
    </item>
    
    <item>
      <title>해석적 함수</title>
      <link>https://freshrimpsushi.github.io/posts/analytic-funcion-regular-function-holomorphic-function/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/analytic-funcion-regular-function-holomorphic-function/</guid>
      <description>정의 열린 집합 $A \subset \mathbb{C}$ 과 $f: A \to \mathbb{C}$ 가 정의되어있고 $\alpha \in A$ 라고 하자. $\displaystyle \lim_{z \to \alpha } f(z) = f (\alpha)$ 면 $f$ 가 $\alpha$ 에서 연속이라고 하고 영역 $\mathscr{R}$ 의 모든 점에서 연속이면 $f$ 가 $\mathscr{R}$ 상에서 연속이라고 한다. 특히 $f$ 가 정의역 상에서 연속이면 연속함수라 부른다. 1 $\alpha$ 에서 $f$ 의 미분계수를 다음과 같이 정의하고, $\alpha$ 에서 미분계수가 존재하면 $f$ 가 $\alpha$ 에서 미분가능 하다고 한다. 2</description>
    </item>
    
    <item>
      <title>확률수렴하면 분포수렴한다</title>
      <link>https://freshrimpsushi.github.io/posts/if-convergence-in-probability-then-convergence-in-distribution/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-convergence-in-probability-then-convergence-in-distribution/</guid>
      <description>정리1 확률변수 $X$ 와 확률변수의 시퀀스 $\left\{ X_{n} \right\}$ 에 대해 $$ X_{n} \overset{P}{\to} X \implies X_{n} \overset{D}{\to} X $$ $\overset{P}{\to}$ 는 확률 수렴을 의미한다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 직관적인 단어로 다시 말하자면, 분포만 수렴하는 것이 정확히 수렴하는 것보다는 훨씬 쉽다는 말이다. 확률변수라는 것 자체를 함수로써 정확하게 이해하고 있다면 받아들이기 어렵지 않을 것이다. 증명 전략: 사건을 둘로</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 유계</title>
      <link>https://freshrimpsushi.github.io/posts/bounded-in-probability/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bounded-in-probability/</guid>
      <description>정의 1 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 주어져 있다고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 다음을 만족시키는 $N_{\varepsilon} \in \mathbb{N}$ 과 상수 $B_{\varepsilon} &amp;gt; 0$ 가 존재하면 $\left\{ X_{n} \right\}$ 가 확률 유계Bounded in Probability라고 한다. $$ n \ge N_{\varepsilon} \implies P \left[ \left| X_{n} \right| \le B_{\varepsilon} \right] \ge 1 - \varepsilon $$ 설명 생각해보면 일상생활에서 실제로 접하는 많은 확률 분포 함수들의 정의역이 무한히 넓다. 표준정규분포 $N(0,1)$</description>
    </item>
    
    <item>
      <title>스튜던트 t-분포의 극한분포로써 표준정규분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-t-distribution/</link>
      <pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-t-distribution/</guid>
      <description>정리 $T_n \sim t(n)$ 이면 $$ T_n \ \overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. $t(r)$ 은 자유도 $r$ 인 t-분포다. $\overset{D}{\to}$ 는 각각 분포 수렴을 의미한다. 애초에 스튜던트 t분포는 표본이 작을 때 통계적 분석을 하기 위해 태어났다. 표본의 크기가 커지면 표준정규분포와 비슷해지는데, 통계학적인 용어로는 분포수렴한다고 말한다. 따라서 별다른 과정이 없더라</description>
    </item>
    
    <item>
      <title>줄리아에서 16진법 RGB 코드 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-hex-rgb-code-in-julia/</link>
      <pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-hex-rgb-code-in-julia/</guid>
      <description>코드 줄리아에서는 rgb() 함수를 사용해서 0부터 1까지의 숫자로 색상을 만드는 법도 있지만 보통 색은 16진법으로 쓰게 편하기 때문에 함수보다 문자열로 바로 넣는 게 낫다. 대개의 언어는 문자열로 &amp;quot;#000000&amp;quot;를 쓰면 바로 검은색이 표현되지만, 줄리아의 경우엔 앞에 colorant를 붙여 명시해주어야한다. using Plots histogram(randn(100), color = colorant&amp;#34;#6666FF&amp;#34;)</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터프레임과 2차원배열 간 변환 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-convert-between-dataframe-and-2-dimensional-array/</link>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-convert-between-dataframe-and-2-dimensional-array/</guid>
      <description>코드 줄리아에서는 다음과 같이 convert() 함수를 통해 간단하게 데이터프레임과 2차원배열 사이를 오갈 수 있다. 이 함수는 물론 다른 자료형에 대해서도 유용하게 사용된다. data1 = rand(4,3) data2 = convert(DataFrame, data1) data3 = convert(Array, data2) 실행결과는 다음과 같다.</description>
    </item>
    
    <item>
      <title>푸아송분포의 극한분포로써 표준정규분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-poisson-distribution/</link>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-poisson-distribution/</guid>
      <description>정리 $X_{n} \sim \text{Poi} \left( n \right)$ 이고 $\displaystyle Y_{n} := {{ X_{n} - n } \over { \sqrt{n} }}$ 이면 $$ Y_{n} \overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. $\text{Poi} (\lambda)$ 는 평균과 분산이 $\lambda$ 인 푸아송 분포다. 설명 이항분포의 푸아송분포 근사를 생각해보면 당연하겠지만, 푸아송분포에서 역시 표준정규분포를 유도될 수 있다. 유도1 $Y_{n}$ 의 적률생성함수 $M_{Y_{n}} (t)$ 를 통해 분포수렴함을 보인다. 푸아송 분</description>
    </item>
    
    <item>
      <title>리만 가설</title>
      <link>https://freshrimpsushi.github.io/posts/riemman-hypothesis/</link>
      <pubDate>Sun, 24 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riemman-hypothesis/</guid>
      <description>추측 $\zeta (s) = 0$ 을 만족하는 모든 비자명 해 $s$ 는 $\displaystyle \text{Re} (s) = {{ 1 } \over { 2 }}$ 를 만족할 것이다. $\zeta$ 는 리만 제타 함수다. $\Re(z)$ 는 복소수 $z \in \mathbb{C}$ 의 실수부를 의미한다. 설명 리만 가설은 아직까지 풀리지 않은 밀레니엄 문제로써, 수학에 익숙하지 않은 비전공자라면 그 의미는 물론 말 자체를 이해하기 어려울 것이다. 이 가설은 참인 것으로 증명될 경우 덩달아 참인걸로 밝혀</description>
    </item>
    
    <item>
      <title>줄리아에서 *.csv 파일 읽어들이는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-csv-files-in-julia/</link>
      <pubDate>Sun, 24 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-csv-files-in-julia/</guid>
      <description>가이드 사실 줄리아는 아직 데이터 입력 면에서 특출나게 편리한 언어는 아니다. 그래도 빠른 속도를 원한다면 파이썬이나 R, matlab보다 줄리아를 선택해야하는 순간이 올 수도 있을 것이다. 가령 위와 같이 E 드라이브 바로 밑에 있는 *.csv파일을 불러들인다고 하면 다음과 같이 입력하면 된다. using CSV data = CSV.read(&amp;#34;E:/example.csv&amp;#34;) 실행 결과를 보면 *.csv파일이 데이터프</description>
    </item>
    
    <item>
      <title>로지스틱 성장 모델: 집단 성장의 한계</title>
      <link>https://freshrimpsushi.github.io/posts/logistic-growth-model/</link>
      <pubDate>Sat, 23 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logistic-growth-model/</guid>
      <description>모델 $$ N&amp;rsquo; = {{ r } \over { K }} N ( K - N) $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 파라메터 $r \in \mathbb{R}$ : 고유 성장률Intrinsic Rate of Increase로써, $0$ 보다 크면 성장하고 $0$ 보다 작으면 쇠퇴한다. 번식률Birth Rate $b$ 와 사망률Death Rate $d$ 의 차 $r:=b-d$ 로 정의되기도 한다. $K$: 환경 용량Carrying Capacity으로,</description>
    </item>
    
    <item>
      <title>윈도우에서 줄리아 병렬연산 시 사용하는 쓰레드 수 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-the-number-of-thread-in-windows/</link>
      <pubDate>Sat, 23 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-the-number-of-thread-in-windows/</guid>
      <description>가이드 줄리아에서는 병렬 연산을 일상적으로 사용하기 때문에 경우에 따라서는 컴퓨터의 모든 소스를 계산에 집중할 필요가 있다. 이때 쓰레드 수를 바꾸는 방법은 여러가지가 있겠지만 가장 스태틱하고 편한 방법은 환경 변수를 편집하는 것이다. Step 1. 시스템 환경 변수 편집 윈도키 혹은 윈도+S를 눌러 &amp;lsquo;시스템 환경 변수 편집&amp;rsquo;을 찾는</description>
    </item>
    
    <item>
      <title>이항분포의 극한분포로써 표준정규분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-binomial-distribution/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/standard-normal-distribution-as-limiting-distribution-of-binomial-distribution/</guid>
      <description>정리 $X_i \sim B(1,p)$ 이고 $Y_n = X_1 + X_2 + \cdots + X_n$ 이라고 하면 $Y_n \sim B(n,p)$ 이고 $$ { { Y_n - np } \over {\sqrt{ np(1-p) } } }\overset{D}{\to} N(0,1) $$ $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. $B(n,p)$ 은 시행 $n$ 번에 확률 $p$ 인 이항 분포다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 통계를 처음 접할때부터 이항분포의 표본이 커지면 정규분포에 근사함을 배워왔다. 경험적으로도 당연하고 증명 과정이 큰 의미를 갖</description>
    </item>
    
    <item>
      <title>줄리아에서 실행되는 코드 파일의 위치 확인하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-the-directory-of-julia-code-file/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-the-directory-of-julia-code-file/</guid>
      <description>가이드 줄리아를 사용하는 사람이라면 서버를 포함해서 여러 운영 체제나 여러 컴퓨터를 사용하는 것에 익숙할 가능성이 높다. 만약 파일 입출력이 있다면 개발환경이 달라질때마다 그 경로를 잡아주는 것이 무척 번거로울 수 있다. 이를 해결해주는 것이 바로 @__DIR__ 매크로다. 가령 다음과 같은 줄리아 코드 파일이 있다고 하자. 기본적으로 터미널에서 실행하면 pwd(</description>
    </item>
    
    <item>
      <title>리눅스에서 줄리아 병렬연산 시 사용하는 쓰레드 수 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-the-number-of-thread-in-linux/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-the-number-of-thread-in-linux/</guid>
      <description>가이드 줄리아에서는 병렬 연산을 일상적으로 사용하기 때문에 경우에 따라서는 컴퓨터의 모든 소스를 계산에 집중할 필요가 있다. 이때 쓰레드 수를 바꾸는 방법은 여러가지가 있겠지만 가장 스태틱하고 편한 방법은 환경 변수를 편집하는 것이다. Step 1. 시스템 환경 변수 편집 Ctrl + Alt + T 를 눌러 터미널을 열고 gedit ~/.bashrc를 입력한다. 그러면 다음과 같이</description>
    </item>
    
    <item>
      <title>이항분포의 극한분포로써 푸아송분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-distribution-as-limiting-distribution-of-binomial-distribution/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-distribution-as-limiting-distribution-of-binomial-distribution/</guid>
      <description>정리 $X_{n} \sim B(n,p)$이라고 하자. $\mu \approx np$ 이면 $$ X_{n} \overset{D}{\to} \text{Poi} (\mu) $$ $B(n,p)$ 은 시행 $n$ 번에 확률 $p$ 인 이항 분포다. $\text{Poi} (\lambda)$ 는 평균과 분산이 $\lambda$ 인 푸아송 분포다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 여기엔 $\mu \approx np$ 이라는 조건이 필요한 것에 주목하자. $ np \approx npq$ 이므로 $q = (1-p) \approx 1$ 즉, $p \approx 0$ 이다. 이는 $p$가 아주 작은 것을 뜻한다. 한편 $\displaystyle p \approx { {\mu} \over {n} }$ 이므로 $n</description>
    </item>
    
    <item>
      <title>줄리아에서 합성함수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-function-composition-in-julia/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-function-composition-in-julia/</guid>
      <description>코드 julia&amp;gt; f(x) = 2x + 1 f (generic function with 1 method) julia&amp;gt; g(x) = x^2 g (generic function with 1 method) julia&amp;gt; (g ∘ f)(3) 49 설명 줄리아에서 함수의 합성은 프로그래밍적으로는 파이프 오퍼레이터와 흡사하다. 이러한 합성이 가능함으로써 가장 큰 이점은 수학자의 입장에서 수식을 코드로 표현하기가 쉬워진다는 것이다. 위 예시는 단지 다음의 수식을 코드로 옮긴 것에 불과하다. $$ f(x) := 2x + 1 \\ g(x) := x^2 \\ (g \circ f) (3)</description>
    </item>
    
    <item>
      <title>수리통계학에서의 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution/</guid>
      <description>정의 1 확률변수 $X$ 와 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $X_{n}$ 이 $X$ 로 분포 수렴Convergence in Distribution한다고 말하고, $X_{n} \overset{D}{\to} X$ 와 같이 나타낸다. $$ \lim_{n \to \infty} F_{X_{n}} (x) = F_{X} (x) \qquad, \forall x \in C_{F_{X}} $$ $F_{X}$ 는 확률변수 $X$ 의 누적분포함수다. $C_{F_{X}}$ 는 함수 $F_{X}$ 가 연속인 점들의 집합을 나타낸다. 설명 분포 수렴은 확률 수렴과 마찬가지</description>
    </item>
    
    <item>
      <title>에이전트 기반 모델 시뮬레이션에서의 사망</title>
      <link>https://freshrimpsushi.github.io/posts/death-in-agent-based-simulation-model/</link>
      <pubDate>Sat, 16 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/death-in-agent-based-simulation-model/</guid>
      <description>시뮬레이션 이 포스트에서는 생성된 에이전트가 사망하는 액션을 주어 거시적인 관점에서 집단의 역성장을 모방하려고 한다. 이 시뮬레이션에서 공간이나 이동에 관련된 모든 것들은 단지 시각화를 위한 것이며, 실제 목적과는 아무런 관계가 없다. 변수 $t$: 현재 턴을 의미한다. $N(t)$: $t$ 턴에서 에이전트의 수를 나타낸다. 파라메터 $N_{0} \in \mathbb{N}$: 시뮬레이션이 시작할 때 에이</description>
    </item>
    
    <item>
      <title>에이전트 기반 모델 시뮬레이션에서의 번식</title>
      <link>https://freshrimpsushi.github.io/posts/reproduction-in-agent-based-simulation-model/</link>
      <pubDate>Tue, 12 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reproduction-in-agent-based-simulation-model/</guid>
      <description>시뮬레이션 이 포스트에서는 생성된 에이전트에게 스스로 복제하는 액션을 주어 거시적인 관점에서 집단의 성장을 모방하려고 한다. 이 시뮬레이션에서 공간이나 이동에 관련된 모든 것들은 단지 시각화를 위한 것이며, 실제 목적과는 아무런 관계가 없다. 변수 $t$: 현재 턴을 의미한다. $N(t)$: $t$ 턴에서 에이전트의 수를 나타낸다. 파라메터 $N_{0} \in \mathbb{N}$: 시뮬레이션이 시작할</description>
    </item>
    
    <item>
      <title>서열정렬 점수와 갭 페널티</title>
      <link>https://freshrimpsushi.github.io/posts/sequence-alignment-score-and-gap-penalty/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sequence-alignment-score-and-gap-penalty/</guid>
      <description>정의 레퍼런스 서열과 쿼리 서열이 주어져 있다고 하자. 서열정렬 점수Sequence Alignment Score란 두 서열을 비교했을 때 얼마나 일치하는지를 수치화하는 것과 그 방법을 말한다. 점수화는 다음과 같은 사항들에 가중치를 주어 계산된다. Match: 두 서열이 일치하는 횟수다. Mismatch: 두 서열이 일치하지 않는 횟수다. 예시 예로써 위와 같은 두 염기서열이 있다고 하자.</description>
    </item>
    
    <item>
      <title>서열정렬에서의 치환행렬</title>
      <link>https://freshrimpsushi.github.io/posts/substitution-matrix/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/substitution-matrix/</guid>
      <description>정의 서열정렬 점수를 매길 때 매치와 미스매치의 기준이 되는 행렬을 치환행렬Substitution Matrix이라 한다. 예시 using BioAlignments EDNAFULL BLOSUM45 PAM30 거두절미하고 예시부터 보자. 줄리아에서는 BioAlignments라는 패키지가 나와있고 손쉽게 원하는 치환행렬을 불러들일 수 있다. DNA 분석에 자주 사용되는 EDNAFULL나 단백질 서열에 쓰이</description>
    </item>
    
    <item>
      <title>벡터의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-vector/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-vector/</guid>
      <description>정의 수의 나열을 벡터라 한다. 설명 보통 교과과정에서 벡터는 &amp;lsquo;크기와 방향을 가진 기하학적 객체&amp;rsquo;로 배우게 된다. 아무래도 물리학에서 가장 먼저 접하게 되는 개념이다보니 다음과 같은 $3$차원 이하의 벡터에 친숙할수밖에 없다. $$ (3,4) = \begin{bmatrix} 3 \\ 4 \end{bmatrix} \\ (x,y,z) = \begin{bmatrix} x \\ y \\ z \end{bmatrix} $$ 그런데 사실 벡터는 그보다 더 많은 좌표에 대해 일반</description>
    </item>
    
    <item>
      <title>에이전트 기반 시뮬레이션 첫걸음: 산점도로 나타내기</title>
      <link>https://freshrimpsushi.github.io/posts/tutorial-on-agent-based-simulation/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tutorial-on-agent-based-simulation/</guid>
      <description>시뮬레이션 코드 리뷰 Step 1. 패키지 로드, 초기값 설정 julia&amp;gt; cd(@\_\_DIR\_\_) # 파일 저장 경로cd(@\_\_DIR\_\_) # 파일 저장 경로 julia&amp;gt; @time using Plots 19.989912 seconds (31.16 M allocations: 1.628 GiB, 4.49% gc Time) julia&amp;gt; @time using Random 0.034412 seconds (33.81 k allocations: 1.722 MiB) julia&amp;gt; @time using Distributions 3.436091 seconds (2.74 M allocations: 156.074 MiB, 0.90% gc Time) julia&amp;gt; @time using LinearAlgebra 0.009646 seconds (1.23 k allocations: 77.531 KiB) julia&amp;gt; N0 = 10 # 초기 인구수 10 julia&amp;gt; gaussian2 = MvNormal([0.0; 0.0], 0.02I) # 2차원 정규분포 IsoNormal( dim: 2 μ: [0.0, 0.0] Σ: [0.02 0.0; 0.0 0.02] ) 위의 코드는 패키</description>
    </item>
    
    <item>
      <title>서열정렬이란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-sequence-alignment/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-sequence-alignment/</guid>
      <description>정의 염기서열 간의 유사도를 근거로 나열하는 것을 서열정렬Sequence Alignment이라 한다. 1 설명 생명정보공학에서 유전체의 길이는 무척 길기 때문에 이를 데이터화하는 것부터가 엄청난 일이다. 상상하기에는 우리도 중합효소처럼 DNA의 상류부터 하류까지 순서대로 읽으면서 저장하면 좋을 것 같지만, 현실적으로는 그렇게 할 수가 없</description>
    </item>
    
    <item>
      <title>동역학적 모델 시뮬레이션</title>
      <link>https://freshrimpsushi.github.io/posts/dynamical-model-simulation/</link>
      <pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamical-model-simulation/</guid>
      <description>설명 위의 움짤은 멜서스 성장 모델을 에이전트 기반 시뮬레이션으로 시각화한 것이다. 시뮬레이션Simulation이란 현상을 설명하는 모델을 가상으로 구현해 실험하는 것을 말하며, 동역학적 모델이라는 맥락에서 시뮬레이션은 흔히 다음과 같은 방법들을 말한다: Agent based Model: 에이전트 기반 모델은 거시세계를 모방하는 모델을 각 행위자(에이전트)의 미</description>
    </item>
    
    <item>
      <title>문자열의 편집 거리</title>
      <link>https://freshrimpsushi.github.io/posts/edit-distance-of-strings/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/edit-distance-of-strings/</guid>
      <description>빌드업 1 문자열에는 다음과 같이 네가지 작용이 있다: 삽입: 문자열에 새로운 문자를 끼워넣는다. 제거: 문자열에서 문자 하나를 없앤다. 교체: 문자열에서 문자 하나를 다른 문자로 바꾼다. 전치: 두 문자의 위치를 서로 바꾼다. 정의 편집 거리는 문자열간의 거리 함수로써 편집 방법을 허용하거나 금지함으로써 다음과 같은 타입들로 구분된다: (1) Hamming distance: 해밍</description>
    </item>
    
    <item>
      <title>mine</title>
      <link>https://freshrimpsushi.github.io/posts/mine/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mine/</guid>
      <description></description>
    </item>
    
    <item>
      <title>세미나</title>
      <link>https://freshrimpsushi.github.io/posts/seminar/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/seminar/</guid>
      <description>220404 Classification strategies in machine learning techniques predicting regime changes and durations in the Lorenz system Google Drive 원드라이브 묵찌빠 공간 가위바위보 집합 $$ \begin{align*} 2 \le_{X} 0 \\ 5 \le_{X} 2 \\ 0 \le_{X} 5 \end{align*} $$ 위의 이항관계 $\le_{X}$가 정의되는 가위바위보 집합RPS Set $X := \left\{ 0,2,5 \right\}$ 를 생각해보자. 여기서 $\le_{X}$ 는 반사적이고 반대칭적이다. 다시 말해, 모든 $x \in X$ 에 대해 다음이 성립한다. $$ x \le_{X} x \\ x \le_{X} y \land y \le_{X} x \implies x = y $$ 여기</description>
    </item>
    
    <item>
      <title>맬서스 성장 모델: 이상적인 집단 성장</title>
      <link>https://freshrimpsushi.github.io/posts/malthusian-growth-model/</link>
      <pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/malthusian-growth-model/</guid>
      <description>모델 $$ N &amp;rsquo; = rN $$ 변수 $N(t)$: $t$ 시점에서 집단의 개체수를 나타낸다. 파라메터 $r \in \mathbb{R}$ : 고유 성장률Intrinsic Rate of Increase로써, $0$ 보다 크면 성장하고 $0$ 보다 작으면 쇠퇴한다. 번식률Birth Rate $b$ 와 사망률Death Rate $d$ 의 차 $r:=b-d$ 로 정의되기도 한다. 설명 인구 동역학Population Dynamics은 동역학이 수리생물</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 유전체와 유전자</title>
      <link>https://freshrimpsushi.github.io/posts/genome-and-gene-in-bioinformatics/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/genome-and-gene-in-bioinformatics/</guid>
      <description>정의 한 개체의 염기서열을 모두 모은 것을 유전체Genome라고 한다. 유전체의 일부를 차지하는 구간으로, 유전 형질의 단위가 되는 것을 유전자Gene라고 한다. 특히 진핵생물에서는 인트론과 엑손으로 이루어져있다. 설명 사실 genome에 대해 유전체라는 순화는 거의 쓰이지 않고, 게놈 혹은 지놈으로 부르는게 보통이다. 지놈과 유전자는, 특</description>
    </item>
    
    <item>
      <title>줄리아에서 움짤 찌는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-gif-animation-in-julia/</link>
      <pubDate>Sun, 27 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-gif-animation-in-julia/</guid>
      <description>코드 원래 생새우초밥집에서는 이보다는 훨씬 자세한 설명을 추가하는 편이지만, 줄리아에서 움짤을 찌는 게 얼마나 쉬운지를 강조하기 위해 가능한한 짧게 설명하도록 하겠다. 위와 같은 랜덤 워크를 시뮬레이션하는 건 둘째치더라도, 위와 같이 움짤로 만드는 것은 언어에 따라 아주 어렵고 힘들 수 있다. 그러나 줄리아에서는 @animate 매크로와 gif() 함수를 통해 어마어마하</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 인트론과 엑손</title>
      <link>https://freshrimpsushi.github.io/posts/intron-and-exon-in-bioinformatics/</link>
      <pubDate>Fri, 25 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/intron-and-exon-in-bioinformatics/</guid>
      <description>정의 진핵 생물의 DNA에서 실제로 단백질의 합성에 관여하는 부분을 엑손Exon, 그렇지 않은 부분을 인트론Intron이라고 한다. 설명 원핵 생물과 진핵 생물은 세포핵에 핵막이 있냐 없느냐로 구분되지만, 생명정보공학의 관점에서 중요한 차이점은 센트럴 도그마에 의해 mRNA가 전사되고 난 뒤의 스플라이싱Splicing이라는 과정이 있느</description>
    </item>
    
    <item>
      <title>R 파일 읽기나 경로 변경 시 Error: &#39;C:\U&#39; used without hex digits in character string starting &#39;C:\U&#39; 해결</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-fix-error-used-without-hex-digits-in-character-string-starting/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-fix-error-used-without-hex-digits-in-character-string-starting/</guid>
      <description>해결만을 위한다면 어떻게 수정하는지만 봐도 되는데, 원리를 알고 다시는 같은 에러를 겪고 싶지 않다면 모두 읽는 것을 추천한다. 에러 진단 가령 바탕화면에 위와 같이 exampe.csv 파일을 읽고싶다고 할 때, 다음과 같은 에러가 뜨는 경우가 있다. Error: &amp;#39;\U&amp;#39; used without hex digits in character string starting &amp;#34;&amp;#34;C:\U&amp;#34; 아무리 봐도 모든 경로에 문제가 없기 때문에 이런 저런 시도를 하다가 &amp;lsquo;바탕 화면&amp;rs</description>
    </item>
    
    <item>
      <title>염기서열의 상류와 하류</title>
      <link>https://freshrimpsushi.github.io/posts/upstream-and-downstream-of-nucleic-sequence/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/upstream-and-downstream-of-nucleic-sequence/</guid>
      <description>빌드업 1 염기서열의 방향은 위의 그림처럼 오탄당의 탄소 원자 위치에 따라 번호를 부여함으로써 나타낼 수 있다. RNA와 DNA는 구체적으로 3번 탄소 $3&amp;rsquo;$와 5번 탄소 $5&amp;rsquo;$가 인산에스터 결합Phosphodiester Bond을 형성함으로써 사슬 구조를 이룬다. 가령 네 개의 염기가 다음과 같이 탄소 위치와 함</description>
    </item>
    
    <item>
      <title>딥러닝의 수학적 근거, 시벤코 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cybenko-theorem/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cybenko-theorem/</guid>
      <description>정리 $\sigma$ 가 연속 시그모이달 함수라고 하면 $$ S := \left\{ G(x) = \sum_{k=1}^{N} \alpha_{k} \sigma \left( y_{k}^{T} x+ \theta_{k} \right) : y_{k} \in \mathbb{R}^{n} \land \alpha_{k} , \theta_{k} \in \mathbb{R} \land N \in \mathbb{N} \right\} $$ 는 $C\left( I_{n} \right)$ 에서 균등 조밀하다. 달리 말하자면, 모든 $f \in C \left( I_{n} \right)$ 과 $\varepsilon &amp;gt; 0$ 에 대해 다음을 만족하는 $G \in S$ 가 존재한다. $$ \left\| G - f \right\| &amp;lt; \varepsilon $$ 다음을 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 을 시그모이달 함수라 한다. $$ \sigma (t) \to \begin{cases} 1 &amp;amp; \text{as } t \to + \infty \\ 0 &amp;amp; \text{as</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 코돈과 아미노산 유전 부호</title>
      <link>https://freshrimpsushi.github.io/posts/codon-amino-acid-genetic-code/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/codon-amino-acid-genetic-code/</guid>
      <description>정의 DNA의 염기 3개를 순서쌍으로 묶은 단위를 트리플렛 코드Triplet Code라 한다. 센트럴 도그마에 따라 전사된 mRNA의 트리플렛 코드를 코돈Codon이라 한다. 화학적으로 아미노기와 카복시기를 포함한 분자로, 단백질의 구성 단위를 아미노산Amino Acid이라 부른다. 코돈의 순열에 따라 아미노산의 대응관계를 유전 부호</description>
    </item>
    
    <item>
      <title>시그모이달 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-sigmoidal-function/</link>
      <pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-sigmoidal-function/</guid>
      <description>정의 다음을 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 을 시그모이달 함수Sigmoidal Function라 한다. $$ \sigma (t) \to \begin{cases} 1 &amp;amp; \text{as } t \to + \infty \\ 0 &amp;amp; \text{as } t \to - \infty \end{cases} $$ 정의에 대한 설명 시그모이달 함수의 정의에서 $0$ 이나 $1$ 이냐는 것은 사실 별로 중요하지 않고, 양이든 음이든 무한대로 갈 때 상수로 수렴한다는 것이 중요하다. 무한대가 아닌 곳에서 어떤 값을 가지</description>
    </item>
    
    <item>
      <title>분자생물학의 중심원리</title>
      <link>https://freshrimpsushi.github.io/posts/central-dogma-of-molecular-biology/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/central-dogma-of-molecular-biology/</guid>
      <description>원리 분자생물학의 중심원리 혹은 센트럴 도그마Central Dogma란 유전 정보는 DNA에서 RNA로, RNA에서 단백질로 전달된다는 가설로써 다음과 같은 세 가지 현상으로 이루어져있다. 복제: DNA는 스스로 복제된다. 전사: DNA와 같은 정보를 담은 RNA가 만들어진다. 번역: RNA의 정보에 따라 단백질이 합성된다. 설명 센트럴</description>
    </item>
    
    <item>
      <title>차별 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-discriminatory-function/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-discriminatory-function/</guid>
      <description>정의 모든 $y \in \mathbb{R}^{n}$ 과 $\theta \in \mathbb{R}$ 와 어떤 $\mu \in M \left( I_{n} \right)$ 에 대해 $$ \int_{I_{n}} \sigma \left( y^{T} x + \theta \right) d \mu (x) = 0 \implies \mu =0 $$ 를 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 를 차별적 함수Discriminatory Function라 한다. $I_{n} := [0,1]^{n}$ 는 $n$차원 유닛 큐브로써, $n$ 개의 단위폐구간 $[0,1]$ 에 데카르트 곱을 취한 것이다. $M \left( I_{n} \right)$ 는 $I_{n} := [0,1]^{n}$ 에서 정의되는 부호 유한 정칙 보렐 측도의 집합</description>
    </item>
    
    <item>
      <title>정칙 측도</title>
      <link>https://freshrimpsushi.github.io/posts/regular-measure/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regular-measure/</guid>
      <description>정의: 측도의 정칙성 1 $\mu$ 가 가측 공간 $(X, \Sigma)$ 에서 정의된 측도라고 하자. $\mu$ 에 대해 가측 집합 $A \in \Sigma$ 가 다음을 만족하면 내적 정칙Inner Regular이라 한다. $$ \mu (A) = \sup \left\{ \mu (F) : F \subset A, F \in \Sigma \text{ is compact} \right\} $$ $\mu$ 에 대해 가측 집합 $A \in \Sigma$ 가 다음을 만족하면 외적 정칙Outer Regular이라 한다. $$ \mu (A) = \inf \left\{ \mu (G) : G \supset A, G \in \Sigma \text{ is open} \right\} $$</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 주요 염기와 염기쌍</title>
      <link>https://freshrimpsushi.github.io/posts/canonical-base-and-pair/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/canonical-base-and-pair/</guid>
      <description>정의 다음의 다섯가지 염기를 주요 염기Canonical Base라고 한다. 퓨린 염기: 아데닌Adenin $A$, 구아닌Guanine $G$ 피리미딘 염기: 사이토신Cytosine $C$, 티민Thymine $T$, 유라실Uracil $U$ 설명 티민은 DNA에서만 사용되며, 유라실은 RNA에서만 사용된다. 따라서 데이터에서 $T$ 와 $U$ 중 어느 것이 쓰이는</description>
    </item>
    
    <item>
      <title>라살 불변 원리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lasalle-invariance-principle/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lasalle-invariance-principle/</guid>
      <description>원리 빌드업 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 플로우 $\phi_t \left( \cdot \right)$ 하에서의 컴팩트 양불변집합을 $\mathcal{M} \subset \mathbb{R}^{n}$ 이라 하자. $\mathcal{M}$ 에서 랴푸노프 함수 $V : \mathcal{M} \to \mathbb{R}$ 가 정의되어 있다고 할 때, 다음의 두 집합을 생각해보자. $$ E := \left\{ x \in \mathcal{M} : V&amp;rsquo;(x) = 0 \right\} $$ 이 $E$ 에 대해 다음과 같이 정의된 집합 $M$ 을 양불변부</description>
    </item>
    
    <item>
      <title>어트랙팅 셋의 베이신</title>
      <link>https://freshrimpsushi.github.io/posts/basin-of-attracting-set/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/basin-of-attracting-set/</guid>
      <description>정의 1 공간 $X$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $\phi(t, \cdot)$ 은 벡터 필드 $x&#39; = f(x)$ 의 플로우, $g^{n}$ 는 맵 $g$ 를 $n$ 번 취한 맵을 나타내도록 하자.다음과 같이 정의된 집합들을 어트랙팅 셋 $A$ 의 베이신Basin이라고 한다. Vector Field $$\displaystyle \bigcup_{t \le 0} \phi ( t, U )$$ Map $$\displaystyle \bigcup_{n \le 0} g^{n} ( U )$$ 설명 베이신은 우리에게 익숙한 단어가 아</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 염기서열</title>
      <link>https://freshrimpsushi.github.io/posts/nucleic-sequence-in-bioinformatics/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/nucleic-sequence-in-bioinformatics/</guid>
      <description>빌드업 화학적 합성에 의해 단위체가 반복되어 연결된 고분자를 중합체Polymer라고 한다. 인산Phosphoric Acid은 무기 산소산의 일종으로, 화학식은 $H_{3}PO_{4}$이다. 5개의 탄소 원자를 갖는 단당류를 오탄당Pentose이라 한다. 유전 정보의 기본단위로써 기능하는 분자를 질소 염기Nitrogenou</description>
    </item>
    
    <item>
      <title>동역학에서의 어트랙터</title>
      <link>https://freshrimpsushi.github.io/posts/attractor-in-dynamics/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/attractor-in-dynamics/</guid>
      <description>빌드업 공간 $X$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $\phi(t, \cdot)$ 은 벡터 필드 $x&#39; = f(x)$ 의 플로우, $g^{n}$ 는 맵 $g$ 를 $n$ 번 취한 맵을 나타내도록 하자. 넌원더링의 정의1 넌원더링Nonwandering한 점 $x_{0} \in X$ 이 다음의 조건을 만족하면 넌원더링 포인트라 하고, 그 집합을 넌원더링 셋이라 한다. (V): $x_{0}$ 의 모든</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 DNA, RNA, 염색체</title>
      <link>https://freshrimpsushi.github.io/posts/dna-rna-chromosome-in-bioinformatics/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dna-rna-chromosome-in-bioinformatics/</guid>
      <description>빌드업 화학적 합성에 의해 단위체가 반복되어 연결된 고분자를 중합체Polymer라고 한다. 인산Phosphoric Acid은 무기 산소산의 일종으로, 화학식은 $H_{3}PO_{4}$이다. 5개의 탄소 원자를 갖는 단당류를 오탄당Pentose이라 한다. 유전 정보의 기본단위로써 기능하는 분자를 질소 염기Nitrogenou</description>
    </item>
    
    <item>
      <title>자율 시스템의 오메가 리미트 셋</title>
      <link>https://freshrimpsushi.github.io/posts/omega-limit-set-of-autonomous-system/</link>
      <pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/omega-limit-set-of-autonomous-system/</guid>
      <description>정의 거리 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 이 벡터 필드의 플로우 $\phi ( t, x )$ 와 한 점 $x_{0} \in X$ 에 대해, $t_{i} \to \infty$ 일 때 $$ \phi \left( t_{i} , x_{0} \right) \to x $$ 을 만족하는 시간의 시퀀스 $\left\{ t_{i} \right\} \subset \mathbb{R}$ 이 존재하면 $ x \in X$ 를 $x_{0}$ 의 오메가 리미트 포인트라 한다. $x_{0}$ 의 오메가 리미트 포인트의 집합을 $x_{0}$ 의 오메가 리</description>
    </item>
    
    <item>
      <title>생명정보공학에서의 원핵 생물과 진핵 생물</title>
      <link>https://freshrimpsushi.github.io/posts/prokaryotes-and-eukaryotes/</link>
      <pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prokaryotes-and-eukaryotes/</guid>
      <description>정의 핵막이 없는 생물을 원핵 생물Prokaryotes이라 한다. 핵막이 있는 핵으로 이루어진 생물을 진핵 생물Eukaryotes이라 한다. 설명 진핵 생물에서는 유전 물질을 지니는 부분인 세포핵Nucleus과 각종 대사가 일어나는 세포질Cytoplasm이 핵막Nuclear Envelope에 의해 구분되지만 원핵 세포는 핵양체</description>
    </item>
    
    <item>
      <title>줄리아에서 거리 행렬 계산하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-calculate-a-distance-matrix-in-julia/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-calculate-a-distance-matrix-in-julia/</guid>
      <description>개요 거리 행렬Distance Matrix은 파티클 다이나믹스Particle Dynamics 및 무빙 에이전트Moving Agent 기반 시뮬레이션 등에 흔히 사용되나, 막상 찾아보면 딱 정리된 함수로는 없고 직접 계산하는 코드를 짜려면 막막한 게 보통이다. 줄리아에서는 pairwise() 와 Distances 패키지의 Euclidean() 함수를 사용해서 다음과 같이 손쉽게 거리 행렬을 계산할 수 있다. 1 dims 옵션</description>
    </item>
    
    <item>
      <title>푸앙카레 재귀 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-poincare-recurrence-theorem/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-poincare-recurrence-theorem/</guid>
      <description>정리 유클리드 공간에서 정의된 다차원 맵 $g : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 이 단사면서 연속이고 $D \subset \mathbb{R}^{n}$ 이 컴팩트 불변 집합, 다시 말해 $g(D) = D$ 라고 하자. 임의의 $\overline{x} \in D$ 의 임의의 근방을 $U$ 라고 하면 어떤 $n \in$ 에 대해 $g^{n} (x) \in U$ 가 되게끔 하는 $x \in U$ 가 존재한다. 설명 스테이트먼트는 단순한데, $D$ 가 컴팩트 불변 집합이면 그 안에서 $U$ 를 잡았을 때 $U$ 에서 잠깐은 벗어날 수 없어도 결국은</description>
    </item>
    
    <item>
      <title>줄리아에서 빈 배열 만드는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-empty-array-in-julia/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-empty-array-in-julia/</guid>
      <description>코드 크기 지정 julia&amp;gt; empty = Array{Float64, 2}(undef, 3, 4) 3×4 Array{Float64,2}: 3.39519e-313 3.18299e-313 4.66839e-313 1.061e-313 4.03179e-313 5.51719e-313 1.6976e-313 4.24399e-314 2.97079e-313 4.66839e-313 7.00259e-313 5.0e-324 위의 코드를 실행시키면 빈 배열이 만들어진다. 간혹 1.76297e-315처럼 이상한 값이 들어가는 것처럼 보이기도 하지만 이는 0에 아주 가까운 값으로써 초기화엔 큰 문제가 없다. Array{X, Y}(undef, ...)는 자료형 X로 Y차원 배열을 자료형에 해당하는 미정값으로 사이즈 ...만큼 채운 배</description>
    </item>
    
    <item>
      <title>동역학에서의 리우빌 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-dynamics/</link>
      <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-dynamics/</guid>
      <description>정리 유클리드 공간 $\mathbb{R}^{n}$ 과 함수 $f : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 이 벡터 필드의 플로우 $\phi_t ( \cdot )$ 과 영역 $D_{0} \subset \mathbb{R}^{n}$ 에 대해 $D_{t} := \phi_{t} \left( D_{0} \right)$ 를 플로우에 따라 시간 $t$가 지나 옮겨진 영역, 그 볼륨을 $V(t) \equiv V \left( D_{t} \right)$ 와 같이 나타내자. 만약 $\nabla \cdot f = 0$ 면 모든 $D_{0} \subset \mathbb{R}^{n}$ 와 $t \in \mathbb{R}$ 에 대해 다음이 성립한다. $$ V \left( D_{t}</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability/</guid>
      <description>정의 1 확률변수 $X$ 와 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $X_{n}$ 이 $X$ 로 확률 수렴Convergence in Probability한다고 말하고, $X_{n} \overset{P}{\to} X$ 와 같이 나타낸다. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left| X_{n} - X \right| &amp;lt; \varepsilon \right] = 1 $$ 설명 확률 수렴의 조건은 수식 그대로 확률의 센스에서 수렴을 정의한 것으로, 쉽게 말해 $n$ 이 커지면 두 확률 변수</description>
    </item>
    
    <item>
      <title>자율 시스템의 보존량</title>
      <link>https://freshrimpsushi.github.io/posts/conservation-in-autonomous-system/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conservation-in-autonomous-system/</guid>
      <description>정의 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 주어진 시스템에 종속된 상수함수 $h : X \to \mathbb{R}$ 가 존재하면 이를 보존량이라 한다. 설명 물리학적, 즉 역학적인(mechanical) 센스에 익숙하다면 보존량이라는 개념은 전혀 낯설지 않을 것이다. 가령 이상적인 상황에서 연직 방향 반대로</description>
    </item>
    
    <item>
      <title>연속 사상 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-continuous-mapping-theorem/</link>
      <pubDate>Wed, 11 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-continuous-mapping-theorem/</guid>
      <description>정리 1 다음은 연속 사상 정리의 측도론적 서술이다. 거리 공간 $\left( S , d \right)$ 와 $\left( S&amp;rsquo; , d&amp;rsquo; \right)$ 에 대해 $g : S \to S&amp;rsquo;$ 가 $C_{g} \subset S$ 에서 연속이라고 하자. $S$ 의 확률 원소 $X$ 에 대해 $P \left( X \in C_{g} \right) = 1$ 이면 $X$ 로 수렴하는 확률 원소의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 에 대해 다음이 성립한다. $$ X_{n} \overset{D}{\to} X \implies g \left( X_{n} \right) \overset{D}{\to} g(X) \\ X_{n} \overset{P}{\to} X \implies g \left( X_{n} \right) \overset{P}{\to} g(X) \\ X_{n} \overset{\text{a.s.}}{\to} X \implies g \left( X_{n} \right) \overset{\text{a.s.}}{\to} g(X) $$ $C_{g} \subset S$ 는 함수 $g$</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 다이벌전스</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-in-vector-field/</link>
      <pubDate>Mon, 09 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-in-vector-field/</guid>
      <description>정의 유클리드 공간에서 정의된 벡터 필드 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 을 $\textbf{f} = (f_{1} , \cdots , f_{n})$ 과 같이 나타내고 축의 방향을 $u_{1} , \cdots , u_{n}$ 이라고 할 때, $\textbf{f}$ 의 다이벌전스 를 다음과 같이 정의한다. $$ \text{div} \textbf{f} := \nabla \cdot \textbf{f} = \sum_{k=1}^{n} {{ \partial f_{k} } \over { \partial u_{k} }} $$ 설명 벡터 필드의 다이벌전스는 다음과 다음과 같이 한 점 $\textbf{v} \in \mathbb{R}^{n}$ 가 주어져 있을 때 그 점에서 벡터들이 모이는지, 퍼지는지에 대한 하나의 척도가 된</description>
    </item>
    
    <item>
      <title>로지스틱 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-a-logistic-function/</link>
      <pubDate>Sat, 07 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-a-logistic-function/</guid>
      <description>정의 1 로지스틱 함수란 미분 방정식의 해 $y&amp;rsquo; = y(1-y)$ 로써, 다음과 같이 구해진다. $$ y(t) = {{ 1 } \over { 1 + e^{-t} }} $$ 설명 조금 더 일반적인 형태로써 $\displaystyle f(x) := {{ L } \over { 1 + e^{-k(x-x_{0})} }}$ 와 같은 꼴을 사용하기도 한다. 로지스틱 함수는 시그모이드 함수며, 쓰임새가 많아 동역학, 통계학, 딥러닝, 생물학 등 여러 분야에서 언급되기도 하는 함수다. 로지스틱? 문제는 도대체</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 볼륨</title>
      <link>https://freshrimpsushi.github.io/posts/volume-in-vector-field/</link>
      <pubDate>Thu, 05 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/volume-in-vector-field/</guid>
      <description>정의 유클리드 공간의 부분공간 $D \subset \mathbb{R}^{n}$ 의 볼륨 $V$ 는 직교좌표 $\textbf{u} = (u_{1}, u_{2}, \cdots , u_{n})$ 으로 나타낼 때 다음과 같이 정의된다. $$ V(D) = \int_{D} du_{1} du_{2} \cdots d u_{n} $$ $\textbf{u} \in \mathbb{R}^{n}$ 가 벡터 함수 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 의해 $\textbf{f} \left( \textbf{u} \right) = \left( f_{1} (\textbf{u}) , \cdots , f_{n} (\textbf{u}) \right)$ 와 같이 변환될 때, $D$ 의 볼륨 은 다음과 같다. $$ V(D) = \int_{D} \left| {{ \partial \textbf{f} (\textbf{u}) } \over { \partial \textbf{u} }} \right| d u_{1} d u_{2} \cdots d u_{n} $$ $\displaystyle \left| {{ \partial \textbf{f} (\textbf{u}) } \over { \partial \textbf{u} }} \right|$ 는 다음과 같이</description>
    </item>
    
    <item>
      <title>2차원 자율 시스템에선 혼돈이 일어나지 않는다 푸앙카레-벤딕슨 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-poincare-bendixson-theorem/</link>
      <pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-poincare-bendixson-theorem/</guid>
      <description>정리 $2$차원 매니폴드 $\mathcal{P}$ 와 함수 $f,g \in C^{r} \left( \mathcal{P} \right)$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x,y) \\ y&amp;rsquo; = g(x,y) $$ $\mathcal{M}$ 이 벡터 필드의 유한한 수의 고정점을 가지는 양불변집합이라고 하면, $p \in \mathcal{M}$ 의 오메가 리미트 셋 $\omega (p)$ 은 다음 세가지 중 하나를 만족한다: (1): $\omega (p)$ 는 홑원소 집합이다. 즉, 단 하나의 고정점만을 포함한다. (2): $\omega (p)$ 는 닫</description>
    </item>
    
    <item>
      <title>시그모이드 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-a-sigmoid-function/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-a-sigmoid-function/</guid>
      <description>정의 1 유계 미분가능 스칼라 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 이 모든 $x \in \mathbb{R}$ 에서 $\sigma &amp;rsquo; (x) \ge 0$ 이고 단 하나의 변곡점을 가지면 시그모이드 함수Sigmoid Function라고 한다. 시그모이달 함수와는 그 정의가 다르다. 종류 시그모이드 함수의 예시로써 다음과 같은 함수들이 알려져있다: 로지스틱 함수: $\displaystyle f(x) := {{ 1 } \over { 1 + e^{-x} }}$ 하이퍼볼릭 탄젠트: $\tanh x$ 아크</description>
    </item>
    
    <item>
      <title>2차원 자율 시스템에서 피리어딕 오빗의 부재성</title>
      <link>https://freshrimpsushi.github.io/posts/nonexistence-of-periodic-orbit-of-2-dimensional-autonomous-system/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/nonexistence-of-periodic-orbit-of-2-dimensional-autonomous-system/</guid>
      <description>피리어딕 오빗에 대한 고찰 보통 자율 시스템에서 피리어딕 오빗이 존재하는지에 대한 질문은 상당히 까다로운데, $1,2$차원 공간이라면 비교적 간단하게 그 부재성에 대해서 논할 수 있다. 공간 $X = \mathbb{R}$ 혹은 $X = \mathbb{R}^{2}$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 1차원 $1$차원 자율 시스템에서는 피리</description>
    </item>
    
    <item>
      <title>순서통계량</title>
      <link>https://freshrimpsushi.github.io/posts/order-statistiics/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order-statistiics/</guid>
      <description>정리1 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 가 서포트 $\mathcal{S} =(a,b)$ 인 확률밀도함수 $f(x)$ 를 가지는 연속확률분포를 따른다고 하자. 이들을 크기 순으로 나열한 확률 변수들을 $Y_{1} &amp;lt; \cdots &amp;lt; Y_{n}$ 와 같이 나타내도록 하면 그 조인트, 마지널 확률밀도함수들은 다음과 같다. [1] 조인트: $$ g \left( y_{1} , \cdots , y_{n} \right) = \begin{cases} n! f (y_{1}) \cdots f (y_{n}) &amp;amp;, a &amp;lt; y_{1} &amp;lt; \cdots &amp;lt; y_{n} &amp;lt; b \\ 0 &amp;amp; , \text{elsewhere} \end{cases} $$ [2] 마지널: $Y_{k}$ 의 누적밀도함수</description>
    </item>
    
    <item>
      <title>벤딕슨 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/bendixsons-criterion/</link>
      <pubDate>Mon, 26 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bendixsons-criterion/</guid>
      <description>벤딕슨 판정법 공간 $\mathbb{R}^{2}$ 와 함수 $f,g \in C^{1} \left( \mathbb{R}^{2} \right)$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x,y) \\ y&amp;rsquo; = g(x,y) $$ 단순 연결 영역 $D \subset \mathbb{R}^{2}$ 에서 $$ {{ \partial f } \over { \partial x }} + {{ \partial g } \over { \partial y }} \ne 0 $$ 의 부호가 바뀌지 않는다면, 주어진 $2$차 벡터 필드는 $D$ 내부에서 닫힌 오빗을 갖지 않는다. $D \subset \mathbb{R}^{2}$ 이 단순 연결 영역이라는 것은 $D$ 의 테두리</description>
    </item>
    
    <item>
      <title>표본 분산을 n-1으로 나누는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-sample-variance-is-divided-by-n-1/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-sample-variance-is-divided-by-n-1/</guid>
      <description>왜 n-1로 나누지? $X_{i} \sim \left( \mu , \sigma^{2} \right)$ 이라고 하면 표본 분산 $S^{2}$ 는 다음과 같다. $$ S^{2} := {{1} \over {n-1}} \sum_{i=1}^{n} \left( X_{i} - \overline{X} \right)^{2} $$ 알다시피 표본 평균과 달리 표본 분산은 편차의 제곱을 모두 더한 후 표본 크기인 $n$ 이 아니라 $n-1$ 로 나눈다. 당연히 이를 이상하게 느껴야한다고는 말하지 않겠지만, 수식에 대한 보편적인 감성이 있다면 $n$ 개를 더하고 $n-1$ 로 나누는 것에서 강렬한 띠꺼움을 느</description>
    </item>
    
    <item>
      <title>불변 매니폴드의 안정성</title>
      <link>https://freshrimpsushi.github.io/posts/stability-of-manifold/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stability-of-manifold/</guid>
      <description>정의 벡터 필드의 매니폴드1 공간 $\mathbb{R}^{n}$ 와 함수 $f : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 고정점 $\overline{x}$ 이 주어져 있다고 할 때, 선형화 행렬 $A := D f \left( \overline{x} \right)$ 의 각 고유값 $\lambda$ 들에 대응되는 고유벡터 $e$ 들을 실수부 $\text{Re} (\lambda)$ 에 따라 다음과 분류하고, 그 생성 $\text{span}$ 을 다음과 같이 나타내자. $$ E^{s} := \text{span} \left\{ e :</description>
    </item>
    
    <item>
      <title>불편추정량</title>
      <link>https://freshrimpsushi.github.io/posts/unbiased-estimator/</link>
      <pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unbiased-estimator/</guid>
      <description>정의 1 $\theta$ 의 추정량 $T$ 가 다음을 만족하면 $T$ 를 $\mu$ 의 불편추정량Unbiased Estimator이라고 한다. $$ E T = \theta $$ 설명 특히 $\theta$ 에 대한 불편추정량 중 가장 분산이 작은 경우 최소분산불편추정량Mimimum Variance Unbiased Estimator, MVUE이라고 한다. 불편성이란 편의를 가지지 않는 성질을 말한다. 가령 $X_{i} \sim \left( \mu , \sigma^{2} \right)$ 라고 할 때 $\mu$ 의 추정량으로써 표본</description>
    </item>
    
    <item>
      <title>동역학에서의 불변 집합</title>
      <link>https://freshrimpsushi.github.io/posts/invariant-set-in-dynamics/</link>
      <pubDate>Sun, 18 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/invariant-set-in-dynamics/</guid>
      <description>정의1 공간 $X$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $S \subset X$ 라고 하자. (V): $\forall x_{0} \in S$ 가 모든 $t \in \mathbb{R}$ 에 대해 다음을 만족하면 벡터 필드 $x&#39;=f(x)$ 하에서의 불변 집합이라 한다. $$ x(t,x_{0}) \in S $$ (M): $\forall x_{0} \in S$ 가 모든 $n \in \mathbb{Z}$ 에 대해 다음을 만족하면 맵 $x \mapsto g(x)$ 하에서의 불변 집합이라 한다. $$ g^{n} (x_{0}) \in S $$ 불변 집합Inva</description>
    </item>
    
    <item>
      <title>편의-분산 트레이드 오프</title>
      <link>https://freshrimpsushi.github.io/posts/bias-variance-trade-off/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bias-variance-trade-off/</guid>
      <description>정의 $$ \text{MSE} \left( \widehat{\theta} \right) = \text{Var} \widehat{\theta} + \left( \text{Bias} \widehat{\theta} \right)^{2} $$ 설명 평균제곱오차 $\text{MSE}$ 는 통계 모형의 평가나 머신 러닝에서의 손실 함수로써 즐겨쓰이는 척도로써, 특히 편의와 분산에 대한 트레이드 오프로 나타난다.통계학도에게 있어서 편의를 다루는 것은 다소 어색할지 모르겠다. 적절한 확률 분포를 가정하고 그에 따른 수학적 이론을 토대로 데이터를 다루는 입장에서 분산은 손에 잡힐</description>
    </item>
    
    <item>
      <title>랴푸노프 함수</title>
      <link>https://freshrimpsushi.github.io/posts/liapunov-function/</link>
      <pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/liapunov-function/</guid>
      <description>정의1 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 한 점 $x_{0} \in X$ 이 주어져 있다고 할 때, $x_{0}$ 의 네이버후드 $\mathcal{N} \left( x_{0} \right)$ 에서 정의된 스칼라 함수 $V \in C^{1} \left( \mathcal{N} (x_{0}) , \mathbb{R} \right)$ 가 다음의 조건을 만족하면 랴푸노프 함수Liapunov Function라고 한다. (i): $V(x_{0}) = 0$ 이고, $x \ne</description>
    </item>
    
    <item>
      <title>수리통계학에서의 편의</title>
      <link>https://freshrimpsushi.github.io/posts/bias-in-mathematical-statistiics/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bias-in-mathematical-statistiics/</guid>
      <description>정의 모수 $\theta$ 에 대한 추정량 $\widehat{\theta}$ 에 대해 다음과 같이 정의된 $\text{Bias}$ 를 편의라 한다. $$ \text{Bias} ( \theta ) = E(\widehat{\theta}) - \theta $$ 설명 Bias는 편의 또는 편향으로 순화되지만, 역시 가장 많이 쓰이는 말은 발음 그대로 읽은 [바이어스]다. 한국어에서 편의는 Convenience인 경우가 압도적으로 많고 수식적으로나 실제 쓰임새로나 &amp;lsquo;편향&amp;rsquo;으로 순</description>
    </item>
    
    <item>
      <title>자율 시스템에서 고정점의 분류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-fixed-point/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-fixed-point/</guid>
      <description>정의 공간 $X$ 와 함수 $f \in C^{1}(X,X)$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ $\overline{x}$ 가 이 자율 시스템의 한 고정점이라 하고 $D f \left( \overline{x} \right)$ 의 아이겐 밸류들을 $\lambda_{1} , \cdots , \lambda_{m}$ 이라 하자. 하이퍼볼릭: 쌍곡 고정점1 Hyperbolic: $D f \left( \overline{x} \right)$ 의 모든 아이겐 밸류들의 실수부가 $0$ 이 아니면 $\overline{x}$ 가 하이퍼볼릭하다고 말한다. $$ \text{Re} \left( \lambda_{1} \right) \ne 0 , \cdots , \text{Re} \left( \lambda_{m} \right)</description>
    </item>
    
    <item>
      <title>신뢰구간의 쉬운 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-confidence-interval/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-confidence-interval/</guid>
      <description>정의 1 확률 밀도 함수 $f (x; \theta)$ 를 가지는 확률 변수 $X$ 의 샘플 $X_{1} , \cdots , X_{n}$ 와 신뢰 계수Confidence Coefficient $\alpha \in (0,1)$ 가 주어져 있다고 하자. $$ L := L \left( X_{1} , \cdots , X_{n} \right) \\ U := U \left( X_{1} , \cdots , X_{n} \right) $$ 통계량 $L &amp;lt; U$ 가 위와 같이 정의되어있다고 할 때, 다음을 만족하는 구간 $(L,U) \subset \mathbb{R}$ 을 모수 $\theta$ 에 대한 $( 1 - \alpha)100 \%$ 신뢰구간이라 한다. $$ 1-\alpha = P \left[ \theta \in \left( L,U \right) \right] $$ 설명 사</description>
    </item>
    
    <item>
      <title>더핑 오실레이터</title>
      <link>https://freshrimpsushi.github.io/posts/duffing-oscillator/</link>
      <pubDate>Tue, 06 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/duffing-oscillator/</guid>
      <description>더핑 방정식1 $$ x&#39;&amp;rsquo; + \delta x&amp;rsquo; + \alpha x + \beta x^{3} = \gamma \cos \left( \omega t \right) $$ 변수 $t$: 시간을 나타낸다. $x$: $1$차원 상에서 (이를 테면 입자의) 위치를 나타낸다. $x&#39;$: (입자의) 속도 를 나타낸다 $x&#39;&amp;rsquo;$: (입자의) 가속도 를 나타낸다. 파라메터 $\delta$: 감쇠(Damping) 를 제어하며, 마찰(Friction)과 비슷한 역할을 한다. $\alpha$: 강성(Stiffness) 를 제</description>
    </item>
    
    <item>
      <title>수리통계학에서의 통계량과 추정량</title>
      <link>https://freshrimpsushi.github.io/posts/statistiic-and-estimator/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statistiic-and-estimator/</guid>
      <description>정의 12 확률 변수 $X$ 의 샘플 $X_{1} , \cdots , X_{n}$ 의 함수 $T$ 를 통계량statistiic이라 한다. $$ T := T \left( X_{1} , \cdots , X_{n} \right) $$ $X$ 의 분포 함수가 $f(x; \theta)$ 혹은 $p(x; \theta)$ 와 같이 나타날 때, $T$ 가 $\theta$ 를 파악하기 위한 통계량이면 $T$ 를 $\theta$ 의 추정량Estimator이라고 한다. 통계량의 확률분포를 샘플링 분포Sampling Distribution라 한다. 설명 2:</description>
    </item>
    
    <item>
      <title>랴푸노프 안정성과 오빗 안정성</title>
      <link>https://freshrimpsushi.github.io/posts/liapunov-stability-and-orbit-stability/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/liapunov-stability-and-orbit-stability/</guid>
      <description>정의 랴푸노프 안정성 1 거리 공간 $\left( X , \left\| \cdot \right\| \right)$ 과 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ $t_{0} \in \mathbb{R}$ 이라 하자. 주어진 미분 방정식의 솔루션 $\overline{x}(t)$ 가 $\varepsilon &amp;gt; 0$ 이 주어질 때마다 $$ \left\| \overline{x} \left( t_{0} \right) - y \left( t_{0} \right) \right\| &amp;lt; \delta \implies \left\| \overline{x}(t) - y(t) \right\| &amp;lt; \varepsilon \qquad , t &amp;gt; t_{0} $$ 를 만족시키는 다른 모든 솔루션 $y(t)$ 에 대해 $\delta ( \varepsilon ) &amp;gt; 0$ 가 존재하</description>
    </item>
    
    <item>
      <title>수리통계학에서의 랜덤 샘플</title>
      <link>https://freshrimpsushi.github.io/posts/random-sample/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-sample/</guid>
      <description>정의 1 확률 변수 $X$ 가 실제로 뽑힌 것을 실현Realization이라 하고 보통 소문자 $x$ 로 나타낸다. 확률 변수 $X$ 와 같은 확률 분포에서 샘플 사이즈Sample Size $n$ 만큼 얻어낸 확률 변수들을 샘플Sample이라 하고 다음과 같이 나타낸다. $$ X_{1} , X_{2} , \cdots , X_{n} $$ 확률 변수 $X_{1} , \cdots , X_{n}$ 이 iid면 사이즈 $n$ 의 랜덤 샘플이라 부른다. 설명 이러한 정의</description>
    </item>
    
    <item>
      <title>비선형 시스템의 선형화</title>
      <link>https://freshrimpsushi.github.io/posts/linearization-of-nonlinear-system/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearization-of-nonlinear-system/</guid>
      <description>빌드업 공간 $\left( X, \left\| \cdot \right\| \right)$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 고정점 $\overline{x}$ 이 주어져 있다고 할 때, 그 근방의 안정성을 파악하기 위해서는 선형화라는 방법이 필수적으로 동원된다. 시스템을 전체적으로 보았을 땐 고정점 근처에서는 선형으로 보고 분석하겠다는 것이다. 이는</description>
    </item>
    
    <item>
      <title>코시 분포: 모평균이 존재하지 않는 분포</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-distribution/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-distribution/</guid>
      <description>정의 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $C$ 를 코시 분포라고 한다. $$ f(x) = {1 \over \pi} {1 \over {x^2 + 1}} \qquad , x \in \mathbb{R} $$ 설명 모든 확률 분포가 평균과 분산을 가질 것 같지만 실제로는 그렇지 않다. 그 대표적인 예시가 코시 분포로, 언뜻 정규 분포와 닮았지만 양쪽 꼬리가 두꺼운 모양을 하고 있다. 모수에 무관하게 적률생성함수가 존재하지 않으니 모평균이든 모</description>
    </item>
    
    <item>
      <title>자율 시스템의 오빗</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-of-autonomous-system/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-of-autonomous-system/</guid>
      <description>정의 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 위와 같은 자율 시스템의 플로우를 $x(t,t_{0},x_{0})$ 와 같이 나타낸다고 하자. 그러면 $x_{0} \in X$ 를 지나는 오빗Orbit$O(x_{0})$ 을 다음과 같이 나타낸다. 1 $$ O(x_{0}) := \left\{ x \in X : x = x(t, t_{0} , x_{0}) \right\} $$ 2. 오빗이 모든 $t \in \mathbb{R}$ 에 대해 다음을 만족시키는 $T &amp;gt;</description>
    </item>
    
    <item>
      <title>t-분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-t-distribution/</link>
      <pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-t-distribution/</guid>
      <description>공식 $X \sim t (\nu)$ 이면 $$ E(X) = 0 \qquad , \nu &amp;gt;1 \\ \text{Var}(X) = {{ \nu } \over { \nu - 2 }} \qquad , \nu &amp;gt; 2 $$ 유도 전략: t-분포 역시 카이제곱분포와 비슷하게 적률 공식이 알려져 있어, 이 공식들을 이용한다. t-분포의 적률: 두 확률 변수 $W,V$ 가 독립이고 $W \sim N(0,1)$, $V \sim \chi^{2} (r)$ 이라 하자. $k &amp;lt; r$ 이면 $\displaystyle T := { {W} \over {\sqrt{V/r} } }$ 는 $k$차 적률이 존재하고 $$ E T^{k} = E W^{k} {{ 2^{-k/2} \Gamma \left( {{ r } \over { 2</description>
    </item>
    
    <item>
      <title>리만 함수 방정식과 리만 제타 함수의 자명근</title>
      <link>https://freshrimpsushi.github.io/posts/trivial-root-of-riemann-zeta-function/</link>
      <pubDate>Fri, 18 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trivial-root-of-riemann-zeta-function/</guid>
      <description>공식 다음을 리만 함수 방정식이라 한다. $$ \zeta(s) = 2^{s} \pi^{s - 1} \sin \left( {{ \pi s } \over { 2 }} \right) \Gamma (1-s) \zeta (1-s) $$ $\Gamma$ 는 감마 함수다. $\zeta$ 는 리만 제타 함수다. 설명 리만 함수 방정식에서 $s \in 2 \mathbb{Z}$ 이면 $\displaystyle \sin \left( {{ \pi s } \over { 2 }} \right) = 0$ 이므로 당연히 $\zeta (s) = 0$ 일 것 같다. 그러나 $s = 0$ 일 때는 우변에 $\zeta (1 - 0)$ 이 나오기 때문에 근이고 뭐고 아예 정의가 되지 않으며, $s &amp;gt; 0$ 일 때는 바</description>
    </item>
    
    <item>
      <title>t-분포</title>
      <link>https://freshrimpsushi.github.io/posts/t-distribution/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/t-distribution/</guid>
      <description>정의 1 자유도 $\nu &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $t \left( \nu \right)$ 를 t-분포라고 한다. $$ f(x) = {{ \Gamma \left( {{ \nu + 1 } \over { 2 }} \right) } \over { \sqrt{\nu \pi} \Gamma \left( {{ \nu } \over { 2 }} \right) }} \left( 1 + {{ x^{2} } \over { \nu }} \right)^{- {{ \nu + 1 } \over { 2 }}} \qquad ,x \in \mathbb{R} $$ $\Gamma (\nu)$ 는 감마 함수다. 설명 t-분포는 지금도 맥주로 유명한 기네스 양조 공장에서 일하던 윌리엄 고셋Will</description>
    </item>
    
    <item>
      <title>리만 자이 함수</title>
      <link>https://freshrimpsushi.github.io/posts/riemann-xi-function/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riemann-xi-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $\xi$ 를 리만 자이 함수Riemann xi Function라고 한다. $$ \xi (s) := {{ 1 } \over { 2 }} s ( s-1) \pi^{-s/2} \zeta (s) \Gamma \left( {{ s } \over { 2 }} \right) $$ $\zeta$ 는 리만 제타 함수다. $\Gamma$ 는 감마 함수다. 설명 리만 자이 함수는 원래 이와 다른 조금 형태로 정의되어있었으나, 에드문트 란다우Edmund Landau에 의해 소문자 자이 $\xi$ 로 다시 정의되</description>
    </item>
    
    <item>
      <title>독립인 정규 분포와 카이제곱 분포에서 스튜던트 t-분포 유도 </title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-t-distribution-from-independent-chi-squared-and-normal-distribution/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-t-distribution-from-independent-chi-squared-and-normal-distribution/</guid>
      <description>정리 두 확률 변수 $W,V$ 가 독립이고 $W \sim N(0,1)$, $V \sim \chi^{2} (r)$ 이라 하면 $$ T = { {W} \over {\sqrt{V/r} } } \sim t(r) $$ $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. $\chi^{2} \left( r \right)$ 은 자유도 $r$ 인 카이제곱 분포다. $t(r)$ 은 자유도 $r$ 인 t-분포다. 설명 어떤 분포에서 다른 분포를 유도하는 것은 공부만 열심히 하면 직관적인 추측이 가능하다. 하지만 둘 이상의 분포에서 다른 분포를 유도해낸다</description>
    </item>
    
    <item>
      <title>완벽 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/perfect-graph/</link>
      <pubDate>Sat, 12 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/perfect-graph/</guid>
      <description>정의 그래프 $G$ 의 모든 유도서브그래프 $H$ 가 다음을 만족하면 완벽 그래프라 한다. $$ \chi (H) = \omega (H) $$ $\chi (H)$ 는 그래프 $H$ 의 크로마틱 수다. $\omega (H)$ 는 그래프 $H$ 의 클리크 수다. 설명 그래프 이론의 세계는 수학의 많은 분과가 그러하듯 어마어마하게 넓은데, 솔직히 조금은 더 넓다고 말하고 싶다. 그래프에서 버텍스와 에지를 정의하는 방법이 너무 다양하기 때문이다. 영</description>
    </item>
    
    <item>
      <title>표준정규분포의 제곱은 자유도가 1인 카이제곱분포를 따름을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/squared-standard-normal-distribution-is-chi-squared-distribution/</link>
      <pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/squared-standard-normal-distribution-is-chi-squared-distribution/</guid>
      <description>정리 $X \sim N(\mu,\sigma ^2)$면 $$ V=\left( { X - \mu \over \sigma} \right) ^2 \sim \chi ^2 (1) $$ $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. $\chi^{2} \left( 1 \right)$ 은 자유도 $1$ 인 카이제곱 분포다. 설명 정리로는 이를 일반화시킨 스튜던트의 정리가 많이 쓰인다. 통계학을 공부하는 사람이라면 표준정규분포의 제곱이 카이제곱분포를 따른다는 것은 팩트로써 항상 당연하게 알고 있어야한다. 어떤 데</description>
    </item>
    
    <item>
      <title>정규 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-normal-distribution/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-normal-distribution/</guid>
      <description>공식 $X \sim N\left( \mu , \sigma^{2} \right)$ 면 $$ E(X) = \mu \\ \text{Var} (X) = \sigma^{2} $$ 유도 전략: 정규 분포는 적률생성함수가 미분하기 쉬우니 그냥 바로 직접연역한다. 정규 분포의 적률생성함수: $$ m(t) = \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) \qquad , t \in \mathbb{R} $$ $$ m&amp;rsquo;(t) = \left( \mu + \sigma^{2} t \right) \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) $$ 이므로 $E(X) = m&amp;rsquo;(0) = \mu$ 이고 $$ m&amp;rsquo;&amp;rsquo;(t) = \left( 0 + \sigma^{2} \right) \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) + \left( \mu +</description>
    </item>
    
    <item>
      <title>리눅스에서 gcc 컴파일러로 c 코드 컴파일 하는 법 </title>
      <link>https://freshrimpsushi.github.io/posts/how-to-compile-c-code-using-gcc-in-linux/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-compile-c-code-using-gcc-in-linux/</guid>
      <description>가이드 보통 C/C++을 이용한 프로그램 개발은 윈도우에서 비주얼 스튜디오를 쓰는 것이 권장되나, 간단한 테스트나 수치계산, 시뮬레이션 등을 리눅스로 진행할 때는 리눅스 특유의 가벼움이 큰 장점으로 다가올 때가 있다. 가령 infection\_modified\_200428.c이라는 c 소스코드가 있다면, 터미널에서 해당 경로로 이동</description>
    </item>
    
    <item>
      <title>정규분포</title>
      <link>https://freshrimpsushi.github.io/posts/normal-distribution/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normal-distribution/</guid>
      <description>정의 평균 $\mu \in \mathbb{R}$ 과 분산 $\sigma^{2} &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $N \left( \mu,\sigma^{2} \right)$ 를 정규 분포Normal Distribution라고 한다. $$ f(x) = {{ 1 } \over { \sqrt{2 \pi} \sigma }} \exp \left[ - {{ 1 } \over { 2 }} \left( {{ x - \mu } \over { \sigma }} \right)^{2} \right] \qquad, x \in \mathbb{R} $$ 특히 다음과 같은 확률 밀도를 함수를 가지는 정규분포 $N \left( 0,1^{2} \right)$ 를 표준정규분포라고 한다. $$ f(z) = {{</description>
    </item>
    
    <item>
      <title>야코비 세타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/jacobi-theta-function/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jacobi-theta-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $\vartheta$ 를 야코비 세타 함수Jacobi theta Function라고 한다. $$ \vartheta (\tau) := \sum_{n \in \mathbb{Z}} e^{-\pi n^{2} \tau } $$ 설명 야코비 함수는 원래 더 일반적으로 정의될 수 있지만, 보통은 필요한 곳에 따라 그냥 특수한 형태를 쓰는 일이 잦다. 여기서 소개된 야코비 세타 함수 역시 정확한 의미에서 모든 맥락을 커버하지는 못한다는 것에 주의하자. 다음의 성질</description>
    </item>
    
    <item>
      <title>독립인 두 카이제곱 분포에서 F-분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-f-distribution-from-two-independent-chi-squared-distribution/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-f-distribution-from-two-independent-chi-squared-distribution/</guid>
      <description>정리 두 확률 변수 $U,V$ 가 독립이고 $U \sim \chi^{2} ( r_{1})$, $V \sim \chi^{2} ( r_{2})$ 이라 하면 $$ {{ U / r_{1} } \over { V / r_{2} }} \sim F \left( r_{1} , r_{2} \right) $$ 설명 두 데이터가 카이제곱 분포를 따르고 독립이라면, 그 비를 분포이론으로 설명할 수 있을지도 모른다.통계학 전반에서는 표준화된 잔차의 제곱이 카이제곱 분포를 따르는 것으로 가정하기 때문에 이 점에 따라 F-검정등을 즐겨쓴다. 증명 자체가</description>
    </item>
    
    <item>
      <title>푸아송 합 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-poisson-summation-formula/</link>
      <pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-poisson-summation-formula/</guid>
      <description>공식 $f : \mathbb{R} \to \mathbb{C}$ 가 슈바르츠 함수라고 하자. 그러면 $$ \sum_{n \in \mathbb{Z}} f(n) = \sum_{k \in \mathbb{Z}} \widehat{f}(k) $$ 슈바르츠 함수 $f \in C^{\infty}(\mathbb{R})$ 란 $x \to \pm \infty$ 일 때 함숫값의 크기 $\left| f (x) \right|$ 가 빠르게 $0$ 으로 수렴하는 함수를 말한다. $f$ 와 $\gamma \in \mathbb{R}$ 에 대해 $\widehat{f}(\gamma)$ 는 다음과 같은 푸리에 변환을 나타낸다. $$ \widehat{f} ( \gamma ) = \int_{\mathbb{R}} f(x) e^{2 \pi i \gamma x} dx $$ 증명1 $$ F(x) := \sum_{n \in \mathbb{Z}} f ( x + n ) $$ 이라고 하면 $F$ 는 $1$-피리어딕하</description>
    </item>
    
    <item>
      <title>감마함수와 리만 제타 함수 디리클레 에타 함수와의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-among-gamma-riemann-zeta-dirichlet-eta-functions/</link>
      <pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-among-gamma-riemann-zeta-dirichlet-eta-functions/</guid>
      <description>정리 $\text{Re} (s) &amp;gt; 1$ 이면 $$ \zeta (s) \Gamma (s) = \mathcal{M} \left[ {{ 1 } \over { e^{x} - 1 }} \right] (s) = \int_{0}^{\infty} {{ x^{s-1} } \over { e^{x} - 1 }} dx \\ \eta (s) \Gamma (s) = \mathcal{M} \left[ {{ 1 } \over { e^{x} + 1 }} \right] (s) = \int_{0}^{\infty} {{ x^{s-1} } \over { e^{x} + 1 }} dx $$ $\mathcal{M}$ 은 멜린 변환이다. $\text{Re} (s)$ 는 복소수 $s$ 의 실수부를 나타낸다. 설명 디리클레 에타 함수 $\eta(s)$ 는 리만 제타 함수 $\zeta(s)$ 의 교대 급수인만큼 서로 수학적으로 흥미로운 관계를 가질 뿐만 아니라 감마 함수 $\Gamma</description>
    </item>
    
    <item>
      <title>작용소로써의 푸리에 변환</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-transform-as-operator/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-transform-as-operator/</guid>
      <description>정의1 함수 $f$ 의 푸리에 변환 $$ \widehat{f} (\gamma ) := \int_{\mathbb{R}} f(x) e^{-2 \pi i x \gamma} dx, \quad \gamma \in \mathbb{R} $$ 을 다음과 같은 작용소 $\mathcal{F}$와 같이 표현하기도 한다. $$ (\mathcal{F} f) (\gamma ) := \widehat{f} ( \gamma ) $$ 설명 푸리에 변환은 해석학 전반에서 널리 쓰이고 있으며 두가지 표현 $\widehat{f}$ 과 $\mathcal{F} f$ 는 본질적으로 다른 점이 없지만, 기호를 사용할 때 뉘앙스의 차이는 살짝 있다. 실질적인 계산과 공식, 빠</description>
    </item>
    
    <item>
      <title>L2 공간에서 트랜슬레이션, 모듈레이션, 다일레이션의 교환관계</title>
      <link>https://freshrimpsushi.github.io/posts/commutation-relations-of-translation-modulation-dilation/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/commutation-relations-of-translation-modulation-dilation/</guid>
      <description>정리1 모든 $a, b \in \mathbb{R}$ 과 $c &amp;gt; 0$ 에 대해 $T_{a}, E_{b}, D_{c}$ 는 다음과 같은 관계를 가진다. $$ \begin{equation} (T_{a} E_{b} f ) (x) = e^{- 2 \pi i b a} (E_{b} T_{a} f ) (x) \end{equation} $$ $$ \begin{equation} (T_{a} D_{c} f ) (x) = (D_{c} T_{a/c} f ) (x) \end{equation} $$ $$ \begin{equation} (D_{c} E_{b} f ) (x) = (E_{b/c} D_{c} f ) (x) \end{equation} $$ 이때 $T_{a}, E_{b}, D_{c}$ 는 각각 $L^{2}$ 에서 정의된 트랜슬레이션, 모듈레이션, 다일레이션이다. 증명 (1) $$ \begin{align*} (T_{a} E_{b} f ) (x) =&amp;amp; T_{a} \left( e^{2 \pi i b x} f(x) \right) \\ =&amp;amp; e^{2 \pi i b (x-a)} f(x-a) \\ =&amp;amp; e^{2 \pi</description>
    </item>
    
    <item>
      <title>거리공간에서 연속과 균등연속</title>
      <link>https://freshrimpsushi.github.io/posts/continuous-functions-and-uniformly-continuous-functions-in-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuous-functions-and-uniformly-continuous-functions-in-metric-space/</guid>
      <description>정의 두 거리 공간 $\left( X , d_{X} \right)$, $\left( Y , d_{Y} \right)$와 부분집합 $E\subset X$ 에 대해 함수 $f : E \to Y$ 를 정의하자. $p \in E$라고 하자. 임의의 $\varepsilon &amp;gt; 0$ 에 대해 $$ x \in E \quad \text{and} \quad d_{X}(p, x ) &amp;lt; \delta \implies d_{Y}(f(p) , f(x) ) &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $f$ 는 $p \in E$ 에서 연속이라 한다. $f$가 $E$ 의 모든 점에서 연속이면 $f$를 $E$ 위에서의 연속함수continuous fu</description>
    </item>
    
    <item>
      <title>보렐-르벡 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-borel-lebesgue-theorem/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-borel-lebesgue-theorem/</guid>
      <description>정리 거리 공간 $(X, \rho)$ 에 대해 다음은 모두 동치다. (a) $X$ 는 컴팩트 공간이다. (b) $X$ 는 시퀀셜리 컴팩트 공간이다. (c) $X$ 는 완비 공간이고 완전 유계 공간이다. 설명 거리 공간 $X$ 가 시퀀셜리 컴팩트Sequentially Compact 공간이라는 것은 $X$ 의 모든 시퀀스가 $X$ 의 한 점으로 수렴하는 서브 시퀀스를 갖는 공간이라는 뜻이다.보렐-르벡 정리는 거리 공간에서 컴팩</description>
    </item>
    
    <item>
      <title>완비 거리 공간의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-complete-metric-space/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-complete-metric-space/</guid>
      <description>성질 $(X,d)$ 가 거리 공간이고 $K \subset X$ 라 하자. [1]: $K$ 는 완비 부분 공간이다. $\iff$ $X$ 에서 $K$가 닫힌 집합이다. [2]: $K$ 는 완전 유계 공간 $\iff$ $X$에서 닫힌 집합 $K$ 는 컴팩트이다. 설명 완비 거리 공간은 완비성을 가지는 거리 공간이라는 점에서 어지간한 상식적 성질을 다 갖추었다고 볼 수 있는 공간이다. 여기서 놈드 벡터 스페이스가 되면 바나흐 공간, 거기에 내적까지 정</description>
    </item>
    
    <item>
      <title>디리클레 에타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/dirichlet-eta-function/</link>
      <pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichlet-eta-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $\eta : \mathbb{C} \to \mathbb{C}$ 를 디리클레 에타 함수Dirichlet eta Function라고 한다. $$ \eta (s) := \sum_{n \in \mathbb{N}} (-1)^{n-1} n^{-s} $$ 디리클레 에타 함수는 교대 리만 제타 함수로 정의된다. 정리 [1] 리만 제타 함수와의 관계: $$ \eta(s) = \left( 1 - 2^{1-s} \right) \zeta(s) $$ [2] 감마 함수와의 관계: $\text{Re} (s) &amp;gt; 1$ 이면 $$ \eta (s) \Gamma (s) = \mathcal{M} \left[ {{ 1 } \over { e^{x} + 1 }} \right] (s) = \int_{0}^{\infty} {{ x^{s-1} } \over { e^{x} +</description>
    </item>
    
    <item>
      <title>L2 공간에서 트랜슬레이션, 모듈레이션, 다일레이션의 역작용소</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-of-translation-modulation-dilation/</link>
      <pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-of-translation-modulation-dilation/</guid>
      <description>정리1 $T_{a}, E_{b}, D_{c}$ 는 유니터리며, 역작용소는 다음과 같다. $$ T_{a}^{-1} = T_{-a} = \left( T_{a} \right)^{ \ast } $$ $$ E_{b}^{-1} = E_{-b} = \left( E_{b} \right)^{ \ast } $$ $$ D_{c}^{-1} = D_{1/c} = \left( D_{c} \right)^{ \ast } $$ 이때 $T_{a}, E_{b}, D_{c}$ 는 각각 $L^{2}$ 에서 정의된 트랜슬레이션, 모듈레이션, 다일레이션이다. 증명 트랜슬레이션 $t := x - a$ 와 같이 치환하면 $$ \begin{align*} \langle T_{a} f , g \rangle =&amp;amp; \int_{-\infty}^{\infty} f \left( x - a \right) \overline{g \left( x \right)} dx \\ =&amp;amp; \int_{-\infty}^{\infty} f \left( t \right) \overline{g \left( t + a \right)} dt \\ =&amp;amp; \langle</description>
    </item>
    
    <item>
      <title>하이네-보렐 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-heine-borel-theorem/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-heine-borel-theorem/</guid>
      <description>정의 실수의 부분집합 $E \subset \mathbb{R}$ 에 대해 $\displaystyle E \subset \bigcup_{\alpha \in \forall} ( x_{\alpha} , y_{\alpha})$ 을 만족하는 개구간의 집합 $\mathcal{O} = \left\{ ( x , y ) \ | \ x &amp;lt; y \right\}$ 을 $E$ 의 오픈 커버링open covering이라 한다. 이러한 $E$ 가 컴팩트compact라는 것은 $E$ 의 모든 오픈 커버링 $\mathcal{O}$ 에 대해 $\displaystyle E \subset \bigcup_{i =1}^{m} O_{i}$ 를 만족하는 $\mathcal{O}$ 의 유한부분집합 $\left\{ O_{1} , O_{2} , \cdots , O_{m} \right\}$ 가 존재한다는 것과 동치다. 이 정</description>
    </item>
    
    <item>
      <title>리만 제타 함수</title>
      <link>https://freshrimpsushi.github.io/posts/riemann-zeta-function/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riemann-zeta-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $\zeta : \mathbb{C} \setminus \left\{ 1 \right\} \to \mathbb{C}$ 를 리만 제타 함수Riemann zeta Function&amp;lt;/sup라고 한다. $$ \zeta (s) := \sum_{n \in \mathbb{N}} n^{-s} = \prod_{p : \text{prime}} \left( 1- {p^{-s}} \right)^{-1} $$ 관련 정리 [0] 라마누잔 합: $\displaystyle \sum_{n \in \mathbb{N}} x^{n-1} = {{ 1 } \over { 1-x }}$ 이 $|x| = 1$ 에서도 성립한다는 주장을 받아들인다면 $$ \zeta (0) = 1 + 1 + 1 + 1 + \cdots = - {{ 1 } \over { 2 }} $$ [1] 오렘의 증명 : $\zeta</description>
    </item>
    
    <item>
      <title>L2 공간의 트랜슬레이션, 모듈레이션, 다일레이션</title>
      <link>https://freshrimpsushi.github.io/posts/translation-modulation-dilation-on-l2/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/translation-modulation-dilation-on-l2/</guid>
      <description>정의1 $a \in \mathbb{R}$ 에 대해 다음과 같이 정의된 $T_{a} : L^{2} \to L^{2}$ 를 트랜슬레이션translation, 평행이동이라 한다. $$ \left( T_{a} f \right) (x) := f(x-a) $$ $b \in \mathbb{R}$ 에 대해 다음과 같이 정의된 $E_{b} : L^{2} \to L^{2}$ 을 모듈레이션modulation, 변조 이라 한다. $$ \left( E_{b} f \right) (x) := e^{2 \pi i b x} f(x) $$ $c &amp;gt; 0$ 에 대해 다음과 같이 정의된 $D_{c} : L^{2} \to L^{2}$ 을 다일레이션dilation,</description>
    </item>
    
    <item>
      <title>수론에서의 p-진수</title>
      <link>https://freshrimpsushi.github.io/posts/p-adic-number/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/p-adic-number/</guid>
      <description>정의 1 소수 $p$ 와 정수 $a \in \mathbb{Z}$ 에 대해 다음과 같이 정의된 $v_{p}$ 를 $a$ 의 $p$-진수 부치$p$-adic Valuation라 한다. $$ v_{p} (a) := \sup \left\{ e \in \mathbb{Z} : p^{e} \mid a \right\} $$ 정리 2 [0]: 모든 소수 $p$ 에 대해 $$ v_{p} (0) = \infty $$ [1]: $$v_{p} (xy) = v_{p}(x) + v_{p}(y)$$ [2]: $$v_{p} (x+y) \ge \min \left\{ v_{p} (x) , v_{p} (y) \right\}$$ [3]: $n \in \mathbb{N}$, $x , y \in \mathbb{Z}$, 소수 $p$ 가 $$ \gcd (n,p) = 1 \\ p \mid (x \mp y) \\ p \nmid x \\ p \nmid y $$ 를 만족하면 $$ v_{p} \left( x^{n}</description>
    </item>
    
    <item>
      <title>지수승강 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lifting-the-exponent-lemma-lte-lemma/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lifting-the-exponent-lemma-lte-lemma/</guid>
      <description>정리 $n \in \mathbb{N}$, $x , y \in \mathbb{Z}$, 소수 $p \ne 2$ 가 $$ \gcd (n,p) = 1 \\ p \mid (x - y) \\ p \nmid x \\ p \nmid y $$ 를 만족하면 $$ v_{p} \left( x^{n} - y^{n} \right) = v_{p} \left( x - y \right) + v_{p} (n) $$ $v_{p} (a)$ 는 $a$ 의 $p$-진수 부치를 의미한다. 증명 1 전략: $p$-진수 부치의 성질들에서 자연스럽게 연역된다. 그런데 정작 그 성질들을 증명하는 과정이 꽤 길다. 관건은 아래의 성질들을 앞서 보이는 것인데, 초등</description>
    </item>
    
    <item>
      <title>F-분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-f-distribution/</link>
      <pubDate>Sat, 15 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-f-distribution/</guid>
      <description>공식 $X \sim F ( r_{1} , r_{2})$ 면 $$ E(X) = {{ r_{2} } \over { r_{2} - 2 }} \qquad , r_{2} &amp;gt; 2 \\ \text{Var}(X) = {{ 2 d_{2}^{2} (d_{1} + d_{2} - 2) } \over { d_{1} (d_{2} -2)^{2} (d_{2} - 4) }} \qquad , r_{2} &amp;gt; 4 $$ 유도 전략: F-분포 역시 카이제곱분포와 비슷하게 적률 공식이 알려져 있어, 이 공식들을 이용한다. F-분포의 적률: $X \sim F(r_{1} , r_{2})$ 이고 $\displaystyle X = {{ X_{1} } \over { X_{2} }}$ 와 같이 나타낼 수 있다고 하자. $X_{1}$ 과 $X_{2}$ 가 각각 자유도 $d_{1}, d_{2}$ 인 카이제</description>
    </item>
    
    <item>
      <title>앤더슨-리빙스톤 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-anderson-livingston-theorem/</link>
      <pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-anderson-livingston-theorem/</guid>
      <description>정리 1 $R$ 이 유니티 $1$ 을 가지는 가환 링이고 그 영인자들의 집합을 $Z(R)$ 라 하면 그 영인자 그래프 $\Gamma (R)$ 는 연결 그래프고 $\text{diam}(\Gamma(R)) \le 3$ $\text{diam}$ 은 그래프의 지름을 의미한다. 설명 앤더슨과 리빙스톤은 영인자 그래프의 연구에서 중요한 업적을 남겼으며, 특히 그래프의 연결성과 지름의 상한값을 특정하는 이 정리를 앤더슨-리빙스톤 정리라 부르기도 한다. 증명 $x,y \in Z(R) (x \ne y)$ 이라</description>
    </item>
    
    <item>
      <title>산술 함수의 부분합에 대한 일반화된 디리클레 곱 표현</title>
      <link>https://freshrimpsushi.github.io/posts/partial-sums-of-dirichlet-product/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partial-sums-of-dirichlet-product/</guid>
      <description>정리 1 $h = f \ast g$ 인 산술 함수 $f,g,h$ 에 대해 $F, G, H$ 를 다음과 같이 정의하자. $$ F (x) := \sum_{n \le x} f(x) \\ G (x) := \sum_{n \le x} g(x) \\ H (x) := \sum_{n \le x} h(x) $$ 그러면 $$ H = f \circ G = g \circ F $$ 여기서 연산 $\circ$ 는 일반화된 컨볼루션을 의미한다. 다시 말해, 다음이 성립한다. $$ H(x) = \sum_{n \le x} f(n) G \left( {{ x } \over { n }} \right) = \sum_{n \le x} g(n) F \left( {{ x } \over { n }} \right) $$ 증명 $$ U(x) := \begin{cases} 0 &amp;amp;, 0 &amp;lt; x &amp;lt; 1</description>
    </item>
    
    <item>
      <title>F-분포</title>
      <link>https://freshrimpsushi.github.io/posts/f-distribution/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/f-distribution/</guid>
      <description>정의 1 자유도 $r_{1}, r_{2} &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $F \left( r_{1} , r_{2} \right)$ 를 F-분포라고 한다. $$ f(x) = {{ 1 } \over { B \left( r_{1}/2 , r_{2} / 2 \right) }} \left( {{ r_{1} } \over { r_{2} }} \right)^{r_{1} / 2} x^{r_{1} / 2 - 1} \left( 1 + {{ r_{1} } \over { r_{2} }} x \right)^{-(r_{1} + r_{2}) / 2} \qquad , x \in (0, \infty) $$ $B(r_{1} / 2, r_{2}/2)$ 는 베타 함수를 의미한다. 기초 성질 적률 생성 함수 [1]: F-분포는 적률 생성 함수가 존재하지 않는</description>
    </item>
    
    <item>
      <title>영인자 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/zero-divisor-graph/</link>
      <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zero-divisor-graph/</guid>
      <description>정의 가환 링 $R$ 이 주어져 있다고 하자. $R$ 의 영인자 집합을 $Z(R)$ 이라고 할 때, 다음과 같이 정의된 그래프 $\Gamma (R)$ 을 $R$ 에 대한 영인자 그래프Zero Divisor Graph라고 한다. $$ V \left( \Gamma(R) \right) = Z(R) \\ E( \Gamma(R)) = \left\{ ab : ab=0 \right\} $$ 설명 알다시피 영인자끼리 곱한다고해서 반드시 $0$ 이 되는 것은 아니다. 예로써, $ 2, 4 \in Z \left( \mathbb{Z}_{10} \right)$ 는 $\mathbb{Z}_{10}$ 의 영인자가 맞지만 그 곱은 $8 \ne 0$ 이다. 따라</description>
    </item>
    
    <item>
      <title>일반화된 디리클레 곱</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-convolution/</link>
      <pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-convolution/</guid>
      <description>정의 1 $F : \mathbb{R}^{+} \to \mathbb{C}$ 는 $x \in (0,1)$ 에서 $F(x) = 0$ 인 함수라고 하자. 임의의 산술 함수 $\alpha$ 에 대해 다음과 같은 연산 $\circ$ 을 일반화된 디리클레 곱이라 정의한다. $$ (\alpha \circ F)(x) := \sum_{n \le x} \alpha(n) F \left( {{ x } \over { n }} \right) $$ 기초 성질 $\alpha$ 와 $\beta$ 는 산술 함수고 $F , G : \mathbb{R}^{+} \to \mathbb{C}$ 는 $x \in (0,1)$ 에서 함숫값이 $0$ 인 함수이라 하자. [1]: $\alpha \circ \left( \beta \circ F \right) = \left( \alpha \ast\ \beta \right) \circ F$ [2] 좌항등원: $(I \circ F) = F$ [3] 일반</description>
    </item>
    
    <item>
      <title>카이제곱 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-chi-square-distribution/</link>
      <pubDate>Wed, 05 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-chi-square-distribution/</guid>
      <description>공식 $X \sim \chi^{2} (r)$ 이면 $$ E(X) = r \\ \text{Var} (X) = 2r $$ 유도 전략: 카이제곱분포는 고맙게도 적률 공식이 알려져있다. 카이제곱 분포의 적률: $X \sim \chi^{2} (r)$ 이라고 하자. $k &amp;gt; - r/ 2$ 이면 $k$차 적률이 존재하고 $$ E X^{k} = {{ 2^{k} \Gamma (r/2 + k) } \over { \Gamma (r/2) }} $$ 평균 $$ EX^{1} = {{ 2^{1} \Gamma (r/2 + 1) } \over { \Gamma (r/2) }} = 2 \cdot {{ r } \over { 2 }} = r $$ ■ 분산 $$ EX^{2} = {{ 2^{2} \Gamma (r/2 + 2) } \over { \Gamma (r/2) }} = 4</description>
    </item>
    
    <item>
      <title>카이제곱 분포</title>
      <link>https://freshrimpsushi.github.io/posts/chi-square-distribution/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chi-square-distribution/</guid>
      <description>정의 1 자유도 $r &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\chi^{2} (r)$ 를 카이제곱 분포chi-square Distribution라고 한다. $$ f(x) = {{ 1 } \over { \Gamma(r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} \qquad , x \in (0, \infty) $$ $\Gamma$ 는 감마 함수를 나타낸다. 기초 성질 적률 생성 함수 [1]: $$m(t) = (1-2t)^{-r/2} \qquad , t &amp;lt; {{ 1 } \over { 2 }}$$ 평균과 분산 [2] 평균과 분산: $X \sim \chi^{2} (r)$ 이면 $$ \begin{align*} E(X) =&amp;amp; r \\</description>
    </item>
    
    <item>
      <title>독립인 두 감마 분포에서 베타 분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-beta-distribution-from-two-independent-gamma-distributions/</link>
      <pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-beta-distribution-from-two-independent-gamma-distributions/</guid>
      <description>정리 두 확률 변수 $X_{1},X_{2}$ 가 독립이고 $X_{1} \sim \Gamma ( \alpha_{1} , 1)$, $X_{2} \sim \Gamma ( \alpha_{2} , 1)$ 이라 하면 $$ {{ X_{1} } \over { X_{1} + X_{2} }} \sim \text{beta} \left( \alpha_{1} , \alpha_{2} \right) $$ 설명 두 데이터가 감마 분포를 따르고 독립이라면, 그 합계를 계산했을 때의 비율을 분포이론으로 설명하는데 쓰일 수 있을지도 모른다. 특히 감마분포는 여러가지 확률분포를 비교적 자유롭게 넘나들 수 있으므로 팩트로써는 알아두는 게 좋다. 유</description>
    </item>
    
    <item>
      <title>힐베르트 공간의 프레임</title>
      <link>https://freshrimpsushi.github.io/posts/frame-in-hilbert-space/</link>
      <pubDate>Sun, 26 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/frame-in-hilbert-space/</guid>
      <description>정의1 힐베르트 공간 $H$의 시퀀스 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}}$에 대해 다음을 만족하는 $A,B &amp;gt; 0$이 존재하면 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 을 프레임frame이라 부르고, 특히 $A = B$일 때 이 프레임이 타이트tight하다고 말한다. $$ A \left\| \mathbf{v} \right\|^{2} \le \sum_{k \in \mathbb{N}} \left| \left\langle \mathbf{v} , \mathbf{v}_{k} \right\rangle \right|^{2} \le B \left\| \mathbf{v} \right\|^{2} \qquad , \mathbf{v} \in H $$ 설명 프레임은 베셀 시퀀스와 달리 $A$가 존재해서 $\</description>
    </item>
    
    <item>
      <title>함수의 서포트와 연속함수 공간의 클래스</title>
      <link>https://freshrimpsushi.github.io/posts/support-and-classes-of-continuous-functions/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/support-and-classes-of-continuous-functions/</guid>
      <description>정의 함수공간 $\mathbb{C}^{\mathbb{R}}$ 의 함수 $f : \mathbb{R} \to \mathbb{C}$ 를 생각해보자. 함수 $f$ 의 서포트support란 다음과 같이 함수값이 $0$ 이 아닌 점들의 집합에 클로져를 취한 클로즈 셋이다. $$ \text{supp} f = \overline{\left\{ x \in \mathbb{R} : f(x) \ne 0 \right\}} $$ $\text{supp} f$ 가 유계면 $f$ 가 컴팩트 서포트를 갖는다고 한다. 클로져는 닫힌 집합이고, 실수 공간에서 닫혀있고 유계인 집합은 컴팩트이기 때문이다. $U\Subset V$ 는 $\overline{U} \subset V$이</description>
    </item>
    
    <item>
      <title>힐베르트 공간의 정규직교 기저와 유니터리 작용소</title>
      <link>https://freshrimpsushi.github.io/posts/orthonormal-bases-of-hilbert-space-and-unitary-operator/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthonormal-bases-of-hilbert-space-and-unitary-operator/</guid>
      <description>정리1 $\left\{ \mathbf{e}_{k} \right\}_{k \in \mathbb{N}}$ 을 $H$ 의 정규직교기저라고 하자. 그러면 $H$ 의 정규직교 기저는 유니터리 작용소 $U : H \to H$ 에 대해 정확하게 $\left\{ U \mathbf{e}_{k} \right\}_{k \in \mathbb{N}}$ 과 같이 나타난다. 설명 이러한 결과를 두고 $H$ 의 모든 정규직교 기저가 유니터리 작용소 $U$ 에 의해 캐릭터라이제이션characterization 된다고 말한다. 증명 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 도 $H$ 의 정규직교 기저라고 하자</description>
    </item>
    
    <item>
      <title>4색 지도 문제</title>
      <link>https://freshrimpsushi.github.io/posts/four-color-map-problem/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/four-color-map-problem/</guid>
      <description>빌드업 4색 지도 문제란 어떤 지도든 이웃된 구역이 서로 구별되도록 채색하는데 4가지 색이면 충분한지 묻는 문제다. 지도가 복잡할수록 색은 많아져야할 것 같지만, 바로 옆이랑만 다르면 되기 때문에 생각보다 많은 색이 필요하지는 않다. 예를 들어 다음은 세계지도를 단 $4$가지 색으로 칠한 것이다. 역사적으로 4색 지도 문제는 1852년 영국의 식물학자</description>
    </item>
    
    <item>
      <title>가분 힐베르트 공간은 스몰엘2 공간과 등거리동형임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/separable-hilbert-space-and-l2-space-are-isometrically-isomorphic/</link>
      <pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separable-hilbert-space-and-l2-space-are-isometrically-isomorphic/</guid>
      <description>정리1 모든 무한차원 가분 힐베르트 공간 $H$는 $\ell^{2}$와 등거리 동형이다. 설명 가분성을 가지는 힐베르트 공간이 $\ell^{2}$와 등거리 동형이라는 말은 사실상 힐베르트 공간을 연구할 때 $\ell^{2}$만 연구하면 된다는 말이나 진배 없다. 증명 가분 힐베르트 공간의 그램-슈미트 정규직교화 모든 가분 힐베르트 공간은</description>
    </item>
    
    <item>
      <title>5색 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-five-color-theorem/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-five-color-theorem/</guid>
      <description>정리 1 모든 심플 평면 그래프는 $5$-채색가능하다. 설명 이 정리는 4색 문제와 구분하는 의미에서 5색 정리라는 이름이 붙었다. 역사적으로는 4색 정리를 증명하려고 했지만 증명에 번번히 실패했고, 대신 조금 완화된 팩트로써 증명되었다. 증명 전략: 수학적 귀납법을 사용한다. $n-1$ 개의 버텍스를 가진 심플 평면 그래프가 모두 $5$-채색가능하다고</description>
    </item>
    
    <item>
      <title>가분 힐베르트 공간의 그램-슈미트 정규직교화</title>
      <link>https://freshrimpsushi.github.io/posts/gram-schmidt-orthonormalization-of-separable-hilbert-space/</link>
      <pubDate>Tue, 14 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gram-schmidt-orthonormalization-of-separable-hilbert-space/</guid>
      <description>정리1 모든 가분 힐베르트 공간은 정규직교기저를 가진다. 증명 전략: 유한차원 벡터 공간에서의 그램-슈미트 정규직교화와 본질적으로 같다. 일반적인 힐베르트 공간은 유한차원 벡터 공간과 달리 기저의 존재성이 보장되지 않으므로 가분성에 따라 정규직교화를 거치기 전의 직교 기저인 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}}$ 를 잡아주어야한다. $$ \overline{\text{span}} \left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}} = H $$ 힐베르트 공간</description>
    </item>
    
    <item>
      <title>그래프 이론에서 지도의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/map-of-graph-theory/</link>
      <pubDate>Sun, 12 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/map-of-graph-theory/</guid>
      <description>정의 1 $3$-연결 평면 그래프를 지도라 정의한다. 같은 에지를 사이에 두고 이웃한 페이스끼리 다른 색이 되도록 $k$ 개의 색을 칠할 수 있는 지도를 $k$-페이스 채색가능 지도라 한다. 기존의 $k$-채색가능 그래프를 $k$-버텍스 채색가능 그래프라 한다. 평면 그래프가 그려지면서 평면 상에서 구분되는 영역들을 페이스라 부른다. 설명 $3$-그</description>
    </item>
    
    <item>
      <title>벡터 공간의 리오더링</title>
      <link>https://freshrimpsushi.github.io/posts/reordering-of-vector-space/</link>
      <pubDate>Fri, 10 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reordering-of-vector-space/</guid>
      <description>정의 1 벡터 공간 $V$의 시퀀스 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}}$이 주어져 있다고 하자. 주어진 전단사 $\sigma : \mathbb{N} \to \mathbb{N}$ 에 대해 다음을 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}}$의 리오더링reordering이라 한다. $$ \left\{ \mathbf{v}_{\sigma (k) } \right\}_{k \in \mathbb{N}} = \left\{ \mathbf{v}_{\sigma(1)} , \mathbf{v}_{\sigma(2)} , \cdots \right\} $$ 설명 리오더링 은 순열Permutation이라 불리기도 하는데, 보다시피 어려운 개념이</description>
    </item>
    
    <item>
      <title>심플 평면 그래프의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-simple-planar-graphs/</link>
      <pubDate>Wed, 08 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-simple-planar-graphs/</guid>
      <description>정리 1 $G$ 가 심플 평면 그래프라고 하자. [1]: $G$ 가 연결 그래프고 $n \ge 3$ 개의 버텍스, $m$ 개의 에지를 가지면 $m \le 3n - 6$ [2]: 모든 심플 평면 그래프 $G$ 는 $\deg v \le 5$ 인 버텍스 $v \in V(G)$ 를 가진다. 증명 [1] 평면 그래프의 각 페이스는 적어도 세 개의 에지로 둘러싸여있다고 하자.가장 간단한 케이스로 컴플리트 그래프 $K_{3}$ 만 달랑 있다면 에지 $m=3$ 에 페이스 $f=2$ 고, 여기서 페이스가</description>
    </item>
    
    <item>
      <title>무한 차원 벡터 공간의 샤우더 베이시스</title>
      <link>https://freshrimpsushi.github.io/posts/schauder-basis-of-infinite-dimensional-vector-space/</link>
      <pubDate>Mon, 06 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schauder-basis-of-infinite-dimensional-vector-space/</guid>
      <description>정의1 $(X, \left\| \cdot \right\|)$를 놈 공간이라고 하자. $X$의 모든 원소 $\mathbf{x}\in X$ 에 대해 다음을 만족하는 스칼라의 시퀀스 $\left\{ a_{k} \right\}_{k \in \mathbb{N}}$ 가 유일하게 존재하면 $\left\{ \mathbf{e}_{k} \right\}_{k \in \mathbb{N}} \subset X$ 를 $X$ 의 샤우더 기저Schauder basis 라 한다. $$ \mathbf{x}= \sum_{k \in \mathbb{N}} a_{k} \mathbf{e}_{k} $$ 설명 벡터 공간의 기저는 특히 &amp;lsquo;무한&amp;rsquo; 선형 결합에 대해 논할 때 샤우더 기저라고 불리</description>
    </item>
    
    <item>
      <title>추상적 듀얼 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/abstract-dual-graph/</link>
      <pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abstract-dual-graph/</guid>
      <description>빌드업 기하적 듀얼 그래프의 성질 [3]: 평면 그래프 $G$ 와 그 기하적 듀얼 그래프 $G^{ \ast }$ 에 대해,$C \subset E(G)$ 가 사이클 $\iff$ $C^{ \ast } \subset E \left( G^{ \ast } \right)$ 는 컷셋 추상적 듀얼 그래프는 직관적으로 평면 그래프에 대해 기하적 듀얼 그래프와 달리 일반적인 그래프에 대해서 추상적으로 정의된다. 듀얼 그래프가 어떠한 방법으로 만들어지는 것이 아니라, 듀얼의 성질을 가지면 듀얼 그</description>
    </item>
    
    <item>
      <title>조밀한 부분공간을 갖는 힐베르트 공간의 베셀 시퀀스</title>
      <link>https://freshrimpsushi.github.io/posts/bessel-sequence-in-hilbert-space-having-dense-subspace/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bessel-sequence-in-hilbert-space-having-dense-subspace/</guid>
      <description>정리1 힐베르트 공간 $H$가 주어져 있을 때 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}} \subset H$와 $\overline{V} = H$인 $V \subset H$가 다음을 만족한다고 하자. $$ \sum_{k \in \mathbb{N}} \left| \left\langle \mathbf{v} , \mathbf{v}_{k} \right\rangle \right|^{2} \le B \left\| \mathbf{v} \right\|^{2} \qquad , \mathbf{v} \in V $$ 그러면 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}}$은 베셀 바운드 $B$인 베셀 시퀀스다. 설명 원래 베셀 시퀀스는 모든 $\mathbf{v} \in H$에서 부등식을 만족해야했지만, $\overline{V} = H$에 따라 그러한 조건이</description>
    </item>
    
    <item>
      <title>기하적 듀얼 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/geometric-dual-graph/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/geometric-dual-graph/</guid>
      <description>정의 1 주어진 평면 그래프 $G$ 에 대해 기하적 듀얼 그래프 $G^{ \ast }$ 는 다음과 같이 만들어진다. Step 1. $G$ 의 각 페이스 $f$ 에 대응되는 버텍스 $v^{ \ast }$ 를 찍는다. Step 2. $G$ 의 각 에지 $e$ 와 겹치도록 대응되는 에지 $e^{ \ast }$ 를 긋는다. Step 3. 원래의 그래프는 지우고 $v^{ \ast }$ 와 $e^{ \ast }$ 로 이루어진 그래프를 $G^{ \ast }$ 로 둔다. 평면 그래프가 그려지면서 평면 상에서 구분되는 영역들을 페</description>
    </item>
    
    <item>
      <title>힐베르트 공간으로 일반화된 베셀 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bessels-inequality-of-hilbert-space/</link>
      <pubDate>Sun, 28 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bessels-inequality-of-hilbert-space/</guid>
      <description>정리1 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}}$이 힐베르트 공간 $H$의 정규직교집합이라고 하면 다음이 성립한다. (a) 모든 $\left\{ c_{k} \right\}_{k \in \mathbb{N}} \in \ell^{2}$에 대해 무한 급수 $\sum_{k \in \mathbb{N}} c_{k} \mathbf{v}_{k}$는 수렴한다. (b) 모든 $\mathbf{v} \in H$에 대해 $$ \sum_{k \in \mathbb{N}} \left| \left\langle \mathbf{v} , \mathbf{v}_{k} \right\rangle \right|^{2} \le \left\| \mathbf{v} \right\|^{2} $$ 설명 $\ell^{2}$ 공간이란 제곱의 합이 수렴하는 복소수 시퀀스의 집합</description>
    </item>
    
    <item>
      <title>그래프의 k-연결성과 멩거 정리</title>
      <link>https://freshrimpsushi.github.io/posts/k-connected-and-menger-theorem/</link>
      <pubDate>Fri, 26 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k-connected-and-menger-theorem/</guid>
      <description>정의 주어진 그래프 $G$ 에 대해 컴포넌트의 수를 $\text{comp} (G)$ 라고 나타내자. 1-1. 다음을 만족하는 에지의 집합 $D \subset E(G)$ 를 $G$ 의 단절 집합Disconnecting Set이라 한다. $$ \text{comp} \left( G \setminus D \right) &amp;gt; \text{comp}(G) $$ 1-2. $G$ 단절 집합 중 단절 집합이 아닌 진부분집합을 갖지 않는 단절 집합을 $G$ 의 컷셋Cutset이라 부른다. 1-3. $G$ 가 연결 그래프라고 할 때, (에지) 컷셋의 기수 중</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서의 베셀 시퀀스</title>
      <link>https://freshrimpsushi.github.io/posts/bessel-sequence-of-hilbert-space/</link>
      <pubDate>Wed, 24 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bessel-sequence-of-hilbert-space/</guid>
      <description>정의1 힐베르트 공간 $H$의 시퀀스 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}} \subset H$에 대해 다음을 만족하는 $B &amp;gt; 0$가 존재하면 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}}$를 베셀 시퀀스Bessel sequence라 하고 $B$를 베셀 바운드Bessel bound라 한다. $$ \sum_{k=1}^{\infty} \left| \left\langle \mathbf{v} , \mathbf{v}_{k} \right\rangle \right|^{2 } \le B \left\| \mathbf{v} \right\|^{2}, \quad \forall \mathbf{v} \in H $$ 설명 베셀 시퀀스는 직관적으로 봤을 때 무한차원 벡터 $</description>
    </item>
    
    <item>
      <title>오일러의 다면체 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-polyhedron-formula/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-polyhedron-formula/</guid>
      <description>개요 오일러의 다면체 정리는 오일러의 표수 , 그래프 이론에서는 그냥 오일러 공식 으로도 불린다. 기하학적으로는 공간도형의 점, 선, 면이 #점-#선+#면=2 의 관계를 따른다는 의미를 갖는다. 예로써 정육면체를 생각해보면, $8$ 개의 점과 $12$ 개의 선, $6$ 개의 면을 가지고 있어 $8-12+6=2$ 가 성립한다. 정리 1 연결 평면 그래프 $G$ 에 대해, $n:=|V(G)|$, $m:=|E(G)|$, $f$ 를 페이스의 수라</description>
    </item>
    
    <item>
      <title>리즈 기저</title>
      <link>https://freshrimpsushi.github.io/posts/riesz-basis/</link>
      <pubDate>Mon, 22 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/riesz-basis/</guid>
      <description>정의1 힐베르트 공간 $H$의 정규 직교 기저 $\left\{ \mathbf{e}_{k} \right\}_{k \in \mathbb{N}}$이 주어져 있다고 하자. 전단사 $U : H \to H$가 선형이고 유계인 작용소 모든 $k \in \mathbb{N}$에 대해 $\mathbf{v}_{k} := U \mathbf{e}_{k}$라고 하면 $\left\{ \mathbf{v}_{k} \right\}_{k \in \mathbb{N}}$는 $H$의 기저가 되며 다음이 성립한다. $$ \mathbf{v} = \sum_{k \in \mathbb{N}} \left\langle \mathbf{v} , \left( U^{-1}</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서 l2 공간으로의 수반 작용소</title>
      <link>https://freshrimpsushi.github.io/posts/adjoint-operator-form-hilbert-space-to-l2-space/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adjoint-operator-form-hilbert-space-to-l2-space/</guid>
      <description>정리1 $\left\{ \mathbf{v}_k \right\}_{k \in \mathbb{N}}$이 힐베르트 공간 $H$에서 정의된 시퀀스라 하자. 유계 선형 작용소 $T : \ell^{2} \to H$ 가 다음과 같이 정의되어있다고 하자. $$ T \left\{ c_{k} \right\}_{k \in \mathbb{N}} := \sum_{k=1}^{\infty} c_{k} \mathbf{v}_{k} $$ 그러면 $T$의 수반 작용소 $T^{ \ast } : H \to \ell^{2}$는 다음과 같이 나타난다. $$ T^{ \ast } \mathbf{v} = \left\{ \left\langle \mathbf{v} , \mathbf{v}_{k} \right\rangle_{H} \right\}_{k \in \mathbb{N}} $$ 그 뿐만 아니라, 모든 $\mathbf{v} \in H$ 에 대해</description>
    </item>
    
    <item>
      <title>평면 그래프와 쿠라토프스키 정리</title>
      <link>https://freshrimpsushi.github.io/posts/planar-graph-and-kuratowski-theorem/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/planar-graph-and-kuratowski-theorem/</guid>
      <description>평면 그래프의 정의 그래프를 평면에 그렸을 때 에지가 겹치지 않게 그릴 수 있으면 그 그래프를 평면 그래프라 한다. 설명 평면 그래프가 그려지면서 평면 상에서 구분되는 영역들을 페이스Face라 부른다. 다음과 같은 평면 그래프 $K_{4}$ 는 네 개의 페이스 $f_{1}, f_{2}, f_{3}, f_{4}$ 를 가지며, 그 중에서도 특히 바운드 되지 않은 $f_{4}$ 를 무한 페이스Infinite Face라 부른다.</description>
    </item>
    
    <item>
      <title>힐베르트 공간에서의 직교 사영</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-projection/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-projection/</guid>
      <description>정의1 힐베르트 공간 $H$의 닫힌 부분공간 $V$가 주어져있다고 하자. $\mathbf{v} \in H$가 $\mathbf{v}_{1} \in V$와 $\mathbf{v}_{2} \in V^{\perp}$에 대해 $\mathbf{v} = \mathbf{v}_{1} + \mathbf{v}_{2}$ 와 같이 나타난다고 할 때, 다음을 만족시키는 전사 $P :H \to V$를 직교 사영orthogonal projection 이라고 한다. $$ P \mathbf{v} = \mathbf{v}_{1} $$ 설명 직교 사영은 다음과 같은 성질들을 가진다. $P$ 는 선형이고 유계이며, $| P |</description>
    </item>
    
    <item>
      <title>그래프의 호메오멀피즘</title>
      <link>https://freshrimpsushi.github.io/posts/homeomorphism-of-graphs/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homeomorphism-of-graphs/</guid>
      <description>정의 1 두 그래프 $G_{1}$ 와 $G_{2}$ 가 주어져 있다고 하자. $G_{1}$ 의 어떤 세분 $G_{1}&amp;rsquo;$ 과 $G_{2}$ 의 어떤 세분 $G_{2}&amp;rsquo;$ 에 대해 그래프 아이소멀피즘이 존재하면 $G_{1}$ 와 $G_{2}$ 가 호메오멀픽Homeomorphic하다고 한다. 그래프 $G$ 에 다음과 같은 조건을 만족하는 버텍스 $w$ 들을 차례로 추가한 그래프를 $G$ 의 세분Subdivision $G&#39;$ 이라 한다. $$ \begin{align*} u \sim_{G} v &amp;amp; \implies \begin{cases} u \nsim_{G&#39;} v \\ u \sim_{G&#39;} w \\ w</description>
    </item>
    
    <item>
      <title>힐베르트 공간의 수반 작용소</title>
      <link>https://freshrimpsushi.github.io/posts/adjoint-operator-on-hilbert-space/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adjoint-operator-on-hilbert-space/</guid>
      <description>빌드업1 힐베르트 공간 $\left( H, \left\langle \cdot , \cdot \right\rangle_{H} \right)$ 과 $\left( K, \left\langle \cdot , \cdot \right\rangle_{K} \right)$ 에 대해 유계 선형 작용소 $T : K \to H$ 가 주어져있다고 하자. 그러면 임의의 고정된 원소 $\mathbf{w} \in H$ 에 대해 다음과 같이 정의된 $\Phi : K \to \mathbb{C}$ 는 선형 범함수 $\Phi \in K^{ \ast }$ 가 된다. $$ \Phi \mathbf{v} := \left\langle T \mathbf{v} , \mathbf{w} \right\rangle_{H} $$ 리즈 표현 정리에 따르면 힐베르트 공간 $K$ 는 $\Phi \in K^{ \ast }$ 와 모든 $\mathbf{v} \in K$ 에 대해 다음을 만족하는 원소 $T^{</description>
    </item>
    
    <item>
      <title>그래프 컬러링과 브룩스 정리</title>
      <link>https://freshrimpsushi.github.io/posts/graph-coloring-and-brooks-theorem/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/graph-coloring-and-brooks-theorem/</guid>
      <description>정의 루프가 없는 그래프 $G$ 에 대해 다음과 같은 함수 $f : V(G) \to [k]$ 를 $G$ 의 $k$-컬러링이라 한다. $$ u \sim v \implies f(u) \ne f(v) $$ 그래프 $G$ 가 $k$-컬러링을 가지면 $k$-채색가능이라도 한다. 만약 $k$-채색가능인데 $(k-1)$-채색가능하지 않으면 그 $k$ 를 $G$ 의 크로마틱 수Chromatic Number라 부르고 $\chi(G) = k$ 와 같이 나타낸다. 크</description>
    </item>
    
    <item>
      <title>셀버그 항등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-selberg-identity/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-selberg-identity/</guid>
      <description>정리 1 $$ \Lambda (n) \log n + \sum_{d \mid n } \Lambda (d) \Lambda \left( {{ n } \over { d }} \right) = \sum_{d \mid n} \mu (d) \log^{2} {{ n } \over { d }} $$ 증명 전략: 보이는 것만큼 어렵지 않다. 산술함수의 미분만 있다면 아주 간단하게 유도할 수 있다. 망골트 급수: $$ \sum_{d \mid n} \Lambda ( d ) = \log n $$ 산술 함수의 미분의 정의에 따라 망골트 급수는 컨볼루션을 써서 다음과 같이 나타낼 수 있다. $$ \Lambda \ast\ u = 1 \cdot \log n = u \log n</description>
    </item>
    
    <item>
      <title>하벨-하키미 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-havel-hakimi-algorithm/</link>
      <pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-havel-hakimi-algorithm/</guid>
      <description>정리 증가하지 않는 시퀀스 $D = (d_{1} , \cdots , d_{n})$ 가 주어져있다고 하자. $D$ 가 그래픽하다면 다음과 같은 방법으로 $D$ 의 실현 $G$ 를 찾을 수 있다. Step 1. $n$ 개의 버텍스 $v_{1} , \cdots , v_{n}$ 를 가지는 널 그래프를 만든다. Step 2. $k = 1, \cdots , n$ **Step 2-1. $v_{k}$ 과 $v_{k+1} , \cdots , v_{d_{k} + 1}$ 를 잇는다. Step 2-2. $d_{k+1} , \cdots , d_{d_{k}+1}$ 를 $1$ 씩 감소시킨다. Step 2-3. $d_{k} \leftarrow 0$ 와 같이 대입한다. $D = (0,\cdots , 0)$ 이 될때까지 Step 2.를</description>
    </item>
    
    <item>
      <title>산술 함수의 미분</title>
      <link>https://freshrimpsushi.github.io/posts/derivative-of-arithmetical-function/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivative-of-arithmetical-function/</guid>
      <description>정의 1 산술 함수 $f$ 의 미분 혹은 도함수 $f &#39;$ 를 다음과 같이 정의한다. $$ f &#39; (n) := f(n) \log n \qquad , n \in \mathbb{N} $$ 기초 성질 [1] 합의 미분법: $(f+g)&#39; = f &#39;+g&#39;$ [2] 곱의 미분법: $\left( f \ast g \right)&#39; = f &#39;\ast g + f \ast g&#39;$ [3] 몫의 미분법: $f(1) \ne 0$ 이면 $\left( f^{-1} \right)&#39; = - f &#39; \ast\ (f \ast\ f)^{-1}$ 설명 산술 함수는 개념적으로는 그냥 수열에 지나지 않기 때문에 흔히 변화율로 설명되곤 하는 미분을 정의할 수 없다. 하</description>
    </item>
    
    <item>
      <title>에르되시-갈라이 정리</title>
      <link>https://freshrimpsushi.github.io/posts/erdoes-gallai-theorem/</link>
      <pubDate>Sat, 30 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/erdoes-gallai-theorem/</guid>
      <description>빌드업 그래프 $G$ 의 차수를 중복을 포함해 모아놓은 집합을 그래프 스코어Graph Score라 하고, $G$ 의 그래프 스코어를 내림차순으로 정렬한 시퀀스를 $G$ 의 디그리 시퀀스Degree Sequence라 한다. 증가하지 않는 자연수들의 시퀀스 $D = (d_{1} , \cdots , d_{n})$ 에 대해 $n$ 개의 버텍스 $v_{1} , \cdots , v_{n}$ 가 다음을 만족 시키게끔 하는 그래프 $G$ 가 존재하면 $D$ 가</description>
    </item>
    
    <item>
      <title>산술 함수의 벨 급수</title>
      <link>https://freshrimpsushi.github.io/posts/bell-series-of-arithmetical-function/</link>
      <pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bell-series-of-arithmetical-function/</guid>
      <description>정의 1 주어진 산술 함수 $f$ 와 소수 $p$ 에 대해 다음과 같이 정의된 $f_{p}(x)$ 를 모듈로 $p$ 에서 $f$ 의 벨 급수 라한다. $$ f_{p}(x) := \sum_{n=0}^{\infty} f \left( p^{n} \right) x^{n} $$ 기초 성질 [1] 유일성: 두 산술 함수 $f,g$ 가 승법적라고 하자. 모든 소수 $p$ 에 대해$f = g \iff f_{p}(x) = g_{p}(x)$ [2] 디리클레 곱: 두 산술 함수 $f,g$ 의 디리클레 곱이 $h = f \ast\ g$ 이라고 하자. 그러면 모든 소수 $p$ 에 대해 $$ h_{p}(x) = f_{p}(x) g_{p} (x) $$ 이다. 만약 $h$ 가 승</description>
    </item>
    
    <item>
      <title>레이블 트리와 케일리 정리</title>
      <link>https://freshrimpsushi.github.io/posts/labeled-tree-and-cayley-theorem/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/labeled-tree-and-cayley-theorem/</guid>
      <description>정의 각 버텍스에 서로 다른 수가 부여된 트리를 레이블 트리라 한다. 설명 레이블은 버텍스의 집합과 같이 실제로 원소가 같은지 다른지 구분하는 것과는 다른 개념이다. 가령 다음의 두 그래프는 쓰여있기는 달라도 본질적으로 같은 레이블 트리로 볼 수 있다. $$ 1-2-3 \\ a-b-c $$ 물론 그래프기 때문에 다음의 두 경우는 서로 같다. $$ 1-2-3 \\ 3-2-1 $$ 그러나 다음 두 그래프는 레이블이</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 리우빌 함수</title>
      <link>https://freshrimpsushi.github.io/posts/liouvilles-function-in-analytic-number-theory/</link>
      <pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/liouvilles-function-in-analytic-number-theory/</guid>
      <description>정의 1 소수 $p_{1} , \cdots , p_{k}$ 에 대해 자연수 $n$ 을 $n = p_{1}^{a_{1}} \cdots p_{k}^{a_{k}}$ 과 같이 나타낸다고 하자. 다음과 같이 정의된 산술 함수 $\lambda$ 를 리우빌 함수라 한다. $$ \lambda (n) = (-1)^{a_{1} + \cdots a_{k}} $$ 기초 성질 [1] 리우빌 급수: $n$ 이 제곱수일 때만 $1$ 이고 그 외엔 $0$ 이다. 다시 말해, $$ \sum_{d \mid n} \lambda (d) = \begin{cases} 1 &amp;amp;, n \text{ is a square} \\ 0 &amp;amp; , \text{otherwise}\end{cases} $$ [2] 완전 승법성: 모든 $m,n \in \mathbb{N}$ 에 대해 $\lambda(mn) = \lambda(m) \lambda(n)$ 설명 $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp;</description>
    </item>
    
    <item>
      <title>트리 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/tree-graph/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tree-graph/</guid>
      <description>정의 1 사이클이 존재하지 않는 연결 그래프를 트리라 한다. 설명 트리는 컴퓨터 공학의 자료 구조 등에서 흔히 볼 수 있는 개념으로써, 컴퓨터를 조금이라도 다루는 이공계 전공이라면 아마 힙 소팅이라는 말을 들어봤을 것이다. 여기서 말하는 그 힙이 바로 트리의 일종이다.트리의 유니언은 직관적이게도 포레스트Forest라 부른다. 유향 그래프일 경우 입력</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 망골트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/mangoldt-function-in-analytic-number-theory/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mangoldt-function-in-analytic-number-theory/</guid>
      <description>정의 1 다음과 같이 정의된 산술 함수 $\Lambda$ 를 망골트 함수라 한다. $$ \Lambda(n) := \begin{cases} \log p &amp;amp; n = p^{m} , p \text{ is prime}, m \in \mathbb{N} \\ 0 &amp;amp; \text{otherwise} \end{cases} $$ 기초 성질 [1] 망골트 급수: 로그 함수 $\log$ 다. 다시 말해, $$ \sum_{d \mid n} \Lambda ( d ) = \log n $$ 설명 $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ \Lambda(n) &amp;amp; 0 &amp;amp; \log 2 &amp;amp; \log 3 &amp;amp; \log 2 &amp;amp; \log 5 &amp;amp; 0 &amp;amp; \log 7 &amp;amp; \log 2 &amp;amp; \log 3 &amp;amp; 0 \\ \sum_{d \mid n} \Lambda(d) &amp;amp; 0 &amp;amp; \log 2 &amp;amp;</description>
    </item>
    
    <item>
      <title>그래프 이론에서의 디락 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-diracs-theorem/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-diracs-theorem/</guid>
      <description>정리 1 $G$ 가 $n ( \ge 3)$ 개의 버텍스를 가진 심플 그래프라고 하자. [1] 디락 정리: $G$ 의 모든 버텍스 $v$ 에 대해 $\deg (v) \ge n / 2$ 면 $G$ 는 해밀톤 그래프다. [2] 오레 정리: $G$ 의 모든 인접하지 않은 두 버텍스의 쌍 $(v ,w)$ 에 대해 $\deg (v) + \deg(w) \ge n$ 면 $G$ 는 해밀톤 그래프다. 설명 디락 정리는 해밀톤 그래프의 동치조건까지는 아니지만 어떤 경우에 충분히 해밀톤 그래프인지를 판별해</description>
    </item>
    
    <item>
      <title>뫼비우스 역 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-m%C3%B6bius-inversion-formula/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-m%C3%B6bius-inversion-formula/</guid>
      <description>공식 1 $f$ 와 $g$ 가 산술 함수고 $\mu$ 는 뫼비우스 함수다. $$ f(n) = \sum_{d \mid n} g(d) \iff g(n) = \sum_{d \mid n} f(d) \mu \left( {{ n } \over { d }} \right) $$ 설명 뫼비우스 함수는 그 정의만 보았을 땐 부자연스러운 함수로 보이지만, 사실 산술 함수 전체를 관통하는 핵심 공식에 등장하게 된다. 임의의 산술 함수 $g$ 의 급수는 유닛 함수 $u$ 와 컨볼루션 $\ast$ 을 써서 $g*u$ 와 같이 표현할 수 있는데, 마침 $u$ 의 인버스가 $\mu$,</description>
    </item>
    
    <item>
      <title>해밀톤 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/hamiltonian-graph/</link>
      <pubDate>Thu, 14 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hamiltonian-graph/</guid>
      <description>정의 1 $G$ 가 연결 그래프라고 하자. $G$ 의 모든 버텍스를 포함하는 닫힌 패스가 존재하면 $G$ 를 해밀톤 그래프라 하고 그 사이클을 해밀턴 사이클이라 한다. 모든 버텍스를 포함하지만 닫혀있지 않은 패스가 존재하면 $G$ 를 세미 해밀톤 그래프라 한다. 설명 오일러 그래프가 모든 에지를 지나는 트레일에 관심이 있듯 해밀톤 그래프는 모든 버텍스를 지나는 패스에 관심이 있</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 유닛 함수</title>
      <link>https://freshrimpsushi.github.io/posts/unit-function-in-analytic-number-theory/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unit-function-in-analytic-number-theory/</guid>
      <description>정의 1 다음과 같이 정의된 산술 함수 $u$ 를 유닛 함수라 한다. $$ u(n) := 1 $$ 기초 성질 [1] 유닛 급수: 약수의 갯수 $\sigma_{0}$ 다. 다시 말해, $$ \sum_{d \mid n} u(d) = \sigma_{0} (n) $$ [2] 완전 승법성: 모든 $m,n \in \mathbb{N}$ 에 대해 $u(mn) = u(m) u(n)$ 설명 $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ u (n) &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 \\ \sum_{d \mid n} u(d) &amp;amp; 1 &amp;amp; 2 &amp;amp; 2 &amp;amp; 3 &amp;amp; 2 &amp;amp; 4 &amp;amp; 2 &amp;amp; 4</description>
    </item>
    
    <item>
      <title>플뢰리 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fleurys-algorithm/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fleurys-algorithm/</guid>
      <description>정의 1 $G$ 가 오일러 그래프라고 하자. 그러면 다음과 같은 방법으로 오일러 트레일을 만들 수 있다. 임의의 버텍스 $u$ 에서 시작해서 다음의 두 규칙을 따라 트레일을 만든다: (i): 이미 지나온 에지는 지운다. 만약 에지가 지워지면서 고립 버텍스가 되면 그 버텍스도 지운다. (ii): 각 단계에서 브릿지는 다른 대안이 없을때만 지나간다. 에지 $b \in G$ 가 지워짐으로써 그래프</description>
    </item>
    
    <item>
      <title>쾨니히스베르크의 다리 문제와 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/koenigsberg-bridge-problem-and-solution/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/koenigsberg-bridge-problem-and-solution/</guid>
      <description>문제 1 쾨니히스베르크의 다리 문제는 다음과 같이 도시에 놓인 7개의 다리를 한 번씩만 건너면서 처음 있는 위치로 돌아올 수 있는지에 관한 것이었다. 해법을 모른다면 언뜻 경우의 수를 다 따져봐야하는 막막한 문제로 보인다. 일단 수학 문제처럼 보이지도 않고, 모든 경우를 다 따져보면 풀릴 것 같은데 막상 따져보기가 쉽지는 않다. 위대한 수학자 오일러는 이것을</description>
    </item>
    
    <item>
      <title>베타 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-beta-distribution/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-beta-distribution/</guid>
      <description>공식 $X \sim \text{Beta}(\alpha,\beta)$ 면 $$ E(X)={\alpha \over {\alpha + \beta} } \\ \text{Var} (X)={ { \alpha \beta } \over {(\alpha + \beta + 1) { ( \alpha + \beta ) }^2 } } $$ 유도 전략: 베타 분포의 정의와 감마 함수의 기본적인 성질로 직접 연역한다. 베타 분포의 정의: $\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\text{Beta}(\alpha,\beta)$ 를 베타 분포라고 한다. $$ f(x) = { \Gamma(\alpha + \beta) \over { \Gamma(\alpha) \Gamma(\beta) } } x^{\alpha - 1} (1-x)^{\beta - 1} \qquad , x \in [0,1] $$ 감마 함수의 재귀 공식</description>
    </item>
    
    <item>
      <title>오일러 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/eulerian-graph/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eulerian-graph/</guid>
      <description>정의 $G$ 가 연결 그래프라고 하자. $G$ 의 모든 에지를 포함하는 닫힌 트레일이 존재하면 $G$ 를 오일러 그래프라 하고 그 트레일을 오일러 트레일이라 한다. 모든 에지를 포함하지만 닫혀있지 않은 트레일이 존재하면 $G$ 를 세미 오일러 그래프라 한다. 설명 우리에게는 한 붓 그리기 문제로도 익숙한 개념이다. 오일러 그래프에 대한 논의는 그 유명한 쾨니히스베르크의 다리</description>
    </item>
    
    <item>
      <title>베타 분포</title>
      <link>https://freshrimpsushi.github.io/posts/beta-distribution/</link>
      <pubDate>Sat, 02 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/beta-distribution/</guid>
      <description>정의 1 $\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\text{Beta}(\alpha,\beta)$ 를 베타 분포beta Distribution라고 한다. $$ f(x) = {{ 1 } \over { B(\alpha,\beta) }} x^{\alpha - 1} (1-x)^{\beta - 1} \qquad , x \in [0,1] $$ $B$ 는 베타 함수를 나타낸다. 기초 성질 적률 생성 함수 [1]: $$m(t) = 1 + \sum_{k=1}^{\infty} \left( \prod_{r=0}^{k-1} {{ \alpha + r } \over { \alpha + \beta + r }} {{ t^{k} } \over { k! }} \right) \qquad , t \in \mathbb{R}$$ 평균과 분산 [2]: $X \sim \text{Beta}(\alpha,\beta)$ 면 $$ \begin{align*} E(X)</description>
    </item>
    
    <item>
      <title>쾨닉의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-koenigs-theorem/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-koenigs-theorem/</guid>
      <description>정리 1 $G$ 가 국소적으로 유한인 연결 그래프라고 하자. 그러면 모든 $v \in V(G)$ 에 대해 $v$ 가 시점인 원웨이 무한 패스가 존재한다. 증명 $G$ 는 연결 그래프이므로 $v$ 가 아닌 모든 $z \in V(G)$ 에 대해 $v$ 에서 $z$ 로 가는 패스가 무한히 많이 존재한다. 그리고 $G$ 는 국소적으로 유한하므로 무한히 많은 패스들 중 무한히 많은 일부는 하나의 같은 에지로 시작해야만한다. 그 에지를 $vv_{1}$ 이</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 오일러 토션트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/totient-fuction-in-analytic-number-theory/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/totient-fuction-in-analytic-number-theory/</guid>
      <description>정의 1 다음과 같이 정의된 산술 함수 $\varphi$ 을 토션트 함수라 한다. $$ \varphi (n) := \sum_{\gcd ( k , n ) = 1} 1 $$ 기초 성질 [1] 토션트 급수: 놈 $N$ 이다. 다시 말해, $$ \sum_{d \mid n } \varphi (d) = N(n) $$ [2] 승법성: $\gcd (m,n) = 1$ 을 만족하는 모든 $m, n \in \mathbb{N}$ 에 대해 $\varphi (mn) = \varphi (m) \varphi (n)$ 설명 $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ \varphi(n) &amp;amp; 1 &amp;amp; 1 &amp;amp; 2 &amp;amp; 2 &amp;amp; 4 &amp;amp; 2 &amp;amp; 6 &amp;amp; 4 &amp;amp; 6 &amp;amp; 4 \\ \sum_{d</description>
    </item>
    
    <item>
      <title>그래프의 오리엔테이션</title>
      <link>https://freshrimpsushi.github.io/posts/orientation-of-graph/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orientation-of-graph/</guid>
      <description>빌드업 유향 그래프 $D$ 가 주어져 있다고 하자. 아크의 유한 시퀀스를 유향 워크Directed Walk라 하고 다음과 같이 나타낸다. $$ v_{0} v_{1} , v_{1} v_{2} , \cdots , v_{m-1} v_{m} \\ v_{0} \rightarrow v_{1} \rightarrow v_{2} \rightarrow \cdots \rightarrow v_{m-1} \rightarrow v_{m} $$ 이 때 $v_{0}$ 을 시점Initial Vertex , $v_{m}$ 을 종점Final Vertex이라 하고 $m$ 을 길이Length라 부른다. 유향 워크의 아크가 모두 다르면 유향 트레일Di</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 뫼비우스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/m%C3%B6bius-function-in-analytic-number-theory/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/m%C3%B6bius-function-in-analytic-number-theory/</guid>
      <description>정의 1 소수 $p_{1} , \cdots , p_{k}$ 에 대해 자연수 $n$ 을 $n = p_{1}^{a_{1}} \cdots p_{k}^{a_{k}}$ 과 같이 나타낸다고 하자. 다음과 같이 정의된 산술 함수 $\mu$ 을 뫼비우스 함수라 한다. $$ \mu(n) := \begin{cases} 1 &amp;amp;, n=1 \\ (-1)^{k} &amp;amp;, a_{1} = \cdots = a_{k} = 1 \\ 0 &amp;amp; , \text{otherwise} \end{cases} $$ 기초 성질 [1] 뫼비우스 급수: 아이덴터티 $I$ 다. 다시 말해, $$ \sum_{d \mid n } \mu (d) = I(n) $$ [2] 승법성: $\gcd (m,n) = 1$ 을 만족하는 모든 $m, n \in \mathbb{N}$ 에 대해 $\mu (mn) = \mu (m) \mu (n)$ 설명 $$</description>
    </item>
    
    <item>
      <title>그래프에서의 거리, 네이버후드, 지름, 둘레</title>
      <link>https://freshrimpsushi.github.io/posts/distance-neighborhood-diameter-girth-in-graph/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/distance-neighborhood-diameter-girth-in-graph/</guid>
      <description>정의 그래프 $G$ 에서 시점이 $v \in V(G)$ 고 종점이 $w \in V(G)$ 인 패스의 집합을 $P(v,w)$ 이라 하고 $v \in V(G)$ 를 포함하는 사이클의 집합을 $C(v)$ 라 하자. 그리고 워크 $x$ 의 길이를 $l(x)$ 과 같이 나타내자. 두 버텍스 $v,w \in V(G)$ 사이의 거리 $d$ 는 $v$ 가 시점이고 $w$ 가 종점인 패스의 길이 중 가장 작은 값으로 정의된다. 다시 말해, $$ d(v,w) := \min_{v,w \in V(G)} \left\{ l(x) : x \in P(v,w) \right\} $$ 버텍스 $v \in V(G)$ 에 대해 $v$ 와의 거리가 정</description>
    </item>
    
    <item>
      <title>해석적 정수론에서의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-in-analytic-number-theory/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-in-analytic-number-theory/</guid>
      <description>정의 1 다음과 같이 정의된 산술 함수 $N$ 을 놈이라 한다. $$ N(n) := n $$ 기초 성질 [1] 놈 급수: 시그마 함수 $\sigma = \sigma_{1}$ 다. 다시 말해, $$ \sum_{d \mid n } N(d) = \sigma_{1}(n) $$ [2] 완전 승법성: 모든 $m,n \in \mathbb{N}$ 에 대해 $N(mn) = N(m) N (n)$ 설명 $$ \begin{matrix} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ N(n) &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 \\ \sum_{d \mid n} N(d) &amp;amp; 1 &amp;amp; 3 &amp;amp; 4 &amp;amp; 7 &amp;amp; 6 &amp;amp; 6 &amp;amp; 8 &amp;amp; 15 &amp;amp;</description>
    </item>
    
    <item>
      <title>그래프 이론에서의 워크, 트레일, 패스, 사이클</title>
      <link>https://freshrimpsushi.github.io/posts/walk-trail-path-cycle/</link>
      <pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/walk-trail-path-cycle/</guid>
      <description>정의 1 그래프 $G$ 가 주어져 있다고 하자. 에지의 유한 시퀀스를 워크라 하고 다음과 같이 나타낸다. $$ v_{0} v_{1} , v_{1} v_{2} , \cdots , v_{m-1} v_{m} \\ v_{0} \rightarrow v_{1} \rightarrow v_{2} \rightarrow \cdots \rightarrow v_{m-1} \rightarrow v_{m} $$ 이 때 $v_{0}$ 을 시점Initial Vertex , $v_{m}$ 을 종점Final Vertex이라 하고 $m$ 을 길이Length라 부른다. 워크의 에지가 모두 다르면 트레일이라 한다. 워크의 버텍스가 모두 다르면 패스라 한다</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 디바이저 함수</title>
      <link>https://freshrimpsushi.github.io/posts/divisor-function-in-analytic-number-theory/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divisor-function-in-analytic-number-theory/</guid>
      <description>정의 1 $\alpha \in \mathbb{C}$ 에 대해 다음과 같이 정의된 $\sigma_{\alpha} : \mathbb{N} \to \mathbb{C}$ 을 디바이저 함수라 부른다. $$ \sigma_{\alpha} (n) := \sum_{d \mid n} d^{\alpha} $$ 기초 성질 [1] 승법성: $\gcd (m,n) = 1$ 을 만족하는 모든 $m, n \in \mathbb{N}$ 에 대해 $\sigma_{\alpha} (mn) = \sigma_{\alpha} (m) \sigma_{\alpha} (n)$ [2]: 소수 $p$ 와 자연수 $a$ 에 대해 $$ \sigma_{\alpha} \left( p^{a} \right) = \begin{cases} a +1 &amp;amp; , \alpha = 0 \\ {{ p^{\alpha (a+1)} - 1 } \over { p^{\alpha} - 1 }} &amp;amp;,\alpha \ne 0 \end{cases} $$ 설명 특히 $\alpha = 0$ 이면 약수의 수를 나타내는 함수 $d := \sigma_{0}$ 로 나타내기도</description>
    </item>
    
    <item>
      <title>무한 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/infinite-graph/</link>
      <pubDate>Tue, 14 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/infinite-graph/</guid>
      <description>정의 1 그래프 $G$ 의 버텍스 집합 $V(G)$ 나 에지 집합 $E(G)$ 가 무한 집합이면 $G$ 를 무한 그래프라고 한다. $V(G)$ 와 $E(G)$ 가 모두 가산 집합인 무한 그래프 $G$ 를 가산 그래프Countable Graph라 한다. 무한 그래프 $G$ 의 버텍스 $v \in V(G)$ 에 대해 $A(v)$ 를 다음과 같이 정의하자. $$ A(v) := \left\{ w : vw \in E(G) \right\} $$ 무한 그래프 $G$ 의 버텍스의 차수는 다음과 같이 $A(v)$ 의 기수로 정의한다. $$ \deg</description>
    </item>
    
    <item>
      <title>승법적 함수의 아벨리안 그룹</title>
      <link>https://freshrimpsushi.github.io/posts/abelian-group-of-multiplicative-functions/</link>
      <pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abelian-group-of-multiplicative-functions/</guid>
      <description>정리 1 승법적 함수 들의 집합 $M$ 과 이항 연산 $\ast$ 에 대해 $(M,*)$ 는 아벨리안 그룹이다. 설명 산술 함수의 집합 $A$ 가 컨볼루션 $\ast$과 더불어 아벨리안 그룹 $(A,*)$ 가 되듯, 승법적 함수 역시 아벨리안 그룹이 된다. 물론 $M \le A$, 즉 $M$ 이 $A$ 의 서브 그룹이 된다. 증명 모노이드 $\left&amp;lt; G, \ast\ \right&amp;gt;$ 의 원소 $a$ 와 항등원 $e$ 대해 $a \ast\ a&amp;rsquo; = a&amp;rsquo; \ast\ a = e$ 를 만족하는 $a&amp;rsquo;$ 가 존재하면 $\left&amp;lt; G, \ast\ \r</description>
    </item>
    
    <item>
      <title>이분 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/bipartite-graph/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bipartite-graph/</guid>
      <description>정의 1 그래프 $G$ 의 버텍스 $V(G)$ 에 대해 파티션 $\left\{ A,B \right\}$ 가 존재하고 모든 $xy \in E(G)$ 에 대해 $x \in A, y \in B$ 혹은 $x \in B , y \in A$ 이면 $G$ 를 이분 그래프라 부르고 $G = G(A,B)$ 와 같이 나타내기도 한다. 설명 이분 그래프는 그 이름 그대로 버텍스가 두 부류로 나뉘며, 같은 부류끼리는 인접하지 않은 그래프다. 가령 다음의 그림을 보면 주황색 버텍스 끼리는 인접하지 않고, 파란색 버</description>
    </item>
    
    <item>
      <title>디리클레 곱과 승법적 성질</title>
      <link>https://freshrimpsushi.github.io/posts/drichlet-convolution-and-multiplicativity/</link>
      <pubDate>Wed, 08 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/drichlet-convolution-and-multiplicativity/</guid>
      <description>정리 1 [1]: $f$ 와 $g$ 가 승법적 함수면 $f \ast\ g$ 도 승법적 함수다. [2]: $g$ 와 $f \ast g$ 가 승법적 함수면 $f$ 도 승법적 함수다. 설명 이 성질들은 승법적 함수들의 대수적인 성질을 논할 때 바로 쓰일 수 있다: 정리 [1]은 다시 말해 승법적 함수가 컨볼루션 $\ast$에 대해 닫혀있음을 의미한다. 정리 [2]는 $g$ 와 $I = g\ast g^{-1}$ 와 같이 둠으로써 승법적 함수의 인버스가 승법적</description>
    </item>
    
    <item>
      <title>감마 분포와 카이제곱 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-chi-squared/</link>
      <pubDate>Tue, 07 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-chi-squared/</guid>
      <description>정리 $$ \Gamma \left( { r \over 2 } , 2 \right) \iff \chi ^2 (r) $$ 설명 감마 분포와 카이제곱 분포는 위와 같은 성질을 가진다. 증명 전략: 두 분포의 적률생성함수가 같은 형태로 나타날 수 있음을 보인다. 카이제곱분포 $\chi ^2 (r)$ 의 적률생성함수는 $\displaystyle m_{1}(t) = (1- 2t)^{- {r \over 2} }$ 이고 감마분포 $\Gamma(k, \theta)$ 의 적률생성함수는 $m_{2}(t) = (1-\theta t)^{-k}$ 이다. 감마분포의 적률생성함수에 $\displaystyle k = {r \over 2}$ 과 $\theta = 2$ 을 대입하</description>
    </item>
    
    <item>
      <title>레귤러 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/regular-graph/</link>
      <pubDate>Mon, 06 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regular-graph/</guid>
      <description>정의 1 모든 버텍스의 차수가 같은 그래프를 레귤러 그래프Regular Graph라고 한다. 특히 모든 버텍스의 차수가 $r$ 이면 $r$-레귤러 그래프라고 한다. 다시 말해, 다음을 만족시키는 그래프 $G$ 를 $r$-레귤러 그래프라고 한다. $$ \deg (v) = r \qquad , \forall v \in V(G) $$ $2$-레귤러 연결 그래프를 사이클Cycle이라고 한다. 예시 레귤러 그래프</description>
    </item>
    
    <item>
      <title>감마 분포와 지수 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-exponential/</link>
      <pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-exponential/</guid>
      <description>정리 $$ \Gamma \left(1, { 1 \over \lambda } \right) \iff \text{exp} (\lambda) $$ 설명 지수 분포의 직관적인 정의를 생각해보면 어떤 사건이 일어날때까지 걸리는 시간에 관심이 있는 것이다. 이산 확률 분포로 따지자면 기하 분포가 이에 해당한다. 이때 기하 분포를 사건의 &amp;lsquo;발생 횟수&amp;rsquo;에 대해 일반화한 것이 음이항 분포다. 이런 센스에서, 지수 분포를 일반화한 것은 감마 분포라</description>
    </item>
    
    <item>
      <title>산술 함수의 승법적 성질</title>
      <link>https://freshrimpsushi.github.io/posts/multiplicativity-of-arithmetical-function/</link>
      <pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplicativity-of-arithmetical-function/</guid>
      <description>정의 1 $\forall n \in \mathbb{N}$ 에 대해 $f(n) = 0$ 은 아닌 산술 함수 $f$ 가 다음을 만족시키면 승법적 함수라 한다. $$ f(mn) = f(m) f(n) \qquad,\gcd(m,n)=1 $$ 승법적 함수가 다음 조건을 만족시키면 완전 승법적 함수라 한다. $$ f(mn) = f(m) f(n) \qquad,m,n \in \mathbb{N} $$ 기초성질 [1]: $f$ 가 승법적이면 $f(1) = 1$ 이다. [2]: $f$ 가 승법적 함수인 것과 모든 소수 $p_{1} , \cdots , p_{r}$ 와 모든 $a_{1} , \cdots, a_{r} \in \mathbb{N}$ 에 대해 $f \left( p_{1}^{a_{1}} \cdots p_{r}^{a_{r}} \right) = f \left( p_{1}^{a_{1}} \right) \cdots f \left( p_{r}^{a_{r}} \right)$ 은 동</description>
    </item>
    
    <item>
      <title>감마 분포와 푸아송 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-poisson/</link>
      <pubDate>Fri, 03 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-poisson/</guid>
      <description>정리 모든 자연수 $k$ 에 대해 $$ \int_{\mu}^{\infty} { { z^{k-1} e^{-z} } \over { \Gamma (k) } } dz = \sum_{x=0}^{k-1} { { {\mu}^{x} e^{-\mu} } \over {x!} } $$ 이 등식은 감마 분포와 푸아송 분포의 누적 확률 분포 함수가 서로 관련이 있음을 보여준다. 이는 감마 분포가 지수 분포와의 관계를 가진다는 점에서 충분히 그럴법하다고 말할 수 있다. 증명 $k=1$ 일 때 $$ \int_{\mu}^{\infty} { { z^{0} e^{-z} } \over { \Gamma (0) } } dz = e^{-\mu} = \sum_{x=0}^{0} { { {\mu}^{x} e^{-\mu} } \over {x!} } $$ $k=N$일 때</description>
    </item>
    
    <item>
      <title>널 그래프와 컴플리트 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/null-graph-and-complete-graph/</link>
      <pubDate>Thu, 02 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/null-graph-and-complete-graph/</guid>
      <description>정의 1 심플 그래프 $G$ 가 주어져 있다고 하자. $E(G) = \emptyset$ 이면 $G$ 를 널 그래프라고 한다. $E \left( \overline{G} \right) = \emptyset$ 이면 $G$ 를 컴플리트 그래프라고 한다. 설명 널 그래프는 말 그대로 비어있는 그래프를 의미한다. 여기서 Empty(빌 공, 空)이 아니라 Null(영 영, 零)이라는 표현을 쓴 이유는 실제로 $G \ne \emptyset$ 일지라도 그래프로써 아무런 의미가 없기 때문이다. 예컨대</description>
    </item>
    
    <item>
      <title>감마 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-gamma-distribution/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-gamma-distribution/</guid>
      <description>공식 $X \sim \Gamma ( \alpha , \beta )$ 면 $$ E(X) = k \theta \\ \text{Var} (X) = k \theta^{2} $$ 유도 전략: 감마 분포의 정의와 감마 함수의 기본적인 성질로 직접 연역한다. $x$ 의 차수가 변하는만큼 계수의 분자 분모를 맞춰주는 트릭을 쓴다. 감마 분포의 정의: $k, \theta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\Gamma ( k , \theta )$ 를 감마 분포라고 한다. $$ f(x) = {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x^{k</description>
    </item>
    
    <item>
      <title>감마 분포</title>
      <link>https://freshrimpsushi.github.io/posts/gamma-distribution/</link>
      <pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gamma-distribution/</guid>
      <description>정의 1 $k, \theta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\Gamma ( k , \theta )$ 를 감마 분포Gamma Distribution라고 한다. $$ f(x) = {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x^{k - 1} e^{ - x / \theta} \qquad , x &amp;gt; 0 $$ $\Gamma$ 는 감마 함수를 나타낸다. 감마 분포의 확률 밀도 함수는 $\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같이 정의되기도 한다. 본질적으로는 $\theta = {{ 1 } \over {</description>
    </item>
    
    <item>
      <title>그래프 컴플리먼트</title>
      <link>https://freshrimpsushi.github.io/posts/complement-of-graph/</link>
      <pubDate>Sun, 29 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complement-of-graph/</guid>
      <description>정의 1 심플 그래프 $G$ 에 대해 다음을 만족하는 그래프 $\overline{G}$ 를 $G$ 의 컴플리먼트라 한다. $$ V \left( \overline{G} \right) = V(G) \\ vw \in E \left( \overline{G} \right) \iff vw \notin E(G) $$ 설명 보통의 수학에서 컴플리먼트Complement가 그러하듯 그래프의 컴플리먼트는 補(도울 보)의 개념을 의미한다. 한국어 순화로는 여그래프Complement Graph가 될텐데, 다 마음에 들지 않아서 그냥</description>
    </item>
    
    <item>
      <title>산술 함수의 아벨리안 그룹</title>
      <link>https://freshrimpsushi.github.io/posts/abelian-group-of-arithmetic-functions/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abelian-group-of-arithmetic-functions/</guid>
      <description>정리 1 $f(1) \ne 0$ 이 아닌 산술 함수 들의 집합 $A = \left\{ f : \mathbb{N} \to \mathbb{C} \mid f(1) \ne 0 \right\}$ 과 이항 연산 $\ast$ 에 대해 $(A,*)$ 는 아벨리안 그룹이다. 설명 엄밀히 말하면 모든 산술 함수의 집합이 아벨리안 그룹이 될 수 있는 것은 아니다. 대수적 구조가 그룹이 되기 위한 마지막 조건인 역원의 존재성 때문인데, 다행스럽게도 그렇게 어려운 조건은 아니고 $f(1) \ne 0$ 이면 충분하다. 증명 모노이드 $\left&amp;lt;</description>
    </item>
    
    <item>
      <title>기하 분포의 무기억성</title>
      <link>https://freshrimpsushi.github.io/posts/memoryless-property-of-geometric-distribution/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/memoryless-property-of-geometric-distribution/</guid>
      <description>정리 $X \sim \text{Geo} ( m )$ 이면 $P(X \ge s+ t ,|, X \ge s) = P(X \ge t)$ 설명 기하 분포는 어떤 사건이 일어나는 횟수에 관심을 두는 이산확률분포다. 지수 분포의 이산화라는 센스에서 생각해보면 이러한 기하분포의 무기억성은 당연하다고 할 수 있겠다. 여기서 무기억성Memoryless Property이란 지나온 시간에 의해 앞으로 일어날 일이 영향을 받지 않는 성질이</description>
    </item>
    
    <item>
      <title>서브 그래프</title>
      <link>https://freshrimpsushi.github.io/posts/subgraph/</link>
      <pubDate>Wed, 25 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subgraph/</guid>
      <description>정의 1 그래프 $G$ 에 대해서 그래프 $H$ 가 $V(H) \subset V(G)$ 와 $ E(H) \subset E(G)$ 를 만족하면 $H$ 가 $G$ 의 서브 그래프라 한다. 설명 주의해야하는 것은 $H$ 가 $G$ 의 서브 그래프라고 $H \subset G$ 와 같이 나타내면 안 된다는 것이다. 서브 그래프는 직접적으로 그래프 이론에서 어떤 관심의 대상이 된다기보단 당연하고 상식적인 용어로써 의미가 있다. 예시 서브 그래프를 정의함으로써 생각할 수 있는</description>
    </item>
    
    <item>
      <title>지수 분포의 무기억성</title>
      <link>https://freshrimpsushi.github.io/posts/memoryless-property-of-exponential-distribution/</link>
      <pubDate>Tue, 24 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/memoryless-property-of-exponential-distribution/</guid>
      <description>성질 $X \sim \exp{ ( \lambda ) }$ 이면 $P(X \ge s+ t ,|, X \ge s) = P(X \ge t)$ 설명 지수 분포는 어떤 사건이 일어나는 기간에 관심을 두는 연속확률분포다. 깊게 생각하지 않아도 수명예측이나 보험 등에 응용될 수 있음을 짐작할 수 있다. 여기서 무기억성Memoryless Property이란 지나온 시간에 의해 앞으로 일어날 일이 영향을 받지 않는 성질이다. 예를 들어 30대</description>
    </item>
    
    <item>
      <title>그래프의 집합 표현</title>
      <link>https://freshrimpsushi.github.io/posts/set-representation-of-graph/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/set-representation-of-graph/</guid>
      <description>정의 1 두 그래프 $G_{1}$ 과 $G_{2}$ 에 대해 $V(G_{1}) \cap V(G_{2}) = \emptyset$ 이라고 하자. 두 그래프의 유니언Union $G = G_{1} \cup G_{2}$ 은 버텍스 셋 $V(G_{1}) \cup V(G_{2})$ 과 에지 셋 $E (G_{1}) \cup E ( G_{2} )$ 을 가지는 그래프다. 그래프 $H$ 가 그래프들의 유니언으로 표현될 수 없으면 $H$ 를 연결되었다Connected고 하고, 그 외에는 단절되었다Disconnected고 한다. 단절된 그래프를 이루는 각 연결</description>
    </item>
    
    <item>
      <title>지수 분포와 푸아송 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-exponential-and-poisson/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-exponential-and-poisson/</guid>
      <description>정리 사건이 일어날 때 걸리는 시간 $X_{k}$ 에 대해 $X_{k} \sim \exp (\lambda)$ 이면 단위시간 당 발생하는 사건의 횟수 $N$ 에 대해 $\displaystyle N \sim \text{Poi} (\lambda)$ 설명 지수 분포와 푸아송 분포의 직관적인 정의를 생각해보자. 지수분포는 어떤 사건이 발생하기까지 걸리는 시간에 관심이 있고, 푸아송분포는 단위 시간 내에 어떤 사건이 몇 번 발생하는지 관심이 있다. 어떤 사건이 일어나는 시간과 사건이 일어나는</description>
    </item>
    
    <item>
      <title>지수 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-exponential-distribution/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-exponential-distribution/</guid>
      <description>공식 $X \sim \exp ( \lambda)$ 면 $$ E(X) = {{ 1 } \over { \lambda }} \\ \text{Var} (X) = {{ 1 } \over { \lambda^{2} }} $$ 증명 전략: 지수 분포의 정의에서 직접 연역한다. 지수 분포의 정의: $\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\exp ( \lambda)$ 를 지수 분포라고 한다. $$ f(x) = \lambda e^{-\lambda x} \qquad , x \ge 0 $$ 평균 $$ E(X)=\int _{ 0 }^{ \infty }{ x\cdot \lambda { e } ^{ -\lambda x } }dx $$ $\lambda x=t$ 이라고 두면 $\lambda dx=dt$ 이므로 $$ \begin{align*} \int _{ 0 }^{ \infty</description>
    </item>
    
    <item>
      <title>지수 분포</title>
      <link>https://freshrimpsushi.github.io/posts/exponential-distribution/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/exponential-distribution/</guid>
      <description>정의 1 $\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\exp ( \lambda)$ 를 지수 분포Exponential Distribution라고 한다. $$ f(x) = \lambda e^{-\lambda x} \qquad , x \ge 0 $$ 모수는 책에 따라서 그 역수인 $\displaystyle \theta = {{ 1 } \over { \lambda }}$ 을 쓰기도 한다. 기초 성질 적률 생성 함수 [1]: $$m(t) = {{ \lambda } \over { \lambda - t }} \qquad , t &amp;lt; \lambda$$ 평균과 분산 [2]: $X \sim \exp ( \lambda)$ 면 $$ \begin{align*} E(X) =&amp;amp;</description>
    </item>
    
    <item>
      <title>다르부의 중간값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-darbouxs-intermediate-value-theorem/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-darbouxs-intermediate-value-theorem/</guid>
      <description>정리 함수 $f : [a,b] \to \mathbb{R}$ 이 $[a,b]$ 에서 미분가능하면 $f &#39; (a)$ 와 $f &#39; (b)$ 사이의 $y_{0}$ 에 대해 $y_{0} = f(c)$ 를 만족하는 $c \in (a,b)$ 가 존재한다. 설명 본 포스트는 &amp;lsquo;짱지&amp;rsquo;님의 요청으로 작성되었다. 증명 일반성을 잃지 않고, $f &#39; (a) &amp;lt; y_{0} &amp;lt; f &#39;(b)$ 라 가정하자. 이에 대해 다음과 같은 함수 $g$ 를 정의하자. $$ g(x) := y_{0} x - f(x) $$ $g$ 는 $[a,b]$ 에서 미분가능하므로 연속</description>
    </item>
    
    <item>
      <title>그래프의 행렬 표현</title>
      <link>https://freshrimpsushi.github.io/posts/matrix-representation-of-graph/</link>
      <pubDate>Tue, 17 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/matrix-representation-of-graph/</guid>
      <description>정의 1 그래프 $G(V,E)$가 주어졌다고 하자. 차수 행렬 각 버텍스 $v_{i}\in V$ 의 차수 $d(v_{i})$를 간단히 $d_{i}$라고 표기하자. 다음과 같은 행렬을 $G$ 의 차수 행렬degree matrix이라고 하고 $D(G)$ 혹은 간단하게 $D$라고 표기한다. $$ D(G) = \mathrm{diag} (d_{1}, \dots, d_{n}) = \begin{bmatrix} d_{1} &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; d_{2} &amp;amp; \cdots &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; \cdots</description>
    </item>
    
    <item>
      <title>자율 시스템의 플로우와 타임-T 맵</title>
      <link>https://freshrimpsushi.github.io/posts/t-map-of-autonomous-system/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/t-map-of-autonomous-system/</guid>
      <description>정의 1 공간 $X$ 와 함수 $f : X \to X$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ x&#39; = f(x) $$ 시간 변수 $t$ 와 초기값 $x_{0}$ 에 대한 자율 미분 방정식의 해를 플로우라 하고 $F(t, x_{0})$ 와 같이 나타낸다. 픽스된 단위 시간 $t = T$ 에 대해 $F_{T}(x) := F(T,x)$ 를 타임-$T$ 맵이라 한다. 설명 플로우Flow는 궤적Trajectory 혹은 위상 공간Phase S</description>
    </item>
    
    <item>
      <title>악수 딜레마 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-handshaking-dilemma/</link>
      <pubDate>Fri, 13 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-handshaking-dilemma/</guid>
      <description>정리 1 임의의 유향 그래프에서, 입력 차수의 합과 출력 차수의 합은 같다. 설명 악수 딜레마는 유향 그래프에서의 악수 렘마라고 할 수 있다. 증명 유향 그래프에서 출력 차수의 합은 아크의 수와 같다. 아크는 하나의 버텍스에서 나오고 하나의 버텍스로 들어가므로, 출력 차수와 입력 차수의 합은 같다. ■ Wilson. (1970). Introduction to Graph Theory: p105.&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>미분방정식으로 표현되는 동역학계와 평형점</title>
      <link>https://freshrimpsushi.github.io/posts/autonomous-system-and-equilibrium-in-dynamics/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/autonomous-system-and-equilibrium-in-dynamics/</guid>
      <description>정의 1 공간 $V$ 와 함수 $f : V \to V$ 에 대해 다음과 같은 벡터 필드가 미분 방정식으로 주어져 있다고 하자. $$ v&amp;rsquo; = f(v) $$ 변수 $t$ 를 포함하는 미분 방정식에서 $t$ 가 명시적으로Explicitly 드러나지 않으면 자율 미분 방정식Automonous Differential Equation이라 한다. 상수 함수 $f_{0} (v)$ 가 자율 미분 방정식 $v &amp;rsquo; = f(v)$ 의 솔루션이면 $f_{0}$ 를 평형점Equ</description>
    </item>
    
    <item>
      <title>악수 렘마 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-handshaking-lemma/</link>
      <pubDate>Mon, 09 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-handshaking-lemma/</guid>
      <description>정리 1 임의의 그래프에서, 모든 버텍스의 차수의 합은 짝수다. 설명 이름의 &amp;lsquo;악수&amp;rsquo;는 보다시피 각각의 버텍스가 인접한 버텍스와 악수를 한다고 했을 때, 그 횟수가 바로 차수의 합이기 때문에 붙은 것이다. 증명 그래프 $G$ 에 대해 모든 차수의 합은 정확하게 모든 에지의 수의 두 배여야하므로 $$ \sum_{v \in V(G)} \deg (v) = 2 \left| E(G) \right| $$ ■ 위의 증명에</description>
    </item>
    
    <item>
      <title>어트랙터의 카오스</title>
      <link>https://freshrimpsushi.github.io/posts/chaotic-attractor/</link>
      <pubDate>Sat, 07 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaotic-attractor/</guid>
      <description>빌드업 공간 $X = \left( \mathbb{R}^{n} , \left\| \cdot \right\| \right)$ 와 함수 $f,g : X \to X$ 에 대해 벡터 필드, 맵이 다음과 같이 표현된다고 하자. $$ x&#39; = f(x) \\ x \mapsto g(x) $$ $\phi(t, \cdot)$ 은 벡터 필드 $x&#39; = f(x)$ 의 플로우, $g^{n}$ 는 맵 $g$ 를 $n$ 번 취한 맵을 나타내고, $\Lambda \subset X$ 가 $\phi(t, \cdot)$ 혹은 $g(\cdot)$ 하에서 불변 컴팩트 집합이라고 하자. $\phi(t,x)$ 혹은 $g(x)$ 가 $\Lambda$ 에서 초기값에 민감하다Sensitive Dependence on Initial Conditions는 것</description>
    </item>
    
    <item>
      <title>그래프 이론에서의 차수</title>
      <link>https://freshrimpsushi.github.io/posts/degree-in-graph-theory/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/degree-in-graph-theory/</guid>
      <description>정의 1 유향 그래프 $G$ 가 주어져있다고 하자. 에지 $vw$ 가 존재하면 에지가 $v$ 에서 나가고 $w$ 로 들어간다고 말한다. 버텍스 $v$ 로 들어오는 에지의 수를 입력 차수Indegree라 하고 $\deg^{-} (v)$ 와 같이 나타낸다. 버텍스 $v$ 에서 나가는 에지의 수를 출력 차수Outdegree라 하고 $\deg^{+}(v)$ 와 같이 나타낸다. $\deg^{-} (v) = 0$ 인 버텍스를 소스Source , $\deg^{+} (v) = 0$ 인 버텍</description>
    </item>
    
    <item>
      <title>디리클레 곱에 대한 인버스</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-function-under-drichlet-convolution/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-function-under-drichlet-convolution/</guid>
      <description>정의 1 산술 함수 $f$ 에 대해 다음을 만족하는 산술 함수 $f^{-1}$ 가 유일하게 존재하면 $f^{-1}$ 를 $f$ 의 (디리클레) 인버스라 한다. $$ f \ast\ f^{-1} = f^{-1} \ast\ f = I $$ 여기서 $I$ 는 컨볼루션에 대한 아이덴터티 함수다. 정리 [1]: 산술 함수 $f$ 가 $f(1) \ne 0$ 면 그 인버스 $f^{-1}$ 가 유일하게 존재하고, 다음과 같은 재귀함수로 나타난다. $$ f^{-1}(n) = \begin{cases} \displaystyle {{1} \over {f(1)}} &amp;amp;,n=1 \\ \displaystyle {{-1} \over {f(1)}} \sum_{d \mid n , d &amp;lt; n } f \left( {{ n</description>
    </item>
    
    <item>
      <title>그래프의 아이소멀피즘</title>
      <link>https://freshrimpsushi.github.io/posts/isomorphism-of-graphs/</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isomorphism-of-graphs/</guid>
      <description>정의 1 두 그래프 $G_{1}$ 와 $G_{2}$ 가 주어져 있다고 하자. $V(G_{1})$ 과 $V(G_{2})$ 사이에 전단사가 존재하고 $G_{1}$ 의 버텍스끼리의 에지의 수와 그에 대응하는 $G_{2}$ 의 버텍스끼리의 에지의 수가 같으면 그 전단사를 아이소멀피즘이라 하고 두 그래프가 아이소멀픽Isomorphic하다고 한다. 다시 말해, 다음을 만족하는 전단사 $\phi : G_{1} \to G_{2}$ 를 아이소멀피즘이라 부른다. $$ u \sim_{1} v \iff \phi (u)</description>
    </item>
    
    <item>
      <title>푸아송 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-poisson-distribution/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-poisson-distribution/</guid>
      <description>공식 $X \sim \text{Poi}(\lambda)$ 면 $$ E(X) = \lambda \\ \text{Var}(X) = \lambda $$ 유도 전략: 푸아송 분포의 정의에서 직접 연역한다. 팩토리얼과 급수를 쪼개는 트릭이 중요하다. 푸아송 분포의 정의: $\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Poi} ( \lambda )$ 를 푸아송 분포라고 한다. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over { x! }} \qquad , x = 0 , 1 , 2, \cdots $$ 평균 $$ \begin{align*} E(X) =&amp;amp; \sum _{ x=0 }^{ \infty }{ x\frac { { \lambda ^ x }{ e ^</description>
    </item>
    
    <item>
      <title>푸아송 분포</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-distribution/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-distribution/</guid>
      <description>정의 1 $\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Poi} ( \lambda )$ 를 푸아송 분포Poisson Distribution라고 한다. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over { x! }} \qquad , x = 0 , 1 , 2, \cdots $$ 기초 성질 적률 생성 함수 [1]: $$m(t) = \exp \left[ \lambda \left( e^{t} - 1 \right) \right] \qquad , t \in \mathbb{R}$$ 평균과 분산 [2]: $X \sim \text{Poi}(\lambda)$ 면 $$ \begin{align*} E(X) =&amp;amp; \lambda \\ \text{Var}(X) =&amp;amp; \lambda \end{align*} $$ 충분통계량과 최대우도추정량 [3]: 랜덤</description>
    </item>
    
    <item>
      <title>디리클레 곱에 대한 아이덴터티</title>
      <link>https://freshrimpsushi.github.io/posts/identity-function-under-drichlet-convolution/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/identity-function-under-drichlet-convolution/</guid>
      <description>정의 1 다음과 같이 정의된 산술 함수 $I$ 를 아이덴터티 함수라 한다. $$ I(n) := \left[ {{ 1 } \over { n }} \right] $$ [1] 아이덴터티 급수: 유닛 함수 $u$ 다. 다시 말해, $$ \sum_{d \mid n}I(d) = u(n) = 1 $$ [2] 완전 승법성: 모든 $n , m \in \mathbb{N}$ 에 대해 $I (mn) = I(m) I(n)$ [a] 컨볼루션에 대한 항등원: 모든 산술 함수 $f$ 에 대해 $$ I \ast\ f = f \ast\ I = f $$ $\left[ x \right] = \lceil x \rceil$ 는 바닥 함수Floor function 로 불리며 $x$ 보</description>
    </item>
    
    <item>
      <title>음이항 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-negative-binomial-distribution/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-negative-binomial-distribution/</guid>
      <description>공식 $X \sim \text{NB}(r, p)$ 면 $$ E(X) = {{ r (1-p) } \over { p }} \\ \text{Var}(X) = {{ r (1-p) } \over { p^{2} }} $$ 증명 전략: 음이항 분포가 기하 분포의 일반화라는 점을 이용한다. [b] 기하분포의 일반화: $Y = X_{1} + \cdots + X_{r}$ 이고 $X_{i} \overset{\text{iid}}{\sim} \text{Geo}(p)$ 면 $Y \sim \text{NB}(r,p)$ 이 때 기하 분포의 정의는 음이항 분포와 마찬가지로 그 서포트가 $\mathcal{S} = \left\{ 0 , 1 , 2, \cdots \right\}$ 와 같이 되도록 둔다. 기하 분포의 평균과 분산: $X \sim \text{Geo} (p)$ 면 $$ E(X) = {{ 1-p</description>
    </item>
    
    <item>
      <title>음이항 분포</title>
      <link>https://freshrimpsushi.github.io/posts/negative-binomial-distribution/</link>
      <pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/negative-binomial-distribution/</guid>
      <description>정의 1 $r \in \mathbb{N}$ 와 $p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{NB}(r,p)$ 를 음이항 분포Negative Binomial Distribution라고 한다. $$ p(x) = \binom{r+x-1}{x-1} p^{r}(1-p)^{x} \qquad, x = 0,1,2,\cdots $$ 기초 성질 적률 생성 함수 [1]: $$m(t) = \left[ {{ p } \over { 1 - (1-p) e^{t} }} \right]^{r} \qquad , t &amp;lt; -\log (1-P)$$ 평균과 분산 [2]: $X \sim \text{NB}(r, p)$ 면 $$ \begin{align*} E(X) =&amp;amp; {{ r (1-p) } \over { p }} \\ \text{Var}(X) =&amp;amp; {{ r (1-p) } \over { p^{2} }}\end{align*} $$ 설명 음이항 분포</description>
    </item>
    
    <item>
      <title>산술 함수의 디리클레 곱</title>
      <link>https://freshrimpsushi.github.io/posts/dirichlet-product-of-arithmetical-function/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichlet-product-of-arithmetical-function/</guid>
      <description>정의 1 두 산술 함수 $f$, $g$ 에 대해 다음을 만족시키는 산술 함수 $h$ 를 $f$, $g$ 의 디리클레 곱Dirichlet Product이라고 부른다. $$ h(n) = \sum_{d \mid n} f(d) g \left( {{ n } \over { d }} \right) $$ 디리클레 곱은 $h (n) = \left( f \ast g \right) (n) $ 혹은 $h = f \ast g$ 와 같이 나타낼 수 있다. 설명 디리클레 곱은 그 모양에서 짐작할 수 있듯 합성곱[컨볼루션]Convolution이라</description>
    </item>
    
    <item>
      <title>기하 분포의 두가지 정의가 가지는 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/two-different-definitions-of-geometric-distribution/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/two-different-definitions-of-geometric-distribution/</guid>
      <description>설명 기하 분포에 대해 공부하면서 가장 당황스럽고 헷갈리는 것이 교재, 블로그, 위키마다 설명이 다르다는 것이다. 어떤 곳에서는 평균이 $\displaystyle {{1} \over {p}} $ 인데 다른 곳은 $\displaystyle {{1-p} \over {p}}$ 로 쓰기도 한다. 이러한 차이는 기하분포를 정의하는 방법이 두가지가 있기 때문이다. 기하분포 $\text{Geo}(p)$ 의 확률질량함수는 $$ p_{1}(x) = p(1-p)^{x-1} , x= 1,2,3,\cdots $$ 혹은 $$ p_{2}(x) = p(1-p)^{x} , x= 0,1,2,\cdots $$ 으로 정의된다. 기댓값</description>
    </item>
    
    <item>
      <title>해석적 수론에서의 산술 함수</title>
      <link>https://freshrimpsushi.github.io/posts/arithmetical-function-in-analytic-number-theory/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arithmetical-function-in-analytic-number-theory/</guid>
      <description>정의 1 정의역이 자연수의 집합 $\mathbb{N}$ 이고 공역이 실수 집합 $\mathbb{R}$ 혹은 복소수 집합 $\mathbb{C}$ 인 함수를 산술 함수라 한다. 설명 해석적 정수론에서는 다양한 산술 함수의 성질과 관계에 관심을 가지며, 다음과 같은 예들이 있다: 아이덴티티 함수 $I$ 디바이저 함수 $\sigma_{\alpha}$ 놈 $N$ 디바이저 함수 $\sigma_{\alpha}$ 뫼비우스 함수 $\mu$ 오일러 토션트 함수 $\varphi$ 유닛 함수 $u$ 망골트 함수 $\Lambda$ 리우빌 함수 $\lambda$ 산술 함수의 정</description>
    </item>
    
    <item>
      <title>기하 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-geometric-distribution/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-geometric-distribution/</guid>
      <description>공식 $X \sim \text{Geo} (p)$ 면 $$ E(X) = {{ 1 } \over { p }} \\ \text{Var}(X) = {{ 1-p } \over { p^{2} }} $$ 유도 기하 분포의 평균과 분산은 생각보다 쉽게 구해지지 않는다. 본 포스트에서는 유익하면서도 재미있는 두가지 증명을 소개한다. 기하 분포의 정의$p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Geo}(p)$ 를 기하 분포라고 한다. $$ p(x) = p (1 - p)^{x-1} \qquad , x = 1 , 2, 3, \cdots $$ 첫번째 방</description>
    </item>
    
    <item>
      <title>리눅스에서 줄리아 최신 버전 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-the-latest-version-julia-in-linux/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-the-latest-version-julia-in-linux/</guid>
      <description>본 포스트에서 줄리아 최신 버전은 v1.3.1이다. 가이드 Step 1. 줄리아 다운로드 Generic Linux Binaries for x86에서 자기 CPU의 비트에 맞는 파일을 다운로드 받는다. Step 2. 압축 해제 후 이동 압축을 해제한다. 줄리아가 저장되어 있을 위치로 폴더를 옮긴다. 본인이 원하는 곳 어디라도 상관 없는데, 해당 포스트에서는 /home/[유저이름]/julia-1.3</description>
    </item>
    
    <item>
      <title>기하 분포</title>
      <link>https://freshrimpsushi.github.io/posts/geometric-distribution/</link>
      <pubDate>Sun, 16 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/geometric-distribution/</guid>
      <description>정의 1 $p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Geo}(p)$ 를 기하 분포Geometric Distribution라고 한다. $$ p(x) = p (1 - p)^{x-1} \qquad , x = 1 , 2, 3, \cdots $$ 두가지 정의가 쓰이고 있으니 수식과 정의역에 특히 주의해야한다. 기초 성질 적률 생성 함수 [1]: $$m(t) = {{ p e^{t} } \over { 1 - (1-p) e^{t} }} \qquad , t &amp;lt; -\log (1-p)$$ 평균과 분산 [2]: $X \sim \text{Geo} (p)$ 면 $$ \begin{align*}</description>
    </item>
    
    <item>
      <title>다차원 맵의 카오스</title>
      <link>https://freshrimpsushi.github.io/posts/chaos-of-multi-dimensional-map/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaos-of-multi-dimensional-map/</guid>
      <description>정의1 맵 $f : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 의 바운디드 오빗 $\left\{ \mathbb{v}_{0}, \mathbb{v}_{1}, \cdots \right\}$ 이 다음을 만족하면 이 오빗을 캐어릭Chaotic하다고 한다. (i): 어심토티컬리 피리어딕이 아니다. (ii): 모든 $i = 1,\cdots , m$ 에 대해 $h_{i} ( \mathbb{v}_{0} ) \ne 0$ (iii): $h_{1} ( \mathbb{v}_{0}) &amp;gt; 0$ 오빗이 바운디드라는 말은 모든 $n \in \mathbb{N}_{0}$ 에 대해 $\left\| \mathbb{v}_{n} \right\| &amp;lt; M$ 을 만족하는 $M \in \mathbb{R}$ 이 존재한다는 뜻이다. $h_{i}(\mathbb{v}_{0})$ 은 랴푸노프 지수를 의미한다. 설명 $1$차</description>
    </item>
    
    <item>
      <title>이항 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-binomial-distribution/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-binomial-distribution/</guid>
      <description>공식 $\displaystyle X \sim \text{Bin} (n,p)$ 면 $$ E(X)=np \\ \text{Var}(X)=npq $$ 여기서 $q : = 1-p$ 다. 유도 전략: 조합을 직접 풀어헤친다. 식이 다소 더럽긴 하지만 고등학교 과정에서 충분히 소화할 수 있다. 한번쯤은 직접 해보도록 하자. 수리통계학을 접하면 조금 더 짧고 간단한 방법으로 증명할 수 있게 된다. 평균이든 분산이든 다음과 같은 이항 분포의 확률 질량 함수에서 시작한다. 이항 분포의 정의: $n \in</description>
    </item>
    
    <item>
      <title>이항 분포</title>
      <link>https://freshrimpsushi.github.io/posts/binomial-distribution/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/binomial-distribution/</guid>
      <description>정의 1 $n \in \mathbb{N}$ 과 $p \in [0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Bin}(n,p)$ 를 이항 분포Binomial Distribution라고 한다. $$ p(x) = \binom{n}{x} p^{x} (1-p)^{n-x} \qquad , x = 0 , 1, \cdots n $$ 기초 성질 적률 생성 함수 [1]: $$m(t) = \left[ (1-p) + pe^{t} \right]^{n} \qquad , t \in \mathbb{R}$$ 평균과 분산 [2]: $X \sim \text{Bin}(n,p)$ 면 $$ \begin{align*} E(X) =&amp;amp; np \\ \text{Var}(X) =&amp;amp; np(1-p) \end{align*} $$ 정리 이항분포의 극한분포로써 푸아송분포 유도 [a]: $X_{n} \sim B(</description>
    </item>
    
    <item>
      <title>1만번째까지의 소수 목록</title>
      <link>https://freshrimpsushi.github.io/posts/list-of-prime-numbers/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/list-of-prime-numbers/</guid>
      <description>소수 1만번째까지의 소수 목록이다. 다운로드 2 3 5 7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97 101 103 107 109 113 127 131 137 139 149 151 157 163 167 173 179 181 191 193 197 199 211 223 227 229 233 239 241 251 257 263 269 271 277 281 283 293 307 311 313 317 331 337 347 349 353 359 367 373 379 383 389 397 401 409 419 421 431 433 439 443 449 457 461 463 467 479 487 491 499 503 509 521 523 541 547 557 563 569 571 577 587 593 599 601 607 613 617 619 631 641 643 647 653 659 661 673 677 683 691 701 709 719 727 733</description>
    </item>
    
    <item>
      <title>확률 변수들의 선형 결합</title>
      <link>https://freshrimpsushi.github.io/posts/linear-combinations-of-random-variable/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-combinations-of-random-variable/</guid>
      <description>정의 1 확률 변수 $X_{1} , \cdots , X_{n}$ 가 어떤 $(a_{1}, \cdots , a_{n}) \in \mathbb{R}^{n}$ 에 대해 $\displaystyle T := \sum_{i=1}^{n} a_{i} X_{i}$ 를 선형 결합Linear Combinations이라고 한다. 설명 특히 $X_{1} , \cdots , X_{n}$ 이 iid면 사이즈 $n$ 의 **랜덤 샘플Random Sample**이라도 부른다. 통계학의 맥락이라면 모든 관측값에 같은 가중치가 곱해진 $a_{1} = \cdots = a_{n} = {{ 1 } \over { n } }$ 을 생각할 것이다</description>
    </item>
    
    <item>
      <title>줄리아에서 병렬처리 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-julia/</link>
      <pubDate>Sat, 08 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-julia/</guid>
      <description>코드 원래 생새우초밥집에는 상세한 설명을 포함하는데, 줄리아가 병렬처리를 얼마나 편하게 할 수 있는지 강조하기 위해 굳이 설명을 생략하려 한다. using Base.Threads for i in 1:10 println(i^2) end 위의 반복문을 병렬처리하고 싶다면 단지 포문 앞에 @threads만 붙이면 된다. @threads for i in 1:10 println(i^2) end 그래도 당부의 말을 한마디만 적는다면, 병렬처리라고 해서 모든 게 빨라지지는 않는다는</description>
    </item>
    
    <item>
      <title>다차원 맵의 랴푸노프 수와 그 수치적 계산법</title>
      <link>https://freshrimpsushi.github.io/posts/lyapunov-number-of-multi-dimensional-map/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lyapunov-number-of-multi-dimensional-map/</guid>
      <description>정의 1 스무스 맵 $\mathbb{f} : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 과 초기값 $\mathbb{v}_{0} \in \mathbb{R}^{m}$ 에 대해 $J_{n} := D \mathbb{f}^{n} ( \mathbb{v}_{0}) \in \mathbb{R}^{m \times m}$ 이라고 하자. $k = 1 , \cdots , m$ 에 대해 $m$차원 단위구 $N := \left\{ \mathbb{x} \in \mathbb{R}^{m} : \left\| \mathbb{x} \right\|_{2} = 1 \right\}$ 의 일립소이드 $J_{n} N$ 의 축의 길이 중 $k$ 번째로 긴 축의 길이를 $r_{k}^{(n)}$ 이라고 두자. 이제 $\mathbb{v}_{0}$ 의 $k$ 번째 랴푸노프 수 $L_{k}$ 를 다음과 같이 정의한다. $$ L_{k} := \lim_{n\to\infty} \left( r_{k}^{(n)} \right)^{1/n} $$ $\mathbb{v}_{0}$ 의 $k$ 번째 랴푸노프 지수는 $h_{k} := \ln L_{k}$ 와 같</description>
    </item>
    
    <item>
      <title>정규분포를 따르는 두 확률 변수가 독립인 것과 공분산이 0인 것은 동치다</title>
      <link>https://freshrimpsushi.github.io/posts/two-normal-distributions-are-independent-iff-their-covariance-is-equal-to-zero/</link>
      <pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/two-normal-distributions-are-independent-iff-their-covariance-is-equal-to-zero/</guid>
      <description>정리 $$ X_{1} \sim N ( \mu_{1} , \sigma_{1} ) \\ X_{2} \sim N ( \mu_{2} , \sigma_{2} ) $$ 면 $$ X_{1} \perp X_{2} \iff \text{cov} (X_{1} , X_{2} ) = 0 $$ 설명 일반적으로 상관관계가 없다고 독립인 것은 아니다. 하지만 분포들이 정규분포를 따른다는 가정이 있다면 공분산이 $0$ 인 것이 독립임을 보장해준다. 증명 $( \Rightarrow )$ $$ M_{X_{1}} (t_{1} ) = \exp \left[ \mu_{1} t_{1} + {{1} \over {2}} \sigma_{1} t_{1}^{2} \right] M_{X_{2}} (t_{2} ) = \exp \left[ \mu_{2} t_{2} + {{1} \over {2}} \sigma_{2} t_{2}^{2} \right] $$ $\sigma_{12} : = \text{cov} (X_{1} , X_{2} )$ 그리고 $\sigma_{21} : =</description>
    </item>
    
    <item>
      <title>타원의 일반화: 일립소이드</title>
      <link>https://freshrimpsushi.github.io/posts/ellipsoid-of-linear-transform/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ellipsoid-of-linear-transform/</guid>
      <description>정의 선형 변환 $A \in \mathbb{R}^{m \times m}$ 에 대해 $m$차원 단위구 $N := \left\{ \mathbb{x} \in \mathbb{R}^{m} : \left\| \mathbb{x} \right\|_{2} = 1 \right\}$ 의 이미지 $AN$ 을 일립소이드라 한다. $A$ 의 아이겐 밸류 $\sigma_{1}^{2} &amp;gt; \cdots \ge \sigma_{m}^{2} \ge 0$ 와 그에 따른 단위 아이겐 벡터 $u_{1} , \cdots , u_{m}$ 에 대해 $\sigma_{i} u_{i}$ 를 일립소이드의 축Axis라 한다. 설명 $m$차원 단위구는 중심이 $\mathbb{0} \in \mathbb{R}^{m}$ 이고 반지름이 $1$ 인 점들을 모아놓은 집합으로, $m=2$ 일 때 우리가 흔히 알고 있</description>
    </item>
    
    <item>
      <title>번스타인 분포: 짝으로 독립이라고 상호 독립은 아니다</title>
      <link>https://freshrimpsushi.github.io/posts/bernstein-distribution/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bernstein-distribution/</guid>
      <description>정의 $(x,y,z) \in \left\{ (1,0,0), (0,1,0), (0,0,1), (1,1,1) \right\}$ 에 대해 다음과 같은 확률질량함수를 가지는 분포를 번스타인 분포Bernstein Distribution라고 한다. $$ p(x,y,z) = {{1} \over {4} } $$ 설명 번스타인 분포는 분포의 조건을 모두 만족시키고는 있지만 자연계에 실재하는 분포라고 보기는 어렵다. &amp;lsquo;짝으로 독립이면 상호 독립이다&amp;rsquo;라는 명제의 반례</description>
    </item>
    
    <item>
      <title>확률 변수들의 상호 독립과 iid</title>
      <link>https://freshrimpsushi.github.io/posts/mutual-independence-and-iid-independent-and-identically-distributed/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mutual-independence-and-iid-independent-and-identically-distributed/</guid>
      <description>정의 1 확률 변수 $X_{1} , \cdots , X_{n}$ 가 다음을 만족하면 $X_{1} , \cdots , X_{n}$ 이 짝으로 독립Pairwise Independent이라 한다. $$ i \ne j \implies X_{i} \perp X_{j} $$ 연속 확률 변수 $X_{1} , \cdots , X_{n}$ 의 조인트 확률 밀도 함수 $f$ 가 각각의 확률 밀도 함수 $f_{1} , \cdots , f_{n}$ 에 대해 다음을 만족하면 $X_{1} , \cdots , X_{n}$ 가 상호 독립이라 한다. $$ f(x_{1} , \cdots , x_{n} ) \equiv f_{1} (x_{1}) \cdots f_{n} (x_{n}) $$ 이산 확률 변수 $X_{1} , \cdots ,</description>
    </item>
    
    <item>
      <title>확률적 경사 하강법</title>
      <link>https://freshrimpsushi.github.io/posts/stochastic-gradient-descent-method/</link>
      <pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stochastic-gradient-descent-method/</guid>
      <description>정의 목적 함수 $Q$ 와 러닝 레이트 $\alpha &amp;gt; 0$, 배치사이즈 $m$ 과 $i$ 번째 데이터에 대해 $$ \omega_{n+1} := \omega_{n} - \alpha {{ 1 } \over { n }} \sum_{i=1}^{m} \nabla Q_{i} ( \omega_{n} ) $$ 를 확률적 경사 하강법이라 한다. 설명 머신러닝 확률적 경사 하강법은 데이터를 다루는만큼 필연적으로 머신러닝과 깊은 관계를 가지고 있을 수밖에 없다. 몇몇 단어가 익숙하지 않더라도 일단 예시를 통해 이해해보는 게 좋다: $x_{1}$ 와 $x_{2}$ 가 주</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 변수의 독립</title>
      <link>https://freshrimpsushi.github.io/posts/independence-of-random-variable/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independence-of-random-variable/</guid>
      <description>정의 1 두 확률 변수 $X_{1}, X_{2}$ 의 조인트 확률 밀도 함수 $f$ 혹은 확률 질량 함수 $p$ 에 대해 $X_{1}, X_{2}$ 의 확률 밀도 함수들 $f_{1}, f_{2}$ 혹은 확률 질량 함수 $p_{1}, p_{2}$ 가 다음을 만족하면 $X_{1}, X_{2}$ 가 독립이라 하고, $X_{1} \perp X_{2}$ 와 같이 나타낸다. $$ f(x_{1} , x_{2} ) \equiv f_{1}(x_{1})f_{2}(x_{2}) \\ p(x_{1} , x_{2} ) \equiv p_{1}(x_{1})p_{2}(x_{2}) $$ 정리 아래의 정리는 이산 확률 변수에 대해서도 같지만, 편의상 연속 확률 변수인 경우만 언급한다. 다음은 모두 동치다. [1]:</description>
    </item>
    
    <item>
      <title>수학에서의 최적화 기법</title>
      <link>https://freshrimpsushi.github.io/posts/optimization-method/</link>
      <pubDate>Sat, 25 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/optimization-method/</guid>
      <description>정의 함수 $f : \mathbb{R}^{n} \to \mathbb{R}$ 의 함수값이 최소가 되도록 하는 $x^{ \ast } = \argmin_{x} f(x)$ 를 구하는 문제를 최적화 문제Optimization Problem라 하고, 그 문제를 푸는 알고리즘을 최적화 기법이라 부른다. 최적화 문제에서 주어진 함수 $f$ 를 특히 목적 함수Objective Function라 한다. 정의역의 모든 $x$ 에 대해 $f(x^{ \ast }) \le f(x)$ 를 만족하는 $x^{ \ast }$ 를</description>
    </item>
    
    <item>
      <title>수리통계학에서의 조건부 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-probability/</link>
      <pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-probability/</guid>
      <description>정의 이산 확률 변수 $X_{1}, X_{2}, \cdots , X_{n}$ 에 대해 다음의 $p_{2, \cdots , n \mid 1}$ 를 $X_{1} = x_{1}$ 이 주어졌을 때의 $ X_{2}, \cdots , X_{n}$ 의 조인트 조건부 확률 질량 함수라고 한다. $$ p_{2, \cdots , n \mid 1} ( x_{2} , \cdots ,x_{n} \mid X_{1} = x_{1} ) = {{ p_{1, \cdots , n}(x_{1} , x_{2} , \cdots , x_{n}) } \over { p_{1}( X_{1} = x_{1} ) }} $$ 연속 확률 변수 $X_{1}, X_{2}, \cdots , X_{n}$ 에 대해 다음의 $f_{2, \cdots , n \mid 1}$ 를 $X_{1} = x_{1}$ 이 주어졌을 때의 $ X_{2}, \cdots , X_{n}$ 의 조인트 조건부 확률 밀도 함수</description>
    </item>
    
    <item>
      <title>메타 프로그래밍</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-meta-programming/</link>
      <pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-meta-programming/</guid>
      <description>메타프로그래밍이란? 간단히 말해 프로그램이 코드를 수정하도록 하는 프로그래밍이라고 볼 수 있다. 정확하게 어떤 기법이라기보다는 그러한 개념 전반을 메타 프로그래밍이라고 부르는데, 어떤 프로그램이 다른 언어로 작성된 코드를 열어 &amp;lsquo;문자열&amp;rsquo;을 고치듯이 코드를 수정하거나 같은 언어끼리, 심지어는 스스로가 수정해도 모</description>
    </item>
    
    <item>
      <title>scp로 서버에 파일 업로드하고 서버에서 다운로드 받는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-scp-command/</link>
      <pubDate>Sun, 19 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-scp-command/</guid>
      <description>명령어 scp는 아마도 server copy의 줄임말로, ssh 서버를 사용할 때 업로드와 다운로드를 하는 커맨드다. 띄어쓰기와 @, :의 위치에 주의하도록 하자. 서버의 계정을 serverACC, 서버의 주소를 serverADD, 서버 내에서 파일을 업로드 하거나 다운로드 받을 디렉터리를 serverDIR, 내가 전송하고자 하는 파일 혹은 디렉터리를 Object, 다운로드 받을 때 내가 다운로드 받고자 하는 디렉터리를 loca</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transform-of-random-variable/</link>
      <pubDate>Fri, 17 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transform-of-random-variable/</guid>
      <description>공식 다변량 확률 변수 $X = ( X_{1} , \cdots , X_{n} )$ 의 조인트 확률밀도함수 $f$ 가 $f(x_{1} , \cdots , x_{n})$ 와 같이 주어져있다고 하고 다음과 같은 변환을 생각해보자. $$ y_{1} = u_{1} (x_{1} , \cdots , x_{n}) \\ \vdots \\ y_{n} = u_{n} (x_{1} , \cdots , x_{n}) $$ 이러한 변환 $u_{1} , \cdots , u_{n}$ 는 단사가 아닐 수 있다. 따라서 $X$ 의 서포트 $S_{X}$ 는 $k$ 개의 파티션 $A_{1} , \cdots , A_{i} , \cdots , A_{k}$ 으로 나누어지고, 다음과 같은 역변환 $w_{ji} \mid_{i=1,\cdots,k \\ j=1,\cdots,n}$ 들을 생각</description>
    </item>
    
    <item>
      <title>줄리아의 강력한 편의 기능, 매크로</title>
      <link>https://freshrimpsushi.github.io/posts/macro-in-julia/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/macro-in-julia/</guid>
      <description>개요 매크로는 줄리아로 코딩할 때 편의를 주는 기능들로써, 스코프 앞에 두어 실행한다. 예를 들어 자신의 프로그램이 얼마나 많은 시간을 소비하는지 알고 싶다면 다음과 같이 작성하면 된다. @time for t in 1:10 foo() bar() end 예시 많은 종류가 있지만 다음의 매크로들이 특히 널리 쓰인다: @time : 뒤에 이어지는 함수나 스코프의 실행 시간을 측정해준다. 어떤 상황에서 어떻게 최적</description>
    </item>
    
    <item>
      <title>R에서 폴더 내부 파일 목록 가져오는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-list-of-folder-in-r/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-list-of-folder-in-r/</guid>
      <description>코드 setwd(&amp;#34;F:\\dsr\\project&amp;#34;) getwd() list.files(getwd()) list.files(getwd(),pattern=&amp;#34;*.csv&amp;#34;) list.files()는 여러개의 파일로 나눠진 데이터를 취합하거나 메타 프로그래밍 등에 유용하게 쓰이는 함수다: path: 첫번째 인자로써 디렉터리를 지정해주면 해당 폴더에 있는 파일들의 목록을 반환한다. pattern: 두번째 인자로써 정규표현식으로 규칙을 받아 조건에 만족하는 파일들의 목록만을 반환한다. 예제에서는 와일드카드 를 사용해 p</description>
    </item>
    
    <item>
      <title>줄리아에서 파이프 오퍼레이터 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/pipe-operator-in-julia/</link>
      <pubDate>Sat, 11 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pipe-operator-in-julia/</guid>
      <description>개요 줄리아는 데이터를 다루는데에서 강점을 내세우는만큼 파이프라인 연산자를 지원한다. 코드 julia&amp;gt; (1:5) .|&amp;gt; (x -&amp;gt; sqrt(x+2)) .|&amp;gt; sin |&amp;gt; minimum 0.4757718381527513 julia&amp;gt; minimum(sin.((x -&amp;gt; sqrt(x+2)).(1:5))) 0.4757718381527513 위의 예제 코드는 배열 $[1,2,3,4,5]$ 를 $\sqrt{x + 2}$ 에 넣어서 얻은 결과를 $\sin$ 에 넣은 후 그 중 작은 값을 얻는 코드로,위와 아래 코드는 완전히 같은 결과를 낸다. 파이프라인이 복잡한 코드를 작성하는 중에 얼마나 유용한지는 굳이 설명할 필요가 없</description>
    </item>
    
    <item>
      <title>수리통계학에서의 다변량 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/multivariate-distribution/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multivariate-distribution/</guid>
      <description>정의 1 표본 공간 $\Omega$ 에서 정의된 $n$ 개의 확률 변수 $X_{i}$ 에 대해 $X = (X_{1} , \cdots , X_{n})$ 를 $n$차원 랜덤 벡터Random Vector라고 한다. $X$ 의 치역 $X(\Omega)$ 를 공간이라고도 부른다. 다음을 만족하는 함수 $F_{X} : \mathbb{R}^{n} \to [0,1]$ 을 $X$ 의 조인트Joint 누적 분포 함수라고 한다. $$ F_{X}\left( x_{1}, \cdots , x_{n} \right) := P \left[ X_{1} \le x_{1} , \cdots , X_{n} \le x_{n} \right] $$ 어떤 $h_{1} , \cdots , h_{n} &amp;gt;0$ 들에 대해 다음을 만족하는</description>
    </item>
    
    <item>
      <title>줄리아에서의 람다식</title>
      <link>https://freshrimpsushi.github.io/posts/lambda-expression-in-julia/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lambda-expression-in-julia/</guid>
      <description>개요 줄리아에서 람다식은 다음과 같이 정의된다. (x -&amp;gt; 3x^2 - 2x + 3)(1) 이는 익명함수 $\lambda : \mathbb{Z} \to \mathbb{Z}$ 를 다음과 같이 정의하고, 거기에 $1$ 을 대입해서 $4$ 라는 함수값을 얻은 것에 해당한다. $$ \lambda : x \mapsto ( 3 x^{2} - 2 x + 3 ) \\ \lambda(1) = 4 $$ 사실 람다식 자체는 줄리아의 특징이 아니라 매트랩과 파이썬을 비롯해 함수형 언어에 영향을 받았다면 거의 당연하게 지원하고, 줄리아</description>
    </item>
    
    <item>
      <title>돈스커의 정리</title>
      <link>https://freshrimpsushi.github.io/posts/donskers-theorem-invariance-priciple-functional-clt/</link>
      <pubDate>Sun, 05 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/donskers-theorem-invariance-priciple-functional-clt/</guid>
      <description>정리 $\left\{ \xi_i \right\}_{i \in \mathbb{N}}$ 이 $(0,1)$ 에서 정의된 확률 과정이라고 하자. 함수 공간 $C[0,1]$ 에서 확률 함수 $X_{n}$ 가 다음과 같이 정의되어 있다고 하자. $$ X_{n}:= {{ 1 } \over { \sqrt{n} }} \sum_{i=1}^{\lfloor nt \rfloor} \xi_{i} + \left( nt - \lfloor nt \rfloor \right) {{ 1 } \over { \sqrt{n} }} \xi_{\lfloor nt \rfloor + 1} $$ $X_{n}$ 은 $n \to \infty$ 일 때 위너 프로세스 $W$ 로 분포 수렴한다. $C[0,1]$ 은 정의역이 $[0,1]$ 이고 공역이 $\mathbb{R}$ 인 연속함수들의 공간이다. $\lfloor \cdot \rfloor$ 은 바닥 함수Floor Func</description>
    </item>
    
    <item>
      <title>옌센 부등식의 기댓값 폼 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-expectation-form-of-jensens-inequality/</link>
      <pubDate>Sat, 04 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-expectation-form-of-jensens-inequality/</guid>
      <description>정리 1 개구간 $I$ 에서 함수 $\phi$ 가 컨벡스하고 두 번 미분가능, 확률변수 $X$ 의 기댓값 $\mu$ 가 존재하며 $X \subset I $ 면 $$ \phi [ E(X) ] \le E [ \phi(X)] $$ 다른 형태 옌센 부등식의 유한 폼 옌센 부등식의 적분 폼 조건부 옌센 부등식 적분 폼과는 상당히 유사한 형태를 가지고 있다. 잘 생각해보면 유한 폼 역시 항이 무한하지는 않지만 가중평균의 부등식이라는 센스에서 기댓값이라고 볼 수 있</description>
    </item>
    
    <item>
      <title>줄리아에서 이미지 불러오고 행렬로 변환 저장하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-and-save-an-image-convert-to-matrix-in-julia/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-and-save-an-image-convert-to-matrix-in-julia/</guid>
      <description>코드 using Images cd(&amp;#34;C:/Users/rmsms/OneDrive/examples&amp;#34;) pwd() example = load(&amp;#34;example.jpg&amp;#34;) typeof(example) size(example) gray1 = Gray.(example) typeof(gray1) size(gray1) M = convert(Array{Float64},gray1) typeof(M) size(M) colorview(Gray, M.^(1/2)) save(&amp;#34;rgb.png&amp;#34;, colorview(RGB, example)) save(&amp;#34;gray1.png&amp;#34;, colorview(Gray, gray1)) save(&amp;#34;gray2.png&amp;#34;, colorview(Gray, transpose(gray1))) save(&amp;#34;gray3.png&amp;#34;, colorview(Gray, M.^(1/2))) 예제 코드를 위에서부터 간략하게 이해해보자: cd() : Change Directory, 작업 경로를 원하는 곳으로 바꿔준다. pwd() : Print Working Directory, 작업 경로를 출력해준다. 예제를 그대로 따라해보고싶다면 위의 파일을 작업 경로에 다운로드 받고 파일 이름을 example.jpg로 수정하자. load() : 작업 경로 내</description>
    </item>
    
    <item>
      <title>체비셰프 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-chebyshevs-inequality/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-chebyshevs-inequality/</guid>
      <description>정리 1 확률변수 $X$ 의 분산 $\sigma^2 &amp;lt; \infty$ 가 존재하면 $\mu := E(X)$ 와 어떤 양수 $k&amp;gt;0$ 에 대해 $$ P(|X-\mu| \ge k\sigma) \le {1 \over k^2} $$ 설명 비교적 형태가 간단하고 식의 조작이 쉬운데다 결과도 한 눈에 들어오기 때문에 보조정리로써 많이 쓰인다. 다만 마코프 부등식과 비교하자면 분산이 존재해야한다는 조건이 하나 더 있다. 조건에서 $2$차 적률이 존재해야하는 것을 보고 너무 쉽고 당연한 조건으</description>
    </item>
    
    <item>
      <title>윈도우에서 ssh 서버 구축하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-construct-ssh-server-in-windows/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-construct-ssh-server-in-windows/</guid>
      <description>개요 윈도우는 10 버전에 들어 파워쉘PowerShell을 비롯하여 리눅스 특유의 편의 기능을 많이 제공하게 되었다. ssh 서버의 경우 GUI를 통해 아주 간단하게 설치할 수 있다. 가이드 **Step 1. 앱 및 기능 Win+S 를 눌러 프로그램 추가/제거 나 앱 및 기능 을 찾아 선택적 기능 을 클릭한다. Step 2. OpenSSH 서버 설치 기능 추가를 클릭하고 OpenSSH 서버 를 설치한다. Step 3. PowerShell Power</description>
    </item>
    
    <item>
      <title>마코프 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-markovs-inequality/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-markovs-inequality/</guid>
      <description>정리 1 확률변수 $X$ 에 대해 함수 $u(X) \ge 0$ 를 정의하자. $E \left( u(X) \right)$ 가 존재하면 $c &amp;gt; 0$ 에 대해 $$ P(u(X) \ge c) \le {E \left( u(X) \right) \over c} $$ 설명 수많은 증명에 사용되는 보조정리로써 이를 좀 더 편리하게 만든 체비셰프 부등식이 있다. 조건에서 $1$차 적률이 존재해야하는 것을 보고 너무 쉽고 당연한 조건으로 여길지 모르겠다. 뭐 어느정도는 맞는 말이지만, 학부생 정도 됐다면 그</description>
    </item>
    
    <item>
      <title>파이썬에서 is와 ==의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/how-different-is-and-in-python/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-different-is-and-in-python/</guid>
      <description>코드 if type(150421) is int : print(&amp;#34;!&amp;#34;) else : print(&amp;#34;?&amp;#34;) x = [1,2] y = [1,2] x == y x is y 설명 깃허브에서 파이썬 코드를 보다보면 간혹 is라는 게 보이기도 한다. 코드가 문장처럼 편안하게 읽히는 것은 둘째치더라도 ==와는 분명한 차이가 있어 적재적소에 사용하면 좋다: ==는 단순하게 값을 비교한다. 우리에게 실제로 보이는 모습을 비교하기 때문에 직관적이다. is는 포인터가 가리키</description>
    </item>
    
    <item>
      <title>n차 적률이 존재하면 차수가 n보다 작은 적률도 존재한다</title>
      <link>https://freshrimpsushi.github.io/posts/if-nth-moment-exists-then-moments-with-less-degree-are-exist/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-nth-moment-exists-then-moments-with-less-degree-are-exist/</guid>
      <description>정리 확률변수 $X$와 자연수 $n$ 에 대해 $E( X^n )$ 이 존재하면 $E( X^m ), m=1,2,3,\cdots, n$ 도 존재한다. 설명 어떤 차수의 적률이든 존재하기만 한다면 그보다 작은 차수의 적률은 항상 존재하지만, 당연히 역은 성립하지 않는다. 물론 실제로 문제를 접해보면 높은 차수의 적률이 먼저 주어지는 경우는 거의 없으나, 어떤 정리의 조건을 나열할 때 지면을 상당히 절약할 수 있게 해주는 정</description>
    </item>
    
    <item>
      <title>타이트 확률 과정</title>
      <link>https://freshrimpsushi.github.io/posts/tight-probability-process/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tight-probability-process/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 에서 확률 과정 $\left\{ X_n \right\}_{n \in \mathbb{N}}$ 이 정의되어 있다고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$\displaystyle \inf_{n \in \mathbb{N}} P\left( X_{n} \in K \right) &amp;gt; 1 - \varepsilon$$ 를 만족시키는 컴팩트 셋 $K \subset \Omega$ 가 존재하면 $\left\{ X_{n} \right\}$ 이 타이트Tight하다고 한다. 설명 수리통계학에서는 확률 유계에 해당하는 개념이다. 타이트는 분포 수렴과 관련해서 다음과 같이 중요한 성질들을 여럿 가진다. 기초 성질</description>
    </item>
    
    <item>
      <title>적률생성함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/moment-generating-function/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-generating-function/</guid>
      <description>정의 1 확률변수 $X$ 와 어떤 양수 $h&amp;gt;0$ 대해 $E(e^{tX})$ 이 $-h&amp;lt; t &amp;lt; h$ 에서 존재하면 $M(t) = E( e^{tX} )$ 를 $X$ 의 적률생성함수Moment Generating Function라고 정의한다. 설명 적률생성함수는 흔히 mgf라는 약어로 많이 쓰인다. 수리통계학에서는 비교적 초반에 배우는데, 생소한 정의와 맥락 없는 등장 때문에 수리통계학을 싫어지게 만드는 주범 중 하나다. 적률생성함수를</description>
    </item>
    
    <item>
      <title>줄리아에서 집합 자료형과 연산자</title>
      <link>https://freshrimpsushi.github.io/posts/set-type-and-operator-in-julia/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/set-type-and-operator-in-julia/</guid>
      <description>개요 줄리아에서는 파이썬과 마찬가지로 집합 자료형을 지원한다. 원래 집합 자료형이 그렇듯 쓰는 사람은 요긴하게 쓰고 안 쓰는 사람은 일절 사용하지 않는데, 줄리아는 언어 설계 자체가 수학과 가까운만큼 집합의 개념과 연산이 잘 구현되어 있어 반드시 알아두는 게 좋다. 기존의 언어, 특히 파이썬과 가장 다른 점은 유니코드 기호들도 코드의 일부로 사용할 수 있다</description>
    </item>
    
    <item>
      <title>수리통계학에서의 첨도</title>
      <link>https://freshrimpsushi.github.io/posts/kurtosis/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kurtosis/</guid>
      <description>첨도 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{2}$ 를 $X$ 의 첨도kurtosis라고 한다. $$ \gamma_{2} := {{ E \left( X - \mu \right)^4 } \over { \sigma^4 }} $$ 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본첨도 $g_{2}$ 는 다음과 같이 구해진다. $$ g_{2} := \sum_{i=1}^{n} = {{ \left( X - \overline{X} \right)^4 } \over { n \widehat{\sigma}^4 }} - 3 $$ 설명 첨도는 4차 적률로 구해지며, 확률변수의 분포함수가 얼마</description>
    </item>
    
    <item>
      <title>파이썬에서 두 변수값 서로 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-swap-two-variables-in-python/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-swap-two-variables-in-python/</guid>
      <description>코드 변수끼리의 스왑은 흔히 아는 것처럼 임시 변수를 만들어서 옮기는 방식으로 쉽게 구현이 가능하지만, 여러가지 프로그래밍 언어를 다루는 입장에서 포인터를 주고받으면서 변수를 바인딩하는 파이썬의 특성상 이러한 방법이 잘 되는지 확신하기도 어렵고 일일이 변수를 스왑하는 함수를 작성하는 것 귀찮은 일이다. 다음과 같이 파이썬 문법 그 자체로 쉽게 해결해</description>
    </item>
    
    <item>
      <title>수리통계학에서의 왜도</title>
      <link>https://freshrimpsushi.github.io/posts/skewness/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/skewness/</guid>
      <description>정의 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{1}$ 를 $X$ 의 왜도Skewness라고 한다. $$ \gamma_{1} := {{ E \left( X - \mu \right)^3 } \over { \sigma^3 }} $$ 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본왜도 $g_{1}$ 은 다음과 같이 구해진다. $$ g_{1} := \sum_{i=1}^{n} {{ \left( X - \overline{X} \right)^3 } \over { n \widehat{\sigma}^3 }} $$ 설명 왜도는 3차 적률로 구해지며, 확률변수의 분포함수가 어떻게 치우</description>
    </item>
    
    <item>
      <title>공분산의 여러가지 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-covariance/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-covariance/</guid>
      <description>정의와 성질 평균이 각각 $\mu_{X}$, $\mu_{Y}$ 인 확률 변수 $X$, $Y$ 에 대해 $\text{Cov} (X ,Y) : = E \left[ ( X - \mu_{X} ) ( Y - \mu_{Y} ) \right]$ 을 $X$ 와 $Y$ 의 공분산Covariance이라고 정의한다. 공분산은 아래의 성질들을 가진다. [1]: $\text{Var} (X) = \text{Cov} (X,X)$ [2]: $\text{Cov} (X,Y) = \text{Cov} (Y, X)$ [3]: $\text{Var} (X + Y) = \text{Var} (X) + \text{Var} (Y) + 2 \text{Cov} (X,Y) $ [4]: $\text{Cov} (X + Y , Z ) = \text{Cov}(X,Z) + \text{Cov}(Y,Z) $ [5]: $\text{Cov} (aX + b , cY + d ) = ac \text{Cov}(X,Y) $ 설명 공분산은 두 변수의 선형상</description>
    </item>
    
    <item>
      <title>줄리아에서 배열의 슬라이싱과 인덱싱</title>
      <link>https://freshrimpsushi.github.io/posts/slicing-and-indexing-in-julia/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/slicing-and-indexing-in-julia/</guid>
      <description>코드 줄리아는 R, 파이썬, 매트랩의 장점이 모두 섞여있는 언어다. 배열은 프로그래밍의 근간이 되는만큼 그 활용에서 여러 언어들의 흔적을 찾아볼 수 있다. 행렬 julia&amp;gt; M = [1. 2. ; 3. 4.] 2×2 Array{Float64,2}: 1.0 2.0 3.0 4.0 julia&amp;gt; size(M) (2, 2) julia&amp;gt; length(M) 4 행렬의 경우 매트랩의 문법과 거의 똑같이 정의하고 거의 똑같이 사용할 수 있다. size() 함수는 매트랩과 똑같이 쓰이고, 파이썬에서 numpy 패키지의 프로</description>
    </item>
    
    <item>
      <title>피어슨 상관계수</title>
      <link>https://freshrimpsushi.github.io/posts/pearson-correlation-coefficient/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pearson-correlation-coefficient/</guid>
      <description>정의 1 다음과 같이 정의된 $\rho = \rho(X,Y)$ 를 피어스 상관계수라고 한다. $$ \rho = { {\text{Cov} (X,Y)} \over {\sigma_X \sigma_Y} } $$ 설명 (피어슨) 상관 계수(Pearson) Correlation Coefficient는 두 변수가 서로 (선형) 상관 관계 를 가지고 있는지를 확인하는 척도가 된다. $1$ 이나 $–1$ 에 가까우면 상관관계가 있다고 보고 $0$ 이면 없다고 본다. 주의할 것은 상관관계와 독립이 같은 개</description>
    </item>
    
    <item>
      <title>평균과 분산의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-mean-and-variance/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-mean-and-variance/</guid>
      <description>정리 평균 $E ( X ) = \mu_{X}$ 과 분산 $\text{Var} (X) = E [ ( X - \mu_{X} )^2 ]$ 은 아래의 성질들을 가진다. [1]: $E(X + Y) = E(X) + E(Y)$ [2]: $E(aX + b) = a E(X) + b$ [3]: $\text{Var} (X) \ge 0$ [4]: $\text{Var} ( X ) = E(X^2) - \mu_{X}^2$ [5]: $\text{Var} (aX + b) = a^2 \text{Var} (X)$ 설명 평균과 분산에 관한 것이니만큼 아주 중요한 성질들이다. 특히 [1]과 [2]는 이른바 선형성Linearity이라 불리우는 성질로써, 수식을 다룰 때 무척 편리하게</description>
    </item>
    
    <item>
      <title>프리컴팩트 확률 과정</title>
      <link>https://freshrimpsushi.github.io/posts/precompact-stochastic-process/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/precompact-stochastic-process/</guid>
      <description>정리 가측 공간 $(S, \mathcal{S})$ 에서 $(S&amp;rsquo;, \mathcal{S}&amp;rsquo;)$ 로 가는 연속함수들을 모아놓은 함수공간을 $\mathscr{H}:= C \left( S,S&amp;rsquo; \right)$와 같이 두고 $\left\{ h^{-1}(A&amp;rsquo;): h \in \mathscr{H} , A&amp;rsquo; \in \mathcal{S}&amp;rsquo; \right\}$ 가 $(S , \mathcal{S})$ 의 세퍼레이팅 클래스라고 하자. $X$ 는 $S$ 에서 정의된 확률 원소, $\left\{ X_n \right\}_{n \in \mathbb{N}}$ 은 $S$ 에서 정의된 확률 과정이다. 만약 (i) $\left\{ X_{n} \right\}$ 은 프리 컴팩트다. (ii) 모든 $h \in \mathscr{H}$ 에 대해 $h \left( X_{n} \right) \overset{D}{\to} h(X)$ 면, $X_{n} \overset{D}{\to} X$ 이다. 설명 연속 사상</description>
    </item>
    
    <item>
      <title>대표값의 수리적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mathematical-property-of-representative-value/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mathematical-property-of-representative-value/</guid>
      <description>정리 데이터 $X = \left\{ x_{1} , \cdots , x_{n} \right\}$ 가 주어져 있다고 하자. [0]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{0}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{mode}(X) $$ [1]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{1}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{median}(X) $$ [2]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{2}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{mean}(X) $$ 설명 선형대수의 용어로 어렵게 말해보자면 다음과 같다: [0]: $l^{0}$-놈을 최소화하는 것은 최빈값이다.</description>
    </item>
    
    <item>
      <title>그리디 알고리즘</title>
      <link>https://freshrimpsushi.github.io/posts/greedy-algorithm/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/greedy-algorithm/</guid>
      <description>정의 그리디 알고리즘 이란 어떤 선택을 할 때 그 순간만을 고려해서 가장 좋은 경우를 고르는 방법이다. 설명 그리드 알고리즘은 탐욕Greed이라는 이름대로 길게 보지 않고 그 순간만을 생각한다. 좋게 말하면 항상 최선을 다하는 것이지만, 크게 보았을 때 이는 현명하지 못할 수도 있다. 다음의 예시를 보자: 왼쪽 0에서 시작해 오른쪽 1에 도착하는 경로를 찾는</description>
    </item>
    
    <item>
      <title>수리통계학에서의 기대값, 평균, 분산, 적률의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-mean-variance-moment/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-mean-variance-moment/</guid>
      <description>정의: 기대값, 평균, 분산 확률 변수 $X$ 가 주어져 있다고 하자. 연속 확률 변수 $X$ 의 확률 밀도 함수 $f(x)$ 가 $\displaystyle \int_{-\infty}^{\infty} |x| f(x) dx &amp;lt; \infty$ 를 만족하면 다음과 같이 정의된 $E(X)$ 를 $X$ 의 기대값Expectation이라고 한다. $$ E(X) := \int_{-\infty}^{\infty} x f(x) dx $$ 이산 확률 변수 $X$ 의 확률 질량 함수 $p(x)$ 가 $\displaystyle \sum_{x} |x| p(x) &amp;lt; \infty$ 를 만족하면 다음과 같이 정의된 $E(X)$ 를 $X$ 의 기대값Expectation이라</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 변수와 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution/</link>
      <pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution/</guid>
      <description>정의 1 표본 공간 $\Omega$ 에서 확률 $P$ 가 정의되어 있다고 하자. 정의역이 표본 공간인 함수 $X : \Omega \to \mathbb{R}$ 을 확률 변수Random Variable라고 한다. 확률 변수의 치역 $X(\Omega)$ 을 공간Space이라고도 부른다. 다음을 만족하는 함수 $F_{X} : \mathbb{R} \to [0,1]$ 을 $X$ 의 누적분포함수(Cummulative Distribution Function, cdf) 라 한다. $$ F_{X}(x) = P_{X}\left( (-\infty,x] \right) = P \left( \left\{ \omega \in \Omega : X(\omega) \le x \right\} \right) $$</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution-in-terms-of-measure-theory/</link>
      <pubDate>Sat, 21 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution-in-terms-of-measure-theory/</guid>
      <description>정의 거리 공간 $S$ 의 보렐 시그마 필드 $\mathcal{S}:= \mathcal{B}(S)$ 에 대해 가측 공간 $(S,\mathcal{S})$ 을 정의하자. 확률 공간 $(\Omega, \mathcal{F}, P)$ 에서 정의된 확률 변수 $X$ 와 확률 과정 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 $n \to \infty$ 일 때 모든 $f \in C_{b}(S)$ 에 대해 다음을 만족하면 $\left\{ X_{n} \right\}$ 이 $X$ 로 분포 수렴한다Converge in Distribution고 말하고 $X_{n} \overset{D}{\to} X$ 와 같이 나타낸다. $$ \int_{\Omega} f(X_{n}) dP \to \int_{\Omega} f(X) dP $$ $C_{b}(S)$ 는 다음과 같이 $S$ 에서 정의되는</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률과 확률의 덧셈법칙</title>
      <link>https://freshrimpsushi.github.io/posts/probability-and-additive-law-of-probability/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-and-additive-law-of-probability/</guid>
      <description>정의 1 같은 조건 하에서 반복할 수 있는 시행을 임의 시행Random Experiment이라고 한다. 임의 시행에서 얻을 수 있는 모든 결과Outcome를 모아놓은 집합 $\Omega$ 를 표본 공간Sample Space이라고 한다. 표본 공간에서 우리가 관심을 가지는 결과들의 집합, 즉 $B \subset \Omega$ 를 사건Event이라 하고 이들의 집합을 $\mathcal{B}$ 와 같이 나타낸다.</description>
    </item>
    
    <item>
      <title>확률론의 혼성 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-portmanteau-theorem-in-probability-theory/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-portmanteau-theorem-in-probability-theory/</guid>
      <description>정리 공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자. 다음은 모두 동치다. (1): $P_{n} \overset{W}{\to} P$ (2): 모든 바운디드, 균등연속함수 $f$ 에 대해 $\displaystyle \int_{S} f dP_{n} \to \int_{S}f d P$ (3): 모든 클로즈드 셋 $F$ 에 대해 $\displaystyle \limsup_{n\to\infty} P_{n}(F) \le P(F)$ (4): 모든 오픈 셋 $G$ 에 대해 $\displaystyle P(G) \le \liminf_{n\to\infty} P_{n}(G)$ (5): $P(\partial A) = 0$ 인 모든 $A$ 에 대해 $\displaystyle \lim_{n\to\infty} P_{n}(A) = P(A)$ 설명 Portmanteau는 &amp;lsquo;여러가지로 이루어진&amp;rsq</description>
    </item>
    
    <item>
      <title>확률과정론에서의 프로젝션 매핑</title>
      <link>https://freshrimpsushi.github.io/posts/projection-mapping/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/projection-mapping/</guid>
      <description>정의 공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이고 $k \in \mathbb{N}$ 이라 하자. 이산형 프로젝션 매핑: (이산 시간) $N = \left\{ n \in \mathbb{N}: n \le \xi, \xi \in [0,\infty] \right\}\subset \mathbb{N}$ 과 $S$ 의 $\displaystyle S^{\sup N}:= \prod_{n \in N} S$ 의 원소 $x:= (x_{1} , x_{2} , \cdots )$ 에 대해 다음과 같이 정의된 $\pi_{k}: S^{\sup N} \to S^{k}$ 를 (이산형) 프로젝션 매핑이라 한다. $$ \pi_{k} (x) = (x_{1} , x_{2} , \cdots , x_{k}) $$ 연속형 프로젝션 매핑: (연속 시간) $T \subset [0,\infty]$ 에 대해 $\displaystyle</description>
    </item>
    
    <item>
      <title>폴란드 공간에서 정의되는 확률 측도는 타이트하다</title>
      <link>https://freshrimpsushi.github.io/posts/1428/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1428/</guid>
      <description>정리 거리 공간 $(S,\rho)$ 가 폴란드 공간이라고 하자. $S$ 에서 정의되는 모든 확률 측도는 타이트하다. 설명 폴란드 공간이란 가분 완비인 거리 공간을 말한다. 확률 측도의 타이트함이라는 것을 논할 때 어지간한 확률이 죄다 타이트한 것이 바로 이 때문이다. 물론 이는 거꾸로 말해 더 나아가 폴란드 공간이 아닌 곳에서 정의된 확률들을 연구해야함을 의미하기도 한다. 증명 전</description>
    </item>
    
    <item>
      <title>폴란드 공간</title>
      <link>https://freshrimpsushi.github.io/posts/polish-space/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/polish-space/</guid>
      <description>정의 다음의 조건들을 만족시키는 위상 공간 $X$ 를 폴란드 공간이라 한다. **(i): $X$ 는 거리화 가능 공간이다. (ii): $X$ 는 가분 공간이다. (iii): $X$ 는 완비 공간이다. 설명 원어가 Polish Space 인데 순화된 표현이 폴란드 공간 인 것에서 짐작할 수 있듯, 우리가 아는 &amp;lsquo;폴란드&amp;rsquo;에서 따온 말이 맞다. 이 공간이 처음 활발하게 연구한 것이 폴란드 출신의 위상수학</description>
    </item>
    
    <item>
      <title>연속체 가설</title>
      <link>https://freshrimpsushi.github.io/posts/continuum-hypothesis/</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuum-hypothesis/</guid>
      <description>추측 연속체 가설: $\aleph_{0} = |\mathbb{N}|$ 에 대해 $\aleph_{0} &amp;lt; x &amp;lt; 2^{\aleph_{0}}$ 를 만족하는 기수 $x$ 는 존재하지 않는다. 일반 연속체 가설: 초한기수 $a = |A|$ 에 대해 $a &amp;lt; x &amp;lt; 2^{a}$ 를 만족하는 기수 $x$ 는 존재하지 않는다. 설명 칸토어는 대각선 논법과 같은 방법으로 무한이라고 다 같은 무한이 아니라는 것을 증명해보였다. 무한집합이라고 해도 그 기수는 크기가 비교할 수 있으며, 자연수 집합 $\mathbb{N}$ 과 정</description>
    </item>
    
    <item>
      <title>러셀의 역설</title>
      <link>https://freshrimpsushi.github.io/posts/russell-paradox/</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/russell-paradox/</guid>
      <description>역설 1 모든 집합의 집합 $\mathscr{U}$ 가 존재한다면 어떤 집합 $R$ 은 $\mathscr{U}$ 에 속하면서도 속하지 않는다. 설명 기원 전 6세기, 크레타 출신의 철학자 에피메니데스는 이렇게 말했다: &amp;ldquo;모든 크레타 사람은 거짓말쟁이다!&amp;rdquo; 에피메니데스의 주장이 참이라면, 에피메니데스 또한 크레타 사람이므로 이 주장은 거짓이다. 그러나, 이 주장이 거짓이라</description>
    </item>
    
    <item>
      <title>부분순서 집합</title>
      <link>https://freshrimpsushi.github.io/posts/partially-ordered-set/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partially-ordered-set/</guid>
      <description>정의 1 집합 $A$ 에서의 관계 $\le$ 가 반사적, 추이적, 반대칭적이면 부분순서Partial Order이라 하고 $(A,\le)$ 를 반순서 집합이라고 부른다. $A$ 가 반순서 집합이라는 것은 모든 원소 $a,b \in A$ 에 대해 다음을 만족하는 것이다. $$ a \le b \land b \le a \implies a = b $$ 부분순서집합 $(A, \le)$ 가 주어져 있을 때 모든 $a,b \in A$ 에 대해 $a \le b$ 혹은 $b \le a$ 면 $\le$ 를 $A$ 에서의 전순서To</description>
    </item>
    
    <item>
      <title>완전 유계 공간</title>
      <link>https://freshrimpsushi.github.io/posts/totally-bounded-space/</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/totally-bounded-space/</guid>
      <description>정의 1 거리 공간 $(X,d)$ 과 $\varepsilon&amp;gt;0$ 가 주어져 있다고 하자. 모든 $x \in X$ 에 대해 $B_{d}(x,\varepsilon) \cap A_{\varepsilon} \ne \emptyset$ 을 만족하는 유한 집합 $A_{\varepsilon} \subset X$ 를 $X$ 에 대한 $\varepsilon$-그물$\varepsilon$-net이라 한다. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $X$ 에 대한 $\varepsilon$-넷 $A_{\varepsilon}$ 가 존재하면 $X$ 가 완전 유계Totally Bounded라 한다. 설명 완전 유</description>
    </item>
    
    <item>
      <title>타이트 확률 측도</title>
      <link>https://freshrimpsushi.github.io/posts/tight-probability-measure/</link>
      <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tight-probability-measure/</guid>
      <description>정의 공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자. $P$ 가 $S$ 에서 정의된 확률 측도라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $P(K) &amp;gt; 1 - \varepsilon$ 가 되도록하는 컴팩트 셋 $K$ 가 존재하면 $P$ 가 타이트Tight하다고 한다. 설명 일반적으로 학부 수준 이하의 확률에서는 타이트하지 않은 확률은 접하기가 어렵다. 가령 정규분포를 따르는 확률 변수 $X$ 에서 유도된 확률 측</description>
    </item>
    
    <item>
      <title>실수의 기수와 유리수의 기수의 크기 비교</title>
      <link>https://freshrimpsushi.github.io/posts/comparing-the-cardinality-of-real-and-rational/</link>
      <pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/comparing-the-cardinality-of-real-and-rational/</guid>
      <description>정리 1 $\text{card}(\mathbb{Q})={{ \aleph }_{ 0 }}, \text{card}(\mathbb{R})=c$ 에 대해 $$ { 2 }^{ {{ \aleph }_{ 0 }} } =c \\ {{ \aleph }_{ 0 }}&amp;lt;c $$ 설명 칸토어의 대각선 논법을 보면 짐작할 수 있듯, 유리수의 집합보다 실수의 집합이 훨씬 많은 원소를 갖는다. 그 기수는 구체적으로 부등식을 세워서 보일 수 있다. 증명 Part 1. $c \le 2^{\aleph_{0}}$ 함수 $f : \mathbb{R} \to \wp (\mathbb{Q})$ 를 $f(a):={x\in \mathbb{Q}|x&amp;lt;a, a\in \mathbb{R}}$ 와 같이 정의하자. 실수의 조밀성 의해 두 실수 $a&amp;lt;b$ 에 대해 $a&amp;lt;r&amp;l</description>
    </item>
    
    <item>
      <title>줄리아에서 패키지 설치하고 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-and-use-packages-in-julia/</link>
      <pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-and-use-packages-in-julia/</guid>
      <description>방법 1 using LinearAlgebra using Pkg Pkg.add(&amp;#34;Plots&amp;#34;) Pkg.add(&amp;#34;Distributions&amp;#34;) using Plots 위의 코드는 LinearAlgebra 패키지와 Pkg 패키지를 불러오며, .add() 함수를 통해 Plots, Distribution 패키지를 설치하는 코드를 나타낸다. 패키지를 불러오는 키워드 using은 마치 수학에서 어떤 정리나 논법을 사용할 때 쓰는 말과 닮았다. 패키지를 설치하는 것 자체는 파이썬보다는 R에 더 가깝고, 사용법은 파이썬과 더 비슷하다. R과 마찬가지로 패키지 이름을</description>
    </item>
    
    <item>
      <title>두 확률 측도가 서로 같아지는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/conditions-for-equality-of-two-probability-measure/</link>
      <pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditions-for-equality-of-two-probability-measure/</guid>
      <description>정리 공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자. $\mathcal{O}$ 는 모든 열린 집합들의 집합, $\mathcal{C}$ 는 모든 닫힌 집합들의 집합이고 $P$ 와 $Q$ 는 $(S,\mathcal{B}(S))$ 에서 정의된 확률 측도다. [1]: 모든 열린 집합 $O \in \mathcal{O} \subset S$ 에 대해 $P(O) = Q(O)$ 면 $P=Q$ 다. 다른 표현으로, $\mathcal{O}$ 는 세퍼레이팅 클래스다. [2]: 모든 닫힌 집합 $C \in \mathcal{C} \subset S$ 에 대해 $P(C) = Q(C)$ 면 $P=Q$ 다. 다른 표현으로, $\mathcal{C}$ 는 세퍼레이팅 클래</description>
    </item>
    
    <item>
      <title>R 패키지 설치 시 Warning in installpackages  lib = CProgram FilesRR-361library is not writable 해결</title>
      <link>https://freshrimpsushi.github.io/posts/1414/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1414/</guid>
      <description>개요 R 을 처음 접하는, 그 중에서 프로그래밍은 고사하고 컴퓨터에 익숙하지조차 않지만 당장 R을 사용해야하는 사용자의 눈높이에 맞췄으므로 지나치게 설명이 자세할 수 있다. WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding: https://cran.rstudio.com/bin/windows/Rtools/ 빨리 R 을 써서 뭔가를 해야하는데 위와 같은 경고가 뜨면서 패키지가 설치되지 않는 경우가 종종 있다. 주로 R을 처음 쓰거나</description>
    </item>
    
    <item>
      <title>칸토어의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cantors-theorem/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cantors-theorem/</guid>
      <description>정리 1 임의의 집합 $X$ 와 그 멱집합 $\mathscr{P} (X)$ 에 대해 $$ \text{card}(X)&amp;lt;\text{card}(\mathscr{P} (X)) $$ 설명 어떤 집합이든 그 기수는 그 멱집합의 기수보다 작다는 말이다. 이미 집합론에서 말하는 무한이라는 개념에 익숙해졌다면 이것은 조금 의외일지도 모르겠다. 자연수의 집합 $\mathbb{N}$ 이 유리수의 집합 $\mathbb{Q}$ 과 일대일 대응이 존재했고, 안타깝게도 $\mathbb{R}$ 과의 일대일 대응은 존재하지 않았다. 이러한 논의들을 생각해볼</description>
    </item>
    
    <item>
      <title>확률론에서의 세퍼레이팅 클래스</title>
      <link>https://freshrimpsushi.github.io/posts/separating-class/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separating-class/</guid>
      <description>정리 가측 공간 $(S, \mathcal{B}(S))$ 에서 정의된 두 확률 $P$, $Q$ 에 대해 다음을 만족하는 $\mathcal{C}$ 를 세퍼레이팅 클래스Separating Class라고 한다. $$ P(A) = Q(A), \forall A \in \mathcal{C} \implies P(A) = Q(A), \forall A \in \mathcal{B}(S) $$ 설명 세퍼레이팅 클래스가 존재한다는 것은 두 측도가 서로 같은지 확인하기 위해서 가측 공간 전체가 아니라 일부만 확인하면 된다는 의미가 된다. 상식적으로 이렇게 좋은 클래스가 그</description>
    </item>
    
    <item>
      <title>칸토어-베른슈타인 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cantor-bernstein-theorem/</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cantor-bernstein-theorem/</guid>
      <description>정리 1 집합 $A$, $B$ 에 대해 $A$ 가 $B$ 의 부분집합과 대등하고 $B$ 가 $A$ 의 부분집합과 대등하면 $A$ 와 $B$ 는 대등하다. 두 집합이 대등하다는 것은 두 집합 사이에 전단사가 존재한다는 것이다. 증명 전략: $x$ 에 함수 $f$ 를 $k$ 번 취하는 것을 $f^{k}(x)$ 와 같이 나타내려고 한다. 그러면 모든 $k \in \mathbb{N}$ 에 대해 $f^{k}(x) = f \left( f^{k-1}(x) \right)$ 처럼 나타낼 수 있을 것이다. 이러한 관점에서 $f^{0}$ 는 함수 $f$ 를 한 번도</description>
    </item>
    
    <item>
      <title>측도의 약한 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/weak-convergence-of-probability-measure/</link>
      <pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weak-convergence-of-probability-measure/</guid>
      <description>정의 공간 $S$ 가 거리 공간 $( S , \rho)$ 이면서 가측 공간 $(S,\mathcal{B}(S))$ 이라고 하자. 측도론 $S$ 에서 정의되는 측도 $\mu$ 와 측도의 시퀀스 $\left\{ \mu_n \right\}_{n \in \mathbb{N}}$ 이 $n \to \infty$ 일 때 모든 $f \in C_{b}(S)$ 에 대해 다음을 만족하면 $\left\{ \mu_{n} \right\}$ 이 측도 $\mu$ 로 약하게 수렴한다Converge Weakly고 말하고 $\mu_{n}\overset{W}{\to}\mu$ 와 같이 나타낸다. $$ \int_{S} f d\mu_{n} \to \int_{S} f d\mu $$ 확률론 $S$ 에서 정의되는 확률 $P$ 와 확률의 시퀀스 $\left\{ P_n \right\}_{n \in \mathbb{N}}$</description>
    </item>
    
    <item>
      <title>파이썬에서 numpy array로 행병합 열병합하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-bind-in-row-or-column-numpy-array/</link>
      <pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-bind-in-row-or-column-numpy-array/</guid>
      <description>코드 import numpy as np a = np.array([[1,2,3]]) b = np.array([[4,5,6]]) print(a) print(b) print(np.c_[a,b]) print(np.r_[a,b]) 파이썬의 numpy 패키지는 무척 편리한 기능을 많이 제공한다. 다음의 스크린샷에서 보이다시피 객체 numpy.c_와 numpy.r_는 대괄호 [] 안에 들어간 배열들을 각각 열(column)병합, 행(row)병합한 배열이다. 여기서 이들이 메서드가 아님을 분명히 하고 넘어가자. 마치 메서드처럼 쓰고 있지만</description>
    </item>
    
    <item>
      <title>확률론에서의 레비 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-levys-theorem-in-probability-theory/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-levys-theorem-in-probability-theory/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져있다고 하자. $\eta$ 가 적분 가능한 확률 변수고 $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$ 가 $\mathcal{F}_{n} \subset \mathcal{F}_{n+1}$ 인 시그마 필드의 시퀀스면 $n \to \infty$ 일 때 $$ E \left( \eta | \mathcal{F}_{n} \right) \to E \left( \eta | \mathcal{F}_{\infty} \right) $$ $\displaystyle \mathcal{F}_{\infty} = \bigotimes_{n=1}^{\infty} \mathcal{F}_{n}$ 는 텐서 곱이 아니라 $\mathcal{F}_{n}$ 들의 모든 원소들을 포함하면서 가장 작은 시그마 필드를 의미한다. 그다지 새로울 것은 없는 게, 사실 위상 공간 $\Omega$ 의 모든 열린 집합을 포함하면서 가장</description>
    </item>
    
    <item>
      <title>딘킨의 파이-람다 정리</title>
      <link>https://freshrimpsushi.github.io/posts/dynkins-pi-lambda-theorem/</link>
      <pubDate>Sat, 30 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynkins-pi-lambda-theorem/</guid>
      <description>정리 파이 시스템 $\mathcal{P}$ 가 람다 시스템 $\mathcal{L}$ 의 부분집합이면 $\mathcal{P} \subset \sigma ( \mathcal{P} ) \subset \mathcal{L}$ 을 만족하는 시그마 필드 $\sigma ( \mathcal{P} )$ 가 존재한다. $\sigma ( \mathcal{P} )$ 는 $\mathcal{P}$ 의 모든 원소를 포함하는 가장 작은 시그마 필드를 나타낸다. 설명 스테이트먼트만 보면 아주 간단해보이지만 이러한 정리들이 그러하듯 그 증명은 상당히 길고 복잡하다. 여기서 파이 시스템 $\mathcal{P}$ 와 람다 시스템 $\mathcal{L}$ 의 역할이 무엇일지</description>
    </item>
    
    <item>
      <title>파이썬에서 큰 csv 파일 한번에 읽는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-big-data-csv-file-in-python/</link>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-big-data-csv-file-in-python/</guid>
      <description>코드 y_test=[] y_csv = open(&amp;#39;y_test.csv&amp;#39;, &amp;#39;r&amp;#39;, encoding=&amp;#39;utf-8&amp;#39;) rdr = csv.reader(y_csv) for line in rdr: y_test.append(line[0]) y_csv.close() 보통 csv 파일을 읽어들일 때는 위와 같이 파이썬 내장함수 open으로 열어서 한줄한줄 처리하지만, 반복문을 사용하는 시점에서 빅데이터의 처리에는 적합하지 않음을 짐작할 수 있다. 가령 700MB가 넘는 파일이라면 사실 별로 크지도 않은 편이지만 한줄한줄 읽어서는 끝이 없다. pandas 패키지 이런 데이터를 다룰 때는 pandas</description>
    </item>
    
    <item>
      <title>파이 시스템과 람다 시스템</title>
      <link>https://freshrimpsushi.github.io/posts/pi-system-and-lambda-system/</link>
      <pubDate>Thu, 28 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pi-system-and-lambda-system/</guid>
      <description>정의 다음을 만족하는 $\mathcal{P}$ 을 $\pi$-시스템이라 한다. $$ A, B \in \mathcal{P} \implies A \cap B \in \mathcal{P} $$ 다음의 조건들을 만족하는 $\mathcal{L}$ 을 $\lambda$-시스템이라 한다. (i): $\emptyset \in \mathcal{L}$ (ii): $A \in \mathcal{L} \implies A^{c} \in \mathcal{L}$ (iii): 모든 $i \ne j$ 에 대해 $\displaystyle A_{i} \cap A_{j} = \emptyset$ 일 때, $\displaystyle \left\{ A_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{L} \implies \bigcup_{n \in \mathbb{N}} A_{n} \in \mathcal{L}$ 설명 측도론에서의 시스템System이란 컬렉션 상에서 정의된 일종의 대수구조로 볼</description>
    </item>
    
    <item>
      <title>L1 수렴 마틴게일이면 클로저블 마틴게일이다</title>
      <link>https://freshrimpsushi.github.io/posts/if-convergence-in-l1-martingale-then-closable/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-convergence-in-l1-martingale-then-closable/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 과 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. 확률 과정 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 확률 변수 $Y$ 로 $\mathcal{L}_{1}$하면 $\left\{ ( X_{n} , \mathcal{F}_{n} ): n = 1 , \cdots , \infty \right\}$ 은 클로저블 마틴게일이다. 설명 원래 $X_{n}$ 이 $Y$ 로 $\mathcal{L}_{1}$ 수렴하고 $X_{n}$ 이 $X_{\infty}$ 로 거의 확실히 수렴한다고 해도 $Y$ 와 $X_{\infty}$ 이 어떤 관계가 있다고 장담할 수는 없다. $$ X_{n} \overset{\mathcal{L}_{1}}{\to} Y</description>
    </item>
    
    <item>
      <title>파이썬에서 pip로 cv2 PIL 패키지 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-cv2-pil-package-in-python-using-pip/</link>
      <pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-cv2-pil-package-in-python-using-pip/</guid>
      <description>가이드 openCV 패키지와 PIL 패키지는 이미지 처리에 유용한 패키지다. 문제는 보통 예제 코드에서 두 패키지를 불러들일 때 cv2, PIL라고 하는데 막상 파이썬에서 pip를 이용해서 설치하려고하면 에러를 낸다는 것이다. 이는 파이썬에서 불러들일때의 이름과 설치할 때의 이름이 다르기 때문이다. openCV 스크린샷에서 보이는 것과 같이 openCV를 설치하기 위해서는</description>
    </item>
    
    <item>
      <title>균등적분가능 마틴게일이면 L1 수렴 마틴게일이다</title>
      <link>https://freshrimpsushi.github.io/posts/if-uniformly-integrable-martingale-then-converge-in-l1/</link>
      <pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-uniformly-integrable-martingale-then-converge-in-l1/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져 있다고 하자. 확률 과정 $\left\{ X_{n} \right\}$ 이 어떤 확률 변수 $X_{\infty}$ 에 대해 다음을 만족하면 $\left\{ X_{n} \right\}$ 이 $X_{\infty}$ 로 $\mathcal{L}_{p}$ 수렴한다고 말한다. $$ \lim_{n \to \infty} \| X_{n} - X_{\infty} \|_{p} = 0 $$ 확률 과정 $\left\{ X_{n} \right\}$ 가 $\mathcal{L}_{p}$ 수렴하면 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 $\mathcal{L}_{p}$ 수렴한다고 말한다. 정리 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 균등적분가능이면 $\mathcal{L}_{1}$ 수렴한다. 설명 측도론의 센스로 보았을</description>
    </item>
    
    <item>
      <title>비탈리 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/vitali-convergence-theorem/</link>
      <pubDate>Sun, 24 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vitali-convergence-theorem/</guid>
      <description>정리 1 측도 공간 $( X , \mathcal{E} , \mu)$ 가 주어져 있다고 하자. $1 \le p &amp;lt; \infty$ 라고 할 때 함수의 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{L}^{p}$ 가 $f$ 로 $\mathcal{L}_{p}$ 수렴하는 것은 다음 세 가지를 모두 만족하는 것과 필요충분조건이다. (i): $\left\{ f_{n} \right\}$ 은 $f$ 로 측도 수렴한다. (ii): $\left\{ | f_{n} |^{p} \right\}$ 은 균등적분가능하다. (iii): 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ F \in \mathcal{E} \land F \cap E = \emptyset \implies \int_{F} | f_{n} |^{p} d \mu &amp;lt; \varepsilon^{p} \qquad \forall n \in \mathbb{N} $$ 를 만족하고 $\mu (E) &amp;lt;</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability-in-terms-of-measure-theory/</link>
      <pubDate>Sat, 23 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability-in-terms-of-measure-theory/</guid>
      <description>확률 수렴의 어려운 정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져 있다고 하자. 확률 변수의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 확률 변수 $X$ 로 측도 수렴하면 확률 수렴한다고 말하고 $X_{n} \overset{P}{\to} X$ 와 같이 나타낸다. 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다. 설명 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 $X$ 로 수렴한다는 말은 곧 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ \lim_{n \to \infty} P \left( \left\{ \omega \in \Omega : | X_{n}(\omega) - X(\omega) | \ge \varepsilon</description>
    </item>
    
    <item>
      <title>측도 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-measure/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-measure/</guid>
      <description>정의 1 측도 공간 $( X , \mathcal{E} , \mu)$ 가 주어져 있다고 하자. 가측 함수의 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 어떤 가측함수 $f$ 와 모든 $M &amp;gt;0$ 에 대해 다음을 만족하면 $f$ 로 측도 수렴한다고 말한다. $$ \lim_{n \to \infty} \mu \left( \left\{ x \in X : | f_{n}(x) - f(x) | \ge M \right\} \right) = 0 $$ 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 모든 $M &amp;gt;0$ 에 대해 다음을 만족하면 측도에서 코시Cauchy in Measure라고 한다. $$ \lim_{n,m \to \infty} \mu \left( \left\{</description>
    </item>
    
    <item>
      <title>집합의 기수</title>
      <link>https://freshrimpsushi.github.io/posts/cardinality-of-set/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cardinality-of-set/</guid>
      <description>정의 1 임의의 집합 $X$ 에 대해 다음의 성질들을 갖는 $\text{card} X$ 를 $X$ 의 기수Cardinality라고 정의한다. (i): $X = \emptyset \iff \text{card} X = 0$ (ii): $A \sim B \iff \text{card} A = \text{card} B$ (iii): 어떤 자연수 $k$ 에 대해 $X \sim \left\{ 1 , 2, \cdots , k \right\}$ 면 $\text{card} X = k$ 특히, 유한집합의 기수를 유한기수라 하고 무한집합의 기수를 초한기수라고 한다. 두 집합 $A$, $B$ 에 대해 $A$ 가 $B$ 의 어떤 부분집합과는 대등하지만</description>
    </item>
    
    <item>
      <title>레귤러 마틴게일이면 균등적분가능 마틴게일이다</title>
      <link>https://freshrimpsushi.github.io/posts/if-regular-martingale-then-uniformly-integrable/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-regular-martingale-then-uniformly-integrable/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 가 주어져 있다고 하자. 확률 변수의 집합 $\Phi$ 가 주어져있다고 할 때, 모든 $\varepsilon&amp;gt;0$ 에 대해 $$ \sup_{ X \in \Phi } \int_{ \left( \left| X \right| \ge k \right) } \left| X \right| dP &amp;lt; \varepsilon $$ 를 만족하는 $k \in \mathbb{N}$ 가 존재하면 $\Phi$ 가 균등적분가능하다고 말한다. 확률 과정 $\left\{ X_{n} \right\}$ 가 균등적분가능하면 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 균등적분가능하다고 말한다. 정리 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$</description>
    </item>
    
    <item>
      <title>균등적분가능성</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-integrablility/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-integrablility/</guid>
      <description>정의 측도 공간 $( X , \mathcal{E} , \mu)$ 가 주어져 있다고 하자. 르벡 적분 가능한 함수의 집합 $\Phi \subset \mathcal{L}^{1}$ 이 주어져있다고 할 때, 모든 $\varepsilon&amp;gt;0$ 에 대해 $$ \mu (E) &amp;lt; \delta \implies \sup_{f \in \Phi} \int_{ E } \left| f \right| d \mu &amp;lt; \varepsilon $$ 를 만족하는 $\delta &amp;gt; 0$ 가 존재하면 $\Phi$ 가 균등적분가능하다고 한다. 설명 균등적분가능성은 균등Uniformly이라는 말이 붙은만큼 셋 개념으로 접근하며, $\Phi$ 에 속한다면 어떤 함수</description>
    </item>
    
    <item>
      <title>레귤러 마틴게일과 클로저블 마틴게일</title>
      <link>https://freshrimpsushi.github.io/posts/regular-martingale-and-closable/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regular-martingale-and-closable/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. 만약 어떤 적분가능한 확률 변수 $\eta$ 에 대해 $X_{n} = E ( \eta | \mathcal{F}_{n} )$ 이면 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 을 레귤러 마틴게일이라 한다. 만약 $\left\{ ( X_{n} , \mathcal{F}_{n} ): n = 1 , \cdots , \infty \right\}$ 이 마틴게일이 되도록 하는 어떤 적분가능한 확률 변수 $X_{\infty}$ 이 존재하고 $\mathcal{F}_{\infty}$-가측</description>
    </item>
    
    <item>
      <title>칸토어의 대각선 논법</title>
      <link>https://freshrimpsushi.github.io/posts/cantors-diagonal-argument/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cantors-diagonal-argument/</guid>
      <description>정리 1 열린 구간 $(0,1)$ 은 비가산집합이다. 증명 실수 집합 $\mathbb{R}$ 은 가산 집합이 아닌데, 이것은 실수 집합과 어떤 가산 집합 사이에 &amp;lsquo;일대일 대응&amp;rsquo;이 존재하지 않음을 통해서 보인다. 이는 자연수 집합과 열린 구간 $(0,1)$ 사이에 일대일 대응이 존재하지 않는 것을 보이고, 그 따름정리로써 얻을 수 있다. 칸토어는 이것을 놀라운 방법으로 증명해냈</description>
    </item>
    
    <item>
      <title>가산집합과 비가산집합</title>
      <link>https://freshrimpsushi.github.io/posts/countable-set-and-uncountable-set/</link>
      <pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/countable-set-and-uncountable-set/</guid>
      <description>정의 1 집합 $X$ 가 유한 집합이거나 $X \sim \mathbb{N}$ 면 가산 집합이라 한다. 가산 집합이 아닌 집합을 비가산 집합이라 한다. $\mathbb{N}$ 은 자연수의 집합이다. 설명 가산 집합이라는 개념은 동양인, 물론 한국인에게 받아들이기 쉽지만은 않다. 이는 영어를 비롯한 인도유럽어족의 사고방식과 우리의 마인드가 판이하게 다른 점에서 온다. 알다시피 유럽어는 명사에도 성이 있고 수,</description>
    </item>
    
    <item>
      <title>서브 마틴게일 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-sub-martingale-convergence-theorem/</link>
      <pubDate>Sat, 16 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-sub-martingale-convergence-theorem/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. $\displaystyle \sup_{n \in \mathbb{N}} E X_{n}^{+} &amp;lt; \infty$ 이라고 하면 $X_{n}$ 은 어떤 확률 변수 $X_{\infty}: \Omega \to \mathbb{R}$ 로 거의 확실히 수렴하고 $$E X_{\infty} &amp;lt; E X_{\infty}^{+} &amp;lt; \infty$$ 증명 전략: 리미트 슈프리멈과 리미트 인피멈의 성질을 사용한다. $$ X^{\ast}:= \limsup_{n \in \mathbb{N}} X_{n} \\ X_{\ast}:= \liminf_{n \in \mathbb{N}} X_{n} $$ 이라고 하면 $$ \left( X^{\ast} &amp;gt; X_{\ast} \right) = \bigcup_{a &amp;lt; b \\ a, b \in \mathbb{Q}} \left( X^{\ast} &amp;gt; b &amp;gt; a &amp;gt; X_{\ast} \right) $$ 인</description>
    </item>
    
    <item>
      <title>집합론으로 엄밀하게 정의되는 유한 집합과 무한 집합</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-infinite-set/</link>
      <pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-infinite-set/</guid>
      <description>정의 1 두 집합 $X,Y$ 에 대해 전단사 $f : X \to Y$ 가 존재하면 $X$ 와 $Y$ 가 서로 대등하다Equipotent고 하고 $X \sim Y$ 와 같이 나타낸다. 공집합이 아닌 $X$ 의 어떤 진부분집합 $Y \subsetneq X$ 에 대해 $X \sim Y$ 면 $X$ 를 무한 집합이라 한다. 무한 집합이 아닌 집합을 유한 집합이라 한다. 설명 흔히 집합론을 동원하지 않고 무한을 설명하려고 할 때 대등하다는 표현을 울타리에서 양</description>
    </item>
    
    <item>
      <title>공진리란?</title>
      <link>https://freshrimpsushi.github.io/posts/vacuous-truth/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vacuous-truth/</guid>
      <description>정리 임의의 명제 $p$ 와 모순 $c$ 그리고 $A_{\alpha} \subset X$ 에 대해 다음이 성립한다. [1] 공진리: $c \implies p$ [2] 합집합: $\displaystyle \bigcup_{\alpha \in \emptyset} A_{\alpha} = \emptyset$ [3] 교집합: $\displaystyle \bigcap_{\alpha \in \emptyset} A_{\alpha} = X$ 설명 예를 들어 &amp;ldquo;신은 죽었다.&amp;rdquo; 라는 말에서 신이 존재하지 않는다면, 가정부터 틀려먹었다면 어떻게 되는 걸까? 신이 존재하지 않는다면 $0$ 명의 신이 죽은 것이므로 누가 진짜 죽었나 살</description>
    </item>
    
    <item>
      <title>확률과정론에서의 업크로싱</title>
      <link>https://freshrimpsushi.github.io/posts/upcrossing-in-stochastic-process/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/upcrossing-in-stochastic-process/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자.폐구간 $[a,b]$ 에 대해 $X_{t_{1}} \le a$ 이었다가 $X_{t_{2}} \ge b$ 가 되는 것을 업크로싱이라 한다. $N \in \mathbb{N}$ 번까지 관찰할 때 업크로싱의 횟수를 다음과 같이 나타낸다. $$ \beta_{N} (a,b): = \text{A number of upcrossing of } \left\{ X_{n} \right\} \text{ of interval } [a,b] $$ 기초 성질 [1]: $\chi_{i}$ 는 $\mathcal{F}_{i-1}$-가측 함수다. [2]: $\displaystyle E</description>
    </item>
    
    <item>
      <title>줄리아의 타입과 애노테이션</title>
      <link>https://freshrimpsushi.github.io/posts/type-and-annotation-in-julia/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/type-and-annotation-in-julia/</guid>
      <description>코드 julia&amp;gt; typeof(0) Int64 julia&amp;gt; typeof(0.0) Float64 julia&amp;gt; typeof(0 == 0.0) Bool julia&amp;gt; typeof(Bool) DataType julia&amp;gt; typeof(NaN) Float64 julia&amp;gt; typeof(Inf) Float64 julia&amp;gt; typeof(&amp;#39;O&amp;#39;) Char julia&amp;gt; typeof(&amp;#34;Ohmygirl&amp;#34;) String julia&amp;gt; typeof(&amp;#34;O&amp;#34;) String 줄리아에는 온갖 타입들이 구현되어있다. $0$ 과 $0.0$ 은 같은 $0$ 이지만 다른 타입을 가지며, 보다시피 타입인 Bool조차 DataType이라는 타입을 갖는다. C 언어처럼 String은 Char의 배열이며, 위와 같이 큰 따옴표인가 작은 따옴표인가로 구분된다. julia&amp;gt; supertype(Int64) Signed julia&amp;gt; supertype(Signed) Integer</description>
    </item>
    
    <item>
      <title>단사, 전사, 전단사, 역함수</title>
      <link>https://freshrimpsushi.github.io/posts/injection-surjection-bijection-inverse-function/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/injection-surjection-bijection-inverse-function/</guid>
      <description>정의 1 $x \in X$ 이고 $y \in Y$ 그리고 $f: X \to Y$ 가 함수라고 하자. 모든 $x_{1}, x_{2} \in X$ 에 대해 $x_{1} \ne x_{2} \implies f(x_{1}) \ne f(x_{2})$ 면 $f$ 를 단사injective라고 한다. $f(X) = Y$ 면 $f$ 를 전사surjective라고 한다. $f$ 가 단사면서 전사면 전단사bijective라고 한다. $I(x) = x$ 를 만족하는 $I : X \to X$ 를 항등함수Identity Function라고 한다. 모</description>
    </item>
    
    <item>
      <title>둡의 최대 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-doobs-maximal-inequality/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-doobs-maximal-inequality/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 마틴 게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. 어떤 $N \in \mathbb{N}$ 과 $p&amp;gt;1$ 에 대해 $X_{n} \ge 0 (n \le N)$, $E X_{N}^{p} &amp;lt; \infty$ 이면 $$ E \left( \max_{n \le N} X_{n}^{p} \right) \le \left( {{ p } \over { p-1 }} \right)^{p} E X_{N}^{p} \text{ a.s.} $$ 설명 수식의 모양은 $\displaystyle \max_{n \le N} \cdot_{n} ^{p}$ 으로 말미암아 생기는 $\displaystyle \left( {{ p } \over { p-1 }} \right)^{p}$ 을 밖으로 빼내고 그 상한을 계산하는 것으로 볼 수 있다. $\displaystyle \left( {{ p } \over { p-1 }} \right)&amp;gt;1$ 이기 때</description>
    </item>
    
    <item>
      <title>줄리아 프로그래밍 언어</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-julia-language/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-julia-language/</guid>
      <description>개요 줄리아는 MIT에서 개발되어 2012년 공개된 프로그래밍 언어로써, 생산성이 높으면서도 속도가 높은 언어를 지향한다. C나 포트란에 준하는 속도를 내면서도 파이썬이나 R처럼 고수준의 문법을 갖추었으며, 그 외에도 여러 언어들의 장점을 취하고 있다. 2019년 11월 현재는 GPU가 급속도로 발전하면서 딥러닝이 유행을 선도하고 있어 조금</description>
    </item>
    
    <item>
      <title>함수의 원상</title>
      <link>https://freshrimpsushi.github.io/posts/preimage-of-function/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/preimage-of-function/</guid>
      <description>정의 1 함수 $f: X \to Y$ 와 $B \subset Y$ 에 대해 $f^{-1}(B): = \left\{ x \in X \ | \ f(x) \in B \right\}$ 를 $f$ 에 따른 $B$ 의 원상 혹은 역상이라 한다. 설명 표기는 비슷하지만 정의 자체만으로 역상과 역함수가 어떤 관계에 있다고 말할 수는 없으며, 이들을 혼동하지 않아야한다. 한국어로 말하기엔 역상이 자연스러운 반면 영어로는 [프리이미지]가 자연스럽게 느껴지는 사람이 있을 것이다. 이는</description>
    </item>
    
    <item>
      <title>마틴게일의 부등식들</title>
      <link>https://freshrimpsushi.github.io/posts/inequalities-of-martingale/</link>
      <pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inequalities-of-martingale/</guid>
      <description>정리 $\left\{ (X_{n} , \mathcal{F}_{n}) \right\}$ 이 슈퍼 마틴게일이라고 하자. [1]: 모든 $\lambda &amp;gt; 0$ 에 대해 $$ \begin{align*} \lambda P \left( \max_{n \le N} X_{n} \ge \lambda \right) \le &amp;amp; E X_{1} - \int_{(\max_{n \le N} X_{n} &amp;lt; \lambda)} X_{N} dP \\ \le &amp;amp; E X_{1} + E X_{N}^{-} \text{ a.s.} \end{align*} $$ [2]: 모든 $\lambda &amp;gt; 0$ 에 대해 $$ \begin{align*} \lambda P \left( \min_{n \le N} X_{n} \le - \lambda \right) \le &amp;amp; - \int_{(\min_{n \le N} X_{n} \le - \lambda)} X_{N} dP \\ \le &amp;amp; E X_{N}^{-} \text{ a.s.} \end{align*} $$ $\left\{ (X_{n} , \mathcal{F}_{n}) \right\}$ 이 서브 마틴게일이라고 하자. [3]: 모든 $\lambda &amp;gt; 0$ 에 대해 $$ \begin{align*} \lambda P \left( \max_{n \le N} X_{n} \ge \lambda \right) \le &amp;amp;</description>
    </item>
    
    <item>
      <title>집합론으로 엄밀하게 정의되는 함수와 상, 수열</title>
      <link>https://freshrimpsushi.github.io/posts/function-image-and-sequence/</link>
      <pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/function-image-and-sequence/</guid>
      <description>정의 1 공집합이 아닌 두 집합 $X$, $Y$ 이 주어져 있다고 하자. 이항 관계 $f \subset (X,Y)$ 가 다음을 만족하면 함수라 하고 $f : X \to Y$ 와 같이 나타낸다. $$ (x ,y_{1}) \in f \land (x,y_{2}) \in f \implies y_{1} = y_{2} $$ 함수 $f : X \to Y$ 에 대해 $\text{Dom} (f) = X$ 를 $f$ 의 정의역Domain, $Y$ 를 $f$ 의 공역Codomain이라 한다. 정의역의 부분집합 $A \subset X$ 이 주어져 있을 때, $f(A):= \left\{ f(a) \in Y \ | \ x \in A \right\}$ 를 $f$</description>
    </item>
    
    <item>
      <title>동치관계에 의한 집합의 분할</title>
      <link>https://freshrimpsushi.github.io/posts/partition-by-equivalent-relation/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-by-equivalent-relation/</guid>
      <description>정리 1 집합 $X$ 상의 동치관계 $R$ 에 대해 $X / R$ 은 $X$ 의 분할이다. 설명 이 정리는 별 것 아닌 것 같아 보이지만 위상수학, 추상대수학 등 수학 전반에서 널리 쓰이고 있다.동치관계란 쉽게 말해서 이거나 저거나 &amp;lsquo;같다&amp;rsquo;고 보자는건데, 아이러니하게도 동치관계가 주어짐으로써 ‘같지 않음’이라는 개념이 동반된다. 전체집합은 동치</description>
    </item>
    
    <item>
      <title>프로그래밍에서의 일급 객체</title>
      <link>https://freshrimpsushi.github.io/posts/first-class-object-in-programming/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/first-class-object-in-programming/</guid>
      <description>정의 프로그래밍에서 일급 객체First Class Object는 다음의 조건을 만족하는 요소를 말한다. (i) 함수의 실제 매개변수가 될 수 있다. (ii) 함수의 반환 값이 될 수 있다. (iii) 할당 명령문의 대상이 될 수 있다. (iv) 동일 비교의 대상이 될 수 있다. 예시 쉽게 말해 보통 수처럼 다룰 수 있는 것을 일급 객체라고 하는데, 이는 자명하게도 &amp;lsquo;보통 수&amp;rsq</description>
    </item>
    
    <item>
      <title>k-평균 군집화</title>
      <link>https://freshrimpsushi.github.io/posts/k-means-clustering/</link>
      <pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k-means-clustering/</guid>
      <description>알고리즘 Input $p$ 차원의 데이터 $N$ 개와 자연수 $k$ 가 주어져있다고 하자. Step 1. 초기화 $k$ 개의 점 $\mu_{1} , \cdots , \mu_{k}$ 을 랜덤하게 정한다. 각각의 $\mu_{j}$ 는 군집 $M_{j}$ 의 평균이 될 것이다. Step 2. 거리 계산 $i$ 번째 데이터 $x_{i}$ 와 $j = 1 , \cdots , k$ 에 대해서 $\| x_{i} - \mu_{j} \|$ 를 계산한다. 그 중 가장 작은 것을 골라 $x_{i} \in M_{j}$ 이 되도록 한다. 이를 각각의 $i = 1 , \cdots , N$ 에 대해 반복한다. Step 3. $\mu_{j}$ 업데</description>
    </item>
    
    <item>
      <title>동치류</title>
      <link>https://freshrimpsushi.github.io/posts/equivalence-class/</link>
      <pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalence-class/</guid>
      <description>정의 1 집합 $X$ 상에서 동치관계 $R$ 이 정의되어있다고 하자. $x \in X$ 에 대해 $x / R := \left\{ y \in X : y R x \right\}$ 를 $x$ 의 동치류라고 한다. 주어진 $X$ 의 모든 동치류를 모은 집합을 $X / R := \left\{ x / R : x \in X \right\}$ 과 같이 나타낸다. 설명 표현이 조금 더러워 보이지만 예시를 생각해보면 전혀 어려운 개념이 아니다.자연수집합 $\mathbb{N}$ 상에서 $3$ 으로 나눈 나머지가 같으면 동치라</description>
    </item>
    
    <item>
      <title>레벤슈타인 알고리즘</title>
      <link>https://freshrimpsushi.github.io/posts/levensteins-algorithm/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/levensteins-algorithm/</guid>
      <description>알고리즘 Input 문자열 $A,B$ 를 $A=[a_{i}]=(a_{1}, a_{2} , \cdots, a_{n})$ 과 $B=[b_{j}]=(b_{1}, b_{2} , \cdots, b_{m})$ 로 표현하자. Step 1. 초기화 행렬 $M_{(n+1) \times (m+1)} = [m_{x y }]$ 를 만들고 $M_{11} ← 0$ 을 대입한다. 그리고 $1$행과 $1$열을 다음과 같이 채운다. $$ M_{(i+1) 1} ← i \\ M_{ 1 (j+1)} ← j $$ Step 2. 동적 계획법 for $i = 1, 2, \cdots , n$ and $j=1,2, \cdots , m$ if $a_{i}==b_{j}$ $M_{i,j} ← M_{(i-1)(j-1)}$ else $M_{i,j} ← \min \left\{ M_{(i-1)(j)}, M_{(i)(j-1)}, M_{(i-1)(j-1)}\right\} + 1 $ Output $A$, $B$ 의 최소 수정 거리는 $m_{nm}$ 이다. 설명 편집 거리 란 두 문자열</description>
    </item>
    
    <item>
      <title>집합의 분할</title>
      <link>https://freshrimpsushi.github.io/posts/partition-of-set/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-of-set/</guid>
      <description>정의 1 집합 $X$ 의 모든 부분집합 $A,B,C$ 에 대해 다음의 조건을 만족하는 $\mathscr{P}$ 를 $X$ 의 분할이라 한다. (i): $$A,B \subset \mathscr{P} \land A \ne B \implies A \cap B = \emptyset$$ (ii): $$\bigcup_{C \in \mathscr{P} } C = X$$ 설명 수식으로 나타내니까 복잡해 보이지만 간단히 말하자면 그냥 전체집합을 빠짐 없이 여러 조각으로 나누는 것에 불과하다. 수식적인 정의에 매달릴 여유가 있다면 차라리 $X$ 의 분할 $\mathscr{P}$ 가 $X$ 의 멱집합 $2^{X} = \mathscr{P} (X)$ 의 부분집</description>
    </item>
    
    <item>
      <title>프로그래밍에서의 타입</title>
      <link>https://freshrimpsushi.github.io/posts/type-in-programming/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/type-in-programming/</guid>
      <description>타입의 탄생 변수를 선언할 때 타입을 지정해야하는 언어를 써본 적이 있다면 거의 확실히 띠꺼움도 함께 느껴봤을 것이다. 어떤 언어들은 굳이 타입이 뭔지 정해주지 않더라도 알아서 계산을 해주는데, 굳이 지저분하고 의미 없어 보이는 코드를 쓰는 것이 시간과 에너지의 낭비처럼 느껴지는 것이다.타입이 없던 시기의 프로그래밍 환경을 상상해보자. 컴퓨터가 이해</description>
    </item>
    
    <item>
      <title>기수 정렬</title>
      <link>https://freshrimpsushi.github.io/posts/radix-sort/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/radix-sort/</guid>
      <description>알고리즘 자리수가 $k$ 로 제한된 $n$ 개의 자연수로 이루어진 데이터가 주어져있다고 하자. 그러면 데이터는 다음의 알고리즘에 따라 정렬되며 그 시간 복잡도는 $O (n)$ 이다. $i = 1 , \cdots , k$ 번째 자리수들끼리 비교해서 정렬한다. 설명 기수 정렬Radix Sort은 자리수의 제한이 있기 때문에 부동소수점이 있는 데이터에 적용할 수는 없으나, 정렬할 때 데이터</description>
    </item>
    
    <item>
      <title>수학에서의 동치관계</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-relation/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-relation/</guid>
      <description>정의 1 반사적이면서 대칭적이면서 추이적인 이항관계를 동치관계라고 한다. 설명 동치관계를 수학적이지 않게 말한다면 &amp;lsquo;그게 그거&amp;rsquo;라는 말이다. 수학을 연구할 때 그 이유가 반드시 필요한 건 아니지만, 만약 수학을 연구하는 실용적인 이유가 반드시 있어야 한다면 그것은 &amp;lsquo;원래 어렵고 복잡한 개념을 쉽고 간단한 영</description>
    </item>
    
    <item>
      <title>수학에서의 이항관계</title>
      <link>https://freshrimpsushi.github.io/posts/binary-relation/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/binary-relation/</guid>
      <description>정의 1 두 집합 $X,Y$ 에 대해 $$ R := \left\{ (x,y): x \in X , y \in Y \right\} \subset X \times Y $$ 를 (이항) 관계라고 정의하고 다음과 같이 나타낸다. $$ (x,y) \in R \iff x R y $$ $x R y \iff y R^{-1} x$ 를 만족하는 $$ R^{-1} : \left\{ (y,x): (a,b) \in R \right\} $$ 을 $R$ 의 역관계Inverse라고 한다. 모든 $x \in X$ 에 대해 다음을 만족하는 $ R \subset X^{2}$ 를 반사적Reflexive이라 한다. $$ x R x $$ 모든 $x,y \in X$ 에 대해</description>
    </item>
    
    <item>
      <title>프로그래밍 패러다임</title>
      <link>https://freshrimpsushi.github.io/posts/programming-paradigm/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/programming-paradigm/</guid>
      <description>정의 프로그래밍 패러다임Programming Paradigm이란 주어진 문제를 해결하는 프로그램을 작성할 때의 관점 내지 방법론을 말한다. 어떠한 패러다임에 알맞는 프로그래밍 언어는 그러한 프로그래밍 패러다임을 갖는다고 말하며, 대개의 언어는 하나의 패러다임을 갖는다. 여러 패러다임을 갖는 언어를 멀티 패러다임 언어라고 한다. 언어가</description>
    </item>
    
    <item>
      <title>집합의 데카르트 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cartesian-product/</link>
      <pubDate>Mon, 04 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cartesian-product/</guid>
      <description>정의 1 임의의 두 대상 $a$, $b$ 에 대해 $(a,b)$ 를 순서쌍Ordered Pair이라 한다. 2. 임의의 두 집합 $A$, $B$ 에 대해 $a \in A$, $b \in B$ 의 순서쌍 $(a,b)$ 의 집합을 $A$, $B$ 의 데카르트 곱Cartesian Product이라 하고 다음과 같이 나타낸다. $$ A \times B := \left\{ (a,b): a \in A \land b \in B \right\} $$ 설명 데카르트 곱에서 &amp;lsquo;곱&amp;rsquo;이라는 표현을 쓰는 이유</description>
    </item>
    
    <item>
      <title>비교 정렬 알고리즘 시간 복잡도의 하한</title>
      <link>https://freshrimpsushi.github.io/posts/lower-bound-of-time-complexity-of-comparison-sort-algorithms/</link>
      <pubDate>Sun, 03 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lower-bound-of-time-complexity-of-comparison-sort-algorithms/</guid>
      <description>정리 비교 정렬 알고리즘의 시간복잡도는 아무리 좋아도 $\Omega ( n \log n )$ 이다. 설명 알고리즘이 원래 신기한 것이지만, 삽입 정렬과 같은 효율적인 알고리즘도 퀵 정렬에 밀리는 것을 보면 그 이상의 알고리즘도 있지 않을까 궁금할 수밖에 없다. 다행인지 아닌지는 모르겠으나, 이 증명에 따라 그보다 효율적인 알고리즘을 생각할 필요는 없다. 물론 일반적인 비교 알고</description>
    </item>
    
    <item>
      <title>집합족과 첨수</title>
      <link>https://freshrimpsushi.github.io/posts/family-and-index/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/family-and-index/</guid>
      <description>정의 원소가 집합인 집합을 패밀리Family라고 한다. 패밀리의 원소를 멤버Member라고 한다. 하나의 집합 $\Gamma$ 의 각 $\gamma \in \Gamma$ 에 집합 $A_{\gamma}$ 가 대응할 때 $\gamma$ 를 인덱스, $\Gamma$ 를 인덱스 집합, $\left\{ A_{\gamma} : \gamma \in \Gamma \right\}$ 를 인덱스 패밀리라고 한다. 설명 패밀리는 본디 &amp;lsquo;집합족&amp;rsquo;으로 순화하도록 되어있으나, 이러한 표현은 &amp;lsquo;집</description>
    </item>
    
    <item>
      <title>비교 정렬 알고리즘들의 시간 복잡도</title>
      <link>https://freshrimpsushi.github.io/posts/time-complexity-of-comparison-sort-algorithms/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-complexity-of-comparison-sort-algorithms/</guid>
      <description>정리 $n$ 개의 데이터가 주어져 있을 때, 비교 정렬 알고리즘들의 시간 복잡도는 다음과 같다. [1] 버블 정렬: $$ \Theta ( n^2 ) \\ O ( n^2 ) $$ [2] 선택 정렬: $$ \Theta ( n^2 ) \\ O ( n^2 ) $$ [3] 삽입 정렬: $$ \Theta ( n^2 ) \\ O ( n^2 ) $$ [4] 힙 정렬: $$ \Theta ( n \log n ) \\ O ( n \log n ) $$ [5] 합병 정렬: $$ \Theta ( n \log n ) \\ O ( n \log n ) $$ [6] 퀵 정렬: $$ \Theta ( n \log n ) \\ O ( n^2 ) $$ 설명</description>
    </item>
    
    <item>
      <title>선택 공리가 추가된 체르멜로-프렝켈 집합론</title>
      <link>https://freshrimpsushi.github.io/posts/zermelo-fraenkel-set-theory-with-the-axiom-of-choice-included/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zermelo-fraenkel-set-theory-with-the-axiom-of-choice-included/</guid>
      <description>체르멜로 공리계 [1] 외연 공리: $$ \forall A \forall B ( \forall x ( x \in A \iff x \in B) ) $$ 임의의 두 집합 $A$, $B$ 에 속한 원소가 같으면 두 집합이 같다고 하고 $A = B$ 와 같이 나타낸다. [2] 공집합 공리: $$ \exists X \forall x \left( \lnot \left( x \in X \right) \right) $$ 어떤 원소도 가지지 않는 집합 $X$ 가 존재하고, 이 집합 $X$ 를 공집합이라고 정의한다. [3] 짝 공리: $$ \forall A \forall B \exists U ( a \in A \land b \in B ) $$ 임의의 두</description>
    </item>
    
    <item>
      <title>선택적 샘플링 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-optional-sampling-theorem/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-optional-sampling-theorem/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 슈퍼 마틴게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. $\tau$ 와 $\sigma$ 가 $\sigma \le \tau$ 면서 $\mathcal{F}_{n}$ 에 대해 바운디드 정지 시간이라고하면 $$ E \left( X_{\tau} | \mathcal{F}_{\sigma} \right) \le X_{\sigma} \text{ a.s.} $$ $\tau$ 가 $\mathcal{F}_{n}$ 에 대해 바운디드라는 것은 말 그대로 모든 $E \in \mathcal{F}_{n}$ 에 대해 $\tau(E) \le N$ 를 만족하는 $N \in \mathbb{N}$ 이 존재한다는 것이다. 설명 수식 자체가 말해주는 것은 $\sigma \le \tau \le N$ 이라는 조건이 있을 때 슈퍼</description>
    </item>
    
    <item>
      <title>선택 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-choice/</link>
      <pubDate>Tue, 29 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-choice/</guid>
      <description>공리 1 $$ \forall U \left( \emptyset \notin U \implies \exists f : U \to \bigcup_{X \in U \\ f(X) \in X } U \right) $$ 모든 공집합이 아닌 집합들의 집합 $U$ 에 대해 $U$ 의 모든 원소로부터 원소 하나씩을 선택하는 선택 함수 $f$ 가 존재한다. 설명 선택 공리는 가령 다음과 같은 집합의 집합 $U$ 가 있을 때, 그 원소인 집합에서 원소 하나을 뽑는 함수 $f$ 가 존재함을 보장해준다. 가령 다음의 예를 생각해보자: $$ U = \left\{ \left\{ \pi , 1/2</description>
    </item>
    
    <item>
      <title>정지 시간의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-stopping-time/</link>
      <pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-stopping-time/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 마틴 게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 이 주어져 있다고 하자. 정지 시간 $\tau$ 에 대해 $\mathcal{F}_{\tau}:= \left\{ A \in \mathcal{F}: A \cap ( \tau = n ) \in \mathcal{F}_{n} \right\}$ 을 $\tau$ 에 의해 유도된 시그마 필드라 한다. [1]: $\mathcal{F}_{\tau}$ 는 시그마 필드다. [2]: $\tau$ 는 $\mathcal{F}_{\tau}$-가측 함수다. [3]: 마틴 게일 $\left\{ ( X_{n} , \mathcal{F}_{n} ) \right\}$ 에 대해 $X_{\tau}$ 는 $\mathcal{F}_{\tau}</description>
    </item>
    
    <item>
      <title>치환 공리꼴</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-schema-of-replacement/</link>
      <pubDate>Sun, 27 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-schema-of-replacement/</guid>
      <description>공리 $$ \forall X \left( \forall x \in X \exists ! y \left( p(x,y) \right) \implies \exists Y \forall x \in X \exists y \in Y \left( p(x,y) \right) \right) $$ 모든 함수에 대한 치역이 존재한다. 기호 $\exists !$ 는 유일하게 존재함을 의미한다. 여기서 $p(x,y)$ 는 $X \times Y$ 에서의 명제함수다. 설명 명제함수 $p(x,y)$ 는 물론 함수지만 엄밀하게 말해 아직 함수로써 정의된 것은 아니며, 설령 함수로 정의되었다고 할지라도 위 공리에서 말하는 함수 그 자체는 아니다.</description>
    </item>
    
    <item>
      <title>확률과정론에서의 정지 시간</title>
      <link>https://freshrimpsushi.github.io/posts/stopping-time/</link>
      <pubDate>Sat, 26 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stopping-time/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 필트레이션 $\left\{ \mathcal{F}_{n} \right\}$ 에 대해 $0$ 보다 크거나 같은 정수 값을 갖는 확률 변수 $\tau$ 가 모든 $n \in \mathbb{N}_{0}$ 에 대해 $(\tau = n) \in \mathcal{F}_{n}$ 을 만족하면 $\tau$ 를 정지 시간Stopping Time이라고 한다. 보렐 셋 $B \in \mathcal{B}(\mathbb{R})$ 에 대해 $(\tau \in B) = \tau^{-1} (B)$ 로써, $(\tau = n)$ 은 $\tau^{-1} ( \left\{ n \right\} )$ 과 같다. 예시 정지 시간의 직관적인 개념은 관심 있는 사건이 일어</description>
    </item>
    
    <item>
      <title>정칙성 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-regularity/</link>
      <pubDate>Fri, 25 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-regularity/</guid>
      <description>공리 $$ \forall X \left( \exists x_{0} ( x_{0} \in X ) \implies \exists y ( y \in X \land \lnot \exists x ( x \in y \land x \in X )) \right) $$ 모든 집합 $X \ne \emptyset$ 은 자기 자신과 서로소인 원소를 가진다. 설명 정칙성 공리에 따라 스스로를 원소로 포함하는 재귀 집합, 예컨대 $X = \left\{ X \right\}$ 와 같은 집합은 존재할 수 없다. 자기 자신과 서로소가 되기 위해서는 적어도 자기 자신은 아니어야하기 때문이다. 정칙성 공리는 공집합이</description>
    </item>
    
    <item>
      <title>Lp 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-lp/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-lp/</guid>
      <description>정의 1 함수의 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 어떤 함수 $f$ 에 대해 다음을 만족하면 $\left\{ f_{n} \right\}$ 이 $f$ 로 $L^{p}$ 수렴한다고 말한다. $$ \lim_{n \to \infty} \left\| f_{n} - f \right\|^{p} = 0 $$ 시퀀스 $\left\{ f_{n} \right\}_{n \in \mathbb{N}}$ 이 다음을 만족하면 $L^{p}$ 에서 코시Cauchy in $L^{p}$라 한다. $$ \lim_{n, m \to \infty} \left\| f_{n} - f_{m} \right\|_{p} = 0 $$ 설명 물론 $\left\| \cdot \right\|_{p}$ 는 $p$-놈으로써 다음과 같이 정의된다. $$ \left\| f \right\|_{p} := \left( \int_{E} | f |^{p} dm \right) ^{{{1} \over</description>
    </item>
    
    <item>
      <title>마틴게일의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-martingales/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-martingales/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. $\mathcal{F}$ 의 서브 시그마 필드의 시퀀스 $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$ 이 다음을 만족하면 필트레이션Filtration이라 부른다. $$ \forall n \in \mathbb{N}, \mathcal{F}_{n} \subset \mathcal{F}_{n+1} $$ 필트레이션 $\left\{ \mathcal{F}_{n} \right\}_{n \in \mathbb{N}}$ 이 주어져 있을 때 르벡 적분 가능한 $\mathcal{F}_{n}$-가측 확률 변수 $X_{n}$ 의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 가 이루는 순서쌍의 시퀀스 $\left\{ (X_{n}, \mathcal{F}_{n})</description>
    </item>
    
    <item>
      <title>무한 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-infinity/</link>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-infinity/</guid>
      <description>공리 $$ \exists U \left( \emptyset \in U \land \forall X ( X \in U \implies S(X) \in U) \right) $$ 공집합과 $X$ 를 원소로 가지면 $S(X)$ 도 원소로 가지는 집합 $U$ 가 존재한다. 집합 $X$ 에 대해 $S(X)$ 는 $S(X):= X \cup \left\{ X \right\}$ 와 같이 정의되는 집합이다. 설명 이것이 왜 무한 공리인지를 구구절절 설명하는 것보다 자연수 집합 $\mathbb{N}$ 의 존재성 증명을 한 번 보는 게 낫다. 정리: 자연수 집합의 존재성 $\mathbb{N}$ 이 존재한다. 증명 전략: 폰 노이만</description>
    </item>
    
    <item>
      <title>조건부 옌센 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conditional-jensens-inequality/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conditional-jensens-inequality/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G} \subset \mathcal{F}$ 가 주어져있다고 하고 $X$ 가 확률 변수라고 하자. 컨벡스 함수 $\phi : \mathbb{R} \to \mathbb{R}$ 와 $\phi (X) \in \mathcal{L}^{1} ( \Omega ) $에 대해 $$ \phi \left( E \left( X | \mathcal{G} \right) \right) \le E \left( \phi (X) | \mathcal{G} \right) $$ $\phi$ 가 컨벡스라는 것은 모든 $x,y \in \mathbb{R}$ 와 $\alpha \in [0,1]$ 에 대해 다음을 만족하는 함수라는 것이다. $$ \phi( \alpha x + (1 - \alpha ) y ) \le \alpha \phi (x) + (1 - \alpha ) \phi (y) $$ $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시</description>
    </item>
    
    <item>
      <title>멱집합 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-power-set/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-power-set/</guid>
      <description>공리 1 $$ \forall X \exists P \forall A ( A \subset X \implies A \in P) $$ 임의의 집합 $X$ 에 대해 $X$ 의 모든 부분집합을 원소로 갖는 집합 $P$ 가 존재한다. 설명 $X$ 의 멱집합은 일반적으로 $\mathcal{P} (X)$ 와 같이 표기하거나 $2^{X}$ 와 같이 쓰는데, 그 이유는 유한 집합 $X$ 의 원소의 개수를 $|X|$ 이라고 하면 $P(X)=2^{|X|}$ 이기 때문이다. 꼭 개수가 중요한 것은 아니기 때문에 집합론을 많이 쓰면 많이 쓰는 분과일수록 $2^{X}$ 와 같은 표현</description>
    </item>
    
    <item>
      <title>합집합 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-union/</link>
      <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-union/</guid>
      <description>공리 $$ \forall X \left( \exists U \left( \forall a \left( a \in x \land x \in X \implies a \in U \right) \right) \right) $$ 임의의 집합 $X$ 에 대해 $X$ 모든 원소들의 원소들을 포함하는 집합 $U$ 가 존재한다. 합집합의 정의 1 합집합 공리는 다음과 같이 정의되는 합집합의 존재성을 보장한다. $$ x \in A \lor x \in B \iff x \in A \cup B $$ 임의의 두 집합 $A$, $B$ 에 대해 적어도 둘 중 하나에 속하는 원소들의 집합을 $A$ 와 $B$ 의 합집합이라 하고</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 조건부 분산</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-variance-in-terms-of-measure-theory/</link>
      <pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-variance-in-terms-of-measure-theory/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G} \subset \mathcal{F}$ 가 주어져있다고 하고 $X$, $Y$ 가 확률 변수라고 하자. 다음과 같이 정의된 $\text{Var}$ 를 $\mathcal{G}$ 가 주어졌을 때 $X$ 의 분산이라고 한다. $$ \text{Var} ( X | \mathcal{G}) := E \left[ (X - E(X | \mathcal{G}))^2 | \mathcal{G} \right] $$ $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드라는 것은 둘 다 $\Omega$ 의 시그마 필드이되, $\mathcal{G} \subset \mathcal{F}$ 임을 의미한다. 정리 [1]: $\text{Var}( X |\mathcal{G}) = E(X^2 | \mathcal{G}) - \left[ E(X | \mathcal{G}) \right]^2$ [2]: $\text{Var}(X) = E \left( \text{Var}(X | \mathcal{G})</description>
    </item>
    
    <item>
      <title>분류 공리꼴</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-schema-of-specification/</link>
      <pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-schema-of-specification/</guid>
      <description>공리 1 $$ \forall X \exists A \forall a \left( a \in A \iff ( a \in X \land p(a)) \right) $$ 임의의 집합 $X$ 에 대해 성질 $p$ 를 가지는 원소들로 이루어진 부분집합 $A$ 가 존재한다. $p(x)$ 는 $X$ 에서의 명제함수다. 설명 $A$ 를 $X$ 의 부분집합으로 한정하는 이유는 러셀의 역설과 같은 문제가 일어나는 것을 방지하기 위함이다.공리가 아니라 공리꼴인 이유는 이 공리가 무수히 많은 $p(x)$ 에 따라 무수히 많이 존재하기</description>
    </item>
    
    <item>
      <title>조건부 기대값의 스무딩 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/smoothing-properties-of-conditional-expectation/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/smoothing-properties-of-conditional-expectation/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G}, \mathcal{G}&amp;rsquo; \subset \mathcal{F}$ 가 주어져있다고 하고 $X$, $Y$ 가 확률 변수라고 하자. [1]: $X$ 가 $\mathcal{G}$-가측이면 $$ E(XY | \mathcal{G}) = X E (Y | \mathcal{G}) \text{ a.s.} $$ [2]: $\mathcal{G}&amp;rsquo; \subset \mathcal{G}$ 이면 $$ \begin{align*} E (X | \mathcal{G}&amp;rsquo;) =&amp;amp; E \left( E ( X | \mathcal{G}) | \mathcal{G}&amp;rsquo; \right) \\ =&amp;amp; E \left( E ( X | \mathcal{G}&amp;rsquo;) | \mathcal{G} \right) \end{align*} $$ $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드라는 것은 둘 다 $\Omega$ 의 시그마 필드이되, $\mathcal{G} \subset \mathcal{F}$ 임을 의미</description>
    </item>
    
    <item>
      <title>짝 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-pair/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-pair/</guid>
      <description>공리 $$ \forall A \forall B \exists U ( a \in A \land b \in B ) $$ 임의의 두 집합 $A$, $B$ 에 대해 $A$ 와 $B$ 를 원소로 가지는 집합 $U$ 가 존재한다. 설명 처음으로 짝 공리를 접하면 (사실 대부분의 공리를 접할 때는 거의 다 비슷하지만) 도대체 이런 공리가 왜 필요한지 의문이 들 수가 있다. 그런데 사실 짝 공리란 진정으로 집합이라는 개념을 수학의 영역으로 끌어올리는 역할을 한다고 말할 수 있</description>
    </item>
    
    <item>
      <title>조건부 확률의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-conditional-probability/</link>
      <pubDate>Mon, 14 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-conditional-probability/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 와 서브 시그마 필드 $\mathcal{G} \subset \mathcal{F}$ 가 주어져있다고 하자. [1] 모든 $B \in \mathcal{G}$ 에 대해 $0 \le P(B | \mathcal{G}) \le 1$ [2] 확률의 연속성: 네스티드 시퀀스 $\left\{ B_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{G}$ 에 대해 $$ \lim_{n \to \infty} B_{n} = B \implies P ( B_{n} | \mathcal{G} ) \to P ( B | \mathcal{G} ) \text{ a.s.} $$ [3] $\left\{ B_{n} \right\}_{n \in \mathbb{N}}$ 가 $\Omega$ 의 파티션이면 $$ P \left( \bigsqcup_{n \in \mathbb{N}} B_{n} | \mathcal{G} \right)= \sum_{n \in \mathbb{N}} P \left( B_{n} | \mathcal{G} \right) $$ 사건의 시퀀스 $\left\{ B_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{G}$ 가 네스티드</description>
    </item>
    
    <item>
      <title>공집합 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-empty-set/</link>
      <pubDate>Sun, 13 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-empty-set/</guid>
      <description>공리 1 $$ \exists X \forall x \left( \lnot \left( x \in X \right) \right) $$ 어떤 원소도 가지지 않는 집합 $X$ 가 존재하고, 이 집합 $X$ 를 공집합이라고 정의한다. 설명 공집합은 일반적으로 $\emptyset$ 과 같이 표기한다. 한편 공집합은 공집합은 원소의 개수가 $0$ 개인 집합으로도 볼 수 있는데, 이와 같이 원소의 개수로 정의할 수 있는 집합에는 다음과 같은 것들이 있다: Singletone Set: 원소의 개수가 단 하나인 집합을 홑원</description>
    </item>
    
    <item>
      <title>조건부 지배 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conditional-dominated-convergence-theorem/</link>
      <pubDate>Sat, 12 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conditional-dominated-convergence-theorem/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 확률 변수의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 이 모든 $n \in \mathbb{N}$ 과 어떤 $Y \in \mathcal{L}^{1} (\Omega)$ 에 대해 $| X_{n} | \le Y$ 라고 하면 $$ X_{n} \to X \text{ a.s.} \implies E( X_{n} | \mathcal{G} ) \to \mathcal{G} ) \text{ a.s.} $$ 설명 조건부 지배 수렴 정리는 단지 DCT가 조건부 기대값에 대해서도 똑같이 적용된다는 것을 말해준다. 물론 확률론에서의 역할도 DCT와 같다. 증명 조건부 기대값의 성</description>
    </item>
    
    <item>
      <title>외연 공리</title>
      <link>https://freshrimpsushi.github.io/posts/axiom-of-extensionality/</link>
      <pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/axiom-of-extensionality/</guid>
      <description>공리 1 $$ \forall A \forall B ( \forall x ( x \in A \iff x \in B) ) $$ 임의의 두 집합 $A$, $B$ 에 속한 원소가 같으면 두 집합이 같다고 하고 $A = B$ 와 같이 나타낸다. 설명 한편 $A$ 와 $B$ 가 같지 않으면 $A \ne B$ 와 같이 나타낸다. 두 집합의 같음은 그 자체로 공리이자 정의다. Extensionality는 확장이 아니라 외연外延을 의미하는 것으로, 집합은 &amp;lsquo;어떠한 집합</description>
    </item>
    
    <item>
      <title>조건부 단조 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conditional-monotone-convergence-theorem/</link>
      <pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conditional-monotone-convergence-theorem/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 확률 변수의 시퀀스 $\left\{ X_{n} \right\}_{n \in \mathbb{N}}$ 과 $X \in \mathcal{L}^{1} (\Omega)$에 대해 $$ X_{1} \le X_{2} \le \cdots \le X \\ X_{n} \to X \text{ a.s.} $$ 이면 $$ \lim_{n \to \infty} E( X_{n} | \mathcal{G} ) = E( \lim_{n \to \infty} X_{n} | \mathcal{G} ) \text{ a.s.} $$ 설명 조건부 단조 수렴 정리는 단지 MCT가 조건부 기대값에 대해서도 똑같이 적용된다는 것을 말해준다. 물론 확률론에서의 역할도 MCT와 같다</description>
    </item>
    
    <item>
      <title>집합의 포함관계</title>
      <link>https://freshrimpsushi.github.io/posts/subset-relation-of-sets/</link>
      <pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subset-relation-of-sets/</guid>
      <description>정의 1 $$ A \subset B \iff \forall x (x\in A \implies x \in B) $$ 임의의 집합 $A$, $B$ 에 대하여 $A$ 의 모든 원소가 $B$ 의 원소일 때 $A$ 는 $B$ 의 부분집합Subset, $B$ 는 $A$ 의 초집합Superset이라 하고 $A \subset B$ 와 같이 나타낸다. 설명 한편 $A \subset B$ 인데 $B \not\subset A$ 이면 $A$ 를 $B$ 의 진부분집합Proper Subset이라고하고 $A \subsetneq B$ 와 같이 나타낸다. 사소한 주의사항으로, $A \subset B$</description>
    </item>
    
    <item>
      <title>임의의 함수의 절대값을 두 개의 음이 아닌 함수로 표현하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/way-to-represent-the-absolute-value-of-any-function-as-two-nonnegative-functions/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/way-to-represent-the-absolute-value-of-any-function-as-two-nonnegative-functions/</guid>
      <description>정리 기본 함수 $f : X \to \mathbb{R}$ 의 절대값 $|f|$ 는 $f$ 의 양의 부분 $f^{+}$ 와 음의 부분 $f^{-}$ 에 대해 다음과 같이 나타난다. $$ |f| = f^{+} + f^{-} $$ 고급 함수 $g : X \to \mathbb{R}$ 은 [[거의 어디서나]] $g \ge 0$ 이라고 하자. [1] 절대값 내부: $$ f^{+} = |f^{+}| \\ f^{-} = |f^{-}| \\ |f| = |f^{+}| + |f^{-}| $$ [2] 절대값 외부: $$ |f|^{-} = 0 \\ |f|^{+} = |f| \\ |f| = |f|^{+} + |f|^{-} $$ [3] 부호의 출입: $$ |f^{+}| + |f^{-}| = |f|^{+} + |f|^{-} \\ |g^{-}| = |g|^{-} = 0 \qquad \text{ a.e.} \\ |g^{+}| =</description>
    </item>
    
    <item>
      <title>조건부 기대값의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-conditional-expectation/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-conditional-expectation/</guid>
      <description>정리 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. [1] 측도론에서의 정리: 가측 함수 $f$, $g$ 가 $\mathcal{F}$-가측이면 $g = h (f)$ 를 만족하는 보렐 함수 $h : \mathbb{R} \to \mathbb{R}$ 가 존재한다. [2] 확률론에서의 응용: 확률 변수 $X$, $Y$ 이 $\sigma(X)$-가측이면 $E(Y | X) = h(X)$ 를 만족하는 보렐 함수 $h : \mathbb{R} \to \mathbb{R}$ 가 존재한다. [3]: $X$ 가 $\mathca</description>
    </item>
    
    <item>
      <title>명제함수의 한정규칙</title>
      <link>https://freshrimpsushi.github.io/posts/quantification-rules/</link>
      <pubDate>Sun, 06 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quantification-rules/</guid>
      <description>정의 1 전체집합 $U$ 의 명제함수 $P(x)$ 가 주어져있다고 하자. Universal Quantifier: &amp;lsquo;모든 $x \in U$ 에 대하여&amp;rsquo;를 $\forall x$ 와 같이 쓰고 전칭기호라고 한다. Existential Quantifier: &amp;lsquo;적어도 하나의 $x \in U$ 가 존재해서&amp;rsquo;를 $\exists x$ 와 같이 쓰고 존재기호라고 한다. 설명 가령 자연수 집합 $\mathbb{N}$ 에 대해 논리식 $p(x)$ 가 &amp;lsquo;$x$ 는 $3$ 의 배수다&amp;rsquo;라면, 위의</description>
    </item>
    
    <item>
      <title>동적 프로그래밍</title>
      <link>https://freshrimpsushi.github.io/posts/dynamic-programing/</link>
      <pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamic-programing/</guid>
      <description>빌드업 문제를 풀 때, 큰 문제의 해답에 그보다 작은 문제의 해답이 포함되어 있으면 최적 부분 구조Optimal Substructure를 가진다고 한다. 최적 부분 구조를 갖춘 문제의 예로써 가장 쉬운 것이 바로 피보나치 수를 구하는 것이다. $n$ 번째 피보나치 수는 $a_{n} = a_{n-1} + a_{n-2}$ 와 같이 구해지므로, 큰 문제 $a_{n}$ 에 작은 문제 $a_{n-1}$, $a_{n-2}$ 가 포함되어 있기 때문이다. 이</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 조건부 확률</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-probability-in-terms-of-measure-theory/</link>
      <pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-probability-in-terms-of-measure-theory/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드라고 할 때, 사건 $F \in \mathcal{F}$ 에 대해 $$ P(F | \mathcal{G}) := E ( \mathbb{1}_{F} | \mathcal{G}) $$ 를 $\mathcal{G}$ 에 대한 $F$ 의 조건부 확률이라고 한다. 다음과 같이 정의된 $f_{Y | X =x}$ 를 $X=x$ 일 때 $Y$ 의 조건부 밀도라고 한다. $$ f_{Y | X = x} (y | X = x) := {{\partial } \over {\partial y }} P( Y \le y | X = x) $$ 아직 측도론을 접하지 못했다면 확률 공간이라는</description>
    </item>
    
    <item>
      <title>집합과 명제함수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-set-and-propositional-function/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-set-and-propositional-function/</guid>
      <description>정의 1 Set: 우리의 직관 또는 사고의 대상으로써 서로 뚜렷이 구분되는 객체의 모임을 집합이라 한다. Element: 집합에 속한 객체를 원소라고 한다. Propositional Function: 집합 $U$ 의 원소 $x$ 에 대해 참이거나 거짓 둘 중 하나인 명제 $p(x)$ 를 $U$ 에서의 명제함수라고 한다. 설명 수학에서 집합은 거의 모국어 하나에 필적할만큼 중요한 개념이다. 어쩌면 자연어보다 나을 수도 있는 게, 필연적으로 따라</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 조건부 기대값</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-expectation-in-terms-of-measure-theory/</link>
      <pubDate>Thu, 03 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-expectation-in-terms-of-measure-theory/</guid>
      <description>정의 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. $\mathcal{G}$ 가 $\mathcal{F}$ 의 서브 시그마 필드고 확률 변수 $X \in \mathcal{L}^{1} ( \Omega )$ 는 적분 가능하다. 모든 $A \in \mathcal{G}$ 에 대해 $$ \int_{A} Y d P = \int_{A} X d P $$ 를 만족하는 $\mathcal{G}$-가측 확률 변수 $Y$ 가 유일하게 존재하면 $Y := E ( X | \mathcal{G} )$ 를 $\mathcal{G}$ 에 대한 $X$ 의 조건부 기대값이라고 정의한다. 아직 측도론을 접하지 못했다면 확률</description>
    </item>
    
    <item>
      <title>라돈-니코딤 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-radon-nikodym-theorem/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-radon-nikodym-theorem/</guid>
      <description>정리 1 가측 공간 $( \Omega , \mathcal{F} )$ 의 두 시그마 유한 측도 $\nu$, $\mu$ 가 $\nu \ll \mu$ 를 만족하면 모든 $A \in \mathcal{F}$ 에 대해 $\mu$-거의 어디서나 $h \ge 0$ 이고 $$ \nu (A) = \int_{A} h d \mu $$ 을 만족하는 $\mathcal{F}$-가측 함수 $h$ 가 주어진 $\mu$ 에 따라 유일하게 존재한다. $h$ 가 $\mu$-거의 어디서나라는 것은 거의 어디서나와 비슷하게 $\mu \left( h^{-1} ( -\infty , 0 ) \right) = 0$ 이라는</description>
    </item>
    
    <item>
      <title>라돈-니코딤 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/radon-nikodym-derivative/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/radon-nikodym-derivative/</guid>
      <description>정리 1 가측 공간 $( \Omega , \mathcal{F} )$ 가 주어져 있다고 하자.측도 $\mu$, $\nu$ 가 $\mu ( \Omega ) = 1$ 과 모든 $F \in \mathcal{F}$ 에 대해 $0 \le \nu (F) \le \mu (F)$ 를 만족하면 모든 $F \in \mathcal{F}$ 에 대해 $$ \nu(F) = \int_{F} h d \mu $$ 를 만족하면서 $h \ge 0$ 인 $\mathcal{F}$-가측 함수 $h : \Omega \to \mathbb{R}$ 가 존재한다. 이 $h$ 를 $\displaystyle h := {{d \nu } \over {d \mu }}$ 와 같이 나타내고 $\mu$ 에 대한 $\nu$ 의 라돈-니코딤 도함수라 한다. 어떤</description>
    </item>
    
    <item>
      <title>재귀함수를 쓸 때 주의해야하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-you-watch-out-when-you-using-recurrence/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-you-watch-out-when-you-using-recurrence/</guid>
      <description>주의 프로그래밍을 처음 배우면 그것이 어떤 언어든지 &amp;lsquo;재귀함수는 조심해서 써야한다&amp;rsquo;는 경고가 함께한다. 사실 재귀함수라는 게 그렇게 빈번하게 사용되는 테크닉이 아니기 때문에 그 이유는 설명하지 않는 경우가 많은데, 배우는 입장에선 이 좋은 걸 왜 꺼리는지 이해가 잘 되지 않을 수 있다. 예시를 통해 알아보자. 예시 def fibo1(n) : if n==1</description>
    </item>
    
    <item>
      <title>시그마 유한 측도</title>
      <link>https://freshrimpsushi.github.io/posts/sigma-finite-measure/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sigma-finite-measure/</guid>
      <description>정의 1 가측 공간 $( X , \mathcal{E} )$가 주어져있다고 하자. $\mu (X) &amp;lt; \infty$ 이면 $\mu$ 를 유한 측도라고 한다. $$\displaystyle X = \bigcup_{i=1}^{\infty} E_{i} \qquad , E_{i} \in \mathcal{E}$$ 라고 할 때 모든 $i \in \mathbb{N}$ 에 대해 $\mu ( E_{i} ) &amp;lt; \infty$ 면 시그마 유한 측도라고 한다. 또한 순서쌍 $(X, \mathcal{E}, \mu)$를 시그마 유한 측도 공간이라 한다. $\mu ( E ) = \infty$ 인 모든 $E \in \mathcal{E}$ 에 대해 $0 &amp;lt; \mu (F) &amp;lt; \infty$ 를 만족하는 $E$ 의 부분집합 $F \in \mathcal{E}$ 이 존재하면 $\mu$ 를</description>
    </item>
    
    <item>
      <title>삼단논법의 수리논리적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-syllogism/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-syllogism/</guid>
      <description>법칙 1 $$ ( p \to q ) \land ( q \to r ) \implies p \to r $$ 설명 삼단논법을 모르는 사람은 없고 굳이 설명해줄 것도 없다고 본다. 고대의 철학적 논쟁이 아닌 이상에야 굳이 &amp;lsquo;삼단논법에 의해&amp;rsquo;라는 말을 쓰는 경우는 흔치 않다. 그만큼 우리들에게는 익숙한 논법이자 보편타당한 원리기 때문이다. 하지만 삼단논법이 증명이 되는 것이고 증명을 해</description>
    </item>
    
    <item>
      <title>수학적 귀납법</title>
      <link>https://freshrimpsushi.github.io/posts/mathmatical-induction/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mathmatical-induction/</guid>
      <description>법칙 1 명제 $p(n) (n=1,2,3, \cdots )$ 에 대해 $p(1)$ 이 참이고 $p(n)$ 을 가정했을 때 $p(n+1)$ 이 성립하면 $p(n)$ 은 참이다. 설명 어떤 식이 자연수에 대해 성립할 때 특히 큰 위력을 발휘하는 증명법으로, 페아노 제5공리라고도 불리며 혹은 &amp;lsquo;수학적&amp;rsquo;이라는 말을 떼고 그냥 귀납법이라고도 한다. 본래 귀납법이란 현상이나 실체를 경험적으로 모아 어떤 결론을 내리는 것인</description>
    </item>
    
    <item>
      <title>귀류법의 수리논리적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-reductio-ad-absurdum/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-reductio-ad-absurdum/</guid>
      <description>법칙 1 $$ (p \land \lnot q) \to c \iff p \to q $$ $c$ 는 모순을 의미한다. 설명 배리법 혹은 귀류법은 수학 전반에서 정말 많이 사용되는 증명법이다. 하지만 처음 귀류법을 접하는 사람은 이게 단어부터 생소해서 거부감이 들 수 있다. 혹은 그냥 익숙해졌을 뿐, 왜 귀류법이 작동하는지 이해하지 못한 사람도 있을 것이다. 아래의 글을 읽어보면서 귀류법을 이해해보자: (1) 결론 $q$</description>
    </item>
    
    <item>
      <title>측도의 절대 연속</title>
      <link>https://freshrimpsushi.github.io/posts/absolutely-continuous/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/absolutely-continuous/</guid>
      <description>정의 1 가측 공간 $( \Omega , \mathcal{F} )$ 가 주어져 있다고 하자. 측도 $\nu$, $\mu$ 가 모든 $A \in \mathcal{F}$ 에 대해 $$ \mu (A) = 0 \implies \nu (A) = 0 $$ 를 만족시키면 $\nu$ 가 $\mu$ 에 대해 절대 연속이라 하고 $\nu \ll \mu$ 와 같이 나타낸다. 설명 $\nu \ll \mu$ 이라는 표기에서 단번에 알 수 있듯 $\mu$ 는 $\nu$ 를 &amp;lsquo;제압&amp;rsquo;하는 느낌이 강하다. 문제는 이걸 왜 &amp;lsquo;절대 연속&amp;lsquo;이</description>
    </item>
    
    <item>
      <title>가측 공간의 파티션과 리파인먼트</title>
      <link>https://freshrimpsushi.github.io/posts/partition-and-refinement/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partition-and-refinement/</guid>
      <description>정의 가측 공간 $( \Omega , \mathcal{F} )$ 가 주어져 있다고 하자. $( \Omega , \mathcal{F} )$ 에 대해 $\displaystyle \bigsqcup_{i=1}^{k} A_{i} = \Omega$ 를 만족하는 $$\mathcal{P} : = \left\{ A_{i} \in \mathcal{F} : i_{1} \ne i_{2} \implies A_{i_{1}} \cap A_{i_{2}} = \emptyset \right\}_{i=1}^{k}$$ 를 가측 공간 $\Omega$ 의 유한 (가측) 파티션이라 한다. 모든 $A_{i} \in \mathcal{P}$ 에 대해 $\displaystyle A_{i} = \bigsqcup_{j \in J} B_{j}$ 를 만족시키는 $B_{j} \in \mathcal{P}&amp;rsquo;$ 들이 존재하면 $\mathcal{P}&amp;rsquo;$ 를 $\mathcal{P}$ 의 리파인먼트라 한다. $\displaystyle \bigsqcup$ 은 서로소인 집합들의 합집합을 의미한다. 설명 리만 합을 정의할</description>
    </item>
    
    <item>
      <title>대우법의 수리논리적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-contrapositive-law/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-contrapositive-law/</guid>
      <description>법칙 1 $$ p \to q \iff \lnot q \to \lnot p $$ 설명 어떤 명제가 참이면 그 대우도 참, 어떤 명제가 거짓이면 그 대우도 거짓이다. 물론 역Converse이 성립한다면 대우법에 의해서 원래 명제의 이Reverse도 성립한다. 이러한 표현들은 수학에 익숙하지 않은 사람들에겐 너무 어려울 수 있다. 직관적인 예를 들어서 이해해보자: $p$ : 날씨가 덥다 $q$ : 땀이 난다 $p</description>
    </item>
    
    <item>
      <title>드 모르간의 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-de-morgans-laws/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-de-morgans-laws/</guid>
      <description>정리 1 [1] 드 모르간의 법칙: $$ \lnot (p \land q) \iff \lnot p \lor \lnot q \\ \lnot(p \lor q) \iff \lnot p \land \lnot q $$ [2] 드 모르간의 정리: $$ (A \cup B)^{c} = A^{c} \cap B^{c} \\ (A \cap B)^{c} = A^{c} \cup B^{c} $$ 설명 드 모르간의 법칙와 드 모르간의 정리는 각각 명제, 집합에 대한 정리지만 실제로 말을 하면서는 별로 구분하지 않는다. 법칙이든 정리든 드 모르간- 만 붙으면 부정이나 여집합을 취하면 괄호 안의 명제, 집합과 기호</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 조인트 분포와 마지널 분포</title>
      <link>https://freshrimpsushi.github.io/posts/joint-distribution-and-marginal-distribution-in-terms-of-measure-theory/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/joint-distribution-and-marginal-distribution-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 조인트 분포: $( \Omega , \mathcal{F} , P)$ 에서 정의된 두 확률 변수 $X$, $Y$ 가 있다고 할 때, 랜덤 벡터 $(X,Y) : \Omega \to \mathbb{R}^2$ 의 분포는 보렐 셋 $B \subset \mathcal{B} \left( \mathbb{R}^2 \right)$ 에 대해 $$ \begin{align*} P_{(X,Y)} (B) &amp;amp;:=&amp;amp; P \left( (X,Y) \in B \right) \\ =&amp;amp; \int_{B} f_{(X,Y)} (x,y) d m_{2} (x,y) \end{align*} $$ 와 같이 정의되며, 이를 만족시키는 $f_{(X,Y)}$ 가 존재한다면 $X$, $Y$ 가 조인트 밀도를 가진다고 한다. 마지널 분포: 보렐 셋 $A \subset \mathbb{R}$</description>
    </item>
    
    <item>
      <title>항진 명제와 항위 명제</title>
      <link>https://freshrimpsushi.github.io/posts/tautology-and-contradiction/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/tautology-and-contradiction/</guid>
      <description>정의 1 모든 논리적 가능성에 대해 참인 명제를 항진 명제TTautology라고 한다. 모든 논리적 가능성에 대해 거짓인 명제를 항위 명제Contradiction라고 한다. $p$, $q$ 에 대해 조건문 $p \to q$ 가 항진 명제면 함의 명제Implication라 하고 다음과 같이 나타낸다. $$ p \implies q $$ $p$, $q$ 에 대해 쌍조건문 $p \leftrightarrow q$ 가 항진 명제면 동치Equ</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 특성 함수와 적률생성함수</title>
      <link>https://freshrimpsushi.github.io/posts/characteristic-function-and-moment-generating-function-in-terms-of-measure-theory/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/characteristic-function-and-moment-generating-function-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.확률 변수 $X$ 과 $t \in \mathbb{R}$ 에 대해 다음과 같이 정의된 $\varphi_{X} (t)$ 를 $X$ 의 특성 함수라고 한다. $$ \varphi_{X} (t) := E \left( e^{i t X} \right) = \int_{\mathbb{R}} e^{it x} f_{X} (x) dx $$ 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다. 설명 확률 변수 $Z : = X + i Y$ 는 두 확률 변수 $X, Y : \Omega \to \mathbb{R}$ 에 대해 다음과 같은 성질을 갖도록 정의된다. $$ \int</description>
    </item>
    
    <item>
      <title>명제와 결합자, 진리표</title>
      <link>https://freshrimpsushi.github.io/posts/statement-connective-truth-table/</link>
      <pubDate>Sun, 22 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statement-connective-truth-table/</guid>
      <description>정의 1 참이거나 거짓이거나 둘 중 하나인 서술을 명제라고 한다. 명제는 참이거나 거짓 둘 중 하나의 진리값Truth Value을 가진다. 두 명제 $p$, $q$ 의 진리값이 같으면 $p$ 와 $q$ 가 (논리적) 동치(Logically) Equivalent라 하고, $p \equiv q$ 와 같이 나타낸다. 합성명제를 구성하는 방법으로써 다음과 같은 기호들을 결합자Conne</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 기대값</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-in-terms-of-measure-theory/</link>
      <pubDate>Sat, 21 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자.확률 변수 $X$ 에 대해서 다음과 같이 정의된 $E(X)$ 를 $X$ 의 (수리적) 기대값이라고 한다. $$ E(X) := \int_{\Omega} X d P $$ 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다. 설명 기대값의 정의는 아무리 측도론이 쓰였다지만 너무 난해하다. 무슨 뜻인지 대강은 알겠지만 한 줄 찍 써놓은 수식만으로는 이해하</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 디락 측도와 이산 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/dirac-measure-and-discrete-probability-distribution-in-terms-of-measure-theory/</link>
      <pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirac-measure-and-discrete-probability-distribution-in-terms-of-measure-theory/</guid>
      <description>개요 기초적인 확률론에서 확률 분포란 이산과 연속 둘 중 하나였고, 그 설명도 다소 직관을 동원할 수밖에 없었다. 그러나 측도론을 도입하면 수학적인 모호함 없이 깔끔하게 이산 확률 분포를 정의할 수 있다. 이산 확률 분포 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. Step 1. 확률 변수 $X$ 가 단 하나의 값을 가지는 경우 $X = a$ 인 경우만 있다고 생각할 때, 그 확률 분</description>
    </item>
    
    <item>
      <title>아이젠슈타인 소수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eisenstein-prime-theorem/</link>
      <pubDate>Thu, 19 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eisenstein-prime-theorem/</guid>
      <description>정리 아이젠슈타인 링의 이리듀서블 엘리먼트를 아이젠슈타인 소수라 한다. 아이젠슈타인 정수 $\pi \in \mathbb{Z}[ \omega ]$ 가 다음의 조건들 중 하나를 만족하면 아이젠슈타인 소수다. (i): $\pi = 1 + \omega 2$ (ii): 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 2 \pmod{3}$ 인 $\pi = p$ (iii): 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 1 \pmod{3}$ 이라고 할 때, $p = u^2 - uv+ v^2$ 를 만족시키는 $\pi = u + \omega v$ (iv): 위의 (i)~(iii) 에 해당되는 $\pi$ 에 $\mathbb{Z} [\omega ]$ 의 유닛 $\pm 1</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 밀도와 누적 분포 함수</title>
      <link>https://freshrimpsushi.github.io/posts/density-and-cumulative-distribution-function-in-terms-of-measure-theory/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/density-and-cumulative-distribution-function-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있고 $m$ 이 측도라고 하자. 측도 $P : \mathcal{F} \to \mathbb{R}$ 가 적분가능한 $f \ge 0$ 에 대해 $$ A \mapsto P(A) = \int_{A} f dm $$ 의 폼을 갖추고 있으면 $P$ 가 절대 연속Absolutely Continuous이라 한다. 특히 이러한 $f$ 를 측도 $m$ 에 대한 $P$ 의 밀도라고 부른다. 다음과 같이 정의된 $F$ 를 밀도 $f$ 에 해당하는 (누적) 분포 함수라고 한다.</description>
    </item>
    
    <item>
      <title>아이젠슈타인 링의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-of-eisenstein-ring/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-of-eisenstein-ring/</guid>
      <description>정리 아이젠슈타인 링 $\mathbb{Z}[ \omega ]$ 에 대해 함수 $N : \mathbb{Z}[\omega] \to \mathbb{Z}$ 를 생각해보자. [1]: $N(x + \omega y) := x^2 - xy + y^2$ 이라고 정의하면 $N$ 은 $\mathbb{Z}[ \omega ]$ 의 승법적 놈이 된다. [2]: $\mathbb{Z}[ \omega ]$ 은 유클리디안 도메인이다. [3]: $\mathbb{Z}[ \omega ]$ 의 유닛은 $\pm 1, \pm \omega, \pm \omega^2 $ 뿐이다. 설명 아이젠슈타인 정수는 추상대수의 도움을 받으면 훨씬 편하게 연구할 수 있다. 인티그럴 도메인에서 정의되는 놈 $N$ 으로 [2] 를 증</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수의 독립</title>
      <link>https://freshrimpsushi.github.io/posts/independence-of-random-variables-in-terms-of-measure-theory/</link>
      <pubDate>Mon, 16 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independence-of-random-variables-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 모든 보렐 셋 $B_{1} , B_{2} \in \mathcal{B} ( \mathbb{R} )$ 에 대해 다음이 성립하면 확률 변수 $X$, $Y$ 가 독립이라고 한다. $$ P \left( X^{-1} (B_{1} ) \cap Y^{-1} (B_{2} ) \right) = P \left( X^{-1} (B_{1}) \right) P \left( Y^{-1} (B_{2}) \right) $$ 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다. 사실 확률론을 공부함에 있어서 기초적인 분포이론을 지나고나면 사건의 독립이라는 것은</description>
    </item>
    
    <item>
      <title>아이젠슈타인 정수</title>
      <link>https://freshrimpsushi.github.io/posts/eisenstein-integer/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eisenstein-integer/</guid>
      <description>정의 $\mathbb{Z} [ \omega ] := \left\{ a + \omega b : a, b \in \mathbb{Z} \right\}$ 를 아이젠슈타인 링Eisenstein Ring이라 하고, 그 원소를 아이젠슈타인 인티저라 한다. 정리 [1]: $\overline{ \omega } = \omega^{2} = - (1 + \omega)$ [2]: $( a \pm \omega b ) + ( c \pm \omega d) = (a \pm c) + \omega (b \pm d)$ [3]: $( a + \omega b )( c + \omega d) = (ac - bd) + \omega (ad - bd + bc)$ 설명 $\omega$ 는 삼차방정식 $x^3 +1 = 0$ 의 복소근 $\displaystyle \omega := {{-1 + \sqrt{-3}} \over {2}} = e^{2 \pi i/3 }$ 으</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률 변수와 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution-in-terms-of-measure-theory/</link>
      <pubDate>Sat, 14 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution-in-terms-of-measure-theory/</guid>
      <description>정의 1 확률 공간 $( \Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. 모든 보렐 셋 $B \in \mathcal{B} (\mathbb{R})$ 에 대해 $X^{-1} (B) \in \mathcal{F}$ 를 만족하는 함수 $X : \Omega \to \mathbb{R}$ 을 확률변수Random Variable라고 한다. 다음과 같이 정의된 $\mathcal{F}_{X}$ 를 $X$ 에 의해 생성된 시그마 필드라고 한다. $$ \mathcal{F}_{X} := X^{-1} ( \mathcal{B} ) = \sigma (X) = \left\{ X^{-1} (B) \in \Omega : B \in \mathcal{B}( \Omega ) \right\} $$ 다음과 같이 정의된 가측함수 $P_{X}$ 를 $X$ 의 확률 분포Prob</description>
    </item>
    
    <item>
      <title>가우스 소수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gaussian-prime-theorem/</link>
      <pubDate>Fri, 13 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gaussian-prime-theorem/</guid>
      <description>정리 1 가우시안 링의 이리듀서블 엘리먼트를 가우스 소수라 한다. 가우스 정수 $\pi \in \mathbb{Z}[i]$ 가 다음의 조건들 중 하나를 만족하면 가우스 소수다. (i): $\pi = 1 + i$ (ii): 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 3 \pmod{4}$ 인 $\pi = p$ (iii): 소수 $p \in \mathbb{Z}$ 에 대해 $p \equiv 1 \pmod{4}$ 이라고 할 때, $p = u^2 + v^2$ 를 만족시키는 $\pi = u + iv$ (iv): 위의 (i)~(iii) 에 해당되는 $\pi$ 에 $\mathbb{Z}[i]$ 의 유닛 $1,-1,i,-i$ 을 곱해서 구해지는 $ i^{k} \pi$ (iv): 위의 (i)~(iii) 에 해당</description>
    </item>
    
    <item>
      <title>슈트라센 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-strassen-algorithm/</link>
      <pubDate>Thu, 12 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-strassen-algorithm/</guid>
      <description>알고리즘 $k \in \mathbb{N}$ 에 대해 $n=2^{k}$ 이라고 하자. $A, B \in \mathbb{R}^{n \times n}$ 에 대해 조던 블록 행렬 표현을 사용해 다음과 같은 8개의 ${{n} \over {2}} \times {{n} \over {2}}$ 행렬 $A_{i}$, $B_{i}$ 들을 생각해보자. $$ AB= \begin{bmatrix} A_{1} &amp;amp; A_{2} \\ A_{3} &amp;amp; A_{4} \end{bmatrix} \begin{bmatrix} B_{1} &amp;amp; B_{2} \\ B_{3} &amp;amp; B_{4} \end{bmatrix} = \begin{bmatrix} C_{1} &amp;amp; C_{2} \\ C_{3} &amp;amp; C_{4} \end{bmatrix} = C $$ $C = AB$ 를 구하기 위해 다음을 계산한다. $$ P_{1} = A_{1} ( B_{2} - B_{4} ) \\ P_{2} = ( A_{1} + A_{2} ) B_{4} \\ P_{3} = ( A_{3} + A_{4} ) B_{1} \\ P_{4} = A_{4} ( B_{3} - B_{1}</description>
    </item>
    
    <item>
      <title>시간복잡도와 공간복잡도</title>
      <link>https://freshrimpsushi.github.io/posts/time-complexity-and-space-complexity/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-complexity-and-space-complexity/</guid>
      <description>정의 주어진 문제를 풀 때의 걸리는 시간을 시간복잡도Time Complexity, 메모리 소요를 공간복잡도Space Complexity라고 한다. 예시 점근적 표기법은 이들을 표현하는데에 굉장히 유용한 수단이 된다. 시간복잡도에 대한 예시를 살펴보자. 상수 시간 $O(1)$ $n$ 에 관계없이 끝낼 수 있는 알고리즘으로, 사실상 시간이 걸리지 않는 것이다. 가령 $\mathbb{x} = [4,3,8,-1,-9,0,5,7,2,6]$ 에서 세</description>
    </item>
    
    <item>
      <title>R 에서 가치 모형으로 시계열 분석 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-garch-model-in-r/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-garch-model-in-r/</guid>
      <description>실습 가치 모델은 아치 이펙트를 설명하는 유용한 수단으로써 분석 절차 자체는 아르마 모델과 흡사하다. 위의 그래프는 내장데이터 EuStockMarkets에서 DAX만 뽑아내서 그린 것으로, 1991년부터 1999년까지 독일 DAX지수를 나타낸다. 리턴의 제곱을 보면 거의 확실하게 아치 이펙트가 있는 것으로 보인다. 리턴의 제곱이 아르마 모</description>
    </item>
    
    <item>
      <title>알고리즘의 비용에 대한 점근적 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/asymptotic-notation/</link>
      <pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/asymptotic-notation/</guid>
      <description>정의 크기가 $n$ 인 데이터에 대해 알고리즘의 비용을 다음과 같이 나타낸다. $O$ 표기법: $$ O(g(n)) := \left\{ f(n) \ | \ \exists c &amp;gt; 0, n_{0} \in \mathbb{N} : \forall n \ge n_{0} \implies f(n) \le c g(n) \right\} $$ $\Omega$ 표기법: $$ \Omega (g(n)) := \left\{ f(n) \ | \ \exists c &amp;gt; 0, n_{0} \in \mathbb{N} : \forall n \ge n_{0} \implies f(n) \ge c g(n) \right\} $$ $\Theta$ 표기법: $$ \Theta (g(n)) := O (g(n)) \cap \Omega (g(n)) $$ 설명 점근적 표기법은 알고리즘의 비용을 수리적으로 나타내는 것으로, 엡실론-델타 논법을</description>
    </item>
    
    <item>
      <title>시계열 분석에서의 가치 모형</title>
      <link>https://freshrimpsushi.github.io/posts/garch-model/</link>
      <pubDate>Sun, 08 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/garch-model/</guid>
      <description>모델 1 가치 모델은 아치 모델을 일반화한 것으로, 이분산성을 파악하기 위한 시계열 분석법이다. $$ (1 - \beta{1} B - \cdots - \beta_{p} B^p) \sigma_{t | t-1}^2 = \omega + (\alpha_{1} B + \cdots + \alpha_{q} B^q) r_{t}^{2} $$ 유도 유도는 가장 간단한 $ARCH(1)$ 모델부터 시작해보자. 2 시계열 데이터 $\left\{ p_{t} \right\}$ 의 리턴 $\left\{ r_{t} \right\}$ 이 주어져 있다고 할 때 데이터가 시차 $1$ 의 아치 이펙트, 즉 자기 회귀 조건부 이분산성을 가진다는 말은 다음과 같이</description>
    </item>
    
    <item>
      <title>맥리어드-리 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/mcleod-li-test/</link>
      <pubDate>Sat, 07 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mcleod-li-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 시계열 데이터의 리턴 $\left\{ r_{t} \right\}$ 이 주어져있다고 하자. $H_{0}$ : 데이터는 시차 $k$ 의 아치 이펙트를 가지지 않는다. $H_{1}$ : 데이터는 시차 $k$ 의 아치 이펙트를 가진다. 맥리어드-리 테스트는 주어진 리턴을 이용해 데이터에 아치 이펙트가 있는지 확인한다. 다행스럽게도 R 에서는 TSA 패키지의 McLeod.Li.test() 함수를 통해 쉽게 테스</description>
    </item>
    
    <item>
      <title>아치 이펙트</title>
      <link>https://freshrimpsushi.github.io/posts/arch-effect-autoregressive-conditional-heteroscedasticity-effect/</link>
      <pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arch-effect-autoregressive-conditional-heteroscedasticity-effect/</guid>
      <description>정의 1 아치 이펙트란 그 AutoRegressive Conditional Heteroscedasticity라는 말 그대로 &amp;lsquo;자기회귀 조건부 이분산 효과&amp;rsquo;로 순화되기 때문에 순화하지 않는다. 설명 쉽게 말해서 데이터의 변동성이 변하면서, 그 자체가 이전의 데이터로 설명될 수 있는 경우 데이터에 아치 이펙트가 있다고 말한다. 이러한 아치 이펙트를 통계적으로 설명</description>
    </item>
    
    <item>
      <title>가우시안 링의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-of-gaussian-ring/</link>
      <pubDate>Thu, 05 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-of-gaussian-ring/</guid>
      <description>정리 1 가우시안 링 $\mathbb{Z}[i]$ 에 대해 함수 $N : \mathbb{Z}[i] \to \mathbb{Z}$ 를 생각해보자. [1]: $N(x + iy) := x^2 + y^2$ 이라고 정의하면 $N$ 은 $\mathbb{Z}[i]$ 의 승법적 놈이 된다. [2]: $\mathbb{Z}[i]$ 은 유클리디안 도메인이다. [3]: $\mathbb{Z}[i]$ 의 유닛은 $1,-1,i,-i$ 뿐이다. 설명 가우스 정수는 추상대수의 도움을 받으면 훨씬 편하게 연구할 수 있다. 인티그럴 도메인에서 정의되는 놈 $N$ 으로 [2] 를 증명하면 ED가 UFD 이므로 가우스 소수로 확장된 산술</description>
    </item>
    
    <item>
      <title>시계열분석에서의 이분산성과 변동성 군집현상</title>
      <link>https://freshrimpsushi.github.io/posts/heteroscedasticity-and-volatility-clustering/</link>
      <pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heteroscedasticity-and-volatility-clustering/</guid>
      <description>정의 1 시계열 데이터 $\left\{ p_{t} \right\}$ 가 주어져 있다고 하자. $\left\{ p_{t} \right\}$ 의 분산이 $t$ 에 종속되어있을 때, $\left\{ p_{t} \right\}$ 는 이분산성Heteroscedasticity을 가진다고 한다. 이분산성을 가지는 $\left\{ p_{t} \right\}$ 의 분산이 커졌다 작아졌다를 반복하는 현상을 변동성 군집현상Volatility Clustering이라고 한다. 다음과 같이 정의된 $r_{t}$ 를 $t$ 에서의</description>
    </item>
    
    <item>
      <title>R 에서 데이터 파일 빠르게 읽기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-data-file-fast-in-r/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-data-file-fast-in-r/</guid>
      <description>개요 R 은 기본적으로 csv 데이터를 읽는 함수로써 read.csv()를 제공하지만, 그냥 간편하게 쓰는 정도가 아니라 실전적인 분석을 하고 있다면 성능이 너무 떨어져서 써먹을 것이 못 된다. 그 대안으로써, readr 패키지에서 제공하는 read\_csv()를 사용할 것을 강력하게 권장한다. read\_csv()는 c++로 작성되었으며, 매우 빠</description>
    </item>
    
    <item>
      <title>가우스 정수</title>
      <link>https://freshrimpsushi.github.io/posts/gaussian-integer/</link>
      <pubDate>Sat, 31 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gaussian-integer/</guid>
      <description>정의 1 $\mathbb{Z} [i] := \left\{ a + i b : a, b \in \mathbb{Z} \right\}$ 를 가우시안 링Gaussian Ring이라 하고, 그 원소를 가우시안 인티저라 한다. 정리 [1]: $\overline{i} = i^{3}$ [2]: $( a \pm ib ) + ( c \pm id) = (a \pm c) + i (b \pm d)$ [3]: $( a + ib )( c + id) = (ac - bd) + i (ad + bc)$ 설명 $i$ 는 이차방정식 $x^2 +1 = 0$ 의 복소근으로써, $\mathbb{Z} [i]$ 은 인티저 링 $\mathbb{Z}$ 의 심플 익스텐젼이 된다. 마치 실수체 $\mathbb{R}$ 이 복소수체</description>
    </item>
    
    <item>
      <title>R 에서 병렬처리하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-r/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-parallel-processing-in-r/</guid>
      <description>개요 R 이 속도 때문에 쓰는 언어는 아니지만, 빠른 속도가 필요할 때도 분명히 있을 것이다. 코드를 깔끔하게 잘 짜더라도 너무 오래 걸린다면 보통 병렬처리나 GPU를 동원하게 된다. 언뜻 생각했을 때 R 에서 병렬처리를 할 일이 뭐 있나 싶겠지만, 빅데이터를 다루게 되거나 규모가 큰 시뮬레이션을 하게 된다면 병렬처리가 특히 유용한 수단이 된다. 오히려 R 이야</description>
    </item>
    
    <item>
      <title>동적 회귀 모형</title>
      <link>https://freshrimpsushi.github.io/posts/dynamic-regression-model/</link>
      <pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamic-regression-model/</guid>
      <description>모델 동적 회귀 모형이란 쉽게 말해 아리마 모형에 회귀 모형을 합친 모형이다. 설명 아리마 외의 독립변수 $X$ 를 추가한다는 의미에서 아리맥스 $ARIMAX$ 라 부르기도 한다. 프로그래밍으로 구현된 경우, 특히 아래의 실습에서 설명하듯 R에서는 xreg와 같이 $X$ 가 강조된다. 사실 이쯤되면 말보다는 수식이 편한데, 종속변수로 분석할 시계열 데이터가 $\left\{ y_{t} \right\}$ 이라고 하</description>
    </item>
    
    <item>
      <title>시계열분석의 이노베이티브 아웃라이어</title>
      <link>https://freshrimpsushi.github.io/posts/innovative-outlier/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/innovative-outlier/</guid>
      <description>빌드업 위의 그래프에서 2001년 9월에 굉장히 큰 아웃라이어를 찾을 수 있다. 그러나 애디티브 아웃라이어와 달리 그 후에도 계속해서 영향을 미치고 있다. 여객기의 이용자 수는 계절성을 가지고 꾸준히 증가하고 있었는데, 911테러의 공포가 이용자 수 자체를 팍 줄여버린 것으로 해석할 수 있다. 정의 1 이렇게 분석의 판도 자체를 바꾸는 아웃라이어를 이노</description>
    </item>
    
    <item>
      <title>인티그럴 도메인의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-in-integral-domain/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-in-integral-domain/</guid>
      <description>정의 1 인티그럴 도메인 $D$ 와 모든 $\alpha , \beta \in D$ 에 대해 다음의 조건을 만족하는 함수 $N : D \to \mathbb{Z}$ 를 승법적 놈Multiplicative Norm이라 정의한다. (i): $N (\alpha) = 0 \iff \alpha = 0$ (ii): $N ( \alpha \beta ) = N ( \alpha ) N ( \beta )$ 정리 $p \in \mathbb{Z}$ 가 소수라고 하자. [1]: $D$ 에서 승법적 놈 $N$ 이 정의되면 $N(1) = 1$ 이고 모든 유닛 $u \in D$ 에 대해 $| N ( u ) | = 1$ [2]: $| N ( \alpha )| =1$</description>
    </item>
    
    <item>
      <title>시계열분석의 애디티브 아웃라이어</title>
      <link>https://freshrimpsushi.github.io/posts/additive-outlier/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/additive-outlier/</guid>
      <description>빌드업 위의 그래프에서 가장 먼저 눈에 띄는 지점은 바로 2015년 2월 근처에 있는 엄청난 아웃라이어다. 이렇듯 극심하게 다른 값을 가지면 분석에 악영향이 있을 수밖에 없다. 다행스러운 건 아주 잠깐, 말 그대로 한 순간의 아웃라이어로 그쳤다는 것이다. 정의 1 이렇듯 데이터의 등락 자체를 바꾸지는 않는 아웃라이어를 애디티브 아웃라이어Additiv</description>
    </item>
    
    <item>
      <title>스텝 함수와 펄스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/step-function-and-pulse-function/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/step-function-and-pulse-function/</guid>
      <description>정의 1 다음과 같이 정의된 $S_{t}^{(T)}$ 를 스텝 함수라 한다. $$ S_{t}^{(T)} := \begin{cases} 1 &amp;amp; , t \le T \\ 0 &amp;amp; , \text{otherwise} \end{cases} $$ 다음과 같이 정의된 $P_{t}^{(T)}$ 를 펄스 함수라 한다. $$ \begin{align*} P_{t}^{(T)} &amp;amp;:=&amp;amp; \nabla S_{t}^{(T)} \\ =&amp;amp; S_{t}^{(T)} - S_{t-1}^{(T)} \end{align*} $$ 설명 스텝 함수와 펄스 함수는 개입 분석에 쓰이는 수식을 나타내기에 유용한 함수들로써, 그 자체의 성질은 크게 의미가 없다. 스텝 함수는 말 그대로 그래프의 개형이 계단처럼 생겨서 붙인 것이고,</description>
    </item>
    
    <item>
      <title>R 에서 코드 실행 시간 재는 법, 벤치마크하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-benchmark-in-r/</link>
      <pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-benchmark-in-r/</guid>
      <description>개요 매트랩R 은 분명 통계 분석에 특화되어 있는 프로그래밍 언어지만, 모든 언어가 그러하듯 속도에 관심이 없는 것은 아니다. 속도가 강점이 아니라고 해도 벤치마킹은 할 수 있어야한다. R 에서는 간단하게도 코드 전문을 system.time({})에 넣어서 시간을 잴 수 있다. 예시 다음은 에라토스테네스의 체를 R 로 구현하고 $2*10^{5}$ 이하의 홀수를 30개</description>
    </item>
    
    <item>
      <title>개입 분석</title>
      <link>https://freshrimpsushi.github.io/posts/intervention-analysis/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/intervention-analysis/</guid>
      <description>빌드업 위 그래프는 실제 2015년 서울의 미세먼지 농도를 나타낸 시계열 데이터다. 누가 보더라도 가장 먼저 눈에 띄는 것은 50번째쯤, 그러니까 2월 말에 미세먼지 농도가 500을 넘긴 날이 있다는 점일 것이다. 데이터를 다루는데에 어느정도 익숙한 사람이라면 가장 먼저 잘못 관측된 것이 아닐까 의심하겠지만, 놀랍게도 실제로 일어난 일이었다. 아예 이</description>
    </item>
    
    <item>
      <title>R 에서 ts 함수의 start, end 옵션과 window 함수에서 start, end 옵션의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/1242/</link>
      <pubDate>Tue, 20 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1242/</guid>
      <description>설명 R 로 시계열 데이터를 다루다보면 ts() 함수와 window() 함수를 자주 사용하게 된다. ts()는 R 이 받아들일 수 있도록 시계열 데이터를 만들 때 쓰고, window()는 시계열 데이터의 일부를 추출하는데 쓰인다. 두 함수 모두 start, end를 옵션으로 갖는데, 그 차이는 다음과 같다. ts() 내가 인덱스를 주기 위한 옵션이다. start: 시계열 데이터로 만들어질 데이터의 첫</description>
    </item>
    
    <item>
      <title>시계열회귀분석에서의 허위 상관관계</title>
      <link>https://freshrimpsushi.github.io/posts/spurious-correlation/</link>
      <pubDate>Mon, 19 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spurious-correlation/</guid>
      <description>정의 1 허위 상관관계는 두 데이터가 그럴싸한 상관관계를 가지는 것 같아 보이지만 실제로는 그렇지 않은 관계를 말한다. 실습 1 다음의 예시를 통해 알아보자. 위와 같이 두 가지 시계열 데이터가 주어져 있다고 하자. 언뜻 보기에 두 시계열은 강력한 상관관계를 가질 것만 같이 보인다. 시간에 따라 조금씩 증가하는 트렌드을 포함해서 계절성을 포함한 등락 패턴이 매</description>
    </item>
    
    <item>
      <title>R 에서 색 테두리 있는 점 찍는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-colorize-scatter-plot/</link>
      <pubDate>Sun, 18 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-colorize-scatter-plot/</guid>
      <description>코드 점 도표에서 테두리의 색을 바꾸거나 내부를 칠하기 위해서는 다음의 옵션들을 바꿔주면 된다: pch: 심볼을 바꿔서 색을 칠한다. 21번부터 25번까지를 사용하면 된다. bg: 백그라운드 컬러로써, 내부에 칠해지는 색을 결정한다. 위 그림에선 연두색이다. col: 심볼 그 자체의 컬러로써, 실제로는 테두리에 해당한다. 위 그림에선 빨간색이다. set.seed(150421) win.graph(4,4) plot(rnorm(10), pch=21, bg=&amp;#39;green&amp;#39;, col=&amp;#39;red&amp;#39;)</description>
    </item>
    
    <item>
      <title>사전백화</title>
      <link>https://freshrimpsushi.github.io/posts/prewhitening/</link>
      <pubDate>Sat, 17 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prewhitening/</guid>
      <description>정의 사전백화Prewhitening란 CCF를 계산할 때 시계열을 백색잡음으로 만들어 두 데이터 간의 상관관계를 더욱 정확하게 파악하는 방법이다. 실습 1 가능하다면 이것이 어떻게 가능한지 수식적으로도 완전히 이해하는 것을 추천하는데, 우선은 예로써 다음의 데이터를 살펴보자. bluebird는 뉴질랜드에서 감자칩을 제조하는 회사인 블</description>
    </item>
    
    <item>
      <title>R 에서 파이프 오퍼레이터 %&gt;% 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/in-r/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/in-r/</guid>
      <description>개요 R 에서 %&amp;gt;%은 파이프 연산자Pipe Operater 로써, 다른 연산자가 모두 그러하듯 이항연산을 한다. 파이프 연산자는 이름 그대로 어떤 값들이 파이프를 통과하는 것처럼 함수와 함수들을 타고다닐 수 있게 해준다. 백마디 말보다 다음의 예시가 더 도움이 될 것이다. 예시 위의 예시는 $1$ 부터 $10$ 까지의 제곱근을 구하고 거기에 로그를 취한 뒤 그 중에서 중위수</description>
    </item>
    
    <item>
      <title>디리클레 경계 조건이 주어진 열방정식에 대한 초기값 문제의 수치해석적 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/numerical-solution-for-heat-equation-with-dirichlet-boundary-condition/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/numerical-solution-for-heat-equation-with-dirichlet-boundary-condition/</guid>
      <description>예제 1 $$ \begin{cases} u_{t} = \gamma u_{xx} \\ u(t,0) = u(t,l) = 0 \\ u(0,x) = f(x) \end{cases} $$ 주어진 문제는 대수적 풀이가 있을 정도로 쉽고 간단하지만, 미분방정식을 푸는 방법으로써의 수치해석을 왜 배우는지 명쾌하게 알려주는 예시가 되기도 한다. 단순히 $y&amp;rsquo; = f(x,y)$ 꼴의 미분방정식을 푸는 게 편미분방정식의 풀이로도 이어지는 것이다. 풀이 대수적 풀이에서와 달리 $\gamma$ 의 값이 중요한 것은 아니므로 편의</description>
    </item>
    
    <item>
      <title>룽게-쿠타 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/runge-kutta-method/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/runge-kutta-method/</guid>
      <description>메소드 1 $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} = Y_{0}$ 에 대해 $$ y_{n+1} = y_{n-1} + h \sum_{j=1}^{p} \gamma_{j} V_{j} $$ 설명 룽게-쿠타 메소드는 아담스 메소드처럼 여러가지 형태를 가지며</description>
    </item>
    
    <item>
      <title>A-스테이블</title>
      <link>https://freshrimpsushi.github.io/posts/a-stable/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/a-stable/</guid>
      <description>빌드업 미드포인트 메소드를 비롯한 멀티스텝 메소드는 $h$ 가 충분히 작지 않을 때 패러사이틱 솔루션이 있을 수 있다. 충분히 작지 않다는 건 $ y&amp;rsquo; = \lambda y$ 와 같은 문제가 있을 때 $| 1 + h \lambda| &amp;lt;1$ 과 같은 조건을 만족하지 못하는 등의 경우를 말한다. $z : = h \lambda \in \mathbb{C}$ 라고 할 때 위의 조건을 복소평면 상에 나타내보면 아래의 그림과 같다. $z$ 이 이 영역에 속하지 못하면 메소드</description>
    </item>
    
    <item>
      <title>교차상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/ccf-cross-correlation-functon/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ccf-cross-correlation-functon/</guid>
      <description>정의 1 $\left\{ X_{t} \right\}_{t=1}^{n}$, $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이라고 하자. 다음과 같이 정의된 $\rho_{k}$ 를 시차 $k$ 의 교차상관함수라고 한다. $$ \rho_{k} (X,Y) := \text{cor} \left( X_{t} , Y_{t-k} \right) = \text{cor} \left( X_{t+k} , Y_{t} \right) $$ 다음과 같이 정의된 $r_{k}$ 를 시차 $k$ 의 표본교차상관함수라고 한다. $$ r_{k} := {{ \sum \left( X_{t} - \overline{X} \right) \left( Y_{t-k} - \overline{Y} \right) } \over { \sqrt{ \sum \left( X_{t} - \overline{X} \right)^2 } \sqrt{ \left( Y_{t-k} - \overline{Y} \right)^2 } }} $$ 설명 교차상관함수는 두 시계열 데이터 간의 상관관계를 파악</description>
    </item>
    
    <item>
      <title>R 에서 오퍼레이터 %% 정의하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-define-binary-operator-in-r/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-define-binary-operator-in-r/</guid>
      <description>개요 R 에서는 함수를 정의할 때 아예 이항연산자로 정의할 수가 있다. 이미 R 에서 기본적으로 정의된 나눗셈의 나머지 %%, 몫 %/%, 내적 %*%, %o%나 포함관계 %in%, 그리고 파이프 연산자 %&amp;gt;% 등도 이러한 이항연산자에 속한다. 코드 가령 파이썬과 같은 언어에서는 문자열끼리 덧셈을 하면 문자열이 연결되기 때문에 아주 편한데, R 은 이에 비해서는 다소 불편한 감이 있다. 이</description>
    </item>
    
    <item>
      <title>일관성을 가지는 멀티스텝 메소드의 수렴성과 루트 컨디션</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-and-root-condition-of-multi-step-method-with-consistency/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-and-root-condition-of-multi-step-method-with-consistency/</guid>
      <description>정리 만약 멀티스텝 메소드가 일관성을 가진다고 하면, 메소드는 수렴성을 가진다 $\iff$ 메소드는 루트 컨디션을 만족 시킨다 설명 폐구간 $[x_{0} , b]$ 에 대해 $h$ 를 단위로 잘라서 노드 포인트를 만들 때, $x_{0} \le x_{1} \le \cdots \le x_{N(h) -1} \le x_{N(h) } \le b$ 라고 하자. 여기서 $N(h)$ 는 $h$ 에 따라 변하는 마지막 노드 포인트의 인덱스를 나타낸다. 메소드가 수렴성을 가진다는 것은 $h \to 0$ 일 때 $\displaystyle \eta (h) :</description>
    </item>
    
    <item>
      <title>시계열 회귀 분석</title>
      <link>https://freshrimpsushi.github.io/posts/time-series-regression-analysis/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-series-regression-analysis/</guid>
      <description>정의 시계열 회귀 분석이란 말 그대로 시계열 데이터로 회귀분석하는 기법을 말한다. 원래 회귀분석 자체가 시계열 데이터를 다루는데 있어서 적합하지 않은 것은 사실이지만, 그럼에도 불구하고 복수의 시계열 데이터를 다룰 때는 회귀분석의 아이디어와 툴을 빌리는 것이 좋을 때가 있다. 실습 가령 위와 같이 두 종류의 데이터 x와 y가 주어져있다고 하자. 물론 두 데</description>
    </item>
    
    <item>
      <title>륭-박스 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/ljung-box-test/</link>
      <pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ljung-box-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 R 에서 륭-박스 테스트 하는 법 시계열 분석으로 얻은 아르마 모형 $ARMA(p,q)$ 을 $M$ 이라고 하자. $H_{0}$ : $M$ 은 적합하다. $H_{1}$ : $M$ 은 적합하지 않다. 륭-박스 테스트는 LBQ 라고도 줄여부르기도 하며, 아리마 모형의 적합성을 판별하는 검정이다.1970년 박스Box와 피어스Pierce는 아리마 모형으로 얻은 잔</description>
    </item>
    
    <item>
      <title>아리마 모형에 대한 잔차분석</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-tsdiag-plots-in-r/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-tsdiag-plots-in-r/</guid>
      <description>설명 회귀분석과 마찬가지로 시계열 분석 역시 잔차분석을 한다. 아리마 모형의 가정에 따르면 잔차는 모두 백색잡음이므로 선형성, 등분산성, 독립성, 정규성을 따르는지 확인은 할 것이다. 회귀분석과 비교하자면 전반적으로 그렇게까지 엄격하지는 않으나, 독립성 하나만큼은 철저하게 체크한다. 애초에 시계열분석 자체가 자기상관성을 파악하기 위한 것</description>
    </item>
    
    <item>
      <title>더빈-왓슨 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/durbin-watson-test/</link>
      <pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/durbin-watson-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 개요 회귀분석을 한 이후의 잔차 $\left\{ e_{t} \right\}_{t=1}^{n}$ 가 주어져있다고 하고 $e_{t} := \rho e_{t-1} + \nu_{t}$ 이라 하자. $H_{0}$ : $\rho = 0$ 즉, 잔차끼리 자기상관성을 가지지 않는다. $H_{1}$ : $\rho \ne 0$ 즉, 잔차끼리 자기상관성을 가진다. 더빈-왓슨 테스트는 회귀분석 후 잔차의 독립성을 확인할 때 쓰이는 테스트로써, 잔차끼리 자기상관성이 있는</description>
    </item>
    
    <item>
      <title>R 에서 EACF를 사용한 ARMA 모형 선택법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-determine-arma-model-using-eacf-in-r/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-determine-arma-model-using-eacf-in-r/</guid>
      <description>실습 1 PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다. 직접 그 예를 살펴보자. ma1.2.s 데이터는 $MA(1)$ 모델에서, ar1.s 데이터는 $AR(1)$ 모델에서 나온 TSA 패키지의 샘플 데이터다. TSA 패키지의 acf() 함수와 pacf() 함수를 사용하면 다음과 같이 여러 시차 $k$ 에 대해 코릴로그램Correlogram을 그려준다. 그림만 봤을 때 파란 선을 넘어가는</description>
    </item>
    
    <item>
      <title>일관성을 가지는 멀티스텝 메소드의 안정성과 루트 컨디션</title>
      <link>https://freshrimpsushi.github.io/posts/stability-and-root-condition-of-multi-step-method-with-consistency/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stability-and-root-condition-of-multi-step-method-with-consistency/</guid>
      <description>정리 만약 멀티스텝 메소드가 일관성을 가진다고 하면, 메소드는 안정성을 가진다 $\iff$ 메소드는 루트 컨디션을 만족 시킨다 설명 폐구간 $[x_{0} , b]$ 에 대해 $h$ 를 단위로 잘라서 노드 포인트를 만들 때, $x_{0} \le x_{1} \le \cdots \le x_{N(h) -1} \le x_{N(h) } \le b$ 라고 하자. 여기서 $N(h)$ 는 $h$ 에 따라 변하는 마지막 노드 포인트의 인덱스를 나타낸다. 원래 주어진 초기값 $y_{0} , \cdots , y_{p}$ 에 대해 아주 조금 변화를</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드의 루트 컨디션</title>
      <link>https://freshrimpsushi.github.io/posts/root-conditions-of-multistep-method/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/root-conditions-of-multistep-method/</guid>
      <description>정의 1 멀티스텝 메소드: $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) ) = (Y_{0}, \cdots , Y_{p} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값과 $0 \le p \le m$ 에 대해 $a_{p} \ne 0$ 혹은 $b_{p} \ne 0$ 이면 다음을 $(p+1)</description>
    </item>
    
    <item>
      <title>확장자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/eacf-extended-autocorrelation-function/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eacf-extended-autocorrelation-function/</guid>
      <description>빌드업 PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다. 하지만 $ARMA(p,q)$ 모형에 적용시킬 땐 아르마 모형의 가역성 때문에 $AR(p)$ 라도 $MA(\infty)$ 처럼 보일 수 있고, $MA(q)$ 라도 $AR(\infty)$ 처럼 보일 수 있다. 따라서 이러한 문제를 회피하고 아르마 모형을 찾기위한 여러가지 방법이 고안되었다. 정의 확장자기상관함수는 그 중의 한 방법으로, 다음과 같이 정의</description>
    </item>
    
    <item>
      <title>아담스 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/adams-method/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adams-method/</guid>
      <description>정의 1 멀티스텝 메소드: $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) ) = (Y_{0}, \cdots , Y_{p} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값과 $0 \le p \le m$ 에 대해 $a_{p} \ne 0$ 혹은 $b_{p} \ne 0$ 이면 다음을 $(p+1)</description>
    </item>
    
    <item>
      <title>편자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/pacf-partial-autocorrelation-function/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pacf-partial-autocorrelation-function/</guid>
      <description>정의 1 $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이고 시차 $k$ 에 대해서 $Y_{t-1}, \cdots , Y_{t-(k-1)}$ 로 $Y_{t}$ 를 회귀분석한 잔차를 $\widehat{e_{t}}$, $Y_{t-k}$ 를 회귀분석한 잔차를 $\widehat{e_{t-k}}$ 이라고 하자. 다음과 같이 정의된 $\phi_{kk}$ 를 시차 $k$ 의 편자기공분산함수라고 한다. $$ \phi_{kk} := \text{cor} ( \widehat{e_{t}} , \widehat{e_{t-k}} ) $$ 다음과 같이 정의된 $\phi_{kk}$ 를 시차 $k$ 의 표본편자기공분산함수라고 한다. $$ \widehat{ \phi_{kk} } := {{ r_{k} - \sum_{j=1}^{k-1} \phi_{(k-1),j} r_{k-j} } \over { 1 - \sum_{j=1}^{k-1} \phi_{(k-1),j} r_{j} }} \\ \phi_{k,j} := \phi_{(k-1),j} - \phi_{kk} \phi_{(k-1),(k-j)} $$ $r_{k}$ 는 시</description>
    </item>
    
    <item>
      <title>거리공간에서 위상동형이란</title>
      <link>https://freshrimpsushi.github.io/posts/homeomorphism/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homeomorphism/</guid>
      <description>정의 두 거리공간 $\left( X, d_{1} \right)$ 과 $\left( Y, d_{2} \right)$ 에 대해 전단사 $f : X \to Y$ 가 존재해서 $f$ 와 그 역함수 $f^{-1}$ 모두 연속함수면 $f$ 를 위상동형사상이라 부르고 두 거리공간이 위상동형Homeomorphic이라 한다. 설명 거리공간에 대한 위상동형의 정의는 언뜻 공허해보인다. 물론 그도 그럴게, 거리공간 자체가 충분히 좋은 공간인데다가 두 거리공간이 위상동형임을</description>
    </item>
    
    <item>
      <title>리차드슨 오차 추정</title>
      <link>https://freshrimpsushi.github.io/posts/richardson-error-estimation/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/richardson-error-estimation/</guid>
      <description>빌드업 미분방정식을 푸는 메소드의 퍼포먼스를 확인하는 방법으로 참값과 비교할 수 있다면 가장 좋겠지만, 당장 참값을 구하기 귀찮은 경우부터 시작해서 아예 트루 솔루션을 구하기 곤란한 경우도 많다. 이땐 $y_{h} (x_{n} )$ 과 스탭사이즈 $h$ 를 두배로 늘렸을 때의 $y_{2h} (x_{n} )$ 을 비교함으로써 오차를 추정할 수 있다. 예를 들어 사다리꼴 메소드라면 $h$ 를 고침으로써 아래의 두 식</description>
    </item>
    
    <item>
      <title>실수 공간에서 정의된 함수의 미분</title>
      <link>https://freshrimpsushi.github.io/posts/differential-in-real-space/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/differential-in-real-space/</guid>
      <description>정의1 $a$ 를 포함하는 어떤 $E$ 에서 $f$ 가 정의되어있고 극한 $$ f &#39; (a) := \lim_{h \to 0} {{ f (a + h ) - f(a) } \over { h }}=\lim \limits_{x\rightarrow a}\frac{f(x)-f(a)}{x-a} $$ 이 존재하면 $f$ 가 $a$ 에서 미분가능differentiable하다고 하고, $f &#39; (a)$ 를 $a$ 에서 $f$ 의 미분계수라 한다. $f &#39;$를 $f$ 의 도함수derivative라 부른다. 설명 해석학을 공부함에 있어 가장 반가운 것이 바로 미분이다. 왜</description>
    </item>
    
    <item>
      <title>사다리꼴 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/trapezoidal-method/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trapezoidal-method/</guid>
      <description>정의 1 $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} = Y_{0}$ 에 대해 $$ y_{n+1} = y_{n-1} + {{h} \over {2}} [ f ( x_{n} , y_{n} ) + f ( x_{n+1} , y_{n+1} ) ] $$ 설명 예측자-수정자 알고리즘 오일러</description>
    </item>
    
    <item>
      <title>자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/acf-autocorrelation-function/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/acf-autocorrelation-function/</guid>
      <description>정의 1 $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이라고 하자. $\mu_{t} := E ( Y_{t} )$ 를 평균함수라고 한다. 다음과 같이 정의된 $\gamma_{ t , s }$ 를 자기공분산함수라고 한다. $$ \gamma_{t , s} : = \text{cov} ( Y_{t} , Y_{s} ) = E ( Y_{t} - \mu_{t} ) E ( Y_{s} - \mu_{s} ) $$ 다음과 같이 정의된 $\rho_{ t , s }$ 를 자기상관함수라고 한다. $$ \rho_{ t , s } := \text{cor} ( Y_{t} , Y_{s} ) = {{ \gamma_{t , s} } \over { \sqrt{ \gamma_{t , t} \gamma_{s , s} } }} $$ 다음과 같이 정의된 $\rho_{</description>
    </item>
    
    <item>
      <title>함수의 균등연속</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-continuous/</link>
      <pubDate>Sat, 03 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-continuous/</guid>
      <description>정의1 공집합이 아닌 $E \subset \mathbb{R}$ 에 대해 $f : E \to \mathbb{R}$ 이라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ | x_{1} - x_{2} | &amp;lt; \delta \land x_{1} , x_{2} \in E \implies | f(x_{1}) - f(x_{2}) | &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $f$ 가 $E$ 상에서 균등연속uniformly continuous이라 한다. $\land$ 는 논리적으로 &amp;lsquo;그리고&amp;rsquo;를 나타내는 논리곱 기호다. 설명 함수의 연속성 그 자체는</description>
    </item>
    
    <item>
      <title>아르마 모형의 가역성</title>
      <link>https://freshrimpsushi.github.io/posts/invertivility-of-arma-model/</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/invertivility-of-arma-model/</guid>
      <description>정의 1 아르마 모형에 있어서 가역성을 가졌다 함은 $AR(p)$ 와 $MA(q)$ 가 서로를 표현할 수 있음을 말한다. 예시 일반적인 $ARMA ( p , q)$ 에 대한 수식전개는 아니지만, $AR(1)$ 과 $MA(1)$ 의 예를 살펴보자. 자기회귀모형 $AR(1) \implies MA( \infty )$ $| \phi | &amp;lt; 1$ 에 대해서 다음의 자기회귀모형 $AR(1)$ 을 생각해보자. $$ Y_{t} = \phi Y_{t-1} + e_{t} $$ $Y_{t-1}$ 역시 $Y_{t-1} = \phi Y_{t-2} + e_{t-1}$ 와 같이 나타낼 수 있으므로 $$ \begin{align*} Y_{t} =&amp;amp; \phi ( \phi Y_{t-2} + e_{t-1} )</description>
    </item>
    
    <item>
      <title>패러사이틱 솔루션</title>
      <link>https://freshrimpsushi.github.io/posts/parasitic-solution/</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/parasitic-solution/</guid>
      <description>정의 1 패러사이틱 솔루션Parasitic Solution 이란 직역했을 때 &amp;lsquo;기생하는 해&amp;rsquo;라는 뜻으로 메소드가 진행될수록 크기가 커지며 부호가 바뀌는 등의 항을 말한다. $a_{n} = 2^{-n} + (-2)^{n}$ 이라는 수열이 $ (-2)^{n}$ 때문에 수렴하지 않는 걸 상상하면 좋다. 이런 항에다 &amp;lsquo;패러사이틱&amp;rsquo;이라는 표현을 쓰는것은 수렴을 방해</description>
    </item>
    
    <item>
      <title>대학교 수학에서 새롭게 정의되는 함수의 연속</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-continuity-of-function-in-analysis/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-continuity-of-function-in-analysis/</guid>
      <description>정의 공집합이 아닌 $E \subset \mathbb{R}$ 에 대해 $f : E \to \mathbb{R}$ 이라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $$ | x - a | &amp;lt; \delta \implies | f(x) - f(a) | &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $f$ 가 $a \in E$ 에서 연속continuous이라 하고, $E$ 의 모든 점에서 연속이면 $f$ 를 연속함수continuous function라 한다. 설명 고등학교에서 연속을 정의할 때 함수값 $f(a)$ 가 존재한다. 극</description>
    </item>
    
    <item>
      <title>미드포인트 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/midpoint-method/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/midpoint-method/</guid>
      <description>메소드 $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ ( y( x_{0} ), y (x_{1}) ) = ( Y_{0} , Y_{1} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 를 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} = Y_{0}$ 에 대해 $$ y_{n+1} := y_{n-1} + 2 h f ( x_{n} , y_{n} ) $$ 유도 1 $Y&amp;rsquo;(t)$ 를 $x_{n}$ 에 대해 테일러 전개하면 $$ Y&amp;rsquo;(t)</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 예측하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-predict-with-arima-model-in-r/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-predict-with-arima-model-in-r/</guid>
      <description>실습 R 내장데이터 UKDriverDeaths는 1969년부터 1984년까지 영국 월별 운전자 사상자에 대한 데이터다. 언뜻 보아도 계절형 아리마 모형을 따르고, 실제로 모형을 찾아내는것은 별로 어렵지 않다. 그러나 최종적으로 얻은 모형으로 식을 직접 써서 계산하는 것은 무척 손이 많이 가고 복잡한 일이다. 따라서 predict() 함수를 사용한다. n.ahead 옵션을</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드의 수렴성과 오차</title>
      <link>https://freshrimpsushi.github.io/posts/error-and-stability-analysis-for-multi-step-method/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/error-and-stability-analysis-for-multi-step-method/</guid>
      <description>정리 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) )= ( Y_{0} , \cdots , Y_{p} ) \end{cases}$ 에 대해 멀티스텝 메소드 $$ \displaystyle y_{n+1} = \sum_{j=0}^{p} a_{j} y_{n-j} + h \sum_{j = -1}^{p} b_{j} f (x_{n-j} , y_{n-j} ) $$ 가 일관성을 가지고, 초기 오차 $\displaystyle \eta (h) : = \max_{ 0 \le i \le p} | Y (x_{i} ) - y_{h} (x_{i} ) |$ 가 $\displaystyle \lim_{ h \to 0} \eta (h) = 0$ 를 만족하고, $j = 0, 1, \cdots , p$ 에 대해 $a_{j} \ge 0$ 이고 $f$ 가 립시츠 조건을 만족하면 메소드는 수렴하고 적절한 상수 $c_{1} , c_{2}$</description>
    </item>
    
    <item>
      <title>입실론-델타 논법</title>
      <link>https://freshrimpsushi.github.io/posts/epsilon-delta-argument/</link>
      <pubDate>Tue, 30 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/epsilon-delta-argument/</guid>
      <description>정의1 $I$ 가 $a \in \mathbb{R}$ 를 포함하는 구간이고, $f$ 는 $I \setminus \left\{ a \right\}$ 에서는 정의된 함수라고 하자. 모든 $\epsilon &amp;gt; 0$ 에 대해 $$ 0 &amp;lt; | x - a | &amp;lt; \delta \implies | f(x) - L | &amp;lt; \varepsilon $$ 을 만족하는 $\delta&amp;gt;0$ 가 존재하면 $x \to a$ 일 때 $f(x)$ 가 $L \in \mathbb{R}$ 로 수렴한다converge고 한다. 설명 입실론-델타 논법의 이름은 보다시피 정의에 등장하는 입실론 $\varepsilon$ 과 델타 $\delta$ 에서 따온 것이다. 이는 &amp;lsq</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 얻은 시계열 분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-arima-model-summary-in-r/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-arima-model-summary-in-r/</guid>
      <description>실습 R 내장데이터 AirPassenger는 1949년부터 1960년까지 월별 항공기의 승객 수에 대한 데이터다. (1) 모형: 사실 계수만 제대로 파악할 수 있다면 중요한 것은 아니다. 계절형 아리마 모형 $ARIMA(p,d,q)\times(P,D,Q)_{s}$ 을 나타낸다. 예로써 위 분석의 결과인 ARIMA(0,1,1)(0,1,1)[12]는 $ARIMA(0,1,1)\times(0,1,1)_{12}$ 를 의미한다. (2) 계수: 모형에 맞는 계수를 나타</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드의 일관성과 수렴차수</title>
      <link>https://freshrimpsushi.github.io/posts/consistency-and-convergence-order-of-multistep-method/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/consistency-and-convergence-order-of-multistep-method/</guid>
      <description>정리 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) )= ( Y_{0} , \cdots , Y_{p} ) \end{cases}$ 에 대해 멀티스텝 메소드 $$ \displaystyle y_{n+1} = \sum_{j=0}^{p} a_{j} y_{n-j} + h \sum_{j = -1}^{p} b_{j} f (x_{n-j} , y_{n-j} ) $$ 가 일관성을 가지는 필요충분조건은 (i) 이고, 수렴차수 $m \in \mathbb{N}$ 을 갖는 필요충분조건은 (ii) 다. (i): $$\begin{cases} \displaystyle \sum_{j = 0}^{p} a_{j} = 1 \\ \displaystyle - \sum_{j = 0}^{p} j a_{j} + \sum_{j = -1}^{p} b_{j} = 1 \end{cases}$$ (ii): $i = 0, 1 , \cdots , m$ 에 대해 $$\sum_{j=0}^{p} (-j)^{i} a_{j} + i \sum_{j=-1}^{p} (- j )^{i-1} b_{j} = 1$$ 설명 멀티</description>
    </item>
    
    <item>
      <title>리미트 슈프리멈과 리미트 인피멈</title>
      <link>https://freshrimpsushi.github.io/posts/limit-supremum-and-limit-infimum/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-supremum-and-limit-infimum/</guid>
      <description>정의 $\left\{ x_{n} \right\}_{n \in \mathbb{N}}$, $\left\{ y_{n} \right\}_{n \in \mathbb{N}}$ 이 실수열이라고 하자. $\displaystyle \limsup_{n \to \infty} x_{n} := \lim_{n \to \infty} \left( \sup_{k \ge n} x_{k} \right)$ 을 $\left\{ x_{n} \right\}$ 의 리미트 슈프리멈limit supremum이라 한다. $\displaystyle \liminf_{n \to \infty} y_{n} := \lim_{n \to \infty} \left( \inf_{k \ge n} y_{k} \right)$ 을 $\left\{ y_{n} \right\}$ 의 리미트 인피멈limit infimum이라 한다. 여기서 $\displaystyle \sup_{k \ge n} x_{k} := \sup \left\{ x_{k} : k \ge n \right\}$ 그리고 $\displaystyle \inf_{k \ge n} x_{k} := \inf \left\{ x_{k} : k \ge n \right\}$ 이다. 성질 (a)</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 시계열 분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-arima-model-in-r/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-arima-model-in-r/</guid>
      <description>실습 R에서 내장데이터 WWWusage 를 불러와 그래프를 그려 확인해보자. WWWusage는 먼 옛날 인터넷에 접속하는 이용자수를 나타내는 시계열 데이터로써, 그 추이를 파악하기 위해서는 시계열 분석을 해야한다. 시계열 분석에서 가장 대표적인 모형은 아리마 모형이나, 같은 아리마 모형이라고 해도 실제로 적절한 모형을 찾아내는 방법은 여러가지가 있다. 다행</description>
    </item>
    
    <item>
      <title>멀티스텝 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/multistep-method/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multistep-method/</guid>
      <description>정의 1 $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ ( y( x_{0} ) , \cdots , y(x_{p}) ) = (Y_{0}, \cdots , Y_{p} ) \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값과 $0 \le p \le m$ 에 대해 $a_{p} \ne 0$ 혹은 $b_{p} \ne 0$ 이면 다음을 $(p+1)$-스텝 메소드라</description>
    </item>
    
    <item>
      <title>초기값이 조금 달라졌을 때 오일러 메소드의 오차</title>
      <link>https://freshrimpsushi.github.io/posts/error-analysis-for-euler-methods-with-perturbed-initial-valued/</link>
      <pubDate>Thu, 25 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/error-analysis-for-euler-methods-with-perturbed-initial-valued/</guid>
      <description>정리 $[x_{0} , b] \times \mathbb{R}$ 에서 정의된 $f$ 에 대해 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 의 해 $Y(x)$ 가 $Y \in C^{3} [ x_{0} , b ]$ 이고 $\displaystyle f_{y} (x,y) = {{ \partial f (x,y) } \over { \partial y }}$ 와 $\displaystyle f_{yy} (x,y) = {{ \partial^{2} f (x,y) } \over { \partial y^{2} }}$ 가 연속이면서 바운디드라고 하자. 초기값 $y_{h} (x_{0} )$ 가 $Y_{0} - y_{h} (x_{0} ) = \delta_{0} h + O ( h^2 )$ 을 만족시킨다고 하자. 그러면 오일러 메소드로 생기는 오차는 선형 초기값 문제 $$ \begin{cases} \displaystyle D&amp;rsquo; (x) = f_{y}</description>
    </item>
    
    <item>
      <title>코시 수열</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-sequence/</link>
      <pubDate>Thu, 25 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-sequence/</guid>
      <description>정의 모든 $\varepsilon &amp;gt; 0$ 에 대해서 $n , m \ge N \implies | x_{n} - x_{m} | &amp;lt; \varepsilon$ 를 만족하는 $N \in \mathbb{N}$ 이 존재하면 수열 $\left\{ x_{n} \right\}_{n \in \mathbb{N}}$ 이 코시Cauchy라 한다. 정리 $\mathbb{R}$ 에서 코시 수열과 수렴하는 수열은 동치다. 설명 세상에 발산하면서도 중요한 수열은 별로 없다는 점을 생각해보면 여기에 이름을 붙인 &amp;lsquo;코시&amp;rsquo;가 대단한 학자였음을 짐작할 수 있다. 고등학</description>
    </item>
    
    <item>
      <title>강한 립시츠 조건과 오일러 메소드의 오차</title>
      <link>https://freshrimpsushi.github.io/posts/stronger-lipschitz/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stronger-lipschitz/</guid>
      <description>정리 $[x_{0} , b] \times \mathbb{R}$ 에서 정의된 $f$ 에 대해 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 의 해 $Y(x)$ 가 $[x_{0} , b]$ 에서 두 번 미분가능하다고 하자. $f$ 가 모든 $x_{0} \le x \le b$ 와 $ y_{1} , y_{2} \in \mathbb{R}$, 그리고 $K \ge 0$ 에 대해 **강한 립시츠 조건 $$ |f(x,y_{1} ) - f(x,y_{2}) | \le K | y_{1} - y_{2} | $$ 을 만족하면 오일러 메소드로 얻은 해 $\left\{ y_{n} ( x_{ n } ) \ : \ x_{0} \le x_{n} \le b \right\} $ 에 대해 $$ \max_{ x_{0 } \le x_{n} \le b } | Y_{x_{n}} - y_{h} (x_{n})</description>
    </item>
    
    <item>
      <title>준소수의 소인수분해 문제가 쉽게 풀리는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/condition-for-factorization-problem-be-solved-easily/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/condition-for-factorization-problem-be-solved-easily/</guid>
      <description>정리 1 준소수의 소인수분해문제 $N = pq$ 는 다음의 조건 하에서 비교적 쉽게 풀리게 된다. (i): $p$ 가 스무스한 소수다. (ii): $p \approx q$ 설명 조건 (ii)의 의미는 $p$ 와 $q$ 의 차이가 적을 때 쉽게 풀린다는 것인데, 이에 대해서는 설명이 필요할 것이다: 언뜻 생각해보았을 때 $p,q \in \mathbb{N}$ 에 대해 $(p + q)$ 가 제한되어있다면 $N = pq$ 를 가장 크게 만드는 방법은 가능한 한 $p$ 와 $q$ 의 차가</description>
    </item>
    
    <item>
      <title>볼자노-바이어슈트라스 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bolzano-weierstrass-theorem/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bolzano-weierstrass-theorem/</guid>
      <description>정리 무한집합 $E \subset \mathbb{R}$ 가 유계이면 $E$ 의 집적점 $p \in \mathbb{R}$이 존재한다. 설명 혹은 &amp;lsquo;유계 수열은 수렴하는 부분수열을 갖는다.&amp;lsquo;라고 해도 좋다. 조건에서 $E$ 가 꼭 닫혀있을 필요는 없다는 점을 알아두도록 하자. 증명 **Part 1. $\displaystyle \bigcap_{n=1}^{\infty} I_{n} = \left\{ x \right\}$ 가정에서 $E$ 가 유계이므로 $E \subset I_{1}$ 를 만족하는 폐구간 $I_{1} := [a,b]$ 가 존재한다.</description>
    </item>
    
    <item>
      <title>수치해석에서의 오일러 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/euler-method-in-numerical-analysis/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euler-method-in-numerical-analysis/</guid>
      <description>메소드 1 $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. 구간 $(a,b)$ 을 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 특히 충분히 작은 $h &amp;gt; 0$ 에 대해 $x_{j} = x_{0} + j h$ 이라고 하면 초기값 $y_{0} \simeq Y_{0}$ 에 대해 $$ y_{n+1} = y_{n} + h f ( x_{n} , y_{n} ) $$ 설명 오일러 메소드는 개념적으로 아주 간단한 방법이지만 수치</description>
    </item>
    
    <item>
      <title>폴라드 p-1 소인수분해 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pollards-p-1-factorization-algorithm/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pollards-p-1-factorization-algorithm/</guid>
      <description>알고리즘 1 준소수 $N$ 이 주어져있다고 하자. $p$ 가 스무스 소수라면 $N$ 의 소인수분해 $N = pq$ 는 다음과 같이 구할 수 있다. Step 1. $a := 2$ 와 $L := 1$ 을 정한다. Step 2. $d := \gcd ( a^{L} - 1 , N )$ 를 계산한다. Step 3. $1&amp;lt; d &amp;lt; N$ 이면 $N$ 의 약수 $d = p$ 를 구한 것이므로 끝이다. 그 외의 경우엔 $L := (L+1)!$ 과 같이 업데이트한다. $L$ 이 너무 큰 경우엔 $L := 1$ 로 되돌리고 $a : = a+ 1$ 과 같</description>
    </item>
    
    <item>
      <title>칸토어의 축소구간 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cantors-nested-intervals-theorem/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cantors-nested-intervals-theorem/</guid>
      <description>정의1 집합의 수열 $\left\{ S_{n} \right\}_{n=1}^{\infty}$ 이 모든 자연수 $n$ 에 대해 $S_{n+1} \subset S_{n}$ 이면 내포Nested 되었다고 한다. 설명 내포의 번역은 별로 매끄럽지 않은데, 별다른 대안이 없으므로 그냥 네스티드Nested로 외우는 걸 추천한다. 정리 내포된 구간 $[a_{n}, b_{n}]$ 에 대해 다음이 성립한다. (a) $\displaystyle \bigcap_{n=1}^{\infty} [a_{n}, b_{n}] \ne \emptyset$ (b) 특히 $\displaystyle \lim_{n \to \infty} (b_{n} - a_{n}) = 0$ 이면 $\displaystyle \bigcap_{n=1}^{\infty} [a_{n}, b_{n}]$ 은 홑원소 집합이다. 홑원소 집합</description>
    </item>
    
    <item>
      <title>골드바서-미칼리 확률 키 암호체계 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-goldwasser-micali-probabilistic-key-cryptosystem/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-goldwasser-micali-probabilistic-key-cryptosystem/</guid>
      <description>빌드업 왼쪽부터 순서대로 앨리스 , 밥 , 이브라 하자. 앨리스와 밥은 메세지를 주고받을 당사자고, 이브는 메세지에 관심이 있는 소극적 공격자다. 주황색 상자는 앨리스만 알고 있는 정보를, 하늘색 상자는 밥만 알고 있는 정보를, 검은색 상자는 공개된(이브도 알고 있는) 정보를 나타낸다. 앨리스는 밥에게 받아야할 메세지 $m \in \left\{ 0 , 1 \right\}$ 이 있다. $\displaystyle \left( {{</description>
    </item>
    
    <item>
      <title>대학교 수학에서 수열의 수렴을 복잡하게 정의하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-we-have-to-define-the-convergence-complicated-in-college/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-we-have-to-define-the-convergence-complicated-in-college/</guid>
      <description>정의 $\left\{ x_{n } \right\}_{n = 1}^{\infty}$ 이 실수의 수열이라고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 $n \ge N \implies | x_{n} - a | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하면 $\left\{ x_{n } \right\}$ 이 $a \in \mathbb{R}$ 로 수렴한다고 한다. $$ \lim_{n \to \infty} x_{n} = a \iff \forall \varepsilon &amp;gt; 0 , \exists N \in \mathbb{N} : n \ge N \implies | x_{n} - a | &amp;lt; \varepsilon $$ 설명 이러한 정의를 사용한 전개를 흔히 입실론-델타 논법이라 부른다. 직관을 버리고 수열의 극한을 엄밀하게 재정의하는</description>
    </item>
    
    <item>
      <title>대학교 수학에서 수열의 극한을 새롭게 정의하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-we-redefine-the-convergence-of-sequence-in-college/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-we-redefine-the-convergence-of-sequence-in-college/</guid>
      <description>정의 $\mathbb{N}$ 은 자연수의 집합, $\mathbb{R}$ 은 실수의 집합을 의미한다. 정의역이 $\mathbb{N}$ 인 함수를 수열이라고 한다. 자연수의 수열 $\left\{ n_{k} \right\}_{ k \in \mathbb{N}}$ 에 대해 $\left\{ x_{n_{k}} \right\}_{ k \in \mathbb{N}}$ 를 $\left\{ x_{n} \right\}_{ n \in \mathbb{N}}$ 의 부분수열Subsequence이라 한다. 모든 $x \in \left\{ x_{n} \right\}_{ n \in \mathbb{N}}$ 에 대해 $x \le M$ 을 만족하는 $M \in \mathbb{R}$ 이 존재하면 $\left\{ x_{n} \right\}_{ n \in \mathbb{N}}$ 가 위로 유계 , $m \le x$ 를 만족하는 $m \in \mathbb{R}$ 이 존재하면 아래로</description>
    </item>
    
    <item>
      <title>RSA 공개 키 암호체계 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rsa-public-key-cryptosystem/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rsa-public-key-cryptosystem/</guid>
      <description>빌드업 왼쪽부터 순서대로 앨리스 , 밥 , 이브라 하자. 앨리스와 밥은 메세지를 주고받을 당사자고, 이브는 메세지에 관심이 있는 소극적 공격자다. 주황색 상자는 앨리스만 알고 있는 정보를, 하늘색 상자는 밥만 알고 있는 정보를, 검은색 상자는 공개된(이브도 알고 있는) 정보를 나타낸다. 앨리스는 밥에게 받아야할 메세지 $m \in \mathbb{N}$ 이 있다. 알고리즘 1 키 설</description>
    </item>
    
    <item>
      <title>소인수분해</title>
      <link>https://freshrimpsushi.github.io/posts/factorization/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factorization/</guid>
      <description>정의 자연수 $N$ 에 대해 $N = p_{1}^{r_{1}} \cdots p_{n}^{r_{n}}$ 을 만족하는 소수 $p_{1} , \cdots , p_{n}$ 와 자연수 $r_{1} , \cdots , r_{n}$ 를 찾는 것을 소인수분해라 한다. 설명 역사적으로 소수는 늘 탐구의 대상이었으나 그럼에도 불구하고 아직 모르는 것이 많다. 페르마 판정법, 코셀트 판정법, 밀러-라빈 판정법과 같은 초등적 도구는 물론, 소수 정리를 비롯한 해석적 접근은 인간 지성의 위대한 산물이다. 완벽</description>
    </item>
    
    <item>
      <title>립시츠 조건</title>
      <link>https://freshrimpsushi.github.io/posts/lipschitz-condition/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lipschitz-condition/</guid>
      <description>정의 우리는 1계 미분방정식에 대한 존재성-유일성 정리의 스테이트먼트에서 립시츠 조건Lipschitz Condition을 발견할 수 있다. $D \subset \mathbb{R}^2$ 에서 정의된 연속함수 $f$ 에 대해 초기값 문제 $\begin{cases} y&amp;rsquo; = f(x,y) \\ y( x_{0} ) = Y_{0} \end{cases}$ 가 주어져 있다. $f$ 가 모든 $(x,y_{1}) , (x , y_{2} ) \in D$ 와 $K &amp;gt; 0$ 에 대해 립시츠 조건 $$ |f(x,y_{1} ) - f(x,y_{2}) | \le K | y_{1} - y_{2} | $$ 을 만족하면 $(x_{0} , Y_{0}) \in</description>
    </item>
    
    <item>
      <title>연속이지만 미분할 수 없는 함수: 바이어슈트라스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/weierstrass-function/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weierstrass-function/</guid>
      <description>정리 어디에서도 미분할 수 없는 연속함수가 존재한다. 증명 Strategy: 연속함수 $g_{1} (x) := | x - 1 |$ 과 $g_{2} (x) := | x - 2 |$ 을 생각해보자. $g_{1}$ 은 $x=1$ 에서, $g_{2}$ 는 $x=2$ 에서 미분가능하지 않다. $(g_{1} + g_{2})$ 는 $x = 1$ 와 $x = 2$ 두 점 모두에서 미분가능하지 않다. 이러한 방식으로 $\displaystyle G: = \sum_{k=1}^{\infty} g_{k}$ 을 구성해보면 $G$ 는 $x \in \mathbb{N}$ 에서 미분가능하지 않을 것이다. 물론 이는 바이어슈트라스 함수</description>
    </item>
    
    <item>
      <title>수치적으로 이상적분을 계산하기 위한 가우스 구적법</title>
      <link>https://freshrimpsushi.github.io/posts/gaussian-quadrature-to-calculate-numerically-improper-integration/</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gaussian-quadrature-to-calculate-numerically-improper-integration/</guid>
      <description>정의 1 가우스-체비셰프 구적법 $$ \int_{-1}^{1} {{ 1 } \over { \sqrt{1 - x^2 } }} f(x) dx \approx \sum_{i=1}^{n} w_{i} f( x_{i} ) $$ $$ w_{i} = {{ \pi } \over { n }} $$ 여기서 $x_{i}$ 들은 $T_{n}(x) = 0$ 를 만족하는 체비셰프 노드다. 가우스-라게르 구적법 $$ \int_{0}^{\infty} e^{-x} f(x) dx \approx \sum_{i=1}^{n} w_{i} f( x_{i} ) $$ $$ w_{i} = {{ x_{i} } \over { (n+1)^2 \left[ L_{n+1} (x_{i} ) \right]^2 }} $$ 여기서 $x_{i}$ 들은 $L_{n}(x) = 0$ 를 만족하는 라게르 노드다. 가우스-에르미트 구적법 $$ \int_{-\infty}^{\infty} e^{-x^2} f(x) dx \approx \sum_{i=1}^{n} w_{i} f( x_{i} ) $$</description>
    </item>
    
    <item>
      <title>함수의 급수</title>
      <link>https://freshrimpsushi.github.io/posts/series-of-function/</link>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-of-function/</guid>
      <description>정의 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 을 정의하자. (1) $\displaystyle \sum_{k=1}^{n} f_{k} (X)$ 이 $n \to \infty$ 일 때 $E$ 에서 점별수렴하면 급수 $\displaystyle \sum_{k=1}^{ \infty } f_{k}$ 가 $E$ 에서 점별수렴한다고 한다. (2) $\displaystyle \sum_{k=1}^{n} f_{k} (X)$ 이 $n \to \infty$ 일 때 $E$ 에서 균등수렴하면 급수 $\displaystyle \sum_{k=1}^{ \infty } f_{k}$ 가 $E$ 에서 균등수렴한다고 한다. (3) $\displaystyle \sum_{k=1}^{n} | f_{k} (x) |$ 이 $n \to \infty$ 일 때 $E$ 에서 점별수렴하면 급수 $\displaystyle \sum_{k=1}^{ \infty } f_{k}$ 가 $E$ 에서 절대수렴한다고 한다. 설명 함수의 수열</description>
    </item>
    
    <item>
      <title>에르미트 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-polynomial/</link>
      <pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-polynomial/</guid>
      <description>정의 확률론자의 에르미트 다항함수 $$ H_{e_{n}} := (-1)^{n} e^{{x^2} \over {2}} {{d^{n}} \over {dx^{n}}} e^{- {{x^2} \over {2}}} $$ 물리학자의 에르미트 다항함수 $$ H_{n} := (-1)^{n} e^{x^2} {{d^{n}} \over {dx^{n}}} e^{-x^2} $$ 기초 성질 에르미트 다항함수는 두가지 꼴이 쓰이며, $H_{n} (x) = 2^{{n} \over {2}} H_{e_{n}} \left( \sqrt{2} x \right)$ 와 같은 관계를 갖는다. 재귀 공식 H_{n+1} (x) = 2x H_{n} (x) - H_{n}&amp;rsquo; (X) $$ 직교 집합 [1] 함수의 내적: $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx$ 에 대해 웨이트 $w$ 를 $\displaystyle w(x) := e^{-x^2}$ 와 같이 주면 $\left\{ H_{0} , H_{1}, H_{2},</description>
    </item>
    
    <item>
      <title>함수의 점별수렴과 균등수렴의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/the-difference-between-the-pointwise-convergence-and-uniformly-convergence-of-a-function/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-difference-between-the-pointwise-convergence-and-uniformly-convergence-of-a-function/</guid>
      <description>$\mathbb{R}$ 의 부분집합 $E \ne \emptyset$ 에 대해 함수 $f : E \to \mathbb{R}$ 와 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 을 정의하자. 함수의 점별수렴 모든 $\varepsilon &amp;gt; 0$ 과 $x \in E$ 에 대해 $n \ge N \implies | f_{n} (x) - f(x) | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하면 $E$ 에서 $f_{n}$ 이 $f$ 로 점별수렴한다고 하고 아래와 같이 표기한다. $$ f_n \rightarrow f $$ 함수의 균등수렴 모든 $\varepsilon &amp;gt; 0$ 에 대해 $n \ge N \implies | f_{n} (x) - f(x) | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하</description>
    </item>
    
    <item>
      <title>거리공간에서의 내부 폐포 경계</title>
      <link>https://freshrimpsushi.github.io/posts/interior-closure-boundary/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interior-closure-boundary/</guid>
      <description>정의 거리공간 $\left( X, d \right)$ 에 대해 $A \subset X$ 라고 하자. $x \in O \subset A$ 를 만족하는 열린 집합 $O$ 가 존재할 때, $x$ 를 $A$ 의 내점Interior Point이라 한다. $A$ 의 내점의 집합 $A^{\circ}$ 를 $A$ 의 내부Interior라 한다. $A$ 와 그 도집합의 합집합 $\overline{A} : = A \cup A&amp;rsquo;$ 를 $A$ 의 폐포Closure라 한다. $x \in \overline{A}$ 이면서 $x \in \overline{X \setminus A}$ 일 때, $x$ 를 $A$ 의 경계점Bounda</description>
    </item>
    
    <item>
      <title>라게르 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/laguerre-polynomial/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laguerre-polynomial/</guid>
      <description>정의 $\displaystyle L_{n} := {{ e^{x} } \over { n! }} {{ d^{n} } \over { dx^{n} }} \left( e^{-x} x^{n} \right)$ 을 라게르 다항함수Laguerre Polynomial라 한다. 기초 성질 재귀 공식 [0]: $$L_{n+1} (x) = {{ 1 } \over { n+1 }} \left[ \left( 2n + 1 - x \right) L_{n} (x) - n L_{n-1} (x) \right]$$ 직교 집합 [1] 함수의 내적: $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx$ 에 대해 웨이트 $w$ 를 $\displaystyle w(x) := e^{-x}$ 와 같이 주면 $\left\{ L_{0} , L_{1}, L_{2}, \cdots \right\}$ 은 직교 집합이 된다. 설명 $n = 0, \cdots , 3$ 에 대한 라</description>
    </item>
    
    <item>
      <title>실수 집합과 공집합은 열려있으면서도 닫혀있다</title>
      <link>https://freshrimpsushi.github.io/posts/real-set-and-empty-set-is-open-and-closed/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/real-set-and-empty-set-is-open-and-closed/</guid>
      <description>정리 $\mathbb{R}$ 과 $\emptyset$ 은 열려있으면서 닫혀있다. 설명 실수 $\mathbb{R}$ 상에서 여러 개구간의 합집합을 열린 집합이라고 한다. 예로써 $(-1,0) \cup (2,3)$ 은 당연히 열린 집합이고, $(0,1)$ 이나 $\mathbb{R}$ 역시 열린 집합이다. 한편 닫혀있음은 열려있음을 통해 정의된다. 어떤 실수의 부분집합 $C$ 에 대해 $R \setminus C$ 가 열려 있으면 $C$ 를 닫힌 집합이라고 한다.제시된 정리에서도 이미 나와있지만 열리고 닫히고는</description>
    </item>
    
    <item>
      <title>실수 집합에서 집적점이란</title>
      <link>https://freshrimpsushi.github.io/posts/limit-point/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-point/</guid>
      <description>정의 실수상에서의 한 점 $x \in \mathbb{R}$ 과 부분집합 $A \subset \mathbb{R}$ 에 대해 $x$ 를 포함한 임의의 열린 집합 $O$ 에 대해 $ O \cap ( A \setminus \left\{ x \right\} ) \ne \emptyset $ 이면 $x$ 를 집적점Limit Point이라 정의한다. $A$ 의 집적점의 집합을 $A$ 의 도집합Derived set이라 부르며, $A&amp;rsquo;$ 로 표기한다. 설명 위 정의에서 조건은 $( O \setminus \left\{ x \right\} ) \cap A \ne \emptyset$ 이어도 상관 없다. 직관적으로 예시</description>
    </item>
    
    <item>
      <title>함수열의 균등수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-uniformly-of-function/</link>
      <pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-uniformly-of-function/</guid>
      <description>정의 $\mathbb{R}$ 의 부분집합 $E \ne \emptyset$ 에 대해 함수 $f : E \to \mathbb{R}$ 와 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 을 정의하자. 모든 $\varepsilon &amp;gt; 0$에 대해 $n \ge N \implies | f_{n} (x) - f(x) | &amp;lt; \varepsilon$ 을 만족하는 $N \in \mathbb{N}$ 이 존재하면 $E$ 에서 $f_{n}$ 이 $f$ 로 균등수렴uniformly convergence한다고 하고 다음과 같이 표기한다. $$ f_n \rightrightarrows f $$ 혹은 $$ f_{n} \overset{\text{unif}}{\to} f $$ 혹은 $$ f_{n} \to f \quad \text{uniformly} $$ 설명 균등수렴은 함수값이</description>
    </item>
    
    <item>
      <title>함수열의 점별수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-pointwise-of-function/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-pointwise-of-function/</guid>
      <description>정의 $\mathbb{R}$ 의 부분집합 $E \ne \emptyset$ 에 대해 함수 $f : E \to \mathbb{R}$ 를 정의하자. 함수열 $\left\{ f_{n} : E \to \mathbb{R} \right\}_{n=1}^{\infty}$ 이 각각의 $x \in E$ 에 대해 $f(x) = \lim \limits_{n \to \infty} f_{n} (X)$ 을 만족하면 $E$ 에서 $f_{n}$ 이 $f$ 로 점별수렴pointwise convergence한다고 하고 다음과 같이 표기한다. $$ f_{n} \to f $$ 설명 위 정의를 입실론-델타 논법으로 다시 써보면 다음과 필요충분조건이다. 모든 $\varepsilon 0$ 과 $x</description>
    </item>
    
    <item>
      <title>수치적으로 이상적분을 계산하기 위한 변수 치환 트릭</title>
      <link>https://freshrimpsushi.github.io/posts/substitution-trick-to-calculate-numerically-improper-integration/</link>
      <pubDate>Sat, 06 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/substitution-trick-to-calculate-numerically-improper-integration/</guid>
      <description>정리 1 $0 &amp;lt; a &amp;lt; b &amp;lt; \infty$ 라고 하자. [1]: $ 0 &amp;lt; p &amp;lt; 1$ 면 $$\int_{0}^{b} {{ f(x) } \over {x^{p} }} dx = \int_{0}^{{{ 1 } \over { 1-p }} b^{1-p} } f \left( \left[ ( 1- p ) m \right]^{{{ 1 } \over { 1-p }}} \right) dm$$ [2]: $ 1 &amp;lt; p$ 면 $$\int_{a}^{ \infty } {{ f(x) } \over {x^{p} }} dx = \int_{0}^{{{ 1 } \over { p-1 }} a^{1-p}}f \left( \left[ ( p-1 ) m \right]^{{{ 1 } \over { 1-p }}} \right) dm$$ 설명 이상적분은 언제나 골칫덩이지만 풀이를 포기할 수는 없다. 보통 적분이 어려운 이유는 어지간한 트릭을 써봐도 정작 그 트</description>
    </item>
    
    <item>
      <title>폐구간에서 적분할 수 없는 함수: 디리클레 함수</title>
      <link>https://freshrimpsushi.github.io/posts/dirichelt-function/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dirichelt-function/</guid>
      <description>정의 다음과 같이 정의되는 $f$를 디리클레 함수라고 한다. $$ f(x) := \begin{cases} 1 &amp;amp;, x \in \mathbb{Q} \\ 0 &amp;amp;, x \notin \mathbb{Q} \end{cases} $$ 설명 디리클레 함수는 리만적분을 할 수 없는 대표적인 함수로, 아마 해석학 이상의 공부를 하지 않는다면 평생 상상도 해볼 일 없는 변태적인 예시다. 콕 찝어서 리만적분 할 수 없다고 말하는 이유는 리만적분이 아니면 적분가능할 수도 있기 때문이다. 정리 디리클</description>
    </item>
    
    <item>
      <title>가우스 구적법</title>
      <link>https://freshrimpsushi.github.io/posts/gaussian-quadrature/</link>
      <pubDate>Thu, 04 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gaussian-quadrature/</guid>
      <description>정의 1 $f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 $a = x_{1} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. $$ I_{n} (f) := \sum_{j=1}^{n} w_{j} f ( x_{j} ) \approx \int_{a}^{b} w(x) f(x) dx = I ( f ) $$ 위와 같이 정의된 $I_{n}$ 의 가중치 $w_{j}$ 들을 구해서 수치적 적분을 계산하는 것을 가우스 구적법이라 한다. 설명 $f$ 를 잘 근사하는 다항함수 $p_{n-1}$ 이 존재하는 것은 보장되어있기 때문에, $f$ 대신 $p_{n-1}$ 을 생각해보려 한</description>
    </item>
    
    <item>
      <title>음이항계수</title>
      <link>https://freshrimpsushi.github.io/posts/negative-binomial-coefficient/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/negative-binomial-coefficient/</guid>
      <description>정의 $r,k \in \mathbb{N}$ 에 대해 $\displaystyle \binom{-r}{k}$ 를 음이항계수Negative Binomial Coefficient라 한다. 설명 음이항계수라는 이름에서 짐작할 수 있듯 이항계수가 음수에 대해 확장된 것이다. 수식적으로만 생각해보면 $\alpha \in \mathbb{Z}$ 에 대해 $\displaystyle \binom{\alpha}{k} = {{ \alpha ( \alpha - 1 ) \cdots ( \alpha - k + 1 ) } \over { k! }}$ 와 같이 계산하지 못할 이유가 없다. 더 나아가서 복소수에 대해서도 일반화 할 수 있</description>
    </item>
    
    <item>
      <title>오일러 상수 e는 무리수이다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-e/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-e/</guid>
      <description>정리 $$ e \notin \mathbb{Q} $$ $\mathbb{Q}$ 는 유리수의 집합을 나타낸다. 증명 매클로린 전개를 이용1 Strategy: 매클로린 전개를 통해 $e^{-1}$ 를 두 파트로 찢고 모순을 이끌어낸다. 매클로린 전개를 사용해야하기 때문에 고등학교 교과과정 내에서는 증명할 수 없다. $\mathbb{N}$ 는 자연수의 집합, $\mathbb{Z}$ 는 정수의 집합을 나타낸다. Part 1. $x_{1} = x_{2}$ $e \in \mathbb{Q}$ 이라고 가정하면 오일러 상수 $e$ 는 어떤 $a,b \in \mathbb{N}$ 에 대해 $e = {{</description>
    </item>
    
    <item>
      <title>원주율은 무리수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-pi/</link>
      <pubDate>Sun, 30 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-pi/</guid>
      <description>정리 $\pi \notin \mathbb{Q}$ $\mathbb{Q}$ 는 유리수의 집합을 나타낸다. 증명 Strategy: 정수가 조밀성을 갖지 않는다는 점을 이용한다. 함수 $f$, $F$ 를 아주 교묘하게 정의해서 갖가지 트릭을 사용한다. 이 방법은 이반 니븐Ivan Niven에 의해 고안된 것으로 $\pi$ 가 무리수라는 것을 보이는 증명 중에서는 가장 쉽지만, 아쉽게도 입실론-델타 논법이 쓰이기 때문에 비약 없이는 고등학교 교과과정</description>
    </item>
    
    <item>
      <title>뉴턴-코테스 적분 공식</title>
      <link>https://freshrimpsushi.github.io/posts/newton-cotes-integration-formulas/</link>
      <pubDate>Sat, 29 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newton-cotes-integration-formulas/</guid>
      <description>정의 1 $f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 간격이 $\displaystyle h:= {{b-a} \over {n}}$ 로 일정한 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 다음과 같이 정의된 수치적 적분 오퍼레이터 $I_{n}^{p}$ 을 뉴턴-코테스 공식이라 한다. $$ I_{n}^{p} (f) := \sum_{i=0}^{n} w_{i} f ( x_{i} ) $$ $i=0,1,\cdots , n$ 에 대해 $x_{i} := a + i h$ 이고, $l_{i}$ 는 라그랑주 공식에서 쓰이는 다항함수 $\displaystyle l_{i} (x) := \prod_{i \ne j} \left( {{ x - x_{j} } \over { x_{i}</description>
    </item>
    
    <item>
      <title>루트 2 는 무리수임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-root-2/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-irrationality-of-root-2/</guid>
      <description>정리 $\sqrt{2}$ 는 무리수다. 증명 전략: $\sqrt{2}$ 를 기약분수꼴로 나타내서 모순을 유도한다. 이 방법은 제곱수가 아닌 모든 $n$ 에 대해 $\sqrt{n}$ 이 무리수임을 보이는데에 사용할 수 있다. $\sqrt{2}$ 가 유리수라고 가정하면 $\sqrt{2}$ 서로소인 어떤 두 자연수 $a,b$ 에 대해 $\displaystyle \sqrt{2} = {{ a } \over {b}}$ 와 같이 나타날 수 있어야한다. 양변에 $b$ 를 곱하면 $$ \sqrt{2} b= a $$ 양변을 제곱하면 $$ 2 b^2 = a^2 $$ $a^2$ 는 $2$ 와 $b^2$ 의 곱이</description>
    </item>
    
    <item>
      <title>심슨 룰</title>
      <link>https://freshrimpsushi.github.io/posts/simpson-rule/</link>
      <pubDate>Wed, 26 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simpson-rule/</guid>
      <description>정의 $f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 간격이 $\displaystyle h:= {{b-a} \over {n}}$ 로 일정한 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 다음과 같이 정의된 수치적 적분 오퍼레이터 $I_{n}^{2}$ 을 심슨 룰이라 한다. $$ I_{n}^{2} (f) := \sum_{k=1}^{n/2} {{h} \over {3}} \left[ f(x_{2k-2}) + 4 f( x_{2k-1} ) + f(x_{2k} ) \right] $$ 정리 $f \in C^4 [a,b]$ 이라고 하자. 심슨 룰의 에러 $E_{1}^{2}$ 와 어심토틱 에러 $\tilde{E}_{n}^{2}$ 는 다음과 같다. [1]: $$E_{1}^{2} (f) = - {{h^5} \over {90}} f^{(4)} ( \xi</description>
    </item>
    
    <item>
      <title>R 에서 로그로그 스케일 그림 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-loglog-scale-graph/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-loglog-scale-graph/</guid>
      <description>좋지 않은 방법 win.graph(7,4); par(mfrow=c(1,2)) plot(pressure,main=&amp;#39;Pressure\&amp;#39;) y&amp;lt;-pressure[-1,]$pressure; logtemp&amp;lt;-log(y) x&amp;lt;-pressure[-1,]$temperature; logpress&amp;lt;-log(x) plot(logpress,logtemp,main=&amp;#39;log scale\&amp;#39;) 로그로그 스케일로 그림을 그리는 가장 쉬운 방법은 데이터 자체에 로그를 취하는 것이다. 만약 로그로그 플랏을 처음 그려본다면 이 방법은 반드시 숙지하는 편이 좋다. 이 방법은 R 이든 어떤 언어든 먹히기 때문에 급한대로 써먹을 수 있기 때문이다. 물론 이 방법은 머리가 편한만큼 손이 다소 수고스럽다. win.graph(5,5) plot(pressure,main=&amp;#39;Pressure\&amp;#39;,log=&amp;#34;xy&amp;#34;) 권장되는 방법 R 자</description>
    </item>
    
    <item>
      <title>사다리꼴 룰</title>
      <link>https://freshrimpsushi.github.io/posts/trapezoidal-rule/</link>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trapezoidal-rule/</guid>
      <description>정의 $f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 간격이 $\displaystyle h:= {{b-a} \over {n}}$ 로 일정한 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 다음과 같이 정의된 수치적 적분 오퍼레이터 $I_{n}^{1}$ 을 사다리꼴 룰이라 한다. $$ I_{n}^{1} (f) := \displaystyle \sum_{k=1}^{n} {{h} \over {2}} \left( f(x_{k-1}) + f(x_{k} ) \right) $$ 정리 $f \in C^2 [a,b]$ 이라고 하자. 사다리꼴 룰의 에러 $E_{1}^{1}$ 와 어심토틱 에러 $\tilde{E}_{n}^{1}$ 는 다음과 같다. [1]: $$E_{1}^{1} (f) = - {{1} \over {12}} h^{3} f &#39;&amp;rsquo;</description>
    </item>
    
    <item>
      <title>R 에서 범례 넣는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-legend-in-r/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-legend-in-r/</guid>
      <description>코드 데이터는 분석하는 것만큼이나 표현하는 것이 중요하다. 그림이 복잡할 수록 꼼꼼한 주석과 깔끔한 범례가 데이터를 이해하는데에 큰 도움을 준다. legend() 함수는 굉장히 많은 옵션을 가지고 있으나, 아래 코드와 같이 아주 필수적인 요소만 사용해도 좋다. 위치를 나타내는 첫번째 옵션은 &amp;ldquo;top&amp;rdquo;, &amp;ldquo;bottom&amp;rdquo; + &amp;ldquo;left&amp;rdquo;, &amp;ldquo;right&amp;rdquo; 의 조합과 &amp;ldquo;center&amp;quot;로 편하게</description>
    </item>
    
    <item>
      <title>수치적 적분</title>
      <link>https://freshrimpsushi.github.io/posts/numerical-intergration/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/numerical-intergration/</guid>
      <description>정의 1 $f : [a,b] \to \mathbb{R}$ 가 $[a,b]$ 에서 적분가능하고 $[a,b]$ 를 $a = x_{0} &amp;lt; \cdots &amp;lt; x_{n} = b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 적분 오퍼레이터 $I$ 를 $\displaystyle I(f) := \int_{a}^{b} f(x) dx$ 와 같이 정의한다. 적분 오퍼레이터 $I_{n}$ 을 $\displaystyle I_{n} (f) := \sum_{k=1}^{n} \int_{x_{k-1}}^{x_{k}} f(x) dx$ 와 같이 정의한다. 에러 $E_{n}$ 을 $E_{n} (f) := I (f) - I_{n} ( f )$ 와 같이 정의한다. $\displaystyle \lim_{n \to \infty} {{\tilde{E}_{n} (f) } \over { E_{n} (f) }} = 1$ 을 만족하는 $\tilde{E}_{n}$ 을 $E_{n}$ 에 대한 어심토틱 에러라고 한</description>
    </item>
    
    <item>
      <title>R 에서 메타데이터, attr 참조하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-refer-attr-in-r/</link>
      <pubDate>Fri, 21 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-refer-attr-in-r/</guid>
      <description>개요 R 에서 함수들을 사용하다보면 간혹 attr(,&amp;quot;something&amp;quot;)과 같은 데이터를 접할 때가 있다. Attribute는 말 그대로 속성 을 의미하는데, 파이썬과 같은 언어와 달리 R 에서는 메타 데이터로써 데이터에 들어있는 일종의 주석으로 받아들여도 좋다. 그런데 R 을 쓰다보면 가끔 이 데이터를 참조하고 싶을 때</description>
    </item>
    
    <item>
      <title>베르누이 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bernoullis-inequality/</link>
      <pubDate>Wed, 19 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bernoullis-inequality/</guid>
      <description>정리 $\alpha &amp;gt; 0$ 이라고 하면 모든 $x \in [ - 1, \infty )$ 에 대해 다음 두 부등식이 성립한다. [1]: $\alpha \in (0, 1] \implies (1 + x )^{\alpha } \le 1 + \alpha x $ [2] $\alpha \in (1, \infty] \implies (1 + x )^{\alpha } \ge 1 + \alpha x $ 설명 부등식의 모양을 잘 보면 $\alpha$ 의 크기에 달려 있긴 하지만 둘 중 한 쪽은 곱이고, 나머지 한 쪽은 거듭제곱이다. 물론 조건 나름이지만 곱이든 거듭제곱이든 거슬리는 계산 하나를 내가 원하는 쪽으로 바</description>
    </item>
    
    <item>
      <title>R 에서 문자열의 벡터를 하나의 문자열로 합치는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-join-string-vector-in-r/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-join-string-vector-in-r/</guid>
      <description>개요 R 은 데이터를 다루기에 무척 편리한 언어지만, 다른 프로그래밍 언어에도 익숙한 사람이라면 R 의 문자열이 다소 낯설 수 있다. C 혹은 파이썬과 달리 R 자체에서 지원하는 기능이 많고, 반대로 그 기능들을 써야만 수월하게 다룰 수 있다. 그래서 내장 함수들이 생각하는대로 작동하지 않으면 답답한 면이 있다. 예시 예를 들어 위와 같이 캐릭터들로 이루어진 벡</description>
    </item>
    
    <item>
      <title>체비셰프 노드</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-node/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-node/</guid>
      <description>정의 $[-1,1]$ 에서 $\displaystyle x_{k} = \cos \left( {{2k-1} \over {2n}} \pi \right)$, $k=1, \cdots , n$ 을 체비셰프 노드라 한다. 설명 체비셰프 노드는 일반적으로 사용하듯 일정한 간격의 노드 포인트와 달리 반원의 호를 일정한 크기로 자르고 그 점들을 $x$ 축으로 사영시킨 노드 포인트를 말한다. 점들의 분포는 가운데보다 양 끝에 조금 몰리는 모양새를 이룬다. 밑에서 다시 설명하겠지만, 이 점이 바로 체비셰프 노드의 장</description>
    </item>
    
    <item>
      <title>R 에서 리스트를 참조하는 여러가지 방법</title>
      <link>https://freshrimpsushi.github.io/posts/some-way-to-refer-list-in-r/</link>
      <pubDate>Sun, 16 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/some-way-to-refer-list-in-r/</guid>
      <description>개요 R 은 데이터를 다루기 위해 정말 좋은 기능들을 많이 제공하는데, 그 중에서도 리스트는 R 을 사용하게 만드는 가장 큰 이유 중 하나다. 파이썬을 위시한 다른 언어에도 리스트 자료형 자체는 많이 구현되어 있으나 R 만큼 데이터를 다루기 편하고 직관적으로 구현되어 있지는 않다. 리스트를 잘 다룰 수 있게 되면 다른 프로그래밍 언어로는 다소 복잡하고 귀찮은 코딩</description>
    </item>
    
    <item>
      <title>체비셰프 전개</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-expansion/</link>
      <pubDate>Sat, 15 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-expansion/</guid>
      <description>빌드업 1 체비셰프 전개를 이해하기 위해서는 어떻게 체비셰프 전개가 나오는지를 먼저 알아야한다. 우선 최소극대화 문제를 푸는 대신 최소제곱 문제를 푼다고 생각해보자. $$ M_{n} (f) := \inf_{\deg(r) \le n } \left\| f - r \right\|_{2} $$ $f : [a,b] \to \mathbb{R}$ 에 대해 위와 같이 최소제곱 문제가 주어져있다고 하자. 목표는 $M_{n} (f)$ 를 최소화하는 $n$ 차 이하의 다항함수 $r_{n}^{ \ast }$ 를 찾는 것이다. 다행스럽게도</description>
    </item>
    
    <item>
      <title>R 에서 최대값과 최소값의 위치 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-argmax-argmin-or-index-of-maximum-or-minimum-in-r/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-argmax-argmin-or-index-of-maximum-or-minimum-in-r/</guid>
      <description>코드 set.seed(150421) x&amp;lt;-sample(100,10); x which.max(x) which.min(x) 통계를 목적으로 데이터를 보다보면 최대값과 최소값이 무엇인지 아는것만 중요한게 아니라 그 게 몇번째 값인지를 파악하는 것도 필요한 경우가 많다. 특히 시계열 데이터는 더더욱 그러하다. 물론 R 은 이런 함수가 없어도 조작이 쉽지만, 가능하다면 복잡한 코드는 지양하는 게 좋다. 데이터 x 의 최대값이 어디인지 궁금해서 which(max</description>
    </item>
    
    <item>
      <title>스톤-바이어슈트라스 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-stone-weierstrass-theorem/</link>
      <pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-stone-weierstrass-theorem/</guid>
      <description>정의1 $X$ 에 대해 $A \subset C(X)$ 이라고 하자. (1) 서로 다른 $x_{1}, x_{2} \in X$ 에 대해 $f(x_{1}) \ne f(x_{2})$ 를 만족하는 $f \in A$ 가 항상 존재하면 $A$ 가 $X$ 의 점들을 분리한다Separate고 말한다. (2) $X$ 가 메트릭 스페이스이고 모든 $\varepsilon &amp;gt; 0$ 과 $f \in C(X)$ 에 대해 $| g - f | &amp;lt; \varepsilon$ 을 만족하는 $g \in A$ 가 존재하면 $A$ 가 $C(X)$ 에서 유니폼리 덴스Uniformly Dense라 한다. 정리 $X$ 가 컴팩트</description>
    </item>
    
    <item>
      <title>수치해석학에서의 최소극대화 근사와 최소제곱 근사</title>
      <link>https://freshrimpsushi.github.io/posts/minimax-approximation-and-least-squares-approximation/</link>
      <pubDate>Wed, 12 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/minimax-approximation-and-least-squares-approximation/</guid>
      <description>빌드업 1 주어진 함수 $f : [a,b] \to \mathbb{R}$ 를 근사하는 문제가 주어져 있다고 하자. 계산은 컴퓨터의 몫이므로 다항함수로 $f$ 를 근사하는 것이 목표다. 함수를 근사시킨다는 것은 한 점에서의 계산이 아니라 정의역 $[a,b]$ 전체에서 $f$ 와 비슷한 함수를 사용하고 싶은 것이므로 가장 크게 틀리는 부분을 줄이는 것이 목표다. 이러한 상황을 최소극대화Minimax 문제라고 한다</description>
    </item>
    
    <item>
      <title>연속함수공간의 알지브라</title>
      <link>https://freshrimpsushi.github.io/posts/algebra-of-continuous-function-space/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebra-of-continuous-function-space/</guid>
      <description>정의1 다음 세 가지 조건을 만족하는 집합 $A$ 를 $C(X)$ 의 알지브라algebra라 한다. **(i): $\emptyset \ne A \subset C(X)$ (ii): $f,g \in A \implies (f+g) , fg \in A$ (iii): $f \in A , c \in \mathbb{R} \implies cf \in A$ 메트릭 스페이스 $X$ 에 대해 $A \subset C(X)$ 이라고 하자. $A$ 의 모든 시퀀스 $\left\{ f_{n} \in A : n \in \mathbb{N} \right\}$ 가 어떤 $f \in A$ 에 대해 $n \to \infty$ 일 때 $\displaystyle | f - f_{n} | \to 0$ 면 $A$ 가 유니폼리 클로즈드Uniformly Closed라 한</description>
    </item>
    
    <item>
      <title>수치해석에서의 함수 근사</title>
      <link>https://freshrimpsushi.github.io/posts/approximation-of-functions-in-numerical-analysis/</link>
      <pubDate>Mon, 10 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/approximation-of-functions-in-numerical-analysis/</guid>
      <description>빌드업 수치적인 계산을 할 때 컴퓨터가 인간보다 압도적으로 빠른 것은 사실이지만, 딱히 컴퓨터가 초월함수와 무리수를 이해했기 때문은 아니다. 가령 $\displaystyle \sin {{ \pi } \over {6}} = {{1} \over { 2 }}$ 을 계산시킨다면 삼각함수의 기하학적인 정의를 이용해서 직각삼각형을 그려보고 빗변과 높이의 비를 구하는 게 아니라, 다항함수로 급수전개해서 사칙연산으로 구하는 식이다.</description>
    </item>
    
    <item>
      <title>이항 급수 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-binomial-series/</link>
      <pubDate>Sun, 09 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-binomial-series/</guid>
      <description>공식 $|x| &amp;lt; 1$ 이면 $\alpha \in \mathbb{C}$ 에 대해 $$ \begin{align*} (1 + x )^{\alpha} =&amp;amp; \sum_{k=0}^{\infty} \binom{\alpha}{k} x^{k} \\ =&amp;amp; 1 + \alpha x + \dfrac{\alpha(\alpha-1)}{2!}x^{2} + \dfrac{\alpha(\alpha-1)(\alpha-2)}{3!}x^{3} + \cdots \end{align*} $$ 설명 이른바 뉴턴의 이항 정리 로써, 이항 전개가 무한대와 복소수에 대해서 일반화된 것으로 볼 수 있다. 한편 우리에게 익숙한 꼴은 다음과 같은 방법으로 간단하게 유도할 수 있다. $$ \begin{align*} &amp;amp;&amp;amp; \left( 1 + {{y} \over {x}} \right)^{\alpha} =&amp;amp; \sum_{k=0}^{\infty} \binom{\alpha}{k} \left( \dfrac{y}{x} \right)^{k} \\ \implies &amp;amp;&amp;amp; x^{-\alpha} \left( x + y \right)^{\alpha} =&amp;amp; \sum_{k=0}^{\infty} \binom{\alpha}{k} y^{k} x^{-k} \\ \implies &amp;amp;&amp;amp; \left( x + y \right)^{\alpha} =&amp;amp;</description>
    </item>
    
    <item>
      <title>가법성을 가진 연속함수의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-continuous-function-with-additivity/</link>
      <pubDate>Sat, 08 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-continuous-function-with-additivity/</guid>
      <description>정리 [1] 연속함수 $f : \mathbb{R} \to \mathbb{R}$ 가 모든 $x, y \in \mathbb{R}$ 에 대해 $f(x + y) = f(x) + f(y)$ 을 만족하면 $$ f(x) = f(1) x $$ [2] 연속함수 $g : \mathbb{R} \to ( 0 , \infty )$ 가 모든 $x, y \in \mathbb{R}$ 에 대해 $g(x + y) = g(x) g(y)$ 을 만족하면 $$ g(x) = \left( g(1) \right)^x $$ 설명 $f(x + y) = f(x) + f(y)$ 와 같이 덧셈이 함수를 넘나들면서 보존되는 성질을 가법성이라 하고 곱셈이 보존되는 성질을 승법성이라고 한다. $g$ 는 가법성과 승법성이 반반</description>
    </item>
    
    <item>
      <title>복소수에 대해 일반화된 이항 계수</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-binomial-coefficient/</link>
      <pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-binomial-coefficient/</guid>
      <description>정의 $\alpha \in \mathbb{C}$ 에 대해 다음을 이항 계수Binomial Coefficient라고 한다. $$ \binom{\alpha}{k} := \begin{cases} \displaystyle {{ \alpha ( \alpha - 1 ) \cdots ( \alpha - k + 1 ) } \over { k! }} &amp;amp; , k \in \mathbb{N} \\ 1 &amp;amp; ,k=0 \end{cases} $$ 설명 원래 이항 계수는 $\alpha \in \mathbb{N}$ 일 때만 직관적인 의미를 가지지만, 그 계산 과정만 생각해보면 딱히 자연수일 필요가 없다. 당장 생각할 수 있는 음의 정수는 물론 실수, 심지어는 복소수</description>
    </item>
    
    <item>
      <title>코시 곱: 수렴하는 두 멱급수의 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-product-of-series/</link>
      <pubDate>Thu, 06 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-product-of-series/</guid>
      <description>정리 1 $f(x) : = \sum _{k=0}^{\infty} a_{k} x^{k}$ 와 $g(x) : = \sum_{k=0}^{\infty} b_{k} x^{k}$ 의 수렴구간이 $(-r,r)$ 이고 $c_{k} := \sum_{j=0}^{k} a_{j} b_{k-j}$ 이라고 하면 $\sum_{k=0}^{\infty} c_{k} x^{k}$ 는 수렴구간 $(-r,r)$ 상에서 $f(x)g(x)$ 로 수렴한다. 설명 계수들의 곱들이 알아서 두 함수의 곱의 계수로 수렴해준다는 점은 사실 꽤 신기한 일이다. 그냥 유한다항함수였다면 증명조차 필요 없을 정도로 당연하지만, 멱급수는 무한히 많은 항을 가지기 때문이다. 증명 $x \in (-r,r)$ 와 $n \in \mathbb{N}$</description>
    </item>
    
    <item>
      <title>멱급수</title>
      <link>https://freshrimpsushi.github.io/posts/power-series/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/power-series/</guid>
      <description>정의 $S(x) : = \sum \limits_{k=0}^{\infty} a_{k} ( x - x_{0} )^{k}$ 를 멱급수라 하고, $x_{0}$ 를 $S(x)$ 의 중심Center이라 한다. $S(x)$ 가 $|x - x_{0}| &amp;lt; R$ 에 대해 절대수렴하고 $|x - x_{0}| &amp;gt; R$ 에 대해 발산할 때 $R$ 을 $S(x)$ 의 수렴반경Radius of Convergence이라 한다. $S(x)$ 가 수렴하는 가장 큰 구간을 수렴구간Interval of Convergence이라 한다. 수렴구간 $[c,d] \subset (a,b)$ 에서 $x_{0} \in (c,d)$</description>
    </item>
    
    <item>
      <title>R 에서 벡터끼리 내적 계산하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-inner-product-in-r/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-inner-product-in-r/</guid>
      <description>코드 x&amp;lt;-1:10; x y&amp;lt;-(-1)^(1:10); y sum(x*y) x %*% y x %o% y R 에서 분석 혹은 시뮬레이션을 하다보면 가중치가 적용된 기댓값을 구할 일이 종종 있다. 물론 수식적으로 $\displaystyle \left&amp;lt; \mathbb{x}, \mathbb{y} \right&amp;gt; = \sum_{i=1}^{n} x_{i} y_{i}$ 는 아주 간단하고 R 자체의 벡터 계산이 아주 편리하기 때문에 sum() 함수만 있다면 쉽게 내적을 할 수 있다. 그러나 이는 길게 보았을 때 코드의 가독성을 떨어뜨리는 요인이 된다. 한편 $n$ 차원 벡터는 $1 \times n$ 차원</description>
    </item>
    
    <item>
      <title>아리마 모형에서의 드리프트</title>
      <link>https://freshrimpsushi.github.io/posts/drift-in-arima-model/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/drift-in-arima-model/</guid>
      <description>설명 시계열 분석을 하다보면 종종 다음과 같이 드리프트Drift라는 계수를 보게 된다. 물론 위의 경우 표준오차에 비해서 계수의 크기가 너무 작기 때문에 무시해도 상관 없다. 그러나 실제로 유의한 계수인 동시에 수식으로도 써야할 일이 있다면 드리프트가 무엇인지 알아야한다. 아쉽게도 국내에는 드리프트가 도대체 무엇인지에 대한 좋은 설명이 없으며, 수</description>
    </item>
    
    <item>
      <title>윈도에서 명령 프롬프트로 파일 목록 얻는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-file-list-using-cmd-in-windows/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-file-list-using-cmd-in-windows/</guid>
      <description>개요 복수의 데이터를 취합하는 프로그램을 짤 때 파일이 너무 많아서 문제가 될 수 있다. 물론 어느 프로그래밍 언어이든 이를 해결하는 방법은 각자 있겠지만, 반복할 필요가 없거나 너무 다양한 언어를 사용하는 경우 임시적인 해결법이 큰 도움이 된다. 윈도의 명령 프롬프트를 통해 쉽고 빠르게 해보자. 가이드 Step 1. 주소 복사 파일 목록이 필요한 폴더로 들어가 주소를</description>
    </item>
    
    <item>
      <title>계절형 아리마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/seasonal-arima-model/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/seasonal-arima-model/</guid>
      <description>모델 1 $\nabla_{s} Y_{t} := Y_{t} - Y_{t-s}$ 와 같이 정의된 오퍼레이터 $\nabla_{s}$ 를 계절형 차분Seasonal Difference이라 한다. $W_{t} := \nabla^{d} \nabla_{s}^{D} Y_{t}$ 와 같이 정의된 $\left\{ W_{t} \right\}_{t \in \mathbb{N}}$ 가 $ARMA(P,Q)$ 고 $\left\{ Y_{t} \right\}_{t \in \mathbb{N}}$ 이 $ARMA(p,q)$ 면 $\left\{ Y_{t} \right\}_{t \in \mathbb{N}}$ 는 계절형 아리마 과정 $ARIMA(p,d,q)\times(P,D,Q)_{s}$ 라고 한다. 이와 같은 꼴을 한 시계열 분석 모형을 계절형 아리마 모형이라 한다. 설명 오늘의 기온은 물론 어제의 기온에 가장 큰 영향을 받겠지</description>
    </item>
    
    <item>
      <title>박스-칵스 변환</title>
      <link>https://freshrimpsushi.github.io/posts/box-cox-transformation/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/box-cox-transformation/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $x &amp;gt; 0$ 에 대해 $g(x) := \begin{cases} \displaystyle {{ x^{\lambda} - 1 } \over { \lambda }} &amp;amp; , \lambda \ne 0 \\ \log x &amp;amp; , \lambda = 0 \end{cases}$ 를 박스-칵스 변환이라 한다. $g$ 는 원래 멱변환Power Transformation이라 불리나, 박스와 칵스에 의해 소개되어 박스-칵스 변환이라고 부르기도 한다. 박스-칵스 변환의 주된 용도는 데이터를 정규분</description>
    </item>
    
    <item>
      <title>다차원 비선형 맵</title>
      <link>https://freshrimpsushi.github.io/posts/multi-dimensional-nonlinear-map/</link>
      <pubDate>Fri, 24 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multi-dimensional-nonlinear-map/</guid>
      <description>비선형 맵의 정의 맵 $\mathbb{f} : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 이 선형이 아니면 비선형이라 한다. 빌드업 1 어떤 맵이 선형인지 보이는 것은 어렵지만 비선형임을 보이는 것은 쉽고, 선형 문제는 쉽지만 비선형 문제는 어렵다. 이 우주의 거의 모든 것은 비선형이며 비선형은 어렵기 때문에 인간들은 비선형을 선형으로 바꿀 궁리부터 한다. 위 그림에서 주어진 곡선은 분명 휘어있긴 하지만, 아주 작</description>
    </item>
    
    <item>
      <title>다차원 선형 맵</title>
      <link>https://freshrimpsushi.github.io/posts/multi-dimensional-linear-map/</link>
      <pubDate>Mon, 20 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multi-dimensional-linear-map/</guid>
      <description>정의 1 맵 $T_{A} : \mathbb{R}^{m} \to \mathbb{R}^{m}$ 가 모든 $a,b \in \mathbb{R}$ 과 $\mathbb{x}, \mathbb{y} \in \mathbb{R}^{m}$ 에 대해 $$ T_{A} ( a \mathbb{x} + b \mathbb{y} ) = a T_{A} ( \mathbb{x} ) + b T_{A} ( \mathbb{y} ) $$ 를 만족하면 $T_{A}$ 가 선형Linear이라고 한다. $A$ 의 아이겐 밸류들을 $\lambda_{1} , \cdots , \lambda_{m}$ 이라고 하자. 2. $| \lambda_{1} | \ne 1, \cdots , | \lambda_{m} | \ne 1$ 이면 $A$ 가 하이퍼볼릭Hyperbolic하다고 한다. 3. 하이퍼볼릭 $A$ 에 대해 $\begin{cases} | \lambda_{i} | &amp;gt;1 \\ | \lambda_{j} | &amp;lt;1 \end{cases}$ 를 만족하는</description>
    </item>
    
    <item>
      <title>수치해석학에서의 B-스플라인 </title>
      <link>https://freshrimpsushi.github.io/posts/b-spline-in-numerical-analysis/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/b-spline-in-numerical-analysis/</guid>
      <description>글과 수식이 읽기 싫으면 그냥 그림으로 보고 이해해도 무방하다. 정의 1 구간 $[a,b]$ 를 $a \le x_{0} &amp;lt; x_{1} &amp;lt; \cdots &amp;lt; x_{n} &amp;lt; \cdots x_{N} \le b$ 와 같은 노드 포인트들로 쪼갰다고 하자. 주어진 자유도 $K$ 에 대해서 $x_{-K} &amp;lt; x_{-K + 1} &amp;lt; \cdots &amp;lt; x_{-1} &amp;lt; x_{0}$ 과 $x_{N} &amp;lt; x_{N + 1} &amp;lt; \cdots &amp;lt; x_{N+K-1} &amp;lt; x_{N+K}$ 의 추가적인 노드를 생각한다. $i$번째 노드 포인트와 자유도 $1 \le k \le K$ 에 디펜드하는 재귀함수 $$ B_{i,k}(x) := \begin{cases} \chi_{[x_{i} , x_{i+1} )} (x)</description>
    </item>
    
    <item>
      <title>R 에서 데이터 프레임 열기준으로 정렬하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-sort-data-frame-by-a-column/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-sort-data-frame-by-a-column/</guid>
      <description>개요 R 에서 데이터를 정렬하는 것 자체는 sort() 함수를 사용하면 간단하게 할 수 있으나, 기본적으로 sort() 함수는 벡터만을 소팅한다. 그러나 실제로는 데이터 프레임의 수많은 카테고리를 다루기 때문에 열 단위로도 정렬할 수 있는 방법이 필요한 경우가 많다. 코드 x&amp;lt;-c(pi,3,99,0,-1) order(x) x[order(x)] head(iris) head(iris[order(iris$Petal.Length),]) order() 함수는 주어진 벡터가 오름차순이 되도록 하는 데이터의 넘버를 반환해준다. 위의 예시를 보</description>
    </item>
    
    <item>
      <title>수치해석에서의 스플라인</title>
      <link>https://freshrimpsushi.github.io/posts/spline-in-numerical-analysis/</link>
      <pubDate>Thu, 16 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spline-in-numerical-analysis/</guid>
      <description>빌드업 인터폴레이션이란 정확한 함수를 복원하는 게 아니라 그와 유사하면서도 다루기 편한 함수를 구하는 것이 목적이다. 물론 익스플릭시트Explicit하고 계산이 쉬워지도록 구할 수 있다면야 제일 좋겠지만, 이 우주는 그렇게 만만한 곳이 아니다. 문제에 따라서는 간단한 부분을 빨리 풀고 복잡한 부분을 정교하게 풀어야할 수도 있고, 연속성조차 보장</description>
    </item>
    
    <item>
      <title>R 에서 히스토그램 더 세밀하게 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-histogram-class-range/</link>
      <pubDate>Wed, 15 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-histogram-class-range/</guid>
      <description>코드 R 에서는 hist() 함수를 통해 히스토그램을 쉽게 그려볼 수 있다. 이 때 계급의 크기는 R 이 알아서 판단하고 결정하는데, 좀 더 세밀하게 보기 위해서는 nclalss 옵션을 사용하면 된다. set.seed(150421) x&amp;lt;-runif(50) win.graph(7,4); par(mfrow=c(1,2)) hist(x) hist(x,nclass=20) 위 코드를 실행시킨 결과는 다음과 같다.</description>
    </item>
    
    <item>
      <title>에르미트 인터폴레이션</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-interpolation/</link>
      <pubDate>Tue, 14 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-interpolation/</guid>
      <description>정의 1 서로 다른 $x_{1} , \cdots , x_{n}$ 의 데이터 $(x_{1}, y_{1} , y&amp;rsquo;_{1}) , \cdots , (x_{n} , y_{n}, y&amp;rsquo;_{n})$ 에 대해 $\begin{cases} p (x_{i} ) = y_{i} \\ p&amp;rsquo;(x_{i} ) = y&amp;rsquo;_{i} \end{cases}$ 와 $\deg H \le 2n-1$ 을 만족하는 인터폴레이션인 다항 함수 $H$ 를 에르미트 인터폴레이션Hermite Interpolation이라고 한다. 정리 존재성과 유일성 [1]: 주어진 데이터에 대해서 $H$ 는 유일하게 존재한다. 라그랑주 폼 [2]: $$H_{n} (x) = \sum_{i=1}^{n} y_{i} h_{i} (x) + \sum_{i=1}^{n} y&amp;rsquo;_{i} \tilde{h}_{i} (x)$$</description>
    </item>
    
    <item>
      <title>에르미트-제노키 공식</title>
      <link>https://freshrimpsushi.github.io/posts/hermite-genocchi-formula/</link>
      <pubDate>Sun, 12 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hermite-genocchi-formula/</guid>
      <description>공식 서로 다른 $x_{0}, \cdots , x_{n}$ 에 대해 $f \in C^{n} \left( \mathscr{H} \left\{ x_{0}, \cdots , x_{n} \right\} \right)$ 이라 하자. 그러면 표준 심플렉스 $$ \tau_{n} := \left\{ ( t_{1} , \cdots , t_{n} ) : t_{i} \ge 0 \land \sum_{i=1}^{t} t_{i} \le 1 \right\} $$ 과 $\displaystyle t_{0} = 1 - \sum_{i=1}^{n} t_{i}$ 에 대해 다음이 성립한다. $$ f [ x_{0}, \cdots , x_{n} ] = \int \cdots \int_{\tau_{n}} f^{(n)} ( t_{0} x_{0} + \cdots + t_{n} x_{n} ) dt_{1} \cdots dt_{n} $$ $\mathscr{H} \left\{ a,b,c, \cdots \right\}$ 는 $a,b,c, \cdots$ 를 포함하는 가장 작은 구간을 나타낸다. 설명 에르미트-제노키 공식Hermite</description>
    </item>
    
    <item>
      <title>R 에서 데이터 표준화하기 표준화된 잔차 보기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-standardize-data-in-r/</link>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-standardize-data-in-r/</guid>
      <description>코드 R 은 통계에 특화된 언어인만큼 Z-score $\displaystyle z:= {{x - \mu} \over {\sigma}}$ 를 구해야할 일이 많다. 이 때 내장된 scale() 함수를 사용하면 편리하다. 예제로써 $\mathbb{x} = ( 1, \cdots , 10 )$ 이라는 벡터를 표준화해보자. center(평균)나 scale(표준편차)과 같이 지저분하게 뜨는 게 보기 싫다면 그냥 벡터를 취하면 된다. 한편 표준화를 가장 많이 하게 되는 일 중 하나가 회귀분석 후 잔</description>
    </item>
    
    <item>
      <title>뉴턴 계차상 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-newton-divided-difference-formula/</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-newton-divided-difference-formula/</guid>
      <description>공식 서로 다른 $x_{0} , \cdots , x_{n}$ 의 데이터 $(x_{0}, f(x_{0} )) , \cdots , (x_{n} , f( x_{n} ) )$ 에 대해 $$ p_{n} (x) =\sum_{i=0}^{n} f [ x_{0} , \cdots , x_{i} ] \prod_{j=0}^{i-1} (x - x_{j} ) $$ 설명 복잡해보이지만 $n=0,1,2$ 에 대해서 실제로 전개를 해보면 다음과 같이 단순하게 나타난다. $$ \begin{align*} p_{0} (x) =&amp;amp; f(x_{0}) \\ p_{1} (x) =&amp;amp; f( x_{0} ) + (x - x_{0} ) f [ x_{0} , x_{1} ] \\ p_{2} (x) =&amp;amp; f( x_{0} ) + (x - x_{0} ) f [ x_{0} , x_{1} ] + ( x - x_{0} ) ( x - x_{1} ) f [ x_{0} , x_{1} , x_{2} ] \end{align*} $$ 뉴턴</description>
    </item>
    
    <item>
      <title>라그랑주 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-lagrange-formula/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-lagrange-formula/</guid>
      <description>공식 1 서로 다른 $x_{0} , \cdots , x_{n}$ 의 데이터 $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$ 에 대해 $\displaystyle l_{i} (x) := \prod_{i \ne j} \left( {{ x - x_{j} } \over { x_{i} - x_{j} }} \right)$ 이라고 하면 $$ p_{n} (x) = \sum_{i=0}^{n} y_{i} l_{i} (X) $$ 설명 라그랑주 공식은 폴리노미얼 인터폴레이션을 찾는 방법 중 가장 심플한 공식이다. 유도 전략: $l_{i}$ 이 인덱스에 대해 크로데커 델타 함수임을 보인다. $$ l_{i} (x_{i}) = \prod_{i \ne j} \left( {{ x_{i} - x_{j} } \over { x_{i} - x_{j} }} \right) = 1 $$ $$ l_{i} (x_{j})</description>
    </item>
    
    <item>
      <title>폴리노미얼 인터폴레이션</title>
      <link>https://freshrimpsushi.github.io/posts/polynomial-interpolation/</link>
      <pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/polynomial-interpolation/</guid>
      <description>정의 1 서로 다른 $x_{0} , \cdots , x_{n}$ 의 데이터 $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$ 에 대해 $p (x_{i} ) = y_{i}$ 와 $\deg p \le n$ 을 만족하는 인터폴레이션인 다항 함수 $p$ 를 폴리노미얼 인터폴레이션Polynomial Interpolation이라 한다. 정리 존재성과 유일성 [1]: 주어진 데이터에 대해서 $p$ 는 유일하게 존재한다. 라그랑주 공식 [2]: $$p_{n} (x) = \sum_{i=0}^{n} y_{i} l_{i} (X)$$ 뉴턴 계차상 공식 [3]: $$p_{n} (x) =</description>
    </item>
    
    <item>
      <title>R 에서 현재 날짜 시간 확인하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-time-and-date-in-r/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-time-and-date-in-r/</guid>
      <description>코드 R 뿐만이 아니라 프로그래밍 언어를 사용해야하는 많은 작업에서 로그를 작성하고 해당 시각에 대한 정보가 필요하다. R 에서는 Sys.Date() 함수를 통해 날짜를 확인할 수 있으며, Sys.time() 함수를 통해 초 단위까지의 정확한 시각을 알 수 있다. 대소문자에 주의해야하며, 만약 날짜가 필요 없다면 문자열을 쪼개서 시각에 대한 정보만 취하면 될 것이다.</description>
    </item>
    
    <item>
      <title>수치해석에서의 인터폴레이션</title>
      <link>https://freshrimpsushi.github.io/posts/interpolation-in-numerical-analysis/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interpolation-in-numerical-analysis/</guid>
      <description>정의 1 주어진 $(n+1)$쌍의 데이터 $(x_{0}, y_{0}) , \cdots , (x_{n} , y_{n})$ 에 대해 $f (x_{i} ) = y_{i}$ 를 만족하면서 어떤 특정한 성질을 가지는 $f$ 를 찾는 방법이나 그 함수 자체를 보간법 혹은 내삽법이라 한다. 설명 예를 들어 위와 같이 데이터가 있긴한데 가운데 데이터가 비어있는 상황을 생각해보자. 물론 실제 데이터가 있는게 가장 좋지만, 없으면 예측이라도 해서 써야할 상황이 있</description>
    </item>
    
    <item>
      <title>카오틱 트랜지션</title>
      <link>https://freshrimpsushi.github.io/posts/chaotic-transition/</link>
      <pubDate>Thu, 02 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaotic-transition/</guid>
      <description>정의 시스템이 파라매터의 변화에 따라 카오틱해지거나 카오틱해지지 않는 등의 현상을 카오틱 트랜지션이라 한다. 예시 예로써 로지스틱 패밀리를 생각해보면 $g_{a} = ax (1-x)$ 로 만들어지는 시스템은 파라매터 $a$ 에 따라 달라지는 모습을 보이다가 $a=4$ 일 때 카오틱 오빗을 가짐을 확인할 수 있다. 그러면 그 다음 질문은 바로 &amp;lsquo;$a&amp;gt;4$ 일 때는 어떻게 될 것인가&amp;rsquo;다. 우</description>
    </item>
    
    <item>
      <title>디키-풀러 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/dickey-fuller-test/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dickey-fuller-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 시계열 데이터 $\left\{ y_{t} \right\}$ 가 주어져 있다고 하자. $H_{0}$ : 데이터 $\left\{ y_{t} \right\}$ 는 정상성을 가지지 않는다. $H_{1}$ : 데이터 $\left\{ y_{t} \right\}$ 는 정상성을 갖는다. 디키-풀러 테스트는 시계열 데이터가 정상성을 가지는지 가지지 않는지를 확인할 때 사용한다. 정상성을 가지지 않으면 차분을 통해 평균을 일정하게 만들어주어야 한다.</description>
    </item>
    
    <item>
      <title>지도학습과 비지도학습</title>
      <link>https://freshrimpsushi.github.io/posts/supervised-learning-vs-unsupervised-learning/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/supervised-learning-vs-unsupervised-learning/</guid>
      <description>정의 머신러닝에서 종속변수가 정해진 경우를 지도학습, 그렇지 않은 경우를 비지도학습이라고 한다. 예시 지도학습과 비지도학습의 차이는 쉽게 비유하자면 객관식과 주관식의 차이다. 예를 들어 위와 같이 6개의 타일을 주고 색을 답하는 문제가 있다고 해보자. 지도학습 그런데 여기서 녹색이냐 적색이냐의 두 가지 선택지만 있다면 솔직히 반반도 있고 아예 노란</description>
    </item>
    
    <item>
      <title>수학에서의 경사하강법</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-descent-method/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-descent-method/</guid>
      <description>정의 1 스칼라 함수 $\varphi : \mathbb{R}^{n} \to \mathbb{R}$ 을 비용 함수Cost Function이라 한다. 비용 함수 $ \varphi ( \mathbb{x} )$ 의 극소값을 구하기 위해 $\mathbb{x} = \mathbb{x}_{n}$ 에서 $\varphi ( \mathbb{x}_{n+1} ) &amp;lt; \varphi ( \mathbb{x}_{n} )$ 를 만족시키는 $\mathbb{x}_{n+1}$ 를 찾는 알고리즘을 하강법Descent Method이라 한다. 설명 $\varphi$ 를 비용 함수라고 부를만한 예로써 집을 한 채 짓는다고 하자. 집 한 채에 들어가는 자원은 목재, 석재, 철</description>
    </item>
    
    <item>
      <title>네츄럴 인베리언트 메져</title>
      <link>https://freshrimpsushi.github.io/posts/natural-invariant-measure/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/natural-invariant-measure/</guid>
      <description>정의 1 카오틱한 동역학계에서 충분히 시간이 지난 뒤의 스테이트를 확률적으로 나타낸 분포함수를 네츄럴 (인베리언트) 메져라 한다. 예시 1 예로써 로지스틱 맵 $g_{4} (x) = 4 x (1 -x)$ 를 생각해보면 카오틱한 시스템이기 때문에 초기값 $x_{0} \in [0,1]$ 만 가지고는 충분히 큰 $N$ 에 대해 $x_{N} = g_{4}^{N} (x_{0})$ 을 전혀 예측할 수 없다. 하지만 이렇게 카오틱한 오빗이 반드시 $[0,1]$ 의 모든 지점에서</description>
    </item>
    
    <item>
      <title>스칼라 필드의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-in-scalar-field/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-in-scalar-field/</guid>
      <description>정의 스칼라 필드 $f : \mathbb{R}^{n} \to \mathbb{R}$의 전 도함수를 특별히 그래디언트gradient, 기울기라 부르고 $\nabla f$라 표기한다. $$ \begin{align*} \nabla f := f^{\prime} =&amp;amp; \begin{bmatrix} D_{1}f &amp;amp; D_{2}f &amp;amp; \cdots &amp;amp; D_{n}f\end{bmatrix} \\ =&amp;amp; \begin{bmatrix} \dfrac{\partial f}{\partial x_{1}} &amp;amp; \dfrac{\partial f}{\partial x_{2}} &amp;amp; \cdots &amp;amp; \dfrac{\partial f}{\partial x_{n}} \end{bmatrix} \\ =&amp;amp; \dfrac{\partial f}{\partial x_{1}}\hat{x}_{1} + \dfrac{\partial f}{\partial x_{2}}\hat{x}_{2} + \dots + \dfrac{\partial f}{\partial x_{n}}\hat{x}_{n} \end{align*} $$ 설명 그래디언트는 쉽게 말해 다변수 함수의 도함수이다. 물리학 등에서 자주 쓰이는 3차원 스칼</description>
    </item>
    
    <item>
      <title>바이퍼케이션 다이어그램</title>
      <link>https://freshrimpsushi.github.io/posts/bifurcation-diagram/</link>
      <pubDate>Sat, 27 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bifurcation-diagram/</guid>
      <description>정의 동역학계에서 파라매터의 변화에 따라 나타나는 오빗을 표현한 그림을 바이퍼케이션 다이어그램이라 한다. 예시1 예로써 로지스틱 패밀리를 생각해보면 파라매터 $a$ 의 변화에 따라 충분히 큰 $N$ 에 대해 $x_{N}$ 의 값은 다음 바이퍼케이션 다이어그램의 검은색 범위 안에 포함된다고 예상할 수 있다. $1&amp;lt;a&amp;lt;3$ 일 때는 하나의 선인 것을 보아 $x_N$ 은 하나의 고정점에서 머무르고,</description>
    </item>
    
    <item>
      <title>넌리니어 시스템을 풀기 위한 뉴턴 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/newton-method-for-nonlinear-system/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newton-method-for-nonlinear-system/</guid>
      <description>메소드 1 $\mathbb{f} ( \mathbb{x} ) := \begin{bmatrix} f_{1}( \mathbb{x} ) \\ \vdots \\ f_{N} ( \mathbb{x} ) \end{bmatrix}$ 와 같은 다변수 함수 $\mathbb{f} : \mathbb{R}^{N} \to \mathbb{R}^{N}$ 가 $\mathbb{f} \in C^{2} \left( N ( \alpha ) \right)$ 이고 $\mathbb{f} ( \alpha ) = \mathbb{0}$, $\left[ D \mathbb{f} ( \alpha ) \right]^{-1}$ 이 존재한다고 하자. $\alpha$ 와 충분히 가까운 초기값 $\mathbb{x}_{0}$ 에 대해 $$ \mathbb{x}_{n+1} := \mathbb{x}_{n} - \left[ D \mathbb{f} ( \mathbb{x}_{n} ) \right]^{-1} f ( \mathbb{x}_{n} ) $$ 과 같이 정의된 수열 $\left\{ \mathbb{x}_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 쿼드러틱하게 수렴한다. $\mathbb{f} \in C^{2} \left( N ( \alpha ) \right)$ 이라는 것은 $\alpha$ 의 근방에서</description>
    </item>
    
    <item>
      <title>딥러닝에서의 드롭아웃</title>
      <link>https://freshrimpsushi.github.io/posts/dropout/</link>
      <pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dropout/</guid>
      <description>정의 드롭아웃Dropout이란 인공 신경망의 뉴런을 확률적으로 사용하지 않음으로써 과적합을 방지하는 기법이다. 설명 언뜻 생각하면 그냥 학습을 덜 하는 것이고 실제로도 어느정도는 맞는 말이다. 일정 확률로 뉴런을 사용하지 않다보면 &amp;lsquo;영향력이 지나치게 강한&amp;rsquo; 뉴런이 무시될 수도 있다. 영향력이 지나치게 강하다는 것은</description>
    </item>
    
    <item>
      <title>R 에서 야코비 행렬 헤세 행렬 구하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-jacobian-matrix-hessian-matrix-in-r/</link>
      <pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-jacobian-matrix-hessian-matrix-in-r/</guid>
      <description>코드 R 에서 야코비 행렬과 헤세 행렬을 구하기 위해서는 numDeriv 패키지의 jacobian() 함수와 hessian() 함수를 사용한다. install.packages(&amp;#34;numDeriv&amp;#34;) library(numDeriv) f &amp;lt;- function(v) {c(v[1]^2 + v[2]^2 - 1, sin(pi*v[1]/2) + v[2]^3)} g &amp;lt;- function(v) {(v[1])^3+(v[2])^2} jacobian(f, c(1,1)) hessian(g, c(1,1)) 위 코드를 실행시킨 결과는 다음과 같다. 위는 $f(x,y) := \begin{bmatrix} x^2 + y^2 -1 \\ \displaystyle \sin {{ \pi } \over {2} } x + y^3 \end{bmatrix}$ 의 야코비 행렬에 $x=y=1$ 을 대입한 결과, 아래는 $g(x,y) := x^3 + y^2$ 의 헤세 행렬에 $x=y=1$ 을 대입한 결과다. 실제로 $f$ 의 야코비 행렬은</description>
    </item>
    
    <item>
      <title>딥러닝에서의 소프트맥스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/softmax-function/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/softmax-function/</guid>
      <description>정의 $\mathbb{x} := x_{1} , \cdots , x_{n} \in \mathbb{R}^{n}$ 이라고 하자. $\displaystyle \sigma ( \mathbb{x} ) = {{ e^{x_{j}} } \over {\sum_{i=1}^{n} e^{x_{i}} }}$ 에 대해 $\sigma( \mathbb{x} ) := \left( \sigma_{1} (\mathbb{x}) , \cdots , \sigma_{n} (\mathbb{x} ) \right)$ 와 같이 정의된 $\sigma : \mathbb{R}^{n} \to (0,1)^{n}$ 을 소프트맥스 함수라 한다. 설명 소프트맥스 함수는 활성화 함수의 일종으로써, 정의역이 $\mathbb{R}^{n}$ 이라는 특징이 있다. 이는 벡터로 인풋을 받아 그 값들을 정규화하는데에 쓰기 위함이다. 어떤 $\mathbb{x} \in \mathbb{R}$ 이든 $\sigma( \mathbb{x} )$ 의 모든 성분은</description>
    </item>
    
    <item>
      <title>헤세 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/hessian-matrix/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hessian-matrix/</guid>
      <description>정의 $D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 스칼라 함수 $f : D \to \mathbb{R}$ 에 대해 다음과 같은 행렬 $H \in \mathbb{R}^{n \times n}$ 을 $f$ 의 헤세 행렬이라 한다. $$ H := \begin{bmatrix} {{\partial^2 f } \over {\partial x_{1}^2 }} &amp;amp; \cdots &amp;amp; {{\partial^2 f } \over { \partial x_{1} \partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial^2 f } \over {\partial x_{n} \partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial^2 f_{m} } \over {\partial x_{n}^2 }} \end{bmatrix} $$ 설명 야코비 행렬이 함수의 고차원적인 도함수에 해당한다면, 헤세 행렬은 고차원적인 이계도함수라고 볼 수 있다.</description>
    </item>
    
    <item>
      <title>딥러닝에서의 활성화 함수</title>
      <link>https://freshrimpsushi.github.io/posts/activation-function/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/activation-function/</guid>
      <description>정의 실제 생물의 역치를 모방한 비선형 함수를 활성화 함수라 한다. 모티브 역치란 생물이 자극에 대해 어떤 반응을 일으키는 데 필요한 최소한의 자극의 세기로써, 딥러닝은 이를 모방하기 위해 각 노드의 계산 결과에 활성화 함수를 취해 다음 레이어로 넘긴다. 이러한 비선형적 보정이 없다면 딥러닝에서 히든 레이어를 두며 계산을 여러번 하는 의미가 없다.활성화 함</description>
    </item>
    
    <item>
      <title>딥러닝이란?</title>
      <link>https://freshrimpsushi.github.io/posts/deep-learning/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/deep-learning/</guid>
      <description>정의 딥러닝은 인공 신경망을 이용한 머신러닝의 일종으로, 특히 인공 신경망을 구성할 때 복수의 레이어를 사용하는 기법을 말한다. 모티브 인간의 두뇌가 뉴런들의 복잡한 연결관계로 구성된 것처럼 딥러닝 역시 인공 신경망을 보다 복잡하게 연결해서 퍼포먼스를 올린다. 감각세포에서 받은 자극이 척수를 통해 뇌로 전달되는 것처럼, 인공 신경망은 여러 레이어를</description>
    </item>
    
    <item>
      <title>야코비 행렬 혹은 자코비 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/jacobian-matrix/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jacobian-matrix/</guid>
      <description>정의 $D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 벡터 함수 $\mathbb{f} : D \to \mathbb{R}^{m}$ 가 각각의 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ 과 같이 정의되었다고 하자. $$ J := \begin{bmatrix} {{\partial f_{1} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{1} } \over {\partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial f_{m} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{m} } \over {\partial x_{n} }} \end{bmatrix} $$ 을 $\mathbb{f}$ 의 야코비 행렬이라 한다. 설명</description>
    </item>
    
    <item>
      <title>머신러닝에서의 경사하강법</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-descent-algorithm/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-descent-algorithm/</guid>
      <description>개요 손실 함수의 기울기를 이용해 손실 함수의 극소값을 찾는 알고리즘 중 가장 간단한 방법으로 경사하강법Gradient Descent Algorithm이 있다. 설명 단, 이 때의 손실 함수 $L$ 은 데이터 셋 $X$ 가 픽스 된 상태에서 가중치와 바이어스에 대한 함수로 본다. 만약 인풋 데이터가 $\mathbb{x} \in \mathbb{R}^{m}$ 처럼 생겼다면 $L$ 은 $(w_{1} , w_{2} , \cdots , w_{m} , b) \in \mathbb{R}^{m+1}$ 에 대한 함수가 되는 것이다</description>
    </item>
    
    <item>
      <title>슈발치언 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/schwarzian-derivative/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schwarzian-derivative/</guid>
      <description>정의1 $p$ 가 스무스한 맵 $f : \mathbb{R} \to \mathbb{R}$ 의 고정점 혹은 피리어딕 포인트라고 하자. $f &#39; (c) = 0$ 인 $c$ 를 $f$ 의 크리티컬 포인트Critical Point라 한다. $p$ 의 베이신이 길이가 무한한 인터벌을 포함하면 인피닛 베이신Infinite Basin이라 한다. $\displaystyle S(f)(x) := {{f&amp;rsquo;&amp;rsquo;&amp;rsquo;(x) } \over { f &#39;(x) }} - {{3} \over {2}} \left( {{f&amp;rsquo;&amp;rsquo;&amp;rsquo;(x) } \over { f &#39;(x) }} \right)^2$ 를 $f$ 의 슈발치언 도함수라 한다. $f &#39;</description>
    </item>
    
    <item>
      <title>R 에서 복소수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-complex-number-in-r/</link>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-complex-number-in-r/</guid>
      <description>개요 R 에는 복소수 자료형이 구현되어있다. 굳이 스스로 구현할 필요 없이 가져다 쓰기만 하면 된다. 사칙연산은 물론 복소수를 다룰 때 빠질 수 없는 여러가지 함수 역시 만들어져 있다. 코드 $z_{1} : = 1- i$, $z_{2} := 1+ i$ 이라고 하자. z_1 = 1-1i z_2 = 1+1i z_1 + z_2 z_1 - z_2 z_1 * z_2 z_1 / z_2 Re(z_1) Im(z_1) Mod(z_1) Arg(z_1) Conj(z_1) 위의 코드를 실행시키면 다음과 같은 결과를 얻을 수 있다. 수식으로 확인해보자.</description>
    </item>
    
    <item>
      <title>R 에서 정적분 구하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-integrate-in-r/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-integrate-in-r/</guid>
      <description>개요 R 에서 정적분을 구하기 위해선 integrate() 함수를 사용할 수 있다. 예를 들어 코드 $\displaystyle \int_{0}^{3} \left( x^2 + 4x + 1 \right) dx$ 과 $\displaystyle \int_{0}^{\infty} e^{-x} dx$ 은 다음과 같이 구할 수 있다. 특히 적분구간에는 inf를 넣음으로써 이상적분까지 할 수 있다. f&amp;lt;-function(x) {x^2 + 4*x + 1} g&amp;lt;-function(x) {exp(-x)} integrate(f,0,3) integrate(g,0,Inf) 실제로 계산해보면 $$ \int_{0}^{3} \left( x^2 + 4x + 1 \right) dx = \left[ {{1} \over {3}} x^{3} + 2 x^2 + x \right]_{x=0}^{3} = 9 + 18 + 3 = 30 $$ 이고 $$ \int_{0}^{\infty} e^{-x} dx = \left[ - e^{-x} \right]_{x = 0}^{\infty} =</description>
    </item>
    
    <item>
      <title>뮬러 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/muller-method/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/muller-method/</guid>
      <description>메소드 $f (\alpha) = 0$ 이라고 하자. 초기값 $x_{0} , x_{1} , x_{2}$ 과 $$ w_{n} := f [x_{n} , x_{n-1} ] + f [ x_{n} , x_{n-2} ] - f [ x_{n-2} , x_{n-1} ] $$ 에 대해 $$ x_{n+1} : = x_{n} - {{ 2 f ( x_{n} ) } \over { w_{n} \pm \sqrt{ w_{n}^{2} - 4 f (x_{n} ) f [ x_{n} , x_{n-1} , x_{n-2} ] } }} $$ 과 같이 정의된 수열 $\left\{ x_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 $p \approx 1.84$ 차 수렴한다. 단, $\left( w_{n} \pm \sqrt{ w_{n}^{2} - 4 f (x_{n} ) f [ x_{n} , x_{n-1} , x_{n-2} ] } \right) \in \mathbb{C}$ 는 $+$ 와 $-$ 둘 중 $\left| w_{n} \pm \sqrt{ w_{n}^{2} - 4 f (x_{n}</description>
    </item>
    
    <item>
      <title>R 에서 미분계수 구하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-differentiate-in-r/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-differentiate-in-r/</guid>
      <description>개요 R 에서 미분계수를 구하기 위해선 numDeriv 패키지의 grad() 함수를 사용할 수 있다. 코드 예를 들어 $f(x) = x^2 + 4x + 1$ 과 $g(x) = e^{-x}$ 의 미분계수는 다음과 같이 구할 수 있다. install.packages(&amp;#34;numDeriv&amp;#34;) library(numDeriv) f&amp;lt;-function(x) {x^2 + 4*x + 1} g&amp;lt;-function(x) {exp(-x)} grad(f,2) grad(g,0) 실제로 계산해보면 $f &#39; (2) = 2 \cdot 2 + 4 = 8$ 이고 $g&#39;(0) = - e^{0} = -1$ 인 것을 확인할 수 있다. 참고로 스칼라 함수의 경우에도 x 옵션에 벡터를 넣어주면 그래디언트를 잘 계산해준</description>
    </item>
    
    <item>
      <title>스칼라 함수와 벡터 함수</title>
      <link>https://freshrimpsushi.github.io/posts/scalar-function-and-vector-function/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scalar-function-and-vector-function/</guid>
      <description>정의 집합 $D$ 를 $n$차원 유클리드 공간의 부분집합 $D\subset \mathbb{R}^{n}$ 이라 하자. $D$ 를 정의역으로 갖는 함수를 다변수 함수라 한다. $f : D \to \mathbb{R}$ 을 스칼라 함수라 한다. 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 다음과 같이 정의된 $\mathbb{f} : D \to \mathbb{R}^{m}$ 를 벡터 함수라 한다. $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ 설명 다변수 함수 다변수 함수라</description>
    </item>
    
    <item>
      <title>카오스 이론에서 맵들의 컨쥬게이트</title>
      <link>https://freshrimpsushi.github.io/posts/conjugate-of-maps-in-chaos-theory/</link>
      <pubDate>Tue, 09 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conjugate-of-maps-in-chaos-theory/</guid>
      <description>개요 카오스 이론에서 맵의 컨쥬게이트는 일종의 아이소메트리, 아이소멀피즘과 비슷하며, 사실 더 일반적인 동역학의 맥락에서는 호메오멀피즘 그 자체다. 1 교재에 따라 완전히 같지는 않을 수 있지만 용도는 정확히 같다. 수학에서 하는 일이 다 그렇듯, 계산이 쉬운 곳에서 어떤 성질이 있음을 확인한 후 실제로 증명이 필요한 곳으로 그 성질을 보존 시키는 것이다</description>
    </item>
    
    <item>
      <title>머신러닝에서의 손실 함수</title>
      <link>https://freshrimpsushi.github.io/posts/loss-function/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/loss-function/</guid>
      <description>정의 데이터 $Y = \begin{bmatrix} y_{1} \\ \vdots \\ y_{n} \end{bmatrix}$ 에 대한 추정치가 $\widehat{Y} = \begin{bmatrix} \widehat{ y_{1} } \\ \vdots \\ \widehat{y_{n}} \end{bmatrix}$ 와 같이 주어져 있을 때 데이터와 추정치의 괴리도를 나태는 스칼라 함수 $L : \mathbb{R}^{n} \to [ 0 , \infty )$ 를 손실 함수라 한다. 다른 이름 손실 함수는 학습을 통해 얻은 데이터의 추정치가 실제 데이터와 얼마나 차이나는지 평가하는 지표로 쓰인다. 이 값이 크면 클수록 많이 틀렸다는 의미고, 이 값이 $0$</description>
    </item>
    
    <item>
      <title>로지스틱 패밀리</title>
      <link>https://freshrimpsushi.github.io/posts/logistic-family/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logistic-family/</guid>
      <description>정의 1 $a \ge 0$ 에 대해 $g_{a} (x) = a x ( 1 - x )$ 를 로지스틱 맵Logistic Map이라고 하고 $\left\{ g_{a} \mid a &amp;gt; 0 \right\}$ 을 로지스틱 패밀리Logistic Family라고 한다. 성질 [1]: $x \in [0,1] \iff g_{a} (x) \ge 0$ [2]: $g&#39;_{a} (x) = a ( 1 - 2x)$ [3]: $1 &amp;lt; a \le 4$ 이면 $\displaystyle x_{1} = {{ a - 1} \over { a }}$ 는 $g_{a} (x)$ 의 고정점이다. [4]: $1 &amp;lt; a &amp;lt; 3$ 이면 $$ \lim_{ k \to \infty} f^{k} (x) = x_{1} = {{a-1} \over {a}} $$ 설명 로지</description>
    </item>
    
    <item>
      <title>수학에서의 그래프와 네트워크</title>
      <link>https://freshrimpsushi.github.io/posts/graph-and-network-in-mathematics/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/graph-and-network-in-mathematics/</guid>
      <description>정의 1 정점과 정점들을 연결한 선들로 이루어진 집합을 그래프 혹은 네트워크라고 한다. 정점들의 집합을 $V$, 선들의 집합을 $E$라고 하자. $V(G) := V$ 의 원소를 $G$ 의 버텍스Vertex 혹은 노드Node라고 한다. $E(G) := E$ 의 원소를 $G$ 의 에지Edge 혹은 링크Link라고 한다. 자기 자신으로 이어진 에지를 루프Loop라고 한다. 두 버텍스가 에지로 이</description>
    </item>
    
    <item>
      <title>샤르코우스키 정리</title>
      <link>https://freshrimpsushi.github.io/posts/sharkovskiis-theorem/</link>
      <pubDate>Sat, 06 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sharkovskiis-theorem/</guid>
      <description>정리 1 $$ 3 \prec 5 \prec 7 \prec 9 \prec \cdots \prec \\ 2\cdot 3 \prec 2 \cdot 5 \prec \cdots \prec \\ 2^2 3 \prec 2^2 5 \prec \cdots \prec \\ 2^3 3 \prec 2^3 5^2 \prec \cdots \prec \\ 2^3 \prec 2^2 \prec 2^1 \prec 2^0 $$ 추이적 관계 $\prec$ 에 대해 위와 같은 순서를 샤르코우스키 오더링이라 한다. 연속 맵 $f : \mathbb{R} \to \mathbb{R}$ 이 피리어딕-$p$ 오빗을 갖는다고 하자. $p \prec q$ 면 $f$ 는 피리어딕-$q$ 오빗을 갖는다. 설명 샤르코우스키 정리Sharkovskii</description>
    </item>
    
    <item>
      <title>인공 신경망이란?</title>
      <link>https://freshrimpsushi.github.io/posts/ann-artificial-neural-network/</link>
      <pubDate>Sat, 06 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ann-artificial-neural-network/</guid>
      <description>정의 실제 생물의 신경계를 모방한 네트워크를 인공 신경망이라 한다. 모티브 신경계는 뉴런들의 결합으로 구성되어있다. 신경세포체는 가지돌기를 통해 자극을 받아들이며, 축삭돌기를 통해 전기자극을 전달한다. 인간을 포함한 많은 생물들은 이렇듯 단순한 뉴런들의 결합을 환경에 적합하도록 진화시켜왔다. 그 결과 신경계는 빛을 감지하거나, 다리를 움직</description>
    </item>
    
    <item>
      <title>리-요크 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-li-yorke-theorem/</link>
      <pubDate>Fri, 05 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-li-yorke-theorem/</guid>
      <description>정리 연속 맵 $f: [a,b] \to [a,b]$ 의 피리어딕-$3$ 오빗이 존재하면 $f$ 는 캐어릭하다. 설명 리-요크 정리Li-Yorke Theorem는 삼주기 정리Period-$3$ Theorem라도 불리며, 피리어딕-$3$ 가 혼돈을 야기한다는 스테이트먼트 자체로도 많이 언급된다. 물론 이 정리만 보면 $1$차원 맵에 한정되어 있지만 고작 피리어딕-$3</description>
    </item>
    
    <item>
      <title>1차원 맵의 혼돈, 카오스</title>
      <link>https://freshrimpsushi.github.io/posts/chaos-of-one-dimensional-map/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaos-of-one-dimensional-map/</guid>
      <description>정의 캐어릭 오빗1 맵 $f : \mathbb{R} \to \mathbb{R}$ 의 바운디드 오빗 $\left\{ x_{1} , x_{2} , \cdots \right\}$ 이 다음을 만족하면 이 오빗을 캐어릭Chaotic하다고 한다. (i) 어심토티컬리 피리어딕이 아니다. (ii): $h (x_{1} ) &amp;gt; 0$ 바운디드 오빗이란 모든 $n \in \mathbb{N}$ 에 대해 $|x_{n} | &amp;lt; M$ 을 만족하는 $M \in \mathbb{R}$ 이 존재한다는 뜻이다. $h(x_{1} )$ 은 랴푸노프 지수를 말한다. 캐어릭 맵 모든 $n \in \mathbb{N}$ 에 대해 피리어딕-$n$</description>
    </item>
    
    <item>
      <title>윈도에서 파이썬 텐서플로우 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-tensorflow-in-windows/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-tensorflow-in-windows/</guid>
      <description>가이드 텐서플로우를 설치할 때 문제가 생기는 경우는 보통 파이썬을 잘못 설치했기 때문이다. 시작하기 전에 파이썬을 삭제하고 처음부터 다시 시작하거나, 가능하다면 컴퓨터를 한 번 밀어두는 것을 추천한다. **Step 1. 파이썬 **Step 1-1. 비트 확인 제어판/모든 제어판 항목/시스템 혹은 내 PC(우클릭)-속성을 통해 시스템 정보를 확인하자.요즘은 대개 64비트기</description>
    </item>
    
    <item>
      <title>1차원 맵의 랴푸노프 수</title>
      <link>https://freshrimpsushi.github.io/posts/lyapunov-number-of-one-dimensional-map/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lyapunov-number-of-one-dimensional-map/</guid>
      <description>정의1 스무스한 $1$차원 맵 $f : \mathbb{R} \to \mathbb{R}$ 의 한 오빗 $\left\{ x_{1} , x_{2} , x_{3} , \cdots \right\}$ 에 대해 $$L ( x_{1} ) : = \lim_{ n \to \infty } \left( \prod_{i = 1}^{n} | f &#39; (x_{i} ) | \right)^{1/n}$$ 을 랴푸노프 수Lyapunov Number라 하고 $$ h ( x_{1} ) := \lim_{n \to \infty } {{1} \over {n}} \sum_{i=1}^{n} \ln | f &#39; (x_{i} ) |$$ 을 랴푸노프 지수Lyapunov Exponent라 한다. 설명 싱크와 소스의 개념을 다시금 생각해보면 싱크란 가</description>
    </item>
    
    <item>
      <title>위너 프로세스</title>
      <link>https://freshrimpsushi.github.io/posts/wiener-process/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/wiener-process/</guid>
      <description>정의 $s&amp;lt; t &amp;lt; t+u$ 라고 할 때, 다음의 조건들을 만족하는 확률과정 $\left\{ W_{t} \right\}$ 를 위너 프로세스라 한다. (i): $W_{0} = 0$ (ii): $\left( W_{t+u} - W_{t} \right) \perp W_{s}$ (iii): $\left( W_{t+u} - W_{t} \right) \sim N ( 0, u )$ (iv): $W_{t}$ 의 샘플 패스는 거의 어디서나 연속이다. 기초 성질 [1]: $\displaystyle W_{t} \sim N ( 0 , t ) $ [2]: $\displaystyle E ( W_{t} ) = 0$ [3]: $\displaystyle \text{Var} ( W_{t} ) = t$ [4]: $\displaystyle \text{cov} ( W_{t} , W_{s} ) = {{1} \over {2}} (|t| + |s| - |t-s|) = \min \left\{ t , s \right\}$ 설명 위너 프로세스는 브라운</description>
    </item>
    
    <item>
      <title>맵 시스템의 오빗</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-of-map-system/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-of-map-system/</guid>
      <description>정의1 맵 $f : X \to X$ 와 $p \in X$ 에 대해 $f^{k} (p) = p$ 를 만족하는 가장 작은 자연수가 $k \in \mathbb{N}$ 라고 하자. 맵 $f : X \to X$ 와 점 $x \in X$ 에 대해 집합 $\left\{ x , f(x) , f^{2} , \cdots \right\}$ 를 $f$ 하에서 $x$ 의 오빗Orbit이라 한다. 이 때 $x$ 를 오빗의 초기값Initial Value이라 한다. 초기값 $p$ 를 가지는 오빗 $\left\{ p , f (p) , f^{2} (p) , \cdots \right\}$ 을 피리어딕-$k$ 오빗이라 하고, $p$</description>
    </item>
    
    <item>
      <title>준소수</title>
      <link>https://freshrimpsushi.github.io/posts/semiprime/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/semiprime/</guid>
      <description>정의 두 소수의 곱을 준소수Semiprime라 한다. 설명 준소수의 예로써 $4 = 2 \cdot 2$ 이나 $21 = 3 \cdot 7$, $673703 = 719 \cdot 937$ 등이 있다. 일본어 번역으로는 반소수半素數라고도 하는데, 한국어 문서로는 준소수나 반소수나 둘 다 찾아보기 어렵다. 본질적으로 준소수는 준소수 자체가 아니라 소수의 성질을 어느정도 이어받아서 응용된다. 예를들어 제법 큰 두 개의 소</description>
    </item>
    
    <item>
      <title>1차원 맵의 싱크와 소스 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/sink-and-source-of-one-dimensional-map/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sink-and-source-of-one-dimensional-map/</guid>
      <description>정리1 스무스한 맵 $f : \mathbb{R} \to \mathbb{R}$ 에 대해 어떤 $p \in \mathbb{R}$ 가 고정점이라고 하자. [1] $| f &#39; (p) | &amp;lt; 1$ 이면 $p$ 는 싱크다. [2] $| f &#39; (p) | &amp;gt; 1$ 이면 $p$ 는 소스다. 예시 $1$차원 맵의 예로써 $f(x) = x^3$ 을 생각해보면 $f &#39; (x) = 3x^{2}$ 이므로 고정점 $f(0) = 0$ 은 싱크, $f(1) = 1$ 은 소스임을 쉽게 확인할 수 있다. 증명 정리 [1]의 증명 $a \in \left( | f &#39;(p) | , 1 \right)$ 이라고 하자. $$ \lim_{x \to p} {{</description>
    </item>
    
    <item>
      <title>하르케-베라 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/jarque-bera-test/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jarque-bera-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 샤피로-윌크 테스트 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 가 주어져 있다고 하자. $H_{0}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따른다. $H_{1}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따르지 않는다. 하르케-베라 테스트는 정규성을 검정하기 위해 사용하는 테스트로써, 보통은 정규성이 있음을 보이기 위해서 사용한다. 귀무가설이 채</description>
    </item>
    
    <item>
      <title>바나흐 고정점 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-banach-fixed-point-theorem/</link>
      <pubDate>Sun, 31 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-banach-fixed-point-theorem/</guid>
      <description>정의 $(X, \left\| \cdot \right\|)$를 바나흐 공간이라고 하자. 모든 $x, \tilde{x} \in X$ 와 $0 \le r &amp;lt; 1$ 에 대해 $\| T(x) - T ( \tilde{x} ) \| \le r \| x - \tilde{x} \|$ 를 만족하는 $T : X \to X$ 를 축소 사상contraction mapping이라 정의한다. $T ( \alpha ) = \alpha$ 를 만족하는 $\alpha \in X$를 고정점이라 한다. 정리 1 $T$의 고정점은 유일하게 존재한다. 설명 바나흐 고정점 정</description>
    </item>
    
    <item>
      <title>R 에서 현재 OS 정보 확인하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-operating-system-in-r/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-operating-system-in-r/</guid>
      <description>개요 R 은 이래저래 리눅스에서도 사용할 일이 있이 많다. 대표적으로 빅데이터를 다루기 위해 하둡을 쓰는 경우가 있다. 물론 윈도우나 리눅스나 R 자체는 크게 다른 게 없지만, 작업환경이 다르기 때문에 작업경로가 달라져서 파일의 입출력이 다소 귀찮아지는 경우가 있다. 작업환경에 관계 없이 작업경로를 편하게 설정하기 위해선 현재의 OS가 어떤 것인지 확인</description>
    </item>
    
    <item>
      <title>로그의 밑변환 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/logarithmic-identities/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logarithmic-identities/</guid>
      <description>공식 임의의 양수 $c&amp;gt;0$ 에 대해, $$ \log_{a} b = {{ \log_{c} b } \over { \log_{c} a }} $$ 설명 현대에 와서 공식 자체만으로는 의미가 없어졌지만 입시에서는 여전히 중요한 공식이다. 간단한 성질이라고 해서 깔보지 말고 &amp;lsquo;공식&amp;rsquo;이라는 이름에 걸맞는 수준의 연습문제를 많이 풀어보는 것을 추천한다. 유도 $x := \log_{a} b$ 라고 하면 로그의 정의에 따라 $$ a^x = b $$ 양</description>
    </item>
    
    <item>
      <title>확률과정론의 인크리먼트</title>
      <link>https://freshrimpsushi.github.io/posts/increment-of-stochastic-process/</link>
      <pubDate>Wed, 27 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/increment-of-stochastic-process/</guid>
      <description>정의 확률과정 $\xi(t)$ 이 시간 $T$ 에서 정의되었고 $t_{0} &amp;lt; t_{1} &amp;lt; \cdots &amp;lt; t_{n} \in T$ 이라고 하자. $\xi ( t ) - \xi ( s )$ 를 인크리먼트라 한다. 모든 $i=1, \cdots , n$ 에 대해 $\xi ( t_{i} ) - \xi ( t_{i-1} )$ 들이 서로 독립이면 $\xi(t)$ 이 독립 인크리먼트Independent Increment를 갖는다고 한다. 모든 $h&amp;gt;0$ 와 $t,s,t+h,s+h \in T$ 에 대해 $\xi (t+h) - \xi ( s + h )$ 가 같은 확률분포를 가지면 $\xi(t)$ 이 정상적</description>
    </item>
    
    <item>
      <title>이산로그 문제가 쉽게 풀리는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/condition-for-discrete-log-problem-be-solved-easily/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/condition-for-discrete-log-problem-be-solved-easily/</guid>
      <description>정리 1 그룹 $G = F_{p}$ 의 원소 $g$ 가 오더 $N$ 이라고 하자. 그러면 이산로그 문제 $g^{x} = h$ 는 다음의 조건 하에서 비교적 쉽게 풀리게 된다. (i): $p$ 가 스무스 소수다. (ii): $p \equiv 3 \pmod{4}$ 고 $a$ 가 모듈로 $p$ 에 대한 이차잉여다. 증명 (i) $p$ 가 스무스한 소수면 폴리그-헬맨 알고리즘을 사용할 수 있으므로 이산로그 문제는 비교적 쉽게 풀린다. ■ (ii) $$ x^{2} \equiv a \pmod{p} $$ $a$ 가 모듈로 $p$ 에 대한 이</description>
    </item>
    
    <item>
      <title>시컨트 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/secant-method/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/secant-method/</guid>
      <description>메소드 $f,f&amp;rsquo;,f&amp;rsquo;&amp;rsquo;$ 가 $\alpha$ 의 근방에서 연속이고 $f(\alpha) = 0, f &#39;(\alpha) \ne 0$ 이라고 하자. $\alpha$ 와 충분히 가까운 초기값 $x_{0} , x_{1}$ 에 대해 $$ x_{n+1} := x_{n} - f ( x_{n} ) {{ x_{n} - x_{n-1} } \over { f ( x_{n} ) - f ( x_{n-1} ) }} $$ 과 같이 정의된 수열 $\left\{ x_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 $\displaystyle {{1 + \sqrt{5} } \over {2}}$ 차 수렴한다. 설명 황금비 수렴차수가 상당히 낯이 익을 것이다. 바로 황금비인 $\displaystyle {{1 + \sqrt{5} } \over {2}} = 1.618 \cdots$ 인데, 수열의 정의에</description>
    </item>
    
    <item>
      <title>아리마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/arima-model-intergrated-autoregressive-moving-average-model/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arima-model-intergrated-autoregressive-moving-average-model/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $$ \nabla^{d} Y_{t} := \sum_{i = 1}^{p} \phi_{i} \nabla^{d} Y_{t-i} + e_{t} - \sum_{i = 1}^{q} \theta_{i} e_{t-i} $$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 $(p,d,q)$차 아리마 과정 $ARIMA (p,d,q)$ 라고 한다. 이와 같은 꼴을 한 시계열 분석 모형을 아리마 모형이라고 한다. 설명 $ARI(p,d) \iff ARIMA(p,d,0)$ 을 아리 모형 , $IMA(d,q) \iff ARIMA(0,d,q)$ 을 이마 모형이라 하긴 하는데 자주 쓰진 않는다. 차라리 $ARIMA(p,d,0)$ 이나 $ ARIMA(0,d,q)$ 와 같은 표현을 즐겨 쓰는 편이</description>
    </item>
    
    <item>
      <title>수치해석학에서의 계차상</title>
      <link>https://freshrimpsushi.github.io/posts/divided-difference/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divided-difference/</guid>
      <description>정의 함수 $f : \mathbb{R} \to \mathbb{R}$ 와 서로 다른 $x_{1} , \cdots , x_{n}$ 에 대해 다음을 $f$ 의 계차상Divided Difference이라고 한다. $$ \begin{align*} f[x_{0}] :=&amp;amp; f( x_{0} ) \\ f [ x_{0} , x_{1} ] :=&amp;amp; {{ f ( x_{1} ) - f ( x_{0} ) } \over { x_{1} - x_{0} }} \\ f [ x_{0} , x_{1} , x_{2} ] :=&amp;amp; {{ f [ x_{1} , x_{2} ] - f [ x_{0} , x_{1} ] } \over { x_{2} - x_{0} }} \\ f [ x_{0} , \cdots , x_{n} ] :=&amp;amp; {{ f [ x_{1} , \cdots , x_{n} ] - f [ x_{0} , \cdots , x_{n-1} ] } \over { x_{n} - x_{0}</description>
    </item>
    
    <item>
      <title>폴리그-헬맨 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pohlig-hellman-algorithm/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pohlig-hellman-algorithm/</guid>
      <description>알고리즘 그룹 $G$ 의 원소 $g$ 가 오더 $N = q_{1}^{r_{1}} q_{2}^{r_{2}} \cdots q_{t}^{r_{t}}$ 이라고 하자. 그러면 이산로그 문제 $g^{x} = h$ 는 다음의 알고리즘에 따라 많아도 $\displaystyle O \left( \sum_{i=1}^{t} S_{q_{i}^{r_{i}}} + \log N \right)$ 스텝 안에 풀린다. Step 1. $\displaystyle g_{i} : = g^{N / q_{i}^{r_{i}}}$ 와 $\displaystyle h_{i} := h^{N / q_{i}^{r_{i}}}$ 을 계산한다. Step 2. 샹크스 알고리즘을 통해 이산로그 문제 $g_{i}^{y} = h_{i}$ 의 해 $y_{i}$ 를 구한다. Step 3. 중국인의 나머지 정리를 통해 $\begin{cases} x \equiv y_{1} \pmod{ q_{1}^{r_{1}} } \\ \qquad \vdots \\ x \equiv y_{t} \pmod{ q_{t}^{r_{t}}</description>
    </item>
    
    <item>
      <title>뉴턴-랩슨 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/newton-raphson-method/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/newton-raphson-method/</guid>
      <description>메소드 1 $f,f&amp;rsquo;,f&amp;rsquo;&amp;rsquo;$ 가 $\alpha$ 의 근방에서 연속이고 $f(\alpha) = 0, f &#39;(\alpha) \ne 0$ 이라고 하자. $\alpha$ 와 충분히 가까운 초기값 $x_{0}$ 에 대해 $$ x_{n+1} := x_{n} - {{ f ( x_{n} ) } \over { f &#39; ( x_{n} ) }} $$ 과 같이 정의된 수열 $\left\{ x_{n} \right\}$ 은 $n \to \infty$ 일 때 $\alpha$ 로 쿼드러틱하게 수렴한다. 설명 뉴턴-랩슨 메소드는 그냥 뉴턴 메소드라고 불리기도 한다. 미분가능성이나 연속성과 같은 조건이 있긴 하지만 그래도 간단하고 수</description>
    </item>
    
    <item>
      <title>샤피로-윌크 테스트</title>
      <link>https://freshrimpsushi.github.io/posts/shapiro-wilk-test/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shapiro-wilk-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 하르케-베라 테스트 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 가 주어져 있다고 하자. $H_{0}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따른다. $H_{1}$ : 데이터 $\left\{ x_{i} \right\}_{i = 1}^{n}$ 는 정규분포를 따르지 않는다. 샤피로-윌크 테스트는 정규성을 검정하기 위해 사용하는 테스트로써, 보통은 정규성이 있음을 보이기 위해서 사용한다. 귀무가설이 채</description>
    </item>
    
    <item>
      <title>바이섹션 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/bisection-method/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bisection-method/</guid>
      <description>메소드 1 연속함수 $f$ 가 폐구간 $[a,b]$ 에서 $f(a) f(b) &amp;lt; 0$ 이라고 하자. 허용오차는 $\varepsilon$ 이다. $f(c) = 0$ 를 만족하는 $c \in [a,b]$ 는 다음과 같이 구할 수 있다. Step 1. $$c:= {{a+b} \over {2}}$$ Step 2. $b-c \le \varepsilon$ 이면 $c$ 를 반환한다. Step 3. $f(b) f(c) &amp;lt; 0$ 이면 $a:=c$, 아니면 $b:=c$ 이라 둔다. 그 후 Step 1. 으로 돌아간다. 설명 중간값정리의 대표적인 응용으로써, 해가 존재하는 구간을 계속 절반으로 줄여가며 방정식 $f(x) = 0$</description>
    </item>
    
    <item>
      <title>시계열분석에서의 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation/</guid>
      <description>빌드업 시계열에서 변환이 필요한 이유는 시간이 흐를수록 분산이 커지는 경우 그에 따른 &amp;lsquo;패널티&amp;rsquo;를 줘서 분산을 일정하게 하고 정상성을 얻기 위함이다. 루트 $\sqrt{}$ 나 로그 $\log$ 는 값이 클수록 줄어드는 양이 많기 때문에 자주 사용된다. 당연하지만 분산이 줄어드는 경우에는 데이터의 추이가 어떤 점으로 수렴한다는 의미가 되므로 변환 이전</description>
    </item>
    
    <item>
      <title>수치해석에서의 수렴률</title>
      <link>https://freshrimpsushi.github.io/posts/rate-of-convergence-in-numerical-analysis/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rate-of-convergence-in-numerical-analysis/</guid>
      <description>정의 1 $\alpha$ 로 수렴하는 수열 $\left\{ x_{n} \right\}$ 이 차수Order $p \ge 1$ 에 대해 $$ | \alpha - x_{n+1} | \le c | \alpha - x_{n} | ^{p} $$ 을 만족시키는 $c \ge 0$ 가 존재하면 $\left\{ x_{n} \right\}$ 이 수렴률 $c$ 로 $\alpha$ 에 $p$ 차 수렴한다고 한다. 설명 특히 $c &amp;lt; 1$ 이라는 조건과 함께 $p=1$ 이면 선형 수렴Linear Convergence이라 부른다. 비슷하게 $p=2$ 일 때는 Quadratic Convergence , $p=3$ 일 때는 Cubic Convergence</description>
    </item>
    
    <item>
      <title>스무스 소수</title>
      <link>https://freshrimpsushi.github.io/posts/smooth-prime/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/smooth-prime/</guid>
      <description>정의 소수 $p$ 에 대해 $(p-1)$ 가 많은 약수를 가지면 $p$ 가 스무스 소수라고 한다. $B$ 보다 작거나 같은 소수들의 곱으로 나타나는 수를 $B$-스무스 수라고 한다. $\psi ( X , B )$ 는 $X$ 보다 작거나 같은 $B$-스무스 수의 갯수를 나타낸다. 설명 스무스한 소수의 예로써 $p=37$ 를 생각해보면 $(p-1)$ 는 $p-1 = 36 = 2^2 3^2$ 와 같이 자잘한 소수들의 곱들로 표현된다. 스무스는 개념은 암호</description>
    </item>
    
    <item>
      <title>샹크스 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-shankss-babystep-giantstep-algorithm/</link>
      <pubDate>Tue, 19 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-shankss-babystep-giantstep-algorithm/</guid>
      <description>알고리즘 1 항등원이 $e$ 인 그룹 $G$ 의 원소 $g$ 가 오더 $N$ 이라고 하자. 그러면 이산로그 문제 $g^{x} = h$ 는 다음의 알고리즘에 따라 많아도 $O \left( \sqrt{N} \log N \right)$ 스텝 안에 풀린다. Step 1. $n: = 1 + \lfloor \sqrt{N} \rfloor $ Step 2. 두 개의 리스트 $A := \left\{ e , g , g^{2} , \cdots , g^{n} \right\}$ 와 $B := \left\{ h , hg^{-n} , hg^{-2n} , \cdots , hg^{-n^2} \right\}$ 를 만든다. Step 3. $g^{i} = h g^{-jn} \in A \cap B$ 를 찾는다. Step 4. $x = i + jn$ 은 $g^{x} = h$ 의 솔루션이다</description>
    </item>
    
    <item>
      <title>시계열분석에서의 차분</title>
      <link>https://freshrimpsushi.github.io/posts/difference-in-time-series-analysis/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-in-time-series-analysis/</guid>
      <description>정의 1 오퍼레이터 $B$ 를 $B Y_{t} = Y_{t-1}$ 과 같이 정의하고, 백쉬프트Backshift라 한다. 오퍼레이터 $\nabla$ 를 $\nabla := 1 - B$ 그리고 $\nabla^{r+1} = \nabla \left( \nabla^{r} Y_{t} \right)$ 와 같이 정의하고 차분 이라한다. 설명 차분의 정의에 따르면 $1$차 차분은 $$ \nabla Y_{t} = Y_{t} - Y_{t-1} $$ 와 같이 계산되며, $2$차 차분은 $$ \begin{align*} \nabla^2 Y_{t} =&amp;amp; \nabla \left( \nabla Y_{t} \right) \\ =&amp;amp; \nabla \left( Y_{t} - Y_{t-1} \right) \\ =&amp;amp; \nabla Y_{t} - \nabla Y_{t-1} \\ =&amp;amp; ( Y_{t} - Y_{t-1} ) - (</description>
    </item>
    
    <item>
      <title>엘가말 공개 키 암호체계 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-elgamal-public-key-cryptosystem/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-elgamal-public-key-cryptosystem/</guid>
      <description>빌드업 왼쪽부터 순서대로 앨리스 , 밥 , 이브라 하자. 앨리스와 밥은 메세지를 주고받을 당사자고, 이브는 메세지에 관심이 있는 소극적 공격자다. 주황색 상자는 앨리스만 알고 있는 정보를, 하늘색 상자는 밥만 알고 있는 정보를, 검은색 상자는 공개된(이브도 알고 있는) 정보를 나타낸다. 앨리스는 밥에게 받아야할 메세지 $m \in \mathbb{N}$ 이 있다. 알고리즘 1 $\mathbb{F}_{p}^{ \ast</description>
    </item>
    
    <item>
      <title>아르마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/arma-model/</link>
      <pubDate>Sat, 16 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arma-model/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $$ Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} +e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q} $$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 **$(p,q)$차 자기회귀이동평균과정 $ARMA(p,q)$**라 한다. 설명 아르마 모형은 단순히 이동평균과정과 자기회귀과정을 이어붙인 모양을 갖고 있다. 예로써 $(1,1)$차라면 $$ ARMA(1,1) : Y_{t} = \phi Y_{t-1} +</description>
    </item>
    
    <item>
      <title>디피-헬만 키 교환 알고리즘 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-diffie-hellman-key-exchange-algorithm/</link>
      <pubDate>Fri, 15 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-diffie-hellman-key-exchange-algorithm/</guid>
      <description>빌드업 왼쪽부터 순서대로 앨리스 , 밥 , 이브라 하자. 앨리스와 밥은 메세지를 주고받을 당사자고, 이브는 메세지에 관심이 있는 소극적 공격자다. 주황색 상자는 앨리스만 알고 있는 정보를, 하늘색 상자는 밥만 알고 있는 정보를, 검은색 상자는 공개된(이브도 알고 있는) 정보를 나타낸다. 앨리스와 밥이 암호체계 $( \mathcal{K} , \mathcal{M} , \mathcal{C} , e_{k} , d_{k} )$ 하에서 메세지를</description>
    </item>
    
    <item>
      <title>우분투에서 R 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-r-in-ubuntu/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-r-in-ubuntu/</guid>
      <description>가이드 Step 1. Ctrl+Alt+T 를 눌러 콘솔창을 띄운다. Step 2. 콘솔창에 다음과 같이 입력한다. sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 관리자 권한이 필요하므로 사용자 계정의 암호를 입력해야한다. Step 3. 콘솔창에 다음과 같이 입력한다. sudo add-apt-repository &amp;#39;deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/&amp;#39; Step 4. 콘솔창에 다음과 같이 입력한다. sudo apt update Step 5. 콘솔창에 다음과 같이 입력한다. sudo apt install r-base *Step 6. 성공적으로 설치되었는지 확인하기 위해 콘솔창에</description>
    </item>
    
    <item>
      <title>자기회귀과정</title>
      <link>https://freshrimpsushi.github.io/posts/ar-autoregressive-process/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ar-autoregressive-process/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} + e_{t}$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 $p$차 자기회귀과정 $AR(p)$ 라고 한다. (1): $AR(1) : Y_{t} = \phi Y_{t-1} + e_{t}$ (2): $AR(2) : Y_{t} = \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + e_{t}$ (p): $AR(p) : Y_{t} = \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} + e_{t}$ (∞): $AR( \infty ) : Y_{t} = e_{t} + \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots $ $\mathbb{N}$ 은 자연수의 집합 $\left\{ 1, 2, 3 , \cdots \right\}$ 을 의미한다. 설명 $AR(p)$ 를 &amp;lsquo;자</description>
    </item>
    
    <item>
      <title>이산로그</title>
      <link>https://freshrimpsushi.github.io/posts/discrete-logarithm/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/discrete-logarithm/</guid>
      <description>정의 1 소수 $p$ 에 대해 갈루아 필드 $\mathbb{F}_{p} := \mathbb{Z} / p \mathbb{Z}$ 의 항등원이 $0$ 이라고 하자. $\mathbb{F}_{p}$ 의 원시근 $g \ne 0$ 에 대해 시클릭 그룹 $\mathbb{F}_{p} ^{ \ast } := \mathbb{F}_{p} \setminus \left\{ 0 \right\} = \left&amp;lt; g \right&amp;gt;$ 상에서 정의된 함수 $\log_{g} : \mathbb{F}_{p}^{ \ast } \to \mathbb{Z} / (p-1) \mathbb{Z}$ 가 다음을 만족하면 이산로그Discrete Logarithm라 한다. $$ g^{ \log_{g} (h) } \equiv h \pmod{p} $$ 설명 $\mathbb{F}_{p} ^{ \ast }$ 의 존재성은 원시근 정리에 의해 보장된다. 사실 이산</description>
    </item>
    
    <item>
      <title>이동평균과정</title>
      <link>https://freshrimpsushi.github.io/posts/ma-moving-average-process/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ma-moving-average-process/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $Y_{t} := e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q}$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 **$q$차 이동평균과정 $MA(q)$**라고 한다. (1): $MA(1) : Y_{t} = e_{t} - \theta e_{t-1}$ (2): $MA(2) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2}$ (q): $MA(q) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q}$ (∞): $MA( \infty ) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots$ $\mathbb{N}$ 은 자연수의 집합 $\left\{ 1, 2, 3 , \cdots \right\}$ 을 의미한다. 설명 다</description>
    </item>
    
    <item>
      <title>암호론에서의 암호화와 복호화</title>
      <link>https://freshrimpsushi.github.io/posts/encryption-and-decryption-in-cryptography/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/encryption-and-decryption-in-cryptography/</guid>
      <description>빌드업 앨리스Alice가 밥Bob에게 전하고 싶은 메세지가 있다고 생각해보자. 세상에 사람이 둘 뿐이라면 이 메세지는 오직 둘만이 공유하며, 감출 이유가 없다. [ NOTE: 암호론에서 앨리스는 $A$ 를 대신하는 이름이고, 밥은 $B$ 를 대신하는 이름이다. ]하지만 이들 외의 제3자로 이브Eve가 있다고 하자. 이브는 딱히 나쁜 의도는 없지만, 앨리스가 밥에게</description>
    </item>
    
    <item>
      <title>시계열분석에서의 정상성</title>
      <link>https://freshrimpsushi.github.io/posts/stationarity-in-time-series-analysis/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stationarity-in-time-series-analysis/</guid>
      <description>정의 1 시계열 데이터의 평균과 분산이 일정할 때 정상성Stationarity을 갖는다고 한다. 설명 정상正常Normal이 아니라 정상定常Stational이다. 데이터가 정상성을 가진다는 것은 평균과 분산이 안정되어 있어서 분석하기 쉽다는 의미가 된다. 데이터가 정상성을 가지지 않으면 분석이 어렵기 때문에 정상성을 갖도록 만드는 전처</description>
    </item>
    
    <item>
      <title>R 에서 그래프 그릴 때 축 이름에 아래첨자 넣기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-subscript-in-plot-in-r/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-subscript-in-plot-in-r/</guid>
      <description>코드 R 에서도 변수의 이름에 언더바 _를 넣는 것은 허용되지만, 그래프에서도 그렇게 나타낸다면 심하게 가독성이 떨어진다. expression() 함수를 아래와 같이 사용하면 축 이름에도 보기 좋게 아래첨자를 넣을 수 있다. data&amp;lt;-as.numeric(lynx) win.graph(4,4) plot(data[-1],data[-length(data)],type=&amp;#39;p&amp;#39;,main=&amp;#39;아</description>
    </item>
    
    <item>
      <title>시계열분석에서의 백색잡음</title>
      <link>https://freshrimpsushi.github.io/posts/white-noise-in-time-series-analysis/</link>
      <pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/white-noise-in-time-series-analysis/</guid>
      <description>정의 1 iid한 확률변수 $e_{t}$ 들의 수열 $\left\{ e_{t} \right\}_{t = 1}^{\infty}$ 를 백색잡음White Noise이라고 한다. iid란 independent identically distributed의 줄임말로써, 서로 독립이고 같은 분포를 가짐을 의미한다. 설명 확률변수의 수열이라는 정의에 따르면 당연히 확률과정이다. 특히 $E ( e_{t} ) = 0$ 이면 $Y_{t} : = \begin{cases} e_{1} &amp;amp; , t=1 \\ Y_{t-1} + e_{t} &amp;amp; , t \ne 1 \\ \end{cases}$ 과 같이 정의된 확률</description>
    </item>
    
    <item>
      <title>지수분포를 통한 푸아송 프로세스의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-poisson-process-by-exponential-distribution/</link>
      <pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-poisson-process-by-exponential-distribution/</guid>
      <description>정의 $\tau_{1} , \tau_{2} , \cdots \sim \text{exp} ( \lambda )$ 이라고 하자. $\lambda$ 를 강도Intensity라고 한다. 2. $\displaystyle s_{n}:= \sum_{k=1}^{n} \tau_{k}$ 를 도달 시간Arrival Time이라 한다. 3. $N_{t}:= \begin{cases} 0 , &amp;amp; 0 \le t &amp;lt; s_{1} \\ k , &amp;amp; s_{k} \le t &amp;lt; s_{k+1} \end{cases}$ 와 같이 정의된 확률과정 $\left\{ N_{t} \right\}_{t = 0}^{\infty}$ 를 푸아송 프로세스Poisson Process라 한다. 기초 성질 [1]: $\displaystyle p (N_{t} = k ) = {{ ( \lambda t )^{t} e^{ - \lambda t} } \over { k! }}$</description>
    </item>
    
    <item>
      <title>히든 마코프 체인</title>
      <link>https://freshrimpsushi.github.io/posts/hidden-markov-chain/</link>
      <pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hidden-markov-chain/</guid>
      <description>빌드업 위의 그림과 같이 어떤 기계에서 일정한 시간마다 어떤 물건을 생산한다고 생각해보자. 녹색이 정상적인 양품 $1$ 이고 적색이 폐기해야하는 불량품 $0$ 이라면, 지금까지의 기록은 $\left( 1, 0 , 1 \right)$ 이 될 것이다. 이렇게 실제로 눈에 보이는 결과를 시그널Signal이라고 한다. 단, 불량품이 나올 확률은 기계가 정상인지 고장인지에 따라 다르다고 하자. 정</description>
    </item>
    
    <item>
      <title>시계열분석이란</title>
      <link>https://freshrimpsushi.github.io/posts/time-series-analysis/</link>
      <pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-series-analysis/</guid>
      <description>설명 시계열Time Series 이란 쉽게 말해 실제 데이터로 얻어지는 확률과정이라고 볼 수 있다. 주가지수는 시간이 흐름에 따라 불확실성을 가지고 그 값이 변하므로 시계열의 좋은 예시가 될 수 있다. 시계열분석이란 이렇듯 시간 변수의 흐름에 따른 종속변수의 움직임을 이해하고 예측하는 것을 목표로 하는 분석법이다. 회귀분석과의 가장 큰 차이점은 회귀분석이 독립</description>
    </item>
    
    <item>
      <title>도박꾼의 파산 문제</title>
      <link>https://freshrimpsushi.github.io/posts/gamblers-ruin-problem/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gamblers-ruin-problem/</guid>
      <description>문제 도박꾼의 파산 문제는 랜덤워크의 일종으로 두 명의 플레이어가 한정된 돈을 걸고 둘 중 하나가 파산할 때까지 반복하는 게임을 상정한다. 당신이 플레이어 중 하나라고 한다면, 위 도식과 같이 당신이 이길 확률이 $p$ 고 질 확률이 $(1-p)$ 라고 할 수 있다. 상태 $0$ 은 당신이 파산한 경우고, 상태 $N$ 은 당신이 상대의 돈을 모두 딴 경우로 더 이상 게임을 반복하지 않는다. 이는</description>
    </item>
    
    <item>
      <title>갈루아 이론</title>
      <link>https://freshrimpsushi.github.io/posts/galois-theory/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/galois-theory/</guid>
      <description>정리 1 $K$ 가 $F$ 의 유한정규확대체고 $F \le E \le K$ 라 하자. 고정된 $E$ 를 남기는 $G ( K / F )$ 의 부분군을 $\lambda (E)$ 와 같이 나타내자. 그러면 사상 $\lambda$ 은 $F$ 와 $K$ 사이의 모든 $E$ 를 $G ( K / F )$ 의 모든 부분군으로 대응시키는 동형사상이 된다. $\lambda$ 는 다음의 성질들을 가진다. $\lambda ( E ) = G ( K / E )$ $E = K_{ G ( K / E ) } = K_{ \lambda (E) }$ $H \le G ( K / F )$ 에 대해 $\lambda ( K_{H}</description>
    </item>
    
    <item>
      <title>ROC 곡선의 AUC 를 이용해 모형 비교하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</guid>
      <description>요약 ROC 곡선은 기본적으로 사각형 $[0,1]^2$ 을 가득 채울수록 좋고, 곡선의 왼쪽 상단의 꺾이는 점이 $(0,1)$ 에 가까울 수록 좋다. 설명 위의 두 ROC 곡선이 있다고 한다면 마음 편하게 &amp;lsquo;좋다&amp;rsquo;라고 할 수 있는 쪽은 오른쪽이다. 이 &amp;lsquo;좋다&amp;rsquo;는 말이 의미하는 것은 ROC 곡선을 그려내는 모형이 더 낫다는 뜻이다. 당연히 비교되는</description>
    </item>
    
    <item>
      <title>펠 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/pells-equation/</link>
      <pubDate>Mon, 25 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pells-equation/</guid>
      <description>빌드업 $a_{n} : = n^2$ 를 사각수Square Number라 한다. $\displaystyle b_{m} : = {{ m ( m + 1 ) } \over {2}}$ 를 삼각수Triangular Number라 한다. 이들 중에서 사각수면서도 삼각수인 수가 있는지 한번 생각해보면, 당장 $a_{1} =b_{1} = 1$ 과 $\displaystyle a_{6} = 6 ^2 = 36 = {{ 8 \cdot 9 } \over {2}} = b_{8}$ 이 있다. 이제 일반적으로 사각수이면서도 삼각수인 경우를 생각해보자. $$ \begin{align*}</description>
    </item>
    
    <item>
      <title>ROC 곡선을 이용해 최적의 컷오프 찾는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</link>
      <pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</guid>
      <description>개요 ROC 곡선을 그리면 트레이닝 데이터로 얻은 모형이 테스트 데이터를 어느정도로 잘 설명하는지 한 눈에 보여서 유용하다. 하지만 이 곡선은 모든 컷오프에 대한 분류율을 계산하고 이은 것이므로 결국 &amp;lsquo;어떤 컷오프로 0과 1을 분류할 것인가&amp;rsquo;는 알 수 없다. 이것을 알아내기 위해 교차검증의 방법론을 응용해보자. 검증 데이터 트레이</description>
    </item>
    
    <item>
      <title>루트가 포함된 분수 유리화 빠르게 하기</title>
      <link>https://freshrimpsushi.github.io/posts/874/</link>
      <pubDate>Fri, 22 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/874/</guid>
      <description>공식 $$ {{ x } \over { \sqrt{a} \pm \sqrt{b} }} = {{ x \left( \sqrt{a} \mp \sqrt{b} \right) } \over { a - b }} $$ 설명 분수의 유리화는 개념적으로는 쉽지만 분자 분모에 복잡한 항을 곱하고 정리하는 부분에서 계산이 많아져서 어렵다. 그러나 위의 공식을 활용하면 빠르고 간단하게, 계산실수를 최소한으로 줄이면서 유리화를 해낼 수 있다.핵심은 이러나 저러나 분모의 루트를 벗겨내기 위해 $( \alpha^2 - \beta^2 )$ 꼴을</description>
    </item>
    
    <item>
      <title>일반화된 랜덤워크</title>
      <link>https://freshrimpsushi.github.io/posts/generalized-random-walk/</link>
      <pubDate>Thu, 21 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generalized-random-walk/</guid>
      <description>정의 확률과정 $\left\{ X_{n} \right\}$ 의 상태공간이 정수의 집합 $\left\{ \cdots , -2 , -1, 0 , 1 , 2 , \cdots \right\}$ 이고, 상태 $0$ 에서 이라고 하자. 다음 스텝에서 $1$ 만큼 작아질 확률을 $p$, $1$ 만큼 커질 확률이 $(1-p)$ 일 때 $\left\{ X_{n} \right\}$ 을 일반화된 랜덤워크라 한다. 설명 랜덤워크란 확률 과정 중에서도 아주 단순한 예시로써, 보통 좌우로 갈 확률을 똑같이 둔다. 일반화된 랜덤워크란 그 확률을 다르게 두기도</description>
    </item>
    
    <item>
      <title>R 에서 ROC 곡선 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</guid>
      <description>정의 오류행렬의 False Positive Rate와 True Positive Rate를 각각 축으로 두고 그린 그림을 ROC 곡선Receiver Operating Characteristic Curve이라 한다. 설명 ROC 곡선은 모델의 퍼포먼스를 한 눈에 보여줄 뿐만 아니라 최적의 컷오프를 찾고 모델 간의 비교에도 쓰이는 등 요긴하게 쓸 데가 많다. 예제를 통해 R 에서 ROC 곡선을 그려보고 그 의미를 이해해보자. 핵심적인 패키지로 ROCR</description>
    </item>
    
    <item>
      <title>로렌츠 끌개</title>
      <link>https://freshrimpsushi.github.io/posts/lorenz-attractor/</link>
      <pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lorenz-attractor/</guid>
      <description>개요 로렌츠 방정식Lorenz Equation이란 대기의 대류를 연립 상미분 방정식으로써 표현하는 수학적 모델이다. 시스템 $$ \begin{align*} {{dx} \over {dt}} =&amp;amp; - \sigma x + \sigma y \\ {{dy} \over {dt}} =&amp;amp; - xz + \rho x - y \\ {{dz} \over {dt}} =&amp;amp; xy - \beta z \end{align*} $$ 변수 $x(t)$: $t$ 시점에서 입자의 $x$ 좌표를 나타낸다. $y(t)$: $t$ 시점에서 입자의 $y$ 좌표를 나타낸다. $z(t)$: $t$ 시점에서 입자의 $z$ 좌표를 나타낸다. 파라메</description>
    </item>
    
    <item>
      <title>교차검증</title>
      <link>https://freshrimpsushi.github.io/posts/cross-validation/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cross-validation/</guid>
      <description>모델 검증 데이터 분석을 해서 얻은 모델은 그 퍼포먼스가 적절한지 확인하는 과정이 필요하다. 주어진 데이터만 잘 설명하고 실전에서 전혀 힘을 쓰지 못하면 분석을 하는 의미가 없기 때문이다. 이를 위해서 전체 데이터를 모델을 얻는데 사용할 데이터셋과 그 모형의 퍼포먼스를 평가할 데이터셋으로 쪼갠다. 모델을 얻겠다는 것은 주어진 데이터를 이용해 다른 데이터</description>
    </item>
    
    <item>
      <title>갈루아체</title>
      <link>https://freshrimpsushi.github.io/posts/galois-field/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/galois-field/</guid>
      <description>정리 1 소수 $p$ 와 자연수 $n$ 에 대해 기수가 $p^{n}$ 인 유한 체Finite Field를 $p^{n}$ 차 갈루아체Galois Field라 정의하고 $\text{GF} \left( p^{n} \right)$ 와 같이 나타낸다. 유한체는 갈루아체 뿐이고, 주어진 $p$ 와 $n$ 에 대해 갈루아체는 유일하게 존재한다. 여기서 유일하다는 말은 서로 다른 체라고 해도 동형사상이 존재해서 사실상 같은 체라는 뜻이다. 설명 가우스가 처</description>
    </item>
    
    <item>
      <title>전이확률의 극한</title>
      <link>https://freshrimpsushi.github.io/posts/limit-of-transition-probability/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-of-transition-probability/</guid>
      <description>정의 현재의 상태가 $i$ 일 때, $k$ 스탭을 거쳐 $j$ 로 갈 전이확률을 $p_{ij}^{(k)}$ 라 할 때, 무한한 스텝 뒤의 전이확률을 다음과 같이 나타낸다. $$ \pi_{j}:= \lim_{n \to \infty} p_{ij}^{ ( n ) } $$ 설명 통계학이든 응용수학이든 하는 일이 대개 그렇지만 주된 관심사는 미래의 예측이다. 확률과정론에서 관심을 갖는 부분 역시 한 치 앞은 물론 먼 미래에 어떻게 될지가 궁금하다. 그리고 주로 이런 표현은 무한</description>
    </item>
    
    <item>
      <title>가분확대체</title>
      <link>https://freshrimpsushi.github.io/posts/separable-extension-in-abstract-algebra/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separable-extension-in-abstract-algebra/</guid>
      <description>정의 1 $E$ 가 $F$ 의 확대체라고 하자. $E$ 에서 $\overline{F}$ 의 부분체로 가는 동형사상 중 고정된 $F$ 를 남기는 동형사상의 갯수를 $F$ 상에서 $E$ 의 인덱스Index라 하고 $\left\{ E : F \right\}$ 와 같이 나타낸다. $E$ 가 유한체라고 할 때, $\left\{ E : F \right\} = [ E : F ]$ 면 $E$ 를 $F$ 의 가분확대체라 한다. $f ( \alpha )$ 가 $F$ 의 가분확대체면 $\alpha \in \overline{F}$ 가 $F$ 상에서 가분이라 한다. $f(x)$ 의 모든 영이 $F$ 상에서</description>
    </item>
    
    <item>
      <title>확률과정론에서 상태의 유형</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-state-in-stochastic-process/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-state-in-stochastic-process/</guid>
      <description>정의 $i,j$ 를 스테이트라고 하자. $p_{ij}^{ ( n ) } &amp;gt; 0$ 를 만족하는 $n \ge 0$ 이 존재하면 $j$ 는 $i$ 로부터 억세서블Accessible하다고 한다. $i$ 와 $j$ 가 서로 억세서블하면 커뮤니케이트Cummunicate하다고 한다. 커뮤니케이트한 스테이트들의 집합 중 가장 큰 것을 클래스Class라고 한다. 두 스테이트가 커뮤니케이트하면 하나의 클래스 안에</description>
    </item>
    
    <item>
      <title>1계 상미분방정식의 초기값 문제에 대한 솔루션의 존재성과 유일성</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-existence-uniqueness-theorem-for-first-order-ordinary-differential-equation/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-existence-uniqueness-theorem-for-first-order-ordinary-differential-equation/</guid>
      <description>정리1 $E$가 $\mathbb{R}^{n}$에서 열린집합이고 $f \in C^{1} (E)$와 $\phi_{0} \in E$에 대해 아래와 같은 초기값 문제가 주어졌다고 하자. $$ \begin{cases} \dot{ \phi } = \mathbb{f} ( \phi ) \\ \phi (0) = \phi_{0} \end{cases} $$ 그러면 어떤 $[-h,h]$ 에서 주어진 초기값 문제의 솔루션 $\phi (t)$ 은 유일하게 존재한다. 설명 유클리드 공간 $\mathbb{R}^{n}$ 의 볼을 $B \left( \mathbb{x}_{0} ; d \right) := \left\{ \mathbb{x} \in \mathbb{R}^{n} \mid | \mathbb{x}_{0} - \mathbb{x} | &amp;lt; d \right\}$, $B \left[ \mathbb{x}_{0} ;</description>
    </item>
    
    <item>
      <title>채프만-콜모고로프 방정식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-chapman-kolmogorov-equation/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-chapman-kolmogorov-equation/</guid>
      <description>정리 확률과정의 전이확률 $p_{ij}^{(n)}$, $p_{ij}(t)$과 전이확률행렬 $P^{(n)}$, $P(t)$ 에 대해 다음의 방정식들이 성립한다. 이산적 확률과정 $$ \begin{align*} p_{ ij }^{ (n+m) } =&amp;amp; \sum _{ k } p_{ ik }^{ (n) } p _{ kj }^{ (m) } \\ P^{(n+m)} =&amp;amp; P^{(n)} P^{(m)} \end{align*} $$ 연속적 확률과정 $$ \begin{align*} p_{ij} (t + s) =&amp;amp; \sum _{ k } p_{ ik } \left( t \right) p _{ kj } \left( s \right) \\ P(t+s) =&amp;amp; P(t) P(s) \end{align*} $$ 설명 스테이트 $i$ 에서 $j$ 로 갈 때까지 걸리는 $n+m$ 의 스텝을 $n$ 과 $m$ 으</description>
    </item>
    
    <item>
      <title>국소 립시츠 조건</title>
      <link>https://freshrimpsushi.github.io/posts/local-lipschitz-condition/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/local-lipschitz-condition/</guid>
      <description>정의 $E$ 가 $\mathbb{R}^{n}$ 에서 오픈이고 $\mathbf{f} : E \to \mathbb{R}^{n}$ 이라고 하자. 모든 $\mathbf{x} _{0} \in E$ 에 대해 $B \left( \mathbf{x} _{0} ; \varepsilon \right) \subset E$ 를 만족하는 $\varepsilon &amp;gt; 0$ 과 모든 $\mathbf{x} , \mathbf{y} \in B \left( \mathbf{x} _{0} ; \varepsilon \right)$ 에 대해 $| \mathbf{f} ( \mathbf{x} ) - \mathbf{f} ( \mathbf{y} ) | \le K | \mathbf{x} - \mathbf{y} |$ 를 만족하는 $K &amp;gt;0$ 가 존재하면 $\mathbf{f}$ 가 $E$ 에서 로컬리 립시츠Locally Lipshitz라 한다. 이때 다음과 같은 관계가 성립한다. 강한 립시츠 조건 $\implies$ 립시</description>
    </item>
    
    <item>
      <title>이산 마코프 체인</title>
      <link>https://freshrimpsushi.github.io/posts/dtmc-markov-chain/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dtmc-markov-chain/</guid>
      <description>정의 상태공간이 가산집합이면서 다음을 만족하는 이산적 확률과정 $\left\{ X_{n} \right\}$ 를 이산 마코프 체인DTMC 혹은 간단히 마코프 체인Markov Chain, MC이라고 한다. $$ p \left( X_{n+1} = j \mid X_{n} = i , X_{n-1} = k , \cdots , X_{0} = l \right) = p \left( X_{n+1} = j \mid X_{n} = i \right) $$ 같이보기 연속 마코프 체인 설명 $p_{ij}:= p \left( X_{n+1} = j \mid X_{n} = i \right)$ 을 전이 확률Transition Probabilit</description>
    </item>
    
    <item>
      <title>피카드 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/picards-method/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/picards-method/</guid>
      <description>정리1 $E$가 $\mathbb{R}^{n}$에서 오픈이고 $f \in C^{1} (E)$에 대해 아래와 같은 초기값 문제가 주어졌다고 하자. $$ \begin{cases} \dot{ \phi } = f ( \phi ) \\ \phi (0) = \phi_{0} \end{cases} $$ 함수열 $\left\{ u_{k} (t) \right\} _{ k =0}^{ \infty }$ 을 아래와 같이 정의하자. $$ \begin{cases} u_{0} (t) = \phi_{0} \\ u_{k+1} (t) = \phi_{0} + \int_{0}^{t} f \left( u_{k} (s) \right) ds \end{cases} $$ 그러면 연속함수 $u (t) := \lim_{k \to \infty} u_{k} (t)$ 는 주어진 초기값 문제의 솔루션이다.</description>
    </item>
    
    <item>
      <title>확률과정이란?</title>
      <link>https://freshrimpsushi.github.io/posts/stochastic-process/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stochastic-process/</guid>
      <description>정의 확률변수 $X: \Omega \to E$ 의 공역을 상태공간이라 한다. 확률변수의 집합 $\left\{ X_{t} \mid t \in [ 0 , \infty ) \right\}$ 을 연속적 확률과정이라 한다. 확률변수의 수열 $\left\{ X_{n} \mid n = 0, 1, 2, \cdots \right\}$ 을 이산적 확률과정이라 한다. 설명 확률과정은 과정Process이라는 단어 때문에 이해하기 어려운, 전형적으로 말이 어려워서 어려운 개념이다. &amp;lsquo;프로세스&amp;rsq</description>
    </item>
    
    <item>
      <title>맵으로 표현되는 동역학계와 고정점</title>
      <link>https://freshrimpsushi.github.io/posts/dynamic-system-map-fixed-point/</link>
      <pubDate>Sat, 09 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamic-system-map-fixed-point/</guid>
      <description>정의1 정의역과 공역이 같은 함수 $f : X \to X$ 를 맵Map이라고 한다. $f$ 를 $k$ 번 합성한 맵을 $f^{k}$ 와 같이 나타낸다. $f(p) = p$ 를 만족하는 $p \in X$ 를 고정점Fixed Point이라고 한다. 모든 $x \in N_{ \epsilon } ( p )$ 에 대해 $\displaystyle \lim_{k \to \infty} f^{k} (x) = p$ 를 만족하는 $\epsilon &amp;gt; 0$ 이 존재하면 고정점 $p$ 를 싱크Sink라 한다. $p$ 를 제외한 모든 $x \in N_{\epsilon } (p)$ 에 대해 $f^{ \infty } (x) \notin N_{\epsilon }</description>
    </item>
    
    <item>
      <title>호스머-렘쇼 적합도 검정</title>
      <link>https://freshrimpsushi.github.io/posts/hosmer-lemeshow-gof-test/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hosmer-lemeshow-gof-test/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 로지스틱 회귀분석R 에서 호스머-렘쇼 적합도 검정 하는 법 로지스틱 회귀분석으로 얻은 모형을 $M$ 이라고 하자. $H_{0}$ : $M$ 은 적합하다. $H_{1}$ : $M$ 은 적합하지 않다. 호스머-렘쇼 적합도 검정은 로지스틱 회귀모형의 적합성을 판별하는 대표적인 방법이다. 아주 단순한 테스트지만 귀무가설과 대립가설이 헷갈</description>
    </item>
    
    <item>
      <title>최소분열체</title>
      <link>https://freshrimpsushi.github.io/posts/splitting-field-in-abstract-algebra/</link>
      <pubDate>Thu, 07 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/splitting-field-in-abstract-algebra/</guid>
      <description>정의 1 $F \le E$ 라고 하자. $f(x) \in F [ x ]$ 가 $E [ x ]$ 의 일차항들로 인수분해되면 $f(x)$ 가 $E$ 에서 분열된다고 한다. $\left\{ f_{i} (x) \mid i \in I \right\} \subset F [ x ]$ 에 대해 모든 $f_{i} (x)$ 들의 영을 포함하고 $E$ 가 $\overline{F}$ 의 가장 작은 부분체가 될 때 $E$ 를 $F$ 상에서 $\left\{ f_{i} (x) \mid i \in I \right\}$ 의 최소분열체라 한다. 예시 말이 어려우므로 예시를 통해 개념적으로 이해해보자. 유리수체 $\mathbb{Q}$ 에 대해 $( x^4 - 5</description>
    </item>
    
    <item>
      <title>R 에서 로지스틱 회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-result-of-logistic-regression-in-r/</link>
      <pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-result-of-logistic-regression-in-r/</guid>
      <description>실습 내장데이터 turnout 데이터를 불러와보자. turnout는 1992년 미국 총선에 대한 데이터로써, race(인종), 연령(age), 교육수준(educate), income(수입)에 따른 vote(투표여부)를 파악할 수 있다. 이 데이터는 투표를 했느냐 안 했느냐하는 종속변수에 관심이 있으므로 로지스틱 회귀분석을 사용할 수 있다</description>
    </item>
    
    <item>
      <title>체의 자기동형사상</title>
      <link>https://freshrimpsushi.github.io/posts/automorphism-of-field/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/automorphism-of-field/</guid>
      <description>정의 1 $E$ 가 $F$ 의 확대체라고 하자. 체 $E$ 에 대해 동형사상 $\sigma : E \to E$ 을 자기동형사상Automorphism이라 하고, $E$ 의 자기동형사상의 집합을 $\text{Auto} (E)$ 와 같이 나타낸다. $\sigma \in \text{Auto} (E)$ 에 대해 $\sigma ( a ) = a$ 면 $\sigma$ 가 고정된 $a$ 를 남긴다고 한다. $S \subset \text{Auto} (E)$ 라고 하자. 모든 $a \in F$ 에 대해 모든 $\sigma \in S$ 가 고정된 $a$ 를 남기면 $S$ 가 고정된 부분체 $F$ 를 남긴다고 한다</description>
    </item>
    
    <item>
      <title>R 에서 두 배열의 성분 비교하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-compare-array-in-r/</link>
      <pubDate>Mon, 04 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-compare-array-in-r/</guid>
      <description>개요 R 은 데이터의 형태, 구조보단 그 내용에 관심이 많은 분야에서 많이 쓰이므로 그 비교 역시 유용하다. 포함관계 (전혀 중요하지는 않지만, 예제에서 A는 삼각수 $\displaystyle {{n(n+1)} \over {2}}$ 이고 B는 사각수 $m^2$ 를 나타낸다.) 이항연산자 %in% 을 사용해 두 배열을 비교해보면 A의 성분 중 B에도 속하는 성분에 대해 참, 그렇지 않으면 거짓으로 반환해준다. 다음과 같이 문자열을</description>
    </item>
    
    <item>
      <title>켤레 동형사상 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-conjugation-isomorphism-theorem/</link>
      <pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-conjugation-isomorphism-theorem/</guid>
      <description>정의 1 체 $F$ 에 대해 $\alpha$ 가 $F$ 상에서 대수적이라고 하자. 최대차항의 계수가 $1$ 이고 $p( \alpha ) = 0$ 를 만족하는 $p(x) \in F [ x ]$ 를 $\alpha$ 에 대한 $F$ 상에서의 기약 다항함수라 하고 $\text{irr} ( \alpha , F) = p(x)$ 와 같이 나타낸다. $\text{irr} ( \alpha , F)$ 의 최대차항의 차수를 $F$ 상에서 $\alpha$ 의 차수 라 하고 $\deg ( \alpha , F )$ 와 같이 나타낸다. $F$ 의 대수적 확대체 $E$ 에 대해 $\text{irr} ( \alpha , F) = \text{irr} ( \beta , F)$ 라고 하면</description>
    </item>
    
    <item>
      <title>R 에서 데이터 프레임의 열과 행 이름 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-row-and-column-name-of-dataframe-in-r/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-row-and-column-name-of-dataframe-in-r/</guid>
      <description>개요 R 에서 데이터 프레임을 이용해 복잡한 코드를 짜다보면 디폴트로 정해주는 열 이름들이 헷갈려서 바꿔줘야 할 상황이 있다. names() 예제로써 위 데이터 프레임을 보면 별 다른 언급이 없으면 V1, V2, V3처럼 무성의하고 구분하기 힘든 열 이름이 주어진다. 여기에 names() 함수를 씌우면 열 이름을 반환하며, 반대로 거기에 바로 문자열을 넣어 열 이름을 바꿀 수 있다. 그냥 단순</description>
    </item>
    
    <item>
      <title>유클리드 정역</title>
      <link>https://freshrimpsushi.github.io/posts/ed-euclidean-domain/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ed-euclidean-domain/</guid>
      <description>정의 1 정역 $D$ 에서 다음의 두 조건을 만족하는 유클리드 놈Euclidean Norm $\nu : D \setminus \left\{ 0 \right\} \to \mathbb{N}_{0}$ 이 존재하면 $D$ 를 유클리드 정역이라 한다. (i): 모든 $a,b \in D (b \ne 0 )$ 에 대해 $$ a = bq + r $$ 을 만족하는 $q$ 와 $r$ 이 존재한다. 이 때 $r = 0$ 이거나 $\nu (r) &amp;lt; \nu (b)$ 둘 중 하나여야한다. (ii): 모든 $a,b \in D (b \ne 0 )$ 에 대해 $\nu ( a ) \le \nu ( ab )$ $\mathbb{N}_{0}$ 은 자연수의 집합에 $0$ 을</description>
    </item>
    
    <item>
      <title>로지스틱 회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/logistic-regression/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logistic-regression/</guid>
      <description>빌드업 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 $Y$ 가 질적변수, 그 중에서도 계급이 두개뿐인 경우가 있을 수 있다. 예를 들어 남자와 여자, 성공과 실패, 양성과 음성, $0$ 과 $1$ 등이 있고, 편의상 그냥 $Y=0$ 혹은 $Y=1$ 이라고 하자. 이렇게 종속변수가 이항적인 경우 관심사는 &amp;lsquo;독립변수 $ X_{1} , \cdots X_{p}$ 들을 보았을 때 $Y$ 가 무엇인지&amp;rsquo;일 것</description>
    </item>
    
    <item>
      <title>유일 인수분해 정역</title>
      <link>https://freshrimpsushi.github.io/posts/ufd-unique-factorization-domain/</link>
      <pubDate>Wed, 30 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ufd-unique-factorization-domain/</guid>
      <description>정의 1 정역 $D$ 의 $0$ 도 아니고 단원도 아닌 모든 원소에 대한 유한 인수분해가 유일하게 존재하면 $D$ 를 유일 인수분해 정역UFD이라 한다. 유일 인수분해 정역 $D$ 의 $a_{1} , \cdots , a_{n}$ 에 대해 $d \mid a_{i}$ 이고 $a_{i}$ 의 모든 약수가 $d$ 를 나누면 $d$ 를 $a_{1} , \cdots , a_{n}$ 의 최대공약소Greatest Common Divisor라 하고 $\gcd$ 로 쓴다. 유일 인수분해 정역 $D$ 의 어떤 다항함수를 $f(x) := a_{0} +</description>
    </item>
    
    <item>
      <title>통계적 분석에서의 변수 선택 기준</title>
      <link>https://freshrimpsushi.github.io/posts/variable-selection-criterion-in-statistiical-analysis/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/variable-selection-criterion-in-statistiical-analysis/</guid>
      <description>개요 변수를 선택하는 문제는 필연적으로 분석자의 주관이 개입할 수 밖에 없지만, 가능한 한 객관적인 결론을 내릴 수 있게 도와주는 수치적인 지표가 필요했다. 그런 값들을 계산해낼 수 있다면 변수 선택 절차를 언제 멈추느냐에 대한 명쾌한 해답이 된다. 다만 이 기준에도 여러가지 종류가 있으며, 기준을 다르게 적용하면 결과 역시 달라질 수 있다. 지표 1 설명력R</description>
    </item>
    
    <item>
      <title>주 아이디얼 정역</title>
      <link>https://freshrimpsushi.github.io/posts/pid-principal-ideal-domain/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pid-principal-ideal-domain/</guid>
      <description>정의 1 정역 $D$ 의 $p \ne 0$ 가 단원이 아니라고 하자. PID $D$ 의 모든 아이디얼이 주 아이디얼이면 $D$ 를 주 아이디얼 정역PID이라 한다. 따름정의 가환환 $R$ 이 단위원 $1$ 을 가진다고 하자. $a,b \in R$ 에 대해 $b=ac$ 를 만족하는 $c \in R$ 이 존재하면 $a$ 가 $b$ 를 나눈다Divide 혹은 $a$ 가 $b$ 의 인수Factor라 하고 $a \mid b$ 와 같이 나타낸다. $a \mid b$ 이고 $b \mid a$ 면 $a,b$ 가 연합</description>
    </item>
    
    <item>
      <title>소수를 3으로 나눈 나머지가 1이 되는 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessity-and-sufficiency-for-prime-number-is-congruent-to-1-mod-4/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessity-and-sufficiency-for-prime-number-is-congruent-to-1-mod-4/</guid>
      <description>정리 $p \ne 3$ 이 소수라고 하자. $p \equiv 1 \pmod{3}$ $\iff$ 어떤 $a,b \in \mathbb{Z}$ 에 대해 $p = a^2 - ab + b^2$ 설명 $p=3$ 은 제외했지만, 사실 $ 3= 2^2 - 2 \cdot 1 + 1^2$ 이므로 정리에 포함되어도 큰 상관은 없다. 예를들어 $13 \equiv 1 \pmod{4}$ 는 $$ 13 = 1 - 4 + 16 = 1^2 - 1 \cdot 4 + 4^2 $$ $37 \equiv 1 \pmod{4}$ 는 $$ 37 = 9 -21 + 49 = 3^2 - 3 \cdot 7+ 7^2 $$ $61 \equiv 1 \pmod{4}$ 는 $$ 61 = 16 - 36 + 81 = 4^2 - 4 \cdot 9 + 9^2 $$ 이러한 팩트는 그 자체만</description>
    </item>
    
    <item>
      <title>뇌터 환</title>
      <link>https://freshrimpsushi.github.io/posts/noetherian-ring/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/noetherian-ring/</guid>
      <description>정의 $N$ 을 환이라고 하자. $N$ 의 아이디얼들이 $S_{1} \le S_{2} \le \cdots$ 을 만족할 때 이를 오름사슬Ascending Chain이라 한다. 오름사슬 $\left\{ S_{i} \right\}_{i \in \mathbb{N} }$ 에 대해 $S_{n} = S_{n+1} = \cdots$ 을 만족하는 $n \in \mathbb{n}$ 이 존재하면 정상적Stationary이라 한다. 다시 말해 정상적 오름사슬에선 아이디얼이 어느 순간부터 더 이상 커지지 않는다. 모든 오름사슬이 정상적인 환을</description>
    </item>
    
    <item>
      <title>소수를 4로 나눈 나머지가 1이 되는 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessity-and-sufficiency-for-prime-number-is-congruent-to-1-mod-3/</link>
      <pubDate>Fri, 25 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessity-and-sufficiency-for-prime-number-is-congruent-to-1-mod-3/</guid>
      <description>정리 $p \ne 2$ 가 소수라고 하자. $p \equiv 1 \pmod{4}$ $\iff$ 어떤 $a,b \in \mathbb{Z}$ 에 대해 $p = a^2 + b^2$ 설명 $p=2$ 는 제외했지만, 사실 $ 2= 1^2 + 1^2$ 이므로 정리에 포함되어도 큰 상관은 없다. 예를들어 $13 \equiv 1 \pmod{4}$ 는 $$ 13 = 4 + 9 = 2^2 + 3^2 $$ $37 \equiv 1 \pmod{4}$ 는 $$ 37 = 1 + 36 = 1^2 + 6^2 $$ $61 \equiv 1 \pmod{4}$ 는 $$ 61 = 25 + 36 = 5^2 + 6^2 $$ 이다. 이러한 팩트는 그 자체만으로도 흥미롭지만, 가우스 소수와 깊은 연관</description>
    </item>
    
    <item>
      <title>통계적 분석에서의 변수 선택 절차</title>
      <link>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistiical-analysis/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistiical-analysis/</guid>
      <description>빌드업 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 독립변수는 $p$ 개로, 회귀분석의 여러가지 가정들을 잘 만족하고 다중공선성이 없으며 설명력이 높다면 좋을 것이다. 물론 정보라는 것은 많으면 많을수록 좋지만, 지나치게 많은 데이터로 얻은 회귀모형은 사용하는데에도 많은 데이터를 요구한다. 그래서 가능하다면 사용하는 독립변수를 줄여</description>
    </item>
    
    <item>
      <title>리눅스 포트란 컴파일 후 aout 실행법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-execute-aout-file-after-fortran-complie/</link>
      <pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-execute-aout-file-after-fortran-complie/</guid>
      <description>가이드 확장자가 .f90인 파일 exameple.f90 을 컴파일하려면 콘솔창에서 gfortran example.f90 을 입력하면 된다. 실행하고 나면 같은 디렉터리에 a.out 라는 파일이 생긴다. 콘솔창에서 ./a.out 을 입력하면 콘솔창에서 프로그램이 실행되는 것을 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>R 에서 주성분회귀분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</guid>
      <description>개요 주성분회귀분석PCR 이란 주성분분석과 다중회귀분석을 합친 것으로, 주성분분석을 통해 얻은 주성분을 새로운 독립변수로 둔 회귀분석을 말한다. 사실 통계학의 관점에서 주성분분석 그 자체는 별 필요가 없고, 보통 회귀분석에 쓰일 때나 의미가 있다. 실습 (다중공선성을 찾아내는 법에 이어서) 주성분을 만들어내는 과정은 행렬분해를 포함한 복잡한</description>
    </item>
    
    <item>
      <title>소체</title>
      <link>https://freshrimpsushi.github.io/posts/prime-field-in-abstract-algebra/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prime-field-in-abstract-algebra/</guid>
      <description>빌드업 환 $R$ 의 모든 원소 $r$ 에 대해 $n \cdot r = 0$ 을 만족하는 가장 큰 자연수 $n$ 을 $R$ 의 표수Characteristic라 정의한다. 만약 그런 자연수가 존재하지 많으면 $0$ 을 $R$ 의 표수로 정의한다. 곱셈에 대한 항등원, 즉 단위원을 갖는 환은 다음과 같은 성질을 가진다. [1]: 단위원을 갖는 $R$ 의 표수가 $n&amp;gt;1$ 이면 $R$ 은 $\mathbb{Z}_{n}$ 과 동형인 부분환을 가진다. [2]: 단위원을 갖는</description>
    </item>
    
    <item>
      <title>3대 작도 불능 문제 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-impossibility-of-construction/</link>
      <pubDate>Mon, 21 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-impossibility-of-construction/</guid>
      <description>정리 1 다음 세 가지 작도는 불가능하다. [1] Squaring the circle: 주어진 사각형과 같은 넓이의 원을 작도하라. [2] Doubling the cube: 주어진 정육면체의 부피가 두 배가 되는 정육면체를 작도하라. [3] Trisecting the angle: 주어진 각을 삼등분하라. 반증 오랫동안 기하학의 문제였으나 대수학으로써 풀린다는 것이 실로 경이롭다. 기본적으로 아래 보조정리의 대우명제를 사용한다. 작도가능수의 성질:</description>
    </item>
    
    <item>
      <title>통계학에서의 주성분분석</title>
      <link>https://freshrimpsushi.github.io/posts/pca-principal-components-analysis-in-statistiics/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pca-principal-components-analysis-in-statistiics/</guid>
      <description>개요 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자. 주성분분석, 영어 약어로 PCA는 쉽게 말해 양적변수들이 제대로 독립이 되도록 &amp;lsquo;재구성&amp;rsquo;해서 분석하는 방법이다. 다변량 데이터의 분석이라는 관점으로 보자면 보다 적은 변수로 현상을 설명하기 위한 &amp;lsquo;차원축소&amp;rsquo;로써의 의미가 있다. 주성</description>
    </item>
    
    <item>
      <title>작도가능수</title>
      <link>https://freshrimpsushi.github.io/posts/construct-number-in-abstract-algebra/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/construct-number-in-abstract-algebra/</guid>
      <description>정의 $1$ 을 포함해 유한번의 사칙연산과 제곱근을 취함으로써 얻을 수 있는 수를 작도가능Constructible하다고 한다. 설명 작도가능이라는 것은 원래 고대 그리스의 논증 기하에서 논의되던 개념이었으나, 현대대수학을 동원하면 캠퍼스로 원을 그리고 자로 선을 그리는 과정이 딱히 필요 없어진다. 어떻게 이 연산들이 작도를 대신하는지 살펴보자.</description>
    </item>
    
    <item>
      <title>분산팽창인자 VIF</title>
      <link>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</guid>
      <description>정의 1 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 할 때 $i$ 번째 독립변수에 대한 다중회귀분석 $$X_{i} \leftarrow X_{1} , \cdots, X_{i-1} , X_{i+1} , \cdots, X_{p}$$ 의 중회귀계수를 $R_{i}^2$ 라고 두자. 다음을 $X_{i}$ 의 분산팽창인자Variance Inflation Factor라고 한다. $$\displaystyle \text{VIF}_{i}: = {{1} \over {1 - R_{i}^{2} }}$$ 설명 우선 다중공선성에 대해 읽어보는 것을 추천한다. VIF는 분산확대지수 로 번역되는 경우도 있는 것 같지만, 보통은 너</description>
    </item>
    
    <item>
      <title>추상대수의 용어로 표현된 대수학의 기본정리</title>
      <link>https://freshrimpsushi.github.io/posts/fundamental-theorem-of-algebra-in-terms-of-abstract-algebra/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fundamental-theorem-of-algebra-in-terms-of-abstract-algebra/</guid>
      <description>정의 1 체 $F$ 의 확대체를 $E$ 라고 하자. $F [ x ]$ 의 모든 다항함수가 $F$ 에서 영을 가지면 $F$ 를 대수적으로 닫혀있다Algebraically Closed고 한다. $\overline{ F_{E}} : = \left\{ \alpha \in E \mid \alpha \text{ is algebraic over } F \right\}$ 를 $E$ 에서 $F$ 의 대수적 폐포Algebraic Closure라 한다. 정리 [1]: $F$ 가 대수적으로 닫혀있다 $\iff$ 모든 $f(x) \in F [ x ]$ 는 $F [ x ]$ 의 $1$ 차항</description>
    </item>
    
    <item>
      <title>가우스의 이차상호 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gausss-law-of-quadratic-reciprocity/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gausss-law-of-quadratic-reciprocity/</guid>
      <description>정리 1 서로 다른 두 홀수 소수 $p , q$ 에 대해 다음이 성립한다. (1): $$ \left( {{ q } \over { p }} \right) = \begin{cases} \left( {{ p } \over { q }} \right) &amp;amp; p \equiv 1 \pmod{4} \lor q \equiv 1 \pmod{4} \\ - \left( {{ p } \over { q }} \right) &amp;amp; p \equiv 3 \pmod{4} \land q \equiv 3 \pmod{4} \end{cases} $$ (2): $$ \left( {{ p } \over { q }} \right) \left( {{ q } \over { p }} \right) = (-1)^{ { {p-1} \over {2} }{ {q-1} \over {2} } } $$ (1)과 (2)는 표현만 다를 뿐 같은 말이다. 이차잉여에 대해 너무나 깔끔하게 정리</description>
    </item>
    
    <item>
      <title>다중공선성</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</guid>
      <description>정의 1 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.이 때 독립변수 $ X_{1} , \cdots, X_{p}$ 중에서 독립변수끼리 강한 상관관계를 가지면 다중공선성Multicollinearity이 있다고 한다 실습 애초에 독립변수끼리 종속적이라는 것 자체가 회귀분석의 가정에 위배되는 말이며, 실제로 수치적인 문제를 야기해 분석 결과를 신뢰할 수 없게 만든다. 데이</description>
    </item>
    
    <item>
      <title>대수적 확대체</title>
      <link>https://freshrimpsushi.github.io/posts/algebraic-extension-field/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebraic-extension-field/</guid>
      <description>정의 1 $E$ 가 $F$ 의 확대체고 $n \in \mathbb{N}$ 이라 하자. $E$ 의 모든 원소가 $F$ 상에서 대수적 수면 $E$ 를 $F$ 의 대수적 확대체라 한다. $E$ 가 $F$ 상에서의 $n$ 차원 벡터 공간이면 $E$ 를 $F$ 상에서의 $n$ 차 유한확대체라 한다. $F$ 상에서의 유한확대체 $E$ 의 차수 를 $[ E : F ]$ 와 같이 나타낸다. 정리 $E$ 가 $F$ 의 유한확대체, $K$ 가 $E$ 의 유한확대체라고 하자. [1]: 유한확대체는 대수적 확대체</description>
    </item>
    
    <item>
      <title>오일러 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/eulers-criterion/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eulers-criterion/</guid>
      <description>정리 1 소수 $p \ne 2$ 에 대해 $$ a^{{p-1} \over {2}} \equiv \left( {a \over p} \right) \pmod{p} $$ 설명 이에 따르면 $a$ 하나만 이차잉여인지 비이차잉여인지 보고싶을 땐 무작정 계산해보면 그만이다. 물론 거듭제곱이 그렇게 만만한 작업은 아니지만 모든 수를 계산해보는 것보단 나을 것이다. 증명 자체는 별로 어렵지 않지만 보조정리가 많이 쓰이기 때문에 어느정도 공부를 해둬야 이해하기 쉽다. 증명 $a$ 가</description>
    </item>
    
    <item>
      <title>르장드르 기호의 곱셈적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-legendre-symbols-multiplicativity/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-legendre-symbols-multiplicativity/</guid>
      <description>정의 QR과 NR은 각각 이차잉여와 비이차잉여를 의미한다. 르장드르 기호Legendre Symbol는 $p$ 보다 작은 자연수 $a$ 에 대해 $$ \left( { a \over p } \right) = \begin{cases} 1 &amp;amp; a \text{: QR} \\ -1 &amp;amp; a \text{: NR} \end{cases} $$ 과 같이 정의된다. 정수론에서 $\displaystyle \left( {{x} \over {y}} \right)$ 는 분수가 아니라 르장드르 기호Legendre Symbol라 하며, 소수가 아닌 자연수에 대해 일반화하면 표기</description>
    </item>
    
    <item>
      <title>추상대수학에서의 벡터 공간</title>
      <link>https://freshrimpsushi.github.io/posts/vector-space-in-abstract-algebra/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vector-space-in-abstract-algebra/</guid>
      <description>정의 1 체 $F$ 와 아벨군 $V$ 의 모든 $\alpha , \beta \in F$ 와 $x, y \in V$ 가 다음의 조건을 만족하면 $V$ 를 $F$ 상의 벡터 공간Vector Space이라고 한다. $F$ 의 원소를 스칼라Scalar, $V$ 의 원소를 벡터Vector라 한다. (i): $\alpha x \in V$ (ii): $\alpha ( \beta x) = ( \alpha \beta ) x$ (iii): $\alpha (x + y) = \alpha x + \alpha y$ (iv): $1 x = x$ 첨수집합 $I$ 에 대해 $\left\{ x_{i} \right\}_{i \in I} \subset V$ 이라고 하자. 어떤 $\left\{ \alpha_{i} \right\}_{</description>
    </item>
    
    <item>
      <title>비선형회귀분석: 회귀분석에서의 변수 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation-of-variables/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation-of-variables/</guid>
      <description>개요 1 회귀분석은 기본적으로 변수들간의 선형관계를 밝히는 방법이지만, 필요하다면 데이터를 선형으로 &amp;lsquo;펴서&amp;rsquo; 분석할 수 있다. 이는 본질적으로 종속변수를 독립변수의 비선형결합으로 설명하는 것이다. 실습 내장데이터 Pressure 데이터를 불러와보자. Pressure 데이터는 사실 통계적으로 분석할 필요는 없다. 이는 어디까지나 자연현상</description>
    </item>
    
    <item>
      <title>이차잉여와 비이차잉여</title>
      <link>https://freshrimpsushi.github.io/posts/quadratic-residue-and-quadratic-nonresidue/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quadratic-residue-and-quadratic-nonresidue/</guid>
      <description>정의 1 소수 $p \ne 2$ 와 $a &amp;lt; p$ 에 대해 합동방정식 $x^{2} \equiv a \pmod{p}$ 의 해가 존재하면 $a$ 를 모듈로 $p$ 에 대한 이차잉여 QR이라 한다. $a$ 가 이차잉여가 아니면 비이차잉여 NR이라 한다. 설명 쉽게 말해 이차잉여란 $\pmod{p}$에서 제곱근이 존재하는 수를 의미한다. 예를 들어 소수 $7$ 을 생각해보면 $$ 1^2 \equiv 1 \pmod{7} \\ 2^2 \equiv 4 \pmod{7} \\ 3^2 \equiv 2 \pmod{7} \\ 4^2 \equiv 2 \pmod{7} \\ 5^2 \equiv 4 \pmod{7} \\</description>
    </item>
    
    <item>
      <title>밀러-라빈 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/miller-rabin-test/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/miller-rabin-test/</guid>
      <description>정리 1 홀수 $n,q$ 를 $n-1 = 2^{k} q$ 와 같이 나타내자. $$ a \nmid n \\ a^{q} \not\equiv 1 \pmod{n} $$ 이면서 모든 $i = 0, 1, \cdots , (k-1)$ 에 대해 $$ a^{2^{i} q} \not\equiv -1 \pmod{n} $$ 를 만족하는 $ a$ 가 존재하면 $n$ 은 합성수다. 설명 계산량이 늘어난만큼 페르마 판정법을 통과하는 합성수도 걸러낼 가능성이 있다. 예로써 카마이클 수인 $561$ 은 $n-1 = 560 = 2^4 \cdot 35$ 이 $2^{35} \equiv 263 \pmod{561}$ 이므로 $561$ 이 소수가 아님을 빠르게 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>실수체로 복소수체를 만들어내는 대수적인 방법</title>
      <link>https://freshrimpsushi.github.io/posts/algebraic-method-to-drive-complex-field-from-real-field/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebraic-method-to-drive-complex-field-from-real-field/</guid>
      <description>정리 1 $$ \mathbb{R} [x ] / \left&amp;lt; x^2 + 1 \right&amp;gt; \simeq \mathbb{C} $$ 설명 팩트로만 보면 당연하고 실수체에서 복소수체를 만들어내는 과정이 상당히 아름답다. $\mathbb{R} [x ]$ 를 $\left&amp;lt; x^2 \right&amp;gt;$ 로 자르든 $\left&amp;lt; x^2 + x \right&amp;gt;$ 로 자르든 원소의 모양새는 $ax + b$ 꼴로 나오겠지만 하필 $\left&amp;lt; x^2 + 1 \right&amp;gt;$ 로 자르는 이유가 있다. 적어도 한 번은 직접 증명해보면서 이 아름다움을 만끽하도록 하자. 증명 $\left( x^2 + 1 \right)$ 은 $F$ 상에서의 기</description>
    </item>
    
    <item>
      <title>코셀트 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/korselt-criterion/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/korselt-criterion/</guid>
      <description>개요 카마이클 수임을 판정하는 방법으로써 필요충분조건이라는 점이 또 유용하게 쓰일 수 있는 정리다. 정리 1 홀수 $n$ 이 합성수라고 하자. $n$ 은 카마이클 수 $\iff$ $p \mid n$ 을 만족하는 모든 소수 $p$ 에 대해 $p^2 \nmid n$ 이면서 $(p-1) \mid (n-1)$ 증명 카마이클 수의 정의: 자연수 $n$ 이 모든 $1 \le a \le n$ 에 대해 $a^{n} \equiv a \pmod{n}$ 를 만족하면 카마이클 수라 한다. $( \Rightarrow )$ 카마이클 수는 $2$ 를 제외한 서</description>
    </item>
    
    <item>
      <title>단순확대체</title>
      <link>https://freshrimpsushi.github.io/posts/simple-extension-in-abstract-algebra/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simple-extension-in-abstract-algebra/</guid>
      <description>정의 1 $F$ 의 확대체 $E$ 가 어떤 $\alpha \in E$ 에 대해 $E = F( \alpha )$ 이면 $E$ 를 $F$ 의 단순확대체Simple Extension라 한다. 설명 $F ( \alpha )$ 은 쉽게 말해 $F$ 에 없던 $\alpha$ 를 하나Simple만 넣어서 확장한 것으로 볼 수 있다. 실수체 $\mathbb{R}$ 으로 말할 것 같으면 그 확대체 $\mathbb{C}$ 의 $i \in \mathbb{C}$ 를 넣으면 $\mathbb{R} ( i ) = \mathbb{C}$ 가 된다. 중요한 팩트로써 $\alpha \in E$ 에 대해 $E = F ( \alpha )$ 면 모든</description>
    </item>
    
    <item>
      <title>원시근 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-primitive-root-thoerem/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-primitive-root-thoerem/</guid>
      <description>정의 1 $1 \le a \le p$ 가 $\text{ord}_{p} (a) = p-1$ 를 만족하면 법 $p$ 의 원시근이라 정의한다. 위수 $\text{ord}_{p} (a) $ 는 $a^{e} \equiv 1 \pmod{p}$ 를 만족하는 가장 작은 자연수 $e$ 를 의미한다. 정리 모든 소수 $p$ 는 $\phi ( p - 1)$ 개의 원시근을 갖는다. $\phi$ 는 토션트 함수다. 설명 $\text{ord}_{p} (a) = p-1$ 를 만족하는 $a$ 를 원시근이라고 부르는 이유는 페르마의 소정리에 의해 $a^{p-1} \equiv 1 \pmod{ p }$ 이므로 $\text{ord}_{p} (a) \le p-1$ 임은 보장되어 있는데,</description>
    </item>
    
    <item>
      <title>대수적 수와 초월수</title>
      <link>https://freshrimpsushi.github.io/posts/algebraic-number-and-transcendental-number/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/algebraic-number-and-transcendental-number/</guid>
      <description>정의 1 체 $F$ 의 확대체를 $E$ 라고 하자. 상수함수가 아닌 $f(x) \in F [ x ]$ 에 대해 $f( \alpha ) = 0$ 을 만족시키는 $\alpha \in E$ 를 $F$ 상에서 대수적Algebraic이라 하고, 대수적이지 않으면 초월적Transcendental이라 한다. $F = \mathbb{Q}$, $E = \mathbb{C}$ 이라고 할 때 $\alpha \in \mathbb{C}$ 가 대수적이면 대수적 수, 초월적이면 초월수라 한다. 설명 예를 들어 $ f(x) = x^2 - 2 $ 라는</description>
    </item>
    
    <item>
      <title>정수론에서의 위수</title>
      <link>https://freshrimpsushi.github.io/posts/order-in-analytic-number-theory/</link>
      <pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order-in-analytic-number-theory/</guid>
      <description>정의 1 $\gcd (a, p) = 1$ 이라고 하자. $a^{e} \equiv 1 \pmod{p}$ 를 만족하는 가장 작은 자연수 $e$ 를 $\text{ord}_{p} (a)$ 라 쓰고 법 $p$ 에서 $a$ 의 위수Order라 정의한다. 정리 $a^{n} \equiv 1 \pmod{p}$ 이라고 하면 $\text{ord}_{p} (a) \mid n$ 이다. 설명 예를 들어 $p=7$ 을 생각해보면 $$ \begin{align*} 1^{1} \equiv &amp;amp; 1 \pmod{ 7 } \\ 2^{3} \equiv &amp;amp; 1 \pmod{ 7 } \\ 3^{6} \equiv &amp;amp; 1 \pmod{ 7 } \\ 4^{3} \equiv &amp;amp; 1 \pmod{ 7 } \\ 5^{6} \equiv &amp;amp; 1 \pmod{ 7 } \\ 6^{2} \equiv &amp;amp; 1 \pmod{ 7 } \end{align*} $$ 이다. 여기서 $6$ 의 위수는 $2$</description>
    </item>
    
    <item>
      <title>확대체의 정의와 크로네커 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-kronecker-thoerem/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-kronecker-thoerem/</guid>
      <description>확대체의 정의 1 체 $F$ 에 대해 $F \le E$ 인 $E$ 를 $F$ 의 확대체Extension Field라 한다. 크로네커 정리 $f(x) \in F [ x ]$ 가 상수가 아니라고 하면 $F$ 의 확대체 $E$ 와 $f ( \alpha ) = 0$ 인 $\alpha \in E$ 가 존재한다. 설명 확대체의 예로써 $\mathbb{C}$ 는 $\mathbb{R}$ 의 확대체다. 크로네커의 정리는 당장 $F$ 에서는 다항함수의 근이 존재하지 않을지라도 정의역을 $E$ 로 키울 수 있고, 키우면 근</description>
    </item>
    
    <item>
      <title>카마이클 수</title>
      <link>https://freshrimpsushi.github.io/posts/carmichael-number/</link>
      <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/carmichael-number/</guid>
      <description>정의 1 자연수 $n$ 이 모든 $1 \le a \le n$ 에 대해 $a^{n} \equiv a \pmod{n}$ 를 만족하면 카마이클 수라 한다. 정리 모든 카마이클 수는 $2$ 를 제외한 서로 다른 소수의 곱으로만 나타난다. 설명 카마이클 수는 합성수임에도 불구하고 페르마 판정법을 통과하는, 말하자면 소수처럼 보이는 수다. 예로써 $561=3 \cdot 11 \cdot 17$ 은 합성수지만 $a^{561} \equiv a \pmod{561}$ 이 항상 성립한다. 한편 이러한 카마이클 수를 잡아</description>
    </item>
    
    <item>
      <title>주 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/principal-ideal-in-abstract-algebra/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/principal-ideal-in-abstract-algebra/</guid>
      <description>정의 1 단위원을 가지는 가환환 $R$ 의 원소 $a$ 로 생성되는 $\left&amp;lt; a \right&amp;gt;$ 를 $a$ 에 의해 생성되는 주 아이디얼Principal Ideal이라고 한다. 곱셈에 대한 항등원 $1$ 을 단위원이라 한다. 설명 $\left&amp;lt; a \right&amp;gt; := \left\{ r a \mid r\ \in R \right\}$ 의 표기는 순환군과 같지만 실제 순환군보다는 조금 더 큰 구조를 이룬다. 예로써 $\mathbb{Z}$ 의 모든 아이디얼 $n \mathbb{Z} = \left&amp;lt; n \right&amp;gt; = \left\{ \cdots , -2n , -n , 0 , n</description>
    </item>
    
    <item>
      <title>합동방정식의 거듭제곱근</title>
      <link>https://freshrimpsushi.github.io/posts/k-th-roots-modulo-m/</link>
      <pubDate>Mon, 31 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k-th-roots-modulo-m/</guid>
      <description>알고리즘 1 자연수 $b,k,m$ 가 $\gcd (b , m) = \gcd ( k , \phi (m) ) = 1$ 을 만족하면 합동방정식 $x^{k} \equiv b \pmod{ m }$ 의 해 $x$ 는 다음과 같이 계산할 수 있다. Step 1. $\phi (m)$ 을 계산한다. Step 2. $ku - \phi(m) v =1$ 을 만족하는 $u, v$ 을 찾고 양변에 $u$ 승을 취해 $x^{ku} \equiv b^{u} \pmod{m}$ 를 얻는다. Step 3. $b^{u} \pmod{ m }$ 을 연속제곱법으로 계산한다. 설명 $\phi$ 는 토션트 함수로, 곱셈적 성질을 가져 $m$ 의 소인수분해가 핵심이다</description>
    </item>
    
    <item>
      <title>소 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/prime-ideal-in-abstract-algebra/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prime-ideal-in-abstract-algebra/</guid>
      <description>정의 1 가환환 $R$ 의 아이디얼 $P \ne R$ 가 $a, b \in R$ 에 대해 $ab \in P$ 이면 $a \in P$ 또는 $b \in P$ 일 때, $P$ 가 $R$ 에서 소 아이디얼Prime Ideal이라 한다. 설명 소Prime라는 명칭에서 알 수 있듯 곱해진 원소를 쪼개는 것에서 출발한다. 예로써 정수환 $\mathbb{Z}$ 을 생각해보면 $2 \mathbb{Z}$ 의 모든 원소들은 $2k$ 와 같은 형태로 나타나고, $2 \in 2 \mathbb{Z}$ 이므로 소 아이디얼이 된다. 같</description>
    </item>
    
    <item>
      <title>극대 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/maximal-ideal-in-abstract-algebra/</link>
      <pubDate>Fri, 28 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maximal-ideal-in-abstract-algebra/</guid>
      <description>정의 1 환 $R$ 의 아이디얼 중 $R$ 이외의 어떤 아이디얼 $N \ne R$ 에도 포함되지 않는 아이디얼 $M \ne R$ 을 $R$ 의 극대 아이디얼Maximal Ideal이라 한다. 다시 말해, $M \subsetneq R$ 이 극대 아이디얼이라는 것은 다음과 같다. $$ \nexists N : M \subsetneq N \subsetneq R $$ 설명 대수학에서 말하는 &amp;lsquo;맥시멀&amp;rsquo;는 집합론에서의 맥시멀과 거의 똑같다. 당연히 정의</description>
    </item>
    
    <item>
      <title>힐베르트 공간은 리플렉시브임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/hilbert-space-is-reflexive/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hilbert-space-is-reflexive/</guid>
      <description>정리 $H^{\ast \ast} \approx H$ 설명 짧고 간단하지만 힐베르트 공간을 연구함에 있어서 듀얼 스페이스보다 커지는 것을 생각할 필요가 없다는 것은 굉장히 좋은 일이다. 증명 Part 1. $(H^{ \ast } , \| \cdot \| )$은 힐베르트 공간이다 리즈 표현 정리 $H$가 힐베르트 공간이라고 하자. $H$의 선형 범함수 $f \in H^{ \ast }$와 $\mathbf{x} \in H$ 에 대해 $f ( \mathbf{x} ) = \left\langle \mathbf{x} , \mathbf{y} \right\rangle</description>
    </item>
    
    <item>
      <title>삼중대각행렬의 행렬식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-tridiagonal-matrixs-determinant/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-tridiagonal-matrixs-determinant/</guid>
      <description>공식 삼중대각행렬 $X_{n} := \begin{bmatrix} x &amp;amp; 1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\ 1 &amp;amp; x &amp;amp; 1 &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; x &amp;amp; \cdots &amp;amp; 0 &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; x &amp;amp; 1 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 1 &amp;amp; x \end{bmatrix}$ 에 대해 $$ | x_{n}| = U_{n} \left( {{x} \over {2}} \right) $$ $U_{n}$ 은 $n$ 차 제2종 체비셰프 다항함수를 의미한다. 물론 $X_{n}$ 은 일반적인 삼중대각행렬이 아니고 삼중대각 퇴플리츠Toepli</description>
    </item>
    
    <item>
      <title>리즈 표현 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-riesz-representation-theorem/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-riesz-representation-theorem/</guid>
      <description>정리1 $\left( H, \left\langle \cdot,\cdot \right\rangle \right)$가 힐베르트 공간이라고 하자. $H$의 선형 범함수 $f \in H^{ \ast }$와 $\mathbf{x} \in H$ 에 대해 $f ( \mathbf{x} ) = \left\langle \mathbf{x} , \mathbf{w} \right\rangle$와 $\| f \|_{H^{\ast}} = \| \mathbf{w} \|_{H}$ 을 만족하는 $\mathbf{w} \in H$ 가 유일하게 존재한다. 설명 쉽게 말해 힐베르트 공간의 듀얼 스페이스 $H^{ \ast }$ 의 모든 원소가 어떻게 생겼는지 규명한 셈인데, 이게 말은 간단해도</description>
    </item>
    
    <item>
      <title>단원을 가지는 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/ideal-with-unity/</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ideal-with-unity/</guid>
      <description>정리 1 [1]: 단위원 $1$ 을 갖는 환 $R$ 의 아이디얼 $I$ 가 단원을 가지면 $I = R$ [2]: 체 $F$ 는 $\left\{ 0 \right\}$, $F$ 외의 아이디얼을 가지지 않는다. 설명 정리 [1]은 아이디얼에 단원이 있다는것만으로 전체가 되어버린다는 정리로, 귀류법을 사용한 증명에 빈번하게 쓰이는 보조정리다. 또한 단위원은 단원이라는 점에서, 멀쩡한 아이디얼이라면 $1$ 을 갖지 않는다는 것을 보장해주기</description>
    </item>
    
    <item>
      <title>직교 분해 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-orthogonal-decomposition-theorem/</link>
      <pubDate>Sun, 23 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-orthogonal-decomposition-theorem/</guid>
      <description>정리1 $\left( H, \left\langle \cdot,\cdot \right\rangle \right)$를 힐베르트 공간이라 하자. 그러면 $H$의 닫힌 부분공간 $M$에 대해서 $$ H = M \oplus M^{\perp} $$ 따름정리 $$ \left( M^{\perp} \right)^{\perp} = M $$ 따름정리로써 $\left( M^{\perp} \right)^{\perp} := \left\{ \mathbf{x} \in H \mid \left\langle \mathbf{x} , \mathbf{m}^{\perp} \right\rangle = 0 , \mathbf{m}^{\perp} \in M^{\perp} \right\}$ 에 대해 위의 사실을 증명해낼 수 있다. 설명 $M^{\perp } := \left\{ \mathbf{x} \in H \mid \left\langle \mathbf{x} , \mathbf{m} \right\rangle = 0 , \mathbf{m} \in M \right\}$ 을 $M$ 의 직교여집합이라고 한다. 직교성만큼</description>
    </item>
    
    <item>
      <title>베이즈 인자를 통한 가설검정</title>
      <link>https://freshrimpsushi.github.io/posts/statistiical-hypothesis-test-by-bayes-factor/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statistiical-hypothesis-test-by-bayes-factor/</guid>
      <description>빌드업 고전적인 가설검정을 쓸 수 있게 되려면 기각역, 유의확률과 같은 개념에 대한 수학적인 이해를 포함해서 이를 직관적으로 받아들일 수 있을 정도의 통계학적 센스까지 갖추어야한다. 학부 1학년 교양 수준에서도 몇 시간이나 할애해가며 가르치고, 그래도 가설검정을 제대로 받아들이지 못하는 학생이 수두룩한 것도 당연한 일이다. 고등학교에서 배우는 통</description>
    </item>
    
    <item>
      <title>방데르몽드 행렬의 행렬식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-vandermonde-matrix-determinant/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-vandermonde-matrix-determinant/</guid>
      <description>정의 서로 다른 $1, x_{1} , x_{2 } , \cdots , x_{n}$ 에 대해 다음과 같이 정의된 행렬 $V_{n}$ 을 방데르몽드 행렬Vandermonde Matrix이라고 한다. $$ V_{n} := \begin{bmatrix} 1 &amp;amp; x_{1} &amp;amp; x_{1}^{2} &amp;amp; \cdots &amp;amp; x_{1}^{n-1} \\ 1 &amp;amp; x_{2} &amp;amp; x_{2}^{2} &amp;amp; \cdots &amp;amp; x_{2}^{n-1} \\ \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 1 &amp;amp; x_{n} &amp;amp; x_{n}^{2} &amp;amp; \cdots &amp;amp; x_{n}^{n-1} \end{bmatrix} $$ 공식 $V_{n}$ 의 행렬식은 $$ \det V_{n} = \prod_{1 \le i &amp;lt; j \le n } (x_{j} - x_{i}) $$ 설명 방데르몽드 행렬은 특이하게 생겼지만 미분방</description>
    </item>
    
    <item>
      <title>제1종 제2종 체비셰프 다항함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relations-between-chebyshev-polynomials/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relations-between-chebyshev-polynomials/</guid>
      <description>정리 제1종 체비셰프 다항함수 $T_{n} (x) = \cos \left( n \cos^{-1} x \right)$ 과 제2종 체비셰프 다항함수 $\displaystyle U_{n} (x) = {{1} \over {n+1} } T_{n+1} &amp;rsquo; (X)$ 은 다음의 관계를 가진다. [1]: $$U_{n} (x) - U_{n-2} (x) = 2 T_{n} (X)$$ [2]: $$T_{n} (x) - T_{n-2} (x) = 2( x^2 - 1 ) U_{n-2} (x)$$ 보통 $0 \le \theta \le \pi$ 에 대해 $\theta := \cos^{-1} x $ 라고 둔다. 증명 위 등식들을 증명하는 데에는 아래의 팩트가 필수적이다. 제2종 체비셰프 다항함수의 다른 표현: $$U_{n} (x) = {{\sin \left( ( n</description>
    </item>
    
    <item>
      <title>크레이머 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cramer-rule/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cramer-rule/</guid>
      <description>개요 크레이머 공식Cramer Rule은 연립방정식을 제대로 풀어내는데에 효율적이라곤 할 수 없지만 $A_{j}$ 가 비가역행렬이라거나 $A$ 자체가 행렬식을 구하기 편리하도록 특정한 조건이 주어져있다면 필요한 답만 바로바로 구해내는데 충분히 유용하게 쓰일 수 있다. 정리 연립방정식 $A \mathbb{x} = \mathbb{b}$ 이 가역행렬 $$ A = \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots</description>
    </item>
    
    <item>
      <title>제2종 체비셰프 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-second-kind/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-second-kind/</guid>
      <description>정의 $$U_{n} (x) := {{1} \over {n+1} } T_{n+1} &amp;rsquo; (x) = {{\sin \left( ( n +1 ) \theta \right)} \over { \sin \theta }} $$ 을 제2종 체비셰프 다항함수라 한다. 기초 성질 재귀 공식 [0]: $$U_{n+1} (x) = 2x U_{n} (x) - U_{n-1} (X)$$ 직교 집합 [1] 함수의 내적: $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx$ 에 대해 웨이트 $w$ 를 $\displaystyle w(x) := \sqrt{1 - x^2}$ 와 같이 주면 $\left\{ U_{0} , U_{1}, U_{2}, \cdots \right\}$ 은 직교 집합이 된다. 체비셰프 노드 [2]: $\displaystyle U_{n} (X)$ 의 근은 $k=1, \cdots , n$ 에 대해 다음과 같다. $$x_{k} = \cos \left( {{k} \over {n+1}} \pi \right)$$ 기</description>
    </item>
    
    <item>
      <title>최단 벡터 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-minimizing-vector-theorem/</link>
      <pubDate>Mon, 17 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-minimizing-vector-theorem/</guid>
      <description>정리1 $\left( H, \left\langle \cdot,\cdot \right\rangle \right)$를 힐베르트 공간이라고 하자. $M \lneq H$ 을 공집합이 아닌 닫힌 컨벡스 부분공간이라고 하자. 그러면 $\mathbf{x} \in ( H \setminus M)$ 에 대해 $$ \delta := \| \mathbf{x} - \mathbf{m}_{0} \| = \inf_{\mathbf{m} \in M} \| \mathbf{x} - \mathbf{m} \| &amp;gt; 0 $$ 을 만족하는 $\mathbf{m}_{0} \in M$가 유일하게 존재한다. 설명 부분공간$M$ 이 컨벡스하다는 것은 모든 $\mathbf{x},y \in M$ 과 $\lambda \in [0,1]$ 에 대해 다음이 성립한다는 것이다. $$ \lambda \mathbf{x}</description>
    </item>
    
    <item>
      <title>제1종 체비셰프 다항함수</title>
      <link>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-first-kind/</link>
      <pubDate>Sun, 16 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chebyshev-polynomial-of-the-first-kind/</guid>
      <description>정의 1 $T_{n} (x) = \cos \left( n \cos^{-1} x \right)$ 을 제1종 체비셰프 다항함수라 한다. 기초 성질 재귀 공식 [0]: $$T_{n+1} (x) = 2x T_{n} (x) - T_{n-1} (X)$$ 직교 집합 [1] 함수의 내적: $\displaystyle \left&amp;lt;f, g\right&amp;gt;:=\int_a^b f(x) g(x) w(x) dx$ 에 대해 웨이트Weight $w$ 를 $\displaystyle w(x) := {{1} \over { \sqrt{1 - x^2} }}$ 와 같이 주면 $\left\{ T_{0} , T_{1}, T_{2}, \cdots \right\}$ 은 직교 집합이 된다. 체비셰프 노드 [2]: $T_{n} (x)$ 의 근은 $k=1, \cdots , n$ 에 대해 다음과 같은 체비셰프 노드다. $$x_{k} = \cos \left( {{2k-1} \over {2n}} \pi \right)$$</description>
    </item>
    
    <item>
      <title>함수해석학에서 힐베르트 공간</title>
      <link>https://freshrimpsushi.github.io/posts/hilbert-space/</link>
      <pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hilbert-space/</guid>
      <description>정의1 완비 내적 공간을 힐베르트 공간Hilbert space라고 한다. 힐베르트의 이름을 따서 주로 $H$라고 표기한다. 설명 완비 공간이란, 모든 코시수열이 수렴하는 공간을 말한다. 바나흐 공간도 완비공간이므로, 힐베르트 공간을 내적이 주어지는 바나흐 공간이라고 설명할 수도 있다. 예시로는 다음과 같은 공간들이 있다. 르벡 공간 $L^{2}$ $\ell^{2}$ 공간</description>
    </item>
    
    <item>
      <title>벡터 공간의 리플렉시브</title>
      <link>https://freshrimpsushi.github.io/posts/reflexive/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reflexive/</guid>
      <description>정의 1 $X$를 벡터공간, $X^{\ast \ast}$를 바이듀얼이라고 하자. $X^{\ast \ast} \approx X$면, $X$가 리플렉시브reflexive라고 한다. 설명 일반적으로 벡터 공간은 듀얼을 취할때마다 점점 그 크기가 더 커진다. 그런데 리플렉시브라는 말은 사실상 듀얼 스페이스가 계속해서 커지지 않는 공간이라고 보아도 좋다. 리플렉시브한 공간에는 다음의 예시가 있</description>
    </item>
    
    <item>
      <title>최고사후밀도 신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</guid>
      <description>정의 1 모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $C : = \left\{ \theta \in \Theta \ | \ p ( \theta | y ) \ge k (\alpha) \right\}$ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 최고사후밀도 신용구간HPD이라고 한다. 여기서 $k(\alpha)$ 는 $p(\theta \in C | y ) \ge 1 - \alpha$ 를 만족하는 가장 큰 상수다. 설명 수식과 말보다는 그림을 통해 보는게 훨씬 이해하기 좋다. 실제 계산에서도 위와 같이 $k$ 를 계</description>
    </item>
    
    <item>
      <title>등거리 사상</title>
      <link>https://freshrimpsushi.github.io/posts/isometric-map/</link>
      <pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isometric-map/</guid>
      <description>정의 두 거리공간 $(X,\ d_X), (Y,\ d_Y)$에 대해서 아래의 조건을 만족하는 사상 $f : X \to Y$가 존재하면 $X$와 $Y$가 아이소메트릭isometric이라 하고 $X \approx Y$라고 표기한다. 또한 사상 $f$를 등거리 사상isomertic map, isometry 이라 한다. $$ d_X(x_1,\ x_2) =d_Y\big( f(x_1),\ f(x_2) \big),\quad \forall\ x_1,x_2\in X $$ 설명 등거리 사상은 이름 그대로 거리를 보존하는 사상이다. 따라서 등거</description>
    </item>
    
    <item>
      <title>복소수의 부호</title>
      <link>https://freshrimpsushi.github.io/posts/sign-of-complex-number/</link>
      <pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sign-of-complex-number/</guid>
      <description>정의 1 2 복소수 $\lambda \in \mathbb{C}$ 에 대해 부호Sign를 다음과 같이 정의한다. $$ \text{sign} ( \lambda ) = \begin{cases} \displaystyle {{ \lambda } \over { \left| \lambda \right| }} &amp;amp;, \lambda \ne 0 \\ 0 &amp;amp;, \lambda = 0 \end{cases} $$ 설명 쉽게 체크할 수 있는 예로써 실수의 부호 $\text{sign} ( +2 ) = 1$, $\text{sign} ( -3 ) = -1$ 를 바로 확인할 수 있다. 따라서 실수의 일반화라는 점에서는 충분히 좋은 정의다. 같이보기 실수의 부호 https://functions.wolfram.com/ComplexComponents/Sign/introductions/ComplexComplements/02/&amp;#160;&amp;#x21a9;&amp;#xfe0e; https://kr.mathworks.com/help/symbolic/sign.html&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>쌍대 공간</title>
      <link>https://freshrimpsushi.github.io/posts/dual-space/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dual-space/</guid>
      <description>쌍대공간 정의11 벡터공간 $X$의 모든 연속인 선형 범함수들의 집합을 $X^{ \ast }$로 표기하고 이를 $X$의 쌍대공간dual space, 간단히 $X$의 듀얼이라 하고 다음과 같이 표기한다. $$ X^{ \ast }:=\left\{ x^{ \ast }:X\to \mathbb{C}\ |\ x^{ \ast } \text{ is continuous and linear} \right\} $$ $$ X^{ \ast }:=B(X,\mathbb{C}) $$ $B \left( X, \mathbb{C} \right)$는 정의역이 $X$고 공역이 $\mathbb{C}$인 유계 선형작용소의 집합이</description>
    </item>
    
    <item>
      <title>신용구간과 신뢰구간의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</guid>
      <description>요약 신용구간과 신뢰구간의 차이는 실로 베이지안과 프리퀀티스트의 차이라고 볼 수 있다. 신뢰구간(프리퀀티스트): 모수는 고정된 상수고, 신뢰구간이 랜덤으로 구해진다. 신용구간(베이지안): 모수도 분포를 가진 변수고, 신용구간도 사후분포로 구해진다. 신뢰구간 고전통계에서 모수 $\mu$ 에 대한 $95 \% $ 신뢰구간 $[a , b]$ 이 의미하는 것은 같은 방법</description>
    </item>
    
    <item>
      <title>선형범함수가 선형독립결합으로 나타나는 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-of-that-linear-functional-is-linearly-independent/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-of-that-linear-functional-is-linearly-independent/</guid>
      <description>정리 $f, f_{1} , \cdots , f_{n}$ 가 정의역이 $X$ 인 선형범함수라고 하자. (a) $c_{1} , \cdots , c_{n} \in \mathbb{C}$ 에 대해 $\displaystyle f = \sum_{i=1}^{n} c_{i} f_{i}$ $\iff$ $\displaystyle \bigcap_{i=1}^{n} \ker ( f_{i} ) \subset \ker (f)$ (b) $f_{1} , \cdots , f_{n}$ 이 선형독립 $\iff$ $f_{j} (x_{i} ) = \delta_{ij}$ 을 만족하는 $x_{1} , \cdots , x_{n}$ 이 존재한다. 이때 $\delta_{ij}$ 는 크로네커 델타이다. 설명 커널이 동차homogeneous의 개념과 관계가 있다는 걸 생각해보면 선형 동차 미분방정식에 대한 유용한 팩트임</description>
    </item>
    
    <item>
      <title>추상대수학에서의 래디컬과 닐래디컬</title>
      <link>https://freshrimpsushi.github.io/posts/radical-and-nilradical-in-abstract-algebra/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/radical-and-nilradical-in-abstract-algebra/</guid>
      <description>정의 1 $N$ 이 환 $R$ 의 아이디얼이라고 하자. $\text{rad} N := \left\{ a \in R \ | \ a^n \in N \right\}$ 을 $N$ 의 래디컬Radical이라 한다. $a^{n} = 0$ 을 만족하는 $n \in \mathbb{N}$ 이 존재하면 $a$ 가 닐포텐트Nilpotent라 한다. 닐포텐트 엘러먼트들의 집합 $\text{nil} R := \left\{ a \in R \ | \ a^n = 0 \right\}$ 을 $R$ 의 닐래디컬Nilradical이라 한다. 설명 $N$ 의 래디컬을 $\sqrt{N}$, $R$ 의 닐래디컬을 $\sqrt{0}$</description>
    </item>
    
    <item>
      <title>회귀분석에서의 교호작용</title>
      <link>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</guid>
      <description>빌드업 우선 질적변수를 포함한 회귀분석에 대해 읽어보는 것을 추천한다. 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 우선 질적변수가 있으므로 성별을 $$ S = \begin{cases} 1 &amp;amp; ,\text{여성} \\ 0 &amp;amp; ,\text{남성} \end{cases} $$ 그리고 학력을 $$ E_{1} = \begin{cases} 1 &amp;amp; ,\text{대졸} \\ 0 &amp;amp; ,\text{고졸</description>
    </item>
    
    <item>
      <title>선형범함수가 연속일 필요충분조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-of-that-linear-functional-to-be-continuous/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-of-that-linear-functional-to-be-continuous/</guid>
      <description>functional 라 한다. $$ f : X \to \mathbb{C} $$ $f$가 [선형 작용소](../728)이면 **선형 범함수**라 한다. ## 설명 한국어로 순화하면 &#39;범함수&#39;라서 별 느낌이 없지만 영어로 볼땐 [functional](../1780)이 형용사가 아니라 명사라는 것에 주의해야한다. 또한 범함수汎函數라는 번역은 [초함수](../1009), [일반화</description>
    </item>
    
    <item>
      <title>질적변수를 포함한 회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/regression-analysis-including-qualitative-factor/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regression-analysis-including-qualitative-factor/</guid>
      <description>개요 회귀분석을 하면서 독립변수로 언제나 양적변수가 들어온다는 보장은 없다. 성별이 무엇인지, 어떤 기업 소속인지, 무슨 색상인지, 금속인지 등등 범주형 자료 역시 분석에 반영시킬 필요가 있다. 빌드업 1 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 다중회귀분석을 사용하면 $Y \leftarrow X_{1} + X_{2}$ 와 같이 연봉 $Y$</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 정규성</title>
      <link>https://freshrimpsushi.github.io/posts/normality-of-standard-residuals/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normality-of-standard-residuals/</guid>
      <description>진단법 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 정규성은 잔차들의 흩어진 모양보다는 히스토그램으로 확인하거나 정규성 검정을 하는 게 낫다. 왼쪽은 가운데에서 위 아래로 갈수록 그 밀도가 작아지는 것에 비해 오른쪽은 위아래 할 것 없이 고르게 퍼져있다. 하지만 이렇게 정말 잔차들이 정규분포 외의 알려진 분포를 따르는 케이스는</description>
    </item>
    
    <item>
      <title>신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval/</guid>
      <description>정의 1 모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $P ( \theta \in C | y ) \ge 1 - \alpha$ 를 만족할 때, $C$ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 신용구간Credible Interval이라고 한다. 설명 베이지안에서의 구간추정이란 모수 $\theta$ 를 포함하는 확률이 높은 구간을 찾는 것이다. 이로써 찾아지는 &amp;lsquo;신용구간&amp;rsquo</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 독립성</title>
      <link>https://freshrimpsushi.github.io/posts/independency-of-standard-residuals/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independency-of-standard-residuals/</guid>
      <description>진단법 직관적 패턴 파악 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 독립성을 확인하려면 잔차 그림에 어떤 뚜렷한 경향이 나타나지 않으면 된다. 안타깝게도 독립성의 진단은 다른 회귀분석의 가정에 비해 매우 주관적일 수밖에 없다. 독립성이 결여된 예로 가장 자주볼 수 있는 경우는 위와 같이 정체를 알 수 없는 직선이 보이는 것이다. 물</description>
    </item>
    
    <item>
      <title>통계학의 세가지 대표값: 최빈값, 중앙값, 평균</title>
      <link>https://freshrimpsushi.github.io/posts/mode-median-mean/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mode-median-mean/</guid>
      <description>개요 대표값은 데이터를 설명하는 대표적인 값을 말한다. 수천 수만에 달하는 데이터가 있어도 일일이 다 살펴볼 게 아니라면 결국 중요한 것은 데이터가 무엇을 의미하느냐고, 대표값은 이를 효과적으로 요약한다. 그 중 가장 자주 쓰이는 세가지 대표값으로써 최빈값, 중앙값, 평균이 있다. (0) 최빈값: 표본에서 가장 자주 발생한 값 (1) 중앙값: 표본에서 중앙에 위</description>
    </item>
    
    <item>
      <title>추상대수학에서의 아이디얼</title>
      <link>https://freshrimpsushi.github.io/posts/ideal-in-abstract-algebra/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ideal-in-abstract-algebra/</guid>
      <description>정의 1 환 $(R , + , \cdot )$ 의 모든 $a,b \in R$ 에 대해 $a I \subset I$ 와 $I b \subset I$ 을 만족하는 부분군 $(I, +)$ 을 아이디얼Ideal이라 한다. 설명 간단한 예시로써 $n \mathbb{Z}$ 는 $\mathbb{Z}$ 의 아이디얼이 된다. 아이디얼이라는 명명은 말 그대로 이상적인Ideal에서 왔다. 추상대수에서 다루기에 이상적인 부분군이기 때문에 실제로 그렇게 부르는 것이다. 특히 $R$ 이 가환환이라면 $I$ 가</description>
    </item>
    
    <item>
      <title>유계 선형작용소의 제곱의 놈</title>
      <link>https://freshrimpsushi.github.io/posts/norm-of-square-of-bounded-linear-operator/</link>
      <pubDate>Fri, 30 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-of-square-of-bounded-linear-operator/</guid>
      <description>정리 유계 선형 작용소 $T, T^2 \in B(X,X)$ 에 대해 $T(Tx) = T^{2} x$이면 $$ \left\| T^{2} \right\| = \left\| T \right\|^{2} $$ 설명 단순하게 보이지만 자그마치 3개의 성질이 합쳐진 컴비네이션이다. 자연수에 대해 일반화하면 $\left\| T^{m} \right\| = \left\| T \right\|^{m}$으로, 거듭제곱을 자유자재로 넣고 뺄 수 있음을 보장하기 때문에 아주 유용하다. 증명 전략: 양쪽 방향으로 똑같이 성립하는 부등식을 세</description>
    </item>
    
    <item>
      <title>아이젠슈타인 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/eisenstein-criterion/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eisenstein-criterion/</guid>
      <description>정리 1 $f(x) = a_{n} x^{n} + \cdots + a_{0 } \in \mathbb{Z} [ x ]$ 가 소수 $p \in \mathbb{Z}$ 와 $k = 0,1,2, \cdots , n-1$ 에 대해 다음 조건들을 만족하면 $f(x)$ 는 $\mathbb{Q}$ 상에서 기약함수다. (i): $a_{n} \not\equiv 0 \pmod{p}$ (ii): $a_{k} \equiv 0 \pmod{p} $ (iii): $a_{0} \not\equiv 0 \pmod{p^2}$ 설명 $f(x) = ax^{n} + b$ 꼴의 정수다항식에 대해 아주 쉬운 판정법으로써 의미가 있다. $\mathbb{Q}$ 에 대한 판정법이라는 점에서 대수적 수와 관련된 논의에서 유용하게 쓰일 수 있다. 예제 $f(x) = 25 x^{5} - 9 x^4 - 3</description>
    </item>
    
    <item>
      <title>라플라스 전개</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-expansion/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-expansion/</guid>
      <description>빌드업 정사각행렬 $A_{n \times n} = (a_{ij})$ 의 $i$ 번째 행과 $j$ 번째 행을 제거한 행렬의 행렬식 $M_{ij}$ 을 소행렬식Minor이라고 한다. 이에 대해 $C_{ij} := (-1)^{i + j} M_{ij}$ 를 여인자Cofactor라고 한다. 정리 [1] 선택된 $i$행 에 대해 $$ \det A = \sum_{j=1}^{n} a_{ij} C_{ij} $$ [2] 선택된 $j$열 에 대해 $$ \det A = \sum_{i=1}^{n} a_{ij} C_{ij} $$ 설명 라플라스 전개는 여인자 전개 로도 불리는 정리로써, 그 유용함이 이루 말할</description>
    </item>
    
    <item>
      <title>다항함수의 기약원</title>
      <link>https://freshrimpsushi.github.io/posts/irreducible-element-in-abstract-algebra/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/irreducible-element-in-abstract-algebra/</guid>
      <description>정의 1 상수함수가 아닌 $f(x) \in F [ x ]$ 가 $f(x)$ 보다 차수가 낮은 어떤 $g(x) , h(x) \in F [ x ]$ 의 곱 $f(x) = g(x) h(X)$ 으로 나타낼 수 없을 때 $f(x)$ 를 $F$ 상에서의 기약원Irreducible Element이라 한다. 설명 예로써 $\mathbb{Q} [x ]$ 를 생각해보면 $x^2 - 2$ 은 $\mathbb{Q}$ 상에서 기약원이지만, $\mathbb{R} [ x ]$ 에서의 $x^2 - 2$ 은 $\mathbb{R}$ 상에서 $$ (x + \sqrt{2} ) ( x - \sqrt{2} ) $$ 로 인수분해가 가능하다. 또</description>
    </item>
    
    <item>
      <title>인수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-factor-theorem/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-factor-theorem/</guid>
      <description>정리 1 $f(x) \in F [ x ]$ 라고 하자. $$ f(a) = 0 \iff f(x) = (x-a) q(x) $$ 설명 중학교부터 지겹도록 해온 인수분해의 존재성을 보장하는 정리다. 주의할 것은 나눗셈 정리나 인수 정리와 같은 팩트들은 다항함수의 차수가 유한할 때 의미가 있다는 것이다. 증명 $( \Rightarrow )$ 나눗셈 정리: $a_{n} \ne 0$ 과 $b_{m} \ne 0$, 그리고 $n &amp;gt; m &amp;gt; 0$ 에 대해 $F [ x ]$ 의 두 원소를 $$ f(x) = a_{n} x^{n} + \cdots + a_{1} x + a_{0} \\ g(x)</description>
    </item>
    
    <item>
      <title>나눗셈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-division-algorithm/</link>
      <pubDate>Fri, 23 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-division-algorithm/</guid>
      <description>정리 1 $a_{n} \ne 0$ 과 $b_{m} \ne 0$, 그리고 $n &amp;gt; m &amp;gt; 0$ 에 대해 $F [ x ]$ 의 두 원소를 $$ f(x) = a_{n} x^{n} + \cdots + a_{1} x + a_{0} \\ g(x) = b_{m} x^{m} + \cdots + b_{1} x + b_{0} $$ 이라고 하자. 그러면 $f(x) = g(x) q(x) + r(X)$ 를 만족하는 $q(x), r(x) \in F [ x ]$ 이 유일하게 존재한다. $r$ 의 차수는 $m$ 보다 작다. 설명 꼭 정리가 있어야 알 수 있는 사실은 아니지만 대수적으로 엄밀한 증명이라는 의의가 있다. 증명 $$ S : = \left\{ f(x)</description>
    </item>
    
    <item>
      <title>선형작용소의 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-linear-operator/</link>
      <pubDate>Thu, 22 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-linear-operator/</guid>
      <description>정리 1 $T : (X , \left\| \cdot \right\|_{X}) \to ( Y , \left\| \cdot \right\|_{Y} )$ 가 선형작용소라고 하자. (a) $T$가 유계이면 모든 $x \in X$ 에 대해 $\left\| T(x) \right\|_{Y} \le \left\| T \right\| \left\| x \right\|_{X}$ (b) $T$는 연속 $\iff$ $T$ 는 유계 (c) $X$가 유한 차원 공간이면 $T$ 는 연속이다. (d) $Y$가 바나흐 공간이면 $( B(X,Y) , \| \cdot \| )$는 바나흐 공간이다. 설명 $B(X,Y)$ 는 유계 선형작용소들의 공간이므로 (b) 에 의해 이 공간의 작용소들은 모두</description>
    </item>
    
    <item>
      <title>다항함수의 영</title>
      <link>https://freshrimpsushi.github.io/posts/zero-of-polynomial-in-abstract-algebra/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zero-of-polynomial-in-abstract-algebra/</guid>
      <description>정의 1 $$ f(x) : = \sum_{i=0}^{n} a_{i} x^{i} = a_{0} + a_{1} x + \cdots + a_{k} x^{k} $$ 다항함수 $f \in F [x]$ 와 체 $F \le E$ 에 대해 $\alpha \in E$ 에서의 평가함수Evaluation $\phi_{\alpha} : F [ x ] \to E$ 를 다음과 같이 정의하자. $$ \phi_{\alpha} ( f(x) ) : = a_{0} + a_{1} \alpha + \cdots + a_{n} \alpha^n = f (\alpha) $$ $f( \alpha ) = 0$ 을 만족시키는 $\alpha \in E$ 를 $f(x)$ 의 영Zero이라 한다. 설명 평가함수 팩트로써, $\phi_{\alpha}$ 는 준동형사상이 된다. 정의가 너무</description>
    </item>
    
    <item>
      <title>함수해석학에서 작용소란</title>
      <link>https://freshrimpsushi.github.io/posts/operator/</link>
      <pubDate>Tue, 20 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/operator/</guid>
      <description>정의1 $(X, \left\| \cdot \right\|_{X}), (Y, \left\| \cdot \right\|_{Y})$를 놈 공간이라고 하자. 놈 공간에서 놈 공간으로의 사상을 작용소operator라 한다. $x,x_{1},x_{2}\in X$ 에 대해서, $T : X \to Y$가 $$ T( x_{1} + x_{2} ) = T( x_{1} ) + T( x_{2} ) \quad \text{and} \quad T( a x ) = a T( x ) $$ 를 만족하면 선형 작용소라고 한다. 모든 $x \in X$ 에 대해 $\left\| T(x) \right\|_{Y} \le C \left\| x \right\|_{X}$를 만족</description>
    </item>
    
    <item>
      <title>빅오 노테이션이 분모에 있을 때 분자로 올리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/trick-for-big-o-notation-in-denominator/</link>
      <pubDate>Mon, 19 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trick-for-big-o-notation-in-denominator/</guid>
      <description>정리 $a \ne 0$ 와 $p&amp;gt;0$, $n \in \mathbb{N}$ 에 대해 다음이 성립한다. $$ {{1} \over { \sqrt[p]{a + O ( h^n ) } }} = {{1} \over { \sqrt[p]{a } }}+ O(h^n) $$ 설명 복잡하게 생긴 분모를 깔끔한 형태로 바꿔주는 렘마로써 요긴하게 쓰일 수 있다. 상수항 $a$ 이 없다면 렘마 없이도 $\displaystyle {{1} \over { \sqrt[p]{ O ( h^n ) } }} = O \left( h^{ - {{n} \over {p}} } \right) $ 으로 깔끔하게 올라오지만 보통 쓸모가 없다. 증명 $$ {{1} \over { \sqrt[p]{a + O ( h^n ) } }} = {{1} \over { \sqrt[p]{a</description>
    </item>
    
    <item>
      <title>리즈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rieszs-theorem/</link>
      <pubDate>Sat, 17 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rieszs-theorem/</guid>
      <description>정리 1 놈 공간 $(X , \left\| \cdot \right\|)$의 스칼라 필드를 $\mathbb{C}$라고 하자. 그러면 $X$는 유한차원이다. $\iff$ $\overline{ B ( 0 ; 1 ) }$은 컴팩트이다. 설명 $\overline{ B ( 0 ; 1 ) } := \left\{ x \in X : \| x \| \le 1 \right\}$는 닫힌 유닛 볼을 나타낸다. 리즈 정리에 따르면 전체 공간이 유한차원인지 판단하기 위해 아주 작은 영역만 체</description>
    </item>
    
    <item>
      <title>다항식의 환</title>
      <link>https://freshrimpsushi.github.io/posts/ring-of-polynomial/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ring-of-polynomial/</guid>
      <description>정의 1 $$ f(x) : = \sum_{i=0}^{n} a_{i} x^{i} = a_{0} + a_{1} x + \cdots + a_{k} x^{k} $$ 환 $R$ 의 다항함수Polynomial $f(x)$ 를 위와 같이 정의한다. $a_{i} \in R$ 들을 $f(x)$ 의 계수Coefficient라 한다. $n &amp;lt; \infty$ 면 $n$ 을 $f(x)$ 의 차수Degree라 한다. $R[x]$ 는 $R$ 의 원소를 계수로 갖는 유한다항함수들을 모아놓은 집합이다. $$ R[x] := \left\{ a_{0} + a_{1} x + \cdots + a_{n} x^{n} \ | \ a_{0}, \cdots , a_{n} \in R \right\} $$ $R[[x]]$ 는 $R$ 의</description>
    </item>
    
    <item>
      <title>수치해석에서의 차분</title>
      <link>https://freshrimpsushi.github.io/posts/difference-in-numerical-analysis/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-in-numerical-analysis/</guid>
      <description>정의 1 전방차분: $$ \begin{align*} \Delta f(x) =&amp;amp; f(x+h) - f(x) \\ \Delta^{r+1} f(x) =&amp;amp; \Delta^{r} f(x+h) - \Delta^{r} f(x) \end{align*} $$ 후방차분: $$ \begin{align*} \nabla f(x) =&amp;amp; f(x) - f(x- h) \\ \nabla^{r+1} f(x) =&amp;amp; \nabla^{r} f(x) - \nabla^{r} f(x- h) \end{align*} $$ 설명 일반적으로 계차Difference란 수열 전반에서 사용하는 말이지만 수치해석에선 특히 두 노드포인트의 함숫값의 차를 말한다. 사실 고등학교때부터 계속 봐왔기 때문에 익숙하다면 익숙한 연산자인데 수치해석에서 자주</description>
    </item>
    
    <item>
      <title>환의 영인자가 멱등원이면 직합으로 나타낼 수 있다</title>
      <link>https://freshrimpsushi.github.io/posts/if-zero-divisor-of-ring-is-idempotent-then-it-can-be-represented-by-direct-sum/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-zero-divisor-of-ring-is-idempotent-then-it-can-be-represented-by-direct-sum/</guid>
      <description>정리 단위원 $1$ 을 가지는 환 $R$ 의 영인자 $a$ 가 $a^2 = a$ 를 만족하면, 즉 멱등원이면 $R$ 은 $aR$ 과 $(1-a)R$ 의 유일한 직곱으로 나타난다. $$ R = a R \times (1-a)R $$ 설명 따로 환에 대한 직합을 정의하지 않아도 알 수 있을 정도로 수학다운 매력이 있는 정리다. 증명 Part (i). 존재성 $r \in R$ 에 대해 $$ ar \in aR \\ (1-a) r \in (1-a) R $$ 이며, $r = ar + (1-a)r$ 이므로 $R = a R \times (1-a)R$ 다. Part (ii). 유일성 $r_{1}, r_{2}, r_{3} , r_{4}</description>
    </item>
    
    <item>
      <title>R 에서 자료구조 뜯어보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/data-structure-in-r/</link>
      <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/data-structure-in-r/</guid>
      <description>개요 R에서 여러가지 함수를 사용하다보면 아래와 같이 친절하게 결과가 출력되는 경우를 자주 볼 수 있게 된다. 문제는 이 결과를 그냥 보는 게 아니라 아웃풋으로써 받아서 써먹고 싶을 때다. 예시 가령 위 스크린샷에서 잔차의 최댓값이 필요하면 그냥 15.9719을 베껴써도 되긴 한다. 하지만 수십 수백번을 반복하면서 각 분석에서 잔차의 최댓값이 궁금하다면</description>
    </item>
    
    <item>
      <title>영인자와 정역</title>
      <link>https://freshrimpsushi.github.io/posts/zero-divisior-and-integral-domain/</link>
      <pubDate>Sun, 11 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zero-divisior-and-integral-domain/</guid>
      <description>정의 1 환 $R$ 에 대해 $ab = 0$ 을 만족시키는 $0$ 이 아닌 $a,b \in R$ 을 영인자Zero Divisor라 한다. 단위원 $1 \ne 0$ 을 가진 $D$ 가 영인자를 가지지 않으면 정역Integral Domain이라 한다. 설명 영인자 $0$ 이 아닌 것끼리 곱해서 $0$ 이 되는 예시로는 $$ \begin{bmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} 0 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{bmatrix} = \begin{bmatrix} 0 &amp;amp; 0 \\ 0 &amp;amp; 0 \end{bmatrix} $$ 과 $2 \cdot 3 \equiv 0 \pmod{6}$ 등이 있다.</description>
    </item>
    
    <item>
      <title>불리언 링</title>
      <link>https://freshrimpsushi.github.io/posts/boolean-ring/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/boolean-ring/</guid>
      <description>정의 1 $R$ 을 환이라고 하자. $r \in R$ 이 $r^2 = r$ 을 만족하면 $r$ 을 멱등원Idempotent Element이라 한다. $R$ 의 모든 원소가 멱원소면 $R$ 을 불리언 링Boolean Ring이라 한다. 설명 불리언 링을 순화하면 &amp;lsquo;불환&amp;rsquo;이지만 어감이 매우 좋지 못해 영어 발음을 그대로 썼다. 선형대수학에서의 사영이 유용한 성질</description>
    </item>
    
    <item>
      <title>제프리 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/jeffreys-prior/</link>
      <pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jeffreys-prior/</guid>
      <description>정의 1 자료의 분포 $p( y | \theta)$ 에 대해 $\pi ( \theta ) \propto I^{1/2} ( \theta )$ 를 제프리 사전분포Jeffreys Prior라 한다. $I$ 는 피셔정보Fishser Information를 의미한다. $$ I ( \theta ) = E \left[ \left( \left. {{\partial \ln p (y | \theta) } \over {\partial \theta}} \right)^2 \right| \theta \right] = E \left[ \left. - {{\partial^2 \ln p (y | \theta) } \over { (\partial \theta )^2 }} \right| \theta \right] $$ 설명 라플라스 사전분포 $\pi (\theta) \propto 1$ 는 모수 $\theta$ 의 사전분포로써</description>
    </item>
    
    <item>
      <title>추상대수학에서의 체</title>
      <link>https://freshrimpsushi.github.io/posts/field-in-abstract-algebra/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/field-in-abstract-algebra/</guid>
      <description>정의 1 환 $(R , + , \cdot)$ 이 곱셉 $\cdot$ 에 대한 항등원 $1 \in R$ 을 가질 때, $1$ 을 단위원Unity이라 한다. 단위원을 가진 환 $R$ 에서 곱셈에 대한 역원이 존재하는 원소 $r \ne 0$ 를 단원Unit이라 한다. 단위원을 가진 환 $R$ 에서 $0$ 이 아닌 모든 원소가 단원이면 상환Division Ring이라 한다. 곱셈에 대해 교환법칙이 성립하는 상환 $R$ 을 체Field라 한다</description>
    </item>
    
    <item>
      <title>라플라스 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-prior/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-prior/</guid>
      <description>빌드업 모수에 대한 정보가 거의 없다면 구태여 복잡한 사전분포를 생각할 이유는 없다. 내년 모 대학의 통계학과 신입생의 성비를 추측해보라고 했을 때, 통계학과를 어느정도 아는 사람이라면 예년의 성비를 보고 어느정도 짐작을 하겠지만 전혀 관계도 없고 관심도 없는 사람이 이 질문을 들었을 땐 특별한 이유가 없는 한 50:50이라고 추측할 것이다. 어떤 주머니</description>
    </item>
    
    <item>
      <title>리즈 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-riesz-lemma/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-riesz-lemma/</guid>
      <description>정리 1 놈 공간 $(X , \| \cdot \| )$ 의 부분 공간 $Y \subsetneq X$ 에 대해 $Y$ 는 닫힌 집합이라고 하자. 모든 $\theta \in (0,1)$ 와 $y \in Y$ 에 대해 $\| x_{ \theta } \| = 1$ 와 $\| x_{ \theta } - y \| &amp;gt; \theta$ 를 만족하는 $x_{\theta} \in X$ 가 존재한다. 증명 전략: 구체적인 $x_{\theta}$ 가 존재함을 보인 후 $\| x_{ \theta } - y \| &amp;gt; \theta$ 가 성립함을 보인다. $ x_{0 } \notin Y$ 면서 $ x_{0 } \in X$ 인 $x_{0}$ 에 대해서 $d:= \inf \left\{ \| x_{0} - y \| : y \in Y \right\}$ 이라고 하자</description>
    </item>
    
    <item>
      <title>민코프스키 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-minkowskis-inequality/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-minkowskis-inequality/</guid>
      <description>정리 두 벡터 $\mathbf{x}= (x_{1} , x_{2} , \dots , x_{n} )$ , $\mathbf{y} = (y_{1} , y_{2} , \dots , y_{n} )$ 와 $1$보다 큰 실수 $p$ 에 대해 다음의 식이 성립한다. $$ \left( \sum_{k=1}^{n} | x_{k} + y_{k} |^{p} \right)^{{1} \over {p}} \le \left( \sum_{k=1}^{n} |x_{k}|^{p} \right)^{{1} \over {p}} + \left( \sum_{k=1}^{n} |y_{k}|^{p} \right)^{{1} \over {p}} $$ 이를 민코프스키 부등식Minkowski&amp;rsquo;s inequality이라 한다. 설명 민코프스키 부등식은 $p$-놈의 정의에서 삼각부등식에 해당한다. 어떤</description>
    </item>
    
    <item>
      <title>켤레사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/conjugate-prior/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conjugate-prior/</guid>
      <description>정의 1 사전분포와 사후분포가 동일한 분포족에 속하면 사전분포를 켤레사전분포Conjugate Prior 혹은 공액사전분포라고 한다. 설명 베이지안이란 본래 사전분포가 어떻게 되든 업데이트를 통해 모수를 찾아가는 것이긴 하지만, 모형에 대해 어느정도 아는 바가 있다면 적절한 사전분포를 사용함으로써 수학적 계산을 간단하게 하고 결과를 이해하기 쉽게 할</description>
    </item>
    
    <item>
      <title>유한 차원 놈 공간은 완비성을 가짐을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/finite-dimentional-normed-space-is-complete/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finite-dimentional-normed-space-is-complete/</guid>
      <description>정리 1 유한 차원 놈 공간은 완비성을 가진다. 설명 이에 따라 유한 차원 벡터 공간은 놈이 정의되는 것만으로 바나흐 공간이 된다. 대표적으로 많이 쓰이는 $\mathbb{R}^{n}$ 혹은 $\mathbb{C}^{n}$ 이 있기 때문에 특히 유용한 팩트다. 증명 전략: 유한차원 벡터 공간이라는 점을 이용해 모든 벡터를 기저 단위로 찢은 후 다루기 편한 놈을 정의한다. 놈의 동치관계를 타서 추상적인 계산을 직접적인 계산</description>
    </item>
    
    <item>
      <title>라플라스 계승 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</guid>
      <description>정리 1 이항모형 $\displaystyle p(y | \theta) = \binom{ n }{ y} \theta^{y} (1- \theta)^{n-y}$ 의 사전분포가 일양 분포 $U (0,1)$ 를 따르고 사후분포가 베타 분포 $\beta (y+1 , n-y+1)$ 을 따라 $p( \theta | y ) \sim \theta^{y} (1- \theta)^{n-y}$ 이라고 하자. 그러면 이제까지 얻은 데이터 $y$ 에 대해 새로운 $\tilde{y}$ 가 $1$ 일 확률은 $$ p(\tilde{y} = 1| y) = {{y+1} \over {n+2}} $$ 설명 프리퀀티스트의 관점으로 보았을 때 $\tilde{y} = 1$ 일 확률은 그 표본비율 $\displaystyle {{y} \over {n}}$ 에 가까울 것이다. 그런데 기본적으</description>
    </item>
    
    <item>
      <title>유한 차원 벡터 공간 상에서 정의된 모든 놈은 동치임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-relation-of-norm-defined-in-finite-dimentional-vector-space/</link>
      <pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-relation-of-norm-defined-in-finite-dimentional-vector-space/</guid>
      <description>정리 1 유한 차원 벡터 공간 상에서 정의된 모든 놈은 동치다. 설명 유클리드 공간 상에서 정의된 모든 놈은 동치라는 사실은 본 정리의 따름 정리에 해당한다. 증명 전략: $c \| v \| _{\alpha} \le \| v \| _{\beta} \le C \| v \| _{\alpha}$ 를 만족하는 $c , C &amp;gt;0$ 가 존재함을 보이면 두 놈 $\left\| \cdot \right\|_{\alpha}$ 와 $\left\| \cdot \right\|_{\beta}$ 는 동치다. 최대최소값 정리를 통해 $\displaystyle { { \| v \| _{\beta} } \over {\| v \| _{\alpha} } }$ 의 최대값과 최소값이</description>
    </item>
    
    <item>
      <title>유한 차원 놈 공간은 기저를 가짐을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/finite-dimentional-normed-space-have-basis/</link>
      <pubDate>Mon, 29 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finite-dimentional-normed-space-have-basis/</guid>
      <description>정리 1 모든 유한 차원 놈 공간은 기저를 가진다. 설명 특정 조건을 만족하는 기저도 아니고 기저의 존재성을 밝힌다는 것이 생소하겠지만, 실제로 기저의 정의에서 모든 벡터 공간의 기저가 존재한다고 한 적이 없다. 유한 차원을 정의하기에 따라서는 별도로 증명이 필요없을 정도로 자명한 팩트기도 하다. 증명 전략: 유한차원이라는 점을 이용해 구체적으로 기저를</description>
    </item>
    
    <item>
      <title>노름 놈의 동치관계</title>
      <link>https://freshrimpsushi.github.io/posts/equivalent-relation-of-norm/</link>
      <pubDate>Sun, 28 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/equivalent-relation-of-norm/</guid>
      <description>정의 벡터공간 $V$ 상에서 정의된 두 놈 $\left\| \cdot \right\|_{\alpha}, \left\| \cdot \right\|_{\beta}$과 임의의 벡터 $\mathbf{v} \in V$ 에 대해 $$ c \left\| \mathbf{v} \right\|_{\alpha} \le \left\| \mathbf{v} \right\|_{\beta} \le C \left\| \mathbf{v} \right\|_{\alpha} $$ 를 만족하는 $c , C &amp;gt;0$ 이 존재하면 두 놈은 서로 동치라 정의한다. 설명 두 놈이 서로 동치라는 것은 놈을 이용한 부등식을 다룰 때 서로 다른 놈을 사용해도 문제가 없다는 말이다. 당연히 사용하기 어려운 놈을 사용</description>
    </item>
    
    <item>
      <title>부분공간의 직교여공간</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-complement/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-complement/</guid>
      <description>정의1 벡터공간 $V$ 의 부분공간 $W$ 에 대해서 집합 $$ W^{\perp} = \left\{ \mathbf{v} \in V \ : \left\langle \mathbf{v} , \mathbf{w} \right\rangle = 0,\quad \forall \mathbf{w} \in W \right\} $$ 를 $W$ 의 직교여공간orthogonal complement이라한다. 이때 $\langle , \rangle$ 는 내적이다. 설명 다시말해 $W^{\perp}$은 $W$ 의 모든 원소와 수직인 벡터를 모아놓은 집합이다. 기호 $^{\perp}$ 는 perpendicular를 줄여서 per</description>
    </item>
    
    <item>
      <title>유한 차원 벡터 공간의 하멜 베이시스</title>
      <link>https://freshrimpsushi.github.io/posts/hamel-basis-of-finite-dimensional-vector-space/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hamel-basis-of-finite-dimensional-vector-space/</guid>
      <description>정의 1 벡터 공간 $X$ 가 주어져 있다고 하자. $X$의 벡터 $x_{1} , \dots , x_{n}$와 스칼라 $\alpha_{1} , \dots , \alpha_{n}$ 에 대해 $\alpha_{1} x_{1} + \cdots + \alpha_{n} x_{n}$를 벡터 $x_{1} , \dots , x_{n}$들의 선형 결합이라 한다. $M =\left\{ x_{1} , \dots , x_{n} \right\}$이라 할 때 $M$의 모든 벡터의 선형 결합들의 집합을 $\text{span} M$ 이라 하고, $M$에 의해 생성된 $X$의 부분 공간이라 한다. $\alpha_{1}</description>
    </item>
    
    <item>
      <title>바나흐 공간</title>
      <link>https://freshrimpsushi.github.io/posts/banach-space/</link>
      <pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/banach-space/</guid>
      <description>정의1 완비 놈 공간을 바나흐 공간Banach space이라 한다. 설명 완비 공간이란, 모든 코시수열이 수렴하는 공간을 말한다. 바나흐 스페이스는 아래의 각 호를 모두 만족시킨 공간으로써 거리 함수가 정의되는데다 완비성을 갖춰 아주 유용한 공간이다. 벡터 공간이다. 놈 공간이다. $\implies$ 거리 공간이다. 완비 공간이다. Normed Vector Space 혹은 **놈드 스페이스</description>
    </item>
    
    <item>
      <title>횔더 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-hoelders-inequality/</link>
      <pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-hoelders-inequality/</guid>
      <description>정의 $\dfrac{1}{p} + \dfrac{1}{q} = 1$ 을 만족하고 1보다 큰 두 상수 $p, q$ 와 $\mathbf{u}, \mathbf{v} \in \mathbb{C}^n$에 대해 다음의 부등식이 성립한다. $$ | \left\langle \mathbf{u}, \mathbf{v} \right\rangle | = |\mathbf{u} ^{\ast} \mathbf{v}| \le ||\mathbf{u}||_{p} ||\mathbf{v}||_{q} $$ 이를 횔더 부등식Hoelder&amp;rsquo;s inequality이라 한다. 설명 원래는 Hölder&amp;rsquo;s inequality로 써야하지만 움라우트가 있어 대체표</description>
    </item>
    
    <item>
      <title>베이지안 패러다임</title>
      <link>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</guid>
      <description>빌드업 통계학이란 &amp;lsquo;모수를 파악하는 방법을 연구하는 학문&amp;rsquo;이라고 할 수 있다. 어떤 물리량을 측정하는 것처럼 공식이나 법칙을 통해 정확하게 모수를 추정할 수 있다면 더할나위 없지만, 현실적으로 그게 불가능하기 때문에 가정과 표본을 이용해 &amp;lsquo;모수로 예상되는 것&amp;rsquo;을 찾아낼 뿐이다. 우리나라 남성</description>
    </item>
    
    <item>
      <title>영의 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-youngs-inequality/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-youngs-inequality/</guid>
      <description>정리 $\displaystyle {{1} \over {p}} + {{1} \over {q}} = 1$ 을 만족하고 1보다 큰 두 상수 $p,q$와 두 양수 $a,b$ 에 대해 $$ ab \le { {a^{p}} \over {p} } + {{b^{q}} \over {q}} $$ 설명 대수적으로 모양이 아름다운 점을 빼면 횔더 부등식을 증명하는 것 외엔 크게 언급되지 않는 부등식이다. 증명 $a$와 $b$ 모두 양수이므로 $a = e^A, b = e^B$ 를 만족하는 실수 $A,B$ 가 존재한다. 볼록함수의 이계도함수 $f$ 가 $I$ 에서 두 번 미분가능</description>
    </item>
    
    <item>
      <title>p=∞ 일 때 p-놈이 맥시멈 놈이 됨을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-p-norm-is-maximum-norm-when-p-is-infinity/</link>
      <pubDate>Sun, 21 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-p-norm-is-maximum-norm-when-p-is-infinity/</guid>
      <description>정리 $1 &amp;lt; p_{0} &amp;lt; \infty$ 에 대해 $\left\{ x_{n} \right\}_{n \in \mathbb{N} } \in \mathcal{l}^{p_{0}}$ 라고 하면 $$ \lim_{p \to \infty} \left( \sum_{n \in \mathbb{N} } | x_{n} |^{p} \right)^{ {{1} \over {p}} } = \sup_{n \in \mathbb{N}} | x_{ n } | $$ 설명 맥시멈 놈은 해석학이나 선형대수학 등에서 꽤 일찍 접함에도 불구하고 왜 하필 $\infty$ 와 관계가 있는지 그 설명을 찾기가 어렵다. 다행스러운 점은 그냥 증명이 가능하는 것이다. 증명 $\displaystyle M := \sup_{n \in \mathbb{N}} | x_{ n } |$ 이라 하자. 만약 $M=0$ 이면 $\displaystyle 0 = \lim_{p \to</description>
    </item>
    
    <item>
      <title>베이즈 정리로 보는 몬티홀 딜레마</title>
      <link>https://freshrimpsushi.github.io/posts/monty-hall-dilemma/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monty-hall-dilemma/</guid>
      <description>설명 알다시피 몬티홀 게임은 실제로 경품이 어디있든 관계 없이 선택을 바꾸는 것이 유리하다. 이것을 팩트로써 받아들이냐와 별개로 몬티홀 게임을 직관적으로 이해하지 못했거나 수식적인 표현이 서툰 사람들이 있다. 편의상 본인이 플레이어고, 1번 문을 선택했다고 생각해보자. 이 때 우리는 경품에 대한 어떤 정보도 없기에, 어떤 번호든 선택할 확률은 같다고</description>
    </item>
    
    <item>
      <title>옌센 부등식의 유한 폼 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-finite-form-of-jensens-inequality/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-finite-form-of-jensens-inequality/</guid>
      <description>정리 $I \subset \mathbb{R}$ 에서 컨벡스 함수 $f : I \to \mathbb{R}$ 와 $\displaystyle \sum_{k=1}^{n} \lambda_{k} = 1, \lambda_{k}&amp;gt;0$ 에 대해 $$ f( \lambda_{1} x_{1} + \lambda_{2} x_{2} + \cdots + \lambda_{n} x_{n} ) \le \lambda_{1} f( x_{1}) + \lambda_{2} f( x_{2}) + \cdots + \lambda_{n} f( x_{n} ) $$ 설명 옌센의 부등식은 컨벡스 함수의 대표적인 응용으로써 여러 분야에서 폭넓게 사용되고 있다.유한 폼은 원래 컨벡스의 정의에서 점의 갯수와 가중치에 대해 일반화가 이루어진 모양을 하고 있다. 증명 전략: 컨벡스 함수의 정의</description>
    </item>
    
    <item>
      <title>선형대수학에서 노름 혹은 놈이란</title>
      <link>https://freshrimpsushi.github.io/posts/norm-in-linear-algebra/</link>
      <pubDate>Sat, 06 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/norm-in-linear-algebra/</guid>
      <description>정의 $V$를 $\mathbb{F}$ 상에서의 벡터공간이라고 하자. $\left\| \cdot \right\| : V \to \mathbb{F}$ 가 $\mathbf{u}, \mathbf{v} \in V$와 $k \in \mathbb{F}$ 에 대해서 다음 세 조건을 만족시키면 $\left\| \cdot \right\|$ 을 $V$ 상에서의 놈이라고 정의한다. (i) 정부호: $\left\| \mathbf{u} \right\| \ge 0$ 이고 $\mathbf{u} = \mathbb{0} \iff \left\| \mathbf{u} \right\| = 0$ (ii) 동질성: $\left\|k \mathbf{u} \right\| = | k | \left\| \mathbf{u} \right\| $ (iii) 삼각부등식: $\left\| \mathbf{u} + \mathbf{v}\right\| \le \left\|\mathbf{v} \right\| + \left\| \mathbf{u} \right\|$ 설명 Norm은 절댓값에서 출발해 추상화된 개념으로,</description>
    </item>
    
    <item>
      <title>엘피 공간</title>
      <link>https://freshrimpsushi.github.io/posts/lp-space/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lp-space/</guid>
      <description>정의 1 $1 \le p &amp;lt; \infty$ 에 대해 거리공간 $( \ell^{p} , d^{p} )$ 는 다음과 같이 정의된다. (i) 수렴하는 수열의 집합: $$ \ell^{p} := \left\{ \left\{ x_{n} \right\}_{n \in \mathbb{N}} \subset \mathbb{C} \left| \left( \sum_{i=1}^{\infty} | x_{i} |^{p} \right)^{{1} \over {p}} &amp;lt; \infty \right. \right\} $$ (ii) 거리 함수: $$ d^{p} ( x_{n} , y_{n} ) := \left( \sum_{i = 1}^{\infty} | x_{i} - y_{i} |^{p} \right)^{ {{1} \over {p}} },\quad \left\{ x_{n} \right\} , \left\{ y_{n} \right\} \in \ell^{p} $$ $p = \infty$ 에 대해 거리공간 $( \ell^{\infty} , d^{\infty} )$ 는 다음과 같이 정의된다. (i)&#39; 유계 수열의 집합: $$ \ell^{\infty} := \left\{ \left\{ x_{n} \right\}_{n \in \mathbb{N}} \</description>
    </item>
    
    <item>
      <title>R 에서 리스트 해체하기, 중복 성분 제거하기</title>
      <link>https://freshrimpsushi.github.io/posts/unlist-unique/</link>
      <pubDate>Sun, 23 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unlist-unique/</guid>
      <description>개요 온갖가지 정제되지 않은 데이터를 상대할 일이 많은 R 에서 리스트 자료형은 데이터를 정리하는데에 특히 유용하다. 그러나 반대급부로 데이터에 접근하는 것이 조금 번거롭고 원하는 내용을 찾는데에 불리한 점이 있다. 이때 unlist() 함수를 통해 리스트 자료형을 깨주면 이러한 조작이 한결 편해진다. unique() 함수는 받은 배열에서 중복되는 원소를 모두 제거하고 하나씩만</description>
    </item>
    
    <item>
      <title>다양체란</title>
      <link>https://freshrimpsushi.github.io/posts/manifold-in-topology/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/manifold-in-topology/</guid>
      <description>정의 1 위상공간 $X$가 아래의 세 조건을 만족시킬 때 $X$를 $n$차원 매니폴드Manifold라 한다. (i): 제 2가산이다. (ii): 하우스도르프이다. (iii): $X$의 모든 점이 $\mathbb{R}^{n}$ 의 열린집합과 위상동형인 네이버후드를 가진다. $n$차원 매니폴드 $X$ 가 다음 두 가지 유형의 점들을 가질 때 $X$ 는 바운더리를 가진다고 한다. (1) 인테리어 포인트: 모든 $x \in X^{\circ}$</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 등분산성</title>
      <link>https://freshrimpsushi.github.io/posts/homoscedasticity-of-standard-residuals/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homoscedasticity-of-standard-residuals/</guid>
      <description>진단법 1 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 등분산성을 확인하려면 잔차들의 흩어진 모양이 전체적으로 고른지 확인하면 된다. 흔히 볼 수 있는 등분산성 결여의 예로써 다음의 두가지 경우가 대표적이다. 뒤로 갈수록 분산이 커지는 꼴인데, 이런 경우 변환이나 가중치를 도입함으로써 해결해야한다. 정말 쉽게 해결되느냐와</description>
    </item>
    
    <item>
      <title>피보나치 수열의 일반항 유도</title>
      <link>https://freshrimpsushi.github.io/posts/the-general-term-of-fibonacci-sequence/</link>
      <pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-general-term-of-fibonacci-sequence/</guid>
      <description>정리 수열 $\left\{ F_{n} \right\}$ 이 $F_{n+1} := F_{n} + F_{n-1}$ 과 같이 정의되어있다고 하자. $F_{0} = F_{1} = 1$ 이면 $\displaystyle r_{0} : = {{1 + \sqrt{5} } \over {2}}$ 와 $\displaystyle r_{1} : = {{1 - \sqrt{5} } \over {2}}$ 에 대해 $$ F_{n} = {{ {r_{0}}^{n+1} - {r_{1}}^{n+1} } \over { r_{0} - r_{1} }} $$ 설명 피보나치 수열의 일반항은 비네 공식Binet Formula이라 부르기도 한다.피보나치 수열은 워낙 많은 성질을 가지고 있고 생각지도 못한 부분에서 응용이 되기도 한다. 아예</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 선형성</title>
      <link>https://freshrimpsushi.github.io/posts/linearity-of-standard-residuals/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearity-of-standard-residuals/</guid>
      <description>진단법 1 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다.선형성이 있는지 확인하려면 $0$ 을 중심으로 잔차들이 대칭적으로 나타나는지 확인하면 된다. 오른쪽 그림을 보면 누가봐도 선형성이 결여되어있음을 확인할 수 있다. 만약 단순회귀분석이었다면 위와 같이 데이터의 경향을 전혀 설명할 수 없는 결과를 낳는다. 주의해야할 형태들로</description>
    </item>
    
    <item>
      <title>회귀분석의 모형진단</title>
      <link>https://freshrimpsushi.github.io/posts/model-diagnostic-of-regression-analysis/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/model-diagnostic-of-regression-analysis/</guid>
      <description>필요성 단순회귀분석의 경우엔 독립변수와 종속변수를 고려해봤자 $2$ 차원이기 때문에 분석이 제대로 되었는지 한 눈에 확인할 수 있다. 하지만 다중회귀분석의 경우 $3$ 차원을 넘어가면 그림으로 그리기 어려워 때문에 분석이 정말 잘 맞는지 확인하기 어렵다. 회귀분석의 가정을 제대로 만족시키지 못했지만 가설검정은 통과하는 경우가 있는데, 이 경우 분석은 그냥</description>
    </item>
    
    <item>
      <title>파푸스-굴딘 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pappus-guldinus-theorem/</link>
      <pubDate>Sat, 08 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pappus-guldinus-theorem/</guid>
      <description>정리 $yz$-평면 상의 도형 $F$ 의 넓이를 $A$ 라고 하고 $F$ 를 $z$-축으로 회전시켜서 얻은 회전체 $W$ 의 부피를 $V$ 라고 하자. $z$-축과 $F$ 의 무게중심 사이의 거리를 $r$ 이라고 하면 $$ V = 2 \pi r A $$ 설명 파푸스-굴딘 정리는 고등학교 수준으로는 증명할 수 없지만 회전체에 대해 배울때 선생님들이 심심찮게 언급하는 정리다. 막상 학부수준의 수학을 공부</description>
    </item>
    
    <item>
      <title>회귀계수의 F검정 F-test for Regression Coefficient</title>
      <link>https://freshrimpsushi.github.io/posts/672/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/672/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 다중회귀분석R 에서 다중회귀분석 결과 $n$ 개의 관측치와 $p$ 개의 독립변수에 대한 다중회귀분석에 대해 $i=0,1,\cdots,p$ 라고 하자. $H_{0}$ : $\beta_{1} = \beta_{2} = \cdots = \beta_{p} = 0$ 즉, 모든 독립변수가 종속변수과 관계 없다. $H_{1}$ : $\beta_{1} , \beta_{2} , \cdots , \beta_{p}$ 중 적어도 하나는 $ 0$ 이 아니다. 즉, 종속변수와 관계 있는 독립변수가 존재한다. $\displaystyle F = {{</description>
    </item>
    
    <item>
      <title>R 에서 다중회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</link>
      <pubDate>Wed, 05 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</guid>
      <description>데이터 탐색 tail(attitude) R에서 내장데이터 attitude를 불러와 tail() 함수를 통해 확인해보자. 우리는 rating을 종속변수로 두고 다른 독립변수들이 rating에 어떤 영향을 얼마나 미치는지에 관심이 있다. 데이터만 봐서는 rating과 다른 변수들 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph() plot(attitude) 그냥 plot() 함수에 데이터</description>
    </item>
    
    <item>
      <title>R 에서 그래프 그릴 때 사용하는 심볼들</title>
      <link>https://freshrimpsushi.github.io/posts/symbols-for-plots-in-r/</link>
      <pubDate>Tue, 04 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/symbols-for-plots-in-r/</guid>
      <description>코드 각종 그래프 관련 함수에서 찍히는 점의 모양을 바꿀 때 pch 옵션을 사용한다. 위 그림은 특히 자주 쓰는 심볼들을 한 눈에 볼 수 있게 나타낸 것이다.쓸만한 게 많지만 특히 16번이 자주 쓰이며, 25번 이후에도 일단 마크 자체는 정해져 있으나 쓸만한 게 없다. 아래 예제 코드에서 sym을 26부터 50으로 고치고 확인해볼 수 있다. 한편 21번부터 25번은 bg</description>
    </item>
    
    <item>
      <title>쉴로브 정리</title>
      <link>https://freshrimpsushi.github.io/posts/sylow-theorem/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sylow-theorem/</guid>
      <description>정리 1 소수 $p$ 와 $\gcd (p, m) = 1$ 을 만족하는 어떤 자연수 $m$ 에 대해 $G$ 가 $|G| = p^{n} m$ 인 유한군이라고 하자. $G$ 의 $p$-부분군 중 다른 $p$-부분군에 포함되지 않는 $p$-부분군을 쉴로브 $p$-부분군이라고 한다. 제1쉴로브 정리: $G$ 는 $i=1, \cdots , n$ 에 대해 $|P| = p^{i}$ 를 만족하는 $p$-부분군이 존재한다. 제2쉴로브 정리: $G$ 의 쉴로브 $p$-부분군</description>
    </item>
    
    <item>
      <title>R 에서 그림에 문자열 찍는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-print-text-in-plot/</link>
      <pubDate>Sun, 02 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-print-text-in-plot/</guid>
      <description>코드 text() 함수를 통해 그래프에 문자열이 찍히도록 할 수 있다. 첫번째 옵션은 $x$ 축 좌표의 벡터, 두번째 옵션은 $y$ 축 좌표의 벡터, 세번째 옵션은 입력될 문자열의 벡터를 받는다. 아래의 예제코드에서 t만 바꿔가면서 실행시켜보면 바로 이해가 될 것이다. win.graph(6,5) plot(x=0,y=0,xlim=c(-1,5),ylim=c(-1,4),xlab=&amp;#34;x&amp;#34;,ylab=&amp;#34;y&amp;#34;) points(4,3,col=&amp;#34;red&amp;#34;,pch=19) #1 abline(h=0) #2 abline(v=0) #3 abline(0,3/4) #4 segments(4,0,4,3) x=c(2,-0.2,2,4.2) y=c(-0.2,2,2,2) t=c(&amp;#34;(1)&amp;#34;,&amp;#34;(2)&amp;#34;,&amp;#34;(3)&amp;#34;,&amp;#34;(4)&amp;#34;) t=c(&amp;#34;(하나)&amp;#34;,&amp;#34;(둘)&amp;#34</description>
    </item>
    
    <item>
      <title>다중회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/multiple-linear-regression/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiple-linear-regression/</guid>
      <description>개요 회귀분석이란 변수 사이의 관계를 알아내는 방법으로써, 특히 선형 관계를 밝히는 데 유용하다. 다중회귀분석Multiple Linear Regression은 하나의 종속변수(반응변수) 에 복수의 독립변수(설명변수) 가 미치는 영향을 파악하는 회귀분석을 말한다. 모델 1 $$Y = \beta_{0} + \beta_{1} X_{1} + \cdots + \beta_{p} X_{p} + \varepsilon $$ 우리는 변수들이 위와 같은 선형관계를 가지</description>
    </item>
    
    <item>
      <title>몫 공간</title>
      <link>https://freshrimpsushi.github.io/posts/quotient-space/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quotient-space/</guid>
      <description>정의 1 위상공간 $(X, \mathscr{T} )$ 와 동치 관계 $\sim$ 에 대해 동치류를 $[x] = \left\{ y \in X \ | \ x \sim y \right\}$ 이라 하자. $X / \sim$ 을 몫 집합이라 정의한다. $q : X \to X / \sim$ 을 $q(x) = [ x ]$ 로 정의하면 몫 함수라 부른다. $U \in \mathscr{T}$ 에 대해 $$ q^{-1} (U) = \bigcup_{[ x ] \in U} [ x ] \iff U \in \mathscr{T_{\sim}} $$ 이라고 하자. $\mathscr{T_{\sim}}$ 을 몫 위상이라 하고, $( X/ \sim , \mathscr{T_{\sim}} )$ 을 모듈러 $\sim$ 에서 $X$ 의 몫 공간이라 정의한다. $A \subset X$ 에 대</description>
    </item>
    
    <item>
      <title>R 에서 수평선 수직선 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-draw-horizontal-or-vertical-line-in-r/</link>
      <pubDate>Thu, 30 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-draw-horizontal-or-vertical-line-in-r/</guid>
      <description>예시 1. abline(h=0) 수평선을 긋는다. 2. abline(v=0) 수직선을 긋는다. 3. abline(0,3/4) $y$ 절편이 $0$ 이고 기울기가 $3/4$ 인 직선을 긋는다. 애초에 abline() 함수 자체가 $y=a+bx$ 의 계수인 $a,b$ 에서 이름을 따온 것이다. 통계를 목적으로 R 을 쓰고 있다면 막상 회귀직선을 그릴 때 빼곤 쓸 일이 없다. segments(4,0,4,3) $(4,0)$ 에서 $(4,3)$ 으로 이어지는 선분을 그린다.깔끔하게 필요한 부분만 그리고 싶을때 필요하다. win.graph(6,5) plot(x=0,y=0,xlim=c(-1,5),ylim=c(-1,4),xlab=&amp;#34;x&amp;#34;,ylab=&amp;#34;y&amp;#34;) points(4,3,col=&amp;#34;red&amp;#34;,pch=19) #1 abline(h=0) #2 abline(v=0) #3 abline(0,3/4)</description>
    </item>
    
    <item>
      <title>군론에서의 코시 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/cauchys-theorem/</link>
      <pubDate>Wed, 29 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchys-theorem/</guid>
      <description>정리 1 유한군 $G$ 에 대해 소수 $p$ 가 $|G|$ 의 약수면 $|H| = p$ 를 만족하는 부분군 $H \leqslant G$ 가 존재한다. 설명 보통 코시 정리라고 할 때 이 정리를 떠올리지는 않는다. 또다른 또다른 코시 정리는 복소해석의 근간을 이룰만큼 중요한 정리인데, 이 정리는 별로 언급 될 일이 없다. 무엇보다도 제1 쉴로브 정리로 일반화되기 때문에 굳이 코시 정리를 써야할 경우는 극히 드물다. 알</description>
    </item>
    
    <item>
      <title>R 에서 그래프 그리기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-in-r/</link>
      <pubDate>Tue, 28 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-in-r/</guid>
      <description>개요 R 은 다른 언어와 비교했을때 그래프의 표현이 아주 쉽다는 장점이 있다. 여타 통계 패키지와 비교하자면 쉬운 그림은 패키지가 빨라도 세세한 표현이 많아지면 R 이 편해지는 경향이 있다. 물론 R이 꼭 그래픽만을 위한 언어는 아니지만, 매우 큰 장점이니만큼 자유자재로 다룰 수 있게 연습하는 게 좋다. 코드 set.seed(150421) x&amp;lt;-1:10 y&amp;lt;-rnorm(10,5) z&amp;lt;-rexp(10) win.graph(4,4) plot(x,y,main=&amp;#3</description>
    </item>
    
    <item>
      <title>추상대수학에서의 p-군</title>
      <link>https://freshrimpsushi.github.io/posts/p-group-in-abstract-algebra/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/p-group-in-abstract-algebra/</guid>
      <description>정의 1 유한군 $G$ 의 항등원이 $e$ 라고 할 때, $g \in G$ 가 $g^{n} = e$ 를 만족하는 가장 작은 $n \in \mathbb{N}$ 에 대해 $|g| = n$ 이라 나타낸다. 모든 $g \in G$ 와 주어진 소수 $p$ 에 대해 $|g| = p^{m}$ 을 만족하는 정수 $m \ge 0$ 이 존재할 때, $G$ 를 $p$-군$p$-group이라고 한다. 설명 $|G| = p^{m}$ 이면 $p$-군이고, 다음과 같은 정리가 알려져있다. 정리 $X_{G} : = \left\{ x \in X \ | \ gx = x</description>
    </item>
    
    <item>
      <title>R 에서 조건부로 데이터 필터링하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/conditionally-data-filtering-in-r/</link>
      <pubDate>Sun, 26 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditionally-data-filtering-in-r/</guid>
      <description>개요 R 이 주로 통계학에서 쓰이기 때문인지, 필요한 데이터를 골라내고 편집하는 기능은 타의 추종을 불허한다. 이러한 데이터의 핸들링에 익숙해지는 것은 조금 어렵지만, 완벽하게 터득하고 나면 다른 언어가 너무나 불편할 것이다. 사실 이러한 팁들은 읽는 것만으로는 크게 도움이 되지 않는다. (실제로 정확성을 기하려다보니 설명도 간결할 수밖에 없다.)</description>
    </item>
    
    <item>
      <title>우리손 보조정리와 티체 확장 정리</title>
      <link>https://freshrimpsushi.github.io/posts/urysohns-lemma-tietze-extension-theorem/</link>
      <pubDate>Sat, 25 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/urysohns-lemma-tietze-extension-theorem/</guid>
      <description>정리 우리손 보조정리 1 $X$ 가 정규 공간이면 $A \cap B = \emptyset$ 인 모든 닫힌 집합 $A, B \subset X$ 에 대해 $f(A) = \left\{ 0 \right\}$ 와 $f(B) = \left\{ 1 \right\}$ 를 만족하는 연속 함수 $f:X \to [0,1]$ 가 존재한다. 티체 확장 정리 2 정규 공간 $X$ 에서 닫힌 집합 $C$ 에 대해 $f : C \to \mathbb{R}$ 가 연속이면 $F |_{C} = f$ 를 만족하는 연속함수 $F : X \to \mathbb{R}$ 가 존재한다. 설명 우리손 보조정리는 위상수학을 사용하는 온갖 분야에 동원되는</description>
    </item>
    
    <item>
      <title>엔탈피 헬름홀츠 함수 깁스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/enthalpy-helmholtz-function-gibbs-function/</link>
      <pubDate>Fri, 24 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/enthalpy-helmholtz-function-gibbs-function/</guid>
      <description>정의 엔탈피enthalpy $H$ 는 다음과 같이 정의된다. $$ H := U + PV $$ 헬름홀츠 함수Helmholtz function $F$ 는 다음과 같이 정의된다. $$ F := U - TS $$ 깁스 함수Gibbs function $G$ 는 다음과 같이 정의된다. $$ G := H - TS $$ 설명 엔탈피는 엔트로피에 거의 준할정도로 이름이 알려진 함수지만 중요하게 다루는 분야는 주로 화학이다. 물리를 위해선 아득바</description>
    </item>
    
    <item>
      <title>R 에서 조건부 합 조건부 평균 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-sum-and-conditional-mean-in-r/</link>
      <pubDate>Thu, 23 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-sum-and-conditional-mean-in-r/</guid>
      <description>개요 엑셀이라고 치면 sumif() 혹은 averageif() 함수가 필요한 상황이 가끔 있다.R 에선 그처럼 단순한 함수는 없지만, 압도적인 상위호환으로 apply 계열 함수가 있다. 이 함수를 꼼꼼하게 익혀놓으면 좋긴한데, 당장은 급한대로 조건부 합과 조건부 평균만 구해보자. 예제 iris 데이터셋을 불러보자. 임의로 10, 50, 90, 130번째 데이터를 살펴보면 범주형 변수로써 종을 분류해놓은 것</description>
    </item>
    
    <item>
      <title>깁스의 엔트로피 표현</title>
      <link>https://freshrimpsushi.github.io/posts/gibbs-expression-for-the-entropy/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gibbs-expression-for-the-entropy/</guid>
      <description>공식 거시상태가 $i$번째 상태일 확률을 $P_{i}$라고 하면 다음이 성립한다. $$ S = - k_{B} \sum_{i} P_{i} \ln P_{i} $$ 설명 이젠 열에 대한 공부라고 말하기도 어려울 정도까지 왔다. 하지만 반대로 생각해보면, 엔트로피 자체가 열역학을 뛰어넘어 이런 것까지 생각하기 위해 도입되었다고 볼 수도 있다. 유도 Part 1. 열역학 제1법칙 $$ d U = \delta Q + \delta W $$ 엔트로피의 정</description>
    </item>
    
    <item>
      <title>회귀계수의 t검정 t-test for Regression Coefficient</title>
      <link>https://freshrimpsushi.github.io/posts/654/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/654/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 단순회귀분석다중회귀분석R 에서 단순회귀분석 결과 $n$ 개의 관측치와 $p$ 개의 독립변수에 대한 다중회귀분석에 대해 $i=0,1,\cdots,p$ 라고 하자. $H_{0}$ : $\beta_{i} = 0$ 즉, $i$ 번째 독립변수는 종속변수과 관계 없다. $H_{1}$ : $\beta_{i} \ne 0$ 즉, $i$ 번째 독립변수에 대한 회귀계수가 유의하다. 회귀계수의 추정치 $\hat{ \beta_{i} }$ 와 표준오차 $ \text{se} ( \hat{</description>
    </item>
    
    <item>
      <title>우주의 엔트로피는 감소하지 않는다</title>
      <link>https://freshrimpsushi.github.io/posts/653/</link>
      <pubDate>Mon, 20 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/653/</guid>
      <description>정리 우주의 엔트로피는 감소하지 않는다. 설명 위 명제를 보고 가장 먼저 알 수 있는 사실은 &amp;lsquo;뭔가 멋있다&amp;rsquo;는 점이다. 하지만 정말로 멋있는 건 이것을 수식적으로 이해한 사람이고, 그런 사람이 될 수 있도록 노력하자. 증명 이 우주는 유일하며, 따라서 이 우주의 &amp;lsquo;외부&amp;rsquo;같은 건 존재하지 않는다는 가정이</description>
    </item>
    
    <item>
      <title>R 에서 단순회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</guid>
      <description>실습 회귀분석하는 법 head(faithful) R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 데이터만 봐서는 두 변수 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph(6,3) par(mfrow=c(1,2)) plot(faithful, main =&amp;#34;faithful&amp;#34;,asp=T) plot(faithful, main =&amp;#34;faithful&amp;#34;) points(head(faithful),col=&amp;#39;red&amp;#39;,pch=19) 왼쪽은 가로세로의 비율이 일정하도록 맞춰놓은 것인데, 정확한 그래프지만 보기가 어렵다. 오른쪽은 보기 편하도록 비율을 조정한 그래프</description>
    </item>
    
    <item>
      <title>열역학에서 엔트로피란</title>
      <link>https://freshrimpsushi.github.io/posts/entropy-in-thermodynamics/</link>
      <pubDate>Sat, 18 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/entropy-in-thermodynamics/</guid>
      <description>정의 다음의 식을 만족하는 $S$를 엔트로피entropy라 정의한다. $$ dS = {{ \delta Q_{\text{rev} } } \over { T }} $$ 설명 엔트로피는 &amp;lsquo;무질서도&amp;rsquo;를 나타내는 물리량으로써, 수식적인 정의만 보고는 이게 왜 무질서도인지 이해하기 어렵다. &amp;lsquo;방 어지르기&amp;rsquo;나 &amp;lsquo;물잔에 잉크 떨어뜨리기&amp;rsq</description>
    </item>
    
    <item>
      <title>단순회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/simple-linear-regression/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simple-linear-regression/</guid>
      <description>개요 회귀분석이란 변수 사이의 관계를 알아내는 방법으로써, 특히 선형 관계를 밝히는 데 유용하다 단순회귀분석Simple Linear Regression은 그 중에서도 가장 쉬운 것으로, 종속변수(반응변수) 하나와 독립변수(설명변수) 하나에 대한 회귀분석을 말한다. 모델 1 독립변수 $x_{i}$ 와 종속변수 $y_{i}$ 가 선형 관계를 가진다는 말은 어떤 $a,b$ 에 대해 $y_{i} = ax_{i}</description>
    </item>
    
    <item>
      <title>클라우지우스 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/clausius-inequality/</link>
      <pubDate>Thu, 16 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/clausius-inequality/</guid>
      <description>정리 순환 과정에서 다음의 식이 성립한다. $$ \oint {{\delta Q} \over {T}} \le 0 $$ 특히 가역 과정이면 다음이 성립한다. $$ \oint {{\delta Q_{\text{rev}}} \over {T}} = 0 $$ 설명 순환 과정이란 위와 같이 과정을 시작할 때와 끝낼 때 계의 상태가 같은 과정을 말한다. 만약 이 과정 전체가 가역과정이라면 그 폐적분은 항상 $0$ 이고, 그때 $Q := Q_{\text{rev}}$ 와 같은 표현을 사용한다.</description>
    </item>
    
    <item>
      <title>적합치, 예측치, 잔차, 오차</title>
      <link>https://freshrimpsushi.github.io/posts/fitted-value-predict-value-residual-error/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fitted-value-predict-value-residual-error/</guid>
      <description>정의 1 회귀분석 $Y \leftarrow X_{1} + X_{2} + \cdots + X_{n}$ 으로 얻은 회귀식을 $y = \beta_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} + \cdots + \beta_{n} x_{n}$ 이라고 하고 $i$ 번째 데이터를 $(y_{i} , x_{i1} , x_{i2} , \cdots , x_{in})$ 와 같이 나타내도록 하자. 평균Mean: $$ \displaystyle \overline{y} := {{1} \over {n}} \sum_{i=1}^{n} y_{i} $$ 적합치Fitted Value: $i$ 번째 데이터 $y_{i}$ 에 대해 $$ \hat{y}_{i} := \beta_{0} + \beta_{1} x_{i1} + \beta_{2} x_{i2} + \cdots + \beta_{n} x_{in} $$ 예측치Predicted Value: 새로운 데이터 $y_{0}$ 에 대해 $$ \hat{y}_{0} := \beta_{0}</description>
    </item>
    
    <item>
      <title>카르노 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-carnot-theorem/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-carnot-theorem/</guid>
      <description>정리 카르노 기관보다 효율이 높은 기관은 존재하지 않는다. 설명 어차피 카르노 기관을 실제로 구현할 순 없지만 이론적인 한계가 된다는 점에서 대단히 의미있는 정리다. 증명 카르노 기관 $C$보다 효율이 높은 기관 $E$가 존재한다고 가정해보자. $E$ 는 열 $Q_{h}&amp;rsquo;$를 받아서 $W$만큼의 일을 하고, $C$ 는 열 $Q_{l}$과 일 $W</description>
    </item>
    
    <item>
      <title>위상수학에서의 함수공간</title>
      <link>https://freshrimpsushi.github.io/posts/function-space/</link>
      <pubDate>Mon, 13 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/function-space/</guid>
      <description>정의 1 위상공간 $X$ 와 $Y$ 에 대해 다음과 같이 정의된 곱 공간 $Y^{X}$를 함수 공간이라 한다. $$ Y^{X} : = \prod_{x \in X} Y = \left\{ f \ | \ f : X \to Y \text{ is a function} \right\} $$ 함수공간의 위상이 되는 것으로 다음이 있다: $x \in X$ 와 $Y$ 에서 열린 집합 $U$ 에 대해 $$ S (x , U) = \left\{ f \in Y^{X} \ | \ f(x) \in U \right\} $$ 라 하자. 부분기저 $\left\{ S(x,U) \ | \ x \in X , U \subset Y \right\}$ 로 생성되는 $Y^{X}$ 의 위상을 포</description>
    </item>
    
    <item>
      <title>카르노 기관</title>
      <link>https://freshrimpsushi.github.io/posts/carnot-engine/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/carnot-engine/</guid>
      <description>정의 다음 네 가지 과정을 순서대로 수행하는 기관을 카르노 기관Carnot engine이라 한다. Step 1. 등온 팽창 과정 $A \to B$: 온도가 $T_{h}$로 유지된 상태에서 열에너지 $Q_{h}$를 받아 부피가 $V_{A}$에서 $V_{B}$로 증가한다. Step 2. 단열 팽창 과정 $B \to C$: 열이 유지된 상태에서 부피가 $V_{B}$에서 $V_{C}$</description>
    </item>
    
    <item>
      <title>제3동형 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-third-isomorphism-thoerem/</link>
      <pubDate>Sat, 11 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-third-isomorphism-thoerem/</guid>
      <description>정리 1 $G,G&#39;$ 가 군이라 하자. 제1동형 정리: 준동형사상 $\phi : G \to G&#39;$ 이 존재하면 $$ G / \ker ( \phi ) \simeq \phi (G) $$ 제2동형 정리: $H \le G$ 이고 $N \triangleleft G$ 면 $$ (HN) / N \simeq H / (H \cap N) $$ 제3동형 정리: $H , K \triangleleft G$ 이고 $K \leq H$ 면 $$ G/H \simeq (G/K) / (H/K) $$ 동형 정리Isomorphism Thoerem는 대수학자 에미 뇌터에 의해 증명된 정리로 독립적인 위의 세 가지 정리를 일컫</description>
    </item>
    
    <item>
      <title>열역학 제2법칙</title>
      <link>https://freshrimpsushi.github.io/posts/the-second-law-of-thermodynamics/</link>
      <pubDate>Fri, 10 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-second-law-of-thermodynamics/</guid>
      <description>법칙 클라우지우스: 스스로 차가운 쪽에서 뜨거운 쪽으로 열을 보내는 과정은 존재하지 않는다. 켈빈: 열을 완전히 일로 바꾸는 과정은 존재하지 않는다. 설명 열역학 제2법칙 에 대한 독일의 물리학자 클라우지우스Clausius와 영국의 물리학자 켈빈Kelvin의 진술은 서로 동치다. 가장 유명한 것은 그리스의 수학자 카라테오도리Καραθεο</description>
    </item>
    
    <item>
      <title>제2동형 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-second-isomorphism-thoerem/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-second-isomorphism-thoerem/</guid>
      <description>정리 1 $G,G&#39;$ 가 군이라 하자. 제1동형 정리: 준동형사상 $\phi : G \to G&#39;$ 이 존재하면 $$ G / \ker ( \phi ) \simeq \phi (G) $$ 제2동형 정리: $H \le G$ 이고 $N \triangleleft G$ 면 $$ (HN) / N \simeq H / (H \cap N) $$ 제3동형 정리: $H , K \triangleleft G$ 이고 $K \leq H$ 면 $$ G/H \simeq (G/K) / (H/K) $$ 동형 정리Isomorphism Thoerem는 대수학자 에미 뇌터에 의해 증명된 정리로 독립적인 위의 세 가지 정리를 일컫</description>
    </item>
    
    <item>
      <title>단열감률의 열역학적 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-adiabatic-lapse-rate/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-adiabatic-lapse-rate/</guid>
      <description>공식 $m$ 을 기체 분자의 질량, $h$를 높이, $T$를 온도라고하면 다음의 식이 성립한다. $$ \dfrac{dT}{dh} = - {{ \gamma -1} \over { \gamma }} \dfrac{ mg }{k_{B}} $$ 이때 $\gamma = \dfrac{C_{p}}{C_{V}}$ 는 등압 열용량과 등적 열용량의 비율이다. 설명 알다시피 고도가 올라갈수록 기온은 떨어지는데, 그 비율을 수식적으로 나타낸 것이다. 물론 이는 습도와 같은 여러가지 변수들을 전혀 고려하지 않고 열역학만을 이용해 유</description>
    </item>
    
    <item>
      <title>제1동형 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-first-isomorphism-thoerem/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-first-isomorphism-thoerem/</guid>
      <description>정리 1 $G,G&#39;$ 가 군이라 하자. 제1동형 정리: 준동형사상 $\phi : G \to G&#39;$ 이 존재하면 $$ G / \ker ( \phi ) \simeq \phi (G) $$ 제2동형 정리: $H \le G$ 이고 $N \triangleleft G$ 면 $$ (HN) / N \simeq H / (H \cap N) $$ 제3동형 정리: $H , K \triangleleft G$ 이고 $K \leq H$ 면 $$ G/H \simeq (G/K) / (H/K) $$ 동형 정리Isomorphism Thoerem는 대수학자 에미 뇌터에 의해 증명된 정리로 독립적인 위의 세 가지 정리를 일컫</description>
    </item>
    
    <item>
      <title>이상기체의 단열 팽창</title>
      <link>https://freshrimpsushi.github.io/posts/adiabatic-expansion-of-an-ideal-gas/</link>
      <pubDate>Mon, 06 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/adiabatic-expansion-of-an-ideal-gas/</guid>
      <description>정리 몰수가 $1$이고 단열 팽창을 하는 이상기체의 계에서 압력이 $p$, 부피가 $V$라고 하면 $p V^{\gamma}$은 상수다. 이때 $\gamma = \dfrac{C_{p}}{C_{V}}$ 는 등압 열용량과 등적 열용량의 비율이다. 설명 단열 팽창이란 열에너지가 변하지 않는 조건에서의 팽창을 말한다. $\gamma = \dfrac{C_{p}}{C_{V}}$ 는 물리적으로의 의미는 딱히 없다. 증명 열역학 제1법칙 $$ d U = \delta Q + \delta W $$ 열역학 제</description>
    </item>
    
    <item>
      <title>번사이드 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-burnside-formula/</link>
      <pubDate>Sun, 05 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-burnside-formula/</guid>
      <description>개요 번사이드 공식은 군의 작용과 등방부분군에 대한 대표적인 응용으로써 조합론을 비롯한 분야에서 즉시 쓰일 수 있다. 공식 1 유한군 $G$ 에 대해 유한집합 $X$ 가 $G$-집합이라고 하자. $r$ 이 $G$ 하의 $X$ 의 궤도의 갯수라고 하면 $$ r |G| = \sum_{g \in G} \left| X_{g} \right| $$ 유도 집합 $\left\{ (g,x) \in G \times X | gx = x \right\}$ 의 기수를 $N$ 이라고 하면 $$ X_{g} = \left\{ x \in X \ | \ gx = x \right\} $$ 이고, $G_{x} =</description>
    </item>
    
    <item>
      <title>이상기체의 등온 팽창</title>
      <link>https://freshrimpsushi.github.io/posts/isothermal-expansion-of-an-ideal-gas/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isothermal-expansion-of-an-ideal-gas/</guid>
      <description>공식 몰 수가 $1$이고 등온 팽창을 하는 이상기체의 계에서 열에너지가 $Q$, 온도가 $T$, 팽창 전의 부피를 $V_{1}$, 팽창 후의 부피를 $V_{2}$라고 할 때 다음의 식이 성립한다. $$ \Delta Q = RT \ln \dfrac{V_{2}}{V_{1}} $$ 설명 등온 팽창이란 온도가 변하지 않는 조건에서의 팽창을 말한다. 이때 열에너지의 변화는 편리하게도 부피의 변화만을 이용해 구해낼 수 있다. 일단은 팽창이므로 $V_{2} &amp;gt; V_{1}$</description>
    </item>
    
    <item>
      <title>등방부분군</title>
      <link>https://freshrimpsushi.github.io/posts/isotropy-subgroup/</link>
      <pubDate>Fri, 03 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isotropy-subgroup/</guid>
      <description>정의 1 군 $G$ 에 대해 $X$ 를 $G$-집합이라고 하자. $x \in X$ 와 $g \in G$ 에 대해 $X_{g} := \left\{ x \in X \ | \ gx = x \right\}$ 그리고 $G_{x} := \left\{ g \in G \ | \ gx = x \right\}$ 라 두자. $G_{x}$ 를 $x$ 에 대한 $G$ 의 등방부분군Isotropy Subgroup이라 정의한다. 설명 등방부분군이 뭔지 감을 잡으려면 군의 작용에 대한 이해가 있어야한다. 위 그림 좌측의 점들과 선들의 집합 $$ X :</description>
    </item>
    
    <item>
      <title>등적 열용량과 등압 열용량</title>
      <link>https://freshrimpsushi.github.io/posts/constant-volume-heat-capacity-and-constant-pressure-heat-capacity/</link>
      <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/constant-volume-heat-capacity-and-constant-pressure-heat-capacity/</guid>
      <description>공식 몰 수가 $1$인 이상기체의 계에서 등적 열용량 $C_{V}$와 등압 열용량 $C_{p}$ 에 대해 다음의 식이 성립한다. $$ C_{p} = C_{V} + R = {{5} \over {2}} R $$ 설명 등적 과정이냐 등압 과정이냐에 따른 열용량은 다를 뿐만이 아니라 수식적으로도 착착 맞아떨어지는 관계가 있다. 특히 $\gamma := \dfrac{C_{p}}{C_{V}}$ 자체는 물리적으로 큰 의미가 없지만, 수식적으로 여기저기서 중요하게 쓰인다. 증</description>
    </item>
    
    <item>
      <title>군의 작용</title>
      <link>https://freshrimpsushi.github.io/posts/group-action/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/group-action/</guid>
      <description>정의 1 항등원이 $e$ 인 군 $G$ 와 집합 $X$ 에 대해 다음의 두 조건을 만족하는 이항연산 $\ast : G \times X \to X$ 를 $X$ 상에서 $G$ 의 작용Action이라 하고 $X$ 를 $G$-집합이라고 부른다. (i): 모든 $x \in X$ 에 대해 $ex = x$ (ii): 모든 $x \in X$ 와 $g_{1} , g_{2} \in G$ 에 대해 $( g_{1} g_{2} ) (x) = g_{1} (g_{2} x)$ 설명 군의 작용은 한마디로 &amp;lsquo;$x \in X$ 에다 $g \in G$ 를 가한다&amp;rsquo;는 말이다. 직관적으로</description>
    </item>
    
    <item>
      <title>열역학 제1법칙</title>
      <link>https://freshrimpsushi.github.io/posts/the-first-law-of-thermodynamics/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-first-law-of-thermodynamics/</guid>
      <description>법칙 열에너지가 $Q$인 계에 가해진 일이 $W$일 때, 내부에너지 $U$ 에 대해서 다음의 식이 성립한다. $$ d U = \delta Q + \delta W $$ $\delta$ 는 불완전 미분inexact differential임을 나타낸다. 설명 이들은 깔끔한 폼으로 원시함수가 존재하지 않기 때문에 선적분을 통해 계산해야한다. 내부에너지의 변화만 가지고는 구체적으로 열에너지가 어느</description>
    </item>
    
    <item>
      <title>추상대수학에서의 몫군</title>
      <link>https://freshrimpsushi.github.io/posts/factor-group/</link>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factor-group/</guid>
      <description>정의 1 $H \subset G$ 의 모든 잉여류의 집합을 $G / H$ 라고 하자. $(aH) \ast\ (bH) = (ab) H$ 와 같이 잘 정의된 이항연산 $\ast$ 이 존재하면 $\left&amp;lt; G / H , * \right&amp;gt;$ 를 몫군Factor Group이라 한다. 정리 $H \leqslant G$ 이라고 하자. $H \triangleleft G$ 인 것과 $G / H$ 는 군인 것은 동치다. 설명 $H \triangleleft G$ 라는 것은 $H$ 가 $G$ 의 정규부분군이라는 것이다. 이항연산 $\ast$ 는 잉여류의 대푯값끼리만 계산하는 이항연</description>
    </item>
    
    <item>
      <title>열용량</title>
      <link>https://freshrimpsushi.github.io/posts/heat-capacity/</link>
      <pubDate>Sun, 29 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heat-capacity/</guid>
      <description>정의1 물체의 온도를 $dT$만큼 올리는데 필요한 열 $dQ$ 열을 물체의 열용량heat capacity이라 하고 capacity의 C를 따서 다음과 같이 표기한다. $$ C = \dfrac{dQ}{dT} [\text{J/K}] $$ 설명 단위질량당 열용량을 특별히 비열specific heat capacity이라고 하는데, 다른 분야에선 모르겠지만 물리에선 별로 중요치 않다. 열역학에서는 어떤 특정</description>
    </item>
    
    <item>
      <title>티호노프 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-tychonoff-theorem/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-tychonoff-theorem/</guid>
      <description>정리 $\left\{ X_{\alpha} \ | \ \alpha \in \mathscr{A} \right\}$ 가 컴팩트 공간들의 집합이면 $\displaystyle X : = \prod_{\alpha \in \mathscr{A}} X_{ \alpha}$ 는 컴팩트다. 설명 이름까지 붙은 정리치고는 일개 성질 나부랭이처럼 보이지만 사실 그 반대로 보는 게 맞다. 일개 성질 나부랭이처럼 보이지만 의외로 증명하기가 너무 어려워서 정리에 이름까지 붙어버린 것이다. 유용하기론 둘째가라면 서러운 컴팩트가 위상공간들의 데카르트 곱에 대</description>
    </item>
    
    <item>
      <title>기체분자의 평균 운동에너지</title>
      <link>https://freshrimpsushi.github.io/posts/mean-kinetic-energy-of-a-gas-molecule/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-kinetic-energy-of-a-gas-molecule/</guid>
      <description>공식1 온도가 $T$인 계에서 기체분자들의 평균 운동에너지는 다음과 같다. $$ \left\langle E_{K} \right\rangle = {{3} \over {2}} k_{B} T $$ 설명 기체분자 하나하나에 대해 운동에너지를 구해서 평균을 구하는 것은 비효율적일뿐만 아니라 현실적으로 불가능하다. 하지만 통계적으로 유도한 이 공식에 따르면 운동에너지는 오로지 온도에만 의존하며 구하기도 쉬워진다. 상수배가 하필 $\dfr</description>
    </item>
    
    <item>
      <title>알렉산더 부분기저 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-alexander-subbasis-theorem/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-alexander-subbasis-theorem/</guid>
      <description>정리 $X$ 가 위상공간이라고 하자. $X$ 는 컴팩트다. $\iff$ $\mathscr{S}$ 의 멤버들로 이루어진 $X$ 의 모든 열린 커버가 유한 부분커버를 갖게끔 하는 $X$ 의 어떤 부분기저 $\mathscr{S}$ 가 존재한다. 설명 컴팩트가 나왔으니 중요성은 말할 필요 없을 것이다. 본 정리는 원래 알렉산더의 스승이 기저에 대해 증명하려고 했던 정리였다. 하지만 기저에 대해서는 증명할 수 없었고, 스승의 유지를 이어받</description>
    </item>
    
    <item>
      <title>맥스웰 분포</title>
      <link>https://freshrimpsushi.github.io/posts/maxwell-distribution/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maxwell-distribution/</guid>
      <description>정리1 기체분자의 속력을 나타내는 확률변수 $V$ 는 확률밀도함수가 아래와 같은 맥스웰 분포Maxwell distribution를 따른다. $$ f(v) = \dfrac{4}{\sqrt{ \pi}} \left( \dfrac{m}{2 k_{B} T} \right)^{3/2} v^{2} e^{-mv^2 / 2k_{B}T } $$ 설명 맥스웰 분포는 볼츠만 분포에서 유도되어 맥스웰-볼츠만 속력 분포라고도 불린다. 통계역학이라는 이름이 무색해질만큼 통계학에서 볼 수 없는 분포로, 굳이 엮자면 정</description>
    </item>
    
    <item>
      <title>추상대수학에서의 핵</title>
      <link>https://freshrimpsushi.github.io/posts/kernel-in-abstract-algebra/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kernel-in-abstract-algebra/</guid>
      <description>정의 $G, G&#39;$ 의 항등원 $e, e&#39;$ 과 준동형사상 $\phi : G \to G&#39;$ 에 대해 $\left\{ e&#39; \right\}$ 의 원상 $ \phi^{-1} [ \left\{ e&#39; \right\} ]$ 을 $\phi$ 의 핵Kernel이라 하고 $\ker \phi $ 라고 쓴다. 정의 [1]: $g \in G$ 에 대해 $g ( \ker \phi ) = ( \ker \phi ) g$ [2]: $\ker \phi \triangleleft G$ [3]: $\ker \phi = \left\{ e \right\}$ $\iff$ $\phi$ 는 단사다. [4]: $\phi$ 가 전사고 $\ker \phi = \left\{ e \right\}$ 면 $\phi$ 는 동형사상이다. 설명 정리 [3]은 필요충분조건이지만 특히 준동형사상이 단사임을 보</description>
    </item>
    
    <item>
      <title>연속제곱법 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-successive-squaring-method/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-successive-squaring-method/</guid>
      <description>알고리즘 자연수 $a,k,m$ 에 대해 $b \equiv a^{k} \pmod{m}$ 를 다음과 같이 계산할 수 있다. Step 1. $k$ 의 이진법 전개 $u_{i} = 0$ 혹은 $u_{i} = 1$ 에 대해 다음과 같이 나타낸다. $$ k = \sum_{i=0}^{r} u_{i} 2^{i} = u_{0} + 2 u_{1} + \cdots + 2^r u_{r} $$ Step 2. $$ \begin{align*} a &amp;amp; &amp;amp; &amp;amp; \equiv A_{0} \pmod{m} \\ a^{2} &amp;amp; \equiv ( a^1 )^2 &amp;amp; \equiv A_{0}^2 &amp;amp; \equiv A_{1} \pmod{m} \\ a^{4} &amp;amp; \equiv ( a^2 )^2 &amp;amp; \equiv A_{1}^2 &amp;amp; \equiv A_{2} \pmod{m} \\ a^{8} &amp;amp; \equiv ( a^4 )^2 &amp;amp; \equiv A_{2}^2 &amp;amp; \equiv A_{3} \pmod{m} \\ &amp;amp; &amp;amp; &amp;amp; \vdots \end{align*} $$ 위와 같이 $a^{2^{r}} \equiv ( a^{2^{r-1}} )^2 \equiv A_{r-1}^2 \equiv A_{r} \pmod{m}$ 를</description>
    </item>
    
    <item>
      <title>위상공간의 데카르트 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cartesian-product-of-topology-space/</link>
      <pubDate>Sun, 22 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cartesian-product-of-topology-space/</guid>
      <description>정의 1 인덱스 집합 $\mathscr{A}$ 에 대해 $\left\{ X_{\alpha} \ | \ \alpha \in \mathscr{A} \right\}$ 가 위상공간들의 집합이고 $O_{\alpha}$ 을 $X_{\alpha}$ 에서 열린 집합이라고 하자. 데카르트 곱 $\displaystyle X := \prod_{\alpha \in \mathscr{A}} X_{ \alpha}$ 에 대해 $p_{\alpha} : X \to X_{\alpha}$ 를 사영Projection이라 한다. 부분기저 $\mathscr{S} : = \left\{ p_{\alpha}^{-1} ( O_{\alpha} ) \ | \ O_{\alpha} \subset X_{\alpha} , \alpha \in \mathscr{A} \right\}$ 에 의해 생성되는 $X$ 의 위상을 곱위상Product Topology라 한다. 기저 $\displaystyle \mathscr{B} : = \left\{</description>
    </item>
    
    <item>
      <title>군의 데카르트 곱</title>
      <link>https://freshrimpsushi.github.io/posts/cartesian-product-of-groups/</link>
      <pubDate>Sat, 21 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cartesian-product-of-groups/</guid>
      <description>정의 1 2 군 $G_{1} , \cdots , G_{n}$ 들의 데카르트 곱과 그 원소 $\displaystyle (a_{1},\cdots , a_{n}), (b_{1} , \cdots , b_{n} ) \in \prod_{i=1}^{n} G_{i}$ 에 대해 $$ (a_{1},\cdots , a_{n}) (b_{1} , \cdots , b_{n} ) = (a_{1} b_{1},\cdots , a_{n} b_{n}) $$ 이면 $\displaystyle \prod_{i=1}^{n} G_{i}$ 를 $G_{1} , \cdots , G_{n}$ 들의 직곱Direct Product이라 한다. 특히 $G_{1}, \cdots , G_{n}$ 이 가환군이면 $\displaystyle \bigoplus_{i=1}^{n} G_{i}$ 로 쓰고 직합Direct Sum이라고도 부른다. $G_{1}$ 가 $G$ 의 부분군라고 할 때, 다음을 만족하는 $G$ 의 또다른 부분</description>
    </item>
    
    <item>
      <title>등온 대기에서 높이에 따른 기체 분자 수 공식</title>
      <link>https://freshrimpsushi.github.io/posts/formulas-in-the-number-of-gaseous-molecules-by-height-in-an-isothermal-atmosphere/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/formulas-in-the-number-of-gaseous-molecules-by-height-in-an-isothermal-atmosphere/</guid>
      <description>공식1 기온 $T$가 일정하다고 할 때 높이 $h$에서 단위 부피 $V=1$당 기체분자의 수를 $N(h)$라고 하자. 기체분자의 질량이 $m$이고 중력가속도가 $g$ 면 다음의 식이 성립한다. $$ N(h) = N(0) e^{- {{mgh} \over {k_{B} T}} } $$ 설명 이 공식은 원래 열역학에선 별볼일 없지만, 유도하는 두 가지 방법이 판이하게 다른 점이 재미있다. 유도 미분방정식을 이용하여 높이</description>
    </item>
    
    <item>
      <title>스털링 근사 공식의 엄밀한 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-stirling-approximation/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-stirling-approximation/</guid>
      <description>정리 $$ \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ 설명 스털링 근사 혹은 스털링 공식Stirling Formula은 통계학이나 물리학 등 여러 곳에서 유용하게 쓰인다. 또 다른 표현으로는 감마 함수를 사용해 다음과 같이 적을 수 있다. $$ \Gamma ( n ) \approx {e^{n \ln n - n} \sqrt{ 2 \pi n}} $$ 본 증명은 &amp;lsquo;제타함수의 비밀&amp;rsquo;이라는 책의 부록에 실</description>
    </item>
    
    <item>
      <title>볼츠만 분포</title>
      <link>https://freshrimpsushi.github.io/posts/boltzmann-distribution/</link>
      <pubDate>Tue, 17 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/boltzmann-distribution/</guid>
      <description>정리1 온도가 $T$인 계의 에너지가 $\varepsilon$일 확률은 다음과 같다. $$ P(\varepsilon) \propto e^{ - \frac{\varepsilon}{k_{B} T} } $$ 이러한 분포를 볼츠만 분포Boltzmann distribution라고 한다. 유도 앙상블ensemble이란 쉽게 말해 &amp;lsquo;계들이 이루는 상황&amp;rsquo;이다. 그 중에서 정준 앙상블canonical ens</description>
    </item>
    
    <item>
      <title>르벡공간에서의 민코프스키 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-minkowskis-inequality-in-lebesgue-space/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-minkowskis-inequality-in-lebesgue-space/</guid>
      <description>정리1 $\Omega \subset \mathbb{R}^{n}$를 열린 집합이라고 하자. $1 \le p &amp;lt; \infty$이고 $u, v \in L^{p}(\Omega)$이면, $$ \left\| u + v \right\|_{p} \le \left\| u \right\|_{p}+\left\| v \right\|_{p} $$ 이를 민코프스키 부등식Minkowski inequality이라 한다. 설명 $\left\| \cdot \right\|_{p}$가 삼각 부등식을 만족하여 놈이 되고, $L^{p}$ 공간은 놈 공</description>
    </item>
    
    <item>
      <title>물리학에서 온도의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-temperature-in-physics/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-temperature-in-physics/</guid>
      <description>정의1 2 에너지가 $E$인 계가 있다고 하자. $E$ 에 대한 미시상태의 개수를 $\Omega(E) = \Omega$ 라고 할 때 $$ \dfrac{1}{k_{B} T} := \dfrac{d \ln ( \Omega )}{d E } $$ 를 만족하는 $T$를 계의 온도temperature라고 정의한다. (단, $k_{B}$는 볼츠만 상수) 미시상태와 거시상태 통계역학에서 어떤 계의 거시상태Macrostate와 미시상태Microstate란 예를</description>
    </item>
    
    <item>
      <title>열역학 제0법칙</title>
      <link>https://freshrimpsushi.github.io/posts/the-zeroth-law-of-thermodynamics/</link>
      <pubDate>Sat, 14 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-zeroth-law-of-thermodynamics/</guid>
      <description>법칙1 계 $A,B,C$ 에 대해 $A$ 와 $B$ 가 열역학적 평형을 이루고 $B$ 와 $C$ 열역학적 평형을 이루면 $A$ 와 $C$ 도 열역학적 평형 을 이룬다. 설명 열역학 제0법칙을 수학적으로 표현하자면 &amp;lsquo;열역학적 평형의 추이성&amp;lsquo;이 된다. 유클리드 기하학 제1공리$A = B \land B=C \implies A = C$ 와 같이 각 분야의 근간을 이루는 중요한 법칙이고, 물리학의 많은 부분에서</description>
    </item>
    
    <item>
      <title>스털링 공식의 간단한 유도</title>
      <link>https://freshrimpsushi.github.io/posts/naive-proof-of-stirling-approximation/</link>
      <pubDate>Wed, 11 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/naive-proof-of-stirling-approximation/</guid>
      <description>공식 다음의 방정식을 스털링 공식Stirling&#39;s formula이라 한다. $$ \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ 설명1 이 근사는 큰 수에 대한 팩토리얼의 계산이라는 측면에서 유용하다. 열열학, 통계역학과 같은 분야에선 많은 수의 분자를 가정하기 때문에 필수적이며, $$ \ln n! \approx n \ln n - n $$ 와 같이 더 간략화된 표현도 사용된다. 아래의</description>
    </item>
    
    <item>
      <title>칸토어 집합</title>
      <link>https://freshrimpsushi.github.io/posts/cantor-set/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cantor-set/</guid>
      <description>정의 $$ \begin{align*} I =&amp;amp; \left[ 0, 1 \right] \\ C_{1} =&amp;amp; \left[ 0, {{1} \over {3}} \right] \cup \left[ {{2} \over {3}} , 1 \right] \\ C_{2} =&amp;amp; \left[ 0, {{1} \over {3^2}} \right] \cup \left[ {{2} \over {3^2}}, {{3} \over {3^2}} \right] \cup \left[ {{6} \over {3^2}}, {{7} \over {3^2}} \right] \cup \left[ {{8} \over {3^2}} , 1 \right] \\ &amp;amp;\vdots \\ C_{n} =&amp;amp; \left[ 0, {{1} \over {3^n}} \right] \cup \left[ {{2} \over {3^n}}, {{3} \over {3^n}} \right] \cup \cdots \cup \left[ {{3^n-3} \over {3^n}}, {{3^n-2} \over {3^n}} \right] \cup \left[ {{3^n - 1} \over {3^n}} , 1 \right] \end{align*} $$ 이라고 하자. $\displaystyle C := \bigcap_{n=1}^{\infty} C_{n}$ 을 칸토어 집합Cantor Set이라 한다. 정리 [1]: $C = \left\{ x \in I \ | \ x= 0.x_{1}</description>
    </item>
    
    <item>
      <title>Lp 공간, 르벡 공간</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-space-lp-space/</link>
      <pubDate>Sun, 08 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-space-lp-space/</guid>
      <description>정의1 2 3 $\Omega \subset \mathbb{R}^{n}$를 열린 집합, $p$를 양의 실수라고 하자. $\Omega$ 위에서 정의된 모든 가측함수 $f$에 대해서 집합 $L^{p}(\Omega)$를 다음과 같이 정의한다. $$ L^{p}(\Omega) := \left\{ f : \int_{\Omega} \left| f(x) \right|^{p} dx &amp;lt; \infty \right\} $$ 이를 엘피공간Lp space 혹은 르벡공간Lebesgue space이라 하고, 간단히 $L^{p}$와 같이</description>
    </item>
    
    <item>
      <title>베르의 범주 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-baire-category-theorem/</link>
      <pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-baire-category-theorem/</guid>
      <description>정의 위상공간 $X$ 의 모든 조밀한 열린 집합의 수열 $\left\{ O_{n} \right\}_{n=1}^{\infty}$ 에 대해 $\displaystyle \bigcap_{n=1}^{\infty} O_{n}$ 이 조밀한 공간을 베르 공간Baire Space이라 한다. 베르의 범주 정리 1 모든 완비거리공간은 베르 공간이다. 증명 Claim: 모든 열린 집합 $U \subset X$ 에 대해 $\displaystyle U \cap \left( \bigcap_{n=1}^{\infty} O_{n} \right) \ne \emptyset$ 이다. Part 1. $X$ 는 거리공간이므로, 열린 집합은 어떤 $x^{ \ast } \in X$ 와 $r^{ \ast } &amp;gt; 0$ 에 대해 다음과 같이 나타낼 수 있다</description>
    </item>
    
    <item>
      <title>병렬회로의 합성저항 쉽게 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/603/</link>
      <pubDate>Fri, 06 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/603/</guid>
      <description>빌드업 위와 같은 회로의 합성저항을 구한다고 생각해보자. 물론 아래와 같이 병렬회로로 바꾸면 답 자체는 공식을 통해 구할 수 있다. 저항이 $n$ 개 있을 때 병렬의 저항 공식은 $\displaystyle {{1} \over {R}} = {{1} \over {R_{1}}} + {{1} \over {R_{2}}} + \cdots + {{1} \over {R_{n}}}$ 이다. 공식에 저항을 대입해보면 $$ \begin{align*} {{1} \over {R}} =&amp;amp; {{1} \over {2}} + {{1} \over {5}} + {{1} \over {5}} \\ =&amp;amp; {{1} \over {2}} + {{2} \over {5}} \\ =&amp;amp; {{5} \over {10}} + {{4} \over {10}} \\ =&amp;amp; {{9} \over {10}} \end{align*} $$ 이고, 따라</description>
    </item>
    
    <item>
      <title>이상기체 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/pv--nrt/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pv--nrt/</guid>
      <description>공식1 기체의 분자 수를 $N$, 부피를 $V$, 압력을 $p$, 절대온도를 $T$라고 하자. 그러면 다음의 식이 성립하며 이를 이상기체 방정식ideal gas equation이라 한다. $$ pV = N k_{B} T $$ 이때 $k_{B} = 1.3807 \times 10^{-23} J / K$를 볼츠만 상수Boltzmann constant라 한다. 설명 역사적으로 보면 실험법칙으로부터 유도되었다가 후에 기체운동론에서 수</description>
    </item>
    
    <item>
      <title>월리스 곱</title>
      <link>https://freshrimpsushi.github.io/posts/wallis-product/</link>
      <pubDate>Wed, 04 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/wallis-product/</guid>
      <description>정리 $$ \prod_{n=1}^{\infty} {{4n^2} \over {4n^2 - 1}} = \lim_{n \to \infty} {{2 \cdot 2 } \over { 1 \cdot 3 } } \cdot {{4 \cdot 4 } \over { 3 \cdot 5 } } \cdot \cdots \cdot {{2n \cdot 2n } \over { (2n-1) \cdot (2n+1) } } = {{ \pi } \over {2}} $$ 설명 급수뿐만이 아니라 곱으로도 원주율을 구할 수 있다는 건 두말할 것도 없이 신기하고 유용한 사실이다. 본디 증명은 이보다 어렵고 사실상 싱크함수의 오일러 표현을 증명하는 과정에 포함되어 있다고 볼 수 있다. 증명 싱크함</description>
    </item>
    
    <item>
      <title>오일러의 완전수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-perfect-number-theorem/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-perfect-number-theorem/</guid>
      <description>정리 1 짝수 $n = 2^{p-1} (2^p - 1)$ 가 완전수면 $2^{p}-1$ 는 메르센 소수다. 설명 언뜻 보면 유클리드 완전수 공식의 역이 되는 것 같지만 짝수에 대해서만 언급되었다는 점이 다르다. 그러나 이 정리는 완전수의 거의 모든 것을 말해주고 있는데, 실제로 홀수 완전수는 아직 발견된 적이 없기 때문이다. 현재까지 홀수 완전수에 대해 밝혀진 사실이라고는 &amp;lsquo;존재한다면 아</description>
    </item>
    
    <item>
      <title>함수의 내적을 정적분으로 정의하는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/reason-for-defining-the-inner-product-of-a-function-as-definitive-integral/</link>
      <pubDate>Mon, 02 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reason-for-defining-the-inner-product-of-a-function-as-definitive-integral/</guid>
      <description>빌드업 내적의 일반적인 정의는 다음과 같다. $H$를 벡터 공간이라고 하자. $x,y,z \in H$와 $\alpha, \beta \in \mathbb{C}$에 대해서 다음의 조건을 만족하는 함수 $$ \langle \cdot , \cdot \rangle \ : \ H \times H \to \mathbb{C} $$ 를 내적이라 정의하고 $\left( H, \langle \cdot ,\cdot \rangle \right)$를 내적공간이라 한다. 선형성: $\langle \alpha x + \beta y ,z \rangle =\alpha \langle x,z\rangle + \beta \langle y,z\rangle$ 켤레대칭성: $\langle x,y \rangle = \overline{ \langle y,x \rangle}$ 정</description>
    </item>
    
    <item>
      <title>한 점 컴팩트화</title>
      <link>https://freshrimpsushi.github.io/posts/one-point-compactification/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/one-point-compactification/</guid>
      <description>정의 1 위상공간 $(X , \mathscr{T})$ 에 대해 $\infty \notin X$ 이라고 하자. $X_{\infty} := X \cup \left\{ \infty \right\}$ 에 대해 아래의 두 조건을 만족하는 위상 $\mathscr{T}_{\infty}$ 을 정의한 $(X_{\infty } , \mathscr{T}_{\infty} )$ 를 $(X, \mathscr{T})$ 의 한 점 컴팩트화One-Point Compactification이라 한다. (i): $\infty \notin U \implies U \in \mathscr{T}_{\infty}$ 와 $U \in \mathscr{T}$ 은 동치다. (ii): $\infty \in U \implies U \in \mathscr{T}_{\infty}$ 와 $X_{\infty} \setminus U$ 가 닫혀있고 컴팩트인 것은 동치다. 정리 $(X_{\infty } , \mathscr{T}_{\infty} )$ 는 다음의</description>
    </item>
    
    <item>
      <title>라그랑주의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lagranges-theorem/</link>
      <pubDate>Sat, 30 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lagranges-theorem/</guid>
      <description>정리 1 $H$ 가 유한군 $G$ 의 부분군이면 $|H|$ 는 $|G|$ 의 약수다. 증명 조금 생각해보면 상식적으로 성립할 수밖에 없고 증명도 그에 걸맞게 간단하다. 모든 잉여류들은 모두 같은 수만큼의 원소를 갖는다. $H$ 역시 $G$ 의 잉여류 중 하나이므로, $H$ 의 잉여류들의 기수Cardinality는 $|H|$ 이다. 잉여류들은 $G$ 의 분할을 이루므로 모든 잉여류들의 기수를 더하면 $|G|$ 이다</description>
    </item>
    
    <item>
      <title>르벡 공간에서의 코시-슈바르츠 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-schwarz-inequality/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-schwarz-inequality/</guid>
      <description>정리1 $f,g \in L^{2} (E)$면 $fg \in L^{1}(E)$이고 다음이 성립한다. $$ \left| \int_{E} f \overline{g} dm \right| \le \left\| f g \right\|_{1} \le \left\| f \right\|_{2} \left\| g \right\|_{2} $$ 여기서 $\| \cdot \|_{2}$은 $L^{2}$ 공간의 놈, $\| \cdot \|_{1}$은 $L^{1}$ 공간의 놈이다. 설명 함수해석학 정도를 배우고 있다면 이 부등식에 왜 코시-슈바르츠라는 이름이 붙었는지 바로 감이 와야한다. 사실 내적이 정의된다면 코시-슈</description>
    </item>
    
    <item>
      <title>L2 공간</title>
      <link>https://freshrimpsushi.github.io/posts/l2-space/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/l2-space/</guid>
      <description>정의 1 함수공간 $L^{2}$를 다음과 같이 정의한다. $$ L^{2} (E) := \left\{ f : \left( \int_{E} | f |^2 dm \right)^{{1} \over {2}} &amp;lt; \infty \right\} $$ 성질 $L^{2}$는 벡터공간이다. $L^{2}$는 놈 공간이다. $L^{2}$는 완비공간이다. $L^{2}$는 내적공간이다. 설명 $L^{2}$ 공간은 $L^{p}$ 공간의 $p=2$일 때의 특수한 경우이며, $L^{p}$ 공간 중 유일하게 내적이 정의되는 공간이</description>
    </item>
    
    <item>
      <title>유클리드의 완전수 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-euclids-perfect-number-formula/</link>
      <pubDate>Tue, 26 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-euclids-perfect-number-formula/</guid>
      <description>공식 1 $2^{p}-1$ 이 소수면 $2^{p-1}(2^{p} - 1)$ 은 완전수다. 설명 모든 완전수가 저런 형태일지는 확실하지 않지만, 저런 형태는 반드시 완전수다. 예를 들면 소수 $(2^2 -1) = 3$ 에 대해 $2^{2-1}(2^2 -1) = 6$ 은 완전수다.완전수와 메르센 소수가 이러한 관계를 가지고 있음은 메르센 소수의 등비급수전개에서 어느정도 짐작을 할 수가 있었다. 유도 $2^{p}-1$ 이 소수이므로, $2^{p-1}(2^{p} - 1)$ 의 약수는 $$ 1,2, \cdots , 2^{p-1} \\ (2^{p}-1),</description>
    </item>
    
    <item>
      <title>L1 공간</title>
      <link>https://freshrimpsushi.github.io/posts/l1-space/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/l1-space/</guid>
      <description>정의1 함수공간 $L^{1}$ 을 다음과 같이 정의한다. $$ L^{1} (E) := \left\{ f : \int_{E} | f | dm \lt \infty \right\} $$ 성질 $L^{1}$은 벡터공간이다. $L^{1}$은 놈 공간이다. $L^{1}$은 완비공간이다. 설명 $L^{1}$ 공간은 $L^{p}$ 공간의 $1=2$일 때의 특수한 경우이며, 르벡 적분가능에 대해 이야기할 때 적분가능한 함수들의 집합으로써 정의된 바 있다. $L^{p}$공</description>
    </item>
    
    <item>
      <title>페아노 공간 충전 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-peano-space-filling-curve/</link>
      <pubDate>Sat, 23 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-peano-space-filling-curve/</guid>
      <description>정리 1 $I = [0,1]$ 에 대해 전사 연속함수 $f : I \to I \times I$ 가 존재한다. 설명 짧지만 몹시 충격적인 정리다. 이 정리가 사실이라면 선만으로 평면을 구성할 수 있다는 뜻인데, 증명을 보고도 납득하기가 어려울 정도다.&amp;lsquo;공간 충전 정리&amp;rsquo;라는 명칭은 일본에서 번역한 것을 임의로 쓴 것이다. 증명 Part 1. 다음 그림들과 같이 경로의 수열 $\left\{ f_{n} \right\}$</description>
    </item>
    
    <item>
      <title>르벡 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lebesgue-theorem/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lebesgue-theorem/</guid>
      <description>정의 $\mathscr{O}$ 를 거리공간 $(X,d)$ 의 열린 커버라고 하자. $\sup \left\{ d(a,b) \ | \ a,b \in A \right\} &amp;lt; \varepsilon$ 를 만족시키는 모든 부분집합 $A \subset X$ 이 어떤 $O \in \mathscr{O}$ 에 대해 $A \subset O$ 를 만족하면 $\varepsilon &amp;gt; 0$ 를 $\mathscr{O}$ 에 대한 르벡 수Lebesgue Number라 한다. 정리 1 [1] 르벡 보조정리: $X$ 가 집적점 컴팩트면 $X$ 의 모든 열린 커버 $\mathscr{O}$ 에 대해 르벡 수가 존재한다. [2] 르벡 정리: $X$ 가 컴팩트면 $X$ 의 모든 열</description>
    </item>
    
    <item>
      <title>디리클레 경계 조건이 주어진 파동방정식에 대한 초기값 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-wave-equation-for-given-dirichlet-boundary-condition/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-wave-equation-for-given-dirichlet-boundary-condition/</guid>
      <description>설명 $$ \begin{cases} u_{tt} = c^2 u_{xx} \\ u(0,x) = f(x) \\ u_{t}(0,x) = g(x) \\ \end{cases} $$ 위 방정식은 파동 방정식에서 길이가 $l$ 인 $1$차원 공간 상의 디리클레 경계조건 $$ \begin{cases} u(t,0) = \alpha(t) \\ u(t,l) = \beta (t) \end{cases} $$ 이 $\alpha = \beta = 0$ 으로 주어지고 파형에 대한 초기 조건이 있는 경우다. 이러한 문제 유형 중에는 가장 쉽고 단순한 형태다. 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간 $t$일 때 $x$</description>
    </item>
    
    <item>
      <title>파동방정식에 대한 코시 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-cauchy-problem-for-wave-equation/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-cauchy-problem-for-wave-equation/</guid>
      <description>설명 $$ \begin{cases} u_{tt} = c^2 u_{xx} \\ u(0,x) = f(x) \\ u_{t}(0,x) = g(x) \end{cases} $$ 위 식은 다음과 같은 파동 방정식 $$ \rho (x) {{\partial^2 u} \over {\partial t^2}} = {{ \partial } \over {\partial x}} \left( \kappa (x) {{ \partial u } \over { \partial x }} \right) $$ 에서 밀도density $\rho (x) &amp;gt; 0$ 와 강도stiffness $\kappa (x) &amp;gt; 0$ 가 모두 상수인 경우로써 $\displaystyle c : = {{\kappa} \over {\rho}}$ 를 파속wave speed이라 한다. 여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때의 파형을 나</description>
    </item>
    
    <item>
      <title>디리클레 경계 조건이 주어진 열방정식에 대한 초기값 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-heat-equation-for-given-dirichlet-boundary-condition/</link>
      <pubDate>Mon, 18 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-initial-value-problem-for-heat-equation-for-given-dirichlet-boundary-condition/</guid>
      <description>설명 $$ \begin{cases} u_{t} = \gamma u_{xx} \\ u(t,0) = u(t,l) = 0 \\ u(0,x) = f(x) \end{cases} $$ 위 방정식은 열방정식에서 길이가 $l$ 인 $1$차원 공간 상의 디리클레 경계조건 $$ \begin{cases} u(t,0) = \alpha(t) \\ u(t,l) = \beta (t) \end{cases} $$ 이 $\alpha = \beta = 0$으로 주어지고 열분포에 대한 초기 조건이 있는 경우다. 이러한 문제 유형 중에는 가장 쉽고 단순한 형태다. 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간 $t$일 때 열</description>
    </item>
    
    <item>
      <title>열방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-heat-equation/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-heat-equation/</guid>
      <description>설명 $$ u_{t} = \gamma u_{xx} $$ 위 식은 다음의 일반화된 열방정식 $$ {{\partial} \over {\partial t}} \left( \sigma (x) u \right) = {{\partial} \over {\partial x }} \left( \kappa (x) {{\partial u} \over {\partial x}} \right) $$ 에서 열전도율thermal conductivity $\kappa (x) &amp;gt; 0$ 와 열용량heat capacity $\sigma(x) &amp;gt; 0$ 이 모두 상수인 경우로써 $\displaystyle \gamma : = {{\kappa} \over {\sigma}}$ 을 열확산율thermal diffusivity이라 한다. 여기서 $t$ 는 시간, $x$ 는 위치, $u(t,x)$ 는 시간 $t$ 일 때 열의 분포를 나타</description>
    </item>
    
    <item>
      <title>편미분 방정식 풀이를 위한 푸리에 급수</title>
      <link>https://freshrimpsushi.github.io/posts/fourier-series/</link>
      <pubDate>Sat, 16 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fourier-series/</guid>
      <description>정의 힐베르트 공간의 함수 $f \in \mathcal{L}^{2} [- \pi , \pi] $ 에 대해 $\displaystyle a_{k} = {{1} \over {\pi}} \int_{- \pi}^{\pi} f(x) \cos kx dx$ 그리고 $\displaystyle b_{k} = {{1} \over {\pi}} \int_{- \pi}^{\pi} f(x) \sin kx dx$ 에 대해 $$ f(x) \sim {{a_{0}} \over {2}} + \sum_{k=1}^{\infty} \left( a_{k} \cos kx + b_{x} \sin kx \right) $$ 를 $f$ 의 푸리에 급수Fourier series라 한다. 설명 테일러 급수가 어떤 함수를 다항식으로 근사시키는 것과 달리 푸리에 급수는 삼각다항식으로 근사시킨다. 이렇듯 복잡한 모양을</description>
    </item>
    
    <item>
      <title>R 에서 여러가지 분포함수</title>
      <link>https://freshrimpsushi.github.io/posts/random-number-generate-in-r/</link>
      <pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-number-generate-in-r/</guid>
      <description>설명 R 에서 특정 분포에 대한 함수들은 다음과 같은 접두어와 접미어의 조합으로 만들어진다. 접두 확률분포 $X$ 의 확률분포함수를 $f(x)$ 라고 하자. r-:랜덤 추출, 확률분포 $X$ 에서 나온 $x_{1}, \cdots , x_{n}$ 을 생각하면 좋다. d-: 분포함수, $f(x)$ p-: 누적분포함수, $F(x) = \displaystyle \int_{\infty}^{x} f(t) dt$ q-: 분위수함수, $F^{-1}(\alpha)$ 접미 이름이 알려진 분포는 거의 다 있지만 특히 자주 쓰는 분포는 아래와 같다.</description>
    </item>
    
    <item>
      <title>버거스 방정식에 대한 리만 문제의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-riemann-problem-for-burgers-equation/</link>
      <pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-riemann-problem-for-burgers-equation/</guid>
      <description>설명 $$ \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = \begin{cases} a &amp;amp; ,x&amp;lt;0 \\ b &amp;amp; ,x&amp;gt;0 \end{cases} &amp;amp; , t=0 \end{cases} $$ 리만 문제란 초기값이 주어진 버거스 방정식 중에서도 그 해를 계단 함수step function 로 갖는 경우를 말한다. 이 때 $a \ne b$ 면 그냥 구한 해의 함숫값이 특정 구간에서 여러개 존재하거나 아예 존재하지 않거나 하게 된다. 따라서 등적률을 적용시키거나 평활화smoothing 된 해를 구한다.</description>
    </item>
    
    <item>
      <title>R 에서 올림, 내림, 반올림, 자릿수 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-round-numbers/</link>
      <pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-round-numbers/</guid>
      <description>개요 ceiling() 함수는 올림 처리를, floor() 함수는 내림 처리를 해준다. 이런 함수들은 주로 통계를 다루는 R 에서는 필요 없어 보이지만 의외로 데이터 핸들링을 할 때 써먹기가 편하다. 설명 trunc() 함수는 소수점 아래를 모두 버려주는 건 똑같지만 $0$ 에 더 가까운 쪽으로 값을 반환해준다. round() 함수와 signif() 함수 모두 자리수를 남기지만 round()는 소수점 아래를, signif(</description>
    </item>
    
    <item>
      <title>볼자노-바이어슈트라스 성질과 집적점 컴팩트</title>
      <link>https://freshrimpsushi.github.io/posts/bolzano-weierstrass-property-and-limit-point-compact/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bolzano-weierstrass-property-and-limit-point-compact/</guid>
      <description>정의 1 위상공간 $X$ 의 모든 무한 부분집합의 집적점이 $X$ 에 속하면 $X$ 가 볼자노-바이어슈트라스 성질을 가진다고 하거나 집적점 컴팩트라 한다. 정리 [1]: 모든 컴팩트 공간은 집적점 컴팩트 공간이다. [2]: $X$ 가 거리 공간이면 $X$ 가 컴팩트인 것과 집적점 컴팩트인 것은 서로 동치다. 설명 예를 들어 $[a,b]$ 는 집적점 컴팩트지만 $(a,b)$ 는 집적점 컴팩트가 아니다. 또한 $\mathbb{Q}$ 는 $$ P =</description>
    </item>
    
    <item>
      <title>가산 컴팩트와 린델뢰프</title>
      <link>https://freshrimpsushi.github.io/posts/countably-compact-and-lindeloef/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/countably-compact-and-lindeloef/</guid>
      <description>정의 1 $X$ 의 모든 가산 열린 커버가 유한 부분 커버를 가지면 $X$ 를 가산 컴팩트Countably Compact라 한다. $X$ 의 모든 열린 커버가 가산 부분 커버를 가지면 $X$ 를 린델뢰프Lindelöf라 한다. 정리 가산 컴팩트 [1-1]: 모든 컴팩트 공간은 가산 컴팩트 공간이다. [1-2]: 가산 컴팩트성는 위상적 성질이다. 린델뢰프 [2-1]: 제2가산 공간은 린델뢰프 공간이다</description>
    </item>
    
    <item>
      <title>리만적분의 일반화로써의 르벡적분</title>
      <link>https://freshrimpsushi.github.io/posts/lbesgue-integral-generalized-riemann-integral/</link>
      <pubDate>Wed, 30 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lbesgue-integral-generalized-riemann-integral/</guid>
      <description>정리 1 유계 함수 $f : [a,b] \to \mathbb{R}$ 와 $g : \mathbb{R} \to [0,\infty)$ 이라고 하자. [1]: $f$ 가 $[a,b]$ 에서 리만 적분가능한 것은 $f$ 가 르벡 측도에 대해 $[a,b]$ 의 거의 어디에서나 연속인 것과 동치다. [2]: $\displaystyle \int_{a}^{b} f(x) dx$ 가 존재하면 $\displaystyle \int_{a}^{b} f(x) dx = \int_{[a,b]} f dm$ [3]: $\displaystyle \int_{-\infty}^{\infty} g(x) dx$ 가 존재하면 $\displaystyle \int_{-\infty}^{\infty} g(x) dx = \int_{\mathbb{R}} g dm$ 설명 측도에 대한 그 수많은 논의는 모두 이 &amp;lsquo;적분의 일반화&amp;rsquo;를 위한 것으로 보아도 무방</description>
    </item>
    
    <item>
      <title>파이썬으로 웹 문서 크롤링하고 태그 제거하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-crawl-web-site-and-remove-html-tag-using-python/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-crawl-web-site-and-remove-html-tag-using-python/</guid>
      <description>개요 파이썬은 크롤링을 위한 패키지가 잘 갖춰져있어 쉽게 따라할 수 있다. 웹 페이지를 읽어들이고 html 태그를 제거해보자. 예제 코드 import requests from bs4 import BeautifulSoup import re rq = requests.get(&amp;#34;https://ko.wikipedia.org/wiki/%EC%98%A4%EB%A7%88%EC%9D%B4%EA%B1%B8&amp;#34;) rqctnt = rq.content soup = BeautifulSoup(rqctnt,&amp;#34;html.parser&amp;#34;) OMG = str(soup.find\_all(&amp;#34;p&amp;#34;)) OMG = re.sub(&amp;#39;&amp;lt;.+?&amp;gt;&amp;#39;, &amp;#39;&amp;#39;, OMG, 0).strip() 결과 예제로 위키피디아에서 오마이걸 항목을 읽어와보도록 하자. 필요한 패키지는 보이는대로 requests와 bs4가 있다. 읽어들이기만 하고 출력해보면</description>
    </item>
    
    <item>
      <title>오류행렬과 민감도, 특이도</title>
      <link>https://freshrimpsushi.github.io/posts/sensitivity-specipicity-and-confusion-matrix/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sensitivity-specipicity-and-confusion-matrix/</guid>
      <description>오류행렬 분류 문제에서 모형을 평가하는 지표로써 위와 같은 오류행렬Confusion Matrix을 참고할 수 있다. 정분류율Accuracy $$ \text{Accuracy} = {{TP + TN} \over { P + N }} $$ 위 표에서 P는 양성, N은 음성을 나타낸다. TP는 양성으로 예측되었고 실제로 양성인 경우, TN은 음성으로 예측되었고 실제로 음성인 경우다. 이 TP와 TN이 상대적으</description>
    </item>
    
    <item>
      <title>균등연속 정리</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-continuous-in-topology/</link>
      <pubDate>Sun, 27 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-continuous-in-topology/</guid>
      <description>정의 거리공간 $(X, d)$ 와 $(Y, d&amp;rsquo;)$ 에 대해 $f : X \to Y$ 라고 하자. 모든 $\varepsilon &amp;gt; 0$ 와 $x_{1}, x_{2} \in X$ 에 대해 $$ d(x_{1}, x_{2}) &amp;lt; \delta \implies d&amp;rsquo;( f( x_{1} ) , f( x_{2} ) ) &amp;lt; \varepsilon $$ 을 만족하는 $\delta &amp;gt; 0$ 가 존재하면 $f$ 를 균등연속Uniformly Continuous이라 한다. 설명 해석학에서 배운 연속의 개념이 위상수학에서 일반화되었듯 균등연속 역시 위상수학에서 일반화가 가능하다. 단 여기서</description>
    </item>
    
    <item>
      <title>랜킨-위고니오 조건과 엔트로피 조건</title>
      <link>https://freshrimpsushi.github.io/posts/rankine-hugoniot-condition-and-entropy-condition/</link>
      <pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rankine-hugoniot-condition-and-entropy-condition/</guid>
      <description>정의 $$ \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 위 비점성 버거스 방정식의 해가 $u$고 그 파열 시간이 $t_{\ast}$ 라고 하자. 비점성 버거스 방정식의 해가 파열할 때, 위와 같이 왼쪽과 오른쪽의 넓이가 같아지도록 하는 선분으로 이어준다. 이렇게 물리적으로 해석할 수 있도록 해를 조정하는 것을 등적률等積律equal area rule이라 한다. 설명 이렇게 생기는</description>
    </item>
    
    <item>
      <title>R 에서 문자열 다루기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-handle-strings-in-r/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-handle-strings-in-r/</guid>
      <description>개요 개발자들이 많이 사용하는 언어들에 비교하면 그 정도가 덜하지만, R 에서도 문자열을 다룰 일이 생각보다 많다. 데이터가 방대하고 제멋대로일수록 이런 사소한 테크닉들이 엄청나게 중요해진다. 팁 nchar() 함수는 단순히 문자열의 길이를 반환한다. 다른 언어를 먼저 접한 사람은 아마 십중팔구 length를 먼저 쳐봤을 것이다. substring() 함수는 그 이름에서 쉽게 짐</description>
    </item>
    
    <item>
      <title>정수론에서의 시그마 함수</title>
      <link>https://freshrimpsushi.github.io/posts/sigma-function-in-number-theory/</link>
      <pubDate>Thu, 24 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sigma-function-in-number-theory/</guid>
      <description>정리 $\displaystyle \sigma (n) : = \sum_{d \mid n} d$ 에 대해 다음이 성립한다. [1]: 소수 $p$ 에 대해 $$\sigma( p^k ) = {{p^{k+1} - 1} \over {p-1}}$$ [2]: $\gcd (n , m ) = 1$ 이면 $$\sigma(nm) = \sigma(n) \sigma(m)$$ 설명 시그마 함수는 쉽게 말해 약수의 합으로, $6$ 을 예로 들자면 $\sigma(6) = 1 + 2 + 3 + 6 = 12$ 이다. 해석적 정수론에서는 디바이저 함수로 일반화된다. 한편 시그마 함수를 언급함으로써 완전수Perfect Number를 깔끔하게 정</description>
    </item>
    
    <item>
      <title>비점성 버거스 방정식에서의 질량 보존 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/law-of-conservation-of-mass-in-inviscid-burgers-equation/</link>
      <pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/law-of-conservation-of-mass-in-inviscid-burgers-equation/</guid>
      <description>정리 $$ \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 위의 비점성 버거스 방정식의 해 $u$에 대해 구간 $[a,b]$까지의 선질량 $M$ 을 다음과 같이 정의하자. $$ M_{a,b}(t) := \int_{a}^{b} u(t,x) dx $$ 그리고 파열시간을 $t_{\ast}$이라고 하면 $t \in ( 0 , t_{\ast})$에 대해 다음이 성립한다. $$ {{d} \over {dt}} M_{a,b}(t) = - \left( {{1} \over {2}} u^2 (t,b) - {{1} \over {2}} u^2 (t,a) \right) $$ 설명 파열 시</description>
    </item>
    
    <item>
      <title>측도론에서의 레비의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-levis-theorem-in-measure-theory/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-levis-theorem-in-measure-theory/</guid>
      <description>정리 1 $\displaystyle \sum_{k=1}^{\infty} \int |f_{k}| dm &amp;lt; \infty$ 면 $\displaystyle \sum_{k=1}^{\infty} f_{k} (x)$ 는 거의 어디에서나 수렴하고 $$ \int \sum_{k=1}^{\infty} f_{k} dm = \sum_{k=1}^{\infty} \int f_{k} dm $$ 증명 $\displaystyle \phi (x) := \sum_{k=1}^{\infty} | f_{k} (x) |$ 이라고 정의하면 $\phi$ 는 음이 아닌 가측 함수다. 단조 수렴 정리의 따름 정리: $$\int \sum_{n=1}^{\infty} f_{n} dm = \sum_{n=1}^{\infty} \int f_{n} dm$$ 단조 수렴 정리에 의해 $\displaystyle \int \phi dm = \sum_{n=1}^{\infty} \int | f_{k} | dm$ 인데 가정에서 $\displaystyle \sum_{k=1}^{\infty} \int |f_{k}| dm &amp;lt; \infty$ 이었으므로 $\phi$ 는 적분가능하다. 따라서 $\phi$ 는 거의 어디서나 유한하</description>
    </item>
    
    <item>
      <title>위상공간에서 최대최소값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-maximum-and-minimum-value-theorem-in-topological-space/</link>
      <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-maximum-and-minimum-value-theorem-in-topological-space/</guid>
      <description>정리 1 컴팩트 공간 $X$ 에 대해 함수 $f : X \to \mathbb{R}$ 가 연속이면 모든 $x \in X$ 에 대해 $f(c) \le f(x) \le f(d)$ 을 만족하는 $c,d \in X$ 가 존재한다. 설명 $\mathbb{R}$ 에서 컴팩트란 폐구간 $[a,b]$ 인 것과 동치이므로 결국 우리가 고등학교, 해석학 때 배운 정리의 일반화가 된다. 위상수학의 어려운 이론들을 사용하는만큼 증명은 오히려 간단하고 쉽다. 증명 컴팩트 공간에 대한 보조정리: $f : X \to Y$ 에</description>
    </item>
    
    <item>
      <title>컴팩트 공간과 연속함수에 대한 유용한 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/useful-properties-of-compact-space-and-continuous-function/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/useful-properties-of-compact-space-and-continuous-function/</guid>
      <description>정리 $f : X \to Y$ 에 대해 $X$ 가 컴팩트, $f$ 가 연속이라고 하자. [1]: $f$ 가 전사면 $Y$ 는 컴팩트다. $f$ 가 전사가 아니더라도 $f(X)$ 는 컴팩트다. [2]: $Y$ 가 하우스도르프면 $f$ 는 닫힌 함수다. 닫힌 집합 $C \subset X$ 에 대해 $f(C) \subset Y$ 는 닫힌 집합이다. [3]: $f$ 가 전단사고 $Y$ 가 하우스도르프면 $f$ 는 위상동형사상이다. [4]: $X$ 가 거리공간이면 $f$ 는 균등연속이다. 설명 별 시덥잖은 성질이</description>
    </item>
    
    <item>
      <title>지프의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/zipfs-law/</link>
      <pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/zipfs-law/</guid>
      <description>법칙 코퍼스에서 $k$ 번째로 자주 나타나는 단어의 상대빈도를 $f_{k}$ 라고 하면 $$ f_{k} = {{C} \over {k}} $$ 설명 여기서 $C$ 는 $\displaystyle \sum_{k} f_{k} = 1$ 이 되도록하는 정규화계수다. 히스토그램으로 나타내보면 대략 위와 같은 모양이되 넓이의 합이 정확하게 $1$ 이 되도록 스케일을 조정해준 것이다. 오른쪽에 생기는 두꺼운 꼬리 모양을 롱테일이라고 부른다. 힙스의 법칙과 마찬가지로 경험적으</description>
    </item>
    
    <item>
      <title>힙스의 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/heaps-law/</link>
      <pubDate>Fri, 18 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heaps-law/</guid>
      <description>법칙 코퍼스에서 어휘의 갯수를 $M$, 토큰의 갯수를 $T$ 라고 하면 $$ M = kT^{b} $$ 설명 코퍼스가 영어일 경우 보통 상수 $k,b$ 는 $10 \le k \le 100$, 그리고 $b = 0.5$ 정도로 나타난다고 한다. 힙스의 법칙은 수학적인 근거를 두고 유도된 것이 아니라 경험적으로 얻어진 법칙이다. 수식은 언뜻 굉장히 복잡해 보이지만 양변에 로그를 취하면 $\log M = \log k + b \log T$ 가 되고, 다음과 같이 선형적</description>
    </item>
    
    <item>
      <title>R 에서 부트스트랩 함수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-boot-in-r/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-boot-in-r/</guid>
      <description>개요 R 에서 부트스트랩을 시행하는 코드를 직접 짜볼 수도 있지만, 기본적으로 제공되는 함수를 이용할 수도 있다. 그 과정은 아래와 같이 단순하지만 다른 함수들과 사용법에 다른 점이 많아서 처음엔 많이 낯설 것이다. 가이드 Step 1. 구하고 싶은 통계량을 반환하는 함수 boot.fn()을 정의한다.당연히 여기서 함수의 이름은 어찌되든 상관 없다. 이때 인수</description>
    </item>
    
    <item>
      <title>지배 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-dominated-convergence-theorem/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-dominated-convergence-theorem/</guid>
      <description>정리 1 가측집합 $E \in \mathcal{M}$ 와 $g \in \mathcal{L}^{1} (E)$ 에 대해 가측함수열 $\left\{ f_{n} \right\}$ 이 $E$ 의 거의 어디서나 $|f_{n}| \le g$ 를 만족한다고 하자. 만약 $E$ 의 거의 어디서나 $\displaystyle f = \lim_{n \to \infty} f_{n}$ 이면, $f \in \mathcal{L}^{1}(E)$ 이고 $$ \lim_{ n \to \infty} \int_{E} f_{n} (x) dm = \int_{E} f dm $$ $f,g \in \mathcal{L}^{1} (E)$ 는 $f$ 와 $g$ 가 르벡 적분가능 함수임을 의미한다. 설명 단조 수렴 정리와 비교해보자면 $f_{n} \nearrow f$ 라는 조건이 빠졌고 심지어 $f_{n} \ge 0$ 일 필요도 없어졌다</description>
    </item>
    
    <item>
      <title>메르센 소수</title>
      <link>https://freshrimpsushi.github.io/posts/mersenne-prime/</link>
      <pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mersenne-prime/</guid>
      <description>정의 1 $M_{n} = 2^{n} - 1$ 가 소수면 $M_{n}$ 를 메르센 소수Mersenne Prime라 한다. 설명 메르센 소수의 발견은 $p=x^{n}-1$ 꼴이 소수인지에 대한 탐구로부터 시작된다. 수식을 보자마자 단박에 알아챌 수 있는 것은 $x$ 가 홀수인 경우 $p=2$ 를 제외하면 소수가 될 수 없다는 것이다. 또한 $$ x^{n}-1 = (x-1) ( x^{n-1} + x^{n-2} + \cdots + x^2 + x + 1 ) $$ 이므로, $( x^{n-1} + x^{n-2} + \cdots + x^2 + x + 1 )$ 이 무슨</description>
    </item>
    
    <item>
      <title>몬테카를로 방법과 부트스트랩의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/difference-between-monte-carlo-method-and-bootstrap/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-between-monte-carlo-method-and-bootstrap/</guid>
      <description>개요 몬테카를로 방법은 작위적인 데이터로 시뮬레이션을 반복해 새로운 기법을 확인하는 방법이고 부트스트랩은 실제 데이터에서 재표본 추출을 통해 비용을 절감하며 문제를 해결하려는 방법이다. 정의 몬테카를로 방법Monte Carlo Method이란 난수 추출을 통해 관심 있는 대상에 대해 점추정량을 찾는 방법이다. 부트스트랩Bootstrap이란 표</description>
    </item>
    
    <item>
      <title>계획행렬</title>
      <link>https://freshrimpsushi.github.io/posts/design-matrix/</link>
      <pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/design-matrix/</guid>
      <description>빌드업 R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 고작 여섯개지만, 척 봐도 eruptions와 waiting은 양의 상관관계를 가지고 있는 것으로 보인다. 만약 이들의 관계를 어떤 두 상수 $\beta_{0}, \beta_{1}$ 에 대해 $$\text{(eruptions)} = \beta_{0} + \beta_{1} \cdot \text{( waiting) }$$ 으로 나타낼 수 있다면 좋을 것이다. 위 식은 두 변수의 선형관계를 직선의 방정식으로써 나타낸 것</description>
    </item>
    
    <item>
      <title>르벡 적분가능</title>
      <link>https://freshrimpsushi.github.io/posts/lesbegue-integrable/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lesbegue-integrable/</guid>
      <description>정의 1 $E \in \mathcal{M}$ 이라고 할 때 가측함수 $f$ 에 대해 $$f^{+} := \max \left\{ f , 0 \right\} \\ f^{-} := \max \left\{ -f , 0 \right\}$$ 라고 하자. 그러면 $$ f = f^{+} - f^{-} \\ | f | = f^{+} + f^{-} $$ 으로 나타낼 수 있다. 만약 $\displaystyle \int_{E} | f | dm &amp;lt; \infty$, 즉 $$ \int_{E} f^{+} dm &amp;lt; \infty \\ \int_{E} f^{-} dm &amp;lt; \infty $$ 이면 $f$ 를 르벡 적분가능Lesbegue Integrable이라 한다. $E$ 에서 적분가능한 함수들의 집합을 다음과 같이 나타낸다.</description>
    </item>
    
    <item>
      <title>회귀분석이란?</title>
      <link>https://freshrimpsushi.github.io/posts/regression-analysis/</link>
      <pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regression-analysis/</guid>
      <description>설명 회귀분석은 거의 모든 통계적 기법의 근간이 되는만큼 너무 일반적이거나 너무 특수하게 설명된 경우가 많다. 그냥 회귀분석이 어떤건지 궁금한 사람에게 한마디로 설명한다면 변수 사이의 관계를 알아내는 방법이라고 할 수 있겠다. 이 유용하고도 놀라운 분석법은 우생학을 만들어낸 프랜시스 골턴Francis Galton의 아이디어에서 태어났다. 골</description>
    </item>
    
    <item>
      <title>포물선의 초점을 지나는 직선이 가지는 성질</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-straight-lines-passing-through-the-focus-of-parabolic-lines/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-straight-lines-passing-through-the-focus-of-parabolic-lines/</guid>
      <description>정리 포물선 $y^2 = 4px$ 에 대해 초점 $P(p,0)$ 을 지나는 직선이 포물선과 만나는 두 점을 각각 $A, B$ 라고 하면 $$ {{1} \over {\overline{PA}} } + {{1} \over {\overline{PB}} } = {{1} \over {p}} $$ 증명 경우 1. $a=b$ 초점을 지나는 직선이 $x = p$ 인 경우다. $\overline{PA} = \overline{PB} = 2p$ 이므로 $$ {{1} \over {\overline{PA}} } + {{1} \over {\overline{PB}} } = {{1} \over {2p}} + {{1} \over {2p}}= {{1} \over {p}} $$ 경우 2. $b \ne a$ 일반성을 잃지 않고, $b&amp;gt;a$ 인 경우만 증명하면 충분하다. $A,B$ 에서 준선으로 내린 선분을 잘 보</description>
    </item>
    
    <item>
      <title>표본표준편차와 표준오차의 구분</title>
      <link>https://freshrimpsushi.github.io/posts/how-different-between-sample-standard-deviation-and-standard-error/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-different-between-sample-standard-deviation-and-standard-error/</guid>
      <description>정의 $X$ 로부터 얻은 데이터를 $\mathbb{x} = ( x_{1}, x_{2}, \cdots , x_{n} )$ 라고 하자. 표본평균: $$ \overline{x} = {{1} \over {n}} \sum_{i=1}^{n} x_{i} $$ 표본표준편차: $$ s_{x} = \sqrt { {{1} \over {n-1}} \sum_{i=1}^{n} ( x_{i} - \overline{x} )^2 } $$ 표준오차: $$ \text{s.e.}( \hat{x} ) = {{ s_{x} } \over { \sqrt{n} }} $$ 설명 말이 비슷해서인지 의외로 많은 사람들이 표본표준편차와 표준오차를 구분하지 못한다. 사실상 통계를 글로만 배우는 고등학생들은 물론이고 심하게는 통계학과</description>
    </item>
    
    <item>
      <title>R 에서 멱함수 그래프 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-power-function-in-r/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-power-function-in-r/</guid>
      <description>개요 간단하게 일변량 함수의 그래프를 그리는 법을 소개한다. 통계학에서 적절한 예로써 멱함수를 그려보자. 정의 귀무가설 $H_{0} : \theta \in \Theta_{0}$ 과 대립가설 $H_{1} : \theta \in \Theta_{1}$ 에 대해 유의수준 $\alpha$ 의 기각역을 $C_{\alpha}$ 라고 하자. 참값 $\theta$ 에 대한 함수 $\gamma_{C_{\alpha}}(\theta) : = P_{\theta} [ \mathbb{x} \in C_{\alpha} ]$ 를 멱함수Power Function라 한다. 설명 다른 표현으로는 $\gamma_{C_{\alpha}}(\theta) : = 1 - P_{\theta}[\text{Type 2 Error}]$ 이다. 유의확률과 마</description>
    </item>
    
    <item>
      <title>p값 혹은 유의확률에 대한 흔한 오개념들</title>
      <link>https://freshrimpsushi.github.io/posts/significance-probability-p-value/</link>
      <pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/significance-probability-p-value/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 요약 : p-value가 아주 작다는 것은 그만큼 드문 일이라는 뜻으로, 단순한 우연으론 보기 어려우며 대립가설을 기각하기 어려움을 의미한다. 가설검정에서 검정통계량이 귀무가설을 기각하도록 나타날 확률로써 귀무가설을 기각하게 되는 최소의 유의수준을 유의확률Significance Probability</description>
    </item>
    
    <item>
      <title>상관관계가 없다고 독립인 것은 아니다</title>
      <link>https://freshrimpsushi.github.io/posts/no-correlation-implies-no-independency/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/no-correlation-implies-no-independency/</guid>
      <description>설명 독립이면 상관관계가 없지만, 상관관계가 없다고 독립인 것은 아니다. 상관관계가 없을 때 독립인 경우, 즉 필요충분조건이 되는 경우는 확률변수가 정규분포를 따를 때다. 왼쪽의 경우에 양의 상관관계, 오른쪽의 경우에 음의 상관관계가 있다고 한다. 그림의 cor는 상관계수로써, 두 변수가 얼마나 선형적인 관계를 가지는지를 나타내는 지표다. 독립</description>
    </item>
    
    <item>
      <title>단조 수렴 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-monotone-convergence-theorem/</link>
      <pubDate>Sun, 06 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-monotone-convergence-theorem/</guid>
      <description>정리 1 함숫값이 음이 아닌 가측 함수의 수열 $\left\{ f_{n} \right\}$ 이 $f_{n} \nearrow f$ 을 만족한다고 하자. 그러면 $$ \lim_{n \to \infty} \int_{E} f_{n} dm = \int_{E} f dm $$ 설명 $f_{n} \nearrow f$ 이란 모든 $x$ 에 대해 $f_{n}(x) \le f_{n+1} (x)$ 이면서 $\displaystyle \lim_{n \to \infty} f_{n} = f$ 인 것이다. 수식은 너무 쉽기 때문에 이 정리를 안다는 것은 &amp;lsquo;조건&amp;rsquo;을 정확하게 안다는 말이다. 유용성으로 따질 것 같으면 극한이 적분을 마음대로 드</description>
    </item>
    
    <item>
      <title>파투의 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fatous-lemma/</link>
      <pubDate>Sat, 05 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fatous-lemma/</guid>
      <description>정리 1 함숫값이 음이 아닌 가측 함수의 수열 $\left\{ f_{n} \right\}$ 에 대해 $$ \int_{E} \left( \liminf_{n \to \infty} f_{n} \right) dm \le \liminf_{n \to \infty} \int_{E} f_{n} dm $$ 설명 실해석에서의 단조 수렴 정리와 지배 수렴 정리를 증명하기 위해 필요한 보조정리다. 가측 함수라는 조건이 빠진 급수에 대한 파투 보조정리는 다음과 같다. 함숫값이 음이 아닌 함수의 수열 $\left\{ f_{k} : \mathbb{N} \to [0, \infty) \right\}_{k \in \mathbb{N}}$ 에 대해 $$ \sum_{j=1}^{\infty} \liminf_{k \to \infty} f_{k} (j) \le \liminf_{k \to \infty} \sum_{j=1}^{\infty} f_{k} (j) \qquad , \forall</description>
    </item>
    
    <item>
      <title>비점성 버거스 방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-inviscid-burgers-equation/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-inviscid-burgers-equation/</guid>
      <description>정의 다음의 준선형 편미분방정식을 버거스 방정식Burgers&amp;rsquo; equation이라 한다. $$ \begin{cases} u_{t} + u u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간 $t$일 때 $x$에서의 파형을 나타낸다. $f$는 초기 조건으로써 특히 $t=0$일 때의 파형을 나타낸다. 설명 버거스 방</description>
    </item>
    
    <item>
      <title>비균일 진행파 편미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-nonuniform-traveling-wave-partial-differential-equation/</link>
      <pubDate>Thu, 03 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-nonuniform-traveling-wave-partial-differential-equation/</guid>
      <description>정의 다음의 식을 만족하는 $u$를 비균일 진행파non-uiform traveling wave라고 한다. $$ \begin{cases} u_{t} + c(x) u_{x} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간 $t$일 때 $x$에서의 파형을 나타낸다. $f$는 초기 조건으로써 특히 $t=0$일 때의 파형을 나타낸다. 함수 $c(x)$는 파동의 진</description>
    </item>
    
    <item>
      <title>균일 진행파 편미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-uniform-traveling-wave-partial-differential-equation/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-uniform-traveling-wave-partial-differential-equation/</guid>
      <description>정의 다음의 식을 만족하는 $u$를 균일 진행파uniform traveling wave라고 한다. $$ \begin{cases} u_{t} + c u_{x} + a u = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간 $t$일 때 $x$에서의 파형을 나타낸다. $f$는 초기 조건으로써 특히 $t=0$일 때의 파형을 나타낸다. 상수 $c$ 는 파동의 진행 속도를 나타</description>
    </item>
    
    <item>
      <title>정상파 편미분방정식의 풀이</title>
      <link>https://freshrimpsushi.github.io/posts/solution-of-stationary-wave-partial-differential-equation/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/solution-of-stationary-wave-partial-differential-equation/</guid>
      <description>정의 다음의 조건을 만족하는 $u$를 정상파stationary wave라고 한다. $$ \begin{cases} u_{t} = 0 &amp;amp; , t&amp;gt;0 \\ u(t,x) = f(x) &amp;amp; , t=0 \end{cases} $$ 설명 정상파는 시간이 흘러도 모양이 변하지 않는 파동이다. 여기서 $t$는 시간, $x$는 위치, $u(t,x)$는 시간이 $t$일 때 $x$에서의 파형을 나타낸다. $f$는 초기 조건으로써 특히 $t=0$일 때의 파</description>
    </item>
    
    <item>
      <title>R 에서 자리수 출력 제한 없애기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-unlimit-digits-and-print-in-r/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-unlimit-digits-and-print-in-r/</guid>
      <description>개요 R 이 통계학을 위한 언어긴하지만 막상 R 콘솔은 데이터를 보는데 적합하지 않다. 그럼에도 불구하고 관측치가 수십만개에 달하는 빅데이터를 다룰 때나 핸들링이 잘 되었나 확인할 땐 단순 출력이 편하다. 팁 관측치가 조금 많을 때 콘솔로 출력해보면 위와 같이 아랫부분이 뭉텅 잘려나온다. 이럴 땐 콘솔창에 options(max.print = .Machine$integer.max</description>
    </item>
    
    <item>
      <title>르벡 적분</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-integral/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-integral/</guid>
      <description>빌드업 리만 적분의 일반화를 생각하기 이전에 단순 함수Simple Function라는 것을 정의할 필요가 있다. 함숫값이 음이 아닌 $\phi : \mathbb{R} \to \mathbb{R}$ 의 치역이 유한 집합 $\left\{ a_{1} , a_{2}, \cdots , a_{n} \right\}$ 이라고 하자. $A_{i} = \phi^{-1} \left( \left\{ a_{i} \right\} \right) \in \mathcal{M}$ 을 만족하면 $\phi$ 를 단순 함수라 한다. 단순 함수는 다음 성질들을 가진다. (i): $i \ne j$ 면 $A_{i } \cap A_{j} = \emptyset$ (ii): $\displaystyle \bigsqcup_{k=1}^{n} A_{k} = \mathbb{R}$ (iii): $\displaystyle \phi(x) = \sum_{k=1}^{n} a_{k} \mathbb{1}_{A_{k}}(x)$ 는</description>
    </item>
    
    <item>
      <title>R 에서 NA 제거하기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-delete-na-in-r/</link>
      <pubDate>Sun, 29 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-delete-na-in-r/</guid>
      <description>개요 NA는 Not Available의 약자로, R 프로그래밍에선 주로 &amp;lsquo;결측값&amp;rsquo;을 의미한다. 일반적인 프로그래밍 언어에서의 null과는 그 의미도 쓰임새도 전혀 다름에 주의하도록 하자. 교과서에서 다루는 예제들은 보통 분석하기에 알맞도록 잘 정리되어 있지만, 실제로 분석에 임할 땐 전혀 그렇지가 않다. 그런 데이터를</description>
    </item>
    
    <item>
      <title>n-그램과 자카드 계수</title>
      <link>https://freshrimpsushi.github.io/posts/n-gram-and-jaccard-coefficient/</link>
      <pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/n-gram-and-jaccard-coefficient/</guid>
      <description>정의 n-그램n-gram이란 어떠한 문자열을 n개씩 끊어서 자른 것을 말한다. 자카드 계수Jaccard Coefficient란 두 집합이 얼마나 비슷한지에 대한 척도로써 $0$ 부터 $1$ 사이의 값을 가진다. 수식으로 표현하면 다음과 같다. $$ JC(A,B) = {{| A \cap B|} \over {| A \cup B| }} = {{| A \cap B|} \over { |A|+ |B| -| A \cap B| }} $$ 예시 예를 들어 &amp;lsquo;오마이갓&amp;</description>
    </item>
    
    <item>
      <title>측도론에서의 거의 어디서나와 거의 확실히</title>
      <link>https://freshrimpsushi.github.io/posts/almost-everywhere-and-almost-surely-in-measure-theory/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/almost-everywhere-and-almost-surely-in-measure-theory/</guid>
      <description>정의 1 함수 $f : E \to \overline{\mathbb{R}}$ 가 $m(E_{0}) = 0$ 인 $E_{0} \subset E$ 을 제외하고 어떤 성질 $P$ 를 가질 때, $f$ 는 $E$ 의 거의 어디서나 $P$ 를 가진다고 한다. 표기 확률을 이야기 할 때 거의 어디서나Almost Everywhere는 거의 확실히Almost Surely 로 표현하며, 한국어만으로 표기하는 게 번거로울 때는 다음과 같이 약자를 써서 표현한다. $$ f = g \text{ a.e.} \\ P(E) = 0 \text{ a.s.} $$ 설명</description>
    </item>
    
    <item>
      <title>정수와 실수의 포맷 코드에 d, f를 쓰는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-format-codes-uses-d-f-for-integer-and-real-number/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-format-codes-uses-d-f-for-integer-and-real-number/</guid>
      <description>왜 하필 d와 f인가 1 C 나 파이썬 등에서 문자열의 입출력에 사용하는 포맷 코드로 %s, %c, %d, %f 등이 있다. 알다시피 %s 은 문자열String을 나타내고 %c 는 문자Character를 나타낸다. 그런데 이렇게 머릿글자에서 따온 것과 달리 정수, 실수를 쓸 땐 %i 와 %r 이 아닌 %d 와 %f 를 사용한다. 그 이유는 %d 가 그냥 정수가 아니라 10진법Decimal을,</description>
    </item>
    
    <item>
      <title>왜 &#39;음함수&#39;는 잘못된 번역인가?</title>
      <link>https://freshrimpsushi.github.io/posts/why-korean-translation-of-implicit-function-is-inappropriate/</link>
      <pubDate>Wed, 25 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-korean-translation-of-implicit-function-is-inappropriate/</guid>
      <description>정의 양함수냐 음함수냐의 차이는 그저 각각을 어떻게 표현했느냐에 지나지 않는다. 수학에서는 다소 생소한 표현이지만, 그 구분은 &amp;lsquo;독립변수&amp;rsquo;와 &amp;lsquo;종속변수&amp;rsquo;를 어떻게 나타내느냐에 달려있다. 간단히 말하자면 독립변수를 $x$, 종속변수를 그에 따라 달라지는 $y$ 로 두고 그 모양을 보는 것이다. 예시 예</description>
    </item>
    
    <item>
      <title>르벡 가측 함수</title>
      <link>https://freshrimpsushi.github.io/posts/lesbegue-measurable-function/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lesbegue-measurable-function/</guid>
      <description>정의 1 함수 $f: E \in \overline{ \mathbb{R} }$ 가 모든 구간 $I \subset \overline{ \mathbb{R} }$ 에 대해 $f^{-1} (I) = \left\{ x \in \mathbb{R} \ | \ f(x) \in I \right\} \in \mathcal{M}$ 이면 $f$ 를 (르벡) 가측(Lesbegue) Measurable이라 한다. 동치조건 아래의 명제들은 서로 동치다. (1): $f$ 가 르벡 가측 함수다. (2): $f^{-1} ( \emptyset ), f^{-1} ( \overline{\mathbb{R}} ) \in \mathcal{M}$ (3): $f^{-1} \left\{ \infty \right\} , f^{-1} \left\{ -\infty \right\} \in \mathcal{M}$ (4): 모든 $r \in \mathbb{R}$ 에 대해 $f^{-1} ( - \infty , r ], f^{-1} (r, \infty ), f^{-1} ( - \infty</description>
    </item>
    
    <item>
      <title>사건의 독립과 조건부 확률</title>
      <link>https://freshrimpsushi.github.io/posts/independent-conditional-probability-of-event/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independent-conditional-probability-of-event/</guid>
      <description>정의 1 확률 공간 $(\Omega , \mathcal{F} , P)$ 이 주어져 있다고 하자. $P(B)&amp;gt;0$ 에 대해 $\displaystyle P (A | B) = {{P(A \cap B)} \over {P(B)}}$ 를 $B$ 에 대한 $A$ 의 조건부 확률Conditional Probability이라고 한다. 만약 $P(A | B) = P(A)$, 즉 $P( A \cap B) = P(A) \cdot P(B)$ 면 $A, B$ 가 서로 독립Independent이라고 한다. 아직 측도론을 접하지 못했다면 확률 공간이라는 말은 무시해도 좋다. 설명 확</description>
    </item>
    
    <item>
      <title>컴팩트 하우스도르프 공간은 정규 공간이다</title>
      <link>https://freshrimpsushi.github.io/posts/compact-hausdorff-space-is-regular-space/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compact-hausdorff-space-is-regular-space/</guid>
      <description>정리 1 [1]: 컴팩트 공간의 닫힌 부분 집합은 컴팩트다. [2]: 하우스도르프 공간의 컴팩트 부분 집합은 닫힌 집합이다. [3]: 하우스도르프 공간 $X$ 의 두 컴팩트 부분 집합 $A,B \subset X$ 가 $A \cap B = \emptyset$ 이면 다음을 만족하는 열린 부분 집합 $U, V \subset X$ 가 존재한다. $$ A \subset U \\ B \subset V \\ U \cap V = \emptyset $$ [4]: 컴팩트 하우스도르프 공간은 정규 공간이다. 설명 정리 [1]과 [2]에서 하우</description>
    </item>
    
    <item>
      <title>기각역과 유의수준</title>
      <link>https://freshrimpsushi.github.io/posts/rejection-region-and-significance-probability/</link>
      <pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rejection-region-and-significance-probability/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 아무리 데이터가 산더미같이 쌓여있고 정교한 수학적 기법을 적용시켰다고 한들 써먹지 못하면 의미가 없다. 여기서 &amp;lsquo;쓴다&amp;rsquo;는 것은 어떤 데이터에 대해 통계를 내고 그 통계를 근거로 어떠한 &amp;lsquo;주장을 한다&amp;rsquo;는 것이다. 이를 위해선 당연히 그 통계가 믿</description>
    </item>
    
    <item>
      <title>제1종 오류와 제2종 오류의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/difference-between-type-1-error-and-type-2-error/</link>
      <pubDate>Sat, 07 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-between-type-1-error-and-type-2-error/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 귀무가설 $H_{0}$ 에 대해 $H_{0}$ 이 참인데 채택하지 않은 경우의 오류를 제1종 오류Type 1 Error , $H_{0}$ 이 거짓인데 채택한 경우의 오류를 제2종 오류Type 2 Error라 한다. 귀무가설에는 &amp;lsquo;채택&amp;rsquo;이라는 말을 쓰고 대립가설에는 &amp;lsquo;기각&amp;rsquo;이라는 말을</description>
    </item>
    
    <item>
      <title>유한 교집합 성질</title>
      <link>https://freshrimpsushi.github.io/posts/finite-intersection-property-fip/</link>
      <pubDate>Fri, 06 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finite-intersection-property-fip/</guid>
      <description>정의 1 위상공간 $X$ 에 대해 $\mathscr{A} \subset \mathscr{P} (X)$ 라고 하자. 모든 유한 부분집합 $A \subset \mathscr{A}$ 에 대해 $\displaystyle \bigcap A \ne \emptyset$ 이면 $A$ 가 유한 교집합 성질Finite Intersection Property을 가진다고 한다. 설명 $A$ 가 f.i.p.를 가진다는 것은 열린 집합 $U_{\alpha} \subset A$ 에 대해 항상 다음이 성립하는 것과 같다. $$ \bigcap_{i=1}^{n} \left( X \setminus U_{i} \right) \ne \emptyset \implies \bigcap_{\alpha \in \forall } \left( X \setminus U_{\alpha} \right) \ne \emptyset $$ 이 성질은 위상공간이 아니라 그냥</description>
    </item>
    
    <item>
      <title>귀무가설과 대립가설을 정하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-choose-null-hypothesis-vs-alternative-hypothesis/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-choose-null-hypothesis-vs-alternative-hypothesis/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 귀무가설 $H_{0}$ vs 대립가설 $H_{1}$ 귀무가설은 영가설이라는 이름으로도 불린다.2018년 4월 기준으로 일부 교과서나 위키백과에서는 귀무가설을 &amp;lsquo;통계학에서 처음부터 버릴것을 예상하는 가설&amp;rsquo;로, 대립가설을 &amp;lsquo;연구를 통해 입증되기를 기대하거나 예상하는 가</description>
    </item>
    
    <item>
      <title>르장드르의 배 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-legendres-duplication-formula/</link>
      <pubDate>Wed, 04 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-legendres-duplication-formula/</guid>
      <description>공식 $$ \Gamma (2r) = {{2^{ 2r - 1} } \over { \sqrt{ \pi } } } \Gamma \left( r \right) \Gamma \left( {{1} \over {2}} + r \right) $$ 설명 쪼개지는 모양이 그렇게 예쁘지는 않지만 인수를 작게 나눌 수 있다는 것은 분명 유용한 사실이다. 유도 자체는 베타함수에서 파생된 보조정리를 사용하면 별로 어렵지 않다. 유도 $$ B(p,q) = {{\Gamma (p) \Gamma (q)} \over {\Gamma (p+q) }} = \int_{0}^{1} t^{p-1} (1-t)^{q-1} dt $$ 에 대해 $r:= p=q$ 이라고 하면 $$ {{\Gamma (r) \Gamma (r)} \over {\Gamma (2r) }} = \int_{0}^{1} t^{r-1} (1-t)^{r-1} dt $$ $\displaystyle t</description>
    </item>
    
    <item>
      <title>측도론으로 정의되는 확률</title>
      <link>https://freshrimpsushi.github.io/posts/probability-in-terms-of-measure-theory/</link>
      <pubDate>Tue, 03 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-in-terms-of-measure-theory/</guid>
      <description>정의 1 $\mathcal{F}$ 가 집합 $\Omega$ 의 시그마 필드라고 하자. 가측 집합 $E \in \mathcal{F}$ 를 사건Event라고 한다. $\mathcal{F}$ 상의 측도 $P : \mathcal{F} \to \mathbb{R}$ 가 $P(\Omega) = 1$ 를 만족하면 $P$ 를 확률Probability이라고 한다. $( \Omega, \mathcal{F} , P )$ 를 확률 공간Probability Space라 한다. 설명 측도론의 힘을 빌리면 확률론의 여러가지 개념들에 대해 수리적 토대가 되고 모호함을 제거할</description>
    </item>
    
    <item>
      <title>R 에서 범주형 데이터의 숫자를 숫자형 데이터로 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/factor-to-numeric-in-r/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/factor-to-numeric-in-r/</guid>
      <description>개요 숫자임에도 불구하고 범주형 자료로 읽혀서 연속형 데이터로 바꾸고 싶은데 생각대로 되지 않는 이들을 위한 팁이다. 이 포스트는 지면 대부분을 그 원리를 설명하기 위해 할애하고 있으므로 결론만 필요하면 아래의 실전 예시부터 읽기를 추천한다. 참고로, 보통 자료형을 바꿀 때는 Cast라는 표현을 사용한다. 원리 R 을 이용해서 통계분석을 할 때 가장 중요</description>
    </item>
    
    <item>
      <title>R 에서 외부 데이터 불러오기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-solve-eof-within-quoted-string/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-solve-eof-within-quoted-string/</guid>
      <description>개요 R 은 기본적으로 통계학을 위해 태어난 언어기 때문에 데이터의 입력 역시 편리하게 되어있다. read.table(file, header = FALSE, sep = &amp;#34;&amp;#34;, na.strings = &amp;#34;NA&amp;#34;, fileEncoding = &amp;#34;&amp;#34;) 함수 소개 read.table()은 데이터 테이블을 불러들이는 함수로써 위와 같이 여러가지 유용한 옵션을 제공한다. 옵션자체는 더 많이 있지만, 자주 쓰이고 반드시 알아두어야할 것을 추린 것이다. 다음의 설명들을 참고하</description>
    </item>
    
    <item>
      <title>보렐 집합</title>
      <link>https://freshrimpsushi.github.io/posts/borel-set/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/borel-set/</guid>
      <description>정의 1 $\mathcal{F}$ 를 유클리드 공간 $\mathbb{R}$ 의 시그마 필드라고 하자. $\displaystyle \mathcal{B} : = \bigcap \left\{ \mathcal{F} : \mathcal{I} \subset \mathcal{F} \right\}$ 을 모든 구간의 집합 $\mathcal{I}$ 에 의해 생성되었다고 한다. $B \in \mathcal{B}$ 을 보렐 집합Borel Set이라 하고, $\mathcal{B}$ 를 보렐 시그마 필드라 부른다. $\mathcal{I}$ 는 모든 구간들의 집합이다. 설명 쉽게 말해 모든 구간을 가지는 시그마 대수 중에 가장 작은 시그마 대수다. 있을 건 다 있으면서 쓸모 없는 것을</description>
    </item>
    
    <item>
      <title>르벡 측도</title>
      <link>https://freshrimpsushi.github.io/posts/lebesgue-measure/</link>
      <pubDate>Thu, 29 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lebesgue-measure/</guid>
      <description>정의 1 $E \in \mathcal{M}$ 에 대해 함수 $m : \mathcal{M} \to [0,\infty]$ 을 $m(E) := m^{ \ast } (E)$ 과 같이 정의하자. $m$ 을 (르벡) 측도라 한다. $\mathcal{M}$ 는 $X = \mathbb{R}$ 의 가측 집합들의 집합인 시그마 대수다. $m^{\ast}$ 는 외측도다. 설명 외측도는 $m^{ \ast } : \mathscr{P}( \mathbb{R} ) \to [0, \infty]$ 으로 깔끔하게 정의된 대신 길이의 일반화로써는 아쉬운 점이 있었다. 대신 실수의 시그마-필드로 정의역에 제한을 주는 것으로 이상적인 &amp;lsqu</description>
    </item>
    
    <item>
      <title>중국인의 나머지 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-chinese-remainder-theorem/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-chinese-remainder-theorem/</guid>
      <description>정리 $\gcd(n,m) = 1$ 면 $\begin{cases} x \equiv b \pmod{n} \\ x \equiv c \pmod{m} \end{cases}$ 는 $1 \le x \le nm$ 에서 단 하나의 해를 갖는다. 설명 중국에서 서기 3세기에서 5세기에 쓰여졌다고 전해지는 한 수학서에는 이런 문제가 있었다고 한다. 어떤 수를 셋 씩 짝 지으면 둘이 남고, 다섯 씩 짝 지으면 셋이 남고, 일곱 씩 짝 지으면 둘이 남는다. 이 수는 무엇인가? - 손자산경 하권, 연습문제 26번 이를 현대적인 수학</description>
    </item>
    
    <item>
      <title>오일러의 토션트 합 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-eulers-totient-summation-formula/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-eulers-totient-summation-formula/</guid>
      <description>공식 $n$ 의 약수를 $d_{1}, d_{2} , \cdots , d_{r}$ 이라고 하면 $$ n = \sum_{ i = 1 }^{r} \phi(d_{i}) = \phi(d_{1}) + \phi(d_{2}) + \cdots + \phi(d_{r}) $$ 설명 토션트 함수는 정의할 때부터 다소 부자연스러운 개념이라고 느낄 수 있다. 하지만 토션트 정리도 그렇고 이런 공식도 있는 걸 보면 수학의 진리 어딘가에 분명히 필요한 함수임을 인정할수밖에 없다. 예를 들어 $15$ 를 보면 $15$ 는 약수 $1,3,5,15$ 를 가진다. 실제로 계산해보면 다음과 같다</description>
    </item>
    
    <item>
      <title>오일러의 토션트 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-totient-theorem/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-totient-theorem/</guid>
      <description>정리 1 $$ \gcd(a,m) = 1 \implies a^{ \phi (m) } \equiv 1 \pmod{m} $$ 설명 보자마자 페르마의 소정리를 일반화한 정리임을 알 수 있고, 실제로 증명법도 사실상 거의 똑같다. 증명 토션트 함수의 정의에 의해, $1 \le b_{i} \le m$ 중 $\gcd( b_{i} , m) =1$ 을 만족하는 $b_{i}$ 는 정확히 $\phi (m)$ 개 존재한다. 이들의 집합을 $$ B:= \left\{ b_{1}, b_{2}, \cdots , b_{\phi (m)} \right\} $$ 라고 하자. 그러면 $\gcd(a,m) = 1$ 이므로 $$ aB = \left\{ ab_{1}, ab_{2}, \cdots , ab_{\phi (m)} \right\} $$ 와 정확히 같</description>
    </item>
    
    <item>
      <title>시그마 대수와 가측 공간</title>
      <link>https://freshrimpsushi.github.io/posts/sigma-algebra-and-measurable-space/</link>
      <pubDate>Sun, 25 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sigma-algebra-and-measurable-space/</guid>
      <description>정의 집합 $X \ne \emptyset$ 에 대해 아래의 조건들을 만족하는 $\mathcal{E} \subset \mathscr{P} (X)$ 를 $X$ 상의 시그마 대수Sigma Algebra 혹은 시그마 필드라 하고 어떤 공간 $X$ 에 대해 시그마 필드 $\mathcal{E}$ 가 주어진다면 $(X , \mathcal{E})$ 를 가측 공간Measurable Space이라고 한다. (i): $\emptyset \in \mathcal{E}$ (ii): $E \in \mathcal{E} \implies E^{c} \in \mathcal{E}$ (iii): $\displaystyle \left\{ E_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{E} \implies \bigcup_{n=1}^{\infty} E_{n} \in \mathcal{E}$ (iv): $\displaystyle \left\{ E_{n} \right\}_{n \in \mathbb{N}} \subset \mathcal{E} \implies \bigcap_{n=1}^{\infty} E_{n} \in \mathcal{E}$ 설명 어떤 공간 $X$ 에 대해 시</description>
    </item>
    
    <item>
      <title>위상공간에서 컴팩트, 프리컴팩트란?</title>
      <link>https://freshrimpsushi.github.io/posts/compactness-precompact-in-topology-space/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/compactness-precompact-in-topology-space/</guid>
      <description>정의 1 위상공간 $\left( X, \mathscr{T} \right)$ 에 대해 $A \subset X$ 라고 하자. $X$ 의 열린 집합으로 이루어진 집합 $\mathscr{O} \subset \mathscr{T}$ 가 다음을 만족하면 $\mathscr{O}$ 를 $A$ 의 오픈 커버링Open Covering라 한다. $$ A \subset \bigcup_{O \in \mathscr{O}} O $$ $\mathscr{O}&amp;rsquo; \subset \mathscr{O}$ 인 $\mathscr{O}&amp;rsquo;$ 를 $\mathscr{O}$ 의 부분 커버Subcover라 한다. 특히 $\mathscr{O}&amp;rsquo;$ 의 기수가 자연수면 유한 부분커버Finite Subcover라 한다. $X$ 의 모든 열린 커버가 유한</description>
    </item>
    
    <item>
      <title>위상수학자의 사인 곡선과 빗 공간</title>
      <link>https://freshrimpsushi.github.io/posts/topologists-sine-curve-and-comb-space/</link>
      <pubDate>Fri, 23 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/topologists-sine-curve-and-comb-space/</guid>
      <description>정의 1 다음과 같이 정의된 $S$ 를 위상수학자의 사인 곡선Topologist&amp;rsquo;s Sine Curve이라 한다. $$ S : = \left\{ (0,y) \ | \ y \in [-1,1] \right\} \cup \left\{ \left. \left( x, \sin {{1} \over {x}} \right) \ \right| \ x \in (0,1] \right\} $$ 다음과 같이 정의된 $C$ 를 위상수학자의 빗 공간Comb Space이라 한다. $$ C := \left\{ (0,y) \ | \ y \in [0,1] \right\} \cup \left\{ (x,0) \ | \ x \in [0,1] \right\} \cup \left\{ \left( {{1} \over {n}} , y \right) \ | \</description>
    </item>
    
    <item>
      <title>국소연결과 국소경로연결</title>
      <link>https://freshrimpsushi.github.io/posts/locally-connected-and-locally-path-connected/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/locally-connected-and-locally-path-connected/</guid>
      <description>정의 $X$ 를 위상공간이라고 하자. $x \in X$ 를 포함하는 모든 $U$ 에 대해 $x \in C \subset U$ 를 만족하는 열린 연결 집합 $C$ 가 존재하면 $X$ 가 $x$ 에서 국소연결이라 한다. 모든 $x \in X$ 에 대해 국소연결이면 $X$ 를 국소연결 공간이라 한다. $x \in X$ 를 포함하는 모든 $U$ 에 대해 $x \in P \subset U$ 를 만족하는 열린 경로연결 집합 $P$ 가 존재하면 $X$ 가 $x$ 에서 국소경로연결이라 한다. 모든 $x \in X$</description>
    </item>
    
    <item>
      <title>경로연결 성분</title>
      <link>https://freshrimpsushi.github.io/posts/path-connected-component-in-in-topology/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/path-connected-component-in-in-topology/</guid>
      <description>정의 1 위상공간 $X$ 의 경로연결 부분공간들 중 자기 자신만을 연결 초집합Superset으로 갖는 경로연결 집합을 $X$ 의 경로연결 성분Path Connected Component이라 한다. 특히 $x \in X$ 를 포함하는 경로연결 성분을 $P_{x}$ 라 쓴다. 정리 [1]: $x \in X$ 은 단 하나의 $P_{x}$ 에만 속한다. [2]: $a,b \in X$ 에 대해 $P_{a} = P_{b}$ 이거나 $P_{a} \cap P_{b} = \emptyset$ 둘 중 하나다. [3]: 모든 경로연결 공간은</description>
    </item>
    
    <item>
      <title>접착 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pasting-lemma/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pasting-lemma/</guid>
      <description>정리 위상공간 $X,Y$ 에 대해 두 닫힌 집합 $A,B \subset X$ 이 $A \cup B = X$ 를 만족하고 두 연속함수 $f : A \to Y$ 와 $g : B \to Y$ 가 모든 $x \in A \cap B$ 에 대해 $f(x) = g(x)$ 라고 하자. 그러면 다음과 같이 정의된 $h$ 는 연속함수다. $$ h(x) : = \begin{cases} f(x), &amp;amp; x \in A \\ g(x), &amp;amp; x \in B \end{cases} $$ 설명 풀 보조정리Gluing Lemma라도 불리는 이 보조정리는 문장을 읽는 것만으로도 이해할 수 있을 정도로 당</description>
    </item>
    
    <item>
      <title>외측도</title>
      <link>https://freshrimpsushi.github.io/posts/outer-measure/</link>
      <pubDate>Mon, 19 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/outer-measure/</guid>
      <description>정의 1 $E \subset \mathbb{R}$, $\left\{ I_{n} \in \mathcal{I} \ | \ n \in \mathbb{N} \right\} $, $\left\{ E_{n} \in \mathscr{P} ( \mathbb{R} ) \ | \ n \in \mathbb{N} \right\}$ 에 대해 $$ Z_{E} : = \left\{ \left. \sum_{n=1}^{\infty} l (I_{n}) \ \right| \ E \subset \bigcup_{n=1}^{\infty} I_{n} \right\} $$ 라고 할 때 함수 $m^{ \ast } (E) : = \inf Z_{E}$ 를 외측도Outer Measure라 한다. 기초 성질 외측도는 아래의 성질들을 가진다. [1] 길이의 일반화: $I \in \mathcal{I} \implies m^{ \ast } (I) = l(I)$ [2] 정부호: $N \in \mathcal{N} \iff m^{ \ast }(N) = 0$ [3] 단조성: $E_{1} \subset E_{2} \implies m^{ \ast }(E_{1})</description>
    </item>
    
    <item>
      <title>위상수학에서 경로연결성이란</title>
      <link>https://freshrimpsushi.github.io/posts/path-connectedness-in-topology/</link>
      <pubDate>Sun, 18 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/path-connectedness-in-topology/</guid>
      <description>정의 1 $X$ 를 위상공간이라고 하고 $C \subset \mathbb{R}^{n}$ 이라고 하자. 연속함수 $p : [0,1] \to X$ 를 시점Initial Point $p(0)$ 에서 종점Terminal Point $p(1)$ 까지의 경로Path라 한다. $\overline{p}(t) = p(1-t)$ 를 $p$ 의 역경로Reverse Path라 한다. 모든 $a,b \in X$ 에 대해 $p(0) = a$ 와 $p(1) = b$ 를 만족하는 경로 $p$ 가 존재하면 $X$ 를 경로연결Path Connected 공간이라고 한다. 모든 $a,b \in C$ 와 $t \in</description>
    </item>
    
    <item>
      <title>위상수학에서 고정점 성질이란?</title>
      <link>https://freshrimpsushi.github.io/posts/fixed-point-property-in-topology/</link>
      <pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fixed-point-property-in-topology/</guid>
      <description>정의 함수 $f : X \to X$ 에 대해 $f(x_{0}) = x_{0}$ 를 만족하는 $x_{0}$ 을 $f$ 의 고정점Fixed Point이라 한다. 모든 연속함수 $f$ 가 고정점을 가지면 $X$ 가 고정점 성질Fixed Point Property을 가진다고 한다. 설명 주로 완비 공간과 관계가 깊다.적어도 $\mathbb{R}$ 에서는 중간값 정리를 이용하면 $f : [a,b] \to [a,b]$ 에 대해 $f(c) = c$ 를 만족하는 $c$ 가 항상 존재함을 보일 수 있다. 정리</description>
    </item>
    
    <item>
      <title>중간값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-intermediate-value-theorem/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-intermediate-value-theorem/</guid>
      <description>정의 1 $f : [a,b] \to \mathbb{R}$ 가 연속이면 $f(a)$ 와 $f(b)$ 사이의 $y_{0}$ 에 대해 $y_{0} = f(c)$ 를 만족하는 $c \in (a,b)$ 가 존재한다. 설명 대우 명제를 이용하면 $\mathbb{R}^2$ 상에서 특정한 조건을 만족한 두 도형을 연결하는 곡선이 없음을 보일 수 있다. 따름정리 한편 중간값 정리에는 다음과 같이 여러 유용한 따름정리가 있다. 방정식 $f(x)=0$ 의 해 존재성 판별법: 연속함수 $f:[a,b] \to \mathbb{R}$ 에 대해 $f(a) f(b) &amp;lt; 0$ 이면 $f(x) = 0$ 는 해 $x_{0}</description>
    </item>
    
    <item>
      <title>영집합</title>
      <link>https://freshrimpsushi.github.io/posts/null-set/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/null-set/</guid>
      <description>정의 1 실수의 구간들의 집합 $\mathcal{I}$ 에 대해 함수 $l : \mathcal{I} \to [ 0 , \infty )$ 을 $l( I ) := \sup{I} - \inf{I}$ 와 같이 정의하고 길이Length라 하자. 임의의 $\varepsilon &amp;gt; 0$ 에 대해 $$ A \subset \bigcup_{n = 1}^{\infty} I_{n} \\ \sum_{n=1}^{\infty} l (I_{n}) &amp;lt; \varepsilon $$ 을 만족하는 구간의 수열 $\left\{ I_{n} \ | \ n \in \mathbb{N} \right\}$ 이 존재하면 $A \subset \mathbb{R}$ 를 영집합Null Set이라고 한다. 설명 모든 구간들의 집합을 $\mathcal{I}$ 로, 모든 영집합의 집합을 $\mathcal{N}$ 으로 나타낸</description>
    </item>
    
    <item>
      <title>연결 성분과 완전 분리 공간</title>
      <link>https://freshrimpsushi.github.io/posts/component-and-totally-disconnected-space/</link>
      <pubDate>Wed, 14 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/component-and-totally-disconnected-space/</guid>
      <description>정의 위상공간 $X$ 의 연결 부분공간들 중 자기 자신만을 연결 초집합Superset으로 갖는 연결 집합을 $X$ 의 연결 성분Connected Component이라 한다. 특히 $x \in X$ 를 포함하는 연결 성분을 $C_{x}$ 라 쓴다. $X$ 의 모든 연결 성분이 홑원소 집합이면 $X$ 를 완전 분리 공간Totally Disconnected Space이라 한다. 설명 연결성분 정의만 보면 말이 빙빙</description>
    </item>
    
    <item>
      <title>연결 공간의 부분 공간의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-subspace-of-connected-space/</link>
      <pubDate>Tue, 13 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-subspace-of-connected-space/</guid>
      <description>정리 위상공간 $X$ 에 대해 $Y \subset X$ 라고 하자. [1]: $Y$ 가 연결 공간이면 $\overline{Y}$ 도 연결 공간이다. [2]: $Y$ 가 비연결 공간인 것과 $$ U \cap Y \ne \emptyset \\ V \cap Y \ne \emptyset \\ U \cap V \cap Y = \emptyset \\ Y \subset U \cup V $$ 를 만족하는 $X$ 의 열린 집합 $U$ 와 $V$ 가 존재하는 것은 서로 동치다. [3]: $X$ 의 연결 부분공간의 집합 $\left\{ A_{\alpha} \ | \ \alpha \in \forall \right\}$ 에 대해 $$ \displaystyle \bigcap_{\alpha \in \forall} A_{\alpha} \ne \emptyset $$ 이면 $\displaystyle \bigcup_{\alpha \in \forall} A_{\alpha}$ 는 연결 공간이다. [4]:</description>
    </item>
    
    <item>
      <title>추상대수학에서의 잉여류와 정규부분군</title>
      <link>https://freshrimpsushi.github.io/posts/normal-subgroup/</link>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normal-subgroup/</guid>
      <description>정의 1 군 $G$ 과 그 부분군 $H$ 에 대해 $aH = \left\{ ah \ | \ h \in H \right\}$ 를 좌잉여류Left Coset, $Ha = \left\{ ha \ | \ h \in H \right\}$ 를 우잉여류Right Coset이라 한다. 여기서 $a \in G$ 고 $aH, Ha \subset G$ 다. $H \leqslant G$ 의 좌(우)잉여류의 갯수를 $(G : H)$ 라 쓰고 $G$ 에서 $H$ 의 인덱스Index라 한다. $H$ 가 $G$ 의 부분군이고 모든 $g \in G$ 에 대해 $gH = Hg$ 면 $H$ 를 $G$ 의 정규부분군Nor</description>
    </item>
    
    <item>
      <title>추상대수학에서의 교대군</title>
      <link>https://freshrimpsushi.github.io/posts/alternating-group/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/alternating-group/</guid>
      <description>정의 1 대칭군 $S_{n}$ 의 짝순열들로 이루어진 군을 교대군Alternating Group이라 하고 $A_{n}$ 으로 쓴다. 정리 $n \ge 2$ 에 대해 $$ \left| A_{n} \right| = {{\left| S_{n} \right|} \over {2}} = {{ n! } \over {2}} $$ 설명 $A_{n}$ 의 위수Order가 정확히 $\left| S_{n} \right|$ 의 절반이 된다는 것은 상당히 흥미로운 성질이 아닐 수 없다. 교대군은 후에 $5$ 차 이상의 방정식이 근의 공식을 갖지 않음을 보일 때 쓰이므로 매우</description>
    </item>
    
    <item>
      <title>짝이면서 홀인 순열은 존재하지 않음을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/there-is-no-permutation-which-is-even-and-odd-both/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/there-is-no-permutation-which-is-even-and-odd-both/</guid>
      <description>정의 유한대칭군의 순열이 짝수 만큼의 전위의 곱으로 나타날 수 있으면 짝Even이라 하고 홀수 만큼의 전위의 곱으로 나타날 수 있으면 홀Odd라 한다. 정리 1 짝이면서 홀인 순열은 존재하지 않는다. 설명 짝과 홀의 정의 자체는 상당히 자연스럽지만 추상적인 학문이니만큼 그 두가지 개념이 배타적인가에 대해선 확신할 수 없다. 증명 유한대칭군 $S_{n}$ 의 전위 $\tau :</description>
    </item>
    
    <item>
      <title>전사 연속함수는 연결성을 보존한다</title>
      <link>https://freshrimpsushi.github.io/posts/surjective-continuous-function-preserves-connectedness/</link>
      <pubDate>Tue, 06 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/surjective-continuous-function-preserves-connectedness/</guid>
      <description>정리 연결 공간 $X$ 에 대해 $f : X \to Y$ 가 전사 연속함수면 $Y$ 는 연결 공간이다. 설명 연결과 연속처럼 비슷한 말이 섞여있어서 조금 헷갈릴 수도 있다. 대개는 영어로 외우면 해결되지만 이 정리에 쓰이는 영단어는 Connected 와 Continuous기 때문에 큰 도움은 되지 않는다. 증명 $Y$ 가 연결 공간이 아니라고 가정하면 $$ A \cap B = \emptyset \\ A \cup B = Y $$ 를 만족하는 열린 진</description>
    </item>
    
    <item>
      <title>연결 공간의 여러가지 동치조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-of-connected-space/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-of-connected-space/</guid>
      <description>정의 1 위상공간 $X$ 에 대해 부분집합 $A \subset X$ 가 $$ A \ne \emptyset \\ A \ne X $$ 면 $A$ 를 $X$ 의 진부분집합Proper Subset이라 한다. 두 진부분집합 $A,B \subset X$ 에 대해 $$ \overline{A} \cap B = \emptyset \\ A \cap \overline{B} = \emptyset $$ 이면 $A$ 와 $B$ 를 분리 집합Separated Set 혹은 그냥 분리Separation라 부른다. 연결 공간의 동치조건 위의 정의를 포함해서 연결 공간의 여러가지 동치</description>
    </item>
    
    <item>
      <title>추상대수학에서의 궤도, 순환, 전위</title>
      <link>https://freshrimpsushi.github.io/posts/orbit-cycle-transposition-in-abstract-algebra/</link>
      <pubDate>Sun, 04 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orbit-cycle-transposition-in-abstract-algebra/</guid>
      <description>정의 1 $\sigma$ 를 군 $G$ 에 대한 순열이라고 하면 $a, b \in G$ 에 대한 동치관계 $\sim$ 는 $b=\sigma^n (a)$ 를 만족하는 정수 $n \in \mathbb{Z}$ 이 존재할 때 $a \sim b$ 로 정의된다. $\sim$ 의 동치류들을 $\sigma$ 의 궤도Orbit라 한다. 원소가 둘 이상인 궤도를 많아도 하나만 가지는 순열을 순환Cycle이라고 한다. 순환이 가지는 궤도들 중 가장 기수가 큰 궤도의 기수를 순환의 길이Length라 한다. 길이</description>
    </item>
    
    <item>
      <title>위상수학에서 연결성이란</title>
      <link>https://freshrimpsushi.github.io/posts/connectedness-in-topology/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/connectedness-in-topology/</guid>
      <description>정의 1 위상공간 $X$ 에서 $A \cap B = \emptyset$ 과 $A \cup B = X$ 을 만족하는 열린 집합 $A \ne \emptyset$, $B \ne \emptyset$ 이 존재하면 $X$ 를 비연결Disconnected 공간이라고 한다. 비연결공간이 아니면 연결Connected 공간이라고 한다. 정리 [1]: 연결성은 위상적 성질이다. [2]: 모든 자명공간은 연결 공간이다. [3]: 모든 이산공간은 비연결 공간이다. [4]: 모든 홑원소집합은 연</description>
    </item>
    
    <item>
      <title>하우스도르프 공간에서는 시퀀스의 극한이 유일하다</title>
      <link>https://freshrimpsushi.github.io/posts/uniqueness-of-limit-of-sequence-in-hausdorff-space/</link>
      <pubDate>Fri, 02 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniqueness-of-limit-of-sequence-in-hausdorff-space/</guid>
      <description>정리 $T_{2}$-공간 $X$ 상의 수열 $\left\{ x_{n} \right\}$ 은 둘 이상의 점으로 수렴하지 않는다. 설명 극한의 유일성에 대해서 그 중요함을 굳이 역설할 필요가 있을까 싶다. 이런 성질이 있다는 것부터가 하우스도르프 공간이 쓸만하다는 증거가 된다. 주의해야하는 것은 표현상 &amp;lsquo;단 하나의 점으로 수렴한다&amp;rsquo;와는 조금 차이가 있다는 것이다. 만</description>
    </item>
    
    <item>
      <title>T1-공간인 것과 모든 유한부분집합이 닫혀있는 것은 동치다</title>
      <link>https://freshrimpsushi.github.io/posts/t1-space-iff-all-finite-subset-are-closed/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/t1-space-iff-all-finite-subset-are-closed/</guid>
      <description>정리 $X$ 가 $T_{1}$-공간인 것과 필요충분조건은 $X$ 의 모든 홑원소집합 $\left\{ x \right\}$ 가 $X$ 에서 닫힌 집합인 것이다. 증명 $(\Rightarrow)$ $T_{1}$-공간 $X$ 에 대해 $x \in X$, $x&#39; \in X \setminus \left\{ x \right\}$ 라고 두면 $x \ne x&amp;rsquo;$ 이다. $X$ 는 $T_{1}$-공간이므로, $x&#39; \in U_{x&amp;rsquo;}$ 이면서 $x \notin U_{x&amp;rsquo;}$ 인 열린 집합 $U_{x&amp;rsquo;} \subset X$ 이 존재한다. 정리하면 $$ x&#39; \in U_{x&amp;rsquo;} \subset X \setminus \left\{ x \right\} $$ 이고, $$ X \setminus \left\{ x \right\} =</description>
    </item>
    
    <item>
      <title>케일리의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cayleys-theorem/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cayleys-theorem/</guid>
      <description>정리 1 모든 군은 대칭군의 어떤 부분군과 동형이다. 설명 짧고도 굵직한 이 정리는 대칭군을 연구하면 모든 군을 파악할 수 있다는 메세지를 담고 있다. 증명 증명은 언뜻 지루해 보이지만 읽어보면 그 테크닉이 상당히 흥미로우니 한번정도는 직접 따라해보는 것을 추천한다. Part 1. $f : G \to G&#39;$ 가 단사면 $G \simeq f (G)$ 군 $G$ 와 $G&#39;$ 에 대해 준동형사상 $f : G \to G&#39;$ 가 단사면 $G \simeq</description>
    </item>
    
    <item>
      <title>베타함수의 삼각함수 표현</title>
      <link>https://freshrimpsushi.github.io/posts/trigonometric-function-representation-of-beta-function/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trigonometric-function-representation-of-beta-function/</guid>
      <description>정리 $$ B(p,q) = 2 \int_{0}^{{\pi} \over {2}} \left( \sin \theta \right) ^{2p-1} \left( \cos \theta \right) ^{2q-1} d \theta $$ 설명 그것이 어떤 종류의 수학이라고 하더라도 어떤 함수를 다른 방식으로 표현할 수 있다는 건 좋은 일이다. 증명 $\displaystyle B(p,q) = \int_{0}^{1} t^{p-1} (1-t)^{q-1} dt$ 에서 $t = \sin^2 \theta$ 로 치환하면 $$ B(p,q) = \int_{0}^{{\pi} \over {2}} \left( \sin^2 \theta \right)^{p-1} \left( 1 - \sin^2 \theta \right) ^{q-1} 2 \sin \theta \cos \theta d \theta $$ $1 - \sin^2 \theta = \cos ^2 \theta$ 이므로 $$ B(p,q) = 2 \int_{0}^{{\pi} \over {2}} \left( \sin \theta \right)^{2p-1} \left( \cos \theta \right) ^{2q-1} d \theta $$ ■ 따름정리 특히 $\sin \theta</description>
    </item>
    
    <item>
      <title>위상수학에서의 분리성질</title>
      <link>https://freshrimpsushi.github.io/posts/separation-properties/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separation-properties/</guid>
      <description>정의 1 $X$ 를 위상공간이라고 하자. $a,b \in X$ 에 대해 $a \ne b$ 고 $U, V \subset X$ 는 $X$ 에서 열린 집합이다. $T_{0}$: 임의의 $a$ 와 $b$ 중 하나만 포함하는 $U$ 가 존재하면, $X$ 를 콜모고로프Kolmogorov 공간이라고 한다. $T_{1}$: 임의의 $a,b$ 에 대해 $$ a \in U, b \notin U \\ a \notin V, b \in V $$ 를 만족하는 $U,V$ 가 존재하면, $X$ 를 프레셰Frechet 공간이라고 한다. $T_{2}$: 임의의 $a,b$ 에 대해</description>
    </item>
    
    <item>
      <title>클라인 사원군</title>
      <link>https://freshrimpsushi.github.io/posts/klein-4-group/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/klein-4-group/</guid>
      <description>정의 1 $V = \left\{ e, a, b, c \right\}$ 과 이항연산 $\cdot$ 에 대해, $\left&amp;lt; V , \ \cdot \ \right&amp;gt;$ 을 클라인 사원군Klein 4-group이라고 한다. 설명 보다시피 원소의 갯수가 항등원을 포함해서도 $4$ 개밖에 안 되기 때문에 굉장히 풍부한 성질을 갖지는 않는다. 하지만 계산이 별로 없고 독자적인 연산을 가진만큼 군의 개념을 체득하기엔 상당히 좋은 예시가 된다. $x \cdot x = e$ 즉, 모</description>
    </item>
    
    <item>
      <title>토션트 함수의 곱셈적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-totient-functions-multiplicativity/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-totient-functions-multiplicativity/</guid>
      <description>정리 1 $$ \gcd (n , m) =1 \implies \phi ( n m ) = \phi (n) \phi (m) $$ 설명 토션트 함수에서 유도되는 여러가지 중요한 결과를 얻기 위해선 반드시 필요한 성질이다. 분명히 $\gcd (n , m) =1$ 라는 조건이 있으니 만능이라고 착각하진 말자. 증명 일반성을 잃지 않고, $$ nm = p_{1}^{{k}_{1}} p_{2}^{{k}_{2}} \cdots p_{r}^{{k}_{r}} \\ p_{1} &amp;lt; p_{2} &amp;lt; \cdots &amp;lt; p_{r} $$ 라고 하자. 가정에서 $\gcd (n , m ) = 1$ 이므로 $p_{i} \mid n$ 이거나 $p_{i} \mid m$ 이거나 둘 중 하나</description>
    </item>
    
    <item>
      <title>이항계수의 일반화 베타함수</title>
      <link>https://freshrimpsushi.github.io/posts/beta-function/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/beta-function/</guid>
      <description>정리: 베타함수로 표현되는 이항계수 $0 \le k\le n$ 을 만족하는 두 자연수 $k,n$ 에 대해서 아래의 식이 성립한다. $$ \binom{n}{k}={}_{n}C_{k}=C(n,k)=\frac{1}{(n+1)B(n-k+1,k+1)} $$ 두 자연수 $m,n$ 에 대해서 아래의 식이 성립한다. $$ B(m,n)=\left[ \frac{mn}{m+n} \begin{pmatrix} m+n \\ n \end{pmatrix}\right]^{-1} $$ 설명 $B(p,q):=\displaystyle \int_{0}^{1}t^{p-1}(1-t)^{q-1}dt$로 정의되는 베타함수는 위와 같이 이항계수의 일반화로 볼 수도 있다. 증명은 어렵지 않으나 증</description>
    </item>
    
    <item>
      <title>일양 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-uniform-distribution/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-uniform-distribution/</guid>
      <description>공식 $X \sim U[a,b]$ 면 $$ E(X) = {{ a+b } \over { 2 }} \\ \text{Var}(X) = {{ (b-a)^{2} } \over { 12 }} $$ 유도 전략: 일양 분포의 정의에서 직접 연역한다. 일양 분포의 정의: $[a,b] \subset \mathbb{R}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포]] $U[a,b]$ 를 일양 분포라 한다. $$ f(x) = {{ 1 } \over { b - a }} \qquad , x \in [a,b] $$ 평균 $$ \begin{align*} E(X) =&amp;amp; \int_{a}^{b} x {{ 1 } \over { b-a }} dx \\ =&amp;amp; {{ 1 } \over { b-a }} \left[ {{ x^{2} } \over { 2 }} \right]_{a}^{b} \\ =&amp;amp; {{</description>
    </item>
    
    <item>
      <title>슈발츠-크리스토플 사상</title>
      <link>https://freshrimpsushi.github.io/posts/schwarz-christoffel-mapping/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schwarz-christoffel-mapping/</guid>
      <description>정리 1 복소평면 상에서 $n$ 개의 각을 가진 꺾인 선을 $\mathscr{P}$ 라고 하고 그 각들을 $w_{r}$, 그 내각의 크기를 $\psi_{r}$ 라 하자. 그러면 $K, C, z_{0} \in \mathbb{C}$ 와 $x_{r} \in \mathbb{R}$ 에 대해 $f(x_{r}) = w_{r}$ 를 만족시키는 등각사상 $$ w = f(z) = K \int_{z_{0}}^{z} \prod_{r = 1}^{n} ( \zeta - x_{r})^{ \psi_{r} / \pi - 1 } d \zeta + C $$ 은 실수축을 꺾인 선 $\mathscr{P}$ 로 대응시킨다. 이를 슈발츠-크리스토플 사상Schwarz Christoffel Mapping이라 부른다. 설명 만약</description>
    </item>
    
    <item>
      <title>일양 분포</title>
      <link>https://freshrimpsushi.github.io/posts/uniform-distribution/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniform-distribution/</guid>
      <description>정의 1 연속형 $[a,b] \subset \mathbb{R}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $U(a,b)$ 를 일양 분포Uniform Distribution라 한다. $$ f(x) = {{ 1 } \over { b - a }} \qquad , x \in [a,b] $$ 이산형 유한집합 $\left\{ x_{k} \right\}_{k=1}^{n}$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포를 일양 분포라 한다. $$ p \left( x_{k} \right) = P \left( X = x_{k} \right) = {{ 1 } \over { n }} \qquad , k = 1, \cdots ,</description>
    </item>
    
    <item>
      <title>쥬코프스키 변환</title>
      <link>https://freshrimpsushi.github.io/posts/joukowski-transform/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/joukowski-transform/</guid>
      <description>정의 1 등각사상 $\displaystyle w = f(z) = a z + {{b} \over {z}}$ 라고 하자. $a=b$ 면 $f$ 를 쥬코프스키 변환Joukowski Transform이라고 하고, 중심이 $0$ 이 아닌 원을 비행기 날개의 단면 모양으로 대응시킨다. [1]: $f$ 는 중심이 $0$ 인 원을 타원으로 대응시킨다. [2]: $f$ 는 $0$ 에서 시작되는 반직선을 쌍곡선으로 대응시킨다. 설명 쥬코프스키Zhukovsky는 항공역</description>
    </item>
    
    <item>
      <title>등각사상으로써의 삼각함수</title>
      <link>https://freshrimpsushi.github.io/posts/trigonometric-function-as-conforming-mapping/</link>
      <pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/trigonometric-function-as-conforming-mapping/</guid>
      <description>정리 1 등각사상 $w = f(z) = \sin z$은 수직선 $y=k$ 를 타원으로, 수평선 $x = k$ 를 쌍곡선으로 대응시킨다. 증명 $$ z = x + iy \\ w = u + i v $$ 라고 하면 $$ u = \sin x \cosh y \\ v = \cos x \sinh y $$ 이다. $y = k$ 라고 하면 $$ {{ u^2 } \over { \cosh^{2} k}} = \sin^{2} x \\ \displaystyle {{ v^2 } \over { \sinh^{2} k}} = \cos^{2} x $$ 양변끼리 더하면 $$ {{ u^2 } \over { \cosh^{2} k}} + {{ v^2 } \over { \sinh^{2} k}} = 1 $$ 즉 타원의 방정식이 된다. $x</description>
    </item>
    
    <item>
      <title>등각사상으로써의 지수함수</title>
      <link>https://freshrimpsushi.github.io/posts/exponential-function-as-conforming-mapping/</link>
      <pubDate>Wed, 21 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/exponential-function-as-conforming-mapping/</guid>
      <description>정리 1 등각사상 $w = f(z) = e^{z} = e^{x} e^{i y}$ 은 직사각형을 부채꼴 혹은 고리로 대응시킨다. 설명 $f(z) = e^{z}$ 는 분명 등각사상이지만 단사는 아니므로 역사상을 생각할 땐 여러가지 제한이 필요하다. Osborne (1999). Complex variables and their applications: p217.&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>위상수학에서 계승적 성질이란?</title>
      <link>https://freshrimpsushi.github.io/posts/hereditary/</link>
      <pubDate>Wed, 21 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hereditary/</guid>
      <description>빌드업: 부분공간 위상공간 $(X, \mathscr{T})$ 에 대해 $Y \subset X$ 라고 하자. $\mathscr{T}&amp;rsquo; := \left\{ U \cap Y \ | \ U \in \mathscr{T} \right\}$ 라고 하면 $(Y , \mathscr{T}&amp;rsquo; )$ 는 $X$ 의 부분공간Subspace이 되고 $\mathscr{T}&amp;rsquo;$ 를 $\mathscr{T}$ 에 의한 $Y$ 의 부분위상Subspace Topology이라 한다. [1]: $A \subset Y$ 가 $Y$ 에서 닫힌 부분집합인 필요충분조건은 $A = C \cap Y$ 를 만족하는 닫힌 부분집합 $C \subset X$ 가 존재하는 것이다. [2]: $y \in</description>
    </item>
    
    <item>
      <title>위상적 성질</title>
      <link>https://freshrimpsushi.github.io/posts/topological-property/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/topological-property/</guid>
      <description>정의 1 위상동형인 두 공간 $X,Y$ 에 대해 $X$ 의 성질 $P$ 를 $Y$ 도 갖고 있으면 $P$ 를 위상적 성질Topological Property이라 한다. 위상적 성질의 예시로는 아래와 같은 것들이 있다. [1]: 가분성 Separability [2]: 제1가산성 First Countability [3]: 제2가산성 Second Countability [4]: 거리화가능성 Metrizability [5]: 하우스도르프 Hausdorff [6]: 연결성 Connectedness [7]: 고정점 성질 Fixed Point Property [8]: 컴팩트성 Compactness [9]: 가산 컴팩트성 Countably Compactness 설명 대수</description>
    </item>
    
    <item>
      <title>토션트 함수</title>
      <link>https://freshrimpsushi.github.io/posts/totient-fuction-phi-function/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/totient-fuction-phi-function/</guid>
      <description>같이보기 해석적 정수론에서의 토션트 함수 정의 1 다음과 같이 정의된 $\phi$ 를 오일러 토션트 함수라 한다. $$ \phi( m ) := \left| \left\{ a \ | \ 1 \le a \le m \land \gcd (a,m) = 1 \right\} \right| = m \prod_{p \mid m} \left( 1 - {{1} \over {p}} \right) $$ 설명 토션트Totient는 전체를 의미하는 Tot-al의 Tot-과 몫을 의미하는 Quo-tient에서 -tient가 붙어서 생긴 단어로 이해해도 무방하</description>
    </item>
    
    <item>
      <title>추상대수학에서의 여러 사상들</title>
      <link>https://freshrimpsushi.github.io/posts/morphisms-in-abstract-algebra/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/morphisms-in-abstract-algebra/</guid>
      <description>정의 군 $\left&amp;lt; G , \ast\ \right&amp;gt; , \left&amp;lt; G&#39; , *&amp;rsquo; \right&amp;gt;$ 에 대해 $\phi : G \to G&#39;$ 이라고 하자. $\forall x ,y \in G $, $\phi (x \ast\ y) = \phi (x ) *&amp;rsquo; \phi ( y)$ 이면 $\phi$ 를 준동형사상Homomorphism이라 한다. 준동형사상 $\phi$ 가 단사면 $\phi$ 를 단형사상Monomorphism이라 하고 $G \hookrightarrow G&#39;$ 라 쓴다. 준동형사상 $\phi$ 가 전사면 $\phi$ 를 전형사상Epimorphism이라 하고 $G \twoheadrightarrow G&#39;$ 라 쓴다. 준</description>
    </item>
    
    <item>
      <title>포물선을 반평면으로 대응시키는 등각사상</title>
      <link>https://freshrimpsushi.github.io/posts/conforming-mapping-parabola-to-half-plane/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conforming-mapping-parabola-to-half-plane/</guid>
      <description>정리 1 등각사상 $\displaystyle w = f(z) = z^{1/2}$ 은 포물선을 반평면으로 대응시킨다. 설명 $\mathbb{R}^2$ 에서 배운 것을 생각해보면야 당연하긴하지만 복소평면에서도 성립하는지는 체크가 필요하다. 깔끔하게 세로축을 기준으로 가르고 싶다면 $\xi = w - a$ 만 한번 더 취해주면 된다. 증명 $$ z = x + i y \\ w = u + i v $$ 라고 두면 $$ z = w^2 = (u + iv)^2 = u^2 - v^2 + i 2 uv = x + iy $$ 이므</description>
    </item>
    
    <item>
      <title>부채꼴을 원으로 대응시키는 등각사상</title>
      <link>https://freshrimpsushi.github.io/posts/conforming-mapping-circular-sector-to-circle/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conforming-mapping-circular-sector-to-circle/</guid>
      <description>정리 1 등각사상 $\displaystyle w = f(z) = z^{n}$ 은 부채꼴을 반원으로 대응시킨다. 설명 부채꼴의 반지름이 무한대라고 생각해보면 $f$ 는 각을 평각으로 보내고 그 내부를 반평면으로 대응시킨다고 할 수 있다. 한편 반원 역시 부채꼴이고 반평면 역시 각이므로, $\xi = w^{2}$ 를 한 번 더 취함으로써 완전한 원이나 평면에 대응시킬 수 있다. Osborne (1999). Complex variables and their applications: p212.&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>위상공간에서 위상동형이란</title>
      <link>https://freshrimpsushi.github.io/posts/homeomorphic-in-topology/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homeomorphic-in-topology/</guid>
      <description>정의 1 두 위상공간 $X,Y$ 에 대해 전단사 $f : X \to Y$ 가 존재해서 $f$ 와 그 역함수 $f^{-1}$ 모두 연속함수면 $f$ 를 위상동형사상Homeomorphism라 부르고 두 위상공간이 위상동형Homeomorphic이라 한다. 정리 다음 명제들은 서로 동치다. (1): $f : X \to Y$ 가 위상동형사상이다. (2): $f^{-1} : Y \to X$ 가 위상동형사상이다. (3): $f : X \to Y$ 가 닫힌 함수면서</description>
    </item>
    
    <item>
      <title>반원을 사분면으로 대응시키는 등각사상</title>
      <link>https://freshrimpsushi.github.io/posts/conforming-mapping-half-circle-to-quadrant/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conforming-mapping-half-circle-to-quadrant/</guid>
      <description>정리 1 등각사상 $\displaystyle w = f(z) = {{z - a} \over {z + a}}$ 는 반원을 사분면으로 대응시킨다. 설명 $\displaystyle w = {{z - a} \over {z + a}}$ 는 별다른 이름은 없지만 매우 중요하고 빈번하게 쓰이는 함수다. 특히 $f(a) = 0$, $f(ai) = i$, $f(-a) = \infty$ 임을 직접 계산해서 확인해보도록 하자. Osborne (1999). Complex variables and their applications: p210.&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>열린 함수와 닫힌 함수</title>
      <link>https://freshrimpsushi.github.io/posts/open-function-and-closed-function/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/open-function-and-closed-function/</guid>
      <description>정의 위상공간 $X,Y$ 에 대해 $f : X \to Y$ 라고 하자. 모든 열린 집합 $O \subset X$ 에 대해, $f (O)$ 가 $Y$ 에서 열린 집합이면 $f$ 를 열린 함수라 한다. 모든 닫힌 집합 $C \subset X$ 에 대해, $f (C)$ 가 $Y$ 에서 닫힌 집합이면 $f$ 를 닫힌 함수라 한다. 정리 특히 연속함수는 아래의 성질을 가진다. [1]: 연속함수 $f : \mathbb{R} \to \mathbb{R}$ 가 전단사면 열린 함수면서 닫힌 함수다. 위의 성질은 아래 정리의 아주 특수</description>
    </item>
    
    <item>
      <title>윌슨의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-wilsons-theorem/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-wilsons-theorem/</guid>
      <description>정리 1 2보다 큰 소수 $p$ 에 대해, $(p-1)! \equiv -1 \pmod{p}$ 설명 페르마의 소정리만큼은 아니더라도, 윌슨의 정리 역시 여기저기서 유용하게 쓰인다. 생긴 모양새부터가 연속되는 수들의 곱을 계산할 때 편리하게 생겼다. 증명 $\pmod{p}$ 에서 곱셈에 대한 역원의 존재성, 유일성을 이용한 증명1과 원시근Primitive root의 성질, 페르마의 소정리를 이용한 증명2 두가지</description>
    </item>
    
    <item>
      <title>복소해석학에서의 역점</title>
      <link>https://freshrimpsushi.github.io/posts/inverse-point/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inverse-point/</guid>
      <description>정의 1 직선 $L: 2px + 2qy + c = 0$ 과 원 $\mathscr{C}: |z - A | = r$ 의 점이 아닌 $P: z = x + iy$ 를 생각하자. 이에 대한 역점Inverse Point은 다음과 같이 정의된다. $\displaystyle {{y - y^{ \ast }} \over {x - x^{ \ast }}} = {{q} \over {p}}$ 와 $p(x + x^{ \ast }) + q(y + i y^{ \ast }) + c = 0$ 를 만족시키는 $Q: z^{ \ast } = x^{ \ast } + i y^{ \ast }$ 를 $P$ 의 직선 $L$ 에 대한 역점이라고 정의한다. 2. $\overline{AP} \cdot \overline{AQ} = r^2$ 를 만족하는</description>
    </item>
    
    <item>
      <title>위상수학에서 연속이란</title>
      <link>https://freshrimpsushi.github.io/posts/continuous-in-topology/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continuous-in-topology/</guid>
      <description>정의 한국어 위상공간 $(X, \mathscr{T}_{X} )$ 와 $(Y, \mathscr{T}_{Y} )$ 에 대해, $f: X \to Y$ 라고 하자. $f(a)$ 를 포함하는 모든 $V \in \mathscr{T}_{Y}$ 에 대해 $f(U) \subset V$ 를 만족하면서 $a$ 를 포함하는 $U \in \mathscr{T}_{X}$ 가 존재하면 $f$ 를 $a$ 에서 연속Continuous라 한다. $f$ 가 $X$ 의 모든 점에서 연속이면 연속함수라 하고 $f \in C(X,Y)$ 로 나타낼 수 있다. 영어 $f$ is continuous at $a$ $\iff$ For all neighborhood $V \in \mathscr{T}_{Y}$ of $f(a)$, there exists a neighborhood $ U \in \mathscr{T}_{X}$ of $a$ such that $a \in U \implies</description>
    </item>
    
    <item>
      <title>페르마의 소정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fermats-little-theorem/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fermats-little-theorem/</guid>
      <description>정리 1 소수 $p$ 와 서로소인 정수 $a$ 에 대해, $a^{p-1} \equiv 1 \pmod{p}$ 설명 페르마의 소정리는 단순하지만 아주 많은 곳에 쓰이는 정리 중 하나다. 오일러에 의해 일반화된 정리도 있지만 페르마의 소정리로도 충분한 경우가 많기 때문이다. 특히 유한체에서의 거듭제곱을 많이 다루는 암호론 등에서는 필수적인 정리다. 증명 전략: 증명은 단순무식하지만 그만큼 간단하지는 않다.</description>
    </item>
    
    <item>
      <title>원시 피타고라스 수끼리는 서로소다</title>
      <link>https://freshrimpsushi.github.io/posts/pytagorean-triples-are-coprime/</link>
      <pubDate>Sun, 11 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pytagorean-triples-are-coprime/</guid>
      <description>정리 $a^2 + b^2 = c^2$ 를 만족하는 세 자연수 $a,b,c$ 에 대해 $\gcd (a,b,c) = 1$ 면 $$ \gcd (a,b) = 1 \\ \gcd (b,c) = 1 \\ \gcd (c,a) = 1 $$ 설명 언뜻 피타고라스 수든 뭐든 당연해보이지만 공약수라는 걸 잘 생각해보면 그렇지만도 않다. 예로써 피타고라스 수라는 조건이 없으면 $\gcd (6,10,15) = 1$ 이지만 각 두 수끼리는 각자 공약수를 갖는다. 전략: 증명에는 아래의 두 보조정리가 기본적으로 전제된다. 피타고</description>
    </item>
    
    <item>
      <title>추상대수학에서의 정이면체군</title>
      <link>https://freshrimpsushi.github.io/posts/dihedral-group/</link>
      <pubDate>Sun, 11 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dihedral-group/</guid>
      <description>정의 1 대칭군의 부분군 $D_{n} \leqslant S_{n}$ 을 $n$각형에 대해 회전, 반전하는 순열만을 가지는 군으로 정의하고 정이면체군Dihedral Group이라 부른다. 설명 도형에서 유도되기 때문에 말만으로는 설명하기 어렵다. $D_{3} = S_{3}$ 가장 작은 정이면체군의 예시로써 대칭군 $D_{3} = S_{3}$ 이 있다. $| D_{n} | =2n$ 이러한 순열은 $n$각형에 대해 $2n$ 개 존재함을 어렵지 않게 짐</description>
    </item>
    
    <item>
      <title>원시 피타고라스 트리플은 두 홀수만으로 표현할 수 있다</title>
      <link>https://freshrimpsushi.github.io/posts/primitive-pytagorean-triple-can-be-represented-by-2-odd-numbers/</link>
      <pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/primitive-pytagorean-triple-can-be-represented-by-2-odd-numbers/</guid>
      <description>정리 1 $a^2 + b^2 = c^2$ 를 만족하는 세 자연수 $a,b,c$ 에 대해 $$ \begin{align*} a =&amp;amp; st \\ b =&amp;amp; {{s^2 - t^2 } \over {2}} \\ c =&amp;amp; {{s^2 + t^2 } \over {2}} \end{align*} $$ 를 만족하는 서로소인 두 홀수 $s&amp;gt;t$ 가 존재한다. 설명 이 정리에 따르면 피타고라스 트리플은 사실상 &amp;lsquo;트리플&amp;rsquo;이라고 부를 이유가 없어진다. 변수를 줄일 수 있다는 건 그것이 어떤 과목이든 가리지 않고 무조건 좋은 일이다. 증</description>
    </item>
    
    <item>
      <title>위상수학에서 기저의 동치 조건</title>
      <link>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-baisis/</link>
      <pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/necessary-and-sufficient-condition-for-baisis/</guid>
      <description>정의 1 집합 $X$ 에서 $\mathscr{B}$ 가 위상 $\mathscr{T}$ 에 대한 기저, $\mathscr{B}&amp;rsquo;$ 가 위상 $\mathscr{T}&amp;rsquo;$ 에 대한 기저라고 할 때, $\mathscr{T} = \mathscr{T}&amp;rsquo;$ 이면 $\mathscr{B}$ 와 $\mathscr{B}&amp;rsquo;$ 를 서로 동치Equivalent라 한다. 정리 기저의 동치는 아래의 두 가지를 만족시키는 것과 필요충분조건이다. (i): 모든 $B \in \mathscr{B}$ 와 $x \in B$ 에 대해, $x \in B&amp;rsquo; \subset B$ 를 만족시키는 $B&amp;rsquo; \in \mathscr{B}&amp;rsquo;$ 가 존재한다. (ii): 모든 $B&amp;rsquo; \in \mathscr{B}&amp;rsquo;$ 와 $x&#39; \in B&amp;rsquo;$ 에 대해, $x&#39; \in B \subset B&amp;rsquo;$ 를 만족시키</description>
    </item>
    
    <item>
      <title>복소해석학에서의 교차비</title>
      <link>https://freshrimpsushi.github.io/posts/cross-ratio-in-complex-analysis/</link>
      <pubDate>Fri, 09 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cross-ratio-in-complex-analysis/</guid>
      <description>정의 1 확장복소평면상에서 네 개의 서로 다른 점 $ z_{1} , z_{2} , z_{3} , z_{4} \in \overline{ \mathbb{C} }$ 에 대해 다음을 교차비Cross Ratio라고 정의한다. $$ (z_{1} , z_{2} , z_{3} , z_{4} ) = {{( z_{1} - z_{4})( z_{3} - z_{2})} \over {(z_{1} - z_{2}) ( z_{3} - z_{4}) } } $$ 설명 조금 모양을 바꿔서 $\displaystyle (z_{1} , z_{2} , z_{3} , z ) = {{( z_{3} - z_{2}) } \over {(z_{1} - z_{2})} } \cdot {{ ( z - z_{1}) } \over { ( z - z_{3}) } }$ 라고 해보면 $$ (z_{1} , z_{2} , z_{3} , z_{1} ) = 0 \\ (z_{1} ,</description>
    </item>
    
    <item>
      <title>위상수학에서의 부분기저</title>
      <link>https://freshrimpsushi.github.io/posts/subbasis-in-topology/</link>
      <pubDate>Fri, 09 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subbasis-in-topology/</guid>
      <description>정의 1 위상공간 $\left( X , \mathscr{T} \right)$ 에 대해 $\mathscr{S} \subset \mathscr{T}$ 이라 하자. $\displaystyle \mathscr{B} = \left\{ \left. B = \bigcap_{ i = 1}^{n} S_{i} \ \right| \ S_{i} \in \mathscr{S} \right\}$ 가 $\mathscr{T}$ 의 기저가 될 때, $\mathscr{S}$ 를 $\mathscr{T}$ 의 부분기저Subbasis라 한다. 설명 부분기저를 받아들이기 어려운 이유는 보통 수학에서 &amp;lsquo;부분&amp;rsquo;을 붙일 때는 부분집합이면서 원래의 성질을 유지하기 때문이다. 예를 들어 부분군이라면 부분</description>
    </item>
    
    <item>
      <title>피타고리스 수 중 하나는 반드시 3의 배수여야한다</title>
      <link>https://freshrimpsushi.github.io/posts/one-of-pythagorean-triple-must-be-multiple-of-3/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/one-of-pythagorean-triple-must-be-multiple-of-3/</guid>
      <description>정의 1 자연수 $a,b,c$ 가 $a^2 + b^2 = c^2$ 를 만족할 때, $a$ 혹은 $b$ 는 $3$ 의 배수다. 설명 피타고라스 수 중 하나는 반드시 짝수일 뿐만이 아니라 적어도 하나는 $3$ 의 배수라는 이야기를 할 수 있다. 증명 어떤 자연수 $n$ 에 대해 자연수를 $3$ 으로 나눈 나머지 $1, 2, 0$ 에 따라 세가지로 나눠 생각해보자. Case 1. 나머지가 $1$ 인 경우 $$ \begin{align*} (3n+1)^2 &amp;amp;= 9 n^2 + 6n + 1 \\ =&amp;amp; 3( 3 n^2 + 2n) + 1 \end{align*} $$ 이므로</description>
    </item>
    
    <item>
      <title>피타고라스 트리플</title>
      <link>https://freshrimpsushi.github.io/posts/pythagorean-triple/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pythagorean-triple/</guid>
      <description>정의 1 $a^2 + b^2 = c^2$ 를 만족하는 세 자연수의 순서쌍 $(a,b,c)$ 을 피타고라스 트리플이라 한다. 만약 세 자연수가 공약수를 가지지 않으면 원시 피타고라스 트리플Primitive Pytahgoras Triple라 한다. 설명 편의상 피타고라스 트리플에 포함된 수를 피타고라스 수라고 부르도록 하자. 피타고라스 트리플의 예로는 다들 잘 아는 것과 같이 $(3, 4, 5)$ 그리고 $(5, 12, 13)$ 등이 있</description>
    </item>
    
    <item>
      <title>피타고리스 수 중 하나는 반드시 짝수여야한다</title>
      <link>https://freshrimpsushi.github.io/posts/one-of-pythagorean-triple-must-be-even/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/one-of-pythagorean-triple-must-be-even/</guid>
      <description>정리 1 자연수 $a,b,c$ 가 $a^2 + b^2 = c^2$ 를 만족할 때, $a$ 혹은 $b$ 는 짝수다. 설명 흥미롭게도 피타고라스 수 중 하나는 반드시 짝수여야한다. 증명 짝수의 제곱은 짝수고 홀수의 제곱은 홀수이므로, $c^2$ 이 홀수면 $a^2$ 이 짝수거나 $b^2$ 여야만 한다. $c^2$ 이 짝수라고 가정하면 $a^2$ 과 $b^2$ 이 모두 홀수거나 짝수인데, 모두 홀수인 경우만 살펴보면 충분하다. 어떤 자연수 $x,y,z \in \mathbb{N}$ 에 대해 $a,b,c$</description>
    </item>
    
    <item>
      <title>확장복소평면에서 원은 쌍선형변환에 대해 불변이다</title>
      <link>https://freshrimpsushi.github.io/posts/circle-is-invariant-to-bilinear-transform-in-extended-complex-plane/</link>
      <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/circle-is-invariant-to-bilinear-transform-in-extended-complex-plane/</guid>
      <description>정리 1 모든 쌍선형변환은 $\overline { \mathbb{C} }$ 의 원을 $\overline { \mathbb{C} }$ 의 원으로 대응시킨다. 증명 일반적인 원의 방정식을 $$ a ( x^2 + y^2 ) + 2p x + 2q y + c = 0 $$ 로 나타내보자. 그리고 $B := p - iq$ 라 두면 복소평면 상의 $z = x + i y$ 에 대해 $$ az \overline{z} + Bz + \overline{Bz } + c = 0 $$ 을 얻을 수 있다. 이제 $az \overline{z} + Bz + \overline{Bz } + c = 0$ 에 선형변환 $\displaystyle w = {{z - \beta} \over {\alpha}}$ 와 반전 $\displaystyle w = {{1} \over {z}}$</description>
    </item>
    
    <item>
      <title>산술의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-arithmetic/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-arithmetic/</guid>
      <description>정리 1 자연수 $n &amp;gt;2$ 은 유일한 소인수분해 $n = p_{1} p_{2} \cdots p_{r}$ 를 가진다. 이때 소수 $p_{1} , p_{2} , \cdots , p_{r}$ 의 순서는 무시한다. 설명 초등학교부터 자연스럽게 써오던 성질이니만큼 증명이 필요하다는 사실이 낯설겠지만 굉장히 중요하다. 어쩌면 이렇게나 쉽다는 것 자체가 기본정리라는 이름을 달만한 자격이 있다는 증거가 될 것이다. 증명 초등적 증명 Part 1. 존재성 $2=2$ 이고 $3=</description>
    </item>
    
    <item>
      <title>오일러의 증명: 소수는 무한히 존재한다</title>
      <link>https://freshrimpsushi.github.io/posts/eulers-proof-of-the-infinitude-of-primes/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eulers-proof-of-the-infinitude-of-primes/</guid>
      <description>정리 소수는 무한히 많이 존재한다. 증명 전략: 어떤 방법을 사용하든 같은 결과에만 도달한다면야 상관은 없지만, 정말 특이하게 풀어냈다면 그 자체로 공부할 가치가 있다. 유클리드의 증명처럼 단순 명료 깔끔한 맛은 없지만 정수론의 문제를 해석적인 툴로 해결했다는 점이 매우 흥미롭다. 오일러가 남긴 많은 증명들이 그렇듯 한 번 보면 잊기 힘들 정도의 충격을 선</description>
    </item>
    
    <item>
      <title>소수 분해 원리</title>
      <link>https://freshrimpsushi.github.io/posts/prime-divisibility-property/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prime-divisibility-property/</guid>
      <description>정리 1 소수 $p$ 가 자연수 $ n : = d_{1} d_{2} \cdots d_{r}$ 에 대해 $p \mid n$ 면 $p$ 는 $d_{1} , d_{2} , \cdots , d_{r}$ 중 적어도 하나를 나누어야한다. 설명 $p \mid n$ 은 $n$ 이 $p$ 의 배수, 즉 $p$ 가 $n$ 을 나눈다는 말이다. 언뜻 보면 당연한 소리 같지만 엄연히 증명이 필요한 소수만의 성질이다. 소수가 아니라도 위의 정리가 항상 성립하는지 생각해보자. 증명 일단은 $n$ 이 두 자연수의 곱, 즉 $n = ab$ 라 두고</description>
    </item>
    
    <item>
      <title>쌍선형변환</title>
      <link>https://freshrimpsushi.github.io/posts/bilinear-transform/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bilinear-transform/</guid>
      <description>정의 1 정의역에서 등각사상인 $f$ 를 다음과 같이 부른다. 이동Translation $f(z) = z + \alpha$ 확대Magnification: $f(z) = \rho z$ 회전Rotation: $f(z) = e^{i \theta} z$ 반전Inversion: $f(z) = {{1} \over {z}}$ 쌍선형변환Bilinear Trasform: $\displaystyle f(z) = {{ \alpha z + \beta } \over { \gamma z + \delta }}$ 이동에서 $\alpha \in \mathbb{C}$ 이고, 확대에서 $\rho \in \mathbb{R}^{ \ast }$ 이다. 설명 1</description>
    </item>
    
    <item>
      <title>추상대수학에서의 대칭군</title>
      <link>https://freshrimpsushi.github.io/posts/symmetric-group/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/symmetric-group/</guid>
      <description>정의 1 집합 $A$ 에 대해 전단사 $\phi : A \to A$ 를 순열Permutation이라 한다. $S_{A}$ 는 모든 순열을 모아놓은 집합으로써 함수의 합성 $\circ$ 에 대해 군 $\left&amp;lt; S_{A} , \circ \right&amp;gt;$ 를 이루고, 대칭군Symmetric Group이라 부른다. 설명 대칭군이 정말 군의 조건을 만족하는지는 순열이 전단사로 정의되었다는 점에서 쉽게 확인할 수 있다. 주로 관심의 대상이 되는 것</description>
    </item>
    
    <item>
      <title>확장된 유클리드 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-extended-euclid-theorem/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-extended-euclid-theorem/</guid>
      <description>정리 1 두 정수 $a,b$ 에 대해 $ax + by = \gcd (a,b)$ 는 반드시 정수해를 가진다. 설명 이 정리는 $\gcd (a,b)$ 가 $a$ 와 $b$ 의 일차Linear식으로 나타날 수 있다는 의미에서 선형 합동 정리Linear Congruence Theorem이라고도 불린다. 다소 복잡한 모양새고 존재성만 논하기 때문에 직접적으로 쓰이긴 어려울 것 같지만 의외로 굉장히 많이 사용한다. 구체적인 해 $(x,y)$ 를 찾아주는 건</description>
    </item>
    
    <item>
      <title>거리공간의 제1가산성과 제2가산성</title>
      <link>https://freshrimpsushi.github.io/posts/if-first-countable-and-seperable-then-second-countable/</link>
      <pubDate>Sat, 03 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-first-countable-and-seperable-then-second-countable/</guid>
      <description>정리 [1]: 모든 거리공간은 제1가산이다. [2]: 모든 가분 거리공간은 제2가산이다. 설명 위상수학에서 온갖 추상적인 공간들을 보고나면 거리공간이 얼마나 편리하고 좋은 공간인지 깨닫게 된다. 증명 [1] 거리공간 $\left( X , d \right)$ 에 대해 $x \in X$ 라고 하면 $$ \left\{ \left. B_{d} \left(x , {{1} \over {n}} \right) \ \right| \ n \in \mathbb{N} \right\} $$ 은 $x$ 에 대한 가산 국소기저이므로, $X$ 는 제1가산이다. ■ [2] 거리공간</description>
    </item>
    
    <item>
      <title>위상수학에서의 기저와 국소기저</title>
      <link>https://freshrimpsushi.github.io/posts/basis-and-local-basis-in-topology/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/basis-and-local-basis-in-topology/</guid>
      <description>정의 위상공간 $\left( X , \mathscr{T} \right)$ 에 대해 $\mathscr{B} , \mathscr{B}_{x} \subset \mathscr{T}$ 라고 하자. $B_{\lambda} \in \mathscr{B}$ 이라고 할 때, 모든 $U \in \mathscr{T}$ 에 대해 $$ U = \bigcup_{\lambda \in \Lambda} B_{ \lambda } $$ 를 만족하는 첨수집합 $\Lambda$ 가 존재하면 $\mathscr{B}$ 를 $\mathscr{T}$ 에 대한 기저Basis라고 한다. 이 때 위상 $\mathscr{T}$ 는 $\mathscr{B}$ 에 의해 생성된다Generated고 한다. $x \in X$ 라고 할 때, 모든 $B \in \mathscr{B}_{x}$ 에 대해 $x \in B$ 이고 $x$ 를 포함하는 모든 $U \in \mathscr{T}$ 에 대해 $$ x \in B</description>
    </item>
    
    <item>
      <title>제1가산과 제2가산</title>
      <link>https://freshrimpsushi.github.io/posts/first-countable-and-second-countable/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/first-countable-and-second-countable/</guid>
      <description>정의 1 위상공간 $X$ 이 주어져 있다고 하자. 모든 점 $x \in X$ 에 대해 가산 국소기저가 존재하면 제1가산 공간이라 한다. $X$ 가 가산 기저를 가지면 제2가산 공간이라 한다. 설명 기저와 국소기저라는 개념을 통해 가산의 새로운 갈래를 만들어냈다고 보면 된다. 제1가산이 되지 못하는 예시 여유한공간 $\left( \mathbb{R} , \mathscr{T}_{f} \right)$ 은 제1가산이 되지 못하며, 말할 것도 없이 제2가산</description>
    </item>
    
    <item>
      <title>등각사상은 내각의 크기를 보존한다</title>
      <link>https://freshrimpsushi.github.io/posts/conformal-mapping-preserves-internal-angle-scale/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conformal-mapping-preserves-internal-angle-scale/</guid>
      <description>정리 1 영역 $\mathscr{R}$ 에서 함수 $f$ 가 등각사상이고 곡선 $\mathscr{C}_{1}$ 과 $\mathscr{C}_{2}$ 가 한 점 $\alpha$ 에서 만나며 그 내각을 $\psi$ 라고 하자. $\mathscr{C}_{1}&amp;rsquo;$ 과 $\mathscr{C}_{2}&amp;rsquo;$ 가 $\mathscr{C}_{1}$ 과 $\mathscr{C}_{2}$ 를 $f$ 로 보낸 상이라고 하면 두 곡선은 $\beta = f ( \alpha )$ 에서 만나며 그 내각 역시 $\psi$ 다. 설명 해석학답게 말은 어렵지만 요는 도형들이 이루는 내각을 등각사상이 보존한다는 것이다. 애초에 등각사상이라는 이름 자체가 이러한 성질에서 나온 것이다.</description>
    </item>
    
    <item>
      <title>모든 순환군은 정수군과 동형임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/every-cyclic-group-is-isomorphic-to-integer-group/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/every-cyclic-group-is-isomorphic-to-integer-group/</guid>
      <description>정리 1 순환군 $\left&amp;lt; a \right&amp;gt;$ 가 유한군이면 $\left&amp;lt; a \right&amp;gt; \simeq \mathbb{Z}_{n}$ 이고 무한군이면 $\left&amp;lt; a \right&amp;gt; \simeq \mathbb{Z}$ 이다. 설명 이 정리로 순환군에 대한 탐구는 사실상 거의 끝난다. 추상적이기만 했던 군이 단숨에 정수론의 영역으로 떨어지기 때문에 할 수 있는 게 상당히 많아진다. 반대로 군론의 이론들을 이용해서 정수론의 문제를 풀어내는 것 역시 가능할 것이다. 증명 어떤 $m \in \mathbb{n}$ 에 대해 $a^m = e$ 을 만</description>
    </item>
    
    <item>
      <title>복소해석에서 등각사상이란?</title>
      <link>https://freshrimpsushi.github.io/posts/conformal-mapping/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conformal-mapping/</guid>
      <description>정의 1 함수 $f: A \subset \mathbb{C} \to \mathbb{C}$ 가 $\mathscr{R} \subset A$ 에서 해석적이고 모든 $z \in \mathscr{R}$ 에 대해 $f &#39; (z) \ne 0$ 이면 $f$ 를 등각사상Conformal Mapping 혹은 등각변환Conformal Transform이라고 한다. 한편 $f &#39; (\alpha) = 0$ 를 만족하는 점 $\alpha$ 가 존재하면 $\alpha$ 를 $f$ 의 임계점Critical Point이라고 한다. 설명 등각等角이라는 한자 그대로 등각변환을 취하면</description>
    </item>
    
    <item>
      <title>복소해석에서 역함수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-inverse-function-theorem-in-complex-analysis/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-inverse-function-theorem-in-complex-analysis/</guid>
      <description>정리 1 $f$ 가 $\alpha$ 에서 해석적이고 $f &#39; (\alpha) \ne 0$ 이면 $\mathcal{N} (\alpha)$ 에서 $f^{-1}$ 가 존재한다. 설명 $f &#39; (\alpha) \ne 0$ 이라는 조건을 잘 생각해보자. 실수함수로 생각해보면 증가함수거나 감소함수라는 것이고, 이는 역함수가 존재하는 조건이 된다. 기하적인 표현을 빌리자면 매끄러운Smooth 함수를 말하는 것이고, 이는 갑자기 방향을 트는 등의 꺾인 점이 없다는 뜻이다. 역함수</description>
    </item>
    
    <item>
      <title>여유한위상과 여가산위상</title>
      <link>https://freshrimpsushi.github.io/posts/cofinite-topology-and-cocountable-topology/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cofinite-topology-and-cocountable-topology/</guid>
      <description>정의 $X$ 가 무한집합이라고 하자. $\mathscr{T}_{f} : = \left\{ \emptyset , X \right\} \cup \left\{ U \subset X : | X \setminus U | &amp;lt; \infty \right\}$ 를 여유한위상이라 한다. $\mathscr{T}_{c} : = \left\{ \emptyset , X \right\} \cup \left\{ U \subset X : | X \setminus U | = \aleph_{0} \right\}$ 를 여가산위상이라 한다. 알레프 제로 $\aleph_{0}$ 는 무한 가산 집합의 기수를 의미한다. 설명 단어와 표현은 어렵지만 의미하는 바는 결국 여집합이 유한인 위상, 여집합이 가산인 위상이라는 말이다. 여유</description>
    </item>
    
    <item>
      <title>일반적인 위상공간에서 수열의 극한은 유일하지 않다</title>
      <link>https://freshrimpsushi.github.io/posts/limits-of-sequence-are-not-unique-in-general-space/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limits-of-sequence-are-not-unique-in-general-space/</guid>
      <description>정리 일반적으로, 위상공간에서 수열의 극한은 유일하지 않다. 설명 도대체 이게 무슨 소린가 싶겠지만 놀랍게도 사실이다. 우리는 이제껏 해석학 등에서 수열을 포함하는 구간이 점점 좁아지면서 한 점으로 수렴하는 이미지를 떠올려왔다. 하지만 위상수학에서 정의하는 수렴의 개념에 따르면 위상공간에 따라선 한 점으로 수렴할 이유가 전혀 없다. 극한의 유일성</description>
    </item>
    
    <item>
      <title>위상공간에서의 가분과 폐포</title>
      <link>https://freshrimpsushi.github.io/posts/separable-in-topology/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separable-in-topology/</guid>
      <description>정의 1 위상공간 $X$ 에 대해 $A \subset X$ 라고 하자. $x \in O \subset A$ 를 만족하는 열린 집합 $O$ 가 존재할 때, $x$ 를 $A$ 의 내점Interior Point이라 한다. $A$ 의 내점의 집합 $A^{\circ}$ 를 $A$ 의 내부Interior라 한다. $A$ 와 그 도집합의 합집합 $\overline{A} : = A \cup A&amp;rsquo;$ 를 $A$ 의 폐포Closure라 한다. $x \in \overline{A}$ 이면서 $x \in \overline{X \setminus A}$ 일 때, $x$ 를 $A$ 의 경계점Boundary</description>
    </item>
    
    <item>
      <title>자명 위상과 이산 위상</title>
      <link>https://freshrimpsushi.github.io/posts/sierpinski-space/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sierpinski-space/</guid>
      <description>정의 1 어떤 집합 $X$ 가 주어져 있을 때 자명 위상Trivial Topology $\left\{ \emptyset , X \right\}$ 를 주면 그 공간은 가장 작은 공간이며 자명 공간이라 한다. 반대로 이산 위상Discrete Topology $\mathscr{P}(X)$ 를 주면 그 공간은 가장 큰 공간이며 이산 공간이라 한다. 시어핀스키 공간 $S : = \left\{ 0, 1 \right\}$ 의 위상이 $\mathscr{T} : = \left\{ \emptyset , \left\{ 1 \right\} , \left\{ 0, 1 \right\} \right\}$ 이면 $S$ 를 시어핀스키 공간Sierpinski</description>
    </item>
    
    <item>
      <title>순환군의 부분군은 순환군임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/subgroup-of-cyclic-group-is-also-cyclic-group/</link>
      <pubDate>Sun, 28 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/subgroup-of-cyclic-group-is-also-cyclic-group/</guid>
      <description>정의 1 순환군 $G$ 의 부분군 $ H \leqslant G$ 은 순환군이다. 설명 생각을 조금만 해보면 당연한 사실이지만 상당히 중요한 정리일뿐만 아니라 증명 역시 간단하지만은 않다. 증명 $H = \left\{ e \right\}$ 일 경우 $H = \left&amp;lt; e \right&amp;gt;$ 이므로 순환군이다. $H \ne \left\{ e \right\}$ 일 경우 어떤 자연수 $n$ 에 대해 $a^{n} \in H$ 일 것이고, 이를 만족하는 가장 작은 자연수를 $m$ 이라고 하자. $c := a^m$ 일 때 $H = \left&amp;lt; a^m \right&amp;gt; = \left&amp;lt;</description>
    </item>
    
    <item>
      <title>추상대수학에서의 동형</title>
      <link>https://freshrimpsushi.github.io/posts/isomorphism-in-abstract-algebra/</link>
      <pubDate>Sun, 28 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/isomorphism-in-abstract-algebra/</guid>
      <description>정의 1 두 이항연산구조 $\left&amp;lt; S , * \right&amp;gt;$ 와 $\left&amp;lt; S&amp;rsquo; , *&amp;rsquo; \right&amp;gt;$ 에 대해 전단사 함수 $\phi : S \to S&amp;rsquo;$ 가 존재해서 모든 $x , y \in S$ 에 대해 $$ \phi(x \ast\ y) = \phi( x ) *&amp;rsquo; \phi( y ) $$ 를 만족하면 $\phi$ 를 동형사상이라 부르고 $S$ 와 $S&amp;rsquo;$ 가 동형Isomorphic이라 하고 $S \simeq S&amp;rsquo;$ 라 쓴다. 설명 정의를 요약하자면 연산를 보존하는 전단사가 존재해주면 사실상 서로 같다고 보겠다는 것이다. 꼭 추상</description>
    </item>
    
    <item>
      <title>모든 순환군은 가환군임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/evert-cyclic-group-is-abelian-group/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/evert-cyclic-group-is-abelian-group/</guid>
      <description>정리 1 모든 순환군은 가환군이다. 설명 굳이 따로 증명하지 않더라도 순환군이 정수군과 동형이라는 것을 보이면 자연스럽게 따라오는 사실이기도 하다. 증명 순환군 $G := \left&amp;lt; a \right&amp;gt;$ 에 대해, $g_{1} = a^{r}$ 그리고 $g_{2} = a^{s}$ 라고 하자. $$ g_{1} g_{2} = a^{r} a^{s} = a^{r+s} = a^{s+r} = a^{s} a^{r} = g_{2} g_{1} $$ 이므로 $G$ 는 가환군이다. ■ Fraleigh. (2003). A first course in abstract algebra(7th Edition): p59.&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>위상공간에서의 집적점과 수렴, 도집합</title>
      <link>https://freshrimpsushi.github.io/posts/limit-point-and-convergence/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/limit-point-and-convergence/</guid>
      <description>정의 1 위상공간 $\left( X , \mathscr{T} \right)$ 이 주어져 있다고 하자. $A \subset X$ 에 대해 $x$ 를 포함하는 임의의 열린 집합 $O$ 가 $O \cap ( A \setminus \left\{ x \right\} ) \ne \emptyset$ 를 만족하면 $x$ 를 $A$ 의 집적점Limit Point , $A$ 의 모든 집적점의 집합 $A&amp;rsquo;$ 를 $A$ 의 도집합Derived Set이라 한다. $X$ 의 수열 $\left\{ x_{n} \right\}$ 이 $x$ 에 수렴한다Converge는 것은 $x$ 를 포함하는 임의의 열린 집합 $O$ 에 대해 다음을</description>
    </item>
    
    <item>
      <title>위상공간이란?</title>
      <link>https://freshrimpsushi.github.io/posts/topology-space/</link>
      <pubDate>Fri, 26 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/topology-space/</guid>
      <description>정의 위상공간 1 집합 $X$ 가 주어졌을 때 $\mathscr{T} \subset \mathscr{P} (X)$ 가 $T \in \mathscr{T}$ 에 대해 다음 세가지 조건을 만족하면 $\mathscr{T}$ 를 $X$ 의 위상Topology이라 부르고, $\left( X , \mathscr{T} \right)$ 를 위상공간Topology Space라 부른다. (i): $$\emptyset , X \in \mathscr{T}$$ (ii): $$\displaystyle \bigcup_{ \alpha \in \forall } T_{\alpha} \in \mathscr{T}$$ (iii): $$\displaystyle \bigcap_{ i= 1}^{n} T_{i} \in \mathscr{T}$$ 조건 (i)~(iii)을 다시 말로 풀어써보면 아래와 같다: (i): $\mathscr{T}$ 는 공집합 $\emptyset$ 와 전체집합</description>
    </item>
    
    <item>
      <title>거리공간에서 완비성과 조밀성</title>
      <link>https://freshrimpsushi.github.io/posts/completeness-density/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/completeness-density/</guid>
      <description>정의 거리 공간 $\left( X , d \right)$ 에 대해 $A \subset X$ 라고 하자. $X$ 의 수열 $\left\{ x_{n} \right\}$ 이 모든 $\varepsilon &amp;gt; 0$ 에 대해 $n,m &amp;gt; n_{0}$ 일때마다 $d(x_{n} , x_{m}) &amp;lt; \varepsilon$ 을 만족하는 자연수 $n_{0}$ 가 존재하면 코시 수열Cauchy sequence이라고 한다. $\left( X , d \right)$ 상의 코시 수열의 수렴하는 점들이 $X$ 에 속하면 $\left( X , d \right)$ 를 완비하다complete고 하고 그렇지 않을 경우 불완비하다incom</description>
    </item>
    
    <item>
      <title>그램-슈미트 직교화</title>
      <link>https://freshrimpsushi.github.io/posts/gram-schmidt-orthogonalization/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gram-schmidt-orthogonalization/</guid>
      <description>정리 모든 유한차원 내적공간은 정규직교기저를 갖는다. 설명 존재성 증명이라는 게 대개 그렇듯 길지도 않고 별것도 아닌것 같아보이지만 엄청나게 중요한 정리다. 선형대수학을 지탱하는 수많은 논리가 바로 이 정규직교기저가 존재한다는데에 의존하고 있기 때문이다. 증명 내적공간 $(V, \left\langle \cdot , \cdot \right\rangle)$ 을 생성하는 기저 중 하나를 $\left\{ \mathbf{x}_{1} , \cdots , \mathbf{x}_{n} \right\}$ 이라고 잡자. 새로</description>
    </item>
    
    <item>
      <title>추상대수학에서의 순환군</title>
      <link>https://freshrimpsushi.github.io/posts/cyclic-group/</link>
      <pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cyclic-group/</guid>
      <description>정의 1 군 $G$ 의 어떤 원소 $a$ 과 임의의 $x \in G$ 에 대해 $x = a^{n}$ 을 만족하는 정수 $n \in \mathbb{Z}$ 이 존재하면 $G$ 를 순환군Cyclic Group이라 하고 $a$ 를 생성원Generator이라 한다. 설명 쉽게 말해 군의 모든 원소를 생성원의 거듭제곱으로 나타낼 수 있으면 순환군이다. 계속해서 거듭제곱하는 형태로 모든 원소를 나타내게 되므로 &amp;lsquo;순환&amp;r</description>
    </item>
    
    <item>
      <title>복소해석을 이용한 제곱수의 역수의 합 계산</title>
      <link>https://freshrimpsushi.github.io/posts/calculating-riemann-zeta-2-using-complex-analysis/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/calculating-riemann-zeta-2-using-complex-analysis/</guid>
      <description>정리 1 $$ \sum_{n =1 }^{\infty} {{1} \over {n^2}} = {{ \pi ^2 } \over { 6 }} $$ 오일러의 풀이가 깔끔하고 멋지긴 한데 아이디어가 너무 기발해서 막상 써먹을데는 별로 없다. 복소해석을 공부하면서 가장 즐거운 점은 이러한 결과를 내는 숏컷이 바로바로 나온다는 것이다. 예제로도 좋으니 직접 한번 풀어보도록 하자. 증명 $\displaystyle f(z) : = {{1} \over {z^2}}$ 이라고 정의하면 $\displaystyle \lim_{z \to \infty} z f(z) = 0$ 이다. 모든 정수에</description>
    </item>
    
    <item>
      <title>오일러의 증명: 싱크함수를 이용한 제곱수의 역수의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/finding-sum-of-reciprocal-of-square-number-using-sinc-function/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finding-sum-of-reciprocal-of-square-number-using-sinc-function/</guid>
      <description>정리 $$ \sum_{n =1 }^{\infty} {{1} \over {n^2}} = {{ \pi ^2 } \over { 6 }} $$ 증명 전략: 이는 오일러가 남긴 풀이로써, 다름아닌 싱크함수의 오일러 표현을 사용해서 증명한다. 아이디어가 상당히 신선하고 재미있어서 한번 보면 잊어버리는 게 더 어려울 것이다. 싱크함수의 오일러 표현: $$ {{\sin x} \over {x}} = \prod_{n=1}^{\infty} \left( 1 - {{x^2} \over { \pi^2 n^2}} \right) $$ 오일러 표현의 우변을 풀어서 적어보면 아래와 같다. $$ \prod_{n=1}^{\infty} \left( 1</description>
    </item>
    
    <item>
      <title>유수정리를 이용한 모든 정수에 대한 급수의 합 공식</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-series-formula-for-all-integers-using-residue-theorem/</link>
      <pubDate>Sun, 21 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-series-formula-for-all-integers-using-residue-theorem/</guid>
      <description>공식 1 분수함수 $f$ 에 대해 $\lim_{n \to \infty} z f(z) = 0, n \in \mathbb{Z}$ 에서 $f(n) \ne 0$ 이라고 하자. $f$ 가 유한한 특이점 $z_{1}, \cdots , z_{m}$ 을 가질 때, $$ \sum_{n=-\infty}^{\infty} f(n) = - \sum_{n = 1}^{m} \text{Res}_{z_{n}} (\pi f(z) \cot \pi z) $$ 설명 단순히 자연수만을 모두 더하는 것이 아니라 모든 정수에 대한 합을 유한한 합계로 나타내는 데 의의가 있다. 물론 주어진 $f$ 가 우함수일 경우 그 절반을 취하면 자연수에 대한 합을 구하는데에도 응용이 가능하</description>
    </item>
    
    <item>
      <title>코탄젠트와 코시컨트의 로랑 전개</title>
      <link>https://freshrimpsushi.github.io/posts/laurnet-expansion-of-cotangent-and-cosecant/</link>
      <pubDate>Sun, 21 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laurnet-expansion-of-cotangent-and-cosecant/</guid>
      <description>공식 $$ \cot z = {{1} \over {z}} - {{z} \over {3}} - {{z^{3}} \over {45}} - {{2 z^{5}} \over {945}} - \cdots \\ \csc z = {{1} \over {z}} + {{z} \over {6}} + {{7 z^{3}} \over {360}} + {{31 z^{5}} \over {15120}} + \cdots $$ 설명 복소해석에서 급수의 합 공식을 쓰기 위해선 코탄젠트와 코시컨트가 곱해진 함수의 유수를 구할 수 있어야한다. 물론 이보다 우아하고 차수가 큰 항에도 쓸 수 있는 급수꼴이 있지만 대개는 이정도면 충분하다. 적어도 세번째 항까지는 시험공부를</description>
    </item>
    
    <item>
      <title>거리공간에서 볼과 열린 집합 닫힌 집합</title>
      <link>https://freshrimpsushi.github.io/posts/ball-open-closed/</link>
      <pubDate>Thu, 18 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ball-open-closed/</guid>
      <description>정의 거리 공간 $\left( X, d \right)$ 에 대해 $a \in X$ 이고 $r &amp;gt; 0$ 이라고 하자. $B_{d} (a,r) = \left\{ x \in X \ | \ d(a,x) &amp;lt; r \right\}$ 을 중심이 $a$ 고 반경이 $r$ 인 열린 볼Open Ball이라 한다. $B_{d} [a,r] = \left\{ x \in X \ | \ d(a,x) \le r \right\}$ 을 중심이 $a$ 고 반경이 $r$ 인 닫힌 볼Closed Ball이라 한다. $O \subset X$ 가 열린 볼의 합집합이면 $O$ 를 $X$ 에서 열린 집합Open Set이라 한다. $C \subset X$ 에 대</description>
    </item>
    
    <item>
      <title>거리공간의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/metric-space/</link>
      <pubDate>Wed, 17 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/metric-space/</guid>
      <description>정의 집합 $X$ 에 대해 함수 $d : X \times X \to [0, \infty)$가 $x,y,z \in X$ 에 대해 아래의 조건들을 만족시킬 때, $d$를 거리metric라고 하고 $\left( X, d\right)$를 거리공간metric space이라고 한다. 거리가 자명한 경우에는 거리공간을 간단히 $X$라고 표기하기도 한다. $d(x,y)=0 \iff x = y$ $d(x,y) = d(y,x)$ $d(x,y) + d(y,z) \ge d(x,z)$ 설명 선형대수학에서 놈의 개</description>
    </item>
    
    <item>
      <title>다가함수의 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/improper-integral-of-mult-ivalued-function/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/improper-integral-of-mult-ivalued-function/</guid>
      <description>빌드업 1 다가함수를 적분할 때의 가장 큰 문제점은 경로를 지나면서 분기선을 만나면 함수값이 원치 않게 바뀐다는 것이다. 이러한 함수를 적분할 땐 이제까지 해왔던 것과 마찬가지로 경로 자체가 분기선을 우회하도록 하는 트릭을 사용한다. 대표적인 다가함수인 로그 $\log$ 를 생각해보면, 음의 실수축이 분기선이고 원점이 분기점이므로 위와 같은 경로를 생각해볼 수</description>
    </item>
    
    <item>
      <title>복소해석학에서의 다가함수와 분기</title>
      <link>https://freshrimpsushi.github.io/posts/multifunction-branch-cut-branch-point/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multifunction-branch-cut-branch-point/</guid>
      <description>정의 1 $X = \mathbb{C}$ 의 원소를 $Y$ 의 여러 값으로 대응시키는 사상을 다가함수Multifunction라 한다. 오픈셋 $A \subset \mathbb{C}$ 에서 정의된 다가함수 $g$ 에 대해 $\alpha \in \mathbb{C}$ 을 감싸고 $A$ 안에 놓이는 폐곡선 $\mathscr{C}$ 를 따라 $z-\alpha$ 가 $2\pi$ 만큼 계속해서 바뀌었을 때 값 $g(z)$ 이 원래의 값이 아니게끔 하도록하는 $\mathscr{C}$ 가 적어도 하나 존재하면 $\alpha$ 를 분기점Branch Point라 한다. $\alpha$ 의 모</description>
    </item>
    
    <item>
      <title>실수축의 특이점을 포함했을 때 조르당 보조정리를 통한 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/improper-integration-by-jordan-lemma-when-real-singular-points-are-included/</link>
      <pubDate>Sun, 07 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/improper-integration-by-jordan-lemma-when-real-singular-points-are-included/</guid>
      <description>빌드업 전체적인 흐름은 조르당 보조정리를 통한 이상적분과 비슷하다. 두 다항함수 $p(z) , q(z)$ 에 대해 $\displaystyle f(z) = {{q(z)} \over {p(z)}}$ 이라고 하자. $q(z) = 0$ 을 만족하는 실수해 $a$ 가 존재한다면 $f$ 는 실수 특이점 $a$ 을 갖는 것이다. 이제까지 이러한 경우를 다루지 않았던 이유는 유수 정리를 쓰기 위함이었다. 물론 실수축에 특이점이 추가되었다는 이유만으로 딱히 유수정리를 포기하지</description>
    </item>
    
    <item>
      <title>조르당 보조정리를 통한 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/improper-integration-by-jordan-lemma/</link>
      <pubDate>Sun, 07 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/improper-integration-by-jordan-lemma/</guid>
      <description>설명 1 우선은 발산하는 반원 상의 복소경로적분을 통한 유리함수의 이상적분과 비슷하게 시작해보자. 두 다항함수 $p(z) , q(z)$ 에 대해 $\displaystyle f(z) = {{q(z)} \over {p(z)}}$ 이라고 하자. $q(z) = 0$ 을 만족하는 실수해가 존재하지 않으면 $f$ 는 실수 특이점을 갖지 않을 것이다. 양수 $m \in \mathbb{R}^{+}$ 에 대해 $\displaystyle \int_{- \infty}^{\infty} \sin{mx}f(x) dx$ 혹은 $\displaystyle \int_{- \infty}^{\infty} \cos{mx}f(x) dx$ 꼴의 적분을 한다고 생각해보자. 이때 이상적분이 존재하는 조건은 $\displaystyle</description>
    </item>
    
    <item>
      <title>조르당 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-jordan-lemma/</link>
      <pubDate>Sat, 06 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-jordan-lemma/</guid>
      <description>정리 1 반원호 $\Gamma$ 를 $z(\theta) = R e^{i \theta} , 0 \le \theta \le \pi$ 와 같이 나타냈을 때, 함수 $f: \mathbb{C} \to \mathbb{C}$ 가 $\Gamma$ 에서 연속이고 $\displaystyle \lim_{z \to \infty} f(z) = 0$ 이면 양수 $m \in \mathbb{R}^{+}$ 에 대해 $$ \lim_{R \to \infty} \int_{\Gamma} e^{m i z } f(z) dz = 0 $$ 설명 조르당이라는 발음법은 콩글리쉬가 아니라 프랑스어에서 온 것이다. 보조정리이니만큼 바로 그 의미를 깨닫긴 어렵고, 여러가지 적분 테크닉에 쓰인다는 정도만 알아두면 충분하다</description>
    </item>
    
    <item>
      <title>특이값 분해를 통한 최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/least-squares-using-sigular-value-decomposition/</link>
      <pubDate>Sat, 06 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/least-squares-using-sigular-value-decomposition/</guid>
      <description>알고리즘 $A \in \mathbb{C}^{m \times n}$ 과 벡터 $\mathbb{b} \in \mathbb{C}^{m}$ 에 대해 $\text{rank} A = n$ 이고 $A \mathbb{x} = \mathbb{b}$ 의 최소제곱해를 $\mathbb{x}_{\ast}$ 이라고 하자. Step 1. 특이값 분해 $A = \widehat{U} \widehat{\Sigma} V^{\ast}$ 를 만족하는 정규직교행렬 $\widehat{U}$ 과 대각행렬 $\widehat{\Sigma}$ 과 유니터리 행렬 $V$ 를 구한다. Step 2. 특이값 분해에서 얻은 $\widehat{U}$ 를 통해 정사영 $P : = \widehat{U} \widehat{U}^{\ast}$ 을 구한다. $A \mathbb{x}_{\ast} = P \mathbb{b}$ 이므로 $\widehat{U} \widehat{\Sigma} V^{\ast} \mathbb{x}_{\ast} = \widehat{U} \widehat{U}^{\ast} \mathbb{b}$ 이고 양변의 왼쪽에 $\widehat{U}^{\ast}$ 을 곱해 $\widehat{\Sigma} V^{\ast} \mathbb{x}_{\ast} = \widehat{U}^{\ast} \mathbb{b}$ 를 얻는</description>
    </item>
    
    <item>
      <title>QR 분해를 통한 최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/least-squares-using-qr-decomposition/</link>
      <pubDate>Fri, 05 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/least-squares-using-qr-decomposition/</guid>
      <description>알고리즘 $A \in \mathbb{C}^{m \times n}$ 과 벡터 $\mathbb{b} \in \mathbb{C}^{m}$ 에 대해 $\text{rank} A = n$ 이고 $A \mathbb{x} = \mathbb{b}$ 의 최소제곱해를 $\mathbb{x}_{\ast}$ 이라고 하자. Step 1. QR 분해 $A = \widehat{Q} \widehat{R}$ 을 만족하는 정규직교행렬 $\widehat{Q}$ 과 상삼각행렬 $\widehat{R}$ 을 구한다. Step 2. QR 분해에서 얻은 $\widehat{Q}$ 를 통해 정사영 $P : = \widehat{Q} \widehat{Q}^{\ast}$ 을 구한다. $A \mathbb{x}_{\ast} = P \mathbb{b}$ 이므로 $\widehat{Q} \widehat{R} \mathbb{x}_{\ast} = \widehat{Q} \widehat{Q}^{\ast} \mathbb{b}$ 이고 양변의 왼쪽에 $\widehat{Q}^{\ast}$ 을 곱해 $\widehat{R} \mathbb{x}_{\ast} = \widehat{Q}^{\ast} \mathbb{b}$ 를 얻는다. Step 3. $\mathbb{y} := \widehat{Q}^{\ast} \mathbb{b}$ 를 계산해 $\widehat{R} \mathbb{x}_{\ast}</description>
    </item>
    
    <item>
      <title>콜레스키 분해를 통한 최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/least-squares-using-cholesky-decomposition/</link>
      <pubDate>Fri, 05 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/least-squares-using-cholesky-decomposition/</guid>
      <description>알고리즘 $A \in \mathbb{C}^{m \times n}$ 과 벡터 $\mathbb{b} \in \mathbb{C}^{m}$ 에 대해 $\text{rank} A = n$ 이고 $A \mathbb{x} = \mathbb{b}$ 의 최소제곱해를 $\mathbb{x}_{\ast}$ 이라고 하자. Step 1. 주어진 방정식의 양변에 $A^{\ast}$ 을 곱해 표준방정식 $A^{\ast} A \mathbb{x} = A^{\ast} \mathbb{b}$ 을 세운다. 표준방정식의 해는 원래 방정식의 최소제곱해가 되므로, 표준방정식의 해 $\mathbb{x}$ 를 구하면 된다. Step 2. $\mathbb{y} := A^{\ast} \mathbb{b}$ 을 계산해 $A^{\ast} A \mathbb{x} = \mathbb{y}$ 을 얻는다. Step 3. 콜레스키 분해 $A^{\ast} A = L L^{\ast}$ 을 만족하</description>
    </item>
    
    <item>
      <title>최소제곱법</title>
      <link>https://freshrimpsushi.github.io/posts/the-method-of-least-square/</link>
      <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-method-of-least-square/</guid>
      <description>정의1 행렬 $A \in \mathbb{C}^{m \times n}$ 와 벡터 $\mathbf{b} \in \mathbb{C}^{m}$에 대해 선형시스템 $A\mathbf{x} = \mathbf{b}$가 과도결정이거나 과소결정라고 하자. 그러면 이 시스템은 해를 갖지 않거나 무수히 많이 갖는다. 이때 $$ \left\| A \mathbf{x} - \mathbf{b} \right\|_{2} $$ 의 값을 최소화하는 문제를 생각해보자. 이를 최소제곱문제LSP, Least Square Problem라고 한다. 이 문제의 해</description>
    </item>
    
    <item>
      <title>행렬의 QR 분해</title>
      <link>https://freshrimpsushi.github.io/posts/qr-decomposition-of-matrix/</link>
      <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/qr-decomposition-of-matrix/</guid>
      <description>개요 효율적인 행렬 분해에는 여러가지 조건이 필요하지만, 효율 이전에 분해 자체를 할 수 있느냐 없느냐가 중요할 수 있다. QR 분해는 정방행렬이라는 조건이 필요 없는 행렬 분해법이다. 정의 계수가 $n$ 인 행렬 $A := \begin{bmatrix} \mathbb{a}_{1} &amp;amp; \cdots &amp;amp; \mathbb{a}_{n} \end{bmatrix} \in \mathbb{C}^{m \times n}_{n}$ 에 대해 $i$ 번째까지의 열벡터로 생성된 부분공간 $$ S_{i} (A) := \text{sp} \left\{ \mathbb{a}_{1}, \cdots , \mathbb{a}_{i} \right\} $$ 을 정의하자. 벡터공간을 생성할 땐 $i$ 가 클수</description>
    </item>
    
    <item>
      <title>행렬대수에서 사영이란</title>
      <link>https://freshrimpsushi.github.io/posts/projection-in-matrix-algebra/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/projection-in-matrix-algebra/</guid>
      <description>정의 정방행렬 $P \in \mathbb{C}^{m \times m}$ 가 $P^2 = P$ 면 사영작용소Projector라 한다. 설명 대수학적인 용어로는 멱등원Idempotent이라는 표현을 사용하고, 마찬가지로 $a^2 = a$ 와 같은 원소를 일컫는다. 한편 $P$ 가 사영이면 $(I-P)^2 = I - 2P + P^2 = I - 2P + P = (I-P)$ 이므로 $(I-P)$ 역시 사영임을 알 수 있다. 이러한 사영작용소 $(I - P)$를 $P$ 의 여사영작용소Co</description>
    </item>
    
    <item>
      <title>행렬대수에서 정사영이란</title>
      <link>https://freshrimpsushi.github.io/posts/orthogonal-projection-in-linear-algebra/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/orthogonal-projection-in-linear-algebra/</guid>
      <description>정의 사영 $P \in \mathbb{C}^{m \times m}$ 가 $\mathcal{C} (P) ^{\perp} = \mathcal{N} (P)$ 를 만족하면 $P$ 를 정사영이라 한다. 설명 사영의 성질 $\mathbb{C}^{m } = \mathcal{C} (P) \oplus \mathcal{N} (P)$ 에 따라 $P$ 는 $\mathbb{C}^{m}$ 을 정확히 두 개의 부분공간 $\mathcal{C} (P)$ 과 $\mathcal{N} (P)$ 으로 분할함을 알 수 있다. 이 분할에서 조건 $\mathcal{N} (P) = \mathcal{C} (P) ^{\perp}$ 을 만족한다는 것은 일차변환 $P$ 의 영공간 $\mathcal{N} (P)$ 가 열공간 $\mathcal{C} (P)$ 의 직교여공간이라는 뜻이므로 그냥 분할이 아니라 수직성이 포함되는 분할임을</description>
    </item>
    
    <item>
      <title>벡터공간에서 직합이란</title>
      <link>https://freshrimpsushi.github.io/posts/direct-sum-of-vector-space/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/direct-sum-of-vector-space/</guid>
      <description>정의 벡터공간 $S$ 의 두 부분공간 $S_{1}$과 $S_{2}$ 에 대해 다음을 만족하면 $S$를 $S_{1}$과 $S_{2}$ 의 직합direct sum이라 하고, $S = S_{1} \oplus S_{2}$와 같이 표기한다. (i) 존재성: 임의의 $\mathbf{s} \in S$ 에 대해 $\mathbf{s} = \mathbf{s}_{1} + \mathbf{s}_{2}$ 을 만족하는 $\mathbf{s}_{1} \in S_{1}$ 과 $\mathbf{s}_{2} \in S_{2}$ 가 존재한다. (ii) 배타성: $S_{1} \cap S_{2} = \left\{ \mathbf{0} \right\}$ (iii) 유일성: 주어진 $\mathbf{s}$ 에 대해 $\mathbf{s} = \mathbf{s}_{1} + \mathbf{s}_{2}$ 을 만족하</description>
    </item>
    
    <item>
      <title>콜레스키 분해의 유일성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-uniqueness-of-cholesky-decomposition/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-uniqueness-of-cholesky-decomposition/</guid>
      <description>정리 $A&amp;gt;0$ 은 오직 하나의 콜레스키 분해를 가진다. 설명 고유값 대각화, 특이값 분해, 슈어 분해, LU 분해, LDU 분해 모두 유일성을 가지지 않는다는 공통점이 있다. 이 방법들은 모두 고유값과 고유벡터의 관계를 이용하거나 $1 = a \dfrac{1}{a}$ 이므로 $L$ 이나 $U$ 에 나눠줄 수 있기 때문이다. 하지만 콜레스키 분해는 고유값의 개념을 사용하지 않고 $A=LL^{T}$ 로 나타나므로 $1$ 을 둘로 쪼개</description>
    </item>
    
    <item>
      <title>양의 정부호 행렬의 콜레스키 분해</title>
      <link>https://freshrimpsushi.github.io/posts/cholesky-decomposition/</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cholesky-decomposition/</guid>
      <description>개요 정칙행렬에서 대각행렬로 조건이 강화되면서 LDU 분해를 할 수 있었듯 양의 정부호 행렬로 조건이 강화되면 더욱 효율적인 행렬 분해인 콜레스키 분해Cholesky Decomposition를 할 수 있다. 빌드업 $m \times m$ 양의 정부호 행렬 $A : = \begin{bmatrix} a_{11} &amp;amp; \mathbb{w}^{T} \\ \mathbb{w} &amp;amp; K \end{bmatrix} &amp;gt; 0$ 을 생각해보면 $a_{11}$ 은 양수, $\mathbb{w} \in \mathbb{R}^{m-1}$ 이고 $K \in \mathbb{R}^{(m-1) \times (m-1)}$ 이다. 만약 $a_{11} \le 0$ 이면 $\mathbb{e}_{1} = (1,</description>
    </item>
    
    <item>
      <title>대칭행렬의 LDU 분해</title>
      <link>https://freshrimpsushi.github.io/posts/ldu-decomposition-of-symmetric-matrix/</link>
      <pubDate>Fri, 29 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ldu-decomposition-of-symmetric-matrix/</guid>
      <description>개요 $L^{T}$ 는 상삼각행렬이므로 $A = LU$ 에서의 $U$ 를 $U:= DL^{T}$ 으로 바꾼다고 보면 된다. 일반적인 LU 분해보다 조건이 까다로워진만큼 계산량은 많이 줄어든다. 정리 가역대칭행렬 $A$ 에 대해 $A = LDL^{T}$ 를 만족하는 하삼각행렬 $L$ 과 대각행렬 $D$ 가 존재한다. 증명 $A$ 는 가역행렬이므로 $A = L U$ 를 만족하는 하삼각행렬 $L$ 과 상삼각행렬 $U$ 가 존재한다. 한편 $A = A^{T}$ 이므로 $$ L</description>
    </item>
    
    <item>
      <title>정칙행렬의 LU 분해</title>
      <link>https://freshrimpsushi.github.io/posts/lu-decomposition-of-nonsingular-matrix/</link>
      <pubDate>Thu, 28 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lu-decomposition-of-nonsingular-matrix/</guid>
      <description>빌드업 행렬 $A \in \mathbb{R}^{m \times m}$ 의 왼쪽에 곱해졌을 때 $(i, j)$ 성분을 $0$ 이 되도록 하는 행렬 $E_{ij}$ 를 $A$ 에 대한 $ij$-소거연산자라고 정의해보자. 구체적으로 정방행렬 $(a_{ij}) \in \mathbb{R}^{m \times m}$ 에 대한 $E_{ij}$ 는 대각성분이 $1$ 이고 $(i,j)$ 성분이 $\displaystyle -m_{ij} = -{{a_{ij}} \over {a_{jj}}}$, 나머지 성분이 $0$으로 구해진다. 이는 연립 방정식의 풀이에서 같은 변수끼리 계수를 맞춰서 소거하는 연산을 행렬로 나타낸 것이다</description>
    </item>
    
    <item>
      <title>스펙트럴 이론 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-spectral-theory/</link>
      <pubDate>Wed, 27 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-spectral-theory/</guid>
      <description>정리 정칙행렬 $A \in \mathbb{C}^{m \times m}$ 의 고유값 $\lambda_{i}$ 들로 구성된 대각행렬을 $\Lambda : = \text{diag} ( \lambda_{1} , \lambda_{2} , \cdots , \lambda_{m} )$, 그 고유값들에 해당하는 정규직교 고유벡터 $\mathbb{q}_{i}$ 들로 구성된 정규직교행렬을 $Q$ 라고 하면 $$ A = A^{\ast} \iff A = Q \Lambda Q^{\ast} $$ 설명 $A^{\ast} = \left( \overline{A} \right)^{T}$ 는 $A$ 에 복소켤레를 취한 행렬의 전치 행렬로, 에르미트 행렬이라 부른다. 스펙트럴 이론Spectral Theory은 다음과 같이</description>
    </item>
    
    <item>
      <title>정칙행렬의 슈어 분해</title>
      <link>https://freshrimpsushi.github.io/posts/schur-factorization-for-nonsingular-matrix/</link>
      <pubDate>Tue, 26 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/schur-factorization-for-nonsingular-matrix/</guid>
      <description>정의 어떤 유니터리 행렬 $Q$ 와 상삼각행렬 $T$ 에 대해, $A = Q T Q^{\ast}$ 이면 $A$ 는 슈어 분해Schur Factorization를 갖는다고 한다. 정리 모든 정칙행렬 $A \in \mathbb{C}^{ m \times m}$ 는 슈어 분해를 갖는다. 설명 고유값 대각화의 단점은 $A = S \Lambda S^{-1}$ 로 분해되었을 때 어쨌든 $S^{-1}$ 을 구하는 수고가 필요하다는 것이다. 거듭제곱을 구하는 시간이 획기적으로 줄어드는 것</description>
    </item>
    
    <item>
      <title>전체 특이값 분해의 존재성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-existence-of-fsvd/</link>
      <pubDate>Sun, 24 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-existence-of-fsvd/</guid>
      <description>개요 고유값 대각화는 적용에 있어서 정방행렬이라는 제한이 있었지만 특이값 분해는 그러한 제약이 없었다. 이렇게 쓸만한 분해법이 모든 행렬에 통하는지, 즉 분해의 존재성을 밝히는 것은 상당히 중요한 문제라고 할 수 있다. 정리 세 자연수 $m \ge n \ge r = \text{rank} A$ 에 대해 행렬 $A \in \mathbb{R}^{m \times n}$ 는 fSVD를 갖는다. 증명 임의의 벡터 $\mathbb{x} \ne \mathbb{0}$ 에 대해 $\mathbb{x}^{T} A^{T} A \mathbb{x} = || A \mathbb{x} || ^2</description>
    </item>
    
    <item>
      <title>행렬의 특이값 분해</title>
      <link>https://freshrimpsushi.github.io/posts/singular-value-decomposition-svd/</link>
      <pubDate>Sat, 23 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/singular-value-decomposition-svd/</guid>
      <description>개요 늘 고유값 대각화를 통해 행렬을 쪼갤 수 있다면 좋겠지만, 이 방법엔 아쉽게도 주어지는 행렬이 정방행렬이어야한다는 제한이 있다. 이에 대각화할 행렬을 정방행렬이 아닌 경우로 확장해서 분해하려고 한다. 빌드업 두 자연수 $m &amp;gt; n$ 에 대해 행렬 $A \in \mathbb{C}^{ m \times n}$ 의 계수가 $\text{rank} A = n$ 으로 주어진다고 하자. 그러면 $\dim C(A) = \dim C(A^{T}) = n $ 으로, 이들의 정규직교벡터</description>
    </item>
    
    <item>
      <title>정칙행렬의 고유값 대각화</title>
      <link>https://freshrimpsushi.github.io/posts/diagonalization-of-nonsingular-matrix/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/diagonalization-of-nonsingular-matrix/</guid>
      <description>정의 $A \in \mathbb{C}^{ m \times m }$ 에 대해 $A = Q^{ \ast } \Lambda Q$ 를 만족하는 유니타리 행렬 $Q$ 와 대각행렬 $\lambda$ 가 존재하면, 행렬 $A$ 는 유니터리 대각화 가능하다고 말한다. 정리 정칙행렬 $A \in \mathbb{R}^{m \times m}$ 의 일차독립인 고유벡터 $\mathbb{x}_{1}, \mathbb{x}_{2}, \cdots , \mathbb{x}_{m}$ 에 대해 $S = \begin{bmatrix} \mathbb{x}_{1}, \mathbb{x}_{2}, \cdots , \mathbb{x}_{m} \end{bmatrix}$ 라 하면 $$ S^{-1} A S = \begin{bmatrix} \lambda_{1} &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; \lambda_2 &amp;amp; \ddots &amp;amp; \vdots \\ \vdots &amp;amp; \ddots &amp;amp; \ddots &amp;amp; 0 \\ 0 &amp;amp; \cdots &amp;amp; 0 &amp;amp; \lambda_{m} \end{bmatrix} $$ 설명 가정에서 고</description>
    </item>
    
    <item>
      <title>발산하는 반원 상의 복소경로적분을 통한 유리함수의 이상적분</title>
      <link>https://freshrimpsushi.github.io/posts/improper-integration-using-contour-integration-on-half-circle/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/improper-integration-using-contour-integration-on-half-circle/</guid>
      <description>빌드업 두 다항함수 $p(z) , q(z)$ 에 대해 $\displaystyle f(z) = {{q(z)} \over {p(z)}}$ 이라고 하자. $q(z) = 0$ 을 만족하는 실수해가 존재하지 않으면 $f$ 는 실수 특이점을 갖지 않을 것이다. 이러한 유리함수의 이상적분 $\displaystyle \int_{-\infty}^{\infty} f(z) dz$ 이 존재하는 조건은 $\displaystyle f(z) \sim {{1} \over {z^{p}}}$ 에서 $p &amp;gt; 1$ 이다. 무한급수의 개념으로 생각해보자면 $\displaystyle \sum_{n=0}^{\infty} {{{1} \over {n^{p}}} }$ 가 수렴하는 필요충분조건이 $p&amp;gt;1$ 인 것과 관련지어볼 수 있겠다. 이 조건을</description>
    </item>
    
    <item>
      <title>복소평면 상에서의 삼각함수 치환을 통한 정적분</title>
      <link>https://freshrimpsushi.github.io/posts/integration-on-complex-plane-by-trigonometric-substitution/</link>
      <pubDate>Sun, 26 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integration-on-complex-plane-by-trigonometric-substitution/</guid>
      <description>정리 $$ \int_{0}^{2 \pi} f( \cos \theta , \sin \theta ) d \theta = \int_{\mathscr{C}} f(z) dz = 2 \pi i \sum \text{Res} f(z) $$ 설명 정적분을 구하기 힘든 실함수는 복소해석으로의 우회를 통해 비교적 쉽게 풀어낼 수 있다. 그 중에서도 삼각함수들로 이루어진 피적분함수에 대한 적분 테크닉을 알아보자. 기본적인 전략은 적분 범위를 $z(\theta) = e^{ i \theta} , 0 &amp;lt; \theta &amp;lt; 2 \pi$ 로 바꿔 필요한 부분을 취하는 것이다. 물론 필요하다면 약간의 조</description>
    </item>
    
    <item>
      <title>R 에서 데이터 프레임의 행과 열의 위치 바꾸기</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-swap-row-and-column-in-r/</link>
      <pubDate>Sat, 25 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-swap-row-and-column-in-r/</guid>
      <description>개요 R 의 강점 중 하나는 프로그래밍 언어가 익숙한 사람의 입장에서 상당히 어려운 조작들을 손쉽게 구현시켜준다는 것이다. 예컨대 배열을 사용할 때 미리 메모리를 할당 시키지 않아도 스스로 확장이 되는가하면, 변수의 값을 바꾸는 등의 조작이 아주 쉽다. 예시 아이리스 데이터셋에서 Sepal.Width 열과 Species 열을 바꿔보자. 방법은 너무나 간단하다. 2번째 열에 5번째 열을</description>
    </item>
    
    <item>
      <title>R 에서 내장 데이터셋 불러오는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-load-built-in-dataset-in-r/</link>
      <pubDate>Fri, 24 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-load-built-in-dataset-in-r/</guid>
      <description>개요 R 은 대표적인 통계 프로그래밍 언어로써 유용한 메소드 뿐만 아니라 예제로 쓰기 좋은 데이터셋도 제공한다. 만약 이런 데이터셋이 없다면 강의를 할 때마다 새로운 데이터를 다운로드하고 불러들어들이는 짓을 해야할 것이다. 가이드 데이터셋을 불러오는 방법은 아주 간단하다. 불러올 데이터셋의 이름을 우리가 사용할 변수에 할당하기만 하면 된다. 통계학</description>
    </item>
    
    <item>
      <title>고유값의 대수적 중복도는 기하적 중복도보다 크거나 같다</title>
      <link>https://freshrimpsushi.github.io/posts/the-algebraic-multiplicity-of-eigenvalues-is-greater-than-or-equal-to-the-geometric-multiplicity/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-algebraic-multiplicity-of-eigenvalues-is-greater-than-or-equal-to-the-geometric-multiplicity/</guid>
      <description>정리 행렬 $A \in \mathbb{C}^{ m \times m}$ 의 고유값 $\lambda$ 가 대수적 중복도 $a$ 를 갖고 기하적 중복도 $g$ 를 갖는다고 하면 $a \ge g$ 이다. 설명 고유값의 대수적 중복도와 기하적 중복도는 서로 같다는 보장이 없다. 만약 같았다면 애초에 다르게 정의하지도 않았을 것이다. 다만 한가지 확신할 수 있는 것은 대수적 중복도가 아무리 작아도 기하적 중복도보다는 크거나 같다는 사실이다. 증명 표</description>
    </item>
    
    <item>
      <title>행렬의 닮음과 고유값</title>
      <link>https://freshrimpsushi.github.io/posts/two-similar-matrices-have-same-eigenvalue/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/two-similar-matrices-have-same-eigenvalue/</guid>
      <description>정의 두 가역행렬 $A$ 와 $B$ 에 대해 $$ A = P^{-1} B P $$ 를 만족하는 가역행렬 $P$ 가 존재하면 $A$ 와 $B$ 는 서로 닮았다고 한다. 켤레 위에서 주어진 식을 $B$ 에 대해서 나타내면 $$ B = P^{-1} A P $$ 이므로 닮음 관계가 대칭적임을 쉽게 알 수 있다. 대수적으로는 $A$ 와 $B$ 가 $P$ 에 대한 켤레conjugate라고 말할 수 있겠다. 정리 두 행렬 $A,B$ 가 닮음이면 다음이 성립한다. $$ \det (A</description>
    </item>
    
    <item>
      <title>고유값의 대수적 중복도와 기하적 중복도</title>
      <link>https://freshrimpsushi.github.io/posts/multiplicity-of-eigen-value/</link>
      <pubDate>Sun, 19 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiplicity-of-eigen-value/</guid>
      <description>대수적 중복도 행렬 $A \in \mathbb{R}^{m \times m}$ 에 대해 고유값은 $\det (A - \lambda I ) =0$ 을 만족하는 $\lambda$ 로 정의된다. 특성방정식은 $\lambda$ 에 대한 $m$ 차 방정식, 즉 $$ \det (A - \lambda I ) = (-1)^m \lambda ^m + c_{m-1} \lambda ^{m-1} + \cdots + c_{1} \lambda + c_{0} = 0 $$ 으로 나타낼 수 있다. 대수학의 기본정리에 의해, 특성방정식은 복소수를 포함하여 정확히 $m$ 개의 근을 갖는다. 여기서 근은 중근을 포함하는데, 중근을 갖는다는 것</description>
    </item>
    
    <item>
      <title>단순극에서의 유수</title>
      <link>https://freshrimpsushi.github.io/posts/the-residue-at-a-simple-pole/</link>
      <pubDate>Sat, 18 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-residue-at-a-simple-pole/</guid>
      <description>정리 1 함수 $f$ 를 $\displaystyle f(z) = {{g(z)} \over {h(z)}}$ 으로 나타낼 수 있다고 하자. 여기서 $g$ 와 $h$ 는 $\alpha$ 에서 해석적이고, $g(\alpha) \ne 0 , h(\alpha) = 0, h&amp;rsquo;(\alpha) \ne 0$ 라고 하면 $\alpha$ 는 $f$ 의 단순 극이고 $$ \text{Res}_{\alpha} f(z) = {{g(\alpha)} \over {h&amp;rsquo;(\alpha)}} $$ 딱히 $\displaystyle f(z) = {{g(z)} \over {h(z)}}$ 꼴에서 $h$ 가 다항함수여야하는 건 아니기 때문에 그저 극에서의 유수를 $m=1$ 에 한정시킨 정리라곤 할 수 없다. 조건만 잘 만족한다면 오히려 더 많은 종류의 함수 $h$ 를 커버할 수</description>
    </item>
    
    <item>
      <title>극점에서의 유수</title>
      <link>https://freshrimpsushi.github.io/posts/the-residue-at-a-pole/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-residue-at-a-pole/</guid>
      <description>정리 1 $\alpha$ 가 함수 $f: A \subset \mathbb{C} \to \mathbb{C}$ 의 pole of order $m$, 즉 $\displaystyle f(z) = {{g(z)} \over { (z - \alpha)^m }}$ 으로 나타낼 수 있다고 하자. 여기서 $g$ 는 $\alpha$ 에서 해석적이며 $g(\alpha) \ne 0$ 이라고 하면 $$ \text{Res}_{\alpha} f(z) = {{g^{(m-1)} (\alpha)} \over {(m-1)!} } $$ 유수정리를 통해 적분 문제를 유수를 구하는 문제로 바꿀 수 있는 것까진 좋은데, 유수를 구하는 게 적분만큼 어렵다면 소용 없는 일이다. 유수정리를 쓸 때마다 정의에 따라서 로랑 전개를 하고</description>
    </item>
    
    <item>
      <title>R 에서 행렬의 곱 역행렬 전치행렬 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/matrix-product-inverse-matrix-transpose-matrix/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/matrix-product-inverse-matrix-transpose-matrix/</guid>
      <description>개요 R 의 강점은 행렬을 위시한 각종 데이터셋의 조작이 간편하다는 점과 풍부한 통계 패키지를 무료로 제공한다는 것이다. 당연한 이야기지만 통계적 분석에서 행렬의 계산은 매우 중요하고, R 은 이러한 니즈를 훌륭하게 충족시켜준다. 매트랩이나 줄리아가 아닌 이상 다른 언어에선 행렬의 연산부터 귀찮게 따로 정의를 해줘야 할 것이다. 코드 행렬의 곱 예로써 행</description>
    </item>
    
    <item>
      <title>R 에서 몫과 나머지 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/quotient-and-remainder-in-r/</link>
      <pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/quotient-and-remainder-in-r/</guid>
      <description>개요 프로그래밍 언어의 문법에서 정말 통일이 안 되는 게 바로 몫과 나머지 연산자다. 기본적으론 다 비슷비슷하게 생긴 것 같지만 오히려 그래서 헷갈리는데 한 몫한다.C는 몫을 /, 나머지를 %으로 쓰고 파이썬은 몫을 //, 나머지를 % 으로 쓰며, 이렇게 헷갈리는 예는 얼마든지 더 들 수 있다. 도대체 통계와 행렬 계산에 초점을 맞춘 R 에서 몫과 나머지를 구할 일이 어디</description>
    </item>
    
    <item>
      <title>R 에서 모든 변수 제거하기 콘솔창 초기화</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-clear-console-and-remove-all-variable-in-r/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-clear-console-and-remove-all-variable-in-r/</guid>
      <description>개요 R 은 인터프리터 언어기 때문에 콘솔을 계속 보며 작업을 하게 된다. 이때 디버그 등을 하기 위해서는 이런 저런 테스트도 같은 작업환경에서 할 수밖에 없는데, 테스트 중간에 생성된 특정 변수가 아주 중요한데 프로그래머가 알아채지 못하고 완성본엔 포함시키지 않는 등의 일이 있을 수 있다. 어제 집에서 할 땐 분명히 돌아갔는데 오늘 발표 때 갑자기 안 돌아가는 등</description>
    </item>
    
    <item>
      <title>R 에서 else if문 사용하기 Error: unexpected else in else 해결</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-fix-error-unexpected-else-in-else-in-r/</link>
      <pubDate>Sun, 12 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-fix-error-unexpected-else-in-else-in-r/</guid>
      <description>개요 R 에는 switch문과 같은 분기문이 없기 때문에 if문을 여러개 이어서 분기를 나누어야만 한다. 여기서 이 조건문이라는 게 프로그래밍 언어마다 if 와 else는 다 똑같은데 유독 else if 만 다를 수가 있다. elseif로 붙여쓰거나 아예 elif 처럼 줄여쓰는 경우가 그 예고, R은 제대로 띄어쓰기가 들어간 else if 를 사용한다. 여러가지 프로그래밍 언어를</description>
    </item>
    
    <item>
      <title>추상대수학에서의 가환군</title>
      <link>https://freshrimpsushi.github.io/posts/abelian-group/</link>
      <pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/abelian-group/</guid>
      <description>정의 1 군 $\left&amp;lt; G, \ast\ \right&amp;gt;$ 의 두 원소 $a, b$ 에 대해 $a \ast\ b = b \ast\ a$ 면 $\left&amp;lt; G, \ast\ \right&amp;gt;$를 가환군Abelian Group이라 정의한다. 설명 가환은 &amp;lsquo;교환법칙이 성립하는&amp;rsquo; 정도의 의미로 받아들이면 좋다. 영칭의 경우 Commutative 대신 Abelian 이라는 말이 붙는데, 이는 천재수학자 아벨에서 따온 말이다. 물론 한칭으로 아벨군이라</description>
    </item>
    
    <item>
      <title>유수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-residue-theorem/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-residue-theorem/</guid>
      <description>정리 1 해석적인 함수 $f: A \subset \mathbb{C} \to \mathbb{C}$ 가 단순폐경로 $\mathscr{C}$ 내부의 유한한 특이점 $z_{1} , z_{2} , \cdots , z_{m}$ 들을 가진다고 하자. 그러면 $$ \int_{\mathscr{C}} f(z) dz = 2 \pi i \sum_{k=1}^{m} \text{Res}_{z_{k}} f(z) $$ 설명 처음 읽어보면 아리송하기짝이 없는 정리다. 적분 값을 구해야하는데 미적분학스러운 계산은 없고 웬 특이점과 유수 이야기를 하고 있으니 그럴만도 하다. 정리만 보자면 유수를 구해서 더하는 것만으로 적분값</description>
    </item>
    
    <item>
      <title>로랑 급수의 주부분과 특이점의 분류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-among-principal-part-and-singular-point-of-laurent-expansion/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-among-principal-part-and-singular-point-of-laurent-expansion/</guid>
      <description>개요 1 로랑 전개의 principal part를 잘 살펴보면 특이점의 종류를 파악할 수 있다. $\alpha$ 를 함수 $f:A\subset \mathbb{C} \to \mathbb{C}$ 의 고립된 특이점이라 하자. 이의 로랑 전개 $$ f(z) = \sum_{n = 0 }^{\infty} a_{n} (z-\alpha) ^{n} + \sum_{n = 1 }^{\infty} { {b_{n} } \over{ (z-\alpha) ^{n} } } $$ 에 대해, 수열 $b_{n}$ 은 아래의 성질들을 가진다. 정리 [1]: 모든 $n$ 에 대해 $b_{n}=0$ $ \iff$ $\alpha$ 는 제거가능한 특이점이다. [2]: 어떤 $m$ 에 대해 $b_{m} \ne 0$ 이고 $b_{m+1} = b_{m+2} = \cdots = 0$ $\iff$ $\alpha$ 는 $</description>
    </item>
    
    <item>
      <title>로랑 급수란?</title>
      <link>https://freshrimpsushi.github.io/posts/laurent-series/</link>
      <pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laurent-series/</guid>
      <description>빌드업 테일러 정리는 평균값의 정리를 미분 횟수에 대해 일반화한 정리다. 원래 $1$번 미분한 것만을 다루던 것에서 $n \in \mathbb{N}$ 으로 확장한 것이다. 그런데 자연수로 일반화가 가능했다면, 정수 전체로 일반화할 수는 없는껄까? 물론 미분을 $-n$ 번 할 수는 없지만, 미분과 역연산 관계에 있는 적분을 생각해면 어떨까? 아래의 로랑 정리를 증명 없이 소개한다. $f: A \subset</description>
    </item>
    
    <item>
      <title>복소해석에서 특이점의 종류</title>
      <link>https://freshrimpsushi.github.io/posts/classification-of-singular-point/</link>
      <pubDate>Sat, 04 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/classification-of-singular-point/</guid>
      <description>정의 특이점 1 함수 $f$ 가 $\alpha$ 에서 어떤 $\mathcal{N}(\alpha)$ 의 모든 점에서 미분가능하면 $\alpha$ 에서 해석적Analytic이라고 한다. 함수 $f$ 가 $\alpha \in \mathbb{C}$ 에서는 해석적이지는 않지만 모든 $\mathcal{N}(\alpha)$ 의 어떤 점에서는 해석적일 때 $\alpha$ 를 $f$ 의 특이점Singular Point이라고 부른다. 특이점 $\alpha$ 이 $\alpha$ 를 제외한 모든 점에서 해석적인 $\mathcal{N}(\alpha)$ 가 존재하면 $\alpha$ 가 고립Isolated되어있다</description>
    </item>
    
    <item>
      <title>선형 독립과 선형 종속</title>
      <link>https://freshrimpsushi.github.io/posts/linearly-independent-and-linearly-dependent/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearly-independent-and-linearly-dependent/</guid>
      <description>정의1 $S = \left\{ \mathbf{v}_{1}, \mathbf{v}_{2}, \dots, \mathbf{v}_{r} \right\}$를 벡터공간 $V$ 의 공집합이 아닌 부분집합이라고 하자. 상수 $k_{1}, k_{2}, \dots, k_{r}$들에 대해서 다음의 방정식 $$ k_{1} \mathbf{v}_{1} + k_{2} \mathbf{v}_{2} + \dots + k_{r} \mathbf{v}_{r} = \mathbf{0} $$ 은 적어도 하나의 해 $$ k_{1} = 0,\ k_{2} = 0,\ \dots,\ k_{r} = 0 $$ 를 갖는다. 이를 자명해trivial solution라고 한다. 오직 자명해만이 유일한 해이면 벡터 $\mathbf{v}_{1}, \mathbf{v}_{2}, \dots, \mat</description>
    </item>
    
    <item>
      <title>연립방정식으로 이해하는 랭크와 무효차수</title>
      <link>https://freshrimpsushi.github.io/posts/rank-and-nullity/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rank-and-nullity/</guid>
      <description>역사적 배경 역사적으로는 행렬이 고안된 배경 자체가 연립방정식을 보다 쉽고 편하게 표기하기 위함이었다. 예를 들어 연립방정식 $$ \begin{cases} 2x_{1} &amp;amp; + &amp;amp; x_{2} &amp;amp; + &amp;amp; x_{3} =&amp;amp; 0 \\ &amp;amp; x_{2} &amp;amp; =&amp;amp; 0 \end{cases} $$ 을 잘 보면, 같은 변수를 여러번 써야한다는 불편함이 있다. 이를 행렬로 나타내면 $$ \begin{bmatrix} 2 &amp;amp; 1 &amp;amp; 1 \\ 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} x_{1} \\ x_{2} \\ x_{3} \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix} $$ 와 같이 각 잡힌 모양으로 깔끔하</description>
    </item>
    
    <item>
      <title>군에서의 항등원과 역원의 유일성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/uniqueness-of-identity-and-inverse-in-group/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniqueness-of-identity-and-inverse-in-group/</guid>
      <description>정리 1 군 $\left&amp;lt;G, \ast \right&amp;gt;$ 에 대해, $G$ 의 모든 원소 $x$ 에 대해 $e \ast x = x \ast e = x$ 를 만족하는 항등원 $e$ 는 유일하다. $G$ 의 어떤 원소 $a$ 에 대해 $a \ast {a&amp;rsquo;} = {a&amp;rsquo;} \ast a = e$ 를 만족시키는 역원 $a&amp;rsquo;$ 는 $a$ 에 대해 유일하다. 설명 다들 당연하게 생각하고 넘어가지만 사실 군의 정의에서는 이들의 존재성만 언급될 뿐이다. 이러한 원소들이 유일하게 존재하는 것은 증명이 필요하다. 증명</description>
    </item>
    
    <item>
      <title>좌우간약율 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-left-and-right-cancellation-law/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-left-and-right-cancellation-law/</guid>
      <description>정리 1 군 $\left&amp;lt;G, \ast \right&amp;gt;$ 의 원소 $a,b,c$ 에 대해, $$ a \ast b = a \ast c \implies b = c \\ b \ast a = c \ast a \implies b=c $$ 설명 추상대수학을 접하면 이제까지 배워왔던 걸 새로운 언어로 배우게 된다. 아마 좌우간약율은 그 중에서도 가장 먼저 접하게되는 정리일 것이다. 우리는 보통 그냥 양변에서 같은 걸 나눈다(역원을 곱한다)는 식으로만 말한다. 간약율은 일본에서 쓰는 표현으로, 굳이</description>
    </item>
    
    <item>
      <title>추상대수학에서의 군</title>
      <link>https://freshrimpsushi.github.io/posts/group-in-abstract-algebra/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/group-in-abstract-algebra/</guid>
      <description>정의 1 모노이드 $\left&amp;lt; G, \ast\ \right&amp;gt;$ 의 원소 $a$ 와 항등원 $e$ 대해 $a \ast\ a&amp;rsquo; = a&amp;rsquo; \ast\ a = e$ 를 만족하는 $a&amp;rsquo;$ 가 존재하면 $\left&amp;lt; G, \ast\ \right&amp;gt;$를 군Group이라고 정의한다. 즉, 군은 아래의 성질들을 만족하는 이항연산구조다. (i): 연산에 대해 결합법칙이 성립한다. (ii): 모든 원소에 대해 항등원이 존재한다. (iii): 모든 원소에 대해 역원이 존재한다. 설명 마그마부터</description>
    </item>
    
    <item>
      <title>추상대수학에서의 모노이드</title>
      <link>https://freshrimpsushi.github.io/posts/monoid-in-abstract-algebra/</link>
      <pubDate>Tue, 31 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monoid-in-abstract-algebra/</guid>
      <description>정의 1 반군 $\left&amp;lt; M , \ast\ \right&amp;gt;$ 의 모든 원소 $a$ 에 대해, $a \ast\ e = e \ast\ a = a$ 를 만족하는 $e$ 가 존재하면 $\left&amp;lt; M , \ast\ \right&amp;gt;$ 를 모노이드Monoid라 정의한다. 설명 모노이드는 항등원이 존재하는 반군이다. 항등원 정도 되는 개념을 도입하면 할 수 있는 이야기는 상당히 많아진다. 반군이 되면서 모노이드가 되지 않는 대표적인 예를 보도록 하자. 반군 $\left&amp;lt; \mathbb{N} , +\right&amp;gt;$ 는 모노이드</description>
    </item>
    
    <item>
      <title>추상대수학에서의 반군</title>
      <link>https://freshrimpsushi.github.io/posts/semigroup-in-abstract-algebra/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/semigroup-in-abstract-algebra/</guid>
      <description>정의 1 마그마 $\left&amp;lt; S, *\right&amp;gt;$ 의 원소 $a,b,c$ 에 대해, $(a \ast\ b) \ast\ c = a \ast\ (b \ast\ c)$ 면 $\left&amp;lt; S, *\right&amp;gt;$ 를 반군Semigroup이라고 정의한다. 설명 반군이란 연산이 결합법칙을 만족하는 마그마다. 항등원이나 역원은 존재할 필요가 없고, 오직 결합법칙만 성립하면 된다. 결합법칙을 만족하는지 증명하기 쉬운가 하는 문제와는 별개로, 폐쇄성 다음으로 결합법칙이 논의되는 것</description>
    </item>
    
    <item>
      <title>추상대수학에서의 이항연산</title>
      <link>https://freshrimpsushi.github.io/posts/magma-in-abstract-algebra/</link>
      <pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/magma-in-abstract-algebra/</guid>
      <description>빌드업 수학을 크게 세 부류로 나누자면 기하학, 해석학, 대수학이라고 할 수 있을 것이다. 그 중에서 대수학은 교과과정 상에서 배우는 이항, 약분 등을 다루는 수학의 한 분과였다. 대수학이란 기본적으로 &amp;lsquo;수&amp;rsquo;를 대신해 문자를 써서 어떤 방정식이든 풀어내는 것을 목표로 하는 학문이었다. 특정한 수에 대해서만 통하는 게 아니라 일</description>
    </item>
    
    <item>
      <title>볼록 함수, 오목 함수</title>
      <link>https://freshrimpsushi.github.io/posts/convex-function-concave-function/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convex-function-concave-function/</guid>
      <description>정의 구간 $I \subset \mathbb{R}$ 의 두 원소 $x_{1} , x_{2}$ 와 함수 $f : I \to \mathbb{R}$ 와 $0 \le t \le 1$ 에 대해, $f( t x_{1} + (1-t) x_{2}) \le t f(x_{1}) + (1-t) f(x_{2})$ 일 때, $f$ 는 $I$ 에서의 볼록 함수로 정의한다. $f( t x_{1} + (1-t) x_{2}) \ge t f(x_{1}) + (1-t) f(x_{2})$ 일 때, $f$ 는 $I$ 에서의 오목 함수로 정의한다. 설명 볼록이나 오목은 위로 볼록이냐, 아래로 오목이냐 식의 헷갈리는 말들이 너무 많기 때문에 컨벡스와 컨케이브를 영어표현 그대로 쓰</description>
    </item>
    
    <item>
      <title>옌센 부등식의 적분 폼 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-integral-form-of-jensens-inequality/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-integral-form-of-jensens-inequality/</guid>
      <description>정리 컨벡스 함수 $ \phi : [a,b] \to \mathbb{R}$ 와 $f: [0,1] \to [a,b]$ 에 대해, $\phi \circ f$ 이 $[0,1]$ 에서 적분가능하면 $$ \phi \left( \int_{0}^{1} f(x) dx \right) \le \int_{0}^{1} (\phi \circ f ) (x) dx $$ 설명 당연하지만 주어진 조건만 만족한다면 치환 등을 통해서 적분 구간 역시 바꿀 수 있다. 유한 폼이 정의를 이용해 항의 갯수를 일반화 한 것과 달리 적분 폼은 함수가 적분 기호를 넘나드는 부등식이 된다. 증명 적분의 평균값 정리에 의해 어떤 상</description>
    </item>
    
    <item>
      <title>삼차원 유클리드 공간에서 외적이란</title>
      <link>https://freshrimpsushi.github.io/posts/outer-product-in-three-dimension/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/outer-product-in-three-dimension/</guid>
      <description>정의 $\mathbf{x}, \mathbf{y} \in \mathbb{R}^3$ 에 대해 다음을 $\mathbf{x}$와 $\mathbf{y}$ 의 외적 으로 정의한다. $$ \begin{align*} \mathbf{x} \times \mathbf{y} =&amp;amp; (x_{2}y_{3} - x_{3}y_{2}, x_{3}y_{1} - x_{1}y_{3}, x_{1}y_{2} - x_{2}y_{1}) \\ =&amp;amp; \det \begin{bmatrix} \mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} \\ x_{1} &amp;amp; x_{2} &amp;amp; x_{3} \\ y_{1} &amp;amp; y_{2} &amp;amp; y_{3} \end{bmatrix} \\ =&amp;amp; \begin{bmatrix} 0 &amp;amp; -x_{3} &amp;amp; x_{2} \\ x_{3} &amp;amp; 0 &amp;amp; -x_{1} \\ -x_{2} &amp;amp; x_{1} &amp;amp; 0 \end{bmatrix} \begin{bmatrix} y_{1} \\ y_{2} \\ y_{3} \end{bmatrix} \end{align*} $$ 설명 참고로 $\mathbf{i} = (1,0,0)$ , $ \mathbf{j} = (0,1,0)$ , $\mathbf{k} = (0,0,1)$ 이다. 내적과 마찬가지로 외적 역시 더욱 일반적인 정의는 가능하지만 실</description>
    </item>
    
    <item>
      <title>유클리드 공간에서 내적이란</title>
      <link>https://freshrimpsushi.github.io/posts/inner-product-in-euclidean-space/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inner-product-in-euclidean-space/</guid>
      <description>정의 벡터공간 $V = \mathbb{R}^n$ 에 대해 $\mathbb{x}, \mathbb{y}, \mathbb{z} \in V$ 그리고 $k \in \mathbb{R}$ 이라고 하자. $\left&amp;lt; \cdot , \cdot \right&amp;gt; : V^2 \to \mathbb{R}$ 가 아래 네 조건들을 만족시킬 때 $\left&amp;lt; \cdot , \cdot \right&amp;gt;$ 를 $V$ 상에서의 내적 으로 정의한다. (1) 대칭성: $\left&amp;lt; \mathbb{x} , \mathbb{y} \right&amp;gt; = \left&amp;lt; \mathbb{y}, \mathbb{x} \right&amp;gt;$ (2) 가산성: $\left&amp;lt; \mathbb{x} + \mathbb{y} , \mathbb{z} \right&amp;gt; = \left&amp;lt; \mathbb{x}, \mathbb{z} \right&amp;gt; + \left&amp;lt; \mathbb{y}, \mathbb{z} \right&amp;gt;$ (3) 동질성: $\left&amp;lt; k \mathbb{x} , \mathbb{y} \right&amp;gt; = k \left&amp;lt; \mathbb{x}, \mathbb{y} \right&amp;gt;$ (4) 정부호: $\left&amp;lt; \mathbb{x} , \mathbb{x} \right&amp;gt; \ge 0$ 그리고 $\left&amp;lt; \mathbb{x} , \mathbb{x} \right&amp;gt; =0 \iff \mathbb{x}=\mathbb{0}$ 특히</description>
    </item>
    
    <item>
      <title>행공간, 열공간, 영공간</title>
      <link>https://freshrimpsushi.github.io/posts/row-space-column-space-null-space-of-matrix/</link>
      <pubDate>Tue, 03 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/row-space-column-space-null-space-of-matrix/</guid>
      <description>정의1 $$ A = \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn} \end{bmatrix} $$ $m \times n$ 행렬 $A$에 대해서, $A$의 행으로 만들어지는 $m$개의 $\mathbb{R}^{n}$ 벡터들 $$ \begin{align*} \mathbf{r}_{1} =&amp;amp; \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \end{bmatrix} \\ \mathbf{r}_{2} =&amp;amp; \begin{bmatrix} a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \end{bmatrix} \\ &amp;amp;\vdots \\ \mathbf{r}_{m} =&amp;amp; \begin{bmatrix} a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn} \end{bmatrix} \end{align*} $$ 을 $A$의 행벡터row vectors라고 한다. $A$의 열로 만들어지는 $</description>
    </item>
    
    <item>
      <title>켤레 복소수</title>
      <link>https://freshrimpsushi.github.io/posts/definition-and-properties-of-complex-conjugate/</link>
      <pubDate>Sat, 23 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-and-properties-of-complex-conjugate/</guid>
      <description>정의 $z$ 를 $z=a+ib(a,b\in \mathbb{R})$인 복소수라고 하자. $\overline{z}$ 를 다음과 같이 정의하고 $z$ 의 켤레 복소수Complex Conjugatre라고 한다. $$ \overline{z}:=\overline{a+ib}=a-ib $$ 설명 원래 복소수에 $i$ 대신 $-i$ 를 대입한 것, 복소 평면에서 실수 축으로 대칭이동한 것 등으로 설명할 수 있다. 켤레라는 말은 더해서 실수를 만들어내는 한 쌍이라는 점 때문에 붙은 이름으로 보인다.</description>
    </item>
    
    <item>
      <title>생성함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/generating-function/</link>
      <pubDate>Wed, 30 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/generating-function/</guid>
      <description>정의 수열 $\left\{ a_{n} \right\}$ 에 대해 $$ g(x) =\sum \limits _{n=0}^{\infty}a_{n}x^{n}= a_{0} + a_{1} x + a_{2} x^2 + \cdots $$ 와 같은 꼴로 나타나는 함수 $g$를 수열 $\left\{ a_{n}\right\}$ 의 생성함수 또는 간단히 생성함수라 한다. 수열이 $a_{n}=a_{n}(x)$인 경우 아래와 같이 표기하기도 한다. $$ G(x,t)=\sum \limits _{n=0}^{\infty}a_{n}(x)t^{n} $$ 설명 예리한 독자라면 눈치챘겠지만 테일러 급수 역시 저 비슷한 꼴을 하고 있다. 예리하지 못한 독자라도 고등학교때</description>
    </item>
    
    <item>
      <title>바이어슈트라스 M 판정법</title>
      <link>https://freshrimpsushi.github.io/posts/weierstrasss-m-test/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weierstrasss-m-test/</guid>
      <description>정리 1 함수 $f_{n}$ 와 $z \in A$ 에 대해 $|f_{n}(z)| \le M_{n}$ 을 만족하는 양수의 수열 $M_{n}$ 이 존재하고 $\displaystyle \sum_{n=1}^{\infty} M_{n}$ 이 수렴하면 $\displaystyle \sum_{n=1}^{\infty} f_{n}$ 은 $A$ 에서 절대수렴하고 균등수렴한다. 설명 M 판정법이라는 이름은 수열 $M_{n}$ 에서 따온 것이다. 이미 수렴한다는 사실을 아는 $M_{n}$ 을 잘 가져와 함수의 절댓값과 부등식을 세울 수 있으면 그냥 수렴도 아니고 절대수렴과 균등수렴을 동시에 보일 수 있어 유용한 정리다</description>
    </item>
    
    <item>
      <title>복소해석을 사용한 테일러 급수 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-taylor-expansion-by-complex-analysis/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-taylor-expansion-by-complex-analysis/</guid>
      <description>정리 1 함수 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 원 $|z - \alpha| &amp;lt; r$ 에서 해석적이면 $$ f(z) = \sum_{n = 0} ^{\infty} {{f^{(n)} (\alpha)} \over {n!}} (z - \alpha)^n $$ 설명 수학의 즐거움 중 하나가 바로 일반화다. 테일러 정리부터가 평균값의 정리를 일반화했다고 할 수 있는데, 이번엔 실수를 복소수로 확장해보자. 재미있는 사실은 꾸역꾸역 확장하는 게 아니라 사실상 처음부터 쌓아올림에도 불구하고 증명은 더 간단해졌다는 것이</description>
    </item>
    
    <item>
      <title>로체의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-roches-theorem/</link>
      <pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-roches-theorem/</guid>
      <description>정리 1 $f$ 와 $g$ 가 단순폐경로 $\mathscr{C}$ 에서 해석적이고 $\mathscr{C}$ 상에서 $|g(z)| &amp;lt; |f(z)|$ 을 만족하면 $f$ 와 $f + g$ 는 $\mathscr{C}$ 내부에서 같은 수의 영점을 갖는다. 설명 원래 주어진 함수를 $h = f + g$ 로 생각하고 $f$ 와 $g$ 로 잘 분리해서 쓰는 정리다. 특히 다항함수의 경우엔 이러한 조작이 아주 쉽기 때문에 유용하게 써먹을 수 있다. 또한 수치해석적인 방법과 함께라면 방정식 $h(z) = 0$ 의 해가 구체적</description>
    </item>
    
    <item>
      <title>유리형함수의 영점과 극점</title>
      <link>https://freshrimpsushi.github.io/posts/poles-and-zeros-of-meromorphic-function/</link>
      <pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poles-and-zeros-of-meromorphic-function/</guid>
      <description>정리 1 단순폐경로 $\mathscr{C}$ 에서 해석적인 함수 $f$ 가 $\mathscr{C}$ 내부에서 $Z$개의 영점과 $P$개의 극점을 갖고 $\mathscr{C}$ 상에서 $f(z) \ne 0$ 이라고 하자. 그러면 $$ {{1} \over {2 \pi i }} \int_{\mathscr{C}} {{f &#39; (z)} \over {f(z)}} dz = Z - P $$ $Z$ 와 $P$ 는 중복되는 수를 모두 더한 수다. 설명 $f$ 가 극점을 갖지 않는다면 방정식 $f(z) = 0$ 의 해의 갯수를 구하는 공식이 될 것이다. 눈여겨봐야할 점은 정수가 등장했다는 것이다.</description>
    </item>
    
    <item>
      <title>슈발츠 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-schwarzs-lemma/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-schwarzs-lemma/</guid>
      <description>정리 1 단위원 $|z| \le 1$ 에서 해석적인 함수 $f$ 에 대해 $f(0) = 0$이고 $0 &amp;lt; |z| &amp;lt; 1$ 에서 $|f(z)| \le 1$ 이라고 하자. 그러면 $0 &amp;lt; |z| &amp;lt; 1$ 에서 $$ |f &#39; (0)| \le 1 \\ |f(z)| \le |z| $$ 증명 물론 일반성을 잃지 않고 $|z| \le r$ 로 확장할 수 있지만 증명의 편의를 위해 단위원을 잡았다. 새로운 함수 $g$ 를 $\displaystyle g(z) := \cases{ {{f(z)} / {z}} &amp;amp; , 0&amp;lt;|z|&amp;lt;1 \\ f &#39;(0) &amp;amp; , z=0}$ 와 같이 정의하자. $\displaystyle \lim_{z \to 0} {{f(z)} \over {z}} = f &#39;(0)$ 이므로 $g$ 는 단</description>
    </item>
    
    <item>
      <title>푸아송 적분 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-poissons-integral-formula/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-poissons-integral-formula/</guid>
      <description>공식 1 $f$ 가 원 $\mathscr{C}: |z| = r$ 을 포함하는 단순연결영역에서 해석적이라고 하자. 그러면 $0 &amp;lt; \rho &amp;lt; r$ 에 대해 $$ f( \rho e ^{i \phi} ) = {{1} \over { 2 \pi }} \int_{0}^{2 \pi} {{r^2 - \rho^2 } \over {r^2 - 2 r \rho \cos (\theta - \phi) + \rho ^2 }} f(r e^{i \theta}) d \theta $$ 본질적으로 코시 적분 공식의 변형이다. 무수한 잔계산을 거칠 뿐이기 때문에 과정은 한 번 읽어보는 것 외에 큰 가치는 없다. 유도 먼저 $\mathscr{C}$ 내부의 $f(\alpha) \ne 0$ 를 만족하는</description>
    </item>
    
    <item>
      <title>가우스의 평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-gausss-mean-value-theorem/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-gausss-mean-value-theorem/</guid>
      <description>정리 함수 $f$ 가 닫힌 원 $| z - z_{0} | \le r$ 에서 해석적이라고 하자. 그러면 $$ f(z_{0}) = {{1} \over {2 \pi}} \int_{0}^{2 \pi} f(z_{0} + r e ^{i \theta } ) d \theta $$ 설명 미분의 평균값 정리가 일반화를 거치며 여러 수학자의 이름이 붙은 변형 정리를 낳았듯, 적분의 평균값 정리도 무려 가우스의 이름이 붙은 변형이 있다. 그 형태는 의심할나위 없는 적분의 평균값 정리지만 개념을 잘 생각해보면 마냥 당연하지</description>
    </item>
    
    <item>
      <title>최대절댓값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-maximum-modulus-theorem/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-maximum-modulus-theorem/</guid>
      <description>정리 1 함수 $f$ 가 단순폐경로 $\mathscr{C}$ 상에서 연속이고 내부에서 해석적이면서 어떤 점에서도 상수함수가 아니라고 하자. 그러면 $\mathscr{C}$ 에서 $|f(z)|$ 를 가장 크게 하는 $z = z_{0}$ 는 $\mathscr{C}$ 상에 존재한다. 설명 쉽게 말해 복소해석에서는 폐경로 내에서 $|f|$ 의 최댓값은 그 테두리에 존재한다는 것이다. 이쯤되면 직관적으로는 따라잡을 수가 없는 수준으로, 왜인지는 모르겠으나 참 신기하다</description>
    </item>
    
    <item>
      <title>대수학의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-algebra/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-algebra/</guid>
      <description>정리 1 $n$차 다항식 $P(z) = a_{0} + a_{1} x + a_{2} x^2 + \cdots + a_{n} x^{n} = 0$ 은 중근을 포함해서 정확히 $n$개의 해를 갖는다. 설명 사실 우리는 다항식을 풀 때 당연히 해가 존재하는마냥 풀고있지만 그게 꼭 그렇다는 보장은 없을 수 있다. 예로써 2차 다항식 $x^2+1 = 0$은 실근이 존재하지 않는다. 하지만 여기서 복소수를 허용하면 $\pm i$ 라는 두 해가 존재함을 알 수 있다. 팩트로</description>
    </item>
    
    <item>
      <title>복소해석에서의 리우빌의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-complex-analysis/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-liouvilles-theorem-in-complex-analysis/</guid>
      <description>정리 1 $f$ 가 전해석함수고 모든 $z \in \mathbb{C}$ 에 대해 $|f(z)| \le M$ 을 만족하는 양수 $M$ 이 존재하면 $f$ 는 상수함수다. 설명 $f$ 가 전해석함수이라는 말은 복소평면 전체에서 해석적이라는 뜻이다. 대우명제로 말하자면 상수함수가 아니면 그 절댓값이 유계Bounded가 되지 않는다는 뜻이다. 예로써 $\sin$ 은 정의역이 실수집합일 땐 자명하게도 $-1$ 과 $1$ 에 바운드되어있지만,</description>
    </item>
    
    <item>
      <title>프레넬 사인 적분의 매클로린 전개</title>
      <link>https://freshrimpsushi.github.io/posts/maclaurin-expansion-of-fresnel-sine-integral/</link>
      <pubDate>Sat, 12 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maclaurin-expansion-of-fresnel-sine-integral/</guid>
      <description>공식 $$ S(x) = \sqrt{{2} \over {\pi}} \int_{0}^{x} \sin (w^2) dw = \sqrt{{2} \over {\pi}} \sum_{n=0}^{\infty} {{(-1)^{n}} \over {(2n+1)! (4n+3)}} x^{4n+3} $$ 설명 프레넬은 광학을 연구했던 물리학자로써 그의 이름이 붙은 결과들을 보면 대개는 삼각함수가 연관되어있다. 아무래도 삼각함수가 파동함수와 깊은 연관이 있기 때문에 없는 공식은 만들어내서라도 공부를 해야했을 것이다. 이러한 연구들이 광학에 어찌 기여했는지는 몰라도 당장 삼각함수에 대한 미적분</description>
    </item>
    
    <item>
      <title>프레넬 적분 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fresnels-integral/</link>
      <pubDate>Sat, 12 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fresnels-integral/</guid>
      <description>정리 1 $$ \int_{0}^{\infty} \cos x^2 dx = \int_{0}^{\infty} \sin x^2 dx = {{1}\over{2}} \sqrt{{\pi}\over{2}} $$ 설명 프레넬 적분은 언뜻 쉬워 보이지만 보이는것만큼 간단한 결과가 아니다. 단순히 삼각함수의 제곱이라면 쉽겠지만 그 안의 $x$ 에 제곱을 취한 것이기 때문이다. 막상 건드려보면 이 $x$ 가 얼마나 사라지지 않는지 알 수 있을 것이다.함수 안의 변수가 핵심 문제기 때문에 그래프의 개형부터 잘 떠오르지 않는다. 일단 이상적분</description>
    </item>
    
    <item>
      <title>e^-x^2꼴의 정적분, 가우스 적분, 오일러-푸아송 적분</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-integral/</link>
      <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-integral/</guid>
      <description>정리 가우스 함수 $f(x)=e^{-x^2}$ 의 전체 영역에 대한 적분은 다음과 같다. $$ \int_{-\infty}^{\infty} e^{-x^2} dx= \sqrt{\pi} $$ 설명 위 적분을 가우스 적분Gaussian integral, 혹은 오일러-푸아송 적분Euler-Poisson integral이라고 부른다. 고등학생에겐 충격적인 적분이자 특히 통계학에선 어마어마하게 중요한 적분이기도 하다. 그도 그럴 것이 고등학교 과정 내에서는 원시함수를 구</description>
    </item>
    
    <item>
      <title>이항정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-binomial-theorem/</link>
      <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-binomial-theorem/</guid>
      <description>정리 $$ (x+y)^{n} = \sum_{r=0}^{n} {_n C _r} x^{r} y^{n-r} $$ 설명 고등학교에서 배우는 것 치고는 놀랍게도 배우자마자 여러군데 쓸데가 보이는 정리다. 생김새가 자유롭기 때문에 많은 공식을 단번에 유도해낼 수 있으며 분야를 가리지 않고 많이 쓰인다. 증명 $(x+y)^{n}$ 을 전개할 때 $x^{r} y^{n-r}$ 의 계수는 $$ (x+y)^{n} = (x+y)(x+y)(x+y) \cdots (x+y) $$ 의 각 $(x+y)$ 중에서 $x$를 $n$개, $y$를 $n-r$개 선택하는 것과 같다. 따라서 조</description>
    </item>
    
    <item>
      <title>모레라의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-moreras-theorem/</link>
      <pubDate>Wed, 09 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-moreras-theorem/</guid>
      <description>정리 1 함수 $f$ 가 단순연결영역 $\mathscr{R}$ 에서 연속이고 $\mathscr{R}$ 내부의 모든 폐경로 $\mathscr{C}$ 에 대해 $\displaystyle \int_{\mathscr{C}} f(z) dz = 0$ 을 만족하면 $f$ 는 $\mathscr{R}$ 에서 해석적이다. 설명 코시 정리의 역 정도로 생각할 수 있겠다. 재미있는 점은 원래 &amp;lsquo;미분가능하면 연속, 연속이면 적분가능&amp;rsquo;이 원래 해석학의 상식이라는 사실이다. 그런데 모레라의 정리는 오히려 적분을 통해 함수</description>
    </item>
    
    <item>
      <title>코시 적분 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-cauchys-integral-formula/</link>
      <pubDate>Wed, 09 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-cauchys-integral-formula/</guid>
      <description>정리 1 함수 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 단순연결영역 $\mathscr{R}$ 에서 해석적이라고 하자. $\mathscr{R}$ 내부의 단순폐경로 $\mathscr{C}$ 가 어떤 점 $\alpha$ 를 둘러싸고 있다면 $$ f(\alpha) = {{1} \over {2 \pi i }} \int_{\mathscr{C}} {{f(z)} \over { z - \alpha }} dz $$ 유도 우선 $\displaystyle 2 \pi i = \int_{\mathscr{C&amp;rsquo;}} {{1} \over { z - \alpha }} dz$ 임을 보이자. 복소경로적분의 수축 보조정리: $\mathscr{C}$ 내부에서 $\alpha$ 를 중심으로 하는 원 $\mathscr{C&amp;rsquo;}$ 에 대해 $$\int_{\mathscr{C}} f(z) dz = \int_{\mathscr{C&amp;rsquo;}} f(z) dz$$ $\displaystyle \int_{\mathscr{C}} {{1} \over { z - \alpha }} dz$ 의 적분구간</description>
    </item>
    
    <item>
      <title>미적분학의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-calculus/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-calculus/</guid>
      <description>정리1 함수 $f$ 가 폐구간 $[a,b]$ 에서 연속이라고 하자. (1) 함수 $\displaystyle F(x) = \int_{a}^{x} f(t) dt$ 는 $[a,b]$ 에서 연속, $(a,b)$ 에서 미분가능하며 $\displaystyle {{dF(x)} \over {dx}} = f(x)$ 를 만족한다. (2) $f$ 의 임의의 부정적분 $F$ 에 대해 $\displaystyle \int_{a}^{b} f(x) dx = F(b) - F(a)$ 설명 물론 우리야 미분, 적분이라는 단어를 사용하기 때문에 이들 사이의 관계를 쉽게 짐작할 수 있다. 하지만 영어로는 differential과 integral</description>
    </item>
    
    <item>
      <title>적분의 평균값 정리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem-for-integral/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem-for-integral/</guid>
      <description>정리 폐구간 $[a,b]$ 에서 함수 $f$ 가 연속이라고 하면 $\displaystyle f(c) = {{1}\over {b-a} } \int_{a}^{b} f(x) dx$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 설명 평균값의 정리와 유사하지만 말 그대로 적분에 사용되기 때문에 이런 이름이 붙었다. 사용법 역시 매우 유사하고 활용도도 결코 평균값의 정리에 뒤지지 않는다. 한편 함수의 평균값을 우변과 같이 정의하는 걸 생각해보면 오히려 이 쪽이 평균값의 정</description>
    </item>
    
    <item>
      <title>복소경로적분의 수축 보조정리</title>
      <link>https://freshrimpsushi.github.io/posts/shrinking-lemma-of-complex-contour-integral/</link>
      <pubDate>Mon, 07 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shrinking-lemma-of-complex-contour-integral/</guid>
      <description>정리 1 단순폐경로 $\mathscr{C}$ 를 포함하는 단순연결영역에서 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 $\mathscr{C}$ 내부의 점 $\alpha$ 를 제외한 모든 점에서 해석적이라고 하자. 그러면 $\mathscr{C}$ 내부에서 $\alpha$ 를 중심으로 하는 폐곡선 $\mathscr{C&amp;rsquo;}$ 에 대해 $$ \int_{\mathscr{C}} f(z) dz = \int_{\mathscr{C&amp;rsquo;}} f(z) dz $$ 설명 말은 긴데 결국 말하자면 폐경로에서 복소적분을 할 땐 어떤 점을 중심으로 그 폐경로를 수축시킬 수 있다는 말이다.적분구간을 이렇게나 마음대로 바꿀 수</description>
    </item>
    
    <item>
      <title>복소해석에서의 코시 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cauchys-theorem/</link>
      <pubDate>Mon, 07 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cauchys-theorem/</guid>
      <description>정리 1 단순폐경로 $\mathscr{C}$와 그 내부에서 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 해석적이고 $f &#39;$ 가 연속이라고 하자. 그러면 $$ \int_{\mathscr{C}} f(z) dz = 0 $$ 증명 $a \le t \le b$ 에 대해 $$ z(t) = x(t) + i y(t) \\ f(z) = u(x,y) + i v(x,y) $$ 라고 하면 $\displaystyle {{dz} \over {dt}} = x&amp;rsquo; + i y&amp;rsquo;$ 이므로 $$ \begin{align*} f(z)dz =&amp;amp; f(z) (x&amp;rsquo; + i y&amp;rsquo;) dt \\ =&amp;amp; (u + i v ) ( x&amp;rsquo; + i y&amp;rsquo; ) dt \\ =&amp;amp; (u x&amp;rsquo; - v y&amp;rsquo;) + i (v x&amp;rsquo; + u y&amp;rsquo;) dt \end{align*} $$ $\displaystyle x&amp;rsquo; = {{dx} \over {dt}}$ 이고</description>
    </item>
    
    <item>
      <title>특정한 분포를 따르는 확률변수들의 덧셈 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/sum-of-some-probability-distribution/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-of-some-probability-distribution/</guid>
      <description>정리 확률 변수 $X_{1} , \cdots , X_{n}$ 들이 상호 독립이라고 하자. [1] 이항 분포: $X_i \sim \text{Bin} ( n_{i}, p)$ 이면 $$ \displaystyle \sum_{i=1}^{m} X_{i} \sim \text{Bin} \left( \sum_{i=1}^{m} n_{i} , p \right) $$ [2] 푸아송 분포: $X_i \sim \text{Poi}( m_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \text{Poi} \left( \sum_{i=1}^{n} m_{i} \right) $$ [3] 감마 분포: $X_i \sim \Gamma( k_{i}, \theta)$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \Gamma \left( \sum_{i=1}^{n} k_{i} , \theta \right) $$ [4] 카이제곱 분포: $X_i \sim \chi^2 ( r_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \chi ^2 \left( \sum_{i=1}^{n} r_{i} \right) $$ [5] 정규 분포: $X_i \sim N( \mu_{i}, \sigma_{i}^{2} )$ 이면 주어진 벡터 $(a_{1} ,</description>
    </item>
    
    <item>
      <title>등비수열의 부분합들도 등비수열임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/partial-sum-of-geometric-sequence-is-geometric-sequence/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partial-sum-of-geometric-sequence-is-geometric-sequence/</guid>
      <description>정리 등비수열 $a_n = a r^{n-1}$과 그 부분합 $\displaystyle S_n = \sum_{k=1}^{n} a_k$ 그리고 어떤 자연수 $m$ 에 대해 $A_n = S_{mn} - S_{m(n-1)}$ 은 등비수열이다. 설명 모르면 정말 고생한다. 예를 들어, 2의 거듭제곱을 세개씩 끊어 더한 수열을 생각해보면$(1 + 2+ 4)= 7 $, $(8 + 16 + 32)=56$, $(64+128+256)=448 \cdots$ 는 초항이 7이고 공비가 8인 등비수열이다. 이러한 성질은 등차수열도 가지고 있다. 원리야 사실 단순하</description>
    </item>
    
    <item>
      <title>등차수열의 부분합들도 등차수열임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/partial-sum-of-arithmetic-sequence-is-arithmetic-sequence/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partial-sum-of-arithmetic-sequence-is-arithmetic-sequence/</guid>
      <description>정리 등차수열 $a_n = a + (n-1)d$과 그 부분합 $\displaystyle S_n = \sum_{k=1}^{n} a_k $ 그리고 어떤 자연수 $m$ 에 대해 $A_n = S_{mn} - S_{m(n-1)} $은 등차수열이다. 설명 모르면 정말 고생한다. 예를 들어, 자연수를 세 개씩 끊어 더한 수열을 생각해보면$(1 + 2+ 3)= 6 $, $(4+5+6)=15$, $(7+8+9)=24 \cdots$ 는 초항이 6이고 공차가 9인 등차수열이다. 이러한 성질은 등비수열도 가지고 있다. 원리야 사실 단순하니까 한번 꼼</description>
    </item>
    
    <item>
      <title>싱크함수의 오일러 표현 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-eulers-representation-of-sinc-function/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-eulers-representation-of-sinc-function/</guid>
      <description>정의 $$ \text{sinc} x = {{\sin x} \over {x}} $$ 정리: 오일러 표현 $$ \text{sinc} x = \prod_{n=1}^{\infty} \left( 1 - {{x^2} \over { \pi^2 n^2}} \right) $$ 설명 싱크함수란 $\sin x$ 을 $x$로 나눈 함수로써, 별도의 이름이 붙은만큼 유용한 구석이 많은 함수다. 교과 과정부터 그 이름만 모를 뿐 극한이나 연속 파트에 종종 등장하기도 한다. 물론 싱크함수는 $x=0$ 에서 정의되지 않지만 다들 잘 알듯 $\displaystyle \lim_{x \to 0} {{\sin x} \over {x}} = 1$ 이므로, 정말 엄밀하</description>
    </item>
    
    <item>
      <title>오일러의 반사 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-eulers-reflection-formula/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-eulers-reflection-formula/</guid>
      <description>공식 정수가 아닌 $p$ 에 대해 $$ {\Gamma (1-p) \Gamma ( p )} = { {\pi} \over {\sin \pi p } } $$ 설명 감마함수를 이용한 공식 중 가장 유명한 공식이다. 반사 공식으로 얻을 수 있는 유용한 결과로는 $ \Gamma ( { 1 \over 2} ) = \sqrt{\pi}$ 이 있다. 그래서일까? 반사 공식이라는 이름 또한 $\frac{1}{2}$ 에 대해 반사 시킨다는 의미에서 붙었다고 한다. 유도 바이어슈트라스의 무한곱: $$ {1 \over \Gamma(p)} = p e^{\gamma p } \prod_{n=1}^{\infty} \left( 1 + {p \over</description>
    </item>
    
    <item>
      <title>제곱수의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/sum-of-square-number/</link>
      <pubDate>Fri, 28 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-of-square-number/</guid>
      <description>공식 $$\displaystyle \sum_{k=1}^{n} { k^2} = {{n(n+1)(2n+1)} \over {6}}$$ 유도 한 차수 더 높은 $k^3$와 $(k-1)^3$ 의 차를 생각해보자. $$ 1^3 - 0^3 = 3 \cdot 1^2 - 3 \cdot 1 + 1 \\ 2^3 - 1^3 = 3 \cdot 2^2 - 3 \cdot 2 + 1 \\ 3^3 - 2^3 = 3 \cdot 3^2 - 3 \cdot 3 + 1 \\ \vdots \\ n^3 - (n-1)^3 = 3n^2 - 3n + 1 $$ 양변을 각각 모두 더하면 $$ n^3 - 0^3 = 3 \sum_{k=1}^{n} { k^2} - 3 \sum_{k=1}^{n} { k} + n $$ 우리는 자연수의 합이 $\displaystyle \sum_{k=1}^{n} {k} = {{n(n+1)} \over {2}}$ 임을 알고 있다. 위의 식을 $\displaystyle \sum_{k=1}^{n} { k^2}$ 에 대해</description>
    </item>
    
    <item>
      <title>감마함수에 대한 바이어슈트라스의 무한곱</title>
      <link>https://freshrimpsushi.github.io/posts/weierstrasss-infinite-product-for-gamma/</link>
      <pubDate>Wed, 26 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weierstrasss-infinite-product-for-gamma/</guid>
      <description>정리 $$ {1 \over \Gamma(x)} = x e^{\gamma x } \lim_{n \to \infty} \prod_{k=1}^{n} \left( 1 + {x \over k} \right) e^{- {x \over k} } $$ $\gamma$ 는 오일러-마스케로니 상수다. 설명 $$ \Gamma(x) = \int_{0}^{\infty} t^{x-1} e^{-t} dt $$ 감마 함수는 위와 같이 정의되고, 오일러의 극한 공식에 의해 $$ \Gamma(x) = \lim_{n \to \infty} {{n^x n!} \over {x(x+1)(x+2) \cdots (x+n) }} $$ 이기도 하다. 여기서 한가지 더, 감마함수의 새로운 형태가 바로 바이어슈트라스의 무한곱이다. 이걸 배움으로써 우리는 감마함수의 가장</description>
    </item>
    
    <item>
      <title>실수의 조밀성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-density-of-real-numbers/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-density-of-real-numbers/</guid>
      <description>정리 두 실수 $a&amp;lt;b$ 에 대해 $a&amp;lt;r&amp;lt;b$ 를 만족하는 $r \in \mathbb{R}$ 이 존재한다 설명 실수상에선 그 어떤 구간을 생각하든 그 사이엔 반드시 또 다른 실수가 존재한다. 아무리 작게 쪼개더라도 그곳엔 또 쪼갤 수 있는 점이 있다는 말이다. 당연해보이지만 이는 당연하지 않을 뿐만 아니라 몹시 추상적인 성질이라는 것도 명심하자. 예로써 물리학에서 다루는 물질과 에너지조차도 작게 작게 쪼개</description>
    </item>
    
    <item>
      <title>해석학의 여러가지 급수판정법 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/series-convergence-test/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-convergence-test/</guid>
      <description>급수판정법들은 별도의 증명 없이 소개만 하고자 한다.증명하는 법 자체보단 팩트로써 잘 활용하는 것이 중요하기도 하고, 대개는 증명 과정도 지루하기 때문이다. 발산 판정법 $\displaystyle \lim _{ n\to \infty }{ { a }_{ n }} \ne 0$ 이면 $\displaystyle \sum _{ n=1 }^{ \infty }{ { a }_{ n }}$ 은 발산한다. 고등학교 때 접할 수 있는 유일한 판정법이다.쉬운만큼 수렴하는 것 자체를 판정할 수는 없는 것이 아쉽지만</description>
    </item>
    
    <item>
      <title>해석학에서 아르키메데스의 원리</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-archimedean-principle/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-archimedean-principle/</guid>
      <description>정리 양수 $a$ 와 실수 $b$ 에 대해, $an&amp;gt;b$ 를 만족하는 자연수 $n$ 이 존재한다. 설명 어떤 $b$를 가져오더라도 항상 그보다는 큰 $a$ 의 $n$ 배수를 생각할 수 있다는 뜻이다. 쉽게 말하면 아무리 &amp;lsquo;작은 수라도 계속 더하면 계속 커진다&amp;rsquo;는 아주 상식적이고 당연한 원리다.부력의 원리, 유레카와는 상관이 전혀 없고 이름만 같을 뿐이다. 증명 Strategy: 증</description>
    </item>
    
    <item>
      <title>해석학의 세 가지 공리: 3 완비성 공리</title>
      <link>https://freshrimpsushi.github.io/posts/completeness-axioms/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/completeness-axioms/</guid>
      <description>공리1 집합 $E \subset \mathbb{R}$ 이 공집합이 아니고 $E$ 가 위로 유계면 상한 $\sup(E) &amp;lt; \infty$ 가 존재한다. 설명 체 공리와 순서 공리는 이미 알던 걸 어렵게 다시 썼지만 완비성 공리는 언뜻 보기에 그렇지가 않다. 우선 여기 등장하는 단어들에 대해서 정의가 필요할 것 같다. 정의 $E$ 의 모든 원소 $a$ 에 대해 $a \le M$ 이 성립하면 $E$를 위로 유계bounded above라 하한다. 이러한 조</description>
    </item>
    
    <item>
      <title>해석학의 세 가지 공리: 1 체 공리</title>
      <link>https://freshrimpsushi.github.io/posts/field-axioms/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/field-axioms/</guid>
      <description>공리1 실수 $a,b,c \in \mathbb{R}$ 와 연산 $+,\cdot$ 에 대해 다음의 성질들이 성립한다고 받아들이자. (A1) 덧셈에 대한 폐쇄성: $a+b \in \mathbb{R}$ (A2) 덧셈에 대한 결합법칙: $(a+b) + c = a + (b+c)$ (A3) 덧셈에 대한 교환법칙: $ a+ b= b + a$ (A4) 덧셈에 대한 항등원: 모든 실수 $a$ 에 대해, $a+0=0+a=a$를 만족하는 $0$ 이 유일하게 존재한다. (A5) 덧셈에 대한 역원: 모든 실수 $a$ 에 대해, $a + (-a) = (-a)</description>
    </item>
    
    <item>
      <title>해석학의 세 가지 공리: 2 순서 공리</title>
      <link>https://freshrimpsushi.github.io/posts/order-axioms/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order-axioms/</guid>
      <description>공리1 실수 $ a,b,c \in \mathbb{R}$ 에 대해, 다음의 성질들이 성립한다고 받아들이자. 삼분성: 주어진 $a,b$ 에 대해서, $a&amp;lt;b$ 혹은 $a&amp;gt;b$ 혹은 $a=b$ 이어야한다 추이성: $a&amp;lt;b$ 이고 $b&amp;lt;c$이면 $a&amp;lt;c$ 가산성: $a&amp;lt;b$ 이고 $c\in \mathbb{R}$ 이면 $a+ c&amp;lt; b + c$ 승산성: $a&amp;lt;b$ 이고 $c&amp;gt;0$ 이면 $ac&amp;lt; bc$, 혹은 $c&amp;lt;0$ 이면 $ac&amp;gt; bc$ 설명 단어들은 상당히 옛날것이지만 너무 당연한 사실들이라 이해하는데는 문제가 없을 것이다. 체</description>
    </item>
    
    <item>
      <title>등비수열의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-geometric-series-formula/</link>
      <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-geometric-series-formula/</guid>
      <description>공식 초항이 $a$ 고 공비가 $r$인 등비수열 $a_{n} = a r^{n-1}$ 에 대해, $$ \sum_{k=1}^{n} a_{k}= {{a (1- r^{n} ) } \over {1-r}} $$ 증명 $\displaystyle S= \sum_{k=1}^{n} a_{k}$ 라고 하자. 그러면 $$ S= a + ar + \cdots + ar^{n-2} + ar^{n-1} $$ 양변에 $r$ 을 곱하면 $$ rS= ar + a r^2 + \cdots + ar^{n-1} + ar^{n} $$ 여기서 위의 두 식에 대해서 양변을 빼면 $$ S - rS = (1-r)S = a- a r^n $$ 오른쪽의 두 식을 $1-r$로 나누면 $$ S=\sum_{k=1}^{n} a_{k}= {{a (1- r^{n} ) } \over {1-r}} $$ ■ 설명 등차수열의 합과는 달</description>
    </item>
    
    <item>
      <title>등차수열의 합 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-arithmetic-series-formula/</link>
      <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-arithmetic-series-formula/</guid>
      <description>공식 🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 초항이 $a$ 고 공차가 $d$ 인 등차수열 $a_{n} = a+(n-1)d$ 에 대해 $$ \sum_{k=1}^{n} a_{k}= {{n \left\{ 2a + (n-1)d \right\} } \over {2}} $$ 설명 처음에 한 번 보고는 다시 이 형태로 쓸 일이 없긴 한 급수지만 이 모양을 잊되 증명을 잊어서는 안 된다. 증명이 쉽고 간단하다고 해도 한번정도는 반드시 손으로 직접 쓰면서 익혀보도록 하자. 등차수열의 합 중 가장 자주쓰이</description>
    </item>
    
    <item>
      <title>쌍곡함수의 미분법</title>
      <link>https://freshrimpsushi.github.io/posts/derivatives-of-hyperbolic-function/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivatives-of-hyperbolic-function/</guid>
      <description>정리1 $$ \left( \sinh x \right)^{\prime} = \cosh x $$ $$ \left( \cosh x \right)^{\prime} = \sinh x $$ $$ \left( \tanh x \right)^{\prime} = \text{sech}^{2} x $$ 설명 쌍곡함수의 미분법은 사실 증명할 것도 외울 것도 별로 없다. 증명은 그냥 단순히 정의를 이용할 뿐이고 모양새도 삼각함수에서 부호만 뗀 정도기 때문이다. 하이퍼볼릭 사인에 대한 증명법으로 하이퍼볼릭 코사인의 도함수도 쉽게 구할 수 있다. 하이퍼볼릭 탄젠트의 도함수는 분수의 미분</description>
    </item>
    
    <item>
      <title>역삼각함수의 미분법</title>
      <link>https://freshrimpsushi.github.io/posts/derivatives-of-inverse-trigonometric-function/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivatives-of-inverse-trigonometric-function/</guid>
      <description>정리1 $$ \left( \sin^{-1}x \right)^{\prime} = {{1} \over {\sqrt{1-x^2}}} $$ $$\left( \cos^{-1}x \right)^{\prime} = -{{1} \over {\sqrt{1-x^2}}}$$ $$\left( \tan^{-1}x \right)^{\prime} = {{1} \over {1+x^2}} $$ 설명 각각 아크사인, 아크코사인, 아크탄젠트 로 읽는다. 세상에 이런 것도 미분이 되나 싶지만 알고보면 생각보다 꽤 단순하다. 우변을 보면 알겠지만 도함수들의 모양이 그닥 생소하거나 복잡하지가 않다. 삼각함수와는 전혀 상관 없을지라도 여기저기서 쓰일데가 많으니 증명은 외워두도록 하자</description>
    </item>
    
    <item>
      <title>그린의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-greens-theorem/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-greens-theorem/</guid>
      <description>정리1 곡선 $\mathcal{C}$ 가 평면 상의 영역 $S = [a,b] \times [c,d]$ 안에서 시계반대방향을 가지고 조각마다 스무스한 단순 폐경로라고 하자. 함수 $P,Q : \mathbb{R}^2 \to \mathbb{R}$ 이 $\mathcal{C}$ 에서 연속이고 그 도함수도 연속이면 $$ \int_{\mathcal{C}} (Pdx + Qdy) = \iint_{S} (Q_{x} - P_{y}) dx dy $$ 설명 경로적분을 면적분으로 바꿔주는 정리로 생각하면 될 것 같다. 케빈-스톡스 정리에서 평면에 국한시킨 따름정리로도 많이 알려져있다. 더 일반화된</description>
    </item>
    
    <item>
      <title>푸비니의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fubinis-theorme/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fubinis-theorme/</guid>
      <description>정리1 2 2차원 영역 $R : [a,b] \times [c,d]$ 에 대해 함수 $f : R \to \mathbb{R}$ 을 정의하자. $f(x,\cdot)$ 가 $[c,d]$ 에서 적분가능하고 $f(\cdot,y)$ 가 $[a,b]$ 에서 적분가능하며 $f$ 가 $R$ 에서 적분가능하면 $$ \iint _{R} f dA = \int_{a}^{b} \int_{c}^{d} f(x,y) dy dx = \int_{c}^{d} \int_{a}^{b} f(x,y) dx dy $$ 설명 적분영역인 $R$ 은 당연히 Rectangle에서 나온 것이다. 해석학이 늘 그렇듯 말이 너무 길어서 읽기 싫은 여러분들을 위해 요약하자면, 직교하는 두 방향으</description>
    </item>
    
    <item>
      <title>ML 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-ml-lemma/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-ml-lemma/</guid>
      <description>정리 1 함수 $f$ 가 적분경로 $\mathscr{C}: z = z(t), t \in [a,b]$ 에서 조각마다 연속라고 하자. 양수 $\displaystyle L = \int_{a}^{b} |z&amp;rsquo;(t)| dt$ 는 $\mathscr{C}$ 의 길이고, $\mathscr{C}$ 상의 모든 점에 대해 $|f(z)| \le M$ 을 만족하는 양수 $M$ 이 존재한다면 $$ \left| \int_{\mathscr{C}} f(z) dz \right| \le ML $$ 증명 함수 $z&amp;rsquo;: [a,b] \to \mathbb{C}$ 에 대해 $\displaystyle \left| \int_{a}^{b} z&amp;rsquo;(t) dt \right| = r$ 이라 하자. $r \ne 0$ 이면 $\displaystyle \int_{a}^{b} z&amp;rsquo;(t) dt = r e^{i \theta}$ 로 나타낼 수 있다. 그러면 $\theta$ 는 상수이므로 $$ r = \int_{a}^{b} e^{- i \theta} z&amp;rsquo;(t) dt \le \int_{a}^{b} \left| e^{- i</description>
    </item>
    
    <item>
      <title>코시-리만 방정식의 역이 성립하는 조건</title>
      <link>https://freshrimpsushi.github.io/posts/condition-for-converse-of-cauchy-riemann-equation-hold/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/condition-for-converse-of-cauchy-riemann-equation-hold/</guid>
      <description>정리 함수 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 실수값을 가지는 함수 $u,v$ 에 대해 $f(z) = f(x+iy) = u(x,y) + iv(x,y)$ 로 나타날 수 있고 $u,v$ 는 $x,y$ 에 대한 연속일차편도함수가 존재하는 동시에 연립미분방정식 $$ \begin{cases} u_{x} (x,y) = v_{y} (x,y) \\ u_{y} (x,y) = -v_{x} (x,y) \end{cases} $$ 을 만족한다면, $f$ 는 $A$ 에서 해석적이다. 설명 해석학은 항상 이렇게 말이 길어서 읽기도 싫은 게 문제다. 간단하게 요약하자면, 코시-리만 방정식의 역이 성립하</description>
    </item>
    
    <item>
      <title>피타고라스의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pythagorean-theorem/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pythagorean-theorem/</guid>
      <description>정리 직각삼각형의 빗변의 길이를 $c$, 나머지 두 변의 길이를 $a,b$라고 하면 아래의 식이 성립한다. $$ a^2 + b^2 = c^2 $$ 설명 여기저기서 쓰이는 건 둘째치고 그 자체만으로도 매우 실용적인 정리다. 가장 오래된 &amp;lsquo;증명&amp;rsquo;을 남긴 것이 피타고라스기 때문에 그 이름이 붙었지만, 실제로 문명을 이루었다고 할 수 있는 고대인들 대부분 팩트</description>
    </item>
    
    <item>
      <title>드 무아브르의 정리를 이용한 삼각함수의 삼배각 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-triple-angle-formula-using-de-moivres-theorem/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-triple-angle-formula-using-de-moivres-theorem/</guid>
      <description>공식 $$ \sin 3\theta = 3 \sin \theta - 4 \sin^{3} {\theta} \\ \cos 3\theta = 4 \cos^{3} {\theta} - 3 \cos \theta $$ 설명 기존의 변형 공식들은 보통 삼각함수의 덧셈정리를 여러번 써서 얻을 수 있었다. 예를 들어 배각 공식은 $\sin(a + b ) = \sin {a} \cos {b} + \sin {b} \cos {a}$ 에서 $b=a$ 를 대입해 $\sin(a+a) = \sin{2a} = 2 \sin{a} \cos{a}$ 을 얻는 식이다. 물론 이런 방식으로 삼배각, 사배각 공식을 유도하는 것 자체는 아무런 문제가 없다. 하지만 복소해석을 이용하</description>
    </item>
    
    <item>
      <title>복소해석에서 삼각함수와 쌍곡함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-of-trigonometric-and-hyperbolic-in-complex-analysis/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-of-trigonometric-and-hyperbolic-in-complex-analysis/</guid>
      <description>정의 1 쌍곡함수 $\sinh$ 와 $\cosh$ 를 아래와 같이 정의하자. $$ \sinh z := { {e^{z} - e^{-z}} \over 2 } \\ \cosh z := { {e^{z} + e^{-z}} \over 2 } $$ 정리 2 $$ \begin{align*} \sinh (iz) =&amp;amp; i \sin z \\ \sin (iz) =&amp;amp; i \sinh z \\ \cosh (iz) =&amp;amp; \cos z \\ \cos (iz) =&amp;amp; \cosh z \end{align*} $$ 설명 쌍곡함수를 처음 접할때 가장 이해가 되지 않는 것이 바로 &amp;lsquo;왜 이런 정의를 쓰는가&amp;rsquo; 하는 점이다. 실수 상에서 삼각함수는 단위원의 삼각비로 정의</description>
    </item>
    
    <item>
      <title>복소해석에서 삼각함수와 지수함수의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relation-of-trigonometric-and-exponential-in-complex-analysis/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relation-of-trigonometric-and-exponential-in-complex-analysis/</guid>
      <description>정리 1 $$ \sin z = { {e^{iz} - e^{-iz}} \over 2 i } \\ \cos z = { {e^{iz} + e^{-iz}} \over 2 } $$ 설명 사실 정리라기보단 그냥 정의라고 생각해도 좋다. 이렇게 정의를 했을 때 기존에 밝혀진 정리들과 충돌이 없다 것을 보이기 위함이다. 증명 또한 이미 오일러 공식으로 알고 있던 것을 삼각함수에 맞게 정리한 것 뿐이다. 증명 오일러 공식 $\displaystyle { e }^{ ix }= \cos x + i \sin x$ 에 의해 $$ \begin{cases} { e }^{ iz }= \cos z +</description>
    </item>
    
    <item>
      <title>코시-리만 방정식</title>
      <link>https://freshrimpsushi.github.io/posts/the-cauchy-riemann-equations/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-cauchy-riemann-equations/</guid>
      <description>정리 1 함수 $f: A \subseteq \mathbb{C} \to \mathbb{C}$ 가 $\mathscr{R}$ 에서 해석적이라고 하자. 만약 실함수 $u,v$ 에 대해 $$ f(z) = f(x+iy) = u(x,y) + iv(x,y) $$ 이라면 $u,v$ 는 $x,y$ 에 대한 일차편도함수가 존재하며 $\mathscr{R}$ 상의 모든 점에서 아래의 연립미분방정식을 만족시킨다. $$ \begin{cases} u_{x} (x,y) = v_{y} (x,y) \\ u_{y} (x,y) = -v_{x} (x,y) \end{cases} $$ 요약 코시-리만 방정식은 아래와 같이 요약된다. $$ \begin{align*} f &#39;(z) =&amp;amp; u_x + i v_x \\ =&amp;amp; v_y - i u_y \\ =&amp;amp; u_x -i u_y \\ =&amp;amp; v_y + i v_x \end{align*}</description>
    </item>
    
    <item>
      <title>오일러-마스케로니 상수의 수렴성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-convergence-of-euler-mascheroni-constant/</link>
      <pubDate>Sun, 16 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-convergence-of-euler-mascheroni-constant/</guid>
      <description>정리 $$ \gamma = \lim_{n \to \infty} \left( \sum_{k=1}^{n} \left( { 1 \over k } \right) - \ln{n} \right) = 0.577215664 \cdots $$ 설명 리만-제타 함수와 연관짓자면 $\gamma$ $0$번째 스틸체스 상수 $\gamma_{0}$ 기도 하다. $\gamma$ 는 짧게는 그냥 오일러 상수 라고도 불리는 수로써, 감마 함수와 깊은 관계가 있다. 정확한 값은 둘째치고, 일단 수렴을 하기는 하는걸까? $\ln{n}$ 와 조화급수 $\displaystyle \sum_{k=1}^{n} \left( { 1 \over k } \right)$ 가 발산하므로 $$ \lim_{n \to \infty} \left( \sum_{k=1}^{n} \left( { 1 \over k } \right) -</description>
    </item>
    
    <item>
      <title>감마함수에 대한 오일러의 극한 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-eulers-limit-formula-for-gamma/</link>
      <pubDate>Sat, 15 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-eulers-limit-formula-for-gamma/</guid>
      <description>공식 $$ \Gamma(x) = \lim_{n \to \infty} {{n^x n!} \over {x(x+1)(x+2) \cdots (x+n) }} $$ 설명 기존에 알고 있던 감마함수는 $\displaystyle \Gamma(x) = \int_{0}^{\infty} t^{x-1} e^{-t} dt$ 의 모양이다. 전혀 닮지 않았지만 두 표현이 완전히 같음을 1729년에 오일러가 증명해냈다. 이 글에서 소개하려는 유도는 원래보다는 조금 약식이지만 이해하는데에 본질적인 문제는 없을 것이다. 유도 $\displaystyle \Gamma_{n}(x) := \int_{0}^{n} t^{x-1} \left( 1 - { t \over n } \right) ^{n} dt$ 이라고 하면 $\displaystyle e^{-t} = \lim_{n \to \infty }</description>
    </item>
    
    <item>
      <title>적분을 이용한 타원의 넓이 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/finding-area-of-ellipse-using-integral/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finding-area-of-ellipse-using-integral/</guid>
      <description>공식 타원 $\displaystyle {x^2 \over a^2} + {y^2 \over b^2} = 1$ 의 넓이는 $ab \pi$ 이다. 설명 특히 $a=b=r$, 즉 반지름이 $r$ 인 원 $x^2 + y^2=r^2$ 의 넓이는 익히 아는대로 $r^2 \pi$ 다. 증명 타원의 넓이를 구하기 위해선 색칠된 영역의 넓이만 구하면 충분하다. 영역의 넓이는 $$ \int _{0} ^{a} \sqrt{b^2-{b^2 \over a^2} x^2} dx $$ 로 주어진다. $x = a \sin \theta$ 로 치환을 하면 $$ \begin{align*} \int _{0} ^{ \pi \over 2 } b \sqrt{1 - \sin ^ 2 \theta } a \cos \theta d \theta =&amp;amp; ab \int _{0} ^{ \pi \over 2 } \cos ^2</description>
    </item>
    
    <item>
      <title>실수의 허수승의 크기는 항상 1이다</title>
      <link>https://freshrimpsushi.github.io/posts/mudulus-of-imaginary-number-power-of-real-number-is-1/</link>
      <pubDate>Thu, 29 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mudulus-of-imaginary-number-power-of-real-number-is-1/</guid>
      <description>정리 $0$ 이 아닌 실수 $r, \theta$ 에 대해 $$ \left| r^{i \theta} \right| = 1 $$ 설명 흔히 $\left| e^{i \theta} \right| = 1$ 는 잘 숙지하고 있지만 밑이 딱히 $e$ 가 아닌 어떤 실수라도 상관없다는 건 떠올리기 어렵다. 생각해보면 당연히 성립이야하겠지만 이렇게는 잘 쓸 일이 없어서다. 증명 $\theta = 0$ 이면 $r^0=1$ 이므로 당연히 $\left| r^{i \theta} \right| = \left| r^{i \cdot 0} \right| = 1$ 이 성립한다. $\theta \ne 0$ 이면 $$ \left| r^{i \theta} \right| = \left| e^{i \theta \ln r} \right| = \left| e^{i \theta</description>
    </item>
    
    <item>
      <title>미적분학에서의 오일러 공식</title>
      <link>https://freshrimpsushi.github.io/posts/euler-formula-in-calculus/</link>
      <pubDate>Tue, 23 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euler-formula-in-calculus/</guid>
      <description>정리 오일러 공식: $$ { e }^{ ix }= \cos x + i \sin x $$ 오일러 등식: $$ { e }^{ i\pi }+1=0 $$ 설명 오일러 공식Euler&amp;rsquo;s Formula은 그 형태 자체가 워낙 기이해서 오일러 본인조차 어디다 쓰일지는 몰랐다고 하는데, 현대에는 너무나 많은 분야에서 활용되고 있어 요약을 하기가 어려울 정도로 유용한 공식이 되었다. 허수라는 것이 학계에서 아직 잘</description>
    </item>
    
    <item>
      <title>정수론에서의 합동</title>
      <link>https://freshrimpsushi.github.io/posts/congruence-in-number-theory/</link>
      <pubDate>Thu, 11 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/congruence-in-number-theory/</guid>
      <description>정의 1 $a \equiv b \pmod{m}$ $\iff$ 정수 $a$, $b$, $m$ 에 대해 $a = b + mk$ 를 만족하는 정수 $k$ 가 존재한다. 정리 $a_{1} \equiv b_{1} \pmod{m}$ 과 $a_{2} \equiv b_{2} \pmod{m}$ 이 성립한다고 하자. [1] 덧셈: $a_{1} + a_{2} \equiv b_{1} + b_{2} \pmod{m}$ [2] 뺄셈: $a_{1} - a_{2} \equiv b_{1} - b_{2} \pmod{m}$ [3] 곱셈: $a_{1} a_{2} \equiv b_{1} b_{2} \pmod{m}$ [4] 나눗셈: $\gcd ( c , m ) = 1$ 이면 $$ ac \equiv bc \pmod{m} \implies a \equiv b \pmod{m} $$ [5] 모듈로끼리의 곱: $\gcd ( m_{1} , m_{2} ) = 1$ 이면 $$ \begin{cases} a \equiv b \pmod{ m_{1} } \\ a = b \pmod{ m_{2} } \end{cases}</description>
    </item>
    
    <item>
      <title>감마함수</title>
      <link>https://freshrimpsushi.github.io/posts/gamma-function/</link>
      <pubDate>Sun, 30 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gamma-function/</guid>
      <description>정의 다음과 같이 정의된 함수 $\Gamma$ 를 감마 함수라고 한다. $$ \Gamma(x) := \int_{0}^{\infty} t^{x-1} e^{-t} dt $$ 위 수식에서 적분에 초점을 두면 오일러 적분이라고도 부른다. 감마함수는 순수수학 뿐만 아니라 물리학, 통계학 등지에서 무척 중요한 함수로도 유명하다. 흥미로운 성질들을 매우 풍부하게 가지고 있으나 가장 대표적인 것은 팩토리얼을 실수에 대해 일반화하는 개념이라는 점이다. 정리</description>
    </item>
    
    <item>
      <title>아크탄젠트 함수의 급수전개</title>
      <link>https://freshrimpsushi.github.io/posts/series-expansion-of-arctangent-function/</link>
      <pubDate>Thu, 27 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/series-expansion-of-arctangent-function/</guid>
      <description>정리1 $$ \tan ^{ -1 } x = \sum _{ n=0 }^{ \infty }{ \frac { (-1) ^{ n } { x } ^ { 2n+1 } } { 2n+1 } } $$ 설명 $\arctan$으로 쓰든 $\tan ^{-1}$로 쓰든 상관없다. 여러 삼각함수의 역함수 중에서도 아크탄젠트가 특히 흥미로운 이유는 바로 $\pi$ 로 수렴하는 급수를 제공해주기 때문이다. $x=1$ 을 대입하면 $$ { \pi \over 4 } = \tan ^{-1} 1 = 1 - {1 \over 3} + {1 \over 5} - {1 \over 7} + \cdots $$ 양변</description>
    </item>
    
    <item>
      <title>이차행렬의 곱의 성분의 합을 쉽게 구하는 공식</title>
      <link>https://freshrimpsushi.github.io/posts/70/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/70/</guid>
      <description>공식 이차행렬 $\begin{bmatrix} { a }&amp;amp;{ b } \\ { c }&amp;amp;{ d } \end{bmatrix} \begin{bmatrix} { p }&amp;amp;{ q } \\ { r }&amp;amp;{ s } \end{bmatrix}$ 의 성분의 합은 다음과 같다. $$ {(a+c)(p+q)}+{(b+d)(r+s)} $$ 설명 두 이차행렬을 주고 그 곱의 성분의 합을 구하라는 문제를 많이 접해보았을 것이다. 다들 알겠지만 이 행렬을 곱한다는게 어렵지는 않지만 시간도 걸리고 여간 귀찮은게 아니다. 해서, 연산을 획기적으로 줄이는 공식을 소개한다. 유도 $$ \begin{bmatrix} a &amp;amp; b</description>
    </item>
    
    <item>
      <title>유클리드 호제법 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-euclidean-algorithm/</link>
      <pubDate>Thu, 20 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-euclidean-algorithm/</guid>
      <description>알고리즘 두 정수 $a \ge b$ 에 대해 $\text{gcd}(a,b)$ 는 다음과 같이 구할 수 있다. Step 1. 초기화 $r_i, i=1,2,3,\cdots$ 에 대해 $a=r_0, b=r_1$ 이라고 두자. Step 2. 반복법 $$ r_{i-1} = r_i \cdot q_i + r_{i+1} \qquad , (r_i&amp;gt;r_{i+1}) $$ 이 성립하도록 $q_i$ 와 새로운 $r_{i+1}$를 계속 구한다. Step 3. $r_{i+1}=0$ 일 때까지 반복하면 $r_i=\text{gcd}(a,b)$ 이다. 설명 이른바 유클리드 호제법Euclidean Algorithm으로 알려진 이 알고리즘은 최대공약수를</description>
    </item>
    
    <item>
      <title>합동방정식에 대한 대수학의 기본정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-algebra-for-congruence/</link>
      <pubDate>Thu, 20 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fundamental-theorem-of-algebra-for-congruence/</guid>
      <description>정리 1 어떤 소수 $p$ 에 대해 $p\nmid a_{ 0 }$ 라 하면 모든 계수가 정수인 다항식 $$ f(x)=a_{ 0 }x^{ d }+a_{ 1 }x^{ d-1 }+ \cdots +a_{ d-1 }x+a_{ d } $$ 에 대해 방정식 $f(x)\equiv 0 \pmod{p}$ 는 많아도 $d$ 개의 합동이 아닌 해를 가진다. 설명 그냥 흔히들 아는 것처럼 실계수를 갖는 다항식에 대해서 말하자면, $n$차 방정식은 중근을 포함해 $n$개의 해를 갖는다는 정리다. 이를 정수론에서 생각해보면 $\pmod{p}$ 에서 정수 계</description>
    </item>
    
    <item>
      <title>유클리드의 증명: 소수는 무한히 존재한다</title>
      <link>https://freshrimpsushi.github.io/posts/euclids-proof-of-the-infinitude-of-primes/</link>
      <pubDate>Sat, 15 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/euclids-proof-of-the-infinitude-of-primes/</guid>
      <description>정리 1 소수는 무한히 많이 존재한다. 설명 소수가 무한하다는 것을 증명하는 방법은 여러가지가 있다. 그 중에서도 가장 간단한 유클리드의 방법을 소개하도록 하겠다. 이 증명은 단순할 뿐만 아니라 매우 아름답기로도 유명하다. 증명 소수가 $n$ 개만 존재한다고 가정하자. $n$ 개의 소수들을 각각 $p_1, p_2, \cdots , p_n$ 이라고 하고 $p_{n+1}=p_1 p_2 \cdots p_n + 1$ 에 대해 생각해보자. 만약 $p_{n+1}$</description>
    </item>
    
    <item>
      <title>자연로그의 급수꼴 유도와 교대조화급수의 수렴성 증명</title>
      <link>https://freshrimpsushi.github.io/posts/expansion-of-natural-log-and-convergence-of-alternating-harmonic-series/</link>
      <pubDate>Tue, 11 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expansion-of-natural-log-and-convergence-of-alternating-harmonic-series/</guid>
      <description>정리 $$ \ln(1-x)=\sum _{ n=0 }^{ \infty }{ \frac { -{ x }^{ n+1 } }{ n+1 } } $$ 설명 $\ln(1-x)$ 의 급수꼴은 비교적 쉽게 구할 수 있다. $\ln(1+x)$의 경우는 정리의 결과로 얻은 식에 $x$ 대신 $-x$ 를 대입하면 된다. $$ -\ln(1-x)=x+\frac { { x }^{ 2 } }{ 2 }+\frac { { x }^{ 3 } }{ 3 }+\frac { { x }^{ 4 } }{ 4 }+ \cdots $$ 에 $x$ 대신 $(-x)$ 를 대입하면 $$ -\ln(1+x)=-x+\frac { { x }^{ 2 } }{ 2 }-\frac { { x }^{ 3 } }{ 3 }+\frac { { x }^{ 4 } }{ 4 }- \cdots $$ $$ \implies</description>
    </item>
    
    <item>
      <title>지수 함수 사인 함수 코사인 함수의 테일러 전개</title>
      <link>https://freshrimpsushi.github.io/posts/59/</link>
      <pubDate>Tue, 11 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/59/</guid>
      <description>정리1 $$ \begin{equation} { { e ^ x } }=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ n } }{ n! } } \end{equation} $$ $$ \begin{equation} \sin x=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ 2n+1 } }{ (2n+1)! }{ { (-1) }^{ n } } } \end{equation} $$ $$ \begin{equation} \cos x=\sum _{ n=0 }^{ \infty }{ \frac { { x } ^{ 2n } }{ (2n)! }{ { (-1) }^{ n } } } \end{equation} $$ 설명 지수 함수, 사인 함수, 코사인 함수의 매클로린 급수는 어려운 테크닉을 사용하지 않고 쉽게 구할 수 있다. 이 셋을 잘 합치면 바로 그 유명한 오일</description>
    </item>
    
    <item>
      <title>근의 공식 유도 무작정 따라하기</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-quadratic-formula/</link>
      <pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-quadratic-formula/</guid>
      <description>공식 이차방정식 $ax^{2}+bx+c=0$ (단, $a\neq 0$)에 대해 $$ x=\dfrac{ -b\pm \sqrt { b^{2}-4ac } }{2a} $$ 설명 이차방정식이 주어졌을 때 그 근은 공식을 통해 쉽게 구할 수 있다. 유도 전략: 공식 유도의 핵심은 바로 &amp;lsquo;완전제곱꼴로 만드는 것&amp;rsquo;이다. 수학이 낯선 어린이 친구들을 위해 가능한 세세하게 풀어서 썼다. 말 그대로 무작정 따라하면 되니까 베껴 적는다고 생각하고 여</description>
    </item>
    
    <item>
      <title>무한급수가 수렴하면 무한수열은 0으로 수렴함을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-the-infinite-series-converges-to-zero-when-it-converges/</link>
      <pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-the-infinite-series-converges-to-zero-when-it-converges/</guid>
      <description>정리 $\displaystyle \sum _{ n=1 }^{ \infty }{ { a }_{ n }}$ 이 수렴하면 $\displaystyle \lim _{ n\to \infty }{ { a }_{ n }}=0$ 설명 처음 접하면 직관과 달라 조금 당황스러울 수 있는 정리로, 왜 역이 성리하지 않는지 궁금할 수 있다. 그 대표적인 반례로는 다음과 같은 수열을 생각해볼 수 있다. $$ \begin{align*} { a }_{ n }&amp;amp;=\frac { 1 }{ n } \\ { b }_{ n }&amp;amp;=\sqrt { n }-\sqrt { n-1 } \end{align*} $$ 두 수열 모두 0으로 수렴하지만 그 합은 무한대로 발산한다. 첫</description>
    </item>
    
    <item>
      <title>회전변환 행렬의 거듭제곱 공식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-power-square-formula-of-the-rotational-transform-matrix/</link>
      <pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-power-square-formula-of-the-rotational-transform-matrix/</guid>
      <description>정리 모든 자연수 $n$ 에 대해 다음이 성립한다. $$ \begin{bmatrix} { \cos \theta }&amp;amp;{ -\sin \theta } \\ { \sin \theta }&amp;amp;{ \cos \theta } \end{bmatrix} ^{n} = \begin{bmatrix} { \cos n\theta }&amp;amp;{ -\sin n\theta } \\ { \sin n\theta }&amp;amp;{ \cos n\theta } \end{bmatrix} $$ 설명 원점을 중심으로 $\theta$만큼 회전하는 일차변환의 행렬을 $n$제곱하면 $n\theta$만큼 회전하는 일차변환이 된다. 증명 전략: 상식적으로도 당연하고, 수학적 귀납법을 이용해 쉽게 증명할 수</description>
    </item>
    
    <item>
      <title>분수 함수의 역함수와 이차정사각 행렬의 역행렬의 모양</title>
      <link>https://freshrimpsushi.github.io/posts/53/</link>
      <pubDate>Wed, 05 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/53/</guid>
      <description>정리 분수함수 $\displaystyle f(x)=\frac { ax+b }{ cx+d }$ 의 역함수는 $$ f^{ -1 }(x)=\frac { dx-b }{ -cx+a } $$ 2차 정사각행렬 $\begin{bmatrix} a &amp;amp; b \\ c &amp;amp; d \end{bmatrix}$ 의 역행렬은 $$ \frac { 1 }{ ad-bc } \begin{bmatrix} d &amp;amp; -b \\ -c &amp;amp; a \end{bmatrix} $$ 설명 단순한 우연의 일치일지도 모르겠지만, 이런 우연을 찾는 것 또한 수학의 즐거움이다. 행렬이 교과 과정에서 없어졌다고는 하지만 얼마든지 유용하게 쓸 수 있는 사실이다. 증명 $$ \begin{align*} &amp;amp; y=\frac { ax+b }{ cx+d }</description>
    </item>
    
    <item>
      <title>포물선의 접선의 방정식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/finding-the-equation-of-parabolic-tangents/</link>
      <pubDate>Wed, 05 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/finding-the-equation-of-parabolic-tangents/</guid>
      <description>유도 기울기가 주어진 경우 우선은 기울기가 주어진 경우를 먼저 보도록 하자. 포물선 $y^{ 2 }=4px$ 에 접하는 직선의 방정식이 $y=mx+n$일 때, 두 도형은 한 점에서만 만나야 하므로 $$ (mx+n)^{ 2 }=4px \implies m^{ 2 }x^{ 2 }+2(mn-2p)x+n^{ 2 }=0 $$ 근의 공식에 따라 $$ \frac { D }{ 4 }=m^{ 2 }n^{ 2 }-4mnp+4p^{ 2 }-m^{ 2 }n^{ 2 }=0 $$ 위 식을 정리하면 $n=\frac { p }{ m }$ 이고, 이를 직선의 방정식에 대입하면 포물선에 접하는 직</description>
    </item>
    
    <item>
      <title>코시-슈바르츠 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cauchy-schwarz-inequality/</link>
      <pubDate>Mon, 03 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cauchy-schwarz-inequality/</guid>
      <description>정리 $$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\ge { (ax+by) }^{ 2 } $$ 증명 $$ \begin{align*} &amp;amp; ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})-{ (ax+by) }^{ 2 } \\ =&amp;amp; {a}^{2}{x}^{2}+{b}^{2}{x}^{2}+{a}^{2}{y}^{2}+{b}^{2}{y}^{2}-{ (ax+by) }^{ 2 } \\ =&amp;amp; {b}^{2}{x}^{2}+{a}^{2}{y}^{2}-2axby \\ =&amp;amp; { (ay-bx) }^{ 2 } \\ \ge&amp;amp; 0 \end{align*} $$ 이므로, 정리하면 다음을 얻는다. $$ ({a}^{2}+{b}^{2})({x}^{2}+{y}^{2})\ge { (ax+by) }^{ 2 } $$ ■ 설명 빠르게는 고등학교 과정부터 접하게 되는 부등식으로, 분야를 가리지 않고 여러 곳에서 쓰이고 있다. 대수적인 증명은 매우 간단하다. 증명과정에서 알 수 있듯 등호가 성립하는 경우는 $ay-bx</description>
    </item>
    
    <item>
      <title>한 직선과 x축 y축으로 둘러싸인 삼각형의 넓이</title>
      <link>https://freshrimpsushi.github.io/posts/50/</link>
      <pubDate>Mon, 03 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/50/</guid>
      <description>개요 최댓값 혹은 최솟값, 접선을 구할 수 있는가를 묻는 문제 등에서 꽤 자주 나오는 것이 이런 삼각형의 넓이 $S$ 다. 물론 삼각형의 넓이를 구하는 건 어렵지 않지만 간단한 공식의 형태로 기억해 바로바로 풀 수 있다면 더 좋을 것이다. 정리 직선 $y=mx+n$ 의 $y$절편은 $n$, $x$절편은 $-\frac { n }{ m }$이다. 이 직선과 $x$축, $y$축으로 둘러싸인 삼각형의 넓이는 다</description>
    </item>
    
    <item>
      <title>포커 족보별 경우의 수 확률 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/probability-of-each-poker-hand-ranking/</link>
      <pubDate>Wed, 29 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-of-each-poker-hand-ranking/</guid>
      <description>문양과 끗수의 정의 확률 이전에 포커 자체를 잘 모른다면 족보를 찾아서 알아보는 걸 추천한다. 확률을 구하기에 앞서 두 가지 정의를 내리자: 문양: 집합 {♠,◇,♤,♣}의 원소 끗수: 집합 {A,2,3,4,5,6,7,8,9,10,J,Q,K}의 원소 만약 두 가지 이상의 족보를 동시에 만족하면 높은 걸 따른다. 아래의 확률들은 5장을 뽑고 그때</description>
    </item>
    
    <item>
      <title>삼각함수의 덧셈정리 여러가지 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-angle-sum-and-difference-identities-of-trigonometric-function/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-angle-sum-and-difference-identities-of-trigonometric-function/</guid>
      <description>정리 $$ \sin\left( \alpha +\beta \right) =\sin\alpha \cos\beta +\cos\alpha \sin\beta \\ \sin\left( \alpha -\beta \right) =\sin\alpha \cos\beta -\cos\alpha \sin\beta \\ \cos\left( \alpha +\beta \right) =\cos\alpha \cos\beta -\sin\alpha \sin\beta \\ \cos\left( \alpha -\beta \right) =\cos\alpha \cos\beta +\sin\alpha \sin\beta \\ \tan\left( \alpha +\beta \right) =\frac { \tan\alpha +\tan\beta }{ 1-\tan\alpha \tan\beta } \\ \tan\left( \alpha -\beta \right) =\frac { \tan\alpha -\tan\beta }{ 1+\tan\alpha \tan\beta } $$ 증명 코사인 법칙을 이용한 증명 피타고라스의 정리에 의해 $$ \begin{align*} {\overline { AB } } ^{ 2 } =&amp;amp; {( \cos \alpha -\cos \beta )}^{ 2 }+{(\sin\alpha -\sin\beta )}^{ 2 } \\ =&amp;amp; 2-2 \cos \alpha \cos \beta –2 \sin \alpha \sin \beta \end{align*} $$ 제2코사인 법칙에 의해 $$ \begin{align*} { \overline { AB } } ^{ 2 } =&amp;amp; 1^{</description>
    </item>
    
    <item>
      <title>자연로그의 거듭제곱의 적분법</title>
      <link>https://freshrimpsushi.github.io/posts/integration-of-power-of-natural-log/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integration-of-power-of-natural-log/</guid>
      <description>공식 $$ \int {{(\ln x)}^{ n }} dx=x{{(\ln x)}^{ n }}-\int n{{(\ln x)}^{ n-1 }}dx $$ 설명 적분 문제를 풀다보면 심심치 않게 보게 되는 유형이다. 이런 문제들을 풀 때 정직하게 부분적분으로 풀면 시간을 너무 많이 빼앗긴다. 우선은 규칙부터 찾아보도록 하자. $f(n)=\int {{(\ln x)}^{ n }} dx$ (단, $n=1,2,3&amp;hellip;$)이라 할 때 $$ \begin{align*} f(1) =&amp;amp; x(\ln|x|-1)+C \\ f(2) =&amp;amp; x{(\ln|x|)^{ 2 }-2\ln|x|+2}+C \\ f(3) =&amp;amp; x{(\ln|x|)^{ 3 }-3(\ln|x|)^{ 2 }+6\ln|x|-6}+C \\ f(4) =&amp;amp; x{(\ln|x|)^{ 4 }-4(\ln|x|)^{ 3 }+12(\ln|x|)^{ 2 }-24\ln|x|+24}+C \end{align*}</description>
    </item>
    
    <item>
      <title>로피탈의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lhospitals-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lhospitals-theorem/</guid>
      <description>정리1 $f(x)$ 와 $g(x)$ 가 $x=a$ 의 근방에서 미분가능하고 $g&#39;(x) \ne 0$ 이며 $\displaystyle \lim _{x \to a} f(x) = \lim _{x \to a} g(x) = 0$ 이면 $$ \lim _{x \to a} {{f(x)} \over {g(x)}} = \lim _{x \to a} {{f &#39; (x)} \over {g&#39;(x)}} $$ 설명 수험생들에게는 마검같은 정리로 이미 수 많은 고등학생들이 배워서 써먹고 있으나, 개인적으로 수능을 몇 달 앞두기 전엔 알아도 봉인해두고 가능한 정석대로 푸는 게 좋다고 생각한다. 사실 이 정리를 처음으로 증명한</description>
    </item>
    
    <item>
      <title>미분적분학에서 롤의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rolles-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rolles-theorem/</guid>
      <description>정리1 함수 $f(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 미분가능하며 $f(a)=f(b)$ 면 $f &#39; (c)=0$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 설명 고등학교 과정에선 평균값의 정리만을 증명하기 위한 보조정리 정도로 소개되고 실제로 그 외엔 전혀 쓰이지 않지만, 고등학교 수준을 벗어나서는 종종 보조정리로써 사용될 때가 있다. 평균값의 정리가 더욱 일반적인 것은 사실이지만, $\displaystyle f &#39;(c) =</description>
    </item>
    
    <item>
      <title>미분적분학에서 평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mean-value-theorem/</guid>
      <description>정리1 함수 $f(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 미분가능하면 $\displaystyle f &#39;(c)={{f(b)-f(a)}\over{b-a}}$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 설명 그냥 자주 쓰는 정도가 아니라 MVT라는 약어도 사용할 정도로 유명한 정리다. 평균값이라는 말은 미분계수가 전구간의 평균변화율과 같아지는 점이 있다는 센스에서 따온 것이다. 평균이라는 개념이 유용한만큼 다양한 분야에 적용시키기 위해 여러</description>
    </item>
    
    <item>
      <title>우함수와 기함수</title>
      <link>https://freshrimpsushi.github.io/posts/even-function-and-odd-function/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/even-function-and-odd-function/</guid>
      <description>정의 $f(-x) = f(x)$ 를 만족하는 함수 $f(x)$ 를 우함수Even라고 한다. $f(-x) = -f(x)$ 를 만족하는 함수 $f(x)$ 를 기함수Odd라고 한다. 설명 우함수는 좌표평면에서 $y$ 축에 대칭인 함수, 기함수는 원점 $O$ 에 대칭인 함수를 말한다. 예시로 삼각함수 중 기함수인 $\sin$과 우함수인 $\cos$ 을 들 수 있겠다. $\sin$ 을 미분하면 $\cos$이, $\cos$ 을 미분하면 $\sin$ 이 된다. 별 필요 없어보</description>
    </item>
    
    <item>
      <title>코시의 평균값 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cauchys-mean-value-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cauchys-mean-value-theorem/</guid>
      <description>정리1 함수 $f(x), g(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 미분가능하며 $g&#39;(x) \ne 0$이면 $$ {{f &#39; (c)}\over{g&#39;(c)}}={{f(b)-f(a)}\over{g(b)-g(a)}} $$ 를 만족하는 $c$ 가 $(a,b)$ 에 적어도 하나 존재한다. 설명 보통 평균값 정리와 달라진 게 있다면 그냥 함수가 하나 더 늘어난 것이다. $g(x) = x$ 로 본다면 이 $g$ 가 더 자유로워졌다는 의미에서 평균값 정리의 일반화라고 할 수 있다. 증명 롤의 정리의 대우 $g&#39;(c)=0$ 를 만족하는 $c$ 가 $(a,b)$ 에 존재하지 않으면</description>
    </item>
    
    <item>
      <title>테일러 급수와 매클로린 급수</title>
      <link>https://freshrimpsushi.github.io/posts/taylor-series-and-maclaurin-series/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/taylor-series-and-maclaurin-series/</guid>
      <description>정리1 함수 $f$ 가 점 $a$ 근방에서 무한히 미분가능하고, $\displaystyle f(x) = \sum_{n=0}^{\infty} {{f^{(n)} (a)}\over{n!}} {(x-a)}^n$ 일 필요충분조건은 어떤 $\xi \in \mathscr{H} \left\{ x , a \right\}$ 에 대해 $$ \lim_{n \to \infty} {{f^{(n)} (\xi)}\over{n!}} {(x-a)}^n = 0 $$ $\xi \in \mathscr{H} \left\{ x , a \right\}$ 라 함은 $\xi$ 가 $(x,a)$ 혹은 $(a,x)$ 에 있다는 표현이다. 설명 테일러 정리는 함수가 한 없이 미분가능할 때 흔히 무한급수의 꼴로 표현된다. 이를 테일러 급수라 하며, 특히 $a=0$인 경우 매클로린 급수라 부</description>
    </item>
    
    <item>
      <title>테일러 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-taylors-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-taylors-theorem/</guid>
      <description>정리[^1] 함수 $f(x)$ 가 $[a,b]$ 에서 연속이고 $(a,b)$ 에서 $n$ 번 미분가능하면 $$ \begin{align*} f(b) =&amp;amp; \sum_{k=0}^{n-1} {{(b-a)^{k}\over{k!}}{f^{(k)}( a )}} + {(b-a)^{n}\over{n!}}{f^{(n)}(\xi)} \\ =&amp;amp; {f(a)} + {(b-a)f &#39; (a)} + \cdots + {(b-a)^{n-1}\over{(n-1)!}}{f^{(n-1)}(a)} + {(b-a)^{n}\over{(n)!}}{f^{(n)}(\xi)} \end{align*} $$ 를 만족하는 $\xi \in (a,b)$ 가 존재한다. 설명 수학 전반에서 너무나 중요하게 쓰이고 있는 정리로, 이 이름을 딴 테일러 급수가 있다. 미분을 $n$ 번 한다는 의미에서는 평균값의 정리를 일반화한 정리라고 볼 수 있다. 관례적으로, 테일러 정리를</description>
    </item>
    
    <item>
      <title>페르마의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-fermats-theorem/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-fermats-theorem/</guid>
      <description>정리1 함수 $f(x)$ 가 $x=c$ 에서 극대 혹은 극소면서 $f &#39; (c)$ 가 존재하면 $f &#39; (c) = 0$ 설명 보통 고등학교 교과서엔 롤의 정리까지만 소개되어 있으나 롤의 정리를 엄밀하게 증명하기 위해서는 극점에서의 미분계수가 왜 $0$ 인지를 보일 수 있어야하고, 페르마의 정리가 그것을 보장한다. 증명 Strategy: 극대와 극소 두가지 경우로 나누어서 증명한다. Case 1. $f(x)$ 가 $x=c$ 에서 극대 충분히 작은</description>
    </item>
    
    <item>
      <title>다양한 삼각함수의 적분법</title>
      <link>https://freshrimpsushi.github.io/posts/31/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/31/</guid>
      <description>개요 적분 문제를 풀다보면 삼각함수의 적분을 상당히 많이 하게 된다. 그리고 이 적분법들에 익숙해지면 삼각함수도 다항함수처럼 빠르게 적분할 수 있다. 시컨트 함수의 적분법, 코시컨트 함수의 적분법 $$ \begin{align*} \int \sec x dx =&amp;amp; \int \frac { \sec x (\sec x +\tan x ) }{ (\sec x +\tan x ) }dx \\ =&amp;amp; \int \frac { \sec^{ 2 }x+\sec x \tan x }{ \tan x +\sec x }dx \end{align*} $$ $ (\tan x )\prime =\sec^{ 2 }x$ 이고 $(\sec x )\prime =\sec x \tan x$ 이므로 $$ \int \sec x</description>
    </item>
    
    <item>
      <title>두 사건이 독립이면 여사건끼리도 독립임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/28/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/28/</guid>
      <description>정리 다음은 서로 동치다. $$ P(A \cap B) = P(A)P(B) \\ P(A \cap B^c)=P(A)P(B^c) \\ P(A^c \cap B)=P(A^c)P(B) \\ P(A^c \cap B^c)=P(A^c)P(B^c) $$ 설명 알아두면 큰 도움이 되는 팩트일 뿐만이 아니라 공식으로써도 유용하다. 증명 $P(A \cap B) = P(A)P(B)$ 이라 가정하자. 다시 말해, 사건 $A$, $B$ 는 독립이다. 여사건의 성질에 따라 $$ P(A)=1-P(A^{ c }) \\ P(B)=1-P(B^{ c }) $$ 이므로 $P(A \cap B) = P(A)P(B)$ 의 우변은 $$ \begin{align*} P(A)P(B)&amp;amp;=(1-P(A^{ c }))(1-P(B^{ c })) \\ =&amp;amp; 1-P(A^{ c })-P(B^{ c })+P(A^{ c })P(B^{ c }) \end{align*} $$ 이고, 좌변은 드 모르</description>
    </item>
    
    <item>
      <title>두 사건이 서로 배반이면 서로 종속임을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/27/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/27/</guid>
      <description>정리 두 사건 $A,B$ 에 대해 $B=A^c$ 면 $P(A\cap B) \neq P(A)P(B)$ 설명 굳이 수식을 통한 증명이 없더라도 상식적으로 배반이면 독립일 리가 없다. 한 사건이 일어났을 때 다른 사건이 일어나지 않는다는 것은 이미 영향을 미치다는 말이기 때문이다. 다만 이것을 알고 모르고는 참 거짓을 판별하는 문제를 풀 때 아주 큰 차이가 있다. 증명 두 사건 $A,B$ 에 대해 $P(A)&amp;gt;0, P(B)&amp;gt;0$ 라 하자.이때 두 사건은 서로 배반이므로</description>
    </item>
    
    <item>
      <title>베이즈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</guid>
      <description>정리 1 표본공간 $S$ 와 사건 $A$ 에 대해서 ${S_1,S_2,&amp;hellip;,S_n}$ 가 $S$ 의 분할이면 $$ P(S_k|A)=\frac { P(S_k)P(A|S_k) }{ \sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$ 설명 혹은 베이즈 법칙으로도 불리는 이 정리는 두개의 법칙만 쓰면 될 정도로 쉽게 증명할 수 있으나 그 응용은 어마어마하다. 이른바 베이지안 패러다임은 통계학 자체를 양분하는 사고방식으로써, 그 중요도는 몇 번을 강조해도 부족함이 없다. 우리가 알고 싶은 것은 위 식</description>
    </item>
    
    <item>
      <title>이차함수의 극점 빠르게 구하기</title>
      <link>https://freshrimpsushi.github.io/posts/30/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/30/</guid>
      <description>공식 이차함수 $f(x)=c(x-a)(x-b)$ 의 극점은 $\frac { a+b }{ 2 }$ (단, $c\neq 0$) 인수분해가 가능한 이차함수의 경우에는 굳이 이런 저런 계산할 것 없이 극점을 알 수 있다.생각해보면 당연하지만, 이 사실을 아느냐 모르느냐에 따라 계산 과정을 하나 줄일 수 있고 없고가 달라진다. 유도 $$ \begin{align*} &amp;amp; f(x) = c(x-a)(x-b) = c x^2 -c(a+b)x+cab \\ \implies&amp;amp; f &#39;(x)=2cx-c(a+b) \\ \implies&amp;amp; 2cx-c(a+b)=0 \\ \implies&amp;amp; x=\frac { c(a+b) }{ 2c } \\ \implies&amp;amp; x=\frac { a+b }{ 2 } \end{align*} $$ ■</description>
    </item>
    
    <item>
      <title>11의 배수판정법 더 간단한 증명</title>
      <link>https://freshrimpsushi.github.io/posts/easy-proof-of-the-11-divisibility-rule/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/easy-proof-of-the-11-divisibility-rule/</guid>
      <description>빌드업 이 포스트에서는 진법에 대한 편의를 위해 다음과 같은 표기를 사용한다. $$ [a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}] := a_{n} \cdot 10^{n} + a_{n-1} \cdot 10^{n-1} +&amp;hellip;+ a_{1} \cdot 10^{1} + a_{0} \cdot 10^{0} $$ 예를 들어 $5714$ 는 다음과 같이 나타낼 수 있다. $$ \begin{align*} [5714] =&amp;amp; 5000+700+10+4 \\ =&amp;amp; 5\cdot 10^{3} +7\cdot 10^{2} +1\cdot 10^{1} +4\cdot 10^{0} \end{align*} $$ 정리 $a_{n} - a_{n-1} + &amp;hellip; + a_{1} - a_{0}$ 이 $11$ 의 배수면 $[a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}]$ 도 $11$ 의 배수다. 설명 물론 $7$ 의 배수 판정법 $13$ 의 배수 판정법에서 주어진 수가 $7$, $11$, $13$ 의 배</description>
    </item>
    
    <item>
      <title>3의 배수판정법과 9의 배수판정법의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-3-and-9-divisibility-rule/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-3-and-9-divisibility-rule/</guid>
      <description>정리 각 자리 숫자를 모두 더해 $3$ 의 배수면 $3$ 의 배수, $9$ 의 배수면 $9$ 의 배수다. 설명 예로써 $8142$ 는 $8142=3 \cdot 2714$ 로 $3$의 배수고, 실제로 $8+1+4+2=15$ 는 $3$ 의 배수다. $1945125$ 는 $1945125=9 \cdot 216125$ 로 $9$의 배수고, 실제로 $1+9+4+5+1+2+5=27$ 은 $9$ 의 배수다. 배수 판정법은 현대에 와선 사실 별 의미가 없어졌지만 여전히 흥미로운 도구다. $2,4,5,8$ 의 배수는 판정하기가 아주 쉽지만 $3, 7, 9, 11$ 등의 수에 대해서는 별도</description>
    </item>
    
    <item>
      <title>7의 배수판정법과 13의 배수판정법의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-7-11-and-13-divisibility-rule/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-7-11-and-13-divisibility-rule/</guid>
      <description>빌드업 이 포스트에서는 진법에 대한 편의를 위해 다음과 같은 표기를 사용한다. $$ [a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}] := a_{n} \cdot 10^{n} + a_{n-1} \cdot 10^{n-1} +&amp;hellip;+ a_{1} \cdot 10^{1} + a_{0} \cdot 10^{0} $$ 예를 들어 $5714$ 는 다음과 같이 나타낼 수 있다. $$ \begin{align*} [5714] =&amp;amp; 5000+700+10+4 \\ =&amp;amp; 5\cdot 10^{3} +7\cdot 10^{2} +1\cdot 10^{1} +4\cdot 10^{0} \end{align*} $$ 정리 $$ a_{n} a_{n-1} a_{n-2} - a_{n-3} a_{n-4} a_{n-5} +&amp;hellip;+ a_{5} a_{4} a_{3} - a_{2} a_{1} a_{0} $$ 이 $7$ 의 배수면 $[a_{n} a_{n-1} &amp;hellip; a_{1} a_{0}]$ 도 $7$ 의 배수고, $$ a_{n} a_{n-1} a_{n-2} - a_{n-3} a_{n-4} a_{n-5} +&amp;hellip;+ a_{5} a_{4} a_{3} - a_{2} a_{1} a_{0} $$ 이 $13$ 의 배수</description>
    </item>
    
    <item>
      <title>원소가 n개인 유한 집합의 부분 집합의 갯수</title>
      <link>https://freshrimpsushi.github.io/posts/the-number-of-subsets-of-finite-set-with-cardinality-n/</link>
      <pubDate>Tue, 21 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-number-of-subsets-of-finite-set-with-cardinality-n/</guid>
      <description>공식 유한집합 $X$ 에 대해 $n(X)=n$ 이면 $n(P(X))=2^{ n }$ 이다. 유도 $n$ 개의 원소 중에서 $k$ 개의 원소를 선택하는 부분집합의 갯수는 $_{ n }{ C }_{ k }$ 이다. 이항 정리를 써서 모든 경우의 수를 더하면 $\displaystyle \sum _{ k=0 }^{ n }{_{ n }{ C }_{ k } }=2^{ n }$ 이므로 $n(P(A))=2^{ n }$ 이다. ■</description>
    </item>
    
    <item>
      <title>가비의 리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mediant/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mediant/</guid>
      <description>정리 $bdf(b+d)\neq 0$ 이면 $$ \frac { a }{ b }=\frac { c }{ d }=\frac { e }{ f } \implies \frac { a+c }{ b+d }=\frac { e }{ f } $$ 설명 &amp;lsquo;가비&amp;rsquo;는 다른 게 아니라 두 한자 더할 가加 견줄 비比로 만들어진 단어다 여기서 견줄 비는 &amp;lsquo;비율&amp;rsquo;할때의 그 비로, 이름에 모든 게 함축된 정리다. 증명 $$ \frac { a }{ b }=\frac { c }{ d }=\frac { e }{ f } $$ 이므로 $\frac { a }{</description>
    </item>
    
    <item>
      <title>구분구적법으로 구한 면적과 정적분의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-the-area-and-the-static-fraction-obtained-by-the-separation-method/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-the-area-and-the-static-fraction-obtained-by-the-separation-method/</guid>
      <description>공식 $$ \begin{align*} &amp;amp; \lim _{ n\to \infty }{ \sum _{ k=1 }^{ n }{ f\left( a+\frac { p }{ n }k \right) \frac { p }{ n } } } \\ =&amp;amp; \int _{ a }^{ a+p }{ f(x)dx } \\ =&amp;amp; \int _{ 0 }^{ p }{ f(a+x)dx } \\ =&amp;amp; \int _{ 0 }^{ 1 }{ pf(a+px)dx } \end{align*} $$ 설명 이따금 보면 극한을 빙자한 적분 문제가 있다. 물론 대개는 극한을 구하는 그 자체로도 풀 수 있게 해놓기 때문에 몰라도 크게 상관은 없다. 하지만 가끔, 아주 가끔 저 관계 자체를 아는지 모르는지 묻는 경우가</description>
    </item>
    
    <item>
      <title>낙하한 물체의 속도를 구하는 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/velocity-of-falling-body/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/velocity-of-falling-body/</guid>
      <description>공식 $g$ 가 중력가속도라고 하자. 어떤 물체가 중력에 의해 높은 곳에서 낮은 곳으로 떨어졌을때, 이 물체의 속도를 낙하한 거리 $h$ 에 대한 공식으로 나타내면 다음과 같다. $$ v=\sqrt { 2gh } $$ 유도 우리가 구하고자 하는 것과 상관 없는 조건들은 모두 무시하기로 하자. 정지해있던 물체가 $h$ 만큼 낙하했을 때의 속도를 $v$라 하자.이때 역학적 에너지가 보존되므로 $$ \frac</description>
    </item>
    
    <item>
      <title>드 무아브르의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-de-moivres-theorem/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-de-moivres-theorem/</guid>
      <description>정리 $z = r \text{cis} \theta$ 이면 모든 자연수 $n$ 에 대해 $z^n = r^n \text{cis} n\theta$ 이 성립한다. $\text{cis} \theta: = \cos \theta + i \sin \theta$ 증명 수학적 귀납법을 사용하자. $n=1$ 에 대해서는 자명하고, $n=k$ 에 대해서도 성립한다고 가정하면 $$ z^{k+1} = z z^k = (r \text{cis} \theta)(r^k \text{cis} k\theta) $$ 이다. 한편 $z_1 z_2 = r_1 r_2 \text{cis} (\theta_1 + \theta_2)$ 이므로 $$ z^{k+1} = r^{k+1} \text{cis} (k+1)\theta $$ $n=k$ 일 때 $n=k+1$ 에 대해서도 성립하므로 주어진 식은 모든 자연수에 대해 성립한다. ■</description>
    </item>
    
    <item>
      <title>삼각함수의  평행이동과  도함수의  관계</title>
      <link>https://freshrimpsushi.github.io/posts/11/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/11/</guid>
      <description>공식 [1] 사인: $$\sin{(\theta +\frac { n }{ 2 }\pi )}={ \sin }^{ (n) }\theta$$ [2] 코사인: $$\cos{(\theta +\frac { n }{ 2 }\pi )}={ \cos }^{ (n) }\theta$$ $(n)$ 은 $n$ 번만큼 미분을 했다는 뜻이다. 설명 쉽게 말해서, 90˚만큼 움직일 때마다 미분을 한번씩 하면 된다. 실제로 $n=3$ 에 대해서 계산을 해보자. 덧셈정리를 사용한 방법 $$ \begin{align*} \cos(\theta +{3 \over 2}\pi ) =&amp;amp; \cos\theta \cos\frac { 3 }{ 2 }\pi -\sin\theta \sin\frac { 3 }{ 2 }\pi \\ =&amp;amp; \cos\theta \cdot 0-\sin\theta \cdot (-1) \\ =&amp;amp; \sin\theta $ \end{align*} $$ 공식을 사용한 방법 $$</description>
    </item>
    
    <item>
      <title>에네스트롬-카케야 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-enestrom-kakeya-theorem/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-enestrom-kakeya-theorem/</guid>
      <description>정리 1 $\left\{ a_{i} \right\}_{i=0}^{n} \subset \mathbb{R}$ 이 $a_0 &amp;gt; a_1 &amp;gt; \cdots &amp;gt; a_n &amp;gt; 0$ 라고 하자. 그러면 다항 함수 $$ P(z) := a_0 + a_1 z + \cdots + a_{n-1} z^{n-1} + a_n z^n $$ 의 모든 근 $z \in \mathbb{C}$ 는 $|z| \ge 1$ 를 만족한다. 증명 만약 $P(z) = 0$ 의 해가 $z=1$ 이면 $\displaystyle 0 = P(1) = \sum_{i=0}^{n} a_{i} &amp;gt; 0$ 이므로 일단 해는 $z \ne 1$ 이어야한다.식 $P(z) = 0$ 의 양변에 $z$ 를 곱해 원래의 식에서 빼고 $a_0$ 에 대해 정리하면 $$ a_0 = (1-z)P(z) + (a_0 - a_1) z + \cdots + (a_{n-1} - a_n) z^n + a_n z^{n+1} $$ 이</description>
    </item>
    
    <item>
      <title>자주 쓰는 이차함수의 정적분</title>
      <link>https://freshrimpsushi.github.io/posts/15/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/15/</guid>
      <description>공식 $$ \int _{ \alpha }^{ \beta }{ (x-\alpha )(x-\beta )dx }=-\frac { { (\beta -\alpha ) } ^ { 3 } }{ 6 } $$ 설명 문제를 풀다보면 생각보다 이런 꼴의 정적분을 할 일이 많다. 풀이를 빠르게 해주는데 외엔 전혀 쓸모가 없는 공식이고 유도도 그냥 계산밖에 없다. 모양만 딱 외워서 쓸 수 있도록 하자. 유도 $$ \begin{align*} &amp;amp; \int _{ \alpha }^{ \beta }{ (x-\alpha )(x-\beta )dx } \\ =&amp;amp; \int _{ \alpha }^{ \beta }{ { {x }^2-(\alpha +\beta )x+\alpha \beta }dx } \\ =&amp;amp; \frac { \beta^3-{ \alpha^3 } }{ 3 }-(\alpha +\beta )\frac { \beta^2-\alpha^2}{ 2</description>
    </item>
    
    <item>
      <title>조화급수의 발산성에 대한 오렘의 증명</title>
      <link>https://freshrimpsushi.github.io/posts/oresmes-proof-of-divergence-of-harmonic-series/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/oresmes-proof-of-divergence-of-harmonic-series/</guid>
      <description>정리 조화급수는 발산한다. $$ \sum _{ n=1 }^{ \infty }{ \frac { 1 }{ n } }=\infty $$ 설명 조화급수는 언뜻 보기에 그 값이 계속 작아지므로 수렴할 것도 같지만 오렘은 이것이 발산한다는 것을 매우 간단하고 아름답게 증명했다. 이러한 팩트는 주로 절대수렴의 개념을 설명하기 위한 예시로써 잘 쓰이는데, 교대조화급수는 $\displaystyle \sum_{n=1}^{\infty} {{(-1)^{n-1}} \over {n}} = 1- {1 \over 2} + { 1 \over 3} - { 1 \over 4 }+ \cdots = \ln 2 &amp;lt;</description>
    </item>
    
    <item>
      <title>조화평균을  활용해  평균속력  구하기</title>
      <link>https://freshrimpsushi.github.io/posts/using-harmonic-means-to-obtain-average-speed/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/using-harmonic-means-to-obtain-average-speed/</guid>
      <description>공식 거리 $S$ 만큼 갈 때 속력 $a$ 로 이동하고 올 때 속력 $b$ 로 이동했다면 평균속력 $v$ 는 다음과 같다. $$ v = \frac { 2ab }{ a+b } $$ 설명 시속 60km로 한 시간 이동한 후 시속 80km로 한 시간 더 이동했을 때 두 시간동안의 평균 속력은 70km/h다. 이처럼 시간이 단위일 경우 쉽게 산술평균으로 답을 내놓을 수 있지만, 단위가 거리일 경우 쉽게 답을 내기가 어렵다. 가</description>
    </item>
    
    <item>
      <title>평행한 두 직선 사이의 거리를 구하는 공식 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-formula-for-distance-of-two-parallel-lines/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-formula-for-distance-of-two-parallel-lines/</guid>
      <description>공식 $$ d=\frac { |2k| }{ \sqrt { m^{ 2 }+1 } } $$ 설명 이차곡선의 접선을 구하는 문제를 풀다보면 두 접선 사이의 거리를 구하라는 경우가 종종 있다. 물론 적당한 한 점과 다른 직선의 거리를 구하는 공식이 있기 때문에 구하는 것 자체가 어려운 것은 아니다. 하지만 아주 쉽고 빠르게 그 거리를 구할 수 있는 공식을 알고 있다면 조금이라도 계산량을 줄일 수 있을 것이다. 유도 평행하는</description>
    </item>
    
    <item>
      <title>산술평균과 기하평균 조화평균사이의 부등식</title>
      <link>https://freshrimpsushi.github.io/posts/inequalities-between-arithmatic-geometric-harmonic-means/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inequalities-between-arithmatic-geometric-harmonic-means/</guid>
      <description>정의 $n$ 개의 양수 ${x}_{1},{x}_{2},\cdots,{x}_{n}$ 에 대해 산술, 기하, 조화평균은 다음과 같다. 산술평균 : $$ \sum _{ k=1 }^{ n }{ \frac { {x}_{k} }{ n } }=\frac { {x}_{1}+{x}_{2}+\cdots+{x}_{n} }{ n } $$ 기하평균 : $$ \prod _{ k=1 }^{ n }{ { {x}_{k} }^{ \frac { 1 }{ n } } }=\sqrt [ n ]{ {x}_{1}{x}_{2}\cdots{x}_{n} } $$ 조화평균 : $$ \left( \frac { \sum _{ k=1 }^{ n }{ \frac { 1 }{ {x}_{k} } } }{ n } \right)^{-1}=\frac { n }{ \frac { 1 }{ {x}_{1} }+\frac { 1 }{ {x}_{2} }+\cdots+\frac { 1 }{ {x}_{n} } } $$ 정리 이에 대해 다음의 부등식이 성립한다. $$ \frac {</description>
    </item>
    
    <item>
      <title>표현자 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-representer-theorem/</link>
      <pubDate>Sat, 29 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-representer-theorem/</guid>
      <description>정리 인풋 집합Input Set $X \ne \emptyset$ 과 양정부호 커널 $k: X \times X \to \mathbb{R}$ 이 주어져 있다고 하자. 학습데이터셋Training Dataset을 $$ D := \left\{ \left( x_{i} , y_{i} \right) \right\}_{i=1}^{m} \subset X \times \mathbb{R} $$ 라 하고, 재생 커널 힐베르트 공간 $H_{k}$ 의 클래스 $$ \mathcal{F} := \left\{ f \in \mathbb{R}^{X} : f \left( \cdot \right) = \sum_{i=1}^{\infty} \beta_{i} k \left( \cdot , z_{i} \right) \land \beta_{i} \in \mathbb{R} \land z_{i} \in X \land \left\| f \right\| &amp;lt; \infty \right\} \subset H_{k} $$ 를 위와 같이 둔다. 임의의 목적 함수 $c :</description>
    </item>
    
    <item>
      <title>머신러닝에서의 정부호 커널과 재생 커널 힐베르트 공간</title>
      <link>https://freshrimpsushi.github.io/posts/kernel-in-machine-learning/</link>
      <pubDate>Tue, 25 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kernel-in-machine-learning/</guid>
      <description>정의 1 2 인풋 공간Input Space $X \ne \emptyset$ 이 정의역이고 공역이 복소수의 집합 $\mathbb{C}$ 인 사상 $f: X \to \mathbb{C}$ 들로 이루어진 함수들의 공간 $\left( H , \left&amp;lt; \cdot , \cdot \right&amp;gt; \right) \subset \mathbb{C}^{X}$ 가 힐베르트공간이라 하자. 재생 커널 힐베르트 공간 픽스된 하나의 데이텀Datum $x \in X$ 에 대해 다음과 같이 함수 $f \in H$ 를 취해주는 범함수 $\delta_{x} : H \to \mathbb{C}$ 를 $x$ 에서의 (디랙) 평가 범함수(Dirac) Evaluation</description>
    </item>
    
    <item>
      <title>최적화이론의 라그랑주 승수법</title>
      <link>https://freshrimpsushi.github.io/posts/lagrangian-multiplier-in-optimization-theory/</link>
      <pubDate>Fri, 21 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lagrangian-multiplier-in-optimization-theory/</guid>
      <description>⚡ 이 포스트는 패스트 트랙Fast Track으로 작성되었습니다. 설명 비선형인 목적 함수를 가지는 비선형 최적화 문제에서 제약조건에 라그랑주 승수Lagrangian Multiplier라는 것을 곱해서 목적 함수에 반영시키는 풀이법을 라그랑주 승수법이라 한다. $$ \begin{matrix} \text{Maximize} &amp;amp; f(x) \\ \text{subject to} &amp;amp; g(x) = 0 \end{matrix} $$ 가령 미분가능한 스칼라함수 $f,g : \mathbb{R}^{p} \to \mathbb{R}$ 에</description>
    </item>
    
    <item>
      <title>서포트 벡터 머신</title>
      <link>https://freshrimpsushi.github.io/posts/support-vector-machine/</link>
      <pubDate>Mon, 17 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/support-vector-machine/</guid>
      <description>모델 1 쉬운 정의 이진분류Binary Classification 가능한 데이터를 가장 잘 구분하도록하는 직선이나 평면을 구하는 방법을 서포트 벡터 머신이라 한다. 어려운 정의 내적공간 $X = \mathbb{R}^{p}$ 와 라벨링Labeling $Y = \left\{ -1, +1 \right\}$ 에 대해 $n$ 개의 데이터를 모아놓은 학습 데이터셋Training Dataset을 $D = \left\{ \left( \mathbf{x}_{k} , y_{k} \right) \right\}_{k=1}^{n} \subset X \times Y$ 라 두고, $$ \begin{align*} X^{+} :=&amp;amp; \left\{ \mathbf{x}_{k} \in</description>
    </item>
    
    <item>
      <title>줄리아의 다차원 인덱스</title>
      <link>https://freshrimpsushi.github.io/posts/multidimensional-index-in-julia/</link>
      <pubDate>Sat, 01 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multidimensional-index-in-julia/</guid>
      <description>개요 줄리아에서는 다차원 배열에 참조할 수 있는 인덱스의 타입인 CatesianIndex를 제공한다. 1 당연히 카티션Catesian이라는 명명은 집합의 곱인 데카르트 곱에서 온 것이다. 코드 julia&amp;gt; M = rand(0:9, 4,4) 4×4 Matrix{Int64}: 9 3 7 0 8 6 2 1 3 8 4 9 5 6 8 2 가령 위와 같은 행렬 M의 3행 4열 원소인 9에 접근하고 싶다고 가정해보자. julia&amp;gt; pt = (3,4) (3, 4) julia&amp;gt;</description>
    </item>
    
    <item>
      <title>줄리아의 숏 서킷</title>
      <link>https://freshrimpsushi.github.io/posts/short-circuit-in-julia/</link>
      <pubDate>Tue, 28 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/short-circuit-in-julia/</guid>
      <description>개요 줄리아에서 &amp;amp;&amp;amp;과 ||는 논리곱, 논리합일 뿐만 아니라 숏-서킷 평가Short-circuit Evaluation을 수행한다.1 가령 A &amp;amp;&amp;amp; B는 A와 B가 모두 참일 때 참을 리턴하는데, 사실 A가 거짓이라면 B가 참인지 거짓인지 볼 것도 없이 A &amp;amp;&amp;amp; B는 거짓이다. 숏-서킷 평가는 그 볼 것도 없는 B를 실제로 안 보는 것이다.</description>
    </item>
    
    <item>
      <title>줄리아의 find 함수들</title>
      <link>https://freshrimpsushi.github.io/posts/find-functions-in-julia/</link>
      <pubDate>Fri, 24 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/find-functions-in-julia/</guid>
      <description>개요 줄리아의 기본 내장 함수들로써 알면 알수록 유용하다. 거두절미하고 예시를 보며 익히자. 코드 x = [3, 7, 4, 5, 10, 3, 12, 3, 2, 4] argmin(x) argmax(x) findmin(x) findmax(x) extrema(x) findfirst(x .== 3) findlast(x .== 3) findall(x .== 3) findnext(x .== 3, 5) findprev(x .== 3, 5) 최적해 argmin(),argmax(),findmin(),findmax(),extrema() 최적해를 찾는다. x = [3, 7, 4, 5, 10, 3, 12, 3, 2, 4] julia&amp;gt; argmin(x) 9 julia&amp;gt; argmax(x) 7 argmin(),argmax() 는 그냥 정확히 최적해, 즉 값이 가장 크고 작은 곳의 인덱스를 리턴한다. x = [3, 7, 4, 5, 10, 3, 12, 3, 2, 4] julia&amp;gt;</description>
    </item>
    
    <item>
      <title>줄리아의 느낌표 컨벤션</title>
      <link>https://freshrimpsushi.github.io/posts/bang-convention-in-julia/</link>
      <pubDate>Mon, 20 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bang-convention-in-julia/</guid>
      <description>개요 1 줄리아에서 함수 이름의 가장 마지막에 느낌표Bang !을 넣는 것을 뱅 컨벤션이라 한다. 이러한 함수들은 입력받은 인수를 수정하는 특징을 가진다. 코드 function add_1!(x) x .+= 1 return x end foo = [2,5,-1] add_1!(foo) foo 예를 들어 위의 코드를 실행하면 다음과 같은 결과를 얻는다. julia&amp;gt; foo = [2,5,-1] 3-element Vector{Int64}: 2 5 -1 julia&amp;gt; add_1!(foo) 3-element Vector{Int64}: 3 6 0 julia&amp;gt; foo 3-element Vector{Int64}: 3 6 0 배열 foo는 함수 밖에서 정의되었고 add_1</description>
    </item>
    
    <item>
      <title>줄리아에서 부분배열 빠르게 참조하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-view-subarray-in-julia/</link>
      <pubDate>Sun, 12 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-view-subarray-in-julia/</guid>
      <description>개요 줄리아에서 view는 배열Array의 부분배열Subarray를 빠르게 참조하게끔 해주는 데이터 구조다. 1 실제로 쓰는 입장에서는 번거롭기만하고 차이가 없어보이지만 게으르게Lazily 참조되면서 더 가볍운 배열을 리턴한다. 따라서 아주 베이직한 수준에서까지 최적화된 줄리아 코드에서는 @views라는 매크로를 쉽게 찾아볼 수</description>
    </item>
    
    <item>
      <title>줄리아의 브로드캐스팅 문법</title>
      <link>https://freshrimpsushi.github.io/posts/syntax-for-broadcasting-in-julia/</link>
      <pubDate>Wed, 08 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/syntax-for-broadcasting-in-julia/</guid>
      <description>개요 브로드캐스팅Broadcasting은 줄리아에서 가장 중요한 개념으로, 벡터화된 코드를 작성함에 있어서 아주 편리한 문법이다.1 이항연산 앞에 .을 찍거나 함수 뒤에 .을 찍는 식으로 사용한다. 이는 점별Pointwise하게 함수를 적용시킨다는 의미에서 찰떡같은 표현이다. 프로그래밍적으로 브로드캐스팅은 맵과 리듀스에서 맵Ma</description>
    </item>
    
    <item>
      <title>줄리아에서 배열로 딕셔너리 만드는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-dictionary-by-arrays-in-julia/</link>
      <pubDate>Wed, 24 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-dictionary-by-arrays-in-julia/</guid>
      <description>코드 1 julia&amp;gt; Dict([&amp;#34;a&amp;#34;, &amp;#34;bc&amp;#34;] .=&amp;gt; [2,8]) Dict{String, Int64} with 2 entries: &amp;#34;a&amp;#34; =&amp;gt; 2 &amp;#34;bc&amp;#34; =&amp;gt; 8 키Key와 밸류Value로 두고 싶은 두 배열이 주어져 있을 때, Dict(Key .=&amp;gt; Value)를 통해 딕셔너리를 만들 수 있다. 본질적으로 페어Pair를 만드는 연산자 =&amp;gt;의 브로드캐스팅Broadcasting에 지나지 않는다. 환경 OS: Windows julia: v1.7.0 https://discourse.julialang.org/t/create-a-dictionary-from-arrays-of-keys-and-values/13908/3&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>줄리아에서 복소수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-complex-number-in-julia/</link>
      <pubDate>Sat, 20 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-complex-number-in-julia/</guid>
      <description>개요 줄리아에서는 기본적으로 R처럼 복소수를 지원한다. 코드 허수 im julia&amp;gt; z = 3 + 4im 3 + 4im im은 순허수 $i = \sqrt{-1}$ 를 나타낸다. 우리가 상식적으로 사용하는 사칙연산은 모두 사용할 수 있다. julia&amp;gt; typeof(z) Complex{Int64} julia&amp;gt; typeof(3.0 + 4.0im) ComplexF64 (alias for Complex{Float64}) 타입을 체크해보면 같은 복소수라도 어떤 복소수로 이루어져있는지가 다르다. 마치 추상대수에서 정수인 경우 $\mathbb{Z} [i]$, 혹은 실수인 경우 $\mathbb{R} [i]$ 로 구</description>
    </item>
    
    <item>
      <title>약한 위상의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-weak-topology/</link>
      <pubDate>Sun, 14 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-weak-topology/</guid>
      <description>정의 1 $X$ 가 두 위상 $\mathscr{T}_{1}$, $\mathscr{T}_{2}$ 를 가진 집합이라 하자. 만약 $\mathscr{T}_{1} \subset \mathscr{T}_{2}$ 이면 $\mathscr{T}_{1}$ 가 $\mathscr{T}_{2}$ 보다 약하다Weaker, $\mathscr{T}_{2}$ 가 $\mathscr{T}_{1}$ 보다 강하다Stronger고 한다. 집합 $X$ 에서 위상공간 $X_{\alpha}$ 로의 단사들을 모아놓은 집합 $\mathscr{F} := \left\{ f_{\alpha} : X \hookrightarrow X_{\alpha} , \alpha \in \mathscr{A} \right\}$ 을 생각해보자. $$ \mathscr{S} := \left\{ f_{\alpha}^{-1} \left( O_{\alpha} \right) \subset X : \alpha \in \mathscr{A}, O_{\alpha} \text{ open in } X_{\alpha} \right\} $$ 위와 같은 개집합들의 집합 $\mathscr{S}$ 을 부분기저로 두어 결정되는</description>
    </item>
    
    <item>
      <title>World Pop 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-world-pop/</link>
      <pubDate>Thu, 04 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-world-pop/</guid>
      <description>소개 세계 항공망 네트워크, 국가 간 이민 통계, 도시화, 연령 및 성별 구조 등에 대한 데이터를 제공한다. 다루는 데이터들 자체가 사이트 이름과 맞게 인구Population에 관한 것들이며, 딱 연구에 필요할법한 데이터들이 제공된다. 요구사항 어떤 요구 사항도 없이 무제한적으로 다운로드 받을 수 있다. 가이드 Global Flight Data로 통하는 링크 https://www.worldpop.org/geodata/summary?id=1287 를 예로 들</description>
    </item>
    
    <item>
      <title>Our World in Data 소개</title>
      <link>https://freshrimpsushi.github.io/posts/introduction-to-our-world-in-data/</link>
      <pubDate>Wed, 27 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/introduction-to-our-world-in-data/</guid>
      <description>소개 Our World in Data는 그 사이트 이름처럼 전세계의 인구, 연령, 경제, 정치, 에너지, 젠더, 질병 등 수백가지 종류의 데이터를 국가별, 연도별로 아무런 대가 없이 제공한다. 다양함과 분량으로 따지자면 세계에서 최고 수준이다. 단점이라면 단점일 특징은 대개의 데이터가 연간별로만 제공된다는 것이다. 월별이나 주별, 일별 단위의 세세한 데이터를 원</description>
    </item>
    
    <item>
      <title>카이제곱분포의 충분통계량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistic-of-chi-square-distribution/</link>
      <pubDate>Sat, 23 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistic-of-chi-square-distribution/</guid>
      <description>정리 카이제곱분포를 따르는 랜덤샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right) \sim \chi^{2} (r)$ 이 주어져 있다고 하자. $r$ 에 대한 충분통계량 $T$ 는 다음과 같다. $$ T = \left( \prod_{i} X_{i} \right) $$ 증명 감마 분포와 카이제곱 분포의 관계: $$ \Gamma \left( { r \over 2 } , 2 \right) \iff \chi ^2 (r) $$ 감마분포의 충분통계량: 감마분포를 따르는 랜덤샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right) \sim \Gamma \left( k, \theta \right)$ 이 주어져 있다고 하자. $\left( k, \theta \right)$ 에 대</description>
    </item>
    
    <item>
      <title>베타분포의 충분통계량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistic-of-beta-distribution/</link>
      <pubDate>Tue, 19 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistic-of-beta-distribution/</guid>
      <description>정리 베타분포를 따르는 랜덤샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right) \sim \text{Beta} \left( \alpha, \beta \right)$ 이 주어져 있다고 하자. $\left( \alpha, \beta \right)$ 에 대한 충분통계량 $T$ 는 다음과 같다. $$ T = \left( \prod_{i} X_{i}, \prod_{i} \left( 1 - X_{i} \right) \right) $$ 증명 $$ \begin{align*} f \left( \mathbf{x} ; \alpha, \beta \right) =&amp;amp; \prod_{k=1}^{n} f \left( x_{k} ; \alpha, \beta \right) \\ =&amp;amp; \prod_{k=1}^{n} {{ 1 } \over { B(\alpha, \beta) }} x_{k}^{\alpha - 1} \left( 1 - x_{k} \right)^{\beta - 1} \\ =&amp;amp; {{ 1 } \over { B(\alpha, \beta) }} \left( \prod_{k=1}^{n} x_{k} \right)^{\alpha - 1} \left( \prod_{k=1}^{n} \left( 1 - x_{k} \right) \right)^{\beta - 1} \end{align*} $$ 네이만 인수분해 정</description>
    </item>
    
    <item>
      <title>감마분포의 충분통계량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistic-of-gamma-distribution/</link>
      <pubDate>Fri, 15 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistic-of-gamma-distribution/</guid>
      <description>정리 감마분포를 따르는 랜덤샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right) \sim \Gamma \left( k, \theta \right)$ 이 주어져 있다고 하자. $\left( k, \theta \right)$ 에 대한 충분통계량 $T$ 는 다음과 같다. $$ T = \left( \prod_{i} X_{i}, \sum_{i} X_{i} \right) $$ 증명 $$ \begin{align*} f \left( \mathbf{x} ; k, \theta \right) =&amp;amp; \prod_{k=1}^{n} f \left( x_{k} ; k, \theta \right) \\ =&amp;amp; \prod_{i=1}^{n} {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x_{i}^{k - 1} e^{ - x_{i} / \theta} \\ =&amp;amp; \left( {{ 1 } \over { \Gamma ( k ) \theta^{k} }} \right)^{n} \left( \prod_{i=1}^{n} x_{i} \right) ^{k - 1} e^{ - \sum_{i} x_{i} / \theta} \\ \overset{k}{=}&amp;amp; \left( {{ 1 } \over { \Gamma ( k</description>
    </item>
    
    <item>
      <title>정규분포의 충분통계량과 최소우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistic-and-mle-of-normal-distribution/</link>
      <pubDate>Mon, 11 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistic-and-mle-of-normal-distribution/</guid>
      <description>정리 정규분포를 따르는 랜덤샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right) \sim N \left( \mu , \sigma^{2} \right)$ 이 주어져 있다고 하자. $\left( \mu, \sigma^{2} \right)$ 에 대한 충분통계량 $T$ 와 최대우도추정량 $\left( \hat{\mu}, \hat{\sigma^{2}} \right)$ 는 다음과 같다. $$ \begin{align*} T =&amp;amp; \left( \sum_{k} X_{k}, \sum_{k} X_{k}^{2} \right) \\ \left( \hat{\mu}, \hat{\sigma^{2}} \right) =&amp;amp; \left( {{ 1 } \over { n }} \sum_{k} X_{k}, {{ 1 } \over { n }} \sum_{k} \left( X_{k} - \overline{X} \right)^{2} \right) \end{align*} $$ 증명 충분통계량 $$ \begin{align*} f \left( \mathbf{x} ; \lambda \right) =&amp;amp; \prod_{k=1}^{n} f \left( x_{k} ; \lambda \right) \\ =&amp;amp; \prod_{k=1}^{n} {{ 1 } \over { \sqrt{2 \pi} \sigma }} \exp</description>
    </item>
    
    <item>
      <title>지수분포의 충분통계량과 최소우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistic-and-mle-of-exponential-distribution/</link>
      <pubDate>Sun, 03 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistic-and-mle-of-exponential-distribution/</guid>
      <description>정리 지수분포를 따르는 랜덤샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right) \sim \exp \left( \lambda \right)$ 이 주어져 있다고 하자. $\lambda$ 에 대한 충분통계량 $T$ 와 최대우도추정량 $\hat{\lambda}$ 는 다음과 같다. $$ \begin{align*} T =&amp;amp; \sum_{k=1}^{n} X_{k} \\ \hat{\lambda} =&amp;amp; {{ n } \over { \sum_{k=1}^{n} X_{k} }} \end{align*} $$ 증명 충분통계량 $$ \begin{align*} f \left( \mathbf{x} ; \lambda \right) =&amp;amp; \prod_{k=1}^{n} f \left( x_{k} ; \lambda \right) \\ =&amp;amp; \prod_{k=1}^{n} \lambda e^{-lambda x_{k}} \\ =&amp;amp; \lambda^{n} e^{-\lambda \sum_{k} x_{k}} \\ =&amp;amp; \lambda^{n} e^{-\lambda \sum_{k} x_{k}} \cdot 1 \end{align*} $$ 네이만 인수분해 정리: 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 이 모수</description>
    </item>
    
    <item>
      <title>푸아송분포의 충분통계량과 최소우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistic-and-mle-of-poisson-distribution/</link>
      <pubDate>Wed, 27 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistic-and-mle-of-poisson-distribution/</guid>
      <description>정리 푸아송분포를 따르는 랜덤샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right) \sim \text{Poi} \left( \lambda \right)$ 이 주어져 있다고 하자. $\lambda$ 에 대한 충분통계량 $T$ 와 최대우도추정량 $\hat{\lambda}$ 는 다음과 같다. $$ \begin{align*} T =&amp;amp; \sum_{k=1}^{n} X_{k} \\ \hat{\lambda} =&amp;amp; {{ 1 } \over { n }} \sum_{k=1}^{n} X_{k} \end{align*} $$ 증명 충분통계량 $$ \begin{align*} f \left( \mathbf{x} ; \lambda \right) =&amp;amp; \prod_{k=1}^{n} f \left( x_{k} ; \lambda \right) \\ =&amp;amp; \prod_{k=1}^{n} {{ e^{-\lambda} \lambda^{x_{k}} } \over { x_{k} ! }} \\ =&amp;amp; {{ e^{-n \lambda} \lambda^{ \sum_{k} x_{k}} } \over { \prod_{k} x_{k} ! }} \\ =&amp;amp; e^{-n \lambda} \lambda^{ \sum_{k} x_{k}} \cdot {{ 1 } \over { \prod_{k} x_{k}</description>
    </item>
    
    <item>
      <title>기하분포의 충분통계량과 최소우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistic-and-mle-of-geometric-distribution/</link>
      <pubDate>Sat, 23 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistic-and-mle-of-geometric-distribution/</guid>
      <description>정리 기하분포를 따르는 랜덤샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right) \sim \text{Geo} \left( p \right)$ 이 주어져 있다고 하자. $p$ 에 대한 충분통계량 $T$ 와 최대우도추정량 $\hat{p}$ 는 다음과 같다. $$ \begin{align*} T =&amp;amp; \sum_{k=1}^{n} X_{k} \\ \hat{p} =&amp;amp; {{ n } \over { \sum_{k=1}^{n} X_{k} }} \end{align*} $$ 증명 충분통계량 $$ \begin{align*} f \left( \mathbf{x} ; p \right) =&amp;amp; \prod_{k=1}^{n} f \left( x_{k} ; p \right) \\ =&amp;amp; \prod_{k=1}^{n} p \left( 1 - p \right)^{x_{k} - 1} \\ =&amp;amp; p^{n} \left( 1 - p \right)^{\sum_{k} x_{k} - n} \\ =&amp;amp; p^{n} \left( 1 - p \right)^{\sum_{k} x_{k} - n} \cdot 1 \end{align*} $$ 네이만 인수분해</description>
    </item>
    
    <item>
      <title>일양분포의 충분통계량과 최소우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistic-and-mle-of-uniform-distribution/</link>
      <pubDate>Tue, 19 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistic-and-mle-of-uniform-distribution/</guid>
      <description>정리 일양분포를 따르는 랜덤샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right) \sim U \left( 0 , \theta \right)$ 이 주어져 있다고 하자. $\theta$ 에 대한 충분통계량 $T$ 와 최대우도추정량 $\hat{\theta}$ 는 다음과 같다. $$ \begin{align*} T =&amp;amp; \max_{k=1 , \cdots , n} X_{k} \\ \hat{\theta} =&amp;amp; \max_{k=1 , \cdots , n} X_{k} \end{align*} $$ 증명 전략: 일양분포의 충분통계량과 최대우도추정량은 그 실용성은 둘째치고 과제와 중간, 기말고사 때문에 수도 없이 봐야할 통계량이다. 정의에 의</description>
    </item>
    
    <item>
      <title>줄리아에서 조건문 짧게 쓰는 법</title>
      <link>https://freshrimpsushi.github.io/posts/shorthand-of-conditional-statement-in-julia/</link>
      <pubDate>Fri, 15 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shorthand-of-conditional-statement-in-julia/</guid>
      <description>개요 줄리아에서 &amp;lt;condition&amp;gt; &amp;amp;&amp;amp; &amp;lt;statement&amp;gt;는 &amp;lt;condition&amp;gt;이 참일 때 &amp;lt;statement&amp;gt;가 실행된다. 함수로써는 참인 경우 &amp;lt;statement&amp;gt;의 결과가 반환되며, 거짓인 경우 &amp;lt;statement&amp;gt;가 아예 평가Evaluation조차 되지 않는다</description>
    </item>
    
    <item>
      <title>유니모달 분포의 최단 신뢰구간</title>
      <link>https://freshrimpsushi.github.io/posts/shortest-confidence-interval-of-unimodal-distribution/</link>
      <pubDate>Thu, 07 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shortest-confidence-interval-of-unimodal-distribution/</guid>
      <description>정리 유니모달 함수의 정의 함수 $f : \mathbb{R} \to \mathbb{R}$ 이 $x \le x^{\ast}$ 에서 감소하지 않고, $x \ge x^{\ast}$ 에서 증가하지 않게끔 하는 모드Mode $x^{\ast}$ 가 존재하면 $f$ 를 유니모달Unimodal하다고 한다. 특히 $f$ 의 확률밀도함수가 유니모달하면 그 확률분포를 유니모달 분포라 부르자. 가장 짧은 신뢰구간 $f(x)$ 가 유니모달 확률밀도함수라 하자. 구간 $[a,b]$ 가 다음 세 조건 (i): $\displaystyle \int_{a}^{b} f(x) dx =</description>
    </item>
    
    <item>
      <title>확률적 증감함수와 신뢰구간</title>
      <link>https://freshrimpsushi.github.io/posts/stochastic-increasing-and-confidence-interval/</link>
      <pubDate>Sun, 03 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stochastic-increasing-and-confidence-interval/</guid>
      <description>정리 1 확률적 증감함수의 정의 누적분포함수 $F \left( t ; \theta \right)$ 가 $\theta$ 에 대해 증가(감소) 함수면 확률적 증가(감소) 함수Stochastic Increasing(Decreasing)라 한다. 연속누적분포함수의 피버팅Pivoting a continusous cdf 통계량 $T$ 가 연속누적분포함수 $F_{T} \left( t ; \theta \right)$ 를 가진다고 하자. 픽스된 $\alpha \in (0,1)$ 에 대해 $\alpha_{1} + \alpha_{2} = \alpha$</description>
    </item>
    
    <item>
      <title>최정확 신뢰집합</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-most-accurate-confidence-set/</link>
      <pubDate>Wed, 30 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-most-accurate-confidence-set/</guid>
      <description>정의 1 $\theta$ 에 대한 가설검정의 $1 - \alpha$ 신뢰집합을 $C \left( \mathbf{x} \right)$ 이라 하고, 채택역을 $A \left( \theta \right) = C \left( \mathbf{x} \right)^{c}$ 이라 하자. $P_{\theta} \left( \theta&amp;rsquo; \in C \left( \mathbf{X} \right) \right)$ 를 $\theta&amp;rsquo; \ne \theta$ 에 대한 펄스 커버리지False Coverage 확률이라 한다. 원래의 커버리지 확률 $P_{\theta} \left( \theta \in C \left( \mathbf{X} \right) \right)$ 을 이와 대비되는 표현인 트루 커버리지True Coverage 확률이라 부른다. $1-\alpha$ 신뢰집합 $C \left( \mathbf{x} \right)$ 이 모든 $\theta&amp;rsquo; \ne \theta$ 에 대해 펄스 커</description>
    </item>
    
    <item>
      <title>가설검정과 신뢰집합의 일대일 대응관계</title>
      <link>https://freshrimpsushi.github.io/posts/one-to-one-corresponding-between-hypothesis-test-and-confidence-set/</link>
      <pubDate>Mon, 28 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/one-to-one-corresponding-between-hypothesis-test-and-confidence-set/</guid>
      <description>정리 모수공간 $\Theta$ 와 공간 $\mathcal{X}$ 가 주어져 있다고 하자. 각각의 $\theta_{0} \in \Theta$ 에 대해 $A \left( \theta_{0} \right)$ 을 가설검정 $H_{0} : \theta = \theta_{0}$ 의 레벨 $\alpha$ 채택역이라 하자. 각각의 $\mathbf{x} \in \mathcal{X}$ 에 대해 다음과 같이 집합 $C \left( \mathbf{x} \right) \subset \Theta$ $$ C \left( \mathbf{x} \right) := \left\{ \theta_{0} : \mathbf{x} \in A \left( \theta_{0} \right) \right\} $$ 을 정의하자. 그러면 랜덤 집합Random Set $C \left( \mathbf{X} \right)$ 는 $1 - \alpha$ 신뢰집합이다. 역으로, $C \left( \mathbf{X} \right)$ 가 $1 - \alpha$ 신뢰집합이라 하자</description>
    </item>
    
    <item>
      <title>수리통계학에서 피벗의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-pivot-in-mathematical-statistics/</link>
      <pubDate>Sat, 26 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-pivot-in-mathematical-statistics/</guid>
      <description>정의 1 확률변수 $Q \left( \mathbf{X} , \theta \right) := Q \left( X_{1} , \cdots , X_{n} ; \theta \right)$ 의 확률분포가 모든 모수 $\theta$ 에 독립이면 $Q$ 를 피벗Pivot 혹은 피버탈 퀀터티Pivotal Quantity라 한다. 설명 당연하지만 $Q$ 는 통계량이다. 확률분포가 모든 모수 $\theta$ 에 독립이라는 말은 곧 $Q \left( \mathbf{X} , \theta \right)$ 의 누적분포함수 $F \left( bfx \right)$ 모든 $\theta$ 에 대해 같다는 것이다. 정의만 읽어보면 어차피</description>
    </item>
    
    <item>
      <title>줄리아 데이터프레임에서 NaN을 0으로 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-replace-nan-of-dataframe-to-0-in-julia/</link>
      <pubDate>Thu, 24 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-replace-nan-of-dataframe-to-0-in-julia/</guid>
      <description>개요 특정 값으로 바꾸는 방법은 한 열씩 바꾸기 때문에 불편하고, 데이터프레임 전체에서 NaN을 처리할 땐 더 좋은 트릭을 사용해봄직하다. 코드 julia&amp;gt; df = DataFrame(rand(1:9,3,3), :auto) ./ DataFrame(rand(0:1,3,3), :auto) 3×3 DataFrame Row │ x1 x2 x3 │ Float64 Float64 Float64 ─────┼─────────────────────────── 1 │ 5.0 Inf 7.0 2 │ Inf 8.0 Inf 3 │ 4.0 1.0 4.0 가령 위의 데이터 프레임에서 Inf를 0으로 대</description>
    </item>
    
    <item>
      <title>수리통계적인 신뢰집합의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-confidence-set-in-mathematical-statistics/</link>
      <pubDate>Tue, 22 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-confidence-set-in-mathematical-statistics/</guid>
      <description>정의 1 모수 $\theta$ 의 구간추정량 $\left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right]$ 에 대해 다음을 커버리지 확률Coverage Probability라 한다. $$ P_{\theta} \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] \right) = P \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] | \theta \right) $$ 커버리지 확률의 인피멈을 신뢰계수Confidence Coefficient라 한다. $$ \inf_{\theta} P_{\theta} \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] \right) $$</description>
    </item>
    
    <item>
      <title>줄리아의 삼항연산자 ? :</title>
      <link>https://freshrimpsushi.github.io/posts/ternary-operator-in-julia/</link>
      <pubDate>Sun, 20 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ternary-operator-in-julia/</guid>
      <description>개요 줄리아에서 A ? B : C는 이른바 삼항연산자Ternary Operator로써, A가 참이면 B, 거짓이면 C를 리턴하는 함수다. 수학적으로 이항연산이 함수로써 정의되듯, 삼항연산 역시 함수다. 조건문과 비슷하면서도 이러한 본질적 차이점이 있기 때문에 익숙해지면 아주 유용하게 쓸 수 있다. 다만 읽기 쉬운 코드와는 조금 멀어질 수 있기 때문에</description>
    </item>
    
    <item>
      <title>구간추정량</title>
      <link>https://freshrimpsushi.github.io/posts/interval-estimator/</link>
      <pubDate>Fri, 18 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interval-estimator/</guid>
      <description>정의 1 모수 $\theta \in \mathbb{R}$ 에 대해 순서쌍 $\left( L \left( x_{1} , \cdots , x_{n} \right), U \left( x_{1} , \cdots , x_{n} \right) \right)$ 이 모든 $\mathbf{x} \in \mathcal{X}$ 에 대해 $L \left( \mathbf{x} \right) \le U \left( \mathbf{x} \right)$ 을 만족하면 $\theta$ 의 구간추정치Interval Estimate라 한다. 랜덤 인터벌Random Interval $\left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right]$ 를 구간추정량Interval Estimator라 한다. $\mathcal{X}$ 는 $L$ 과 $U$ 의 서포트다. 설명 데이터 $\mathbf{X} = \mathbf{x}$</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터프레임 특정 값 변경하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-replace-element-of-dataframe-in-julia/</link>
      <pubDate>Wed, 16 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-replace-element-of-dataframe-in-julia/</guid>
      <description>개요 replace!() 메소드를 사용하면 된다.1 첫번째 인자로는 변경할 데이터프레임의 칼럼이 들어가고, 두번째 인자로는 페어 A =&amp;gt; B 가 들어간다. 여기서 데이터프레임의 칼럼이 들어간다는 게 중요하다. 코드 julia&amp;gt; WJSN 10×4 DataFrame Row │ member birth height unit │ String Int64 Int64 String ─────┼─────────────────────────────── 1 │ 다영 99 161 쪼꼬미 2 │</description>
    </item>
    
    <item>
      <title>줄리아에서 빈도수 계산하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-calculate-frequency-in-julia/</link>
      <pubDate>Sat, 12 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-calculate-frequency-in-julia/</guid>
      <description>개요 1 FreqTables.jl 패키지의 freqtable() 함수를 사용하면 된다. R에서의 freq() 함수와 유사한 기능을 한다. 코드 배열 julia&amp;gt; compartment = rand([&amp;#39;S&amp;#39;,&amp;#39;I&amp;#39;,&amp;#39;R&amp;#39;], 1000); julia&amp;gt; freqtable(compartment) 3-element Named Vector{Int64} Dim1 │ ──────┼──── &amp;#39;I&amp;#39; │ 316 &amp;#39;R&amp;#39; │ 342 &amp;#39;S&amp;#39; │ 342 위와 같이 그냥 배열을 넣으면 각 계급별로 카운트 해준다. 데이터프레임 freqtable()는 특히 데이터프레임에 유용하다. R에서의 질적변수를 포함한 회귀분석 예제와 마찬가</description>
    </item>
    
    <item>
      <title>줄리아에서 csv 파일 컬럼만 읽어들이는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-read-column-names-of-csv-file-only-in-julia/</link>
      <pubDate>Tue, 08 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-read-column-names-of-csv-file-only-in-julia/</guid>
      <description>가이드 가령 위와 같은 example.csv 파일이 있다고 하자. 이를 데이터프레임으로 불러들일 때, 데이터 전체가 아니라 열이름만 유지되어있고 텅 빈 데이터프레임을 만들고 싶을 때가 있다. 빈 데이터프레임이 필요한 경우가 있기 때문에 이런 경우도 반드시 있다. julia&amp;gt; using CSV, DataFrames julia&amp;gt; df = CSV.read(&amp;#34;example.csv&amp;#34;, DataFrame, limit = 1)[[false],:] 0×3 DataFrame 위 실행 결과에서 만들어진 데이터프레임은 3개의 열을 그대로 가지고 있지</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터 프레임 요약보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-summarize-dataframe-in-julia/</link>
      <pubDate>Fri, 04 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-summarize-dataframe-in-julia/</guid>
      <description>가이드 1 using RDatasets iris = dataset(&amp;#34;datasets&amp;#34;, &amp;#34;iris&amp;#34;) describe(iris) describe() 함수를 사용하면 된다. iris 데이터를 요약해보자. julia&amp;gt; describe(iris) 5×7 DataFrame Row │ variable mean min median max nmissing eltype │ Symbol Union… Any Union… Any Int64 DataType ─────┼──────────────────────────────────────────────────────────────────────────────</description>
    </item>
    
    <item>
      <title>줄리아의 범주형 배열</title>
      <link>https://freshrimpsushi.github.io/posts/categorical-array-in-julia/</link>
      <pubDate>Mon, 31 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/categorical-array-in-julia/</guid>
      <description>개요 줄리아의 CategoricalArrays.jl 패키지는 R에서의 factor와 비슷한 역할을 한다. 코드 julia&amp;gt; A = [&amp;#34;red&amp;#34;, &amp;#34;blue&amp;#34;, &amp;#34;red&amp;#34;, &amp;#34;green&amp;#34;] 4-element Vector{String}: &amp;#34;red&amp;#34; &amp;#34;blue&amp;#34; &amp;#34;red&amp;#34; &amp;#34;green&amp;#34; julia&amp;gt; B = categorical(A) 4-element CategoricalArray{String,1,UInt32}: &amp;#34;red&amp;#34; &amp;#34;blue&amp;#34; &amp;#34;red&amp;#34; &amp;#34;green&amp;#34; julia&amp;gt; levels(B) 3-element Vector{String}: &amp;#34;blue&amp;#34; &amp;#34;green&amp;#34; &amp;#34;red&amp;#34; categorical() categorical() 함수로 일반 배열을 범주형 배열로 캐스트Cast 할 수 있다. levels() levels() 함수로는 계급을 볼 수 있다. 당연히 계급엔 중복이 없으며, 배열에서 해당 계급에 해당하는 원소가 없어도 계급 자체는 유지된다. julia&amp;gt; B[2] =</description>
    </item>
    
    <item>
      <title>줄리아에서 R에서 쓰던 내장데이터셋 불러오는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-load-datasets-in-r-in-julia/</link>
      <pubDate>Thu, 27 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-load-datasets-in-r-in-julia/</guid>
      <description>가이드 RDatasets.jl 패키지를 사용하면 된다. 다음은 제일 만만한 iris 데이터를 불러오는 예제다. 기본 내장 데이터셋 외에도 여러가지 데이터셋을 포함하고 있으니 깃허브를 참고하도록 하자. 1 julia&amp;gt; using RDatasets julia&amp;gt; iris = dataset(&amp;#34;datasets&amp;#34;, &amp;#34;iris&amp;#34;) 150×5 DataFrame Row │ SepalLength SepalWidth PetalLength PetalWidth Species │ Float64 Float64 Float64 Float64 Cat… ─────┼──────────────────────────────────────</description>
    </item>
    
    <item>
      <title>줄리아에서 패키지 버전 확인하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-version-of-package-in-julia/</link>
      <pubDate>Fri, 21 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-version-of-package-in-julia/</guid>
      <description>가이드 예로써 Plots.jl 패키지의 버전을 확인해보자. REPL에서 ] 키를 누르면 패키지 모드로 진입한다. 여기서 status foo을 입력하면 다음과 같이 foo 패키지의 버전을 확인할 수 있다. 환경 OS: Windows julia: v1.6.3</description>
    </item>
    
    <item>
      <title>줄리아에서 배열이 비어있는지 확인하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-that-array-is-empty-in-julia/</link>
      <pubDate>Mon, 17 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-that-array-is-empty-in-julia/</guid>
      <description>개요 isempty() 함수를 사용하면 된다. 코드 julia&amp;gt; isempty([]) true julia&amp;gt; isempty(Set()) true julia&amp;gt; isempty(&amp;#34;&amp;#34;) true 제목에서는 배열이라고 했지만 사실 배열이 아니라 집합이나 문자열이어도 된다. 최적화 물론 배열이 비어있는지는 length()가 $0$ 인지 확인해도 상관 없을 수 있다. julia&amp;gt; @time for t in 1:10^6 isempty([]) end 0.039721 seconds (1000.00 k allocations: 76.294 MiB, 27.85% gc time) julia&amp;gt; @time for t in 1:10^6 length([]) == 0 end 0.041762 seconds (1000.00 k allocations: 76.294 MiB, 19.18% gc time) 보다시피 빈 배열의 경우 두 방법은 성능</description>
    </item>
    
    <item>
      <title>줄리아에서 예외처리하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-handle-exception-in-julia/</link>
      <pubDate>Thu, 13 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-handle-exception-in-julia/</guid>
      <description>개요 지독한 외로움에 쩔쩔매본 사람은 알게되지 음 알게되지 코딩을 하다가 알수없는 에러에 고생해본 사람은 알게된다, 프로그래밍에 있어서 에러가 정말 중요하다는 사실을&amp;hellip; 줄리아에서는 error() 함수 혹은 @error 매크로를 통해 에러를 낼 수 있다. 내장 예외는 줄리아 v1.63을 기준으로 25가지가 정의되어 있다. 1 코드 julia&amp;gt; log(1 + 2im) 0.8047189562170501 + 1.1071487177940904im 가령 프로</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터프레임 사이즈 확인하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-the-size-of-dataframe-in-julia/</link>
      <pubDate>Sun, 09 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-the-size-of-dataframe-in-julia/</guid>
      <description>개요 nrow(), ncol(), size() 등을 사용할 수 있다. R과 달리 length()는 에러를 낸다. 코드 julia&amp;gt; df = DataFrame(rand(100000,5), :auto) 100000×5 DataFrame Row │ x1 x2 x3 x4 x5 │ Float64 Float64 Float64 Float64 Float64 ────────┼───────────────────────────────────────────────────── 1 │ 0.474921 0.942137 0.0523668 0.588696 0.0176242 2 │ 0.842828 0.910385 0.216194 0.794668 0.664883 3 │ 0.0350312 0.96542 0.837923 0.920311 0.748409 4 │ 0.613249 0.731643 0.941826</description>
    </item>
    
    <item>
      <title>줄리아에서 변수이름을 칼럼명으로 가지는 데이터프레임 만드는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-dataframe-with-variable-name-as-column-name/</link>
      <pubDate>Wed, 05 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-dataframe-with-variable-name-as-column-name/</guid>
      <description>개요 네임드 튜플을 사용하면 된다. 네임드 튜플을 만드는 방법은 왼쪽 괄호 바로 뒤에 세미콜론 ;을 붙이는 것이다. 가령 DataFrame(; x, y)이라고 하면 칼럼명이 :x, &amp;quot;y 이고 내용도 각각 x, y인 데이터프레임이 만들어진다. 코드 julia&amp;gt; MyCol7 = rand(5); B = 1:5; julia&amp;gt; DataFrame(; MyCol7, B) 5×2 DataFrame Row │ MyCol7 B │ Float64 Int64 ─────┼───────────────── 1 │ 0.911763 1 2 │ 0.93374 2 3 │ 0.116779 3 4 │ 0.467364</description>
    </item>
    
    <item>
      <title>수리통계적인 유의확률의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-p-value-in-mathematical-statistics/</link>
      <pubDate>Mon, 03 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-p-value-in-mathematical-statistics/</guid>
      <description>정의 1 가설검정 $H_{0} \text{ vs } H_{1}$ 이 주어져 있다고 하자. 모든 실현 $\mathbf{x} \in \Omega$ 에 대해 $0 \le p \left( \mathbf{x} \right) \le 1$ 를 만족시키는 검정 통계량 $p \left( \mathbf{X} \right)$ 를 유의확률 혹은 p-밸류p-value라 한다. $p \left( \mathbf{X} \right)$ 가 모든 $\theta \in \Theta_{0}$ 와 모든 $\alpha \in [0,1]$ 에 대해 다음을 만족하면 유효하다Valid고 말한다. $$ P_{\theta} \left( p \left( \mathbf{X} \right) \le \alpha \right) \le \alpha $$ 설명 유효한 p-밸류의 조건에 있는 수식을 풀어</description>
    </item>
    
    <item>
      <title>줄리아의 네임드 튜플</title>
      <link>https://freshrimpsushi.github.io/posts/named-tuple-in-julia/</link>
      <pubDate>Sat, 01 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/named-tuple-in-julia/</guid>
      <description>개요 네임드 튜플Named Tuple은 일반적인 튜플과 달리 딕셔너리나 구조체Structure처럼 사용할 수 있는 튜플이다. 1 심볼Symbol의 배열을 키Key로 가지고 키로써 밸류Value에 접근할 수 있으면서도 튜플처럼 사용할 수 있다. 코드 x = rand(Bool, 5); y = rand(Bool, 5); z = (; x, y) typeof(z) z.x 위의 코드를 실행해서 네임드 튜플을 어떻게 사용하는지 확</description>
    </item>
    
    <item>
      <title>충분통계량이 포함된 최강력검정</title>
      <link>https://freshrimpsushi.github.io/posts/ump-based-on-sufficient-statistic/</link>
      <pubDate>Tue, 27 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ump-based-on-sufficient-statistic/</guid>
      <description>정리 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta = \theta_{0} \\ H_{1} :&amp;amp; \theta = \theta_{1} \end{align*} $$ 위와 같은 가설검정에서 $\theta$ 에 대한 충분통계량 $T$ 의 $\theta_{0}, \theta_{1}$ 에 대한 확률밀도함수 혹은 확률질량함수를 $g \left( t | \theta_{0} \right), g \left( t | \theta_{1} \right)$ 라고 하자. 그러면 기각역 $S$ 와 어떤 상수 $k \ge 0$ 에 대해, 다음 세 조건을 만족하면서 $T$ 에 종속된 모든 가설 검정은 레벨 $\alpha$의 최강력검정이다. (i): $g \left( t | \theta_{1} \right) &amp;gt; k</description>
    </item>
    
    <item>
      <title>칼린-루빈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-karlin-rubin-theorem/</link>
      <pubDate>Fri, 23 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-karlin-rubin-theorem/</guid>
      <description>정리 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta \le \theta_{0} \\ H_{1} :&amp;amp; \theta &amp;gt; \theta_{0} \end{align*} $$ 위와 같은 가설검정에서 $T$ 를 $\theta$ 의 충분통계량이라 하고, $t$ 의 확률밀도함수 혹은 확률질량함수의 패밀리 $\left\{ g(t | \theta) : \theta \in \Theta \right\}$ 가 단조우도비 MLR을 갖는다고 하자. 그러면 $\forall t_{0}$ 에 대해 $$ H_{0} \text{ is rejected if and only if } T &amp;gt; t_{0} $$ 인 가설검정은 레벨 $\alpha = P_{\theta_{0}} \left( T &amp;gt; t_{0} \right)$ 최강력검정이다. 모수 $\theta$ 에 대해 기각역이 $R$ 인</description>
    </item>
    
    <item>
      <title>단조우도비의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-monotone-likelihood-ratio/</link>
      <pubDate>Mon, 19 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-monotone-likelihood-ratio/</guid>
      <description>정의 모수 $\theta \in \mathbb{R}$ 와 일변량 확률변수 $T$ 에 대한 확률질량함수 혹은 확률밀도함수의 패밀리를 $G := \left\{ g ( t | \theta) : \theta \in \Theta \right\}$ 라 하자. 모든 $\theta_{2} &amp;gt; \theta_{1}$ 에 대해 $$ {{ g \left( t | \theta_{2} \right) } \over { g \left( t | \theta_{1} \right) }} $$ 가 $\left\{ t : g \left( t | \theta_{1} \right) &amp;gt; 0 \lor g \left( t | \theta_{2} \right) &amp;gt; 0 \right\}$ 에서 단조함수면 $G$ 가 단조우도비Monotone Llikelihood Ratio, MLR을 가진다고 한다. 설명 널리 알려진 수 많은 분</description>
    </item>
    
    <item>
      <title>네이만-피어슨 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-neyman-pearson-lemma/</link>
      <pubDate>Thu, 15 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-neyman-pearson-lemma/</guid>
      <description>정리 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta = \theta_{0} \\ H_{1} :&amp;amp; \theta = \theta_{1} \end{align*} $$ 위와 같은 가설검정에서 $\theta_{0}, \theta_{1}$ 에 대한 확률밀도함수 혹은 확률질량함수를 $f \left( \mathbf{x} | \theta_{0} \right), f \left( \mathbf{x} | \theta_{1} \right)$ 이라 하고 기각역 $R$ 과 어떤 상수 $k \ge 0$ 에 대해 만약 (i): $f \left( \mathbf{x} | \theta_{1} \right) &amp;gt; k f \left( \mathbf{x} | \theta_{0} \right)$ 이면 $\mathbf{x} \in R$ (ii): $f \left( \mathbf{x} | \theta_{1} \right) &amp;lt; k f \left( \mathbf{x} | \theta_{0} \right)$ 이면 $\mathbf{x} \in R^{c}$ (iii): $\alpha = P_{\theta_{0}} \left( \mathbf{X} \in R \right)$ 이라면, 다음 두 명제는 동치다. 위 세</description>
    </item>
    
    <item>
      <title>일변량 확률 변수 샘플링하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-sample-random-variable/</link>
      <pubDate>Tue, 13 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-sample-random-variable/</guid>
      <description>개요 확률변수의 구체적인 실현을 구하는 방법이다. 정리 일변량 확률변수 $T$ 의 누적분포함수 $F = F_{T}$ 가 주어져 있다고 하자. 그러면 일양분포를 따르는 확률 변수 $U \sim U \left( 0,1 \right)$ 에 대해 다음이 성립한다. $$ T = F^{-1} \left( U \right) $$ 설명 누적분포함수의 치역은 항상 $[0,1]$ 이라는 점을 생각해보면 당연하면서도 영리한 방법이다. 뭐가 됐든 $0$ 부터 $1$ 사이의 값 하나만 구하면 반</description>
    </item>
    
    <item>
      <title>불편 검정력 함수와 최강력검정</title>
      <link>https://freshrimpsushi.github.io/posts/unbiased-power-function-and-most-powerful-test/</link>
      <pubDate>Sun, 11 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unbiased-power-function-and-most-powerful-test/</guid>
      <description>정의 1 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 검정력 함수 $\beta (\theta)$가 모든 $\theta_{0} \in \Theta_{0}$ 와 $\theta_{1} \in \Theta_{0}^{c}$ 에 대해 다음을 만족하면 불편Unbiased 검정력 함수라 한다. $$ \beta \left( \theta_{0} \right) \le \beta \left( \theta_{1} \right) $$ $\mathcal{C}$ 가 위와 같은 가설검정을 모아놓은 집합이라고 하자. $\mathcal{C}$ 에서 검정력 함수 $\beta (\theta)$ 를 가진 가설검정 $A$ 가, 모든 $\theta \in \Theta_{0}^{c}$ 와 $\mathcal{C}$ 의 모든 가설검정의 검정력 함</description>
    </item>
    
    <item>
      <title>가설 검정의 검정력 함수</title>
      <link>https://freshrimpsushi.github.io/posts/power-function-of-hypothesis-test/</link>
      <pubDate>Wed, 07 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/power-function-of-hypothesis-test/</guid>
      <description>정의 1 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 위와 같은 가설검정이 주어져 있고 $\alpha \in [0,1]$ 이라 하자. 모수 $\theta$ 에 대해 기각역이 $R$ 인 함수 $\beta (\theta) := P_{\theta} \left( \mathbf{X} \in \mathbb{R} \right)$ 을 검정력 함수Power Function라 한다. $\sup_{\theta \in \Theta_{0}} \beta (\theta) = \alpha$ 면 주어진 가설검정을 사이즈Size $\alpha$ 가설검정이라 한다. $\sup_{\theta \in \Theta_{0}} \beta (\theta) \le \alpha$ 면 주어진 가설검정을 레벨Level $\alpha$ 가설</description>
    </item>
    
    <item>
      <title>충분통계량이 포함된 우도비검정</title>
      <link>https://freshrimpsushi.github.io/posts/lrt-based-on-sufficient-statistic/</link>
      <pubDate>Sat, 03 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lrt-based-on-sufficient-statistic/</guid>
      <description>정리 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 우도비검정통계량: $$ \lambda \left( \mathbf{x} \right) := {{ \sup_{\Theta_{0}} L \left( \theta \mid \mathbf{x} \right) } \over { \sup_{\Theta} L \left( \theta \mid \mathbf{x} \right) }} $$ 만약 $T \left( \mathbf{X} \right)$ 가 모수 $\theta$ 의 충분통계량이고 $\lambda^{\ast} (t)$ 가 $T$ 에 종속된 우도비검정통계량 $\lambda (\mathbf{x})$ 가 $\mathbf{X}$ 에 종속된 우도비검정통계량 이라고 하면, 모든 표본공간의 모든 $\mathbf{x} \in \Omega$ 에 대해 $\lambda^{\ast} \left( T \left( \mathbf{x} \right) \right) = \lambda \left( \mathbf{x} \right)$ 다. 설명 다시금 충분통</description>
    </item>
    
    <item>
      <title>수리통계적인 우도비검정의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-likelihood-ratio-test-in-mathematical-statistics/</link>
      <pubDate>Tue, 30 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-likelihood-ratio-test-in-mathematical-statistics/</guid>
      <description>정의 1 $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 위와 같은 가설검정에 대해 다음의 통계량 $\lambda$ 를 우도비검정 통계량Likelihood Ratio Test Statistic이라 한다. $$ \lambda \left( \mathbf{x} \right) := {{ \sup_{\Theta_{0}} L \left( \theta \mid \mathbf{x} \right) } \over { \sup_{\Theta} L \left( \theta \mid \mathbf{x} \right) }} $$ 주어진 $c \in [0,1]$ 에 대해 기각역 $\left\{ \mathbf{x} : \lambda \left( \mathbf{x} \right) \le c \right\}$ 를 가지는 모든 가설검정을 우도비검정Likelihood Ratio Test</description>
    </item>
    
    <item>
      <title>로케이션 패밀리의 충분통계량과 최대우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistiic-and-mle-of-location-family/</link>
      <pubDate>Fri, 26 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistiic-and-mle-of-location-family/</guid>
      <description>정리 확률밀도함수가 $f_{X} \left( x ; \theta \right) = f_{X} \left( x - \theta \right)$ 인 로케이션 패밀리에서 얻은 랜덤샘플 $X_{1} , \cdots , X_{n} \sim X$ 이 주어져 있다고 하자. 충분통계량과 최대우도추정량은 $X$ 의 서포트가 위로 유계면 $\max X_{k}$ $X$ 의 서포트가 아래로 유계면 $\min X_{k}$ 에 종속된다. 확률변수의 서포트란 확률밀도함수의 함수값이 $0$ 보다 큰 점들의 집합을 의미한다. $$ S_{X} := \left\{ x \in \mathbb{R} : f_{X} (x ; \theta) &amp;gt;</description>
    </item>
    
    <item>
      <title>수리통계적인 가설검정의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-hypothesis-test-in-mathematical-statistics/</link>
      <pubDate>Mon, 22 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-hypothesis-test-in-mathematical-statistics/</guid>
      <description>정의 1 모수에 관한 명제를 가설Hypothesis이라 한다. 주어진 샘플에 따라 가설 $H_{0}$ 을 참으로 받아들이게 만들거나 가설 $H_{0}$ 을 기각하고 $H_{1}$ 을 채택하는 문제를 가설 검정Hypothesis Test이라 한다. 가설검정에서 상보적인complementary 가설 $H_{0}$, $H_{1}$ 을 각각 귀무가설Null Hypothesis, 대립가설Altanative Hypot</description>
    </item>
    
    <item>
      <title>랜덤샘플의 표본평균의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-of-sample-mean-of-random-sample/</link>
      <pubDate>Thu, 18 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-of-sample-mean-of-random-sample/</guid>
      <description>공식 랜덤샘플 $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} X$ 이 주어져 있다고 하면 그 표본평균의 평균과 분산은 다음과 같다. $$ \begin{align*} E \bar{X} =&amp;amp; E X \\ \text{Var} \bar{X} =&amp;amp; {{ 1 } \over { n }} \text{Var} X \end{align*} $$ 설명 너무 쉬워서, 실제로 쉽다보니 대충 생각해서 갑자기 물어보면 의외로 헷갈리고 당황스러운 것이 바로 표본평균의 평균과 분산이다. 조금만 머리를 굴려보면 금방 알 수 있긴한데, 가능하면 머리는 조금 더 가치</description>
    </item>
    
    <item>
      <title>줄리아에서 명령줄 인수 넣는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-give-command-line-arguments-in-julia/</link>
      <pubDate>Tue, 16 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-give-command-line-arguments-in-julia/</guid>
      <description>코드 println(ARGS[1] * &amp;#34; + &amp;#34; * ARGS[2] * &amp;#34; = &amp;#34; * string(parse(Float64, ARGS[1]) + parse(Float64, ARGS[2]))) 위와 같이 한 줄로 이루어진 example.jl 파일이 있다고 해보자. 줄리아에서는 ARGS를 통해 커맨드라인에서의 인수를 배열로 받아줄 수 있다. 파이썬에서 sys.argv가 명령줄 인수의 배열로 들어오는 것과 유사하다. 작성된 코드는 숫자 두개를 받아서 그 합을 출력하는 프로그램이다. 실행 결과는 다음과 같다. 환경</description>
    </item>
    
    <item>
      <title>유일한 최대우도추정량은 충분통계량에 종속된다</title>
      <link>https://freshrimpsushi.github.io/posts/unique-mle-depends-on-sufficient-statistiic/</link>
      <pubDate>Sun, 14 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unique-mle-depends-on-sufficient-statistiic/</guid>
      <description>정리 만약 모수 $\theta$ 에 대한 충분통계량 $T$ 가 존재하고 $\theta$ 의 최대우도추정량 $\hat{\theta}$ 가 유일하게 존재한다면, $\hat{\theta}$ 는 $T$ 에 대한 함수로 나타난다. 증명 1 확률밀도함수 $f \left( x ; \theta \right)$ 를 가지는 랜덤샘플 $X_{1} , \cdots , X_{n}$ 에 대한 충분통계량 $T := T \left( X_{1} , \cdots , X_{n} \right)$ 과 그 확률밀도함수 $f_{t}$ 를 생각해보자. 충분통계량의 정의에 따라 그 우도함수 $L$ 은 $\theta$ 에 종속되지 않은 어떤 함수 $H$ 에</description>
    </item>
    
    <item>
      <title>줄리아에서 외부 프로그램 실행하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-run-external-programs-in-julia/</link>
      <pubDate>Fri, 12 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-run-external-programs-in-julia/</guid>
      <description>코드 줄리아에서는 run() 함수를 통해 백틱Backtick `으로 감싸진 문자열을 실행한다. 파이썬으로 치자면 os 모듈의 os.system() 을 사용한것 비슷하다. julia&amp;gt; txt = &amp;#34;helloworld&amp;#34; &amp;#34;helloworld&amp;#34; julia&amp;gt; typeof(`echo $txt`) Cmd 위와 같이 백틱으로 감싸진 문자열은 Cmd라는 타입을 가지고, run() 함수로써 실행할 수 있다. julia&amp;gt; run(`cmd /C echo $txt`) helloworld Process(`cmd /C echo helloworld`, ProcessExited(0)) 이 예제로 한정했을 때, 윈도에서는 cmd에 있는 echo를 실행시</description>
    </item>
    
    <item>
      <title>레만-셰페 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lehmann-scheff%C3%A9-theorem/</link>
      <pubDate>Wed, 10 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lehmann-scheff%C3%A9-theorem/</guid>
      <description>정리 1 2 완비 충분 통계량에 종속된 불편추정량은 유일하다. 다시 말해, $\theta$ 의 완비충분통계량 $T$ 에 대해 만약 $E \left[ \phi (T) \right] = \tau (\theta)$ 면 $\phi (T)$ 는 $\tau (\theta)$ 의 유일한 불편추정량, 즉 최선불편추정량이다. 설명 레만-셰페 정리는 불편추정량의 유일성을 보존하는 강력한 정리로써, 통계량의 완비성과 충분성이 중요한 이유 자체가 될 수 있다. 이 정리에 따라 충분통계량을</description>
    </item>
    
    <item>
      <title>줄리아에서 문자열 숫자로 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-cast-string-to-number-in-julia/</link>
      <pubDate>Mon, 08 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-cast-string-to-number-in-julia/</guid>
      <description>코드 parse(type, str)를 사용하면 된다. 문자열 str을 type 타입의 숫자로 변경해준다. julia&amp;gt; parse(Int, &amp;#34;21&amp;#34;) 21 julia&amp;gt; parse(Float64, &amp;#34;3.14&amp;#34;) 3.14 환경 OS: Windows julia: v1.6.3</description>
    </item>
    
    <item>
      <title>최소분산불편추정량의 유일성</title>
      <link>https://freshrimpsushi.github.io/posts/uniqueness-of-umvue/</link>
      <pubDate>Sat, 06 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniqueness-of-umvue/</guid>
      <description>정리 1 만약 $W$ 가 $\tau(\theta)$ 의 최선불편추정량이라면, $W$ 는 유일하다. 증명 코시-슈바르츠 부등식: 확률변수 $X, Y$ 에 대해 다음이 성립한다. $$ \text{Cov} (X,Y) \le \text{Var} X \text{Var} Y $$ 등호가 성립하는 필요충분조건은 다음과 같다. $$ \exist a \ne 0 , b \in \mathbb{R} : a X + b = Y $$ $W&amp;rsquo;$ 가 $W$ 와 또 다른 최선불편추정량이라고 하고, $W^{\ast} := \left( W + W&amp;rsquo; \right) / 2$ 를 생각해보면 그 기대값은 $$ E_{\theta} W^{\ast} = \left( \tau (\theta)</description>
    </item>
    
    <item>
      <title>최선불편추정량, 최소분산불편추정량 UMVUE</title>
      <link>https://freshrimpsushi.github.io/posts/uniform-minimum-variance-unbiased-estimator-umvue/</link>
      <pubDate>Tue, 02 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniform-minimum-variance-unbiased-estimator-umvue/</guid>
      <description>정의 1 모수 $\theta$ 가 주어져 있다고 하자. 불편추정량 $W^{\ast}$ 가 다른 모든 불편추정량 $W$ 에 대해 다음을 만족하면 최선불편추정량Best Unbiased Estimator 혹은 최소분산불편추정량UMVUE, Uniform Minimum Variance Unbiased Estimator이라 한다. $$ \text{Var}_{\theta} W^{\ast} \le \text{Var}_{\theta} W \qquad , \forall \theta $$ 설명 UMVUE는 가장 앞의 Uniform을 떼고 그냥 MVUE라고 할 때도 있다. UMVUE가 너무 길기도 하</description>
    </item>
    
    <item>
      <title>불편추정량의 라오-크래머 하한</title>
      <link>https://freshrimpsushi.github.io/posts/rao-cram%C3%A9r-lower-bound-of-unbiased-estimator/</link>
      <pubDate>Fri, 28 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rao-cram%C3%A9r-lower-bound-of-unbiased-estimator/</guid>
      <description>정리 정칙조건: (R0): 확률밀도함수 $f$ 는 $\theta$ 에 대해 단사다. 수식으로는 다음을 만족시킨다. $$ \theta \ne \theta&amp;rsquo; \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta&amp;rsquo; \right) $$ (R1): 확률밀도함수 $f$ 는 모든 $\theta$ 에 대해 같은 서포트를 가진다. (R2): 참값 $\theta_{0}$ 는 $\Omega$ 의 내점Interior Point이다. (R3): 확률밀도함수 $f$ 는 $\theta$ 에 대해 두 번 미분가능하다. (R4): 적분 $\int f (x; \theta) dx$ 은 적분 기호를 넘나들며 $\theta$ 에 대</description>
    </item>
    
    <item>
      <title>최대우도추정량의 불변성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/invariant-property-of-mle/</link>
      <pubDate>Mon, 24 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/invariant-property-of-mle/</guid>
      <description>정리 최대우도추정량은 함수를 취하는 것에 대해 불변Invariant 하다. 다시 말해 만약 $\hat{\theta}$ 가 모수 $\theta$ 의 최대우도추정량면, 모든 함수 $\tau$ 에 대해 $\tau \left( \hat{\theta} \right)$ 역시 $\tau \left( \theta \right)$ 의 최대우도추정량이다. 증명 1 $\eta := \tau \left( \theta \right)$ 라고 두고 우도함수 $L = L \left( \theta | \mathbf{x} \right)$ 에 대해 새로운 함수 $L^{\ast}$ 를 $$ L^{\ast} \left( \hat{\eta} | \mathbf{x} \right) = L^{\ast} \left( \tau^{-1} \left( \eta \right) | \mathbf{x} \right) $$ 과 같이 정의하자. $\hat{\eta}$ 가 우도함</description>
    </item>
    
    <item>
      <title>새터스화이트 근사</title>
      <link>https://freshrimpsushi.github.io/posts/satterthwaite-approximation/</link>
      <pubDate>Thu, 20 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/satterthwaite-approximation/</guid>
      <description>빌드업 자유도가 $r_{k}$ 인 카이제곱분포를 따르는 독립적인 $n$ 개의 확률변수 $Y_{k} \sim \chi_{r_{k}}^{2}$ 가 주어져 있다고 하자. 널리 알려진대로, 이들의 합인 $\sum_{k=1}^{n} Y_{k}$ 는 자유도가 $\sum_{k=1}^{n} r_{k}$ 인 카이제곱분포를 따른다. 이러한 인사이트는 t-분포를 따르는 $\displaystyle {{W} \over {\sqrt{V / r}}}$ 의 분모를 볼 때 유용하게 쓰일 수 있는데, 안타깝게도 풀드 샘플Pooled Sample, 그러니까 이질적인 모집단이 섞여있는 상황</description>
    </item>
    
    <item>
      <title>줄리아에서 가변 인자 함수 정의하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-define-varargs-function-in-julia/</link>
      <pubDate>Tue, 18 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-define-varargs-function-in-julia/</guid>
      <description>개요 1 가변인자 함수란 보통 프로그래밍에서 Varargs Function이라 불리는 것으로, 복수의 인자가 제한 없이 들어올 수 있는 함수를 말한다. 줄리아에서는 간단히 변수 뒤에 ...을 찍는 것으로 가변 인자를 정할 수 있다. 예제 코드를 보고 이해해보자. 참고로 이 ...을 스플랫 오퍼레이터Splat Operator 라 부른다.2 코드 아이작 뉴턴은 간단히 팩토리얼의</description>
    </item>
    
    <item>
      <title>로케이션-스케일 패밀리의 보조통계량</title>
      <link>https://freshrimpsushi.github.io/posts/ancillary-statistiic-of-location-scale-family/</link>
      <pubDate>Sun, 16 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ancillary-statistiic-of-location-scale-family/</guid>
      <description>정리 1 $X_{1} , \cdots , X_{n}$ 가 로케이션 패밀리면서 스케일 패밀리에서 나온 랜덤샘플이라 하자. 두 통계량 $T_{1} \left( X_{1} , \cdots, X_{n} \right)$ 과 $T_{2} \left( X_{1} , \cdots , X_{n} \right)$ 가 모든 $x_{1} , \cdots , x_{n}$ 와 모든 상수 $b \in \mathbb{R}$ 과 $a &amp;gt; 0$ 에 대해 $$ T_{i} \left( a x_{1} + b , \cdots , a x_{n} + b \right) = a T_{i} \left( x_{1} , \cdots , x_{n} \right) $$ 을 만족시킨다면, 그 비 $T_{1}/T_{2}$ 는 보조통계량이다. 증명 $X_{k}$ 는 로케이션-스케일 패밀리에서 나왔으므로 어떤</description>
    </item>
    
    <item>
      <title>줄리아 컨테이너 내부 원소 타입 체크하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-type-of-element-in-container-in-julia/</link>
      <pubDate>Fri, 14 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-type-of-element-in-container-in-julia/</guid>
      <description>개요 eltype() 함수를 사용하면 된다. 아마 element type에서 나온 명명일 것이다. 코드 julia&amp;gt; set_primes = Set([2,3,5,7,11,13]) Set{Int64} with 6 elements: 5 13 7 2 11 3 julia&amp;gt; arr_primes = Array([2,3,5,7,11,13]) 6-element Vector{Int64}: 2 3 5 7 11 13 위와 같이 $13$ 까지의 소수를 원소로 가지는 두 가지의 컨테이너를 생각해보자. 솔직히 같은 데이터지만 위는 집합이고 아래는 배열이라는 차이만 있다. julia&amp;gt; typeof(set_primes) Set{Int64} julia&amp;gt; eltype(set_primes) Int64 julia&amp;gt; typeof(arr_primes) Vector{Int64} (alias for Array{Int64, 1}) julia&amp;gt; eltype(arr_primes) Int64 이 둘에 typeof()를 취</description>
    </item>
    
    <item>
      <title>최소충분통계량이 주어진 불편추정량의 분산은 최소가 된다</title>
      <link>https://freshrimpsushi.github.io/posts/the-variance-of-unbaised-estimator-given-minimal-sufficient-statistiic-is-minimized/</link>
      <pubDate>Wed, 12 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-variance-of-unbaised-estimator-given-minimal-sufficient-statistiic-is-minimized/</guid>
      <description>정리 1 모수 $\theta$ 가 주어져 있다고 하자. $U$ 는 그 불편추정량, $T_{1}$ 은 충분통계량이고 $T_{2}$ 은 최소충분통계량이고 다음과 같이 $$ \begin{align*} U_{1} :=&amp;amp; E \left( U | T_{1} \right) \\ U_{2} :=&amp;amp; E \left( U | T_{2} \right) \end{align*} $$ 를 정의하면 다음이 성립한다. $$ \text{Var} U_{2} \le \text{Var} U_{1} $$ 설명 이러나 저러나 $U$ 는 불편추정량이기 때문에 $T_{1}$ 이 주어졌든 $T_{2}$ 가 주어졌든 그 기대값은 $\theta$ 를 찍기는 하지만, 대충 말해서 최소충분통계량이</description>
    </item>
    
    <item>
      <title>줄리아 그림 기본 설정 바꾸는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-default-setting-of-plot-in-julia/</link>
      <pubDate>Mon, 10 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-default-setting-of-plot-in-julia/</guid>
      <description>코드 default() 함수를 사용하면 된다. using Plots default(size = (400,400), color = :red) default(:size, (400,400)) for key in [:size, :color], value in [(400,400), :red] default(key, value) end 일반 plot() 함수처럼 세팅하는 방법이 있고, 키와 밸류를 줘서 하나씩 바꾸는 방법이 있다. 보통은 위가 더 편하겠지만 세팅이 아주 복잡한 경우 반복문을 이용해 아래의 방법을 사용할 수도 있다. 초기화 모든 디폴트 세팅을 초기화 하고싶다면 default()를 사용하면 된다. 환</description>
    </item>
    
    <item>
      <title>지수족 확률분포의 완비통계량</title>
      <link>https://freshrimpsushi.github.io/posts/complete-statistiic-for-exponential-family/</link>
      <pubDate>Sat, 08 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complete-statistiic-for-exponential-family/</guid>
      <description>정리 1 모수 $\mathbf{\theta} = \left( \theta_{1} , \cdots , \theta_{k} \right)$ 가 주어져 있고, 랜덤샘플 $X_{1} , \cdots , X_{n}$ 의 확률밀도함수 혹은 확률질량함수가 다음과 같이 지수족확률분포를 따른다고 하자. $$ f(x; \mathbf{\theta}) = h(x) c (\mathbf{\theta}) \exp \left( \sum_{i=1}^{k} w_{i} \left( \theta_{j} \right) t_{i} (x) \right) $$ 그러면 다음의 통계량 $T$ 는 완비통계량이다. $$ T \left( \mathbf{X} \right) = \left( \sum_{i=1}^{n} t_{1} \left( X_{i} \right) , \cdots , \sum_{i=1}^{n} t_{k} \left( X_{i} \right) \right) $$ 증명 라플라스 변환의 유일성에 따라 자명하다. ■ Casella. (2001). statistiical Inference(2nd</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터프레임 특정 행만 제거하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-delete-some-column-of-dataframe-in-julia/</link>
      <pubDate>Thu, 06 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-delete-some-column-of-dataframe-in-julia/</guid>
      <description>개요 인덱싱할 때 Not() 함수를 사용하면 된다. 1 칼럼명 그대로의 심볼이나 심볼의 배열을 넣으면 그 칼럼들만 제외하고 인덱싱된다. 코드 using DataFrames WJSN = DataFrame( member = [&amp;#34;다영&amp;#34;,&amp;#34;다원&amp;#34;,&amp;#34;루다&amp;#34;,&amp;#34;소정&amp;#34;,&amp;#34;수빈&amp;#34;,&amp;#34;연정&amp;#34;,&amp;#34;주연&amp;</description>
    </item>
    
    <item>
      <title>모먼트 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/moment-method/</link>
      <pubDate>Tue, 04 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-method/</guid>
      <description>정의 1 주어진 분포의 모수를 모를 때, 적률로써 모수에 대한 연립방정식을 세우고 그 해를 모수의 추정량으로 보는 방법을 모먼트 메소드Moment Method라 한다. 설명 모먼트 메소드는 최소 1800년대부터 칼 피어슨Karl Pearson 등에 의해 오래도록 사용된 점 추정 기법이다. 많은 경우에서 대단히 좋은 결과를 도출해내지는 못했지만, 가장 간단하고</description>
    </item>
    
    <item>
      <title>줄리아에서 그림에 수직선 수평선 넣는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-horizon-line-and-vertical-line-in-julia/</link>
      <pubDate>Sun, 02 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-horizon-line-and-vertical-line-in-julia/</guid>
      <description>개요 vline!(), hline!() 함수를 사용하면 된다. 코드 @time using Plots plot(rand(100)) hline!([0.5], linewidth = 2) vline!([25, 75], linewidth = 2) png(&amp;#34;result&amp;#34;) 선이 그어지는 위치는 배열로 넘겨준다. 배열의 요소가 여러개면 여러개의 선을 한 번에 그어준다. 환경 OS: Windows julia: v1.6.3</description>
    </item>
    
    <item>
      <title>바수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-baus-theorem/</link>
      <pubDate>Fri, 31 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-baus-theorem/</guid>
      <description>정리 만약 $T \left( \mathbf{X} \right)$ 이 완비통계량이면서 최소충분통계량이면, $T \left( \mathbf{X} \right)$ 은 모든 보조통계량과 독립이다. 설명 바수 정리는 충분통계량에 관한 정리 중에 가장 중요한 정리로써, 어떤 두 통계량이 독립임을 보일 수 있는 아주 강력한 결과를 도출 할 수 있다. 직관적으로 충분통계량은 모수 $\theta$ 에 대한 모든 정보를 가지고, 보조통계량은 $\theta$ 에 종속되어 있지 않으므로 둘</description>
    </item>
    
    <item>
      <title>줄리아에서 그림 양식 만드는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-user-plot-template-in-julia/</link>
      <pubDate>Wed, 29 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-user-plot-template-in-julia/</guid>
      <description>개요 RecipesBase.jl은 유저가 직접 새로운 그림의 양식을 만들게 해주는 패키지다. R 프로그래밍 언어에서 ggplot이 그러하듯 원래의 줄리아와는 또 다른 독자적인 문법1이 있다. 예제를 통해 익혀보자. 코드 using Plots using DataFrames df = DataFrame(x = 1:10, y = rand(10)) plot(df) @userplot TimeEvolution @recipe function f(te::TimeEvolution) df = te.args[1] linealpha --&amp;gt; 0.5 column_names = names(df) for (column_index, column_name) ∈ enumerate(column_names) @series begin label --&amp;gt; column_name df[:,column_index] end end end timeevolution(df); png(&amp;#34;1&amp;#34;) timeevolution(df, legend = :left); png(&amp;#34;2&amp;#34;) 우선 위 코드</description>
    </item>
    
    <item>
      <title>완비통계량</title>
      <link>https://freshrimpsushi.github.io/posts/complete-statistiic/</link>
      <pubDate>Mon, 27 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complete-statistiic/</guid>
      <description>정의 1 $\Omega$ 를 모수의 집합이라고 하자. 샘플 $\mathbf{X}$ 의 통계량 $T := T \left( \mathbf{X} \right)$ 의 확률밀도함수 혹은 확률질량함수 $f \left( t ; \theta \right)$ 들을 모아놓은 패밀리 $\left\{ f \left( t ; \theta \right) : \theta \in \Theta \right\}$ 가 $$ \forall \theta, E_{\theta} g (T) = 0 \implies \forall \theta, P_{\theta} \left( g(T) = 0 \right) = 1 $$ 를 만족하면 컴플리트Complete하다고 말하고, $T \left( \mathbf{X} \right)$ 를 완비통계량Complete statistiic이라 한다. 설</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터프레임 그룹별로 나누고 계산하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-divide-dataframe-by-group-and-calculate-in-julia/</link>
      <pubDate>Sat, 25 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-divide-dataframe-by-group-and-calculate-in-julia/</guid>
      <description>개요 groupby()를 사용해 그룹별로 나누고 combine()을 사용해 계산하면 된다.1 groupby(df, :colname) :colname을 기준으로 GroupedDataFrame를 리턴한다. combine(gdf, :colname =&amp;gt; fun) gdf는 그룹별로 나뉜 GroupedDataFrame다. :colname =&amp;gt; fun은 계산할 값이 있는 열의 이름인 심볼 :colname과 계산할 함수 fun의</description>
    </item>
    
    <item>
      <title>스케일 패밀리</title>
      <link>https://freshrimpsushi.github.io/posts/scale-family/</link>
      <pubDate>Thu, 23 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scale-family/</guid>
      <description>정의 누적분포함수 $F$ 에 대해 $F_{\sigma}$ 는 모든 $x$ 에 대해 $F_{\sigma} (x) = F \left( x / \sigma \right)$ 를 만족한다고 하자. $\left\{ F_{\sigma} : \sigma &amp;gt; 0 \right\}$ 을 스케일 패밀리Scale Family라 한다. 예시 1 모수 $\sigma$ 에 대한 랜덤샘플 $X_{1} , \cdots , X_{n}$ 을 생각해보면 누적분포함수 $F_{1} (x) = F ( x / 1) = F(x)$ 를 가지는 랜덤샘플 $Z_{1} , \cdots , Z_{n}$ 에 대해서 $$ X_{i} = \sigma Z_{i} $$ 와 같이 나타낼 수 있다. 이 샘플의 어떤 통계량이</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터프레임 중복된 행 삭제하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-drop-duplicated-rows-of-dataframe-in-julia/</link>
      <pubDate>Tue, 21 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-drop-duplicated-rows-of-dataframe-in-julia/</guid>
      <description>개요 unique()를 사용하면 된다. 정확하게는 중복된 행을 삭제한다기보단 하나만 남기는 것이다. 코드 using DataFrames WJSN = DataFrame( member = [&amp;#34;다영&amp;#34;,&amp;#34;다원&amp;#34;,&amp;#34;루다&amp;#34;,&amp;#34;소정&amp;#34;,&amp;#34;수빈&amp;#34;,&amp;#34;연정&amp;#34;,&amp;#34;주연&amp;#34;,&amp;#34</description>
    </item>
    
    <item>
      <title>로케이션 패밀리</title>
      <link>https://freshrimpsushi.github.io/posts/location-family/</link>
      <pubDate>Sun, 19 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/location-family/</guid>
      <description>정의 누적분포함수 $F$ 에 대해 $F_{\theta}$ 는 모든 $x$ 에 대해 $F_{\theta} (x) = F \left( x - \theta \right)$ 를 만족한다고 하자. $\left\{ F_{\theta} : \theta \in \mathbb{R} \right\}$ 을 로케이션 패밀리Location Family라 한다. 예시 1 모수 $\theta$ 에 대한 랜덤샘플 $X_{1} , \cdots , X_{n}$ 을 생각해보면 누적분포함수 $F_{0} (x) = F (x - 0) = F(x)$ 를 가지는 랜덤샘플 $Z_{1} , \cdots , Z_{n}$ 에 대해서 $$ X_{i} = Z_{i} + \theta $$ 와 같이 나타낼 수 있다. 이 샘플의 통계</description>
    </item>
    
    <item>
      <title>줄리아에서 레이아웃 주고 서브플랏 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-give-layout-and-make-subplot-in-julia/</link>
      <pubDate>Fri, 17 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-give-layout-and-make-subplot-in-julia/</guid>
      <description>개요 줄리아에서 서브플랏에 관련된 옵션은 layout 옵션을 통해 제어할 수 있다. 정수를 입력하면 해당 수만큼의 그리드를 눈치껏 만들어준다. 정수의 2-튜플을 입력하면 정확히 주어진 대로의 그리드를 만들어준다. @layout 매크로를 통해 Plots.GridLayout 타입의 복잡한 레이아웃을 구성한다. 코드 using Plots left = plot(randn(100), color = :red) right = plot(randn(100), color = :blue) plot(left, right) png(&amp;#34;easyone&amp;#34;) data = rand(10, 6) plot(data, layout = 6) png(&amp;#34;easytwo&amp;#34;) plot(data, layout = (3,2)) png(&amp;#34;easygrid&amp;#34;) l = @layout [p1 ;</description>
    </item>
    
    <item>
      <title>보조통계량</title>
      <link>https://freshrimpsushi.github.io/posts/ancillary-statistiic/</link>
      <pubDate>Wed, 15 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ancillary-statistiic/</guid>
      <description>정의 1 $S$ 가 샘플 $\mathbf{X}$ 의 통계량이라고 하자. $S \left( \mathbf{X} \right)$ 의 분포가 모수 $\theta$ 에 종속되지 않으면 보조통계량Ancillary statistiic이라 한다. 설명 사실 말로 할 땐 아무도 보조통계량이라 하지 않고 [앵실러리 스태티스틱]이라고 발음한다. 충분통계량이 $\theta$ 에 대한 모든 정보를 가지고 있다는 느낌이라면, 보조통계량은 $\theta$ 에 대한 정보가 전혀 없</description>
    </item>
    
    <item>
      <title>줄리아에서 그림 범례 위치 조정하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-change-position-of-legend-in-julia-plot/</link>
      <pubDate>Mon, 13 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-change-position-of-legend-in-julia-plot/</guid>
      <description>개요 1 plot() 함수의 legend 옵션으로 범례의 위치를 자유롭게 조정할 수 있다. $0$ 부터 $1$ 사이의 값으로 이루어진 2-튜플을 주면 정확히 그 위치에 찍히고, 그 외에는 심볼로 제어할 수 있다. 심볼의 경우 top/bottom 과 left/right를 순서대로 연결해서 조합한다. 가장 앞에 outer를 붙이면 그림 바깥에 범례가 찍힌다. 조합으로 만들어지는 심볼의 예시로는 다음이</description>
    </item>
    
    <item>
      <title>최소충분통계량</title>
      <link>https://freshrimpsushi.github.io/posts/minimal-sufficient-statistiic/</link>
      <pubDate>Sat, 11 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/minimal-sufficient-statistiic/</guid>
      <description>정의 1 충분통계량 $T \left( \mathbf{X} \right)$ 가 모든 다른 충분통계량 $T&amp;rsquo; \left( \mathbf{X} \right)$ 에 대해 $T \left( \mathbf{x} \right)$ 가 $T&amp;rsquo; \left( \mathbf{x} \right)$ 의 함수로 나타나면 $T \left( \mathbf{X} \right)$ 를 최소충분통계량Minimal Sufficient statistiic이라 한다. 정리 $f \left( \mathbf{x} ; \theta \right)$ 가 샘플 $\mathbf{X}$ 의 확률밀도함수 혹은 확률질량함수라 하자. 모든 실현 $\mathbf{x} , \mathbf{y}$ 에 대해 $$ {{ f \left( \mathbf{x} ; \theta \right) } \over { f \left( \mathbf{y} ; \theta \right) }} = c (\theta) \text{ is constant as function a of</description>
    </item>
    
    <item>
      <title>줄리아 그림 가로세율 비율 조정하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-controll-ratio-of-plot-in-julia/</link>
      <pubDate>Thu, 09 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-controll-ratio-of-plot-in-julia/</guid>
      <description>개요 1 그림의 가로세로를 조절하기 위해서는 옵션에 ratio를 넣으면 된다. 추천하는 다른 가명으로는 aspect_ratios, axis_ratio가 있다. ratio = :none: 기본값으로, 그림의 사이즈에 비율이 맞춰진다. ratio = :equal: 그림의 사이즈에 상관없이 가로세로의 축이 일대일 비율로 맞춰진다. ratio = Number: Number대로 비율이 맞춰진다. Number는 ${{세로} \over {</description>
    </item>
    
    <item>
      <title>줄리아에서 CSV 출력 시 깨진 문자 해결법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-fix-broken-text-of-csv-in-julia/</link>
      <pubDate>Sun, 05 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-fix-broken-text-of-csv-in-julia/</guid>
      <description>에러 using DataFrames, CSV example = DataFrame(x = 1:10, 가 = &amp;#34;나다&amp;#34;) CSV.write(&amp;#34;example.csv&amp;#34;, example) 줄리아에서 CSV 파일로 출력하다보면 위와 같이 한글이 깨지는 현상을 볼 수가 있다. 원인 사실 한글이 깨지는 게 아니라 유니코드 인코딩의 문제로, 특히 UTF-8 인코딩의 BOMByte Order Mark 때문에 일어난다. 파이썬 등에서는 인코딩을 UTF-8-sig로 주는 식으로 해결할 수 있다. 해결법 1 CSV.write(&amp;#34;example.csv&amp;#34;, example, bom = true) CSV</description>
    </item>
    
    <item>
      <title>줄리아에서 텍스트 출력 꾸미는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-decorate-text-in-julia-console/</link>
      <pubDate>Wed, 01 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-decorate-text-in-julia-console/</guid>
      <description>개요 줄리아에서 텍스트 출력을 꾸미는 패키지로는 Crayons.jl이 알려져있다.1 코드 using Crayons print(Crayon(background = :red), &amp;#34;빨강&amp;#34;) print(Crayon(foreground = :blue), &amp;#34;파랑&amp;#34;) print(Crayon(bold = true), &amp;#34;볼드&amp;#34;) print(Crayon(italics = true), &amp;#34;이탤릭&amp;#34;) print(Crayon(bold = true, italics = true), &amp;#34;볼드 이탤릭&amp;#34;) 위 콘솔을 실행하면 다음과 같이 꾸며진 결과를 얻</description>
    </item>
    
    <item>
      <title>줄리아 그림에 선분 넣는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-put-line-segment-in-julia-plot/</link>
      <pubDate>Sat, 28 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-put-line-segment-in-julia-plot/</guid>
      <description>코드 using Plots scatter(rand(100), randn(100)) plot!([0,1],[0,1]) png(&amp;#34;example1&amp;#34;) plot!([.00,.25,.50],[-2,0,-2]) png(&amp;#34;example2&amp;#34;) θ = 0:0.01:2π plot!(.5 .+ cos.(θ)/3, 1.5sin.(θ)) png(&amp;#34;example3&amp;#34;) 위 코드를 실행해 그림에 선분을 넣는 방법을 알아보자. 선분 plot!([0,1],[0,1]) 그냥 선분 하나를 긋든 다른 걸 긋든 방식은 똑같다. 선분에는 두 개의 점이 필요하므로 x좌표의 배열과 y좌표의 배열을 주면 된다. 여러 선분 plot!([.00,.25,.50],[-2,0,-2]) y2는 한번에 두 개의 선분을 그려낸 것이다. 선</description>
    </item>
    
    <item>
      <title>우도함수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-likelihood-function/</link>
      <pubDate>Thu, 26 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-likelihood-function/</guid>
      <description>정의 1 샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right)$ 의 조인트 확률밀도함수 혹은 확률질량함수를 $f(\mathbf{x}|\theta)$ 라 하자. 그 실현 $\mathbf{x}$ 가 주어져 있을 때, $f(\mathbf{x}|\theta)$ 를 $\theta$ 에 대한 함수로 본 $$ L \left( \theta | \mathbf{x} \right) := f \left( \mathbf{x} | \theta \right) $$ 를 우도 함수Likelihood Function라 한다. 설명 최대우도추정량을 논하는 맥락에서는 샘플에 더불어 iid여야할 필요가 있지만, 우도 원리Likelih</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터프레임 정렬하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-sort-dataframe-in-julia/</link>
      <pubDate>Tue, 24 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-sort-dataframe-in-julia/</guid>
      <description>코드 using DataFrames Unit1 = DataFrame( member = [&amp;#34;다영&amp;#34;,&amp;#34;루다&amp;#34;,&amp;#34;수빈&amp;#34;,&amp;#34;진숙&amp;#34;], birth = [99,97,96,99], height = [161,157,159,162] ) Unit2 = DataFrame( member = [&amp;#34;소정&amp;#34;,&amp;#34;주연&amp;#34;,&amp;#34;지연&amp;#34;,&amp;#34;현정&amp;#34;], birth = [95,98,95,94], height = [166,172,163,165] ) WJSN = vcat(Unit1, Unit2) push!(WJSN, [&amp;#34;다원&amp;</description>
    </item>
    
    <item>
      <title>수리통계학에서의 델타 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/delta-method-in-mathematical-statistiics/</link>
      <pubDate>Sun, 22 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/delta-method-in-mathematical-statistiics/</guid>
      <description>정리 상수 $\theta \in \mathbb{R}$ 와 확률변수의 시퀀스 $\left\{ Y_{n} \right\}_{n \in \mathbb{N}}$ 에 대해 $\sqrt{n} \left( Y_{n} - \theta \right)$ 가 정규분포 $N \left(0, \sigma^{2} \right)$ 로 분포수렴한다고 하자. $1$계 델타 메소드 1 $g&#39;(\theta) \ne 0$ 이 존재한다면, $$ \sqrt{n} \left[ g \left( Y_{n} \right) - g(\theta) \right] \overset{D}{\to} N \left( 0, \sigma^{2} \left[ g&#39;(\theta) \right]^{2} \right) $$ $2$계 델타 메소드 2 $g&#39;(\theta) = 0$ 이고 $g&#39;&amp;rsquo;(\theta) \ne 0$ 이 존재한다면, $$ n \left[ g \left( Y_{n} \right) - g(\theta) \right] \overset{D}{\to} \sigma^{2} {{ g&#39;&amp;rsquo;\left( \theta \right) } \over { 2 }} \chi_{1}^{2} $$ 일반화된 델타 메소드 $n$ 에 종</description>
    </item>
    
    <item>
      <title>줄리아에서 데이터프레임에 새 행 넣는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-add-new-row-to-dataframe-in-julia/</link>
      <pubDate>Fri, 20 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-add-new-row-to-dataframe-in-julia/</guid>
      <description>코드 using DataFrames Unit1 = DataFrame( member = [&amp;#34;다영&amp;#34;,&amp;#34;루다&amp;#34;,&amp;#34;수빈&amp;#34;,&amp;#34;진숙&amp;#34;], birth = [99,97,96,99], height = [161,157,159,162] ) Unit2 = DataFrame( member = [&amp;#34;소정&amp;#34;,&amp;#34;주연&amp;#34;,&amp;#34;지연&amp;#34;,&amp;#34;현정&amp;#34;], birth = [95,98,95,94], height = [166,172,163,165] ) WJSN = vcat(Unit1, Unit2) push!(WJSN, [&amp;#34;다원&amp;</description>
    </item>
    
    <item>
      <title>스털링 공식의 수리통계적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/mathematical-statistiical-proof-of-stirling-approximation/</link>
      <pubDate>Wed, 18 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mathematical-statistiical-proof-of-stirling-approximation/</guid>
      <description>정리 $$ \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ 설명 스털링 근사 혹은 스털링 공식Stirling Formula은 통계학이나 물리학 등 여러 곳에서 유용하게 쓰인다. 수리통계적인 증명은 분포이론에 빠삭하다면야 오히려 다른 증명에 비해 직관적이고 이해하기 쉽다. 같이보기 가우스 적분을 이용한 증명 엄밀한 증명 증명 $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} \exp (1)$ 이라고 하자</description>
    </item>
    
    <item>
      <title>줄리아에서 무한대 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-infinity-in-julia/</link>
      <pubDate>Mon, 16 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-infinity-in-julia/</guid>
      <description>개요 Infinities.jl은 줄리아에서 무한대 기호를 사용하게 도와주는 패키지다.1 과학계산에 관련된 코딩에 있어서 무한대는 의외로 유용하다. 코드 julia&amp;gt; 8 &amp;lt; Inf true 개요에서 무한대를 사용하는 게 아니라 무한대 기호를 사용하게 도와준다고 한 이유는 사실 패키지 없이도 사용할 수 있기 때문이다. julia&amp;gt; using Infinities julia&amp;gt; 8 &amp;lt; ∞ true julia&amp;gt; -∞ &amp;lt; 8 true julia&amp;gt; max(∞, 10,</description>
    </item>
    
    <item>
      <title>t-분포에서 F-분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-f-distribution-from-t-distribution/</link>
      <pubDate>Sat, 14 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-f-distribution-from-t-distribution/</guid>
      <description>정리 1 자유도 $\nu &amp;gt; 0$ 인 t-분포를 따르는 확률변수 $X \sim t(\nu)$ 에 대해 다음과 같이 정의된 $Y$ 는 F-분포 $F (1,\nu)$ 을 따른다. $$ Y := X^{2} \sim F (1,\nu) $$ 증명 카이제곱분포를 통한 우회 $X \sim t(\nu)$ 는 표준정규분포를 따르는 $Z \sim N(0,1)$ 와 자유도 $\nu$ 인 카이제곱분포를 따르는 $W$ 에 대해 $$ X^{2} = \left( {{ Z } \over { \sqrt{W / \nu} }} \right)^{2} = {{ Z^{2} / 1 } \over { W / \nu }} \qquad , Z \perp W $$ 이고, $Z^{2}$ 은 자유도 $1$ 인 카</description>
    </item>
    
    <item>
      <title>줄리아에서 패키지 특정 버전으로 설치하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-install-package-specific-version-in-julia/</link>
      <pubDate>Thu, 12 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-install-package-specific-version-in-julia/</guid>
      <description>가이드 1 (@v1.6) pkg&amp;gt; status JuMP Status `C:\Users\rmsms\.julia\environments\v1.6\Project.toml` [4076af6c] JuMP v0.20.0 REPL에서 ] 키를 누르면 패키지 모드로 진입한다. 예로써 위와 같이 버전이 v0.20.0인 패키지를 v0.21로 버전업하고 싶다면, 다음과 같이 패키지 뒤에 @x.yy를 붙여서 설치하면 된다. (@v1.6) pkg&amp;gt; add JuMP@0.21 Resolving package versions... ... (@v1.6) pkg&amp;gt; status JuMP Status `C:\Users\rmsms\.julia\environments\v1.6\Project.toml` [4076af6c] JuMP v0.21.4 다시 버전을 확인해보면 정상적으로 패키지의 버전이 변경된 것을 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>F-분포에서 베타 분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/derivation-of-beta-distribution-from-f-distribution/</link>
      <pubDate>Tue, 10 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivation-of-beta-distribution-from-f-distribution/</guid>
      <description>정리 1 자유도 $r_{1} , r_{2}$ 인 F-분포를 따르는 확률변수 $X \sim F \left( r_{1}, r_{2} \right)$ 에 대해 다음과 같이 정의된 $Y$ 는 베타분포 $\text{Best} \left( {{ r_{1} } \over { 2 }} , {{ r_{2} } \over { 2 }} \right)$ 를 따른다. $$ Y := {{ \left( r_{1} / r_{2} \right) X } \over { 1 + \left( r_{1} / r_{2} \right) X }} \sim \text{Beta} \left( {{ r_{1} } \over { 2 }} , {{ r_{2} } \over { 2 }} \right) $$ 증명 전략: 확률밀도함수로 직접연역한다. F-분포의 정의: 자유도 $r_{1}, r_{2} &amp;gt; 0$ 에 대해 다음</description>
    </item>
    
    <item>
      <title>줄리아에서 빈 데이터프레임 만드는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-make-empty-dataframe-in-julia/</link>
      <pubDate>Sun, 08 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-make-empty-dataframe-in-julia/</guid>
      <description>개요 많은 언어에서 데이터프레임을 지원함에도 의외로 할 때마다 새롭고 짜증나는 게 빈 배열 생성이다. 코드 타입 지정 julia&amp;gt; using DataFrames julia&amp;gt; df1 = DataFrame(x = Int64[], y = String[]) 0×2 DataFrame 실제로 빈 배열을 데이터로써 넣어주면 된다. 이 때 타입을 지정하게 되는데, 데이터가 전혀 없을 땐 칼럼 이름과 타입도 보이지 않는다. julia&amp;gt; push!(df1, [3, &amp;#34;three&amp;#34;]) 1×2 DataFrame │ Row │ x │ y │ │ │ Int64 │ String │ ├─────┼─</description>
    </item>
    
    <item>
      <title>줄리아 문자열에서 특정 패턴 위치 찾는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-some-pattern-of-string-in-julia/</link>
      <pubDate>Sat, 30 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-some-pattern-of-string-in-julia/</guid>
      <description>코드 julia&amp;gt; findfirst(&amp;#34;li&amp;#34;, &amp;#34;multicolinearlity&amp;#34;) 8:9 julia&amp;gt; findlast(&amp;#34;li&amp;#34;, &amp;#34;multicolinearlity&amp;#34;) 14:15 julia&amp;gt; findnext(&amp;#34;l&amp;#34;, &amp;#34;multicolinearlity&amp;#34;, 1) 3:3 julia&amp;gt; findnext(&amp;#34;l&amp;#34;, &amp;#34;multicolinearlity&amp;#34;, 4) 8:8 julia&amp;gt; findnext(&amp;#34;l&amp;#34;, &amp;#34;multicolinearlity&amp;#34;, 9) 14:14 julia&amp;gt; findfirst(r&amp;#34;t.+t&amp;#34;, &amp;#34;multicolinearlity&amp;#34;) 4:16 findfirst(pattern, A) 문자열 A에서 pattern과 일치하는 구간을 Range로 리턴한다. 패턴에는 정규표현식이 들어갈 수 있다. 마지막 예시에서는 첫번째 t부터 마지막 t까지의 구간을 찾아서 리턴했다. 환경 OS: Windows julia: v1.6.2</description>
    </item>
    
    <item>
      <title>줄리아에서 특정 문자열 포함 여부 확인하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-some-string-included-in-julia/</link>
      <pubDate>Tue, 26 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-some-string-included-in-julia/</guid>
      <description>코드 julia&amp;gt; contains(&amp;#34;qwerty&amp;#34;, &amp;#34;er&amp;#34;) true julia&amp;gt; contains(&amp;#34;qwerty&amp;#34;, &amp;#34;et&amp;#34;) false julia&amp;gt; contains(&amp;#34;qwerty&amp;#34;, r&amp;#34;q?&amp;#34;) true contains(haystack::AbstractString, needle) haystack에 needle이 포함되었는지 확인해 불리언으로 리턴한다. needle에는 r&amp;quot;...&amp;quot;와 같이 정규표현식이 들어갈 수 있다. 환경 OS: Windows julia: v1.6.2</description>
    </item>
    
    <item>
      <title>줄리아에서 소인수분해 및 소수관련 함수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-factorization-in-julia/</link>
      <pubDate>Fri, 22 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-factorization-in-julia/</guid>
      <description>개요 Primes.jl은 소수에 관련된 함수 및 소인수분해를 다루는 패키지다. 해석적 정수론에 관련된 함수에 대한 구현은 아직 미비한 편이다. 패키지의 모든 기능을 정리한 것은 아니고 유용할만한 것만 추렸으니 자세한 것은 리파지터리를 확인하자. 1 타입 소인수분해 Primes.Factorization julia&amp;gt; factor(12) 2^2 * 3 julia&amp;gt; factor(12)[1] 0 julia&amp;gt; factor(12)[2] 2 julia&amp;gt; factor(12)[3] 1 julia&amp;gt; factor(12)[4] 0 소인수분해는 밑과 지수가 구분되어서 독자</description>
    </item>
    
    <item>
      <title>줄리아에서 다항함수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-polynomials.jl-in-julia/</link>
      <pubDate>Mon, 18 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-polynomials.jl-in-julia/</guid>
      <description>개요 Polynomials.jl은 다항 함수의 표현 및 계산 등을 포함한 패키지다. 다항함수라는 게 수학적으로 쉬워서 그런지 코딩도 간단하게 생각하는 경우가 있는데 막상 필요한 기능들을 구현하다보면 꽤 번거롭다. 물론 엄청 어려운 건 아닌데, 어지간하면 패키지를 사용하도록 하자. 패키지의 모든 기능을 정리한 것은 아니고 유용할만한 것만 추렸으니</description>
    </item>
    
    <item>
      <title>베이불 분포</title>
      <link>https://freshrimpsushi.github.io/posts/weibull-distribution/</link>
      <pubDate>Sat, 16 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weibull-distribution/</guid>
      <description>정의 스케일Scale 파라메터 $\lambda &amp;gt; 0$ 와 쉐이프Shape 파라메터 $k &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 확률분포를 베이불 분포Weibull Distribution라 한다. $$ f(x) = {{ k } \over { \lambda }} \left( {{ x } \over { \lambda }} \right)^{k-1} e^{-(x/\lambda)^{k}} \qquad , x \ge 0 $$ 정리 [1] 지수 분포의 일반화: 베이불 분포는 $k=1$ 일 때 지수 분포가 된다. [2] 레일리 분포의 일반화:</description>
    </item>
    
    <item>
      <title>줄리아에서 문자열 합치는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-concatenate-strings-in-julia/</link>
      <pubDate>Thu, 14 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-concatenate-strings-in-julia/</guid>
      <description>코드 문자열 합치기 * julia&amp;gt; &amp;#34;oh&amp;#34; * &amp;#34;my&amp;#34; * &amp;#34;girl&amp;#34; &amp;#34;ohmygirl&amp;#34; 파이썬의 +에 해당한다. 여러 문자열 합치기 string() julia&amp;gt; string(&amp;#34;oh&amp;#34;,&amp;#34;my&amp;#34;, &amp;#34;girl&amp;#34;) &amp;#34;ohmygirl&amp;#34; R의 paste0()에 해당한다. 문자열의 리스트의 아이템으로써 합치기 join() julia&amp;gt; OMG = [&amp;#34;oh&amp;#34;,&amp;#34;my&amp;#34;, &amp;#34;girl&amp;#34;] 3-element Vector{String}: &amp;#34;oh&amp;#34; &amp;#34;my&amp;#34; &amp;#34;girl&amp;#34; julia&amp;gt; join(OMG) &amp;#34;ohmygirl&amp;#34; 파이썬의 join()에 해당한다. 같은 문자열 반복하기 ^ julia&amp;gt; &amp;#34;=-&amp;#34; ^ 10 &amp;#34;=-=-=-=-=-=-=-=-=-=-&amp;#34; 파이썬의 *에 해당한다. 거듭제곱으로 반복을 표현한 것은 전혀 우연이 아닌</description>
    </item>
    
    <item>
      <title>줄리아 그림에서 특정 데이터만 라벨 숨기는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-hide-some-lables-in-julia-plot/</link>
      <pubDate>Sun, 10 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-hide-some-lables-in-julia-plot/</guid>
      <description>코드 1 using Plots x = rand(30) y = rand(30) z = rand(30) plot(x) plot!(y) plot!(z) png(&amp;#34;result1&amp;#34;) 위와 같이 세 데이터에 대한 라벨 중 특정 데이터만 범례에서 나타나지 않게 하고 싶을 수 있다. label = &amp;quot;&amp;quot; plot(x, label = &amp;#34;&amp;#34;) plot!(y) png(&amp;#34;result2&amp;#34;) 그럴 땐 위와 같이 label = &amp;quot;&amp;quot;을 옵션으로 주면 된다. 첫번째 데이터가 그림에선 출력되지만 범례에서는 나타나지 않는 것을 볼 수 있다. primary = false plot!(z, primary = false) png(&amp;#34;result3&amp;#34;) 다른 방법으로는 primary = fal</description>
    </item>
    
    <item>
      <title>줄리아 그림에 텍스트 넣는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-put-text-in-julia-plot/</link>
      <pubDate>Wed, 06 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-put-text-in-julia-plot/</guid>
      <description>코드 1 annotate!()를 사용하면 된다. 다음 코드는 브라운 모션에서 최대점과 최소점을 표시한 그림을 그려주는 코드다. using Plots cd(@__DIR__) data = cumsum(randn(100)) plot(data, color = :black, legend = :none) annotate!(argmax(data), maximum(data), &amp;#34;max\n&amp;#34;) annotate!(argmin(data), minimum(data), &amp;#34;\nmin&amp;#34;) png(&amp;#34;result&amp;#34;) 환경 OS: Windows julia: v1.7.0 https://discourse.julialang.org/t/plots-annotate/37784&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>지수족 확률분포</title>
      <link>https://freshrimpsushi.github.io/posts/exponential-family/</link>
      <pubDate>Mon, 04 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/exponential-family/</guid>
      <description>정의 12 모수 $\theta$ 인 확률분포의 확률질량함수 혹은 확률밀도함수가 어떤 함수 $p,K,H,q,h,c,w_{i},t_{i}$ 들에 대해 다음과 같이 나타낼 수 있으면 지수족Exponential Family 혹은 익스포넨셜 클래스Exponential Class에 속한다고 한다. $$ \begin{align*} f \left( x ; \theta \right) =&amp;amp; \exp \left( p (\theta) K (x) + H(x) + q(\theta) \right) \\ =&amp;amp; h(x) c (\theta) \exp \left( \sum_{i=1}^{k} w_{i} (\theta) t_{i} (x) \right) \end{align*} $$ 설명 정의에서 두 수식의 형태가 사실상 같다</description>
    </item>
    
    <item>
      <title>줄리아 그림에 한글 넣는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-korean-in-julia-plot/</link>
      <pubDate>Sat, 02 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-korean-in-julia-plot/</guid>
      <description>환경 OS: Windows julia: v1.6.2 에러 julia&amp;gt; plot(data, color = :black, label = &amp;#34;값&amp;#34;, title = &amp;#34;브라운모션&amp;#34;) GKS: glyph missing from current font: 48652 GKS: glyph missing from current font: 46972 GKS: glyph missing from current font: 50868 GKS: glyph missing from current font: 47784 GKS: glyph missing from current font: 49496 원인 한글 폰트를 못 찾아서 그렇다. 해결법 두 방법 별로 좋지만은 않으며, 대안이 있다면 언제든지 제보 바란다. 줄리아를 사용하는 일이라면 한국어가 많이 필요하지 않</description>
    </item>
    
    <item>
      <title>확률 밀도 함수의 컨볼루션 공식</title>
      <link>https://freshrimpsushi.github.io/posts/convolution-formula-for-pdfs/</link>
      <pubDate>Thu, 31 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convolution-formula-for-pdfs/</guid>
      <description>공식 1 독립인 두 연속확률변수 $X, Y$ 의 확률밀도함수가 $f_{X}, f_{Y}$ 로 주어져 있다고 하자. 그러면 $Z := X + Y$ 의 확률밀도함수는 두 확률밀도함수의 합성곱 $f_{Z} = f_{X} \ast f_{Y}$ 이다. $$ f_{Z} (z) = \left( f_{X} \ast f_{Y} \right) (z) = \int_{-\infty}^{\infty} f_{X} (w) f_{Y} (z-w) dw $$ 유도 $W := X$ 라 하면 자코비안은 $$ \begin{Vmatrix} 1 &amp;amp; 1 \\ 1 &amp;amp; 0 \end{Vmatrix} = \left| -1 \right| = 1 $$ 이고, $Z$ 와 $W$ 의 조인트 확률밀도함수 $f_{Z,W}$ 는 $$ f_{Z,W} \left( z,w \right) = f_{X,Y} \left( w, z-w \right) = f_{X} (w)</description>
    </item>
    
    <item>
      <title>레일리 분포</title>
      <link>https://freshrimpsushi.github.io/posts/rayleigh-distribution/</link>
      <pubDate>Tue, 29 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rayleigh-distribution/</guid>
      <description>정의 1 스케일 파라메터 $\sigma &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포를 레일리 분포Rayleigh Distribution라 한다. $$ f(x) = {{ x } \over { \sigma^{2} }} e^{ - x^{2} / (2 \sigma^{2})} \qquad , x \ge 0 $$ 정리 [1]: $X, Y \sim N \left( 0, \sigma^{2} \right)$ 면 $\sqrt{X^{2} + Y^{2}}$ 는 $\sigma &amp;gt; 0$ 인 레일리 분포를 따른다. 설명 정리 [1]에서 알 수 있듯, 레일리 분포는 이변량 정규분포를 따르는</description>
    </item>
    
    <item>
      <title>함수를 취한 확률변수꼴 합의 기대값</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-of-sum-of-function-values-of-random-variables/</link>
      <pubDate>Sun, 27 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-of-sum-of-function-values-of-random-variables/</guid>
      <description>정리 1 $X_{1} , \cdots , X_{n}$ 이 랜덤 샘플이고, $E g \left( X_{1} \right)$ 과 $\text{Var} g \left( X_{1} \right)$ 가 존재하게끔 하는 함수 $g : \mathbb{R} \to \mathbb{R}$ 가 주어져 있다고 하자. 그러면 다음이 성립한다. [1] 평균: $$ E \left( \sum_{k = 1}^{n} g \left( X_{k} \right) \right) = n E g \left( X_{1} \right) $$ [2] 분산: $$ \text{Var} \left( \sum_{k = 1}^{n} g \left( X_{k} \right) \right) = n \text{Var} g \left( X_{1} \right) $$ 설명 이 정리에서 눈여겨보아야 할 부분은 $\left\{ X_{k} \right\}_{k=1}^{n}$ 이 랜덤 샘플, 다시 말해 iid라는 것이다. 가령</description>
    </item>
    
    <item>
      <title>줄리아에서 파이썬처럼 문자열 다루는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-handle-strings-like-python-in-julia/</link>
      <pubDate>Sat, 19 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-handle-strings-like-python-in-julia/</guid>
      <description>코드 1 2 3 julia&amp;gt; replace(&amp;#34;qwerty&amp;#34;, &amp;#34;q&amp;#34;=&amp;gt;&amp;#34;Q&amp;#34;) &amp;#34;Qwerty&amp;#34; julia&amp;gt; join(&amp;#34;qwerty&amp;#34;, &amp;#34;,&amp;#34;) &amp;#34;q,w,e,r,t,y&amp;#34; julia&amp;gt; split(&amp;#34;qwerty&amp;#34;, &amp;#34;&amp;#34;) 6-element Vector{SubString{String}}: &amp;#34;q&amp;#34; &amp;#34;w&amp;#34; &amp;#34;e&amp;#34; &amp;#34;r&amp;#34; &amp;#34;t&amp;#34; &amp;#34;y&amp;#34; 줄리아는 문자열 처리에 특출난 언어는 아니지만, 그 때문인지 파이썬을 많이 따라해서 쉽고 빠르게 배울 수 있다. 대부분 다 알던 기능들이 구현되어 있어 모듈인지 아닌지 하는 부분만 빼면 사용법이 거의 비슷하다. 참고로 replace()를 쓸 때 &amp;quot;q&amp;quot;=&amp;gt;&amp;quot</description>
    </item>
    
    <item>
      <title>줄리아에서 근사값 체크하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-approximate-value-in-julia/</link>
      <pubDate>Tue, 15 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-approximate-value-in-julia/</guid>
      <description>코드 비교연산자로써 $\approx$ 를 사용하면 두 값이 충분히 비슷할 때만 참을 반환한다. ≈ 는 $\TeX$에서와 마찬가지로 \approx 을 입력하고 탭(Tab)을 치면 쓸 수 있다. julia&amp;gt; π ≈ 3.141592653 true julia&amp;gt; π ≈ 3.14159265 true julia&amp;gt; π ≈ 3.1415926 false julia&amp;gt; π ≈ 3.141592 false 환경 OS: Windows julia: v1.7.0</description>
    </item>
    
    <item>
      <title>줄리아에서 딕셔너리와 페어</title>
      <link>https://freshrimpsushi.github.io/posts/dictionary-and-pair-in-julia/</link>
      <pubDate>Fri, 11 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dictionary-and-pair-in-julia/</guid>
      <description>코드 1 julia&amp;gt; d = Dict(&amp;#34;A&amp;#34;=&amp;gt;1, &amp;#34;B&amp;#34;=&amp;gt;2) Dict{String, Int64} with 2 entries: &amp;#34;B&amp;#34; =&amp;gt; 2 &amp;#34;A&amp;#34; =&amp;gt; 1 julia&amp;gt; push!(d,(&amp;#34;C&amp;#34;,3)) ERROR: MethodError: no method matching push!(::Dict{String, Int64}, ::Tuple{String, Int64}) julia&amp;gt; push!(d,&amp;#34;C&amp;#34; =&amp;gt; 3) Dict{String, Int64} with 3 entries: &amp;#34;B&amp;#34; =&amp;gt; 2 &amp;#34;A&amp;#34; =&amp;gt; 1 &amp;#34;C&amp;#34; =&amp;gt; 3 julia&amp;gt; typeof(&amp;#34;C&amp;#34; =&amp;gt; 3) Pair{String, Int64} 줄리아의 딕셔너리Dictionary는 여타 프로그래밍 언어에서 쉽게 찾아볼 수 있는 키Key와 밸류Value로 묶인 자료형이다. 줄리아에서 약간 다른 점은 딕셔너리를 각 페어Pair의 모임으로 본다는 것이다. 위의</description>
    </item>
    
    <item>
      <title>줄리아에서 .mat처럼 데이터를 저장하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-save-data-like-matlab-mat-file/</link>
      <pubDate>Mon, 07 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-save-data-like-matlab-mat-file/</guid>
      <description>코드 1 JLD는 줄리아를 사용하면서 생기는 임시 데이터들을 저장할 수 있도록 해주는 패키지다. 퓨어 줄리아 프로젝트를 하면서 데이터의 입출력이 번거롭다면 유용하게 쓸 수 있다. using JLD cd(@__DIR__); pwd() numpad = reshape(1:9, 3,3) cube = zeros(Int64, 3,3,3) save(&amp;#34;mydata.jld&amp;#34;, &amp;#34;numpad&amp;#34;,numpad, &amp;#34;cube&amp;#34;,cube) mydata = load(&amp;#34;mydata.jld&amp;#34;) mydata[&amp;#34;numpad&amp;#34;] mydata[&amp;#34;cube&amp;#34;] 실행결과 julia&amp;gt; numpad = reshape(1:9, 3,3) 3×3 reshape(::UnitRange{Int64}, 3, 3) with eltype Int64: 1 4 7 2 5 8 3 6 9 julia&amp;gt; cube = zeros(Int64, 3,3,3) 3×3×3 Array{Int64, 3}: [:, :, 1] = 0 0 0 0 0 0 0 0 0 [:, :,</description>
    </item>
    
    <item>
      <title>줄리아의 반복문에서 인덱스와 값을 동시에 참조하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/julia-enumerate-equivalent-to-enumerate-in-python/</link>
      <pubDate>Thu, 03 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/julia-enumerate-equivalent-to-enumerate-in-python/</guid>
      <description>코드 1 Base.Iterators.enumerate() 는 파이썬과 같이 배열의 인덱스와 값을 동시에 참조할 수 있는 반복자Iterator를 반환한다. julia&amp;gt; x = [3,5,4,1,2] 5-element Vector{Int64}: 3 5 4 1 2 julia&amp;gt; for (idx, value) in enumerate(x) println(&amp;#34;x[$idx]: $value&amp;#34;) end x[1]: 3 x[2]: 5 x[3]: 4 x[4]: 1 x[5]: 2 julia&amp;gt; typeof(enumerate(x)) Base.Iterators.Enumerate{Vector{Int64}} https://docs.julialang.org/en/v1/base/iterators/#Base.Iterators.enumerate&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>줄리아에서의 심볼</title>
      <link>https://freshrimpsushi.github.io/posts/sysbols-in-julia/</link>
      <pubDate>Sun, 29 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sysbols-in-julia/</guid>
      <description>개요 줄리아를 처음 접하면서 적잖이 당황할 수 있는 것이 바로 심볼Symbol 자료형이다. 심볼은 맨 앞에 :을 붙여서 사용하며, 어떤 내부 데이터도 없이 그 이름 그 자체로써 기능한다. 주로 이름이나 라벨, 딕셔너리 키 등으로 사용된다.1 설명 여타 프로그래밍 언어에서는 함수에 옵션을 줄 때 숫자로 주거나 의미를 정확히 하기 위해 문자열로 주곤 한다. 가령</description>
    </item>
    
    <item>
      <title>줄리아에서 배열의 원소들이 어떤 리스트에 속하는지 체크하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-check-that-elements-in-array-are-in-some-list/</link>
      <pubDate>Wed, 25 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-check-that-elements-in-array-are-in-some-list/</guid>
      <description>가이드 1 julia&amp;gt; x = rand(&amp;#39;a&amp;#39;:&amp;#39;c&amp;#39;, 10) 10-element Vector{Char}: &amp;#39;a&amp;#39;: ASCII/Unicode U+0061 (category Ll: Letter, lowercase) &amp;#39;a&amp;#39;: ASCII/Unicode U+0061 (category Ll: Letter, lowercase) &amp;#39;b&amp;#39;: ASCII/Unicode U+0062 (category Ll: Letter, lowercase) &amp;#39;c&amp;#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase) &amp;#39;b&amp;#39;: ASCII/Unicode U+0062 (category Ll: Letter, lowercase) &amp;#39;c&amp;#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase) &amp;#39;c&amp;#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase) &amp;#39;c&amp;#39;: ASCII/Unicode U+0063 (category Ll: Letter, lowercase) &amp;#39;b&amp;#39;: ASCII/Unicode U+0062 (category Ll: Letter, lowercase) &amp;#39;b&amp;#39;: ASCII/Unicode U+0062 (category Ll: Letter, lowercase) 위와 같은 배열이 있다고 하자. 예제에서 우리의 목표는 &#39;a&#39; 와 &#39;b&#39; 를 모두 골라내는 것이라고 하자. 상식적으로는 포함기호 $\in$로 브로드캐스트하면 될 것 같지만</description>
    </item>
    
    <item>
      <title>줄리아에서 우아한 반복문을 사용하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-write-elegant-loop-in-julia/</link>
      <pubDate>Sat, 21 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-write-elegant-loop-in-julia/</guid>
      <description>가이드 while while 문은 여타 언어들과 다를 게 없다. julia&amp;gt; while x &amp;lt; 10 x += 1 print(&amp;#34;$x- &amp;#34;) end 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - for julia&amp;gt; for i in 1:10 print(&amp;#34;$i- &amp;#34;) end 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - julia&amp;gt; for i = 1:10 print(&amp;#34;$i- &amp;#34;) end 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - julia&amp;gt; for i ∈ 1:10 print(&amp;#34;$i- &amp;#34;) end 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 줄리아에서 메이저하게 쓰이는 반복</description>
    </item>
    
    <item>
      <title>파레토 분포</title>
      <link>https://freshrimpsushi.github.io/posts/pareto-distribution/</link>
      <pubDate>Sun, 01 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pareto-distribution/</guid>
      <description>정의 1 스케일Scale 파라메터 $x_{0} &amp;gt; 0$ 과 쉐이프Shape 파라메터 $\alpha &amp;gt; 0$ 에 대해 다음과 같은 확률함수를 가지는 확률분포를 파레토 분포Pareto Distribution 혹은 멱법칙Power Law, 무척도 분포Scale-free Distribution라 한다. 연속형: 상수 $\displaystyle \int_{x_{0}}^{\infty} p(x) dx = 1$ 를 만족시키는 상수 $C$ 에 대해 $$ p(x) = C x^{-\alpha} \qquad , x &amp;gt; x_{0} $$ 이산형: 리만</description>
    </item>
    
    <item>
      <title>줄리아에서 plot에 tex 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-tex-in-julia-plot/</link>
      <pubDate>Fri, 30 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-tex-in-julia-plot/</guid>
      <description>코드 1 LaTeXStrings 라이브러리를 부르고 L&amp;quot;...&amp;quot; 과 같이 문자열 앞에 L을 적어주면 된다. @time using Plots @time using LaTeXStrings plot(0:0.1:2π, sin.(0:0.1:2π), xlabel = L&amp;#34;x&amp;#34;, ylabel = L&amp;#34;y&amp;#34;) title!(L&amp;#34;\mathrm{TeX\,representation:\,} y = \sin x , x \in [0, 2 \pi]&amp;#34;) 주의해야할 것은 패키지 이름의 대소문자가 정확히 LaTeXStrings 이라는 점과 일반 텍스트는 \text{} 가 먹히지 않으니 \mathrm{} 를 사용해야 한다는 점이다. 띄어쓰기는 \, 으로 한다. 환경</description>
    </item>
    
    <item>
      <title>줄리아에서 그림 배경 투명하게 출력하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-transparent-background-in-julia/</link>
      <pubDate>Fri, 16 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-transparent-background-in-julia/</guid>
      <description>코드 1 브라우저를 다크모드로 보면 확실히 배경이 투명하게 출력되었음을 확인할 수 있다. background_color 옵션에 :transparent 심볼을 넣어주면 된다. *.png로는 잘 저장하지만 *.pdf로는 저장이 잘 되지 않는다고 한다. using Plots plot(rand(10), background_color = :transparent) png(&amp;#34;example&amp;#34;) 옵션 이름에서 예상할 수 있듯 컬러 심볼을 넣어주면 해당 색으로 출력된다. 예를 들어 노란색인 :yellow 로 뽑은 그림은 다음과 같다. 환경 OS: Windows julia:</description>
    </item>
    
    <item>
      <title>줄리아에서 ==과 ===의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/how-different--and--in-julia/</link>
      <pubDate>Sun, 12 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-different--and--in-julia/</guid>
      <description>코드 1 ==는 값이 같은지를 비교하고, ===는 비교할 값이 가변Mutable인지 아닌지에 따라 다르게 작동한다. Mutable: 두 항이 같은 오브젝트인지 확인한다. 다시 말해, 프로그래밍적으로 두 변수가 구분될 수 있는지 없는지를 리턴한다. Immutable: 두 항의 타입이 같은지 체크하고, 두 항의 스트럭쳐가 같은지 체크하고, 그 각각의 요소가 ===하게 같은지 재귀적</description>
    </item>
    
    <item>
      <title>로그-정규분포</title>
      <link>https://freshrimpsushi.github.io/posts/log-normal-distribution/</link>
      <pubDate>Sat, 04 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/log-normal-distribution/</guid>
      <description>정의 1 $\mu \in \mathbb{R}$ 과 $\sigma^{2} &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\log N \left( \mu,\sigma^{2} \right)$ 를 로그-정규분포Normal Distribution라고 한다. $$ f(x) = {{ 1 } \over { x \sigma \sqrt{2 \pi}}} \exp \left[ - {{ \left( \log x - \mu \right)^{2} } \over { 2 \sigma^{2} }} \right] \qquad, x &amp;gt; 0 $$ 설명 사실 위의 정의는 말도 안 되게 어렵고, 직관적으로는 다음과 같이 로그 함수를 취했을 때 정규분포를 따르는</description>
    </item>
    
    <item>
      <title>줄리아에서 비트 배열 반전시키는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-get-negation-of-bit-array/</link>
      <pubDate>Fri, 27 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-get-negation-of-bit-array/</guid>
      <description>코드 1 아주 간단한데 부정 연산 !과 ~을 그냥 단항 연산이 아니라 함수로 보고 !. 혹은 ~.을 취하는 실수를 많이 한다. .!이나 .~으로 쓰면 된다. julia&amp;gt; a = rand(1,10) .&amp;lt; 0.5 1×10 BitMatrix: 1 1 0 0 1 0 1 0 0 0 julia&amp;gt; .!(a) 1×10 BitMatrix: 0 0 1 1 0 1 0 1 1 1 julia&amp;gt; .~(a) 1×10 BitMatrix: 0 0 1 1 0 1 0 1 1 1 환경 OS: Windows julia: v1.6.0 https://discourse.julialang.org/t/negation-of-boolean-array/16159/2&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>제1회 생새우초밥집 대회: Graph Group</title>
      <link>https://freshrimpsushi.github.io/posts/1-graph-group/</link>
      <pubDate>Wed, 11 Jul 1923 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1-graph-group/</guid>
      <description>2022년을 맞아 생새우초밥집은 독자 여러분들이 참가할 수 있는 정기 이벤트를 열게 되었습니다. 한 분기마다 한 개의 과제를 공개합니다. 이번 대회의 섹션은 순수수학으로, 그래프의 집합에 연산을 주고 그 구조에 대해서 탐구하는 것입니다. 예상 난이도는 학부 2~3학년 수준입니다. 그래프 그룹 $n$ 개의 레이블 된 심플 그래프의 집합을 $\mathbb{G}_{n}$ 과 같이 나타내봅</description>
    </item>
    
    <item>
      <title>줄리아에서 선형대수 패키지 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-linear-algebra-package-in-julia/</link>
      <pubDate>Sat, 07 Jul 1923 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-linear-algebra-package-in-julia/</guid>
      <description>개요 줄리아는 매트랩 수준으로 선형대수를 잘 지원한다. 오히려 매트랩 이상으로 발전된, 직관적이고 미려한 문법을 보면 줄리아가 만들어진 시점부터 잘 설계된 느낌을 받을 수 있다. 1 코드 julia&amp;gt; A = [ 1 0 3 0 5 1 3 1 9 ] 3×3 Matrix{Int64}: 1 0 3 0 5 1 3 1 9 보다시피 행렬을 정의하는 단계에서 이미 직관적이고 편하다. 이제 몇몇가지 상식적으로 있어야할 함수들</description>
    </item>
    
    <item>
      <title>줄리아에서 날짜 및 시간 관련 함수 사용하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-the-functions-for-time-or-date-in-julia/</link>
      <pubDate>Tue, 03 Jul 1923 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-the-functions-for-time-or-date-in-julia/</guid>
      <description>개요 1 Dates는 날짜 및 시간과 관련된 함수를 모아놓은 모듈이다. 일반적인 프로그래밍은 물론이고 시계열에 관련된, 아니 관련 없더라도 많은 데이터를 다루는 데에 있어서 유용할 수밖에 없다. 1 코드 전체코드 using Dates 오늘 = DateTime(2022,3,10) typeof(오늘) propertynames(오늘) 오늘.instant myformat = DateFormat(&amp;#34;d-m-y&amp;#34;) 내일 = Date(&amp;#34;11-3-2022&amp;#34;, myformat) Dates.day</description>
    </item>
    
    <item>
      <title>추상대수학에서의 프리 그룹</title>
      <link>https://freshrimpsushi.github.io/posts/free-group-in-abstract-algebra/</link>
      <pubDate>Thu, 07 Dec 1922 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/free-group-in-abstract-algebra/</guid>
      <description>정의 1 인덱스 집합 $I \ne \emptyset$ 에 대해 집합 $A := \left\{ a_{i} : i \in I \right\}$ 를 알파벳Alphabet이라 하고, 그 원소 $a_{i} \in A$ 를 레터Letter라 하자. 정수 $n \in \mathbb{Z}$ 에 대해 $a_{i}^{n}$ 와 같은 꼴을 음절Syllable이라 한다. 이들의 유한한 병치Juxtapostion인 문자열 $w$ 을 단어Word라 한다. 음절 $a_{i}^{n} a_{i}^{m}$ 은 $a_{i}^{n+m}$ 와 같이 나타낼 수 있으며, 이를 초등 축약E</description>
    </item>
    
    <item>
      <title>르벡공간의 횔더 부등식 증명</title>
      <link>https://freshrimpsushi.github.io/posts/%EB%A5%B4%EB%B2%A1%EA%B3%B5%EA%B0%84%EC%9D%98-%ED%9A%94%EB%8D%94-%EB%B6%80%EB%93%B1%EC%8B%9D-%EC%A6%9D%EB%AA%85/</link>
      <pubDate>Thu, 12 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/%EB%A5%B4%EB%B2%A1%EA%B3%B5%EA%B0%84%EC%9D%98-%ED%9A%94%EB%8D%94-%EB%B6%80%EB%93%B1%EC%8B%9D-%EC%A6%9D%EB%AA%85/</guid>
      <description>정리1 $\Omega \subset \mathbb{R}^{n}$를 열린 집합이라고 하자. 다음의 식을 만족시키는 두 상수 $1 \lt p \lt \infty, 1 \lt p^{\prime} \lt \infty$가 주어졌다고 하자. $$ \dfrac{1}{p}+\dfrac{1}{p^{\prime}} = 1 \left(\text{or } p^{\prime} = \frac{p}{p-1} \right) $$ 만약 $u \in L^p(\Omega)$, $v\in L^{p^{\prime}}(\Omega)$이면 $uv \in L^1(\Omega)$이고 아래의 부등식이 성립한다. $$ \| uv \|_{1} = \int_{\Omega} |u(x)v(x)| dx \le \| u</description>
    </item>
    
  </channel>
</rss>
