<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>데이터과학 on 생새우초밥집</title><link>https://freshrimpsushi.github.io/ko/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B3%BC%ED%95%99/</link><description>Recent content in 데이터과학 on 생새우초밥집</description><generator>Hugo -- gohugo.io</generator><language>ko</language><lastBuildDate>Tue, 16 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/ko/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B3%BC%ED%95%99/index.xml" rel="self" type="application/rss+xml"/><item><title>데이터 과학에서 민감도 분석</title><link>https://freshrimpsushi.github.io/ko/posts/2711/</link><pubDate>Tue, 16 Sep 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2711/</guid><description>정의 1 (주로 회귀문제에서) 입력과 출력이 있는 모델model이 있다고 하자. 모델에서 출력output 불확실성uncertainty을 입력 불확실성의</description></item><item><title>패리티 플롯</title><link>https://freshrimpsushi.github.io/ko/posts/1053/</link><pubDate>Sun, 06 Apr 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1053/</guid><description>정의 참값true과 예측값prediction의 순서쌍을 산점도로 그린 것을 패리티 플롯parity plot이라 한다. 설명 실제 발음에 가깝게 적으면 [패</description></item><item><title>차원의 저주</title><link>https://freshrimpsushi.github.io/ko/posts/708/</link><pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/708/</guid><description>정의 1 주로 유클리드 공간 $\mathbb{R}^{d}$ 에서, 어떤 문제를 풀기 위한 메모리의 양이나 연산 횟수가 차원 $d$ 에 따라 지수적으로 커지는 것을 차원의 저주curse of dimensi</description></item><item><title>평균아크탄젠트절대비오차 MAAPE</title><link>https://freshrimpsushi.github.io/ko/posts/320/</link><pubDate>Fri, 17 Jan 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/320/</guid><description>정의 1 회귀문제에서, 데이터 포인트 $\left\{ x_{k} \right\}_{k=1}^{n}$ 과 그 예측치 $\left\{ \widehat{x}_{k} \right\}_{k=1}^{n}$ 에 대해 평균아크탄젠트절대비오차MAAPE(Mean Arctangent Absolute Precentage Error)를 다음과 같이 정의한</description></item><item><title>평균절대비오차 MAPE</title><link>https://freshrimpsushi.github.io/ko/posts/312/</link><pubDate>Mon, 13 Jan 2025 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/312/</guid><description>정의 1 회귀문제에서, 데이터 포인트 $\left\{ x_{k} \right\}_{k=1}^{n}$ 과 그 예측치 $\left\{ \widehat{x}_{k} \right\}_{k=1}^{n}$ 에 대해 평균절대비오차MAPE(Mean Absolute Precentage Error)를 다음과 같이 정의한다. $$ \text{MAPE} = {{ 1</description></item><item><title>데이터의 정규화</title><link>https://freshrimpsushi.github.io/ko/posts/2600/</link><pubDate>Sun, 21 Jul 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2600/</guid><description>용어 정규화 주어진 데이터를 $0$ 부터 $1$ 사이의 값으로 변환하는 것을 정규화normalization라 한다. 흔히 데이터의 최대값 $x_{\text{max}}$ 과 최소값 $x_{\text{min}}$ 에 대해 다음과 같</description></item><item><title>초모수, 하이퍼 파라미터란?</title><link>https://freshrimpsushi.github.io/ko/posts/2594/</link><pubDate>Fri, 05 Jul 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2594/</guid><description>용어 베이지안 통계학 1 베이지안 패러다임에서, 다음을 베이지안 계층적 모델Bayesian hierarchical model이라 한다. (1) 데이터 $y_{1} , \cdots , y_{n}$ 가 파라미터 $\theta_{1} , \cdots ,</description></item><item><title>데이터과학에서 F1 스코어란?</title><link>https://freshrimpsushi.github.io/ko/posts/2549/</link><pubDate>Sat, 06 Apr 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2549/</guid><description>정의 양성positive $P$ 와 음성negative $N$ 을 구분하는 분류문제에서 양성과 음성을 판정하는 모델이 주어져 있다고 하자. 양을 양으로 판정한 수를 참양</description></item><item><title>데이터과학에서 재현도란?</title><link>https://freshrimpsushi.github.io/ko/posts/2547/</link><pubDate>Tue, 02 Apr 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2547/</guid><description>정의 양성positive $P$ 와 음성negative $N$ 을 구분하는 분류문제에서 양성과 음성을 판정하는 모델이 주어져 있다고 하자. 양을 양으로 판정한 수를 참양</description></item><item><title>데이터과학에서 정밀도란?</title><link>https://freshrimpsushi.github.io/ko/posts/2545/</link><pubDate>Fri, 29 Mar 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2545/</guid><description>정의 양성positive $P$ 와 음성negative $N$ 을 구분하는 분류문제에서 양성과 음성을 판정하는 모델이 주어져 있다고 하자. 양을 양으로 판정한 수를 참양</description></item><item><title>데이터과학에서 정확도가 과대평가 되는 상황</title><link>https://freshrimpsushi.github.io/ko/posts/2543/</link><pubDate>Mon, 25 Mar 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2543/</guid><description>정의 양성positive $P$ 와 음성negative $N$ 을 구분하는 분류문제에서 양성과 음성을 판정하는 모델이 주어져 있다고 하자. 양을 양으로 판정한 수를 참양</description></item><item><title>데이터과학에서 분류문제와 회귀문제의 정의</title><link>https://freshrimpsushi.github.io/ko/posts/2540/</link><pubDate>Tue, 19 Mar 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2540/</guid><description>용어 데이터과학에서는 문제의 종속변수가 무엇인지에 따라서 다음과 같이 구분하기도 한다. 분류 문제 종속변수가 질적변수인 문제를 분류classificati</description></item><item><title>데이터과학에서 독립변수와 종속변수</title><link>https://freshrimpsushi.github.io/ko/posts/2538/</link><pubDate>Fri, 15 Mar 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2538/</guid><description>용어 통계학이나 머신러닝 등 데이터과학의 분야의 모델model에서 데이터의 변수는 크게 다음의 두가지 부류로 나뉜다. 종속변수 종속변수dependent v</description></item><item><title>데이터과학에서 차원축소란?</title><link>https://freshrimpsushi.github.io/ko/posts/3563/</link><pubDate>Wed, 06 Mar 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/3563/</guid><description>정의 데이터 집합 $X \subset \mathbb{R}^{n}$이 주어졌다고 하자. $m \lt n$에 대해서 다음과 같은 매핑을 차원 축소dimension reductio</description></item><item><title>상자 그림(Box plot)</title><link>https://freshrimpsushi.github.io/ko/posts/3557/</link><pubDate>Fri, 23 Feb 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/3557/</guid><description>정의1 데이터의 중앙값median, 1분위수first quartile, 3분위수third quartile, 최댓값maximum, 최솟값minimum을 아래와 같이 나타낸 그림을</description></item><item><title>통계학에서의 자유도</title><link>https://freshrimpsushi.github.io/ko/posts/2456/</link><pubDate>Tue, 03 Oct 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2456/</guid><description>용어 어떤 통계량을 산출할 때 그 값을 바꿀 수 있는 독립적인 데이터의 수를 자유도degree of freedom라 한다1. 설명 자유도를 설명하기 어려운 이유 신입생</description></item><item><title>백분위수와 이상치</title><link>https://freshrimpsushi.github.io/ko/posts/2452/</link><pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2452/</guid><description>정의 1 양적 데이터가 주어져 있다고 하자. 전체에서 $p \%$ 만큼보다 크고 $(100-p) \%$ 만큼보다 작은 값을 $p$-퍼센타일$p$th Percentile이라 한다. $1</description></item><item><title>z-스코어와 표준화</title><link>https://freshrimpsushi.github.io/ko/posts/2450/</link><pubDate>Thu, 21 Sep 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2450/</guid><description>정의 1 모평균이 $\mu$ 고 모표준편차가 $\sigma$ 인 분포를 따르는 확률변수 $X$ 에 대해 다음과 같은 변환을 표준화standardization라 한다. $$ Z = {{ X - \mu } \over</description></item><item><title>기초통계학에서 분산의 정의</title><link>https://freshrimpsushi.github.io/ko/posts/2448/</link><pubDate>Sun, 17 Sep 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2448/</guid><description>정의 1 $n$개의 양적 데이터가 주어져 있다고 하자. 표본평균 $\overline{x}$ 과 데이터의 차 $\left( \overline{x} - x_{i} \right)$ 를 편차deviation라 한다. 편차의 제곱의 합을 $n-1$으로</description></item><item><title>기초통계학에서 최빈값의 정의</title><link>https://freshrimpsushi.github.io/ko/posts/2446/</link><pubDate>Wed, 13 Sep 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2446/</guid><description>정의 1 질적 데이터가 주어져 있을 때, 가장 도수가 높은 범주를 최빈값mode이라 한다. 양적 데이터의 경우, 가장 도수가 높은 계급을 최빈계급modal clas</description></item><item><title>기초통계학에서 중앙값의 정의</title><link>https://freshrimpsushi.github.io/ko/posts/2444/</link><pubDate>Sat, 09 Sep 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2444/</guid><description>정의 1 $n$개의 양적 데이터가 크기 순서대로 주어져 있을 때, 전체 데이터의 가운데에 위치하는 값을 중앙값 혹은 중위수median $m$ 이라 한다. $n$ 이 홀수면 $m :=</description></item><item><title>기초통계학에서의 모수와 통계량</title><link>https://freshrimpsushi.github.io/ko/posts/2440/</link><pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2440/</guid><description>정의 1 모집단에 연관된 수치적으로 기술되는 측도numerical descriptive measure를 모수parameter라 하고, 샘플에서 계산된 것을 통계량stat</description></item><item><title>기초통계학에서 평균의 정의</title><link>https://freshrimpsushi.github.io/ko/posts/2438/</link><pubDate>Mon, 28 Aug 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2438/</guid><description>정의 1 $$ \overline{x} := {{ 1 } \over { n }} \sum_{k=1}^{n} x_{k} $$ $n$개의 양적 데이터가 주어져 있을 때, 그 값들을 모두 더하고 $n$ 으로 나눈 값 $\overline{x}$ 을 표본평균sample mean, 산술 평균arit</description></item><item><title>다변량 데이터의 점도표</title><link>https://freshrimpsushi.github.io/ko/posts/2436/</link><pubDate>Thu, 24 Aug 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2436/</guid><description>정의 1 다변량 데이터가 주어져 있다고 하자. 양적 데이터 두 개를 골라 하나는 수평축(x축), 하나는 수직축(y축)으로 두어 점을 찍은 그림을 점도표scatte</description></item><item><title>시계열 데이터의 꺾은 선 그래프</title><link>https://freshrimpsushi.github.io/ko/posts/2434/</link><pubDate>Sun, 20 Aug 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2434/</guid><description>정의 1 시계열 데이터가 주어져 있다고 하자. 시간의 변화를 수평축(x축)으로 나타내면서 값의 변화를 선으로 이어 나타내는 그래프를 꺾은 선 그래프line Cha</description></item><item><title>양적 데이터의 히스토그램</title><link>https://freshrimpsushi.github.io/ko/posts/2432/</link><pubDate>Wed, 16 Aug 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2432/</guid><description>정의 1 2 어려운 정의 양적 데이터의 도수분포로 만들어진 막대 그래프를 히스토그램histogram이라 한다. 쉬운 정의 숫자로 된 데이터를 일정 구간으로 나누어</description></item><item><title>질적 데이터의 막대 그래프</title><link>https://freshrimpsushi.github.io/ko/posts/2430/</link><pubDate>Sat, 12 Aug 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2430/</guid><description>정의 1 질적 데이터의 도수분포가 주어져 있다고 하자. 막대의 높이가 도수를 나타내는 그래프를 바 차트bar Chart라 한다. 원호의 넓이가 상대도수를 나타내는</description></item><item><title>양적자료의 계급</title><link>https://freshrimpsushi.github.io/ko/posts/2428/</link><pubDate>Tue, 08 Aug 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2428/</guid><description>정의 1 양적 데이터의 값에 따라 상한과 하한을 정해 나눈 구간을 계급class이라 한다. 각 계급에 속한 데이터의 수를 도수frequency라 한다. 설명 학술용</description></item><item><title>질적자료의 도수</title><link>https://freshrimpsushi.github.io/ko/posts/2426/</link><pubDate>Fri, 04 Aug 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2426/</guid><description>정의 1 질적 데이터의 각 관측값이 나타나는 빈도수를 도수frequency라 한다. 도수를 전체 자료의 갯수로 나눈 것을 상대도수relative Freque</description></item><item><title>통계학의 정의</title><link>https://freshrimpsushi.github.io/ko/posts/2424/</link><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2424/</guid><description>정의 1 통계학은 데이터를 수집하고 분석하며 나타내고 해석하며 결정을 하는 방법들의 집합이다. 기술통계학은 도표나 그래프와 요약 측도 등을 이용하여 데이터를 구성</description></item><item><title>통계학에서의 척도: 명목, 순서, 구간, 비율</title><link>https://freshrimpsushi.github.io/ko/posts/2422/</link><pubDate>Thu, 27 Jul 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2422/</guid><description>개요 일반적으로, 실제 세상에서 데이터를 만든다는 것은 현상이나 실험을 관측observe하여 그에 대해 기록하는 작업을 말하며, 이를 측정한다measure</description></item><item><title>질적변수와 양적변수</title><link>https://freshrimpsushi.github.io/ko/posts/2420/</link><pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2420/</guid><description>정의 1 질적변수 질적qualitative인 특성을 측정한 변수를 질적변수라 한다. 음식이&amp;hellip; 맛있다 / 그럭저럭이다 / 맛없다 색깔이&amp;hel</description></item><item><title>데이터의 정의와 어원</title><link>https://freshrimpsushi.github.io/ko/posts/2418/</link><pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2418/</guid><description>개요 사실 현대사회에서 데이터에 대해 전혀 모르는 지식인은 없다. 전혀 관심없는 비전공자라 하더라도 &amp;lsquo;무언가에 대한 지식&amp;rsquo; 혹은 &amp;ls</description></item><item><title>덴드로그램(Dendrogram)</title><link>https://freshrimpsushi.github.io/ko/posts/3255/</link><pubDate>Sat, 25 Jun 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/3255/</guid><description>정의 주어진 데이터(왼쪽)의 계층적 군집화를 트리 구조로 나타낸 그림(오른쪽)을 덴드로그램dendrogram이라 한다. 설명 $x$축은 각 데이터의 레이</description></item><item><title>히트맵(Heatmap)</title><link>https://freshrimpsushi.github.io/ko/posts/3233/</link><pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/3233/</guid><description>정의 함수 $f : \mathbb{R}^{2} \to \mathbb{R}$의 그래프를 $xy-$평면으로 사영시켜, 함숫값을 색으로 나타낸 것을 히트맵heatmap이라 한다. 설명 위 그림</description></item><item><title>ROC 곡선의 AUC 를 이용해 모형 비교하는 법</title><link>https://freshrimpsushi.github.io/ko/posts/887/</link><pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/887/</guid><description>요약 ROC 곡선은 기본적으로 사각형 $[0,1]^2$ 을 가득 채울수록 좋고, 곡선의 왼쪽 상단의 꺾이는 점이 $(0,1)$ 에 가까울 수록 좋다. 설명 위의 두 ROC 곡선이 있다고 한다면 마음 편하게 &amp;l</description></item><item><title>ROC 곡선을 이용해 최적의 컷오프 찾는 법</title><link>https://freshrimpsushi.github.io/ko/posts/877/</link><pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/877/</guid><description>개요 ROC 곡선을 그리면 트레이닝 데이터로 얻은 모형이 테스트 데이터를 어느정도로 잘 설명하는지 한 눈에 보여서 유용하다. 하지만 이 곡선은 모든 컷오프에 대한 분류율을</description></item><item><title>R 에서 ROC 곡선 그리는 법</title><link>https://freshrimpsushi.github.io/ko/posts/868/</link><pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/868/</guid><description>정의 오류행렬의 False Positive Rate와 True Positive Rate를 각각 축으로 두고 그린 그림을 ROC 곡선Receiver Operating Characteristic Curve이라 한다. 설명 ROC 곡선은 모델의 퍼포먼스를</description></item><item><title>교차검증</title><link>https://freshrimpsushi.github.io/ko/posts/866/</link><pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/866/</guid><description>모델 검증 데이터 분석을 해서 얻은 모델은 그 퍼포먼스가 적절한지 확인하는 과정이 필요하다. 주어진 데이터만 잘 설명하고 실전에서 전혀 힘을 쓰지 못하면 분석을 하는 의</description></item><item><title>적합치, 예측치, 잔차, 오차</title><link>https://freshrimpsushi.github.io/ko/posts/650/</link><pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/650/</guid><description>정의 1 회귀분석 $Y \gets X_{1} + X_{2} + \cdots + X_{n}$ 으로 얻은 회귀식을 $y = \beta_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} + \cdots + \beta_{n} x_{n}$ 이라고 하고 $i$번째 데이터를 $(y_{i} , x_{i1} , x_{i2} , \cdots , x_{in})$ 와 같이 나타내도록 하</description></item><item><title>오류행렬과 민감도, 특이도</title><link>https://freshrimpsushi.github.io/ko/posts/571/</link><pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/571/</guid><description>정의 양성positive $P$ 와 음성negative $N$ 을 구분하는 분류문제에서 양성과 음성을 판정하는 모델이 주어져 있다고 하자. 양을 양으로 판정한 수를 참양</description></item><item><title>계획행렬</title><link>https://freshrimpsushi.github.io/ko/posts/550/</link><pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/550/</guid><description>빌드업 R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 고작 여섯개지만, 척 봐도 eruptions와 waiting은 양의 상관관계</description></item></channel></rss>