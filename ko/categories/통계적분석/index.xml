<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>통계적분석 on 생새우초밥집</title><link>https://freshrimpsushi.github.io/ko/categories/%ED%86%B5%EA%B3%84%EC%A0%81%EB%B6%84%EC%84%9D/</link><description>Recent content in 통계적분석 on 생새우초밥집</description><generator>Hugo -- gohugo.io</generator><language>ko</language><lastBuildDate>Tue, 28 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/ko/categories/%ED%86%B5%EA%B3%84%EC%A0%81%EB%B6%84%EC%84%9D/index.xml" rel="self" type="application/rss+xml"/><item><title>압축 센싱이란?</title><link>https://freshrimpsushi.github.io/ko/posts/2575/</link><pubDate>Tue, 28 May 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2575/</guid><description>정의 $$ \mathbf{y} = \Theta \mathbf{s} $$ $\Theta \in \mathbb{R}^{n \times p}$ 에 대해 $n \ll p$ 일 때, 다시 말해 과소결정계라서 위의 행렬방정식을 만족하는 해 $\mathbf{s}$ 가 무수히 많이 존재한다고 하자. 이 행렬방정식을 만족</description></item><item><title>라쏘 회귀란?</title><link>https://freshrimpsushi.github.io/ko/posts/2571/</link><pubDate>Mon, 20 May 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2571/</guid><description>정의 $$ \begin{bmatrix} y_{1} \\ y_{2} \\ \vdots \\ y_{n} \end{bmatrix} = \begin{bmatrix} 1 &amp;amp; x_{11} &amp;amp; \cdots &amp;amp; x_{p1} \\ 1 &amp;amp; x_{12} &amp;amp; \cdots &amp;amp; x_{p2} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 1 &amp;amp; x_{1n} &amp;amp; \cdots &amp;amp; x_{pn} \end{bmatrix} \begin{bmatrix} \beta_{0} \\ \beta_{1} \\ \vdots \\ \beta_{p} \end{bmatrix} + \begin{bmatrix} \varepsilon_{1} \\ \varepsilon_{2} \\ \vdots \\ \varepsilon_{n} \end{bmatrix} $$ $n$ 개의 데</description></item><item><title>리지 회귀란?</title><link>https://freshrimpsushi.github.io/ko/posts/2567/</link><pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2567/</guid><description>정의 $$ \begin{bmatrix} y_{1} \\ y_{2} \\ \vdots \\ y_{n} \end{bmatrix} = \begin{bmatrix} 1 &amp;amp; x_{11} &amp;amp; \cdots &amp;amp; x_{p1} \\ 1 &amp;amp; x_{12} &amp;amp; \cdots &amp;amp; x_{p2} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 1 &amp;amp; x_{1n} &amp;amp; \cdots &amp;amp; x_{pn} \end{bmatrix} \begin{bmatrix} \beta_{0} \\ \beta_{1} \\ \vdots \\ \beta_{p} \end{bmatrix} + \begin{bmatrix} \varepsilon_{1} \\ \varepsilon_{2} \\ \vdots \\ \varepsilon_{n} \end{bmatrix} $$ $n$ 개의 데</description></item><item><title>스파스 회귀란?</title><link>https://freshrimpsushi.github.io/ko/posts/2563/</link><pubDate>Sat, 04 May 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2563/</guid><description>정의 행렬 $A \in \mathbb{R}^{m \times n}$ 과 벡터 $\mathbf{b} \in \mathbb{R}^{m}$ 에 대해 행렬방정식이 다음과 같이 주어져 있다고 하자. $$ A \mathbf{x} = \mathbf{b} $$ 스파스 회귀sparse Regression는 위와 같은</description></item><item><title>지구통계학에서의 PROJ 소개</title><link>https://freshrimpsushi.github.io/ko/posts/2541/</link><pubDate>Thu, 21 Mar 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2541/</guid><description>빌드업 지구는 둥글며, 더 자세하게는 타원구로 보고 있다. 지구를 단순히 축소시켜놓은 &amp;lsquo;지구본&amp;rsquo;은 정확한 모형일 뿐 쓰임새가 그다지 많</description></item><item><title>R 회귀분석에서 not defined because of singularities 해결</title><link>https://freshrimpsushi.github.io/ko/posts/2534/</link><pubDate>Thu, 07 Mar 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2534/</guid><description>당신이 통계나 수학 전공자라면 원인을 대강 파악하고 직면한 문제를 해결하는 것에서 그치지 않고, 수리적인 증명까지 이해하는 것을 강하게 권한다. 에러 진단 Coefficients: (1 not defined</description></item><item><title>유니버설 크리깅</title><link>https://freshrimpsushi.github.io/ko/posts/2523/</link><pubDate>Wed, 14 Feb 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2523/</guid><description>모델 오디너리 크리깅 공간데이터분석에서 랜덤필드 $\mathbf{Y} = \left( Y \left( s_{1} \right) , \cdots , Y \left( s_{n} \right) \right)$ 의 평균 $\mu \in \mathbb{R}$ 과 공분산행렬 $\Sigma \in \mathbb{R}^{n \times n}$ 과 다변량정규분포를 따르는 $\varepsilon \sim N_{n} \left(</description></item><item><title>공간데이터분석에서 크리깅이란?</title><link>https://freshrimpsushi.github.io/ko/posts/2521/</link><pubDate>Sat, 10 Feb 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2521/</guid><description>모델 오디너리 크리깅 공간데이터분석에서 랜덤필드 $\mathbf{Y} = \left( Y \left( s_{1} \right) , \cdots , Y \left( s_{n} \right) \right)$ 의 평균 $\mu \in \mathbb{R}$ 과 공분산행렬 $\Sigma \in \mathbb{R}^{n \times n}$ 과 다변량정규분포를 따르는 $\varepsilon \sim N_{n} \left(</description></item><item><title>경험적 배리오그램</title><link>https://freshrimpsushi.github.io/ko/posts/2519/</link><pubDate>Tue, 06 Feb 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2519/</guid><description>빌드업 배리오그램의 정의: 유클리드 공간의 픽스된 부분집합 $D \subset \mathbb{R}^{r}$ 에서 확률변수 $Y(s) : \Omega \to \mathbb{R}^{1}$ 의 집합인 공간과정 $\left\{ Y(s) \right\}_{s \in D}$ 와 방향벡터 $\mathbf{h} \in \mathbb{R}^{r}$ 를 생각해보자. 구체</description></item><item><title>세미배리오그램의 모형들</title><link>https://freshrimpsushi.github.io/ko/posts/2502/</link><pubDate>Wed, 03 Jan 2024 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2502/</guid><description>개요 공간통계분석에서 공간과정이 아이소트로픽해서 세미배리오그램이 $\gamma \left( \left\| \mathbf{h} \right\| \right) = \gamma (d)$ 을 만족하는 경우 $\gamma$ 는 복잡한 행렬 꼴이 아닌 1차원 스칼라함수, 즉 $\gamma :</description></item><item><title>배리오그램의 등방성</title><link>https://freshrimpsushi.github.io/ko/posts/2500/</link><pubDate>Sat, 30 Dec 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2500/</guid><description>정의 1 공간과정의 세미배리오그램 $\gamma \left( \mathbf{h} \right)$ 가 방향벡터 $\mathbf{h} \in \mathbb{R}^{r}$ 에 의존할 뿐만 아니라, 사실 방향과 관계 없이 그 크기 $d := \left\| \mathbf{h} \right\|$ 에만 의존해서 다음과 같이 나타낼 수 있</description></item><item><title>배리오그램의 정의</title><link>https://freshrimpsushi.github.io/ko/posts/2498/</link><pubDate>Tue, 26 Dec 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2498/</guid><description>정의 1 유클리드 공간의 픽스된 부분집합 $D \subset \mathbb{R}^{r}$ 에서 확률변수 $Y(s) : \Omega \to \mathbb{R}^{1}$ 의 집합인 공간과정 $\left\{ Y(s) \right\}_{s \in D}$ 와 방향벡터 $\mathbf{h} \in \mathbb{R}^{r}$ 를 생각해보자. 구체적으로 $n \in \mathbb{N}$ 개의 사</description></item><item><title>공간 과정의 정상성</title><link>https://freshrimpsushi.github.io/ko/posts/2496/</link><pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2496/</guid><description>정의 1 유클리드 공간의 픽스된 부분집합 $D \subset \mathbb{R}^{r}$ 에서 확률변수 $Y(s) : \Omega \to \mathbb{R}^{1}$ 의 집합인 공간과정 $\left\{ Y(s) \right\}_{s \in D}$ 와 방향벡터 $\mathbf{h} \in \mathbb{R}^{r}$ 를 생각해보자. 구체적으로 $n \in \mathbb{N}$ 개의 사</description></item><item><title>공간 과정</title><link>https://freshrimpsushi.github.io/ko/posts/2494/</link><pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2494/</guid><description>정의 1 특히 $r &amp;gt; 1$ 일 때, 유클리드 공간의 픽스된 부분집합 $D \in \mathbb{R}^{r}$ 에 대해서 다음과 같이 $p$-변량 랜덤벡터 $Y(s) : \Omega \to \mathbb{R}^{p}$ 의 집합인 확률과정을 공간 과정spati</description></item><item><title>공간 데이터 분석이란?</title><link>https://freshrimpsushi.github.io/ko/posts/2492/</link><pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2492/</guid><description>설명 1 공간 데이터spatial Data란 말 그대로 공간에 대한 정보를 포함하는 데이터로써, 공간 통계학spatial Statistics는 주로 유클리</description></item><item><title>다중회귀분석에서 잔차의 분산에 대한 추정량과 회귀계수의 표준오차</title><link>https://freshrimpsushi.github.io/ko/posts/2464/</link><pubDate>Thu, 19 Oct 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2464/</guid><description>정리 $$ \begin{bmatrix} y_{1} \\ y_{2} \\ \vdots \\ y_{n} \end{bmatrix} = \begin{bmatrix} 1 &amp;amp; x_{11} &amp;amp; \cdots &amp;amp; x_{p1} \\ 1 &amp;amp; x_{12} &amp;amp; \cdots &amp;amp; x_{p2} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 1 &amp;amp; x_{1n} &amp;amp; \cdots &amp;amp; x_{pn} \end{bmatrix} \begin{bmatrix} \beta_{0} \\ \beta_{1} \\ \vdots \\ \beta_{p} \end{bmatrix} + \begin{bmatrix} \varepsilon_{1} \\ \varepsilon_{2} \\ \vdots \\ \varepsilon_{n} \end{bmatrix} $$ 독립변수</description></item><item><title>회귀계수의 정의와 추정량의 공식 유도</title><link>https://freshrimpsushi.github.io/ko/posts/2458/</link><pubDate>Sat, 07 Oct 2023 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2458/</guid><description>정의 1 $$ Y = \beta_{0} + \beta_{1} X_{1} + \cdots + \beta_{p} X_{p} + \varepsilon $$ 다중회귀분석에서 주어진 $p$ 개의 독립변수 $X_{1} , \cdots , X_{p}$ 에 대해 위와 같은 선형모델linear model을 세울 때, $\beta_{0} ,</description></item><item><title>QGIS로 shp 파일 열어보는 방법</title><link>https://freshrimpsushi.github.io/ko/posts/2089/</link><pubDate>Wed, 29 Sep 2021 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/2089/</guid><description>개요 shp 확장자는 Shapefile을 나타낸다. 많은 지리정보 데이터들이 *.shp 파일과 동봉된 *.dbf, *.sbn, *.sbx, *.shx 등의 포맷으로 관리된다. 데이터를 받았을 때 가장 황당한 것은</description></item><item><title>R 에서 가치 모형으로 시계열 분석 하는 법</title><link>https://freshrimpsushi.github.io/ko/posts/1282/</link><pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1282/</guid><description>실습 가치 모델은 아치 이펙트를 설명하는 유용한 수단으로써 분석 절차 자체는 아르마 모델과 흡사하다. 위의 그래프는 내장데이터 EuStockMarkets에서</description></item><item><title>시계열 분석에서의 가치 모형</title><link>https://freshrimpsushi.github.io/ko/posts/1280/</link><pubDate>Sun, 08 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1280/</guid><description>모델 1 가치 모델은 아치 모델을 일반화한 것으로, 이분산성을 파악하기 위한 시계열 분석법이다. $$ (1 - \beta{1} B - \cdots - \beta_{p} B^p) \sigma_{t | t-1}^2 = \omega + (\alpha_{1} B + \cdots + \alpha_{q} B^q) r_{t}^{2} $$ 유도 유도</description></item><item><title>아치 이펙트</title><link>https://freshrimpsushi.github.io/ko/posts/1278/</link><pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1278/</guid><description>정의 1 아치 이펙트란 그 AutoRegressive Conditional Heteroscedasticity라는 말 그대로 &amp;lsquo;자기회귀 조건부 이분산 효과&amp;rsquo;로 순화되기 때문에</description></item><item><title>시계열분석에서의 이분산성과 변동성 군집현상</title><link>https://freshrimpsushi.github.io/ko/posts/1272/</link><pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1272/</guid><description>정의 1 시계열 데이터 $\left\{ p_{t} \right\}$ 가 주어져 있다고 하자. $\left\{ p_{t} \right\}$ 의 분산이 $t$ 에 종속되어있을 때, $\left\{ p_{t} \right\}$ 는 이분산성heteroscedasticity을 가진다고</description></item><item><title>동적 회귀 모형</title><link>https://freshrimpsushi.github.io/ko/posts/1265/</link><pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1265/</guid><description>모델 동적 회귀 모형이란 쉽게 말해 아리마 모형에 회귀 모형을 합친 모형이다. 설명 아리마 외의 독립변수 $X$ 를 추가한다는 의미에서 아리맥스 $ARIMAX$ 라 부르기도 한다. 프로그</description></item><item><title>시계열분석의 이노베이티브 아웃라이어</title><link>https://freshrimpsushi.github.io/ko/posts/1260/</link><pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1260/</guid><description>빌드업 위의 그래프에서 2001년 9월에 굉장히 큰 아웃라이어를 찾을 수 있다. 그러나 애디티브 아웃라이어와 달리 그 후에도 계속해서 영향을 미치고 있다. 여객기의</description></item><item><title>시계열분석의 애디티브 아웃라이어</title><link>https://freshrimpsushi.github.io/ko/posts/1258/</link><pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1258/</guid><description>빌드업 위의 그래프에서 가장 먼저 눈에 띄는 지점은 바로 2015년 2월 근처에 있는 엄청난 아웃라이어다. 이렇듯 극심하게 다른 값을 가지면 분석에 악영향이 있을 수밖</description></item><item><title>스텝 함수와 펄스 함수</title><link>https://freshrimpsushi.github.io/ko/posts/1248/</link><pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1248/</guid><description>정의 1 다음과 같이 정의된 $S_{t}^{(T)}$ 를 스텝 함수라 한다. $$ S_{t}^{(T)} := \begin{cases} 1 &amp;amp; , t \le T \\ 0 &amp;amp; , \text{otherwise} \end{cases} $$ 다음과 같이 정의된 $P_{t}^{(T)}$ 를 펄스 함수라 한다. $$ \begin{align*} P_{t}^{(T)} :=&amp;amp; \nabla S_{t}^{(T)} \\ =&amp;amp; S_{t}^{(T)} - S_{t-1}^{(T)} \end{align*} $$ 설</description></item><item><title>개입 분석</title><link>https://freshrimpsushi.github.io/ko/posts/1243/</link><pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1243/</guid><description>빌드업 위 그래프는 실제 2015년 서울의 미세먼지 농도를 나타낸 시계열 데이터다. 누가 보더라도 가장 먼저 눈에 띄는 것은 50번째쯤, 그러니까 2월 말에 미세먼지</description></item><item><title>시계열회귀분석에서의 허위 상관관계</title><link>https://freshrimpsushi.github.io/ko/posts/1238/</link><pubDate>Mon, 19 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1238/</guid><description>정의 1 허위 상관관계는 두 데이터가 그럴싸한 상관관계를 가지는 것 같아 보이지만 실제로는 그렇지 않은 관계를 말한다. 실습 1 다음의 예시를 통해 알아보자. 위와 같이</description></item><item><title>사전백화</title><link>https://freshrimpsushi.github.io/ko/posts/1236/</link><pubDate>Sat, 17 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1236/</guid><description>정의 사전백화prewhitening란 CCF를 계산할 때 시계열을 백색 잡음으로 만들어 두 데이터 간의 상관관계를 더욱 정확하게 파악하는 방법이다. 실습 1 가</description></item><item><title>교차상관함수</title><link>https://freshrimpsushi.github.io/ko/posts/1227/</link><pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1227/</guid><description>정의 1 $\left\{ X_{t} \right\}_{t=1}^{n}$, $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이라고 하자. 다음과 같이 정의된 $\rho_{k}$ 를 시차 $k$ 의 교차상관함수cross 라고 한다. $$ \rho_{k} (X,Y) := \text{cor} \left( X_{t} , Y_{t-k} \right) = \text{cor} \left( X_{t+k} , Y_{t} \right) $$ 다음</description></item><item><title>시계열 회귀 분석</title><link>https://freshrimpsushi.github.io/ko/posts/1223/</link><pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1223/</guid><description>정의 시계열 회귀 분석이란 말 그대로 시계열 데이터로 회귀분석하는 기법을 말한다. 원래 회귀분석 자체가 시계열 데이터를 다루는데 있어서 적합하지 않은 것은 사실이지</description></item><item><title>아리마 모형에 대한 잔차분석</title><link>https://freshrimpsushi.github.io/ko/posts/1218/</link><pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1218/</guid><description>설명 회귀분석과 마찬가지로 시계열 분석 역시 잔차분석을 한다. 아리마 모형의 가정에 따르면 잔차는 모두 백색 잡음이므로 선형성, 등분산성, 독립성, 정규성을 따르</description></item><item><title>R 에서 EACF를 사용한 ARMA 모형 선택법</title><link>https://freshrimpsushi.github.io/ko/posts/1216/</link><pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1216/</guid><description>실습 1 PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다. 직접 그 예를 살펴보자. ma1.2.s 데이터는 $MA(1)$ 모델에서, ar1.s 데이터는 $AR(1)$ 모델에서</description></item><item><title>확장자기상관함수</title><link>https://freshrimpsushi.github.io/ko/posts/1213/</link><pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1213/</guid><description>빌드업 PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다. 하지만 $ARMA(p,q)$ 모형에 적용시킬 땐 아르마 모형의 가역성 때문에 $AR(p)$ 라도 $MA(\infty)$ 처럼 보</description></item><item><title>편자기상관함수</title><link>https://freshrimpsushi.github.io/ko/posts/1211/</link><pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1211/</guid><description>정의 1 $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이고 시차 $k$ 에 대해서 $Y_{t-1}, \cdots , Y_{t-(k-1)}$ 로 $Y_{t}$ 를 회귀분석한 잔차를 $\widehat{e_{t}}$, $Y_{t-k}$ 를 회귀분석한 잔차를 $\widehat{e_{t-k}}$ 이라고 하자. 다음과 같이 정의된 $\phi_{kk}$ 를 시차 $k$ 의 편자기</description></item><item><title>자기상관함수</title><link>https://freshrimpsushi.github.io/ko/posts/1209/</link><pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1209/</guid><description>정의 1 $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이라고 하자. $\mu_{t} := E ( Y_{t} )$ 를 평균함수라고 한다. 다음과 같이 정의된 $\gamma_{ t , s }$ 를 자기공분산함수라고 한다. $$ \gamma_{t , s} : = \text{cov} ( Y_{t} , Y_{s}</description></item><item><title>아르마 모형의 가역성</title><link>https://freshrimpsushi.github.io/ko/posts/1208/</link><pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1208/</guid><description>정의 1 아르마 모형에 있어서 가역성을 가졌다 함은 $AR(p)$ 와 $MA(q)$ 가 서로를 표현할 수 있음을 말한다. 예시 일반적인 $ARMA ( p , q)$ 에 대한 수식전개는 아니지만, $AR(1)$ 과 $MA(1)$ 의 예를 살</description></item><item><title>R 에서 아리마 모형으로 예측하는 법</title><link>https://freshrimpsushi.github.io/ko/posts/1205/</link><pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1205/</guid><description>실습 R 내장데이터 UKDriverDeaths는 1969년부터 1984년까지 영국 월별 운전자 사상자에 대한 데이터다. 언뜻 보아도 계절형 아리마 모형을 따</description></item><item><title>R 에서 아리마 모형으로 얻은 시계열 분석 결과 보는 법</title><link>https://freshrimpsushi.github.io/ko/posts/1200/</link><pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1200/</guid><description>실습 R 내장데이터 AirPassenger는 1949년부터 1960년까지 월별 항공기의 승객 수에 대한 데이터다. (1) 모형: 사실 계수만 제대로 파악할 수 있다</description></item><item><title>R 에서 아리마 모형으로 시계열 분석하는 법</title><link>https://freshrimpsushi.github.io/ko/posts/1197/</link><pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1197/</guid><description>실습 R에서 내장데이터 WWWusage 를 불러와 그래프를 그려 확인해보자. WWWusage는 먼 옛날 인터넷에 접속하는 이용자수를 나타내는 시계열 데이터로써, 그 추이를 파</description></item><item><title>아리마 모형에서의 드리프트</title><link>https://freshrimpsushi.github.io/ko/posts/1115/</link><pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1115/</guid><description>설명 시계열 분석을 하다보면 종종 다음과 같이 드리프트drift라는 계수를 보게 된다. 물론 위의 경우 표준오차에 비해서 계수의 크기가 너무 작기 때문에 무시해도 상</description></item><item><title>계절형 아리마 모형</title><link>https://freshrimpsushi.github.io/ko/posts/1067/</link><pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/1067/</guid><description>모델 1 $\nabla_{s} Y_{t} := Y_{t} - Y_{t-s}$ 와 같이 정의된 오퍼레이터 $\nabla_{s}$ 를 계절형 차분seasonal Difference이라 한다. $W_{t} := \nabla^{d} \nabla_{s}^{D} Y_{t}$ 와 같이 정의된 $\left\{ W_{t} \right\}_{t \in \mathbb{N}}$ 가 $ARMA(P,Q)$ 고 $\left\{</description></item><item><title>아리마 모형</title><link>https://freshrimpsushi.github.io/ko/posts/941/</link><pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/941/</guid><description>모델 1 백색 잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $$ \nabla^{d} Y_{t} := \sum_{i = 1}^{p} \phi_{i} \nabla^{d} Y_{t-i} + e_{t} - \sum_{i = 1}^{q} \theta_{i} e_{t-i} $$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 $(p,d,q)$차 아리마 과정 $ARIMA (p,d,q)$ 라고 한다.</description></item><item><title>시계열분석에서의 변환</title><link>https://freshrimpsushi.github.io/ko/posts/938/</link><pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/938/</guid><description>빌드업 시계열에서 변환이 필요한 이유는 시간이 흐를수록 분산이 커지는 경우 그에 따른 &amp;lsquo;패널티&amp;rsquo;를 줘서 분산을 일정하게 하고 정상성을 얻</description></item><item><title>시계열분석에서의 차분</title><link>https://freshrimpsushi.github.io/ko/posts/916/</link><pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/916/</guid><description>정의 1 오퍼레이터 $B$ 를 $B Y_{t} = Y_{t-1}$ 과 같이 정의하고, 백쉬프트backshift라 한다. 오퍼레이터 $\nabla$ 를 $\nabla := 1 - B$ 그리고 $\nabla^{r+1} = \nabla \left( \nabla^{r} Y_{t} \right)$ 와 같이 정의하고 차분</description></item><item><title>아르마 모형</title><link>https://freshrimpsushi.github.io/ko/posts/914/</link><pubDate>Sat, 16 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/914/</guid><description>모델 1 백색 잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $$ Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} +e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q} $$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 **$(p,q)$차 자기회귀이</description></item><item><title>자기회귀과정</title><link>https://freshrimpsushi.github.io/ko/posts/910/</link><pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/910/</guid><description>모델 1 백색 잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} + e_{t}$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 $p$차 자기회귀과정 $AR(p)$ 라고 한다. (1): $AR(1) : Y_{t} = \phi Y_{t-1} + e_{t}$ (2): $AR(2)</description></item><item><title>이동평균과정</title><link>https://freshrimpsushi.github.io/ko/posts/909/</link><pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/909/</guid><description>모델 1 백색 잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $Y_{t} := e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q}$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 **$q$차 이동평균과정 $MA(q)$**라고 한다. (1):</description></item><item><title>시계열분석에서의 정상성</title><link>https://freshrimpsushi.github.io/ko/posts/907/</link><pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/907/</guid><description>정의 1 시계열 데이터의 평균과 분산이 일정할 때 정상성stationarity을 갖는다고 한다. 설명 정상正常Normal이 아니라 정상定常Station</description></item><item><title>시계열분석에서의 백색 잡음</title><link>https://freshrimpsushi.github.io/ko/posts/904/</link><pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/904/</guid><description>정의 1 iid한 확률변수 $e_{t}$ 들의 수열 $\left\{ e_{t} \right\}_{t = 1}^{\infty}$ 를 백색 잡음white noise이라고 한다. iid란 independent identically distributed의 줄임말로써, 서로 독립</description></item><item><title>시계열분석이란</title><link>https://freshrimpsushi.github.io/ko/posts/900/</link><pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/900/</guid><description>설명 시계열time Series 이란 쉽게 말해 실제 데이터로 얻어지는 확률과정이라고 볼 수 있다. 주가지수는 시간이 흐름에 따라 불확실성을 가지고 그 값이 변하므로 시계열의</description></item><item><title>R 에서 로지스틱 회귀분석 결과 보는 법</title><link>https://freshrimpsushi.github.io/ko/posts/850/</link><pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/850/</guid><description>실습 내장데이터 turnout 데이터를 불러와보자. turnout는 1992년 미국 총선에 대한 데이터로써, race(인종), 연령(age), 교육수준(educ</description></item><item><title>로지스틱 회귀분석</title><link>https://freshrimpsushi.github.io/ko/posts/832/</link><pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/832/</guid><description>빌드업 $Y \gets X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 $Y$ 가 질적변수, 그 중에서도 계급이 두개뿐인 경우가 있을 수 있다. 예를 들어 남자와 여자, 성공과 실패, 양성과 음</description></item><item><title>통계적 분석에서의 변수 선택 기준</title><link>https://freshrimpsushi.github.io/ko/posts/826/</link><pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/826/</guid><description>개요 변수를 선택하는 문제는 필연적으로 분석자의 주관이 개입할 수 밖에 없지만, 가능한 한 객관적인 결론을 내릴 수 있게 도와주는 수치적인 지표가 필요했다. 그런 값들</description></item><item><title>통계적 분석에서의 변수 선택 절차</title><link>https://freshrimpsushi.github.io/ko/posts/821/</link><pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/821/</guid><description>빌드업 다중회귀분석 $Y \gets X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 독립변수는 $p$ 개로, 회귀분석의 여러가지 가정들을 잘 만족하고 다중공선성이 없으며 설명력이 높다</description></item><item><title>R 에서 주성분회귀분석하는 법</title><link>https://freshrimpsushi.github.io/ko/posts/814/</link><pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/814/</guid><description>개요 주성분회귀분석pCR 이란 주성분분석과 다중회귀분석을 합친 것으로, 주성분분석을 통해 얻은 주성분을 새로운 독립변수로 둔 회귀분석을 말한다. 사실 통계학</description></item><item><title>통계학에서의 주성분분석</title><link>https://freshrimpsushi.github.io/ko/posts/812/</link><pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/812/</guid><description>개요 다중회귀분석 $Y \gets X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자. 주성분분석, 영어 약어로 PCA는 쉽게 말해 양적변수들이 제대로 독립이 되도록 &amp;lsquo;재구성&amp;r</description></item><item><title>분산팽창인자 VIF</title><link>https://freshrimpsushi.github.io/ko/posts/810/</link><pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/810/</guid><description>정의 1 다중회귀분석 $Y \gets X_{1} , \cdots, X_{p}$ 을 할 때 $i$번째 독립변수에 대한 다중회귀분석 $$X_{i} \gets X_{1} , \cdots, X_{i-1} , X_{i+1} , \cdots, X_{p}$$ 의 중회귀계수를 $R_{i}^2$ 라고 두자. 다음을 $X_{i}$ 의 분산팽창인</description></item><item><title>다중공선성</title><link>https://freshrimpsushi.github.io/ko/posts/808/</link><pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/808/</guid><description>정의 1 다중회귀분석 $Y \gets X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.이 때 독립변수 $ X_{1} , \cdots, X_{p}$ 중에서 독립변수끼리 강한 상관관계를 가지면 다중공선성multicolli</description></item><item><title>비선형회귀분석: 회귀분석에서의 변수 변환</title><link>https://freshrimpsushi.github.io/ko/posts/805/</link><pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/805/</guid><description>개요 1 회귀분석은 기본적으로 변수들간의 선형관계를 밝히는 방법이지만, 필요하다면 데이터를 선형으로 &amp;lsquo;펴서&amp;rsquo; 분석할 수 있다. 이는</description></item><item><title>회귀분석에서의 교호작용</title><link>https://freshrimpsushi.github.io/ko/posts/696/</link><pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/696/</guid><description>빌드업 우선 질적변수를 포함한 회귀분석에 대해 읽어보는 것을 추천한다. 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자</description></item><item><title>질적변수를 포함한 회귀분석</title><link>https://freshrimpsushi.github.io/ko/posts/686/</link><pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/686/</guid><description>개요 회귀분석을 하면서 독립변수로 언제나 양적변수가 들어온다는 보장은 없다. 성별이 무엇인지, 어떤 기업 소속인지, 무슨 색상인지, 금속인지 등등 범주형 자료 역</description></item><item><title>모형진단으로 확인하는 잔차의 정규성</title><link>https://freshrimpsushi.github.io/ko/posts/683/</link><pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/683/</guid><description>진단법 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 정규성은 잔차들의 흩어진 모양보다는 히스토그램으로 확인하거나 정규성 검정을 하는 게</description></item><item><title>모형진단으로 확인하는 잔차의 독립성</title><link>https://freshrimpsushi.github.io/ko/posts/679/</link><pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/679/</guid><description>진단법 직관적 패턴 파악 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 독립성을 확인하려면 잔차 그림에 어떤 뚜렷한 경향이 나타나지 않으면 된</description></item><item><title>모형진단으로 확인하는 잔차의 등분산성</title><link>https://freshrimpsushi.github.io/ko/posts/681/</link><pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/681/</guid><description>진단법 1 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 등분산성을 확인하려면 잔차들의 흩어진 모양이 전체적으로 고른지 확인하면 된다. 흔</description></item><item><title>모형진단으로 확인하는 잔차의 선형성</title><link>https://freshrimpsushi.github.io/ko/posts/677/</link><pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/677/</guid><description>진단법 1 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 선형성이 있는지 확인하려면 $0$ 을 중심으로 잔차들이 대칭적으로 나타나는지 확인하면</description></item><item><title>회귀분석의 모형진단</title><link>https://freshrimpsushi.github.io/ko/posts/675/</link><pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/675/</guid><description>필요성 단순회귀분석의 경우엔 독립변수와 종속변수를 고려해봤자 $2$ 차원이기 때문에 분석이 제대로 되었는지 한 눈에 확인할 수 있다. 하지만 다중회귀분석의 경우 $3$ 차</description></item><item><title>R 에서 다중회귀분석 결과 보는 법</title><link>https://freshrimpsushi.github.io/ko/posts/670/</link><pubDate>Wed, 05 Sep 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/670/</guid><description>데이터 탐색 tail(attitude) R에서 내장데이터 attitude를 불러와 tail() 함수를 통해 확인해보자. 우리는 이 데이터에서 다중회귀분석을 실시하려 한다. 우리는 rating</description></item><item><title>다중회귀분석</title><link>https://freshrimpsushi.github.io/ko/posts/666/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/666/</guid><description>개요 회귀분석이란 변수 사이의 관계를 알아내는 방법으로써, 특히 선형 관계를 밝히는 데 유용하다. 다중회귀분석multiple Linear Regression은 하나</description></item><item><title>R 에서 단순회귀분석 결과 보는 법</title><link>https://freshrimpsushi.github.io/ko/posts/652/</link><pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/652/</guid><description>실습 회귀분석하는 법 head(faithful) R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 데이터만 봐서는 두 변수 사이에 선형관계가 있는지 확인하기 어려우</description></item><item><title>단순회귀분석</title><link>https://freshrimpsushi.github.io/ko/posts/648/</link><pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/648/</guid><description>개요 회귀분석이란 변수 사이의 관계를 알아내는 방법으로써, 특히 선형 관계를 밝히는 데 유용하다. 단순회귀분석simple Linear Regression은 그 중에서</description></item><item><title>적합치, 예측치, 잔차, 오차</title><link>https://freshrimpsushi.github.io/ko/posts/650/</link><pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/650/</guid><description>정의 1 회귀분석 $Y \gets X_{1} + X_{2} + \cdots + X_{n}$ 으로 얻은 회귀식을 $y = \beta_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} + \cdots + \beta_{n} x_{n}$ 이라고 하고 $i$번째 데이터를 $(y_{i} , x_{i1} , x_{i2} , \cdots , x_{in})$ 와 같이 나타내도록 하</description></item><item><title>계획행렬</title><link>https://freshrimpsushi.github.io/ko/posts/550/</link><pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/550/</guid><description>빌드업 R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 고작 여섯개지만, 척 봐도 eruptions와 waiting은 양의 상관관계</description></item><item><title>회귀분석이란?</title><link>https://freshrimpsushi.github.io/ko/posts/548/</link><pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/548/</guid><description>설명 회귀분석은 거의 모든 통계적 기법의 근간이 되는만큼 너무 일반적이거나 너무 특수하게 설명된 경우가 많다. 그냥 회귀분석이 어떤건지 궁금한 사람에게 한마디로 설</description></item><item><title>상관관계가 없다고 독립인 것은 아니다</title><link>https://freshrimpsushi.github.io/ko/posts/536/</link><pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate><guid>https://freshrimpsushi.github.io/ko/posts/536/</guid><description>설명 독립이면 상관관계가 없지만, 상관관계가 없다고 독립인 것은 아니다. 상관관계가 없을 때 독립인 경우, 즉 필요충분조건이 되는 경우는 확률변수가 정규분포를 따</description></item></channel></rss>