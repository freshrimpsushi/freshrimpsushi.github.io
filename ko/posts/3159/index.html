<!doctype html><html class=blog lang=ko><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link rel=preload href=https://freshrimpsushi.github.io/ko/css/style.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=preload href=https://freshrimpsushi.github.io/ko/css/comment.css rel=preload as=style onload='this.rel="stylesheet"'><link rel=icon href=https://freshrimpsushi.github.io/ko/logo/favicon.ico><meta name=msapplication-TileColor content="#FFFFFF"><meta name=msapplication-TileImage content="logo/basic.png"><meta name=NaverBot content="All"><meta name=NaverBot content="index,follow"><meta name=Yeti content="All"><meta name=Yeti content="index,follow"><meta name=google-site-verification content="KYAokS7-6C5YuXOjatJQsiK1T0O8x4YncYFIF4tneYI"><meta name=naver-site-verification content="e5651d6f97899061897203413efc84994f04bbba"><link rel=alternate type=application/rss+xml title=생새우초밥집 href=https://freshrimpsushi.github.io/ko/index.xml><title>논문 리뷰: Neural Ordinary Differential Equations</title></head><meta name=title content="논문 리뷰: Neural Ordinary Differential Equations"><meta name=description content="국내 최대의 수학, 물리학, 통계학 블로그"><meta property="og:title" content="논문 리뷰: Neural Ordinary Differential Equations"><meta property="og:description" content><meta property="og:image" content="https://freshrimpsushi.github.io/ko/logo/basic.png/"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"j_","name":"논문 리뷰: Neural Ordinary Differential Equations","headline":"논문 리뷰: Neural Ordinary Differential Equations","alternativeHeadline":"","description":"개요 및 요약 「Neural Ordinary Differential Equations」는 Ricky T. Q. Chen 외 3명이 2018년에 발표한 논문으로, 2018 NeurIPS Best Papers에 선정되었다. 다음과 같이 간단","inLanguage":"ko","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/freshrimpsushi.github.io\/ko\/posts\/3159\/"},"author":{"@type":"Person","name":"전기현","url":"https://math.stackexchange.com/users/459895/ryu-dae-sick"},"creator":{"@type":"Person","name":"전기현"},"accountablePerson":{"@type":"Person","name":"전기현"},"copyrightHolder":"생새우초밥집","copyrightYear":"2021","dateCreated":"2021-12-15T00:00:00.00Z","datePublished":"2021-12-15T00:00:00.00Z","dateModified":"2021-12-15T00:00:00.00Z","publisher":{"@type":"Organization","name":"생새우초밥집","url":"https://freshrimpsushi.github.io/ko/","logo":{"@type":"ImageObject","url":"https:\/\/freshrimpsushi.github.io\/ko\/logo\/basic.png","width":"32","height":"32"}},"image":"https://freshrimpsushi.github.io/ko/logo/basic.png","url":"https:\/\/freshrimpsushi.github.io\/ko\/posts\/3159\/","wordCount":"5005","genre":[],"keywords":[]}</script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/mhchem.min.js integrity=sha384-F2ptQFZqNJuqfGGl28mIXyQ5kXH48spn7rcoS0Y9psqIKAcZPLd1NzwFlm/bl1mH crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>function renderKaTex(e){renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],trust:!0,trust:e=>["\\htmlId","\\href","\\includegraphics"].includes(e.command),macros:{"\\eqref":"(\\text{#1})","\\ref":"\\href{###1}{\\text{#1}}","\\label":"\\htmlId{#1}{}","\\sech":"\\operatorname{sech}","\\csch":"\\operatorname{csch}","\\sgn":"\\operatorname{sgn}","\\sign":"\\operatorname{sign}","\\sinc":"\\operatorname{sinc}","\\diag":"\\operatorname{diag}","\\diam":"\\operatorname{diam}","\\trace":"\\operatorname{trace}","\\Tr":"\\operatorname{Tr}","\\tr":"\\operatorname{tr}","\\re":"\\operatorname{Re}","\\im":"\\operatorname{Im}","\\Var":"\\operatorname{Var}","\\Poi":"\\operatorname{Poi}","\\Cov":"\\operatorname{Cov}","\\span":"\\operatorname{span}","\\supp":"\\operatorname{supp}","\\rank":"\\operatorname{rank}","\\nullity":"\\operatorname{nullity}","\\ad":"\\operatorname{ad}","\\Ric":"\\operatorname{Ric}","\\i":"\\mathrm{i}","\\d":"\\mathrm{d}","\\cR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5863.png}","\\acR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.4371.png}","\\bcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2202/2615581243_1645770096.5899.png}","\\abcR":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.0596.png}","\\crH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\smallcrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680622958.7632.png}","\\acrH":"\\includegraphics[height=0.8em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}","\\smallacrH":"\\includegraphics[height=0.6em]{https://freshrimpsushi.com/community/data/editor/2304/2175452104_1680634690.8386.png}"},throwOnError:!1})}</script><body class=main><header><a href=https://freshrimpsushi.github.io/ko/ rel=home><p style=text-align:center;font-size:1rem;color:#000><img src=https://freshrimpsushi.github.io/ko/logo/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.png style=height:80px alt=logo></p></a></header><form method=get action=/ko/search style=border:1px;text-align:center><div class=field><input type=text id=searchtext placeholder=🔍︎ class=input_text name=s style=background-color:#eee;text-align:center;width:200px;font-size:1.5rem;border:1px;border-radius:5px;padding-top:5px;padding-bottom:5px;margin-bottom:1.5rem></div></form><aside style=text-align:center;margin-bottom:1rem><a href=https://freshrimpsushi.github.io/ko//posts/3159/>한국어</a> |
<a href=https://freshrimpsushi.github.io/en//posts/3159/>English</a> |
<a href=https://freshrimpsushi.github.io/jp//posts/3159/>日本語</a></aside><div class=wrapper><div class=content><div class=content-box><title>논문 리뷰: Neural Ordinary Differential Equations</title>
<a href=https://freshrimpsushi.github.io/ko/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/ style=background-color:rgba(0,0,0,.8);color:orange;border-radius:10px;padding:5px>📂머신러닝</a><h1>논문 리뷰: Neural Ordinary Differential Equations</h1><aside><div class=innerheader><div class=innertoc><b>목차</b><nav id=TableOfContents><ul><li><a href=#개요-및-요약>개요 및 요약</a></li><li><a href=#1-introduction>1 Introduction</a></li><li><a href=#2-reverse-mode-automatic-differentiation-of-ode-solutions>2 Reverse-mode automatic differentiation of ODE solutions</a></li><li><a href=#3-replacing-residual-networks-with-odes-for-supervised-learning>3 Replacing residual networks with ODEs for supervised learning</a></li><li><a href=#4-continuous-normalizing-flows>4 Continuous Normalizing Flows</a><ul><li><a href=#41-experiments-with-continuous-normalizing-flows>4.1 Experiments with Continuous Normalizing Flows</a></li></ul></li><li><a href=#5-a-generative-latent-function-time-series-model>5 A generative latent function time-series model</a><ul><li><a href=#51-time-series-latent-ode-experiments>5.1 Time-series Latent ODE Experiments</a></li></ul></li></ul></nav></div></div></aside><h2 id=개요-및-요약>개요 및 요약</h2><p>「<a href=https://proceedings.neurips.cc/paper_files/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf>Neural Ordinary Differential Equations</a>」는 Ricky T. Q. Chen 외 3명이 2018년에 발표한 논문으로, <a href=https://neurips.cc/Conferences/2018/Awards>2018 NeurIPS Best Papers</a>에 선정되었다. 다음과 같이 간단한 <a href=../1660>1계 상미분 방정식</a>인 <a href=../1505>비자율 시스템</a>을 신경망으로 근사하는 방법을 제안한다.</p><p>$$
\dfrac{\mathrm{d}y}{\mathrm{d}t} = f(y, t)
$$</p><p>주목할 점은 신경망이 근사(예측)하는 것은 $y$가 아니라 변화율 $f$라는 것이다. 위 식의 양변을 $0$에서 임의의 $T$까지 적분하면 다음과 같다.</p><p>$$
y(T) - y(0) = \int\limits_{0}^{T} f(y, t) \mathrm{d}t \implies y(T) = y(0) + \int\limits_{0}^{T} f(y, t) \mathrm{d}t
$$</p><p>따라서 $f$를 정확히 근사할 수만 있으면, 임의의 $T$에 대해서 $y(T)$를 얻을 수 있다.</p><h2 id=1-introduction>1 Introduction</h2><p>아래의 그림과 같이 균등한 시간 간격인 8개의 데이터 포인트로 이루어진 <a href=../900>시계열데이터</a>가 주어져있다고 하자.</p><p><img src=3159_1.png#center alt></p><p>이런 상황에서 보통 우리가 하고 싶은 일은 $t_{9}$, $t_{10}$, $t_{11}$, $\dots$에 대한 데이터 $\mathbf{h}_{9}$, $\mathbf{h}_{10}$, $\mathbf{h}_{11}$, $\dots$를 예측하는 것이다. 이를 위해 쉽게 생각할 수 있는 방법 중 하나는 잔차 신경망, <a href=../3634>RNN</a>, <a href=../3247>normailizing flow</a> 등을 사용하여 다음과 같이 모델링하는 것이다.</p><p>$$
\mathbf{h}_{t+1} = \mathbf{h}_{t} + f(\mathbf{h}_{t}; \theta) \tag{1}
$$</p><p>여기서 $f$는 <a href=../962>신경망</a>이고, $\theta$는 $f$의 학습해야할 <a href=../962>파라미터</a>(가중치)이다. 이런 방법은 간단하고 직관적이며, 가장 먼저 시도해볼 수 있는 방법 중 하나이지만 다음과 같은 단점이 있다.</p><ul><li>데이터를 <a href=../1016>보간</a>하기는 힘들다. $(1)$과 같은 모델로는 $t_{3}$과 $t_{4}$ 사이의 데이터를 예측하기 힘들다. 특히나 임의의 시간 $t_{3.472}$에 대한 데이터를 예측하기는 쉽지않다.</li><li>시간간격이 균등하지 않은 데이터에 대해서는 적용하기 어렵다. $(1)$에서 $\mathbf{h}_{t+1}$를 업데이트하는 규칙은 $f$를 한 번, 두 번, 정수 횟수로 더해가는 것이기 때문에 시간 간격이 균등하지 않으면 $(1)$의 등식은 성립하지 않는다.</li></ul><p>이 논문에서 제안하는 방법은 이산 <a href=../1660>자율 시스템</a>인 $(1)$을 다음과 같이 연속적인 <a href=../1660>비자율 시스템</a>으로 바꾸어 생각하는 것이다.</p><p>$$
\dfrac{\mathrm{d}\mathbf{h}}{\mathrm{d}t} = f(\mathbf{h}(t), t; \theta) \tag{2}
$$</p><p>"비자율 시스템에서 외력(혹은 속도) $f$를 파라미터가 $\theta$인 인공신경망으로 정의한 $(2)$"를 Neural Ordinary Differential Equations (Neural ODE, NODE)라 한다.</p><p>이런 ODE를 풀어주는 <a href=../1093>솔버</a>(즉 $f$를 적분해주는 것)는 이미 많이 연구되어있고, 성능 좋은 다양한 방법들이 제안되어있다. 따라서 인경신공망을 통해 $f$를 잘 근사했다면 아래의 식을 통해 임의의 시간 $t$에 대한 $\mathbf{h}(t)$를 예측할 수 있다. 양 변을 적분하면,</p><p>$$
\mathbf{h}(t) = \mathbf{h}(0) + \int\limits_{0}^{t} f(\mathbf{h}(t), s; \theta) \mathrm{d}s \tag{3}
$$</p><p>우변은 초기값 $\mathbf{h}(0)$와 $f$가 주어져있다면 ODE 솔버를 통해 얻을 수 있는 값이므로, 논문에서는 다음과 같이 표기한다.</p><p>$$
\mathbf{h}(t_{1}) = \operatorname{ODESolve}(\mathbf{h}(t_{0}), f, t_{0}, t_{1}, \theta)
$$</p><p>논문에서는 ODE 솔버로 모델을 정의하고 값을 계산하면 얻을 수 있는 장점을 다음과 같이 설명한다.</p><ul><li><p><strong>Memory efficiency<sup>메모리 효율</sup>:</strong></p><p>아래의 2장에서 <a href=../3077>역전파 알고리즘</a>을 사용하지 않고도 손실 함수의 <a href=../1010>그래디언트</a>를 계산하는 방법을 소개한다. 따라서 모델의 함숫값을 계산할 때 <a href=../3442>중간 계산 결과를 저장</a>하지 않아도 되며, 이는 메모리 사용량이 모델의 크기에 의존하지 않고 일정하게 유지된다는 것을 의미한다.</p></li><li><p><strong>Adaptive computation<sup>적응형 계산</sup>:</strong></p><p><a href=../687>오일러 메소드</a> 이후로 120년이 지나는 동안 더 정확하고 효율적인 ODE 솔버들이 많이 개발되어왔다. 특히 최근의 ODE 솔버들은 오차 모니터링 및 높은 정확도 달성을 위해 실행 중에 평가 전략<sup>evaluation strategy</sup>을 동적으로 조정하는 기능을 제공한다.</p></li><li><p><strong>Scalable and invertible normalizing flows<sup>노멀라이징 플로우의 일반화</sup>:</strong></p><p>연속적인 모델의 부수적인 이점 중 하나는 변수 변환 공식을 계산하기 쉽다는 것인데 (4장에서 설명한다), 이는 효율적인 <a href=../3247>노멀라이징 플로우</a> 모델을 만들 수 있다는 것을 의미한다.</p></li><li><p><strong>Continuous time-series models<sup>연속 시계열 모델</sup>:</strong></p><p>훈련 및 예측 데이터가 균등간격으로 이산화되어있어야하는 RNN과 달리, 연속적으로 정의된 Neural ODE는 임의의 시간 $t$에 대한 예측을 수행할 수 있다. 이 내용은 5장에서 자세히 다룬다.</p></li></ul><h2 id=2-reverse-mode-automatic-differentiation-of-ode-solutions>2 Reverse-mode automatic differentiation of ODE solutions</h2><p>Neural ODE에 대한 핵심 아이디어와 원리는 <a href=#1-Introduction>Introduction</a>에서 모두 설명하였다. 2장은 학습법에 대해서 다룬다. 저자는 Neural ODE를 구현하는 방법을 개발하여 <a href=https://github.com/rtqichen/torchdiffeq>깃허브에 공개</a> 해두었다. 직접 구현할것이 아니라서 학습에 관한 내용이 크게 궁금하지 않다면 넘어가도 좋다고 본다. 3~5장은 Neural ODE가 어떻게 응용될 수 있는지를 다루기 때문에, 본인의 필드에서 Neural ODE를 활용하고 싶다면 3~5장을 상세히 읽어보는 것을 추천한다. 특히나 4장의 내용은 diffusion model 다음으로 생성모델의 주류를 이끌고있는 flow matching과도 연결된다.</p><p>관측값(정답 데이터)은 신경망의 파라미터 $\theta$에 의존하지않는 상수이므로, 손실함수를 다음과 같이 간단히 나타내자.</p><p>$$
L(\mathbf{z}(t_{1})) = L \left( \mathbf{z}(t_{0}) + \int_{t_{0}}^{t_{1}} f(\mathbf{z}(t), t; \theta) \mathrm{d}t \right) = L \left( \operatorname{OSESolve}(\mathbf{z}(t_{0}), f_{\theta}, t_{0}, t_{1}) \right)
$$</p><p>논문에서 손실함수의 <a href=../1010>그래디언트</a>를 계산하기 위해 방법은 adjoint sensitivity method이며, 이는 또다른 ODE를 시간 역순으로 적분하는 것이다. 그 결과만 보면 다음과 같다.</p><p>$$
\dfrac{\mathrm{d}L}{\mathrm{d}\theta} = \int\limits_{t_{1}}^{t_{0}} \left( \dfrac{\partial L}{\partial \mathbf{z}(t)} \right)^{\mathsf{T}} \dfrac{\partial f(\mathbf{z}(t), t; \theta)}{\partial \theta} \mathrm{d}t
$$</p><p>자세한 내용은 Appendix B, C, D에서 확인할 수 있다. <a href=https://proceedings.neurips.cc/paper_files/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Supplemental.zip>(다운로드 링크)</a> 또한 아래에서 설명한 예제에 대한 코드와 학습에 관련된 메서드는 <code>torchdiffeq</code> 패키지에 포함되어있으며, <a href=https://github.com/rtqichen/torchdiffeq/tree/master>깃허브</a>에 공개되어있다.</p><h2 id=3-replacing-residual-networks-with-odes-for-supervised-learning>3 Replacing residual networks with ODEs for supervised learning</h2><p>Neural ODE는 $(1)$을 $(3)$과 같이 바꾼 것이라 생각하면, residual network의 일반화로 볼 수 있다.</p><p>$$
\text{residual: } \mathbf{h}_{t+1} = \mathbf{h}_{t} + f(\mathbf{h}_{t}; \theta) \quad\overset{\text{generalization}}{\implies}\quad \dfrac{\mathrm{d}\mathbf{h}}{\mathrm{d}t} = f(\mathbf{h}(t), t; \theta)
$$</p><p>그래서 ResNet을 활용한 지도학습에서 Neural ODE를 활용할 수 있다. 저자들은 <a href=../3444>MNIST 데이터셋</a>의 판별문제에서 ResNet 부분을 그대로 Neural ODE로 치환하여 성능을 비교하였다.</p><p>ODE의 초기값 문제를 수치적으로 풀기위해 선택한 <a href=../1093>솔버</a>는 <a href=../724>아담스 메소드</a>이다. <code>scipy.integrate</code> 패키지로 제공되는 <a href=../2671>암시적 메소드</a>를 사용하였다. 최적화 기법인 adjoint sensitivity method를 <code>pytorch.autograd</code>로 구현하였다.</p><p>실험 결과로 ODE-Net은 ResNet에 비해서 $1/3$ 정도의 파라미터를 가짐에도 불구하고 거의 비슷한 성능을 보여주었다. $L$은 ResNet의 레이어 수를 의미하며, ResNet의 계산 시간과 역전파에 필요한 메모리는 $L$에 비례한다. $\tilde{L}$은 ODE 솔버의 number of function evaluations (NFE)인데, 적분 구간을 얼마나 나누어 계산할 것인지를 의미한다. ODE 솔버는 수치적분을 수행하므로 <a href=../1128>적분 구간을 나누게</a>되는데 NFE는 이 구간의 수를 말한다. 가령 $[0, 1]$구간을 $0.05$의 간격으로 적분을 수행하면 $\text{NFE} = \dfrac{1}{0.05} = 20$이다. 논문에서는 이를 ODE-Net의 layer 수로 해석할 수 있다고 언급한다. NFE가 클수록 정확하게 계산할 수 있지만, 계산시간이 오래 걸리므로 적당한 숫자를 선택하는 것이 중요하다. Neural ODE에서는 NFE를 모델이 알아서 선택한다.</p><p><img src=3159_3.png alt></p><p>Figure 3a, 3b에서는 각각 순방향 계산에서의 NFE에 따른 오차와 계산 시간을 보여주며, 직관에 잘 들어맞는 결과라 할 수 있다. Figure 3c를 보면 역방향 계산이 순방향 계산에 비해 절반 정도의 수준이라는 것을 알 수 있다. 이는 제안하는 학습 방법 adjoint sensitivity method가 꽤 효율적이라는 것을 보여준다. Figure 3d는 훈련이 진행됨에 따라 NFE가 증가함을 보여주는데, 이는 모델이 훈련되며 점점 복잡해지고 이를 잘 표현하기 위해 정교해지는 것이라 설명한다.</p><p><img src=3159_4.png alt></p><h2 id=4-continuous-normalizing-flows>4 Continuous Normalizing Flows</h2><p>$(1)$과 같은 이산적 모델링은 <a href=../3247>노멀라이징 플로우</a><sup>normalizing flow (NF)</sup> 에서도 나타난다.</p><p>$$
\mathbf{z}_{1} = f(\mathbf{z}_{0})
$$</p><p>$$
\log p(\mathbf{z}_{1}) = \log p(\mathbf{z}_{0}) - \log \left| \det \dfrac{\partial f}{\partial \mathbf{z}_{0}} \right| \tag{a4}
$$</p><p>간단히 planar flow를 예로 들면,</p><p>$$
\mathbf{z}_{t+1} = \mathbf{z}_{t} + \mathbf{u} \tanh (\mathbf{w}^{\mathsf{T}}\mathbf{z}_{t} + b)
$$</p><p>$$
\log p(\mathbf{z}_{t+1}) = \log p(\mathbf{z}_{t}) - \log \left| 1 + \mathbf{u}^{\mathsf{T}} \dfrac{\partial \tanh}{\partial \mathbf{z}} \right|
$$</p><p>노멀 플로우를 학습하는데 있어서 가장 중요하게 고려해야할 사항은 $(a4)$의 <a href=../252>행렬식</a> 계산이다. 이는 $\mathbf{z}$의 차원이나 가중치 개수에 대해서 세제곱의 계산비용을 가진다. 흥미롭게도 이산적 구조 $(1)$에서 연속적구조 $(3)$으로 바꾸면 이와 관련된 계산이 더 단순해진다.</p><hr><p>$\textbf{Theorem 1 }\text{(Instantaneous Change of Variables).}$</p><p>$\mathbf{z}(t)$를 <a href=../1433>연속확률변수</a>, $p(\mathbf{z}(t))$를 이에 대한 <a href=../1433>확률밀도함수</a>라 하자. 그리고 <a href=../1660>비자율 미분방정식</a>이 다음과 같이 주어졌다고 하자.</p><p>$$
\dfrac{\mathrm{d} \mathbf{z}}{\mathrm{d}t} = f(\mathbf{z}(t), t) \tag{a5}
$$</p><p>$f$가 변수 $\mathbf{z}$에 대해서 <a href=../3541>립시츠연속</a>이고, 변수 $t$에 대해서 <a href=../1206>연속</a>이라고 하자. 그러면 로그확률밀도의 도함수는 다음과 같다.</p><p>$$
\dfrac{\partial \log p(\mathbf{z}(t))}{\partial t} = -\Tr \left( \dfrac{\partial f}{\partial \mathbf{z}(t)} \right)
$$</p><p>여기서 $\Tr$은 <a href=../1924>트레이스</a>이다.</p><hr><p>$(a4)$의 행렬식 계산이 단순한 트레이스 계산으로 바뀌었다. 또한 표준적인 이산 노멀라이징 플로우에서와 달리, 이 경우에서는 $f$가 <a href=../471>전단사</a>일 필요가 없다. 위에서 예로든 planar flow를 위 $\textbf{Theorem 1}$에 맞춰 연속적인 형태로 바꾸면 다음과 같다.</p><p>$$
\dfrac{\mathrm{d}\mathbf{z}(t)}{\mathrm{d}t} = \mathbf{u} \tanh(\mathbf{w}^{\mathsf{T}}\mathbf{z}(t) + b), \qquad \dfrac{\partial \log p (\mathbf{z}(t))}{\partial t} = -\Tr \left( \mathbf{u} \dfrac{\partial \tanh(\mathbf{w}^{\mathsf{T}}\mathbf{z}(t) + b)}{\partial \mathbf{z}(t)} \right)
$$</p><p><strong>Using multiple hidden units with linear cost</strong></p><p>행렬식은 선형이 아니지만, <a href=../1924>트레이스는 선형</a>이므로 $\Tr \sum\limits_{n} J_{n} = \sum\limits_{n} \Tr J_{n}$이 성립한다. 따라서 $(a5)$의 $f$를 선형결합으로 나타내어도, 로그확률밀도함수의 도함수는 다음과 같이 간단히 나타낼 수 있다.</p><p>$$
\dfrac{\mathrm{d} \mathbf{z}(t)}{\mathrm{d}t} = \sum\limits_{n=1}^{M} f_{n}(\mathbf{z}(t)), \qquad \dfrac{\mathrm{d}\log p(\mathbf{z}(t))}{\mathrm{d}t} = -\sum\limits_{n=1}^{M} \Tr \left( \dfrac{\partial f_{n}}{\partial \mathbf{z}(t)} \right)
$$</p><p>이는 은닉층의 노드 수 $M$에 대해 계산 비용이 선형적으로 증가함을 의미한다. 기존의 노멀라이징 플로우는 $\mathcal{O}(M^{3})$의 계산 비용 때문에 대부분 한 개의 노드를 층을 많이 쌓는 구조로 사용한다.</p><p><strong>Time-dependent dynamics</strong></p><p>논문에서는 gating이라 불리는 방법을 사용하여 플로우를 아래와 같이 정의한다.</p><p>$$
\dfrac{\mathrm{d} \mathbf{z}}{\mathrm{d}t} = \sum\limits_{n} \sigma_{n}(t)f_{n}(\mathbf{z}), \qquad \sigma_{n}(t) \in (0 1)
$$</p><p>즉 $f(\mathbf{z}, t)$가 <a href=../1985>변수분리 가능</a>하다고 가정하는 것이다. 여기서 $\sigma_{n}$도 $f_{n}$도 모두 학습해야할 신경망이다. 논문에서는 이를 <strong>연속 노멀라이징 플로우</strong><sup>consinuous normalizing flow (CNF)</sup>라 한다. [플로우 매칭]은 이 CNF를 더 효율적으로 학습할 수 있는 하나의 방법이다.</p><h3 id=41-experiments-with-continuous-normalizing-flows>4.1 Experiments with Continuous Normalizing Flows</h3><p>CNF와 NF를 비교한다. CNF는 위에서 설명한대로 구현되었으며, <a href=../3529>Adam</a> 옵티마이저를 사용하여 10,000 반복하여 훈련하였다. NF는 <a href=../3247>처음 제안된 논문</a>에서와 같이 구현되었으며, <a href=../3529>RMSprop</a> 옵티마이저를 사용하여 500,000 반복하여 훈련하였다. CNF 쪽이 반복 횟수가 현저히 적다. 결과는 아래 그림에서 확인할 수 있다.</p><p><img src=3159_5.png alt></p><p>아래의 Figure 5에서 위의 두 행은 CNF, 마지막 행은 NF에 대한 결과로 보인다. CNF는 매끄럽게 변환되는 반면, NF는 그렇지 못하며 Two Moons 데이터에 대해서는 제대로 모델링하지 못했다.</p><p><img src=3159_6.png alt></p><h2 id=5-a-generative-latent-function-time-series-model>5 A generative latent function time-series model</h2><p>Neural ODE는 비자율 시스템을 신경망으로 근사하는 방법이니 만큼, <a href=../900>시계열데이터</a>의 예측, 보간, 결측치 생성 등에도 사용할 수 있다. 논문에서 제안하는 훈련 방법은 아래와 같다.</p><ol start=0><li>시계열 데이터 $\left\{ \mathbf{x}_{i}, t_{i} \right\}_{i=1}^{N}$이 주어져있다고 하자.</li><li>RNN을 <a href=../3380>인코더</a>로 사용하여 <a href=../3589>잠재변수</a> $\boldsymbol{\mu}$와 $\boldsymbol{\sigma}$를 추출한다.
$$
(\boldsymbol{\mu}, \log\boldsymbol{\sigma}^{2}) = \operatorname{RNNencoder}\left( \left\{ \mathbf{x}_{i}, t_{i} \right\} \right)
$$</li><li>정규분포 $N(\mathbf{0}, I)$에서 $\boldsymbol{\epsilon}$를 <a href=../2686>추출</a>하고 $\boldsymbol{\mu}$와 $\boldsymbol{\sigma}$를 사용하여 잠재변수의 초기값 $\mathbf{z}_{t_{0}}$를 생성한다.
$$
\mathbf{z}_{t_{0}} = \exp(0.5 \log\boldsymbol{\sigma}^{2}) \odot \boldsymbol{\epsilon} + \boldsymbol{\mu}
$$
이렇게하면 마치 $\operatorname{RNNencoder}$가 시계열데이터를 <a href=../3589>잠재공간</a> $N(\boldsymbol{\mu}, \diag(\boldsymbol{\sigma}^{2}))$로 매핑하는 것과 같은 효과를 주면서도, 역전파가 가능하다.</li><li>잠재변수의 초기값 $\mathbf{z}_{t_{0}}$와 Neural ODE를 통해 $\mathbf{z}_{t_{i}}$를 계산한다.
$$
(\mathbf{z}_{t_{1}}, \mathbf{z}_{t_{2}}, \dots, \mathbf{z}_{t_{N}})
= \operatorname{ODESolve}(\mathbf{z}_{t_{0}}, f, t_{0}, \dots, t_{N}, \theta)
$$</li><li>$\mathbf{z}_{t_{i}}$를 <a href=../3447>FCN</a>으로 정의한 <a href=../3380>디코더</a> 입력하여 예측된 시계열 데이터 $\mathbf{x}_{i}$를 얻는다.
$$
\mathbf{x}_{t_{i}} = \operatorname{FCNdecoder}(\mathbf{z}_{t_{i}})
$$</li><li>ELBO를 최대화 한다.
$$
\text{ELBO} = \sum\limits_{i} \log p(\mathbf{x}_{t_{i}} | \mathbf{z}_{t_{i}}) + \log p(\mathbf{z}_{t_{0}}) - \log q(\mathbf{z}_{t_{0}} | \left\{ \mathbf{x}_{t_{i}}, t_{i} \right\})
$$</li></ol><h3 id=51-time-series-latent-ode-experiments>5.1 Time-series Latent ODE Experiments</h3><p>실험에 사용한 신경망은 다음과 같다.</p><ul><li>$\operatorname{RNNencoder}$: 노드가 25개인 RNN</li><li>잠개공간은 4차원. $(\boldsymbol{\mu}), (\boldsymbol{\sigma}) \in \mathbb{R}^{2 \times 2}$</li><li>NeuralODE $f$: 노드가 20개인 은닉층 하나를 가진 MLP</li><li>$\operatorname{FCNdecoder}$: 노드가 20개인 은닉층 하나를 가진 또 다른 MLP</li></ul><p>데이터셋에 대한 조건은 아래와 같다.</p><ul><li>2차원 나선형 데이터 1,000개 생성.</li><li>절반은 시계방향, 나머지는 시계반대방향.</li><li>각 궤적은 서로 다른 초기값에서 시작하여 균등한 시간 간격으로 100개의 점 샘플링.</li><li>관측치에 가우시안 노이즈 추가함.</li><li>학습할 때는 각 궤적의 100개의 점 중에서 중복없이 무작위로 30/50/100개를 추출하여 사용함.</li></ul><p>아래의 표를 보면 NeuralODE의 성능이 현저히 좋은 것을 알 수 있고, 또한 데이터가 적을 때도 많을 때에 비해서 성능이 크게 내려가지 않는다는 것을 확인할 수 있다.</p><p><img src=3159_7.png alt></p><p>아래의 그림은 RNN과 NeuralODE의 예측 결과이다. NeuralODE의 결과가 더 매끄러우며, 학습하지않은 바깥 영역에서의 예측 또한 더 낫다는 것을 보여둔다.</p><p><img src=3159_8.png alt></p><p>아래의 그림은 잠재변수의 궤적을 처음 두 차원에 대해서 그린 것이다. 궤적들은 시계방향의 나선과 시계반대방향의 나선 두 가지 군집으로 나뉘는데, 이는 제안하는 방법이 <a href=../3589>잠재변수</a>를 잘 묘사한다는 것을 의미한다.</p><p><img src=3159_9.png alt></p><aside style=text-align:right>2021-12-15&emsp;
전기현&emsp;
<a href=../1889>🎲 3159</a></aside><script>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="논문 리뷰: Neural Ordinary Differential Equations",c="https://freshrimpsushi.github.io/ko/posts/3159/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script></div><aside><h2>댓글</h2><div class=area-reply><div class=list-reply></div></div><div class=write-box><div class="write-author-info box-account"><input type=hidden name=cmt_idx>
<input class=ai-author type=text placeholder=Name>
<input class=ai-password type=password maxlength=20 placeholder=Password></div><div class=write-content><textarea class=ai-content value placeholder=내용 style=ime-mode:active></textarea></div><button class=write-button onclick=write_comment() aria-label=send><i class='fa-solid fa-paper-plane'></i></button><aside class=tex>댓글에도 $\TeX$이 적용됩니다.</aside></div></aside><script>let commentRows=[];const listReply=document.querySelector(".list-reply");document.addEventListener("DOMContentLoaded",()=>{get_all_comment()});function get_all_comment(){fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=getAllComment";return postFetch(t,{board_idx:"3159",user_ip:e})}).then(e=>e.json()).then(e=>{e.ok&&(commentRows=e.rows,render_comment(commentRows))}).catch(e=>console.error(e))}function render_comment(e){const n=["류대식","전기현","ㅇㅇ","질문"],s=["류대식","전기현"];render_blank();let t="";e.map(e=>{t+=`<div id="comment${e.cmt_idx}" class="parents">`,t+=`<div class="content-info">`;let o="";e.cmt_cnt>125?o="🥇":e.cmt_cnt>25?o="🥈":e.cmt_cnt>5&&(o="🥉"),n.includes(e.author)&&(o="");let i="";e.ip_address==null?i="(-)":(ipParts=e.ip_address.split("."),i=`(${ipParts[0]}.${ipParts[1]})`),s.includes(e.author)&&(i=""),t+=`<div class="list-author">${o} ${e.author} ${i}</div>`,t+=`<sup class="list-date">${e.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${e.cmt_idx}', 'parents');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,e.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> 관리자의 승인을 기다리고 있습니다</div>`);let a=e.content;a=a.replace(/\n/g,"<br />"),t+=`<div class="content-text">${a} <span class="re-comment-button" onclick="re_comment('${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`,e.child.map(o=>{let c="child";e.ip_address&&o.ip_address===e.ip_address&&(c="parentself"),t+=`<div id="comment${o.cmt_idx}" class="${c}">`,t+=`<div class="content-info">`;let i="";o.cmt_cnt>5?i="🥉":o.cmt_cnt>25?i="🥈":o.cmt_cnt>125&&(i="🥇"),n.includes(o.author)&&(i="");let a="";o.ip_address==null?a="(-)":a=`(${o.ip_address})`,s.includes(o.author)&&(a=""),t+=`<div class="list-author">${i} ${o.author} ${a}</div>`,t+=`<sup class="list-date">${o.datetime.slice(2,-3)}</sup>`,t+=`<div class="list-button">`,t+=`<div class="list-update-button" onclick="update_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-pen-to-square"></i></div>`,t+=`<div class="list-delete-button" onclick="delete_comment('${o.cmt_idx}', 'child');"><i class="fa-solid fa-trash"></i></div>`,t+=`</div>`,t+=`</div>`,o.approve||(t+=`<div style="text-align: right;"><i class="fa-solid fa-hourglass"></i> 관리자의 승인을 기다리고 있습니다</div>`);let r=o.content;r=r.replace(/\n/g,"<br />"),t+=`<div class="content-text">${r} <span class="re-comment-button" onclick="re_comment('${o.cmt_idx}', '${e.cmt_idx}');"><i class="fa-solid fa-reply" style="cursor: pointer;"></i></span></div>`,t+=`<div class="re-comment"></div>`,t+=`</div>`})}),listReply.innerHTML=t,renderKaTex(listReply),location.href.indexOf("#")!=-1&&(location.href=location.href.substr(location.href.indexOf("#")))}function render_blank(){listReply.innerHTML=""}function write_comment(){const e=document.querySelector(".ai-author"),t=document.querySelector(".ai-password"),n=document.querySelector(".ai-content"),s=e.value,o=t.value,i=n.value;if(s===""||o===""||i===""){alert("빈칸을 채워주세요");return}const a="3159",r="",c="논문 리뷰: Neural Ordinary Differential Equations";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeComment";return postFetch(t,{board_idx:a,board_slug:r,board_title:c,author:s.replace(/\+/g,"%2B"),password:o,content:i.replace(/\+/g,"%2B"),user_ip:e})}).then(e=>e.json()).then(s=>{s.ok?(commentRows.push(s.row),render_comment(commentRows),e.value="",t.value="",n.value=""):s.status===606?(Swal.fire(`Warning!
지속적인 도배 시도시
IP가 차단될 수 있습니다.`),e.value="",t.value="",n.value=""):s.status===607&&(alert(`지나친 댓글 도배를 확인하여
접근을 차단합니다.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}async function update_comment(e,t){const{value:n}=await Swal.fire({title:"댓글 수정",input:"password",inputPlaceholder:"글 작성 시 입력했던 패스워드를 입력하세요",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(s=>{if(s.ok){const s=document.querySelector(`#comment${e}`),o="https://freshrimpsushi.com/blog/ajax/comment.php?action=getComment";postFetch(o,{cmt_idx:e}).then(e=>e.json()).then(o=>{if(o.ok){const a=o.row,r=a.author,c=a.content;let i="";i+=`<div class="update-author-info">`,i+=`<input class="update-author" type="text" value="${r}" placeholder="이름" />`,i+=`<input class="update-password" type="password" value="${n}" placeholder="비밀번호" disabled />`,i+="</div>",i+=`<textarea class="update-content" value="" style="IME-MODE:active;">${c}</textarea>`,i+=`<input class="update_comment-button" type="submit" value="수정" onclick="update_comment_click(${e}, '${t}')" />`,i+=`<input class="update_comment-button" type="submit" value="취소" onclick="cancel_click(${e})" />`,s.innerHTML=i}}).catch(e=>console.error(e))}else Swal.fire("패스워드 일치 오류")}).catch(e=>console.error(e))}}async function delete_comment(e,t){const{value:n}=await Swal.fire({title:"댓글 삭제",text:"삭제하면 되돌릴 수 없습니다.",input:"password",icon:"warning",showCancelButton:!0,confirmButtonColor:"#3085d6",cancelButtonColor:"#d33",inputPlaceholder:"글 작성 시 입력했던 패스워드를 입력하세요",inputAttributes:{maxlength:20,autocapitalize:"off",autocorrect:"off"}});if(n){const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=checkPassword";postFetch(s,{cmt_idx:e,password:n}).then(e=>e.json()).then(n=>{if(n.ok){const n="https://freshrimpsushi.com/blog/ajax/comment.php?action=deleteComment";postFetch(n,{cmt_idx:e}).then(e=>e.json()).then(n=>{Swal.fire("삭제되었습니다."),t==="parents"?commentRows=commentRows.filter(t=>t.cmt_idx!==e):t==="child"&&commentRows.map(t=>{t.child=t.child.filter(t=>t.cmt_idx!==e),t.child_cnt=t.child.length}),render_comment(commentRows)}).catch(e=>console.error(e))}else Swal.fire("패스워드 일치 오류")}).catch(e=>console.error(e))}}function update_comment_click(e,t){const i=document.querySelector(`#comment${e} .update-author`),a=document.querySelector(`#comment${e} .update-password`),r=document.querySelector(`#comment${e} .update-content`),n=i.value,s=a.value,o=r.value;(n===""||s===""||o==="")&&alert("빈칸을 채워주세요");const c="https://freshrimpsushi.com/blog/ajax/comment.php?action=updateComment";postFetch(c,{cmt_idx:e,author:n.replace(/\+/g,"%2B"),password:s,content:o.replace(/\+/g,"%2B")}).then(e=>e.json()).then(n=>{n.ok&&(Swal.fire("수정되었습니다."),t==="parents"?commentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}):t==="child"&&commentRows.map(t=>{t.cmt_idx==n.parent_cmt_idx&&t.child.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)})}),render_comment(commentRows),recentRows.map(t=>{t.cmt_idx==e&&(t.author=n.author,t.content=n.content)}),render_recent_comment(recentRows))}).catch(e=>console.error(e))}function cancel_click(){render_comment(commentRows)}function re_comment(e,t){const s=document.querySelector(`#comment${e} .re-comment`);let n="";n+='<div class="re-comment-box">',n+='<div class="re-comment-author-info">',n+='<input class="re-comment-author" type="text" value="" placeholder="이름" />',n+='<input class="re-comment-password" type="password" value="" placeholder="비밀번호" />',n+="</div>",n+='<textarea class="re-comment-content" placeholder="내용" value="" style="IME-MODE:active;"></textarea>',t===void 0?n+=`<button class="write-button" onclick="re_comment_click(${e})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`:n+=`<button class="write-button" onclick="re_comment_click(${e}, ${t})" value="send"><i class='fa-solid fa-paper-plane'></i></button>`,n+=`<button class="write-button" onclick="cancel_click(${e})" value="close"><i class='fa-solid fa-solid fa-ban'></i></button>`,n+="</div>",s.innerHTML=n}function re_comment_click(e,t){const n=document.querySelector(`#comment${e} .re-comment-author`),s=document.querySelector(`#comment${e} .re-comment-password`),o=document.querySelector(`#comment${e} .re-comment-content`),i=n.value,a=s.value,r=o.value;if(i===""||a===""||r===""){alert("빈칸을 채워주세요");return}const c="3159",l="",d="논문 리뷰: Neural Ordinary Differential Equations";fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(n=>{const s="https://freshrimpsushi.com/blog/ajax/comment.php?action=writeReComment";return postFetch(s,{board_idx:c,board_slug:l,board_title:d,cmt_idx:t===void 0?e:t,author:i.replace(/\+/g,"%2B"),password:a,content:r.replace(/\+/g,"%2B"),user_ip:n})}).then(e=>e.json()).then(i=>{i.ok?(commentRows.map(n=>{t===void 0?n.cmt_idx==e&&n.child.push(i.row):n.cmt_idx==t&&n.child.push(i.row)}),render_comment(commentRows)):i.status==606?(Swal.fire(`Warning!
지속적인 도배 시도시
IP가 차단될 수 있습니다.`),n.value="",s.value="",o.value=""):i.status===607&&(alert(`지나친 댓글 도배를 확인하여
접근을 차단합니다.`),window.location.href="https://google.com")}).catch(e=>console.error(e))}</script></div><aside class=sidebar><aside><style>.reddot a:link{color:#67d10f;text-shadow:0 0 10px #d3d3d3;font-weight:700}.reddot a:visited{color:#f5f5f5}</style><p class=reddot style=text-align:center;margin:0><a href=https://freshrimpsushi.github.io/ko/posts/2707/>여름 특선 오마카세<br>「상상 속의 수」</a></p></aside><br><div class=category></div><div style=display:flex>● 를 클릭해서 관심있는 분야만 강조해보세요.<div class=resetmute><button class="sb-btn btnReset" style=border-radius:5px;border:0>reset</button>
<button class="sb-btn btnMute" style=border-radius:5px;border:0>mute</button></div></div><script defer>const color={green:"#33cc33",yellow:"#ffcc00",red:"#ff3333",black:"#000000"},categoryRows=[[{idx:1,name:"함수",color:color.green,show:"함수",size:"146"},{idx:2,name:"보조정리",color:color.green,show:"보조정리",size:"62"},{idx:3,name:"미분적분학",color:color.green,show:"미분적분학",size:"45"},{idx:4,name:"행렬대수",color:color.green,show:"행렬대수",size:"117"}],[{idx:1,name:"정수론",color:color.green,show:"정수론",size:"90"},{idx:2,name:"집합론",color:color.green,show:"집합론",size:"49"},{idx:3,name:"그래프이론",color:color.green,show:"그래프이론",size:"65"},{idx:4,name:"선형대수",color:color.green,show:"선형대수",size:"97"},{idx:5,name:"해석개론",color:color.green,show:"해석개론",size:"84"},{idx:6,name:"추상대수",color:color.green,show:"추상대수",size:"98"},{idx:7,name:"위상수학",color:color.green,show:"위상수학",size:"64"},{idx:8,name:"기하학",color:color.green,show:"기하학",size:"167"}],[{idx:1,name:"다변수벡터해석",color:color.green,show:"다변수벡터해석",size:"36"},{idx:2,name:"복소해석",color:color.green,show:"복소해석",size:"71"},{idx:3,name:"측도론",color:color.green,show:"측도론",size:"54"},{idx:4,name:"푸리에해석",color:color.green,show:"푸리에해석",size:"54"},{idx:5,name:"표현론",color:color.red,show:"표현론",size:"7"},{idx:6,name:"초함수론",color:color.green,show:"초함수론",size:"22"},{idx:7,name:"단층촬영",color:color.green,show:"단층촬영",size:"20"}],[{idx:1,name:"거리공간",color:color.green,show:"거리공간",size:"38"},{idx:2,name:"바나흐공간",color:color.green,show:"바나흐공간",size:"38"},{idx:3,name:"힐베르트공간",color:color.green,show:"힐베르트공간",size:"31"},{idx:4,name:"르벡공간",color:color.green,show:"르벡공간",size:"33"}],[{idx:1,name:"상미분방정식",color:color.green,show:"상미분방정식",size:"58"},{idx:2,name:"편미분방정식",color:color.green,show:"편미분방정식",size:"60"},{idx:3,name:"확률미분방정식",color:color.green,show:"확률미분방정식",size:"26"}],[{idx:1,name:"줄리아",color:color.green,show:"줄리아",size:"234"},{idx:2,name:"알고리즘",color:color.green,show:"알고리즘",size:"28"},{idx:3,name:"수치해석",color:color.green,show:"수치해석",size:"63"},{idx:4,name:"최적화이론",color:color.green,show:"최적화이론",size:"37"},{idx:5,name:"머신러닝",color:color.green,show:"머신러닝",size:"115"},{idx:6,name:"프로그래밍",color:color.yellow,show:"프로그래밍",size:"126"},{idx:7,name:"세이버메트릭스",color:color.green,show:"세이버메트릭스",size:"234",size:"13"}],[{idx:1,name:"물리학",color:color.green,show:"물리학",size:"30"},{idx:2,name:"수리물리",color:color.green,show:"수리물리",size:"78"},{idx:3,name:"고전역학",color:color.green,show:"고전역학",size:"48"},{idx:4,name:"전자기학",color:color.green,show:"전자기학",size:"51"},{idx:5,name:"양자역학",color:color.green,show:"양자역학",size:"57"},{idx:6,name:"열물리학",color:color.green,show:"열물리학",size:"29"}],[{idx:1,name:"R",color:color.green,show:"R",size:"54"},{idx:2,name:"데이터확보",color:color.green,show:"데이터확보",size:"29"},{idx:3,name:"데이터과학",color:color.green,show:"데이터과학",size:"42"},{idx:4,name:"통계적검정",color:color.green,show:"통계적검정",size:"40"},{idx:5,name:"통계적분석",color:color.green,show:"통계적분석",size:"76"},{idx:6,name:"수리통계학",color:color.green,show:"수리통계학",size:"124"},{idx:7,name:"확률분포론",color:color.green,show:"확률분포론",size:"86"},{idx:8,name:"확률론",color:color.green,show:"확률론",size:"80"},{idx:9,name:"위상데이터분석",color:color.green,show:"위상데이터분석",size:"40"}],[{idx:1,name:"논문작성",color:color.red,show:"논문작성",size:"65"},{idx:2,name:"생새우초밥지",color:color.black,show:"생새우초밥지",size:"7"}]];document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("blindList"));(e==""||e==null||e==null||e==0||e==NaN)&&localStorage.setItem("blindList",null),render_category(categoryRows),blind_category(e);const t=document.querySelector(".btnReset");t.addEventListener("click",()=>{let e=new Array;localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)});const n=document.querySelector(".btnMute");n.addEventListener("click",()=>{let e=new Array;for(let t=0;t<categoryRows.length;t++)categoryRows[t].map(n=>{const s={mainIdx:t,subIdx:n.idx};e.push(s)});localStorage.setItem("blindList",JSON.stringify(e)),blind_category(e)})});function render_category(e){const n=document.querySelector(".category");let t="";for(let n=0;n<e.length;n++)e[n].map(e=>{t+=`<span id="cate${n}-${e.idx}" class="cate etewsert">`,t+=`<span onclick="check_blind(${n}, ${e.idx});" style="cursor: pointer; color: ${e.color}">●</span>`,t+=`<a href="https://freshrimpsushi.github.io/ko/categories/${e.name.toLowerCase()}/">`,t+=` ${e.show} (${e.size})</a>`,t+="</span>",screen.width>954?t+="<br>":t+=" "}),t+="<hr>";n.innerHTML=t}function check_blind(e,t){const o=document.querySelector(`#cate${e}-${t}`);let n=new Array;const i={mainIdx:e,subIdx:t};let s=JSON.parse(localStorage.getItem("blindList"));if(s==""||s==null||s==null||s==0||s==NaN)n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind";else{n=s;let a=null;for(let s=0;s<n.length;s++)if(n[s].mainIdx==e&&n[s].subIdx==t){a=n.filter(n=>n.mainIdx!=e||n.subIdx!=t);break}a===null?(n.push(i),localStorage.setItem("blindList",JSON.stringify(n)),o.className+=" blind"):(localStorage.setItem("blindList",JSON.stringify(a)),o.className="cate")}}function blind_category(e){const t=document.querySelectorAll(".cate");t.forEach(e=>{e.className="cate"}),e!==null&&e.map(e=>{const t=document.querySelector(`#cate${e.mainIdx}-${e.subIdx}`);t.className+=" blind"})}</script><br><aside><img src=https://freshrimpsushi.github.io/ko/banner/%EC%A4%84%EB%A6%AC%EC%95%84%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.png alt=줄리아프로그래밍>
저희들의 저서 「줄리아 프로그래밍」이 2024 세종도서 학술부문에 선정되었습니다!<p style=margin:0><a href=https://product.kyobobook.co.kr/detail/S000213090376><img src=https://freshrimpsushi.github.io/ko/banner/%EA%B5%90%EB%B3%B4.png style=width:70px alt=교보문고></a>
<a href=https://www.yes24.com/Product/Goods/126164843><img src=https://freshrimpsushi.github.io/ko/banner/%EC%98%88%EC%8A%A424.png style=width:70px alt=예스24></a>
<a href="https://www.aladin.co.kr/shop/wproduct.aspx?ISBN=K532930200&start=pnaver_02"><img src=https://freshrimpsushi.github.io/ko/banner/%EC%95%8C%EB%9D%BC%EB%94%98.png style=width:70px alt=알라딘></a></p></aside><br><b>최근 본 포스트</b><div class=lately-viewed-list style=padding-left:4px></div><script defer>document.addEventListener("DOMContentLoaded",()=>{const e=JSON.parse(localStorage.getItem("latelyViewPostList")),n=document.querySelector(".lately-viewed-list");let t="";if(e==""||e==null||e==null||e==0||e==NaN)localStorage.setItem("latelyViewPostList",null),t+='<div class="lv-list">',t+=" · 열람한 포스트가 없습니다.",t+="</div>",n.innerHTML=t;else{for(let n=e.length-1;n>=0;n--)t+='<div class="lv-list">',t+=`<a href="${e[n].link}"> · ${e[n].title}</a>`,t+="</div>";n.innerHTML=t}})</script><script defer>document.addEventListener("DOMContentLoaded",()=>{const s=document.querySelector(".content-box");s&&renderKaTex(s);const o=document.querySelector(".tex");o&&renderKaTex(o);var n,r,i="논문 리뷰: Neural Ordinary Differential Equations",c="https://freshrimpsushi.github.io/ko/posts/3159/",t=new Array,a={title:i,link:c},e=JSON.parse(localStorage.getItem("latelyViewPostList"));if(e==""||e==null||e==null||e==0||e==NaN)t.push(a),localStorage.setItem("latelyViewPostList",JSON.stringify(t));else{for(r=e.length,n=0;n<r;n++)if(i==e[n].title){e.splice(n,1);break}t=e,t.push(a),t.length>5&&t.shift(),localStorage.setItem("latelyViewPostList",JSON.stringify(t))}})</script><br><b>최신 댓글</b><div class=current-reply></div><script defer>const url="https://freshrimpsushi.com/blog/ajax/recent_comment.php?action=getCurrentComment";let recentRows=[];fetch(url).then(e=>e.json()).then(e=>{e.ok&&(recentRows=e.rows,render_recent_comment(recentRows))}).catch(e=>console.error(e));function render_recent_comment(e){const n=document.querySelector(".current-reply");let t="";e.map(e=>{let n="https://freshrimpsushi.github.io/ko/";e.board_idx>-1?n+=`posts/${e.board_idx}#comment${e.cmt_idx}`:e.board_idx==-1?n+=`#comment${e.cmt_idx}`:n+=`categories/${e.board_title}#comment${e.cmt_idx}`,t+='<div class="current-reply-list">',t+=`<a href="${n}">`,t+=`<b> - ${e.author}</b>: `,t+=`${e.content}`,t+=`</a>`,t+=`</div>`}),n.innerHTML=t,renderKaTex(n)}</script><br></aside></div><footer><aside><div><p id=mirror-link style=text-align:center><a style=cursor:text href=http://localhost:1313//ko/posts/3159/>© 생새우초밥집 / Powered by 류대식, 전기현</a><br>Contact:
<img src=https://freshrimpsushi.github.io/ko/logo/gmail.png width=12px alt=mail> freshrimpsushi@gmail.com
<a href=https://freshrimpsushi.github.io/ko/index.xml><img src=https://freshrimpsushi.github.io/ko/logo/RSS.png width=12px alt=RSS> RSS</a></p></div><script type=text/javascript>var goIndex=function(){var e=document.getElementsByName("idx")[0].value,t="https://freshrimpsushi.github.io/ko/posts/"+e;location.replace(t)};document.addEventListener("keydown",function(e){const n=document.getElementById("navigator");if(e.altKey&&e.ctrlKey&&e.key==="l"){e.preventDefault();var t=document.querySelector("#mirror-link a");t?t.click():console.log("거울 링크를 찾지 못했습니다.")}})</script></aside></footer></body><script async src="https://www.googletagmanager.com/gtag/js?id=G-NLV8Y9PRK1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NLV8Y9PRK1")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4751085325232621" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/sweetalert2@11></script><script src=https://freshrimpsushi.github.io/ko/js/fontawsome.min.js></script><script src=https://freshrimpsushi.github.io/ko/js/common.js></script><script>document.addEventListener("DOMContentLoaded",()=>{fetch("https://api64.ipify.org?format=json").then(e=>e.json()).then(e=>e.ip).then(e=>{const t="https://freshrimpsushi.com/blog/ajax/ip_checker.php";return postFetch(t,{user_ip:e})}).then(e=>e.json()).then(e=>{e.ok||(alert(`차단된 IP입니다.
Contact:
freshrimpsushi@gmail.com`),window.location.href="https://google.com")}).catch(e=>console.error(e))})</script></html>