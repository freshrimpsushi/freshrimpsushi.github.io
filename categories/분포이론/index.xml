<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>분포이론 on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/categories/%EB%B6%84%ED%8F%AC%EC%9D%B4%EB%A1%A0/</link>
    <description>Recent content in 분포이론 on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Wed, 23 Sep 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/categories/%EB%B6%84%ED%8F%AC%EC%9D%B4%EB%A1%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>모평균이 존재하지 않는 분포  코시분포</title>
      <link>https://freshrimpsushi.github.io/posts/cauchy-distribution/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cauchy-distribution/</guid>
      <description>다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $C$ 를 코시 분포 라고 한다. $$ f(x) = {1 \over \pi} {1 \over {x^2 + 1}} \qquad , x \in \mathbb{R} $$ [1] 코시 분포의 적률생성함수는 존재하지 않는다. 모든 확률 분포가 평균과 분산을 가질 것 같지만 실제로는 그렇지 않다. 그 대표적인 예시가 코시 분포로, 언뜻 정규 분포와 닮았지만 양쪽 꼬리가 두꺼운 모양을 하고 있다. 모수에 무관하게 적률생</description>
    </item>
    
    <item>
      <title>t-분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-t-distribution/</link>
      <pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-t-distribution/</guid>
      <description>$X \sim t (\nu)$ 이면 $$ E(X) = 0 \qquad , \nu &amp;gt;1 \\ \text{Var}(X) = {{ \nu } \over { \nu - 2 }} \qquad , \nu &amp;gt; 2 $$ Strategy** : t-분포 역시 카이제곱분포와 비슷하게 적률 공식이 알려져 있어, 이 공식들을 이용한다. t-분포의 적률두 확률 변수 $W,V$ 가 독립이고 $W \sim N(0,1)$, $V \sim \chi^{2} (r)$ 이라 하자. $k &amp;lt; r$ 이면 $\displaystyle T := { {W} \over {\sqrt{V/r} } }$ 는 $k$차 적률이 존재하고 $$ E T^{k} = E W^{k} {{ 2^{-k/2} \Gamma \left( {{ r } \over { 2 }} - {{ k } \over</description>
    </item>
    
    <item>
      <title>t-분포</title>
      <link>https://freshrimpsushi.github.io/posts/t-distribution/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/t-distribution/</guid>
      <description>자유도 $\nu &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $t \left( \nu \right)$ 를 t-분포라고 한다. $$ f(x) = {{ \Gamma \left( {{ \nu + 1 } \over { 2 }} \right) } \over { \sqrt{\nu \pi} \Gamma \left( {{ \nu } \over { 2 }} \right) }} \left( 1 + {{ x^{2} } \over { \nu }} \right)^{- {{ \nu + 1 } \over { 2 }}} \qquad ,x \in \mathbb{R} $$ * $\Gamma (\nu)$ 는 감마 함수다.t-분포 는 지금도 맥주로 유명한 기네스 양조 공장에서 일하던 윌리엄 고셋William S.</description>
    </item>
    
    <item>
      <title>독립인 정규 분포와 카이제곱 분포에서 스튜던트 t-분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/204/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/204/</guid>
      <description>두 확률 변수 $W,V$ 가 독립이고 $W \sim N(0,1)$, $V \sim \chi^{2} (r)$ 이라 하면 $$ \displaystyle T = { {W} \over {\sqrt{V/r} } } \sim t(r) $$ * $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. * $\chi^{2} \left( r \right)$ 은 자유도 $r$ 인 카이제곱 분포다. * $t(r)$ 은 자유도 $r$ 인 t-분포다.어떤 분포에서 다른 분포를 유도하는 것은 공부만 열심히 하면 직관적인 추측이 가능하다. 하지만 둘 이상의 분포에서 다른 분포를 유도해낸다</description>
    </item>
    
    <item>
      <title>표준정규분포의 제곱은 자유도가 1인 카이제곱분포를 따름을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/148/</link>
      <pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/148/</guid>
      <description>$X \sim N(\mu,\sigma ^2)$면 $$ \displaystyle V=\left( { X - \mu \over \sigma} \right) ^2 \sim \chi ^2 (1) $$ * $N \left( \mu , \sigma^{2} \right)$ 는 평균이 $\mu$ 고 분산이 $\sigma^{2}$ 인 정규 분포다. * $\chi^{2} \left( 1 \right)$ 은 자유도 $1$ 인 카이제곱 분포다.정리로는 이를 일반화시킨 스튜던트의 정리가 많이 쓰인다.통계학을 공부하는 사람이라면 표준정규분포의 제곱이 카이제곱분포를 따른다는 것은 팩트로써 항상 당연하게 알고 있어야한다. 어떤 데이</description>
    </item>
    
    <item>
      <title>정규 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-normal-distribution/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-normal-distribution/</guid>
      <description>$X \sim N\left( \mu , \sigma^{2} \right)$ 면 $$ E(X) = \mu \\ \text{Var} (X) = \sigma^{2} $$ Strategy** : 정규 분포는 적률생성함수가 미분하기 쉬우니 그냥 바로 직접연역한다. **정규 분포의 적률생성함수 $$ m(t) = \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) \qquad , t \in \mathbb{R} $$ 증명 $$ m&#39;(t) = \left( \mu + \sigma^{2} t \right) \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) $$ 이므로 $E(X) = m&#39;(0) = \mu$ 이고 $$ m&#39;&#39;(t) = \left( 0 + \sigma^{2} \right) \exp \left( \mu t + {{ \sigma^{2} t^{2} } \over { 2 }} \right) + \left( \mu + \sigma^{2} t</description>
    </item>
    
    <item>
      <title>F-분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-f-distribution/</link>
      <pubDate>Sat, 15 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-f-distribution/</guid>
      <description>$X \sim F ( r_{1} , r_{2})$ 면 $$ E(X) = {{ r_{2} } \over { r_{2} - 2 }} \qquad , r_{2} &amp;gt; 2 \\ \text{Var}(X) = {{ 2 d_{2}^{2} (d_{1} + d_{2} - 2) } \over { d_{1} (d_{2} -2)^{2} (d_{2} - 4) }} \qquad , r_{2} &amp;gt; 4 $$ Strategy** : F-분포 역시 카이제곱분포와 비슷하게 적률 공식이 알려져 있어, 이 공식들을 이용한다. F-분포의 적률$X \sim F(r_{1} , r_{2})$ 이고 $\displaystyle X = {{ X_{1} } \over { X_{2} }}$ 와 같이 나타낼 수 있다고 하자. $X_{1}$ 과 $X_{2}$ 가 각각 자유도 $d_{1}, d_{2}$ 인 카이제곱 분포를 따</description>
    </item>
    
    <item>
      <title>F-분포</title>
      <link>https://freshrimpsushi.github.io/posts/f-distribution/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/f-distribution/</guid>
      <description>자유도 $r_{1}, r_{2} &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $F \left( r_{1} , r_{2} \right)$ 를 F-분포 라고 한다. $$ f(x) = {{ 1 } \over { B \left( r_{1}/2 , r_{2} / 2 \right) }} \left( {{ r_{1} } \over { r_{2} }} \right)^{r_{1} / 2} x^{r_{1} / 2 - 1} \left( 1 + {{ r_{1} } \over { r_{2} }} x \right)^{-(r_{1} + r_{2}) / 2} \qquad , x \in (0, \infty) $$ * $B(r_{1} / 2, r_{2}/2)$ 는 베타 함수를 의미한다. [1] 적률 생성 함수 : F-분포는 적률 생성 함수가 존재하지 않는다.[2]</description>
    </item>
    
    <item>
      <title>독립인 두 감마 분포에서 베타 분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/1596/</link>
      <pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1596/</guid>
      <description>두 확률 변수 $X_{1},X_{2}$ 가 독립이고 $X_{1} \sim \Gamma ( \alpha_{1} , 1)$, $X_{2} \sim \Gamma ( \alpha_{2} , 1)$ 이라 하면 $$ {{ X_{1} } \over { X_{1} + X_{2} }} \sim \text{beta} \left( \alpha_{1} , \alpha_{2} \right) $$ 두 데이터가 감마 분포를 따르고 독립이라면, 그 합계를 계산했을 때의 비율을 분포이론으로 설명하는데 쓰일 수 있을지도 모른다. 특히 감마분포는 여러가지 확률분포를 비교적 자유롭게 넘나들 수 있으므로 팩트로써는 알아두는 게 좋다. Strategy** : 감마 분</description>
    </item>
    
    <item>
      <title>감마 분포</title>
      <link>https://freshrimpsushi.github.io/posts/gamma-distribution/</link>
      <pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gamma-distribution/</guid>
      <description>$k, \theta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\Gamma ( k , \theta )$ 를 감마 분포 라고 한다. $$ f(x) = {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x^{k - 1} e^{ - x / \theta} \qquad , x &amp;gt; 0 $$ * $\Gamma$ 는 감마 함수를 나타낸다. * 감마 분포의 확률 밀도 함수는 $\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같이 정의되기도 한다. 본질적으로는 $\theta = {{ 1 } \over { \beta }}$ 냐의 차이 뿐이다. $$ f(x) = {{ \beta^{\alpha } } \over</description>
    </item>
    
    <item>
      <title>기하 분포의 무기억성</title>
      <link>https://freshrimpsushi.github.io/posts/memoryless-property-of-geometric-distribution/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/memoryless-property-of-geometric-distribution/</guid>
      <description>지수 분포의 무기억성 $X \sim \text{Geo} ( m )$ 이면 $P(X \ge s+ t ,|, X \ge s) = P(X \ge t)$ 기하 분포는 어떤 사건이 일어나는 횟수에 관심을 두는 이산확률분포다. 지수 분포의 이산화라는 센스에서 생각해보면 이러한 기하분포의 무기억성은 당연하다고 할 수 있겠다.여기서 무기억성 이란 지나온 시간에 의해 앞으로 일어날 일이 영향을 받지 않는 성질이다. 예를 들어 30대의 남성이</description>
    </item>
    
    <item>
      <title>지수 분포의 무기억성</title>
      <link>https://freshrimpsushi.github.io/posts/memoryless-property-of-exponential-distribution/</link>
      <pubDate>Tue, 24 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/memoryless-property-of-exponential-distribution/</guid>
      <description>기하 분포의 무기억성 $X \sim \exp{ ( \lambda ) }$ 이면 $P(X \ge s+ t ,|, X \ge s) = P(X \ge t)$ 지수 분포는 어떤 사건이 일어나는 기간에 관심을 두는 연속확률분포다. 깊게 생각하지 않아도 수명예측이나 보험 등에 응용될 수 있음을 짐작할 수 있다.여기서 무기억성 이란 지나온 시간에 의해 앞으로 일어날 일이 영향을 받지 않는 성질이다. 예를 들어 30대의 남성이나 50대의 남성이 건</description>
    </item>
    
    <item>
      <title>지수 분포와 푸아송 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-exponential-and-poisson/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-exponential-and-poisson/</guid>
      <description>푸아송 프로세스 사건이 일어날 때 걸리는 시간 $X_{k}$ 에 대해 $X_{k} \sim \exp (\lambda) $ 이면 단위시간 당 발생하는 사건의 횟수 $N$ 에 대해 $\displaystyle N \sim \text{Poi} (\lambda)$ 지수 분포와 푸아송 분포의 직관적인 정의를 생각해보자. 지수분포는 어떤 사건이 발생하기까지 걸리는 시간에 관심이 있고, 푸아송분포는 단위 시간 내에 어떤 사건이 몇 번 발생하는지 관심이 있다. 어떤 사건이 일어나는 시간과 사건이</description>
    </item>
    
    <item>
      <title>지수 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-exponential-distribution/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-exponential-distribution/</guid>
      <description>$X \sim \exp ( \lambda)$ 면 $$ E(X) = {{ 1 } \over { \lambda }} \\ \text{Var} (X) = {{ 1 } \over { \lambda^{2} }} $$ Strategy** : 지수 분포의 정의에서 직접 연역한다. 지수 분포의 정의$\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\exp ( \lambda)$ 를 지수 분포 라고 한다. $$ f(x) = \lambda e^{-\lambda x} \qquad , x \ge 0 $$ 증명(평균) $$ \displaystyle E(X)=\int _{ 0 }^{ \infty }{ x\cdot \lambda { e } ^{ -\lambda x } }dx $$ $\lambda x=t$ 이라고 두면 $\lambda dx=dt$ 이므로 $$</description>
    </item>
    
    <item>
      <title>지수 분포</title>
      <link>https://freshrimpsushi.github.io/posts/exponential-distribution/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/exponential-distribution/</guid>
      <description>$\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\exp ( \lambda)$ 를 지수 분포 라고 한다. $$ f(x) = \lambda e^{-\lambda x} \qquad , x \ge 0 $$ * 모수는 책에 따라서 그 역수인 $\displaystyle \theta = {{ 1 } \over { \lambda }}$ 을 쓰기도 한다. [1] 적률 생성 함수 : $$ m(t) = {{ \lambda } \over { \lambda - t }} \qquad , t &amp;lt; \lambda $$ [2] 평균과 분산 : $X \sim \exp ( \lambda)$ 면 $$ E(X) = {{ 1 } \over { \lambda }} \\ \text{Var} (X) = {{ 1 } \over { \lambda^{2} }} $$ [a] 무기억성 : $X</description>
    </item>
    
    <item>
      <title>푸아송 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-poisson-distribution/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-poisson-distribution/</guid>
      <description>$**X \sim \text{Poi}(\lambda)$ 면 $$ E(X) = \lambda \\ \text{Var}(X) = \lambda $$ Strategy : 푸아송 분포의 정의에서 직접 연역한다. 팩토리얼과 급수를 쪼개는 트릭이 중요하다. 푸아송 분포의 정의$\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Poi} ( \lambda )$ 를 푸아송 분포라고 한다. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over { x! }} \qquad , x = 0 , 1 , 2, \cdots $$ 증명(평균) $$ \displaystyle \begin{eqnarray*} E(X) &amp;amp;=&amp;amp; \sum _{ x=0 }^{ \infty }{ x\frac { {</description>
    </item>
    
    <item>
      <title>푸아송 분포</title>
      <link>https://freshrimpsushi.github.io/posts/poisson-distribution/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/poisson-distribution/</guid>
      <description>$\lambda &amp;gt; 0$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Poi} ( \lambda )$ 를 푸아송 분포 라고 한다. $$ p(x) = {{ e^{-\lambda} \lambda^{x} } \over { x! }} \qquad , x = 0 , 1 , 2, \cdots $$ [1] 적률 생성 함수 : $$ m(t) = \exp \left[ \lambda \left( e^{t} - 1 \right) \right] \qquad , t \in \mathbb{R} $$ [2] 평균과 분산 : $X \sim \text{Poi}(\lambda)$ 면 $$ E(X) = \lambda \\ \text{Var}(X) = \lambda $$ [a] 이항분포의 극한분포로써 푸아송분포 유도: $X_{n} \sim B(n,p)$이라고 하자. $\mu \approx np$ 이면</description>
    </item>
    
    <item>
      <title>음이항 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-negative-binomial-distribution/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-negative-binomial-distribution/</guid>
      <description>$X \sim \text{NB}(r, p)$ 면 $$ E(X) = {{ r (1-p) } \over { p }} \\ \text{Var}(X) = {{ r (1-p) } \over { p^{2} }} $$ Strategy : 음이항 분포가 기하 분포의 일반화라는 점을 이용한다. [b] 기하분포의 일반화 : $Y = X_{1} + \cdots + X_{r}$ 이고 $X_{i} \overset{\text{iid}}{\sim} \text{Geo}(p)$ 면 $Y \sim \text{NB}(r,p)$ 이 때 기하 분포의 정의는 음이항 분포와 마찬가지로 그 서포트가 $\mathcal{S} = \left\{ 0 , 1 , 2, \cdots \right\}$ 와 같이 되도록 둔다. 기하 분포의 평균과 분산 : $X \sim \text{Geo} (p)$ 면 $$ E(X) = {{ 1-p } \over { p }}</description>
    </item>
    
    <item>
      <title>음이항 분포</title>
      <link>https://freshrimpsushi.github.io/posts/negative-binomial-distribution/</link>
      <pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/negative-binomial-distribution/</guid>
      <description>$r \in \mathbb{N}$ 와 $p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{NB}(r,p)$ 를 음이항 분포 라고 한다. $$ p(x) = \binom{r+x-1}{x-1} p^{r}(1-p)^{x} \qquad, x = 0,1,2,\cdots $$ [1] 적률 생성 함수 : $$ m(t) = \left[ {{ p } \over { 1 - (1-p) e^{t} }} \right]^{r} \qquad , t &amp;lt; -\log (1-P) $$ [2] 평균과 분산 : $X \sim \text{NB}(r, p)$ 면 $$ E(X) = {{ r (1-p) } \over { p }} \\ \text{Var}(X) = {{ r (1-p) } \over { p^{2} }} $$ 음이항 분포는 일어날 확률이 $p$ 인 어떤 사건이 $r$ 번 일어날 때까지의 횟수에 관</description>
    </item>
    
    <item>
      <title>기하 분포의 두가지 정의가 가지는 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/295/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/295/</guid>
      <description>기하 분포에 대해 공부하면서 가장 당황스럽고 헷갈리는 것이 교재, 블로그, 위키마다 설명이 다르다는 것이다. 어떤 곳에서는 평균이 $\displaystyle {{1} \over {p}} $ 인데 다른 곳은 $\displaystyle {{1-p} \over {p}} $ 로 쓰기도 한다.이러한 차이는 기하분포를 정의하는 방법이 두가지가 있기 때문이다. 기하분포 $\text{Geo}(p)$ 의 확률질량함수는 $$ p_{1}(x) = p(1-p)^{x-1} , x= 1,2,3,\cdots $$ 혹은 $$ p_{2}(x) = p(1-p)^{x} , x= 0,1,2,\cdots $$ 으로 정의된다. 기댓값은</description>
    </item>
    
    <item>
      <title>기하 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-geometric-distribution/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-geometric-distribution/</guid>
      <description>$X \sim \text{Geo} (p)$ 면 $$ E(X) = {{ 1 } \over { p }} \\ \text{Var}(X) = {{ 1-p } \over { p^{2} }} $$ 기하 분포의 평균과 분산은 생각보다 쉽게 구해지지 않는다. 본 포스트에서는 유익하면서도 재미있는 두가지 증명을 소개한다. Strategy1** : 등비 급수의 공식과 미분을 사용한다. 기하 분포의 정의$p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Geo}(p)$ 를 기하 분포 라고 한다. $$ p(x) = p (1 - p)^{x-1}</description>
    </item>
    
    <item>
      <title>기하 분포</title>
      <link>https://freshrimpsushi.github.io/posts/geometric-distribution/</link>
      <pubDate>Sun, 16 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/geometric-distribution/</guid>
      <description>$p \in (0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Geo}(p)$ 를 기하 분포라고 한다. $$ p(x) = p (1 - p)^{x-1} \qquad , x = 1 , 2, 3, \cdots $$ 두가지 정의가 쓰이고 있으니 수식과 정의역에 특히 주의해야한다. [1] 적률 생성 함수 : $$ m(t) = {{ p e^{t} } \over { 1 - (1-p) e^{t} }} \qquad , t &amp;lt; -\log (1-p) $$ [2] 평균과 분산 : $X \sim \text{Geo} (p)$ 면 $$ E(X) = {{ 1 } \over { p }} \\ \text{Var}(X) = {{ 1-p } \over { p^{2} }} $$ [a] 무기억성</description>
    </item>
    
    <item>
      <title>이항 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-binomial-distribution/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-binomial-distribution/</guid>
      <description>$ \displaystyle X \sim \text{Bin} (n,p) $ 면 $$ E(X)=np \\ \text{Var}(X)=npq $$ 여기서 $q : = 1-p$ 다.전략 : 조합을 직접 풀어헤친다. 식이 다소 더럽긴 하지만 고등학교 과정에서 충분히 소화할 수 있다. 한번쯤은 직접 해보도록 하자. 수리통계학을 접하면 조금 더 짧고 간단한 방법으로 증명할 수 있게 된다. 평균이든 분산이든 다음과 같은 이항 분포의 확률 질량 함수에서 시작한다. 이항 분포의 정의$n \in \mathbb{N}$ 과</description>
    </item>
    
    <item>
      <title>이항 분포</title>
      <link>https://freshrimpsushi.github.io/posts/binomial-distribution/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/binomial-distribution/</guid>
      <description>$n \in \mathbb{N}$ 과 $p \in [0,1]$ 에 대해 다음과 같은 확률 질량 함수를 가지는 이산 확률 분포 $\text{Bin}(n,p)$ 를 이항 분포 라고 한다. $$ p(x) = \binom{n}{x} p^{x} (1-p)^{n-x} \qquad , x = 0 , 1, \cdots n $$ [1] 적률 생성 함수 : $$ m(t) = \left[ (1-p) + pe^{t} \right]^{n} \qquad , t \in \mathbb{R} $$ [2] 평균과 분산 : $X \sim \text{Bin}(n,p)$ 면 $$ E(X) = np \\ \text{Var}(X) = np(1-p) $$ [a] 이항분포의 극한분포로써 푸아송분포 유도: $X_{n} \sim B(n,p)$이라고 하자. $\mu \approx np$ 이면 $$ X_{n} \overset{D}{\to} \text{Poi} (\mu) $$ [b] 이항분</description>
    </item>
    
    <item>
      <title>일양 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-uniform-distribution/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-uniform-distribution/</guid>
      <description>공식 $X \sim U[a,b]$ 면 $$ E(X) = {{ a+b } \over { 2 }} \\ \text{Var}(X) = {{ (b-a)^{2} } \over { 12 }} $$ Strategy : 일양 분포의 정의에서 직접 연역한다. 일양 분포의 정의 $[a,b] \subset \mathbb{R}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포]] $U[a,b]$ 를 일양 분포 라 한다. $$ f(x) = {{ 1 } \over { b - a }} \qquad , x \in [a,b] $$ 증명(평균) $$ \begin{eqnarray*} E(X) &amp;amp;=&amp;amp; \int_{a}^{b} x {{ 1 } \over { b-a }} dx \\ &amp;amp;=&amp;amp; {{ 1 } \over { b-a }} \left[ {{ x^{2} } \over { 2 }} \right]_{a}^{b} \\ &amp;amp;=&amp;amp; {{</description>
    </item>
    
    <item>
      <title>일양 분포</title>
      <link>https://freshrimpsushi.github.io/posts/uniform-distribution/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniform-distribution/</guid>
      <description>정의 $[a,b] \subset \mathbb{R}$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $U(a,b)$ 를 일양 분포 라 한다. $$ f(x) = {{ 1 } \over { b - a }} \qquad , x \in [a,b] $$ 흔히 일양 분포는 균등 분포 로 불리기도 한다. 위의 정의는 연속인 경우고, 이산 일양 분포 역시 모든 케이스에 대해 같은 확률을 줌으로써 정의할 수 있다. 일양 분포가 중요한 이유는 따로 있다기보단 우리가 생각할 수 있는 가장 단</description>
    </item>
    
    <item>
      <title>감마 분포와 지수 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-exponential/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-exponential/</guid>
      <description>$$ \displaystyle \Gamma \left(1, { 1 \over \lambda } \right) \iff \text{exp} (\lambda) $$ 지수 분포의 직관적인 정의를 생각해보면 어떤 사건이 일어날때까지 걸리는 시간에 관심이 있는 것이다. 이산 확률 분포로 따지자면 기하 분포가 이에 해당한다.이때 기하 분포를 사건의 &amp;lsquo;발생 횟수&amp;rsquo;에 대해 일반화한 것이 음이항 분포다. 이런 센스에서, 지수 분포를 일반화한 것은 감마 분포라고 할 수</description>
    </item>
    
    <item>
      <title>감마 분포와 카이제곱 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-chi-squared/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-chi-squared/</guid>
      <description>$$ \displaystyle \Gamma \left( { r \over 2 } , 2 \right) \iff \chi ^2 (r) $$ 감마 분포와 카이제곱 분포는 위와 같은 성질을 가진다. Strategy** : 두 분포의 적률생성함수가 같은 형태로 나타날 수 있음을 보인다. 증명 카이제곱분포 $\chi ^2 (r)$ 의 적률생성함수는 $ \displaystyle m_{1}(t) = (1- 2t)^{- {r \over 2} }$ 이고 감마분포 $\Gamma(k, \theta)$ 의 적률생성함수는 $m_{2}(t) = (1-\theta t)^{-k}$ 이다. 감마분포의 적률생성함수에 $\displaystyle k = {r \over 2}$ 과 $\theta = 2 $ 을 대입하면 $$</description>
    </item>
    
    <item>
      <title>감마 분포와 푸아송 분포의 관계</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-poisson/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-gamma-and-poisson/</guid>
      <description>모든 자연수 $k$ 에 대해 $$ \displaystyle \int_{\mu}^{\infty} { { z^{k-1} e^{-z} } \over { \Gamma (k) } } dz = \sum_{x=0}^{k-1} { { {\mu}^{x} e^{-\mu} } \over {x!} } $$ 이 등식은 감마 분포와 푸아송 분포의 누적 확률 분포 함수가 서로 관련이 있음을 보여준다. 이는 감마 분포가 지수 분포와의 관계를 가진다는 점에서 충분히 그럴법하다고 말할 수 있다. 증명 $k=1$ 일 때 $$ \displaystyle \int_{\mu}^{\infty} { { z^{0} e^{-z} } \over { \Gamma (0) } } dz = e^{-\mu} = \sum_{x=0}^{0} { { {\mu}^{x} e^{-\mu} } \over {x!} } $$ $k=N$일 때</description>
    </item>
    
    <item>
      <title>감마 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-gamma-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-gamma-distribution/</guid>
      <description>$X \sim \Gamma ( \alpha , \beta )$ 면 $$ E(X) = k \theta \\ \text{Var} (X) = k \theta^{2} $$ Strategy** : 감마 분포의 정의와 감마 함수의 기본적인 성질로 직접 연역한다. $x$ 의 차수가 변하는만큼 계수의 분자 분모를 맞춰주는 트릭을 쓴다. 감마 분포의 정의$k, \theta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\Gamma ( k , \theta )$ 를 감마 분포 라고 한다. $$ f(x) = {{ 1 } \over { \Gamma ( k ) \theta^{k} }} x^{k - 1} e^{ -</description>
    </item>
    
    <item>
      <title>독립인 두 카이제곱 분포에서 F-분포 유도</title>
      <link>https://freshrimpsushi.github.io/posts/1643/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/1643/</guid>
      <description>두 확률 변수 $U,V$ 가 독립이고 $U \sim \chi^{2} ( r_{1})$, $V \sim \chi^{2} ( r_{2})$ 이라 하면 $$ {{ U / r_{1} } \over { V / r_{2} }} \sim F \left( r_{1} , r_{2} \right) $$ 두 데이터가 카이제곱 분포를 따르고 독립이라면, 그 비를 분포이론으로 설명할 수 있을지도 모른다.통계학 전반에서는 표준화된 잔차의 제곱이 카이제곱 분포를 따르는 것으로 가정하기 때문에 이 점에 따라 F-검정등을 즐겨쓴다. 증명 자체가 중요한 것</description>
    </item>
    
    <item>
      <title>베타 분포</title>
      <link>https://freshrimpsushi.github.io/posts/beta-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/beta-distribution/</guid>
      <description>$\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\text{Beta}(\alpha,\beta)$ 를 베타 분포 라고 한다. $$ f(x) = {{ 1 } \over { B(\alpha,\beta) }} x^{\alpha - 1} (1-x)^{\beta - 1} \qquad , x \in [0,1] $$ * $B$ 는 베타 함수를 나타낸다. [1] 적률 생성 함수 : $$ m(t) = 1 + \sum_{k=1}^{\infty} \left( \prod_{r=0}^{k-1} {{ \alpha + r } \over { \alpha + \beta + r }} {{ t^{k} } \over { k! }} \right) \qquad , t \in \mathbb{R} $$ [2] 평균과 분산 : $X \sim \text{Beta}(\alpha,\beta)$ 면 $$ E(X)={\alpha \over {\alpha + \beta} } \\ \text{Var} (X)={ { \alpha \beta } \over {(\alpha + \beta + 1) {</description>
    </item>
    
    <item>
      <title>베타 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-beta-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-beta-distribution/</guid>
      <description>$X \sim \text{Beta}(\alpha,\beta)$ 면 $$ E(X)={\alpha \over {\alpha + \beta} } \\ \text{Var} (X)={ { \alpha \beta } \over {(\alpha + \beta + 1) { ( \alpha + \beta ) }^2 } } $$ Strategy** : 베타 분포의 정의와 감마 함수의 기본적인 성질로 직접 연역한다. 베타 분포의 정의$\alpha , \beta &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\text{Beta}(\alpha,\beta)$ 를 베타 분포라고 한다. $$ f(x) = { \Gamma(\alpha + \beta) \over { \Gamma(\alpha) \Gamma(\beta) } } x^{\alpha - 1} (1-x)^{\beta - 1} \qquad , x \in [0,1] $$ 감마 함수의 재귀 공식</description>
    </item>
    
    <item>
      <title>정규분포</title>
      <link>https://freshrimpsushi.github.io/posts/normal-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normal-distribution/</guid>
      <description>$\mu \in \mathbb{R}$ 과 $\sigma &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $N \left( \mu,\sigma^{2} \right)$ 를 정규 분포 라고 한다. $$ f(x) = {{ 1 } \over { \sqrt{2 \pi} \sigma }} \exp \left[ - {{ 1 } \over { 2 }} \left( {{ x - \mu } \over { \sigma }} \right)^{2} \right] \qquad, x \in \mathbb{R} $$ 특히 다음과 같은 확률 밀도를 함수를 가지는 정규분포 $N \left( 0,1^{2} \right)$ 를 표준정규분포 라고 한다. $$ f(z) = {{ 1 } \over { \sqrt{2 \pi} }} \exp \left[ - {{ z^{2} } \over { 2 }} \right] $$ 정규분포의</description>
    </item>
    
    <item>
      <title>카이제곱 분포</title>
      <link>https://freshrimpsushi.github.io/posts/chi-square-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chi-square-distribution/</guid>
      <description>자유도 $r &amp;gt; 0$ 에 대해 다음과 같은 확률 밀도 함수를 가지는 연속 확률 분포 $\chi^{2} (r)$ 를 카이제곱 분포 라고 한다. $$ f(x) = {{ 1 } \over { \Gamma(r/2) 2^{r/2} }} x^{r/2-1} e^{-x/2} \qquad , x \in (0, \infty) $$ [1] 적률 생성 함수 : $$ m(t) = (1-2t)^{-r/2} \qquad , t &amp;lt; {{ 1 } \over { 2 }} $$ [2] 평균과 분산 : $X \sim \chi^{2} (r)$ 이면 $$ E(X) = r \\ \text{Var} (X) = 2r $$ [a] $k$차 적률 : $X \sim \chi^{2} (r)$ 이라고 하자. $k &amp;gt; - r/ 2$ 이면 $k$차 적률이 존재하고 $$ E X^{k}</description>
    </item>
    
    <item>
      <title>카이제곱 분포의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-chi-square-distribution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-chi-square-distribution/</guid>
      <description>$X \sim \chi^{2} (r)$ 이면 $$ E(X) = r \\ \text{Var} (X) = 2r $$ Strategy** : 카이제곱분포는 고맙게도 적률 공식이 알려져있다. 카이제곱 분포의 적률$X \sim \chi^{2} (r)$ 이라고 하자. $k &amp;gt; - r/ 2$ 이면 $k$차 적률이 존재하고 $$ E X^{k} = {{ 2^{k} \Gamma (r/2 + k) } \over { \Gamma (r/2) }} $$ 증명(평균) $$ EX^{1} = {{ 2^{1} \Gamma (r/2 + 1) } \over { \Gamma (r/2) }} = 2 \cdot {{ r } \over { 2 }} = r $$ ■ 증명(분산) $$ EX^{2} = {{ 2^{2} \Gamma (r/2 + 2) } \over { \Gamma (r/2)</description>
    </item>
    
    <item>
      <title>특정한 분포를 따르는 확률변수들의 덧셈 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/202/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/202/</guid>
      <description>확률 변수 $X_{1} , \cdots , X_{n}$ 들이 상호 독립이라고 하자.[1] 이항 분포 : $X_i \sim \text{Bin} ( n_{i}, p)$ 이면 $$ \displaystyle \sum_{i=1}^{m} X_{i} \sim \text{Bin} \left( \sum_{i=1}^{m} n_{i} , p \right) $$ [2] 푸아송 분포 : $X_i \sim \text{Poi}( m_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \text{Poi} \left( \sum_{i=1}^{n} m_{i} \right) $$ [3] 감마 분포 : $X_i \sim \Gamma( k_{i}, \theta)$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \Gamma \left( \sum_{i=1}^{n} k_{i} , \theta \right) $$ [4] 카이제곱 분포 : $X_i \sim \chi^2 ( r_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \chi ^2 \left( \sum_{i=1}^{n} r_{i} \right) $$ [5] 정규 분포 : $X_i \sim N( \mu_{i}, \sigma_{i}^{2} )$ 이면 주어진 벡터 $(a_{1} ,</description>
    </item>
    
  </channel>
</rss>
