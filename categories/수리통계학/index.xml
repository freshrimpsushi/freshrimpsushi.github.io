<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>수리통계학 on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/categories/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99/</link>
    <description>Recent content in 수리통계학 on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Thu, 04 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/categories/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>라오-블랙웰 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rao-blackwell-theorem/</link>
      <pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rao-blackwell-theorem/</guid>
      <description>정리 1 2 모수 $\theta$ 가 주어져 있다고 하자. $T$ 가 $\theta$ 의 충분통계량이고 $W$ 가 $\tau \left( \theta \right)$ 의 불편추정량이라고 할 때 $\phi \left( T \right) := E \left( W | T \right)$ 를 정의하면 모든 $\theta$ 에 대해 다음이 성립한다. $$ \begin{align*} E_{\theta} \phi (T) =&amp;amp; \tau (\theta) \\ \text{Var}_{\theta} \phi (T) \le&amp;amp; \text{Var}_{\theta} W \end{align*} $$ 다시 말해, $\phi (T)$ 는 $\tau (\theta)$ 에 대해 $W$ 보다 더 나은 불편추정량Uniformly Better Unbiased Estimator이다. 설명 라오-블랙웰 정리를</description>
    </item>
    
    <item>
      <title>네이만 인수분해 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-neyman-factorization-theorem/</link>
      <pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-neyman-factorization-theorem/</guid>
      <description>정리 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 이 모수 $\theta \in \Omega$ 에 대해 같은 확률질량/밀도함수 $f \left( x ; \theta \right)$ 를 가진다고 하자. 통계량 $Y = u_{1} \left( X_{1} , \cdots , X_{n} \right)$ 이 $\theta$ 의 충분통계량인 것은 다음을 만족하는 음이 아닌 두 함수 $k_{1} , k_{2} \ge 0$ 이 존재하는 것이다. $$ f \left( x_{1} ; \theta \right) \cdots f \left( x_{n} ; \theta \right) = k_{1} \left[ u_{1} \left( x_{1} , \cdots , x_{n} \right) ; \theta \right] k_{2} \left( x_{1} , \cdots , x_{n} \right) $$ 단, $k_{2}$ 는 $\theta$ 에 종속되지 않아야한다.</description>
    </item>
    
    <item>
      <title>충분통계량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistic/</link>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistic/</guid>
      <description>정의 수식적인 정의 1 모수 $\theta \in \Omega$ 에 대해 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 의 확률질량/밀도함수를 $f(x;\theta)$, 통계량 $Y_{1} := u_{1} \left( X_{1} , \cdots , X_{n} \right)$ 의 확률질량/밀도함수를 $f_{Y_{1}} \left( y_{1}; \theta \right)$ 이라 하자. $\theta \in \Omega$ 에 종속되지 않은 $H \left( x_{1} , \cdots , x_{n} \right)$ 에 대해 $$ {{ f \left( x_{1} ; \theta \right) \cdots f \left( x_{n} ; \theta \right) } \over { f_{Y_{1}} \left( u_{1} \left( x_{1} , \cdots, x_{n} \right) ; \theta \right) }} = H \left( x_{1} , \cdots , x_{n} \right) $$ 이면 $Y_{1}$ 을 $\theta$ 에 대한 충분통계량Suf</description>
    </item>
    
    <item>
      <title>효율적추정량</title>
      <link>https://freshrimpsushi.github.io/posts/efficient-estimator/</link>
      <pubDate>Sat, 31 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/efficient-estimator/</guid>
      <description>정의 1 $Y$ 가 모수 $\theta$ 에 대한 불편추정량이라고 하자. 라오-크래머 하한 $\text{RC}$ 에 대해 다음을 추정량 $Y$ 의 효율성Efficiency이라고 한다. $$ {{ \text{RC} } \over { \text{Var} (Y) }} $$ 효율성이 $1$ 인 추정량을 효율적추정량Efficient Estimator이라고 한다. 설명 라오-크래머 부등식: $$ \text{Var} (Y) \ge {{ \left[ k&#39;(\theta) \right]^{2} } \over { n I (\theta) }} = \text{RC} $$ 위 부등식에 따라 효율</description>
    </item>
    
    <item>
      <title>라오-크래머 하한</title>
      <link>https://freshrimpsushi.github.io/posts/rao-cramer-lower-bound/</link>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rao-cramer-lower-bound/</guid>
      <description>정리 1 정칙조건: (R0): 확률밀도함수 $f$ 는 $\theta$ 에 대해 단사다. 수식으로는 다음을 만족시킨다. $$ \theta \ne \theta&#39; \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta&#39; \right) $$ (R1): 확률밀도함수 $f$ 는 모든 $\theta$ 에 대해 같은 서포트를 가진다. (R2): 참값 $\theta_{0}$ 는 $\Omega$ 의 내점Interior Point이다. (R3): 확률밀도함수 $f$ 는 $\theta$ 에 대해 두 번 미분가능하다. (R4): 적분 $\int f (x; \theta) dx$ 은 적분 기호를 넘나들며 $\theta$ 에</description>
    </item>
    
    <item>
      <title>바틀렛 항등식</title>
      <link>https://freshrimpsushi.github.io/posts/bartlett-identity/</link>
      <pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bartlett-identity/</guid>
      <description>정리 정칙조건: (R0): 확률밀도함수 $f$ 는 $\theta$ 에 대해 단사다. 수식으로는 다음을 만족시킨다. $$ \theta \ne \theta&#39; \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta&#39; \right) $$ (R1): 확률밀도함수 $f$ 는 모든 $\theta$ 에 대해 같은 서포트를 가진다. (R2): 참값 $\theta_{0}$ 는 $\Omega$ 의 내점Interior Point이다. (R3): 확률밀도함수 $f$ 는 $\theta$ 에 대해 두 번 미분가능하다. (R4): 적분 $\int f (x; \theta) dx$ 은 적분 기호를 넘나들며 $\theta$ 에 대</description>
    </item>
    
    <item>
      <title>피셔 정보</title>
      <link>https://freshrimpsushi.github.io/posts/fisher-information/</link>
      <pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fisher-information/</guid>
      <description>빌드업 스코어 함수 모수 $\theta \in \Omega$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. 로그우도함수가 가장 커지는 추정량인 최대우도추정량은 다음과 같은 편미분방정식을 만족하는 $\widehat{\theta}$ 으로 구할 수 있었다. $$ \sum_{k=1}^{n} {{ \partial \log f \left( x_{k} ; \theta \right) } \over { \partial \theta }} $$ 여기서 $\displaystyle {{ \partial \log f ( x ; \theta ) } \over { \partial \theta }}$ 를 스코어 함수Score Function이라</description>
    </item>
    
    <item>
      <title>수리통계학에서의 정칙성 조건</title>
      <link>https://freshrimpsushi.github.io/posts/regularity-conditions-in-mathematical-statistics/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regularity-conditions-in-mathematical-statistics/</guid>
      <description>개요 수학을 사용하는 과목에서 대개 정칙성Regularity Conditions이란 대개 응용될 구석이 많으면서 이론적인 전개가 편해지는 조건들을 말하며, 수리통계학에서는 다음과 같다. 가정 1 모수 $\theta \in \Omega$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. $X$ 와 같은 분포로 iid하게 뽑은 랜덤샘플 $X_{1} , \cdots , X_{n}$ 는 같은 확률</description>
    </item>
    
    <item>
      <title>최대우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/maximum-likelihood-estimator/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maximum-likelihood-estimator/</guid>
      <description>빌드업 모수 $\theta \in \Omega$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. $X$ 와 같은 분포로 iid하게 뽑은 랜덤샘플 $X_{1} , \cdots , X_{n}$ 는 같은 확률밀도함수 $f(x ; \theta)$ 와 실현 $\mathbf{x} := \left( x_{1} , \cdots , x_{n} \right)$ 을 가진다. 이에 대해 다음과 같은 함수 $L$ 을 우도함수Likelihood Function라 한다. $$ L ( \theta ; \mathbf{x} ) := \prod_{k=1}^{n} f \left( x_{k} ; \theta \right) $$ 아래에서 나오</description>
    </item>
    
    <item>
      <title>일치추정량</title>
      <link>https://freshrimpsushi.github.io/posts/consistent-estimator/</link>
      <pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/consistent-estimator/</guid>
      <description>정의 1 확률변수 $X$ 가 누적분포함수 $F ( x ; \theta), \theta \in \Omega$ 를 가진다고 하자. $X_{1} , \cdots , X_{n}$ 을 $X$ 에서 뽑은 샘플이라고 할 때, 통계량 $T_{n}$ 이 다음을 만족하면 모수 $\theta$ 에 대한 일치추정량Consistent Estimator이라 한다. $$ T_{n} \overset{P}{\to} \theta $$ $\overset{P}{\to}$ 는 확률수렴이다. 예시 $X_{1} , \cdots , X_{n}$ 가 확률분포 $\left( \mu, \sigma^{2} \right)$ 를 따르는 랜덤 샘플, 즉 $X_{1} , \cdots , X_{n} \sim \left( \mu, \sigma^{2} \right)$ 이고 첨</description>
    </item>
    
    <item>
      <title>스튜던트의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-students-theorem/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-students-theorem/</guid>
      <description>정리 1 확률 변수 $X_{1} , \cdots , X_{n}$ 들이 iid로 정규분포 $N\left( \mu,\sigma^{2} \right)$ 를 따른다고 하면 (a): $$ \overline{X} \sim N\left( \mu , { {\sigma^2} \over {n} } \right) $$ (b): $$ \overline{X} \perp S^2 $$ (c): $$ (n-1) { {S^2} \over {\sigma^2} } \sim \chi^2 (n-1) $$ (d): $$ T = { {\overline{X} - \mu } \over {S / \sqrt{n}} } \sim t(n-1) $$ 표뵨 평균 $\overline{X}$ 과 표본 분산 $S^{2}$ 는 다음과 같이 정의된 확률 변수다. $$ \overline{X} := {{ 1 } \over { n }} \sum_{k=1}^{n} X_{k} \\ S^{2} := {{ 1 } \over { n-1 }} \sum_{k=1}^{n} \left( X_{k} - \overline{X} \right)^{2} $$ 설명 통계학을 하는 사람들은 당연</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution-of-random-vector/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution-of-random-vector/</guid>
      <description>정의1 $p$차원 랜덤 벡터 $\mathbf{X}$ 와 랜덤 벡터의 시퀀스 $\left\{ \mathbf{X}_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $\mathbf{X}_{n}$ 이 $\mathbf{X}$ 로 분포 수렴한다고 말하고, $\mathbf{X}_{n} \overset{D}{\to} \mathbf{X}$ 와 같이 나타낸다. $$\lim_{n \to \infty} F_{\mathbf{X}_{n}} (x) = F_{\mathbf{X}} (x) \qquad, \forall x \in C_{F_{\mathbf{X}}}$$ $F_{X}$ 는 확률변수 $X$ 의 누적분포함수다. $C_{F_{\mathbf{X}}}$ 는 함수 $F_{\mathbf{X}}$ 가 연속인 점들의 집합을 나타낸다. 다변량 중심 극한 정리 $\left\{ \mathbf{X}_{n} \right\}$ 가 평균 벡터 $\mathbf{\mu} \in \mathbb{R}^{p}$ 와 공분산 행렬 $\Sigma \in \mathbb{R}^{p \times p}$ 를 가지고 ii</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability-of-random-vector/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability-of-random-vector/</guid>
      <description>정의 1 $p$차원 랜덤 벡터 $\mathbf{X}$ 와 랜덤 벡터의 시퀀스 $\left\{ \mathbf{X}_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $\mathbf{X}_{n}$ 이 $\mathbf{X}$ 로 확률 수렴Convergence in Probability한다고 말하고, $\mathbf{X} _ {n} \overset{P}{\to} \mathbf{X}$ 와 같이 나타낸다. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left\| \mathbf{X}_{n} - \mathbf{X} \right\| &amp;lt; \varepsilon \right] = 1 $$ $\| \cdot \|$ 는 유클리드 놈으로써, $\left\| \left( x_{1} , \cdots , x_{n} \right) \right\| = \sqrt{ x_{1}^{2} + \cdots + x_{n}^{2}}$ 와 같이 정의된다. 정리</description>
    </item>
    
    <item>
      <title>공분산 행렬</title>
      <link>https://freshrimpsushi.github.io/posts/covariance-matrix/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/covariance-matrix/</guid>
      <description>정의1 $p$차원 랜덤 벡터 $\mathbf{X} = \left( X_{1}, \cdots , X_{p} \right)$ 에 대해 다음과 같이 정의된 $\text{Cov} (\mathbf{X})$ 를 공분산 행렬Covariance Matrix이라 한다. $$ \left( \text{Cov} \left( \mathbf{X} \right) \right)_{ij} := \text{Cov} \left( X_{i} , X_{j} \right) $$ $\text{Cov}$ 는 공분산이다. 설명 정의를 더 쉽게 풀어 적어보면 다음과 같다. $$ \text{Cov} \left( \mathbf{X} \right) := \begin{pmatrix} \text{Var} \left( X_{1} \right) &amp;amp; \text{Cov} \left( X_{1} , X_{2} \right) &amp;amp; \cdots &amp;amp; \text{Cov} \left( X_{1} , X_{p} \right) \\ \text{Cov} \left( X_{2} , X_{1} \right) &amp;amp; \text{Var} \left( X_{2} \right) &amp;amp; \cdots &amp;amp; \text{Cov} \left( X_{2} , X_{p}</description>
    </item>
    
    <item>
      <title>중심극한 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-central-limit-theorem/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-central-limit-theorem/</guid>
      <description>정리 1 ${X_n}$가 iid 확률 변수들이고 확률분포 $\left( \mu, \sigma^2 \right) $를 따른다고 하면 $n \to \infty$ 일 때 $$ \displaystyle \sqrt{n} {{ \overline{X}_n - \mu } \over {\sigma}} \overset{D}{\to} \text{N} (0,1) $$ $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 통계학에선 대수의 법칙과 더불어 정말 그 명성이 자자한 정리로 꼽힌다. 수없이 듣고 쓰는 정리지만 막상 증명은 수리통계학을 배우면서 한번 해볼까말까다. 하지만 실제로는 활용도를 떠나 증명 자체</description>
    </item>
    
    <item>
      <title>약한 대수의 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-weak-law-of-large-numbers/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-weak-law-of-large-numbers/</guid>
      <description>법칙 ${X_n}$가 iid 확률 변수들이고 확률분포 $\left( \mu, \sigma^2 \right) $를 따른다고 하면 $n \to \infty$ 일 때 $$ \overline{X}_n \overset{P}{\to} \mu $$ $\overset{P}{\to}$ 는확률 수렴을 의미한다. 설명 이 정리는 그 어떤 분포든 &amp;lsquo;표본평균은 모평균으로 수렴한다&amp;rsquo;는 팩트를 함의한다. 생각해보면 당연할 수도 있지만, 자연과학에서 &amp;lsquo;당연하다&amp;rsquo;는 말만큼 중요한</description>
    </item>
    
    <item>
      <title>분포수렴하면 확률유계다</title>
      <link>https://freshrimpsushi.github.io/posts/if-convergence-in-distribution-then-bounded-in-probability/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-convergence-in-distribution-then-bounded-in-probability/</guid>
      <description>정리 확률변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 분포수렴하면 확률유계다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 앞서 확률수렴하면 분포수렴함을 보였으므로, 이 대우 명제를 생각해보면 &amp;lsquo;확률유계가 아니면 확률수렴하지 않는다&amp;rsquo;는 상식적인 따름정리도 얻을 수 있다. 증명 $\epsilon&amp;gt;0$ 가 주어져 있고 $X_{n}$ 이 확률변수 $X$ 로 분포수렴하며 그 누적분포함수가 $F_{X}$</description>
    </item>
    
    <item>
      <title>확률수렴하면 분포수렴한다</title>
      <link>https://freshrimpsushi.github.io/posts/if-convergence-in-probability-then-convergence-in-distribution/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-convergence-in-probability-then-convergence-in-distribution/</guid>
      <description>정리1 확률변수 $X$ 와 확률변수의 시퀀스 $\left\{ X_{n} \right\}$ 에 대해 $$ X_{n} \overset{P}{\to} X \implies X_{n} \overset{D}{\to} X $$ $\overset{P}{\to}$ 는 확률 수렴을 의미한다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 직관적인 단어로 다시 말하자면, 분포만 수렴하는 것이 정확히 수렴하는 것보다는 훨씬 쉽다는 말이다. 확률변수라는 것 자체를 함수로써 정확하게 이해하고 있다면 받아들이기 어렵지 않을 것이다. 증명 전략: 사건을 둘로</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 유계</title>
      <link>https://freshrimpsushi.github.io/posts/bounded-in-probability/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bounded-in-probability/</guid>
      <description>정의 1 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 주어져 있다고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 다음을 만족시키는 $N_{\varepsilon} \in \mathbb{N}$ 과 상수 $B_{\varepsilon} &amp;gt; 0$ 가 존재하면 $\left\{ X_{n} \right\}$ 가 확률 유계Bounded in Probability라고 한다. $$ n \ge N_{\varepsilon} \implies P \left[ \left| X_{n} \right| \le B_{\varepsilon} \right] \ge 1 - \varepsilon $$ 설명 생각해보면 일상생활에서 실제로 접하는 많은 확률 분포 함수들의 정의역이 무한히 넓다. 표준정규분포 $N(0,1)$</description>
    </item>
    
    <item>
      <title>수리통계학에서의 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution/</guid>
      <description>정의 1 확률변수 $X$ 와 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $X_{n}$ 이 $X$ 로 분포 수렴Convergence in Distribution한다고 말하고, $X_{n} \overset{D}{\to} X$ 와 같이 나타낸다. $$ \lim_{n \to \infty} F_{X_{n}} (x) = F_{X} (x) \qquad, \forall x \in C_{F_{X}} $$ $F_{X}$ 는 확률변수 $X$ 의 누적분포함수다. $C_{F_{X}}$ 는 함수 $F_{X}$ 가 연속인 점들의 집합을 나타낸다. 설명 분포 수렴은 확률 수렴과 마찬가지</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability/</guid>
      <description>정의 1 확률변수 $X$ 와 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $X_{n}$ 이 $X$ 로 확률 수렴Convergence in Probability한다고 말하고, $X_{n} \overset{P}{\to} X$ 와 같이 나타낸다. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left| X_{n} - X \right| &amp;lt; \varepsilon \right] = 1 $$ 설명 확률 수렴의 조건은 수식 그대로 확률의 센스에서 수렴을 정의한 것으로, 쉽게 말해 $n$ 이 커지면 두 확률 변수</description>
    </item>
    
    <item>
      <title>순서통계량</title>
      <link>https://freshrimpsushi.github.io/posts/order-statistics/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order-statistics/</guid>
      <description>정리1 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 가 서포트 $\mathcal{S} =(a,b)$ 인 확률밀도함수 $f(x)$ 를 가지는 연속확률분포를 따른다고 하자. 이들을 크기 순으로 나열한 확률 변수들을 $Y_{1} &amp;lt; \cdots &amp;lt; Y_{n}$ 와 같이 나타내도록 하면 그 조인트, 마지널 확률밀도함수들은 다음과 같다. [1] 조인트: $$ g \left( y_{1} , \cdots , y_{n} \right) = \begin{cases} n! f (y_{1}) \cdots f (y_{n}) &amp;amp;, a &amp;lt; y_{1} &amp;lt; \cdots &amp;lt; y_{n} &amp;lt; b \\ 0 &amp;amp; , \text{elsewhere} \end{cases} $$ [2] 마지널: $Y_{k}$ 의 누적밀도함수</description>
    </item>
    
    <item>
      <title>표본 분산을 n-1으로 나누는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-sample-variance-is-divided-by-n-1/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-sample-variance-is-divided-by-n-1/</guid>
      <description>왜 n-1로 나누지? $X_{i} \sim \left( \mu , \sigma^{2} \right)$ 이라고 하면 표본 분산 $S^{2}$ 는 다음과 같다. $$ S^{2} := {{1} \over {n-1}} \sum_{i=1}^{n} \left( X_{i} - \overline{X} \right)^{2} $$ 알다시피 표본 평균과 달리 표본 분산은 편차의 제곱을 모두 더한 후 표본 크기인 $n$ 이 아니라 $n-1$ 로 나눈다. 당연히 이를 이상하게 느껴야한다고는 말하지 않겠지만, 수식에 대한 보편적인 감성이 있다면 $n$ 개를 더하고 $n-1$ 로 나누는 것에서 강렬한 띠꺼움을 느</description>
    </item>
    
    <item>
      <title>불편추정량</title>
      <link>https://freshrimpsushi.github.io/posts/unbiased-estimator/</link>
      <pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unbiased-estimator/</guid>
      <description>정의 1 $\theta$ 의 추정량 $T$ 가 다음을 만족하면 $T$ 를 $\mu$ 의 불편추정량Unbiased Estimator이라고 한다. $$ E T = \theta $$ 설명 특히 $\theta$ 에 대한 불편추정량 중 가장 분산이 작은 경우 최소분산불편추정량Mimimum Variance Unbiased Estimator, MVUE이라고 한다. 불편성이란 편의를 가지지 않는 성질을 말한다. 가령 $X_{i} \sim \left( \mu , \sigma^{2} \right)$ 라고 할 때 $\mu$ 의 추정량으로써 표본</description>
    </item>
    
    <item>
      <title>편의-분산 트레이드 오프</title>
      <link>https://freshrimpsushi.github.io/posts/bias-variance-trade-off/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bias-variance-trade-off/</guid>
      <description>정의 $$ \text{MSE} \left( \widehat{\theta} \right) = \text{Var} \widehat{\theta} + \left( \text{Bias} \widehat{\theta} \right)^{2} $$ 설명 평균제곱오차 $\text{MSE}$ 는 통계 모형의 평가나 머신 러닝에서의 손실 함수로써 즐겨쓰이는 척도로써, 특히 편의와 분산에 대한 트레이드 오프로 나타난다.통계학도에게 있어서 편의를 다루는 것은 다소 어색할지 모르겠다. 적절한 확률 분포를 가정하고 그에 따른 수학적 이론을 토대로 데이터를 다루는 입장에서 분산은 손에 잡힐</description>
    </item>
    
    <item>
      <title>수리통계학에서의 편의</title>
      <link>https://freshrimpsushi.github.io/posts/bias-in-mathematical-statistics/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bias-in-mathematical-statistics/</guid>
      <description>정의 모수 $\theta$ 에 대한 추정량 $\widehat{\theta}$ 에 대해 다음과 같이 정의된 $\text{Bias}$ 를 편의라 한다. $$ \text{Bias} ( \theta ) = E(\widehat{\theta}) - \theta $$ 설명 Bias는 편의 또는 편향으로 순화되지만, 역시 가장 많이 쓰이는 말은 발음 그대로 읽은 [바이어스]다. 한국어에서 편의는 Convenience인 경우가 압도적으로 많고 수식적으로나 실제 쓰임새로나 &amp;lsquo;편향&amp;rsquo;으로 순</description>
    </item>
    
    <item>
      <title>수리통계학에서의 신뢰 구간</title>
      <link>https://freshrimpsushi.github.io/posts/confidence-interval/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/confidence-interval/</guid>
      <description>정의 1 확률 밀도 함수 $f (x; \theta)$ 를 가지는 확률 변수 $X$ 의 샘플 $X_{1} , \cdots , X_{n}$ 와 신뢰 계수Confidence Coefficient $\alpha \in (0,1)$ 가 주어져 있다고 하자. $$ L := L \left( X_{1} , \cdots , X_{n} \right) \\ U := U \left( X_{1} , \cdots , X_{n} \right) $$ 통계량 $L,U$ 가 위와 같이 정의되어있다고 할 때, 다음을 만족하는 구간 $(L,U) \subset \mathbb{R}$ 을 모수 $\theta$ 에 대한 $( 1 - \alpha)100 \%$ 신뢰구간이라 한다. $$ 1-\alpha = P \left[ \theta \in \left( L,U \right) \right] $$ 설명 사실 신</description>
    </item>
    
    <item>
      <title>수리통계학에서의 통계량과 추정량</title>
      <link>https://freshrimpsushi.github.io/posts/statistic-and-estimator/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statistic-and-estimator/</guid>
      <description>정의 12 확률 변수 $X$ 의 샘플 $X_{1} , \cdots , X_{n}$ 의 함수 $T$ 를 통계량Statistic이라 한다. $$ T := T \left( X_{1} , \cdots , X_{n} \right) $$ $X$ 의 분포 함수가 $f(x; \theta)$ 혹은 $p(x; \theta)$ 와 같이 나타날 때, $T$ 가 $\theta$ 를 파악하기 위한 통계량이면 $T$ 를 $\theta$ 의 추정량Estimator이라고 한다. 통계량과 모수에 대한 함수를 피벗Pivot이라고 한다. 통계량의 확률분포를 샘플링 분포Sam</description>
    </item>
    
    <item>
      <title>수리통계학에서의 랜덤 샘플</title>
      <link>https://freshrimpsushi.github.io/posts/random-sample/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-sample/</guid>
      <description>정의 1 확률 변수 $X$ 가 실제로 뽑힌 것을 실현Realization이라 하고 보통 소문자 $x$ 로 나타낸다. 확률 변수 $X$ 와 같은 확률 분포에서 샘플 사이즈Sample Size $n$ 만큼 얻어낸 확률 변수들을 샘플Sample이라 하고 다음과 같이 나타낸다. $$ X_{1} , X_{2} , \cdots , X_{n} $$ 확률 변수 $X_{1} , \cdots , X_{n}$ 이 iid면 사이즈 $n$ 의 랜덤 샘플이라 부른다. 설명 이러한 정의</description>
    </item>
    
    <item>
      <title>확률 변수들의 선형 결합</title>
      <link>https://freshrimpsushi.github.io/posts/linear-combinations-of-random-variable/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-combinations-of-random-variable/</guid>
      <description>정의 1 확률 변수 $X_{1} , \cdots , X_{n}$ 가 어떤 $(a_{1}, \cdots , a_{n}) \in \mathbb{R}^{n}$ 에 대해 $\displaystyle T := \sum_{i=1}^{n} a_{i} X_{i}$ 를 선형 결합Linear Combinations이라고 한다. 설명 특히 $X_{1} , \cdots , X_{n}$ 이 iid면 사이즈 $n$ 의 **랜덤 샘플Random Sample**이라도 부른다. 통계학의 맥락이라면 모든 관측값에 같은 가중치가 곱해진 $a_{1} = \cdots = a_{n} = {{ 1 } \over { n } }$ 을 생각할 것이다</description>
    </item>
    
    <item>
      <title>정규분포를 따르는 두 확률 변수가 독립인 것과 공분산이 0인 것은 동치다</title>
      <link>https://freshrimpsushi.github.io/posts/two-normal-distributions-are-independent-iff-their-covariance-is-equal-to-zero/</link>
      <pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/two-normal-distributions-are-independent-iff-their-covariance-is-equal-to-zero/</guid>
      <description>정리 $$ X_{1} \sim N ( \mu_{1} , \sigma_{1} ) \\ X_{2} \sim N ( \mu_{2} , \sigma_{2} ) $$ 면 $$ X_{1} \perp X_{2} \iff \text{cov} (X_{1} , X_{2} ) = 0 $$ 설명 일반적으로 상관관계가 없다고 독립인 것은 아니다. 하지만 분포들이 정규분포를 따른다는 가정이 있다면 공분산이 $0$ 인 것이 독립임을 보장해준다. 증명 $( \Rightarrow )$ $$ \displaystyle M_{X_{1}} (t_{1} ) = \exp \left[ \mu_{1} t_{1} + {{1} \over {2}} \sigma_{1} t_{1}^{2} \right] M_{X_{2}} (t_{2} ) = \exp \left[ \mu_{2} t_{2} + {{1} \over {2}} \sigma_{2} t_{2}^{2} \right] $$ $\sigma_{12} : = \text{cov} (X_{1} , X_{2} )$ 그리고 $\sigma_{21} :</description>
    </item>
    
    <item>
      <title>번스타인 분포: 짝으로 독립이라고 상호 독립은 아니다</title>
      <link>https://freshrimpsushi.github.io/posts/bernstein-distribution/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bernstein-distribution/</guid>
      <description>정의 $(x,y,z) \in \left\{ (1,0,0), (0,1,0), (0,0,1), (1,1,1) \right\}$ 에 대해 다음과 같은 확률질량함수를 가지는 분포를 번스타인 분포Bernstein Distribution라고 한다. $$ p(x,y,z) = {{1} \over {4} } $$ 설명 번스타인 분포는 분포의 조건을 모두 만족시키고는 있지만 자연계에 실재하는 분포라고 보기는 어렵다. &amp;lsquo;짝으로 독립이면 상호 독립이다&amp;rsquo;라는 명제의 반례</description>
    </item>
    
    <item>
      <title>확률 변수들의 상호 독립과 iid</title>
      <link>https://freshrimpsushi.github.io/posts/mutual-independence-and-iid-independent-and-identically-distributed/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mutual-independence-and-iid-independent-and-identically-distributed/</guid>
      <description>정의 1 확률 변수 $X_{1} , \cdots , X_{n}$ 가 다음을 만족하면 $X_{1} , \cdots , X_{n}$ 이 짝으로 독립Pairwise Independent이라 한다. $$ i \ne j \implies X_{i} \perp X_{j} $$ 연속 확률 변수 $X_{1} , \cdots , X_{n}$ 의 조인트 확률 밀도 함수 $f$ 가 각각의 확률 밀도 함수 $f_{1} , \cdots , f_{n}$ 에 대해 다음을 만족하면 $X_{1} , \cdots , X_{n}$ 가 상호 독립이라 한다. $$ f(x_{1} , \cdots , x_{n} ) \equiv f_{1} (x_{1}) \cdots f_{n} (x_{n}) $$ 이산 확률 변수 $X_{1} , \cdots ,</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 변수의 독립</title>
      <link>https://freshrimpsushi.github.io/posts/independence-of-random-variable/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independence-of-random-variable/</guid>
      <description>정의 1 두 확률 변수 $X_{1}, X_{2}$ 의 조인트 확률 밀도 함수 $f$ 혹은 확률 질량 함수 $p$ 에 대해 $X_{1}, X_{2}$ 의 확률 밀도 함수들 $f_{1}, f_{2}$ 혹은 확률 질량 함수 $p_{1}, p_{2}$ 가 다음을 만족하면 $X_{1}, X_{2}$ 가 독립이라 하고, $X_{1} \perp X_{2}$ 와 같이 나타낸다. $$ f(x_{1} , x_{2} ) \equiv f_{1}(x_{1})f_{2}(x_{2}) \\ p(x_{1} , x_{2} ) \equiv p_{1}(x_{1})p_{2}(x_{2}) $$ 정리 아래의 정리는 이산 확률 변수에 대해서도 같지만, 편의상 연속 확률 변수인 경우만 언급한다. 다음은 모두 동치다. [1]:</description>
    </item>
    
    <item>
      <title>수리통계학에서의 조건부 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-probability/</link>
      <pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-probability/</guid>
      <description>정의 이산 확률 변수 $X_{1}, X_{2}, \cdots , X_{n}$ 에 대해 다음의 $p_{2, \cdots , n \mid 1}$ 를 $X_{1} = x_{1}$ 이 주어졌을 때의 $ X_{2}, \cdots , X_{n}$ 의 조인트 조건부 확률 질량 함수라고 한다. $$ p_{2, \cdots , n \mid 1} ( x_{2} , \cdots ,x_{n} \mid X_{1} = x_{1} ) = {{ p_{1, \cdots , n}(x_{1} , x_{2} , \cdots , x_{n}) } \over { p_{1}( X_{1} = x_{1} ) }} $$ 연속 확률 변수 $X_{1}, X_{2}, \cdots , X_{n}$ 에 대해 다음의 $f_{2, \cdots , n \mid 1}$ 를 $X_{1} = x_{1}$ 이 주어졌을 때의 $ X_{2}, \cdots , X_{n}$ 의 조인트 조건부 확률 밀도 함수</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transform-of-random-variable/</link>
      <pubDate>Fri, 17 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transform-of-random-variable/</guid>
      <description>공식 다변량 확률 변수 $X = ( X_{1} , \cdots , X_{n} )$ 의 조인트 확률밀도함수 $f$ 가 $f(x_{1} , \cdots , x_{n})$ 와 같이 주어져있다고 하고 다음과 같은 변환을 생각해보자. $$ y_{1} = u_{1} (x_{1} , \cdots , x_{n}) \\ \vdots \\ y_{n} = u_{n} (x_{1} , \cdots , x_{n}) $$ 이러한 변환 $u_{1} , \cdots , u_{n}$ 는 단사가 아닐 수 있다. 따라서 $X$ 의 서포트 $S_{X}$ 는 $k$ 개의 파티션 $A_{1} , \cdots , A_{i} , \cdots , A_{k}$ 으로 나누어지고, 다음과 같은 역변환 $w_{ji} \mid_{i=1,\cdots,k \\ j=1,\cdots,n}$ 들을 생각</description>
    </item>
    
    <item>
      <title>수리통계학에서의 다변량 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/multivariate-distribution/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multivariate-distribution/</guid>
      <description>정의 1 표본 공간 $\Omega$ 에서 정의된 $n$ 개의 확률 변수 $X_{i}$ 에 대해 $X = (X_{1} , \cdots , X_{n})$ 를 $n$차원 랜덤 벡터Random Vector라고 한다. $X$ 의 치역 $X(\Omega)$ 를 공간이라고도 부른다. 다음을 만족하는 함수 $F_{X} : \mathbb{R}^{n} \to [0,1]$ 을 $X$ 의 조인트Joint 누적 분포 함수라고 한다. $$ F_{X}\left( x_{1}, \cdots , x_{n} \right) := P \left[ X_{1} \le x_{1} , \cdots , X_{n} \le x_{n} \right] $$ 어떤 $h_{1} , \cdots , h_{n} &amp;gt;0$ 들에 대해 다음을 만족하는</description>
    </item>
    
    <item>
      <title>n차 적률이 존재하면 차수가 n보다 작은 적률도 존재한다</title>
      <link>https://freshrimpsushi.github.io/posts/if-nth-moment-exists-then-moments-with-less-degree-are-exist/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-nth-moment-exists-then-moments-with-less-degree-are-exist/</guid>
      <description>정리 확률변수 $X$와 자연수 $n$ 에 대해 $E( X^n )$ 이 존재하면 $E( X^m ), m=1,2,3,\cdots, n$ 도 존재한다. 설명 어떤 차수의 적률이든 존재하기만 한다면 그보다 작은 차수의 적률은 항상 존재하지만, 당연히 역은 성립하지 않는다. 물론 실제로 문제를 접해보면 높은 차수의 적률이 먼저 주어지는 경우는 거의 없으나, 어떤 정리의 조건을 나열할 때 지면을 상당히 절약할 수 있게 해주는 정</description>
    </item>
    
    <item>
      <title>적률생성함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/moment-generating-function/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-generating-function/</guid>
      <description>정의 1 확률변수 $X$ 와 어떤 양수 $h&amp;gt;0$ 대해 $E(e^{tX})$ 이 $-h&amp;lt; t &amp;lt; h$ 에서 존재하면 $M(t) = E( e^{tX} )$ 를 $X$ 의 적률생성함수Moment Generating Function라고 정의한다. 설명 적률생성함수는 흔히 mgf라는 약어로 많이 쓰인다. 수리통계학에서는 비교적 초반에 배우는데, 생소한 정의와 맥락 없는 등장 때문에 수리통계학을 싫어지게 만드는 주범 중 하나다. 적률생성함수를</description>
    </item>
    
    <item>
      <title>수리통계학에서의 첨도</title>
      <link>https://freshrimpsushi.github.io/posts/kurtosis/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kurtosis/</guid>
      <description>첨도 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{2}$ 를 $X$ 의 첨도kurtosis라고 한다. $$ \gamma_{2} := {{ E \left( X - \mu \right)^4 } \over { \sigma^4 }} $$ 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본첨도 $g_{2}$ 는 다음과 같이 구해진다. $$ g_{2} := \sum_{i=1}^{n} = {{ \left( X - \overline{X} \right)^4 } \over { n \widehat{\sigma}^4 }} - 3 $$ 설명 첨도는 4차 적률로 구해지며, 확률변수의 분포함수가 얼마</description>
    </item>
    
    <item>
      <title>수리통계학에서의 왜도</title>
      <link>https://freshrimpsushi.github.io/posts/skewness/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/skewness/</guid>
      <description>정의 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{1}$ 를 $X$ 의 왜도Skewness라고 한다. $$ \gamma_{1} := {{ E \left( X - \mu \right)^3 } \over { \sigma^3 }} $$ 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본왜도 $g_{1}$ 은 다음과 같이 구해진다. $$ g_{1} := \sum_{i=1}^{n} {{ \left( X - \overline{X} \right)^3 } \over { n \widehat{\sigma}^3 }} $$ 설명 왜도는 3차 적률로 구해지며, 확률변수의 분포함수가 어떻게 치우</description>
    </item>
    
    <item>
      <title>공분산의 여러가지 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-covariance/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-covariance/</guid>
      <description>정의와 성질 평균이 각각 $\mu_{X}$, $\mu_{Y}$ 인 확률 변수 $X$, $Y$ 에 대해 $\text{Cov} (X ,Y) : = E \left[ ( X - \mu_{X} ) ( Y - \mu_{Y} ) \right] $ 을 $X$ 와 $Y$ 의 공분산Covariance이라고 정의한다. 공분산은 아래의 성질들을 가진다. [1]: $\text{Var} (X) = \text{Cov} (X,X)$ [2]: $\text{Cov} (X,Y) = \text{Cov} (Y, X)$ [3]: $\text{Var} (X + Y) = \text{Var} (X) + \text{Var} (Y) + 2 \text{Cov} (X,Y) $ [4]: $\text{Cov} (X + Y , Z ) = \text{Cov}(X,Z) + \text{Cov}(Y,Z) $ [5]: $\text{Cov} (aX + b , cY + d ) = ac \text{Cov}(X,Y) $ 설명 공분산은 두 변수의 선형</description>
    </item>
    
    <item>
      <title>피어슨 상관계수</title>
      <link>https://freshrimpsushi.github.io/posts/pearson-correlation-coefficient/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pearson-correlation-coefficient/</guid>
      <description>정의 1 다음과 같이 정의된 $\rho = \rho(X,Y)$ 를 피어스 상관계수라고 한다. $$ \rho = { {\text{Cov} (X,Y)} \over {\sigma_X \sigma_Y} } $$ 설명 (피어슨) 상관 계수(Pearson) Correlation Coefficient는 두 변수가 서로 (선형) 상관 관계 를 가지고 있는지를 확인하는 척도가 된다. $1$ 이나 $–1$ 에 가까우면 상관관계가 있다고 보고 $0$ 이면 없다고 본다. 주의할 것은 상관관계와 독립이 같은 개</description>
    </item>
    
    <item>
      <title>평균과 분산의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-mean-and-variance/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-mean-and-variance/</guid>
      <description>정리 평균 $E ( X ) = \mu_{X}$ 과 분산 $\text{Var} (X) = E [ ( X - \mu_{X} )^2 ]$ 은 아래의 성질들을 가진다. [1]: $E(X + Y) = E(X) + E(Y)$ [2]: $E(aX + b) = a E(X) + b$ [3]: $\text{Var} (X) \ge 0$ [4]: $\text{Var} ( X ) = E(X^2) - \mu_{X}^2$ [5]: $\text{Var} (aX + b) = a^2 \text{Var} (X)$ 설명 평균과 분산에 관한 것이니만큼 아주 중요한 성질들이다. 특히 [1]과 [2]는 이른바 선형성Linearity이라 불리우는 성질로써, 수식을 다룰 때 무척 편리하게</description>
    </item>
    
    <item>
      <title>대표값의 수리적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mathematical-property-of-representative-value/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mathematical-property-of-representative-value/</guid>
      <description>정리 데이터 $X = \left\{ x_{1} , \cdots , x_{n} \right\}$ 가 주어져 있다고 하자. [0]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{0}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{mode}(X) $$ [1]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{1}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{median}(X) $$ [2]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{2}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{mean}(X) $$ 설명 선형대수의 용어로 어렵게 말해보자면 다음과 같다: [0]: $l^{0}$-놈을 최소화하는 것은 최빈값이다.</description>
    </item>
    
    <item>
      <title>수리통계학에서의 기대값, 평균, 분산, 적률의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-mean-variance-moment/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-mean-variance-moment/</guid>
      <description>정의: 기대값, 평균, 분산 확률 변수 $X$ 가 주어져 있다고 하자. 연속 확률 변수 $X$ 의 확률 밀도 함수 $f(x)$ 가 $\displaystyle \int_{-\infty}^{\infty} |x| f(x) dx &amp;lt; \infty$ 를 만족하면 다음과 같이 정의된 $E(X)$ 를 $X$ 의 기대값Expectation이라고 한다. $$ E(X) := \int_{-\infty}^{\infty} x f(x) dx $$ 이산 확률 변수 $X$ 의 확률 질량 함수 $p(x)$ 가 $\displaystyle \sum_{x} |x| p(x) &amp;lt; \infty$ 를 만족하면 다음과 같이 정의된 $E(X)$ 를 $X$ 의 기대값Expectation이라</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 변수와 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution/</link>
      <pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution/</guid>
      <description>정의 1 표본 공간 $\Omega$ 에서 확률 $P$ 가 정의되어 있다고 하자. 정의역이 표본 공간인 함수 $X : \Omega \to \mathbb{R}$ 을 확률 변수Random Variable라고 한다. 확률 변수의 치역 $X(\Omega)$ 을 공간Space이라고도 부른다. 다음을 만족하는 함수 $F_{X} : \mathbb{R} \to [0,1]$ 을 $X$ 의 **누적분포함수(Cummulative Distribution Function, cdf)**라 한다. $$ F_{X}(x) = P_{X}\left( (-\infty,x] \right) = P \left( \left\{ \omega \in \Omega</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률과 확률의 덧셈법칙</title>
      <link>https://freshrimpsushi.github.io/posts/probability-and-additive-law-of-probability/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-and-additive-law-of-probability/</guid>
      <description>정의 1 같은 조건 하에서 반복할 수 있는 시행을 임의 시행Random Experiment이라고 한다. 임의 시행에서 얻을 수 있는 모든 결과Outcome를 모아놓은 집합 $\Omega$ 를 표본 공간Sample Space이라고 한다. 표본 공간에서 우리가 관심을 가지는 결과들의 집합, 즉 $B \subset \Omega$ 를 사건Event이라 하고 이들의 집합을 $\mathcal{B}$ 와 같이 나타낸다.</description>
    </item>
    
    <item>
      <title>베이즈 인자를 통한 가설검정</title>
      <link>https://freshrimpsushi.github.io/posts/statistical-hypothesis-test-by-bayes-factor/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statistical-hypothesis-test-by-bayes-factor/</guid>
      <description>빌드업 고전적인 가설검정을 쓸 수 있게 되려면 기각역, 유의확률과 같은 개념에 대한 수학적인 이해를 포함해서 이를 직관적으로 받아들일 수 있을 정도의 통계학적 센스까지 갖추어야한다. 학부 1학년 교양 수준에서도 몇 시간이나 할애해가며 가르치고, 그래도 가설검정을 제대로 받아들이지 못하는 학생이 수두룩한 것도 당연한 일이다. 고등학교에서 배우는 통</description>
    </item>
    
    <item>
      <title>최고사후밀도 신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</guid>
      <description>정의 1 모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $C : = \left\{ \theta \in \Theta \ | \ p ( \theta | y ) \ge k (\alpha) \right\}$ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 최고사후밀도 신용구간HPD이라고 한다. 여기서 $k(\alpha)$ 는 $p(\theta \in C | y ) \ge 1 - \alpha$ 를 만족하는 가장 큰 상수다. 설명 수식과 말보다는 그림을 통해 보는게 훨씬 이해하기 좋다. 실제 계산에서도 위와 같이 $k$ 를 계</description>
    </item>
    
    <item>
      <title>신용구간과 신뢰구간의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</guid>
      <description>요약 신용구간과 신뢰구간의 차이는 실로 베이지안과 프리퀀티스트의 차이라고 볼 수 있다. 신뢰구간(프리퀀티스트): 모수는 고정된 상수고, 신뢰구간이 랜덤으로 구해진다. 신용구간(베이지안): 모수도 분포를 가진 변수고, 신용구간도 사후분포로 구해진다. 신뢰구간 고전통계에서 모수 $\mu$ 에 대한 $95 \% $ 신뢰구간 $[a , b]$ 이 의미하는 것은 같은 방법</description>
    </item>
    
    <item>
      <title>신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval/</guid>
      <description>정의 1 모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $P ( \theta \in C | y ) \ge 1 - \alpha$ 를 만족할 때, $C$ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 신용구간Credible Interval이라고 한다. 설명 베이지안에서의 구간추정이란 모수 $\theta$ 를 포함하는 확률이 높은 구간을 찾는 것이다. 이로써 찾아지는 &amp;lsquo;신용구간&amp;rsquo</description>
    </item>
    
    <item>
      <title>통계학의 세가지 대표값: 최빈값, 중앙값, 평균</title>
      <link>https://freshrimpsushi.github.io/posts/mode-median-mean/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mode-median-mean/</guid>
      <description>개요 대표값은 데이터를 설명하는 대표적인 값을 말한다. 수천 수만에 달하는 데이터가 있어도 일일이 다 살펴볼 게 아니라면 결국 중요한 것은 데이터가 무엇을 의미하느냐고, 대표값은 이를 효과적으로 요약한다. 그 중 가장 자주 쓰이는 세가지 대표값으로써 최빈값, 중앙값, 평균이 있다. (0) 최빈값: 표본에서 가장 자주 발생한 값 (1) 중앙값: 표본에서 중앙에 위</description>
    </item>
    
    <item>
      <title>제프리 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/jeffreys-prior/</link>
      <pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jeffreys-prior/</guid>
      <description>정의 1 자료의 분포 $p( y | \theta)$ 에 대해 $\pi ( \theta ) \propto I^{1/2} ( \theta )$ 를 제프리 사전분포Jeffreys Prior라 한다. $I$ 는 피셔정보Fishser Information를 의미한다. $$ I ( \theta ) = E \left[ \left( \left. {{\partial \ln p (y | \theta) } \over {\partial \theta}} \right)^2 \right| \theta \right] = E \left[ \left. - {{\partial^2 \ln p (y | \theta) } \over { (\partial \theta )^2 }} \right| \theta \right] $$ 설명 라플라스 사전분포 $\pi (\theta) \propto 1$ 는 모수 $\theta$ 의 사전분포로써</description>
    </item>
    
    <item>
      <title>라플라스 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-prior/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-prior/</guid>
      <description>빌드업 모수에 대한 정보가 거의 없다면 구태여 복잡한 사전분포를 생각할 이유는 없다. 내년 모 대학의 통계학과 신입생의 성비를 추측해보라고 했을 때, 통계학과를 어느정도 아는 사람이라면 예년의 성비를 보고 어느정도 짐작을 하겠지만 전혀 관계도 없고 관심도 없는 사람이 이 질문을 들었을 땐 특별한 이유가 없는 한 50:50이라고 추측할 것이다. 어떤 주머니</description>
    </item>
    
    <item>
      <title>켤레사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/conjugate-prior/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conjugate-prior/</guid>
      <description>정의 1 사전분포와 사후분포가 동일한 분포족에 속하면 사전분포를 켤레사전분포Conjugate Prior 혹은 공액사전분포라고 한다. 설명 베이지안이란 본래 사전분포가 어떻게 되든 업데이트를 통해 모수를 찾아가는 것이긴 하지만, 모형에 대해 어느정도 아는 바가 있다면 적절한 사전분포를 사용함으로써 수학적 계산을 간단하게 하고 결과를 이해하기 쉽게 할</description>
    </item>
    
    <item>
      <title>라플라스 계승 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</guid>
      <description>정리 1 이항모형 $\displaystyle p(y | \theta) = \pmatrix{ n \\ y} \theta^{y} (1- \theta)^{n-y}$ 의 사전분포가 일양 분포 $U (0,1)$ 를 따르고 사후분포가 베타 분포 $\beta (y+1 , n-y+1)$ 을 따라 $p( \theta | y ) \sim \theta^{y} (1- \theta)^{n-y}$ 이라고 하자. 그러면 이제까지 얻은 데이터 $y$ 에 대해 새로운 $\tilde{y}$ 가 $1$ 일 확률은 $$ p(\tilde{y} = 1| y) = {{y+1} \over {n+2}} $$ 설명 프리퀀티스트의 관점으로 보았을 때 $\tilde{y} = 1$ 일 확률은 그 표본비율 $\displaystyle {{y} \over {n}}$ 에 가까울 것이다. 그런데 기본적으</description>
    </item>
    
    <item>
      <title>베이지안 패러다임</title>
      <link>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</guid>
      <description>빌드업 통계학이란 &amp;lsquo;모수를 파악하는 방법을 연구하는 학문&amp;rsquo;이라고 할 수 있다. 어떤 물리량을 측정하는 것처럼 공식이나 법칙을 통해 정확하게 모수를 추정할 수 있다면 더할나위 없지만, 현실적으로 그게 불가능하기 때문에 가정과 표본을 이용해 &amp;lsquo;모수로 예상되는 것&amp;rsquo;을 찾아낼 뿐이다. 우리나라 남성</description>
    </item>
    
    <item>
      <title>베이즈 정리로 보는 몬티홀 딜레마</title>
      <link>https://freshrimpsushi.github.io/posts/monty-hall-dilemma/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monty-hall-dilemma/</guid>
      <description>설명 알다시피 몬티홀 게임은 실제로 경품이 어디있든 관계 없이 선택을 바꾸는 것이 유리하다. 이것을 팩트로써 받아들이냐와 별개로 몬티홀 게임을 직관적으로 이해하지 못했거나 수식적인 표현이 서툰 사람들이 있다. 편의상 본인이 플레이어고, 1번 문을 선택했다고 생각해보자. 이 때 우리는 경품에 대한 어떤 정보도 없기에, 어떤 번호든 선택할 확률은 같다고</description>
    </item>
    
    <item>
      <title>몬테카를로 방법과 부트스트랩의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/difference-between-monte-carlo-method-and-bootstrap/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-between-monte-carlo-method-and-bootstrap/</guid>
      <description>개요 몬테카를로 방법은 작위적인 데이터로 시뮬레이션을 반복해 새로운 기법을 확인하는 방법이고 부트스트랩은 실제 데이터에서 재표본 추출을 통해 비용을 절감하며 문제를 해결하려는 방법이다. 정의 몬테카를로 방법Monte Carlo Method이란 난수 추출을 통해 관심 있는 대상에 대해 점추정량을 찾는 방법이다. 부트스트랩Bootstrap이란 표</description>
    </item>
    
    <item>
      <title>표본표준편차와 표준오차의 구분</title>
      <link>https://freshrimpsushi.github.io/posts/how-different-between-sample-standard-deviation-and-standard-error/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-different-between-sample-standard-deviation-and-standard-error/</guid>
      <description>정의 $X$ 로부터 얻은 데이터를 $\mathbb{x} = ( x_{1}, x_{2}, \cdots , x_{n} )$ 라고 하자. 표본평균: $$ \overline{x} = {{1} \over {n}} \sum_{i=1}^{n} x_{i} $$ 표본표준편차: $$ s_{x} = \sqrt { {{1} \over {n-1}} \sum_{i=1}^{n} ( x_{i} - \overline{x} )^2 } $$ 표준오차: $$ \text{s.e.}( \hat{x} ) = {{ s_{x} } \over { \sqrt{n} }} $$ 설명 말이 비슷해서인지 의외로 많은 사람들이 표본표준편차와 표준오차를 구분하지 못한다. 사실상 통계를 글로만 배우는 고등학생들은 물론이고 심하게는 통계학과</description>
    </item>
    
    <item>
      <title>특정한 분포를 따르는 확률변수들의 덧셈 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/sum-of-some-probability-distribution/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-of-some-probability-distribution/</guid>
      <description>정리 확률 변수 $X_{1} , \cdots , X_{n}$ 들이 상호 독립이라고 하자. [1] 이항 분포: $X_i \sim \text{Bin} ( n_{i}, p)$ 이면 $$ \displaystyle \sum_{i=1}^{m} X_{i} \sim \text{Bin} \left( \sum_{i=1}^{m} n_{i} , p \right) $$ [2] 푸아송 분포: $X_i \sim \text{Poi}( m_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \text{Poi} \left( \sum_{i=1}^{n} m_{i} \right) $$ [3] 감마 분포: $X_i \sim \Gamma( k_{i}, \theta)$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \Gamma \left( \sum_{i=1}^{n} k_{i} , \theta \right) $$ [4] 카이제곱 분포: $X_i \sim \chi^2 ( r_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \chi ^2 \left( \sum_{i=1}^{n} r_{i} \right) $$ [5] 정규 분포: $X_i \sim N( \mu_{i}, \sigma_{i}^{2} )$ 이면 주어진 벡터 $(a_{1} ,</description>
    </item>
    
    <item>
      <title>베이즈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</guid>
      <description>정리 1 표본공간 $S$ 와 사건 $A$ 에 대해서 ${S_1,S_2,&amp;hellip;,S_n}$ 가 $S$ 의 분할이면 $$ \displaystyle P(S_k|A)=\frac { P(S_k)P(A|S_k) }{ \sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$ 설명 혹은 베이즈 법칙으로도 불리는 이 정리는 두개의 법칙만 쓰면 될 정도로 쉽게 증명할 수 있으나 그 응용은 어마어마하다. 이른바 베이지안 패러다임은 통계학 자체를 양분하는 사고방식으로써, 그 중요도는 몇 번을 강조해도 부족함이 없다. 우리가 알고 싶은 것은 위</description>
    </item>
    
  </channel>
</rss>
