<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>수리통계학 on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/categories/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99/</link>
    <description>Recent content in 수리통계학 on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Thu, 04 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/categories/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>라오-블랙웰 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-rao-blackwell-theorem/</link>
      <pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-rao-blackwell-theorem/</guid>
      <description>정리 1 2 모수 $\theta$ 가 주어져 있다고 하자. $T$ 가 $\theta$ 의 충분통계량이고 $W$ 가 $\tau \left( \theta \right)$ 의 불편추정량이라고 할 때 $\phi \left( T \right) := E \left( W | T \right)$ 를 정의하면 모든 $\theta$ 에 대해 다음이 성립한다. $$ \begin{align*} E_{\theta} \phi (T) =&amp;amp; \tau (\theta) \\ \text{Var}_{\theta} \phi (T) \le&amp;amp; \text{Var}_{\theta} W \end{align*} $$ 다시 말해, $\phi (T)$ 는 $\tau (\theta)$ 에 대해 $W$ 보다 더 나은 불편추정량Uniformly Better Unbiased Estimator이다. 설명 라오-블랙웰 정리를</description>
    </item>
    
    <item>
      <title>네이만 인수분해 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-neyman-factorization-theorem/</link>
      <pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-neyman-factorization-theorem/</guid>
      <description>정리 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 이 모수 $\theta \in \Theta$ 에 대해 같은 확률질량/밀도함수 $f \left( x ; \theta \right)$ 를 가진다고 하자. 통계량 $Y = u_{1} \left( X_{1} , \cdots , X_{n} \right)$ 이 $\theta$ 의 충분통계량인 것은 다음을 만족하는 음이 아닌 두 함수 $k_{1} , k_{2} \ge 0$ 이 존재하는 것이다. $$ f \left( x_{1} ; \theta \right) \cdots f \left( x_{n} ; \theta \right) = k_{1} \left[ u_{1} \left( x_{1} , \cdots , x_{n} \right) ; \theta \right] k_{2} \left( x_{1} , \cdots , x_{n} \right) $$ 단, $k_{2}$ 는 $\theta$ 에 종속되지 않아야한다.</description>
    </item>
    
    <item>
      <title>충분통계량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistiic/</link>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistiic/</guid>
      <description>정의 수식적인 정의 1 모수 $\theta \in \Theta$ 에 대해 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 의 확률질량/밀도함수를 $f(x;\theta)$, 통계량 $Y_{1} := u_{1} \left( X_{1} , \cdots , X_{n} \right)$ 의 확률질량/밀도함수를 $f_{Y_{1}} \left( y_{1}; \theta \right)$ 이라 하자. $\theta \in \Theta$ 에 종속되지 않은 $H \left( x_{1} , \cdots , x_{n} \right)$ 에 대해 $$ {{ f \left( x_{1} ; \theta \right) \cdots f \left( x_{n} ; \theta \right) } \over { f_{Y_{1}} \left( u_{1} \left( x_{1} , \cdots, x_{n} \right) ; \theta \right) }} = H \left( x_{1} , \cdots , x_{n} \right) $$ 이면 $Y_{1}$ 을 $\theta$ 에 대한 충분통계량Suf</description>
    </item>
    
    <item>
      <title>효율적추정량</title>
      <link>https://freshrimpsushi.github.io/posts/efficient-estimator/</link>
      <pubDate>Sat, 31 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/efficient-estimator/</guid>
      <description>정의 1 $Y$ 가 모수 $\theta$ 에 대한 불편추정량이라고 하자. 라오-크래머 하한 $\text{RC}$ 에 대해 다음을 추정량 $Y$ 의 효율성Efficiency이라고 한다. $$ {{ \text{RC} } \over { \text{Var} (Y) }} $$ 효율성이 $1$ 인 추정량을 효율적추정량Efficient Estimator이라고 한다. 설명 라오-크래머 부등식: $$ \text{Var} (Y) \ge {{ \left[ k&#39;(\theta) \right]^{2} } \over { n I (\theta) }} = \text{RC} $$ 위 부등식에 따라 효율</description>
    </item>
    
    <item>
      <title>라오-크래머 하한</title>
      <link>https://freshrimpsushi.github.io/posts/rao-cramer-lower-bound/</link>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rao-cramer-lower-bound/</guid>
      <description>정리 1 정칙조건: (R0): 확률밀도함수 $f$ 는 $\theta$ 에 대해 단사다. 수식으로는 다음을 만족시킨다. $$ \theta \ne \theta&#39; \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta&#39; \right) $$ (R1): 확률밀도함수 $f$ 는 모든 $\theta$ 에 대해 같은 서포트를 가진다. (R2): 참값 $\theta_{0}$ 는 $\Omega$ 의 내점Interior Point이다. (R3): 확률밀도함수 $f$ 는 $\theta$ 에 대해 두 번 미분가능하다. (R4): 적분 $\int f (x; \theta) dx$ 은 적분 기호를 넘나들며 $\theta$ 에</description>
    </item>
    
    <item>
      <title>바틀렛 항등식</title>
      <link>https://freshrimpsushi.github.io/posts/bartlett-identity/</link>
      <pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bartlett-identity/</guid>
      <description>정리 정칙조건: (R0): 확률밀도함수 $f$ 는 $\theta$ 에 대해 단사다. 수식으로는 다음을 만족시킨다. $$ \theta \ne \theta&#39; \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta&#39; \right) $$ (R1): 확률밀도함수 $f$ 는 모든 $\theta$ 에 대해 같은 서포트를 가진다. (R2): 참값 $\theta_{0}$ 는 $\Omega$ 의 내점Interior Point이다. (R3): 확률밀도함수 $f$ 는 $\theta$ 에 대해 두 번 미분가능하다. (R4): 적분 $\int f (x; \theta) dx$ 은 적분 기호를 넘나들며 $\theta$ 에 대</description>
    </item>
    
    <item>
      <title>피셔 정보</title>
      <link>https://freshrimpsushi.github.io/posts/fisher-information/</link>
      <pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fisher-information/</guid>
      <description>빌드업 스코어 함수 모수 $\theta \in \Theta$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. 로그우도함수가 가장 커지는 추정량인 최대우도추정량은 다음과 같은 편미분방정식을 만족하는 $\widehat{\theta}$ 으로 구할 수 있었다. $$ \sum_{k=1}^{n} {{ \partial \log f \left( x_{k} ; \theta \right) } \over { \partial \theta }} $$ 여기서 $\displaystyle {{ \partial \log f ( x ; \theta ) } \over { \partial \theta }}$ 를 스코어 함수Score Function이라</description>
    </item>
    
    <item>
      <title>수리통계학에서의 정칙성 조건</title>
      <link>https://freshrimpsushi.github.io/posts/regularity-conditions-in-mathematical-statistiics/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regularity-conditions-in-mathematical-statistiics/</guid>
      <description>개요 수학을 사용하는 과목에서 대개 정칙성Regularity Conditions이란 대개 응용될 구석이 많으면서 이론적인 전개가 편해지는 조건들을 말하며, 수리통계학에서는 다음과 같다. 가정 1 모수 $\theta \in \Theta$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. $X$ 와 같은 분포로 iid하게 뽑은 랜덤샘플 $X_{1} , \cdots , X_{n}$ 는 같은 확률</description>
    </item>
    
    <item>
      <title>최대우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/maximum-likelihood-estimator/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/maximum-likelihood-estimator/</guid>
      <description>빌드업 모수 $\theta \in \Theta$ 에 대해 확률밀도함수가 $f \left( x ; \theta \right)$ 인 확률변수 $X$ 를 생각해보자. $X$ 와 같은 분포로 iid하게 뽑은 랜덤샘플 $X_{1} , \cdots , X_{n}$ 는 같은 확률밀도함수 $f(x ; \theta)$ 와 실현 $\mathbf{x} := \left( x_{1} , \cdots , x_{n} \right)$ 을 가진다. 이에 대해 다음과 같은 함수 $L$ 을 우도함수Likelihood Function라 한다. $$ L ( \theta ; \mathbf{x} ) := \prod_{k=1}^{n} f \left( x_{k} ; \theta \right) $$ 아래에서 나오</description>
    </item>
    
    <item>
      <title>일치추정량</title>
      <link>https://freshrimpsushi.github.io/posts/consistent-estimator/</link>
      <pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/consistent-estimator/</guid>
      <description>정의 1 확률변수 $X$ 가 누적분포함수 $F ( x ; \theta), \theta \in \Theta$ 를 가진다고 하자. $X_{1} , \cdots , X_{n}$ 을 $X$ 에서 뽑은 샘플이라고 할 때, 통계량 $T_{n}$ 이 다음을 만족하면 모수 $\theta$ 에 대한 일치추정량Consistent Estimator이라 한다. $$ T_{n} \overset{P}{\to} \theta $$ $\overset{P}{\to}$ 는 확률수렴이다. 예시 $X_{1} , \cdots , X_{n}$ 가 확률분포 $\left( \mu, \sigma^{2} \right)$ 를 따르는 랜덤 샘플, 즉 $X_{1} , \cdots , X_{n} \sim \left( \mu, \sigma^{2} \right)$ 이고 첨</description>
    </item>
    
    <item>
      <title>스튜던트의 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-students-theorem/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-students-theorem/</guid>
      <description>정리 1 확률 변수 $X_{1} , \cdots , X_{n}$ 들이 iid로 정규분포 $N\left( \mu,\sigma^{2} \right)$ 를 따른다고 하면 (a): $$ \overline{X} \sim N\left( \mu , { {\sigma^2} \over {n} } \right) $$ (b): $$ \overline{X} \perp S^2 $$ (c): $$ (n-1) { {S^2} \over {\sigma^2} } \sim \chi^2 (n-1) $$ (d): $$ T = { {\overline{X} - \mu } \over {S / \sqrt{n}} } \sim t(n-1) $$ 표뵨 평균 $\overline{X}$ 과 표본 분산 $S^{2}$ 는 다음과 같이 정의된 확률 변수다. $$ \overline{X} := {{ 1 } \over { n }} \sum_{k=1}^{n} X_{k} \\ S^{2} := {{ 1 } \over { n-1 }} \sum_{k=1}^{n} \left( X_{k} - \overline{X} \right)^{2} $$ 설명 통계학을 하는 사람들은 당연</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution-of-random-vector/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution-of-random-vector/</guid>
      <description>정의1 $p$차원 랜덤 벡터 $\mathbf{X}$ 와 랜덤 벡터의 시퀀스 $\left\{ \mathbf{X}_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $\mathbf{X}_{n}$ 이 $\mathbf{X}$ 로 분포 수렴한다고 말하고, $\mathbf{X}_{n} \overset{D}{\to} \mathbf{X}$ 와 같이 나타낸다. $$\lim_{n \to \infty} F_{\mathbf{X}_{n}} (x) = F_{\mathbf{X}} (x) \qquad, \forall x \in C_{F_{\mathbf{X}}}$$ $F_{X}$ 는 확률변수 $X$ 의 누적분포함수다. $C_{F_{\mathbf{X}}}$ 는 함수 $F_{\mathbf{X}}$ 가 연속인 점들의 집합을 나타낸다. 다변량 중심 극한 정리 $\left\{ \mathbf{X}_{n} \right\}$ 가 평균 벡터 $\mathbf{\mu} \in \mathbb{R}^{p}$ 와 공분산 행렬 $\Sigma \in \mathbb{R}^{p \times p}$ 를 가지고 ii</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability-of-random-vector/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability-of-random-vector/</guid>
      <description>정의 1 $p$차원 랜덤 벡터 $\mathbf{X}$ 와 랜덤 벡터의 시퀀스 $\left\{ \mathbf{X}_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $\mathbf{X}_{n}$ 이 $\mathbf{X}$ 로 확률 수렴Convergence in Probability한다고 말하고, $\mathbf{X} _ {n} \overset{P}{\to} \mathbf{X}$ 와 같이 나타낸다. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left\| \mathbf{X}_{n} - \mathbf{X} \right\| &amp;lt; \varepsilon \right] = 1 $$ $\| \cdot \|$ 는 유클리드 놈으로써, $\left\| \left( x_{1} , \cdots , x_{n} \right) \right\| = \sqrt{ x_{1}^{2} + \cdots + x_{n}^{2}}$ 와 같이 정의된다. 정리</description>
    </item>
    
    <item>
      <title>공분산 행렬</title>
      <link>https://freshrimpsushi.github.io/posts/covariance-matrix/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/covariance-matrix/</guid>
      <description>정의1 $p$차원 랜덤 벡터 $\mathbf{X} = \left( X_{1}, \cdots , X_{p} \right)$ 에 대해 다음과 같이 정의된 $\text{Cov} (\mathbf{X})$ 를 공분산 행렬Covariance Matrix이라 한다. $$ \left( \text{Cov} \left( \mathbf{X} \right) \right)_{ij} := \text{Cov} \left( X_{i} , X_{j} \right) $$ $\text{Cov}$ 는 공분산이다. 설명 정의를 더 쉽게 풀어 적어보면 다음과 같다. $$ \text{Cov} \left( \mathbf{X} \right) := \begin{pmatrix} \text{Var} \left( X_{1} \right) &amp;amp; \text{Cov} \left( X_{1} , X_{2} \right) &amp;amp; \cdots &amp;amp; \text{Cov} \left( X_{1} , X_{p} \right) \\ \text{Cov} \left( X_{2} , X_{1} \right) &amp;amp; \text{Var} \left( X_{2} \right) &amp;amp; \cdots &amp;amp; \text{Cov} \left( X_{2} , X_{p}</description>
    </item>
    
    <item>
      <title>중심극한 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-central-limit-theorem/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-central-limit-theorem/</guid>
      <description>정리 1 ${X_n}$가 iid 확률 변수들이고 확률분포 $\left( \mu, \sigma^2 \right) $를 따른다고 하면 $n \to \infty$ 일 때 $$ \displaystyle \sqrt{n} {{ \overline{X}_n - \mu } \over {\sigma}} \overset{D}{\to} \text{N} (0,1) $$ $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 통계학에선 대수의 법칙과 더불어 정말 그 명성이 자자한 정리로 꼽힌다. 수없이 듣고 쓰는 정리지만 막상 증명은 수리통계학을 배우면서 한번 해볼까말까다. 하지만 실제로는 활용도를 떠나 증명 자체</description>
    </item>
    
    <item>
      <title>약한 대수의 법칙 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-the-weak-law-of-large-numbers/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-the-weak-law-of-large-numbers/</guid>
      <description>법칙 ${X_n}$가 iid 확률 변수들이고 확률분포 $\left( \mu, \sigma^2 \right) $를 따른다고 하면 $n \to \infty$ 일 때 $$ \overline{X}_n \overset{P}{\to} \mu $$ $\overset{P}{\to}$ 는확률 수렴을 의미한다. 설명 이 정리는 그 어떤 분포든 &amp;lsquo;표본평균은 모평균으로 수렴한다&amp;rsquo;는 팩트를 함의한다. 생각해보면 당연할 수도 있지만, 자연과학에서 &amp;lsquo;당연하다&amp;rsquo;는 말만큼 중요한</description>
    </item>
    
    <item>
      <title>분포수렴하면 확률유계다</title>
      <link>https://freshrimpsushi.github.io/posts/if-convergence-in-distribution-then-bounded-in-probability/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-convergence-in-distribution-then-bounded-in-probability/</guid>
      <description>정리 확률변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 분포수렴하면 확률유계다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 앞서 확률수렴하면 분포수렴함을 보였으므로, 이 대우 명제를 생각해보면 &amp;lsquo;확률유계가 아니면 확률수렴하지 않는다&amp;rsquo;는 상식적인 따름정리도 얻을 수 있다. 증명 $\epsilon&amp;gt;0$ 가 주어져 있고 $X_{n}$ 이 확률변수 $X$ 로 분포수렴하며 그 누적분포함수가 $F_{X}$</description>
    </item>
    
    <item>
      <title>확률수렴하면 분포수렴한다</title>
      <link>https://freshrimpsushi.github.io/posts/if-convergence-in-probability-then-convergence-in-distribution/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-convergence-in-probability-then-convergence-in-distribution/</guid>
      <description>정리1 확률변수 $X$ 와 확률변수의 시퀀스 $\left\{ X_{n} \right\}$ 에 대해 $$ X_{n} \overset{P}{\to} X \implies X_{n} \overset{D}{\to} X $$ $\overset{P}{\to}$ 는 확률 수렴을 의미한다. $\overset{D}{\to}$ 는 분포 수렴을 의미한다. 설명 직관적인 단어로 다시 말하자면, 분포만 수렴하는 것이 정확히 수렴하는 것보다는 훨씬 쉽다는 말이다. 확률변수라는 것 자체를 함수로써 정확하게 이해하고 있다면 받아들이기 어렵지 않을 것이다. 증명 전략: 사건을 둘로</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 유계</title>
      <link>https://freshrimpsushi.github.io/posts/bounded-in-probability/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bounded-in-probability/</guid>
      <description>정의 1 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 주어져 있다고 하자. 모든 $\varepsilon &amp;gt; 0$ 에 대해 다음을 만족시키는 $N_{\varepsilon} \in \mathbb{N}$ 과 상수 $B_{\varepsilon} &amp;gt; 0$ 가 존재하면 $\left\{ X_{n} \right\}$ 가 확률 유계Bounded in Probability라고 한다. $$ n \ge N_{\varepsilon} \implies P \left[ \left| X_{n} \right| \le B_{\varepsilon} \right] \ge 1 - \varepsilon $$ 설명 생각해보면 일상생활에서 실제로 접하는 많은 확률 분포 함수들의 정의역이 무한히 넓다. 표준정규분포 $N(0,1)$</description>
    </item>
    
    <item>
      <title>수리통계학에서의 분포 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-distribution/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-distribution/</guid>
      <description>정의 1 확률변수 $X$ 와 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $X_{n}$ 이 $X$ 로 분포 수렴Convergence in Distribution한다고 말하고, $X_{n} \overset{D}{\to} X$ 와 같이 나타낸다. $$ \lim_{n \to \infty} F_{X_{n}} (x) = F_{X} (x) \qquad, \forall x \in C_{F_{X}} $$ $F_{X}$ 는 확률변수 $X$ 의 누적분포함수다. $C_{F_{X}}$ 는 함수 $F_{X}$ 가 연속인 점들의 집합을 나타낸다. 설명 분포 수렴은 확률 수렴과 마찬가지</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 수렴</title>
      <link>https://freshrimpsushi.github.io/posts/convergence-in-probability/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convergence-in-probability/</guid>
      <description>정의 1 확률변수 $X$ 와 확률 변수의 시퀀스 $\left\{ X_{n} \right\}$ 가 다음을 만족하면 $n \to \infty$ 일 때 $X_{n}$ 이 $X$ 로 확률 수렴Convergence in Probability한다고 말하고, $X_{n} \overset{P}{\to} X$ 와 같이 나타낸다. $$ \forall \varepsilon &amp;gt; 0 , \lim_{n \to \infty} P \left[ \left| X_{n} - X \right| &amp;lt; \varepsilon \right] = 1 $$ 설명 확률 수렴의 조건은 수식 그대로 확률의 센스에서 수렴을 정의한 것으로, 쉽게 말해 $n$ 이 커지면 두 확률 변수</description>
    </item>
    
    <item>
      <title>순서통계량</title>
      <link>https://freshrimpsushi.github.io/posts/order-statistiics/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/order-statistiics/</guid>
      <description>정리1 랜덤 샘플 $X_{1} , \cdots , X_{n}$ 가 서포트 $\mathcal{S} =(a,b)$ 인 확률밀도함수 $f(x)$ 를 가지는 연속확률분포를 따른다고 하자. 이들을 크기 순으로 나열한 확률 변수들을 $Y_{1} &amp;lt; \cdots &amp;lt; Y_{n}$ 와 같이 나타내도록 하면 그 조인트, 마지널 확률밀도함수들은 다음과 같다. [1] 조인트: $$ g \left( y_{1} , \cdots , y_{n} \right) = \begin{cases} n! f (y_{1}) \cdots f (y_{n}) &amp;amp;, a &amp;lt; y_{1} &amp;lt; \cdots &amp;lt; y_{n} &amp;lt; b \\ 0 &amp;amp; , \text{elsewhere} \end{cases} $$ [2] 마지널: $Y_{k}$ 의 누적밀도함수</description>
    </item>
    
    <item>
      <title>표본 분산을 n-1으로 나누는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/why-sample-variance-is-divided-by-n-1/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/why-sample-variance-is-divided-by-n-1/</guid>
      <description>왜 n-1로 나누지? $X_{i} \sim \left( \mu , \sigma^{2} \right)$ 이라고 하면 표본 분산 $S^{2}$ 는 다음과 같다. $$ S^{2} := {{1} \over {n-1}} \sum_{i=1}^{n} \left( X_{i} - \overline{X} \right)^{2} $$ 알다시피 표본 평균과 달리 표본 분산은 편차의 제곱을 모두 더한 후 표본 크기인 $n$ 이 아니라 $n-1$ 로 나눈다. 당연히 이를 이상하게 느껴야한다고는 말하지 않겠지만, 수식에 대한 보편적인 감성이 있다면 $n$ 개를 더하고 $n-1$ 로 나누는 것에서 강렬한 띠꺼움을 느</description>
    </item>
    
    <item>
      <title>불편추정량</title>
      <link>https://freshrimpsushi.github.io/posts/unbiased-estimator/</link>
      <pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unbiased-estimator/</guid>
      <description>정의 1 $\theta$ 의 추정량 $T$ 가 다음을 만족하면 $T$ 를 $\mu$ 의 불편추정량Unbiased Estimator이라고 한다. $$ E T = \theta $$ 설명 특히 $\theta$ 에 대한 불편추정량 중 가장 분산이 작은 경우 최소분산불편추정량Mimimum Variance Unbiased Estimator, MVUE이라고 한다. 불편성이란 편의를 가지지 않는 성질을 말한다. 가령 $X_{i} \sim \left( \mu , \sigma^{2} \right)$ 라고 할 때 $\mu$ 의 추정량으로써 표본</description>
    </item>
    
    <item>
      <title>편의-분산 트레이드 오프</title>
      <link>https://freshrimpsushi.github.io/posts/bias-variance-trade-off/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bias-variance-trade-off/</guid>
      <description>정의 $$ \text{MSE} \left( \widehat{\theta} \right) = \text{Var} \widehat{\theta} + \left( \text{Bias} \widehat{\theta} \right)^{2} $$ 설명 평균제곱오차 $\text{MSE}$ 는 통계 모형의 평가나 머신 러닝에서의 손실 함수로써 즐겨쓰이는 척도로써, 특히 편의와 분산에 대한 트레이드 오프로 나타난다.통계학도에게 있어서 편의를 다루는 것은 다소 어색할지 모르겠다. 적절한 확률 분포를 가정하고 그에 따른 수학적 이론을 토대로 데이터를 다루는 입장에서 분산은 손에 잡힐</description>
    </item>
    
    <item>
      <title>수리통계학에서의 편의</title>
      <link>https://freshrimpsushi.github.io/posts/bias-in-mathematical-statistiics/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bias-in-mathematical-statistiics/</guid>
      <description>정의 모수 $\theta$ 에 대한 추정량 $\widehat{\theta}$ 에 대해 다음과 같이 정의된 $\text{Bias}$ 를 편의라 한다. $$ \text{Bias} ( \theta ) = E(\widehat{\theta}) - \theta $$ 설명 Bias는 편의 또는 편향으로 순화되지만, 역시 가장 많이 쓰이는 말은 발음 그대로 읽은 [바이어스]다. 한국어에서 편의는 Convenience인 경우가 압도적으로 많고 수식적으로나 실제 쓰임새로나 &amp;lsquo;편향&amp;rsquo;으로 순</description>
    </item>
    
    <item>
      <title>신뢰구간의 쉬운 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-confidence-interval/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-confidence-interval/</guid>
      <description>정의 1 확률 밀도 함수 $f (x; \theta)$ 를 가지는 확률 변수 $X$ 의 샘플 $X_{1} , \cdots , X_{n}$ 와 신뢰 계수Confidence Coefficient $\alpha \in (0,1)$ 가 주어져 있다고 하자. $$ L := L \left( X_{1} , \cdots , X_{n} \right) \\ U := U \left( X_{1} , \cdots , X_{n} \right) $$ 통계량 $L &amp;lt; U$ 가 위와 같이 정의되어있다고 할 때, 다음을 만족하는 구간 $(L,U) \subset \mathbb{R}$ 을 모수 $\theta$ 에 대한 $( 1 - \alpha)100 \%$ 신뢰구간이라 한다. $$ 1-\alpha = P \left[ \theta \in \left( L,U \right) \right] $$ 설명 사</description>
    </item>
    
    <item>
      <title>수리통계학에서의 통계량과 추정량</title>
      <link>https://freshrimpsushi.github.io/posts/statistiic-and-estimator/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statistiic-and-estimator/</guid>
      <description>정의 12 확률 변수 $X$ 의 샘플 $X_{1} , \cdots , X_{n}$ 의 함수 $T$ 를 통계량statistiic이라 한다. $$ T := T \left( X_{1} , \cdots , X_{n} \right) $$ $X$ 의 분포 함수가 $f(x; \theta)$ 혹은 $p(x; \theta)$ 와 같이 나타날 때, $T$ 가 $\theta$ 를 파악하기 위한 통계량이면 $T$ 를 $\theta$ 의 추정량Estimator이라고 한다. 통계량의 확률분포를 샘플링 분포Sampling Distribution라 한다. 설명 2:</description>
    </item>
    
    <item>
      <title>수리통계학에서의 랜덤 샘플</title>
      <link>https://freshrimpsushi.github.io/posts/random-sample/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-sample/</guid>
      <description>정의 1 확률 변수 $X$ 가 실제로 뽑힌 것을 실현Realization이라 하고 보통 소문자 $x$ 로 나타낸다. 확률 변수 $X$ 와 같은 확률 분포에서 샘플 사이즈Sample Size $n$ 만큼 얻어낸 확률 변수들을 샘플Sample이라 하고 다음과 같이 나타낸다. $$ X_{1} , X_{2} , \cdots , X_{n} $$ 확률 변수 $X_{1} , \cdots , X_{n}$ 이 iid면 사이즈 $n$ 의 랜덤 샘플이라 부른다. 설명 이러한 정의</description>
    </item>
    
    <item>
      <title>확률 변수들의 선형 결합</title>
      <link>https://freshrimpsushi.github.io/posts/linear-combinations-of-random-variable/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-combinations-of-random-variable/</guid>
      <description>정의 1 확률 변수 $X_{1} , \cdots , X_{n}$ 가 어떤 $(a_{1}, \cdots , a_{n}) \in \mathbb{R}^{n}$ 에 대해 $\displaystyle T := \sum_{i=1}^{n} a_{i} X_{i}$ 를 선형 결합Linear Combinations이라고 한다. 설명 특히 $X_{1} , \cdots , X_{n}$ 이 iid면 사이즈 $n$ 의 **랜덤 샘플Random Sample**이라도 부른다. 통계학의 맥락이라면 모든 관측값에 같은 가중치가 곱해진 $a_{1} = \cdots = a_{n} = {{ 1 } \over { n } }$ 을 생각할 것이다</description>
    </item>
    
    <item>
      <title>정규분포를 따르는 두 확률 변수가 독립인 것과 공분산이 0인 것은 동치다</title>
      <link>https://freshrimpsushi.github.io/posts/two-normal-distributions-are-independent-iff-their-covariance-is-equal-to-zero/</link>
      <pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/two-normal-distributions-are-independent-iff-their-covariance-is-equal-to-zero/</guid>
      <description>정리 $$ X_{1} \sim N ( \mu_{1} , \sigma_{1} ) \\ X_{2} \sim N ( \mu_{2} , \sigma_{2} ) $$ 면 $$ X_{1} \perp X_{2} \iff \text{cov} (X_{1} , X_{2} ) = 0 $$ 설명 일반적으로 상관관계가 없다고 독립인 것은 아니다. 하지만 분포들이 정규분포를 따른다는 가정이 있다면 공분산이 $0$ 인 것이 독립임을 보장해준다. 증명 $( \Rightarrow )$ $$ \displaystyle M_{X_{1}} (t_{1} ) = \exp \left[ \mu_{1} t_{1} + {{1} \over {2}} \sigma_{1} t_{1}^{2} \right] M_{X_{2}} (t_{2} ) = \exp \left[ \mu_{2} t_{2} + {{1} \over {2}} \sigma_{2} t_{2}^{2} \right] $$ $\sigma_{12} : = \text{cov} (X_{1} , X_{2} )$ 그리고 $\sigma_{21} :</description>
    </item>
    
    <item>
      <title>번스타인 분포: 짝으로 독립이라고 상호 독립은 아니다</title>
      <link>https://freshrimpsushi.github.io/posts/bernstein-distribution/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bernstein-distribution/</guid>
      <description>정의 $(x,y,z) \in \left\{ (1,0,0), (0,1,0), (0,0,1), (1,1,1) \right\}$ 에 대해 다음과 같은 확률질량함수를 가지는 분포를 번스타인 분포Bernstein Distribution라고 한다. $$ p(x,y,z) = {{1} \over {4} } $$ 설명 번스타인 분포는 분포의 조건을 모두 만족시키고는 있지만 자연계에 실재하는 분포라고 보기는 어렵다. &amp;lsquo;짝으로 독립이면 상호 독립이다&amp;rsquo;라는 명제의 반례</description>
    </item>
    
    <item>
      <title>확률 변수들의 상호 독립과 iid</title>
      <link>https://freshrimpsushi.github.io/posts/mutual-independence-and-iid-independent-and-identically-distributed/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mutual-independence-and-iid-independent-and-identically-distributed/</guid>
      <description>정의 1 확률 변수 $X_{1} , \cdots , X_{n}$ 가 다음을 만족하면 $X_{1} , \cdots , X_{n}$ 이 짝으로 독립Pairwise Independent이라 한다. $$ i \ne j \implies X_{i} \perp X_{j} $$ 연속 확률 변수 $X_{1} , \cdots , X_{n}$ 의 조인트 확률 밀도 함수 $f$ 가 각각의 확률 밀도 함수 $f_{1} , \cdots , f_{n}$ 에 대해 다음을 만족하면 $X_{1} , \cdots , X_{n}$ 가 상호 독립이라 한다. $$ f(x_{1} , \cdots , x_{n} ) \equiv f_{1} (x_{1}) \cdots f_{n} (x_{n}) $$ 이산 확률 변수 $X_{1} , \cdots ,</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 변수의 독립</title>
      <link>https://freshrimpsushi.github.io/posts/independence-of-random-variable/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independence-of-random-variable/</guid>
      <description>정의 1 두 확률 변수 $X_{1}, X_{2}$ 의 조인트 확률 밀도 함수 $f$ 혹은 확률 질량 함수 $p$ 에 대해 $X_{1}, X_{2}$ 의 확률 밀도 함수들 $f_{1}, f_{2}$ 혹은 확률 질량 함수 $p_{1}, p_{2}$ 가 다음을 만족하면 $X_{1}, X_{2}$ 가 독립이라 하고, $X_{1} \perp X_{2}$ 와 같이 나타낸다. $$ f(x_{1} , x_{2} ) \equiv f_{1}(x_{1})f_{2}(x_{2}) \\ p(x_{1} , x_{2} ) \equiv p_{1}(x_{1})p_{2}(x_{2}) $$ 정리 아래의 정리는 이산 확률 변수에 대해서도 같지만, 편의상 연속 확률 변수인 경우만 언급한다. 다음은 모두 동치다. [1]:</description>
    </item>
    
    <item>
      <title>수리통계학에서의 조건부 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/conditional-probability/</link>
      <pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conditional-probability/</guid>
      <description>정의 이산 확률 변수 $X_{1}, X_{2}, \cdots , X_{n}$ 에 대해 다음의 $p_{2, \cdots , n \mid 1}$ 를 $X_{1} = x_{1}$ 이 주어졌을 때의 $ X_{2}, \cdots , X_{n}$ 의 조인트 조건부 확률 질량 함수라고 한다. $$ p_{2, \cdots , n \mid 1} ( x_{2} , \cdots ,x_{n} \mid X_{1} = x_{1} ) = {{ p_{1, \cdots , n}(x_{1} , x_{2} , \cdots , x_{n}) } \over { p_{1}( X_{1} = x_{1} ) }} $$ 연속 확률 변수 $X_{1}, X_{2}, \cdots , X_{n}$ 에 대해 다음의 $f_{2, \cdots , n \mid 1}$ 를 $X_{1} = x_{1}$ 이 주어졌을 때의 $ X_{2}, \cdots , X_{n}$ 의 조인트 조건부 확률 밀도 함수</description>
    </item>
    
    <item>
      <title>다변량 확률 변수의 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transform-of-random-variable/</link>
      <pubDate>Fri, 17 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transform-of-random-variable/</guid>
      <description>공식 다변량 확률 변수 $X = ( X_{1} , \cdots , X_{n} )$ 의 조인트 확률밀도함수 $f$ 가 $f(x_{1} , \cdots , x_{n})$ 와 같이 주어져있다고 하고 다음과 같은 변환을 생각해보자. $$ y_{1} = u_{1} (x_{1} , \cdots , x_{n}) \\ \vdots \\ y_{n} = u_{n} (x_{1} , \cdots , x_{n}) $$ 이러한 변환 $u_{1} , \cdots , u_{n}$ 는 단사가 아닐 수 있다. 따라서 $X$ 의 서포트 $S_{X}$ 는 $k$ 개의 파티션 $A_{1} , \cdots , A_{i} , \cdots , A_{k}$ 으로 나누어지고, 다음과 같은 역변환 $w_{ji} \mid_{i=1,\cdots,k \\ j=1,\cdots,n}$ 들을 생각</description>
    </item>
    
    <item>
      <title>수리통계학에서의 다변량 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/multivariate-distribution/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multivariate-distribution/</guid>
      <description>정의 1 표본 공간 $\Omega$ 에서 정의된 $n$ 개의 확률 변수 $X_{i}$ 에 대해 $X = (X_{1} , \cdots , X_{n})$ 를 $n$차원 랜덤 벡터Random Vector라고 한다. $X$ 의 치역 $X(\Omega)$ 를 공간이라고도 부른다. 다음을 만족하는 함수 $F_{X} : \mathbb{R}^{n} \to [0,1]$ 을 $X$ 의 조인트Joint 누적 분포 함수라고 한다. $$ F_{X}\left( x_{1}, \cdots , x_{n} \right) := P \left[ X_{1} \le x_{1} , \cdots , X_{n} \le x_{n} \right] $$ 어떤 $h_{1} , \cdots , h_{n} &amp;gt;0$ 들에 대해 다음을 만족하는</description>
    </item>
    
    <item>
      <title>n차 적률이 존재하면 차수가 n보다 작은 적률도 존재한다</title>
      <link>https://freshrimpsushi.github.io/posts/if-nth-moment-exists-then-moments-with-less-degree-are-exist/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/if-nth-moment-exists-then-moments-with-less-degree-are-exist/</guid>
      <description>정리 확률변수 $X$와 자연수 $n$ 에 대해 $E( X^n )$ 이 존재하면 $E( X^m ), m=1,2,3,\cdots, n$ 도 존재한다. 설명 어떤 차수의 적률이든 존재하기만 한다면 그보다 작은 차수의 적률은 항상 존재하지만, 당연히 역은 성립하지 않는다. 물론 실제로 문제를 접해보면 높은 차수의 적률이 먼저 주어지는 경우는 거의 없으나, 어떤 정리의 조건을 나열할 때 지면을 상당히 절약할 수 있게 해주는 정</description>
    </item>
    
    <item>
      <title>적률생성함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/moment-generating-function/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-generating-function/</guid>
      <description>정의 1 확률변수 $X$ 와 어떤 양수 $h&amp;gt;0$ 대해 $E(e^{tX})$ 이 $-h&amp;lt; t &amp;lt; h$ 에서 존재하면 $M(t) = E( e^{tX} )$ 를 $X$ 의 적률생성함수Moment Generating Function라고 정의한다. 설명 적률생성함수는 흔히 mgf라는 약어로 많이 쓰인다. 수리통계학에서는 비교적 초반에 배우는데, 생소한 정의와 맥락 없는 등장 때문에 수리통계학을 싫어지게 만드는 주범 중 하나다. 적률생성함수를</description>
    </item>
    
    <item>
      <title>수리통계학에서의 첨도</title>
      <link>https://freshrimpsushi.github.io/posts/kurtosis/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kurtosis/</guid>
      <description>첨도 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{2}$ 를 $X$ 의 첨도kurtosis라고 한다. $$ \gamma_{2} := {{ E \left( X - \mu \right)^4 } \over { \sigma^4 }} $$ 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본첨도 $g_{2}$ 는 다음과 같이 구해진다. $$ g_{2} := \sum_{i=1}^{n} = {{ \left( X - \overline{X} \right)^4 } \over { n \widehat{\sigma}^4 }} - 3 $$ 설명 첨도는 4차 적률로 구해지며, 확률변수의 분포함수가 얼마</description>
    </item>
    
    <item>
      <title>수리통계학에서의 왜도</title>
      <link>https://freshrimpsushi.github.io/posts/skewness/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/skewness/</guid>
      <description>정의 확률변수 $X$ 의 평균이 $\mu$, 분산이 $\sigma^2$ 라고 할 때 다음과 같이 정의된 $\gamma_{1}$ 를 $X$ 의 왜도Skewness라고 한다. $$ \gamma_{1} := {{ E \left( X - \mu \right)^3 } \over { \sigma^3 }} $$ 데이터 $\left\{ X_{i} \right\}_{i}^{n}$ 의 표본평균이 $\overline{X}$, 표본분산이 $\widehat{\sigma}^2$ 이라고 할 때 표본왜도 $g_{1}$ 은 다음과 같이 구해진다. $$ g_{1} := \sum_{i=1}^{n} {{ \left( X - \overline{X} \right)^3 } \over { n \widehat{\sigma}^3 }} $$ 설명 왜도는 3차 적률로 구해지며, 확률변수의 분포함수가 어떻게 치우</description>
    </item>
    
    <item>
      <title>공분산의 여러가지 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-covariance/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-covariance/</guid>
      <description>정의와 성질 평균이 각각 $\mu_{X}$, $\mu_{Y}$ 인 확률 변수 $X$, $Y$ 에 대해 $\text{Cov} (X ,Y) : = E \left[ ( X - \mu_{X} ) ( Y - \mu_{Y} ) \right]$ 을 $X$ 와 $Y$ 의 공분산Covariance이라고 정의한다. 공분산은 아래의 성질들을 가진다. [1]: $\text{Var} (X) = \text{Cov} (X,X)$ [2]: $\text{Cov} (X,Y) = \text{Cov} (Y, X)$ [3]: $\text{Var} (X + Y) = \text{Var} (X) + \text{Var} (Y) + 2 \text{Cov} (X,Y) $ [4]: $\text{Cov} (X + Y , Z ) = \text{Cov}(X,Z) + \text{Cov}(Y,Z) $ [5]: $\text{Cov} (aX + b , cY + d ) = ac \text{Cov}(X,Y) $ 설명 공분산은 두 변수의 선형상</description>
    </item>
    
    <item>
      <title>피어슨 상관계수</title>
      <link>https://freshrimpsushi.github.io/posts/pearson-correlation-coefficient/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pearson-correlation-coefficient/</guid>
      <description>정의 1 다음과 같이 정의된 $\rho = \rho(X,Y)$ 를 피어스 상관계수라고 한다. $$ \rho = { {\text{Cov} (X,Y)} \over {\sigma_X \sigma_Y} } $$ 설명 (피어슨) 상관 계수(Pearson) Correlation Coefficient는 두 변수가 서로 (선형) 상관 관계 를 가지고 있는지를 확인하는 척도가 된다. $1$ 이나 $–1$ 에 가까우면 상관관계가 있다고 보고 $0$ 이면 없다고 본다. 주의할 것은 상관관계와 독립이 같은 개</description>
    </item>
    
    <item>
      <title>평균과 분산의 성질들</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-mean-and-variance/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-mean-and-variance/</guid>
      <description>정리 평균 $E ( X ) = \mu_{X}$ 과 분산 $\text{Var} (X) = E [ ( X - \mu_{X} )^2 ]$ 은 아래의 성질들을 가진다. [1]: $E(X + Y) = E(X) + E(Y)$ [2]: $E(aX + b) = a E(X) + b$ [3]: $\text{Var} (X) \ge 0$ [4]: $\text{Var} ( X ) = E(X^2) - \mu_{X}^2$ [5]: $\text{Var} (aX + b) = a^2 \text{Var} (X)$ 설명 평균과 분산에 관한 것이니만큼 아주 중요한 성질들이다. 특히 [1]과 [2]는 이른바 선형성Linearity이라 불리우는 성질로써, 수식을 다룰 때 무척 편리하게</description>
    </item>
    
    <item>
      <title>대표값의 수리적 성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-mathematical-property-of-representative-value/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-mathematical-property-of-representative-value/</guid>
      <description>정리 데이터 $X = \left\{ x_{1} , \cdots , x_{n} \right\}$ 가 주어져 있다고 하자. [0]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{0}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{mode}(X) $$ [1]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{1}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{median}(X) $$ [2]: $\displaystyle h(\theta)=\sum_{i=1}^{n} {|x_i - \theta|}^{2}$ 가 최소가 되도록 하는 $\theta$ 는 $$ \argmin_{\theta} h \left( \theta \right) = \text{mean}(X) $$ 설명 선형대수의 용어로 어렵게 말해보자면 다음과 같다: [0]: $l^{0}$-놈을 최소화하는 것은 최빈값이다.</description>
    </item>
    
    <item>
      <title>수리통계학에서의 기대값, 평균, 분산, 적률의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-mean-variance-moment/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-mean-variance-moment/</guid>
      <description>정의: 기대값, 평균, 분산 확률 변수 $X$ 가 주어져 있다고 하자. 연속 확률 변수 $X$ 의 확률 밀도 함수 $f(x)$ 가 $\displaystyle \int_{-\infty}^{\infty} |x| f(x) dx &amp;lt; \infty$ 를 만족하면 다음과 같이 정의된 $E(X)$ 를 $X$ 의 기대값Expectation이라고 한다. $$ E(X) := \int_{-\infty}^{\infty} x f(x) dx $$ 이산 확률 변수 $X$ 의 확률 질량 함수 $p(x)$ 가 $\displaystyle \sum_{x} |x| p(x) &amp;lt; \infty$ 를 만족하면 다음과 같이 정의된 $E(X)$ 를 $X$ 의 기대값Expectation이라</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률 변수와 확률 분포</title>
      <link>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution/</link>
      <pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/random-variable-and-probability-distribution/</guid>
      <description>정의 1 표본 공간 $\Omega$ 에서 확률 $P$ 가 정의되어 있다고 하자. 정의역이 표본 공간인 함수 $X : \Omega \to \mathbb{R}$ 을 확률 변수Random Variable라고 한다. 확률 변수의 치역 $X(\Omega)$ 을 공간Space이라고도 부른다. 다음을 만족하는 함수 $F_{X} : \mathbb{R} \to [0,1]$ 을 $X$ 의 누적분포함수(Cummulative Distribution Function, cdf) 라 한다. $$ F_{X}(x) = P_{X}\left( (-\infty,x] \right) = P \left( \left\{ \omega \in \Omega : X(\omega) \le x \right\} \right) $$</description>
    </item>
    
    <item>
      <title>수리통계학에서의 확률과 확률의 덧셈법칙</title>
      <link>https://freshrimpsushi.github.io/posts/probability-and-additive-law-of-probability/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/probability-and-additive-law-of-probability/</guid>
      <description>정의 1 같은 조건 하에서 반복할 수 있는 시행을 임의 시행Random Experiment이라고 한다. 임의 시행에서 얻을 수 있는 모든 결과Outcome를 모아놓은 집합 $\Omega$ 를 표본 공간Sample Space이라고 한다. 표본 공간에서 우리가 관심을 가지는 결과들의 집합, 즉 $B \subset \Omega$ 를 사건Event이라 하고 이들의 집합을 $\mathcal{B}$ 와 같이 나타낸다.</description>
    </item>
    
    <item>
      <title>베이즈 인자를 통한 가설검정</title>
      <link>https://freshrimpsushi.github.io/posts/statistiical-hypothesis-test-by-bayes-factor/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statistiical-hypothesis-test-by-bayes-factor/</guid>
      <description>빌드업 고전적인 가설검정을 쓸 수 있게 되려면 기각역, 유의확률과 같은 개념에 대한 수학적인 이해를 포함해서 이를 직관적으로 받아들일 수 있을 정도의 통계학적 센스까지 갖추어야한다. 학부 1학년 교양 수준에서도 몇 시간이나 할애해가며 가르치고, 그래도 가설검정을 제대로 받아들이지 못하는 학생이 수두룩한 것도 당연한 일이다. 고등학교에서 배우는 통</description>
    </item>
    
    <item>
      <title>최고사후밀도 신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</guid>
      <description>정의 1 모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $C : = \left\{ \theta \in \Theta \ | \ p ( \theta | y ) \ge k (\alpha) \right\}$ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 최고사후밀도 신용구간HPD이라고 한다. 여기서 $k(\alpha)$ 는 $p(\theta \in C | y ) \ge 1 - \alpha$ 를 만족하는 가장 큰 상수다. 설명 수식과 말보다는 그림을 통해 보는게 훨씬 이해하기 좋다. 실제 계산에서도 위와 같이 $k$ 를 계</description>
    </item>
    
    <item>
      <title>신용구간과 신뢰구간의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</guid>
      <description>요약 신용구간과 신뢰구간의 차이는 실로 베이지안과 프리퀀티스트의 차이라고 볼 수 있다. 신뢰구간(프리퀀티스트): 모수는 고정된 상수고, 신뢰구간이 랜덤으로 구해진다. 신용구간(베이지안): 모수도 분포를 가진 변수고, 신용구간도 사후분포로 구해진다. 신뢰구간 고전통계에서 모수 $\mu$ 에 대한 $95 \% $ 신뢰구간 $[a , b]$ 이 의미하는 것은 같은 방법</description>
    </item>
    
    <item>
      <title>신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval/</guid>
      <description>정의 1 모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $P ( \theta \in C | y ) \ge 1 - \alpha$ 를 만족할 때, $C$ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 신용구간Credible Interval이라고 한다. 설명 베이지안에서의 구간추정이란 모수 $\theta$ 를 포함하는 확률이 높은 구간을 찾는 것이다. 이로써 찾아지는 &amp;lsquo;신용구간&amp;rsquo</description>
    </item>
    
    <item>
      <title>통계학의 세가지 대표값: 최빈값, 중앙값, 평균</title>
      <link>https://freshrimpsushi.github.io/posts/mode-median-mean/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mode-median-mean/</guid>
      <description>개요 대표값은 데이터를 설명하는 대표적인 값을 말한다. 수천 수만에 달하는 데이터가 있어도 일일이 다 살펴볼 게 아니라면 결국 중요한 것은 데이터가 무엇을 의미하느냐고, 대표값은 이를 효과적으로 요약한다. 그 중 가장 자주 쓰이는 세가지 대표값으로써 최빈값, 중앙값, 평균이 있다. (0) 최빈값: 표본에서 가장 자주 발생한 값 (1) 중앙값: 표본에서 중앙에 위</description>
    </item>
    
    <item>
      <title>제프리 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/jeffreys-prior/</link>
      <pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jeffreys-prior/</guid>
      <description>정의 1 자료의 분포 $p( y | \theta)$ 에 대해 $\pi ( \theta ) \propto I^{1/2} ( \theta )$ 를 제프리 사전분포Jeffreys Prior라 한다. $I$ 는 피셔정보Fishser Information를 의미한다. $$ I ( \theta ) = E \left[ \left( \left. {{\partial \ln p (y | \theta) } \over {\partial \theta}} \right)^2 \right| \theta \right] = E \left[ \left. - {{\partial^2 \ln p (y | \theta) } \over { (\partial \theta )^2 }} \right| \theta \right] $$ 설명 라플라스 사전분포 $\pi (\theta) \propto 1$ 는 모수 $\theta$ 의 사전분포로써</description>
    </item>
    
    <item>
      <title>라플라스 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-prior/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-prior/</guid>
      <description>빌드업 모수에 대한 정보가 거의 없다면 구태여 복잡한 사전분포를 생각할 이유는 없다. 내년 모 대학의 통계학과 신입생의 성비를 추측해보라고 했을 때, 통계학과를 어느정도 아는 사람이라면 예년의 성비를 보고 어느정도 짐작을 하겠지만 전혀 관계도 없고 관심도 없는 사람이 이 질문을 들었을 땐 특별한 이유가 없는 한 50:50이라고 추측할 것이다. 어떤 주머니</description>
    </item>
    
    <item>
      <title>켤레사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/conjugate-prior/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conjugate-prior/</guid>
      <description>정의 1 사전분포와 사후분포가 동일한 분포족에 속하면 사전분포를 켤레사전분포Conjugate Prior 혹은 공액사전분포라고 한다. 설명 베이지안이란 본래 사전분포가 어떻게 되든 업데이트를 통해 모수를 찾아가는 것이긴 하지만, 모형에 대해 어느정도 아는 바가 있다면 적절한 사전분포를 사용함으로써 수학적 계산을 간단하게 하고 결과를 이해하기 쉽게 할</description>
    </item>
    
    <item>
      <title>라플라스 계승 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</guid>
      <description>정리 1 이항모형 $\displaystyle p(y | \theta) = \binom{ n }{ y} \theta^{y} (1- \theta)^{n-y}$ 의 사전분포가 일양 분포 $U (0,1)$ 를 따르고 사후분포가 베타 분포 $\beta (y+1 , n-y+1)$ 을 따라 $p( \theta | y ) \sim \theta^{y} (1- \theta)^{n-y}$ 이라고 하자. 그러면 이제까지 얻은 데이터 $y$ 에 대해 새로운 $\tilde{y}$ 가 $1$ 일 확률은 $$ p(\tilde{y} = 1| y) = {{y+1} \over {n+2}} $$ 설명 프리퀀티스트의 관점으로 보았을 때 $\tilde{y} = 1$ 일 확률은 그 표본비율 $\displaystyle {{y} \over {n}}$ 에 가까울 것이다. 그런데 기본적으</description>
    </item>
    
    <item>
      <title>베이지안 패러다임</title>
      <link>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</guid>
      <description>빌드업 통계학이란 &amp;lsquo;모수를 파악하는 방법을 연구하는 학문&amp;rsquo;이라고 할 수 있다. 어떤 물리량을 측정하는 것처럼 공식이나 법칙을 통해 정확하게 모수를 추정할 수 있다면 더할나위 없지만, 현실적으로 그게 불가능하기 때문에 가정과 표본을 이용해 &amp;lsquo;모수로 예상되는 것&amp;rsquo;을 찾아낼 뿐이다. 우리나라 남성</description>
    </item>
    
    <item>
      <title>베이즈 정리로 보는 몬티홀 딜레마</title>
      <link>https://freshrimpsushi.github.io/posts/monty-hall-dilemma/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monty-hall-dilemma/</guid>
      <description>설명 알다시피 몬티홀 게임은 실제로 경품이 어디있든 관계 없이 선택을 바꾸는 것이 유리하다. 이것을 팩트로써 받아들이냐와 별개로 몬티홀 게임을 직관적으로 이해하지 못했거나 수식적인 표현이 서툰 사람들이 있다. 편의상 본인이 플레이어고, 1번 문을 선택했다고 생각해보자. 이 때 우리는 경품에 대한 어떤 정보도 없기에, 어떤 번호든 선택할 확률은 같다고</description>
    </item>
    
    <item>
      <title>몬테카를로 방법과 부트스트랩의 차이점</title>
      <link>https://freshrimpsushi.github.io/posts/difference-between-monte-carlo-method-and-bootstrap/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference-between-monte-carlo-method-and-bootstrap/</guid>
      <description>개요 몬테카를로 방법은 작위적인 데이터로 시뮬레이션을 반복해 새로운 기법을 확인하는 방법이고 부트스트랩은 실제 데이터에서 재표본 추출을 통해 비용을 절감하며 문제를 해결하려는 방법이다. 정의 몬테카를로 방법Monte Carlo Method이란 난수 추출을 통해 관심 있는 대상에 대해 점추정량을 찾는 방법이다. 부트스트랩Bootstrap이란 표</description>
    </item>
    
    <item>
      <title>표본표준편차와 표준오차의 구분</title>
      <link>https://freshrimpsushi.github.io/posts/how-different-between-sample-standard-deviation-and-standard-error/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-different-between-sample-standard-deviation-and-standard-error/</guid>
      <description>정의 $X$ 로부터 얻은 데이터를 $\mathbb{x} = ( x_{1}, x_{2}, \cdots , x_{n} )$ 라고 하자. 표본평균: $$ \overline{x} = {{1} \over {n}} \sum_{i=1}^{n} x_{i} $$ 표본표준편차: $$ s_{x} = \sqrt { {{1} \over {n-1}} \sum_{i=1}^{n} ( x_{i} - \overline{x} )^2 } $$ 표준오차: $$ \text{s.e.}( \hat{x} ) = {{ s_{x} } \over { \sqrt{n} }} $$ 설명 말이 비슷해서인지 의외로 많은 사람들이 표본표준편차와 표준오차를 구분하지 못한다. 사실상 통계를 글로만 배우는 고등학생들은 물론이고 심하게는 통계학과</description>
    </item>
    
    <item>
      <title>특정한 분포를 따르는 확률변수들의 덧셈 총정리</title>
      <link>https://freshrimpsushi.github.io/posts/sum-of-some-probability-distribution/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sum-of-some-probability-distribution/</guid>
      <description>정리 확률 변수 $X_{1} , \cdots , X_{n}$ 들이 상호 독립이라고 하자. [1] 이항 분포: $X_i \sim \text{Bin} ( n_{i}, p)$ 이면 $$ \displaystyle \sum_{i=1}^{m} X_{i} \sim \text{Bin} \left( \sum_{i=1}^{m} n_{i} , p \right) $$ [2] 푸아송 분포: $X_i \sim \text{Poi}( m_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \text{Poi} \left( \sum_{i=1}^{n} m_{i} \right) $$ [3] 감마 분포: $X_i \sim \Gamma( k_{i}, \theta)$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \Gamma \left( \sum_{i=1}^{n} k_{i} , \theta \right) $$ [4] 카이제곱 분포: $X_i \sim \chi^2 ( r_{i} )$ 이면 $$ \displaystyle \sum_{i=1}^{n} X_{i} \sim \chi ^2 \left( \sum_{i=1}^{n} r_{i} \right) $$ [5] 정규 분포: $X_i \sim N( \mu_{i}, \sigma_{i}^{2} )$ 이면 주어진 벡터 $(a_{1} ,</description>
    </item>
    
    <item>
      <title>베이즈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</guid>
      <description>정리 1 표본공간 $S$ 와 사건 $A$ 에 대해서 ${S_1,S_2,&amp;hellip;,S_n}$ 가 $S$ 의 분할이면 $$ P(S_k|A)=\frac { P(S_k)P(A|S_k) }{ \sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$ 설명 혹은 베이즈 법칙으로도 불리는 이 정리는 두개의 법칙만 쓰면 될 정도로 쉽게 증명할 수 있으나 그 응용은 어마어마하다. 이른바 베이지안 패러다임은 통계학 자체를 양분하는 사고방식으로써, 그 중요도는 몇 번을 강조해도 부족함이 없다. 우리가 알고 싶은 것은 위 식</description>
    </item>
    
    <item>
      <title>유니모달 분포의 최단 신뢰구간</title>
      <link>https://freshrimpsushi.github.io/posts/shortest-confidence-interval-of-unimodal-distribution/</link>
      <pubDate>Thu, 07 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/shortest-confidence-interval-of-unimodal-distribution/</guid>
      <description>정리 유니모달 함수의 정의 함수 $f : \mathbb{R} \to \mathbb{R}$ 이 $x \le x^{\ast}$ 에서 감소하지 않고, $x \ge x^{\ast}$ 에서 증가하지 않게끔 하는 모드Mode $x^{\ast}$ 가 존재하면 $f$ 를 유니모달Unimodal하다고 한다. 특히 $f$ 의 확률밀도함수가 유니모달하면 그 확률분포를 유니모달 분포라 부르자. 가장 짧은 신뢰구간 $f(x)$ 가 유니모달 확률밀도함수라 하자. 구간 $[a,b]$ 가 다음 세 조건 (i): $\displaystyle \int_{a}^{b} f(x) dx =</description>
    </item>
    
    <item>
      <title>확률적 증감함수와 신뢰구간</title>
      <link>https://freshrimpsushi.github.io/posts/stochastic-increasing-and-confidence-interval/</link>
      <pubDate>Sun, 03 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stochastic-increasing-and-confidence-interval/</guid>
      <description>정리 1 확률적 증감함수의 정의 누적분포함수 $F \left( t ; \theta \right)$ 가 $\theta$ 에 대해 증가(감소) 함수면 확률적 증가(감소) 함수Stochastic Increasing(Decreasing)라 한다. 연속누적분포함수의 피버팅Pivoting a continusous cdf 통계량 $T$ 가 연속누적분포함수 $F_{T} \left( t ; \theta \right)$ 를 가진다고 하자. 픽스된 $\alpha \in (0,1)$ 에 대해 $\alpha_{1} + \alpha_{2} = \alpha$</description>
    </item>
    
    <item>
      <title>최정확 신뢰집합</title>
      <link>https://freshrimpsushi.github.io/posts/uniformly-most-accurate-confidence-set/</link>
      <pubDate>Wed, 30 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniformly-most-accurate-confidence-set/</guid>
      <description>정의 1 $\theta$ 에 대한 가설검정의 $1 - \alpha$ 신뢰집합을 $C \left( \mathbf{x} \right)$ 이라 하고, 채택역을 $A \left( \theta \right) = C \left( \mathbf{x} \right)^{c}$ 이라 하자. $P_{\theta} \left( \theta&#39; \in C \left( \mathbf{X} \right) \right)$ 를 $\theta&#39; \ne \theta$ 에 대한 펄스 커버리지False Coverage 확률이라 한다. 원래의 커버리지 확률 $P_{\theta} \left( \theta \in C \left( \mathbf{X} \right) \right)$ 을 이와 대비되는 표현인 트루 커버리지True Coverage 확률이라 부른다. $1-\alpha$ 신뢰집합 $C \left( \mathbf{x} \right)$ 이 모든 $\theta&#39; \ne \theta$ 에 대해 펄스 커</description>
    </item>
    
    <item>
      <title>가설검정과 신뢰집합의 일대일 대응관계</title>
      <link>https://freshrimpsushi.github.io/posts/one-to-one-corresponding-between-hypothesis-test-and-confidence-set/</link>
      <pubDate>Mon, 28 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/one-to-one-corresponding-between-hypothesis-test-and-confidence-set/</guid>
      <description>정리 모수공간 $\Theta$ 와 공간 $\mathcal{X}$ 가 주어져 있다고 하자. 각각의 $\theta_{0} \in \Theta$ 에 대해 $A \left( \theta_{0} \right)$ 을 가설검정 $H_{0} : \theta = \theta_{0}$ 의 레벨 $\alpha$ 채택역이라 하자. 각각의 $\mathbf{x} \in \mathcal{X}$ 에 대해 다음과 같이 집합 $C \left( \mathbf{x} \right) \subset \Theta$ $$ C \left( \mathbf{x} \right) := \left\{ \theta_{0} : \mathbf{x} \in A \left( \theta_{0} \right) \right\} $$ 을 정의하자. 그러면 랜덤 집합Random Set $C \left( \mathbf{X} \right)$ 는 $1 - \alpha$ 신뢰집합이다. 역으로, $C \left( \mathbf{X} \right)$ 가 $1 - \alpha$ 신뢰집합이라 하자</description>
    </item>
    
    <item>
      <title>수리통계학에서 피벗의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-pivot-in-mathematical-statistics/</link>
      <pubDate>Sat, 26 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-pivot-in-mathematical-statistics/</guid>
      <description>정의 1 확률변수 $Q \left( \mathbf{X} , \theta \right) := Q \left( X_{1} , \cdots , X_{n} ; \theta \right)$ 의 확률분포가 모든 모수 $\theta$ 에 독립이면 $Q$ 를 피벗Pivot 혹은 피버탈 퀀터티Pivotal Quantity라 한다. 설명 당연하지만 $Q$ 는 통계량이다. 확률분포가 모든 모수 $\theta$ 에 독립이라는 말은 곧 $Q \left( \mathbf{X} , \theta \right)$ 의 누적분포함수 $F \left( bfx \right)$ 모든 $\theta$ 에 대해 같다는 것이다. 정의만 읽어보면 어차피</description>
    </item>
    
    <item>
      <title>수리통계적인 신뢰집합의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-confidence-set-in-mathematical-statistics/</link>
      <pubDate>Tue, 22 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-confidence-set-in-mathematical-statistics/</guid>
      <description>정의 1 모수 $\theta$ 의 구간추정량 $\left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right]$ 에 대해 다음을 커버리지 확률Coverage Probability라 한다. $$ P_{\theta} \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] \right) = P \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] | \theta \right) $$ 커버리지 확률의 인피멈을 신뢰계수Confidence Coefficient라 한다. $$ \inf_{\theta} P_{\theta} \left( \theta \in \left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right] \right) $$</description>
    </item>
    
    <item>
      <title>구간추정량</title>
      <link>https://freshrimpsushi.github.io/posts/interval-estimator/</link>
      <pubDate>Fri, 18 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interval-estimator/</guid>
      <description>정의 1 모수 $\theta \in \mathbb{R}$ 에 대해 순서쌍 $\left( L \left( x_{1} , \cdots , x_{n} \right), U \left( x_{1} , \cdots , x_{n} \right) \right)$ 이 모든 $\mathbf{x} \in \mathcal{X}$ 에 대해 $L \left( \mathbf{x} \right) \le U \left( \mathbf{x} \right)$ 을 만족하면 $\theta$ 의 구간추정치Interval Estimate라 한다. 랜덤 인터벌Random Interval $\left[ L \left( \mathbf{X} \right), U \left( \mathbf{X} \right) \right]$ 를 구간추정량Interval Estimator라 한다. $\mathcal{X}$ 는 $L$ 과 $U$ 의 서포트다. 설명 데이터 $\mathbf{X} = \mathbf{x}$</description>
    </item>
    
    <item>
      <title>수리통계적인 유의확률의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-p-value-in-mathematical-statistics/</link>
      <pubDate>Mon, 03 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-p-value-in-mathematical-statistics/</guid>
      <description>정의 1 가설검정 $H_{0} \text{ vs } H_{1}$ 이 주어져 있다고 하자. 모든 실현 $\mathbf{x} \in \Omega$ 에 대해 $0 \le p \left( \mathbf{x} \right) \le 1$ 를 만족시키는 검정 통계량 $p \left( \mathbf{X} \right)$ 를 유의확률 혹은 p-밸류p-value라 한다. $p \left( \mathbf{X} \right)$ 가 모든 $\theta \in \Theta_{0}$ 와 모든 $\alpha \in [0,1]$ 에 대해 다음을 만족하면 유효하다Valid고 말한다. $$ P_{\theta} \left( p \left( \mathbf{X} \right) \le \alpha \right) \le \alpha $$ 설명 유효한 p-밸류의 조건에 있는 수식을 풀어</description>
    </item>
    
    <item>
      <title>충분통계량이 포함된 최강력검정</title>
      <link>https://freshrimpsushi.github.io/posts/ump-based-on-sufficient-statistic/</link>
      <pubDate>Tue, 27 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ump-based-on-sufficient-statistic/</guid>
      <description>정리 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta = \theta_{0} \\ H_{1} :&amp;amp; \theta = \theta_{1} \end{align*} $$ 위와 같은 가설검정에서 $\theta$ 에 대한 충분통계량 $T$ 의 $\theta_{0}, \theta_{1}$ 에 대한 확률밀도함수 혹은 확률질량함수를 $g \left( t | \theta_{0} \right), g \left( t | \theta_{1} \right)$ 라고 하자. 그러면 기각역 $S$ 와 어떤 상수 $k \ge 0$ 에 대해, 다음 세 조건을 만족하면서 $T$ 에 종속된 모든 가설 검정은 레벨 $\alpha$의 최강력검정이다. (i): $g \left( t | \theta_{1} \right) &amp;gt; k</description>
    </item>
    
    <item>
      <title>칼린-루빈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-karlin-rubin-theorem/</link>
      <pubDate>Fri, 23 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-karlin-rubin-theorem/</guid>
      <description>정리 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta \le \theta_{0} \\ H_{1} :&amp;amp; \theta &amp;gt; \theta_{0} \end{align*} $$ 위와 같은 가설검정에서 $T$ 를 $\theta$ 의 충분통계량이라 하고, $t$ 의 확률밀도함수 혹은 확률질량함수의 패밀리 $\left\{ g(t | \theta) : \theta \in \Theta \right\}$ 가 단조우도비 MLR을 갖는다고 하자. 그러면 $\forall t_{0}$ 에 대해 $$ H_{0} \text{ is rejected if and only if } T &amp;gt; t_{0} $$ 인 가설검정은 레벨 $\alpha = P_{\theta_{0}} \left( T &amp;gt; t_{0} \right)$ 최강력검정이다. 모수 $\theta$ 에 대해 기각역이 $R$ 인</description>
    </item>
    
    <item>
      <title>단조우도비의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-monotone-likelihood-ratio/</link>
      <pubDate>Mon, 19 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-monotone-likelihood-ratio/</guid>
      <description>정의 모수 $\theta \in \mathbb{R}$ 와 일변량 확률변수 $T$ 에 대한 확률질량함수 혹은 확률밀도함수의 패밀리를 $G := \left\{ g ( t | \theta) : \theta \in \Theta \right\}$ 라 하자. 모든 $\theta_{2} &amp;gt; \theta_{1}$ 에 대해 $$ {{ g \left( t | \theta_{2} \right) } \over { g \left( t | \theta_{1} \right) }} $$ 가 $\left\{ t : g \left( t | \theta_{1} \right) &amp;gt; 0 \lor g \left( t | \theta_{2} \right) &amp;gt; 0 \right\}$ 에서 단조함수면 $G$ 가 단조우도비Monotone Llikelihood Ratio, MLR을 가진다고 한다. 설명 널리 알려진 수 많은 분</description>
    </item>
    
    <item>
      <title>네이만-피어슨 보조정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-neyman-pearson-lemma/</link>
      <pubDate>Thu, 15 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-neyman-pearson-lemma/</guid>
      <description>정리 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta = \theta_{0} \\ H_{1} :&amp;amp; \theta = \theta_{1} \end{align*} $$ 위와 같은 가설검정에서 $\theta_{0}, \theta_{1}$ 에 대한 확률밀도함수 혹은 확률질량함수를 $f \left( \mathbf{x} | \theta_{0} \right), f \left( \mathbf{x} | \theta_{1} \right)$ 이라 하고 기각역 $R$ 과 어떤 상수 $k \ge 0$ 에 대해 만약 (i): $f \left( \mathbf{x} | \theta_{1} \right) &amp;gt; k f \left( \mathbf{x} | \theta_{0} \right)$ 이면 $\mathbf{x} \in R$ (ii): $f \left( \mathbf{x} | \theta_{1} \right) &amp;lt; k f \left( \mathbf{x} | \theta_{0} \right)$ 이면 $\mathbf{x} \in R^{c}$ (iii): $\alpha = P_{\theta_{0}} \left( \mathbf{X} \in R \right)$ 이라면, 다음 두 명제는 동치다. 위 세</description>
    </item>
    
    <item>
      <title>일변량 확률 변수 샘플링하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-sample-random-variable/</link>
      <pubDate>Tue, 13 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-sample-random-variable/</guid>
      <description>개요 확률변수의 구체적인 실현을 구하는 방법이다. 정리 일변량 확률변수 $T$ 의 누적분포함수 $F = F_{T}$ 가 주어져 있다고 하자. 그러면 일양분포를 따르는 확률 변수 $U \sim U \left( 0,1 \right)$ 에 대해 다음이 성립한다. $$ T = F^{-1} \left( U \right) $$ 설명 누적분포함수의 치역은 항상 $[0,1]$ 이라는 점을 생각해보면 당연하면서도 영리한 방법이다. 뭐가 됐든 $0$ 부터 $1$ 사이의 값 하나만 구하면 반</description>
    </item>
    
    <item>
      <title>불편 검정력 함수와 최강력검정</title>
      <link>https://freshrimpsushi.github.io/posts/unbiased-power-function-and-most-powerful-test/</link>
      <pubDate>Sun, 11 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unbiased-power-function-and-most-powerful-test/</guid>
      <description>정의 1 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 검정력 함수 $\beta (\theta)$가 모든 $\theta_{0} \in \Theta_{0}$ 와 $\theta_{1} \in \Theta_{0}^{c}$ 에 대해 다음을 만족하면 불편Unbiased 검정력 함수라 한다. $$ \beta \left( \theta_{0} \right) \le \beta \left( \theta_{1} \right) $$ $\mathcal{C}$ 가 위와 같은 가설검정을 모아놓은 집합이라고 하자. $\mathcal{C}$ 에서 검정력 함수 $\beta (\theta)$ 를 가진 가설검정 $A$ 가, 모든 $\theta \in \Theta_{0}^{c}$ 와 $\mathcal{C}$ 의 모든 가설검정의 검정력 함</description>
    </item>
    
    <item>
      <title>가설 검정의 검정력 함수</title>
      <link>https://freshrimpsushi.github.io/posts/power-function-of-hypothesis-test/</link>
      <pubDate>Wed, 07 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/power-function-of-hypothesis-test/</guid>
      <description>정의 1 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 위와 같은 가설검정이 주어져 있고 $\alpha \in [0,1]$ 이라 하자. 모수 $\theta$ 에 대해 기각역이 $R$ 인 함수 $\beta (\theta) := P_{\theta} \left( \mathbf{X} \in \mathbb{R} \right)$ 을 검정력 함수Power Function라 한다. $\sup_{\theta \in \Theta_{0}} \beta (\theta) = \alpha$ 면 주어진 가설검정을 사이즈Size $\alpha$ 가설검정이라 한다. $\sup_{\theta \in \Theta_{0}} \beta (\theta) \le \alpha$ 면 주어진 가설검정을 레벨Level $\alpha$ 가설</description>
    </item>
    
    <item>
      <title>충분통계량이 포함된 우도비검정</title>
      <link>https://freshrimpsushi.github.io/posts/lrt-based-on-sufficient-statistic/</link>
      <pubDate>Sat, 03 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/lrt-based-on-sufficient-statistic/</guid>
      <description>정리 가설검정: $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 우도비검정통계량: $$ \lambda \left( \mathbf{x} \right) := {{ \sup_{\Theta_{0}} L \left( \theta \mid \mathbf{x} \right) } \over { \sup_{\Theta} L \left( \theta \mid \mathbf{x} \right) }} $$ 만약 $T \left( \mathbf{X} \right)$ 가 모수 $\theta$ 의 충분통계량이고 $\lambda^{\ast} (t)$ 가 $T$ 에 종속된 우도비검정통계량 $\lambda (\mathbf{x})$ 가 $\mathbf{X}$ 에 종속된 우도비검정통계량 이라고 하면, 모든 표본공간의 모든 $\mathbf{x} \in \Omega$ 에 대해 $\lambda^{\ast} \left( T \left( \mathbf{x} \right) \right) = \lambda \left( \mathbf{x} \right)$ 다. 설명 다시금 충분통</description>
    </item>
    
    <item>
      <title>수리통계적인 우도비검정의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-likelihood-ratio-test-in-mathematical-statistics/</link>
      <pubDate>Tue, 30 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-likelihood-ratio-test-in-mathematical-statistics/</guid>
      <description>정의 1 $$ \begin{align*} H_{0} :&amp;amp; \theta \in \Theta_{0} \\ H_{1} :&amp;amp; \theta \in \Theta_{0}^{c} \end{align*} $$ 위와 같은 가설검정에 대해 다음의 통계량 $\lambda$ 를 우도비검정 통계량Likelihood Ratio Test Statistic이라 한다. $$ \lambda \left( \mathbf{x} \right) := {{ \sup_{\Theta_{0}} L \left( \theta \mid \mathbf{x} \right) } \over { \sup_{\Theta} L \left( \theta \mid \mathbf{x} \right) }} $$ 주어진 $c \in [0,1]$ 에 대해 기각역 $\left\{ \mathbf{x} : \lambda \left( \mathbf{x} \right) \le c \right\}$ 를 가지는 모든 가설검정을 우도비검정Likelihood Ratio Test</description>
    </item>
    
    <item>
      <title>로케이션 패밀리의 충분통계량과 최대우도추정량</title>
      <link>https://freshrimpsushi.github.io/posts/sufficient-statistiic-and-mle-of-location-family/</link>
      <pubDate>Fri, 26 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sufficient-statistiic-and-mle-of-location-family/</guid>
      <description>정리 확률밀도함수가 $f_{X} \left( x ; \theta \right) = f_{X} \left( x - \theta \right)$ 인 로케이션 패밀리에서 얻은 랜덤샘플 $X_{1} , \cdots , X_{n} \sim X$ 이 주어져 있다고 하자. 충분통계량과 최대우도추정량은 $X$ 의 서포트가 위로 유계면 $\max X_{k}$ $X$ 의 서포트가 아래로 유계면 $\min X_{k}$ 에 종속된다. 확률변수의 서포트란 확률밀도함수의 함수값이 $0$ 보다 큰 점들의 집합을 의미한다. $$ S_{X} := \left\{ x \in \mathbb{R} : f_{X} (x ; \theta) &amp;gt;</description>
    </item>
    
    <item>
      <title>수리통계적인 가설검정의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-hypothesis-test-in-mathematical-statistics/</link>
      <pubDate>Mon, 22 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-hypothesis-test-in-mathematical-statistics/</guid>
      <description>정의 1 모수에 관한 명제를 가설Hypothesis이라 한다. 주어진 샘플에 따라 가설 $H_{0}$ 을 참으로 받아들이게 만들거나 가설 $H_{0}$ 을 기각하고 $H_{1}$ 을 채택하는 문제를 가설 검정Hypothesis Test이라 한다. 가설검정에서 상보적인complementary 가설 $H_{0}$, $H_{1}$ 을 각각 귀무가설Null Hypothesis, 대립가설Altanative Hypot</description>
    </item>
    
    <item>
      <title>랜덤샘플의 표본평균의 평균과 분산</title>
      <link>https://freshrimpsushi.github.io/posts/mean-and-variance-of-of-sample-mean-of-random-sample/</link>
      <pubDate>Thu, 18 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mean-and-variance-of-of-sample-mean-of-random-sample/</guid>
      <description>공식 랜덤샘플 $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} X$ 이 주어져 있다고 하면 그 표본평균의 평균과 분산은 다음과 같다. $$ \begin{align*} E \bar{X} =&amp;amp; E X \\ \text{Var} \bar{X} =&amp;amp; {{ 1 } \over { n }} \text{Var} X \end{align*} $$ 설명 너무 쉬워서, 실제로 쉽다보니 대충 생각해서 갑자기 물어보면 의외로 헷갈리고 당황스러운 것이 바로 표본평균의 평균과 분산이다. 조금만 머리를 굴려보면 금방 알 수 있긴한데, 가능하면 머리는 조금 더 가치</description>
    </item>
    
    <item>
      <title>유일한 최대우도추정량은 충분통계량에 종속된다</title>
      <link>https://freshrimpsushi.github.io/posts/unique-mle-depends-on-sufficient-statistiic/</link>
      <pubDate>Sun, 14 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/unique-mle-depends-on-sufficient-statistiic/</guid>
      <description>정리 만약 모수 $\theta$ 에 대한 충분통계량 $T$ 가 존재하고 $\theta$ 의 최대우도추정량 $\hat{\theta}$ 가 유일하게 존재한다면, $\hat{\theta}$ 는 $T$ 에 대한 함수로 나타난다. 증명 1 확률밀도함수 $f \left( x ; \theta \right)$ 를 가지는 랜덤샘플 $X_{1} , \cdots , X_{n}$ 에 대한 충분통계량 $T := T \left( X_{1} , \cdots , X_{n} \right)$ 과 그 확률밀도함수 $f_{t}$ 를 생각해보자. 충분통계량의 정의에 따라 그 우도함수 $L$ 은 $\theta$ 에 종속되지 않은 어떤 함수 $H$ 에</description>
    </item>
    
    <item>
      <title>레만-셰페 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-lehmann-scheff%C3%A9-theorem/</link>
      <pubDate>Wed, 10 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-lehmann-scheff%C3%A9-theorem/</guid>
      <description>정리 1 2 완비 충분 통계량에 종속된 불편추정량은 유일하다. 다시 말해, $\theta$ 의 완비충분통계량 $T$ 에 대해 만약 $E \left[ \phi (T) \right] = \tau (\theta)$ 면 $\phi (T)$ 는 $\tau (\theta)$ 의 유일한 불편추정량, 즉 최선불편추정량이다. 설명 레만-셰페 정리는 불편추정량의 유일성을 보존하는 강력한 정리로써, 통계량의 완비성과 충분성이 중요한 이유 자체가 될 수 있다. 이 정리에 따라 충분통계량을</description>
    </item>
    
    <item>
      <title>최선불편추정량, 최소분산불편추정량 UMVUE</title>
      <link>https://freshrimpsushi.github.io/posts/uniform-minimum-variance-unbiased-estimator-umvue/</link>
      <pubDate>Tue, 02 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/uniform-minimum-variance-unbiased-estimator-umvue/</guid>
      <description>정의 1 모수 $\theta$ 가 주어져 있다고 하자. 불편추정량 $W^{\ast}$ 가 다른 모든 불편추정량 $W$ 에 대해 다음을 만족하면 최선불편추정량Best Unbiased Estimator 혹은 최소분산불편추정량UMVUE, Uniform Minimum Variance Unbiased Estimator이라 한다. $$ \text{Var}_{\theta} W^{\ast} \le \text{Var}_{\theta} W \qquad , \forall \theta $$ 설명 UMVUE는 가장 앞의 Uniform을 떼고 그냥 MVUE라고 할 때도 있다. UMVUE가 너무 길기도 하</description>
    </item>
    
    <item>
      <title>불편추정량의 라오-크래머 하한</title>
      <link>https://freshrimpsushi.github.io/posts/rao-cram%C3%A9r-lower-bound-of-unbiased-estimator/</link>
      <pubDate>Fri, 28 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rao-cram%C3%A9r-lower-bound-of-unbiased-estimator/</guid>
      <description>정리 정칙조건: (R0): 확률밀도함수 $f$ 는 $\theta$ 에 대해 단사다. 수식으로는 다음을 만족시킨다. $$ \theta \ne \theta&#39; \implies f \left( x_{k} ; \theta \right) \ne f \left( x_{k} ; \theta&#39; \right) $$ (R1): 확률밀도함수 $f$ 는 모든 $\theta$ 에 대해 같은 서포트를 가진다. (R2): 참값 $\theta_{0}$ 는 $\Omega$ 의 내점Interior Point이다. (R3): 확률밀도함수 $f$ 는 $\theta$ 에 대해 두 번 미분가능하다. (R4): 적분 $\int f (x; \theta) dx$ 은 적분 기호를 넘나들며 $\theta$ 에 대</description>
    </item>
    
    <item>
      <title>최대우도추정량의 불변성질 증명</title>
      <link>https://freshrimpsushi.github.io/posts/invariant-property-of-mle/</link>
      <pubDate>Mon, 24 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/invariant-property-of-mle/</guid>
      <description>정리 최대우도추정량은 함수를 취하는 것에 대해 불변Invariant 하다. 다시 말해 만약 $\hat{\theta}$ 가 모수 $\theta$ 의 최대우도추정량면, 모든 함수 $\tau$ 에 대해 $\tau \left( \hat{\theta} \right)$ 역시 $\tau \left( \theta \right)$ 의 최대우도추정량이다. 증명 1 $\eta := \tau \left( \theta \right)$ 라고 두고 우도함수 $L = L \left( \theta | \mathbf{x} \right)$ 에 대해 새로운 함수 $L^{\ast}$ 를 $$ L^{\ast} \left( \hat{\eta} | \mathbf{x} \right) = L^{\ast} \left( \tau^{-1} \left( \eta \right) | \mathbf{x} \right) $$ 과 같이 정의하자. $\hat{\eta}$ 가 우도함</description>
    </item>
    
    <item>
      <title>새터스화이트 근사</title>
      <link>https://freshrimpsushi.github.io/posts/satterthwaite-approximation/</link>
      <pubDate>Thu, 20 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/satterthwaite-approximation/</guid>
      <description>빌드업 자유도가 $r_{k}$ 인 카이제곱분포를 따르는 독립적인 $n$ 개의 확률변수 $Y_{k} \sim \chi_{r_{k}}^{2}$ 가 주어져 있다고 하자. 널리 알려진대로, 이들의 합인 $\sum_{k=1}^{n} Y_{k}$ 는 자유도가 $\sum_{k=1}^{n} r_{k}$ 인 카이제곱분포를 따른다. 이러한 인사이트는 t-분포를 따르는 $\displaystyle {{W} \over {\sqrt{V / r}}}$ 의 분모를 볼 때 유용하게 쓰일 수 있는데, 안타깝게도 풀드 샘플Pooled Sample, 그러니까 이질적인 모집단이 섞여있는 상황</description>
    </item>
    
    <item>
      <title>로케이션-스케일 패밀리의 보조통계량</title>
      <link>https://freshrimpsushi.github.io/posts/ancillary-statistiic-of-location-scale-family/</link>
      <pubDate>Sun, 16 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ancillary-statistiic-of-location-scale-family/</guid>
      <description>정리 1 $X_{1} , \cdots , X_{n}$ 가 로케이션 패밀리면서 스케일 패밀리에서 나온 랜덤샘플이라 하자. 두 통계량 $T_{1} \left( X_{1} , \cdots, X_{n} \right)$ 과 $T_{2} \left( X_{1} , \cdots , X_{n} \right)$ 가 모든 $x_{1} , \cdots , x_{n}$ 와 모든 상수 $b \in \mathbb{R}$ 과 $a &amp;gt; 0$ 에 대해 $$ T_{i} \left( a x_{1} + b , \cdots , a x_{n} + b \right) = a T_{i} \left( x_{1} , \cdots , x_{n} \right) $$ 을 만족시킨다면, 그 비 $T_{1}/T_{2}$ 는 보조통계량이다. 증명 $X_{k}$ 는 로케이션-스케일 패밀리에서 나왔으므로 어떤</description>
    </item>
    
    <item>
      <title>최소충분통계량이 주어진 불편추정량의 분산은 최소가 된다</title>
      <link>https://freshrimpsushi.github.io/posts/the-variance-of-unbaised-estimator-given-minimal-sufficient-statistiic-is-minimized/</link>
      <pubDate>Wed, 12 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-variance-of-unbaised-estimator-given-minimal-sufficient-statistiic-is-minimized/</guid>
      <description>정리 1 모수 $\theta$ 가 주어져 있다고 하자. $U$ 는 그 불편추정량, $T_{1}$ 은 충분통계량이고 $T_{2}$ 은 최소충분통계량이고 다음과 같이 $$ \begin{align*} U_{1} :=&amp;amp; E \left( U | T_{1} \right) \\ U_{2} :=&amp;amp; E \left( U | T_{2} \right) \end{align*} $$ 를 정의하면 다음이 성립한다. $$ \text{Var} U_{2} \le \text{Var} U_{1} $$ 설명 이러나 저러나 $U$ 는 불편추정량이기 때문에 $T_{1}$ 이 주어졌든 $T_{2}$ 가 주어졌든 그 기대값은 $\theta$ 를 찍기는 하지만, 대충 말해서 최소충분통계량이</description>
    </item>
    
    <item>
      <title>지수족 확률분포의 완비통계량</title>
      <link>https://freshrimpsushi.github.io/posts/complete-statistiic-for-exponential-family/</link>
      <pubDate>Sat, 08 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complete-statistiic-for-exponential-family/</guid>
      <description>정리 1 모수 $\mathbf{\theta} = \left( \theta_{1} , \cdots , \theta_{k} \right)$ 가 주어져 있고, 랜덤샘플 $X_{1} , \cdots , X_{n}$ 의 확률밀도함수 혹은 확률질량함수가 다음과 같이 지수족확률분포를 따른다고 하자. $$ f(x; \mathbf{\theta}) = h(x) c (\mathbf{\theta}) \exp \left( \sum_{i=1}^{k} w_{i} \left( \theta_{j} \right) t_{i} (x) \right) $$ 그러면 다음의 통계량 $T$ 는 완비통계량이다. $$ T \left( \mathbf{X} \right) = \left( \sum_{i=1}^{n} t_{1} \left( X_{i} \right) , \cdots , \sum_{i=1}^{n} t_{k} \left( X_{i} \right) \right) $$ 증명 라플라스 변환의 유일성에 따라 자명하다. ■ Casella. (2001). statistiical Inference(2nd</description>
    </item>
    
    <item>
      <title>모먼트 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/moment-method/</link>
      <pubDate>Tue, 04 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/moment-method/</guid>
      <description>정의 1 주어진 분포의 모수를 모를 때, 적률로써 모수에 대한 연립방정식을 세우고 그 해를 모수의 추정량으로 보는 방법을 모먼트 메소드Moment Method라 한다. 설명 모먼트 메소드는 최소 1800년대부터 칼 피어슨Karl Pearson 등에 의해 오래도록 사용된 점 추정 기법이다. 많은 경우에서 대단히 좋은 결과를 도출해내지는 못했지만, 가장 간단하고</description>
    </item>
    
    <item>
      <title>바수 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-baus-theorem/</link>
      <pubDate>Fri, 31 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-baus-theorem/</guid>
      <description>정리 만약 $T \left( \mathbf{X} \right)$ 이 완비통계량이면서 최소충분통계량이면, $T \left( \mathbf{X} \right)$ 은 모든 보조통계량과 독립이다. 설명 바수 정리는 충분통계량에 관한 정리 중에 가장 중요한 정리로써, 어떤 두 통계량이 독립임을 보일 수 있는 아주 강력한 결과를 도출 할 수 있다. 직관적으로 충분통계량은 모수 $\theta$ 에 대한 모든 정보를 가지고, 보조통계량은 $\theta$ 에 종속되어 있지 않으므로 둘</description>
    </item>
    
    <item>
      <title>완비통계량</title>
      <link>https://freshrimpsushi.github.io/posts/complete-statistiic/</link>
      <pubDate>Mon, 27 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/complete-statistiic/</guid>
      <description>정의 1 $\Omega$ 를 모수의 집합이라고 하자. 샘플 $\mathbf{X}$ 의 통계량 $T := T \left( \mathbf{X} \right)$ 의 확률밀도함수 혹은 확률질량함수 $f \left( t ; \theta \right)$ 들을 모아놓은 패밀리 $\left\{ f \left( t ; \theta \right) : \theta \in \Theta \right\}$ 가 $$ \forall \theta, E_{\theta} g (T) = 0 \implies \forall \theta, P_{\theta} \left( g(T) = 0 \right) = 1 $$ 를 만족하면 컴플리트Complete하다고 말하고, $T \left( \mathbf{X} \right)$ 를 완비통계량Complete statistiic이라 한다. 설</description>
    </item>
    
    <item>
      <title>스케일 패밀리</title>
      <link>https://freshrimpsushi.github.io/posts/scale-family/</link>
      <pubDate>Thu, 23 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scale-family/</guid>
      <description>정의 누적분포함수 $F$ 에 대해 $F_{\sigma}$ 는 모든 $x$ 에 대해 $F_{\sigma} (x) = F \left( x / \sigma \right)$ 를 만족한다고 하자. $\left\{ F_{\sigma} : \sigma &amp;gt; 0 \right\}$ 을 스케일 패밀리Scale Family라 한다. 예시 1 모수 $\sigma$ 에 대한 랜덤샘플 $X_{1} , \cdots , X_{n}$ 을 생각해보면 누적분포함수 $F_{1} (x) = F ( x / 1) = F(x)$ 를 가지는 랜덤샘플 $Z_{1} , \cdots , Z_{n}$ 에 대해서 $$ X_{i} = \sigma Z_{i} $$ 와 같이 나타낼 수 있다. 이 샘플의 어떤 통계량이</description>
    </item>
    
    <item>
      <title>로케이션 패밀리</title>
      <link>https://freshrimpsushi.github.io/posts/location-family/</link>
      <pubDate>Sun, 19 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/location-family/</guid>
      <description>정의 누적분포함수 $F$ 에 대해 $F_{\theta}$ 는 모든 $x$ 에 대해 $F_{\theta} (x) = F \left( x - \theta \right)$ 를 만족한다고 하자. $\left\{ F_{\theta} : \theta \in \mathbb{R} \right\}$ 을 로케이션 패밀리Location Family라 한다. 예시 1 모수 $\theta$ 에 대한 랜덤샘플 $X_{1} , \cdots , X_{n}$ 을 생각해보면 누적분포함수 $F_{0} (x) = F (x - 0) = F(x)$ 를 가지는 랜덤샘플 $Z_{1} , \cdots , Z_{n}$ 에 대해서 $$ X_{i} = Z_{i} + \theta $$ 와 같이 나타낼 수 있다. 이 샘플의 통계</description>
    </item>
    
    <item>
      <title>보조통계량</title>
      <link>https://freshrimpsushi.github.io/posts/ancillary-statistiic/</link>
      <pubDate>Wed, 15 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ancillary-statistiic/</guid>
      <description>정의 1 $S$ 가 샘플 $\mathbf{X}$ 의 통계량이라고 하자. $S \left( \mathbf{X} \right)$ 의 분포가 모수 $\theta$ 에 종속되지 않으면 보조통계량Ancillary statistiic이라 한다. 설명 사실 말로 할 땐 아무도 보조통계량이라 하지 않고 [앵실러리 스태티스틱]이라고 발음한다. 충분통계량이 $\theta$ 에 대한 모든 정보를 가지고 있다는 느낌이라면, 보조통계량은 $\theta$ 에 대한 정보가 전혀 없</description>
    </item>
    
    <item>
      <title>최소충분통계량</title>
      <link>https://freshrimpsushi.github.io/posts/minimal-sufficient-statistiic/</link>
      <pubDate>Sat, 11 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/minimal-sufficient-statistiic/</guid>
      <description>정의 1 충분통계량 $T \left( \mathbf{X} \right)$ 가 모든 다른 충분통계량 $T&#39; \left( \mathbf{X} \right)$ 에 대해 $T \left( \mathbf{x} \right)$ 가 $T&#39; \left( \mathbf{x} \right)$ 의 함수로 나타나면 $T \left( \mathbf{X} \right)$ 를 최소충분통계량Minimal Sufficient statistiic이라 한다. 정리 $f \left( \mathbf{x} ; \theta \right)$ 가 샘플 $\mathbf{X}$ 의 확률밀도함수 혹은 확률질량함수라 하자. 모든 실현 $\mathbf{x} , \mathbf{y}$ 에 대해 $$ {{ f \left( \mathbf{x} ; \theta \right) } \over { f \left( \mathbf{y} ; \theta \right) }} = c (\theta) \text{ is constant as function a of</description>
    </item>
    
    <item>
      <title>우도함수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-likelihood-function/</link>
      <pubDate>Thu, 26 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-likelihood-function/</guid>
      <description>정의 1 샘플 $\mathbf{X} := \left( X_{1} , \cdots , X_{n} \right)$ 의 조인트 확률밀도함수 혹은 확률질량함수를 $f(\mathbf{x}|\theta)$ 라 하자. 그 실현 $\mathbf{x}$ 가 주어져 있을 때, $f(\mathbf{x}|\theta)$ 를 $\theta$ 에 대한 함수로 본 $$ L \left( \theta | \mathbf{x} \right) := f \left( \mathbf{x} | \theta \right) $$ 를 우도 함수Likelihood Function라 한다. 설명 최대우도추정량을 논하는 맥락에서는 샘플에 더불어 iid여야할 필요가 있지만, 우도 원리Likelih</description>
    </item>
    
    <item>
      <title>수리통계학에서의 델타 메소드</title>
      <link>https://freshrimpsushi.github.io/posts/delta-method-in-mathematical-statistiics/</link>
      <pubDate>Sun, 22 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/delta-method-in-mathematical-statistiics/</guid>
      <description>정리 상수 $\theta \in \mathbb{R}$ 와 확률변수의 시퀀스 $\left\{ Y_{n} \right\}_{n \in \mathbb{N}}$ 에 대해 $\sqrt{n} \left( Y_{n} - \theta \right)$ 가 정규분포 $N \left(0, \sigma^{2} \right)$ 로 분포수렴한다고 하자. $1$계 델타 메소드 1 $g&#39;(\theta) \ne 0$ 이 존재한다면, $$ \sqrt{n} \left[ g \left( Y_{n} \right) - g(\theta) \right] \overset{D}{\to} N \left( 0, \sigma^{2} \left[ g&#39;(\theta) \right]^{2} \right) $$ $2$계 델타 메소드 2 $g&#39;(\theta) = 0$ 이고 $g&#39;&#39;(\theta) \ne 0$ 이 존재한다면, $$ n \left[ g \left( Y_{n} \right) - g(\theta) \right] \overset{D}{\to} \sigma^{2} {{ g&#39;&#39;\left( \theta \right) } \over { 2 }} \chi_{1}^{2} $$ 일반화된 델타 메소드 $n$ 에 종</description>
    </item>
    
    <item>
      <title>스털링 공식의 수리통계적 증명</title>
      <link>https://freshrimpsushi.github.io/posts/mathematical-statistiical-proof-of-stirling-approximation/</link>
      <pubDate>Wed, 18 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/mathematical-statistiical-proof-of-stirling-approximation/</guid>
      <description>정리 $$ \lim_{n \to \infty} {{n!} \over {e^{n \ln n - n} \sqrt{ 2 \pi n} }} = 1 $$ 설명 스털링 근사 혹은 스털링 공식Stirling Formula은 통계학이나 물리학 등 여러 곳에서 유용하게 쓰인다. 수리통계적인 증명은 분포이론에 빠삭하다면야 오히려 다른 증명에 비해 직관적이고 이해하기 쉽다. 같이보기 가우스 적분을 이용한 증명 엄밀한 증명 증명 $X_{1} , \cdots , X_{n} \overset{\text{iid}}{\sim} \exp (1)$ 이라고 하자</description>
    </item>
    
    <item>
      <title>지수족 확률분포</title>
      <link>https://freshrimpsushi.github.io/posts/exponential-family/</link>
      <pubDate>Mon, 04 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/exponential-family/</guid>
      <description>정의 12 모수 $\theta$ 인 확률분포의 확률질량함수 혹은 확률밀도함수가 어떤 함수 $p,K,H,q,h,c,w_{i},t_{i}$ 들에 대해 다음과 같이 나타낼 수 있으면 지수족Exponential Family 혹은 익스포넨셜 클래스Exponential Class에 속한다고 한다. $$ \begin{align*} f \left( x ; \theta \right) =&amp;amp; \exp \left( p (\theta) K (x) + H(x) + q(\theta) \right) \\ =&amp;amp; h(x) c (\theta) \exp \left( \sum_{i=1}^{k} w_{i} (\theta) t_{i} (x) \right) \end{align*} $$ 설명 정의에서 두 수식의 형태가 사실상 같다</description>
    </item>
    
    <item>
      <title>확률 밀도 함수의 컨볼루션 공식</title>
      <link>https://freshrimpsushi.github.io/posts/convolution-formula-for-pdfs/</link>
      <pubDate>Thu, 31 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/convolution-formula-for-pdfs/</guid>
      <description>공식 1 독립인 두 연속확률변수 $X, Y$ 의 확률밀도함수가 $f_{X}, f_{Y}$ 로 주어져 있다고 하자. 그러면 $Z := X + Y$ 의 확률밀도함수는 두 확률밀도함수의 합성곱 $f_{Z} = f_{X} \ast f_{Y}$ 이다. $$ f_{Z} (z) = \left( f_{X} \ast f_{Y} \right) (z) = \int_{-\infty}^{\infty} f_{X} (w) f_{Y} (z-w) dw $$ 유도 $W := X$ 라 하면 자코비안은 $$ \begin{Vmatrix} 1 &amp;amp; 1 \\ 1 &amp;amp; 0 \end{Vmatrix} = \left| -1 \right| = 1 $$ 이고, $Z$ 와 $W$ 의 조인트 확률밀도함수 $f_{Z,W}$ 는 $$ f_{Z,W} \left( z,w \right) = f_{X,Y} \left( w, z-w \right) = f_{X} (w)</description>
    </item>
    
    <item>
      <title>함수를 취한 확률변수꼴 합의 기대값</title>
      <link>https://freshrimpsushi.github.io/posts/expectation-of-sum-of-function-values-of-random-variables/</link>
      <pubDate>Sun, 27 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/expectation-of-sum-of-function-values-of-random-variables/</guid>
      <description>정리 1 $X_{1} , \cdots , X_{n}$ 이 랜덤 샘플이고, $E g \left( X_{1} \right)$ 과 $\text{Var} g \left( X_{1} \right)$ 가 존재하게끔 하는 함수 $g : \mathbb{R} \to \mathbb{R}$ 가 주어져 있다고 하자. 그러면 다음이 성립한다. [1] 평균: $$ E \left( \sum_{k = 1}^{n} g \left( X_{k} \right) \right) = n E g \left( X_{1} \right) $$ [2] 분산: $$ \text{Var} \left( \sum_{k = 1}^{n} g \left( X_{k} \right) \right) = n \text{Var} g \left( X_{1} \right) $$ 설명 이 정리에서 눈여겨보아야 할 부분은 $\left\{ X_{k} \right\}_{k=1}^{n}$ 이 랜덤 샘플, 다시 말해 iid라는 것이다. 가령</description>
    </item>
    
  </channel>
</rss>
