<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>베이지안 on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/categories/%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88/</link>
    <description>Recent content in 베이지안 on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Fri, 21 Dec 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/categories/%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>베이즈 인자를 통한 가설검정</title>
      <link>https://freshrimpsushi.github.io/posts/statistical-hypothesis-test-by-bayes-factor/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/statistical-hypothesis-test-by-bayes-factor/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 고전적인 가설검정을 쓸 수 있게 되려면 기각역, 유의확률과 같은 개념에 대한 수학적인 이해를 포함해서 이를 직관적으로 받아들일 수 있을 정도의 통계학적 센스까지 갖추어야한다. 학부 1학년 교양 수준에서도 몇 시간이나 할애해가며 가르치고, 그래도 가설검정을 제대로 받아들이지 못하는 학생이 수두룩</description>
    </item>
    
    <item>
      <title>최고사후밀도 신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/highst-posterior-density-credible-interval/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $C : = \left\{ \theta \in \Theta , | , p ( \theta | y ) \ge k (\alpha) \right\} $ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 최고사후밀도 신용구간 이라고 한다. 여기서 $k(\alpha)$ 는 $p(\theta \in C | y ) \ge 1 - \alpha$ 를 만족하는 가장 큰 상수다.수식과 말보다는 그림을 통해 보는게 훨씬 이해하기 좋</description>
    </item>
    
    <item>
      <title>신용구간과 신뢰구간의 차이</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval-vs-confidence-interval/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 신용구간과 신뢰구간의 차이는 실로 베이지안과 프리퀀티스트의 차이라고 볼 수 있다. **요약 - 신뢰구간(프리퀀티스트) : 모수는 고정된 상수고, 신뢰구간이 랜덤으로 구해진다. - 신용구간(베이지안) : 모수도 분포를 가진 변수고, 신용구간도 사후분포로 구해진다. **신뢰구간 고전통계</description>
    </item>
    
    <item>
      <title>신용구간</title>
      <link>https://freshrimpsushi.github.io/posts/credible-interval/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/credible-interval/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 모수공간 $\Theta$ 의 부분집합 $C \subset \Theta$ 가 유의수준 $\alpha$ 에 대해 $P ( \theta \in C | y ) \ge 1 - \alpha$ 를 만족할 때, $C$ 를 자료 $y$ 가 주어졌을 때 $\theta$ 에 대한 $100(1 - \alpha) % $ 신용구간 이라고 한다. 베이지안에서의 구간추정이란 모수 $\theta$ 를 포함하는 확률이 높은 구간을 찾는 것이다.이로써 찾아지는 &amp;lsquo;신용구간&amp;rsq</description>
    </item>
    
    <item>
      <title>제프리 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/jeffreys-prior/</link>
      <pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jeffreys-prior/</guid>
      <description>정의 자료의 분포 $p( y | \theta) $ 에 대해 $\pi ( \theta ) \propto I^{1/2} ( \theta )$ 를 제프리 사전분포Jeffreys Prior 라고 한다. $I$ 는 다음과 같은 피셔정보Fishser Information를 의미한다. $$ I ( \theta ) = E \left[ \left( \left. {{\partial \ln p (y | \theta) } \over {\partial \theta}} \right)^2 \right| \theta \right] = E \left[ \left. - {{\partial^2 \ln p (y | \theta) } \over { (\partial \theta )^2 }} \right| \theta \right] $$ 설명 라플라스 사전분포 $\pi (\theta) \propto 1$ 는 모수 $\theta$ 의 사전분포</description>
    </item>
    
    <item>
      <title>라플라스 사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/laplace-prior/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplace-prior/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 모수에 대한 정보가 거의 없다면 구태여 복잡한 사전분포를 생각할 이유는 없다. 내년 모 대학의 통계학과 신입생의 성비를 추측해보라고 했을 때, 통계학과를 어느정도 아는 사람이라면 예년의 성비를 보고 어느정도 짐작을 하겠지만 전혀 관계도 없고 관심도 없는 사람이 이 질문을 들었을 땐 특별한 이유가 없는 한</description>
    </item>
    
    <item>
      <title>켤레사전분포</title>
      <link>https://freshrimpsushi.github.io/posts/conjugate-prior/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/conjugate-prior/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 사전분포와 사후분포가 동일한 분포족에 속하면 사전분포를 켤레사전분포 라고 한다.베이지안이란 본래 사전분포가 어떻게 되든 업데이트를 통해 모수를 찾아가는 것이긴 하지만, 모형에 대해 어느정도 아는 바가 있다면 적절한 사전분포를 사용함으로써 수학적 계산을 간단하게 하고 결과를 이해하기 쉽게 할</description>
    </item>
    
    <item>
      <title>라플라스 계승 법칙</title>
      <link>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplaces-law-of-succession/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정리 이항모형 $\displaystyle p(y | \theta) = \pmatrix{ n \\ y} \theta^{y} (1- \theta)^{n-y}$ 의 사전분포가 균일분포 $U (0,1)$ 를 따르고 사후분포가 베타분포 $\beta (y+1 , n-y+1)$ 을 따라 $p( \theta | y ) \sim \theta^{y} (1- \theta)^{n-y} $ 이라고 하자. 그러면 이제까지 얻은 데이터 $y$ 에 대해 새로운 $\tilde{y}$ 가 $1$ 일 확률은 $$ p(\tilde{y} = 1| y) = {{y+1} \over {n+2}} $$ 프리퀀티스트의 관점으로 보았을 때 $\tilde{y} = 1$ 일 확률은 그 표본</description>
    </item>
    
    <item>
      <title>베이지안 패러다임</title>
      <link>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/bayesian-paradigm/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 통계학이란 &amp;lsquo;모수를 파악하는 방법을 연구하는 학문&amp;rsquo;이라고 할 수 있다. 어떤 물리량을 측정하는 것처럼 공식이나 법칙을 통해 정확하게 모수를 추정할 수 있다면 더할나위 없지만, 현실적으로 그게 불가능하기 때문에 가정과 표본을 이용해 &amp;lsquo;모수로 예상되는 것&amp;</description>
    </item>
    
    <item>
      <title>베이즈 정리로 보는 몬티홀 딜레마</title>
      <link>https://freshrimpsushi.github.io/posts/monty-hall-dilemma/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/monty-hall-dilemma/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 *베이즈 정리를 아는 정도라면 몬티홀 게임도 알 것이라 상정하고 몬티홀 게임에 자체는 다른 지면을 빌어 설명하겠다.알다시피 몬티홀 게임은 실제로 경품이 어디있든 관계 없이 선택을 바꾸는 것이 유리하다. 이것을 팩트로써 받아들이냐와 별개로 몬티홀 게임을 직관적으로 이해하지 못했거나 수식적인 표현</description>
    </item>
    
    <item>
      <title>베이즈 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-bayes-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 표본공간 $S$ 와 사건 $A$ 에 대해서 ${S_1,S_2,&amp;hellip;,S_n}$ 가 $S$ 의 분할이면 $$ \displaystyle P(S_k|A)=\frac { P(S_k)P(A|S_k) }{ \sum _{ k=1 }^{ n }{ P(S_k)P(A|S_k) } } $$ 혹은 베이즈 법칙으로도 불리는 이 정리는 두개의 법칙만 쓰면 될 정도로 쉽게 증명할 수 있으나 그 응용은 어마어마하다. 이른바 베이지안 패러다임은 통계학 자체를 양분하는 사고방식으로써, 그 중요도는 몇 번을 강조해</description>
    </item>
    
  </channel>
</rss>
