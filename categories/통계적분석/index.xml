<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>통계적분석 on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/categories/%ED%86%B5%EA%B3%84%EC%A0%81%EB%B6%84%EC%84%9D/</link>
    <description>Recent content in 통계적분석 on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Wed, 29 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/categories/%ED%86%B5%EA%B3%84%EC%A0%81%EB%B6%84%EC%84%9D/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>QGIS로 shp 파일 열어보는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-open-shp-file-using-qgis/</link>
      <pubDate>Wed, 29 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-open-shp-file-using-qgis/</guid>
      <description>개요 shp 확장자는 Shapefile을 나타낸다. 많은 지리정보 데이터들이 *.shp 파일과 동봉된 *.dbf, *.sbn, *.sbx, *.shx 등의 포맷으로 관리된다. 데이터를 받았을 때 가장 황당한 것은 도대체 이걸 어떻게 보는지 모르기 때문이다. 가이드 Step 1. QGIS 설치 https://qgis.org/ko/site/forusers/download.html QGIS는 GIS(Geographic Information System) 데이터를 조회하고 편집하는 기능을 갖춘 응용소프트웨어다. 위 링크에서 각자 환경에 맞는 인스톨러를 받</description>
    </item>
    
    <item>
      <title>R 에서 가치 모형으로 시계열 분석 하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-garch-model-in-r/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-garch-model-in-r/</guid>
      <description>실습 가치 모델은 아치 이펙트를 설명하는 유용한 수단으로써 분석 절차 자체는 아르마 모델과 흡사하다. 위의 그래프는 내장데이터 EuStockMarkets에서 DAX만 뽑아내서 그린 것으로, 1991년부터 1999년까지 독일 DAX지수를 나타낸다. 리턴의 제곱을 보면 거의 확실하게 아치 이펙트가 있는 것으로 보인다. 리턴의 제곱이 아르마 모</description>
    </item>
    
    <item>
      <title>시계열 분석에서의 가치 모형</title>
      <link>https://freshrimpsushi.github.io/posts/garch-model/</link>
      <pubDate>Sun, 08 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/garch-model/</guid>
      <description>모델 1 가치 모델은 아치 모델을 일반화한 것으로, 이분산성을 파악하기 위한 시계열 분석법이다. $$ (1 - \beta{1} B - \cdots - \beta_{p} B^p) \sigma_{t | t-1}^2 = \omega + (\alpha_{1} B + \cdots + \alpha_{q} B^q) r_{t}^{2} $$ 유도 유도는 가장 간단한 $ARCH(1)$ 모델부터 시작해보자.2 시계열 데이터 $\left\{ p_{t} \right\}$ 의 리턴 $\left\{ r_{t} \right\}$ 이 주어져 있다고 할 때 데이터가 시차 $1$ 의 아치 이펙트, 즉 자기 회귀 조건부 이분산성을 가진다는 말은 다음과 같이</description>
    </item>
    
    <item>
      <title>아치 이펙트</title>
      <link>https://freshrimpsushi.github.io/posts/arch-effect-autoregressive-conditional-heteroscedasticity-effect/</link>
      <pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arch-effect-autoregressive-conditional-heteroscedasticity-effect/</guid>
      <description>정의 1 아치 이펙트란 그 AutoRegressive Conditional Heteroscedasticity라는 말 그대로 &amp;lsquo;자기회귀 조건부 이분산 효과&amp;rsquo;로 순화되기 때문에 순화하지 않는다. 설명 쉽게 말해서 데이터의 변동성이 변하면서, 그 자체가 이전의 데이터로 설명될 수 있는 경우 데이터에 아치 이펙트가 있다고 말한다. 이러한 아치 이펙트를 통계적으로 설명</description>
    </item>
    
    <item>
      <title>시계열분석에서의 이분산성과 변동성 군집현상</title>
      <link>https://freshrimpsushi.github.io/posts/heteroscedasticity-and-volatility-clustering/</link>
      <pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/heteroscedasticity-and-volatility-clustering/</guid>
      <description>정의 1 시계열 데이터 $\left\{ p_{t} \right\}$ 가 주어져 있다고 하자. $\left\{ p_{t} \right\}$ 의 분산이 $t$ 에 종속되어있을 때, $\left\{ p_{t} \right\}$ 는 이분산성Heteroscedasticity을 가진다고 한다. 이분산성을 가지는 $\left\{ p_{t} \right\}$ 의 분산이 커졌다 작아졌다를 반복하는 현상을 변동성 군집현상Volatility Clustering이라고 한다. 다음과 같이 정의된 $r_{t}$ 를 $t$ 에서의</description>
    </item>
    
    <item>
      <title>동적 회귀 모형</title>
      <link>https://freshrimpsushi.github.io/posts/dynamic-regression-model/</link>
      <pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dynamic-regression-model/</guid>
      <description>모델 동적 회귀 모형이란 쉽게 말해 아리마 모형에 회귀 모형을 합친 모형이다. 설명 사실 이쯤되면 말보다는 수식이 편한데, 종속변수로 분석할 시계열 데이터가 $\left\{ y_{t} \right\}$ 이라고 하고 이 데이터를 설명할 독립변수로써 또 다른 시계열 데이터 $\left\{ x_{t} \right\}$ 가 있다고 해보자. $x_{t}$ 가 $y_{t}$ 를 잘 설명한다면 그것 자체로도 시계열 회귀분석이 가능하고, 그것으로도 설명되지 않는 부분</description>
    </item>
    
    <item>
      <title>시계열분석의 이노베이티브 아웃라이어</title>
      <link>https://freshrimpsushi.github.io/posts/innovative-outlier/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/innovative-outlier/</guid>
      <description>빌드업 위의 그래프에서 2001년 9월에 굉장히 큰 아웃라이어를 찾을 수 있다. 그러나 애디티브 아웃라이어와 달리 그 후에도 계속해서 영향을 미치고 있다. 여객기의 이용자 수는 계절성을 가지고 꾸준히 증가하고 있었는데, 911테러의 공포가 이용자 수 자체를 팍 줄여버린 것으로 해석할 수 있다. 정의 1 이렇게 분석의 판도 자체를 바꾸는 아웃라이어를 이노</description>
    </item>
    
    <item>
      <title>시계열분석의 애디티브 아웃라이어</title>
      <link>https://freshrimpsushi.github.io/posts/additive-outlier/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/additive-outlier/</guid>
      <description>빌드업 위의 그래프에서 가장 먼저 눈에 띄는 지점은 바로 2015년 2월 근처에 있는 엄청난 아웃라이어다. 이렇듯 극심하게 다른 값을 가지면 분석에 악영향이 있을 수밖에 없다. 다행스러운 건 아주 잠깐, 말 그대로 한 순간의 아웃라이어로 그쳤다는 것이다. 정의 1 이렇듯 데이터의 등락 자체를 바꾸지는 않는 아웃라이어를 애디티브 아웃라이어Additiv</description>
    </item>
    
    <item>
      <title>스텝 함수와 펄스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/step-function-and-pulse-function/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/step-function-and-pulse-function/</guid>
      <description>정의 1 다음과 같이 정의된 $S_{t}^{(T)}$ 를 스텝 함수라 한다. $$ S_{t}^{(T)} := \begin{cases} 1 &amp;amp; , t \le T \\ 0 &amp;amp; , \text{otherwise} \end{cases} $$ 다음과 같이 정의된 $P_{t}^{(T)}$ 를 펄스 함수라 한다. $$ \begin{align*} P_{t}^{(T)} &amp;amp;:=&amp;amp; \nabla S_{t}^{(T)} \\ =&amp;amp; S_{t}^{(T)} - S_{t-1}^{(T)} \end{align*} $$ 설명 스텝 함수와 펄스 함수는 개입 분석에 쓰이는 수식을 나타내기에 유용한 함수들로써, 그 자체의 성질은 크게 의미가 없다. 스텝 함수는 말 그대로 그래프의 개형이 계단처럼 생겨서 붙인 것이고,</description>
    </item>
    
    <item>
      <title>개입 분석</title>
      <link>https://freshrimpsushi.github.io/posts/intervention-analysis/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/intervention-analysis/</guid>
      <description>빌드업 위 그래프는 실제 2015년 서울의 미세먼지 농도를 나타낸 시계열 데이터다. 누가 보더라도 가장 먼저 눈에 띄는 것은 50번째쯤, 그러니까 2월 말에 미세먼지 농도가 500을 넘긴 날이 있다는 점일 것이다. 데이터를 다루는데에 어느정도 익숙한 사람이라면 가장 먼저 잘못 관측된 것이 아닐까 의심하겠지만, 놀랍게도 실제로 일어난 일이었다. 아예 이</description>
    </item>
    
    <item>
      <title>시계열회귀분석에서의 허위 상관관계</title>
      <link>https://freshrimpsushi.github.io/posts/spurious-correlation/</link>
      <pubDate>Mon, 19 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/spurious-correlation/</guid>
      <description>정의 1 허위 상관관계는 두 데이터가 그럴싸한 상관관계를 가지는 것 같아 보이지만 실제로는 그렇지 않은 관계를 말한다. 실습 1 다음의 예시를 통해 알아보자. 위와 같이 두 가지 시계열 데이터가 주어져 있다고 하자. 언뜻 보기에 두 시계열은 강력한 상관관계를 가질 것만 같이 보인다. 시간에 따라 조금씩 증가하는 트렌드을 포함해서 계절성을 포함한 등락 패턴이 매</description>
    </item>
    
    <item>
      <title>사전백화</title>
      <link>https://freshrimpsushi.github.io/posts/prewhitening/</link>
      <pubDate>Sat, 17 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/prewhitening/</guid>
      <description>정의 사전백화Prewhitening 란 CCF를 계산할 때 시계열을 백색잡음으로 만들어 두 데이터 간의 상관관계를 더욱 정확하게 파악하는 방법이다. 실습 1 가능하다면 이것이 어떻게 가능한지 수식적으로도 완전히 이해하는 것을 추천하는데, 우선은 예로써 다음의 데이터를 살펴보자. bluebird는 뉴질랜드에서 감자칩을 제조하는 회사인 블</description>
    </item>
    
    <item>
      <title>교차상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/ccf-cross-correlation-functon/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ccf-cross-correlation-functon/</guid>
      <description>정의 1 $\left\{ X_{t} \right\}_{t=1}^{n}$, $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이라고 하자. 다음과 같이 정의된 $\rho_{k}$ 를 시차 $k$ 의 교차상관함수라고 한다. $$ \rho_{k} (X,Y) := \text{cor} \left( X_{t} , Y_{t-k} \right) = \text{cor} \left( X_{t+k} , Y_{t} \right) $$ 다음과 같이 정의된 $r_{k}$ 를 시차 $k$ 의 표본교차상관함수라고 한다. $$ r_{k} := {{ \sum \left( X_{t} - \overline{X} \right) \left( Y_{t-k} - \overline{Y} \right) } \over { \sqrt{ \sum \left( X_{t} - \overline{X} \right)^2 } \sqrt{ \left( Y_{t-k} - \overline{Y} \right)^2 } }} $$ 설명 교차상관함수는 두 시계열 데이터 간의 상관관계를 파악</description>
    </item>
    
    <item>
      <title>시계열 회귀 분석</title>
      <link>https://freshrimpsushi.github.io/posts/time-series-regression-analysis/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-series-regression-analysis/</guid>
      <description>정의 시계열 회귀 분석이란 말 그대로 시계열 데이터로 회귀분석하는 기법을 말한다. 원래 회귀분석 자체가 시계열 데이터를 다루는데 있어서 적합하지 않은 것은 사실이지만, 그럼에도 불구하고 복수의 시계열 데이터를 다룰 때는 회귀분석의 아이디어와 툴을 빌리는 것이 좋을 때가 있다. 실습 가령 위와 같이 두 종류의 데이터 x와 y가 주어져있다고 하자. 물론 두 데</description>
    </item>
    
    <item>
      <title>아리마 모형에 대한 잔차분석</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-tsdiag-plots-in-r/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-tsdiag-plots-in-r/</guid>
      <description>설명 회귀분석과 마찬가지로 시계열 분석 역시 잔차분석을 한다. 아리마 모형의 가정에 따르면 잔차는 모두 백색잡음이므로 선형성, 등분산성, 독립성, 정규성을 따르는지 확인은 할 것이다. 회귀분석과 비교하자면 전반적으로 그렇게까지 엄격하지는 않으나, 독립성 하나만큼은 철저하게 체크한다. 애초에 시계열분석 자체가 자기상관성을 파악하기 위한 것</description>
    </item>
    
    <item>
      <title>R 에서 EACF를 사용한 ARMA 모형 선택법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-determine-arma-model-using-eacf-in-r/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-determine-arma-model-using-eacf-in-r/</guid>
      <description>실습 1 PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다. 직접 그 예를 살펴보자. ma1.2.s 데이터는 $MA(1)$ 모델에서, ar1.s 데이터는 $AR(1)$ 모델에서 나온 TSA 패키지의 샘플 데이터다. TSA 패키지의 acf() 함수와 pacf() 함수를 사용하면 다음과 같이 여러 시차 $k$ 에 대해 코릴로그램Correlogram을 그려준다. 그림만 봤을 때 파란 선을 넘어가는</description>
    </item>
    
    <item>
      <title>확장자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/eacf-extended-autocorrelation-function/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/eacf-extended-autocorrelation-function/</guid>
      <description>빌드업 PACF는 $AR(p)$의 차수를, ACF는 $MA(q)$ 의 차수를 정할 때 큰 도움이 된다. 하지만 $ARMA(p,q)$ 모형에 적용시킬 땐 아르마 모형의 가역성 때문에 $AR(p)$ 라도 $MA(\infty)$ 처럼 보일 수 있고, $MA(q)$ 라도 $AR(\infty)$ 처럼 보일 수 있다. 따라서 이러한 문제를 회피하고 아르마 모형을 찾기위한 여러가지 방법이 고안되었다. 정의 확장자기상관함수 는 그 중의 한 방법으로, 다음과 같이 정의</description>
    </item>
    
    <item>
      <title>편자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/pacf-partial-autocorrelation-function/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pacf-partial-autocorrelation-function/</guid>
      <description>정의 1 $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이고 시차 $k$ 에 대해서 $Y_{t-1}, \cdots , Y_{t-(k-1)}$ 로 $Y_{t}$ 를 회귀분석한 잔차를 $\widehat{e_{t}}$, $Y_{t-k}$ 를 회귀분석한 잔차를 $\widehat{e_{t-k}}$ 이라고 하자. 다음과 같이 정의된 $\phi_{kk}$ 를 시차 $k$ 의 편자기공분산함수라고 한다. $$ \phi_{kk} := \text{cor} ( \widehat{e_{t}} , \widehat{e_{t-k}} ) $$ 다음과 같이 정의된 $\phi_{kk}$ 를 시차 $k$ 의 표본편자기공분산함수라고 한다. $$ \widehat{ \phi_{kk} } := {{ r_{k} - \sum_{j=1}^{k-1} \phi_{(k-1),j} r_{k-j} } \over { 1 - \sum_{j=1}^{k-1} \phi_{(k-1),j} r_{j} }} \\ \phi_{k,j} := \phi_{(k-1),j} - \phi_{kk} \phi_{(k-1),(k-j)} $$ $r_{k}$ 는 시</description>
    </item>
    
    <item>
      <title>자기상관함수</title>
      <link>https://freshrimpsushi.github.io/posts/acf-autocorrelation-function/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/acf-autocorrelation-function/</guid>
      <description>정의 1 $\left\{ Y_{t} \right\}_{t=1}^{n}$ 이 확률과정이라고 하자. $\mu_{t} := E ( Y_{t} )$ 를 평균함수라고 한다. 다음과 같이 정의된 $\gamma_{ t , s }$ 를 자기공분산함수라고 한다. $$ \gamma_{t , s} : = \text{cov} ( Y_{t} , Y_{s} ) = E ( Y_{t} - \mu_{t} ) E ( Y_{s} - \mu_{s} ) $$ 다음과 같이 정의된 $\rho_{ t , s }$ 를 자기상관함수라고 한다. $$ \displaystyle \rho_{ t , s } := \text{cor} ( Y_{t} , Y_{s} ) = {{ \gamma_{t , s} } \over { \sqrt{ \gamma_{t , t} \gamma_{s , s} } }} $$ 다음과 같이 정의된</description>
    </item>
    
    <item>
      <title>아르마 모형의 가역성</title>
      <link>https://freshrimpsushi.github.io/posts/invertivility-of-arma-model/</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/invertivility-of-arma-model/</guid>
      <description>정의 1 아르마 모형에 있어서 가역성을 가졌다 함은 $AR(p)$ 와 $MA(q)$ 가 서로를 표현할 수 있음을 말한다. 예시 일반적인 $ARMA ( p , q)$ 에 대한 수식전개는 아니지만, $AR(1)$ 과 $MA(1)$ 의 예를 살펴보자. 자기회귀모형 $AR(1) \implies MA( \infty )$ $| \phi | &amp;lt; 1$ 에 대해서 다음의 자기회귀모형 $AR(1)$ 을 생각해보자. $$ Y_{t} = \phi Y_{t-1} + e_{t} $$ $Y_{t-1}$ 역시 $Y_{t-1} = \phi Y_{t-2} + e_{t-1}$ 와 같이 나타낼 수 있으므로 $$ \begin{align*} Y_{t} =&amp;amp; \phi ( \phi Y_{t-2} + e_{t-1} )</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 예측하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-predict-with-arima-model-in-r/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-predict-with-arima-model-in-r/</guid>
      <description>실습 R 내장데이터 UKDriverDeaths는 1969년부터 1984년까지 영국 월별 운전자 사상자에 대한 데이터다. 언뜻 보아도 계절형 아리마 모형을 따르고, 실제로 모형을 찾아내는것은 별로 어렵지 않다. 그러나 최종적으로 얻은 모형으로 식을 직접 써서 계산하는 것은 무척 손이 많이 가고 복잡한 일이다. 따라서 predict() 함수를 사용한다. n.ahead 옵션을</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 얻은 시계열 분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-arima-model-summary-in-r/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-arima-model-summary-in-r/</guid>
      <description>실습 R 내장데이터 AirPassenger는 1949년부터 1960년까지 월별 항공기의 승객 수에 대한 데이터다. (1) 모형: 사실 계수만 제대로 파악할 수 있다면 중요한 것은 아니다. 계절형 아리마 모형 $ARIMA(p,d,q)\times(P,D,Q)_{s}$ 을 나타낸다. 예로써 위 분석의 결과인 ARIMA(0,1,1)(0,1,1)[12]는 $ARIMA(0,1,1)\times(0,1,1)_{12}$ 를 의미한다. (2) 계수: 모형에 맞는 계수를 나타</description>
    </item>
    
    <item>
      <title>R 에서 아리마 모형으로 시계열 분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-arima-model-in-r/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-analyze-time-series-with-arima-model-in-r/</guid>
      <description>실습 R에서 내장데이터 WWWusage 를 불러와 그래프를 그려 확인해보자. WWWusage는 먼 옛날 인터넷에 접속하는 이용자수를 나타내는 시계열 데이터로써, 그 추이를 파악하기 위해서는 시계열 분석을 해야한다. 시계열 분석에서 가장 대표적인 모형은 아리마 모형이나, 같은 아리마 모형이라고 해도 실제로 적절한 모형을 찾아내는 방법은 여러가지가 있다. 다행</description>
    </item>
    
    <item>
      <title>아리마 모형에서의 드리프트</title>
      <link>https://freshrimpsushi.github.io/posts/drift-in-arima-model/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/drift-in-arima-model/</guid>
      <description>설명 시계열 분석을 하다보면 종종 다음과 같이 드리프트Drift라는 계수를 보게 된다. 물론 위의 경우 표준오차에 비해서 계수의 크기가 너무 작기 때문에 무시해도 상관 없다. 그러나 실제로 유의한 계수인 동시에 수식으로도 써야할 일이 있다면 드리프트가 무엇인지 알아야한다. 아쉽게도 국내에는 드리프트가 도대체 무엇인지에 대한 좋은 설명이 없으며, 수</description>
    </item>
    
    <item>
      <title>계절형 아리마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/seasonal-arima-model/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/seasonal-arima-model/</guid>
      <description>모델 1 $\nabla_{s} Y_{t} := Y_{t} - Y_{t-s}$ 와 같이 정의된 오퍼레이터 $\nabla_{s}$ 를 계절형 차분Seasonal Difference이라 한다. $W_{t} := \nabla^{d} \nabla_{s}^{D} Y_{t}$ 와 같이 정의된 $\left\{ W_{t} \right\}_{t \in \mathbb{N}}$ 가 $ARMA(P,Q)$ 고 $\left\{ Y_{t} \right\}_{t \in \mathbb{N}}$ 이 $ARMA(p,q)$ 면 $\left\{ Y_{t} \right\}_{t \in \mathbb{N}}$ 는 계절형 아리마 과정 $ARIMA(p,d,q)\times(P,D,Q)_{s}$ 라고 한다. 이와 같은 꼴을 한 시계열 분석 모형을 계절형 아리마 모형이라 한다. 설명 오늘의 기온은 물론 어제의 기온에 가장 큰 영향을 받겠지</description>
    </item>
    
    <item>
      <title>아리마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/arima-model-intergrated-autoregressive-moving-average-model/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arima-model-intergrated-autoregressive-moving-average-model/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $$ \displaystyle \nabla^{d} Y_{t} := \sum_{i = 1}^{p} \phi_{i} \nabla^{d} Y_{t-i} + e_{t} - \sum_{i = 1}^{q} \theta_{i} e_{t-i} $$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 $(p,d,q)$차 아리마 과정 $ARIMA (p,d,q)$ 라고 한다. 이와 같은 꼴을 한 시계열 분석 모형을 아리마 모형이라고 한다. 설명 $ARI(p,d) \iff ARIMA(p,d,0)$ 을 아리 모형 , $IMA(d,q) \iff ARIMA(0,d,q)$ 을 이마 모형이라 하긴 하는데 자주 쓰진 않는다. 차라리 $ARIMA(p,d,0)$ 이나 $ ARIMA(0,d,q)$ 와 같은 표현을 즐겨 쓰는 편</description>
    </item>
    
    <item>
      <title>시계열분석에서의 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation/</guid>
      <description>빌드업 시계열에서 변환이 필요한 이유는 시간이 흐를수록 분산이 커지는 경우 그에 따른 &amp;lsquo;패널티&amp;rsquo;를 줘서 분산을 일정하게 하고 정상성을 얻기 위함이다. 루트 $\sqrt{}$ 나 로그 $\log$ 는 값이 클수록 줄어드는 양이 많기 때문에 자주 사용된다. 당연하지만 분산이 줄어드는 경우에는 데이터의 추이가 어떤 점으로 수렴한다는 의미가 되므로 변환 이전</description>
    </item>
    
    <item>
      <title>시계열분석에서의 차분</title>
      <link>https://freshrimpsushi.github.io/posts/difference/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/difference/</guid>
      <description>정의 1 오퍼레이터 $B$ 를 $B Y_{t} = Y_{t-1}$ 과 같이 정의하고, 백쉬프트Backshift라 한다. 오퍼레이터 $\nabla$ 를 $\nabla := 1 - B$ 그리고 $\nabla^{r+1} = \nabla \left( \nabla^{r} Y_{t} \right)$ 와 같이 정의하고 차분 이라한다. 설명 차분의 정의에 따르면 $1$차 차분은 $$ \nabla Y_{t} = Y_{t} - Y_{t-1} $$ 와 같이 계산되며, $2$차 차분은 $$ \begin{align*} \nabla^2 Y_{t} =&amp;amp; \nabla \left( \nabla Y_{t} \right) \\ =&amp;amp; \nabla \left( Y_{t} - Y_{t-1} \right) \\ =&amp;amp; \nabla Y_{t} - \nabla Y_{t-1} \\ =&amp;amp; ( Y_{t} - Y_{t-1} ) - (</description>
    </item>
    
    <item>
      <title>아르마 모형</title>
      <link>https://freshrimpsushi.github.io/posts/arma-model/</link>
      <pubDate>Sat, 16 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/arma-model/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $$ Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} +e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q} $$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 **$(p,q)$차 자기회귀이동평균과정 $ARMA(p,q)$**라 한다. 설명 아르마 모형은 단순히 이동평균과정과 자기회귀과정을 이어붙인 모양을 갖고 있다. 예로써 $(1,1)$차라면 $$ ARMA(1,1) : Y_{t} = \phi Y_{t-1} +</description>
    </item>
    
    <item>
      <title>자기회귀과정</title>
      <link>https://freshrimpsushi.github.io/posts/ar-autoregressive-process/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ar-autoregressive-process/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $Y_{t} := \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} + e_{t}$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 $p$차 자기회귀과정 $AR(p)$ 라고 한다. (1): $AR(1) : Y_{t} = \phi Y_{t-1} + e_{t}$ (2): $AR(2) : Y_{t} = \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + e_{t}$ (p): $AR(p) : Y_{t} = \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots + \phi_{p} Y_{t-p} + e_{t}$ (∞): $AR( \infty ) : Y_{t} = e_{t} + \phi_{1} Y_{t-1} + \phi_{2} Y_{t-2} + \cdots $ $\mathbb{N}$ 은 자연수의 집합 $\left\{ 1, 2, 3 , \cdots \right\}$ 을 의미한다. 설명 $AR(p)$ 를 &amp;lsquo;자</description>
    </item>
    
    <item>
      <title>이동평균과정</title>
      <link>https://freshrimpsushi.github.io/posts/ma-moving-average-process/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ma-moving-average-process/</guid>
      <description>모델 1 백색잡음 $\left\{ e_{t} \right\}_{t \in \mathbb{N}}$ 에 대해 $Y_{t} := e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q}$ 과 같이 정의된 $\left\{ Y_{t} \right\}_{ t \in \mathbb{N} }$ 을 **$q$차 이동평균과정 $MA(q)$**라고 한다. (1): $MA(1) : Y_{t} = e_{t} - \theta e_{t-1}$ (2): $MA(2) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2}$ (q): $MA(q) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots - \theta_{q} e_{t-q}$ (∞): $MA( \infty ) : Y_{t} = e_{t} - \theta_{1} e_{t-1} - \theta_{2} e_{t-2} - \cdots$ $\mathbb{N}$ 은 자연수의 집합 $\left\{ 1, 2, 3 , \cdots \right\}$ 을 의미한다. 설명 다</description>
    </item>
    
    <item>
      <title>시계열분석에서의 정상성</title>
      <link>https://freshrimpsushi.github.io/posts/stationarity-in-time-series-analysis/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stationarity-in-time-series-analysis/</guid>
      <description>정의 1 시계열 데이터의 평균과 분산이 일정할 때 정상성Stationarity을 갖는다고 한다. 설명 정상正常Normal이 아니라 정상定常Stational이다. 데이터가 정상성을 가진다는 것은 평균과 분산이 안정되어 있어서 분석하기 쉽다는 의미가 된다. 데이터가 정상성을 가지지 않으면 분석이 어렵기 때문에 정상성을 갖도록 만드는 전처</description>
    </item>
    
    <item>
      <title>시계열분석에서의 백색잡음</title>
      <link>https://freshrimpsushi.github.io/posts/white-noise-in-time-series-analysis/</link>
      <pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/white-noise-in-time-series-analysis/</guid>
      <description>정의 1 iid한 확률변수 $e_{t}$ 들의 수열 $\left\{ e_{t} \right\}_{t = 1}^{\infty}$ 를 백색잡음White Noise이라고 한다. iid란 independent identically distributed의 줄임말로써, 서로 독립이고 같은 분포를 가짐을 의미한다. 설명 확률변수의 수열이라는 정의에 따르면 당연히 확률과정이다. 특히 $E ( e_{t} ) = 0$ 이면 $Y_{t} : = \begin{cases} e_{1} &amp;amp; , t=1 \\ Y_{t-1} + e_{t} &amp;amp; , t \ne 1 \\ \end{cases}$ 과 같이 정의된 확률</description>
    </item>
    
    <item>
      <title>시계열분석이란</title>
      <link>https://freshrimpsushi.github.io/posts/time-series-analysis/</link>
      <pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/time-series-analysis/</guid>
      <description>설명 시계열Time Series 이란 쉽게 말해 실제 데이터로 얻어지는 확률과정이라고 볼 수 있다. 주가지수는 시간이 흐름에 따라 불확실성을 가지고 그 값이 변하므로 시계열의 좋은 예시가 될 수 있다. 시계열분석이란 이렇듯 시간 변수의 흐름에 따른 종속변수의 움직임을 이해하고 예측하는 것을 목표로 하는 분석법이다. 회귀분석과의 가장 큰 차이점은 회귀분석이 독립</description>
    </item>
    
    <item>
      <title>R 에서 로지스틱 회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-result-of-logistic-regression-in-r/</link>
      <pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-result-of-logistic-regression-in-r/</guid>
      <description>실습 내장데이터 turnout 데이터를 불러와보자. turnout는 1992년 미국 총선에 대한 데이터로써, race(인종), 연령(age), 교육수준(educate), income(수입)에 따른 vote(투표여부)를 파악할 수 있다. 이 데이터는 투표를 했느냐 안 했느냐하는 종속변수에 관심이 있으므로 로지스틱 회귀분석을 사용할 수 있다</description>
    </item>
    
    <item>
      <title>로지스틱 회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/logistic-regression/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/logistic-regression/</guid>
      <description>빌드업 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 $Y$ 가 질적변수, 그 중에서도 계급이 두개뿐인 경우가 있을 수 있다. 예를 들어 남자와 여자, 성공과 실패, 양성과 음성, $0$ 과 $1$ 등이 있고, 편의상 그냥 $Y=0$ 혹은 $Y=1$ 이라고 하자. 이렇게 종속변수가 이항적인 경우 관심사는 &amp;lsquo;독립변수 $ X_{1} , \cdots X_{p}$ 들을 보았을 때 $Y$ 가 무엇인지&amp;rsquo;일 것</description>
    </item>
    
    <item>
      <title>통계적 분석에서의 변수 선택 기준</title>
      <link>https://freshrimpsushi.github.io/posts/variable-selection-criterion-in-statistiical-analysis/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/variable-selection-criterion-in-statistiical-analysis/</guid>
      <description>개요 변수를 선택하는 문제는 필연적으로 분석자의 주관이 개입할 수 밖에 없지만, 가능한 한 객관적인 결론을 내릴 수 있게 도와주는 수치적인 지표가 필요했다. 그런 값들을 계산해낼 수 있다면 변수 선택 절차를 언제 멈추느냐에 대한 명쾌한 해답이 된다. 다만 이 기준에도 여러가지 종류가 있으며, 기준을 다르게 적용하면 결과 역시 달라질 수 있다. 지표 1 설명력 R-squared</description>
    </item>
    
    <item>
      <title>통계적 분석에서의 변수 선택 절차</title>
      <link>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistiical-analysis/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/variable-selection-procedure-in-statistiical-analysis/</guid>
      <description>빌드업 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.여기서 독립변수는 $p$ 개로, 회귀분석의 여러가지 가정들을 잘 만족하고 다중공선성이 없으며 설명력이 높다면 좋을 것이다. 물론 정보라는 것은 많으면 많을수록 좋지만, 지나치게 많은 데이터로 얻은 회귀모형은 사용하는데에도 많은 데이터를 요구한다. 그래서 가능하다면 사용하는 독립변수를 줄여</description>
    </item>
    
    <item>
      <title>R 에서 주성분회귀분석하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-pcr-in-r/</guid>
      <description>개요 주성분회귀분석PCR 이란 주성분분석과 다중회귀분석을 합친 것으로, 주성분분석을 통해 얻은 주성분을 새로운 독립변수로 둔 회귀분석을 말한다. 사실 통계학의 관점에서 주성분분석 그 자체는 별 필요가 없고, 보통 회귀분석에 쓰일 때나 의미가 있다. 실습 (다중공선성을 찾아내는 법에 이어서) 주성분을 만들어내는 과정은 행렬분해를 포함한 복잡한</description>
    </item>
    
    <item>
      <title>통계학에서의 주성분분석</title>
      <link>https://freshrimpsushi.github.io/posts/pca-principal-components-analysis-in-statistiics/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pca-principal-components-analysis-in-statistiics/</guid>
      <description>개요 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자. 주성분분석, 영어 약어로 PCA는 쉽게 말해 양적변수들이 제대로 독립이 되도록 &amp;lsquo;재구성&amp;rsquo;해서 분석하는 방법이다. 다변량 데이터의 분석이라는 관점으로 보자면 보다 적은 변수로 현상을 설명하기 위한 &amp;lsquo;차원축소&amp;rsquo;로써의 의미가 있다. 주성</description>
    </item>
    
    <item>
      <title>분산팽창인자 VIF</title>
      <link>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vif-variance-inflation-factor/</guid>
      <description>정의 1 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 할 때 $i$ 번째 독립변수에 대한 다중회귀분석 $$X_{i} \leftarrow X_{1} , \cdots, X_{i-1} , X_{i+1} , \cdots, X_{p}$$ 의 중회귀계수를 $R_{i}^2$ 라고 두자. 다음을 $X_{i}$ 의 분산팽창인자Variance Inflation Factor라고 한다. $$\displaystyle \text{VIF}_{i}: = {{1} \over {1 - R_{i}^{2} }}$$ 설명 우선 다중공선성에 대해 읽어보는 것을 추천한다. VIF는 분산확대지수 로 번역되는 경우도 있는 것 같지만, 보통은 너</description>
    </item>
    
    <item>
      <title>다중공선성</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-detect-multicollinearity/</guid>
      <description>정의 1 다중회귀분석 $Y \leftarrow X_{1} , \cdots, X_{p}$ 을 한다고 생각해보자.이 때 독립변수 $ X_{1} , \cdots, X_{p}$ 중에서 독립변수끼리 강한 상관관계를 가지면 다중공선성Multicollinearity이 있다고 한다 실습 애초에 독립변수끼리 종속적이라는 것 자체가 회귀분석의 가정에 위배되는 말이며, 실제로 수치적인 문제를 야기해 분석 결과를 신뢰할 수 없게 만든다. 데이</description>
    </item>
    
    <item>
      <title>비선형회귀분석: 회귀분석에서의 변수 변환</title>
      <link>https://freshrimpsushi.github.io/posts/transformation-of-variables/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/transformation-of-variables/</guid>
      <description>개요 1 회귀분석은 기본적으로 변수들간의 선형관계를 밝히는 방법이지만, 필요하다면 데이터를 선형으로 &amp;lsquo;펴서&amp;rsquo; 분석할 수 있다. 이는 본질적으로 종속변수를 독립변수의 비선형결합으로 설명하는 것이다. 실습 내장데이터 Pressure 데이터를 불러와보자. Pressure 데이터는 사실 통계적으로 분석할 필요는 없다. 이는 어디까지나 자연현상</description>
    </item>
    
    <item>
      <title>회귀분석에서의 교호작용</title>
      <link>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/interaction-in-regression-analysis/</guid>
      <description>빌드업 우선 질적변수를 포함한 회귀분석에 대해 읽어보는 것을 추천한다. 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 우선 질적변수가 있으므로 성별을 $$ S = \begin{cases} 1 &amp;amp; ,\text{여성} \\ 0 &amp;amp; ,\text{남성} \end{cases} $$ 그리고 학력을 $$ E_{1} = \begin{cases} 1 &amp;amp; ,\text{대졸} \\ 0 &amp;amp; ,\text{고졸</description>
    </item>
    
    <item>
      <title>질적변수를 포함한 회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/regression-analysis-including-qualitative-factor/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regression-analysis-including-qualitative-factor/</guid>
      <description>개요 회귀분석을 하면서 독립변수로 언제나 양적변수가 들어온다는 보장은 없다. 성별이 무엇인지, 어떤 기업 소속인지, 무슨 색상인지, 금속인지 등등 범주형 자료 역시 분석에 반영시킬 필요가 있다. 빌드업 1 올해 취업자 전체의 수능 성적 $X_{1}$, 연령 $X_{2}$, 성별 $S$, 최종학력 $E$ 로 초봉 $Y$ 를 추측한다고 상상해보자. 다중회귀분석을 사용하면 $Y \leftarrow X_{1} + X_{2}$ 와 같이 연봉 $Y$</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 정규성</title>
      <link>https://freshrimpsushi.github.io/posts/normality-of-standard-residuals/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/normality-of-standard-residuals/</guid>
      <description>진단법 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 정규성은 잔차들의 흩어진 모양보다는 히스토그램으로 확인하거나 정규성 검정을 하는 게 낫다. 왼쪽은 가운데에서 위 아래로 갈수록 그 밀도가 작아지는 것에 비해 오른쪽은 위아래 할 것 없이 고르게 퍼져있다. 하지만 이렇게 정말 잔차들이 정규분포 외의 알려진 분포를 따르는 케이스는</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 독립성</title>
      <link>https://freshrimpsushi.github.io/posts/independency-of-standard-residuals/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/independency-of-standard-residuals/</guid>
      <description>진단법 직관적 패턴 파악 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 독립성을 확인하려면 잔차 그림에 어떤 뚜렷한 경향이 나타나지 않으면 된다. 안타깝게도 독립성의 진단은 다른 회귀분석의 가정에 비해 매우 주관적일 수밖에 없다. 독립성이 결여된 예로 가장 자주볼 수 있는 경우는 위와 같이 정체를 알 수 없는 직선이 보이는 것이다. 물</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 등분산성</title>
      <link>https://freshrimpsushi.github.io/posts/homoscedasticity-of-standard-residuals/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/homoscedasticity-of-standard-residuals/</guid>
      <description>진단법 1 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다. 등분산성을 확인하려면 잔차들의 흩어진 모양이 전체적으로 고른지 확인하면 된다. 흔히 볼 수 있는 등분산성 결여의 예로써 다음의 두가지 경우가 대표적이다. 뒤로 갈수록 분산이 커지는 꼴인데, 이런 경우 변환이나 가중치를 도입함으로써 해결해야한다. 정말 쉽게 해결되느냐와</description>
    </item>
    
    <item>
      <title>모형진단으로 확인하는 잔차의 선형성</title>
      <link>https://freshrimpsushi.github.io/posts/linearity-of-standard-residuals/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linearity-of-standard-residuals/</guid>
      <description>진단법 1 표준화 잔차 그림을 통해 회귀분석이 제대로 되었는지 확인할 수가 있다.선형성이 있는지 확인하려면 $0$ 을 중심으로 잔차들이 대칭적으로 나타나는지 확인하면 된다. 오른쪽 그림을 보면 누가봐도 선형성이 결여되어있음을 확인할 수 있다. 만약 단순회귀분석이었다면 위와 같이 데이터의 경향을 전혀 설명할 수 없는 결과를 낳는다. 주의해야할 형태들로</description>
    </item>
    
    <item>
      <title>회귀분석의 모형진단</title>
      <link>https://freshrimpsushi.github.io/posts/model-diagnostic-of-regression-analysis/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/model-diagnostic-of-regression-analysis/</guid>
      <description>필요성 단순회귀분석의 경우엔 독립변수와 종속변수를 고려해봤자 $2$ 차원이기 때문에 분석이 제대로 되었는지 한 눈에 확인할 수 있다. 하지만 다중회귀분석의 경우 $3$ 차원을 넘어가면 그림으로 그리기 어려워 때문에 분석이 정말 잘 맞는지 확인하기 어렵다. 회귀분석의 가정을 제대로 만족시키지 못했지만 가설검정은 통과하는 경우가 있는데, 이 경우 분석은 그냥</description>
    </item>
    
    <item>
      <title>R 에서 다중회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</link>
      <pubDate>Wed, 05 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-multiple-regression-summary-in-r/</guid>
      <description>데이터 탐색 tail(attitude) R에서 내장데이터 attitude를 불러와 tail() 함수를 통해 확인해보자. 우리는 rating을 종속변수로 두고 다른 독립변수들이 rating에 어떤 영향을 얼마나 미치는지에 관심이 있다. 데이터만 봐서는 rating과 다른 변수들 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph() plot(attitude) 그냥 plot() 함수에 데이터</description>
    </item>
    
    <item>
      <title>다중회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/multiple-linear-regression/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/multiple-linear-regression/</guid>
      <description>개요 회귀분석이란 변수 사이의 관계를 알아내는 방법으로써, 특히 선형 관계를 밝히는 데 유용하다. 다중회귀분석Multiple Linear Regression은 하나의 종속변수(반응변수) 에 복수의 독립변수(설명변수) 가 미치는 영향을 파악하는 회귀분석을 말한다. 모델 1 $$Y = \beta_{0} + \beta_{1} X_{1} + \cdots + \beta_{p} X_{p} + \varepsilon $$ 우리는 변수들이 위와 같은 선형관계를 가지</description>
    </item>
    
    <item>
      <title>R 에서 단순회귀분석 결과 보는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-interpret-simple-regression-summary-in-r/</guid>
      <description>실습 회귀분석하는 법 head(faithful) R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 데이터만 봐서는 두 변수 사이에 선형관계가 있는지 확인하기 어려우므로 그림을 그려 확인해보자. win.graph(6,3) par(mfrow=c(1,2)) plot(faithful, main =&amp;quot;faithful&amp;quot;,asp=T) plot(faithful, main =&amp;quot;faithful&amp;quot;) points(head(faithful),col=&#39;red&#39;,pch=19) 왼쪽은 가로세로의 비율이 일정하도록 맞춰놓은 것인데, 정확한 그래프지만 보기가 어렵다. 오른쪽은 보기 편하도록 비율을 조정한 그래프</description>
    </item>
    
    <item>
      <title>단순회귀분석</title>
      <link>https://freshrimpsushi.github.io/posts/simple-linear-regression/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/simple-linear-regression/</guid>
      <description>개요 회귀분석이란 변수 사이의 관계를 알아내는 방법으로써, 특히 선형 관계를 밝히는 데 유용하다 단순회귀분석Simple Linear Regression은 그 중에서도 가장 쉬운 것으로, 종속변수(반응변수) 하나와 독립변수(설명변수) 하나에 대한 회귀분석을 말한다. 모델 1 독립변수 $x_{i}$ 와 종속변수 $y_{i}$ 가 선형 관계를 가진다는 말은 어떤 $a,b$ 에 대해 $y_{i} = ax_{i}</description>
    </item>
    
    <item>
      <title>적합치, 예측치, 잔차, 오차</title>
      <link>https://freshrimpsushi.github.io/posts/fitted-value-predict-value-residual-error/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fitted-value-predict-value-residual-error/</guid>
      <description>정의 1 회귀분석 $Y \leftarrow X_{1} + X_{2} + \cdots + X_{n}$ 으로 얻은 회귀식을 $y = \beta_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} + \cdots + \beta_{n} x_{n}$ 이라고 하고 $i$ 번째 데이터를 $(y_{i} , x_{i1} , x_{i2} , \cdots , x_{in})$ 와 같이 나타내도록 하자. 평균Mean: $$ \displaystyle \overline{y} := {{1} \over {n}} \sum_{i=1}^{n} y_{i} $$ 적합치Fitted Value: $i$ 번째 데이터 $y_{i}$ 에 대해 $$ \hat{y}_{i} := \beta_{0} + \beta_{1} x_{i1} + \beta_{2} x_{i2} + \cdots + \beta_{n} x_{in} $$ 예측치Predicted Value: 새로운 데이터 $y_{0}$ 에 대해 $$ \hat{y}_{0} := \beta_{0}</description>
    </item>
    
    <item>
      <title>계획행렬</title>
      <link>https://freshrimpsushi.github.io/posts/design-matrix/</link>
      <pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/design-matrix/</guid>
      <description>빌드업 R에서 내장데이터 faithful을 불러와 head() 함수를 통해 확인해보자. 고작 여섯개지만, 척 봐도 eruptions와 waiting은 양의 상관관계를 가지고 있는 것으로 보인다. 만약 이들의 관계를 어떤 두 상수 $\beta_{0}, \beta_{1}$ 에 대해 $$\text{(eruptions)} = \beta_{0} + \beta_{1} \cdot \text{( waiting) }$$ 으로 나타낼 수 있다면 좋을 것이다. 위 식은 두 변수의 선형관계를 직선의 방정식으로써 나타낸 것</description>
    </item>
    
    <item>
      <title>회귀분석이란?</title>
      <link>https://freshrimpsushi.github.io/posts/regression-analysis/</link>
      <pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regression-analysis/</guid>
      <description>설명 회귀분석은 거의 모든 통계적 기법의 근간이 되는만큼 너무 일반적이거나 너무 특수하게 설명된 경우가 많다. 그냥 회귀분석이 어떤건지 궁금한 사람에게 한마디로 설명한다면 변수 사이의 관계를 알아내는 방법이라고 할 수 있겠다. 이 유용하고도 놀라운 분석법은 우생학을 만들어낸 프랜시스 골턴Francis Galton의 아이디어에서 태어났다. 골</description>
    </item>
    
    <item>
      <title>상관관계가 없다고 독립인 것은 아니다</title>
      <link>https://freshrimpsushi.github.io/posts/no-correlation-implies-no-independency/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/no-correlation-implies-no-independency/</guid>
      <description>설명 독립이면 상관관계가 없지만, 상관관계가 없다고 독립인 것은 아니다. 상관관계가 없을 때 독립인 경우, 즉 필요충분조건이 되는 경우는 확률변수가 정규분포를 따를 때다. 왼쪽의 경우에 양의 상관관계, 오른쪽의 경우에 음의 상관관계가 있다고 한다. 그림의 cor는 상관계수로써, 두 변수가 얼마나 선형적인 관계를 가지는지를 나타내는 지표다. 독립</description>
    </item>
    
  </channel>
</rss>
