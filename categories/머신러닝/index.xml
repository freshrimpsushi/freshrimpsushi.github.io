<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>머신러닝 on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/</link>
    <description>Recent content in 머신러닝 on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Tue, 21 Jun 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>계층적 군집화</title>
      <link>https://freshrimpsushi.github.io/posts/hierarchical-clustering/</link>
      <pubDate>Tue, 21 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hierarchical-clustering/</guid>
      <description>알고리즘 Input $p$ 차원의 데이터 $N$개와 거리 $d$가 주어져있다고 하자. Step 1. 각각의 점을 하나의 군집으로 생각한다. 가장 가까운 두 군집을 하나의 군집으로 묶는다. Step 2. 다시 가장 가까운 두 군집을 하나의 군집으로 묶는다. Step 3. 마지막으로 하나의 군집이 남을 때까지 반복한다. Output 각 데이터들이 어떤 군집에 속하는지와 군집 사이의 거리를 반환한다. 이렇</description>
    </item>
    
    <item>
      <title>파이토치에서 모델의 가중치 값을 얻는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-obtaion-weights-of-model-in-pytorch/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-obtaion-weights-of-model-in-pytorch/</guid>
      <description>설명 다음과 같은 모델을 정의하자. import torch import torch.nn as nn class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.linear = nn.Linear(3, 3, bias=True) self.conv = nn.Conv2d(3, 5, 2) f = Model() 그러면 .weight와 .bias 메소드로 각 층의 가중치와 바이어스에 접근할 수 있다. 단 .weight(.bias)로 얻은 값은 텐서가 아니라 파라매터라는 객체이므로 가중치의 값을 가진 텐서를 얻고 싶다면 .weight.data(.bias.dat</description>
    </item>
    
    <item>
      <title>파이토치에서 텐서 깊은 복사하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/hot-to-deepcopy-pytorch-tensor/</link>
      <pubDate>Thu, 20 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hot-to-deepcopy-pytorch-tensor/</guid>
      <description>설명 파이토치 텐서도 다른 객체와 마찬가지로 copy.deepcopy()를 이용해 깊은 복사를 할 수 있다. &amp;gt;&amp;gt;&amp;gt; import torch &amp;gt;&amp;gt;&amp;gt; import copy &amp;gt;&amp;gt;&amp;gt; a = torch.ones(2,2) &amp;gt;&amp;gt;&amp;gt; b = a &amp;gt;&amp;gt;&amp;gt; c = copy.deepcopy(a) &amp;gt;&amp;gt;&amp;gt; a += 1 &amp;gt;&amp;gt;&amp;gt; a tensor([[2., 2.], [2., 2.]]) &amp;gt;&amp;gt;&amp;gt; b tensor([[2., 2.], [2., 2.]]) &amp;gt;&amp;gt;&amp;gt; c tensor([[1., 1.], [1., 1.]]) 하지만 이는 사용자가 명시적으로 정의한 텐서에 한해서만 가능하다. 가령 딥러닝 모델의 아웃풋을 copy.deepcopy()로 복사하려고</description>
    </item>
    
    <item>
      <title>파이토치에서 리스트와 반복문으로 인공 신경망 레이어 정의하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-define-neural-network-using-list-and-for-statement-in-pytorch/</link>
      <pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-define-neural-network-using-list-and-for-statement-in-pytorch/</guid>
      <description>설명 쌓아야할 층이 많거나, 신경망 구조를 자주 바꿔야하는 등의 이유로 인공 신경망의 정의를 자동화하고 싶은 경우가 있다. 이럴 때 다음과 같은 for문으로 정의하고 싶은 생각이 들 것이다. class Model(nn.Module): def __init__(self): super(Model, self).__init__() fc_ = [nn.Linear(n,n) for i in range(m)] def forward(self, x): for i in range(m): x = fc_[m](x) x = F.relu(x) return x 하지만 이와 같이 파이썬 리스트로 신경망을 정의하게되면 각 nn.Linear 층의 파라매터를 인식하지 못한다. 따</description>
    </item>
    
    <item>
      <title>파이토치에서 랜덤 순열 만들고 텐서 순서 섞는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-create-random-permutation-and-shuffle-order-of-tensor-in-pytorch/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-create-random-permutation-and-shuffle-order-of-tensor-in-pytorch/</guid>
      <description>torch.randperm()1 torch.randperm(n): 은 0부터 n-1개의 랜덤한 정수 순열을 리턴한다. 당연하게도 정수형이 아니면 입력으로 쓸 수 없다. &amp;gt;&amp;gt;&amp;gt; torch.randperm(4) tensor([2, 1, 0, 3]) &amp;gt;&amp;gt;&amp;gt; torch.randperm(8) tensor([4, 0, 1, 3, 2, 5, 6, 7]) &amp;gt;&amp;gt;&amp;gt; torch.randperm(16) tensor([12, 5, 6, 3, 15, 13, 2, 4, 7, 11, 1, 0, 9, 10, 14, 8]) &amp;gt;&amp;gt;&amp;gt; torch.randperm(4.0) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; TypeError: randperm(): argument &amp;#39;n&amp;#39; (position 1) must be int, not float tensor[indices] 인덱스 텐서를 인덱싱하면 그에 맞게 인덱스가 바뀐다. 기준은 dim=0이다. numpy array에 대해서도 같</description>
    </item>
    
    <item>
      <title>파이토치에서 가중치, 모델, 옵티마이저 저장하고 불러오는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/saving-and-loading-a-general-checkpoint-in-pytorch/</link>
      <pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/saving-and-loading-a-general-checkpoint-in-pytorch/</guid>
      <description>재학습하지 않는 경우1 2 3 저장하기 재학습하지 않는 경우라면 간단하게 가중치 혹은 모델만 저장해도 된다. 아래에서 말하겠지만 재학습을 할거라면 옵티마이저까지 저장해야한다. 가중치는 다음과 같이 간단히 저장할 수 있다. # 모델 정의 class CustomModel(nn.module): ...(이하생략) model = CustomModel() # 가중치 저장 torch.save(model.state_dict(), &#39;weights.pt&#39;) 이때 확장자는 .pt 혹은 .pth를 사용한다. 모델을 통째로 저장</description>
    </item>
    
    <item>
      <title>파이토치에서 Numpy 배열로 커스텀 데이터 셋 만들고 사용하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-create-and-use-custom-data-set-from-numpy-arrays-in-pytorch/</link>
      <pubDate>Sat, 04 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-create-and-use-custom-data-set-from-numpy-arrays-in-pytorch/</guid>
      <description>설명 &amp;gt;&amp;gt;&amp;gt; import numpy as np &amp;gt;&amp;gt;&amp;gt; import torch &amp;gt;&amp;gt;&amp;gt; from torch.utils.data import TensorDataset, DataLoader $32\times 32$의 크기로 된 &amp;lsquo;흑백&amp;rsquo;사진 100장을 쌓아올린 numpy 배열 $X$와 이에 대한 레이블 $Y$가 준비되어있다고 가정하자. 이를 다음가 같은 코드로 불러왔다고 하자. &amp;gt;&amp;gt;&amp;gt; X = np.load(&amp;quot;X.npy&amp;quot;) &amp;gt;&amp;gt;&amp;gt; X.shape (100, 32, 32) &amp;gt;&amp;gt;&amp;gt; Y = np.load(&amp;quot;Y.npy&amp;quot;) &amp;gt;&amp;gt;&amp;gt; Y.shape (100) 학습에 사용할 데이터 셋을 만들기 위해 다음과 같이 numpy배열을 tenso</description>
    </item>
    
    <item>
      <title>파이토치에서 가중치 초기화 하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/weights-initialization-in-pytorch/</link>
      <pubDate>Fri, 27 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/weights-initialization-in-pytorch/</guid>
      <description>코드1 다음과 같이 뉴럴 네트워크를 정의했다고 하자. forward 부분은 생략하였다. import torch import torch.nn as nn class Custom_Net(nn.Module): def __init__(self): super(Custom_Net, self).__init__() self.linear_1 = nn.Linear(1024, 1024, bias=False) self.linear_2 = nn.Linear(1024, 512, bias=False) self.linear_3 = nn.Linear(512, 10, bias=True) torch.nn.init.constant_(self.linear_1.weight.data, 0) torch.nn.init.unifiom_(self.linear_2.weight.data) torch.nn.init.xavier_normal_(self.linear_3.weight.data) torch.nn.init.xavier_normal_(self.linear_3.bias.data) def forward(self, x): ... 가중치의 초기화는 nn.init을 통해 설정할 수 있다. 바이어스가 있는 층의 경우 이도 따로 설정해주어야 한다. 기본 torch.nn.init.constant_(tensor, val): 상수로 설정한다. torch.nn.init.ones_(tensor): $1$로 설정한다. torch.nn.init.zeros_(tensor): $0$으로 설정한다</description>
    </item>
    
    <item>
      <title>파이토치에서 MLP 구현하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-construct-mlp-in-pytorch/</link>
      <pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-construct-mlp-in-pytorch/</guid>
      <description>라이브러리 import torch import torch.nn as nn import torch.nn.functional as F nn와 nn.functional에는 뉴럴 네트워크를 구성하는 여러가지 레이어, 손실함수, 활성화 함수 등이 포함되어있다. 인공신경망 정의 fully connected layer 3개를, relu 활성화 함수를 써서 쌓은 MLPmulti layer perceptron를 만들고 싶다면 다음과 같은 코드로 구현할 수 있다. class Custom_Net(nn.Module): def __init__(self): super(Custom_Net, self).__init__() self.fully_cnnected_1 = nn.Linear(1024, 1024, bias=False) self.fully_cnnected_2 = nn.Linear(1024, 512, bias=False) self.fully_cnnected_3 = nn.Linear(512, 10,</description>
    </item>
    
    <item>
      <title>파이토치 RuntimeError: grad can be implicitly created only for scalar outputs 해결법</title>
      <link>https://freshrimpsushi.github.io/posts/pytorch-error-solution-for-runtimeerror-grad-can-be-implicitly-created-only-for-scalar-outputs/</link>
      <pubDate>Mon, 09 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pytorch-error-solution-for-runtimeerror-grad-can-be-implicitly-created-only-for-scalar-outputs/</guid>
      <description>사례1 만약 손실함수를 loss = sum(a,b)와 같이 뒀다면 loss.backward()에서 백프로파게이션할 때 해당 오류가 날 수 있다. 이때 loss = torch.sum(a,b)로 바꿔주면 에러가 나지 않는다.</description>
    </item>
    
    <item>
      <title>역 전파 알고리즘</title>
      <link>https://freshrimpsushi.github.io/posts/back-propagation-algorithm/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/back-propagation-algorithm/</guid>
      <description>이 글은 역전파 알고리즘의 원리를 수학 전공자가 이해하기 쉽도록 작성되었다. 표기법 위 그림과 같은 인공 신경망이 주어졌다고 하자. $\mathbf{x} = (x_{1}, x_{2}, \dots, x_{n_{0}})$는 입력input, $y_{j}^{l}$는 $l$번째 층의 $j$번째 노드, $\hat{\mathbf{y}} = (\hat{y}_{1}, \hat{y}_{2}, \dots, \hat{y}_{\hat{n}})$는 출력output이다. $L \in \mat</description>
    </item>
    
    <item>
      <title>퍼셉트론 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/perceptron-convergence-theorem/</link>
      <pubDate>Mon, 05 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/perceptron-convergence-theorem/</guid>
      <description>$X^{+}$, $X^{-}$가 선형 분리 가능한 트레이닝 셋이라고 하자. $y$를 다음과 같은 레이블이라고 하자. $$ y_{i} = \pm 1\ (\mathbf{x}_{i} \in X^{\pm}) $$ 전체 트레이닝 셋 $X = X^{+} \cup X^{-}$에 $N$개의 데이터가 있다고 할 때 다음과 같은 순서로 입력값을 대입한다고 하자. $$ \mathbf{x}(1), \mathbf{x}(2), \cdots \mathbf{x}(N), \mathbf{x}(1), \mathbf{x}(2), \cdots \mathbf{x}(N),\mathbf{x}(1), \mathbf{x}(2), \cdots $$ 즉 마지막 데이터까지 학습 과정이 끝나면 처음으로 돌아가 다시 시작하는 것이</description>
    </item>
    
    <item>
      <title>마코프 결정 과정</title>
      <link>https://freshrimpsushi.github.io/posts/markov-decision-process/</link>
      <pubDate>Sun, 14 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/markov-decision-process/</guid>
      <description>정의 쉬운 정의1 강화학습에서 환경은 에이전트가 선택한 행동에 따라 다음 상태와 보상을 결정한다. 이 때 바로 직전 시점의 정보만 참고하여 상태와 보상을 결정하는 것을 마코프 결정 과정Markov decision procsee이라 한다. 이를 수식으로 나타내면 다음과 같다. $$ P(S_{t+1}, R_{t+1} | S_{t}, A_{t}) = P\left( S_{t+1}, R_{t+1} | S_{t}, A_{t}, S_{t-1}, A_{t-1}, \dots, S_{1}, A_{1}, S_{0}, A_{0} \right) $$ 어려운 정의 환경을 묘사하는 상태, 행</description>
    </item>
    
    <item>
      <title>머신러닝에서 강화학습이란</title>
      <link>https://freshrimpsushi.github.io/posts/reinforcement-learning-in-machine-learning/</link>
      <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reinforcement-learning-in-machine-learning/</guid>
      <description>정의 강화학습이란, 에이전트가 환경과 상호작용하여 누적 보상을 최대화하는 정책을 찾을 수 있도록 하는 것이다. 설명1 강화학습을 이루고 있는 요소들은 다음과 같다. 에이전트agent: 주어진 상태에 대해서, 정책에 따라 행동을 결정한다. 상태state: 에이전트가 처한 상황을 말한다. 행동action: 에이전트가 주어진 상태에서 취할 수</description>
    </item>
    
    <item>
      <title>머신 러닝에서 자주 쓰이는 벡터, 행렬의 그래디언트 계산표</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-for-vector-and-matrix-in-machine-learning/</link>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-for-vector-and-matrix-in-machine-learning/</guid>
      <description>스칼라 함수의 그래디언트: $$ \frac{ \partial f(\mathbf{w})}{ \partial \mathbf{w} } :=\nabla f(\mathbf{w})=\begin{bmatrix} \dfrac{ \partial f(\mathbf{w})}{ \partial w_{1} } &amp;amp; \dfrac{ \partial f(\mathbf{w})}{ \partial w_{2} } &amp;amp; \cdots &amp;amp; \dfrac{ \partial f(\mathbf{w})}{ \partial w_{n} } \end{bmatrix}^{T} $$ 내적의 그래디언트 $f(\mathbf{w})=\mathbf{w}^{T}\mathbf{x}$라고 하면 $$ \begin{align*} \frac{ \partial f(\mathbf{w})}{ \partial \mathbf{w} } =\frac{ \partial (\mathbf{w}^{T}\mathbf{x})}{ \partial \mathbf{w} } &amp;amp;=\begin{bmatrix} \dfrac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{1} } &amp;amp; \dfrac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{2} } &amp;amp; \cdots &amp;amp; \dfrac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{n} } \end{bmatrix}^{T} \\ &amp;amp;= \begin{bmatrix}</description>
    </item>
    
    <item>
      <title>딥러닝의 수학적 근거, 시벤코 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cybenko-theorem/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cybenko-theorem/</guid>
      <description>정리 $\sigma$ 가 연속 시그모이달 함수라고 하면 $$ S := \left\{ G(x) = \sum_{k=1}^{N} \alpha_{k} \sigma \left( y_{k}^{T} x+ \theta_{k} \right) : y_{k} \in \mathbb{R}^{n} \land \alpha_{k} , \theta_{k} \in \mathbb{R} \land N \in \mathbb{N} \right\} $$ 는 $C\left( I_{n} \right)$ 에서 균등 조밀하다. 달리 말하자면, 모든 $f \in C \left( I_{n} \right)$ 과 $\varepsilon &amp;gt; 0$ 에 대해 다음을 만족하는 $G \in S$ 가 존재한다. $$ \left\| G - f \right\| &amp;lt; \varepsilon $$ 다음을 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 을 시그모이달 함수라 한다. $$ \sigma (t) \to \begin{cases} 1 &amp;amp; \text{as } t \to + \infty \\ 0 &amp;amp; \text{as</description>
    </item>
    
    <item>
      <title>시그모이달 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-sigmoidal-function/</link>
      <pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-sigmoidal-function/</guid>
      <description>정의 다음을 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 을 시그모이달 함수Sigmoidal Function라 한다. $$ \sigma (t) \to \begin{cases} 1 &amp;amp; \text{as } t \to + \infty \\ 0 &amp;amp; \text{as } t \to - \infty \end{cases} $$ 정의에 대한 설명 시그모이달 함수의 정의에서 $0$ 이나 $1$ 이냐는 것은 사실 별로 중요하지 않고, 양이든 음이든 무한대로 갈 때 상수로 수렴한다는 것이 중요하다. 무한대가 아닌 곳에서 어떤 값을 가지</description>
    </item>
    
    <item>
      <title>차별 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-discriminatory-function/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-discriminatory-function/</guid>
      <description>정의 모든 $y \in \mathbb{R}^{n}$ 과 $\theta \in \mathbb{R}$ 와 어떤 $\mu \in M \left( I_{n} \right)$ 에 대해 $$ \int_{I_{n}} \sigma \left( y^{T} x + \theta \right) d \mu (x) = 0 \implies \mu =0 $$ 를 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 를 차별적 함수Discriminatory Function라 한다. $I_{n} := [0,1]^{n}$ 는 $n$차원 유닛 큐브로써, $n$ 개의 단위폐구간 $[0,1]$ 에 데카르트 곱을 취한 것이다. $M \left( I_{n} \right)$ 는 $I_{n} := [0,1]^{n}$ 에서 정의되는 부호 유한 정칙 보렐 측도의 집합</description>
    </item>
    
    <item>
      <title>머신 러닝에서 회귀를 위한 선형 모델</title>
      <link>https://freshrimpsushi.github.io/posts/linear-regression-in-machine-learning/</link>
      <pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-regression-in-machine-learning/</guid>
      <description>정의1 단순 모델 데이터 집합 $X = \left\{ \mathbf{x}_{i} \right\}$와 레이블 집합 $Y = \left\{ y_{i} \right\}$ 사이의 타겟 함수target function $f : X \to Y$를 다음과 같이 정의하자. $$ y_{i} = f(\mathbf{x}_{i}) $$ 머신러닝에서 선형회귀linear regression란, 다음의 식을 만족하는 $\mathbf{w}$에 대한 선형함수 $\hat{f}$를 찾는 것을 말한다. $$ y_{i} \approx \hat{y}_{i}</description>
    </item>
    
    <item>
      <title>머신 러닝에서 벡터, 행렬 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/vector-and-matrix-notation-in-machine-learning/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vector-and-matrix-notation-in-machine-learning/</guid>
      <description>선형대수를 잘 알지 못하거나, 잘 알아도 실제로 행렬 계산을 많이 해보지 않은 경우에 머신 러닝을 공부하면서 벡터와 행렬 표기법 때문에 힘들 수 있다. 해당 값이 스칼라인지, 벡터인지, 행렬인지 잘 구분해야하는데 실제로 손 계산을 해보면 익숙해지는데에 도움이 된다. 본 글의 표기법은 Bishop의 &#39;패턴 인식과 기계 학습&#39;1을 참고했다. 벡터 주로 소문</description>
    </item>
    
    <item>
      <title>로지스틱 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-a-logistic-function/</link>
      <pubDate>Sat, 07 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-a-logistic-function/</guid>
      <description>정의 1 로지스틱 함수란 미분 방정식의 해 $y &#39; = y(1-y)$ 로써, 다음과 같이 구해진다. $$ y(t) = {{ 1 } \over { 1 + e^{-t} }} $$ 설명 조금 더 일반적인 형태로써 $\displaystyle f(x) := {{ L } \over { 1 + e^{-k(x-x_{0})} }}$ 와 같은 꼴을 사용하기도 한다. 로지스틱 함수는 시그모이드 함수며, 쓰임새가 많아 동역학, 통계학, 딥러닝, 생물학 등 여러 분야에서 언급되기도 하는 함수다. 로지스틱? 문제는 도대</description>
    </item>
    
    <item>
      <title>시그모이드 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-a-sigmoid-function/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-a-sigmoid-function/</guid>
      <description>정의 1 유계 미분가능 스칼라 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 이 모든 $x \in \mathbb{R}$ 에서 $\sigma &#39; (x) \ge 0$ 이고 단 하나의 변곡점을 가지면 시그모이드 함수Sigmoid Function라고 한다. 시그모이달 함수와는 그 정의가 다르다. 종류 시그모이드 함수의 예시로써 다음과 같은 함수들이 알려져있다: 로지스틱 함수: $\displaystyle f(x) := {{ 1 } \over { 1 + e^{-x} }}$ 하이퍼볼릭 탄젠트: $\tanh x$ 아크</description>
    </item>
    
    <item>
      <title>퍼셉트론의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-perceptron/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-perceptron/</guid>
      <description>정의 선형 함수 $f(x) = wx + b$와 단위 계단 함수 $H$의 합성을 퍼셉트론perceptron이라 정의한다. $$ \text{Perceptron} := H \circ f (x) = H(wx + b) $$ 다변수 함수의 경우, $f(\mathbf{x}) = \mathbf{w}\cdot \mathbf{x} + b = w_{1}x_{1} + \cdots w_{n}x_{n} + b$이고, $$ \text{Perceptron} := H \circ f (\mathbf{x}) = H(\mathbf{w} \cdot \mathbf{x} + b) $$ 특히나 이를 단층 퍼셉트론single layer perceptron이라 부르기도 한다. 설명 퍼셉트론은 1957년 로젠</description>
    </item>
    
    <item>
      <title>컴퓨터 비전이란</title>
      <link>https://freshrimpsushi.github.io/posts/computer-vision/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/computer-vision/</guid>
      <description>설명 컴퓨터 비전 이란 주로 사람의 시각에 해당하는 기능을 컴퓨터가 수행할 수 있도록 하는 연구 분야이며 이미지나 영상을 다룬다. 컴퓨터 비전을 전문적으로 다루는 컨퍼런스로는 ICCV(International Conference on Computer Vision), ECCV(European Conference on Computer Vision), CVPR(Conference on Computer Vision and Pattern Recognition)등이 있다. 컴퓨터 비전에서 주로 다루는 문제는 아래의 사진과 같이 크게 3가지로 분류할 수 있다. 분류class</description>
    </item>
    
    <item>
      <title>딥러닝에서 연속 학습이란</title>
      <link>https://freshrimpsushi.github.io/posts/continual-learning-lifelong-learning-incremental-learning/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continual-learning-lifelong-learning-incremental-learning/</guid>
      <description>설명 딥러닝에서 연속 학습이란 평생 학습, 점진적 학습과 같은 말로서 인공 신경망이 순차적으로 여러 작업을 학습하는 것을 말한다. 인간의 경우 새로운 지식을 학습한다고 해서 기존의 지식을 잊어버리지 않는다. 물론 시간이 지나면 기존의 지식을 잊기도 하지만 이 원인이 새로운 지식을 학습했기 때문은 아니다. 하지만 인공 신경망의 경우 하나의 작업을 충분히 학</description>
    </item>
    
    <item>
      <title>논문 리뷰: Do We Need Zero Training Loss After Achieving Zero Training Error?</title>
      <link>https://freshrimpsushi.github.io/posts/flooding-do-we-need-zero-training-loss-after-achieving-zero-training-error-review/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/flooding-do-we-need-zero-training-loss-after-achieving-zero-training-error-review/</guid>
      <description>논문 리뷰 플루딩은 ICML 2020에서 발표된 Do We Need Zero Training Loss After Achieving Zero Training Error?에서 소개한 레귤라이제이션 기법을 말한다. 이 논문의 저자는 오버 피팅이 일어나는 이유가 아래 그림과 같이 지나치게 작은 트레이닝 로스라고 말한다. 따라서 아래 그림과 같이 학습 과정에서 트레이닝 로스가 특정한 값 이하로 내려가지 않게 조절하면 테스트 로스를 줄일 수 있을 것이</description>
    </item>
    
    <item>
      <title>머신러닝에서 많이 쓰이는 데이터 셋</title>
      <link>https://freshrimpsushi.github.io/posts/popular-datasets-in-machine-learning/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/popular-datasets-in-machine-learning/</guid>
      <description>이미지 처리 MNIST 머신 러닝을 공부할 때 가장 먼저 접할 데이터 셋이다. [엠니스트]라고 읽으며 $28\times 28$ 크기의 손글씨 사진 데이터이다. 학습 데이터 60,000개, 테스트 데이터 10,000개가 포함되어 있다[^1] CIFAR-10, CIFAR-100 CIFAR-10은 [싸이파-텐]이라고 읽으며, 10가지 카테고리 대한 $32\times 32$ 크기의 컬러 이미지 60,000장을 포함하는 데</description>
    </item>
    
    <item>
      <title>머신러닝에서 레귤러라이제이션이란</title>
      <link>https://freshrimpsushi.github.io/posts/regularization-in-machine-learning/</link>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regularization-in-machine-learning/</guid>
      <description>정의 트레이닝 로스가 아닌 테스트 로스를 줄이기 위해 알고리즘을 수정하는 모든 방법을 레귤러라이제이션 이라 한다.1 Goodfellow defines regularization as &amp;ldquo;any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.&amp;rdquo; 즉, 오버피팅을 막기 위한 모든 방법을 묶어서 레귤러라이제이션이라 한다. 머신러닝, 딥러닝 교재에서 흔히 소개되는 기법으로는 드롭 아웃이 있다. 종류 $l_{2}$ regularization $l_{1}$ regularization Weight decay Early stopping 드롭</description>
    </item>
    
    <item>
      <title>k-평균 군집화</title>
      <link>https://freshrimpsushi.github.io/posts/k-means-clustering/</link>
      <pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k-means-clustering/</guid>
      <description>알고리즘 Input $p$ 차원의 데이터 $N$ 개와 자연수 $k$ 가 주어져있다고 하자. Step 1. 초기화 $k$ 개의 점 $\mu_{1} , \cdots , \mu_{k}$ 을 랜덤하게 정한다. 각각의 $\mu_{j}$ 는 군집 $M_{j}$ 의 평균이 될 것이다. Step 2. 거리 계산 $i$번째 데이터 $x_{i}$ 와 $j = 1 , \cdots , k$ 에 대해서 $\| x_{i} - \mu_{j} \|$ 를 계산한다. 그 중 가장 작은 것을 골라 $x_{i} \in M_{j}$ 이 되도록 한다. 이를 각각의 $i = 1 , \cdots , N$ 에 대해 반복한다. Step 3. $\mu_{j}$</description>
    </item>
    
    <item>
      <title>지도학습과 비지도학습</title>
      <link>https://freshrimpsushi.github.io/posts/supervised-learning-vs-unsupervised-learning/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/supervised-learning-vs-unsupervised-learning/</guid>
      <description>정의 머신러닝에서 종속변수가 정해진 경우를 지도학습, 그렇지 않은 경우를 비지도학습이라고 한다. 예시 지도학습과 비지도학습의 차이는 쉽게 비유하자면 객관식과 주관식의 차이다. 예를 들어 위와 같이 6개의 타일을 주고 색을 답하는 문제가 있다고 해보자. 지도학습 그런데 여기서 녹색이냐 적색이냐의 두 가지 선택지만 있다면 솔직히 반반도 있고 아예 노란</description>
    </item>
    
    <item>
      <title>딥러닝에서의 드롭아웃</title>
      <link>https://freshrimpsushi.github.io/posts/dropout/</link>
      <pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dropout/</guid>
      <description>정의 드롭아웃Dropout이란 인공 신경망의 뉴런을 확률적으로 사용하지 않음으로써 과적합을 방지하는 기법이다. 설명 언뜻 생각하면 그냥 학습을 덜 하는 것이고 실제로도 어느정도는 맞는 말이다. 일정 확률로 뉴런을 사용하지 않다보면 &amp;lsquo;영향력이 지나치게 강한&amp;rsquo; 뉴런이 무시될 수도 있다. 영향력이 지나치게 강하다는 것은</description>
    </item>
    
    <item>
      <title>딥러닝에서의 소프트맥스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/softmax-function/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/softmax-function/</guid>
      <description>정의 $\mathbb{x} := x_{1} , \cdots , x_{n} \in \mathbb{R}^{n}$ 이라고 하자. $\displaystyle \sigma ( \mathbb{x} ) = {{ e^{x_{j}} } \over {\sum_{i=1}^{n} e^{x_{i}} }}$ 에 대해 $\sigma( \mathbb{x} ) := \left( \sigma_{1} (\mathbb{x}) , \cdots , \sigma_{n} (\mathbb{x} ) \right)$ 와 같이 정의된 $\sigma : \mathbb{R}^{n} \to (0,1)^{n}$ 을 소프트맥스 함수라 한다. 설명 소프트맥스 함수는 활성화 함수의 일종으로써, 정의역이 $\mathbb{R}^{n}$ 이라는 특징이 있다. 이는 벡터로 인풋을 받아 그 값들을 정규화하는데에 쓰기 위함이다. 어떤 $\mathbb{x} \in \mathbb{R}$ 이든 $\sigma( \mathbb{x} )$ 의 모든 성분은</description>
    </item>
    
    <item>
      <title>딥러닝에서의 활성화 함수</title>
      <link>https://freshrimpsushi.github.io/posts/activation-function/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/activation-function/</guid>
      <description>정의 실제 생물의 역치를 모방한 비선형 함수를 활성화 함수라 한다. 모티브 역치란 생물이 자극에 대해 어떤 반응을 일으키는 데 필요한 최소한의 자극의 세기로써, 딥러닝은 이를 모방하기 위해 각 노드의 계산 결과에 활성화 함수를 취해 다음 레이어로 넘긴다. 이러한 비선형적 보정이 없다면 딥러닝에서 히든 레이어를 두며 계산을 여러번 하는 의미가 없다.활성화 함</description>
    </item>
    
    <item>
      <title>딥러닝이란?</title>
      <link>https://freshrimpsushi.github.io/posts/deep-learning/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/deep-learning/</guid>
      <description>정의 딥러닝은 인공 신경망을 이용한 머신러닝의 일종으로, 특히 인공 신경망을 구성할 때 복수의 레이어를 사용하는 기법을 말한다. 모티브 인간의 두뇌가 뉴런들의 복잡한 연결관계로 구성된 것처럼 딥러닝 역시 인공 신경망을 보다 복잡하게 연결해서 퍼포먼스를 올린다. 감각세포에서 받은 자극이 척수를 통해 뇌로 전달되는 것처럼, 인공 신경망은 여러 레이어를</description>
    </item>
    
    <item>
      <title>머신러닝에서의 경사하강법</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-descent-algorithm/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-descent-algorithm/</guid>
      <description>개요 손실 함수의 기울기를 이용해 손실 함수의 극소값을 찾는 알고리즘 중 가장 간단한 방법으로 경사하강법Gradient Descent Algorithm이 있다. 설명 단, 이 때의 손실 함수 $L$ 은 데이터 셋 $X$ 가 픽스 된 상태에서 가중치와 바이어스에 대한 함수로 본다. 만약 인풋 데이터가 $\mathbb{x} \in \mathbb{R}^{m}$ 처럼 생겼다면 $L$ 은 $(w_{1} , w_{2} , \cdots , w_{m} , b) \in \mathbb{R}^{m+1}$ 에 대한 함수가 되는 것이다</description>
    </item>
    
    <item>
      <title>머신러닝에서의 손실 함수</title>
      <link>https://freshrimpsushi.github.io/posts/loss-function/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/loss-function/</guid>
      <description>정의 데이터 $Y = \begin{bmatrix} y_{1} \\ \vdots \\ y_{n} \end{bmatrix}$ 에 대한 추정치가 $\widehat{Y} = \begin{bmatrix} \widehat{ y_{1} } \\ \vdots \\ \widehat{y_{n}} \end{bmatrix}$ 와 같이 주어져 있을 때 데이터와 추정치의 괴리도를 나태는 스칼라 함수 $L : \mathbb{R}^{n} \to [ 0 , \infty )$ 를 손실 함수라 한다. 다른 이름 손실 함수는 학습을 통해 얻은 데이터의 추정치가 실제 데이터와 얼마나 차이나는지 평가하는 지표로 쓰인다. 이 값이 크면 클수록 많이 틀렸다는 의미고, 이 값이 $0$</description>
    </item>
    
    <item>
      <title>인공 신경망이란?</title>
      <link>https://freshrimpsushi.github.io/posts/ann-artificial-neural-network/</link>
      <pubDate>Sat, 06 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ann-artificial-neural-network/</guid>
      <description>정의 실제 생물의 신경계를 모방한 네트워크를 인공 신경망이라 한다. 모티브 신경계는 뉴런들의 결합으로 구성되어있다. 신경세포체는 가지돌기를 통해 자극을 받아들이며, 축삭돌기를 통해 전기자극을 전달한다. 인간을 포함한 많은 생물들은 이렇듯 단순한 뉴런들의 결합을 환경에 적합하도록 진화시켜왔다. 그 결과 신경계는 빛을 감지하거나, 다리를 움직</description>
    </item>
    
    <item>
      <title>ROC 곡선의 AUC 를 이용해 모형 비교하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</guid>
      <description>요약 ROC 곡선은 기본적으로 사각형 $[0,1]^2$ 을 가득 채울수록 좋고, 곡선의 왼쪽 상단의 꺾이는 점이 $(0,1)$ 에 가까울 수록 좋다. 설명 위의 두 ROC 곡선이 있다고 한다면 마음 편하게 &amp;lsquo;좋다&amp;rsquo;라고 할 수 있는 쪽은 오른쪽이다. 이 &amp;lsquo;좋다&amp;rsquo;는 말이 의미하는 것은 ROC 곡선을 그려내는 모형이 더 낫다는 뜻이다. 당연히 비교되는</description>
    </item>
    
    <item>
      <title>ROC 곡선을 이용해 최적의 컷오프 찾는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</link>
      <pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</guid>
      <description>개요 ROC 곡선을 그리면 트레이닝 데이터로 얻은 모형이 테스트 데이터를 어느정도로 잘 설명하는지 한 눈에 보여서 유용하다. 하지만 이 곡선은 모든 컷오프에 대한 분류율을 계산하고 이은 것이므로 결국 &amp;lsquo;어떤 컷오프로 0과 1을 분류할 것인가&amp;rsquo;는 알 수 없다. 이것을 알아내기 위해 교차검증의 방법론을 응용해보자. 검증 데이터 트레이</description>
    </item>
    
    <item>
      <title>R 에서 ROC 곡선 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</guid>
      <description>정의 오류행렬의 False Positive Rate와 True Positive Rate를 각각 축으로 두고 그린 그림을 ROC 곡선Receiver Operating Characteristic Curve이라 한다. 설명 ROC 곡선은 모델의 퍼포먼스를 한 눈에 보여줄 뿐만 아니라 최적의 컷오프를 찾고 모델 간의 비교에도 쓰이는 등 요긴하게 쓸 데가 많다. 예제를 통해 R 에서 ROC 곡선을 그려보고 그 의미를 이해해보자. 핵심적인 패키지로 ROCR</description>
    </item>
    
    <item>
      <title>교차검증</title>
      <link>https://freshrimpsushi.github.io/posts/cross-validation/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cross-validation/</guid>
      <description>모델 검증 데이터 분석을 해서 얻은 모델은 그 퍼포먼스가 적절한지 확인하는 과정이 필요하다. 주어진 데이터만 잘 설명하고 실전에서 전혀 힘을 쓰지 못하면 분석을 하는 의미가 없기 때문이다. 이를 위해서 전체 데이터를 모델을 얻는데 사용할 데이터셋과 그 모형의 퍼포먼스를 평가할 데이터셋으로 쪼갠다. 모델을 얻겠다는 것은 주어진 데이터를 이용해 다른 데이터</description>
    </item>
    
    <item>
      <title>오류행렬과 민감도, 특이도</title>
      <link>https://freshrimpsushi.github.io/posts/sensitivity-specipicity-and-confusion-matrix/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sensitivity-specipicity-and-confusion-matrix/</guid>
      <description>오류행렬 분류 문제에서 모형을 평가하는 지표로써 위와 같은 오류행렬Confusion Matrix을 참고할 수 있다. 정분류율Accuracy $$ \text{Accuracy} = {{TP + TN} \over { P + N }} $$ 위 표에서 P는 양성, N은 음성을 나타낸다. TP는 양성으로 예측되었고 실제로 양성인 경우, TN은 음성으로 예측되었고 실제로 음성인 경우다. 이 TP와 TN이 상대적으</description>
    </item>
    
    <item>
      <title>머신러닝에서 선형회귀모델의 경사하강법 학습</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-descent-for-linear-regression-in-machine-learning/</link>
      <pubDate>Sat, 07 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-descent-for-linear-regression-in-machine-learning/</guid>
      <description>개요1 선형회귀모델의 학습 방법 중 하나인 경사하강법gradient descent을 이용한 방법을 소개한다. 설명 데이터 셋을 $X = \left\{ \mathbf{x}_{i} \right\}_{i=1}^{N}$, 레이블 셋을 $Y = \left\{ y_{i} \right\}_{i=1}^{N}$라고 하자. 그리고 다음과 같은 선형회귀모델을 가정하자. $$ \hat{y} = \sum\limits_{j=0}^{n} w_{j}x_{j} = \mathbf{w}^{T} \mathbf{x} $$ 이때 $\mathbf{x} = \begin{bmatrix} x_{0} &amp;amp; \dots &amp;amp; x_{n} \end{bmatrix}^{T}$, $\mathbf{w} = \begin{bmatrix} w_{0} &amp;amp; \dots &amp;amp; w_{n} \end{bm</description>
    </item>
    
    <item>
      <title>줄리아 플럭스에서 MLP 구현해서 비선형함수 근사하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-implement-mlp-and-approximate-nonlinear-function-in-julia-flux/</link>
      <pubDate>Mon, 30 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-implement-mlp-and-approximate-nonlinear-function-in-julia-flux/</guid>
      <description>시작 using Flux using Plots using Distributions using Flux: @epochs function f(x) if -5 ≤ x &amp;lt; -2 y = -3x + 2 elseif -2 ≤ x &amp;lt; 1 y = x + 10 elseif 1 ≤ x &amp;lt; 2 y = -2x + 13 elseif 2 ≤ x &amp;lt; 3 y = 4x + 1 elseif 3 ≤ x ≤ 5 y = -4x + 25 end return y end x_ = -5:0.01:5 y_ = f.(x_) plot(x_, y_) 필요한 패키지를 불러오고, 우리가 근사하고 싶은 비선형함수를 정의하자. 학습집합 생성 julia&amp;gt; Data = convert.(Float32, rand(Uniform(-5,5), 1024)) 1024-element Vector{Float32}: julia&amp;gt; Data = convert(Matrix, reshape(Data, (1,1024))) 1×1024 Matrix{Float32}: 함수의 정의역인 $[-5, 5]$</description>
    </item>
    
    <item>
      <title>파이토치에서 리스트에 대한 타입 에러 &#39;TypeError: can&#39;t convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.&#39; 해결법</title>
      <link>https://freshrimpsushi.github.io/posts/pytorch-error-solution-for-typeerror-cant-convert-cuda0-device-type-tensor-to-numpy-use-tensor-to-copy-the-tensor-to-host-memory-first/</link>
      <pubDate>Thu, 26 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pytorch-error-solution-for-typeerror-cant-convert-cuda0-device-type-tensor-to-numpy-use-tensor-to-copy-the-tensor-to-host-memory-first/</guid>
      <description>에러 TypeError: can&#39;t convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first. 분명히 파이토치 텐서나 넘파이 배열이 아니라 리스트를 다루고 있음에도 불구하고 위와 같은 에러가 나올 수 있다. 시키는대로 .cpu()나 .numpy() 메서드를 쓰면 다음과 같은 에러를 만난다. AttributeError: &#39;list&#39; object has no attribute &#39;cpu&#39; 해결법 이러한 에러가 뜨는 원인은 리스트의 원소가 파이토치 텐서이기 때문이다. 따라서 에러를 해결하기</description>
    </item>
    
    <item>
      <title>줄리아 플럭스에서 MLP 구현하고 MNIST 학습하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/example-of-mlp-implementation-and-mnist-learning-in-julia-flux/</link>
      <pubDate>Wed, 18 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/example-of-mlp-implementation-and-mnist-learning-in-julia-flux/</guid>
      <description>MNIST 데이터 셋 불러오기 오래된 예제의 경우 이 부분에서 Flux.Data를 사용하는 코드를 볼 수 있는데, 이제는 플럭스에서 지원하지 않는다. julia&amp;gt; Flux.Data.MNIST.images() ┌ Warning: Flux&#39;s datasets are deprecated, please use the package MLDatasets.jl 공식 문서1에서 `MLDatasets.jl&#39; 패키지를 사용하라고 안내한다. julia&amp;gt; using Flux julia&amp;gt; using MLDatasets julia&amp;gt; imgs = MLDatasets.MNIST.traintensor() 28×28×60000 reinterpret(FixedPointNumbers.N0f8, ::Array{UInt8, 3}) julia&amp;gt; labs = MLDatasets.MNIST.trainlabels() 60000-element Vector{Int64} 이미지와 레이블을 이대로 쓸 수는 없다. 이미지는 자료형</description>
    </item>
    
    <item>
      <title>줄리아 플럭스에서 원-핫 인코딩하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-one-hot-encode-in-julia-flux/</link>
      <pubDate>Sat, 14 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-one-hot-encode-in-julia-flux/</guid>
      <description>코드1 onehot() onehot(x, labels, [default]) x .== labels를 반환한다. 다만 결과가 완전 같은 것은 아니고, OneHotVector라는 타입으로 반환한다. 여러 데이터를 인코딩할 때는 아래의 onehotbatch()를 쓴다. julia&amp;gt; 3 .== [1,3,4] 3-element BitVector: 0 1 0 julia&amp;gt; Flux.onehot(3, [1,3,4]) 3-element OneHotVector(::UInt32) with eltype Bool: ⋅ 1 ⋅ julia&amp;gt; Flux.onehot(3, 1:6) 6-element OneHotVector(::UInt32) with eltype Bool: ⋅ ⋅ 1 ⋅ ⋅ ⋅ julia&amp;gt; Flux.onehot(:c, [:a,:b,:c]) 3-element OneHotVector(::UInt32) with eltype Bool: ⋅ ⋅ 1 기본값을 지정하면 레이블에 없는</description>
    </item>
    
    <item>
      <title>줄리아 플럭스에서 MLP 구현하고 경사하강법으로 최적화하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-implement-mlp-and-optimize-it-using-gradient-descent-in-flux/</link>
      <pubDate>Thu, 29 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-implement-mlp-and-optimize-it-using-gradient-descent-in-flux/</guid>
      <description>MLP 구현 우선 줄리아의 머신러닝 패키지인 Flux.jl와 옵티마이저 업데이트 메소드 update!를 불러오자. using Flux using Flux: update! Dense() 함수로 선형층을 쓸 수 있다. Chain() 함수로 선형층을 쌓을 수 있다. 케라스와 파이토치에서 Sequential()과 같은 기능을 한다. julia&amp;gt; model = Chain( Dense(10, 5, relu), Dense(5, 5, relu), Dense(5, 2) ) Chain( Dense(10, 5, relu), # 55 parameters Dense(5, 5, relu), # 30 parameters Dense(5, 2), # 12 parameters ) # Total: 6 arrays, 97</description>
    </item>
    
    <item>
      <title>줄리아 플럭스에서 은닉층 다루는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-handle-hidden-layer-in-julia-flux/</link>
      <pubDate>Sun, 25 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-handle-hidden-layer-in-julia-flux/</guid>
      <description>선형1 플럭스에서 선형층은 Dense()로 구현할 수 있다. Dense(in, out, σ=identity; bias=true, init=glorot_uniform) Dense(W::AbstractMatrix, [bias, σ] 활성화함수에 대한 기본값은 항등함수이다. relu나 tanh, sigmoid 등 잘 알려진 함수를 사용할 수 있다. julia&amp;gt; Dense(5, 2) Dense(5, 2) # 12 parameters julia&amp;gt; Dense(5, 2, relu) Dense(5, 2, relu) # 12 parameters julia&amp;gt; Dense(5, 2, sigmoid) Dense(5, 2, σ) julia&amp;gt; d1 = Dense(ones(2, 5), false, tanh) # using provided weight matrix Dense(5, 2, tanh; bias=false) # 10 parameters julia&amp;gt; d1(ones(5)) 2-element Vector{Float64}: 0.9999092042625951 0.9999092042625951 컨볼루션2 플럭스에서 컨볼</description>
    </item>
    
    <item>
      <title>파이토치 텐서의 차원, 크기 다루기</title>
      <link>https://freshrimpsushi.github.io/posts/handling-dimension-and-size-of-tensor-in-pytorch/</link>
      <pubDate>Sat, 17 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/handling-dimension-and-size-of-tensor-in-pytorch/</guid>
      <description>정의 $A$를 파이토치 텐서라고 하자. 다음과 같은 순서쌍 $(a_{0}, a_{1}, \dots, a_{n-1})$을 $A$의 사이즈라고 한다. $$ \text{A.size() = torch.Size}([a_{0}, a_{1}, \dots, a_{n-1} ]) $$ $\prod \limits_{i=0}^{n-1} a_{i} = a_{0} \times a_{1} \times \cdots a_{n-1}$을 $A$의 크기라고 하자. $A$를 $n$차원 텐서라고 한다. $a_{i}$는 각각 $i$번째 차원의 크기이며 $1$보다 큰 정수이다. 파이썬이므로 $0$번째 차원</description>
    </item>
    
    <item>
      <title>파이토치 텐서 패딩하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/hot-to-pad-a-tensor-in-pytorch/</link>
      <pubDate>Mon, 05 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hot-to-pad-a-tensor-in-pytorch/</guid>
      <description>코드 1 torch.nn.functional.pad(input, pad, mode=&#39;constant&#39;, value=0.0) input: 패딩할 텐서 pad: 패딩할 위치 mode: 패딩할 방법 mode: 패딩할 값 설명 pad $n$차원 텐서를 input으로 쓸 때, 최대 $2n-$순서쌍을 인자를 입력할 수 있다. $$ ((n-1)_{\text{low}}, (n-1)_{\text{up}}, (n-2)_{\text{low}}, (n-2)_{\text{up}}, \dots, 1_{\text{low}}, 1_{\text{up}}, 0_{\text{low}}, 0_{\text{up}}) $$ $i_{\text{low}}$는 $i$번째 차원의 낮은 인덱스 쪽, 그러니까 $0$번째 값 이전에 몇 개의 값을 패딩할 지를 나타낸다. $i_{\te</description>
    </item>
    
    <item>
      <title>줄리아에서 머신러닝 데이터 셋 사용하는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-use-machine-learning-data-sets-in-julia/</link>
      <pubDate>Fri, 17 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-use-machine-learning-data-sets-in-julia/</guid>
      <description>설명 MLDatasets.jl1 2 패키지로 아래와 같은 데이터 셋을 사용할 수 있다. Vision CIFAR10 CIFAR100 EMNIST FashionMNIST MNIST SVHN2 Miscellaneous BostonHousing Iris Mutagenesis Text PTBLM UD_English Graphs CiteSeer Cora PubMed TUDatasets 이 데이터를 원-핫 인코딩하거나, 학습시키는 방법은 다음을 참고하라. 데이터 원-핫 인코딩하는 방법 MLP 구현해서 MNIST 데이터 셋 학습시키는 방법 예시 MNIST 데이터와 레이블을 한 번에 불러오려면 .traindata()를 사용한다. julia&amp;gt; Train_X, Train_Y = MLDatasets.MNIST.traindata() julia&amp;gt; typeof(Train_X) Base.ReinterpretArray{FixedPointNumbers.N0f8,</description>
    </item>
    
    <item>
      <title>파이토치에서 텐서 붙이거나 쌓는 방법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-concatenate-or-stack-tensors-in-pytorch/</link>
      <pubDate>Thu, 09 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-concatenate-or-stack-tensors-in-pytorch/</guid>
      <description>텐서 붙이기 cat()1 cat(tensors, dim=0)는 2개 이상의 텐서들을 지정한 차원을 기준으로 붙인다. 기준이 된다는 말은 지정한 차원의 크기가 늘어나도록 붙인다는 뜻이다. 따라서 당연하게도 지정한 차원 외의 나머지 부분의 크기가 같아야한다. 예를 들어 $(2,2)$ 텐서와 $(2,3)$ 텐서가 있다면 0번째 차원으로는 붙일 수 없고, 1번째 차원으로는 붙일 수 있다. $$ \text{cat} \Big( [(a,b),(a,b)], \dim=0 \Big) = (2a,b) \\ \text{cat}</description>
    </item>
    
    <item>
      <title>표현자 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-representer-theorem/</link>
      <pubDate>Fri, 29 Jun 1923 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-representer-theorem/</guid>
      <description>정리 인풋 집합Input Set $X \ne \emptyset$ 과 양정부호 커널 $k: X \times X \to \mathbb{R}$ 이 주어져 있다고 하자. 학습데이터셋Training Dataset을 $$ D := \left\{ \left( x_{i} , y_{i} \right) \right\}_{i=1}^{m} \subset X \times \mathbb{R} $$ 라 하고, 재생 커널 힐베르트 공간 $H_{k}$ 의 클래스 $$ \mathcal{F} := \left\{ f \in \mathbb{R}^{X} : f \left( \cdot \right) = \sum_{i=1}^{\infty} \beta_{i} k \left( \cdot , z_{i} \right) \land \beta_{i} \in \mathbb{R} \land z_{i} \in X \land \left\| f \right\| &amp;lt; \infty \right\} \subset H_{k} $$ 를 위와 같이 둔다. 임의의 목적 함수 $c :</description>
    </item>
    
    <item>
      <title>머신러닝에서의 정부호 커널과 재생 커널 힐베르트 공간</title>
      <link>https://freshrimpsushi.github.io/posts/kernel-in-machine-learning/</link>
      <pubDate>Mon, 25 Jun 1923 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/kernel-in-machine-learning/</guid>
      <description>정의 1 2 인풋 공간Input Space $X \ne \emptyset$ 이 정의역이고 공역이 복소수의 집합 $\mathbb{C}$ 인 사상 $f: X \to \mathbb{C}$ 들로 이루어진 함수들의 공간 $\left( H , \left&amp;lt; \cdot , \cdot \right&amp;gt; \right) \subset \mathbb{C}^{X}$ 가 힐베르트공간이라 하자. 재생 커널 힐베르트 공간 픽스된 하나의 데이텀Datum $x \in X$ 에 대해 다음과 같이 함수 $f \in H$ 를 취해주는 범함수 $\delta_{x} : H \to \mathbb{C}$ 를 $x$ 에서의 (디랙) 평가 범함수(Dirac) Evaluation</description>
    </item>
    
    <item>
      <title>서포트 벡터 머신</title>
      <link>https://freshrimpsushi.github.io/posts/support-vector-machine/</link>
      <pubDate>Sun, 17 Jun 1923 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/support-vector-machine/</guid>
      <description>모델 1 쉬운 정의 이진분류Binary Classification 가능한 데이터를 가장 잘 구분하도록하는 직선이나 평면을 구하는 방법을 서포트 벡터 머신이라 한다. 어려운 정의 내적공간 $X = \mathbb{R}^{p}$ 와 라벨링Labeling $Y = \left\{ -1, +1 \right\}$ 에 대해 $n$ 개의 데이터를 모아놓은 학습 데이터셋Training Dataset을 $D = \left\{ \left( \mathbf{x}_{k} , y_{k} \right) \right\}_{k=1}^{n} \subset X \times Y$ 라 두고, $$ \begin{align*} X^{+} :=&amp;amp; \left\{ \mathbf{x}_{k} \in</description>
    </item>
    
  </channel>
</rss>
