<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>머신러닝 on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/</link>
    <description>Recent content in 머신러닝 on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Tue, 27 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>역 전파 알고리즘</title>
      <link>https://freshrimpsushi.github.io/posts/back-propagation-algorithm/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/back-propagation-algorithm/</guid>
      <description>이 글은 역전파 알고리즘의 원리를 수학 전공자가 이해하기 쉽도록 작성되었다. 표기법 위 그림과 같은 인공 신경망이 주어졌다고 하자. $\mathbf{x} = (x_{1}, x_{2}, \dots, x_{n_{0}})$는 입력input, $y_{j}^{l}$는 $l$번째 층의 $j$번째 노드, $\hat{\mathbf{y}} = (\hat{y}_{1}, \hat{y}_{2}, \dots, \hat{y}_{\hat{n}})$는 출력output이다. $L \in \mat</description>
    </item>
    
    <item>
      <title>퍼셉트론 수렴 정리</title>
      <link>https://freshrimpsushi.github.io/posts/perceptron-convergence-theorem/</link>
      <pubDate>Mon, 05 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/perceptron-convergence-theorem/</guid>
      <description>$X^{+}$, $X^{-}$가 선형 분리 가능한 트레이닝 셋이라고 하자. $y$를 다음과 같은 레이블이라고 하자. $$ y_{i} = \pm 1\ (\mathbf{x}_{i} \in X^{\pm}) $$ 전체 트레이닝 셋 $X = X^{+} \cup X^{-}$에 $N$개의 데이터가 있다고 할 때 다음과 같은 순서로 입력값을 대입한다고 하자. $$ \mathbf{x}(1), \mathbf{x}(2), \cdots \mathbf{x}(N), \mathbf{x}(1), \mathbf{x}(2), \cdots \mathbf{x}(N),\mathbf{x}(1), \mathbf{x}(2), \cdots $$ 즉 마지막 데이터까지 학습 과정이 끝나면 처음으로 돌아가 다시 시작하는 것이</description>
    </item>
    
    <item>
      <title>머신 러닝에서 벡터 행렬의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-for-vector-and-matrix-in-machine-learning/</link>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-for-vector-and-matrix-in-machine-learning/</guid>
      <description>스칼라 함수의 그래디언트: $$ \frac{ \partial f(\mathbf{w})}{ \partial \mathbf{w} } :=\nabla_{\mathbf{w}}f(\mathbf{w})=\begin{bmatrix} \frac{ \partial f(\mathbf{w})}{ \partial w_{1} },\frac{ \partial f(\mathbf{w})}{ \partial w_{2} },\cdots,\frac{ \partial f(\mathbf{w})}{ \partial w_{n} } \end{bmatrix}^{T} $$ 내적의 그래디언트 $f(\mathbf{w})=\mathbf{w}^{T}\mathbf{x}$라고 하면 $$ \begin{align*} \frac{ \partial f(\mathbf{w})}{ \partial \mathbf{w} } =\frac{ \partial (\mathbf{w}^{T}\mathbf{x})}{ \partial \mathbf{w} } &amp;amp;=\begin{bmatrix} \frac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{1} },\frac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{2} },\cdots,\frac{ \partial \left( \sum _{i=1} ^{n} w_{i}x_{i}\right)}{ \partial w_{n} } \end{bmatrix}^{T} \\ &amp;amp;= \begin{bmatrix} x_{1} &amp;amp; x_{2} &amp;amp; \cdots &amp;amp; x_{n} \end{bmatrix}^{T} \\ &amp;amp;= \mathbf{x} \end{align*} $$</description>
    </item>
    
    <item>
      <title>딥러닝의 수학적 근거, 시벤코 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-cybenko-theorem/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-cybenko-theorem/</guid>
      <description>정리 $\sigma$ 가 연속 시그모이달 함수라고 하면 $$ \displaystyle S := \left\{ G(x) = \sum_{k=1}^{N} \alpha_{k} \sigma \left( y_{k}^{T} x+ \theta_{k} \right) : y_{k} \in \mathbb{R}^{n} \land \alpha_{k} , \theta_{k} \in \mathbb{R} \land N \in \mathbb{N} \right\} $$ 는 $C\left( I_{n} \right)$ 에서 균등 조밀하다. 달리 말하자면, 모든 $f \in C \left( I_{n} \right)$ 과 $\varepsilon &amp;gt; 0$ 에 대해 다음을 만족하는 $G \in S$ 가 존재한다. $$ \left\| G - f \right\| &amp;lt; \varepsilon $$ 다음을 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 을 시그모이달 함수라 한다. $$ \sigma (t) \to \begin{cases} 1 &amp;amp; \text{as } t \to + \infty \\ 0 &amp;amp;</description>
    </item>
    
    <item>
      <title>시그모이달 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-sigmoidal-function/</link>
      <pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-sigmoidal-function/</guid>
      <description>정의 다음을 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 을 시그모이달 함수Sigmoidal Function라 한다. $$ \sigma (t) \to \begin{cases} 1 &amp;amp; \text{as } t \to + \infty \\ 0 &amp;amp; \text{as } t \to - \infty \end{cases} $$ 정의에 대한 설명 시그모이달 함수의 정의에서 $0$ 이나 $1$ 이냐는 것은 사실 별로 중요하지 않고, 양이든 음이든 무한대로 갈 때 상수로 수렴한다는 것이 중요하다. 무한대가 아닌 곳에서 어떤 값을 가지</description>
    </item>
    
    <item>
      <title>차별 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-discriminatory-function/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-discriminatory-function/</guid>
      <description>정의 모든 $y \in \mathbb{R}^{n}$ 과 $\theta \in \mathbb{R}$ 와 어떤 $\mu \in M \left( I_{n} \right) $ 에 대해 $$ \int_{I_{n}} \sigma \left( y^{T} x + \theta \right) d \mu (x) = 0 \implies \mu =0 $$ 를 만족하는 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 를 차별적 함수Discriminatory Function라 한다. $I_{n} := [0,1]^{n}$ 는 $n$차원 유닛 큐브로써, $n$ 개의 단위폐구간 $[0,1]$ 에 데카르트 곱을 취한 것이다. $M \left( I_{n} \right)$ 는 $I_{n} := [0,1]^{n}$ 에서 정의되는 부호 유한 정칙 보렐 측도의 집</description>
    </item>
    
    <item>
      <title>머신 러닝에서 선형 회귀</title>
      <link>https://freshrimpsushi.github.io/posts/linear-regression-in-machine-learning/</link>
      <pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/linear-regression-in-machine-learning/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 머신 러닝에서 선형 회귀 란 주어진 작업에 대한 실제 함수를 가장 잘 근사하는 선형 함수를 찾는 알고리즘이다. 어떤 트레이닝 샘플 $D=\left\{ (\mathbf{x}_{1},y_{1}),\dots,(\mathbf{x}_{n},y_{n }) \right\}$가 있다고 하자. 이때 인풋 $x_{i}$에 대해서 아웃풋 $y_{i}$를 주는 함수를 $f$라고 하자. $$ f(\mathbf{x}_{i})=y_{i}\quad (i=1,\dots,n) $$ 즉 $f$는 모든 데이터 $\</description>
    </item>
    
    <item>
      <title>머신 러닝에서 벡터 행렬 표기법</title>
      <link>https://freshrimpsushi.github.io/posts/vector-and-matrix-notation-in-machine-learning/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/vector-and-matrix-notation-in-machine-learning/</guid>
      <description>선형대수를 잘 알지 못하거나, 잘 알아도 실제로 행렬 계산을 많이 해보지 않은 경우에 머신 러닝을 공부하면서 벡터와 행렬 표기법 때문에 힘들 수 있다. 해당 값이 스칼라인지, 벡터인지, 행렬인지 잘 구분해야하는데 실제로 손 계산을 해보면 익숙해지는데에 도움이 된다. 본 글의 표기법은 비숍의 &#39; 패턴 인식과 기계 학습1 &amp;lsquo;을 참고했다. 벡터 주로</description>
    </item>
    
    <item>
      <title>로지스틱 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-a-logistic-function/</link>
      <pubDate>Sat, 07 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-a-logistic-function/</guid>
      <description>정의 1 로지스틱 함수란 미분 방정식의 해 $y&#39; = y(1-y)$ 로써, 다음과 같이 구해진다. $$ y(t) = {{ 1 } \over { 1 + e^{-t} }} $$ 설명 조금 더 일반적인 형태로써 $\displaystyle f(x) := {{ L } \over { 1 + e^{-k(x-x_{0})} }}$ 와 같은 꼴을 사용하기도 한다. 로지스틱 함수는 시그모이드 함수며, 쓰임새가 많아 동역학, 통계학, 딥러닝, 생물학 등 여러 분야에서 언급되기도 하는 함수다. 로지스틱? 문제는 도대체</description>
    </item>
    
    <item>
      <title>시그모이드 함수란?</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-a-sigmoid-function/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-a-sigmoid-function/</guid>
      <description>정의 1 유계 미분가능 스칼라 함수 $\sigma : \mathbb{R} \to \mathbb{R}$ 이 모든 $x \in \mathbb{R}$ 에서 $\sigma &#39; (x) \ge 0$ 이고 단 하나의 변곡점을 가지면 시그모이드 함수Sigmoid Function라고 한다. - 시그모이달 함수와는 그 정의가 다르다. 종류 시그모이드 함수의 예시로써 다음과 같은 함수들이 알려져있다: 로지스틱 함수: $\displaystyle f(x) := {{ 1 } \over { 1 + e^{-x} }}$ 하이퍼볼릭 탄젠트: $\tanh x$ 아</description>
    </item>
    
    <item>
      <title>로젠블렛의 단층 퍼셉트론</title>
      <link>https://freshrimpsushi.github.io/posts/rosenblatts-perceptron/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/rosenblatts-perceptron/</guid>
      <description>설명 퍼셉트론 은 1957년 로젠블렛에 의해 고안됐으며 최초의 지도 학습 모델이다. 위 그림1과 같이 단일 층으로 구성돼있고 활성화 함수 $\varphi$는 입력 데이터와 가중치의 곱을 $+1$ 혹은 $-1$로 반환한다. $-1$대신 $0$이라 두기도 하는데 본질적으로 차이는 없다. 간단한 예로 아래 그림과 같은 $m=2$인 2차원 데이터를 생각해보</description>
    </item>
    
    <item>
      <title>컴퓨터 비전이란</title>
      <link>https://freshrimpsushi.github.io/posts/computer-vision/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/computer-vision/</guid>
      <description>설명 컴퓨터 비전 이란 주로 사람의 시각에 해당하는 기능을 컴퓨터가 수행할 수 있도록 하는 연구 분야이며 이미지나 영상을 다룬다. 컴퓨터 비전을 전문적으로 다루는 컨퍼런스로는 ICCV(International Conference on Computer Vision), ECCV(European Conference on Computer Vision), CVPR(Conference on Computer Vision and Pattern Recognition)등이 있다. 컴퓨터 비전에서 주로 다루는 문제는 아래의 사진과 같이 크게 3가지로 분류할 수 있다. 분류class</description>
    </item>
    
    <item>
      <title>딥러닝에서 연속 학습이란</title>
      <link>https://freshrimpsushi.github.io/posts/continual-learning-lifelong-learning-incremental-learning/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/continual-learning-lifelong-learning-incremental-learning/</guid>
      <description>설명 딥러닝에서 연속 학습이란 평생 학습, 점진적 학습과 같은 말로서 인공 신경망이 순차적으로 여러 작업을 학습하는 것을 말한다. 인간의 경우 새로운 지식을 학습한다고 해서 기존의 지식을 잊어버리지 않는다. 물론 시간이 지나면 기존의 지식을 잊기도 하지만 이 원인이 새로운 지식을 학습했기 때문은 아니다. 하지만 인공 신경망의 경우 하나의 작업을 충분히 학</description>
    </item>
    
    <item>
      <title>논문 리뷰: Do We Need Zero Training Loss After Achieving Zero Training Error?</title>
      <link>https://freshrimpsushi.github.io/posts/flooding-do-we-need-zero-training-loss-after-achieving-zero-training-error-review/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/flooding-do-we-need-zero-training-loss-after-achieving-zero-training-error-review/</guid>
      <description>논문 리뷰 플루딩은 ICML 2020에서 발표된 Do We Need Zero Training Loss After Achieving Zero Training Error?에서 소개한 레귤라이제이션 기법을 말한다. 이 논문의 저자는 오버 피팅이 일어나는 이유가 아래 그림과 같이 지나치게 작은 트레이닝 로스라고 말한다. 따라서 아래 그림과 같이 학습 과정에서 트레이닝 로스가 특정한 값 이하로 내려가지 않게 조절하면 테스트 로스를 줄일 수 있을 것이</description>
    </item>
    
    <item>
      <title>머신러닝에서 많이 쓰이는 데이터 셋</title>
      <link>https://freshrimpsushi.github.io/posts/popular-datasets-in-machine-learning/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/popular-datasets-in-machine-learning/</guid>
      <description>이미지 처리 MNIST 머신 러닝을 공부할 때 가장 먼저 접할 데이터 셋이다. [엠니스트]라고 읽으며 $28\times 28$ 크기의 손글씨 사진 데이터이다. 학습 데이터 60,000개, 테스트 데이터 10,000개가 포함되어 있다[^1] CIFAR-10, CIFAR-100 CIFAR-10은 [싸이파-텐]이라고 읽으며, 10가지 카테고리 대한 $32\times 32$ 크기의 컬러 이미지 60,000장을 포함하는 데</description>
    </item>
    
    <item>
      <title>머신러닝에서 레귤라이제이션이란</title>
      <link>https://freshrimpsushi.github.io/posts/regularization-in-machine-learning/</link>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regularization-in-machine-learning/</guid>
      <description>정의 트레이닝 로스가 아닌 테스트 로스를 줄이기 위해 알고리즘을 수정하는 모든 방법을 레귤라이제이션 이라 한다.1 Goodfellow defines regularization as &amp;ldquo;any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.&amp;rdquo; 즉, 오버피팅을 막기 위한 모든 방법을 묶어서 레귤라이제이션이라 한다. 머신러닝, 딥러닝 교재에서 흔히 소개되는 기법으로는 드롭 아웃이 있다. 종류 $l_{2}$ regularization $l_{1}$ regularization Weight decay Early stopping 드롭 아웃</description>
    </item>
    
    <item>
      <title>k-평균 군집화</title>
      <link>https://freshrimpsushi.github.io/posts/k-means-clustering/</link>
      <pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/k-means-clustering/</guid>
      <description>알고리즘 Input $p$ 차원의 데이터 $N$ 개와 자연수 $k$ 가 주어져있다고 하자. Step 1. 초기화 $k$ 개의 점 $\mu_{1} , \cdots , \mu_{k} $ 을 랜덤하게 정한다. 각각의 $\mu_{j}$ 는 군집 $M_{j}$ 의 평균이 될 것이다. Step 2. 거리 계산 $i$ 번째 데이터 $x_{i}$ 와 $j = 1 , \cdots , k$ 에 대해서 $\| x_{i} - \mu_{j} \| $ 를 계산한다. 그 중 가장 작은 것을 골라 $x_{i} \in M_{j}$ 이 되도록 한다. 이를 각각의 $i = 1 , \cdots , N $ 에 대해 반복한다. Step 3.</description>
    </item>
    
    <item>
      <title>지도학습과 비지도학습</title>
      <link>https://freshrimpsushi.github.io/posts/supervised-learning-vs-unsupervised-learning/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/supervised-learning-vs-unsupervised-learning/</guid>
      <description>정의 머신러닝에서 종속변수가 정해진 경우를 지도학습, 그렇지 않은 경우를 비지도학습이라고 한다. 예시 지도학습과 비지도학습의 차이는 쉽게 비유하자면 객관식과 주관식의 차이다. 예를 들어 위와 같이 6개의 타일을 주고 색을 답하는 문제가 있다고 해보자. 지도학습 그런데 여기서 녹색이냐 적색이냐의 두 가지 선택지만 있다면 솔직히 반반도 있고 아예 노란</description>
    </item>
    
    <item>
      <title>딥러닝에서의 드롭아웃</title>
      <link>https://freshrimpsushi.github.io/posts/dropout/</link>
      <pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/dropout/</guid>
      <description>정의 드롭아웃Dropout이란 인공 신경망의 뉴런을 확률적으로 사용하지 않음으로써 과적합을 방지하는 기법이다. 설명 언뜻 생각하면 그냥 학습을 덜 하는 것이고 실제로도 어느정도는 맞는 말이다. 일정 확률로 뉴런을 사용하지 않다보면 &amp;lsquo;영향력이 지나치게 강한&amp;rsquo; 뉴런이 무시될 수도 있다. 영향력이 지나치게 강하다는 것은</description>
    </item>
    
    <item>
      <title>딥러닝에서의 소프트맥스 함수</title>
      <link>https://freshrimpsushi.github.io/posts/softmax-function/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/softmax-function/</guid>
      <description>정의 $\mathbb{x} := x_{1} , \cdots , x_{n} \in \mathbb{R}^{n}$ 이라고 하자. $\displaystyle \sigma ( \mathbb{x} ) = {{ e^{x_{j}} } \over {\sum_{i=1}^{n} e^{x_{i}} }} $ 에 대해 $\sigma( \mathbb{x} ) := \left( \sigma_{1} (\mathbb{x}) , \cdots , \sigma_{n} (\mathbb{x} ) \right) $ 와 같이 정의된 $\sigma : \mathbb{R}^{n} \to (0,1)^{n}$ 을 소프트맥스 함수라 한다. 설명 소프트맥스 함수는 활성화 함수의 일종으로써, 정의역이 $\mathbb{R}^{n}$ 이라는 특징이 있다. 이는 벡터로 인풋을 받아 그 값들을 정규화하는데에 쓰기 위함이다. 어떤 $\mathbb{x} \in \mathbb{R}$ 이든 $\sigma( \mathbb{x} )$ 의 모든 성</description>
    </item>
    
    <item>
      <title>딥러닝에서의 활성화 함수</title>
      <link>https://freshrimpsushi.github.io/posts/activation-function/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/activation-function/</guid>
      <description>정의 실제 생물의 역치를 모방한 비선형 함수를 활성화 함수라 한다. 모티브 역치란 생물이 자극에 대해 어떤 반응을 일으키는 데 필요한 최소한의 자극의 세기로써, 딥러닝은 이를 모방하기 위해 각 노드의 계산 결과에 활성화 함수를 취해 다음 레이어로 넘긴다. 이러한 비선형적 보정이 없다면 딥러닝에서 히든 레이어를 두며 계산을 여러번 하는 의미가 없다.활성화 함</description>
    </item>
    
    <item>
      <title>딥러닝이란?</title>
      <link>https://freshrimpsushi.github.io/posts/deep-learning/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/deep-learning/</guid>
      <description>정의 딥러닝은 인공 신경망을 이용한 머신러닝의 일종으로, 특히 인공 신경망을 구성할 때 복수의 레이어를 사용하는 기법을 말한다. 모티브 인간의 두뇌가 뉴런들의 복잡한 연결관계로 구성된 것처럼 딥러닝 역시 인공 신경망을 보다 복잡하게 연결해서 퍼포먼스를 올린다. 감각세포에서 받은 자극이 척수를 통해 뇌로 전달되는 것처럼, 인공 신경망은 여러 레이어를</description>
    </item>
    
    <item>
      <title>머신러닝에서의 경사하강법</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-descent-algorithm/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-descent-algorithm/</guid>
      <description>개요 손실 함수의 기울기를 이용해 손실 함수의 극소값을 찾는 알고리즘 중 가장 간단한 방법으로 경사하강법Gradient Descent Algorithm이 있다. 설명 단, 이 때의 손실 함수 $L$ 은 데이터 셋 $X$ 가 픽스 된 상태에서 가중치와 바이어스에 대한 함수로 본다. 만약 인풋 데이터가 $\mathbb{x} \in \mathbb{R}^{m}$ 처럼 생겼다면 $L$ 은 $(w_{1} , w_{2} , \cdots , w_{m} , b) \in \mathbb{R}^{m+1}$ 에 대한 함수가 되는 것이다</description>
    </item>
    
    <item>
      <title>머신러닝에서의 손실 함수</title>
      <link>https://freshrimpsushi.github.io/posts/loss-function/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/loss-function/</guid>
      <description>정의 데이터 $Y = \begin{bmatrix} y_{1} \\ \vdots \\ y_{n} \end{bmatrix}$ 에 대한 추정치가 $\widehat{Y} = \begin{bmatrix} \widehat{ y_{1} } \\ \vdots \\ \widehat{y_{n}} \end{bmatrix}$ 와 같이 주어져 있을 때 데이터와 추정치의 괴리도를 나태는 스칼라 함수 $L : \mathbb{R}^{n} \to [ 0 , \infty ) $ 를 손실 함수라 한다. 다른 이름 손실 함수는 학습을 통해 얻은 데이터의 추정치가 실제 데이터와 얼마나 차이나는지 평가하는 지표로 쓰인다. 이 값이 크면 클수록 많이 틀렸다는 의미고, 이 값이</description>
    </item>
    
    <item>
      <title>인공 신경망이란?</title>
      <link>https://freshrimpsushi.github.io/posts/ann-artificial-neural-network/</link>
      <pubDate>Sat, 06 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/ann-artificial-neural-network/</guid>
      <description>정의 실제 생물의 신경계를 모방한 네트워크를 인공 신경망 이라고 한다. 모티브 신경계는 뉴런들의 결합으로 구성되어있다. 신경세포체는 가지돌기를 통해 자극을 받아들이며, 축삭돌기를 통해 전기자극을 전달한다. 인간을 포함한 많은 생물들은 이렇듯 단순한 뉴런들의 결합을 환경에 적합하도록 진화시켜왔다. 그 결과 신경계는 빛을 감지하거나, 다리를 움</description>
    </item>
    
    <item>
      <title>ROC 곡선의 AUC 를 이용해 모형 비교하는 법</title>
      <link>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/auc-area-under-curve/</guid>
      <description>요약 ROC 곡선은 기본적으로 사각형 $[0,1]^2$ 을 가득 채울수록 좋고, 곡선의 왼쪽 상단의 꺾이는 점이 $(0,1)$ 에 가까울 수록 좋다. 설명 위의 두 ROC 곡선이 있다고 한다면 마음 편하게 &amp;lsquo;좋다&amp;rsquo;라고 할 수 있는 쪽은 오른쪽이다. 이 &amp;lsquo;좋다&amp;rsquo;는 말이 의미하는 것은 ROC 곡선을 그려내는 모형이 더 낫다는 뜻이다. 당연히 비교되는</description>
    </item>
    
    <item>
      <title>ROC 곡선을 이용해 최적의 컷오프 찾는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</link>
      <pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-find-optimal-cutoff-using-roc/</guid>
      <description>개요 ROC 곡선을 그리면 트레이닝 데이터로 얻은 모형이 테스트 데이터를 어느정도로 잘 설명하는지 한 눈에 보여서 유용하다. 하지만 이 곡선은 모든 컷오프에 대한 분류율을 계산하고 이은 것이므로 결국 &amp;lsquo;어떤 컷오프로 0과 1을 분류할 것인가&amp;rsquo;는 알 수 없다. 이것을 알아내기 위해 교차검증의 방법론을 응용해보자. 검증 데이터 트레이</description>
    </item>
    
    <item>
      <title>R 에서 ROC 곡선 그리는 법</title>
      <link>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/how-to-plot-roc-curve/</guid>
      <description>정의 오류행렬의 False Positive Rate와 True Positive Rate를 각각 축으로 두고 그린 그림을 ROC 곡선Receiver Operating Characteristic Curve 이라고 한다. 설명 ROC 곡선은 모델의 퍼포먼스를 한 눈에 보여줄 뿐만 아니라 최적의 컷오프를 찾고 모델 간의 비교에도 쓰이는 등 요긴하게 쓸 데가 많다. 예제를 통해 R 에서 ROC 곡선을 그려보고 그 의미를 이해해보자. 핵심적인 패키지로 ROCR이 쓰인</description>
    </item>
    
    <item>
      <title>교차검증</title>
      <link>https://freshrimpsushi.github.io/posts/cross-validation/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/cross-validation/</guid>
      <description>모델 검증 데이터 분석을 해서 얻은 모델은 그 퍼포먼스가 적절한지 확인하는 과정이 필요하다. 주어진 데이터만 잘 설명하고 실전에서 전혀 힘을 쓰지 못하면 분석을 하는 의미가 없기 때문이다. 이를 위해서 전체 데이터를 모델을 얻는데 사용할 데이터셋과 그 모형의 퍼포먼스를 평가할 데이터셋으로 쪼갠다. 모델을 얻겠다는 것은 주어진 데이터를 이용해 다른 데이터</description>
    </item>
    
    <item>
      <title>오류행렬과 민감도, 특이도</title>
      <link>https://freshrimpsushi.github.io/posts/sensitivity-specipicity-and-confusion-matrix/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/sensitivity-specipicity-and-confusion-matrix/</guid>
      <description>오류행렬 분류 문제에서 모형을 평가하는 지표로써 위와 같은 오류행렬Confusion Matrix을 참고할 수 있다. 정분류율Accuracy $$ \displaystyle \text{Accuracy} = {{TP + TN} \over { P + N }} $$ 위 표에서 P는 양성, N은 음성을 나타낸다. TP는 양성으로 예측되었고 실제로 양성인 경우, TN은 음성으로 예측되었고 실제로 음성인 경우다. 이 TP와 TN이 상대적</description>
    </item>
    
  </channel>
</rss>
