<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>벡터 해석 on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/categories/%EB%B2%A1%ED%84%B0-%ED%95%B4%EC%84%9D/</link>
    <description>Recent content in 벡터 해석 on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Sun, 15 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/categories/%EB%B2%A1%ED%84%B0-%ED%95%B4%EC%84%9D/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>3차원 데카르트 좌표계에서 스칼라 함수의 라플라시안</title>
      <link>https://freshrimpsushi.github.io/laplacian-of-scalar-function-in-cartesian-coordinate-system/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/laplacian-of-scalar-function-in-cartesian-coordinate-system/</guid>
      <description>3변수 스칼라 함수 $f=f(x,y,z)$의 라플라시안을 아래와 같이 $f$의 그래디언트의 다이버전스로 정의하고 $\nabla ^2$로 표기한다. $$ \nabla ^2 f:= \nabla \cdot(\nabla f)= \frac{ \partial^2 f}{ \partial x^2 }+\frac{ \partial^2 f}{ \partial y^2}+\frac{ \partial^2 f}{ \partial z^2} $$ 라플라시안이라는 이름은 프랑스 수학자 라플라스 에서 따온 것이다. $\nabla^{2}$라는 표현은 편의를 위해서 사용하는 것이다. 수학에서는 $</description>
    </item>
    
    <item>
      <title>1r^2의 발산 The divergence of 1</title>
      <link>https://freshrimpsushi.github.io/r2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/r2/</guid>
      <description>$\nabla \cdot \left( \dfrac{1}{r^2}\hat{ \mathbf{r} } \right) = 4\pi \delta^3(\mathbf{r}) $$ \nabla \cdot \left( \dfrac{1}{\eta^2}\hat{ \boldsymbol{\eta} } \right) = 4\pi \delta^3(\boldsymbol{\eta}) $$ \nabla^2 \left(\dfrac{1}{\eta} \right) =-4\pi \delta^3 ( \mathbf{r} ) $벡터함수 $\mathbf{v} = \dfrac{1}{r^2}\hat{\mathbf{r}}$이 있다고 하자.크기는 거리 제곱에 반비례하고 방향은 반지름 방향이다.이제부터 이 함수의 발산을 계산해보자.구좌표계에서의 기울기 공식 을 사용하면$\nabla \cdot \mathbf{v} = \dfrac{1}{r^2}\dfrac{\partial}{\partial r}\left( r^2\dfrac{1}{r^2} \right) = \dfrac{1}{r^2}\dfrac{\partial}{\partial r</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 벡터 함수의 다이버전스발산</title>
      <link>https://freshrimpsushi.github.io/divergence-of-fector-function-in-cartesian-cooridenates-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/divergence-of-fector-function-in-cartesian-cooridenates-system/</guid>
      <description>벡터 함수 $\mathbf{F}(x,y,z)=F_{x}\hat{\mathbf{x}}+F_{y}\hat{\mathbf{y}} + F_{z}\hat{\mathbf{z}}$의 **다이버전스** 를 아래와 같이 정의하고 $\nabla \cdot \mathbf{F}$라고 표기한다. $$ \nabla \cdot \mathbf{F} := \frac{ \partial F_{x}}{ \partial x} + \frac{ \partial F_{y}}{ \partial y }+ \frac{ \partial F_{z}}{ \partial z} $$ 기하학적으로 $\nabla \cdot \mathbf{F}&amp;gt;0$이면 $\mathbf{F}$가 퍼져나가는, 밖으로 나가는 모양을 하고 있음을</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 벡터 함수의 컬</title>
      <link>https://freshrimpsushi.github.io/curl-of-vector-function-in-cartesian-coordinate-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/curl-of-vector-function-in-cartesian-coordinate-system/</guid>
      <description>한 줄 요약 : $\nabla \times \mathbf{F}$를 축으로 두고 오른손 법칙을 적용하면 실제 $\mathbf{F}$가 회전하는 방향과 같다.3차원 벡터 $\mathbf{F}=(F_{x},F_{y},F_{z})$에 대해서 아래의 연산을 $\mathbf{F}$의 **컬 혹은 회전** 이라고 한다. $$ \begin{align*} \nabla \times \mathbf{F} &amp;amp;=\begin{vmatrix} \hat{\mathbf{x}} &amp;amp; \hat{\mathbf{y}} &amp;amp; \hat{\mathbf{z}} \\ \frac{ \partial }{ \partial</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 스칼라 함수의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/gradient-of-scalar-function-in-cartesian-coordinate-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/gradient-of-scalar-function-in-cartesian-coordinate-system/</guid>
      <description>3변수 스칼라 함수 $f=f(x,y,z)$의 그래프의 각 점에서 기울기와 증가하는 방향을 나타내는 벡터를 $\nabla f$라고 표기하며 그래디언트 라고 부른다. $$ \mathrm{grad}f=\nabla f = \frac{ \partial f}{ \partial x }\hat{\mathbf{x}}+\frac{ \partial f}{ \partial y}\hat{\mathbf{y}}+\frac{ \partial f}{ \partial z}\hat{\mathbf{z}} $$ ※ 그래디언트는 방향도함수, 기울기, 구배 등으로 번역된다. 구배는 기울기의 한자어이기 때문에 기울기와 같은 말이며 최근에는 잘 쓰이지 않는다. 기</description>
    </item>
    
    <item>
      <title>3차원 스칼라 함수의 기울기</title>
      <link>https://freshrimpsushi.github.io/the-gradient-of-3-dimention-scalar-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/the-gradient-of-3-dimention-scalar-function/</guid>
      <description>3변수 함수 $T(x,y,z)$의 기울기를 $\nabla T$라 하고 다음과 같이 정의한다.$\nabla T \equiv \dfrac{\partial T}{\partial x}\hat x + \dfrac{\partial T}{\partial y}\hat y + \dfrac{\partial T}{\partial z}\hat z$1.먼저 1변수 함수를 예로 들어보자.함수 $f(x)$가 있다고 하자.$f$의 미소 변화량을 $df$, $x$의 미소변화량을 $dx$라고 하자.그럼 $x$가 미소량 만큼 바뀔 때 마다 $f$에도 변화가 생길 것이</description>
    </item>
    
    <item>
      <title>구좌표계에서의 미소부피</title>
      <link>https://freshrimpsushi.github.io/1753/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/1753/</guid>
      <description>극 좌표계에서 미소 면적, 원통 좌표계에서 미소 부피구좌표계에서 미소 부피는 아래와 같다. $$ dV=r^{2}\sin\theta dr d\theta d\phi $$ 구 표면 위의 미소 면적은 $dr$을 곱하지 않음으로써 얻을 수 있다. $$ da=\color{blue}{rd\theta} \cdot \color{red}{r\sin\theta d \phi}=r^{2}\sin\theta d\theta d\phi $$ 1. 그림을 통한 이해(아래 그림을 매트랩에서 그리는 코드) 구좌표계에서 미소부피는 위 그림에서 보이는 바와 같이 (초록선의 길이)$\times$(파란</description>
    </item>
    
    <item>
      <title>극 좌표계에서 미소 면적 원통 좌표계에서 미소 부피</title>
      <link>https://freshrimpsushi.github.io/1755/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/1755/</guid>
      <description>구 좌표계에서 미소 부피극 좌표계에서 미소 면적은 다음과 같다. $$ dA=rdrd\theta $$ 원통 좌표계에서 미소 부피와 원통 표면의 미소 면적은 다음과 같다. $$ dV=\rho d\rho d\phi dz \\ dA=\rho d\phi dz $$ 매트랩에서 극 좌표계 그림 그리는 코드, 원통좌표계 그림 그리는 코드극 좌표계 $\mathbf{r}=\mathbf{r}(r,\theta)$ 미소 면적은 그림에서와 같이 (초록선의 길이)$\times$(파란선의 길이)이다. 초록색 선은 지름 방향</description>
    </item>
    
    <item>
      <title>기울기의 기본 정리</title>
      <link>https://freshrimpsushi.github.io/fundamental-theorem-for-gradient/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/fundamental-theorem-for-gradient/</guid>
      <description>기울기의 기본 정리 임의의 경로를 따라 점 $a$에서 점 $b$로 갈 때 $T$의 총 변화량은 아래와 같다.$T(b)-T(a) = \displaystyle \int _a^b (\nabla T) \cdot d\mathbf{l}$ $\cdots (1)$이에 관련된 개념들을 수학적으로 엄밀하게 정의하고 해당 내용을 증명하는 것은 물리학을 공부하는 이에게 중요한 내용이 아니므로 간단하게 서술하겠다.기울기의 기본 정리가 어떤 내용인지? 어떤 의</description>
    </item>
    
    <item>
      <title>기울기의 회전이 항상 0임을 증명</title>
      <link>https://freshrimpsushi.github.io/proof-of-that-the-curl-of-a-gradient-is-always-0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/proof-of-that-the-curl-of-a-gradient-is-always-0/</guid>
      <description>기울기의 회전은 항상 $0$이다 $$ \nabla \times (\nabla T)=0 $$ 증명 직교 좌표계에서 $T$의 기울기는 $$ \displaystyle \nabla T= \frac{\partial T}{\partial x}\hat{\mathbf{ x}} +\frac{\partial T}{\partial y}\hat{\mathbf{y}} +\frac{\partial T}{\partial z}\hat{\mathbf{z}} $$ 위의 식에 회전 연산자를 취하면 $$ \begin{eqnarray*} \nabla \times (\nabla T) &amp;amp;=&amp;amp; \begin{vmatrix} \displaystyle \hat{\mathbf{x}} &amp;amp;\hat{\mathbf{y}} &amp;amp; \hat{\mathbf{z}} \\ \displaystyle \frac{\partial }{\partial x} &amp;amp; \displaystyle \frac{\partial }{\partial y} &amp;amp; \displaystyle \frac{\partial }{\partial z} \\ \displaystyle \frac{\partial T}{\partial x} &amp;amp; \displaystyle \frac{\partial T}{\partial y} &amp;amp; \displaystyle\frac{\partial T}{\partial z} \end{vmatrix} \\ &amp;amp;=&amp;amp; \left( \frac{\partial^2 T}{\partial y \partial z}-\frac{\partial^2 T}{\partial z \partial y} \right) \hat {\mathbf{x}} + \left( \frac{\partial ^2 T}{\partial x \partial z}-\frac{\partial ^2 T}{\partial z \partial x} \right) \hat {\mathbf{y}} + \left( \frac{\partial^2 T}{\partial x \partial y} -\frac{\partial^2 T}{\partial y \partial</description>
    </item>
    
    <item>
      <title>델 연산자가 두 번 들어간 수식 2계 도함수</title>
      <link>https://freshrimpsushi.github.io/second-derivative-with-del-operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/second-derivative-with-del-operator/</guid>
      <description>$T$는 스칼라 함수, $\mathbf{A}$는 벡터 함수라고하자.$(1)$ 기울기의 발산 $\nabla \cdot (\nabla T) =\nabla ^2 T $$ (2)$ 기울기의 회전 $\nabla \times (\nabla T)=0 $$ (3)$ 발산의 기울기 $\nabla (\nabla \cdot \mathbf{A} ) $$ (4)$ 회전의 발산 $\nabla \cdot (\nabla \times \mathbf{A})=0 $$ (5)$ 회전의 회전 $\nabla \times (\nabla \times \mathbf{A})=\nabla ( \nabla \cdot \mathbf{A}) - \nabla ^2 \mathbf{A}$기울기와 회전의 결과가 벡터이고 발산의 결과가 스칼라이므로 2계 도함수는 총</description>
    </item>
    
    <item>
      <title>델 연산자가 포함된 곱셈 규칙</title>
      <link>https://freshrimpsushi.github.io/product-rule-with-del-operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/product-rule-with-del-operator/</guid>
      <description>이전에 나뉘어 있던 두 문서의 내용을 합쳤습니다. 다른 문서에 있는 덧글도 모두 본 글로 옮겼습니다. 공식 델 연산자가 포함된 곱셈규칙 그래디언트(gradient, 기울기) (a) $\nabla{(fg)}=f\nabla{g}+g\nabla{f}$(b) $\nabla(\mathbf{A} \cdot \mathbf{B}) = \mathbf{A} \times (\nabla \times \mathbf{B}) + \mathbf{B} \times (\nabla \times \mathbf{A})+(\mathbf{A} \cdot \nabla)\mathbf{B}+(\mathbf{B} \cdot \nabla) \mathbf{A}$다이버전스(divergence, 발산) (c) $\nabla \cdot (f\mathbf{A}) = f(\nabla \cdot \mathbf{A}) + \mathbf{A} \cdot (\nabla f)$(d) $\nabla \cdot (\mathbf{A} \times \mathbf{B}) = \mathbf{B} \cdot (\nabla \times</description>
    </item>
    
    <item>
      <title>델 연산자가 포함된 식의 부분적분</title>
      <link>https://freshrimpsushi.github.io/integral-by-part-with-del-operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/integral-by-part-with-del-operator/</guid>
      <description>부분적분의 원리를 그대로 사용해서 델 연산자가 포함된 식의 모습을 유용하게 바꿀 수 있다.부분적분 $\dfrac{d}{dx}\left( fg \right) = f\dfrac{dg}{dx}+g\dfrac{df}{dx}$양 변을 정적분하면$\displaystyle \int_a^b \dfrac{d}{dx} \left(fg\right) = (fg)\Big|a^b=\int_a^b f\left(\dfrac{dg}{dx}\right)dx+\int_a^bg\left(\dfrac{df}{dx}\right)dx $$ \displaystyle \Rightarrow \int_a^b f\left(\dfrac{dg}{dx}\right)dx = (fg)\Big|a^b-\int_a^bg\left(\dfrac{df}</description>
    </item>
    
    <item>
      <title>두 벡터의 외적의 크기는 두 벡터가 만드는 평행사변형의 넓이와 같다</title>
      <link>https://freshrimpsushi.github.io/1681/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/1681/</guid>
      <description>두 벡터 $\mathbf{A}$, $\mathbf{B}$ 사이의 각도가 $\theta$일 때 두 벡터의 외적의 크기는 다음과 같다. $$ \left| \mathbf{A}\times \mathbf{B}\right| =\left|\mathbf{A}\right|\left| \mathbf{B} \right|\sin \theta $$ 그리고 이는 두 벡터가 만드는 평행사변형의 넓이와 같다.**** **증명** 두 벡터 $\mathbf{A}=(A_{x},A_{y},A_{z})$, $\mathbf{B}=(B_{x},B_{y},B_{z})$가 위 그림과 같다고 하자. 그러면**Part 1. 평행사변형의 넓이** 평행사</description>
    </item>
    
    <item>
      <title>물리학에서 구배 물매란</title>
      <link>https://freshrimpsushi.github.io/292/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/292/</guid>
      <description>물리학 교재에서 구배, 물매라는 단어를 본 적이 있을 것이다. 바로 그래디언트$\mathrm {Gradient}$이다.구배, 물매는 $\mathrm {Gradient}$의 옛날식 번역이다. 요즘은 gradient는 기울기로 번역한다. 혹은 경사라고도 하지만 대부분 기울기라고 쓰는 것 같다.그러니 $f$의 구배를 구하라는 문제를 봤다면 당황하</description>
    </item>
    
    <item>
      <title>물리학에서 델 연산자란</title>
      <link>https://freshrimpsushi.github.io/del-operator-in-physics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/del-operator-in-physics/</guid>
      <description>델 연산자란 간단히 말해서 3차원 공간 좌표에 대한 미분 연산자이다. 연산자라는 말이 생소하다면 그냥 대상을 계산하는 규칙이라고 이해하면 된다. 예를 들어 $\dfrac{d}{dx}$는 함수를 $x$에 대해서 미분하라는 미분 연산자이다. 델 연산자는 보통 아래와 같이 소개된다. $$ \nabla = \frac{ d }{ d x }\hat{\mathbf{x}}+\frac{ d }{ d y }\hat{\mathbf{y}}+\frac{ d }{ d z }\hat{\mathbf{z}} $$ 마치 벡터인 것처럼</description>
    </item>
    
    <item>
      <title>물리학을 위한 스토크스 정리</title>
      <link>https://freshrimpsushi.github.io/stokes-theorem-for-physics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/stokes-theorem-for-physics/</guid>
      <description>스토크스 정리(회전의 기본 정리) $$ \int_{\mathcal{S}} (\nabla \times \mathbf{v} )\cdot d\mathbf{a} = \oint_{\mathcal{P}}v\cdot d\mathbf{l} $$ 어떤 영역 안에서의 벡터 $\mathbf{v}$가 회전하는 양(좌변)은 그 영역의 테두리에서 벡터 $\mathbf{v}$의 값(우변)과 같다.사실 물리학을 공부하는 사람이라면 위 수식의 증명이 크게 중요한 것은 아니다. 그보다 더 중요한 것은 수식이 어떤 의미를 가지고 있느냐를 아</description>
    </item>
    
    <item>
      <title>발산 정리 증명</title>
      <link>https://freshrimpsushi.github.io/proof-of-divergence-theorem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/proof-of-divergence-theorem/</guid>
      <description>발산 정리divergence\ theorem})$, 가우스 정리**Gauss\ theorem $$ \displaystyle \int_\mathcal{V} \nabla \cdot \mathbf{ F} dV = \oint _\mathcal{S} \mathbf{F} \cdot d \mathbf{S} $$ 발산 정리는** 가우스 정리** 혹은 **그린 정리**Green&amp;rsquo;s\ theorem 라고도 부르며 물리에서는 주로 전자기학에서 많이 사용된다. 간단한 모양이면서도 정말 중요한 정리이다. 수학적인 의미는 수식 그대로 부피적분을 면적분</description>
    </item>
    
    <item>
      <title>백캡BAC-CAB공식을 이용한 간단한 수식 증명</title>
      <link>https://freshrimpsushi.github.io/146/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/146/</guid>
      <description>BAC-CAB(백캡) 공식 $ \vec{A} \times (\vec{B} \times \vec{C} )= \vec{B}(\vec{A} \cdot \vec{C} )-\vec{C}(\vec{A} \cdot \vec{B}) $백캡 공식을 이용하여 아래의 수식을 증명해보자.(그리피스 전자기학 문제 1.6)정말 간단하다.$[\vec{A} \times (\vec{B} \times \vec{C})] +[\vec{B} \times (\vec{C} \times \vec{A})] +[\vec{C} \times (\vec{A} \times \vec{B})] = 0$증명 BAC-CAB 공식에 의해$ \vec{A} \times (\vec{B} \times \vec{C})=\vec{B}(\vec{A} \cdot \vec{C}) -\vec{C} (\vec{A} \cdot \vec{B}) $$ \vec{B} \times (\vec{C} \times \vec{B})=\vec{C}(\vec{B} \cdot \vec{A}) -\vec{A} (\vec{B} \cdot \vec{C}) $$ \vec{C} \times (\vec{A} \times \vec{B})=\vec{A}(\vec{C} \cdot \vec{B}) -\vec{B} (\vec{C} \cdot \vec{A})$다 더</description>
    </item>
    
    <item>
      <title>벡터 삼중곱백캡 공식 증명</title>
      <link>https://freshrimpsushi.github.io/proof-of-vector-triple-productbac-cab-rule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/proof-of-vector-triple-productbac-cab-rule/</guid>
      <description>In English**BAC-CAB(백캡) 공식** $$ \mathbf{A} \times (\mathbf{B} \times \mathbf{C} )= \mathbf{B}(\mathbf{A} \cdot \mathbf{C} )-\mathbf{C}(\mathbf{A} \cdot \mathbf{B}) $$ **벡터 삼중곱**vector\ triple\ product 의 결과를 간단하게 BAC-CAB(백캡)이라고 외운다.벡터 삼중곱은 벡터를 3번 곱하는 연산 중에서 그 결과가 벡터인 것이다. 결과가 스칼라인 것은 스칼라 삼중곱이라 부른다. 결과가 벡터로 나오기 위해서 식에는 외</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 다이버전스</title>
      <link>https://freshrimpsushi.github.io/divergence-in-vector-field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/divergence-in-vector-field/</guid>
      <description>다이버전스의 정의 유클리드 공간에서 정의된 벡터 필드 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 을 $\textbf{f} = (f_{1} , \cdots , f_{n})$ 과 같이 나타내고 축의 방향을 $u_{1} , \cdots , u_{n}$ 이라고 할 때, $\textbf{f}$ 의 **다이버전스** 를 다음과 같이 정의한다. $$ \text{div} \textbf{f} := \nabla \cdot \textbf{f} = \sum_{k=1}^{n} {{ \partial f_{k} } \over { \partial u_{k} }} $$ 벡터 필드의 다이버전스는 다음과 다음과 같이 한 점 $\textbf{v} \in \mathbb{R}^{n}$ 가 주어져 있을 때 그 점에서 벡터들이 모이는지, 퍼지는지에 대</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 볼륨</title>
      <link>https://freshrimpsushi.github.io/volume-in-vector-field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/volume-in-vector-field/</guid>
      <description>볼륨의 정의 유클리드 공간의 부분공간 $D \subset \mathbb{R}^{n} $ 의 볼륨 $V$ 는 직교좌표 $\textbf{u} = (u_{1}, u_{2}, \cdots , u_{n})$ 으로 나타낼 때 다음과 같이 정의된다. $$ V(D) = \int_{D} du_{1} du_{2} \cdots d u_{n} $$ $\textbf{u} \in \mathbb{R}^{n}$ 가 벡터 함수 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 의해 $\textbf{f} \left( \textbf{u} \right) = \left( f_{1} (\textbf{u}) , \cdots , f_{n} (\textbf{u}) \right) $ 와 같이 변환될 때, $D$ 의 **볼륨** 은 다음과 같다.$$ V(D) = \int_{D} \left| {{ \partial \textbf{f} (\textbf{u}) } \over { \partial \textbf{u} }} \right| d u_{1} d u_{2} \cdots d u_{n} $$ * $\displaystyle \left| {{ \partial \textbf{f} (\textbf{u}) } \over</description>
    </item>
    
    <item>
      <title>벡터의 회전의 회전</title>
      <link>https://freshrimpsushi.github.io/the-curl-of-curl-of-vector-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/the-curl-of-curl-of-vector-function/</guid>
      <description>$\nabla \times (\nabla \times \mathbf{A}) = \nabla (\nabla \cdot \mathbf{A}) - \nabla^2 \mathbf{A}$증명에는 레비-치비타 심볼 *Levi-Civita\ symbol})$이 사용된다.증명 $$ \begin{eqnarray} \nabla \times ( \nabla \times \mathbf{A}) &amp;amp;=&amp;amp; \epsilon_{ijk} e_i \nabla_j (\nabla \times \mathbf{A})_k \\ &amp;amp;=&amp;amp; \epsilon_{ijk} \hat e_i \nabla_j (\epsilon_{klm} \nabla_l A_m) \\ &amp;amp;=&amp;amp; \color{blue}{\epsilon_{ijk}\epsilon_{klm}}\hat e_i \nabla_j \nabla_l A_m \\ &amp;amp;=&amp;amp; \color{blue}{(\delta_{il}\delta_{jm} - \delta_{im} \delta_{jl}) }\hat e_i \nabla _j \nabla _l A_m \\ &amp;amp;=&amp;amp; \hat e_i\nabla_i \nabla_j A_j - \nabla_j \nabla_j \hat e_i A_i \\ &amp;amp;=&amp;amp; \nabla(\nabla \cdot \mathbf{A}) - \nabla \cdot \nabla \mathbf{A} \end{eqnarray*} $$ 파란 부분의 증명은 여기 참고 첫번째 항인 $\nabla(\nabla \cdot \mathbf{A}</description>
    </item>
    
    <item>
      <title>분리벡터</title>
      <link>https://freshrimpsushi.github.io/separation-vector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/separation-vector/</guid>
      <description>원천점에서 관찰점까지의 벡터를 분리 벡터라 한다. $$ \boldsymbol{\eta} = \mathbf{r} - \mathbf{r}&#39; $$ **** 분리벡터separation\ vector})$ ** $\boldsymbol{\eta}$ : 위치벡터와 근원벡터(원천벡터)의 차.근원벡터source\ vector $\mathbf{r}&#39;$ : 전하나 전류가 있는 곳. 즉, 전자기장을 만드는 근원지.위치벡터position\ vector $\mathbf{r}$ : 전기장 $\mathbf{E}$나 자기장 $\mathbf{B}$ 등을 측정하는 지점.</description>
    </item>
    
    <item>
      <title>분리벡터 1r^2의 회전 Curl of separation vector 1</title>
      <link>https://freshrimpsushi.github.io/r2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/r2/</guid>
      <description>$\nabla \times \dfrac{\hat{\boldsymbol{\eta}} }{\eta ^2} =0$이 식이 특별한 의미를 가지는 것은 아니다.자기장의 발산을 구하는 과정에서 나오는데 계산이 간단하지 않아 따로 설명한다.$\boldsymbol{\eta}=(x-x&#39;)\mathbf{x} + (y-y&#39;)\mathbf{y} + (z-z&#39;)\mathbf{z}$는 분리벡터 $$ | \boldsymbol{\eta} |=\eta=\sqrt{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2} $$ $$ \hat{ \boldsymbol{\eta}}=\dfrac{ \boldsymbol{\eta} } { \eta}=\dfrac{(x-x&#39;)\mathbf{x} + (y-y&#39;)\mathbf{y} + (z-z&#39;)\mathbf{z}}{\sqrt{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2}} $$ $$ \dfrac{\hat{\boldsymbol{\eta}}}{\eta^2}=\dfrac{1}{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2}\dfrac{(x-x&#39;)\mathbf{x} + (y-y&#39;)\mathbf{y} + (z-z&#39;)\mathbf{z}}{\sqrt{(x-x&#39;)^2+(y-y&#39;)^2 +</description>
    </item>
    
    <item>
      <title>분리벡터의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/gradient-of-separation-vector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/gradient-of-separation-vector/</guid>
      <description>분리 벡터 $\boldsymbol{\eta}$의 크기의 $n-$제곱인 $\eta ^{n}$의 그래디언트는 다음과 같다. $$ \nabla (\eta^n)=n\eta^{n-1}\hat{\boldsymbol{\eta}} $$ 분리 벡터는 $\boldsymbol{\eta}=\mathbf{r}-\mathbf{r&#39;}$이므로 $(x,y,z)$와 $(x&#39;,y&#39;,z&#39;)$를 변수로 가진다. 따라서 미분할 때 이에 주의해야</description>
    </item>
    
    <item>
      <title>삼차원 유클리드 공간에서 외적이란</title>
      <link>https://freshrimpsushi.github.io/outer-product-in-three-dimension/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/outer-product-in-three-dimension/</guid>
      <description>$\mathbb{x}, \mathbb{y} \in \mathbb{R}^3$ 에 대해 다음을 $\mathbb{x}$와 $\mathbb{y} $의 외적 으로 정의한다. $$ \begin{eqnarray*} \mathbb{x} \times \mathbb{y} &amp;amp;=&amp;amp; (x_{2}y_{3} - x_{3}y_{2}, x_{3}y_{1} - x_{1}y_{3}, x_{1}y_{2} - x_{2}y_{1}) \\ &amp;amp;=&amp;amp; \det \begin{bmatrix} \mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} \\ x_{1} &amp;amp; x_{2} &amp;amp; x_{3} \\ y_{1} &amp;amp; y_{2} &amp;amp; y_{3} \end{bmatrix} \\ &amp;amp;=&amp;amp; \begin{bmatrix} 0 &amp;amp; -x_{3} &amp;amp; x_{2} \\ x_{3} &amp;amp; 0 &amp;amp; -x_{1} \\ -x_{2} &amp;amp; x_{1} &amp;amp; 0 \end{bmatrix} \begin{bmatrix} y_{1} \\ y_{2} \\ y_{3} \end{bmatrix} \end{eqnarray*} $$ 참고로 $\mathbf{i} = (1,0,0)$ , $ \mathbf{j} = (0,1,0)$ , $ \mathbf{k} = (0,0,1)$ 이다.내적과 마찬가지로 외적 역시 더욱 일반적인 정의는 가능하지만 실용적</description>
    </item>
    
    <item>
      <title>스칼라 삼중곱의 특징</title>
      <link>https://freshrimpsushi.github.io/properties-of-scalar-triple-product/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/properties-of-scalar-triple-product/</guid>
      <description>스칼라 삼중곱은 벡터 3개를 곱하는 연산 중에서 결과가 스칼라인 것을 말한다. 결과가 벡터인 것은 벡터 삼중곱이라 한다. 결과가 스칼라로 나오기 위해서는 우선 두 벡터를 외적해서 나온 벡터와 다른 벡터를 내적해야한다. 즉, 수식은 아래와 같은 모양이다. $$ \mathbf{A}\cdot (\mathbf{B} \times \mathbf{C} ) $$ 스칼라 삼중곱의 특징을 하나씩 살펴보자.1. 스칼라 삼중곱의 크기는 세 벡터가 만드</description>
    </item>
    
    <item>
      <title>스칼라 필드의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/gradient-in-scalar-field/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/gradient-in-scalar-field/</guid>
      <description>벡터장의 미분계수 :야코비 행렬스칼라 필드 $f : \mathbb{R}^{n} \to \mathbb{R}$ 에 대해 한 점 $\mathbb{x}{0} \in \mathbb{R}^{n}$ 에서 함수의 증가율이 가장 큰 방향을 나타낸 벡터를 $\mathbb{x}{0}$ 에서 $f$ 의 그래디언트 라고 한다.스칼라장의 예시로써 위의 그림을 생각해보자. 위 그림은 $z(x,y) = x^2 - y^2$ 와 같이 정의된 함수 $z : \mathbb{R}^{2} \to \mathbb{R}$ 을 시각적으로 나타낸 것이다. $y= f(x)$ 와 같은 곡선에서는 변화율을 구할만할 방향이 $x$ 축 뿐이었기</description>
    </item>
    
    <item>
      <title>스칼라 함수와 벡터 함수</title>
      <link>https://freshrimpsushi.github.io/scalar-function-and-vector-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/scalar-function-and-vector-function/</guid>
      <description>$D \subset \mathbb{R}^{n}$ 이라고 하자.1. $D$ 를 정의역으로 갖는 함수를 다변수 함수 라고 한다.2. $f : D \to \mathbb{R}$ 을 스칼라 함수 라고 한다.3. 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 $\mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix}$ 과 같이 정의된 $\mathbb{f} : D \to \mathbb{R}^{m}$ 를 **벡터 함수** 라고 한다.**1.** 다변수 함수라는 표현은 특히 미적분학을 위</description>
    </item>
    
    <item>
      <title>야코비 행렬 혹은 자코비 행렬이란</title>
      <link>https://freshrimpsushi.github.io/jacobian-matrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/jacobian-matrix/</guid>
      <description>스칼라장의 미분계수 : 델 연산자$D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 벡터 함수 $\mathbb{f} : D \to \mathbb{R}^{m}$ 가 각각의 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ 과 같이 정의되었다고 하자. $$ J := \begin{bmatrix} {{\partial f_{1} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{1} } \over {\partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial f_{m} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{m} } \over {\partial x_{n} }} \end{bmatrix} $$ 을 $\mathbb{f}$</description>
    </item>
    
    <item>
      <title>원통 좌표계의 변수로 r theta를 쓰면 안되는 이유</title>
      <link>https://freshrimpsushi.github.io/1795/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/1795/</guid>
      <description>원통 좌표계는 아래와 같이 3차원 공간의 점을 $(\rho,\phi,z)$로 표현하는 좌표계를 말한다.그런데 원통 좌표계를 $(r,\theta, z)$와 같이 표기한 것을 볼 수 있다. 극좌표계 $(r,\theta)$에서 높이 $z$가 추가되었으니 아무 생각 없이 $(r,\theta, z)$와 같이 표기한 것으로 보이는데 이는 각 기호의 의미를 생각해봤을 때 명백하게 잘못 되었다</description>
    </item>
    
    <item>
      <title>유사벡터란</title>
      <link>https://freshrimpsushi.github.io/pseudovector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/pseudovector/</guid>
      <description>물리학 공부를 하다 보면 유사벡터 혹은 수도벡터라는 말을 접할 수 있다. 중요한 점은 유사벡터를 접하기만 할 뿐 어떤 녀석인지 알기는 힘들다는 거다. 유사벡터가 뭔지 몰라도 학부 물리학을 공부하는데 아무 지장은 없다지만 제대로 설명해놓은 교재를 본 적이 없다. 나는 유사벡터의 특징을 배울 수 있도록 한 그리피스 전자기학의 연습문제에서 준벡터(Pseud</description>
    </item>
    
    <item>
      <title>유클리드 공간에서 내적이란</title>
      <link>https://freshrimpsushi.github.io/inner-product-in-euclidean-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/inner-product-in-euclidean-space/</guid>
      <description>벡터공간 $V = \mathbb{R}^n$ 에 대해 $\mathbb{x}, \mathbb{y}, \mathbb{z} \in V$ 그리고 $k \in \mathbb{R}$ 이라고 하자. $\left&amp;lt; , , \right&amp;gt; : V^2 \to \mathbb{R} $ 가 아래 네 조건들을 만족시킬 때 $\left&amp;lt; , , \right&amp;gt;$ 를 $V$ 상에서의 내적 으로 정의한다.(1) 대칭성 : $\left&amp;lt; \mathbb{x} , \mathbb{y} \right&amp;gt; = \left&amp;lt; \mathbb{y}, \mathbb{x} \right&amp;gt;$(2) 가산성 : $\left&amp;lt; \mathbb{x} + \mathbb{y} , \mathbb{z} \right&amp;gt; = \left&amp;lt; \mathbb{x}, \mathbb{z} \right&amp;gt; + \left&amp;lt; \mathbb{y}, \mathbb{z} \right&amp;gt;$(3) 동질성 : $ \left&amp;lt; k \mathbb{x} , \mathbb{y} \right&amp;gt; = k \left&amp;lt; \mathbb{x}, \mathbb{y} \right&amp;gt;$(4) 정부호 : $\left&amp;lt; \mathbb{x} , \mathbb{x} \right&amp;gt; \ge 0$ 그리고 $\left&amp;lt; \mathbb{x} , \mathbb{x} \right&amp;gt; =0 \iff \mathb</description>
    </item>
    
    <item>
      <title>유클리드 공간이란</title>
      <link>https://freshrimpsushi.github.io/what-is-an-euclidean-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/what-is-an-euclidean-space/</guid>
      <description>정의 유클리드 공간 $$ \mathbb{R}^{n} = \mathbb{R} \times \cdots \times \mathbb{R} $$ 자연수 $n \in \mathbb{N}$ 에 대해 실수 집합 $\mathbb{R}$ 의 데카르트 곱 $\mathbb{R}^{n}$ 을 유클리드 공간 이라고 한다. 1. $\mathbb{R}^{1}$ 을 실수 공간 혹은 수직선 이라고 한다. 2. $\mathbb{R}^{2}$ 을 평면 이라고 한다. 3. $\mathbb{R}^{3}$ 을 $3$차원 공간 이라고 한다. $\mathbb{N} := \left\{ 1, 2, 3, \cdots \right\}$ 은 자연수를 모두 모아놓은 집합을 의미한다. $\mathbb{R}$ 은 실수를 모두 모아놓은 집합을 의미한다. 유클리드 공간은 기</description>
    </item>
    
    <item>
      <title>전미분</title>
      <link>https://freshrimpsushi.github.io/total-derivative/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/total-derivative/</guid>
      <description>3차원 공간에서 정의된 함수 $f=f(x,y,z)$가 주어졌다고 하자. 각 변수 $x$, $y$, $z$의 변화에 따른 $f$의 함숫값의 변화를 전미분 이라 하고 $df$로 표기한다. 그러면 아래의 식이 성립한다. $$ df=\frac{ \partial f}{ \partial x }dx + \frac{ \partial f}{ \partial y}dy+\frac{ \partial f}{ \partial z}dz $$ 2변수 함수$z=f(x,y)$에 대해서 나타내면 $$ dz=\frac{ \partial f}{ \partial x}dx+\frac{ \partial f}{ \partial y}dy $$ 와 같고 변수가 $n$개</description>
    </item>
    
    <item>
      <title>직교 원통 구면 좌표계에 대한 기울기 발산 회전 라플라스 연산</title>
      <link>https://freshrimpsushi.github.io/294/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/294/</guid>
      <description>직교좌표계, 원통좌표계, 구면좌표계에서의 기울기$\mathrm{Gradient}$, 발산$\mathrm{Divergence}$, 회전$\mathrm{Curl}$, 라플라스 연산$\mathrm{Laplasian}$을 정리했다. 이렇게 정리한 이유는 보고 달달달 외우라는게 아니다. 절대 외울 필요 없다. 외</description>
    </item>
    
    <item>
      <title>직교좌표계 단위벡터를 구면좌표계의 단위벡터로 나타내기</title>
      <link>https://freshrimpsushi.github.io/291/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/291/</guid>
      <description>직교좌표계의 단위벡터를 구면좌표계의 단위벡터로 나타낸 식은 아래와 같다. $$ \begin{eqnarray*} \hat{ \mathbf{x} }&amp;amp;=&amp;amp; \cos \phi \sin \theta \hat{ \mathbf{r} } + \cos \phi \cos \theta \hat{ \boldsymbol{\theta} } - \sin\phi\hat{ \boldsymbol{\phi} } \\ \hat{ \mathbf{y} } &amp;amp;=&amp;amp; \sin\phi\sin\theta \hat{ \mathbf{r} } + \sin\phi\cos\theta\hat{ \boldsymbol{\theta} } + \cos\phi\hat{ \boldsymbol{\phi} } \\ \hat{ \mathbf{z} } &amp;amp;=&amp;amp; \cos\theta\hat{ \mathbf{r} } - \sin\theta\hat{ \boldsymbol{\theta} } \end{eqnarray*} $$ 구면좌표계의 단위벡터를 직교좌표계의 단위벡터로 나타내면 아래와 같다. (구면좌표계와 직교좌표계의 관계) $$ \begin{eqnarray*} \hat{ \mathbf{r} } &amp;amp;=&amp;amp; \cos\phi \sin\theta \hat{ \mathbf{x} } + \sin\phi \sin\theta\hat{</description>
    </item>
    
    <item>
      <title>직교좌표계에서의 벡터 미분</title>
      <link>https://freshrimpsushi.github.io/derivative-of-a-vector-in-cartesian-coordinate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/derivative-of-a-vector-in-cartesian-coordinate/</guid>
      <description>3차원 직교좌표계에서 두 벡터 $\mathbf{A}$, $\mathbf{B}$에 대한 미분은 다음과 같다.$\mathbf{A},\ \mathbf{B}$를 각각$\mathbf{A}(u)=A_x(u)\hat x + A_y(u)\hat y + A_z(u)\hat z$,$\mathbf{B}(u)=B_x(u)\hat x + B_y(u)\hat y + B_z(u)\hat z$라고 하면$1 \ \ \dfrac{ d \left( n \mathbf{A} \right) }{du} = \dfrac{ dn }{du} \mathbf{A} + n\dfrac{ d\mathbf{A}}{du} $$ 2 \ \ \dfrac{ d ( \mathbf{A} \cdot \mathbf{B} )} {du} = \dfrac{ \mathbf{A} }{du} \cdot \mathbf{B} + \mathbf{A} \cdot \dfrac{</description>
    </item>
    
    <item>
      <title>직교좌표계의 단위벡터로 표현한 구면좌표계의 단위벡터</title>
      <link>https://freshrimpsushi.github.io/152/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/152/</guid>
      <description>구면좌표계의 단위벡터를 직교좌표계의 단위벡터로 표현하면 아래와 같다. $$ \begin{align*} \hat{\mathbf{r}} &amp;amp;= \cos\phi \sin\theta\hat{\mathbf{x}} + \sin\phi \sin\theta\hat{\mathbf{y}} + \cos\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\theta}} &amp;amp;= \cos\phi \cos\theta \hat{\mathbf{x}} + \sin\phi \cos\theta \hat{\mathbf{y}} - \sin\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\phi}} &amp;amp;= -\sin\phi \hat{\mathbf{x}} + \cos\phi \hat{\mathbf{y}} \end{align*} $$ $\hat{\mathbf{r}}$을 먼저 구한 뒤 이를 이용해서 나머지 둘을 구한다.**증명** $$ \hat{\mathbf{r}}=r\hat{\mathbf{r}}=x\hat{\mathbf{x}}+y\hat{\mathbf{y}}+z\hat{\mathbf{z}} $$ 이므로 양변을 $r$로 나누면 $$ \begin{eqnarray*} \hat{\mathbf{r}}&amp;amp;=&amp;amp;\frac{x}{r}\hat{\mathbf{x}}+\frac{y}{r}\hat{\mathbf{y}}+\frac{z}{r}\hat{\mathbf{z}} \\ &amp;amp;=&amp;amp; \frac{x}{r \sin\theta}\sin\theta\hat{\mathbf{x}}+\frac{y}{r \sin\theta}\sin\theta\hat{\mathbf{y}}+\cos\theta\hat{\mathbf{z}} \\ &amp;amp;=&amp;amp; \cos\phi \sin\theta \hat{\mathbf{x}} + \sin\phi \sin\theta\hat{\mathbf{y}} + \cos\theta\hat{\mathbf{z}} \end{eqnarray*} $$ $\ha</description>
    </item>
    
    <item>
      <title>헤비사이드 계단 함수를 미분하면 디락 델타 함수가 됨을 증명</title>
      <link>https://freshrimpsushi.github.io/878/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/878/</guid>
      <description>헤비사이드 계단 함수의 미분은 디락 델타 함수이다. $$ \dfrac{dH}{dx}=\delta (x) $$ $H=H(x)$는 헤비사이드 계단 함수($\mathrm{Heaviside}$ $\mathrm{step}$ $\mathrm{function}$, $\mathrm{or}$ $\mathrm{unit}$ $\mathrm{step}$ $\mathrm{function}$ 단위 계단 함수)$H(x)=\begin{cases} 1 &amp;amp; x&amp;gt;0 \\ 0 &amp;amp; x \le 0 \end{cases} $$ \delta=\delta (x)$는 디락 델타 함수 $1.\ \ \delta (x) = \begin{cases} 0, &amp;amp; x\neq 0 \\ \infty , &amp;amp; x=0 \end{cases} $$ 2.\ \ \displaystyle{ \int_{-\infty}^{\infty}{\delta (x) dx}=1 } $**증명*</description>
    </item>
    
    <item>
      <title>헤세 행렬이란</title>
      <link>https://freshrimpsushi.github.io/hessian-matrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/hessian-matrix/</guid>
      <description>$D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 스칼라 함수 $f : D \to \mathbb{R}$ 에 대해 다음과 같은 행렬 $H \in \mathbb{R}^{n \times n}$ 을 $f $ 의 헤세 행렬 이라고 한다. $$ H := \begin{bmatrix} {{\partial^2 f } \over {\partial x_{1}^2 }} &amp;amp; \cdots &amp;amp; {{\partial^2 f } \over { \partial x_{1} \partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial^2 f } \over {\partial x_{n} \partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial^2 f_{m} } \over {\partial x_{n}^2 }} \end{bmatrix} $$ 야코비 행렬이 함수의 고차원적인 도함수에 해당한다면, 헤세 행렬은 고차원적인 이계도함수라고 볼 수 있다. 물론</description>
    </item>
    
    <item>
      <title>회전의 발산이 항상 0임을 증명</title>
      <link>https://freshrimpsushi.github.io/proof-that-divergence-of-curl-is-always-0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/proof-that-divergence-of-curl-is-always-0/</guid>
      <description>회전의 발산은 항상 $0$이다 $$ \nabla \cdot (\nabla \times \mathbf{A})=0 $$ 증명(직교좌표계) $$ \begin{eqnarray*} \nabla \times \mathbf{A} &amp;amp;=&amp;amp; \begin{vmatrix} \hat x &amp;amp; \hat y &amp;amp; \hat z \\ \displaystyle \frac{\partial}{\partial x} &amp;amp; \displaystyle \frac{\partial}{\partial y} &amp;amp; \displaystyle \frac{\partial}{\partial z} \\ A_x &amp;amp; A_y &amp;amp; A_z \end{vmatrix} \\ &amp;amp;=&amp;amp; \hat x \left( \frac{\partial V_z}{\partial y} - \frac{\partial V_y}{\partial z} \right) + \hat y \left( \frac{\partial V_x}{\partial z} - \frac{ \partial V_z}{\partial x} \right) + \hat z \left( \frac{\partial V_y}{\partial x}-\frac{\partial V_x}{\partial y} \right) \end{eqnarray*} $$ 이고 $$ \displaystyle \nabla = \hat x \frac{\partial}{\partial x} + \hat y \frac{\partial }{\partial y} + \hat z \frac{\partial }{\partial z} $$ 이므로 $$ \begin{eqnarray*} \nabla \cdot (\nabla \times \mathbf{A}) &amp;amp;=&amp;amp; \frac{\partial}{\partial x} \left( \frac{\partial V_z}{\partial y} - \frac{\partial V_y}{\partial z} \right) + \frac{\partial}{\partial y} \left(</description>
    </item>
    
  </channel>
</rss>
