<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>벡터 해석 on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/categories/%EB%B2%A1%ED%84%B0-%ED%95%B4%EC%84%9D/</link>
    <description>Recent content in 벡터 해석 on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Thu, 07 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/categories/%EB%B2%A1%ED%84%B0-%ED%95%B4%EC%84%9D/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>델 연산자가 포함된 곱셈 규칙</title>
      <link>https://freshrimpsushi.github.io/posts/product-rule-with-del-operator/</link>
      <pubDate>Thu, 07 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/product-rule-with-del-operator/</guid>
      <description>공식 $f=f(x,y,z)$를 스칼라 함수라고 하자. $\mathbf{A} = A_{x}\hat{\mathbf{x}} + A_{y}\hat{\mathbf{y}} + A_{z}\hat{\mathbf{z}}, \mathbf{B} = B_{x}\hat{\mathbf{x}} + B_{y}\hat{\mathbf{y}} + B_{z}\hat{\mathbf{z}}$를 벡터 함수라고 하자. 그러면 다음의 식들이 성립한다. 그래디언트(기울기) (a) $\nabla{(fg)}=f\nabla{g}+g\nabla{f}$ (b) $\nabla(\mathbf{A} \cdot \mathbf{B}) = \mathbf{A} \times (\nabla \times \mathbf{B}) + \mathbf{B} \times (\nabla \times \mathbf{A})+(\mathbf{A} \cdot \nabla)\mathbf{B}+(\mathbf{B} \cdot \nabla) \mathbf{A}$ 다이벌전스(발산) (c) $\nabla \cdot (f\mathbf{A}) = f(\nabla \cdot \mathbf{A}) + \mathbf{A} \cdot (\nabla f)$ (d) $\nabla \cdot (\mathbf{A} \times \mathbf{B}) = \mathbf{B} \cdot (\nabla \times</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 스칼라 함수의 라플라시안</title>
      <link>https://freshrimpsushi.github.io/posts/laplacian-of-scalar-function-in-cartesian-coordinate-system/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplacian-of-scalar-function-in-cartesian-coordinate-system/</guid>
      <description>정의 3차원 스칼라 함수 $f=f(x,y,z)$의 그래디언트의 다이벌전스를 $f$의 라플라시안Laplacian이라 하고 $\nabla^{2}$로 표기한다. $$ \nabla ^{2} f := \nabla \cdot(\nabla f)= \frac{ \partial^{2} f}{ \partial x^{2} }+\frac{ \partial^{2} f}{ \partial y^{2}}+\frac{ \partial^{2} f}{ \partial z^{2}} $$ 설명 라플라시안이라는 이름은 프랑스 수학자 라플라스 에서 따온 것이다. $\nabla^{2}$라는 표현은 편의를 위</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 다이버전스</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-in-vector-field/</link>
      <pubDate>Mon, 09 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-in-vector-field/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **다이버전스의 정의 유클리드 공간에서 정의된 벡터 필드 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 을 $\textbf{f} = (f_{1} , \cdots , f_{n})$ 과 같이 나타내고 축의 방향을 $u_{1} , \cdots , u_{n}$ 이라고 할 때, $\textbf{f}$ 의 다이버전스 를 다음과 같이 정의한다. $$ \text{div} \textbf{f} := \nabla \cdot \textbf{f} = \sum_{k=1}^{n} {{ \partial f_{k} } \over { \partial u_{k} }} $$ 벡터 필드의 다이버전스는 다음과 다음과 같이 한 점 $\textbf{v} \in \mathbb{R}^{n}$ 가 주어져 있</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 볼륨</title>
      <link>https://freshrimpsushi.github.io/posts/volume-in-vector-field/</link>
      <pubDate>Thu, 05 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/volume-in-vector-field/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **볼륨의 정의 유클리드 공간의 부분공간 $D \subset \mathbb{R}^{n} $ 의 볼륨 $V$ 는 직교좌표 $\textbf{u} = (u_{1}, u_{2}, \cdots , u_{n})$ 으로 나타낼 때 다음과 같이 정의된다. $$ V(D) = \int_{D} du_{1} du_{2} \cdots d u_{n} $$ $\textbf{u} \in \mathbb{R}^{n}$ 가 벡터 함수 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 의해 $\textbf{f} \left( \textbf{u} \right) = \left( f_{1} (\textbf{u}) , \cdots , f_{n} (\textbf{u}) \right) $ 와 같이 변환될 때, $D$ 의 볼륨 은 다음과 같다.$$ V(D) = \int_{D} \left| {{ \partial \textbf{f} (\textbf{u}) } \over {</description>
    </item>
    
    <item>
      <title>전미분</title>
      <link>https://freshrimpsushi.github.io/posts/total-derivative/</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/total-derivative/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 3차원 공간에서 정의된 함수 $f=f(x,y,z)$가 주어졌다고 하자. 각 변수 $x$, $y$, $z$의 변화에 따른 $f$의 함숫값의 변화를 전미분 이라 하고 $df$로 표기한다. 그러면 아래의 식이 성립한다. $$ df=\frac{ \partial f}{ \partial x }dx + \frac{ \partial f}{ \partial y}dy+\frac{ \partial f}{ \partial z}dz $$ 2변수 함수$z=f(x,y)$에 대해서 나타</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 벡터함수의 다이벌전스(발산)</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-of-fector-function-in-cartesian-cooridenates-system/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-of-fector-function-in-cartesian-cooridenates-system/</guid>
      <description>정의 벡터함수 $\mathbf{F}(x,y,z)=F_{x}\hat{\mathbf{x}}+F_{y}\hat{\mathbf{y}} + F_{z}\hat{\mathbf{z}}$에 대해서 다음과 같은 스칼라값을 $\mathbf{F}$ 다이벌전스divergence라고 정의하고 $\nabla \cdot \mathbf{F}$라고 표기한다. $$ \begin{equation} \nabla \cdot \mathbf{F} := \frac{ \partial F_{x}}{ \partial x} + \frac{ \partial F_{y}}{ \partial y }+ \frac{ \partial F_{z}}{ \partial z} \label{divergence} \end{equation} $$ 기하학적으로 $\nabla \cdot \mathbf{F}&amp;gt;0$이면 $\mathbf{F}$</description>
    </item>
    
    <item>
      <title>원통 좌표계의 변수로 알 세타를 쓰면 안되는 이유</title>
      <link>https://freshrimpsushi.github.io/posts/reason-not-to-use-rtheta-as-a-variable-in-the-cylindrical-coordinate-system/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/reason-not-to-use-rtheta-as-a-variable-in-the-cylindrical-coordinate-system/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 원통 좌표계는 아래와 같이 3차원 공간의 점을 $(\rho,\phi,z)$로 표현하는 좌표계를 말한다.그런데 원통 좌표계를 $(r,\theta, z)$와 같이 표기한 것을 볼 수 있다. 극좌표계 $(r,\theta)$에서 높이 $z$가 추가되었으니 아무 생각 없이 $(r,\theta, z)$와 같이 표기한 것으로 보이는데 이</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 스칼라 함수의 그래디언트(기울기)</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-of-scalar-function-in-cartesian-coordinate-system/</link>
      <pubDate>Sat, 12 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-of-scalar-function-in-cartesian-coordinate-system/</guid>
      <description>정의 3변수 스칼라 함수 $f=f(x,y,z)$의 그래프의 각 점에서 기울기와 증가하는 방향을 나타내는 벡터를 $\nabla f$라고 표기하며 그래디언트gradient라고 부른다. $$ \mathrm{grad}f=\nabla f = \frac{ \partial f}{ \partial x }\hat{\mathbf{x}}+\frac{ \partial f}{ \partial y}\hat{\mathbf{y}}+\frac{ \partial f}{ \partial z}\hat{\mathbf{z}} $$ 설명 그래디언트는 기울기, 구배, 물매 등으로 번역된다. 구매, 물매는 그래디언트의 옛날식 번역이고 최근에는 잘 쓰이지 않는</description>
    </item>
    
    <item>
      <title>구좌표계에서의 미소부피</title>
      <link>https://freshrimpsushi.github.io/posts/volume-in-polar-coordinates/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/volume-in-polar-coordinates/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 극 좌표계에서 미소 면적, 원통 좌표계에서 미소 부피 구좌표계에서 미소 부피는 아래와 같다. $$ dV=r^{2}\sin\theta dr d\theta d\phi $$ 구 표면 위의 미소 면적은 $dr$을 곱하지 않음으로써 얻을 수 있다. $$ da=\color{blue}{rd\theta} \cdot \color{red}{r\sin\theta d \phi}=r^{2}\sin\theta d\theta d\phi $$ 그림을 통한 이해(아래 그림을 매트랩에서 그리는 코드)** 구좌표계에서 미소부피는 위 그림에서 보이</description>
    </item>
    
    <item>
      <title>극 좌표계에서 미소 면적 원통 좌표계에서 미소 부피</title>
      <link>https://freshrimpsushi.github.io/posts/volume-in-cylindrical-coordinates/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/volume-in-cylindrical-coordinates/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 구 좌표계에서 미소 부피 극 좌표계에서 미소 면적은 다음과 같다. $$ dA=rdrd\theta $$ 원통 좌표계에서 미소 부피와 원통 표면의 미소 면적은 다음과 같다. $$ dV=\rho d\rho d\phi dz \\ dA=\rho d\phi dz $$ 매트랩에서 극 좌표계 그림 그리는 코드, 원통좌표계 그림 그리는 코드**극 좌표계 $\mathbf{r}=\mathbf{r}(r,\theta)$ 미소 면적은 그림에서와 같이 (초록선의 길이)$\t</description>
    </item>
    
    <item>
      <title>3차원 데카르트 좌표계에서 벡터함수의 컬(회전)</title>
      <link>https://freshrimpsushi.github.io/posts/curl-of-vector-function-in-cartesian-coordinate-system/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/curl-of-vector-function-in-cartesian-coordinate-system/</guid>
      <description>정의 3차원 벡터 $\mathbf{F}(x,y,z)=(F_{x},F_{y},F_{z})=F_{x}\hat{\mathbf{x}} + F_{y}\hat{\mathbf{y}} + F_{z}\hat{\mathbf{z}}$에 대해서 다음과 같은 벡터를 $\mathbf{F}$의 컬curl이라 정의하고 $\nabla \times \mathbf{F}$라고 표기한다. $$ \begin{align} \nabla \times \mathbf{F} &amp;amp;= \left( \dfrac{ \partial F_{z}}{ \partial y }-\dfrac{ \partial F_{y}}{ \partial z} \right)\hat{\mathbf{x}}+ \left( \dfrac{ \partial F_{x}}{ \partial z }-\dfrac{ \partial F_{z}}{ \partial x} \right)\hat{\mathbf{y}}+ \left( \dfrac{ \partial F_{y}}{ \partial x }-\dfrac{ \partial F_{x}}{ \partial y} \right)\hat{\mathbf{z}} \label{def1} \\ &amp;amp;=\begin{vmatrix} \hat{\mathbf{x}} &amp;amp; \hat{\mathbf{y}} &amp;amp; \hat{\mathbf{z}} \\ \dfrac{ \partial }{ \partial x} &amp;amp; \dfrac{ \partial }{ \partial</description>
    </item>
    
    <item>
      <title>두 벡터의 외적의 크기는 두 벡터가 만드는 평행사변형의 넓이와 같다</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-outer-product/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-outer-product/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 두 벡터 $\mathbf{A}$, $\mathbf{B}$ 사이의 각도가 $\theta$일 때 두 벡터의 외적의 크기는 다음과 같다. $$ \left| \mathbf{A}\times \mathbf{B}\right| =\left|\mathbf{A}\right|\left| \mathbf{B} \right|\sin \theta $$ 그리고 이는 두 벡터가 만드는 평행사변형의 넓이와 같다. 증명 두 벡터 $\mathbf{A}=(A_{x},A_{y},A_{z})$, $\mathbf{B}=(B_{x},B_{y},B_{z})$가 위 그림과 같다고 하자. 그러면 Part 1. 평행사</description>
    </item>
    
    <item>
      <title>물리학에서 델 연산자란</title>
      <link>https://freshrimpsushi.github.io/posts/del-operator-in-physics/</link>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/del-operator-in-physics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 델 연산자란 간단히 말해서 3차원 공간 좌표에 대한 미분 연산자이다. 연산자라는 말이 생소하다면 그냥 대상을 계산하는 규칙이라고 이해하면 된다. 예를 들어 $\dfrac{d}{dx}$는 함수를 $x$에 대해서 미분하라는 미분 연산자이다. 델 연산자는 보통 아래와 같이 소개된다. $$ \nabla = \frac{ d</description>
    </item>
    
    <item>
      <title>스칼라 필드의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-in-scalar-field/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-in-scalar-field/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 벡터장의 미분계수 :야코비 행렬 스칼라 필드 $f : \mathbb{R}^{n} \to \mathbb{R}$ 에 대해 한 점 $\mathbb{x}_{0} \in \mathbb{R}^{n}$ 에서 함수의 증가율이 가장 큰 방향을 나타낸 벡터를 $\mathbb{x}_{0}$ 에서 $f$ 의 그래디언트 라고 한다. 스칼라장의 예시로써 위의 그림을 생각해보자. 위 그림은 $z(x,y) = x^2 - y^2$ 와 같이 정의된 함수 $z : \mathbb{R}^{2} \to \mathbb{R}$ 을 시각적으로 나타낸 것이다. $y= f(x)$ 와 같</description>
    </item>
    
    <item>
      <title>헤세 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/hessian-matrix/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hessian-matrix/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 스칼라 함수 $f : D \to \mathbb{R}$ 에 대해 다음과 같은 행렬 $H \in \mathbb{R}^{n \times n}$ 을 $f $ 의 헤세 행렬 이라고 한다. $$ H := \begin{bmatrix} {{\partial^2 f } \over {\partial x_{1}^2 }} &amp;amp; \cdots &amp;amp; {{\partial^2 f } \over { \partial x_{1} \partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial^2 f } \over {\partial x_{n} \partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial^2 f_{m} } \over {\partial x_{n}^2 }} \end{bmatrix} $$ 야코비 행렬이 함수의 고차원적인 도함수에 해당한다면, 헤</description>
    </item>
    
    <item>
      <title>야코비 행렬 혹은 자코비 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/jacobian-matrix/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jacobian-matrix/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 스칼라장의 미분계수 : 델 연산자 $D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 벡터 함수 $\mathbb{f} : D \to \mathbb{R}^{m}$ 가 각각의 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ 과 같이 정의되었다고 하자. $$ J := \begin{bmatrix} {{\partial f_{1} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{1} } \over {\partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots</description>
    </item>
    
    <item>
      <title>스칼라 함수와 벡터 함수</title>
      <link>https://freshrimpsushi.github.io/posts/scalar-function-and-vector-function/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scalar-function-and-vector-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $D \subset \mathbb{R}^{n}$ 이라고 하자. 1.** $D$ 를 정의역으로 갖는 함수를 **다변수 함수** 라고 한다. 2.** $f : D \to \mathbb{R}$ 을 **스칼라 함수** 라고 한다. 3.** 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 $\mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix}$ 과 같이 정의된 $\mathbb{f} : D \to \mathbb{R}^{m}$ 를 **벡터 함수** 라</description>
    </item>
    
    <item>
      <title>델 연산자가 포함된 식의 부분적분</title>
      <link>https://freshrimpsushi.github.io/posts/integral-by-part-with-del-operator/</link>
      <pubDate>Sun, 17 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integral-by-part-with-del-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 부분적분의 원리를 그대로 사용해서 델 연산자가 포함된 식의 모습을 유용하게 바꿀 수 있다. **부분적분 $\dfrac{d}{dx}\left( fg \right) = f\dfrac{dg}{dx}+g\dfrac{df}{dx}$양 변을 정적분하면$\displaystyle \int_a^b \dfrac{d}{dx} \left(fg\right) = (fg)\Big|_a^b=\int_a^b f\left(\dfrac{dg}{dx}\right)dx+\int_a^bg\left(\dfrac{df}{dx}\right)dx $$ \implies \int_a^b f\left(\dfrac{dg}{dx}\right)dx = (fg)\Big|_a^b-\int_a^bg\left(\dfrac{df}{dx}\right)dx$ 부분적분은 어떤 함수$(f\</description>
    </item>
    
    <item>
      <title>물리학을 위한 스토크스 정리</title>
      <link>https://freshrimpsushi.github.io/posts/stokes-theorem-for-physics/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/stokes-theorem-for-physics/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **스토크스 정리(회전의 기본 정리) $$ \int_{\mathcal{S}} (\nabla \times \mathbf{v} )\cdot d\mathbf{a} = \oint_{\mathcal{P}}v\cdot d\mathbf{l} $$ 어떤 영역 안에서의 벡터 $\mathbf{v}$가 회전하는 양(좌변)은 그 영역의 테두리에서 벡터 $\mathbf{v}$의 값(우변)과 같다.사실 물리학을 공부하는 사람이라면 위 수식의 증명이 크게 중요한 것은 아니다.</description>
    </item>
    
    <item>
      <title>분리벡터 의 회전</title>
      <link>https://freshrimpsushi.github.io/posts/curl-of-separation-vector-1r2/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/curl-of-separation-vector-1r2/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\nabla \times \dfrac{\hat{\boldsymbol{\eta}} }{\eta ^2} =0$ 이 식이 특별한 의미를 가지는 것은 아니다.자기장의 발산을 구하는 과정에서 나오는데 계산이 간단하지 않아 따로 설명한다.$\boldsymbol{\eta}=(x-x&#39;)\mathbf{x} + (y-y&#39;)\mathbf{y} + (z-z&#39;)\mathbf{z}$는 분리벡터 $$ | \boldsymbol{\eta} |=\eta=\sqrt{(x-x&#39;)^2+(y-y&#39;)^2 + (z-z&#39;)^2} $$ $$ \hat{</description>
    </item>
    
    <item>
      <title>델 연산자가 두 번 들어간 수식 2계 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/second-derivative-with-del-operator/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/second-derivative-with-del-operator/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $T$는 스칼라 함수, $\mathbf{A}$는 벡터 함수라고하자.$(1)$ 기울기의 발산 $\nabla \cdot (\nabla T) =\nabla ^2 T $$ (2)$ 기울기의 회전 $\nabla \times (\nabla T)=0 $$ (3)$ 발산의 기울기 $\nabla (\nabla \cdot \mathbf{A} ) $$ (4)$ 회전의 발산 $\nabla \cdot (\nabla \times \mathbf{A})=0 $$ (5)$ 회전의 회전 $\nabla \times (\nabla \times \mathbf{A})=\nabla ( \nabla \cdot \mathbf{A}) - \nabla ^2 \mathbf{A}$ 기울기와 회전의 결과가 벡터이고 발산의 결과가</description>
    </item>
    
    <item>
      <title>헤비사이드 계단 함수를 미분하면 디락 델타 함수가 됨을 증명</title>
      <link>https://freshrimpsushi.github.io/posts/derivative-of-heaviside-function-is-dirac-delta-function/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivative-of-heaviside-function-is-dirac-delta-function/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 헤비사이드 계단 함수의 미분은 디락 델타 함수이다. $$ \dfrac{dH}{dx}=\delta (x) $$ $H=H(x)$는 헤비사이드 계단 함수(Heaviside step function) 혹은 **단위 계단 함수(unit step function) $$ H(x)=\begin{cases} 1 &amp;amp; x&amp;gt;0 \\ 0 &amp;amp; x \le 0 \end{cases} $$ $\delta=\delta (x)$는 **디락 델타 함수 $$ \delta (x) = \begin{cases} 0, &amp;amp; x\neq 0 \\ \infty , &amp;amp; x=0 \end{cases} $$ $$ \int_{-\infty}^{\infty}{\delta (x) dx}=1 $$ 증명 $\df</description>
    </item>
    
    <item>
      <title>1ㄱ^2의 발산</title>
      <link>https://freshrimpsushi.github.io/posts/the-divergence-of-1r2/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-divergence-of-1r2/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\nabla \cdot \left( \dfrac{1}{r^2}\hat{ \mathbf{r} } \right) = 4\pi \delta^3(\mathbf{r}) $$ \nabla \cdot \left( \dfrac{1}{\eta^2}\hat{ \boldsymbol{\eta} } \right) = 4\pi \delta^3(\boldsymbol{\eta}) $$ \nabla^2 \left(\dfrac{1}{\eta} \right) =-4\pi \delta^3 ( \mathbf{r} ) $ 벡터함수 $\mathbf{v} = \dfrac{1}{r^2}\hat{\mathbf{r}}$이 있다고 하자.크기는 거리 제곱에 반비례하고 방향은 반지름 방향이다.이제부터 이 함수의 발산을 계산해보자.구좌표계에서의 기울기 공</description>
    </item>
    
    <item>
      <title>기울기의 기본 정리</title>
      <link>https://freshrimpsushi.github.io/posts/fundamental-theorem-for-gradient/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/fundamental-theorem-for-gradient/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 **기울기의 기본 정리 임의의 경로를 따라 점 $a$에서 점 $b$로 갈 때 $T$의 총 변화량은 아래와 같다.$T(b)-T(a) = \displaystyle \int _a^b (\nabla T) \cdot d\mathbf{l}$ $\cdots (1)$ 이에 관련된 개념들을 수학적으로 엄밀하게 정의하고 해당 내용을 증명하는 것은 물리학을 공부하는 이에게 중요한 내용이 아니므로 간단하게 서술하</description>
    </item>
    
    <item>
      <title>유사벡터란</title>
      <link>https://freshrimpsushi.github.io/posts/pseudovector/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/pseudovector/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 물리학 공부를 하다 보면 유사벡터 혹은 수도벡터라는 말을 접할 수 있다. 중요한 점은 유사벡터를 접하기만 할 뿐 어떤 녀석인지 알기는 힘들다는 거다. 유사벡터가 뭔지 몰라도 학부 물리학을 공부하는데 아무 지장은 없다지만 제대로 설명해놓은 교재를 본 적이 없다. 나는 유사벡터의 특징을 배울 수 있도록 한 그</description>
    </item>
    
    <item>
      <title>발산 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-divergence-theorem/</link>
      <pubDate>Sat, 12 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-divergence-theorem/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 발산 정리$(\mathrm{divergence\ theorem})$, 가우스 정리$(\mathrm{Gauss\ theorem})$ $$ \displaystyle \int_\mathcal{V} \nabla \cdot \mathbf{ F} dV = \oint _\mathcal{S} \mathbf{F} \cdot d \mathbf{S} $$ 발산 정리는** 가우스 정리** 혹은 **그린 정리$(\mathrm{Green&amp;rsquo;s\ theorem})$** 라고도 부르며 물리에서는 주로 전자기</description>
    </item>
    
    <item>
      <title>직교좌표계에서의 벡터 미분</title>
      <link>https://freshrimpsushi.github.io/posts/derivative-of-a-vector-in-cartesian-coordinate/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/derivative-of-a-vector-in-cartesian-coordinate/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 3차원 직교좌표계에서 두 벡터 $\mathbf{A}$, $\mathbf{B}$에 대한 미분은 다음과 같다.$\mathbf{A},\ \mathbf{B}$를 각각$\mathbf{A}(u)=A_{x}(u)\hat{\mathbf{x}} + A_{y}(u)\hat{\mathbf{y}} + A_{z}(u)\hat{\mathbf{z}}$,$\mathbf{B}(u)=B_{x}(u)\hat{\mathbf{x}} + B_{y}(u)\hat{\mathbf{y}} + B_{z}(u)\hat{\ma</description>
    </item>
    
    <item>
      <title>직교 원통 구면 좌표계에 대한 기울기 발산 회전 라플라스 연산</title>
      <link>https://freshrimpsushi.github.io/posts/del-operator-in-several-coordinates/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/del-operator-in-several-coordinates/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 직교좌표계, 원통좌표계, 구면좌표계에서의 기울기$\mathrm{Gradient}$, 발산$\mathrm{Divergence}$, 회전$\mathrm{Curl}$, 라플라스 연산$\mathrm{Laplasian}$을 정리했다. 이렇게 정리한 이유는 보</description>
    </item>
    
    <item>
      <title>직교좌표계 단위벡터를 구면좌표계의 단위벡터로 나타내기</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-cartesian-coordinate-system-unit-vectors-and-spherical-coordinate-system-unit-vectors/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-cartesian-coordinate-system-unit-vectors-and-spherical-coordinate-system-unit-vectors/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 직교좌표계의 단위벡터를 구면좌표계의 단위벡터로 나타낸 식은 아래와 같다. $$ \begin{align*} \hat{ \mathbf{x} }&amp;amp;= \cos \phi \sin \theta \hat{ \mathbf{r} } + \cos \phi \cos \theta \hat{ \boldsymbol{\theta} } - \sin\phi\hat{ \boldsymbol{\phi} } \\ \hat{ \mathbf{y} } &amp;amp;= \sin\phi\sin\theta \hat{ \mathbf{r} } + \sin\phi\cos\theta\hat{ \boldsymbol{\theta} } + \cos\phi\hat{ \boldsymbol{\phi} } \\ \hat{ \mathbf{z} } &amp;amp;= \cos\theta\hat{ \mathbf{r} } - \sin\theta\hat{ \boldsymbol{\theta} } \end{align*} $$ 구면좌표계의 단위벡터를 직교좌표계의 단위벡터로 나타내면 아래와 같다. (구면좌표계와</description>
    </item>
    
    <item>
      <title>삼차원 유클리드 공간에서 외적이란</title>
      <link>https://freshrimpsushi.github.io/posts/outer-product-in-three-dimension/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/outer-product-in-three-dimension/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 $\mathbb{x}, \mathbb{y} \in \mathbb{R}^3$ 에 대해 다음을 $\mathbb{x}$와 $\mathbb{y} $의 외적 으로 정의한다. $$ \begin{eqnarray*} \mathbb{x} \times \mathbb{y} &amp;amp;=&amp;amp; (x_{2}y_{3} - x_{3}y_{2}, x_{3}y_{1} - x_{1}y_{3}, x_{1}y_{2} - x_{2}y_{1}) \\ &amp;amp;=&amp;amp; \det \begin{bmatrix} \mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} \\ x_{1} &amp;amp; x_{2} &amp;amp; x_{3} \\ y_{1} &amp;amp; y_{2} &amp;amp; y_{3} \end{bmatrix} \\ &amp;amp;=&amp;amp; \begin{bmatrix} 0 &amp;amp; -x_{3} &amp;amp; x_{2} \\ x_{3} &amp;amp; 0 &amp;amp; -x_{1} \\ -x_{2} &amp;amp; x_{1} &amp;amp; 0 \end{bmatrix} \begin{bmatrix} y_{1} \\ y_{2} \\ y_{3} \end{bmatrix} \end{eqnarray*} $$ 참고로 $\mathbf{i} = (1,0,0)$ , $ \mathbf{j} = (0,1,0)$ , $ \mathbf{k} = (0,0,1)$ 이다.내적과 마찬가</description>
    </item>
    
    <item>
      <title>유클리드 공간에서 내적이란</title>
      <link>https://freshrimpsushi.github.io/posts/inner-product-in-euclidean-space/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inner-product-in-euclidean-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 벡터공간 $V = \mathbb{R}^n$ 에 대해 $\mathbb{x}, \mathbb{y}, \mathbb{z} \in V$ 그리고 $k \in \mathbb{R}$ 이라고 하자. $\left&amp;lt; , , \right&amp;gt; : V^2 \to \mathbb{R} $ 가 아래 네 조건들을 만족시킬 때 $\left&amp;lt; , , \right&amp;gt;$ 를 $V$ 상에서의 내적 으로 정의한다. (1) 대칭성** : $\left&amp;lt; \mathbb{x} , \mathbb{y} \right&amp;gt; = \left&amp;lt; \mathbb{y}, \mathbb{x} \right&amp;gt;$ (2) 가산성** : $\left&amp;lt; \mathbb{x} + \mathbb{y} , \mathbb{z} \right&amp;gt; = \left&amp;lt; \mathbb{x}, \mathbb{z} \right&amp;gt; + \left&amp;lt; \mathbb{y}, \mathbb{z} \right&amp;gt;$ (3) 동질성** : $ \left&amp;lt; k \mathbb{x} , \mathbb{y} \right&amp;gt; = k \left&amp;lt; \mathbb{x},</description>
    </item>
    
    <item>
      <title>컬의 다이버전스는 항상 0이다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-that-diaergence-of-curl-is-always-0/</link>
      <pubDate>Fri, 22 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-that-diaergence-of-curl-is-always-0/</guid>
      <description>공식 벡터함수 $\mathbf{A}$의 컬의 다이버전스는 항상 $0$이다. $$ \nabla \cdot (\nabla \times \mathbf{A}) = 0 $$ 증명 $\mathbf{A}$의 컬은 다음과 같다. $$ \begin{align*} \nabla \times \mathbf{A} &amp;amp;= \begin{vmatrix} \hat{\mathbf{x}} &amp;amp; \hat{\mathbf{y}} &amp;amp; \hat{\mathbf{z}} \\ \displaystyle \frac{\partial}{\partial x} &amp;amp; \displaystyle \frac{\partial}{\partial y} &amp;amp; \displaystyle \frac{\partial}{\partial z} \\ A_{x} &amp;amp; A_{y} &amp;amp; A_{z} \end{vmatrix} \\ &amp;amp;= \hat{\mathbf{x}} \left( \frac{\partial A_{z}}{\partial y} - \frac{\partial A_{y}}{\partial z} \right) + \hat{\mathbf{y}} \left( \frac{\partial A_{x}}{\partial z} - \frac{ \partial A_{z}}{\partial x} \right) + \hat{\mathbf{z}} \left( \frac{\partial A_{y}}{\partial x}-\frac{\partial A_{x}}{\partial y} \right) \end{align*} $$ 어떤 벡터함수 $\mathbf{F}</description>
    </item>
    
    <item>
      <title>벡터함수의 컬의 컬</title>
      <link>https://freshrimpsushi.github.io/posts/the-curl-of-curl-of-vector-function/</link>
      <pubDate>Sun, 06 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-curl-of-curl-of-vector-function/</guid>
      <description>공식 벡터함수의 컬의 컬은 다음과 같다. $$ \nabla \times (\nabla \times \mathbf{A}) = \nabla (\nabla \cdot \mathbf{A}) - \nabla^2 \mathbf{A} $$ 설명 첫번째 항인 $\nabla(\nabla \cdot \mathbf{A})$는 다이버전스의 그래디언트이며 따로 붙여진 이름은 없다. 두번째 항은 중요해서 이름이 있다. $\nabla \cdot \nabla$를 라플라시안이라 하는데, 정확하게는 벡터함수의 라플라시안이다. 컬의 컬에 특별한 의미가 있는 것은 아니고,</description>
    </item>
    
    <item>
      <title>그래디언트의 컬은 항상 0이다</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-that-the-curl-of-a-gradient-is-always-0/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-that-the-curl-of-a-gradient-is-always-0/</guid>
      <description>공식 스칼라 함수 $T$의 그래디언트의 컬은 항상 $\mathbf{0}$이다 $$ \nabla \times (\nabla T)=0 $$ 증명 직교 좌표계에서 $T$의 그래디언트는 다음과 같다. $$ \nabla T = \frac{\partial T}{\partial x}\hat{\mathbf{ x}} +\frac{\partial T}{\partial y}\hat{\mathbf{y}} +\frac{\partial T}{\partial z}\hat{\mathbf{z}} $$ $\nabla T$의 컬을 구하면 다음과 같다. $$ \begin{align*} \nabla \times (\nabla T) &amp;amp;= \begin{vmatrix} \displaystyle \hat{\mathbf{x}} &amp;amp;\hat{\mathbf{y}} &amp;amp; \hat{\mathbf{z}} \\ \displaystyle \frac{\partial }{\partial x} &amp;amp; \displaystyle \frac{\partial }{\partial y} &amp;amp; \displaystyle \frac{\partial }{\partial z} \\ \displaystyle \frac{\partial T}{\partial x} &amp;amp; \displaystyle \frac{\partial T}{\partial y} &amp;amp; \displaystyle\frac{\partial T}{\partial z} \end{vmatrix} \\ &amp;amp;= \left( \frac{\partial^2 T}{\partial y \partial z}-\frac{\partial^2 T}{\partial z \partial</description>
    </item>
    
    <item>
      <title>유클리드 공간이란</title>
      <link>https://freshrimpsushi.github.io/posts/what-is-an-euclidean-space/</link>
      <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/what-is-an-euclidean-space/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 정의 유클리드 공간 $$ \mathbb{R}^{n} = \mathbb{R} \times \cdots \times \mathbb{R} $$ 자연수 $n \in \mathbb{N}$ 에 대해 실수 집합 $\mathbb{R}$ 의 데카르트 곱 $\mathbb{R}^{n}$ 을 유클리드 공간 이라고 한다. 1. $\mathbb{R}^{1}$ 을 실수 공간 혹은 수직선 이라고 한다. 2. $\mathbb{R}^{2}$ 을 평면 이라고 한다. 3. $\mathbb{R}^{3}$ 을 $3$차원 공간 이라고 한다. $\mathbb{N} := \left\{ 1, 2, 3, \cdots \right\}$ 은 자연수를 모두 모아놓은 집합을 의미한다. $\mathbb{R}$ 은 실수</description>
    </item>
    
    <item>
      <title>직교좌표계의 단위벡터로 표현한 구면좌표계의 단위벡터</title>
      <link>https://freshrimpsushi.github.io/posts/relationship-between-cartesian-coordinate-system-unit-vectors-and-spherical-coordinate-system-unit-vectors/</link>
      <pubDate>Sun, 16 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/relationship-between-cartesian-coordinate-system-unit-vectors-and-spherical-coordinate-system-unit-vectors/</guid>
      <description>🚧 이 포스트는 아직 이관 작업이 완료되지 않았습니다 🚧 구면좌표계의 단위벡터를 직교좌표계의 단위벡터로 표현하면 아래와 같다. $$ \begin{align*} \hat{\mathbf{r}} &amp;amp;= \cos\phi \sin\theta\hat{\mathbf{x}} + \sin\phi \sin\theta\hat{\mathbf{y}} + \cos\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\theta}} &amp;amp;= \cos\phi \cos\theta \hat{\mathbf{x}} + \sin\phi \cos\theta \hat{\mathbf{y}} - \sin\theta\hat{\mathbf{z}} \\ \hat{\boldsymbol{\phi}} &amp;amp;= -\sin\phi \hat{\mathbf{x}} + \cos\phi \hat{\mathbf{y}} \end{align*} $$ $\hat{\mathbf{r}}$을 먼저 구한 뒤 이를 이용해서 나머지 둘을 구한다.증명 $$ \hat{\mathbf{r}}=r\hat{\mathbf{r}}=x\hat{\mathbf{x}}+y\hat{\mathbf{y}}+z\hat{\mathbf{z}} $$ 이므로 양변을 $r$로 나누면 $$ \begin{align*} \hat{\mathbf{r}}&amp;amp;=\frac{x}{r}\hat{\mathbf{x}}+\frac{y}{r}\hat{\mathbf{y}}+\frac{z}{r}\hat{\mathbf{z}} \\ &amp;amp;=</description>
    </item>
    
    <item>
      <title>스칼라 삼중곱</title>
      <link>https://freshrimpsushi.github.io/posts/properties-of-scalar-triple-product/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/properties-of-scalar-triple-product/</guid>
      <description>스칼라 삼중곱 $$ \mathbf{A}\cdot (\mathbf{B} \times \mathbf{C} ) $$ 설명 위 식을 스칼라 삼중곱scalar triple product이라 한다. 스칼라 삼중곱은 벡터 3개를 곱하는 연산 중에서 결과가 스칼라인 것을 말한다. 결과가 벡터인 것은 벡터 삼중곱이라 한다. 결과가 스칼라로 나오기 위해서는 우선 두 벡터를 외적해서 나온 벡터와 다른 벡터를 내적해야한다. 스칼라 삼중곱의 특징을 하나씩 살펴</description>
    </item>
    
    <item>
      <title>분리벡터</title>
      <link>https://freshrimpsushi.github.io/posts/separation-vector/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/separation-vector/</guid>
      <description>정의1 원천점에서 관찰점까지의 벡터를 분리벡터separation vector라 한다. $$ \boldsymbol{\eta} = \mathbf{r} - \mathbf{r}&#39; $$ 설명 원천벡터source vector $\mathbf{r}&#39;$: 전하나 전류가 있는 곳. 즉, 전자기장을 만드는 근원지의 좌표를 나타내는 벡터이다. 위치벡터position vector $\mathbf{r}$: 전기장 $\mathbf{E}$나 자기장 $\mathbf{B}$ 등을 측정하는 곳의 좌표를 나타내는 벡터이</description>
    </item>
    
    <item>
      <title>분리벡터의 크기의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-of-separation-vector/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-of-separation-vector/</guid>
      <description>공식 분리벡터 $\boldsymbol{\eta}$의 크기의 $n$ 제곱, $\eta ^{n}$의 그래디언트는 다음과 같다. $$ \nabla (\eta^n)=n\eta^{n-1}\hat{\boldsymbol{\eta}} $$ 다항함수의 미분과 같은 방식으로 계산한 뒤에 단위벡터인 $\hat{\boldsymbol{\eta}}$만 붙여주면 된다. 설명 분리벡터는 $\boldsymbol{\eta}=\mathbf{r}-</description>
    </item>
    
    <item>
      <title>벡터 삼중곱, BAC-CAB 공식</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-vector-triple-productbac-cab-rule/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-vector-triple-productbac-cab-rule/</guid>
      <description>공식 $$ \mathbf{A} \times (\mathbf{B} \times \mathbf{C} ) = \mathbf{B}(\mathbf{A} \cdot \mathbf{C} )-\mathbf{C}(\mathbf{A} \cdot \mathbf{B}) $$ 설명 위 공식의 좌변을 벡터 삼중곱vector triple product이라 한다. 우변의 결과를 간단하게 **BAC-CAB(백캡)**이라고 한다. 벡터 삼중곱은 벡터를 3번 곱하는 연산 중에서 그 결과가 벡터인 것이다. 결과가 벡터로 나오기 위해서 식에는 외적만 두 번 들어간다. 두 벡터의 외적은 여전히 벡터이므</description>
    </item>
    
  </channel>
</rss>
