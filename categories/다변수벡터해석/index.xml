<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>다변수벡터해석 on 생새우초밥집</title>
    <link>https://freshrimpsushi.github.io/categories/%EB%8B%A4%EB%B3%80%EC%88%98%EB%B2%A1%ED%84%B0%ED%95%B4%EC%84%9D/</link>
    <description>Recent content in 다변수벡터해석 on 생새우초밥집</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Wed, 04 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://freshrimpsushi.github.io/categories/%EB%8B%A4%EB%B3%80%EC%88%98%EB%B2%A1%ED%84%B0%ED%95%B4%EC%84%9D/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>n차원 극좌표</title>
      <link>https://freshrimpsushi.github.io/posts/n-dimensional-polar-coordinate/</link>
      <pubDate>Wed, 04 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/n-dimensional-polar-coordinate/</guid>
      <description>정의1 점 $x \in \mathbb{R}^{n}$의 데카르트 좌표를 $x_{1}, \dots, x_{n}$이라고 하자. 그러면 이 점의 극좌표polar coordinates $r, \varphi_{1}, \dots, \varphi_{n-1}$와의 관계는 다음과 같다. $$ \begin{align*} x_{1} =&amp;amp;\ r \sin \varphi_{1} \sin \varphi_{2} \sin \varphi_{3} \cdots \sin \varphi_{n-2} \cos \varphi_{n-1} \\ x_{2} =&amp;amp;\ r \sin \varphi_{1} \sin \varphi_{2} \sin \varphi_{3} \cdots \sin \varphi_{n-2} \sin \varphi_{n-1} \\ x_{3} =&amp;amp;\ r \sin \varphi_{1} \sin \varphi_{2} \sin \varphi_{3} \cdots \cos \varphi_{n-2} \\ x_{4} =&amp;amp;\ r \sin \varphi_{1} \sin \varphi_{2} \sin \varphi_{3} \cdots \sin \varphi_{n-2} \\ \vdots&amp;amp;\ \\ x_{n-1} =&amp;amp;\ r \sin</description>
    </item>
    
    <item>
      <title>다변수 함수에 대한 테일러 정리</title>
      <link>https://freshrimpsushi.github.io/posts/taylors-theorem-with-remainder-for-multivariable-function/</link>
      <pubDate>Thu, 23 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/taylors-theorem-with-remainder-for-multivariable-function/</guid>
      <description>정리1 $F : \mathbb{R}^{n} \to \mathbb{R}$를 $C^{k}$ 함수, $\mathbf{a} = (a_{1}, \dots, a_{n}) \in \mathbb{R}^{n}$라고 하자. 그러면 다음을 만족하는 $C^{k-2}$ 함수 $h_{ij}$가 존재한다. $$ F(x_{1}, \dots, x_{n}) = F(a_{1}, \dots, a_{n}) + \sum_{i} \dfrac{\partial F}{\partial x_{i}}(\mathbf{a})(x_{i} - a_{i}) + \sum_{i,j}h_{ij}(\mathbf{x})(x_{i} - a_{i}) (x_{j} - a_{j}) $$ 증명 $$ \begin{align*} F(\mathbf{x}) - F(\mathbf{a}) =&amp;amp;\ \int_{0}^{1} \dfrac{d}{dt} \left[ F(t(\mathbf{x} - \mathbf{a}) + \mathbf{a}) \right]dt \\ =&amp;amp;\ \int_{0}^{1} \left( \sum_{i} \dfrac{\partial F}{\partial x_{i}}\left( t(\mathbf{x} - \mathbf{a}) + \mathbf{a} \right)(x_{i}-a_{i}) \right) dt &amp;amp; \text{by } \href{https://freshrimpsushi.github.io/posts/3134}{\text{chain rule}} \\ =&amp;amp;\ \sum_{i}(x_{i} - a_{i}) \int_{0}^{1} \left( \dfrac{\partial F}{\partial x_{i}}\left( t(\mathbf{x} - \mathbf{a})</description>
    </item>
    
    <item>
      <title>해석학에서 역함수 정리</title>
      <link>https://freshrimpsushi.github.io/posts/the-inverse-function-theorem-in-analysis/</link>
      <pubDate>Fri, 05 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/the-inverse-function-theorem-in-analysis/</guid>
      <description>정리1 열린 집합 $E$에서 정의된 함수 $\mathbf{f} : E \subset \mathbb{R}^{n} \to \mathbb{R}^{n}$이 $C^{1}-$함수라고 하자. $\mathbf{a} \in E$에 대해서, $\mathbf{f}^{\prime}(\mathbf{a})$가 가역이고 $\mathbf{b} = \mathbf{\mathbf{a}}$라고 하자. 그러면 다음이 성립한다. (a) $\mathbf{a} \in U, \mathbf{b} \in V$이고,</description>
    </item>
    
    <item>
      <title>합성함수의 자코비안</title>
      <link>https://freshrimpsushi.github.io/posts/jacobian-of-composition-function/</link>
      <pubDate>Wed, 03 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jacobian-of-composition-function/</guid>
      <description>정리 두 함수 $f : \mathbb{R}^{n} \to \mathbb{R}^{m}$, $g : \mathbb{R}^{m} \to \mathbb{R}^{k}$가 주어졌다고 하자. $f$의 자코비안를 $J(f)$와 같이 표기하자. 그러면 다음이 성립한다. $$ J(g \circ f) = J(g) J(f) $$ 설명 자코비안은 가장 일반화된 도함수이므로, 위 정리는 연쇄법칙의 일반화이다. 증명 자코비안의 정의에 의해 $$ J(g \circ f) = \begin{bmatrix} \dfrac{\partial (g \circ f)_{1}}{\partial x_{1}} &amp;amp; \cdots &amp;amp; \dfrac{\partial (g \circ f)_{1}}{\partial x_{n}} \\ \vdots &amp;amp; \ddots</description>
    </item>
    
    <item>
      <title>다변수 벡터함수의 연쇄법칙</title>
      <link>https://freshrimpsushi.github.io/posts/chaine-rule-for-multivariable-vector-valued-funtion/</link>
      <pubDate>Tue, 26 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/chaine-rule-for-multivariable-vector-valued-funtion/</guid>
      <description>정리 두 함수 $\mathbf{g} : D \subset \mathbb{R}^{m} \to \mathbb{R}^{k}$, $\mathbf{f} : \mathbf{g}(\mathbb{R}^{k}) \subset \mathbb{R}^{k} \to \mathbb{R}^{n}$가 미분 가능하다고 하자. 그러면 두 함수의 합성 $\mathbf{F} = \mathbf{f} \circ \mathbf{g} : \mathbb{R}^{m} \to \mathbb{R}^{n}$도 미분가능하고, $\mathbf{F}$의 (전)도함수는 다음을 만족한다. $$ \mathbf{F}^{\prime}(\mathbf{x}) = \mathbf{f}^{\prime}\left( \mathbf{g}(\mathbf{x}) \right) \mathbf{g}^{\prime}(\mathbf{x}) $$ 설명 이를 연쇄법칙이라 한다. 증명은 여기를 참고하자. $\mathbf{x} = (x_{1}, \dots, x_{m})$, $\mathbf{g}(\mathbf{x})</description>
    </item>
    
    <item>
      <title>방향 도함수의 정의</title>
      <link>https://freshrimpsushi.github.io/posts/definition-of-directional-derivative/</link>
      <pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/definition-of-directional-derivative/</guid>
      <description>빌드업 다변수 함수 $f = \mathbb{R}^{n} \to \mathbb{R}$이 주어졌다고 하자. $f$의 도함수를 구하려고하면, 일변수함수일 때는 하지않았던 &amp;lsquo;어느 방향&amp;rsquo; 으로의 변화율인지에 대해서 생각해야한다. 익숙한 예로 편 도함수가 있다. 편 도함수는 하나의 변수에 대해서만 변화율을 생각한 것이다. 가령 $f=f(x,y,z)$</description>
    </item>
    
    <item>
      <title>정칙 사상</title>
      <link>https://freshrimpsushi.github.io/posts/regular-mapping/</link>
      <pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/regular-mapping/</guid>
      <description>정의1 사상 $\mathbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{m}$이 아래와 같이 주어졌다고 하자. $$ \mathbf{f}(\mathbf{x}) = \left( f_{1}(\mathbf{x}), f_{2}(\mathbf{x}), \dots, f_{m}(\mathbf{x}) \right),\quad \mathbf{x}\in \R^{n} $$ $\mathbf{f}$의 전 도함수, 혹은 야코비 행렬은 다음과 같다. $$ \mathbf{f}^{\prime} = J = \begin{bmatrix} \dfrac{\partial f_{1}}{\partial x_{1}} &amp;amp; \cdots &amp;amp; \dfrac{\partial f_{1}}{\partial x_{n}} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ \dfrac{\partial f_{m}}{\partial x_{1}} &amp;amp; \cdots &amp;amp; \dfrac{\partial f_{m}}{\partial x_{n}} \end{bmatrix} $$ 모든 점 $\mathbf{x} \in \R^{n}$에서 $\mathbf{f}$의 야코비 행렬의 랭크</description>
    </item>
    
    <item>
      <title>전 도함수: 다변수 벡터함수의 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/total-derivative-of-multivariable-vector-function/</link>
      <pubDate>Wed, 14 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/total-derivative-of-multivariable-vector-function/</guid>
      <description>빌드업1 일변수함수의 도함수의 정의를 떠올려보자. $$ \lim \limits_{h\to 0} \dfrac{f(x+h) - f(x)}{h} = f^{\prime}(x) $$ 여기서 좌변의 분자를 아래와 같이 $h$에 대한 선형함수로 근사하면 다음과 같다. $$ \begin{equation} f(x+h) - f(x) = a h + r(h) \label{1} \end{equation} $$ 여기서 $r(h)$는 다음과 같은 조건을 만족하는 나머지remainder, 잔차라고 하자. $$ \lim \limits_{h \to 0} \dfrac{r(h)}{h}=0 $$ 그러면 $\eqref{1}$의 양변을 $h</description>
    </item>
    
    <item>
      <title>스칼라필드의 라플라시안</title>
      <link>https://freshrimpsushi.github.io/posts/laplacian-of-scalar-field/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/laplacian-of-scalar-field/</guid>
      <description>정의 스칼라 함수 $u : \mathbb{R}^{n} \to \mathbb{R}$의 그래디언트의 다이벌전스를 라플라시안Laplacian이라 하고 다음과 같이 표기한다. $$ \begin{align*} \Delta u :&amp;amp;= \mathrm{div}(\nabla (u)) \\ &amp;amp;= \mathrm{div} \left( \left( u_{x_{1}}, u_{x_{2}}, \dots, u_{x_{n}} \right) \right) \\ &amp;amp;= u_{x_{1}x_{1}} + u_{x_{2}x_{2}} + \cdots + u_{x_{n}x_{n}} \\ &amp;amp;= \sum _{i=1}^{n} u_{x_{i}x_{i}} \end{align*} $$ 여기서 $u_{x_{i}}=\dfrac{\partial u}{\partial x_{i}}$이다. 설명 수학에서는 다이벌전스를 $\mathrm{div}$로 표기하는 일이 잦고, 라</description>
    </item>
    
    <item>
      <title>편 도함수</title>
      <link>https://freshrimpsushi.github.io/posts/partial-derivative/</link>
      <pubDate>Mon, 08 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/partial-derivative/</guid>
      <description>정의1 $E\subset \mathbb{R}^{n}$를 열린집합, $\mathbf{x}\in E$, 그리고 $\mathbf{f} : E \to \mathbb{R}^{m}$라고 하자. $\left\{ \mathbf{e}_{1}, \mathbf{e}_{2}, \dots, \mathbf{e}_{n} \right\}$, $\left\{ \mathbf{u}_{1}, \mathbf{u}_{2}, \dots, \mathbf{u}_{m} \right\}$을 각각 $\mathbb{R}^{n}$, $\mathbb{R}^{m}$의 표준기저라고 하자. 그러면 $\mathbf{f}$의 성분components $f_{i} : \mathbb{R}^{n} \to \mathbb{R}$은 다음</description>
    </item>
    
    <item>
      <title>다변수 함수의 적분</title>
      <link>https://freshrimpsushi.github.io/posts/integral-of-multi-variable-function/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integral-of-multi-variable-function/</guid>
      <description>정의1 $I^{k}$가 k-cell이고, $\mathbf{x} \in I^{k}$라고 하자. $$ \mathbf{x} = (x_{1},\dots,x_{k}),\quad a_{i} \le x_{i} \le b_{i} (i=1,\dots,k) $$ $f: I^{k} \to \mathbb{R}$가 연속이라고 하자. 그러면 적분가능하므로 $f=f_{k}$로 두고, $f_{k-1} : I^{k-1} \to \mathbb{R}$을 다음과 같이 정의하자. $$ f_{k-1} (x_{1}, \dots, x_{k-1}) = \int_{a_{k}}^{b_{k}} f_{k}(x_{1}, \dots, x_{k}) dx_{k} $$ 그러면 라이프니츠 룰에 의해서 $f_{k-1}$</description>
    </item>
    
    <item>
      <title>벡터값 함수의 적분</title>
      <link>https://freshrimpsushi.github.io/posts/integration-of-vector-valued-function/</link>
      <pubDate>Tue, 10 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/integration-of-vector-valued-function/</guid>
      <description>정의1 $f_{1}$, $f_{2}$, $\dots$, $f_{k}$가 구간 $[a,b]$위에서 실수값을 갖는 함수라고 하자. 그리고 $\mathbf{f} : [a,b] \to \mathbb{R}^{k}$가 다음과 같다고 하자. $$ \mathbf{f}(x)=\left( f_{1}(x),\dots,f_{k}(x) \right),\quad x\in [a,b] $$ 이때 각각의 $f_{k}$가 구간 $[a,b]$에서 적분가능하면, $\mathbf{f}$의 적분을 다음과 같이 정의한다. $$ \int _{a} ^{b} \mathbf{f}dx = \left( \int _{a} ^{b}f_{1} dx, \dots, \int _{a} ^{b}f_{k}</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 다이벌전스</title>
      <link>https://freshrimpsushi.github.io/posts/divergence-in-vector-field/</link>
      <pubDate>Mon, 09 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/divergence-in-vector-field/</guid>
      <description>정의 유클리드 공간에서 정의된 벡터 필드 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 을 $\textbf{f} = (f_{1} , \cdots , f_{n})$ 과 같이 나타내고 축의 방향을 $u_{1} , \cdots , u_{n}$ 이라고 할 때, $\textbf{f}$ 의 다이벌전스 를 다음과 같이 정의한다. $$ \text{div} \textbf{f} := \nabla \cdot \textbf{f} = \sum_{k=1}^{n} {{ \partial f_{k} } \over { \partial u_{k} }} $$ 설명 벡터 필드의 다이벌전스는 다음과 다음과 같이 한 점 $\textbf{v} \in \mathbb{R}^{n}$ 가 주어져 있을 때 그 점에서 벡터들이 모이는지, 퍼지는지에 대한 하나의 척도가 된</description>
    </item>
    
    <item>
      <title>벡터 필드에서의 볼륨</title>
      <link>https://freshrimpsushi.github.io/posts/volume-in-vector-field/</link>
      <pubDate>Thu, 05 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/volume-in-vector-field/</guid>
      <description>정의 유클리드 공간의 부분공간 $D \subset \mathbb{R}^{n}$ 의 볼륨 $V$ 는 직교좌표 $\textbf{u} = (u_{1}, u_{2}, \cdots , u_{n})$ 으로 나타낼 때 다음과 같이 정의된다. $$ V(D) = \int_{D} du_{1} du_{2} \cdots d u_{n} $$ $\textbf{u} \in \mathbb{R}^{n}$ 가 벡터 함수 $\textbf{f} : \mathbb{R}^{n} \to \mathbb{R}^{n}$ 에 의해 $\textbf{f} \left( \textbf{u} \right) = \left( f_{1} (\textbf{u}) , \cdots , f_{n} (\textbf{u}) \right)$ 와 같이 변환될 때, $D$ 의 볼륨 은 다음과 같다. $$ V(D) = \int_{D} \left| {{ \partial \textbf{f} (\textbf{u}) } \over { \partial \textbf{u} }} \right| d u_{1} d u_{2} \cdots d u_{n} $$ $\displaystyle \left| {{ \partial \textbf{f} (\textbf{u}) } \over { \partial \textbf{u} }} \right|$ 는 다음과 같이</description>
    </item>
    
    <item>
      <title>스칼라 필드의 그래디언트</title>
      <link>https://freshrimpsushi.github.io/posts/gradient-in-scalar-field/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/gradient-in-scalar-field/</guid>
      <description>정의 스칼라 필드 $f : \mathbb{R}^{n} \to \mathbb{R}$의 전 도함수를 특별히 그래디언트gradient, 기울기라 부르고 $\nabla f$라 표기한다. $$ \begin{align*} \nabla f := f^{\prime} =&amp;amp; \begin{bmatrix} D_{1}f &amp;amp; D_{2}f &amp;amp; \cdots &amp;amp; D_{n}f\end{bmatrix} \\ =&amp;amp; \begin{bmatrix} \dfrac{\partial f}{\partial x_{1}} &amp;amp; \dfrac{\partial f}{\partial x_{2}} &amp;amp; \cdots &amp;amp; \dfrac{\partial f}{\partial x_{n}} \end{bmatrix} \\ =&amp;amp; \dfrac{\partial f}{\partial x_{1}}\hat{x}_{1} + \dfrac{\partial f}{\partial x_{2}}\hat{x}_{2} + \dots + \dfrac{\partial f}{\partial x_{n}}\hat{x}_{n} \end{align*} $$ 설명 그래디언트는 쉽게 말해 다변수 함수의 도함수이다. 물리학 등에서 자주 쓰이는 3차원 스칼</description>
    </item>
    
    <item>
      <title>헤세 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/hessian-matrix/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/hessian-matrix/</guid>
      <description>정의 $D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 스칼라 함수 $f : D \to \mathbb{R}$ 에 대해 다음과 같은 행렬 $H \in \mathbb{R}^{n \times n}$ 을 $f$ 의 헤세 행렬이라 한다. $$ H := \begin{bmatrix} {{\partial^2 f } \over {\partial x_{1}^2 }} &amp;amp; \cdots &amp;amp; {{\partial^2 f } \over { \partial x_{1} \partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial^2 f } \over {\partial x_{n} \partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial^2 f_{m} } \over {\partial x_{n}^2 }} \end{bmatrix} $$ 설명 야코비 행렬이 함수의 고차원적인 도함수에 해당한다면, 헤세 행렬은 고차원적인 이계도함수라고 볼 수 있다.</description>
    </item>
    
    <item>
      <title>야코비 행렬 혹은 자코비 행렬이란</title>
      <link>https://freshrimpsushi.github.io/posts/jacobian-matrix/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/jacobian-matrix/</guid>
      <description>정의 $D \subset \mathbb{R}^{n}$ 에서 정의된 다변수 벡터 함수 $\mathbb{f} : D \to \mathbb{R}^{m}$ 가 각각의 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ 과 같이 정의되었다고 하자. $$ J := \begin{bmatrix} {{\partial f_{1} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{1} } \over {\partial x_{n} }} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {{\partial f_{m} } \over {\partial x_{1} }} &amp;amp; \cdots &amp;amp; {{\partial f_{m} } \over {\partial x_{n} }} \end{bmatrix} $$ 을 $\mathbb{f}$ 의 야코비 행렬이라 한다. 설명</description>
    </item>
    
    <item>
      <title>스칼라 함수와 벡터 함수</title>
      <link>https://freshrimpsushi.github.io/posts/scalar-function-and-vector-function/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/scalar-function-and-vector-function/</guid>
      <description>정의 집합 $D$ 를 $n$차원 유클리드 공간의 부분집합 $D\subset \mathbb{R}^{n}$ 이라 하자. $D$ 를 정의역으로 갖는 함수를 다변수 함수라 한다. $f : D \to \mathbb{R}$ 을 스칼라 함수라 한다. 스칼라 함수 $f_{1} , \cdots , f_{m} : D \to \mathbb{R}$ 에 대해 다음과 같이 정의된 $\mathbb{f} : D \to \mathbb{R}^{m}$ 를 벡터 함수라 한다. $$ \mathbb{f} ( x_{1} , \cdots , x_{n} ) : = \begin{bmatrix} f_{1} ( x_{1} , \cdots , x_{n} ) \\ \vdots \\ f_{m} ( x_{1} , \cdots , x_{n} ) \end{bmatrix} $$ 설명 다변수 함수 다변수 함수라</description>
    </item>
    
    <item>
      <title>파푸스-굴딘 정리 증명</title>
      <link>https://freshrimpsushi.github.io/posts/proof-of-pappus-guldinus-theorem/</link>
      <pubDate>Sat, 08 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/proof-of-pappus-guldinus-theorem/</guid>
      <description>정리 $yz$-평면 상의 도형 $F$ 의 넓이를 $A$ 라고 하고 $F$ 를 $z$-축으로 회전시켜서 얻은 회전체 $W$ 의 부피를 $V$ 라고 하자. $z$-축과 $F$ 의 무게중심 사이의 거리를 $r$ 이라고 하면 $$ V = 2 \pi r A $$ 설명 파푸스-굴딘 정리는 고등학교 수준으로는 증명할 수 없지만 회전체에 대해 배울때 선생님들이 심심찮게 언급하는 정리다. 막상 학부수준의 수학을 공부</description>
    </item>
    
    <item>
      <title>유클리드 공간에서 내적이란</title>
      <link>https://freshrimpsushi.github.io/posts/inner-product-in-euclidean-space/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://freshrimpsushi.github.io/posts/inner-product-in-euclidean-space/</guid>
      <description>정의 벡터공간 $V = \mathbb{R}^n$ 에 대해 $\mathbb{x}, \mathbb{y}, \mathbb{z} \in V$ 그리고 $k \in \mathbb{R}$ 이라고 하자. $\left&amp;lt; \cdot , \cdot \right&amp;gt; : V^2 \to \mathbb{R}$ 가 아래 네 조건들을 만족시킬 때 $\left&amp;lt; \cdot , \cdot \right&amp;gt;$ 를 $V$ 상에서의 내적 으로 정의한다. (1) 대칭성: $\left&amp;lt; \mathbb{x} , \mathbb{y} \right&amp;gt; = \left&amp;lt; \mathbb{y}, \mathbb{x} \right&amp;gt;$ (2) 가산성: $\left&amp;lt; \mathbb{x} + \mathbb{y} , \mathbb{z} \right&amp;gt; = \left&amp;lt; \mathbb{x}, \mathbb{z} \right&amp;gt; + \left&amp;lt; \mathbb{y}, \mathbb{z} \right&amp;gt;$ (3) 동질성: $\left&amp;lt; k \mathbb{x} , \mathbb{y} \right&amp;gt; = k \left&amp;lt; \mathbb{x}, \mathbb{y} \right&amp;gt;$ (4) 정부호: $\left&amp;lt; \mathbb{x} , \mathbb{x} \right&amp;gt; \ge 0$ 그리고 $\left&amp;lt; \mathbb{x} , \mathbb{x} \right&amp;gt; =0 \iff \mathbb{x}=\mathbb{0}$ 특히</description>
    </item>
    
  </channel>
</rss>
